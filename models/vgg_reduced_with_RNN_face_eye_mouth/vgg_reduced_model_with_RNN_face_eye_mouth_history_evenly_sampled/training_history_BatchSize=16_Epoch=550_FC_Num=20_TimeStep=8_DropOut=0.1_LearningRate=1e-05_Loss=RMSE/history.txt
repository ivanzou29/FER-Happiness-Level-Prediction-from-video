Epoch: 1| Step: 0
Training loss: 5.2600792905683855
Validation loss: 5.765177153132577

Epoch: 6| Step: 1
Training loss: 5.2546075856248535
Validation loss: 5.753697601499163

Epoch: 6| Step: 2
Training loss: 6.279145300950538
Validation loss: 5.741671818842335

Epoch: 6| Step: 3
Training loss: 4.74963638520108
Validation loss: 5.729274623297461

Epoch: 6| Step: 4
Training loss: 6.577202884077723
Validation loss: 5.717397240117493

Epoch: 6| Step: 5
Training loss: 5.495456552881605
Validation loss: 5.704725469826312

Epoch: 6| Step: 6
Training loss: 6.048930920179169
Validation loss: 5.691620900733382

Epoch: 6| Step: 7
Training loss: 5.669723396887788
Validation loss: 5.6781149547142045

Epoch: 6| Step: 8
Training loss: 5.95541602077208
Validation loss: 5.664000730365122

Epoch: 6| Step: 9
Training loss: 5.97688705460672
Validation loss: 5.648455930610073

Epoch: 6| Step: 10
Training loss: 6.868524449457319
Validation loss: 5.6328882889280365

Epoch: 6| Step: 11
Training loss: 5.739155702070421
Validation loss: 5.615226898516528

Epoch: 6| Step: 12
Training loss: 5.002225189972587
Validation loss: 5.5962200347322355

Epoch: 6| Step: 13
Training loss: 3.7772447795979547
Validation loss: 5.5766028456485675

Epoch: 2| Step: 0
Training loss: 6.00261504088856
Validation loss: 5.557952244047305

Epoch: 6| Step: 1
Training loss: 5.341452835413258
Validation loss: 5.535519196756888

Epoch: 6| Step: 2
Training loss: 6.195661614335911
Validation loss: 5.513251698199533

Epoch: 6| Step: 3
Training loss: 5.305766427119686
Validation loss: 5.48907993802258

Epoch: 6| Step: 4
Training loss: 5.9093829529626545
Validation loss: 5.464707121338487

Epoch: 6| Step: 5
Training loss: 4.802899978717692
Validation loss: 5.438080761005267

Epoch: 6| Step: 6
Training loss: 5.099777306575274
Validation loss: 5.41029701024623

Epoch: 6| Step: 7
Training loss: 5.7628385431965015
Validation loss: 5.3816096614572455

Epoch: 6| Step: 8
Training loss: 5.23356927392489
Validation loss: 5.35242956107688

Epoch: 6| Step: 9
Training loss: 4.735674890519953
Validation loss: 5.320904600488594

Epoch: 6| Step: 10
Training loss: 6.707861020854387
Validation loss: 5.290148647712056

Epoch: 6| Step: 11
Training loss: 4.400866527195019
Validation loss: 5.25747368833269

Epoch: 6| Step: 12
Training loss: 5.043403116278346
Validation loss: 5.22414844582383

Epoch: 6| Step: 13
Training loss: 4.994424381482189
Validation loss: 5.187750185525153

Epoch: 3| Step: 0
Training loss: 4.241872758236663
Validation loss: 5.155192728492054

Epoch: 6| Step: 1
Training loss: 4.225017046470789
Validation loss: 5.121434708126156

Epoch: 6| Step: 2
Training loss: 5.0212509593625585
Validation loss: 5.086379896170624

Epoch: 6| Step: 3
Training loss: 5.22325259836233
Validation loss: 5.051991167444588

Epoch: 6| Step: 4
Training loss: 5.659924404326909
Validation loss: 5.017092481180876

Epoch: 6| Step: 5
Training loss: 4.487390866453476
Validation loss: 4.9817637654099505

Epoch: 6| Step: 6
Training loss: 5.067106811746758
Validation loss: 4.945821188267233

Epoch: 6| Step: 7
Training loss: 4.888966629585458
Validation loss: 4.907031447775749

Epoch: 6| Step: 8
Training loss: 5.201581663060319
Validation loss: 4.872001674581023

Epoch: 6| Step: 9
Training loss: 4.725580185888472
Validation loss: 4.834230536305262

Epoch: 6| Step: 10
Training loss: 5.418864268997731
Validation loss: 4.797534705532642

Epoch: 6| Step: 11
Training loss: 5.631034327027592
Validation loss: 4.761362708776178

Epoch: 6| Step: 12
Training loss: 4.83773252731684
Validation loss: 4.727360726663363

Epoch: 6| Step: 13
Training loss: 4.799433817850167
Validation loss: 4.691378719535296

Epoch: 4| Step: 0
Training loss: 3.858878408753943
Validation loss: 4.661409956662194

Epoch: 6| Step: 1
Training loss: 4.101850343322349
Validation loss: 4.630011916252335

Epoch: 6| Step: 2
Training loss: 5.124086996490928
Validation loss: 4.602171759378701

Epoch: 6| Step: 3
Training loss: 4.342905085879835
Validation loss: 4.574726802765642

Epoch: 6| Step: 4
Training loss: 4.432191924584004
Validation loss: 4.547856622301365

Epoch: 6| Step: 5
Training loss: 4.581069988549644
Validation loss: 4.521930109959548

Epoch: 6| Step: 6
Training loss: 5.421881156280277
Validation loss: 4.497205520586675

Epoch: 6| Step: 7
Training loss: 4.952696580138642
Validation loss: 4.472878652372761

Epoch: 6| Step: 8
Training loss: 4.308108982956815
Validation loss: 4.450398188371511

Epoch: 6| Step: 9
Training loss: 4.632630934864347
Validation loss: 4.427775696596022

Epoch: 6| Step: 10
Training loss: 4.263668743557027
Validation loss: 4.405306737609988

Epoch: 6| Step: 11
Training loss: 5.161432424634877
Validation loss: 4.384165221416881

Epoch: 6| Step: 12
Training loss: 4.31522493379523
Validation loss: 4.36353478521477

Epoch: 6| Step: 13
Training loss: 4.428038705699715
Validation loss: 4.345173901378997

Epoch: 5| Step: 0
Training loss: 4.7380928574460475
Validation loss: 4.325057646949125

Epoch: 6| Step: 1
Training loss: 3.8815941846890456
Validation loss: 4.3047366287146325

Epoch: 6| Step: 2
Training loss: 3.6810401325602973
Validation loss: 4.289490412120962

Epoch: 6| Step: 3
Training loss: 4.9369413808302305
Validation loss: 4.271539465962075

Epoch: 6| Step: 4
Training loss: 4.183890309940063
Validation loss: 4.253831086123301

Epoch: 6| Step: 5
Training loss: 4.920737095644627
Validation loss: 4.235616754880401

Epoch: 6| Step: 6
Training loss: 3.694408088320357
Validation loss: 4.217922465880021

Epoch: 6| Step: 7
Training loss: 5.295286227262667
Validation loss: 4.201127647215573

Epoch: 6| Step: 8
Training loss: 2.939035704113877
Validation loss: 4.18340979300615

Epoch: 6| Step: 9
Training loss: 4.949399299007962
Validation loss: 4.169437569160629

Epoch: 6| Step: 10
Training loss: 4.892810467287572
Validation loss: 4.1513259738250134

Epoch: 6| Step: 11
Training loss: 4.304850109649897
Validation loss: 4.136716802814015

Epoch: 6| Step: 12
Training loss: 3.9600296936463173
Validation loss: 4.122833708582894

Epoch: 6| Step: 13
Training loss: 3.183336717959963
Validation loss: 4.107973308014452

Epoch: 6| Step: 0
Training loss: 3.265963158142142
Validation loss: 4.097480837974556

Epoch: 6| Step: 1
Training loss: 4.4853331708541395
Validation loss: 4.0891123320960805

Epoch: 6| Step: 2
Training loss: 4.177436921461303
Validation loss: 4.078177090644819

Epoch: 6| Step: 3
Training loss: 4.02820560916241
Validation loss: 4.063266792218565

Epoch: 6| Step: 4
Training loss: 4.096076595394891
Validation loss: 4.054141362517698

Epoch: 6| Step: 5
Training loss: 4.50595377081985
Validation loss: 4.042106956262557

Epoch: 6| Step: 6
Training loss: 4.292757926394642
Validation loss: 4.03127304265161

Epoch: 6| Step: 7
Training loss: 4.371578513529315
Validation loss: 4.01516789213996

Epoch: 6| Step: 8
Training loss: 4.8703763505399085
Validation loss: 4.007009942116397

Epoch: 6| Step: 9
Training loss: 4.225951427348472
Validation loss: 3.992221589793057

Epoch: 6| Step: 10
Training loss: 3.969745060688758
Validation loss: 3.9829920042019595

Epoch: 6| Step: 11
Training loss: 2.934088816311946
Validation loss: 3.9721259900425405

Epoch: 6| Step: 12
Training loss: 4.6815721795685015
Validation loss: 3.962545397134736

Epoch: 6| Step: 13
Training loss: 4.0318543919959255
Validation loss: 3.9537005884394896

Epoch: 7| Step: 0
Training loss: 3.6657393467752306
Validation loss: 3.940753504771104

Epoch: 6| Step: 1
Training loss: 3.9488228166465085
Validation loss: 3.930286592827206

Epoch: 6| Step: 2
Training loss: 3.8331196490452113
Validation loss: 3.9217651545292993

Epoch: 6| Step: 3
Training loss: 3.8530773101107676
Validation loss: 3.909673309899351

Epoch: 6| Step: 4
Training loss: 4.655930271308214
Validation loss: 3.894818367496692

Epoch: 6| Step: 5
Training loss: 4.202189628581812
Validation loss: 3.8880500718453357

Epoch: 6| Step: 6
Training loss: 3.7991148068240435
Validation loss: 3.8793725805539827

Epoch: 6| Step: 7
Training loss: 3.7859977991306297
Validation loss: 3.863634081419733

Epoch: 6| Step: 8
Training loss: 4.923417494529532
Validation loss: 3.8569949658279987

Epoch: 6| Step: 9
Training loss: 3.342390122587036
Validation loss: 3.851878640055903

Epoch: 6| Step: 10
Training loss: 4.534962152998189
Validation loss: 3.8485775710015067

Epoch: 6| Step: 11
Training loss: 3.6992228748657046
Validation loss: 3.840407362652819

Epoch: 6| Step: 12
Training loss: 4.269649409747049
Validation loss: 3.83638522140465

Epoch: 6| Step: 13
Training loss: 3.465884838218372
Validation loss: 3.8291196460553527

Epoch: 8| Step: 0
Training loss: 3.420309466364575
Validation loss: 3.8181439869821276

Epoch: 6| Step: 1
Training loss: 3.6873797380912294
Validation loss: 3.814394509239113

Epoch: 6| Step: 2
Training loss: 4.117041568956716
Validation loss: 3.8069930142601565

Epoch: 6| Step: 3
Training loss: 4.179925701448401
Validation loss: 3.7979700934999894

Epoch: 6| Step: 4
Training loss: 4.701628082416367
Validation loss: 3.789362091544563

Epoch: 6| Step: 5
Training loss: 4.646788129783378
Validation loss: 3.7814498139397954

Epoch: 6| Step: 6
Training loss: 3.8973748052528423
Validation loss: 3.7782198762673675

Epoch: 6| Step: 7
Training loss: 3.7351402871214274
Validation loss: 3.7772009634087125

Epoch: 6| Step: 8
Training loss: 4.1511435438391695
Validation loss: 3.7658271869729014

Epoch: 6| Step: 9
Training loss: 3.2092134994091683
Validation loss: 3.7536859192745435

Epoch: 6| Step: 10
Training loss: 4.4762452763775125
Validation loss: 3.7472210941360484

Epoch: 6| Step: 11
Training loss: 3.544183323116405
Validation loss: 3.7428924583661716

Epoch: 6| Step: 12
Training loss: 3.6555858563137127
Validation loss: 3.736216612017276

Epoch: 6| Step: 13
Training loss: 3.257797131399226
Validation loss: 3.7328292552153517

Epoch: 9| Step: 0
Training loss: 4.292378017889607
Validation loss: 3.725652590710893

Epoch: 6| Step: 1
Training loss: 4.631213576447736
Validation loss: 3.7218325254870175

Epoch: 6| Step: 2
Training loss: 3.3616088537169495
Validation loss: 3.712743511868259

Epoch: 6| Step: 3
Training loss: 3.452803652901613
Validation loss: 3.7080215017890876

Epoch: 6| Step: 4
Training loss: 3.0551154966108625
Validation loss: 3.698957593392211

Epoch: 6| Step: 5
Training loss: 3.4965288115298576
Validation loss: 3.689726268554098

Epoch: 6| Step: 6
Training loss: 3.621362505407163
Validation loss: 3.691351139117096

Epoch: 6| Step: 7
Training loss: 4.582143224468329
Validation loss: 3.685624932229531

Epoch: 6| Step: 8
Training loss: 4.137482915652865
Validation loss: 3.6779711622719935

Epoch: 6| Step: 9
Training loss: 3.12953558794525
Validation loss: 3.676748034171942

Epoch: 6| Step: 10
Training loss: 4.283743250685429
Validation loss: 3.6700208476687317

Epoch: 6| Step: 11
Training loss: 4.665744599574331
Validation loss: 3.660913787530132

Epoch: 6| Step: 12
Training loss: 3.46306357083642
Validation loss: 3.6554655375200684

Epoch: 6| Step: 13
Training loss: 3.248481102119142
Validation loss: 3.6513335719951647

Epoch: 10| Step: 0
Training loss: 4.930959111325945
Validation loss: 3.6432912253725918

Epoch: 6| Step: 1
Training loss: 4.0754460564559105
Validation loss: 3.638168629451218

Epoch: 6| Step: 2
Training loss: 3.9977191144045854
Validation loss: 3.6400338441631446

Epoch: 6| Step: 3
Training loss: 3.0821847236819595
Validation loss: 3.6272395100519312

Epoch: 6| Step: 4
Training loss: 3.2789996468560396
Validation loss: 3.6196566058629704

Epoch: 6| Step: 5
Training loss: 4.102454795053687
Validation loss: 3.6162105093062187

Epoch: 6| Step: 6
Training loss: 3.5504189150079033
Validation loss: 3.606446203905437

Epoch: 6| Step: 7
Training loss: 4.510898532045057
Validation loss: 3.60435109280424

Epoch: 6| Step: 8
Training loss: 2.3030443443968465
Validation loss: 3.5904861416919513

Epoch: 6| Step: 9
Training loss: 4.041308252756628
Validation loss: 3.5865641140353652

Epoch: 6| Step: 10
Training loss: 3.7824600427386605
Validation loss: 3.5842465703374766

Epoch: 6| Step: 11
Training loss: 2.8242693167099566
Validation loss: 3.5811569809687342

Epoch: 6| Step: 12
Training loss: 3.609899705671858
Validation loss: 3.569231242396858

Epoch: 6| Step: 13
Training loss: 4.670871180240091
Validation loss: 3.5632956738329824

Epoch: 11| Step: 0
Training loss: 3.632328780589705
Validation loss: 3.557884984911897

Epoch: 6| Step: 1
Training loss: 3.903949762193097
Validation loss: 3.5587142045591778

Epoch: 6| Step: 2
Training loss: 3.9730945746694197
Validation loss: 3.545311370680078

Epoch: 6| Step: 3
Training loss: 3.1748330740714183
Validation loss: 3.5403032857572003

Epoch: 6| Step: 4
Training loss: 4.387170484727092
Validation loss: 3.533911657765358

Epoch: 6| Step: 5
Training loss: 3.7965838787730704
Validation loss: 3.52324519974039

Epoch: 6| Step: 6
Training loss: 3.9543332149588455
Validation loss: 3.519308883086701

Epoch: 6| Step: 7
Training loss: 3.552930460547027
Validation loss: 3.5147178990946952

Epoch: 6| Step: 8
Training loss: 4.064357626295785
Validation loss: 3.5106845662323116

Epoch: 6| Step: 9
Training loss: 3.6316564545845984
Validation loss: 3.4998788893235733

Epoch: 6| Step: 10
Training loss: 3.364802177248553
Validation loss: 3.499013454080981

Epoch: 6| Step: 11
Training loss: 3.5826828092583596
Validation loss: 3.4968130468350895

Epoch: 6| Step: 12
Training loss: 3.669203935188854
Validation loss: 3.4928324418767325

Epoch: 6| Step: 13
Training loss: 3.033259404158345
Validation loss: 3.483847564710192

Epoch: 12| Step: 0
Training loss: 3.6187644470664364
Validation loss: 3.48157641232117

Epoch: 6| Step: 1
Training loss: 4.0202529303848005
Validation loss: 3.471146854916885

Epoch: 6| Step: 2
Training loss: 3.9389833350815655
Validation loss: 3.469864057106404

Epoch: 6| Step: 3
Training loss: 3.9487768090072546
Validation loss: 3.461014393457564

Epoch: 6| Step: 4
Training loss: 3.483119858279866
Validation loss: 3.457752259520715

Epoch: 6| Step: 5
Training loss: 3.233083568508849
Validation loss: 3.4610296892801538

Epoch: 6| Step: 6
Training loss: 3.870929672197573
Validation loss: 3.4509228390414246

Epoch: 6| Step: 7
Training loss: 3.737039166366474
Validation loss: 3.444945704025141

Epoch: 6| Step: 8
Training loss: 3.5871768712852434
Validation loss: 3.4589135555133685

Epoch: 6| Step: 9
Training loss: 3.370818620861059
Validation loss: 3.4379568025786935

Epoch: 6| Step: 10
Training loss: 3.5073935209658305
Validation loss: 3.436162147198554

Epoch: 6| Step: 11
Training loss: 3.267931402049091
Validation loss: 3.4425464969568167

Epoch: 6| Step: 12
Training loss: 4.3270462840218595
Validation loss: 3.443270423390794

Epoch: 6| Step: 13
Training loss: 3.029921565032102
Validation loss: 3.4338209135944435

Epoch: 13| Step: 0
Training loss: 4.190005108231592
Validation loss: 3.424858918086334

Epoch: 6| Step: 1
Training loss: 3.0414138758573803
Validation loss: 3.4149232723859373

Epoch: 6| Step: 2
Training loss: 3.840560582290387
Validation loss: 3.4112997083773124

Epoch: 6| Step: 3
Training loss: 3.878819091063507
Validation loss: 3.4086199077463792

Epoch: 6| Step: 4
Training loss: 3.698137360913673
Validation loss: 3.4022093212611404

Epoch: 6| Step: 5
Training loss: 3.025738296578189
Validation loss: 3.3944655114105386

Epoch: 6| Step: 6
Training loss: 3.3322313076482097
Validation loss: 3.385521381484621

Epoch: 6| Step: 7
Training loss: 2.905834865659006
Validation loss: 3.3798351252774745

Epoch: 6| Step: 8
Training loss: 3.030038807938325
Validation loss: 3.3752220335997825

Epoch: 6| Step: 9
Training loss: 3.4283274949808686
Validation loss: 3.3683461950659894

Epoch: 6| Step: 10
Training loss: 3.7553789344302007
Validation loss: 3.365151829746587

Epoch: 6| Step: 11
Training loss: 4.634476721400289
Validation loss: 3.3679781096152386

Epoch: 6| Step: 12
Training loss: 3.3199418163946195
Validation loss: 3.353490639178538

Epoch: 6| Step: 13
Training loss: 4.364214873257381
Validation loss: 3.3463349707089467

Epoch: 14| Step: 0
Training loss: 3.392636875660697
Validation loss: 3.3382438657517106

Epoch: 6| Step: 1
Training loss: 4.0852895190061576
Validation loss: 3.339528024081741

Epoch: 6| Step: 2
Training loss: 3.53363226819599
Validation loss: 3.333775633006048

Epoch: 6| Step: 3
Training loss: 3.346975321828896
Validation loss: 3.3265508641598047

Epoch: 6| Step: 4
Training loss: 3.734666884758573
Validation loss: 3.324039041441053

Epoch: 6| Step: 5
Training loss: 4.421735673738108
Validation loss: 3.318102891272151

Epoch: 6| Step: 6
Training loss: 3.0611846590370257
Validation loss: 3.3200407407514194

Epoch: 6| Step: 7
Training loss: 2.819637481979759
Validation loss: 3.314402915380965

Epoch: 6| Step: 8
Training loss: 2.5369101454205074
Validation loss: 3.3055134465491873

Epoch: 6| Step: 9
Training loss: 3.682265364765654
Validation loss: 3.3077000106300494

Epoch: 6| Step: 10
Training loss: 2.9203036565835534
Validation loss: 3.29747977515302

Epoch: 6| Step: 11
Training loss: 4.197086577148961
Validation loss: 3.296940395272546

Epoch: 6| Step: 12
Training loss: 3.534954052617059
Validation loss: 3.2896216771675477

Epoch: 6| Step: 13
Training loss: 4.218045324177008
Validation loss: 3.287109495105724

Epoch: 15| Step: 0
Training loss: 3.387006525223165
Validation loss: 3.2813390076143483

Epoch: 6| Step: 1
Training loss: 2.750229999287462
Validation loss: 3.2787184677373915

Epoch: 6| Step: 2
Training loss: 3.507504048198993
Validation loss: 3.281093678459514

Epoch: 6| Step: 3
Training loss: 3.336176772101849
Validation loss: 3.2767194199479155

Epoch: 6| Step: 4
Training loss: 3.7656443741802557
Validation loss: 3.275815560791257

Epoch: 6| Step: 5
Training loss: 4.365476870361824
Validation loss: 3.275237347292735

Epoch: 6| Step: 6
Training loss: 3.8764361519694104
Validation loss: 3.264586301388484

Epoch: 6| Step: 7
Training loss: 3.4718053609901016
Validation loss: 3.264073290503418

Epoch: 6| Step: 8
Training loss: 3.9505116867666996
Validation loss: 3.267476112171763

Epoch: 6| Step: 9
Training loss: 3.2665587919939134
Validation loss: 3.2541390551538147

Epoch: 6| Step: 10
Training loss: 3.7601883132933946
Validation loss: 3.2568274912963178

Epoch: 6| Step: 11
Training loss: 3.0740211355442013
Validation loss: 3.2548799234749364

Epoch: 6| Step: 12
Training loss: 3.1681344662748967
Validation loss: 3.250862940971863

Epoch: 6| Step: 13
Training loss: 2.938047966676546
Validation loss: 3.2504765845024464

Epoch: 16| Step: 0
Training loss: 3.1807959871512415
Validation loss: 3.242608015156133

Epoch: 6| Step: 1
Training loss: 3.5643634941641786
Validation loss: 3.2436098329794207

Epoch: 6| Step: 2
Training loss: 3.632094445584463
Validation loss: 3.24272910441326

Epoch: 6| Step: 3
Training loss: 4.38895262230633
Validation loss: 3.2359692492295395

Epoch: 6| Step: 4
Training loss: 2.26652845587751
Validation loss: 3.2343700508570046

Epoch: 6| Step: 5
Training loss: 3.144164411104352
Validation loss: 3.232658355125463

Epoch: 6| Step: 6
Training loss: 3.7855578387649507
Validation loss: 3.2366609227919345

Epoch: 6| Step: 7
Training loss: 3.2009132750947398
Validation loss: 3.2315290914812396

Epoch: 6| Step: 8
Training loss: 3.797787654748043
Validation loss: 3.227906700114687

Epoch: 6| Step: 9
Training loss: 3.190988015979916
Validation loss: 3.225254702655416

Epoch: 6| Step: 10
Training loss: 3.360671533961581
Validation loss: 3.228926478148737

Epoch: 6| Step: 11
Training loss: 3.2563862777572656
Validation loss: 3.2221054760970675

Epoch: 6| Step: 12
Training loss: 4.128790760861182
Validation loss: 3.223373347025131

Epoch: 6| Step: 13
Training loss: 3.3415868304094714
Validation loss: 3.2182143176089615

Epoch: 17| Step: 0
Training loss: 3.26648989088829
Validation loss: 3.21614932894989

Epoch: 6| Step: 1
Training loss: 3.7540645188898
Validation loss: 3.213977635697403

Epoch: 6| Step: 2
Training loss: 3.3491466858827743
Validation loss: 3.209502425988452

Epoch: 6| Step: 3
Training loss: 3.5177917585043565
Validation loss: 3.210418522703354

Epoch: 6| Step: 4
Training loss: 3.0658964668804267
Validation loss: 3.205720423736343

Epoch: 6| Step: 5
Training loss: 3.544905733434325
Validation loss: 3.20562603439741

Epoch: 6| Step: 6
Training loss: 3.954748611852184
Validation loss: 3.206763291008273

Epoch: 6| Step: 7
Training loss: 3.080961518004931
Validation loss: 3.204940767059369

Epoch: 6| Step: 8
Training loss: 3.414095461618629
Validation loss: 3.2043998048308158

Epoch: 6| Step: 9
Training loss: 3.7504928265029904
Validation loss: 3.199004653813982

Epoch: 6| Step: 10
Training loss: 3.5810116780124472
Validation loss: 3.199819921097544

Epoch: 6| Step: 11
Training loss: 3.5933024252114882
Validation loss: 3.1959129491609426

Epoch: 6| Step: 12
Training loss: 3.356028464622862
Validation loss: 3.1961145021071378

Epoch: 6| Step: 13
Training loss: 2.819091786303396
Validation loss: 3.193557229469515

Epoch: 18| Step: 0
Training loss: 3.3515270738129903
Validation loss: 3.190928771087182

Epoch: 6| Step: 1
Training loss: 3.416729546565335
Validation loss: 3.18964638166695

Epoch: 6| Step: 2
Training loss: 4.1946716387412675
Validation loss: 3.1898798606757675

Epoch: 6| Step: 3
Training loss: 3.481791132675415
Validation loss: 3.1901974493087066

Epoch: 6| Step: 4
Training loss: 3.4417997345280935
Validation loss: 3.1839227438581297

Epoch: 6| Step: 5
Training loss: 2.879506601083949
Validation loss: 3.1820352652863626

Epoch: 6| Step: 6
Training loss: 2.3606608341679687
Validation loss: 3.1809316781333465

Epoch: 6| Step: 7
Training loss: 3.802696631449504
Validation loss: 3.179731640571461

Epoch: 6| Step: 8
Training loss: 3.517590867463733
Validation loss: 3.180087632344044

Epoch: 6| Step: 9
Training loss: 4.072657402092562
Validation loss: 3.1783757314381402

Epoch: 6| Step: 10
Training loss: 2.8293434173998717
Validation loss: 3.182092548855074

Epoch: 6| Step: 11
Training loss: 3.4201211136013385
Validation loss: 3.1819051145901525

Epoch: 6| Step: 12
Training loss: 3.4614669360408743
Validation loss: 3.1807852193129387

Epoch: 6| Step: 13
Training loss: 3.6764085418850967
Validation loss: 3.1807838394795276

Epoch: 19| Step: 0
Training loss: 4.1877500544801896
Validation loss: 3.1824945811732777

Epoch: 6| Step: 1
Training loss: 4.231906297911928
Validation loss: 3.1792346182036906

Epoch: 6| Step: 2
Training loss: 3.841377828887387
Validation loss: 3.1778537130260127

Epoch: 6| Step: 3
Training loss: 2.3952374809247736
Validation loss: 3.176072788487954

Epoch: 6| Step: 4
Training loss: 3.2307471232653455
Validation loss: 3.174728470310796

Epoch: 6| Step: 5
Training loss: 2.98873790168946
Validation loss: 3.173208424689951

Epoch: 6| Step: 6
Training loss: 3.546962518494519
Validation loss: 3.1795496418282214

Epoch: 6| Step: 7
Training loss: 3.316920659549029
Validation loss: 3.1776160482297393

Epoch: 6| Step: 8
Training loss: 3.7153833360422226
Validation loss: 3.170627201657735

Epoch: 6| Step: 9
Training loss: 3.6590740024686563
Validation loss: 3.1693829257015604

Epoch: 6| Step: 10
Training loss: 3.5292687723701284
Validation loss: 3.1691838435196296

Epoch: 6| Step: 11
Training loss: 3.007251558387626
Validation loss: 3.167269756700031

Epoch: 6| Step: 12
Training loss: 2.5507879797480135
Validation loss: 3.166280233630886

Epoch: 6| Step: 13
Training loss: 3.241988063331388
Validation loss: 3.1642055684220463

Epoch: 20| Step: 0
Training loss: 3.6008792651147847
Validation loss: 3.1590883011178312

Epoch: 6| Step: 1
Training loss: 3.1973929872120586
Validation loss: 3.1653480299373404

Epoch: 6| Step: 2
Training loss: 3.6216945705283905
Validation loss: 3.1597514711943657

Epoch: 6| Step: 3
Training loss: 3.207955044990299
Validation loss: 3.1566824927898485

Epoch: 6| Step: 4
Training loss: 3.2956919784872842
Validation loss: 3.1575417342004215

Epoch: 6| Step: 5
Training loss: 2.9870178344316747
Validation loss: 3.1586539528464384

Epoch: 6| Step: 6
Training loss: 3.6695485638280467
Validation loss: 3.159020615354996

Epoch: 6| Step: 7
Training loss: 3.66727812321452
Validation loss: 3.159611824706681

Epoch: 6| Step: 8
Training loss: 2.9364180499982404
Validation loss: 3.156682327927192

Epoch: 6| Step: 9
Training loss: 3.937112335013212
Validation loss: 3.1539512587923975

Epoch: 6| Step: 10
Training loss: 3.5165926131516225
Validation loss: 3.1565136949087624

Epoch: 6| Step: 11
Training loss: 3.539824212230208
Validation loss: 3.1556566383854996

Epoch: 6| Step: 12
Training loss: 3.1553369088903893
Validation loss: 3.149874226939754

Epoch: 6| Step: 13
Training loss: 3.371799505624249
Validation loss: 3.148111206627211

Epoch: 21| Step: 0
Training loss: 2.770923259298846
Validation loss: 3.149253858870303

Epoch: 6| Step: 1
Training loss: 3.3746442254067746
Validation loss: 3.1461972490177113

Epoch: 6| Step: 2
Training loss: 3.944168015466445
Validation loss: 3.141994253952205

Epoch: 6| Step: 3
Training loss: 3.69615837884074
Validation loss: 3.155346975472096

Epoch: 6| Step: 4
Training loss: 4.088995349115463
Validation loss: 3.150760974889332

Epoch: 6| Step: 5
Training loss: 3.0567139443083486
Validation loss: 3.1561698485092244

Epoch: 6| Step: 6
Training loss: 3.255717017546188
Validation loss: 3.1440354454881176

Epoch: 6| Step: 7
Training loss: 2.359253937097377
Validation loss: 3.141374025554635

Epoch: 6| Step: 8
Training loss: 3.7129155398460485
Validation loss: 3.146197579841865

Epoch: 6| Step: 9
Training loss: 3.389807395977496
Validation loss: 3.143191063981632

Epoch: 6| Step: 10
Training loss: 3.6271845056109484
Validation loss: 3.1485812849204535

Epoch: 6| Step: 11
Training loss: 3.898982252692557
Validation loss: 3.1476730028798015

Epoch: 6| Step: 12
Training loss: 2.1849270539142753
Validation loss: 3.148304421362961

Epoch: 6| Step: 13
Training loss: 3.979738177788222
Validation loss: 3.138537623454438

Epoch: 22| Step: 0
Training loss: 3.275534747779534
Validation loss: 3.139891614175242

Epoch: 6| Step: 1
Training loss: 4.074945957316944
Validation loss: 3.141892555058345

Epoch: 6| Step: 2
Training loss: 3.647947748219905
Validation loss: 3.13332271239218

Epoch: 6| Step: 3
Training loss: 2.406419723271899
Validation loss: 3.141746042973945

Epoch: 6| Step: 4
Training loss: 3.2489772067551734
Validation loss: 3.1512889081990942

Epoch: 6| Step: 5
Training loss: 3.71833119318097
Validation loss: 3.136538069160754

Epoch: 6| Step: 6
Training loss: 3.2920653347239055
Validation loss: 3.135119464592913

Epoch: 6| Step: 7
Training loss: 3.698881655583774
Validation loss: 3.1358958594838247

Epoch: 6| Step: 8
Training loss: 3.5538579958065166
Validation loss: 3.1348048452554163

Epoch: 6| Step: 9
Training loss: 3.494273269037632
Validation loss: 3.1416348122761035

Epoch: 6| Step: 10
Training loss: 3.7678260543666764
Validation loss: 3.1394889032524307

Epoch: 6| Step: 11
Training loss: 3.6990458882113453
Validation loss: 3.1321697097859147

Epoch: 6| Step: 12
Training loss: 2.839721677063799
Validation loss: 3.1295550498695905

Epoch: 6| Step: 13
Training loss: 1.3044149148314697
Validation loss: 3.133838916571789

Epoch: 23| Step: 0
Training loss: 3.907774848863376
Validation loss: 3.1403866834955503

Epoch: 6| Step: 1
Training loss: 3.509032719022287
Validation loss: 3.1413887787760615

Epoch: 6| Step: 2
Training loss: 3.843231166155477
Validation loss: 3.1401973509325507

Epoch: 6| Step: 3
Training loss: 2.9636347018065425
Validation loss: 3.1336778659691795

Epoch: 6| Step: 4
Training loss: 2.9793233407889326
Validation loss: 3.134158020456068

Epoch: 6| Step: 5
Training loss: 3.1312012750485594
Validation loss: 3.129652259378458

Epoch: 6| Step: 6
Training loss: 3.5972758370572553
Validation loss: 3.12431664983683

Epoch: 6| Step: 7
Training loss: 3.2232863671379923
Validation loss: 3.1241683164983725

Epoch: 6| Step: 8
Training loss: 3.162448952002773
Validation loss: 3.127884063501174

Epoch: 6| Step: 9
Training loss: 3.271955714646578
Validation loss: 3.1248335254585844

Epoch: 6| Step: 10
Training loss: 3.455697736714567
Validation loss: 3.1246381882438983

Epoch: 6| Step: 11
Training loss: 3.3427922668729106
Validation loss: 3.124637850214362

Epoch: 6| Step: 12
Training loss: 3.4724615362136695
Validation loss: 3.120448867859791

Epoch: 6| Step: 13
Training loss: 3.565735669303361
Validation loss: 3.1195298554326

Epoch: 24| Step: 0
Training loss: 3.729423144736016
Validation loss: 3.121610214824697

Epoch: 6| Step: 1
Training loss: 3.4572302809496414
Validation loss: 3.123379869413697

Epoch: 6| Step: 2
Training loss: 3.392748471004003
Validation loss: 3.1168379728380793

Epoch: 6| Step: 3
Training loss: 2.874950242648571
Validation loss: 3.116006712316429

Epoch: 6| Step: 4
Training loss: 3.4003226127155104
Validation loss: 3.118533563630239

Epoch: 6| Step: 5
Training loss: 3.6515827875385827
Validation loss: 3.1228427684949445

Epoch: 6| Step: 6
Training loss: 3.2718883845684923
Validation loss: 3.1171055635805893

Epoch: 6| Step: 7
Training loss: 2.501768059180554
Validation loss: 3.1135878723108585

Epoch: 6| Step: 8
Training loss: 3.855238578132841
Validation loss: 3.1109038570572145

Epoch: 6| Step: 9
Training loss: 3.890240385968471
Validation loss: 3.1143493471165846

Epoch: 6| Step: 10
Training loss: 2.691014586631341
Validation loss: 3.114370607892735

Epoch: 6| Step: 11
Training loss: 3.8359742949482736
Validation loss: 3.1232946816854685

Epoch: 6| Step: 12
Training loss: 2.732139065594718
Validation loss: 3.123595792241111

Epoch: 6| Step: 13
Training loss: 3.864050500267268
Validation loss: 3.1192330962820316

Epoch: 25| Step: 0
Training loss: 3.782301827412437
Validation loss: 3.11050649877702

Epoch: 6| Step: 1
Training loss: 3.335374270917675
Validation loss: 3.102942513931697

Epoch: 6| Step: 2
Training loss: 3.775238555040057
Validation loss: 3.103907254210848

Epoch: 6| Step: 3
Training loss: 3.547709900316569
Validation loss: 3.108824790638355

Epoch: 6| Step: 4
Training loss: 3.5306052910674506
Validation loss: 3.1106233169224184

Epoch: 6| Step: 5
Training loss: 3.9094163192651186
Validation loss: 3.1053597557344164

Epoch: 6| Step: 6
Training loss: 3.0706690612774796
Validation loss: 3.1060766554713557

Epoch: 6| Step: 7
Training loss: 2.957148641576697
Validation loss: 3.1034201229251637

Epoch: 6| Step: 8
Training loss: 3.461447512418119
Validation loss: 3.104568650047511

Epoch: 6| Step: 9
Training loss: 2.7019371112758703
Validation loss: 3.1169262141040917

Epoch: 6| Step: 10
Training loss: 3.3912662304083137
Validation loss: 3.1443533107516086

Epoch: 6| Step: 11
Training loss: 3.8826317236589025
Validation loss: 3.133644710111502

Epoch: 6| Step: 12
Training loss: 2.968051547155518
Validation loss: 3.099732495746531

Epoch: 6| Step: 13
Training loss: 1.9699545914117211
Validation loss: 3.1030110263567283

Epoch: 26| Step: 0
Training loss: 3.1565589375896423
Validation loss: 3.106681126328471

Epoch: 6| Step: 1
Training loss: 3.351042878389164
Validation loss: 3.121029014623993

Epoch: 6| Step: 2
Training loss: 3.7920624802347214
Validation loss: 3.115556993911853

Epoch: 6| Step: 3
Training loss: 3.6755464420054422
Validation loss: 3.1091817423830164

Epoch: 6| Step: 4
Training loss: 3.35745865922076
Validation loss: 3.1041412457085027

Epoch: 6| Step: 5
Training loss: 3.220362435314186
Validation loss: 3.1021078926944

Epoch: 6| Step: 6
Training loss: 3.6323367884095763
Validation loss: 3.1012205480568555

Epoch: 6| Step: 7
Training loss: 2.7584793105975307
Validation loss: 3.1043138774005983

Epoch: 6| Step: 8
Training loss: 4.040405994448527
Validation loss: 3.108937916732345

Epoch: 6| Step: 9
Training loss: 3.23316601258036
Validation loss: 3.115353183394759

Epoch: 6| Step: 10
Training loss: 3.4303709144341377
Validation loss: 3.113377450875157

Epoch: 6| Step: 11
Training loss: 2.7085776487828594
Validation loss: 3.1107452180042108

Epoch: 6| Step: 12
Training loss: 3.7297655331551356
Validation loss: 3.100325255212912

Epoch: 6| Step: 13
Training loss: 2.4997357228784445
Validation loss: 3.0924144011032215

Epoch: 27| Step: 0
Training loss: 3.0141566363199317
Validation loss: 3.096998531724249

Epoch: 6| Step: 1
Training loss: 3.7066693948374345
Validation loss: 3.097041992474549

Epoch: 6| Step: 2
Training loss: 2.990629662138395
Validation loss: 3.0939509621825376

Epoch: 6| Step: 3
Training loss: 4.143176174564215
Validation loss: 3.100035299509692

Epoch: 6| Step: 4
Training loss: 3.640398272220129
Validation loss: 3.096903546385117

Epoch: 6| Step: 5
Training loss: 3.151165180570396
Validation loss: 3.090551901677361

Epoch: 6| Step: 6
Training loss: 3.6900235609010523
Validation loss: 3.0883550256372243

Epoch: 6| Step: 7
Training loss: 3.3367055683237345
Validation loss: 3.0878298619744626

Epoch: 6| Step: 8
Training loss: 2.914814460830132
Validation loss: 3.0897121627257533

Epoch: 6| Step: 9
Training loss: 3.897166440538406
Validation loss: 3.0910098496249807

Epoch: 6| Step: 10
Training loss: 2.7189224013114144
Validation loss: 3.0920215591616476

Epoch: 6| Step: 11
Training loss: 2.643070330177325
Validation loss: 3.0886682260574703

Epoch: 6| Step: 12
Training loss: 3.3892898391866213
Validation loss: 3.094699745741703

Epoch: 6| Step: 13
Training loss: 3.4732165748120742
Validation loss: 3.101440326440396

Epoch: 28| Step: 0
Training loss: 3.834137845963625
Validation loss: 3.1212604067565763

Epoch: 6| Step: 1
Training loss: 3.667968229998632
Validation loss: 3.1226416403180215

Epoch: 6| Step: 2
Training loss: 3.650004734402029
Validation loss: 3.081806774987993

Epoch: 6| Step: 3
Training loss: 3.3014000668084815
Validation loss: 3.0838752515352654

Epoch: 6| Step: 4
Training loss: 3.7776709398109554
Validation loss: 3.0911184392409585

Epoch: 6| Step: 5
Training loss: 3.9069411009739436
Validation loss: 3.1034695627895093

Epoch: 6| Step: 6
Training loss: 3.1634246560016597
Validation loss: 3.1171148020654584

Epoch: 6| Step: 7
Training loss: 2.268123958584254
Validation loss: 3.123615491431594

Epoch: 6| Step: 8
Training loss: 3.1728010657916106
Validation loss: 3.11139657636806

Epoch: 6| Step: 9
Training loss: 3.3959803325141977
Validation loss: 3.097960863755935

Epoch: 6| Step: 10
Training loss: 3.201521607077787
Validation loss: 3.0908418180669472

Epoch: 6| Step: 11
Training loss: 2.0814927426389676
Validation loss: 3.0863073141687623

Epoch: 6| Step: 12
Training loss: 3.680955154191364
Validation loss: 3.0857591877879793

Epoch: 6| Step: 13
Training loss: 3.6171690443981124
Validation loss: 3.0880497200307477

Epoch: 29| Step: 0
Training loss: 3.3152195545061685
Validation loss: 3.094073224328324

Epoch: 6| Step: 1
Training loss: 3.494608950587933
Validation loss: 3.0912803536798665

Epoch: 6| Step: 2
Training loss: 3.5212208611715075
Validation loss: 3.0909080242150537

Epoch: 6| Step: 3
Training loss: 3.947711358817179
Validation loss: 3.081155737753975

Epoch: 6| Step: 4
Training loss: 3.6779103128140584
Validation loss: 3.077288507145338

Epoch: 6| Step: 5
Training loss: 2.9835330114902123
Validation loss: 3.076862911613476

Epoch: 6| Step: 6
Training loss: 2.9805201054819492
Validation loss: 3.0731007254768614

Epoch: 6| Step: 7
Training loss: 2.8802366249575866
Validation loss: 3.0771454349261735

Epoch: 6| Step: 8
Training loss: 3.42209962429837
Validation loss: 3.0727135256194575

Epoch: 6| Step: 9
Training loss: 3.2168929288937793
Validation loss: 3.0722488726107207

Epoch: 6| Step: 10
Training loss: 3.7867044249071418
Validation loss: 3.0744761007597465

Epoch: 6| Step: 11
Training loss: 3.4216485492903623
Validation loss: 3.0716662188078794

Epoch: 6| Step: 12
Training loss: 2.884839510891563
Validation loss: 3.068603831735397

Epoch: 6| Step: 13
Training loss: 3.0583053199531456
Validation loss: 3.0724833660419235

Epoch: 30| Step: 0
Training loss: 3.9045482132863887
Validation loss: 3.0755532832173555

Epoch: 6| Step: 1
Training loss: 3.4079829016422223
Validation loss: 3.0789072389840952

Epoch: 6| Step: 2
Training loss: 4.327160008130265
Validation loss: 3.078889478587881

Epoch: 6| Step: 3
Training loss: 2.9459392983578896
Validation loss: 3.0760219034129617

Epoch: 6| Step: 4
Training loss: 3.750558048687516
Validation loss: 3.06948112932724

Epoch: 6| Step: 5
Training loss: 3.5913280784757795
Validation loss: 3.0703830096667843

Epoch: 6| Step: 6
Training loss: 3.7081429650523963
Validation loss: 3.0663986562323036

Epoch: 6| Step: 7
Training loss: 3.2090546593889298
Validation loss: 3.068039345149781

Epoch: 6| Step: 8
Training loss: 3.56071012272327
Validation loss: 3.0677250330780153

Epoch: 6| Step: 9
Training loss: 1.858879921021193
Validation loss: 3.0664811023244702

Epoch: 6| Step: 10
Training loss: 2.749372930992061
Validation loss: 3.06614334403805

Epoch: 6| Step: 11
Training loss: 2.999599906945192
Validation loss: 3.0664848410052414

Epoch: 6| Step: 12
Training loss: 2.7078502126313877
Validation loss: 3.0702957085645495

Epoch: 6| Step: 13
Training loss: 3.346491322755642
Validation loss: 3.0676581878689166

Epoch: 31| Step: 0
Training loss: 3.674377886996017
Validation loss: 3.0678113335141144

Epoch: 6| Step: 1
Training loss: 3.2454060584638658
Validation loss: 3.064814888273144

Epoch: 6| Step: 2
Training loss: 2.6448235174191597
Validation loss: 3.068084614051124

Epoch: 6| Step: 3
Training loss: 2.8197126516754856
Validation loss: 3.0669759254245865

Epoch: 6| Step: 4
Training loss: 3.26682212096397
Validation loss: 3.0633584402148264

Epoch: 6| Step: 5
Training loss: 3.1898352352629438
Validation loss: 3.064511171783816

Epoch: 6| Step: 6
Training loss: 3.6492458975420576
Validation loss: 3.064177960237151

Epoch: 6| Step: 7
Training loss: 2.7952704062365656
Validation loss: 3.0648698199220585

Epoch: 6| Step: 8
Training loss: 3.5626930050685335
Validation loss: 3.0643989764576545

Epoch: 6| Step: 9
Training loss: 3.723760098958735
Validation loss: 3.064398638475922

Epoch: 6| Step: 10
Training loss: 3.394875108447014
Validation loss: 3.061358388277639

Epoch: 6| Step: 11
Training loss: 3.71702984687618
Validation loss: 3.061372071678618

Epoch: 6| Step: 12
Training loss: 3.088852830793778
Validation loss: 3.0626493345997323

Epoch: 6| Step: 13
Training loss: 3.9868541708732677
Validation loss: 3.0612812408888628

Epoch: 32| Step: 0
Training loss: 3.215102119307137
Validation loss: 3.05917197493002

Epoch: 6| Step: 1
Training loss: 3.1250198363628243
Validation loss: 3.0672905950878038

Epoch: 6| Step: 2
Training loss: 2.841706264663698
Validation loss: 3.0710317885982095

Epoch: 6| Step: 3
Training loss: 2.6024600018772333
Validation loss: 3.065267809294662

Epoch: 6| Step: 4
Training loss: 3.17103016693962
Validation loss: 3.0680423085886748

Epoch: 6| Step: 5
Training loss: 3.5011908004097725
Validation loss: 3.0731315463969726

Epoch: 6| Step: 6
Training loss: 3.467186377767112
Validation loss: 3.067139453699792

Epoch: 6| Step: 7
Training loss: 2.8316331886197017
Validation loss: 3.061265994410684

Epoch: 6| Step: 8
Training loss: 3.700086675092658
Validation loss: 3.0580247916579455

Epoch: 6| Step: 9
Training loss: 2.651457648376231
Validation loss: 3.0593205845629448

Epoch: 6| Step: 10
Training loss: 4.186930603487234
Validation loss: 3.0584228201322774

Epoch: 6| Step: 11
Training loss: 4.551441324849187
Validation loss: 3.056678716537588

Epoch: 6| Step: 12
Training loss: 2.5416437262661953
Validation loss: 3.056040566757938

Epoch: 6| Step: 13
Training loss: 3.671257324211444
Validation loss: 3.0552717722807814

Epoch: 33| Step: 0
Training loss: 2.38689595515184
Validation loss: 3.059743629009178

Epoch: 6| Step: 1
Training loss: 3.246924485682206
Validation loss: 3.0511172059493568

Epoch: 6| Step: 2
Training loss: 3.7898741177309665
Validation loss: 3.055145992139784

Epoch: 6| Step: 3
Training loss: 3.33469340869665
Validation loss: 3.0559276367937835

Epoch: 6| Step: 4
Training loss: 3.6320452136195738
Validation loss: 3.0539051786438316

Epoch: 6| Step: 5
Training loss: 3.4983726532937394
Validation loss: 3.0538098074334914

Epoch: 6| Step: 6
Training loss: 3.1123137268950156
Validation loss: 3.0525321682222013

Epoch: 6| Step: 7
Training loss: 3.6444870270461407
Validation loss: 3.0512739468558565

Epoch: 6| Step: 8
Training loss: 3.34389260246444
Validation loss: 3.05027536154143

Epoch: 6| Step: 9
Training loss: 3.43251286181258
Validation loss: 3.051591526047587

Epoch: 6| Step: 10
Training loss: 3.719357480991997
Validation loss: 3.052761169063652

Epoch: 6| Step: 11
Training loss: 3.010270657457954
Validation loss: 3.0488438700813814

Epoch: 6| Step: 12
Training loss: 3.5177939273058954
Validation loss: 3.050131505507859

Epoch: 6| Step: 13
Training loss: 1.8351606308067523
Validation loss: 3.0470712317209245

Epoch: 34| Step: 0
Training loss: 3.412508752832611
Validation loss: 3.0483621254285733

Epoch: 6| Step: 1
Training loss: 3.5856566474984746
Validation loss: 3.047357137904792

Epoch: 6| Step: 2
Training loss: 3.417562336328757
Validation loss: 3.0486907151273903

Epoch: 6| Step: 3
Training loss: 3.903077447019734
Validation loss: 3.0540617546407614

Epoch: 6| Step: 4
Training loss: 3.360744463326291
Validation loss: 3.0646585613531165

Epoch: 6| Step: 5
Training loss: 3.085497242873312
Validation loss: 3.0666501468340113

Epoch: 6| Step: 6
Training loss: 3.846079422890934
Validation loss: 3.0470234664618117

Epoch: 6| Step: 7
Training loss: 2.880789856152736
Validation loss: 3.045747724382398

Epoch: 6| Step: 8
Training loss: 3.416737361889889
Validation loss: 3.0452624146757317

Epoch: 6| Step: 9
Training loss: 3.1338832480879826
Validation loss: 3.0443111565676433

Epoch: 6| Step: 10
Training loss: 2.720260814195454
Validation loss: 3.045102696389929

Epoch: 6| Step: 11
Training loss: 2.659547173096216
Validation loss: 3.048618042097428

Epoch: 6| Step: 12
Training loss: 3.457030422404562
Validation loss: 3.0547631883293733

Epoch: 6| Step: 13
Training loss: 3.2734769759608815
Validation loss: 3.0546828891675397

Epoch: 35| Step: 0
Training loss: 4.045870505311799
Validation loss: 3.0520706677673637

Epoch: 6| Step: 1
Training loss: 3.758268776710634
Validation loss: 3.0499755649270357

Epoch: 6| Step: 2
Training loss: 2.630199006822625
Validation loss: 3.0482881889372715

Epoch: 6| Step: 3
Training loss: 3.6411729654006884
Validation loss: 3.043387887843555

Epoch: 6| Step: 4
Training loss: 3.1934798751634133
Validation loss: 3.03978790121337

Epoch: 6| Step: 5
Training loss: 3.896772560418978
Validation loss: 3.0385544571566596

Epoch: 6| Step: 6
Training loss: 3.1698674204926895
Validation loss: 3.038217515395895

Epoch: 6| Step: 7
Training loss: 3.474898928263311
Validation loss: 3.039280570079115

Epoch: 6| Step: 8
Training loss: 2.825100709588532
Validation loss: 3.0385599285723566

Epoch: 6| Step: 9
Training loss: 3.4799946848510843
Validation loss: 3.043906730623607

Epoch: 6| Step: 10
Training loss: 2.9035267530351465
Validation loss: 3.0501316853752116

Epoch: 6| Step: 11
Training loss: 3.1317110860481767
Validation loss: 3.0496941493638996

Epoch: 6| Step: 12
Training loss: 3.0507524906614996
Validation loss: 3.0474398282697126

Epoch: 6| Step: 13
Training loss: 2.3457978520891802
Validation loss: 3.0411527022154763

Epoch: 36| Step: 0
Training loss: 3.2167144561011076
Validation loss: 3.041163694696533

Epoch: 6| Step: 1
Training loss: 3.052685952611004
Validation loss: 3.0385752122048695

Epoch: 6| Step: 2
Training loss: 3.2229426956029834
Validation loss: 3.037531525011812

Epoch: 6| Step: 3
Training loss: 3.347422356819725
Validation loss: 3.03705116239661

Epoch: 6| Step: 4
Training loss: 3.6647205534562
Validation loss: 3.0446535706716613

Epoch: 6| Step: 5
Training loss: 2.6387099144012818
Validation loss: 3.0419827166544047

Epoch: 6| Step: 6
Training loss: 2.8214543532837055
Validation loss: 3.044857551810753

Epoch: 6| Step: 7
Training loss: 3.6841914965202647
Validation loss: 3.0401685759004557

Epoch: 6| Step: 8
Training loss: 2.9485247269076016
Validation loss: 3.0316385642373374

Epoch: 6| Step: 9
Training loss: 3.6277682816551695
Validation loss: 3.030416272714575

Epoch: 6| Step: 10
Training loss: 3.376696831159556
Validation loss: 3.0301994648954804

Epoch: 6| Step: 11
Training loss: 2.9469452640251323
Validation loss: 3.0351347637515356

Epoch: 6| Step: 12
Training loss: 3.7287753590697523
Validation loss: 3.032019854544305

Epoch: 6| Step: 13
Training loss: 4.0038988662279476
Validation loss: 3.039264899450026

Epoch: 37| Step: 0
Training loss: 3.41062128800464
Validation loss: 3.0352271654500482

Epoch: 6| Step: 1
Training loss: 3.778596183228073
Validation loss: 3.03099196646348

Epoch: 6| Step: 2
Training loss: 3.413450557240587
Validation loss: 3.0304981191870537

Epoch: 6| Step: 3
Training loss: 3.0635344646066116
Validation loss: 3.029770607157417

Epoch: 6| Step: 4
Training loss: 3.8492591888304184
Validation loss: 3.0299356586189603

Epoch: 6| Step: 5
Training loss: 3.5306448628951883
Validation loss: 3.0271695235944507

Epoch: 6| Step: 6
Training loss: 3.3003424900232154
Validation loss: 3.0262443451025214

Epoch: 6| Step: 7
Training loss: 2.324628521355312
Validation loss: 3.0257695202955035

Epoch: 6| Step: 8
Training loss: 2.9795080313922395
Validation loss: 3.028167420751791

Epoch: 6| Step: 9
Training loss: 2.926724413024725
Validation loss: 3.031054046525216

Epoch: 6| Step: 10
Training loss: 2.8383454327895685
Validation loss: 3.033041907001216

Epoch: 6| Step: 11
Training loss: 3.1877635772035395
Validation loss: 3.0296507171654063

Epoch: 6| Step: 12
Training loss: 4.084247538672615
Validation loss: 3.0272685303805553

Epoch: 6| Step: 13
Training loss: 3.0321276465850753
Validation loss: 3.023291677558008

Epoch: 38| Step: 0
Training loss: 3.9391402203989077
Validation loss: 3.0245113031951396

Epoch: 6| Step: 1
Training loss: 2.866153374634922
Validation loss: 3.0233210695218804

Epoch: 6| Step: 2
Training loss: 1.981583802415965
Validation loss: 3.0271877466416655

Epoch: 6| Step: 3
Training loss: 2.5496113125638993
Validation loss: 3.0238448823495134

Epoch: 6| Step: 4
Training loss: 3.89372062855721
Validation loss: 3.0225779210349764

Epoch: 6| Step: 5
Training loss: 2.9812033211754443
Validation loss: 3.0206378442114676

Epoch: 6| Step: 6
Training loss: 2.9886986534465603
Validation loss: 3.021922824305277

Epoch: 6| Step: 7
Training loss: 2.662202247124727
Validation loss: 3.0228055739966204

Epoch: 6| Step: 8
Training loss: 3.3026279678212997
Validation loss: 3.03326856417124

Epoch: 6| Step: 9
Training loss: 3.9534057999949352
Validation loss: 3.045094843232558

Epoch: 6| Step: 10
Training loss: 3.693057124026879
Validation loss: 3.0487992496968657

Epoch: 6| Step: 11
Training loss: 3.424650973614196
Validation loss: 3.0359638192556364

Epoch: 6| Step: 12
Training loss: 3.1869822062871513
Validation loss: 3.026433866371758

Epoch: 6| Step: 13
Training loss: 4.4399501859602655
Validation loss: 3.0177423303135513

Epoch: 39| Step: 0
Training loss: 3.316165838974588
Validation loss: 3.0184293851460544

Epoch: 6| Step: 1
Training loss: 2.7575654089355894
Validation loss: 3.0171041803876517

Epoch: 6| Step: 2
Training loss: 3.3898839184626746
Validation loss: 3.017478621845738

Epoch: 6| Step: 3
Training loss: 2.758504980533951
Validation loss: 3.0202104689421567

Epoch: 6| Step: 4
Training loss: 3.4201234837597663
Validation loss: 3.0203100909015044

Epoch: 6| Step: 5
Training loss: 2.9816956001130293
Validation loss: 3.0208749385651803

Epoch: 6| Step: 6
Training loss: 3.926672444320426
Validation loss: 3.0225702646522685

Epoch: 6| Step: 7
Training loss: 2.9301986858716735
Validation loss: 3.018876501845191

Epoch: 6| Step: 8
Training loss: 3.208739630664199
Validation loss: 3.0159633930544043

Epoch: 6| Step: 9
Training loss: 3.178675385025835
Validation loss: 3.0130748198155373

Epoch: 6| Step: 10
Training loss: 3.476030013206152
Validation loss: 3.0134395667494465

Epoch: 6| Step: 11
Training loss: 3.3188933088320502
Validation loss: 3.010231063156364

Epoch: 6| Step: 12
Training loss: 3.7852616900707003
Validation loss: 3.0119702023378245

Epoch: 6| Step: 13
Training loss: 3.489089581682991
Validation loss: 3.0124446934112292

Epoch: 40| Step: 0
Training loss: 3.914249864917272
Validation loss: 3.0212085908053217

Epoch: 6| Step: 1
Training loss: 3.017976308680348
Validation loss: 3.0186235228498632

Epoch: 6| Step: 2
Training loss: 2.8759754018991717
Validation loss: 3.0196727221859447

Epoch: 6| Step: 3
Training loss: 2.7248487798046215
Validation loss: 3.014850471721933

Epoch: 6| Step: 4
Training loss: 3.2171176363680685
Validation loss: 3.0164092672759013

Epoch: 6| Step: 5
Training loss: 3.409312280345488
Validation loss: 3.012632757117714

Epoch: 6| Step: 6
Training loss: 3.7214545665070493
Validation loss: 3.008766205302807

Epoch: 6| Step: 7
Training loss: 3.474127647624264
Validation loss: 3.0086260403476097

Epoch: 6| Step: 8
Training loss: 3.3486981723444247
Validation loss: 3.007730401011644

Epoch: 6| Step: 9
Training loss: 3.674057591850245
Validation loss: 3.0100704927563573

Epoch: 6| Step: 10
Training loss: 2.6973345704213334
Validation loss: 3.011809077748488

Epoch: 6| Step: 11
Training loss: 3.6856267017802398
Validation loss: 3.0144114640407778

Epoch: 6| Step: 12
Training loss: 3.1379223482287104
Validation loss: 3.0140674115029866

Epoch: 6| Step: 13
Training loss: 2.4642370961607916
Validation loss: 3.0125632836532605

Epoch: 41| Step: 0
Training loss: 3.3521187416294485
Validation loss: 3.006024650283643

Epoch: 6| Step: 1
Training loss: 3.806340479284306
Validation loss: 3.0071534305031435

Epoch: 6| Step: 2
Training loss: 3.3095435138336673
Validation loss: 3.006286730160405

Epoch: 6| Step: 3
Training loss: 3.6033772098247194
Validation loss: 3.0051882975930133

Epoch: 6| Step: 4
Training loss: 3.364671515066051
Validation loss: 3.003135281913205

Epoch: 6| Step: 5
Training loss: 2.965399367147239
Validation loss: 3.002385797341971

Epoch: 6| Step: 6
Training loss: 2.5784417160160604
Validation loss: 3.00383958057529

Epoch: 6| Step: 7
Training loss: 3.3533498270932323
Validation loss: 3.004384729838805

Epoch: 6| Step: 8
Training loss: 3.8147186327526583
Validation loss: 3.0031319082678207

Epoch: 6| Step: 9
Training loss: 2.9123484297839166
Validation loss: 3.002060165726346

Epoch: 6| Step: 10
Training loss: 3.5379300021271156
Validation loss: 3.0025292232182452

Epoch: 6| Step: 11
Training loss: 2.5171742851530836
Validation loss: 3.003751699072055

Epoch: 6| Step: 12
Training loss: 3.468347337050781
Validation loss: 3.000465879020672

Epoch: 6| Step: 13
Training loss: 2.756526831048101
Validation loss: 2.997123678465749

Epoch: 42| Step: 0
Training loss: 3.235861321569829
Validation loss: 2.9992320571584243

Epoch: 6| Step: 1
Training loss: 3.081982050165761
Validation loss: 2.9979077925959734

Epoch: 6| Step: 2
Training loss: 3.4381557879432934
Validation loss: 2.9966492124688844

Epoch: 6| Step: 3
Training loss: 3.6325862034691987
Validation loss: 2.9997796487040236

Epoch: 6| Step: 4
Training loss: 3.3003267415442594
Validation loss: 2.997598963935295

Epoch: 6| Step: 5
Training loss: 3.561841401910433
Validation loss: 2.9984835856398924

Epoch: 6| Step: 6
Training loss: 2.14712251127647
Validation loss: 2.99704261338519

Epoch: 6| Step: 7
Training loss: 3.870583632470021
Validation loss: 2.9923788466962726

Epoch: 6| Step: 8
Training loss: 3.546822165209112
Validation loss: 2.9936435322327926

Epoch: 6| Step: 9
Training loss: 3.604526450367161
Validation loss: 2.9956956221241904

Epoch: 6| Step: 10
Training loss: 2.7895931305450934
Validation loss: 3.0061884616252117

Epoch: 6| Step: 11
Training loss: 3.1461574732709505
Validation loss: 3.0186433015439302

Epoch: 6| Step: 12
Training loss: 3.217113930897157
Validation loss: 3.0313442136507014

Epoch: 6| Step: 13
Training loss: 2.6278125590826695
Validation loss: 3.0170535334515507

Epoch: 43| Step: 0
Training loss: 2.764197374398903
Validation loss: 3.005006796021583

Epoch: 6| Step: 1
Training loss: 3.7616306504562167
Validation loss: 3.021702510611936

Epoch: 6| Step: 2
Training loss: 3.731890630119122
Validation loss: 3.00226617234567

Epoch: 6| Step: 3
Training loss: 3.7178627045528168
Validation loss: 2.996370843008034

Epoch: 6| Step: 4
Training loss: 2.5676501553168953
Validation loss: 2.9949859758698896

Epoch: 6| Step: 5
Training loss: 3.053486697774983
Validation loss: 2.9974198474803906

Epoch: 6| Step: 6
Training loss: 3.346301094950424
Validation loss: 2.997145188302059

Epoch: 6| Step: 7
Training loss: 3.8046055340407263
Validation loss: 2.998013190570288

Epoch: 6| Step: 8
Training loss: 3.4487080352541817
Validation loss: 2.9942302972045196

Epoch: 6| Step: 9
Training loss: 3.4225485500238717
Validation loss: 2.994806906869569

Epoch: 6| Step: 10
Training loss: 2.198549538084401
Validation loss: 2.9931089240424247

Epoch: 6| Step: 11
Training loss: 3.165038309211959
Validation loss: 2.9922529759773893

Epoch: 6| Step: 12
Training loss: 2.6144595376504167
Validation loss: 2.9908022524278794

Epoch: 6| Step: 13
Training loss: 3.932309802015645
Validation loss: 2.9901825656344854

Epoch: 44| Step: 0
Training loss: 3.469650564051241
Validation loss: 2.9886697032911456

Epoch: 6| Step: 1
Training loss: 2.6298749252863995
Validation loss: 2.988129863192536

Epoch: 6| Step: 2
Training loss: 3.161414726916025
Validation loss: 2.9891536281346873

Epoch: 6| Step: 3
Training loss: 2.979729196929837
Validation loss: 2.9913057711552704

Epoch: 6| Step: 4
Training loss: 3.1144612946517394
Validation loss: 2.988322983016774

Epoch: 6| Step: 5
Training loss: 3.873544481161173
Validation loss: 2.9882306541767023

Epoch: 6| Step: 6
Training loss: 2.8119937017161347
Validation loss: 2.9908715267870396

Epoch: 6| Step: 7
Training loss: 3.029640950498991
Validation loss: 2.989896179022659

Epoch: 6| Step: 8
Training loss: 3.5858308531084524
Validation loss: 2.9859727429816436

Epoch: 6| Step: 9
Training loss: 3.9008516164339113
Validation loss: 2.985582195683033

Epoch: 6| Step: 10
Training loss: 3.328577001977461
Validation loss: 2.983468937251072

Epoch: 6| Step: 11
Training loss: 3.3579351133856066
Validation loss: 2.9828504909859905

Epoch: 6| Step: 12
Training loss: 3.2042832676209003
Validation loss: 2.9871389394566967

Epoch: 6| Step: 13
Training loss: 2.8407864062087955
Validation loss: 2.9860023408771563

Epoch: 45| Step: 0
Training loss: 3.75733332443869
Validation loss: 2.984735681099868

Epoch: 6| Step: 1
Training loss: 3.5120201787694763
Validation loss: 2.9839972405292645

Epoch: 6| Step: 2
Training loss: 3.173434020002477
Validation loss: 2.982192307514196

Epoch: 6| Step: 3
Training loss: 3.3183013210416203
Validation loss: 2.9804184602333565

Epoch: 6| Step: 4
Training loss: 3.488894144960023
Validation loss: 2.9824554484233956

Epoch: 6| Step: 5
Training loss: 3.607863336719576
Validation loss: 2.98376219959175

Epoch: 6| Step: 6
Training loss: 3.3142204854916693
Validation loss: 2.98183817787638

Epoch: 6| Step: 7
Training loss: 2.1390866508820277
Validation loss: 2.9813488547173352

Epoch: 6| Step: 8
Training loss: 2.6918011335517216
Validation loss: 2.9912193435109926

Epoch: 6| Step: 9
Training loss: 3.608105456855851
Validation loss: 3.0007702665803984

Epoch: 6| Step: 10
Training loss: 3.1295392447450494
Validation loss: 3.022634360708059

Epoch: 6| Step: 11
Training loss: 3.565922615542382
Validation loss: 2.997314038619132

Epoch: 6| Step: 12
Training loss: 3.002320504774784
Validation loss: 2.9932400826316212

Epoch: 6| Step: 13
Training loss: 3.1439423761983867
Validation loss: 2.9870738543122783

Epoch: 46| Step: 0
Training loss: 3.2763498683875336
Validation loss: 2.984010875745482

Epoch: 6| Step: 1
Training loss: 3.4427922518029908
Validation loss: 2.9792719354209

Epoch: 6| Step: 2
Training loss: 2.97248557123351
Validation loss: 2.976774823560773

Epoch: 6| Step: 3
Training loss: 2.875535832104394
Validation loss: 2.9808256241821076

Epoch: 6| Step: 4
Training loss: 2.7833905501585496
Validation loss: 2.9786582362050296

Epoch: 6| Step: 5
Training loss: 3.4125756838723356
Validation loss: 2.977899691304926

Epoch: 6| Step: 6
Training loss: 2.571909399717973
Validation loss: 2.9788807264829646

Epoch: 6| Step: 7
Training loss: 3.4988800709360497
Validation loss: 2.978509873724727

Epoch: 6| Step: 8
Training loss: 3.5229812631187305
Validation loss: 2.983955582757893

Epoch: 6| Step: 9
Training loss: 3.1612396080778464
Validation loss: 2.9925296964434747

Epoch: 6| Step: 10
Training loss: 2.633567724379387
Validation loss: 2.9929071738615334

Epoch: 6| Step: 11
Training loss: 3.661222027912388
Validation loss: 2.9867717334271617

Epoch: 6| Step: 12
Training loss: 3.9451426856631815
Validation loss: 2.9801834161891576

Epoch: 6| Step: 13
Training loss: 3.7739611276182266
Validation loss: 2.9763550024336163

Epoch: 47| Step: 0
Training loss: 3.7653899693250565
Validation loss: 2.9774428225781318

Epoch: 6| Step: 1
Training loss: 3.064620548923915
Validation loss: 2.9782266212952018

Epoch: 6| Step: 2
Training loss: 3.849317287006854
Validation loss: 2.9773146361864566

Epoch: 6| Step: 3
Training loss: 3.2348033971461816
Validation loss: 2.977631226081738

Epoch: 6| Step: 4
Training loss: 2.9152934156724073
Validation loss: 2.977603889409973

Epoch: 6| Step: 5
Training loss: 3.592067689627415
Validation loss: 2.977269140977493

Epoch: 6| Step: 6
Training loss: 3.2767448378196513
Validation loss: 2.980069376009999

Epoch: 6| Step: 7
Training loss: 3.391437767109081
Validation loss: 2.977170522584733

Epoch: 6| Step: 8
Training loss: 2.6013731558231705
Validation loss: 2.9771102949405144

Epoch: 6| Step: 9
Training loss: 2.645365055326002
Validation loss: 2.9748211640505313

Epoch: 6| Step: 10
Training loss: 3.0021724782111074
Validation loss: 2.9744343376778857

Epoch: 6| Step: 11
Training loss: 3.5104909072104054
Validation loss: 2.9729414603047304

Epoch: 6| Step: 12
Training loss: 3.358749828274733
Validation loss: 2.9741820900302853

Epoch: 6| Step: 13
Training loss: 2.988735508518673
Validation loss: 2.9724024240525027

Epoch: 48| Step: 0
Training loss: 3.6529330344297746
Validation loss: 2.972195347224331

Epoch: 6| Step: 1
Training loss: 3.10195359231359
Validation loss: 2.9732326806620835

Epoch: 6| Step: 2
Training loss: 3.5970303366863607
Validation loss: 2.9759747049135137

Epoch: 6| Step: 3
Training loss: 3.986833120802761
Validation loss: 2.97770862682207

Epoch: 6| Step: 4
Training loss: 2.837129200641954
Validation loss: 2.971515559499464

Epoch: 6| Step: 5
Training loss: 3.65050844805505
Validation loss: 2.9720490264636545

Epoch: 6| Step: 6
Training loss: 2.4833732840718876
Validation loss: 2.9676335228536805

Epoch: 6| Step: 7
Training loss: 2.358620428216854
Validation loss: 2.967683637946154

Epoch: 6| Step: 8
Training loss: 3.2318075558617347
Validation loss: 2.965905684120722

Epoch: 6| Step: 9
Training loss: 2.5655454820769537
Validation loss: 2.965907730948766

Epoch: 6| Step: 10
Training loss: 3.8025287245368355
Validation loss: 2.9656868097181572

Epoch: 6| Step: 11
Training loss: 3.567458065564408
Validation loss: 2.9653905481877088

Epoch: 6| Step: 12
Training loss: 3.321545324895765
Validation loss: 2.964811976304143

Epoch: 6| Step: 13
Training loss: 2.3817787804809183
Validation loss: 2.9681773153107645

Epoch: 49| Step: 0
Training loss: 3.7898328489619817
Validation loss: 2.9612777704489437

Epoch: 6| Step: 1
Training loss: 4.228950432321619
Validation loss: 2.9624130205101675

Epoch: 6| Step: 2
Training loss: 2.8994160360173478
Validation loss: 2.9661054057009397

Epoch: 6| Step: 3
Training loss: 2.8788666638327385
Validation loss: 2.963925441438344

Epoch: 6| Step: 4
Training loss: 2.698309429157853
Validation loss: 2.960608501069568

Epoch: 6| Step: 5
Training loss: 3.06160100081173
Validation loss: 2.962675964313448

Epoch: 6| Step: 6
Training loss: 3.023285775727109
Validation loss: 2.9633634065150622

Epoch: 6| Step: 7
Training loss: 3.357159118844855
Validation loss: 2.9655406986127426

Epoch: 6| Step: 8
Training loss: 3.1881243524361906
Validation loss: 2.96222403422046

Epoch: 6| Step: 9
Training loss: 2.960384427959266
Validation loss: 2.9611418647012817

Epoch: 6| Step: 10
Training loss: 3.781681761248476
Validation loss: 2.9645678558705417

Epoch: 6| Step: 11
Training loss: 3.017089488147839
Validation loss: 2.963272051896717

Epoch: 6| Step: 12
Training loss: 3.1676857630234916
Validation loss: 2.9631024080950557

Epoch: 6| Step: 13
Training loss: 2.8276167776478043
Validation loss: 2.964760504373252

Epoch: 50| Step: 0
Training loss: 3.679720673948126
Validation loss: 2.961631107285701

Epoch: 6| Step: 1
Training loss: 3.3973494969506968
Validation loss: 2.9616590492968218

Epoch: 6| Step: 2
Training loss: 3.7440670127577187
Validation loss: 2.961997815687028

Epoch: 6| Step: 3
Training loss: 3.05292930639632
Validation loss: 2.961974955731698

Epoch: 6| Step: 4
Training loss: 3.0666093309543503
Validation loss: 2.963090554995798

Epoch: 6| Step: 5
Training loss: 3.206999728643812
Validation loss: 2.960232839065351

Epoch: 6| Step: 6
Training loss: 3.2591702127173208
Validation loss: 2.960646996016509

Epoch: 6| Step: 7
Training loss: 3.207563349156955
Validation loss: 2.960579184445281

Epoch: 6| Step: 8
Training loss: 3.290030511407335
Validation loss: 2.960155725312771

Epoch: 6| Step: 9
Training loss: 2.6035314675354915
Validation loss: 2.9579430042006276

Epoch: 6| Step: 10
Training loss: 3.1305955762617077
Validation loss: 2.9593727582803115

Epoch: 6| Step: 11
Training loss: 3.1722748603024047
Validation loss: 2.9602812573553696

Epoch: 6| Step: 12
Training loss: 2.850962118410266
Validation loss: 2.9591964359240173

Epoch: 6| Step: 13
Training loss: 3.7933795678975466
Validation loss: 2.9592602473708296

Epoch: 51| Step: 0
Training loss: 3.6708945406004854
Validation loss: 2.957539739817055

Epoch: 6| Step: 1
Training loss: 2.4482466671403973
Validation loss: 2.9568760359021575

Epoch: 6| Step: 2
Training loss: 2.074911055899163
Validation loss: 2.95642023883944

Epoch: 6| Step: 3
Training loss: 3.2966544271871263
Validation loss: 2.9558692582709565

Epoch: 6| Step: 4
Training loss: 3.604091459750174
Validation loss: 2.9544869120304043

Epoch: 6| Step: 5
Training loss: 3.2766306013707673
Validation loss: 2.9581963904467052

Epoch: 6| Step: 6
Training loss: 3.110487235806669
Validation loss: 2.9536412865258774

Epoch: 6| Step: 7
Training loss: 3.245670956690842
Validation loss: 2.9533591202872347

Epoch: 6| Step: 8
Training loss: 3.7882874630188534
Validation loss: 2.9578637566893473

Epoch: 6| Step: 9
Training loss: 3.3196288358655637
Validation loss: 2.9528882088595783

Epoch: 6| Step: 10
Training loss: 3.28953755407065
Validation loss: 2.957456316338013

Epoch: 6| Step: 11
Training loss: 3.7823146865944053
Validation loss: 2.9564294496234997

Epoch: 6| Step: 12
Training loss: 2.708932976486083
Validation loss: 2.9552727020156553

Epoch: 6| Step: 13
Training loss: 3.2011627886063083
Validation loss: 2.95560679834516

Epoch: 52| Step: 0
Training loss: 2.7434724150296845
Validation loss: 2.9553143338334875

Epoch: 6| Step: 1
Training loss: 3.757289413875916
Validation loss: 2.9509984680896375

Epoch: 6| Step: 2
Training loss: 3.428665043483792
Validation loss: 2.952101092045934

Epoch: 6| Step: 3
Training loss: 3.4769635258523235
Validation loss: 2.9522759590336975

Epoch: 6| Step: 4
Training loss: 3.3078742207574283
Validation loss: 2.9518786676681392

Epoch: 6| Step: 5
Training loss: 2.732923896486475
Validation loss: 2.9520279274105308

Epoch: 6| Step: 6
Training loss: 2.987220885194692
Validation loss: 2.953274266197602

Epoch: 6| Step: 7
Training loss: 3.2337140131224578
Validation loss: 2.951301104796178

Epoch: 6| Step: 8
Training loss: 2.6216892981436564
Validation loss: 2.9503060923363678

Epoch: 6| Step: 9
Training loss: 3.885249211825193
Validation loss: 2.9515018181103994

Epoch: 6| Step: 10
Training loss: 3.304930910204936
Validation loss: 2.950443423458143

Epoch: 6| Step: 11
Training loss: 3.2746472001237508
Validation loss: 2.9469296574119572

Epoch: 6| Step: 12
Training loss: 3.033445998254891
Validation loss: 2.9483610280867327

Epoch: 6| Step: 13
Training loss: 3.2219546762377
Validation loss: 2.9463329565135923

Epoch: 53| Step: 0
Training loss: 2.9224043585902724
Validation loss: 2.944909993157098

Epoch: 6| Step: 1
Training loss: 4.006216939947445
Validation loss: 2.9458839130081422

Epoch: 6| Step: 2
Training loss: 3.077827555425661
Validation loss: 2.9443855148824474

Epoch: 6| Step: 3
Training loss: 2.848572383497291
Validation loss: 2.9465908969840324

Epoch: 6| Step: 4
Training loss: 2.6409458665192767
Validation loss: 2.948096362288757

Epoch: 6| Step: 5
Training loss: 3.567223612953016
Validation loss: 2.9425831592336555

Epoch: 6| Step: 6
Training loss: 2.9957123952620943
Validation loss: 2.946334491391344

Epoch: 6| Step: 7
Training loss: 2.7034785750570016
Validation loss: 2.9498767071309455

Epoch: 6| Step: 8
Training loss: 3.1310601030281124
Validation loss: 2.9710871479332672

Epoch: 6| Step: 9
Training loss: 4.017004585033684
Validation loss: 2.9725652206467443

Epoch: 6| Step: 10
Training loss: 3.135416294913201
Validation loss: 2.9926004436764626

Epoch: 6| Step: 11
Training loss: 3.7324558577894367
Validation loss: 2.965472647960433

Epoch: 6| Step: 12
Training loss: 3.6127454205737988
Validation loss: 2.9406481829877102

Epoch: 6| Step: 13
Training loss: 1.2495624253187079
Validation loss: 2.9411768909709806

Epoch: 54| Step: 0
Training loss: 3.713814160522371
Validation loss: 2.9423682446547303

Epoch: 6| Step: 1
Training loss: 2.9761637423086644
Validation loss: 2.9456591079732775

Epoch: 6| Step: 2
Training loss: 2.6641725757936254
Validation loss: 2.949642003631056

Epoch: 6| Step: 3
Training loss: 3.473636793424413
Validation loss: 2.951741130607085

Epoch: 6| Step: 4
Training loss: 3.6982521155712393
Validation loss: 2.954999550230341

Epoch: 6| Step: 5
Training loss: 3.562052113001339
Validation loss: 2.954141520324269

Epoch: 6| Step: 6
Training loss: 3.8020099092822948
Validation loss: 2.9604286897177636

Epoch: 6| Step: 7
Training loss: 2.6019936510751895
Validation loss: 2.9485599870021657

Epoch: 6| Step: 8
Training loss: 2.621257839382166
Validation loss: 2.9421689315132498

Epoch: 6| Step: 9
Training loss: 2.977406299567642
Validation loss: 2.941189351877022

Epoch: 6| Step: 10
Training loss: 3.5895625389295325
Validation loss: 2.9378931833596695

Epoch: 6| Step: 11
Training loss: 3.1602555343064043
Validation loss: 2.938446189262558

Epoch: 6| Step: 12
Training loss: 3.053863180017341
Validation loss: 2.9346541786491516

Epoch: 6| Step: 13
Training loss: 2.7370872778672215
Validation loss: 2.937959797799051

Epoch: 55| Step: 0
Training loss: 3.438992540409642
Validation loss: 2.9510574217098857

Epoch: 6| Step: 1
Training loss: 2.5788403992333486
Validation loss: 2.9668042078335115

Epoch: 6| Step: 2
Training loss: 3.0334933130465034
Validation loss: 2.983969126236723

Epoch: 6| Step: 3
Training loss: 3.5801913362657674
Validation loss: 3.0192699054221137

Epoch: 6| Step: 4
Training loss: 3.285293993517221
Validation loss: 2.9905463884890304

Epoch: 6| Step: 5
Training loss: 3.5414090829564833
Validation loss: 2.9394787433884124

Epoch: 6| Step: 6
Training loss: 3.3550719624972514
Validation loss: 2.934362827784991

Epoch: 6| Step: 7
Training loss: 3.126335316515409
Validation loss: 2.9368766327462263

Epoch: 6| Step: 8
Training loss: 4.069746391774231
Validation loss: 2.941400678921044

Epoch: 6| Step: 9
Training loss: 3.001523108077423
Validation loss: 2.944942980940891

Epoch: 6| Step: 10
Training loss: 2.761739296411813
Validation loss: 2.945658810326772

Epoch: 6| Step: 11
Training loss: 3.614991149469413
Validation loss: 2.954743889070324

Epoch: 6| Step: 12
Training loss: 2.226058528147844
Validation loss: 2.9527615628845423

Epoch: 6| Step: 13
Training loss: 3.188490171534893
Validation loss: 2.938568198541153

Epoch: 56| Step: 0
Training loss: 2.411270452860562
Validation loss: 2.9366890462727726

Epoch: 6| Step: 1
Training loss: 3.3371455486542434
Validation loss: 2.9382964926170625

Epoch: 6| Step: 2
Training loss: 3.686643598000322
Validation loss: 2.9326494463801622

Epoch: 6| Step: 3
Training loss: 2.758875309769094
Validation loss: 2.9348394336073365

Epoch: 6| Step: 4
Training loss: 2.9914323536134186
Validation loss: 2.9342243893165043

Epoch: 6| Step: 5
Training loss: 3.476869170989575
Validation loss: 2.9353216896513246

Epoch: 6| Step: 6
Training loss: 3.2192776441952065
Validation loss: 2.931874350079176

Epoch: 6| Step: 7
Training loss: 3.627736078489694
Validation loss: 2.939140922742785

Epoch: 6| Step: 8
Training loss: 2.750140966790473
Validation loss: 2.9349066344705705

Epoch: 6| Step: 9
Training loss: 3.289760343408837
Validation loss: 2.9503860702795883

Epoch: 6| Step: 10
Training loss: 3.5316770852334156
Validation loss: 2.953887316722175

Epoch: 6| Step: 11
Training loss: 3.2764008066922687
Validation loss: 2.9379018082433075

Epoch: 6| Step: 12
Training loss: 3.389585977438794
Validation loss: 2.9302294691842143

Epoch: 6| Step: 13
Training loss: 2.9605177931635027
Validation loss: 2.9287223134977354

Epoch: 57| Step: 0
Training loss: 2.919135946696037
Validation loss: 2.931015467538896

Epoch: 6| Step: 1
Training loss: 3.113903026641352
Validation loss: 2.9320878628488876

Epoch: 6| Step: 2
Training loss: 3.5892494216092676
Validation loss: 2.9355262429932796

Epoch: 6| Step: 3
Training loss: 2.3195875685867704
Validation loss: 2.936662420575392

Epoch: 6| Step: 4
Training loss: 3.1246844323089125
Validation loss: 2.945323067674947

Epoch: 6| Step: 5
Training loss: 2.675260484793775
Validation loss: 2.9450062133126282

Epoch: 6| Step: 6
Training loss: 3.467574461651073
Validation loss: 2.958146049629302

Epoch: 6| Step: 7
Training loss: 3.880966269523695
Validation loss: 2.9450246244214777

Epoch: 6| Step: 8
Training loss: 3.1932894917812122
Validation loss: 2.9378930481048173

Epoch: 6| Step: 9
Training loss: 4.083605361492842
Validation loss: 2.932621187753288

Epoch: 6| Step: 10
Training loss: 3.4066629421962777
Validation loss: 2.9288204152014328

Epoch: 6| Step: 11
Training loss: 2.668116731575016
Validation loss: 2.9246321786344605

Epoch: 6| Step: 12
Training loss: 2.8310144322228563
Validation loss: 2.926560377789864

Epoch: 6| Step: 13
Training loss: 3.3860599004558525
Validation loss: 2.926401854159943

Epoch: 58| Step: 0
Training loss: 3.4786609274467284
Validation loss: 2.9336388703836143

Epoch: 6| Step: 1
Training loss: 2.89959973170884
Validation loss: 2.972746535780487

Epoch: 6| Step: 2
Training loss: 2.6196406923226245
Validation loss: 3.090024434102005

Epoch: 6| Step: 3
Training loss: 3.0797599671700553
Validation loss: 3.2298227956837424

Epoch: 6| Step: 4
Training loss: 3.609001239399051
Validation loss: 3.1556715181828148

Epoch: 6| Step: 5
Training loss: 3.5036362423838057
Validation loss: 3.0041242948909095

Epoch: 6| Step: 6
Training loss: 4.323485604347041
Validation loss: 2.925102191994822

Epoch: 6| Step: 7
Training loss: 2.6922857566610605
Validation loss: 2.922066513417413

Epoch: 6| Step: 8
Training loss: 2.8309278561728606
Validation loss: 2.927607635659977

Epoch: 6| Step: 9
Training loss: 3.403094028300438
Validation loss: 2.970858437339847

Epoch: 6| Step: 10
Training loss: 3.3058352810625
Validation loss: 3.0109742032215787

Epoch: 6| Step: 11
Training loss: 3.9646014059633417
Validation loss: 3.0077427668878776

Epoch: 6| Step: 12
Training loss: 2.2121000973781255
Validation loss: 2.9778964771746765

Epoch: 6| Step: 13
Training loss: 2.800953283838967
Validation loss: 2.9501692988038575

Epoch: 59| Step: 0
Training loss: 3.7184109573321
Validation loss: 2.9342161782442733

Epoch: 6| Step: 1
Training loss: 2.7587547529669654
Validation loss: 2.9272518726170627

Epoch: 6| Step: 2
Training loss: 3.075672702555034
Validation loss: 2.9224696225246585

Epoch: 6| Step: 3
Training loss: 3.7529855923008903
Validation loss: 2.9188699764955994

Epoch: 6| Step: 4
Training loss: 3.3595464618307065
Validation loss: 2.9182817625324895

Epoch: 6| Step: 5
Training loss: 3.399600476745651
Validation loss: 2.9245932359400695

Epoch: 6| Step: 6
Training loss: 2.812371314601585
Validation loss: 2.9338477476042306

Epoch: 6| Step: 7
Training loss: 3.5459426797277813
Validation loss: 2.930327788139893

Epoch: 6| Step: 8
Training loss: 3.7341622647139836
Validation loss: 2.925693935574046

Epoch: 6| Step: 9
Training loss: 3.3240236612848064
Validation loss: 2.9202708575014795

Epoch: 6| Step: 10
Training loss: 3.0187014368546228
Validation loss: 2.916160681705755

Epoch: 6| Step: 11
Training loss: 2.8568856498204305
Validation loss: 2.9166923668310685

Epoch: 6| Step: 12
Training loss: 2.8570827614049925
Validation loss: 2.915745807489892

Epoch: 6| Step: 13
Training loss: 1.5253641319172204
Validation loss: 2.9153018484415365

Epoch: 60| Step: 0
Training loss: 3.323138589334387
Validation loss: 2.9173804035378423

Epoch: 6| Step: 1
Training loss: 3.718001089899274
Validation loss: 2.9169475324966503

Epoch: 6| Step: 2
Training loss: 2.850327984860138
Validation loss: 2.9156957668686743

Epoch: 6| Step: 3
Training loss: 2.7976834284941097
Validation loss: 2.9150142794015026

Epoch: 6| Step: 4
Training loss: 2.5364727252235975
Validation loss: 2.914798308381544

Epoch: 6| Step: 5
Training loss: 3.781826511287186
Validation loss: 2.914819637686355

Epoch: 6| Step: 6
Training loss: 2.5902065293436625
Validation loss: 2.915117225499805

Epoch: 6| Step: 7
Training loss: 3.563151651311881
Validation loss: 2.9121419790168273

Epoch: 6| Step: 8
Training loss: 3.1903335841720217
Validation loss: 2.9081595467082155

Epoch: 6| Step: 9
Training loss: 3.5725133610789883
Validation loss: 2.9119797793153626

Epoch: 6| Step: 10
Training loss: 3.139547134592368
Validation loss: 2.912126436781412

Epoch: 6| Step: 11
Training loss: 3.5504645782366957
Validation loss: 2.916547551923695

Epoch: 6| Step: 12
Training loss: 2.7670651581664236
Validation loss: 2.9202513518719355

Epoch: 6| Step: 13
Training loss: 2.990536704997206
Validation loss: 2.9387714319816394

Epoch: 61| Step: 0
Training loss: 3.004259899736708
Validation loss: 2.929155294226788

Epoch: 6| Step: 1
Training loss: 3.6106850364570873
Validation loss: 2.9460370112261267

Epoch: 6| Step: 2
Training loss: 2.4700705943656556
Validation loss: 2.9213987897591824

Epoch: 6| Step: 3
Training loss: 3.5481742462240184
Validation loss: 2.9118663598712713

Epoch: 6| Step: 4
Training loss: 2.3987466320910724
Validation loss: 2.9148858629914067

Epoch: 6| Step: 5
Training loss: 3.8738919796671403
Validation loss: 2.9133241395370426

Epoch: 6| Step: 6
Training loss: 3.719391070334233
Validation loss: 2.9115547814182072

Epoch: 6| Step: 7
Training loss: 3.972861255618737
Validation loss: 2.91334638247805

Epoch: 6| Step: 8
Training loss: 3.461886101570793
Validation loss: 2.91032187576977

Epoch: 6| Step: 9
Training loss: 3.287932213049695
Validation loss: 2.910874204792006

Epoch: 6| Step: 10
Training loss: 1.9910010301557604
Validation loss: 2.908073616178531

Epoch: 6| Step: 11
Training loss: 2.9541146371094964
Validation loss: 2.908804191099609

Epoch: 6| Step: 12
Training loss: 3.1635747839775115
Validation loss: 2.9068441181773417

Epoch: 6| Step: 13
Training loss: 1.918547440066353
Validation loss: 2.9063413131293805

Epoch: 62| Step: 0
Training loss: 3.7329071863236223
Validation loss: 2.908016603387835

Epoch: 6| Step: 1
Training loss: 3.5410983059672905
Validation loss: 2.9055415875816957

Epoch: 6| Step: 2
Training loss: 3.594724042166666
Validation loss: 2.9057709793892594

Epoch: 6| Step: 3
Training loss: 2.8470771525158796
Validation loss: 2.906391603899412

Epoch: 6| Step: 4
Training loss: 3.0462708485562593
Validation loss: 2.906245568261377

Epoch: 6| Step: 5
Training loss: 2.5885780889659404
Validation loss: 2.9049294707138715

Epoch: 6| Step: 6
Training loss: 3.622655834060589
Validation loss: 2.904880638161817

Epoch: 6| Step: 7
Training loss: 3.0109407877248366
Validation loss: 2.9043884790314305

Epoch: 6| Step: 8
Training loss: 2.963845146386331
Validation loss: 2.902923788805248

Epoch: 6| Step: 9
Training loss: 2.9985856854992905
Validation loss: 2.904653251028704

Epoch: 6| Step: 10
Training loss: 2.370199672802407
Validation loss: 2.9046344657558976

Epoch: 6| Step: 11
Training loss: 3.692164945594066
Validation loss: 2.9064933912226785

Epoch: 6| Step: 12
Training loss: 3.0766080419948496
Validation loss: 2.908465049965564

Epoch: 6| Step: 13
Training loss: 3.417525361866247
Validation loss: 2.9062059619437

Epoch: 63| Step: 0
Training loss: 2.484480945559385
Validation loss: 2.90510545189269

Epoch: 6| Step: 1
Training loss: 3.4911063139917786
Validation loss: 2.9030348695044657

Epoch: 6| Step: 2
Training loss: 2.6299065646555504
Validation loss: 2.9065575059332125

Epoch: 6| Step: 3
Training loss: 3.268611436755263
Validation loss: 2.9093306902243334

Epoch: 6| Step: 4
Training loss: 2.836574850632316
Validation loss: 2.908997546777993

Epoch: 6| Step: 5
Training loss: 3.616210541917005
Validation loss: 2.9071027898512516

Epoch: 6| Step: 6
Training loss: 3.60535448085444
Validation loss: 2.9046083520478425

Epoch: 6| Step: 7
Training loss: 3.6820731882822737
Validation loss: 2.9048429601181716

Epoch: 6| Step: 8
Training loss: 3.4527593220546313
Validation loss: 2.9055365812484326

Epoch: 6| Step: 9
Training loss: 3.3261327377229906
Validation loss: 2.9043499992994612

Epoch: 6| Step: 10
Training loss: 2.72439375266867
Validation loss: 2.899726590962277

Epoch: 6| Step: 11
Training loss: 3.1174689526759423
Validation loss: 2.9054695957853864

Epoch: 6| Step: 12
Training loss: 3.2307810695836507
Validation loss: 2.9005830796697416

Epoch: 6| Step: 13
Training loss: 2.4621502506882296
Validation loss: 2.8979954377042523

Epoch: 64| Step: 0
Training loss: 2.673898566400004
Validation loss: 2.8990504738277014

Epoch: 6| Step: 1
Training loss: 2.749637233041857
Validation loss: 2.897341336376233

Epoch: 6| Step: 2
Training loss: 2.7955781284823233
Validation loss: 2.8975101861889088

Epoch: 6| Step: 3
Training loss: 3.140519629082011
Validation loss: 2.897869118392805

Epoch: 6| Step: 4
Training loss: 3.2864919299037183
Validation loss: 2.8972083901090047

Epoch: 6| Step: 5
Training loss: 3.7820759021035606
Validation loss: 2.8984478980524857

Epoch: 6| Step: 6
Training loss: 2.2750785646392
Validation loss: 2.897059796977815

Epoch: 6| Step: 7
Training loss: 3.851477198400926
Validation loss: 2.897521286537738

Epoch: 6| Step: 8
Training loss: 3.2109971980650256
Validation loss: 2.897522252706691

Epoch: 6| Step: 9
Training loss: 3.298356722118639
Validation loss: 2.8968547690734976

Epoch: 6| Step: 10
Training loss: 3.3112738877237993
Validation loss: 2.8948242443082592

Epoch: 6| Step: 11
Training loss: 4.053252743580732
Validation loss: 2.893737016197483

Epoch: 6| Step: 12
Training loss: 2.2472135455898314
Validation loss: 2.8929090722191924

Epoch: 6| Step: 13
Training loss: 3.545531972293119
Validation loss: 2.8935858207796574

Epoch: 65| Step: 0
Training loss: 3.377995045126968
Validation loss: 2.892897206233206

Epoch: 6| Step: 1
Training loss: 3.367043051752311
Validation loss: 2.8940274254281855

Epoch: 6| Step: 2
Training loss: 2.941004995508501
Validation loss: 2.893363714622396

Epoch: 6| Step: 3
Training loss: 3.2654026083533885
Validation loss: 2.88933096370044

Epoch: 6| Step: 4
Training loss: 2.9595212745166077
Validation loss: 2.8894780263343036

Epoch: 6| Step: 5
Training loss: 3.4925591529200344
Validation loss: 2.8897705136621012

Epoch: 6| Step: 6
Training loss: 3.034683013903272
Validation loss: 2.8914979937332634

Epoch: 6| Step: 7
Training loss: 3.5027389708414702
Validation loss: 2.8940125043276446

Epoch: 6| Step: 8
Training loss: 3.21265181839517
Validation loss: 2.889166706074474

Epoch: 6| Step: 9
Training loss: 3.3681320671139066
Validation loss: 2.902531976922472

Epoch: 6| Step: 10
Training loss: 3.5136794746999525
Validation loss: 2.909157760787478

Epoch: 6| Step: 11
Training loss: 2.6414399102860733
Validation loss: 2.931587778370046

Epoch: 6| Step: 12
Training loss: 2.6671814322332765
Validation loss: 2.921082911385045

Epoch: 6| Step: 13
Training loss: 3.0387125868006444
Validation loss: 2.925823958613244

Epoch: 66| Step: 0
Training loss: 3.1596460484602216
Validation loss: 2.921957233634573

Epoch: 6| Step: 1
Training loss: 3.4525938704406145
Validation loss: 2.922145239424791

Epoch: 6| Step: 2
Training loss: 3.4746793640189675
Validation loss: 2.8977965918416038

Epoch: 6| Step: 3
Training loss: 3.265805326164706
Validation loss: 2.885739294039256

Epoch: 6| Step: 4
Training loss: 3.3797516046476925
Validation loss: 2.884616605097384

Epoch: 6| Step: 5
Training loss: 3.460945353273045
Validation loss: 2.884943419999791

Epoch: 6| Step: 6
Training loss: 3.0820222765038885
Validation loss: 2.8873833791728445

Epoch: 6| Step: 7
Training loss: 2.691958787339051
Validation loss: 2.8863017364517773

Epoch: 6| Step: 8
Training loss: 3.0106512768061777
Validation loss: 2.8869375249525366

Epoch: 6| Step: 9
Training loss: 2.408091645394674
Validation loss: 2.886066655571483

Epoch: 6| Step: 10
Training loss: 3.424319156442732
Validation loss: 2.8843612283584923

Epoch: 6| Step: 11
Training loss: 2.922370419856047
Validation loss: 2.8850894311653734

Epoch: 6| Step: 12
Training loss: 3.3408061821445543
Validation loss: 2.885093578177982

Epoch: 6| Step: 13
Training loss: 3.3831534621308026
Validation loss: 2.8854625495830417

Epoch: 67| Step: 0
Training loss: 3.5494974667176975
Validation loss: 2.885912439947822

Epoch: 6| Step: 1
Training loss: 3.369439241748248
Validation loss: 2.887290910653602

Epoch: 6| Step: 2
Training loss: 3.3875383663468197
Validation loss: 2.8859343700504225

Epoch: 6| Step: 3
Training loss: 2.8000305957484977
Validation loss: 2.896734272071764

Epoch: 6| Step: 4
Training loss: 3.4673786373668745
Validation loss: 2.9043774773084756

Epoch: 6| Step: 5
Training loss: 3.850298258139977
Validation loss: 2.9215297822964983

Epoch: 6| Step: 6
Training loss: 2.9414702835306774
Validation loss: 2.9064938569392536

Epoch: 6| Step: 7
Training loss: 2.610436046758765
Validation loss: 2.8938397597926735

Epoch: 6| Step: 8
Training loss: 3.2918706581227597
Validation loss: 2.8814543928658605

Epoch: 6| Step: 9
Training loss: 2.681321338335874
Validation loss: 2.8762186721342284

Epoch: 6| Step: 10
Training loss: 2.8099288207843904
Validation loss: 2.878338179904136

Epoch: 6| Step: 11
Training loss: 3.6361402139518186
Validation loss: 2.8799048054309004

Epoch: 6| Step: 12
Training loss: 2.9638301840770813
Validation loss: 2.880757716022317

Epoch: 6| Step: 13
Training loss: 2.591603689460937
Validation loss: 2.8789437127203676

Epoch: 68| Step: 0
Training loss: 2.8710837850592377
Validation loss: 2.8830075188425486

Epoch: 6| Step: 1
Training loss: 3.3203643435750347
Validation loss: 2.883575453210815

Epoch: 6| Step: 2
Training loss: 3.2258784790611568
Validation loss: 2.882401418468447

Epoch: 6| Step: 3
Training loss: 2.910452153056204
Validation loss: 2.8817875507371484

Epoch: 6| Step: 4
Training loss: 3.2094134869816826
Validation loss: 2.880164881846535

Epoch: 6| Step: 5
Training loss: 3.519279784301798
Validation loss: 2.8838735075757262

Epoch: 6| Step: 6
Training loss: 3.3970713006847584
Validation loss: 2.8860602195181437

Epoch: 6| Step: 7
Training loss: 3.3489507711670226
Validation loss: 2.8782178090953727

Epoch: 6| Step: 8
Training loss: 3.292241315940442
Validation loss: 2.875102798814089

Epoch: 6| Step: 9
Training loss: 3.2184259936761044
Validation loss: 2.875274662917196

Epoch: 6| Step: 10
Training loss: 2.179601086506719
Validation loss: 2.877357036576862

Epoch: 6| Step: 11
Training loss: 2.7040991819294775
Validation loss: 2.8770446827379272

Epoch: 6| Step: 12
Training loss: 3.5900504267559237
Validation loss: 2.875865928928324

Epoch: 6| Step: 13
Training loss: 3.5827588056956943
Validation loss: 2.872814489155906

Epoch: 69| Step: 0
Training loss: 3.1413624974609506
Validation loss: 2.875176802839258

Epoch: 6| Step: 1
Training loss: 2.8237940889777713
Validation loss: 2.8758777252316956

Epoch: 6| Step: 2
Training loss: 3.297879757476823
Validation loss: 2.875956097704883

Epoch: 6| Step: 3
Training loss: 2.830731787003349
Validation loss: 2.874915734795448

Epoch: 6| Step: 4
Training loss: 3.8012740157829197
Validation loss: 2.872664803772741

Epoch: 6| Step: 5
Training loss: 3.0443680842616097
Validation loss: 2.874226515570429

Epoch: 6| Step: 6
Training loss: 3.24282308576212
Validation loss: 2.8714076672161073

Epoch: 6| Step: 7
Training loss: 3.1247241089152076
Validation loss: 2.8737441071198044

Epoch: 6| Step: 8
Training loss: 3.0463993581566817
Validation loss: 2.87082426564246

Epoch: 6| Step: 9
Training loss: 2.5912743209087634
Validation loss: 2.8720022412028374

Epoch: 6| Step: 10
Training loss: 2.738378242810113
Validation loss: 2.87549167225718

Epoch: 6| Step: 11
Training loss: 3.7151425599460723
Validation loss: 2.8837586004335725

Epoch: 6| Step: 12
Training loss: 3.559892737669344
Validation loss: 2.882401140972082

Epoch: 6| Step: 13
Training loss: 3.0456997683385376
Validation loss: 2.8777226400795266

Epoch: 70| Step: 0
Training loss: 3.1661951483648787
Validation loss: 2.879382156830465

Epoch: 6| Step: 1
Training loss: 3.592897795100779
Validation loss: 2.8766119398590853

Epoch: 6| Step: 2
Training loss: 3.4516526617567
Validation loss: 2.8825050525987246

Epoch: 6| Step: 3
Training loss: 3.282715678977378
Validation loss: 2.8735104822412323

Epoch: 6| Step: 4
Training loss: 3.0252645329598478
Validation loss: 2.8722310118458987

Epoch: 6| Step: 5
Training loss: 3.1312381279695565
Validation loss: 2.869899351920536

Epoch: 6| Step: 6
Training loss: 3.5347450986736875
Validation loss: 2.8673601237416904

Epoch: 6| Step: 7
Training loss: 2.452575816500104
Validation loss: 2.8667076388600683

Epoch: 6| Step: 8
Training loss: 3.441053461184451
Validation loss: 2.8673965794981666

Epoch: 6| Step: 9
Training loss: 3.432569400894258
Validation loss: 2.8697037290397738

Epoch: 6| Step: 10
Training loss: 2.4114637491537514
Validation loss: 2.8660923436406356

Epoch: 6| Step: 11
Training loss: 2.995684698995523
Validation loss: 2.868558707952626

Epoch: 6| Step: 12
Training loss: 2.9446949602316157
Validation loss: 2.8669467898860796

Epoch: 6| Step: 13
Training loss: 3.21974981390414
Validation loss: 2.8687268819138185

Epoch: 71| Step: 0
Training loss: 3.029616240066183
Validation loss: 2.8669839197557967

Epoch: 6| Step: 1
Training loss: 2.957111231580155
Validation loss: 2.864745574264686

Epoch: 6| Step: 2
Training loss: 3.37161494852912
Validation loss: 2.8643084053866144

Epoch: 6| Step: 3
Training loss: 3.277401656501991
Validation loss: 2.868060387494734

Epoch: 6| Step: 4
Training loss: 3.0446932292681907
Validation loss: 2.8707678017098637

Epoch: 6| Step: 5
Training loss: 3.274070223382009
Validation loss: 2.8775252486984204

Epoch: 6| Step: 6
Training loss: 2.479807559822423
Validation loss: 2.8806618274486384

Epoch: 6| Step: 7
Training loss: 3.2962292947361176
Validation loss: 2.8831083680195544

Epoch: 6| Step: 8
Training loss: 3.066500794720823
Validation loss: 2.8882821683471054

Epoch: 6| Step: 9
Training loss: 3.1945644706254437
Validation loss: 2.8918328854284368

Epoch: 6| Step: 10
Training loss: 3.0070969560302356
Validation loss: 2.882624340811597

Epoch: 6| Step: 11
Training loss: 3.2448535666319795
Validation loss: 2.8682688921147355

Epoch: 6| Step: 12
Training loss: 3.256380127633218
Validation loss: 2.8660718485201495

Epoch: 6| Step: 13
Training loss: 3.9810533028823696
Validation loss: 2.8610097442921636

Epoch: 72| Step: 0
Training loss: 3.2580573632592165
Validation loss: 2.863176493852137

Epoch: 6| Step: 1
Training loss: 2.6383345562692466
Validation loss: 2.8644846536563437

Epoch: 6| Step: 2
Training loss: 3.420744408688014
Validation loss: 2.8626001456135386

Epoch: 6| Step: 3
Training loss: 2.977375229944606
Validation loss: 2.8629935217850875

Epoch: 6| Step: 4
Training loss: 3.188798527724045
Validation loss: 2.8623675869450405

Epoch: 6| Step: 5
Training loss: 3.1508339217040056
Validation loss: 2.865389277199189

Epoch: 6| Step: 6
Training loss: 2.674289437868975
Validation loss: 2.8615794312429164

Epoch: 6| Step: 7
Training loss: 2.8527765903224864
Validation loss: 2.863964791885767

Epoch: 6| Step: 8
Training loss: 3.284445813955464
Validation loss: 2.8651787833517464

Epoch: 6| Step: 9
Training loss: 3.5830024891790653
Validation loss: 2.8631280943900492

Epoch: 6| Step: 10
Training loss: 3.707681034167185
Validation loss: 2.85844735471506

Epoch: 6| Step: 11
Training loss: 2.999463987149217
Validation loss: 2.86167287928266

Epoch: 6| Step: 12
Training loss: 3.5907557743384366
Validation loss: 2.856553596608629

Epoch: 6| Step: 13
Training loss: 2.3072463491106925
Validation loss: 2.852662120100846

Epoch: 73| Step: 0
Training loss: 3.841717066127374
Validation loss: 2.8556930359414774

Epoch: 6| Step: 1
Training loss: 4.036829908762601
Validation loss: 2.857058044462465

Epoch: 6| Step: 2
Training loss: 2.8610833073060307
Validation loss: 2.8540722374998615

Epoch: 6| Step: 3
Training loss: 3.2259764797254333
Validation loss: 2.8547336729839823

Epoch: 6| Step: 4
Training loss: 3.443711096791376
Validation loss: 2.8527438263440574

Epoch: 6| Step: 5
Training loss: 2.455165136186824
Validation loss: 2.8528814318059763

Epoch: 6| Step: 6
Training loss: 2.646370049854211
Validation loss: 2.854605279437524

Epoch: 6| Step: 7
Training loss: 3.50581816327623
Validation loss: 2.8527212744361545

Epoch: 6| Step: 8
Training loss: 2.6977387496039165
Validation loss: 2.8632668903307876

Epoch: 6| Step: 9
Training loss: 2.4996549368186045
Validation loss: 2.857711553797092

Epoch: 6| Step: 10
Training loss: 3.119650572747679
Validation loss: 2.8673125039130607

Epoch: 6| Step: 11
Training loss: 3.116595754649677
Validation loss: 2.872427025776796

Epoch: 6| Step: 12
Training loss: 3.552564318059246
Validation loss: 2.8909951356347245

Epoch: 6| Step: 13
Training loss: 2.092356203669018
Validation loss: 2.8678687503081233

Epoch: 74| Step: 0
Training loss: 3.289863253363288
Validation loss: 2.8586235401566564

Epoch: 6| Step: 1
Training loss: 3.9914559666420697
Validation loss: 2.851108550741408

Epoch: 6| Step: 2
Training loss: 2.919855572512287
Validation loss: 2.8514270129390846

Epoch: 6| Step: 3
Training loss: 3.894339752845879
Validation loss: 2.852694339522968

Epoch: 6| Step: 4
Training loss: 2.530160174821726
Validation loss: 2.854708408553249

Epoch: 6| Step: 5
Training loss: 2.733040445809424
Validation loss: 2.856881643127525

Epoch: 6| Step: 6
Training loss: 2.9532194576597415
Validation loss: 2.8593421547277127

Epoch: 6| Step: 7
Training loss: 3.7092948409998714
Validation loss: 2.8625578173802286

Epoch: 6| Step: 8
Training loss: 2.950471361940223
Validation loss: 2.8582243531555442

Epoch: 6| Step: 9
Training loss: 3.5069568159600695
Validation loss: 2.8595200565778445

Epoch: 6| Step: 10
Training loss: 2.9596704675915184
Validation loss: 2.8565567089958397

Epoch: 6| Step: 11
Training loss: 3.004718566511751
Validation loss: 2.8546422644908014

Epoch: 6| Step: 12
Training loss: 2.2691362204618124
Validation loss: 2.8514094054418595

Epoch: 6| Step: 13
Training loss: 3.0271607177532545
Validation loss: 2.8507760026807185

Epoch: 75| Step: 0
Training loss: 3.1211154445233187
Validation loss: 2.850160535908445

Epoch: 6| Step: 1
Training loss: 3.354859053583202
Validation loss: 2.847988955305109

Epoch: 6| Step: 2
Training loss: 3.4224816746914266
Validation loss: 2.8499002625954177

Epoch: 6| Step: 3
Training loss: 2.8772067018466654
Validation loss: 2.8510824530166015

Epoch: 6| Step: 4
Training loss: 2.8939707595623956
Validation loss: 2.861336256737546

Epoch: 6| Step: 5
Training loss: 3.445596488614637
Validation loss: 2.8747783448821913

Epoch: 6| Step: 6
Training loss: 2.795458386933816
Validation loss: 2.859333282117959

Epoch: 6| Step: 7
Training loss: 3.1531288653558907
Validation loss: 2.855175209885093

Epoch: 6| Step: 8
Training loss: 3.3142767405740807
Validation loss: 2.850335243166444

Epoch: 6| Step: 9
Training loss: 2.536181884572899
Validation loss: 2.8492437892564113

Epoch: 6| Step: 10
Training loss: 3.64915887207351
Validation loss: 2.8460695618888487

Epoch: 6| Step: 11
Training loss: 2.794127409359911
Validation loss: 2.8472902964302462

Epoch: 6| Step: 12
Training loss: 2.7469849096882886
Validation loss: 2.8448240137722314

Epoch: 6| Step: 13
Training loss: 4.133508173003191
Validation loss: 2.8430903031406265

Epoch: 76| Step: 0
Training loss: 2.9274662803577836
Validation loss: 2.8448691398853616

Epoch: 6| Step: 1
Training loss: 3.3658030910003776
Validation loss: 2.8430524978300507

Epoch: 6| Step: 2
Training loss: 2.7385144100426477
Validation loss: 2.8468318909425037

Epoch: 6| Step: 3
Training loss: 3.3050796600760233
Validation loss: 2.847964142336004

Epoch: 6| Step: 4
Training loss: 2.9980331967318263
Validation loss: 2.846782179778873

Epoch: 6| Step: 5
Training loss: 3.761246410912031
Validation loss: 2.8458987572548504

Epoch: 6| Step: 6
Training loss: 3.1385919623655423
Validation loss: 2.8463819823834746

Epoch: 6| Step: 7
Training loss: 3.073136212970665
Validation loss: 2.8447493697384787

Epoch: 6| Step: 8
Training loss: 2.7178906365091158
Validation loss: 2.8460566448854734

Epoch: 6| Step: 9
Training loss: 3.113690472634523
Validation loss: 2.8453458617109937

Epoch: 6| Step: 10
Training loss: 3.4135378646169765
Validation loss: 2.8458176940705404

Epoch: 6| Step: 11
Training loss: 3.3884774012099803
Validation loss: 2.845590618921682

Epoch: 6| Step: 12
Training loss: 3.181200272147101
Validation loss: 2.84446223914852

Epoch: 6| Step: 13
Training loss: 2.579018825141327
Validation loss: 2.844434271569075

Epoch: 77| Step: 0
Training loss: 3.844421948261139
Validation loss: 2.844862258731043

Epoch: 6| Step: 1
Training loss: 2.735661144231341
Validation loss: 2.8433648296748193

Epoch: 6| Step: 2
Training loss: 3.532566331590245
Validation loss: 2.8456561959061037

Epoch: 6| Step: 3
Training loss: 2.73508814640024
Validation loss: 2.8432088528838966

Epoch: 6| Step: 4
Training loss: 3.137320682827073
Validation loss: 2.8434448204644447

Epoch: 6| Step: 5
Training loss: 2.881827829802641
Validation loss: 2.8407247327572276

Epoch: 6| Step: 6
Training loss: 3.041603261905147
Validation loss: 2.8391977877068397

Epoch: 6| Step: 7
Training loss: 2.3382565013673164
Validation loss: 2.8426023220774175

Epoch: 6| Step: 8
Training loss: 3.383230135115813
Validation loss: 2.840305101149718

Epoch: 6| Step: 9
Training loss: 3.3441803557205034
Validation loss: 2.857533059378643

Epoch: 6| Step: 10
Training loss: 2.9615857866528366
Validation loss: 2.856855626856285

Epoch: 6| Step: 11
Training loss: 2.8515462796520694
Validation loss: 2.862034119397345

Epoch: 6| Step: 12
Training loss: 3.6570282458329895
Validation loss: 2.8563034691312392

Epoch: 6| Step: 13
Training loss: 3.302497877860994
Validation loss: 2.8438192019042785

Epoch: 78| Step: 0
Training loss: 3.875334448378874
Validation loss: 2.837910955977156

Epoch: 6| Step: 1
Training loss: 3.1914433041759542
Validation loss: 2.8361912313867927

Epoch: 6| Step: 2
Training loss: 3.0505345986040338
Validation loss: 2.8328492736158073

Epoch: 6| Step: 3
Training loss: 2.728686710310457
Validation loss: 2.8351225502814152

Epoch: 6| Step: 4
Training loss: 3.2551504552146255
Validation loss: 2.8317106368293614

Epoch: 6| Step: 5
Training loss: 2.5545876393063858
Validation loss: 2.8325406995011964

Epoch: 6| Step: 6
Training loss: 2.9301734622996363
Validation loss: 2.836001693851953

Epoch: 6| Step: 7
Training loss: 3.728907968651395
Validation loss: 2.8456486752153274

Epoch: 6| Step: 8
Training loss: 2.949823057396204
Validation loss: 2.858073120580621

Epoch: 6| Step: 9
Training loss: 2.831166018152038
Validation loss: 2.8790869855414365

Epoch: 6| Step: 10
Training loss: 2.115532823185819
Validation loss: 2.866321290819968

Epoch: 6| Step: 11
Training loss: 3.4327504030427036
Validation loss: 2.86339238681995

Epoch: 6| Step: 12
Training loss: 3.7374880277001754
Validation loss: 2.878582039523894

Epoch: 6| Step: 13
Training loss: 3.2055660715560563
Validation loss: 2.8381350929523816

Epoch: 79| Step: 0
Training loss: 2.6941716972639993
Validation loss: 2.830926169976487

Epoch: 6| Step: 1
Training loss: 3.4442701774183906
Validation loss: 2.830302623217828

Epoch: 6| Step: 2
Training loss: 3.4193629968816355
Validation loss: 2.8281665563943696

Epoch: 6| Step: 3
Training loss: 3.4135523923477042
Validation loss: 2.83362808510048

Epoch: 6| Step: 4
Training loss: 3.6026368762558074
Validation loss: 2.834719634230048

Epoch: 6| Step: 5
Training loss: 3.0512544897437905
Validation loss: 2.842840329348647

Epoch: 6| Step: 6
Training loss: 2.3876353999385147
Validation loss: 2.8445770907167525

Epoch: 6| Step: 7
Training loss: 3.6042817084560874
Validation loss: 2.8464963629177773

Epoch: 6| Step: 8
Training loss: 3.305774987752996
Validation loss: 2.84622804532512

Epoch: 6| Step: 9
Training loss: 2.6590115721337066
Validation loss: 2.8411628559689484

Epoch: 6| Step: 10
Training loss: 3.153688203173693
Validation loss: 2.833917354627092

Epoch: 6| Step: 11
Training loss: 2.577162869417719
Validation loss: 2.830054251994633

Epoch: 6| Step: 12
Training loss: 3.4027784663262395
Validation loss: 2.826703293657473

Epoch: 6| Step: 13
Training loss: 2.9265310144232792
Validation loss: 2.8219752501295616

Epoch: 80| Step: 0
Training loss: 3.1581809303197392
Validation loss: 2.820067007927912

Epoch: 6| Step: 1
Training loss: 3.5579030678353654
Validation loss: 2.8190006635140468

Epoch: 6| Step: 2
Training loss: 2.759398266531122
Validation loss: 2.822769163607139

Epoch: 6| Step: 3
Training loss: 3.7809919789452917
Validation loss: 2.830112538225115

Epoch: 6| Step: 4
Training loss: 2.7846131296793137
Validation loss: 2.8313038257188263

Epoch: 6| Step: 5
Training loss: 3.0760748372591564
Validation loss: 2.8341836907924574

Epoch: 6| Step: 6
Training loss: 2.4003795999098414
Validation loss: 2.843644316993805

Epoch: 6| Step: 7
Training loss: 3.1414031777489018
Validation loss: 2.8473918861909766

Epoch: 6| Step: 8
Training loss: 2.7062378528489743
Validation loss: 2.8456133147293325

Epoch: 6| Step: 9
Training loss: 3.531524377476522
Validation loss: 2.8244834093619446

Epoch: 6| Step: 10
Training loss: 3.032778167923351
Validation loss: 2.821379579821407

Epoch: 6| Step: 11
Training loss: 2.873857022184639
Validation loss: 2.821386160241839

Epoch: 6| Step: 12
Training loss: 3.0744816475005785
Validation loss: 2.818981305646332

Epoch: 6| Step: 13
Training loss: 3.988218600297602
Validation loss: 2.8189693876596893

Epoch: 81| Step: 0
Training loss: 3.2700501170386267
Validation loss: 2.8160408855649752

Epoch: 6| Step: 1
Training loss: 3.254521086307585
Validation loss: 2.816657503053317

Epoch: 6| Step: 2
Training loss: 2.805462828342835
Validation loss: 2.8188744612115415

Epoch: 6| Step: 3
Training loss: 3.1328957563262976
Validation loss: 2.817694113839581

Epoch: 6| Step: 4
Training loss: 3.033901510019328
Validation loss: 2.816799027939108

Epoch: 6| Step: 5
Training loss: 3.4633185675719007
Validation loss: 2.8164071211114416

Epoch: 6| Step: 6
Training loss: 2.4845312297329962
Validation loss: 2.8141956008144255

Epoch: 6| Step: 7
Training loss: 3.8621978937906305
Validation loss: 2.8125597893889633

Epoch: 6| Step: 8
Training loss: 3.366281055487086
Validation loss: 2.815308422705215

Epoch: 6| Step: 9
Training loss: 2.742976670130174
Validation loss: 2.812439901240779

Epoch: 6| Step: 10
Training loss: 4.036845500795149
Validation loss: 2.8142815356182767

Epoch: 6| Step: 11
Training loss: 2.139030698173421
Validation loss: 2.813463246187574

Epoch: 6| Step: 12
Training loss: 2.503865876965854
Validation loss: 2.8127866573844043

Epoch: 6| Step: 13
Training loss: 3.0364154967508465
Validation loss: 2.813906645318876

Epoch: 82| Step: 0
Training loss: 2.8679803484851276
Validation loss: 2.810316907076524

Epoch: 6| Step: 1
Training loss: 3.29060106694429
Validation loss: 2.810693599636488

Epoch: 6| Step: 2
Training loss: 3.9966279359859875
Validation loss: 2.8117415669136947

Epoch: 6| Step: 3
Training loss: 3.0514401397159228
Validation loss: 2.8102280239647457

Epoch: 6| Step: 4
Training loss: 2.3577615640142495
Validation loss: 2.810400655358429

Epoch: 6| Step: 5
Training loss: 3.6087837560678366
Validation loss: 2.8105168413850747

Epoch: 6| Step: 6
Training loss: 2.915802709595452
Validation loss: 2.8097115387921785

Epoch: 6| Step: 7
Training loss: 2.4350153657400977
Validation loss: 2.808123925660887

Epoch: 6| Step: 8
Training loss: 2.706409905975552
Validation loss: 2.806565638640759

Epoch: 6| Step: 9
Training loss: 2.6664078308690926
Validation loss: 2.806635841417332

Epoch: 6| Step: 10
Training loss: 3.158031904855453
Validation loss: 2.807395802690626

Epoch: 6| Step: 11
Training loss: 3.4139113752843526
Validation loss: 2.811404179943451

Epoch: 6| Step: 12
Training loss: 3.3864715028332886
Validation loss: 2.810402353869782

Epoch: 6| Step: 13
Training loss: 3.6187398063766456
Validation loss: 2.8117152761179125

Epoch: 83| Step: 0
Training loss: 3.0989839611543166
Validation loss: 2.8122124036092226

Epoch: 6| Step: 1
Training loss: 3.0240586699894854
Validation loss: 2.8139131174888607

Epoch: 6| Step: 2
Training loss: 3.2000536079684774
Validation loss: 2.8137734778460817

Epoch: 6| Step: 3
Training loss: 2.2986957832817176
Validation loss: 2.820453255669313

Epoch: 6| Step: 4
Training loss: 3.480857133869986
Validation loss: 2.8322019314702644

Epoch: 6| Step: 5
Training loss: 3.4018146440715475
Validation loss: 2.823725373204866

Epoch: 6| Step: 6
Training loss: 2.9747164551064778
Validation loss: 2.8118782130923607

Epoch: 6| Step: 7
Training loss: 3.3394842300099805
Validation loss: 2.806169449086155

Epoch: 6| Step: 8
Training loss: 3.4240813088255138
Validation loss: 2.8074101467899464

Epoch: 6| Step: 9
Training loss: 2.9411489670533393
Validation loss: 2.799930894162969

Epoch: 6| Step: 10
Training loss: 2.9341968876384636
Validation loss: 2.802235823144431

Epoch: 6| Step: 11
Training loss: 3.344947386642902
Validation loss: 2.8024742718947118

Epoch: 6| Step: 12
Training loss: 3.0905817937193367
Validation loss: 2.8002210373071597

Epoch: 6| Step: 13
Training loss: 2.7245606339446313
Validation loss: 2.7996410414457324

Epoch: 84| Step: 0
Training loss: 3.3058367234727037
Validation loss: 2.8007252714856117

Epoch: 6| Step: 1
Training loss: 2.4181095507520904
Validation loss: 2.8008819382116945

Epoch: 6| Step: 2
Training loss: 2.7990384392206225
Validation loss: 2.799951974139011

Epoch: 6| Step: 3
Training loss: 3.109444775589199
Validation loss: 2.8008331826278114

Epoch: 6| Step: 4
Training loss: 3.2317258148787484
Validation loss: 2.802663759835011

Epoch: 6| Step: 5
Training loss: 2.5743297963944416
Validation loss: 2.801257709503675

Epoch: 6| Step: 6
Training loss: 3.270206723459567
Validation loss: 2.8032899875027635

Epoch: 6| Step: 7
Training loss: 3.0912072106780784
Validation loss: 2.8002089167954662

Epoch: 6| Step: 8
Training loss: 2.9079855382105833
Validation loss: 2.8014037319138168

Epoch: 6| Step: 9
Training loss: 3.769191841301746
Validation loss: 2.8024622471176106

Epoch: 6| Step: 10
Training loss: 3.0377272783813667
Validation loss: 2.8075210060883413

Epoch: 6| Step: 11
Training loss: 3.223626008210026
Validation loss: 2.8037387325057956

Epoch: 6| Step: 12
Training loss: 3.654298701813413
Validation loss: 2.807310640625325

Epoch: 6| Step: 13
Training loss: 2.7463877969514603
Validation loss: 2.811271880623101

Epoch: 85| Step: 0
Training loss: 2.934029659794813
Validation loss: 2.8220458344690287

Epoch: 6| Step: 1
Training loss: 2.6133099883684667
Validation loss: 2.829277252100086

Epoch: 6| Step: 2
Training loss: 3.2125914089393652
Validation loss: 2.834961226874344

Epoch: 6| Step: 3
Training loss: 3.545319068872344
Validation loss: 2.813157349110252

Epoch: 6| Step: 4
Training loss: 3.2381245721295073
Validation loss: 2.8041318398471917

Epoch: 6| Step: 5
Training loss: 2.701080431048864
Validation loss: 2.8011976065802404

Epoch: 6| Step: 6
Training loss: 2.485251410064589
Validation loss: 2.8001763965048365

Epoch: 6| Step: 7
Training loss: 3.1586835185618978
Validation loss: 2.7978008536904255

Epoch: 6| Step: 8
Training loss: 3.4351340734977542
Validation loss: 2.7982330077706177

Epoch: 6| Step: 9
Training loss: 3.59503150979188
Validation loss: 2.7927997666782804

Epoch: 6| Step: 10
Training loss: 2.4853598124249126
Validation loss: 2.7932967812772227

Epoch: 6| Step: 11
Training loss: 3.647171094784135
Validation loss: 2.7976368549188004

Epoch: 6| Step: 12
Training loss: 3.1893504138487034
Validation loss: 2.7939005475672603

Epoch: 6| Step: 13
Training loss: 2.782883239566661
Validation loss: 2.793399207666649

Epoch: 86| Step: 0
Training loss: 2.529719891025641
Validation loss: 2.7928341839504602

Epoch: 6| Step: 1
Training loss: 3.6193970096889228
Validation loss: 2.7975193421956694

Epoch: 6| Step: 2
Training loss: 2.779114578498624
Validation loss: 2.7916760218730934

Epoch: 6| Step: 3
Training loss: 2.9435908701785536
Validation loss: 2.792897362875613

Epoch: 6| Step: 4
Training loss: 3.500896611491203
Validation loss: 2.793727509575377

Epoch: 6| Step: 5
Training loss: 2.857673180272549
Validation loss: 2.7901846438856013

Epoch: 6| Step: 6
Training loss: 3.1011695132406927
Validation loss: 2.790265931377084

Epoch: 6| Step: 7
Training loss: 3.0166810711539584
Validation loss: 2.7922007570669827

Epoch: 6| Step: 8
Training loss: 2.841121590729715
Validation loss: 2.7890885033812403

Epoch: 6| Step: 9
Training loss: 3.14165817650846
Validation loss: 2.79049736614549

Epoch: 6| Step: 10
Training loss: 3.1469377680014308
Validation loss: 2.7876208982475386

Epoch: 6| Step: 11
Training loss: 3.7768137736568095
Validation loss: 2.7902421183344726

Epoch: 6| Step: 12
Training loss: 2.5438459673500335
Validation loss: 2.7896460911873286

Epoch: 6| Step: 13
Training loss: 3.5748017049361294
Validation loss: 2.791773245963659

Epoch: 87| Step: 0
Training loss: 2.994151613696812
Validation loss: 2.790634001621917

Epoch: 6| Step: 1
Training loss: 3.685863325626738
Validation loss: 2.7947219551603095

Epoch: 6| Step: 2
Training loss: 3.351277941737068
Validation loss: 2.789726107830582

Epoch: 6| Step: 3
Training loss: 3.1178670730395233
Validation loss: 2.788698732409695

Epoch: 6| Step: 4
Training loss: 3.0326135459077608
Validation loss: 2.7875452052767513

Epoch: 6| Step: 5
Training loss: 2.5103805560499883
Validation loss: 2.788955866137104

Epoch: 6| Step: 6
Training loss: 2.869659106913673
Validation loss: 2.788507878112776

Epoch: 6| Step: 7
Training loss: 2.7219761966502602
Validation loss: 2.7929036928059654

Epoch: 6| Step: 8
Training loss: 3.2678663237276733
Validation loss: 2.7925737995099995

Epoch: 6| Step: 9
Training loss: 3.157762674866306
Validation loss: 2.791715206139948

Epoch: 6| Step: 10
Training loss: 2.3424683181753543
Validation loss: 2.7917627481215117

Epoch: 6| Step: 11
Training loss: 3.240704521299737
Validation loss: 2.794007227608105

Epoch: 6| Step: 12
Training loss: 3.3432710964182233
Validation loss: 2.7921705894670383

Epoch: 6| Step: 13
Training loss: 3.9065655390135094
Validation loss: 2.78904403092595

Epoch: 88| Step: 0
Training loss: 3.1133578301826734
Validation loss: 2.789112204944122

Epoch: 6| Step: 1
Training loss: 3.951789962237321
Validation loss: 2.791171975186526

Epoch: 6| Step: 2
Training loss: 2.947147516168077
Validation loss: 2.791350087003494

Epoch: 6| Step: 3
Training loss: 2.5547119512758574
Validation loss: 2.788803496214627

Epoch: 6| Step: 4
Training loss: 2.695610582758458
Validation loss: 2.794959839698117

Epoch: 6| Step: 5
Training loss: 3.5397198131908683
Validation loss: 2.796882210036647

Epoch: 6| Step: 6
Training loss: 2.3588406797767374
Validation loss: 2.7991637343489457

Epoch: 6| Step: 7
Training loss: 3.77890749164945
Validation loss: 2.8012073387416185

Epoch: 6| Step: 8
Training loss: 2.9928146780690623
Validation loss: 2.795130027845781

Epoch: 6| Step: 9
Training loss: 3.195493660340506
Validation loss: 2.7965080170333576

Epoch: 6| Step: 10
Training loss: 2.4074507850694973
Validation loss: 2.79116027737792

Epoch: 6| Step: 11
Training loss: 3.197813813153253
Validation loss: 2.787198774610226

Epoch: 6| Step: 12
Training loss: 3.1682989698617074
Validation loss: 2.786966933459913

Epoch: 6| Step: 13
Training loss: 2.9693159668164344
Validation loss: 2.7905444998477495

Epoch: 89| Step: 0
Training loss: 3.1007878563681515
Validation loss: 2.794649361570142

Epoch: 6| Step: 1
Training loss: 3.265604557539186
Validation loss: 2.7844404158919236

Epoch: 6| Step: 2
Training loss: 3.2095791433274727
Validation loss: 2.7840007062449517

Epoch: 6| Step: 3
Training loss: 2.8816626925539404
Validation loss: 2.7808325263969267

Epoch: 6| Step: 4
Training loss: 3.501719188801649
Validation loss: 2.7821915781614592

Epoch: 6| Step: 5
Training loss: 3.0650516701056576
Validation loss: 2.7810950536222294

Epoch: 6| Step: 6
Training loss: 2.9361595179492124
Validation loss: 2.784740642560708

Epoch: 6| Step: 7
Training loss: 2.8489039739598523
Validation loss: 2.783589285295158

Epoch: 6| Step: 8
Training loss: 3.399875100029526
Validation loss: 2.7789499428362703

Epoch: 6| Step: 9
Training loss: 3.1060908624115684
Validation loss: 2.78616787892948

Epoch: 6| Step: 10
Training loss: 2.9086369382411714
Validation loss: 2.7894529627329234

Epoch: 6| Step: 11
Training loss: 2.569381034916365
Validation loss: 2.794458179764543

Epoch: 6| Step: 12
Training loss: 3.3991694221257847
Validation loss: 2.8216725767509456

Epoch: 6| Step: 13
Training loss: 3.025894940616807
Validation loss: 2.8017735103934203

Epoch: 90| Step: 0
Training loss: 3.1890715670421694
Validation loss: 2.799109725594512

Epoch: 6| Step: 1
Training loss: 2.827517702433437
Validation loss: 2.7996999150568587

Epoch: 6| Step: 2
Training loss: 3.481172056027537
Validation loss: 2.8051677074187844

Epoch: 6| Step: 3
Training loss: 2.279445300136034
Validation loss: 2.7841262075903415

Epoch: 6| Step: 4
Training loss: 2.7180209004354356
Validation loss: 2.78153107326554

Epoch: 6| Step: 5
Training loss: 3.1577356449006575
Validation loss: 2.7802216095429637

Epoch: 6| Step: 6
Training loss: 4.056396829683724
Validation loss: 2.7809261618794934

Epoch: 6| Step: 7
Training loss: 3.1095125560908765
Validation loss: 2.78262443543811

Epoch: 6| Step: 8
Training loss: 3.241954381444123
Validation loss: 2.779498312909871

Epoch: 6| Step: 9
Training loss: 3.0811670443063344
Validation loss: 2.777639701617817

Epoch: 6| Step: 10
Training loss: 2.748413408530579
Validation loss: 2.7798517797533338

Epoch: 6| Step: 11
Training loss: 3.0720984625037446
Validation loss: 2.7812026590058485

Epoch: 6| Step: 12
Training loss: 2.9216920519993734
Validation loss: 2.7795602639081656

Epoch: 6| Step: 13
Training loss: 3.1765337025640688
Validation loss: 2.7819634656553625

Epoch: 91| Step: 0
Training loss: 2.900298885859755
Validation loss: 2.7782387696172153

Epoch: 6| Step: 1
Training loss: 3.0818853500894856
Validation loss: 2.776989049060037

Epoch: 6| Step: 2
Training loss: 2.605059224076029
Validation loss: 2.7736277996649665

Epoch: 6| Step: 3
Training loss: 3.2541301599881542
Validation loss: 2.777087011655559

Epoch: 6| Step: 4
Training loss: 3.5118224878657087
Validation loss: 2.7809589920913456

Epoch: 6| Step: 5
Training loss: 3.236112708299176
Validation loss: 2.781980773628392

Epoch: 6| Step: 6
Training loss: 3.151502154202325
Validation loss: 2.797704470423991

Epoch: 6| Step: 7
Training loss: 3.2399300311033437
Validation loss: 2.7995750862205

Epoch: 6| Step: 8
Training loss: 2.4356633627290383
Validation loss: 2.7853748685781934

Epoch: 6| Step: 9
Training loss: 3.5955264800784477
Validation loss: 2.7829928337289274

Epoch: 6| Step: 10
Training loss: 3.026362933352528
Validation loss: 2.7799140253566197

Epoch: 6| Step: 11
Training loss: 2.6572139113018847
Validation loss: 2.776227704747727

Epoch: 6| Step: 12
Training loss: 3.4373124504944585
Validation loss: 2.773483475184611

Epoch: 6| Step: 13
Training loss: 2.733165626110536
Validation loss: 2.7702368952401004

Epoch: 92| Step: 0
Training loss: 2.6769705920593774
Validation loss: 2.775406632751734

Epoch: 6| Step: 1
Training loss: 3.723218781278065
Validation loss: 2.7705374433355696

Epoch: 6| Step: 2
Training loss: 2.6955493767627257
Validation loss: 2.773907306123832

Epoch: 6| Step: 3
Training loss: 3.419860525577658
Validation loss: 2.778334037158189

Epoch: 6| Step: 4
Training loss: 3.4091385658863405
Validation loss: 2.7862073403266794

Epoch: 6| Step: 5
Training loss: 2.996891000205756
Validation loss: 2.7881347762312285

Epoch: 6| Step: 6
Training loss: 2.8592300795221157
Validation loss: 2.809626302751791

Epoch: 6| Step: 7
Training loss: 2.7939413017982835
Validation loss: 2.857083831875455

Epoch: 6| Step: 8
Training loss: 3.263317260105137
Validation loss: 2.8831130553982094

Epoch: 6| Step: 9
Training loss: 2.9936330306550607
Validation loss: 2.9071789087405135

Epoch: 6| Step: 10
Training loss: 3.139568701602193
Validation loss: 2.9064735646815536

Epoch: 6| Step: 11
Training loss: 3.17933611603632
Validation loss: 2.880836421151379

Epoch: 6| Step: 12
Training loss: 3.2388556216061657
Validation loss: 2.8234822471377807

Epoch: 6| Step: 13
Training loss: 2.7167927504068707
Validation loss: 2.7768588214111136

Epoch: 93| Step: 0
Training loss: 3.0345294948419794
Validation loss: 2.772108954933135

Epoch: 6| Step: 1
Training loss: 2.790301392386056
Validation loss: 2.769554534846161

Epoch: 6| Step: 2
Training loss: 3.0976642546003132
Validation loss: 2.7743528614984454

Epoch: 6| Step: 3
Training loss: 2.6913526554612552
Validation loss: 2.7801312497116677

Epoch: 6| Step: 4
Training loss: 2.465431784056484
Validation loss: 2.7998164828760306

Epoch: 6| Step: 5
Training loss: 3.1574212346706947
Validation loss: 2.814374525534218

Epoch: 6| Step: 6
Training loss: 2.938953770396256
Validation loss: 2.833324216710962

Epoch: 6| Step: 7
Training loss: 3.5832791583083767
Validation loss: 2.8300204803251576

Epoch: 6| Step: 8
Training loss: 3.2216674027406733
Validation loss: 2.8131234247150316

Epoch: 6| Step: 9
Training loss: 3.416605475893474
Validation loss: 2.7903860721433777

Epoch: 6| Step: 10
Training loss: 3.5201953257206604
Validation loss: 2.773649322633631

Epoch: 6| Step: 11
Training loss: 3.2600666544834334
Validation loss: 2.766923046748518

Epoch: 6| Step: 12
Training loss: 3.0525912924321874
Validation loss: 2.7682364377304154

Epoch: 6| Step: 13
Training loss: 3.200249548956791
Validation loss: 2.7631945513344904

Epoch: 94| Step: 0
Training loss: 2.9207758340513434
Validation loss: 2.761397935464095

Epoch: 6| Step: 1
Training loss: 3.2113942659074914
Validation loss: 2.7667524559704897

Epoch: 6| Step: 2
Training loss: 3.291688138352553
Validation loss: 2.772924374536796

Epoch: 6| Step: 3
Training loss: 3.2224294131814606
Validation loss: 2.8087699356005786

Epoch: 6| Step: 4
Training loss: 2.943223288161231
Validation loss: 2.8222958960224203

Epoch: 6| Step: 5
Training loss: 2.5516612943081536
Validation loss: 2.8251981581698016

Epoch: 6| Step: 6
Training loss: 3.085034047438138
Validation loss: 2.860590994868743

Epoch: 6| Step: 7
Training loss: 3.2299321569634287
Validation loss: 2.853212938394649

Epoch: 6| Step: 8
Training loss: 3.380292345755532
Validation loss: 2.8305315234981094

Epoch: 6| Step: 9
Training loss: 3.2986162116474183
Validation loss: 2.764655390338217

Epoch: 6| Step: 10
Training loss: 3.503059956936171
Validation loss: 2.7616609613528955

Epoch: 6| Step: 11
Training loss: 2.392781002240409
Validation loss: 2.7662494228663017

Epoch: 6| Step: 12
Training loss: 3.0871547181580024
Validation loss: 2.7654298889995754

Epoch: 6| Step: 13
Training loss: 2.9302021032421512
Validation loss: 2.7734390381261824

Epoch: 95| Step: 0
Training loss: 2.6509560282027227
Validation loss: 2.7755245385912186

Epoch: 6| Step: 1
Training loss: 2.8824293920995623
Validation loss: 2.778863433895787

Epoch: 6| Step: 2
Training loss: 3.6289615688480734
Validation loss: 2.785580684867788

Epoch: 6| Step: 3
Training loss: 3.1441460604531226
Validation loss: 2.785121504046214

Epoch: 6| Step: 4
Training loss: 3.94840438098249
Validation loss: 2.789252183998813

Epoch: 6| Step: 5
Training loss: 2.8568839807396342
Validation loss: 2.779387164185526

Epoch: 6| Step: 6
Training loss: 3.29779126781756
Validation loss: 2.7718916919636336

Epoch: 6| Step: 7
Training loss: 2.8340836447767064
Validation loss: 2.7664007344913046

Epoch: 6| Step: 8
Training loss: 2.865148167265655
Validation loss: 2.764860310391454

Epoch: 6| Step: 9
Training loss: 3.199317120168051
Validation loss: 2.762189936745272

Epoch: 6| Step: 10
Training loss: 2.6480788266530073
Validation loss: 2.762115024470129

Epoch: 6| Step: 11
Training loss: 2.8651425087522235
Validation loss: 2.762432357256156

Epoch: 6| Step: 12
Training loss: 3.2983604808870486
Validation loss: 2.7625858884307215

Epoch: 6| Step: 13
Training loss: 2.964984955773615
Validation loss: 2.760387022231128

Epoch: 96| Step: 0
Training loss: 2.8057404563161628
Validation loss: 2.759986517638296

Epoch: 6| Step: 1
Training loss: 3.5771261761780018
Validation loss: 2.7586941682461577

Epoch: 6| Step: 2
Training loss: 2.6813976291659953
Validation loss: 2.7636903299622593

Epoch: 6| Step: 3
Training loss: 2.373693207055862
Validation loss: 2.7580294982247735

Epoch: 6| Step: 4
Training loss: 3.2033506732620878
Validation loss: 2.7574667872090277

Epoch: 6| Step: 5
Training loss: 3.174412956934681
Validation loss: 2.7560688074483677

Epoch: 6| Step: 6
Training loss: 3.3349826705917036
Validation loss: 2.75501618195143

Epoch: 6| Step: 7
Training loss: 3.1964621119706957
Validation loss: 2.754704535396641

Epoch: 6| Step: 8
Training loss: 2.499490972195473
Validation loss: 2.7591782011122645

Epoch: 6| Step: 9
Training loss: 2.9049128255715218
Validation loss: 2.7614858261374176

Epoch: 6| Step: 10
Training loss: 3.6568889874660386
Validation loss: 2.7615607796172794

Epoch: 6| Step: 11
Training loss: 2.9842970273681866
Validation loss: 2.7717232383455177

Epoch: 6| Step: 12
Training loss: 3.1199394450057727
Validation loss: 2.782166287104979

Epoch: 6| Step: 13
Training loss: 3.3656442739064096
Validation loss: 2.814960474513335

Epoch: 97| Step: 0
Training loss: 3.4533328170726887
Validation loss: 2.79233831175594

Epoch: 6| Step: 1
Training loss: 3.1041052554070245
Validation loss: 2.7624883312668786

Epoch: 6| Step: 2
Training loss: 2.87328834997075
Validation loss: 2.758041226869728

Epoch: 6| Step: 3
Training loss: 2.5558408414392315
Validation loss: 2.75479944144871

Epoch: 6| Step: 4
Training loss: 3.0418476590867116
Validation loss: 2.7546765034202583

Epoch: 6| Step: 5
Training loss: 3.5490041383669175
Validation loss: 2.755184504185734

Epoch: 6| Step: 6
Training loss: 3.019678899355427
Validation loss: 2.756414537464825

Epoch: 6| Step: 7
Training loss: 3.266129158199282
Validation loss: 2.755213315379131

Epoch: 6| Step: 8
Training loss: 3.32985488277556
Validation loss: 2.755512537968067

Epoch: 6| Step: 9
Training loss: 2.950669332315465
Validation loss: 2.7576399139724037

Epoch: 6| Step: 10
Training loss: 3.145852970963041
Validation loss: 2.756946573604212

Epoch: 6| Step: 11
Training loss: 2.736071948326816
Validation loss: 2.755400220726002

Epoch: 6| Step: 12
Training loss: 3.0785986831161627
Validation loss: 2.7557945599373177

Epoch: 6| Step: 13
Training loss: 2.651289043363847
Validation loss: 2.75509369261547

Epoch: 98| Step: 0
Training loss: 3.1479900789989137
Validation loss: 2.7574661187484506

Epoch: 6| Step: 1
Training loss: 2.925880827692558
Validation loss: 2.7554817472677176

Epoch: 6| Step: 2
Training loss: 2.681235708629872
Validation loss: 2.7554612490950747

Epoch: 6| Step: 3
Training loss: 3.217841158951629
Validation loss: 2.755118935359391

Epoch: 6| Step: 4
Training loss: 2.7735953272654448
Validation loss: 2.758830119822173

Epoch: 6| Step: 5
Training loss: 3.1033931681610962
Validation loss: 2.7586932017792116

Epoch: 6| Step: 6
Training loss: 3.9790863242035686
Validation loss: 2.748823275839988

Epoch: 6| Step: 7
Training loss: 2.8050739160274265
Validation loss: 2.7520999069170027

Epoch: 6| Step: 8
Training loss: 2.9773005974634557
Validation loss: 2.7506558614087777

Epoch: 6| Step: 9
Training loss: 3.2112606285100482
Validation loss: 2.7512846031748133

Epoch: 6| Step: 10
Training loss: 3.068733411072063
Validation loss: 2.7559837244124963

Epoch: 6| Step: 11
Training loss: 3.031233954632952
Validation loss: 2.7573092008141864

Epoch: 6| Step: 12
Training loss: 3.0121056769527295
Validation loss: 2.7573576298190647

Epoch: 6| Step: 13
Training loss: 2.6453428840131528
Validation loss: 2.763827019002404

Epoch: 99| Step: 0
Training loss: 2.568256611091707
Validation loss: 2.762810895422376

Epoch: 6| Step: 1
Training loss: 2.428627298016997
Validation loss: 2.7621531737117158

Epoch: 6| Step: 2
Training loss: 3.4577266360109906
Validation loss: 2.7571894672150505

Epoch: 6| Step: 3
Training loss: 3.4830718062449555
Validation loss: 2.7563176091897987

Epoch: 6| Step: 4
Training loss: 3.1692513575251953
Validation loss: 2.7537715430045875

Epoch: 6| Step: 5
Training loss: 2.9466628968170125
Validation loss: 2.747123737369151

Epoch: 6| Step: 6
Training loss: 2.7290773352837085
Validation loss: 2.7492181182885687

Epoch: 6| Step: 7
Training loss: 2.7196462622795545
Validation loss: 2.7444278220360725

Epoch: 6| Step: 8
Training loss: 3.016672851668563
Validation loss: 2.747294972153728

Epoch: 6| Step: 9
Training loss: 3.335944075209416
Validation loss: 2.747891862573169

Epoch: 6| Step: 10
Training loss: 2.6078519659330173
Validation loss: 2.7423337604016

Epoch: 6| Step: 11
Training loss: 3.751949439377094
Validation loss: 2.7452618396917376

Epoch: 6| Step: 12
Training loss: 2.9207604878511653
Validation loss: 2.745646863737967

Epoch: 6| Step: 13
Training loss: 3.696691404993119
Validation loss: 2.745542273043678

Epoch: 100| Step: 0
Training loss: 2.5692311711049656
Validation loss: 2.748934859267246

Epoch: 6| Step: 1
Training loss: 3.2237595767544174
Validation loss: 2.761694349196897

Epoch: 6| Step: 2
Training loss: 2.7173872415263447
Validation loss: 2.7642221203717803

Epoch: 6| Step: 3
Training loss: 2.593978596001218
Validation loss: 2.748995370906831

Epoch: 6| Step: 4
Training loss: 3.301850961557603
Validation loss: 2.7437565238935435

Epoch: 6| Step: 5
Training loss: 2.551786215996724
Validation loss: 2.7482583934570664

Epoch: 6| Step: 6
Training loss: 3.115056047746658
Validation loss: 2.7404786637803578

Epoch: 6| Step: 7
Training loss: 3.1717539797090653
Validation loss: 2.743318585125523

Epoch: 6| Step: 8
Training loss: 3.3072217238031545
Validation loss: 2.742703003504279

Epoch: 6| Step: 9
Training loss: 3.182894502387737
Validation loss: 2.739139429370896

Epoch: 6| Step: 10
Training loss: 3.322190128569738
Validation loss: 2.742131103182497

Epoch: 6| Step: 11
Training loss: 3.475558909744938
Validation loss: 2.7415858834863354

Epoch: 6| Step: 12
Training loss: 2.941930473392993
Validation loss: 2.742059216219929

Epoch: 6| Step: 13
Training loss: 3.3460686746174755
Validation loss: 2.7411675755913754

Epoch: 101| Step: 0
Training loss: 3.633672928178128
Validation loss: 2.743385861071746

Epoch: 6| Step: 1
Training loss: 2.1995756086746296
Validation loss: 2.7397724393434957

Epoch: 6| Step: 2
Training loss: 3.365380034391199
Validation loss: 2.7396263360302258

Epoch: 6| Step: 3
Training loss: 3.026589497774204
Validation loss: 2.7475561309335546

Epoch: 6| Step: 4
Training loss: 3.1610723235736446
Validation loss: 2.7602401864275232

Epoch: 6| Step: 5
Training loss: 2.571454475665934
Validation loss: 2.765035257830277

Epoch: 6| Step: 6
Training loss: 2.8629466612041345
Validation loss: 2.793939082192182

Epoch: 6| Step: 7
Training loss: 2.985133369316182
Validation loss: 2.834021959340892

Epoch: 6| Step: 8
Training loss: 2.78151847315086
Validation loss: 2.8554899407013155

Epoch: 6| Step: 9
Training loss: 2.7391867888519745
Validation loss: 2.941945784104502

Epoch: 6| Step: 10
Training loss: 3.212460196281864
Validation loss: 2.8270455308546936

Epoch: 6| Step: 11
Training loss: 3.554328380511743
Validation loss: 2.759646274812862

Epoch: 6| Step: 12
Training loss: 3.0492916597899984
Validation loss: 2.7405892586432796

Epoch: 6| Step: 13
Training loss: 3.9002197105924115
Validation loss: 2.7457710809037135

Epoch: 102| Step: 0
Training loss: 2.9981669547919028
Validation loss: 2.7468807983225245

Epoch: 6| Step: 1
Training loss: 2.5193173813057026
Validation loss: 2.764230309624414

Epoch: 6| Step: 2
Training loss: 2.8047314483684604
Validation loss: 2.772352427815654

Epoch: 6| Step: 3
Training loss: 2.7099514357941534
Validation loss: 2.790993986109959

Epoch: 6| Step: 4
Training loss: 3.3120623605358226
Validation loss: 2.7978717354460967

Epoch: 6| Step: 5
Training loss: 3.3264664649987425
Validation loss: 2.799487890452676

Epoch: 6| Step: 6
Training loss: 3.419399393671342
Validation loss: 2.7649999372991907

Epoch: 6| Step: 7
Training loss: 2.982554414673237
Validation loss: 2.7507052286393954

Epoch: 6| Step: 8
Training loss: 2.9451271221398856
Validation loss: 2.74523998583573

Epoch: 6| Step: 9
Training loss: 2.6321999943878356
Validation loss: 2.742030437907619

Epoch: 6| Step: 10
Training loss: 3.5180755890429256
Validation loss: 2.7430365318828374

Epoch: 6| Step: 11
Training loss: 3.2833532949186157
Validation loss: 2.7401860718570954

Epoch: 6| Step: 12
Training loss: 3.5832352439998654
Validation loss: 2.7398878271670153

Epoch: 6| Step: 13
Training loss: 2.891875620244811
Validation loss: 2.7485391189496817

Epoch: 103| Step: 0
Training loss: 2.8462305673263386
Validation loss: 2.7461550150619236

Epoch: 6| Step: 1
Training loss: 2.4934725423019737
Validation loss: 2.7477729576244854

Epoch: 6| Step: 2
Training loss: 3.637718251815256
Validation loss: 2.753925320569383

Epoch: 6| Step: 3
Training loss: 2.508473532001961
Validation loss: 2.7522114804550637

Epoch: 6| Step: 4
Training loss: 3.0997084449747296
Validation loss: 2.7625528018248127

Epoch: 6| Step: 5
Training loss: 3.448732093358052
Validation loss: 2.763834958982789

Epoch: 6| Step: 6
Training loss: 3.3772970788904595
Validation loss: 2.750512287940855

Epoch: 6| Step: 7
Training loss: 3.2813424233635287
Validation loss: 2.7553740641006494

Epoch: 6| Step: 8
Training loss: 2.27653622582642
Validation loss: 2.756534976200639

Epoch: 6| Step: 9
Training loss: 3.0130237171595606
Validation loss: 2.7434485378329536

Epoch: 6| Step: 10
Training loss: 3.111833836608272
Validation loss: 2.731330818235883

Epoch: 6| Step: 11
Training loss: 3.211307105257886
Validation loss: 2.732224924007341

Epoch: 6| Step: 12
Training loss: 3.0746282089135386
Validation loss: 2.7284504460164514

Epoch: 6| Step: 13
Training loss: 3.1462523495010255
Validation loss: 2.7277034938193814

Epoch: 104| Step: 0
Training loss: 2.868535777219449
Validation loss: 2.730239566782184

Epoch: 6| Step: 1
Training loss: 3.8602212449149054
Validation loss: 2.72876336985593

Epoch: 6| Step: 2
Training loss: 3.3367895963306804
Validation loss: 2.734034629064432

Epoch: 6| Step: 3
Training loss: 2.503451825354368
Validation loss: 2.732675099094623

Epoch: 6| Step: 4
Training loss: 3.215935671139235
Validation loss: 2.74173546827024

Epoch: 6| Step: 5
Training loss: 3.031892688694116
Validation loss: 2.7412480389064706

Epoch: 6| Step: 6
Training loss: 2.8782413289338695
Validation loss: 2.7543353086658775

Epoch: 6| Step: 7
Training loss: 3.273410696862224
Validation loss: 2.770867587986604

Epoch: 6| Step: 8
Training loss: 2.6637460291316897
Validation loss: 2.816582629552102

Epoch: 6| Step: 9
Training loss: 3.3004431918230575
Validation loss: 2.8303732399143846

Epoch: 6| Step: 10
Training loss: 2.6287411868917663
Validation loss: 2.8384512661216528

Epoch: 6| Step: 11
Training loss: 2.4861043033707917
Validation loss: 2.820208745779641

Epoch: 6| Step: 12
Training loss: 3.25169387104719
Validation loss: 2.7723914690805507

Epoch: 6| Step: 13
Training loss: 3.210779339313008
Validation loss: 2.7551051899658803

Epoch: 105| Step: 0
Training loss: 3.3095492770060324
Validation loss: 2.739886111141143

Epoch: 6| Step: 1
Training loss: 3.407759445735928
Validation loss: 2.74123800268959

Epoch: 6| Step: 2
Training loss: 2.27011316294651
Validation loss: 2.7420019668925444

Epoch: 6| Step: 3
Training loss: 2.835029561798602
Validation loss: 2.739741573741254

Epoch: 6| Step: 4
Training loss: 3.070628996787643
Validation loss: 2.7412628595956487

Epoch: 6| Step: 5
Training loss: 3.1120167920167052
Validation loss: 2.7354116154878616

Epoch: 6| Step: 6
Training loss: 2.2688140523816993
Validation loss: 2.7288357893329285

Epoch: 6| Step: 7
Training loss: 2.6498629804491833
Validation loss: 2.726571245217948

Epoch: 6| Step: 8
Training loss: 3.8931717101825627
Validation loss: 2.728214480752104

Epoch: 6| Step: 9
Training loss: 2.64940038411047
Validation loss: 2.7284561643906224

Epoch: 6| Step: 10
Training loss: 3.7282311884041546
Validation loss: 2.729050570337834

Epoch: 6| Step: 11
Training loss: 3.291198037183192
Validation loss: 2.7310107389464457

Epoch: 6| Step: 12
Training loss: 2.595743631085615
Validation loss: 2.7314324616294394

Epoch: 6| Step: 13
Training loss: 3.2634883625845226
Validation loss: 2.72092264275671

Epoch: 106| Step: 0
Training loss: 3.26076090562537
Validation loss: 2.7257708988127116

Epoch: 6| Step: 1
Training loss: 2.702021555511761
Validation loss: 2.734495723655238

Epoch: 6| Step: 2
Training loss: 2.681708994172382
Validation loss: 2.7533354616349364

Epoch: 6| Step: 3
Training loss: 3.1167879159227048
Validation loss: 2.78130983438315

Epoch: 6| Step: 4
Training loss: 2.6950111994749504
Validation loss: 2.7671568562930533

Epoch: 6| Step: 5
Training loss: 3.4023380038610345
Validation loss: 2.7786262103176878

Epoch: 6| Step: 6
Training loss: 3.3041648361245883
Validation loss: 2.7686673081579896

Epoch: 6| Step: 7
Training loss: 3.1639473599806487
Validation loss: 2.77109058014667

Epoch: 6| Step: 8
Training loss: 2.953347495441911
Validation loss: 2.7565152754552793

Epoch: 6| Step: 9
Training loss: 3.144447240240369
Validation loss: 2.7591858813063133

Epoch: 6| Step: 10
Training loss: 3.459052060981953
Validation loss: 2.7537323457466294

Epoch: 6| Step: 11
Training loss: 3.3136609040510066
Validation loss: 2.742804431094429

Epoch: 6| Step: 12
Training loss: 2.8420834531188888
Validation loss: 2.730189284873521

Epoch: 6| Step: 13
Training loss: 2.1429716738111777
Validation loss: 2.7224949584026548

Epoch: 107| Step: 0
Training loss: 2.6717034000370954
Validation loss: 2.723272386686958

Epoch: 6| Step: 1
Training loss: 3.167538840666189
Validation loss: 2.725455497107398

Epoch: 6| Step: 2
Training loss: 2.6748423021839502
Validation loss: 2.7290941999205316

Epoch: 6| Step: 3
Training loss: 3.1857254474109564
Validation loss: 2.7259184886583743

Epoch: 6| Step: 4
Training loss: 3.0300268477959493
Validation loss: 2.7229830628613234

Epoch: 6| Step: 5
Training loss: 2.8728843866037326
Validation loss: 2.721552719469718

Epoch: 6| Step: 6
Training loss: 3.6255540095578085
Validation loss: 2.7203706355413537

Epoch: 6| Step: 7
Training loss: 3.113889244760914
Validation loss: 2.71819779395481

Epoch: 6| Step: 8
Training loss: 3.0541258000393205
Validation loss: 2.727685774710983

Epoch: 6| Step: 9
Training loss: 3.1104899952023484
Validation loss: 2.718159901161293

Epoch: 6| Step: 10
Training loss: 3.0992018318147223
Validation loss: 2.721562369067142

Epoch: 6| Step: 11
Training loss: 2.896540347360402
Validation loss: 2.72088392955916

Epoch: 6| Step: 12
Training loss: 2.7653837799221193
Validation loss: 2.7148931716430287

Epoch: 6| Step: 13
Training loss: 3.455169762775718
Validation loss: 2.717292275092508

Epoch: 108| Step: 0
Training loss: 2.993169319683393
Validation loss: 2.716101632682621

Epoch: 6| Step: 1
Training loss: 3.161484108096555
Validation loss: 2.711439189760028

Epoch: 6| Step: 2
Training loss: 3.5268035170811123
Validation loss: 2.7119053579318195

Epoch: 6| Step: 3
Training loss: 2.1673750330749364
Validation loss: 2.7134293631445585

Epoch: 6| Step: 4
Training loss: 3.485737350374158
Validation loss: 2.7099888861716295

Epoch: 6| Step: 5
Training loss: 2.795938004544512
Validation loss: 2.7121476952251458

Epoch: 6| Step: 6
Training loss: 2.8732564863946424
Validation loss: 2.709984110775909

Epoch: 6| Step: 7
Training loss: 3.336907346303967
Validation loss: 2.711018495058105

Epoch: 6| Step: 8
Training loss: 2.9343532183633974
Validation loss: 2.7106117610069047

Epoch: 6| Step: 9
Training loss: 2.122283770327247
Validation loss: 2.7148866022245093

Epoch: 6| Step: 10
Training loss: 2.983464766294174
Validation loss: 2.7160694834141905

Epoch: 6| Step: 11
Training loss: 3.362316174782512
Validation loss: 2.725393737573807

Epoch: 6| Step: 12
Training loss: 2.9981946281282688
Validation loss: 2.733469824443172

Epoch: 6| Step: 13
Training loss: 3.5447837277231127
Validation loss: 2.7308940372866473

Epoch: 109| Step: 0
Training loss: 3.7477903849835825
Validation loss: 2.73344934502682

Epoch: 6| Step: 1
Training loss: 2.339462631341305
Validation loss: 2.7191881386173735

Epoch: 6| Step: 2
Training loss: 2.5075985826184968
Validation loss: 2.7137556547704547

Epoch: 6| Step: 3
Training loss: 3.171126253798372
Validation loss: 2.715750912214858

Epoch: 6| Step: 4
Training loss: 2.3727307772369706
Validation loss: 2.7192337365802315

Epoch: 6| Step: 5
Training loss: 3.3640341453225466
Validation loss: 2.719128469324878

Epoch: 6| Step: 6
Training loss: 3.0841525939713796
Validation loss: 2.7237957346464627

Epoch: 6| Step: 7
Training loss: 3.478344544150603
Validation loss: 2.7188560447242476

Epoch: 6| Step: 8
Training loss: 3.4402526931214363
Validation loss: 2.7136513644133995

Epoch: 6| Step: 9
Training loss: 2.955537325421218
Validation loss: 2.7069799024768044

Epoch: 6| Step: 10
Training loss: 3.0861045309325292
Validation loss: 2.7101670852855215

Epoch: 6| Step: 11
Training loss: 3.1088219538982993
Validation loss: 2.71038325581278

Epoch: 6| Step: 12
Training loss: 2.5458476797179355
Validation loss: 2.7118502797150543

Epoch: 6| Step: 13
Training loss: 2.8154854082567087
Validation loss: 2.709799029328565

Epoch: 110| Step: 0
Training loss: 2.656238331488617
Validation loss: 2.713024176426543

Epoch: 6| Step: 1
Training loss: 3.2566252450121116
Validation loss: 2.710754138674442

Epoch: 6| Step: 2
Training loss: 3.5990472645497973
Validation loss: 2.709800628174586

Epoch: 6| Step: 3
Training loss: 3.3217968304427137
Validation loss: 2.709201956161197

Epoch: 6| Step: 4
Training loss: 2.505159299586054
Validation loss: 2.710980391274636

Epoch: 6| Step: 5
Training loss: 3.0405916029849482
Validation loss: 2.7086119086510436

Epoch: 6| Step: 6
Training loss: 3.275651788279933
Validation loss: 2.7103673511455444

Epoch: 6| Step: 7
Training loss: 2.714123878817146
Validation loss: 2.7071962394332334

Epoch: 6| Step: 8
Training loss: 3.0086535578359803
Validation loss: 2.7075258614719004

Epoch: 6| Step: 9
Training loss: 3.669063189524092
Validation loss: 2.708421234017007

Epoch: 6| Step: 10
Training loss: 2.5221543016778667
Validation loss: 2.709725260007038

Epoch: 6| Step: 11
Training loss: 3.286318107470914
Validation loss: 2.7142142297141336

Epoch: 6| Step: 12
Training loss: 2.932632146461182
Validation loss: 2.710695678709827

Epoch: 6| Step: 13
Training loss: 2.0975384954436866
Validation loss: 2.7174122958467066

Epoch: 111| Step: 0
Training loss: 3.1040456522111177
Validation loss: 2.717681322066642

Epoch: 6| Step: 1
Training loss: 3.5286568091340293
Validation loss: 2.7177169698607546

Epoch: 6| Step: 2
Training loss: 3.191690570021346
Validation loss: 2.7144276620353076

Epoch: 6| Step: 3
Training loss: 2.740545058090376
Validation loss: 2.7162452506283814

Epoch: 6| Step: 4
Training loss: 2.9664477606886206
Validation loss: 2.709087231558904

Epoch: 6| Step: 5
Training loss: 3.1267856836610743
Validation loss: 2.7055331809228313

Epoch: 6| Step: 6
Training loss: 3.393182449233914
Validation loss: 2.704387638537598

Epoch: 6| Step: 7
Training loss: 2.7967444021752565
Validation loss: 2.702292654708505

Epoch: 6| Step: 8
Training loss: 3.167051961112992
Validation loss: 2.701304859359134

Epoch: 6| Step: 9
Training loss: 2.8232915049955745
Validation loss: 2.703415275075739

Epoch: 6| Step: 10
Training loss: 2.908379215727479
Validation loss: 2.700520255517844

Epoch: 6| Step: 11
Training loss: 2.8154318892529546
Validation loss: 2.7010614847141827

Epoch: 6| Step: 12
Training loss: 3.090433211590688
Validation loss: 2.7036382588709964

Epoch: 6| Step: 13
Training loss: 2.5425312468672607
Validation loss: 2.698601536055297

Epoch: 112| Step: 0
Training loss: 2.5177692254977955
Validation loss: 2.7001962942082205

Epoch: 6| Step: 1
Training loss: 3.151034587925718
Validation loss: 2.703276301421002

Epoch: 6| Step: 2
Training loss: 3.450558083771021
Validation loss: 2.702032649645466

Epoch: 6| Step: 3
Training loss: 2.4870406910474507
Validation loss: 2.707793414976453

Epoch: 6| Step: 4
Training loss: 3.608444556327403
Validation loss: 2.7022194697988047

Epoch: 6| Step: 5
Training loss: 2.6435184314215827
Validation loss: 2.7103614867784396

Epoch: 6| Step: 6
Training loss: 3.0445265889590956
Validation loss: 2.7227645181374553

Epoch: 6| Step: 7
Training loss: 2.8301150238601274
Validation loss: 2.734622958377385

Epoch: 6| Step: 8
Training loss: 3.6500402683492807
Validation loss: 2.7186078402295224

Epoch: 6| Step: 9
Training loss: 2.7337839414201515
Validation loss: 2.71487848320579

Epoch: 6| Step: 10
Training loss: 2.9496177555006096
Validation loss: 2.7033263224039996

Epoch: 6| Step: 11
Training loss: 3.3026385076269773
Validation loss: 2.705322070768871

Epoch: 6| Step: 12
Training loss: 2.5523956938082693
Validation loss: 2.7016955386144397

Epoch: 6| Step: 13
Training loss: 3.2403260552035134
Validation loss: 2.697228222274501

Epoch: 113| Step: 0
Training loss: 3.1885710767959656
Validation loss: 2.699951953680732

Epoch: 6| Step: 1
Training loss: 2.758709726458802
Validation loss: 2.697237845789083

Epoch: 6| Step: 2
Training loss: 3.6574625466254966
Validation loss: 2.7003533230530166

Epoch: 6| Step: 3
Training loss: 3.5587395346098756
Validation loss: 2.706203408512674

Epoch: 6| Step: 4
Training loss: 3.0953016917363985
Validation loss: 2.7008223054703517

Epoch: 6| Step: 5
Training loss: 2.877238853131375
Validation loss: 2.6980252370979807

Epoch: 6| Step: 6
Training loss: 3.258628834416888
Validation loss: 2.7080932744285335

Epoch: 6| Step: 7
Training loss: 2.4546822628594276
Validation loss: 2.7053261493594007

Epoch: 6| Step: 8
Training loss: 3.1892750603329003
Validation loss: 2.707387506935231

Epoch: 6| Step: 9
Training loss: 3.267563823844227
Validation loss: 2.7074387908616884

Epoch: 6| Step: 10
Training loss: 2.97880617819512
Validation loss: 2.7091394996288414

Epoch: 6| Step: 11
Training loss: 2.6074877098430247
Validation loss: 2.713112130808992

Epoch: 6| Step: 12
Training loss: 2.3350440520678952
Validation loss: 2.7196320378420262

Epoch: 6| Step: 13
Training loss: 2.6461790464724775
Validation loss: 2.7357623737249455

Epoch: 114| Step: 0
Training loss: 2.9808370180207655
Validation loss: 2.7755071293953835

Epoch: 6| Step: 1
Training loss: 3.1970800906384924
Validation loss: 2.8080639509841894

Epoch: 6| Step: 2
Training loss: 1.7991217457456887
Validation loss: 2.773537210222988

Epoch: 6| Step: 3
Training loss: 3.5321713486232738
Validation loss: 2.7214064622742997

Epoch: 6| Step: 4
Training loss: 2.7022931356947835
Validation loss: 2.707464894537449

Epoch: 6| Step: 5
Training loss: 3.3352514629127765
Validation loss: 2.694625092946497

Epoch: 6| Step: 6
Training loss: 3.0721225208049425
Validation loss: 2.6883980580550007

Epoch: 6| Step: 7
Training loss: 3.8654999721232524
Validation loss: 2.69341627715237

Epoch: 6| Step: 8
Training loss: 3.0015888774930097
Validation loss: 2.700197339527703

Epoch: 6| Step: 9
Training loss: 3.163786247344197
Validation loss: 2.707086029466814

Epoch: 6| Step: 10
Training loss: 2.66687811569486
Validation loss: 2.706392334473149

Epoch: 6| Step: 11
Training loss: 2.6790959453197107
Validation loss: 2.7043926664918367

Epoch: 6| Step: 12
Training loss: 3.3498090945834225
Validation loss: 2.699975906474979

Epoch: 6| Step: 13
Training loss: 2.540382582018878
Validation loss: 2.697257530878232

Epoch: 115| Step: 0
Training loss: 2.5591416099992
Validation loss: 2.698602377745046

Epoch: 6| Step: 1
Training loss: 3.6557489035458066
Validation loss: 2.694045233224094

Epoch: 6| Step: 2
Training loss: 3.435923544320652
Validation loss: 2.6932320808503407

Epoch: 6| Step: 3
Training loss: 2.3485379967217686
Validation loss: 2.692053261856166

Epoch: 6| Step: 4
Training loss: 3.0813714736609423
Validation loss: 2.690337016996789

Epoch: 6| Step: 5
Training loss: 3.4064694955082344
Validation loss: 2.6876306094278415

Epoch: 6| Step: 6
Training loss: 2.9255729570590434
Validation loss: 2.692507943552903

Epoch: 6| Step: 7
Training loss: 2.2032490147525996
Validation loss: 2.6948762511800624

Epoch: 6| Step: 8
Training loss: 2.5451438028294784
Validation loss: 2.706192674408371

Epoch: 6| Step: 9
Training loss: 2.7650826132437243
Validation loss: 2.709897548647741

Epoch: 6| Step: 10
Training loss: 3.2561188830667813
Validation loss: 2.718374067677463

Epoch: 6| Step: 11
Training loss: 2.978542040098032
Validation loss: 2.7016637369711005

Epoch: 6| Step: 12
Training loss: 3.266040830283376
Validation loss: 2.7115470775615074

Epoch: 6| Step: 13
Training loss: 3.9176619191840563
Validation loss: 2.7009617319020585

Epoch: 116| Step: 0
Training loss: 2.9515754630761855
Validation loss: 2.695564011699614

Epoch: 6| Step: 1
Training loss: 3.183336118793434
Validation loss: 2.684836584343569

Epoch: 6| Step: 2
Training loss: 3.3136234897335375
Validation loss: 2.6920479442112106

Epoch: 6| Step: 3
Training loss: 2.665787035186377
Validation loss: 2.6903077835608973

Epoch: 6| Step: 4
Training loss: 2.977796724205411
Validation loss: 2.688846751499057

Epoch: 6| Step: 5
Training loss: 3.0451912164390817
Validation loss: 2.689996857289625

Epoch: 6| Step: 6
Training loss: 3.242866904530318
Validation loss: 2.687484087256607

Epoch: 6| Step: 7
Training loss: 2.4501778946732937
Validation loss: 2.6884980691482006

Epoch: 6| Step: 8
Training loss: 3.3673867434435616
Validation loss: 2.6906484032252997

Epoch: 6| Step: 9
Training loss: 3.1618812106437786
Validation loss: 2.693877844323394

Epoch: 6| Step: 10
Training loss: 3.209514961793764
Validation loss: 2.690613402014746

Epoch: 6| Step: 11
Training loss: 2.7987313530025166
Validation loss: 2.702891390733712

Epoch: 6| Step: 12
Training loss: 2.963585788999496
Validation loss: 2.7049741909906735

Epoch: 6| Step: 13
Training loss: 2.855195372889674
Validation loss: 2.6902569821109115

Epoch: 117| Step: 0
Training loss: 3.2972949876891273
Validation loss: 2.6914664081578827

Epoch: 6| Step: 1
Training loss: 2.7636227013624417
Validation loss: 2.6877278228754427

Epoch: 6| Step: 2
Training loss: 3.1611335667187084
Validation loss: 2.6886878692547924

Epoch: 6| Step: 3
Training loss: 2.897968264535666
Validation loss: 2.6890750179876615

Epoch: 6| Step: 4
Training loss: 3.0052393620220794
Validation loss: 2.686556212298442

Epoch: 6| Step: 5
Training loss: 2.8623734891829105
Validation loss: 2.6896510271714273

Epoch: 6| Step: 6
Training loss: 2.8032755153225892
Validation loss: 2.691880893008124

Epoch: 6| Step: 7
Training loss: 3.3885471991654006
Validation loss: 2.6859690661999425

Epoch: 6| Step: 8
Training loss: 3.1155571749391697
Validation loss: 2.678117041050053

Epoch: 6| Step: 9
Training loss: 3.0111602779971043
Validation loss: 2.6832936262651277

Epoch: 6| Step: 10
Training loss: 3.110623056488932
Validation loss: 2.678374906402412

Epoch: 6| Step: 11
Training loss: 2.6898311883930566
Validation loss: 2.682960367801445

Epoch: 6| Step: 12
Training loss: 3.1943508650484285
Validation loss: 2.6799765418141317

Epoch: 6| Step: 13
Training loss: 2.732934103474565
Validation loss: 2.6829618278460554

Epoch: 118| Step: 0
Training loss: 3.247561053141923
Validation loss: 2.6821507462398944

Epoch: 6| Step: 1
Training loss: 3.502319112568095
Validation loss: 2.679826616899705

Epoch: 6| Step: 2
Training loss: 2.7255573332709444
Validation loss: 2.680242020847742

Epoch: 6| Step: 3
Training loss: 2.674308783809545
Validation loss: 2.6806676440109776

Epoch: 6| Step: 4
Training loss: 2.9672587614657266
Validation loss: 2.6784549699537394

Epoch: 6| Step: 5
Training loss: 2.4340860961757684
Validation loss: 2.6774894630058808

Epoch: 6| Step: 6
Training loss: 2.6139967869663705
Validation loss: 2.6792565244974753

Epoch: 6| Step: 7
Training loss: 2.972872311413368
Validation loss: 2.6839445337776042

Epoch: 6| Step: 8
Training loss: 3.4182139978978503
Validation loss: 2.677861991313739

Epoch: 6| Step: 9
Training loss: 3.483078788205721
Validation loss: 2.677568542922764

Epoch: 6| Step: 10
Training loss: 3.5545715983852224
Validation loss: 2.681733729852376

Epoch: 6| Step: 11
Training loss: 2.420490385922552
Validation loss: 2.6841470779894245

Epoch: 6| Step: 12
Training loss: 3.2471380103375203
Validation loss: 2.684601642441628

Epoch: 6| Step: 13
Training loss: 2.1057722053466628
Validation loss: 2.681690894679837

Epoch: 119| Step: 0
Training loss: 3.056936855403992
Validation loss: 2.6874903034589503

Epoch: 6| Step: 1
Training loss: 3.4740222351205965
Validation loss: 2.6949593679906934

Epoch: 6| Step: 2
Training loss: 3.1413719086191816
Validation loss: 2.7054053679379466

Epoch: 6| Step: 3
Training loss: 3.0204822380100627
Validation loss: 2.699021249219545

Epoch: 6| Step: 4
Training loss: 3.12595108817916
Validation loss: 2.722372810319168

Epoch: 6| Step: 5
Training loss: 3.381085031825086
Validation loss: 2.7310046213342023

Epoch: 6| Step: 6
Training loss: 2.497190040698792
Validation loss: 2.713733070124118

Epoch: 6| Step: 7
Training loss: 2.45690335424535
Validation loss: 2.710130717642467

Epoch: 6| Step: 8
Training loss: 1.7707737482555432
Validation loss: 2.6969164312894147

Epoch: 6| Step: 9
Training loss: 2.954241183425726
Validation loss: 2.6953831940865105

Epoch: 6| Step: 10
Training loss: 3.2594666158175185
Validation loss: 2.6888146243609516

Epoch: 6| Step: 11
Training loss: 3.082419406056941
Validation loss: 2.700054544758526

Epoch: 6| Step: 12
Training loss: 3.227324979898818
Validation loss: 2.724320606270914

Epoch: 6| Step: 13
Training loss: 3.528308284516241
Validation loss: 2.726104975313869

Epoch: 120| Step: 0
Training loss: 3.075744327927204
Validation loss: 2.7392414269103393

Epoch: 6| Step: 1
Training loss: 2.68155865082055
Validation loss: 2.7556052540900775

Epoch: 6| Step: 2
Training loss: 3.2665122255160473
Validation loss: 2.7626926618121175

Epoch: 6| Step: 3
Training loss: 3.2218130407286485
Validation loss: 2.7641083827775774

Epoch: 6| Step: 4
Training loss: 3.2114404437597655
Validation loss: 2.7566412208985662

Epoch: 6| Step: 5
Training loss: 3.20525308023401
Validation loss: 2.7487041836108204

Epoch: 6| Step: 6
Training loss: 3.032161143114749
Validation loss: 2.75191862124474

Epoch: 6| Step: 7
Training loss: 2.8505205314845634
Validation loss: 2.7469660690479736

Epoch: 6| Step: 8
Training loss: 2.958970999608796
Validation loss: 2.7465254703144186

Epoch: 6| Step: 9
Training loss: 3.275884983377226
Validation loss: 2.7421109100276535

Epoch: 6| Step: 10
Training loss: 2.3902959659506786
Validation loss: 2.734201299303855

Epoch: 6| Step: 11
Training loss: 3.4995377099046143
Validation loss: 2.734717433131432

Epoch: 6| Step: 12
Training loss: 3.17207162933482
Validation loss: 2.732243433745345

Epoch: 6| Step: 13
Training loss: 2.637427295568619
Validation loss: 2.732502534395287

Epoch: 121| Step: 0
Training loss: 3.153511294396568
Validation loss: 2.735156192787683

Epoch: 6| Step: 1
Training loss: 3.44235496996719
Validation loss: 2.7439651684822044

Epoch: 6| Step: 2
Training loss: 2.832334641615416
Validation loss: 2.73198363570351

Epoch: 6| Step: 3
Training loss: 2.5665280387234164
Validation loss: 2.7269582416849367

Epoch: 6| Step: 4
Training loss: 2.5765136306967715
Validation loss: 2.7255318421360073

Epoch: 6| Step: 5
Training loss: 2.9094184913211785
Validation loss: 2.7257912779126796

Epoch: 6| Step: 6
Training loss: 3.1163869035244156
Validation loss: 2.7243320283497727

Epoch: 6| Step: 7
Training loss: 2.8674312976432583
Validation loss: 2.7234922611996817

Epoch: 6| Step: 8
Training loss: 3.299612057164176
Validation loss: 2.7206947425410624

Epoch: 6| Step: 9
Training loss: 3.1264437582867965
Validation loss: 2.7220171132338886

Epoch: 6| Step: 10
Training loss: 3.084521777710115
Validation loss: 2.7244665376521677

Epoch: 6| Step: 11
Training loss: 3.1137599983805186
Validation loss: 2.72584227202077

Epoch: 6| Step: 12
Training loss: 3.272409063580948
Validation loss: 2.716555641357146

Epoch: 6| Step: 13
Training loss: 3.2505621790669483
Validation loss: 2.7011688398257356

Epoch: 122| Step: 0
Training loss: 3.2667786235178595
Validation loss: 2.675418488508524

Epoch: 6| Step: 1
Training loss: 2.9231469960636094
Validation loss: 2.672213870334161

Epoch: 6| Step: 2
Training loss: 2.269124557640492
Validation loss: 2.6728533349913683

Epoch: 6| Step: 3
Training loss: 3.5543230142375317
Validation loss: 2.681052529571631

Epoch: 6| Step: 4
Training loss: 3.2572924155362624
Validation loss: 2.6953633383720614

Epoch: 6| Step: 5
Training loss: 3.253336147817843
Validation loss: 2.687700442036389

Epoch: 6| Step: 6
Training loss: 2.959394309475349
Validation loss: 2.702296497852885

Epoch: 6| Step: 7
Training loss: 2.349718555884963
Validation loss: 2.682422461199532

Epoch: 6| Step: 8
Training loss: 3.07572913480582
Validation loss: 2.673249345604523

Epoch: 6| Step: 9
Training loss: 3.058734681060306
Validation loss: 2.668225836882627

Epoch: 6| Step: 10
Training loss: 2.7419897806991362
Validation loss: 2.6673507079071617

Epoch: 6| Step: 11
Training loss: 3.1989191494902753
Validation loss: 2.6674842106809833

Epoch: 6| Step: 12
Training loss: 3.0293963555554653
Validation loss: 2.6703145420696424

Epoch: 6| Step: 13
Training loss: 2.9111903049610515
Validation loss: 2.668313233977887

Epoch: 123| Step: 0
Training loss: 3.4064927320874543
Validation loss: 2.6818061182857535

Epoch: 6| Step: 1
Training loss: 2.521021581089082
Validation loss: 2.698353204264916

Epoch: 6| Step: 2
Training loss: 3.3356476061467553
Validation loss: 2.721983621091221

Epoch: 6| Step: 3
Training loss: 3.2947528390991567
Validation loss: 2.7216109028960336

Epoch: 6| Step: 4
Training loss: 2.9548615693329694
Validation loss: 2.735705750742508

Epoch: 6| Step: 5
Training loss: 3.1959162283984273
Validation loss: 2.7286704265971573

Epoch: 6| Step: 6
Training loss: 3.1626184252854594
Validation loss: 2.6876509438756373

Epoch: 6| Step: 7
Training loss: 3.1035317575984886
Validation loss: 2.6720621354949703

Epoch: 6| Step: 8
Training loss: 2.785935559060816
Validation loss: 2.662383617742443

Epoch: 6| Step: 9
Training loss: 2.8869992172826824
Validation loss: 2.6653006131718042

Epoch: 6| Step: 10
Training loss: 2.6716628854891016
Validation loss: 2.6646124621225185

Epoch: 6| Step: 11
Training loss: 2.916061901790784
Validation loss: 2.6681583780184335

Epoch: 6| Step: 12
Training loss: 2.9050641665701034
Validation loss: 2.677465208988838

Epoch: 6| Step: 13
Training loss: 2.495410903394915
Validation loss: 2.6787654079861025

Epoch: 124| Step: 0
Training loss: 2.7052521026521372
Validation loss: 2.676107307618029

Epoch: 6| Step: 1
Training loss: 2.813844486583744
Validation loss: 2.675537103985249

Epoch: 6| Step: 2
Training loss: 3.0118827725682418
Validation loss: 2.6713494176879613

Epoch: 6| Step: 3
Training loss: 3.0888974444257897
Validation loss: 2.668308175508526

Epoch: 6| Step: 4
Training loss: 2.6716472684838592
Validation loss: 2.6652802957684782

Epoch: 6| Step: 5
Training loss: 3.393490753669333
Validation loss: 2.665232492558032

Epoch: 6| Step: 6
Training loss: 3.637356973569384
Validation loss: 2.6655686550818767

Epoch: 6| Step: 7
Training loss: 2.6897193261673884
Validation loss: 2.663580972954641

Epoch: 6| Step: 8
Training loss: 3.007452767398405
Validation loss: 2.664181613373333

Epoch: 6| Step: 9
Training loss: 2.907160298518425
Validation loss: 2.665785006035613

Epoch: 6| Step: 10
Training loss: 2.6312338060619176
Validation loss: 2.673846604661575

Epoch: 6| Step: 11
Training loss: 3.4047529097878724
Validation loss: 2.6750054133110024

Epoch: 6| Step: 12
Training loss: 2.613352776020412
Validation loss: 2.681053335653835

Epoch: 6| Step: 13
Training loss: 3.713891839009035
Validation loss: 2.675528460248074

Epoch: 125| Step: 0
Training loss: 2.8563808753415727
Validation loss: 2.669747363797804

Epoch: 6| Step: 1
Training loss: 3.1639466064326895
Validation loss: 2.6646547838837322

Epoch: 6| Step: 2
Training loss: 2.7230197220563355
Validation loss: 2.667309976346929

Epoch: 6| Step: 3
Training loss: 3.028529253766252
Validation loss: 2.667469039177438

Epoch: 6| Step: 4
Training loss: 2.9503435225826022
Validation loss: 2.660436036371083

Epoch: 6| Step: 5
Training loss: 2.7307359294576004
Validation loss: 2.662721431994475

Epoch: 6| Step: 6
Training loss: 2.936860684564726
Validation loss: 2.666221734070521

Epoch: 6| Step: 7
Training loss: 2.8330692467378067
Validation loss: 2.665788643118966

Epoch: 6| Step: 8
Training loss: 3.447680569927536
Validation loss: 2.6659667483469667

Epoch: 6| Step: 9
Training loss: 2.9625753336796437
Validation loss: 2.6692497406653146

Epoch: 6| Step: 10
Training loss: 3.1217246629412756
Validation loss: 2.6646000605424907

Epoch: 6| Step: 11
Training loss: 3.175644011775622
Validation loss: 2.6623234225558035

Epoch: 6| Step: 12
Training loss: 2.7037338717716346
Validation loss: 2.6648624652811397

Epoch: 6| Step: 13
Training loss: 3.364890888593369
Validation loss: 2.660679640050986

Epoch: 126| Step: 0
Training loss: 3.322510761275133
Validation loss: 2.666444769851131

Epoch: 6| Step: 1
Training loss: 2.4766836046518477
Validation loss: 2.667842384372251

Epoch: 6| Step: 2
Training loss: 3.318886125147161
Validation loss: 2.663988898048473

Epoch: 6| Step: 3
Training loss: 3.015546254132977
Validation loss: 2.6622120868097596

Epoch: 6| Step: 4
Training loss: 2.7609903759040813
Validation loss: 2.6620047533541653

Epoch: 6| Step: 5
Training loss: 3.0543818406258127
Validation loss: 2.6662526988633446

Epoch: 6| Step: 6
Training loss: 2.9716406953467995
Validation loss: 2.6723296642104857

Epoch: 6| Step: 7
Training loss: 3.0995686077088282
Validation loss: 2.677282763979096

Epoch: 6| Step: 8
Training loss: 3.387047352408297
Validation loss: 2.66734634250247

Epoch: 6| Step: 9
Training loss: 2.804259711238631
Validation loss: 2.6707219474305455

Epoch: 6| Step: 10
Training loss: 3.44214579746995
Validation loss: 2.666716693080782

Epoch: 6| Step: 11
Training loss: 2.7049820535173748
Validation loss: 2.6627956023505193

Epoch: 6| Step: 12
Training loss: 2.4484344151324695
Validation loss: 2.6691794829665527

Epoch: 6| Step: 13
Training loss: 2.764918263970783
Validation loss: 2.6693536605810055

Epoch: 127| Step: 0
Training loss: 2.8356975527472494
Validation loss: 2.6584763512136393

Epoch: 6| Step: 1
Training loss: 3.394531530944321
Validation loss: 2.663189076592233

Epoch: 6| Step: 2
Training loss: 3.0222984356557974
Validation loss: 2.656556241009679

Epoch: 6| Step: 3
Training loss: 3.3579444855763905
Validation loss: 2.6625036140712774

Epoch: 6| Step: 4
Training loss: 3.0513212187697882
Validation loss: 2.6629101542221236

Epoch: 6| Step: 5
Training loss: 3.0804371161968658
Validation loss: 2.658806475793897

Epoch: 6| Step: 6
Training loss: 3.0918024271507316
Validation loss: 2.665644842795591

Epoch: 6| Step: 7
Training loss: 3.077180204285013
Validation loss: 2.6617543642842425

Epoch: 6| Step: 8
Training loss: 3.411828468957212
Validation loss: 2.6598887758782173

Epoch: 6| Step: 9
Training loss: 1.7406052730408108
Validation loss: 2.6654002213218226

Epoch: 6| Step: 10
Training loss: 2.345550862499421
Validation loss: 2.654155214526813

Epoch: 6| Step: 11
Training loss: 3.333986091278117
Validation loss: 2.658056039190101

Epoch: 6| Step: 12
Training loss: 2.249739207942481
Validation loss: 2.655523041688456

Epoch: 6| Step: 13
Training loss: 3.6952269465601804
Validation loss: 2.6520139654805197

Epoch: 128| Step: 0
Training loss: 3.049803123998959
Validation loss: 2.661385919644445

Epoch: 6| Step: 1
Training loss: 2.954812511298934
Validation loss: 2.656606838668281

Epoch: 6| Step: 2
Training loss: 2.9888170347908645
Validation loss: 2.6599081966790754

Epoch: 6| Step: 3
Training loss: 2.5951951378749736
Validation loss: 2.6549833922471873

Epoch: 6| Step: 4
Training loss: 2.593740899862848
Validation loss: 2.6553279987248755

Epoch: 6| Step: 5
Training loss: 2.4373663841207573
Validation loss: 2.6574336952335527

Epoch: 6| Step: 6
Training loss: 3.0227289675683715
Validation loss: 2.657229135568613

Epoch: 6| Step: 7
Training loss: 3.9902423815616563
Validation loss: 2.651268491432244

Epoch: 6| Step: 8
Training loss: 2.7786956372694145
Validation loss: 2.6548947780479253

Epoch: 6| Step: 9
Training loss: 3.1080592453070883
Validation loss: 2.6585046318823706

Epoch: 6| Step: 10
Training loss: 2.966055038353056
Validation loss: 2.6538626165978356

Epoch: 6| Step: 11
Training loss: 3.2168914466023923
Validation loss: 2.6592528875141275

Epoch: 6| Step: 12
Training loss: 2.7512654947332447
Validation loss: 2.6631200346234625

Epoch: 6| Step: 13
Training loss: 3.2221253113770727
Validation loss: 2.668283484467918

Epoch: 129| Step: 0
Training loss: 3.274519784678582
Validation loss: 2.6720244490531173

Epoch: 6| Step: 1
Training loss: 3.38892458982024
Validation loss: 2.678543945577784

Epoch: 6| Step: 2
Training loss: 2.6729016032776896
Validation loss: 2.6685604944890575

Epoch: 6| Step: 3
Training loss: 3.075609602630901
Validation loss: 2.6590980659850874

Epoch: 6| Step: 4
Training loss: 2.720018463633084
Validation loss: 2.6558331041160828

Epoch: 6| Step: 5
Training loss: 3.013171527141716
Validation loss: 2.6521525040617306

Epoch: 6| Step: 6
Training loss: 3.316610700687826
Validation loss: 2.6466023160365992

Epoch: 6| Step: 7
Training loss: 3.5488024612531737
Validation loss: 2.652964417493639

Epoch: 6| Step: 8
Training loss: 2.7368667148726895
Validation loss: 2.6481676795796565

Epoch: 6| Step: 9
Training loss: 3.2748303784422728
Validation loss: 2.645116302079898

Epoch: 6| Step: 10
Training loss: 2.837110208634395
Validation loss: 2.646948714861284

Epoch: 6| Step: 11
Training loss: 2.7779215923803693
Validation loss: 2.648317943742977

Epoch: 6| Step: 12
Training loss: 2.20180780521007
Validation loss: 2.649170185456274

Epoch: 6| Step: 13
Training loss: 2.3417763092690573
Validation loss: 2.6468369803515546

Epoch: 130| Step: 0
Training loss: 3.0068373647589177
Validation loss: 2.6499870680363657

Epoch: 6| Step: 1
Training loss: 3.044857981209045
Validation loss: 2.6516236883327404

Epoch: 6| Step: 2
Training loss: 2.4884167309442486
Validation loss: 2.64604026780374

Epoch: 6| Step: 3
Training loss: 2.9854303061969443
Validation loss: 2.6501281841942697

Epoch: 6| Step: 4
Training loss: 3.1592320622107506
Validation loss: 2.652872687944145

Epoch: 6| Step: 5
Training loss: 3.4379413668174745
Validation loss: 2.6463407143514104

Epoch: 6| Step: 6
Training loss: 2.8298752569197396
Validation loss: 2.650072983850998

Epoch: 6| Step: 7
Training loss: 3.1093145776753333
Validation loss: 2.645431562335153

Epoch: 6| Step: 8
Training loss: 2.9513140580408335
Validation loss: 2.6461016026665174

Epoch: 6| Step: 9
Training loss: 3.0592263299591025
Validation loss: 2.6464259648515283

Epoch: 6| Step: 10
Training loss: 2.8855701685722193
Validation loss: 2.642022121697983

Epoch: 6| Step: 11
Training loss: 2.736301027173329
Validation loss: 2.650109547846491

Epoch: 6| Step: 12
Training loss: 3.206538321635604
Validation loss: 2.6481354316393797

Epoch: 6| Step: 13
Training loss: 2.669933037221775
Validation loss: 2.643997282675182

Epoch: 131| Step: 0
Training loss: 2.5524079304528735
Validation loss: 2.6512619272928313

Epoch: 6| Step: 1
Training loss: 2.444658965995456
Validation loss: 2.648194982225438

Epoch: 6| Step: 2
Training loss: 2.745351156484742
Validation loss: 2.645562185576187

Epoch: 6| Step: 3
Training loss: 2.813650955361805
Validation loss: 2.6427212083049962

Epoch: 6| Step: 4
Training loss: 2.708416736981384
Validation loss: 2.65280661488261

Epoch: 6| Step: 5
Training loss: 3.2294253009875
Validation loss: 2.650871031701363

Epoch: 6| Step: 6
Training loss: 2.988474641413751
Validation loss: 2.6481682091198735

Epoch: 6| Step: 7
Training loss: 3.0451669453674772
Validation loss: 2.6456875213863347

Epoch: 6| Step: 8
Training loss: 3.2679011976978494
Validation loss: 2.6445636698506823

Epoch: 6| Step: 9
Training loss: 2.8645063540201265
Validation loss: 2.642855453724269

Epoch: 6| Step: 10
Training loss: 2.920943330950971
Validation loss: 2.64256411048498

Epoch: 6| Step: 11
Training loss: 3.1179473639175113
Validation loss: 2.6392015723823437

Epoch: 6| Step: 12
Training loss: 3.2865782573279048
Validation loss: 2.6457741669142174

Epoch: 6| Step: 13
Training loss: 4.0357468238415874
Validation loss: 2.6353480579674433

Epoch: 132| Step: 0
Training loss: 3.073316351980874
Validation loss: 2.6422364517499233

Epoch: 6| Step: 1
Training loss: 2.8880171275595212
Validation loss: 2.637136473508504

Epoch: 6| Step: 2
Training loss: 2.161756147220395
Validation loss: 2.6434183604743904

Epoch: 6| Step: 3
Training loss: 3.21729905100439
Validation loss: 2.647277851119447

Epoch: 6| Step: 4
Training loss: 3.097366839018139
Validation loss: 2.6491793806643344

Epoch: 6| Step: 5
Training loss: 2.9409249001791347
Validation loss: 2.6447673698315763

Epoch: 6| Step: 6
Training loss: 3.0020519232888145
Validation loss: 2.648302517235653

Epoch: 6| Step: 7
Training loss: 3.6810830096207097
Validation loss: 2.657843782527872

Epoch: 6| Step: 8
Training loss: 3.214510449621388
Validation loss: 2.6500052321822154

Epoch: 6| Step: 9
Training loss: 2.6673378596414827
Validation loss: 2.6486446575351152

Epoch: 6| Step: 10
Training loss: 2.8788307211089683
Validation loss: 2.638637984660025

Epoch: 6| Step: 11
Training loss: 2.7996452719919387
Validation loss: 2.6378404994421367

Epoch: 6| Step: 12
Training loss: 2.9804036344562097
Validation loss: 2.636980532370694

Epoch: 6| Step: 13
Training loss: 2.7218883422104105
Validation loss: 2.6367650488066636

Epoch: 133| Step: 0
Training loss: 3.5021385743736944
Validation loss: 2.6360794207449807

Epoch: 6| Step: 1
Training loss: 2.779464234107073
Validation loss: 2.635031655514439

Epoch: 6| Step: 2
Training loss: 3.056571516041825
Validation loss: 2.635787218619054

Epoch: 6| Step: 3
Training loss: 2.9769780226906293
Validation loss: 2.6335477676509846

Epoch: 6| Step: 4
Training loss: 2.557630797441356
Validation loss: 2.6369010431434

Epoch: 6| Step: 5
Training loss: 2.9603853943954004
Validation loss: 2.634125238243267

Epoch: 6| Step: 6
Training loss: 3.349673292256419
Validation loss: 2.6364930186690825

Epoch: 6| Step: 7
Training loss: 2.7059070184807856
Validation loss: 2.6426026225740356

Epoch: 6| Step: 8
Training loss: 3.2406428690668747
Validation loss: 2.6393520983495473

Epoch: 6| Step: 9
Training loss: 3.0716217588583703
Validation loss: 2.645799935223512

Epoch: 6| Step: 10
Training loss: 2.5194971836359747
Validation loss: 2.6486013007721745

Epoch: 6| Step: 11
Training loss: 3.381852575399442
Validation loss: 2.6378634043979865

Epoch: 6| Step: 12
Training loss: 2.5915345071375318
Validation loss: 2.641546814805935

Epoch: 6| Step: 13
Training loss: 2.5476781596739295
Validation loss: 2.635836469126507

Epoch: 134| Step: 0
Training loss: 3.150143447516192
Validation loss: 2.6365594198503333

Epoch: 6| Step: 1
Training loss: 3.1308538921115434
Validation loss: 2.629664215530155

Epoch: 6| Step: 2
Training loss: 2.7842475082716507
Validation loss: 2.6318546788924646

Epoch: 6| Step: 3
Training loss: 2.9336187816217345
Validation loss: 2.636268763152766

Epoch: 6| Step: 4
Training loss: 2.786325602474806
Validation loss: 2.6324006805882165

Epoch: 6| Step: 5
Training loss: 3.2618088030233268
Validation loss: 2.631014709420562

Epoch: 6| Step: 6
Training loss: 3.29523908335269
Validation loss: 2.631625875738408

Epoch: 6| Step: 7
Training loss: 3.001264146853291
Validation loss: 2.6342455714832775

Epoch: 6| Step: 8
Training loss: 3.0346050768447794
Validation loss: 2.636524606816743

Epoch: 6| Step: 9
Training loss: 3.2520169088620836
Validation loss: 2.636594575656857

Epoch: 6| Step: 10
Training loss: 2.991574695274993
Validation loss: 2.631821499523382

Epoch: 6| Step: 11
Training loss: 2.6237502074729977
Validation loss: 2.6354002923897353

Epoch: 6| Step: 12
Training loss: 2.3837038467972147
Validation loss: 2.643170914775153

Epoch: 6| Step: 13
Training loss: 2.665421393825944
Validation loss: 2.6607985618607057

Epoch: 135| Step: 0
Training loss: 3.4188879902274776
Validation loss: 2.666783381863768

Epoch: 6| Step: 1
Training loss: 3.0636627169891333
Validation loss: 2.6888604723473106

Epoch: 6| Step: 2
Training loss: 2.742915304169038
Validation loss: 2.666115372787199

Epoch: 6| Step: 3
Training loss: 3.0734828276557087
Validation loss: 2.651127192770902

Epoch: 6| Step: 4
Training loss: 2.702563277076332
Validation loss: 2.6391324580322535

Epoch: 6| Step: 5
Training loss: 3.1543212133832705
Validation loss: 2.6326385914814923

Epoch: 6| Step: 6
Training loss: 3.3770772404805
Validation loss: 2.6344103276580055

Epoch: 6| Step: 7
Training loss: 3.112497420099254
Validation loss: 2.633453898618384

Epoch: 6| Step: 8
Training loss: 2.718291583821366
Validation loss: 2.630845245438614

Epoch: 6| Step: 9
Training loss: 3.0208790918151163
Validation loss: 2.633243473301222

Epoch: 6| Step: 10
Training loss: 2.990737284721877
Validation loss: 2.6357794103493424

Epoch: 6| Step: 11
Training loss: 3.1256630766253584
Validation loss: 2.635893614201523

Epoch: 6| Step: 12
Training loss: 2.6532459101180397
Validation loss: 2.634366566322858

Epoch: 6| Step: 13
Training loss: 2.0618693225570826
Validation loss: 2.6381452323957775

Epoch: 136| Step: 0
Training loss: 3.1415948841046517
Validation loss: 2.6359387497166153

Epoch: 6| Step: 1
Training loss: 2.9555078006254876
Validation loss: 2.6442340231750006

Epoch: 6| Step: 2
Training loss: 3.120430619282515
Validation loss: 2.63938944123786

Epoch: 6| Step: 3
Training loss: 2.594226563576374
Validation loss: 2.6480357772038676

Epoch: 6| Step: 4
Training loss: 2.7331746109569166
Validation loss: 2.65107834236964

Epoch: 6| Step: 5
Training loss: 2.8353296053990693
Validation loss: 2.6552038015675326

Epoch: 6| Step: 6
Training loss: 2.476801334260734
Validation loss: 2.666195558328754

Epoch: 6| Step: 7
Training loss: 3.2479796365372047
Validation loss: 2.676616769932755

Epoch: 6| Step: 8
Training loss: 3.3252556838774336
Validation loss: 2.673598379371081

Epoch: 6| Step: 9
Training loss: 3.5761681415532123
Validation loss: 2.6435529050617177

Epoch: 6| Step: 10
Training loss: 2.9172172753275896
Validation loss: 2.633545664987023

Epoch: 6| Step: 11
Training loss: 3.134747067215318
Validation loss: 2.6269095585605466

Epoch: 6| Step: 12
Training loss: 2.5727912985545425
Validation loss: 2.627495284331662

Epoch: 6| Step: 13
Training loss: 2.6174513954233354
Validation loss: 2.6313838164852315

Epoch: 137| Step: 0
Training loss: 2.4128541360362235
Validation loss: 2.630626340578595

Epoch: 6| Step: 1
Training loss: 3.194368628740161
Validation loss: 2.634033547056295

Epoch: 6| Step: 2
Training loss: 2.973059167010787
Validation loss: 2.6368189716623736

Epoch: 6| Step: 3
Training loss: 2.712376545149025
Validation loss: 2.6291091329424083

Epoch: 6| Step: 4
Training loss: 3.267090828923499
Validation loss: 2.6329881486504743

Epoch: 6| Step: 5
Training loss: 2.86631657732281
Validation loss: 2.628510295696768

Epoch: 6| Step: 6
Training loss: 3.396741562286833
Validation loss: 2.6310777830308623

Epoch: 6| Step: 7
Training loss: 2.722263915419538
Validation loss: 2.6334772895285705

Epoch: 6| Step: 8
Training loss: 2.7006105403782312
Validation loss: 2.6345735779119446

Epoch: 6| Step: 9
Training loss: 3.267590383083702
Validation loss: 2.629209117651677

Epoch: 6| Step: 10
Training loss: 3.3510489970751456
Validation loss: 2.6264549848322614

Epoch: 6| Step: 11
Training loss: 2.766925139781793
Validation loss: 2.631756419521341

Epoch: 6| Step: 12
Training loss: 2.5606107492867385
Validation loss: 2.634412069571622

Epoch: 6| Step: 13
Training loss: 3.1895271288012093
Validation loss: 2.6402634903957134

Epoch: 138| Step: 0
Training loss: 2.106472137237926
Validation loss: 2.644255742297118

Epoch: 6| Step: 1
Training loss: 3.1736503856481586
Validation loss: 2.648224831556924

Epoch: 6| Step: 2
Training loss: 3.467641567428954
Validation loss: 2.6297437421803647

Epoch: 6| Step: 3
Training loss: 2.580254802098041
Validation loss: 2.6313130309865524

Epoch: 6| Step: 4
Training loss: 2.2181368773167383
Validation loss: 2.6285721342062534

Epoch: 6| Step: 5
Training loss: 3.174086978626796
Validation loss: 2.624995392279187

Epoch: 6| Step: 6
Training loss: 3.704479372251058
Validation loss: 2.6300227059614283

Epoch: 6| Step: 7
Training loss: 3.379480425610203
Validation loss: 2.6291874126926777

Epoch: 6| Step: 8
Training loss: 2.568507711674076
Validation loss: 2.624929833438807

Epoch: 6| Step: 9
Training loss: 2.9450644634037326
Validation loss: 2.6263283846649235

Epoch: 6| Step: 10
Training loss: 2.861902006229724
Validation loss: 2.6297310055606418

Epoch: 6| Step: 11
Training loss: 2.882221275015056
Validation loss: 2.6295840137783744

Epoch: 6| Step: 12
Training loss: 3.1092012443109103
Validation loss: 2.6250827578982925

Epoch: 6| Step: 13
Training loss: 2.808508944656936
Validation loss: 2.629195646167221

Epoch: 139| Step: 0
Training loss: 2.7042297575359546
Validation loss: 2.6309592210880246

Epoch: 6| Step: 1
Training loss: 2.3319331009496578
Validation loss: 2.6200947927544873

Epoch: 6| Step: 2
Training loss: 3.0791382646777863
Validation loss: 2.623408163544365

Epoch: 6| Step: 3
Training loss: 2.9356862413898632
Validation loss: 2.629193998791828

Epoch: 6| Step: 4
Training loss: 2.996439728536673
Validation loss: 2.6246588602984393

Epoch: 6| Step: 5
Training loss: 2.7140288303111766
Validation loss: 2.6253869132418206

Epoch: 6| Step: 6
Training loss: 3.0518953094025396
Validation loss: 2.6301630052583618

Epoch: 6| Step: 7
Training loss: 3.352877130083725
Validation loss: 2.635450790387338

Epoch: 6| Step: 8
Training loss: 2.158971313194103
Validation loss: 2.635963990760955

Epoch: 6| Step: 9
Training loss: 2.8513782180394047
Validation loss: 2.6353035835720386

Epoch: 6| Step: 10
Training loss: 2.835158900629961
Validation loss: 2.632848142062108

Epoch: 6| Step: 11
Training loss: 2.7191470502994766
Validation loss: 2.622906324078573

Epoch: 6| Step: 12
Training loss: 3.905349261384128
Validation loss: 2.622776705300598

Epoch: 6| Step: 13
Training loss: 3.743312085352645
Validation loss: 2.631554032932642

Epoch: 140| Step: 0
Training loss: 2.760075923594115
Validation loss: 2.630908274390069

Epoch: 6| Step: 1
Training loss: 3.2871543441479862
Validation loss: 2.6313133865994187

Epoch: 6| Step: 2
Training loss: 2.9963023922524696
Validation loss: 2.625015672831276

Epoch: 6| Step: 3
Training loss: 2.861027474605796
Validation loss: 2.6285984281035937

Epoch: 6| Step: 4
Training loss: 3.2231507078058717
Validation loss: 2.622721310506183

Epoch: 6| Step: 5
Training loss: 2.865968200698848
Validation loss: 2.6295453217442333

Epoch: 6| Step: 6
Training loss: 3.253524336549599
Validation loss: 2.6285399696631173

Epoch: 6| Step: 7
Training loss: 3.244011864354725
Validation loss: 2.623991622654693

Epoch: 6| Step: 8
Training loss: 3.151574779632203
Validation loss: 2.626787022733709

Epoch: 6| Step: 9
Training loss: 2.0452116985849678
Validation loss: 2.6156563254451717

Epoch: 6| Step: 10
Training loss: 2.613289096062119
Validation loss: 2.619564070892851

Epoch: 6| Step: 11
Training loss: 2.928974034218713
Validation loss: 2.618247584790048

Epoch: 6| Step: 12
Training loss: 3.11073066640792
Validation loss: 2.618596822057242

Epoch: 6| Step: 13
Training loss: 2.71013468967196
Validation loss: 2.628263882037998

Epoch: 141| Step: 0
Training loss: 3.1522237951057903
Validation loss: 2.620612197721485

Epoch: 6| Step: 1
Training loss: 3.6178354955823657
Validation loss: 2.6188242251820117

Epoch: 6| Step: 2
Training loss: 3.3585964986395473
Validation loss: 2.6229385098136833

Epoch: 6| Step: 3
Training loss: 2.433936815894589
Validation loss: 2.6221762420002275

Epoch: 6| Step: 4
Training loss: 2.7325380967286153
Validation loss: 2.6321388634808667

Epoch: 6| Step: 5
Training loss: 3.197829619143473
Validation loss: 2.6526155724121203

Epoch: 6| Step: 6
Training loss: 2.760833727921691
Validation loss: 2.6696935726016133

Epoch: 6| Step: 7
Training loss: 3.4972670648103814
Validation loss: 2.712520975593499

Epoch: 6| Step: 8
Training loss: 2.6036242314298677
Validation loss: 2.7388132723122065

Epoch: 6| Step: 9
Training loss: 2.7917986786408053
Validation loss: 2.691337758533208

Epoch: 6| Step: 10
Training loss: 2.948010087077509
Validation loss: 2.6547629052384867

Epoch: 6| Step: 11
Training loss: 2.561359803139281
Validation loss: 2.6448285752477663

Epoch: 6| Step: 12
Training loss: 2.9727181667541567
Validation loss: 2.624779148450542

Epoch: 6| Step: 13
Training loss: 2.2556682819495775
Validation loss: 2.6182414808010885

Epoch: 142| Step: 0
Training loss: 3.169098037777764
Validation loss: 2.6246363323949984

Epoch: 6| Step: 1
Training loss: 3.2368682244895237
Validation loss: 2.620699133285983

Epoch: 6| Step: 2
Training loss: 2.7105165534021536
Validation loss: 2.616157924051579

Epoch: 6| Step: 3
Training loss: 2.748605114291666
Validation loss: 2.622541217533815

Epoch: 6| Step: 4
Training loss: 3.335803134186553
Validation loss: 2.615384951204117

Epoch: 6| Step: 5
Training loss: 2.2163042369731634
Validation loss: 2.6165339014223608

Epoch: 6| Step: 6
Training loss: 2.7699075935457174
Validation loss: 2.6169553807751704

Epoch: 6| Step: 7
Training loss: 3.095412299036332
Validation loss: 2.623290080752298

Epoch: 6| Step: 8
Training loss: 3.498299049135539
Validation loss: 2.6238311219967065

Epoch: 6| Step: 9
Training loss: 3.1364505790953285
Validation loss: 2.6230274764417927

Epoch: 6| Step: 10
Training loss: 3.145009638251499
Validation loss: 2.6255753321747584

Epoch: 6| Step: 11
Training loss: 2.7627690110906085
Validation loss: 2.632268802335703

Epoch: 6| Step: 12
Training loss: 2.5448098264138137
Validation loss: 2.6447054951180755

Epoch: 6| Step: 13
Training loss: 2.8792563734051098
Validation loss: 2.656530179442626

Epoch: 143| Step: 0
Training loss: 2.4266179065556455
Validation loss: 2.653925857196934

Epoch: 6| Step: 1
Training loss: 2.6917254918838265
Validation loss: 2.668983868476155

Epoch: 6| Step: 2
Training loss: 3.723769574838994
Validation loss: 2.656777091091438

Epoch: 6| Step: 3
Training loss: 2.662495708909853
Validation loss: 2.649788331029375

Epoch: 6| Step: 4
Training loss: 2.6085424865456512
Validation loss: 2.6382688644173697

Epoch: 6| Step: 5
Training loss: 3.0202569521292
Validation loss: 2.636163056160316

Epoch: 6| Step: 6
Training loss: 2.656235279715646
Validation loss: 2.6111440327766084

Epoch: 6| Step: 7
Training loss: 2.692719115795828
Validation loss: 2.614463227504004

Epoch: 6| Step: 8
Training loss: 3.232294712849955
Validation loss: 2.6163749862491916

Epoch: 6| Step: 9
Training loss: 3.211291811066879
Validation loss: 2.6149246123168046

Epoch: 6| Step: 10
Training loss: 3.1922486779712633
Validation loss: 2.6201576312131007

Epoch: 6| Step: 11
Training loss: 2.974117366103907
Validation loss: 2.6168810789168155

Epoch: 6| Step: 12
Training loss: 3.312503742719731
Validation loss: 2.620617861841972

Epoch: 6| Step: 13
Training loss: 2.8852913802911013
Validation loss: 2.61152779212216

Epoch: 144| Step: 0
Training loss: 2.449418298601911
Validation loss: 2.622410745848489

Epoch: 6| Step: 1
Training loss: 2.1763495588234814
Validation loss: 2.6133540243141593

Epoch: 6| Step: 2
Training loss: 3.573181468763631
Validation loss: 2.6259421998119343

Epoch: 6| Step: 3
Training loss: 3.3720650804060917
Validation loss: 2.6366810552347753

Epoch: 6| Step: 4
Training loss: 3.450168224048062
Validation loss: 2.6378971938984592

Epoch: 6| Step: 5
Training loss: 4.05496150213704
Validation loss: 2.6736241527875517

Epoch: 6| Step: 6
Training loss: 2.4032232891960694
Validation loss: 2.6435940016927617

Epoch: 6| Step: 7
Training loss: 2.7574776508328274
Validation loss: 2.645173259277087

Epoch: 6| Step: 8
Training loss: 3.052602539339767
Validation loss: 2.6413208554991936

Epoch: 6| Step: 9
Training loss: 3.3096409100983126
Validation loss: 2.645561149678263

Epoch: 6| Step: 10
Training loss: 2.6694405155988776
Validation loss: 2.617790770485081

Epoch: 6| Step: 11
Training loss: 2.391554508392767
Validation loss: 2.6144199216500397

Epoch: 6| Step: 12
Training loss: 2.4008411205112052
Validation loss: 2.6157772441796623

Epoch: 6| Step: 13
Training loss: 2.471928156342661
Validation loss: 2.608462196557645

Epoch: 145| Step: 0
Training loss: 2.816596036698865
Validation loss: 2.6085277702573952

Epoch: 6| Step: 1
Training loss: 3.0214970002160277
Validation loss: 2.6063650395472493

Epoch: 6| Step: 2
Training loss: 3.0457742903623095
Validation loss: 2.6078503271934195

Epoch: 6| Step: 3
Training loss: 2.866462969381252
Validation loss: 2.6097778398416263

Epoch: 6| Step: 4
Training loss: 1.8241850300517066
Validation loss: 2.605878427999165

Epoch: 6| Step: 5
Training loss: 2.900274553127774
Validation loss: 2.6064865624250677

Epoch: 6| Step: 6
Training loss: 3.178299734587797
Validation loss: 2.606873106010769

Epoch: 6| Step: 7
Training loss: 2.74726436836803
Validation loss: 2.6052916469785257

Epoch: 6| Step: 8
Training loss: 3.153203721665815
Validation loss: 2.6021439974293408

Epoch: 6| Step: 9
Training loss: 3.0429084194015346
Validation loss: 2.607384290582163

Epoch: 6| Step: 10
Training loss: 3.4722393459321683
Validation loss: 2.6048974151800275

Epoch: 6| Step: 11
Training loss: 2.976536547930664
Validation loss: 2.6166102069443182

Epoch: 6| Step: 12
Training loss: 3.1318546647884893
Validation loss: 2.6080528192439663

Epoch: 6| Step: 13
Training loss: 2.8793421587386665
Validation loss: 2.610383483680002

Epoch: 146| Step: 0
Training loss: 2.584884567487277
Validation loss: 2.6039249900326964

Epoch: 6| Step: 1
Training loss: 3.488672727892909
Validation loss: 2.603070432884348

Epoch: 6| Step: 2
Training loss: 2.917189651104339
Validation loss: 2.603080687149229

Epoch: 6| Step: 3
Training loss: 2.292353428904774
Validation loss: 2.604342797670683

Epoch: 6| Step: 4
Training loss: 2.571574263759606
Validation loss: 2.6041297512924526

Epoch: 6| Step: 5
Training loss: 3.6242593469009132
Validation loss: 2.6093608906662693

Epoch: 6| Step: 6
Training loss: 2.895245627358207
Validation loss: 2.6010328085756553

Epoch: 6| Step: 7
Training loss: 3.366422703530805
Validation loss: 2.6043327462346477

Epoch: 6| Step: 8
Training loss: 1.9614059071178527
Validation loss: 2.6045429687982855

Epoch: 6| Step: 9
Training loss: 3.186217255631739
Validation loss: 2.6076430709264464

Epoch: 6| Step: 10
Training loss: 3.37612684299953
Validation loss: 2.6030646409598734

Epoch: 6| Step: 11
Training loss: 3.145742621387619
Validation loss: 2.6070033783273865

Epoch: 6| Step: 12
Training loss: 2.6603944646575566
Validation loss: 2.6053464121338754

Epoch: 6| Step: 13
Training loss: 2.4465528760879836
Validation loss: 2.6037024788566177

Epoch: 147| Step: 0
Training loss: 3.3733120688671607
Validation loss: 2.609743428895933

Epoch: 6| Step: 1
Training loss: 2.581144194939915
Validation loss: 2.6216359984574553

Epoch: 6| Step: 2
Training loss: 2.8533642237170627
Validation loss: 2.6277015982051632

Epoch: 6| Step: 3
Training loss: 2.9699216438001357
Validation loss: 2.633575129386183

Epoch: 6| Step: 4
Training loss: 2.8088190362422663
Validation loss: 2.6547211273548683

Epoch: 6| Step: 5
Training loss: 2.4060514293827886
Validation loss: 2.6416061276680782

Epoch: 6| Step: 6
Training loss: 3.2373823107681026
Validation loss: 2.6374272353031776

Epoch: 6| Step: 7
Training loss: 3.210063583362254
Validation loss: 2.634626463095204

Epoch: 6| Step: 8
Training loss: 2.790082985248861
Validation loss: 2.649019381231985

Epoch: 6| Step: 9
Training loss: 3.3328059415041835
Validation loss: 2.659641229686563

Epoch: 6| Step: 10
Training loss: 2.895611560114352
Validation loss: 2.654215469880138

Epoch: 6| Step: 11
Training loss: 3.231434835611227
Validation loss: 2.6508948636839236

Epoch: 6| Step: 12
Training loss: 2.6510657488635325
Validation loss: 2.649186655907368

Epoch: 6| Step: 13
Training loss: 2.634641380010461
Validation loss: 2.6338838023990085

Epoch: 148| Step: 0
Training loss: 1.959727548522464
Validation loss: 2.6045723518299675

Epoch: 6| Step: 1
Training loss: 3.4399997292008404
Validation loss: 2.6085285633705455

Epoch: 6| Step: 2
Training loss: 3.0623318372995243
Validation loss: 2.6129899833457104

Epoch: 6| Step: 3
Training loss: 3.3166222024617613
Validation loss: 2.613252127738491

Epoch: 6| Step: 4
Training loss: 2.898933471032099
Validation loss: 2.615787726970333

Epoch: 6| Step: 5
Training loss: 2.9176185326249393
Validation loss: 2.6154756705274766

Epoch: 6| Step: 6
Training loss: 3.0873457773587023
Validation loss: 2.6136616136763693

Epoch: 6| Step: 7
Training loss: 3.273696488579969
Validation loss: 2.6144272083092552

Epoch: 6| Step: 8
Training loss: 2.6757936352074223
Validation loss: 2.612945845604626

Epoch: 6| Step: 9
Training loss: 3.2254388436696377
Validation loss: 2.6073130354257312

Epoch: 6| Step: 10
Training loss: 2.694486895179841
Validation loss: 2.605357455455309

Epoch: 6| Step: 11
Training loss: 3.364076810488315
Validation loss: 2.6072606266888463

Epoch: 6| Step: 12
Training loss: 2.38244325872464
Validation loss: 2.604301705745666

Epoch: 6| Step: 13
Training loss: 2.8422153230367475
Validation loss: 2.607069937152986

Epoch: 149| Step: 0
Training loss: 2.4519063267200414
Validation loss: 2.6084817673164373

Epoch: 6| Step: 1
Training loss: 3.3319974765653546
Validation loss: 2.617020490886113

Epoch: 6| Step: 2
Training loss: 3.216091354258767
Validation loss: 2.6291704854304814

Epoch: 6| Step: 3
Training loss: 3.193253952292709
Validation loss: 2.6472256622193395

Epoch: 6| Step: 4
Training loss: 3.2944328338635738
Validation loss: 2.6708486529083335

Epoch: 6| Step: 5
Training loss: 3.152019725156922
Validation loss: 2.7038457629039163

Epoch: 6| Step: 6
Training loss: 2.9944336431147676
Validation loss: 2.73279673134776

Epoch: 6| Step: 7
Training loss: 2.6925004083177972
Validation loss: 2.7821887999989356

Epoch: 6| Step: 8
Training loss: 2.9103318948671903
Validation loss: 2.7952517736575415

Epoch: 6| Step: 9
Training loss: 2.484921377308306
Validation loss: 2.827981924724314

Epoch: 6| Step: 10
Training loss: 3.350914383402688
Validation loss: 2.7823482224176153

Epoch: 6| Step: 11
Training loss: 3.0998478144544968
Validation loss: 2.69033917818871

Epoch: 6| Step: 12
Training loss: 2.7208899483819726
Validation loss: 2.6415361294982485

Epoch: 6| Step: 13
Training loss: 2.761028025362281
Validation loss: 2.617724325596727

Epoch: 150| Step: 0
Training loss: 3.2539358515497776
Validation loss: 2.609356198345354

Epoch: 6| Step: 1
Training loss: 3.0647339749908764
Validation loss: 2.612540605357741

Epoch: 6| Step: 2
Training loss: 3.3198610963833692
Validation loss: 2.625316459186913

Epoch: 6| Step: 3
Training loss: 2.732944310424535
Validation loss: 2.641400543650369

Epoch: 6| Step: 4
Training loss: 3.282799345895231
Validation loss: 2.664694897007868

Epoch: 6| Step: 5
Training loss: 2.556700493772385
Validation loss: 2.667084195600509

Epoch: 6| Step: 6
Training loss: 2.904443322846049
Validation loss: 2.682736545414245

Epoch: 6| Step: 7
Training loss: 2.6750938256467163
Validation loss: 2.690253158932083

Epoch: 6| Step: 8
Training loss: 3.0852006636142204
Validation loss: 2.6911372139840237

Epoch: 6| Step: 9
Training loss: 2.9971929769313816
Validation loss: 2.63737609374724

Epoch: 6| Step: 10
Training loss: 3.2223576447833278
Validation loss: 2.611966193580221

Epoch: 6| Step: 11
Training loss: 2.6909313031985667
Validation loss: 2.603374759163859

Epoch: 6| Step: 12
Training loss: 2.923967723788322
Validation loss: 2.607979201530843

Epoch: 6| Step: 13
Training loss: 2.4554055662458243
Validation loss: 2.607862146346226

Epoch: 151| Step: 0
Training loss: 3.068696273675249
Validation loss: 2.6243141272479837

Epoch: 6| Step: 1
Training loss: 2.663391565761287
Validation loss: 2.624942758407776

Epoch: 6| Step: 2
Training loss: 3.3124523519291973
Validation loss: 2.6469258720593265

Epoch: 6| Step: 3
Training loss: 3.1697320323043416
Validation loss: 2.6804178219071444

Epoch: 6| Step: 4
Training loss: 2.847336237002123
Validation loss: 2.6648259719119634

Epoch: 6| Step: 5
Training loss: 2.9354981439318513
Validation loss: 2.658342737451332

Epoch: 6| Step: 6
Training loss: 2.985723859728614
Validation loss: 2.644793272991906

Epoch: 6| Step: 7
Training loss: 2.779304509745531
Validation loss: 2.6426446284194562

Epoch: 6| Step: 8
Training loss: 2.4292529536299274
Validation loss: 2.6273228826806476

Epoch: 6| Step: 9
Training loss: 2.992828061534475
Validation loss: 2.6188910743501497

Epoch: 6| Step: 10
Training loss: 2.9937615698987026
Validation loss: 2.604546599862862

Epoch: 6| Step: 11
Training loss: 3.305989038448081
Validation loss: 2.606711605421511

Epoch: 6| Step: 12
Training loss: 2.9058328965010523
Validation loss: 2.6142532495872564

Epoch: 6| Step: 13
Training loss: 2.5231771895836803
Validation loss: 2.6209194238530067

Epoch: 152| Step: 0
Training loss: 2.342892604403331
Validation loss: 2.6341290606474352

Epoch: 6| Step: 1
Training loss: 3.096954381639414
Validation loss: 2.6423394625853525

Epoch: 6| Step: 2
Training loss: 3.0932511977548978
Validation loss: 2.620838548554109

Epoch: 6| Step: 3
Training loss: 3.0101551791520125
Validation loss: 2.618919553423682

Epoch: 6| Step: 4
Training loss: 2.6014248465013607
Validation loss: 2.6246943259217925

Epoch: 6| Step: 5
Training loss: 2.325937459490303
Validation loss: 2.621393402059538

Epoch: 6| Step: 6
Training loss: 3.106427813531348
Validation loss: 2.6386735033420536

Epoch: 6| Step: 7
Training loss: 3.2995441353093753
Validation loss: 2.6404152248216377

Epoch: 6| Step: 8
Training loss: 3.1802072311151224
Validation loss: 2.6282393288476023

Epoch: 6| Step: 9
Training loss: 2.9168095871559063
Validation loss: 2.625521134946425

Epoch: 6| Step: 10
Training loss: 3.270509999486056
Validation loss: 2.626388556596936

Epoch: 6| Step: 11
Training loss: 2.9388700496243625
Validation loss: 2.623895241757793

Epoch: 6| Step: 12
Training loss: 2.455947709834715
Validation loss: 2.605234697100467

Epoch: 6| Step: 13
Training loss: 3.396750687023904
Validation loss: 2.60278556247552

Epoch: 153| Step: 0
Training loss: 3.2478845020110123
Validation loss: 2.5976696462175544

Epoch: 6| Step: 1
Training loss: 2.8382516881997706
Validation loss: 2.600889814242289

Epoch: 6| Step: 2
Training loss: 2.8677089954896924
Validation loss: 2.598478750722888

Epoch: 6| Step: 3
Training loss: 3.200137051985314
Validation loss: 2.6066743126943717

Epoch: 6| Step: 4
Training loss: 2.547193074403386
Validation loss: 2.598819815203423

Epoch: 6| Step: 5
Training loss: 3.130875823607759
Validation loss: 2.6093425919424598

Epoch: 6| Step: 6
Training loss: 2.7637629733218945
Validation loss: 2.6056932748422335

Epoch: 6| Step: 7
Training loss: 2.8974474426716412
Validation loss: 2.622058196612794

Epoch: 6| Step: 8
Training loss: 2.78072257880982
Validation loss: 2.6145022741313775

Epoch: 6| Step: 9
Training loss: 3.006235318534674
Validation loss: 2.6334948072645252

Epoch: 6| Step: 10
Training loss: 3.0381283145549802
Validation loss: 2.6421412603502277

Epoch: 6| Step: 11
Training loss: 3.1705841294024437
Validation loss: 2.631462920473481

Epoch: 6| Step: 12
Training loss: 2.9003881589320324
Validation loss: 2.624349254649726

Epoch: 6| Step: 13
Training loss: 2.468480735291027
Validation loss: 2.609181276631088

Epoch: 154| Step: 0
Training loss: 2.9900178139452547
Validation loss: 2.61490739664736

Epoch: 6| Step: 1
Training loss: 2.9137252326086167
Validation loss: 2.6003727085313764

Epoch: 6| Step: 2
Training loss: 3.1501001554037464
Validation loss: 2.6077066351199414

Epoch: 6| Step: 3
Training loss: 2.8980100578728547
Validation loss: 2.60130909784954

Epoch: 6| Step: 4
Training loss: 3.5578979749970743
Validation loss: 2.602495122825402

Epoch: 6| Step: 5
Training loss: 2.5672737873270703
Validation loss: 2.600360040015704

Epoch: 6| Step: 6
Training loss: 2.8537813098207483
Validation loss: 2.594530035987963

Epoch: 6| Step: 7
Training loss: 3.0856000112132516
Validation loss: 2.601479082569502

Epoch: 6| Step: 8
Training loss: 2.8760664247421004
Validation loss: 2.5947964204716745

Epoch: 6| Step: 9
Training loss: 3.360695654743743
Validation loss: 2.6032150840124206

Epoch: 6| Step: 10
Training loss: 2.7205404765632766
Validation loss: 2.5983837943561094

Epoch: 6| Step: 11
Training loss: 2.617828928219779
Validation loss: 2.5966130978132287

Epoch: 6| Step: 12
Training loss: 2.6546918899293273
Validation loss: 2.6350653344194184

Epoch: 6| Step: 13
Training loss: 2.335789398295509
Validation loss: 2.6611505807338154

Epoch: 155| Step: 0
Training loss: 2.895005819153414
Validation loss: 2.698781474992705

Epoch: 6| Step: 1
Training loss: 3.1362471552593028
Validation loss: 2.746222083362048

Epoch: 6| Step: 2
Training loss: 3.11727973973608
Validation loss: 2.7335458274717666

Epoch: 6| Step: 3
Training loss: 3.0961993761355595
Validation loss: 2.7313676526003046

Epoch: 6| Step: 4
Training loss: 3.052582701016536
Validation loss: 2.707802792655113

Epoch: 6| Step: 5
Training loss: 2.623665606707591
Validation loss: 2.73761245686472

Epoch: 6| Step: 6
Training loss: 3.1169601778210243
Validation loss: 2.6635853118062434

Epoch: 6| Step: 7
Training loss: 2.6268708964244767
Validation loss: 2.6411248472033892

Epoch: 6| Step: 8
Training loss: 2.785146833620565
Validation loss: 2.6293837287955073

Epoch: 6| Step: 9
Training loss: 2.6788068831363474
Validation loss: 2.602063113943827

Epoch: 6| Step: 10
Training loss: 3.3881976320707334
Validation loss: 2.5933698406961354

Epoch: 6| Step: 11
Training loss: 2.782410111804771
Validation loss: 2.5909861083736216

Epoch: 6| Step: 12
Training loss: 2.5813503550678916
Validation loss: 2.5925834632975837

Epoch: 6| Step: 13
Training loss: 3.0396638486123817
Validation loss: 2.589667799363291

Epoch: 156| Step: 0
Training loss: 3.133042020309557
Validation loss: 2.5975404992237316

Epoch: 6| Step: 1
Training loss: 3.1762250564358405
Validation loss: 2.5945848608153685

Epoch: 6| Step: 2
Training loss: 2.6399823371700935
Validation loss: 2.5928318352126105

Epoch: 6| Step: 3
Training loss: 2.38205934722534
Validation loss: 2.597074487100136

Epoch: 6| Step: 4
Training loss: 3.4316710555975036
Validation loss: 2.592382124453915

Epoch: 6| Step: 5
Training loss: 2.7645314958930505
Validation loss: 2.6063744585572475

Epoch: 6| Step: 6
Training loss: 3.316737218007394
Validation loss: 2.611314288344814

Epoch: 6| Step: 7
Training loss: 2.8045236013653434
Validation loss: 2.62336635881947

Epoch: 6| Step: 8
Training loss: 3.2120979977832684
Validation loss: 2.681345695151161

Epoch: 6| Step: 9
Training loss: 3.0510900831999015
Validation loss: 2.727167655361726

Epoch: 6| Step: 10
Training loss: 3.3340993636804725
Validation loss: 2.7761635693061595

Epoch: 6| Step: 11
Training loss: 2.87728890235449
Validation loss: 2.7167221557649515

Epoch: 6| Step: 12
Training loss: 2.3618897431986743
Validation loss: 2.6717222830110745

Epoch: 6| Step: 13
Training loss: 2.695245537409809
Validation loss: 2.6283528117893096

Epoch: 157| Step: 0
Training loss: 2.9559337035450266
Validation loss: 2.610999098267326

Epoch: 6| Step: 1
Training loss: 2.948566773961175
Validation loss: 2.5986125707085583

Epoch: 6| Step: 2
Training loss: 2.913794456610826
Validation loss: 2.6013536823660655

Epoch: 6| Step: 3
Training loss: 3.296189946599331
Validation loss: 2.610618834722484

Epoch: 6| Step: 4
Training loss: 2.7931823221992484
Validation loss: 2.6153346842945555

Epoch: 6| Step: 5
Training loss: 2.499455201869468
Validation loss: 2.605173488455965

Epoch: 6| Step: 6
Training loss: 2.649519887653384
Validation loss: 2.6124096342114638

Epoch: 6| Step: 7
Training loss: 3.1274584445891263
Validation loss: 2.6155621828486466

Epoch: 6| Step: 8
Training loss: 2.8982152313803033
Validation loss: 2.628614793386131

Epoch: 6| Step: 9
Training loss: 3.324261065526428
Validation loss: 2.6179553107269244

Epoch: 6| Step: 10
Training loss: 3.1373196189062913
Validation loss: 2.6126334713111206

Epoch: 6| Step: 11
Training loss: 2.1464832642598353
Validation loss: 2.5986174698718805

Epoch: 6| Step: 12
Training loss: 3.0448463924856717
Validation loss: 2.580217803606903

Epoch: 6| Step: 13
Training loss: 3.4635066362870583
Validation loss: 2.585857249708345

Epoch: 158| Step: 0
Training loss: 2.3625709159743358
Validation loss: 2.590166746289484

Epoch: 6| Step: 1
Training loss: 2.787734968605873
Validation loss: 2.594818839911414

Epoch: 6| Step: 2
Training loss: 3.0681461524817037
Validation loss: 2.595876929402078

Epoch: 6| Step: 3
Training loss: 3.0715264402999876
Validation loss: 2.599875858299669

Epoch: 6| Step: 4
Training loss: 3.628872085919645
Validation loss: 2.6003614291189954

Epoch: 6| Step: 5
Training loss: 3.231829982629206
Validation loss: 2.5921642775236715

Epoch: 6| Step: 6
Training loss: 2.872983474083761
Validation loss: 2.597000259074161

Epoch: 6| Step: 7
Training loss: 2.66910717470213
Validation loss: 2.592558593945396

Epoch: 6| Step: 8
Training loss: 3.3897999405694965
Validation loss: 2.59856142391792

Epoch: 6| Step: 9
Training loss: 2.279790751241394
Validation loss: 2.603638093198535

Epoch: 6| Step: 10
Training loss: 2.7615341707567778
Validation loss: 2.6017942100294102

Epoch: 6| Step: 11
Training loss: 2.6794430813104926
Validation loss: 2.6059024746999855

Epoch: 6| Step: 12
Training loss: 3.107130304320587
Validation loss: 2.608060318319961

Epoch: 6| Step: 13
Training loss: 3.1956706324362694
Validation loss: 2.623556070053986

Epoch: 159| Step: 0
Training loss: 2.8481709416769028
Validation loss: 2.622063415680819

Epoch: 6| Step: 1
Training loss: 3.4893333838986003
Validation loss: 2.6370820482243076

Epoch: 6| Step: 2
Training loss: 2.5910752074362526
Validation loss: 2.6264411468532196

Epoch: 6| Step: 3
Training loss: 3.2278011429145823
Validation loss: 2.612007176705818

Epoch: 6| Step: 4
Training loss: 3.0981084774916554
Validation loss: 2.6003919399103204

Epoch: 6| Step: 5
Training loss: 2.726934806522862
Validation loss: 2.5981060967496794

Epoch: 6| Step: 6
Training loss: 2.713797959264561
Validation loss: 2.595300801143932

Epoch: 6| Step: 7
Training loss: 2.262232799453257
Validation loss: 2.582675304885384

Epoch: 6| Step: 8
Training loss: 2.515599694924405
Validation loss: 2.576821962904085

Epoch: 6| Step: 9
Training loss: 3.0124925542082517
Validation loss: 2.581064358787564

Epoch: 6| Step: 10
Training loss: 2.976972416563837
Validation loss: 2.578301051279426

Epoch: 6| Step: 11
Training loss: 2.9083028126802994
Validation loss: 2.581765168959153

Epoch: 6| Step: 12
Training loss: 3.409816030199026
Validation loss: 2.580705167857207

Epoch: 6| Step: 13
Training loss: 3.0461188527374374
Validation loss: 2.5850962773847805

Epoch: 160| Step: 0
Training loss: 3.2145981167552025
Validation loss: 2.5806884709436146

Epoch: 6| Step: 1
Training loss: 3.0069651809772218
Validation loss: 2.575946347472979

Epoch: 6| Step: 2
Training loss: 3.4130276785532097
Validation loss: 2.5815616844865508

Epoch: 6| Step: 3
Training loss: 3.4399537085589986
Validation loss: 2.5736606112394926

Epoch: 6| Step: 4
Training loss: 2.974652496045379
Validation loss: 2.5749659460252956

Epoch: 6| Step: 5
Training loss: 2.3043489886461663
Validation loss: 2.571576245625614

Epoch: 6| Step: 6
Training loss: 2.507578425906706
Validation loss: 2.5782619615198117

Epoch: 6| Step: 7
Training loss: 3.0033704579973466
Validation loss: 2.5823446476446503

Epoch: 6| Step: 8
Training loss: 3.0292849119283445
Validation loss: 2.594154293784133

Epoch: 6| Step: 9
Training loss: 2.9014031797351008
Validation loss: 2.5895013339856368

Epoch: 6| Step: 10
Training loss: 2.750312614011811
Validation loss: 2.583531012565128

Epoch: 6| Step: 11
Training loss: 3.1466239457813434
Validation loss: 2.583586577851636

Epoch: 6| Step: 12
Training loss: 2.40175218199155
Validation loss: 2.5891201221134756

Epoch: 6| Step: 13
Training loss: 2.510927446460359
Validation loss: 2.5872103218588007

Epoch: 161| Step: 0
Training loss: 2.9456236495337254
Validation loss: 2.5838386343803283

Epoch: 6| Step: 1
Training loss: 2.89935666544948
Validation loss: 2.585113213586244

Epoch: 6| Step: 2
Training loss: 2.7462674733067476
Validation loss: 2.586121807390037

Epoch: 6| Step: 3
Training loss: 1.990281872842354
Validation loss: 2.586089483640871

Epoch: 6| Step: 4
Training loss: 2.925727140896518
Validation loss: 2.5827219382153634

Epoch: 6| Step: 5
Training loss: 2.9445359397763795
Validation loss: 2.5907428189145176

Epoch: 6| Step: 6
Training loss: 2.9188838887188977
Validation loss: 2.5882576935463057

Epoch: 6| Step: 7
Training loss: 3.113708543352177
Validation loss: 2.5952083778765775

Epoch: 6| Step: 8
Training loss: 2.9361858268990755
Validation loss: 2.5901384994057093

Epoch: 6| Step: 9
Training loss: 2.8200171149525826
Validation loss: 2.598953164864271

Epoch: 6| Step: 10
Training loss: 3.346602747054726
Validation loss: 2.5904445012987387

Epoch: 6| Step: 11
Training loss: 3.1124843980022803
Validation loss: 2.5928558812962406

Epoch: 6| Step: 12
Training loss: 3.0296497643625653
Validation loss: 2.5924068857306986

Epoch: 6| Step: 13
Training loss: 2.9981437344390205
Validation loss: 2.6022010331740653

Epoch: 162| Step: 0
Training loss: 3.4387601449997742
Validation loss: 2.5972493911140155

Epoch: 6| Step: 1
Training loss: 3.4511228254596635
Validation loss: 2.600597284943877

Epoch: 6| Step: 2
Training loss: 2.8235521809393833
Validation loss: 2.592182526417426

Epoch: 6| Step: 3
Training loss: 3.175981841374141
Validation loss: 2.600602177410919

Epoch: 6| Step: 4
Training loss: 2.282784559847838
Validation loss: 2.594797378824683

Epoch: 6| Step: 5
Training loss: 3.0133468640566616
Validation loss: 2.5938276597282455

Epoch: 6| Step: 6
Training loss: 2.715343401918851
Validation loss: 2.5898529083753736

Epoch: 6| Step: 7
Training loss: 3.3762046642006633
Validation loss: 2.5950360648854107

Epoch: 6| Step: 8
Training loss: 2.166071320927866
Validation loss: 2.5799623387805743

Epoch: 6| Step: 9
Training loss: 3.2901273258697104
Validation loss: 2.5812664215098673

Epoch: 6| Step: 10
Training loss: 2.8104919894799396
Validation loss: 2.5791069778352167

Epoch: 6| Step: 11
Training loss: 2.111205260648024
Validation loss: 2.5849231425400103

Epoch: 6| Step: 12
Training loss: 2.7726342985821835
Validation loss: 2.5875256969540597

Epoch: 6| Step: 13
Training loss: 3.137505495590929
Validation loss: 2.576058960446923

Epoch: 163| Step: 0
Training loss: 2.7047801160023397
Validation loss: 2.5758053016260636

Epoch: 6| Step: 1
Training loss: 2.999292290181695
Validation loss: 2.5774706982558673

Epoch: 6| Step: 2
Training loss: 2.927250939906852
Validation loss: 2.5854412728326515

Epoch: 6| Step: 3
Training loss: 2.4753499718040186
Validation loss: 2.589362015573129

Epoch: 6| Step: 4
Training loss: 3.3536583809524805
Validation loss: 2.592063029037732

Epoch: 6| Step: 5
Training loss: 2.750724870341797
Validation loss: 2.5895466752055896

Epoch: 6| Step: 6
Training loss: 3.1605928965758534
Validation loss: 2.593099098061077

Epoch: 6| Step: 7
Training loss: 3.111936194895955
Validation loss: 2.5910520907135783

Epoch: 6| Step: 8
Training loss: 2.711793615944716
Validation loss: 2.592738878984512

Epoch: 6| Step: 9
Training loss: 2.6340320151200225
Validation loss: 2.6076978314300114

Epoch: 6| Step: 10
Training loss: 3.0172099163500854
Validation loss: 2.5991915186116215

Epoch: 6| Step: 11
Training loss: 3.0796139596551595
Validation loss: 2.6100268434919935

Epoch: 6| Step: 12
Training loss: 2.972007650629929
Validation loss: 2.6111167737325887

Epoch: 6| Step: 13
Training loss: 2.7532592879245805
Validation loss: 2.6211013995562786

Epoch: 164| Step: 0
Training loss: 3.1518554309280593
Validation loss: 2.6077978997624336

Epoch: 6| Step: 1
Training loss: 2.7950499989741036
Validation loss: 2.6120360458871934

Epoch: 6| Step: 2
Training loss: 3.1180278056570607
Validation loss: 2.613961842620351

Epoch: 6| Step: 3
Training loss: 2.882154105244366
Validation loss: 2.59758205142851

Epoch: 6| Step: 4
Training loss: 3.227228349974011
Validation loss: 2.5916715622363626

Epoch: 6| Step: 5
Training loss: 2.4789687539824774
Validation loss: 2.582963110811858

Epoch: 6| Step: 6
Training loss: 3.0281600147029875
Validation loss: 2.5784440217032274

Epoch: 6| Step: 7
Training loss: 2.7898312318681806
Validation loss: 2.5760345465918624

Epoch: 6| Step: 8
Training loss: 2.675580405612392
Validation loss: 2.580537208355238

Epoch: 6| Step: 9
Training loss: 3.394605137555323
Validation loss: 2.578053366721504

Epoch: 6| Step: 10
Training loss: 2.71700134166113
Validation loss: 2.580667889723108

Epoch: 6| Step: 11
Training loss: 2.808948648284178
Validation loss: 2.5833930234599176

Epoch: 6| Step: 12
Training loss: 2.7300243534497026
Validation loss: 2.5939201410865365

Epoch: 6| Step: 13
Training loss: 2.8889343266296486
Validation loss: 2.5889531402728174

Epoch: 165| Step: 0
Training loss: 2.826521613909741
Validation loss: 2.593968365053193

Epoch: 6| Step: 1
Training loss: 2.685353508663561
Validation loss: 2.6243166612741238

Epoch: 6| Step: 2
Training loss: 3.091480694410226
Validation loss: 2.6329193935808557

Epoch: 6| Step: 3
Training loss: 2.7432832186151326
Validation loss: 2.6136975355284227

Epoch: 6| Step: 4
Training loss: 3.2171880395044927
Validation loss: 2.6041236693411465

Epoch: 6| Step: 5
Training loss: 2.4016467564234256
Validation loss: 2.5872123502096773

Epoch: 6| Step: 6
Training loss: 2.9878840562726037
Validation loss: 2.576891269616808

Epoch: 6| Step: 7
Training loss: 2.8539355293482487
Validation loss: 2.5694578836879085

Epoch: 6| Step: 8
Training loss: 3.0488875564755173
Validation loss: 2.561089768672001

Epoch: 6| Step: 9
Training loss: 3.1189427990843246
Validation loss: 2.5627079350834068

Epoch: 6| Step: 10
Training loss: 3.3288458818012523
Validation loss: 2.5636648606358783

Epoch: 6| Step: 11
Training loss: 2.782780344122409
Validation loss: 2.5653477653609293

Epoch: 6| Step: 12
Training loss: 2.954279921010291
Validation loss: 2.5707944673766208

Epoch: 6| Step: 13
Training loss: 2.793149374076388
Validation loss: 2.5625484030789454

Epoch: 166| Step: 0
Training loss: 2.4586139669638674
Validation loss: 2.5625471265347595

Epoch: 6| Step: 1
Training loss: 3.0323794119084297
Validation loss: 2.563765685700464

Epoch: 6| Step: 2
Training loss: 3.07061377835606
Validation loss: 2.5714107854590686

Epoch: 6| Step: 3
Training loss: 2.522382391616091
Validation loss: 2.5743927501343604

Epoch: 6| Step: 4
Training loss: 3.0012711375110603
Validation loss: 2.599558983514224

Epoch: 6| Step: 5
Training loss: 2.7202848289524137
Validation loss: 2.6096496476791065

Epoch: 6| Step: 6
Training loss: 3.088247318404695
Validation loss: 2.616962105907161

Epoch: 6| Step: 7
Training loss: 3.127155781075476
Validation loss: 2.628206721286529

Epoch: 6| Step: 8
Training loss: 2.429076973604391
Validation loss: 2.6104361439840615

Epoch: 6| Step: 9
Training loss: 3.176181068918482
Validation loss: 2.6281473986589696

Epoch: 6| Step: 10
Training loss: 2.9305171351352457
Validation loss: 2.5998317986723083

Epoch: 6| Step: 11
Training loss: 3.2510444723400527
Validation loss: 2.5981991125621433

Epoch: 6| Step: 12
Training loss: 2.437371666293107
Validation loss: 2.598095223900681

Epoch: 6| Step: 13
Training loss: 3.589188176546696
Validation loss: 2.584874810322686

Epoch: 167| Step: 0
Training loss: 2.7082370643134244
Validation loss: 2.567973971419523

Epoch: 6| Step: 1
Training loss: 3.4287046792612355
Validation loss: 2.558658831295556

Epoch: 6| Step: 2
Training loss: 2.270123455370767
Validation loss: 2.5633329252833215

Epoch: 6| Step: 3
Training loss: 3.31793357447838
Validation loss: 2.5595591938226314

Epoch: 6| Step: 4
Training loss: 3.3433910426759246
Validation loss: 2.5623701269261723

Epoch: 6| Step: 5
Training loss: 2.658453263195348
Validation loss: 2.5598032577667067

Epoch: 6| Step: 6
Training loss: 3.0681279688261474
Validation loss: 2.5607362745680295

Epoch: 6| Step: 7
Training loss: 2.8395676931247635
Validation loss: 2.55804089501534

Epoch: 6| Step: 8
Training loss: 2.6494132525973235
Validation loss: 2.566210808389443

Epoch: 6| Step: 9
Training loss: 2.9540739603565846
Validation loss: 2.5677916431263723

Epoch: 6| Step: 10
Training loss: 2.6403031914901676
Validation loss: 2.5654503050290276

Epoch: 6| Step: 11
Training loss: 2.4201362521064316
Validation loss: 2.5690070490515677

Epoch: 6| Step: 12
Training loss: 3.308515923855922
Validation loss: 2.5639516168886005

Epoch: 6| Step: 13
Training loss: 2.8826580057899216
Validation loss: 2.566737042804514

Epoch: 168| Step: 0
Training loss: 3.1739030940665
Validation loss: 2.5841988302232797

Epoch: 6| Step: 1
Training loss: 2.549844146154375
Validation loss: 2.6130212865763736

Epoch: 6| Step: 2
Training loss: 2.8027356509960075
Validation loss: 2.6556414993582904

Epoch: 6| Step: 3
Training loss: 2.942623783123474
Validation loss: 2.6934625579268507

Epoch: 6| Step: 4
Training loss: 2.7684620244634015
Validation loss: 2.789336021557432

Epoch: 6| Step: 5
Training loss: 3.2602304683732375
Validation loss: 2.810587292080675

Epoch: 6| Step: 6
Training loss: 2.7116003627756036
Validation loss: 2.814653199959883

Epoch: 6| Step: 7
Training loss: 3.259732273084325
Validation loss: 2.7402376868635576

Epoch: 6| Step: 8
Training loss: 2.8762854314724713
Validation loss: 2.716859610318094

Epoch: 6| Step: 9
Training loss: 2.8376126976991687
Validation loss: 2.6647019509442424

Epoch: 6| Step: 10
Training loss: 2.944098508254463
Validation loss: 2.642236113131236

Epoch: 6| Step: 11
Training loss: 3.065605613032799
Validation loss: 2.621320324287527

Epoch: 6| Step: 12
Training loss: 2.9896173419856704
Validation loss: 2.595883970850281

Epoch: 6| Step: 13
Training loss: 2.8885074591901048
Validation loss: 2.5923396354545027

Epoch: 169| Step: 0
Training loss: 2.932755554979595
Validation loss: 2.5874297887228863

Epoch: 6| Step: 1
Training loss: 2.426545002930116
Validation loss: 2.58690986559719

Epoch: 6| Step: 2
Training loss: 2.7223199666785245
Validation loss: 2.585075348457895

Epoch: 6| Step: 3
Training loss: 2.1462261124416315
Validation loss: 2.585654438258355

Epoch: 6| Step: 4
Training loss: 3.156093178054091
Validation loss: 2.579673367263563

Epoch: 6| Step: 5
Training loss: 2.909331298237668
Validation loss: 2.586951298193828

Epoch: 6| Step: 6
Training loss: 3.001414283536349
Validation loss: 2.579244009466512

Epoch: 6| Step: 7
Training loss: 2.930832783953243
Validation loss: 2.582750586822306

Epoch: 6| Step: 8
Training loss: 3.0890917917965033
Validation loss: 2.5848681832053426

Epoch: 6| Step: 9
Training loss: 3.4134798927681587
Validation loss: 2.580240210619402

Epoch: 6| Step: 10
Training loss: 3.1198706683227346
Validation loss: 2.5823718088359984

Epoch: 6| Step: 11
Training loss: 3.2216656266270154
Validation loss: 2.594142497165898

Epoch: 6| Step: 12
Training loss: 3.036654972538239
Validation loss: 2.59708783005261

Epoch: 6| Step: 13
Training loss: 2.562804413368613
Validation loss: 2.602729517626964

Epoch: 170| Step: 0
Training loss: 3.0579841171860123
Validation loss: 2.6071240754525915

Epoch: 6| Step: 1
Training loss: 3.1442598024336657
Validation loss: 2.6160799609735226

Epoch: 6| Step: 2
Training loss: 2.665555026890159
Validation loss: 2.624194138211568

Epoch: 6| Step: 3
Training loss: 2.675563118389899
Validation loss: 2.659043482814163

Epoch: 6| Step: 4
Training loss: 3.355408638003831
Validation loss: 2.6698511577600104

Epoch: 6| Step: 5
Training loss: 2.534790765076535
Validation loss: 2.657564401400836

Epoch: 6| Step: 6
Training loss: 2.842515614650384
Validation loss: 2.6434352508097736

Epoch: 6| Step: 7
Training loss: 3.289633948186564
Validation loss: 2.6234781167337764

Epoch: 6| Step: 8
Training loss: 2.9763090571440487
Validation loss: 2.6184850359535687

Epoch: 6| Step: 9
Training loss: 3.2103103062271203
Validation loss: 2.6057494664876275

Epoch: 6| Step: 10
Training loss: 2.7789400773755086
Validation loss: 2.6099335626081204

Epoch: 6| Step: 11
Training loss: 2.823424083717952
Validation loss: 2.5980082799281954

Epoch: 6| Step: 12
Training loss: 2.3836580370970544
Validation loss: 2.6143099829033636

Epoch: 6| Step: 13
Training loss: 2.9744768019230245
Validation loss: 2.610427026396075

Epoch: 171| Step: 0
Training loss: 3.247305706928137
Validation loss: 2.5987069583803994

Epoch: 6| Step: 1
Training loss: 3.2534803681942797
Validation loss: 2.6031692658889205

Epoch: 6| Step: 2
Training loss: 2.7593356240941884
Validation loss: 2.609321133393656

Epoch: 6| Step: 3
Training loss: 2.752191190798344
Validation loss: 2.592269694463725

Epoch: 6| Step: 4
Training loss: 2.669337891767549
Validation loss: 2.5762285433750387

Epoch: 6| Step: 5
Training loss: 2.649969417467527
Validation loss: 2.579992341588794

Epoch: 6| Step: 6
Training loss: 3.1620294514876353
Validation loss: 2.5777878427409187

Epoch: 6| Step: 7
Training loss: 2.8900094691454714
Validation loss: 2.579884155351889

Epoch: 6| Step: 8
Training loss: 3.0010747573830705
Validation loss: 2.592636281450444

Epoch: 6| Step: 9
Training loss: 2.936998202704249
Validation loss: 2.5846972855816843

Epoch: 6| Step: 10
Training loss: 2.7105549918983796
Validation loss: 2.5838177736496197

Epoch: 6| Step: 11
Training loss: 2.8206145317683005
Validation loss: 2.5690479052027118

Epoch: 6| Step: 12
Training loss: 2.9447019232528584
Validation loss: 2.5613012623880693

Epoch: 6| Step: 13
Training loss: 2.7890355725951967
Validation loss: 2.554522482389453

Epoch: 172| Step: 0
Training loss: 2.9814958515000836
Validation loss: 2.5514937966558557

Epoch: 6| Step: 1
Training loss: 2.4640636146557404
Validation loss: 2.5563581280786023

Epoch: 6| Step: 2
Training loss: 3.708446172361905
Validation loss: 2.5494045205706106

Epoch: 6| Step: 3
Training loss: 3.0019720271749564
Validation loss: 2.550261747505603

Epoch: 6| Step: 4
Training loss: 2.5527507194807186
Validation loss: 2.5556733102570135

Epoch: 6| Step: 5
Training loss: 3.2189163609446774
Validation loss: 2.558359588325856

Epoch: 6| Step: 6
Training loss: 2.4849025717964883
Validation loss: 2.5603438349341214

Epoch: 6| Step: 7
Training loss: 3.1371311472461545
Validation loss: 2.5638776327956574

Epoch: 6| Step: 8
Training loss: 2.8505784100298865
Validation loss: 2.5788467306864966

Epoch: 6| Step: 9
Training loss: 2.28848894764934
Validation loss: 2.597436759903956

Epoch: 6| Step: 10
Training loss: 2.750227832026241
Validation loss: 2.6190639752368825

Epoch: 6| Step: 11
Training loss: 3.2866904070488765
Validation loss: 2.621578634518023

Epoch: 6| Step: 12
Training loss: 2.8853546760225703
Validation loss: 2.660432382333988

Epoch: 6| Step: 13
Training loss: 2.905283613427557
Validation loss: 2.708623041098292

Epoch: 173| Step: 0
Training loss: 2.958321011656411
Validation loss: 2.7017529483912153

Epoch: 6| Step: 1
Training loss: 2.860580940465689
Validation loss: 2.67517991835703

Epoch: 6| Step: 2
Training loss: 3.0430036941892005
Validation loss: 2.6520714937321563

Epoch: 6| Step: 3
Training loss: 2.504942395429273
Validation loss: 2.6134177649809067

Epoch: 6| Step: 4
Training loss: 3.190452853499075
Validation loss: 2.6060183754461845

Epoch: 6| Step: 5
Training loss: 2.835139054482505
Validation loss: 2.589220194561227

Epoch: 6| Step: 6
Training loss: 2.613454040380125
Validation loss: 2.5738157910235393

Epoch: 6| Step: 7
Training loss: 2.550495406253808
Validation loss: 2.5734289811005273

Epoch: 6| Step: 8
Training loss: 2.5270873327346774
Validation loss: 2.575694616446086

Epoch: 6| Step: 9
Training loss: 3.332804367692185
Validation loss: 2.5732703120115588

Epoch: 6| Step: 10
Training loss: 2.807476983591712
Validation loss: 2.5594448301992596

Epoch: 6| Step: 11
Training loss: 3.3992342310951624
Validation loss: 2.5554228225498252

Epoch: 6| Step: 12
Training loss: 3.287200618209651
Validation loss: 2.5607223627695386

Epoch: 6| Step: 13
Training loss: 2.6983660663632327
Validation loss: 2.5649430209302158

Epoch: 174| Step: 0
Training loss: 2.746708981441108
Validation loss: 2.5618642643180216

Epoch: 6| Step: 1
Training loss: 2.657116468140313
Validation loss: 2.5833351467363053

Epoch: 6| Step: 2
Training loss: 3.133342441248
Validation loss: 2.613934936121623

Epoch: 6| Step: 3
Training loss: 2.857649485765547
Validation loss: 2.630752473238742

Epoch: 6| Step: 4
Training loss: 2.578837718128155
Validation loss: 2.608565500358251

Epoch: 6| Step: 5
Training loss: 2.7390471732738435
Validation loss: 2.6021394315010293

Epoch: 6| Step: 6
Training loss: 2.6972434383421775
Validation loss: 2.5816381398874193

Epoch: 6| Step: 7
Training loss: 3.290855227220711
Validation loss: 2.5861603312755115

Epoch: 6| Step: 8
Training loss: 3.1396030262559607
Validation loss: 2.575702280399491

Epoch: 6| Step: 9
Training loss: 2.3745022302305023
Validation loss: 2.5678531747568685

Epoch: 6| Step: 10
Training loss: 3.0528409015522624
Validation loss: 2.563176401717728

Epoch: 6| Step: 11
Training loss: 3.130572728904715
Validation loss: 2.5589826250610432

Epoch: 6| Step: 12
Training loss: 3.0207483915466606
Validation loss: 2.5603607035714195

Epoch: 6| Step: 13
Training loss: 3.381977921010592
Validation loss: 2.561459629009285

Epoch: 175| Step: 0
Training loss: 3.0260336126766383
Validation loss: 2.561518916762536

Epoch: 6| Step: 1
Training loss: 2.6172550932852605
Validation loss: 2.567610477066404

Epoch: 6| Step: 2
Training loss: 2.7541897675146094
Validation loss: 2.566702006882068

Epoch: 6| Step: 3
Training loss: 2.6720346325040447
Validation loss: 2.562827928931195

Epoch: 6| Step: 4
Training loss: 2.988900951879551
Validation loss: 2.5651397664296307

Epoch: 6| Step: 5
Training loss: 2.5846856997168537
Validation loss: 2.5610311847105685

Epoch: 6| Step: 6
Training loss: 2.8248305548429307
Validation loss: 2.5598744924043775

Epoch: 6| Step: 7
Training loss: 3.5291898676362217
Validation loss: 2.570545915909931

Epoch: 6| Step: 8
Training loss: 2.497342986554445
Validation loss: 2.565360154081339

Epoch: 6| Step: 9
Training loss: 2.9599504662570473
Validation loss: 2.5724548758083117

Epoch: 6| Step: 10
Training loss: 2.8301947170169175
Validation loss: 2.5650110264799215

Epoch: 6| Step: 11
Training loss: 2.980377235857498
Validation loss: 2.5858569255177732

Epoch: 6| Step: 12
Training loss: 3.048266753200814
Validation loss: 2.608343200274406

Epoch: 6| Step: 13
Training loss: 3.292356459052816
Validation loss: 2.621146172633382

Epoch: 176| Step: 0
Training loss: 3.043136415771583
Validation loss: 2.626378091715058

Epoch: 6| Step: 1
Training loss: 3.006903652260014
Validation loss: 2.640311452443105

Epoch: 6| Step: 2
Training loss: 3.0576628806770243
Validation loss: 2.6224123598478952

Epoch: 6| Step: 3
Training loss: 2.954937736771833
Validation loss: 2.618562463366509

Epoch: 6| Step: 4
Training loss: 3.358051837895909
Validation loss: 2.613945629316886

Epoch: 6| Step: 5
Training loss: 3.419243344934648
Validation loss: 2.6030538104894063

Epoch: 6| Step: 6
Training loss: 2.8136212974746666
Validation loss: 2.5845256247830397

Epoch: 6| Step: 7
Training loss: 3.1159768107754795
Validation loss: 2.5681840636907878

Epoch: 6| Step: 8
Training loss: 2.4736480411221917
Validation loss: 2.56807893385222

Epoch: 6| Step: 9
Training loss: 2.4454238427501513
Validation loss: 2.5611069957553663

Epoch: 6| Step: 10
Training loss: 2.4728501471357314
Validation loss: 2.5484690893795965

Epoch: 6| Step: 11
Training loss: 1.9822313038597041
Validation loss: 2.551672294686956

Epoch: 6| Step: 12
Training loss: 3.05888495879824
Validation loss: 2.55193594899792

Epoch: 6| Step: 13
Training loss: 3.024622643003315
Validation loss: 2.5576175683949103

Epoch: 177| Step: 0
Training loss: 2.980864212378135
Validation loss: 2.556648494475493

Epoch: 6| Step: 1
Training loss: 2.9579433309454175
Validation loss: 2.599776665401193

Epoch: 6| Step: 2
Training loss: 2.842126739339015
Validation loss: 2.608519351646188

Epoch: 6| Step: 3
Training loss: 3.467947927310629
Validation loss: 2.62412081213377

Epoch: 6| Step: 4
Training loss: 3.2499495282288855
Validation loss: 2.6340581260441436

Epoch: 6| Step: 5
Training loss: 2.713415063600305
Validation loss: 2.6575810069709602

Epoch: 6| Step: 6
Training loss: 3.0615700068726865
Validation loss: 2.662707890323614

Epoch: 6| Step: 7
Training loss: 2.768775998374517
Validation loss: 2.659267651829144

Epoch: 6| Step: 8
Training loss: 2.905226004077071
Validation loss: 2.638849679935905

Epoch: 6| Step: 9
Training loss: 2.9596459785314364
Validation loss: 2.5970067950162465

Epoch: 6| Step: 10
Training loss: 2.7994984518170525
Validation loss: 2.5766788169133834

Epoch: 6| Step: 11
Training loss: 2.3578601546682467
Validation loss: 2.582389902074377

Epoch: 6| Step: 12
Training loss: 2.7087854643763505
Validation loss: 2.567880367929197

Epoch: 6| Step: 13
Training loss: 2.4057224240277026
Validation loss: 2.585768417988611

Epoch: 178| Step: 0
Training loss: 2.6650521238572384
Validation loss: 2.575586568201166

Epoch: 6| Step: 1
Training loss: 3.4742105479193994
Validation loss: 2.5633712345953006

Epoch: 6| Step: 2
Training loss: 2.588537839174159
Validation loss: 2.5789262229500225

Epoch: 6| Step: 3
Training loss: 2.982908198008954
Validation loss: 2.5618678848241485

Epoch: 6| Step: 4
Training loss: 2.5680671322565476
Validation loss: 2.5485851153923877

Epoch: 6| Step: 5
Training loss: 3.1917660159060794
Validation loss: 2.5503992981519525

Epoch: 6| Step: 6
Training loss: 2.7715555172500106
Validation loss: 2.5512390434467704

Epoch: 6| Step: 7
Training loss: 2.6972082575305465
Validation loss: 2.547294185105871

Epoch: 6| Step: 8
Training loss: 2.91796352074498
Validation loss: 2.560336005854096

Epoch: 6| Step: 9
Training loss: 3.0522922969452337
Validation loss: 2.5712254475012326

Epoch: 6| Step: 10
Training loss: 2.403824512677713
Validation loss: 2.5788299342585734

Epoch: 6| Step: 11
Training loss: 2.9677703847364194
Validation loss: 2.5884914898836784

Epoch: 6| Step: 12
Training loss: 2.925712798556733
Validation loss: 2.6168538424067442

Epoch: 6| Step: 13
Training loss: 3.280980852986804
Validation loss: 2.645506549821988

Epoch: 179| Step: 0
Training loss: 2.5537452943434564
Validation loss: 2.657274092955912

Epoch: 6| Step: 1
Training loss: 3.2930427443402928
Validation loss: 2.6218314416396447

Epoch: 6| Step: 2
Training loss: 3.5207341347588645
Validation loss: 2.601590984493656

Epoch: 6| Step: 3
Training loss: 2.205151214604672
Validation loss: 2.587242734656023

Epoch: 6| Step: 4
Training loss: 2.9290297113111796
Validation loss: 2.5926907122418803

Epoch: 6| Step: 5
Training loss: 2.8598355615466624
Validation loss: 2.6225662062862924

Epoch: 6| Step: 6
Training loss: 2.700857633791128
Validation loss: 2.610030342184678

Epoch: 6| Step: 7
Training loss: 2.823174121185279
Validation loss: 2.5693068659196574

Epoch: 6| Step: 8
Training loss: 2.6322372215526744
Validation loss: 2.563863956023533

Epoch: 6| Step: 9
Training loss: 2.6997933555927633
Validation loss: 2.559056995609981

Epoch: 6| Step: 10
Training loss: 3.360213773829719
Validation loss: 2.5540244446315383

Epoch: 6| Step: 11
Training loss: 2.9450097371120134
Validation loss: 2.5596066294035484

Epoch: 6| Step: 12
Training loss: 2.8799766921053913
Validation loss: 2.5535505131120053

Epoch: 6| Step: 13
Training loss: 3.1355784090385166
Validation loss: 2.5608510905725463

Epoch: 180| Step: 0
Training loss: 2.8038964816369965
Validation loss: 2.556461884719379

Epoch: 6| Step: 1
Training loss: 2.697636141731095
Validation loss: 2.564268515361026

Epoch: 6| Step: 2
Training loss: 2.7000337245389106
Validation loss: 2.5791327343179917

Epoch: 6| Step: 3
Training loss: 2.6587541332849423
Validation loss: 2.597213757021351

Epoch: 6| Step: 4
Training loss: 2.8958236547806915
Validation loss: 2.5797566500691196

Epoch: 6| Step: 5
Training loss: 3.192342931218845
Validation loss: 2.594185652347947

Epoch: 6| Step: 6
Training loss: 2.7783776356125127
Validation loss: 2.5803914061695745

Epoch: 6| Step: 7
Training loss: 2.894227788052582
Validation loss: 2.5752900716563167

Epoch: 6| Step: 8
Training loss: 3.32185683294803
Validation loss: 2.571119891626775

Epoch: 6| Step: 9
Training loss: 2.33867737192961
Validation loss: 2.5669819942457925

Epoch: 6| Step: 10
Training loss: 2.978858842930211
Validation loss: 2.562730147568495

Epoch: 6| Step: 11
Training loss: 2.6382010807218195
Validation loss: 2.567053880543857

Epoch: 6| Step: 12
Training loss: 3.1919180974371932
Validation loss: 2.5701864509433765

Epoch: 6| Step: 13
Training loss: 3.2685189451754297
Validation loss: 2.590657177860386

Epoch: 181| Step: 0
Training loss: 2.250369889266937
Validation loss: 2.626033042543442

Epoch: 6| Step: 1
Training loss: 2.9741848638321136
Validation loss: 2.6464901125842335

Epoch: 6| Step: 2
Training loss: 3.363950797856287
Validation loss: 2.7065906026034936

Epoch: 6| Step: 3
Training loss: 3.3521595669824857
Validation loss: 2.723761569758889

Epoch: 6| Step: 4
Training loss: 2.897115153838316
Validation loss: 2.664805695143492

Epoch: 6| Step: 5
Training loss: 2.0449013549591264
Validation loss: 2.6108872608155145

Epoch: 6| Step: 6
Training loss: 2.9616703143193055
Validation loss: 2.57727834572317

Epoch: 6| Step: 7
Training loss: 2.9710809491203007
Validation loss: 2.5470661479385983

Epoch: 6| Step: 8
Training loss: 2.9363862219043075
Validation loss: 2.5452510534058823

Epoch: 6| Step: 9
Training loss: 3.3608281740703436
Validation loss: 2.5456802350997068

Epoch: 6| Step: 10
Training loss: 2.18128673446022
Validation loss: 2.541790057663124

Epoch: 6| Step: 11
Training loss: 3.250375285855676
Validation loss: 2.5409867540412896

Epoch: 6| Step: 12
Training loss: 2.4490270706929844
Validation loss: 2.5439565689536683

Epoch: 6| Step: 13
Training loss: 3.162254890924864
Validation loss: 2.5425509822956753

Epoch: 182| Step: 0
Training loss: 2.838639246578684
Validation loss: 2.545627449751726

Epoch: 6| Step: 1
Training loss: 2.4024083570771335
Validation loss: 2.5515204241820046

Epoch: 6| Step: 2
Training loss: 3.1860976780862575
Validation loss: 2.560459492058419

Epoch: 6| Step: 3
Training loss: 2.9754793694508024
Validation loss: 2.5543457356579538

Epoch: 6| Step: 4
Training loss: 3.1115671989127294
Validation loss: 2.5606029941094084

Epoch: 6| Step: 5
Training loss: 2.79779148536612
Validation loss: 2.5587247345151494

Epoch: 6| Step: 6
Training loss: 2.432701081828146
Validation loss: 2.568895125894729

Epoch: 6| Step: 7
Training loss: 2.4292867152113082
Validation loss: 2.594378583372414

Epoch: 6| Step: 8
Training loss: 2.8026937129563443
Validation loss: 2.6277157690607313

Epoch: 6| Step: 9
Training loss: 2.9721996944282814
Validation loss: 2.576586817155624

Epoch: 6| Step: 10
Training loss: 2.660947259155942
Validation loss: 2.5590548622948504

Epoch: 6| Step: 11
Training loss: 3.377651444660359
Validation loss: 2.547452177639635

Epoch: 6| Step: 12
Training loss: 3.171498093033286
Validation loss: 2.53726819168343

Epoch: 6| Step: 13
Training loss: 3.140307510042511
Validation loss: 2.5413267362866305

Epoch: 183| Step: 0
Training loss: 3.0268932376479913
Validation loss: 2.541966290685728

Epoch: 6| Step: 1
Training loss: 3.1632395486492437
Validation loss: 2.5381310972605178

Epoch: 6| Step: 2
Training loss: 3.105838470522971
Validation loss: 2.5349092527365062

Epoch: 6| Step: 3
Training loss: 2.6865280522952
Validation loss: 2.536375848755062

Epoch: 6| Step: 4
Training loss: 2.6744604261732854
Validation loss: 2.538160415827639

Epoch: 6| Step: 5
Training loss: 3.0788494361372774
Validation loss: 2.547734798710502

Epoch: 6| Step: 6
Training loss: 2.703147755786172
Validation loss: 2.5655653812141876

Epoch: 6| Step: 7
Training loss: 2.6872670272272083
Validation loss: 2.5858138762178693

Epoch: 6| Step: 8
Training loss: 2.555026530596503
Validation loss: 2.6073129744642283

Epoch: 6| Step: 9
Training loss: 2.7967547172383163
Validation loss: 2.601234525482632

Epoch: 6| Step: 10
Training loss: 3.17497154883906
Validation loss: 2.6050027164003153

Epoch: 6| Step: 11
Training loss: 3.4481990425826736
Validation loss: 2.6029538483492662

Epoch: 6| Step: 12
Training loss: 2.3215232284865968
Validation loss: 2.609744859174366

Epoch: 6| Step: 13
Training loss: 3.228158034444584
Validation loss: 2.594247481921343

Epoch: 184| Step: 0
Training loss: 2.7128251509321477
Validation loss: 2.5666594263759603

Epoch: 6| Step: 1
Training loss: 3.0064345336871514
Validation loss: 2.555005478773706

Epoch: 6| Step: 2
Training loss: 3.281106854904049
Validation loss: 2.5442051475305627

Epoch: 6| Step: 3
Training loss: 3.446644220727945
Validation loss: 2.5496564672718414

Epoch: 6| Step: 4
Training loss: 2.768202189723449
Validation loss: 2.5455232384021556

Epoch: 6| Step: 5
Training loss: 3.1252732729636112
Validation loss: 2.5417480765030125

Epoch: 6| Step: 6
Training loss: 2.9559167653961764
Validation loss: 2.525858632036177

Epoch: 6| Step: 7
Training loss: 2.76072266999866
Validation loss: 2.524815154277212

Epoch: 6| Step: 8
Training loss: 2.630141808200443
Validation loss: 2.5336153106486936

Epoch: 6| Step: 9
Training loss: 2.454106808651874
Validation loss: 2.535013626353911

Epoch: 6| Step: 10
Training loss: 2.335935764886218
Validation loss: 2.5412431014658643

Epoch: 6| Step: 11
Training loss: 2.5975453747484285
Validation loss: 2.55637597270755

Epoch: 6| Step: 12
Training loss: 2.7035836067796493
Validation loss: 2.5555378506947637

Epoch: 6| Step: 13
Training loss: 3.636757691663487
Validation loss: 2.5587092207197792

Epoch: 185| Step: 0
Training loss: 2.5432430652616485
Validation loss: 2.55506855144664

Epoch: 6| Step: 1
Training loss: 2.522684274224227
Validation loss: 2.556199835531699

Epoch: 6| Step: 2
Training loss: 2.6198214357983924
Validation loss: 2.5546587112980763

Epoch: 6| Step: 3
Training loss: 2.8234698514874035
Validation loss: 2.5517120489713587

Epoch: 6| Step: 4
Training loss: 3.058198204138891
Validation loss: 2.558827353237518

Epoch: 6| Step: 5
Training loss: 2.699113636758056
Validation loss: 2.5702971598767137

Epoch: 6| Step: 6
Training loss: 2.7719289195978196
Validation loss: 2.6034202516673406

Epoch: 6| Step: 7
Training loss: 2.7803645921294633
Validation loss: 2.6235932263953274

Epoch: 6| Step: 8
Training loss: 3.64122547878674
Validation loss: 2.63937631796238

Epoch: 6| Step: 9
Training loss: 3.1224974720977494
Validation loss: 2.6363726406899666

Epoch: 6| Step: 10
Training loss: 3.201299379705975
Validation loss: 2.612701914405547

Epoch: 6| Step: 11
Training loss: 2.671428085338761
Validation loss: 2.6096854921370696

Epoch: 6| Step: 12
Training loss: 2.642523179254852
Validation loss: 2.614188426535271

Epoch: 6| Step: 13
Training loss: 2.9593638563903015
Validation loss: 2.616533680970729

Epoch: 186| Step: 0
Training loss: 3.168156139697109
Validation loss: 2.590832639776771

Epoch: 6| Step: 1
Training loss: 2.5678580487433673
Validation loss: 2.5559307383715844

Epoch: 6| Step: 2
Training loss: 2.583294765635716
Validation loss: 2.5593059751805383

Epoch: 6| Step: 3
Training loss: 2.719005791919259
Validation loss: 2.5529104038198263

Epoch: 6| Step: 4
Training loss: 3.3304982208444205
Validation loss: 2.551698588303709

Epoch: 6| Step: 5
Training loss: 3.129660069102126
Validation loss: 2.5532824219257533

Epoch: 6| Step: 6
Training loss: 3.653396144753937
Validation loss: 2.552130420510764

Epoch: 6| Step: 7
Training loss: 2.5184045445867733
Validation loss: 2.5571155858812316

Epoch: 6| Step: 8
Training loss: 2.6417160940108992
Validation loss: 2.559820020803603

Epoch: 6| Step: 9
Training loss: 2.883333980876284
Validation loss: 2.556955665860427

Epoch: 6| Step: 10
Training loss: 2.581744341124044
Validation loss: 2.5708869027694816

Epoch: 6| Step: 11
Training loss: 2.290402693844356
Validation loss: 2.5849108098919618

Epoch: 6| Step: 12
Training loss: 2.679899602119715
Validation loss: 2.597175606353917

Epoch: 6| Step: 13
Training loss: 3.5495072734762
Validation loss: 2.644569624869604

Epoch: 187| Step: 0
Training loss: 2.792945616299517
Validation loss: 2.663812927020828

Epoch: 6| Step: 1
Training loss: 3.0880302190142053
Validation loss: 2.6657594943818044

Epoch: 6| Step: 2
Training loss: 3.435761306776289
Validation loss: 2.6222727828649144

Epoch: 6| Step: 3
Training loss: 2.9070950171784564
Validation loss: 2.57119622778445

Epoch: 6| Step: 4
Training loss: 3.1455995249649886
Validation loss: 2.54712666045082

Epoch: 6| Step: 5
Training loss: 3.090737465566218
Validation loss: 2.5500677839290433

Epoch: 6| Step: 6
Training loss: 3.034771319199993
Validation loss: 2.5574264101571624

Epoch: 6| Step: 7
Training loss: 2.7028092216430357
Validation loss: 2.5691431375683487

Epoch: 6| Step: 8
Training loss: 2.8009232361368714
Validation loss: 2.5741892664855732

Epoch: 6| Step: 9
Training loss: 2.984247174945781
Validation loss: 2.5801759340047474

Epoch: 6| Step: 10
Training loss: 2.6022808011222396
Validation loss: 2.581115215635749

Epoch: 6| Step: 11
Training loss: 3.0810929140358416
Validation loss: 2.5875116111507137

Epoch: 6| Step: 12
Training loss: 2.766638618541545
Validation loss: 2.578468623525383

Epoch: 6| Step: 13
Training loss: 3.0712962042842245
Validation loss: 2.5686411808083367

Epoch: 188| Step: 0
Training loss: 2.5597022065168757
Validation loss: 2.564351641654272

Epoch: 6| Step: 1
Training loss: 3.0873173586303677
Validation loss: 2.5544153772089158

Epoch: 6| Step: 2
Training loss: 2.8518738459096324
Validation loss: 2.5507509036009113

Epoch: 6| Step: 3
Training loss: 2.7835615174951114
Validation loss: 2.554335467408165

Epoch: 6| Step: 4
Training loss: 3.3430970882520734
Validation loss: 2.5513027824915517

Epoch: 6| Step: 5
Training loss: 2.8795663809181855
Validation loss: 2.548107375248705

Epoch: 6| Step: 6
Training loss: 3.2100687824141074
Validation loss: 2.5457399618386396

Epoch: 6| Step: 7
Training loss: 2.929987289349063
Validation loss: 2.547870594645445

Epoch: 6| Step: 8
Training loss: 2.4371771965488946
Validation loss: 2.572519482365705

Epoch: 6| Step: 9
Training loss: 2.6324027900100204
Validation loss: 2.60453234035084

Epoch: 6| Step: 10
Training loss: 2.9653516090685224
Validation loss: 2.630552347875904

Epoch: 6| Step: 11
Training loss: 2.9212023934960567
Validation loss: 2.6756732499414295

Epoch: 6| Step: 12
Training loss: 2.9415810015112873
Validation loss: 2.6410905204744988

Epoch: 6| Step: 13
Training loss: 2.9669780060634685
Validation loss: 2.6183190348685756

Epoch: 189| Step: 0
Training loss: 2.9807048819058855
Validation loss: 2.607701954568895

Epoch: 6| Step: 1
Training loss: 3.193848813314364
Validation loss: 2.5719380391842925

Epoch: 6| Step: 2
Training loss: 3.307859517206148
Validation loss: 2.549008368093959

Epoch: 6| Step: 3
Training loss: 2.980233719384398
Validation loss: 2.54360033497846

Epoch: 6| Step: 4
Training loss: 3.218877993510996
Validation loss: 2.5336721795659343

Epoch: 6| Step: 5
Training loss: 2.3448888427807315
Validation loss: 2.541374370955707

Epoch: 6| Step: 6
Training loss: 3.254754330319329
Validation loss: 2.53470023671938

Epoch: 6| Step: 7
Training loss: 2.8240448408808354
Validation loss: 2.542800317311978

Epoch: 6| Step: 8
Training loss: 3.425999215824641
Validation loss: 2.5585638569771176

Epoch: 6| Step: 9
Training loss: 2.1340739673212004
Validation loss: 2.5701131191347253

Epoch: 6| Step: 10
Training loss: 2.5920544333217106
Validation loss: 2.588269917141527

Epoch: 6| Step: 11
Training loss: 2.3966853299252096
Validation loss: 2.6316552866218625

Epoch: 6| Step: 12
Training loss: 2.8174467876185365
Validation loss: 2.63015901382652

Epoch: 6| Step: 13
Training loss: 1.6194936921861602
Validation loss: 2.649030150551079

Epoch: 190| Step: 0
Training loss: 2.6651004324305316
Validation loss: 2.61761623710055

Epoch: 6| Step: 1
Training loss: 2.725038731151026
Validation loss: 2.6265134076891195

Epoch: 6| Step: 2
Training loss: 2.948943876884345
Validation loss: 2.621820249656484

Epoch: 6| Step: 3
Training loss: 2.410374858716729
Validation loss: 2.6073205356462172

Epoch: 6| Step: 4
Training loss: 3.3059743265123207
Validation loss: 2.5931791232529493

Epoch: 6| Step: 5
Training loss: 2.5823719532806138
Validation loss: 2.5689508580591487

Epoch: 6| Step: 6
Training loss: 2.5122731310394233
Validation loss: 2.5694040193475316

Epoch: 6| Step: 7
Training loss: 3.385029337317766
Validation loss: 2.5730391917390962

Epoch: 6| Step: 8
Training loss: 2.707838942568705
Validation loss: 2.5437068997941648

Epoch: 6| Step: 9
Training loss: 2.4870008111514497
Validation loss: 2.547759676944155

Epoch: 6| Step: 10
Training loss: 2.9753367385702316
Validation loss: 2.5394056105085916

Epoch: 6| Step: 11
Training loss: 2.8667810136330525
Validation loss: 2.5310025090992836

Epoch: 6| Step: 12
Training loss: 3.444301465529581
Validation loss: 2.537465648336769

Epoch: 6| Step: 13
Training loss: 2.348486729636982
Validation loss: 2.5390899207414863

Epoch: 191| Step: 0
Training loss: 2.8968692454391
Validation loss: 2.5318391904948085

Epoch: 6| Step: 1
Training loss: 2.704297643780134
Validation loss: 2.5357822570782402

Epoch: 6| Step: 2
Training loss: 2.594142930015869
Validation loss: 2.532362677802043

Epoch: 6| Step: 3
Training loss: 2.2143799634291588
Validation loss: 2.5387778279871913

Epoch: 6| Step: 4
Training loss: 2.9982121226344227
Validation loss: 2.544349733590041

Epoch: 6| Step: 5
Training loss: 3.1016813394758707
Validation loss: 2.5385521210912807

Epoch: 6| Step: 6
Training loss: 2.9412149516561525
Validation loss: 2.5634306831531894

Epoch: 6| Step: 7
Training loss: 2.798647441475697
Validation loss: 2.5692254555624876

Epoch: 6| Step: 8
Training loss: 2.7061093124223214
Validation loss: 2.591762560641926

Epoch: 6| Step: 9
Training loss: 3.2659030047635276
Validation loss: 2.5995899830028923

Epoch: 6| Step: 10
Training loss: 3.065525662273857
Validation loss: 2.598621504818224

Epoch: 6| Step: 11
Training loss: 2.718174928376329
Validation loss: 2.595401805778331

Epoch: 6| Step: 12
Training loss: 2.995988070577546
Validation loss: 2.6103612990758025

Epoch: 6| Step: 13
Training loss: 2.7154528915598073
Validation loss: 2.5900195382317603

Epoch: 192| Step: 0
Training loss: 2.7957382875784056
Validation loss: 2.588868618419173

Epoch: 6| Step: 1
Training loss: 2.429746571892939
Validation loss: 2.592781136003875

Epoch: 6| Step: 2
Training loss: 2.4421740980018547
Validation loss: 2.573419430548109

Epoch: 6| Step: 3
Training loss: 2.9611639172790007
Validation loss: 2.5661717622377345

Epoch: 6| Step: 4
Training loss: 2.7910053741501746
Validation loss: 2.551960504994406

Epoch: 6| Step: 5
Training loss: 3.3183889763798895
Validation loss: 2.557232687256452

Epoch: 6| Step: 6
Training loss: 2.8751983574150883
Validation loss: 2.5465122047295936

Epoch: 6| Step: 7
Training loss: 2.856183715318294
Validation loss: 2.5464610786314226

Epoch: 6| Step: 8
Training loss: 3.0297733131441578
Validation loss: 2.5517742988635264

Epoch: 6| Step: 9
Training loss: 2.906547613184749
Validation loss: 2.552117649138137

Epoch: 6| Step: 10
Training loss: 2.3907025891846274
Validation loss: 2.549512232441039

Epoch: 6| Step: 11
Training loss: 3.1339644980011254
Validation loss: 2.5681751684400194

Epoch: 6| Step: 12
Training loss: 3.0608836988595853
Validation loss: 2.5572809524433655

Epoch: 6| Step: 13
Training loss: 2.483348994451035
Validation loss: 2.5816002893299435

Epoch: 193| Step: 0
Training loss: 3.413452093869717
Validation loss: 2.5682560276421733

Epoch: 6| Step: 1
Training loss: 2.6770652641745407
Validation loss: 2.5817378678284553

Epoch: 6| Step: 2
Training loss: 2.7848646698813253
Validation loss: 2.6036739002926623

Epoch: 6| Step: 3
Training loss: 3.0722704364135085
Validation loss: 2.6437479779449484

Epoch: 6| Step: 4
Training loss: 2.489292388472354
Validation loss: 2.658673879519559

Epoch: 6| Step: 5
Training loss: 2.529588035998442
Validation loss: 2.6371905263233026

Epoch: 6| Step: 6
Training loss: 2.7096718243864926
Validation loss: 2.6130507783386556

Epoch: 6| Step: 7
Training loss: 2.6904110778054204
Validation loss: 2.5777101075367055

Epoch: 6| Step: 8
Training loss: 3.10140322028827
Validation loss: 2.5470880182415185

Epoch: 6| Step: 9
Training loss: 3.1355151459868424
Validation loss: 2.5285272106716854

Epoch: 6| Step: 10
Training loss: 2.647682825103149
Validation loss: 2.5398820925867036

Epoch: 6| Step: 11
Training loss: 2.4084605182296626
Validation loss: 2.5418106864042693

Epoch: 6| Step: 12
Training loss: 3.3854279659767363
Validation loss: 2.5396331897968425

Epoch: 6| Step: 13
Training loss: 2.4839083635194386
Validation loss: 2.5383845810220698

Epoch: 194| Step: 0
Training loss: 2.968067612775003
Validation loss: 2.5431516371851415

Epoch: 6| Step: 1
Training loss: 2.678480226689767
Validation loss: 2.536772136720885

Epoch: 6| Step: 2
Training loss: 3.308018658051463
Validation loss: 2.531422257623082

Epoch: 6| Step: 3
Training loss: 2.9489784799685097
Validation loss: 2.5340043232441887

Epoch: 6| Step: 4
Training loss: 2.7160371421555265
Validation loss: 2.533257226766858

Epoch: 6| Step: 5
Training loss: 2.447953622958374
Validation loss: 2.532744127337461

Epoch: 6| Step: 6
Training loss: 2.453308390183046
Validation loss: 2.5323992801109325

Epoch: 6| Step: 7
Training loss: 3.11029867130265
Validation loss: 2.546364613380253

Epoch: 6| Step: 8
Training loss: 3.3345040808506985
Validation loss: 2.5549613918960046

Epoch: 6| Step: 9
Training loss: 2.4347499103305235
Validation loss: 2.5640298861993718

Epoch: 6| Step: 10
Training loss: 2.203973052301456
Validation loss: 2.593880684806357

Epoch: 6| Step: 11
Training loss: 3.4479487360973584
Validation loss: 2.6027156323045766

Epoch: 6| Step: 12
Training loss: 3.3328781929820614
Validation loss: 2.62562544013272

Epoch: 6| Step: 13
Training loss: 2.367117802062832
Validation loss: 2.596417756765053

Epoch: 195| Step: 0
Training loss: 2.978362893112807
Validation loss: 2.5909421063504454

Epoch: 6| Step: 1
Training loss: 2.235646239689837
Validation loss: 2.568783585084559

Epoch: 6| Step: 2
Training loss: 2.6477427964010314
Validation loss: 2.554180878641152

Epoch: 6| Step: 3
Training loss: 2.7216790743013752
Validation loss: 2.5491310413302295

Epoch: 6| Step: 4
Training loss: 3.435467483271131
Validation loss: 2.5448522859418214

Epoch: 6| Step: 5
Training loss: 2.7145437390437532
Validation loss: 2.5357522285910554

Epoch: 6| Step: 6
Training loss: 2.1527416048463244
Validation loss: 2.5500604430532507

Epoch: 6| Step: 7
Training loss: 2.8547783263508464
Validation loss: 2.574033488732579

Epoch: 6| Step: 8
Training loss: 2.654560314632119
Validation loss: 2.594370100072798

Epoch: 6| Step: 9
Training loss: 3.006153312920632
Validation loss: 2.6171971406179013

Epoch: 6| Step: 10
Training loss: 3.1088458813896516
Validation loss: 2.657402385052998

Epoch: 6| Step: 11
Training loss: 3.2239849888568064
Validation loss: 2.6671752441512213

Epoch: 6| Step: 12
Training loss: 3.3321660541129425
Validation loss: 2.7073325972112516

Epoch: 6| Step: 13
Training loss: 2.2663682441983135
Validation loss: 2.6424120706300918

Epoch: 196| Step: 0
Training loss: 3.038130668818481
Validation loss: 2.6067867891789303

Epoch: 6| Step: 1
Training loss: 3.0951658149635763
Validation loss: 2.5379094299740874

Epoch: 6| Step: 2
Training loss: 2.930924218136821
Validation loss: 2.5320282690029257

Epoch: 6| Step: 3
Training loss: 2.6447265192286387
Validation loss: 2.5245196011877438

Epoch: 6| Step: 4
Training loss: 2.7340262926368037
Validation loss: 2.52393031193346

Epoch: 6| Step: 5
Training loss: 2.4629096953873595
Validation loss: 2.528323784330474

Epoch: 6| Step: 6
Training loss: 2.719987434189886
Validation loss: 2.528235711521877

Epoch: 6| Step: 7
Training loss: 3.0763640812968416
Validation loss: 2.532727796468932

Epoch: 6| Step: 8
Training loss: 3.118668512720826
Validation loss: 2.5298046440318904

Epoch: 6| Step: 9
Training loss: 2.711964525378985
Validation loss: 2.5241829071428685

Epoch: 6| Step: 10
Training loss: 2.4666242501332087
Validation loss: 2.5268634000422576

Epoch: 6| Step: 11
Training loss: 2.9478709798087555
Validation loss: 2.536732019959166

Epoch: 6| Step: 12
Training loss: 3.2572164379021307
Validation loss: 2.5325448823320267

Epoch: 6| Step: 13
Training loss: 2.6764330439039523
Validation loss: 2.536456123231992

Epoch: 197| Step: 0
Training loss: 3.246468312381302
Validation loss: 2.5374004932700815

Epoch: 6| Step: 1
Training loss: 2.98238893901673
Validation loss: 2.5419204618151063

Epoch: 6| Step: 2
Training loss: 2.516780800999714
Validation loss: 2.5432656569122525

Epoch: 6| Step: 3
Training loss: 2.1580958551183844
Validation loss: 2.554869443955973

Epoch: 6| Step: 4
Training loss: 2.1365847362495503
Validation loss: 2.5619549675626003

Epoch: 6| Step: 5
Training loss: 3.1132444908432144
Validation loss: 2.566936138602312

Epoch: 6| Step: 6
Training loss: 3.215719778074743
Validation loss: 2.5773831222062276

Epoch: 6| Step: 7
Training loss: 2.904642624531479
Validation loss: 2.5785878909135813

Epoch: 6| Step: 8
Training loss: 2.276614666238337
Validation loss: 2.590216581161338

Epoch: 6| Step: 9
Training loss: 3.4291213139578254
Validation loss: 2.5855881516002808

Epoch: 6| Step: 10
Training loss: 2.527347240416108
Validation loss: 2.5776129310077702

Epoch: 6| Step: 11
Training loss: 2.3204602538052113
Validation loss: 2.5860514722110333

Epoch: 6| Step: 12
Training loss: 2.8863576371520385
Validation loss: 2.567250728402119

Epoch: 6| Step: 13
Training loss: 3.7829389346964852
Validation loss: 2.5585571977812607

Epoch: 198| Step: 0
Training loss: 2.493113091766232
Validation loss: 2.542527711756206

Epoch: 6| Step: 1
Training loss: 1.9353672102025048
Validation loss: 2.525225453285416

Epoch: 6| Step: 2
Training loss: 3.253962228941499
Validation loss: 2.520942603922498

Epoch: 6| Step: 3
Training loss: 3.2205580290618405
Validation loss: 2.5225938876273144

Epoch: 6| Step: 4
Training loss: 2.6945025567760927
Validation loss: 2.5314793110026605

Epoch: 6| Step: 5
Training loss: 2.8897063574057573
Validation loss: 2.545134252908394

Epoch: 6| Step: 6
Training loss: 3.3526669263138604
Validation loss: 2.574175639520331

Epoch: 6| Step: 7
Training loss: 2.9015351474440263
Validation loss: 2.5817147667989837

Epoch: 6| Step: 8
Training loss: 2.998085682770002
Validation loss: 2.6122702391803374

Epoch: 6| Step: 9
Training loss: 2.5979054266944717
Validation loss: 2.650258417312986

Epoch: 6| Step: 10
Training loss: 3.0430687237869654
Validation loss: 2.6696227984180485

Epoch: 6| Step: 11
Training loss: 2.88142373974123
Validation loss: 2.696115763514741

Epoch: 6| Step: 12
Training loss: 2.3032137021668486
Validation loss: 2.7381712210437157

Epoch: 6| Step: 13
Training loss: 3.0037011521741417
Validation loss: 2.683986063573554

Epoch: 199| Step: 0
Training loss: 2.227696715465867
Validation loss: 2.6655577323370077

Epoch: 6| Step: 1
Training loss: 2.659739188551566
Validation loss: 2.639481658794184

Epoch: 6| Step: 2
Training loss: 2.6878110129018857
Validation loss: 2.6046975941215167

Epoch: 6| Step: 3
Training loss: 2.8192206723547506
Validation loss: 2.582865502638517

Epoch: 6| Step: 4
Training loss: 3.1086314476854704
Validation loss: 2.5447035757650074

Epoch: 6| Step: 5
Training loss: 3.1333107873091945
Validation loss: 2.5286011584458934

Epoch: 6| Step: 6
Training loss: 2.086194197615259
Validation loss: 2.5199442578456583

Epoch: 6| Step: 7
Training loss: 3.1482796830600286
Validation loss: 2.5312811048088664

Epoch: 6| Step: 8
Training loss: 2.744183979167092
Validation loss: 2.541744532233792

Epoch: 6| Step: 9
Training loss: 3.225831473161192
Validation loss: 2.5342970166428587

Epoch: 6| Step: 10
Training loss: 2.911806434926185
Validation loss: 2.551780222274406

Epoch: 6| Step: 11
Training loss: 2.9922796090791937
Validation loss: 2.5673763439340824

Epoch: 6| Step: 12
Training loss: 2.5024489805525616
Validation loss: 2.5840929282785035

Epoch: 6| Step: 13
Training loss: 3.439772530952776
Validation loss: 2.6255920189857207

Epoch: 200| Step: 0
Training loss: 2.430504958822014
Validation loss: 2.6014567786703

Epoch: 6| Step: 1
Training loss: 3.216484087043203
Validation loss: 2.5519393394754126

Epoch: 6| Step: 2
Training loss: 2.6563258440746087
Validation loss: 2.5401865773174475

Epoch: 6| Step: 3
Training loss: 3.099487071517858
Validation loss: 2.52594122898946

Epoch: 6| Step: 4
Training loss: 2.1151580655888433
Validation loss: 2.530210153036676

Epoch: 6| Step: 5
Training loss: 2.857429551318295
Validation loss: 2.532320684109801

Epoch: 6| Step: 6
Training loss: 2.5674021282318273
Validation loss: 2.548892606759512

Epoch: 6| Step: 7
Training loss: 2.980782628561726
Validation loss: 2.5603693376032948

Epoch: 6| Step: 8
Training loss: 2.765981791267398
Validation loss: 2.5916302011461596

Epoch: 6| Step: 9
Training loss: 2.4482266060782596
Validation loss: 2.5926671966031662

Epoch: 6| Step: 10
Training loss: 2.8897416698270733
Validation loss: 2.6027012790368262

Epoch: 6| Step: 11
Training loss: 3.3984421302500785
Validation loss: 2.624615366150893

Epoch: 6| Step: 12
Training loss: 2.962181775992729
Validation loss: 2.5962766894827536

Epoch: 6| Step: 13
Training loss: 3.1771894760328303
Validation loss: 2.5705043186166203

Epoch: 201| Step: 0
Training loss: 3.0731494018007934
Validation loss: 2.5614250203324933

Epoch: 6| Step: 1
Training loss: 2.895605796455518
Validation loss: 2.5468040077435874

Epoch: 6| Step: 2
Training loss: 2.981860794420532
Validation loss: 2.548526564873509

Epoch: 6| Step: 3
Training loss: 2.6827120158373714
Validation loss: 2.546603690339264

Epoch: 6| Step: 4
Training loss: 2.6389307308783736
Validation loss: 2.54461735743904

Epoch: 6| Step: 5
Training loss: 3.0425202378263663
Validation loss: 2.5450160277397216

Epoch: 6| Step: 6
Training loss: 2.3793611138602198
Validation loss: 2.53958324762235

Epoch: 6| Step: 7
Training loss: 1.9974792211070114
Validation loss: 2.5503043816461592

Epoch: 6| Step: 8
Training loss: 2.555218842572013
Validation loss: 2.5441130557094143

Epoch: 6| Step: 9
Training loss: 2.8479954814446424
Validation loss: 2.55058967589411

Epoch: 6| Step: 10
Training loss: 3.148023251526405
Validation loss: 2.5979028422362016

Epoch: 6| Step: 11
Training loss: 3.3892754888373116
Validation loss: 2.678492320895135

Epoch: 6| Step: 12
Training loss: 3.054622249442964
Validation loss: 2.7440499683233566

Epoch: 6| Step: 13
Training loss: 3.3217432866221372
Validation loss: 2.6452228467448253

Epoch: 202| Step: 0
Training loss: 2.5328959070647556
Validation loss: 2.5644568878047003

Epoch: 6| Step: 1
Training loss: 3.4009196720569115
Validation loss: 2.536556528955026

Epoch: 6| Step: 2
Training loss: 2.860351729205782
Validation loss: 2.523943478852815

Epoch: 6| Step: 3
Training loss: 2.325670010408711
Validation loss: 2.5207511968476712

Epoch: 6| Step: 4
Training loss: 2.825391934643862
Validation loss: 2.530667616655278

Epoch: 6| Step: 5
Training loss: 2.7766059077813807
Validation loss: 2.530271341214834

Epoch: 6| Step: 6
Training loss: 2.394926203504641
Validation loss: 2.53515186932294

Epoch: 6| Step: 7
Training loss: 2.247962452938068
Validation loss: 2.528670914918445

Epoch: 6| Step: 8
Training loss: 2.6820517028330983
Validation loss: 2.5328619425163663

Epoch: 6| Step: 9
Training loss: 2.722526645722668
Validation loss: 2.5484434837182084

Epoch: 6| Step: 10
Training loss: 3.558283535849354
Validation loss: 2.564974526730986

Epoch: 6| Step: 11
Training loss: 3.182552012747439
Validation loss: 2.5921159853780917

Epoch: 6| Step: 12
Training loss: 3.052739998195397
Validation loss: 2.6382143789248764

Epoch: 6| Step: 13
Training loss: 3.32576872465048
Validation loss: 2.598515010718032

Epoch: 203| Step: 0
Training loss: 2.4366091543038664
Validation loss: 2.5599111089347772

Epoch: 6| Step: 1
Training loss: 2.5497624230507174
Validation loss: 2.553125519671555

Epoch: 6| Step: 2
Training loss: 2.9020448841433377
Validation loss: 2.54124463687972

Epoch: 6| Step: 3
Training loss: 2.7650173403315184
Validation loss: 2.5371219470783157

Epoch: 6| Step: 4
Training loss: 3.130690314856163
Validation loss: 2.5326193985962404

Epoch: 6| Step: 5
Training loss: 3.134532579927812
Validation loss: 2.531125854461901

Epoch: 6| Step: 6
Training loss: 2.817061814875447
Validation loss: 2.527174623876806

Epoch: 6| Step: 7
Training loss: 2.4313265555520647
Validation loss: 2.543231032494872

Epoch: 6| Step: 8
Training loss: 2.2485400867718743
Validation loss: 2.544437340316901

Epoch: 6| Step: 9
Training loss: 3.173380677593969
Validation loss: 2.5555546708021493

Epoch: 6| Step: 10
Training loss: 3.156222806001352
Validation loss: 2.5718919728672907

Epoch: 6| Step: 11
Training loss: 2.684004972842708
Validation loss: 2.580011286681037

Epoch: 6| Step: 12
Training loss: 2.616975781431801
Validation loss: 2.561984547841836

Epoch: 6| Step: 13
Training loss: 3.369594625208264
Validation loss: 2.5691932350515

Epoch: 204| Step: 0
Training loss: 3.169316956250549
Validation loss: 2.6113048724266403

Epoch: 6| Step: 1
Training loss: 3.1313425929832954
Validation loss: 2.7082298700781173

Epoch: 6| Step: 2
Training loss: 2.7185184774803983
Validation loss: 2.732557965649768

Epoch: 6| Step: 3
Training loss: 2.7751224181520318
Validation loss: 2.790580693176737

Epoch: 6| Step: 4
Training loss: 3.160391931975572
Validation loss: 2.821953474352782

Epoch: 6| Step: 5
Training loss: 2.6318670097597576
Validation loss: 2.7496495568951906

Epoch: 6| Step: 6
Training loss: 2.978926873504616
Validation loss: 2.6903231817063182

Epoch: 6| Step: 7
Training loss: 2.735104621545948
Validation loss: 2.5978286388657437

Epoch: 6| Step: 8
Training loss: 2.7034890695939686
Validation loss: 2.5672952538152214

Epoch: 6| Step: 9
Training loss: 2.6297640485042884
Validation loss: 2.5552929639961204

Epoch: 6| Step: 10
Training loss: 2.7267256636015764
Validation loss: 2.5553949901814033

Epoch: 6| Step: 11
Training loss: 2.7903529155212534
Validation loss: 2.551221501527855

Epoch: 6| Step: 12
Training loss: 3.069043855912483
Validation loss: 2.5556582594376445

Epoch: 6| Step: 13
Training loss: 2.4491737763140597
Validation loss: 2.546654185412325

Epoch: 205| Step: 0
Training loss: 3.1953896510876154
Validation loss: 2.5423935856487967

Epoch: 6| Step: 1
Training loss: 3.0192904160405045
Validation loss: 2.5382080882037714

Epoch: 6| Step: 2
Training loss: 3.0747569290481307
Validation loss: 2.539360619800321

Epoch: 6| Step: 3
Training loss: 2.3310287084198555
Validation loss: 2.539233197831364

Epoch: 6| Step: 4
Training loss: 3.3798157983731327
Validation loss: 2.5366315767139755

Epoch: 6| Step: 5
Training loss: 2.5118231625605305
Validation loss: 2.5483123017206464

Epoch: 6| Step: 6
Training loss: 3.0642909827045752
Validation loss: 2.541711267906735

Epoch: 6| Step: 7
Training loss: 2.8705838328008633
Validation loss: 2.5540170699586056

Epoch: 6| Step: 8
Training loss: 2.4253646812335456
Validation loss: 2.5653256579869224

Epoch: 6| Step: 9
Training loss: 3.0730113041847034
Validation loss: 2.602161633492351

Epoch: 6| Step: 10
Training loss: 2.946290842775813
Validation loss: 2.620462099937433

Epoch: 6| Step: 11
Training loss: 3.2184282160527933
Validation loss: 2.585359474125916

Epoch: 6| Step: 12
Training loss: 2.51648218939815
Validation loss: 2.5560374771559147

Epoch: 6| Step: 13
Training loss: 1.2905244801980622
Validation loss: 2.530717855322434

Epoch: 206| Step: 0
Training loss: 2.8782767820150164
Validation loss: 2.525913195593387

Epoch: 6| Step: 1
Training loss: 2.7632524043964626
Validation loss: 2.523669496685893

Epoch: 6| Step: 2
Training loss: 3.2656702649935565
Validation loss: 2.5131427765698127

Epoch: 6| Step: 3
Training loss: 2.3701135661282593
Validation loss: 2.513386339635249

Epoch: 6| Step: 4
Training loss: 2.597112291789585
Validation loss: 2.521024144706468

Epoch: 6| Step: 5
Training loss: 2.5427648225224195
Validation loss: 2.5192286679899425

Epoch: 6| Step: 6
Training loss: 2.9161178254130773
Validation loss: 2.52249410200615

Epoch: 6| Step: 7
Training loss: 2.783883209124603
Validation loss: 2.5202606012937294

Epoch: 6| Step: 8
Training loss: 2.7648836855713785
Validation loss: 2.532239290432621

Epoch: 6| Step: 9
Training loss: 2.927198975655501
Validation loss: 2.536683771072711

Epoch: 6| Step: 10
Training loss: 3.026797140672981
Validation loss: 2.5475988606933906

Epoch: 6| Step: 11
Training loss: 2.953700741144455
Validation loss: 2.5881753162411885

Epoch: 6| Step: 12
Training loss: 2.6652023248647745
Validation loss: 2.6104177987832204

Epoch: 6| Step: 13
Training loss: 3.127219823153892
Validation loss: 2.614600950530718

Epoch: 207| Step: 0
Training loss: 2.705992131799056
Validation loss: 2.573844190149382

Epoch: 6| Step: 1
Training loss: 2.457627944176968
Validation loss: 2.5372164387733664

Epoch: 6| Step: 2
Training loss: 2.6903756304120146
Validation loss: 2.5360512085926015

Epoch: 6| Step: 3
Training loss: 2.689884813246232
Validation loss: 2.5317047958334307

Epoch: 6| Step: 4
Training loss: 3.380924252879815
Validation loss: 2.536368469262185

Epoch: 6| Step: 5
Training loss: 3.039051830596631
Validation loss: 2.531269022268639

Epoch: 6| Step: 6
Training loss: 2.1933830715132454
Validation loss: 2.5354265004849013

Epoch: 6| Step: 7
Training loss: 2.7047918395439736
Validation loss: 2.536252618213975

Epoch: 6| Step: 8
Training loss: 2.989805064911737
Validation loss: 2.5403443286887395

Epoch: 6| Step: 9
Training loss: 3.01505886950359
Validation loss: 2.533371118038152

Epoch: 6| Step: 10
Training loss: 2.790781554543577
Validation loss: 2.529505866734941

Epoch: 6| Step: 11
Training loss: 2.5446595461496506
Validation loss: 2.538689038346179

Epoch: 6| Step: 12
Training loss: 3.056780866141837
Validation loss: 2.540188241542454

Epoch: 6| Step: 13
Training loss: 2.7585622832675907
Validation loss: 2.541813821094915

Epoch: 208| Step: 0
Training loss: 2.9504799274640328
Validation loss: 2.5601009781211097

Epoch: 6| Step: 1
Training loss: 2.8021949169153944
Validation loss: 2.5779193556263005

Epoch: 6| Step: 2
Training loss: 2.679456695314905
Validation loss: 2.58835955243476

Epoch: 6| Step: 3
Training loss: 2.981506247074249
Validation loss: 2.610662832101811

Epoch: 6| Step: 4
Training loss: 2.8785618818057834
Validation loss: 2.6226659399565917

Epoch: 6| Step: 5
Training loss: 2.2469976314774964
Validation loss: 2.6160044670909786

Epoch: 6| Step: 6
Training loss: 3.0275543336536668
Validation loss: 2.6059230179602406

Epoch: 6| Step: 7
Training loss: 2.7698841811662804
Validation loss: 2.5759383558211897

Epoch: 6| Step: 8
Training loss: 3.0108874171812583
Validation loss: 2.565543402621196

Epoch: 6| Step: 9
Training loss: 3.3241318221779084
Validation loss: 2.538449833030684

Epoch: 6| Step: 10
Training loss: 2.8433757158394988
Validation loss: 2.5499488886971498

Epoch: 6| Step: 11
Training loss: 2.4811088156709684
Validation loss: 2.529248811670014

Epoch: 6| Step: 12
Training loss: 2.145081051804578
Validation loss: 2.525546024886211

Epoch: 6| Step: 13
Training loss: 2.873543743681412
Validation loss: 2.522660562296148

Epoch: 209| Step: 0
Training loss: 2.0865545038947313
Validation loss: 2.5161189590036326

Epoch: 6| Step: 1
Training loss: 3.06741219317949
Validation loss: 2.517196963093671

Epoch: 6| Step: 2
Training loss: 2.77423479681979
Validation loss: 2.519159018449933

Epoch: 6| Step: 3
Training loss: 2.825944259957755
Validation loss: 2.528099704603056

Epoch: 6| Step: 4
Training loss: 3.1252163621388944
Validation loss: 2.5329672385223474

Epoch: 6| Step: 5
Training loss: 3.14199662503766
Validation loss: 2.540434072638862

Epoch: 6| Step: 6
Training loss: 3.1071171062636394
Validation loss: 2.5493010167154613

Epoch: 6| Step: 7
Training loss: 2.876112681148478
Validation loss: 2.5563753770194624

Epoch: 6| Step: 8
Training loss: 2.7696336907513284
Validation loss: 2.5602642753873073

Epoch: 6| Step: 9
Training loss: 2.1236552302976137
Validation loss: 2.5792059627521797

Epoch: 6| Step: 10
Training loss: 1.9170985219091634
Validation loss: 2.5736639063584197

Epoch: 6| Step: 11
Training loss: 3.023214642495165
Validation loss: 2.5819073706716873

Epoch: 6| Step: 12
Training loss: 3.239529101213234
Validation loss: 2.57229523122329

Epoch: 6| Step: 13
Training loss: 2.540973214360717
Validation loss: 2.55197769525684

Epoch: 210| Step: 0
Training loss: 2.61472708217003
Validation loss: 2.571736378940426

Epoch: 6| Step: 1
Training loss: 2.911808236284632
Validation loss: 2.5536133255633255

Epoch: 6| Step: 2
Training loss: 2.4834636240154317
Validation loss: 2.5542087222319605

Epoch: 6| Step: 3
Training loss: 2.9481223386227255
Validation loss: 2.555848846782732

Epoch: 6| Step: 4
Training loss: 2.442821269620448
Validation loss: 2.564521474427018

Epoch: 6| Step: 5
Training loss: 2.6488591311459495
Validation loss: 2.563884325168242

Epoch: 6| Step: 6
Training loss: 2.508723678716886
Validation loss: 2.5670979914348835

Epoch: 6| Step: 7
Training loss: 3.1411334333184007
Validation loss: 2.5741511848973233

Epoch: 6| Step: 8
Training loss: 3.3706838064582856
Validation loss: 2.5783726488423575

Epoch: 6| Step: 9
Training loss: 2.665129864446844
Validation loss: 2.5703960192809436

Epoch: 6| Step: 10
Training loss: 2.228860626128145
Validation loss: 2.5657078952554158

Epoch: 6| Step: 11
Training loss: 2.999600224879015
Validation loss: 2.5518458289573327

Epoch: 6| Step: 12
Training loss: 2.6597196469959865
Validation loss: 2.565559007991193

Epoch: 6| Step: 13
Training loss: 3.2210941112073077
Validation loss: 2.5512660198027555

Epoch: 211| Step: 0
Training loss: 2.8361079897745585
Validation loss: 2.5386802952356566

Epoch: 6| Step: 1
Training loss: 2.6211324993060647
Validation loss: 2.5435966350530084

Epoch: 6| Step: 2
Training loss: 3.1106477365856597
Validation loss: 2.5297655163094

Epoch: 6| Step: 3
Training loss: 2.7217366267702925
Validation loss: 2.5331167783723916

Epoch: 6| Step: 4
Training loss: 2.274777780935254
Validation loss: 2.5328572876262125

Epoch: 6| Step: 5
Training loss: 2.595356455229167
Validation loss: 2.5368903499411797

Epoch: 6| Step: 6
Training loss: 2.6803652959931785
Validation loss: 2.56672718469235

Epoch: 6| Step: 7
Training loss: 2.2096653166175195
Validation loss: 2.5836022399476875

Epoch: 6| Step: 8
Training loss: 3.130019467326797
Validation loss: 2.583750735397786

Epoch: 6| Step: 9
Training loss: 3.330621919950871
Validation loss: 2.5894148182523717

Epoch: 6| Step: 10
Training loss: 2.8443973349438445
Validation loss: 2.5920636630089846

Epoch: 6| Step: 11
Training loss: 3.2909646231211247
Validation loss: 2.5658502005541393

Epoch: 6| Step: 12
Training loss: 2.3903464360720057
Validation loss: 2.5701097925313205

Epoch: 6| Step: 13
Training loss: 2.8391167760939915
Validation loss: 2.566337446301043

Epoch: 212| Step: 0
Training loss: 2.6423217017473295
Validation loss: 2.5739889787869745

Epoch: 6| Step: 1
Training loss: 2.3084782863601276
Validation loss: 2.5708462543421784

Epoch: 6| Step: 2
Training loss: 2.4356244035876227
Validation loss: 2.5992410542059887

Epoch: 6| Step: 3
Training loss: 3.2690394315351474
Validation loss: 2.6038653475448115

Epoch: 6| Step: 4
Training loss: 2.238514939603187
Validation loss: 2.591118962818525

Epoch: 6| Step: 5
Training loss: 2.616038329214041
Validation loss: 2.5937812339739534

Epoch: 6| Step: 6
Training loss: 2.9458559379807467
Validation loss: 2.592431684348957

Epoch: 6| Step: 7
Training loss: 3.138859646491237
Validation loss: 2.577017878589359

Epoch: 6| Step: 8
Training loss: 2.88423514476547
Validation loss: 2.574195848394495

Epoch: 6| Step: 9
Training loss: 2.713348108418545
Validation loss: 2.558391584036702

Epoch: 6| Step: 10
Training loss: 3.1562397267391593
Validation loss: 2.533848209781122

Epoch: 6| Step: 11
Training loss: 3.199021702474879
Validation loss: 2.533704542174206

Epoch: 6| Step: 12
Training loss: 2.9275615658952305
Validation loss: 2.526534642706426

Epoch: 6| Step: 13
Training loss: 1.2671143986963234
Validation loss: 2.528684185909012

Epoch: 213| Step: 0
Training loss: 2.334487516048319
Validation loss: 2.5261157068215088

Epoch: 6| Step: 1
Training loss: 3.146374653774414
Validation loss: 2.519999232276595

Epoch: 6| Step: 2
Training loss: 2.394465534248123
Validation loss: 2.5059536132811697

Epoch: 6| Step: 3
Training loss: 3.308739597028945
Validation loss: 2.5138087604242076

Epoch: 6| Step: 4
Training loss: 2.889914430453649
Validation loss: 2.5263339693168545

Epoch: 6| Step: 5
Training loss: 2.8296760815832913
Validation loss: 2.5554734463257516

Epoch: 6| Step: 6
Training loss: 2.525597371358775
Validation loss: 2.572432145358763

Epoch: 6| Step: 7
Training loss: 3.099364147809602
Validation loss: 2.5923820394073873

Epoch: 6| Step: 8
Training loss: 2.9862192257572495
Validation loss: 2.600175248156802

Epoch: 6| Step: 9
Training loss: 2.698395400610724
Validation loss: 2.586421327827298

Epoch: 6| Step: 10
Training loss: 2.5982498293857965
Validation loss: 2.5577571876171

Epoch: 6| Step: 11
Training loss: 2.4159570068550824
Validation loss: 2.5783079885983406

Epoch: 6| Step: 12
Training loss: 2.89130636896647
Validation loss: 2.5674785919004672

Epoch: 6| Step: 13
Training loss: 2.8194029971512515
Validation loss: 2.549430712884963

Epoch: 214| Step: 0
Training loss: 2.787874198395893
Validation loss: 2.5442421215717603

Epoch: 6| Step: 1
Training loss: 2.5093909314173604
Validation loss: 2.535788170329093

Epoch: 6| Step: 2
Training loss: 2.762752096833802
Validation loss: 2.5568870590427353

Epoch: 6| Step: 3
Training loss: 3.211479493965536
Validation loss: 2.5568821320585045

Epoch: 6| Step: 4
Training loss: 2.4663901337274377
Validation loss: 2.558114861512745

Epoch: 6| Step: 5
Training loss: 2.9418922215369565
Validation loss: 2.557966193757608

Epoch: 6| Step: 6
Training loss: 2.627152514069908
Validation loss: 2.564638700469268

Epoch: 6| Step: 7
Training loss: 2.6457320266512525
Validation loss: 2.560498921682216

Epoch: 6| Step: 8
Training loss: 2.3826157785726223
Validation loss: 2.548885097549776

Epoch: 6| Step: 9
Training loss: 2.837262141135276
Validation loss: 2.54260378009024

Epoch: 6| Step: 10
Training loss: 2.4470407636869287
Validation loss: 2.5465308804394327

Epoch: 6| Step: 11
Training loss: 2.9754197537795637
Validation loss: 2.550891187094274

Epoch: 6| Step: 12
Training loss: 3.4237637815723847
Validation loss: 2.5547830639618407

Epoch: 6| Step: 13
Training loss: 2.314778107952552
Validation loss: 2.525186534811441

Epoch: 215| Step: 0
Training loss: 2.071277782044365
Validation loss: 2.523467231071695

Epoch: 6| Step: 1
Training loss: 2.026050544725855
Validation loss: 2.527210450231544

Epoch: 6| Step: 2
Training loss: 3.5284489688175054
Validation loss: 2.522239059883657

Epoch: 6| Step: 3
Training loss: 2.6793105858511628
Validation loss: 2.520309452451518

Epoch: 6| Step: 4
Training loss: 3.273117013323868
Validation loss: 2.524096943612255

Epoch: 6| Step: 5
Training loss: 2.4177336694084826
Validation loss: 2.5287543354716346

Epoch: 6| Step: 6
Training loss: 2.782188771434066
Validation loss: 2.528925499982881

Epoch: 6| Step: 7
Training loss: 2.601337503320717
Validation loss: 2.531929050616617

Epoch: 6| Step: 8
Training loss: 2.7462547113988482
Validation loss: 2.5427570038427216

Epoch: 6| Step: 9
Training loss: 2.640398094766476
Validation loss: 2.534949589483516

Epoch: 6| Step: 10
Training loss: 2.4098785586645204
Validation loss: 2.5298177134947633

Epoch: 6| Step: 11
Training loss: 3.105516963560482
Validation loss: 2.54346240404451

Epoch: 6| Step: 12
Training loss: 3.4018590781186
Validation loss: 2.5385050247606302

Epoch: 6| Step: 13
Training loss: 2.427651880386426
Validation loss: 2.540587728960291

Epoch: 216| Step: 0
Training loss: 2.7093122816031388
Validation loss: 2.54807323415835

Epoch: 6| Step: 1
Training loss: 2.2369679164640583
Validation loss: 2.5622549392528216

Epoch: 6| Step: 2
Training loss: 3.053242919893676
Validation loss: 2.563912860296996

Epoch: 6| Step: 3
Training loss: 3.3394726641890218
Validation loss: 2.573723705858091

Epoch: 6| Step: 4
Training loss: 2.957288279883602
Validation loss: 2.564970139010212

Epoch: 6| Step: 5
Training loss: 2.489481350606895
Validation loss: 2.538988538852798

Epoch: 6| Step: 6
Training loss: 2.6997801090698297
Validation loss: 2.5571548765839363

Epoch: 6| Step: 7
Training loss: 2.2661734081692764
Validation loss: 2.5529140952678886

Epoch: 6| Step: 8
Training loss: 3.2408351789570427
Validation loss: 2.557473431705442

Epoch: 6| Step: 9
Training loss: 2.619681010301377
Validation loss: 2.5524901624371097

Epoch: 6| Step: 10
Training loss: 2.722032253833864
Validation loss: 2.534955209372479

Epoch: 6| Step: 11
Training loss: 2.9395374780255477
Validation loss: 2.5554195089257807

Epoch: 6| Step: 12
Training loss: 2.3135337580981217
Validation loss: 2.5610082522657716

Epoch: 6| Step: 13
Training loss: 2.9619444893652305
Validation loss: 2.54672346149334

Epoch: 217| Step: 0
Training loss: 2.5451553249363306
Validation loss: 2.5718156613478778

Epoch: 6| Step: 1
Training loss: 2.5952079995353072
Validation loss: 2.5482857442928464

Epoch: 6| Step: 2
Training loss: 3.06487726858822
Validation loss: 2.5561622722314716

Epoch: 6| Step: 3
Training loss: 1.9710399086607058
Validation loss: 2.544209907613312

Epoch: 6| Step: 4
Training loss: 2.774492262020516
Validation loss: 2.548296850287999

Epoch: 6| Step: 5
Training loss: 3.306650719399093
Validation loss: 2.526200170759086

Epoch: 6| Step: 6
Training loss: 2.4377949854056924
Validation loss: 2.5405375028221147

Epoch: 6| Step: 7
Training loss: 2.596051309739758
Validation loss: 2.5426680073248695

Epoch: 6| Step: 8
Training loss: 2.6796231720879837
Validation loss: 2.554636467267798

Epoch: 6| Step: 9
Training loss: 2.7819263621662205
Validation loss: 2.5481102748157243

Epoch: 6| Step: 10
Training loss: 2.9329922766806527
Validation loss: 2.559057366773573

Epoch: 6| Step: 11
Training loss: 2.8024242056704822
Validation loss: 2.5695494163538304

Epoch: 6| Step: 12
Training loss: 2.9678083030507927
Validation loss: 2.5515090413416917

Epoch: 6| Step: 13
Training loss: 3.184689198754499
Validation loss: 2.5215464794879945

Epoch: 218| Step: 0
Training loss: 3.092451651587657
Validation loss: 2.5083368204545216

Epoch: 6| Step: 1
Training loss: 2.4548383427244067
Validation loss: 2.5102732780871038

Epoch: 6| Step: 2
Training loss: 2.529700664559052
Validation loss: 2.5070357695551997

Epoch: 6| Step: 3
Training loss: 3.2955021463143224
Validation loss: 2.498900241350391

Epoch: 6| Step: 4
Training loss: 2.364414920495082
Validation loss: 2.4970738334258296

Epoch: 6| Step: 5
Training loss: 2.164643467889946
Validation loss: 2.4989734572481543

Epoch: 6| Step: 6
Training loss: 2.8306137009940744
Validation loss: 2.503028348034548

Epoch: 6| Step: 7
Training loss: 3.042286709508419
Validation loss: 2.500187934456573

Epoch: 6| Step: 8
Training loss: 2.9027730180213593
Validation loss: 2.5157869215923823

Epoch: 6| Step: 9
Training loss: 3.118164368344802
Validation loss: 2.517541458936037

Epoch: 6| Step: 10
Training loss: 2.799455528455192
Validation loss: 2.5546304521340373

Epoch: 6| Step: 11
Training loss: 2.4741819474735687
Validation loss: 2.574359975384788

Epoch: 6| Step: 12
Training loss: 2.704742300623252
Validation loss: 2.5938849692644053

Epoch: 6| Step: 13
Training loss: 2.887589298865637
Validation loss: 2.578030170027859

Epoch: 219| Step: 0
Training loss: 3.0100948245298076
Validation loss: 2.5521656866056546

Epoch: 6| Step: 1
Training loss: 2.7533619011265915
Validation loss: 2.5276856600776663

Epoch: 6| Step: 2
Training loss: 2.9216053884216286
Validation loss: 2.519934869812658

Epoch: 6| Step: 3
Training loss: 2.716600730501481
Validation loss: 2.523549442036399

Epoch: 6| Step: 4
Training loss: 2.7469677246552884
Validation loss: 2.5173803151979612

Epoch: 6| Step: 5
Training loss: 2.9156915033571407
Validation loss: 2.524991525290396

Epoch: 6| Step: 6
Training loss: 2.7946363472525384
Validation loss: 2.5140241541851633

Epoch: 6| Step: 7
Training loss: 2.308771478359937
Validation loss: 2.537384255011973

Epoch: 6| Step: 8
Training loss: 2.9692268390180985
Validation loss: 2.5586025573233204

Epoch: 6| Step: 9
Training loss: 3.0223203660263187
Validation loss: 2.5243329826046406

Epoch: 6| Step: 10
Training loss: 2.592594394859818
Validation loss: 2.5282635112974

Epoch: 6| Step: 11
Training loss: 2.5845348783808544
Validation loss: 2.523064370409957

Epoch: 6| Step: 12
Training loss: 2.422600323752104
Validation loss: 2.5256243840728847

Epoch: 6| Step: 13
Training loss: 3.1051957304318183
Validation loss: 2.532500936918208

Epoch: 220| Step: 0
Training loss: 3.540798005930136
Validation loss: 2.513767573504774

Epoch: 6| Step: 1
Training loss: 3.1083148318260814
Validation loss: 2.5147644346272373

Epoch: 6| Step: 2
Training loss: 3.1476030403462834
Validation loss: 2.5141364133821913

Epoch: 6| Step: 3
Training loss: 2.0080719420247184
Validation loss: 2.5079464229276436

Epoch: 6| Step: 4
Training loss: 2.0492318831040035
Validation loss: 2.4928745090884656

Epoch: 6| Step: 5
Training loss: 2.9524559595245665
Validation loss: 2.5073229013089597

Epoch: 6| Step: 6
Training loss: 1.8544102912324338
Validation loss: 2.509166355281049

Epoch: 6| Step: 7
Training loss: 2.224120504167732
Validation loss: 2.520342046149736

Epoch: 6| Step: 8
Training loss: 3.0971522263931663
Validation loss: 2.527705399851344

Epoch: 6| Step: 9
Training loss: 2.5896378056962255
Validation loss: 2.532608771481209

Epoch: 6| Step: 10
Training loss: 2.742857153004124
Validation loss: 2.529318408381074

Epoch: 6| Step: 11
Training loss: 2.579042213736405
Validation loss: 2.5511314034795007

Epoch: 6| Step: 12
Training loss: 3.164409703172339
Validation loss: 2.559413566841179

Epoch: 6| Step: 13
Training loss: 3.09018355284258
Validation loss: 2.5470540416401932

Epoch: 221| Step: 0
Training loss: 2.6112609261174144
Validation loss: 2.5544824988674426

Epoch: 6| Step: 1
Training loss: 2.7934710711143205
Validation loss: 2.562826118356581

Epoch: 6| Step: 2
Training loss: 2.4452319634675916
Validation loss: 2.557744872324439

Epoch: 6| Step: 3
Training loss: 2.836728492747401
Validation loss: 2.5431254931044402

Epoch: 6| Step: 4
Training loss: 2.719245602390149
Validation loss: 2.5415925677986877

Epoch: 6| Step: 5
Training loss: 3.084612984640804
Validation loss: 2.5357911951906713

Epoch: 6| Step: 6
Training loss: 2.6304839842728778
Validation loss: 2.527638699020265

Epoch: 6| Step: 7
Training loss: 2.4186819377460536
Validation loss: 2.524654844933517

Epoch: 6| Step: 8
Training loss: 2.8782090231759243
Validation loss: 2.5181610209845733

Epoch: 6| Step: 9
Training loss: 2.75487692750169
Validation loss: 2.5105325339116806

Epoch: 6| Step: 10
Training loss: 2.503154671596728
Validation loss: 2.52214994619113

Epoch: 6| Step: 11
Training loss: 3.117329759148125
Validation loss: 2.5201836388366123

Epoch: 6| Step: 12
Training loss: 2.581708602252741
Validation loss: 2.5081145754692007

Epoch: 6| Step: 13
Training loss: 3.336562658690259
Validation loss: 2.5166139680945823

Epoch: 222| Step: 0
Training loss: 3.3218143432476563
Validation loss: 2.5096813894016328

Epoch: 6| Step: 1
Training loss: 2.931333684641742
Validation loss: 2.510645301512917

Epoch: 6| Step: 2
Training loss: 2.72896638285786
Validation loss: 2.5130941931267152

Epoch: 6| Step: 3
Training loss: 2.3305015978542727
Validation loss: 2.5125152744152777

Epoch: 6| Step: 4
Training loss: 2.536304466599
Validation loss: 2.5108101182915536

Epoch: 6| Step: 5
Training loss: 2.8190456937325528
Validation loss: 2.5021480007847905

Epoch: 6| Step: 6
Training loss: 2.701368698484864
Validation loss: 2.520416501583021

Epoch: 6| Step: 7
Training loss: 2.680764918696976
Validation loss: 2.5090220754481427

Epoch: 6| Step: 8
Training loss: 2.5666243694172555
Validation loss: 2.506221814309456

Epoch: 6| Step: 9
Training loss: 2.5248463952205107
Validation loss: 2.5183287958621796

Epoch: 6| Step: 10
Training loss: 3.2944849399553013
Validation loss: 2.5299974140428176

Epoch: 6| Step: 11
Training loss: 2.4751565594718414
Validation loss: 2.543591709537798

Epoch: 6| Step: 12
Training loss: 2.8865410075100457
Validation loss: 2.5848422656775627

Epoch: 6| Step: 13
Training loss: 2.3564048412655967
Validation loss: 2.5752501955471674

Epoch: 223| Step: 0
Training loss: 2.2457368517400216
Validation loss: 2.597070702454987

Epoch: 6| Step: 1
Training loss: 2.701094553868937
Validation loss: 2.6409355272729464

Epoch: 6| Step: 2
Training loss: 2.8714239021485626
Validation loss: 2.6515142054024072

Epoch: 6| Step: 3
Training loss: 3.0098359670965666
Validation loss: 2.606954885599812

Epoch: 6| Step: 4
Training loss: 3.0085991957701137
Validation loss: 2.574196693913123

Epoch: 6| Step: 5
Training loss: 3.134602251875957
Validation loss: 2.5560440626785756

Epoch: 6| Step: 6
Training loss: 3.2005737565178287
Validation loss: 2.5298077459706874

Epoch: 6| Step: 7
Training loss: 2.3842334950305695
Validation loss: 2.52384103042459

Epoch: 6| Step: 8
Training loss: 2.4427636851293495
Validation loss: 2.5262048084861695

Epoch: 6| Step: 9
Training loss: 2.642909038431857
Validation loss: 2.5284678965779848

Epoch: 6| Step: 10
Training loss: 2.484303791297194
Validation loss: 2.528078855477243

Epoch: 6| Step: 11
Training loss: 2.7539379361541476
Validation loss: 2.5248965547681506

Epoch: 6| Step: 12
Training loss: 2.7077751073440175
Validation loss: 2.527909050386502

Epoch: 6| Step: 13
Training loss: 2.907271995099738
Validation loss: 2.534599880858967

Epoch: 224| Step: 0
Training loss: 2.8578543866958372
Validation loss: 2.5411812876775492

Epoch: 6| Step: 1
Training loss: 2.578183815025146
Validation loss: 2.56461582227402

Epoch: 6| Step: 2
Training loss: 2.846632617803391
Validation loss: 2.568156881720102

Epoch: 6| Step: 3
Training loss: 2.7199742860139593
Validation loss: 2.556916635788195

Epoch: 6| Step: 4
Training loss: 2.611118853221625
Validation loss: 2.5548378075204674

Epoch: 6| Step: 5
Training loss: 2.6782689023610926
Validation loss: 2.5549378962434544

Epoch: 6| Step: 6
Training loss: 2.814217954045332
Validation loss: 2.5484142210835556

Epoch: 6| Step: 7
Training loss: 2.4860293080696083
Validation loss: 2.543101669347772

Epoch: 6| Step: 8
Training loss: 3.4668230082641776
Validation loss: 2.5516363295315694

Epoch: 6| Step: 9
Training loss: 2.4522108573671346
Validation loss: 2.55304521754394

Epoch: 6| Step: 10
Training loss: 2.417859692802622
Validation loss: 2.539736773725299

Epoch: 6| Step: 11
Training loss: 2.577853286759004
Validation loss: 2.556779881457007

Epoch: 6| Step: 12
Training loss: 3.0062254843237652
Validation loss: 2.549746110692224

Epoch: 6| Step: 13
Training loss: 2.8206069243122607
Validation loss: 2.610155350088165

Epoch: 225| Step: 0
Training loss: 3.126552348809108
Validation loss: 2.601599579248489

Epoch: 6| Step: 1
Training loss: 2.4699354584944966
Validation loss: 2.58018891226306

Epoch: 6| Step: 2
Training loss: 2.7933072825319445
Validation loss: 2.57424803101323

Epoch: 6| Step: 3
Training loss: 3.052937740646966
Validation loss: 2.5541634221678575

Epoch: 6| Step: 4
Training loss: 2.653777374112018
Validation loss: 2.5511241209341255

Epoch: 6| Step: 5
Training loss: 3.3571605392036776
Validation loss: 2.5299192125952437

Epoch: 6| Step: 6
Training loss: 2.697981864308342
Validation loss: 2.542723027846262

Epoch: 6| Step: 7
Training loss: 3.0739502456301833
Validation loss: 2.527363789649771

Epoch: 6| Step: 8
Training loss: 2.3426506007097205
Validation loss: 2.5292754002236446

Epoch: 6| Step: 9
Training loss: 2.618992425081034
Validation loss: 2.5356028269814903

Epoch: 6| Step: 10
Training loss: 2.557073849312413
Validation loss: 2.5338074143673333

Epoch: 6| Step: 11
Training loss: 2.4560310013768394
Validation loss: 2.5232514191173614

Epoch: 6| Step: 12
Training loss: 2.3846920417599424
Validation loss: 2.5304561490811257

Epoch: 6| Step: 13
Training loss: 2.5050159679216093
Validation loss: 2.5263633984065703

Epoch: 226| Step: 0
Training loss: 2.2291800121252523
Validation loss: 2.512287985637015

Epoch: 6| Step: 1
Training loss: 3.3801261684186747
Validation loss: 2.5248916536939525

Epoch: 6| Step: 2
Training loss: 2.903769634441545
Validation loss: 2.5221031127983964

Epoch: 6| Step: 3
Training loss: 2.2320922715040927
Validation loss: 2.5227064493957334

Epoch: 6| Step: 4
Training loss: 2.9787451883870273
Validation loss: 2.5286943809022837

Epoch: 6| Step: 5
Training loss: 2.302757877815545
Validation loss: 2.521632833946071

Epoch: 6| Step: 6
Training loss: 2.923302612781228
Validation loss: 2.516639452445327

Epoch: 6| Step: 7
Training loss: 2.976282301803183
Validation loss: 2.5345537771849855

Epoch: 6| Step: 8
Training loss: 3.0109583665394943
Validation loss: 2.5558386507732647

Epoch: 6| Step: 9
Training loss: 2.5382254291759008
Validation loss: 2.548257472302245

Epoch: 6| Step: 10
Training loss: 2.117711526693503
Validation loss: 2.54680379333546

Epoch: 6| Step: 11
Training loss: 2.6724615512861973
Validation loss: 2.557646714706136

Epoch: 6| Step: 12
Training loss: 2.737353462930585
Validation loss: 2.55670013881143

Epoch: 6| Step: 13
Training loss: 3.162203471036664
Validation loss: 2.5866056438561946

Epoch: 227| Step: 0
Training loss: 2.1174041524585316
Validation loss: 2.601525332519088

Epoch: 6| Step: 1
Training loss: 2.5479143514386124
Validation loss: 2.60302845418943

Epoch: 6| Step: 2
Training loss: 3.4285105291135083
Validation loss: 2.6102890860928447

Epoch: 6| Step: 3
Training loss: 2.7604596884391923
Validation loss: 2.6065698697624398

Epoch: 6| Step: 4
Training loss: 2.28325919938226
Validation loss: 2.586429168641279

Epoch: 6| Step: 5
Training loss: 2.64762195194617
Validation loss: 2.576739875653294

Epoch: 6| Step: 6
Training loss: 2.6881124109196466
Validation loss: 2.579604227722467

Epoch: 6| Step: 7
Training loss: 2.6987143457910143
Validation loss: 2.5723022933724495

Epoch: 6| Step: 8
Training loss: 3.1911626977331196
Validation loss: 2.54850401281755

Epoch: 6| Step: 9
Training loss: 3.085047339968019
Validation loss: 2.5316004214944408

Epoch: 6| Step: 10
Training loss: 2.669461236381136
Validation loss: 2.533135567009496

Epoch: 6| Step: 11
Training loss: 2.890781872590857
Validation loss: 2.536368283283728

Epoch: 6| Step: 12
Training loss: 2.565595199653505
Validation loss: 2.5279007354812895

Epoch: 6| Step: 13
Training loss: 2.134516555761245
Validation loss: 2.548318515868295

Epoch: 228| Step: 0
Training loss: 2.5168135779070924
Validation loss: 2.556003633560337

Epoch: 6| Step: 1
Training loss: 1.7057740494353437
Validation loss: 2.5770879664085022

Epoch: 6| Step: 2
Training loss: 2.7127475467354745
Validation loss: 2.5823051743332655

Epoch: 6| Step: 3
Training loss: 3.082134752747556
Validation loss: 2.63733793109771

Epoch: 6| Step: 4
Training loss: 2.752582551166953
Validation loss: 2.6345966319305156

Epoch: 6| Step: 5
Training loss: 2.6664557572247127
Validation loss: 2.616075944134898

Epoch: 6| Step: 6
Training loss: 2.7615300266471356
Validation loss: 2.6022747197753966

Epoch: 6| Step: 7
Training loss: 2.7885557937881718
Validation loss: 2.573442617996643

Epoch: 6| Step: 8
Training loss: 3.0174599238581186
Validation loss: 2.558738064040485

Epoch: 6| Step: 9
Training loss: 2.8303288255936496
Validation loss: 2.534136293455322

Epoch: 6| Step: 10
Training loss: 2.3860453703052826
Validation loss: 2.529431298274498

Epoch: 6| Step: 11
Training loss: 2.919051330826005
Validation loss: 2.5361445494099892

Epoch: 6| Step: 12
Training loss: 3.1656194929732147
Validation loss: 2.533357811894807

Epoch: 6| Step: 13
Training loss: 3.1839994768784443
Validation loss: 2.5381083599114103

Epoch: 229| Step: 0
Training loss: 2.643912531769342
Validation loss: 2.5396375849519037

Epoch: 6| Step: 1
Training loss: 2.3738229746195363
Validation loss: 2.5357816514974894

Epoch: 6| Step: 2
Training loss: 3.0377828458483127
Validation loss: 2.5288520979702778

Epoch: 6| Step: 3
Training loss: 2.555489323858875
Validation loss: 2.534051458708354

Epoch: 6| Step: 4
Training loss: 2.7683610905636176
Validation loss: 2.546015979277229

Epoch: 6| Step: 5
Training loss: 3.2005108842728722
Validation loss: 2.5304123781238594

Epoch: 6| Step: 6
Training loss: 2.6236986840233576
Validation loss: 2.54480717090684

Epoch: 6| Step: 7
Training loss: 2.387100314093628
Validation loss: 2.5494327531933116

Epoch: 6| Step: 8
Training loss: 3.0274543200573945
Validation loss: 2.551150895516394

Epoch: 6| Step: 9
Training loss: 2.1272443251503286
Validation loss: 2.5433694265391953

Epoch: 6| Step: 10
Training loss: 2.9303059243121004
Validation loss: 2.5664104105083343

Epoch: 6| Step: 11
Training loss: 3.0484403843868497
Validation loss: 2.5614012016366408

Epoch: 6| Step: 12
Training loss: 2.684689227398803
Validation loss: 2.562246797839306

Epoch: 6| Step: 13
Training loss: 2.560802734999908
Validation loss: 2.552402164181214

Epoch: 230| Step: 0
Training loss: 2.6441076663512257
Validation loss: 2.563635570745333

Epoch: 6| Step: 1
Training loss: 2.7080165286496496
Validation loss: 2.5844947957498885

Epoch: 6| Step: 2
Training loss: 2.6601591180234174
Validation loss: 2.582049779012721

Epoch: 6| Step: 3
Training loss: 2.553025384498086
Validation loss: 2.571063555365185

Epoch: 6| Step: 4
Training loss: 3.0442217890060475
Validation loss: 2.5663498941763336

Epoch: 6| Step: 5
Training loss: 2.9984715064716005
Validation loss: 2.542996360488157

Epoch: 6| Step: 6
Training loss: 2.1696887092746295
Validation loss: 2.558157491043715

Epoch: 6| Step: 7
Training loss: 3.1017374522641856
Validation loss: 2.5567661767441496

Epoch: 6| Step: 8
Training loss: 2.7546589140726003
Validation loss: 2.537560852612688

Epoch: 6| Step: 9
Training loss: 2.438242285752333
Validation loss: 2.521378589287333

Epoch: 6| Step: 10
Training loss: 2.2647413964251824
Validation loss: 2.531013593188669

Epoch: 6| Step: 11
Training loss: 2.7536546524586782
Validation loss: 2.513164189261455

Epoch: 6| Step: 12
Training loss: 2.6324028805807247
Validation loss: 2.528408399598553

Epoch: 6| Step: 13
Training loss: 3.659684483628931
Validation loss: 2.5177686349306665

Epoch: 231| Step: 0
Training loss: 3.2121618308110405
Validation loss: 2.5077054362481928

Epoch: 6| Step: 1
Training loss: 3.1517578488101874
Validation loss: 2.524670336977284

Epoch: 6| Step: 2
Training loss: 2.827244405484734
Validation loss: 2.5108801239860714

Epoch: 6| Step: 3
Training loss: 2.458887414937076
Validation loss: 2.506325197742432

Epoch: 6| Step: 4
Training loss: 1.7374333403170574
Validation loss: 2.5010959038291305

Epoch: 6| Step: 5
Training loss: 2.6415565247142636
Validation loss: 2.5065395101779973

Epoch: 6| Step: 6
Training loss: 2.9636892450702748
Validation loss: 2.508005747037157

Epoch: 6| Step: 7
Training loss: 2.9907364875317923
Validation loss: 2.5454388521507685

Epoch: 6| Step: 8
Training loss: 2.427990286881502
Validation loss: 2.547649585598571

Epoch: 6| Step: 9
Training loss: 2.86860309964382
Validation loss: 2.5646938094221787

Epoch: 6| Step: 10
Training loss: 2.5863211079294723
Validation loss: 2.5400103429390426

Epoch: 6| Step: 11
Training loss: 2.0533761020433814
Validation loss: 2.547552480050702

Epoch: 6| Step: 12
Training loss: 2.88429581852736
Validation loss: 2.550850743642663

Epoch: 6| Step: 13
Training loss: 3.1088854533750565
Validation loss: 2.572383909321136

Epoch: 232| Step: 0
Training loss: 2.2193858350458684
Validation loss: 2.5927398064571956

Epoch: 6| Step: 1
Training loss: 3.3944489323124523
Validation loss: 2.6107709978480322

Epoch: 6| Step: 2
Training loss: 2.102805185020401
Validation loss: 2.64194767768964

Epoch: 6| Step: 3
Training loss: 2.7161867181926094
Validation loss: 2.618789400562067

Epoch: 6| Step: 4
Training loss: 2.886535886514024
Validation loss: 2.592121004622486

Epoch: 6| Step: 5
Training loss: 2.7572887236653068
Validation loss: 2.5566188163588306

Epoch: 6| Step: 6
Training loss: 3.05394093788259
Validation loss: 2.5360030144835006

Epoch: 6| Step: 7
Training loss: 3.0842784429739716
Validation loss: 2.5067336264686344

Epoch: 6| Step: 8
Training loss: 2.801760705764888
Validation loss: 2.4893752986120194

Epoch: 6| Step: 9
Training loss: 2.655615338069786
Validation loss: 2.4939533923054533

Epoch: 6| Step: 10
Training loss: 3.1204352036190963
Validation loss: 2.4936662724711516

Epoch: 6| Step: 11
Training loss: 2.372853965924476
Validation loss: 2.4866495872838494

Epoch: 6| Step: 12
Training loss: 2.522811670320928
Validation loss: 2.5078924477676257

Epoch: 6| Step: 13
Training loss: 2.2411856190699546
Validation loss: 2.499246146255838

Epoch: 233| Step: 0
Training loss: 2.648640852691552
Validation loss: 2.511855437717549

Epoch: 6| Step: 1
Training loss: 2.985219306749038
Validation loss: 2.5334900495320003

Epoch: 6| Step: 2
Training loss: 3.1944484894952643
Validation loss: 2.554277166130868

Epoch: 6| Step: 3
Training loss: 2.7194913532998424
Validation loss: 2.564741220506742

Epoch: 6| Step: 4
Training loss: 3.0500465514585926
Validation loss: 2.575118459733923

Epoch: 6| Step: 5
Training loss: 2.9775747745583043
Validation loss: 2.5813694967649146

Epoch: 6| Step: 6
Training loss: 2.143890674301783
Validation loss: 2.5869985362327435

Epoch: 6| Step: 7
Training loss: 2.288530828293729
Validation loss: 2.545485843860029

Epoch: 6| Step: 8
Training loss: 2.5751290224213426
Validation loss: 2.5330531034392623

Epoch: 6| Step: 9
Training loss: 2.7224384587445885
Validation loss: 2.5094720251757536

Epoch: 6| Step: 10
Training loss: 2.3097968927902737
Validation loss: 2.498426256859505

Epoch: 6| Step: 11
Training loss: 3.3199471306325514
Validation loss: 2.491701787328703

Epoch: 6| Step: 12
Training loss: 2.5685505030773936
Validation loss: 2.485938512735492

Epoch: 6| Step: 13
Training loss: 2.308352695021239
Validation loss: 2.5042236458688545

Epoch: 234| Step: 0
Training loss: 3.0684913106679996
Validation loss: 2.4879715495060806

Epoch: 6| Step: 1
Training loss: 3.0220729695970836
Validation loss: 2.5009231329436394

Epoch: 6| Step: 2
Training loss: 2.6366559960703575
Validation loss: 2.4913168156543883

Epoch: 6| Step: 3
Training loss: 2.5605652180705007
Validation loss: 2.50108017709835

Epoch: 6| Step: 4
Training loss: 2.413660503606993
Validation loss: 2.526199342157716

Epoch: 6| Step: 5
Training loss: 2.278213989026791
Validation loss: 2.5445624010507726

Epoch: 6| Step: 6
Training loss: 2.920959002684106
Validation loss: 2.551664102428357

Epoch: 6| Step: 7
Training loss: 2.853164014100385
Validation loss: 2.580617959862319

Epoch: 6| Step: 8
Training loss: 2.1922454587054343
Validation loss: 2.6064375245227187

Epoch: 6| Step: 9
Training loss: 2.9333577270649482
Validation loss: 2.6120778650992933

Epoch: 6| Step: 10
Training loss: 3.294967171674788
Validation loss: 2.570978313761719

Epoch: 6| Step: 11
Training loss: 2.668524710729676
Validation loss: 2.5401688793423483

Epoch: 6| Step: 12
Training loss: 2.657795176149633
Validation loss: 2.530418017207829

Epoch: 6| Step: 13
Training loss: 2.2342571947746626
Validation loss: 2.49469664021451

Epoch: 235| Step: 0
Training loss: 2.5964928337775466
Validation loss: 2.5162674135770384

Epoch: 6| Step: 1
Training loss: 3.008588259842271
Validation loss: 2.5403140271536513

Epoch: 6| Step: 2
Training loss: 2.7665988909987544
Validation loss: 2.576229184228261

Epoch: 6| Step: 3
Training loss: 2.274569409880958
Validation loss: 2.6019486637081757

Epoch: 6| Step: 4
Training loss: 2.7178255460666603
Validation loss: 2.6169478503701575

Epoch: 6| Step: 5
Training loss: 3.189240223681136
Validation loss: 2.630896304442841

Epoch: 6| Step: 6
Training loss: 3.1172110573397136
Validation loss: 2.6294864241745235

Epoch: 6| Step: 7
Training loss: 2.4935652891507223
Validation loss: 2.61629555492905

Epoch: 6| Step: 8
Training loss: 2.5941819899813416
Validation loss: 2.57921767660393

Epoch: 6| Step: 9
Training loss: 2.610337953428563
Validation loss: 2.537910816894199

Epoch: 6| Step: 10
Training loss: 2.397812951499432
Validation loss: 2.516516473834813

Epoch: 6| Step: 11
Training loss: 2.8554622373493617
Validation loss: 2.522626866442838

Epoch: 6| Step: 12
Training loss: 2.4262885455489847
Validation loss: 2.510491143130612

Epoch: 6| Step: 13
Training loss: 3.0916882976039184
Validation loss: 2.5008290772170274

Epoch: 236| Step: 0
Training loss: 2.742967717391352
Validation loss: 2.5065683565233807

Epoch: 6| Step: 1
Training loss: 2.9453142808660897
Validation loss: 2.503530789036996

Epoch: 6| Step: 2
Training loss: 2.680427738188377
Validation loss: 2.5186607801226066

Epoch: 6| Step: 3
Training loss: 2.731179511865065
Validation loss: 2.5303447228267877

Epoch: 6| Step: 4
Training loss: 2.8023462751221375
Validation loss: 2.518191477102679

Epoch: 6| Step: 5
Training loss: 2.677906122688922
Validation loss: 2.5250404615804283

Epoch: 6| Step: 6
Training loss: 2.850060472348775
Validation loss: 2.5304791091802996

Epoch: 6| Step: 7
Training loss: 2.4545123799661273
Validation loss: 2.5269247433209974

Epoch: 6| Step: 8
Training loss: 2.7099187954212023
Validation loss: 2.531295582512671

Epoch: 6| Step: 9
Training loss: 2.5372353890291772
Validation loss: 2.5271071613819207

Epoch: 6| Step: 10
Training loss: 2.627653234280125
Validation loss: 2.5195800471272505

Epoch: 6| Step: 11
Training loss: 3.2310214878644037
Validation loss: 2.531125230548703

Epoch: 6| Step: 12
Training loss: 2.657326244656145
Validation loss: 2.5453508523440322

Epoch: 6| Step: 13
Training loss: 1.9507404266595747
Validation loss: 2.547872518479039

Epoch: 237| Step: 0
Training loss: 2.3319049845750968
Validation loss: 2.548234979233581

Epoch: 6| Step: 1
Training loss: 3.0596088074601138
Validation loss: 2.55244663675405

Epoch: 6| Step: 2
Training loss: 2.161973295952026
Validation loss: 2.543907313791027

Epoch: 6| Step: 3
Training loss: 2.4356645373668404
Validation loss: 2.53770007109494

Epoch: 6| Step: 4
Training loss: 2.6834254760401723
Validation loss: 2.5188524040613074

Epoch: 6| Step: 5
Training loss: 2.6803385218997957
Validation loss: 2.521832887212245

Epoch: 6| Step: 6
Training loss: 2.931594268818626
Validation loss: 2.5391823825348276

Epoch: 6| Step: 7
Training loss: 2.9717360085958435
Validation loss: 2.535144424581542

Epoch: 6| Step: 8
Training loss: 2.637211687140053
Validation loss: 2.5476392008009796

Epoch: 6| Step: 9
Training loss: 2.4269530189031543
Validation loss: 2.533743183100044

Epoch: 6| Step: 10
Training loss: 2.610131433911887
Validation loss: 2.5578049457752283

Epoch: 6| Step: 11
Training loss: 2.9687136999219867
Validation loss: 2.5643562808634255

Epoch: 6| Step: 12
Training loss: 2.8790301395917575
Validation loss: 2.5674361371068466

Epoch: 6| Step: 13
Training loss: 3.234864865860461
Validation loss: 2.5721754886657817

Epoch: 238| Step: 0
Training loss: 2.7707355931379123
Validation loss: 2.607837996800001

Epoch: 6| Step: 1
Training loss: 2.7466733057750474
Validation loss: 2.631029881640274

Epoch: 6| Step: 2
Training loss: 3.2518061974127894
Validation loss: 2.598568574505776

Epoch: 6| Step: 3
Training loss: 2.606216529247053
Validation loss: 2.6018020493481737

Epoch: 6| Step: 4
Training loss: 2.4115362189110137
Validation loss: 2.560786691189518

Epoch: 6| Step: 5
Training loss: 2.830475225817616
Validation loss: 2.5265085265698857

Epoch: 6| Step: 6
Training loss: 2.586000101766562
Validation loss: 2.5033645508497315

Epoch: 6| Step: 7
Training loss: 3.070914095502837
Validation loss: 2.4928315838304855

Epoch: 6| Step: 8
Training loss: 2.3848809941509046
Validation loss: 2.487081350606674

Epoch: 6| Step: 9
Training loss: 2.7352407774167005
Validation loss: 2.490204647625905

Epoch: 6| Step: 10
Training loss: 2.7921831213132813
Validation loss: 2.5040497434692304

Epoch: 6| Step: 11
Training loss: 2.3418743512061355
Validation loss: 2.497748648169551

Epoch: 6| Step: 12
Training loss: 2.6507809154129154
Validation loss: 2.5197288848396378

Epoch: 6| Step: 13
Training loss: 2.8103823000590777
Validation loss: 2.5231247076939955

Epoch: 239| Step: 0
Training loss: 3.06717589614702
Validation loss: 2.569035463414928

Epoch: 6| Step: 1
Training loss: 2.7326499511115685
Validation loss: 2.579570435918711

Epoch: 6| Step: 2
Training loss: 2.954447455214765
Validation loss: 2.5956297318499644

Epoch: 6| Step: 3
Training loss: 2.0928703851713313
Validation loss: 2.6094528932313166

Epoch: 6| Step: 4
Training loss: 2.6858343241049933
Validation loss: 2.6573327730735365

Epoch: 6| Step: 5
Training loss: 2.3606696208506968
Validation loss: 2.664308815594933

Epoch: 6| Step: 6
Training loss: 2.96956502869625
Validation loss: 2.683636606385343

Epoch: 6| Step: 7
Training loss: 3.503652029692163
Validation loss: 2.663691151416915

Epoch: 6| Step: 8
Training loss: 2.755883771651846
Validation loss: 2.6246467475696726

Epoch: 6| Step: 9
Training loss: 2.480991002169141
Validation loss: 2.5750651070471635

Epoch: 6| Step: 10
Training loss: 2.959091375953138
Validation loss: 2.532420716249036

Epoch: 6| Step: 11
Training loss: 2.036762562797425
Validation loss: 2.526684071678157

Epoch: 6| Step: 12
Training loss: 2.659945441812288
Validation loss: 2.5216668348593796

Epoch: 6| Step: 13
Training loss: 2.9255905598530645
Validation loss: 2.519373184489873

Epoch: 240| Step: 0
Training loss: 2.766768569295242
Validation loss: 2.5136355650129962

Epoch: 6| Step: 1
Training loss: 2.6251867318720903
Validation loss: 2.5086807824569615

Epoch: 6| Step: 2
Training loss: 3.1750430367023545
Validation loss: 2.515139377553004

Epoch: 6| Step: 3
Training loss: 2.78737762593105
Validation loss: 2.5014204184207656

Epoch: 6| Step: 4
Training loss: 2.590822613107959
Validation loss: 2.5013300434028776

Epoch: 6| Step: 5
Training loss: 2.7824501277159164
Validation loss: 2.5163496223861097

Epoch: 6| Step: 6
Training loss: 3.1923919238838314
Validation loss: 2.5092473418694485

Epoch: 6| Step: 7
Training loss: 2.335547373162788
Validation loss: 2.515425333577935

Epoch: 6| Step: 8
Training loss: 2.4718100981746125
Validation loss: 2.5345847049017913

Epoch: 6| Step: 9
Training loss: 2.6897802216326214
Validation loss: 2.527978078560069

Epoch: 6| Step: 10
Training loss: 2.7122857426698492
Validation loss: 2.5543828599895098

Epoch: 6| Step: 11
Training loss: 2.464359290246814
Validation loss: 2.58142254833775

Epoch: 6| Step: 12
Training loss: 2.3572402289949963
Validation loss: 2.6220523498363524

Epoch: 6| Step: 13
Training loss: 3.060044530407388
Validation loss: 2.67983199706138

Epoch: 241| Step: 0
Training loss: 2.6987079849259037
Validation loss: 2.660719571262548

Epoch: 6| Step: 1
Training loss: 2.4204335506894674
Validation loss: 2.6320217280604834

Epoch: 6| Step: 2
Training loss: 1.9724720481758318
Validation loss: 2.591287786724306

Epoch: 6| Step: 3
Training loss: 2.1827908645245775
Validation loss: 2.562783401428717

Epoch: 6| Step: 4
Training loss: 2.6612910288402407
Validation loss: 2.564449832041516

Epoch: 6| Step: 5
Training loss: 2.7066211472365262
Validation loss: 2.5596235354502443

Epoch: 6| Step: 6
Training loss: 2.95129337729697
Validation loss: 2.5581624987493634

Epoch: 6| Step: 7
Training loss: 2.8740463333695545
Validation loss: 2.5650256066446517

Epoch: 6| Step: 8
Training loss: 3.2218340570492003
Validation loss: 2.5757592845674404

Epoch: 6| Step: 9
Training loss: 2.2556642654396395
Validation loss: 2.578236791947003

Epoch: 6| Step: 10
Training loss: 3.1908193022833835
Validation loss: 2.5902562941693876

Epoch: 6| Step: 11
Training loss: 3.1067717883398225
Validation loss: 2.570054135373866

Epoch: 6| Step: 12
Training loss: 3.1558629166840197
Validation loss: 2.564343747331548

Epoch: 6| Step: 13
Training loss: 2.042774548609149
Validation loss: 2.5577374512469864

Epoch: 242| Step: 0
Training loss: 2.209313972633879
Validation loss: 2.569754376759753

Epoch: 6| Step: 1
Training loss: 2.550801439190776
Validation loss: 2.569820585012117

Epoch: 6| Step: 2
Training loss: 2.6156819582335347
Validation loss: 2.593694196788434

Epoch: 6| Step: 3
Training loss: 3.1846859047366998
Validation loss: 2.6096114469729357

Epoch: 6| Step: 4
Training loss: 2.7159303974115363
Validation loss: 2.597734646597621

Epoch: 6| Step: 5
Training loss: 2.9738164134103746
Validation loss: 2.6019186628304394

Epoch: 6| Step: 6
Training loss: 2.904119879967368
Validation loss: 2.613052583545496

Epoch: 6| Step: 7
Training loss: 2.7743570871756695
Validation loss: 2.5791272295772694

Epoch: 6| Step: 8
Training loss: 2.3325829548205537
Validation loss: 2.537519765304385

Epoch: 6| Step: 9
Training loss: 2.6594425537996584
Validation loss: 2.533000399066508

Epoch: 6| Step: 10
Training loss: 2.97030871780853
Validation loss: 2.5288414393103795

Epoch: 6| Step: 11
Training loss: 2.518259505227558
Validation loss: 2.5109307595821244

Epoch: 6| Step: 12
Training loss: 2.762173843116977
Validation loss: 2.492619436434192

Epoch: 6| Step: 13
Training loss: 2.5540833298330736
Validation loss: 2.48829951071707

Epoch: 243| Step: 0
Training loss: 2.5232774429816978
Validation loss: 2.5061718640685515

Epoch: 6| Step: 1
Training loss: 2.7776151757862895
Validation loss: 2.5426873303296618

Epoch: 6| Step: 2
Training loss: 2.8456488337734593
Validation loss: 2.5725162625152302

Epoch: 6| Step: 3
Training loss: 2.706563185262423
Validation loss: 2.6105412424117564

Epoch: 6| Step: 4
Training loss: 3.205040930904692
Validation loss: 2.633407077234425

Epoch: 6| Step: 5
Training loss: 3.1024062692898564
Validation loss: 2.6416266824725367

Epoch: 6| Step: 6
Training loss: 2.3475181297764043
Validation loss: 2.6380387507568157

Epoch: 6| Step: 7
Training loss: 3.0793321440284855
Validation loss: 2.6410522251253488

Epoch: 6| Step: 8
Training loss: 2.5501609153090175
Validation loss: 2.6282898951770264

Epoch: 6| Step: 9
Training loss: 2.2045492343816555
Validation loss: 2.6102755994624407

Epoch: 6| Step: 10
Training loss: 2.9221419758127154
Validation loss: 2.611533564295186

Epoch: 6| Step: 11
Training loss: 3.101156443576593
Validation loss: 2.6020209790922535

Epoch: 6| Step: 12
Training loss: 2.0126149968054525
Validation loss: 2.592339725447068

Epoch: 6| Step: 13
Training loss: 2.0482685499549063
Validation loss: 2.6041269347738742

Epoch: 244| Step: 0
Training loss: 2.6383400686551184
Validation loss: 2.5867024250664845

Epoch: 6| Step: 1
Training loss: 2.5431545676038096
Validation loss: 2.5592693590076103

Epoch: 6| Step: 2
Training loss: 2.5331725366491225
Validation loss: 2.548653829006704

Epoch: 6| Step: 3
Training loss: 2.6884339949635883
Validation loss: 2.544682115150256

Epoch: 6| Step: 4
Training loss: 2.4382004342807937
Validation loss: 2.538186405004313

Epoch: 6| Step: 5
Training loss: 2.6592471099834945
Validation loss: 2.5305799830318265

Epoch: 6| Step: 6
Training loss: 2.838300576893667
Validation loss: 2.5248231833624533

Epoch: 6| Step: 7
Training loss: 2.51126678339665
Validation loss: 2.5338331476983083

Epoch: 6| Step: 8
Training loss: 2.877024228213764
Validation loss: 2.548175436734062

Epoch: 6| Step: 9
Training loss: 3.018848968842212
Validation loss: 2.5632342395387857

Epoch: 6| Step: 10
Training loss: 2.6167762547119158
Validation loss: 2.5934131827149383

Epoch: 6| Step: 11
Training loss: 3.0963265835127243
Validation loss: 2.618071962622876

Epoch: 6| Step: 12
Training loss: 2.5745426142120467
Validation loss: 2.615149266413237

Epoch: 6| Step: 13
Training loss: 2.8116161229132492
Validation loss: 2.5927862310838377

Epoch: 245| Step: 0
Training loss: 2.7150270249231836
Validation loss: 2.6098810100372463

Epoch: 6| Step: 1
Training loss: 3.013279768824986
Validation loss: 2.6331886949481556

Epoch: 6| Step: 2
Training loss: 2.4850416908374386
Validation loss: 2.6748337031645857

Epoch: 6| Step: 3
Training loss: 2.4532772915942265
Validation loss: 2.6600026713106586

Epoch: 6| Step: 4
Training loss: 2.9892951392230116
Validation loss: 2.6761246919117654

Epoch: 6| Step: 5
Training loss: 2.441042746376276
Validation loss: 2.637476015839679

Epoch: 6| Step: 6
Training loss: 2.786912789525955
Validation loss: 2.6122945008468856

Epoch: 6| Step: 7
Training loss: 3.2457336887119297
Validation loss: 2.571911262708409

Epoch: 6| Step: 8
Training loss: 2.695426164524738
Validation loss: 2.5372674348981885

Epoch: 6| Step: 9
Training loss: 2.4267226402757998
Validation loss: 2.5283668147588374

Epoch: 6| Step: 10
Training loss: 2.73335578451783
Validation loss: 2.519822030610521

Epoch: 6| Step: 11
Training loss: 2.411930463696361
Validation loss: 2.5086190410894043

Epoch: 6| Step: 12
Training loss: 2.910838452966358
Validation loss: 2.507669865904241

Epoch: 6| Step: 13
Training loss: 2.9899830478965903
Validation loss: 2.507954388463807

Epoch: 246| Step: 0
Training loss: 3.0371511376750835
Validation loss: 2.507724418341732

Epoch: 6| Step: 1
Training loss: 2.4083312310690324
Validation loss: 2.5130556988591506

Epoch: 6| Step: 2
Training loss: 3.198949856106651
Validation loss: 2.508211328217557

Epoch: 6| Step: 3
Training loss: 3.019310157251751
Validation loss: 2.5174687988384092

Epoch: 6| Step: 4
Training loss: 2.8573923376698747
Validation loss: 2.524250160374504

Epoch: 6| Step: 5
Training loss: 2.60776986646687
Validation loss: 2.5559701084709814

Epoch: 6| Step: 6
Training loss: 2.7607834674244023
Validation loss: 2.571289896013141

Epoch: 6| Step: 7
Training loss: 2.4872954854806224
Validation loss: 2.624302984928221

Epoch: 6| Step: 8
Training loss: 2.718402971942348
Validation loss: 2.686142046326022

Epoch: 6| Step: 9
Training loss: 2.687792207667684
Validation loss: 2.7195814071015465

Epoch: 6| Step: 10
Training loss: 2.729530620816177
Validation loss: 2.711768753619742

Epoch: 6| Step: 11
Training loss: 2.727648761863764
Validation loss: 2.68053965629623

Epoch: 6| Step: 12
Training loss: 2.7197156046401783
Validation loss: 2.622353271767255

Epoch: 6| Step: 13
Training loss: 1.2853779239267007
Validation loss: 2.5954742512217224

Epoch: 247| Step: 0
Training loss: 3.02318640955111
Validation loss: 2.5843810222260104

Epoch: 6| Step: 1
Training loss: 2.4399464385610754
Validation loss: 2.5432551110756965

Epoch: 6| Step: 2
Training loss: 2.5595556882391737
Validation loss: 2.5276479245605583

Epoch: 6| Step: 3
Training loss: 2.5079547211911386
Validation loss: 2.5167863545041422

Epoch: 6| Step: 4
Training loss: 2.681583723449473
Validation loss: 2.5071166899912365

Epoch: 6| Step: 5
Training loss: 2.557034781943358
Validation loss: 2.4994079401502147

Epoch: 6| Step: 6
Training loss: 2.8532574358617366
Validation loss: 2.5087693943555647

Epoch: 6| Step: 7
Training loss: 2.8132548696715975
Validation loss: 2.522784697607129

Epoch: 6| Step: 8
Training loss: 2.8227260755174255
Validation loss: 2.5364795050632654

Epoch: 6| Step: 9
Training loss: 3.19966332929535
Validation loss: 2.546326118680749

Epoch: 6| Step: 10
Training loss: 2.3124099920128542
Validation loss: 2.556195410685051

Epoch: 6| Step: 11
Training loss: 2.5705651619974925
Validation loss: 2.573121090183254

Epoch: 6| Step: 12
Training loss: 3.0563392173679107
Validation loss: 2.5786530123969693

Epoch: 6| Step: 13
Training loss: 2.218494131889088
Validation loss: 2.580830531326801

Epoch: 248| Step: 0
Training loss: 2.4737042319992275
Validation loss: 2.5611609865458034

Epoch: 6| Step: 1
Training loss: 2.3158262919506174
Validation loss: 2.558781118013111

Epoch: 6| Step: 2
Training loss: 2.725776624689308
Validation loss: 2.540508469009481

Epoch: 6| Step: 3
Training loss: 2.165222407980133
Validation loss: 2.5178247901174555

Epoch: 6| Step: 4
Training loss: 2.3649868949865773
Validation loss: 2.5166547243921107

Epoch: 6| Step: 5
Training loss: 2.6474780480012363
Validation loss: 2.5165173866130983

Epoch: 6| Step: 6
Training loss: 2.97223819795714
Validation loss: 2.5240451755770192

Epoch: 6| Step: 7
Training loss: 3.0280335655619677
Validation loss: 2.5228735053704323

Epoch: 6| Step: 8
Training loss: 2.956091949560739
Validation loss: 2.5143426658463253

Epoch: 6| Step: 9
Training loss: 3.2700148285229176
Validation loss: 2.536625374362022

Epoch: 6| Step: 10
Training loss: 2.914595731572977
Validation loss: 2.55086152239473

Epoch: 6| Step: 11
Training loss: 2.3636440030221264
Validation loss: 2.5713261097047955

Epoch: 6| Step: 12
Training loss: 2.47334701748513
Validation loss: 2.587199228822336

Epoch: 6| Step: 13
Training loss: 3.097401015552791
Validation loss: 2.602345175045781

Epoch: 249| Step: 0
Training loss: 2.9621371855870877
Validation loss: 2.623759432165434

Epoch: 6| Step: 1
Training loss: 2.383260716041155
Validation loss: 2.6111153618783707

Epoch: 6| Step: 2
Training loss: 3.384443000258251
Validation loss: 2.6249079094831336

Epoch: 6| Step: 3
Training loss: 2.4998378701089905
Validation loss: 2.61000801411927

Epoch: 6| Step: 4
Training loss: 2.3365194048803284
Validation loss: 2.603514724013824

Epoch: 6| Step: 5
Training loss: 2.3097472431568153
Validation loss: 2.5904611531431114

Epoch: 6| Step: 6
Training loss: 3.0581592236538695
Validation loss: 2.597410918931728

Epoch: 6| Step: 7
Training loss: 2.8615317626981995
Validation loss: 2.6136811190198235

Epoch: 6| Step: 8
Training loss: 2.625525467367887
Validation loss: 2.6007037726386226

Epoch: 6| Step: 9
Training loss: 3.1149890001816125
Validation loss: 2.599912042605088

Epoch: 6| Step: 10
Training loss: 2.0561048601402443
Validation loss: 2.617892037487135

Epoch: 6| Step: 11
Training loss: 2.2948944479744053
Validation loss: 2.6107992954641457

Epoch: 6| Step: 12
Training loss: 2.4704113935042313
Validation loss: 2.595281531051169

Epoch: 6| Step: 13
Training loss: 2.845004968085753
Validation loss: 2.566384829019118

Epoch: 250| Step: 0
Training loss: 2.211039941793577
Validation loss: 2.5412125412913227

Epoch: 6| Step: 1
Training loss: 2.427038877241031
Validation loss: 2.5025236015997163

Epoch: 6| Step: 2
Training loss: 2.700712505565842
Validation loss: 2.4860999393798373

Epoch: 6| Step: 3
Training loss: 2.203768372440188
Validation loss: 2.48693167335034

Epoch: 6| Step: 4
Training loss: 2.9782929284063075
Validation loss: 2.4762812856844083

Epoch: 6| Step: 5
Training loss: 3.0578297407456603
Validation loss: 2.467760665873946

Epoch: 6| Step: 6
Training loss: 3.360995021808437
Validation loss: 2.4755853285852147

Epoch: 6| Step: 7
Training loss: 2.197105028853309
Validation loss: 2.4772889376903136

Epoch: 6| Step: 8
Training loss: 2.9226004775945245
Validation loss: 2.477844455124179

Epoch: 6| Step: 9
Training loss: 3.0908477733772197
Validation loss: 2.4900653249137497

Epoch: 6| Step: 10
Training loss: 2.18481433035901
Validation loss: 2.493930113411403

Epoch: 6| Step: 11
Training loss: 2.4402441570195226
Validation loss: 2.510263932523284

Epoch: 6| Step: 12
Training loss: 3.0969780928834956
Validation loss: 2.5174538307149033

Epoch: 6| Step: 13
Training loss: 2.7497507329156523
Validation loss: 2.5328258590496247

Epoch: 251| Step: 0
Training loss: 2.465333723648285
Validation loss: 2.5487222088369332

Epoch: 6| Step: 1
Training loss: 2.707704578676962
Validation loss: 2.5933744996642747

Epoch: 6| Step: 2
Training loss: 2.89942179210194
Validation loss: 2.5999958071031988

Epoch: 6| Step: 3
Training loss: 2.253890806042734
Validation loss: 2.586391399101378

Epoch: 6| Step: 4
Training loss: 2.475132767169957
Validation loss: 2.581512552471546

Epoch: 6| Step: 5
Training loss: 2.9604809089435515
Validation loss: 2.569481238586096

Epoch: 6| Step: 6
Training loss: 2.6211281332157084
Validation loss: 2.5543126153609372

Epoch: 6| Step: 7
Training loss: 2.805886864902577
Validation loss: 2.549834711362736

Epoch: 6| Step: 8
Training loss: 2.6535569844644007
Validation loss: 2.5414426722706325

Epoch: 6| Step: 9
Training loss: 2.3091363930711024
Validation loss: 2.521877330608119

Epoch: 6| Step: 10
Training loss: 2.5109533683308674
Validation loss: 2.506765719663917

Epoch: 6| Step: 11
Training loss: 2.72084920234979
Validation loss: 2.520367101194289

Epoch: 6| Step: 12
Training loss: 2.9278719960671102
Validation loss: 2.529331758073066

Epoch: 6| Step: 13
Training loss: 3.2589544037692777
Validation loss: 2.518353678537779

Epoch: 252| Step: 0
Training loss: 2.862911851064886
Validation loss: 2.5460378374558417

Epoch: 6| Step: 1
Training loss: 2.706107638449144
Validation loss: 2.5417583159234924

Epoch: 6| Step: 2
Training loss: 2.7708857442923125
Validation loss: 2.5554901504870755

Epoch: 6| Step: 3
Training loss: 2.3266482181783186
Validation loss: 2.560314991679905

Epoch: 6| Step: 4
Training loss: 2.7827354493309517
Validation loss: 2.562983923637441

Epoch: 6| Step: 5
Training loss: 2.739382795722691
Validation loss: 2.564719821604099

Epoch: 6| Step: 6
Training loss: 2.8443953232530546
Validation loss: 2.5629748582992016

Epoch: 6| Step: 7
Training loss: 2.732713815991324
Validation loss: 2.5736732647520784

Epoch: 6| Step: 8
Training loss: 2.850151653605008
Validation loss: 2.5875396509091435

Epoch: 6| Step: 9
Training loss: 2.9204786911604854
Validation loss: 2.5909140153514163

Epoch: 6| Step: 10
Training loss: 2.3592884982590787
Validation loss: 2.632257788159424

Epoch: 6| Step: 11
Training loss: 2.8475313303147383
Validation loss: 2.644521980465099

Epoch: 6| Step: 12
Training loss: 2.3880026403057895
Validation loss: 2.631381679941653

Epoch: 6| Step: 13
Training loss: 1.5469334909189012
Validation loss: 2.5852724122249864

Epoch: 253| Step: 0
Training loss: 2.753969275652914
Validation loss: 2.5401947894347456

Epoch: 6| Step: 1
Training loss: 2.3809933581686167
Validation loss: 2.5058686653766618

Epoch: 6| Step: 2
Training loss: 2.7858908862772997
Validation loss: 2.4988816620955117

Epoch: 6| Step: 3
Training loss: 2.8257183984459022
Validation loss: 2.4857661136450546

Epoch: 6| Step: 4
Training loss: 2.2368276512930887
Validation loss: 2.494376024856238

Epoch: 6| Step: 5
Training loss: 2.467654407621063
Validation loss: 2.4922727177509816

Epoch: 6| Step: 6
Training loss: 2.6751658379317367
Validation loss: 2.501157663834201

Epoch: 6| Step: 7
Training loss: 2.413618423455325
Validation loss: 2.4999283647015833

Epoch: 6| Step: 8
Training loss: 2.7138519012141455
Validation loss: 2.5086031029713767

Epoch: 6| Step: 9
Training loss: 2.8157990498152436
Validation loss: 2.5385069152959794

Epoch: 6| Step: 10
Training loss: 3.201612161797602
Validation loss: 2.5895731564709736

Epoch: 6| Step: 11
Training loss: 2.799870852489253
Validation loss: 2.6059723301746702

Epoch: 6| Step: 12
Training loss: 2.7164484564393447
Validation loss: 2.656130999047511

Epoch: 6| Step: 13
Training loss: 3.0034506344371596
Validation loss: 2.6556661660316014

Epoch: 254| Step: 0
Training loss: 2.6909234177186936
Validation loss: 2.6265050994339476

Epoch: 6| Step: 1
Training loss: 3.373881967231307
Validation loss: 2.608529295550378

Epoch: 6| Step: 2
Training loss: 2.3392383129679577
Validation loss: 2.5942995467993963

Epoch: 6| Step: 3
Training loss: 2.2698749538043286
Validation loss: 2.5744133277476133

Epoch: 6| Step: 4
Training loss: 2.6798359020723885
Validation loss: 2.5544431510024377

Epoch: 6| Step: 5
Training loss: 3.03388484999349
Validation loss: 2.541930520012386

Epoch: 6| Step: 6
Training loss: 2.4479763159011343
Validation loss: 2.5240146275808546

Epoch: 6| Step: 7
Training loss: 2.934606222482034
Validation loss: 2.531449945438284

Epoch: 6| Step: 8
Training loss: 2.9594531201018484
Validation loss: 2.5165317037416797

Epoch: 6| Step: 9
Training loss: 2.3842964929377706
Validation loss: 2.5191773128092905

Epoch: 6| Step: 10
Training loss: 2.5595872653602068
Validation loss: 2.506119238835984

Epoch: 6| Step: 11
Training loss: 2.498363054322248
Validation loss: 2.5148703884638333

Epoch: 6| Step: 12
Training loss: 2.6685463320630554
Validation loss: 2.5254610558747

Epoch: 6| Step: 13
Training loss: 2.228004818279323
Validation loss: 2.536324698249804

Epoch: 255| Step: 0
Training loss: 2.516202682603571
Validation loss: 2.566651499697691

Epoch: 6| Step: 1
Training loss: 2.4814341671335693
Validation loss: 2.591246392795979

Epoch: 6| Step: 2
Training loss: 2.478863438459893
Validation loss: 2.637978035037937

Epoch: 6| Step: 3
Training loss: 2.354922001836814
Validation loss: 2.6878555760889022

Epoch: 6| Step: 4
Training loss: 2.9306518595109985
Validation loss: 2.7014652666731407

Epoch: 6| Step: 5
Training loss: 3.0229802537500947
Validation loss: 2.7059813371706016

Epoch: 6| Step: 6
Training loss: 2.6330868722367677
Validation loss: 2.721697005829919

Epoch: 6| Step: 7
Training loss: 2.6460306489514496
Validation loss: 2.6518706150222706

Epoch: 6| Step: 8
Training loss: 2.492858891949097
Validation loss: 2.627432517936139

Epoch: 6| Step: 9
Training loss: 2.8720522156540538
Validation loss: 2.5956408767596066

Epoch: 6| Step: 10
Training loss: 2.666287474693057
Validation loss: 2.5516893542727686

Epoch: 6| Step: 11
Training loss: 2.5081442735294113
Validation loss: 2.526349247604351

Epoch: 6| Step: 12
Training loss: 2.962222985301484
Validation loss: 2.510686794924969

Epoch: 6| Step: 13
Training loss: 2.6339265634007223
Validation loss: 2.497109571645716

Epoch: 256| Step: 0
Training loss: 3.0500252894619453
Validation loss: 2.4712829866591193

Epoch: 6| Step: 1
Training loss: 2.8575587106248523
Validation loss: 2.4855463082969997

Epoch: 6| Step: 2
Training loss: 1.8973695867501317
Validation loss: 2.4910319647956727

Epoch: 6| Step: 3
Training loss: 2.934806075439986
Validation loss: 2.4935509306302714

Epoch: 6| Step: 4
Training loss: 2.51455627865105
Validation loss: 2.520124859782417

Epoch: 6| Step: 5
Training loss: 2.5294159261014344
Validation loss: 2.5227780577817125

Epoch: 6| Step: 6
Training loss: 2.5395612490921784
Validation loss: 2.5293597677702775

Epoch: 6| Step: 7
Training loss: 2.7934563057839688
Validation loss: 2.537906151061617

Epoch: 6| Step: 8
Training loss: 2.274451065909003
Validation loss: 2.563417874072175

Epoch: 6| Step: 9
Training loss: 2.393873911705724
Validation loss: 2.5911658646729663

Epoch: 6| Step: 10
Training loss: 2.9295812155199994
Validation loss: 2.574624862130307

Epoch: 6| Step: 11
Training loss: 2.66345360025644
Validation loss: 2.583871138089289

Epoch: 6| Step: 12
Training loss: 2.903423452486013
Validation loss: 2.5710488538905687

Epoch: 6| Step: 13
Training loss: 2.5324547808602724
Validation loss: 2.548282596939886

Epoch: 257| Step: 0
Training loss: 2.257408449126778
Validation loss: 2.5458298700480038

Epoch: 6| Step: 1
Training loss: 2.879999043941339
Validation loss: 2.5411577251444193

Epoch: 6| Step: 2
Training loss: 2.215020927864219
Validation loss: 2.549021431622233

Epoch: 6| Step: 3
Training loss: 2.549772895722908
Validation loss: 2.558528585887131

Epoch: 6| Step: 4
Training loss: 2.528474015521609
Validation loss: 2.567597539068469

Epoch: 6| Step: 5
Training loss: 1.8795512593173316
Validation loss: 2.585430648160515

Epoch: 6| Step: 6
Training loss: 2.625692185466496
Validation loss: 2.589754756067307

Epoch: 6| Step: 7
Training loss: 2.0281665580265265
Validation loss: 2.596464416774452

Epoch: 6| Step: 8
Training loss: 2.555693915210628
Validation loss: 2.577804787178652

Epoch: 6| Step: 9
Training loss: 2.3211479352740008
Validation loss: 2.5615265370579148

Epoch: 6| Step: 10
Training loss: 3.7713954920990065
Validation loss: 2.534597900423963

Epoch: 6| Step: 11
Training loss: 3.179515037264706
Validation loss: 2.5222369538717015

Epoch: 6| Step: 12
Training loss: 2.82978696095391
Validation loss: 2.4932992626987205

Epoch: 6| Step: 13
Training loss: 3.1695391693655686
Validation loss: 2.511696446179599

Epoch: 258| Step: 0
Training loss: 2.765366967874336
Validation loss: 2.5283733790705627

Epoch: 6| Step: 1
Training loss: 2.3793489892939212
Validation loss: 2.529887009299701

Epoch: 6| Step: 2
Training loss: 2.3244631855117777
Validation loss: 2.5417106889543133

Epoch: 6| Step: 3
Training loss: 2.7395465882209784
Validation loss: 2.5609709486905192

Epoch: 6| Step: 4
Training loss: 3.218372952497076
Validation loss: 2.5803026098250954

Epoch: 6| Step: 5
Training loss: 2.623938663818328
Validation loss: 2.6072817649373223

Epoch: 6| Step: 6
Training loss: 2.45715855691653
Validation loss: 2.6300656496324097

Epoch: 6| Step: 7
Training loss: 2.55587759499729
Validation loss: 2.6323511437495295

Epoch: 6| Step: 8
Training loss: 3.0644932702317846
Validation loss: 2.607527249277755

Epoch: 6| Step: 9
Training loss: 2.322382661711242
Validation loss: 2.6229922345787697

Epoch: 6| Step: 10
Training loss: 2.8748915278662377
Validation loss: 2.6331610984546967

Epoch: 6| Step: 11
Training loss: 2.3653161234001985
Validation loss: 2.639062645363429

Epoch: 6| Step: 12
Training loss: 2.690209996276529
Validation loss: 2.6269740032978586

Epoch: 6| Step: 13
Training loss: 2.0796668277346453
Validation loss: 2.5933740182478404

Epoch: 259| Step: 0
Training loss: 2.549954290541322
Validation loss: 2.591106652734344

Epoch: 6| Step: 1
Training loss: 2.784524254699931
Validation loss: 2.5738033941968896

Epoch: 6| Step: 2
Training loss: 2.4195220346001247
Validation loss: 2.5810314323598087

Epoch: 6| Step: 3
Training loss: 2.753035344061506
Validation loss: 2.5775424322690434

Epoch: 6| Step: 4
Training loss: 2.310122117947253
Validation loss: 2.552166347564043

Epoch: 6| Step: 5
Training loss: 2.3362732712927095
Validation loss: 2.5628495136829677

Epoch: 6| Step: 6
Training loss: 2.832049770952369
Validation loss: 2.575142598546999

Epoch: 6| Step: 7
Training loss: 2.1044077845241103
Validation loss: 2.5712568703407386

Epoch: 6| Step: 8
Training loss: 2.6371005763756252
Validation loss: 2.5550331969876177

Epoch: 6| Step: 9
Training loss: 2.453075141157083
Validation loss: 2.537326771632309

Epoch: 6| Step: 10
Training loss: 2.7181257210820675
Validation loss: 2.5204051328763057

Epoch: 6| Step: 11
Training loss: 3.2903221056175975
Validation loss: 2.5109659743759933

Epoch: 6| Step: 12
Training loss: 2.587111100166456
Validation loss: 2.5433604233332727

Epoch: 6| Step: 13
Training loss: 2.9600559824727233
Validation loss: 2.5994008008803346

Epoch: 260| Step: 0
Training loss: 2.042829169616332
Validation loss: 2.6624657133749583

Epoch: 6| Step: 1
Training loss: 2.101346143058196
Validation loss: 2.722333107292239

Epoch: 6| Step: 2
Training loss: 2.7639774221003273
Validation loss: 2.796635378074994

Epoch: 6| Step: 3
Training loss: 2.717671761510983
Validation loss: 2.791282577490962

Epoch: 6| Step: 4
Training loss: 2.8944100008343128
Validation loss: 2.6618444413403206

Epoch: 6| Step: 5
Training loss: 2.6842265930718483
Validation loss: 2.5574316298041926

Epoch: 6| Step: 6
Training loss: 2.64939525469619
Validation loss: 2.4878731450869576

Epoch: 6| Step: 7
Training loss: 2.513725463959897
Validation loss: 2.4804029214883316

Epoch: 6| Step: 8
Training loss: 3.411828468957212
Validation loss: 2.4933826081838726

Epoch: 6| Step: 9
Training loss: 2.03287194859268
Validation loss: 2.4878216939505546

Epoch: 6| Step: 10
Training loss: 3.00669875889784
Validation loss: 2.4986144010021345

Epoch: 6| Step: 11
Training loss: 2.5800910620180955
Validation loss: 2.507393325409431

Epoch: 6| Step: 12
Training loss: 2.9716946102874573
Validation loss: 2.5101675560902863

Epoch: 6| Step: 13
Training loss: 3.2248051547547507
Validation loss: 2.5607546052694357

Epoch: 261| Step: 0
Training loss: 3.173689750589305
Validation loss: 2.5758688313854465

Epoch: 6| Step: 1
Training loss: 2.4094749736701306
Validation loss: 2.5974347479267865

Epoch: 6| Step: 2
Training loss: 2.2673781353589026
Validation loss: 2.655178587973993

Epoch: 6| Step: 3
Training loss: 2.857089771050057
Validation loss: 2.737364946758289

Epoch: 6| Step: 4
Training loss: 2.6163403406780392
Validation loss: 2.7608661851345726

Epoch: 6| Step: 5
Training loss: 2.491345684933823
Validation loss: 2.8296120151209374

Epoch: 6| Step: 6
Training loss: 2.9982603115189788
Validation loss: 2.86900137513249

Epoch: 6| Step: 7
Training loss: 2.45542003402423
Validation loss: 2.8098301948510414

Epoch: 6| Step: 8
Training loss: 2.2692280499517867
Validation loss: 2.7579029496845027

Epoch: 6| Step: 9
Training loss: 3.0377420336835725
Validation loss: 2.702318002663606

Epoch: 6| Step: 10
Training loss: 2.939251803477478
Validation loss: 2.6503697222349234

Epoch: 6| Step: 11
Training loss: 2.303983833090699
Validation loss: 2.5397790677336176

Epoch: 6| Step: 12
Training loss: 2.9524919749771867
Validation loss: 2.5312458019558535

Epoch: 6| Step: 13
Training loss: 3.3105123062354456
Validation loss: 2.506114381853385

Epoch: 262| Step: 0
Training loss: 2.934776179603009
Validation loss: 2.486020746874801

Epoch: 6| Step: 1
Training loss: 2.7454726492166035
Validation loss: 2.474544180051653

Epoch: 6| Step: 2
Training loss: 2.0519782360551235
Validation loss: 2.4811469541885645

Epoch: 6| Step: 3
Training loss: 2.269077170245386
Validation loss: 2.487677524114939

Epoch: 6| Step: 4
Training loss: 2.118467612563897
Validation loss: 2.504558664642125

Epoch: 6| Step: 5
Training loss: 3.1132568971071524
Validation loss: 2.5162288445747305

Epoch: 6| Step: 6
Training loss: 2.7156559669124958
Validation loss: 2.5388109227344473

Epoch: 6| Step: 7
Training loss: 1.9136218128091838
Validation loss: 2.558485411431185

Epoch: 6| Step: 8
Training loss: 2.930440495679491
Validation loss: 2.6150369917751233

Epoch: 6| Step: 9
Training loss: 3.1401643177943765
Validation loss: 2.6314199055909917

Epoch: 6| Step: 10
Training loss: 2.6162365452565797
Validation loss: 2.6182739314562484

Epoch: 6| Step: 11
Training loss: 3.112789560353526
Validation loss: 2.5896795728072743

Epoch: 6| Step: 12
Training loss: 2.259730702281198
Validation loss: 2.580963990970348

Epoch: 6| Step: 13
Training loss: 2.6222999855766824
Validation loss: 2.573769817083063

Epoch: 263| Step: 0
Training loss: 1.9382907115331722
Validation loss: 2.560543219586099

Epoch: 6| Step: 1
Training loss: 2.1637568619485403
Validation loss: 2.5624533898381188

Epoch: 6| Step: 2
Training loss: 2.429985494217139
Validation loss: 2.581222473290149

Epoch: 6| Step: 3
Training loss: 2.856079203300802
Validation loss: 2.592896411098285

Epoch: 6| Step: 4
Training loss: 2.9688145680684057
Validation loss: 2.5989891755864187

Epoch: 6| Step: 5
Training loss: 2.632935473006714
Validation loss: 2.59117717619872

Epoch: 6| Step: 6
Training loss: 2.916811712382327
Validation loss: 2.5939740092761285

Epoch: 6| Step: 7
Training loss: 2.0141222179192155
Validation loss: 2.586210355362673

Epoch: 6| Step: 8
Training loss: 2.212707673579649
Validation loss: 2.608031728530052

Epoch: 6| Step: 9
Training loss: 2.688151258470313
Validation loss: 2.6430195160559156

Epoch: 6| Step: 10
Training loss: 2.722558434369839
Validation loss: 2.633939465634787

Epoch: 6| Step: 11
Training loss: 3.0221567521608383
Validation loss: 2.6606142570948985

Epoch: 6| Step: 12
Training loss: 2.627576562580836
Validation loss: 2.631486510772791

Epoch: 6| Step: 13
Training loss: 3.1735665457110165
Validation loss: 2.606865747098704

Epoch: 264| Step: 0
Training loss: 2.7195946269333913
Validation loss: 2.5991992523535075

Epoch: 6| Step: 1
Training loss: 2.959902136963381
Validation loss: 2.5625265566782596

Epoch: 6| Step: 2
Training loss: 2.9967105633409865
Validation loss: 2.5885842242782124

Epoch: 6| Step: 3
Training loss: 2.5851809037325015
Validation loss: 2.587713707394446

Epoch: 6| Step: 4
Training loss: 1.9744018083366262
Validation loss: 2.6028531416992347

Epoch: 6| Step: 5
Training loss: 2.2857880069560563
Validation loss: 2.5944641845881544

Epoch: 6| Step: 6
Training loss: 3.063364646455482
Validation loss: 2.6197989964464687

Epoch: 6| Step: 7
Training loss: 2.7375729416139287
Validation loss: 2.598635189060258

Epoch: 6| Step: 8
Training loss: 2.3182497456572158
Validation loss: 2.633210114768287

Epoch: 6| Step: 9
Training loss: 2.686219376025125
Validation loss: 2.6316084468755463

Epoch: 6| Step: 10
Training loss: 2.5747442099919766
Validation loss: 2.643852088632975

Epoch: 6| Step: 11
Training loss: 2.29347506754205
Validation loss: 2.616037533477798

Epoch: 6| Step: 12
Training loss: 2.8216715996014337
Validation loss: 2.5829597590721423

Epoch: 6| Step: 13
Training loss: 1.6814088030270118
Validation loss: 2.599395663535889

Epoch: 265| Step: 0
Training loss: 2.2310954748334426
Validation loss: 2.6020689711524176

Epoch: 6| Step: 1
Training loss: 1.9387481729780451
Validation loss: 2.6110897853884887

Epoch: 6| Step: 2
Training loss: 2.6044100736669
Validation loss: 2.622461276951583

Epoch: 6| Step: 3
Training loss: 3.003232486004078
Validation loss: 2.6464858532307254

Epoch: 6| Step: 4
Training loss: 2.4612360697478475
Validation loss: 2.605697931453356

Epoch: 6| Step: 5
Training loss: 2.4099823380452277
Validation loss: 2.556592314633547

Epoch: 6| Step: 6
Training loss: 2.661317904973588
Validation loss: 2.5053009274651377

Epoch: 6| Step: 7
Training loss: 2.8757311679051356
Validation loss: 2.4750333250737095

Epoch: 6| Step: 8
Training loss: 2.6472222795071705
Validation loss: 2.4894498707863866

Epoch: 6| Step: 9
Training loss: 2.795217779611335
Validation loss: 2.4912737699135903

Epoch: 6| Step: 10
Training loss: 2.918238697561813
Validation loss: 2.4919777642185728

Epoch: 6| Step: 11
Training loss: 2.7565413617304317
Validation loss: 2.490723826021709

Epoch: 6| Step: 12
Training loss: 2.3512601436252196
Validation loss: 2.543368466951367

Epoch: 6| Step: 13
Training loss: 3.06847421684951
Validation loss: 2.583788240916938

Epoch: 266| Step: 0
Training loss: 2.6535358699417704
Validation loss: 2.6545341513800236

Epoch: 6| Step: 1
Training loss: 2.5242625679881234
Validation loss: 2.704261146011208

Epoch: 6| Step: 2
Training loss: 2.976852442920029
Validation loss: 2.7218897738388432

Epoch: 6| Step: 3
Training loss: 2.790450063521445
Validation loss: 2.7426996675109248

Epoch: 6| Step: 4
Training loss: 2.9601238008332973
Validation loss: 2.7520741744427504

Epoch: 6| Step: 5
Training loss: 2.827908502374632
Validation loss: 2.6755446352532717

Epoch: 6| Step: 6
Training loss: 2.2595474282892307
Validation loss: 2.6042538621312343

Epoch: 6| Step: 7
Training loss: 1.9808232518721782
Validation loss: 2.5439048775370914

Epoch: 6| Step: 8
Training loss: 2.4810368405504786
Validation loss: 2.5047987340705635

Epoch: 6| Step: 9
Training loss: 2.8131890194686586
Validation loss: 2.5086186854566876

Epoch: 6| Step: 10
Training loss: 2.628325581012034
Validation loss: 2.492799716438941

Epoch: 6| Step: 11
Training loss: 2.193311763800372
Validation loss: 2.5215544523880555

Epoch: 6| Step: 12
Training loss: 2.7540187947969286
Validation loss: 2.549848364854261

Epoch: 6| Step: 13
Training loss: 2.635321262326505
Validation loss: 2.5567272510685752

Epoch: 267| Step: 0
Training loss: 3.1465725735427252
Validation loss: 2.549188201204246

Epoch: 6| Step: 1
Training loss: 2.6122413470708787
Validation loss: 2.5639520608347093

Epoch: 6| Step: 2
Training loss: 2.306851163424214
Validation loss: 2.5430303096463667

Epoch: 6| Step: 3
Training loss: 3.146029552546448
Validation loss: 2.5358129494197557

Epoch: 6| Step: 4
Training loss: 2.5014453524549283
Validation loss: 2.5387362524403496

Epoch: 6| Step: 5
Training loss: 2.5843423493062927
Validation loss: 2.5170309985589543

Epoch: 6| Step: 6
Training loss: 2.788710884561998
Validation loss: 2.523222502381731

Epoch: 6| Step: 7
Training loss: 2.8975703749449795
Validation loss: 2.539060007098846

Epoch: 6| Step: 8
Training loss: 2.1263309125625858
Validation loss: 2.547206429048058

Epoch: 6| Step: 9
Training loss: 2.58249825136877
Validation loss: 2.5701857427515247

Epoch: 6| Step: 10
Training loss: 2.3941582393885192
Validation loss: 2.6040352953517476

Epoch: 6| Step: 11
Training loss: 2.5608685580196924
Validation loss: 2.6162602400228647

Epoch: 6| Step: 12
Training loss: 2.337504088046329
Validation loss: 2.5897740153136923

Epoch: 6| Step: 13
Training loss: 2.015463889137071
Validation loss: 2.5798979479234774

Epoch: 268| Step: 0
Training loss: 2.4361065525121988
Validation loss: 2.592522079568835

Epoch: 6| Step: 1
Training loss: 2.1709130441549203
Validation loss: 2.572399498108319

Epoch: 6| Step: 2
Training loss: 2.860772797006737
Validation loss: 2.582595450548863

Epoch: 6| Step: 3
Training loss: 3.0326377602127113
Validation loss: 2.554715354626838

Epoch: 6| Step: 4
Training loss: 2.8247348424651855
Validation loss: 2.5211706672255647

Epoch: 6| Step: 5
Training loss: 1.763854227534813
Validation loss: 2.5412199581673773

Epoch: 6| Step: 6
Training loss: 2.3842438947998037
Validation loss: 2.541152788848774

Epoch: 6| Step: 7
Training loss: 2.3449828910610195
Validation loss: 2.543873345599839

Epoch: 6| Step: 8
Training loss: 2.885096195937746
Validation loss: 2.5424292116640594

Epoch: 6| Step: 9
Training loss: 2.678777690393658
Validation loss: 2.5799963440566707

Epoch: 6| Step: 10
Training loss: 2.3928927965903783
Validation loss: 2.6203930925143215

Epoch: 6| Step: 11
Training loss: 2.480659057045084
Validation loss: 2.7749187492693212

Epoch: 6| Step: 12
Training loss: 2.9073656463413537
Validation loss: 2.848966015658795

Epoch: 6| Step: 13
Training loss: 2.6612353943817713
Validation loss: 2.8827777643359545

Epoch: 269| Step: 0
Training loss: 2.7727364527156673
Validation loss: 2.9278886858045525

Epoch: 6| Step: 1
Training loss: 2.221115999918783
Validation loss: 2.8275101616043985

Epoch: 6| Step: 2
Training loss: 3.054567768843174
Validation loss: 2.7420241102098655

Epoch: 6| Step: 3
Training loss: 2.905170855594437
Validation loss: 2.6547849491142412

Epoch: 6| Step: 4
Training loss: 2.805027848103775
Validation loss: 2.535094000596598

Epoch: 6| Step: 5
Training loss: 2.6604819301485536
Validation loss: 2.493124982871256

Epoch: 6| Step: 6
Training loss: 2.843997148107287
Validation loss: 2.4719967679578296

Epoch: 6| Step: 7
Training loss: 2.5655525448194374
Validation loss: 2.4789998094953543

Epoch: 6| Step: 8
Training loss: 2.5976389948909993
Validation loss: 2.4728313317251183

Epoch: 6| Step: 9
Training loss: 2.6435934683270137
Validation loss: 2.45944707310679

Epoch: 6| Step: 10
Training loss: 1.9531348266354362
Validation loss: 2.4676300972937413

Epoch: 6| Step: 11
Training loss: 2.3047730510803195
Validation loss: 2.483637117083114

Epoch: 6| Step: 12
Training loss: 2.98775781771946
Validation loss: 2.51884700269066

Epoch: 6| Step: 13
Training loss: 2.8427868563965326
Validation loss: 2.5430365215795243

Epoch: 270| Step: 0
Training loss: 2.409084483640291
Validation loss: 2.58434571810065

Epoch: 6| Step: 1
Training loss: 2.54876610691431
Validation loss: 2.6352473041655005

Epoch: 6| Step: 2
Training loss: 2.8231792726635203
Validation loss: 2.6559344051725247

Epoch: 6| Step: 3
Training loss: 2.345732295659326
Validation loss: 2.6714160800684006

Epoch: 6| Step: 4
Training loss: 2.7271191047982066
Validation loss: 2.6674323873289936

Epoch: 6| Step: 5
Training loss: 2.2977612919874977
Validation loss: 2.6438164368613895

Epoch: 6| Step: 6
Training loss: 1.7708123224545316
Validation loss: 2.65065172833429

Epoch: 6| Step: 7
Training loss: 2.629087263340043
Validation loss: 2.6683787174721654

Epoch: 6| Step: 8
Training loss: 2.54069058379373
Validation loss: 2.6628101737261147

Epoch: 6| Step: 9
Training loss: 2.7137924244436107
Validation loss: 2.634734326156054

Epoch: 6| Step: 10
Training loss: 2.480340524798464
Validation loss: 2.638357281061746

Epoch: 6| Step: 11
Training loss: 2.1705546585227395
Validation loss: 2.6322087005445836

Epoch: 6| Step: 12
Training loss: 3.3504061893912405
Validation loss: 2.6158416613227047

Epoch: 6| Step: 13
Training loss: 3.436425752110478
Validation loss: 2.5998574740814977

Epoch: 271| Step: 0
Training loss: 2.577692076429505
Validation loss: 2.5780341377542197

Epoch: 6| Step: 1
Training loss: 2.363618987359686
Validation loss: 2.5690355382574315

Epoch: 6| Step: 2
Training loss: 2.270473475042772
Validation loss: 2.5861627034367243

Epoch: 6| Step: 3
Training loss: 2.585964421711259
Validation loss: 2.5695137024199606

Epoch: 6| Step: 4
Training loss: 2.8216404205862124
Validation loss: 2.5678102708968957

Epoch: 6| Step: 5
Training loss: 2.8666249900568026
Validation loss: 2.5652402432051944

Epoch: 6| Step: 6
Training loss: 2.712324683505133
Validation loss: 2.5607375004565514

Epoch: 6| Step: 7
Training loss: 2.3816300256614333
Validation loss: 2.5491511188857823

Epoch: 6| Step: 8
Training loss: 3.051537648308303
Validation loss: 2.549482165564059

Epoch: 6| Step: 9
Training loss: 2.19949680555857
Validation loss: 2.5662367272734943

Epoch: 6| Step: 10
Training loss: 2.6342689719080363
Validation loss: 2.585446138451876

Epoch: 6| Step: 11
Training loss: 2.345723453023908
Validation loss: 2.6083632309189673

Epoch: 6| Step: 12
Training loss: 2.5206955696062483
Validation loss: 2.6139901581636447

Epoch: 6| Step: 13
Training loss: 2.309338134966932
Validation loss: 2.6198799292780586

Epoch: 272| Step: 0
Training loss: 2.6556661525167367
Validation loss: 2.641349279085788

Epoch: 6| Step: 1
Training loss: 2.138569868607584
Validation loss: 2.678355203135157

Epoch: 6| Step: 2
Training loss: 2.587846034403577
Validation loss: 2.6770552722342362

Epoch: 6| Step: 3
Training loss: 2.311012408194746
Validation loss: 2.660451714368851

Epoch: 6| Step: 4
Training loss: 2.702454412112874
Validation loss: 2.6171078611821934

Epoch: 6| Step: 5
Training loss: 2.5307279448746045
Validation loss: 2.604713439310282

Epoch: 6| Step: 6
Training loss: 2.406051627565227
Validation loss: 2.5629173057067844

Epoch: 6| Step: 7
Training loss: 2.336010985988755
Validation loss: 2.5577351449353047

Epoch: 6| Step: 8
Training loss: 2.8200314875799495
Validation loss: 2.530690561666616

Epoch: 6| Step: 9
Training loss: 2.5597954410543675
Validation loss: 2.5256258650336383

Epoch: 6| Step: 10
Training loss: 2.4171289023834257
Validation loss: 2.5316237124778365

Epoch: 6| Step: 11
Training loss: 2.7836177048681576
Validation loss: 2.546032972043708

Epoch: 6| Step: 12
Training loss: 2.757883043980898
Validation loss: 2.5687205916824305

Epoch: 6| Step: 13
Training loss: 2.975092807892919
Validation loss: 2.595512945450042

Epoch: 273| Step: 0
Training loss: 2.6249416889798587
Validation loss: 2.639219400842962

Epoch: 6| Step: 1
Training loss: 2.8702378015656858
Validation loss: 2.6522489822548425

Epoch: 6| Step: 2
Training loss: 2.559639613593494
Validation loss: 2.6470005334407554

Epoch: 6| Step: 3
Training loss: 2.5332451010279926
Validation loss: 2.6616148469889973

Epoch: 6| Step: 4
Training loss: 3.048142076780421
Validation loss: 2.6327069585354788

Epoch: 6| Step: 5
Training loss: 2.6283244017661116
Validation loss: 2.6507344126584957

Epoch: 6| Step: 6
Training loss: 1.7938754712393186
Validation loss: 2.6475360737582636

Epoch: 6| Step: 7
Training loss: 2.5441316210568257
Validation loss: 2.674574984541195

Epoch: 6| Step: 8
Training loss: 1.7312313836263926
Validation loss: 2.6711095617724103

Epoch: 6| Step: 9
Training loss: 2.667722006428474
Validation loss: 2.6511343862759387

Epoch: 6| Step: 10
Training loss: 2.697860088761594
Validation loss: 2.6223732628523986

Epoch: 6| Step: 11
Training loss: 2.29886162408552
Validation loss: 2.6342420124984063

Epoch: 6| Step: 12
Training loss: 2.557492643851014
Validation loss: 2.6402532523723616

Epoch: 6| Step: 13
Training loss: 2.8495185110706127
Validation loss: 2.635497591513488

Epoch: 274| Step: 0
Training loss: 2.8117300039173747
Validation loss: 2.6540168287836345

Epoch: 6| Step: 1
Training loss: 2.839233164887944
Validation loss: 2.641188217109902

Epoch: 6| Step: 2
Training loss: 2.3944830586249704
Validation loss: 2.637026770195282

Epoch: 6| Step: 3
Training loss: 2.6786796075683337
Validation loss: 2.656071933324937

Epoch: 6| Step: 4
Training loss: 2.0070652146247854
Validation loss: 2.655802807451806

Epoch: 6| Step: 5
Training loss: 2.4676521854177547
Validation loss: 2.6566046558245815

Epoch: 6| Step: 6
Training loss: 2.4814202353551345
Validation loss: 2.6791135800661867

Epoch: 6| Step: 7
Training loss: 3.3564183198289075
Validation loss: 2.6604983739333243

Epoch: 6| Step: 8
Training loss: 1.754743210680086
Validation loss: 2.632408230090029

Epoch: 6| Step: 9
Training loss: 2.3674081630276333
Validation loss: 2.6142545607022645

Epoch: 6| Step: 10
Training loss: 2.5471600332079114
Validation loss: 2.58612235459144

Epoch: 6| Step: 11
Training loss: 2.617240518061404
Validation loss: 2.5506379451684986

Epoch: 6| Step: 12
Training loss: 2.3211933352158938
Validation loss: 2.532289146622908

Epoch: 6| Step: 13
Training loss: 2.6240626886950813
Validation loss: 2.5203718269595243

Epoch: 275| Step: 0
Training loss: 2.6209815011243096
Validation loss: 2.5650683996691592

Epoch: 6| Step: 1
Training loss: 2.70698368972019
Validation loss: 2.5993319030093662

Epoch: 6| Step: 2
Training loss: 2.7303097396195684
Validation loss: 2.6219065144988756

Epoch: 6| Step: 3
Training loss: 2.222338715784743
Validation loss: 2.677485692449891

Epoch: 6| Step: 4
Training loss: 2.5393542312873145
Validation loss: 2.671288866951176

Epoch: 6| Step: 5
Training loss: 2.5760176860486514
Validation loss: 2.654509456803792

Epoch: 6| Step: 6
Training loss: 2.6433791745970456
Validation loss: 2.651917035016493

Epoch: 6| Step: 7
Training loss: 2.2247512678354298
Validation loss: 2.647674273432819

Epoch: 6| Step: 8
Training loss: 2.5039641422714602
Validation loss: 2.6571631505736995

Epoch: 6| Step: 9
Training loss: 2.7616577141692837
Validation loss: 2.604683285239743

Epoch: 6| Step: 10
Training loss: 2.5333948349598066
Validation loss: 2.596614159162385

Epoch: 6| Step: 11
Training loss: 2.713301010345461
Validation loss: 2.62374136870009

Epoch: 6| Step: 12
Training loss: 2.2969796293133444
Validation loss: 2.6104581521625008

Epoch: 6| Step: 13
Training loss: 1.8233722299173085
Validation loss: 2.589859164402191

Epoch: 276| Step: 0
Training loss: 2.10341565417908
Validation loss: 2.5646859936210884

Epoch: 6| Step: 1
Training loss: 2.2429227786400454
Validation loss: 2.561746569064191

Epoch: 6| Step: 2
Training loss: 2.599916596175322
Validation loss: 2.542583480433897

Epoch: 6| Step: 3
Training loss: 2.622574548525407
Validation loss: 2.542179386451114

Epoch: 6| Step: 4
Training loss: 2.6495179079699236
Validation loss: 2.5349785736971966

Epoch: 6| Step: 5
Training loss: 2.8907681816312496
Validation loss: 2.5389983764325827

Epoch: 6| Step: 6
Training loss: 3.0298446071549376
Validation loss: 2.5576088619249764

Epoch: 6| Step: 7
Training loss: 2.372701436084482
Validation loss: 2.559027535768235

Epoch: 6| Step: 8
Training loss: 1.962638816054532
Validation loss: 2.56720474024969

Epoch: 6| Step: 9
Training loss: 2.251273324730163
Validation loss: 2.614485835220309

Epoch: 6| Step: 10
Training loss: 2.154937123312912
Validation loss: 2.6467954265366727

Epoch: 6| Step: 11
Training loss: 2.685563565289045
Validation loss: 2.6428733021572373

Epoch: 6| Step: 12
Training loss: 2.7479196829462356
Validation loss: 2.661024888450406

Epoch: 6| Step: 13
Training loss: 2.9070036536457207
Validation loss: 2.6824115191566866

Epoch: 277| Step: 0
Training loss: 2.2110291586703967
Validation loss: 2.6636128943404342

Epoch: 6| Step: 1
Training loss: 2.526610467062643
Validation loss: 2.634992864455539

Epoch: 6| Step: 2
Training loss: 2.7876703116215853
Validation loss: 2.6061610623190363

Epoch: 6| Step: 3
Training loss: 2.1233525341289643
Validation loss: 2.573531308358275

Epoch: 6| Step: 4
Training loss: 2.6350277599920946
Validation loss: 2.515820932219735

Epoch: 6| Step: 5
Training loss: 2.852944068143824
Validation loss: 2.4987189230524063

Epoch: 6| Step: 6
Training loss: 1.9654878504806288
Validation loss: 2.482962170169805

Epoch: 6| Step: 7
Training loss: 2.6642910588012527
Validation loss: 2.4805632656165164

Epoch: 6| Step: 8
Training loss: 2.816675773771412
Validation loss: 2.4671014421998683

Epoch: 6| Step: 9
Training loss: 2.708114429332634
Validation loss: 2.4922462827025105

Epoch: 6| Step: 10
Training loss: 2.898021411076885
Validation loss: 2.496854204697575

Epoch: 6| Step: 11
Training loss: 2.198253684096436
Validation loss: 2.5064361110370523

Epoch: 6| Step: 12
Training loss: 2.5615638325422374
Validation loss: 2.5102439085322725

Epoch: 6| Step: 13
Training loss: 1.9973227343721565
Validation loss: 2.533713089974155

Epoch: 278| Step: 0
Training loss: 2.926946145821537
Validation loss: 2.539541121966062

Epoch: 6| Step: 1
Training loss: 2.434694191374242
Validation loss: 2.5241998539195567

Epoch: 6| Step: 2
Training loss: 2.0221713902765095
Validation loss: 2.514689220556122

Epoch: 6| Step: 3
Training loss: 2.5897251752173043
Validation loss: 2.548611926707286

Epoch: 6| Step: 4
Training loss: 2.8186058735001236
Validation loss: 2.5689141977337555

Epoch: 6| Step: 5
Training loss: 1.8510919286816028
Validation loss: 2.6007898773570823

Epoch: 6| Step: 6
Training loss: 2.394945217772292
Validation loss: 2.642040957730509

Epoch: 6| Step: 7
Training loss: 2.508070602682622
Validation loss: 2.6817892554847185

Epoch: 6| Step: 8
Training loss: 2.3573075893357123
Validation loss: 2.6976111204147353

Epoch: 6| Step: 9
Training loss: 2.876562606090438
Validation loss: 2.6997814669601166

Epoch: 6| Step: 10
Training loss: 2.763518484866481
Validation loss: 2.728723285363465

Epoch: 6| Step: 11
Training loss: 2.398472490583525
Validation loss: 2.7200502467204357

Epoch: 6| Step: 12
Training loss: 2.7604799851167154
Validation loss: 2.709696424014017

Epoch: 6| Step: 13
Training loss: 2.399227447146195
Validation loss: 2.6993998786159636

Epoch: 279| Step: 0
Training loss: 2.817166674172538
Validation loss: 2.6430052313192967

Epoch: 6| Step: 1
Training loss: 1.7899390992401523
Validation loss: 2.650105370732757

Epoch: 6| Step: 2
Training loss: 2.4612056525532675
Validation loss: 2.6559150344652567

Epoch: 6| Step: 3
Training loss: 2.2421436903657783
Validation loss: 2.662074192123303

Epoch: 6| Step: 4
Training loss: 2.544935927568167
Validation loss: 2.662376051170667

Epoch: 6| Step: 5
Training loss: 2.7147269463969397
Validation loss: 2.6992867974101578

Epoch: 6| Step: 6
Training loss: 2.907737433332173
Validation loss: 2.739734499662293

Epoch: 6| Step: 7
Training loss: 2.5423480095158606
Validation loss: 2.683417135723764

Epoch: 6| Step: 8
Training loss: 1.968960705335501
Validation loss: 2.6563560247524407

Epoch: 6| Step: 9
Training loss: 2.5883245140395412
Validation loss: 2.598389959793009

Epoch: 6| Step: 10
Training loss: 2.911933182337541
Validation loss: 2.5658658370295995

Epoch: 6| Step: 11
Training loss: 2.539677472100046
Validation loss: 2.529949853453544

Epoch: 6| Step: 12
Training loss: 2.3325201956476707
Validation loss: 2.5089315920966104

Epoch: 6| Step: 13
Training loss: 1.999365944491572
Validation loss: 2.500436843114333

Epoch: 280| Step: 0
Training loss: 2.790301734167865
Validation loss: 2.4983081076344797

Epoch: 6| Step: 1
Training loss: 2.2753692494972366
Validation loss: 2.5200642624747878

Epoch: 6| Step: 2
Training loss: 2.765998599578216
Validation loss: 2.5500996484333602

Epoch: 6| Step: 3
Training loss: 2.7448815482453344
Validation loss: 2.584220481507162

Epoch: 6| Step: 4
Training loss: 2.8200117040621238
Validation loss: 2.5910076712788452

Epoch: 6| Step: 5
Training loss: 2.2897222303815514
Validation loss: 2.6106220576607626

Epoch: 6| Step: 6
Training loss: 2.91012986958471
Validation loss: 2.6082921312633234

Epoch: 6| Step: 7
Training loss: 2.250279197324604
Validation loss: 2.5984202234009075

Epoch: 6| Step: 8
Training loss: 1.864129726991484
Validation loss: 2.6127670471110087

Epoch: 6| Step: 9
Training loss: 2.156675877185396
Validation loss: 2.6446579161700896

Epoch: 6| Step: 10
Training loss: 2.308889095823254
Validation loss: 2.6450363711379117

Epoch: 6| Step: 11
Training loss: 2.5299349535997564
Validation loss: 2.621040203459039

Epoch: 6| Step: 12
Training loss: 2.5949066524584548
Validation loss: 2.648639764762751

Epoch: 6| Step: 13
Training loss: 2.245170071623238
Validation loss: 2.624434459528786

Epoch: 281| Step: 0
Training loss: 2.260503940098735
Validation loss: 2.61893604575212

Epoch: 6| Step: 1
Training loss: 2.4776377945813013
Validation loss: 2.643177869998028

Epoch: 6| Step: 2
Training loss: 2.229251562860858
Validation loss: 2.6530801204948387

Epoch: 6| Step: 3
Training loss: 2.5018140886731466
Validation loss: 2.6487843276139187

Epoch: 6| Step: 4
Training loss: 2.2261754820580753
Validation loss: 2.643346815866914

Epoch: 6| Step: 5
Training loss: 2.5925339755238705
Validation loss: 2.6210215275422697

Epoch: 6| Step: 6
Training loss: 2.8175246389779023
Validation loss: 2.615652017841852

Epoch: 6| Step: 7
Training loss: 2.467221136751685
Validation loss: 2.594068483700053

Epoch: 6| Step: 8
Training loss: 1.7902397713360327
Validation loss: 2.579817473985437

Epoch: 6| Step: 9
Training loss: 1.8109721617388992
Validation loss: 2.5758171752573005

Epoch: 6| Step: 10
Training loss: 3.237719000401598
Validation loss: 2.577986231276442

Epoch: 6| Step: 11
Training loss: 2.7145330237535035
Validation loss: 2.595011387970598

Epoch: 6| Step: 12
Training loss: 2.1793352614976054
Validation loss: 2.588470468569276

Epoch: 6| Step: 13
Training loss: 3.134552508088572
Validation loss: 2.609621343490987

Epoch: 282| Step: 0
Training loss: 2.252444952187351
Validation loss: 2.6074604273228066

Epoch: 6| Step: 1
Training loss: 2.69264987510715
Validation loss: 2.615997894824862

Epoch: 6| Step: 2
Training loss: 2.631630833264866
Validation loss: 2.609409639805152

Epoch: 6| Step: 3
Training loss: 2.166629521956303
Validation loss: 2.618590848112391

Epoch: 6| Step: 4
Training loss: 2.4483335315902486
Validation loss: 2.604549708262726

Epoch: 6| Step: 5
Training loss: 2.511441561056042
Validation loss: 2.581735039790559

Epoch: 6| Step: 6
Training loss: 1.8411085960439046
Validation loss: 2.558707309041766

Epoch: 6| Step: 7
Training loss: 2.09728227687967
Validation loss: 2.5607117176297405

Epoch: 6| Step: 8
Training loss: 2.6182247099349336
Validation loss: 2.591407094295682

Epoch: 6| Step: 9
Training loss: 2.6345264504408585
Validation loss: 2.609550995270866

Epoch: 6| Step: 10
Training loss: 2.734525316738856
Validation loss: 2.628311901141571

Epoch: 6| Step: 11
Training loss: 2.5131371558482885
Validation loss: 2.6740095795068433

Epoch: 6| Step: 12
Training loss: 2.569335009561311
Validation loss: 2.7363803355521847

Epoch: 6| Step: 13
Training loss: 3.0784408484744596
Validation loss: 2.6852136336347843

Epoch: 283| Step: 0
Training loss: 2.5268658004770663
Validation loss: 2.717341887118795

Epoch: 6| Step: 1
Training loss: 2.1501592222295356
Validation loss: 2.7359549776448793

Epoch: 6| Step: 2
Training loss: 2.9594353964744293
Validation loss: 2.740098832146429

Epoch: 6| Step: 3
Training loss: 2.3113007399919328
Validation loss: 2.6743567363296745

Epoch: 6| Step: 4
Training loss: 1.985070414603431
Validation loss: 2.617088979900213

Epoch: 6| Step: 5
Training loss: 2.9647752354361154
Validation loss: 2.5472762285472195

Epoch: 6| Step: 6
Training loss: 2.507234025352588
Validation loss: 2.5003663614972824

Epoch: 6| Step: 7
Training loss: 2.848511283617804
Validation loss: 2.466867412650861

Epoch: 6| Step: 8
Training loss: 1.9961395557022643
Validation loss: 2.449717964629146

Epoch: 6| Step: 9
Training loss: 2.3946161799592245
Validation loss: 2.4551843892716043

Epoch: 6| Step: 10
Training loss: 2.264200117668834
Validation loss: 2.4656624397188445

Epoch: 6| Step: 11
Training loss: 2.823808864538903
Validation loss: 2.5455211264761823

Epoch: 6| Step: 12
Training loss: 2.4700972345649808
Validation loss: 2.5814469152085673

Epoch: 6| Step: 13
Training loss: 3.285027935774422
Validation loss: 2.537506554667499

Epoch: 284| Step: 0
Training loss: 2.907531619765137
Validation loss: 2.4591457508134655

Epoch: 6| Step: 1
Training loss: 2.2763658259259656
Validation loss: 2.432833742102505

Epoch: 6| Step: 2
Training loss: 2.9071486529596786
Validation loss: 2.4189867467711132

Epoch: 6| Step: 3
Training loss: 3.0262962842613867
Validation loss: 2.4208199967597004

Epoch: 6| Step: 4
Training loss: 2.461296999876354
Validation loss: 2.4278990379895866

Epoch: 6| Step: 5
Training loss: 2.7833616833946677
Validation loss: 2.4505920877543934

Epoch: 6| Step: 6
Training loss: 2.566086747764386
Validation loss: 2.4991171262358867

Epoch: 6| Step: 7
Training loss: 1.8982492361400027
Validation loss: 2.5783907915208872

Epoch: 6| Step: 8
Training loss: 2.653880779333911
Validation loss: 2.6704754880056707

Epoch: 6| Step: 9
Training loss: 2.4517583259479268
Validation loss: 2.799695115036807

Epoch: 6| Step: 10
Training loss: 2.1354646506772226
Validation loss: 2.8633695910919377

Epoch: 6| Step: 11
Training loss: 2.269710146341815
Validation loss: 2.926590536253603

Epoch: 6| Step: 12
Training loss: 2.910827477383086
Validation loss: 2.8711387043108756

Epoch: 6| Step: 13
Training loss: 2.8235923737279878
Validation loss: 2.740117963259548

Epoch: 285| Step: 0
Training loss: 2.352129085378489
Validation loss: 2.613128116598734

Epoch: 6| Step: 1
Training loss: 1.7417440491540863
Validation loss: 2.5343732920622033

Epoch: 6| Step: 2
Training loss: 2.2210713452830375
Validation loss: 2.4858648520750695

Epoch: 6| Step: 3
Training loss: 3.1340150118664862
Validation loss: 2.465062709865071

Epoch: 6| Step: 4
Training loss: 2.8437486585676783
Validation loss: 2.455637451800439

Epoch: 6| Step: 5
Training loss: 2.402902231196773
Validation loss: 2.439897134178659

Epoch: 6| Step: 6
Training loss: 2.735942805277998
Validation loss: 2.444225873043943

Epoch: 6| Step: 7
Training loss: 2.621716671188097
Validation loss: 2.441625181820967

Epoch: 6| Step: 8
Training loss: 2.9909962008192905
Validation loss: 2.4555543212601076

Epoch: 6| Step: 9
Training loss: 2.262449156469137
Validation loss: 2.451809349194827

Epoch: 6| Step: 10
Training loss: 2.4807788084387785
Validation loss: 2.4686835734251034

Epoch: 6| Step: 11
Training loss: 2.45397788607855
Validation loss: 2.479409607582616

Epoch: 6| Step: 12
Training loss: 2.665645900702516
Validation loss: 2.5380011771972604

Epoch: 6| Step: 13
Training loss: 2.0618724446253394
Validation loss: 2.5614997438229437

Epoch: 286| Step: 0
Training loss: 2.0865909538711356
Validation loss: 2.591619407962314

Epoch: 6| Step: 1
Training loss: 2.360063465040929
Validation loss: 2.6298652775279967

Epoch: 6| Step: 2
Training loss: 2.565635065948775
Validation loss: 2.634116446449319

Epoch: 6| Step: 3
Training loss: 2.5448729714578944
Validation loss: 2.614711854569826

Epoch: 6| Step: 4
Training loss: 2.403402055065581
Validation loss: 2.5973089979882635

Epoch: 6| Step: 5
Training loss: 2.0910179190905476
Validation loss: 2.568661014045618

Epoch: 6| Step: 6
Training loss: 2.2315989501950657
Validation loss: 2.5618920564247936

Epoch: 6| Step: 7
Training loss: 2.614811880956358
Validation loss: 2.5699922933391517

Epoch: 6| Step: 8
Training loss: 2.6685308755078734
Validation loss: 2.579726847247694

Epoch: 6| Step: 9
Training loss: 2.8300664992320734
Validation loss: 2.5641516008294767

Epoch: 6| Step: 10
Training loss: 2.6151021820002076
Validation loss: 2.5475127705457195

Epoch: 6| Step: 11
Training loss: 2.981301367615065
Validation loss: 2.55637408535862

Epoch: 6| Step: 12
Training loss: 2.288340171401811
Validation loss: 2.5346799971593588

Epoch: 6| Step: 13
Training loss: 2.1527062749439043
Validation loss: 2.564834116942688

Epoch: 287| Step: 0
Training loss: 2.121080149120471
Validation loss: 2.570342890728118

Epoch: 6| Step: 1
Training loss: 2.6438145983584334
Validation loss: 2.590389164766608

Epoch: 6| Step: 2
Training loss: 2.2814983076013644
Validation loss: 2.624038252511291

Epoch: 6| Step: 3
Training loss: 2.059204705799242
Validation loss: 2.6235846919649504

Epoch: 6| Step: 4
Training loss: 2.5336475085478645
Validation loss: 2.6196189961608503

Epoch: 6| Step: 5
Training loss: 2.1800453685274284
Validation loss: 2.5965385722463346

Epoch: 6| Step: 6
Training loss: 2.505803048860332
Validation loss: 2.5591899964577167

Epoch: 6| Step: 7
Training loss: 2.333777203802305
Validation loss: 2.557940086838814

Epoch: 6| Step: 8
Training loss: 2.6840948667005953
Validation loss: 2.5448402557469842

Epoch: 6| Step: 9
Training loss: 2.3349762536746725
Validation loss: 2.530096650423043

Epoch: 6| Step: 10
Training loss: 2.408776876223431
Validation loss: 2.524953995217224

Epoch: 6| Step: 11
Training loss: 3.0918206257971197
Validation loss: 2.4948607082465695

Epoch: 6| Step: 12
Training loss: 2.605094642603955
Validation loss: 2.5078389355478787

Epoch: 6| Step: 13
Training loss: 2.6030013770599183
Validation loss: 2.530617500582802

Epoch: 288| Step: 0
Training loss: 2.225456311014963
Validation loss: 2.5730866931542082

Epoch: 6| Step: 1
Training loss: 2.1932088200707835
Validation loss: 2.5968727817162884

Epoch: 6| Step: 2
Training loss: 2.0247850092037165
Validation loss: 2.595441489822062

Epoch: 6| Step: 3
Training loss: 2.617709070871727
Validation loss: 2.617615955039134

Epoch: 6| Step: 4
Training loss: 1.8610215149690925
Validation loss: 2.599499124481137

Epoch: 6| Step: 5
Training loss: 2.3556420308360533
Validation loss: 2.594689811863628

Epoch: 6| Step: 6
Training loss: 2.716339182471463
Validation loss: 2.5924040574647123

Epoch: 6| Step: 7
Training loss: 2.5490829165034943
Validation loss: 2.571749652987829

Epoch: 6| Step: 8
Training loss: 2.4019310573495347
Validation loss: 2.5615815998739686

Epoch: 6| Step: 9
Training loss: 2.3859862157098934
Validation loss: 2.5578821343197236

Epoch: 6| Step: 10
Training loss: 2.4926322133649674
Validation loss: 2.5506390799236835

Epoch: 6| Step: 11
Training loss: 3.085160787834565
Validation loss: 2.5676169929681376

Epoch: 6| Step: 12
Training loss: 2.4046429308354482
Validation loss: 2.5914229989847244

Epoch: 6| Step: 13
Training loss: 2.900068538776636
Validation loss: 2.6302447137516776

Epoch: 289| Step: 0
Training loss: 2.6159114630645997
Validation loss: 2.6615771426518733

Epoch: 6| Step: 1
Training loss: 2.511131490870384
Validation loss: 2.684984949115241

Epoch: 6| Step: 2
Training loss: 2.079413566633009
Validation loss: 2.709648839555197

Epoch: 6| Step: 3
Training loss: 2.3126661911090896
Validation loss: 2.6797010046568017

Epoch: 6| Step: 4
Training loss: 2.9709151554120052
Validation loss: 2.6355548990840307

Epoch: 6| Step: 5
Training loss: 2.20581647811962
Validation loss: 2.6085478505894706

Epoch: 6| Step: 6
Training loss: 2.2781581044244676
Validation loss: 2.5710014344811016

Epoch: 6| Step: 7
Training loss: 2.340343899520684
Validation loss: 2.5505000118652346

Epoch: 6| Step: 8
Training loss: 2.386224723670059
Validation loss: 2.538210186014201

Epoch: 6| Step: 9
Training loss: 2.3532278051120943
Validation loss: 2.537431008426334

Epoch: 6| Step: 10
Training loss: 2.4356525951894548
Validation loss: 2.544053759355722

Epoch: 6| Step: 11
Training loss: 2.6033473035540924
Validation loss: 2.5521718270833023

Epoch: 6| Step: 12
Training loss: 2.005905849137553
Validation loss: 2.5741003896471537

Epoch: 6| Step: 13
Training loss: 2.8785158304107505
Validation loss: 2.577341707874709

Epoch: 290| Step: 0
Training loss: 2.815228304506429
Validation loss: 2.578962917895507

Epoch: 6| Step: 1
Training loss: 2.7116253334776386
Validation loss: 2.5447866974191773

Epoch: 6| Step: 2
Training loss: 2.9797195952936826
Validation loss: 2.5417038171622814

Epoch: 6| Step: 3
Training loss: 2.6694619508880004
Validation loss: 2.5231028400024433

Epoch: 6| Step: 4
Training loss: 2.832465955322592
Validation loss: 2.4980406486848437

Epoch: 6| Step: 5
Training loss: 2.5278466975652623
Validation loss: 2.5161247961998874

Epoch: 6| Step: 6
Training loss: 2.097574299893331
Validation loss: 2.5194223133475835

Epoch: 6| Step: 7
Training loss: 2.081285754747247
Validation loss: 2.5319753367464672

Epoch: 6| Step: 8
Training loss: 1.8767501292576103
Validation loss: 2.5911522240925016

Epoch: 6| Step: 9
Training loss: 2.6148171693917153
Validation loss: 2.645822341065411

Epoch: 6| Step: 10
Training loss: 1.6023393189189021
Validation loss: 2.6877362890743814

Epoch: 6| Step: 11
Training loss: 2.3473834547336168
Validation loss: 2.7070658116504203

Epoch: 6| Step: 12
Training loss: 2.511262700991984
Validation loss: 2.6669848300984365

Epoch: 6| Step: 13
Training loss: 1.8265878458605898
Validation loss: 2.611519170160357

Epoch: 291| Step: 0
Training loss: 1.9207652539858142
Validation loss: 2.5755635822071774

Epoch: 6| Step: 1
Training loss: 2.7340650110280094
Validation loss: 2.5503957392676595

Epoch: 6| Step: 2
Training loss: 2.304685224111694
Validation loss: 2.5282134428862095

Epoch: 6| Step: 3
Training loss: 2.7518735052412704
Validation loss: 2.5137298309839906

Epoch: 6| Step: 4
Training loss: 2.5455656840163927
Validation loss: 2.5249660968078147

Epoch: 6| Step: 5
Training loss: 3.0104008622508114
Validation loss: 2.5127693140088727

Epoch: 6| Step: 6
Training loss: 2.4996955686225104
Validation loss: 2.5428182843061022

Epoch: 6| Step: 7
Training loss: 1.946922769465618
Validation loss: 2.5710511911355063

Epoch: 6| Step: 8
Training loss: 2.4652354659149265
Validation loss: 2.5933786050455585

Epoch: 6| Step: 9
Training loss: 2.7316732083099344
Validation loss: 2.569781309389649

Epoch: 6| Step: 10
Training loss: 1.881183410175716
Validation loss: 2.6182748165931

Epoch: 6| Step: 11
Training loss: 2.517145301659308
Validation loss: 2.6158730166712054

Epoch: 6| Step: 12
Training loss: 2.242558677866766
Validation loss: 2.609789782877946

Epoch: 6| Step: 13
Training loss: 1.6530907928446694
Validation loss: 2.6046009451426553

Epoch: 292| Step: 0
Training loss: 2.520366961842059
Validation loss: 2.6077370176987262

Epoch: 6| Step: 1
Training loss: 1.8780125259006062
Validation loss: 2.620258232425158

Epoch: 6| Step: 2
Training loss: 2.1208520684854295
Validation loss: 2.604841782869582

Epoch: 6| Step: 3
Training loss: 2.469380165505999
Validation loss: 2.5767911272645185

Epoch: 6| Step: 4
Training loss: 2.7585788775021243
Validation loss: 2.5988455351364252

Epoch: 6| Step: 5
Training loss: 2.616146962578664
Validation loss: 2.58777390838885

Epoch: 6| Step: 6
Training loss: 1.9675521233911717
Validation loss: 2.577529992694665

Epoch: 6| Step: 7
Training loss: 2.0388105097900397
Validation loss: 2.580565536492202

Epoch: 6| Step: 8
Training loss: 2.361301671235712
Validation loss: 2.5572536094671916

Epoch: 6| Step: 9
Training loss: 2.051196247072997
Validation loss: 2.5448573858125627

Epoch: 6| Step: 10
Training loss: 2.560268267642069
Validation loss: 2.539903071926925

Epoch: 6| Step: 11
Training loss: 2.237503316013713
Validation loss: 2.5514544534410613

Epoch: 6| Step: 12
Training loss: 3.1252279579942184
Validation loss: 2.5649716182426556

Epoch: 6| Step: 13
Training loss: 3.023542377713046
Validation loss: 2.5775525175599245

Epoch: 293| Step: 0
Training loss: 2.908888408808826
Validation loss: 2.587465419838423

Epoch: 6| Step: 1
Training loss: 2.231941124655721
Validation loss: 2.58302093632171

Epoch: 6| Step: 2
Training loss: 2.3851229113370778
Validation loss: 2.6213188563152094

Epoch: 6| Step: 3
Training loss: 2.8816640163370466
Validation loss: 2.632861666912401

Epoch: 6| Step: 4
Training loss: 2.8059835600585488
Validation loss: 2.6202405068308185

Epoch: 6| Step: 5
Training loss: 2.0013631705047152
Validation loss: 2.6139491816096223

Epoch: 6| Step: 6
Training loss: 2.1289393991111845
Validation loss: 2.599541079301889

Epoch: 6| Step: 7
Training loss: 2.483601863688235
Validation loss: 2.6035537231366663

Epoch: 6| Step: 8
Training loss: 2.8146966621027034
Validation loss: 2.5980673286529736

Epoch: 6| Step: 9
Training loss: 2.3958688705683575
Validation loss: 2.647614095306756

Epoch: 6| Step: 10
Training loss: 2.234821408366879
Validation loss: 2.5958015442186606

Epoch: 6| Step: 11
Training loss: 2.220370600756957
Validation loss: 2.604059504775457

Epoch: 6| Step: 12
Training loss: 1.7251179032874593
Validation loss: 2.6011534757359036

Epoch: 6| Step: 13
Training loss: 1.7141852363590673
Validation loss: 2.600144447908166

Epoch: 294| Step: 0
Training loss: 2.795268615071119
Validation loss: 2.570756281649393

Epoch: 6| Step: 1
Training loss: 2.3357543873542084
Validation loss: 2.537686535093236

Epoch: 6| Step: 2
Training loss: 1.6334382094882893
Validation loss: 2.5358516037111314

Epoch: 6| Step: 3
Training loss: 2.9174967719863516
Validation loss: 2.534933860402878

Epoch: 6| Step: 4
Training loss: 2.143251242046915
Validation loss: 2.5305867948680647

Epoch: 6| Step: 5
Training loss: 2.302806642804182
Validation loss: 2.568451196345586

Epoch: 6| Step: 6
Training loss: 2.4445814313459064
Validation loss: 2.5669425243855764

Epoch: 6| Step: 7
Training loss: 2.069727401106865
Validation loss: 2.6027960522823426

Epoch: 6| Step: 8
Training loss: 2.784388453732578
Validation loss: 2.6421384348671113

Epoch: 6| Step: 9
Training loss: 1.659883651792436
Validation loss: 2.6587001495637916

Epoch: 6| Step: 10
Training loss: 3.137512030711418
Validation loss: 2.6934245436743116

Epoch: 6| Step: 11
Training loss: 1.6793069097800757
Validation loss: 2.6714349305259195

Epoch: 6| Step: 12
Training loss: 2.459775232420792
Validation loss: 2.632890932542142

Epoch: 6| Step: 13
Training loss: 2.8914391273292925
Validation loss: 2.594350077992295

Epoch: 295| Step: 0
Training loss: 2.538366040298565
Validation loss: 2.5640518362726104

Epoch: 6| Step: 1
Training loss: 2.456513221361952
Validation loss: 2.5548922659370845

Epoch: 6| Step: 2
Training loss: 2.2869173485649803
Validation loss: 2.5186824919716675

Epoch: 6| Step: 3
Training loss: 2.411019193954993
Validation loss: 2.5107288890640924

Epoch: 6| Step: 4
Training loss: 2.8259061254742126
Validation loss: 2.4951228611443343

Epoch: 6| Step: 5
Training loss: 2.278576682358462
Validation loss: 2.492065757945996

Epoch: 6| Step: 6
Training loss: 2.1705024828330926
Validation loss: 2.507213655073748

Epoch: 6| Step: 7
Training loss: 1.696237478751153
Validation loss: 2.5335853768901564

Epoch: 6| Step: 8
Training loss: 2.8975363098976503
Validation loss: 2.5509377341586728

Epoch: 6| Step: 9
Training loss: 1.9866844615310004
Validation loss: 2.5718026787144748

Epoch: 6| Step: 10
Training loss: 2.49201031954911
Validation loss: 2.583372469740221

Epoch: 6| Step: 11
Training loss: 2.2664545053409464
Validation loss: 2.5675220025440373

Epoch: 6| Step: 12
Training loss: 2.7775581802880844
Validation loss: 2.573872250811476

Epoch: 6| Step: 13
Training loss: 2.1452805507695283
Validation loss: 2.594032388361485

Epoch: 296| Step: 0
Training loss: 2.1558018094198275
Validation loss: 2.588747783668318

Epoch: 6| Step: 1
Training loss: 2.119604778877453
Validation loss: 2.5965290859616

Epoch: 6| Step: 2
Training loss: 2.078923351700609
Validation loss: 2.5900672993429015

Epoch: 6| Step: 3
Training loss: 2.0460057633319724
Validation loss: 2.6038669267656176

Epoch: 6| Step: 4
Training loss: 2.5124804823387783
Validation loss: 2.582342947051409

Epoch: 6| Step: 5
Training loss: 2.11291038093492
Validation loss: 2.627382058048907

Epoch: 6| Step: 6
Training loss: 2.4401922763046593
Validation loss: 2.6266473444189504

Epoch: 6| Step: 7
Training loss: 2.2191698993349425
Validation loss: 2.637180828530994

Epoch: 6| Step: 8
Training loss: 2.474493757164897
Validation loss: 2.6338019673543642

Epoch: 6| Step: 9
Training loss: 2.7853258249842985
Validation loss: 2.5899119529862236

Epoch: 6| Step: 10
Training loss: 2.5200459745542716
Validation loss: 2.6195858369932212

Epoch: 6| Step: 11
Training loss: 2.7070737012476807
Validation loss: 2.6174529693854227

Epoch: 6| Step: 12
Training loss: 2.7581326134094923
Validation loss: 2.579988750491427

Epoch: 6| Step: 13
Training loss: 2.105952672602289
Validation loss: 2.593680336238207

Epoch: 297| Step: 0
Training loss: 2.2551597137731165
Validation loss: 2.584129999264399

Epoch: 6| Step: 1
Training loss: 2.493623995166966
Validation loss: 2.5890119043827338

Epoch: 6| Step: 2
Training loss: 2.425030037605426
Validation loss: 2.5778667351666624

Epoch: 6| Step: 3
Training loss: 2.2007671752522957
Validation loss: 2.5600405149256527

Epoch: 6| Step: 4
Training loss: 2.1870343393875085
Validation loss: 2.528660653931393

Epoch: 6| Step: 5
Training loss: 2.5211719464166733
Validation loss: 2.523259270805805

Epoch: 6| Step: 6
Training loss: 2.341280029886371
Validation loss: 2.513551728367198

Epoch: 6| Step: 7
Training loss: 2.1469516124132144
Validation loss: 2.481174576892301

Epoch: 6| Step: 8
Training loss: 1.9242574919418112
Validation loss: 2.495465914902411

Epoch: 6| Step: 9
Training loss: 2.6267060684824703
Validation loss: 2.5131182115779476

Epoch: 6| Step: 10
Training loss: 2.7073958510553133
Validation loss: 2.548549528151812

Epoch: 6| Step: 11
Training loss: 2.970062126511726
Validation loss: 2.583630520586528

Epoch: 6| Step: 12
Training loss: 2.2667213681109186
Validation loss: 2.641578211503074

Epoch: 6| Step: 13
Training loss: 1.6133153879465438
Validation loss: 2.669206884755143

Epoch: 298| Step: 0
Training loss: 2.528900374628736
Validation loss: 2.680661557830334

Epoch: 6| Step: 1
Training loss: 2.1355917013741244
Validation loss: 2.6916100719093174

Epoch: 6| Step: 2
Training loss: 2.2587279473533393
Validation loss: 2.706600453304248

Epoch: 6| Step: 3
Training loss: 2.3811859082184847
Validation loss: 2.6686719621280024

Epoch: 6| Step: 4
Training loss: 2.326072146234094
Validation loss: 2.6402139059120135

Epoch: 6| Step: 5
Training loss: 2.218218027734626
Validation loss: 2.6084976278477687

Epoch: 6| Step: 6
Training loss: 2.6198909632001133
Validation loss: 2.5727002917789488

Epoch: 6| Step: 7
Training loss: 2.2282831336534334
Validation loss: 2.555688745179459

Epoch: 6| Step: 8
Training loss: 2.5739417151348585
Validation loss: 2.531290906005648

Epoch: 6| Step: 9
Training loss: 2.325143530732475
Validation loss: 2.5539195721106975

Epoch: 6| Step: 10
Training loss: 2.1360474810019956
Validation loss: 2.556644471499967

Epoch: 6| Step: 11
Training loss: 2.784402154004448
Validation loss: 2.546903752876128

Epoch: 6| Step: 12
Training loss: 1.8561527316621431
Validation loss: 2.530907371116827

Epoch: 6| Step: 13
Training loss: 2.2966854510302714
Validation loss: 2.550246772310719

Epoch: 299| Step: 0
Training loss: 2.1325654386294035
Validation loss: 2.5427784141635867

Epoch: 6| Step: 1
Training loss: 1.9136538322300523
Validation loss: 2.5432601713085967

Epoch: 6| Step: 2
Training loss: 2.241218277663634
Validation loss: 2.525009329644683

Epoch: 6| Step: 3
Training loss: 2.1989435867352403
Validation loss: 2.5323323870577936

Epoch: 6| Step: 4
Training loss: 2.5011452912504577
Validation loss: 2.557536393395629

Epoch: 6| Step: 5
Training loss: 2.4332233961519143
Validation loss: 2.572034835070212

Epoch: 6| Step: 6
Training loss: 2.3316228818929314
Validation loss: 2.5586774954968936

Epoch: 6| Step: 7
Training loss: 2.3704208600717984
Validation loss: 2.5583200926613596

Epoch: 6| Step: 8
Training loss: 2.1249033962057635
Validation loss: 2.576298707895242

Epoch: 6| Step: 9
Training loss: 2.6130818061388226
Validation loss: 2.5758399609307867

Epoch: 6| Step: 10
Training loss: 2.499198594389165
Validation loss: 2.582754239591147

Epoch: 6| Step: 11
Training loss: 2.952822553698473
Validation loss: 2.611537775617456

Epoch: 6| Step: 12
Training loss: 1.9788547537782815
Validation loss: 2.605674766378715

Epoch: 6| Step: 13
Training loss: 2.3166211496542526
Validation loss: 2.6361326219287835

Epoch: 300| Step: 0
Training loss: 2.7214447347120236
Validation loss: 2.6134183810194718

Epoch: 6| Step: 1
Training loss: 2.536162895109418
Validation loss: 2.5855527722414493

Epoch: 6| Step: 2
Training loss: 2.099418028163119
Validation loss: 2.5840904530244675

Epoch: 6| Step: 3
Training loss: 2.2655970078416234
Validation loss: 2.540140533662967

Epoch: 6| Step: 4
Training loss: 2.7902566186070885
Validation loss: 2.5454392081785318

Epoch: 6| Step: 5
Training loss: 1.7659667367967076
Validation loss: 2.501868828226001

Epoch: 6| Step: 6
Training loss: 2.3963159379160133
Validation loss: 2.5300047452412695

Epoch: 6| Step: 7
Training loss: 1.860529308888903
Validation loss: 2.530233046976867

Epoch: 6| Step: 8
Training loss: 2.893337482355662
Validation loss: 2.5390215520972452

Epoch: 6| Step: 9
Training loss: 2.001441793502149
Validation loss: 2.5992588105678474

Epoch: 6| Step: 10
Training loss: 2.5418926722200883
Validation loss: 2.666153016791554

Epoch: 6| Step: 11
Training loss: 2.4409523992214375
Validation loss: 2.6695427436706867

Epoch: 6| Step: 12
Training loss: 2.111978238470498
Validation loss: 2.660271719228822

Epoch: 6| Step: 13
Training loss: 2.2532629089899894
Validation loss: 2.6427298390578042

Epoch: 301| Step: 0
Training loss: 2.46206619779217
Validation loss: 2.605256071224602

Epoch: 6| Step: 1
Training loss: 2.093871839024365
Validation loss: 2.6332393083755616

Epoch: 6| Step: 2
Training loss: 2.153473434713067
Validation loss: 2.6178891975832093

Epoch: 6| Step: 3
Training loss: 2.148335180447033
Validation loss: 2.590781911340866

Epoch: 6| Step: 4
Training loss: 2.232961140644288
Validation loss: 2.5509140406472612

Epoch: 6| Step: 5
Training loss: 2.5581890222892025
Validation loss: 2.518233152602428

Epoch: 6| Step: 6
Training loss: 2.1305643046947
Validation loss: 2.5498824067722228

Epoch: 6| Step: 7
Training loss: 2.605702814343425
Validation loss: 2.5492943262840773

Epoch: 6| Step: 8
Training loss: 2.174267336336454
Validation loss: 2.6030372726867195

Epoch: 6| Step: 9
Training loss: 3.025649097254471
Validation loss: 2.597289767471045

Epoch: 6| Step: 10
Training loss: 2.2888385545984042
Validation loss: 2.602498107586681

Epoch: 6| Step: 11
Training loss: 2.489271796192088
Validation loss: 2.5852417884428895

Epoch: 6| Step: 12
Training loss: 2.2060907841364013
Validation loss: 2.5593989406830593

Epoch: 6| Step: 13
Training loss: 1.6524148118630737
Validation loss: 2.552677237287552

Epoch: 302| Step: 0
Training loss: 2.3722651948493456
Validation loss: 2.557005171473663

Epoch: 6| Step: 1
Training loss: 2.709325217523334
Validation loss: 2.5218748476581125

Epoch: 6| Step: 2
Training loss: 1.8577824031101997
Validation loss: 2.522400282482367

Epoch: 6| Step: 3
Training loss: 2.468318466907613
Validation loss: 2.516621388195995

Epoch: 6| Step: 4
Training loss: 2.042447258818134
Validation loss: 2.5191502731965056

Epoch: 6| Step: 5
Training loss: 2.5155179966506678
Validation loss: 2.5277341476558153

Epoch: 6| Step: 6
Training loss: 1.8395007030322925
Validation loss: 2.5555510704437507

Epoch: 6| Step: 7
Training loss: 2.504710908757774
Validation loss: 2.5621966290719316

Epoch: 6| Step: 8
Training loss: 2.60149917296353
Validation loss: 2.571221940873577

Epoch: 6| Step: 9
Training loss: 3.0669597927924435
Validation loss: 2.5738581953689055

Epoch: 6| Step: 10
Training loss: 2.167231143877748
Validation loss: 2.560059930116888

Epoch: 6| Step: 11
Training loss: 1.651390720698299
Validation loss: 2.5534981294020382

Epoch: 6| Step: 12
Training loss: 2.13275012249958
Validation loss: 2.581988883571099

Epoch: 6| Step: 13
Training loss: 2.1394623432166298
Validation loss: 2.602533956961859

Epoch: 303| Step: 0
Training loss: 2.41911424363441
Validation loss: 2.6036626145042825

Epoch: 6| Step: 1
Training loss: 1.9089090531088095
Validation loss: 2.588870071123157

Epoch: 6| Step: 2
Training loss: 2.114416131485806
Validation loss: 2.591866252098691

Epoch: 6| Step: 3
Training loss: 2.217697538675388
Validation loss: 2.5940855224109876

Epoch: 6| Step: 4
Training loss: 2.0266791928473076
Validation loss: 2.6490874658572428

Epoch: 6| Step: 5
Training loss: 2.544451256520325
Validation loss: 2.6612854628457963

Epoch: 6| Step: 6
Training loss: 2.6808907612760473
Validation loss: 2.645207729764816

Epoch: 6| Step: 7
Training loss: 2.3603020671915433
Validation loss: 2.653977645804362

Epoch: 6| Step: 8
Training loss: 2.451141527451578
Validation loss: 2.639183123091737

Epoch: 6| Step: 9
Training loss: 1.7499190720510556
Validation loss: 2.6153140953733045

Epoch: 6| Step: 10
Training loss: 2.824359726717856
Validation loss: 2.573508227302413

Epoch: 6| Step: 11
Training loss: 2.7896973985214566
Validation loss: 2.529981291411271

Epoch: 6| Step: 12
Training loss: 1.8903061148582478
Validation loss: 2.5029480113719473

Epoch: 6| Step: 13
Training loss: 1.823957077307698
Validation loss: 2.478187009342339

Epoch: 304| Step: 0
Training loss: 2.745180414937984
Validation loss: 2.4595076306190955

Epoch: 6| Step: 1
Training loss: 2.0342122705773797
Validation loss: 2.4969660510109493

Epoch: 6| Step: 2
Training loss: 2.2152404968037214
Validation loss: 2.5117407361961983

Epoch: 6| Step: 3
Training loss: 2.1808862158729125
Validation loss: 2.550222342559917

Epoch: 6| Step: 4
Training loss: 2.008263207104285
Validation loss: 2.5913733752802104

Epoch: 6| Step: 5
Training loss: 2.9860375052752026
Validation loss: 2.6095407998332076

Epoch: 6| Step: 6
Training loss: 1.9093930956892995
Validation loss: 2.6314308200050753

Epoch: 6| Step: 7
Training loss: 2.9806781660230843
Validation loss: 2.6208010753525337

Epoch: 6| Step: 8
Training loss: 2.1986275076346793
Validation loss: 2.6081302791678946

Epoch: 6| Step: 9
Training loss: 2.1269351898922433
Validation loss: 2.599765226612165

Epoch: 6| Step: 10
Training loss: 2.3842652941822546
Validation loss: 2.5692444111980817

Epoch: 6| Step: 11
Training loss: 2.2703202627512673
Validation loss: 2.532038503180597

Epoch: 6| Step: 12
Training loss: 1.65772311358854
Validation loss: 2.521808755560666

Epoch: 6| Step: 13
Training loss: 2.159084944283309
Validation loss: 2.5013055489353446

Epoch: 305| Step: 0
Training loss: 2.2888884494476556
Validation loss: 2.505225115113896

Epoch: 6| Step: 1
Training loss: 2.235003296339775
Validation loss: 2.505486469043771

Epoch: 6| Step: 2
Training loss: 2.53675714151827
Validation loss: 2.533716937891258

Epoch: 6| Step: 3
Training loss: 2.712129446288073
Validation loss: 2.55624719154205

Epoch: 6| Step: 4
Training loss: 2.6875751396143324
Validation loss: 2.535617013597219

Epoch: 6| Step: 5
Training loss: 1.903448892226422
Validation loss: 2.551968349723552

Epoch: 6| Step: 6
Training loss: 1.9003950160133622
Validation loss: 2.5576977808427297

Epoch: 6| Step: 7
Training loss: 2.315040636138523
Validation loss: 2.577336644928026

Epoch: 6| Step: 8
Training loss: 2.2854934313205484
Validation loss: 2.6091496836556245

Epoch: 6| Step: 9
Training loss: 1.7795230457928362
Validation loss: 2.6356923409337267

Epoch: 6| Step: 10
Training loss: 2.364691497972773
Validation loss: 2.624960947405469

Epoch: 6| Step: 11
Training loss: 2.2186446903650348
Validation loss: 2.626091050131943

Epoch: 6| Step: 12
Training loss: 2.426548736592185
Validation loss: 2.629338119026153

Epoch: 6| Step: 13
Training loss: 1.9449637226752028
Validation loss: 2.64145161699373

Epoch: 306| Step: 0
Training loss: 2.340975632525648
Validation loss: 2.637331233622124

Epoch: 6| Step: 1
Training loss: 1.5952984636457066
Validation loss: 2.588651793951553

Epoch: 6| Step: 2
Training loss: 2.506672537708847
Validation loss: 2.5800583089793006

Epoch: 6| Step: 3
Training loss: 2.2061962607433565
Validation loss: 2.5310203582779467

Epoch: 6| Step: 4
Training loss: 2.448175771000295
Validation loss: 2.5382671625692406

Epoch: 6| Step: 5
Training loss: 2.1237806299795
Validation loss: 2.492169772852184

Epoch: 6| Step: 6
Training loss: 2.171175507896607
Validation loss: 2.5117536026400207

Epoch: 6| Step: 7
Training loss: 2.3555825175935534
Validation loss: 2.5106767412391466

Epoch: 6| Step: 8
Training loss: 2.108036096701752
Validation loss: 2.5363986824943656

Epoch: 6| Step: 9
Training loss: 1.9833450648284072
Validation loss: 2.5294700419794975

Epoch: 6| Step: 10
Training loss: 2.232928254508576
Validation loss: 2.542785202395413

Epoch: 6| Step: 11
Training loss: 2.633433011337371
Validation loss: 2.584740982303063

Epoch: 6| Step: 12
Training loss: 2.6057401455705045
Validation loss: 2.623795580218661

Epoch: 6| Step: 13
Training loss: 2.523714693983537
Validation loss: 2.660192136691264

Epoch: 307| Step: 0
Training loss: 2.4490063345512936
Validation loss: 2.6291148772419874

Epoch: 6| Step: 1
Training loss: 2.5373395972456048
Validation loss: 2.618916320139851

Epoch: 6| Step: 2
Training loss: 2.0856209846986067
Validation loss: 2.5790999919711397

Epoch: 6| Step: 3
Training loss: 2.5613235936685457
Validation loss: 2.552967734137381

Epoch: 6| Step: 4
Training loss: 2.7692391439254176
Validation loss: 2.516450995391245

Epoch: 6| Step: 5
Training loss: 1.9915556859442005
Validation loss: 2.5261871942113916

Epoch: 6| Step: 6
Training loss: 2.2824230574709734
Validation loss: 2.492734135403528

Epoch: 6| Step: 7
Training loss: 2.45842854805734
Validation loss: 2.5217999773076096

Epoch: 6| Step: 8
Training loss: 2.1666920244738193
Validation loss: 2.5211744163315326

Epoch: 6| Step: 9
Training loss: 2.5639378305238805
Validation loss: 2.569467419033184

Epoch: 6| Step: 10
Training loss: 1.741141377256098
Validation loss: 2.5925895129909997

Epoch: 6| Step: 11
Training loss: 1.5983976029146107
Validation loss: 2.6216371279065087

Epoch: 6| Step: 12
Training loss: 2.255167219978039
Validation loss: 2.668955440461576

Epoch: 6| Step: 13
Training loss: 2.2258285651327876
Validation loss: 2.6330724898009685

Epoch: 308| Step: 0
Training loss: 2.178791477248469
Validation loss: 2.598306014273149

Epoch: 6| Step: 1
Training loss: 1.968524738322011
Validation loss: 2.560742860020262

Epoch: 6| Step: 2
Training loss: 1.6139471790221587
Validation loss: 2.5568969841699745

Epoch: 6| Step: 3
Training loss: 2.7311846622709033
Validation loss: 2.5425319123468295

Epoch: 6| Step: 4
Training loss: 2.227032314057532
Validation loss: 2.5063281262127113

Epoch: 6| Step: 5
Training loss: 1.8126987479849057
Validation loss: 2.5081864420242956

Epoch: 6| Step: 6
Training loss: 1.90913167049192
Validation loss: 2.521263493327468

Epoch: 6| Step: 7
Training loss: 2.4536818340081306
Validation loss: 2.547548450761687

Epoch: 6| Step: 8
Training loss: 2.2029858267904383
Validation loss: 2.558068672539084

Epoch: 6| Step: 9
Training loss: 2.498504954579166
Validation loss: 2.566479569855243

Epoch: 6| Step: 10
Training loss: 2.303772618663443
Validation loss: 2.5787485615915644

Epoch: 6| Step: 11
Training loss: 2.5711062055185803
Validation loss: 2.5582050793845266

Epoch: 6| Step: 12
Training loss: 2.860007627783787
Validation loss: 2.566723496130618

Epoch: 6| Step: 13
Training loss: 2.2342209129288344
Validation loss: 2.5403998970471067

Epoch: 309| Step: 0
Training loss: 2.4150997760451167
Validation loss: 2.554068819697924

Epoch: 6| Step: 1
Training loss: 1.889830367130426
Validation loss: 2.5485626805408264

Epoch: 6| Step: 2
Training loss: 2.289898091676499
Validation loss: 2.542658641689383

Epoch: 6| Step: 3
Training loss: 2.059860158451415
Validation loss: 2.521700456110645

Epoch: 6| Step: 4
Training loss: 2.223809826171036
Validation loss: 2.5146541017396276

Epoch: 6| Step: 5
Training loss: 2.081734412470164
Validation loss: 2.522841169967457

Epoch: 6| Step: 6
Training loss: 1.7346624875004883
Validation loss: 2.5383804058867563

Epoch: 6| Step: 7
Training loss: 2.583011596907672
Validation loss: 2.530475617005503

Epoch: 6| Step: 8
Training loss: 2.477176626216949
Validation loss: 2.5162292510928155

Epoch: 6| Step: 9
Training loss: 2.3500805617788054
Validation loss: 2.5115154198537692

Epoch: 6| Step: 10
Training loss: 2.3722371544865544
Validation loss: 2.502776415194537

Epoch: 6| Step: 11
Training loss: 2.5935455609377978
Validation loss: 2.531840970575735

Epoch: 6| Step: 12
Training loss: 2.1821623940671353
Validation loss: 2.5449745178381367

Epoch: 6| Step: 13
Training loss: 2.1177113015272435
Validation loss: 2.57358440695096

Epoch: 310| Step: 0
Training loss: 2.7230714675653047
Validation loss: 2.626030474052604

Epoch: 6| Step: 1
Training loss: 2.091736579830997
Validation loss: 2.6918707484465365

Epoch: 6| Step: 2
Training loss: 2.773848124449316
Validation loss: 2.7253058493796276

Epoch: 6| Step: 3
Training loss: 2.4292986886826924
Validation loss: 2.7233557052839084

Epoch: 6| Step: 4
Training loss: 2.3480087244173915
Validation loss: 2.6193883823548125

Epoch: 6| Step: 5
Training loss: 2.0345411194747323
Validation loss: 2.553726393318121

Epoch: 6| Step: 6
Training loss: 2.4453930338800194
Validation loss: 2.491542414171852

Epoch: 6| Step: 7
Training loss: 1.334787241666074
Validation loss: 2.457167160245612

Epoch: 6| Step: 8
Training loss: 2.3345790217251587
Validation loss: 2.4349898493836677

Epoch: 6| Step: 9
Training loss: 1.9647987315061992
Validation loss: 2.451233876291555

Epoch: 6| Step: 10
Training loss: 2.317016315374773
Validation loss: 2.4332084002375804

Epoch: 6| Step: 11
Training loss: 1.912768677931037
Validation loss: 2.430872632589613

Epoch: 6| Step: 12
Training loss: 2.6073589645968718
Validation loss: 2.4447694964658284

Epoch: 6| Step: 13
Training loss: 2.4664749092451337
Validation loss: 2.4209600294164972

Epoch: 311| Step: 0
Training loss: 2.689533883449582
Validation loss: 2.453730526027228

Epoch: 6| Step: 1
Training loss: 1.8534906705215566
Validation loss: 2.4649681854391488

Epoch: 6| Step: 2
Training loss: 2.5217005181251784
Validation loss: 2.484130183797273

Epoch: 6| Step: 3
Training loss: 2.25287243489645
Validation loss: 2.5083308414665844

Epoch: 6| Step: 4
Training loss: 1.899805086578393
Validation loss: 2.5281543546594616

Epoch: 6| Step: 5
Training loss: 2.0535495638423793
Validation loss: 2.543401833583215

Epoch: 6| Step: 6
Training loss: 2.499956702811106
Validation loss: 2.5528249165838757

Epoch: 6| Step: 7
Training loss: 1.8059232370024914
Validation loss: 2.568402631016319

Epoch: 6| Step: 8
Training loss: 2.5957786256302384
Validation loss: 2.547900160346123

Epoch: 6| Step: 9
Training loss: 2.464021234160741
Validation loss: 2.553668855157914

Epoch: 6| Step: 10
Training loss: 2.0208101041841737
Validation loss: 2.5200056342507784

Epoch: 6| Step: 11
Training loss: 2.221087232131331
Validation loss: 2.520168936572217

Epoch: 6| Step: 12
Training loss: 1.8215660395958437
Validation loss: 2.4847237544761778

Epoch: 6| Step: 13
Training loss: 2.91787364145955
Validation loss: 2.5151922798605755

Epoch: 312| Step: 0
Training loss: 1.7904622961025034
Validation loss: 2.5022287411889192

Epoch: 6| Step: 1
Training loss: 2.377369351332226
Validation loss: 2.534614087754391

Epoch: 6| Step: 2
Training loss: 2.6410900361076113
Validation loss: 2.558801143895022

Epoch: 6| Step: 3
Training loss: 1.954134138713661
Validation loss: 2.6293756694598778

Epoch: 6| Step: 4
Training loss: 2.13954681196928
Validation loss: 2.633219062926625

Epoch: 6| Step: 5
Training loss: 2.2886056281348193
Validation loss: 2.6469456717484867

Epoch: 6| Step: 6
Training loss: 2.397123989814959
Validation loss: 2.6352364182050376

Epoch: 6| Step: 7
Training loss: 2.0412821764491946
Validation loss: 2.625209592937642

Epoch: 6| Step: 8
Training loss: 2.450582462283092
Validation loss: 2.595607575224492

Epoch: 6| Step: 9
Training loss: 1.7752735195839366
Validation loss: 2.5677066742985004

Epoch: 6| Step: 10
Training loss: 2.687960296956396
Validation loss: 2.552139379720102

Epoch: 6| Step: 11
Training loss: 2.168673234180099
Validation loss: 2.4992487650339537

Epoch: 6| Step: 12
Training loss: 2.1555251962723925
Validation loss: 2.487496178250431

Epoch: 6| Step: 13
Training loss: 2.411391672705688
Validation loss: 2.4753157013142584

Epoch: 313| Step: 0
Training loss: 1.7950311239407906
Validation loss: 2.453160068524394

Epoch: 6| Step: 1
Training loss: 2.29245805658307
Validation loss: 2.4609587366841894

Epoch: 6| Step: 2
Training loss: 1.7712002392807467
Validation loss: 2.4451932668685195

Epoch: 6| Step: 3
Training loss: 2.4149735099018854
Validation loss: 2.4315042473874944

Epoch: 6| Step: 4
Training loss: 2.3680414352915813
Validation loss: 2.465018244690409

Epoch: 6| Step: 5
Training loss: 2.234465377153559
Validation loss: 2.5059854668520893

Epoch: 6| Step: 6
Training loss: 2.24116125778953
Validation loss: 2.5231318302493864

Epoch: 6| Step: 7
Training loss: 1.9895054134535881
Validation loss: 2.6172595520337647

Epoch: 6| Step: 8
Training loss: 2.6703331497313587
Validation loss: 2.6254115995438174

Epoch: 6| Step: 9
Training loss: 2.6182066797631816
Validation loss: 2.6942744646695167

Epoch: 6| Step: 10
Training loss: 2.7333065888406765
Validation loss: 2.724821152904442

Epoch: 6| Step: 11
Training loss: 2.308501317583005
Validation loss: 2.6623154109363285

Epoch: 6| Step: 12
Training loss: 2.0823251828092726
Validation loss: 2.5757781234445

Epoch: 6| Step: 13
Training loss: 2.0346580671742815
Validation loss: 2.505965794350562

Epoch: 314| Step: 0
Training loss: 2.453521016222335
Validation loss: 2.474752396940527

Epoch: 6| Step: 1
Training loss: 2.223139115428968
Validation loss: 2.4417784536507674

Epoch: 6| Step: 2
Training loss: 1.8818779996596557
Validation loss: 2.4514364065412146

Epoch: 6| Step: 3
Training loss: 2.5735147581564823
Validation loss: 2.447905995265624

Epoch: 6| Step: 4
Training loss: 2.2298335091061214
Validation loss: 2.466266020548012

Epoch: 6| Step: 5
Training loss: 2.6238895065490326
Validation loss: 2.478595891987561

Epoch: 6| Step: 6
Training loss: 2.2039064144335945
Validation loss: 2.532969887211969

Epoch: 6| Step: 7
Training loss: 2.4967727812085516
Validation loss: 2.5957564455849904

Epoch: 6| Step: 8
Training loss: 1.7535859561037594
Validation loss: 2.59523616950983

Epoch: 6| Step: 9
Training loss: 2.1130581947830485
Validation loss: 2.591135472803442

Epoch: 6| Step: 10
Training loss: 1.9491757558235876
Validation loss: 2.6115772174131013

Epoch: 6| Step: 11
Training loss: 2.312214189342644
Validation loss: 2.5849069618160314

Epoch: 6| Step: 12
Training loss: 2.197463966742535
Validation loss: 2.575408208110651

Epoch: 6| Step: 13
Training loss: 2.1484565872731665
Validation loss: 2.5588554989270627

Epoch: 315| Step: 0
Training loss: 1.8845482261075912
Validation loss: 2.5414196175414725

Epoch: 6| Step: 1
Training loss: 2.246136739568216
Validation loss: 2.543505904060962

Epoch: 6| Step: 2
Training loss: 2.496208176355608
Validation loss: 2.521794842498287

Epoch: 6| Step: 3
Training loss: 2.483596199852814
Validation loss: 2.510403140138881

Epoch: 6| Step: 4
Training loss: 1.921147340552181
Validation loss: 2.5138946770256725

Epoch: 6| Step: 5
Training loss: 1.8179754226752274
Validation loss: 2.520562899741733

Epoch: 6| Step: 6
Training loss: 1.7243292679344544
Validation loss: 2.522188899323774

Epoch: 6| Step: 7
Training loss: 2.457681785061344
Validation loss: 2.5555978496286205

Epoch: 6| Step: 8
Training loss: 2.0515993067046487
Validation loss: 2.562443093048902

Epoch: 6| Step: 9
Training loss: 2.2653531667811446
Validation loss: 2.5944453450334937

Epoch: 6| Step: 10
Training loss: 2.6252932611774704
Validation loss: 2.6100078982155637

Epoch: 6| Step: 11
Training loss: 2.3484383040558128
Validation loss: 2.6039281611998732

Epoch: 6| Step: 12
Training loss: 2.142095353184874
Validation loss: 2.585118502283641

Epoch: 6| Step: 13
Training loss: 2.096041094857586
Validation loss: 2.5436256991277233

Epoch: 316| Step: 0
Training loss: 2.310950301252894
Validation loss: 2.5684336477147713

Epoch: 6| Step: 1
Training loss: 2.313511292248026
Validation loss: 2.5862274111505883

Epoch: 6| Step: 2
Training loss: 1.809345789329328
Validation loss: 2.6049867401138282

Epoch: 6| Step: 3
Training loss: 2.0858749780321717
Validation loss: 2.586331754715482

Epoch: 6| Step: 4
Training loss: 2.2115382803722294
Validation loss: 2.5384548988028848

Epoch: 6| Step: 5
Training loss: 2.432589744802052
Validation loss: 2.5283041152933077

Epoch: 6| Step: 6
Training loss: 1.8267896943301358
Validation loss: 2.4757530851585883

Epoch: 6| Step: 7
Training loss: 2.1754073364470785
Validation loss: 2.4680305679851324

Epoch: 6| Step: 8
Training loss: 1.8127678640335283
Validation loss: 2.487727303646529

Epoch: 6| Step: 9
Training loss: 2.435475804959969
Validation loss: 2.490001128708324

Epoch: 6| Step: 10
Training loss: 2.206309728921595
Validation loss: 2.4990838207640196

Epoch: 6| Step: 11
Training loss: 2.7172256230141705
Validation loss: 2.5118321665371988

Epoch: 6| Step: 12
Training loss: 2.406064113025921
Validation loss: 2.5237968440663696

Epoch: 6| Step: 13
Training loss: 2.055934049223929
Validation loss: 2.5936515691577826

Epoch: 317| Step: 0
Training loss: 2.3077363101725505
Validation loss: 2.6098319936765306

Epoch: 6| Step: 1
Training loss: 2.771724203968752
Validation loss: 2.659511037677991

Epoch: 6| Step: 2
Training loss: 2.120200177944447
Validation loss: 2.678324227985095

Epoch: 6| Step: 3
Training loss: 2.4208862255137733
Validation loss: 2.7323345337577165

Epoch: 6| Step: 4
Training loss: 2.3441060113727175
Validation loss: 2.6880320933018482

Epoch: 6| Step: 5
Training loss: 2.4828792843920215
Validation loss: 2.641462604480718

Epoch: 6| Step: 6
Training loss: 1.7830183386766185
Validation loss: 2.598650177420307

Epoch: 6| Step: 7
Training loss: 2.2152958161334833
Validation loss: 2.548507716683784

Epoch: 6| Step: 8
Training loss: 1.5707626077260441
Validation loss: 2.489341347878595

Epoch: 6| Step: 9
Training loss: 2.6368454288145533
Validation loss: 2.4602905287644616

Epoch: 6| Step: 10
Training loss: 1.7093675630676173
Validation loss: 2.4282886445706424

Epoch: 6| Step: 11
Training loss: 1.9166169851194357
Validation loss: 2.4289055784669

Epoch: 6| Step: 12
Training loss: 2.102048002411781
Validation loss: 2.4434552515572974

Epoch: 6| Step: 13
Training loss: 2.0541680553294888
Validation loss: 2.4441758463027825

Epoch: 318| Step: 0
Training loss: 2.1650355385909528
Validation loss: 2.497357733889043

Epoch: 6| Step: 1
Training loss: 1.7923625511345278
Validation loss: 2.5166856403269886

Epoch: 6| Step: 2
Training loss: 2.606634471170898
Validation loss: 2.5264561615735714

Epoch: 6| Step: 3
Training loss: 1.886275024045834
Validation loss: 2.5376175477423857

Epoch: 6| Step: 4
Training loss: 2.7195052928392625
Validation loss: 2.548717427508804

Epoch: 6| Step: 5
Training loss: 2.466646964621689
Validation loss: 2.5542700962991884

Epoch: 6| Step: 6
Training loss: 2.2256009351184014
Validation loss: 2.579575141177133

Epoch: 6| Step: 7
Training loss: 2.2947672820271143
Validation loss: 2.629857235265238

Epoch: 6| Step: 8
Training loss: 2.6324987932077453
Validation loss: 2.6555548195538923

Epoch: 6| Step: 9
Training loss: 1.6973720293306296
Validation loss: 2.619505524362423

Epoch: 6| Step: 10
Training loss: 1.7910055079117198
Validation loss: 2.596760893665176

Epoch: 6| Step: 11
Training loss: 1.6974194350527725
Validation loss: 2.5612597786977407

Epoch: 6| Step: 12
Training loss: 2.088418349686697
Validation loss: 2.5617721528383135

Epoch: 6| Step: 13
Training loss: 2.7928980678337636
Validation loss: 2.514837981759586

Epoch: 319| Step: 0
Training loss: 1.5922296789869772
Validation loss: 2.492780672117683

Epoch: 6| Step: 1
Training loss: 2.2626202883278563
Validation loss: 2.5193512649014993

Epoch: 6| Step: 2
Training loss: 2.4014356928389358
Validation loss: 2.4935611171074044

Epoch: 6| Step: 3
Training loss: 1.5863536420290199
Validation loss: 2.5066714193570805

Epoch: 6| Step: 4
Training loss: 2.1775642362770364
Validation loss: 2.5004662376360156

Epoch: 6| Step: 5
Training loss: 2.0417696349459944
Validation loss: 2.478103734185753

Epoch: 6| Step: 6
Training loss: 2.767072137358979
Validation loss: 2.4855090283953074

Epoch: 6| Step: 7
Training loss: 2.2378336140926103
Validation loss: 2.4878228934243705

Epoch: 6| Step: 8
Training loss: 2.063355124096079
Validation loss: 2.500652600295613

Epoch: 6| Step: 9
Training loss: 2.566386740971797
Validation loss: 2.504760066256862

Epoch: 6| Step: 10
Training loss: 1.861249860016745
Validation loss: 2.5476490140332926

Epoch: 6| Step: 11
Training loss: 1.9920624936844995
Validation loss: 2.5413826478303783

Epoch: 6| Step: 12
Training loss: 2.1082569691495223
Validation loss: 2.5719016138187825

Epoch: 6| Step: 13
Training loss: 2.1388513498466235
Validation loss: 2.5987099386140478

Epoch: 320| Step: 0
Training loss: 2.0896291462169745
Validation loss: 2.6110051651851944

Epoch: 6| Step: 1
Training loss: 2.1336817943575266
Validation loss: 2.6786609736650315

Epoch: 6| Step: 2
Training loss: 2.5701047123457585
Validation loss: 2.669233259071151

Epoch: 6| Step: 3
Training loss: 1.4446511069831334
Validation loss: 2.680161643374933

Epoch: 6| Step: 4
Training loss: 1.5833926524377404
Validation loss: 2.6671884805546666

Epoch: 6| Step: 5
Training loss: 2.404168752298051
Validation loss: 2.6413673056055758

Epoch: 6| Step: 6
Training loss: 1.7254184712880558
Validation loss: 2.555482083828364

Epoch: 6| Step: 7
Training loss: 2.008505616244535
Validation loss: 2.5081068051597857

Epoch: 6| Step: 8
Training loss: 2.1095022657644
Validation loss: 2.4812503336839593

Epoch: 6| Step: 9
Training loss: 2.772835077756829
Validation loss: 2.4274142977669664

Epoch: 6| Step: 10
Training loss: 2.197330511194719
Validation loss: 2.4542192973642663

Epoch: 6| Step: 11
Training loss: 2.3259031202980505
Validation loss: 2.486268067112053

Epoch: 6| Step: 12
Training loss: 2.271932726602833
Validation loss: 2.5053936114610256

Epoch: 6| Step: 13
Training loss: 2.541348036091408
Validation loss: 2.553882606675037

Epoch: 321| Step: 0
Training loss: 1.9278004179891448
Validation loss: 2.561908330473159

Epoch: 6| Step: 1
Training loss: 2.3021741708178296
Validation loss: 2.5841772095116364

Epoch: 6| Step: 2
Training loss: 1.7369120831286864
Validation loss: 2.6115263804901483

Epoch: 6| Step: 3
Training loss: 1.842850740607495
Validation loss: 2.6195838826414355

Epoch: 6| Step: 4
Training loss: 2.7869780629160052
Validation loss: 2.6393356714297074

Epoch: 6| Step: 5
Training loss: 1.8005994593282955
Validation loss: 2.6043492807328303

Epoch: 6| Step: 6
Training loss: 2.5446532686637187
Validation loss: 2.5532892474949094

Epoch: 6| Step: 7
Training loss: 2.003082641534577
Validation loss: 2.547056408955481

Epoch: 6| Step: 8
Training loss: 2.5218606752274777
Validation loss: 2.54279679265697

Epoch: 6| Step: 9
Training loss: 1.9903025367452702
Validation loss: 2.5384895297909793

Epoch: 6| Step: 10
Training loss: 1.5660937370902392
Validation loss: 2.551638816174124

Epoch: 6| Step: 11
Training loss: 2.113604452129067
Validation loss: 2.553245316736265

Epoch: 6| Step: 12
Training loss: 2.0495913586734376
Validation loss: 2.535344496680882

Epoch: 6| Step: 13
Training loss: 2.573273781975158
Validation loss: 2.5494207144454313

Epoch: 322| Step: 0
Training loss: 2.3067313748950684
Validation loss: 2.538403018596037

Epoch: 6| Step: 1
Training loss: 2.051739568688226
Validation loss: 2.5178427082774286

Epoch: 6| Step: 2
Training loss: 1.6299341558251486
Validation loss: 2.5226621171501864

Epoch: 6| Step: 3
Training loss: 2.460138100260039
Validation loss: 2.5041812048709744

Epoch: 6| Step: 4
Training loss: 2.0377872615585666
Validation loss: 2.4906247470352403

Epoch: 6| Step: 5
Training loss: 2.3862522000142303
Validation loss: 2.5037173925502505

Epoch: 6| Step: 6
Training loss: 2.4868891248663787
Validation loss: 2.505997823722989

Epoch: 6| Step: 7
Training loss: 2.4800565602405498
Validation loss: 2.495358822771882

Epoch: 6| Step: 8
Training loss: 1.812683227748681
Validation loss: 2.4740538088515787

Epoch: 6| Step: 9
Training loss: 1.5897719158468246
Validation loss: 2.496533133230395

Epoch: 6| Step: 10
Training loss: 1.4999668594514062
Validation loss: 2.543211607777623

Epoch: 6| Step: 11
Training loss: 2.030687929295519
Validation loss: 2.551649019923209

Epoch: 6| Step: 12
Training loss: 2.340018187884211
Validation loss: 2.566396778200528

Epoch: 6| Step: 13
Training loss: 2.8081328500637532
Validation loss: 2.573616314988463

Epoch: 323| Step: 0
Training loss: 1.9707719017707768
Validation loss: 2.563441996554751

Epoch: 6| Step: 1
Training loss: 2.429647267489951
Validation loss: 2.5397685054009598

Epoch: 6| Step: 2
Training loss: 1.6298626257924556
Validation loss: 2.549610433754533

Epoch: 6| Step: 3
Training loss: 2.2251175324333072
Validation loss: 2.5131118542850137

Epoch: 6| Step: 4
Training loss: 1.9985489349673138
Validation loss: 2.508370678632216

Epoch: 6| Step: 5
Training loss: 1.567294356562581
Validation loss: 2.508786135880472

Epoch: 6| Step: 6
Training loss: 1.9294649065260936
Validation loss: 2.503477545069362

Epoch: 6| Step: 7
Training loss: 2.644656743237349
Validation loss: 2.5253267522100185

Epoch: 6| Step: 8
Training loss: 2.203227480405466
Validation loss: 2.5508015296437803

Epoch: 6| Step: 9
Training loss: 2.422416577236342
Validation loss: 2.541836461757346

Epoch: 6| Step: 10
Training loss: 2.8071281843172886
Validation loss: 2.509986980232711

Epoch: 6| Step: 11
Training loss: 1.4415652799879286
Validation loss: 2.5352258928496285

Epoch: 6| Step: 12
Training loss: 2.2198541607078632
Validation loss: 2.5340030596362606

Epoch: 6| Step: 13
Training loss: 1.5176785900977805
Validation loss: 2.555569810509512

Epoch: 324| Step: 0
Training loss: 2.652415481069342
Validation loss: 2.5814867472377863

Epoch: 6| Step: 1
Training loss: 2.0595002757102594
Validation loss: 2.5851477798327465

Epoch: 6| Step: 2
Training loss: 2.161263649380563
Validation loss: 2.5956774825719635

Epoch: 6| Step: 3
Training loss: 2.6780967328105474
Validation loss: 2.583550348471777

Epoch: 6| Step: 4
Training loss: 2.420958905620886
Validation loss: 2.5815930917427314

Epoch: 6| Step: 5
Training loss: 1.517194426940128
Validation loss: 2.555514035311925

Epoch: 6| Step: 6
Training loss: 2.059550632981489
Validation loss: 2.5379602384340156

Epoch: 6| Step: 7
Training loss: 2.491327597811151
Validation loss: 2.534163681511778

Epoch: 6| Step: 8
Training loss: 1.7609677627792768
Validation loss: 2.5246238478676073

Epoch: 6| Step: 9
Training loss: 1.6824710935288911
Validation loss: 2.5562602220885444

Epoch: 6| Step: 10
Training loss: 1.560766479165664
Validation loss: 2.554861191708608

Epoch: 6| Step: 11
Training loss: 1.9209245021585737
Validation loss: 2.5621991955162327

Epoch: 6| Step: 12
Training loss: 2.348700622721708
Validation loss: 2.606941691488307

Epoch: 6| Step: 13
Training loss: 1.2805853259381261
Validation loss: 2.6194571657011476

Epoch: 325| Step: 0
Training loss: 2.078832978996973
Validation loss: 2.603519182661494

Epoch: 6| Step: 1
Training loss: 2.276418088837274
Validation loss: 2.613991865628715

Epoch: 6| Step: 2
Training loss: 1.9905434799869064
Validation loss: 2.5898027249906637

Epoch: 6| Step: 3
Training loss: 2.402715489848661
Validation loss: 2.598238155950798

Epoch: 6| Step: 4
Training loss: 2.280412703188349
Validation loss: 2.561359827160652

Epoch: 6| Step: 5
Training loss: 2.378857541642663
Validation loss: 2.5077071353190767

Epoch: 6| Step: 6
Training loss: 2.5685027920093475
Validation loss: 2.5083657708191565

Epoch: 6| Step: 7
Training loss: 1.7765730643650275
Validation loss: 2.4862630888598916

Epoch: 6| Step: 8
Training loss: 1.7138083423391428
Validation loss: 2.5245373245846747

Epoch: 6| Step: 9
Training loss: 2.5801568549920186
Validation loss: 2.552654558200217

Epoch: 6| Step: 10
Training loss: 1.9673024259875833
Validation loss: 2.5911226483129823

Epoch: 6| Step: 11
Training loss: 1.6424989443097722
Validation loss: 2.569323717618175

Epoch: 6| Step: 12
Training loss: 1.9983190983108043
Validation loss: 2.5836336700269578

Epoch: 6| Step: 13
Training loss: 1.1652460418025032
Validation loss: 2.5905111100132534

Epoch: 326| Step: 0
Training loss: 1.4274353465656082
Validation loss: 2.5736738205768366

Epoch: 6| Step: 1
Training loss: 2.2058197207067467
Validation loss: 2.5908214296556897

Epoch: 6| Step: 2
Training loss: 2.470365937033217
Validation loss: 2.598569107247461

Epoch: 6| Step: 3
Training loss: 2.115789085347194
Validation loss: 2.5522867877987196

Epoch: 6| Step: 4
Training loss: 1.679618443688561
Validation loss: 2.5226165747734597

Epoch: 6| Step: 5
Training loss: 2.597055098879304
Validation loss: 2.495134317304634

Epoch: 6| Step: 6
Training loss: 2.1580247071684022
Validation loss: 2.491465895054215

Epoch: 6| Step: 7
Training loss: 2.3071991246754844
Validation loss: 2.5182860723770593

Epoch: 6| Step: 8
Training loss: 2.1085305112929293
Validation loss: 2.543031236094355

Epoch: 6| Step: 9
Training loss: 2.1414010527644085
Validation loss: 2.5345669819714116

Epoch: 6| Step: 10
Training loss: 1.677209916481199
Validation loss: 2.564874496826159

Epoch: 6| Step: 11
Training loss: 2.59073454437755
Validation loss: 2.561829689127387

Epoch: 6| Step: 12
Training loss: 1.949379587513576
Validation loss: 2.5907512596670452

Epoch: 6| Step: 13
Training loss: 1.8837876070213726
Validation loss: 2.570466297130309

Epoch: 327| Step: 0
Training loss: 1.9060023412700096
Validation loss: 2.5720916533987483

Epoch: 6| Step: 1
Training loss: 1.2604772169633383
Validation loss: 2.5567719612489004

Epoch: 6| Step: 2
Training loss: 1.8709174533048454
Validation loss: 2.5790523408756103

Epoch: 6| Step: 3
Training loss: 2.343738708468894
Validation loss: 2.555929086402919

Epoch: 6| Step: 4
Training loss: 2.5211965336045443
Validation loss: 2.575382749842285

Epoch: 6| Step: 5
Training loss: 2.5930454262352467
Validation loss: 2.571329134634649

Epoch: 6| Step: 6
Training loss: 1.8454818350725546
Validation loss: 2.5788678344239617

Epoch: 6| Step: 7
Training loss: 2.2808649443597444
Validation loss: 2.5694949892218926

Epoch: 6| Step: 8
Training loss: 1.981090982114626
Validation loss: 2.594396299890855

Epoch: 6| Step: 9
Training loss: 2.084271740965066
Validation loss: 2.579679746361437

Epoch: 6| Step: 10
Training loss: 1.8280614858174096
Validation loss: 2.6191077172061976

Epoch: 6| Step: 11
Training loss: 2.21572519352914
Validation loss: 2.6196690252625268

Epoch: 6| Step: 12
Training loss: 1.9414943007337142
Validation loss: 2.636396722365445

Epoch: 6| Step: 13
Training loss: 2.125438420565098
Validation loss: 2.601477888197737

Epoch: 328| Step: 0
Training loss: 1.7374633236314243
Validation loss: 2.5767000936158895

Epoch: 6| Step: 1
Training loss: 1.9515458093300542
Validation loss: 2.555102565955817

Epoch: 6| Step: 2
Training loss: 2.4034575074806073
Validation loss: 2.5377871739782067

Epoch: 6| Step: 3
Training loss: 2.42618123809526
Validation loss: 2.5047625718018924

Epoch: 6| Step: 4
Training loss: 2.472726444254446
Validation loss: 2.4874659162389623

Epoch: 6| Step: 5
Training loss: 1.937762273449122
Validation loss: 2.4657162683987477

Epoch: 6| Step: 6
Training loss: 1.7150589584136637
Validation loss: 2.462877196219335

Epoch: 6| Step: 7
Training loss: 1.9900639604229047
Validation loss: 2.4921333614937704

Epoch: 6| Step: 8
Training loss: 2.4525793161116822
Validation loss: 2.546086999044069

Epoch: 6| Step: 9
Training loss: 1.8786665353109415
Validation loss: 2.576455343714827

Epoch: 6| Step: 10
Training loss: 2.1085040519662757
Validation loss: 2.621314824032588

Epoch: 6| Step: 11
Training loss: 1.9467516252298553
Validation loss: 2.6655775523203302

Epoch: 6| Step: 12
Training loss: 1.629915871350624
Validation loss: 2.6857463440859815

Epoch: 6| Step: 13
Training loss: 2.1083138516497266
Validation loss: 2.6857812015926896

Epoch: 329| Step: 0
Training loss: 2.3737030503550036
Validation loss: 2.654636614516411

Epoch: 6| Step: 1
Training loss: 1.56622572165363
Validation loss: 2.6038984922743533

Epoch: 6| Step: 2
Training loss: 1.983933046641728
Validation loss: 2.5624384378701217

Epoch: 6| Step: 3
Training loss: 1.2756402558569053
Validation loss: 2.55991812713509

Epoch: 6| Step: 4
Training loss: 1.8974714293609505
Validation loss: 2.5283789142098847

Epoch: 6| Step: 5
Training loss: 2.0585535613738997
Validation loss: 2.5619299880161277

Epoch: 6| Step: 6
Training loss: 2.3225616959342323
Validation loss: 2.5446044697748262

Epoch: 6| Step: 7
Training loss: 2.5391740510351384
Validation loss: 2.5456343985675254

Epoch: 6| Step: 8
Training loss: 2.001913704832928
Validation loss: 2.549797058313992

Epoch: 6| Step: 9
Training loss: 1.906910953689155
Validation loss: 2.5837620922852067

Epoch: 6| Step: 10
Training loss: 1.5717557281685859
Validation loss: 2.5268395102144954

Epoch: 6| Step: 11
Training loss: 2.2994509414778093
Validation loss: 2.5468624649932186

Epoch: 6| Step: 12
Training loss: 2.6006104156224543
Validation loss: 2.5736848224956006

Epoch: 6| Step: 13
Training loss: 1.889067015788421
Validation loss: 2.5501889787138694

Epoch: 330| Step: 0
Training loss: 2.2329190719296363
Validation loss: 2.5402999227789143

Epoch: 6| Step: 1
Training loss: 2.343998806780619
Validation loss: 2.539872015174466

Epoch: 6| Step: 2
Training loss: 2.1698966037710483
Validation loss: 2.5208365076693067

Epoch: 6| Step: 3
Training loss: 1.78191430269621
Validation loss: 2.53379805948703

Epoch: 6| Step: 4
Training loss: 1.5875755081842253
Validation loss: 2.515457508501265

Epoch: 6| Step: 5
Training loss: 2.0091752351978713
Validation loss: 2.5326247382023825

Epoch: 6| Step: 6
Training loss: 2.0436185602040795
Validation loss: 2.5313731975951175

Epoch: 6| Step: 7
Training loss: 1.7403752091230997
Validation loss: 2.5383214321243552

Epoch: 6| Step: 8
Training loss: 2.4987751821419772
Validation loss: 2.5612562949600215

Epoch: 6| Step: 9
Training loss: 1.9814605937911847
Validation loss: 2.558286482687386

Epoch: 6| Step: 10
Training loss: 2.1292165547577455
Validation loss: 2.5836682977423324

Epoch: 6| Step: 11
Training loss: 1.7747295227288058
Validation loss: 2.561616948020795

Epoch: 6| Step: 12
Training loss: 2.045515234846411
Validation loss: 2.545536198962426

Epoch: 6| Step: 13
Training loss: 2.308288037605095
Validation loss: 2.557064637700245

Epoch: 331| Step: 0
Training loss: 1.5037395434440142
Validation loss: 2.549914046376485

Epoch: 6| Step: 1
Training loss: 2.6050789010954385
Validation loss: 2.536039052744794

Epoch: 6| Step: 2
Training loss: 2.347071011379608
Validation loss: 2.5163257611104464

Epoch: 6| Step: 3
Training loss: 1.7566994088660564
Validation loss: 2.54393965402216

Epoch: 6| Step: 4
Training loss: 1.8410719479452688
Validation loss: 2.5329170950766464

Epoch: 6| Step: 5
Training loss: 1.9597895328248824
Validation loss: 2.544933884662002

Epoch: 6| Step: 6
Training loss: 2.2509090918236883
Validation loss: 2.5128978585455726

Epoch: 6| Step: 7
Training loss: 1.8347813638682517
Validation loss: 2.5516484552819967

Epoch: 6| Step: 8
Training loss: 2.3376895113737652
Validation loss: 2.5550535482362764

Epoch: 6| Step: 9
Training loss: 2.1330727219343806
Validation loss: 2.5363582495236097

Epoch: 6| Step: 10
Training loss: 2.041605448940384
Validation loss: 2.5180263422124587

Epoch: 6| Step: 11
Training loss: 2.008480688152768
Validation loss: 2.490111187745759

Epoch: 6| Step: 12
Training loss: 1.8947658118325477
Validation loss: 2.531118900251879

Epoch: 6| Step: 13
Training loss: 1.4094382278232778
Validation loss: 2.5412090830343153

Epoch: 332| Step: 0
Training loss: 1.8991309889080863
Validation loss: 2.5604552888393273

Epoch: 6| Step: 1
Training loss: 2.2080615854105656
Validation loss: 2.6203912180103672

Epoch: 6| Step: 2
Training loss: 2.1627686967563
Validation loss: 2.5950875913526485

Epoch: 6| Step: 3
Training loss: 2.2216620878423776
Validation loss: 2.6545165571215916

Epoch: 6| Step: 4
Training loss: 1.6157526847513668
Validation loss: 2.6298715923929596

Epoch: 6| Step: 5
Training loss: 1.8565740565768771
Validation loss: 2.6103187815766735

Epoch: 6| Step: 6
Training loss: 1.7747054755631697
Validation loss: 2.5928182281153345

Epoch: 6| Step: 7
Training loss: 2.1578756644957213
Validation loss: 2.540696032566074

Epoch: 6| Step: 8
Training loss: 2.3841339949451816
Validation loss: 2.5028490608696963

Epoch: 6| Step: 9
Training loss: 2.1465004806677963
Validation loss: 2.478869972527053

Epoch: 6| Step: 10
Training loss: 2.370061156212175
Validation loss: 2.4891460585768868

Epoch: 6| Step: 11
Training loss: 1.8294984923484494
Validation loss: 2.498614616467358

Epoch: 6| Step: 12
Training loss: 1.7055594867049373
Validation loss: 2.478798558106315

Epoch: 6| Step: 13
Training loss: 1.84176088785428
Validation loss: 2.481428887840749

Epoch: 333| Step: 0
Training loss: 1.9303552499254941
Validation loss: 2.5028714978185675

Epoch: 6| Step: 1
Training loss: 2.056065550534735
Validation loss: 2.526914757283739

Epoch: 6| Step: 2
Training loss: 1.9525859851928502
Validation loss: 2.5422685785619783

Epoch: 6| Step: 3
Training loss: 1.9160207268105496
Validation loss: 2.5339562804070876

Epoch: 6| Step: 4
Training loss: 2.688596989504499
Validation loss: 2.5368756030221693

Epoch: 6| Step: 5
Training loss: 1.7786394363965958
Validation loss: 2.5407526617724443

Epoch: 6| Step: 6
Training loss: 1.8159223014367512
Validation loss: 2.5441096941014107

Epoch: 6| Step: 7
Training loss: 2.1393244892903214
Validation loss: 2.526520471554794

Epoch: 6| Step: 8
Training loss: 1.4614700733818071
Validation loss: 2.522631989396016

Epoch: 6| Step: 9
Training loss: 2.3401319934428098
Validation loss: 2.5328916844207785

Epoch: 6| Step: 10
Training loss: 2.304035676494522
Validation loss: 2.579573246453235

Epoch: 6| Step: 11
Training loss: 1.7292240393745486
Validation loss: 2.5971606499548727

Epoch: 6| Step: 12
Training loss: 2.0517873276226677
Validation loss: 2.5835974661143544

Epoch: 6| Step: 13
Training loss: 1.3140623693658897
Validation loss: 2.6396900513780195

Epoch: 334| Step: 0
Training loss: 1.6494061846457446
Validation loss: 2.639728269371048

Epoch: 6| Step: 1
Training loss: 1.9140363418971509
Validation loss: 2.625994534442186

Epoch: 6| Step: 2
Training loss: 1.7640881221454618
Validation loss: 2.5621268968459057

Epoch: 6| Step: 3
Training loss: 2.415513081197154
Validation loss: 2.534877200316384

Epoch: 6| Step: 4
Training loss: 1.9054058269451275
Validation loss: 2.503208353595766

Epoch: 6| Step: 5
Training loss: 1.8875667332858517
Validation loss: 2.4578086421014653

Epoch: 6| Step: 6
Training loss: 1.564188312115868
Validation loss: 2.4902747137255687

Epoch: 6| Step: 7
Training loss: 1.8932873604570326
Validation loss: 2.5057050388092

Epoch: 6| Step: 8
Training loss: 1.951826778015294
Validation loss: 2.5232765936086183

Epoch: 6| Step: 9
Training loss: 1.6844381883195254
Validation loss: 2.5430400065863377

Epoch: 6| Step: 10
Training loss: 2.135560218513965
Validation loss: 2.5298623256893933

Epoch: 6| Step: 11
Training loss: 2.786694630143375
Validation loss: 2.5782701319082513

Epoch: 6| Step: 12
Training loss: 2.1130859510395483
Validation loss: 2.5490547966698607

Epoch: 6| Step: 13
Training loss: 2.1874319883400446
Validation loss: 2.539256406688925

Epoch: 335| Step: 0
Training loss: 2.1607976309635153
Validation loss: 2.5459182867942474

Epoch: 6| Step: 1
Training loss: 1.980149824658347
Validation loss: 2.6212104118654396

Epoch: 6| Step: 2
Training loss: 2.0728095201056522
Validation loss: 2.6625325076699053

Epoch: 6| Step: 3
Training loss: 2.115626361344997
Validation loss: 2.719598858510313

Epoch: 6| Step: 4
Training loss: 1.99751282058822
Validation loss: 2.6534980662662586

Epoch: 6| Step: 5
Training loss: 2.1786024886514634
Validation loss: 2.5802060813790813

Epoch: 6| Step: 6
Training loss: 1.9314804087846822
Validation loss: 2.5083704108592397

Epoch: 6| Step: 7
Training loss: 2.133727383976993
Validation loss: 2.42673141911801

Epoch: 6| Step: 8
Training loss: 1.763284262543464
Validation loss: 2.383027202173248

Epoch: 6| Step: 9
Training loss: 2.093746469978659
Validation loss: 2.388970559876684

Epoch: 6| Step: 10
Training loss: 2.2399486036875635
Validation loss: 2.4062460089742195

Epoch: 6| Step: 11
Training loss: 1.9539779631622465
Validation loss: 2.468956566015757

Epoch: 6| Step: 12
Training loss: 2.0872937768733277
Validation loss: 2.533596260968315

Epoch: 6| Step: 13
Training loss: 2.4539681704632454
Validation loss: 2.593803832188245

Epoch: 336| Step: 0
Training loss: 1.8344224238073643
Validation loss: 2.557753521200205

Epoch: 6| Step: 1
Training loss: 1.770219681571629
Validation loss: 2.5259059134159525

Epoch: 6| Step: 2
Training loss: 2.416862172955157
Validation loss: 2.507865802202399

Epoch: 6| Step: 3
Training loss: 1.764580544293514
Validation loss: 2.4700508579317253

Epoch: 6| Step: 4
Training loss: 1.7509496700606706
Validation loss: 2.471623882602188

Epoch: 6| Step: 5
Training loss: 2.2926798805875785
Validation loss: 2.482040057187554

Epoch: 6| Step: 6
Training loss: 1.8434264335552357
Validation loss: 2.5544327837873775

Epoch: 6| Step: 7
Training loss: 2.6517647067619095
Validation loss: 2.5592658981040706

Epoch: 6| Step: 8
Training loss: 2.1976501399666217
Validation loss: 2.544954595202068

Epoch: 6| Step: 9
Training loss: 1.8333693703086238
Validation loss: 2.5520145627153186

Epoch: 6| Step: 10
Training loss: 2.0102844458338778
Validation loss: 2.545211457066471

Epoch: 6| Step: 11
Training loss: 1.8678264721684015
Validation loss: 2.5489281429446313

Epoch: 6| Step: 12
Training loss: 2.130531068959855
Validation loss: 2.526280309891443

Epoch: 6| Step: 13
Training loss: 2.0980958389196602
Validation loss: 2.5270701070670922

Epoch: 337| Step: 0
Training loss: 1.5957984475621285
Validation loss: 2.4935911786927485

Epoch: 6| Step: 1
Training loss: 2.1841959387389474
Validation loss: 2.4766632294574755

Epoch: 6| Step: 2
Training loss: 1.6658434583245876
Validation loss: 2.4814880514375086

Epoch: 6| Step: 3
Training loss: 1.7468193987082612
Validation loss: 2.476594399830044

Epoch: 6| Step: 4
Training loss: 1.8474609400810404
Validation loss: 2.4682527142255357

Epoch: 6| Step: 5
Training loss: 2.1074726710238854
Validation loss: 2.476096620323941

Epoch: 6| Step: 6
Training loss: 2.310754168539591
Validation loss: 2.4765817352849124

Epoch: 6| Step: 7
Training loss: 2.113243680891506
Validation loss: 2.4605203837906355

Epoch: 6| Step: 8
Training loss: 2.3515925104501156
Validation loss: 2.436137996575163

Epoch: 6| Step: 9
Training loss: 2.412666979135221
Validation loss: 2.497991957277263

Epoch: 6| Step: 10
Training loss: 1.4270425312678536
Validation loss: 2.5968544334962615

Epoch: 6| Step: 11
Training loss: 2.142953427740121
Validation loss: 2.6370405195721918

Epoch: 6| Step: 12
Training loss: 2.1669107690878655
Validation loss: 2.7490263704126074

Epoch: 6| Step: 13
Training loss: 1.82595690109598
Validation loss: 2.747761487439633

Epoch: 338| Step: 0
Training loss: 2.4419983656969153
Validation loss: 2.7299753146637085

Epoch: 6| Step: 1
Training loss: 1.8855018245229944
Validation loss: 2.680731761333121

Epoch: 6| Step: 2
Training loss: 1.834468107443788
Validation loss: 2.58584306558926

Epoch: 6| Step: 3
Training loss: 1.9825303522506823
Validation loss: 2.5448254944529913

Epoch: 6| Step: 4
Training loss: 1.8510919286816028
Validation loss: 2.467575501035753

Epoch: 6| Step: 5
Training loss: 1.6627240596451804
Validation loss: 2.4139012336859778

Epoch: 6| Step: 6
Training loss: 1.9119021933730125
Validation loss: 2.3919063841441233

Epoch: 6| Step: 7
Training loss: 1.8167616629771437
Validation loss: 2.3835773253917485

Epoch: 6| Step: 8
Training loss: 2.071838392391702
Validation loss: 2.408900558614726

Epoch: 6| Step: 9
Training loss: 2.312978128028829
Validation loss: 2.4623091670024917

Epoch: 6| Step: 10
Training loss: 2.2232253380225515
Validation loss: 2.4777078166665314

Epoch: 6| Step: 11
Training loss: 1.9409086944550435
Validation loss: 2.5075623809828715

Epoch: 6| Step: 12
Training loss: 2.176956489433072
Validation loss: 2.5409984402813497

Epoch: 6| Step: 13
Training loss: 1.4931852989108703
Validation loss: 2.5433843363909587

Epoch: 339| Step: 0
Training loss: 1.8976154823996796
Validation loss: 2.589131272270159

Epoch: 6| Step: 1
Training loss: 2.1044508361294145
Validation loss: 2.5857189990662888

Epoch: 6| Step: 2
Training loss: 1.96213868575139
Validation loss: 2.599152946218041

Epoch: 6| Step: 3
Training loss: 1.7980765264644836
Validation loss: 2.5558862552069144

Epoch: 6| Step: 4
Training loss: 1.4734166456346625
Validation loss: 2.4974629182723436

Epoch: 6| Step: 5
Training loss: 2.0649897257847156
Validation loss: 2.4812243184749816

Epoch: 6| Step: 6
Training loss: 1.8689291265366619
Validation loss: 2.479863259645588

Epoch: 6| Step: 7
Training loss: 1.7985671327271924
Validation loss: 2.4681900591918797

Epoch: 6| Step: 8
Training loss: 2.1247470929608094
Validation loss: 2.4779578391890955

Epoch: 6| Step: 9
Training loss: 1.9588670476767005
Validation loss: 2.4773791600843853

Epoch: 6| Step: 10
Training loss: 1.730450563356746
Validation loss: 2.4687620396058945

Epoch: 6| Step: 11
Training loss: 2.708149468465244
Validation loss: 2.4907302744234237

Epoch: 6| Step: 12
Training loss: 2.0790350506035686
Validation loss: 2.5252856516279625

Epoch: 6| Step: 13
Training loss: 1.6376128383517121
Validation loss: 2.563143439536904

Epoch: 340| Step: 0
Training loss: 2.1247285781751764
Validation loss: 2.6079531106440466

Epoch: 6| Step: 1
Training loss: 1.9104142278103113
Validation loss: 2.6175681951391936

Epoch: 6| Step: 2
Training loss: 1.9744577170370572
Validation loss: 2.589371420197908

Epoch: 6| Step: 3
Training loss: 2.0804597746268327
Validation loss: 2.5409941756120418

Epoch: 6| Step: 4
Training loss: 1.8836514831580873
Validation loss: 2.5634018906335068

Epoch: 6| Step: 5
Training loss: 2.359735019323076
Validation loss: 2.53495483518555

Epoch: 6| Step: 6
Training loss: 1.872125329297211
Validation loss: 2.516635296243127

Epoch: 6| Step: 7
Training loss: 1.939401247496635
Validation loss: 2.5140037512268663

Epoch: 6| Step: 8
Training loss: 1.6312647150187145
Validation loss: 2.5211946016174864

Epoch: 6| Step: 9
Training loss: 2.0333538017910353
Validation loss: 2.5226004639125463

Epoch: 6| Step: 10
Training loss: 1.6753204352346216
Validation loss: 2.5219309617315915

Epoch: 6| Step: 11
Training loss: 1.8068336837304206
Validation loss: 2.5268634284497833

Epoch: 6| Step: 12
Training loss: 1.6642611389520872
Validation loss: 2.565432911248261

Epoch: 6| Step: 13
Training loss: 2.460424945073382
Validation loss: 2.5054772365963567

Epoch: 341| Step: 0
Training loss: 2.2792638205883
Validation loss: 2.552500178984193

Epoch: 6| Step: 1
Training loss: 1.8317407568865889
Validation loss: 2.559043373718644

Epoch: 6| Step: 2
Training loss: 1.5622548483219205
Validation loss: 2.522797077877731

Epoch: 6| Step: 3
Training loss: 2.1056681522647764
Validation loss: 2.525060006793908

Epoch: 6| Step: 4
Training loss: 2.0259158006288893
Validation loss: 2.538507490939476

Epoch: 6| Step: 5
Training loss: 1.6186298075354237
Validation loss: 2.530995088617178

Epoch: 6| Step: 6
Training loss: 1.340157163570093
Validation loss: 2.5291725322290937

Epoch: 6| Step: 7
Training loss: 1.7322097872133515
Validation loss: 2.565601068172527

Epoch: 6| Step: 8
Training loss: 2.0890018656910865
Validation loss: 2.582516575514615

Epoch: 6| Step: 9
Training loss: 1.6388261651933345
Validation loss: 2.59630088830891

Epoch: 6| Step: 10
Training loss: 1.9778520199893808
Validation loss: 2.611554586480768

Epoch: 6| Step: 11
Training loss: 2.1574447196871254
Validation loss: 2.6246510511550563

Epoch: 6| Step: 12
Training loss: 2.211124910964373
Validation loss: 2.6065019305330095

Epoch: 6| Step: 13
Training loss: 2.4078277765639755
Validation loss: 2.5777565333277512

Epoch: 342| Step: 0
Training loss: 1.9782723129404427
Validation loss: 2.5575000856868426

Epoch: 6| Step: 1
Training loss: 1.0550511616238327
Validation loss: 2.5518398243241642

Epoch: 6| Step: 2
Training loss: 1.973091183294993
Validation loss: 2.527141084584217

Epoch: 6| Step: 3
Training loss: 1.7575181502684258
Validation loss: 2.523773883107105

Epoch: 6| Step: 4
Training loss: 1.9829611359566475
Validation loss: 2.5601648875652407

Epoch: 6| Step: 5
Training loss: 2.3745859688711146
Validation loss: 2.579904380125635

Epoch: 6| Step: 6
Training loss: 1.8254966425868735
Validation loss: 2.537995687285731

Epoch: 6| Step: 7
Training loss: 2.0424367529276086
Validation loss: 2.527758275477841

Epoch: 6| Step: 8
Training loss: 1.6995171646638525
Validation loss: 2.4696698939289274

Epoch: 6| Step: 9
Training loss: 2.076874779957505
Validation loss: 2.444289909050918

Epoch: 6| Step: 10
Training loss: 2.1301897292191376
Validation loss: 2.4158949724913676

Epoch: 6| Step: 11
Training loss: 1.8429637460935804
Validation loss: 2.4189373023858796

Epoch: 6| Step: 12
Training loss: 1.9720460457832756
Validation loss: 2.4298996184020187

Epoch: 6| Step: 13
Training loss: 2.378861951493852
Validation loss: 2.462939970794275

Epoch: 343| Step: 0
Training loss: 1.893264189496344
Validation loss: 2.4857097973319884

Epoch: 6| Step: 1
Training loss: 2.2591525526273077
Validation loss: 2.575663939502453

Epoch: 6| Step: 2
Training loss: 1.8562964590918298
Validation loss: 2.6282293102762857

Epoch: 6| Step: 3
Training loss: 1.819300554456654
Validation loss: 2.6624629441245355

Epoch: 6| Step: 4
Training loss: 1.57274935845159
Validation loss: 2.6712672687756824

Epoch: 6| Step: 5
Training loss: 2.017369897516507
Validation loss: 2.6595597881330035

Epoch: 6| Step: 6
Training loss: 1.8447480167657935
Validation loss: 2.626411355468138

Epoch: 6| Step: 7
Training loss: 1.8086107553955524
Validation loss: 2.602588003446002

Epoch: 6| Step: 8
Training loss: 2.1155164817577345
Validation loss: 2.5441215896997096

Epoch: 6| Step: 9
Training loss: 1.8985692359208828
Validation loss: 2.476233945054495

Epoch: 6| Step: 10
Training loss: 2.0162911903634253
Validation loss: 2.4561664346545404

Epoch: 6| Step: 11
Training loss: 2.327903993088546
Validation loss: 2.4316091870919903

Epoch: 6| Step: 12
Training loss: 2.025419111796414
Validation loss: 2.4221334710469296

Epoch: 6| Step: 13
Training loss: 1.413431100402824
Validation loss: 2.4547022053667833

Epoch: 344| Step: 0
Training loss: 1.646078944490437
Validation loss: 2.4872191304940805

Epoch: 6| Step: 1
Training loss: 1.530882343607595
Validation loss: 2.560638144517927

Epoch: 6| Step: 2
Training loss: 1.5743552023387555
Validation loss: 2.609215714641237

Epoch: 6| Step: 3
Training loss: 2.273236977035119
Validation loss: 2.6649225405863275

Epoch: 6| Step: 4
Training loss: 2.014691040357837
Validation loss: 2.5803601750428253

Epoch: 6| Step: 5
Training loss: 2.397299630202235
Validation loss: 2.542459910480601

Epoch: 6| Step: 6
Training loss: 1.861756282528916
Validation loss: 2.4888985139438327

Epoch: 6| Step: 7
Training loss: 2.324665340826154
Validation loss: 2.4779502484787717

Epoch: 6| Step: 8
Training loss: 1.4190031119938196
Validation loss: 2.4950814428330337

Epoch: 6| Step: 9
Training loss: 2.2877305878699485
Validation loss: 2.5117818981738442

Epoch: 6| Step: 10
Training loss: 2.255772391619817
Validation loss: 2.5305778900397935

Epoch: 6| Step: 11
Training loss: 2.227899304016654
Validation loss: 2.5089867495845257

Epoch: 6| Step: 12
Training loss: 1.7879832648191754
Validation loss: 2.515842641063859

Epoch: 6| Step: 13
Training loss: 2.1294847174958407
Validation loss: 2.5168397121376382

Epoch: 345| Step: 0
Training loss: 1.9684412880712852
Validation loss: 2.547029094109853

Epoch: 6| Step: 1
Training loss: 1.935890636846723
Validation loss: 2.523808178194965

Epoch: 6| Step: 2
Training loss: 1.6257052725068712
Validation loss: 2.5698633515617333

Epoch: 6| Step: 3
Training loss: 1.8958429259452292
Validation loss: 2.5349836079765957

Epoch: 6| Step: 4
Training loss: 1.9479246564351063
Validation loss: 2.557710422867428

Epoch: 6| Step: 5
Training loss: 1.4907212968027292
Validation loss: 2.608266081839551

Epoch: 6| Step: 6
Training loss: 1.9171318512467257
Validation loss: 2.5722714972370024

Epoch: 6| Step: 7
Training loss: 2.2876157387392317
Validation loss: 2.5693322227498787

Epoch: 6| Step: 8
Training loss: 1.8638634881633753
Validation loss: 2.5700793541595957

Epoch: 6| Step: 9
Training loss: 2.105672681341639
Validation loss: 2.5645111289607327

Epoch: 6| Step: 10
Training loss: 2.192038596133676
Validation loss: 2.5415036424722977

Epoch: 6| Step: 11
Training loss: 1.8451035267386882
Validation loss: 2.5159777077673415

Epoch: 6| Step: 12
Training loss: 2.2329197125759044
Validation loss: 2.5076888421331596

Epoch: 6| Step: 13
Training loss: 1.1201967911175599
Validation loss: 2.4736423674505454

Epoch: 346| Step: 0
Training loss: 2.4663428631027124
Validation loss: 2.4636396853266977

Epoch: 6| Step: 1
Training loss: 2.183660352643141
Validation loss: 2.4436691734497646

Epoch: 6| Step: 2
Training loss: 2.041935675927737
Validation loss: 2.495987227632177

Epoch: 6| Step: 3
Training loss: 1.8860695553288729
Validation loss: 2.5432785674887897

Epoch: 6| Step: 4
Training loss: 1.8188119359957224
Validation loss: 2.5593429063585806

Epoch: 6| Step: 5
Training loss: 1.9901571062266918
Validation loss: 2.605200516440378

Epoch: 6| Step: 6
Training loss: 2.0296973529955347
Validation loss: 2.639909943919655

Epoch: 6| Step: 7
Training loss: 2.201557873625595
Validation loss: 2.647345783952062

Epoch: 6| Step: 8
Training loss: 1.586435098993489
Validation loss: 2.5719371904312016

Epoch: 6| Step: 9
Training loss: 1.2036261072307235
Validation loss: 2.5433971576646544

Epoch: 6| Step: 10
Training loss: 2.1478798992316674
Validation loss: 2.4879753239095805

Epoch: 6| Step: 11
Training loss: 1.7632877780724168
Validation loss: 2.443111782461572

Epoch: 6| Step: 12
Training loss: 1.8633992219761781
Validation loss: 2.437654812684333

Epoch: 6| Step: 13
Training loss: 1.288136421238121
Validation loss: 2.4419863285160615

Epoch: 347| Step: 0
Training loss: 1.9665693892111709
Validation loss: 2.4715815897354734

Epoch: 6| Step: 1
Training loss: 1.4741459200304698
Validation loss: 2.5305387357763185

Epoch: 6| Step: 2
Training loss: 1.5667645051855983
Validation loss: 2.5774002742049515

Epoch: 6| Step: 3
Training loss: 1.9249539406951033
Validation loss: 2.5937140400886136

Epoch: 6| Step: 4
Training loss: 1.7382927712047966
Validation loss: 2.614386054254433

Epoch: 6| Step: 5
Training loss: 1.644980905995966
Validation loss: 2.649353737135997

Epoch: 6| Step: 6
Training loss: 1.9714951525673807
Validation loss: 2.681828414493229

Epoch: 6| Step: 7
Training loss: 1.612593608179569
Validation loss: 2.6298960591833476

Epoch: 6| Step: 8
Training loss: 1.9117758034258874
Validation loss: 2.605652081230053

Epoch: 6| Step: 9
Training loss: 2.159566236493678
Validation loss: 2.566145193331998

Epoch: 6| Step: 10
Training loss: 1.8818522176944004
Validation loss: 2.5231061442490064

Epoch: 6| Step: 11
Training loss: 2.075321917093903
Validation loss: 2.4908146074823803

Epoch: 6| Step: 12
Training loss: 2.2086154349699276
Validation loss: 2.43923447328054

Epoch: 6| Step: 13
Training loss: 2.618125451389109
Validation loss: 2.4638470996283317

Epoch: 348| Step: 0
Training loss: 1.8051868094782484
Validation loss: 2.4985943462386073

Epoch: 6| Step: 1
Training loss: 1.886492287133468
Validation loss: 2.5618991032215086

Epoch: 6| Step: 2
Training loss: 1.9866618398419997
Validation loss: 2.5962195324745623

Epoch: 6| Step: 3
Training loss: 1.597315446464256
Validation loss: 2.662700657801159

Epoch: 6| Step: 4
Training loss: 1.4642915625904007
Validation loss: 2.679099487780135

Epoch: 6| Step: 5
Training loss: 1.5228617044629496
Validation loss: 2.741506994077236

Epoch: 6| Step: 6
Training loss: 2.0306052725301265
Validation loss: 2.7560569978552425

Epoch: 6| Step: 7
Training loss: 2.0295633209041717
Validation loss: 2.7219118321238542

Epoch: 6| Step: 8
Training loss: 2.1086093219353104
Validation loss: 2.6573321517795914

Epoch: 6| Step: 9
Training loss: 1.8472725145127196
Validation loss: 2.600219421262381

Epoch: 6| Step: 10
Training loss: 2.236916863517903
Validation loss: 2.5435830235947523

Epoch: 6| Step: 11
Training loss: 1.6903191083488693
Validation loss: 2.4607125440717934

Epoch: 6| Step: 12
Training loss: 2.398122064679626
Validation loss: 2.4317187050990503

Epoch: 6| Step: 13
Training loss: 2.0089615083446715
Validation loss: 2.4500289366978163

Epoch: 349| Step: 0
Training loss: 1.994817635655168
Validation loss: 2.450605101590921

Epoch: 6| Step: 1
Training loss: 2.265159190733135
Validation loss: 2.455484563224494

Epoch: 6| Step: 2
Training loss: 2.3357351974611102
Validation loss: 2.4788686684039134

Epoch: 6| Step: 3
Training loss: 1.324949439901496
Validation loss: 2.5099492993439276

Epoch: 6| Step: 4
Training loss: 1.5151203534505315
Validation loss: 2.506470852004107

Epoch: 6| Step: 5
Training loss: 1.7881284715978103
Validation loss: 2.541828927667637

Epoch: 6| Step: 6
Training loss: 1.7760892024535315
Validation loss: 2.5583253946595677

Epoch: 6| Step: 7
Training loss: 1.4231985450608535
Validation loss: 2.5588684836306417

Epoch: 6| Step: 8
Training loss: 1.8399936104746464
Validation loss: 2.5358288904056603

Epoch: 6| Step: 9
Training loss: 2.2075090009391345
Validation loss: 2.5487343152584567

Epoch: 6| Step: 10
Training loss: 2.1295601776641506
Validation loss: 2.4794794534896636

Epoch: 6| Step: 11
Training loss: 1.7872193016054996
Validation loss: 2.4925349340501293

Epoch: 6| Step: 12
Training loss: 1.8019278427986722
Validation loss: 2.505092234839204

Epoch: 6| Step: 13
Training loss: 2.2075677540318797
Validation loss: 2.500777262177167

Epoch: 350| Step: 0
Training loss: 1.7776871904830842
Validation loss: 2.552300606963771

Epoch: 6| Step: 1
Training loss: 1.757393409785066
Validation loss: 2.622573142839447

Epoch: 6| Step: 2
Training loss: 1.734616099602586
Validation loss: 2.6352250934508117

Epoch: 6| Step: 3
Training loss: 1.6933179804088418
Validation loss: 2.6368418295879903

Epoch: 6| Step: 4
Training loss: 1.7993233627536827
Validation loss: 2.6314043673543432

Epoch: 6| Step: 5
Training loss: 1.5162507957714286
Validation loss: 2.6273627890732505

Epoch: 6| Step: 6
Training loss: 2.0829450881320275
Validation loss: 2.6029055278841406

Epoch: 6| Step: 7
Training loss: 1.8288278125366846
Validation loss: 2.578522884110251

Epoch: 6| Step: 8
Training loss: 1.903010382747741
Validation loss: 2.5787699787872946

Epoch: 6| Step: 9
Training loss: 2.3433699236093632
Validation loss: 2.562905676399205

Epoch: 6| Step: 10
Training loss: 1.8393438676590284
Validation loss: 2.522840633428568

Epoch: 6| Step: 11
Training loss: 1.8338522899054346
Validation loss: 2.5265019706040293

Epoch: 6| Step: 12
Training loss: 1.8225360436662552
Validation loss: 2.530710257741539

Epoch: 6| Step: 13
Training loss: 2.09799242788863
Validation loss: 2.5231616858319814

Epoch: 351| Step: 0
Training loss: 1.7726195881777567
Validation loss: 2.522063785290726

Epoch: 6| Step: 1
Training loss: 1.7798760452401392
Validation loss: 2.5478909085242467

Epoch: 6| Step: 2
Training loss: 2.2113869146265746
Validation loss: 2.5512097264584326

Epoch: 6| Step: 3
Training loss: 1.6447879835509926
Validation loss: 2.554334975623101

Epoch: 6| Step: 4
Training loss: 1.598544967185934
Validation loss: 2.5222226670955235

Epoch: 6| Step: 5
Training loss: 2.0107576018562883
Validation loss: 2.560988654067147

Epoch: 6| Step: 6
Training loss: 1.662263426046185
Validation loss: 2.5556206530673293

Epoch: 6| Step: 7
Training loss: 1.4043970403906816
Validation loss: 2.584552929199112

Epoch: 6| Step: 8
Training loss: 2.00718138754263
Validation loss: 2.597202945583806

Epoch: 6| Step: 9
Training loss: 1.9799554825604395
Validation loss: 2.6239605724240476

Epoch: 6| Step: 10
Training loss: 1.5994834244809193
Validation loss: 2.639582389855137

Epoch: 6| Step: 11
Training loss: 2.0768169215642964
Validation loss: 2.6478746746439707

Epoch: 6| Step: 12
Training loss: 2.1015216582346463
Validation loss: 2.6095921749828737

Epoch: 6| Step: 13
Training loss: 1.8352543635345704
Validation loss: 2.613075105358177

Epoch: 352| Step: 0
Training loss: 2.2383373845968655
Validation loss: 2.582456345278886

Epoch: 6| Step: 1
Training loss: 1.963412057121896
Validation loss: 2.5626823196360555

Epoch: 6| Step: 2
Training loss: 2.1549658890788184
Validation loss: 2.553760970804761

Epoch: 6| Step: 3
Training loss: 1.3481357329626205
Validation loss: 2.525527310733549

Epoch: 6| Step: 4
Training loss: 1.777672973994056
Validation loss: 2.4954757062647435

Epoch: 6| Step: 5
Training loss: 1.9345022822149938
Validation loss: 2.5019325231868326

Epoch: 6| Step: 6
Training loss: 1.64680805395963
Validation loss: 2.507212370806068

Epoch: 6| Step: 7
Training loss: 2.0261624520065973
Validation loss: 2.4969956106201483

Epoch: 6| Step: 8
Training loss: 1.935750848548503
Validation loss: 2.492751008019555

Epoch: 6| Step: 9
Training loss: 1.93973455471257
Validation loss: 2.5339414941546594

Epoch: 6| Step: 10
Training loss: 2.025948869660646
Validation loss: 2.5296362763162126

Epoch: 6| Step: 11
Training loss: 1.543428762889662
Validation loss: 2.5549757213686006

Epoch: 6| Step: 12
Training loss: 1.404777221869429
Validation loss: 2.578229490507546

Epoch: 6| Step: 13
Training loss: 1.0755459441547213
Validation loss: 2.583718461363525

Epoch: 353| Step: 0
Training loss: 1.5044963521155685
Validation loss: 2.5746116965062007

Epoch: 6| Step: 1
Training loss: 1.799472159240004
Validation loss: 2.535861875028297

Epoch: 6| Step: 2
Training loss: 2.340761033550098
Validation loss: 2.5426676917431394

Epoch: 6| Step: 3
Training loss: 1.8067195400839047
Validation loss: 2.523828363747663

Epoch: 6| Step: 4
Training loss: 2.1996074759831306
Validation loss: 2.5371982805468876

Epoch: 6| Step: 5
Training loss: 1.5381409650374753
Validation loss: 2.5613830026745856

Epoch: 6| Step: 6
Training loss: 1.6427958340785445
Validation loss: 2.584035715077358

Epoch: 6| Step: 7
Training loss: 1.9912952893525317
Validation loss: 2.5921094860602945

Epoch: 6| Step: 8
Training loss: 1.8581005184384116
Validation loss: 2.615087365380575

Epoch: 6| Step: 9
Training loss: 1.5168024582211175
Validation loss: 2.6339108822736166

Epoch: 6| Step: 10
Training loss: 1.7650753279651024
Validation loss: 2.6475313619484577

Epoch: 6| Step: 11
Training loss: 1.4507678202314092
Validation loss: 2.6847127782779983

Epoch: 6| Step: 12
Training loss: 1.8505802687907902
Validation loss: 2.6483881711623543

Epoch: 6| Step: 13
Training loss: 2.135694743092994
Validation loss: 2.6430811344054024

Epoch: 354| Step: 0
Training loss: 1.7769722015705307
Validation loss: 2.597938570490964

Epoch: 6| Step: 1
Training loss: 2.0441098937486086
Validation loss: 2.586530438440738

Epoch: 6| Step: 2
Training loss: 1.4217705321448464
Validation loss: 2.570250586382315

Epoch: 6| Step: 3
Training loss: 1.6591620127167024
Validation loss: 2.5276082857374607

Epoch: 6| Step: 4
Training loss: 2.1806958781755976
Validation loss: 2.518505656742498

Epoch: 6| Step: 5
Training loss: 1.7645279168168675
Validation loss: 2.5104739148963335

Epoch: 6| Step: 6
Training loss: 1.8503201336567088
Validation loss: 2.455116411012178

Epoch: 6| Step: 7
Training loss: 1.659481135707938
Validation loss: 2.4648542402488958

Epoch: 6| Step: 8
Training loss: 1.2475228560194374
Validation loss: 2.5074782748264695

Epoch: 6| Step: 9
Training loss: 1.7732447044673183
Validation loss: 2.4813678476555068

Epoch: 6| Step: 10
Training loss: 1.9185792530144947
Validation loss: 2.503483985197116

Epoch: 6| Step: 11
Training loss: 2.438481060080454
Validation loss: 2.550314486190857

Epoch: 6| Step: 12
Training loss: 1.6508688690864277
Validation loss: 2.5865848718470152

Epoch: 6| Step: 13
Training loss: 1.9255315220228069
Validation loss: 2.6215877035430055

Epoch: 355| Step: 0
Training loss: 1.4819669766884542
Validation loss: 2.643554896485476

Epoch: 6| Step: 1
Training loss: 1.93696808435303
Validation loss: 2.5992293102632877

Epoch: 6| Step: 2
Training loss: 1.562368158500202
Validation loss: 2.5436823951396956

Epoch: 6| Step: 3
Training loss: 1.151739912717153
Validation loss: 2.5169126017485834

Epoch: 6| Step: 4
Training loss: 2.1050189215382793
Validation loss: 2.4720569641161854

Epoch: 6| Step: 5
Training loss: 2.1025272693294434
Validation loss: 2.4648069609704177

Epoch: 6| Step: 6
Training loss: 1.854128705039727
Validation loss: 2.4481842697655924

Epoch: 6| Step: 7
Training loss: 1.50764503932647
Validation loss: 2.4414975484861197

Epoch: 6| Step: 8
Training loss: 2.0516883224637654
Validation loss: 2.4483664039063684

Epoch: 6| Step: 9
Training loss: 1.7628872331028331
Validation loss: 2.4626415909705623

Epoch: 6| Step: 10
Training loss: 1.9288704567141854
Validation loss: 2.5204243463370997

Epoch: 6| Step: 11
Training loss: 1.7020122147468093
Validation loss: 2.541927904864751

Epoch: 6| Step: 12
Training loss: 2.117854052132208
Validation loss: 2.6278032198414327

Epoch: 6| Step: 13
Training loss: 2.033386515354421
Validation loss: 2.656233279943473

Epoch: 356| Step: 0
Training loss: 1.820642531441832
Validation loss: 2.732126407530302

Epoch: 6| Step: 1
Training loss: 2.326854384682172
Validation loss: 2.776576298311175

Epoch: 6| Step: 2
Training loss: 2.1935443749201093
Validation loss: 2.7920517696387206

Epoch: 6| Step: 3
Training loss: 2.0519730075153957
Validation loss: 2.7119740200317457

Epoch: 6| Step: 4
Training loss: 1.751501801363808
Validation loss: 2.6524331665866727

Epoch: 6| Step: 5
Training loss: 1.9779739466842319
Validation loss: 2.600169694299179

Epoch: 6| Step: 6
Training loss: 1.5331017333114647
Validation loss: 2.5683603841423337

Epoch: 6| Step: 7
Training loss: 1.6113082976999828
Validation loss: 2.535750198506097

Epoch: 6| Step: 8
Training loss: 1.5558617532698995
Validation loss: 2.5007521584832357

Epoch: 6| Step: 9
Training loss: 1.8919729046524654
Validation loss: 2.4768142983666883

Epoch: 6| Step: 10
Training loss: 1.8001567560391725
Validation loss: 2.4522329970841628

Epoch: 6| Step: 11
Training loss: 1.5968203421418845
Validation loss: 2.4879573853953643

Epoch: 6| Step: 12
Training loss: 1.9027402492018235
Validation loss: 2.5309309186702817

Epoch: 6| Step: 13
Training loss: 1.1579405823157625
Validation loss: 2.514349890769042

Epoch: 357| Step: 0
Training loss: 1.5121455415634566
Validation loss: 2.550907845887339

Epoch: 6| Step: 1
Training loss: 1.8811521688478154
Validation loss: 2.6081243869157813

Epoch: 6| Step: 2
Training loss: 1.886479143364593
Validation loss: 2.581397124556008

Epoch: 6| Step: 3
Training loss: 1.7723406790298375
Validation loss: 2.61422612495124

Epoch: 6| Step: 4
Training loss: 1.607316561802992
Validation loss: 2.6240779841531463

Epoch: 6| Step: 5
Training loss: 1.7779923481728297
Validation loss: 2.638609185981616

Epoch: 6| Step: 6
Training loss: 2.092849879575389
Validation loss: 2.6331201515211435

Epoch: 6| Step: 7
Training loss: 1.0762680204612955
Validation loss: 2.632897891552552

Epoch: 6| Step: 8
Training loss: 1.9784377780372426
Validation loss: 2.590742658609221

Epoch: 6| Step: 9
Training loss: 2.2004012998961615
Validation loss: 2.57325814966752

Epoch: 6| Step: 10
Training loss: 1.8764556956012368
Validation loss: 2.5610568707268944

Epoch: 6| Step: 11
Training loss: 1.8878148529992849
Validation loss: 2.56856327658184

Epoch: 6| Step: 12
Training loss: 1.662058523545518
Validation loss: 2.539497943705039

Epoch: 6| Step: 13
Training loss: 1.7032246691736357
Validation loss: 2.54819298754953

Epoch: 358| Step: 0
Training loss: 1.7956507617285478
Validation loss: 2.5152892862780627

Epoch: 6| Step: 1
Training loss: 1.5879771078847502
Validation loss: 2.517041894128519

Epoch: 6| Step: 2
Training loss: 1.4394251330279493
Validation loss: 2.514106627030974

Epoch: 6| Step: 3
Training loss: 1.5372032127189963
Validation loss: 2.5486757571025467

Epoch: 6| Step: 4
Training loss: 1.8239525022763896
Validation loss: 2.6123585799259548

Epoch: 6| Step: 5
Training loss: 1.7725941001114722
Validation loss: 2.6332043141724117

Epoch: 6| Step: 6
Training loss: 2.298691634515343
Validation loss: 2.6281959973497777

Epoch: 6| Step: 7
Training loss: 2.044202384693698
Validation loss: 2.6326469339385987

Epoch: 6| Step: 8
Training loss: 1.7297183922246264
Validation loss: 2.6788290798967505

Epoch: 6| Step: 9
Training loss: 2.211286645286972
Validation loss: 2.6224419864830577

Epoch: 6| Step: 10
Training loss: 1.5179332970500425
Validation loss: 2.577246735683126

Epoch: 6| Step: 11
Training loss: 1.9948592875865976
Validation loss: 2.5554082497950836

Epoch: 6| Step: 12
Training loss: 1.6591380149453265
Validation loss: 2.5473534100557034

Epoch: 6| Step: 13
Training loss: 1.6949149513850508
Validation loss: 2.544302488645601

Epoch: 359| Step: 0
Training loss: 2.1866326928794733
Validation loss: 2.5287915861117556

Epoch: 6| Step: 1
Training loss: 2.2073063771752452
Validation loss: 2.514300875898712

Epoch: 6| Step: 2
Training loss: 2.3562052067311128
Validation loss: 2.553931832571796

Epoch: 6| Step: 3
Training loss: 1.5521859598046548
Validation loss: 2.5693548224761833

Epoch: 6| Step: 4
Training loss: 1.568449290965273
Validation loss: 2.5815661423203284

Epoch: 6| Step: 5
Training loss: 1.9005337668101034
Validation loss: 2.631968556282835

Epoch: 6| Step: 6
Training loss: 1.845489328101883
Validation loss: 2.670552999682049

Epoch: 6| Step: 7
Training loss: 1.4972435738372607
Validation loss: 2.6461826882209567

Epoch: 6| Step: 8
Training loss: 0.8044679953430783
Validation loss: 2.668800097280105

Epoch: 6| Step: 9
Training loss: 1.6299452726853938
Validation loss: 2.658827997778121

Epoch: 6| Step: 10
Training loss: 1.8367694674117423
Validation loss: 2.6145659667041614

Epoch: 6| Step: 11
Training loss: 1.862094077096866
Validation loss: 2.6071031473413626

Epoch: 6| Step: 12
Training loss: 1.5005658195166856
Validation loss: 2.5804358483998184

Epoch: 6| Step: 13
Training loss: 1.5040169811355413
Validation loss: 2.5613485380921883

Epoch: 360| Step: 0
Training loss: 1.5004761258100632
Validation loss: 2.5634020516484965

Epoch: 6| Step: 1
Training loss: 1.5764636368845268
Validation loss: 2.527649374922779

Epoch: 6| Step: 2
Training loss: 1.6094368487575241
Validation loss: 2.5473854484003167

Epoch: 6| Step: 3
Training loss: 2.0161697479566754
Validation loss: 2.552281283415004

Epoch: 6| Step: 4
Training loss: 1.6745229411793343
Validation loss: 2.5615609281877774

Epoch: 6| Step: 5
Training loss: 1.904545444013447
Validation loss: 2.586788484455967

Epoch: 6| Step: 6
Training loss: 1.7954454125456314
Validation loss: 2.5688461078944034

Epoch: 6| Step: 7
Training loss: 2.2587934956587494
Validation loss: 2.594953433492765

Epoch: 6| Step: 8
Training loss: 1.9537226258530511
Validation loss: 2.6245890313733002

Epoch: 6| Step: 9
Training loss: 1.9306028102638138
Validation loss: 2.589387284917576

Epoch: 6| Step: 10
Training loss: 1.6510579041205034
Validation loss: 2.5559615468399035

Epoch: 6| Step: 11
Training loss: 1.2915598404711817
Validation loss: 2.568051920476757

Epoch: 6| Step: 12
Training loss: 1.2127267723776565
Validation loss: 2.5544117290785264

Epoch: 6| Step: 13
Training loss: 2.312985549677113
Validation loss: 2.570287571754461

Epoch: 361| Step: 0
Training loss: 1.394338728066615
Validation loss: 2.584560624415649

Epoch: 6| Step: 1
Training loss: 2.04055322401107
Validation loss: 2.5812125960110053

Epoch: 6| Step: 2
Training loss: 1.7367527102549052
Validation loss: 2.580304735011901

Epoch: 6| Step: 3
Training loss: 1.7050589683828656
Validation loss: 2.5560421821053763

Epoch: 6| Step: 4
Training loss: 1.9749032395236372
Validation loss: 2.5841858929365573

Epoch: 6| Step: 5
Training loss: 1.7892677156115802
Validation loss: 2.564976064930182

Epoch: 6| Step: 6
Training loss: 1.4381122943660085
Validation loss: 2.5651053573200033

Epoch: 6| Step: 7
Training loss: 2.1105357049607245
Validation loss: 2.573511607290427

Epoch: 6| Step: 8
Training loss: 1.5663573906715158
Validation loss: 2.5683782631641083

Epoch: 6| Step: 9
Training loss: 1.740676498336133
Validation loss: 2.5857871571748956

Epoch: 6| Step: 10
Training loss: 2.1358484591473
Validation loss: 2.615005135243024

Epoch: 6| Step: 11
Training loss: 1.4274807768694853
Validation loss: 2.643827549304572

Epoch: 6| Step: 12
Training loss: 1.2677569858281068
Validation loss: 2.646541667945153

Epoch: 6| Step: 13
Training loss: 2.1784326366194615
Validation loss: 2.644022215055

Epoch: 362| Step: 0
Training loss: 1.5340681029400252
Validation loss: 2.6730839483453432

Epoch: 6| Step: 1
Training loss: 2.12091479591548
Validation loss: 2.667227298372773

Epoch: 6| Step: 2
Training loss: 1.856276422691455
Validation loss: 2.623877048303643

Epoch: 6| Step: 3
Training loss: 1.3606644576610956
Validation loss: 2.606175011421902

Epoch: 6| Step: 4
Training loss: 1.8062848044873419
Validation loss: 2.5783840652125334

Epoch: 6| Step: 5
Training loss: 1.8383154221068825
Validation loss: 2.5649039424850764

Epoch: 6| Step: 6
Training loss: 1.8677632230347525
Validation loss: 2.534829856189431

Epoch: 6| Step: 7
Training loss: 2.025164599852106
Validation loss: 2.5453949656823163

Epoch: 6| Step: 8
Training loss: 1.9738664295338286
Validation loss: 2.5303601688897945

Epoch: 6| Step: 9
Training loss: 2.0244187733604138
Validation loss: 2.554905954612856

Epoch: 6| Step: 10
Training loss: 1.1339853989100128
Validation loss: 2.5669452698480364

Epoch: 6| Step: 11
Training loss: 1.9015600325130355
Validation loss: 2.5618987319692823

Epoch: 6| Step: 12
Training loss: 1.2898372287227258
Validation loss: 2.5965905487308283

Epoch: 6| Step: 13
Training loss: 1.3305607618859638
Validation loss: 2.599959524374425

Epoch: 363| Step: 0
Training loss: 1.50268275046069
Validation loss: 2.63424646585143

Epoch: 6| Step: 1
Training loss: 2.2687968183578544
Validation loss: 2.6564384630049385

Epoch: 6| Step: 2
Training loss: 1.7203306385993118
Validation loss: 2.587510700628748

Epoch: 6| Step: 3
Training loss: 1.5725839612466763
Validation loss: 2.5417430878972795

Epoch: 6| Step: 4
Training loss: 1.6753051366005582
Validation loss: 2.4831659046537418

Epoch: 6| Step: 5
Training loss: 1.7659055773850838
Validation loss: 2.498796435816147

Epoch: 6| Step: 6
Training loss: 2.148790143288781
Validation loss: 2.4670262121529585

Epoch: 6| Step: 7
Training loss: 1.9397010606328908
Validation loss: 2.4918566544080445

Epoch: 6| Step: 8
Training loss: 1.6694818642023377
Validation loss: 2.5530484328305674

Epoch: 6| Step: 9
Training loss: 1.3243429750222269
Validation loss: 2.6238013508072915

Epoch: 6| Step: 10
Training loss: 1.4887125987136012
Validation loss: 2.647131834659294

Epoch: 6| Step: 11
Training loss: 1.7723850706903825
Validation loss: 2.6862145230616914

Epoch: 6| Step: 12
Training loss: 1.6261948081055055
Validation loss: 2.6922272308552526

Epoch: 6| Step: 13
Training loss: 2.1334698121800653
Validation loss: 2.724260822603661

Epoch: 364| Step: 0
Training loss: 1.8685484200140525
Validation loss: 2.7245694175798563

Epoch: 6| Step: 1
Training loss: 1.5427465351259313
Validation loss: 2.708243454860891

Epoch: 6| Step: 2
Training loss: 1.517589750699517
Validation loss: 2.6705484484783804

Epoch: 6| Step: 3
Training loss: 1.3648278936940044
Validation loss: 2.618716700937855

Epoch: 6| Step: 4
Training loss: 1.312800146025255
Validation loss: 2.5448755301883357

Epoch: 6| Step: 5
Training loss: 2.0865733574103
Validation loss: 2.506886793861883

Epoch: 6| Step: 6
Training loss: 1.9863274048210346
Validation loss: 2.461780461148733

Epoch: 6| Step: 7
Training loss: 1.262269269047047
Validation loss: 2.4519081031434773

Epoch: 6| Step: 8
Training loss: 2.4066168765503217
Validation loss: 2.4414984168590697

Epoch: 6| Step: 9
Training loss: 1.073274176331736
Validation loss: 2.438056975771248

Epoch: 6| Step: 10
Training loss: 2.5148695291156002
Validation loss: 2.4960893685537706

Epoch: 6| Step: 11
Training loss: 1.924803634635525
Validation loss: 2.530322011254054

Epoch: 6| Step: 12
Training loss: 1.664332981245321
Validation loss: 2.6112113858618655

Epoch: 6| Step: 13
Training loss: 1.7152583635529672
Validation loss: 2.668627802932184

Epoch: 365| Step: 0
Training loss: 1.9829824171917105
Validation loss: 2.6986963062017346

Epoch: 6| Step: 1
Training loss: 1.4948192775537739
Validation loss: 2.7109154914325955

Epoch: 6| Step: 2
Training loss: 1.4462890625
Validation loss: 2.7133071253557133

Epoch: 6| Step: 3
Training loss: 1.7217678971394121
Validation loss: 2.6685708294964923

Epoch: 6| Step: 4
Training loss: 1.5233783416999367
Validation loss: 2.618991265125474

Epoch: 6| Step: 5
Training loss: 1.8663726688651745
Validation loss: 2.573148153957386

Epoch: 6| Step: 6
Training loss: 1.7877996393630333
Validation loss: 2.5049306520201315

Epoch: 6| Step: 7
Training loss: 1.5879599918543226
Validation loss: 2.4828819235303894

Epoch: 6| Step: 8
Training loss: 1.7414317865497375
Validation loss: 2.498041813490326

Epoch: 6| Step: 9
Training loss: 1.6612686559176393
Validation loss: 2.531190817569116

Epoch: 6| Step: 10
Training loss: 1.7733134087659825
Validation loss: 2.5639902384127136

Epoch: 6| Step: 11
Training loss: 2.2021491953643375
Validation loss: 2.6071518265986273

Epoch: 6| Step: 12
Training loss: 1.9037729647898785
Validation loss: 2.6207096218230075

Epoch: 6| Step: 13
Training loss: 1.7809583860244613
Validation loss: 2.6513510139017504

Epoch: 366| Step: 0
Training loss: 2.0159614932681844
Validation loss: 2.670973697654921

Epoch: 6| Step: 1
Training loss: 2.183153029512259
Validation loss: 2.6626567943267827

Epoch: 6| Step: 2
Training loss: 1.4418516220492674
Validation loss: 2.6661567802973622

Epoch: 6| Step: 3
Training loss: 1.6266113508439366
Validation loss: 2.6521597692158254

Epoch: 6| Step: 4
Training loss: 1.5519268887249127
Validation loss: 2.6143039967111066

Epoch: 6| Step: 5
Training loss: 1.4137492807725447
Validation loss: 2.5771361522017022

Epoch: 6| Step: 6
Training loss: 1.5364267464532102
Validation loss: 2.5889378036554214

Epoch: 6| Step: 7
Training loss: 1.6235271528233182
Validation loss: 2.5850846457063303

Epoch: 6| Step: 8
Training loss: 1.524987239471579
Validation loss: 2.590998057884451

Epoch: 6| Step: 9
Training loss: 1.6116737318755239
Validation loss: 2.5780047913509696

Epoch: 6| Step: 10
Training loss: 1.65631909496206
Validation loss: 2.604979063903385

Epoch: 6| Step: 11
Training loss: 2.3290942945706834
Validation loss: 2.6052981793400916

Epoch: 6| Step: 12
Training loss: 1.811478425569488
Validation loss: 2.591245940664574

Epoch: 6| Step: 13
Training loss: 1.4512117157058373
Validation loss: 2.583274237432828

Epoch: 367| Step: 0
Training loss: 1.637320396532731
Validation loss: 2.5780094373152815

Epoch: 6| Step: 1
Training loss: 2.0336460946520307
Validation loss: 2.557559142462119

Epoch: 6| Step: 2
Training loss: 1.665252689741385
Validation loss: 2.565193847234567

Epoch: 6| Step: 3
Training loss: 1.9969075852483051
Validation loss: 2.5521008254643163

Epoch: 6| Step: 4
Training loss: 2.0725985591263156
Validation loss: 2.545146370353041

Epoch: 6| Step: 5
Training loss: 1.3893185597297497
Validation loss: 2.5661758611874936

Epoch: 6| Step: 6
Training loss: 1.4735981082052954
Validation loss: 2.59740554323893

Epoch: 6| Step: 7
Training loss: 1.1875925028058412
Validation loss: 2.5930050431090055

Epoch: 6| Step: 8
Training loss: 1.5093840478345535
Validation loss: 2.5994142285430057

Epoch: 6| Step: 9
Training loss: 1.7747088341254325
Validation loss: 2.5939526093933774

Epoch: 6| Step: 10
Training loss: 1.784998847148961
Validation loss: 2.606435234746745

Epoch: 6| Step: 11
Training loss: 1.8974336709553377
Validation loss: 2.5832543233670457

Epoch: 6| Step: 12
Training loss: 1.4799119209164626
Validation loss: 2.5580261036640346

Epoch: 6| Step: 13
Training loss: 1.839723036383791
Validation loss: 2.5534180894914607

Epoch: 368| Step: 0
Training loss: 2.0539924403258576
Validation loss: 2.5549399090755847

Epoch: 6| Step: 1
Training loss: 1.4251218342146563
Validation loss: 2.5681444735489705

Epoch: 6| Step: 2
Training loss: 1.939390798068573
Validation loss: 2.5785102484307822

Epoch: 6| Step: 3
Training loss: 2.1650896079392403
Validation loss: 2.59837343078511

Epoch: 6| Step: 4
Training loss: 1.0770846336745499
Validation loss: 2.584277096401089

Epoch: 6| Step: 5
Training loss: 1.4489280223989796
Validation loss: 2.6192068915459887

Epoch: 6| Step: 6
Training loss: 2.0760109839984886
Validation loss: 2.6134108884896166

Epoch: 6| Step: 7
Training loss: 0.8785994948081117
Validation loss: 2.623553050620091

Epoch: 6| Step: 8
Training loss: 0.8399205017504404
Validation loss: 2.6354021834556285

Epoch: 6| Step: 9
Training loss: 2.0604679616850077
Validation loss: 2.6064115096772005

Epoch: 6| Step: 10
Training loss: 1.8910006315491508
Validation loss: 2.6179389992586106

Epoch: 6| Step: 11
Training loss: 1.8352915824790637
Validation loss: 2.624462504324922

Epoch: 6| Step: 12
Training loss: 1.7395588155453954
Validation loss: 2.5686367254948395

Epoch: 6| Step: 13
Training loss: 1.4519655257406952
Validation loss: 2.575679988184967

Epoch: 369| Step: 0
Training loss: 1.3700712037203961
Validation loss: 2.5655279050768307

Epoch: 6| Step: 1
Training loss: 1.456618999833192
Validation loss: 2.56807192896984

Epoch: 6| Step: 2
Training loss: 2.0650371782775383
Validation loss: 2.5883301666078538

Epoch: 6| Step: 3
Training loss: 1.9459071954707936
Validation loss: 2.55154093557235

Epoch: 6| Step: 4
Training loss: 1.5971413227915248
Validation loss: 2.5845170159018127

Epoch: 6| Step: 5
Training loss: 1.444094665472901
Validation loss: 2.596955468524278

Epoch: 6| Step: 6
Training loss: 1.8193040927919555
Validation loss: 2.6028124596343774

Epoch: 6| Step: 7
Training loss: 1.1354819579410729
Validation loss: 2.6437008161975113

Epoch: 6| Step: 8
Training loss: 1.9686313169522018
Validation loss: 2.6582688054678454

Epoch: 6| Step: 9
Training loss: 1.4398408158055596
Validation loss: 2.648938095073982

Epoch: 6| Step: 10
Training loss: 1.7301828393621557
Validation loss: 2.633450764952699

Epoch: 6| Step: 11
Training loss: 2.1495500492960637
Validation loss: 2.615713922173545

Epoch: 6| Step: 12
Training loss: 1.3209487916722347
Validation loss: 2.5911442427316747

Epoch: 6| Step: 13
Training loss: 1.9898551302563081
Validation loss: 2.5700574411017434

Epoch: 370| Step: 0
Training loss: 2.1421469964915194
Validation loss: 2.544456431249014

Epoch: 6| Step: 1
Training loss: 1.8204912744578583
Validation loss: 2.538633545641954

Epoch: 6| Step: 2
Training loss: 1.845870657285866
Validation loss: 2.512226514564243

Epoch: 6| Step: 3
Training loss: 2.179371800684242
Validation loss: 2.5355438331034477

Epoch: 6| Step: 4
Training loss: 1.6481056783365962
Validation loss: 2.588145285467298

Epoch: 6| Step: 5
Training loss: 1.4880628851143798
Validation loss: 2.631678159686142

Epoch: 6| Step: 6
Training loss: 1.04554470431158
Validation loss: 2.643824106003655

Epoch: 6| Step: 7
Training loss: 1.9084293852153063
Validation loss: 2.7072253132295847

Epoch: 6| Step: 8
Training loss: 1.490181578254621
Validation loss: 2.700163676903936

Epoch: 6| Step: 9
Training loss: 1.741430075179975
Validation loss: 2.663264333206518

Epoch: 6| Step: 10
Training loss: 1.472847114154617
Validation loss: 2.6359301969031907

Epoch: 6| Step: 11
Training loss: 1.5340470439406582
Validation loss: 2.579162379003545

Epoch: 6| Step: 12
Training loss: 1.1638628897321115
Validation loss: 2.532096405289034

Epoch: 6| Step: 13
Training loss: 2.038632168431584
Validation loss: 2.506253324869642

Epoch: 371| Step: 0
Training loss: 1.5817219749778815
Validation loss: 2.5352470775681457

Epoch: 6| Step: 1
Training loss: 1.325505804290208
Validation loss: 2.609393570639658

Epoch: 6| Step: 2
Training loss: 1.541074957146573
Validation loss: 2.642413218364106

Epoch: 6| Step: 3
Training loss: 1.9021821942356465
Validation loss: 2.6471300526927535

Epoch: 6| Step: 4
Training loss: 1.6599244438349363
Validation loss: 2.6762873268699883

Epoch: 6| Step: 5
Training loss: 2.1891630118341605
Validation loss: 2.6845192506344198

Epoch: 6| Step: 6
Training loss: 2.0328751151948
Validation loss: 2.7010706760094623

Epoch: 6| Step: 7
Training loss: 1.3108876633747681
Validation loss: 2.6999167758780778

Epoch: 6| Step: 8
Training loss: 1.628359403229089
Validation loss: 2.69005487887634

Epoch: 6| Step: 9
Training loss: 1.6283583051054544
Validation loss: 2.648990198944353

Epoch: 6| Step: 10
Training loss: 1.3645791594851582
Validation loss: 2.6013135661907563

Epoch: 6| Step: 11
Training loss: 1.4347495427361077
Validation loss: 2.6219871994390296

Epoch: 6| Step: 12
Training loss: 1.5255519180890424
Validation loss: 2.5801787001617407

Epoch: 6| Step: 13
Training loss: 2.3980758344607676
Validation loss: 2.541231701846465

Epoch: 372| Step: 0
Training loss: 1.7067604111962542
Validation loss: 2.544106338535035

Epoch: 6| Step: 1
Training loss: 1.3561443217368456
Validation loss: 2.533301787498426

Epoch: 6| Step: 2
Training loss: 1.3250842121641864
Validation loss: 2.561187933468251

Epoch: 6| Step: 3
Training loss: 1.47106977656963
Validation loss: 2.567372379707644

Epoch: 6| Step: 4
Training loss: 1.6254458182676466
Validation loss: 2.5770378537796996

Epoch: 6| Step: 5
Training loss: 1.891686007811137
Validation loss: 2.593952481900821

Epoch: 6| Step: 6
Training loss: 1.6093321859349856
Validation loss: 2.612438176090803

Epoch: 6| Step: 7
Training loss: 1.6902274237203951
Validation loss: 2.650115050250272

Epoch: 6| Step: 8
Training loss: 1.3889080549613115
Validation loss: 2.674820457630382

Epoch: 6| Step: 9
Training loss: 1.6585784954532101
Validation loss: 2.667694321270079

Epoch: 6| Step: 10
Training loss: 2.01728007653016
Validation loss: 2.7065224717129173

Epoch: 6| Step: 11
Training loss: 1.601536448197032
Validation loss: 2.6747511254854017

Epoch: 6| Step: 12
Training loss: 1.9686958668850512
Validation loss: 2.6360303342730336

Epoch: 6| Step: 13
Training loss: 2.007449699902326
Validation loss: 2.588630604589716

Epoch: 373| Step: 0
Training loss: 1.9202486926187208
Validation loss: 2.526288548947219

Epoch: 6| Step: 1
Training loss: 1.5823731606320064
Validation loss: 2.528929466694411

Epoch: 6| Step: 2
Training loss: 1.4959188413840954
Validation loss: 2.510116154425765

Epoch: 6| Step: 3
Training loss: 1.546821593316334
Validation loss: 2.493369263428543

Epoch: 6| Step: 4
Training loss: 1.8718728372755595
Validation loss: 2.514108944813528

Epoch: 6| Step: 5
Training loss: 1.7065206152416532
Validation loss: 2.510747727813462

Epoch: 6| Step: 6
Training loss: 1.2156167468891594
Validation loss: 2.5750766555569884

Epoch: 6| Step: 7
Training loss: 1.9270140626846561
Validation loss: 2.6252238036115845

Epoch: 6| Step: 8
Training loss: 0.9060363188762878
Validation loss: 2.633699465558946

Epoch: 6| Step: 9
Training loss: 2.1042879151514167
Validation loss: 2.6627392502829097

Epoch: 6| Step: 10
Training loss: 1.5053931874037563
Validation loss: 2.7107832622633916

Epoch: 6| Step: 11
Training loss: 1.7038284388934613
Validation loss: 2.6730875016502247

Epoch: 6| Step: 12
Training loss: 1.7989555587113952
Validation loss: 2.6597897333711917

Epoch: 6| Step: 13
Training loss: 2.065638725939232
Validation loss: 2.6413789718711205

Epoch: 374| Step: 0
Training loss: 1.9095543535222521
Validation loss: 2.6298010264730745

Epoch: 6| Step: 1
Training loss: 1.7387034385694102
Validation loss: 2.6070813094751712

Epoch: 6| Step: 2
Training loss: 1.5064031309426498
Validation loss: 2.598778929919664

Epoch: 6| Step: 3
Training loss: 1.2389988309225088
Validation loss: 2.6114508963327654

Epoch: 6| Step: 4
Training loss: 1.7118048015573049
Validation loss: 2.592098650860688

Epoch: 6| Step: 5
Training loss: 1.3143515469666676
Validation loss: 2.577897340151454

Epoch: 6| Step: 6
Training loss: 1.8635505145825806
Validation loss: 2.567685123388542

Epoch: 6| Step: 7
Training loss: 1.7392142888513065
Validation loss: 2.5386310230338767

Epoch: 6| Step: 8
Training loss: 1.454842895337127
Validation loss: 2.5579301637544942

Epoch: 6| Step: 9
Training loss: 1.5672529030080962
Validation loss: 2.551498762680671

Epoch: 6| Step: 10
Training loss: 1.4320234382778445
Validation loss: 2.5776254378129595

Epoch: 6| Step: 11
Training loss: 1.918818330324692
Validation loss: 2.54632862158383

Epoch: 6| Step: 12
Training loss: 1.7276326311043795
Validation loss: 2.5536548918067083

Epoch: 6| Step: 13
Training loss: 1.8569486157524122
Validation loss: 2.538414197622969

Epoch: 375| Step: 0
Training loss: 1.8985743218241713
Validation loss: 2.5834380501420515

Epoch: 6| Step: 1
Training loss: 1.1503097946189067
Validation loss: 2.5916886147271816

Epoch: 6| Step: 2
Training loss: 1.6642985288476313
Validation loss: 2.6282732264701907

Epoch: 6| Step: 3
Training loss: 1.477975320798409
Validation loss: 2.590471805675395

Epoch: 6| Step: 4
Training loss: 1.2301541365212003
Validation loss: 2.6167652664382004

Epoch: 6| Step: 5
Training loss: 1.6559930998018038
Validation loss: 2.6538499000970006

Epoch: 6| Step: 6
Training loss: 1.4910094719016016
Validation loss: 2.668945251025154

Epoch: 6| Step: 7
Training loss: 1.6067927115345577
Validation loss: 2.6414660576537456

Epoch: 6| Step: 8
Training loss: 1.2511234003705278
Validation loss: 2.6012573496810747

Epoch: 6| Step: 9
Training loss: 1.316898152166416
Validation loss: 2.5794195997384044

Epoch: 6| Step: 10
Training loss: 1.985194299926968
Validation loss: 2.586259394166966

Epoch: 6| Step: 11
Training loss: 2.091812831842733
Validation loss: 2.563229863841403

Epoch: 6| Step: 12
Training loss: 1.7199419916706244
Validation loss: 2.53156467448137

Epoch: 6| Step: 13
Training loss: 2.3699510010752456
Validation loss: 2.524579977821335

Epoch: 376| Step: 0
Training loss: 2.2426568048572566
Validation loss: 2.5599936296559362

Epoch: 6| Step: 1
Training loss: 1.4199857631829313
Validation loss: 2.594592190334499

Epoch: 6| Step: 2
Training loss: 2.036140423584396
Validation loss: 2.6313772392769

Epoch: 6| Step: 3
Training loss: 1.3261302553817598
Validation loss: 2.6146175024563862

Epoch: 6| Step: 4
Training loss: 1.6163894969575352
Validation loss: 2.6534292552190064

Epoch: 6| Step: 5
Training loss: 1.8007617874914235
Validation loss: 2.6269068084304292

Epoch: 6| Step: 6
Training loss: 2.033433767350181
Validation loss: 2.605438514146973

Epoch: 6| Step: 7
Training loss: 1.6689340268507393
Validation loss: 2.625066868662325

Epoch: 6| Step: 8
Training loss: 1.8045360947548124
Validation loss: 2.575299802420297

Epoch: 6| Step: 9
Training loss: 0.971994320330882
Validation loss: 2.5734758965413986

Epoch: 6| Step: 10
Training loss: 1.4313687304428666
Validation loss: 2.574150105323191

Epoch: 6| Step: 11
Training loss: 1.5812308087899452
Validation loss: 2.558509635027964

Epoch: 6| Step: 12
Training loss: 0.9807430354815987
Validation loss: 2.5827480005992873

Epoch: 6| Step: 13
Training loss: 1.2122957057506463
Validation loss: 2.5982998575170044

Epoch: 377| Step: 0
Training loss: 1.9514050043722004
Validation loss: 2.580004976965252

Epoch: 6| Step: 1
Training loss: 1.4856667770398255
Validation loss: 2.609577568257029

Epoch: 6| Step: 2
Training loss: 2.1297283300234775
Validation loss: 2.59342536224048

Epoch: 6| Step: 3
Training loss: 1.584342793695986
Validation loss: 2.60005458588327

Epoch: 6| Step: 4
Training loss: 1.3653195945326662
Validation loss: 2.606015351432248

Epoch: 6| Step: 5
Training loss: 1.5090295495033932
Validation loss: 2.5956097165229908

Epoch: 6| Step: 6
Training loss: 1.7793402891588848
Validation loss: 2.596637766417382

Epoch: 6| Step: 7
Training loss: 1.7016124483314072
Validation loss: 2.612037311985961

Epoch: 6| Step: 8
Training loss: 1.590256096230768
Validation loss: 2.603867829599027

Epoch: 6| Step: 9
Training loss: 1.4982181137870054
Validation loss: 2.6188336111278607

Epoch: 6| Step: 10
Training loss: 1.792659824327543
Validation loss: 2.618663005444582

Epoch: 6| Step: 11
Training loss: 1.6107226904721392
Validation loss: 2.5695354934061863

Epoch: 6| Step: 12
Training loss: 1.3334508585791542
Validation loss: 2.6075363573418704

Epoch: 6| Step: 13
Training loss: 1.0739152514267638
Validation loss: 2.5462445716248907

Epoch: 378| Step: 0
Training loss: 0.897308336635538
Validation loss: 2.5561945928096788

Epoch: 6| Step: 1
Training loss: 1.8214335775440138
Validation loss: 2.585392676623555

Epoch: 6| Step: 2
Training loss: 1.4124683224662138
Validation loss: 2.6442981513694552

Epoch: 6| Step: 3
Training loss: 1.7514905031705235
Validation loss: 2.6331164556827003

Epoch: 6| Step: 4
Training loss: 1.6790391957227548
Validation loss: 2.630054672042898

Epoch: 6| Step: 5
Training loss: 1.5143002098088894
Validation loss: 2.6523794591970846

Epoch: 6| Step: 6
Training loss: 1.5833552342288857
Validation loss: 2.667417098277132

Epoch: 6| Step: 7
Training loss: 1.30760524479353
Validation loss: 2.6463112680847694

Epoch: 6| Step: 8
Training loss: 1.6030570151505037
Validation loss: 2.6340473149772436

Epoch: 6| Step: 9
Training loss: 1.8485525912830443
Validation loss: 2.6035030308589397

Epoch: 6| Step: 10
Training loss: 2.0636172880758457
Validation loss: 2.584198838159637

Epoch: 6| Step: 11
Training loss: 1.4742140082044004
Validation loss: 2.5543752655533623

Epoch: 6| Step: 12
Training loss: 1.6373576735748971
Validation loss: 2.5489429357967395

Epoch: 6| Step: 13
Training loss: 1.853549711760131
Validation loss: 2.569514831832331

Epoch: 379| Step: 0
Training loss: 1.5477350329508959
Validation loss: 2.581539485571256

Epoch: 6| Step: 1
Training loss: 1.2586139471326663
Validation loss: 2.6040492474736023

Epoch: 6| Step: 2
Training loss: 1.6835090633609482
Validation loss: 2.6215406692478753

Epoch: 6| Step: 3
Training loss: 1.7362746411765897
Validation loss: 2.6064555003745276

Epoch: 6| Step: 4
Training loss: 1.4785040951963335
Validation loss: 2.6038580096689894

Epoch: 6| Step: 5
Training loss: 1.7604729758141069
Validation loss: 2.6297360982662012

Epoch: 6| Step: 6
Training loss: 1.5086688046228822
Validation loss: 2.6190201835942615

Epoch: 6| Step: 7
Training loss: 1.8191164204742405
Validation loss: 2.659875249664458

Epoch: 6| Step: 8
Training loss: 1.9363559298416912
Validation loss: 2.6786077486086706

Epoch: 6| Step: 9
Training loss: 1.3958738045969576
Validation loss: 2.6608929489998268

Epoch: 6| Step: 10
Training loss: 1.9745454409971481
Validation loss: 2.6639351618736193

Epoch: 6| Step: 11
Training loss: 1.4119647573282024
Validation loss: 2.6531544492588663

Epoch: 6| Step: 12
Training loss: 1.0005768661787764
Validation loss: 2.6327666526384155

Epoch: 6| Step: 13
Training loss: 1.8112583511402218
Validation loss: 2.6435869234356475

Epoch: 380| Step: 0
Training loss: 1.985627447456386
Validation loss: 2.6166582772715024

Epoch: 6| Step: 1
Training loss: 1.4587910433423925
Validation loss: 2.633983079312056

Epoch: 6| Step: 2
Training loss: 1.0565382930822458
Validation loss: 2.5981310619965448

Epoch: 6| Step: 3
Training loss: 1.3006620151984725
Validation loss: 2.5991174496808607

Epoch: 6| Step: 4
Training loss: 1.3843329739703722
Validation loss: 2.6046334594425216

Epoch: 6| Step: 5
Training loss: 1.6404503865644395
Validation loss: 2.64851786067177

Epoch: 6| Step: 6
Training loss: 2.0375849606639296
Validation loss: 2.6380695633742945

Epoch: 6| Step: 7
Training loss: 1.5975238773191267
Validation loss: 2.60840328879811

Epoch: 6| Step: 8
Training loss: 1.205058043573818
Validation loss: 2.5978024835326177

Epoch: 6| Step: 9
Training loss: 1.6187836514660958
Validation loss: 2.611268153850212

Epoch: 6| Step: 10
Training loss: 1.6331166253384315
Validation loss: 2.642928515133439

Epoch: 6| Step: 11
Training loss: 2.1012991701235832
Validation loss: 2.641901014600646

Epoch: 6| Step: 12
Training loss: 1.5387507863666374
Validation loss: 2.629304902050283

Epoch: 6| Step: 13
Training loss: 1.5309884762769437
Validation loss: 2.645216164871989

Epoch: 381| Step: 0
Training loss: 1.091369872964926
Validation loss: 2.6160513843497197

Epoch: 6| Step: 1
Training loss: 1.36491933961591
Validation loss: 2.5977454814809597

Epoch: 6| Step: 2
Training loss: 2.1269192723574366
Validation loss: 2.6189693315905953

Epoch: 6| Step: 3
Training loss: 1.553683392791862
Validation loss: 2.6189445777112788

Epoch: 6| Step: 4
Training loss: 1.5655254827305933
Validation loss: 2.635924137752029

Epoch: 6| Step: 5
Training loss: 1.3051755985783635
Validation loss: 2.592627404832637

Epoch: 6| Step: 6
Training loss: 1.4815571591245387
Validation loss: 2.5677420179983153

Epoch: 6| Step: 7
Training loss: 1.679531356296222
Validation loss: 2.5957932448212864

Epoch: 6| Step: 8
Training loss: 1.8131629126186988
Validation loss: 2.6022870430341727

Epoch: 6| Step: 9
Training loss: 1.243651001790599
Validation loss: 2.5856137413964366

Epoch: 6| Step: 10
Training loss: 1.4213831124084704
Validation loss: 2.6293965879964265

Epoch: 6| Step: 11
Training loss: 1.9377460938720548
Validation loss: 2.6421887046312644

Epoch: 6| Step: 12
Training loss: 1.8412814668140662
Validation loss: 2.644461879897945

Epoch: 6| Step: 13
Training loss: 1.8843112536223823
Validation loss: 2.642628312186659

Epoch: 382| Step: 0
Training loss: 1.709903491682118
Validation loss: 2.6548019168108787

Epoch: 6| Step: 1
Training loss: 1.541835088379526
Validation loss: 2.6266216087953302

Epoch: 6| Step: 2
Training loss: 1.6835824209305603
Validation loss: 2.590697309623702

Epoch: 6| Step: 3
Training loss: 1.2965266667634663
Validation loss: 2.552075788642893

Epoch: 6| Step: 4
Training loss: 1.6258761171583607
Validation loss: 2.5460914641131867

Epoch: 6| Step: 5
Training loss: 1.6752270758135868
Validation loss: 2.5531184762724335

Epoch: 6| Step: 6
Training loss: 1.4552760456836444
Validation loss: 2.6078985108194535

Epoch: 6| Step: 7
Training loss: 1.4034843800201813
Validation loss: 2.6151921484689438

Epoch: 6| Step: 8
Training loss: 2.1698100201115453
Validation loss: 2.6628601076417255

Epoch: 6| Step: 9
Training loss: 0.9771219710876126
Validation loss: 2.726759446305098

Epoch: 6| Step: 10
Training loss: 1.6333102694978512
Validation loss: 2.743764905038583

Epoch: 6| Step: 11
Training loss: 1.2881313775805605
Validation loss: 2.779110476286211

Epoch: 6| Step: 12
Training loss: 1.9094310546238795
Validation loss: 2.713074391876534

Epoch: 6| Step: 13
Training loss: 1.857885260797396
Validation loss: 2.7034932685352726

Epoch: 383| Step: 0
Training loss: 1.5278862577515306
Validation loss: 2.5908593978201138

Epoch: 6| Step: 1
Training loss: 1.5542358048974878
Validation loss: 2.578932738095493

Epoch: 6| Step: 2
Training loss: 1.4972405483057714
Validation loss: 2.5858462886736855

Epoch: 6| Step: 3
Training loss: 1.613954712923709
Validation loss: 2.5803426204700535

Epoch: 6| Step: 4
Training loss: 1.4344828081028207
Validation loss: 2.568429237456448

Epoch: 6| Step: 5
Training loss: 2.137517971387125
Validation loss: 2.6031922385714945

Epoch: 6| Step: 6
Training loss: 1.4909766911936824
Validation loss: 2.6582478248123134

Epoch: 6| Step: 7
Training loss: 1.2101362961859625
Validation loss: 2.6840432484940995

Epoch: 6| Step: 8
Training loss: 1.8252583386197159
Validation loss: 2.7095916633029886

Epoch: 6| Step: 9
Training loss: 1.0692201595249722
Validation loss: 2.7237155769823143

Epoch: 6| Step: 10
Training loss: 1.8481582056544974
Validation loss: 2.6759980820083755

Epoch: 6| Step: 11
Training loss: 1.6365874973010217
Validation loss: 2.6784079474560265

Epoch: 6| Step: 12
Training loss: 1.6952974520951545
Validation loss: 2.6688110807204675

Epoch: 6| Step: 13
Training loss: 1.3828164224515123
Validation loss: 2.6638837939696667

Epoch: 384| Step: 0
Training loss: 1.587483671810252
Validation loss: 2.647541986264007

Epoch: 6| Step: 1
Training loss: 2.039067761644612
Validation loss: 2.619155880685852

Epoch: 6| Step: 2
Training loss: 1.6613132887840873
Validation loss: 2.6262390066345698

Epoch: 6| Step: 3
Training loss: 0.9787325742298151
Validation loss: 2.612014140318409

Epoch: 6| Step: 4
Training loss: 1.8134664392471218
Validation loss: 2.623278808015636

Epoch: 6| Step: 5
Training loss: 1.5530591708994281
Validation loss: 2.616536680091109

Epoch: 6| Step: 6
Training loss: 1.4975814394705484
Validation loss: 2.6427407174330706

Epoch: 6| Step: 7
Training loss: 1.8880806187777444
Validation loss: 2.614336523207329

Epoch: 6| Step: 8
Training loss: 1.261528874805035
Validation loss: 2.610130927102659

Epoch: 6| Step: 9
Training loss: 1.8249903482678345
Validation loss: 2.5958271044379204

Epoch: 6| Step: 10
Training loss: 1.8406404037996813
Validation loss: 2.602075752492842

Epoch: 6| Step: 11
Training loss: 1.0285024744244204
Validation loss: 2.6150743309208893

Epoch: 6| Step: 12
Training loss: 1.4863497798911174
Validation loss: 2.6038489192595975

Epoch: 6| Step: 13
Training loss: 1.1858133082643678
Validation loss: 2.6615786577706753

Epoch: 385| Step: 0
Training loss: 1.6739318886713301
Validation loss: 2.6324985244270516

Epoch: 6| Step: 1
Training loss: 1.2413200372488509
Validation loss: 2.64961888348622

Epoch: 6| Step: 2
Training loss: 1.7243424032904255
Validation loss: 2.678582101147275

Epoch: 6| Step: 3
Training loss: 1.4744499474040826
Validation loss: 2.669953338423015

Epoch: 6| Step: 4
Training loss: 1.6403937040502563
Validation loss: 2.673226440319917

Epoch: 6| Step: 5
Training loss: 1.8043667727085622
Validation loss: 2.61928824689862

Epoch: 6| Step: 6
Training loss: 1.577811937156391
Validation loss: 2.60391925612732

Epoch: 6| Step: 7
Training loss: 1.488670958911831
Validation loss: 2.601286693693687

Epoch: 6| Step: 8
Training loss: 1.5313036383751595
Validation loss: 2.590512639976679

Epoch: 6| Step: 9
Training loss: 1.744982064709677
Validation loss: 2.561216546683584

Epoch: 6| Step: 10
Training loss: 1.4747451012402795
Validation loss: 2.568474173127682

Epoch: 6| Step: 11
Training loss: 1.4988476777559827
Validation loss: 2.5487056896547124

Epoch: 6| Step: 12
Training loss: 1.4780421034167655
Validation loss: 2.5798033808756853

Epoch: 6| Step: 13
Training loss: 1.75997994628232
Validation loss: 2.618240574111749

Epoch: 386| Step: 0
Training loss: 1.9564898992794892
Validation loss: 2.612706135619243

Epoch: 6| Step: 1
Training loss: 1.4965507267576295
Validation loss: 2.6170184729035397

Epoch: 6| Step: 2
Training loss: 1.2560738340379798
Validation loss: 2.6313239202691454

Epoch: 6| Step: 3
Training loss: 1.8474357102374885
Validation loss: 2.6321929965219857

Epoch: 6| Step: 4
Training loss: 1.6729464796298938
Validation loss: 2.617443856650916

Epoch: 6| Step: 5
Training loss: 1.2654150800513926
Validation loss: 2.6257722932488923

Epoch: 6| Step: 6
Training loss: 1.800424602549616
Validation loss: 2.617436724327334

Epoch: 6| Step: 7
Training loss: 1.5314683563868958
Validation loss: 2.628834612752749

Epoch: 6| Step: 8
Training loss: 1.4929143922692465
Validation loss: 2.6187008695041456

Epoch: 6| Step: 9
Training loss: 1.6844197170004926
Validation loss: 2.6272520702231583

Epoch: 6| Step: 10
Training loss: 1.6336524664580747
Validation loss: 2.6142816477793396

Epoch: 6| Step: 11
Training loss: 1.5270469747936106
Validation loss: 2.640711501946687

Epoch: 6| Step: 12
Training loss: 1.4810508851731077
Validation loss: 2.645613659695634

Epoch: 6| Step: 13
Training loss: 1.336018074684313
Validation loss: 2.658991210532258

Epoch: 387| Step: 0
Training loss: 1.1887932812245445
Validation loss: 2.6563910739408283

Epoch: 6| Step: 1
Training loss: 1.6217273622911343
Validation loss: 2.6731763480815975

Epoch: 6| Step: 2
Training loss: 1.5175928927651798
Validation loss: 2.66680833096711

Epoch: 6| Step: 3
Training loss: 1.9399725611211185
Validation loss: 2.6424020136258513

Epoch: 6| Step: 4
Training loss: 1.4980712252034183
Validation loss: 2.639779173068173

Epoch: 6| Step: 5
Training loss: 1.6619082552196105
Validation loss: 2.655498485673057

Epoch: 6| Step: 6
Training loss: 1.497853650857522
Validation loss: 2.621116148925387

Epoch: 6| Step: 7
Training loss: 1.3948513059089878
Validation loss: 2.624982211691906

Epoch: 6| Step: 8
Training loss: 1.1370129810756435
Validation loss: 2.6558231225491813

Epoch: 6| Step: 9
Training loss: 2.0303298039614166
Validation loss: 2.6905183033273627

Epoch: 6| Step: 10
Training loss: 1.5058033261091526
Validation loss: 2.671493028981497

Epoch: 6| Step: 11
Training loss: 1.8713363458337149
Validation loss: 2.688494592471052

Epoch: 6| Step: 12
Training loss: 1.449464350451145
Validation loss: 2.608739175025865

Epoch: 6| Step: 13
Training loss: 1.3014700958679526
Validation loss: 2.5712120999566603

Epoch: 388| Step: 0
Training loss: 1.3307822628091288
Validation loss: 2.5947671618827486

Epoch: 6| Step: 1
Training loss: 1.5443965438272553
Validation loss: 2.5966672448254204

Epoch: 6| Step: 2
Training loss: 1.6643647828255856
Validation loss: 2.646027333500907

Epoch: 6| Step: 3
Training loss: 1.8847733413459271
Validation loss: 2.6530774545037095

Epoch: 6| Step: 4
Training loss: 1.44842877925482
Validation loss: 2.6547859476146733

Epoch: 6| Step: 5
Training loss: 1.3101439446432688
Validation loss: 2.688175498088544

Epoch: 6| Step: 6
Training loss: 2.0508312400901225
Validation loss: 2.689204881697815

Epoch: 6| Step: 7
Training loss: 1.4353650036259185
Validation loss: 2.73222503003499

Epoch: 6| Step: 8
Training loss: 1.6971524006573862
Validation loss: 2.7105993419497807

Epoch: 6| Step: 9
Training loss: 1.6747101604155048
Validation loss: 2.70768496480469

Epoch: 6| Step: 10
Training loss: 1.545726233968295
Validation loss: 2.712990253872021

Epoch: 6| Step: 11
Training loss: 1.4363379549961508
Validation loss: 2.6781257022782987

Epoch: 6| Step: 12
Training loss: 1.3633200741024405
Validation loss: 2.6230633633684772

Epoch: 6| Step: 13
Training loss: 1.3534507130392088
Validation loss: 2.61308194348993

Epoch: 389| Step: 0
Training loss: 1.2344359853624256
Validation loss: 2.573964317216783

Epoch: 6| Step: 1
Training loss: 1.343961388572603
Validation loss: 2.624967467442898

Epoch: 6| Step: 2
Training loss: 1.3100903962519623
Validation loss: 2.670233701593129

Epoch: 6| Step: 3
Training loss: 1.649624221088179
Validation loss: 2.687256871925985

Epoch: 6| Step: 4
Training loss: 1.8275615117148758
Validation loss: 2.731526726221948

Epoch: 6| Step: 5
Training loss: 1.8030637892675137
Validation loss: 2.7395516718960984

Epoch: 6| Step: 6
Training loss: 1.1804986148391476
Validation loss: 2.7563567789843924

Epoch: 6| Step: 7
Training loss: 1.9623205163605264
Validation loss: 2.7612801032444594

Epoch: 6| Step: 8
Training loss: 1.585756864737047
Validation loss: 2.7640730661697486

Epoch: 6| Step: 9
Training loss: 1.6038966591571961
Validation loss: 2.7045356710953863

Epoch: 6| Step: 10
Training loss: 1.514325007149939
Validation loss: 2.653700129831125

Epoch: 6| Step: 11
Training loss: 1.5995591450351487
Validation loss: 2.579626735469659

Epoch: 6| Step: 12
Training loss: 1.5805600707993972
Validation loss: 2.5702224607456365

Epoch: 6| Step: 13
Training loss: 1.2902599437280928
Validation loss: 2.5297002049745836

Epoch: 390| Step: 0
Training loss: 1.5651267288621333
Validation loss: 2.4653553956025265

Epoch: 6| Step: 1
Training loss: 1.652675442060773
Validation loss: 2.499227258763119

Epoch: 6| Step: 2
Training loss: 1.7710784817219645
Validation loss: 2.544099539720764

Epoch: 6| Step: 3
Training loss: 1.7077341967446096
Validation loss: 2.6040741173490636

Epoch: 6| Step: 4
Training loss: 1.211067881794522
Validation loss: 2.707850032750043

Epoch: 6| Step: 5
Training loss: 1.9848915689289612
Validation loss: 2.7923301939203067

Epoch: 6| Step: 6
Training loss: 1.8391907782530432
Validation loss: 2.7817158250749867

Epoch: 6| Step: 7
Training loss: 1.9507596761406558
Validation loss: 2.8125044372596513

Epoch: 6| Step: 8
Training loss: 1.6160742572256863
Validation loss: 2.7732942471676387

Epoch: 6| Step: 9
Training loss: 1.5324731729222272
Validation loss: 2.6779786576650375

Epoch: 6| Step: 10
Training loss: 1.5467409017987994
Validation loss: 2.591073065358611

Epoch: 6| Step: 11
Training loss: 0.9738652937949756
Validation loss: 2.54108104955942

Epoch: 6| Step: 12
Training loss: 1.462043384445793
Validation loss: 2.4426194534768384

Epoch: 6| Step: 13
Training loss: 0.8006892826023854
Validation loss: 2.462203118077517

Epoch: 391| Step: 0
Training loss: 1.2036184314671758
Validation loss: 2.4547670343675074

Epoch: 6| Step: 1
Training loss: 1.88903893392171
Validation loss: 2.4482957211795564

Epoch: 6| Step: 2
Training loss: 1.4644100920591232
Validation loss: 2.487509195862446

Epoch: 6| Step: 3
Training loss: 1.7739857905785381
Validation loss: 2.562527300001177

Epoch: 6| Step: 4
Training loss: 1.323737312954918
Validation loss: 2.6016703888176855

Epoch: 6| Step: 5
Training loss: 1.4259507169995047
Validation loss: 2.6694683848024208

Epoch: 6| Step: 6
Training loss: 1.8613374755880687
Validation loss: 2.6799089740914743

Epoch: 6| Step: 7
Training loss: 1.764407658154791
Validation loss: 2.737896836255078

Epoch: 6| Step: 8
Training loss: 1.7523097735243378
Validation loss: 2.716722042526694

Epoch: 6| Step: 9
Training loss: 1.8693432992015606
Validation loss: 2.7293786050590336

Epoch: 6| Step: 10
Training loss: 0.9001732685934944
Validation loss: 2.6779943258196046

Epoch: 6| Step: 11
Training loss: 1.2761830880822904
Validation loss: 2.6596155299357473

Epoch: 6| Step: 12
Training loss: 1.376248096669169
Validation loss: 2.6090784324965934

Epoch: 6| Step: 13
Training loss: 1.563542742880244
Validation loss: 2.6389344933769445

Epoch: 392| Step: 0
Training loss: 1.429536238209357
Validation loss: 2.66020054693207

Epoch: 6| Step: 1
Training loss: 1.5963450976596958
Validation loss: 2.647972608927555

Epoch: 6| Step: 2
Training loss: 1.3476120651299472
Validation loss: 2.690396658776905

Epoch: 6| Step: 3
Training loss: 1.5665393496921522
Validation loss: 2.6605467931345332

Epoch: 6| Step: 4
Training loss: 1.2249198653810887
Validation loss: 2.670775676639479

Epoch: 6| Step: 5
Training loss: 1.570276440258586
Validation loss: 2.6644907913725464

Epoch: 6| Step: 6
Training loss: 1.359000757375791
Validation loss: 2.683219500854324

Epoch: 6| Step: 7
Training loss: 1.5950809979575225
Validation loss: 2.6470580331236984

Epoch: 6| Step: 8
Training loss: 1.8145721692144399
Validation loss: 2.6387981375083007

Epoch: 6| Step: 9
Training loss: 1.452766292146527
Validation loss: 2.6295739632830566

Epoch: 6| Step: 10
Training loss: 1.6056802058130517
Validation loss: 2.6316390259733233

Epoch: 6| Step: 11
Training loss: 1.7725627607202343
Validation loss: 2.632502804951104

Epoch: 6| Step: 12
Training loss: 1.5537992460712788
Validation loss: 2.61791683657244

Epoch: 6| Step: 13
Training loss: 1.192818826724097
Validation loss: 2.5929855028522035

Epoch: 393| Step: 0
Training loss: 1.6213405191509054
Validation loss: 2.5790652164399153

Epoch: 6| Step: 1
Training loss: 1.4556474020099344
Validation loss: 2.5785606943384103

Epoch: 6| Step: 2
Training loss: 2.168283910439768
Validation loss: 2.570600279403033

Epoch: 6| Step: 3
Training loss: 1.3784707221795203
Validation loss: 2.619874981807319

Epoch: 6| Step: 4
Training loss: 1.0194043193742843
Validation loss: 2.618874900862911

Epoch: 6| Step: 5
Training loss: 1.244168076144981
Validation loss: 2.6158667856169955

Epoch: 6| Step: 6
Training loss: 1.0343790843687064
Validation loss: 2.6706619392251483

Epoch: 6| Step: 7
Training loss: 1.4519829312627
Validation loss: 2.678062654061193

Epoch: 6| Step: 8
Training loss: 1.6460547559815046
Validation loss: 2.6824772500672696

Epoch: 6| Step: 9
Training loss: 1.6704745978553754
Validation loss: 2.6866257579398107

Epoch: 6| Step: 10
Training loss: 1.95166858540524
Validation loss: 2.6823581061700343

Epoch: 6| Step: 11
Training loss: 1.6708219545251206
Validation loss: 2.662814038232171

Epoch: 6| Step: 12
Training loss: 1.2370166759492525
Validation loss: 2.641846218769955

Epoch: 6| Step: 13
Training loss: 1.305986910887317
Validation loss: 2.5655544254162383

Epoch: 394| Step: 0
Training loss: 1.2623160634272668
Validation loss: 2.5333390046667703

Epoch: 6| Step: 1
Training loss: 1.3023048619332254
Validation loss: 2.534598285789629

Epoch: 6| Step: 2
Training loss: 1.5937685497924776
Validation loss: 2.541022539009186

Epoch: 6| Step: 3
Training loss: 1.803809674941984
Validation loss: 2.560838071873603

Epoch: 6| Step: 4
Training loss: 1.2833196624836887
Validation loss: 2.577036634153004

Epoch: 6| Step: 5
Training loss: 1.676398885943462
Validation loss: 2.6159930277211516

Epoch: 6| Step: 6
Training loss: 1.6641987489611032
Validation loss: 2.6149051495823707

Epoch: 6| Step: 7
Training loss: 0.8150854789046009
Validation loss: 2.6604850117398664

Epoch: 6| Step: 8
Training loss: 1.482765610237901
Validation loss: 2.658983335422466

Epoch: 6| Step: 9
Training loss: 1.9603684044091967
Validation loss: 2.6452397139284067

Epoch: 6| Step: 10
Training loss: 1.2960451987326282
Validation loss: 2.6351131322938994

Epoch: 6| Step: 11
Training loss: 1.6062490233184576
Validation loss: 2.6480384627927775

Epoch: 6| Step: 12
Training loss: 1.5433531463427843
Validation loss: 2.6236365860321746

Epoch: 6| Step: 13
Training loss: 1.4297301906194575
Validation loss: 2.61336035111876

Epoch: 395| Step: 0
Training loss: 1.5351386226971837
Validation loss: 2.5824445041588366

Epoch: 6| Step: 1
Training loss: 1.662378452991881
Validation loss: 2.580935392062969

Epoch: 6| Step: 2
Training loss: 1.5205454445005924
Validation loss: 2.594465752733316

Epoch: 6| Step: 3
Training loss: 1.6360961166771288
Validation loss: 2.6070450673389307

Epoch: 6| Step: 4
Training loss: 1.028779567604153
Validation loss: 2.5984500949746687

Epoch: 6| Step: 5
Training loss: 1.5638282470886027
Validation loss: 2.5898589911738035

Epoch: 6| Step: 6
Training loss: 1.6297195563084943
Validation loss: 2.6233250782109097

Epoch: 6| Step: 7
Training loss: 1.2617965532531197
Validation loss: 2.666171686189744

Epoch: 6| Step: 8
Training loss: 1.7872237038651515
Validation loss: 2.648751319662277

Epoch: 6| Step: 9
Training loss: 1.0840704256561413
Validation loss: 2.6057603005115246

Epoch: 6| Step: 10
Training loss: 1.3053060196196702
Validation loss: 2.6864811730122593

Epoch: 6| Step: 11
Training loss: 1.7731954938814514
Validation loss: 2.6635156487068232

Epoch: 6| Step: 12
Training loss: 1.6336862516917607
Validation loss: 2.693852604427827

Epoch: 6| Step: 13
Training loss: 0.9251465372053443
Validation loss: 2.6595013991057868

Epoch: 396| Step: 0
Training loss: 2.007826036934546
Validation loss: 2.6531076856618028

Epoch: 6| Step: 1
Training loss: 1.4918893246548295
Validation loss: 2.6508515843431084

Epoch: 6| Step: 2
Training loss: 1.4575533097792301
Validation loss: 2.67773865836699

Epoch: 6| Step: 3
Training loss: 1.4669676984729545
Validation loss: 2.6675330210877504

Epoch: 6| Step: 4
Training loss: 1.7689659445133195
Validation loss: 2.65173565619825

Epoch: 6| Step: 5
Training loss: 1.7286514832290432
Validation loss: 2.6272058521132506

Epoch: 6| Step: 6
Training loss: 1.403778277525911
Validation loss: 2.6186502952076873

Epoch: 6| Step: 7
Training loss: 1.4023582011463795
Validation loss: 2.619898129940484

Epoch: 6| Step: 8
Training loss: 1.5615458054458387
Validation loss: 2.5951133008575114

Epoch: 6| Step: 9
Training loss: 1.3275859411980773
Validation loss: 2.605974732505452

Epoch: 6| Step: 10
Training loss: 1.0011369679021778
Validation loss: 2.620815211133865

Epoch: 6| Step: 11
Training loss: 1.4750958783297792
Validation loss: 2.666139288700423

Epoch: 6| Step: 12
Training loss: 1.304316896351766
Validation loss: 2.692982771269913

Epoch: 6| Step: 13
Training loss: 1.4722937990378906
Validation loss: 2.7302137268663915

Epoch: 397| Step: 0
Training loss: 1.4651468599158297
Validation loss: 2.698722893417384

Epoch: 6| Step: 1
Training loss: 1.1964738975512013
Validation loss: 2.6259410683094444

Epoch: 6| Step: 2
Training loss: 1.1314525991870599
Validation loss: 2.652282775035943

Epoch: 6| Step: 3
Training loss: 1.601339408409311
Validation loss: 2.603961077706763

Epoch: 6| Step: 4
Training loss: 1.6670536863472822
Validation loss: 2.5978443266103164

Epoch: 6| Step: 5
Training loss: 1.8009096708039023
Validation loss: 2.5708999757845734

Epoch: 6| Step: 6
Training loss: 1.1375942987613021
Validation loss: 2.5898199550985916

Epoch: 6| Step: 7
Training loss: 1.7796069146215543
Validation loss: 2.5777059433865244

Epoch: 6| Step: 8
Training loss: 1.6953065230444395
Validation loss: 2.6173797365401943

Epoch: 6| Step: 9
Training loss: 1.8992766735136566
Validation loss: 2.606974330984596

Epoch: 6| Step: 10
Training loss: 0.9687080066562275
Validation loss: 2.598397821221816

Epoch: 6| Step: 11
Training loss: 1.4385439357790313
Validation loss: 2.6347754036840434

Epoch: 6| Step: 12
Training loss: 1.4569234117788439
Validation loss: 2.6348549200654303

Epoch: 6| Step: 13
Training loss: 0.9199357730277284
Validation loss: 2.6663615016243942

Epoch: 398| Step: 0
Training loss: 1.1883600032073194
Validation loss: 2.702629355463842

Epoch: 6| Step: 1
Training loss: 2.059545076377514
Validation loss: 2.7051611794918142

Epoch: 6| Step: 2
Training loss: 1.78155514964334
Validation loss: 2.7017142148123554

Epoch: 6| Step: 3
Training loss: 1.4375467707447342
Validation loss: 2.6433589583171

Epoch: 6| Step: 4
Training loss: 1.5584104807859627
Validation loss: 2.615051231259676

Epoch: 6| Step: 5
Training loss: 1.618917010319139
Validation loss: 2.5731177121730573

Epoch: 6| Step: 6
Training loss: 0.9867900408847244
Validation loss: 2.5110394137700682

Epoch: 6| Step: 7
Training loss: 1.2304441419290315
Validation loss: 2.5037310886500785

Epoch: 6| Step: 8
Training loss: 1.420383131832985
Validation loss: 2.516845622019556

Epoch: 6| Step: 9
Training loss: 1.4029566028705107
Validation loss: 2.5461075280269343

Epoch: 6| Step: 10
Training loss: 1.635846399432233
Validation loss: 2.610041944216805

Epoch: 6| Step: 11
Training loss: 1.3048767135379378
Validation loss: 2.685783031890422

Epoch: 6| Step: 12
Training loss: 1.7430144259128866
Validation loss: 2.712290460137144

Epoch: 6| Step: 13
Training loss: 1.4410966576872926
Validation loss: 2.710627491163449

Epoch: 399| Step: 0
Training loss: 2.0241047705270376
Validation loss: 2.778496304832994

Epoch: 6| Step: 1
Training loss: 1.577206108054539
Validation loss: 2.7507183371030894

Epoch: 6| Step: 2
Training loss: 1.7318818326861407
Validation loss: 2.74601031376068

Epoch: 6| Step: 3
Training loss: 1.413950372960821
Validation loss: 2.693640791063476

Epoch: 6| Step: 4
Training loss: 1.4696223326569045
Validation loss: 2.6532340950550752

Epoch: 6| Step: 5
Training loss: 1.3923947934552792
Validation loss: 2.6388501481985296

Epoch: 6| Step: 6
Training loss: 1.7667548016690322
Validation loss: 2.6128495341060787

Epoch: 6| Step: 7
Training loss: 1.3008646895307114
Validation loss: 2.5456039293800976

Epoch: 6| Step: 8
Training loss: 1.211069309075111
Validation loss: 2.5763117116557037

Epoch: 6| Step: 9
Training loss: 1.3602645857172173
Validation loss: 2.5434488120266816

Epoch: 6| Step: 10
Training loss: 1.328797069372589
Validation loss: 2.526347166328726

Epoch: 6| Step: 11
Training loss: 1.4060354704933953
Validation loss: 2.5554343344255788

Epoch: 6| Step: 12
Training loss: 1.121690119648837
Validation loss: 2.603826449576893

Epoch: 6| Step: 13
Training loss: 1.62327520827791
Validation loss: 2.6309789908773147

Epoch: 400| Step: 0
Training loss: 1.5401706482108894
Validation loss: 2.6430584696272406

Epoch: 6| Step: 1
Training loss: 1.6308475334057368
Validation loss: 2.6471084859602025

Epoch: 6| Step: 2
Training loss: 1.2371073552685201
Validation loss: 2.6571512043483807

Epoch: 6| Step: 3
Training loss: 1.562359612833887
Validation loss: 2.641322418149257

Epoch: 6| Step: 4
Training loss: 1.4139878058332631
Validation loss: 2.637796509279094

Epoch: 6| Step: 5
Training loss: 1.445364791336568
Validation loss: 2.6082089959023045

Epoch: 6| Step: 6
Training loss: 1.3357011909513254
Validation loss: 2.6134508954857836

Epoch: 6| Step: 7
Training loss: 1.3735446597359415
Validation loss: 2.5899971198108993

Epoch: 6| Step: 8
Training loss: 1.1344883591519974
Validation loss: 2.644751026467324

Epoch: 6| Step: 9
Training loss: 1.5370000972462352
Validation loss: 2.608867037531274

Epoch: 6| Step: 10
Training loss: 1.7334559987141727
Validation loss: 2.639994076560278

Epoch: 6| Step: 11
Training loss: 1.0660272840153753
Validation loss: 2.6728143389505834

Epoch: 6| Step: 12
Training loss: 1.8083847946837284
Validation loss: 2.687771535683815

Epoch: 6| Step: 13
Training loss: 1.6602870754978447
Validation loss: 2.7116713559438477

Epoch: 401| Step: 0
Training loss: 1.9653746113399808
Validation loss: 2.6731837900985274

Epoch: 6| Step: 1
Training loss: 1.2736610731204885
Validation loss: 2.6905603319362927

Epoch: 6| Step: 2
Training loss: 1.7459302309348201
Validation loss: 2.6977209562703077

Epoch: 6| Step: 3
Training loss: 1.457001632103042
Validation loss: 2.6560423623278617

Epoch: 6| Step: 4
Training loss: 1.2804412149909918
Validation loss: 2.6492589853294795

Epoch: 6| Step: 5
Training loss: 1.6042617753143473
Validation loss: 2.652045705159879

Epoch: 6| Step: 6
Training loss: 1.4666824397770604
Validation loss: 2.6652255939274307

Epoch: 6| Step: 7
Training loss: 1.3159693323985466
Validation loss: 2.660913676609269

Epoch: 6| Step: 8
Training loss: 1.3560633166111555
Validation loss: 2.6488296238346254

Epoch: 6| Step: 9
Training loss: 1.0809885227042244
Validation loss: 2.609331371936665

Epoch: 6| Step: 10
Training loss: 1.438947777829747
Validation loss: 2.653876646795908

Epoch: 6| Step: 11
Training loss: 1.4263427464839535
Validation loss: 2.6512248338222206

Epoch: 6| Step: 12
Training loss: 1.6551470412887017
Validation loss: 2.633974550320569

Epoch: 6| Step: 13
Training loss: 1.1428729858747848
Validation loss: 2.609392752245297

Epoch: 402| Step: 0
Training loss: 1.5880366372030725
Validation loss: 2.5923249962926582

Epoch: 6| Step: 1
Training loss: 1.3329248199897206
Validation loss: 2.5808603959028837

Epoch: 6| Step: 2
Training loss: 1.0822726094119606
Validation loss: 2.60023125045269

Epoch: 6| Step: 3
Training loss: 1.790986138853006
Validation loss: 2.5950092521058536

Epoch: 6| Step: 4
Training loss: 1.395807958723369
Validation loss: 2.603301116501161

Epoch: 6| Step: 5
Training loss: 1.56784349367933
Validation loss: 2.6107211694172925

Epoch: 6| Step: 6
Training loss: 1.366803186079894
Validation loss: 2.605069648634007

Epoch: 6| Step: 7
Training loss: 1.4984391356649214
Validation loss: 2.6499276699458223

Epoch: 6| Step: 8
Training loss: 1.8371796646638883
Validation loss: 2.698353190963852

Epoch: 6| Step: 9
Training loss: 1.183147635910883
Validation loss: 2.751058540699875

Epoch: 6| Step: 10
Training loss: 1.3546663487245032
Validation loss: 2.710443088306583

Epoch: 6| Step: 11
Training loss: 1.6357741076642984
Validation loss: 2.71153502111656

Epoch: 6| Step: 12
Training loss: 1.6878769065124641
Validation loss: 2.6780089150129

Epoch: 6| Step: 13
Training loss: 0.8872941960548545
Validation loss: 2.6285493804099564

Epoch: 403| Step: 0
Training loss: 1.2499917983739723
Validation loss: 2.6125869626990017

Epoch: 6| Step: 1
Training loss: 1.790350637670592
Validation loss: 2.5927200422193697

Epoch: 6| Step: 2
Training loss: 1.340082130690789
Validation loss: 2.585705774920027

Epoch: 6| Step: 3
Training loss: 1.3466493687525922
Validation loss: 2.552182248684625

Epoch: 6| Step: 4
Training loss: 1.3393096304075076
Validation loss: 2.543457394610722

Epoch: 6| Step: 5
Training loss: 1.7563437874618566
Validation loss: 2.6092135658406046

Epoch: 6| Step: 6
Training loss: 1.2139874350417594
Validation loss: 2.6290786658101104

Epoch: 6| Step: 7
Training loss: 1.4089739378988608
Validation loss: 2.6575663249280983

Epoch: 6| Step: 8
Training loss: 1.453822553009912
Validation loss: 2.735126606061265

Epoch: 6| Step: 9
Training loss: 1.6253601555419612
Validation loss: 2.7598217134762137

Epoch: 6| Step: 10
Training loss: 1.946953751393365
Validation loss: 2.7258938407469215

Epoch: 6| Step: 11
Training loss: 1.2256599555898244
Validation loss: 2.7073016022881635

Epoch: 6| Step: 12
Training loss: 0.8206973308520293
Validation loss: 2.722541674259369

Epoch: 6| Step: 13
Training loss: 1.7997340138262297
Validation loss: 2.700123066719963

Epoch: 404| Step: 0
Training loss: 1.059512482220804
Validation loss: 2.615522484552931

Epoch: 6| Step: 1
Training loss: 1.672609114572974
Validation loss: 2.5418756416895456

Epoch: 6| Step: 2
Training loss: 1.6666300133807337
Validation loss: 2.548951961526585

Epoch: 6| Step: 3
Training loss: 1.2738753426137452
Validation loss: 2.530156887893212

Epoch: 6| Step: 4
Training loss: 2.0916523460516006
Validation loss: 2.52276511952257

Epoch: 6| Step: 5
Training loss: 1.2310687827347815
Validation loss: 2.553737782337019

Epoch: 6| Step: 6
Training loss: 1.257249030670563
Validation loss: 2.6207625099395955

Epoch: 6| Step: 7
Training loss: 1.4695906161171186
Validation loss: 2.649339783621676

Epoch: 6| Step: 8
Training loss: 1.5728907130375944
Validation loss: 2.695019755041354

Epoch: 6| Step: 9
Training loss: 1.4591638743172155
Validation loss: 2.7137310654879596

Epoch: 6| Step: 10
Training loss: 1.5144023879877238
Validation loss: 2.731356916021932

Epoch: 6| Step: 11
Training loss: 1.4282002869508907
Validation loss: 2.7055655946792587

Epoch: 6| Step: 12
Training loss: 1.2545745114654312
Validation loss: 2.6746773019987606

Epoch: 6| Step: 13
Training loss: 1.0801824205479214
Validation loss: 2.640873809352463

Epoch: 405| Step: 0
Training loss: 1.1522734539767732
Validation loss: 2.6378529490800324

Epoch: 6| Step: 1
Training loss: 1.2142579852873048
Validation loss: 2.62104506461383

Epoch: 6| Step: 2
Training loss: 1.1343800715393528
Validation loss: 2.6480503397625523

Epoch: 6| Step: 3
Training loss: 1.3725750955073486
Validation loss: 2.6508241949404137

Epoch: 6| Step: 4
Training loss: 1.3954697130580282
Validation loss: 2.649065211504209

Epoch: 6| Step: 5
Training loss: 1.8586392910586411
Validation loss: 2.6016866465937936

Epoch: 6| Step: 6
Training loss: 1.6502556920617268
Validation loss: 2.5927972448465786

Epoch: 6| Step: 7
Training loss: 1.3906709899155472
Validation loss: 2.5889994506022913

Epoch: 6| Step: 8
Training loss: 1.6251107691645033
Validation loss: 2.6031712049893074

Epoch: 6| Step: 9
Training loss: 1.3330476077221456
Validation loss: 2.5908498986573116

Epoch: 6| Step: 10
Training loss: 1.5531178894494235
Validation loss: 2.6199734744451577

Epoch: 6| Step: 11
Training loss: 1.4458783665806902
Validation loss: 2.6619286767041315

Epoch: 6| Step: 12
Training loss: 1.3109278572828187
Validation loss: 2.6698417888910773

Epoch: 6| Step: 13
Training loss: 1.8085577613100647
Validation loss: 2.677427003511395

Epoch: 406| Step: 0
Training loss: 1.3677040214305969
Validation loss: 2.6387291850403347

Epoch: 6| Step: 1
Training loss: 1.0413991139447167
Validation loss: 2.6695514202335757

Epoch: 6| Step: 2
Training loss: 1.2019969556550938
Validation loss: 2.6657480915706766

Epoch: 6| Step: 3
Training loss: 2.038868043477105
Validation loss: 2.649933380725983

Epoch: 6| Step: 4
Training loss: 1.20944702959074
Validation loss: 2.6418143623728647

Epoch: 6| Step: 5
Training loss: 1.3300784835030721
Validation loss: 2.616888335211346

Epoch: 6| Step: 6
Training loss: 1.3893814098435093
Validation loss: 2.6164055052877804

Epoch: 6| Step: 7
Training loss: 1.569731040075812
Validation loss: 2.6416756863056903

Epoch: 6| Step: 8
Training loss: 1.6784792790729053
Validation loss: 2.608265720135726

Epoch: 6| Step: 9
Training loss: 1.4280818406810099
Validation loss: 2.6070004808354255

Epoch: 6| Step: 10
Training loss: 1.3416922138380263
Validation loss: 2.5786738602297534

Epoch: 6| Step: 11
Training loss: 1.567051856730574
Validation loss: 2.5921042131102032

Epoch: 6| Step: 12
Training loss: 1.3102150964686228
Validation loss: 2.6002006924226153

Epoch: 6| Step: 13
Training loss: 1.601224016846823
Validation loss: 2.6005059903923002

Epoch: 407| Step: 0
Training loss: 1.2345682306789618
Validation loss: 2.6266624608570184

Epoch: 6| Step: 1
Training loss: 1.8372358560468
Validation loss: 2.6273054867462307

Epoch: 6| Step: 2
Training loss: 1.477737363025247
Validation loss: 2.683535345108016

Epoch: 6| Step: 3
Training loss: 1.450598211866997
Validation loss: 2.6489183189877115

Epoch: 6| Step: 4
Training loss: 2.0183124221529103
Validation loss: 2.6685133821800773

Epoch: 6| Step: 5
Training loss: 1.0111251916242652
Validation loss: 2.6580915732718533

Epoch: 6| Step: 6
Training loss: 1.6390545549372872
Validation loss: 2.633256704052219

Epoch: 6| Step: 7
Training loss: 1.27474459165603
Validation loss: 2.677970253476905

Epoch: 6| Step: 8
Training loss: 0.5897913018965146
Validation loss: 2.699082936878387

Epoch: 6| Step: 9
Training loss: 1.620282735523615
Validation loss: 2.7206769523447987

Epoch: 6| Step: 10
Training loss: 1.2732695954449833
Validation loss: 2.7107154769695505

Epoch: 6| Step: 11
Training loss: 1.1557963744408148
Validation loss: 2.6997734601454324

Epoch: 6| Step: 12
Training loss: 1.4025098441963346
Validation loss: 2.67393197723759

Epoch: 6| Step: 13
Training loss: 1.3731151580110565
Validation loss: 2.658351295305841

Epoch: 408| Step: 0
Training loss: 1.4061357663698981
Validation loss: 2.606715302308537

Epoch: 6| Step: 1
Training loss: 1.3382561177456485
Validation loss: 2.5986011988131867

Epoch: 6| Step: 2
Training loss: 1.3544401724027113
Validation loss: 2.612696343021009

Epoch: 6| Step: 3
Training loss: 1.4641946804179786
Validation loss: 2.6238437905270686

Epoch: 6| Step: 4
Training loss: 1.462592915900878
Validation loss: 2.5842500474931733

Epoch: 6| Step: 5
Training loss: 1.4597104064934234
Validation loss: 2.588410821579137

Epoch: 6| Step: 6
Training loss: 1.3446610932768153
Validation loss: 2.6201005969335758

Epoch: 6| Step: 7
Training loss: 1.321974842097624
Validation loss: 2.6082769437427404

Epoch: 6| Step: 8
Training loss: 1.407240285813116
Validation loss: 2.693605292900989

Epoch: 6| Step: 9
Training loss: 1.3367894896935901
Validation loss: 2.663181570066307

Epoch: 6| Step: 10
Training loss: 1.8000958311214166
Validation loss: 2.7306424337037334

Epoch: 6| Step: 11
Training loss: 1.346365047487111
Validation loss: 2.7461959522743546

Epoch: 6| Step: 12
Training loss: 1.4821275260513191
Validation loss: 2.7772274592685022

Epoch: 6| Step: 13
Training loss: 1.3206254035309999
Validation loss: 2.7430420254533354

Epoch: 409| Step: 0
Training loss: 1.0393048340860356
Validation loss: 2.693601456391316

Epoch: 6| Step: 1
Training loss: 1.300932775154853
Validation loss: 2.6270107531490767

Epoch: 6| Step: 2
Training loss: 1.6111413835918817
Validation loss: 2.599075091502483

Epoch: 6| Step: 3
Training loss: 1.8865480207513483
Validation loss: 2.5599434317535192

Epoch: 6| Step: 4
Training loss: 1.5606017216484354
Validation loss: 2.6313489749228567

Epoch: 6| Step: 5
Training loss: 1.3879897189872636
Validation loss: 2.588354660597746

Epoch: 6| Step: 6
Training loss: 1.0957482748538063
Validation loss: 2.5899033352830316

Epoch: 6| Step: 7
Training loss: 1.1961827818701107
Validation loss: 2.6149595374246597

Epoch: 6| Step: 8
Training loss: 1.6107931462758063
Validation loss: 2.6166700674170373

Epoch: 6| Step: 9
Training loss: 1.2271817338971698
Validation loss: 2.645004501793322

Epoch: 6| Step: 10
Training loss: 1.8405051692692116
Validation loss: 2.655916891619117

Epoch: 6| Step: 11
Training loss: 0.7243905366773407
Validation loss: 2.672388612346428

Epoch: 6| Step: 12
Training loss: 1.592211710228256
Validation loss: 2.697456066042166

Epoch: 6| Step: 13
Training loss: 1.1317011149748213
Validation loss: 2.686906532033667

Epoch: 410| Step: 0
Training loss: 1.7732861155961588
Validation loss: 2.6837542415534767

Epoch: 6| Step: 1
Training loss: 1.4849503857580029
Validation loss: 2.6526092015155838

Epoch: 6| Step: 2
Training loss: 1.1318542636970836
Validation loss: 2.6400163005618964

Epoch: 6| Step: 3
Training loss: 1.4225520942682495
Validation loss: 2.5709709877199227

Epoch: 6| Step: 4
Training loss: 1.363826609836455
Validation loss: 2.577395073612432

Epoch: 6| Step: 5
Training loss: 1.4318367900437374
Validation loss: 2.580750598054617

Epoch: 6| Step: 6
Training loss: 1.5965244602727342
Validation loss: 2.566641594811337

Epoch: 6| Step: 7
Training loss: 1.6959047469615154
Validation loss: 2.5893363202492856

Epoch: 6| Step: 8
Training loss: 1.579503958252442
Validation loss: 2.5865338331285734

Epoch: 6| Step: 9
Training loss: 0.8757530105761224
Validation loss: 2.604755141843151

Epoch: 6| Step: 10
Training loss: 1.2039984962922905
Validation loss: 2.6553811473395346

Epoch: 6| Step: 11
Training loss: 1.7632146265832112
Validation loss: 2.6579611606810696

Epoch: 6| Step: 12
Training loss: 1.1966764360062732
Validation loss: 2.7072589358684978

Epoch: 6| Step: 13
Training loss: 0.7590004173699841
Validation loss: 2.7110214227500906

Epoch: 411| Step: 0
Training loss: 1.9323541540305496
Validation loss: 2.7122234025207415

Epoch: 6| Step: 1
Training loss: 1.8997263359948358
Validation loss: 2.697285634941031

Epoch: 6| Step: 2
Training loss: 1.4609592048542255
Validation loss: 2.662135254832062

Epoch: 6| Step: 3
Training loss: 1.4747830118176033
Validation loss: 2.6569902531041145

Epoch: 6| Step: 4
Training loss: 1.3735271715351811
Validation loss: 2.6464489524313337

Epoch: 6| Step: 5
Training loss: 0.9318230088567785
Validation loss: 2.6195143089210147

Epoch: 6| Step: 6
Training loss: 0.9914911785377746
Validation loss: 2.60828961017248

Epoch: 6| Step: 7
Training loss: 0.9645539748225961
Validation loss: 2.613229527988522

Epoch: 6| Step: 8
Training loss: 1.3625175719921658
Validation loss: 2.608586841293978

Epoch: 6| Step: 9
Training loss: 1.3311692298420938
Validation loss: 2.6106229355719623

Epoch: 6| Step: 10
Training loss: 1.8613539350707575
Validation loss: 2.610641477694578

Epoch: 6| Step: 11
Training loss: 1.1546958582347189
Validation loss: 2.6449466259808885

Epoch: 6| Step: 12
Training loss: 1.302567547091873
Validation loss: 2.6561170647284014

Epoch: 6| Step: 13
Training loss: 1.1679526235430375
Validation loss: 2.6858960263776055

Epoch: 412| Step: 0
Training loss: 1.3217189002248353
Validation loss: 2.7099311258334935

Epoch: 6| Step: 1
Training loss: 1.6638973673521515
Validation loss: 2.706031885105534

Epoch: 6| Step: 2
Training loss: 1.5403885139504652
Validation loss: 2.690316153972806

Epoch: 6| Step: 3
Training loss: 1.242299008912575
Validation loss: 2.6631519904132293

Epoch: 6| Step: 4
Training loss: 1.2476001590739665
Validation loss: 2.657971577411389

Epoch: 6| Step: 5
Training loss: 1.4015661437328524
Validation loss: 2.6231888374296592

Epoch: 6| Step: 6
Training loss: 1.3107552966691673
Validation loss: 2.6292013015469244

Epoch: 6| Step: 7
Training loss: 1.2738176492203548
Validation loss: 2.6008060055950395

Epoch: 6| Step: 8
Training loss: 0.9169091785303923
Validation loss: 2.6114826698304245

Epoch: 6| Step: 9
Training loss: 1.220515415255265
Validation loss: 2.6364480365558536

Epoch: 6| Step: 10
Training loss: 1.3571257563280843
Validation loss: 2.644603659246712

Epoch: 6| Step: 11
Training loss: 2.0885186959110915
Validation loss: 2.6511694774202463

Epoch: 6| Step: 12
Training loss: 1.4919872848643925
Validation loss: 2.712845278576318

Epoch: 6| Step: 13
Training loss: 1.2355856933670692
Validation loss: 2.6990865091458107

Epoch: 413| Step: 0
Training loss: 1.6102453304342108
Validation loss: 2.710775217015528

Epoch: 6| Step: 1
Training loss: 1.3391707261994668
Validation loss: 2.660543364726778

Epoch: 6| Step: 2
Training loss: 1.2755474560805737
Validation loss: 2.660275249654368

Epoch: 6| Step: 3
Training loss: 1.6790010690873123
Validation loss: 2.620163918596257

Epoch: 6| Step: 4
Training loss: 0.9136151254161794
Validation loss: 2.603349119428477

Epoch: 6| Step: 5
Training loss: 1.1096646642631538
Validation loss: 2.6040927376046468

Epoch: 6| Step: 6
Training loss: 1.6557443674675119
Validation loss: 2.6067115346111733

Epoch: 6| Step: 7
Training loss: 1.14137619574299
Validation loss: 2.60513200025938

Epoch: 6| Step: 8
Training loss: 1.414837703765639
Validation loss: 2.606508190859487

Epoch: 6| Step: 9
Training loss: 1.444186044875921
Validation loss: 2.621931191525887

Epoch: 6| Step: 10
Training loss: 1.6014684137760151
Validation loss: 2.666135811713822

Epoch: 6| Step: 11
Training loss: 1.9416775120553704
Validation loss: 2.672778608305959

Epoch: 6| Step: 12
Training loss: 1.0101786788728053
Validation loss: 2.695100275345648

Epoch: 6| Step: 13
Training loss: 0.8458336075342294
Validation loss: 2.6818925614187004

Epoch: 414| Step: 0
Training loss: 1.6285219905634616
Validation loss: 2.74570449831098

Epoch: 6| Step: 1
Training loss: 1.6152418290949904
Validation loss: 2.6955174607598122

Epoch: 6| Step: 2
Training loss: 1.4884728335924622
Validation loss: 2.6787014340495485

Epoch: 6| Step: 3
Training loss: 1.3636536185299974
Validation loss: 2.6592304897519607

Epoch: 6| Step: 4
Training loss: 1.410740401145272
Validation loss: 2.676875575655213

Epoch: 6| Step: 5
Training loss: 1.921834929754088
Validation loss: 2.627844639850294

Epoch: 6| Step: 6
Training loss: 1.1316496043166688
Validation loss: 2.6122935390991637

Epoch: 6| Step: 7
Training loss: 1.4189395996314798
Validation loss: 2.5962057258922497

Epoch: 6| Step: 8
Training loss: 1.0892621200829296
Validation loss: 2.6402556439020453

Epoch: 6| Step: 9
Training loss: 1.460023808481145
Validation loss: 2.628476654718149

Epoch: 6| Step: 10
Training loss: 1.39058642387462
Validation loss: 2.6094056451196708

Epoch: 6| Step: 11
Training loss: 1.5299797238770367
Validation loss: 2.611517409050233

Epoch: 6| Step: 12
Training loss: 0.717840946681764
Validation loss: 2.6102295811642797

Epoch: 6| Step: 13
Training loss: 0.6182049923042665
Validation loss: 2.64463366059066

Epoch: 415| Step: 0
Training loss: 0.9553937020074074
Validation loss: 2.6761055439877173

Epoch: 6| Step: 1
Training loss: 1.1089571313578597
Validation loss: 2.6336731972803875

Epoch: 6| Step: 2
Training loss: 1.4863553940706475
Validation loss: 2.649275878102945

Epoch: 6| Step: 3
Training loss: 0.769132210533879
Validation loss: 2.6255510350510125

Epoch: 6| Step: 4
Training loss: 1.2898644929138705
Validation loss: 2.6220814408422317

Epoch: 6| Step: 5
Training loss: 1.5891443912256495
Validation loss: 2.617820814704281

Epoch: 6| Step: 6
Training loss: 1.3734879850064108
Validation loss: 2.6307068857381775

Epoch: 6| Step: 7
Training loss: 1.1252997316983055
Validation loss: 2.6352655660171247

Epoch: 6| Step: 8
Training loss: 1.3717438550407883
Validation loss: 2.65229744476373

Epoch: 6| Step: 9
Training loss: 2.0281917143724417
Validation loss: 2.6965894121517437

Epoch: 6| Step: 10
Training loss: 1.3116898079656112
Validation loss: 2.6900071518715984

Epoch: 6| Step: 11
Training loss: 1.4132462142388873
Validation loss: 2.6725155486480845

Epoch: 6| Step: 12
Training loss: 1.118103771999729
Validation loss: 2.712905903472599

Epoch: 6| Step: 13
Training loss: 2.1600453243092073
Validation loss: 2.679891009761597

Epoch: 416| Step: 0
Training loss: 1.8851784683859552
Validation loss: 2.6523303486574292

Epoch: 6| Step: 1
Training loss: 1.2567952467371404
Validation loss: 2.602965562684165

Epoch: 6| Step: 2
Training loss: 1.2189734816448006
Validation loss: 2.5816551623284085

Epoch: 6| Step: 3
Training loss: 1.420873268140481
Validation loss: 2.5960976593485943

Epoch: 6| Step: 4
Training loss: 1.540698348769559
Validation loss: 2.5762083504461986

Epoch: 6| Step: 5
Training loss: 1.4624185653576525
Validation loss: 2.5977419455184436

Epoch: 6| Step: 6
Training loss: 1.2524071404303798
Validation loss: 2.657643996065917

Epoch: 6| Step: 7
Training loss: 1.486244309577283
Validation loss: 2.7079959551969637

Epoch: 6| Step: 8
Training loss: 1.5719427499902234
Validation loss: 2.714690461356828

Epoch: 6| Step: 9
Training loss: 0.9928125830420056
Validation loss: 2.774132773639153

Epoch: 6| Step: 10
Training loss: 1.215476947388503
Validation loss: 2.733119812220657

Epoch: 6| Step: 11
Training loss: 1.2774679607696025
Validation loss: 2.727265271838213

Epoch: 6| Step: 12
Training loss: 1.2297643673827774
Validation loss: 2.6788259906975163

Epoch: 6| Step: 13
Training loss: 1.553173535699627
Validation loss: 2.6403580717745774

Epoch: 417| Step: 0
Training loss: 0.898392518617522
Validation loss: 2.5856693957755663

Epoch: 6| Step: 1
Training loss: 1.6459495970145852
Validation loss: 2.5476678363752567

Epoch: 6| Step: 2
Training loss: 2.110167290984571
Validation loss: 2.6180501026613117

Epoch: 6| Step: 3
Training loss: 1.2634178035917079
Validation loss: 2.626296559672077

Epoch: 6| Step: 4
Training loss: 1.3988425238368116
Validation loss: 2.627215525250517

Epoch: 6| Step: 5
Training loss: 1.2927098778595818
Validation loss: 2.602581751420466

Epoch: 6| Step: 6
Training loss: 1.4899102854761759
Validation loss: 2.644992436682888

Epoch: 6| Step: 7
Training loss: 1.2390693058245514
Validation loss: 2.701234551819992

Epoch: 6| Step: 8
Training loss: 1.1154971907036124
Validation loss: 2.685223478741125

Epoch: 6| Step: 9
Training loss: 1.2123034740728935
Validation loss: 2.695296109770759

Epoch: 6| Step: 10
Training loss: 1.173058433615501
Validation loss: 2.6925940259761543

Epoch: 6| Step: 11
Training loss: 1.1238693807837152
Validation loss: 2.6831030585628186

Epoch: 6| Step: 12
Training loss: 1.4959025049110717
Validation loss: 2.7038092125754263

Epoch: 6| Step: 13
Training loss: 1.2630458973498373
Validation loss: 2.65657188207327

Epoch: 418| Step: 0
Training loss: 1.344625321000513
Validation loss: 2.6845336744922954

Epoch: 6| Step: 1
Training loss: 1.1330772353645049
Validation loss: 2.6470636212863563

Epoch: 6| Step: 2
Training loss: 1.6928001809266107
Validation loss: 2.6323972418180235

Epoch: 6| Step: 3
Training loss: 1.1406812784603095
Validation loss: 2.6343829064772466

Epoch: 6| Step: 4
Training loss: 1.2660140393278696
Validation loss: 2.6551245045199767

Epoch: 6| Step: 5
Training loss: 1.7192522875565508
Validation loss: 2.6306385290747922

Epoch: 6| Step: 6
Training loss: 1.0705445866357448
Validation loss: 2.6296381067972274

Epoch: 6| Step: 7
Training loss: 1.3685219491990084
Validation loss: 2.604060608375639

Epoch: 6| Step: 8
Training loss: 1.513759763073485
Validation loss: 2.6296229479953253

Epoch: 6| Step: 9
Training loss: 1.3599045697558243
Validation loss: 2.63548392503828

Epoch: 6| Step: 10
Training loss: 1.3428599048864374
Validation loss: 2.609451759491005

Epoch: 6| Step: 11
Training loss: 1.1226221492209967
Validation loss: 2.6144488181206333

Epoch: 6| Step: 12
Training loss: 1.2890860815492196
Validation loss: 2.6160602334250567

Epoch: 6| Step: 13
Training loss: 1.7880678702024477
Validation loss: 2.6203630680044787

Epoch: 419| Step: 0
Training loss: 1.456541250025176
Validation loss: 2.6154789404106227

Epoch: 6| Step: 1
Training loss: 1.014745419432007
Validation loss: 2.6526990411474904

Epoch: 6| Step: 2
Training loss: 1.148632422273463
Validation loss: 2.700376231309359

Epoch: 6| Step: 3
Training loss: 1.1013075080257497
Validation loss: 2.6843691936049403

Epoch: 6| Step: 4
Training loss: 1.2755251195775086
Validation loss: 2.68605914343067

Epoch: 6| Step: 5
Training loss: 1.4133004089710084
Validation loss: 2.7162191218505427

Epoch: 6| Step: 6
Training loss: 1.550153167909185
Validation loss: 2.68462503843487

Epoch: 6| Step: 7
Training loss: 1.273582871453442
Validation loss: 2.681285058461232

Epoch: 6| Step: 8
Training loss: 1.6544407013001863
Validation loss: 2.6837640538038166

Epoch: 6| Step: 9
Training loss: 1.5175686201389524
Validation loss: 2.662762588045581

Epoch: 6| Step: 10
Training loss: 1.3916330434350361
Validation loss: 2.6558378687674478

Epoch: 6| Step: 11
Training loss: 1.7396553694682326
Validation loss: 2.5976184621093754

Epoch: 6| Step: 12
Training loss: 0.8627889619053112
Validation loss: 2.6206269948436263

Epoch: 6| Step: 13
Training loss: 1.2974642598369326
Validation loss: 2.6059781648243368

Epoch: 420| Step: 0
Training loss: 1.4483116580817634
Validation loss: 2.6122410084895766

Epoch: 6| Step: 1
Training loss: 1.8245449387171688
Validation loss: 2.623131948220063

Epoch: 6| Step: 2
Training loss: 1.79432683302734
Validation loss: 2.6493183200315276

Epoch: 6| Step: 3
Training loss: 1.311888961245182
Validation loss: 2.679525090551833

Epoch: 6| Step: 4
Training loss: 1.0005488081831704
Validation loss: 2.670870210315792

Epoch: 6| Step: 5
Training loss: 0.8377092071682967
Validation loss: 2.6858211041867484

Epoch: 6| Step: 6
Training loss: 1.1528716349150918
Validation loss: 2.686056200938347

Epoch: 6| Step: 7
Training loss: 1.2036425975765421
Validation loss: 2.69358591423594

Epoch: 6| Step: 8
Training loss: 1.080692109847632
Validation loss: 2.673620306783253

Epoch: 6| Step: 9
Training loss: 1.8731333659929996
Validation loss: 2.7020102990894013

Epoch: 6| Step: 10
Training loss: 1.2577632159890497
Validation loss: 2.6610204471566608

Epoch: 6| Step: 11
Training loss: 1.3337791363180165
Validation loss: 2.688510681839106

Epoch: 6| Step: 12
Training loss: 1.1651014261749237
Validation loss: 2.672455047355523

Epoch: 6| Step: 13
Training loss: 0.5308132901093192
Validation loss: 2.675269775273317

Epoch: 421| Step: 0
Training loss: 1.13526377683881
Validation loss: 2.6167092878346505

Epoch: 6| Step: 1
Training loss: 1.5495699131996448
Validation loss: 2.5957327147612186

Epoch: 6| Step: 2
Training loss: 1.678277848029571
Validation loss: 2.600154095024227

Epoch: 6| Step: 3
Training loss: 1.0429508050524932
Validation loss: 2.5651924840600997

Epoch: 6| Step: 4
Training loss: 1.321902294192786
Validation loss: 2.5474332077816997

Epoch: 6| Step: 5
Training loss: 0.7416301039637931
Validation loss: 2.537783573667747

Epoch: 6| Step: 6
Training loss: 1.1677111083152845
Validation loss: 2.5937100212296578

Epoch: 6| Step: 7
Training loss: 1.0941407186990935
Validation loss: 2.5880882787343586

Epoch: 6| Step: 8
Training loss: 1.959389246351904
Validation loss: 2.611178849399888

Epoch: 6| Step: 9
Training loss: 1.0742944309278113
Validation loss: 2.655877612152147

Epoch: 6| Step: 10
Training loss: 1.4043753102008933
Validation loss: 2.6684492277885745

Epoch: 6| Step: 11
Training loss: 1.4090979665428467
Validation loss: 2.709175419739182

Epoch: 6| Step: 12
Training loss: 1.4784998218896195
Validation loss: 2.7253581346930718

Epoch: 6| Step: 13
Training loss: 1.2936689434367308
Validation loss: 2.7132535722506526

Epoch: 422| Step: 0
Training loss: 1.232946559255279
Validation loss: 2.6889765251740734

Epoch: 6| Step: 1
Training loss: 1.4908508385614423
Validation loss: 2.6945730570936615

Epoch: 6| Step: 2
Training loss: 1.1709987161565791
Validation loss: 2.6497665522823683

Epoch: 6| Step: 3
Training loss: 1.7279787770884205
Validation loss: 2.627940986136395

Epoch: 6| Step: 4
Training loss: 1.198195328297531
Validation loss: 2.6428005787381332

Epoch: 6| Step: 5
Training loss: 0.8645099164439254
Validation loss: 2.656266127361872

Epoch: 6| Step: 6
Training loss: 1.8404186994549878
Validation loss: 2.640627419347517

Epoch: 6| Step: 7
Training loss: 1.537193596555032
Validation loss: 2.6451406172000307

Epoch: 6| Step: 8
Training loss: 0.949306468285698
Validation loss: 2.668890956656558

Epoch: 6| Step: 9
Training loss: 0.9685194294860858
Validation loss: 2.650541622993623

Epoch: 6| Step: 10
Training loss: 1.3314649882911551
Validation loss: 2.6968690034768796

Epoch: 6| Step: 11
Training loss: 1.2457781544504205
Validation loss: 2.7045723708520613

Epoch: 6| Step: 12
Training loss: 1.588261297112819
Validation loss: 2.6791638273091625

Epoch: 6| Step: 13
Training loss: 1.0881421330925563
Validation loss: 2.6921667887845335

Epoch: 423| Step: 0
Training loss: 1.1400321569424763
Validation loss: 2.673300412236966

Epoch: 6| Step: 1
Training loss: 1.6053618235378142
Validation loss: 2.697388035650536

Epoch: 6| Step: 2
Training loss: 1.1439889918711363
Validation loss: 2.675978467580739

Epoch: 6| Step: 3
Training loss: 0.9966282924921626
Validation loss: 2.6496982262943436

Epoch: 6| Step: 4
Training loss: 1.1935622921506173
Validation loss: 2.6679143089178994

Epoch: 6| Step: 5
Training loss: 1.3188438147129122
Validation loss: 2.644419256293852

Epoch: 6| Step: 6
Training loss: 1.6471044565138315
Validation loss: 2.630000808864173

Epoch: 6| Step: 7
Training loss: 1.2680680043970964
Validation loss: 2.5973471412677736

Epoch: 6| Step: 8
Training loss: 1.058953199557395
Validation loss: 2.6414244251690073

Epoch: 6| Step: 9
Training loss: 1.8787209782290946
Validation loss: 2.662517641101401

Epoch: 6| Step: 10
Training loss: 0.8161926720248881
Validation loss: 2.640076767427414

Epoch: 6| Step: 11
Training loss: 1.3051046287131265
Validation loss: 2.662536206967642

Epoch: 6| Step: 12
Training loss: 1.365729595517207
Validation loss: 2.6651546202945235

Epoch: 6| Step: 13
Training loss: 1.4206829733542978
Validation loss: 2.6547643214018595

Epoch: 424| Step: 0
Training loss: 1.4764017491913435
Validation loss: 2.6626498991323957

Epoch: 6| Step: 1
Training loss: 1.0448606669244602
Validation loss: 2.6392344957841156

Epoch: 6| Step: 2
Training loss: 1.2393634291208284
Validation loss: 2.617323846009693

Epoch: 6| Step: 3
Training loss: 1.7086632650333817
Validation loss: 2.6339417772459375

Epoch: 6| Step: 4
Training loss: 1.5615638980550044
Validation loss: 2.6148985534746867

Epoch: 6| Step: 5
Training loss: 0.9709232318715034
Validation loss: 2.567924022362096

Epoch: 6| Step: 6
Training loss: 1.243646975903708
Validation loss: 2.590191088305925

Epoch: 6| Step: 7
Training loss: 0.7851409910626643
Validation loss: 2.6067718485860487

Epoch: 6| Step: 8
Training loss: 1.4863202649985177
Validation loss: 2.6492842755818033

Epoch: 6| Step: 9
Training loss: 1.4854689732883744
Validation loss: 2.6378601564313695

Epoch: 6| Step: 10
Training loss: 1.5861013543934357
Validation loss: 2.6989020814555196

Epoch: 6| Step: 11
Training loss: 1.120360077894473
Validation loss: 2.7418053604432098

Epoch: 6| Step: 12
Training loss: 1.1633874356679166
Validation loss: 2.7329561354675156

Epoch: 6| Step: 13
Training loss: 1.346908450319763
Validation loss: 2.6849171770611546

Epoch: 425| Step: 0
Training loss: 1.234128130599419
Validation loss: 2.675715158183869

Epoch: 6| Step: 1
Training loss: 1.2693401016704708
Validation loss: 2.641626463144495

Epoch: 6| Step: 2
Training loss: 1.463351371946502
Validation loss: 2.6095488546055767

Epoch: 6| Step: 3
Training loss: 1.2250671504553108
Validation loss: 2.598604229481934

Epoch: 6| Step: 4
Training loss: 0.970812724198964
Validation loss: 2.614376945538714

Epoch: 6| Step: 5
Training loss: 1.076489687202691
Validation loss: 2.643589449170204

Epoch: 6| Step: 6
Training loss: 1.158805806154579
Validation loss: 2.651723818937651

Epoch: 6| Step: 7
Training loss: 1.5328210828503892
Validation loss: 2.6694232423952293

Epoch: 6| Step: 8
Training loss: 1.478381696352215
Validation loss: 2.674201760591843

Epoch: 6| Step: 9
Training loss: 1.5787684573486211
Validation loss: 2.6940247053332462

Epoch: 6| Step: 10
Training loss: 0.9246392268207616
Validation loss: 2.6956007508615984

Epoch: 6| Step: 11
Training loss: 1.4077976611304794
Validation loss: 2.713036280115089

Epoch: 6| Step: 12
Training loss: 1.4178058120808588
Validation loss: 2.6634786979771654

Epoch: 6| Step: 13
Training loss: 1.633925720081328
Validation loss: 2.6688201314102242

Epoch: 426| Step: 0
Training loss: 1.3604025191096711
Validation loss: 2.6162137606074873

Epoch: 6| Step: 1
Training loss: 0.9190266134395535
Validation loss: 2.597614258815297

Epoch: 6| Step: 2
Training loss: 1.295644705107762
Validation loss: 2.579876809883095

Epoch: 6| Step: 3
Training loss: 1.6130281485355857
Validation loss: 2.5586546070833593

Epoch: 6| Step: 4
Training loss: 1.314672669983776
Validation loss: 2.6074668328268173

Epoch: 6| Step: 5
Training loss: 1.4269128776532216
Validation loss: 2.6391893457226745

Epoch: 6| Step: 6
Training loss: 1.8942378809987912
Validation loss: 2.6770188502714247

Epoch: 6| Step: 7
Training loss: 1.193719737682924
Validation loss: 2.729395409599572

Epoch: 6| Step: 8
Training loss: 1.563678983300067
Validation loss: 2.719108317478943

Epoch: 6| Step: 9
Training loss: 1.1217357113367912
Validation loss: 2.7567699197320605

Epoch: 6| Step: 10
Training loss: 1.4189532936748614
Validation loss: 2.768978754386855

Epoch: 6| Step: 11
Training loss: 0.6135061787012012
Validation loss: 2.79443077500711

Epoch: 6| Step: 12
Training loss: 1.2364405479962424
Validation loss: 2.744642048871618

Epoch: 6| Step: 13
Training loss: 1.0609503833735723
Validation loss: 2.740915655192861

Epoch: 427| Step: 0
Training loss: 1.517985128568597
Validation loss: 2.7270610379524953

Epoch: 6| Step: 1
Training loss: 1.160761973690444
Validation loss: 2.722695071702093

Epoch: 6| Step: 2
Training loss: 1.5016361690872104
Validation loss: 2.6767764357084625

Epoch: 6| Step: 3
Training loss: 1.1740402563169454
Validation loss: 2.637744563341113

Epoch: 6| Step: 4
Training loss: 1.2317178834444893
Validation loss: 2.5931926730946997

Epoch: 6| Step: 5
Training loss: 1.098046827231467
Validation loss: 2.61210237195157

Epoch: 6| Step: 6
Training loss: 1.2072442616768508
Validation loss: 2.589298027773488

Epoch: 6| Step: 7
Training loss: 1.2819916509246332
Validation loss: 2.589543295357323

Epoch: 6| Step: 8
Training loss: 1.2542247902380306
Validation loss: 2.6369060597795495

Epoch: 6| Step: 9
Training loss: 1.7785632299079956
Validation loss: 2.63283246522285

Epoch: 6| Step: 10
Training loss: 1.1410376964864752
Validation loss: 2.7163657314904284

Epoch: 6| Step: 11
Training loss: 1.6670096362406954
Validation loss: 2.6973406760075607

Epoch: 6| Step: 12
Training loss: 1.2105854137843322
Validation loss: 2.6813237811981847

Epoch: 6| Step: 13
Training loss: 0.4971809938485825
Validation loss: 2.7240482106011457

Epoch: 428| Step: 0
Training loss: 1.0473277123731604
Validation loss: 2.702518055230864

Epoch: 6| Step: 1
Training loss: 1.45001371640262
Validation loss: 2.7165354647631164

Epoch: 6| Step: 2
Training loss: 1.3676457972101501
Validation loss: 2.7109576705017213

Epoch: 6| Step: 3
Training loss: 1.4169901684168937
Validation loss: 2.6736664325807955

Epoch: 6| Step: 4
Training loss: 1.051136509850794
Validation loss: 2.6851939375854217

Epoch: 6| Step: 5
Training loss: 1.2849353264144978
Validation loss: 2.6703176075137023

Epoch: 6| Step: 6
Training loss: 0.9324673357501905
Validation loss: 2.649439123882199

Epoch: 6| Step: 7
Training loss: 0.9552191881722986
Validation loss: 2.6870961402128386

Epoch: 6| Step: 8
Training loss: 1.5562500888563997
Validation loss: 2.642300783661977

Epoch: 6| Step: 9
Training loss: 1.6715666584641382
Validation loss: 2.661606837089433

Epoch: 6| Step: 10
Training loss: 1.3132145162915883
Validation loss: 2.6711829540843497

Epoch: 6| Step: 11
Training loss: 1.2334617423320242
Validation loss: 2.6524241489012925

Epoch: 6| Step: 12
Training loss: 1.6375179115072915
Validation loss: 2.6973581886226428

Epoch: 6| Step: 13
Training loss: 0.5493415250333312
Validation loss: 2.6710676321379645

Epoch: 429| Step: 0
Training loss: 1.3154003250481272
Validation loss: 2.6907241647326843

Epoch: 6| Step: 1
Training loss: 1.379730324172371
Validation loss: 2.6664886344680263

Epoch: 6| Step: 2
Training loss: 1.3352372414458447
Validation loss: 2.6468090815823504

Epoch: 6| Step: 3
Training loss: 1.2578092776429026
Validation loss: 2.672943634581841

Epoch: 6| Step: 4
Training loss: 1.5075283276883917
Validation loss: 2.6938805089543254

Epoch: 6| Step: 5
Training loss: 0.9684737026837213
Validation loss: 2.64186343550408

Epoch: 6| Step: 6
Training loss: 1.909587252692836
Validation loss: 2.69488485569113

Epoch: 6| Step: 7
Training loss: 1.0070397423267003
Validation loss: 2.660257054927131

Epoch: 6| Step: 8
Training loss: 1.307181162425525
Validation loss: 2.6423683515859357

Epoch: 6| Step: 9
Training loss: 1.0734126725303303
Validation loss: 2.626856762976346

Epoch: 6| Step: 10
Training loss: 1.0112622973020908
Validation loss: 2.6422286897060703

Epoch: 6| Step: 11
Training loss: 1.2703885983504364
Validation loss: 2.6119917585438923

Epoch: 6| Step: 12
Training loss: 1.396866069995575
Validation loss: 2.6261077375707833

Epoch: 6| Step: 13
Training loss: 0.7260740135207974
Validation loss: 2.6165208379165135

Epoch: 430| Step: 0
Training loss: 1.228266025046566
Validation loss: 2.614873535565446

Epoch: 6| Step: 1
Training loss: 1.3156407787980595
Validation loss: 2.627114811831537

Epoch: 6| Step: 2
Training loss: 1.1232238099411123
Validation loss: 2.661879465453886

Epoch: 6| Step: 3
Training loss: 1.568806851637301
Validation loss: 2.6544804700808586

Epoch: 6| Step: 4
Training loss: 1.5182408048293836
Validation loss: 2.65634464527198

Epoch: 6| Step: 5
Training loss: 1.0183988984182173
Validation loss: 2.651051372098758

Epoch: 6| Step: 6
Training loss: 1.3620894942324686
Validation loss: 2.636185209375823

Epoch: 6| Step: 7
Training loss: 1.757658277739838
Validation loss: 2.571318511472087

Epoch: 6| Step: 8
Training loss: 1.2127060312051465
Validation loss: 2.615525619115103

Epoch: 6| Step: 9
Training loss: 1.3532836186778392
Validation loss: 2.5821865591647755

Epoch: 6| Step: 10
Training loss: 0.9219145038998549
Validation loss: 2.58182350486978

Epoch: 6| Step: 11
Training loss: 1.3481715005168697
Validation loss: 2.5994497082066337

Epoch: 6| Step: 12
Training loss: 0.7529313895160521
Validation loss: 2.679130113313062

Epoch: 6| Step: 13
Training loss: 1.209822405873549
Validation loss: 2.6840319778027535

Epoch: 431| Step: 0
Training loss: 0.9213089255609146
Validation loss: 2.6746114896262485

Epoch: 6| Step: 1
Training loss: 1.0210460648788644
Validation loss: 2.697316221264726

Epoch: 6| Step: 2
Training loss: 1.321660679606811
Validation loss: 2.7225585737309634

Epoch: 6| Step: 3
Training loss: 1.4307539667517453
Validation loss: 2.635523359622886

Epoch: 6| Step: 4
Training loss: 0.9429632583369759
Validation loss: 2.663444119368468

Epoch: 6| Step: 5
Training loss: 1.3418839383371741
Validation loss: 2.599117564097509

Epoch: 6| Step: 6
Training loss: 1.1504945044255708
Validation loss: 2.594194324012968

Epoch: 6| Step: 7
Training loss: 1.1136005144594912
Validation loss: 2.6287753086830916

Epoch: 6| Step: 8
Training loss: 1.3284663042325624
Validation loss: 2.6524856000019974

Epoch: 6| Step: 9
Training loss: 1.6508219319000716
Validation loss: 2.6422113404853613

Epoch: 6| Step: 10
Training loss: 1.5202200537054602
Validation loss: 2.7084393394555395

Epoch: 6| Step: 11
Training loss: 1.0084495009874666
Validation loss: 2.7210129487970875

Epoch: 6| Step: 12
Training loss: 1.5179249724290815
Validation loss: 2.694507427160988

Epoch: 6| Step: 13
Training loss: 1.6703848927496163
Validation loss: 2.7147661317376848

Epoch: 432| Step: 0
Training loss: 1.787131120726646
Validation loss: 2.662187840943635

Epoch: 6| Step: 1
Training loss: 1.5229431915408547
Validation loss: 2.6210918036191204

Epoch: 6| Step: 2
Training loss: 1.4353806172325527
Validation loss: 2.66166272384057

Epoch: 6| Step: 3
Training loss: 1.1872655737524769
Validation loss: 2.627397026826986

Epoch: 6| Step: 4
Training loss: 1.0961321910335595
Validation loss: 2.646686652448437

Epoch: 6| Step: 5
Training loss: 1.660015863204903
Validation loss: 2.650158379346112

Epoch: 6| Step: 6
Training loss: 0.8756371630546106
Validation loss: 2.6521067319733125

Epoch: 6| Step: 7
Training loss: 1.2488210840775475
Validation loss: 2.6858765720457343

Epoch: 6| Step: 8
Training loss: 0.4936677230416474
Validation loss: 2.6404229164647335

Epoch: 6| Step: 9
Training loss: 1.4030012964037386
Validation loss: 2.7120066337784423

Epoch: 6| Step: 10
Training loss: 1.3989742676752248
Validation loss: 2.724295559962981

Epoch: 6| Step: 11
Training loss: 1.122489671553436
Validation loss: 2.7200743632402893

Epoch: 6| Step: 12
Training loss: 1.0783474457734632
Validation loss: 2.6864603353921845

Epoch: 6| Step: 13
Training loss: 0.8623710425347325
Validation loss: 2.7422650068031906

Epoch: 433| Step: 0
Training loss: 1.2266097818968276
Validation loss: 2.6330543441800858

Epoch: 6| Step: 1
Training loss: 1.4129373700353658
Validation loss: 2.569013817374649

Epoch: 6| Step: 2
Training loss: 1.455824283046938
Validation loss: 2.5699016822352685

Epoch: 6| Step: 3
Training loss: 1.4803724433756382
Validation loss: 2.474790365117019

Epoch: 6| Step: 4
Training loss: 1.6621661776060597
Validation loss: 2.4788216936584972

Epoch: 6| Step: 5
Training loss: 1.037664807110166
Validation loss: 2.4845502134670934

Epoch: 6| Step: 6
Training loss: 1.2466152618557234
Validation loss: 2.595388376124325

Epoch: 6| Step: 7
Training loss: 1.665696608845232
Validation loss: 2.6768927729980545

Epoch: 6| Step: 8
Training loss: 0.6019571669317221
Validation loss: 2.7802550197692226

Epoch: 6| Step: 9
Training loss: 1.5534374636563941
Validation loss: 2.8289566915627584

Epoch: 6| Step: 10
Training loss: 1.1025733368025703
Validation loss: 2.8214188749349267

Epoch: 6| Step: 11
Training loss: 1.3915497351916981
Validation loss: 2.771498561786023

Epoch: 6| Step: 12
Training loss: 0.9965851413168032
Validation loss: 2.6921620798585923

Epoch: 6| Step: 13
Training loss: 1.5426479344089281
Validation loss: 2.594226584328784

Epoch: 434| Step: 0
Training loss: 0.7846281258723024
Validation loss: 2.540887936928948

Epoch: 6| Step: 1
Training loss: 1.3306965335594683
Validation loss: 2.5020369353126717

Epoch: 6| Step: 2
Training loss: 1.0992823600664756
Validation loss: 2.5526453728212704

Epoch: 6| Step: 3
Training loss: 1.546822672257486
Validation loss: 2.559387871845118

Epoch: 6| Step: 4
Training loss: 1.2322475594209852
Validation loss: 2.58922307630606

Epoch: 6| Step: 5
Training loss: 1.4586725476255078
Validation loss: 2.669759008795606

Epoch: 6| Step: 6
Training loss: 1.7689127062041277
Validation loss: 2.6383047339939627

Epoch: 6| Step: 7
Training loss: 1.4864890052858424
Validation loss: 2.669624405000632

Epoch: 6| Step: 8
Training loss: 1.349067634464944
Validation loss: 2.6648094595900855

Epoch: 6| Step: 9
Training loss: 1.1392001828888683
Validation loss: 2.6796367048136296

Epoch: 6| Step: 10
Training loss: 1.187103004350605
Validation loss: 2.650719154958263

Epoch: 6| Step: 11
Training loss: 0.6194973468523579
Validation loss: 2.637706847274465

Epoch: 6| Step: 12
Training loss: 1.4068588210488557
Validation loss: 2.619864466443896

Epoch: 6| Step: 13
Training loss: 1.4456016457498173
Validation loss: 2.55615556164733

Epoch: 435| Step: 0
Training loss: 1.2439363272952302
Validation loss: 2.551547223743127

Epoch: 6| Step: 1
Training loss: 1.5075340211486619
Validation loss: 2.4942306962389127

Epoch: 6| Step: 2
Training loss: 1.590577502187903
Validation loss: 2.5130314533396683

Epoch: 6| Step: 3
Training loss: 1.357874557429026
Validation loss: 2.5323297508621176

Epoch: 6| Step: 4
Training loss: 1.6956691103188302
Validation loss: 2.5593460666546046

Epoch: 6| Step: 5
Training loss: 1.180749326897566
Validation loss: 2.5848524712558345

Epoch: 6| Step: 6
Training loss: 1.3418711457110533
Validation loss: 2.660641107304128

Epoch: 6| Step: 7
Training loss: 1.430014150856267
Validation loss: 2.700552943984888

Epoch: 6| Step: 8
Training loss: 1.0897565690586677
Validation loss: 2.684753453978497

Epoch: 6| Step: 9
Training loss: 1.1240606624958376
Validation loss: 2.696722822123959

Epoch: 6| Step: 10
Training loss: 1.1106178950660495
Validation loss: 2.696915335267966

Epoch: 6| Step: 11
Training loss: 1.0431852080361286
Validation loss: 2.6889487146731823

Epoch: 6| Step: 12
Training loss: 0.49910136769573
Validation loss: 2.668633166284567

Epoch: 6| Step: 13
Training loss: 1.106055329861691
Validation loss: 2.6723553405006877

Epoch: 436| Step: 0
Training loss: 1.4346095340111482
Validation loss: 2.66530835226979

Epoch: 6| Step: 1
Training loss: 1.3314798058250854
Validation loss: 2.6362358732161106

Epoch: 6| Step: 2
Training loss: 1.3318891253677798
Validation loss: 2.5969632977702846

Epoch: 6| Step: 3
Training loss: 1.2275019649948273
Validation loss: 2.5846602475288907

Epoch: 6| Step: 4
Training loss: 1.5330031343491495
Validation loss: 2.5742299716724855

Epoch: 6| Step: 5
Training loss: 1.2593481510603903
Validation loss: 2.5813921807931197

Epoch: 6| Step: 6
Training loss: 0.8562006497605872
Validation loss: 2.6108937286091276

Epoch: 6| Step: 7
Training loss: 1.009986012239191
Validation loss: 2.60721911467395

Epoch: 6| Step: 8
Training loss: 1.692616441628844
Validation loss: 2.641155236527599

Epoch: 6| Step: 9
Training loss: 1.1562548456863728
Validation loss: 2.6467104872386304

Epoch: 6| Step: 10
Training loss: 0.95495317573996
Validation loss: 2.675886898471585

Epoch: 6| Step: 11
Training loss: 1.2128722455141756
Validation loss: 2.7075503295743406

Epoch: 6| Step: 12
Training loss: 1.2916937127922126
Validation loss: 2.7086428781691985

Epoch: 6| Step: 13
Training loss: 1.1767568501195493
Validation loss: 2.7314889329269803

Epoch: 437| Step: 0
Training loss: 0.9923494161817369
Validation loss: 2.7382537464522283

Epoch: 6| Step: 1
Training loss: 1.0037200992638937
Validation loss: 2.7089844223173754

Epoch: 6| Step: 2
Training loss: 1.3867784943941257
Validation loss: 2.688557171018325

Epoch: 6| Step: 3
Training loss: 0.994837878021027
Validation loss: 2.69527925908066

Epoch: 6| Step: 4
Training loss: 1.1276485208270517
Validation loss: 2.6235097570280304

Epoch: 6| Step: 5
Training loss: 1.2383376629130345
Validation loss: 2.599482106461321

Epoch: 6| Step: 6
Training loss: 1.0575673663098002
Validation loss: 2.601237731467239

Epoch: 6| Step: 7
Training loss: 1.023139036498262
Validation loss: 2.5860287814685745

Epoch: 6| Step: 8
Training loss: 1.7730942448559686
Validation loss: 2.6270462280077305

Epoch: 6| Step: 9
Training loss: 1.3401242510282283
Validation loss: 2.613089952028082

Epoch: 6| Step: 10
Training loss: 1.2843231005055968
Validation loss: 2.6211263413951595

Epoch: 6| Step: 11
Training loss: 1.2158198222576824
Validation loss: 2.65359671563749

Epoch: 6| Step: 12
Training loss: 1.5116618143247025
Validation loss: 2.691456844017948

Epoch: 6| Step: 13
Training loss: 1.3191694017591977
Validation loss: 2.6725675055699782

Epoch: 438| Step: 0
Training loss: 1.268443372157889
Validation loss: 2.6874386846478457

Epoch: 6| Step: 1
Training loss: 1.0060199498270763
Validation loss: 2.694889164119793

Epoch: 6| Step: 2
Training loss: 1.231946947386009
Validation loss: 2.6788256193808873

Epoch: 6| Step: 3
Training loss: 1.1363688451474194
Validation loss: 2.647445235830681

Epoch: 6| Step: 4
Training loss: 1.010275794889597
Validation loss: 2.662848543189619

Epoch: 6| Step: 5
Training loss: 1.2080045559715098
Validation loss: 2.6592339825157354

Epoch: 6| Step: 6
Training loss: 1.0493218593535598
Validation loss: 2.628213079153783

Epoch: 6| Step: 7
Training loss: 1.1829405137081779
Validation loss: 2.6249575047488554

Epoch: 6| Step: 8
Training loss: 1.449409739615488
Validation loss: 2.612578683751498

Epoch: 6| Step: 9
Training loss: 1.3463856775173677
Validation loss: 2.6162530143226603

Epoch: 6| Step: 10
Training loss: 0.904204032202043
Validation loss: 2.6230595121335125

Epoch: 6| Step: 11
Training loss: 1.1129862076486563
Validation loss: 2.6223075270080725

Epoch: 6| Step: 12
Training loss: 1.8775009006950159
Validation loss: 2.615141856286684

Epoch: 6| Step: 13
Training loss: 1.2986803472674338
Validation loss: 2.622705083418052

Epoch: 439| Step: 0
Training loss: 1.0242171484660438
Validation loss: 2.642551770354842

Epoch: 6| Step: 1
Training loss: 0.8163850772430207
Validation loss: 2.6342151150982116

Epoch: 6| Step: 2
Training loss: 0.7378218498106117
Validation loss: 2.656699281707095

Epoch: 6| Step: 3
Training loss: 1.2411385191673758
Validation loss: 2.664373414146802

Epoch: 6| Step: 4
Training loss: 1.5541223620252205
Validation loss: 2.6678184539371355

Epoch: 6| Step: 5
Training loss: 1.6369158277921962
Validation loss: 2.627372080117133

Epoch: 6| Step: 6
Training loss: 1.4864655881017212
Validation loss: 2.6417019147984035

Epoch: 6| Step: 7
Training loss: 1.4099361004790543
Validation loss: 2.623409702661637

Epoch: 6| Step: 8
Training loss: 1.0863953318239967
Validation loss: 2.6072933939490337

Epoch: 6| Step: 9
Training loss: 1.210979141011607
Validation loss: 2.6093140869419074

Epoch: 6| Step: 10
Training loss: 0.9826081480438076
Validation loss: 2.59811924791235

Epoch: 6| Step: 11
Training loss: 1.339229921359551
Validation loss: 2.591210505980676

Epoch: 6| Step: 12
Training loss: 1.3827655590301378
Validation loss: 2.6312678511988357

Epoch: 6| Step: 13
Training loss: 0.9033257561596955
Validation loss: 2.646606321415852

Epoch: 440| Step: 0
Training loss: 1.5691644827729092
Validation loss: 2.685011405713598

Epoch: 6| Step: 1
Training loss: 1.033573192527517
Validation loss: 2.682403767281521

Epoch: 6| Step: 2
Training loss: 0.9992168757560517
Validation loss: 2.670545499455536

Epoch: 6| Step: 3
Training loss: 1.1202909672368973
Validation loss: 2.6381072946625483

Epoch: 6| Step: 4
Training loss: 1.3198745271985544
Validation loss: 2.5920426063769275

Epoch: 6| Step: 5
Training loss: 1.113978545675737
Validation loss: 2.608103658998434

Epoch: 6| Step: 6
Training loss: 0.80705261793034
Validation loss: 2.607699129128217

Epoch: 6| Step: 7
Training loss: 1.1627602685783722
Validation loss: 2.6028634982680403

Epoch: 6| Step: 8
Training loss: 1.2934738970269324
Validation loss: 2.6022211209498107

Epoch: 6| Step: 9
Training loss: 0.8718988435827917
Validation loss: 2.6264915164733282

Epoch: 6| Step: 10
Training loss: 1.2968429193780153
Validation loss: 2.581122676767473

Epoch: 6| Step: 11
Training loss: 1.0152475682774071
Validation loss: 2.579001144141154

Epoch: 6| Step: 12
Training loss: 1.8675775479681054
Validation loss: 2.6268668833995656

Epoch: 6| Step: 13
Training loss: 1.5193277335494053
Validation loss: 2.6239363170151635

Epoch: 441| Step: 0
Training loss: 1.3767474081701845
Validation loss: 2.646723413359906

Epoch: 6| Step: 1
Training loss: 1.3096622943933027
Validation loss: 2.6485150865172065

Epoch: 6| Step: 2
Training loss: 1.1007700565546041
Validation loss: 2.655142685659056

Epoch: 6| Step: 3
Training loss: 1.4946592141548956
Validation loss: 2.6661863169988105

Epoch: 6| Step: 4
Training loss: 1.1825296887789964
Validation loss: 2.7136551839135503

Epoch: 6| Step: 5
Training loss: 1.1246148085785885
Validation loss: 2.6624400543685325

Epoch: 6| Step: 6
Training loss: 1.2766589274225804
Validation loss: 2.6489320511599836

Epoch: 6| Step: 7
Training loss: 1.1276404864634055
Validation loss: 2.6345685509959123

Epoch: 6| Step: 8
Training loss: 1.4817533128861307
Validation loss: 2.6050279944368637

Epoch: 6| Step: 9
Training loss: 1.0911579480405307
Validation loss: 2.5831187837591805

Epoch: 6| Step: 10
Training loss: 1.0025330291215724
Validation loss: 2.6007721708772564

Epoch: 6| Step: 11
Training loss: 1.2850415024938742
Validation loss: 2.6011685402578584

Epoch: 6| Step: 12
Training loss: 0.7985912615387057
Validation loss: 2.56154910857208

Epoch: 6| Step: 13
Training loss: 1.3137882359218858
Validation loss: 2.6064078910466

Epoch: 442| Step: 0
Training loss: 1.283109710869838
Validation loss: 2.616443721437864

Epoch: 6| Step: 1
Training loss: 1.2276488917342543
Validation loss: 2.6338216763848186

Epoch: 6| Step: 2
Training loss: 1.0960258783710173
Validation loss: 2.650033487165247

Epoch: 6| Step: 3
Training loss: 1.2669831982607298
Validation loss: 2.654150771396762

Epoch: 6| Step: 4
Training loss: 0.63746166768486
Validation loss: 2.6377979982098476

Epoch: 6| Step: 5
Training loss: 0.8262818896766287
Validation loss: 2.63553836776106

Epoch: 6| Step: 6
Training loss: 1.3757099139615632
Validation loss: 2.659056027931787

Epoch: 6| Step: 7
Training loss: 1.4297767152726641
Validation loss: 2.669807799699064

Epoch: 6| Step: 8
Training loss: 0.9104827819025751
Validation loss: 2.66892539265464

Epoch: 6| Step: 9
Training loss: 1.3761918797637462
Validation loss: 2.6573436611298726

Epoch: 6| Step: 10
Training loss: 1.9881955111440743
Validation loss: 2.6292234295656973

Epoch: 6| Step: 11
Training loss: 1.1695535172232834
Validation loss: 2.56633979083365

Epoch: 6| Step: 12
Training loss: 0.8169074459388944
Validation loss: 2.61592177479494

Epoch: 6| Step: 13
Training loss: 0.9575502195211321
Validation loss: 2.597367743804771

Epoch: 443| Step: 0
Training loss: 0.757870819364654
Validation loss: 2.596061005147805

Epoch: 6| Step: 1
Training loss: 1.9696043673557542
Validation loss: 2.625807021353313

Epoch: 6| Step: 2
Training loss: 1.3243409047006753
Validation loss: 2.6686562622957477

Epoch: 6| Step: 3
Training loss: 0.7603078834026644
Validation loss: 2.655300478813444

Epoch: 6| Step: 4
Training loss: 1.438665912335127
Validation loss: 2.6674053431010383

Epoch: 6| Step: 5
Training loss: 1.0084901645693334
Validation loss: 2.631607544791637

Epoch: 6| Step: 6
Training loss: 0.8551292965260637
Validation loss: 2.6600039251799563

Epoch: 6| Step: 7
Training loss: 1.4710879284727816
Validation loss: 2.6447133982025246

Epoch: 6| Step: 8
Training loss: 1.04388490364713
Validation loss: 2.6767473194693183

Epoch: 6| Step: 9
Training loss: 0.7670880565950299
Validation loss: 2.6535600364192513

Epoch: 6| Step: 10
Training loss: 1.3230624481537059
Validation loss: 2.6356260200397412

Epoch: 6| Step: 11
Training loss: 1.429607118108327
Validation loss: 2.5939129371629286

Epoch: 6| Step: 12
Training loss: 0.8530950841444347
Validation loss: 2.5635946363376565

Epoch: 6| Step: 13
Training loss: 1.3027165767706363
Validation loss: 2.5721816989829187

Epoch: 444| Step: 0
Training loss: 1.1562577840182189
Validation loss: 2.5930243034254765

Epoch: 6| Step: 1
Training loss: 1.2402102490579112
Validation loss: 2.5913860085855562

Epoch: 6| Step: 2
Training loss: 1.233881888098973
Validation loss: 2.5931930981943827

Epoch: 6| Step: 3
Training loss: 1.0173934212430125
Validation loss: 2.6388289393156907

Epoch: 6| Step: 4
Training loss: 0.9840419750913882
Validation loss: 2.6602133169168605

Epoch: 6| Step: 5
Training loss: 0.6730022732241415
Validation loss: 2.6604494932444833

Epoch: 6| Step: 6
Training loss: 1.1664907231949189
Validation loss: 2.6996622871718827

Epoch: 6| Step: 7
Training loss: 1.2272497790692507
Validation loss: 2.6764130169508897

Epoch: 6| Step: 8
Training loss: 1.3031013578104418
Validation loss: 2.670449588200031

Epoch: 6| Step: 9
Training loss: 1.4540044932761678
Validation loss: 2.649931286226473

Epoch: 6| Step: 10
Training loss: 1.1651395385083954
Validation loss: 2.592128816822159

Epoch: 6| Step: 11
Training loss: 1.096329834487573
Validation loss: 2.5596552659740635

Epoch: 6| Step: 12
Training loss: 1.1563556210501549
Validation loss: 2.5215438620084853

Epoch: 6| Step: 13
Training loss: 2.052946912685799
Validation loss: 2.5059364009107585

Epoch: 445| Step: 0
Training loss: 1.1363048520922665
Validation loss: 2.4837351742781246

Epoch: 6| Step: 1
Training loss: 1.120497382110302
Validation loss: 2.50064486523537

Epoch: 6| Step: 2
Training loss: 1.5124357036449225
Validation loss: 2.5555523670348146

Epoch: 6| Step: 3
Training loss: 1.1983455995737462
Validation loss: 2.5706734811335266

Epoch: 6| Step: 4
Training loss: 1.1664081468713645
Validation loss: 2.6336889494209954

Epoch: 6| Step: 5
Training loss: 1.403349024638858
Validation loss: 2.6740989292945505

Epoch: 6| Step: 6
Training loss: 1.2210269101838283
Validation loss: 2.719465189721724

Epoch: 6| Step: 7
Training loss: 0.9431880692716689
Validation loss: 2.7032190188331175

Epoch: 6| Step: 8
Training loss: 0.781772133870391
Validation loss: 2.715082027365757

Epoch: 6| Step: 9
Training loss: 1.2793048887511407
Validation loss: 2.6793032507941086

Epoch: 6| Step: 10
Training loss: 0.8786447093498911
Validation loss: 2.649951614894739

Epoch: 6| Step: 11
Training loss: 1.8123462217142894
Validation loss: 2.6579444108789234

Epoch: 6| Step: 12
Training loss: 1.290230886216143
Validation loss: 2.630199732969964

Epoch: 6| Step: 13
Training loss: 0.6057545879361875
Validation loss: 2.6567722065413304

Epoch: 446| Step: 0
Training loss: 0.9498883307227227
Validation loss: 2.6502506787638342

Epoch: 6| Step: 1
Training loss: 1.3691448042910537
Validation loss: 2.649523739613884

Epoch: 6| Step: 2
Training loss: 1.3028290812827332
Validation loss: 2.6411185883646895

Epoch: 6| Step: 3
Training loss: 1.1835097985033252
Validation loss: 2.644665773836668

Epoch: 6| Step: 4
Training loss: 0.9840887652635499
Validation loss: 2.6772542282633585

Epoch: 6| Step: 5
Training loss: 1.2102733636660354
Validation loss: 2.6698072110754625

Epoch: 6| Step: 6
Training loss: 0.9052253060163556
Validation loss: 2.656764809258107

Epoch: 6| Step: 7
Training loss: 1.7609270097205143
Validation loss: 2.6518290298749356

Epoch: 6| Step: 8
Training loss: 1.5337232740043212
Validation loss: 2.6814404642430167

Epoch: 6| Step: 9
Training loss: 0.7031711563219586
Validation loss: 2.6779168935903135

Epoch: 6| Step: 10
Training loss: 0.9088801004085413
Validation loss: 2.6573833791000205

Epoch: 6| Step: 11
Training loss: 1.3476650956457887
Validation loss: 2.6658950592693227

Epoch: 6| Step: 12
Training loss: 1.2206617668775066
Validation loss: 2.6705081468042677

Epoch: 6| Step: 13
Training loss: 0.5144203447863098
Validation loss: 2.6767484955795866

Epoch: 447| Step: 0
Training loss: 1.1496908394261371
Validation loss: 2.660671197600964

Epoch: 6| Step: 1
Training loss: 1.4505680517139479
Validation loss: 2.644841797478811

Epoch: 6| Step: 2
Training loss: 1.3341488380757887
Validation loss: 2.6441658436343793

Epoch: 6| Step: 3
Training loss: 1.0663256492477007
Validation loss: 2.6070570356777005

Epoch: 6| Step: 4
Training loss: 1.1739587187519587
Validation loss: 2.663972142840707

Epoch: 6| Step: 5
Training loss: 1.295508894624435
Validation loss: 2.6542125186471255

Epoch: 6| Step: 6
Training loss: 1.0593180413251735
Validation loss: 2.7112812343132586

Epoch: 6| Step: 7
Training loss: 1.1383348231122017
Validation loss: 2.708609492292524

Epoch: 6| Step: 8
Training loss: 0.9692491967958237
Validation loss: 2.733313716134727

Epoch: 6| Step: 9
Training loss: 0.9258373903402535
Validation loss: 2.712724678688779

Epoch: 6| Step: 10
Training loss: 0.8824824838818136
Validation loss: 2.715784075311247

Epoch: 6| Step: 11
Training loss: 1.0586511800467633
Validation loss: 2.6868942419408945

Epoch: 6| Step: 12
Training loss: 1.8116130631888678
Validation loss: 2.667963863839107

Epoch: 6| Step: 13
Training loss: 1.0670482673131525
Validation loss: 2.6041901014360547

Epoch: 448| Step: 0
Training loss: 0.7615010268266433
Validation loss: 2.559337826086896

Epoch: 6| Step: 1
Training loss: 1.1611259338329156
Validation loss: 2.584029080847484

Epoch: 6| Step: 2
Training loss: 1.0284388981881805
Validation loss: 2.5855982213724436

Epoch: 6| Step: 3
Training loss: 1.1546553879584187
Validation loss: 2.5471542067453337

Epoch: 6| Step: 4
Training loss: 1.5627752443116696
Validation loss: 2.569822692929873

Epoch: 6| Step: 5
Training loss: 1.0480813434860277
Validation loss: 2.6131204466449436

Epoch: 6| Step: 6
Training loss: 1.0481355962974008
Validation loss: 2.5919904892406533

Epoch: 6| Step: 7
Training loss: 0.8042314959535655
Validation loss: 2.606572321702506

Epoch: 6| Step: 8
Training loss: 1.1292802659683423
Validation loss: 2.609989301497483

Epoch: 6| Step: 9
Training loss: 1.1569800263166934
Validation loss: 2.649104815529309

Epoch: 6| Step: 10
Training loss: 1.4820155615974127
Validation loss: 2.6718536445183054

Epoch: 6| Step: 11
Training loss: 0.9741128333178898
Validation loss: 2.650996195330274

Epoch: 6| Step: 12
Training loss: 1.697968612843602
Validation loss: 2.663769546706318

Epoch: 6| Step: 13
Training loss: 1.177307912057069
Validation loss: 2.697608420504939

Epoch: 449| Step: 0
Training loss: 0.869944408657624
Validation loss: 2.677052949969432

Epoch: 6| Step: 1
Training loss: 1.3856381786581775
Validation loss: 2.6521685761102365

Epoch: 6| Step: 2
Training loss: 1.3813749265490396
Validation loss: 2.628299688200268

Epoch: 6| Step: 3
Training loss: 1.3486939788582133
Validation loss: 2.618003519888306

Epoch: 6| Step: 4
Training loss: 1.1606532615297973
Validation loss: 2.620858149165902

Epoch: 6| Step: 5
Training loss: 1.5799812504102537
Validation loss: 2.603813858908373

Epoch: 6| Step: 6
Training loss: 1.008589688860978
Validation loss: 2.595401569209196

Epoch: 6| Step: 7
Training loss: 0.9745072366710987
Validation loss: 2.614112549494466

Epoch: 6| Step: 8
Training loss: 1.0223195033730546
Validation loss: 2.6498587265171856

Epoch: 6| Step: 9
Training loss: 0.8089789242563119
Validation loss: 2.6446794534492075

Epoch: 6| Step: 10
Training loss: 1.0727007318374187
Validation loss: 2.67248755917644

Epoch: 6| Step: 11
Training loss: 0.9956662326471664
Validation loss: 2.672605713848588

Epoch: 6| Step: 12
Training loss: 1.390370120575572
Validation loss: 2.611483982091003

Epoch: 6| Step: 13
Training loss: 0.9870452389036042
Validation loss: 2.657802634226824

Epoch: 450| Step: 0
Training loss: 1.2429719283508673
Validation loss: 2.649842235089239

Epoch: 6| Step: 1
Training loss: 0.9953949814759423
Validation loss: 2.648325099381529

Epoch: 6| Step: 2
Training loss: 1.4524527194392323
Validation loss: 2.6481264273936738

Epoch: 6| Step: 3
Training loss: 1.3494963094824086
Validation loss: 2.6600760539560477

Epoch: 6| Step: 4
Training loss: 1.2853724521017043
Validation loss: 2.620163584952432

Epoch: 6| Step: 5
Training loss: 1.1345353803939036
Validation loss: 2.611032056218999

Epoch: 6| Step: 6
Training loss: 0.933443320696485
Validation loss: 2.603080155330876

Epoch: 6| Step: 7
Training loss: 1.6594040546639421
Validation loss: 2.594808681435529

Epoch: 6| Step: 8
Training loss: 1.1773375290147523
Validation loss: 2.583148339032383

Epoch: 6| Step: 9
Training loss: 0.9490096250393661
Validation loss: 2.6538532627692444

Epoch: 6| Step: 10
Training loss: 0.8863427797722473
Validation loss: 2.6595314126505993

Epoch: 6| Step: 11
Training loss: 0.9695030484950833
Validation loss: 2.713114898442333

Epoch: 6| Step: 12
Training loss: 1.2049790995514549
Validation loss: 2.7222197083185424

Epoch: 6| Step: 13
Training loss: 0.8678060851308175
Validation loss: 2.6875623756337843

Epoch: 451| Step: 0
Training loss: 0.7901729663591583
Validation loss: 2.675905946886353

Epoch: 6| Step: 1
Training loss: 0.7737044056907353
Validation loss: 2.6384640510544597

Epoch: 6| Step: 2
Training loss: 0.7950838565985289
Validation loss: 2.6559625826005147

Epoch: 6| Step: 3
Training loss: 1.1376260498967516
Validation loss: 2.651336505248319

Epoch: 6| Step: 4
Training loss: 1.140689116465691
Validation loss: 2.597775076597814

Epoch: 6| Step: 5
Training loss: 1.387002577412802
Validation loss: 2.6393551657585634

Epoch: 6| Step: 6
Training loss: 1.1039400887887938
Validation loss: 2.6562719490162645

Epoch: 6| Step: 7
Training loss: 1.8672443205675175
Validation loss: 2.6602002462570233

Epoch: 6| Step: 8
Training loss: 1.1472410859862892
Validation loss: 2.692022089107981

Epoch: 6| Step: 9
Training loss: 1.3472901220132398
Validation loss: 2.67590519625731

Epoch: 6| Step: 10
Training loss: 1.4479729986781946
Validation loss: 2.702856280591259

Epoch: 6| Step: 11
Training loss: 0.9374201740612206
Validation loss: 2.7084345726862

Epoch: 6| Step: 12
Training loss: 1.0967563728023895
Validation loss: 2.7030211720421016

Epoch: 6| Step: 13
Training loss: 0.8391786292497866
Validation loss: 2.6517462830046346

Epoch: 452| Step: 0
Training loss: 1.1034413000412477
Validation loss: 2.6513856641706175

Epoch: 6| Step: 1
Training loss: 1.582011055523116
Validation loss: 2.6471324651265165

Epoch: 6| Step: 2
Training loss: 0.9943106455331536
Validation loss: 2.618305124516639

Epoch: 6| Step: 3
Training loss: 1.4859476692822453
Validation loss: 2.608882520344853

Epoch: 6| Step: 4
Training loss: 1.249734087316764
Validation loss: 2.6013185785290918

Epoch: 6| Step: 5
Training loss: 1.0661525773936305
Validation loss: 2.6291653672523836

Epoch: 6| Step: 6
Training loss: 0.577299250022101
Validation loss: 2.6192079388458183

Epoch: 6| Step: 7
Training loss: 0.6826757534154676
Validation loss: 2.6467888479138364

Epoch: 6| Step: 8
Training loss: 1.2702780067856467
Validation loss: 2.6495852023481103

Epoch: 6| Step: 9
Training loss: 1.091117961712697
Validation loss: 2.659527384323549

Epoch: 6| Step: 10
Training loss: 1.1346030455319962
Validation loss: 2.6516485615730803

Epoch: 6| Step: 11
Training loss: 1.1699023109799929
Validation loss: 2.6656223381306265

Epoch: 6| Step: 12
Training loss: 1.3294738203371257
Validation loss: 2.6395133248123934

Epoch: 6| Step: 13
Training loss: 1.179889383788707
Validation loss: 2.625739510551325

Epoch: 453| Step: 0
Training loss: 1.2891051776641445
Validation loss: 2.624099598507663

Epoch: 6| Step: 1
Training loss: 1.0907474722316006
Validation loss: 2.6333599327813593

Epoch: 6| Step: 2
Training loss: 1.7485054309728991
Validation loss: 2.663051550176221

Epoch: 6| Step: 3
Training loss: 0.5958036744354336
Validation loss: 2.627311535525136

Epoch: 6| Step: 4
Training loss: 1.1757324310002362
Validation loss: 2.7154789814503153

Epoch: 6| Step: 5
Training loss: 1.04654847931604
Validation loss: 2.6637737678368327

Epoch: 6| Step: 6
Training loss: 1.3242080823080409
Validation loss: 2.6556292238573715

Epoch: 6| Step: 7
Training loss: 1.094455110241921
Validation loss: 2.662712190160587

Epoch: 6| Step: 8
Training loss: 1.2516356257531747
Validation loss: 2.652308992393148

Epoch: 6| Step: 9
Training loss: 0.9547060688416871
Validation loss: 2.658236568195615

Epoch: 6| Step: 10
Training loss: 1.0391008183577135
Validation loss: 2.646876416257617

Epoch: 6| Step: 11
Training loss: 0.6063948654840019
Validation loss: 2.6283773322200683

Epoch: 6| Step: 12
Training loss: 1.2949576394506102
Validation loss: 2.6074801481626215

Epoch: 6| Step: 13
Training loss: 1.0380915644323625
Validation loss: 2.6779809197742765

Epoch: 454| Step: 0
Training loss: 1.0858498407564636
Validation loss: 2.6630213500749895

Epoch: 6| Step: 1
Training loss: 1.1965061784800741
Validation loss: 2.650530146008928

Epoch: 6| Step: 2
Training loss: 1.2001145586327011
Validation loss: 2.644775611994046

Epoch: 6| Step: 3
Training loss: 0.9822856892106893
Validation loss: 2.6640674943582128

Epoch: 6| Step: 4
Training loss: 1.0462376376644253
Validation loss: 2.615790266316165

Epoch: 6| Step: 5
Training loss: 1.0613735623087686
Validation loss: 2.6177426230209235

Epoch: 6| Step: 6
Training loss: 1.1002962667128506
Validation loss: 2.6195811913684373

Epoch: 6| Step: 7
Training loss: 1.8609424043297702
Validation loss: 2.6266176012456914

Epoch: 6| Step: 8
Training loss: 0.9932134535369546
Validation loss: 2.6574164226095873

Epoch: 6| Step: 9
Training loss: 0.8235060516718731
Validation loss: 2.6805468148639044

Epoch: 6| Step: 10
Training loss: 1.1447116852792478
Validation loss: 2.6685741015680278

Epoch: 6| Step: 11
Training loss: 1.318521582903101
Validation loss: 2.670697237909301

Epoch: 6| Step: 12
Training loss: 1.001263178287414
Validation loss: 2.642225156998311

Epoch: 6| Step: 13
Training loss: 0.7920419698513917
Validation loss: 2.6645510742181564

Epoch: 455| Step: 0
Training loss: 0.963853953849439
Validation loss: 2.606269159642757

Epoch: 6| Step: 1
Training loss: 1.0319218036797202
Validation loss: 2.616006922927923

Epoch: 6| Step: 2
Training loss: 0.7442781015997344
Validation loss: 2.5582354556097213

Epoch: 6| Step: 3
Training loss: 1.1596662212157887
Validation loss: 2.5863925518709845

Epoch: 6| Step: 4
Training loss: 1.071638636205165
Validation loss: 2.5911891183975273

Epoch: 6| Step: 5
Training loss: 1.3374907181319697
Validation loss: 2.646463377447402

Epoch: 6| Step: 6
Training loss: 0.9024918339748207
Validation loss: 2.6953596489366936

Epoch: 6| Step: 7
Training loss: 1.0272455204754378
Validation loss: 2.7044783109100914

Epoch: 6| Step: 8
Training loss: 1.9813926091900438
Validation loss: 2.7396356080210507

Epoch: 6| Step: 9
Training loss: 0.873287568846724
Validation loss: 2.72460481905945

Epoch: 6| Step: 10
Training loss: 1.004003141603456
Validation loss: 2.68631088113711

Epoch: 6| Step: 11
Training loss: 1.3699485147505805
Validation loss: 2.6648128353696405

Epoch: 6| Step: 12
Training loss: 1.194649406462399
Validation loss: 2.600870590487474

Epoch: 6| Step: 13
Training loss: 0.7124811956366952
Validation loss: 2.562619411348433

Epoch: 456| Step: 0
Training loss: 0.9933781725942146
Validation loss: 2.571992481400147

Epoch: 6| Step: 1
Training loss: 1.104607667965497
Validation loss: 2.5851264447304922

Epoch: 6| Step: 2
Training loss: 1.2061634091936857
Validation loss: 2.6259089838115974

Epoch: 6| Step: 3
Training loss: 1.1563764966897925
Validation loss: 2.6489715923341888

Epoch: 6| Step: 4
Training loss: 1.1121344297887599
Validation loss: 2.591582078097009

Epoch: 6| Step: 5
Training loss: 1.1639125138502273
Validation loss: 2.6265147302531604

Epoch: 6| Step: 6
Training loss: 1.121780238492772
Validation loss: 2.655477134614288

Epoch: 6| Step: 7
Training loss: 1.1850139293576285
Validation loss: 2.627945464800182

Epoch: 6| Step: 8
Training loss: 1.6955881202362584
Validation loss: 2.6501867690917846

Epoch: 6| Step: 9
Training loss: 0.9182336952471409
Validation loss: 2.662782275754049

Epoch: 6| Step: 10
Training loss: 0.9068598832619476
Validation loss: 2.616191411821395

Epoch: 6| Step: 11
Training loss: 1.106279810272122
Validation loss: 2.606008109130865

Epoch: 6| Step: 12
Training loss: 1.09371468623237
Validation loss: 2.6111049074570407

Epoch: 6| Step: 13
Training loss: 0.7979904296750471
Validation loss: 2.6232244411791283

Epoch: 457| Step: 0
Training loss: 1.1692579420210274
Validation loss: 2.624405287152553

Epoch: 6| Step: 1
Training loss: 1.0726646139620368
Validation loss: 2.6719226901265865

Epoch: 6| Step: 2
Training loss: 0.9869483734936866
Validation loss: 2.669022080990853

Epoch: 6| Step: 3
Training loss: 0.5716259606922851
Validation loss: 2.67366382930627

Epoch: 6| Step: 4
Training loss: 0.7448750073592482
Validation loss: 2.735716583642597

Epoch: 6| Step: 5
Training loss: 1.2416054183566445
Validation loss: 2.687914531853535

Epoch: 6| Step: 6
Training loss: 0.7926680271831074
Validation loss: 2.684116904162196

Epoch: 6| Step: 7
Training loss: 1.4035114325427052
Validation loss: 2.7052337626588523

Epoch: 6| Step: 8
Training loss: 1.9084467502967595
Validation loss: 2.6403298501565557

Epoch: 6| Step: 9
Training loss: 1.1851938341049237
Validation loss: 2.668473070906286

Epoch: 6| Step: 10
Training loss: 1.2301482252423463
Validation loss: 2.665351082343481

Epoch: 6| Step: 11
Training loss: 1.1329798081594489
Validation loss: 2.660230075561719

Epoch: 6| Step: 12
Training loss: 0.7507841858424364
Validation loss: 2.6160600403724588

Epoch: 6| Step: 13
Training loss: 0.8911692646155923
Validation loss: 2.611071181648364

Epoch: 458| Step: 0
Training loss: 0.8334071643230291
Validation loss: 2.628282095846757

Epoch: 6| Step: 1
Training loss: 1.1813738056677727
Validation loss: 2.588533980643985

Epoch: 6| Step: 2
Training loss: 1.177183613964418
Validation loss: 2.585993783738124

Epoch: 6| Step: 3
Training loss: 1.2885907783904214
Validation loss: 2.6128454289018923

Epoch: 6| Step: 4
Training loss: 1.5652483610818786
Validation loss: 2.6094614365480138

Epoch: 6| Step: 5
Training loss: 1.2312324212847785
Validation loss: 2.6162602792183636

Epoch: 6| Step: 6
Training loss: 0.9633226025345586
Validation loss: 2.621793144638218

Epoch: 6| Step: 7
Training loss: 1.0344523789888793
Validation loss: 2.680443443674089

Epoch: 6| Step: 8
Training loss: 0.888551942885895
Validation loss: 2.642277561094496

Epoch: 6| Step: 9
Training loss: 0.9113920278500629
Validation loss: 2.624091857064323

Epoch: 6| Step: 10
Training loss: 1.1405930188019717
Validation loss: 2.674927051650883

Epoch: 6| Step: 11
Training loss: 0.8200397582999046
Validation loss: 2.6618277053798423

Epoch: 6| Step: 12
Training loss: 1.1743066608873174
Validation loss: 2.6561770251176973

Epoch: 6| Step: 13
Training loss: 1.3537849279461023
Validation loss: 2.6121178532542872

Epoch: 459| Step: 0
Training loss: 1.246154592338114
Validation loss: 2.5937268942673453

Epoch: 6| Step: 1
Training loss: 0.903433138013118
Validation loss: 2.608983083679575

Epoch: 6| Step: 2
Training loss: 1.0595561927522628
Validation loss: 2.5804585614985776

Epoch: 6| Step: 3
Training loss: 0.9048620974604541
Validation loss: 2.572604934987124

Epoch: 6| Step: 4
Training loss: 1.0775558517389914
Validation loss: 2.5895292650788657

Epoch: 6| Step: 5
Training loss: 1.009461524963267
Validation loss: 2.615367190620776

Epoch: 6| Step: 6
Training loss: 1.0189538248623133
Validation loss: 2.625148083913996

Epoch: 6| Step: 7
Training loss: 1.0521127992538732
Validation loss: 2.638750872720546

Epoch: 6| Step: 8
Training loss: 1.304407466599526
Validation loss: 2.669550746084376

Epoch: 6| Step: 9
Training loss: 1.5914441051297394
Validation loss: 2.658531374180908

Epoch: 6| Step: 10
Training loss: 0.675654360815161
Validation loss: 2.648713048932239

Epoch: 6| Step: 11
Training loss: 1.4071493028322992
Validation loss: 2.684568857150006

Epoch: 6| Step: 12
Training loss: 1.2246534713763824
Validation loss: 2.622143389901698

Epoch: 6| Step: 13
Training loss: 0.6603647162484968
Validation loss: 2.6175376152218197

Epoch: 460| Step: 0
Training loss: 1.2263944474283073
Validation loss: 2.654533562266879

Epoch: 6| Step: 1
Training loss: 0.893685619996546
Validation loss: 2.6456364755516377

Epoch: 6| Step: 2
Training loss: 1.227437624385658
Validation loss: 2.6697588772411196

Epoch: 6| Step: 3
Training loss: 0.9319432245016918
Validation loss: 2.635827199165282

Epoch: 6| Step: 4
Training loss: 0.9324747825669556
Validation loss: 2.645540477179591

Epoch: 6| Step: 5
Training loss: 1.0995429173065057
Validation loss: 2.652375195769432

Epoch: 6| Step: 6
Training loss: 0.7378788815357001
Validation loss: 2.6609584455365627

Epoch: 6| Step: 7
Training loss: 0.817563783216377
Validation loss: 2.646665935466146

Epoch: 6| Step: 8
Training loss: 1.6192568011415647
Validation loss: 2.6492231256892884

Epoch: 6| Step: 9
Training loss: 1.1997363436653585
Validation loss: 2.662629938447716

Epoch: 6| Step: 10
Training loss: 1.3575125025951504
Validation loss: 2.6565831052130666

Epoch: 6| Step: 11
Training loss: 1.177059150829988
Validation loss: 2.625665990370939

Epoch: 6| Step: 12
Training loss: 0.8619087666846533
Validation loss: 2.594948482954804

Epoch: 6| Step: 13
Training loss: 1.0356307183926807
Validation loss: 2.6261505031637196

Epoch: 461| Step: 0
Training loss: 0.7675557218199082
Validation loss: 2.6552519726338306

Epoch: 6| Step: 1
Training loss: 1.0045154074118137
Validation loss: 2.668065416313286

Epoch: 6| Step: 2
Training loss: 1.1190015030647118
Validation loss: 2.663508087275964

Epoch: 6| Step: 3
Training loss: 0.9500373795333152
Validation loss: 2.6823369345034522

Epoch: 6| Step: 4
Training loss: 1.2194992110096161
Validation loss: 2.6911815944431448

Epoch: 6| Step: 5
Training loss: 0.6325044706435392
Validation loss: 2.6676468265573785

Epoch: 6| Step: 6
Training loss: 1.0676844834556007
Validation loss: 2.665513289758908

Epoch: 6| Step: 7
Training loss: 1.2952671425013937
Validation loss: 2.630699135477547

Epoch: 6| Step: 8
Training loss: 1.0310745089938573
Validation loss: 2.583605280272612

Epoch: 6| Step: 9
Training loss: 0.7760442097940101
Validation loss: 2.5785949835502935

Epoch: 6| Step: 10
Training loss: 1.4334834833381143
Validation loss: 2.5129807111285327

Epoch: 6| Step: 11
Training loss: 1.8999696678952849
Validation loss: 2.50391958671897

Epoch: 6| Step: 12
Training loss: 0.7870513667462211
Validation loss: 2.550055197259712

Epoch: 6| Step: 13
Training loss: 0.7773192895462557
Validation loss: 2.615295676561869

Epoch: 462| Step: 0
Training loss: 0.9893884299566229
Validation loss: 2.6462825354744726

Epoch: 6| Step: 1
Training loss: 1.0429887519661492
Validation loss: 2.7020577562049057

Epoch: 6| Step: 2
Training loss: 0.5905749607586279
Validation loss: 2.683708590045562

Epoch: 6| Step: 3
Training loss: 1.3303921366667377
Validation loss: 2.7267572143204

Epoch: 6| Step: 4
Training loss: 0.6324787201524601
Validation loss: 2.6956619423765202

Epoch: 6| Step: 5
Training loss: 0.6957081729763608
Validation loss: 2.6926699488635566

Epoch: 6| Step: 6
Training loss: 1.2779066612831245
Validation loss: 2.6783305951444776

Epoch: 6| Step: 7
Training loss: 1.2522753034652345
Validation loss: 2.673745156706374

Epoch: 6| Step: 8
Training loss: 1.2410089431981457
Validation loss: 2.6501451962164735

Epoch: 6| Step: 9
Training loss: 1.7421457602115267
Validation loss: 2.643536428603066

Epoch: 6| Step: 10
Training loss: 0.9711690970150877
Validation loss: 2.6006887808347146

Epoch: 6| Step: 11
Training loss: 0.9800285475815792
Validation loss: 2.598493105609648

Epoch: 6| Step: 12
Training loss: 1.173723720788542
Validation loss: 2.5876185313488476

Epoch: 6| Step: 13
Training loss: 0.8655193195489701
Validation loss: 2.603465846769711

Epoch: 463| Step: 0
Training loss: 1.607513832993857
Validation loss: 2.631289923841486

Epoch: 6| Step: 1
Training loss: 0.8458619706390713
Validation loss: 2.6307266476787654

Epoch: 6| Step: 2
Training loss: 0.9353666191617737
Validation loss: 2.634360876293545

Epoch: 6| Step: 3
Training loss: 1.122489671553436
Validation loss: 2.6229164499704023

Epoch: 6| Step: 4
Training loss: 0.9665355598945387
Validation loss: 2.6425845821681198

Epoch: 6| Step: 5
Training loss: 1.3210506745754087
Validation loss: 2.627694391283587

Epoch: 6| Step: 6
Training loss: 1.227710017012115
Validation loss: 2.6386652498915106

Epoch: 6| Step: 7
Training loss: 0.8235088020739066
Validation loss: 2.6649600821544563

Epoch: 6| Step: 8
Training loss: 0.7366294345537743
Validation loss: 2.6719169294378413

Epoch: 6| Step: 9
Training loss: 1.1163816947185279
Validation loss: 2.656343335629722

Epoch: 6| Step: 10
Training loss: 1.1681445445573355
Validation loss: 2.6754877372440733

Epoch: 6| Step: 11
Training loss: 1.1107375146034058
Validation loss: 2.633446199275921

Epoch: 6| Step: 12
Training loss: 1.1667011233191535
Validation loss: 2.6108759875513945

Epoch: 6| Step: 13
Training loss: 0.9482058234269498
Validation loss: 2.637802381414956

Epoch: 464| Step: 0
Training loss: 1.0941525944494628
Validation loss: 2.6177769875755774

Epoch: 6| Step: 1
Training loss: 0.8225826277579267
Validation loss: 2.671754028444886

Epoch: 6| Step: 2
Training loss: 0.8003800666525985
Validation loss: 2.643843375243595

Epoch: 6| Step: 3
Training loss: 1.1822442648819715
Validation loss: 2.6695996099363968

Epoch: 6| Step: 4
Training loss: 0.9023490674411269
Validation loss: 2.7181208939600836

Epoch: 6| Step: 5
Training loss: 0.826740186662458
Validation loss: 2.712589093805458

Epoch: 6| Step: 6
Training loss: 1.0328202286285386
Validation loss: 2.716936254446597

Epoch: 6| Step: 7
Training loss: 1.5377627078520275
Validation loss: 2.6922204842417226

Epoch: 6| Step: 8
Training loss: 1.282545411791288
Validation loss: 2.6560642406697808

Epoch: 6| Step: 9
Training loss: 1.3306696132564857
Validation loss: 2.6212792266199525

Epoch: 6| Step: 10
Training loss: 0.9946129057416062
Validation loss: 2.656130947893048

Epoch: 6| Step: 11
Training loss: 1.150368811719524
Validation loss: 2.593634345723869

Epoch: 6| Step: 12
Training loss: 0.7100476575357353
Validation loss: 2.6042677727217476

Epoch: 6| Step: 13
Training loss: 1.3585849088235273
Validation loss: 2.5556489855448654

Epoch: 465| Step: 0
Training loss: 1.1103800129998977
Validation loss: 2.59125448168061

Epoch: 6| Step: 1
Training loss: 1.1366274033381234
Validation loss: 2.6157920848234086

Epoch: 6| Step: 2
Training loss: 1.0545534401923098
Validation loss: 2.622742833407343

Epoch: 6| Step: 3
Training loss: 1.6685754891918176
Validation loss: 2.657293869566074

Epoch: 6| Step: 4
Training loss: 0.571099091594884
Validation loss: 2.6676238304019027

Epoch: 6| Step: 5
Training loss: 1.146959352639428
Validation loss: 2.704324313383804

Epoch: 6| Step: 6
Training loss: 1.185936350061716
Validation loss: 2.7121015423615193

Epoch: 6| Step: 7
Training loss: 0.7792692633687266
Validation loss: 2.7312606293942245

Epoch: 6| Step: 8
Training loss: 0.8999839410408775
Validation loss: 2.703201506252379

Epoch: 6| Step: 9
Training loss: 1.0346419298280802
Validation loss: 2.6722401813944

Epoch: 6| Step: 10
Training loss: 1.153215705591563
Validation loss: 2.6730403454092917

Epoch: 6| Step: 11
Training loss: 0.9179961829448953
Validation loss: 2.610072818218532

Epoch: 6| Step: 12
Training loss: 1.2468707015266995
Validation loss: 2.6170305748980462

Epoch: 6| Step: 13
Training loss: 0.8693835658317156
Validation loss: 2.622396296061517

Epoch: 466| Step: 0
Training loss: 0.7100690630782476
Validation loss: 2.6174713343286187

Epoch: 6| Step: 1
Training loss: 0.870928419358048
Validation loss: 2.6318052165233996

Epoch: 6| Step: 2
Training loss: 1.0245539276093933
Validation loss: 2.599771642201244

Epoch: 6| Step: 3
Training loss: 1.162700496324325
Validation loss: 2.56935185808191

Epoch: 6| Step: 4
Training loss: 1.1968720677591367
Validation loss: 2.6685317334071548

Epoch: 6| Step: 5
Training loss: 1.0767078761037587
Validation loss: 2.6759279028124574

Epoch: 6| Step: 6
Training loss: 1.1237634114450643
Validation loss: 2.660161619831642

Epoch: 6| Step: 7
Training loss: 1.0759267095046317
Validation loss: 2.692749480750321

Epoch: 6| Step: 8
Training loss: 0.9939835280007248
Validation loss: 2.7102189565281316

Epoch: 6| Step: 9
Training loss: 1.3099850674134852
Validation loss: 2.651790632446295

Epoch: 6| Step: 10
Training loss: 0.7994107311336874
Validation loss: 2.641084413950789

Epoch: 6| Step: 11
Training loss: 1.4221062943692857
Validation loss: 2.5903298648050694

Epoch: 6| Step: 12
Training loss: 1.0685026362185341
Validation loss: 2.5706310541725066

Epoch: 6| Step: 13
Training loss: 1.313728030499276
Validation loss: 2.59583557310001

Epoch: 467| Step: 0
Training loss: 1.1414793812263508
Validation loss: 2.6029397603488547

Epoch: 6| Step: 1
Training loss: 0.8581643333228
Validation loss: 2.5973183511360562

Epoch: 6| Step: 2
Training loss: 1.2226642449943275
Validation loss: 2.6098626511113725

Epoch: 6| Step: 3
Training loss: 0.9863476137558684
Validation loss: 2.652399405684259

Epoch: 6| Step: 4
Training loss: 1.0305705866841381
Validation loss: 2.7212067883815454

Epoch: 6| Step: 5
Training loss: 1.0195886588467435
Validation loss: 2.753252121943486

Epoch: 6| Step: 6
Training loss: 1.0133443020134951
Validation loss: 2.7431419022168733

Epoch: 6| Step: 7
Training loss: 0.9640136421967591
Validation loss: 2.7181652412882715

Epoch: 6| Step: 8
Training loss: 0.8151974284450637
Validation loss: 2.700897829053849

Epoch: 6| Step: 9
Training loss: 0.7806929700594297
Validation loss: 2.7295007434679834

Epoch: 6| Step: 10
Training loss: 1.8701017613185567
Validation loss: 2.6918678465920434

Epoch: 6| Step: 11
Training loss: 1.0116687894879546
Validation loss: 2.6827894396269847

Epoch: 6| Step: 12
Training loss: 1.2589435112713134
Validation loss: 2.68066620088737

Epoch: 6| Step: 13
Training loss: 0.7493437439013205
Validation loss: 2.7026741030656245

Epoch: 468| Step: 0
Training loss: 1.2562148093993026
Validation loss: 2.726634667659055

Epoch: 6| Step: 1
Training loss: 0.9308471179432124
Validation loss: 2.705234696103357

Epoch: 6| Step: 2
Training loss: 0.9628638521074305
Validation loss: 2.691043356066518

Epoch: 6| Step: 3
Training loss: 1.5281322424469304
Validation loss: 2.6987696882946106

Epoch: 6| Step: 4
Training loss: 1.022900156378634
Validation loss: 2.6721226298535705

Epoch: 6| Step: 5
Training loss: 0.8234692098747933
Validation loss: 2.605044009834604

Epoch: 6| Step: 6
Training loss: 1.0408957235198064
Validation loss: 2.593439664040325

Epoch: 6| Step: 7
Training loss: 0.9016876477628563
Validation loss: 2.601271744424264

Epoch: 6| Step: 8
Training loss: 0.679392739760085
Validation loss: 2.6242111552114884

Epoch: 6| Step: 9
Training loss: 0.8512987200761097
Validation loss: 2.605363362328954

Epoch: 6| Step: 10
Training loss: 1.0938977277990718
Validation loss: 2.6331994394422304

Epoch: 6| Step: 11
Training loss: 0.8476478822356639
Validation loss: 2.6705160772065284

Epoch: 6| Step: 12
Training loss: 1.107083546460559
Validation loss: 2.6763533509149706

Epoch: 6| Step: 13
Training loss: 2.037943565905033
Validation loss: 2.674884583807923

Epoch: 469| Step: 0
Training loss: 1.2382321513457082
Validation loss: 2.6732507510156456

Epoch: 6| Step: 1
Training loss: 0.8366123220821677
Validation loss: 2.6056789242025626

Epoch: 6| Step: 2
Training loss: 1.1633155013268934
Validation loss: 2.6057766006544014

Epoch: 6| Step: 3
Training loss: 0.7326745169736496
Validation loss: 2.58619867516591

Epoch: 6| Step: 4
Training loss: 0.8666719158331535
Validation loss: 2.592971128350506

Epoch: 6| Step: 5
Training loss: 0.8587827202061938
Validation loss: 2.6184772935758813

Epoch: 6| Step: 6
Training loss: 1.2861266023779931
Validation loss: 2.603424892649732

Epoch: 6| Step: 7
Training loss: 0.7287521591939723
Validation loss: 2.656872071708691

Epoch: 6| Step: 8
Training loss: 0.99281261306008
Validation loss: 2.6468508182411896

Epoch: 6| Step: 9
Training loss: 1.3054446461870464
Validation loss: 2.6441562819536246

Epoch: 6| Step: 10
Training loss: 1.280483528317256
Validation loss: 2.6930410255335286

Epoch: 6| Step: 11
Training loss: 0.9091865711381798
Validation loss: 2.657405426803221

Epoch: 6| Step: 12
Training loss: 1.5227667481211131
Validation loss: 2.652691593848659

Epoch: 6| Step: 13
Training loss: 1.023583845784453
Validation loss: 2.659509798035599

Epoch: 470| Step: 0
Training loss: 0.7897728092924565
Validation loss: 2.6522207508742115

Epoch: 6| Step: 1
Training loss: 0.7500091393231807
Validation loss: 2.597626910127618

Epoch: 6| Step: 2
Training loss: 1.3063299382769078
Validation loss: 2.6263229329674536

Epoch: 6| Step: 3
Training loss: 0.7889883554201266
Validation loss: 2.6307784749260574

Epoch: 6| Step: 4
Training loss: 0.7396310647596882
Validation loss: 2.6526489348039246

Epoch: 6| Step: 5
Training loss: 0.7050410548897472
Validation loss: 2.6640501045205958

Epoch: 6| Step: 6
Training loss: 0.8853504193523911
Validation loss: 2.676087265773511

Epoch: 6| Step: 7
Training loss: 1.143033763316741
Validation loss: 2.727030919208204

Epoch: 6| Step: 8
Training loss: 1.0572196234350781
Validation loss: 2.6817808173528093

Epoch: 6| Step: 9
Training loss: 1.0104058779635372
Validation loss: 2.7098399850329793

Epoch: 6| Step: 10
Training loss: 1.071277100210247
Validation loss: 2.662383571522676

Epoch: 6| Step: 11
Training loss: 0.777087682212408
Validation loss: 2.67631391638545

Epoch: 6| Step: 12
Training loss: 1.3619789527129473
Validation loss: 2.655074545816409

Epoch: 6| Step: 13
Training loss: 2.2886938638016594
Validation loss: 2.6524505513990695

Epoch: 471| Step: 0
Training loss: 0.843701467177863
Validation loss: 2.634745927409243

Epoch: 6| Step: 1
Training loss: 1.1766184617471507
Validation loss: 2.6484873844982824

Epoch: 6| Step: 2
Training loss: 1.0599149785042736
Validation loss: 2.6483492369347132

Epoch: 6| Step: 3
Training loss: 1.6832891131091436
Validation loss: 2.6735456839997

Epoch: 6| Step: 4
Training loss: 0.8507923528333871
Validation loss: 2.6511566706423797

Epoch: 6| Step: 5
Training loss: 1.0800936320124657
Validation loss: 2.6717642839318185

Epoch: 6| Step: 6
Training loss: 0.8782661989663474
Validation loss: 2.654539571214819

Epoch: 6| Step: 7
Training loss: 1.0904354007167465
Validation loss: 2.642496408833847

Epoch: 6| Step: 8
Training loss: 1.2041248279065715
Validation loss: 2.6021702810406047

Epoch: 6| Step: 9
Training loss: 0.5374987491326969
Validation loss: 2.6223854388726626

Epoch: 6| Step: 10
Training loss: 0.9551160059868502
Validation loss: 2.6248101675105264

Epoch: 6| Step: 11
Training loss: 0.9708639276510891
Validation loss: 2.651859070317587

Epoch: 6| Step: 12
Training loss: 1.3046983729840254
Validation loss: 2.683569909394511

Epoch: 6| Step: 13
Training loss: 0.9431461701440802
Validation loss: 2.6972843413754934

Epoch: 472| Step: 0
Training loss: 0.9907781849542868
Validation loss: 2.6967286952357483

Epoch: 6| Step: 1
Training loss: 0.9981695349879213
Validation loss: 2.7001498497140104

Epoch: 6| Step: 2
Training loss: 0.8484777170558647
Validation loss: 2.7201675059654904

Epoch: 6| Step: 3
Training loss: 0.983895442346562
Validation loss: 2.710571250137187

Epoch: 6| Step: 4
Training loss: 0.8488245704601031
Validation loss: 2.7029852270545187

Epoch: 6| Step: 5
Training loss: 1.0970018818820888
Validation loss: 2.700389277441266

Epoch: 6| Step: 6
Training loss: 1.0016730141927856
Validation loss: 2.697676279509013

Epoch: 6| Step: 7
Training loss: 1.9039240545505527
Validation loss: 2.668365904900482

Epoch: 6| Step: 8
Training loss: 1.1216824677154078
Validation loss: 2.635236221693095

Epoch: 6| Step: 9
Training loss: 0.7626170803297238
Validation loss: 2.5581393792420037

Epoch: 6| Step: 10
Training loss: 0.9470641246301641
Validation loss: 2.596266746046932

Epoch: 6| Step: 11
Training loss: 1.294264728779919
Validation loss: 2.591680295729203

Epoch: 6| Step: 12
Training loss: 0.8279114213869155
Validation loss: 2.6250501985335384

Epoch: 6| Step: 13
Training loss: 0.6702907203034817
Validation loss: 2.6251045837116718

Epoch: 473| Step: 0
Training loss: 1.0630836006011313
Validation loss: 2.6641817192221473

Epoch: 6| Step: 1
Training loss: 1.6347314974596352
Validation loss: 2.705015406450315

Epoch: 6| Step: 2
Training loss: 0.6571017142486388
Validation loss: 2.7206175230115868

Epoch: 6| Step: 3
Training loss: 1.0231951361067102
Validation loss: 2.7248202026484996

Epoch: 6| Step: 4
Training loss: 0.9093180386246578
Validation loss: 2.6880638750114905

Epoch: 6| Step: 5
Training loss: 0.7216175346814341
Validation loss: 2.689540034386815

Epoch: 6| Step: 6
Training loss: 0.7698955157841936
Validation loss: 2.6820409275080337

Epoch: 6| Step: 7
Training loss: 0.9010398328170783
Validation loss: 2.6311785659327924

Epoch: 6| Step: 8
Training loss: 1.2972305913396986
Validation loss: 2.5870337115017175

Epoch: 6| Step: 9
Training loss: 1.0508785840868733
Validation loss: 2.577089280515145

Epoch: 6| Step: 10
Training loss: 1.134966781567029
Validation loss: 2.6032519014047395

Epoch: 6| Step: 11
Training loss: 1.0206505488546005
Validation loss: 2.6146073890373294

Epoch: 6| Step: 12
Training loss: 1.178129316569953
Validation loss: 2.69553147957633

Epoch: 6| Step: 13
Training loss: 1.153709352465397
Validation loss: 2.704944289297203

Epoch: 474| Step: 0
Training loss: 0.691183496142311
Validation loss: 2.7110270190207415

Epoch: 6| Step: 1
Training loss: 0.7660025230271543
Validation loss: 2.6893395960026045

Epoch: 6| Step: 2
Training loss: 0.8754379675003255
Validation loss: 2.633180178961078

Epoch: 6| Step: 3
Training loss: 0.8687396892786505
Validation loss: 2.68401536108784

Epoch: 6| Step: 4
Training loss: 0.9985965178273306
Validation loss: 2.6593803698281864

Epoch: 6| Step: 5
Training loss: 0.9492280433733593
Validation loss: 2.6262818291469343

Epoch: 6| Step: 6
Training loss: 0.992071700660109
Validation loss: 2.6107334714641706

Epoch: 6| Step: 7
Training loss: 0.9858912038437597
Validation loss: 2.6325276090656757

Epoch: 6| Step: 8
Training loss: 1.9448286933282382
Validation loss: 2.620643960659711

Epoch: 6| Step: 9
Training loss: 1.1506058341050964
Validation loss: 2.6151744694110812

Epoch: 6| Step: 10
Training loss: 0.8581033488054572
Validation loss: 2.651326327387806

Epoch: 6| Step: 11
Training loss: 0.8813500570755909
Validation loss: 2.657275142618221

Epoch: 6| Step: 12
Training loss: 1.3776369818064362
Validation loss: 2.688860360795981

Epoch: 6| Step: 13
Training loss: 0.6346554704601526
Validation loss: 2.663805943872483

Epoch: 475| Step: 0
Training loss: 0.7763710261795823
Validation loss: 2.654068311348433

Epoch: 6| Step: 1
Training loss: 0.5791524057439281
Validation loss: 2.657777032447145

Epoch: 6| Step: 2
Training loss: 1.1839651400099536
Validation loss: 2.677611266917155

Epoch: 6| Step: 3
Training loss: 0.9197165549611326
Validation loss: 2.6480678762995318

Epoch: 6| Step: 4
Training loss: 0.9727888514814766
Validation loss: 2.638491058657755

Epoch: 6| Step: 5
Training loss: 1.1343096606560439
Validation loss: 2.652443297673164

Epoch: 6| Step: 6
Training loss: 1.0730464572857077
Validation loss: 2.666322848115554

Epoch: 6| Step: 7
Training loss: 1.0690442667289668
Validation loss: 2.6663324668362107

Epoch: 6| Step: 8
Training loss: 0.9527989439533252
Validation loss: 2.6381986377709814

Epoch: 6| Step: 9
Training loss: 0.8832482806830647
Validation loss: 2.6758335938052134

Epoch: 6| Step: 10
Training loss: 1.6751125041699697
Validation loss: 2.650037432216802

Epoch: 6| Step: 11
Training loss: 0.9920917975459709
Validation loss: 2.661922183153715

Epoch: 6| Step: 12
Training loss: 0.9202019655852124
Validation loss: 2.650238298972841

Epoch: 6| Step: 13
Training loss: 0.9755667225393608
Validation loss: 2.6859939938633084

Epoch: 476| Step: 0
Training loss: 1.8292992887739654
Validation loss: 2.6563687611040607

Epoch: 6| Step: 1
Training loss: 1.0084719607266726
Validation loss: 2.65254739471335

Epoch: 6| Step: 2
Training loss: 0.9055105678588342
Validation loss: 2.6953818282737037

Epoch: 6| Step: 3
Training loss: 1.1299997597246842
Validation loss: 2.6695853137774566

Epoch: 6| Step: 4
Training loss: 1.0565018483410693
Validation loss: 2.663075666883383

Epoch: 6| Step: 5
Training loss: 1.1517803819349173
Validation loss: 2.6698471536456108

Epoch: 6| Step: 6
Training loss: 0.6026998395043288
Validation loss: 2.6496494629918788

Epoch: 6| Step: 7
Training loss: 0.4687309420208235
Validation loss: 2.6735776235309268

Epoch: 6| Step: 8
Training loss: 0.9698805518686494
Validation loss: 2.6692339568313304

Epoch: 6| Step: 9
Training loss: 1.141489720148291
Validation loss: 2.648768416988602

Epoch: 6| Step: 10
Training loss: 1.2569688135434487
Validation loss: 2.6824446452444493

Epoch: 6| Step: 11
Training loss: 0.5616974403467003
Validation loss: 2.6619513854667853

Epoch: 6| Step: 12
Training loss: 0.8533686810364708
Validation loss: 2.6341810078110544

Epoch: 6| Step: 13
Training loss: 0.8258363299374789
Validation loss: 2.6512456109097724

Epoch: 477| Step: 0
Training loss: 1.0686141970725724
Validation loss: 2.5840474764823536

Epoch: 6| Step: 1
Training loss: 0.7584553774065464
Validation loss: 2.598705204371709

Epoch: 6| Step: 2
Training loss: 0.9384842791919835
Validation loss: 2.5808138987983957

Epoch: 6| Step: 3
Training loss: 0.8074886491881217
Validation loss: 2.59397523378724

Epoch: 6| Step: 4
Training loss: 0.8303413602029309
Validation loss: 2.5905663266722

Epoch: 6| Step: 5
Training loss: 0.7630488593430239
Validation loss: 2.565478252148873

Epoch: 6| Step: 6
Training loss: 0.815317806403546
Validation loss: 2.571207827072649

Epoch: 6| Step: 7
Training loss: 1.491105651136415
Validation loss: 2.573777832401268

Epoch: 6| Step: 8
Training loss: 1.0612906136621292
Validation loss: 2.580440736372518

Epoch: 6| Step: 9
Training loss: 1.0340670631471711
Validation loss: 2.5799768722106795

Epoch: 6| Step: 10
Training loss: 0.8993410956889263
Validation loss: 2.561497832726278

Epoch: 6| Step: 11
Training loss: 1.3019317945672415
Validation loss: 2.6094971244380925

Epoch: 6| Step: 12
Training loss: 1.0416558964490412
Validation loss: 2.595060920374074

Epoch: 6| Step: 13
Training loss: 1.4417600946894868
Validation loss: 2.6343815927290772

Epoch: 478| Step: 0
Training loss: 0.7524354254938536
Validation loss: 2.640967692282007

Epoch: 6| Step: 1
Training loss: 1.102210429217801
Validation loss: 2.6514298968492023

Epoch: 6| Step: 2
Training loss: 0.9722455854484875
Validation loss: 2.634810128908665

Epoch: 6| Step: 3
Training loss: 1.224880158148115
Validation loss: 2.642560827550324

Epoch: 6| Step: 4
Training loss: 1.1092460449918575
Validation loss: 2.631422264230593

Epoch: 6| Step: 5
Training loss: 0.7436753467952055
Validation loss: 2.573641488907707

Epoch: 6| Step: 6
Training loss: 1.434390976760746
Validation loss: 2.602806768585938

Epoch: 6| Step: 7
Training loss: 0.7385616274684308
Validation loss: 2.6396916295613315

Epoch: 6| Step: 8
Training loss: 0.6125446682815732
Validation loss: 2.6477750626784577

Epoch: 6| Step: 9
Training loss: 0.7968706617050261
Validation loss: 2.657598818244426

Epoch: 6| Step: 10
Training loss: 0.8495962558478849
Validation loss: 2.683571373884036

Epoch: 6| Step: 11
Training loss: 1.6336099967714184
Validation loss: 2.7286330428374095

Epoch: 6| Step: 12
Training loss: 0.696324843761991
Validation loss: 2.6853399579683277

Epoch: 6| Step: 13
Training loss: 1.2402019346304833
Validation loss: 2.690174800675038

Epoch: 479| Step: 0
Training loss: 1.1052629798277136
Validation loss: 2.6491212360647407

Epoch: 6| Step: 1
Training loss: 1.078161377223987
Validation loss: 2.6709393206994423

Epoch: 6| Step: 2
Training loss: 0.9280012851040262
Validation loss: 2.637605722868002

Epoch: 6| Step: 3
Training loss: 1.6901238846375621
Validation loss: 2.653410982147585

Epoch: 6| Step: 4
Training loss: 1.1440282764541532
Validation loss: 2.5916899154955577

Epoch: 6| Step: 5
Training loss: 1.1243636132724477
Validation loss: 2.6231745649117375

Epoch: 6| Step: 6
Training loss: 0.9390756399850722
Validation loss: 2.651497874135073

Epoch: 6| Step: 7
Training loss: 0.8469643295865777
Validation loss: 2.6523610996361104

Epoch: 6| Step: 8
Training loss: 1.0008938490025454
Validation loss: 2.6813152545951318

Epoch: 6| Step: 9
Training loss: 0.6495934718990222
Validation loss: 2.701681741089399

Epoch: 6| Step: 10
Training loss: 0.7998931425969781
Validation loss: 2.7389940415428367

Epoch: 6| Step: 11
Training loss: 1.0892239247112836
Validation loss: 2.740034804443864

Epoch: 6| Step: 12
Training loss: 0.7266167241033219
Validation loss: 2.7040331972929788

Epoch: 6| Step: 13
Training loss: 0.9970245201363163
Validation loss: 2.6512724438321316

Epoch: 480| Step: 0
Training loss: 1.7230083771743858
Validation loss: 2.6318656372851668

Epoch: 6| Step: 1
Training loss: 0.9867846650422301
Validation loss: 2.6330067041495875

Epoch: 6| Step: 2
Training loss: 1.3635042986352668
Validation loss: 2.6234188972805503

Epoch: 6| Step: 3
Training loss: 0.7250780096507138
Validation loss: 2.619764925566779

Epoch: 6| Step: 4
Training loss: 0.7223626442463309
Validation loss: 2.652843706529783

Epoch: 6| Step: 5
Training loss: 1.011001627331187
Validation loss: 2.6655535775081542

Epoch: 6| Step: 6
Training loss: 0.9511626632839683
Validation loss: 2.6648351592758375

Epoch: 6| Step: 7
Training loss: 0.770378923937528
Validation loss: 2.6931514014081

Epoch: 6| Step: 8
Training loss: 1.0895266054361623
Validation loss: 2.6794991605372456

Epoch: 6| Step: 9
Training loss: 0.5838129053387032
Validation loss: 2.6646202234233383

Epoch: 6| Step: 10
Training loss: 0.9543501062650247
Validation loss: 2.677294594522547

Epoch: 6| Step: 11
Training loss: 1.0877771506720626
Validation loss: 2.703166355089613

Epoch: 6| Step: 12
Training loss: 0.9576751411356028
Validation loss: 2.6909500607731243

Epoch: 6| Step: 13
Training loss: 0.9075457747398411
Validation loss: 2.6558306328600665

Epoch: 481| Step: 0
Training loss: 1.046905744869784
Validation loss: 2.659124335695062

Epoch: 6| Step: 1
Training loss: 0.46983662860270026
Validation loss: 2.6351097213853603

Epoch: 6| Step: 2
Training loss: 1.7625634310515537
Validation loss: 2.5601307911110056

Epoch: 6| Step: 3
Training loss: 0.7308241851506662
Validation loss: 2.5757962804165038

Epoch: 6| Step: 4
Training loss: 0.8811423445612728
Validation loss: 2.5618378078495674

Epoch: 6| Step: 5
Training loss: 1.2581940066443302
Validation loss: 2.6455250451359134

Epoch: 6| Step: 6
Training loss: 1.2646702120169369
Validation loss: 2.6173393968249647

Epoch: 6| Step: 7
Training loss: 0.7853596741685039
Validation loss: 2.6604429406758916

Epoch: 6| Step: 8
Training loss: 0.8163132317953536
Validation loss: 2.699580083420786

Epoch: 6| Step: 9
Training loss: 1.1650652566732598
Validation loss: 2.7191579227694667

Epoch: 6| Step: 10
Training loss: 0.8206122077938469
Validation loss: 2.6980647951803323

Epoch: 6| Step: 11
Training loss: 1.1913158945309736
Validation loss: 2.706372825709208

Epoch: 6| Step: 12
Training loss: 0.9405197781739861
Validation loss: 2.654205127269404

Epoch: 6| Step: 13
Training loss: 0.29039929557378574
Validation loss: 2.6327139550351957

Epoch: 482| Step: 0
Training loss: 1.3272710859988077
Validation loss: 2.6510508392663326

Epoch: 6| Step: 1
Training loss: 0.41279685725015647
Validation loss: 2.637025751360003

Epoch: 6| Step: 2
Training loss: 1.065539164735862
Validation loss: 2.6066171456716685

Epoch: 6| Step: 3
Training loss: 1.1651108392698604
Validation loss: 2.6218461820128534

Epoch: 6| Step: 4
Training loss: 0.9295495195335947
Validation loss: 2.638351775513615

Epoch: 6| Step: 5
Training loss: 1.0545602227166457
Validation loss: 2.6254315273065885

Epoch: 6| Step: 6
Training loss: 0.8016756227023414
Validation loss: 2.6638211872455746

Epoch: 6| Step: 7
Training loss: 1.3147464328593441
Validation loss: 2.749264671928898

Epoch: 6| Step: 8
Training loss: 0.3445070448523291
Validation loss: 2.6978801940690116

Epoch: 6| Step: 9
Training loss: 0.8322141562707465
Validation loss: 2.6780338150594196

Epoch: 6| Step: 10
Training loss: 1.4934009191994286
Validation loss: 2.6207241151473766

Epoch: 6| Step: 11
Training loss: 0.9354083251297999
Validation loss: 2.61364494682082

Epoch: 6| Step: 12
Training loss: 1.2489417364795707
Validation loss: 2.6254433200416485

Epoch: 6| Step: 13
Training loss: 0.6793449459429516
Validation loss: 2.6202171308181503

Epoch: 483| Step: 0
Training loss: 0.9591038274079909
Validation loss: 2.6227447934693044

Epoch: 6| Step: 1
Training loss: 1.0963753934543552
Validation loss: 2.615050419537615

Epoch: 6| Step: 2
Training loss: 0.4919934874332302
Validation loss: 2.645306877281099

Epoch: 6| Step: 3
Training loss: 1.2237935489624783
Validation loss: 2.624025760777546

Epoch: 6| Step: 4
Training loss: 0.9160985197450263
Validation loss: 2.6450362461076273

Epoch: 6| Step: 5
Training loss: 1.0430714417382374
Validation loss: 2.649219576664581

Epoch: 6| Step: 6
Training loss: 1.7578118218314664
Validation loss: 2.6393402074921752

Epoch: 6| Step: 7
Training loss: 0.8146930588158356
Validation loss: 2.602221416501999

Epoch: 6| Step: 8
Training loss: 0.9960507551899753
Validation loss: 2.633714503558393

Epoch: 6| Step: 9
Training loss: 0.8049305669090693
Validation loss: 2.649132627219147

Epoch: 6| Step: 10
Training loss: 0.8646173968364808
Validation loss: 2.625244392937007

Epoch: 6| Step: 11
Training loss: 0.7484907621095181
Validation loss: 2.6590542443150764

Epoch: 6| Step: 12
Training loss: 0.9961490391365176
Validation loss: 2.6930213362779267

Epoch: 6| Step: 13
Training loss: 1.0659734385618436
Validation loss: 2.7420490618978293

Epoch: 484| Step: 0
Training loss: 0.933604635390662
Validation loss: 2.7050102772979114

Epoch: 6| Step: 1
Training loss: 1.016863962217892
Validation loss: 2.685402973753376

Epoch: 6| Step: 2
Training loss: 1.074326554871078
Validation loss: 2.6816788072519713

Epoch: 6| Step: 3
Training loss: 0.8009954770730822
Validation loss: 2.585789503901158

Epoch: 6| Step: 4
Training loss: 0.7978316156328862
Validation loss: 2.5950502787766725

Epoch: 6| Step: 5
Training loss: 0.7919970040698174
Validation loss: 2.629777144683986

Epoch: 6| Step: 6
Training loss: 1.029558933781487
Validation loss: 2.608950777860678

Epoch: 6| Step: 7
Training loss: 0.6440788762260871
Validation loss: 2.654978516949854

Epoch: 6| Step: 8
Training loss: 0.8213339486029517
Validation loss: 2.62624820794269

Epoch: 6| Step: 9
Training loss: 1.8139612292822334
Validation loss: 2.701189599452708

Epoch: 6| Step: 10
Training loss: 1.256188760280143
Validation loss: 2.7639463648910216

Epoch: 6| Step: 11
Training loss: 0.8290057986324703
Validation loss: 2.7468079735508804

Epoch: 6| Step: 12
Training loss: 1.0974615609947453
Validation loss: 2.7291855816505426

Epoch: 6| Step: 13
Training loss: 0.4387009180497615
Validation loss: 2.693710053866757

Epoch: 485| Step: 0
Training loss: 0.9457812762674013
Validation loss: 2.648760797005056

Epoch: 6| Step: 1
Training loss: 1.019055076274953
Validation loss: 2.673081014107968

Epoch: 6| Step: 2
Training loss: 0.8037173153889559
Validation loss: 2.6330101917801585

Epoch: 6| Step: 3
Training loss: 1.549428816118857
Validation loss: 2.6382213122325124

Epoch: 6| Step: 4
Training loss: 1.224542010582386
Validation loss: 2.604352420867972

Epoch: 6| Step: 5
Training loss: 0.934734206542423
Validation loss: 2.5944369182755795

Epoch: 6| Step: 6
Training loss: 0.46604682005771536
Validation loss: 2.627118828381077

Epoch: 6| Step: 7
Training loss: 1.1888966628936566
Validation loss: 2.6315860778310443

Epoch: 6| Step: 8
Training loss: 1.0196068395896292
Validation loss: 2.6754454114922823

Epoch: 6| Step: 9
Training loss: 1.0723978041040518
Validation loss: 2.6651106692722335

Epoch: 6| Step: 10
Training loss: 1.0436744160039058
Validation loss: 2.670285724995356

Epoch: 6| Step: 11
Training loss: 0.8325587288586607
Validation loss: 2.6953516946147986

Epoch: 6| Step: 12
Training loss: 0.5900652387482932
Validation loss: 2.6563402916982057

Epoch: 6| Step: 13
Training loss: 0.6642310657853551
Validation loss: 2.6962362847918833

Epoch: 486| Step: 0
Training loss: 0.9163407844646638
Validation loss: 2.7025548876805447

Epoch: 6| Step: 1
Training loss: 0.6857937534015528
Validation loss: 2.6980935920580977

Epoch: 6| Step: 2
Training loss: 0.813865467909188
Validation loss: 2.7336942607635315

Epoch: 6| Step: 3
Training loss: 0.819119375932871
Validation loss: 2.6629542541996014

Epoch: 6| Step: 4
Training loss: 0.8800144245309319
Validation loss: 2.647724332070791

Epoch: 6| Step: 5
Training loss: 1.4441288405606467
Validation loss: 2.637381193075244

Epoch: 6| Step: 6
Training loss: 1.0773412094473536
Validation loss: 2.641121348933711

Epoch: 6| Step: 7
Training loss: 0.989692012775372
Validation loss: 2.6116032603141077

Epoch: 6| Step: 8
Training loss: 0.9841893944523721
Validation loss: 2.5860795129312795

Epoch: 6| Step: 9
Training loss: 0.9776443287575438
Validation loss: 2.6360227153964595

Epoch: 6| Step: 10
Training loss: 0.9561790564655641
Validation loss: 2.640037085262411

Epoch: 6| Step: 11
Training loss: 1.1591057950694204
Validation loss: 2.6841637492846355

Epoch: 6| Step: 12
Training loss: 1.2759370670135683
Validation loss: 2.655437868916435

Epoch: 6| Step: 13
Training loss: 0.6234738791040968
Validation loss: 2.641583889868065

Epoch: 487| Step: 0
Training loss: 0.9657553871788602
Validation loss: 2.6690035861751613

Epoch: 6| Step: 1
Training loss: 0.7384937525506258
Validation loss: 2.6314583810616763

Epoch: 6| Step: 2
Training loss: 1.0644906973551034
Validation loss: 2.618285910152371

Epoch: 6| Step: 3
Training loss: 1.0653575169973821
Validation loss: 2.63719579515702

Epoch: 6| Step: 4
Training loss: 0.7967734552646911
Validation loss: 2.6195969338082925

Epoch: 6| Step: 5
Training loss: 1.2545069506419582
Validation loss: 2.6223345660972757

Epoch: 6| Step: 6
Training loss: 0.9356093097153455
Validation loss: 2.6586549858321886

Epoch: 6| Step: 7
Training loss: 0.8587857393604328
Validation loss: 2.6390115481289134

Epoch: 6| Step: 8
Training loss: 0.6776759977236181
Validation loss: 2.621085819711464

Epoch: 6| Step: 9
Training loss: 0.8420847247938174
Validation loss: 2.649315790565827

Epoch: 6| Step: 10
Training loss: 1.6459514076597015
Validation loss: 2.6770068250636982

Epoch: 6| Step: 11
Training loss: 0.7151192306261824
Validation loss: 2.6571585171002585

Epoch: 6| Step: 12
Training loss: 0.6025010750788677
Validation loss: 2.630080443280053

Epoch: 6| Step: 13
Training loss: 1.2752872442667198
Validation loss: 2.632847081687539

Epoch: 488| Step: 0
Training loss: 0.9730629434564346
Validation loss: 2.599349388514739

Epoch: 6| Step: 1
Training loss: 0.7978761031860202
Validation loss: 2.6422186737250377

Epoch: 6| Step: 2
Training loss: 1.5344499899880386
Validation loss: 2.6337257890587034

Epoch: 6| Step: 3
Training loss: 0.9917459782104644
Validation loss: 2.642194452028777

Epoch: 6| Step: 4
Training loss: 0.38113569359620425
Validation loss: 2.646773499667479

Epoch: 6| Step: 5
Training loss: 1.3249069271147549
Validation loss: 2.6453480929994555

Epoch: 6| Step: 6
Training loss: 0.9079851442667812
Validation loss: 2.667490509530221

Epoch: 6| Step: 7
Training loss: 0.8079858973802051
Validation loss: 2.709207849060639

Epoch: 6| Step: 8
Training loss: 0.8220619076158455
Validation loss: 2.6776942303081706

Epoch: 6| Step: 9
Training loss: 0.865253525773883
Validation loss: 2.6671557402568786

Epoch: 6| Step: 10
Training loss: 1.2179243274195042
Validation loss: 2.675085357770079

Epoch: 6| Step: 11
Training loss: 0.8318600903901002
Validation loss: 2.6618339887210714

Epoch: 6| Step: 12
Training loss: 1.0370487403745374
Validation loss: 2.5951228545532756

Epoch: 6| Step: 13
Training loss: 0.7088394647475547
Validation loss: 2.632230557848018

Epoch: 489| Step: 0
Training loss: 0.989885558439956
Validation loss: 2.6617770894625647

Epoch: 6| Step: 1
Training loss: 0.47101066957525417
Validation loss: 2.660081516469114

Epoch: 6| Step: 2
Training loss: 0.9970663670266575
Validation loss: 2.6734298809414714

Epoch: 6| Step: 3
Training loss: 0.7432920568777975
Validation loss: 2.6603451069802704

Epoch: 6| Step: 4
Training loss: 0.8691591410861244
Validation loss: 2.697689694113838

Epoch: 6| Step: 5
Training loss: 0.8884081774155344
Validation loss: 2.6511245451229186

Epoch: 6| Step: 6
Training loss: 1.5549107683589414
Validation loss: 2.625682238215096

Epoch: 6| Step: 7
Training loss: 1.0853951835824902
Validation loss: 2.577982686111988

Epoch: 6| Step: 8
Training loss: 0.893746043910094
Validation loss: 2.5928434252154626

Epoch: 6| Step: 9
Training loss: 0.8303316694005861
Validation loss: 2.6113170293710204

Epoch: 6| Step: 10
Training loss: 1.1368562805245235
Validation loss: 2.5817303270491765

Epoch: 6| Step: 11
Training loss: 0.9109511281166941
Validation loss: 2.6102054103064325

Epoch: 6| Step: 12
Training loss: 0.9841193215278911
Validation loss: 2.6244856383698854

Epoch: 6| Step: 13
Training loss: 0.9828642802706049
Validation loss: 2.6287479052776836

Epoch: 490| Step: 0
Training loss: 1.0704527157456973
Validation loss: 2.646956554105188

Epoch: 6| Step: 1
Training loss: 0.7903649939211805
Validation loss: 2.6873507127938945

Epoch: 6| Step: 2
Training loss: 0.3340277169642368
Validation loss: 2.7087701446809156

Epoch: 6| Step: 3
Training loss: 0.878291919903363
Validation loss: 2.738203606091263

Epoch: 6| Step: 4
Training loss: 1.0695672329408001
Validation loss: 2.762684589099361

Epoch: 6| Step: 5
Training loss: 1.0308205259345233
Validation loss: 2.716813757363391

Epoch: 6| Step: 6
Training loss: 0.9270020817215805
Validation loss: 2.715239766899396

Epoch: 6| Step: 7
Training loss: 1.0441862850573727
Validation loss: 2.6690176261100658

Epoch: 6| Step: 8
Training loss: 0.9310244715984862
Validation loss: 2.6288274118629373

Epoch: 6| Step: 9
Training loss: 0.9407627866587153
Validation loss: 2.6198216657589213

Epoch: 6| Step: 10
Training loss: 0.9552251472504779
Validation loss: 2.5924085421437852

Epoch: 6| Step: 11
Training loss: 1.4533828998710887
Validation loss: 2.6584713357439633

Epoch: 6| Step: 12
Training loss: 1.0552179203683725
Validation loss: 2.621777379205951

Epoch: 6| Step: 13
Training loss: 0.9257124541269159
Validation loss: 2.6104420315091454

Epoch: 491| Step: 0
Training loss: 0.8805544847855608
Validation loss: 2.645088516005102

Epoch: 6| Step: 1
Training loss: 0.8857954486618028
Validation loss: 2.6185906542673445

Epoch: 6| Step: 2
Training loss: 0.942591573885645
Validation loss: 2.64231674584486

Epoch: 6| Step: 3
Training loss: 1.2292136921480965
Validation loss: 2.6536205018868557

Epoch: 6| Step: 4
Training loss: 0.5965488121736444
Validation loss: 2.678172651238312

Epoch: 6| Step: 5
Training loss: 0.5676769341234477
Validation loss: 2.6830328339781566

Epoch: 6| Step: 6
Training loss: 1.6593261079356303
Validation loss: 2.691439426356412

Epoch: 6| Step: 7
Training loss: 0.6806928718851595
Validation loss: 2.6688208854728868

Epoch: 6| Step: 8
Training loss: 0.9620092974152035
Validation loss: 2.657907483008347

Epoch: 6| Step: 9
Training loss: 0.8437352355795531
Validation loss: 2.616148975353908

Epoch: 6| Step: 10
Training loss: 1.0770359897108008
Validation loss: 2.634279735352394

Epoch: 6| Step: 11
Training loss: 0.6720728472013603
Validation loss: 2.682634178886754

Epoch: 6| Step: 12
Training loss: 0.9041905515712494
Validation loss: 2.654793377691804

Epoch: 6| Step: 13
Training loss: 1.2132618899498724
Validation loss: 2.6676221707193397

Epoch: 492| Step: 0
Training loss: 0.8790700802169399
Validation loss: 2.7022550056451555

Epoch: 6| Step: 1
Training loss: 0.7560234581723941
Validation loss: 2.706669405311392

Epoch: 6| Step: 2
Training loss: 0.9972700167483413
Validation loss: 2.7105552519931364

Epoch: 6| Step: 3
Training loss: 0.9047632189014518
Validation loss: 2.6768066721676234

Epoch: 6| Step: 4
Training loss: 0.8198677673951384
Validation loss: 2.66227409004829

Epoch: 6| Step: 5
Training loss: 0.7859352763999593
Validation loss: 2.662946165535931

Epoch: 6| Step: 6
Training loss: 1.6342359844772127
Validation loss: 2.662944007142829

Epoch: 6| Step: 7
Training loss: 0.5831756094735382
Validation loss: 2.6056554608446745

Epoch: 6| Step: 8
Training loss: 0.9900376464929951
Validation loss: 2.614855697977441

Epoch: 6| Step: 9
Training loss: 0.9405823263836243
Validation loss: 2.589825594504053

Epoch: 6| Step: 10
Training loss: 1.1738082706340083
Validation loss: 2.622374797689059

Epoch: 6| Step: 11
Training loss: 0.6543933398747269
Validation loss: 2.610769509214861

Epoch: 6| Step: 12
Training loss: 1.1011174703083564
Validation loss: 2.6452663470737017

Epoch: 6| Step: 13
Training loss: 0.8704694897400824
Validation loss: 2.670722193166337

Epoch: 493| Step: 0
Training loss: 1.075839730462149
Validation loss: 2.7151156546857695

Epoch: 6| Step: 1
Training loss: 0.8802480331286249
Validation loss: 2.758857239826287

Epoch: 6| Step: 2
Training loss: 1.633880484987884
Validation loss: 2.7279830303473274

Epoch: 6| Step: 3
Training loss: 0.8584910962260162
Validation loss: 2.688550123411908

Epoch: 6| Step: 4
Training loss: 0.92248262973135
Validation loss: 2.65720996436273

Epoch: 6| Step: 5
Training loss: 0.9235072153178229
Validation loss: 2.642557950128474

Epoch: 6| Step: 6
Training loss: 0.9688553291403784
Validation loss: 2.63156828922948

Epoch: 6| Step: 7
Training loss: 1.136492572318768
Validation loss: 2.6200557414101655

Epoch: 6| Step: 8
Training loss: 1.162684604384642
Validation loss: 2.6155714981680727

Epoch: 6| Step: 9
Training loss: 0.6865674977387609
Validation loss: 2.6346949829029707

Epoch: 6| Step: 10
Training loss: 0.9285467185149131
Validation loss: 2.6314728366181623

Epoch: 6| Step: 11
Training loss: 0.6443901832412371
Validation loss: 2.6452057042108605

Epoch: 6| Step: 12
Training loss: 0.5694447277683494
Validation loss: 2.6899244014548342

Epoch: 6| Step: 13
Training loss: 0.4719266541105813
Validation loss: 2.7179814318937265

Epoch: 494| Step: 0
Training loss: 0.9831989468594491
Validation loss: 2.743989377522418

Epoch: 6| Step: 1
Training loss: 0.7302757048896876
Validation loss: 2.7532345779675658

Epoch: 6| Step: 2
Training loss: 0.9836335190057367
Validation loss: 2.7247829241286157

Epoch: 6| Step: 3
Training loss: 0.7863775215987738
Validation loss: 2.7281484770351114

Epoch: 6| Step: 4
Training loss: 0.9260122920305973
Validation loss: 2.6918117431394957

Epoch: 6| Step: 5
Training loss: 0.47343114905299444
Validation loss: 2.6395938318866428

Epoch: 6| Step: 6
Training loss: 0.8441136247729047
Validation loss: 2.634380087270184

Epoch: 6| Step: 7
Training loss: 0.940733419867799
Validation loss: 2.5720155591135434

Epoch: 6| Step: 8
Training loss: 0.7864458491532396
Validation loss: 2.581757902322823

Epoch: 6| Step: 9
Training loss: 0.7015713162282411
Validation loss: 2.59605339635895

Epoch: 6| Step: 10
Training loss: 0.9836708759735733
Validation loss: 2.634006861650151

Epoch: 6| Step: 11
Training loss: 0.9552732553054863
Validation loss: 2.6512371403524804

Epoch: 6| Step: 12
Training loss: 1.212403032023818
Validation loss: 2.6834928358036065

Epoch: 6| Step: 13
Training loss: 2.1146251755757355
Validation loss: 2.690187818612816

Epoch: 495| Step: 0
Training loss: 0.9743460871020211
Validation loss: 2.7367067329166996

Epoch: 6| Step: 1
Training loss: 0.6983346304354158
Validation loss: 2.7629623447875002

Epoch: 6| Step: 2
Training loss: 0.927556970599753
Validation loss: 2.76564915663121

Epoch: 6| Step: 3
Training loss: 0.8123145992319141
Validation loss: 2.7197985571332786

Epoch: 6| Step: 4
Training loss: 0.6018397200277312
Validation loss: 2.6168900329482043

Epoch: 6| Step: 5
Training loss: 0.8247428059652998
Validation loss: 2.584771681446333

Epoch: 6| Step: 6
Training loss: 1.5109011782804245
Validation loss: 2.5572292065538984

Epoch: 6| Step: 7
Training loss: 0.9037627255399893
Validation loss: 2.5731051490845687

Epoch: 6| Step: 8
Training loss: 0.9523173490499605
Validation loss: 2.557841148929896

Epoch: 6| Step: 9
Training loss: 1.059572337627673
Validation loss: 2.586875317940871

Epoch: 6| Step: 10
Training loss: 1.1690372950312886
Validation loss: 2.634643970271158

Epoch: 6| Step: 11
Training loss: 1.0090548524303908
Validation loss: 2.6511086398393515

Epoch: 6| Step: 12
Training loss: 1.051072658136094
Validation loss: 2.671874771641077

Epoch: 6| Step: 13
Training loss: 0.9864266223637638
Validation loss: 2.7196556405641723

Epoch: 496| Step: 0
Training loss: 0.5945009201273683
Validation loss: 2.6905656658609334

Epoch: 6| Step: 1
Training loss: 0.6484398209863512
Validation loss: 2.702529121713977

Epoch: 6| Step: 2
Training loss: 0.905890722419166
Validation loss: 2.673032425373304

Epoch: 6| Step: 3
Training loss: 1.040969475444291
Validation loss: 2.632748531200888

Epoch: 6| Step: 4
Training loss: 0.9271348803187759
Validation loss: 2.6338377400821393

Epoch: 6| Step: 5
Training loss: 1.496637310357547
Validation loss: 2.650664241598065

Epoch: 6| Step: 6
Training loss: 1.071949952288152
Validation loss: 2.617651217377441

Epoch: 6| Step: 7
Training loss: 0.6548458927440789
Validation loss: 2.6757911978353244

Epoch: 6| Step: 8
Training loss: 1.0566741881619297
Validation loss: 2.648758391861534

Epoch: 6| Step: 9
Training loss: 0.6995982626624043
Validation loss: 2.6755919246163855

Epoch: 6| Step: 10
Training loss: 1.0532872830557543
Validation loss: 2.708158967973656

Epoch: 6| Step: 11
Training loss: 0.9516772233930877
Validation loss: 2.6831205867131778

Epoch: 6| Step: 12
Training loss: 0.8394744060902213
Validation loss: 2.7000146217892174

Epoch: 6| Step: 13
Training loss: 1.2252007475649862
Validation loss: 2.6969212174663224

Epoch: 497| Step: 0
Training loss: 1.6394965514402426
Validation loss: 2.724779371437036

Epoch: 6| Step: 1
Training loss: 0.7109700289819506
Validation loss: 2.6794255214484877

Epoch: 6| Step: 2
Training loss: 0.8938226683624877
Validation loss: 2.6743477676451013

Epoch: 6| Step: 3
Training loss: 0.9364741434722367
Validation loss: 2.6794134204522497

Epoch: 6| Step: 4
Training loss: 0.7275635171146982
Validation loss: 2.661251631213427

Epoch: 6| Step: 5
Training loss: 0.9050146430501176
Validation loss: 2.665828799766799

Epoch: 6| Step: 6
Training loss: 0.7280432675703404
Validation loss: 2.664789591564031

Epoch: 6| Step: 7
Training loss: 1.022131807681311
Validation loss: 2.6375749563462048

Epoch: 6| Step: 8
Training loss: 1.009791715126254
Validation loss: 2.6467418323682725

Epoch: 6| Step: 9
Training loss: 0.7777118673856568
Validation loss: 2.660619871707457

Epoch: 6| Step: 10
Training loss: 1.02589947381661
Validation loss: 2.692279961461327

Epoch: 6| Step: 11
Training loss: 0.5669024431594875
Validation loss: 2.7054057071785276

Epoch: 6| Step: 12
Training loss: 0.8540651136987125
Validation loss: 2.67323641300642

Epoch: 6| Step: 13
Training loss: 1.1224424643097435
Validation loss: 2.707807912730876

Epoch: 498| Step: 0
Training loss: 1.5589005017831763
Validation loss: 2.726208923734233

Epoch: 6| Step: 1
Training loss: 0.8178584857936787
Validation loss: 2.6739702101213196

Epoch: 6| Step: 2
Training loss: 1.215159041038664
Validation loss: 2.6434004972949867

Epoch: 6| Step: 3
Training loss: 0.9992318779602695
Validation loss: 2.618815943926616

Epoch: 6| Step: 4
Training loss: 0.9401248108912206
Validation loss: 2.6125759047982036

Epoch: 6| Step: 5
Training loss: 0.7975728961908822
Validation loss: 2.583041472988837

Epoch: 6| Step: 6
Training loss: 0.8339312712939865
Validation loss: 2.6064199026382657

Epoch: 6| Step: 7
Training loss: 0.8628769700371729
Validation loss: 2.6167816391059433

Epoch: 6| Step: 8
Training loss: 0.8009446884469713
Validation loss: 2.6214435351884036

Epoch: 6| Step: 9
Training loss: 0.9335361287359172
Validation loss: 2.711968195060546

Epoch: 6| Step: 10
Training loss: 0.7269668274438218
Validation loss: 2.7137467152142167

Epoch: 6| Step: 11
Training loss: 1.0343827722724188
Validation loss: 2.725448713287485

Epoch: 6| Step: 12
Training loss: 0.34589053316740215
Validation loss: 2.7463021218069876

Epoch: 6| Step: 13
Training loss: 0.9384211465310676
Validation loss: 2.727417340527757

Epoch: 499| Step: 0
Training loss: 0.5484208737540307
Validation loss: 2.6965902715820875

Epoch: 6| Step: 1
Training loss: 0.7035894343552801
Validation loss: 2.699277929604056

Epoch: 6| Step: 2
Training loss: 0.6227883786259536
Validation loss: 2.6754590391312933

Epoch: 6| Step: 3
Training loss: 1.2490765498413563
Validation loss: 2.6765664049537237

Epoch: 6| Step: 4
Training loss: 0.4959834719661304
Validation loss: 2.661231759745488

Epoch: 6| Step: 5
Training loss: 0.9030587142325345
Validation loss: 2.6638130088244143

Epoch: 6| Step: 6
Training loss: 0.5036718133684053
Validation loss: 2.6564061986948806

Epoch: 6| Step: 7
Training loss: 0.8616534459952466
Validation loss: 2.64374586302987

Epoch: 6| Step: 8
Training loss: 1.3014019009538893
Validation loss: 2.647201564779825

Epoch: 6| Step: 9
Training loss: 1.6669286124694165
Validation loss: 2.6357473911439397

Epoch: 6| Step: 10
Training loss: 0.4389990940671189
Validation loss: 2.644459099549601

Epoch: 6| Step: 11
Training loss: 1.0324348809718051
Validation loss: 2.645192577808304

Epoch: 6| Step: 12
Training loss: 0.9662461687137895
Validation loss: 2.6406906439178788

Epoch: 6| Step: 13
Training loss: 0.9017690504603685
Validation loss: 2.6842481557380937

Epoch: 500| Step: 0
Training loss: 0.9493192140765105
Validation loss: 2.672649344498521

Epoch: 6| Step: 1
Training loss: 0.548437067450111
Validation loss: 2.650606935240315

Epoch: 6| Step: 2
Training loss: 0.48683969945096106
Validation loss: 2.675810863695375

Epoch: 6| Step: 3
Training loss: 1.0235072687260858
Validation loss: 2.7046179138021635

Epoch: 6| Step: 4
Training loss: 0.5791795494741665
Validation loss: 2.6879540622890574

Epoch: 6| Step: 5
Training loss: 1.7559838850198664
Validation loss: 2.737453005006128

Epoch: 6| Step: 6
Training loss: 1.0633022981756426
Validation loss: 2.7045548641908796

Epoch: 6| Step: 7
Training loss: 0.6178696640960375
Validation loss: 2.7020604924661247

Epoch: 6| Step: 8
Training loss: 1.2106933347590867
Validation loss: 2.7119664783837516

Epoch: 6| Step: 9
Training loss: 0.2927761843745247
Validation loss: 2.6810084681568527

Epoch: 6| Step: 10
Training loss: 0.879278248369754
Validation loss: 2.6980743720030067

Epoch: 6| Step: 11
Training loss: 0.9171792064077322
Validation loss: 2.671963622897377

Epoch: 6| Step: 12
Training loss: 1.135478178452076
Validation loss: 2.6739399598041818

Epoch: 6| Step: 13
Training loss: 0.31401451987435425
Validation loss: 2.6747574263907556

Epoch: 501| Step: 0
Training loss: 0.97697275318194
Validation loss: 2.688767578043437

Epoch: 6| Step: 1
Training loss: 0.9538552660364843
Validation loss: 2.655506925260179

Epoch: 6| Step: 2
Training loss: 0.8706830001428898
Validation loss: 2.6743739086501344

Epoch: 6| Step: 3
Training loss: 1.1799076708540004
Validation loss: 2.6645022909682115

Epoch: 6| Step: 4
Training loss: 0.9302458488927384
Validation loss: 2.6516953335000446

Epoch: 6| Step: 5
Training loss: 0.6623731104774686
Validation loss: 2.67136905842684

Epoch: 6| Step: 6
Training loss: 0.8849881799630526
Validation loss: 2.6794602487796886

Epoch: 6| Step: 7
Training loss: 0.5108358322858232
Validation loss: 2.706311687865375

Epoch: 6| Step: 8
Training loss: 0.881520701826865
Validation loss: 2.6897786995248967

Epoch: 6| Step: 9
Training loss: 0.8390266879660037
Validation loss: 2.720748340457793

Epoch: 6| Step: 10
Training loss: 0.8035548117599848
Validation loss: 2.7164049474573084

Epoch: 6| Step: 11
Training loss: 1.608027366168082
Validation loss: 2.622697937055184

Epoch: 6| Step: 12
Training loss: 0.6328054357063739
Validation loss: 2.684769607781407

Epoch: 6| Step: 13
Training loss: 0.575497559181824
Validation loss: 2.6248480659576843

Epoch: 502| Step: 0
Training loss: 1.5473910925386065
Validation loss: 2.608379990494151

Epoch: 6| Step: 1
Training loss: 1.0295039914995419
Validation loss: 2.6193291183965104

Epoch: 6| Step: 2
Training loss: 1.0078952962295344
Validation loss: 2.6005085140999427

Epoch: 6| Step: 3
Training loss: 0.3865297414334028
Validation loss: 2.6558483913191195

Epoch: 6| Step: 4
Training loss: 0.8726073658637754
Validation loss: 2.693103567927937

Epoch: 6| Step: 5
Training loss: 0.4920472444785665
Validation loss: 2.692154759819244

Epoch: 6| Step: 6
Training loss: 0.9011941167089951
Validation loss: 2.659757857668228

Epoch: 6| Step: 7
Training loss: 0.8218493642543806
Validation loss: 2.702339409589717

Epoch: 6| Step: 8
Training loss: 0.7750528978937753
Validation loss: 2.635747729623601

Epoch: 6| Step: 9
Training loss: 0.709462910721091
Validation loss: 2.6083438322544032

Epoch: 6| Step: 10
Training loss: 0.9720193700489074
Validation loss: 2.6117195093000927

Epoch: 6| Step: 11
Training loss: 1.070167086113768
Validation loss: 2.5615762055357303

Epoch: 6| Step: 12
Training loss: 1.0546539301298112
Validation loss: 2.572188294999047

Epoch: 6| Step: 13
Training loss: 0.9805985930894675
Validation loss: 2.6315637465897734

Epoch: 503| Step: 0
Training loss: 0.9486391786326757
Validation loss: 2.679474334384523

Epoch: 6| Step: 1
Training loss: 0.9601089503135402
Validation loss: 2.738432810873132

Epoch: 6| Step: 2
Training loss: 0.9754754386695758
Validation loss: 2.757316162861402

Epoch: 6| Step: 3
Training loss: 1.0262988908949227
Validation loss: 2.7183172862030935

Epoch: 6| Step: 4
Training loss: 0.7657714625808993
Validation loss: 2.7273759137207407

Epoch: 6| Step: 5
Training loss: 0.6844433110254916
Validation loss: 2.657507345611404

Epoch: 6| Step: 6
Training loss: 0.9420208646018651
Validation loss: 2.6738549316853506

Epoch: 6| Step: 7
Training loss: 0.7243858465611964
Validation loss: 2.638580575478979

Epoch: 6| Step: 8
Training loss: 1.6046969375407119
Validation loss: 2.626071715062298

Epoch: 6| Step: 9
Training loss: 1.07972951716192
Validation loss: 2.623080803073544

Epoch: 6| Step: 10
Training loss: 0.8941848283992955
Validation loss: 2.6373942436551543

Epoch: 6| Step: 11
Training loss: 0.6286769709635955
Validation loss: 2.6733834211838063

Epoch: 6| Step: 12
Training loss: 0.7788790010298385
Validation loss: 2.667334301079994

Epoch: 6| Step: 13
Training loss: 0.36217652802062394
Validation loss: 2.6811789591211435

Epoch: 504| Step: 0
Training loss: 0.860866639255222
Validation loss: 2.667888390013936

Epoch: 6| Step: 1
Training loss: 0.8671241943346834
Validation loss: 2.6684162843924217

Epoch: 6| Step: 2
Training loss: 0.929626975774108
Validation loss: 2.6919496411193515

Epoch: 6| Step: 3
Training loss: 0.8415697680930418
Validation loss: 2.7029557984531842

Epoch: 6| Step: 4
Training loss: 1.0198370814642368
Validation loss: 2.7008356902113446

Epoch: 6| Step: 5
Training loss: 0.662482142657604
Validation loss: 2.6656077561603766

Epoch: 6| Step: 6
Training loss: 0.6896911512795898
Validation loss: 2.656021357328504

Epoch: 6| Step: 7
Training loss: 0.6205988657770417
Validation loss: 2.681016008916929

Epoch: 6| Step: 8
Training loss: 0.9119933746875237
Validation loss: 2.687661874126224

Epoch: 6| Step: 9
Training loss: 1.6167971374850671
Validation loss: 2.6561556910952877

Epoch: 6| Step: 10
Training loss: 0.5209376866386642
Validation loss: 2.6947041437725603

Epoch: 6| Step: 11
Training loss: 1.1033388789595564
Validation loss: 2.6702691888312238

Epoch: 6| Step: 12
Training loss: 0.9387269574218667
Validation loss: 2.6633175063344154

Epoch: 6| Step: 13
Training loss: 0.5656393186326991
Validation loss: 2.6806081520545555

Epoch: 505| Step: 0
Training loss: 1.585151740792048
Validation loss: 2.633179986190044

Epoch: 6| Step: 1
Training loss: 0.7700801382844438
Validation loss: 2.643198503750536

Epoch: 6| Step: 2
Training loss: 0.766746283799237
Validation loss: 2.62422875238687

Epoch: 6| Step: 3
Training loss: 0.8765107804270313
Validation loss: 2.6522222065757157

Epoch: 6| Step: 4
Training loss: 1.0900321442125296
Validation loss: 2.605067381766103

Epoch: 6| Step: 5
Training loss: 0.9570538576530944
Validation loss: 2.6486528614987206

Epoch: 6| Step: 6
Training loss: 0.981558722021489
Validation loss: 2.626240645613837

Epoch: 6| Step: 7
Training loss: 0.635910879041892
Validation loss: 2.6521283518244494

Epoch: 6| Step: 8
Training loss: 0.3105598782869943
Validation loss: 2.6451787855176017

Epoch: 6| Step: 9
Training loss: 0.6105823050168767
Validation loss: 2.6670909476448874

Epoch: 6| Step: 10
Training loss: 0.71097250212975
Validation loss: 2.6821042932155814

Epoch: 6| Step: 11
Training loss: 1.0163611458484052
Validation loss: 2.657802800133114

Epoch: 6| Step: 12
Training loss: 0.9145641743442545
Validation loss: 2.712447413564278

Epoch: 6| Step: 13
Training loss: 0.7392246334637632
Validation loss: 2.698547907717219

Epoch: 506| Step: 0
Training loss: 0.7510236271469893
Validation loss: 2.699355106178311

Epoch: 6| Step: 1
Training loss: 0.8481319516599127
Validation loss: 2.716210703845502

Epoch: 6| Step: 2
Training loss: 1.0388456993225883
Validation loss: 2.6902643149374543

Epoch: 6| Step: 3
Training loss: 0.6248598179965509
Validation loss: 2.6742424379908796

Epoch: 6| Step: 4
Training loss: 0.5755837493844538
Validation loss: 2.6639136118607762

Epoch: 6| Step: 5
Training loss: 0.4978231787868235
Validation loss: 2.6265507017875733

Epoch: 6| Step: 6
Training loss: 0.8907360543062178
Validation loss: 2.641839144563621

Epoch: 6| Step: 7
Training loss: 1.615264929190685
Validation loss: 2.6468492791948157

Epoch: 6| Step: 8
Training loss: 0.8799187486700217
Validation loss: 2.6374576040512405

Epoch: 6| Step: 9
Training loss: 0.7514600449991963
Validation loss: 2.6708515622422357

Epoch: 6| Step: 10
Training loss: 0.6395987687956105
Validation loss: 2.615458990727204

Epoch: 6| Step: 11
Training loss: 0.8524590069040524
Validation loss: 2.6627199560375328

Epoch: 6| Step: 12
Training loss: 1.1642314609053337
Validation loss: 2.656149073884501

Epoch: 6| Step: 13
Training loss: 1.160515007267155
Validation loss: 2.631146594993103

Epoch: 507| Step: 0
Training loss: 1.5603281567286729
Validation loss: 2.655735855482337

Epoch: 6| Step: 1
Training loss: 0.9944916350932044
Validation loss: 2.699301506108169

Epoch: 6| Step: 2
Training loss: 0.7831387386349916
Validation loss: 2.670961588601357

Epoch: 6| Step: 3
Training loss: 0.7329627722775139
Validation loss: 2.6703722794486695

Epoch: 6| Step: 4
Training loss: 0.7507258320340857
Validation loss: 2.6889433365448423

Epoch: 6| Step: 5
Training loss: 0.6872636865742666
Validation loss: 2.6379853042438506

Epoch: 6| Step: 6
Training loss: 0.9042809569438799
Validation loss: 2.631999055222609

Epoch: 6| Step: 7
Training loss: 0.8811270228944595
Validation loss: 2.6610836766081247

Epoch: 6| Step: 8
Training loss: 1.1208071458633657
Validation loss: 2.6309348489593876

Epoch: 6| Step: 9
Training loss: 0.7675427144742373
Validation loss: 2.617087014867658

Epoch: 6| Step: 10
Training loss: 0.6443829915007167
Validation loss: 2.6602814243944857

Epoch: 6| Step: 11
Training loss: 0.781658714195689
Validation loss: 2.6922285525610463

Epoch: 6| Step: 12
Training loss: 0.948195231381961
Validation loss: 2.6893135623381554

Epoch: 6| Step: 13
Training loss: 0.2813949476362608
Validation loss: 2.7073044506693593

Epoch: 508| Step: 0
Training loss: 1.4154988786375615
Validation loss: 2.6654671719502407

Epoch: 6| Step: 1
Training loss: 0.8065106007706445
Validation loss: 2.723724957256376

Epoch: 6| Step: 2
Training loss: 0.6612384210304698
Validation loss: 2.698634922247357

Epoch: 6| Step: 3
Training loss: 0.7080206929054662
Validation loss: 2.69488055201208

Epoch: 6| Step: 4
Training loss: 1.1394121698206012
Validation loss: 2.728532071242797

Epoch: 6| Step: 5
Training loss: 0.7043996489442192
Validation loss: 2.680706544936917

Epoch: 6| Step: 6
Training loss: 0.6436574387902149
Validation loss: 2.717137773481191

Epoch: 6| Step: 7
Training loss: 0.6903336173506256
Validation loss: 2.7192393593175255

Epoch: 6| Step: 8
Training loss: 1.0500495944345176
Validation loss: 2.661959006214265

Epoch: 6| Step: 9
Training loss: 0.7518122553468611
Validation loss: 2.7230177355544862

Epoch: 6| Step: 10
Training loss: 0.8388748612680151
Validation loss: 2.705557081936582

Epoch: 6| Step: 11
Training loss: 1.0745857860176777
Validation loss: 2.638387665339738

Epoch: 6| Step: 12
Training loss: 0.7649733046941467
Validation loss: 2.629874095718992

Epoch: 6| Step: 13
Training loss: 0.8561786162421419
Validation loss: 2.652848992593289

Epoch: 509| Step: 0
Training loss: 0.8375312016496609
Validation loss: 2.6913438472421984

Epoch: 6| Step: 1
Training loss: 0.4910133677379888
Validation loss: 2.705348321849691

Epoch: 6| Step: 2
Training loss: 1.3090088143339709
Validation loss: 2.688045678111728

Epoch: 6| Step: 3
Training loss: 0.9880615713957398
Validation loss: 2.6773860781440475

Epoch: 6| Step: 4
Training loss: 1.5217377399059127
Validation loss: 2.6918046411965437

Epoch: 6| Step: 5
Training loss: 0.6487111123324195
Validation loss: 2.6958534091497945

Epoch: 6| Step: 6
Training loss: 0.6802911379907439
Validation loss: 2.739913117839159

Epoch: 6| Step: 7
Training loss: 0.9572060561615412
Validation loss: 2.7128101460585126

Epoch: 6| Step: 8
Training loss: 0.6430294226089186
Validation loss: 2.684496019885779

Epoch: 6| Step: 9
Training loss: 0.8472510569169922
Validation loss: 2.629296624066531

Epoch: 6| Step: 10
Training loss: 0.5746168456379643
Validation loss: 2.5798017342564425

Epoch: 6| Step: 11
Training loss: 0.7176461658396357
Validation loss: 2.5757534038595353

Epoch: 6| Step: 12
Training loss: 0.9698499157406753
Validation loss: 2.6189732441465168

Epoch: 6| Step: 13
Training loss: 0.7018128337147604
Validation loss: 2.6323360453707108

Epoch: 510| Step: 0
Training loss: 0.8086173381221298
Validation loss: 2.6442189625915975

Epoch: 6| Step: 1
Training loss: 0.9212616642041446
Validation loss: 2.6796681307056733

Epoch: 6| Step: 2
Training loss: 0.5715203754300522
Validation loss: 2.675857026222038

Epoch: 6| Step: 3
Training loss: 0.7428418938675093
Validation loss: 2.7155528913755718

Epoch: 6| Step: 4
Training loss: 0.941756757010697
Validation loss: 2.714932500002827

Epoch: 6| Step: 5
Training loss: 0.799145511914701
Validation loss: 2.6802604955033265

Epoch: 6| Step: 6
Training loss: 0.686532966037571
Validation loss: 2.672762209380035

Epoch: 6| Step: 7
Training loss: 0.512714610871914
Validation loss: 2.6931528145197143

Epoch: 6| Step: 8
Training loss: 0.8437848966940793
Validation loss: 2.6856412934740153

Epoch: 6| Step: 9
Training loss: 1.0268123978648367
Validation loss: 2.6708498354555212

Epoch: 6| Step: 10
Training loss: 0.8433211967728317
Validation loss: 2.6488048344581165

Epoch: 6| Step: 11
Training loss: 0.7721018191528234
Validation loss: 2.651573938251574

Epoch: 6| Step: 12
Training loss: 1.7530680057284544
Validation loss: 2.669819479241598

Epoch: 6| Step: 13
Training loss: 0.6148809477473253
Validation loss: 2.6926319415108577

Epoch: 511| Step: 0
Training loss: 0.7388510952113968
Validation loss: 2.6641942170507438

Epoch: 6| Step: 1
Training loss: 0.7360131275493789
Validation loss: 2.66872324363247

Epoch: 6| Step: 2
Training loss: 0.8833575971137975
Validation loss: 2.662617373581398

Epoch: 6| Step: 3
Training loss: 0.8597641843916294
Validation loss: 2.653799950726471

Epoch: 6| Step: 4
Training loss: 0.8415552133159021
Validation loss: 2.607456924198608

Epoch: 6| Step: 5
Training loss: 1.4161190863334399
Validation loss: 2.6228778970899285

Epoch: 6| Step: 6
Training loss: 0.9531553920215327
Validation loss: 2.6111097596176003

Epoch: 6| Step: 7
Training loss: 0.4952410180049059
Validation loss: 2.669484311783061

Epoch: 6| Step: 8
Training loss: 0.7585773737325247
Validation loss: 2.719071297241774

Epoch: 6| Step: 9
Training loss: 0.7900563392589075
Validation loss: 2.706502728030435

Epoch: 6| Step: 10
Training loss: 1.091457416533796
Validation loss: 2.7202410750411614

Epoch: 6| Step: 11
Training loss: 0.8842537854161879
Validation loss: 2.7257157951002804

Epoch: 6| Step: 12
Training loss: 0.9247727192204339
Validation loss: 2.7078552606650876

Epoch: 6| Step: 13
Training loss: 0.9231694072768336
Validation loss: 2.652605531864502

Epoch: 512| Step: 0
Training loss: 1.3717312974330953
Validation loss: 2.6000534894566782

Epoch: 6| Step: 1
Training loss: 1.0561422981563982
Validation loss: 2.5817585845017685

Epoch: 6| Step: 2
Training loss: 0.48735264788665894
Validation loss: 2.55939713870094

Epoch: 6| Step: 3
Training loss: 1.0403369172594827
Validation loss: 2.5478730910003673

Epoch: 6| Step: 4
Training loss: 0.6143717698005521
Validation loss: 2.603923966614213

Epoch: 6| Step: 5
Training loss: 0.5991274608718311
Validation loss: 2.628218988308423

Epoch: 6| Step: 6
Training loss: 0.4960876824916541
Validation loss: 2.612072819181511

Epoch: 6| Step: 7
Training loss: 0.8672593233075275
Validation loss: 2.662549624340953

Epoch: 6| Step: 8
Training loss: 0.8103810336035319
Validation loss: 2.6968897359586093

Epoch: 6| Step: 9
Training loss: 1.0895555450124694
Validation loss: 2.737300993718473

Epoch: 6| Step: 10
Training loss: 1.1807554350046798
Validation loss: 2.7133127660436185

Epoch: 6| Step: 11
Training loss: 1.0131913591569885
Validation loss: 2.7248147819494752

Epoch: 6| Step: 12
Training loss: 0.8265002885276812
Validation loss: 2.689667407955905

Epoch: 6| Step: 13
Training loss: 0.6627285068427095
Validation loss: 2.69050020116148

Epoch: 513| Step: 0
Training loss: 0.6452496772833294
Validation loss: 2.6347245901324485

Epoch: 6| Step: 1
Training loss: 1.007875721449217
Validation loss: 2.6589695307846504

Epoch: 6| Step: 2
Training loss: 0.808836785248641
Validation loss: 2.6638069110819664

Epoch: 6| Step: 3
Training loss: 0.4746343661035421
Validation loss: 2.643679144881531

Epoch: 6| Step: 4
Training loss: 0.6929679948013474
Validation loss: 2.6493924011467653

Epoch: 6| Step: 5
Training loss: 0.9008595865137071
Validation loss: 2.650119447908652

Epoch: 6| Step: 6
Training loss: 1.4206691281622392
Validation loss: 2.6539811425832442

Epoch: 6| Step: 7
Training loss: 0.43469222855344253
Validation loss: 2.6773618308506486

Epoch: 6| Step: 8
Training loss: 1.2557466969584261
Validation loss: 2.6905422348173524

Epoch: 6| Step: 9
Training loss: 0.5919476811094608
Validation loss: 2.680782290956872

Epoch: 6| Step: 10
Training loss: 1.0296583319137622
Validation loss: 2.649098125544833

Epoch: 6| Step: 11
Training loss: 0.8833007137705544
Validation loss: 2.6388291744203602

Epoch: 6| Step: 12
Training loss: 1.0061538413406064
Validation loss: 2.6212686904833244

Epoch: 6| Step: 13
Training loss: 0.6295935151265443
Validation loss: 2.6448527776670643

Epoch: 514| Step: 0
Training loss: 0.8789772513638918
Validation loss: 2.649812891587213

Epoch: 6| Step: 1
Training loss: 0.6459990001794736
Validation loss: 2.6567608741961033

Epoch: 6| Step: 2
Training loss: 0.6192022828408725
Validation loss: 2.688778564776143

Epoch: 6| Step: 3
Training loss: 0.8759029021491924
Validation loss: 2.6962157498120822

Epoch: 6| Step: 4
Training loss: 0.7393762450800236
Validation loss: 2.699613397684277

Epoch: 6| Step: 5
Training loss: 0.5986322150919735
Validation loss: 2.6978400688274493

Epoch: 6| Step: 6
Training loss: 0.8253423977296591
Validation loss: 2.70969751865015

Epoch: 6| Step: 7
Training loss: 0.6255887596312056
Validation loss: 2.713377987889828

Epoch: 6| Step: 8
Training loss: 1.1149474407860362
Validation loss: 2.6735431860857815

Epoch: 6| Step: 9
Training loss: 0.8161354893603195
Validation loss: 2.695037060146677

Epoch: 6| Step: 10
Training loss: 1.0713044741833828
Validation loss: 2.656472612640133

Epoch: 6| Step: 11
Training loss: 1.5484245322846013
Validation loss: 2.6565804301921325

Epoch: 6| Step: 12
Training loss: 0.9182486898619052
Validation loss: 2.695309224244883

Epoch: 6| Step: 13
Training loss: 0.8356101919387153
Validation loss: 2.688470957431474

Epoch: 515| Step: 0
Training loss: 0.8532428087210318
Validation loss: 2.7087882809119033

Epoch: 6| Step: 1
Training loss: 0.8034017716798247
Validation loss: 2.666219068720036

Epoch: 6| Step: 2
Training loss: 1.4734067749832869
Validation loss: 2.6084975909926365

Epoch: 6| Step: 3
Training loss: 0.7806166179442139
Validation loss: 2.6658080560395634

Epoch: 6| Step: 4
Training loss: 0.820357076251183
Validation loss: 2.6254338981612793

Epoch: 6| Step: 5
Training loss: 0.3915323781379269
Validation loss: 2.613526180627566

Epoch: 6| Step: 6
Training loss: 0.8041061968295755
Validation loss: 2.6123847220037346

Epoch: 6| Step: 7
Training loss: 0.7314987264975402
Validation loss: 2.6082673025895913

Epoch: 6| Step: 8
Training loss: 0.5426069192956284
Validation loss: 2.640151229232843

Epoch: 6| Step: 9
Training loss: 1.101186160468208
Validation loss: 2.678749914692757

Epoch: 6| Step: 10
Training loss: 0.6758386003270994
Validation loss: 2.66733080498694

Epoch: 6| Step: 11
Training loss: 1.2210513175284001
Validation loss: 2.689037772092584

Epoch: 6| Step: 12
Training loss: 0.63768830229804
Validation loss: 2.7045666550614493

Epoch: 6| Step: 13
Training loss: 1.0710591405929484
Validation loss: 2.6977361486523592

Epoch: 516| Step: 0
Training loss: 1.4479608140248188
Validation loss: 2.6970479040533752

Epoch: 6| Step: 1
Training loss: 1.0760363927947671
Validation loss: 2.6193949642201555

Epoch: 6| Step: 2
Training loss: 0.6642788254179958
Validation loss: 2.6116706427838183

Epoch: 6| Step: 3
Training loss: 0.7141428361772292
Validation loss: 2.5853735032346976

Epoch: 6| Step: 4
Training loss: 0.828420190561974
Validation loss: 2.585186694074247

Epoch: 6| Step: 5
Training loss: 0.7900418916894452
Validation loss: 2.598921778006266

Epoch: 6| Step: 6
Training loss: 1.1330585081072333
Validation loss: 2.6655526200692443

Epoch: 6| Step: 7
Training loss: 1.0620040858202713
Validation loss: 2.6833671028347514

Epoch: 6| Step: 8
Training loss: 0.6523686250067079
Validation loss: 2.709797772956592

Epoch: 6| Step: 9
Training loss: 0.6818329722794303
Validation loss: 2.711022306920014

Epoch: 6| Step: 10
Training loss: 0.6461329585474707
Validation loss: 2.760661947846179

Epoch: 6| Step: 11
Training loss: 0.7218657835665162
Validation loss: 2.775946696634226

Epoch: 6| Step: 12
Training loss: 0.7383124531605666
Validation loss: 2.7057179345120805

Epoch: 6| Step: 13
Training loss: 0.5464384789107402
Validation loss: 2.6533249811789354

Epoch: 517| Step: 0
Training loss: 0.706126208132296
Validation loss: 2.641575799819839

Epoch: 6| Step: 1
Training loss: 0.9894380998280115
Validation loss: 2.618078014129879

Epoch: 6| Step: 2
Training loss: 0.45604093151053604
Validation loss: 2.5913525821303045

Epoch: 6| Step: 3
Training loss: 0.9837038386080094
Validation loss: 2.5673519453712927

Epoch: 6| Step: 4
Training loss: 0.9470495862496392
Validation loss: 2.5867808791154934

Epoch: 6| Step: 5
Training loss: 0.8578743055969745
Validation loss: 2.602806463250693

Epoch: 6| Step: 6
Training loss: 0.5747891661518271
Validation loss: 2.6308522498127367

Epoch: 6| Step: 7
Training loss: 0.9158991757941971
Validation loss: 2.670021232015745

Epoch: 6| Step: 8
Training loss: 0.8269480132538264
Validation loss: 2.6794461267431657

Epoch: 6| Step: 9
Training loss: 0.6853595488575692
Validation loss: 2.666265088910427

Epoch: 6| Step: 10
Training loss: 0.8474401383090566
Validation loss: 2.6894722503390303

Epoch: 6| Step: 11
Training loss: 0.8206948978496487
Validation loss: 2.7006883965074544

Epoch: 6| Step: 12
Training loss: 1.3353092880442508
Validation loss: 2.6633556259238573

Epoch: 6| Step: 13
Training loss: 0.6157261169965564
Validation loss: 2.694059497599063

Epoch: 518| Step: 0
Training loss: 0.5127698571643979
Validation loss: 2.640296371426798

Epoch: 6| Step: 1
Training loss: 0.6812312911028202
Validation loss: 2.651533151905619

Epoch: 6| Step: 2
Training loss: 1.4292666123181932
Validation loss: 2.5998063897466555

Epoch: 6| Step: 3
Training loss: 0.7552368597145834
Validation loss: 2.601194985995003

Epoch: 6| Step: 4
Training loss: 0.9916430804442291
Validation loss: 2.5764571745624307

Epoch: 6| Step: 5
Training loss: 0.9004274637956828
Validation loss: 2.621943403820806

Epoch: 6| Step: 6
Training loss: 0.5556628557403279
Validation loss: 2.611317711191025

Epoch: 6| Step: 7
Training loss: 0.7735526259310602
Validation loss: 2.6934126354963124

Epoch: 6| Step: 8
Training loss: 0.7131476370104682
Validation loss: 2.698962789681534

Epoch: 6| Step: 9
Training loss: 0.7381143532678802
Validation loss: 2.723551479081421

Epoch: 6| Step: 10
Training loss: 1.1272656620550947
Validation loss: 2.716051467538163

Epoch: 6| Step: 11
Training loss: 1.0908478517394309
Validation loss: 2.7199284855669177

Epoch: 6| Step: 12
Training loss: 0.6322321644353057
Validation loss: 2.7317970145039485

Epoch: 6| Step: 13
Training loss: 0.6685601900917925
Validation loss: 2.6746889523702038

Epoch: 519| Step: 0
Training loss: 1.01449710132228
Validation loss: 2.677743720083968

Epoch: 6| Step: 1
Training loss: 0.9413708565417795
Validation loss: 2.651454634610423

Epoch: 6| Step: 2
Training loss: 0.3730460960819441
Validation loss: 2.729900272469097

Epoch: 6| Step: 3
Training loss: 0.7898614068326364
Validation loss: 2.737688663739375

Epoch: 6| Step: 4
Training loss: 0.8845443617336306
Validation loss: 2.7307431977105177

Epoch: 6| Step: 5
Training loss: 0.4977893238216315
Validation loss: 2.7175327509109057

Epoch: 6| Step: 6
Training loss: 1.3931161234501408
Validation loss: 2.7200854186158154

Epoch: 6| Step: 7
Training loss: 0.8182657047096794
Validation loss: 2.7248713682848904

Epoch: 6| Step: 8
Training loss: 0.4746059841458731
Validation loss: 2.711219778811799

Epoch: 6| Step: 9
Training loss: 0.7452978712521627
Validation loss: 2.740691107750559

Epoch: 6| Step: 10
Training loss: 1.0046693150608397
Validation loss: 2.7011819523615124

Epoch: 6| Step: 11
Training loss: 0.6826276218997525
Validation loss: 2.657828641840545

Epoch: 6| Step: 12
Training loss: 0.9507476988791405
Validation loss: 2.6691531931207404

Epoch: 6| Step: 13
Training loss: 0.7915676874893632
Validation loss: 2.6675971263973577

Epoch: 520| Step: 0
Training loss: 0.6956930083749983
Validation loss: 2.655061522276353

Epoch: 6| Step: 1
Training loss: 0.6958563745608923
Validation loss: 2.7240313137831884

Epoch: 6| Step: 2
Training loss: 0.7941554168059142
Validation loss: 2.699451627688175

Epoch: 6| Step: 3
Training loss: 0.7022007908091686
Validation loss: 2.6862010244285988

Epoch: 6| Step: 4
Training loss: 0.7355017033835368
Validation loss: 2.7206796830721007

Epoch: 6| Step: 5
Training loss: 0.8080637572434592
Validation loss: 2.7352130408449837

Epoch: 6| Step: 6
Training loss: 1.025563543362528
Validation loss: 2.7230021852432524

Epoch: 6| Step: 7
Training loss: 0.6235499488551578
Validation loss: 2.7113214017476612

Epoch: 6| Step: 8
Training loss: 0.7070299011554814
Validation loss: 2.6905686358176055

Epoch: 6| Step: 9
Training loss: 1.4885788667522806
Validation loss: 2.6756004579606825

Epoch: 6| Step: 10
Training loss: 0.8699727393406602
Validation loss: 2.637155987010594

Epoch: 6| Step: 11
Training loss: 0.9562974568976319
Validation loss: 2.6397288928659406

Epoch: 6| Step: 12
Training loss: 0.461445576883988
Validation loss: 2.627536966774835

Epoch: 6| Step: 13
Training loss: 0.7235990817590837
Validation loss: 2.6404778991179807

Epoch: 521| Step: 0
Training loss: 1.3266218767480722
Validation loss: 2.632551834982404

Epoch: 6| Step: 1
Training loss: 0.6476071568048258
Validation loss: 2.6278079153191083

Epoch: 6| Step: 2
Training loss: 0.6268870000936237
Validation loss: 2.661261977265105

Epoch: 6| Step: 3
Training loss: 0.95184052012282
Validation loss: 2.6957770176926856

Epoch: 6| Step: 4
Training loss: 0.8843568779803918
Validation loss: 2.680381516412855

Epoch: 6| Step: 5
Training loss: 0.7285914650066622
Validation loss: 2.702130544174156

Epoch: 6| Step: 6
Training loss: 0.9853431240056933
Validation loss: 2.6638877695152914

Epoch: 6| Step: 7
Training loss: 0.8889891005857359
Validation loss: 2.615493369603346

Epoch: 6| Step: 8
Training loss: 0.7616394001638558
Validation loss: 2.596665241631185

Epoch: 6| Step: 9
Training loss: 0.5393386354708402
Validation loss: 2.581526046365999

Epoch: 6| Step: 10
Training loss: 0.6130419707779666
Validation loss: 2.6442198293482413

Epoch: 6| Step: 11
Training loss: 0.8147758740896015
Validation loss: 2.650421623854979

Epoch: 6| Step: 12
Training loss: 1.0947144751855555
Validation loss: 2.693392898510493

Epoch: 6| Step: 13
Training loss: 0.2478002238028996
Validation loss: 2.698293723150889

Epoch: 522| Step: 0
Training loss: 0.8161010901953445
Validation loss: 2.6858040298740242

Epoch: 6| Step: 1
Training loss: 0.49718608894363703
Validation loss: 2.6904954369118728

Epoch: 6| Step: 2
Training loss: 0.3519043214347262
Validation loss: 2.6928936348761745

Epoch: 6| Step: 3
Training loss: 1.0621615600112018
Validation loss: 2.6663776668590486

Epoch: 6| Step: 4
Training loss: 0.868913599431484
Validation loss: 2.615500344517773

Epoch: 6| Step: 5
Training loss: 0.8748213721913736
Validation loss: 2.6068062053309466

Epoch: 6| Step: 6
Training loss: 0.5520337790316003
Validation loss: 2.569517198408586

Epoch: 6| Step: 7
Training loss: 0.9367509392559799
Validation loss: 2.6290259089098504

Epoch: 6| Step: 8
Training loss: 0.5908790243942631
Validation loss: 2.618549519632271

Epoch: 6| Step: 9
Training loss: 0.8073387173303284
Validation loss: 2.588653607260075

Epoch: 6| Step: 10
Training loss: 1.0029719417180714
Validation loss: 2.611156386339486

Epoch: 6| Step: 11
Training loss: 0.8524554409340562
Validation loss: 2.643778933475342

Epoch: 6| Step: 12
Training loss: 0.6345908056292195
Validation loss: 2.672788343831744

Epoch: 6| Step: 13
Training loss: 1.6838300145316107
Validation loss: 2.6988014081502905

Epoch: 523| Step: 0
Training loss: 0.5739171280467394
Validation loss: 2.713062328989793

Epoch: 6| Step: 1
Training loss: 0.9452671323876749
Validation loss: 2.7389829712300022

Epoch: 6| Step: 2
Training loss: 0.7399721511549359
Validation loss: 2.7588532533835988

Epoch: 6| Step: 3
Training loss: 0.7498940154531065
Validation loss: 2.654954440632463

Epoch: 6| Step: 4
Training loss: 0.879129305191813
Validation loss: 2.611289918414038

Epoch: 6| Step: 5
Training loss: 0.679372911985219
Validation loss: 2.634573457250503

Epoch: 6| Step: 6
Training loss: 0.8054178867505168
Validation loss: 2.616609081203955

Epoch: 6| Step: 7
Training loss: 0.5700301163647855
Validation loss: 2.6204271816414546

Epoch: 6| Step: 8
Training loss: 0.9004590056099148
Validation loss: 2.6366586971394574

Epoch: 6| Step: 9
Training loss: 1.2793313990004007
Validation loss: 2.6875676077189357

Epoch: 6| Step: 10
Training loss: 1.0800589202773856
Validation loss: 2.677902355591595

Epoch: 6| Step: 11
Training loss: 1.070381886258839
Validation loss: 2.7001709120939563

Epoch: 6| Step: 12
Training loss: 0.6563196599410118
Validation loss: 2.721309863141687

Epoch: 6| Step: 13
Training loss: 0.161101176306253
Validation loss: 2.704704557699519

Epoch: 524| Step: 0
Training loss: 0.7736790597715514
Validation loss: 2.704481283598976

Epoch: 6| Step: 1
Training loss: 0.5041269218394949
Validation loss: 2.691413748292378

Epoch: 6| Step: 2
Training loss: 0.7502395724087044
Validation loss: 2.6722442980054626

Epoch: 6| Step: 3
Training loss: 0.9737983034956267
Validation loss: 2.7101235095150162

Epoch: 6| Step: 4
Training loss: 0.82060294686034
Validation loss: 2.6792557102198975

Epoch: 6| Step: 5
Training loss: 0.5751699238016821
Validation loss: 2.6087880753250072

Epoch: 6| Step: 6
Training loss: 0.5927167736540823
Validation loss: 2.621769528233689

Epoch: 6| Step: 7
Training loss: 0.5904890660881429
Validation loss: 2.646424838232181

Epoch: 6| Step: 8
Training loss: 0.9660546430273325
Validation loss: 2.643518187036122

Epoch: 6| Step: 9
Training loss: 0.7310280112419547
Validation loss: 2.6350491132990843

Epoch: 6| Step: 10
Training loss: 0.8301603388743956
Validation loss: 2.629791508098029

Epoch: 6| Step: 11
Training loss: 0.7646640274192984
Validation loss: 2.6662530344318847

Epoch: 6| Step: 12
Training loss: 1.3540825255247173
Validation loss: 2.6595474593860153

Epoch: 6| Step: 13
Training loss: 0.9664877040769624
Validation loss: 2.670410121209359

Epoch: 525| Step: 0
Training loss: 0.35192419096193933
Validation loss: 2.6755588507034376

Epoch: 6| Step: 1
Training loss: 0.6017458747687503
Validation loss: 2.6600021528003537

Epoch: 6| Step: 2
Training loss: 0.638416740950103
Validation loss: 2.6844075566992234

Epoch: 6| Step: 3
Training loss: 0.5137835479141077
Validation loss: 2.672503185660356

Epoch: 6| Step: 4
Training loss: 0.9245167720113
Validation loss: 2.659390294181767

Epoch: 6| Step: 5
Training loss: 0.9725743148181187
Validation loss: 2.6416010772563303

Epoch: 6| Step: 6
Training loss: 1.339181452734613
Validation loss: 2.6610213599828243

Epoch: 6| Step: 7
Training loss: 0.37512697613255047
Validation loss: 2.667115677119799

Epoch: 6| Step: 8
Training loss: 0.9400552576644715
Validation loss: 2.664725624595577

Epoch: 6| Step: 9
Training loss: 0.9011608478613914
Validation loss: 2.659337179901856

Epoch: 6| Step: 10
Training loss: 1.079194961579497
Validation loss: 2.6691823374527135

Epoch: 6| Step: 11
Training loss: 0.7369350694239867
Validation loss: 2.66505604667688

Epoch: 6| Step: 12
Training loss: 0.31008637071075473
Validation loss: 2.6435463872235765

Epoch: 6| Step: 13
Training loss: 1.0184865692856169
Validation loss: 2.643232369078733

Epoch: 526| Step: 0
Training loss: 0.5425064259249618
Validation loss: 2.653586452733947

Epoch: 6| Step: 1
Training loss: 0.7999603902428476
Validation loss: 2.6571476364861457

Epoch: 6| Step: 2
Training loss: 0.797840505871216
Validation loss: 2.6712988795009065

Epoch: 6| Step: 3
Training loss: 0.8816182320877363
Validation loss: 2.646340060445572

Epoch: 6| Step: 4
Training loss: 0.8083946240840458
Validation loss: 2.6645972415562023

Epoch: 6| Step: 5
Training loss: 0.7405895095884723
Validation loss: 2.7133468291244403

Epoch: 6| Step: 6
Training loss: 1.114460210446719
Validation loss: 2.6661313404716225

Epoch: 6| Step: 7
Training loss: 0.8278687278513419
Validation loss: 2.669980244502191

Epoch: 6| Step: 8
Training loss: 0.25652250593843173
Validation loss: 2.676572018669109

Epoch: 6| Step: 9
Training loss: 0.7911535448942028
Validation loss: 2.630176855821022

Epoch: 6| Step: 10
Training loss: 0.7276109903097977
Validation loss: 2.6768768474789715

Epoch: 6| Step: 11
Training loss: 1.341910766920876
Validation loss: 2.6472590310438786

Epoch: 6| Step: 12
Training loss: 0.5046406207441505
Validation loss: 2.6474986598594477

Epoch: 6| Step: 13
Training loss: 0.5321619677060904
Validation loss: 2.629985703815826

Epoch: 527| Step: 0
Training loss: 0.7725126343221694
Validation loss: 2.6542527982756208

Epoch: 6| Step: 1
Training loss: 1.300077001418614
Validation loss: 2.6663934142397294

Epoch: 6| Step: 2
Training loss: 0.9685129675521389
Validation loss: 2.6362899970081455

Epoch: 6| Step: 3
Training loss: 0.7437831390435085
Validation loss: 2.6745144646549672

Epoch: 6| Step: 4
Training loss: 1.0458632177412106
Validation loss: 2.678666750476036

Epoch: 6| Step: 5
Training loss: 0.8502457263528435
Validation loss: 2.715683768236072

Epoch: 6| Step: 6
Training loss: 0.595348239937216
Validation loss: 2.716155264132362

Epoch: 6| Step: 7
Training loss: 0.8080142981047875
Validation loss: 2.7286122471359846

Epoch: 6| Step: 8
Training loss: 0.7043054632000729
Validation loss: 2.7109750275382853

Epoch: 6| Step: 9
Training loss: 0.49167121572599115
Validation loss: 2.6991536727821623

Epoch: 6| Step: 10
Training loss: 0.5578777285779878
Validation loss: 2.6590042842428514

Epoch: 6| Step: 11
Training loss: 0.9248398126620512
Validation loss: 2.619953080495905

Epoch: 6| Step: 12
Training loss: 0.5350617374022166
Validation loss: 2.6315221474135555

Epoch: 6| Step: 13
Training loss: 0.5386903003089174
Validation loss: 2.5936346501620293

Epoch: 528| Step: 0
Training loss: 0.5977120466926914
Validation loss: 2.6274045019145995

Epoch: 6| Step: 1
Training loss: 1.4002207462801333
Validation loss: 2.6371058133083816

Epoch: 6| Step: 2
Training loss: 0.929643133050463
Validation loss: 2.6393937411822606

Epoch: 6| Step: 3
Training loss: 0.5328045148055353
Validation loss: 2.6415763345634744

Epoch: 6| Step: 4
Training loss: 1.1144536855049743
Validation loss: 2.6481425180686156

Epoch: 6| Step: 5
Training loss: 0.7845896484180276
Validation loss: 2.690323839215362

Epoch: 6| Step: 6
Training loss: 0.82572954028587
Validation loss: 2.7126943908464303

Epoch: 6| Step: 7
Training loss: 0.8489751443583141
Validation loss: 2.705566848278795

Epoch: 6| Step: 8
Training loss: 0.5445664863733856
Validation loss: 2.7041658513324385

Epoch: 6| Step: 9
Training loss: 0.7123268301816755
Validation loss: 2.717107235736695

Epoch: 6| Step: 10
Training loss: 0.5469519424807109
Validation loss: 2.660783360907721

Epoch: 6| Step: 11
Training loss: 0.580999932794682
Validation loss: 2.628715370341819

Epoch: 6| Step: 12
Training loss: 0.8288700423031272
Validation loss: 2.6517346420475616

Epoch: 6| Step: 13
Training loss: 0.2620290653089916
Validation loss: 2.629123447350892

Epoch: 529| Step: 0
Training loss: 0.8847751237978311
Validation loss: 2.6021253957409263

Epoch: 6| Step: 1
Training loss: 0.31651773961011404
Validation loss: 2.64320282562546

Epoch: 6| Step: 2
Training loss: 1.0051732954859725
Validation loss: 2.6509258614779077

Epoch: 6| Step: 3
Training loss: 0.7854278246612322
Validation loss: 2.665996358312703

Epoch: 6| Step: 4
Training loss: 0.8788175410961766
Validation loss: 2.6716824865006834

Epoch: 6| Step: 5
Training loss: 0.9430585740992597
Validation loss: 2.70573049725258

Epoch: 6| Step: 6
Training loss: 0.4009570883041461
Validation loss: 2.7376362009516817

Epoch: 6| Step: 7
Training loss: 0.39911616252095744
Validation loss: 2.7325277447176446

Epoch: 6| Step: 8
Training loss: 0.4016973617836486
Validation loss: 2.7258587315715532

Epoch: 6| Step: 9
Training loss: 1.3962441404487786
Validation loss: 2.6679285112135327

Epoch: 6| Step: 10
Training loss: 0.3351012400407538
Validation loss: 2.6292026022825357

Epoch: 6| Step: 11
Training loss: 1.0642370722180179
Validation loss: 2.667623071195763

Epoch: 6| Step: 12
Training loss: 0.8651946943496934
Validation loss: 2.625015733381664

Epoch: 6| Step: 13
Training loss: 0.52000013145115
Validation loss: 2.6433005082008565

Epoch: 530| Step: 0
Training loss: 0.4043221212419637
Validation loss: 2.6031616424233706

Epoch: 6| Step: 1
Training loss: 0.9135928455372445
Validation loss: 2.5776002013550277

Epoch: 6| Step: 2
Training loss: 0.9594091340991417
Validation loss: 2.567260591993334

Epoch: 6| Step: 3
Training loss: 0.7992222193906475
Validation loss: 2.574381608837644

Epoch: 6| Step: 4
Training loss: 0.8345285824360056
Validation loss: 2.638042296845132

Epoch: 6| Step: 5
Training loss: 1.2739223189213682
Validation loss: 2.6284639773062044

Epoch: 6| Step: 6
Training loss: 0.648949294744241
Validation loss: 2.638479462212081

Epoch: 6| Step: 7
Training loss: 0.8565660867821222
Validation loss: 2.6737167889039983

Epoch: 6| Step: 8
Training loss: 0.9366944985197302
Validation loss: 2.688742174806403

Epoch: 6| Step: 9
Training loss: 0.7759462378966648
Validation loss: 2.6904400471267382

Epoch: 6| Step: 10
Training loss: 0.48586829020737604
Validation loss: 2.666838727547913

Epoch: 6| Step: 11
Training loss: 0.7595073976991462
Validation loss: 2.675047809755122

Epoch: 6| Step: 12
Training loss: 0.4379413286131306
Validation loss: 2.650238262214507

Epoch: 6| Step: 13
Training loss: 0.6720188563502731
Validation loss: 2.61034172964118

Epoch: 531| Step: 0
Training loss: 0.8109677244812515
Validation loss: 2.6160716176233567

Epoch: 6| Step: 1
Training loss: 0.8613028663166805
Validation loss: 2.5718347803093806

Epoch: 6| Step: 2
Training loss: 0.8792685207165853
Validation loss: 2.577911222910224

Epoch: 6| Step: 3
Training loss: 0.6804487853948217
Validation loss: 2.6223719753485972

Epoch: 6| Step: 4
Training loss: 0.6235367574051364
Validation loss: 2.563193882823672

Epoch: 6| Step: 5
Training loss: 0.8117239253417938
Validation loss: 2.6321477899576986

Epoch: 6| Step: 6
Training loss: 0.9216914236619355
Validation loss: 2.644921275836641

Epoch: 6| Step: 7
Training loss: 0.7702166221020621
Validation loss: 2.707545891217204

Epoch: 6| Step: 8
Training loss: 0.7138081120418869
Validation loss: 2.6571890882277156

Epoch: 6| Step: 9
Training loss: 1.323696697483956
Validation loss: 2.677091357576348

Epoch: 6| Step: 10
Training loss: 0.7884104839206578
Validation loss: 2.695353288714909

Epoch: 6| Step: 11
Training loss: 0.6665727852243784
Validation loss: 2.673347194689806

Epoch: 6| Step: 12
Training loss: 0.36133138294297695
Validation loss: 2.6374756348135784

Epoch: 6| Step: 13
Training loss: 0.6254754880360676
Validation loss: 2.577958403841906

Epoch: 532| Step: 0
Training loss: 0.38586026086761555
Validation loss: 2.5746554030919646

Epoch: 6| Step: 1
Training loss: 0.8219526334002768
Validation loss: 2.5751677565503166

Epoch: 6| Step: 2
Training loss: 0.7957356479535793
Validation loss: 2.572891897502709

Epoch: 6| Step: 3
Training loss: 0.9948814344930169
Validation loss: 2.5829879246666887

Epoch: 6| Step: 4
Training loss: 0.6333286864545236
Validation loss: 2.579505742093146

Epoch: 6| Step: 5
Training loss: 0.8856023406775745
Validation loss: 2.6002027806416903

Epoch: 6| Step: 6
Training loss: 0.308132164428862
Validation loss: 2.5949710838471933

Epoch: 6| Step: 7
Training loss: 0.7997543822177693
Validation loss: 2.613231077024808

Epoch: 6| Step: 8
Training loss: 0.6963790899556175
Validation loss: 2.632099920701965

Epoch: 6| Step: 9
Training loss: 0.4503828969459512
Validation loss: 2.626720922042595

Epoch: 6| Step: 10
Training loss: 0.8866221505537057
Validation loss: 2.6218114943359847

Epoch: 6| Step: 11
Training loss: 1.3814515566593735
Validation loss: 2.6201780274839384

Epoch: 6| Step: 12
Training loss: 0.5133630382573753
Validation loss: 2.5964147975974297

Epoch: 6| Step: 13
Training loss: 0.9106530074065143
Validation loss: 2.6190086448277516

Epoch: 533| Step: 0
Training loss: 0.7310404452812607
Validation loss: 2.6486098097646824

Epoch: 6| Step: 1
Training loss: 0.7839239518202954
Validation loss: 2.6097310121601107

Epoch: 6| Step: 2
Training loss: 0.6569155996100156
Validation loss: 2.60953369797706

Epoch: 6| Step: 3
Training loss: 0.6341805916542725
Validation loss: 2.6649401969735704

Epoch: 6| Step: 4
Training loss: 0.8620322327351531
Validation loss: 2.645412225198282

Epoch: 6| Step: 5
Training loss: 1.3033667177833683
Validation loss: 2.625902906418389

Epoch: 6| Step: 6
Training loss: 0.880096714383886
Validation loss: 2.6382129009181874

Epoch: 6| Step: 7
Training loss: 0.8968166159524005
Validation loss: 2.6273392627386447

Epoch: 6| Step: 8
Training loss: 0.8278360402499659
Validation loss: 2.6171198168080783

Epoch: 6| Step: 9
Training loss: 0.4361215401203637
Validation loss: 2.6328232830307936

Epoch: 6| Step: 10
Training loss: 0.6413039819404328
Validation loss: 2.611300174763183

Epoch: 6| Step: 11
Training loss: 0.5459752173842857
Validation loss: 2.642405049358832

Epoch: 6| Step: 12
Training loss: 0.7692719230738837
Validation loss: 2.624663111119443

Epoch: 6| Step: 13
Training loss: 0.7309584582562683
Validation loss: 2.623274801222839

Epoch: 534| Step: 0
Training loss: 0.5900315497335842
Validation loss: 2.6293795704310066

Epoch: 6| Step: 1
Training loss: 1.1623177477808448
Validation loss: 2.6077597417290623

Epoch: 6| Step: 2
Training loss: 0.7890862565194084
Validation loss: 2.673806220385669

Epoch: 6| Step: 3
Training loss: 0.6900531653985683
Validation loss: 2.6674920049521154

Epoch: 6| Step: 4
Training loss: 0.5881689686408125
Validation loss: 2.6795391337189507

Epoch: 6| Step: 5
Training loss: 0.830454088226973
Validation loss: 2.6669894215077377

Epoch: 6| Step: 6
Training loss: 1.2201347309510429
Validation loss: 2.6698695410810624

Epoch: 6| Step: 7
Training loss: 0.7220789485019768
Validation loss: 2.671691965021205

Epoch: 6| Step: 8
Training loss: 0.440529619539573
Validation loss: 2.66719169857384

Epoch: 6| Step: 9
Training loss: 0.9194518749427255
Validation loss: 2.6323114678335005

Epoch: 6| Step: 10
Training loss: 0.6194935704206265
Validation loss: 2.645349925591081

Epoch: 6| Step: 11
Training loss: 0.4673408945417901
Validation loss: 2.6307912288875275

Epoch: 6| Step: 12
Training loss: 0.889567098238619
Validation loss: 2.6147707672715232

Epoch: 6| Step: 13
Training loss: 0.4453474332258161
Validation loss: 2.6708816478900648

Epoch: 535| Step: 0
Training loss: 0.6556675460581982
Validation loss: 2.647723835362069

Epoch: 6| Step: 1
Training loss: 0.5897138591509168
Validation loss: 2.6518710858193266

Epoch: 6| Step: 2
Training loss: 0.8264021315880433
Validation loss: 2.664470181071087

Epoch: 6| Step: 3
Training loss: 0.83033472022093
Validation loss: 2.6614788047327993

Epoch: 6| Step: 4
Training loss: 0.8084986534036664
Validation loss: 2.6488450588861543

Epoch: 6| Step: 5
Training loss: 0.7195245052854053
Validation loss: 2.651420314953549

Epoch: 6| Step: 6
Training loss: 0.7168105537294333
Validation loss: 2.6339717924808843

Epoch: 6| Step: 7
Training loss: 0.7411538404906554
Validation loss: 2.650798838141787

Epoch: 6| Step: 8
Training loss: 0.8770522505507158
Validation loss: 2.6387875187921033

Epoch: 6| Step: 9
Training loss: 1.3006196709248274
Validation loss: 2.633811039065097

Epoch: 6| Step: 10
Training loss: 0.48451170991716197
Validation loss: 2.685616955570823

Epoch: 6| Step: 11
Training loss: 0.6988788822989381
Validation loss: 2.667626523179405

Epoch: 6| Step: 12
Training loss: 0.7275216119708778
Validation loss: 2.709951333625092

Epoch: 6| Step: 13
Training loss: 0.9283732573509682
Validation loss: 2.6581676338803377

Epoch: 536| Step: 0
Training loss: 1.370996281563845
Validation loss: 2.666943312402761

Epoch: 6| Step: 1
Training loss: 0.739922369673955
Validation loss: 2.6378562310708054

Epoch: 6| Step: 2
Training loss: 0.7652678921940473
Validation loss: 2.649173161176962

Epoch: 6| Step: 3
Training loss: 0.8054496341068669
Validation loss: 2.635817214298057

Epoch: 6| Step: 4
Training loss: 0.7470320548440396
Validation loss: 2.6457222845873765

Epoch: 6| Step: 5
Training loss: 0.3478172229607267
Validation loss: 2.6338389869406025

Epoch: 6| Step: 6
Training loss: 0.8197988445996949
Validation loss: 2.6602597773261096

Epoch: 6| Step: 7
Training loss: 0.34579316814652966
Validation loss: 2.6279216354115733

Epoch: 6| Step: 8
Training loss: 0.6876585300774404
Validation loss: 2.655990593710091

Epoch: 6| Step: 9
Training loss: 0.6071449948922356
Validation loss: 2.6411531768048406

Epoch: 6| Step: 10
Training loss: 0.6641460141792443
Validation loss: 2.6631424795723917

Epoch: 6| Step: 11
Training loss: 0.7405777187787752
Validation loss: 2.693265935292529

Epoch: 6| Step: 12
Training loss: 0.8292287632359369
Validation loss: 2.6492360705170244

Epoch: 6| Step: 13
Training loss: 0.7131513980857391
Validation loss: 2.6772173297401864

Epoch: 537| Step: 0
Training loss: 0.6543030468094526
Validation loss: 2.6607817990884643

Epoch: 6| Step: 1
Training loss: 0.6227202800150552
Validation loss: 2.670971973346706

Epoch: 6| Step: 2
Training loss: 0.6371944265470874
Validation loss: 2.6738080334724823

Epoch: 6| Step: 3
Training loss: 0.8475991506726203
Validation loss: 2.6239614624817134

Epoch: 6| Step: 4
Training loss: 0.6976253746180715
Validation loss: 2.6263721100904953

Epoch: 6| Step: 5
Training loss: 0.8867052052005323
Validation loss: 2.638404718083103

Epoch: 6| Step: 6
Training loss: 0.591620063177612
Validation loss: 2.643829261256654

Epoch: 6| Step: 7
Training loss: 0.7576939204931317
Validation loss: 2.642065816391489

Epoch: 6| Step: 8
Training loss: 0.5741548048472634
Validation loss: 2.650033756102249

Epoch: 6| Step: 9
Training loss: 0.8184712044504046
Validation loss: 2.6765809080653447

Epoch: 6| Step: 10
Training loss: 0.4688387786717614
Validation loss: 2.664398409871381

Epoch: 6| Step: 11
Training loss: 0.619302361479559
Validation loss: 2.672822192492215

Epoch: 6| Step: 12
Training loss: 1.4204131775814377
Validation loss: 2.6872481733481184

Epoch: 6| Step: 13
Training loss: 0.8603457776501922
Validation loss: 2.6459664997685586

Epoch: 538| Step: 0
Training loss: 0.5732504017126021
Validation loss: 2.689134763070701

Epoch: 6| Step: 1
Training loss: 1.0621803027114274
Validation loss: 2.634157130695464

Epoch: 6| Step: 2
Training loss: 0.6377797560111028
Validation loss: 2.6237018967570833

Epoch: 6| Step: 3
Training loss: 0.5233622824301554
Validation loss: 2.6845148081011425

Epoch: 6| Step: 4
Training loss: 0.799648619016286
Validation loss: 2.63774540987139

Epoch: 6| Step: 5
Training loss: 0.9060364175555133
Validation loss: 2.6333689524711916

Epoch: 6| Step: 6
Training loss: 0.22167010013501395
Validation loss: 2.6032664131402687

Epoch: 6| Step: 7
Training loss: 0.5778820970954742
Validation loss: 2.630391145727274

Epoch: 6| Step: 8
Training loss: 0.9185251051535294
Validation loss: 2.655579821053448

Epoch: 6| Step: 9
Training loss: 0.6156300559054118
Validation loss: 2.676782370781408

Epoch: 6| Step: 10
Training loss: 1.2130989227558058
Validation loss: 2.7176795731525107

Epoch: 6| Step: 11
Training loss: 0.6278241010916551
Validation loss: 2.7130096489051896

Epoch: 6| Step: 12
Training loss: 0.7447529673803758
Validation loss: 2.7393773621949946

Epoch: 6| Step: 13
Training loss: 0.7570402398771438
Validation loss: 2.715261331123116

Epoch: 539| Step: 0
Training loss: 0.7510769582243874
Validation loss: 2.696371238704667

Epoch: 6| Step: 1
Training loss: 0.7342017760814111
Validation loss: 2.681776799504075

Epoch: 6| Step: 2
Training loss: 0.8559922310641501
Validation loss: 2.633873810164476

Epoch: 6| Step: 3
Training loss: 0.711298253680182
Validation loss: 2.662376188867444

Epoch: 6| Step: 4
Training loss: 0.5921815182426516
Validation loss: 2.653223269365653

Epoch: 6| Step: 5
Training loss: 0.6226559072993734
Validation loss: 2.658841137856486

Epoch: 6| Step: 6
Training loss: 0.7194992803870891
Validation loss: 2.61873182497544

Epoch: 6| Step: 7
Training loss: 0.9264233772597767
Validation loss: 2.6865331213084187

Epoch: 6| Step: 8
Training loss: 0.8501462445952472
Validation loss: 2.706501709300251

Epoch: 6| Step: 9
Training loss: 0.4084338033752572
Validation loss: 2.722860972452236

Epoch: 6| Step: 10
Training loss: 0.8049591494792281
Validation loss: 2.7361200917333957

Epoch: 6| Step: 11
Training loss: 0.7126889296225206
Validation loss: 2.7250395731419994

Epoch: 6| Step: 12
Training loss: 1.2264375562264942
Validation loss: 2.679334979125011

Epoch: 6| Step: 13
Training loss: 0.6718697658601082
Validation loss: 2.680893831839565

Epoch: 540| Step: 0
Training loss: 0.5535943448469696
Validation loss: 2.665053664896933

Epoch: 6| Step: 1
Training loss: 0.6480896257920155
Validation loss: 2.617670926080262

Epoch: 6| Step: 2
Training loss: 0.6843581802879264
Validation loss: 2.645804553222191

Epoch: 6| Step: 3
Training loss: 0.8828723853400794
Validation loss: 2.620299253160536

Epoch: 6| Step: 4
Training loss: 0.50615698112882
Validation loss: 2.6379879990927715

Epoch: 6| Step: 5
Training loss: 0.8588057279759118
Validation loss: 2.625265144204334

Epoch: 6| Step: 6
Training loss: 1.3086817469829992
Validation loss: 2.6208001891125097

Epoch: 6| Step: 7
Training loss: 0.6769915200608151
Validation loss: 2.6638793920877295

Epoch: 6| Step: 8
Training loss: 0.9335883870629177
Validation loss: 2.633373295345909

Epoch: 6| Step: 9
Training loss: 0.3269796590850969
Validation loss: 2.6131142718154425

Epoch: 6| Step: 10
Training loss: 0.6278836009434955
Validation loss: 2.615198970281989

Epoch: 6| Step: 11
Training loss: 1.0554320356532862
Validation loss: 2.657811210218067

Epoch: 6| Step: 12
Training loss: 0.5144884704172891
Validation loss: 2.677958613551409

Epoch: 6| Step: 13
Training loss: 0.32057518771018145
Validation loss: 2.6758891383978316

Epoch: 541| Step: 0
Training loss: 0.4979618673145186
Validation loss: 2.718274058001918

Epoch: 6| Step: 1
Training loss: 0.5365747183562218
Validation loss: 2.696804346768866

Epoch: 6| Step: 2
Training loss: 0.8492062719528549
Validation loss: 2.688501249264475

Epoch: 6| Step: 3
Training loss: 1.275030578919769
Validation loss: 2.697646804396322

Epoch: 6| Step: 4
Training loss: 0.7846077288783467
Validation loss: 2.63311963355885

Epoch: 6| Step: 5
Training loss: 0.5424281660767567
Validation loss: 2.5845146402462817

Epoch: 6| Step: 6
Training loss: 0.6756011634736463
Validation loss: 2.556721913669625

Epoch: 6| Step: 7
Training loss: 0.7200704138815667
Validation loss: 2.5379874276485332

Epoch: 6| Step: 8
Training loss: 0.6419490529312242
Validation loss: 2.6131165802654848

Epoch: 6| Step: 9
Training loss: 0.8980158604281131
Validation loss: 2.6713320598992296

Epoch: 6| Step: 10
Training loss: 0.5600828050802849
Validation loss: 2.6658935514118998

Epoch: 6| Step: 11
Training loss: 0.5617231461693817
Validation loss: 2.6751858138482842

Epoch: 6| Step: 12
Training loss: 0.987883325612413
Validation loss: 2.6460081276400658

Epoch: 6| Step: 13
Training loss: 1.0981558209318516
Validation loss: 2.6115994672744987

Epoch: 542| Step: 0
Training loss: 0.798689366160021
Validation loss: 2.613706453385434

Epoch: 6| Step: 1
Training loss: 0.8771209556200394
Validation loss: 2.618049025521773

Epoch: 6| Step: 2
Training loss: 0.7134012562137813
Validation loss: 2.6668706580042585

Epoch: 6| Step: 3
Training loss: 0.7923463530470438
Validation loss: 2.6346589503351927

Epoch: 6| Step: 4
Training loss: 0.7772962086003901
Validation loss: 2.682749110655447

Epoch: 6| Step: 5
Training loss: 0.6097421762575254
Validation loss: 2.694462770377797

Epoch: 6| Step: 6
Training loss: 0.7041565427861227
Validation loss: 2.609172573224074

Epoch: 6| Step: 7
Training loss: 0.6513182523037973
Validation loss: 2.6075130188470586

Epoch: 6| Step: 8
Training loss: 0.76905401312754
Validation loss: 2.621139701774352

Epoch: 6| Step: 9
Training loss: 1.209417656828811
Validation loss: 2.6072646620249835

Epoch: 6| Step: 10
Training loss: 0.674695614778768
Validation loss: 2.5797526621356757

Epoch: 6| Step: 11
Training loss: 0.5388446588843183
Validation loss: 2.6363511804401587

Epoch: 6| Step: 12
Training loss: 0.6863664906199555
Validation loss: 2.630540659908367

Epoch: 6| Step: 13
Training loss: 0.6440751051097302
Validation loss: 2.5984353639521625

Epoch: 543| Step: 0
Training loss: 0.7352844450819311
Validation loss: 2.579198432461816

Epoch: 6| Step: 1
Training loss: 0.5141726761296208
Validation loss: 2.596374294083556

Epoch: 6| Step: 2
Training loss: 0.6197641163534375
Validation loss: 2.5830648767694537

Epoch: 6| Step: 3
Training loss: 0.7822930049419173
Validation loss: 2.602420223405414

Epoch: 6| Step: 4
Training loss: 0.9030271972180892
Validation loss: 2.6080123608212764

Epoch: 6| Step: 5
Training loss: 1.2751995603677908
Validation loss: 2.634034844432378

Epoch: 6| Step: 6
Training loss: 0.6716241811949316
Validation loss: 2.651021228700783

Epoch: 6| Step: 7
Training loss: 0.4227631368530382
Validation loss: 2.704304825724662

Epoch: 6| Step: 8
Training loss: 0.5776192282755896
Validation loss: 2.72132860067591

Epoch: 6| Step: 9
Training loss: 0.8777676136767009
Validation loss: 2.67756936513367

Epoch: 6| Step: 10
Training loss: 0.5842235164850889
Validation loss: 2.6808233083991664

Epoch: 6| Step: 11
Training loss: 0.9021739387087571
Validation loss: 2.6623856047102272

Epoch: 6| Step: 12
Training loss: 0.8264356692525455
Validation loss: 2.643381758235209

Epoch: 6| Step: 13
Training loss: 0.6305141153759678
Validation loss: 2.649458901886733

Epoch: 544| Step: 0
Training loss: 0.47565550559687186
Validation loss: 2.664033342961574

Epoch: 6| Step: 1
Training loss: 0.7782298649365355
Validation loss: 2.67646279765647

Epoch: 6| Step: 2
Training loss: 0.3970474604360282
Validation loss: 2.653772385504905

Epoch: 6| Step: 3
Training loss: 0.43668452966470694
Validation loss: 2.68471329106093

Epoch: 6| Step: 4
Training loss: 0.7592744784285766
Validation loss: 2.6956005226105204

Epoch: 6| Step: 5
Training loss: 0.6375075059336676
Validation loss: 2.6764094436355177

Epoch: 6| Step: 6
Training loss: 1.2513619632531516
Validation loss: 2.678699448178252

Epoch: 6| Step: 7
Training loss: 0.8539523964686616
Validation loss: 2.6873680839777343

Epoch: 6| Step: 8
Training loss: 0.5935453262921465
Validation loss: 2.683210196816476

Epoch: 6| Step: 9
Training loss: 0.8312673868067544
Validation loss: 2.6652074796467407

Epoch: 6| Step: 10
Training loss: 0.6166421436468486
Validation loss: 2.6182502793921323

Epoch: 6| Step: 11
Training loss: 0.6745123002052701
Validation loss: 2.651988961297983

Epoch: 6| Step: 12
Training loss: 0.8857419856196366
Validation loss: 2.6402603191761083

Epoch: 6| Step: 13
Training loss: 1.022709012109362
Validation loss: 2.6050059433345463

Epoch: 545| Step: 0
Training loss: 0.8096509279025164
Validation loss: 2.6589730017158355

Epoch: 6| Step: 1
Training loss: 0.5338543279383966
Validation loss: 2.650385833145143

Epoch: 6| Step: 2
Training loss: 0.31325802657506346
Validation loss: 2.653606731180604

Epoch: 6| Step: 3
Training loss: 0.3985251349021358
Validation loss: 2.6749454949689095

Epoch: 6| Step: 4
Training loss: 0.6753155200472359
Validation loss: 2.7100355423289257

Epoch: 6| Step: 5
Training loss: 0.7562991890791596
Validation loss: 2.6725203929130625

Epoch: 6| Step: 6
Training loss: 0.7840067481558239
Validation loss: 2.644202440837094

Epoch: 6| Step: 7
Training loss: 0.5669199225680676
Validation loss: 2.6383586550177833

Epoch: 6| Step: 8
Training loss: 0.627178781369921
Validation loss: 2.5554195179547348

Epoch: 6| Step: 9
Training loss: 0.6928913524803225
Validation loss: 2.5790895886842997

Epoch: 6| Step: 10
Training loss: 0.938959003654485
Validation loss: 2.5730944774601316

Epoch: 6| Step: 11
Training loss: 1.1679642080773676
Validation loss: 2.6219582775174226

Epoch: 6| Step: 12
Training loss: 0.829876397247908
Validation loss: 2.6027031495364708

Epoch: 6| Step: 13
Training loss: 0.9102361095576629
Validation loss: 2.609627479431216

Epoch: 546| Step: 0
Training loss: 1.1337981047093135
Validation loss: 2.6415054417530164

Epoch: 6| Step: 1
Training loss: 0.4663204011870216
Validation loss: 2.6592245945578727

Epoch: 6| Step: 2
Training loss: 0.7612891134852897
Validation loss: 2.6829046380308967

Epoch: 6| Step: 3
Training loss: 1.0624294818589302
Validation loss: 2.693370374412468

Epoch: 6| Step: 4
Training loss: 0.39564007090086106
Validation loss: 2.6480163283858804

Epoch: 6| Step: 5
Training loss: 0.6097857240422722
Validation loss: 2.60928911472175

Epoch: 6| Step: 6
Training loss: 0.7817630990239005
Validation loss: 2.5660521935016605

Epoch: 6| Step: 7
Training loss: 0.7355473676893597
Validation loss: 2.5117155471296773

Epoch: 6| Step: 8
Training loss: 0.6825532241999991
Validation loss: 2.554146553753559

Epoch: 6| Step: 9
Training loss: 0.7488832902164512
Validation loss: 2.4532719611144094

Epoch: 6| Step: 10
Training loss: 0.5478689697546482
Validation loss: 2.5651773661668384

Epoch: 6| Step: 11
Training loss: 0.4678050052447629
Validation loss: 2.5512105685414945

Epoch: 6| Step: 12
Training loss: 0.6289413158047389
Validation loss: 2.5834118959810852

Epoch: 6| Step: 13
Training loss: 0.9956140896665748
Validation loss: 2.573487563754253

Epoch: 547| Step: 0
Training loss: 0.6411415204280898
Validation loss: 2.605968105923444

Epoch: 6| Step: 1
Training loss: 0.9158879498159379
Validation loss: 2.6098473234212625

Epoch: 6| Step: 2
Training loss: 0.7200104400752056
Validation loss: 2.627851316627891

Epoch: 6| Step: 3
Training loss: 0.8301153556103801
Validation loss: 2.6116709500275643

Epoch: 6| Step: 4
Training loss: 0.8405607135114675
Validation loss: 2.6174242481012846

Epoch: 6| Step: 5
Training loss: 0.5529413812897152
Validation loss: 2.604919419961686

Epoch: 6| Step: 6
Training loss: 0.5087295468129771
Validation loss: 2.627478845728404

Epoch: 6| Step: 7
Training loss: 0.587238190530167
Validation loss: 2.636146477108848

Epoch: 6| Step: 8
Training loss: 0.35737511584322407
Validation loss: 2.6983711644419652

Epoch: 6| Step: 9
Training loss: 0.6112421237305491
Validation loss: 2.650117045932927

Epoch: 6| Step: 10
Training loss: 0.4894487385351565
Validation loss: 2.611210285283883

Epoch: 6| Step: 11
Training loss: 1.2809848976346832
Validation loss: 2.588518243406679

Epoch: 6| Step: 12
Training loss: 0.8483359428870255
Validation loss: 2.614861643200022

Epoch: 6| Step: 13
Training loss: 0.6020679084711521
Validation loss: 2.5808451711212643

Epoch: 548| Step: 0
Training loss: 0.677144676266268
Validation loss: 2.565123063142737

Epoch: 6| Step: 1
Training loss: 0.6490039878775594
Validation loss: 2.588514703753088

Epoch: 6| Step: 2
Training loss: 0.7094147692048215
Validation loss: 2.5766077573239157

Epoch: 6| Step: 3
Training loss: 0.7074921512505391
Validation loss: 2.5974502865483644

Epoch: 6| Step: 4
Training loss: 0.7952993935215174
Validation loss: 2.619128056561998

Epoch: 6| Step: 5
Training loss: 0.8920344861189542
Validation loss: 2.5906718036865897

Epoch: 6| Step: 6
Training loss: 0.5459277805364994
Validation loss: 2.626581497398437

Epoch: 6| Step: 7
Training loss: 0.5555908208489078
Validation loss: 2.6739319983301586

Epoch: 6| Step: 8
Training loss: 0.49864079087624913
Validation loss: 2.6691158325107893

Epoch: 6| Step: 9
Training loss: 0.7486447168882138
Validation loss: 2.671433574541128

Epoch: 6| Step: 10
Training loss: 0.23450347240313124
Validation loss: 2.6526868670355053

Epoch: 6| Step: 11
Training loss: 1.0532735883895035
Validation loss: 2.6578489158928864

Epoch: 6| Step: 12
Training loss: 0.8640493022883434
Validation loss: 2.638898964607017

Epoch: 6| Step: 13
Training loss: 0.7604758270103673
Validation loss: 2.6512663017759963

Epoch: 549| Step: 0
Training loss: 0.8682027836028923
Validation loss: 2.6658570139771753

Epoch: 6| Step: 1
Training loss: 0.7709725142600389
Validation loss: 2.630574099071554

Epoch: 6| Step: 2
Training loss: 0.5955198412487642
Validation loss: 2.640618399208723

Epoch: 6| Step: 3
Training loss: 0.8157937704695284
Validation loss: 2.602956218994525

Epoch: 6| Step: 4
Training loss: 0.8127169686172987
Validation loss: 2.6104377540933665

Epoch: 6| Step: 5
Training loss: 0.555848558632973
Validation loss: 2.583799433926841

Epoch: 6| Step: 6
Training loss: 0.5369180234427832
Validation loss: 2.6147664336981404

Epoch: 6| Step: 7
Training loss: 0.6051017879737686
Validation loss: 2.5813751198721397

Epoch: 6| Step: 8
Training loss: 0.5702371416862321
Validation loss: 2.6370557630880516

Epoch: 6| Step: 9
Training loss: 0.6302072088898855
Validation loss: 2.6162483916866552

Epoch: 6| Step: 10
Training loss: 0.47611306056493136
Validation loss: 2.675660244264238

Epoch: 6| Step: 11
Training loss: 1.1331943789081815
Validation loss: 2.653363549640715

Epoch: 6| Step: 12
Training loss: 0.817747301440683
Validation loss: 2.69186791516232

Epoch: 6| Step: 13
Training loss: 0.559371566761925
Validation loss: 2.658125558929876

Epoch: 550| Step: 0
Training loss: 0.5464592034171426
Validation loss: 2.6479164981013392

Epoch: 6| Step: 1
Training loss: 0.5633543996097906
Validation loss: 2.6470404298499717

Epoch: 6| Step: 2
Training loss: 0.8238739449504845
Validation loss: 2.629036354475959

Epoch: 6| Step: 3
Training loss: 0.8681552058348506
Validation loss: 2.5951688414094503

Epoch: 6| Step: 4
Training loss: 0.9699028907420514
Validation loss: 2.605287813753384

Epoch: 6| Step: 5
Training loss: 0.7296713490301782
Validation loss: 2.6262412889055993

Epoch: 6| Step: 6
Training loss: 0.5480992646303413
Validation loss: 2.5974923583542875

Epoch: 6| Step: 7
Training loss: 0.6914415296616274
Validation loss: 2.590784932355589

Epoch: 6| Step: 8
Training loss: 0.7187519902740787
Validation loss: 2.6076087016124094

Epoch: 6| Step: 9
Training loss: 0.3441307603372652
Validation loss: 2.618683024701302

Epoch: 6| Step: 10
Training loss: 0.9497417061170712
Validation loss: 2.6283263657126046

Epoch: 6| Step: 11
Training loss: 0.6082403427624241
Validation loss: 2.6547838666002925

Epoch: 6| Step: 12
Training loss: 0.5651986765314847
Validation loss: 2.6357772520803775

Epoch: 6| Step: 13
Training loss: 0.5172302516543233
Validation loss: 2.665509694618267

Testing loss: 2.44715548429251
