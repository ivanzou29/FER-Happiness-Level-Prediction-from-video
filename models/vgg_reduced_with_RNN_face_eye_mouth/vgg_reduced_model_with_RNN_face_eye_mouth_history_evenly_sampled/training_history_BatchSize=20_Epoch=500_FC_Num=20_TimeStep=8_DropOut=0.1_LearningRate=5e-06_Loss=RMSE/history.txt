Epoch: 1| Step: 0
Training loss: 6.090029788891828
Validation loss: 5.828462922521416

Epoch: 5| Step: 1
Training loss: 7.18696711679486
Validation loss: 5.824346647626317

Epoch: 5| Step: 2
Training loss: 6.068164813726055
Validation loss: 5.8199950821042465

Epoch: 5| Step: 3
Training loss: 5.913759977194805
Validation loss: 5.815825549362674

Epoch: 5| Step: 4
Training loss: 5.211271306774624
Validation loss: 5.811951451611036

Epoch: 5| Step: 5
Training loss: 4.404149630299186
Validation loss: 5.807849436286025

Epoch: 5| Step: 6
Training loss: 5.014689800979601
Validation loss: 5.803916822466713

Epoch: 5| Step: 7
Training loss: 6.308831990470532
Validation loss: 5.799365968600216

Epoch: 5| Step: 8
Training loss: 6.0518270712966435
Validation loss: 5.7953250697919145

Epoch: 5| Step: 9
Training loss: 5.562152465936302
Validation loss: 5.790890182223558

Epoch: 5| Step: 10
Training loss: 6.004758219683409
Validation loss: 5.7858420925402525

Epoch: 2| Step: 0
Training loss: 6.323370006550786
Validation loss: 5.780773416579064

Epoch: 5| Step: 1
Training loss: 5.359889770342272
Validation loss: 5.775590152077823

Epoch: 5| Step: 2
Training loss: 4.417648830011586
Validation loss: 5.7695740079098305

Epoch: 5| Step: 3
Training loss: 5.477929307975216
Validation loss: 5.764090025699721

Epoch: 5| Step: 4
Training loss: 6.717434066715789
Validation loss: 5.757408541218519

Epoch: 5| Step: 5
Training loss: 5.873638563477091
Validation loss: 5.751133486474657

Epoch: 5| Step: 6
Training loss: 5.961087246235083
Validation loss: 5.743375042498388

Epoch: 5| Step: 7
Training loss: 6.792149376438615
Validation loss: 5.735823366199054

Epoch: 5| Step: 8
Training loss: 5.372095077116388
Validation loss: 5.72752899599012

Epoch: 5| Step: 9
Training loss: 5.737195893250403
Validation loss: 5.718508974372534

Epoch: 5| Step: 10
Training loss: 5.041169995941271
Validation loss: 5.709128727778053

Epoch: 3| Step: 0
Training loss: 5.651584281594655
Validation loss: 5.6992796197460915

Epoch: 5| Step: 1
Training loss: 4.230126082613222
Validation loss: 5.688407464052903

Epoch: 5| Step: 2
Training loss: 6.671563384665206
Validation loss: 5.677440363019145

Epoch: 5| Step: 3
Training loss: 5.972296015951356
Validation loss: 5.665989706270548

Epoch: 5| Step: 4
Training loss: 5.540135891621417
Validation loss: 5.653581119125281

Epoch: 5| Step: 5
Training loss: 5.732846755442424
Validation loss: 5.641744135904281

Epoch: 5| Step: 6
Training loss: 6.493072045543854
Validation loss: 5.628258428376552

Epoch: 5| Step: 7
Training loss: 4.993180010639747
Validation loss: 5.6145709983176815

Epoch: 5| Step: 8
Training loss: 5.667273133679769
Validation loss: 5.599064333561681

Epoch: 5| Step: 9
Training loss: 5.671475146782905
Validation loss: 5.583492467183097

Epoch: 5| Step: 10
Training loss: 5.365897877441196
Validation loss: 5.566443798065919

Epoch: 4| Step: 0
Training loss: 5.309218346775291
Validation loss: 5.550652055499082

Epoch: 5| Step: 1
Training loss: 5.38870638552514
Validation loss: 5.533055544666997

Epoch: 5| Step: 2
Training loss: 5.288609179589976
Validation loss: 5.514187191020748

Epoch: 5| Step: 3
Training loss: 5.376912153914464
Validation loss: 5.496208132996008

Epoch: 5| Step: 4
Training loss: 5.980406877333434
Validation loss: 5.47581801391446

Epoch: 5| Step: 5
Training loss: 6.312960768397827
Validation loss: 5.4550190475908975

Epoch: 5| Step: 6
Training loss: 5.133431732588777
Validation loss: 5.434288682461855

Epoch: 5| Step: 7
Training loss: 4.968132124576698
Validation loss: 5.413237505560204

Epoch: 5| Step: 8
Training loss: 6.349215253263618
Validation loss: 5.390641192316338

Epoch: 5| Step: 9
Training loss: 5.171988218053628
Validation loss: 5.368515674498344

Epoch: 5| Step: 10
Training loss: 4.8184326067347385
Validation loss: 5.342124944697942

Epoch: 5| Step: 0
Training loss: 4.9787905030898045
Validation loss: 5.318408257081203

Epoch: 5| Step: 1
Training loss: 5.774898194575801
Validation loss: 5.2942972631438225

Epoch: 5| Step: 2
Training loss: 4.900129254251771
Validation loss: 5.267368703096142

Epoch: 5| Step: 3
Training loss: 4.818046643175069
Validation loss: 5.2424377163578555

Epoch: 5| Step: 4
Training loss: 5.395991653221015
Validation loss: 5.215339110424505

Epoch: 5| Step: 5
Training loss: 4.666701498355756
Validation loss: 5.187885519667359

Epoch: 5| Step: 6
Training loss: 5.179574634363746
Validation loss: 5.158618033959536

Epoch: 5| Step: 7
Training loss: 4.6387263565879495
Validation loss: 5.131025012733236

Epoch: 5| Step: 8
Training loss: 5.3038106426770195
Validation loss: 5.103304423703399

Epoch: 5| Step: 9
Training loss: 5.390423491761313
Validation loss: 5.070821994635988

Epoch: 5| Step: 10
Training loss: 6.41319114723068
Validation loss: 5.0411936979552765

Epoch: 6| Step: 0
Training loss: 5.277304174132232
Validation loss: 5.010486193568017

Epoch: 5| Step: 1
Training loss: 3.8979955510622473
Validation loss: 4.978626585258884

Epoch: 5| Step: 2
Training loss: 4.674299854746171
Validation loss: 4.946797920868085

Epoch: 5| Step: 3
Training loss: 5.101561004498249
Validation loss: 4.917052420529209

Epoch: 5| Step: 4
Training loss: 5.834819313788607
Validation loss: 4.885373922839234

Epoch: 5| Step: 5
Training loss: 4.391481146371409
Validation loss: 4.852953229664776

Epoch: 5| Step: 6
Training loss: 4.398162128508063
Validation loss: 4.824333988185194

Epoch: 5| Step: 7
Training loss: 4.779160984416179
Validation loss: 4.794249333572642

Epoch: 5| Step: 8
Training loss: 5.642072074594747
Validation loss: 4.764080529075636

Epoch: 5| Step: 9
Training loss: 5.233249645819388
Validation loss: 4.731899915577017

Epoch: 5| Step: 10
Training loss: 4.509610192820054
Validation loss: 4.701027411104402

Epoch: 7| Step: 0
Training loss: 4.898896945658246
Validation loss: 4.66905289098614

Epoch: 5| Step: 1
Training loss: 5.900062508979314
Validation loss: 4.638169504488643

Epoch: 5| Step: 2
Training loss: 3.9232605694095057
Validation loss: 4.598410107677288

Epoch: 5| Step: 3
Training loss: 5.03458346237784
Validation loss: 4.558210668577927

Epoch: 5| Step: 4
Training loss: 4.068820672659311
Validation loss: 4.519530732680777

Epoch: 5| Step: 5
Training loss: 4.632640610283497
Validation loss: 4.484864461932376

Epoch: 5| Step: 6
Training loss: 3.612733013729524
Validation loss: 4.454849037811344

Epoch: 5| Step: 7
Training loss: 4.631866306991151
Validation loss: 4.42944914499959

Epoch: 5| Step: 8
Training loss: 4.879581352787019
Validation loss: 4.405674762074561

Epoch: 5| Step: 9
Training loss: 4.122687645337749
Validation loss: 4.382986536760708

Epoch: 5| Step: 10
Training loss: 4.424390528889151
Validation loss: 4.357117041265217

Epoch: 8| Step: 0
Training loss: 4.33871101821273
Validation loss: 4.334478971494118

Epoch: 5| Step: 1
Training loss: 4.615952173206741
Validation loss: 4.314058275245928

Epoch: 5| Step: 2
Training loss: 4.914808838271133
Validation loss: 4.292863174668005

Epoch: 5| Step: 3
Training loss: 4.818600639670587
Validation loss: 4.274371030399808

Epoch: 5| Step: 4
Training loss: 3.9002779054662455
Validation loss: 4.252040074209545

Epoch: 5| Step: 5
Training loss: 4.609388241506404
Validation loss: 4.228245601175981

Epoch: 5| Step: 6
Training loss: 4.379667571529759
Validation loss: 4.2054617502614065

Epoch: 5| Step: 7
Training loss: 4.652333295603808
Validation loss: 4.182208067878919

Epoch: 5| Step: 8
Training loss: 3.753589946270265
Validation loss: 4.163309014766092

Epoch: 5| Step: 9
Training loss: 3.6933344573376137
Validation loss: 4.139441315913701

Epoch: 5| Step: 10
Training loss: 3.96575562462633
Validation loss: 4.121394839551166

Epoch: 9| Step: 0
Training loss: 4.50714709363984
Validation loss: 4.104723886546041

Epoch: 5| Step: 1
Training loss: 3.9641030808334983
Validation loss: 4.089306437840491

Epoch: 5| Step: 2
Training loss: 4.418133234255704
Validation loss: 4.076567832236971

Epoch: 5| Step: 3
Training loss: 3.9396823708552366
Validation loss: 4.064402680084164

Epoch: 5| Step: 4
Training loss: 4.294630539516439
Validation loss: 4.054077553998312

Epoch: 5| Step: 5
Training loss: 3.6221070420168595
Validation loss: 4.043350870166967

Epoch: 5| Step: 6
Training loss: 3.8912520918210953
Validation loss: 4.030760136016656

Epoch: 5| Step: 7
Training loss: 4.5455469243459214
Validation loss: 4.020895445110842

Epoch: 5| Step: 8
Training loss: 5.036507459977517
Validation loss: 4.015032306706106

Epoch: 5| Step: 9
Training loss: 3.815790101274553
Validation loss: 3.9978020022937284

Epoch: 5| Step: 10
Training loss: 3.7136856343672604
Validation loss: 3.9851759920791325

Epoch: 10| Step: 0
Training loss: 4.976467065779408
Validation loss: 3.9754546150253103

Epoch: 5| Step: 1
Training loss: 3.513631433463067
Validation loss: 3.9680883844267654

Epoch: 5| Step: 2
Training loss: 4.186550203473161
Validation loss: 3.957788671942562

Epoch: 5| Step: 3
Training loss: 4.418725499539794
Validation loss: 3.9495070094127116

Epoch: 5| Step: 4
Training loss: 3.040739327424933
Validation loss: 3.9395247392447703

Epoch: 5| Step: 5
Training loss: 3.9048782991989874
Validation loss: 3.929958941086971

Epoch: 5| Step: 6
Training loss: 3.6640850139650127
Validation loss: 3.921675759329403

Epoch: 5| Step: 7
Training loss: 4.814307727900843
Validation loss: 3.914370275748905

Epoch: 5| Step: 8
Training loss: 4.381255990322225
Validation loss: 3.9089472781333057

Epoch: 5| Step: 9
Training loss: 4.1815603463218896
Validation loss: 3.9002316130843835

Epoch: 5| Step: 10
Training loss: 3.320831760867204
Validation loss: 3.8912506516369763

Epoch: 11| Step: 0
Training loss: 4.928507281215692
Validation loss: 3.887346573522861

Epoch: 5| Step: 1
Training loss: 3.6164350942374894
Validation loss: 3.87824391617234

Epoch: 5| Step: 2
Training loss: 4.369349290949209
Validation loss: 3.876559775527518

Epoch: 5| Step: 3
Training loss: 4.458038082625874
Validation loss: 3.8690724124359708

Epoch: 5| Step: 4
Training loss: 3.6002687459875773
Validation loss: 3.8608404025153273

Epoch: 5| Step: 5
Training loss: 4.124470532278156
Validation loss: 3.8559465727818742

Epoch: 5| Step: 6
Training loss: 3.4947811454390965
Validation loss: 3.8500248310368153

Epoch: 5| Step: 7
Training loss: 4.178411841692825
Validation loss: 3.8445910875744946

Epoch: 5| Step: 8
Training loss: 3.5195531982008483
Validation loss: 3.8396009102743087

Epoch: 5| Step: 9
Training loss: 4.097071806881967
Validation loss: 3.8356782973374446

Epoch: 5| Step: 10
Training loss: 3.517553046612088
Validation loss: 3.8284023885072003

Epoch: 12| Step: 0
Training loss: 3.6562601725118906
Validation loss: 3.8258123266738067

Epoch: 5| Step: 1
Training loss: 3.7954112555579425
Validation loss: 3.821611549407123

Epoch: 5| Step: 2
Training loss: 3.7725726729990345
Validation loss: 3.8154060884633956

Epoch: 5| Step: 3
Training loss: 3.795936499881526
Validation loss: 3.814013796047115

Epoch: 5| Step: 4
Training loss: 4.0229840365668466
Validation loss: 3.810929179047859

Epoch: 5| Step: 5
Training loss: 4.05010574579529
Validation loss: 3.803907776198726

Epoch: 5| Step: 6
Training loss: 3.9593294329230355
Validation loss: 3.80037859993601

Epoch: 5| Step: 7
Training loss: 4.781663465386896
Validation loss: 3.7974377624466253

Epoch: 5| Step: 8
Training loss: 3.855856214106001
Validation loss: 3.7926584916568316

Epoch: 5| Step: 9
Training loss: 4.122596271563655
Validation loss: 3.7873562952086615

Epoch: 5| Step: 10
Training loss: 3.755433406072307
Validation loss: 3.7835757504002996

Epoch: 13| Step: 0
Training loss: 4.174503941104485
Validation loss: 3.779853233999237

Epoch: 5| Step: 1
Training loss: 3.3125308053365647
Validation loss: 3.773513167127563

Epoch: 5| Step: 2
Training loss: 3.1529744591517828
Validation loss: 3.7706335301829146

Epoch: 5| Step: 3
Training loss: 3.8941161643297115
Validation loss: 3.7660499414341673

Epoch: 5| Step: 4
Training loss: 4.6124453905796114
Validation loss: 3.7689026126631378

Epoch: 5| Step: 5
Training loss: 4.2883217872042145
Validation loss: 3.758963084808045

Epoch: 5| Step: 6
Training loss: 3.42897864035214
Validation loss: 3.7551665861940404

Epoch: 5| Step: 7
Training loss: 3.9118824139262856
Validation loss: 3.7524742318084408

Epoch: 5| Step: 8
Training loss: 3.8707188983888043
Validation loss: 3.7513080899607796

Epoch: 5| Step: 9
Training loss: 4.359600321097886
Validation loss: 3.746294215495556

Epoch: 5| Step: 10
Training loss: 4.057022627731907
Validation loss: 3.7427667321987066

Epoch: 14| Step: 0
Training loss: 3.0413433234042206
Validation loss: 3.73823088319273

Epoch: 5| Step: 1
Training loss: 3.966454029528059
Validation loss: 3.730614254315125

Epoch: 5| Step: 2
Training loss: 4.36651136592922
Validation loss: 3.725413693595912

Epoch: 5| Step: 3
Training loss: 3.564049902278673
Validation loss: 3.7188441188032293

Epoch: 5| Step: 4
Training loss: 3.251525814173902
Validation loss: 3.713232538426009

Epoch: 5| Step: 5
Training loss: 4.359103724198395
Validation loss: 3.7002952573725794

Epoch: 5| Step: 6
Training loss: 4.155531512806835
Validation loss: 3.6902831086561863

Epoch: 5| Step: 7
Training loss: 3.770230844042657
Validation loss: 3.680858215334704

Epoch: 5| Step: 8
Training loss: 4.278139418361044
Validation loss: 3.672573266697545

Epoch: 5| Step: 9
Training loss: 3.5992449339470434
Validation loss: 3.6684427802603445

Epoch: 5| Step: 10
Training loss: 4.116818029630034
Validation loss: 3.660767382639407

Epoch: 15| Step: 0
Training loss: 3.3742260928647094
Validation loss: 3.654333206246692

Epoch: 5| Step: 1
Training loss: 3.9163543630770166
Validation loss: 3.65097054582848

Epoch: 5| Step: 2
Training loss: 3.9243181984975535
Validation loss: 3.64526118604347

Epoch: 5| Step: 3
Training loss: 4.221136703710404
Validation loss: 3.6412098669303337

Epoch: 5| Step: 4
Training loss: 3.675871925978751
Validation loss: 3.6354111544678376

Epoch: 5| Step: 5
Training loss: 3.444323893115814
Validation loss: 3.63273916321545

Epoch: 5| Step: 6
Training loss: 3.4143147320833913
Validation loss: 3.624959213485655

Epoch: 5| Step: 7
Training loss: 3.423175999914641
Validation loss: 3.6224000890848695

Epoch: 5| Step: 8
Training loss: 3.6421653534139393
Validation loss: 3.617467533068522

Epoch: 5| Step: 9
Training loss: 4.208203052480738
Validation loss: 3.6146344892307494

Epoch: 5| Step: 10
Training loss: 4.725751318563255
Validation loss: 3.6086805876260675

Epoch: 16| Step: 0
Training loss: 4.178278548301593
Validation loss: 3.6013723382869465

Epoch: 5| Step: 1
Training loss: 3.027463612798484
Validation loss: 3.599226795187907

Epoch: 5| Step: 2
Training loss: 3.62818715964732
Validation loss: 3.5956962533559307

Epoch: 5| Step: 3
Training loss: 3.311242926688324
Validation loss: 3.5906480096723965

Epoch: 5| Step: 4
Training loss: 3.7678080835163867
Validation loss: 3.5835969250382904

Epoch: 5| Step: 5
Training loss: 3.390433591722506
Validation loss: 3.5785380145383106

Epoch: 5| Step: 6
Training loss: 4.552384960851522
Validation loss: 3.5763842119557427

Epoch: 5| Step: 7
Training loss: 4.091295278026502
Validation loss: 3.572203404100954

Epoch: 5| Step: 8
Training loss: 4.648753025662206
Validation loss: 3.567434618409598

Epoch: 5| Step: 9
Training loss: 2.980047473657335
Validation loss: 3.5602996455753804

Epoch: 5| Step: 10
Training loss: 3.5025226493718487
Validation loss: 3.5592912371978755

Epoch: 17| Step: 0
Training loss: 3.9376789839497643
Validation loss: 3.5535231857759455

Epoch: 5| Step: 1
Training loss: 3.6108260767676197
Validation loss: 3.5464303039337604

Epoch: 5| Step: 2
Training loss: 3.6229719868860744
Validation loss: 3.5378058283034712

Epoch: 5| Step: 3
Training loss: 3.9977079023222846
Validation loss: 3.536855305854963

Epoch: 5| Step: 4
Training loss: 3.46420320010901
Validation loss: 3.531006822372095

Epoch: 5| Step: 5
Training loss: 3.2309714575415613
Validation loss: 3.5226196550610007

Epoch: 5| Step: 6
Training loss: 3.4920934199348457
Validation loss: 3.5209960759115266

Epoch: 5| Step: 7
Training loss: 3.7548200783120893
Validation loss: 3.520300056180605

Epoch: 5| Step: 8
Training loss: 3.468755086259292
Validation loss: 3.51194893669328

Epoch: 5| Step: 9
Training loss: 4.2681687144974765
Validation loss: 3.5035632361331484

Epoch: 5| Step: 10
Training loss: 4.080657055998089
Validation loss: 3.4989517329716695

Epoch: 18| Step: 0
Training loss: 3.28997326199412
Validation loss: 3.4941218423052813

Epoch: 5| Step: 1
Training loss: 3.4075165240082343
Validation loss: 3.4926898289717774

Epoch: 5| Step: 2
Training loss: 4.201228171112818
Validation loss: 3.4879571295826572

Epoch: 5| Step: 3
Training loss: 3.4476154268788206
Validation loss: 3.485411263413951

Epoch: 5| Step: 4
Training loss: 3.7363092369164503
Validation loss: 3.4801572853647893

Epoch: 5| Step: 5
Training loss: 4.0764760158455084
Validation loss: 3.4768738000177044

Epoch: 5| Step: 6
Training loss: 3.7516947413551667
Validation loss: 3.4682882294084396

Epoch: 5| Step: 7
Training loss: 3.923263121770453
Validation loss: 3.46462951250128

Epoch: 5| Step: 8
Training loss: 3.5716093617047746
Validation loss: 3.458457985054933

Epoch: 5| Step: 9
Training loss: 3.4681474316947933
Validation loss: 3.4617384657791286

Epoch: 5| Step: 10
Training loss: 3.5984661172382353
Validation loss: 3.4573692053230043

Epoch: 19| Step: 0
Training loss: 3.9045965738994375
Validation loss: 3.4565855685970033

Epoch: 5| Step: 1
Training loss: 3.499612786808388
Validation loss: 3.45444388318034

Epoch: 5| Step: 2
Training loss: 3.60446692008043
Validation loss: 3.4540247838321285

Epoch: 5| Step: 3
Training loss: 3.630790295284893
Validation loss: 3.4493224559559326

Epoch: 5| Step: 4
Training loss: 3.1732376253564025
Validation loss: 3.4419445461283025

Epoch: 5| Step: 5
Training loss: 3.9736832123093997
Validation loss: 3.432487058853309

Epoch: 5| Step: 6
Training loss: 3.5037339592361305
Validation loss: 3.4274390151674248

Epoch: 5| Step: 7
Training loss: 4.30178474824853
Validation loss: 3.426216928345393

Epoch: 5| Step: 8
Training loss: 3.514231630345557
Validation loss: 3.42090193872143

Epoch: 5| Step: 9
Training loss: 3.171892137903978
Validation loss: 3.4183053512193116

Epoch: 5| Step: 10
Training loss: 3.77578921120876
Validation loss: 3.414660777884544

Epoch: 20| Step: 0
Training loss: 3.9713599566641538
Validation loss: 3.412228108066152

Epoch: 5| Step: 1
Training loss: 3.9432507859460646
Validation loss: 3.4093490325741

Epoch: 5| Step: 2
Training loss: 3.333244147697066
Validation loss: 3.403573961319233

Epoch: 5| Step: 3
Training loss: 3.650442352663193
Validation loss: 3.39823119475903

Epoch: 5| Step: 4
Training loss: 4.0133919648442715
Validation loss: 3.396660061976475

Epoch: 5| Step: 5
Training loss: 4.032102036441462
Validation loss: 3.3922091668172545

Epoch: 5| Step: 6
Training loss: 3.0354707572130404
Validation loss: 3.392421723647934

Epoch: 5| Step: 7
Training loss: 2.770379328042703
Validation loss: 3.391944866910471

Epoch: 5| Step: 8
Training loss: 3.5953199854859466
Validation loss: 3.3952161337645794

Epoch: 5| Step: 9
Training loss: 3.0991501350779083
Validation loss: 3.390445450993103

Epoch: 5| Step: 10
Training loss: 4.149856583288781
Validation loss: 3.3851231243132043

Epoch: 21| Step: 0
Training loss: 3.572522170343072
Validation loss: 3.3791348412910205

Epoch: 5| Step: 1
Training loss: 3.602311261307085
Validation loss: 3.375518234918272

Epoch: 5| Step: 2
Training loss: 2.8835765787469643
Validation loss: 3.3728280684338134

Epoch: 5| Step: 3
Training loss: 3.9182364922848465
Validation loss: 3.380345125987317

Epoch: 5| Step: 4
Training loss: 3.7195264502568275
Validation loss: 3.3681526804098976

Epoch: 5| Step: 5
Training loss: 3.6598123004081438
Validation loss: 3.3614913848251953

Epoch: 5| Step: 6
Training loss: 3.42447149278291
Validation loss: 3.3574090744181424

Epoch: 5| Step: 7
Training loss: 4.010540426086906
Validation loss: 3.3560670722262995

Epoch: 5| Step: 8
Training loss: 3.7283235303613202
Validation loss: 3.3519674061772466

Epoch: 5| Step: 9
Training loss: 3.075012337264456
Validation loss: 3.3521286990784747

Epoch: 5| Step: 10
Training loss: 3.7978780543962247
Validation loss: 3.3494294688590553

Epoch: 22| Step: 0
Training loss: 3.248346494984341
Validation loss: 3.3444183650733086

Epoch: 5| Step: 1
Training loss: 3.9236905580352337
Validation loss: 3.3429618690956584

Epoch: 5| Step: 2
Training loss: 3.1919591791224526
Validation loss: 3.3380074283400187

Epoch: 5| Step: 3
Training loss: 3.3369553596636106
Validation loss: 3.334294165803861

Epoch: 5| Step: 4
Training loss: 4.1763418907873335
Validation loss: 3.3253706783505446

Epoch: 5| Step: 5
Training loss: 2.796002129255147
Validation loss: 3.3269915832887285

Epoch: 5| Step: 6
Training loss: 3.91614798229409
Validation loss: 3.3215886114598416

Epoch: 5| Step: 7
Training loss: 3.1031132047646075
Validation loss: 3.3267274562767524

Epoch: 5| Step: 8
Training loss: 3.854987488366392
Validation loss: 3.336096428004728

Epoch: 5| Step: 9
Training loss: 3.451810975151842
Validation loss: 3.316170056862079

Epoch: 5| Step: 10
Training loss: 3.9624216884251298
Validation loss: 3.3072843681231014

Epoch: 23| Step: 0
Training loss: 2.8267184811767465
Validation loss: 3.304896520065365

Epoch: 5| Step: 1
Training loss: 3.3146512225807343
Validation loss: 3.303551219752152

Epoch: 5| Step: 2
Training loss: 3.825176987885327
Validation loss: 3.3018033135457703

Epoch: 5| Step: 3
Training loss: 3.341044820129222
Validation loss: 3.2944332182813065

Epoch: 5| Step: 4
Training loss: 4.106706920731997
Validation loss: 3.289725654407512

Epoch: 5| Step: 5
Training loss: 3.0488858361069817
Validation loss: 3.2855646895147346

Epoch: 5| Step: 6
Training loss: 3.3583372420547746
Validation loss: 3.2787136652840947

Epoch: 5| Step: 7
Training loss: 4.350891390266203
Validation loss: 3.2808372179320657

Epoch: 5| Step: 8
Training loss: 2.562670446170133
Validation loss: 3.2784924805263063

Epoch: 5| Step: 9
Training loss: 3.3946669434005172
Validation loss: 3.2784478648755933

Epoch: 5| Step: 10
Training loss: 4.329363373787195
Validation loss: 3.27231004679063

Epoch: 24| Step: 0
Training loss: 3.671980576316307
Validation loss: 3.269650186452367

Epoch: 5| Step: 1
Training loss: 3.0383106860978435
Validation loss: 3.265980523699637

Epoch: 5| Step: 2
Training loss: 3.382526059610674
Validation loss: 3.258099348356593

Epoch: 5| Step: 3
Training loss: 4.132416733250771
Validation loss: 3.261056491210641

Epoch: 5| Step: 4
Training loss: 4.027873673156135
Validation loss: 3.253609901363144

Epoch: 5| Step: 5
Training loss: 3.608051536310405
Validation loss: 3.260833762829711

Epoch: 5| Step: 6
Training loss: 3.113064824219451
Validation loss: 3.2479930862354385

Epoch: 5| Step: 7
Training loss: 3.194043940624661
Validation loss: 3.2495119503012497

Epoch: 5| Step: 8
Training loss: 3.3995001874324156
Validation loss: 3.2480234962398313

Epoch: 5| Step: 9
Training loss: 3.2190730849398377
Validation loss: 3.2481871771759954

Epoch: 5| Step: 10
Training loss: 3.587889030177925
Validation loss: 3.2493443896646554

Epoch: 25| Step: 0
Training loss: 3.424607670721459
Validation loss: 3.246577051362872

Epoch: 5| Step: 1
Training loss: 3.766394065737526
Validation loss: 3.240253564462446

Epoch: 5| Step: 2
Training loss: 4.149426128740694
Validation loss: 3.2299137173596355

Epoch: 5| Step: 3
Training loss: 3.227810006592654
Validation loss: 3.2266933274898646

Epoch: 5| Step: 4
Training loss: 3.0795078947124312
Validation loss: 3.2301190837741953

Epoch: 5| Step: 5
Training loss: 3.243598061239021
Validation loss: 3.2292244600700784

Epoch: 5| Step: 6
Training loss: 3.133499488753829
Validation loss: 3.2374151960801756

Epoch: 5| Step: 7
Training loss: 3.4562823330296375
Validation loss: 3.2199687090197715

Epoch: 5| Step: 8
Training loss: 3.6099311433179815
Validation loss: 3.2226403207593446

Epoch: 5| Step: 9
Training loss: 3.215654236240772
Validation loss: 3.2219006873957463

Epoch: 5| Step: 10
Training loss: 3.897331983114716
Validation loss: 3.2226663497214663

Epoch: 26| Step: 0
Training loss: 3.5128827738326867
Validation loss: 3.2217393492420072

Epoch: 5| Step: 1
Training loss: 3.159111916052442
Validation loss: 3.2240645644775694

Epoch: 5| Step: 2
Training loss: 3.2061602842037344
Validation loss: 3.2203119185717246

Epoch: 5| Step: 3
Training loss: 3.5499246401242837
Validation loss: 3.214008646722084

Epoch: 5| Step: 4
Training loss: 3.3079964595162243
Validation loss: 3.204041647940739

Epoch: 5| Step: 5
Training loss: 4.233286362234738
Validation loss: 3.20137992121319

Epoch: 5| Step: 6
Training loss: 3.392329899255929
Validation loss: 3.197471529685004

Epoch: 5| Step: 7
Training loss: 3.242753092139016
Validation loss: 3.199420756551232

Epoch: 5| Step: 8
Training loss: 3.337741051587677
Validation loss: 3.232345587193241

Epoch: 5| Step: 9
Training loss: 3.2053171983409037
Validation loss: 3.213292738073382

Epoch: 5| Step: 10
Training loss: 3.9069666090730313
Validation loss: 3.191500488766363

Epoch: 27| Step: 0
Training loss: 2.9284779404129635
Validation loss: 3.1888526235806514

Epoch: 5| Step: 1
Training loss: 3.890296278705312
Validation loss: 3.188857477756182

Epoch: 5| Step: 2
Training loss: 2.7998772389884814
Validation loss: 3.195410152832251

Epoch: 5| Step: 3
Training loss: 3.7494839631106602
Validation loss: 3.191229221367655

Epoch: 5| Step: 4
Training loss: 4.1046045266642315
Validation loss: 3.1890759843765686

Epoch: 5| Step: 5
Training loss: 3.515198134892437
Validation loss: 3.1880058869957932

Epoch: 5| Step: 6
Training loss: 3.522927257868575
Validation loss: 3.1843557925808708

Epoch: 5| Step: 7
Training loss: 3.270593103872543
Validation loss: 3.1823063472726516

Epoch: 5| Step: 8
Training loss: 3.112968630153824
Validation loss: 3.1786361213474916

Epoch: 5| Step: 9
Training loss: 3.3758781138469414
Validation loss: 3.1768222604068757

Epoch: 5| Step: 10
Training loss: 3.457388476864591
Validation loss: 3.1797567727206832

Epoch: 28| Step: 0
Training loss: 3.816066761984306
Validation loss: 3.1717954098560144

Epoch: 5| Step: 1
Training loss: 3.688062721894111
Validation loss: 3.1720480753206592

Epoch: 5| Step: 2
Training loss: 3.2402557133207126
Validation loss: 3.168402493714208

Epoch: 5| Step: 3
Training loss: 3.815014619611773
Validation loss: 3.1735473294547347

Epoch: 5| Step: 4
Training loss: 2.8523204057543254
Validation loss: 3.1694996299297666

Epoch: 5| Step: 5
Training loss: 3.251077620040518
Validation loss: 3.166251465132045

Epoch: 5| Step: 6
Training loss: 2.4109460164263976
Validation loss: 3.167418786211166

Epoch: 5| Step: 7
Training loss: 3.5395962815761703
Validation loss: 3.166166182336156

Epoch: 5| Step: 8
Training loss: 3.9750603197427408
Validation loss: 3.161722045761472

Epoch: 5| Step: 9
Training loss: 3.3513439614065654
Validation loss: 3.1592103648940135

Epoch: 5| Step: 10
Training loss: 3.45351991078232
Validation loss: 3.158470702219064

Epoch: 29| Step: 0
Training loss: 2.887292208770724
Validation loss: 3.1588929184969

Epoch: 5| Step: 1
Training loss: 4.418172951320852
Validation loss: 3.151844905837065

Epoch: 5| Step: 2
Training loss: 3.487052675497509
Validation loss: 3.1527587594671798

Epoch: 5| Step: 3
Training loss: 3.5800164566514243
Validation loss: 3.150689923878646

Epoch: 5| Step: 4
Training loss: 2.887417389980181
Validation loss: 3.153345257594914

Epoch: 5| Step: 5
Training loss: 2.762424751050878
Validation loss: 3.1524630302379766

Epoch: 5| Step: 6
Training loss: 3.0447806178147085
Validation loss: 3.1622481556205266

Epoch: 5| Step: 7
Training loss: 3.0038335466453776
Validation loss: 3.1624822371346886

Epoch: 5| Step: 8
Training loss: 4.089409077307197
Validation loss: 3.147496904458326

Epoch: 5| Step: 9
Training loss: 3.330522846495768
Validation loss: 3.142065943819491

Epoch: 5| Step: 10
Training loss: 3.7054909660611166
Validation loss: 3.1420496402787643

Epoch: 30| Step: 0
Training loss: 3.7273984727138645
Validation loss: 3.143016115752448

Epoch: 5| Step: 1
Training loss: 2.9218322424386556
Validation loss: 3.1385681162555894

Epoch: 5| Step: 2
Training loss: 3.5329375159285052
Validation loss: 3.1402636186280826

Epoch: 5| Step: 3
Training loss: 3.6163123371805077
Validation loss: 3.1343973977984785

Epoch: 5| Step: 4
Training loss: 3.462131957176648
Validation loss: 3.131111230334384

Epoch: 5| Step: 5
Training loss: 4.143602675268608
Validation loss: 3.1309540581215627

Epoch: 5| Step: 6
Training loss: 3.168168330931947
Validation loss: 3.1289749255751342

Epoch: 5| Step: 7
Training loss: 3.284302372587664
Validation loss: 3.124580033498202

Epoch: 5| Step: 8
Training loss: 3.317280612524579
Validation loss: 3.1222863817235957

Epoch: 5| Step: 9
Training loss: 3.12404633275449
Validation loss: 3.1206676978789405

Epoch: 5| Step: 10
Training loss: 2.8223932679558823
Validation loss: 3.124420262367105

Epoch: 31| Step: 0
Training loss: 3.6738126796010384
Validation loss: 3.1245749161897747

Epoch: 5| Step: 1
Training loss: 3.2220396249561545
Validation loss: 3.1217341628661406

Epoch: 5| Step: 2
Training loss: 3.498223671420346
Validation loss: 3.118411566638968

Epoch: 5| Step: 3
Training loss: 2.9470491424595027
Validation loss: 3.1118992550870477

Epoch: 5| Step: 4
Training loss: 3.4872973037936394
Validation loss: 3.11164303364427

Epoch: 5| Step: 5
Training loss: 3.4600680186912114
Validation loss: 3.12299798476229

Epoch: 5| Step: 6
Training loss: 3.5476527768680697
Validation loss: 3.1205528248765346

Epoch: 5| Step: 7
Training loss: 3.599865693659992
Validation loss: 3.122071907143408

Epoch: 5| Step: 8
Training loss: 2.516712498615942
Validation loss: 3.106423705336248

Epoch: 5| Step: 9
Training loss: 3.2577232147349844
Validation loss: 3.0999986925760794

Epoch: 5| Step: 10
Training loss: 3.8848594013631144
Validation loss: 3.0998785273979497

Epoch: 32| Step: 0
Training loss: 3.0845123476871783
Validation loss: 3.098303433621594

Epoch: 5| Step: 1
Training loss: 3.293156121874879
Validation loss: 3.0998554892040557

Epoch: 5| Step: 2
Training loss: 3.4424538722718894
Validation loss: 3.10233715679528

Epoch: 5| Step: 3
Training loss: 2.845798132154171
Validation loss: 3.094812915985695

Epoch: 5| Step: 4
Training loss: 3.671890323688105
Validation loss: 3.095979358194525

Epoch: 5| Step: 5
Training loss: 2.879137627712347
Validation loss: 3.096877597815902

Epoch: 5| Step: 6
Training loss: 4.0354171624262944
Validation loss: 3.0947705033088972

Epoch: 5| Step: 7
Training loss: 2.9090116771832117
Validation loss: 3.097498674668603

Epoch: 5| Step: 8
Training loss: 3.1938571740250516
Validation loss: 3.098599336256121

Epoch: 5| Step: 9
Training loss: 3.9221045438303115
Validation loss: 3.106548589398718

Epoch: 5| Step: 10
Training loss: 3.6094265228161104
Validation loss: 3.084708224603938

Epoch: 33| Step: 0
Training loss: 3.657409744870011
Validation loss: 3.086528561448941

Epoch: 5| Step: 1
Training loss: 3.136993130171419
Validation loss: 3.088481736000742

Epoch: 5| Step: 2
Training loss: 2.8154801580197004
Validation loss: 3.0889099634160377

Epoch: 5| Step: 3
Training loss: 3.7107414113488715
Validation loss: 3.0862790736067516

Epoch: 5| Step: 4
Training loss: 3.1729784018776015
Validation loss: 3.0849738879692654

Epoch: 5| Step: 5
Training loss: 3.510905306320051
Validation loss: 3.0879915295958713

Epoch: 5| Step: 6
Training loss: 3.6780473491863104
Validation loss: 3.089571400047507

Epoch: 5| Step: 7
Training loss: 2.392350017027899
Validation loss: 3.0862208688919672

Epoch: 5| Step: 8
Training loss: 3.0903059159234867
Validation loss: 3.0816219877482003

Epoch: 5| Step: 9
Training loss: 4.036055192401769
Validation loss: 3.0818087880954863

Epoch: 5| Step: 10
Training loss: 3.523126491176147
Validation loss: 3.080913263000401

Epoch: 34| Step: 0
Training loss: 2.8634301286115624
Validation loss: 3.0755028277622705

Epoch: 5| Step: 1
Training loss: 4.011079702022457
Validation loss: 3.0758898665257024

Epoch: 5| Step: 2
Training loss: 3.578932225487623
Validation loss: 3.0770268459132555

Epoch: 5| Step: 3
Training loss: 2.903370569065533
Validation loss: 3.074442424857139

Epoch: 5| Step: 4
Training loss: 3.93234387630472
Validation loss: 3.0747614364064155

Epoch: 5| Step: 5
Training loss: 3.655463631339585
Validation loss: 3.065413232277185

Epoch: 5| Step: 6
Training loss: 2.743992051416123
Validation loss: 3.0684393789181783

Epoch: 5| Step: 7
Training loss: 3.4305769129889243
Validation loss: 3.06770089014845

Epoch: 5| Step: 8
Training loss: 3.363825347521469
Validation loss: 3.0687267336585675

Epoch: 5| Step: 9
Training loss: 2.625081833063408
Validation loss: 3.0645667396299663

Epoch: 5| Step: 10
Training loss: 3.485938298846418
Validation loss: 3.061877663124349

Epoch: 35| Step: 0
Training loss: 2.873637996314481
Validation loss: 3.0623933590639343

Epoch: 5| Step: 1
Training loss: 3.1037514598780014
Validation loss: 3.0639709696937056

Epoch: 5| Step: 2
Training loss: 3.179900740987709
Validation loss: 3.0772896018178684

Epoch: 5| Step: 3
Training loss: 3.418390319984063
Validation loss: 3.0922038620227057

Epoch: 5| Step: 4
Training loss: 3.5951130811284746
Validation loss: 3.063291889711815

Epoch: 5| Step: 5
Training loss: 3.3197588290667297
Validation loss: 3.050588574734677

Epoch: 5| Step: 6
Training loss: 3.8814611405148898
Validation loss: 3.053270879949433

Epoch: 5| Step: 7
Training loss: 3.4756387576328427
Validation loss: 3.052755312448623

Epoch: 5| Step: 8
Training loss: 3.4105965416384896
Validation loss: 3.054809064344761

Epoch: 5| Step: 9
Training loss: 3.363793594378385
Validation loss: 3.053608099198035

Epoch: 5| Step: 10
Training loss: 2.989080583963363
Validation loss: 3.0527928394343182

Epoch: 36| Step: 0
Training loss: 3.852836599331072
Validation loss: 3.0541561879351216

Epoch: 5| Step: 1
Training loss: 3.675655674993685
Validation loss: 3.0511524500392313

Epoch: 5| Step: 2
Training loss: 3.0686257269221855
Validation loss: 3.051624664434087

Epoch: 5| Step: 3
Training loss: 3.02116462381713
Validation loss: 3.0457933700505495

Epoch: 5| Step: 4
Training loss: 3.1227569159190747
Validation loss: 3.0474293598107245

Epoch: 5| Step: 5
Training loss: 3.210737904380393
Validation loss: 3.0543006761361626

Epoch: 5| Step: 6
Training loss: 3.882634916792297
Validation loss: 3.041728830032412

Epoch: 5| Step: 7
Training loss: 3.914594968108867
Validation loss: 3.038484837277495

Epoch: 5| Step: 8
Training loss: 3.0220415702601398
Validation loss: 3.0412879836793993

Epoch: 5| Step: 9
Training loss: 2.882301512713906
Validation loss: 3.0409335760120046

Epoch: 5| Step: 10
Training loss: 2.650623061150847
Validation loss: 3.0415195480641244

Epoch: 37| Step: 0
Training loss: 3.1572283748641565
Validation loss: 3.0435524821761315

Epoch: 5| Step: 1
Training loss: 3.3248888499102964
Validation loss: 3.0503029932865764

Epoch: 5| Step: 2
Training loss: 2.4130250744803297
Validation loss: 3.049715111047288

Epoch: 5| Step: 3
Training loss: 4.1413976560200165
Validation loss: 3.0417840976834127

Epoch: 5| Step: 4
Training loss: 3.2840702107831112
Validation loss: 3.0352464199720965

Epoch: 5| Step: 5
Training loss: 3.6151152703992615
Validation loss: 3.0226873380988395

Epoch: 5| Step: 6
Training loss: 2.8684282242903123
Validation loss: 3.0275726788590616

Epoch: 5| Step: 7
Training loss: 3.843002618840894
Validation loss: 3.0295867230114837

Epoch: 5| Step: 8
Training loss: 2.841099772209595
Validation loss: 3.0273115517197065

Epoch: 5| Step: 9
Training loss: 3.7858952764344154
Validation loss: 3.026280104197561

Epoch: 5| Step: 10
Training loss: 2.777821688834785
Validation loss: 3.0223196874375224

Epoch: 38| Step: 0
Training loss: 3.2775877360480643
Validation loss: 3.0188829031347466

Epoch: 5| Step: 1
Training loss: 3.3843564921513214
Validation loss: 3.0161806955081003

Epoch: 5| Step: 2
Training loss: 2.9434620839951364
Validation loss: 3.0102457369204583

Epoch: 5| Step: 3
Training loss: 3.1794766442871354
Validation loss: 3.0127311098782084

Epoch: 5| Step: 4
Training loss: 3.192264362143665
Validation loss: 3.0053766097965844

Epoch: 5| Step: 5
Training loss: 3.4979571784110037
Validation loss: 3.0114958918890813

Epoch: 5| Step: 6
Training loss: 3.0475452175024684
Validation loss: 3.0124064272038598

Epoch: 5| Step: 7
Training loss: 3.6341938632949593
Validation loss: 3.0188191562833615

Epoch: 5| Step: 8
Training loss: 3.559354095799499
Validation loss: 3.028270055480548

Epoch: 5| Step: 9
Training loss: 3.3207362723594844
Validation loss: 3.0358152983340942

Epoch: 5| Step: 10
Training loss: 3.1982153505553423
Validation loss: 3.0137494193897605

Epoch: 39| Step: 0
Training loss: 3.3384422886539245
Validation loss: 2.9994177629298955

Epoch: 5| Step: 1
Training loss: 3.306626781202562
Validation loss: 3.003649559731294

Epoch: 5| Step: 2
Training loss: 2.404629149048124
Validation loss: 3.001818351963577

Epoch: 5| Step: 3
Training loss: 3.153679735971171
Validation loss: 3.0038903026594084

Epoch: 5| Step: 4
Training loss: 2.5788489972415465
Validation loss: 3.003855630599167

Epoch: 5| Step: 5
Training loss: 3.698503016160305
Validation loss: 3.002879388005939

Epoch: 5| Step: 6
Training loss: 3.794104801787668
Validation loss: 2.9968310285922817

Epoch: 5| Step: 7
Training loss: 3.1219067332322687
Validation loss: 2.997820168206383

Epoch: 5| Step: 8
Training loss: 3.6346966195256534
Validation loss: 2.9956906706074657

Epoch: 5| Step: 9
Training loss: 3.3427460491318834
Validation loss: 2.9935157201410147

Epoch: 5| Step: 10
Training loss: 3.59617188157675
Validation loss: 2.993933003486778

Epoch: 40| Step: 0
Training loss: 2.88608999463865
Validation loss: 2.992766303846274

Epoch: 5| Step: 1
Training loss: 3.083282796772071
Validation loss: 3.0005748276686197

Epoch: 5| Step: 2
Training loss: 3.3808190372557503
Validation loss: 2.9891548519976574

Epoch: 5| Step: 3
Training loss: 3.863692243447347
Validation loss: 2.9880945569750934

Epoch: 5| Step: 4
Training loss: 3.181187381390411
Validation loss: 2.9842712009759538

Epoch: 5| Step: 5
Training loss: 3.0511146197198915
Validation loss: 2.980654997786752

Epoch: 5| Step: 6
Training loss: 3.7165233453278868
Validation loss: 2.9772403242301153

Epoch: 5| Step: 7
Training loss: 3.3927127721373105
Validation loss: 2.979327212935069

Epoch: 5| Step: 8
Training loss: 3.351516403201353
Validation loss: 2.9723873530211815

Epoch: 5| Step: 9
Training loss: 3.4902912086167346
Validation loss: 2.976535808949669

Epoch: 5| Step: 10
Training loss: 2.273971861867348
Validation loss: 2.973143773749461

Epoch: 41| Step: 0
Training loss: 2.821999507620138
Validation loss: 2.9738594606099347

Epoch: 5| Step: 1
Training loss: 3.542024362489995
Validation loss: 2.9802550517705697

Epoch: 5| Step: 2
Training loss: 3.9584787174764333
Validation loss: 2.986090825450688

Epoch: 5| Step: 3
Training loss: 3.34316640734458
Validation loss: 3.0005582474629984

Epoch: 5| Step: 4
Training loss: 3.207768196435489
Validation loss: 3.003805735789958

Epoch: 5| Step: 5
Training loss: 3.8191833699711717
Validation loss: 2.9903444036949924

Epoch: 5| Step: 6
Training loss: 2.3415910059243648
Validation loss: 2.967189150095274

Epoch: 5| Step: 7
Training loss: 3.683107248907912
Validation loss: 2.965875576223382

Epoch: 5| Step: 8
Training loss: 2.995704277417385
Validation loss: 2.964283933680116

Epoch: 5| Step: 9
Training loss: 2.8867280002389006
Validation loss: 2.9671146744020724

Epoch: 5| Step: 10
Training loss: 2.9759488812434958
Validation loss: 2.973815904788492

Epoch: 42| Step: 0
Training loss: 2.958526515473747
Validation loss: 2.977278760849111

Epoch: 5| Step: 1
Training loss: 2.8082217419769075
Validation loss: 2.9827857041888133

Epoch: 5| Step: 2
Training loss: 3.265092286095257
Validation loss: 2.989450575605058

Epoch: 5| Step: 3
Training loss: 3.2394952465646014
Validation loss: 2.9840376743352293

Epoch: 5| Step: 4
Training loss: 3.9000368067642914
Validation loss: 2.9836166819470797

Epoch: 5| Step: 5
Training loss: 3.4002759148335406
Validation loss: 2.9733378531327235

Epoch: 5| Step: 6
Training loss: 2.934774879777102
Validation loss: 2.9683459349661048

Epoch: 5| Step: 7
Training loss: 3.2920715630262998
Validation loss: 2.9649407309053277

Epoch: 5| Step: 8
Training loss: 3.024379061187521
Validation loss: 2.9632531753804177

Epoch: 5| Step: 9
Training loss: 3.590887903693131
Validation loss: 2.959516844587979

Epoch: 5| Step: 10
Training loss: 3.4005534282627052
Validation loss: 2.9557691539498747

Epoch: 43| Step: 0
Training loss: 3.356659115199131
Validation loss: 2.9543887774988065

Epoch: 5| Step: 1
Training loss: 2.631179801385074
Validation loss: 2.953954915673279

Epoch: 5| Step: 2
Training loss: 3.4281879874800394
Validation loss: 2.954084563511919

Epoch: 5| Step: 3
Training loss: 3.1122288474737605
Validation loss: 2.9694501032974046

Epoch: 5| Step: 4
Training loss: 3.892537700100553
Validation loss: 2.979343987014011

Epoch: 5| Step: 5
Training loss: 2.895461865940261
Validation loss: 2.9704061132106068

Epoch: 5| Step: 6
Training loss: 2.7878033870620342
Validation loss: 2.961569339617081

Epoch: 5| Step: 7
Training loss: 3.737714224197074
Validation loss: 2.9558518774246156

Epoch: 5| Step: 8
Training loss: 2.7095928980094253
Validation loss: 2.9468380899901327

Epoch: 5| Step: 9
Training loss: 3.907374105835542
Validation loss: 2.9417092861557954

Epoch: 5| Step: 10
Training loss: 2.9188484387676064
Validation loss: 2.9447534689475408

Epoch: 44| Step: 0
Training loss: 3.449443529004358
Validation loss: 2.940788920365206

Epoch: 5| Step: 1
Training loss: 3.3863016859512634
Validation loss: 2.9384285169086932

Epoch: 5| Step: 2
Training loss: 2.606663740145056
Validation loss: 2.9404637979209665

Epoch: 5| Step: 3
Training loss: 3.780735075387604
Validation loss: 2.9389373702940986

Epoch: 5| Step: 4
Training loss: 2.9555076392869957
Validation loss: 2.93449941463528

Epoch: 5| Step: 5
Training loss: 3.0817327898797804
Validation loss: 2.933962209914305

Epoch: 5| Step: 6
Training loss: 3.031510174784069
Validation loss: 2.9307078301359413

Epoch: 5| Step: 7
Training loss: 3.3815664767305478
Validation loss: 2.929040816494099

Epoch: 5| Step: 8
Training loss: 3.2547484701217337
Validation loss: 2.930592834816668

Epoch: 5| Step: 9
Training loss: 3.058954950784692
Validation loss: 2.929598680469262

Epoch: 5| Step: 10
Training loss: 3.4941160607367405
Validation loss: 2.9355369437088763

Epoch: 45| Step: 0
Training loss: 2.6316410707368907
Validation loss: 2.9357678829463083

Epoch: 5| Step: 1
Training loss: 3.795723069254294
Validation loss: 2.9418664185073418

Epoch: 5| Step: 2
Training loss: 3.0887325714619993
Validation loss: 2.9392508859139106

Epoch: 5| Step: 3
Training loss: 3.0692279637685926
Validation loss: 2.932116485091519

Epoch: 5| Step: 4
Training loss: 2.5794154781033627
Validation loss: 2.932335393689583

Epoch: 5| Step: 5
Training loss: 3.5499983827829036
Validation loss: 2.941846800733383

Epoch: 5| Step: 6
Training loss: 3.313502609820624
Validation loss: 2.9331010002360403

Epoch: 5| Step: 7
Training loss: 3.487653754888701
Validation loss: 2.92560956984032

Epoch: 5| Step: 8
Training loss: 3.3669408013057
Validation loss: 2.925076696601431

Epoch: 5| Step: 9
Training loss: 3.3225317147078157
Validation loss: 2.9236603812464583

Epoch: 5| Step: 10
Training loss: 3.0447162512254033
Validation loss: 2.925641156780721

Epoch: 46| Step: 0
Training loss: 3.088630833660077
Validation loss: 2.9196440057432347

Epoch: 5| Step: 1
Training loss: 3.043319740668948
Validation loss: 2.9252761524651856

Epoch: 5| Step: 2
Training loss: 3.803559999813356
Validation loss: 2.920871619587329

Epoch: 5| Step: 3
Training loss: 3.1656240118689847
Validation loss: 2.920092634113103

Epoch: 5| Step: 4
Training loss: 2.5159655986065435
Validation loss: 2.920375122929167

Epoch: 5| Step: 5
Training loss: 3.834806380376405
Validation loss: 2.9287255899099396

Epoch: 5| Step: 6
Training loss: 2.937480033644328
Validation loss: 2.9192109333399623

Epoch: 5| Step: 7
Training loss: 3.5826081421868996
Validation loss: 2.918061212786094

Epoch: 5| Step: 8
Training loss: 2.8223983363855956
Validation loss: 2.9161226992942635

Epoch: 5| Step: 9
Training loss: 3.430303357558618
Validation loss: 2.9113095273529295

Epoch: 5| Step: 10
Training loss: 2.7884723455690166
Validation loss: 2.913376393503882

Epoch: 47| Step: 0
Training loss: 3.9499554498791847
Validation loss: 2.908760807778007

Epoch: 5| Step: 1
Training loss: 3.076834316073801
Validation loss: 2.910236596650559

Epoch: 5| Step: 2
Training loss: 3.267375422162722
Validation loss: 2.9124219433716863

Epoch: 5| Step: 3
Training loss: 2.9148301655154505
Validation loss: 2.907765975225269

Epoch: 5| Step: 4
Training loss: 3.651078960901195
Validation loss: 2.9135131124513385

Epoch: 5| Step: 5
Training loss: 3.2883737889575935
Validation loss: 2.911855474443114

Epoch: 5| Step: 6
Training loss: 3.3127082903171297
Validation loss: 2.9103509551931004

Epoch: 5| Step: 7
Training loss: 2.4572780952116573
Validation loss: 2.910005478643237

Epoch: 5| Step: 8
Training loss: 3.125922410252211
Validation loss: 2.9114316788332593

Epoch: 5| Step: 9
Training loss: 3.095117902343421
Validation loss: 2.9125688734400415

Epoch: 5| Step: 10
Training loss: 2.882892555841336
Validation loss: 2.9073698277126123

Epoch: 48| Step: 0
Training loss: 3.3068087648295177
Validation loss: 2.914592586168021

Epoch: 5| Step: 1
Training loss: 2.9908442657035645
Validation loss: 2.9157760444001513

Epoch: 5| Step: 2
Training loss: 3.024683338331498
Validation loss: 2.924642530890906

Epoch: 5| Step: 3
Training loss: 2.553151733557301
Validation loss: 2.9272048400059063

Epoch: 5| Step: 4
Training loss: 3.25312610813089
Validation loss: 2.9276093134579138

Epoch: 5| Step: 5
Training loss: 2.8761251155394505
Validation loss: 2.9111700383948804

Epoch: 5| Step: 6
Training loss: 3.3171983902869693
Validation loss: 2.9082115064847143

Epoch: 5| Step: 7
Training loss: 3.483417191172885
Validation loss: 2.9052589641847177

Epoch: 5| Step: 8
Training loss: 3.6890766200078544
Validation loss: 2.904407730180979

Epoch: 5| Step: 9
Training loss: 3.3663181678507677
Validation loss: 2.8994651453968032

Epoch: 5| Step: 10
Training loss: 3.2535861843636527
Validation loss: 2.896624735774613

Epoch: 49| Step: 0
Training loss: 3.3536005114929885
Validation loss: 2.897979481670354

Epoch: 5| Step: 1
Training loss: 3.168157945808934
Validation loss: 2.897137180543063

Epoch: 5| Step: 2
Training loss: 3.0262373545278867
Validation loss: 2.8952728836344424

Epoch: 5| Step: 3
Training loss: 2.9511730060284895
Validation loss: 2.8975437259939505

Epoch: 5| Step: 4
Training loss: 3.667334293504275
Validation loss: 2.895551098673597

Epoch: 5| Step: 5
Training loss: 2.6914014663985975
Validation loss: 2.8965438894079205

Epoch: 5| Step: 6
Training loss: 3.623038978259588
Validation loss: 2.89757221346583

Epoch: 5| Step: 7
Training loss: 3.2503984647183426
Validation loss: 2.89976871877975

Epoch: 5| Step: 8
Training loss: 3.0031827891304252
Validation loss: 2.8986049778732044

Epoch: 5| Step: 9
Training loss: 3.301180518566367
Validation loss: 2.8977071478023855

Epoch: 5| Step: 10
Training loss: 3.048989994852147
Validation loss: 2.902399633211842

Epoch: 50| Step: 0
Training loss: 3.2769209142273463
Validation loss: 2.9028649951363708

Epoch: 5| Step: 1
Training loss: 2.6341422596997184
Validation loss: 2.9028223125923938

Epoch: 5| Step: 2
Training loss: 3.4564340883865903
Validation loss: 2.9045929716197163

Epoch: 5| Step: 3
Training loss: 3.537310235962395
Validation loss: 2.899587672952263

Epoch: 5| Step: 4
Training loss: 3.129214687122868
Validation loss: 2.904541697347755

Epoch: 5| Step: 5
Training loss: 3.4301034592575976
Validation loss: 2.8992365898752674

Epoch: 5| Step: 6
Training loss: 2.3115482949458235
Validation loss: 2.903965514699524

Epoch: 5| Step: 7
Training loss: 3.583401849372592
Validation loss: 2.9082382331045276

Epoch: 5| Step: 8
Training loss: 3.8195961122551156
Validation loss: 2.9045794472611246

Epoch: 5| Step: 9
Training loss: 2.972783450639648
Validation loss: 2.9042459053357748

Epoch: 5| Step: 10
Training loss: 2.6115316284589873
Validation loss: 2.89319503928125

Epoch: 51| Step: 0
Training loss: 3.0612952529098334
Validation loss: 2.889902230153283

Epoch: 5| Step: 1
Training loss: 3.267738935728372
Validation loss: 2.8906430071774563

Epoch: 5| Step: 2
Training loss: 3.161260423744909
Validation loss: 2.88842664035139

Epoch: 5| Step: 3
Training loss: 3.1160305237554375
Validation loss: 2.89234652308712

Epoch: 5| Step: 4
Training loss: 3.4930226396274198
Validation loss: 2.8889470909646136

Epoch: 5| Step: 5
Training loss: 3.401072916273852
Validation loss: 2.891983116712093

Epoch: 5| Step: 6
Training loss: 3.2819293090999384
Validation loss: 2.8927431354120956

Epoch: 5| Step: 7
Training loss: 3.1792414771827664
Validation loss: 2.893518434615231

Epoch: 5| Step: 8
Training loss: 3.0927244085551737
Validation loss: 2.888241856802448

Epoch: 5| Step: 9
Training loss: 2.765609310127193
Validation loss: 2.8905938259617736

Epoch: 5| Step: 10
Training loss: 3.331079022741657
Validation loss: 2.8909179069051807

Epoch: 52| Step: 0
Training loss: 3.137714612695466
Validation loss: 2.8897187137859617

Epoch: 5| Step: 1
Training loss: 2.972269000421102
Validation loss: 2.8904677002646713

Epoch: 5| Step: 2
Training loss: 3.112970774639911
Validation loss: 2.889621026144564

Epoch: 5| Step: 3
Training loss: 3.4271902668666026
Validation loss: 2.8962746761399445

Epoch: 5| Step: 4
Training loss: 3.2564502676445235
Validation loss: 2.896962514402486

Epoch: 5| Step: 5
Training loss: 3.322439288983245
Validation loss: 2.9025240188934225

Epoch: 5| Step: 6
Training loss: 3.0617952119702494
Validation loss: 2.8959731124839236

Epoch: 5| Step: 7
Training loss: 2.9079074850254925
Validation loss: 2.89721079074894

Epoch: 5| Step: 8
Training loss: 2.9606063778408163
Validation loss: 2.903064195004178

Epoch: 5| Step: 9
Training loss: 3.9003752210042593
Validation loss: 2.8883760944777457

Epoch: 5| Step: 10
Training loss: 2.9237995847074822
Validation loss: 2.8930088668687417

Epoch: 53| Step: 0
Training loss: 3.2995471701454937
Validation loss: 2.885447668597069

Epoch: 5| Step: 1
Training loss: 3.198892318224956
Validation loss: 2.8821854274941487

Epoch: 5| Step: 2
Training loss: 3.1070230301174426
Validation loss: 2.8846910386935942

Epoch: 5| Step: 3
Training loss: 3.484282214379093
Validation loss: 2.881993542904607

Epoch: 5| Step: 4
Training loss: 2.9715785956761707
Validation loss: 2.8892123587771494

Epoch: 5| Step: 5
Training loss: 3.766135280114101
Validation loss: 2.895834432268115

Epoch: 5| Step: 6
Training loss: 3.1226882012903605
Validation loss: 2.8946967849603524

Epoch: 5| Step: 7
Training loss: 3.657281322604054
Validation loss: 2.8819752664141407

Epoch: 5| Step: 8
Training loss: 2.582012967089677
Validation loss: 2.8788025326234914

Epoch: 5| Step: 9
Training loss: 2.6733999083577684
Validation loss: 2.8828147445533467

Epoch: 5| Step: 10
Training loss: 3.0131212029297663
Validation loss: 2.8776148309465026

Epoch: 54| Step: 0
Training loss: 2.932425478405439
Validation loss: 2.8830737626317355

Epoch: 5| Step: 1
Training loss: 3.447786511195585
Validation loss: 2.8806828354960237

Epoch: 5| Step: 2
Training loss: 3.578126332645085
Validation loss: 2.879396033698656

Epoch: 5| Step: 3
Training loss: 3.5599976166706466
Validation loss: 2.8813180790273254

Epoch: 5| Step: 4
Training loss: 2.3288830028808185
Validation loss: 2.881655216014821

Epoch: 5| Step: 5
Training loss: 3.3453284130047583
Validation loss: 2.8800871535271906

Epoch: 5| Step: 6
Training loss: 3.8395731492027356
Validation loss: 2.8745737138744087

Epoch: 5| Step: 7
Training loss: 2.911274821731278
Validation loss: 2.876597885578415

Epoch: 5| Step: 8
Training loss: 2.6228925328637915
Validation loss: 2.873629992169267

Epoch: 5| Step: 9
Training loss: 3.132222184194031
Validation loss: 2.8732276552283804

Epoch: 5| Step: 10
Training loss: 2.9500293148329937
Validation loss: 2.8755803015228256

Epoch: 55| Step: 0
Training loss: 3.1852459885299735
Validation loss: 2.869241448265379

Epoch: 5| Step: 1
Training loss: 3.334229650788436
Validation loss: 2.8710972073620464

Epoch: 5| Step: 2
Training loss: 2.577454450854181
Validation loss: 2.871749867026679

Epoch: 5| Step: 3
Training loss: 3.0781448286163373
Validation loss: 2.867715737789896

Epoch: 5| Step: 4
Training loss: 3.58463132252744
Validation loss: 2.868015749633243

Epoch: 5| Step: 5
Training loss: 2.944984802310505
Validation loss: 2.868359689390933

Epoch: 5| Step: 6
Training loss: 2.816325235458196
Validation loss: 2.871137242632698

Epoch: 5| Step: 7
Training loss: 3.2026795612534067
Validation loss: 2.8674857700950116

Epoch: 5| Step: 8
Training loss: 2.9134455378011443
Validation loss: 2.8669235851499626

Epoch: 5| Step: 9
Training loss: 3.7540424175355622
Validation loss: 2.8706847411206735

Epoch: 5| Step: 10
Training loss: 3.444938379852244
Validation loss: 2.8670457445762305

Epoch: 56| Step: 0
Training loss: 2.323442499377292
Validation loss: 2.869156594876541

Epoch: 5| Step: 1
Training loss: 3.791335849513165
Validation loss: 2.8663211155173656

Epoch: 5| Step: 2
Training loss: 3.084580366878757
Validation loss: 2.8671226381244264

Epoch: 5| Step: 3
Training loss: 3.1586343049817307
Validation loss: 2.8654363608693627

Epoch: 5| Step: 4
Training loss: 2.8103213030841516
Validation loss: 2.865581591036671

Epoch: 5| Step: 5
Training loss: 3.4585672016042563
Validation loss: 2.86714307923806

Epoch: 5| Step: 6
Training loss: 3.5671678713819497
Validation loss: 2.869665006661595

Epoch: 5| Step: 7
Training loss: 3.343904010398881
Validation loss: 2.874753261070592

Epoch: 5| Step: 8
Training loss: 3.0149642932099634
Validation loss: 2.8813302329292068

Epoch: 5| Step: 9
Training loss: 2.6030685143908125
Validation loss: 2.8868517415358035

Epoch: 5| Step: 10
Training loss: 3.521452960203747
Validation loss: 2.8856248041230566

Epoch: 57| Step: 0
Training loss: 3.159338620181093
Validation loss: 2.8858949939955734

Epoch: 5| Step: 1
Training loss: 2.9985416364452244
Validation loss: 2.8909784838659616

Epoch: 5| Step: 2
Training loss: 3.542619075994841
Validation loss: 2.901998926240614

Epoch: 5| Step: 3
Training loss: 3.382266099600364
Validation loss: 2.9006400794807568

Epoch: 5| Step: 4
Training loss: 3.0991679828583223
Validation loss: 2.88881463162337

Epoch: 5| Step: 5
Training loss: 3.637086515751183
Validation loss: 2.8885163256136828

Epoch: 5| Step: 6
Training loss: 2.674845421861471
Validation loss: 2.87411694476668

Epoch: 5| Step: 7
Training loss: 3.3751672773939108
Validation loss: 2.8693245148961064

Epoch: 5| Step: 8
Training loss: 3.110127113663841
Validation loss: 2.861965795954869

Epoch: 5| Step: 9
Training loss: 2.967582071353668
Validation loss: 2.863809701633815

Epoch: 5| Step: 10
Training loss: 2.8441233966202373
Validation loss: 2.8610967801083564

Epoch: 58| Step: 0
Training loss: 2.369472294900033
Validation loss: 2.85944710334697

Epoch: 5| Step: 1
Training loss: 3.188522174970455
Validation loss: 2.8675465738543644

Epoch: 5| Step: 2
Training loss: 3.510769623501975
Validation loss: 2.8704504331879357

Epoch: 5| Step: 3
Training loss: 2.9848990254919534
Validation loss: 2.8623625122646312

Epoch: 5| Step: 4
Training loss: 3.2530147068407733
Validation loss: 2.8643617468604763

Epoch: 5| Step: 5
Training loss: 3.4693899853024863
Validation loss: 2.858479604892214

Epoch: 5| Step: 6
Training loss: 3.213223648204231
Validation loss: 2.858566172473436

Epoch: 5| Step: 7
Training loss: 2.9916341484094753
Validation loss: 2.8593189420718375

Epoch: 5| Step: 8
Training loss: 2.8354343777191464
Validation loss: 2.860385708301951

Epoch: 5| Step: 9
Training loss: 3.377144167754371
Validation loss: 2.8611072583133943

Epoch: 5| Step: 10
Training loss: 3.5686418560364492
Validation loss: 2.8583585422016156

Epoch: 59| Step: 0
Training loss: 3.7041603926500724
Validation loss: 2.859178751197694

Epoch: 5| Step: 1
Training loss: 3.697496216561198
Validation loss: 2.8627637147455114

Epoch: 5| Step: 2
Training loss: 3.153314112577135
Validation loss: 2.8592549570106875

Epoch: 5| Step: 3
Training loss: 3.08672405793765
Validation loss: 2.8568562298851217

Epoch: 5| Step: 4
Training loss: 3.1340503102289055
Validation loss: 2.8607115651912665

Epoch: 5| Step: 5
Training loss: 2.6297828153856
Validation loss: 2.8580297233566827

Epoch: 5| Step: 6
Training loss: 2.6852596614881548
Validation loss: 2.857227589812812

Epoch: 5| Step: 7
Training loss: 2.7812199966012447
Validation loss: 2.859901549641721

Epoch: 5| Step: 8
Training loss: 3.465317823798285
Validation loss: 2.857788079517831

Epoch: 5| Step: 9
Training loss: 3.1459014750462613
Validation loss: 2.85874457458641

Epoch: 5| Step: 10
Training loss: 3.1476892382004933
Validation loss: 2.8631237642395706

Epoch: 60| Step: 0
Training loss: 3.6142467301741736
Validation loss: 2.865153111744998

Epoch: 5| Step: 1
Training loss: 2.691232617539588
Validation loss: 2.85919353488252

Epoch: 5| Step: 2
Training loss: 2.7553642147126385
Validation loss: 2.862865696576859

Epoch: 5| Step: 3
Training loss: 2.839661058428948
Validation loss: 2.861680863120938

Epoch: 5| Step: 4
Training loss: 3.6177425741341294
Validation loss: 2.859011464639972

Epoch: 5| Step: 5
Training loss: 2.5372887622121176
Validation loss: 2.8592461083389313

Epoch: 5| Step: 6
Training loss: 3.5977276889198557
Validation loss: 2.8618856966782613

Epoch: 5| Step: 7
Training loss: 2.4388750550445697
Validation loss: 2.85687132530658

Epoch: 5| Step: 8
Training loss: 3.561201561664992
Validation loss: 2.854738254736792

Epoch: 5| Step: 9
Training loss: 3.5967648009546345
Validation loss: 2.8548484085652412

Epoch: 5| Step: 10
Training loss: 3.1266679508664788
Validation loss: 2.85663712282342

Epoch: 61| Step: 0
Training loss: 3.3616586419613226
Validation loss: 2.859836122711403

Epoch: 5| Step: 1
Training loss: 2.5315220062667616
Validation loss: 2.867284085958046

Epoch: 5| Step: 2
Training loss: 3.1510858874199954
Validation loss: 2.8751481090736934

Epoch: 5| Step: 3
Training loss: 2.5995638848386515
Validation loss: 2.8660713905469444

Epoch: 5| Step: 4
Training loss: 3.254339695301797
Validation loss: 2.854916944544737

Epoch: 5| Step: 5
Training loss: 2.9193914129358927
Validation loss: 2.852048510238317

Epoch: 5| Step: 6
Training loss: 3.716266475965595
Validation loss: 2.8539628100605077

Epoch: 5| Step: 7
Training loss: 3.3043218459978254
Validation loss: 2.852731749255638

Epoch: 5| Step: 8
Training loss: 3.408203125
Validation loss: 2.8650800728821624

Epoch: 5| Step: 9
Training loss: 3.398052325289844
Validation loss: 2.859294108176731

Epoch: 5| Step: 10
Training loss: 2.890735356054351
Validation loss: 2.8682327772595544

Epoch: 62| Step: 0
Training loss: 3.1733014887593036
Validation loss: 2.85796063500873

Epoch: 5| Step: 1
Training loss: 3.122315894411491
Validation loss: 2.860204741124521

Epoch: 5| Step: 2
Training loss: 3.0223361431728772
Validation loss: 2.8585934681836442

Epoch: 5| Step: 3
Training loss: 2.5214312346138317
Validation loss: 2.8532295877381793

Epoch: 5| Step: 4
Training loss: 3.240311928085996
Validation loss: 2.854330831653407

Epoch: 5| Step: 5
Training loss: 3.2605639212183197
Validation loss: 2.8603430138861716

Epoch: 5| Step: 6
Training loss: 3.224903040175049
Validation loss: 2.8629372105537643

Epoch: 5| Step: 7
Training loss: 3.1108891619879078
Validation loss: 2.858519354109389

Epoch: 5| Step: 8
Training loss: 3.701584894089208
Validation loss: 2.8584283034508258

Epoch: 5| Step: 9
Training loss: 3.3586626583962365
Validation loss: 2.8562807927460216

Epoch: 5| Step: 10
Training loss: 2.8719975923724697
Validation loss: 2.8524043929653753

Epoch: 63| Step: 0
Training loss: 2.7089932640276384
Validation loss: 2.8528078505041807

Epoch: 5| Step: 1
Training loss: 3.281793022635707
Validation loss: 2.8520487331597892

Epoch: 5| Step: 2
Training loss: 3.2681527461911144
Validation loss: 2.8519167480151553

Epoch: 5| Step: 3
Training loss: 3.581739174552827
Validation loss: 2.852023319999727

Epoch: 5| Step: 4
Training loss: 2.8429356341675294
Validation loss: 2.8503034881647533

Epoch: 5| Step: 5
Training loss: 2.8577457643353545
Validation loss: 2.850753302111414

Epoch: 5| Step: 6
Training loss: 3.294031155075852
Validation loss: 2.8568725322548576

Epoch: 5| Step: 7
Training loss: 2.5435589692839065
Validation loss: 2.8599209236573704

Epoch: 5| Step: 8
Training loss: 3.381664336761329
Validation loss: 2.8581147761291312

Epoch: 5| Step: 9
Training loss: 3.443087112126897
Validation loss: 2.870070069858202

Epoch: 5| Step: 10
Training loss: 3.38623001109631
Validation loss: 2.8650883648749814

Epoch: 64| Step: 0
Training loss: 3.232739610988806
Validation loss: 2.86169335036552

Epoch: 5| Step: 1
Training loss: 3.049192515560184
Validation loss: 2.85205853988957

Epoch: 5| Step: 2
Training loss: 2.944042468272609
Validation loss: 2.8594110456248187

Epoch: 5| Step: 3
Training loss: 3.3095299703391046
Validation loss: 2.852780191200865

Epoch: 5| Step: 4
Training loss: 3.074304523749808
Validation loss: 2.8510818514641056

Epoch: 5| Step: 5
Training loss: 3.4515777850039275
Validation loss: 2.8440441974217494

Epoch: 5| Step: 6
Training loss: 3.1801280623267125
Validation loss: 2.8478664024293363

Epoch: 5| Step: 7
Training loss: 2.9057122830323614
Validation loss: 2.845049747113062

Epoch: 5| Step: 8
Training loss: 3.2325732238925613
Validation loss: 2.842860401285588

Epoch: 5| Step: 9
Training loss: 3.3474007044930296
Validation loss: 2.846056093614569

Epoch: 5| Step: 10
Training loss: 2.9194276729561346
Validation loss: 2.8427357127466912

Epoch: 65| Step: 0
Training loss: 3.473883052774729
Validation loss: 2.842454047263133

Epoch: 5| Step: 1
Training loss: 2.513547335535437
Validation loss: 2.8413082612617826

Epoch: 5| Step: 2
Training loss: 3.6086485821195446
Validation loss: 2.842827190260253

Epoch: 5| Step: 3
Training loss: 3.16269833391406
Validation loss: 2.843545618998707

Epoch: 5| Step: 4
Training loss: 3.043036130812879
Validation loss: 2.844106827374512

Epoch: 5| Step: 5
Training loss: 3.4410249150246375
Validation loss: 2.8417605265649666

Epoch: 5| Step: 6
Training loss: 2.786983965676689
Validation loss: 2.842196475058585

Epoch: 5| Step: 7
Training loss: 2.90636386443191
Validation loss: 2.8407336454388776

Epoch: 5| Step: 8
Training loss: 3.216550353192311
Validation loss: 2.843088579072145

Epoch: 5| Step: 9
Training loss: 3.566787682616358
Validation loss: 2.842200196678265

Epoch: 5| Step: 10
Training loss: 2.691908835115838
Validation loss: 2.8411472593093205

Epoch: 66| Step: 0
Training loss: 3.2913894214648116
Validation loss: 2.8421012464798894

Epoch: 5| Step: 1
Training loss: 2.8680380409409962
Validation loss: 2.8484378306300275

Epoch: 5| Step: 2
Training loss: 3.3028176791774637
Validation loss: 2.854412973325765

Epoch: 5| Step: 3
Training loss: 3.368388304817853
Validation loss: 2.8542962739093936

Epoch: 5| Step: 4
Training loss: 2.9546398334501207
Validation loss: 2.863259852830991

Epoch: 5| Step: 5
Training loss: 2.590590977646675
Validation loss: 2.866027464136211

Epoch: 5| Step: 6
Training loss: 3.676412562641673
Validation loss: 2.858840676384734

Epoch: 5| Step: 7
Training loss: 2.7976173822152575
Validation loss: 2.8536935783507977

Epoch: 5| Step: 8
Training loss: 2.9378668373422028
Validation loss: 2.843753071408854

Epoch: 5| Step: 9
Training loss: 3.1406066286678938
Validation loss: 2.841247586247651

Epoch: 5| Step: 10
Training loss: 3.63893854594302
Validation loss: 2.8370238186061933

Epoch: 67| Step: 0
Training loss: 3.156479175669941
Validation loss: 2.8379455000565073

Epoch: 5| Step: 1
Training loss: 3.130063037176603
Validation loss: 2.8390761475178565

Epoch: 5| Step: 2
Training loss: 3.012681542462453
Validation loss: 2.841476767799883

Epoch: 5| Step: 3
Training loss: 3.3761922355266543
Validation loss: 2.842189532411852

Epoch: 5| Step: 4
Training loss: 2.8231341757972546
Validation loss: 2.8431743051271874

Epoch: 5| Step: 5
Training loss: 3.0808431174883273
Validation loss: 2.843393461442816

Epoch: 5| Step: 6
Training loss: 3.3172922557186717
Validation loss: 2.8386514567765415

Epoch: 5| Step: 7
Training loss: 3.4529153751594746
Validation loss: 2.8416235608139497

Epoch: 5| Step: 8
Training loss: 3.5487835156456033
Validation loss: 2.8396744757827546

Epoch: 5| Step: 9
Training loss: 2.282498266380295
Validation loss: 2.838990967749376

Epoch: 5| Step: 10
Training loss: 3.3562563592434955
Validation loss: 2.8399532556709315

Epoch: 68| Step: 0
Training loss: 3.0972119622471617
Validation loss: 2.8398233886256015

Epoch: 5| Step: 1
Training loss: 3.3882311267764824
Validation loss: 2.8397031411482043

Epoch: 5| Step: 2
Training loss: 3.7277433495811754
Validation loss: 2.8385105757164473

Epoch: 5| Step: 3
Training loss: 2.414175777802169
Validation loss: 2.839566017475884

Epoch: 5| Step: 4
Training loss: 3.0839045914711556
Validation loss: 2.841824108055735

Epoch: 5| Step: 5
Training loss: 3.122837539155611
Validation loss: 2.846569972274874

Epoch: 5| Step: 6
Training loss: 3.2941039675140042
Validation loss: 2.844770897123787

Epoch: 5| Step: 7
Training loss: 2.7696348098310506
Validation loss: 2.846627144029689

Epoch: 5| Step: 8
Training loss: 3.5084578636219286
Validation loss: 2.8388711536953384

Epoch: 5| Step: 9
Training loss: 3.08871003196481
Validation loss: 2.8417399542922097

Epoch: 5| Step: 10
Training loss: 3.0081393770230593
Validation loss: 2.8369248143725656

Epoch: 69| Step: 0
Training loss: 3.323151503409349
Validation loss: 2.838377264672763

Epoch: 5| Step: 1
Training loss: 3.494617273989041
Validation loss: 2.838044369319495

Epoch: 5| Step: 2
Training loss: 3.021242907590358
Validation loss: 2.8409809278129443

Epoch: 5| Step: 3
Training loss: 2.7775225575077873
Validation loss: 2.837907310034626

Epoch: 5| Step: 4
Training loss: 2.691955864628117
Validation loss: 2.8405003921800187

Epoch: 5| Step: 5
Training loss: 2.714400660081508
Validation loss: 2.8398080924476465

Epoch: 5| Step: 6
Training loss: 3.456297232941485
Validation loss: 2.842548619177755

Epoch: 5| Step: 7
Training loss: 3.0258000726604384
Validation loss: 2.8436635863057096

Epoch: 5| Step: 8
Training loss: 2.94108719634158
Validation loss: 2.843951148187873

Epoch: 5| Step: 9
Training loss: 3.5381259647456345
Validation loss: 2.852039845051459

Epoch: 5| Step: 10
Training loss: 3.574977506553472
Validation loss: 2.8492582411933123

Epoch: 70| Step: 0
Training loss: 3.549084349196621
Validation loss: 2.8417110334159075

Epoch: 5| Step: 1
Training loss: 2.872908453391333
Validation loss: 2.839309111470936

Epoch: 5| Step: 2
Training loss: 2.9593725573037206
Validation loss: 2.837186891541564

Epoch: 5| Step: 3
Training loss: 3.696836516179199
Validation loss: 2.83661572470832

Epoch: 5| Step: 4
Training loss: 3.663111060922576
Validation loss: 2.846824123011295

Epoch: 5| Step: 5
Training loss: 3.013688804989306
Validation loss: 2.8562375388258783

Epoch: 5| Step: 6
Training loss: 2.8697066297353584
Validation loss: 2.846792087500437

Epoch: 5| Step: 7
Training loss: 2.7713692703700574
Validation loss: 2.837192755804711

Epoch: 5| Step: 8
Training loss: 3.581594192981081
Validation loss: 2.836911317142246

Epoch: 5| Step: 9
Training loss: 2.48293766692908
Validation loss: 2.8367261050880157

Epoch: 5| Step: 10
Training loss: 2.8456307364677658
Validation loss: 2.8394432735063573

Epoch: 71| Step: 0
Training loss: 2.8939061693272152
Validation loss: 2.838290261978645

Epoch: 5| Step: 1
Training loss: 3.3772975024573983
Validation loss: 2.8400738554307012

Epoch: 5| Step: 2
Training loss: 2.3496608205285927
Validation loss: 2.838294144076281

Epoch: 5| Step: 3
Training loss: 3.059809846143329
Validation loss: 2.838633322988184

Epoch: 5| Step: 4
Training loss: 3.3133535185211205
Validation loss: 2.847269719092252

Epoch: 5| Step: 5
Training loss: 3.509835320546529
Validation loss: 2.8479069317079997

Epoch: 5| Step: 6
Training loss: 3.4151233971392583
Validation loss: 2.8473217392950843

Epoch: 5| Step: 7
Training loss: 2.8229308086946605
Validation loss: 2.8511083439315454

Epoch: 5| Step: 8
Training loss: 2.619780846959568
Validation loss: 2.8509072052462487

Epoch: 5| Step: 9
Training loss: 3.49547638796674
Validation loss: 2.8472001706588417

Epoch: 5| Step: 10
Training loss: 3.548958456347148
Validation loss: 2.8390433112139544

Epoch: 72| Step: 0
Training loss: 2.752030923148454
Validation loss: 2.8366706045451258

Epoch: 5| Step: 1
Training loss: 3.2321743320055596
Validation loss: 2.831193288269387

Epoch: 5| Step: 2
Training loss: 3.311723726110911
Validation loss: 2.82662572139992

Epoch: 5| Step: 3
Training loss: 3.224634513549044
Validation loss: 2.829522190617526

Epoch: 5| Step: 4
Training loss: 2.8310514873106265
Validation loss: 2.831649243280558

Epoch: 5| Step: 5
Training loss: 3.180849355114775
Validation loss: 2.829114388369451

Epoch: 5| Step: 6
Training loss: 3.350799402537753
Validation loss: 2.8307229506025156

Epoch: 5| Step: 7
Training loss: 3.166614548772946
Validation loss: 2.8323364464508063

Epoch: 5| Step: 8
Training loss: 3.163494294563118
Validation loss: 2.828546161256423

Epoch: 5| Step: 9
Training loss: 3.262708758109829
Validation loss: 2.8274348664523226

Epoch: 5| Step: 10
Training loss: 3.0277891557423313
Validation loss: 2.826681178829246

Epoch: 73| Step: 0
Training loss: 2.9860818984699864
Validation loss: 2.82721220977413

Epoch: 5| Step: 1
Training loss: 2.812686744424185
Validation loss: 2.8289514101416557

Epoch: 5| Step: 2
Training loss: 3.0160286588749097
Validation loss: 2.8287367738349634

Epoch: 5| Step: 3
Training loss: 3.3073053474844176
Validation loss: 2.8293092757112457

Epoch: 5| Step: 4
Training loss: 3.2380206068772206
Validation loss: 2.831683364904201

Epoch: 5| Step: 5
Training loss: 3.6817584841048876
Validation loss: 2.834377818942792

Epoch: 5| Step: 6
Training loss: 3.659637837861703
Validation loss: 2.8441293087763246

Epoch: 5| Step: 7
Training loss: 3.187726629839729
Validation loss: 2.840553494822842

Epoch: 5| Step: 8
Training loss: 3.0987279127779512
Validation loss: 2.8402589006282457

Epoch: 5| Step: 9
Training loss: 2.5008556808935847
Validation loss: 2.835258380651076

Epoch: 5| Step: 10
Training loss: 2.779581662543844
Validation loss: 2.8432529478892024

Epoch: 74| Step: 0
Training loss: 2.864811799157544
Validation loss: 2.8450791584785096

Epoch: 5| Step: 1
Training loss: 3.2490143381673002
Validation loss: 2.8612730622431384

Epoch: 5| Step: 2
Training loss: 3.0479962755515904
Validation loss: 2.8625688848980744

Epoch: 5| Step: 3
Training loss: 4.002089193254768
Validation loss: 2.8576967714165558

Epoch: 5| Step: 4
Training loss: 3.062409535843005
Validation loss: 2.8426881854461588

Epoch: 5| Step: 5
Training loss: 2.832660726109925
Validation loss: 2.8370244457304326

Epoch: 5| Step: 6
Training loss: 2.184466847683977
Validation loss: 2.8313266650234556

Epoch: 5| Step: 7
Training loss: 3.2177581740438446
Validation loss: 2.8279074589353153

Epoch: 5| Step: 8
Training loss: 3.2219034691338138
Validation loss: 2.8235177417797996

Epoch: 5| Step: 9
Training loss: 3.5568667931161224
Validation loss: 2.82192892484732

Epoch: 5| Step: 10
Training loss: 2.9152382940710457
Validation loss: 2.8240186655327717

Epoch: 75| Step: 0
Training loss: 3.1205085520884617
Validation loss: 2.824376210304435

Epoch: 5| Step: 1
Training loss: 2.7482460670967037
Validation loss: 2.830272583663568

Epoch: 5| Step: 2
Training loss: 3.849360147786029
Validation loss: 2.829590094262139

Epoch: 5| Step: 3
Training loss: 3.084966656521685
Validation loss: 2.832147165994811

Epoch: 5| Step: 4
Training loss: 2.9777896784391196
Validation loss: 2.8266528530222526

Epoch: 5| Step: 5
Training loss: 3.2153078210103145
Validation loss: 2.824235360583735

Epoch: 5| Step: 6
Training loss: 3.0401372504622137
Validation loss: 2.824178526184894

Epoch: 5| Step: 7
Training loss: 3.449159857138079
Validation loss: 2.8259635075341847

Epoch: 5| Step: 8
Training loss: 2.7827610668674803
Validation loss: 2.826027780988758

Epoch: 5| Step: 9
Training loss: 3.400799090783162
Validation loss: 2.8250555036448097

Epoch: 5| Step: 10
Training loss: 2.5395466034892813
Validation loss: 2.8275741161183423

Epoch: 76| Step: 0
Training loss: 2.548447012635047
Validation loss: 2.8248504752284

Epoch: 5| Step: 1
Training loss: 3.268781240981354
Validation loss: 2.8240910579246084

Epoch: 5| Step: 2
Training loss: 2.692295320712998
Validation loss: 2.8278670264984713

Epoch: 5| Step: 3
Training loss: 2.7563221824692006
Validation loss: 2.8309294844109405

Epoch: 5| Step: 4
Training loss: 2.620474683989046
Validation loss: 2.8382188098401757

Epoch: 5| Step: 5
Training loss: 3.538274748921081
Validation loss: 2.8368181234124616

Epoch: 5| Step: 6
Training loss: 3.333285633381648
Validation loss: 2.8335918752516043

Epoch: 5| Step: 7
Training loss: 3.158417816508401
Validation loss: 2.8300610830971413

Epoch: 5| Step: 8
Training loss: 2.843268552834501
Validation loss: 2.8394698736597475

Epoch: 5| Step: 9
Training loss: 3.80338460871518
Validation loss: 2.8397862954322552

Epoch: 5| Step: 10
Training loss: 3.7130845454191674
Validation loss: 2.8339697610446035

Epoch: 77| Step: 0
Training loss: 2.6316888148813455
Validation loss: 2.827409583862816

Epoch: 5| Step: 1
Training loss: 3.0303340196469897
Validation loss: 2.8225715885515137

Epoch: 5| Step: 2
Training loss: 2.7219259193816807
Validation loss: 2.821573062488659

Epoch: 5| Step: 3
Training loss: 3.0730828364212437
Validation loss: 2.827748140906568

Epoch: 5| Step: 4
Training loss: 2.5444367327658868
Validation loss: 2.8347372820873646

Epoch: 5| Step: 5
Training loss: 3.623693822798322
Validation loss: 2.832344181705204

Epoch: 5| Step: 6
Training loss: 3.4143421049870932
Validation loss: 2.841761656032917

Epoch: 5| Step: 7
Training loss: 3.584796931901269
Validation loss: 2.8285488404130272

Epoch: 5| Step: 8
Training loss: 2.9211988023638735
Validation loss: 2.8234652771045825

Epoch: 5| Step: 9
Training loss: 2.7736273042446715
Validation loss: 2.824647894240359

Epoch: 5| Step: 10
Training loss: 3.889007477238893
Validation loss: 2.824627148322624

Epoch: 78| Step: 0
Training loss: 3.810625209423558
Validation loss: 2.8271338689134957

Epoch: 5| Step: 1
Training loss: 3.381397823691473
Validation loss: 2.8280509196167194

Epoch: 5| Step: 2
Training loss: 2.601084255673919
Validation loss: 2.8289817763659366

Epoch: 5| Step: 3
Training loss: 3.083837485121996
Validation loss: 2.822819052441393

Epoch: 5| Step: 4
Training loss: 2.7962689302474706
Validation loss: 2.8216618771497823

Epoch: 5| Step: 5
Training loss: 3.2914159333226745
Validation loss: 2.8180699076180815

Epoch: 5| Step: 6
Training loss: 3.2079062900126822
Validation loss: 2.820003300434114

Epoch: 5| Step: 7
Training loss: 3.1648017678999327
Validation loss: 2.8216959396544774

Epoch: 5| Step: 8
Training loss: 2.5528546679289064
Validation loss: 2.8237959664542815

Epoch: 5| Step: 9
Training loss: 3.012099819591169
Validation loss: 2.823375929877371

Epoch: 5| Step: 10
Training loss: 3.338190180248033
Validation loss: 2.8246335650699517

Epoch: 79| Step: 0
Training loss: 3.4363505435692345
Validation loss: 2.824049410693726

Epoch: 5| Step: 1
Training loss: 3.4287292949344796
Validation loss: 2.8225408581743667

Epoch: 5| Step: 2
Training loss: 2.5885395891781204
Validation loss: 2.8285721025639394

Epoch: 5| Step: 3
Training loss: 2.547530949847261
Validation loss: 2.824397207676584

Epoch: 5| Step: 4
Training loss: 3.7087561691330584
Validation loss: 2.824009366026989

Epoch: 5| Step: 5
Training loss: 2.996487468528419
Validation loss: 2.825819906405085

Epoch: 5| Step: 6
Training loss: 3.5368528225653906
Validation loss: 2.8245752910302286

Epoch: 5| Step: 7
Training loss: 3.1193662596457643
Validation loss: 2.8270978034951466

Epoch: 5| Step: 8
Training loss: 2.7749095180297236
Validation loss: 2.828990996998312

Epoch: 5| Step: 9
Training loss: 2.6163213862464167
Validation loss: 2.828050421039249

Epoch: 5| Step: 10
Training loss: 3.3575536714242022
Validation loss: 2.832626922163039

Epoch: 80| Step: 0
Training loss: 3.120052693973515
Validation loss: 2.826620753967553

Epoch: 5| Step: 1
Training loss: 2.665471126860128
Validation loss: 2.8119343579640543

Epoch: 5| Step: 2
Training loss: 3.1817107640749605
Validation loss: 2.8147222783851777

Epoch: 5| Step: 3
Training loss: 3.077069871408557
Validation loss: 2.8156319538458656

Epoch: 5| Step: 4
Training loss: 3.3556043177830746
Validation loss: 2.818699767602808

Epoch: 5| Step: 5
Training loss: 3.247104235020172
Validation loss: 2.8246805366686485

Epoch: 5| Step: 6
Training loss: 3.7299566586510142
Validation loss: 2.8395235390853957

Epoch: 5| Step: 7
Training loss: 2.9190013442368006
Validation loss: 2.8486180730029433

Epoch: 5| Step: 8
Training loss: 2.9608482810395675
Validation loss: 2.8429363745109484

Epoch: 5| Step: 9
Training loss: 2.9377757815503167
Validation loss: 2.8234810667749413

Epoch: 5| Step: 10
Training loss: 3.094032351777799
Validation loss: 2.8135968000974794

Epoch: 81| Step: 0
Training loss: 3.3852858454541366
Validation loss: 2.8138415018803546

Epoch: 5| Step: 1
Training loss: 3.0815995642902387
Validation loss: 2.8127750020730127

Epoch: 5| Step: 2
Training loss: 3.4542651473402968
Validation loss: 2.8149461616023643

Epoch: 5| Step: 3
Training loss: 3.054843752247727
Validation loss: 2.810898083752578

Epoch: 5| Step: 4
Training loss: 3.0728631138849654
Validation loss: 2.8116702907971765

Epoch: 5| Step: 5
Training loss: 3.5428197591760577
Validation loss: 2.812006503508628

Epoch: 5| Step: 6
Training loss: 3.0442408986356155
Validation loss: 2.8064091293434825

Epoch: 5| Step: 7
Training loss: 2.808081822966542
Validation loss: 2.807267107053175

Epoch: 5| Step: 8
Training loss: 3.3175370408198783
Validation loss: 2.80920953997155

Epoch: 5| Step: 9
Training loss: 3.0257181245230664
Validation loss: 2.80767551036606

Epoch: 5| Step: 10
Training loss: 2.2395510175872255
Validation loss: 2.8105311221234883

Epoch: 82| Step: 0
Training loss: 3.2843768525413277
Validation loss: 2.8112088483605584

Epoch: 5| Step: 1
Training loss: 3.658822352948693
Validation loss: 2.8165239595640696

Epoch: 5| Step: 2
Training loss: 3.1171679197380033
Validation loss: 2.818464656278986

Epoch: 5| Step: 3
Training loss: 2.838473276603496
Validation loss: 2.826980357368588

Epoch: 5| Step: 4
Training loss: 2.995381615069683
Validation loss: 2.8167504736901736

Epoch: 5| Step: 5
Training loss: 3.3074437544488604
Validation loss: 2.81118994387785

Epoch: 5| Step: 6
Training loss: 2.8361584285716495
Validation loss: 2.8071594304545444

Epoch: 5| Step: 7
Training loss: 2.911022246883487
Validation loss: 2.811156045897812

Epoch: 5| Step: 8
Training loss: 3.427234511050826
Validation loss: 2.8150074454130976

Epoch: 5| Step: 9
Training loss: 2.6253060661993572
Validation loss: 2.80741396018217

Epoch: 5| Step: 10
Training loss: 3.244334197312308
Validation loss: 2.812328959634145

Epoch: 83| Step: 0
Training loss: 2.9972098409094308
Validation loss: 2.8143156929150264

Epoch: 5| Step: 1
Training loss: 3.1420875294401927
Validation loss: 2.810976957355359

Epoch: 5| Step: 2
Training loss: 2.716018181224527
Validation loss: 2.8085469201173647

Epoch: 5| Step: 3
Training loss: 3.5417898418474065
Validation loss: 2.8099444046041455

Epoch: 5| Step: 4
Training loss: 2.9160978761737906
Validation loss: 2.8104556037782005

Epoch: 5| Step: 5
Training loss: 3.5484102262375177
Validation loss: 2.80768531229441

Epoch: 5| Step: 6
Training loss: 2.9911894167014754
Validation loss: 2.807517646669295

Epoch: 5| Step: 7
Training loss: 2.7261917168195398
Validation loss: 2.807015258695656

Epoch: 5| Step: 8
Training loss: 3.3202306400754598
Validation loss: 2.805048545221519

Epoch: 5| Step: 9
Training loss: 3.3487497188600748
Validation loss: 2.8075765614755905

Epoch: 5| Step: 10
Training loss: 2.8558117286110547
Validation loss: 2.803856516705513

Epoch: 84| Step: 0
Training loss: 3.377651444660359
Validation loss: 2.8038102495684507

Epoch: 5| Step: 1
Training loss: 2.618955191719425
Validation loss: 2.8044783891632274

Epoch: 5| Step: 2
Training loss: 3.605820792587568
Validation loss: 2.803110992703571

Epoch: 5| Step: 3
Training loss: 2.8045764784237273
Validation loss: 2.803288699870424

Epoch: 5| Step: 4
Training loss: 2.6927722404368306
Validation loss: 2.804526135274713

Epoch: 5| Step: 5
Training loss: 2.945865164391008
Validation loss: 2.80279996318636

Epoch: 5| Step: 6
Training loss: 3.447573518916596
Validation loss: 2.80275460061171

Epoch: 5| Step: 7
Training loss: 3.279106966191792
Validation loss: 2.8019262674591823

Epoch: 5| Step: 8
Training loss: 2.9424777770519905
Validation loss: 2.801049535179375

Epoch: 5| Step: 9
Training loss: 3.3351621061672643
Validation loss: 2.8026256552626885

Epoch: 5| Step: 10
Training loss: 3.073561795721957
Validation loss: 2.801300368224668

Epoch: 85| Step: 0
Training loss: 2.508773286917606
Validation loss: 2.8010595131394496

Epoch: 5| Step: 1
Training loss: 3.6410873185028003
Validation loss: 2.8041262200276975

Epoch: 5| Step: 2
Training loss: 2.8986444527910438
Validation loss: 2.80746571258929

Epoch: 5| Step: 3
Training loss: 2.180808158654382
Validation loss: 2.8019112374285355

Epoch: 5| Step: 4
Training loss: 2.7764139885971404
Validation loss: 2.8055202895210476

Epoch: 5| Step: 5
Training loss: 3.228754587439728
Validation loss: 2.8072218376684837

Epoch: 5| Step: 6
Training loss: 3.68525782807654
Validation loss: 2.803593781786435

Epoch: 5| Step: 7
Training loss: 3.2339174988272648
Validation loss: 2.8048627683630243

Epoch: 5| Step: 8
Training loss: 2.8791367996219805
Validation loss: 2.8044533676530654

Epoch: 5| Step: 9
Training loss: 3.358492855199018
Validation loss: 2.80205419467082

Epoch: 5| Step: 10
Training loss: 3.5873175066211447
Validation loss: 2.8042921412099666

Epoch: 86| Step: 0
Training loss: 2.531275336998241
Validation loss: 2.8046723092669503

Epoch: 5| Step: 1
Training loss: 3.3604158430262054
Validation loss: 2.8033197684081337

Epoch: 5| Step: 2
Training loss: 2.9488190436921364
Validation loss: 2.8031899335981123

Epoch: 5| Step: 3
Training loss: 2.8378230780631295
Validation loss: 2.800987286989141

Epoch: 5| Step: 4
Training loss: 2.6291081207898666
Validation loss: 2.7980211093136234

Epoch: 5| Step: 5
Training loss: 3.4340919940336962
Validation loss: 2.8011655581159993

Epoch: 5| Step: 6
Training loss: 3.6396024520421366
Validation loss: 2.79789988991382

Epoch: 5| Step: 7
Training loss: 3.539912847965527
Validation loss: 2.801683102644475

Epoch: 5| Step: 8
Training loss: 3.212668887200201
Validation loss: 2.8002270284221997

Epoch: 5| Step: 9
Training loss: 2.8414255220747138
Validation loss: 2.7978491068443785

Epoch: 5| Step: 10
Training loss: 3.0921162616837425
Validation loss: 2.799839815269019

Epoch: 87| Step: 0
Training loss: 3.598269465204916
Validation loss: 2.804139555995515

Epoch: 5| Step: 1
Training loss: 2.940873339683475
Validation loss: 2.8066419805144007

Epoch: 5| Step: 2
Training loss: 3.0572422593309105
Validation loss: 2.8080205386473263

Epoch: 5| Step: 3
Training loss: 2.877961002279157
Validation loss: 2.8110006804736307

Epoch: 5| Step: 4
Training loss: 3.0213693252882012
Validation loss: 2.8136513699322054

Epoch: 5| Step: 5
Training loss: 3.060709838813086
Validation loss: 2.8129107850952457

Epoch: 5| Step: 6
Training loss: 3.3376936209874875
Validation loss: 2.81704593189201

Epoch: 5| Step: 7
Training loss: 3.455550502747511
Validation loss: 2.8137368730884718

Epoch: 5| Step: 8
Training loss: 2.6607462807009
Validation loss: 2.815698693816924

Epoch: 5| Step: 9
Training loss: 2.6883420290474245
Validation loss: 2.807493914208767

Epoch: 5| Step: 10
Training loss: 3.4341746111263167
Validation loss: 2.807289518192303

Epoch: 88| Step: 0
Training loss: 3.406432120677828
Validation loss: 2.798428950088824

Epoch: 5| Step: 1
Training loss: 2.839539145566425
Validation loss: 2.7977049377559156

Epoch: 5| Step: 2
Training loss: 3.2556035079144126
Validation loss: 2.7961901331903767

Epoch: 5| Step: 3
Training loss: 3.2487508867592094
Validation loss: 2.7957048542284815

Epoch: 5| Step: 4
Training loss: 3.5838518580746332
Validation loss: 2.7975189050738734

Epoch: 5| Step: 5
Training loss: 3.2578268439619773
Validation loss: 2.7943559940272236

Epoch: 5| Step: 6
Training loss: 2.489367668568214
Validation loss: 2.7988161111208907

Epoch: 5| Step: 7
Training loss: 2.9484430568786233
Validation loss: 2.800455401745367

Epoch: 5| Step: 8
Training loss: 3.4015002250665707
Validation loss: 2.797312607121129

Epoch: 5| Step: 9
Training loss: 2.4933770190031073
Validation loss: 2.7990998432626286

Epoch: 5| Step: 10
Training loss: 3.063593299497197
Validation loss: 2.8021786944152898

Epoch: 89| Step: 0
Training loss: 2.712395619436422
Validation loss: 2.79883528237495

Epoch: 5| Step: 1
Training loss: 2.5470642768408664
Validation loss: 2.7967128948440143

Epoch: 5| Step: 2
Training loss: 2.908261331215283
Validation loss: 2.796827592583723

Epoch: 5| Step: 3
Training loss: 3.2153570569569943
Validation loss: 2.804226703114176

Epoch: 5| Step: 4
Training loss: 2.6573304615506075
Validation loss: 2.7998298979727694

Epoch: 5| Step: 5
Training loss: 3.225839750979429
Validation loss: 2.79743232337058

Epoch: 5| Step: 6
Training loss: 3.3646345262599167
Validation loss: 2.7950018855268746

Epoch: 5| Step: 7
Training loss: 3.128019476300653
Validation loss: 2.794126657918887

Epoch: 5| Step: 8
Training loss: 3.103127034504541
Validation loss: 2.79691387769808

Epoch: 5| Step: 9
Training loss: 3.4106442166808195
Validation loss: 2.794187390033485

Epoch: 5| Step: 10
Training loss: 3.7930800070980024
Validation loss: 2.795386413166735

Epoch: 90| Step: 0
Training loss: 3.4154480102138334
Validation loss: 2.7939352595840723

Epoch: 5| Step: 1
Training loss: 3.265664278369121
Validation loss: 2.7929738204248

Epoch: 5| Step: 2
Training loss: 2.7619848055742713
Validation loss: 2.792482339279124

Epoch: 5| Step: 3
Training loss: 2.858192407750339
Validation loss: 2.796678827807303

Epoch: 5| Step: 4
Training loss: 3.428138609088045
Validation loss: 2.792887317202634

Epoch: 5| Step: 5
Training loss: 3.1814242032362645
Validation loss: 2.7936397302696316

Epoch: 5| Step: 6
Training loss: 2.972194560586747
Validation loss: 2.7908642897896163

Epoch: 5| Step: 7
Training loss: 3.127341651963448
Validation loss: 2.791373715176754

Epoch: 5| Step: 8
Training loss: 2.216458816631054
Validation loss: 2.793913815811757

Epoch: 5| Step: 9
Training loss: 3.6824906802140425
Validation loss: 2.797227532163407

Epoch: 5| Step: 10
Training loss: 3.00369559592366
Validation loss: 2.7961998195189564

Epoch: 91| Step: 0
Training loss: 2.9060504803824814
Validation loss: 2.7934964617202422

Epoch: 5| Step: 1
Training loss: 3.1000242478437547
Validation loss: 2.794867166036588

Epoch: 5| Step: 2
Training loss: 3.168836820417485
Validation loss: 2.7991953807784435

Epoch: 5| Step: 3
Training loss: 2.5889718960164547
Validation loss: 2.796124698938548

Epoch: 5| Step: 4
Training loss: 2.8002794739348986
Validation loss: 2.796173042445879

Epoch: 5| Step: 5
Training loss: 2.8092237251467256
Validation loss: 2.7946319962903776

Epoch: 5| Step: 6
Training loss: 3.1559484356631136
Validation loss: 2.7952525954159584

Epoch: 5| Step: 7
Training loss: 2.488915953839072
Validation loss: 2.7935068410860726

Epoch: 5| Step: 8
Training loss: 3.4422254507472303
Validation loss: 2.7996341883135933

Epoch: 5| Step: 9
Training loss: 3.8080360669423534
Validation loss: 2.7939755426004496

Epoch: 5| Step: 10
Training loss: 3.6760007365063085
Validation loss: 2.7944673638576933

Epoch: 92| Step: 0
Training loss: 3.240913747579606
Validation loss: 2.7953572098928023

Epoch: 5| Step: 1
Training loss: 3.6040083716292113
Validation loss: 2.8011395680047406

Epoch: 5| Step: 2
Training loss: 2.93301812631369
Validation loss: 2.7971850450386406

Epoch: 5| Step: 3
Training loss: 3.280862403865506
Validation loss: 2.798795131591384

Epoch: 5| Step: 4
Training loss: 3.32777137847721
Validation loss: 2.7996608645213263

Epoch: 5| Step: 5
Training loss: 3.501303974840082
Validation loss: 2.7992561998263072

Epoch: 5| Step: 6
Training loss: 2.994489854725053
Validation loss: 2.7910018106850925

Epoch: 5| Step: 7
Training loss: 2.588291813684629
Validation loss: 2.790824095061587

Epoch: 5| Step: 8
Training loss: 2.9692477160396273
Validation loss: 2.786718486379247

Epoch: 5| Step: 9
Training loss: 3.2299736409248507
Validation loss: 2.7859998541832676

Epoch: 5| Step: 10
Training loss: 1.9724739821426016
Validation loss: 2.7871661641456833

Epoch: 93| Step: 0
Training loss: 2.401451875698867
Validation loss: 2.7865782917289357

Epoch: 5| Step: 1
Training loss: 2.8188707042487295
Validation loss: 2.7848744729289825

Epoch: 5| Step: 2
Training loss: 3.7205925231674737
Validation loss: 2.7875677446244773

Epoch: 5| Step: 3
Training loss: 3.5172604973978223
Validation loss: 2.7864531105934827

Epoch: 5| Step: 4
Training loss: 2.9137941293144483
Validation loss: 2.785286595930374

Epoch: 5| Step: 5
Training loss: 2.6819011119957286
Validation loss: 2.7849505790858404

Epoch: 5| Step: 6
Training loss: 3.3050968286408637
Validation loss: 2.7846381140359253

Epoch: 5| Step: 7
Training loss: 2.979141359733031
Validation loss: 2.7866914618079313

Epoch: 5| Step: 8
Training loss: 2.794692311965808
Validation loss: 2.786756432203164

Epoch: 5| Step: 9
Training loss: 3.4957879470831292
Validation loss: 2.788533220136574

Epoch: 5| Step: 10
Training loss: 3.246807878257571
Validation loss: 2.791163692305443

Epoch: 94| Step: 0
Training loss: 3.129716899122402
Validation loss: 2.7862367370343093

Epoch: 5| Step: 1
Training loss: 3.361209528159097
Validation loss: 2.785806788596332

Epoch: 5| Step: 2
Training loss: 3.2998778060484413
Validation loss: 2.787284186942934

Epoch: 5| Step: 3
Training loss: 3.017253534828092
Validation loss: 2.784152051737622

Epoch: 5| Step: 4
Training loss: 2.9230925119424502
Validation loss: 2.7841192794359753

Epoch: 5| Step: 5
Training loss: 3.0234889141905907
Validation loss: 2.785130294588887

Epoch: 5| Step: 6
Training loss: 3.286738718750621
Validation loss: 2.7928534981569397

Epoch: 5| Step: 7
Training loss: 2.5416075173254513
Validation loss: 2.7918904523517063

Epoch: 5| Step: 8
Training loss: 2.791517870529289
Validation loss: 2.7863436203303644

Epoch: 5| Step: 9
Training loss: 2.9728761609175476
Validation loss: 2.790171506754989

Epoch: 5| Step: 10
Training loss: 3.709252290053823
Validation loss: 2.7905241186729652

Epoch: 95| Step: 0
Training loss: 3.364989800402302
Validation loss: 2.782719988595483

Epoch: 5| Step: 1
Training loss: 3.387481779492915
Validation loss: 2.7815905430824572

Epoch: 5| Step: 2
Training loss: 2.761286376602992
Validation loss: 2.786999805655259

Epoch: 5| Step: 3
Training loss: 2.890532456024927
Validation loss: 2.7882596657983134

Epoch: 5| Step: 4
Training loss: 3.0892728526495805
Validation loss: 2.7888646181838794

Epoch: 5| Step: 5
Training loss: 3.6205598670109507
Validation loss: 2.789326145957225

Epoch: 5| Step: 6
Training loss: 3.2801790942167655
Validation loss: 2.789999636001966

Epoch: 5| Step: 7
Training loss: 3.381906013522812
Validation loss: 2.7912728979781383

Epoch: 5| Step: 8
Training loss: 2.913942881729317
Validation loss: 2.791772948439635

Epoch: 5| Step: 9
Training loss: 2.1514485292299654
Validation loss: 2.7935252925849663

Epoch: 5| Step: 10
Training loss: 3.0575243954999194
Validation loss: 2.7928451624331476

Epoch: 96| Step: 0
Training loss: 3.4093644489016675
Validation loss: 2.7903830798040343

Epoch: 5| Step: 1
Training loss: 3.056148560133562
Validation loss: 2.789365697778404

Epoch: 5| Step: 2
Training loss: 2.9561338889806867
Validation loss: 2.8030309035973864

Epoch: 5| Step: 3
Training loss: 2.681881287424491
Validation loss: 2.792278970769637

Epoch: 5| Step: 4
Training loss: 2.9483172320897895
Validation loss: 2.791899062725781

Epoch: 5| Step: 5
Training loss: 3.4039147447607454
Validation loss: 2.792427700033375

Epoch: 5| Step: 6
Training loss: 3.164895783888622
Validation loss: 2.7893048873339015

Epoch: 5| Step: 7
Training loss: 3.516599799751363
Validation loss: 2.7822100595521184

Epoch: 5| Step: 8
Training loss: 3.0402669603683847
Validation loss: 2.7840459213413413

Epoch: 5| Step: 9
Training loss: 2.7723242876184226
Validation loss: 2.779621406514659

Epoch: 5| Step: 10
Training loss: 3.1186630083997433
Validation loss: 2.783394770404424

Epoch: 97| Step: 0
Training loss: 2.777830615070939
Validation loss: 2.7827840844010865

Epoch: 5| Step: 1
Training loss: 3.605266924961275
Validation loss: 2.7800721212265307

Epoch: 5| Step: 2
Training loss: 2.9259052734164768
Validation loss: 2.7836948390890552

Epoch: 5| Step: 3
Training loss: 3.262711827208653
Validation loss: 2.7878139954507892

Epoch: 5| Step: 4
Training loss: 3.510919838603289
Validation loss: 2.7914040328232153

Epoch: 5| Step: 5
Training loss: 2.847030256876336
Validation loss: 2.787592939772322

Epoch: 5| Step: 6
Training loss: 2.9035287237571143
Validation loss: 2.7878835016524923

Epoch: 5| Step: 7
Training loss: 3.328652496800771
Validation loss: 2.7965257685217875

Epoch: 5| Step: 8
Training loss: 3.211848146081749
Validation loss: 2.7950972879549125

Epoch: 5| Step: 9
Training loss: 2.8833139701884
Validation loss: 2.7865790645253945

Epoch: 5| Step: 10
Training loss: 2.6166267363625844
Validation loss: 2.78693768335589

Epoch: 98| Step: 0
Training loss: 3.4123488955177503
Validation loss: 2.782942476903877

Epoch: 5| Step: 1
Training loss: 2.202858766742848
Validation loss: 2.7779560610939398

Epoch: 5| Step: 2
Training loss: 2.9064093105172284
Validation loss: 2.775554444689383

Epoch: 5| Step: 3
Training loss: 3.1351364534362838
Validation loss: 2.780507929711107

Epoch: 5| Step: 4
Training loss: 2.932913913507836
Validation loss: 2.780268970930257

Epoch: 5| Step: 5
Training loss: 1.8686480695298322
Validation loss: 2.7863283498303764

Epoch: 5| Step: 6
Training loss: 3.3820519418275112
Validation loss: 2.7828003831134276

Epoch: 5| Step: 7
Training loss: 3.86664788691027
Validation loss: 2.7862206534879785

Epoch: 5| Step: 8
Training loss: 3.143037239710971
Validation loss: 2.779883882117888

Epoch: 5| Step: 9
Training loss: 3.5081296237933435
Validation loss: 2.7796401475568664

Epoch: 5| Step: 10
Training loss: 3.1861056101525276
Validation loss: 2.7801346846413924

Epoch: 99| Step: 0
Training loss: 3.0568432628019058
Validation loss: 2.7750605362165994

Epoch: 5| Step: 1
Training loss: 2.8910472664546667
Validation loss: 2.773990519697718

Epoch: 5| Step: 2
Training loss: 2.8020574197433605
Validation loss: 2.7746950974044005

Epoch: 5| Step: 3
Training loss: 1.8625686530446837
Validation loss: 2.7776483100198144

Epoch: 5| Step: 4
Training loss: 3.3813844269774136
Validation loss: 2.777197217637462

Epoch: 5| Step: 5
Training loss: 2.9316666492016132
Validation loss: 2.7775720619266693

Epoch: 5| Step: 6
Training loss: 3.2917134889258315
Validation loss: 2.780729023115848

Epoch: 5| Step: 7
Training loss: 3.7420460588647275
Validation loss: 2.7782892356887845

Epoch: 5| Step: 8
Training loss: 3.315395313472396
Validation loss: 2.7778467638070086

Epoch: 5| Step: 9
Training loss: 2.9996121473730515
Validation loss: 2.779992866003822

Epoch: 5| Step: 10
Training loss: 3.454257140836439
Validation loss: 2.7761820621993527

Epoch: 100| Step: 0
Training loss: 2.5641685264001284
Validation loss: 2.7755900890344956

Epoch: 5| Step: 1
Training loss: 3.4314873562901838
Validation loss: 2.7780345835639526

Epoch: 5| Step: 2
Training loss: 3.66610693271681
Validation loss: 2.7783546360136993

Epoch: 5| Step: 3
Training loss: 2.645907743914485
Validation loss: 2.780721537946973

Epoch: 5| Step: 4
Training loss: 2.7970054212455597
Validation loss: 2.775620563843051

Epoch: 5| Step: 5
Training loss: 3.422090427811364
Validation loss: 2.7767452579753686

Epoch: 5| Step: 6
Training loss: 3.1042639356559802
Validation loss: 2.7776036793147414

Epoch: 5| Step: 7
Training loss: 3.1128575743908335
Validation loss: 2.771536205395953

Epoch: 5| Step: 8
Training loss: 2.501275118845148
Validation loss: 2.771626923137119

Epoch: 5| Step: 9
Training loss: 3.0419214917045996
Validation loss: 2.776626677340448

Epoch: 5| Step: 10
Training loss: 3.5141534735004023
Validation loss: 2.775269322406145

Epoch: 101| Step: 0
Training loss: 3.4923893061621722
Validation loss: 2.7784144543203655

Epoch: 5| Step: 1
Training loss: 2.978203909149791
Validation loss: 2.7847477634159357

Epoch: 5| Step: 2
Training loss: 2.8079283964749218
Validation loss: 2.7774364379297993

Epoch: 5| Step: 3
Training loss: 2.845621185065581
Validation loss: 2.7739722339968704

Epoch: 5| Step: 4
Training loss: 2.987889961105953
Validation loss: 2.7761786251494263

Epoch: 5| Step: 5
Training loss: 3.185776637320631
Validation loss: 2.7731659814807705

Epoch: 5| Step: 6
Training loss: 3.251358041929755
Validation loss: 2.774046124640383

Epoch: 5| Step: 7
Training loss: 3.166315326942942
Validation loss: 2.774067541783326

Epoch: 5| Step: 8
Training loss: 2.859873577071381
Validation loss: 2.7739949501683

Epoch: 5| Step: 9
Training loss: 3.0343017946442714
Validation loss: 2.7739770240008146

Epoch: 5| Step: 10
Training loss: 3.3145427523146216
Validation loss: 2.776375466508544

Epoch: 102| Step: 0
Training loss: 2.5895167355759887
Validation loss: 2.7755310882556317

Epoch: 5| Step: 1
Training loss: 3.601183294163748
Validation loss: 2.7734447469332095

Epoch: 5| Step: 2
Training loss: 3.4629715911642904
Validation loss: 2.7762644734777124

Epoch: 5| Step: 3
Training loss: 2.9699442820347848
Validation loss: 2.773726371754668

Epoch: 5| Step: 4
Training loss: 2.6588641598345863
Validation loss: 2.7715969034375982

Epoch: 5| Step: 5
Training loss: 2.7136624846893813
Validation loss: 2.7733197735057775

Epoch: 5| Step: 6
Training loss: 2.9149849175771303
Validation loss: 2.774481127755675

Epoch: 5| Step: 7
Training loss: 2.7852735240584185
Validation loss: 2.7734975805712003

Epoch: 5| Step: 8
Training loss: 3.4451412928248466
Validation loss: 2.770083751101671

Epoch: 5| Step: 9
Training loss: 3.2943504756100777
Validation loss: 2.7708861032722902

Epoch: 5| Step: 10
Training loss: 3.3966399250968182
Validation loss: 2.769187466799774

Epoch: 103| Step: 0
Training loss: 3.04149822308678
Validation loss: 2.7764369368669817

Epoch: 5| Step: 1
Training loss: 3.1420589987923666
Validation loss: 2.7736343371711336

Epoch: 5| Step: 2
Training loss: 3.3541977843426674
Validation loss: 2.774067376361367

Epoch: 5| Step: 3
Training loss: 3.327436922250761
Validation loss: 2.7730228625408193

Epoch: 5| Step: 4
Training loss: 2.9449598672978747
Validation loss: 2.770472919846243

Epoch: 5| Step: 5
Training loss: 2.612756878940972
Validation loss: 2.771621642542459

Epoch: 5| Step: 6
Training loss: 3.1103175282674838
Validation loss: 2.772210133379102

Epoch: 5| Step: 7
Training loss: 2.6523797056657146
Validation loss: 2.7729370081555853

Epoch: 5| Step: 8
Training loss: 2.833132699332809
Validation loss: 2.7718409420093195

Epoch: 5| Step: 9
Training loss: 3.5529538129300198
Validation loss: 2.768969651479828

Epoch: 5| Step: 10
Training loss: 3.267142641333304
Validation loss: 2.779859535630041

Epoch: 104| Step: 0
Training loss: 3.166517120310227
Validation loss: 2.77154200969615

Epoch: 5| Step: 1
Training loss: 2.8659968177580755
Validation loss: 2.770308790411541

Epoch: 5| Step: 2
Training loss: 3.0781500955710817
Validation loss: 2.771075613226966

Epoch: 5| Step: 3
Training loss: 3.0931765863013654
Validation loss: 2.772454129068934

Epoch: 5| Step: 4
Training loss: 3.39415476371638
Validation loss: 2.7695305418710205

Epoch: 5| Step: 5
Training loss: 3.39010770868556
Validation loss: 2.769465321952936

Epoch: 5| Step: 6
Training loss: 3.043634500994982
Validation loss: 2.7697729363405714

Epoch: 5| Step: 7
Training loss: 2.885216844894926
Validation loss: 2.7766794605898677

Epoch: 5| Step: 8
Training loss: 2.8238062471594225
Validation loss: 2.7853269184306915

Epoch: 5| Step: 9
Training loss: 3.207809372429826
Validation loss: 2.79598281571018

Epoch: 5| Step: 10
Training loss: 2.9368511051391972
Validation loss: 2.803444630772167

Epoch: 105| Step: 0
Training loss: 3.1192586419047807
Validation loss: 2.7750157447182775

Epoch: 5| Step: 1
Training loss: 2.8405624802427067
Validation loss: 2.7696506703540176

Epoch: 5| Step: 2
Training loss: 2.824919258921835
Validation loss: 2.768644141779996

Epoch: 5| Step: 3
Training loss: 3.1871191058996255
Validation loss: 2.7703041328750926

Epoch: 5| Step: 4
Training loss: 3.1056275141216996
Validation loss: 2.7689915198858848

Epoch: 5| Step: 5
Training loss: 3.2267349603482303
Validation loss: 2.7761629801467467

Epoch: 5| Step: 6
Training loss: 3.193653375466629
Validation loss: 2.7730700001968085

Epoch: 5| Step: 7
Training loss: 3.2362591696410745
Validation loss: 2.769851385361792

Epoch: 5| Step: 8
Training loss: 2.463603098925317
Validation loss: 2.773807318995966

Epoch: 5| Step: 9
Training loss: 3.5669994383208077
Validation loss: 2.7633643663044474

Epoch: 5| Step: 10
Training loss: 2.976794296410501
Validation loss: 2.7644641243467656

Epoch: 106| Step: 0
Training loss: 3.5702502622960206
Validation loss: 2.768577388859821

Epoch: 5| Step: 1
Training loss: 2.8071609683684944
Validation loss: 2.7663980762333726

Epoch: 5| Step: 2
Training loss: 3.4376180455139664
Validation loss: 2.76503711123012

Epoch: 5| Step: 3
Training loss: 3.2053049996351417
Validation loss: 2.766926159891726

Epoch: 5| Step: 4
Training loss: 3.0173979770255386
Validation loss: 2.7650532030276644

Epoch: 5| Step: 5
Training loss: 3.468458421154116
Validation loss: 2.764158039327803

Epoch: 5| Step: 6
Training loss: 2.9566188912758964
Validation loss: 2.766661682178778

Epoch: 5| Step: 7
Training loss: 2.8372507128673026
Validation loss: 2.7647192577097197

Epoch: 5| Step: 8
Training loss: 2.6959328642389977
Validation loss: 2.7654658436828146

Epoch: 5| Step: 9
Training loss: 3.004617634088437
Validation loss: 2.7637967698798307

Epoch: 5| Step: 10
Training loss: 2.765156334429033
Validation loss: 2.7661665714155905

Epoch: 107| Step: 0
Training loss: 3.16886962424057
Validation loss: 2.768790661990952

Epoch: 5| Step: 1
Training loss: 3.082869847146616
Validation loss: 2.773232209809886

Epoch: 5| Step: 2
Training loss: 2.9269521735910304
Validation loss: 2.76777242229653

Epoch: 5| Step: 3
Training loss: 2.4674905389142525
Validation loss: 2.7779212176980272

Epoch: 5| Step: 4
Training loss: 3.5863580727207154
Validation loss: 2.779079344659925

Epoch: 5| Step: 5
Training loss: 2.871482521775776
Validation loss: 2.7780590392499414

Epoch: 5| Step: 6
Training loss: 2.562521027269387
Validation loss: 2.7700859583564075

Epoch: 5| Step: 7
Training loss: 3.4117908733091777
Validation loss: 2.7735004570999475

Epoch: 5| Step: 8
Training loss: 3.1334934017878275
Validation loss: 2.772779886776181

Epoch: 5| Step: 9
Training loss: 2.682636029011008
Validation loss: 2.7667577097215332

Epoch: 5| Step: 10
Training loss: 3.8449489305376194
Validation loss: 2.7683508345414793

Epoch: 108| Step: 0
Training loss: 3.4139034138153153
Validation loss: 2.7637365331521253

Epoch: 5| Step: 1
Training loss: 3.0035417630788146
Validation loss: 2.7633181949292203

Epoch: 5| Step: 2
Training loss: 3.0953534527476054
Validation loss: 2.764327518744345

Epoch: 5| Step: 3
Training loss: 3.323352239077355
Validation loss: 2.7618601712718482

Epoch: 5| Step: 4
Training loss: 2.9009030284434068
Validation loss: 2.7634894643292434

Epoch: 5| Step: 5
Training loss: 2.7387788023972828
Validation loss: 2.761253056243804

Epoch: 5| Step: 6
Training loss: 3.371330526972211
Validation loss: 2.761042160025581

Epoch: 5| Step: 7
Training loss: 2.2512526733789238
Validation loss: 2.7617435302495217

Epoch: 5| Step: 8
Training loss: 3.2063118317053614
Validation loss: 2.762205165277906

Epoch: 5| Step: 9
Training loss: 3.4544734479618366
Validation loss: 2.759323930681787

Epoch: 5| Step: 10
Training loss: 2.8409794316686896
Validation loss: 2.7579244856832044

Epoch: 109| Step: 0
Training loss: 2.805822031398482
Validation loss: 2.7608007503191754

Epoch: 5| Step: 1
Training loss: 2.9182690896094754
Validation loss: 2.7606271735871446

Epoch: 5| Step: 2
Training loss: 2.8207712407981296
Validation loss: 2.7605763075567045

Epoch: 5| Step: 3
Training loss: 3.745934507865726
Validation loss: 2.7574405748796695

Epoch: 5| Step: 4
Training loss: 3.0869543790371825
Validation loss: 2.7632483055408135

Epoch: 5| Step: 5
Training loss: 2.6513801363634073
Validation loss: 2.768651745714236

Epoch: 5| Step: 6
Training loss: 2.8778234798119624
Validation loss: 2.7693143272784915

Epoch: 5| Step: 7
Training loss: 3.606206783253898
Validation loss: 2.777794149480449

Epoch: 5| Step: 8
Training loss: 3.025164443661509
Validation loss: 2.7731245512246225

Epoch: 5| Step: 9
Training loss: 3.193449115950425
Validation loss: 2.7689052951473756

Epoch: 5| Step: 10
Training loss: 2.9649167661257727
Validation loss: 2.7603966614518187

Epoch: 110| Step: 0
Training loss: 2.9356037268904345
Validation loss: 2.7653942305027894

Epoch: 5| Step: 1
Training loss: 3.018912623351196
Validation loss: 2.7638263511525465

Epoch: 5| Step: 2
Training loss: 3.552781887481224
Validation loss: 2.756631955422021

Epoch: 5| Step: 3
Training loss: 2.9255654595405383
Validation loss: 2.7578447417829475

Epoch: 5| Step: 4
Training loss: 3.4604152862405213
Validation loss: 2.7537628264480816

Epoch: 5| Step: 5
Training loss: 2.6656266707742695
Validation loss: 2.7603884143896598

Epoch: 5| Step: 6
Training loss: 3.079828400971579
Validation loss: 2.756875392851217

Epoch: 5| Step: 7
Training loss: 2.6694120242606485
Validation loss: 2.754954401139171

Epoch: 5| Step: 8
Training loss: 3.0636003035755754
Validation loss: 2.756225428600651

Epoch: 5| Step: 9
Training loss: 3.090678067421916
Validation loss: 2.7537165890439272

Epoch: 5| Step: 10
Training loss: 3.254787147230875
Validation loss: 2.756280448804357

Epoch: 111| Step: 0
Training loss: 3.3789501385787664
Validation loss: 2.7579857444920357

Epoch: 5| Step: 1
Training loss: 3.4660612115578147
Validation loss: 2.7559522236377054

Epoch: 5| Step: 2
Training loss: 2.8575773998601344
Validation loss: 2.7552026773062797

Epoch: 5| Step: 3
Training loss: 3.513404653670996
Validation loss: 2.756151641540954

Epoch: 5| Step: 4
Training loss: 3.0941510181423415
Validation loss: 2.7552451325835827

Epoch: 5| Step: 5
Training loss: 2.943193153796019
Validation loss: 2.7594263462328716

Epoch: 5| Step: 6
Training loss: 3.0790015197432985
Validation loss: 2.7514695746387723

Epoch: 5| Step: 7
Training loss: 2.7582346131175566
Validation loss: 2.756328841939161

Epoch: 5| Step: 8
Training loss: 2.861608414706004
Validation loss: 2.75825895994786

Epoch: 5| Step: 9
Training loss: 3.0023732335044824
Validation loss: 2.758407786487577

Epoch: 5| Step: 10
Training loss: 2.7010450354066067
Validation loss: 2.7577738008105266

Epoch: 112| Step: 0
Training loss: 2.8933168816281856
Validation loss: 2.7536889836420295

Epoch: 5| Step: 1
Training loss: 2.566122053833784
Validation loss: 2.757462112630135

Epoch: 5| Step: 2
Training loss: 3.096810570594211
Validation loss: 2.7555823137528046

Epoch: 5| Step: 3
Training loss: 2.6894084452988043
Validation loss: 2.7537630089160645

Epoch: 5| Step: 4
Training loss: 2.8745445222377666
Validation loss: 2.7560315590607183

Epoch: 5| Step: 5
Training loss: 3.13068087158793
Validation loss: 2.759828547497669

Epoch: 5| Step: 6
Training loss: 3.2390564288658883
Validation loss: 2.7607328429261053

Epoch: 5| Step: 7
Training loss: 3.5881416677364597
Validation loss: 2.7593418089658055

Epoch: 5| Step: 8
Training loss: 3.1908391777882352
Validation loss: 2.7621724161255132

Epoch: 5| Step: 9
Training loss: 2.909348343707604
Validation loss: 2.755009764039922

Epoch: 5| Step: 10
Training loss: 3.5364341828650407
Validation loss: 2.757038002007171

Epoch: 113| Step: 0
Training loss: 2.8421735481142063
Validation loss: 2.759742371821483

Epoch: 5| Step: 1
Training loss: 2.647023141221541
Validation loss: 2.753627511938336

Epoch: 5| Step: 2
Training loss: 2.549628892709594
Validation loss: 2.757356569909079

Epoch: 5| Step: 3
Training loss: 3.4542621103927424
Validation loss: 2.75635744027334

Epoch: 5| Step: 4
Training loss: 2.6680962684283562
Validation loss: 2.758473550372617

Epoch: 5| Step: 5
Training loss: 2.9400524656324394
Validation loss: 2.767113066221382

Epoch: 5| Step: 6
Training loss: 3.513824951501557
Validation loss: 2.76894640152695

Epoch: 5| Step: 7
Training loss: 3.987303252433614
Validation loss: 2.773368203942363

Epoch: 5| Step: 8
Training loss: 2.848395273938763
Validation loss: 2.7722114326724725

Epoch: 5| Step: 9
Training loss: 3.3384054377350902
Validation loss: 2.7572413608431

Epoch: 5| Step: 10
Training loss: 2.6420650731287774
Validation loss: 2.754277585699788

Epoch: 114| Step: 0
Training loss: 3.5215004885152
Validation loss: 2.750464833594912

Epoch: 5| Step: 1
Training loss: 2.928974034218713
Validation loss: 2.7562083681521194

Epoch: 5| Step: 2
Training loss: 2.8493846362821844
Validation loss: 2.7505594693114443

Epoch: 5| Step: 3
Training loss: 2.67025064984919
Validation loss: 2.751359901647471

Epoch: 5| Step: 4
Training loss: 2.4604833759133085
Validation loss: 2.7543243777326425

Epoch: 5| Step: 5
Training loss: 3.2373086644489146
Validation loss: 2.7481254152848904

Epoch: 5| Step: 6
Training loss: 3.299472743597405
Validation loss: 2.7507178487405426

Epoch: 5| Step: 7
Training loss: 3.031154670396128
Validation loss: 2.7503287714537024

Epoch: 5| Step: 8
Training loss: 3.443422244445203
Validation loss: 2.7489176603116787

Epoch: 5| Step: 9
Training loss: 3.125293260165537
Validation loss: 2.7522110091241787

Epoch: 5| Step: 10
Training loss: 3.086804695448716
Validation loss: 2.7498328716545637

Epoch: 115| Step: 0
Training loss: 3.2724173692918166
Validation loss: 2.7541364117618508

Epoch: 5| Step: 1
Training loss: 3.4670806166895676
Validation loss: 2.7488888628714525

Epoch: 5| Step: 2
Training loss: 2.803252466678172
Validation loss: 2.7483616504396777

Epoch: 5| Step: 3
Training loss: 2.839688933086569
Validation loss: 2.7515264434314495

Epoch: 5| Step: 4
Training loss: 3.3897926258136364
Validation loss: 2.7478825498689337

Epoch: 5| Step: 5
Training loss: 3.310225227506994
Validation loss: 2.754950849202845

Epoch: 5| Step: 6
Training loss: 2.9704260662427955
Validation loss: 2.7561407633889874

Epoch: 5| Step: 7
Training loss: 2.909392268112187
Validation loss: 2.750651612368813

Epoch: 5| Step: 8
Training loss: 2.83479963021753
Validation loss: 2.7563708799369806

Epoch: 5| Step: 9
Training loss: 2.580476001032898
Validation loss: 2.752401762993619

Epoch: 5| Step: 10
Training loss: 3.2505879970645553
Validation loss: 2.7531724391856645

Epoch: 116| Step: 0
Training loss: 2.8144356742280814
Validation loss: 2.750458066719116

Epoch: 5| Step: 1
Training loss: 3.097830191463309
Validation loss: 2.7547231649026562

Epoch: 5| Step: 2
Training loss: 3.360391152638405
Validation loss: 2.7498440171543512

Epoch: 5| Step: 3
Training loss: 3.0428462071161486
Validation loss: 2.75048659374134

Epoch: 5| Step: 4
Training loss: 2.7542774572514364
Validation loss: 2.7521075649458004

Epoch: 5| Step: 5
Training loss: 3.159730559583757
Validation loss: 2.7484353593455357

Epoch: 5| Step: 6
Training loss: 3.1728475047584856
Validation loss: 2.7459591723001426

Epoch: 5| Step: 7
Training loss: 3.1668032231919536
Validation loss: 2.7452382040505507

Epoch: 5| Step: 8
Training loss: 2.989294820193166
Validation loss: 2.744869103983294

Epoch: 5| Step: 9
Training loss: 3.2069203291376795
Validation loss: 2.753237043153641

Epoch: 5| Step: 10
Training loss: 2.870794952829938
Validation loss: 2.7493830293591395

Epoch: 117| Step: 0
Training loss: 2.776465425957191
Validation loss: 2.747757363610049

Epoch: 5| Step: 1
Training loss: 2.544689996421364
Validation loss: 2.7498294883734613

Epoch: 5| Step: 2
Training loss: 3.149650548291823
Validation loss: 2.7486723597102984

Epoch: 5| Step: 3
Training loss: 3.330150578848893
Validation loss: 2.746786930921137

Epoch: 5| Step: 4
Training loss: 3.0134084194528294
Validation loss: 2.747547773483151

Epoch: 5| Step: 5
Training loss: 2.8517902440090497
Validation loss: 2.7494076662353626

Epoch: 5| Step: 6
Training loss: 3.245655089851704
Validation loss: 2.7420390346899026

Epoch: 5| Step: 7
Training loss: 3.035748319675496
Validation loss: 2.742314483018184

Epoch: 5| Step: 8
Training loss: 3.2588190586628913
Validation loss: 2.7456958737901127

Epoch: 5| Step: 9
Training loss: 2.9195127679016784
Validation loss: 2.750533655317959

Epoch: 5| Step: 10
Training loss: 3.520514042990326
Validation loss: 2.7448113505304907

Epoch: 118| Step: 0
Training loss: 3.734675311538767
Validation loss: 2.744628173481959

Epoch: 5| Step: 1
Training loss: 3.412191266636779
Validation loss: 2.7462407890801375

Epoch: 5| Step: 2
Training loss: 2.8502383149209227
Validation loss: 2.749817213805863

Epoch: 5| Step: 3
Training loss: 3.2873667062635703
Validation loss: 2.744125737174056

Epoch: 5| Step: 4
Training loss: 2.6105780654863655
Validation loss: 2.7438370061216286

Epoch: 5| Step: 5
Training loss: 3.3214396639168444
Validation loss: 2.7402913291401805

Epoch: 5| Step: 6
Training loss: 2.7932234641282534
Validation loss: 2.738135569897114

Epoch: 5| Step: 7
Training loss: 3.1492108703832673
Validation loss: 2.739748780674344

Epoch: 5| Step: 8
Training loss: 2.313237665417045
Validation loss: 2.7370610754911993

Epoch: 5| Step: 9
Training loss: 2.435623914147209
Validation loss: 2.741624541871818

Epoch: 5| Step: 10
Training loss: 3.4444383822835536
Validation loss: 2.736460756478753

Epoch: 119| Step: 0
Training loss: 3.3246533550176736
Validation loss: 2.738074821064079

Epoch: 5| Step: 1
Training loss: 3.6013856128606294
Validation loss: 2.74118153349661

Epoch: 5| Step: 2
Training loss: 2.995856602719432
Validation loss: 2.73866896801149

Epoch: 5| Step: 3
Training loss: 2.7655298248983584
Validation loss: 2.7396850779153774

Epoch: 5| Step: 4
Training loss: 3.076822227879384
Validation loss: 2.7385233352138645

Epoch: 5| Step: 5
Training loss: 3.252520244280291
Validation loss: 2.737401816056621

Epoch: 5| Step: 6
Training loss: 2.9037922957678033
Validation loss: 2.7378131867296025

Epoch: 5| Step: 7
Training loss: 2.394414354367855
Validation loss: 2.7375587082487747

Epoch: 5| Step: 8
Training loss: 2.7387968222839096
Validation loss: 2.742497854331129

Epoch: 5| Step: 9
Training loss: 3.232916166654
Validation loss: 2.7480950455712

Epoch: 5| Step: 10
Training loss: 3.163427821424074
Validation loss: 2.742492983172089

Epoch: 120| Step: 0
Training loss: 2.2949742347750335
Validation loss: 2.74088356034177

Epoch: 5| Step: 1
Training loss: 3.4352599734969482
Validation loss: 2.7461151097476857

Epoch: 5| Step: 2
Training loss: 3.2858321393835026
Validation loss: 2.748133169279953

Epoch: 5| Step: 3
Training loss: 2.8198374509294513
Validation loss: 2.739520250281394

Epoch: 5| Step: 4
Training loss: 3.288966669059312
Validation loss: 2.7393995454445217

Epoch: 5| Step: 5
Training loss: 2.6971411652132504
Validation loss: 2.7370821704139296

Epoch: 5| Step: 6
Training loss: 2.865269989021166
Validation loss: 2.736463614792535

Epoch: 5| Step: 7
Training loss: 2.652525950312973
Validation loss: 2.739431399393231

Epoch: 5| Step: 8
Training loss: 3.19097337156618
Validation loss: 2.735084179677979

Epoch: 5| Step: 9
Training loss: 3.5714654375625843
Validation loss: 2.7377196030529274

Epoch: 5| Step: 10
Training loss: 3.2675226711896403
Validation loss: 2.732561692111856

Epoch: 121| Step: 0
Training loss: 3.415160956101352
Validation loss: 2.7341770176621365

Epoch: 5| Step: 1
Training loss: 3.2977919907819127
Validation loss: 2.734912732481482

Epoch: 5| Step: 2
Training loss: 2.4042949908920828
Validation loss: 2.732775750627807

Epoch: 5| Step: 3
Training loss: 2.9132204859138864
Validation loss: 2.733436097475044

Epoch: 5| Step: 4
Training loss: 2.8704240290321765
Validation loss: 2.737160403414559

Epoch: 5| Step: 5
Training loss: 3.4281836755924604
Validation loss: 2.732355235451452

Epoch: 5| Step: 6
Training loss: 2.6783478616329544
Validation loss: 2.7340823306074644

Epoch: 5| Step: 7
Training loss: 3.1428130010502238
Validation loss: 2.735002856854393

Epoch: 5| Step: 8
Training loss: 3.2964714490318623
Validation loss: 2.7365395431047363

Epoch: 5| Step: 9
Training loss: 2.5572804582172797
Validation loss: 2.7351573419077106

Epoch: 5| Step: 10
Training loss: 3.4350591143056644
Validation loss: 2.734390429381451

Epoch: 122| Step: 0
Training loss: 3.533248740809046
Validation loss: 2.734623033375383

Epoch: 5| Step: 1
Training loss: 3.1307481923294973
Validation loss: 2.7386288632820013

Epoch: 5| Step: 2
Training loss: 2.899083972821368
Validation loss: 2.733848968864073

Epoch: 5| Step: 3
Training loss: 2.8528352588218358
Validation loss: 2.733888988518363

Epoch: 5| Step: 4
Training loss: 2.896203179835061
Validation loss: 2.7305110988143393

Epoch: 5| Step: 5
Training loss: 2.8612309670471467
Validation loss: 2.73521743196427

Epoch: 5| Step: 6
Training loss: 3.2659354176440294
Validation loss: 2.7354596318122755

Epoch: 5| Step: 7
Training loss: 2.709890905626636
Validation loss: 2.7391004654243196

Epoch: 5| Step: 8
Training loss: 2.431965045658939
Validation loss: 2.7372306835472533

Epoch: 5| Step: 9
Training loss: 3.3143670920073194
Validation loss: 2.732893724628167

Epoch: 5| Step: 10
Training loss: 3.5414944475974095
Validation loss: 2.7338883161682532

Epoch: 123| Step: 0
Training loss: 3.124920042922411
Validation loss: 2.7334792790990528

Epoch: 5| Step: 1
Training loss: 2.7657187925479922
Validation loss: 2.734869428195147

Epoch: 5| Step: 2
Training loss: 2.9081004824692176
Validation loss: 2.7344434541492575

Epoch: 5| Step: 3
Training loss: 2.7860862602358702
Validation loss: 2.7353849518840585

Epoch: 5| Step: 4
Training loss: 3.3675439207842035
Validation loss: 2.733571933183717

Epoch: 5| Step: 5
Training loss: 3.0683310912326274
Validation loss: 2.730990628781824

Epoch: 5| Step: 6
Training loss: 3.147866019736299
Validation loss: 2.7315979706233047

Epoch: 5| Step: 7
Training loss: 2.7793860886946415
Validation loss: 2.73789147094144

Epoch: 5| Step: 8
Training loss: 3.51294534921201
Validation loss: 2.741152616438853

Epoch: 5| Step: 9
Training loss: 2.799774797783644
Validation loss: 2.7353242103806594

Epoch: 5| Step: 10
Training loss: 3.1648358188850882
Validation loss: 2.738294171713051

Epoch: 124| Step: 0
Training loss: 3.2748193123163776
Validation loss: 2.733882260321179

Epoch: 5| Step: 1
Training loss: 3.0345266663728996
Validation loss: 2.7307504058606056

Epoch: 5| Step: 2
Training loss: 3.0374858463412853
Validation loss: 2.731966354430428

Epoch: 5| Step: 3
Training loss: 3.525050434806874
Validation loss: 2.735307527552972

Epoch: 5| Step: 4
Training loss: 3.176937329215389
Validation loss: 2.7292591152268684

Epoch: 5| Step: 5
Training loss: 1.9617974572778807
Validation loss: 2.7275714957738866

Epoch: 5| Step: 6
Training loss: 3.099148134889216
Validation loss: 2.729489774598533

Epoch: 5| Step: 7
Training loss: 2.3955133860259257
Validation loss: 2.7278273382729674

Epoch: 5| Step: 8
Training loss: 2.8936491122692334
Validation loss: 2.7287244409505234

Epoch: 5| Step: 9
Training loss: 3.169673663168094
Validation loss: 2.7299072828177766

Epoch: 5| Step: 10
Training loss: 3.6840014914676327
Validation loss: 2.730612242269549

Epoch: 125| Step: 0
Training loss: 2.5139685443133284
Validation loss: 2.7270417823378263

Epoch: 5| Step: 1
Training loss: 2.912217443291575
Validation loss: 2.7293983992959876

Epoch: 5| Step: 2
Training loss: 3.7618448745324926
Validation loss: 2.7299223101649677

Epoch: 5| Step: 3
Training loss: 3.06663887453616
Validation loss: 2.7277327823048774

Epoch: 5| Step: 4
Training loss: 3.0929851164436584
Validation loss: 2.727864475569871

Epoch: 5| Step: 5
Training loss: 2.358801462555125
Validation loss: 2.7264077460910983

Epoch: 5| Step: 6
Training loss: 3.40931507760736
Validation loss: 2.724837386235469

Epoch: 5| Step: 7
Training loss: 3.4609472821444007
Validation loss: 2.725037556126316

Epoch: 5| Step: 8
Training loss: 2.587271262853095
Validation loss: 2.7271601604301865

Epoch: 5| Step: 9
Training loss: 2.779960419078053
Validation loss: 2.726095971868955

Epoch: 5| Step: 10
Training loss: 3.301180085233031
Validation loss: 2.729566318608085

Epoch: 126| Step: 0
Training loss: 3.196059459128409
Validation loss: 2.728586065785829

Epoch: 5| Step: 1
Training loss: 2.748403606021466
Validation loss: 2.724997650142461

Epoch: 5| Step: 2
Training loss: 2.770754609865923
Validation loss: 2.725951715210095

Epoch: 5| Step: 3
Training loss: 3.053541197663001
Validation loss: 2.72412881490448

Epoch: 5| Step: 4
Training loss: 3.8115243132285057
Validation loss: 2.7308488358557246

Epoch: 5| Step: 5
Training loss: 2.726338899292002
Validation loss: 2.727904644105467

Epoch: 5| Step: 6
Training loss: 2.820870214885129
Validation loss: 2.730932127946906

Epoch: 5| Step: 7
Training loss: 3.233321308493785
Validation loss: 2.733230252752053

Epoch: 5| Step: 8
Training loss: 3.051384195879676
Validation loss: 2.7235488001804002

Epoch: 5| Step: 9
Training loss: 2.9175833941703324
Validation loss: 2.7250361148623297

Epoch: 5| Step: 10
Training loss: 3.0566841488015517
Validation loss: 2.7265068048745897

Epoch: 127| Step: 0
Training loss: 2.786269127432269
Validation loss: 2.7232843986996107

Epoch: 5| Step: 1
Training loss: 2.6211787066498964
Validation loss: 2.725914380688609

Epoch: 5| Step: 2
Training loss: 3.1756286959822764
Validation loss: 2.7284171033154347

Epoch: 5| Step: 3
Training loss: 3.053998083967146
Validation loss: 2.7314422706071646

Epoch: 5| Step: 4
Training loss: 2.86239997655699
Validation loss: 2.727276762424565

Epoch: 5| Step: 5
Training loss: 3.3818211325206544
Validation loss: 2.7274118427445733

Epoch: 5| Step: 6
Training loss: 3.252136408592477
Validation loss: 2.7259522042477413

Epoch: 5| Step: 7
Training loss: 3.2610887478681363
Validation loss: 2.7257697946426154

Epoch: 5| Step: 8
Training loss: 3.1039657698444763
Validation loss: 2.730112609025262

Epoch: 5| Step: 9
Training loss: 3.0497454302500486
Validation loss: 2.7294498153627145

Epoch: 5| Step: 10
Training loss: 2.793506063782116
Validation loss: 2.726314842888834

Epoch: 128| Step: 0
Training loss: 3.56463732935848
Validation loss: 2.7267344759896974

Epoch: 5| Step: 1
Training loss: 2.560720896099563
Validation loss: 2.7294181877538146

Epoch: 5| Step: 2
Training loss: 2.333996837375201
Validation loss: 2.7298199935370606

Epoch: 5| Step: 3
Training loss: 3.3767489387554033
Validation loss: 2.7289566288614546

Epoch: 5| Step: 4
Training loss: 3.1086360494224077
Validation loss: 2.729202917165572

Epoch: 5| Step: 5
Training loss: 3.4216413026201895
Validation loss: 2.726202392868097

Epoch: 5| Step: 6
Training loss: 2.6987167311115656
Validation loss: 2.7228895899425973

Epoch: 5| Step: 7
Training loss: 2.8698134701287676
Validation loss: 2.7235450623278057

Epoch: 5| Step: 8
Training loss: 2.9968173310873922
Validation loss: 2.7204428044290814

Epoch: 5| Step: 9
Training loss: 3.301891397539819
Validation loss: 2.7203001224403764

Epoch: 5| Step: 10
Training loss: 2.9757913706981185
Validation loss: 2.720884909456079

Epoch: 129| Step: 0
Training loss: 3.652473651391463
Validation loss: 2.721176075847421

Epoch: 5| Step: 1
Training loss: 3.7566522722439544
Validation loss: 2.7203302992141793

Epoch: 5| Step: 2
Training loss: 2.7764299609011043
Validation loss: 2.7207993499342655

Epoch: 5| Step: 3
Training loss: 3.1921128946288326
Validation loss: 2.72041824826158

Epoch: 5| Step: 4
Training loss: 3.298846048833781
Validation loss: 2.7213258432801517

Epoch: 5| Step: 5
Training loss: 2.77813795191832
Validation loss: 2.718290006945504

Epoch: 5| Step: 6
Training loss: 3.3980993343785157
Validation loss: 2.72393677945167

Epoch: 5| Step: 7
Training loss: 2.873999048220929
Validation loss: 2.720619702081796

Epoch: 5| Step: 8
Training loss: 2.4094265864251425
Validation loss: 2.72278982898119

Epoch: 5| Step: 9
Training loss: 2.303688065373688
Validation loss: 2.72197464357106

Epoch: 5| Step: 10
Training loss: 2.55544407458566
Validation loss: 2.723481199885973

Epoch: 130| Step: 0
Training loss: 2.799695516107092
Validation loss: 2.724971166877579

Epoch: 5| Step: 1
Training loss: 2.7175058609408826
Validation loss: 2.720405488541404

Epoch: 5| Step: 2
Training loss: 3.237084474740572
Validation loss: 2.722950333911878

Epoch: 5| Step: 3
Training loss: 2.436234365680257
Validation loss: 2.7283829060933384

Epoch: 5| Step: 4
Training loss: 3.04517743675765
Validation loss: 2.7306153198245156

Epoch: 5| Step: 5
Training loss: 3.0167597873990837
Validation loss: 2.7265410848633884

Epoch: 5| Step: 6
Training loss: 3.3931442254014197
Validation loss: 2.7224060264694825

Epoch: 5| Step: 7
Training loss: 3.2048177572679237
Validation loss: 2.7211296125886117

Epoch: 5| Step: 8
Training loss: 3.7748743958450772
Validation loss: 2.7221707483659383

Epoch: 5| Step: 9
Training loss: 2.7854173278427385
Validation loss: 2.715883583881428

Epoch: 5| Step: 10
Training loss: 2.8587165449592633
Validation loss: 2.7181574187814928

Epoch: 131| Step: 0
Training loss: 3.5070026371894016
Validation loss: 2.718716504384871

Epoch: 5| Step: 1
Training loss: 2.858490353674607
Validation loss: 2.719116257931248

Epoch: 5| Step: 2
Training loss: 2.919898359019018
Validation loss: 2.7184881099042637

Epoch: 5| Step: 3
Training loss: 3.309309520559939
Validation loss: 2.719532792747681

Epoch: 5| Step: 4
Training loss: 2.886313527408867
Validation loss: 2.7216742393525397

Epoch: 5| Step: 5
Training loss: 3.264013741632594
Validation loss: 2.7206141448603742

Epoch: 5| Step: 6
Training loss: 3.288135533855237
Validation loss: 2.726681959451974

Epoch: 5| Step: 7
Training loss: 2.5626701670644922
Validation loss: 2.720513250695291

Epoch: 5| Step: 8
Training loss: 2.867038483866017
Validation loss: 2.722594797965072

Epoch: 5| Step: 9
Training loss: 2.969625885902411
Validation loss: 2.7171919482144835

Epoch: 5| Step: 10
Training loss: 3.0655818146785436
Validation loss: 2.719685442726269

Epoch: 132| Step: 0
Training loss: 2.587287665606515
Validation loss: 2.7183100026445284

Epoch: 5| Step: 1
Training loss: 2.976992758744992
Validation loss: 2.7202029845241262

Epoch: 5| Step: 2
Training loss: 3.240743366018372
Validation loss: 2.7304219754148265

Epoch: 5| Step: 3
Training loss: 3.1998552706891186
Validation loss: 2.7341412938060445

Epoch: 5| Step: 4
Training loss: 3.081516469455563
Validation loss: 2.7354942541388283

Epoch: 5| Step: 5
Training loss: 3.2692388223747386
Validation loss: 2.7388926099710496

Epoch: 5| Step: 6
Training loss: 3.0417702191288223
Validation loss: 2.7209569111276397

Epoch: 5| Step: 7
Training loss: 3.312374760401475
Validation loss: 2.7164084129503374

Epoch: 5| Step: 8
Training loss: 3.324994114461867
Validation loss: 2.7173420116524643

Epoch: 5| Step: 9
Training loss: 3.0383089597404123
Validation loss: 2.713415684807708

Epoch: 5| Step: 10
Training loss: 2.118360694070272
Validation loss: 2.7145673567313935

Epoch: 133| Step: 0
Training loss: 3.1264629754235593
Validation loss: 2.713201352254735

Epoch: 5| Step: 1
Training loss: 2.941768061661776
Validation loss: 2.714523162173664

Epoch: 5| Step: 2
Training loss: 3.044969324668376
Validation loss: 2.7167907697318068

Epoch: 5| Step: 3
Training loss: 3.22975602873142
Validation loss: 2.718117865450688

Epoch: 5| Step: 4
Training loss: 3.0578949228599943
Validation loss: 2.720762502524125

Epoch: 5| Step: 5
Training loss: 3.0123043455796346
Validation loss: 2.7240018471533327

Epoch: 5| Step: 6
Training loss: 2.726650641035943
Validation loss: 2.7290709371591078

Epoch: 5| Step: 7
Training loss: 3.0027369094625542
Validation loss: 2.7241959088345866

Epoch: 5| Step: 8
Training loss: 2.9501023743533104
Validation loss: 2.7278231655113827

Epoch: 5| Step: 9
Training loss: 2.986744843492968
Validation loss: 2.7189154239276405

Epoch: 5| Step: 10
Training loss: 3.398925886467909
Validation loss: 2.7210588817343195

Epoch: 134| Step: 0
Training loss: 3.099683062441296
Validation loss: 2.7193009842842235

Epoch: 5| Step: 1
Training loss: 2.922142465354759
Validation loss: 2.7146034628374767

Epoch: 5| Step: 2
Training loss: 3.03665120388523
Validation loss: 2.7191127600620972

Epoch: 5| Step: 3
Training loss: 2.9833659917937005
Validation loss: 2.716715755908701

Epoch: 5| Step: 4
Training loss: 2.8556779818713838
Validation loss: 2.71633812920701

Epoch: 5| Step: 5
Training loss: 2.8256081188214868
Validation loss: 2.719927358289178

Epoch: 5| Step: 6
Training loss: 2.5021397017059273
Validation loss: 2.718076568544704

Epoch: 5| Step: 7
Training loss: 3.2193574795091617
Validation loss: 2.7160998383895065

Epoch: 5| Step: 8
Training loss: 3.3588419646608703
Validation loss: 2.7159861253590645

Epoch: 5| Step: 9
Training loss: 3.1753587054575734
Validation loss: 2.715999610937097

Epoch: 5| Step: 10
Training loss: 3.354811722863418
Validation loss: 2.714195655585001

Epoch: 135| Step: 0
Training loss: 3.091805665900721
Validation loss: 2.7170231867623738

Epoch: 5| Step: 1
Training loss: 3.278808993682496
Validation loss: 2.7130803883377967

Epoch: 5| Step: 2
Training loss: 3.250847485891314
Validation loss: 2.7127781959285793

Epoch: 5| Step: 3
Training loss: 3.017364790699223
Validation loss: 2.713168481686323

Epoch: 5| Step: 4
Training loss: 3.2672777875833194
Validation loss: 2.7115790913605062

Epoch: 5| Step: 5
Training loss: 3.5233820130574154
Validation loss: 2.7133357916446403

Epoch: 5| Step: 6
Training loss: 3.2514829920113173
Validation loss: 2.7099871549970533

Epoch: 5| Step: 7
Training loss: 2.2361499698756027
Validation loss: 2.7108593745929737

Epoch: 5| Step: 8
Training loss: 2.6228929873592683
Validation loss: 2.7156417480067097

Epoch: 5| Step: 9
Training loss: 2.8173194283110528
Validation loss: 2.7104403387535156

Epoch: 5| Step: 10
Training loss: 2.7815455590411395
Validation loss: 2.7098659719205247

Epoch: 136| Step: 0
Training loss: 3.142118336178605
Validation loss: 2.714410319048409

Epoch: 5| Step: 1
Training loss: 2.912272130868508
Validation loss: 2.7131647229188225

Epoch: 5| Step: 2
Training loss: 3.260164066234939
Validation loss: 2.712102919604738

Epoch: 5| Step: 3
Training loss: 3.4731376322883296
Validation loss: 2.7165035027685267

Epoch: 5| Step: 4
Training loss: 3.1430924624740415
Validation loss: 2.7131065482883563

Epoch: 5| Step: 5
Training loss: 2.836730173687322
Validation loss: 2.709773528080045

Epoch: 5| Step: 6
Training loss: 2.719597607608219
Validation loss: 2.7104074971269507

Epoch: 5| Step: 7
Training loss: 2.951072019633455
Validation loss: 2.710540790686785

Epoch: 5| Step: 8
Training loss: 2.948605586093832
Validation loss: 2.7101893146558758

Epoch: 5| Step: 9
Training loss: 2.8753922236380727
Validation loss: 2.713397361727757

Epoch: 5| Step: 10
Training loss: 3.0258898978767
Validation loss: 2.7132614844839944

Epoch: 137| Step: 0
Training loss: 3.309085165413246
Validation loss: 2.7115456423632964

Epoch: 5| Step: 1
Training loss: 2.3313565963633143
Validation loss: 2.710441819937248

Epoch: 5| Step: 2
Training loss: 3.1103639803029197
Validation loss: 2.713703915842325

Epoch: 5| Step: 3
Training loss: 3.1653954982882464
Validation loss: 2.7152394397454023

Epoch: 5| Step: 4
Training loss: 3.2919425043992656
Validation loss: 2.7104433616538115

Epoch: 5| Step: 5
Training loss: 2.975837839579493
Validation loss: 2.709143517587336

Epoch: 5| Step: 6
Training loss: 2.761649944306207
Validation loss: 2.706621995904117

Epoch: 5| Step: 7
Training loss: 3.050067813307023
Validation loss: 2.707527416211146

Epoch: 5| Step: 8
Training loss: 3.233808384896522
Validation loss: 2.7063822480950557

Epoch: 5| Step: 9
Training loss: 2.8484326051302737
Validation loss: 2.708296934755645

Epoch: 5| Step: 10
Training loss: 3.1900102790977822
Validation loss: 2.709265574194377

Epoch: 138| Step: 0
Training loss: 3.0435011744377083
Validation loss: 2.7096153525379796

Epoch: 5| Step: 1
Training loss: 2.5273234677569567
Validation loss: 2.708890798541363

Epoch: 5| Step: 2
Training loss: 2.462808339909628
Validation loss: 2.7110338899921933

Epoch: 5| Step: 3
Training loss: 3.584828057628258
Validation loss: 2.7101064445279377

Epoch: 5| Step: 4
Training loss: 3.344129736897866
Validation loss: 2.711371172194328

Epoch: 5| Step: 5
Training loss: 2.7363557453381615
Validation loss: 2.7061357860709663

Epoch: 5| Step: 6
Training loss: 3.4581281915205597
Validation loss: 2.7077867393370547

Epoch: 5| Step: 7
Training loss: 2.9529446339905485
Validation loss: 2.7100819706515917

Epoch: 5| Step: 8
Training loss: 2.9961930597947957
Validation loss: 2.7052840042591675

Epoch: 5| Step: 9
Training loss: 2.9789921813944193
Validation loss: 2.70660858578845

Epoch: 5| Step: 10
Training loss: 3.05454388449162
Validation loss: 2.712383304953452

Epoch: 139| Step: 0
Training loss: 2.9890810625424176
Validation loss: 2.7102465596478202

Epoch: 5| Step: 1
Training loss: 2.71579362457671
Validation loss: 2.710860451737045

Epoch: 5| Step: 2
Training loss: 3.04535875985019
Validation loss: 2.7179420882282788

Epoch: 5| Step: 3
Training loss: 3.0585990506220035
Validation loss: 2.716271469760515

Epoch: 5| Step: 4
Training loss: 3.047372630636295
Validation loss: 2.724731228057816

Epoch: 5| Step: 5
Training loss: 2.980589377985692
Validation loss: 2.719417116295291

Epoch: 5| Step: 6
Training loss: 2.8221968592941677
Validation loss: 2.724702564988849

Epoch: 5| Step: 7
Training loss: 3.565367899526242
Validation loss: 2.7236646503590802

Epoch: 5| Step: 8
Training loss: 2.677371344801211
Validation loss: 2.7311531373546853

Epoch: 5| Step: 9
Training loss: 2.982133273067688
Validation loss: 2.723530509033163

Epoch: 5| Step: 10
Training loss: 3.4269313295428527
Validation loss: 2.710343667537379

Epoch: 140| Step: 0
Training loss: 3.061988476443144
Validation loss: 2.703599582645794

Epoch: 5| Step: 1
Training loss: 3.363856533352387
Validation loss: 2.704488669806703

Epoch: 5| Step: 2
Training loss: 3.292638868504074
Validation loss: 2.7062263515587004

Epoch: 5| Step: 3
Training loss: 2.6631324912276746
Validation loss: 2.7025668362060706

Epoch: 5| Step: 4
Training loss: 2.942479559633729
Validation loss: 2.7032941122441643

Epoch: 5| Step: 5
Training loss: 2.0393577157356955
Validation loss: 2.7082535958364593

Epoch: 5| Step: 6
Training loss: 3.5887418930084385
Validation loss: 2.7056515563397294

Epoch: 5| Step: 7
Training loss: 3.5795902100774777
Validation loss: 2.7100528489859546

Epoch: 5| Step: 8
Training loss: 2.5615252990366852
Validation loss: 2.703845121957122

Epoch: 5| Step: 9
Training loss: 3.194677313089011
Validation loss: 2.7037217141127483

Epoch: 5| Step: 10
Training loss: 2.7623435342934153
Validation loss: 2.705273982453059

Epoch: 141| Step: 0
Training loss: 2.9753032433608535
Validation loss: 2.701660303331522

Epoch: 5| Step: 1
Training loss: 3.1057541818020242
Validation loss: 2.7031199867590416

Epoch: 5| Step: 2
Training loss: 2.801095857068851
Validation loss: 2.7024346965767156

Epoch: 5| Step: 3
Training loss: 3.5813990110916083
Validation loss: 2.700556683283351

Epoch: 5| Step: 4
Training loss: 2.772914525543999
Validation loss: 2.7074882501448663

Epoch: 5| Step: 5
Training loss: 2.907704963314972
Validation loss: 2.712557140126737

Epoch: 5| Step: 6
Training loss: 3.127851024904572
Validation loss: 2.71215572033264

Epoch: 5| Step: 7
Training loss: 3.365237350595391
Validation loss: 2.7150125175611595

Epoch: 5| Step: 8
Training loss: 2.764291732882921
Validation loss: 2.720290776063677

Epoch: 5| Step: 9
Training loss: 2.8887403788255748
Validation loss: 2.7190659730368303

Epoch: 5| Step: 10
Training loss: 3.0413942781178935
Validation loss: 2.7216858628074823

Epoch: 142| Step: 0
Training loss: 2.788143743927884
Validation loss: 2.713513645309842

Epoch: 5| Step: 1
Training loss: 2.5038984420583215
Validation loss: 2.7065345722723064

Epoch: 5| Step: 2
Training loss: 3.550841277468059
Validation loss: 2.6993209871505206

Epoch: 5| Step: 3
Training loss: 3.0629076005260676
Validation loss: 2.698108329114582

Epoch: 5| Step: 4
Training loss: 2.7807138333371517
Validation loss: 2.7068074764300936

Epoch: 5| Step: 5
Training loss: 3.1242256731098275
Validation loss: 2.7015213964494156

Epoch: 5| Step: 6
Training loss: 3.185252425702223
Validation loss: 2.699644316591974

Epoch: 5| Step: 7
Training loss: 2.8144377073332913
Validation loss: 2.7050392873980647

Epoch: 5| Step: 8
Training loss: 2.926775245245463
Validation loss: 2.707152059960486

Epoch: 5| Step: 9
Training loss: 3.6055402986281733
Validation loss: 2.7141989368820463

Epoch: 5| Step: 10
Training loss: 2.7482360904840957
Validation loss: 2.7097094224347624

Epoch: 143| Step: 0
Training loss: 2.619600373723342
Validation loss: 2.7190804446295727

Epoch: 5| Step: 1
Training loss: 2.59232576172815
Validation loss: 2.712650599560775

Epoch: 5| Step: 2
Training loss: 2.5144020093149426
Validation loss: 2.738154286853771

Epoch: 5| Step: 3
Training loss: 3.6429036749210675
Validation loss: 2.732061097929673

Epoch: 5| Step: 4
Training loss: 2.9951504611271265
Validation loss: 2.7371021880545765

Epoch: 5| Step: 5
Training loss: 3.098152188290873
Validation loss: 2.7504375702540695

Epoch: 5| Step: 6
Training loss: 3.507684446176736
Validation loss: 2.754708207703081

Epoch: 5| Step: 7
Training loss: 3.071416370076122
Validation loss: 2.7465320452627364

Epoch: 5| Step: 8
Training loss: 3.2972244149850396
Validation loss: 2.741322209819527

Epoch: 5| Step: 9
Training loss: 2.90226981683676
Validation loss: 2.727428775956477

Epoch: 5| Step: 10
Training loss: 3.121499198770489
Validation loss: 2.7287285822698797

Epoch: 144| Step: 0
Training loss: 2.400273021427475
Validation loss: 2.715735448677086

Epoch: 5| Step: 1
Training loss: 3.352224858064184
Validation loss: 2.704907754760431

Epoch: 5| Step: 2
Training loss: 3.1893572912634687
Validation loss: 2.6936273134661723

Epoch: 5| Step: 3
Training loss: 2.645049502192553
Validation loss: 2.6982104515689227

Epoch: 5| Step: 4
Training loss: 3.025249086323597
Validation loss: 2.7000400462004563

Epoch: 5| Step: 5
Training loss: 3.4945742922783785
Validation loss: 2.7030560656991742

Epoch: 5| Step: 6
Training loss: 3.3201380066740924
Validation loss: 2.6990636991729553

Epoch: 5| Step: 7
Training loss: 3.296561709881322
Validation loss: 2.702216404493531

Epoch: 5| Step: 8
Training loss: 2.9681972591418595
Validation loss: 2.698354001378567

Epoch: 5| Step: 9
Training loss: 2.789086435252688
Validation loss: 2.700948891656103

Epoch: 5| Step: 10
Training loss: 2.6231532185372557
Validation loss: 2.7026769373526713

Epoch: 145| Step: 0
Training loss: 2.9729812183781283
Validation loss: 2.7098492723772987

Epoch: 5| Step: 1
Training loss: 3.025724428304739
Validation loss: 2.704431255539842

Epoch: 5| Step: 2
Training loss: 3.2125632075759847
Validation loss: 2.7090838267276767

Epoch: 5| Step: 3
Training loss: 2.876347433377115
Validation loss: 2.713684388788441

Epoch: 5| Step: 4
Training loss: 3.023135936591883
Validation loss: 2.7114804355341904

Epoch: 5| Step: 5
Training loss: 3.1902031002144167
Validation loss: 2.7066175820719973

Epoch: 5| Step: 6
Training loss: 3.3889698963871253
Validation loss: 2.707530429107678

Epoch: 5| Step: 7
Training loss: 3.1175659255924386
Validation loss: 2.6965041256376057

Epoch: 5| Step: 8
Training loss: 2.8310135900561337
Validation loss: 2.7025923115458435

Epoch: 5| Step: 9
Training loss: 2.8988013848820584
Validation loss: 2.6999523201928906

Epoch: 5| Step: 10
Training loss: 2.6591626522934884
Validation loss: 2.7008424542215947

Epoch: 146| Step: 0
Training loss: 3.334778345340036
Validation loss: 2.7003284019152383

Epoch: 5| Step: 1
Training loss: 2.8409096083207093
Validation loss: 2.6991006718431145

Epoch: 5| Step: 2
Training loss: 3.150230938151056
Validation loss: 2.6973990889654873

Epoch: 5| Step: 3
Training loss: 2.3531224345766955
Validation loss: 2.696948654881408

Epoch: 5| Step: 4
Training loss: 2.6950370316093255
Validation loss: 2.6967221015308582

Epoch: 5| Step: 5
Training loss: 3.020299579338148
Validation loss: 2.694146377335693

Epoch: 5| Step: 6
Training loss: 3.254066417548495
Validation loss: 2.6954222098159346

Epoch: 5| Step: 7
Training loss: 2.917049074081227
Validation loss: 2.6926914886641478

Epoch: 5| Step: 8
Training loss: 3.2666265238676346
Validation loss: 2.692221432672818

Epoch: 5| Step: 9
Training loss: 3.2442555645464832
Validation loss: 2.6965486060077195

Epoch: 5| Step: 10
Training loss: 3.074727463468815
Validation loss: 2.6927185635987154

Epoch: 147| Step: 0
Training loss: 2.9828934911779728
Validation loss: 2.693648548669761

Epoch: 5| Step: 1
Training loss: 3.7971455042047757
Validation loss: 2.6920295323557863

Epoch: 5| Step: 2
Training loss: 3.0101165269873658
Validation loss: 2.6920105423196037

Epoch: 5| Step: 3
Training loss: 2.9182875534408654
Validation loss: 2.6963798674435537

Epoch: 5| Step: 4
Training loss: 2.5544324275077
Validation loss: 2.6952540912811838

Epoch: 5| Step: 5
Training loss: 3.0465308361812493
Validation loss: 2.692277537110186

Epoch: 5| Step: 6
Training loss: 2.694695355070889
Validation loss: 2.693493385636382

Epoch: 5| Step: 7
Training loss: 3.0390350419007803
Validation loss: 2.6902339143090854

Epoch: 5| Step: 8
Training loss: 2.5038889201452745
Validation loss: 2.6912395504789375

Epoch: 5| Step: 9
Training loss: 3.079638578586656
Validation loss: 2.6982119204637387

Epoch: 5| Step: 10
Training loss: 3.466654926671421
Validation loss: 2.694035715351634

Epoch: 148| Step: 0
Training loss: 2.89217372336628
Validation loss: 2.6940250031848114

Epoch: 5| Step: 1
Training loss: 3.375635157970506
Validation loss: 2.692464241942631

Epoch: 5| Step: 2
Training loss: 3.1194130355176157
Validation loss: 2.6934601927000696

Epoch: 5| Step: 3
Training loss: 3.0327086724221743
Validation loss: 2.694051681225762

Epoch: 5| Step: 4
Training loss: 3.0464182976028957
Validation loss: 2.6913568781000086

Epoch: 5| Step: 5
Training loss: 2.796019695076182
Validation loss: 2.691257871528249

Epoch: 5| Step: 6
Training loss: 2.715782738637958
Validation loss: 2.688859563728227

Epoch: 5| Step: 7
Training loss: 3.285063643630089
Validation loss: 2.6937626764557723

Epoch: 5| Step: 8
Training loss: 2.9626232974634727
Validation loss: 2.6911280030513383

Epoch: 5| Step: 9
Training loss: 3.0666035776974145
Validation loss: 2.6899050505962516

Epoch: 5| Step: 10
Training loss: 2.801974458718275
Validation loss: 2.6910394730347766

Epoch: 149| Step: 0
Training loss: 2.740438571970177
Validation loss: 2.6922731226144414

Epoch: 5| Step: 1
Training loss: 3.1773243963788493
Validation loss: 2.6917509222055527

Epoch: 5| Step: 2
Training loss: 3.110162223191168
Validation loss: 2.6955586158605094

Epoch: 5| Step: 3
Training loss: 2.5914345942992196
Validation loss: 2.70067324826153

Epoch: 5| Step: 4
Training loss: 2.9226234823723627
Validation loss: 2.696620446540206

Epoch: 5| Step: 5
Training loss: 3.445397477604946
Validation loss: 2.7022036887997674

Epoch: 5| Step: 6
Training loss: 2.7163496273218515
Validation loss: 2.6965286276755056

Epoch: 5| Step: 7
Training loss: 3.1359797042948974
Validation loss: 2.6899246702157793

Epoch: 5| Step: 8
Training loss: 2.7673979857405246
Validation loss: 2.689341760855845

Epoch: 5| Step: 9
Training loss: 3.195272953749398
Validation loss: 2.688924914872149

Epoch: 5| Step: 10
Training loss: 3.3948694901248366
Validation loss: 2.6891609090516417

Epoch: 150| Step: 0
Training loss: 2.6354947788488596
Validation loss: 2.6905218326542863

Epoch: 5| Step: 1
Training loss: 2.8480363338381594
Validation loss: 2.6903792485450504

Epoch: 5| Step: 2
Training loss: 3.017393868262078
Validation loss: 2.6895024613106955

Epoch: 5| Step: 3
Training loss: 3.0621329885614426
Validation loss: 2.689912661721836

Epoch: 5| Step: 4
Training loss: 2.366534454610712
Validation loss: 2.688584291400954

Epoch: 5| Step: 5
Training loss: 2.8950829025283897
Validation loss: 2.6910496597888938

Epoch: 5| Step: 6
Training loss: 3.27027642111235
Validation loss: 2.6906329831210285

Epoch: 5| Step: 7
Training loss: 3.3720339704908864
Validation loss: 2.688866416024278

Epoch: 5| Step: 8
Training loss: 3.294414451795675
Validation loss: 2.688469290593598

Epoch: 5| Step: 9
Training loss: 3.4348236762800197
Validation loss: 2.685469908744053

Epoch: 5| Step: 10
Training loss: 2.8382211113377447
Validation loss: 2.6876911344334116

Epoch: 151| Step: 0
Training loss: 3.077747457364869
Validation loss: 2.690690761370084

Epoch: 5| Step: 1
Training loss: 2.9745064590494263
Validation loss: 2.6849054421694665

Epoch: 5| Step: 2
Training loss: 3.3140522900486586
Validation loss: 2.690573095034171

Epoch: 5| Step: 3
Training loss: 2.696879498068019
Validation loss: 2.6938953870630176

Epoch: 5| Step: 4
Training loss: 2.5876171730527187
Validation loss: 2.687319037604239

Epoch: 5| Step: 5
Training loss: 3.2901189199365146
Validation loss: 2.6876953122710776

Epoch: 5| Step: 6
Training loss: 3.3269509407189464
Validation loss: 2.6968391725686596

Epoch: 5| Step: 7
Training loss: 2.861994976153919
Validation loss: 2.687147698821407

Epoch: 5| Step: 8
Training loss: 3.0450260127417508
Validation loss: 2.694402689586108

Epoch: 5| Step: 9
Training loss: 2.725786158698602
Validation loss: 2.687411091949086

Epoch: 5| Step: 10
Training loss: 3.165534084630047
Validation loss: 2.691795544929784

Epoch: 152| Step: 0
Training loss: 2.7085417349425387
Validation loss: 2.690130064345402

Epoch: 5| Step: 1
Training loss: 3.4636964844637896
Validation loss: 2.688703061189608

Epoch: 5| Step: 2
Training loss: 2.9722248822098316
Validation loss: 2.687551879000516

Epoch: 5| Step: 3
Training loss: 2.8027051119988022
Validation loss: 2.687576558042626

Epoch: 5| Step: 4
Training loss: 2.443725363370608
Validation loss: 2.687678440634743

Epoch: 5| Step: 5
Training loss: 2.9703920340688317
Validation loss: 2.6835731526693247

Epoch: 5| Step: 6
Training loss: 3.2126481077733806
Validation loss: 2.6870513297292997

Epoch: 5| Step: 7
Training loss: 3.2712354149673666
Validation loss: 2.6858754782006944

Epoch: 5| Step: 8
Training loss: 2.795146130749237
Validation loss: 2.684040153834409

Epoch: 5| Step: 9
Training loss: 3.1813051949679827
Validation loss: 2.6905538403127776

Epoch: 5| Step: 10
Training loss: 3.1886908606679367
Validation loss: 2.685129559233483

Epoch: 153| Step: 0
Training loss: 3.019948281609503
Validation loss: 2.685664162081735

Epoch: 5| Step: 1
Training loss: 2.5968988447322565
Validation loss: 2.681885337617623

Epoch: 5| Step: 2
Training loss: 2.9851389601166063
Validation loss: 2.682720479708691

Epoch: 5| Step: 3
Training loss: 3.2922571030959507
Validation loss: 2.689641095331024

Epoch: 5| Step: 4
Training loss: 3.0458974981963927
Validation loss: 2.6848332700255986

Epoch: 5| Step: 5
Training loss: 3.2516179092430217
Validation loss: 2.694838189326152

Epoch: 5| Step: 6
Training loss: 3.2800287789733726
Validation loss: 2.6865990720011865

Epoch: 5| Step: 7
Training loss: 2.905273273371844
Validation loss: 2.6855087305606062

Epoch: 5| Step: 8
Training loss: 3.235100264019914
Validation loss: 2.6888070940307056

Epoch: 5| Step: 9
Training loss: 2.7725573365428757
Validation loss: 2.6921865585655267

Epoch: 5| Step: 10
Training loss: 2.5324690908972802
Validation loss: 2.696986390376958

Epoch: 154| Step: 0
Training loss: 3.1782878822740184
Validation loss: 2.6903373162095305

Epoch: 5| Step: 1
Training loss: 2.7683530811460573
Validation loss: 2.696564337390333

Epoch: 5| Step: 2
Training loss: 3.158378865124332
Validation loss: 2.695452309398072

Epoch: 5| Step: 3
Training loss: 2.6463479770547225
Validation loss: 2.689932599604615

Epoch: 5| Step: 4
Training loss: 3.439903667343111
Validation loss: 2.6906481269142732

Epoch: 5| Step: 5
Training loss: 2.533910036532905
Validation loss: 2.6851521849200575

Epoch: 5| Step: 6
Training loss: 2.763445065091235
Validation loss: 2.6855914051171292

Epoch: 5| Step: 7
Training loss: 3.3311411483758584
Validation loss: 2.681189123100765

Epoch: 5| Step: 8
Training loss: 3.582901876926045
Validation loss: 2.6792472899437154

Epoch: 5| Step: 9
Training loss: 2.7079815758398156
Validation loss: 2.6816496056216312

Epoch: 5| Step: 10
Training loss: 2.7847319677049724
Validation loss: 2.678410992151378

Epoch: 155| Step: 0
Training loss: 2.8671143234020215
Validation loss: 2.6824912223492254

Epoch: 5| Step: 1
Training loss: 3.5453031981116268
Validation loss: 2.678316783022171

Epoch: 5| Step: 2
Training loss: 3.0115048422840194
Validation loss: 2.6807918501464374

Epoch: 5| Step: 3
Training loss: 3.1839891433914116
Validation loss: 2.6815725341987573

Epoch: 5| Step: 4
Training loss: 2.8384492538294466
Validation loss: 2.682127598205835

Epoch: 5| Step: 5
Training loss: 2.7196099686072
Validation loss: 2.68161685307098

Epoch: 5| Step: 6
Training loss: 2.890976838015465
Validation loss: 2.6823135357562697

Epoch: 5| Step: 7
Training loss: 2.661980853263387
Validation loss: 2.685227815082758

Epoch: 5| Step: 8
Training loss: 3.4236061211361135
Validation loss: 2.682918205803983

Epoch: 5| Step: 9
Training loss: 2.5673719473369845
Validation loss: 2.686637751544476

Epoch: 5| Step: 10
Training loss: 3.2771605666643353
Validation loss: 2.6927211075127486

Epoch: 156| Step: 0
Training loss: 2.6436182697204518
Validation loss: 2.6883538576496413

Epoch: 5| Step: 1
Training loss: 2.936327923633507
Validation loss: 2.694507868625408

Epoch: 5| Step: 2
Training loss: 2.6487205151604125
Validation loss: 2.6880644529613202

Epoch: 5| Step: 3
Training loss: 2.636125240638668
Validation loss: 2.693656714546977

Epoch: 5| Step: 4
Training loss: 3.2197244891182284
Validation loss: 2.6868554267853244

Epoch: 5| Step: 5
Training loss: 3.5937980316932863
Validation loss: 2.688367907146392

Epoch: 5| Step: 6
Training loss: 3.1737298662674625
Validation loss: 2.6868157408791253

Epoch: 5| Step: 7
Training loss: 2.9341541471234995
Validation loss: 2.6789932205422535

Epoch: 5| Step: 8
Training loss: 3.2747852400623576
Validation loss: 2.68547179700926

Epoch: 5| Step: 9
Training loss: 3.019215714128817
Validation loss: 2.6736996440046705

Epoch: 5| Step: 10
Training loss: 2.8541801248126384
Validation loss: 2.677948436353283

Epoch: 157| Step: 0
Training loss: 2.8111643692754757
Validation loss: 2.6766547901518023

Epoch: 5| Step: 1
Training loss: 3.0781192682667924
Validation loss: 2.681360891397162

Epoch: 5| Step: 2
Training loss: 2.5159474041873784
Validation loss: 2.685888709305132

Epoch: 5| Step: 3
Training loss: 2.978690760732186
Validation loss: 2.679145862288886

Epoch: 5| Step: 4
Training loss: 2.888021585494764
Validation loss: 2.6780460271117232

Epoch: 5| Step: 5
Training loss: 2.9881239107884374
Validation loss: 2.680034431188284

Epoch: 5| Step: 6
Training loss: 3.291329298154343
Validation loss: 2.6783152639715238

Epoch: 5| Step: 7
Training loss: 3.4329134773887477
Validation loss: 2.683123883081892

Epoch: 5| Step: 8
Training loss: 3.0258426217794843
Validation loss: 2.6789050617839267

Epoch: 5| Step: 9
Training loss: 3.0822741433320497
Validation loss: 2.6801605548496785

Epoch: 5| Step: 10
Training loss: 2.9057116266188343
Validation loss: 2.6815479920619802

Epoch: 158| Step: 0
Training loss: 3.308208348550162
Validation loss: 2.676487659405843

Epoch: 5| Step: 1
Training loss: 3.0982108275141758
Validation loss: 2.683226117230475

Epoch: 5| Step: 2
Training loss: 3.0773012249834544
Validation loss: 2.6812309967605983

Epoch: 5| Step: 3
Training loss: 2.8230744677892563
Validation loss: 2.6783069737876883

Epoch: 5| Step: 4
Training loss: 2.433641852673425
Validation loss: 2.677512428047497

Epoch: 5| Step: 5
Training loss: 3.3285490670262865
Validation loss: 2.6782201641340126

Epoch: 5| Step: 6
Training loss: 2.9958153785588437
Validation loss: 2.6739604280851736

Epoch: 5| Step: 7
Training loss: 2.6738743133679574
Validation loss: 2.6801824859656698

Epoch: 5| Step: 8
Training loss: 2.772325663610523
Validation loss: 2.6780942037227535

Epoch: 5| Step: 9
Training loss: 3.1556707171647203
Validation loss: 2.6766100107900153

Epoch: 5| Step: 10
Training loss: 3.3031297985031225
Validation loss: 2.68059050896933

Epoch: 159| Step: 0
Training loss: 2.712588024908537
Validation loss: 2.6750174144522654

Epoch: 5| Step: 1
Training loss: 3.347447285311883
Validation loss: 2.679056768380618

Epoch: 5| Step: 2
Training loss: 2.1263902267871546
Validation loss: 2.6855135762079048

Epoch: 5| Step: 3
Training loss: 2.463264067953178
Validation loss: 2.684822654822933

Epoch: 5| Step: 4
Training loss: 3.352363828529142
Validation loss: 2.6764962339547025

Epoch: 5| Step: 5
Training loss: 2.9627871410426097
Validation loss: 2.6797847557351058

Epoch: 5| Step: 6
Training loss: 2.6569636564285237
Validation loss: 2.6817909953024293

Epoch: 5| Step: 7
Training loss: 3.135922835714421
Validation loss: 2.686406990500963

Epoch: 5| Step: 8
Training loss: 3.3473732115342867
Validation loss: 2.689066320524339

Epoch: 5| Step: 9
Training loss: 3.4546731783786986
Validation loss: 2.6884281828787118

Epoch: 5| Step: 10
Training loss: 3.213487934835982
Validation loss: 2.696748497167798

Epoch: 160| Step: 0
Training loss: 3.2067250931533064
Validation loss: 2.6837616083865274

Epoch: 5| Step: 1
Training loss: 3.1899732082760575
Validation loss: 2.6831625028449966

Epoch: 5| Step: 2
Training loss: 3.0659350379387282
Validation loss: 2.6747824228389208

Epoch: 5| Step: 3
Training loss: 2.898203714407018
Validation loss: 2.6736765206052078

Epoch: 5| Step: 4
Training loss: 2.9037333431086365
Validation loss: 2.6738794763598843

Epoch: 5| Step: 5
Training loss: 2.9565463153495717
Validation loss: 2.6737577373554897

Epoch: 5| Step: 6
Training loss: 2.631738822999522
Validation loss: 2.6776562679320866

Epoch: 5| Step: 7
Training loss: 3.095520745810653
Validation loss: 2.6782510342376433

Epoch: 5| Step: 8
Training loss: 2.8730345932563797
Validation loss: 2.6801874235028857

Epoch: 5| Step: 9
Training loss: 3.183027832657402
Validation loss: 2.6806457579873317

Epoch: 5| Step: 10
Training loss: 3.0458040360391125
Validation loss: 2.679977123421214

Epoch: 161| Step: 0
Training loss: 3.1089563135787563
Validation loss: 2.6778262270193527

Epoch: 5| Step: 1
Training loss: 3.0100347855291
Validation loss: 2.6754731170553328

Epoch: 5| Step: 2
Training loss: 3.3282509363551784
Validation loss: 2.6743953810850534

Epoch: 5| Step: 3
Training loss: 2.946630693909412
Validation loss: 2.6738670458526785

Epoch: 5| Step: 4
Training loss: 3.0055187644594845
Validation loss: 2.677103090331059

Epoch: 5| Step: 5
Training loss: 3.333890550451916
Validation loss: 2.6738519795977935

Epoch: 5| Step: 6
Training loss: 3.0318351259521075
Validation loss: 2.675526673239842

Epoch: 5| Step: 7
Training loss: 2.9989960898093706
Validation loss: 2.6853552499907227

Epoch: 5| Step: 8
Training loss: 2.2808041071479823
Validation loss: 2.6875166876986185

Epoch: 5| Step: 9
Training loss: 3.149886713564247
Validation loss: 2.6887203764389946

Epoch: 5| Step: 10
Training loss: 2.6463491482691164
Validation loss: 2.6925411729835886

Epoch: 162| Step: 0
Training loss: 2.4175014259941685
Validation loss: 2.689313135273379

Epoch: 5| Step: 1
Training loss: 3.1453175574544847
Validation loss: 2.684232514537066

Epoch: 5| Step: 2
Training loss: 3.240922428265625
Validation loss: 2.6775748745386334

Epoch: 5| Step: 3
Training loss: 3.9067253128788164
Validation loss: 2.676426176059086

Epoch: 5| Step: 4
Training loss: 2.8242516733363656
Validation loss: 2.6741087587585386

Epoch: 5| Step: 5
Training loss: 2.634949945629499
Validation loss: 2.6699336018129136

Epoch: 5| Step: 6
Training loss: 3.2940302865281086
Validation loss: 2.66908758455349

Epoch: 5| Step: 7
Training loss: 3.336514639679541
Validation loss: 2.6743113346909237

Epoch: 5| Step: 8
Training loss: 2.2711782864222307
Validation loss: 2.671011408520289

Epoch: 5| Step: 9
Training loss: 3.0520773270236514
Validation loss: 2.6715771203763055

Epoch: 5| Step: 10
Training loss: 2.425483820521349
Validation loss: 2.670732913368247

Epoch: 163| Step: 0
Training loss: 3.1857318836143986
Validation loss: 2.670140715169402

Epoch: 5| Step: 1
Training loss: 2.9715617467045066
Validation loss: 2.671928043027264

Epoch: 5| Step: 2
Training loss: 2.885635936865882
Validation loss: 2.670027477832306

Epoch: 5| Step: 3
Training loss: 2.7630876874011476
Validation loss: 2.673350666133057

Epoch: 5| Step: 4
Training loss: 3.2896809121159514
Validation loss: 2.677820408664625

Epoch: 5| Step: 5
Training loss: 2.918564660275406
Validation loss: 2.686314751917294

Epoch: 5| Step: 6
Training loss: 3.2347811384028287
Validation loss: 2.6943168523943632

Epoch: 5| Step: 7
Training loss: 2.415474981508089
Validation loss: 2.7019921600592878

Epoch: 5| Step: 8
Training loss: 2.8626879901041473
Validation loss: 2.7012789580931518

Epoch: 5| Step: 9
Training loss: 3.065205682819788
Validation loss: 2.7202000356133493

Epoch: 5| Step: 10
Training loss: 3.4829280568834995
Validation loss: 2.715571256082372

Epoch: 164| Step: 0
Training loss: 3.0841465642219488
Validation loss: 2.693730891556593

Epoch: 5| Step: 1
Training loss: 3.080123020539159
Validation loss: 2.6843799853697314

Epoch: 5| Step: 2
Training loss: 3.5994951847901047
Validation loss: 2.669855834980522

Epoch: 5| Step: 3
Training loss: 2.8216170149744126
Validation loss: 2.668843437131276

Epoch: 5| Step: 4
Training loss: 3.1838913480057327
Validation loss: 2.670810850476679

Epoch: 5| Step: 5
Training loss: 2.5208446302765064
Validation loss: 2.6717916505751025

Epoch: 5| Step: 6
Training loss: 3.1707069990043477
Validation loss: 2.672479733429655

Epoch: 5| Step: 7
Training loss: 2.7682487843566888
Validation loss: 2.673542558011089

Epoch: 5| Step: 8
Training loss: 3.2597758645547685
Validation loss: 2.675340990351167

Epoch: 5| Step: 9
Training loss: 2.834583137718178
Validation loss: 2.6790013794157463

Epoch: 5| Step: 10
Training loss: 2.5996395484783923
Validation loss: 2.6754606613733896

Epoch: 165| Step: 0
Training loss: 3.2500686638254397
Validation loss: 2.6741738194464078

Epoch: 5| Step: 1
Training loss: 2.876356882747889
Validation loss: 2.676734143742657

Epoch: 5| Step: 2
Training loss: 2.8754229027234994
Validation loss: 2.6951093937512915

Epoch: 5| Step: 3
Training loss: 2.565582096610007
Validation loss: 2.706141346972657

Epoch: 5| Step: 4
Training loss: 3.2101785547145836
Validation loss: 2.7083171831379893

Epoch: 5| Step: 5
Training loss: 3.286235981153533
Validation loss: 2.7091305325384165

Epoch: 5| Step: 6
Training loss: 3.419903609718857
Validation loss: 2.7081385357062486

Epoch: 5| Step: 7
Training loss: 2.806628817199631
Validation loss: 2.6891975946012825

Epoch: 5| Step: 8
Training loss: 2.648273294135197
Validation loss: 2.6685476193847637

Epoch: 5| Step: 9
Training loss: 2.9024953892397667
Validation loss: 2.666178449679676

Epoch: 5| Step: 10
Training loss: 3.1853343113860073
Validation loss: 2.6692064535129094

Epoch: 166| Step: 0
Training loss: 2.2946870724296975
Validation loss: 2.668103254760475

Epoch: 5| Step: 1
Training loss: 3.159274021727199
Validation loss: 2.6643301459143705

Epoch: 5| Step: 2
Training loss: 2.460538607769837
Validation loss: 2.664535048957

Epoch: 5| Step: 3
Training loss: 2.710098532542924
Validation loss: 2.665352055725137

Epoch: 5| Step: 4
Training loss: 3.30321727901678
Validation loss: 2.666195133330202

Epoch: 5| Step: 5
Training loss: 3.0612002358805728
Validation loss: 2.6670534000249515

Epoch: 5| Step: 6
Training loss: 3.3387626459759834
Validation loss: 2.6623065519059557

Epoch: 5| Step: 7
Training loss: 2.8856914586805966
Validation loss: 2.666334965736469

Epoch: 5| Step: 8
Training loss: 2.959092665097659
Validation loss: 2.6672134998786645

Epoch: 5| Step: 9
Training loss: 3.335405150915246
Validation loss: 2.6657918570578736

Epoch: 5| Step: 10
Training loss: 3.3672669438949674
Validation loss: 2.6677098066969407

Epoch: 167| Step: 0
Training loss: 3.0074107508683405
Validation loss: 2.66804478558191

Epoch: 5| Step: 1
Training loss: 2.9238995560537986
Validation loss: 2.666914743438649

Epoch: 5| Step: 2
Training loss: 2.4521548545689633
Validation loss: 2.667674910063487

Epoch: 5| Step: 3
Training loss: 2.9728567529498577
Validation loss: 2.6709965555514796

Epoch: 5| Step: 4
Training loss: 2.3712608617876683
Validation loss: 2.663246256603953

Epoch: 5| Step: 5
Training loss: 3.7721374673237578
Validation loss: 2.6740624996610016

Epoch: 5| Step: 6
Training loss: 2.6534495232731663
Validation loss: 2.672258690264911

Epoch: 5| Step: 7
Training loss: 2.896236437361189
Validation loss: 2.668625394559624

Epoch: 5| Step: 8
Training loss: 3.468311866377303
Validation loss: 2.673783523617956

Epoch: 5| Step: 9
Training loss: 3.3518814610936993
Validation loss: 2.669935242775257

Epoch: 5| Step: 10
Training loss: 2.8135307966180263
Validation loss: 2.6733222979804547

Epoch: 168| Step: 0
Training loss: 3.3766831333653884
Validation loss: 2.6732741226401697

Epoch: 5| Step: 1
Training loss: 3.1764431834856732
Validation loss: 2.6778622162900545

Epoch: 5| Step: 2
Training loss: 2.561183963667165
Validation loss: 2.6716886564667384

Epoch: 5| Step: 3
Training loss: 3.2005806098158502
Validation loss: 2.674138816389086

Epoch: 5| Step: 4
Training loss: 2.7880162432456017
Validation loss: 2.6712177492247373

Epoch: 5| Step: 5
Training loss: 3.006212477737346
Validation loss: 2.6705948951586236

Epoch: 5| Step: 6
Training loss: 2.9231902237606007
Validation loss: 2.673135086708762

Epoch: 5| Step: 7
Training loss: 2.747494336331529
Validation loss: 2.6787122974572717

Epoch: 5| Step: 8
Training loss: 2.586215831149223
Validation loss: 2.666899396626154

Epoch: 5| Step: 9
Training loss: 3.5521963927472373
Validation loss: 2.6667202192999935

Epoch: 5| Step: 10
Training loss: 2.807480295575801
Validation loss: 2.6637654208479344

Epoch: 169| Step: 0
Training loss: 2.681068887351301
Validation loss: 2.663329063937385

Epoch: 5| Step: 1
Training loss: 2.1474835861697876
Validation loss: 2.6611435164204056

Epoch: 5| Step: 2
Training loss: 3.3688724134635613
Validation loss: 2.6607179130543868

Epoch: 5| Step: 3
Training loss: 3.3447100250503574
Validation loss: 2.662885421794081

Epoch: 5| Step: 4
Training loss: 3.4950570215640795
Validation loss: 2.660321199688642

Epoch: 5| Step: 5
Training loss: 2.9076487138916893
Validation loss: 2.662697133961216

Epoch: 5| Step: 6
Training loss: 2.7046350219501387
Validation loss: 2.6753361895234766

Epoch: 5| Step: 7
Training loss: 3.128318245603597
Validation loss: 2.690007250986064

Epoch: 5| Step: 8
Training loss: 2.5487468370359063
Validation loss: 2.696377569428303

Epoch: 5| Step: 9
Training loss: 3.223610920385373
Validation loss: 2.673294902413834

Epoch: 5| Step: 10
Training loss: 3.1995514078423213
Validation loss: 2.6652969927359487

Epoch: 170| Step: 0
Training loss: 3.2306070540319562
Validation loss: 2.660203873629356

Epoch: 5| Step: 1
Training loss: 3.348833871825598
Validation loss: 2.6645331679837274

Epoch: 5| Step: 2
Training loss: 2.6660635584060888
Validation loss: 2.6671797290223127

Epoch: 5| Step: 3
Training loss: 3.30251202773879
Validation loss: 2.6719104107487563

Epoch: 5| Step: 4
Training loss: 2.743970590122421
Validation loss: 2.672745690456164

Epoch: 5| Step: 5
Training loss: 3.0660868290042216
Validation loss: 2.6936216639144717

Epoch: 5| Step: 6
Training loss: 2.7145526098667934
Validation loss: 2.6852582217871195

Epoch: 5| Step: 7
Training loss: 3.34385067797104
Validation loss: 2.6832160899507875

Epoch: 5| Step: 8
Training loss: 2.635546885855519
Validation loss: 2.672646786755194

Epoch: 5| Step: 9
Training loss: 3.0815481912118043
Validation loss: 2.6730371641624906

Epoch: 5| Step: 10
Training loss: 2.66635382327186
Validation loss: 2.674405460608326

Epoch: 171| Step: 0
Training loss: 2.830649750597746
Validation loss: 2.677074959213038

Epoch: 5| Step: 1
Training loss: 3.214874452835998
Validation loss: 2.6698121524369385

Epoch: 5| Step: 2
Training loss: 2.7590414016233216
Validation loss: 2.662813651204164

Epoch: 5| Step: 3
Training loss: 2.8201718282092316
Validation loss: 2.665995598643102

Epoch: 5| Step: 4
Training loss: 3.336329274098634
Validation loss: 2.6659043569032166

Epoch: 5| Step: 5
Training loss: 2.1520317945436034
Validation loss: 2.653732158479636

Epoch: 5| Step: 6
Training loss: 2.9967328400849733
Validation loss: 2.6567476485624564

Epoch: 5| Step: 7
Training loss: 2.8004163773074002
Validation loss: 2.6549236829980085

Epoch: 5| Step: 8
Training loss: 2.903474364185757
Validation loss: 2.6582273647766157

Epoch: 5| Step: 9
Training loss: 3.2373690545542906
Validation loss: 2.655153487108488

Epoch: 5| Step: 10
Training loss: 3.6912925743078975
Validation loss: 2.657930242041848

Epoch: 172| Step: 0
Training loss: 3.2113519479999915
Validation loss: 2.6591306726645643

Epoch: 5| Step: 1
Training loss: 3.225637529626381
Validation loss: 2.6579919863683714

Epoch: 5| Step: 2
Training loss: 3.140533142264793
Validation loss: 2.651029135198985

Epoch: 5| Step: 3
Training loss: 3.0872841516326877
Validation loss: 2.6577536663396857

Epoch: 5| Step: 4
Training loss: 3.0784811210852694
Validation loss: 2.6564384321228

Epoch: 5| Step: 5
Training loss: 2.5986345557056816
Validation loss: 2.664739644739472

Epoch: 5| Step: 6
Training loss: 3.0685146202670244
Validation loss: 2.657373538900408

Epoch: 5| Step: 7
Training loss: 3.0307739513230865
Validation loss: 2.6587313764828684

Epoch: 5| Step: 8
Training loss: 2.7201729043532574
Validation loss: 2.655493917356416

Epoch: 5| Step: 9
Training loss: 2.6207585354933185
Validation loss: 2.6618876209229545

Epoch: 5| Step: 10
Training loss: 3.024590639521674
Validation loss: 2.659145242913096

Epoch: 173| Step: 0
Training loss: 2.8591463591668766
Validation loss: 2.653874753438338

Epoch: 5| Step: 1
Training loss: 3.372937172506736
Validation loss: 2.6616447124518015

Epoch: 5| Step: 2
Training loss: 3.275300654231662
Validation loss: 2.6657255810454297

Epoch: 5| Step: 3
Training loss: 2.886249261445438
Validation loss: 2.6561703288165917

Epoch: 5| Step: 4
Training loss: 3.0826703123392285
Validation loss: 2.663225615493865

Epoch: 5| Step: 5
Training loss: 2.6765614061414595
Validation loss: 2.6665565932023796

Epoch: 5| Step: 6
Training loss: 3.3439398025405804
Validation loss: 2.666275553965096

Epoch: 5| Step: 7
Training loss: 3.2002943976402207
Validation loss: 2.682572512445014

Epoch: 5| Step: 8
Training loss: 2.5076078052109025
Validation loss: 2.6825656928109707

Epoch: 5| Step: 9
Training loss: 2.7644531870959614
Validation loss: 2.687028819258493

Epoch: 5| Step: 10
Training loss: 2.7082642668696275
Validation loss: 2.6819764361918024

Epoch: 174| Step: 0
Training loss: 3.5045343726996876
Validation loss: 2.688469894202628

Epoch: 5| Step: 1
Training loss: 3.2706776640632365
Validation loss: 2.6760150062104353

Epoch: 5| Step: 2
Training loss: 2.42253782984876
Validation loss: 2.659331071414498

Epoch: 5| Step: 3
Training loss: 2.7774039260633234
Validation loss: 2.6611341573563734

Epoch: 5| Step: 4
Training loss: 2.145931599660139
Validation loss: 2.661947023727494

Epoch: 5| Step: 5
Training loss: 2.945759139864496
Validation loss: 2.656591155350003

Epoch: 5| Step: 6
Training loss: 3.156678274577093
Validation loss: 2.6621257673229275

Epoch: 5| Step: 7
Training loss: 3.3655007512102095
Validation loss: 2.6547634252549237

Epoch: 5| Step: 8
Training loss: 3.466367160868178
Validation loss: 2.6510664045048107

Epoch: 5| Step: 9
Training loss: 2.7733985575776128
Validation loss: 2.663843582979466

Epoch: 5| Step: 10
Training loss: 2.6434380710275143
Validation loss: 2.6628433848039252

Epoch: 175| Step: 0
Training loss: 3.293665621000624
Validation loss: 2.662114278647542

Epoch: 5| Step: 1
Training loss: 3.0760453843041438
Validation loss: 2.6633366249139394

Epoch: 5| Step: 2
Training loss: 2.9908488892364775
Validation loss: 2.675260939975319

Epoch: 5| Step: 3
Training loss: 2.341278807895127
Validation loss: 2.6646085569298825

Epoch: 5| Step: 4
Training loss: 2.9254779327400047
Validation loss: 2.6655403368332773

Epoch: 5| Step: 5
Training loss: 3.1584377449377503
Validation loss: 2.661313169399325

Epoch: 5| Step: 6
Training loss: 2.9853496457918283
Validation loss: 2.657221103765762

Epoch: 5| Step: 7
Training loss: 2.747141913420995
Validation loss: 2.658323808621413

Epoch: 5| Step: 8
Training loss: 3.2938053249511814
Validation loss: 2.6525342862788226

Epoch: 5| Step: 9
Training loss: 2.7006570652314177
Validation loss: 2.653661606836442

Epoch: 5| Step: 10
Training loss: 3.263163976226476
Validation loss: 2.655057084525247

Epoch: 176| Step: 0
Training loss: 2.8901426170560907
Validation loss: 2.65487334971133

Epoch: 5| Step: 1
Training loss: 3.3861591796411705
Validation loss: 2.657937302356762

Epoch: 5| Step: 2
Training loss: 3.425191726330306
Validation loss: 2.6559736056154835

Epoch: 5| Step: 3
Training loss: 2.833027505263769
Validation loss: 2.6573500129578345

Epoch: 5| Step: 4
Training loss: 3.1347598447181912
Validation loss: 2.6561781331232286

Epoch: 5| Step: 5
Training loss: 2.9675724304152613
Validation loss: 2.654412864712595

Epoch: 5| Step: 6
Training loss: 2.3762805899427515
Validation loss: 2.6513054344171

Epoch: 5| Step: 7
Training loss: 3.269932438563677
Validation loss: 2.653927367024031

Epoch: 5| Step: 8
Training loss: 2.9875366081005956
Validation loss: 2.656474592931064

Epoch: 5| Step: 9
Training loss: 2.541143697081117
Validation loss: 2.6541692103378582

Epoch: 5| Step: 10
Training loss: 2.9376824504925034
Validation loss: 2.660861497911378

Epoch: 177| Step: 0
Training loss: 3.134469600021974
Validation loss: 2.6646345885530534

Epoch: 5| Step: 1
Training loss: 2.828299248317088
Validation loss: 2.6656613326316236

Epoch: 5| Step: 2
Training loss: 2.8949806183741056
Validation loss: 2.678115234709465

Epoch: 5| Step: 3
Training loss: 3.4089519738294185
Validation loss: 2.6676104942899594

Epoch: 5| Step: 4
Training loss: 2.8811927111178512
Validation loss: 2.6742079233074163

Epoch: 5| Step: 5
Training loss: 3.0588960266799807
Validation loss: 2.6663749276312143

Epoch: 5| Step: 6
Training loss: 2.81788111995433
Validation loss: 2.6552020626734056

Epoch: 5| Step: 7
Training loss: 3.3210882021279526
Validation loss: 2.6564548053962977

Epoch: 5| Step: 8
Training loss: 2.7707738846063745
Validation loss: 2.6519529316988457

Epoch: 5| Step: 9
Training loss: 2.5328499717693878
Validation loss: 2.6523392845042637

Epoch: 5| Step: 10
Training loss: 3.148188957456815
Validation loss: 2.649914194468129

Epoch: 178| Step: 0
Training loss: 3.239307126028386
Validation loss: 2.649275311044759

Epoch: 5| Step: 1
Training loss: 2.9135928350780524
Validation loss: 2.654375428947906

Epoch: 5| Step: 2
Training loss: 2.9895361565424183
Validation loss: 2.6516056445250236

Epoch: 5| Step: 3
Training loss: 2.866688864274542
Validation loss: 2.648694686218788

Epoch: 5| Step: 4
Training loss: 2.813839995861234
Validation loss: 2.6556800274198613

Epoch: 5| Step: 5
Training loss: 2.4223650036686326
Validation loss: 2.6574528325080142

Epoch: 5| Step: 6
Training loss: 3.3189071014634517
Validation loss: 2.6543036059686056

Epoch: 5| Step: 7
Training loss: 3.032027941109538
Validation loss: 2.6549096158457357

Epoch: 5| Step: 8
Training loss: 2.860256038489018
Validation loss: 2.65120957991133

Epoch: 5| Step: 9
Training loss: 3.231248164222535
Validation loss: 2.6558712201223944

Epoch: 5| Step: 10
Training loss: 3.033793375391256
Validation loss: 2.651614941505208

Epoch: 179| Step: 0
Training loss: 2.3768943459633536
Validation loss: 2.653391250026278

Epoch: 5| Step: 1
Training loss: 3.6299680669551706
Validation loss: 2.6577639498058647

Epoch: 5| Step: 2
Training loss: 2.7480676971492595
Validation loss: 2.6543139472297756

Epoch: 5| Step: 3
Training loss: 2.992531221333662
Validation loss: 2.6533190699652733

Epoch: 5| Step: 4
Training loss: 2.8251314284548275
Validation loss: 2.6536206052586615

Epoch: 5| Step: 5
Training loss: 2.763808693885835
Validation loss: 2.652304171140742

Epoch: 5| Step: 6
Training loss: 2.8351380453526516
Validation loss: 2.651781133062107

Epoch: 5| Step: 7
Training loss: 3.13864513639824
Validation loss: 2.6529657403998685

Epoch: 5| Step: 8
Training loss: 2.899462084374125
Validation loss: 2.653533749302096

Epoch: 5| Step: 9
Training loss: 2.9418157163327385
Validation loss: 2.6538782629107645

Epoch: 5| Step: 10
Training loss: 3.5364807008345864
Validation loss: 2.646141381111477

Epoch: 180| Step: 0
Training loss: 2.2386431709330403
Validation loss: 2.6518508298696033

Epoch: 5| Step: 1
Training loss: 2.9997332772260052
Validation loss: 2.656272144937104

Epoch: 5| Step: 2
Training loss: 2.7071332375606785
Validation loss: 2.656790522110521

Epoch: 5| Step: 3
Training loss: 3.0388800166634202
Validation loss: 2.651914014039048

Epoch: 5| Step: 4
Training loss: 2.7908525465991807
Validation loss: 2.662052637638769

Epoch: 5| Step: 5
Training loss: 3.317813426478705
Validation loss: 2.664708023548815

Epoch: 5| Step: 6
Training loss: 3.096501831606054
Validation loss: 2.658778619698835

Epoch: 5| Step: 7
Training loss: 3.344552344915298
Validation loss: 2.6515312762117063

Epoch: 5| Step: 8
Training loss: 3.123584579355848
Validation loss: 2.651115056890095

Epoch: 5| Step: 9
Training loss: 2.772244994920025
Validation loss: 2.6450150412735804

Epoch: 5| Step: 10
Training loss: 3.2409693624195355
Validation loss: 2.6498337484361967

Epoch: 181| Step: 0
Training loss: 3.0396486320218563
Validation loss: 2.649147102459634

Epoch: 5| Step: 1
Training loss: 2.549415772026212
Validation loss: 2.6470845772754936

Epoch: 5| Step: 2
Training loss: 2.8251528639493824
Validation loss: 2.6488738149951043

Epoch: 5| Step: 3
Training loss: 2.807861826977637
Validation loss: 2.6471454182408993

Epoch: 5| Step: 4
Training loss: 3.3980896519626844
Validation loss: 2.6509019282303696

Epoch: 5| Step: 5
Training loss: 2.8030639029386255
Validation loss: 2.647099052093755

Epoch: 5| Step: 6
Training loss: 2.7395666046985587
Validation loss: 2.6446898808104193

Epoch: 5| Step: 7
Training loss: 3.4934198650048423
Validation loss: 2.65162772383292

Epoch: 5| Step: 8
Training loss: 3.482912723268103
Validation loss: 2.6474168796291058

Epoch: 5| Step: 9
Training loss: 2.5349216911063555
Validation loss: 2.645935762641723

Epoch: 5| Step: 10
Training loss: 2.884167691237664
Validation loss: 2.6462201468832163

Epoch: 182| Step: 0
Training loss: 2.9798277719383446
Validation loss: 2.6446286140217987

Epoch: 5| Step: 1
Training loss: 2.7897045774846254
Validation loss: 2.650216394784652

Epoch: 5| Step: 2
Training loss: 3.487042282858969
Validation loss: 2.6468097179379177

Epoch: 5| Step: 3
Training loss: 2.4021248074138586
Validation loss: 2.64639851802031

Epoch: 5| Step: 4
Training loss: 2.581941680970565
Validation loss: 2.6487529776189906

Epoch: 5| Step: 5
Training loss: 3.020326418383282
Validation loss: 2.639747973486555

Epoch: 5| Step: 6
Training loss: 2.841370310017239
Validation loss: 2.641094759408978

Epoch: 5| Step: 7
Training loss: 3.1208424186489414
Validation loss: 2.6480712889112317

Epoch: 5| Step: 8
Training loss: 3.3088854376293337
Validation loss: 2.6448196673369337

Epoch: 5| Step: 9
Training loss: 3.0739842171496514
Validation loss: 2.646460118723899

Epoch: 5| Step: 10
Training loss: 3.049817977226488
Validation loss: 2.6493697603632156

Epoch: 183| Step: 0
Training loss: 3.2875264039810475
Validation loss: 2.6511390162564887

Epoch: 5| Step: 1
Training loss: 3.060728533915609
Validation loss: 2.646733221478444

Epoch: 5| Step: 2
Training loss: 3.107321056022798
Validation loss: 2.650429702378699

Epoch: 5| Step: 3
Training loss: 2.4246434293690524
Validation loss: 2.644344648064181

Epoch: 5| Step: 4
Training loss: 3.167372340495345
Validation loss: 2.645493834824319

Epoch: 5| Step: 5
Training loss: 2.901730376334252
Validation loss: 2.6438995657251843

Epoch: 5| Step: 6
Training loss: 3.2033165851145924
Validation loss: 2.6431423187334437

Epoch: 5| Step: 7
Training loss: 3.124780570909421
Validation loss: 2.637521833826992

Epoch: 5| Step: 8
Training loss: 2.791616088257178
Validation loss: 2.641400551414858

Epoch: 5| Step: 9
Training loss: 2.7963461775561096
Validation loss: 2.640181827849571

Epoch: 5| Step: 10
Training loss: 2.802505196694993
Validation loss: 2.638410717124562

Epoch: 184| Step: 0
Training loss: 3.4882820701811745
Validation loss: 2.6404484418402765

Epoch: 5| Step: 1
Training loss: 2.821686639762019
Validation loss: 2.6382415086060216

Epoch: 5| Step: 2
Training loss: 2.8403882287853133
Validation loss: 2.6428013867871174

Epoch: 5| Step: 3
Training loss: 3.0781277884068907
Validation loss: 2.637904796670788

Epoch: 5| Step: 4
Training loss: 3.032603482763118
Validation loss: 2.636935744264762

Epoch: 5| Step: 5
Training loss: 2.859776869919669
Validation loss: 2.641166461114819

Epoch: 5| Step: 6
Training loss: 2.8545117320469284
Validation loss: 2.638434539228265

Epoch: 5| Step: 7
Training loss: 3.176586841915926
Validation loss: 2.636555630626142

Epoch: 5| Step: 8
Training loss: 2.7758642620683425
Validation loss: 2.6389278932145297

Epoch: 5| Step: 9
Training loss: 3.308426853911185
Validation loss: 2.6498328477193733

Epoch: 5| Step: 10
Training loss: 2.2861626389687166
Validation loss: 2.6400025919310797

Epoch: 185| Step: 0
Training loss: 2.9114762762309545
Validation loss: 2.6347633501128764

Epoch: 5| Step: 1
Training loss: 2.9573771225336234
Validation loss: 2.6349200675338045

Epoch: 5| Step: 2
Training loss: 2.84611965840956
Validation loss: 2.6385817666583344

Epoch: 5| Step: 3
Training loss: 3.0294344469285526
Validation loss: 2.637827186719837

Epoch: 5| Step: 4
Training loss: 3.360312255700435
Validation loss: 2.6457554194733475

Epoch: 5| Step: 5
Training loss: 2.996624318956242
Validation loss: 2.638974000745244

Epoch: 5| Step: 6
Training loss: 2.3480117706380716
Validation loss: 2.638949009984593

Epoch: 5| Step: 7
Training loss: 2.8610624743363546
Validation loss: 2.640620434106572

Epoch: 5| Step: 8
Training loss: 3.201479605499418
Validation loss: 2.6355688428995467

Epoch: 5| Step: 9
Training loss: 2.8752688406594076
Validation loss: 2.6381455793136177

Epoch: 5| Step: 10
Training loss: 3.272724957176314
Validation loss: 2.6422277204192426

Epoch: 186| Step: 0
Training loss: 3.191527570942163
Validation loss: 2.63460014178303

Epoch: 5| Step: 1
Training loss: 2.7979468311114424
Validation loss: 2.6385436612831805

Epoch: 5| Step: 2
Training loss: 3.179392957987236
Validation loss: 2.637571116094575

Epoch: 5| Step: 3
Training loss: 3.269975456588984
Validation loss: 2.637309806446284

Epoch: 5| Step: 4
Training loss: 2.8607151247162435
Validation loss: 2.6349266018455553

Epoch: 5| Step: 5
Training loss: 3.1305276429644024
Validation loss: 2.639668395694109

Epoch: 5| Step: 6
Training loss: 2.619133342644611
Validation loss: 2.6383194051651944

Epoch: 5| Step: 7
Training loss: 2.81422252888389
Validation loss: 2.6344238571389136

Epoch: 5| Step: 8
Training loss: 2.689964672409706
Validation loss: 2.6390239737851005

Epoch: 5| Step: 9
Training loss: 3.230769114616588
Validation loss: 2.648117874251589

Epoch: 5| Step: 10
Training loss: 2.8587087052952698
Validation loss: 2.6453088853132964

Epoch: 187| Step: 0
Training loss: 2.950456493424752
Validation loss: 2.645560191302741

Epoch: 5| Step: 1
Training loss: 2.9628050055608726
Validation loss: 2.648359945090187

Epoch: 5| Step: 2
Training loss: 2.7968110657955334
Validation loss: 2.654614279207041

Epoch: 5| Step: 3
Training loss: 2.789370394255682
Validation loss: 2.650043800589498

Epoch: 5| Step: 4
Training loss: 3.3502335481224788
Validation loss: 2.647474277309445

Epoch: 5| Step: 5
Training loss: 2.6025482234829385
Validation loss: 2.6383068717330347

Epoch: 5| Step: 6
Training loss: 2.8878568024256186
Validation loss: 2.6336841539469162

Epoch: 5| Step: 7
Training loss: 2.5949983465229858
Validation loss: 2.631899284623065

Epoch: 5| Step: 8
Training loss: 2.8517986043093955
Validation loss: 2.6365895370367407

Epoch: 5| Step: 9
Training loss: 3.1534680485193167
Validation loss: 2.640316938369596

Epoch: 5| Step: 10
Training loss: 3.7438190383786534
Validation loss: 2.639762773085048

Epoch: 188| Step: 0
Training loss: 3.0189619033396093
Validation loss: 2.6407046567257924

Epoch: 5| Step: 1
Training loss: 2.601998232530819
Validation loss: 2.6390143021590786

Epoch: 5| Step: 2
Training loss: 3.3723979385349767
Validation loss: 2.6442823921394742

Epoch: 5| Step: 3
Training loss: 3.05984475384006
Validation loss: 2.6405150503544457

Epoch: 5| Step: 4
Training loss: 2.6619395637788132
Validation loss: 2.640530143714133

Epoch: 5| Step: 5
Training loss: 3.5382460437656316
Validation loss: 2.6391871834426537

Epoch: 5| Step: 6
Training loss: 2.431054518816024
Validation loss: 2.6375612651577787

Epoch: 5| Step: 7
Training loss: 2.8244299591990925
Validation loss: 2.6388600001528633

Epoch: 5| Step: 8
Training loss: 2.624522120255551
Validation loss: 2.6348472793035245

Epoch: 5| Step: 9
Training loss: 2.9445148875449134
Validation loss: 2.6301951801690406

Epoch: 5| Step: 10
Training loss: 3.621180528179115
Validation loss: 2.6347647833503736

Epoch: 189| Step: 0
Training loss: 2.8189502924027585
Validation loss: 2.6377192781048655

Epoch: 5| Step: 1
Training loss: 2.7542656846553353
Validation loss: 2.6363428535944817

Epoch: 5| Step: 2
Training loss: 2.98130920479325
Validation loss: 2.6473722632428993

Epoch: 5| Step: 3
Training loss: 3.5458278370570713
Validation loss: 2.669872568627621

Epoch: 5| Step: 4
Training loss: 3.2282453309607866
Validation loss: 2.67955603364208

Epoch: 5| Step: 5
Training loss: 2.8280910258070273
Validation loss: 2.658076673185046

Epoch: 5| Step: 6
Training loss: 2.6454414818419436
Validation loss: 2.653579527691036

Epoch: 5| Step: 7
Training loss: 2.9561213072171784
Validation loss: 2.6473772029028266

Epoch: 5| Step: 8
Training loss: 3.105247940754421
Validation loss: 2.6386770291460753

Epoch: 5| Step: 9
Training loss: 2.978622404592127
Validation loss: 2.6350569402720914

Epoch: 5| Step: 10
Training loss: 2.8686744098220474
Validation loss: 2.6303312778319556

Epoch: 190| Step: 0
Training loss: 2.8845763560858213
Validation loss: 2.634579471827412

Epoch: 5| Step: 1
Training loss: 2.37480132627214
Validation loss: 2.62961510679802

Epoch: 5| Step: 2
Training loss: 3.4207724271146582
Validation loss: 2.6346294717844545

Epoch: 5| Step: 3
Training loss: 2.988515328607791
Validation loss: 2.6353702345712096

Epoch: 5| Step: 4
Training loss: 2.821450973201067
Validation loss: 2.633641503872954

Epoch: 5| Step: 5
Training loss: 2.984919153904621
Validation loss: 2.63052101059584

Epoch: 5| Step: 6
Training loss: 3.3490205386224843
Validation loss: 2.631772354091216

Epoch: 5| Step: 7
Training loss: 2.7822949450288
Validation loss: 2.6288748150829266

Epoch: 5| Step: 8
Training loss: 2.4460699596241087
Validation loss: 2.6333672858022834

Epoch: 5| Step: 9
Training loss: 3.5175087184296383
Validation loss: 2.6305210125449907

Epoch: 5| Step: 10
Training loss: 2.9151386799875527
Validation loss: 2.641214321349687

Epoch: 191| Step: 0
Training loss: 3.104995326777334
Validation loss: 2.6369996532935054

Epoch: 5| Step: 1
Training loss: 3.108286758223909
Validation loss: 2.63949106452413

Epoch: 5| Step: 2
Training loss: 2.935899338974153
Validation loss: 2.6348887286871547

Epoch: 5| Step: 3
Training loss: 3.2103731350894256
Validation loss: 2.6388875477356915

Epoch: 5| Step: 4
Training loss: 3.0199339130572707
Validation loss: 2.635679536765814

Epoch: 5| Step: 5
Training loss: 2.639845964533003
Validation loss: 2.6400660023699816

Epoch: 5| Step: 6
Training loss: 3.439203013868979
Validation loss: 2.6370376886238307

Epoch: 5| Step: 7
Training loss: 2.5772478865747006
Validation loss: 2.6393328594555907

Epoch: 5| Step: 8
Training loss: 2.8225879735895467
Validation loss: 2.6316997233094916

Epoch: 5| Step: 9
Training loss: 3.3354983610258677
Validation loss: 2.635431132936947

Epoch: 5| Step: 10
Training loss: 2.142122287995836
Validation loss: 2.628549635940181

Epoch: 192| Step: 0
Training loss: 2.692026717332552
Validation loss: 2.6354033254875633

Epoch: 5| Step: 1
Training loss: 2.901789862661226
Validation loss: 2.62983756719878

Epoch: 5| Step: 2
Training loss: 2.593751194965133
Validation loss: 2.6343072305951765

Epoch: 5| Step: 3
Training loss: 2.29154089380241
Validation loss: 2.6379441561925123

Epoch: 5| Step: 4
Training loss: 2.689771269110639
Validation loss: 2.6318516670311167

Epoch: 5| Step: 5
Training loss: 3.0339252425396603
Validation loss: 2.628808518210226

Epoch: 5| Step: 6
Training loss: 3.4351154726656388
Validation loss: 2.6265178458405054

Epoch: 5| Step: 7
Training loss: 3.3080846761915748
Validation loss: 2.6291407444738875

Epoch: 5| Step: 8
Training loss: 2.914444231081876
Validation loss: 2.6270563877113404

Epoch: 5| Step: 9
Training loss: 3.299766104529909
Validation loss: 2.6303529387524587

Epoch: 5| Step: 10
Training loss: 3.3288848439378644
Validation loss: 2.628330362366009

Epoch: 193| Step: 0
Training loss: 3.247486756659706
Validation loss: 2.629287257920627

Epoch: 5| Step: 1
Training loss: 3.245384313223187
Validation loss: 2.6265772247931434

Epoch: 5| Step: 2
Training loss: 3.145611500444859
Validation loss: 2.630063076307067

Epoch: 5| Step: 3
Training loss: 3.1673807710941038
Validation loss: 2.6289542710226

Epoch: 5| Step: 4
Training loss: 2.9357625814793766
Validation loss: 2.628749804054856

Epoch: 5| Step: 5
Training loss: 3.2701954958744888
Validation loss: 2.627306120995358

Epoch: 5| Step: 6
Training loss: 2.443639701051673
Validation loss: 2.6252373579760206

Epoch: 5| Step: 7
Training loss: 3.0046358846991064
Validation loss: 2.6274793901709708

Epoch: 5| Step: 8
Training loss: 2.8881866893606616
Validation loss: 2.6293767907093577

Epoch: 5| Step: 9
Training loss: 2.5971923413883893
Validation loss: 2.631096192694393

Epoch: 5| Step: 10
Training loss: 2.520590011160882
Validation loss: 2.6334687034103776

Epoch: 194| Step: 0
Training loss: 3.054344997083017
Validation loss: 2.632658003940085

Epoch: 5| Step: 1
Training loss: 3.0761033598520653
Validation loss: 2.6359822437572134

Epoch: 5| Step: 2
Training loss: 2.431288409481303
Validation loss: 2.6311288453173263

Epoch: 5| Step: 3
Training loss: 2.8206549354687347
Validation loss: 2.631938957986216

Epoch: 5| Step: 4
Training loss: 3.075193451789688
Validation loss: 2.633930200676937

Epoch: 5| Step: 5
Training loss: 2.7061613812814835
Validation loss: 2.6343861665161703

Epoch: 5| Step: 6
Training loss: 3.342470441186806
Validation loss: 2.6284849245556288

Epoch: 5| Step: 7
Training loss: 3.0144397995809853
Validation loss: 2.6386439151608916

Epoch: 5| Step: 8
Training loss: 2.688554423874793
Validation loss: 2.640176095491003

Epoch: 5| Step: 9
Training loss: 3.1400689539050446
Validation loss: 2.638599575988656

Epoch: 5| Step: 10
Training loss: 3.187900293684027
Validation loss: 2.631662537248896

Epoch: 195| Step: 0
Training loss: 2.605192567293847
Validation loss: 2.6355943073165204

Epoch: 5| Step: 1
Training loss: 2.6991627490007457
Validation loss: 2.6329328002495624

Epoch: 5| Step: 2
Training loss: 2.9066132349242
Validation loss: 2.636044665559446

Epoch: 5| Step: 3
Training loss: 2.9912102998489365
Validation loss: 2.6361484984400088

Epoch: 5| Step: 4
Training loss: 2.615544136283159
Validation loss: 2.6320243233343117

Epoch: 5| Step: 5
Training loss: 2.9265640902374885
Validation loss: 2.638648550541459

Epoch: 5| Step: 6
Training loss: 3.6149126648542875
Validation loss: 2.6369281727257223

Epoch: 5| Step: 7
Training loss: 3.0230925607192827
Validation loss: 2.646690536622408

Epoch: 5| Step: 8
Training loss: 2.64550573969211
Validation loss: 2.6311562146690926

Epoch: 5| Step: 9
Training loss: 3.0162362383494146
Validation loss: 2.6317464055718447

Epoch: 5| Step: 10
Training loss: 3.538127042914338
Validation loss: 2.627079767273854

Epoch: 196| Step: 0
Training loss: 2.95443292950382
Validation loss: 2.6254644027069265

Epoch: 5| Step: 1
Training loss: 3.192258685975884
Validation loss: 2.62561539596524

Epoch: 5| Step: 2
Training loss: 2.8289886336194336
Validation loss: 2.624735027286354

Epoch: 5| Step: 3
Training loss: 2.6261743915755176
Validation loss: 2.6243593134317216

Epoch: 5| Step: 4
Training loss: 3.0378964891410227
Validation loss: 2.6217279007714955

Epoch: 5| Step: 5
Training loss: 3.095228362155465
Validation loss: 2.622368086438059

Epoch: 5| Step: 6
Training loss: 2.23869141553672
Validation loss: 2.6277692146939042

Epoch: 5| Step: 7
Training loss: 2.8826293887157934
Validation loss: 2.621782609589045

Epoch: 5| Step: 8
Training loss: 3.500573383775543
Validation loss: 2.6243101933482764

Epoch: 5| Step: 9
Training loss: 3.411693178591626
Validation loss: 2.6235352808392105

Epoch: 5| Step: 10
Training loss: 2.54785904859479
Validation loss: 2.6233739538647103

Epoch: 197| Step: 0
Training loss: 2.5970348102409075
Validation loss: 2.622190858226273

Epoch: 5| Step: 1
Training loss: 3.2988386769461937
Validation loss: 2.631734064398206

Epoch: 5| Step: 2
Training loss: 2.431259088572796
Validation loss: 2.6343396984161083

Epoch: 5| Step: 3
Training loss: 3.2082364121366846
Validation loss: 2.643760583036453

Epoch: 5| Step: 4
Training loss: 3.008887319375021
Validation loss: 2.652436249796828

Epoch: 5| Step: 5
Training loss: 3.0688112582989686
Validation loss: 2.634169578277225

Epoch: 5| Step: 6
Training loss: 3.2169880905713546
Validation loss: 2.63134525516278

Epoch: 5| Step: 7
Training loss: 2.8065529572686003
Validation loss: 2.6220103435907895

Epoch: 5| Step: 8
Training loss: 3.561692263401599
Validation loss: 2.618854953554943

Epoch: 5| Step: 9
Training loss: 2.265014355679254
Validation loss: 2.6169196388332114

Epoch: 5| Step: 10
Training loss: 2.8901472367000074
Validation loss: 2.6210993504828504

Epoch: 198| Step: 0
Training loss: 2.990036472621192
Validation loss: 2.6217388496667824

Epoch: 5| Step: 1
Training loss: 2.8694410900364296
Validation loss: 2.6237739262305837

Epoch: 5| Step: 2
Training loss: 3.081205888474974
Validation loss: 2.6271348857353476

Epoch: 5| Step: 3
Training loss: 2.9836062095204134
Validation loss: 2.6257204199113846

Epoch: 5| Step: 4
Training loss: 2.8165052928255188
Validation loss: 2.6233435794152657

Epoch: 5| Step: 5
Training loss: 2.6636407691760535
Validation loss: 2.6262692372912975

Epoch: 5| Step: 6
Training loss: 3.4233726812204317
Validation loss: 2.6231915621387145

Epoch: 5| Step: 7
Training loss: 3.020242111404154
Validation loss: 2.6229095240991924

Epoch: 5| Step: 8
Training loss: 2.757790541088657
Validation loss: 2.62259912151473

Epoch: 5| Step: 9
Training loss: 3.0608054942183927
Validation loss: 2.6236353333479814

Epoch: 5| Step: 10
Training loss: 3.000311517436174
Validation loss: 2.624269687612355

Epoch: 199| Step: 0
Training loss: 2.8874926942675097
Validation loss: 2.623416580306072

Epoch: 5| Step: 1
Training loss: 3.375291741088965
Validation loss: 2.624335209215937

Epoch: 5| Step: 2
Training loss: 3.0539379712533754
Validation loss: 2.629135881711139

Epoch: 5| Step: 3
Training loss: 2.602631403732355
Validation loss: 2.6359289306098295

Epoch: 5| Step: 4
Training loss: 3.0841314124918613
Validation loss: 2.6329729185846578

Epoch: 5| Step: 5
Training loss: 2.981005778995864
Validation loss: 2.640301764171985

Epoch: 5| Step: 6
Training loss: 2.769441288400287
Validation loss: 2.6364269658766113

Epoch: 5| Step: 7
Training loss: 2.918174807870418
Validation loss: 2.6362583710409937

Epoch: 5| Step: 8
Training loss: 2.503379540234968
Validation loss: 2.6340412106173843

Epoch: 5| Step: 9
Training loss: 2.875144125601525
Validation loss: 2.632686768392939

Epoch: 5| Step: 10
Training loss: 3.497562240690284
Validation loss: 2.628782019667654

Epoch: 200| Step: 0
Training loss: 2.6574408161969205
Validation loss: 2.6222385515295286

Epoch: 5| Step: 1
Training loss: 3.049265388446812
Validation loss: 2.6203167357215986

Epoch: 5| Step: 2
Training loss: 3.0889355739050837
Validation loss: 2.621043489874533

Epoch: 5| Step: 3
Training loss: 3.260898802253016
Validation loss: 2.62056902478633

Epoch: 5| Step: 4
Training loss: 2.4763223910738463
Validation loss: 2.6184416987083337

Epoch: 5| Step: 5
Training loss: 3.5327601621682896
Validation loss: 2.620414886948562

Epoch: 5| Step: 6
Training loss: 2.5227174469727562
Validation loss: 2.6184928879621876

Epoch: 5| Step: 7
Training loss: 2.5929221245325476
Validation loss: 2.615557789817178

Epoch: 5| Step: 8
Training loss: 3.171557631376587
Validation loss: 2.6180666729284363

Epoch: 5| Step: 9
Training loss: 3.1567542551437486
Validation loss: 2.6182675357461274

Epoch: 5| Step: 10
Training loss: 2.8842526691983545
Validation loss: 2.6152671923350455

Epoch: 201| Step: 0
Training loss: 2.6355135953867714
Validation loss: 2.620149876166036

Epoch: 5| Step: 1
Training loss: 3.0380143660205055
Validation loss: 2.6217377202615513

Epoch: 5| Step: 2
Training loss: 2.7490249118834855
Validation loss: 2.6250736892287465

Epoch: 5| Step: 3
Training loss: 2.835589931406556
Validation loss: 2.6193967474379263

Epoch: 5| Step: 4
Training loss: 3.363840231704109
Validation loss: 2.622280314598158

Epoch: 5| Step: 5
Training loss: 3.2841120272542703
Validation loss: 2.6310095246736984

Epoch: 5| Step: 6
Training loss: 2.852057761464772
Validation loss: 2.6280858701124017

Epoch: 5| Step: 7
Training loss: 2.866703002906398
Validation loss: 2.625722085575979

Epoch: 5| Step: 8
Training loss: 2.4573071056580074
Validation loss: 2.634561548717485

Epoch: 5| Step: 9
Training loss: 3.331291161259614
Validation loss: 2.648141124018461

Epoch: 5| Step: 10
Training loss: 3.039625257935458
Validation loss: 2.6321261783841354

Epoch: 202| Step: 0
Training loss: 3.7565715430017343
Validation loss: 2.621679610483597

Epoch: 5| Step: 1
Training loss: 3.2066718584310756
Validation loss: 2.622246860593259

Epoch: 5| Step: 2
Training loss: 2.6626328018809855
Validation loss: 2.6196827414582495

Epoch: 5| Step: 3
Training loss: 2.821781272641213
Validation loss: 2.6178746141383797

Epoch: 5| Step: 4
Training loss: 2.6315500192558026
Validation loss: 2.6170181163278166

Epoch: 5| Step: 5
Training loss: 3.0371936847723098
Validation loss: 2.618254766799259

Epoch: 5| Step: 6
Training loss: 2.6171391269142044
Validation loss: 2.616250156961337

Epoch: 5| Step: 7
Training loss: 2.5380992764294543
Validation loss: 2.6186922554958354

Epoch: 5| Step: 8
Training loss: 3.3005996563860696
Validation loss: 2.618003329916712

Epoch: 5| Step: 9
Training loss: 2.4201078797562317
Validation loss: 2.619108784122119

Epoch: 5| Step: 10
Training loss: 3.3711518849546227
Validation loss: 2.6161665630631306

Epoch: 203| Step: 0
Training loss: 3.0742334852628908
Validation loss: 2.6201384656576283

Epoch: 5| Step: 1
Training loss: 2.848136118368447
Validation loss: 2.616047540921407

Epoch: 5| Step: 2
Training loss: 2.8882997800621104
Validation loss: 2.618689705258367

Epoch: 5| Step: 3
Training loss: 3.073300836547146
Validation loss: 2.612023254329333

Epoch: 5| Step: 4
Training loss: 2.784710820386909
Validation loss: 2.61248472071601

Epoch: 5| Step: 5
Training loss: 2.5013717702557186
Validation loss: 2.613691809330107

Epoch: 5| Step: 6
Training loss: 2.825764635294024
Validation loss: 2.6171279491493458

Epoch: 5| Step: 7
Training loss: 2.9158275668805027
Validation loss: 2.622887125827691

Epoch: 5| Step: 8
Training loss: 3.2402524757914404
Validation loss: 2.6230430711424773

Epoch: 5| Step: 9
Training loss: 3.309553887536699
Validation loss: 2.629728446530867

Epoch: 5| Step: 10
Training loss: 3.0714811086121827
Validation loss: 2.614468329357827

Epoch: 204| Step: 0
Training loss: 3.184067018119893
Validation loss: 2.616813020909079

Epoch: 5| Step: 1
Training loss: 2.9529338149092292
Validation loss: 2.6155333721905167

Epoch: 5| Step: 2
Training loss: 2.7573486456744076
Validation loss: 2.6172835784061075

Epoch: 5| Step: 3
Training loss: 3.208467373380531
Validation loss: 2.6133275392678232

Epoch: 5| Step: 4
Training loss: 3.1505263902957084
Validation loss: 2.614747303140847

Epoch: 5| Step: 5
Training loss: 3.27097973020099
Validation loss: 2.617333770665952

Epoch: 5| Step: 6
Training loss: 2.766525380613666
Validation loss: 2.6189365547729504

Epoch: 5| Step: 7
Training loss: 2.5306405169613533
Validation loss: 2.61947757427687

Epoch: 5| Step: 8
Training loss: 2.973262689917323
Validation loss: 2.6131215925284446

Epoch: 5| Step: 9
Training loss: 2.6889838624457933
Validation loss: 2.6154534070822226

Epoch: 5| Step: 10
Training loss: 3.0132318201379875
Validation loss: 2.617508221025414

Epoch: 205| Step: 0
Training loss: 2.8281072120739377
Validation loss: 2.6163766108308653

Epoch: 5| Step: 1
Training loss: 2.811300233737305
Validation loss: 2.6158421160632073

Epoch: 5| Step: 2
Training loss: 2.734053849025534
Validation loss: 2.6124577062698062

Epoch: 5| Step: 3
Training loss: 2.607101637930614
Validation loss: 2.6177093352948995

Epoch: 5| Step: 4
Training loss: 2.9337276829446495
Validation loss: 2.6166306465428137

Epoch: 5| Step: 5
Training loss: 3.1419999638101537
Validation loss: 2.618514396666705

Epoch: 5| Step: 6
Training loss: 2.916884132634152
Validation loss: 2.6233346845465926

Epoch: 5| Step: 7
Training loss: 3.4622194142045255
Validation loss: 2.6226993680887825

Epoch: 5| Step: 8
Training loss: 2.815889731778726
Validation loss: 2.6288995622492135

Epoch: 5| Step: 9
Training loss: 2.9380038214880058
Validation loss: 2.626464549461768

Epoch: 5| Step: 10
Training loss: 3.300881071669229
Validation loss: 2.637502007133025

Epoch: 206| Step: 0
Training loss: 2.1590983057579853
Validation loss: 2.624486976608024

Epoch: 5| Step: 1
Training loss: 2.8423904690403132
Validation loss: 2.6315704519245906

Epoch: 5| Step: 2
Training loss: 2.5923504098168966
Validation loss: 2.6351819244928274

Epoch: 5| Step: 3
Training loss: 3.52328984866801
Validation loss: 2.6253819693134823

Epoch: 5| Step: 4
Training loss: 2.9543690155272118
Validation loss: 2.615672223821409

Epoch: 5| Step: 5
Training loss: 3.1954994799834826
Validation loss: 2.6189788599314774

Epoch: 5| Step: 6
Training loss: 2.9642325312822067
Validation loss: 2.6125085250700484

Epoch: 5| Step: 7
Training loss: 2.9066585130606333
Validation loss: 2.6131461043081674

Epoch: 5| Step: 8
Training loss: 2.892218238341602
Validation loss: 2.614768243603191

Epoch: 5| Step: 9
Training loss: 3.315579835977815
Validation loss: 2.612251133523635

Epoch: 5| Step: 10
Training loss: 2.954285408793695
Validation loss: 2.6086549954963836

Epoch: 207| Step: 0
Training loss: 3.2324770458849126
Validation loss: 2.6138887429377267

Epoch: 5| Step: 1
Training loss: 2.528081252729835
Validation loss: 2.6145602561351584

Epoch: 5| Step: 2
Training loss: 3.0047038077369628
Validation loss: 2.6140921480682686

Epoch: 5| Step: 3
Training loss: 2.331123111329507
Validation loss: 2.6072745173043117

Epoch: 5| Step: 4
Training loss: 3.1403144948632056
Validation loss: 2.6108545779364345

Epoch: 5| Step: 5
Training loss: 3.194333698361719
Validation loss: 2.61273530125249

Epoch: 5| Step: 6
Training loss: 2.800406927103085
Validation loss: 2.6189572835833363

Epoch: 5| Step: 7
Training loss: 2.611958121724921
Validation loss: 2.625322389508929

Epoch: 5| Step: 8
Training loss: 2.807148738093648
Validation loss: 2.632328280428628

Epoch: 5| Step: 9
Training loss: 3.340131852065809
Validation loss: 2.656254399083046

Epoch: 5| Step: 10
Training loss: 3.416300932375085
Validation loss: 2.653703501387705

Epoch: 208| Step: 0
Training loss: 3.015698684029365
Validation loss: 2.6659422692961043

Epoch: 5| Step: 1
Training loss: 2.8767461035388706
Validation loss: 2.664879414027154

Epoch: 5| Step: 2
Training loss: 2.8479270021427325
Validation loss: 2.655562539750143

Epoch: 5| Step: 3
Training loss: 2.246139923947945
Validation loss: 2.6479971921353385

Epoch: 5| Step: 4
Training loss: 3.1542093459701697
Validation loss: 2.6337931136460355

Epoch: 5| Step: 5
Training loss: 3.269361922278599
Validation loss: 2.6177049106103008

Epoch: 5| Step: 6
Training loss: 2.7534804427569517
Validation loss: 2.6095179439496805

Epoch: 5| Step: 7
Training loss: 3.145363644194997
Validation loss: 2.607122121592436

Epoch: 5| Step: 8
Training loss: 2.74006227046626
Validation loss: 2.6112938169506545

Epoch: 5| Step: 9
Training loss: 3.3353252340377666
Validation loss: 2.609377173229499

Epoch: 5| Step: 10
Training loss: 3.0128246211613408
Validation loss: 2.6180177021101687

Epoch: 209| Step: 0
Training loss: 3.6213069388008696
Validation loss: 2.6166126935649174

Epoch: 5| Step: 1
Training loss: 2.6402351949424956
Validation loss: 2.6175392018643753

Epoch: 5| Step: 2
Training loss: 3.1699799387203775
Validation loss: 2.6131991082222306

Epoch: 5| Step: 3
Training loss: 3.083113757038941
Validation loss: 2.618983063686629

Epoch: 5| Step: 4
Training loss: 3.154863562921061
Validation loss: 2.6137773361232512

Epoch: 5| Step: 5
Training loss: 2.7650954607028155
Validation loss: 2.616083942527654

Epoch: 5| Step: 6
Training loss: 2.8253315148749025
Validation loss: 2.6159049194754247

Epoch: 5| Step: 7
Training loss: 2.828228184624897
Validation loss: 2.610817582996267

Epoch: 5| Step: 8
Training loss: 2.573931526055807
Validation loss: 2.6124252638362075

Epoch: 5| Step: 9
Training loss: 3.208736212730137
Validation loss: 2.610585843075497

Epoch: 5| Step: 10
Training loss: 2.5139702513883737
Validation loss: 2.6070382379565937

Epoch: 210| Step: 0
Training loss: 3.12847402113678
Validation loss: 2.608743539248493

Epoch: 5| Step: 1
Training loss: 2.6778276845978044
Validation loss: 2.615298279121328

Epoch: 5| Step: 2
Training loss: 3.350738637541618
Validation loss: 2.61740138368088

Epoch: 5| Step: 3
Training loss: 2.882452882909343
Validation loss: 2.6186824803878714

Epoch: 5| Step: 4
Training loss: 3.179040941491352
Validation loss: 2.6143761149760185

Epoch: 5| Step: 5
Training loss: 2.854626156837405
Validation loss: 2.6137083836874777

Epoch: 5| Step: 6
Training loss: 2.6671845608713487
Validation loss: 2.6103425280958397

Epoch: 5| Step: 7
Training loss: 3.025851761882544
Validation loss: 2.6101339895646714

Epoch: 5| Step: 8
Training loss: 2.904079159732257
Validation loss: 2.61326807703853

Epoch: 5| Step: 9
Training loss: 2.358416533153921
Validation loss: 2.608942351770721

Epoch: 5| Step: 10
Training loss: 3.41135548832135
Validation loss: 2.606081512002728

Epoch: 211| Step: 0
Training loss: 2.4305037816906396
Validation loss: 2.6125863395955333

Epoch: 5| Step: 1
Training loss: 3.210859682945434
Validation loss: 2.611653173021652

Epoch: 5| Step: 2
Training loss: 3.05686790913173
Validation loss: 2.611890461047392

Epoch: 5| Step: 3
Training loss: 2.6981248419335033
Validation loss: 2.6100692154683425

Epoch: 5| Step: 4
Training loss: 3.058382029409894
Validation loss: 2.6104699231718747

Epoch: 5| Step: 5
Training loss: 3.4476930175037825
Validation loss: 2.615753504854997

Epoch: 5| Step: 6
Training loss: 3.0352194054119477
Validation loss: 2.6113761570825984

Epoch: 5| Step: 7
Training loss: 2.3577917989197483
Validation loss: 2.6151030064503757

Epoch: 5| Step: 8
Training loss: 2.458409733851261
Validation loss: 2.61733682078221

Epoch: 5| Step: 9
Training loss: 3.0419935982641193
Validation loss: 2.6124850445461743

Epoch: 5| Step: 10
Training loss: 3.525051111161895
Validation loss: 2.614957427657073

Epoch: 212| Step: 0
Training loss: 2.6696170836624806
Validation loss: 2.6092877726190338

Epoch: 5| Step: 1
Training loss: 2.7122027607855563
Validation loss: 2.612118850398572

Epoch: 5| Step: 2
Training loss: 2.902400595107012
Validation loss: 2.6122460420604106

Epoch: 5| Step: 3
Training loss: 2.569076194378671
Validation loss: 2.6125737911431886

Epoch: 5| Step: 4
Training loss: 3.152023960990649
Validation loss: 2.6076411607127237

Epoch: 5| Step: 5
Training loss: 3.9605235950069084
Validation loss: 2.613546229422317

Epoch: 5| Step: 6
Training loss: 2.6970101580119112
Validation loss: 2.60672167915588

Epoch: 5| Step: 7
Training loss: 3.0284450176879045
Validation loss: 2.6076096503409367

Epoch: 5| Step: 8
Training loss: 2.9031595184934873
Validation loss: 2.6068522024371723

Epoch: 5| Step: 9
Training loss: 2.8427268063420383
Validation loss: 2.602725295992484

Epoch: 5| Step: 10
Training loss: 2.7316179599419
Validation loss: 2.6063693841386923

Epoch: 213| Step: 0
Training loss: 2.9081208145042616
Validation loss: 2.604909517390072

Epoch: 5| Step: 1
Training loss: 2.6819636962276916
Validation loss: 2.6094807217840437

Epoch: 5| Step: 2
Training loss: 3.2436967025817696
Validation loss: 2.6072228954037864

Epoch: 5| Step: 3
Training loss: 3.122574437081093
Validation loss: 2.6027493324260056

Epoch: 5| Step: 4
Training loss: 2.7525816850035874
Validation loss: 2.6032107735486325

Epoch: 5| Step: 5
Training loss: 2.6318130180762234
Validation loss: 2.607867782125672

Epoch: 5| Step: 6
Training loss: 3.001867031235357
Validation loss: 2.6050156861126372

Epoch: 5| Step: 7
Training loss: 2.8571854009185627
Validation loss: 2.609906563993298

Epoch: 5| Step: 8
Training loss: 3.098505545911124
Validation loss: 2.6109737425415154

Epoch: 5| Step: 9
Training loss: 3.1083683703973097
Validation loss: 2.602879236430989

Epoch: 5| Step: 10
Training loss: 2.994328064348628
Validation loss: 2.6191980398881305

Epoch: 214| Step: 0
Training loss: 3.522686051382036
Validation loss: 2.6129310030215893

Epoch: 5| Step: 1
Training loss: 3.3142288302956673
Validation loss: 2.615563267873355

Epoch: 5| Step: 2
Training loss: 3.271733753321702
Validation loss: 2.6219518849279404

Epoch: 5| Step: 3
Training loss: 2.69263880705708
Validation loss: 2.6208990920410264

Epoch: 5| Step: 4
Training loss: 2.504186938854894
Validation loss: 2.61814177834191

Epoch: 5| Step: 5
Training loss: 2.7605062410228443
Validation loss: 2.6214484396029323

Epoch: 5| Step: 6
Training loss: 3.044043531109092
Validation loss: 2.612349830186022

Epoch: 5| Step: 7
Training loss: 3.142178127705441
Validation loss: 2.6125189012590586

Epoch: 5| Step: 8
Training loss: 3.0483139943767257
Validation loss: 2.6073550346127456

Epoch: 5| Step: 9
Training loss: 2.6485302214019004
Validation loss: 2.609104255678175

Epoch: 5| Step: 10
Training loss: 2.062114563964512
Validation loss: 2.605591651800052

Epoch: 215| Step: 0
Training loss: 3.0403042881913844
Validation loss: 2.6004988086561736

Epoch: 5| Step: 1
Training loss: 2.6012586811439586
Validation loss: 2.6051492824959417

Epoch: 5| Step: 2
Training loss: 2.2536546907250132
Validation loss: 2.6001146155195247

Epoch: 5| Step: 3
Training loss: 2.198185788231404
Validation loss: 2.6005246292956405

Epoch: 5| Step: 4
Training loss: 3.3407490891907328
Validation loss: 2.6035462504670877

Epoch: 5| Step: 5
Training loss: 3.421683528194017
Validation loss: 2.6026477412014497

Epoch: 5| Step: 6
Training loss: 2.9766405150434845
Validation loss: 2.6023058366549354

Epoch: 5| Step: 7
Training loss: 3.2095362072120754
Validation loss: 2.6035884325145555

Epoch: 5| Step: 8
Training loss: 3.2634287480506625
Validation loss: 2.603082967072975

Epoch: 5| Step: 9
Training loss: 2.5293537148234453
Validation loss: 2.6009035013350688

Epoch: 5| Step: 10
Training loss: 3.270645881351445
Validation loss: 2.605530593225934

Epoch: 216| Step: 0
Training loss: 2.642724912052882
Validation loss: 2.6051176740820545

Epoch: 5| Step: 1
Training loss: 2.9410145614040446
Validation loss: 2.6103551471826263

Epoch: 5| Step: 2
Training loss: 3.2512674061193043
Validation loss: 2.6093152993416813

Epoch: 5| Step: 3
Training loss: 2.9614492492500677
Validation loss: 2.6102359808549522

Epoch: 5| Step: 4
Training loss: 3.3483253620433215
Validation loss: 2.611014667605662

Epoch: 5| Step: 5
Training loss: 1.9772562008349435
Validation loss: 2.6326816453655177

Epoch: 5| Step: 6
Training loss: 2.9263434691169055
Validation loss: 2.6403120563810574

Epoch: 5| Step: 7
Training loss: 3.3589384993033216
Validation loss: 2.6315257139736987

Epoch: 5| Step: 8
Training loss: 2.7829689114719263
Validation loss: 2.629996798665552

Epoch: 5| Step: 9
Training loss: 3.262188138708671
Validation loss: 2.637798992935637

Epoch: 5| Step: 10
Training loss: 2.7460252473841607
Validation loss: 2.62140920696367

Epoch: 217| Step: 0
Training loss: 3.6719739535369937
Validation loss: 2.602146751070874

Epoch: 5| Step: 1
Training loss: 2.591564130645721
Validation loss: 2.5986261218151565

Epoch: 5| Step: 2
Training loss: 2.881286217054356
Validation loss: 2.600974484600922

Epoch: 5| Step: 3
Training loss: 2.886869888581935
Validation loss: 2.601117452596579

Epoch: 5| Step: 4
Training loss: 2.904741121138846
Validation loss: 2.601282310308237

Epoch: 5| Step: 5
Training loss: 2.9143457351776143
Validation loss: 2.602094341728257

Epoch: 5| Step: 6
Training loss: 2.3517139677521595
Validation loss: 2.6038243347269105

Epoch: 5| Step: 7
Training loss: 3.3861239745893923
Validation loss: 2.608493730046119

Epoch: 5| Step: 8
Training loss: 2.652899030895718
Validation loss: 2.604606743001396

Epoch: 5| Step: 9
Training loss: 3.0459513511354523
Validation loss: 2.6051400725994953

Epoch: 5| Step: 10
Training loss: 2.9807847081769365
Validation loss: 2.606455360215296

Epoch: 218| Step: 0
Training loss: 3.3794767570661426
Validation loss: 2.609873566289288

Epoch: 5| Step: 1
Training loss: 3.483645786222702
Validation loss: 2.6095857024898015

Epoch: 5| Step: 2
Training loss: 2.896683730443541
Validation loss: 2.6135303347889223

Epoch: 5| Step: 3
Training loss: 2.7350169273006064
Validation loss: 2.613893244697955

Epoch: 5| Step: 4
Training loss: 2.8033848874873706
Validation loss: 2.6223677970669086

Epoch: 5| Step: 5
Training loss: 2.4877283269478463
Validation loss: 2.6232649112593

Epoch: 5| Step: 6
Training loss: 2.973450483172522
Validation loss: 2.6219830576986305

Epoch: 5| Step: 7
Training loss: 2.842586069540224
Validation loss: 2.616808232716354

Epoch: 5| Step: 8
Training loss: 2.6900284871291165
Validation loss: 2.607751239042389

Epoch: 5| Step: 9
Training loss: 2.961733265737806
Validation loss: 2.603248228158093

Epoch: 5| Step: 10
Training loss: 2.9549004601561712
Validation loss: 2.608018988107045

Epoch: 219| Step: 0
Training loss: 3.25659215377896
Validation loss: 2.609331835671661

Epoch: 5| Step: 1
Training loss: 2.7765107656112513
Validation loss: 2.607610430952544

Epoch: 5| Step: 2
Training loss: 2.9617946058584956
Validation loss: 2.6111609944268332

Epoch: 5| Step: 3
Training loss: 3.038611528135984
Validation loss: 2.598272653162805

Epoch: 5| Step: 4
Training loss: 2.6963294722897695
Validation loss: 2.6119604429747745

Epoch: 5| Step: 5
Training loss: 3.275973045871689
Validation loss: 2.6055264715705815

Epoch: 5| Step: 6
Training loss: 3.048871603930047
Validation loss: 2.6070920848644645

Epoch: 5| Step: 7
Training loss: 3.0439017632030705
Validation loss: 2.602406124142866

Epoch: 5| Step: 8
Training loss: 2.5632659883751128
Validation loss: 2.6045642590288454

Epoch: 5| Step: 9
Training loss: 3.021211499626611
Validation loss: 2.598618882597083

Epoch: 5| Step: 10
Training loss: 2.546183392754213
Validation loss: 2.5964881606577563

Epoch: 220| Step: 0
Training loss: 2.4864095358394462
Validation loss: 2.600810809941419

Epoch: 5| Step: 1
Training loss: 3.03261857746756
Validation loss: 2.5962252577115192

Epoch: 5| Step: 2
Training loss: 3.408000251393913
Validation loss: 2.5993630018593654

Epoch: 5| Step: 3
Training loss: 2.7561463247855964
Validation loss: 2.596876933888843

Epoch: 5| Step: 4
Training loss: 3.3888669004578147
Validation loss: 2.5942690947979754

Epoch: 5| Step: 5
Training loss: 2.646599866310727
Validation loss: 2.600211042795148

Epoch: 5| Step: 6
Training loss: 2.8959856793697627
Validation loss: 2.5983094202159536

Epoch: 5| Step: 7
Training loss: 2.6415020090124752
Validation loss: 2.596629163137481

Epoch: 5| Step: 8
Training loss: 2.893941100959934
Validation loss: 2.5940898757090673

Epoch: 5| Step: 9
Training loss: 2.7787592160736607
Validation loss: 2.599833563753873

Epoch: 5| Step: 10
Training loss: 3.334315743317548
Validation loss: 2.603636043181707

Epoch: 221| Step: 0
Training loss: 3.211034026168504
Validation loss: 2.5960140337285114

Epoch: 5| Step: 1
Training loss: 2.8440794701505334
Validation loss: 2.598011397137625

Epoch: 5| Step: 2
Training loss: 2.982567684304093
Validation loss: 2.598458074613632

Epoch: 5| Step: 3
Training loss: 3.3289788095677
Validation loss: 2.6011325133848175

Epoch: 5| Step: 4
Training loss: 2.8161290808809003
Validation loss: 2.5963102520003125

Epoch: 5| Step: 5
Training loss: 3.0377393651767806
Validation loss: 2.604729180074767

Epoch: 5| Step: 6
Training loss: 2.9034572842311595
Validation loss: 2.6024522206903415

Epoch: 5| Step: 7
Training loss: 2.6895209409852696
Validation loss: 2.6026224498968524

Epoch: 5| Step: 8
Training loss: 2.620217462498342
Validation loss: 2.60961359053403

Epoch: 5| Step: 9
Training loss: 3.007264560479964
Validation loss: 2.617412862929936

Epoch: 5| Step: 10
Training loss: 2.7570429692785425
Validation loss: 2.618938242372073

Epoch: 222| Step: 0
Training loss: 3.7169075897773975
Validation loss: 2.6124051269506414

Epoch: 5| Step: 1
Training loss: 2.7936387758921977
Validation loss: 2.624989126234684

Epoch: 5| Step: 2
Training loss: 2.732899731072107
Validation loss: 2.6268241001911394

Epoch: 5| Step: 3
Training loss: 2.812805667797276
Validation loss: 2.621783300910165

Epoch: 5| Step: 4
Training loss: 2.757421536059885
Validation loss: 2.6226134216021135

Epoch: 5| Step: 5
Training loss: 3.083097053616153
Validation loss: 2.622348031768631

Epoch: 5| Step: 6
Training loss: 2.600204342368175
Validation loss: 2.617264653334248

Epoch: 5| Step: 7
Training loss: 2.839752741513699
Validation loss: 2.623611818537222

Epoch: 5| Step: 8
Training loss: 3.20844790431634
Validation loss: 2.614274972628596

Epoch: 5| Step: 9
Training loss: 2.8164890398827733
Validation loss: 2.6283223378406273

Epoch: 5| Step: 10
Training loss: 2.8808130292882246
Validation loss: 2.6230443241095163

Epoch: 223| Step: 0
Training loss: 2.926276497376678
Validation loss: 2.621139686125338

Epoch: 5| Step: 1
Training loss: 2.7089818226995455
Validation loss: 2.6192895036193304

Epoch: 5| Step: 2
Training loss: 3.3288805466657596
Validation loss: 2.6129456856803643

Epoch: 5| Step: 3
Training loss: 3.1339191565490574
Validation loss: 2.6110673112525866

Epoch: 5| Step: 4
Training loss: 3.2031121974782257
Validation loss: 2.6145850730948714

Epoch: 5| Step: 5
Training loss: 2.1076126083028743
Validation loss: 2.617730608541267

Epoch: 5| Step: 6
Training loss: 2.9352887535698247
Validation loss: 2.620902706314329

Epoch: 5| Step: 7
Training loss: 2.516232245468364
Validation loss: 2.6142760464199717

Epoch: 5| Step: 8
Training loss: 3.3808355391183875
Validation loss: 2.6155792667897737

Epoch: 5| Step: 9
Training loss: 2.622352082014755
Validation loss: 2.616264412380398

Epoch: 5| Step: 10
Training loss: 3.3033401231538786
Validation loss: 2.60246864695644

Epoch: 224| Step: 0
Training loss: 2.730180760641831
Validation loss: 2.5993059669624716

Epoch: 5| Step: 1
Training loss: 2.791667330917355
Validation loss: 2.6001295736602064

Epoch: 5| Step: 2
Training loss: 2.3852945377008883
Validation loss: 2.601484502566496

Epoch: 5| Step: 3
Training loss: 2.98403593204331
Validation loss: 2.6067560424627656

Epoch: 5| Step: 4
Training loss: 2.8614387777239108
Validation loss: 2.5990358545327843

Epoch: 5| Step: 5
Training loss: 2.9644609488136315
Validation loss: 2.607569728725944

Epoch: 5| Step: 6
Training loss: 2.922468155817123
Validation loss: 2.6106406439794676

Epoch: 5| Step: 7
Training loss: 3.1550716806723527
Validation loss: 2.60473369668124

Epoch: 5| Step: 8
Training loss: 3.465498491459998
Validation loss: 2.6055679564377656

Epoch: 5| Step: 9
Training loss: 2.4745439552385142
Validation loss: 2.6043804973469062

Epoch: 5| Step: 10
Training loss: 3.4972481127134003
Validation loss: 2.5967113759180194

Epoch: 225| Step: 0
Training loss: 2.839332754974175
Validation loss: 2.6052292465280673

Epoch: 5| Step: 1
Training loss: 2.864066688880001
Validation loss: 2.5939243147869995

Epoch: 5| Step: 2
Training loss: 2.7892509845548297
Validation loss: 2.594516351832337

Epoch: 5| Step: 3
Training loss: 2.5568027896610457
Validation loss: 2.594282985801035

Epoch: 5| Step: 4
Training loss: 3.2693177293630153
Validation loss: 2.594845288120053

Epoch: 5| Step: 5
Training loss: 3.0811241758705195
Validation loss: 2.6004338162462637

Epoch: 5| Step: 6
Training loss: 2.6639830278193903
Validation loss: 2.605486799443474

Epoch: 5| Step: 7
Training loss: 3.5082045168269147
Validation loss: 2.593721371080168

Epoch: 5| Step: 8
Training loss: 2.406243757760014
Validation loss: 2.5883796119402294

Epoch: 5| Step: 9
Training loss: 3.2939292439109256
Validation loss: 2.598066574776541

Epoch: 5| Step: 10
Training loss: 2.8353284281599946
Validation loss: 2.593352699417312

Epoch: 226| Step: 0
Training loss: 3.327633960300122
Validation loss: 2.5974267241838405

Epoch: 5| Step: 1
Training loss: 2.487161093776695
Validation loss: 2.5958205092321447

Epoch: 5| Step: 2
Training loss: 2.5203520155077492
Validation loss: 2.598603385985616

Epoch: 5| Step: 3
Training loss: 3.3600886097077693
Validation loss: 2.599616831373728

Epoch: 5| Step: 4
Training loss: 2.174546828140493
Validation loss: 2.5964537759924853

Epoch: 5| Step: 5
Training loss: 3.197018342892333
Validation loss: 2.590955847972322

Epoch: 5| Step: 6
Training loss: 3.2718519499658165
Validation loss: 2.5983880654692584

Epoch: 5| Step: 7
Training loss: 2.538038874942422
Validation loss: 2.596126589909407

Epoch: 5| Step: 8
Training loss: 2.976776195474617
Validation loss: 2.5955904832928423

Epoch: 5| Step: 9
Training loss: 3.3324957431042006
Validation loss: 2.596033584765417

Epoch: 5| Step: 10
Training loss: 2.859917927878214
Validation loss: 2.596804200804573

Epoch: 227| Step: 0
Training loss: 2.8245466999522564
Validation loss: 2.595696586762935

Epoch: 5| Step: 1
Training loss: 3.2944357286680686
Validation loss: 2.5992322248017627

Epoch: 5| Step: 2
Training loss: 3.0064292996999344
Validation loss: 2.597593831439549

Epoch: 5| Step: 3
Training loss: 2.9108669565266347
Validation loss: 2.592935892243015

Epoch: 5| Step: 4
Training loss: 2.98636884143883
Validation loss: 2.5975169968950285

Epoch: 5| Step: 5
Training loss: 2.5916683622234067
Validation loss: 2.60311888619555

Epoch: 5| Step: 6
Training loss: 2.6276391704081594
Validation loss: 2.6065260865566495

Epoch: 5| Step: 7
Training loss: 2.856815881411619
Validation loss: 2.5996144419046185

Epoch: 5| Step: 8
Training loss: 3.431356593076222
Validation loss: 2.613696230999934

Epoch: 5| Step: 9
Training loss: 2.715786601395413
Validation loss: 2.605159591558205

Epoch: 5| Step: 10
Training loss: 2.8989908764614354
Validation loss: 2.607773572667502

Epoch: 228| Step: 0
Training loss: 2.79178774746654
Validation loss: 2.6150843459718085

Epoch: 5| Step: 1
Training loss: 3.1202255397363894
Validation loss: 2.6410385830253547

Epoch: 5| Step: 2
Training loss: 3.195060440232053
Validation loss: 2.620890336577786

Epoch: 5| Step: 3
Training loss: 2.680821570822307
Validation loss: 2.6293157384668913

Epoch: 5| Step: 4
Training loss: 2.83777737375109
Validation loss: 2.62955904589447

Epoch: 5| Step: 5
Training loss: 2.8006019694516366
Validation loss: 2.6333835864019672

Epoch: 5| Step: 6
Training loss: 2.973970821819818
Validation loss: 2.6217409246420518

Epoch: 5| Step: 7
Training loss: 3.16755841063587
Validation loss: 2.613319789458147

Epoch: 5| Step: 8
Training loss: 3.1104792642053987
Validation loss: 2.6112547154742023

Epoch: 5| Step: 9
Training loss: 2.5529311555933063
Validation loss: 2.598755103385053

Epoch: 5| Step: 10
Training loss: 3.0746989281123374
Validation loss: 2.5932309733078225

Epoch: 229| Step: 0
Training loss: 3.3701674159995725
Validation loss: 2.593477096660922

Epoch: 5| Step: 1
Training loss: 2.374957234850894
Validation loss: 2.5952973507528685

Epoch: 5| Step: 2
Training loss: 3.101407371504265
Validation loss: 2.5934265702058883

Epoch: 5| Step: 3
Training loss: 2.3843575893181406
Validation loss: 2.59248475676809

Epoch: 5| Step: 4
Training loss: 3.2758104559126138
Validation loss: 2.590547114385164

Epoch: 5| Step: 5
Training loss: 3.2382316263443744
Validation loss: 2.5920039562808905

Epoch: 5| Step: 6
Training loss: 3.1746417226418906
Validation loss: 2.5919767679400465

Epoch: 5| Step: 7
Training loss: 2.477683887451439
Validation loss: 2.5890560303073378

Epoch: 5| Step: 8
Training loss: 3.219350814298955
Validation loss: 2.587048770049097

Epoch: 5| Step: 9
Training loss: 2.7053546860542994
Validation loss: 2.591247508778628

Epoch: 5| Step: 10
Training loss: 2.7724334188710023
Validation loss: 2.5881734926923574

Epoch: 230| Step: 0
Training loss: 3.3054569151307427
Validation loss: 2.5950831863825297

Epoch: 5| Step: 1
Training loss: 2.541426464883435
Validation loss: 2.597681303456297

Epoch: 5| Step: 2
Training loss: 2.8012610627023595
Validation loss: 2.608817735320909

Epoch: 5| Step: 3
Training loss: 2.7977153005922037
Validation loss: 2.6487529601973843

Epoch: 5| Step: 4
Training loss: 3.092084648345543
Validation loss: 2.670492957920634

Epoch: 5| Step: 5
Training loss: 2.645544672160393
Validation loss: 2.639214692641272

Epoch: 5| Step: 6
Training loss: 2.9298579052004428
Validation loss: 2.602453991875325

Epoch: 5| Step: 7
Training loss: 3.216807251330411
Validation loss: 2.594274059478877

Epoch: 5| Step: 8
Training loss: 2.7824475571179366
Validation loss: 2.592794173772454

Epoch: 5| Step: 9
Training loss: 3.1477727069837083
Validation loss: 2.588487842239809

Epoch: 5| Step: 10
Training loss: 3.04204689331829
Validation loss: 2.5904691009814083

Epoch: 231| Step: 0
Training loss: 3.065144856500751
Validation loss: 2.589156014138911

Epoch: 5| Step: 1
Training loss: 2.884058902567526
Validation loss: 2.5935371688183233

Epoch: 5| Step: 2
Training loss: 2.6509905637201174
Validation loss: 2.586445592594029

Epoch: 5| Step: 3
Training loss: 3.2500542856230985
Validation loss: 2.5969399955508234

Epoch: 5| Step: 4
Training loss: 3.1407789505760886
Validation loss: 2.5980184999009506

Epoch: 5| Step: 5
Training loss: 3.1487800657889653
Validation loss: 2.5918350573621365

Epoch: 5| Step: 6
Training loss: 2.74866288363227
Validation loss: 2.6047120367802252

Epoch: 5| Step: 7
Training loss: 2.6150962559506223
Validation loss: 2.596495096776966

Epoch: 5| Step: 8
Training loss: 3.2747995096819715
Validation loss: 2.5940228726517955

Epoch: 5| Step: 9
Training loss: 2.848895103036521
Validation loss: 2.6021121446292006

Epoch: 5| Step: 10
Training loss: 2.544589368597427
Validation loss: 2.5998708057094313

Epoch: 232| Step: 0
Training loss: 2.9560614624550707
Validation loss: 2.6009327914321947

Epoch: 5| Step: 1
Training loss: 2.8787278594980616
Validation loss: 2.616029334048494

Epoch: 5| Step: 2
Training loss: 2.770911299294575
Validation loss: 2.6017917250116693

Epoch: 5| Step: 3
Training loss: 3.4184355150037944
Validation loss: 2.610732784090794

Epoch: 5| Step: 4
Training loss: 3.0297482890207594
Validation loss: 2.6106821870215646

Epoch: 5| Step: 5
Training loss: 2.7159519047081346
Validation loss: 2.6034978710837895

Epoch: 5| Step: 6
Training loss: 2.7242933739521553
Validation loss: 2.6034551952155467

Epoch: 5| Step: 7
Training loss: 2.6118985154443632
Validation loss: 2.591748362351143

Epoch: 5| Step: 8
Training loss: 2.769044303321954
Validation loss: 2.599237512387588

Epoch: 5| Step: 9
Training loss: 3.267930380650469
Validation loss: 2.604549123592484

Epoch: 5| Step: 10
Training loss: 3.006510187575556
Validation loss: 2.592442626440098

Epoch: 233| Step: 0
Training loss: 3.1632223638667267
Validation loss: 2.5950479117759966

Epoch: 5| Step: 1
Training loss: 3.1275541929921116
Validation loss: 2.597563932253967

Epoch: 5| Step: 2
Training loss: 2.5398256064793356
Validation loss: 2.603019501719697

Epoch: 5| Step: 3
Training loss: 3.0719045922841874
Validation loss: 2.597868457545595

Epoch: 5| Step: 4
Training loss: 2.9891196676671004
Validation loss: 2.591925649447337

Epoch: 5| Step: 5
Training loss: 2.667533068179347
Validation loss: 2.5860910152288668

Epoch: 5| Step: 6
Training loss: 2.9345106782106325
Validation loss: 2.5839860606232032

Epoch: 5| Step: 7
Training loss: 2.948153554791438
Validation loss: 2.587893491880006

Epoch: 5| Step: 8
Training loss: 2.176066025566718
Validation loss: 2.5753407100503365

Epoch: 5| Step: 9
Training loss: 3.129066263172017
Validation loss: 2.58109200474341

Epoch: 5| Step: 10
Training loss: 3.420276704045854
Validation loss: 2.585206975043091

Epoch: 234| Step: 0
Training loss: 3.288517777738097
Validation loss: 2.586010943187335

Epoch: 5| Step: 1
Training loss: 2.8318615250865684
Validation loss: 2.5866864487352816

Epoch: 5| Step: 2
Training loss: 3.00315389152864
Validation loss: 2.5879007749693175

Epoch: 5| Step: 3
Training loss: 2.876152305220415
Validation loss: 2.577125740987275

Epoch: 5| Step: 4
Training loss: 2.8661616930394858
Validation loss: 2.581981402105823

Epoch: 5| Step: 5
Training loss: 3.356995489486196
Validation loss: 2.5831626758977064

Epoch: 5| Step: 6
Training loss: 3.1697375983771776
Validation loss: 2.579570929849505

Epoch: 5| Step: 7
Training loss: 2.839450310445795
Validation loss: 2.582222231852745

Epoch: 5| Step: 8
Training loss: 2.4617978484322003
Validation loss: 2.581622426154247

Epoch: 5| Step: 9
Training loss: 2.610996678958389
Validation loss: 2.575452335179678

Epoch: 5| Step: 10
Training loss: 2.81700392477773
Validation loss: 2.5843781519455704

Epoch: 235| Step: 0
Training loss: 2.7478270181797066
Validation loss: 2.583787960123672

Epoch: 5| Step: 1
Training loss: 3.447394401587265
Validation loss: 2.5803792942797807

Epoch: 5| Step: 2
Training loss: 2.76494439150196
Validation loss: 2.5820771979743795

Epoch: 5| Step: 3
Training loss: 2.726787743651086
Validation loss: 2.583885015540354

Epoch: 5| Step: 4
Training loss: 2.9776737411633056
Validation loss: 2.583046635912235

Epoch: 5| Step: 5
Training loss: 2.712045404689901
Validation loss: 2.583477985435377

Epoch: 5| Step: 6
Training loss: 3.3079207815719776
Validation loss: 2.5835881029851566

Epoch: 5| Step: 7
Training loss: 3.2689513281241327
Validation loss: 2.5823050978898094

Epoch: 5| Step: 8
Training loss: 2.6572892792522893
Validation loss: 2.5836478434536394

Epoch: 5| Step: 9
Training loss: 2.436501225005213
Validation loss: 2.5848983710650244

Epoch: 5| Step: 10
Training loss: 2.9986449996292106
Validation loss: 2.59000349426794

Epoch: 236| Step: 0
Training loss: 2.9516202130387716
Validation loss: 2.587150894534962

Epoch: 5| Step: 1
Training loss: 2.9155178168937677
Validation loss: 2.5948759418197307

Epoch: 5| Step: 2
Training loss: 2.4153948320138143
Validation loss: 2.595797916723079

Epoch: 5| Step: 3
Training loss: 2.839516979029063
Validation loss: 2.608005042477392

Epoch: 5| Step: 4
Training loss: 3.2295107914492873
Validation loss: 2.594266570949782

Epoch: 5| Step: 5
Training loss: 3.289019441662557
Validation loss: 2.5949358571137737

Epoch: 5| Step: 6
Training loss: 2.5264555182422543
Validation loss: 2.5910815332334924

Epoch: 5| Step: 7
Training loss: 3.4837385887941865
Validation loss: 2.5853169371409668

Epoch: 5| Step: 8
Training loss: 2.857874075099527
Validation loss: 2.585891431261736

Epoch: 5| Step: 9
Training loss: 2.5285126755471943
Validation loss: 2.5853692780495705

Epoch: 5| Step: 10
Training loss: 3.011168670886167
Validation loss: 2.5857026121399818

Epoch: 237| Step: 0
Training loss: 3.325106259132403
Validation loss: 2.5786629124045786

Epoch: 5| Step: 1
Training loss: 3.2853260699456084
Validation loss: 2.5783844629252672

Epoch: 5| Step: 2
Training loss: 2.5552270535326174
Validation loss: 2.5812315182425323

Epoch: 5| Step: 3
Training loss: 2.6182491142120656
Validation loss: 2.583403153390618

Epoch: 5| Step: 4
Training loss: 2.4990844003591413
Validation loss: 2.579250639107213

Epoch: 5| Step: 5
Training loss: 3.214920729020278
Validation loss: 2.580000708210199

Epoch: 5| Step: 6
Training loss: 3.0598287025825397
Validation loss: 2.577206531246295

Epoch: 5| Step: 7
Training loss: 2.706024026576569
Validation loss: 2.5751703289823755

Epoch: 5| Step: 8
Training loss: 2.6924619777194336
Validation loss: 2.5820773965463304

Epoch: 5| Step: 9
Training loss: 3.28743691039377
Validation loss: 2.5790443777348426

Epoch: 5| Step: 10
Training loss: 2.7742983919151185
Validation loss: 2.582949595641735

Epoch: 238| Step: 0
Training loss: 3.1710459560599773
Validation loss: 2.5847294055606684

Epoch: 5| Step: 1
Training loss: 2.704920354435659
Validation loss: 2.5934690216279934

Epoch: 5| Step: 2
Training loss: 2.8366088072646995
Validation loss: 2.586306042171633

Epoch: 5| Step: 3
Training loss: 3.07097309955627
Validation loss: 2.5825491325919785

Epoch: 5| Step: 4
Training loss: 2.8803866137513094
Validation loss: 2.5898143008324457

Epoch: 5| Step: 5
Training loss: 3.2615865897626466
Validation loss: 2.5883890228581694

Epoch: 5| Step: 6
Training loss: 3.2870329260365105
Validation loss: 2.5777618182226574

Epoch: 5| Step: 7
Training loss: 2.931834337110682
Validation loss: 2.576490654963536

Epoch: 5| Step: 8
Training loss: 2.5171058987272894
Validation loss: 2.5766066151011255

Epoch: 5| Step: 9
Training loss: 2.395052730162998
Validation loss: 2.577238575976439

Epoch: 5| Step: 10
Training loss: 3.0535440085190997
Validation loss: 2.577103334749281

Epoch: 239| Step: 0
Training loss: 3.2127791643375163
Validation loss: 2.576934931570401

Epoch: 5| Step: 1
Training loss: 2.6257205155943737
Validation loss: 2.5744111379484487

Epoch: 5| Step: 2
Training loss: 3.211187274063356
Validation loss: 2.575587766616566

Epoch: 5| Step: 3
Training loss: 2.471746822848612
Validation loss: 2.5805432942368767

Epoch: 5| Step: 4
Training loss: 2.566645734462181
Validation loss: 2.581214023228035

Epoch: 5| Step: 5
Training loss: 2.4843095494891747
Validation loss: 2.5769480584645312

Epoch: 5| Step: 6
Training loss: 3.5005296578863874
Validation loss: 2.58567534762581

Epoch: 5| Step: 7
Training loss: 3.0561203193845583
Validation loss: 2.595124460827281

Epoch: 5| Step: 8
Training loss: 3.371978961802023
Validation loss: 2.6002240630280875

Epoch: 5| Step: 9
Training loss: 2.7744512719972674
Validation loss: 2.6054178972049598

Epoch: 5| Step: 10
Training loss: 2.6468622705002622
Validation loss: 2.595779138698327

Epoch: 240| Step: 0
Training loss: 2.938483053436666
Validation loss: 2.606153293657925

Epoch: 5| Step: 1
Training loss: 2.724851579736371
Validation loss: 2.6048292010455145

Epoch: 5| Step: 2
Training loss: 2.8102145764022333
Validation loss: 2.598168644103062

Epoch: 5| Step: 3
Training loss: 3.2378318115813074
Validation loss: 2.5875079660886007

Epoch: 5| Step: 4
Training loss: 2.918407483802787
Validation loss: 2.5928526609927927

Epoch: 5| Step: 5
Training loss: 3.233392243651573
Validation loss: 2.595264420673309

Epoch: 5| Step: 6
Training loss: 3.4511826519886912
Validation loss: 2.5849121775443726

Epoch: 5| Step: 7
Training loss: 2.6606616913817374
Validation loss: 2.5778891934433044

Epoch: 5| Step: 8
Training loss: 2.3150206566171208
Validation loss: 2.5748386790892743

Epoch: 5| Step: 9
Training loss: 2.9095717284726703
Validation loss: 2.5763691411607956

Epoch: 5| Step: 10
Training loss: 2.8595229147086147
Validation loss: 2.5781352679662493

Epoch: 241| Step: 0
Training loss: 2.7781141797982483
Validation loss: 2.5752304289847165

Epoch: 5| Step: 1
Training loss: 3.443807190906548
Validation loss: 2.5851836204049867

Epoch: 5| Step: 2
Training loss: 3.4351494815734576
Validation loss: 2.5768319147160947

Epoch: 5| Step: 3
Training loss: 2.8521050760031597
Validation loss: 2.5818517344930187

Epoch: 5| Step: 4
Training loss: 2.8752119566696934
Validation loss: 2.580952941610662

Epoch: 5| Step: 5
Training loss: 2.6109354070521515
Validation loss: 2.584945946130632

Epoch: 5| Step: 6
Training loss: 2.6228653538911093
Validation loss: 2.5843936941759775

Epoch: 5| Step: 7
Training loss: 2.865677521701671
Validation loss: 2.59423635968362

Epoch: 5| Step: 8
Training loss: 3.0338862645275393
Validation loss: 2.5904657599431524

Epoch: 5| Step: 9
Training loss: 2.8586396486028045
Validation loss: 2.597141500268586

Epoch: 5| Step: 10
Training loss: 2.6896289997868
Validation loss: 2.604507589030714

Epoch: 242| Step: 0
Training loss: 3.267494943931538
Validation loss: 2.613675925390596

Epoch: 5| Step: 1
Training loss: 2.8063178039379677
Validation loss: 2.6124432730674867

Epoch: 5| Step: 2
Training loss: 2.7665159008204143
Validation loss: 2.6238741269435235

Epoch: 5| Step: 3
Training loss: 3.1674045573053453
Validation loss: 2.6083333254442

Epoch: 5| Step: 4
Training loss: 2.729733260261921
Validation loss: 2.613147239388814

Epoch: 5| Step: 5
Training loss: 2.8098353160508207
Validation loss: 2.607403856649741

Epoch: 5| Step: 6
Training loss: 3.1185036846736676
Validation loss: 2.6199829668438386

Epoch: 5| Step: 7
Training loss: 2.894523672075944
Validation loss: 2.627732908620623

Epoch: 5| Step: 8
Training loss: 2.8879160791815797
Validation loss: 2.6204380352039993

Epoch: 5| Step: 9
Training loss: 2.3472063138022663
Validation loss: 2.6188469176160925

Epoch: 5| Step: 10
Training loss: 3.387097189063825
Validation loss: 2.6017892114167656

Epoch: 243| Step: 0
Training loss: 3.340388096401752
Validation loss: 2.6004899036701636

Epoch: 5| Step: 1
Training loss: 2.343688862321089
Validation loss: 2.588756476519687

Epoch: 5| Step: 2
Training loss: 3.1742269881580736
Validation loss: 2.5799279435310236

Epoch: 5| Step: 3
Training loss: 3.5060953469941967
Validation loss: 2.5790459363692486

Epoch: 5| Step: 4
Training loss: 2.478022484986
Validation loss: 2.582050080845286

Epoch: 5| Step: 5
Training loss: 2.809038702638745
Validation loss: 2.58326948730719

Epoch: 5| Step: 6
Training loss: 3.188043585408741
Validation loss: 2.5798540389956655

Epoch: 5| Step: 7
Training loss: 2.430664258675665
Validation loss: 2.584302730923482

Epoch: 5| Step: 8
Training loss: 2.961113031262254
Validation loss: 2.5882721595969396

Epoch: 5| Step: 9
Training loss: 3.0122617635270075
Validation loss: 2.5842807549483804

Epoch: 5| Step: 10
Training loss: 2.6053647959959165
Validation loss: 2.581398643038128

Epoch: 244| Step: 0
Training loss: 3.0261872475951193
Validation loss: 2.579884262175043

Epoch: 5| Step: 1
Training loss: 2.898933306544995
Validation loss: 2.5811888784684323

Epoch: 5| Step: 2
Training loss: 3.0877127261373247
Validation loss: 2.5793909389824217

Epoch: 5| Step: 3
Training loss: 2.837728139973758
Validation loss: 2.58862029902603

Epoch: 5| Step: 4
Training loss: 2.592244090266761
Validation loss: 2.588382637739663

Epoch: 5| Step: 5
Training loss: 2.9444468716145553
Validation loss: 2.5876768026711687

Epoch: 5| Step: 6
Training loss: 2.9002658393295153
Validation loss: 2.580859811826013

Epoch: 5| Step: 7
Training loss: 2.9969579850243924
Validation loss: 2.5834490233790293

Epoch: 5| Step: 8
Training loss: 3.0505844619330253
Validation loss: 2.578939973923606

Epoch: 5| Step: 9
Training loss: 3.2205494415463236
Validation loss: 2.5757690573516427

Epoch: 5| Step: 10
Training loss: 2.470380220685354
Validation loss: 2.5753565098935147

Epoch: 245| Step: 0
Training loss: 2.7754295394714235
Validation loss: 2.579117363159929

Epoch: 5| Step: 1
Training loss: 2.807201225980163
Validation loss: 2.592169153270381

Epoch: 5| Step: 2
Training loss: 3.1474780568394967
Validation loss: 2.5828525179782393

Epoch: 5| Step: 3
Training loss: 2.6348083356897734
Validation loss: 2.576971527035745

Epoch: 5| Step: 4
Training loss: 2.958301185827247
Validation loss: 2.577557018133111

Epoch: 5| Step: 5
Training loss: 2.901494555276104
Validation loss: 2.5736598193345266

Epoch: 5| Step: 6
Training loss: 2.878401195681092
Validation loss: 2.574246612880546

Epoch: 5| Step: 7
Training loss: 3.2007857550081185
Validation loss: 2.5705623545789384

Epoch: 5| Step: 8
Training loss: 2.949417127796235
Validation loss: 2.575222808424676

Epoch: 5| Step: 9
Training loss: 2.9955923762575547
Validation loss: 2.5670730829058126

Epoch: 5| Step: 10
Training loss: 2.7898551605256188
Validation loss: 2.574752508038262

Epoch: 246| Step: 0
Training loss: 2.9459402695328487
Validation loss: 2.5715913219134547

Epoch: 5| Step: 1
Training loss: 2.9424085796353503
Validation loss: 2.5729231515275997

Epoch: 5| Step: 2
Training loss: 3.0751267755938323
Validation loss: 2.574052413941007

Epoch: 5| Step: 3
Training loss: 2.882989149186339
Validation loss: 2.570917675603729

Epoch: 5| Step: 4
Training loss: 2.852147541386903
Validation loss: 2.5776878883809844

Epoch: 5| Step: 5
Training loss: 2.423170272486874
Validation loss: 2.5784561735055354

Epoch: 5| Step: 6
Training loss: 2.5756405043048556
Validation loss: 2.575981285529008

Epoch: 5| Step: 7
Training loss: 2.907005622010623
Validation loss: 2.57456734791174

Epoch: 5| Step: 8
Training loss: 3.1431900102040573
Validation loss: 2.5834233942783507

Epoch: 5| Step: 9
Training loss: 2.9252547845973296
Validation loss: 2.5818587595799274

Epoch: 5| Step: 10
Training loss: 3.4140532818632705
Validation loss: 2.5871335148590306

Epoch: 247| Step: 0
Training loss: 3.3340684715887567
Validation loss: 2.5780339796419325

Epoch: 5| Step: 1
Training loss: 2.906953951990244
Validation loss: 2.5752783528808054

Epoch: 5| Step: 2
Training loss: 3.3358910443468353
Validation loss: 2.5840537336668903

Epoch: 5| Step: 3
Training loss: 2.5219257184190877
Validation loss: 2.576867888360382

Epoch: 5| Step: 4
Training loss: 2.642945032241671
Validation loss: 2.5819990617049102

Epoch: 5| Step: 5
Training loss: 2.8378336638833552
Validation loss: 2.577513025563471

Epoch: 5| Step: 6
Training loss: 2.7584436142956212
Validation loss: 2.5803507524775515

Epoch: 5| Step: 7
Training loss: 2.863895699013688
Validation loss: 2.5756058950698764

Epoch: 5| Step: 8
Training loss: 3.5476103033078115
Validation loss: 2.5731399384123947

Epoch: 5| Step: 9
Training loss: 2.690556230009561
Validation loss: 2.5813755965744147

Epoch: 5| Step: 10
Training loss: 2.3274355898097663
Validation loss: 2.574532642597322

Epoch: 248| Step: 0
Training loss: 2.9592368845950725
Validation loss: 2.578201858602922

Epoch: 5| Step: 1
Training loss: 3.317906412213141
Validation loss: 2.5766832055896662

Epoch: 5| Step: 2
Training loss: 2.437934054339474
Validation loss: 2.577816679446119

Epoch: 5| Step: 3
Training loss: 3.0593909227153637
Validation loss: 2.5882082072549846

Epoch: 5| Step: 4
Training loss: 3.269266388988204
Validation loss: 2.58751968297833

Epoch: 5| Step: 5
Training loss: 3.270173769658831
Validation loss: 2.57472748139188

Epoch: 5| Step: 6
Training loss: 2.870367879649988
Validation loss: 2.5808482335674268

Epoch: 5| Step: 7
Training loss: 2.7270483769992757
Validation loss: 2.5754487576602196

Epoch: 5| Step: 8
Training loss: 2.7161207091259714
Validation loss: 2.581998649655594

Epoch: 5| Step: 9
Training loss: 2.159611169291096
Validation loss: 2.579939382829412

Epoch: 5| Step: 10
Training loss: 3.164883730712815
Validation loss: 2.5799661216934475

Epoch: 249| Step: 0
Training loss: 2.6866075675213144
Validation loss: 2.5936029953210666

Epoch: 5| Step: 1
Training loss: 2.598246984786361
Validation loss: 2.5877778988211224

Epoch: 5| Step: 2
Training loss: 3.018177908636864
Validation loss: 2.584928015085102

Epoch: 5| Step: 3
Training loss: 3.1989008148166564
Validation loss: 2.5817528768330695

Epoch: 5| Step: 4
Training loss: 3.1553861738990214
Validation loss: 2.575988632153881

Epoch: 5| Step: 5
Training loss: 2.309688921538163
Validation loss: 2.5664871035015353

Epoch: 5| Step: 6
Training loss: 2.769826854431127
Validation loss: 2.576950837039913

Epoch: 5| Step: 7
Training loss: 2.819593765948273
Validation loss: 2.5806414412528063

Epoch: 5| Step: 8
Training loss: 3.255202604161625
Validation loss: 2.583119232350811

Epoch: 5| Step: 9
Training loss: 3.10058455339536
Validation loss: 2.58567395459862

Epoch: 5| Step: 10
Training loss: 3.058263690235234
Validation loss: 2.5903811439417916

Epoch: 250| Step: 0
Training loss: 3.423560855093397
Validation loss: 2.584471605289836

Epoch: 5| Step: 1
Training loss: 2.9083861017404264
Validation loss: 2.5787720525481417

Epoch: 5| Step: 2
Training loss: 2.910423317758055
Validation loss: 2.589394524203191

Epoch: 5| Step: 3
Training loss: 2.726386209379609
Validation loss: 2.5787571037371633

Epoch: 5| Step: 4
Training loss: 2.5255353492282415
Validation loss: 2.571679044356685

Epoch: 5| Step: 5
Training loss: 3.170522016029218
Validation loss: 2.571612787252567

Epoch: 5| Step: 6
Training loss: 3.0865803881863854
Validation loss: 2.580358379750724

Epoch: 5| Step: 7
Training loss: 3.095297070175449
Validation loss: 2.5698734789595323

Epoch: 5| Step: 8
Training loss: 2.265871337126703
Validation loss: 2.5733698641359184

Epoch: 5| Step: 9
Training loss: 2.87785065344693
Validation loss: 2.57649375840593

Epoch: 5| Step: 10
Training loss: 2.9593342086413723
Validation loss: 2.5705990442558515

Epoch: 251| Step: 0
Training loss: 2.24771022844519
Validation loss: 2.5709279793352935

Epoch: 5| Step: 1
Training loss: 2.8900229987051027
Validation loss: 2.5821054074491876

Epoch: 5| Step: 2
Training loss: 3.2004922607404582
Validation loss: 2.5701075222591787

Epoch: 5| Step: 3
Training loss: 3.2292733615763503
Validation loss: 2.5809169325276806

Epoch: 5| Step: 4
Training loss: 3.2060500768604525
Validation loss: 2.5825377286778095

Epoch: 5| Step: 5
Training loss: 2.6664275022386836
Validation loss: 2.592115234715878

Epoch: 5| Step: 6
Training loss: 3.1820406068120626
Validation loss: 2.6010870705591644

Epoch: 5| Step: 7
Training loss: 3.7117858559482495
Validation loss: 2.6276302354443635

Epoch: 5| Step: 8
Training loss: 2.3659871397402523
Validation loss: 2.6279117843980155

Epoch: 5| Step: 9
Training loss: 2.525584438407016
Validation loss: 2.6326644309076275

Epoch: 5| Step: 10
Training loss: 2.498325263789274
Validation loss: 2.6002170057268215

Epoch: 252| Step: 0
Training loss: 3.0378423364447653
Validation loss: 2.590678777148538

Epoch: 5| Step: 1
Training loss: 3.1180371343176603
Validation loss: 2.5782178745837196

Epoch: 5| Step: 2
Training loss: 3.209165952238804
Validation loss: 2.573728538844886

Epoch: 5| Step: 3
Training loss: 2.221892160169647
Validation loss: 2.575222112568364

Epoch: 5| Step: 4
Training loss: 3.1147838685322062
Validation loss: 2.5707562886300175

Epoch: 5| Step: 5
Training loss: 2.7241368037753895
Validation loss: 2.5720906467170677

Epoch: 5| Step: 6
Training loss: 3.0159545085926593
Validation loss: 2.5756063151093946

Epoch: 5| Step: 7
Training loss: 2.990280459975131
Validation loss: 2.5727623228168377

Epoch: 5| Step: 8
Training loss: 2.9038663543760324
Validation loss: 2.573091215487113

Epoch: 5| Step: 9
Training loss: 3.0336302231200563
Validation loss: 2.578962445717561

Epoch: 5| Step: 10
Training loss: 2.5320209224011263
Validation loss: 2.578401347762788

Epoch: 253| Step: 0
Training loss: 2.854423529953902
Validation loss: 2.583645453107307

Epoch: 5| Step: 1
Training loss: 3.29510001903387
Validation loss: 2.5897621150951693

Epoch: 5| Step: 2
Training loss: 3.061641339187093
Validation loss: 2.595233132932267

Epoch: 5| Step: 3
Training loss: 2.809394308496982
Validation loss: 2.6010252744540807

Epoch: 5| Step: 4
Training loss: 2.782391089049905
Validation loss: 2.60662823966945

Epoch: 5| Step: 5
Training loss: 3.0486994049641254
Validation loss: 2.605664390483642

Epoch: 5| Step: 6
Training loss: 2.862318847787815
Validation loss: 2.593366940328547

Epoch: 5| Step: 7
Training loss: 3.1484670330016082
Validation loss: 2.5927538252949422

Epoch: 5| Step: 8
Training loss: 2.560471080411862
Validation loss: 2.590591367547799

Epoch: 5| Step: 9
Training loss: 2.521922882268387
Validation loss: 2.5761655409534003

Epoch: 5| Step: 10
Training loss: 2.9808845280008587
Validation loss: 2.5803609718461136

Epoch: 254| Step: 0
Training loss: 2.44462844006844
Validation loss: 2.5768036698949595

Epoch: 5| Step: 1
Training loss: 3.3152716215542
Validation loss: 2.5755679916957925

Epoch: 5| Step: 2
Training loss: 2.501925680470086
Validation loss: 2.5714245337524395

Epoch: 5| Step: 3
Training loss: 3.3379086247868974
Validation loss: 2.572421170969818

Epoch: 5| Step: 4
Training loss: 3.2316490886092786
Validation loss: 2.5808729922632354

Epoch: 5| Step: 5
Training loss: 2.496494123797661
Validation loss: 2.584232892844043

Epoch: 5| Step: 6
Training loss: 2.389326852627179
Validation loss: 2.5959326145883885

Epoch: 5| Step: 7
Training loss: 3.328839722304087
Validation loss: 2.6176308386342244

Epoch: 5| Step: 8
Training loss: 3.1809673311150326
Validation loss: 2.602248717498051

Epoch: 5| Step: 9
Training loss: 2.8021309339221654
Validation loss: 2.597478911873758

Epoch: 5| Step: 10
Training loss: 2.6822842397247504
Validation loss: 2.5946728759249487

Epoch: 255| Step: 0
Training loss: 2.818431533450181
Validation loss: 2.5867083140837788

Epoch: 5| Step: 1
Training loss: 2.8698182886530805
Validation loss: 2.589779860224855

Epoch: 5| Step: 2
Training loss: 2.7181355450693823
Validation loss: 2.590038003167979

Epoch: 5| Step: 3
Training loss: 3.028486427492107
Validation loss: 2.5824193902421397

Epoch: 5| Step: 4
Training loss: 2.6522761520288745
Validation loss: 2.5762111666388527

Epoch: 5| Step: 5
Training loss: 2.9167075744666575
Validation loss: 2.57348319752121

Epoch: 5| Step: 6
Training loss: 3.5048025424424742
Validation loss: 2.5662778762733796

Epoch: 5| Step: 7
Training loss: 2.8942264700159885
Validation loss: 2.575285377980546

Epoch: 5| Step: 8
Training loss: 2.9918754554367277
Validation loss: 2.56072764978246

Epoch: 5| Step: 9
Training loss: 2.4365168814102676
Validation loss: 2.577705426223864

Epoch: 5| Step: 10
Training loss: 3.0527887321216234
Validation loss: 2.573140833097078

Epoch: 256| Step: 0
Training loss: 3.1544732862336957
Validation loss: 2.5870609250353223

Epoch: 5| Step: 1
Training loss: 3.0996767552340803
Validation loss: 2.582957945736464

Epoch: 5| Step: 2
Training loss: 2.682261751372292
Validation loss: 2.591469651978283

Epoch: 5| Step: 3
Training loss: 3.356047219627378
Validation loss: 2.5992189263920316

Epoch: 5| Step: 4
Training loss: 2.7014898746010547
Validation loss: 2.5909107678975105

Epoch: 5| Step: 5
Training loss: 2.6608004917213135
Validation loss: 2.5933015546642353

Epoch: 5| Step: 6
Training loss: 2.5939579156477954
Validation loss: 2.60010499734327

Epoch: 5| Step: 7
Training loss: 2.6116551470507545
Validation loss: 2.599642441847761

Epoch: 5| Step: 8
Training loss: 2.638833967830836
Validation loss: 2.5920695200652397

Epoch: 5| Step: 9
Training loss: 3.4632846975965528
Validation loss: 2.5967226810577766

Epoch: 5| Step: 10
Training loss: 2.7949067761155315
Validation loss: 2.58574314996228

Epoch: 257| Step: 0
Training loss: 3.2068343851346053
Validation loss: 2.5740297717981253

Epoch: 5| Step: 1
Training loss: 2.794729422095207
Validation loss: 2.569185231873124

Epoch: 5| Step: 2
Training loss: 3.0021689839336596
Validation loss: 2.566947034572629

Epoch: 5| Step: 3
Training loss: 2.9597055897055666
Validation loss: 2.5677946911891834

Epoch: 5| Step: 4
Training loss: 2.778350347212437
Validation loss: 2.5705854660747214

Epoch: 5| Step: 5
Training loss: 2.74747368339174
Validation loss: 2.5687337555638767

Epoch: 5| Step: 6
Training loss: 2.9013333313827423
Validation loss: 2.562631137992912

Epoch: 5| Step: 7
Training loss: 3.523334916137609
Validation loss: 2.5604403061794554

Epoch: 5| Step: 8
Training loss: 2.6916266407859526
Validation loss: 2.563895853046528

Epoch: 5| Step: 9
Training loss: 2.8418027477924714
Validation loss: 2.572880316269079

Epoch: 5| Step: 10
Training loss: 2.42525792274168
Validation loss: 2.5664968087072557

Epoch: 258| Step: 0
Training loss: 3.1437681042129055
Validation loss: 2.570118394809677

Epoch: 5| Step: 1
Training loss: 2.8453207184506857
Validation loss: 2.5803488468976417

Epoch: 5| Step: 2
Training loss: 2.675701858567879
Validation loss: 2.590670587509737

Epoch: 5| Step: 3
Training loss: 3.0087419931505686
Validation loss: 2.595197893950411

Epoch: 5| Step: 4
Training loss: 3.081026520275367
Validation loss: 2.5921126533856573

Epoch: 5| Step: 5
Training loss: 2.697051352595118
Validation loss: 2.583303537372262

Epoch: 5| Step: 6
Training loss: 2.9909930123337136
Validation loss: 2.5754736618307104

Epoch: 5| Step: 7
Training loss: 2.7286505368847447
Validation loss: 2.580984749613385

Epoch: 5| Step: 8
Training loss: 2.8864448634236823
Validation loss: 2.5837009385382537

Epoch: 5| Step: 9
Training loss: 3.0070489087556322
Validation loss: 2.5796859475568996

Epoch: 5| Step: 10
Training loss: 2.9004133127269216
Validation loss: 2.5756144580894618

Epoch: 259| Step: 0
Training loss: 2.697651961804033
Validation loss: 2.5734500525600925

Epoch: 5| Step: 1
Training loss: 2.39685503417929
Validation loss: 2.5777026763091273

Epoch: 5| Step: 2
Training loss: 2.7362510131164877
Validation loss: 2.5846282804318346

Epoch: 5| Step: 3
Training loss: 3.319986484454117
Validation loss: 2.5890223083974817

Epoch: 5| Step: 4
Training loss: 2.76795077187527
Validation loss: 2.5976188697071483

Epoch: 5| Step: 5
Training loss: 3.1223887405548263
Validation loss: 2.591207034313285

Epoch: 5| Step: 6
Training loss: 3.268556000475909
Validation loss: 2.592715740510101

Epoch: 5| Step: 7
Training loss: 3.1780968888951575
Validation loss: 2.586872996975102

Epoch: 5| Step: 8
Training loss: 2.7496695753472067
Validation loss: 2.58746792455997

Epoch: 5| Step: 9
Training loss: 2.9490114657081157
Validation loss: 2.607711344172482

Epoch: 5| Step: 10
Training loss: 2.5578231932475393
Validation loss: 2.5936523025720564

Epoch: 260| Step: 0
Training loss: 2.7042974674544347
Validation loss: 2.597389202406832

Epoch: 5| Step: 1
Training loss: 3.097112658453488
Validation loss: 2.594972654649813

Epoch: 5| Step: 2
Training loss: 2.806911511180554
Validation loss: 2.582812907512437

Epoch: 5| Step: 3
Training loss: 2.8564643428853254
Validation loss: 2.577610839406514

Epoch: 5| Step: 4
Training loss: 3.3737814787519405
Validation loss: 2.5825537485422236

Epoch: 5| Step: 5
Training loss: 3.0695952143015677
Validation loss: 2.576752991602173

Epoch: 5| Step: 6
Training loss: 2.8596954999896638
Validation loss: 2.585121717346225

Epoch: 5| Step: 7
Training loss: 2.892340568560102
Validation loss: 2.577521172465951

Epoch: 5| Step: 8
Training loss: 3.1925878870254825
Validation loss: 2.5732248214817823

Epoch: 5| Step: 9
Training loss: 2.2432087024835536
Validation loss: 2.582939630677001

Epoch: 5| Step: 10
Training loss: 2.6626110429845258
Validation loss: 2.5842555006488066

Epoch: 261| Step: 0
Training loss: 2.88239266664714
Validation loss: 2.5870934189790624

Epoch: 5| Step: 1
Training loss: 2.620216734562999
Validation loss: 2.5735972172308297

Epoch: 5| Step: 2
Training loss: 2.752997152280599
Validation loss: 2.5664258837442477

Epoch: 5| Step: 3
Training loss: 2.7570495414613547
Validation loss: 2.577481694411365

Epoch: 5| Step: 4
Training loss: 2.6950628634961005
Validation loss: 2.572309566787769

Epoch: 5| Step: 5
Training loss: 3.0696287679971057
Validation loss: 2.5730522528226207

Epoch: 5| Step: 6
Training loss: 2.850068001186842
Validation loss: 2.575046396360192

Epoch: 5| Step: 7
Training loss: 3.411633777717673
Validation loss: 2.5760898516233506

Epoch: 5| Step: 8
Training loss: 3.0061531543002555
Validation loss: 2.576197831989168

Epoch: 5| Step: 9
Training loss: 2.7504399554576504
Validation loss: 2.577899522016917

Epoch: 5| Step: 10
Training loss: 3.026125636990244
Validation loss: 2.5872077148261012

Epoch: 262| Step: 0
Training loss: 2.6958564541123473
Validation loss: 2.585153389763232

Epoch: 5| Step: 1
Training loss: 3.3062900418198655
Validation loss: 2.5883390470678522

Epoch: 5| Step: 2
Training loss: 3.1856208198614238
Validation loss: 2.582536830299771

Epoch: 5| Step: 3
Training loss: 2.7092848255678557
Validation loss: 2.586288952208763

Epoch: 5| Step: 4
Training loss: 2.272007653142907
Validation loss: 2.5764861982982983

Epoch: 5| Step: 5
Training loss: 3.1391431054740893
Validation loss: 2.5815043784421543

Epoch: 5| Step: 6
Training loss: 2.9857631470755632
Validation loss: 2.584431505806266

Epoch: 5| Step: 7
Training loss: 2.28649633516493
Validation loss: 2.5722053779842486

Epoch: 5| Step: 8
Training loss: 3.009586752218387
Validation loss: 2.5770383193466713

Epoch: 5| Step: 9
Training loss: 3.1057805894433663
Validation loss: 2.5725731718567055

Epoch: 5| Step: 10
Training loss: 3.012408977732123
Validation loss: 2.5696091779164476

Epoch: 263| Step: 0
Training loss: 3.2723713233309555
Validation loss: 2.578917342881635

Epoch: 5| Step: 1
Training loss: 2.739329878731161
Validation loss: 2.5734247900989433

Epoch: 5| Step: 2
Training loss: 3.0522912033865635
Validation loss: 2.5677299822252215

Epoch: 5| Step: 3
Training loss: 2.9176685429049893
Validation loss: 2.567591838860235

Epoch: 5| Step: 4
Training loss: 2.465207612616678
Validation loss: 2.5760785922748

Epoch: 5| Step: 5
Training loss: 3.2778613803640075
Validation loss: 2.579386667223376

Epoch: 5| Step: 6
Training loss: 3.3635148909845785
Validation loss: 2.5852625771932636

Epoch: 5| Step: 7
Training loss: 2.581952392481987
Validation loss: 2.576902632858681

Epoch: 5| Step: 8
Training loss: 2.526175227353969
Validation loss: 2.573377630649591

Epoch: 5| Step: 9
Training loss: 2.8773931411535205
Validation loss: 2.567649381526982

Epoch: 5| Step: 10
Training loss: 2.6629972145848133
Validation loss: 2.569981364393335

Epoch: 264| Step: 0
Training loss: 2.589607515679956
Validation loss: 2.5732245813793955

Epoch: 5| Step: 1
Training loss: 3.0449298616295994
Validation loss: 2.562929607148116

Epoch: 5| Step: 2
Training loss: 2.7413573135961107
Validation loss: 2.5692602615024365

Epoch: 5| Step: 3
Training loss: 3.1854441875884767
Validation loss: 2.5712836805509864

Epoch: 5| Step: 4
Training loss: 2.9604150316169906
Validation loss: 2.5647465552109736

Epoch: 5| Step: 5
Training loss: 3.180006156531558
Validation loss: 2.559744814620097

Epoch: 5| Step: 6
Training loss: 3.2364819431988714
Validation loss: 2.560745736269777

Epoch: 5| Step: 7
Training loss: 2.662505738158154
Validation loss: 2.5667098345227415

Epoch: 5| Step: 8
Training loss: 2.3927050747570346
Validation loss: 2.5742216819006916

Epoch: 5| Step: 9
Training loss: 3.119059753325032
Validation loss: 2.5760855883226883

Epoch: 5| Step: 10
Training loss: 2.6592820757579037
Validation loss: 2.567606847683996

Epoch: 265| Step: 0
Training loss: 3.084291429556637
Validation loss: 2.577904929932561

Epoch: 5| Step: 1
Training loss: 2.8418542600520484
Validation loss: 2.565360962538952

Epoch: 5| Step: 2
Training loss: 3.0574470406887198
Validation loss: 2.57783579765775

Epoch: 5| Step: 3
Training loss: 2.493096069412894
Validation loss: 2.581557807584977

Epoch: 5| Step: 4
Training loss: 2.9101711605637313
Validation loss: 2.5896427960852146

Epoch: 5| Step: 5
Training loss: 3.0143382435265487
Validation loss: 2.581927315481146

Epoch: 5| Step: 6
Training loss: 2.456388695758898
Validation loss: 2.5904517742469038

Epoch: 5| Step: 7
Training loss: 3.3362010699814997
Validation loss: 2.581454718993935

Epoch: 5| Step: 8
Training loss: 2.684963537497832
Validation loss: 2.5879677265218697

Epoch: 5| Step: 9
Training loss: 3.01449753631071
Validation loss: 2.5856190479085357

Epoch: 5| Step: 10
Training loss: 2.845354235540455
Validation loss: 2.5851033858824297

Epoch: 266| Step: 0
Training loss: 3.0945331853731957
Validation loss: 2.5978546439373966

Epoch: 5| Step: 1
Training loss: 2.6728615528905366
Validation loss: 2.5810596180038057

Epoch: 5| Step: 2
Training loss: 2.599749233917408
Validation loss: 2.5838675196410597

Epoch: 5| Step: 3
Training loss: 3.2391687518375543
Validation loss: 2.5877234830802633

Epoch: 5| Step: 4
Training loss: 3.0510972722644123
Validation loss: 2.5795206269349946

Epoch: 5| Step: 5
Training loss: 3.131378987410015
Validation loss: 2.5813749391225045

Epoch: 5| Step: 6
Training loss: 2.729267167043931
Validation loss: 2.5848203557815306

Epoch: 5| Step: 7
Training loss: 2.8047305983098374
Validation loss: 2.5885418918131085

Epoch: 5| Step: 8
Training loss: 2.636715585212221
Validation loss: 2.5878808435064435

Epoch: 5| Step: 9
Training loss: 2.8024442834956003
Validation loss: 2.579361262137033

Epoch: 5| Step: 10
Training loss: 3.0288502740890184
Validation loss: 2.5830207437772765

Epoch: 267| Step: 0
Training loss: 2.9771061598532444
Validation loss: 2.579904605694615

Epoch: 5| Step: 1
Training loss: 2.6244188301149296
Validation loss: 2.5798480220420257

Epoch: 5| Step: 2
Training loss: 2.56434732234856
Validation loss: 2.575372006029119

Epoch: 5| Step: 3
Training loss: 2.7443660765650284
Validation loss: 2.5722047630386164

Epoch: 5| Step: 4
Training loss: 2.6876307610926005
Validation loss: 2.5696114725731136

Epoch: 5| Step: 5
Training loss: 3.034958763030948
Validation loss: 2.5729576234786395

Epoch: 5| Step: 6
Training loss: 3.362410766098209
Validation loss: 2.5760019828145073

Epoch: 5| Step: 7
Training loss: 2.6540714081138956
Validation loss: 2.576965461071489

Epoch: 5| Step: 8
Training loss: 3.495940579090517
Validation loss: 2.5744282091710877

Epoch: 5| Step: 9
Training loss: 3.1175166747405147
Validation loss: 2.5901897650103503

Epoch: 5| Step: 10
Training loss: 2.276936149435723
Validation loss: 2.6022340148754037

Epoch: 268| Step: 0
Training loss: 2.3931857088866377
Validation loss: 2.629271273188564

Epoch: 5| Step: 1
Training loss: 2.5909462907849283
Validation loss: 2.6223997303493354

Epoch: 5| Step: 2
Training loss: 3.304223860012762
Validation loss: 2.618307616381415

Epoch: 5| Step: 3
Training loss: 2.97705042086526
Validation loss: 2.5963878321875162

Epoch: 5| Step: 4
Training loss: 3.1963614162201037
Validation loss: 2.595685450981382

Epoch: 5| Step: 5
Training loss: 3.1349674718407385
Validation loss: 2.5897052078040503

Epoch: 5| Step: 6
Training loss: 3.088371610972115
Validation loss: 2.575676502551805

Epoch: 5| Step: 7
Training loss: 2.781629215062261
Validation loss: 2.5649874959501493

Epoch: 5| Step: 8
Training loss: 2.4914245394265384
Validation loss: 2.5728031283021284

Epoch: 5| Step: 9
Training loss: 2.9820480462136687
Validation loss: 2.5630250348390065

Epoch: 5| Step: 10
Training loss: 2.8550791337625627
Validation loss: 2.565910542835833

Epoch: 269| Step: 0
Training loss: 2.6719339821534835
Validation loss: 2.559866175172369

Epoch: 5| Step: 1
Training loss: 3.19290555476557
Validation loss: 2.557809098224206

Epoch: 5| Step: 2
Training loss: 2.9937848242404694
Validation loss: 2.559224901817958

Epoch: 5| Step: 3
Training loss: 2.7565379885431462
Validation loss: 2.5756188276770016

Epoch: 5| Step: 4
Training loss: 3.3244007746598605
Validation loss: 2.5670593842103377

Epoch: 5| Step: 5
Training loss: 2.787290293242254
Validation loss: 2.569920507190938

Epoch: 5| Step: 6
Training loss: 2.852121961920448
Validation loss: 2.5713052431751224

Epoch: 5| Step: 7
Training loss: 2.692618972997542
Validation loss: 2.591154905317658

Epoch: 5| Step: 8
Training loss: 3.17222706010683
Validation loss: 2.611390425364517

Epoch: 5| Step: 9
Training loss: 2.1559043275487566
Validation loss: 2.6297566522632208

Epoch: 5| Step: 10
Training loss: 3.185201227367854
Validation loss: 2.6030076714121364

Epoch: 270| Step: 0
Training loss: 3.4619885779621558
Validation loss: 2.6166805417322823

Epoch: 5| Step: 1
Training loss: 2.6916164543105836
Validation loss: 2.59073709244694

Epoch: 5| Step: 2
Training loss: 3.2745308518167167
Validation loss: 2.564521069566092

Epoch: 5| Step: 3
Training loss: 2.699323064220991
Validation loss: 2.5638585204912636

Epoch: 5| Step: 4
Training loss: 2.517717900624298
Validation loss: 2.564262208397952

Epoch: 5| Step: 5
Training loss: 2.72638323612656
Validation loss: 2.5603880298871777

Epoch: 5| Step: 6
Training loss: 2.738999994830173
Validation loss: 2.564579377878109

Epoch: 5| Step: 7
Training loss: 2.923996751671277
Validation loss: 2.5649741239405306

Epoch: 5| Step: 8
Training loss: 2.646086062478453
Validation loss: 2.5630287147200064

Epoch: 5| Step: 9
Training loss: 3.075424326330808
Validation loss: 2.575760875048544

Epoch: 5| Step: 10
Training loss: 3.0980427562208623
Validation loss: 2.574751182782124

Epoch: 271| Step: 0
Training loss: 2.7546872161155376
Validation loss: 2.589038294079225

Epoch: 5| Step: 1
Training loss: 3.0576636604181466
Validation loss: 2.5831688935429993

Epoch: 5| Step: 2
Training loss: 2.8436255794596494
Validation loss: 2.5745125648221032

Epoch: 5| Step: 3
Training loss: 2.8484167017676993
Validation loss: 2.577487594052499

Epoch: 5| Step: 4
Training loss: 2.843027043930812
Validation loss: 2.5656803693039243

Epoch: 5| Step: 5
Training loss: 3.137763850451651
Validation loss: 2.578101399233807

Epoch: 5| Step: 6
Training loss: 2.9219655721569695
Validation loss: 2.557608874955635

Epoch: 5| Step: 7
Training loss: 3.165125237468474
Validation loss: 2.5646832937205866

Epoch: 5| Step: 8
Training loss: 2.919897052570077
Validation loss: 2.57135441868172

Epoch: 5| Step: 9
Training loss: 3.004937559167756
Validation loss: 2.5846619753615907

Epoch: 5| Step: 10
Training loss: 2.168211117505222
Validation loss: 2.5890928237805415

Epoch: 272| Step: 0
Training loss: 3.296642277173837
Validation loss: 2.5953486576838487

Epoch: 5| Step: 1
Training loss: 3.014416704579454
Validation loss: 2.598040128771256

Epoch: 5| Step: 2
Training loss: 2.247633431179246
Validation loss: 2.5896953445647766

Epoch: 5| Step: 3
Training loss: 2.9173887358094115
Validation loss: 2.591761625895482

Epoch: 5| Step: 4
Training loss: 2.6201412101722066
Validation loss: 2.5861929178196057

Epoch: 5| Step: 5
Training loss: 3.24469941050421
Validation loss: 2.5846606849424445

Epoch: 5| Step: 6
Training loss: 3.041926194358408
Validation loss: 2.5651818569709692

Epoch: 5| Step: 7
Training loss: 2.890924551624202
Validation loss: 2.584015104958605

Epoch: 5| Step: 8
Training loss: 2.7590409695555067
Validation loss: 2.5797388697810764

Epoch: 5| Step: 9
Training loss: 2.45428517114331
Validation loss: 2.578704263762723

Epoch: 5| Step: 10
Training loss: 3.1746559917885167
Validation loss: 2.582366902181645

Epoch: 273| Step: 0
Training loss: 2.6773331422932367
Validation loss: 2.5648661388351743

Epoch: 5| Step: 1
Training loss: 3.1543490284484887
Validation loss: 2.5784606794612026

Epoch: 5| Step: 2
Training loss: 3.0365229098660054
Validation loss: 2.5750641841597037

Epoch: 5| Step: 3
Training loss: 2.942781934689813
Validation loss: 2.578978491766804

Epoch: 5| Step: 4
Training loss: 2.492772335682002
Validation loss: 2.57855484537197

Epoch: 5| Step: 5
Training loss: 2.9437813662014083
Validation loss: 2.581876503424576

Epoch: 5| Step: 6
Training loss: 2.886644747021672
Validation loss: 2.592015945606692

Epoch: 5| Step: 7
Training loss: 2.846918541651709
Validation loss: 2.5914124809478922

Epoch: 5| Step: 8
Training loss: 2.2789794910105656
Validation loss: 2.593596457720453

Epoch: 5| Step: 9
Training loss: 3.034095608295546
Validation loss: 2.6005597339917594

Epoch: 5| Step: 10
Training loss: 3.3764453195047404
Validation loss: 2.579266902030715

Epoch: 274| Step: 0
Training loss: 3.0791771344397105
Validation loss: 2.5869507323389684

Epoch: 5| Step: 1
Training loss: 2.931904109370388
Validation loss: 2.581586660768971

Epoch: 5| Step: 2
Training loss: 2.1227029839496736
Validation loss: 2.5742051819486975

Epoch: 5| Step: 3
Training loss: 3.30426628729082
Validation loss: 2.565905287483658

Epoch: 5| Step: 4
Training loss: 3.2578691436453826
Validation loss: 2.569053086269492

Epoch: 5| Step: 5
Training loss: 3.1983150933961317
Validation loss: 2.5677491994990946

Epoch: 5| Step: 6
Training loss: 2.6256713008816313
Validation loss: 2.563795158093437

Epoch: 5| Step: 7
Training loss: 2.668785495209328
Validation loss: 2.571018882324975

Epoch: 5| Step: 8
Training loss: 2.7376412202823017
Validation loss: 2.5654433139544826

Epoch: 5| Step: 9
Training loss: 2.9608706665548468
Validation loss: 2.5655117988830973

Epoch: 5| Step: 10
Training loss: 2.8076959058258186
Validation loss: 2.5706414069221957

Epoch: 275| Step: 0
Training loss: 3.1778041501347705
Validation loss: 2.565472353370329

Epoch: 5| Step: 1
Training loss: 3.165908538682881
Validation loss: 2.5732082742901556

Epoch: 5| Step: 2
Training loss: 3.173434771297602
Validation loss: 2.5679201069011435

Epoch: 5| Step: 3
Training loss: 2.3224643785847228
Validation loss: 2.563569582765703

Epoch: 5| Step: 4
Training loss: 2.7739551329776315
Validation loss: 2.5709339882474604

Epoch: 5| Step: 5
Training loss: 3.009797469260887
Validation loss: 2.5626197644890816

Epoch: 5| Step: 6
Training loss: 2.7796852767961178
Validation loss: 2.5680627837611665

Epoch: 5| Step: 7
Training loss: 2.8499242805996383
Validation loss: 2.563660571672819

Epoch: 5| Step: 8
Training loss: 3.2281120957359457
Validation loss: 2.5775551204338174

Epoch: 5| Step: 9
Training loss: 2.4185500424554642
Validation loss: 2.578073974780619

Epoch: 5| Step: 10
Training loss: 2.65095791687546
Validation loss: 2.57104464405239

Epoch: 276| Step: 0
Training loss: 3.1148227527332635
Validation loss: 2.569639822388337

Epoch: 5| Step: 1
Training loss: 2.964396768482379
Validation loss: 2.561973248517678

Epoch: 5| Step: 2
Training loss: 2.9324183236249644
Validation loss: 2.567686053920334

Epoch: 5| Step: 3
Training loss: 2.0163341132425416
Validation loss: 2.5763508310055423

Epoch: 5| Step: 4
Training loss: 2.4864411789092333
Validation loss: 2.5813182357480735

Epoch: 5| Step: 5
Training loss: 2.4367093491197105
Validation loss: 2.57927270067941

Epoch: 5| Step: 6
Training loss: 3.304612323456021
Validation loss: 2.5830983598555113

Epoch: 5| Step: 7
Training loss: 3.068883820702286
Validation loss: 2.579137028365436

Epoch: 5| Step: 8
Training loss: 2.6295974072296477
Validation loss: 2.580491326346133

Epoch: 5| Step: 9
Training loss: 3.1892174974199565
Validation loss: 2.58359973643985

Epoch: 5| Step: 10
Training loss: 3.3459865897594536
Validation loss: 2.5801493453617095

Epoch: 277| Step: 0
Training loss: 3.412496875579857
Validation loss: 2.5946176419239566

Epoch: 5| Step: 1
Training loss: 2.587704426526755
Validation loss: 2.575524105500987

Epoch: 5| Step: 2
Training loss: 2.969438332516794
Validation loss: 2.585127842019467

Epoch: 5| Step: 3
Training loss: 2.7323732733068145
Validation loss: 2.5980315942747985

Epoch: 5| Step: 4
Training loss: 2.356087826275432
Validation loss: 2.581659332024847

Epoch: 5| Step: 5
Training loss: 3.115274631156434
Validation loss: 2.587457879898561

Epoch: 5| Step: 6
Training loss: 2.837081468274994
Validation loss: 2.5738411462625588

Epoch: 5| Step: 7
Training loss: 2.3265775107468873
Validation loss: 2.582809782878214

Epoch: 5| Step: 8
Training loss: 3.1463992049886675
Validation loss: 2.570018101267708

Epoch: 5| Step: 9
Training loss: 2.7117617011068815
Validation loss: 2.566638015998144

Epoch: 5| Step: 10
Training loss: 3.3929630779277797
Validation loss: 2.5659396618877697

Epoch: 278| Step: 0
Training loss: 3.009974903749799
Validation loss: 2.564589013331734

Epoch: 5| Step: 1
Training loss: 2.9752719915096693
Validation loss: 2.5735591627431367

Epoch: 5| Step: 2
Training loss: 2.507871252779939
Validation loss: 2.57135584538848

Epoch: 5| Step: 3
Training loss: 2.094600675485925
Validation loss: 2.5786040804695802

Epoch: 5| Step: 4
Training loss: 2.9573880865958
Validation loss: 2.5747026815226564

Epoch: 5| Step: 5
Training loss: 3.3198665543819392
Validation loss: 2.5947603041371186

Epoch: 5| Step: 6
Training loss: 3.165825849301485
Validation loss: 2.5938124754787384

Epoch: 5| Step: 7
Training loss: 2.8975274232976997
Validation loss: 2.615556392121995

Epoch: 5| Step: 8
Training loss: 3.1636178916981823
Validation loss: 2.620991174736689

Epoch: 5| Step: 9
Training loss: 3.004595257101459
Validation loss: 2.597825276700447

Epoch: 5| Step: 10
Training loss: 2.477511347524329
Validation loss: 2.5692182761924935

Epoch: 279| Step: 0
Training loss: 3.0697969969690337
Validation loss: 2.5647772262964117

Epoch: 5| Step: 1
Training loss: 2.8918853486524974
Validation loss: 2.557953622902066

Epoch: 5| Step: 2
Training loss: 3.1618756307407887
Validation loss: 2.559948277236947

Epoch: 5| Step: 3
Training loss: 2.3185611370319275
Validation loss: 2.5699133157968275

Epoch: 5| Step: 4
Training loss: 3.0072030378881944
Validation loss: 2.5600666595071746

Epoch: 5| Step: 5
Training loss: 2.5253724984848307
Validation loss: 2.565124609248234

Epoch: 5| Step: 6
Training loss: 2.7909468581615426
Validation loss: 2.5702712380519976

Epoch: 5| Step: 7
Training loss: 3.0696141659709757
Validation loss: 2.556474905146339

Epoch: 5| Step: 8
Training loss: 3.1251893558353645
Validation loss: 2.567248555960409

Epoch: 5| Step: 9
Training loss: 2.682667757105495
Validation loss: 2.567689929801274

Epoch: 5| Step: 10
Training loss: 2.999847408228667
Validation loss: 2.566012094907892

Epoch: 280| Step: 0
Training loss: 2.847900715029584
Validation loss: 2.5578566459405074

Epoch: 5| Step: 1
Training loss: 2.678715031725362
Validation loss: 2.5604571171103183

Epoch: 5| Step: 2
Training loss: 2.9155894515475915
Validation loss: 2.566304795440054

Epoch: 5| Step: 3
Training loss: 3.2799845843999584
Validation loss: 2.5684644185006866

Epoch: 5| Step: 4
Training loss: 2.691846836386492
Validation loss: 2.558663751351752

Epoch: 5| Step: 5
Training loss: 2.306050353467385
Validation loss: 2.584480964226321

Epoch: 5| Step: 6
Training loss: 2.5798409964483406
Validation loss: 2.584834037710679

Epoch: 5| Step: 7
Training loss: 2.9482764753512964
Validation loss: 2.5758770213076176

Epoch: 5| Step: 8
Training loss: 3.1606399675180437
Validation loss: 2.587428567058954

Epoch: 5| Step: 9
Training loss: 3.363365606475131
Validation loss: 2.6079655800797834

Epoch: 5| Step: 10
Training loss: 2.6394106990379123
Validation loss: 2.6129863797120922

Epoch: 281| Step: 0
Training loss: 3.1876014244548396
Validation loss: 2.590924264297165

Epoch: 5| Step: 1
Training loss: 2.851571195406263
Validation loss: 2.5911786157359784

Epoch: 5| Step: 2
Training loss: 3.0263421352121362
Validation loss: 2.599839039443416

Epoch: 5| Step: 3
Training loss: 3.357679640110532
Validation loss: 2.591170145704921

Epoch: 5| Step: 4
Training loss: 2.919024704089278
Validation loss: 2.5957597294445898

Epoch: 5| Step: 5
Training loss: 3.2613009065256877
Validation loss: 2.575747843624675

Epoch: 5| Step: 6
Training loss: 2.8003656352957225
Validation loss: 2.5710821913377297

Epoch: 5| Step: 7
Training loss: 2.32936810581752
Validation loss: 2.576218164316954

Epoch: 5| Step: 8
Training loss: 2.5401069253657926
Validation loss: 2.5696644217053444

Epoch: 5| Step: 9
Training loss: 2.7938452139039756
Validation loss: 2.5708450766520388

Epoch: 5| Step: 10
Training loss: 2.3998641452485208
Validation loss: 2.5734800695285753

Epoch: 282| Step: 0
Training loss: 2.723021385632836
Validation loss: 2.5656395489572184

Epoch: 5| Step: 1
Training loss: 3.231262330966936
Validation loss: 2.57325221592114

Epoch: 5| Step: 2
Training loss: 2.3744120623012264
Validation loss: 2.577356260060979

Epoch: 5| Step: 3
Training loss: 2.8300710484512974
Validation loss: 2.6007564564356223

Epoch: 5| Step: 4
Training loss: 2.862323345746932
Validation loss: 2.6112393370490627

Epoch: 5| Step: 5
Training loss: 3.220375613464503
Validation loss: 2.6196876247040892

Epoch: 5| Step: 6
Training loss: 2.623246560978178
Validation loss: 2.638261915687248

Epoch: 5| Step: 7
Training loss: 2.16276682271512
Validation loss: 2.6193275866688865

Epoch: 5| Step: 8
Training loss: 2.923033296012409
Validation loss: 2.642542303728526

Epoch: 5| Step: 9
Training loss: 3.690939899030711
Validation loss: 2.608479758453066

Epoch: 5| Step: 10
Training loss: 2.7104161005706158
Validation loss: 2.595132803359863

Epoch: 283| Step: 0
Training loss: 2.806545906353394
Validation loss: 2.5760617160970196

Epoch: 5| Step: 1
Training loss: 2.3205709088733166
Validation loss: 2.5586407120211767

Epoch: 5| Step: 2
Training loss: 2.6173583017668562
Validation loss: 2.567068919476829

Epoch: 5| Step: 3
Training loss: 3.0774464125503695
Validation loss: 2.553100962328702

Epoch: 5| Step: 4
Training loss: 2.8296919217593834
Validation loss: 2.5539171700010175

Epoch: 5| Step: 5
Training loss: 2.8799086421145845
Validation loss: 2.5615427613859185

Epoch: 5| Step: 6
Training loss: 2.858412617138984
Validation loss: 2.5632519822900215

Epoch: 5| Step: 7
Training loss: 2.9874141856362213
Validation loss: 2.5705803190128007

Epoch: 5| Step: 8
Training loss: 3.1516867405578095
Validation loss: 2.568999661505115

Epoch: 5| Step: 9
Training loss: 3.2856651029992974
Validation loss: 2.57037164838423

Epoch: 5| Step: 10
Training loss: 2.71746848585566
Validation loss: 2.589390390724072

Epoch: 284| Step: 0
Training loss: 2.6998544653770336
Validation loss: 2.584157195757833

Epoch: 5| Step: 1
Training loss: 2.666941767648632
Validation loss: 2.615374683427529

Epoch: 5| Step: 2
Training loss: 2.8873067419600518
Validation loss: 2.637389859771742

Epoch: 5| Step: 3
Training loss: 2.930249620551996
Validation loss: 2.6484007870806647

Epoch: 5| Step: 4
Training loss: 2.4012155752578908
Validation loss: 2.623214217769905

Epoch: 5| Step: 5
Training loss: 2.463859155908679
Validation loss: 2.6033060994088695

Epoch: 5| Step: 6
Training loss: 3.1329201087640186
Validation loss: 2.5861037035826886

Epoch: 5| Step: 7
Training loss: 3.088988059058161
Validation loss: 2.5649657372891648

Epoch: 5| Step: 8
Training loss: 3.0014965774946196
Validation loss: 2.558172259588311

Epoch: 5| Step: 9
Training loss: 3.2440065727120264
Validation loss: 2.5464325221084216

Epoch: 5| Step: 10
Training loss: 3.0927176246148025
Validation loss: 2.5571690072943007

Epoch: 285| Step: 0
Training loss: 2.893738260925079
Validation loss: 2.556226838764609

Epoch: 5| Step: 1
Training loss: 2.748703911270455
Validation loss: 2.5553365044017116

Epoch: 5| Step: 2
Training loss: 3.18568054330418
Validation loss: 2.551208577888844

Epoch: 5| Step: 3
Training loss: 2.600902118435332
Validation loss: 2.5539139839147387

Epoch: 5| Step: 4
Training loss: 2.853339490735312
Validation loss: 2.5480779246364267

Epoch: 5| Step: 5
Training loss: 2.53626818143251
Validation loss: 2.548655007898123

Epoch: 5| Step: 6
Training loss: 3.2006619543628716
Validation loss: 2.5507584153582803

Epoch: 5| Step: 7
Training loss: 3.0148580099551006
Validation loss: 2.5545492594882653

Epoch: 5| Step: 8
Training loss: 2.5322879499886493
Validation loss: 2.5537336353145106

Epoch: 5| Step: 9
Training loss: 2.956034846470827
Validation loss: 2.565105694127548

Epoch: 5| Step: 10
Training loss: 3.195804026509525
Validation loss: 2.5704122065751145

Epoch: 286| Step: 0
Training loss: 2.736949384523061
Validation loss: 2.5740235440285546

Epoch: 5| Step: 1
Training loss: 3.2612551422487996
Validation loss: 2.59372589104077

Epoch: 5| Step: 2
Training loss: 2.7368632303225713
Validation loss: 2.577412860122592

Epoch: 5| Step: 3
Training loss: 3.4186331664490717
Validation loss: 2.566474419553431

Epoch: 5| Step: 4
Training loss: 2.696904958688973
Validation loss: 2.5467353891750117

Epoch: 5| Step: 5
Training loss: 2.505628924577265
Validation loss: 2.541661585441794

Epoch: 5| Step: 6
Training loss: 3.2589106549929476
Validation loss: 2.541771794940123

Epoch: 5| Step: 7
Training loss: 2.738442322351201
Validation loss: 2.5481944553938525

Epoch: 5| Step: 8
Training loss: 3.0044586110329687
Validation loss: 2.5423916012012397

Epoch: 5| Step: 9
Training loss: 2.5300656597377524
Validation loss: 2.5464228531887882

Epoch: 5| Step: 10
Training loss: 2.826687442175373
Validation loss: 2.558017879639721

Epoch: 287| Step: 0
Training loss: 2.6589224442630353
Validation loss: 2.5707029880173655

Epoch: 5| Step: 1
Training loss: 3.0762162075178505
Validation loss: 2.6009575373448253

Epoch: 5| Step: 2
Training loss: 2.8762257492322947
Validation loss: 2.5956231889834736

Epoch: 5| Step: 3
Training loss: 3.027626309898184
Validation loss: 2.593634360550403

Epoch: 5| Step: 4
Training loss: 2.5887363189232606
Validation loss: 2.5952193754330612

Epoch: 5| Step: 5
Training loss: 2.268240635547629
Validation loss: 2.584878551333833

Epoch: 5| Step: 6
Training loss: 2.780571158212166
Validation loss: 2.6014708599197753

Epoch: 5| Step: 7
Training loss: 3.048401122704692
Validation loss: 2.597326113157152

Epoch: 5| Step: 8
Training loss: 2.9250185778427285
Validation loss: 2.6194273770965752

Epoch: 5| Step: 9
Training loss: 3.0604946811220355
Validation loss: 2.6097015968343693

Epoch: 5| Step: 10
Training loss: 3.379189610589558
Validation loss: 2.6053715746617643

Epoch: 288| Step: 0
Training loss: 2.650896489353295
Validation loss: 2.589079302486214

Epoch: 5| Step: 1
Training loss: 3.0618226216950637
Validation loss: 2.5963049989370597

Epoch: 5| Step: 2
Training loss: 2.610537880906716
Validation loss: 2.5710234551601183

Epoch: 5| Step: 3
Training loss: 2.4978681057453676
Validation loss: 2.5723430892127728

Epoch: 5| Step: 4
Training loss: 2.7683748701525044
Validation loss: 2.575751677515637

Epoch: 5| Step: 5
Training loss: 2.801208633737034
Validation loss: 2.566165296613204

Epoch: 5| Step: 6
Training loss: 3.0413615104153817
Validation loss: 2.5660744974238487

Epoch: 5| Step: 7
Training loss: 2.1938517315960646
Validation loss: 2.565626515586425

Epoch: 5| Step: 8
Training loss: 3.192996503178718
Validation loss: 2.561683864970375

Epoch: 5| Step: 9
Training loss: 3.2153957630002137
Validation loss: 2.5687582897051224

Epoch: 5| Step: 10
Training loss: 3.4529624659058475
Validation loss: 2.5707571542273158

Epoch: 289| Step: 0
Training loss: 2.8648585701697726
Validation loss: 2.5611222637992714

Epoch: 5| Step: 1
Training loss: 2.5928950911608184
Validation loss: 2.563860222346057

Epoch: 5| Step: 2
Training loss: 2.604590134840377
Validation loss: 2.5718714807413754

Epoch: 5| Step: 3
Training loss: 3.0942570434598635
Validation loss: 2.566870852694608

Epoch: 5| Step: 4
Training loss: 2.9300849339800568
Validation loss: 2.568892256773733

Epoch: 5| Step: 5
Training loss: 3.004144031652783
Validation loss: 2.5721236736443327

Epoch: 5| Step: 6
Training loss: 2.68024636716181
Validation loss: 2.5770313099683677

Epoch: 5| Step: 7
Training loss: 3.1713066907363254
Validation loss: 2.589327483802844

Epoch: 5| Step: 8
Training loss: 2.9306188298325395
Validation loss: 2.5874711723717208

Epoch: 5| Step: 9
Training loss: 2.768462455060893
Validation loss: 2.5741840041332122

Epoch: 5| Step: 10
Training loss: 2.831801074967314
Validation loss: 2.58980037101206

Epoch: 290| Step: 0
Training loss: 2.3977533911811393
Validation loss: 2.60025284021305

Epoch: 5| Step: 1
Training loss: 2.9500896052313466
Validation loss: 2.599321107285805

Epoch: 5| Step: 2
Training loss: 2.803023585905857
Validation loss: 2.6165755096205907

Epoch: 5| Step: 3
Training loss: 2.455021896264658
Validation loss: 2.61485122924748

Epoch: 5| Step: 4
Training loss: 3.090701981097808
Validation loss: 2.6262311104300644

Epoch: 5| Step: 5
Training loss: 3.2019902894386902
Validation loss: 2.618579497383823

Epoch: 5| Step: 6
Training loss: 3.4289007653144505
Validation loss: 2.6307182679480343

Epoch: 5| Step: 7
Training loss: 3.209047527005266
Validation loss: 2.5864894619770116

Epoch: 5| Step: 8
Training loss: 2.764537360339235
Validation loss: 2.578088243408301

Epoch: 5| Step: 9
Training loss: 2.8167565243023236
Validation loss: 2.5727384715709807

Epoch: 5| Step: 10
Training loss: 2.167927839563326
Validation loss: 2.549586363912961

Epoch: 291| Step: 0
Training loss: 2.827620740584173
Validation loss: 2.5448981657743244

Epoch: 5| Step: 1
Training loss: 2.9458607939897496
Validation loss: 2.5405323302020446

Epoch: 5| Step: 2
Training loss: 2.783675518435519
Validation loss: 2.555330351463764

Epoch: 5| Step: 3
Training loss: 3.146878066909038
Validation loss: 2.5524039610577196

Epoch: 5| Step: 4
Training loss: 2.749726195142781
Validation loss: 2.556081782171384

Epoch: 5| Step: 5
Training loss: 2.471113208618158
Validation loss: 2.553326738601188

Epoch: 5| Step: 6
Training loss: 2.9761542893889166
Validation loss: 2.5633406962042766

Epoch: 5| Step: 7
Training loss: 3.4066012140196076
Validation loss: 2.5646742643770097

Epoch: 5| Step: 8
Training loss: 3.1737442897581496
Validation loss: 2.57388540179154

Epoch: 5| Step: 9
Training loss: 2.356893687268982
Validation loss: 2.5877977567770127

Epoch: 5| Step: 10
Training loss: 2.5490513027890374
Validation loss: 2.6167713145990255

Epoch: 292| Step: 0
Training loss: 2.181616145229713
Validation loss: 2.6342687276376764

Epoch: 5| Step: 1
Training loss: 3.002583027500844
Validation loss: 2.644040148692666

Epoch: 5| Step: 2
Training loss: 2.713688314994015
Validation loss: 2.6511749316925033

Epoch: 5| Step: 3
Training loss: 3.2923789078697854
Validation loss: 2.6750441986778175

Epoch: 5| Step: 4
Training loss: 2.7018343098718116
Validation loss: 2.660594266202968

Epoch: 5| Step: 5
Training loss: 2.8427239547715897
Validation loss: 2.6163736850153745

Epoch: 5| Step: 6
Training loss: 3.3043961633271857
Validation loss: 2.5975546885542773

Epoch: 5| Step: 7
Training loss: 2.79609856936862
Validation loss: 2.596673926735677

Epoch: 5| Step: 8
Training loss: 2.7257381384412236
Validation loss: 2.589792089504308

Epoch: 5| Step: 9
Training loss: 3.02932568062344
Validation loss: 2.5869848835886704

Epoch: 5| Step: 10
Training loss: 2.9266113407521908
Validation loss: 2.5711004881617026

Epoch: 293| Step: 0
Training loss: 3.076805180345004
Validation loss: 2.570995138550429

Epoch: 5| Step: 1
Training loss: 2.672322018355497
Validation loss: 2.5658510932845524

Epoch: 5| Step: 2
Training loss: 2.767298046900116
Validation loss: 2.5631261341222595

Epoch: 5| Step: 3
Training loss: 2.793269043898049
Validation loss: 2.56298935702352

Epoch: 5| Step: 4
Training loss: 2.960571266413079
Validation loss: 2.552489378025215

Epoch: 5| Step: 5
Training loss: 2.5532579067566847
Validation loss: 2.5534208379494947

Epoch: 5| Step: 6
Training loss: 3.3521265653418877
Validation loss: 2.5643744187360396

Epoch: 5| Step: 7
Training loss: 2.3833864615149727
Validation loss: 2.561376471915049

Epoch: 5| Step: 8
Training loss: 3.341609091195344
Validation loss: 2.5587206035905794

Epoch: 5| Step: 9
Training loss: 2.7281924734259686
Validation loss: 2.562521045277251

Epoch: 5| Step: 10
Training loss: 2.781164789501828
Validation loss: 2.5637139347024567

Epoch: 294| Step: 0
Training loss: 2.8184216360932988
Validation loss: 2.563097205153234

Epoch: 5| Step: 1
Training loss: 3.27212840559067
Validation loss: 2.549918609806554

Epoch: 5| Step: 2
Training loss: 2.6711443521103067
Validation loss: 2.5620619126514264

Epoch: 5| Step: 3
Training loss: 3.263067384688683
Validation loss: 2.5618409600643597

Epoch: 5| Step: 4
Training loss: 3.340495870180265
Validation loss: 2.564478529822624

Epoch: 5| Step: 5
Training loss: 2.8463491781225345
Validation loss: 2.563332790267112

Epoch: 5| Step: 6
Training loss: 2.336856112815762
Validation loss: 2.5636514967273283

Epoch: 5| Step: 7
Training loss: 2.8524185358930496
Validation loss: 2.562358891333331

Epoch: 5| Step: 8
Training loss: 2.998559765015144
Validation loss: 2.5813431647289224

Epoch: 5| Step: 9
Training loss: 2.156277089708964
Validation loss: 2.560667751021588

Epoch: 5| Step: 10
Training loss: 2.704508432931953
Validation loss: 2.56743355392997

Epoch: 295| Step: 0
Training loss: 2.7900629893750026
Validation loss: 2.5798358221410114

Epoch: 5| Step: 1
Training loss: 3.0714955465168674
Validation loss: 2.5681147166535827

Epoch: 5| Step: 2
Training loss: 2.5537080432882737
Validation loss: 2.5809908652313465

Epoch: 5| Step: 3
Training loss: 3.1823985846123635
Validation loss: 2.5811831824516123

Epoch: 5| Step: 4
Training loss: 2.655054878199319
Validation loss: 2.574937312359389

Epoch: 5| Step: 5
Training loss: 2.603905067020105
Validation loss: 2.5602644416062152

Epoch: 5| Step: 6
Training loss: 3.3146742396873003
Validation loss: 2.554700431127436

Epoch: 5| Step: 7
Training loss: 2.7847783713785472
Validation loss: 2.554579809645511

Epoch: 5| Step: 8
Training loss: 2.787325106894759
Validation loss: 2.556437259645554

Epoch: 5| Step: 9
Training loss: 2.8157734788364372
Validation loss: 2.5496628058396777

Epoch: 5| Step: 10
Training loss: 2.88792499535715
Validation loss: 2.5544596110025672

Epoch: 296| Step: 0
Training loss: 2.7802401648869624
Validation loss: 2.57724211221724

Epoch: 5| Step: 1
Training loss: 3.0844587042213543
Validation loss: 2.574388684184058

Epoch: 5| Step: 2
Training loss: 3.057745999961534
Validation loss: 2.5847742810178054

Epoch: 5| Step: 3
Training loss: 2.5026693398480506
Validation loss: 2.582118855056736

Epoch: 5| Step: 4
Training loss: 2.671305099297479
Validation loss: 2.576974819413319

Epoch: 5| Step: 5
Training loss: 2.144236837998928
Validation loss: 2.5860494598023203

Epoch: 5| Step: 6
Training loss: 3.6058806972391872
Validation loss: 2.5966846771902516

Epoch: 5| Step: 7
Training loss: 2.931643552734214
Validation loss: 2.576166197246933

Epoch: 5| Step: 8
Training loss: 2.433734626427573
Validation loss: 2.5747329099096983

Epoch: 5| Step: 9
Training loss: 3.3032825270003827
Validation loss: 2.5775727934503605

Epoch: 5| Step: 10
Training loss: 2.6735805845513325
Validation loss: 2.5811797072295968

Epoch: 297| Step: 0
Training loss: 2.642160454537762
Validation loss: 2.563270008959523

Epoch: 5| Step: 1
Training loss: 3.199925457563029
Validation loss: 2.556492383942408

Epoch: 5| Step: 2
Training loss: 3.249768762431774
Validation loss: 2.5529256259876933

Epoch: 5| Step: 3
Training loss: 2.4578339883164477
Validation loss: 2.5529313112435226

Epoch: 5| Step: 4
Training loss: 2.9034525215335973
Validation loss: 2.567161234364648

Epoch: 5| Step: 5
Training loss: 2.925286081783852
Validation loss: 2.559032774689971

Epoch: 5| Step: 6
Training loss: 2.7308597312057232
Validation loss: 2.5478338785261005

Epoch: 5| Step: 7
Training loss: 1.9673280576344125
Validation loss: 2.557299652765486

Epoch: 5| Step: 8
Training loss: 2.930788692784823
Validation loss: 2.56472183175712

Epoch: 5| Step: 9
Training loss: 3.301515179361322
Validation loss: 2.577168201288574

Epoch: 5| Step: 10
Training loss: 2.912158661187973
Validation loss: 2.579171215487201

Epoch: 298| Step: 0
Training loss: 2.588610140984079
Validation loss: 2.5863005606286493

Epoch: 5| Step: 1
Training loss: 2.7141853686836077
Validation loss: 2.5874839505591605

Epoch: 5| Step: 2
Training loss: 3.168923343529396
Validation loss: 2.606027906871184

Epoch: 5| Step: 3
Training loss: 3.093582765317052
Validation loss: 2.6126158971053575

Epoch: 5| Step: 4
Training loss: 2.712073711878892
Validation loss: 2.6009861053437437

Epoch: 5| Step: 5
Training loss: 2.5919754208294177
Validation loss: 2.5771342651349043

Epoch: 5| Step: 6
Training loss: 2.7333068505221525
Validation loss: 2.574288318999896

Epoch: 5| Step: 7
Training loss: 2.684374211303453
Validation loss: 2.5561322835765514

Epoch: 5| Step: 8
Training loss: 3.3132965281826183
Validation loss: 2.5596598951663068

Epoch: 5| Step: 9
Training loss: 2.874844422484669
Validation loss: 2.557551857169526

Epoch: 5| Step: 10
Training loss: 2.8153803169719565
Validation loss: 2.5634384277757465

Epoch: 299| Step: 0
Training loss: 1.8342426024817196
Validation loss: 2.562061390329721

Epoch: 5| Step: 1
Training loss: 2.7839694497361513
Validation loss: 2.566689097265582

Epoch: 5| Step: 2
Training loss: 3.2346082225508477
Validation loss: 2.5662029033024845

Epoch: 5| Step: 3
Training loss: 3.267561197094526
Validation loss: 2.5656104599733527

Epoch: 5| Step: 4
Training loss: 3.354562123998035
Validation loss: 2.5547949209010397

Epoch: 5| Step: 5
Training loss: 2.4003266589066596
Validation loss: 2.561559227807811

Epoch: 5| Step: 6
Training loss: 2.7889943688883925
Validation loss: 2.569009503911687

Epoch: 5| Step: 7
Training loss: 2.6258864949457315
Validation loss: 2.568708908805896

Epoch: 5| Step: 8
Training loss: 3.2783723837836622
Validation loss: 2.592718747406125

Epoch: 5| Step: 9
Training loss: 2.772630687003531
Validation loss: 2.601981064346426

Epoch: 5| Step: 10
Training loss: 2.8071106880089154
Validation loss: 2.5895809228978752

Epoch: 300| Step: 0
Training loss: 3.5846234741824916
Validation loss: 2.5970910599113948

Epoch: 5| Step: 1
Training loss: 3.194724926636495
Validation loss: 2.579979070203511

Epoch: 5| Step: 2
Training loss: 2.4079775863187303
Validation loss: 2.5764935305483117

Epoch: 5| Step: 3
Training loss: 2.789297227572328
Validation loss: 2.563016783844438

Epoch: 5| Step: 4
Training loss: 3.3176375081613547
Validation loss: 2.566654481194343

Epoch: 5| Step: 5
Training loss: 2.585045329273867
Validation loss: 2.55378609751402

Epoch: 5| Step: 6
Training loss: 2.909077571166413
Validation loss: 2.55374431456143

Epoch: 5| Step: 7
Training loss: 2.4284823946299943
Validation loss: 2.5400251372626577

Epoch: 5| Step: 8
Training loss: 2.6698341829623353
Validation loss: 2.5413205126082494

Epoch: 5| Step: 9
Training loss: 2.7278761008420838
Validation loss: 2.55727133155856

Epoch: 5| Step: 10
Training loss: 2.5403757308540706
Validation loss: 2.565466873279989

Epoch: 301| Step: 0
Training loss: 2.6342300538068795
Validation loss: 2.5658689063636264

Epoch: 5| Step: 1
Training loss: 2.7280744934650394
Validation loss: 2.5802672176068824

Epoch: 5| Step: 2
Training loss: 3.2128446164069007
Validation loss: 2.5657230959528645

Epoch: 5| Step: 3
Training loss: 2.692832447096322
Validation loss: 2.5749590455002305

Epoch: 5| Step: 4
Training loss: 2.772399708178231
Validation loss: 2.5807670501987725

Epoch: 5| Step: 5
Training loss: 3.049383138593762
Validation loss: 2.5626957406178295

Epoch: 5| Step: 6
Training loss: 3.1488309477138134
Validation loss: 2.5545356311220995

Epoch: 5| Step: 7
Training loss: 2.2766288040758536
Validation loss: 2.557089617654656

Epoch: 5| Step: 8
Training loss: 2.848696587979529
Validation loss: 2.551318359912584

Epoch: 5| Step: 9
Training loss: 2.7550942313803715
Validation loss: 2.55165570920408

Epoch: 5| Step: 10
Training loss: 3.2020596849357936
Validation loss: 2.558032508683423

Epoch: 302| Step: 0
Training loss: 2.2847859400476884
Validation loss: 2.5571869405019836

Epoch: 5| Step: 1
Training loss: 3.1090464969567853
Validation loss: 2.561319111613706

Epoch: 5| Step: 2
Training loss: 2.57361240221094
Validation loss: 2.5658126406513353

Epoch: 5| Step: 3
Training loss: 2.8991810135478615
Validation loss: 2.575361324884416

Epoch: 5| Step: 4
Training loss: 3.07931046483507
Validation loss: 2.5750186979421588

Epoch: 5| Step: 5
Training loss: 2.6952367799599406
Validation loss: 2.5792515137811756

Epoch: 5| Step: 6
Training loss: 2.649444388677571
Validation loss: 2.5801805134634765

Epoch: 5| Step: 7
Training loss: 2.893109712558258
Validation loss: 2.5579970238124288

Epoch: 5| Step: 8
Training loss: 2.9873504984330648
Validation loss: 2.564078250399781

Epoch: 5| Step: 9
Training loss: 3.2013765354612316
Validation loss: 2.582587888449677

Epoch: 5| Step: 10
Training loss: 2.8861222121810814
Validation loss: 2.574246549144227

Epoch: 303| Step: 0
Training loss: 1.870960206938476
Validation loss: 2.571008213009434

Epoch: 5| Step: 1
Training loss: 2.907755800050033
Validation loss: 2.5706213311663193

Epoch: 5| Step: 2
Training loss: 2.651234637858458
Validation loss: 2.591677155077957

Epoch: 5| Step: 3
Training loss: 3.0867918739163445
Validation loss: 2.5713184356990197

Epoch: 5| Step: 4
Training loss: 2.4929213444940426
Validation loss: 2.559908995859853

Epoch: 5| Step: 5
Training loss: 2.775654768806698
Validation loss: 2.5480607010217398

Epoch: 5| Step: 6
Training loss: 3.648231124759045
Validation loss: 2.547621471076333

Epoch: 5| Step: 7
Training loss: 2.94485445786632
Validation loss: 2.556981517140089

Epoch: 5| Step: 8
Training loss: 3.2083811735739642
Validation loss: 2.546337418976667

Epoch: 5| Step: 9
Training loss: 2.8709683553080443
Validation loss: 2.5491099076314288

Epoch: 5| Step: 10
Training loss: 2.6416708776719218
Validation loss: 2.5573082409934718

Epoch: 304| Step: 0
Training loss: 2.6194381829307516
Validation loss: 2.556174863931636

Epoch: 5| Step: 1
Training loss: 2.6744907357851853
Validation loss: 2.5584937040934843

Epoch: 5| Step: 2
Training loss: 2.8453431749444786
Validation loss: 2.5607189869244853

Epoch: 5| Step: 3
Training loss: 3.5276804749560626
Validation loss: 2.5729926459579175

Epoch: 5| Step: 4
Training loss: 3.053107826395453
Validation loss: 2.5847410199928524

Epoch: 5| Step: 5
Training loss: 3.239096618266553
Validation loss: 2.583945888123255

Epoch: 5| Step: 6
Training loss: 2.4602628237189785
Validation loss: 2.5899229324489124

Epoch: 5| Step: 7
Training loss: 2.761629828892463
Validation loss: 2.6038224679863924

Epoch: 5| Step: 8
Training loss: 2.5310915673677044
Validation loss: 2.6041881817985137

Epoch: 5| Step: 9
Training loss: 2.9492869792397425
Validation loss: 2.5985227977753063

Epoch: 5| Step: 10
Training loss: 2.6730349515776926
Validation loss: 2.5929717848395613

Epoch: 305| Step: 0
Training loss: 2.8608538029426676
Validation loss: 2.591639694481322

Epoch: 5| Step: 1
Training loss: 2.736389987199986
Validation loss: 2.5743205708439953

Epoch: 5| Step: 2
Training loss: 3.1516661642535806
Validation loss: 2.5783980050072426

Epoch: 5| Step: 3
Training loss: 2.833740896943173
Validation loss: 2.577982794505588

Epoch: 5| Step: 4
Training loss: 2.3561340708254677
Validation loss: 2.5975014216613688

Epoch: 5| Step: 5
Training loss: 2.808238976664011
Validation loss: 2.585608458669539

Epoch: 5| Step: 6
Training loss: 2.8774305932815882
Validation loss: 2.5992525505345485

Epoch: 5| Step: 7
Training loss: 3.001871478944199
Validation loss: 2.617285774453926

Epoch: 5| Step: 8
Training loss: 2.9833308285608555
Validation loss: 2.6127740057547943

Epoch: 5| Step: 9
Training loss: 2.518889400136423
Validation loss: 2.590766393580506

Epoch: 5| Step: 10
Training loss: 3.238681450975621
Validation loss: 2.555438768615738

Epoch: 306| Step: 0
Training loss: 2.790772328006636
Validation loss: 2.5612280305165736

Epoch: 5| Step: 1
Training loss: 2.4702714505244403
Validation loss: 2.5554392501562875

Epoch: 5| Step: 2
Training loss: 2.82448533357799
Validation loss: 2.5509804936765197

Epoch: 5| Step: 3
Training loss: 3.005758163602242
Validation loss: 2.552061526264161

Epoch: 5| Step: 4
Training loss: 3.0809698755165282
Validation loss: 2.548645378592435

Epoch: 5| Step: 5
Training loss: 3.0143739941789285
Validation loss: 2.54858610520508

Epoch: 5| Step: 6
Training loss: 2.9345584507351785
Validation loss: 2.552496457810907

Epoch: 5| Step: 7
Training loss: 2.7959125930155975
Validation loss: 2.562710531026545

Epoch: 5| Step: 8
Training loss: 2.42606370543814
Validation loss: 2.556835935855635

Epoch: 5| Step: 9
Training loss: 3.034887589159277
Validation loss: 2.5644995698596085

Epoch: 5| Step: 10
Training loss: 3.0140818071711033
Validation loss: 2.566860003341962

Epoch: 307| Step: 0
Training loss: 2.691811762187192
Validation loss: 2.5798575468085705

Epoch: 5| Step: 1
Training loss: 2.553448111026889
Validation loss: 2.583984886937475

Epoch: 5| Step: 2
Training loss: 3.2063693851604556
Validation loss: 2.5923029478955177

Epoch: 5| Step: 3
Training loss: 2.776200500486697
Validation loss: 2.586478297953713

Epoch: 5| Step: 4
Training loss: 2.5415810638353897
Validation loss: 2.5967353515226996

Epoch: 5| Step: 5
Training loss: 2.5440678953191584
Validation loss: 2.589320317595899

Epoch: 5| Step: 6
Training loss: 2.8607357935320605
Validation loss: 2.6114036667002014

Epoch: 5| Step: 7
Training loss: 3.5578521391244
Validation loss: 2.5954724812000847

Epoch: 5| Step: 8
Training loss: 2.376561304176125
Validation loss: 2.573290202221786

Epoch: 5| Step: 9
Training loss: 3.125500143082572
Validation loss: 2.5790284424332444

Epoch: 5| Step: 10
Training loss: 2.943034538260806
Validation loss: 2.5774592380545585

Epoch: 308| Step: 0
Training loss: 2.8835822010868366
Validation loss: 2.569197884477074

Epoch: 5| Step: 1
Training loss: 2.8943240031027146
Validation loss: 2.595598704817382

Epoch: 5| Step: 2
Training loss: 2.995641243992264
Validation loss: 2.590477137862951

Epoch: 5| Step: 3
Training loss: 2.6014281458714796
Validation loss: 2.599627734346461

Epoch: 5| Step: 4
Training loss: 2.7134742850481697
Validation loss: 2.5881569875854784

Epoch: 5| Step: 5
Training loss: 2.7270169029761133
Validation loss: 2.600250690907102

Epoch: 5| Step: 6
Training loss: 2.7632406700375043
Validation loss: 2.593878581614211

Epoch: 5| Step: 7
Training loss: 3.5407440030871973
Validation loss: 2.5913345856025223

Epoch: 5| Step: 8
Training loss: 2.805979056755318
Validation loss: 2.5882194792101627

Epoch: 5| Step: 9
Training loss: 1.9236916740553394
Validation loss: 2.5750961475320815

Epoch: 5| Step: 10
Training loss: 3.1806742568726714
Validation loss: 2.5719431257163268

Epoch: 309| Step: 0
Training loss: 3.143611266334189
Validation loss: 2.5580368401551334

Epoch: 5| Step: 1
Training loss: 2.9523002643516993
Validation loss: 2.5762947802849574

Epoch: 5| Step: 2
Training loss: 2.965538456159511
Validation loss: 2.575704191407697

Epoch: 5| Step: 3
Training loss: 2.7354910180668326
Validation loss: 2.5790452166937854

Epoch: 5| Step: 4
Training loss: 2.69884208999137
Validation loss: 2.579026551780859

Epoch: 5| Step: 5
Training loss: 1.9409949252628766
Validation loss: 2.615895384837903

Epoch: 5| Step: 6
Training loss: 2.8702186963697094
Validation loss: 2.6194064347325723

Epoch: 5| Step: 7
Training loss: 3.202783631533276
Validation loss: 2.6532180792222895

Epoch: 5| Step: 8
Training loss: 2.6460784037674085
Validation loss: 2.623225031459832

Epoch: 5| Step: 9
Training loss: 3.3787975845062737
Validation loss: 2.6156270630064427

Epoch: 5| Step: 10
Training loss: 2.504851592763535
Validation loss: 2.624627766192974

Epoch: 310| Step: 0
Training loss: 2.634293770584209
Validation loss: 2.597925594064603

Epoch: 5| Step: 1
Training loss: 2.6376057355034495
Validation loss: 2.60028677436357

Epoch: 5| Step: 2
Training loss: 2.3076589276271577
Validation loss: 2.5927987358883384

Epoch: 5| Step: 3
Training loss: 3.0875817662581957
Validation loss: 2.582665775621114

Epoch: 5| Step: 4
Training loss: 2.3575292782467256
Validation loss: 2.5703430223839203

Epoch: 5| Step: 5
Training loss: 2.618953006860248
Validation loss: 2.582896327297569

Epoch: 5| Step: 6
Training loss: 2.8719783328522097
Validation loss: 2.571796500377437

Epoch: 5| Step: 7
Training loss: 2.8384638691078083
Validation loss: 2.589169160264568

Epoch: 5| Step: 8
Training loss: 3.30710421453991
Validation loss: 2.5812902763895433

Epoch: 5| Step: 9
Training loss: 3.2985573765354435
Validation loss: 2.5875375722858416

Epoch: 5| Step: 10
Training loss: 2.9678757835984504
Validation loss: 2.589512280539022

Epoch: 311| Step: 0
Training loss: 3.114033951463391
Validation loss: 2.564920158442915

Epoch: 5| Step: 1
Training loss: 2.617548038074644
Validation loss: 2.567836184618532

Epoch: 5| Step: 2
Training loss: 2.9507119952117526
Validation loss: 2.5618511301836095

Epoch: 5| Step: 3
Training loss: 2.853658997617378
Validation loss: 2.56702800286693

Epoch: 5| Step: 4
Training loss: 2.3839549843359222
Validation loss: 2.5481675662431313

Epoch: 5| Step: 5
Training loss: 2.7060901938249358
Validation loss: 2.542570538095837

Epoch: 5| Step: 6
Training loss: 2.7654065406854946
Validation loss: 2.544933102957829

Epoch: 5| Step: 7
Training loss: 3.5125776180501904
Validation loss: 2.5499069966200394

Epoch: 5| Step: 8
Training loss: 2.513117612777133
Validation loss: 2.5397805353937204

Epoch: 5| Step: 9
Training loss: 3.1481839591422522
Validation loss: 2.544826708361857

Epoch: 5| Step: 10
Training loss: 2.3723427815093956
Validation loss: 2.546019260835363

Epoch: 312| Step: 0
Training loss: 2.5420280157986985
Validation loss: 2.57301714746079

Epoch: 5| Step: 1
Training loss: 2.4862039419657718
Validation loss: 2.5937995891078263

Epoch: 5| Step: 2
Training loss: 3.1915764267185347
Validation loss: 2.6534204293209323

Epoch: 5| Step: 3
Training loss: 2.5692744144394375
Validation loss: 2.633492578006459

Epoch: 5| Step: 4
Training loss: 2.340122722113783
Validation loss: 2.6116728003605423

Epoch: 5| Step: 5
Training loss: 3.338506419709406
Validation loss: 2.581942419696917

Epoch: 5| Step: 6
Training loss: 3.1830907506203103
Validation loss: 2.566237618370962

Epoch: 5| Step: 7
Training loss: 3.1041445806003476
Validation loss: 2.5755651071147034

Epoch: 5| Step: 8
Training loss: 3.1577691680638114
Validation loss: 2.5696911437772254

Epoch: 5| Step: 9
Training loss: 2.1033157919602155
Validation loss: 2.565244470064321

Epoch: 5| Step: 10
Training loss: 2.8963011402658014
Validation loss: 2.578401181221679

Epoch: 313| Step: 0
Training loss: 2.687895013921764
Validation loss: 2.5832029032520922

Epoch: 5| Step: 1
Training loss: 3.3224108718617034
Validation loss: 2.6042025052137445

Epoch: 5| Step: 2
Training loss: 2.2268397108478277
Validation loss: 2.6094709814313726

Epoch: 5| Step: 3
Training loss: 2.6112161867719914
Validation loss: 2.648918360603395

Epoch: 5| Step: 4
Training loss: 3.2368045840620767
Validation loss: 2.622473444742674

Epoch: 5| Step: 5
Training loss: 2.670573581278232
Validation loss: 2.575072074986142

Epoch: 5| Step: 6
Training loss: 3.0679198593156887
Validation loss: 2.57971324456508

Epoch: 5| Step: 7
Training loss: 2.8330655438899686
Validation loss: 2.5594524777042102

Epoch: 5| Step: 8
Training loss: 2.7173417927751022
Validation loss: 2.5533044267402536

Epoch: 5| Step: 9
Training loss: 3.206228399668727
Validation loss: 2.5543120312354812

Epoch: 5| Step: 10
Training loss: 2.4009136129946427
Validation loss: 2.5480280171849192

Epoch: 314| Step: 0
Training loss: 2.610273012519981
Validation loss: 2.5464483070140074

Epoch: 5| Step: 1
Training loss: 3.138478014976094
Validation loss: 2.549932416671368

Epoch: 5| Step: 2
Training loss: 2.8401476501982708
Validation loss: 2.559562587222845

Epoch: 5| Step: 3
Training loss: 3.086984654711269
Validation loss: 2.5629764477114794

Epoch: 5| Step: 4
Training loss: 2.6438546378708883
Validation loss: 2.5921692848066256

Epoch: 5| Step: 5
Training loss: 2.437418031536943
Validation loss: 2.609864094094225

Epoch: 5| Step: 6
Training loss: 3.052106698807124
Validation loss: 2.6175066128168196

Epoch: 5| Step: 7
Training loss: 3.0713420044622226
Validation loss: 2.640608631483047

Epoch: 5| Step: 8
Training loss: 2.638727352708338
Validation loss: 2.624231190758162

Epoch: 5| Step: 9
Training loss: 2.9344396679529736
Validation loss: 2.6426357082963436

Epoch: 5| Step: 10
Training loss: 2.898578486136853
Validation loss: 2.595563943907493

Epoch: 315| Step: 0
Training loss: 2.924706214431607
Validation loss: 2.5693547456474284

Epoch: 5| Step: 1
Training loss: 2.6378710228174573
Validation loss: 2.546684792026268

Epoch: 5| Step: 2
Training loss: 2.941875364628954
Validation loss: 2.54711885918624

Epoch: 5| Step: 3
Training loss: 3.0499987117577003
Validation loss: 2.547750921190022

Epoch: 5| Step: 4
Training loss: 2.9699845808765626
Validation loss: 2.5470952992423

Epoch: 5| Step: 5
Training loss: 3.06930253596008
Validation loss: 2.5459402374442694

Epoch: 5| Step: 6
Training loss: 2.8529004446283173
Validation loss: 2.552136181369352

Epoch: 5| Step: 7
Training loss: 2.076477889496449
Validation loss: 2.5547885649623097

Epoch: 5| Step: 8
Training loss: 3.2331375482279934
Validation loss: 2.5662805275446217

Epoch: 5| Step: 9
Training loss: 2.653649796522561
Validation loss: 2.561617637565015

Epoch: 5| Step: 10
Training loss: 2.920245527108745
Validation loss: 2.5750089178300266

Epoch: 316| Step: 0
Training loss: 2.9235644020906033
Validation loss: 2.5817703205331646

Epoch: 5| Step: 1
Training loss: 3.0541109677622655
Validation loss: 2.581632345558747

Epoch: 5| Step: 2
Training loss: 2.4061669669749493
Validation loss: 2.6037124401724383

Epoch: 5| Step: 3
Training loss: 3.0599793940828937
Validation loss: 2.606217724398194

Epoch: 5| Step: 4
Training loss: 2.8422367974567817
Validation loss: 2.6316740585252743

Epoch: 5| Step: 5
Training loss: 2.8795259758475966
Validation loss: 2.6303228544444317

Epoch: 5| Step: 6
Training loss: 2.8713421980088696
Validation loss: 2.6163418427991143

Epoch: 5| Step: 7
Training loss: 3.425774151262956
Validation loss: 2.592851944160808

Epoch: 5| Step: 8
Training loss: 2.626484224241217
Validation loss: 2.57309895295212

Epoch: 5| Step: 9
Training loss: 2.743965637492345
Validation loss: 2.563198063548817

Epoch: 5| Step: 10
Training loss: 2.4501440317284615
Validation loss: 2.5625049672052365

Epoch: 317| Step: 0
Training loss: 3.113528444056396
Validation loss: 2.552361093808196

Epoch: 5| Step: 1
Training loss: 3.4501960035291552
Validation loss: 2.554369343142066

Epoch: 5| Step: 2
Training loss: 2.9091223192144837
Validation loss: 2.5514482790840214

Epoch: 5| Step: 3
Training loss: 3.13365531105776
Validation loss: 2.5391396979498686

Epoch: 5| Step: 4
Training loss: 2.846860421203066
Validation loss: 2.546682109281268

Epoch: 5| Step: 5
Training loss: 2.2114153773525693
Validation loss: 2.54706400810321

Epoch: 5| Step: 6
Training loss: 2.5365239525883534
Validation loss: 2.559993808910936

Epoch: 5| Step: 7
Training loss: 2.8458830829551984
Validation loss: 2.5668263763495154

Epoch: 5| Step: 8
Training loss: 2.565766462359284
Validation loss: 2.568871337541458

Epoch: 5| Step: 9
Training loss: 2.487743373447625
Validation loss: 2.5614477128439637

Epoch: 5| Step: 10
Training loss: 2.770158489526978
Validation loss: 2.578695391877448

Epoch: 318| Step: 0
Training loss: 2.7785705346460827
Validation loss: 2.5848482848908465

Epoch: 5| Step: 1
Training loss: 2.8505098254976757
Validation loss: 2.580157141148444

Epoch: 5| Step: 2
Training loss: 3.1181724732211182
Validation loss: 2.622994181504187

Epoch: 5| Step: 3
Training loss: 2.738603298170393
Validation loss: 2.605781166604438

Epoch: 5| Step: 4
Training loss: 2.8296164273584083
Validation loss: 2.6119891183377075

Epoch: 5| Step: 5
Training loss: 2.1780668406883437
Validation loss: 2.6347704248302453

Epoch: 5| Step: 6
Training loss: 2.7797935186863723
Validation loss: 2.646978900762372

Epoch: 5| Step: 7
Training loss: 2.897431479195969
Validation loss: 2.609260696580917

Epoch: 5| Step: 8
Training loss: 3.104521216982473
Validation loss: 2.581505237456301

Epoch: 5| Step: 9
Training loss: 2.7820120635384713
Validation loss: 2.557790490830265

Epoch: 5| Step: 10
Training loss: 3.092399687809226
Validation loss: 2.542231234971263

Epoch: 319| Step: 0
Training loss: 3.0382177752855433
Validation loss: 2.552585179951914

Epoch: 5| Step: 1
Training loss: 2.8700128505831133
Validation loss: 2.538465786745164

Epoch: 5| Step: 2
Training loss: 2.770424595182398
Validation loss: 2.536178275918632

Epoch: 5| Step: 3
Training loss: 2.84821396796519
Validation loss: 2.5358261668577087

Epoch: 5| Step: 4
Training loss: 3.1471445917078107
Validation loss: 2.5381573099562655

Epoch: 5| Step: 5
Training loss: 2.4064060507371092
Validation loss: 2.5392881029741887

Epoch: 5| Step: 6
Training loss: 2.7895887717169545
Validation loss: 2.540170979570408

Epoch: 5| Step: 7
Training loss: 3.2536808590718342
Validation loss: 2.5538343947116853

Epoch: 5| Step: 8
Training loss: 2.7380418006152687
Validation loss: 2.542012889230439

Epoch: 5| Step: 9
Training loss: 2.6540530824735593
Validation loss: 2.5522744260210937

Epoch: 5| Step: 10
Training loss: 2.763377596550892
Validation loss: 2.561131732082879

Epoch: 320| Step: 0
Training loss: 3.2420601325697587
Validation loss: 2.5694603361218302

Epoch: 5| Step: 1
Training loss: 3.1935802138374974
Validation loss: 2.563941371110986

Epoch: 5| Step: 2
Training loss: 2.8516974430292548
Validation loss: 2.566458507093281

Epoch: 5| Step: 3
Training loss: 2.3330413317757417
Validation loss: 2.568602050835227

Epoch: 5| Step: 4
Training loss: 2.7584772362488024
Validation loss: 2.5922160292005305

Epoch: 5| Step: 5
Training loss: 2.32823365233171
Validation loss: 2.5891455769963603

Epoch: 5| Step: 6
Training loss: 2.9192700529253437
Validation loss: 2.621226373379859

Epoch: 5| Step: 7
Training loss: 3.002989392191024
Validation loss: 2.6229873340281755

Epoch: 5| Step: 8
Training loss: 2.690507758196903
Validation loss: 2.59870790049369

Epoch: 5| Step: 9
Training loss: 2.6885163802729286
Validation loss: 2.5940218823874326

Epoch: 5| Step: 10
Training loss: 2.902087276006039
Validation loss: 2.6024478272006957

Epoch: 321| Step: 0
Training loss: 2.5381401382066233
Validation loss: 2.6006702875219054

Epoch: 5| Step: 1
Training loss: 2.582345640401425
Validation loss: 2.621523066741492

Epoch: 5| Step: 2
Training loss: 2.3536039597011844
Validation loss: 2.6334447847906564

Epoch: 5| Step: 3
Training loss: 3.314957480869941
Validation loss: 2.6600113067090576

Epoch: 5| Step: 4
Training loss: 3.0063771179351635
Validation loss: 2.6059752086428216

Epoch: 5| Step: 5
Training loss: 2.715040987383319
Validation loss: 2.625139854834728

Epoch: 5| Step: 6
Training loss: 3.110130180013901
Validation loss: 2.6276931249238618

Epoch: 5| Step: 7
Training loss: 2.5356136432531597
Validation loss: 2.617293647691398

Epoch: 5| Step: 8
Training loss: 2.3575094565467856
Validation loss: 2.581652171344105

Epoch: 5| Step: 9
Training loss: 3.008291865210067
Validation loss: 2.569034606218636

Epoch: 5| Step: 10
Training loss: 3.5500840781557694
Validation loss: 2.5545452362174816

Epoch: 322| Step: 0
Training loss: 2.355080441277473
Validation loss: 2.5412118643691577

Epoch: 5| Step: 1
Training loss: 2.3896064333698526
Validation loss: 2.5457859706834958

Epoch: 5| Step: 2
Training loss: 2.3891779690188972
Validation loss: 2.5539484203379157

Epoch: 5| Step: 3
Training loss: 2.840704156593158
Validation loss: 2.5421740790149747

Epoch: 5| Step: 4
Training loss: 3.017161239912749
Validation loss: 2.553932838380713

Epoch: 5| Step: 5
Training loss: 3.1219707302502937
Validation loss: 2.5507811203496624

Epoch: 5| Step: 6
Training loss: 2.962806775912672
Validation loss: 2.5388282706965377

Epoch: 5| Step: 7
Training loss: 2.86739670824361
Validation loss: 2.5468132574742106

Epoch: 5| Step: 8
Training loss: 2.918783745580819
Validation loss: 2.5580026752472973

Epoch: 5| Step: 9
Training loss: 2.9846766454231477
Validation loss: 2.5787818288268154

Epoch: 5| Step: 10
Training loss: 3.236297331014857
Validation loss: 2.5902177302490776

Epoch: 323| Step: 0
Training loss: 2.726726712853592
Validation loss: 2.5989137248225367

Epoch: 5| Step: 1
Training loss: 3.2296661154782336
Validation loss: 2.606991793257077

Epoch: 5| Step: 2
Training loss: 2.8523618648960003
Validation loss: 2.602790359228111

Epoch: 5| Step: 3
Training loss: 2.333253881827477
Validation loss: 2.5730778367713714

Epoch: 5| Step: 4
Training loss: 3.0886746785865293
Validation loss: 2.569125406564194

Epoch: 5| Step: 5
Training loss: 2.9645072736028393
Validation loss: 2.5582897655415113

Epoch: 5| Step: 6
Training loss: 2.556300409468196
Validation loss: 2.5468057471666024

Epoch: 5| Step: 7
Training loss: 2.7974278420422403
Validation loss: 2.542644487808552

Epoch: 5| Step: 8
Training loss: 2.6909875640978713
Validation loss: 2.5605079887778093

Epoch: 5| Step: 9
Training loss: 2.854304252334109
Validation loss: 2.566500500591439

Epoch: 5| Step: 10
Training loss: 2.9668683965724814
Validation loss: 2.585790605384529

Epoch: 324| Step: 0
Training loss: 2.7900212881171664
Validation loss: 2.591680831865193

Epoch: 5| Step: 1
Training loss: 2.6601007710635955
Validation loss: 2.580721550754288

Epoch: 5| Step: 2
Training loss: 2.4850308494264852
Validation loss: 2.5781529718089176

Epoch: 5| Step: 3
Training loss: 3.0892808789720188
Validation loss: 2.602690147615403

Epoch: 5| Step: 4
Training loss: 3.048136445102789
Validation loss: 2.640505205546138

Epoch: 5| Step: 5
Training loss: 2.9333084719500215
Validation loss: 2.632554106911466

Epoch: 5| Step: 6
Training loss: 2.8902724592347413
Validation loss: 2.618266311825539

Epoch: 5| Step: 7
Training loss: 2.9122344718687443
Validation loss: 2.602827568726491

Epoch: 5| Step: 8
Training loss: 3.017334132530566
Validation loss: 2.59961952950872

Epoch: 5| Step: 9
Training loss: 2.221052667356602
Validation loss: 2.5688523013111895

Epoch: 5| Step: 10
Training loss: 2.825154045428605
Validation loss: 2.5713327717242374

Epoch: 325| Step: 0
Training loss: 2.560544826527117
Validation loss: 2.571423530298996

Epoch: 5| Step: 1
Training loss: 3.1884406702612296
Validation loss: 2.564971829133157

Epoch: 5| Step: 2
Training loss: 2.3385976488737583
Validation loss: 2.5879239535222

Epoch: 5| Step: 3
Training loss: 3.3533971784465937
Validation loss: 2.567393946223793

Epoch: 5| Step: 4
Training loss: 2.3754254010337736
Validation loss: 2.580224859968917

Epoch: 5| Step: 5
Training loss: 3.136497404238823
Validation loss: 2.596547870904375

Epoch: 5| Step: 6
Training loss: 3.004113397289119
Validation loss: 2.5979875635638554

Epoch: 5| Step: 7
Training loss: 2.6830515751098987
Validation loss: 2.585722596581556

Epoch: 5| Step: 8
Training loss: 3.182106840985816
Validation loss: 2.6007146986554237

Epoch: 5| Step: 9
Training loss: 2.6698606158960785
Validation loss: 2.561323130249662

Epoch: 5| Step: 10
Training loss: 2.119307241613799
Validation loss: 2.584724084328149

Epoch: 326| Step: 0
Training loss: 2.46549570496432
Validation loss: 2.543864277664286

Epoch: 5| Step: 1
Training loss: 2.852282456737533
Validation loss: 2.5526830400966727

Epoch: 5| Step: 2
Training loss: 2.841723883566475
Validation loss: 2.550392948849613

Epoch: 5| Step: 3
Training loss: 2.960450950243288
Validation loss: 2.572046249669661

Epoch: 5| Step: 4
Training loss: 2.558163858654928
Validation loss: 2.565219403623546

Epoch: 5| Step: 5
Training loss: 3.039070345125639
Validation loss: 2.557976922482451

Epoch: 5| Step: 6
Training loss: 2.7024698510901146
Validation loss: 2.589680510285126

Epoch: 5| Step: 7
Training loss: 2.8637683240753
Validation loss: 2.586705920619094

Epoch: 5| Step: 8
Training loss: 2.7483952781986454
Validation loss: 2.5849891526954303

Epoch: 5| Step: 9
Training loss: 3.030150853295193
Validation loss: 2.6044276185908877

Epoch: 5| Step: 10
Training loss: 2.81306053509824
Validation loss: 2.566105087200112

Epoch: 327| Step: 0
Training loss: 3.102871481689947
Validation loss: 2.549593610630336

Epoch: 5| Step: 1
Training loss: 2.6946656266326383
Validation loss: 2.556178638922292

Epoch: 5| Step: 2
Training loss: 2.838948986448374
Validation loss: 2.5625565805498933

Epoch: 5| Step: 3
Training loss: 2.5644305330604733
Validation loss: 2.578536274343335

Epoch: 5| Step: 4
Training loss: 2.6931371783912716
Validation loss: 2.5525178115469305

Epoch: 5| Step: 5
Training loss: 2.357466576380764
Validation loss: 2.548846929582406

Epoch: 5| Step: 6
Training loss: 2.5563568354061954
Validation loss: 2.5574093066414507

Epoch: 5| Step: 7
Training loss: 3.1850079537236957
Validation loss: 2.5360937723020403

Epoch: 5| Step: 8
Training loss: 2.925599035234634
Validation loss: 2.5525947773216906

Epoch: 5| Step: 9
Training loss: 3.2105405241888003
Validation loss: 2.5762084579193316

Epoch: 5| Step: 10
Training loss: 2.5140396714581748
Validation loss: 2.5871924887514046

Epoch: 328| Step: 0
Training loss: 2.665168599705459
Validation loss: 2.605663592563203

Epoch: 5| Step: 1
Training loss: 2.4884239167855076
Validation loss: 2.5917136002467793

Epoch: 5| Step: 2
Training loss: 2.8988023718494573
Validation loss: 2.5819183017609793

Epoch: 5| Step: 3
Training loss: 2.531885420552517
Validation loss: 2.557209945310948

Epoch: 5| Step: 4
Training loss: 3.0033545812207305
Validation loss: 2.565882109853387

Epoch: 5| Step: 5
Training loss: 2.770564350657908
Validation loss: 2.5636081435444322

Epoch: 5| Step: 6
Training loss: 3.132751007618132
Validation loss: 2.562933162131629

Epoch: 5| Step: 7
Training loss: 2.558908597487732
Validation loss: 2.555515148841511

Epoch: 5| Step: 8
Training loss: 2.542204805114781
Validation loss: 2.561354466385697

Epoch: 5| Step: 9
Training loss: 2.9676383095368055
Validation loss: 2.5486609989112776

Epoch: 5| Step: 10
Training loss: 3.262495814061311
Validation loss: 2.554659249182542

Epoch: 329| Step: 0
Training loss: 2.892631205729206
Validation loss: 2.550434147413337

Epoch: 5| Step: 1
Training loss: 2.4276170157486927
Validation loss: 2.5504616841196452

Epoch: 5| Step: 2
Training loss: 2.4465408896080043
Validation loss: 2.5476863738059587

Epoch: 5| Step: 3
Training loss: 2.49616080180627
Validation loss: 2.5524374506268623

Epoch: 5| Step: 4
Training loss: 2.8609831409990965
Validation loss: 2.5569833709547467

Epoch: 5| Step: 5
Training loss: 2.4992501087850747
Validation loss: 2.5634598793779966

Epoch: 5| Step: 6
Training loss: 2.755895883384594
Validation loss: 2.596751341059668

Epoch: 5| Step: 7
Training loss: 3.2993564035910823
Validation loss: 2.575524977458975

Epoch: 5| Step: 8
Training loss: 2.8022868048287517
Validation loss: 2.5672164159908877

Epoch: 5| Step: 9
Training loss: 3.2099437057455034
Validation loss: 2.5817400563781283

Epoch: 5| Step: 10
Training loss: 2.9946818898301797
Validation loss: 2.56561261131942

Epoch: 330| Step: 0
Training loss: 2.417521150293308
Validation loss: 2.571542227700552

Epoch: 5| Step: 1
Training loss: 3.041307262629453
Validation loss: 2.568673248058554

Epoch: 5| Step: 2
Training loss: 2.4529419848940788
Validation loss: 2.5847099792895594

Epoch: 5| Step: 3
Training loss: 3.2582180584925577
Validation loss: 2.5735169417452384

Epoch: 5| Step: 4
Training loss: 2.6481495928618375
Validation loss: 2.5633854160463385

Epoch: 5| Step: 5
Training loss: 2.851428553949548
Validation loss: 2.56099962639409

Epoch: 5| Step: 6
Training loss: 2.659799156924406
Validation loss: 2.568829187196042

Epoch: 5| Step: 7
Training loss: 3.004727136089651
Validation loss: 2.58739209422961

Epoch: 5| Step: 8
Training loss: 2.1817456444689936
Validation loss: 2.5986505818966723

Epoch: 5| Step: 9
Training loss: 2.8534213761385976
Validation loss: 2.613885799625813

Epoch: 5| Step: 10
Training loss: 3.3206321652186306
Validation loss: 2.652791705405738

Epoch: 331| Step: 0
Training loss: 2.6308690717330117
Validation loss: 2.611596228854593

Epoch: 5| Step: 1
Training loss: 2.7558806571976784
Validation loss: 2.6034750950838816

Epoch: 5| Step: 2
Training loss: 3.2393568804096327
Validation loss: 2.5714231998023216

Epoch: 5| Step: 3
Training loss: 2.5255191118283395
Validation loss: 2.558582963743052

Epoch: 5| Step: 4
Training loss: 2.7140108216701755
Validation loss: 2.5409261396996747

Epoch: 5| Step: 5
Training loss: 2.307125547699275
Validation loss: 2.533538515069667

Epoch: 5| Step: 6
Training loss: 3.016189601402552
Validation loss: 2.537052243102185

Epoch: 5| Step: 7
Training loss: 2.823976118500099
Validation loss: 2.5266711894398632

Epoch: 5| Step: 8
Training loss: 3.02134328462197
Validation loss: 2.545419997715424

Epoch: 5| Step: 9
Training loss: 2.9877491994695045
Validation loss: 2.561525376100272

Epoch: 5| Step: 10
Training loss: 2.688357726441893
Validation loss: 2.594087277566779

Epoch: 332| Step: 0
Training loss: 2.7208653255838664
Validation loss: 2.6354229111609424

Epoch: 5| Step: 1
Training loss: 3.0488107645345743
Validation loss: 2.659763845174819

Epoch: 5| Step: 2
Training loss: 2.6372904292005614
Validation loss: 2.7127492194464247

Epoch: 5| Step: 3
Training loss: 2.899423272236131
Validation loss: 2.7771843587751164

Epoch: 5| Step: 4
Training loss: 3.3238684428194354
Validation loss: 2.791565425055116

Epoch: 5| Step: 5
Training loss: 2.0715905041656915
Validation loss: 2.7223398546158273

Epoch: 5| Step: 6
Training loss: 2.5515047831878293
Validation loss: 2.6465109936822833

Epoch: 5| Step: 7
Training loss: 2.9406299554537814
Validation loss: 2.555236386144218

Epoch: 5| Step: 8
Training loss: 2.96256197450092
Validation loss: 2.537278836162217

Epoch: 5| Step: 9
Training loss: 2.695685584742692
Validation loss: 2.5269249198491885

Epoch: 5| Step: 10
Training loss: 3.1454767357689475
Validation loss: 2.5336393693105292

Epoch: 333| Step: 0
Training loss: 3.0551267342260315
Validation loss: 2.528661425458495

Epoch: 5| Step: 1
Training loss: 2.380507958805695
Validation loss: 2.5318247726032284

Epoch: 5| Step: 2
Training loss: 2.8841189187091194
Validation loss: 2.5334546104939366

Epoch: 5| Step: 3
Training loss: 2.984201635947494
Validation loss: 2.550286228145995

Epoch: 5| Step: 4
Training loss: 2.869783063392182
Validation loss: 2.5635182108271883

Epoch: 5| Step: 5
Training loss: 2.8127527759129065
Validation loss: 2.5562025855118624

Epoch: 5| Step: 6
Training loss: 2.8061251980019657
Validation loss: 2.532605153686673

Epoch: 5| Step: 7
Training loss: 2.709511417531696
Validation loss: 2.548135724864062

Epoch: 5| Step: 8
Training loss: 3.378754822970669
Validation loss: 2.5486536590129303

Epoch: 5| Step: 9
Training loss: 2.3640037756242633
Validation loss: 2.55291340136443

Epoch: 5| Step: 10
Training loss: 2.74977414330757
Validation loss: 2.546584727247899

Epoch: 334| Step: 0
Training loss: 3.3376991926893154
Validation loss: 2.556675175106111

Epoch: 5| Step: 1
Training loss: 3.0978665178280798
Validation loss: 2.5717937451413553

Epoch: 5| Step: 2
Training loss: 3.2594048795857478
Validation loss: 2.565725527976164

Epoch: 5| Step: 3
Training loss: 2.5229043781244798
Validation loss: 2.569967979463739

Epoch: 5| Step: 4
Training loss: 2.2931433226174907
Validation loss: 2.582918502641039

Epoch: 5| Step: 5
Training loss: 2.870249098491303
Validation loss: 2.5885475369740907

Epoch: 5| Step: 6
Training loss: 2.727898824957873
Validation loss: 2.583203121586051

Epoch: 5| Step: 7
Training loss: 1.94890351890361
Validation loss: 2.5483136920331244

Epoch: 5| Step: 8
Training loss: 3.105953154781125
Validation loss: 2.5412300756311055

Epoch: 5| Step: 9
Training loss: 2.8031177431350724
Validation loss: 2.5365082170993127

Epoch: 5| Step: 10
Training loss: 2.5981194334174695
Validation loss: 2.5246323015121277

Epoch: 335| Step: 0
Training loss: 2.691780407591844
Validation loss: 2.5378149953969804

Epoch: 5| Step: 1
Training loss: 2.143392069215973
Validation loss: 2.5300239075865383

Epoch: 5| Step: 2
Training loss: 3.085444234707262
Validation loss: 2.535048368063377

Epoch: 5| Step: 3
Training loss: 2.9930370907510198
Validation loss: 2.524927803842271

Epoch: 5| Step: 4
Training loss: 2.936623787568703
Validation loss: 2.5490511338274944

Epoch: 5| Step: 5
Training loss: 2.451772912491838
Validation loss: 2.5462083324611196

Epoch: 5| Step: 6
Training loss: 2.9011673320808145
Validation loss: 2.551079206252818

Epoch: 5| Step: 7
Training loss: 3.183221825715485
Validation loss: 2.557405304911498

Epoch: 5| Step: 8
Training loss: 2.539623585841743
Validation loss: 2.5521458617924146

Epoch: 5| Step: 9
Training loss: 2.8730246350473343
Validation loss: 2.563548530095774

Epoch: 5| Step: 10
Training loss: 2.952926063901226
Validation loss: 2.550400707933158

Epoch: 336| Step: 0
Training loss: 2.870096752383444
Validation loss: 2.5541928136532057

Epoch: 5| Step: 1
Training loss: 2.7644629326948653
Validation loss: 2.5473970449036343

Epoch: 5| Step: 2
Training loss: 2.6624695610491367
Validation loss: 2.5593345132745378

Epoch: 5| Step: 3
Training loss: 2.6416377546330763
Validation loss: 2.5647872063523254

Epoch: 5| Step: 4
Training loss: 2.6022395722085645
Validation loss: 2.539596116351127

Epoch: 5| Step: 5
Training loss: 3.078268289861635
Validation loss: 2.551672127908346

Epoch: 5| Step: 6
Training loss: 3.101262998173146
Validation loss: 2.5380905585591442

Epoch: 5| Step: 7
Training loss: 2.68803107758563
Validation loss: 2.5358323893618206

Epoch: 5| Step: 8
Training loss: 2.992739155963922
Validation loss: 2.5563831700928863

Epoch: 5| Step: 9
Training loss: 2.7888309158220186
Validation loss: 2.542199987830629

Epoch: 5| Step: 10
Training loss: 2.515014953568826
Validation loss: 2.5782902241723744

Epoch: 337| Step: 0
Training loss: 2.2703602732641928
Validation loss: 2.5871312268252624

Epoch: 5| Step: 1
Training loss: 2.40134574194877
Validation loss: 2.6222075392002218

Epoch: 5| Step: 2
Training loss: 3.0760184113505846
Validation loss: 2.625090555014926

Epoch: 5| Step: 3
Training loss: 3.508652618328859
Validation loss: 2.6110951000171605

Epoch: 5| Step: 4
Training loss: 2.817983749007075
Validation loss: 2.591303937498128

Epoch: 5| Step: 5
Training loss: 2.8342130267748287
Validation loss: 2.577234803980903

Epoch: 5| Step: 6
Training loss: 2.4099484049549025
Validation loss: 2.5548226183199865

Epoch: 5| Step: 7
Training loss: 2.871583650274263
Validation loss: 2.535527101676977

Epoch: 5| Step: 8
Training loss: 2.8013167248481237
Validation loss: 2.5339927079421454

Epoch: 5| Step: 9
Training loss: 2.943739412778699
Validation loss: 2.521819743836917

Epoch: 5| Step: 10
Training loss: 2.612874773513221
Validation loss: 2.5176232162863683

Epoch: 338| Step: 0
Training loss: 2.9875185722507998
Validation loss: 2.5437689071863274

Epoch: 5| Step: 1
Training loss: 2.92955501002502
Validation loss: 2.53656911994419

Epoch: 5| Step: 2
Training loss: 3.0395560758613525
Validation loss: 2.5377904298101193

Epoch: 5| Step: 3
Training loss: 3.073166004130013
Validation loss: 2.5464181908717514

Epoch: 5| Step: 4
Training loss: 2.7698138567631116
Validation loss: 2.6035580586340368

Epoch: 5| Step: 5
Training loss: 3.050385629007706
Validation loss: 2.5888542982989864

Epoch: 5| Step: 6
Training loss: 2.369842148686782
Validation loss: 2.6047300865462084

Epoch: 5| Step: 7
Training loss: 2.6735950309853345
Validation loss: 2.583836432725427

Epoch: 5| Step: 8
Training loss: 2.6337705957361504
Validation loss: 2.550495178083842

Epoch: 5| Step: 9
Training loss: 2.5763365119575234
Validation loss: 2.54162809913244

Epoch: 5| Step: 10
Training loss: 2.505132651557237
Validation loss: 2.535100318944843

Epoch: 339| Step: 0
Training loss: 2.899211934317305
Validation loss: 2.537443883018641

Epoch: 5| Step: 1
Training loss: 2.9337176056785297
Validation loss: 2.5473643223601217

Epoch: 5| Step: 2
Training loss: 2.6830021679528597
Validation loss: 2.5289258365402985

Epoch: 5| Step: 3
Training loss: 2.5738338941080148
Validation loss: 2.5517342692658027

Epoch: 5| Step: 4
Training loss: 2.6743814412766223
Validation loss: 2.537793618965656

Epoch: 5| Step: 5
Training loss: 2.6663742997909528
Validation loss: 2.5456610445826042

Epoch: 5| Step: 6
Training loss: 2.8148370993115037
Validation loss: 2.561602421512699

Epoch: 5| Step: 7
Training loss: 3.2926072977782836
Validation loss: 2.5692226167452006

Epoch: 5| Step: 8
Training loss: 2.7555999958221618
Validation loss: 2.5912140775686634

Epoch: 5| Step: 9
Training loss: 2.9279131996963392
Validation loss: 2.6045092347950827

Epoch: 5| Step: 10
Training loss: 2.22334254820066
Validation loss: 2.612584970729912

Epoch: 340| Step: 0
Training loss: 2.728452011382639
Validation loss: 2.658258413048

Epoch: 5| Step: 1
Training loss: 2.630172719179264
Validation loss: 2.6343470963871285

Epoch: 5| Step: 2
Training loss: 3.0372378012437076
Validation loss: 2.646789515268989

Epoch: 5| Step: 3
Training loss: 2.4212650638519384
Validation loss: 2.621996310071585

Epoch: 5| Step: 4
Training loss: 2.8186759110079302
Validation loss: 2.597953307290786

Epoch: 5| Step: 5
Training loss: 2.5783188255738647
Validation loss: 2.5859187688428875

Epoch: 5| Step: 6
Training loss: 2.707192068015759
Validation loss: 2.5754676595285804

Epoch: 5| Step: 7
Training loss: 3.11484709338374
Validation loss: 2.5633564820025727

Epoch: 5| Step: 8
Training loss: 2.7835983477609902
Validation loss: 2.538555422396666

Epoch: 5| Step: 9
Training loss: 2.7020346145728054
Validation loss: 2.550605170728252

Epoch: 5| Step: 10
Training loss: 2.9031223982849617
Validation loss: 2.5310198761431213

Epoch: 341| Step: 0
Training loss: 2.4009851102863786
Validation loss: 2.5326898718870003

Epoch: 5| Step: 1
Training loss: 2.5635982113993108
Validation loss: 2.536908895386385

Epoch: 5| Step: 2
Training loss: 2.662862020604445
Validation loss: 2.542440058386306

Epoch: 5| Step: 3
Training loss: 3.042830536314747
Validation loss: 2.5486047526410607

Epoch: 5| Step: 4
Training loss: 2.929759439220924
Validation loss: 2.540812534613111

Epoch: 5| Step: 5
Training loss: 2.8534432675524033
Validation loss: 2.5488399191183424

Epoch: 5| Step: 6
Training loss: 2.849410575013717
Validation loss: 2.566319835765884

Epoch: 5| Step: 7
Training loss: 2.71997446132339
Validation loss: 2.5606332257524365

Epoch: 5| Step: 8
Training loss: 2.7180553732782986
Validation loss: 2.5923990140456814

Epoch: 5| Step: 9
Training loss: 2.704934721633245
Validation loss: 2.606041729293785

Epoch: 5| Step: 10
Training loss: 3.0880048949049663
Validation loss: 2.637553707078121

Epoch: 342| Step: 0
Training loss: 2.57241243886264
Validation loss: 2.6877081519274215

Epoch: 5| Step: 1
Training loss: 2.486214202883989
Validation loss: 2.688025798716286

Epoch: 5| Step: 2
Training loss: 2.490367930701673
Validation loss: 2.686661803479492

Epoch: 5| Step: 3
Training loss: 2.5515196404767346
Validation loss: 2.657342763923302

Epoch: 5| Step: 4
Training loss: 2.4740091633175982
Validation loss: 2.5995477587561413

Epoch: 5| Step: 5
Training loss: 2.8513802248036595
Validation loss: 2.570987054728334

Epoch: 5| Step: 6
Training loss: 3.0180565710915017
Validation loss: 2.559610290662092

Epoch: 5| Step: 7
Training loss: 2.9176039869904113
Validation loss: 2.5369985769504892

Epoch: 5| Step: 8
Training loss: 2.9906663339722113
Validation loss: 2.529738687663964

Epoch: 5| Step: 9
Training loss: 3.1123613747975254
Validation loss: 2.5291785308737476

Epoch: 5| Step: 10
Training loss: 3.0890172342429083
Validation loss: 2.516860811483054

Epoch: 343| Step: 0
Training loss: 2.8579568316521007
Validation loss: 2.516347916925215

Epoch: 5| Step: 1
Training loss: 3.375204292048338
Validation loss: 2.5188971982494097

Epoch: 5| Step: 2
Training loss: 2.924862563335976
Validation loss: 2.5316186056949044

Epoch: 5| Step: 3
Training loss: 2.3398786997533283
Validation loss: 2.563502584033316

Epoch: 5| Step: 4
Training loss: 2.729776144526297
Validation loss: 2.5724909081695957

Epoch: 5| Step: 5
Training loss: 2.436417070104347
Validation loss: 2.635612344989896

Epoch: 5| Step: 6
Training loss: 2.7812682590528186
Validation loss: 2.6704843544961925

Epoch: 5| Step: 7
Training loss: 3.0850640328313967
Validation loss: 2.6482887963196085

Epoch: 5| Step: 8
Training loss: 2.587064837291689
Validation loss: 2.5888949432298145

Epoch: 5| Step: 9
Training loss: 2.7903016487224166
Validation loss: 2.5623533885762098

Epoch: 5| Step: 10
Training loss: 2.710633978218618
Validation loss: 2.5477181584135367

Epoch: 344| Step: 0
Training loss: 2.731179511865065
Validation loss: 2.540591298051984

Epoch: 5| Step: 1
Training loss: 3.2948621055911946
Validation loss: 2.5451770092005312

Epoch: 5| Step: 2
Training loss: 2.2900016862954673
Validation loss: 2.5464384096208432

Epoch: 5| Step: 3
Training loss: 3.2830931799984366
Validation loss: 2.5401813424194297

Epoch: 5| Step: 4
Training loss: 3.045984539100447
Validation loss: 2.5496042458822967

Epoch: 5| Step: 5
Training loss: 2.6731443903293126
Validation loss: 2.5435704249938778

Epoch: 5| Step: 6
Training loss: 2.742418589187791
Validation loss: 2.54205504250326

Epoch: 5| Step: 7
Training loss: 2.401602381000952
Validation loss: 2.5323245614765892

Epoch: 5| Step: 8
Training loss: 2.8032764508724197
Validation loss: 2.542696598060497

Epoch: 5| Step: 9
Training loss: 2.83414556043603
Validation loss: 2.5539672138205165

Epoch: 5| Step: 10
Training loss: 2.200447782549176
Validation loss: 2.5564521013050254

Epoch: 345| Step: 0
Training loss: 1.8187083105179203
Validation loss: 2.585906950517339

Epoch: 5| Step: 1
Training loss: 2.8105111613599156
Validation loss: 2.5837430883723416

Epoch: 5| Step: 2
Training loss: 3.1328307648314198
Validation loss: 2.6468603730937135

Epoch: 5| Step: 3
Training loss: 2.223929685695509
Validation loss: 2.641137489080491

Epoch: 5| Step: 4
Training loss: 3.139150092885662
Validation loss: 2.6360775418351747

Epoch: 5| Step: 5
Training loss: 3.206354662281906
Validation loss: 2.5715319229409266

Epoch: 5| Step: 6
Training loss: 2.9265246599137016
Validation loss: 2.5332026230402995

Epoch: 5| Step: 7
Training loss: 2.9906420987237325
Validation loss: 2.533964530420591

Epoch: 5| Step: 8
Training loss: 2.381952049112244
Validation loss: 2.5093697071996552

Epoch: 5| Step: 9
Training loss: 3.0345400230092725
Validation loss: 2.507253242097804

Epoch: 5| Step: 10
Training loss: 2.6796825175336334
Validation loss: 2.5070924913375925

Epoch: 346| Step: 0
Training loss: 3.076611761703283
Validation loss: 2.511059140960062

Epoch: 5| Step: 1
Training loss: 2.8749205536853433
Validation loss: 2.518016837071966

Epoch: 5| Step: 2
Training loss: 2.9527414870122874
Validation loss: 2.5194307666381404

Epoch: 5| Step: 3
Training loss: 2.4044211236998385
Validation loss: 2.5256906945337567

Epoch: 5| Step: 4
Training loss: 2.2616463288882893
Validation loss: 2.5158452741553834

Epoch: 5| Step: 5
Training loss: 3.2643690112338564
Validation loss: 2.5563615237223236

Epoch: 5| Step: 6
Training loss: 3.0195871523164506
Validation loss: 2.570393974667836

Epoch: 5| Step: 7
Training loss: 3.0708650281108127
Validation loss: 2.5702742751949295

Epoch: 5| Step: 8
Training loss: 2.829894465982545
Validation loss: 2.5877679851415167

Epoch: 5| Step: 9
Training loss: 2.1092461440677446
Validation loss: 2.63405567292469

Epoch: 5| Step: 10
Training loss: 2.195749911244332
Validation loss: 2.661271397531737

Epoch: 347| Step: 0
Training loss: 2.247449488936796
Validation loss: 2.6198624897935376

Epoch: 5| Step: 1
Training loss: 3.34661314836647
Validation loss: 2.6739180791161914

Epoch: 5| Step: 2
Training loss: 2.4896440591681612
Validation loss: 2.6529091041547974

Epoch: 5| Step: 3
Training loss: 2.91713129611598
Validation loss: 2.6362676005880465

Epoch: 5| Step: 4
Training loss: 3.12640379846551
Validation loss: 2.574219634350832

Epoch: 5| Step: 5
Training loss: 2.3648287159870653
Validation loss: 2.568899696522602

Epoch: 5| Step: 6
Training loss: 2.8866282282407223
Validation loss: 2.5425170983270875

Epoch: 5| Step: 7
Training loss: 2.9348566052112077
Validation loss: 2.5311848601549776

Epoch: 5| Step: 8
Training loss: 2.889460313557791
Validation loss: 2.5161065204016637

Epoch: 5| Step: 9
Training loss: 2.664871227309509
Validation loss: 2.5241832575358436

Epoch: 5| Step: 10
Training loss: 2.6148027629392447
Validation loss: 2.518022801205659

Epoch: 348| Step: 0
Training loss: 2.6429399805084617
Validation loss: 2.520023685431258

Epoch: 5| Step: 1
Training loss: 2.741175538185441
Validation loss: 2.5187939807070188

Epoch: 5| Step: 2
Training loss: 2.6963032104165214
Validation loss: 2.5373561894151795

Epoch: 5| Step: 3
Training loss: 3.190055421210275
Validation loss: 2.546653449536372

Epoch: 5| Step: 4
Training loss: 2.9106659513266724
Validation loss: 2.5441193335206216

Epoch: 5| Step: 5
Training loss: 2.1865264906186814
Validation loss: 2.5673030127426792

Epoch: 5| Step: 6
Training loss: 3.109923041271574
Validation loss: 2.5703646263115427

Epoch: 5| Step: 7
Training loss: 2.2797488146165055
Validation loss: 2.6007090966624675

Epoch: 5| Step: 8
Training loss: 2.3996787571490077
Validation loss: 2.606938256504445

Epoch: 5| Step: 9
Training loss: 3.064581650129038
Validation loss: 2.6324456851155356

Epoch: 5| Step: 10
Training loss: 2.946023141950055
Validation loss: 2.639997611282476

Epoch: 349| Step: 0
Training loss: 2.2857873811273857
Validation loss: 2.6460465343780615

Epoch: 5| Step: 1
Training loss: 2.825149066334249
Validation loss: 2.6282095802802887

Epoch: 5| Step: 2
Training loss: 2.284918878730523
Validation loss: 2.6088551531615383

Epoch: 5| Step: 3
Training loss: 3.482777866689343
Validation loss: 2.6041091732118455

Epoch: 5| Step: 4
Training loss: 2.402025055874537
Validation loss: 2.5607952727284573

Epoch: 5| Step: 5
Training loss: 2.654023797118976
Validation loss: 2.5636871543282798

Epoch: 5| Step: 6
Training loss: 2.9682411159246525
Validation loss: 2.552960764110418

Epoch: 5| Step: 7
Training loss: 2.9427051285357733
Validation loss: 2.5532304654727884

Epoch: 5| Step: 8
Training loss: 2.478452424670726
Validation loss: 2.547155299774223

Epoch: 5| Step: 9
Training loss: 2.627910090855027
Validation loss: 2.533448232385879

Epoch: 5| Step: 10
Training loss: 3.1129568354539408
Validation loss: 2.546033653725562

Epoch: 350| Step: 0
Training loss: 2.723883069216071
Validation loss: 2.555513024106259

Epoch: 5| Step: 1
Training loss: 3.0491518561111346
Validation loss: 2.549378831789916

Epoch: 5| Step: 2
Training loss: 2.836998102778438
Validation loss: 2.54705164614034

Epoch: 5| Step: 3
Training loss: 2.754555310535853
Validation loss: 2.5656417327535457

Epoch: 5| Step: 4
Training loss: 2.5536425958828546
Validation loss: 2.5597071380883287

Epoch: 5| Step: 5
Training loss: 2.639021889084457
Validation loss: 2.5864239976020995

Epoch: 5| Step: 6
Training loss: 2.902120301795525
Validation loss: 2.606134524831249

Epoch: 5| Step: 7
Training loss: 3.0871287690279554
Validation loss: 2.6502477284360206

Epoch: 5| Step: 8
Training loss: 2.3203206174560767
Validation loss: 2.5881363855222896

Epoch: 5| Step: 9
Training loss: 2.6189626566411945
Validation loss: 2.567010287712956

Epoch: 5| Step: 10
Training loss: 2.603796289172606
Validation loss: 2.549770615386659

Epoch: 351| Step: 0
Training loss: 2.918306017155436
Validation loss: 2.5521060439491627

Epoch: 5| Step: 1
Training loss: 2.83699894316865
Validation loss: 2.549408659551382

Epoch: 5| Step: 2
Training loss: 2.906553683257832
Validation loss: 2.5494171235249117

Epoch: 5| Step: 3
Training loss: 3.0316997076509087
Validation loss: 2.5642312627141806

Epoch: 5| Step: 4
Training loss: 2.5402781232116736
Validation loss: 2.5831317978471047

Epoch: 5| Step: 5
Training loss: 2.797975973455574
Validation loss: 2.578980496770401

Epoch: 5| Step: 6
Training loss: 2.7828362045692128
Validation loss: 2.5732395603381106

Epoch: 5| Step: 7
Training loss: 2.570404236614489
Validation loss: 2.559726560815829

Epoch: 5| Step: 8
Training loss: 2.7143339048854496
Validation loss: 2.5483857528420257

Epoch: 5| Step: 9
Training loss: 2.5410696693906814
Validation loss: 2.5497200151255854

Epoch: 5| Step: 10
Training loss: 2.4116351815967088
Validation loss: 2.564657507078582

Epoch: 352| Step: 0
Training loss: 3.018557372966696
Validation loss: 2.5778522733769256

Epoch: 5| Step: 1
Training loss: 3.0251395390381344
Validation loss: 2.5602291919417297

Epoch: 5| Step: 2
Training loss: 3.1478876812296996
Validation loss: 2.5658335738305564

Epoch: 5| Step: 3
Training loss: 2.591350410602743
Validation loss: 2.5576236982892744

Epoch: 5| Step: 4
Training loss: 2.6035469436765
Validation loss: 2.589113970248193

Epoch: 5| Step: 5
Training loss: 1.7268501145747384
Validation loss: 2.603403158837166

Epoch: 5| Step: 6
Training loss: 2.502956930511609
Validation loss: 2.6046560835808656

Epoch: 5| Step: 7
Training loss: 2.823047611441806
Validation loss: 2.626891587998911

Epoch: 5| Step: 8
Training loss: 2.766349223512502
Validation loss: 2.615098417563317

Epoch: 5| Step: 9
Training loss: 2.8083033298810243
Validation loss: 2.620803695921448

Epoch: 5| Step: 10
Training loss: 2.866708325667382
Validation loss: 2.5614467390107674

Epoch: 353| Step: 0
Training loss: 2.849535412315495
Validation loss: 2.5410933084057983

Epoch: 5| Step: 1
Training loss: 2.7630175351702353
Validation loss: 2.5248509034370428

Epoch: 5| Step: 2
Training loss: 2.7376807584264813
Validation loss: 2.5235297784543653

Epoch: 5| Step: 3
Training loss: 2.4195132645655093
Validation loss: 2.534535730363697

Epoch: 5| Step: 4
Training loss: 2.3609432036093003
Validation loss: 2.5252320064740865

Epoch: 5| Step: 5
Training loss: 2.5416020765592062
Validation loss: 2.519587765773893

Epoch: 5| Step: 6
Training loss: 2.7149444780942615
Validation loss: 2.547641986184953

Epoch: 5| Step: 7
Training loss: 2.903880640409085
Validation loss: 2.551646016874471

Epoch: 5| Step: 8
Training loss: 2.8411340104278717
Validation loss: 2.555718042887564

Epoch: 5| Step: 9
Training loss: 2.937513960135545
Validation loss: 2.581329072003702

Epoch: 5| Step: 10
Training loss: 3.082482366581065
Validation loss: 2.608528415951763

Epoch: 354| Step: 0
Training loss: 2.822094636905084
Validation loss: 2.6134531104491914

Epoch: 5| Step: 1
Training loss: 3.0327212509114614
Validation loss: 2.6264211886830924

Epoch: 5| Step: 2
Training loss: 2.6427854469324723
Validation loss: 2.629824359214139

Epoch: 5| Step: 3
Training loss: 2.986546230896523
Validation loss: 2.594360427990425

Epoch: 5| Step: 4
Training loss: 2.565600682467449
Validation loss: 2.5871398220529427

Epoch: 5| Step: 5
Training loss: 2.753648158756027
Validation loss: 2.555266936112559

Epoch: 5| Step: 6
Training loss: 2.9026049654279773
Validation loss: 2.5561432306146985

Epoch: 5| Step: 7
Training loss: 2.5645649661148346
Validation loss: 2.555506401100527

Epoch: 5| Step: 8
Training loss: 2.690677450025492
Validation loss: 2.548833183723911

Epoch: 5| Step: 9
Training loss: 2.6192635116934997
Validation loss: 2.5364466891771413

Epoch: 5| Step: 10
Training loss: 2.5948145876229045
Validation loss: 2.5490480422315716

Epoch: 355| Step: 0
Training loss: 2.702948062816902
Validation loss: 2.5645271304774213

Epoch: 5| Step: 1
Training loss: 2.9557909361088783
Validation loss: 2.581516906117263

Epoch: 5| Step: 2
Training loss: 2.535799905801316
Validation loss: 2.6139447525216353

Epoch: 5| Step: 3
Training loss: 2.5949952227304105
Validation loss: 2.583433476457713

Epoch: 5| Step: 4
Training loss: 2.5761561418563357
Validation loss: 2.5819195736923346

Epoch: 5| Step: 5
Training loss: 2.7697947474980564
Validation loss: 2.5684010808952205

Epoch: 5| Step: 6
Training loss: 2.951653653903611
Validation loss: 2.5945434582277644

Epoch: 5| Step: 7
Training loss: 2.3680918763160506
Validation loss: 2.589809814630706

Epoch: 5| Step: 8
Training loss: 3.0290267499244394
Validation loss: 2.54680079161978

Epoch: 5| Step: 9
Training loss: 2.650873914606071
Validation loss: 2.5060404272996415

Epoch: 5| Step: 10
Training loss: 3.010051102315342
Validation loss: 2.5117323626636403

Epoch: 356| Step: 0
Training loss: 2.639952624791782
Validation loss: 2.4997965996558333

Epoch: 5| Step: 1
Training loss: 2.4925762578840365
Validation loss: 2.5069268994041285

Epoch: 5| Step: 2
Training loss: 2.861381452148117
Validation loss: 2.5006818959145547

Epoch: 5| Step: 3
Training loss: 2.7004630150977156
Validation loss: 2.520268088983961

Epoch: 5| Step: 4
Training loss: 2.730509439800984
Validation loss: 2.5101521445868378

Epoch: 5| Step: 5
Training loss: 2.777535089911502
Validation loss: 2.5047203374758755

Epoch: 5| Step: 6
Training loss: 3.2637804288406267
Validation loss: 2.519480378207407

Epoch: 5| Step: 7
Training loss: 2.6550603558707757
Validation loss: 2.5497716147935376

Epoch: 5| Step: 8
Training loss: 2.551585422653512
Validation loss: 2.5532834741770865

Epoch: 5| Step: 9
Training loss: 2.9832721689727673
Validation loss: 2.59158151325325

Epoch: 5| Step: 10
Training loss: 2.6677865319419745
Validation loss: 2.5959368265307092

Epoch: 357| Step: 0
Training loss: 2.786902181386301
Validation loss: 2.6053727583927198

Epoch: 5| Step: 1
Training loss: 2.7134316703384935
Validation loss: 2.5677336962980926

Epoch: 5| Step: 2
Training loss: 2.4686806584530956
Validation loss: 2.600112536103398

Epoch: 5| Step: 3
Training loss: 3.1819536910988133
Validation loss: 2.5715499548724012

Epoch: 5| Step: 4
Training loss: 2.670235738884228
Validation loss: 2.5658635999703576

Epoch: 5| Step: 5
Training loss: 2.2737297578133955
Validation loss: 2.577102983593317

Epoch: 5| Step: 6
Training loss: 2.528995498906629
Validation loss: 2.58667233953096

Epoch: 5| Step: 7
Training loss: 2.7946768705943725
Validation loss: 2.6018422446998057

Epoch: 5| Step: 8
Training loss: 3.308943368574123
Validation loss: 2.59479661411829

Epoch: 5| Step: 9
Training loss: 2.510258037784117
Validation loss: 2.5909453794910706

Epoch: 5| Step: 10
Training loss: 2.5997438231221586
Validation loss: 2.5963712272404837

Epoch: 358| Step: 0
Training loss: 2.857061064775558
Validation loss: 2.598633479397162

Epoch: 5| Step: 1
Training loss: 2.289939738317791
Validation loss: 2.6390080800868394

Epoch: 5| Step: 2
Training loss: 2.8120261746866446
Validation loss: 2.6635116860808283

Epoch: 5| Step: 3
Training loss: 3.054927416499542
Validation loss: 2.686854680646461

Epoch: 5| Step: 4
Training loss: 2.7239769861422682
Validation loss: 2.650305236988074

Epoch: 5| Step: 5
Training loss: 2.4901551955855696
Validation loss: 2.620610426091648

Epoch: 5| Step: 6
Training loss: 2.720392542170356
Validation loss: 2.5826337133592054

Epoch: 5| Step: 7
Training loss: 2.4755343159065593
Validation loss: 2.5549628568552274

Epoch: 5| Step: 8
Training loss: 3.035605221880861
Validation loss: 2.5472926130817477

Epoch: 5| Step: 9
Training loss: 2.6317241468024877
Validation loss: 2.5431310798050712

Epoch: 5| Step: 10
Training loss: 2.937164125111049
Validation loss: 2.5102238220834696

Epoch: 359| Step: 0
Training loss: 2.2854933270023383
Validation loss: 2.53203143402905

Epoch: 5| Step: 1
Training loss: 2.8030714729497355
Validation loss: 2.5230610772856044

Epoch: 5| Step: 2
Training loss: 2.693962665845743
Validation loss: 2.509811725386979

Epoch: 5| Step: 3
Training loss: 2.599492988302552
Validation loss: 2.5138983992505843

Epoch: 5| Step: 4
Training loss: 3.066267071134848
Validation loss: 2.5222986973059656

Epoch: 5| Step: 5
Training loss: 2.692413982976076
Validation loss: 2.5203462857509433

Epoch: 5| Step: 6
Training loss: 2.8100075591993643
Validation loss: 2.5373620798012513

Epoch: 5| Step: 7
Training loss: 2.4137132509299533
Validation loss: 2.549552011356813

Epoch: 5| Step: 8
Training loss: 2.9905658839650147
Validation loss: 2.566805188591199

Epoch: 5| Step: 9
Training loss: 2.8878325299766616
Validation loss: 2.629822099549335

Epoch: 5| Step: 10
Training loss: 2.75375335485364
Validation loss: 2.620184754128678

Epoch: 360| Step: 0
Training loss: 2.851351461047716
Validation loss: 2.6207904453434323

Epoch: 5| Step: 1
Training loss: 2.4135801950759257
Validation loss: 2.625858975965997

Epoch: 5| Step: 2
Training loss: 2.6881013241869174
Validation loss: 2.641218289280256

Epoch: 5| Step: 3
Training loss: 2.875451757348381
Validation loss: 2.6627908645904075

Epoch: 5| Step: 4
Training loss: 2.3470049825907195
Validation loss: 2.647402862646468

Epoch: 5| Step: 5
Training loss: 2.4097716087926195
Validation loss: 2.6077575229129333

Epoch: 5| Step: 6
Training loss: 2.7124379867285713
Validation loss: 2.5976696866804616

Epoch: 5| Step: 7
Training loss: 2.83967852210188
Validation loss: 2.5787596447528434

Epoch: 5| Step: 8
Training loss: 2.628677516922925
Validation loss: 2.5542603155301693

Epoch: 5| Step: 9
Training loss: 3.2085810644114034
Validation loss: 2.552966524099488

Epoch: 5| Step: 10
Training loss: 2.919731455433973
Validation loss: 2.5337424181793424

Epoch: 361| Step: 0
Training loss: 2.817080434244672
Validation loss: 2.5082886723330913

Epoch: 5| Step: 1
Training loss: 2.5653575688140595
Validation loss: 2.5153138759314215

Epoch: 5| Step: 2
Training loss: 2.6956125285910204
Validation loss: 2.5015279294876502

Epoch: 5| Step: 3
Training loss: 1.9628464119709683
Validation loss: 2.5394083564656493

Epoch: 5| Step: 4
Training loss: 3.0196395795372033
Validation loss: 2.5615319865460267

Epoch: 5| Step: 5
Training loss: 3.10493773712782
Validation loss: 2.5614196366740374

Epoch: 5| Step: 6
Training loss: 2.1671799883062524
Validation loss: 2.555827864925765

Epoch: 5| Step: 7
Training loss: 2.7940120429050475
Validation loss: 2.5526867409121463

Epoch: 5| Step: 8
Training loss: 2.45318321596304
Validation loss: 2.5467507111660193

Epoch: 5| Step: 9
Training loss: 3.043034877229981
Validation loss: 2.5486367058491206

Epoch: 5| Step: 10
Training loss: 3.250318951728256
Validation loss: 2.5483246575680556

Epoch: 362| Step: 0
Training loss: 2.3687556646676886
Validation loss: 2.5524806932336235

Epoch: 5| Step: 1
Training loss: 3.1442120313029984
Validation loss: 2.529327543668764

Epoch: 5| Step: 2
Training loss: 2.627888679538831
Validation loss: 2.528490372850313

Epoch: 5| Step: 3
Training loss: 2.653595708960766
Validation loss: 2.514020854317687

Epoch: 5| Step: 4
Training loss: 2.741953608870997
Validation loss: 2.5293381404800646

Epoch: 5| Step: 5
Training loss: 2.516925262487351
Validation loss: 2.531044673555095

Epoch: 5| Step: 6
Training loss: 3.2374851182278923
Validation loss: 2.5456534241267055

Epoch: 5| Step: 7
Training loss: 2.106633418017989
Validation loss: 2.583586293067333

Epoch: 5| Step: 8
Training loss: 3.2659958624267533
Validation loss: 2.592255268522596

Epoch: 5| Step: 9
Training loss: 2.7479193358930147
Validation loss: 2.587858404576949

Epoch: 5| Step: 10
Training loss: 2.248084418466368
Validation loss: 2.5630109644217

Epoch: 363| Step: 0
Training loss: 2.7708134662422643
Validation loss: 2.57677341008562

Epoch: 5| Step: 1
Training loss: 2.5993863188489588
Validation loss: 2.576827544200968

Epoch: 5| Step: 2
Training loss: 2.1033213462830593
Validation loss: 2.567579522812722

Epoch: 5| Step: 3
Training loss: 2.934146671532198
Validation loss: 2.53489541258904

Epoch: 5| Step: 4
Training loss: 2.9921895716886593
Validation loss: 2.5534737217219856

Epoch: 5| Step: 5
Training loss: 2.6112701478055764
Validation loss: 2.541076982769156

Epoch: 5| Step: 6
Training loss: 2.687391589439968
Validation loss: 2.5428165088851986

Epoch: 5| Step: 7
Training loss: 2.937585383046837
Validation loss: 2.5634229995124143

Epoch: 5| Step: 8
Training loss: 2.7134479255128916
Validation loss: 2.54625814066424

Epoch: 5| Step: 9
Training loss: 2.593858371906516
Validation loss: 2.5858012513805417

Epoch: 5| Step: 10
Training loss: 2.910362041800894
Validation loss: 2.6508805962406563

Epoch: 364| Step: 0
Training loss: 3.1394651178499005
Validation loss: 2.7008270818779834

Epoch: 5| Step: 1
Training loss: 3.6858378398079132
Validation loss: 2.6554826046568243

Epoch: 5| Step: 2
Training loss: 2.593561004738993
Validation loss: 2.6368917720635694

Epoch: 5| Step: 3
Training loss: 2.4265326228516244
Validation loss: 2.5668373711630923

Epoch: 5| Step: 4
Training loss: 2.485778220377047
Validation loss: 2.537686107766982

Epoch: 5| Step: 5
Training loss: 2.484662021395503
Validation loss: 2.532775723938966

Epoch: 5| Step: 6
Training loss: 2.7799818598203436
Validation loss: 2.509319997387037

Epoch: 5| Step: 7
Training loss: 2.933851207910219
Validation loss: 2.522068497711939

Epoch: 5| Step: 8
Training loss: 2.335272755018572
Validation loss: 2.5043904627225158

Epoch: 5| Step: 9
Training loss: 2.7518586899938784
Validation loss: 2.5235329856320305

Epoch: 5| Step: 10
Training loss: 2.2655360763462404
Validation loss: 2.5406070021976808

Epoch: 365| Step: 0
Training loss: 2.8461220039600867
Validation loss: 2.585682198730818

Epoch: 5| Step: 1
Training loss: 2.878289041390064
Validation loss: 2.6156105370720235

Epoch: 5| Step: 2
Training loss: 2.6241758960292243
Validation loss: 2.600065567871591

Epoch: 5| Step: 3
Training loss: 2.7232493735561074
Validation loss: 2.56861585408463

Epoch: 5| Step: 4
Training loss: 3.050469415531048
Validation loss: 2.598441789730939

Epoch: 5| Step: 5
Training loss: 2.966831430581757
Validation loss: 2.564365822182192

Epoch: 5| Step: 6
Training loss: 2.273139016394291
Validation loss: 2.549743152658445

Epoch: 5| Step: 7
Training loss: 2.5856994334925645
Validation loss: 2.5317389915894797

Epoch: 5| Step: 8
Training loss: 2.1731804965209367
Validation loss: 2.500322787663166

Epoch: 5| Step: 9
Training loss: 2.9537772613830042
Validation loss: 2.5242023259497497

Epoch: 5| Step: 10
Training loss: 2.6981974766133656
Validation loss: 2.51726303929821

Epoch: 366| Step: 0
Training loss: 2.7005751385772556
Validation loss: 2.5335206522633946

Epoch: 5| Step: 1
Training loss: 2.2956695507451115
Validation loss: 2.5845369187505747

Epoch: 5| Step: 2
Training loss: 3.0287806884621524
Validation loss: 2.5970116369926397

Epoch: 5| Step: 3
Training loss: 2.595367111375587
Validation loss: 2.604399158231244

Epoch: 5| Step: 4
Training loss: 2.573591558202927
Validation loss: 2.6378331550029044

Epoch: 5| Step: 5
Training loss: 2.645619201004951
Validation loss: 2.63528896419438

Epoch: 5| Step: 6
Training loss: 2.2549686671615574
Validation loss: 2.62540483356135

Epoch: 5| Step: 7
Training loss: 2.889409650016825
Validation loss: 2.630378071609827

Epoch: 5| Step: 8
Training loss: 3.1318523809788155
Validation loss: 2.597648279740835

Epoch: 5| Step: 9
Training loss: 2.806775009558954
Validation loss: 2.5784035958181404

Epoch: 5| Step: 10
Training loss: 2.9297169594873016
Validation loss: 2.5474042203582905

Epoch: 367| Step: 0
Training loss: 2.6529172746375935
Validation loss: 2.539878997904868

Epoch: 5| Step: 1
Training loss: 2.4969710120312403
Validation loss: 2.5288928156852686

Epoch: 5| Step: 2
Training loss: 2.5379785659582366
Validation loss: 2.5146305312417065

Epoch: 5| Step: 3
Training loss: 2.831127111871132
Validation loss: 2.5275600472850126

Epoch: 5| Step: 4
Training loss: 2.95635260954324
Validation loss: 2.513823161307159

Epoch: 5| Step: 5
Training loss: 2.703656976645388
Validation loss: 2.531847387665958

Epoch: 5| Step: 6
Training loss: 2.7441831972342716
Validation loss: 2.5460955148388646

Epoch: 5| Step: 7
Training loss: 2.626723949546812
Validation loss: 2.5871343571403327

Epoch: 5| Step: 8
Training loss: 2.886007549135905
Validation loss: 2.5998371067324144

Epoch: 5| Step: 9
Training loss: 2.3628730358314796
Validation loss: 2.6296243898839666

Epoch: 5| Step: 10
Training loss: 3.1695668508830663
Validation loss: 2.639762213694948

Epoch: 368| Step: 0
Training loss: 2.902649156153437
Validation loss: 2.556851875113834

Epoch: 5| Step: 1
Training loss: 2.23955974714294
Validation loss: 2.555876474604348

Epoch: 5| Step: 2
Training loss: 3.145923907931829
Validation loss: 2.501164738247341

Epoch: 5| Step: 3
Training loss: 2.9474921218469117
Validation loss: 2.5132266095164844

Epoch: 5| Step: 4
Training loss: 2.20394406074941
Validation loss: 2.505093732031633

Epoch: 5| Step: 5
Training loss: 2.7131802738642947
Validation loss: 2.497352728469076

Epoch: 5| Step: 6
Training loss: 2.600856834223146
Validation loss: 2.5114274803150813

Epoch: 5| Step: 7
Training loss: 2.796074438334837
Validation loss: 2.5114184580444263

Epoch: 5| Step: 8
Training loss: 2.099812172255519
Validation loss: 2.528137310677566

Epoch: 5| Step: 9
Training loss: 3.166572837108732
Validation loss: 2.5316747301218965

Epoch: 5| Step: 10
Training loss: 2.8865709073376977
Validation loss: 2.5776294260537815

Epoch: 369| Step: 0
Training loss: 2.865147834412233
Validation loss: 2.5797241700450817

Epoch: 5| Step: 1
Training loss: 2.6863020067608
Validation loss: 2.6138003587697423

Epoch: 5| Step: 2
Training loss: 2.5838512291199844
Validation loss: 2.591424091148631

Epoch: 5| Step: 3
Training loss: 2.6835455966499464
Validation loss: 2.5764724222883544

Epoch: 5| Step: 4
Training loss: 2.2160223729625796
Validation loss: 2.595284326547151

Epoch: 5| Step: 5
Training loss: 2.9754377027094816
Validation loss: 2.5846276833201136

Epoch: 5| Step: 6
Training loss: 3.090325203482839
Validation loss: 2.5606547399004342

Epoch: 5| Step: 7
Training loss: 2.4489233882287076
Validation loss: 2.5212952693908797

Epoch: 5| Step: 8
Training loss: 2.8253440883690404
Validation loss: 2.4988490449612555

Epoch: 5| Step: 9
Training loss: 2.8055519748157107
Validation loss: 2.48619181874614

Epoch: 5| Step: 10
Training loss: 2.5537526698012174
Validation loss: 2.4883099505037407

Epoch: 370| Step: 0
Training loss: 2.8848834778842
Validation loss: 2.4924592435647863

Epoch: 5| Step: 1
Training loss: 2.8969732734940563
Validation loss: 2.4984687607286764

Epoch: 5| Step: 2
Training loss: 3.027151581602422
Validation loss: 2.512813000525237

Epoch: 5| Step: 3
Training loss: 3.0044603568407484
Validation loss: 2.5107769301482783

Epoch: 5| Step: 4
Training loss: 2.260057857414244
Validation loss: 2.5312664396561635

Epoch: 5| Step: 5
Training loss: 2.6077283586261073
Validation loss: 2.5514890948739337

Epoch: 5| Step: 6
Training loss: 2.962059754443114
Validation loss: 2.5793150953231265

Epoch: 5| Step: 7
Training loss: 2.4511205173902577
Validation loss: 2.6018852406432815

Epoch: 5| Step: 8
Training loss: 2.504255868483487
Validation loss: 2.6406053655343076

Epoch: 5| Step: 9
Training loss: 2.6343118716603033
Validation loss: 2.673756279955377

Epoch: 5| Step: 10
Training loss: 2.7416219535667743
Validation loss: 2.7132445941905585

Epoch: 371| Step: 0
Training loss: 2.7937474159041025
Validation loss: 2.602461316963491

Epoch: 5| Step: 1
Training loss: 2.4326324768688528
Validation loss: 2.569682556030983

Epoch: 5| Step: 2
Training loss: 2.6893075586400483
Validation loss: 2.5454309898163374

Epoch: 5| Step: 3
Training loss: 3.0823668090558023
Validation loss: 2.5424561463789384

Epoch: 5| Step: 4
Training loss: 2.870896936015663
Validation loss: 2.5471757703271445

Epoch: 5| Step: 5
Training loss: 2.682951338057635
Validation loss: 2.547073427995393

Epoch: 5| Step: 6
Training loss: 2.967065272894778
Validation loss: 2.534214038020553

Epoch: 5| Step: 7
Training loss: 2.41785279028284
Validation loss: 2.547696376033139

Epoch: 5| Step: 8
Training loss: 2.5431040363099284
Validation loss: 2.5279043275561492

Epoch: 5| Step: 9
Training loss: 2.872630262218423
Validation loss: 2.5379878811868486

Epoch: 5| Step: 10
Training loss: 2.7367686230914536
Validation loss: 2.525033075357045

Epoch: 372| Step: 0
Training loss: 2.7220744711381646
Validation loss: 2.53337587570869

Epoch: 5| Step: 1
Training loss: 2.445659381284552
Validation loss: 2.543189662809593

Epoch: 5| Step: 2
Training loss: 3.066124775596448
Validation loss: 2.556281310713424

Epoch: 5| Step: 3
Training loss: 2.9814806579034094
Validation loss: 2.5484339843889923

Epoch: 5| Step: 4
Training loss: 2.6262340369776607
Validation loss: 2.552830793370659

Epoch: 5| Step: 5
Training loss: 2.9845390873881934
Validation loss: 2.5549912789047067

Epoch: 5| Step: 6
Training loss: 2.3498153532818367
Validation loss: 2.5648177025317302

Epoch: 5| Step: 7
Training loss: 2.5043847732219966
Validation loss: 2.575585006477935

Epoch: 5| Step: 8
Training loss: 2.687801610301231
Validation loss: 2.5500124785254483

Epoch: 5| Step: 9
Training loss: 2.415717289236241
Validation loss: 2.5672166386802697

Epoch: 5| Step: 10
Training loss: 3.0252254433602626
Validation loss: 2.559782749987674

Epoch: 373| Step: 0
Training loss: 2.3305181709699125
Validation loss: 2.5602909423695004

Epoch: 5| Step: 1
Training loss: 2.7287492699825275
Validation loss: 2.563214931405293

Epoch: 5| Step: 2
Training loss: 2.9055056695523382
Validation loss: 2.5357751579238506

Epoch: 5| Step: 3
Training loss: 3.1470627729654304
Validation loss: 2.515380735416515

Epoch: 5| Step: 4
Training loss: 2.4347334591720537
Validation loss: 2.5255059429726705

Epoch: 5| Step: 5
Training loss: 3.2746643826272726
Validation loss: 2.5203683685872127

Epoch: 5| Step: 6
Training loss: 2.4025944276605826
Validation loss: 2.502711236948191

Epoch: 5| Step: 7
Training loss: 2.8288389537679555
Validation loss: 2.505373832498135

Epoch: 5| Step: 8
Training loss: 2.2896195602906344
Validation loss: 2.5083447474462988

Epoch: 5| Step: 9
Training loss: 2.6345317897996305
Validation loss: 2.506401193660447

Epoch: 5| Step: 10
Training loss: 2.923760932552909
Validation loss: 2.5251524092070183

Epoch: 374| Step: 0
Training loss: 2.5593430215516895
Validation loss: 2.544937996663765

Epoch: 5| Step: 1
Training loss: 3.1971340816518112
Validation loss: 2.583730814586249

Epoch: 5| Step: 2
Training loss: 2.2366704287357595
Validation loss: 2.5921729500168933

Epoch: 5| Step: 3
Training loss: 2.3396766360919643
Validation loss: 2.6610840715947957

Epoch: 5| Step: 4
Training loss: 3.144888190630532
Validation loss: 2.6570957002963014

Epoch: 5| Step: 5
Training loss: 2.8386118655609156
Validation loss: 2.634312517846957

Epoch: 5| Step: 6
Training loss: 2.604209584200389
Validation loss: 2.6498638356850854

Epoch: 5| Step: 7
Training loss: 2.3775386292922467
Validation loss: 2.5899700034475948

Epoch: 5| Step: 8
Training loss: 3.0265638171238907
Validation loss: 2.567542402577101

Epoch: 5| Step: 9
Training loss: 2.326096540715741
Validation loss: 2.553997841706197

Epoch: 5| Step: 10
Training loss: 2.933577007951977
Validation loss: 2.525480191789077

Epoch: 375| Step: 0
Training loss: 2.913375814493319
Validation loss: 2.5240381551366218

Epoch: 5| Step: 1
Training loss: 2.748131724269779
Validation loss: 2.5115417368080872

Epoch: 5| Step: 2
Training loss: 2.6612974791369974
Validation loss: 2.5152970180916863

Epoch: 5| Step: 3
Training loss: 2.7399044259659378
Validation loss: 2.5024288100218977

Epoch: 5| Step: 4
Training loss: 2.7569605562351587
Validation loss: 2.531451502995482

Epoch: 5| Step: 5
Training loss: 2.733202001471382
Validation loss: 2.563358621238793

Epoch: 5| Step: 6
Training loss: 2.2874942133262275
Validation loss: 2.590595714842399

Epoch: 5| Step: 7
Training loss: 2.717861863567763
Validation loss: 2.5903729652381644

Epoch: 5| Step: 8
Training loss: 2.825473111126131
Validation loss: 2.6233736352875985

Epoch: 5| Step: 9
Training loss: 2.682156506932331
Validation loss: 2.653734652822175

Epoch: 5| Step: 10
Training loss: 2.5716251627386555
Validation loss: 2.6479071561858576

Epoch: 376| Step: 0
Training loss: 2.749907058532416
Validation loss: 2.595696717132778

Epoch: 5| Step: 1
Training loss: 2.6890762497208485
Validation loss: 2.5492667478046727

Epoch: 5| Step: 2
Training loss: 2.343934318924202
Validation loss: 2.5330503303512537

Epoch: 5| Step: 3
Training loss: 2.7534205231550706
Validation loss: 2.5093070530791515

Epoch: 5| Step: 4
Training loss: 2.68058437096937
Validation loss: 2.516090485029329

Epoch: 5| Step: 5
Training loss: 3.057707169657679
Validation loss: 2.5070076853046155

Epoch: 5| Step: 6
Training loss: 2.73105589921105
Validation loss: 2.5083586737897026

Epoch: 5| Step: 7
Training loss: 2.130305007444627
Validation loss: 2.5093769341808723

Epoch: 5| Step: 8
Training loss: 2.5499895394802583
Validation loss: 2.545399512035102

Epoch: 5| Step: 9
Training loss: 2.811293109921151
Validation loss: 2.5557340222197786

Epoch: 5| Step: 10
Training loss: 3.088281441458617
Validation loss: 2.591291677759142

Epoch: 377| Step: 0
Training loss: 2.1545775188347176
Validation loss: 2.624243281959257

Epoch: 5| Step: 1
Training loss: 3.0353309453425186
Validation loss: 2.5878284989103397

Epoch: 5| Step: 2
Training loss: 2.608812100119606
Validation loss: 2.6172810130829722

Epoch: 5| Step: 3
Training loss: 2.8226548715139868
Validation loss: 2.5928273829054707

Epoch: 5| Step: 4
Training loss: 2.2091976369756394
Validation loss: 2.56254656329445

Epoch: 5| Step: 5
Training loss: 2.3514886888852087
Validation loss: 2.5573273852097147

Epoch: 5| Step: 6
Training loss: 3.0545641783970243
Validation loss: 2.5470532173066744

Epoch: 5| Step: 7
Training loss: 2.9873880086042783
Validation loss: 2.544952894807551

Epoch: 5| Step: 8
Training loss: 2.9718139898894966
Validation loss: 2.556644640962424

Epoch: 5| Step: 9
Training loss: 2.647411226363795
Validation loss: 2.5164189574600204

Epoch: 5| Step: 10
Training loss: 2.3742477831959206
Validation loss: 2.511996932998508

Epoch: 378| Step: 0
Training loss: 2.668721887230488
Validation loss: 2.5072255283835916

Epoch: 5| Step: 1
Training loss: 3.051456078833481
Validation loss: 2.500363504993132

Epoch: 5| Step: 2
Training loss: 2.7196452102958677
Validation loss: 2.490473181775079

Epoch: 5| Step: 3
Training loss: 2.1277161237628275
Validation loss: 2.5167710864119686

Epoch: 5| Step: 4
Training loss: 2.655104176835601
Validation loss: 2.53977901322628

Epoch: 5| Step: 5
Training loss: 2.8889508322245194
Validation loss: 2.566937559775032

Epoch: 5| Step: 6
Training loss: 2.839038341127604
Validation loss: 2.6063277949768344

Epoch: 5| Step: 7
Training loss: 2.497048543119812
Validation loss: 2.604883870125395

Epoch: 5| Step: 8
Training loss: 2.6567599536339204
Validation loss: 2.5717344350782287

Epoch: 5| Step: 9
Training loss: 2.7079467986669163
Validation loss: 2.534494197506471

Epoch: 5| Step: 10
Training loss: 3.0012414271030856
Validation loss: 2.5291441839299753

Epoch: 379| Step: 0
Training loss: 2.5283826435019026
Validation loss: 2.5352910269520748

Epoch: 5| Step: 1
Training loss: 2.792720330134436
Validation loss: 2.529575901792195

Epoch: 5| Step: 2
Training loss: 2.7191407372324354
Validation loss: 2.539224656498385

Epoch: 5| Step: 3
Training loss: 2.750505400945856
Validation loss: 2.549796190628371

Epoch: 5| Step: 4
Training loss: 2.96718098186241
Validation loss: 2.530689509138419

Epoch: 5| Step: 5
Training loss: 2.8212519636979745
Validation loss: 2.514243452078261

Epoch: 5| Step: 6
Training loss: 2.471789167339047
Validation loss: 2.535350286580257

Epoch: 5| Step: 7
Training loss: 2.433997841682825
Validation loss: 2.5310621334937964

Epoch: 5| Step: 8
Training loss: 2.619401319986398
Validation loss: 2.5383111101610947

Epoch: 5| Step: 9
Training loss: 2.6519175483406383
Validation loss: 2.5503231471973047

Epoch: 5| Step: 10
Training loss: 2.449397760447555
Validation loss: 2.5637145026861536

Epoch: 380| Step: 0
Training loss: 2.6769866233209325
Validation loss: 2.632347592916244

Epoch: 5| Step: 1
Training loss: 3.261379859359552
Validation loss: 2.6685484148339866

Epoch: 5| Step: 2
Training loss: 2.734194853161741
Validation loss: 2.5975578309816076

Epoch: 5| Step: 3
Training loss: 2.5066822392744252
Validation loss: 2.574043674420147

Epoch: 5| Step: 4
Training loss: 2.933770267138632
Validation loss: 2.5422220462179483

Epoch: 5| Step: 5
Training loss: 2.303059872828327
Validation loss: 2.534091690745132

Epoch: 5| Step: 6
Training loss: 2.870087116261742
Validation loss: 2.5217911359950977

Epoch: 5| Step: 7
Training loss: 2.5171081719901336
Validation loss: 2.5148227344595595

Epoch: 5| Step: 8
Training loss: 2.453534329031357
Validation loss: 2.5150794929019162

Epoch: 5| Step: 9
Training loss: 2.5474144299991166
Validation loss: 2.537520014846956

Epoch: 5| Step: 10
Training loss: 2.7782371575594116
Validation loss: 2.588905572499327

Epoch: 381| Step: 0
Training loss: 2.5316407643797696
Validation loss: 2.612898347668517

Epoch: 5| Step: 1
Training loss: 3.1836545599061976
Validation loss: 2.6428929556645557

Epoch: 5| Step: 2
Training loss: 2.5643955755930747
Validation loss: 2.6885115161988957

Epoch: 5| Step: 3
Training loss: 2.559905995490755
Validation loss: 2.7356046175531548

Epoch: 5| Step: 4
Training loss: 2.6370618808850397
Validation loss: 2.655522265507139

Epoch: 5| Step: 5
Training loss: 2.7123019168092712
Validation loss: 2.6003712721121177

Epoch: 5| Step: 6
Training loss: 2.513280024363676
Validation loss: 2.543628901124454

Epoch: 5| Step: 7
Training loss: 2.727982378156022
Validation loss: 2.5277308433737344

Epoch: 5| Step: 8
Training loss: 2.3778614073551703
Validation loss: 2.5108388920894034

Epoch: 5| Step: 9
Training loss: 2.6414921707941326
Validation loss: 2.5108986379421205

Epoch: 5| Step: 10
Training loss: 2.8089994050049416
Validation loss: 2.502786126741106

Epoch: 382| Step: 0
Training loss: 2.8489973680424474
Validation loss: 2.5068741642362933

Epoch: 5| Step: 1
Training loss: 2.796397589317203
Validation loss: 2.4943196547245856

Epoch: 5| Step: 2
Training loss: 2.9536962208995776
Validation loss: 2.4863328860768594

Epoch: 5| Step: 3
Training loss: 2.943007804463622
Validation loss: 2.487105096636279

Epoch: 5| Step: 4
Training loss: 2.2572222403385656
Validation loss: 2.491735916816101

Epoch: 5| Step: 5
Training loss: 2.1871370286891456
Validation loss: 2.520875617370723

Epoch: 5| Step: 6
Training loss: 2.6645949382593894
Validation loss: 2.507178666724358

Epoch: 5| Step: 7
Training loss: 3.034639331685577
Validation loss: 2.5329572014108654

Epoch: 5| Step: 8
Training loss: 2.4239381923475367
Validation loss: 2.548989035679133

Epoch: 5| Step: 9
Training loss: 3.0195893631212507
Validation loss: 2.5616089997342524

Epoch: 5| Step: 10
Training loss: 2.631573122168669
Validation loss: 2.5694036421953887

Epoch: 383| Step: 0
Training loss: 2.331936168170011
Validation loss: 2.5855141213101542

Epoch: 5| Step: 1
Training loss: 2.681672898311578
Validation loss: 2.604502406637915

Epoch: 5| Step: 2
Training loss: 2.358705033933508
Validation loss: 2.638177830812413

Epoch: 5| Step: 3
Training loss: 2.379614412985029
Validation loss: 2.651763021685162

Epoch: 5| Step: 4
Training loss: 3.0425434329491234
Validation loss: 2.6280836421191083

Epoch: 5| Step: 5
Training loss: 2.852309706523166
Validation loss: 2.5591416600871004

Epoch: 5| Step: 6
Training loss: 2.90896332119622
Validation loss: 2.531068340362582

Epoch: 5| Step: 7
Training loss: 2.495019624896643
Validation loss: 2.506337758533883

Epoch: 5| Step: 8
Training loss: 2.7525402820768248
Validation loss: 2.4910183851504226

Epoch: 5| Step: 9
Training loss: 2.6101764658761897
Validation loss: 2.4960154795323772

Epoch: 5| Step: 10
Training loss: 3.138937881297437
Validation loss: 2.5021420541389783

Epoch: 384| Step: 0
Training loss: 2.587080688409676
Validation loss: 2.5000022108827067

Epoch: 5| Step: 1
Training loss: 2.8096550009503365
Validation loss: 2.5002337602825837

Epoch: 5| Step: 2
Training loss: 2.8171362069824397
Validation loss: 2.5008139567059806

Epoch: 5| Step: 3
Training loss: 2.736438256170598
Validation loss: 2.504977288109934

Epoch: 5| Step: 4
Training loss: 2.594560703293047
Validation loss: 2.491727411238458

Epoch: 5| Step: 5
Training loss: 2.7168303103004137
Validation loss: 2.49201816782464

Epoch: 5| Step: 6
Training loss: 2.6657346249004354
Validation loss: 2.495260181595515

Epoch: 5| Step: 7
Training loss: 3.133914744090844
Validation loss: 2.5335739934087846

Epoch: 5| Step: 8
Training loss: 2.799138692807097
Validation loss: 2.577052501192577

Epoch: 5| Step: 9
Training loss: 2.7420045623184857
Validation loss: 2.5817669151135236

Epoch: 5| Step: 10
Training loss: 2.5216683720265447
Validation loss: 2.622624520269552

Epoch: 385| Step: 0
Training loss: 2.876181649892564
Validation loss: 2.5882935559311315

Epoch: 5| Step: 1
Training loss: 2.3174021543651313
Validation loss: 2.563953759627781

Epoch: 5| Step: 2
Training loss: 2.497365421644348
Validation loss: 2.5570315686615293

Epoch: 5| Step: 3
Training loss: 2.8383051129153585
Validation loss: 2.5719986961461725

Epoch: 5| Step: 4
Training loss: 2.1506152403836465
Validation loss: 2.5336925485949666

Epoch: 5| Step: 5
Training loss: 3.179578774582705
Validation loss: 2.537082227909506

Epoch: 5| Step: 6
Training loss: 2.8897576757824615
Validation loss: 2.5109896344051594

Epoch: 5| Step: 7
Training loss: 2.415914769330337
Validation loss: 2.5076206039169624

Epoch: 5| Step: 8
Training loss: 2.535863651274497
Validation loss: 2.505398010914742

Epoch: 5| Step: 9
Training loss: 2.579935721106773
Validation loss: 2.50410848010812

Epoch: 5| Step: 10
Training loss: 2.85569601550501
Validation loss: 2.5188756704322035

Epoch: 386| Step: 0
Training loss: 2.623867517232118
Validation loss: 2.524163146423815

Epoch: 5| Step: 1
Training loss: 2.4672994094216496
Validation loss: 2.530317836999519

Epoch: 5| Step: 2
Training loss: 2.5615870082120713
Validation loss: 2.54031958976188

Epoch: 5| Step: 3
Training loss: 2.9723273958828003
Validation loss: 2.584547990480784

Epoch: 5| Step: 4
Training loss: 2.5508606972816126
Validation loss: 2.604227685685177

Epoch: 5| Step: 5
Training loss: 2.4436868254552016
Validation loss: 2.6209185405874385

Epoch: 5| Step: 6
Training loss: 2.2981266063013344
Validation loss: 2.637610491287133

Epoch: 5| Step: 7
Training loss: 2.2799643460213184
Validation loss: 2.614727647896563

Epoch: 5| Step: 8
Training loss: 2.9475137999181626
Validation loss: 2.582140862338103

Epoch: 5| Step: 9
Training loss: 2.8344384637391795
Validation loss: 2.5457098544362906

Epoch: 5| Step: 10
Training loss: 3.1293047438091524
Validation loss: 2.5058058868866877

Epoch: 387| Step: 0
Training loss: 2.875638807894134
Validation loss: 2.49899945284872

Epoch: 5| Step: 1
Training loss: 2.2899482757857057
Validation loss: 2.4880065689087245

Epoch: 5| Step: 2
Training loss: 2.8144070411737183
Validation loss: 2.488833633040883

Epoch: 5| Step: 3
Training loss: 2.694950599146864
Validation loss: 2.484152947711342

Epoch: 5| Step: 4
Training loss: 2.4059252829488633
Validation loss: 2.4818553224317568

Epoch: 5| Step: 5
Training loss: 2.957678458213911
Validation loss: 2.517228661149058

Epoch: 5| Step: 6
Training loss: 2.7203446896317596
Validation loss: 2.5337287031929194

Epoch: 5| Step: 7
Training loss: 2.5679890528828815
Validation loss: 2.5200201594387406

Epoch: 5| Step: 8
Training loss: 2.4210085395621412
Validation loss: 2.527509262032125

Epoch: 5| Step: 9
Training loss: 2.3128287622946733
Validation loss: 2.5312162635304127

Epoch: 5| Step: 10
Training loss: 3.2538193488452047
Validation loss: 2.5763981221062546

Epoch: 388| Step: 0
Training loss: 2.582280364838294
Validation loss: 2.58974927390463

Epoch: 5| Step: 1
Training loss: 2.3739825629258373
Validation loss: 2.595510314162024

Epoch: 5| Step: 2
Training loss: 2.0708989302481613
Validation loss: 2.632617357875911

Epoch: 5| Step: 3
Training loss: 3.1235451935926934
Validation loss: 2.6607620609284717

Epoch: 5| Step: 4
Training loss: 2.525390341774201
Validation loss: 2.6064597966201624

Epoch: 5| Step: 5
Training loss: 2.2812765459580264
Validation loss: 2.5818681230229377

Epoch: 5| Step: 6
Training loss: 2.9617136237508395
Validation loss: 2.577251175117715

Epoch: 5| Step: 7
Training loss: 3.2786359274272434
Validation loss: 2.5424695521214287

Epoch: 5| Step: 8
Training loss: 2.370229346690802
Validation loss: 2.517155708379113

Epoch: 5| Step: 9
Training loss: 2.5874714983416194
Validation loss: 2.5031807067316802

Epoch: 5| Step: 10
Training loss: 2.8146227137598725
Validation loss: 2.500303469461513

Epoch: 389| Step: 0
Training loss: 2.1603640685733874
Validation loss: 2.49501886659917

Epoch: 5| Step: 1
Training loss: 3.080322410750992
Validation loss: 2.504843672116139

Epoch: 5| Step: 2
Training loss: 2.674179511042872
Validation loss: 2.4986865726045795

Epoch: 5| Step: 3
Training loss: 3.066207509980806
Validation loss: 2.4978735699281174

Epoch: 5| Step: 4
Training loss: 2.271018927686352
Validation loss: 2.4792957573904078

Epoch: 5| Step: 5
Training loss: 2.5085290378336835
Validation loss: 2.496708604473074

Epoch: 5| Step: 6
Training loss: 2.8596383062147224
Validation loss: 2.504044504690373

Epoch: 5| Step: 7
Training loss: 2.617942678332532
Validation loss: 2.516291129715142

Epoch: 5| Step: 8
Training loss: 2.3692104646934986
Validation loss: 2.5718489908489572

Epoch: 5| Step: 9
Training loss: 3.030730212763682
Validation loss: 2.605391255226021

Epoch: 5| Step: 10
Training loss: 2.2563133674662814
Validation loss: 2.633827069246654

Epoch: 390| Step: 0
Training loss: 2.8997600653475577
Validation loss: 2.643480838465533

Epoch: 5| Step: 1
Training loss: 2.6129787937184106
Validation loss: 2.61099689595007

Epoch: 5| Step: 2
Training loss: 3.0262882484562077
Validation loss: 2.5627686044381734

Epoch: 5| Step: 3
Training loss: 2.9425615572263575
Validation loss: 2.5178533972065567

Epoch: 5| Step: 4
Training loss: 2.559906181762103
Validation loss: 2.486728753577225

Epoch: 5| Step: 5
Training loss: 2.5943482409967142
Validation loss: 2.508253419951059

Epoch: 5| Step: 6
Training loss: 2.705596323334978
Validation loss: 2.4998232461116388

Epoch: 5| Step: 7
Training loss: 2.4190663448727476
Validation loss: 2.4910265154509013

Epoch: 5| Step: 8
Training loss: 2.7374621593350845
Validation loss: 2.5111432425442457

Epoch: 5| Step: 9
Training loss: 2.4358839889237576
Validation loss: 2.5147023186236033

Epoch: 5| Step: 10
Training loss: 2.8706984474890453
Validation loss: 2.526551959287174

Epoch: 391| Step: 0
Training loss: 2.950570429592446
Validation loss: 2.5334407957931586

Epoch: 5| Step: 1
Training loss: 2.6885745539544987
Validation loss: 2.524739696382082

Epoch: 5| Step: 2
Training loss: 2.498698658799775
Validation loss: 2.5408285764081033

Epoch: 5| Step: 3
Training loss: 2.899534937959071
Validation loss: 2.55317708214341

Epoch: 5| Step: 4
Training loss: 2.91510383879034
Validation loss: 2.550866237895998

Epoch: 5| Step: 5
Training loss: 2.582042792174703
Validation loss: 2.5661594153982508

Epoch: 5| Step: 6
Training loss: 2.7203950837651654
Validation loss: 2.572433858483361

Epoch: 5| Step: 7
Training loss: 2.5522970512328564
Validation loss: 2.5983929078315993

Epoch: 5| Step: 8
Training loss: 2.289545522510089
Validation loss: 2.6368022533276023

Epoch: 5| Step: 9
Training loss: 2.6302302797113226
Validation loss: 2.6383741299498764

Epoch: 5| Step: 10
Training loss: 2.6695717147336953
Validation loss: 2.598502684369353

Epoch: 392| Step: 0
Training loss: 2.432353430759536
Validation loss: 2.520777906559201

Epoch: 5| Step: 1
Training loss: 2.550478579920502
Validation loss: 2.5100310042193397

Epoch: 5| Step: 2
Training loss: 2.804283006662758
Validation loss: 2.4921024048371185

Epoch: 5| Step: 3
Training loss: 2.953535747724401
Validation loss: 2.477202406582742

Epoch: 5| Step: 4
Training loss: 2.8297340494557814
Validation loss: 2.4843850393899265

Epoch: 5| Step: 5
Training loss: 2.0691521613843844
Validation loss: 2.4909507369340314

Epoch: 5| Step: 6
Training loss: 2.555760336240718
Validation loss: 2.4860369823894963

Epoch: 5| Step: 7
Training loss: 2.663693757700846
Validation loss: 2.48441718600921

Epoch: 5| Step: 8
Training loss: 2.6024829965818332
Validation loss: 2.4985026684944662

Epoch: 5| Step: 9
Training loss: 2.9377093950675524
Validation loss: 2.5221312393663045

Epoch: 5| Step: 10
Training loss: 2.5539725233495396
Validation loss: 2.5508539084296946

Epoch: 393| Step: 0
Training loss: 3.1752842212728387
Validation loss: 2.58580447947423

Epoch: 5| Step: 1
Training loss: 2.3502819338559404
Validation loss: 2.57326495114272

Epoch: 5| Step: 2
Training loss: 2.402157362243564
Validation loss: 2.602733338367713

Epoch: 5| Step: 3
Training loss: 2.7889576953676247
Validation loss: 2.611976601368501

Epoch: 5| Step: 4
Training loss: 2.7028422125044225
Validation loss: 2.5837440905139832

Epoch: 5| Step: 5
Training loss: 2.442124698976103
Validation loss: 2.571874796094931

Epoch: 5| Step: 6
Training loss: 2.5219788483860333
Validation loss: 2.5840501769846576

Epoch: 5| Step: 7
Training loss: 2.741207458472142
Validation loss: 2.5534848367781002

Epoch: 5| Step: 8
Training loss: 2.4544107748580926
Validation loss: 2.525495470166083

Epoch: 5| Step: 9
Training loss: 2.5764961414571066
Validation loss: 2.496967526381631

Epoch: 5| Step: 10
Training loss: 2.814480317492032
Validation loss: 2.504251913874967

Epoch: 394| Step: 0
Training loss: 2.8585866039235803
Validation loss: 2.4900050668260874

Epoch: 5| Step: 1
Training loss: 2.242281283766554
Validation loss: 2.525767441481079

Epoch: 5| Step: 2
Training loss: 2.3640494619187726
Validation loss: 2.5092410595688803

Epoch: 5| Step: 3
Training loss: 3.008409475558777
Validation loss: 2.5025103260777217

Epoch: 5| Step: 4
Training loss: 2.7448726885791204
Validation loss: 2.5079409663802177

Epoch: 5| Step: 5
Training loss: 2.1619468290158523
Validation loss: 2.493653762995509

Epoch: 5| Step: 6
Training loss: 3.0892933814711996
Validation loss: 2.486553620418508

Epoch: 5| Step: 7
Training loss: 1.9294728765941362
Validation loss: 2.516197870556281

Epoch: 5| Step: 8
Training loss: 2.8658770235115814
Validation loss: 2.529176632351894

Epoch: 5| Step: 9
Training loss: 2.9163251586071635
Validation loss: 2.5692249117471166

Epoch: 5| Step: 10
Training loss: 2.642230837853989
Validation loss: 2.5967800303623947

Epoch: 395| Step: 0
Training loss: 2.5011115464109817
Validation loss: 2.605033147244865

Epoch: 5| Step: 1
Training loss: 2.685688739150737
Validation loss: 2.5565894206754374

Epoch: 5| Step: 2
Training loss: 2.413309516877035
Validation loss: 2.551622964916618

Epoch: 5| Step: 3
Training loss: 2.7916844115950625
Validation loss: 2.5218895018564536

Epoch: 5| Step: 4
Training loss: 2.6854493945376365
Validation loss: 2.5134717566163007

Epoch: 5| Step: 5
Training loss: 2.624265749738438
Validation loss: 2.50482533243082

Epoch: 5| Step: 6
Training loss: 2.4679452091361047
Validation loss: 2.4995811029416353

Epoch: 5| Step: 7
Training loss: 2.7828414307192983
Validation loss: 2.517009856588906

Epoch: 5| Step: 8
Training loss: 2.6445459452774402
Validation loss: 2.526783553341499

Epoch: 5| Step: 9
Training loss: 2.692389542519699
Validation loss: 2.5236311109045713

Epoch: 5| Step: 10
Training loss: 2.7838396167761483
Validation loss: 2.5620412898687035

Epoch: 396| Step: 0
Training loss: 2.7311055719174417
Validation loss: 2.57678240797629

Epoch: 5| Step: 1
Training loss: 2.6395878306779332
Validation loss: 2.642808715479407

Epoch: 5| Step: 2
Training loss: 2.59922910412491
Validation loss: 2.674785982513496

Epoch: 5| Step: 3
Training loss: 2.4681866159908172
Validation loss: 2.6179855596778543

Epoch: 5| Step: 4
Training loss: 2.9210114044311593
Validation loss: 2.594978878575374

Epoch: 5| Step: 5
Training loss: 3.179575025364073
Validation loss: 2.565337116429942

Epoch: 5| Step: 6
Training loss: 2.7451184034260026
Validation loss: 2.523436231100747

Epoch: 5| Step: 7
Training loss: 2.378934011313026
Validation loss: 2.484648937276932

Epoch: 5| Step: 8
Training loss: 2.2150685029814294
Validation loss: 2.480194030074933

Epoch: 5| Step: 9
Training loss: 2.5347135418840527
Validation loss: 2.4697807614001595

Epoch: 5| Step: 10
Training loss: 2.7093202895610187
Validation loss: 2.481073136805505

Epoch: 397| Step: 0
Training loss: 2.919188217822588
Validation loss: 2.4863895898786943

Epoch: 5| Step: 1
Training loss: 2.599702003714594
Validation loss: 2.493312297310278

Epoch: 5| Step: 2
Training loss: 2.202656039925096
Validation loss: 2.4900744693382295

Epoch: 5| Step: 3
Training loss: 2.828413131957872
Validation loss: 2.5121296409213896

Epoch: 5| Step: 4
Training loss: 2.8734488241730705
Validation loss: 2.520532520081852

Epoch: 5| Step: 5
Training loss: 2.8663480189749024
Validation loss: 2.52559415462184

Epoch: 5| Step: 6
Training loss: 2.4571389567385413
Validation loss: 2.536123742159344

Epoch: 5| Step: 7
Training loss: 2.9704620243425977
Validation loss: 2.5758471755890042

Epoch: 5| Step: 8
Training loss: 2.6729893730742953
Validation loss: 2.589466900105793

Epoch: 5| Step: 9
Training loss: 2.4675817501976893
Validation loss: 2.5993526500825377

Epoch: 5| Step: 10
Training loss: 1.865706363098675
Validation loss: 2.6172843110752546

Epoch: 398| Step: 0
Training loss: 2.3302201438016756
Validation loss: 2.62919331868242

Epoch: 5| Step: 1
Training loss: 2.2307622552757587
Validation loss: 2.6245669541457217

Epoch: 5| Step: 2
Training loss: 2.6389747293352985
Validation loss: 2.6320385731877933

Epoch: 5| Step: 3
Training loss: 2.5776246481206533
Validation loss: 2.5648362209623152

Epoch: 5| Step: 4
Training loss: 2.4692361087499095
Validation loss: 2.5166399465032208

Epoch: 5| Step: 5
Training loss: 2.932055032960431
Validation loss: 2.5146706804756684

Epoch: 5| Step: 6
Training loss: 2.878060743378799
Validation loss: 2.4745019894162597

Epoch: 5| Step: 7
Training loss: 2.808188036396425
Validation loss: 2.4908708557242276

Epoch: 5| Step: 8
Training loss: 2.787842470351553
Validation loss: 2.4712441139367494

Epoch: 5| Step: 9
Training loss: 2.312707737020348
Validation loss: 2.476069799290464

Epoch: 5| Step: 10
Training loss: 3.1418164778252837
Validation loss: 2.476077833724332

Epoch: 399| Step: 0
Training loss: 2.516709940793024
Validation loss: 2.4824028181899127

Epoch: 5| Step: 1
Training loss: 2.679924067517569
Validation loss: 2.498357208463392

Epoch: 5| Step: 2
Training loss: 2.343406855577021
Validation loss: 2.5053800288216017

Epoch: 5| Step: 3
Training loss: 2.6271045967308395
Validation loss: 2.5136239239213527

Epoch: 5| Step: 4
Training loss: 2.912289159125911
Validation loss: 2.528191328185686

Epoch: 5| Step: 5
Training loss: 2.718479713070969
Validation loss: 2.5766217186681812

Epoch: 5| Step: 6
Training loss: 2.7548913803427117
Validation loss: 2.604817569890328

Epoch: 5| Step: 7
Training loss: 2.894339818969241
Validation loss: 2.607324732141921

Epoch: 5| Step: 8
Training loss: 2.6677616871229346
Validation loss: 2.60523243775644

Epoch: 5| Step: 9
Training loss: 2.8549314898873988
Validation loss: 2.5565590619950656

Epoch: 5| Step: 10
Training loss: 2.2325656207138587
Validation loss: 2.5304843823855028

Epoch: 400| Step: 0
Training loss: 2.5634220604325204
Validation loss: 2.5361108644033217

Epoch: 5| Step: 1
Training loss: 3.250869047908634
Validation loss: 2.510105848229091

Epoch: 5| Step: 2
Training loss: 2.457474757983632
Validation loss: 2.4980323061986893

Epoch: 5| Step: 3
Training loss: 2.648542824060307
Validation loss: 2.502666486996847

Epoch: 5| Step: 4
Training loss: 2.405507951734805
Validation loss: 2.4845790509654426

Epoch: 5| Step: 5
Training loss: 2.9553801791265077
Validation loss: 2.482134650338599

Epoch: 5| Step: 6
Training loss: 2.5829262156298975
Validation loss: 2.4957544630037667

Epoch: 5| Step: 7
Training loss: 2.2623568410525614
Validation loss: 2.492555871695781

Epoch: 5| Step: 8
Training loss: 2.6285236868165676
Validation loss: 2.4941442451390072

Epoch: 5| Step: 9
Training loss: 2.6189112210777057
Validation loss: 2.509671115129209

Epoch: 5| Step: 10
Training loss: 2.536870297627063
Validation loss: 2.5598704554706995

Epoch: 401| Step: 0
Training loss: 2.6133535058676736
Validation loss: 2.568482489434468

Epoch: 5| Step: 1
Training loss: 2.7363218515720376
Validation loss: 2.6068807196060644

Epoch: 5| Step: 2
Training loss: 2.5609805556769025
Validation loss: 2.6057046561242863

Epoch: 5| Step: 3
Training loss: 2.6386299497039385
Validation loss: 2.6037144852060705

Epoch: 5| Step: 4
Training loss: 2.7969518896008383
Validation loss: 2.620089556066704

Epoch: 5| Step: 5
Training loss: 2.6622041278189523
Validation loss: 2.56067940450888

Epoch: 5| Step: 6
Training loss: 2.7415621226436677
Validation loss: 2.5470341166493236

Epoch: 5| Step: 7
Training loss: 2.3989107242906007
Validation loss: 2.509862570480119

Epoch: 5| Step: 8
Training loss: 2.602731436370377
Validation loss: 2.511780293717514

Epoch: 5| Step: 9
Training loss: 2.776010958064545
Validation loss: 2.5131759579524493

Epoch: 5| Step: 10
Training loss: 2.36584555480889
Validation loss: 2.4997786987964115

Epoch: 402| Step: 0
Training loss: 2.589531466843652
Validation loss: 2.5150782493458546

Epoch: 5| Step: 1
Training loss: 2.1792707147308468
Validation loss: 2.5202915330108064

Epoch: 5| Step: 2
Training loss: 2.869329748808502
Validation loss: 2.5064765326781684

Epoch: 5| Step: 3
Training loss: 3.1056084751388884
Validation loss: 2.5388494253560214

Epoch: 5| Step: 4
Training loss: 2.3794054030732283
Validation loss: 2.544110226154772

Epoch: 5| Step: 5
Training loss: 2.618845946527647
Validation loss: 2.531744532534361

Epoch: 5| Step: 6
Training loss: 2.672089685214109
Validation loss: 2.515290282058715

Epoch: 5| Step: 7
Training loss: 2.860306384874957
Validation loss: 2.504805705062617

Epoch: 5| Step: 8
Training loss: 2.24361605443653
Validation loss: 2.4911041996484613

Epoch: 5| Step: 9
Training loss: 2.931531971462537
Validation loss: 2.50450980822573

Epoch: 5| Step: 10
Training loss: 2.142934736481855
Validation loss: 2.5135333400262856

Epoch: 403| Step: 0
Training loss: 2.2577235854437636
Validation loss: 2.531718256480355

Epoch: 5| Step: 1
Training loss: 2.457048813312873
Validation loss: 2.545276767731675

Epoch: 5| Step: 2
Training loss: 2.6596284810526756
Validation loss: 2.560499799758138

Epoch: 5| Step: 3
Training loss: 2.9226618232663717
Validation loss: 2.598419788303611

Epoch: 5| Step: 4
Training loss: 2.602182675234959
Validation loss: 2.5732991017085896

Epoch: 5| Step: 5
Training loss: 2.359469885528644
Validation loss: 2.5725321624185784

Epoch: 5| Step: 6
Training loss: 2.9905271380605396
Validation loss: 2.5560815103699674

Epoch: 5| Step: 7
Training loss: 2.590147895272539
Validation loss: 2.571326031937929

Epoch: 5| Step: 8
Training loss: 3.1201931414366264
Validation loss: 2.548488935753001

Epoch: 5| Step: 9
Training loss: 2.217291446585302
Validation loss: 2.553000495318796

Epoch: 5| Step: 10
Training loss: 2.671333213441848
Validation loss: 2.540304556966773

Epoch: 404| Step: 0
Training loss: 2.8842417577715205
Validation loss: 2.5259474423520225

Epoch: 5| Step: 1
Training loss: 2.640313214737548
Validation loss: 2.5068559641691888

Epoch: 5| Step: 2
Training loss: 2.2973767206202282
Validation loss: 2.5018470401419983

Epoch: 5| Step: 3
Training loss: 2.7147184274412894
Validation loss: 2.4934026205561888

Epoch: 5| Step: 4
Training loss: 2.4732098434274565
Validation loss: 2.4952905848672406

Epoch: 5| Step: 5
Training loss: 2.7966095356188636
Validation loss: 2.495210292406659

Epoch: 5| Step: 6
Training loss: 2.420178021905588
Validation loss: 2.5238646449224738

Epoch: 5| Step: 7
Training loss: 2.6504512546607075
Validation loss: 2.5313057801544407

Epoch: 5| Step: 8
Training loss: 2.6144434877563114
Validation loss: 2.5340352121413003

Epoch: 5| Step: 9
Training loss: 2.7363622800777003
Validation loss: 2.502314332086164

Epoch: 5| Step: 10
Training loss: 2.6088916993419375
Validation loss: 2.506243413994718

Epoch: 405| Step: 0
Training loss: 2.4102966168796636
Validation loss: 2.4916096028640395

Epoch: 5| Step: 1
Training loss: 2.792534897192616
Validation loss: 2.4835663594743584

Epoch: 5| Step: 2
Training loss: 2.526037807396107
Validation loss: 2.504962862981622

Epoch: 5| Step: 3
Training loss: 2.348063454246596
Validation loss: 2.513887122421839

Epoch: 5| Step: 4
Training loss: 2.4642272274903614
Validation loss: 2.501441369318837

Epoch: 5| Step: 5
Training loss: 2.3773851965814887
Validation loss: 2.5321587567320343

Epoch: 5| Step: 6
Training loss: 3.103518236950207
Validation loss: 2.5351531778639256

Epoch: 5| Step: 7
Training loss: 2.8017426653585846
Validation loss: 2.5793961211394354

Epoch: 5| Step: 8
Training loss: 2.4727779316302776
Validation loss: 2.5622834525062097

Epoch: 5| Step: 9
Training loss: 2.0682355719410883
Validation loss: 2.596601555242905

Epoch: 5| Step: 10
Training loss: 3.063211475172091
Validation loss: 2.5797993820833782

Epoch: 406| Step: 0
Training loss: 2.730064001905137
Validation loss: 2.583313812542008

Epoch: 5| Step: 1
Training loss: 2.7593078881609934
Validation loss: 2.540998372684329

Epoch: 5| Step: 2
Training loss: 2.849469480159311
Validation loss: 2.551655385691651

Epoch: 5| Step: 3
Training loss: 2.223399488884175
Validation loss: 2.495915160292157

Epoch: 5| Step: 4
Training loss: 2.3596312528991055
Validation loss: 2.482005990623857

Epoch: 5| Step: 5
Training loss: 2.8305313242419077
Validation loss: 2.47774155225606

Epoch: 5| Step: 6
Training loss: 2.9532499741041054
Validation loss: 2.494799086249094

Epoch: 5| Step: 7
Training loss: 2.402535283586777
Validation loss: 2.497339971583281

Epoch: 5| Step: 8
Training loss: 2.3383046279997814
Validation loss: 2.499672893946205

Epoch: 5| Step: 9
Training loss: 2.4116493187917296
Validation loss: 2.5281848972524696

Epoch: 5| Step: 10
Training loss: 2.7441922328888264
Validation loss: 2.5308626841519746

Epoch: 407| Step: 0
Training loss: 2.6761953659930904
Validation loss: 2.5654601140860653

Epoch: 5| Step: 1
Training loss: 2.5938193989856817
Validation loss: 2.5797584219299203

Epoch: 5| Step: 2
Training loss: 2.81888178413701
Validation loss: 2.568784686874009

Epoch: 5| Step: 3
Training loss: 2.45994213501399
Validation loss: 2.5574881991881986

Epoch: 5| Step: 4
Training loss: 2.417013691507875
Validation loss: 2.5226290803606983

Epoch: 5| Step: 5
Training loss: 2.6230999564156257
Validation loss: 2.545759389418505

Epoch: 5| Step: 6
Training loss: 2.720450560053394
Validation loss: 2.5200106791129855

Epoch: 5| Step: 7
Training loss: 2.426920894922701
Validation loss: 2.4956665567046192

Epoch: 5| Step: 8
Training loss: 2.578747668355386
Validation loss: 2.4789555508765075

Epoch: 5| Step: 9
Training loss: 3.035074868700633
Validation loss: 2.502783888612473

Epoch: 5| Step: 10
Training loss: 2.3419633286013313
Validation loss: 2.4769242436779133

Epoch: 408| Step: 0
Training loss: 2.330815239423402
Validation loss: 2.4948595111288117

Epoch: 5| Step: 1
Training loss: 2.495414342933839
Validation loss: 2.5050585278169555

Epoch: 5| Step: 2
Training loss: 2.645680660939254
Validation loss: 2.5327816057461447

Epoch: 5| Step: 3
Training loss: 2.479782754550411
Validation loss: 2.5711340044147812

Epoch: 5| Step: 4
Training loss: 3.026642118794158
Validation loss: 2.5906844770268656

Epoch: 5| Step: 5
Training loss: 2.2555010622496017
Validation loss: 2.6022415435270485

Epoch: 5| Step: 6
Training loss: 3.1745304210969874
Validation loss: 2.595507531749832

Epoch: 5| Step: 7
Training loss: 2.5186135683428343
Validation loss: 2.5330779902501486

Epoch: 5| Step: 8
Training loss: 2.7437254676504166
Validation loss: 2.495276292267791

Epoch: 5| Step: 9
Training loss: 2.437030747067443
Validation loss: 2.487051263936829

Epoch: 5| Step: 10
Training loss: 2.6435628946527108
Validation loss: 2.4679513711437573

Epoch: 409| Step: 0
Training loss: 2.647250829539636
Validation loss: 2.481697994526357

Epoch: 5| Step: 1
Training loss: 2.7978145789985853
Validation loss: 2.4666194307476705

Epoch: 5| Step: 2
Training loss: 2.459988850203887
Validation loss: 2.491260895459063

Epoch: 5| Step: 3
Training loss: 2.7236511076664582
Validation loss: 2.4726795373700754

Epoch: 5| Step: 4
Training loss: 2.5450370100886444
Validation loss: 2.4956416409506117

Epoch: 5| Step: 5
Training loss: 2.7682329371017853
Validation loss: 2.5306432106338748

Epoch: 5| Step: 6
Training loss: 2.2929078180122846
Validation loss: 2.5696866433947334

Epoch: 5| Step: 7
Training loss: 2.59075589464771
Validation loss: 2.590143745179869

Epoch: 5| Step: 8
Training loss: 2.639372669736541
Validation loss: 2.64947714899696

Epoch: 5| Step: 9
Training loss: 2.8289582937489546
Validation loss: 2.658133553279579

Epoch: 5| Step: 10
Training loss: 2.5538373459990233
Validation loss: 2.6215180832548843

Epoch: 410| Step: 0
Training loss: 2.49941008283485
Validation loss: 2.5505527104442125

Epoch: 5| Step: 1
Training loss: 2.1236664570704673
Validation loss: 2.5124373165566563

Epoch: 5| Step: 2
Training loss: 2.7589559372926056
Validation loss: 2.4855257014837586

Epoch: 5| Step: 3
Training loss: 2.3772245328948975
Validation loss: 2.4696237521789475

Epoch: 5| Step: 4
Training loss: 2.965694099481472
Validation loss: 2.467317894002764

Epoch: 5| Step: 5
Training loss: 2.387177518465937
Validation loss: 2.4726156290275174

Epoch: 5| Step: 6
Training loss: 2.8797756833562915
Validation loss: 2.4667580012141084

Epoch: 5| Step: 7
Training loss: 2.1973847623951404
Validation loss: 2.4680292716379983

Epoch: 5| Step: 8
Training loss: 2.378396366391709
Validation loss: 2.4653972108819704

Epoch: 5| Step: 9
Training loss: 2.8241701240627197
Validation loss: 2.499247987504349

Epoch: 5| Step: 10
Training loss: 3.1954666510894927
Validation loss: 2.522810730350633

Epoch: 411| Step: 0
Training loss: 2.3717527777702894
Validation loss: 2.556889593718755

Epoch: 5| Step: 1
Training loss: 2.7162983681751847
Validation loss: 2.5757484119406473

Epoch: 5| Step: 2
Training loss: 2.8460786109624294
Validation loss: 2.560506111483157

Epoch: 5| Step: 3
Training loss: 3.005758163602242
Validation loss: 2.563535202582306

Epoch: 5| Step: 4
Training loss: 2.111139986052666
Validation loss: 2.51288157213282

Epoch: 5| Step: 5
Training loss: 2.8898807701674634
Validation loss: 2.511189284972551

Epoch: 5| Step: 6
Training loss: 2.1107329342179426
Validation loss: 2.520707756731041

Epoch: 5| Step: 7
Training loss: 2.633289327937845
Validation loss: 2.5042384765537946

Epoch: 5| Step: 8
Training loss: 2.866908254719534
Validation loss: 2.4859823015699205

Epoch: 5| Step: 9
Training loss: 2.210419287456813
Validation loss: 2.473604417408814

Epoch: 5| Step: 10
Training loss: 2.7176041216235367
Validation loss: 2.4705813847628915

Epoch: 412| Step: 0
Training loss: 2.4297330306224296
Validation loss: 2.460280043022884

Epoch: 5| Step: 1
Training loss: 2.2396333082670625
Validation loss: 2.5004273900416014

Epoch: 5| Step: 2
Training loss: 2.7072139970050086
Validation loss: 2.5241371636840695

Epoch: 5| Step: 3
Training loss: 3.041450562486238
Validation loss: 2.550730665767202

Epoch: 5| Step: 4
Training loss: 2.787455119639839
Validation loss: 2.564528128132243

Epoch: 5| Step: 5
Training loss: 2.7674831893672227
Validation loss: 2.5731475641446977

Epoch: 5| Step: 6
Training loss: 2.3928477606355596
Validation loss: 2.573842014806548

Epoch: 5| Step: 7
Training loss: 2.5283222927823936
Validation loss: 2.5885371716567738

Epoch: 5| Step: 8
Training loss: 2.684073281790019
Validation loss: 2.5734240758248763

Epoch: 5| Step: 9
Training loss: 2.2467431763243675
Validation loss: 2.578228588639628

Epoch: 5| Step: 10
Training loss: 2.39346005748016
Validation loss: 2.5666681211227984

Epoch: 413| Step: 0
Training loss: 2.473229509044144
Validation loss: 2.52370095396066

Epoch: 5| Step: 1
Training loss: 2.430936339084217
Validation loss: 2.488819375980388

Epoch: 5| Step: 2
Training loss: 2.37396659453493
Validation loss: 2.4833651823963745

Epoch: 5| Step: 3
Training loss: 2.7256098178649752
Validation loss: 2.4671803920023923

Epoch: 5| Step: 4
Training loss: 3.261677523597993
Validation loss: 2.463236616993673

Epoch: 5| Step: 5
Training loss: 2.4553680855643436
Validation loss: 2.507702587081617

Epoch: 5| Step: 6
Training loss: 2.416453242469378
Validation loss: 2.510219382576682

Epoch: 5| Step: 7
Training loss: 2.735837795808956
Validation loss: 2.563866772776616

Epoch: 5| Step: 8
Training loss: 2.9684631209046373
Validation loss: 2.6100771232431126

Epoch: 5| Step: 9
Training loss: 2.194367228999186
Validation loss: 2.5961077150188574

Epoch: 5| Step: 10
Training loss: 2.59417904901618
Validation loss: 2.590672627005339

Epoch: 414| Step: 0
Training loss: 2.666077330158167
Validation loss: 2.549473064283367

Epoch: 5| Step: 1
Training loss: 2.661372910613645
Validation loss: 2.517415850172326

Epoch: 5| Step: 2
Training loss: 2.435672074612592
Validation loss: 2.507880475391849

Epoch: 5| Step: 3
Training loss: 2.5788138654144106
Validation loss: 2.5014835949530005

Epoch: 5| Step: 4
Training loss: 2.7355335505998677
Validation loss: 2.494613758948623

Epoch: 5| Step: 5
Training loss: 2.5339095660769737
Validation loss: 2.4837507104748004

Epoch: 5| Step: 6
Training loss: 2.5426781835543584
Validation loss: 2.4924397132157026

Epoch: 5| Step: 7
Training loss: 2.540015408626887
Validation loss: 2.4870456120800375

Epoch: 5| Step: 8
Training loss: 2.0680111167726976
Validation loss: 2.480849092181951

Epoch: 5| Step: 9
Training loss: 3.086482287256141
Validation loss: 2.503855864491891

Epoch: 5| Step: 10
Training loss: 2.4372255219683883
Validation loss: 2.502345637776209

Epoch: 415| Step: 0
Training loss: 2.9053317024094496
Validation loss: 2.476712096933258

Epoch: 5| Step: 1
Training loss: 2.2672630965224436
Validation loss: 2.478349771513873

Epoch: 5| Step: 2
Training loss: 2.4605759127959934
Validation loss: 2.490731938756798

Epoch: 5| Step: 3
Training loss: 2.1864798210533603
Validation loss: 2.505700901302539

Epoch: 5| Step: 4
Training loss: 2.1962564957011894
Validation loss: 2.5135117611687923

Epoch: 5| Step: 5
Training loss: 2.7027898150658753
Validation loss: 2.5364602499882576

Epoch: 5| Step: 6
Training loss: 2.371117681291402
Validation loss: 2.541025368975417

Epoch: 5| Step: 7
Training loss: 2.4525795105344015
Validation loss: 2.5165921212494133

Epoch: 5| Step: 8
Training loss: 2.7976077521114484
Validation loss: 2.535804173140388

Epoch: 5| Step: 9
Training loss: 2.7441211631872147
Validation loss: 2.5252537552229892

Epoch: 5| Step: 10
Training loss: 3.1382254928182607
Validation loss: 2.5237775938089313

Epoch: 416| Step: 0
Training loss: 1.8927553643062558
Validation loss: 2.5074440631130415

Epoch: 5| Step: 1
Training loss: 2.2494330221643883
Validation loss: 2.4990042826250667

Epoch: 5| Step: 2
Training loss: 2.799528855466854
Validation loss: 2.528447947806419

Epoch: 5| Step: 3
Training loss: 2.737502396813306
Validation loss: 2.48435749365872

Epoch: 5| Step: 4
Training loss: 1.6910906843101066
Validation loss: 2.5151316472933485

Epoch: 5| Step: 5
Training loss: 3.0296190731196635
Validation loss: 2.5083031616328677

Epoch: 5| Step: 6
Training loss: 2.2901288045448993
Validation loss: 2.4958741916682117

Epoch: 5| Step: 7
Training loss: 2.850046920390135
Validation loss: 2.5005045402195565

Epoch: 5| Step: 8
Training loss: 2.843249769544378
Validation loss: 2.5061552986708415

Epoch: 5| Step: 9
Training loss: 2.9198639012325884
Validation loss: 2.512774276476246

Epoch: 5| Step: 10
Training loss: 2.643397393847417
Validation loss: 2.529596628112291

Epoch: 417| Step: 0
Training loss: 2.8926440636474924
Validation loss: 2.5264307904511147

Epoch: 5| Step: 1
Training loss: 2.238585339938648
Validation loss: 2.5434436171050203

Epoch: 5| Step: 2
Training loss: 2.2177337683250418
Validation loss: 2.5482242245832256

Epoch: 5| Step: 3
Training loss: 2.7206138273045215
Validation loss: 2.4996148910056353

Epoch: 5| Step: 4
Training loss: 2.7076061348440827
Validation loss: 2.5074262148050717

Epoch: 5| Step: 5
Training loss: 2.5237463416667723
Validation loss: 2.5042830540726455

Epoch: 5| Step: 6
Training loss: 2.330401235913919
Validation loss: 2.502374457679557

Epoch: 5| Step: 7
Training loss: 2.5278173648496445
Validation loss: 2.5296134626116817

Epoch: 5| Step: 8
Training loss: 2.6945445860336115
Validation loss: 2.5359167803765055

Epoch: 5| Step: 9
Training loss: 2.57158529659286
Validation loss: 2.553978492855046

Epoch: 5| Step: 10
Training loss: 2.7476824618454025
Validation loss: 2.5314553725791455

Epoch: 418| Step: 0
Training loss: 2.9444842805706797
Validation loss: 2.5231404250437373

Epoch: 5| Step: 1
Training loss: 2.627499071986709
Validation loss: 2.5379378743114867

Epoch: 5| Step: 2
Training loss: 2.3443758319720036
Validation loss: 2.5160926175828315

Epoch: 5| Step: 3
Training loss: 2.6950280080836766
Validation loss: 2.5155392128159897

Epoch: 5| Step: 4
Training loss: 2.48844767781952
Validation loss: 2.4795391278306615

Epoch: 5| Step: 5
Training loss: 2.3402954073228397
Validation loss: 2.479490365700971

Epoch: 5| Step: 6
Training loss: 2.813853044355855
Validation loss: 2.463153775187085

Epoch: 5| Step: 7
Training loss: 2.112391370880873
Validation loss: 2.4757399415308337

Epoch: 5| Step: 8
Training loss: 2.7706641716815827
Validation loss: 2.506736008851014

Epoch: 5| Step: 9
Training loss: 2.4577777256236533
Validation loss: 2.5370120751923952

Epoch: 5| Step: 10
Training loss: 2.5766648290149736
Validation loss: 2.57376783491403

Epoch: 419| Step: 0
Training loss: 3.2481568318448315
Validation loss: 2.590555779427285

Epoch: 5| Step: 1
Training loss: 2.2419957733590867
Validation loss: 2.5678567678502286

Epoch: 5| Step: 2
Training loss: 2.0258706093354144
Validation loss: 2.5469296639069134

Epoch: 5| Step: 3
Training loss: 2.96822778224606
Validation loss: 2.497524302097062

Epoch: 5| Step: 4
Training loss: 2.554971008434904
Validation loss: 2.488456551061109

Epoch: 5| Step: 5
Training loss: 2.636671458632611
Validation loss: 2.489693661400419

Epoch: 5| Step: 6
Training loss: 2.2897690863981586
Validation loss: 2.4883372206724497

Epoch: 5| Step: 7
Training loss: 2.5135461024405816
Validation loss: 2.5089880830113125

Epoch: 5| Step: 8
Training loss: 2.5002210519337513
Validation loss: 2.516930818728706

Epoch: 5| Step: 9
Training loss: 2.3882532259738523
Validation loss: 2.5059584644372577

Epoch: 5| Step: 10
Training loss: 2.625377537053795
Validation loss: 2.525087235924751

Epoch: 420| Step: 0
Training loss: 2.2495182369295894
Validation loss: 2.5567273854309076

Epoch: 5| Step: 1
Training loss: 1.8748289030211898
Validation loss: 2.577914265969133

Epoch: 5| Step: 2
Training loss: 2.617463145757161
Validation loss: 2.5586506293439624

Epoch: 5| Step: 3
Training loss: 3.251560276806139
Validation loss: 2.538493489636775

Epoch: 5| Step: 4
Training loss: 2.166007039334314
Validation loss: 2.5271459194150285

Epoch: 5| Step: 5
Training loss: 2.542737537191842
Validation loss: 2.513680496020646

Epoch: 5| Step: 6
Training loss: 2.3376081227474095
Validation loss: 2.5017551188372025

Epoch: 5| Step: 7
Training loss: 2.568500192937385
Validation loss: 2.476286534540555

Epoch: 5| Step: 8
Training loss: 2.8437783376099257
Validation loss: 2.4897952506812486

Epoch: 5| Step: 9
Training loss: 2.9962137489210665
Validation loss: 2.4771419670309207

Epoch: 5| Step: 10
Training loss: 2.3785034239517597
Validation loss: 2.496534266905963

Epoch: 421| Step: 0
Training loss: 2.945661367300747
Validation loss: 2.4900316523041566

Epoch: 5| Step: 1
Training loss: 2.4518470107947725
Validation loss: 2.5086085662540687

Epoch: 5| Step: 2
Training loss: 2.1221782799055506
Validation loss: 2.5110732513316956

Epoch: 5| Step: 3
Training loss: 2.6253216864251807
Validation loss: 2.5394898413899276

Epoch: 5| Step: 4
Training loss: 2.346234644909193
Validation loss: 2.5524181662811745

Epoch: 5| Step: 5
Training loss: 2.2430994392356562
Validation loss: 2.53205024742562

Epoch: 5| Step: 6
Training loss: 2.5479194980043123
Validation loss: 2.546463320654766

Epoch: 5| Step: 7
Training loss: 2.616863629243763
Validation loss: 2.532514127101084

Epoch: 5| Step: 8
Training loss: 2.90153826989496
Validation loss: 2.5747780302872982

Epoch: 5| Step: 9
Training loss: 2.460171341085075
Validation loss: 2.573080583658138

Epoch: 5| Step: 10
Training loss: 2.8333933954791597
Validation loss: 2.553398191069053

Epoch: 422| Step: 0
Training loss: 2.200091065342701
Validation loss: 2.503276595338964

Epoch: 5| Step: 1
Training loss: 2.5657714801934755
Validation loss: 2.478688429090201

Epoch: 5| Step: 2
Training loss: 2.509600420906389
Validation loss: 2.493914990134619

Epoch: 5| Step: 3
Training loss: 2.706485841971646
Validation loss: 2.458070700479031

Epoch: 5| Step: 4
Training loss: 2.7079211777297663
Validation loss: 2.485847408821947

Epoch: 5| Step: 5
Training loss: 3.1206193355705243
Validation loss: 2.458082049294658

Epoch: 5| Step: 6
Training loss: 2.4776614666008374
Validation loss: 2.47528365295399

Epoch: 5| Step: 7
Training loss: 2.703248037724377
Validation loss: 2.4577687280628204

Epoch: 5| Step: 8
Training loss: 2.0934537991203706
Validation loss: 2.4568687033184338

Epoch: 5| Step: 9
Training loss: 2.5869453978377748
Validation loss: 2.481301156525036

Epoch: 5| Step: 10
Training loss: 2.3434563007712064
Validation loss: 2.5003296050322796

Epoch: 423| Step: 0
Training loss: 2.3435958811632442
Validation loss: 2.4858961205067165

Epoch: 5| Step: 1
Training loss: 1.9415703134273612
Validation loss: 2.5321935669704763

Epoch: 5| Step: 2
Training loss: 2.5975361043350245
Validation loss: 2.550388131953639

Epoch: 5| Step: 3
Training loss: 2.9470353892945353
Validation loss: 2.557849718301268

Epoch: 5| Step: 4
Training loss: 2.749996358695654
Validation loss: 2.5088456353057347

Epoch: 5| Step: 5
Training loss: 2.085864005062057
Validation loss: 2.5116197347130447

Epoch: 5| Step: 6
Training loss: 2.5271464864875286
Validation loss: 2.534609912476856

Epoch: 5| Step: 7
Training loss: 3.0422332619162633
Validation loss: 2.5035357565047183

Epoch: 5| Step: 8
Training loss: 2.1544562356062325
Validation loss: 2.4855446270828394

Epoch: 5| Step: 9
Training loss: 2.7616756711025316
Validation loss: 2.458279736495818

Epoch: 5| Step: 10
Training loss: 2.833797098987502
Validation loss: 2.472770411069207

Epoch: 424| Step: 0
Training loss: 2.108444121494415
Validation loss: 2.46790221281127

Epoch: 5| Step: 1
Training loss: 2.582377492799963
Validation loss: 2.4857790124331034

Epoch: 5| Step: 2
Training loss: 2.5554405292479316
Validation loss: 2.4933811934108236

Epoch: 5| Step: 3
Training loss: 2.6510578347383222
Validation loss: 2.5250813163968893

Epoch: 5| Step: 4
Training loss: 2.3711192901090503
Validation loss: 2.5581742448221476

Epoch: 5| Step: 5
Training loss: 2.897458139796846
Validation loss: 2.5852074277348325

Epoch: 5| Step: 6
Training loss: 2.2598776694754195
Validation loss: 2.5731261753729577

Epoch: 5| Step: 7
Training loss: 2.6367699286121087
Validation loss: 2.5139121367622717

Epoch: 5| Step: 8
Training loss: 2.542360106964131
Validation loss: 2.487137413219576

Epoch: 5| Step: 9
Training loss: 2.745415333801431
Validation loss: 2.484363461204062

Epoch: 5| Step: 10
Training loss: 2.6463022091940394
Validation loss: 2.5101036615655308

Epoch: 425| Step: 0
Training loss: 2.518997774644863
Validation loss: 2.5054669522463193

Epoch: 5| Step: 1
Training loss: 2.5671674508201714
Validation loss: 2.4973222584258625

Epoch: 5| Step: 2
Training loss: 2.5431712548977665
Validation loss: 2.4866776952664194

Epoch: 5| Step: 3
Training loss: 2.4962170589835138
Validation loss: 2.495385572092603

Epoch: 5| Step: 4
Training loss: 2.3409559762001773
Validation loss: 2.50014808585361

Epoch: 5| Step: 5
Training loss: 3.2285800195861794
Validation loss: 2.5085208620628645

Epoch: 5| Step: 6
Training loss: 2.68529730729589
Validation loss: 2.5297316587023415

Epoch: 5| Step: 7
Training loss: 2.5329350643637123
Validation loss: 2.5403001024144025

Epoch: 5| Step: 8
Training loss: 2.1403213619762194
Validation loss: 2.507140047886972

Epoch: 5| Step: 9
Training loss: 2.5781602336903493
Validation loss: 2.47267153129216

Epoch: 5| Step: 10
Training loss: 2.267581279269447
Validation loss: 2.4603169742460285

Epoch: 426| Step: 0
Training loss: 2.567252148901393
Validation loss: 2.476926592113825

Epoch: 5| Step: 1
Training loss: 2.3415868313394643
Validation loss: 2.4444045296710626

Epoch: 5| Step: 2
Training loss: 2.791607547722367
Validation loss: 2.474524980728825

Epoch: 5| Step: 3
Training loss: 2.7002577376091015
Validation loss: 2.4839919043783167

Epoch: 5| Step: 4
Training loss: 2.8023796255784
Validation loss: 2.4888480867594702

Epoch: 5| Step: 5
Training loss: 1.7206118816037768
Validation loss: 2.5271565263887

Epoch: 5| Step: 6
Training loss: 2.552548133926799
Validation loss: 2.580377150277617

Epoch: 5| Step: 7
Training loss: 2.3513738106593842
Validation loss: 2.600257138819616

Epoch: 5| Step: 8
Training loss: 2.907476023003598
Validation loss: 2.5914653476987946

Epoch: 5| Step: 9
Training loss: 2.5971836205082757
Validation loss: 2.5321880239709103

Epoch: 5| Step: 10
Training loss: 2.6460898467745513
Validation loss: 2.486753553480118

Epoch: 427| Step: 0
Training loss: 2.2374556851394054
Validation loss: 2.4672838257419674

Epoch: 5| Step: 1
Training loss: 1.9186619517847432
Validation loss: 2.4562921206432775

Epoch: 5| Step: 2
Training loss: 2.719394212890312
Validation loss: 2.4585810648251116

Epoch: 5| Step: 3
Training loss: 2.8559314441627137
Validation loss: 2.440479407612608

Epoch: 5| Step: 4
Training loss: 2.615630913913472
Validation loss: 2.4529246492792356

Epoch: 5| Step: 5
Training loss: 3.066298950650563
Validation loss: 2.459643429044387

Epoch: 5| Step: 6
Training loss: 2.7541415499543698
Validation loss: 2.466312961056922

Epoch: 5| Step: 7
Training loss: 2.7181481758580435
Validation loss: 2.4729828430848237

Epoch: 5| Step: 8
Training loss: 2.5561631166947056
Validation loss: 2.4952970723231895

Epoch: 5| Step: 9
Training loss: 2.4270101926422165
Validation loss: 2.531351531805628

Epoch: 5| Step: 10
Training loss: 2.2920073747233305
Validation loss: 2.555453129520421

Epoch: 428| Step: 0
Training loss: 2.371412881054077
Validation loss: 2.6102614674968474

Epoch: 5| Step: 1
Training loss: 2.6281111309760576
Validation loss: 2.634790045371164

Epoch: 5| Step: 2
Training loss: 2.7502356341586434
Validation loss: 2.648555706393162

Epoch: 5| Step: 3
Training loss: 2.881131806504207
Validation loss: 2.559725286870498

Epoch: 5| Step: 4
Training loss: 2.4336703611411257
Validation loss: 2.487173780985122

Epoch: 5| Step: 5
Training loss: 2.68926234458593
Validation loss: 2.4645547367967673

Epoch: 5| Step: 6
Training loss: 2.618263683821318
Validation loss: 2.435203513766915

Epoch: 5| Step: 7
Training loss: 2.3435416574065844
Validation loss: 2.4292900056529176

Epoch: 5| Step: 8
Training loss: 2.5042221655595935
Validation loss: 2.4217722680105433

Epoch: 5| Step: 9
Training loss: 3.0075507508369435
Validation loss: 2.4454601612423112

Epoch: 5| Step: 10
Training loss: 2.6168079613443505
Validation loss: 2.4376556161701726

Epoch: 429| Step: 0
Training loss: 2.3609881412671996
Validation loss: 2.450176743734267

Epoch: 5| Step: 1
Training loss: 2.331167907905789
Validation loss: 2.458444176398506

Epoch: 5| Step: 2
Training loss: 3.1319737250929887
Validation loss: 2.475809341126485

Epoch: 5| Step: 3
Training loss: 2.220060579315366
Validation loss: 2.4878232262679476

Epoch: 5| Step: 4
Training loss: 2.458167948790161
Validation loss: 2.527499871669269

Epoch: 5| Step: 5
Training loss: 2.02022128979808
Validation loss: 2.536423170594723

Epoch: 5| Step: 6
Training loss: 2.7335180193061355
Validation loss: 2.5481136135393108

Epoch: 5| Step: 7
Training loss: 2.7350004516266444
Validation loss: 2.5611021259379125

Epoch: 5| Step: 8
Training loss: 2.650594817288567
Validation loss: 2.556133359728142

Epoch: 5| Step: 9
Training loss: 2.7971713798807665
Validation loss: 2.568700565287311

Epoch: 5| Step: 10
Training loss: 2.408598212313161
Validation loss: 2.5445209089368253

Epoch: 430| Step: 0
Training loss: 2.4067182209202778
Validation loss: 2.505917587373334

Epoch: 5| Step: 1
Training loss: 2.6873766848639025
Validation loss: 2.481003479394091

Epoch: 5| Step: 2
Training loss: 2.56896362158951
Validation loss: 2.47767516290994

Epoch: 5| Step: 3
Training loss: 2.271575269905918
Validation loss: 2.4656369660290918

Epoch: 5| Step: 4
Training loss: 2.829651310066323
Validation loss: 2.4666715122475735

Epoch: 5| Step: 5
Training loss: 2.604205464391979
Validation loss: 2.4649291299266354

Epoch: 5| Step: 6
Training loss: 2.8933343510545386
Validation loss: 2.4716922532169527

Epoch: 5| Step: 7
Training loss: 2.1483194214711
Validation loss: 2.466554416451544

Epoch: 5| Step: 8
Training loss: 2.7709408120173937
Validation loss: 2.4738661927107226

Epoch: 5| Step: 9
Training loss: 2.8050273381225264
Validation loss: 2.4751984189088865

Epoch: 5| Step: 10
Training loss: 1.8301728996562343
Validation loss: 2.467721754288221

Epoch: 431| Step: 0
Training loss: 2.9041960646802916
Validation loss: 2.5098860795268787

Epoch: 5| Step: 1
Training loss: 2.8448943466118015
Validation loss: 2.5383992060609133

Epoch: 5| Step: 2
Training loss: 2.2158078310578393
Validation loss: 2.5596668058877428

Epoch: 5| Step: 3
Training loss: 2.341107111784956
Validation loss: 2.57699219199499

Epoch: 5| Step: 4
Training loss: 2.3593097197741546
Validation loss: 2.594001752859838

Epoch: 5| Step: 5
Training loss: 3.173650085150547
Validation loss: 2.6138162615691565

Epoch: 5| Step: 6
Training loss: 2.626787757631937
Validation loss: 2.6312918714473685

Epoch: 5| Step: 7
Training loss: 2.667006848412651
Validation loss: 2.578128534030574

Epoch: 5| Step: 8
Training loss: 2.444884046367661
Validation loss: 2.487074897898083

Epoch: 5| Step: 9
Training loss: 2.0281611505469406
Validation loss: 2.4503012565078426

Epoch: 5| Step: 10
Training loss: 2.203426692137061
Validation loss: 2.447598539865007

Epoch: 432| Step: 0
Training loss: 2.7211337984408877
Validation loss: 2.4439783766796803

Epoch: 5| Step: 1
Training loss: 2.335546148172136
Validation loss: 2.4286796395323123

Epoch: 5| Step: 2
Training loss: 2.672817844656252
Validation loss: 2.4319976490509436

Epoch: 5| Step: 3
Training loss: 2.8238975162821682
Validation loss: 2.4392099107115093

Epoch: 5| Step: 4
Training loss: 2.2870733061177013
Validation loss: 2.46933029227146

Epoch: 5| Step: 5
Training loss: 2.76763119104912
Validation loss: 2.491117849834684

Epoch: 5| Step: 6
Training loss: 2.5701464567497054
Validation loss: 2.500731058801694

Epoch: 5| Step: 7
Training loss: 2.0383832830680806
Validation loss: 2.49286789654897

Epoch: 5| Step: 8
Training loss: 2.8998391600105453
Validation loss: 2.4906667978534904

Epoch: 5| Step: 9
Training loss: 2.520638061610667
Validation loss: 2.4809146143516427

Epoch: 5| Step: 10
Training loss: 2.614589209885598
Validation loss: 2.4766948179760218

Epoch: 433| Step: 0
Training loss: 2.6761680156438836
Validation loss: 2.4752215539322537

Epoch: 5| Step: 1
Training loss: 2.1628405705220377
Validation loss: 2.499891172111777

Epoch: 5| Step: 2
Training loss: 2.2802347510770753
Validation loss: 2.5340504389381073

Epoch: 5| Step: 3
Training loss: 3.0279069536594965
Validation loss: 2.56425239075951

Epoch: 5| Step: 4
Training loss: 2.518932182595462
Validation loss: 2.585145464257749

Epoch: 5| Step: 5
Training loss: 3.0076717195138305
Validation loss: 2.5757720462098015

Epoch: 5| Step: 6
Training loss: 2.7363763950618454
Validation loss: 2.5236994485063198

Epoch: 5| Step: 7
Training loss: 2.4054085387288575
Validation loss: 2.483734006891895

Epoch: 5| Step: 8
Training loss: 2.2182730578519623
Validation loss: 2.456956976238405

Epoch: 5| Step: 9
Training loss: 2.263986771332607
Validation loss: 2.447197616909294

Epoch: 5| Step: 10
Training loss: 2.739360776111909
Validation loss: 2.4338388369124324

Epoch: 434| Step: 0
Training loss: 2.940702275589494
Validation loss: 2.4187508037879852

Epoch: 5| Step: 1
Training loss: 2.9890092748279193
Validation loss: 2.4316153568358976

Epoch: 5| Step: 2
Training loss: 2.542576913486086
Validation loss: 2.430059599623851

Epoch: 5| Step: 3
Training loss: 2.3943207540916736
Validation loss: 2.4377676861782023

Epoch: 5| Step: 4
Training loss: 2.9540905862399387
Validation loss: 2.4831248578325784

Epoch: 5| Step: 5
Training loss: 2.1570844279652377
Validation loss: 2.484219252691801

Epoch: 5| Step: 6
Training loss: 2.2748489455493828
Validation loss: 2.496357303570679

Epoch: 5| Step: 7
Training loss: 2.4735507883718557
Validation loss: 2.513516284615296

Epoch: 5| Step: 8
Training loss: 2.319924061946477
Validation loss: 2.4971398019992708

Epoch: 5| Step: 9
Training loss: 2.7317029703958005
Validation loss: 2.5157114089375456

Epoch: 5| Step: 10
Training loss: 2.1058548553820216
Validation loss: 2.493607892325077

Epoch: 435| Step: 0
Training loss: 2.671910514372434
Validation loss: 2.5053792997528785

Epoch: 5| Step: 1
Training loss: 2.6353931853161754
Validation loss: 2.4567576976910024

Epoch: 5| Step: 2
Training loss: 2.323152185198387
Validation loss: 2.447676397893029

Epoch: 5| Step: 3
Training loss: 2.8261551714800963
Validation loss: 2.4609531301173617

Epoch: 5| Step: 4
Training loss: 2.064765956999446
Validation loss: 2.4492486063939154

Epoch: 5| Step: 5
Training loss: 2.4559987723505885
Validation loss: 2.462168030500578

Epoch: 5| Step: 6
Training loss: 2.6330481177604588
Validation loss: 2.493261800535226

Epoch: 5| Step: 7
Training loss: 2.5970641874034714
Validation loss: 2.522051424799806

Epoch: 5| Step: 8
Training loss: 2.174429070967358
Validation loss: 2.5249039738818433

Epoch: 5| Step: 9
Training loss: 2.674931167002146
Validation loss: 2.567363385783805

Epoch: 5| Step: 10
Training loss: 2.7866772622115406
Validation loss: 2.576856789601051

Epoch: 436| Step: 0
Training loss: 2.8494974262087367
Validation loss: 2.5748688481326565

Epoch: 5| Step: 1
Training loss: 2.345029456272853
Validation loss: 2.5570948951350716

Epoch: 5| Step: 2
Training loss: 3.0398809512569636
Validation loss: 2.4863767880860057

Epoch: 5| Step: 3
Training loss: 2.585781127258442
Validation loss: 2.4933647599816253

Epoch: 5| Step: 4
Training loss: 2.25868456409544
Validation loss: 2.4642911130628224

Epoch: 5| Step: 5
Training loss: 2.2673588925231183
Validation loss: 2.456671256332973

Epoch: 5| Step: 6
Training loss: 2.2279454269916656
Validation loss: 2.452080105860553

Epoch: 5| Step: 7
Training loss: 2.659007537234306
Validation loss: 2.4409899668200103

Epoch: 5| Step: 8
Training loss: 2.2510070666317064
Validation loss: 2.462855482680602

Epoch: 5| Step: 9
Training loss: 2.68278293493351
Validation loss: 2.5016679634507946

Epoch: 5| Step: 10
Training loss: 2.746443616303932
Validation loss: 2.5147766178737467

Epoch: 437| Step: 0
Training loss: 2.2994326928447677
Validation loss: 2.4898324633170237

Epoch: 5| Step: 1
Training loss: 2.943954518982735
Validation loss: 2.5068100804332683

Epoch: 5| Step: 2
Training loss: 2.2600724152972833
Validation loss: 2.504474020526283

Epoch: 5| Step: 3
Training loss: 1.9715170412964516
Validation loss: 2.5147127905039457

Epoch: 5| Step: 4
Training loss: 2.625496045428007
Validation loss: 2.49904295948207

Epoch: 5| Step: 5
Training loss: 2.8933231442648557
Validation loss: 2.5005668397450065

Epoch: 5| Step: 6
Training loss: 2.891112250424681
Validation loss: 2.4955154455901343

Epoch: 5| Step: 7
Training loss: 2.893559301696456
Validation loss: 2.483570667531146

Epoch: 5| Step: 8
Training loss: 2.4153099417182444
Validation loss: 2.4751314641849973

Epoch: 5| Step: 9
Training loss: 2.228090103539569
Validation loss: 2.468756113269361

Epoch: 5| Step: 10
Training loss: 1.8711229294192007
Validation loss: 2.4586793361614374

Epoch: 438| Step: 0
Training loss: 2.9079379850488793
Validation loss: 2.47813110011493

Epoch: 5| Step: 1
Training loss: 2.130454412173575
Validation loss: 2.4890942609108175

Epoch: 5| Step: 2
Training loss: 1.9641530698106826
Validation loss: 2.5292458327047846

Epoch: 5| Step: 3
Training loss: 2.835836613649737
Validation loss: 2.5472757203029093

Epoch: 5| Step: 4
Training loss: 2.8244629644855044
Validation loss: 2.5173889774924887

Epoch: 5| Step: 5
Training loss: 2.5539461979348355
Validation loss: 2.505000784669997

Epoch: 5| Step: 6
Training loss: 2.2527333716821394
Validation loss: 2.4847015612016774

Epoch: 5| Step: 7
Training loss: 2.482213933775855
Validation loss: 2.470892051014717

Epoch: 5| Step: 8
Training loss: 2.5030049384537434
Validation loss: 2.464244507520864

Epoch: 5| Step: 9
Training loss: 2.626762161971732
Validation loss: 2.4510953851961417

Epoch: 5| Step: 10
Training loss: 2.4589062254882004
Validation loss: 2.455506090329713

Epoch: 439| Step: 0
Training loss: 2.853161674339012
Validation loss: 2.4714994140301867

Epoch: 5| Step: 1
Training loss: 1.8219983067342382
Validation loss: 2.4692999031465117

Epoch: 5| Step: 2
Training loss: 2.449209404886478
Validation loss: 2.469697117676079

Epoch: 5| Step: 3
Training loss: 2.384757826883749
Validation loss: 2.4559888789275313

Epoch: 5| Step: 4
Training loss: 2.971335640308197
Validation loss: 2.4621093480944225

Epoch: 5| Step: 5
Training loss: 2.4119756375817403
Validation loss: 2.474144785428152

Epoch: 5| Step: 6
Training loss: 2.5656242863123246
Validation loss: 2.4904657836176733

Epoch: 5| Step: 7
Training loss: 2.9996159625611347
Validation loss: 2.5230885276471002

Epoch: 5| Step: 8
Training loss: 2.4092392622219645
Validation loss: 2.55196807045201

Epoch: 5| Step: 9
Training loss: 2.3308681226399663
Validation loss: 2.5466579795491233

Epoch: 5| Step: 10
Training loss: 2.1021301183670573
Validation loss: 2.5297743297522364

Epoch: 440| Step: 0
Training loss: 2.7962340574189475
Validation loss: 2.526898277141637

Epoch: 5| Step: 1
Training loss: 2.621048905604409
Validation loss: 2.5290031695566078

Epoch: 5| Step: 2
Training loss: 2.4736894856318736
Validation loss: 2.5033159046225353

Epoch: 5| Step: 3
Training loss: 2.175421036055446
Validation loss: 2.4902575854949576

Epoch: 5| Step: 4
Training loss: 2.67093253663105
Validation loss: 2.460782014303988

Epoch: 5| Step: 5
Training loss: 2.568010870782773
Validation loss: 2.4761594801092133

Epoch: 5| Step: 6
Training loss: 2.527528169439136
Validation loss: 2.487766020829343

Epoch: 5| Step: 7
Training loss: 2.086706127041449
Validation loss: 2.462903182472698

Epoch: 5| Step: 8
Training loss: 2.3479127664429282
Validation loss: 2.4815786697243936

Epoch: 5| Step: 9
Training loss: 2.7457078035764932
Validation loss: 2.480808723166129

Epoch: 5| Step: 10
Training loss: 2.518887885699778
Validation loss: 2.4980145856352873

Epoch: 441| Step: 0
Training loss: 2.256560826751972
Validation loss: 2.491420795973148

Epoch: 5| Step: 1
Training loss: 2.7078718721514075
Validation loss: 2.487046826359308

Epoch: 5| Step: 2
Training loss: 2.5986423542430983
Validation loss: 2.4694232949349844

Epoch: 5| Step: 3
Training loss: 2.958087767675593
Validation loss: 2.4649245277170775

Epoch: 5| Step: 4
Training loss: 2.272448557322852
Validation loss: 2.471701858712848

Epoch: 5| Step: 5
Training loss: 2.6907317668719157
Validation loss: 2.4484425936499075

Epoch: 5| Step: 6
Training loss: 2.4377008013055645
Validation loss: 2.4712429188647165

Epoch: 5| Step: 7
Training loss: 2.182142618289459
Validation loss: 2.474255619720944

Epoch: 5| Step: 8
Training loss: 2.6654532373863473
Validation loss: 2.4643474049405576

Epoch: 5| Step: 9
Training loss: 2.160100511932065
Validation loss: 2.479425517261993

Epoch: 5| Step: 10
Training loss: 2.6113155253412375
Validation loss: 2.4858310679076823

Epoch: 442| Step: 0
Training loss: 2.9834762737902794
Validation loss: 2.508890815586448

Epoch: 5| Step: 1
Training loss: 2.6359954520086437
Validation loss: 2.506409395779354

Epoch: 5| Step: 2
Training loss: 2.535614207420859
Validation loss: 2.4966493754253145

Epoch: 5| Step: 3
Training loss: 2.2987058440090795
Validation loss: 2.4794392927471067

Epoch: 5| Step: 4
Training loss: 2.3588691826059778
Validation loss: 2.5048237879978164

Epoch: 5| Step: 5
Training loss: 1.494428300277946
Validation loss: 2.5079868948467268

Epoch: 5| Step: 6
Training loss: 2.6514000990705955
Validation loss: 2.504288916809571

Epoch: 5| Step: 7
Training loss: 2.7308035060016884
Validation loss: 2.48967414539644

Epoch: 5| Step: 8
Training loss: 2.4942823831276613
Validation loss: 2.4843672462487363

Epoch: 5| Step: 9
Training loss: 2.755244196542398
Validation loss: 2.461620080278931

Epoch: 5| Step: 10
Training loss: 2.2130927374878984
Validation loss: 2.473974885653102

Epoch: 443| Step: 0
Training loss: 2.621367529770531
Validation loss: 2.469794475461977

Epoch: 5| Step: 1
Training loss: 2.444347934792521
Validation loss: 2.472791218520982

Epoch: 5| Step: 2
Training loss: 2.677411683920744
Validation loss: 2.499188800174009

Epoch: 5| Step: 3
Training loss: 2.5429831883830705
Validation loss: 2.53855095871568

Epoch: 5| Step: 4
Training loss: 2.621327146778328
Validation loss: 2.5454501810607097

Epoch: 5| Step: 5
Training loss: 1.5922651666897278
Validation loss: 2.5069496444775323

Epoch: 5| Step: 6
Training loss: 2.4023471242989514
Validation loss: 2.4937404767983193

Epoch: 5| Step: 7
Training loss: 2.6941188657063613
Validation loss: 2.482681253247077

Epoch: 5| Step: 8
Training loss: 2.8637991276843398
Validation loss: 2.476550345111031

Epoch: 5| Step: 9
Training loss: 2.770452822225898
Validation loss: 2.4737413229372986

Epoch: 5| Step: 10
Training loss: 2.166506932557189
Validation loss: 2.4605151554810223

Epoch: 444| Step: 0
Training loss: 2.4580229439343553
Validation loss: 2.4583984944790966

Epoch: 5| Step: 1
Training loss: 2.6095813052917554
Validation loss: 2.490016414747854

Epoch: 5| Step: 2
Training loss: 2.320003399024315
Validation loss: 2.472528598428851

Epoch: 5| Step: 3
Training loss: 2.6943309821221195
Validation loss: 2.489292634610608

Epoch: 5| Step: 4
Training loss: 2.813996489077332
Validation loss: 2.5005098479297687

Epoch: 5| Step: 5
Training loss: 2.572549791215651
Validation loss: 2.490825437099344

Epoch: 5| Step: 6
Training loss: 2.0129028391009447
Validation loss: 2.476362547497218

Epoch: 5| Step: 7
Training loss: 2.595348463090639
Validation loss: 2.4627622132558264

Epoch: 5| Step: 8
Training loss: 2.6814272379594235
Validation loss: 2.4882686557555047

Epoch: 5| Step: 9
Training loss: 2.2609574217534876
Validation loss: 2.4720781975737247

Epoch: 5| Step: 10
Training loss: 2.3636595368082993
Validation loss: 2.502112473361909

Epoch: 445| Step: 0
Training loss: 2.754056539560454
Validation loss: 2.4913244397286474

Epoch: 5| Step: 1
Training loss: 2.1757400481399607
Validation loss: 2.482101158305548

Epoch: 5| Step: 2
Training loss: 2.689601786043163
Validation loss: 2.462162094539791

Epoch: 5| Step: 3
Training loss: 2.44421381536721
Validation loss: 2.4520445346825204

Epoch: 5| Step: 4
Training loss: 2.8079045369258497
Validation loss: 2.4789957897777284

Epoch: 5| Step: 5
Training loss: 2.047508316488924
Validation loss: 2.45874841445373

Epoch: 5| Step: 6
Training loss: 2.766744527142486
Validation loss: 2.45992331675182

Epoch: 5| Step: 7
Training loss: 2.664192800607455
Validation loss: 2.475384079221698

Epoch: 5| Step: 8
Training loss: 2.2423793165719417
Validation loss: 2.485968466435837

Epoch: 5| Step: 9
Training loss: 2.4398038686814676
Validation loss: 2.4538768130690225

Epoch: 5| Step: 10
Training loss: 2.3291403585277766
Validation loss: 2.4472882206155564

Epoch: 446| Step: 0
Training loss: 2.333408377212654
Validation loss: 2.4674025368609183

Epoch: 5| Step: 1
Training loss: 2.8281012265381142
Validation loss: 2.4705981118974036

Epoch: 5| Step: 2
Training loss: 2.4114607830872803
Validation loss: 2.454910832191682

Epoch: 5| Step: 3
Training loss: 3.0574102340833393
Validation loss: 2.4686446358857896

Epoch: 5| Step: 4
Training loss: 2.3001137041928112
Validation loss: 2.47062383535287

Epoch: 5| Step: 5
Training loss: 2.354132986812425
Validation loss: 2.471781962178636

Epoch: 5| Step: 6
Training loss: 2.1230359818530915
Validation loss: 2.46459048212091

Epoch: 5| Step: 7
Training loss: 2.8096475335342888
Validation loss: 2.489525122435449

Epoch: 5| Step: 8
Training loss: 2.6027231004640523
Validation loss: 2.4809726628595166

Epoch: 5| Step: 9
Training loss: 2.051800458229758
Validation loss: 2.469906960695856

Epoch: 5| Step: 10
Training loss: 2.531768651502389
Validation loss: 2.472684369826989

Epoch: 447| Step: 0
Training loss: 2.205813019354764
Validation loss: 2.494960993847956

Epoch: 5| Step: 1
Training loss: 2.55538380317532
Validation loss: 2.491400907625079

Epoch: 5| Step: 2
Training loss: 2.1067957049498225
Validation loss: 2.488245360768461

Epoch: 5| Step: 3
Training loss: 2.59637492996428
Validation loss: 2.5315514682121134

Epoch: 5| Step: 4
Training loss: 2.230238065799066
Validation loss: 2.5080910528840774

Epoch: 5| Step: 5
Training loss: 2.375607463046335
Validation loss: 2.4738850531009273

Epoch: 5| Step: 6
Training loss: 2.379703983041907
Validation loss: 2.4494997995602557

Epoch: 5| Step: 7
Training loss: 2.617704425833645
Validation loss: 2.4514842323111257

Epoch: 5| Step: 8
Training loss: 2.6772155036410106
Validation loss: 2.4377095553357235

Epoch: 5| Step: 9
Training loss: 2.9630859954333095
Validation loss: 2.455954440569291

Epoch: 5| Step: 10
Training loss: 2.552027072416107
Validation loss: 2.449513326797011

Epoch: 448| Step: 0
Training loss: 2.3575905626525566
Validation loss: 2.450492180196268

Epoch: 5| Step: 1
Training loss: 2.3999756096554226
Validation loss: 2.473340216955639

Epoch: 5| Step: 2
Training loss: 2.1419341824461258
Validation loss: 2.4708836189413748

Epoch: 5| Step: 3
Training loss: 2.3672493400931356
Validation loss: 2.468968201217383

Epoch: 5| Step: 4
Training loss: 2.864056699489915
Validation loss: 2.48353464519555

Epoch: 5| Step: 5
Training loss: 2.5879071159557117
Validation loss: 2.5262205437131553

Epoch: 5| Step: 6
Training loss: 2.828754502519167
Validation loss: 2.534527039684043

Epoch: 5| Step: 7
Training loss: 2.5292427675800435
Validation loss: 2.5163951528744444

Epoch: 5| Step: 8
Training loss: 2.2114533270840453
Validation loss: 2.52937305643111

Epoch: 5| Step: 9
Training loss: 2.423237571118507
Validation loss: 2.5214646653201513

Epoch: 5| Step: 10
Training loss: 2.6594950880825396
Validation loss: 2.501088406917204

Epoch: 449| Step: 0
Training loss: 2.776412872249879
Validation loss: 2.4754982677629154

Epoch: 5| Step: 1
Training loss: 2.635592478641275
Validation loss: 2.4694162541673643

Epoch: 5| Step: 2
Training loss: 2.3690890992954214
Validation loss: 2.4813742728457444

Epoch: 5| Step: 3
Training loss: 2.1914247454238436
Validation loss: 2.4572099625599004

Epoch: 5| Step: 4
Training loss: 2.2930419494278635
Validation loss: 2.4753961440398626

Epoch: 5| Step: 5
Training loss: 2.785761827545268
Validation loss: 2.4449895767220244

Epoch: 5| Step: 6
Training loss: 2.498965812397353
Validation loss: 2.4520956821374478

Epoch: 5| Step: 7
Training loss: 2.513394522019062
Validation loss: 2.458971478489496

Epoch: 5| Step: 8
Training loss: 2.1982556363426893
Validation loss: 2.452842982013

Epoch: 5| Step: 9
Training loss: 2.5943588093854593
Validation loss: 2.4748281814716164

Epoch: 5| Step: 10
Training loss: 2.43632772573199
Validation loss: 2.4632159859017233

Epoch: 450| Step: 0
Training loss: 2.6473195464941517
Validation loss: 2.488955985360379

Epoch: 5| Step: 1
Training loss: 1.9389021322252906
Validation loss: 2.492653734369323

Epoch: 5| Step: 2
Training loss: 2.6796908809540443
Validation loss: 2.49958649466278

Epoch: 5| Step: 3
Training loss: 2.9792305110323722
Validation loss: 2.4711638083752847

Epoch: 5| Step: 4
Training loss: 2.136809687100257
Validation loss: 2.4774783579796646

Epoch: 5| Step: 5
Training loss: 2.813674596710774
Validation loss: 2.458951944890938

Epoch: 5| Step: 6
Training loss: 2.3276547974800064
Validation loss: 2.4510095620769032

Epoch: 5| Step: 7
Training loss: 1.9709886206110183
Validation loss: 2.4515555995546356

Epoch: 5| Step: 8
Training loss: 2.4358958320895536
Validation loss: 2.466392838323594

Epoch: 5| Step: 9
Training loss: 2.5106953720778815
Validation loss: 2.464406453281756

Epoch: 5| Step: 10
Training loss: 2.666402555340751
Validation loss: 2.4568506983753147

Epoch: 451| Step: 0
Training loss: 2.4402508985003646
Validation loss: 2.4775735619549697

Epoch: 5| Step: 1
Training loss: 2.9301879455385107
Validation loss: 2.464816670265537

Epoch: 5| Step: 2
Training loss: 2.446295494939148
Validation loss: 2.4772949295070545

Epoch: 5| Step: 3
Training loss: 2.4386406210455203
Validation loss: 2.466575548650278

Epoch: 5| Step: 4
Training loss: 2.6519134127432866
Validation loss: 2.4925715401023094

Epoch: 5| Step: 5
Training loss: 2.344531221526418
Validation loss: 2.482444200187596

Epoch: 5| Step: 6
Training loss: 2.668193936095207
Validation loss: 2.466120891512271

Epoch: 5| Step: 7
Training loss: 2.248411465534538
Validation loss: 2.450444116409698

Epoch: 5| Step: 8
Training loss: 2.5121015432025424
Validation loss: 2.44851881033915

Epoch: 5| Step: 9
Training loss: 2.427487963127049
Validation loss: 2.44297363476369

Epoch: 5| Step: 10
Training loss: 2.0275605954900064
Validation loss: 2.4519262416182372

Epoch: 452| Step: 0
Training loss: 2.156362558274246
Validation loss: 2.436443683695775

Epoch: 5| Step: 1
Training loss: 2.372830353580158
Validation loss: 2.4805898313689725

Epoch: 5| Step: 2
Training loss: 2.8860817336724023
Validation loss: 2.467750715719602

Epoch: 5| Step: 3
Training loss: 2.3766562057771385
Validation loss: 2.4829697620779707

Epoch: 5| Step: 4
Training loss: 2.726096301951908
Validation loss: 2.488514103252612

Epoch: 5| Step: 5
Training loss: 2.4776504966686845
Validation loss: 2.512046791905041

Epoch: 5| Step: 6
Training loss: 2.5986952001859005
Validation loss: 2.5426623097074765

Epoch: 5| Step: 7
Training loss: 2.4826311432925836
Validation loss: 2.5449051095298865

Epoch: 5| Step: 8
Training loss: 2.28888855361113
Validation loss: 2.524583060792873

Epoch: 5| Step: 9
Training loss: 2.7170371436822363
Validation loss: 2.517792689228678

Epoch: 5| Step: 10
Training loss: 2.000582490974101
Validation loss: 2.4849926601306547

Epoch: 453| Step: 0
Training loss: 2.02717639621912
Validation loss: 2.4325534849776074

Epoch: 5| Step: 1
Training loss: 2.2422340733811765
Validation loss: 2.419689740959412

Epoch: 5| Step: 2
Training loss: 2.410417193316834
Validation loss: 2.4142932679996387

Epoch: 5| Step: 3
Training loss: 2.2667119016995514
Validation loss: 2.4358703838936355

Epoch: 5| Step: 4
Training loss: 2.733328221091475
Validation loss: 2.429685559611777

Epoch: 5| Step: 5
Training loss: 2.4822064418038776
Validation loss: 2.430964223332845

Epoch: 5| Step: 6
Training loss: 2.4527493328933034
Validation loss: 2.444847932180824

Epoch: 5| Step: 7
Training loss: 2.7609630883611915
Validation loss: 2.4509492977119502

Epoch: 5| Step: 8
Training loss: 2.5210328351567974
Validation loss: 2.485950542315268

Epoch: 5| Step: 9
Training loss: 2.80683676313723
Validation loss: 2.4774235172315806

Epoch: 5| Step: 10
Training loss: 2.7090832967924707
Validation loss: 2.511795872822663

Epoch: 454| Step: 0
Training loss: 2.28175745506402
Validation loss: 2.520486901592207

Epoch: 5| Step: 1
Training loss: 2.567998894171313
Validation loss: 2.5132038529064546

Epoch: 5| Step: 2
Training loss: 2.486800443342273
Validation loss: 2.4924654087380005

Epoch: 5| Step: 3
Training loss: 2.4075818029907188
Validation loss: 2.4553093064177225

Epoch: 5| Step: 4
Training loss: 2.711935249990379
Validation loss: 2.442452640341107

Epoch: 5| Step: 5
Training loss: 2.147177364817897
Validation loss: 2.448447807427427

Epoch: 5| Step: 6
Training loss: 2.855490959696886
Validation loss: 2.4338832028571944

Epoch: 5| Step: 7
Training loss: 2.428959482909647
Validation loss: 2.441344015923863

Epoch: 5| Step: 8
Training loss: 1.8006131637803895
Validation loss: 2.474097928230603

Epoch: 5| Step: 9
Training loss: 2.8891865218318062
Validation loss: 2.476747410097238

Epoch: 5| Step: 10
Training loss: 2.713896793452447
Validation loss: 2.4927890825719135

Epoch: 455| Step: 0
Training loss: 2.4973931072221554
Validation loss: 2.4985221868500482

Epoch: 5| Step: 1
Training loss: 2.0907591909270185
Validation loss: 2.480987775130065

Epoch: 5| Step: 2
Training loss: 2.443735705087516
Validation loss: 2.5252136016660014

Epoch: 5| Step: 3
Training loss: 2.571890117837222
Validation loss: 2.560424847835374

Epoch: 5| Step: 4
Training loss: 2.410640624601225
Validation loss: 2.533124611626669

Epoch: 5| Step: 5
Training loss: 2.630887196371779
Validation loss: 2.499978327913588

Epoch: 5| Step: 6
Training loss: 2.398887269036859
Validation loss: 2.4764378055209604

Epoch: 5| Step: 7
Training loss: 2.3202055318817254
Validation loss: 2.476512224830873

Epoch: 5| Step: 8
Training loss: 2.521822007767615
Validation loss: 2.4782924270550333

Epoch: 5| Step: 9
Training loss: 2.6934320496732926
Validation loss: 2.489725746684126

Epoch: 5| Step: 10
Training loss: 2.5379797871824126
Validation loss: 2.4693213897531763

Epoch: 456| Step: 0
Training loss: 2.739743874684429
Validation loss: 2.46725437150808

Epoch: 5| Step: 1
Training loss: 2.552849624705667
Validation loss: 2.4605066357506225

Epoch: 5| Step: 2
Training loss: 1.9540458644571834
Validation loss: 2.463036407028094

Epoch: 5| Step: 3
Training loss: 2.874179888973494
Validation loss: 2.477925936736895

Epoch: 5| Step: 4
Training loss: 2.5540017423750774
Validation loss: 2.4756842897699514

Epoch: 5| Step: 5
Training loss: 2.248658416053586
Validation loss: 2.450700983399571

Epoch: 5| Step: 6
Training loss: 2.491665680884057
Validation loss: 2.43574561652989

Epoch: 5| Step: 7
Training loss: 2.8335579801772837
Validation loss: 2.4529136199308788

Epoch: 5| Step: 8
Training loss: 2.2167731061156895
Validation loss: 2.446777181870746

Epoch: 5| Step: 9
Training loss: 2.698705422906554
Validation loss: 2.435188966936678

Epoch: 5| Step: 10
Training loss: 1.75550629966516
Validation loss: 2.443496381426279

Epoch: 457| Step: 0
Training loss: 2.3696439480417144
Validation loss: 2.452326652854232

Epoch: 5| Step: 1
Training loss: 2.5369856101632773
Validation loss: 2.473425255915781

Epoch: 5| Step: 2
Training loss: 2.4082252024978987
Validation loss: 2.4392046556422637

Epoch: 5| Step: 3
Training loss: 2.600969126622622
Validation loss: 2.470163104203039

Epoch: 5| Step: 4
Training loss: 2.050398029670855
Validation loss: 2.491964891858008

Epoch: 5| Step: 5
Training loss: 2.575560710560984
Validation loss: 2.4833800602236167

Epoch: 5| Step: 6
Training loss: 2.5797580055477103
Validation loss: 2.49490952036237

Epoch: 5| Step: 7
Training loss: 2.8449431211554765
Validation loss: 2.503280636489591

Epoch: 5| Step: 8
Training loss: 2.367021712235409
Validation loss: 2.4861401224550876

Epoch: 5| Step: 9
Training loss: 2.657429242632049
Validation loss: 2.4863732391237536

Epoch: 5| Step: 10
Training loss: 1.8836807844764425
Validation loss: 2.4436650735838263

Epoch: 458| Step: 0
Training loss: 2.4787377272247726
Validation loss: 2.433127554726122

Epoch: 5| Step: 1
Training loss: 2.307544760388736
Validation loss: 2.43868141162005

Epoch: 5| Step: 2
Training loss: 2.398554895367227
Validation loss: 2.4403587911766027

Epoch: 5| Step: 3
Training loss: 2.6961978950824474
Validation loss: 2.4457875998208607

Epoch: 5| Step: 4
Training loss: 2.4312204511165767
Validation loss: 2.4429221614705963

Epoch: 5| Step: 5
Training loss: 2.254075597685079
Validation loss: 2.455947545950284

Epoch: 5| Step: 6
Training loss: 2.5295523142610623
Validation loss: 2.4356232247202234

Epoch: 5| Step: 7
Training loss: 2.2816544265734557
Validation loss: 2.4659861468442394

Epoch: 5| Step: 8
Training loss: 2.204715884841749
Validation loss: 2.46434140140871

Epoch: 5| Step: 9
Training loss: 2.783836961817353
Validation loss: 2.479794823296311

Epoch: 5| Step: 10
Training loss: 2.621273847552427
Validation loss: 2.474729027555278

Epoch: 459| Step: 0
Training loss: 2.294082916796641
Validation loss: 2.4957725930295918

Epoch: 5| Step: 1
Training loss: 2.399882921701039
Validation loss: 2.4683554289775653

Epoch: 5| Step: 2
Training loss: 2.6682305717179124
Validation loss: 2.4702546807036043

Epoch: 5| Step: 3
Training loss: 2.403118821075393
Validation loss: 2.479603089321311

Epoch: 5| Step: 4
Training loss: 2.8815281599245197
Validation loss: 2.464762379889467

Epoch: 5| Step: 5
Training loss: 1.881709618676531
Validation loss: 2.445252539756538

Epoch: 5| Step: 6
Training loss: 2.5842288731289607
Validation loss: 2.4425049988911316

Epoch: 5| Step: 7
Training loss: 2.7809043412311265
Validation loss: 2.4418547072157764

Epoch: 5| Step: 8
Training loss: 2.542529934057055
Validation loss: 2.4366886312503313

Epoch: 5| Step: 9
Training loss: 2.2900681093240474
Validation loss: 2.4881726050294053

Epoch: 5| Step: 10
Training loss: 2.132393484910162
Validation loss: 2.5237754443858176

Epoch: 460| Step: 0
Training loss: 1.990499641627318
Validation loss: 2.504237414955258

Epoch: 5| Step: 1
Training loss: 2.789157128531912
Validation loss: 2.498062662903463

Epoch: 5| Step: 2
Training loss: 2.527610894401291
Validation loss: 2.498163202742859

Epoch: 5| Step: 3
Training loss: 2.88263153914164
Validation loss: 2.474744276365742

Epoch: 5| Step: 4
Training loss: 2.796258954446069
Validation loss: 2.4579637756161525

Epoch: 5| Step: 5
Training loss: 2.525769552669229
Validation loss: 2.435576092713136

Epoch: 5| Step: 6
Training loss: 2.5462208475308334
Validation loss: 2.420438876169661

Epoch: 5| Step: 7
Training loss: 2.4162340982844364
Validation loss: 2.4045651842944764

Epoch: 5| Step: 8
Training loss: 2.3454707631712473
Validation loss: 2.4247362397449517

Epoch: 5| Step: 9
Training loss: 2.1014771851874294
Validation loss: 2.4287260825716444

Epoch: 5| Step: 10
Training loss: 1.9989813356200878
Validation loss: 2.4511264372087127

Epoch: 461| Step: 0
Training loss: 2.628032023160734
Validation loss: 2.4861765772478375

Epoch: 5| Step: 1
Training loss: 2.404880084182851
Validation loss: 2.5204749748009205

Epoch: 5| Step: 2
Training loss: 2.6229581611952675
Validation loss: 2.5288305251367142

Epoch: 5| Step: 3
Training loss: 2.0453251219754134
Validation loss: 2.5300464885892078

Epoch: 5| Step: 4
Training loss: 2.367047094833078
Validation loss: 2.4901397992101564

Epoch: 5| Step: 5
Training loss: 2.389693733288016
Validation loss: 2.4292470723212167

Epoch: 5| Step: 6
Training loss: 2.481164741492646
Validation loss: 2.4536057463532126

Epoch: 5| Step: 7
Training loss: 2.5424049326659763
Validation loss: 2.434955704677725

Epoch: 5| Step: 8
Training loss: 2.5175569117608996
Validation loss: 2.4608834938677204

Epoch: 5| Step: 9
Training loss: 2.5030685666088948
Validation loss: 2.452632577952925

Epoch: 5| Step: 10
Training loss: 2.632130610967499
Validation loss: 2.4467209300150583

Epoch: 462| Step: 0
Training loss: 2.2334501046166246
Validation loss: 2.4699179691720534

Epoch: 5| Step: 1
Training loss: 2.5947795800767643
Validation loss: 2.5062568630701145

Epoch: 5| Step: 2
Training loss: 2.448401112337799
Validation loss: 2.5260656475979313

Epoch: 5| Step: 3
Training loss: 2.232589114675663
Validation loss: 2.5860652556816204

Epoch: 5| Step: 4
Training loss: 2.5858005821652834
Validation loss: 2.6349073014500513

Epoch: 5| Step: 5
Training loss: 2.8173505705206683
Validation loss: 2.622320865727315

Epoch: 5| Step: 6
Training loss: 2.8379887500241563
Validation loss: 2.5853111282501886

Epoch: 5| Step: 7
Training loss: 2.4150314608591947
Validation loss: 2.5307154970357653

Epoch: 5| Step: 8
Training loss: 2.436766196104238
Validation loss: 2.423954321219859

Epoch: 5| Step: 9
Training loss: 2.5082222196823203
Validation loss: 2.4005142706464047

Epoch: 5| Step: 10
Training loss: 1.8653335624805572
Validation loss: 2.401597157860199

Epoch: 463| Step: 0
Training loss: 2.827805137460284
Validation loss: 2.402431593345319

Epoch: 5| Step: 1
Training loss: 2.71638491130936
Validation loss: 2.402895977592717

Epoch: 5| Step: 2
Training loss: 2.431644546934588
Validation loss: 2.4018861289583304

Epoch: 5| Step: 3
Training loss: 2.3223502205470647
Validation loss: 2.40396031172843

Epoch: 5| Step: 4
Training loss: 2.1552702294875874
Validation loss: 2.3954498676097145

Epoch: 5| Step: 5
Training loss: 2.5263654888016127
Validation loss: 2.4086836446166884

Epoch: 5| Step: 6
Training loss: 2.2447743662250845
Validation loss: 2.4209049479926295

Epoch: 5| Step: 7
Training loss: 2.4451367007306586
Validation loss: 2.456109851941866

Epoch: 5| Step: 8
Training loss: 2.566323289154503
Validation loss: 2.542318443783625

Epoch: 5| Step: 9
Training loss: 3.115370141780956
Validation loss: 2.617632012903868

Epoch: 5| Step: 10
Training loss: 2.7235194497573882
Validation loss: 2.656754686931357

Epoch: 464| Step: 0
Training loss: 2.817172767571018
Validation loss: 2.6108453174674997

Epoch: 5| Step: 1
Training loss: 2.720962238227788
Validation loss: 2.5604023054594887

Epoch: 5| Step: 2
Training loss: 2.5685541231417144
Validation loss: 2.4927111413180865

Epoch: 5| Step: 3
Training loss: 1.7574899335114391
Validation loss: 2.4436008134760954

Epoch: 5| Step: 4
Training loss: 2.794983975768857
Validation loss: 2.427354197989887

Epoch: 5| Step: 5
Training loss: 2.407842926288636
Validation loss: 2.4306539119697916

Epoch: 5| Step: 6
Training loss: 2.5178602251461064
Validation loss: 2.433484177318501

Epoch: 5| Step: 7
Training loss: 1.951244883655827
Validation loss: 2.422858292062822

Epoch: 5| Step: 8
Training loss: 2.6639109817329505
Validation loss: 2.4269706012969934

Epoch: 5| Step: 9
Training loss: 2.280770970045865
Validation loss: 2.4393767890062787

Epoch: 5| Step: 10
Training loss: 2.645537102003098
Validation loss: 2.421867245156598

Epoch: 465| Step: 0
Training loss: 2.228491232201076
Validation loss: 2.4748322100302014

Epoch: 5| Step: 1
Training loss: 2.304447795234401
Validation loss: 2.4338500696202994

Epoch: 5| Step: 2
Training loss: 2.4673857963747494
Validation loss: 2.4767272931656956

Epoch: 5| Step: 3
Training loss: 2.5418161337840877
Validation loss: 2.477750425555498

Epoch: 5| Step: 4
Training loss: 2.8922124679204892
Validation loss: 2.471699756314551

Epoch: 5| Step: 5
Training loss: 1.9942868409834813
Validation loss: 2.4461544814725316

Epoch: 5| Step: 6
Training loss: 2.348789646043486
Validation loss: 2.473742702307366

Epoch: 5| Step: 7
Training loss: 2.4709318153177975
Validation loss: 2.476529823895858

Epoch: 5| Step: 8
Training loss: 2.14776589733657
Validation loss: 2.4422968690121976

Epoch: 5| Step: 9
Training loss: 2.9229845194555106
Validation loss: 2.4455792199270627

Epoch: 5| Step: 10
Training loss: 2.3983115495545624
Validation loss: 2.4629754116791545

Epoch: 466| Step: 0
Training loss: 2.40717268258667
Validation loss: 2.514790249664905

Epoch: 5| Step: 1
Training loss: 2.7957099747104155
Validation loss: 2.537954153472767

Epoch: 5| Step: 2
Training loss: 2.1260553992832674
Validation loss: 2.541002118767272

Epoch: 5| Step: 3
Training loss: 2.4444200148469526
Validation loss: 2.586559345180138

Epoch: 5| Step: 4
Training loss: 2.3338711890703934
Validation loss: 2.570392657138235

Epoch: 5| Step: 5
Training loss: 2.6476709387386697
Validation loss: 2.5950601695758366

Epoch: 5| Step: 6
Training loss: 2.3689457875365383
Validation loss: 2.564279331189227

Epoch: 5| Step: 7
Training loss: 2.642055327246931
Validation loss: 2.4797130712294346

Epoch: 5| Step: 8
Training loss: 2.0359976817419496
Validation loss: 2.4743498851889054

Epoch: 5| Step: 9
Training loss: 2.8218928001746435
Validation loss: 2.4305177658901385

Epoch: 5| Step: 10
Training loss: 2.050317446623203
Validation loss: 2.4448702785587657

Epoch: 467| Step: 0
Training loss: 2.094551502373181
Validation loss: 2.4448952692241335

Epoch: 5| Step: 1
Training loss: 2.187738895995311
Validation loss: 2.405546617455411

Epoch: 5| Step: 2
Training loss: 2.6559443578464363
Validation loss: 2.399971204417452

Epoch: 5| Step: 3
Training loss: 2.1933657883017883
Validation loss: 2.418481573504787

Epoch: 5| Step: 4
Training loss: 2.2554468347418264
Validation loss: 2.4612403153341798

Epoch: 5| Step: 5
Training loss: 2.7347553969498333
Validation loss: 2.4910502094651084

Epoch: 5| Step: 6
Training loss: 2.590814054836016
Validation loss: 2.5102431987484595

Epoch: 5| Step: 7
Training loss: 2.1332277445690075
Validation loss: 2.525972745255596

Epoch: 5| Step: 8
Training loss: 2.771255451449967
Validation loss: 2.5586173122773617

Epoch: 5| Step: 9
Training loss: 2.800361037819708
Validation loss: 2.5736504857947433

Epoch: 5| Step: 10
Training loss: 2.7895696269793784
Validation loss: 2.4948542792550636

Epoch: 468| Step: 0
Training loss: 2.2467608978628606
Validation loss: 2.445433907861425

Epoch: 5| Step: 1
Training loss: 2.7616375124798136
Validation loss: 2.4331220947572634

Epoch: 5| Step: 2
Training loss: 2.2619601369595017
Validation loss: 2.403231747449166

Epoch: 5| Step: 3
Training loss: 2.1031178671275192
Validation loss: 2.4154550165555797

Epoch: 5| Step: 4
Training loss: 2.7520764920893
Validation loss: 2.42239183831651

Epoch: 5| Step: 5
Training loss: 2.8595060724953347
Validation loss: 2.4277857648126564

Epoch: 5| Step: 6
Training loss: 2.544401688010596
Validation loss: 2.421665356970523

Epoch: 5| Step: 7
Training loss: 2.3929367357205433
Validation loss: 2.486458322088112

Epoch: 5| Step: 8
Training loss: 2.4115030986236845
Validation loss: 2.50588191389959

Epoch: 5| Step: 9
Training loss: 2.3775744288333716
Validation loss: 2.546500667620845

Epoch: 5| Step: 10
Training loss: 2.315524108583286
Validation loss: 2.5277390604601075

Epoch: 469| Step: 0
Training loss: 1.9360237650397858
Validation loss: 2.4850783319598557

Epoch: 5| Step: 1
Training loss: 2.419065950640322
Validation loss: 2.5015610220512894

Epoch: 5| Step: 2
Training loss: 2.430274720694781
Validation loss: 2.458180838044357

Epoch: 5| Step: 3
Training loss: 2.3620209667428362
Validation loss: 2.441578469648159

Epoch: 5| Step: 4
Training loss: 2.3862837724408945
Validation loss: 2.463152930060575

Epoch: 5| Step: 5
Training loss: 2.6991223816292513
Validation loss: 2.43121652269828

Epoch: 5| Step: 6
Training loss: 2.603643278296333
Validation loss: 2.43595025960496

Epoch: 5| Step: 7
Training loss: 2.069368658306667
Validation loss: 2.440658840567566

Epoch: 5| Step: 8
Training loss: 2.7501883875736177
Validation loss: 2.4369167600863966

Epoch: 5| Step: 9
Training loss: 2.453885780499282
Validation loss: 2.4448574680305453

Epoch: 5| Step: 10
Training loss: 2.7393471987142775
Validation loss: 2.4617567202505803

Epoch: 470| Step: 0
Training loss: 2.4707681639784407
Validation loss: 2.456028561981271

Epoch: 5| Step: 1
Training loss: 2.3003155118727947
Validation loss: 2.4243708933394092

Epoch: 5| Step: 2
Training loss: 2.6644383498160926
Validation loss: 2.460940511388803

Epoch: 5| Step: 3
Training loss: 2.405210096893611
Validation loss: 2.4699268757676993

Epoch: 5| Step: 4
Training loss: 2.608890602698658
Validation loss: 2.4622641794105005

Epoch: 5| Step: 5
Training loss: 2.9201281216352712
Validation loss: 2.4874888196778344

Epoch: 5| Step: 6
Training loss: 2.0593146956417407
Validation loss: 2.466010937035131

Epoch: 5| Step: 7
Training loss: 2.214858066842231
Validation loss: 2.493277947769409

Epoch: 5| Step: 8
Training loss: 2.3362695974606704
Validation loss: 2.4814677792287334

Epoch: 5| Step: 9
Training loss: 2.560944154648109
Validation loss: 2.4872313796079273

Epoch: 5| Step: 10
Training loss: 2.1992182079470357
Validation loss: 2.4817977263535664

Epoch: 471| Step: 0
Training loss: 2.5063340056460284
Validation loss: 2.4875458367095997

Epoch: 5| Step: 1
Training loss: 2.1189354019291926
Validation loss: 2.4818824166488183

Epoch: 5| Step: 2
Training loss: 2.6234085163198957
Validation loss: 2.4675425064450747

Epoch: 5| Step: 3
Training loss: 2.4770547756626824
Validation loss: 2.463066473751762

Epoch: 5| Step: 4
Training loss: 2.1445753860795778
Validation loss: 2.4640778599316775

Epoch: 5| Step: 5
Training loss: 2.4532351135032378
Validation loss: 2.4541130231649406

Epoch: 5| Step: 6
Training loss: 2.5229761983419308
Validation loss: 2.448619057016526

Epoch: 5| Step: 7
Training loss: 2.7187020308548826
Validation loss: 2.445392259145364

Epoch: 5| Step: 8
Training loss: 2.0942134059674737
Validation loss: 2.4589858877552073

Epoch: 5| Step: 9
Training loss: 2.4563498712090706
Validation loss: 2.4524280547469295

Epoch: 5| Step: 10
Training loss: 2.4915106640548665
Validation loss: 2.456812027214001

Epoch: 472| Step: 0
Training loss: 2.6678477493036135
Validation loss: 2.4479844718623993

Epoch: 5| Step: 1
Training loss: 2.4895027073104
Validation loss: 2.443491160755798

Epoch: 5| Step: 2
Training loss: 2.4767590754619837
Validation loss: 2.481197274932336

Epoch: 5| Step: 3
Training loss: 2.6129323501209507
Validation loss: 2.4769791389494453

Epoch: 5| Step: 4
Training loss: 2.636242904110905
Validation loss: 2.500604865006599

Epoch: 5| Step: 5
Training loss: 2.7454458153302808
Validation loss: 2.5092695724437557

Epoch: 5| Step: 6
Training loss: 2.13293266656529
Validation loss: 2.4807709473408255

Epoch: 5| Step: 7
Training loss: 1.8692858409376574
Validation loss: 2.4530896038686296

Epoch: 5| Step: 8
Training loss: 2.3661722454791576
Validation loss: 2.410915631468674

Epoch: 5| Step: 9
Training loss: 2.187007412626231
Validation loss: 2.416255962351165

Epoch: 5| Step: 10
Training loss: 2.4919982646978958
Validation loss: 2.413137098518114

Epoch: 473| Step: 0
Training loss: 2.133133301695019
Validation loss: 2.4218149760598577

Epoch: 5| Step: 1
Training loss: 2.69658005251926
Validation loss: 2.446718640600953

Epoch: 5| Step: 2
Training loss: 2.2770501760550776
Validation loss: 2.4711816063295156

Epoch: 5| Step: 3
Training loss: 2.214411725356916
Validation loss: 2.5200959895708093

Epoch: 5| Step: 4
Training loss: 2.6193272284500284
Validation loss: 2.535390437338459

Epoch: 5| Step: 5
Training loss: 2.464458840569583
Validation loss: 2.5495206146221223

Epoch: 5| Step: 6
Training loss: 2.4043518109711837
Validation loss: 2.540462193035821

Epoch: 5| Step: 7
Training loss: 2.2623086795740375
Validation loss: 2.4982670530595974

Epoch: 5| Step: 8
Training loss: 2.865446721212833
Validation loss: 2.467031197009481

Epoch: 5| Step: 9
Training loss: 2.32904198528362
Validation loss: 2.4162717658516986

Epoch: 5| Step: 10
Training loss: 2.506004370926853
Validation loss: 2.4103935522294506

Epoch: 474| Step: 0
Training loss: 2.7821468664546516
Validation loss: 2.4302088859913367

Epoch: 5| Step: 1
Training loss: 2.39752498005094
Validation loss: 2.385015784370658

Epoch: 5| Step: 2
Training loss: 2.6063018793664634
Validation loss: 2.4081534815605616

Epoch: 5| Step: 3
Training loss: 2.7304883091216485
Validation loss: 2.3961313227328462

Epoch: 5| Step: 4
Training loss: 2.556740125755489
Validation loss: 2.4196061541147964

Epoch: 5| Step: 5
Training loss: 2.6980818080559836
Validation loss: 2.428924413282947

Epoch: 5| Step: 6
Training loss: 1.7785073966965586
Validation loss: 2.441787093321347

Epoch: 5| Step: 7
Training loss: 2.315498264154761
Validation loss: 2.457806381790505

Epoch: 5| Step: 8
Training loss: 2.268974196440711
Validation loss: 2.465829546836084

Epoch: 5| Step: 9
Training loss: 2.4935762846824074
Validation loss: 2.4739612527947723

Epoch: 5| Step: 10
Training loss: 2.177300900139279
Validation loss: 2.5180267199331317

Epoch: 475| Step: 0
Training loss: 2.6685667917585305
Validation loss: 2.539186048507186

Epoch: 5| Step: 1
Training loss: 2.18661023164046
Validation loss: 2.5572963756576987

Epoch: 5| Step: 2
Training loss: 2.3833627534486577
Validation loss: 2.505605993577278

Epoch: 5| Step: 3
Training loss: 2.2334075113570044
Validation loss: 2.5434618144034196

Epoch: 5| Step: 4
Training loss: 2.738080113924009
Validation loss: 2.5141873413008327

Epoch: 5| Step: 5
Training loss: 2.5313907160322673
Validation loss: 2.4892086773973223

Epoch: 5| Step: 6
Training loss: 2.8397339349684034
Validation loss: 2.419019462556498

Epoch: 5| Step: 7
Training loss: 2.231417212111087
Validation loss: 2.406858009687017

Epoch: 5| Step: 8
Training loss: 1.9223382903149198
Validation loss: 2.3881000114679587

Epoch: 5| Step: 9
Training loss: 2.7916107931286733
Validation loss: 2.3841505103005374

Epoch: 5| Step: 10
Training loss: 2.436616101538286
Validation loss: 2.372492479547358

Epoch: 476| Step: 0
Training loss: 2.4053302344656786
Validation loss: 2.3910777299816326

Epoch: 5| Step: 1
Training loss: 2.450614276094913
Validation loss: 2.4435313174547946

Epoch: 5| Step: 2
Training loss: 2.3439182475418523
Validation loss: 2.440984606357105

Epoch: 5| Step: 3
Training loss: 1.891688339456546
Validation loss: 2.473361542010193

Epoch: 5| Step: 4
Training loss: 2.8279725766073067
Validation loss: 2.4980158387122104

Epoch: 5| Step: 5
Training loss: 2.9227414401970484
Validation loss: 2.518785419936192

Epoch: 5| Step: 6
Training loss: 2.5135123343771197
Validation loss: 2.4958389580726736

Epoch: 5| Step: 7
Training loss: 2.523615024805985
Validation loss: 2.4457586539896345

Epoch: 5| Step: 8
Training loss: 2.3848498030418703
Validation loss: 2.436064668558346

Epoch: 5| Step: 9
Training loss: 2.1046487488892707
Validation loss: 2.41512457055306

Epoch: 5| Step: 10
Training loss: 2.3697126661833448
Validation loss: 2.4073354134558893

Epoch: 477| Step: 0
Training loss: 2.454696346390856
Validation loss: 2.4324383817997712

Epoch: 5| Step: 1
Training loss: 2.5975825478559917
Validation loss: 2.428492434948069

Epoch: 5| Step: 2
Training loss: 1.9113123852744203
Validation loss: 2.4507884345144686

Epoch: 5| Step: 3
Training loss: 2.611383909715245
Validation loss: 2.4840409321333246

Epoch: 5| Step: 4
Training loss: 3.126767078514364
Validation loss: 2.4961295335770988

Epoch: 5| Step: 5
Training loss: 2.5079484468968816
Validation loss: 2.479226752159983

Epoch: 5| Step: 6
Training loss: 2.10296277898554
Validation loss: 2.5079860004297903

Epoch: 5| Step: 7
Training loss: 2.539455817643214
Validation loss: 2.494177608861575

Epoch: 5| Step: 8
Training loss: 2.4044424426637887
Validation loss: 2.4420485451734737

Epoch: 5| Step: 9
Training loss: 2.0687256687727253
Validation loss: 2.415612620670992

Epoch: 5| Step: 10
Training loss: 2.2725733002611412
Validation loss: 2.4173989970297485

Epoch: 478| Step: 0
Training loss: 2.246119437692784
Validation loss: 2.401823889142782

Epoch: 5| Step: 1
Training loss: 2.6111288971892628
Validation loss: 2.411108178962875

Epoch: 5| Step: 2
Training loss: 2.579110067195368
Validation loss: 2.42367693514547

Epoch: 5| Step: 3
Training loss: 2.445611320006951
Validation loss: 2.3939403815397062

Epoch: 5| Step: 4
Training loss: 2.0014121315522964
Validation loss: 2.4053910843570367

Epoch: 5| Step: 5
Training loss: 2.779512527045073
Validation loss: 2.4275778070853997

Epoch: 5| Step: 6
Training loss: 2.317687736734033
Validation loss: 2.4295660534005905

Epoch: 5| Step: 7
Training loss: 2.3656536710304334
Validation loss: 2.465151990352149

Epoch: 5| Step: 8
Training loss: 2.4923567280967447
Validation loss: 2.4758021694107706

Epoch: 5| Step: 9
Training loss: 2.558158359901892
Validation loss: 2.5455046257982383

Epoch: 5| Step: 10
Training loss: 2.3232170446766323
Validation loss: 2.5408147291535967

Epoch: 479| Step: 0
Training loss: 2.3505774174128926
Validation loss: 2.5195462388507512

Epoch: 5| Step: 1
Training loss: 2.5018786047767287
Validation loss: 2.506536388648869

Epoch: 5| Step: 2
Training loss: 2.4548120225467445
Validation loss: 2.461065384028674

Epoch: 5| Step: 3
Training loss: 2.2388143121032544
Validation loss: 2.4615773890167643

Epoch: 5| Step: 4
Training loss: 2.379474440496488
Validation loss: 2.4192454426824743

Epoch: 5| Step: 5
Training loss: 2.0865553037443068
Validation loss: 2.4220881246260126

Epoch: 5| Step: 6
Training loss: 2.335851967562944
Validation loss: 2.4140436023270238

Epoch: 5| Step: 7
Training loss: 2.448828853254747
Validation loss: 2.4304211426898923

Epoch: 5| Step: 8
Training loss: 2.602518175338322
Validation loss: 2.4353038832640475

Epoch: 5| Step: 9
Training loss: 2.47060208924467
Validation loss: 2.4486104864718716

Epoch: 5| Step: 10
Training loss: 2.707310165414482
Validation loss: 2.4474635992860962

Epoch: 480| Step: 0
Training loss: 2.459206786940671
Validation loss: 2.458989994396112

Epoch: 5| Step: 1
Training loss: 2.4877141429029415
Validation loss: 2.463701851514165

Epoch: 5| Step: 2
Training loss: 2.2917902710843685
Validation loss: 2.465438346442279

Epoch: 5| Step: 3
Training loss: 2.6844315865961708
Validation loss: 2.431983277005923

Epoch: 5| Step: 4
Training loss: 2.123867630779689
Validation loss: 2.4228335629438087

Epoch: 5| Step: 5
Training loss: 2.140566191596389
Validation loss: 2.421751294266426

Epoch: 5| Step: 6
Training loss: 2.2198452462565674
Validation loss: 2.4114895442102635

Epoch: 5| Step: 7
Training loss: 2.790072389162614
Validation loss: 2.411503586581147

Epoch: 5| Step: 8
Training loss: 2.620955211997549
Validation loss: 2.4268213903840965

Epoch: 5| Step: 9
Training loss: 2.395553793701078
Validation loss: 2.4567117496188007

Epoch: 5| Step: 10
Training loss: 2.274775265503149
Validation loss: 2.4956579607719114

Epoch: 481| Step: 0
Training loss: 2.0964756774437623
Validation loss: 2.5574352435539613

Epoch: 5| Step: 1
Training loss: 2.8717893834681694
Validation loss: 2.5467700394327535

Epoch: 5| Step: 2
Training loss: 2.3235869759127477
Validation loss: 2.5602411297996746

Epoch: 5| Step: 3
Training loss: 2.2994198357663445
Validation loss: 2.5039766452864796

Epoch: 5| Step: 4
Training loss: 2.6863088407679934
Validation loss: 2.4948325496241037

Epoch: 5| Step: 5
Training loss: 2.5288349451495584
Validation loss: 2.4399620182235546

Epoch: 5| Step: 6
Training loss: 2.7085024756409175
Validation loss: 2.4339593393378185

Epoch: 5| Step: 7
Training loss: 1.8990023679191206
Validation loss: 2.4286800200651593

Epoch: 5| Step: 8
Training loss: 2.923742177103903
Validation loss: 2.440676089990978

Epoch: 5| Step: 9
Training loss: 1.9364754213506343
Validation loss: 2.4237727620916627

Epoch: 5| Step: 10
Training loss: 2.0573164797546033
Validation loss: 2.442118606171417

Epoch: 482| Step: 0
Training loss: 2.185179214984236
Validation loss: 2.404588256324037

Epoch: 5| Step: 1
Training loss: 2.207077917095114
Validation loss: 2.4451110331204213

Epoch: 5| Step: 2
Training loss: 2.638899019009962
Validation loss: 2.4515156872358412

Epoch: 5| Step: 3
Training loss: 2.6744898443309144
Validation loss: 2.4518009139690213

Epoch: 5| Step: 4
Training loss: 1.926028964996406
Validation loss: 2.456879196315127

Epoch: 5| Step: 5
Training loss: 2.169173062530401
Validation loss: 2.4651205617514673

Epoch: 5| Step: 6
Training loss: 2.6400396838240003
Validation loss: 2.478890707062027

Epoch: 5| Step: 7
Training loss: 2.787858462699359
Validation loss: 2.461924764123566

Epoch: 5| Step: 8
Training loss: 2.278226651826702
Validation loss: 2.478237265018132

Epoch: 5| Step: 9
Training loss: 2.244145512056798
Validation loss: 2.479302955191036

Epoch: 5| Step: 10
Training loss: 2.615422715690618
Validation loss: 2.4357802764092065

Epoch: 483| Step: 0
Training loss: 1.7641540071119999
Validation loss: 2.450015308716531

Epoch: 5| Step: 1
Training loss: 2.1682356386609647
Validation loss: 2.4450789034057667

Epoch: 5| Step: 2
Training loss: 2.3313757200321277
Validation loss: 2.435016614388076

Epoch: 5| Step: 3
Training loss: 2.798830850923306
Validation loss: 2.414443410287368

Epoch: 5| Step: 4
Training loss: 2.4134959324529213
Validation loss: 2.418745872055448

Epoch: 5| Step: 5
Training loss: 2.2082384436991758
Validation loss: 2.4415019806500213

Epoch: 5| Step: 6
Training loss: 2.325859964952448
Validation loss: 2.4466393202474777

Epoch: 5| Step: 7
Training loss: 2.488833379646835
Validation loss: 2.448505746674128

Epoch: 5| Step: 8
Training loss: 2.357503995436906
Validation loss: 2.4784591325610443

Epoch: 5| Step: 9
Training loss: 2.634142440721506
Validation loss: 2.4835079385549674

Epoch: 5| Step: 10
Training loss: 2.8144792162435652
Validation loss: 2.476384617775746

Epoch: 484| Step: 0
Training loss: 2.035987259673182
Validation loss: 2.5169327886195796

Epoch: 5| Step: 1
Training loss: 2.2984145836948695
Validation loss: 2.5105828181003376

Epoch: 5| Step: 2
Training loss: 2.2238657900087935
Validation loss: 2.4911871091754225

Epoch: 5| Step: 3
Training loss: 2.424895243004258
Validation loss: 2.513145779723311

Epoch: 5| Step: 4
Training loss: 2.531212606271586
Validation loss: 2.487460062291035

Epoch: 5| Step: 5
Training loss: 2.6645673793606406
Validation loss: 2.501285720734694

Epoch: 5| Step: 6
Training loss: 2.58291680044055
Validation loss: 2.4690669998382178

Epoch: 5| Step: 7
Training loss: 2.4395504665576886
Validation loss: 2.4556737455570805

Epoch: 5| Step: 8
Training loss: 2.384799016645319
Validation loss: 2.4210468031290806

Epoch: 5| Step: 9
Training loss: 2.0796197090592936
Validation loss: 2.4116857260192224

Epoch: 5| Step: 10
Training loss: 2.7404885966024217
Validation loss: 2.3996012092734467

Epoch: 485| Step: 0
Training loss: 2.515541406984084
Validation loss: 2.4183208006449153

Epoch: 5| Step: 1
Training loss: 2.4030964982385106
Validation loss: 2.4192220235075226

Epoch: 5| Step: 2
Training loss: 2.2119481233580607
Validation loss: 2.391526813183338

Epoch: 5| Step: 3
Training loss: 2.357410244411295
Validation loss: 2.418995071480857

Epoch: 5| Step: 4
Training loss: 2.3987449424097953
Validation loss: 2.432591964257563

Epoch: 5| Step: 5
Training loss: 2.2559457209191986
Validation loss: 2.4520519348013927

Epoch: 5| Step: 6
Training loss: 2.575200774874516
Validation loss: 2.4839538817876052

Epoch: 5| Step: 7
Training loss: 2.62895649242712
Validation loss: 2.509902986987681

Epoch: 5| Step: 8
Training loss: 1.9090850260259964
Validation loss: 2.537215604170736

Epoch: 5| Step: 9
Training loss: 2.3218752546554158
Validation loss: 2.5561257664810975

Epoch: 5| Step: 10
Training loss: 2.7262950864454245
Validation loss: 2.5154656994351896

Epoch: 486| Step: 0
Training loss: 2.68380954102491
Validation loss: 2.534952487919797

Epoch: 5| Step: 1
Training loss: 2.8233526439824543
Validation loss: 2.495792031558003

Epoch: 5| Step: 2
Training loss: 2.4025078942271407
Validation loss: 2.4849105745764013

Epoch: 5| Step: 3
Training loss: 2.3635039926022707
Validation loss: 2.462063719602189

Epoch: 5| Step: 4
Training loss: 2.4780115166520424
Validation loss: 2.4564237938762203

Epoch: 5| Step: 5
Training loss: 2.1752655130316985
Validation loss: 2.4453875950069124

Epoch: 5| Step: 6
Training loss: 2.576155401470737
Validation loss: 2.439684664234333

Epoch: 5| Step: 7
Training loss: 1.706721995817802
Validation loss: 2.432420836821082

Epoch: 5| Step: 8
Training loss: 2.585346165837506
Validation loss: 2.442947372500977

Epoch: 5| Step: 9
Training loss: 2.0078493107490147
Validation loss: 2.431903572492044

Epoch: 5| Step: 10
Training loss: 2.297775818516289
Validation loss: 2.4589406683791086

Epoch: 487| Step: 0
Training loss: 2.2356726872810655
Validation loss: 2.4926196339047624

Epoch: 5| Step: 1
Training loss: 2.5718920645721277
Validation loss: 2.4694855034284284

Epoch: 5| Step: 2
Training loss: 2.432997531016297
Validation loss: 2.4826727269745046

Epoch: 5| Step: 3
Training loss: 2.4194237886878764
Validation loss: 2.4762870262967245

Epoch: 5| Step: 4
Training loss: 1.909333908213275
Validation loss: 2.4951050685442726

Epoch: 5| Step: 5
Training loss: 2.3208810642705813
Validation loss: 2.4745472818492744

Epoch: 5| Step: 6
Training loss: 2.507012355468152
Validation loss: 2.477937924517381

Epoch: 5| Step: 7
Training loss: 2.1745622874075567
Validation loss: 2.456575145240799

Epoch: 5| Step: 8
Training loss: 2.2759931429674203
Validation loss: 2.4355416130797667

Epoch: 5| Step: 9
Training loss: 2.827314481981655
Validation loss: 2.4357830192032917

Epoch: 5| Step: 10
Training loss: 2.560635609547761
Validation loss: 2.4117388715694923

Epoch: 488| Step: 0
Training loss: 2.575734828059748
Validation loss: 2.4180310418051043

Epoch: 5| Step: 1
Training loss: 2.5220562724370588
Validation loss: 2.4176882659132595

Epoch: 5| Step: 2
Training loss: 1.9141693085433715
Validation loss: 2.4190145239531753

Epoch: 5| Step: 3
Training loss: 2.3822605181616057
Validation loss: 2.4246101550642982

Epoch: 5| Step: 4
Training loss: 2.6304354931525076
Validation loss: 2.4394856262130618

Epoch: 5| Step: 5
Training loss: 2.0876985466926956
Validation loss: 2.455594090680429

Epoch: 5| Step: 6
Training loss: 2.5500501253773926
Validation loss: 2.4423142149833605

Epoch: 5| Step: 7
Training loss: 2.08132286975209
Validation loss: 2.473702048394117

Epoch: 5| Step: 8
Training loss: 2.702133261386729
Validation loss: 2.461316071674675

Epoch: 5| Step: 9
Training loss: 2.40117714941669
Validation loss: 2.4509971716871637

Epoch: 5| Step: 10
Training loss: 2.2128301815926
Validation loss: 2.4657459271124798

Epoch: 489| Step: 0
Training loss: 2.3069065596396503
Validation loss: 2.4835456954589326

Epoch: 5| Step: 1
Training loss: 2.058525417286783
Validation loss: 2.464926992630384

Epoch: 5| Step: 2
Training loss: 2.628961933787593
Validation loss: 2.4655792198390047

Epoch: 5| Step: 3
Training loss: 2.4189583227849556
Validation loss: 2.4795890893565606

Epoch: 5| Step: 4
Training loss: 2.4957054445068168
Validation loss: 2.4583892499579116

Epoch: 5| Step: 5
Training loss: 1.9449748776536882
Validation loss: 2.4516338181602

Epoch: 5| Step: 6
Training loss: 2.386131501570197
Validation loss: 2.4087384400953313

Epoch: 5| Step: 7
Training loss: 2.451805780519367
Validation loss: 2.406939379678526

Epoch: 5| Step: 8
Training loss: 2.325180649661086
Validation loss: 2.3985802403319485

Epoch: 5| Step: 9
Training loss: 2.595282044711434
Validation loss: 2.3976951765888197

Epoch: 5| Step: 10
Training loss: 2.730144519683556
Validation loss: 2.4145571867576243

Epoch: 490| Step: 0
Training loss: 2.6614775436116167
Validation loss: 2.4143916026966963

Epoch: 5| Step: 1
Training loss: 2.168769757183568
Validation loss: 2.452096536825081

Epoch: 5| Step: 2
Training loss: 2.1316880835838434
Validation loss: 2.4704090150067954

Epoch: 5| Step: 3
Training loss: 2.4538395320903255
Validation loss: 2.5033538471632877

Epoch: 5| Step: 4
Training loss: 2.6100727907166412
Validation loss: 2.509559467298468

Epoch: 5| Step: 5
Training loss: 2.251483110541139
Validation loss: 2.550762794358892

Epoch: 5| Step: 6
Training loss: 2.681263451887056
Validation loss: 2.5422836552056545

Epoch: 5| Step: 7
Training loss: 2.0839797987883215
Validation loss: 2.4651069984825273

Epoch: 5| Step: 8
Training loss: 2.4614755193750986
Validation loss: 2.4218211368812534

Epoch: 5| Step: 9
Training loss: 2.2452008670247245
Validation loss: 2.4295095803207234

Epoch: 5| Step: 10
Training loss: 2.483100996307103
Validation loss: 2.396010611575246

Epoch: 491| Step: 0
Training loss: 2.1938002186648773
Validation loss: 2.402698344544306

Epoch: 5| Step: 1
Training loss: 2.4072836105055613
Validation loss: 2.4078683811036785

Epoch: 5| Step: 2
Training loss: 2.4324653666932967
Validation loss: 2.4391492885956816

Epoch: 5| Step: 3
Training loss: 2.2561791659830814
Validation loss: 2.4506936241831374

Epoch: 5| Step: 4
Training loss: 2.130861388991372
Validation loss: 2.5192764696501264

Epoch: 5| Step: 5
Training loss: 2.6995437801772635
Validation loss: 2.533400051499166

Epoch: 5| Step: 6
Training loss: 2.311692896031552
Validation loss: 2.5437638761842294

Epoch: 5| Step: 7
Training loss: 2.725700001532093
Validation loss: 2.5237729445109798

Epoch: 5| Step: 8
Training loss: 2.635643317285814
Validation loss: 2.4559145026589566

Epoch: 5| Step: 9
Training loss: 2.515701292788425
Validation loss: 2.4125401138574354

Epoch: 5| Step: 10
Training loss: 1.8969492160915051
Validation loss: 2.391212033667674

Epoch: 492| Step: 0
Training loss: 2.380646969189855
Validation loss: 2.3894382667689418

Epoch: 5| Step: 1
Training loss: 2.0938615911552128
Validation loss: 2.38266844385441

Epoch: 5| Step: 2
Training loss: 2.612349225671728
Validation loss: 2.406790431998929

Epoch: 5| Step: 3
Training loss: 2.4568946206050053
Validation loss: 2.3920375471951436

Epoch: 5| Step: 4
Training loss: 2.5323476413036214
Validation loss: 2.413171255545666

Epoch: 5| Step: 5
Training loss: 2.3554317034944274
Validation loss: 2.4201930657208846

Epoch: 5| Step: 6
Training loss: 2.661959626428315
Validation loss: 2.436460218004581

Epoch: 5| Step: 7
Training loss: 2.322956364268212
Validation loss: 2.512667732270257

Epoch: 5| Step: 8
Training loss: 1.9864718554922856
Validation loss: 2.5289042846104763

Epoch: 5| Step: 9
Training loss: 2.2816905811172083
Validation loss: 2.5395433892789425

Epoch: 5| Step: 10
Training loss: 2.676251669415056
Validation loss: 2.5395121908356137

Epoch: 493| Step: 0
Training loss: 2.4712213628611814
Validation loss: 2.496740699207784

Epoch: 5| Step: 1
Training loss: 2.9158331270336837
Validation loss: 2.4770999696725693

Epoch: 5| Step: 2
Training loss: 2.6604119400623687
Validation loss: 2.4375829395942676

Epoch: 5| Step: 3
Training loss: 2.4648145380722433
Validation loss: 2.4315253763389135

Epoch: 5| Step: 4
Training loss: 2.54179183985257
Validation loss: 2.4111822372404874

Epoch: 5| Step: 5
Training loss: 2.15887402079387
Validation loss: 2.4259045822038696

Epoch: 5| Step: 6
Training loss: 2.2820305729923467
Validation loss: 2.4270801268659423

Epoch: 5| Step: 7
Training loss: 1.9042533047900194
Validation loss: 2.409433939748749

Epoch: 5| Step: 8
Training loss: 2.5157347471572193
Validation loss: 2.4302686498707056

Epoch: 5| Step: 9
Training loss: 2.3426812341823706
Validation loss: 2.3987535292059383

Epoch: 5| Step: 10
Training loss: 1.3821748459452567
Validation loss: 2.41314688450493

Epoch: 494| Step: 0
Training loss: 2.6084526396289536
Validation loss: 2.428853880922229

Epoch: 5| Step: 1
Training loss: 1.9193338481301274
Validation loss: 2.44643982633576

Epoch: 5| Step: 2
Training loss: 2.4750592696674354
Validation loss: 2.476184226428169

Epoch: 5| Step: 3
Training loss: 2.4683522737005186
Validation loss: 2.4695598997099553

Epoch: 5| Step: 4
Training loss: 2.486661997970548
Validation loss: 2.4905174621751445

Epoch: 5| Step: 5
Training loss: 2.1612094843140754
Validation loss: 2.4995791675806474

Epoch: 5| Step: 6
Training loss: 2.570435402201516
Validation loss: 2.479795422906962

Epoch: 5| Step: 7
Training loss: 2.4080399630452662
Validation loss: 2.4526700251796667

Epoch: 5| Step: 8
Training loss: 2.2324261469228595
Validation loss: 2.4237863541132127

Epoch: 5| Step: 9
Training loss: 2.034490143173389
Validation loss: 2.4210003424924365

Epoch: 5| Step: 10
Training loss: 2.5815293463413753
Validation loss: 2.41520264537128

Epoch: 495| Step: 0
Training loss: 2.5840866979752417
Validation loss: 2.4147101074999786

Epoch: 5| Step: 1
Training loss: 2.8401651108792363
Validation loss: 2.4065302523271366

Epoch: 5| Step: 2
Training loss: 1.8325669536354967
Validation loss: 2.442615025439704

Epoch: 5| Step: 3
Training loss: 2.3428950467017553
Validation loss: 2.4325617579898524

Epoch: 5| Step: 4
Training loss: 2.3308704752503515
Validation loss: 2.438904694338967

Epoch: 5| Step: 5
Training loss: 2.573597023981358
Validation loss: 2.461484333100795

Epoch: 5| Step: 6
Training loss: 2.1256737482436403
Validation loss: 2.454107086524201

Epoch: 5| Step: 7
Training loss: 2.6520224644901944
Validation loss: 2.459980463086602

Epoch: 5| Step: 8
Training loss: 2.395876035447971
Validation loss: 2.4553333952210403

Epoch: 5| Step: 9
Training loss: 2.5311816170956885
Validation loss: 2.403341838567944

Epoch: 5| Step: 10
Training loss: 1.8023925986282356
Validation loss: 2.394399875580143

Epoch: 496| Step: 0
Training loss: 2.1101904529114415
Validation loss: 2.412094608119033

Epoch: 5| Step: 1
Training loss: 2.098153110528335
Validation loss: 2.3709065750527243

Epoch: 5| Step: 2
Training loss: 2.375604351850186
Validation loss: 2.395855470602336

Epoch: 5| Step: 3
Training loss: 2.4861944481812923
Validation loss: 2.3729629351186823

Epoch: 5| Step: 4
Training loss: 2.5778650326138663
Validation loss: 2.3933643268663913

Epoch: 5| Step: 5
Training loss: 2.6523972338760258
Validation loss: 2.401294027575699

Epoch: 5| Step: 6
Training loss: 2.2610144696318875
Validation loss: 2.3795802149111718

Epoch: 5| Step: 7
Training loss: 2.149694900156142
Validation loss: 2.4032604022404804

Epoch: 5| Step: 8
Training loss: 2.3948092275946045
Validation loss: 2.416193469873216

Epoch: 5| Step: 9
Training loss: 2.035845092643705
Validation loss: 2.453019606436806

Epoch: 5| Step: 10
Training loss: 2.9362080756418396
Validation loss: 2.482947743105591

Epoch: 497| Step: 0
Training loss: 2.0607120971970296
Validation loss: 2.4921156483626583

Epoch: 5| Step: 1
Training loss: 2.2406782327497416
Validation loss: 2.5330035719867974

Epoch: 5| Step: 2
Training loss: 1.8247355151894415
Validation loss: 2.5488466600268986

Epoch: 5| Step: 3
Training loss: 2.8710455857992407
Validation loss: 2.5851996159401573

Epoch: 5| Step: 4
Training loss: 2.267721850089596
Validation loss: 2.574705351002527

Epoch: 5| Step: 5
Training loss: 2.684859109375169
Validation loss: 2.511671837442102

Epoch: 5| Step: 6
Training loss: 2.2455607171523386
Validation loss: 2.476910379684089

Epoch: 5| Step: 7
Training loss: 2.395043173701477
Validation loss: 2.4557964889152237

Epoch: 5| Step: 8
Training loss: 2.6720353463227786
Validation loss: 2.411779055231465

Epoch: 5| Step: 9
Training loss: 2.36493376657273
Validation loss: 2.41347778770556

Epoch: 5| Step: 10
Training loss: 2.4581608684841356
Validation loss: 2.3953243155386983

Epoch: 498| Step: 0
Training loss: 2.4450294403924846
Validation loss: 2.3702638354268064

Epoch: 5| Step: 1
Training loss: 2.37023497965817
Validation loss: 2.3992054962842384

Epoch: 5| Step: 2
Training loss: 2.278752252909289
Validation loss: 2.4117752335976888

Epoch: 5| Step: 3
Training loss: 2.401949916905078
Validation loss: 2.4164285050924588

Epoch: 5| Step: 4
Training loss: 2.121593662313486
Validation loss: 2.498507484866166

Epoch: 5| Step: 5
Training loss: 2.5241541361589586
Validation loss: 2.504409912158879

Epoch: 5| Step: 6
Training loss: 2.411213894697832
Validation loss: 2.521063989758098

Epoch: 5| Step: 7
Training loss: 2.312998743659708
Validation loss: 2.5730924892910574

Epoch: 5| Step: 8
Training loss: 2.794467166616973
Validation loss: 2.583852265945904

Epoch: 5| Step: 9
Training loss: 2.3617419565709312
Validation loss: 2.4703599595431194

Epoch: 5| Step: 10
Training loss: 1.9822708147495418
Validation loss: 2.4140309489274756

Epoch: 499| Step: 0
Training loss: 2.2774930352147424
Validation loss: 2.3857335103529524

Epoch: 5| Step: 1
Training loss: 2.797952455096227
Validation loss: 2.411519575372352

Epoch: 5| Step: 2
Training loss: 2.181411334960117
Validation loss: 2.3938902463493372

Epoch: 5| Step: 3
Training loss: 2.7341080017524146
Validation loss: 2.406235142824299

Epoch: 5| Step: 4
Training loss: 1.806882176102936
Validation loss: 2.4268878155776794

Epoch: 5| Step: 5
Training loss: 2.2362559477640103
Validation loss: 2.4114989398188214

Epoch: 5| Step: 6
Training loss: 2.4705330891959356
Validation loss: 2.4654452971866347

Epoch: 5| Step: 7
Training loss: 2.6139969693832517
Validation loss: 2.4786893216676806

Epoch: 5| Step: 8
Training loss: 2.5249527199728203
Validation loss: 2.4976040423595878

Epoch: 5| Step: 9
Training loss: 2.1316362987360464
Validation loss: 2.5151002724288647

Epoch: 5| Step: 10
Training loss: 2.431792791423628
Validation loss: 2.5255944885779953

Epoch: 500| Step: 0
Training loss: 2.2458922718738745
Validation loss: 2.482749407646734

Epoch: 5| Step: 1
Training loss: 1.4135234079139842
Validation loss: 2.45978012253829

Epoch: 5| Step: 2
Training loss: 2.673888579884038
Validation loss: 2.4731743449971453

Epoch: 5| Step: 3
Training loss: 2.625709074617988
Validation loss: 2.453926201697237

Epoch: 5| Step: 4
Training loss: 2.572501968961357
Validation loss: 2.465969034959275

Epoch: 5| Step: 5
Training loss: 2.276926516071308
Validation loss: 2.433490678369701

Epoch: 5| Step: 6
Training loss: 1.9050477410889857
Validation loss: 2.4131502431667173

Epoch: 5| Step: 7
Training loss: 2.7635657623732106
Validation loss: 2.4190334336623223

Epoch: 5| Step: 8
Training loss: 2.1496838093174317
Validation loss: 2.4154504198489213

Epoch: 5| Step: 9
Training loss: 2.521890833543803
Validation loss: 2.4159487204890593

Epoch: 5| Step: 10
Training loss: 2.5029971277004806
Validation loss: 2.430657280718619

Testing loss: 2.6702619198246764
