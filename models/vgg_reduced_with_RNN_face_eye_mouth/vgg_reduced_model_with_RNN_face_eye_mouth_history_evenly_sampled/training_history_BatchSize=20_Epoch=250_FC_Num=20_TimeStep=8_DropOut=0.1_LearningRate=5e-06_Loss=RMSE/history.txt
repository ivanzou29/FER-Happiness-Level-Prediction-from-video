Epoch: 1| Step: 0
Training loss: 5.926858782634936
Validation loss: 5.742301438304581

Epoch: 5| Step: 1
Training loss: 6.393485401454615
Validation loss: 5.738706634756689

Epoch: 5| Step: 2
Training loss: 5.465722864756882
Validation loss: 5.734993925064477

Epoch: 5| Step: 3
Training loss: 5.415244145547252
Validation loss: 5.731072199078602

Epoch: 5| Step: 4
Training loss: 5.199440874704308
Validation loss: 5.726879026346798

Epoch: 5| Step: 5
Training loss: 5.781014432489539
Validation loss: 5.722467385308256

Epoch: 5| Step: 6
Training loss: 5.58549717588168
Validation loss: 5.717773967465575

Epoch: 5| Step: 7
Training loss: 5.743076966612374
Validation loss: 5.71302401249252

Epoch: 5| Step: 8
Training loss: 6.148518155840097
Validation loss: 5.708276130252528

Epoch: 5| Step: 9
Training loss: 6.140527156603603
Validation loss: 5.702674355924131

Epoch: 5| Step: 10
Training loss: 5.368624610013915
Validation loss: 5.697101461888612

Epoch: 2| Step: 0
Training loss: 5.164076350622027
Validation loss: 5.691676378242588

Epoch: 5| Step: 1
Training loss: 5.5073378771012145
Validation loss: 5.6856915558987415

Epoch: 5| Step: 2
Training loss: 6.088448277114268
Validation loss: 5.679924673741901

Epoch: 5| Step: 3
Training loss: 5.696403493112795
Validation loss: 5.673094147421551

Epoch: 5| Step: 4
Training loss: 6.082053515835127
Validation loss: 5.666862507330794

Epoch: 5| Step: 5
Training loss: 5.4222144644495875
Validation loss: 5.660282238545235

Epoch: 5| Step: 6
Training loss: 6.553509757589612
Validation loss: 5.652954356134462

Epoch: 5| Step: 7
Training loss: 5.213813685721236
Validation loss: 5.645606140329067

Epoch: 5| Step: 8
Training loss: 6.460466914354166
Validation loss: 5.637998500566505

Epoch: 5| Step: 9
Training loss: 5.986168814152605
Validation loss: 5.630850915815422

Epoch: 5| Step: 10
Training loss: 3.716393629802056
Validation loss: 5.622059232702331

Epoch: 3| Step: 0
Training loss: 4.745777461811818
Validation loss: 5.613836925075631

Epoch: 5| Step: 1
Training loss: 5.323140696410277
Validation loss: 5.6057222056133815

Epoch: 5| Step: 2
Training loss: 6.288792271465371
Validation loss: 5.596937926433201

Epoch: 5| Step: 3
Training loss: 5.657413257670541
Validation loss: 5.588296433161359

Epoch: 5| Step: 4
Training loss: 5.5358567531552945
Validation loss: 5.578417314358257

Epoch: 5| Step: 5
Training loss: 5.351500840771615
Validation loss: 5.56868233404197

Epoch: 5| Step: 6
Training loss: 6.024785347434879
Validation loss: 5.558461239237216

Epoch: 5| Step: 7
Training loss: 5.617815982639065
Validation loss: 5.5474318330418715

Epoch: 5| Step: 8
Training loss: 5.520005688318832
Validation loss: 5.536593477209993

Epoch: 5| Step: 9
Training loss: 6.144942534808891
Validation loss: 5.525254951607833

Epoch: 5| Step: 10
Training loss: 5.219871902940288
Validation loss: 5.51312014364834

Epoch: 4| Step: 0
Training loss: 6.262637979354165
Validation loss: 5.5005845051086695

Epoch: 5| Step: 1
Training loss: 5.658673689226353
Validation loss: 5.488582947315762

Epoch: 5| Step: 2
Training loss: 6.003255278937569
Validation loss: 5.475319426130063

Epoch: 5| Step: 3
Training loss: 4.479906148268069
Validation loss: 5.461925900854338

Epoch: 5| Step: 4
Training loss: 6.277489290763808
Validation loss: 5.446738105407146

Epoch: 5| Step: 5
Training loss: 5.268150199515785
Validation loss: 5.433297297976455

Epoch: 5| Step: 6
Training loss: 5.360824878191209
Validation loss: 5.418391338251933

Epoch: 5| Step: 7
Training loss: 4.904936402012577
Validation loss: 5.403939548125071

Epoch: 5| Step: 8
Training loss: 5.857937974824805
Validation loss: 5.388427099879074

Epoch: 5| Step: 9
Training loss: 4.978440725272694
Validation loss: 5.372596663203716

Epoch: 5| Step: 10
Training loss: 4.772610506883527
Validation loss: 5.357562529713052

Epoch: 5| Step: 0
Training loss: 5.243286563368028
Validation loss: 5.341911905072289

Epoch: 5| Step: 1
Training loss: 5.461590772855616
Validation loss: 5.325001219840254

Epoch: 5| Step: 2
Training loss: 4.861648861644644
Validation loss: 5.308055522707412

Epoch: 5| Step: 3
Training loss: 5.5729881591013966
Validation loss: 5.292226160902623

Epoch: 5| Step: 4
Training loss: 5.3469667624130235
Validation loss: 5.2759066916547805

Epoch: 5| Step: 5
Training loss: 5.396467056274236
Validation loss: 5.25749013664908

Epoch: 5| Step: 6
Training loss: 5.779317996962078
Validation loss: 5.2415064222298255

Epoch: 5| Step: 7
Training loss: 5.885163626393393
Validation loss: 5.223531005637314

Epoch: 5| Step: 8
Training loss: 4.709384744554347
Validation loss: 5.206520800152347

Epoch: 5| Step: 9
Training loss: 5.066610104261862
Validation loss: 5.187955810352607

Epoch: 5| Step: 10
Training loss: 4.894620293296688
Validation loss: 5.169854431445088

Epoch: 6| Step: 0
Training loss: 4.331308674380489
Validation loss: 5.151515802213716

Epoch: 5| Step: 1
Training loss: 4.519737614805693
Validation loss: 5.134377045489603

Epoch: 5| Step: 2
Training loss: 5.451032614219007
Validation loss: 5.116971410043097

Epoch: 5| Step: 3
Training loss: 6.0287356496976665
Validation loss: 5.097829154110751

Epoch: 5| Step: 4
Training loss: 5.204260899729295
Validation loss: 5.081171290443881

Epoch: 5| Step: 5
Training loss: 6.554232084801052
Validation loss: 5.0620048804448

Epoch: 5| Step: 6
Training loss: 4.999741547580489
Validation loss: 5.043223338101693

Epoch: 5| Step: 7
Training loss: 3.8419890052681778
Validation loss: 5.025958549487664

Epoch: 5| Step: 8
Training loss: 5.127094492098639
Validation loss: 5.008849563325849

Epoch: 5| Step: 9
Training loss: 5.119199494129268
Validation loss: 4.992722081296821

Epoch: 5| Step: 10
Training loss: 4.566909958050564
Validation loss: 4.975708134350092

Epoch: 7| Step: 0
Training loss: 4.961289088488562
Validation loss: 4.959709186854063

Epoch: 5| Step: 1
Training loss: 4.516676414075706
Validation loss: 4.943581792568031

Epoch: 5| Step: 2
Training loss: 4.75491680854683
Validation loss: 4.927157836481202

Epoch: 5| Step: 3
Training loss: 5.117986206155355
Validation loss: 4.912650288486224

Epoch: 5| Step: 4
Training loss: 5.356918439251705
Validation loss: 4.897058632168873

Epoch: 5| Step: 5
Training loss: 4.892819433295688
Validation loss: 4.881649317518655

Epoch: 5| Step: 6
Training loss: 5.720612769749914
Validation loss: 4.867670655467852

Epoch: 5| Step: 7
Training loss: 4.625868019922763
Validation loss: 4.851264806959899

Epoch: 5| Step: 8
Training loss: 3.892877868657166
Validation loss: 4.8375648875960415

Epoch: 5| Step: 9
Training loss: 5.875613566073932
Validation loss: 4.8218057319010015

Epoch: 5| Step: 10
Training loss: 4.393871478250452
Validation loss: 4.80657577085881

Epoch: 8| Step: 0
Training loss: 5.661569022810623
Validation loss: 4.79009607727754

Epoch: 5| Step: 1
Training loss: 4.967145744789011
Validation loss: 4.77544812281226

Epoch: 5| Step: 2
Training loss: 4.716327171553702
Validation loss: 4.759278398180247

Epoch: 5| Step: 3
Training loss: 5.1141874182130245
Validation loss: 4.744926346536232

Epoch: 5| Step: 4
Training loss: 5.05980657818484
Validation loss: 4.730451197543503

Epoch: 5| Step: 5
Training loss: 4.838439787034029
Validation loss: 4.7177082670230615

Epoch: 5| Step: 6
Training loss: 4.738734891077989
Validation loss: 4.701973164604874

Epoch: 5| Step: 7
Training loss: 4.3323427437463895
Validation loss: 4.689177083903292

Epoch: 5| Step: 8
Training loss: 4.469828868892801
Validation loss: 4.675889400407794

Epoch: 5| Step: 9
Training loss: 4.242544029245647
Validation loss: 4.6640899850323345

Epoch: 5| Step: 10
Training loss: 4.570709993732019
Validation loss: 4.65422902333122

Epoch: 9| Step: 0
Training loss: 4.823300812529674
Validation loss: 4.644870372234053

Epoch: 5| Step: 1
Training loss: 4.397136163716191
Validation loss: 4.631976133629902

Epoch: 5| Step: 2
Training loss: 4.7707354051070565
Validation loss: 4.618692906150446

Epoch: 5| Step: 3
Training loss: 3.8025713603028297
Validation loss: 4.60666581354397

Epoch: 5| Step: 4
Training loss: 4.821490126928332
Validation loss: 4.595027792468272

Epoch: 5| Step: 5
Training loss: 4.790294992685039
Validation loss: 4.585183665993673

Epoch: 5| Step: 6
Training loss: 5.217082596712731
Validation loss: 4.574844904991291

Epoch: 5| Step: 7
Training loss: 5.100698587779327
Validation loss: 4.56404633501179

Epoch: 5| Step: 8
Training loss: 4.433111895621581
Validation loss: 4.554961421065616

Epoch: 5| Step: 9
Training loss: 4.565678991354912
Validation loss: 4.545577433818315

Epoch: 5| Step: 10
Training loss: 4.629731927942413
Validation loss: 4.537855975542472

Epoch: 10| Step: 0
Training loss: 4.28080758363597
Validation loss: 4.528769782137497

Epoch: 5| Step: 1
Training loss: 4.969645677366681
Validation loss: 4.519231756508391

Epoch: 5| Step: 2
Training loss: 3.5432706155426885
Validation loss: 4.514226715765493

Epoch: 5| Step: 3
Training loss: 4.027033767092562
Validation loss: 4.505645572922063

Epoch: 5| Step: 4
Training loss: 4.602475967800341
Validation loss: 4.49776699123748

Epoch: 5| Step: 5
Training loss: 4.640760426198924
Validation loss: 4.491642673833283

Epoch: 5| Step: 6
Training loss: 4.175495762428762
Validation loss: 4.483258755343385

Epoch: 5| Step: 7
Training loss: 5.1150837308382675
Validation loss: 4.473770253206043

Epoch: 5| Step: 8
Training loss: 5.066088123083689
Validation loss: 4.468338646612457

Epoch: 5| Step: 9
Training loss: 4.735059430596336
Validation loss: 4.461878888902119

Epoch: 5| Step: 10
Training loss: 5.1901054733231335
Validation loss: 4.454349263035572

Epoch: 11| Step: 0
Training loss: 4.462179408592049
Validation loss: 4.449208547787952

Epoch: 5| Step: 1
Training loss: 4.698000527230432
Validation loss: 4.441544319685239

Epoch: 5| Step: 2
Training loss: 4.374658189772516
Validation loss: 4.432082709472736

Epoch: 5| Step: 3
Training loss: 4.611005695062354
Validation loss: 4.424485116940482

Epoch: 5| Step: 4
Training loss: 4.3695090577223406
Validation loss: 4.418649210314654

Epoch: 5| Step: 5
Training loss: 4.541152551699043
Validation loss: 4.409743341036792

Epoch: 5| Step: 6
Training loss: 4.027102680557805
Validation loss: 4.402038045908342

Epoch: 5| Step: 7
Training loss: 4.09352961522124
Validation loss: 4.397101321999754

Epoch: 5| Step: 8
Training loss: 4.715739521433387
Validation loss: 4.390115451947027

Epoch: 5| Step: 9
Training loss: 4.475349941103703
Validation loss: 4.38214833364366

Epoch: 5| Step: 10
Training loss: 5.406784295818429
Validation loss: 4.377673863463604

Epoch: 12| Step: 0
Training loss: 5.470032459839186
Validation loss: 4.370953471345102

Epoch: 5| Step: 1
Training loss: 4.213429805117945
Validation loss: 4.365926948615699

Epoch: 5| Step: 2
Training loss: 4.927837720007282
Validation loss: 4.360929517403252

Epoch: 5| Step: 3
Training loss: 3.42000971430241
Validation loss: 4.352522948638797

Epoch: 5| Step: 4
Training loss: 5.1928495836193544
Validation loss: 4.344769500807972

Epoch: 5| Step: 5
Training loss: 3.98920952196904
Validation loss: 4.3405610279263085

Epoch: 5| Step: 6
Training loss: 4.217048358353204
Validation loss: 4.3343149868621405

Epoch: 5| Step: 7
Training loss: 4.643372618177464
Validation loss: 4.323920217540862

Epoch: 5| Step: 8
Training loss: 4.328171492233935
Validation loss: 4.314650194678328

Epoch: 5| Step: 9
Training loss: 4.6039912447875135
Validation loss: 4.308706273751311

Epoch: 5| Step: 10
Training loss: 3.423043665481207
Validation loss: 4.303992417549285

Epoch: 13| Step: 0
Training loss: 3.9354882323484497
Validation loss: 4.295724915104422

Epoch: 5| Step: 1
Training loss: 4.588116363779163
Validation loss: 4.284411199879954

Epoch: 5| Step: 2
Training loss: 4.506931053472191
Validation loss: 4.273718081415827

Epoch: 5| Step: 3
Training loss: 4.630826630591214
Validation loss: 4.265460935864217

Epoch: 5| Step: 4
Training loss: 5.205099378474432
Validation loss: 4.260143418190249

Epoch: 5| Step: 5
Training loss: 4.268673879634497
Validation loss: 4.255979311802948

Epoch: 5| Step: 6
Training loss: 4.073369670108564
Validation loss: 4.241679543089768

Epoch: 5| Step: 7
Training loss: 4.667154332066401
Validation loss: 4.230661934199734

Epoch: 5| Step: 8
Training loss: 4.156628584290896
Validation loss: 4.226071599040798

Epoch: 5| Step: 9
Training loss: 4.440256901087622
Validation loss: 4.215378284492199

Epoch: 5| Step: 10
Training loss: 3.269324438556978
Validation loss: 4.210143058473545

Epoch: 14| Step: 0
Training loss: 4.216098432488459
Validation loss: 4.202625239304972

Epoch: 5| Step: 1
Training loss: 4.875057904804343
Validation loss: 4.193528184455565

Epoch: 5| Step: 2
Training loss: 4.903934393961975
Validation loss: 4.183542525819841

Epoch: 5| Step: 3
Training loss: 3.663025666617934
Validation loss: 4.174488192616666

Epoch: 5| Step: 4
Training loss: 4.150647969962839
Validation loss: 4.168581099880746

Epoch: 5| Step: 5
Training loss: 3.596447670190877
Validation loss: 4.160059147229716

Epoch: 5| Step: 6
Training loss: 3.8731481988054197
Validation loss: 4.154753350223247

Epoch: 5| Step: 7
Training loss: 4.4701264935715495
Validation loss: 4.146361995602106

Epoch: 5| Step: 8
Training loss: 3.6160333163828056
Validation loss: 4.1407367662579135

Epoch: 5| Step: 9
Training loss: 4.632719042190769
Validation loss: 4.135189154388541

Epoch: 5| Step: 10
Training loss: 5.072174811771277
Validation loss: 4.1290705569154875

Epoch: 15| Step: 0
Training loss: 4.014441170952573
Validation loss: 4.125591309030453

Epoch: 5| Step: 1
Training loss: 4.566537612056765
Validation loss: 4.119346572932953

Epoch: 5| Step: 2
Training loss: 3.6240377793353376
Validation loss: 4.1150541776287035

Epoch: 5| Step: 3
Training loss: 4.341905380588616
Validation loss: 4.113343036966118

Epoch: 5| Step: 4
Training loss: 3.9564855713337153
Validation loss: 4.10929583744587

Epoch: 5| Step: 5
Training loss: 3.461921362606901
Validation loss: 4.102689884722036

Epoch: 5| Step: 6
Training loss: 4.377056619355963
Validation loss: 4.0970404304027825

Epoch: 5| Step: 7
Training loss: 4.549566881294641
Validation loss: 4.0952145191644105

Epoch: 5| Step: 8
Training loss: 4.749528761125549
Validation loss: 4.090150806657306

Epoch: 5| Step: 9
Training loss: 4.21613575504348
Validation loss: 4.084323428178541

Epoch: 5| Step: 10
Training loss: 4.66882796420324
Validation loss: 4.079295252186825

Epoch: 16| Step: 0
Training loss: 3.8211072473437753
Validation loss: 4.073528229508637

Epoch: 5| Step: 1
Training loss: 4.581088516282844
Validation loss: 4.070878136536344

Epoch: 5| Step: 2
Training loss: 4.0965478087012
Validation loss: 4.0657626622062715

Epoch: 5| Step: 3
Training loss: 4.743457705774315
Validation loss: 4.064748254569913

Epoch: 5| Step: 4
Training loss: 4.265289405225294
Validation loss: 4.059594547079475

Epoch: 5| Step: 5
Training loss: 3.3222597403589123
Validation loss: 4.052994426553489

Epoch: 5| Step: 6
Training loss: 4.163144008545546
Validation loss: 4.049504619743007

Epoch: 5| Step: 7
Training loss: 3.879889203288847
Validation loss: 4.046821699362775

Epoch: 5| Step: 8
Training loss: 4.517416628314729
Validation loss: 4.042693952784853

Epoch: 5| Step: 9
Training loss: 4.136574891266286
Validation loss: 4.038971062382887

Epoch: 5| Step: 10
Training loss: 4.5163130186547855
Validation loss: 4.033337610178584

Epoch: 17| Step: 0
Training loss: 3.949272479890741
Validation loss: 4.031938982859558

Epoch: 5| Step: 1
Training loss: 4.543044951464851
Validation loss: 4.029242401441177

Epoch: 5| Step: 2
Training loss: 4.532810547547839
Validation loss: 4.023939354948027

Epoch: 5| Step: 3
Training loss: 3.7525247339987597
Validation loss: 4.020610661403064

Epoch: 5| Step: 4
Training loss: 4.551013649175901
Validation loss: 4.013461310562979

Epoch: 5| Step: 5
Training loss: 2.7712127789039753
Validation loss: 4.010009246744726

Epoch: 5| Step: 6
Training loss: 4.207593846580632
Validation loss: 4.004057756464267

Epoch: 5| Step: 7
Training loss: 4.103641121355626
Validation loss: 4.00028278007565

Epoch: 5| Step: 8
Training loss: 4.084826812621476
Validation loss: 3.994001833999529

Epoch: 5| Step: 9
Training loss: 4.363170653113784
Validation loss: 3.9900124412620426

Epoch: 5| Step: 10
Training loss: 4.682166969525711
Validation loss: 3.9909102721767606

Epoch: 18| Step: 0
Training loss: 3.308903162876845
Validation loss: 3.9898547034175293

Epoch: 5| Step: 1
Training loss: 3.9109626113871836
Validation loss: 3.979909774096435

Epoch: 5| Step: 2
Training loss: 4.11280685253986
Validation loss: 3.9741630868625957

Epoch: 5| Step: 3
Training loss: 4.399321174276049
Validation loss: 3.970762204399144

Epoch: 5| Step: 4
Training loss: 4.324355263695996
Validation loss: 3.9653492359063147

Epoch: 5| Step: 5
Training loss: 3.9976818997125148
Validation loss: 3.9676571530647227

Epoch: 5| Step: 6
Training loss: 3.5598375510537807
Validation loss: 3.9661732846012607

Epoch: 5| Step: 7
Training loss: 3.965091971909747
Validation loss: 3.958304536689884

Epoch: 5| Step: 8
Training loss: 4.770077086011728
Validation loss: 3.9488802913584236

Epoch: 5| Step: 9
Training loss: 4.479485694110456
Validation loss: 3.946072750782916

Epoch: 5| Step: 10
Training loss: 4.290945393712925
Validation loss: 3.945548928282867

Epoch: 19| Step: 0
Training loss: 5.19954340470696
Validation loss: 3.9377369038688506

Epoch: 5| Step: 1
Training loss: 3.808963698979559
Validation loss: 3.9362892624221866

Epoch: 5| Step: 2
Training loss: 4.0620926872884215
Validation loss: 3.9286612893406714

Epoch: 5| Step: 3
Training loss: 3.6626621978569567
Validation loss: 3.9239612026890054

Epoch: 5| Step: 4
Training loss: 3.953979158662042
Validation loss: 3.922390126630133

Epoch: 5| Step: 5
Training loss: 3.0735748275849994
Validation loss: 3.9219789071661055

Epoch: 5| Step: 6
Training loss: 4.287794471170692
Validation loss: 3.9198897659375875

Epoch: 5| Step: 7
Training loss: 3.68001793027739
Validation loss: 3.9097695417938225

Epoch: 5| Step: 8
Training loss: 3.9098491719611577
Validation loss: 3.907363209258483

Epoch: 5| Step: 9
Training loss: 4.747129878219941
Validation loss: 3.902086832457871

Epoch: 5| Step: 10
Training loss: 4.127993566715047
Validation loss: 3.9032852571218184

Epoch: 20| Step: 0
Training loss: 3.445068627547315
Validation loss: 3.897623384062893

Epoch: 5| Step: 1
Training loss: 4.527088227191123
Validation loss: 3.89141998425292

Epoch: 5| Step: 2
Training loss: 3.7136630359021634
Validation loss: 3.8890843143572407

Epoch: 5| Step: 3
Training loss: 4.120278864561588
Validation loss: 3.883114197729169

Epoch: 5| Step: 4
Training loss: 3.624614563543678
Validation loss: 3.8829094055209374

Epoch: 5| Step: 5
Training loss: 3.4750637295594324
Validation loss: 3.876776679276964

Epoch: 5| Step: 6
Training loss: 3.632930893148072
Validation loss: 3.87365862057006

Epoch: 5| Step: 7
Training loss: 4.679215701970929
Validation loss: 3.8680412005650933

Epoch: 5| Step: 8
Training loss: 3.879038398389374
Validation loss: 3.866205774688235

Epoch: 5| Step: 9
Training loss: 4.33324319794641
Validation loss: 3.861837602373902

Epoch: 5| Step: 10
Training loss: 4.8566500269478885
Validation loss: 3.857970254220658

Epoch: 21| Step: 0
Training loss: 3.7979275221816855
Validation loss: 3.8514150431408614

Epoch: 5| Step: 1
Training loss: 3.2970705381142182
Validation loss: 3.8492012256449253

Epoch: 5| Step: 2
Training loss: 3.3066766762838324
Validation loss: 3.8469998993505317

Epoch: 5| Step: 3
Training loss: 3.6329214428389265
Validation loss: 3.842087765167256

Epoch: 5| Step: 4
Training loss: 4.157485434116119
Validation loss: 3.842971377408565

Epoch: 5| Step: 5
Training loss: 5.042938870578602
Validation loss: 3.8399836731784944

Epoch: 5| Step: 6
Training loss: 4.310096181340647
Validation loss: 3.8311905447292816

Epoch: 5| Step: 7
Training loss: 3.2878315631483126
Validation loss: 3.829613375130804

Epoch: 5| Step: 8
Training loss: 4.12870991654187
Validation loss: 3.8300044696543702

Epoch: 5| Step: 9
Training loss: 4.664837796742978
Validation loss: 3.8268438161268197

Epoch: 5| Step: 10
Training loss: 4.0340434014213065
Validation loss: 3.822640575037628

Epoch: 22| Step: 0
Training loss: 4.4300978267020685
Validation loss: 3.8171406836077937

Epoch: 5| Step: 1
Training loss: 3.571097456705443
Validation loss: 3.810732782414633

Epoch: 5| Step: 2
Training loss: 2.979798327796836
Validation loss: 3.8054576716778605

Epoch: 5| Step: 3
Training loss: 3.9228405010968643
Validation loss: 3.8053508159354195

Epoch: 5| Step: 4
Training loss: 4.3798300103074155
Validation loss: 3.8090934549706548

Epoch: 5| Step: 5
Training loss: 4.120313814674373
Validation loss: 3.80262697215659

Epoch: 5| Step: 6
Training loss: 4.158443474441723
Validation loss: 3.7939484978376594

Epoch: 5| Step: 7
Training loss: 3.8385262077085818
Validation loss: 3.7920580885826065

Epoch: 5| Step: 8
Training loss: 3.3582715018538294
Validation loss: 3.795181707747548

Epoch: 5| Step: 9
Training loss: 4.022503968610875
Validation loss: 3.794144480830112

Epoch: 5| Step: 10
Training loss: 4.740383653526072
Validation loss: 3.78862422856413

Epoch: 23| Step: 0
Training loss: 4.135021405424092
Validation loss: 3.78212383454591

Epoch: 5| Step: 1
Training loss: 4.19876246612597
Validation loss: 3.777494768797501

Epoch: 5| Step: 2
Training loss: 4.189837813777727
Validation loss: 3.7749808185135976

Epoch: 5| Step: 3
Training loss: 3.431825427668373
Validation loss: 3.7760163776143516

Epoch: 5| Step: 4
Training loss: 3.6498777499693986
Validation loss: 3.7768805789839957

Epoch: 5| Step: 5
Training loss: 4.947175987085196
Validation loss: 3.777798573018296

Epoch: 5| Step: 6
Training loss: 3.144148638650258
Validation loss: 3.760139277620531

Epoch: 5| Step: 7
Training loss: 4.418326635730971
Validation loss: 3.754375098674326

Epoch: 5| Step: 8
Training loss: 3.857563782990989
Validation loss: 3.755903228564667

Epoch: 5| Step: 9
Training loss: 3.0090320047062775
Validation loss: 3.750714514967117

Epoch: 5| Step: 10
Training loss: 3.992739883697613
Validation loss: 3.7505132754593595

Epoch: 24| Step: 0
Training loss: 4.476949571848232
Validation loss: 3.746755675948669

Epoch: 5| Step: 1
Training loss: 3.6149915451858443
Validation loss: 3.7380353827235364

Epoch: 5| Step: 2
Training loss: 3.702705327328632
Validation loss: 3.7364345052286674

Epoch: 5| Step: 3
Training loss: 3.6078523669181712
Validation loss: 3.732399793851165

Epoch: 5| Step: 4
Training loss: 3.6728954439348853
Validation loss: 3.7302203953413864

Epoch: 5| Step: 5
Training loss: 4.603941530733009
Validation loss: 3.7334192932102073

Epoch: 5| Step: 6
Training loss: 3.3742858696329927
Validation loss: 3.729263539974312

Epoch: 5| Step: 7
Training loss: 3.86629640735755
Validation loss: 3.7271746174438976

Epoch: 5| Step: 8
Training loss: 4.508333542988902
Validation loss: 3.72346937654172

Epoch: 5| Step: 9
Training loss: 3.487657446366515
Validation loss: 3.722666104696881

Epoch: 5| Step: 10
Training loss: 3.8712995765080978
Validation loss: 3.7206273264634695

Epoch: 25| Step: 0
Training loss: 4.670953461970744
Validation loss: 3.716765648750546

Epoch: 5| Step: 1
Training loss: 2.7808631885157866
Validation loss: 3.7177682657706135

Epoch: 5| Step: 2
Training loss: 3.8823291009453174
Validation loss: 3.7105497313718336

Epoch: 5| Step: 3
Training loss: 3.3617363725608573
Validation loss: 3.706017519915149

Epoch: 5| Step: 4
Training loss: 4.374734489013617
Validation loss: 3.70136322609982

Epoch: 5| Step: 5
Training loss: 4.85866764722103
Validation loss: 3.69880890724533

Epoch: 5| Step: 6
Training loss: 4.044763669724215
Validation loss: 3.694197616383285

Epoch: 5| Step: 7
Training loss: 3.820025162139627
Validation loss: 3.6928771441620203

Epoch: 5| Step: 8
Training loss: 3.118253367907631
Validation loss: 3.686543022939856

Epoch: 5| Step: 9
Training loss: 4.0091724133468505
Validation loss: 3.6876534203590023

Epoch: 5| Step: 10
Training loss: 3.1678904795355587
Validation loss: 3.6826112618972195

Epoch: 26| Step: 0
Training loss: 3.3917650688074525
Validation loss: 3.6810280074393082

Epoch: 5| Step: 1
Training loss: 3.807074767203956
Validation loss: 3.672509148129503

Epoch: 5| Step: 2
Training loss: 3.974047631909874
Validation loss: 3.6697410245498787

Epoch: 5| Step: 3
Training loss: 3.740102549488246
Validation loss: 3.670964855954426

Epoch: 5| Step: 4
Training loss: 4.133558699914006
Validation loss: 3.663760477085633

Epoch: 5| Step: 5
Training loss: 3.1475435033674786
Validation loss: 3.6639359328108587

Epoch: 5| Step: 6
Training loss: 2.983151010095809
Validation loss: 3.660317611626401

Epoch: 5| Step: 7
Training loss: 3.7658069614118137
Validation loss: 3.6585999131134637

Epoch: 5| Step: 8
Training loss: 4.3775509617931005
Validation loss: 3.655812130253731

Epoch: 5| Step: 9
Training loss: 4.715547396942122
Validation loss: 3.6544643683858657

Epoch: 5| Step: 10
Training loss: 4.041377158791247
Validation loss: 3.649898846919177

Epoch: 27| Step: 0
Training loss: 4.353983727708162
Validation loss: 3.6512201582806894

Epoch: 5| Step: 1
Training loss: 4.031125325485491
Validation loss: 3.646830295836677

Epoch: 5| Step: 2
Training loss: 3.308172169818792
Validation loss: 3.643255437016663

Epoch: 5| Step: 3
Training loss: 3.4698693471271813
Validation loss: 3.6391123439231747

Epoch: 5| Step: 4
Training loss: 4.24794876862289
Validation loss: 3.6337687609558724

Epoch: 5| Step: 5
Training loss: 3.4132682522390714
Validation loss: 3.63412897799176

Epoch: 5| Step: 6
Training loss: 3.609443696924712
Validation loss: 3.6287810295860754

Epoch: 5| Step: 7
Training loss: 3.9602979636559543
Validation loss: 3.630566852564547

Epoch: 5| Step: 8
Training loss: 3.107696693683153
Validation loss: 3.6272103795143877

Epoch: 5| Step: 9
Training loss: 3.857416188682518
Validation loss: 3.622837727276307

Epoch: 5| Step: 10
Training loss: 4.588597112949209
Validation loss: 3.6168246557997006

Epoch: 28| Step: 0
Training loss: 4.147329063824989
Validation loss: 3.616562912652434

Epoch: 5| Step: 1
Training loss: 3.1764199153124504
Validation loss: 3.610606703199463

Epoch: 5| Step: 2
Training loss: 3.3950067149841687
Validation loss: 3.610082210356535

Epoch: 5| Step: 3
Training loss: 4.002592438792526
Validation loss: 3.6114980995637627

Epoch: 5| Step: 4
Training loss: 3.712281443523669
Validation loss: 3.6050147877781953

Epoch: 5| Step: 5
Training loss: 4.32159305516193
Validation loss: 3.5987648977018827

Epoch: 5| Step: 6
Training loss: 3.3329953658114357
Validation loss: 3.6026821067657844

Epoch: 5| Step: 7
Training loss: 3.6643922571995513
Validation loss: 3.6063467333571357

Epoch: 5| Step: 8
Training loss: 4.054613175197886
Validation loss: 3.595226308118165

Epoch: 5| Step: 9
Training loss: 4.103025455240625
Validation loss: 3.591538261659511

Epoch: 5| Step: 10
Training loss: 3.6968211669097957
Validation loss: 3.5944719200286404

Epoch: 29| Step: 0
Training loss: 3.818112354142101
Validation loss: 3.590901304123953

Epoch: 5| Step: 1
Training loss: 3.0688387607393945
Validation loss: 3.5909656469132276

Epoch: 5| Step: 2
Training loss: 2.7676906307076896
Validation loss: 3.5915190446798193

Epoch: 5| Step: 3
Training loss: 3.142416371983068
Validation loss: 3.5975462363911768

Epoch: 5| Step: 4
Training loss: 3.6254369538138573
Validation loss: 3.5948139828836525

Epoch: 5| Step: 5
Training loss: 3.9586993934954853
Validation loss: 3.5835693340801753

Epoch: 5| Step: 6
Training loss: 4.45722424743734
Validation loss: 3.5718633129304154

Epoch: 5| Step: 7
Training loss: 3.9317025996031383
Validation loss: 3.5683767252061664

Epoch: 5| Step: 8
Training loss: 4.423797081844723
Validation loss: 3.56475079367718

Epoch: 5| Step: 9
Training loss: 3.8608458646662456
Validation loss: 3.5626315697246134

Epoch: 5| Step: 10
Training loss: 4.1803295177185475
Validation loss: 3.5645539444102727

Epoch: 30| Step: 0
Training loss: 3.4127189035036354
Validation loss: 3.558211364081272

Epoch: 5| Step: 1
Training loss: 3.7743661815769594
Validation loss: 3.557131997712811

Epoch: 5| Step: 2
Training loss: 4.544325910378384
Validation loss: 3.5511486714825677

Epoch: 5| Step: 3
Training loss: 3.9062239989369023
Validation loss: 3.548072287246328

Epoch: 5| Step: 4
Training loss: 3.8465294441812885
Validation loss: 3.5437435818750953

Epoch: 5| Step: 5
Training loss: 4.026164787880635
Validation loss: 3.54395660598517

Epoch: 5| Step: 6
Training loss: 4.258452593084585
Validation loss: 3.5364206209892948

Epoch: 5| Step: 7
Training loss: 3.3229541995680227
Validation loss: 3.531956227348087

Epoch: 5| Step: 8
Training loss: 3.323117352746441
Validation loss: 3.5255342471251927

Epoch: 5| Step: 9
Training loss: 2.416075524564406
Validation loss: 3.5261684790016923

Epoch: 5| Step: 10
Training loss: 4.017472491547006
Validation loss: 3.531488192568213

Epoch: 31| Step: 0
Training loss: 3.4155943203426875
Validation loss: 3.5177804874194516

Epoch: 5| Step: 1
Training loss: 3.375801980136607
Validation loss: 3.5158573692761013

Epoch: 5| Step: 2
Training loss: 3.3776229273565006
Validation loss: 3.5088697644825317

Epoch: 5| Step: 3
Training loss: 4.2276641481768955
Validation loss: 3.5098298643331507

Epoch: 5| Step: 4
Training loss: 3.4068372027816833
Validation loss: 3.5142838462850445

Epoch: 5| Step: 5
Training loss: 3.9413179325307017
Validation loss: 3.511236610199426

Epoch: 5| Step: 6
Training loss: 3.891020115165314
Validation loss: 3.5052799415682196

Epoch: 5| Step: 7
Training loss: 4.280837658704271
Validation loss: 3.503075192117798

Epoch: 5| Step: 8
Training loss: 3.947951599342311
Validation loss: 3.504442316882738

Epoch: 5| Step: 9
Training loss: 3.1347329206335286
Validation loss: 3.5118513141023104

Epoch: 5| Step: 10
Training loss: 3.7207655373292274
Validation loss: 3.5032095849481912

Epoch: 32| Step: 0
Training loss: 4.417328455065532
Validation loss: 3.5010381629716574

Epoch: 5| Step: 1
Training loss: 3.2902555861520226
Validation loss: 3.4971605830994603

Epoch: 5| Step: 2
Training loss: 3.278903958090544
Validation loss: 3.492033228329999

Epoch: 5| Step: 3
Training loss: 3.5783552737037936
Validation loss: 3.48696008758348

Epoch: 5| Step: 4
Training loss: 3.4764749923151155
Validation loss: 3.4862107581601367

Epoch: 5| Step: 5
Training loss: 4.479264061630379
Validation loss: 3.476139382707967

Epoch: 5| Step: 6
Training loss: 3.74562796997584
Validation loss: 3.475241727662734

Epoch: 5| Step: 7
Training loss: 3.761148411503068
Validation loss: 3.472329029094945

Epoch: 5| Step: 8
Training loss: 3.5133464295675814
Validation loss: 3.4688188375486178

Epoch: 5| Step: 9
Training loss: 3.2356682739547247
Validation loss: 3.4691381277049427

Epoch: 5| Step: 10
Training loss: 3.6352606943040215
Validation loss: 3.468117421686606

Epoch: 33| Step: 0
Training loss: 3.0520074897864196
Validation loss: 3.465805092557596

Epoch: 5| Step: 1
Training loss: 4.297317537580721
Validation loss: 3.461275875318788

Epoch: 5| Step: 2
Training loss: 3.6380555085932866
Validation loss: 3.4595255782689396

Epoch: 5| Step: 3
Training loss: 3.171517187522709
Validation loss: 3.4559036231742644

Epoch: 5| Step: 4
Training loss: 3.8875364737317546
Validation loss: 3.4534562066718566

Epoch: 5| Step: 5
Training loss: 4.0278166115010485
Validation loss: 3.4500264891870325

Epoch: 5| Step: 6
Training loss: 3.8512283396893348
Validation loss: 3.448181049017981

Epoch: 5| Step: 7
Training loss: 3.962270899747189
Validation loss: 3.4430706778023192

Epoch: 5| Step: 8
Training loss: 3.1532767615643844
Validation loss: 3.444538420053372

Epoch: 5| Step: 9
Training loss: 2.799055560095837
Validation loss: 3.4444561334130035

Epoch: 5| Step: 10
Training loss: 4.274284990090585
Validation loss: 3.4413828409307214

Epoch: 34| Step: 0
Training loss: 3.9548864247523507
Validation loss: 3.441469816619707

Epoch: 5| Step: 1
Training loss: 3.3354523281372748
Validation loss: 3.434704758478959

Epoch: 5| Step: 2
Training loss: 4.111302145107939
Validation loss: 3.4323766479597935

Epoch: 5| Step: 3
Training loss: 3.1500577709410527
Validation loss: 3.4273859369143556

Epoch: 5| Step: 4
Training loss: 3.882099907494971
Validation loss: 3.4284847797801783

Epoch: 5| Step: 5
Training loss: 3.9447930022301976
Validation loss: 3.4278390181341587

Epoch: 5| Step: 6
Training loss: 3.812997003897774
Validation loss: 3.429815055976801

Epoch: 5| Step: 7
Training loss: 3.548673064770814
Validation loss: 3.424620974707567

Epoch: 5| Step: 8
Training loss: 3.03884408357155
Validation loss: 3.4201570390902254

Epoch: 5| Step: 9
Training loss: 3.2878472264477936
Validation loss: 3.4202268966251803

Epoch: 5| Step: 10
Training loss: 3.951460778257136
Validation loss: 3.419792893010924

Epoch: 35| Step: 0
Training loss: 3.1690458261216548
Validation loss: 3.418657412201998

Epoch: 5| Step: 1
Training loss: 3.971948251116308
Validation loss: 3.417498589075124

Epoch: 5| Step: 2
Training loss: 3.267774540663477
Validation loss: 3.410331658132703

Epoch: 5| Step: 3
Training loss: 3.3016116570542606
Validation loss: 3.40746538949265

Epoch: 5| Step: 4
Training loss: 3.5237543001720417
Validation loss: 3.4091692424585998

Epoch: 5| Step: 5
Training loss: 3.9868877789940966
Validation loss: 3.4040055231036757

Epoch: 5| Step: 6
Training loss: 4.415125571999999
Validation loss: 3.404506631962734

Epoch: 5| Step: 7
Training loss: 3.0292707450718632
Validation loss: 3.4050045651125513

Epoch: 5| Step: 8
Training loss: 3.5394359669460513
Validation loss: 3.4054433562378015

Epoch: 5| Step: 9
Training loss: 3.439299233940114
Validation loss: 3.405903439118974

Epoch: 5| Step: 10
Training loss: 4.12374188281576
Validation loss: 3.3979453600262137

Epoch: 36| Step: 0
Training loss: 3.4287961874815607
Validation loss: 3.394590318787216

Epoch: 5| Step: 1
Training loss: 3.682963668316742
Validation loss: 3.392627883432789

Epoch: 5| Step: 2
Training loss: 3.6204022155630184
Validation loss: 3.390107956723136

Epoch: 5| Step: 3
Training loss: 4.1093299776229015
Validation loss: 3.388606815600747

Epoch: 5| Step: 4
Training loss: 3.8893662220302456
Validation loss: 3.3859167676509623

Epoch: 5| Step: 5
Training loss: 3.086859224985475
Validation loss: 3.3844878244711656

Epoch: 5| Step: 6
Training loss: 3.0763519912546875
Validation loss: 3.381864205506351

Epoch: 5| Step: 7
Training loss: 3.5667618807148735
Validation loss: 3.3865947380627968

Epoch: 5| Step: 8
Training loss: 3.5569315439950473
Validation loss: 3.3809244530620903

Epoch: 5| Step: 9
Training loss: 3.797182172743748
Validation loss: 3.383011406709415

Epoch: 5| Step: 10
Training loss: 3.8608204223715545
Validation loss: 3.3770370351982684

Epoch: 37| Step: 0
Training loss: 3.408382483192489
Validation loss: 3.375153340965987

Epoch: 5| Step: 1
Training loss: 3.8035537315074643
Validation loss: 3.3735034105278827

Epoch: 5| Step: 2
Training loss: 3.8212783310288874
Validation loss: 3.37165013779933

Epoch: 5| Step: 3
Training loss: 3.379600074402714
Validation loss: 3.371986946229679

Epoch: 5| Step: 4
Training loss: 3.9121787283621035
Validation loss: 3.370378974513319

Epoch: 5| Step: 5
Training loss: 4.013713693516939
Validation loss: 3.369400520305439

Epoch: 5| Step: 6
Training loss: 3.6514345720413677
Validation loss: 3.3656929513126874

Epoch: 5| Step: 7
Training loss: 2.8493248926280765
Validation loss: 3.3638965455998835

Epoch: 5| Step: 8
Training loss: 3.8606534377130366
Validation loss: 3.3642539566632084

Epoch: 5| Step: 9
Training loss: 3.458764489808387
Validation loss: 3.361696368156666

Epoch: 5| Step: 10
Training loss: 3.226612746468629
Validation loss: 3.3598500836602088

Epoch: 38| Step: 0
Training loss: 4.015284661145979
Validation loss: 3.358911551091355

Epoch: 5| Step: 1
Training loss: 4.009440011666632
Validation loss: 3.354562276843055

Epoch: 5| Step: 2
Training loss: 3.4306341789457786
Validation loss: 3.3586295817339957

Epoch: 5| Step: 3
Training loss: 3.066558173236926
Validation loss: 3.3582373739697244

Epoch: 5| Step: 4
Training loss: 4.023747285935007
Validation loss: 3.3560226162666833

Epoch: 5| Step: 5
Training loss: 3.262908828083577
Validation loss: 3.3553294206700457

Epoch: 5| Step: 6
Training loss: 3.624364599905997
Validation loss: 3.352067427412408

Epoch: 5| Step: 7
Training loss: 3.2042712137919356
Validation loss: 3.3491649665686647

Epoch: 5| Step: 8
Training loss: 3.2404253847595896
Validation loss: 3.349554302655318

Epoch: 5| Step: 9
Training loss: 3.8680251322169448
Validation loss: 3.3474977896381937

Epoch: 5| Step: 10
Training loss: 3.523847399634474
Validation loss: 3.345267075027643

Epoch: 39| Step: 0
Training loss: 3.3555687921640516
Validation loss: 3.343953875188793

Epoch: 5| Step: 1
Training loss: 3.687126270040882
Validation loss: 3.34198700018485

Epoch: 5| Step: 2
Training loss: 3.234461391603618
Validation loss: 3.3422398761096512

Epoch: 5| Step: 3
Training loss: 3.259599739731373
Validation loss: 3.341819702069707

Epoch: 5| Step: 4
Training loss: 3.2483206591710374
Validation loss: 3.3370350346869766

Epoch: 5| Step: 5
Training loss: 3.648168386463099
Validation loss: 3.3370547983463337

Epoch: 5| Step: 6
Training loss: 2.9959466890651947
Validation loss: 3.3368575775026192

Epoch: 5| Step: 7
Training loss: 4.223034300982576
Validation loss: 3.3377232060493816

Epoch: 5| Step: 8
Training loss: 3.6744592541272927
Validation loss: 3.3330867742801593

Epoch: 5| Step: 9
Training loss: 3.8750938896371814
Validation loss: 3.3331814828760677

Epoch: 5| Step: 10
Training loss: 3.9858940071296147
Validation loss: 3.333059214016279

Epoch: 40| Step: 0
Training loss: 3.932730192612163
Validation loss: 3.329091570059041

Epoch: 5| Step: 1
Training loss: 3.102716879691484
Validation loss: 3.329892445770201

Epoch: 5| Step: 2
Training loss: 4.384103295954
Validation loss: 3.3256021100188886

Epoch: 5| Step: 3
Training loss: 3.548003567527173
Validation loss: 3.3238890668420455

Epoch: 5| Step: 4
Training loss: 3.1880405939980583
Validation loss: 3.3240894571898996

Epoch: 5| Step: 5
Training loss: 2.5587291419628477
Validation loss: 3.3228023845133157

Epoch: 5| Step: 6
Training loss: 3.75909211702926
Validation loss: 3.322234499405377

Epoch: 5| Step: 7
Training loss: 3.919176609600697
Validation loss: 3.320744537485118

Epoch: 5| Step: 8
Training loss: 3.584583301029089
Validation loss: 3.320634913658214

Epoch: 5| Step: 9
Training loss: 3.531948864403577
Validation loss: 3.317999814116065

Epoch: 5| Step: 10
Training loss: 3.322942289215763
Validation loss: 3.3183872829371537

Epoch: 41| Step: 0
Training loss: 2.9824815105878755
Validation loss: 3.3152381568234786

Epoch: 5| Step: 1
Training loss: 4.016636821166362
Validation loss: 3.313287125641994

Epoch: 5| Step: 2
Training loss: 3.5546830732716255
Validation loss: 3.3123765265743246

Epoch: 5| Step: 3
Training loss: 3.2907724896278094
Validation loss: 3.311598543858565

Epoch: 5| Step: 4
Training loss: 3.9209076801727925
Validation loss: 3.3113312659096854

Epoch: 5| Step: 5
Training loss: 3.131304675327293
Validation loss: 3.309011658412677

Epoch: 5| Step: 6
Training loss: 3.595657638436151
Validation loss: 3.3092562503528393

Epoch: 5| Step: 7
Training loss: 3.321297533113647
Validation loss: 3.30998759417924

Epoch: 5| Step: 8
Training loss: 3.949041255052477
Validation loss: 3.3076134966062765

Epoch: 5| Step: 9
Training loss: 4.0218341484455244
Validation loss: 3.3057895578838408

Epoch: 5| Step: 10
Training loss: 2.9713918074492405
Validation loss: 3.3048156466744056

Epoch: 42| Step: 0
Training loss: 3.8907277043892634
Validation loss: 3.306111060777056

Epoch: 5| Step: 1
Training loss: 3.586756128686806
Validation loss: 3.3069318802233294

Epoch: 5| Step: 2
Training loss: 3.515323202106884
Validation loss: 3.3007307345461694

Epoch: 5| Step: 3
Training loss: 3.6700955888320608
Validation loss: 3.299632741119108

Epoch: 5| Step: 4
Training loss: 3.4818759047356935
Validation loss: 3.299742368111047

Epoch: 5| Step: 5
Training loss: 3.3888265173197856
Validation loss: 3.2971063830224487

Epoch: 5| Step: 6
Training loss: 3.7646077788417247
Validation loss: 3.2946191326922802

Epoch: 5| Step: 7
Training loss: 3.485488918822561
Validation loss: 3.2977414715172344

Epoch: 5| Step: 8
Training loss: 3.6141877557973205
Validation loss: 3.29344115293458

Epoch: 5| Step: 9
Training loss: 3.173432817929907
Validation loss: 3.293366174274654

Epoch: 5| Step: 10
Training loss: 3.305143428581594
Validation loss: 3.292289479220566

Epoch: 43| Step: 0
Training loss: 3.8314839476804554
Validation loss: 3.289972649520532

Epoch: 5| Step: 1
Training loss: 2.6838756341049117
Validation loss: 3.288885572323803

Epoch: 5| Step: 2
Training loss: 2.9283234129035476
Validation loss: 3.292371420275838

Epoch: 5| Step: 3
Training loss: 4.049934085262463
Validation loss: 3.291748088443892

Epoch: 5| Step: 4
Training loss: 3.1545602033078946
Validation loss: 3.2888386921357924

Epoch: 5| Step: 5
Training loss: 2.980130837659701
Validation loss: 3.285295683729482

Epoch: 5| Step: 6
Training loss: 4.250342860136219
Validation loss: 3.2842165083388077

Epoch: 5| Step: 7
Training loss: 4.102578696659002
Validation loss: 3.2821114889259984

Epoch: 5| Step: 8
Training loss: 3.2542359550286113
Validation loss: 3.2810793658929773

Epoch: 5| Step: 9
Training loss: 3.4280679480674507
Validation loss: 3.2800937160286554

Epoch: 5| Step: 10
Training loss: 3.8206426247717995
Validation loss: 3.2822009840004474

Epoch: 44| Step: 0
Training loss: 3.5154863796455866
Validation loss: 3.279091963211759

Epoch: 5| Step: 1
Training loss: 3.2225804915337743
Validation loss: 3.2770695555322957

Epoch: 5| Step: 2
Training loss: 3.7980161608150773
Validation loss: 3.2761832609539394

Epoch: 5| Step: 3
Training loss: 3.9063447254139683
Validation loss: 3.2742931349912587

Epoch: 5| Step: 4
Training loss: 3.7055176035398945
Validation loss: 3.2742615611930503

Epoch: 5| Step: 5
Training loss: 3.369927444356126
Validation loss: 3.270714389218175

Epoch: 5| Step: 6
Training loss: 3.228063497483688
Validation loss: 3.2736006322708526

Epoch: 5| Step: 7
Training loss: 3.93952163387071
Validation loss: 3.2743000532187327

Epoch: 5| Step: 8
Training loss: 3.5533357502378604
Validation loss: 3.2735556601881473

Epoch: 5| Step: 9
Training loss: 3.4474435041748746
Validation loss: 3.2700216107649873

Epoch: 5| Step: 10
Training loss: 2.789522790192468
Validation loss: 3.268940831846303

Epoch: 45| Step: 0
Training loss: 3.8739081044166297
Validation loss: 3.2671160345119397

Epoch: 5| Step: 1
Training loss: 2.9711971436494524
Validation loss: 3.266558683689598

Epoch: 5| Step: 2
Training loss: 4.090030756976967
Validation loss: 3.2633473859033577

Epoch: 5| Step: 3
Training loss: 3.087130622544478
Validation loss: 3.2646222524630946

Epoch: 5| Step: 4
Training loss: 3.3008433680360567
Validation loss: 3.2627958766500833

Epoch: 5| Step: 5
Training loss: 3.411219480272463
Validation loss: 3.2601576322862322

Epoch: 5| Step: 6
Training loss: 3.6808598102713845
Validation loss: 3.258503259875671

Epoch: 5| Step: 7
Training loss: 4.0447528238303745
Validation loss: 3.25780126589834

Epoch: 5| Step: 8
Training loss: 2.7925963680404084
Validation loss: 3.256314478350318

Epoch: 5| Step: 9
Training loss: 3.9605226318267537
Validation loss: 3.2531938186441027

Epoch: 5| Step: 10
Training loss: 3.013618711050836
Validation loss: 3.252414056069783

Epoch: 46| Step: 0
Training loss: 3.708049477560885
Validation loss: 3.253581704116361

Epoch: 5| Step: 1
Training loss: 3.6888404608104834
Validation loss: 3.251887398958202

Epoch: 5| Step: 2
Training loss: 3.45134388830133
Validation loss: 3.2504247051871924

Epoch: 5| Step: 3
Training loss: 4.268723476880449
Validation loss: 3.2496041205889687

Epoch: 5| Step: 4
Training loss: 2.598405268246144
Validation loss: 3.2478429768679113

Epoch: 5| Step: 5
Training loss: 3.3842916800685563
Validation loss: 3.2475881359325913

Epoch: 5| Step: 6
Training loss: 3.8481733720151468
Validation loss: 3.244324169784944

Epoch: 5| Step: 7
Training loss: 3.7103008808373983
Validation loss: 3.243592588716717

Epoch: 5| Step: 8
Training loss: 3.21349312834764
Validation loss: 3.2424667726385192

Epoch: 5| Step: 9
Training loss: 3.0903318383754286
Validation loss: 3.2417354303659818

Epoch: 5| Step: 10
Training loss: 3.22934394267781
Validation loss: 3.241502535543933

Epoch: 47| Step: 0
Training loss: 3.0998533521851823
Validation loss: 3.2430808054254396

Epoch: 5| Step: 1
Training loss: 3.618397586509141
Validation loss: 3.241296553704719

Epoch: 5| Step: 2
Training loss: 3.924906011537328
Validation loss: 3.2379610681739126

Epoch: 5| Step: 3
Training loss: 3.557491864686351
Validation loss: 3.2379168362257946

Epoch: 5| Step: 4
Training loss: 2.948196092354545
Validation loss: 3.2392085805306734

Epoch: 5| Step: 5
Training loss: 3.179250026291624
Validation loss: 3.2382026198801155

Epoch: 5| Step: 6
Training loss: 3.512320359818785
Validation loss: 3.235029125405523

Epoch: 5| Step: 7
Training loss: 3.566943425881939
Validation loss: 3.234945501259714

Epoch: 5| Step: 8
Training loss: 3.576994338323577
Validation loss: 3.231515885829053

Epoch: 5| Step: 9
Training loss: 3.720911375610675
Validation loss: 3.230972992089259

Epoch: 5| Step: 10
Training loss: 3.5811012916247518
Validation loss: 3.230512933148327

Epoch: 48| Step: 0
Training loss: 3.093486582012804
Validation loss: 3.2282566536207247

Epoch: 5| Step: 1
Training loss: 2.984489878096171
Validation loss: 3.2304800236008733

Epoch: 5| Step: 2
Training loss: 3.3589633423286154
Validation loss: 3.22953646497733

Epoch: 5| Step: 3
Training loss: 4.216446763487732
Validation loss: 3.2252202164775747

Epoch: 5| Step: 4
Training loss: 4.331587855605618
Validation loss: 3.227251320139355

Epoch: 5| Step: 5
Training loss: 3.271649074678805
Validation loss: 3.224252978014497

Epoch: 5| Step: 6
Training loss: 3.407337400121121
Validation loss: 3.222001573197644

Epoch: 5| Step: 7
Training loss: 3.0060895468546005
Validation loss: 3.2197466003442776

Epoch: 5| Step: 8
Training loss: 3.5255431926820577
Validation loss: 3.2198278587908895

Epoch: 5| Step: 9
Training loss: 2.8401085311676093
Validation loss: 3.218121123214908

Epoch: 5| Step: 10
Training loss: 3.97329343713875
Validation loss: 3.220976636311738

Epoch: 49| Step: 0
Training loss: 3.4527723037323064
Validation loss: 3.226848050661626

Epoch: 5| Step: 1
Training loss: 3.507606959108994
Validation loss: 3.2285982587683293

Epoch: 5| Step: 2
Training loss: 3.3511291081422807
Validation loss: 3.2238506646589147

Epoch: 5| Step: 3
Training loss: 3.3155538049760866
Validation loss: 3.2190822513864896

Epoch: 5| Step: 4
Training loss: 3.5371906644010136
Validation loss: 3.2147442376865407

Epoch: 5| Step: 5
Training loss: 3.277738163236325
Validation loss: 3.217483159699467

Epoch: 5| Step: 6
Training loss: 3.5595960325716876
Validation loss: 3.2152696895829114

Epoch: 5| Step: 7
Training loss: 3.2156730685334614
Validation loss: 3.215253435111236

Epoch: 5| Step: 8
Training loss: 3.9431119617313715
Validation loss: 3.21566787136744

Epoch: 5| Step: 9
Training loss: 3.307931448663224
Validation loss: 3.213615614607523

Epoch: 5| Step: 10
Training loss: 3.729526069129613
Validation loss: 3.2120467093648446

Epoch: 50| Step: 0
Training loss: 4.237361516349444
Validation loss: 3.20853172448495

Epoch: 5| Step: 1
Training loss: 2.9162690754514697
Validation loss: 3.2117049114522542

Epoch: 5| Step: 2
Training loss: 3.416847890994399
Validation loss: 3.207954028470005

Epoch: 5| Step: 3
Training loss: 3.641560184717322
Validation loss: 3.2098010562341592

Epoch: 5| Step: 4
Training loss: 3.4099643998511118
Validation loss: 3.210283905568049

Epoch: 5| Step: 5
Training loss: 3.2059908816088334
Validation loss: 3.2052723799463094

Epoch: 5| Step: 6
Training loss: 3.2860087446397084
Validation loss: 3.20286376592178

Epoch: 5| Step: 7
Training loss: 3.777119548025734
Validation loss: 3.20387027212966

Epoch: 5| Step: 8
Training loss: 3.2108341395316624
Validation loss: 3.202278898246961

Epoch: 5| Step: 9
Training loss: 3.560958260998332
Validation loss: 3.2018451189561463

Epoch: 5| Step: 10
Training loss: 3.2372848026821424
Validation loss: 3.200164282975832

Epoch: 51| Step: 0
Training loss: 3.365104721503051
Validation loss: 3.199266227045243

Epoch: 5| Step: 1
Training loss: 3.8227078469990747
Validation loss: 3.2005674983449537

Epoch: 5| Step: 2
Training loss: 3.0323767386825033
Validation loss: 3.198373792680828

Epoch: 5| Step: 3
Training loss: 4.095398316253794
Validation loss: 3.1978959407591043

Epoch: 5| Step: 4
Training loss: 3.353376417875479
Validation loss: 3.1954534199550424

Epoch: 5| Step: 5
Training loss: 3.180014253740335
Validation loss: 3.1942582521277294

Epoch: 5| Step: 6
Training loss: 3.887043848291403
Validation loss: 3.194040017358934

Epoch: 5| Step: 7
Training loss: 3.4551908777620404
Validation loss: 3.192308128045789

Epoch: 5| Step: 8
Training loss: 3.3478231844682136
Validation loss: 3.1928431754739988

Epoch: 5| Step: 9
Training loss: 3.33971211134947
Validation loss: 3.190706061445855

Epoch: 5| Step: 10
Training loss: 2.845379037932703
Validation loss: 3.1921355970639205

Epoch: 52| Step: 0
Training loss: 3.822536952037851
Validation loss: 3.1887688553292617

Epoch: 5| Step: 1
Training loss: 3.9644525043646057
Validation loss: 3.193300174905608

Epoch: 5| Step: 2
Training loss: 3.427208075915099
Validation loss: 3.1924912319447913

Epoch: 5| Step: 3
Training loss: 2.7575250319090894
Validation loss: 3.1871388974982096

Epoch: 5| Step: 4
Training loss: 3.0154584927618924
Validation loss: 3.1870322506590094

Epoch: 5| Step: 5
Training loss: 3.3891627942761846
Validation loss: 3.1856742872588555

Epoch: 5| Step: 6
Training loss: 3.4493251969878393
Validation loss: 3.1856874865827036

Epoch: 5| Step: 7
Training loss: 3.6072348322601346
Validation loss: 3.184701758172335

Epoch: 5| Step: 8
Training loss: 3.517474556880374
Validation loss: 3.1838512991642536

Epoch: 5| Step: 9
Training loss: 2.909479295477627
Validation loss: 3.183688328728003

Epoch: 5| Step: 10
Training loss: 3.9195467052341293
Validation loss: 3.1841194182377306

Epoch: 53| Step: 0
Training loss: 3.947103022303416
Validation loss: 3.1828085797724643

Epoch: 5| Step: 1
Training loss: 3.9494238855832045
Validation loss: 3.18081893558201

Epoch: 5| Step: 2
Training loss: 3.962274991455055
Validation loss: 3.179596085433768

Epoch: 5| Step: 3
Training loss: 2.858041754735918
Validation loss: 3.181075764078401

Epoch: 5| Step: 4
Training loss: 2.9638337235549073
Validation loss: 3.179121998521362

Epoch: 5| Step: 5
Training loss: 3.476815135220317
Validation loss: 3.178869692083298

Epoch: 5| Step: 6
Training loss: 3.7767930679739257
Validation loss: 3.1784868717147643

Epoch: 5| Step: 7
Training loss: 3.03932514379622
Validation loss: 3.1791799684004154

Epoch: 5| Step: 8
Training loss: 3.9506399915809354
Validation loss: 3.1814665082637954

Epoch: 5| Step: 9
Training loss: 2.774481262660728
Validation loss: 3.1758972202494338

Epoch: 5| Step: 10
Training loss: 2.662408846875311
Validation loss: 3.177059811095348

Epoch: 54| Step: 0
Training loss: 3.4887196093458526
Validation loss: 3.178056185425208

Epoch: 5| Step: 1
Training loss: 3.390557354370931
Validation loss: 3.1765750397042556

Epoch: 5| Step: 2
Training loss: 3.5113794080083207
Validation loss: 3.1754718703432014

Epoch: 5| Step: 3
Training loss: 3.124086017464795
Validation loss: 3.178523873249766

Epoch: 5| Step: 4
Training loss: 3.3158182761965826
Validation loss: 3.1754508071410257

Epoch: 5| Step: 5
Training loss: 3.3751936962917837
Validation loss: 3.1753296825397617

Epoch: 5| Step: 6
Training loss: 2.9346913647557678
Validation loss: 3.1732663361746596

Epoch: 5| Step: 7
Training loss: 3.4408566818744712
Validation loss: 3.1728612470847204

Epoch: 5| Step: 8
Training loss: 4.019466477475563
Validation loss: 3.171399144520908

Epoch: 5| Step: 9
Training loss: 3.7183814627489
Validation loss: 3.1727551804448386

Epoch: 5| Step: 10
Training loss: 3.3853138756430097
Validation loss: 3.170924124749831

Epoch: 55| Step: 0
Training loss: 3.3336735710705976
Validation loss: 3.1702924112554096

Epoch: 5| Step: 1
Training loss: 3.7405985921311595
Validation loss: 3.1713556696709237

Epoch: 5| Step: 2
Training loss: 3.543659113503968
Validation loss: 3.171243928625748

Epoch: 5| Step: 3
Training loss: 3.468137807349795
Validation loss: 3.1707254870058836

Epoch: 5| Step: 4
Training loss: 3.1497639401101107
Validation loss: 3.1705602619300732

Epoch: 5| Step: 5
Training loss: 3.6617390437751065
Validation loss: 3.1690969473134962

Epoch: 5| Step: 6
Training loss: 3.621444932025188
Validation loss: 3.1692350385231656

Epoch: 5| Step: 7
Training loss: 4.3464915454044615
Validation loss: 3.1659740431021084

Epoch: 5| Step: 8
Training loss: 2.20426684069617
Validation loss: 3.1673196843584632

Epoch: 5| Step: 9
Training loss: 3.0002967369826488
Validation loss: 3.1678271755071945

Epoch: 5| Step: 10
Training loss: 3.269366735332342
Validation loss: 3.1662327340114937

Epoch: 56| Step: 0
Training loss: 3.5264754974626014
Validation loss: 3.1667936560832133

Epoch: 5| Step: 1
Training loss: 3.4801889771638064
Validation loss: 3.168105294637334

Epoch: 5| Step: 2
Training loss: 3.455292586705388
Validation loss: 3.1651845652281323

Epoch: 5| Step: 3
Training loss: 3.2640520167787317
Validation loss: 3.1669029726243836

Epoch: 5| Step: 4
Training loss: 3.6155919290281386
Validation loss: 3.1632114405726393

Epoch: 5| Step: 5
Training loss: 2.676529427506104
Validation loss: 3.163442651701959

Epoch: 5| Step: 6
Training loss: 4.087828102125785
Validation loss: 3.164213245871777

Epoch: 5| Step: 7
Training loss: 3.315202582197767
Validation loss: 3.162981402376727

Epoch: 5| Step: 8
Training loss: 2.800830707618809
Validation loss: 3.164174313976835

Epoch: 5| Step: 9
Training loss: 3.4093078047217187
Validation loss: 3.1628368228312143

Epoch: 5| Step: 10
Training loss: 3.9228234834926745
Validation loss: 3.163393142614385

Epoch: 57| Step: 0
Training loss: 3.19195380118646
Validation loss: 3.161401802516192

Epoch: 5| Step: 1
Training loss: 4.10325021080612
Validation loss: 3.1609525750205516

Epoch: 5| Step: 2
Training loss: 3.194599099953518
Validation loss: 3.1620116374629474

Epoch: 5| Step: 3
Training loss: 3.9413881027363447
Validation loss: 3.1627328663324508

Epoch: 5| Step: 4
Training loss: 3.5907822005983303
Validation loss: 3.1619072922219105

Epoch: 5| Step: 5
Training loss: 3.0011197225757917
Validation loss: 3.160641106322476

Epoch: 5| Step: 6
Training loss: 3.405215044891163
Validation loss: 3.160476429643437

Epoch: 5| Step: 7
Training loss: 3.4135516939005264
Validation loss: 3.158227012802121

Epoch: 5| Step: 8
Training loss: 3.433174880238521
Validation loss: 3.159460596390307

Epoch: 5| Step: 9
Training loss: 2.704519628717666
Validation loss: 3.162423758508037

Epoch: 5| Step: 10
Training loss: 3.4868415347632022
Validation loss: 3.1587920136335152

Epoch: 58| Step: 0
Training loss: 3.1931716723791514
Validation loss: 3.157962991736582

Epoch: 5| Step: 1
Training loss: 2.8848846349012733
Validation loss: 3.160965799716514

Epoch: 5| Step: 2
Training loss: 3.707425738650065
Validation loss: 3.161402118774567

Epoch: 5| Step: 3
Training loss: 3.8427143717665198
Validation loss: 3.160605308409095

Epoch: 5| Step: 4
Training loss: 3.5996357362623312
Validation loss: 3.155289329841992

Epoch: 5| Step: 5
Training loss: 3.393591923132048
Validation loss: 3.1556805763347473

Epoch: 5| Step: 6
Training loss: 3.508706299686672
Validation loss: 3.1547319223018295

Epoch: 5| Step: 7
Training loss: 3.9726460474534058
Validation loss: 3.1552549320831176

Epoch: 5| Step: 8
Training loss: 2.8695374714913497
Validation loss: 3.156105451625401

Epoch: 5| Step: 9
Training loss: 3.469049251810475
Validation loss: 3.1563069994204422

Epoch: 5| Step: 10
Training loss: 2.934402780939613
Validation loss: 3.152087091155864

Epoch: 59| Step: 0
Training loss: 3.08797262180624
Validation loss: 3.152020558009472

Epoch: 5| Step: 1
Training loss: 3.0233267830382036
Validation loss: 3.1529779651783674

Epoch: 5| Step: 2
Training loss: 3.4532619811631546
Validation loss: 3.152894188614937

Epoch: 5| Step: 3
Training loss: 3.3185108278232094
Validation loss: 3.1529882864686907

Epoch: 5| Step: 4
Training loss: 4.116122084413186
Validation loss: 3.151661900282525

Epoch: 5| Step: 5
Training loss: 4.2797889165431995
Validation loss: 3.1521353651154125

Epoch: 5| Step: 6
Training loss: 3.7171424789235834
Validation loss: 3.1546349850206923

Epoch: 5| Step: 7
Training loss: 3.1896800645495107
Validation loss: 3.1509176977198234

Epoch: 5| Step: 8
Training loss: 2.486269054924781
Validation loss: 3.151223931583334

Epoch: 5| Step: 9
Training loss: 3.2980911398301256
Validation loss: 3.1545480407504405

Epoch: 5| Step: 10
Training loss: 3.252081277974123
Validation loss: 3.1568403655412247

Epoch: 60| Step: 0
Training loss: 4.123388727094083
Validation loss: 3.155802796289569

Epoch: 5| Step: 1
Training loss: 3.5913498534445827
Validation loss: 3.1535603326633135

Epoch: 5| Step: 2
Training loss: 3.1783942514578323
Validation loss: 3.151351577188961

Epoch: 5| Step: 3
Training loss: 3.171169559599805
Validation loss: 3.1518117344895877

Epoch: 5| Step: 4
Training loss: 3.2965666278694297
Validation loss: 3.1531803080193663

Epoch: 5| Step: 5
Training loss: 3.528634512157039
Validation loss: 3.1490471867223744

Epoch: 5| Step: 6
Training loss: 3.4293867600651087
Validation loss: 3.1546483678509203

Epoch: 5| Step: 7
Training loss: 3.328606082728849
Validation loss: 3.1519434336287033

Epoch: 5| Step: 8
Training loss: 3.493440475810662
Validation loss: 3.1549013875770466

Epoch: 5| Step: 9
Training loss: 2.6515508935839547
Validation loss: 3.150026695150068

Epoch: 5| Step: 10
Training loss: 3.6436275821490676
Validation loss: 3.149391691105059

Epoch: 61| Step: 0
Training loss: 2.787145217419103
Validation loss: 3.148681171954007

Epoch: 5| Step: 1
Training loss: 3.6067794120310133
Validation loss: 3.1480229322952242

Epoch: 5| Step: 2
Training loss: 3.066916259338829
Validation loss: 3.14549277541041

Epoch: 5| Step: 3
Training loss: 3.8693720648693892
Validation loss: 3.1452688031033116

Epoch: 5| Step: 4
Training loss: 3.3924320872515294
Validation loss: 3.148412567319241

Epoch: 5| Step: 5
Training loss: 3.682164745310683
Validation loss: 3.148270165520275

Epoch: 5| Step: 6
Training loss: 3.2883707438095655
Validation loss: 3.147954954861071

Epoch: 5| Step: 7
Training loss: 3.082702022222145
Validation loss: 3.146557277564276

Epoch: 5| Step: 8
Training loss: 3.4292086395129924
Validation loss: 3.1491878357108667

Epoch: 5| Step: 9
Training loss: 4.064486912701946
Validation loss: 3.1492635997415626

Epoch: 5| Step: 10
Training loss: 3.0103062980157906
Validation loss: 3.146275035737637

Epoch: 62| Step: 0
Training loss: 3.5367196182711687
Validation loss: 3.144518398064258

Epoch: 5| Step: 1
Training loss: 3.6301527561802582
Validation loss: 3.1491270196539647

Epoch: 5| Step: 2
Training loss: 3.2022622039679116
Validation loss: 3.149005566377488

Epoch: 5| Step: 3
Training loss: 3.739339043050501
Validation loss: 3.154998466184892

Epoch: 5| Step: 4
Training loss: 3.0586646840333818
Validation loss: 3.1478084398986717

Epoch: 5| Step: 5
Training loss: 3.4889530504675323
Validation loss: 3.1485198936957763

Epoch: 5| Step: 6
Training loss: 2.8181069327778023
Validation loss: 3.1432951806841043

Epoch: 5| Step: 7
Training loss: 3.9385539264113167
Validation loss: 3.1427354712494004

Epoch: 5| Step: 8
Training loss: 3.724501705763845
Validation loss: 3.1414091237121977

Epoch: 5| Step: 9
Training loss: 2.664214546585548
Validation loss: 3.1428610952560487

Epoch: 5| Step: 10
Training loss: 3.4841567172115453
Validation loss: 3.139736637007079

Epoch: 63| Step: 0
Training loss: 3.8060067335541294
Validation loss: 3.1407873333864056

Epoch: 5| Step: 1
Training loss: 3.8225982006724406
Validation loss: 3.138313433336097

Epoch: 5| Step: 2
Training loss: 3.4605828441486297
Validation loss: 3.140789081774988

Epoch: 5| Step: 3
Training loss: 3.2720414054694427
Validation loss: 3.138574637728061

Epoch: 5| Step: 4
Training loss: 3.5948397103813905
Validation loss: 3.1389976762360017

Epoch: 5| Step: 5
Training loss: 3.2157805736043
Validation loss: 3.139131485887073

Epoch: 5| Step: 6
Training loss: 2.4240280917274126
Validation loss: 3.137587725338661

Epoch: 5| Step: 7
Training loss: 3.5982609840129474
Validation loss: 3.136943400597157

Epoch: 5| Step: 8
Training loss: 2.612780239278816
Validation loss: 3.1379723506806263

Epoch: 5| Step: 9
Training loss: 3.472814841666557
Validation loss: 3.13566875061037

Epoch: 5| Step: 10
Training loss: 3.9421581991454686
Validation loss: 3.138195231142736

Epoch: 64| Step: 0
Training loss: 3.6993888968921906
Validation loss: 3.136300800638759

Epoch: 5| Step: 1
Training loss: 3.81710887051896
Validation loss: 3.1350255933589835

Epoch: 5| Step: 2
Training loss: 2.9757251913489444
Validation loss: 3.139112878778192

Epoch: 5| Step: 3
Training loss: 2.7969641644634065
Validation loss: 3.1381859591369956

Epoch: 5| Step: 4
Training loss: 3.41204439132989
Validation loss: 3.136576708194696

Epoch: 5| Step: 5
Training loss: 3.3780135370122175
Validation loss: 3.141130201356959

Epoch: 5| Step: 6
Training loss: 3.3380391917639245
Validation loss: 3.138529161937538

Epoch: 5| Step: 7
Training loss: 3.3696152858572175
Validation loss: 3.13703934411071

Epoch: 5| Step: 8
Training loss: 3.5810432361079516
Validation loss: 3.1398151798249376

Epoch: 5| Step: 9
Training loss: 3.2500462161959587
Validation loss: 3.1374384554830907

Epoch: 5| Step: 10
Training loss: 3.7295486993296367
Validation loss: 3.1351321097438505

Epoch: 65| Step: 0
Training loss: 3.5257319995729257
Validation loss: 3.1351279361300906

Epoch: 5| Step: 1
Training loss: 3.3418502402043844
Validation loss: 3.135120301935059

Epoch: 5| Step: 2
Training loss: 3.240602698842548
Validation loss: 3.1353375723985026

Epoch: 5| Step: 3
Training loss: 3.2819425306199363
Validation loss: 3.134536639832614

Epoch: 5| Step: 4
Training loss: 3.5501110757992764
Validation loss: 3.135668488986741

Epoch: 5| Step: 5
Training loss: 3.1824033793535507
Validation loss: 3.1327641353249964

Epoch: 5| Step: 6
Training loss: 3.2885992670839865
Validation loss: 3.131672118475047

Epoch: 5| Step: 7
Training loss: 4.339607953413656
Validation loss: 3.1311128252859266

Epoch: 5| Step: 8
Training loss: 3.684042392565499
Validation loss: 3.1332398560595736

Epoch: 5| Step: 9
Training loss: 2.575036435656493
Validation loss: 3.1309344247552624

Epoch: 5| Step: 10
Training loss: 3.082444311970837
Validation loss: 3.131740062964914

Epoch: 66| Step: 0
Training loss: 2.9930291249661285
Validation loss: 3.131452772140241

Epoch: 5| Step: 1
Training loss: 3.3627736487234503
Validation loss: 3.1310922398684298

Epoch: 5| Step: 2
Training loss: 2.8151862985002736
Validation loss: 3.1321223746798137

Epoch: 5| Step: 3
Training loss: 3.6530385055287846
Validation loss: 3.1336171383205706

Epoch: 5| Step: 4
Training loss: 3.127910174482533
Validation loss: 3.1309618695109025

Epoch: 5| Step: 5
Training loss: 3.549587472936446
Validation loss: 3.1332615319401045

Epoch: 5| Step: 6
Training loss: 3.089016308050802
Validation loss: 3.132879848583315

Epoch: 5| Step: 7
Training loss: 3.8807460881647056
Validation loss: 3.1312676021343258

Epoch: 5| Step: 8
Training loss: 4.004780058994857
Validation loss: 3.1315630726734986

Epoch: 5| Step: 9
Training loss: 3.584332541203477
Validation loss: 3.12822088154643

Epoch: 5| Step: 10
Training loss: 3.0697031751153054
Validation loss: 3.131127251864097

Epoch: 67| Step: 0
Training loss: 2.9611336434250366
Validation loss: 3.127654989265989

Epoch: 5| Step: 1
Training loss: 3.616487966830997
Validation loss: 3.128503252564273

Epoch: 5| Step: 2
Training loss: 3.7428765349473356
Validation loss: 3.1269164740947795

Epoch: 5| Step: 3
Training loss: 3.1254915995163803
Validation loss: 3.126411504784512

Epoch: 5| Step: 4
Training loss: 3.214673766674849
Validation loss: 3.125917804438462

Epoch: 5| Step: 5
Training loss: 3.4044627128998477
Validation loss: 3.126018199142392

Epoch: 5| Step: 6
Training loss: 3.5968923347910504
Validation loss: 3.127912882445524

Epoch: 5| Step: 7
Training loss: 3.7159361892658103
Validation loss: 3.1279132717559914

Epoch: 5| Step: 8
Training loss: 3.378496125308654
Validation loss: 3.127208100239651

Epoch: 5| Step: 9
Training loss: 3.5176552568670725
Validation loss: 3.124404481319511

Epoch: 5| Step: 10
Training loss: 2.8782815863709192
Validation loss: 3.128863966811563

Epoch: 68| Step: 0
Training loss: 3.5748722667149435
Validation loss: 3.1259894923073293

Epoch: 5| Step: 1
Training loss: 3.039634356594482
Validation loss: 3.1262469750933275

Epoch: 5| Step: 2
Training loss: 3.4750054119260074
Validation loss: 3.1252102606804826

Epoch: 5| Step: 3
Training loss: 3.4187815718788266
Validation loss: 3.1239674722572253

Epoch: 5| Step: 4
Training loss: 2.3447085645589443
Validation loss: 3.124620842850979

Epoch: 5| Step: 5
Training loss: 3.5605028142415738
Validation loss: 3.125246980813098

Epoch: 5| Step: 6
Training loss: 3.8514604845135736
Validation loss: 3.126316857932045

Epoch: 5| Step: 7
Training loss: 3.825237820281749
Validation loss: 3.1266312375829353

Epoch: 5| Step: 8
Training loss: 3.0840063305702
Validation loss: 3.125673739089802

Epoch: 5| Step: 9
Training loss: 3.916381027411362
Validation loss: 3.1228447288792385

Epoch: 5| Step: 10
Training loss: 2.788646848678238
Validation loss: 3.121121384781461

Epoch: 69| Step: 0
Training loss: 3.4420894156882764
Validation loss: 3.12210366435473

Epoch: 5| Step: 1
Training loss: 3.785263453678928
Validation loss: 3.121303148586547

Epoch: 5| Step: 2
Training loss: 3.5147041979895315
Validation loss: 3.123567012257192

Epoch: 5| Step: 3
Training loss: 3.4929435986744055
Validation loss: 3.123487547067967

Epoch: 5| Step: 4
Training loss: 2.466804220471051
Validation loss: 3.124142722397527

Epoch: 5| Step: 5
Training loss: 2.8689827352957016
Validation loss: 3.123165529026668

Epoch: 5| Step: 6
Training loss: 3.565791566988534
Validation loss: 3.122453423930715

Epoch: 5| Step: 7
Training loss: 3.140258008476731
Validation loss: 3.122444172505136

Epoch: 5| Step: 8
Training loss: 4.181392485923546
Validation loss: 3.123637348179037

Epoch: 5| Step: 9
Training loss: 3.1408298103013848
Validation loss: 3.125361575466465

Epoch: 5| Step: 10
Training loss: 3.3849021324986985
Validation loss: 3.1278558229402362

Epoch: 70| Step: 0
Training loss: 3.6925965342884486
Validation loss: 3.125485359154887

Epoch: 5| Step: 1
Training loss: 2.959148420060785
Validation loss: 3.125117223038192

Epoch: 5| Step: 2
Training loss: 3.323752526335744
Validation loss: 3.1209012960879865

Epoch: 5| Step: 3
Training loss: 3.975046524639287
Validation loss: 3.120231601645054

Epoch: 5| Step: 4
Training loss: 2.802855081650518
Validation loss: 3.1191490380192612

Epoch: 5| Step: 5
Training loss: 2.9325116596168996
Validation loss: 3.121400421254271

Epoch: 5| Step: 6
Training loss: 2.7610484905634003
Validation loss: 3.1190452807940114

Epoch: 5| Step: 7
Training loss: 4.1040071304735255
Validation loss: 3.1203445935326655

Epoch: 5| Step: 8
Training loss: 3.700231524260324
Validation loss: 3.11862086418095

Epoch: 5| Step: 9
Training loss: 2.9281177435167223
Validation loss: 3.1205109674321228

Epoch: 5| Step: 10
Training loss: 3.7891941322979497
Validation loss: 3.118542420557516

Epoch: 71| Step: 0
Training loss: 3.088143557299946
Validation loss: 3.120051390811262

Epoch: 5| Step: 1
Training loss: 4.198007865022413
Validation loss: 3.1182926297754134

Epoch: 5| Step: 2
Training loss: 3.150291483880602
Validation loss: 3.1194204895458313

Epoch: 5| Step: 3
Training loss: 3.370846205515071
Validation loss: 3.1235825332584763

Epoch: 5| Step: 4
Training loss: 3.9520073920424053
Validation loss: 3.1200746446985113

Epoch: 5| Step: 5
Training loss: 3.5408797493149757
Validation loss: 3.1184253531958426

Epoch: 5| Step: 6
Training loss: 3.9396898749819327
Validation loss: 3.1167559375736404

Epoch: 5| Step: 7
Training loss: 2.954455202231401
Validation loss: 3.117182993129355

Epoch: 5| Step: 8
Training loss: 3.0833055305945787
Validation loss: 3.1144196055760593

Epoch: 5| Step: 9
Training loss: 2.498826419030067
Validation loss: 3.116840639425004

Epoch: 5| Step: 10
Training loss: 3.044097573489764
Validation loss: 3.1177439645667104

Epoch: 72| Step: 0
Training loss: 3.0574404903930548
Validation loss: 3.1199111974469202

Epoch: 5| Step: 1
Training loss: 3.3316548572030107
Validation loss: 3.118786557354634

Epoch: 5| Step: 2
Training loss: 3.0045205072346493
Validation loss: 3.117045433394268

Epoch: 5| Step: 3
Training loss: 4.058881586054742
Validation loss: 3.1171127064870308

Epoch: 5| Step: 4
Training loss: 3.0004796598355594
Validation loss: 3.1158736456236404

Epoch: 5| Step: 5
Training loss: 3.3416225046742065
Validation loss: 3.120576158001528

Epoch: 5| Step: 6
Training loss: 2.8931336110997026
Validation loss: 3.116080852814968

Epoch: 5| Step: 7
Training loss: 3.9636874612802724
Validation loss: 3.1128478793682257

Epoch: 5| Step: 8
Training loss: 3.1669467166408847
Validation loss: 3.1126165380470123

Epoch: 5| Step: 9
Training loss: 3.534155401529571
Validation loss: 3.1130771521427327

Epoch: 5| Step: 10
Training loss: 3.665832872667491
Validation loss: 3.112071243896251

Epoch: 73| Step: 0
Training loss: 3.1241354700136736
Validation loss: 3.1132628342437165

Epoch: 5| Step: 1
Training loss: 2.7011003795107045
Validation loss: 3.1125754428165675

Epoch: 5| Step: 2
Training loss: 3.534901849012688
Validation loss: 3.1141942414609294

Epoch: 5| Step: 3
Training loss: 3.680049675937895
Validation loss: 3.11262792963615

Epoch: 5| Step: 4
Training loss: 4.266029869679656
Validation loss: 3.112785219244386

Epoch: 5| Step: 5
Training loss: 3.0710738696471616
Validation loss: 3.114676956699529

Epoch: 5| Step: 6
Training loss: 3.419925360729591
Validation loss: 3.1124087995759817

Epoch: 5| Step: 7
Training loss: 3.5022692816886543
Validation loss: 3.1126434351766403

Epoch: 5| Step: 8
Training loss: 3.129036547058789
Validation loss: 3.111167250611132

Epoch: 5| Step: 9
Training loss: 2.876561611492428
Validation loss: 3.110650078819355

Epoch: 5| Step: 10
Training loss: 3.641268693723403
Validation loss: 3.1108226410436246

Epoch: 74| Step: 0
Training loss: 3.475982411883318
Validation loss: 3.1099441608456573

Epoch: 5| Step: 1
Training loss: 3.0650998971412933
Validation loss: 3.108883339055657

Epoch: 5| Step: 2
Training loss: 3.5052924332678166
Validation loss: 3.1091896942239576

Epoch: 5| Step: 3
Training loss: 3.1323147423497533
Validation loss: 3.109850348282823

Epoch: 5| Step: 4
Training loss: 3.128848948055194
Validation loss: 3.1083435765302485

Epoch: 5| Step: 5
Training loss: 3.239602108294838
Validation loss: 3.1078737637431715

Epoch: 5| Step: 6
Training loss: 3.342529359287693
Validation loss: 3.1103745781735683

Epoch: 5| Step: 7
Training loss: 3.505101573087247
Validation loss: 3.1102114462558794

Epoch: 5| Step: 8
Training loss: 3.607904175807484
Validation loss: 3.1086335819686104

Epoch: 5| Step: 9
Training loss: 3.76738093420264
Validation loss: 3.1134207546266426

Epoch: 5| Step: 10
Training loss: 3.2941646191910445
Validation loss: 3.119368887910167

Epoch: 75| Step: 0
Training loss: 3.209507830433015
Validation loss: 3.1224632024311485

Epoch: 5| Step: 1
Training loss: 3.5821774119068945
Validation loss: 3.117344810375062

Epoch: 5| Step: 2
Training loss: 3.0232681108678454
Validation loss: 3.1106250608372266

Epoch: 5| Step: 3
Training loss: 3.3881976320707334
Validation loss: 3.1117573655666053

Epoch: 5| Step: 4
Training loss: 3.2248498098014373
Validation loss: 3.1101520993830603

Epoch: 5| Step: 5
Training loss: 3.3998490131736627
Validation loss: 3.1069551870536385

Epoch: 5| Step: 6
Training loss: 3.98700893332019
Validation loss: 3.108497089632904

Epoch: 5| Step: 7
Training loss: 3.081739443271579
Validation loss: 3.105317501141811

Epoch: 5| Step: 8
Training loss: 3.1984561295332514
Validation loss: 3.1049755779825965

Epoch: 5| Step: 9
Training loss: 3.6330112197832927
Validation loss: 3.1056209267657224

Epoch: 5| Step: 10
Training loss: 3.282544561869523
Validation loss: 3.1051666230435204

Epoch: 76| Step: 0
Training loss: 3.3681581164777903
Validation loss: 3.1086750962881555

Epoch: 5| Step: 1
Training loss: 3.8139251796782907
Validation loss: 3.1040600509707317

Epoch: 5| Step: 2
Training loss: 3.5229318598519836
Validation loss: 3.1051355355627432

Epoch: 5| Step: 3
Training loss: 3.2241485654615807
Validation loss: 3.1082203844832326

Epoch: 5| Step: 4
Training loss: 3.5109430629684457
Validation loss: 3.1139552539809303

Epoch: 5| Step: 5
Training loss: 3.2268438701469098
Validation loss: 3.1127292636092663

Epoch: 5| Step: 6
Training loss: 3.203171743656645
Validation loss: 3.10960407869479

Epoch: 5| Step: 7
Training loss: 2.906823870697843
Validation loss: 3.108575144305205

Epoch: 5| Step: 8
Training loss: 3.665978294836909
Validation loss: 3.1084296597702705

Epoch: 5| Step: 9
Training loss: 3.136913478787848
Validation loss: 3.108326195467804

Epoch: 5| Step: 10
Training loss: 3.483797444601188
Validation loss: 3.108028552990267

Epoch: 77| Step: 0
Training loss: 3.8345227400368698
Validation loss: 3.1057842973250174

Epoch: 5| Step: 1
Training loss: 3.0687289048846926
Validation loss: 3.106060586438239

Epoch: 5| Step: 2
Training loss: 3.1653683828594965
Validation loss: 3.1044489920789182

Epoch: 5| Step: 3
Training loss: 3.0738411929645015
Validation loss: 3.103380231773777

Epoch: 5| Step: 4
Training loss: 3.1307769783586012
Validation loss: 3.1036865841514922

Epoch: 5| Step: 5
Training loss: 3.124645823435293
Validation loss: 3.1020550592833187

Epoch: 5| Step: 6
Training loss: 3.5555841342121868
Validation loss: 3.10221251969658

Epoch: 5| Step: 7
Training loss: 3.793173661673336
Validation loss: 3.1044522622281767

Epoch: 5| Step: 8
Training loss: 3.536994919591808
Validation loss: 3.10419298650718

Epoch: 5| Step: 9
Training loss: 3.0190737280218802
Validation loss: 3.0977124837001684

Epoch: 5| Step: 10
Training loss: 3.6881480536542766
Validation loss: 3.100198660104237

Epoch: 78| Step: 0
Training loss: 3.5200491639518594
Validation loss: 3.0996836562742014

Epoch: 5| Step: 1
Training loss: 2.8307139312324785
Validation loss: 3.0985457298285533

Epoch: 5| Step: 2
Training loss: 4.277576513358554
Validation loss: 3.0982916691470885

Epoch: 5| Step: 3
Training loss: 3.505163471148337
Validation loss: 3.100574214759081

Epoch: 5| Step: 4
Training loss: 2.721794440810574
Validation loss: 3.0998970631906486

Epoch: 5| Step: 5
Training loss: 3.3949117677709544
Validation loss: 3.1016968856879386

Epoch: 5| Step: 6
Training loss: 3.6271432262882572
Validation loss: 3.101725796690906

Epoch: 5| Step: 7
Training loss: 3.8369622813685593
Validation loss: 3.105568240622856

Epoch: 5| Step: 8
Training loss: 3.0734386108582608
Validation loss: 3.1031784865441603

Epoch: 5| Step: 9
Training loss: 2.8185084271158645
Validation loss: 3.101979081888875

Epoch: 5| Step: 10
Training loss: 3.0209638545460344
Validation loss: 3.1005996346455778

Epoch: 79| Step: 0
Training loss: 2.5795958051553063
Validation loss: 3.0988533121487265

Epoch: 5| Step: 1
Training loss: 3.313205715794499
Validation loss: 3.100864255656459

Epoch: 5| Step: 2
Training loss: 3.888968241351267
Validation loss: 3.100137104637286

Epoch: 5| Step: 3
Training loss: 3.4160887686923385
Validation loss: 3.102135515623612

Epoch: 5| Step: 4
Training loss: 3.075929739974369
Validation loss: 3.0987492906618375

Epoch: 5| Step: 5
Training loss: 3.383872203163309
Validation loss: 3.0956541391429733

Epoch: 5| Step: 6
Training loss: 3.3276581772625247
Validation loss: 3.095824392136855

Epoch: 5| Step: 7
Training loss: 3.4247023515773476
Validation loss: 3.094133151365332

Epoch: 5| Step: 8
Training loss: 2.9970391285238223
Validation loss: 3.0960232265720746

Epoch: 5| Step: 9
Training loss: 3.515412048671996
Validation loss: 3.096625845837749

Epoch: 5| Step: 10
Training loss: 3.9573380406892373
Validation loss: 3.097332006573433

Epoch: 80| Step: 0
Training loss: 3.9243580530113285
Validation loss: 3.0947347304149346

Epoch: 5| Step: 1
Training loss: 3.4927405958376028
Validation loss: 3.0935762931920676

Epoch: 5| Step: 2
Training loss: 3.210839485844383
Validation loss: 3.093143150463931

Epoch: 5| Step: 3
Training loss: 2.7882583270916976
Validation loss: 3.094922034836049

Epoch: 5| Step: 4
Training loss: 3.4967731859863886
Validation loss: 3.095269022618835

Epoch: 5| Step: 5
Training loss: 2.5696963235470967
Validation loss: 3.0989396226124537

Epoch: 5| Step: 6
Training loss: 4.555522024346566
Validation loss: 3.1023550325166003

Epoch: 5| Step: 7
Training loss: 2.1533123405464676
Validation loss: 3.0942515653090026

Epoch: 5| Step: 8
Training loss: 2.9698551730927063
Validation loss: 3.090096406283299

Epoch: 5| Step: 9
Training loss: 3.3280055064926075
Validation loss: 3.090930541048917

Epoch: 5| Step: 10
Training loss: 3.8947055972760154
Validation loss: 3.0913017714570064

Epoch: 81| Step: 0
Training loss: 3.256282602685124
Validation loss: 3.0902156203393054

Epoch: 5| Step: 1
Training loss: 3.7115137556279287
Validation loss: 3.0904503423915846

Epoch: 5| Step: 2
Training loss: 3.4995182250728725
Validation loss: 3.0897218448819306

Epoch: 5| Step: 3
Training loss: 2.9488044902558275
Validation loss: 3.0912452627371225

Epoch: 5| Step: 4
Training loss: 3.4148240276701833
Validation loss: 3.089200249665573

Epoch: 5| Step: 5
Training loss: 2.785005840932313
Validation loss: 3.0897099332284697

Epoch: 5| Step: 6
Training loss: 3.3229936612734865
Validation loss: 3.090360579457318

Epoch: 5| Step: 7
Training loss: 4.02865990519352
Validation loss: 3.093014948500815

Epoch: 5| Step: 8
Training loss: 2.7351151690738993
Validation loss: 3.0931957507031136

Epoch: 5| Step: 9
Training loss: 3.699609560599457
Validation loss: 3.093455012512793

Epoch: 5| Step: 10
Training loss: 3.3132861661975728
Validation loss: 3.0893749377511743

Epoch: 82| Step: 0
Training loss: 3.5262133032056626
Validation loss: 3.090717757552716

Epoch: 5| Step: 1
Training loss: 3.050983026647976
Validation loss: 3.0906065525655007

Epoch: 5| Step: 2
Training loss: 3.801484500635158
Validation loss: 3.0906412882751884

Epoch: 5| Step: 3
Training loss: 3.5794396796293384
Validation loss: 3.0882757833633594

Epoch: 5| Step: 4
Training loss: 3.666653950987066
Validation loss: 3.086348112926633

Epoch: 5| Step: 5
Training loss: 2.5407389109695235
Validation loss: 3.0862855975832906

Epoch: 5| Step: 6
Training loss: 2.2813779194122223
Validation loss: 3.0877185496578576

Epoch: 5| Step: 7
Training loss: 3.8800543769486806
Validation loss: 3.0932354640577335

Epoch: 5| Step: 8
Training loss: 3.848746301216214
Validation loss: 3.085913428112354

Epoch: 5| Step: 9
Training loss: 3.211037144657869
Validation loss: 3.08676764923048

Epoch: 5| Step: 10
Training loss: 3.0793552167166776
Validation loss: 3.0863954182770317

Epoch: 83| Step: 0
Training loss: 3.4410767413724805
Validation loss: 3.0899609411186786

Epoch: 5| Step: 1
Training loss: 3.4029676388735615
Validation loss: 3.0865540272420047

Epoch: 5| Step: 2
Training loss: 3.09692066209005
Validation loss: 3.0860858998378413

Epoch: 5| Step: 3
Training loss: 3.2537951685158713
Validation loss: 3.0844407015104935

Epoch: 5| Step: 4
Training loss: 3.5480949555671004
Validation loss: 3.0841804417182748

Epoch: 5| Step: 5
Training loss: 3.267706394813132
Validation loss: 3.0835754833790654

Epoch: 5| Step: 6
Training loss: 3.627421655420133
Validation loss: 3.08359003259491

Epoch: 5| Step: 7
Training loss: 3.877945303615309
Validation loss: 3.0817083740216096

Epoch: 5| Step: 8
Training loss: 2.5495663330222875
Validation loss: 3.0831454374160163

Epoch: 5| Step: 9
Training loss: 3.6620294262106383
Validation loss: 3.0823786085275504

Epoch: 5| Step: 10
Training loss: 2.866550801027787
Validation loss: 3.0808960101051617

Epoch: 84| Step: 0
Training loss: 2.7776113131765183
Validation loss: 3.0801023914780776

Epoch: 5| Step: 1
Training loss: 3.8152102233241014
Validation loss: 3.080928189248042

Epoch: 5| Step: 2
Training loss: 2.754405740662021
Validation loss: 3.078998051043191

Epoch: 5| Step: 3
Training loss: 3.3132802656082747
Validation loss: 3.0786691928654677

Epoch: 5| Step: 4
Training loss: 3.6753357506830615
Validation loss: 3.0779122740861435

Epoch: 5| Step: 5
Training loss: 3.299982423446548
Validation loss: 3.081543119746033

Epoch: 5| Step: 6
Training loss: 3.676228900370253
Validation loss: 3.0766627547527725

Epoch: 5| Step: 7
Training loss: 3.6378755460803673
Validation loss: 3.0774258321908166

Epoch: 5| Step: 8
Training loss: 3.272269320477351
Validation loss: 3.0734168533913007

Epoch: 5| Step: 9
Training loss: 3.7127479393364915
Validation loss: 3.0707909964413846

Epoch: 5| Step: 10
Training loss: 2.397454274589774
Validation loss: 3.0709756957753664

Epoch: 85| Step: 0
Training loss: 2.838723907686738
Validation loss: 3.0714936092808527

Epoch: 5| Step: 1
Training loss: 3.246049974791327
Validation loss: 3.0702274881343055

Epoch: 5| Step: 2
Training loss: 3.045136723698236
Validation loss: 3.06697381899246

Epoch: 5| Step: 3
Training loss: 3.3118065162110346
Validation loss: 3.0703868905487806

Epoch: 5| Step: 4
Training loss: 3.5292224295638306
Validation loss: 3.067143109665758

Epoch: 5| Step: 5
Training loss: 3.4748013611149835
Validation loss: 3.0667699329204576

Epoch: 5| Step: 6
Training loss: 3.447426352927979
Validation loss: 3.0659075261742603

Epoch: 5| Step: 7
Training loss: 3.01583086803371
Validation loss: 3.0650862354007735

Epoch: 5| Step: 8
Training loss: 3.966479034687715
Validation loss: 3.0672812809215277

Epoch: 5| Step: 9
Training loss: 3.3056944987982124
Validation loss: 3.066593350215759

Epoch: 5| Step: 10
Training loss: 3.3972860556097033
Validation loss: 3.0668996867061686

Epoch: 86| Step: 0
Training loss: 3.0991222861807417
Validation loss: 3.068761169842328

Epoch: 5| Step: 1
Training loss: 2.9506006502206494
Validation loss: 3.0642800882471333

Epoch: 5| Step: 2
Training loss: 3.024037540636719
Validation loss: 3.0635396612822254

Epoch: 5| Step: 3
Training loss: 2.845128322717535
Validation loss: 3.0639012010677313

Epoch: 5| Step: 4
Training loss: 3.518257206885777
Validation loss: 3.0655756815004507

Epoch: 5| Step: 5
Training loss: 3.2522947572989893
Validation loss: 3.0636264620349674

Epoch: 5| Step: 6
Training loss: 3.490522085668846
Validation loss: 3.065741095723193

Epoch: 5| Step: 7
Training loss: 3.9491933940673403
Validation loss: 3.062784251653062

Epoch: 5| Step: 8
Training loss: 3.6312324615422655
Validation loss: 3.0640577364743233

Epoch: 5| Step: 9
Training loss: 3.0811394971489223
Validation loss: 3.062959818571619

Epoch: 5| Step: 10
Training loss: 3.6516502986827244
Validation loss: 3.0611259964353708

Epoch: 87| Step: 0
Training loss: 2.8770704692209543
Validation loss: 3.065943727397377

Epoch: 5| Step: 1
Training loss: 3.8108483160577893
Validation loss: 3.0617297997335577

Epoch: 5| Step: 2
Training loss: 3.3553075962647236
Validation loss: 3.0619612021637246

Epoch: 5| Step: 3
Training loss: 3.953246827189591
Validation loss: 3.0626408785440034

Epoch: 5| Step: 4
Training loss: 3.1944143063510277
Validation loss: 3.0603128550249346

Epoch: 5| Step: 5
Training loss: 3.1632113595271347
Validation loss: 3.0621270510802545

Epoch: 5| Step: 6
Training loss: 2.9531035245891597
Validation loss: 3.0611321393661797

Epoch: 5| Step: 7
Training loss: 3.552674916395317
Validation loss: 3.0581271519824633

Epoch: 5| Step: 8
Training loss: 2.7059958323173823
Validation loss: 3.0609594709961327

Epoch: 5| Step: 9
Training loss: 3.3709356065346783
Validation loss: 3.05829958795805

Epoch: 5| Step: 10
Training loss: 3.4863430332751975
Validation loss: 3.0596279014241428

Epoch: 88| Step: 0
Training loss: 3.5920589282973006
Validation loss: 3.0589630784473263

Epoch: 5| Step: 1
Training loss: 3.712700033739239
Validation loss: 3.0614070720996636

Epoch: 5| Step: 2
Training loss: 3.339353005566883
Validation loss: 3.0590473675222905

Epoch: 5| Step: 3
Training loss: 3.570614858299421
Validation loss: 3.0582876679221505

Epoch: 5| Step: 4
Training loss: 2.9180475145201235
Validation loss: 3.06231245588786

Epoch: 5| Step: 5
Training loss: 3.460098750518876
Validation loss: 3.0616740187931146

Epoch: 5| Step: 6
Training loss: 3.797451273823403
Validation loss: 3.062739004017538

Epoch: 5| Step: 7
Training loss: 2.928738453053055
Validation loss: 3.0600125086560404

Epoch: 5| Step: 8
Training loss: 2.868149931070482
Validation loss: 3.0589459447930163

Epoch: 5| Step: 9
Training loss: 2.2464511222149333
Validation loss: 3.0635153171658467

Epoch: 5| Step: 10
Training loss: 3.8957685305395753
Validation loss: 3.058489127051266

Epoch: 89| Step: 0
Training loss: 3.3543076732368844
Validation loss: 3.0589373410542606

Epoch: 5| Step: 1
Training loss: 3.921083408424921
Validation loss: 3.0563124664155

Epoch: 5| Step: 2
Training loss: 3.0871431337518973
Validation loss: 3.0555410487954586

Epoch: 5| Step: 3
Training loss: 3.0124423769429773
Validation loss: 3.055037364169658

Epoch: 5| Step: 4
Training loss: 3.0421730734743164
Validation loss: 3.0530496644065015

Epoch: 5| Step: 5
Training loss: 3.391815679652467
Validation loss: 3.056001065485693

Epoch: 5| Step: 6
Training loss: 3.765077543232699
Validation loss: 3.054492120154427

Epoch: 5| Step: 7
Training loss: 3.303364229516497
Validation loss: 3.056353156423723

Epoch: 5| Step: 8
Training loss: 3.5902195049962025
Validation loss: 3.0540491784238517

Epoch: 5| Step: 9
Training loss: 2.9023550862518346
Validation loss: 3.0556144314037947

Epoch: 5| Step: 10
Training loss: 2.977012780441103
Validation loss: 3.053893533589837

Epoch: 90| Step: 0
Training loss: 3.69045992230933
Validation loss: 3.052352647001925

Epoch: 5| Step: 1
Training loss: 3.419456428474466
Validation loss: 3.0546762473409466

Epoch: 5| Step: 2
Training loss: 3.733675456265545
Validation loss: 3.052258996984145

Epoch: 5| Step: 3
Training loss: 3.041902053991729
Validation loss: 3.0550189161969574

Epoch: 5| Step: 4
Training loss: 2.988804111988008
Validation loss: 3.0539302994730657

Epoch: 5| Step: 5
Training loss: 3.719787709321191
Validation loss: 3.0534729958292455

Epoch: 5| Step: 6
Training loss: 3.818218382747007
Validation loss: 3.049195212718687

Epoch: 5| Step: 7
Training loss: 2.4808642455065066
Validation loss: 3.0509467319353223

Epoch: 5| Step: 8
Training loss: 3.4418640178659685
Validation loss: 3.051510893908723

Epoch: 5| Step: 9
Training loss: 2.744439051138469
Validation loss: 3.0520311025145554

Epoch: 5| Step: 10
Training loss: 3.119379253013859
Validation loss: 3.050376071603979

Epoch: 91| Step: 0
Training loss: 2.5696801796305193
Validation loss: 3.051208144382604

Epoch: 5| Step: 1
Training loss: 2.400470679541286
Validation loss: 3.0502945231751637

Epoch: 5| Step: 2
Training loss: 3.2021415875574797
Validation loss: 3.05235351208856

Epoch: 5| Step: 3
Training loss: 2.893334021443697
Validation loss: 3.049564712652935

Epoch: 5| Step: 4
Training loss: 2.870878831773231
Validation loss: 3.049922573169939

Epoch: 5| Step: 5
Training loss: 3.8047071765806004
Validation loss: 3.049003566438631

Epoch: 5| Step: 6
Training loss: 3.762593168708311
Validation loss: 3.0506070242879155

Epoch: 5| Step: 7
Training loss: 3.141872632655809
Validation loss: 3.04907441500814

Epoch: 5| Step: 8
Training loss: 3.790492592155606
Validation loss: 3.0487252657851642

Epoch: 5| Step: 9
Training loss: 3.596012365334778
Validation loss: 3.0496859751425753

Epoch: 5| Step: 10
Training loss: 4.11589525127674
Validation loss: 3.0497719294638808

Epoch: 92| Step: 0
Training loss: 3.168553760478814
Validation loss: 3.0490541198774928

Epoch: 5| Step: 1
Training loss: 3.2993517788104008
Validation loss: 3.051325922059999

Epoch: 5| Step: 2
Training loss: 3.527428643946574
Validation loss: 3.0516355066217424

Epoch: 5| Step: 3
Training loss: 3.3481762547830813
Validation loss: 3.0494931239087557

Epoch: 5| Step: 4
Training loss: 2.826267960502721
Validation loss: 3.0517546883384545

Epoch: 5| Step: 5
Training loss: 3.7094226194569377
Validation loss: 3.0522615074915156

Epoch: 5| Step: 6
Training loss: 3.927156213274679
Validation loss: 3.049578149699039

Epoch: 5| Step: 7
Training loss: 2.4583890768509225
Validation loss: 3.0470069623188496

Epoch: 5| Step: 8
Training loss: 3.12089620067665
Validation loss: 3.0446094328249647

Epoch: 5| Step: 9
Training loss: 3.6508743022845285
Validation loss: 3.0471604450426777

Epoch: 5| Step: 10
Training loss: 3.1650304750057057
Validation loss: 3.045159444279161

Epoch: 93| Step: 0
Training loss: 3.5615387004402868
Validation loss: 3.0465578463698106

Epoch: 5| Step: 1
Training loss: 3.482486640811444
Validation loss: 3.045720920806068

Epoch: 5| Step: 2
Training loss: 3.7033193030264697
Validation loss: 3.0451985625463087

Epoch: 5| Step: 3
Training loss: 3.022569793072064
Validation loss: 3.046699444404278

Epoch: 5| Step: 4
Training loss: 3.523121348066672
Validation loss: 3.047318442747647

Epoch: 5| Step: 5
Training loss: 2.962588209939472
Validation loss: 3.044039336194442

Epoch: 5| Step: 6
Training loss: 3.41502523923961
Validation loss: 3.0442971505850283

Epoch: 5| Step: 7
Training loss: 3.7671371526213586
Validation loss: 3.0435927784275765

Epoch: 5| Step: 8
Training loss: 3.0603927836428677
Validation loss: 3.0410320604968635

Epoch: 5| Step: 9
Training loss: 2.696090807010854
Validation loss: 3.043953827229377

Epoch: 5| Step: 10
Training loss: 3.009479328379229
Validation loss: 3.045415716785983

Epoch: 94| Step: 0
Training loss: 2.246242670844364
Validation loss: 3.0457494431566285

Epoch: 5| Step: 1
Training loss: 3.47859348593377
Validation loss: 3.044551729070888

Epoch: 5| Step: 2
Training loss: 2.5590404324424982
Validation loss: 3.0425515353595145

Epoch: 5| Step: 3
Training loss: 3.5437347357957742
Validation loss: 3.047183158947365

Epoch: 5| Step: 4
Training loss: 2.968924587537032
Validation loss: 3.0422846112619375

Epoch: 5| Step: 5
Training loss: 3.817389932480889
Validation loss: 3.0464426361247385

Epoch: 5| Step: 6
Training loss: 3.2852800597675014
Validation loss: 3.0428536128055033

Epoch: 5| Step: 7
Training loss: 3.299911185716695
Validation loss: 3.041112161197217

Epoch: 5| Step: 8
Training loss: 3.4001045435372164
Validation loss: 3.0410897172304945

Epoch: 5| Step: 9
Training loss: 3.5984234483703745
Validation loss: 3.040850216370357

Epoch: 5| Step: 10
Training loss: 3.942239724265776
Validation loss: 3.039239906240525

Epoch: 95| Step: 0
Training loss: 2.758081266366367
Validation loss: 3.0382575718913136

Epoch: 5| Step: 1
Training loss: 3.118786394598751
Validation loss: 3.041940273622206

Epoch: 5| Step: 2
Training loss: 3.3340882082359267
Validation loss: 3.0387276528457767

Epoch: 5| Step: 3
Training loss: 3.9692786157552846
Validation loss: 3.0421059853512964

Epoch: 5| Step: 4
Training loss: 3.37807931648581
Validation loss: 3.038257223407481

Epoch: 5| Step: 5
Training loss: 3.7030387256728776
Validation loss: 3.038695877222301

Epoch: 5| Step: 6
Training loss: 3.3676790024746266
Validation loss: 3.0388846767816

Epoch: 5| Step: 7
Training loss: 3.037727592324713
Validation loss: 3.037352108086436

Epoch: 5| Step: 8
Training loss: 3.2634573865410794
Validation loss: 3.036892893060573

Epoch: 5| Step: 9
Training loss: 2.9180465340619866
Validation loss: 3.0394132602414783

Epoch: 5| Step: 10
Training loss: 3.3839292731142376
Validation loss: 3.041411475246444

Epoch: 96| Step: 0
Training loss: 3.1834131107686097
Validation loss: 3.0415082096007136

Epoch: 5| Step: 1
Training loss: 4.021831540078174
Validation loss: 3.0471117624447617

Epoch: 5| Step: 2
Training loss: 3.295415329176652
Validation loss: 3.048634458472667

Epoch: 5| Step: 3
Training loss: 2.9046337596729868
Validation loss: 3.0528628342135953

Epoch: 5| Step: 4
Training loss: 3.577204023549486
Validation loss: 3.0600757911283045

Epoch: 5| Step: 5
Training loss: 3.4872983976770495
Validation loss: 3.0522088527575404

Epoch: 5| Step: 6
Training loss: 3.1020854826117645
Validation loss: 3.0455450301614935

Epoch: 5| Step: 7
Training loss: 2.7836988148225172
Validation loss: 3.0378969077088285

Epoch: 5| Step: 8
Training loss: 3.118161156972887
Validation loss: 3.0368855808889883

Epoch: 5| Step: 9
Training loss: 3.852542280575335
Validation loss: 3.037813220849014

Epoch: 5| Step: 10
Training loss: 2.7458675720056025
Validation loss: 3.035892359880204

Epoch: 97| Step: 0
Training loss: 3.2627379875052585
Validation loss: 3.0342609525557958

Epoch: 5| Step: 1
Training loss: 3.450549792282174
Validation loss: 3.0341299077551436

Epoch: 5| Step: 2
Training loss: 3.2822251097140493
Validation loss: 3.033795227692274

Epoch: 5| Step: 3
Training loss: 3.0239952814882796
Validation loss: 3.031781054401666

Epoch: 5| Step: 4
Training loss: 3.5179522462068467
Validation loss: 3.0314360869003565

Epoch: 5| Step: 5
Training loss: 3.398462896142537
Validation loss: 3.033709822932886

Epoch: 5| Step: 6
Training loss: 3.5008737290946996
Validation loss: 3.0331090514991543

Epoch: 5| Step: 7
Training loss: 2.7004635448258867
Validation loss: 3.0339976946142584

Epoch: 5| Step: 8
Training loss: 3.5295520852749087
Validation loss: 3.0309449272702977

Epoch: 5| Step: 9
Training loss: 3.2846445599103613
Validation loss: 3.0308307154326664

Epoch: 5| Step: 10
Training loss: 3.350237391017519
Validation loss: 3.0352982067792413

Epoch: 98| Step: 0
Training loss: 3.690035966320553
Validation loss: 3.0347469428290905

Epoch: 5| Step: 1
Training loss: 3.470776490062379
Validation loss: 3.036680637075926

Epoch: 5| Step: 2
Training loss: 2.9893868588916788
Validation loss: 3.031003811151196

Epoch: 5| Step: 3
Training loss: 3.3375611831829026
Validation loss: 3.033036673286352

Epoch: 5| Step: 4
Training loss: 3.562959072583528
Validation loss: 3.0309987549198425

Epoch: 5| Step: 5
Training loss: 4.050167438201267
Validation loss: 3.0331851155840197

Epoch: 5| Step: 6
Training loss: 3.3807849049423906
Validation loss: 3.031471938666751

Epoch: 5| Step: 7
Training loss: 3.0162009840459354
Validation loss: 3.0282711009935244

Epoch: 5| Step: 8
Training loss: 3.303606438175112
Validation loss: 3.028799628045241

Epoch: 5| Step: 9
Training loss: 2.748933498612009
Validation loss: 3.0295108964904895

Epoch: 5| Step: 10
Training loss: 2.3554809974870747
Validation loss: 3.0293615692136866

Epoch: 99| Step: 0
Training loss: 3.2792151544872663
Validation loss: 3.0298133052817824

Epoch: 5| Step: 1
Training loss: 3.4165931941870733
Validation loss: 3.029655727414134

Epoch: 5| Step: 2
Training loss: 3.752385715724106
Validation loss: 3.0296764664217757

Epoch: 5| Step: 3
Training loss: 3.47243050183699
Validation loss: 3.0284276724342365

Epoch: 5| Step: 4
Training loss: 3.5599122938860632
Validation loss: 3.0303140863000615

Epoch: 5| Step: 5
Training loss: 2.934851243572562
Validation loss: 3.02754622836527

Epoch: 5| Step: 6
Training loss: 3.147643488490977
Validation loss: 3.029164935007675

Epoch: 5| Step: 7
Training loss: 3.186034520174745
Validation loss: 3.030998213603173

Epoch: 5| Step: 8
Training loss: 2.376051820440364
Validation loss: 3.0292840639499103

Epoch: 5| Step: 9
Training loss: 3.3483622461959652
Validation loss: 3.031037844494334

Epoch: 5| Step: 10
Training loss: 3.686477131331692
Validation loss: 3.029482472585705

Epoch: 100| Step: 0
Training loss: 3.7427909221219866
Validation loss: 3.027583413271797

Epoch: 5| Step: 1
Training loss: 3.2837334816658434
Validation loss: 3.028621315677224

Epoch: 5| Step: 2
Training loss: 2.099740411972027
Validation loss: 3.0282605789683315

Epoch: 5| Step: 3
Training loss: 3.7614814469542783
Validation loss: 3.027119130598316

Epoch: 5| Step: 4
Training loss: 3.271885907028367
Validation loss: 3.027612270761271

Epoch: 5| Step: 5
Training loss: 3.1830694784958182
Validation loss: 3.0268434363178427

Epoch: 5| Step: 6
Training loss: 3.210156125226254
Validation loss: 3.0252473423435813

Epoch: 5| Step: 7
Training loss: 3.630758250255965
Validation loss: 3.0250644391880614

Epoch: 5| Step: 8
Training loss: 3.505337596095083
Validation loss: 3.024021282362272

Epoch: 5| Step: 9
Training loss: 3.0872484730185348
Validation loss: 3.0237189632465795

Epoch: 5| Step: 10
Training loss: 3.183030529167035
Validation loss: 3.0236266248907637

Epoch: 101| Step: 0
Training loss: 2.648155625008454
Validation loss: 3.021862915108557

Epoch: 5| Step: 1
Training loss: 3.839447342521589
Validation loss: 3.0227628515181757

Epoch: 5| Step: 2
Training loss: 3.495292495035929
Validation loss: 3.0227081478165094

Epoch: 5| Step: 3
Training loss: 2.9611990216795787
Validation loss: 3.0220524167854372

Epoch: 5| Step: 4
Training loss: 2.4545861041752146
Validation loss: 3.024104615903507

Epoch: 5| Step: 5
Training loss: 3.9564570078997305
Validation loss: 3.023066651924644

Epoch: 5| Step: 6
Training loss: 2.653777284270803
Validation loss: 3.024364764545374

Epoch: 5| Step: 7
Training loss: 3.4121870742798985
Validation loss: 3.0253772296650148

Epoch: 5| Step: 8
Training loss: 3.852959122378313
Validation loss: 3.02154296217482

Epoch: 5| Step: 9
Training loss: 3.3421550048275654
Validation loss: 3.021895140903262

Epoch: 5| Step: 10
Training loss: 3.218187301486085
Validation loss: 3.0203683749212598

Epoch: 102| Step: 0
Training loss: 4.151690972766351
Validation loss: 3.0214677059007746

Epoch: 5| Step: 1
Training loss: 3.5800910445842304
Validation loss: 3.0226825877026267

Epoch: 5| Step: 2
Training loss: 2.4924861525721984
Validation loss: 3.0211473895064254

Epoch: 5| Step: 3
Training loss: 3.1201899321527717
Validation loss: 3.0214824048506435

Epoch: 5| Step: 4
Training loss: 2.937784546401703
Validation loss: 3.021301800672838

Epoch: 5| Step: 5
Training loss: 3.4600626440386
Validation loss: 3.0196965444604427

Epoch: 5| Step: 6
Training loss: 3.3588023562622165
Validation loss: 3.020432960758812

Epoch: 5| Step: 7
Training loss: 3.483280848300873
Validation loss: 3.0199047275209367

Epoch: 5| Step: 8
Training loss: 3.4201835736982615
Validation loss: 3.019670810283209

Epoch: 5| Step: 9
Training loss: 3.181846242013039
Validation loss: 3.019281388532637

Epoch: 5| Step: 10
Training loss: 2.6653319435872964
Validation loss: 3.0199975497914893

Epoch: 103| Step: 0
Training loss: 3.165752948310453
Validation loss: 3.018993648900069

Epoch: 5| Step: 1
Training loss: 3.5553256960584796
Validation loss: 3.019665538111756

Epoch: 5| Step: 2
Training loss: 3.155102511764271
Validation loss: 3.019366785367535

Epoch: 5| Step: 3
Training loss: 3.057778124257864
Validation loss: 3.0197633952451874

Epoch: 5| Step: 4
Training loss: 3.115016554150137
Validation loss: 3.0198949734786305

Epoch: 5| Step: 5
Training loss: 3.6330334011719136
Validation loss: 3.0181079809630664

Epoch: 5| Step: 6
Training loss: 3.463986261653307
Validation loss: 3.0173852140120525

Epoch: 5| Step: 7
Training loss: 2.581219290118846
Validation loss: 3.0195533524413656

Epoch: 5| Step: 8
Training loss: 3.310036660996907
Validation loss: 3.017320755805994

Epoch: 5| Step: 9
Training loss: 3.615674882839777
Validation loss: 3.0192622024415123

Epoch: 5| Step: 10
Training loss: 3.4297941360753614
Validation loss: 3.018222801646792

Epoch: 104| Step: 0
Training loss: 3.8758108459708294
Validation loss: 3.0166229156039135

Epoch: 5| Step: 1
Training loss: 3.3246206540425227
Validation loss: 3.0184179735354792

Epoch: 5| Step: 2
Training loss: 3.193797752784819
Validation loss: 3.0184932183655726

Epoch: 5| Step: 3
Training loss: 3.756854849307416
Validation loss: 3.013689077202205

Epoch: 5| Step: 4
Training loss: 3.042646711788332
Validation loss: 3.0154074117984817

Epoch: 5| Step: 5
Training loss: 3.059454824713529
Validation loss: 3.013306711231575

Epoch: 5| Step: 6
Training loss: 2.845833486740384
Validation loss: 3.0109104064277217

Epoch: 5| Step: 7
Training loss: 3.041127736322559
Validation loss: 3.0131853613030524

Epoch: 5| Step: 8
Training loss: 3.2779326608850394
Validation loss: 3.0128033849418876

Epoch: 5| Step: 9
Training loss: 3.4481406854573877
Validation loss: 3.013403277548692

Epoch: 5| Step: 10
Training loss: 3.1619273575721167
Validation loss: 3.0112547456031393

Epoch: 105| Step: 0
Training loss: 3.781357566627612
Validation loss: 3.0123006332697018

Epoch: 5| Step: 1
Training loss: 3.304291829981224
Validation loss: 3.011105448647348

Epoch: 5| Step: 2
Training loss: 3.270051866872471
Validation loss: 3.010100829726701

Epoch: 5| Step: 3
Training loss: 3.410303206625564
Validation loss: 3.0122660980149725

Epoch: 5| Step: 4
Training loss: 3.4127880659539462
Validation loss: 3.0121947956187602

Epoch: 5| Step: 5
Training loss: 3.4793899525395964
Validation loss: 3.0135860190438333

Epoch: 5| Step: 6
Training loss: 2.675889863643011
Validation loss: 3.0114561093857004

Epoch: 5| Step: 7
Training loss: 3.534817134546371
Validation loss: 3.013298159247092

Epoch: 5| Step: 8
Training loss: 2.5649460074112787
Validation loss: 3.0139212879657165

Epoch: 5| Step: 9
Training loss: 3.5706945836735304
Validation loss: 3.013083131647245

Epoch: 5| Step: 10
Training loss: 2.8467505418390524
Validation loss: 3.0133434439919733

Epoch: 106| Step: 0
Training loss: 2.9693835736863337
Validation loss: 3.0138228132767626

Epoch: 5| Step: 1
Training loss: 3.7131506815241977
Validation loss: 3.0105089157236824

Epoch: 5| Step: 2
Training loss: 3.032550965185138
Validation loss: 3.0101441654137244

Epoch: 5| Step: 3
Training loss: 3.22183968111173
Validation loss: 3.0113294968704682

Epoch: 5| Step: 4
Training loss: 3.2707677619986546
Validation loss: 3.0099057096316417

Epoch: 5| Step: 5
Training loss: 3.3281251432750114
Validation loss: 3.0131786552310547

Epoch: 5| Step: 6
Training loss: 2.8984787930325915
Validation loss: 3.010510217764564

Epoch: 5| Step: 7
Training loss: 3.7424162155690537
Validation loss: 3.007885681634317

Epoch: 5| Step: 8
Training loss: 3.238911271785855
Validation loss: 3.007339760437585

Epoch: 5| Step: 9
Training loss: 3.4434299991871127
Validation loss: 3.009628694927486

Epoch: 5| Step: 10
Training loss: 3.148445829849015
Validation loss: 3.008675804093642

Epoch: 107| Step: 0
Training loss: 3.3142345853206656
Validation loss: 3.0084380278340626

Epoch: 5| Step: 1
Training loss: 3.392041732207478
Validation loss: 3.0092488450160344

Epoch: 5| Step: 2
Training loss: 3.1529829282482953
Validation loss: 3.0091817555325977

Epoch: 5| Step: 3
Training loss: 2.340082070468277
Validation loss: 3.010444351161532

Epoch: 5| Step: 4
Training loss: 2.8460424217016667
Validation loss: 3.0141417587544703

Epoch: 5| Step: 5
Training loss: 3.787508994113831
Validation loss: 3.01409003372233

Epoch: 5| Step: 6
Training loss: 3.279496078393484
Validation loss: 3.016416753169458

Epoch: 5| Step: 7
Training loss: 3.54021241493658
Validation loss: 3.0160662543792705

Epoch: 5| Step: 8
Training loss: 4.124247395610524
Validation loss: 3.014973503704764

Epoch: 5| Step: 9
Training loss: 2.18260768401874
Validation loss: 3.012273666545371

Epoch: 5| Step: 10
Training loss: 3.6836189924489697
Validation loss: 3.0166345983035945

Epoch: 108| Step: 0
Training loss: 3.0383875864792804
Validation loss: 3.008782359410177

Epoch: 5| Step: 1
Training loss: 3.659790020740349
Validation loss: 3.0081387634140424

Epoch: 5| Step: 2
Training loss: 3.4810164477697536
Validation loss: 3.005446265594133

Epoch: 5| Step: 3
Training loss: 3.220352662718453
Validation loss: 3.004907528393566

Epoch: 5| Step: 4
Training loss: 3.58297121450885
Validation loss: 3.004027122217327

Epoch: 5| Step: 5
Training loss: 2.762236507501931
Validation loss: 3.0047910385692633

Epoch: 5| Step: 6
Training loss: 3.167529055636008
Validation loss: 3.0035241289071632

Epoch: 5| Step: 7
Training loss: 3.2103905130682975
Validation loss: 3.003295105727992

Epoch: 5| Step: 8
Training loss: 3.3365638019916153
Validation loss: 3.00192125389062

Epoch: 5| Step: 9
Training loss: 2.9070881281073198
Validation loss: 3.0039392453472757

Epoch: 5| Step: 10
Training loss: 3.6291486743316033
Validation loss: 3.0027075755589023

Epoch: 109| Step: 0
Training loss: 3.5272672355523302
Validation loss: 3.001986867698599

Epoch: 5| Step: 1
Training loss: 3.669473975004437
Validation loss: 3.0033304432379344

Epoch: 5| Step: 2
Training loss: 3.5303273303718328
Validation loss: 3.002360792572412

Epoch: 5| Step: 3
Training loss: 3.1329424823993275
Validation loss: 3.0016554602557353

Epoch: 5| Step: 4
Training loss: 3.7677544235660143
Validation loss: 3.001259744370577

Epoch: 5| Step: 5
Training loss: 2.6196382349991167
Validation loss: 3.0005527058980146

Epoch: 5| Step: 6
Training loss: 2.7961584270763886
Validation loss: 3.002179405271093

Epoch: 5| Step: 7
Training loss: 2.9004001604430796
Validation loss: 3.0017288483652425

Epoch: 5| Step: 8
Training loss: 3.4453401802317765
Validation loss: 3.0012538914673765

Epoch: 5| Step: 9
Training loss: 2.5639761417963083
Validation loss: 3.0010184282131367

Epoch: 5| Step: 10
Training loss: 3.8598721450424
Validation loss: 3.000576556939659

Epoch: 110| Step: 0
Training loss: 3.1935203395020793
Validation loss: 3.002455932372214

Epoch: 5| Step: 1
Training loss: 3.3398318998784657
Validation loss: 3.001865970548058

Epoch: 5| Step: 2
Training loss: 3.1031908041746736
Validation loss: 3.0017389996422597

Epoch: 5| Step: 3
Training loss: 3.771843551845974
Validation loss: 3.0009564700306504

Epoch: 5| Step: 4
Training loss: 3.0985375554121988
Validation loss: 3.0008645794397637

Epoch: 5| Step: 5
Training loss: 2.7694710750525955
Validation loss: 3.0015922067516336

Epoch: 5| Step: 6
Training loss: 2.9476700714458626
Validation loss: 3.001182265084701

Epoch: 5| Step: 7
Training loss: 3.3760556583336276
Validation loss: 3.0072777006176636

Epoch: 5| Step: 8
Training loss: 3.031430111282839
Validation loss: 3.0113450915264544

Epoch: 5| Step: 9
Training loss: 3.902146281915729
Validation loss: 3.008931343071668

Epoch: 5| Step: 10
Training loss: 3.3589595094167
Validation loss: 3.0009584143588186

Epoch: 111| Step: 0
Training loss: 3.307836452680311
Validation loss: 2.9982727267134885

Epoch: 5| Step: 1
Training loss: 3.4295732135891432
Validation loss: 3.0003447983966214

Epoch: 5| Step: 2
Training loss: 2.698601261508584
Validation loss: 2.9968020877062926

Epoch: 5| Step: 3
Training loss: 3.0754829337648593
Validation loss: 2.9975215046303236

Epoch: 5| Step: 4
Training loss: 2.6141397066907905
Validation loss: 2.9972757203671456

Epoch: 5| Step: 5
Training loss: 3.754128027804261
Validation loss: 2.9981556379278462

Epoch: 5| Step: 6
Training loss: 3.3777283837097754
Validation loss: 2.99602316397962

Epoch: 5| Step: 7
Training loss: 3.4373179994432976
Validation loss: 2.9965884001737373

Epoch: 5| Step: 8
Training loss: 3.5994371609984475
Validation loss: 2.997349798172711

Epoch: 5| Step: 9
Training loss: 3.5471643002198117
Validation loss: 2.998820466078791

Epoch: 5| Step: 10
Training loss: 2.930999380756522
Validation loss: 2.9989697266457185

Epoch: 112| Step: 0
Training loss: 3.6240700153635723
Validation loss: 2.9973840947495662

Epoch: 5| Step: 1
Training loss: 3.0190107086891373
Validation loss: 2.9995300136751135

Epoch: 5| Step: 2
Training loss: 3.4866556820474557
Validation loss: 3.002915444969339

Epoch: 5| Step: 3
Training loss: 3.0696682241883724
Validation loss: 2.9973094293356772

Epoch: 5| Step: 4
Training loss: 4.018537007289479
Validation loss: 3.003220973966953

Epoch: 5| Step: 5
Training loss: 3.616416898502834
Validation loss: 2.998178479394301

Epoch: 5| Step: 6
Training loss: 2.465049771315183
Validation loss: 2.996211419904145

Epoch: 5| Step: 7
Training loss: 3.4987188446740256
Validation loss: 2.9965956250295323

Epoch: 5| Step: 8
Training loss: 2.8482841144890347
Validation loss: 2.993564580669175

Epoch: 5| Step: 9
Training loss: 2.8708200337213103
Validation loss: 2.995951458750042

Epoch: 5| Step: 10
Training loss: 3.1805633163542555
Validation loss: 2.9938433908819926

Epoch: 113| Step: 0
Training loss: 3.302789093232046
Validation loss: 2.9926336579076964

Epoch: 5| Step: 1
Training loss: 3.1876133917292786
Validation loss: 2.992553330440709

Epoch: 5| Step: 2
Training loss: 2.7450504844484027
Validation loss: 2.9960973848458097

Epoch: 5| Step: 3
Training loss: 3.3145562753266278
Validation loss: 2.994099091231868

Epoch: 5| Step: 4
Training loss: 3.7430695388208766
Validation loss: 2.9947108075468973

Epoch: 5| Step: 5
Training loss: 3.1142206055220942
Validation loss: 2.9937247407350998

Epoch: 5| Step: 6
Training loss: 3.6604113250733974
Validation loss: 2.994471283727052

Epoch: 5| Step: 7
Training loss: 2.774175841145477
Validation loss: 2.994266135539209

Epoch: 5| Step: 8
Training loss: 2.958863833147019
Validation loss: 2.994580562618254

Epoch: 5| Step: 9
Training loss: 3.48818036624485
Validation loss: 2.9951784276697584

Epoch: 5| Step: 10
Training loss: 3.561590111968443
Validation loss: 2.992683547094256

Epoch: 114| Step: 0
Training loss: 2.8212338789114635
Validation loss: 2.9929424096019948

Epoch: 5| Step: 1
Training loss: 3.3969526883868535
Validation loss: 2.9924417089637445

Epoch: 5| Step: 2
Training loss: 3.1310695451525876
Validation loss: 2.995802794012199

Epoch: 5| Step: 3
Training loss: 3.3918033081823133
Validation loss: 2.9934619036119883

Epoch: 5| Step: 4
Training loss: 3.3780883504765664
Validation loss: 2.994277661456495

Epoch: 5| Step: 5
Training loss: 2.9134565035216498
Validation loss: 2.9989590795889938

Epoch: 5| Step: 6
Training loss: 3.6886188943199567
Validation loss: 2.996641677194147

Epoch: 5| Step: 7
Training loss: 2.926524822850017
Validation loss: 2.991082367497787

Epoch: 5| Step: 8
Training loss: 3.193788496110183
Validation loss: 2.9907673120603198

Epoch: 5| Step: 9
Training loss: 3.918178442442831
Validation loss: 2.99213276166189

Epoch: 5| Step: 10
Training loss: 2.9813464710933353
Validation loss: 2.988718114655639

Epoch: 115| Step: 0
Training loss: 3.5697336207578494
Validation loss: 2.9909917180818777

Epoch: 5| Step: 1
Training loss: 3.4411864887089805
Validation loss: 2.9916155853924136

Epoch: 5| Step: 2
Training loss: 3.554296585218831
Validation loss: 2.990665018148645

Epoch: 5| Step: 3
Training loss: 3.536768963766783
Validation loss: 2.9982959563277785

Epoch: 5| Step: 4
Training loss: 2.6822623735822084
Validation loss: 2.993757908239681

Epoch: 5| Step: 5
Training loss: 3.052825438251114
Validation loss: 2.9954420590306774

Epoch: 5| Step: 6
Training loss: 3.1891518594799946
Validation loss: 2.9898357224079115

Epoch: 5| Step: 7
Training loss: 2.6709673494309274
Validation loss: 2.988100227172124

Epoch: 5| Step: 8
Training loss: 3.4667201245905632
Validation loss: 2.9900065699833123

Epoch: 5| Step: 9
Training loss: 3.3880049607151648
Validation loss: 2.991248334125839

Epoch: 5| Step: 10
Training loss: 3.254967487834985
Validation loss: 2.992787914385113

Epoch: 116| Step: 0
Training loss: 3.0214065709419433
Validation loss: 2.994772843582187

Epoch: 5| Step: 1
Training loss: 3.2274677032107624
Validation loss: 2.9953423409043745

Epoch: 5| Step: 2
Training loss: 3.4695623322992715
Validation loss: 2.9942514553845063

Epoch: 5| Step: 3
Training loss: 3.3183123858595542
Validation loss: 2.9921580498224225

Epoch: 5| Step: 4
Training loss: 3.4219895435131136
Validation loss: 2.9920470347924213

Epoch: 5| Step: 5
Training loss: 3.5454224960728133
Validation loss: 2.9932669878723486

Epoch: 5| Step: 6
Training loss: 2.9210605404178347
Validation loss: 2.995415604677564

Epoch: 5| Step: 7
Training loss: 3.0510497616111
Validation loss: 2.9912082891902565

Epoch: 5| Step: 8
Training loss: 2.9282595804038705
Validation loss: 2.989411276688754

Epoch: 5| Step: 9
Training loss: 3.8965939002072467
Validation loss: 2.991538999517741

Epoch: 5| Step: 10
Training loss: 2.931922649971353
Validation loss: 2.9874422040056317

Epoch: 117| Step: 0
Training loss: 2.6245637258655297
Validation loss: 2.988493812417033

Epoch: 5| Step: 1
Training loss: 3.255821442912286
Validation loss: 2.986203889644778

Epoch: 5| Step: 2
Training loss: 3.0336503425642087
Validation loss: 2.9852609855302656

Epoch: 5| Step: 3
Training loss: 3.3732418143129896
Validation loss: 2.98378192455018

Epoch: 5| Step: 4
Training loss: 3.50917485550434
Validation loss: 2.98585078185846

Epoch: 5| Step: 5
Training loss: 3.7369772810272175
Validation loss: 2.9839131786594573

Epoch: 5| Step: 6
Training loss: 3.292871005416548
Validation loss: 2.9819897749111965

Epoch: 5| Step: 7
Training loss: 3.4046784021361924
Validation loss: 2.9840529734702894

Epoch: 5| Step: 8
Training loss: 3.6207794085936524
Validation loss: 2.9837572776755548

Epoch: 5| Step: 9
Training loss: 2.998774914147071
Validation loss: 2.982057844098837

Epoch: 5| Step: 10
Training loss: 2.784729827295469
Validation loss: 2.9805759653692765

Epoch: 118| Step: 0
Training loss: 3.183225420842046
Validation loss: 2.9828093294444304

Epoch: 5| Step: 1
Training loss: 3.551095745062443
Validation loss: 2.9841873117657656

Epoch: 5| Step: 2
Training loss: 2.7918758788405267
Validation loss: 2.9853064216347875

Epoch: 5| Step: 3
Training loss: 3.1945958161540355
Validation loss: 2.9810508895263443

Epoch: 5| Step: 4
Training loss: 3.551896628267488
Validation loss: 2.98219777058285

Epoch: 5| Step: 5
Training loss: 2.648785773589729
Validation loss: 2.981631856967223

Epoch: 5| Step: 6
Training loss: 3.404476719109272
Validation loss: 2.981300383881786

Epoch: 5| Step: 7
Training loss: 3.2437546217339728
Validation loss: 2.9817321634406952

Epoch: 5| Step: 8
Training loss: 2.9108243648967154
Validation loss: 2.9819055541414747

Epoch: 5| Step: 9
Training loss: 4.037744303300778
Validation loss: 2.9795157838036554

Epoch: 5| Step: 10
Training loss: 3.0838891293081914
Validation loss: 2.980003164344347

Epoch: 119| Step: 0
Training loss: 3.0690367088869444
Validation loss: 2.980040723983921

Epoch: 5| Step: 1
Training loss: 3.3819054495364727
Validation loss: 2.982388174838461

Epoch: 5| Step: 2
Training loss: 3.506808062798225
Validation loss: 2.9821470930373497

Epoch: 5| Step: 3
Training loss: 3.0986417378929128
Validation loss: 2.9822139413793423

Epoch: 5| Step: 4
Training loss: 3.3186415832397165
Validation loss: 2.9812735873439586

Epoch: 5| Step: 5
Training loss: 2.5338698592815763
Validation loss: 2.981051550849986

Epoch: 5| Step: 6
Training loss: 3.671025084482322
Validation loss: 2.9802692942081603

Epoch: 5| Step: 7
Training loss: 3.12344474238233
Validation loss: 2.980222574422859

Epoch: 5| Step: 8
Training loss: 3.306728156835764
Validation loss: 2.9813074394091785

Epoch: 5| Step: 9
Training loss: 3.9168037363511385
Validation loss: 2.9812308759405513

Epoch: 5| Step: 10
Training loss: 2.5627261736540623
Validation loss: 2.9810138749480224

Epoch: 120| Step: 0
Training loss: 3.7060117133542687
Validation loss: 2.9796319316131057

Epoch: 5| Step: 1
Training loss: 3.5007812445516486
Validation loss: 2.9818901820876387

Epoch: 5| Step: 2
Training loss: 3.1670667161385557
Validation loss: 2.9809711090833435

Epoch: 5| Step: 3
Training loss: 3.6973891764056646
Validation loss: 2.983138109154386

Epoch: 5| Step: 4
Training loss: 2.9464874757105353
Validation loss: 2.985889990262752

Epoch: 5| Step: 5
Training loss: 3.4775634696208924
Validation loss: 2.984216587179111

Epoch: 5| Step: 6
Training loss: 3.2412581617059133
Validation loss: 2.9796539058508302

Epoch: 5| Step: 7
Training loss: 2.861555425058825
Validation loss: 2.9802711814959246

Epoch: 5| Step: 8
Training loss: 3.243025999912489
Validation loss: 2.9789348967930263

Epoch: 5| Step: 9
Training loss: 2.4855773703289947
Validation loss: 2.979491487110943

Epoch: 5| Step: 10
Training loss: 3.296283831634322
Validation loss: 2.9766120522175705

Epoch: 121| Step: 0
Training loss: 3.6991767276685246
Validation loss: 2.976433135317155

Epoch: 5| Step: 1
Training loss: 2.917661515368381
Validation loss: 2.977282141401699

Epoch: 5| Step: 2
Training loss: 3.0639802119260997
Validation loss: 2.976337884630586

Epoch: 5| Step: 3
Training loss: 3.106018094591637
Validation loss: 2.9745316324689037

Epoch: 5| Step: 4
Training loss: 3.425661265448004
Validation loss: 2.977711250978491

Epoch: 5| Step: 5
Training loss: 3.0716230007744634
Validation loss: 2.977686273185887

Epoch: 5| Step: 6
Training loss: 3.2653376256629745
Validation loss: 2.9744582076761614

Epoch: 5| Step: 7
Training loss: 3.13223893011565
Validation loss: 2.9760424357422472

Epoch: 5| Step: 8
Training loss: 3.7839282930608458
Validation loss: 2.9743797216772747

Epoch: 5| Step: 9
Training loss: 2.415716993152016
Validation loss: 2.9731007256726123

Epoch: 5| Step: 10
Training loss: 3.757996362324041
Validation loss: 2.9741013659197777

Epoch: 122| Step: 0
Training loss: 3.561173576908748
Validation loss: 2.9752671593772124

Epoch: 5| Step: 1
Training loss: 3.3424252176300397
Validation loss: 2.9742452989703256

Epoch: 5| Step: 2
Training loss: 3.8410830045400104
Validation loss: 2.974588297739223

Epoch: 5| Step: 3
Training loss: 3.1940566302052327
Validation loss: 2.9716875172711066

Epoch: 5| Step: 4
Training loss: 2.7144557318823828
Validation loss: 2.974531754853537

Epoch: 5| Step: 5
Training loss: 3.0763002205368384
Validation loss: 2.972036311092168

Epoch: 5| Step: 6
Training loss: 2.952400401193457
Validation loss: 2.973102934829137

Epoch: 5| Step: 7
Training loss: 3.364885503626334
Validation loss: 2.975757081126119

Epoch: 5| Step: 8
Training loss: 3.1129280378171176
Validation loss: 2.9744160060442

Epoch: 5| Step: 9
Training loss: 3.1504834061527522
Validation loss: 2.978629098953394

Epoch: 5| Step: 10
Training loss: 3.346540908451728
Validation loss: 2.974488544146415

Epoch: 123| Step: 0
Training loss: 2.715608733274425
Validation loss: 2.974445843049587

Epoch: 5| Step: 1
Training loss: 2.7983941582284526
Validation loss: 2.97442531107112

Epoch: 5| Step: 2
Training loss: 3.667552335296814
Validation loss: 2.9752299048200483

Epoch: 5| Step: 3
Training loss: 3.105502683826
Validation loss: 2.976324868023097

Epoch: 5| Step: 4
Training loss: 3.1320273159779797
Validation loss: 2.9753435437194846

Epoch: 5| Step: 5
Training loss: 3.6836608039197856
Validation loss: 2.979192826729668

Epoch: 5| Step: 6
Training loss: 3.4524985733416
Validation loss: 2.9735456909928897

Epoch: 5| Step: 7
Training loss: 3.3311727833342357
Validation loss: 2.9712325859419746

Epoch: 5| Step: 8
Training loss: 3.4150593085884697
Validation loss: 2.9742959525550807

Epoch: 5| Step: 9
Training loss: 3.28157986390675
Validation loss: 2.9710050557561622

Epoch: 5| Step: 10
Training loss: 3.0098743060155675
Validation loss: 2.9712714479897593

Epoch: 124| Step: 0
Training loss: 3.6836255942917027
Validation loss: 2.97148312035785

Epoch: 5| Step: 1
Training loss: 3.133255392146799
Validation loss: 2.9712246134690807

Epoch: 5| Step: 2
Training loss: 3.5514507606741734
Validation loss: 2.9700835069230695

Epoch: 5| Step: 3
Training loss: 2.9913768815685877
Validation loss: 2.9702315808212

Epoch: 5| Step: 4
Training loss: 3.3337772709546725
Validation loss: 2.9700798566408855

Epoch: 5| Step: 5
Training loss: 2.8317131758341754
Validation loss: 2.9695664755952462

Epoch: 5| Step: 6
Training loss: 3.693422636703716
Validation loss: 2.9693843558884483

Epoch: 5| Step: 7
Training loss: 3.127527206875831
Validation loss: 2.969306175235912

Epoch: 5| Step: 8
Training loss: 3.2640498254656833
Validation loss: 2.9695025230225314

Epoch: 5| Step: 9
Training loss: 3.0720950477618545
Validation loss: 2.9698392379947514

Epoch: 5| Step: 10
Training loss: 2.918354381730101
Validation loss: 2.969338573407185

Epoch: 125| Step: 0
Training loss: 3.456931109513589
Validation loss: 2.9692769039072777

Epoch: 5| Step: 1
Training loss: 2.5476513012999122
Validation loss: 2.969100946948825

Epoch: 5| Step: 2
Training loss: 3.439621842690753
Validation loss: 2.971606091301832

Epoch: 5| Step: 3
Training loss: 3.2549304243348645
Validation loss: 2.9680342333300653

Epoch: 5| Step: 4
Training loss: 3.785492463823505
Validation loss: 2.969345566703564

Epoch: 5| Step: 5
Training loss: 3.5717319196210187
Validation loss: 2.9684411778252175

Epoch: 5| Step: 6
Training loss: 3.5512865502243267
Validation loss: 2.9672599831276725

Epoch: 5| Step: 7
Training loss: 3.3717027735100715
Validation loss: 2.967152393734316

Epoch: 5| Step: 8
Training loss: 2.4256114070976387
Validation loss: 2.9693892243581237

Epoch: 5| Step: 9
Training loss: 3.427195553937534
Validation loss: 2.969754362735093

Epoch: 5| Step: 10
Training loss: 2.4271204103794917
Validation loss: 2.970047818726999

Epoch: 126| Step: 0
Training loss: 2.713587100965954
Validation loss: 2.9661150565935586

Epoch: 5| Step: 1
Training loss: 3.808237538430197
Validation loss: 2.9678732837704036

Epoch: 5| Step: 2
Training loss: 3.4659124917299327
Validation loss: 2.967252623773205

Epoch: 5| Step: 3
Training loss: 3.368079826206357
Validation loss: 2.9680639073253214

Epoch: 5| Step: 4
Training loss: 3.093658600044674
Validation loss: 2.9707973206101794

Epoch: 5| Step: 5
Training loss: 3.2661011271194282
Validation loss: 2.9664471038872016

Epoch: 5| Step: 6
Training loss: 2.8443923057142015
Validation loss: 2.967455708648103

Epoch: 5| Step: 7
Training loss: 3.637168323824527
Validation loss: 2.965498852461648

Epoch: 5| Step: 8
Training loss: 2.872646197523715
Validation loss: 2.964837317639652

Epoch: 5| Step: 9
Training loss: 3.295447741175596
Validation loss: 2.9634587922064135

Epoch: 5| Step: 10
Training loss: 3.1625033834688083
Validation loss: 2.9649401602352414

Epoch: 127| Step: 0
Training loss: 3.580834308352185
Validation loss: 2.964354902723768

Epoch: 5| Step: 1
Training loss: 2.6918536563166184
Validation loss: 2.9641825429250366

Epoch: 5| Step: 2
Training loss: 3.555254746335392
Validation loss: 2.965648806360885

Epoch: 5| Step: 3
Training loss: 3.539108579221957
Validation loss: 2.9643187390880916

Epoch: 5| Step: 4
Training loss: 3.548124656173262
Validation loss: 2.9649562574127803

Epoch: 5| Step: 5
Training loss: 2.882093386395179
Validation loss: 2.964344884603712

Epoch: 5| Step: 6
Training loss: 4.058079823768761
Validation loss: 2.964602233352817

Epoch: 5| Step: 7
Training loss: 2.7762623330039427
Validation loss: 2.9663391064718168

Epoch: 5| Step: 8
Training loss: 3.1162262392878777
Validation loss: 2.9670087093362296

Epoch: 5| Step: 9
Training loss: 2.729457072951677
Validation loss: 2.969035943017397

Epoch: 5| Step: 10
Training loss: 2.902314341256203
Validation loss: 2.964563438671558

Epoch: 128| Step: 0
Training loss: 3.492734588848985
Validation loss: 2.9642189218432633

Epoch: 5| Step: 1
Training loss: 2.7084631277429754
Validation loss: 2.9620819386649555

Epoch: 5| Step: 2
Training loss: 3.39749602507751
Validation loss: 2.961723827351725

Epoch: 5| Step: 3
Training loss: 3.4284953693627322
Validation loss: 2.9611728795547947

Epoch: 5| Step: 4
Training loss: 3.2904802107587607
Validation loss: 2.960991615023631

Epoch: 5| Step: 5
Training loss: 2.7167426404880524
Validation loss: 2.962541529769917

Epoch: 5| Step: 6
Training loss: 3.1360403731141213
Validation loss: 2.9636153336633106

Epoch: 5| Step: 7
Training loss: 2.7386373378157636
Validation loss: 2.962937961575292

Epoch: 5| Step: 8
Training loss: 3.5178196817219543
Validation loss: 2.9624764528693452

Epoch: 5| Step: 9
Training loss: 3.3716166456518772
Validation loss: 2.959602011706059

Epoch: 5| Step: 10
Training loss: 3.758738825901626
Validation loss: 2.9614709446163747

Epoch: 129| Step: 0
Training loss: 3.155137574208551
Validation loss: 2.9642485726275947

Epoch: 5| Step: 1
Training loss: 3.379549280621445
Validation loss: 2.959457520673244

Epoch: 5| Step: 2
Training loss: 3.099769669866712
Validation loss: 2.9646747850142257

Epoch: 5| Step: 3
Training loss: 3.4625579278279885
Validation loss: 2.9604283900923383

Epoch: 5| Step: 4
Training loss: 3.5612986362680354
Validation loss: 2.959996678024286

Epoch: 5| Step: 5
Training loss: 3.2854999448630817
Validation loss: 2.9574839094515846

Epoch: 5| Step: 6
Training loss: 2.5305730597398592
Validation loss: 2.957030463663242

Epoch: 5| Step: 7
Training loss: 3.5603040653203513
Validation loss: 2.9572158642924973

Epoch: 5| Step: 8
Training loss: 2.935315557669346
Validation loss: 2.9586518826896144

Epoch: 5| Step: 9
Training loss: 3.401291063559226
Validation loss: 2.9600376847771965

Epoch: 5| Step: 10
Training loss: 3.1150018587305883
Validation loss: 2.960906782257982

Epoch: 130| Step: 0
Training loss: 3.1388774203950867
Validation loss: 2.966701985497262

Epoch: 5| Step: 1
Training loss: 2.7092638813538623
Validation loss: 2.9669774789881336

Epoch: 5| Step: 2
Training loss: 3.4720411753608107
Validation loss: 2.9592247613139904

Epoch: 5| Step: 3
Training loss: 3.664978823737237
Validation loss: 2.9598916135448183

Epoch: 5| Step: 4
Training loss: 3.2582959152635813
Validation loss: 2.9589691403223983

Epoch: 5| Step: 5
Training loss: 3.082134288617433
Validation loss: 2.9558185725233237

Epoch: 5| Step: 6
Training loss: 2.971081109613116
Validation loss: 2.955518787235616

Epoch: 5| Step: 7
Training loss: 3.01816795535001
Validation loss: 2.956409130710154

Epoch: 5| Step: 8
Training loss: 3.2595552681715105
Validation loss: 2.954144996778688

Epoch: 5| Step: 9
Training loss: 3.7628799500101615
Validation loss: 2.9544428562817497

Epoch: 5| Step: 10
Training loss: 3.1388979286206213
Validation loss: 2.954607461520602

Epoch: 131| Step: 0
Training loss: 3.1287585734403454
Validation loss: 2.9549669774950447

Epoch: 5| Step: 1
Training loss: 3.3425730122229216
Validation loss: 2.955381133319902

Epoch: 5| Step: 2
Training loss: 2.4546234996666936
Validation loss: 2.9553523252181315

Epoch: 5| Step: 3
Training loss: 3.5391445529343586
Validation loss: 2.9542038329362867

Epoch: 5| Step: 4
Training loss: 3.2948830901318362
Validation loss: 2.953351809191936

Epoch: 5| Step: 5
Training loss: 3.3453677533222357
Validation loss: 2.953482487354064

Epoch: 5| Step: 6
Training loss: 3.3850870920807457
Validation loss: 2.953266908450527

Epoch: 5| Step: 7
Training loss: 2.726666904844291
Validation loss: 2.952824533193882

Epoch: 5| Step: 8
Training loss: 4.091041426011331
Validation loss: 2.9545034835275907

Epoch: 5| Step: 9
Training loss: 3.428513310711877
Validation loss: 2.954075627461856

Epoch: 5| Step: 10
Training loss: 2.2982399965199467
Validation loss: 2.957738060503657

Epoch: 132| Step: 0
Training loss: 3.711737552531767
Validation loss: 2.9551527669706132

Epoch: 5| Step: 1
Training loss: 3.2667396504819237
Validation loss: 2.957132833934284

Epoch: 5| Step: 2
Training loss: 3.1737169451680587
Validation loss: 2.953883034564223

Epoch: 5| Step: 3
Training loss: 3.3776957730606174
Validation loss: 2.95517132306749

Epoch: 5| Step: 4
Training loss: 2.838700726920082
Validation loss: 2.955815854341118

Epoch: 5| Step: 5
Training loss: 2.7249082777352913
Validation loss: 2.9559714528049863

Epoch: 5| Step: 6
Training loss: 3.071135199593885
Validation loss: 2.9612561031020967

Epoch: 5| Step: 7
Training loss: 3.7030165773124195
Validation loss: 2.959429868863929

Epoch: 5| Step: 8
Training loss: 3.1458493331266517
Validation loss: 2.9552696354714607

Epoch: 5| Step: 9
Training loss: 3.0280060074518595
Validation loss: 2.955256041143444

Epoch: 5| Step: 10
Training loss: 3.389673477471615
Validation loss: 2.958248021653269

Epoch: 133| Step: 0
Training loss: 3.374122081589842
Validation loss: 2.9534743350300934

Epoch: 5| Step: 1
Training loss: 3.326991501609559
Validation loss: 2.9515322446098935

Epoch: 5| Step: 2
Training loss: 3.1591236893703942
Validation loss: 2.952048151426049

Epoch: 5| Step: 3
Training loss: 2.889319542631724
Validation loss: 2.951596336401186

Epoch: 5| Step: 4
Training loss: 3.580512037687678
Validation loss: 2.9515223506033217

Epoch: 5| Step: 5
Training loss: 3.422626012317213
Validation loss: 2.9501258633451206

Epoch: 5| Step: 6
Training loss: 3.8530874579983743
Validation loss: 2.9517139771319196

Epoch: 5| Step: 7
Training loss: 2.3878963081620475
Validation loss: 2.953450928221882

Epoch: 5| Step: 8
Training loss: 3.0569998728084817
Validation loss: 2.951183494516276

Epoch: 5| Step: 9
Training loss: 2.8080590684878226
Validation loss: 2.953638097641424

Epoch: 5| Step: 10
Training loss: 3.484306026853774
Validation loss: 2.9520165995391716

Epoch: 134| Step: 0
Training loss: 2.5831529082593487
Validation loss: 2.949680296654224

Epoch: 5| Step: 1
Training loss: 3.1924086529143083
Validation loss: 2.94873747571024

Epoch: 5| Step: 2
Training loss: 3.8316999908586644
Validation loss: 2.9476684242002062

Epoch: 5| Step: 3
Training loss: 3.7082337498241613
Validation loss: 2.9500320930953015

Epoch: 5| Step: 4
Training loss: 3.1495875678950975
Validation loss: 2.9501193389335985

Epoch: 5| Step: 5
Training loss: 3.414828635701366
Validation loss: 2.9480687613135244

Epoch: 5| Step: 6
Training loss: 2.8901177038491097
Validation loss: 2.94918029016861

Epoch: 5| Step: 7
Training loss: 3.13725350312127
Validation loss: 2.9496284129170234

Epoch: 5| Step: 8
Training loss: 3.3141659559965793
Validation loss: 2.949456587585743

Epoch: 5| Step: 9
Training loss: 2.55045193799907
Validation loss: 2.9498520785371207

Epoch: 5| Step: 10
Training loss: 3.560907108165474
Validation loss: 2.9481743601695416

Epoch: 135| Step: 0
Training loss: 3.4129914932390855
Validation loss: 2.946779135475559

Epoch: 5| Step: 1
Training loss: 3.11822966552309
Validation loss: 2.945615061185151

Epoch: 5| Step: 2
Training loss: 3.042342193698725
Validation loss: 2.9462348801698863

Epoch: 5| Step: 3
Training loss: 3.256776347608894
Validation loss: 2.9488179934824106

Epoch: 5| Step: 4
Training loss: 3.467689558264632
Validation loss: 2.9465770007336824

Epoch: 5| Step: 5
Training loss: 3.1021946183621867
Validation loss: 2.9472806000754326

Epoch: 5| Step: 6
Training loss: 3.111882717707576
Validation loss: 2.9492713641562953

Epoch: 5| Step: 7
Training loss: 3.4408983944849973
Validation loss: 2.9530014148519848

Epoch: 5| Step: 8
Training loss: 3.0872552689768296
Validation loss: 2.9467796052650375

Epoch: 5| Step: 9
Training loss: 3.347545288098666
Validation loss: 2.949119689099186

Epoch: 5| Step: 10
Training loss: 3.0653368208794696
Validation loss: 2.947692692714679

Epoch: 136| Step: 0
Training loss: 3.48790545003814
Validation loss: 2.9476390058380515

Epoch: 5| Step: 1
Training loss: 3.215998390102458
Validation loss: 2.9457242239508132

Epoch: 5| Step: 2
Training loss: 3.2393481955283163
Validation loss: 2.945805697833557

Epoch: 5| Step: 3
Training loss: 3.0980168982895173
Validation loss: 2.94369193904356

Epoch: 5| Step: 4
Training loss: 3.2112806744741986
Validation loss: 2.9437091373878252

Epoch: 5| Step: 5
Training loss: 3.3613933798503206
Validation loss: 2.9445925101552897

Epoch: 5| Step: 6
Training loss: 3.8246723408698227
Validation loss: 2.945584665819282

Epoch: 5| Step: 7
Training loss: 2.9316502214512323
Validation loss: 2.9430607491673424

Epoch: 5| Step: 8
Training loss: 3.0085958674484563
Validation loss: 2.9434113866615332

Epoch: 5| Step: 9
Training loss: 3.1405867389227233
Validation loss: 2.943253784563348

Epoch: 5| Step: 10
Training loss: 2.8293046545911613
Validation loss: 2.9437791507161464

Epoch: 137| Step: 0
Training loss: 3.6540726919642936
Validation loss: 2.9415517113902983

Epoch: 5| Step: 1
Training loss: 3.683463522104808
Validation loss: 2.9424594798248034

Epoch: 5| Step: 2
Training loss: 2.98261196927135
Validation loss: 2.9458561120313873

Epoch: 5| Step: 3
Training loss: 2.364271829619487
Validation loss: 2.944633459793801

Epoch: 5| Step: 4
Training loss: 3.2174167279046983
Validation loss: 2.9426063797989084

Epoch: 5| Step: 5
Training loss: 3.269784860562357
Validation loss: 2.9442479151280305

Epoch: 5| Step: 6
Training loss: 3.834541393049151
Validation loss: 2.940920011612061

Epoch: 5| Step: 7
Training loss: 3.640533577094455
Validation loss: 2.944651758312851

Epoch: 5| Step: 8
Training loss: 2.4244407598865894
Validation loss: 2.9438812859884655

Epoch: 5| Step: 9
Training loss: 3.4786598308472185
Validation loss: 2.943211002234172

Epoch: 5| Step: 10
Training loss: 2.2932153728369737
Validation loss: 2.94249059053219

Epoch: 138| Step: 0
Training loss: 3.054017132424375
Validation loss: 2.9411614141314097

Epoch: 5| Step: 1
Training loss: 3.4270718621677476
Validation loss: 2.9431362185496543

Epoch: 5| Step: 2
Training loss: 3.266388288301189
Validation loss: 2.941399124037299

Epoch: 5| Step: 3
Training loss: 3.279481974609641
Validation loss: 2.9403469835181943

Epoch: 5| Step: 4
Training loss: 2.9779839113004547
Validation loss: 2.942084244391226

Epoch: 5| Step: 5
Training loss: 3.4719398197197155
Validation loss: 2.941275496818452

Epoch: 5| Step: 6
Training loss: 3.551923746381651
Validation loss: 2.940178893484543

Epoch: 5| Step: 7
Training loss: 2.8028673306606775
Validation loss: 2.9399289308984535

Epoch: 5| Step: 8
Training loss: 3.4218947875961834
Validation loss: 2.938438771702804

Epoch: 5| Step: 9
Training loss: 2.0425474122613285
Validation loss: 2.940467301880302

Epoch: 5| Step: 10
Training loss: 3.907401441623445
Validation loss: 2.9381518787187892

Epoch: 139| Step: 0
Training loss: 3.8331646813043427
Validation loss: 2.94071452230653

Epoch: 5| Step: 1
Training loss: 2.74502251732212
Validation loss: 2.940526378581465

Epoch: 5| Step: 2
Training loss: 3.673827346241943
Validation loss: 2.936263016619188

Epoch: 5| Step: 3
Training loss: 3.8130590310398205
Validation loss: 2.9369037400914935

Epoch: 5| Step: 4
Training loss: 2.746507420861611
Validation loss: 2.9395004421823687

Epoch: 5| Step: 5
Training loss: 3.0924003045950994
Validation loss: 2.9396174367377887

Epoch: 5| Step: 6
Training loss: 3.4395551606812678
Validation loss: 2.939472216276127

Epoch: 5| Step: 7
Training loss: 3.118583500456001
Validation loss: 2.94209102799009

Epoch: 5| Step: 8
Training loss: 3.0933039179861264
Validation loss: 2.941378722213003

Epoch: 5| Step: 9
Training loss: 2.358340206967459
Validation loss: 2.9396975642021452

Epoch: 5| Step: 10
Training loss: 3.1668812193883817
Validation loss: 2.9387591056340523

Epoch: 140| Step: 0
Training loss: 3.243346519587163
Validation loss: 2.938518700986469

Epoch: 5| Step: 1
Training loss: 2.746400731863518
Validation loss: 2.9397400218032863

Epoch: 5| Step: 2
Training loss: 2.75746528665891
Validation loss: 2.939768722152458

Epoch: 5| Step: 3
Training loss: 3.0265280529104155
Validation loss: 2.940703114240166

Epoch: 5| Step: 4
Training loss: 3.314798097747887
Validation loss: 2.937384945918741

Epoch: 5| Step: 5
Training loss: 3.380291640436052
Validation loss: 2.9364115632274075

Epoch: 5| Step: 6
Training loss: 3.341542593792264
Validation loss: 2.9386439507985176

Epoch: 5| Step: 7
Training loss: 3.319296001341104
Validation loss: 2.938022885533626

Epoch: 5| Step: 8
Training loss: 3.151496102007622
Validation loss: 2.943199994940687

Epoch: 5| Step: 9
Training loss: 3.493605221391239
Validation loss: 2.9391969672126597

Epoch: 5| Step: 10
Training loss: 3.577446485928221
Validation loss: 2.942217257585794

Epoch: 141| Step: 0
Training loss: 3.3792536738836363
Validation loss: 2.9444324428411526

Epoch: 5| Step: 1
Training loss: 2.9155217421258572
Validation loss: 2.9420001020667894

Epoch: 5| Step: 2
Training loss: 2.896882413753829
Validation loss: 2.9370557038416885

Epoch: 5| Step: 3
Training loss: 4.08479599479482
Validation loss: 2.9339772406577485

Epoch: 5| Step: 4
Training loss: 3.420581172395387
Validation loss: 2.9340179601119427

Epoch: 5| Step: 5
Training loss: 2.7051307425218774
Validation loss: 2.934462520510263

Epoch: 5| Step: 6
Training loss: 2.7875938502366076
Validation loss: 2.934441986589691

Epoch: 5| Step: 7
Training loss: 3.3489308373413595
Validation loss: 2.933847621774845

Epoch: 5| Step: 8
Training loss: 3.5126344974058608
Validation loss: 2.935319714946662

Epoch: 5| Step: 9
Training loss: 3.269556626525624
Validation loss: 2.9348909935397827

Epoch: 5| Step: 10
Training loss: 2.7524580806966763
Validation loss: 2.935793943040625

Epoch: 142| Step: 0
Training loss: 3.228664055543272
Validation loss: 2.931544203144508

Epoch: 5| Step: 1
Training loss: 2.720497534351322
Validation loss: 2.9326231546590447

Epoch: 5| Step: 2
Training loss: 3.61625511066222
Validation loss: 2.9329106024402445

Epoch: 5| Step: 3
Training loss: 2.994032646964436
Validation loss: 2.9317287897932673

Epoch: 5| Step: 4
Training loss: 3.478566344468107
Validation loss: 2.932801926022372

Epoch: 5| Step: 5
Training loss: 2.9748873264549935
Validation loss: 2.930861368594525

Epoch: 5| Step: 6
Training loss: 3.4394962409900476
Validation loss: 2.9319443312384763

Epoch: 5| Step: 7
Training loss: 2.852262395379276
Validation loss: 2.9323700082922692

Epoch: 5| Step: 8
Training loss: 3.0961063543578597
Validation loss: 2.9322730596219344

Epoch: 5| Step: 9
Training loss: 3.6617705572429853
Validation loss: 2.9314248609548637

Epoch: 5| Step: 10
Training loss: 3.183393338688091
Validation loss: 2.931945196876963

Epoch: 143| Step: 0
Training loss: 3.090832037398772
Validation loss: 2.933401468493403

Epoch: 5| Step: 1
Training loss: 2.620825763766259
Validation loss: 2.931836851927843

Epoch: 5| Step: 2
Training loss: 3.150634302126685
Validation loss: 2.9349142199338516

Epoch: 5| Step: 3
Training loss: 2.7694857960832784
Validation loss: 2.9334804963705468

Epoch: 5| Step: 4
Training loss: 3.3755122608385366
Validation loss: 2.935497443526014

Epoch: 5| Step: 5
Training loss: 3.2531879635158427
Validation loss: 2.9372516929460972

Epoch: 5| Step: 6
Training loss: 3.7450495787166687
Validation loss: 2.940023385254104

Epoch: 5| Step: 7
Training loss: 3.5093998705151677
Validation loss: 2.9371209389837234

Epoch: 5| Step: 8
Training loss: 3.4523709539760383
Validation loss: 2.936119166100009

Epoch: 5| Step: 9
Training loss: 3.5562885409715435
Validation loss: 2.9300319192988566

Epoch: 5| Step: 10
Training loss: 2.5217324747229366
Validation loss: 2.9296983016713956

Epoch: 144| Step: 0
Training loss: 3.382791919953998
Validation loss: 2.9302899456186005

Epoch: 5| Step: 1
Training loss: 3.010077399085666
Validation loss: 2.9298173519330075

Epoch: 5| Step: 2
Training loss: 3.299713648307628
Validation loss: 2.930080624035689

Epoch: 5| Step: 3
Training loss: 2.8269537086164678
Validation loss: 2.9284194995883945

Epoch: 5| Step: 4
Training loss: 3.368234989241253
Validation loss: 2.930281334200508

Epoch: 5| Step: 5
Training loss: 2.356953976647543
Validation loss: 2.9281949655649853

Epoch: 5| Step: 6
Training loss: 2.8677071664301814
Validation loss: 2.9283530034246286

Epoch: 5| Step: 7
Training loss: 3.4081971089219825
Validation loss: 2.92963761350756

Epoch: 5| Step: 8
Training loss: 3.0780199681676006
Validation loss: 2.931051733322971

Epoch: 5| Step: 9
Training loss: 3.834892425818818
Validation loss: 2.929659393066338

Epoch: 5| Step: 10
Training loss: 3.7442530782783336
Validation loss: 2.928786083392688

Epoch: 145| Step: 0
Training loss: 3.5847462522547113
Validation loss: 2.927378002952573

Epoch: 5| Step: 1
Training loss: 3.641731323319995
Validation loss: 2.9271750416973767

Epoch: 5| Step: 2
Training loss: 3.7003917022803376
Validation loss: 2.92897545565548

Epoch: 5| Step: 3
Training loss: 3.3857412016421264
Validation loss: 2.928660054841874

Epoch: 5| Step: 4
Training loss: 3.5669610719003018
Validation loss: 2.9325523102526514

Epoch: 5| Step: 5
Training loss: 2.5177173324464115
Validation loss: 2.9346389906342396

Epoch: 5| Step: 6
Training loss: 3.280275327245288
Validation loss: 2.9313795919266084

Epoch: 5| Step: 7
Training loss: 3.08334048158659
Validation loss: 2.9298263733466605

Epoch: 5| Step: 8
Training loss: 3.0964451619544646
Validation loss: 2.930490047446675

Epoch: 5| Step: 9
Training loss: 2.3250095080109476
Validation loss: 2.926686969771402

Epoch: 5| Step: 10
Training loss: 2.733465860999682
Validation loss: 2.925902914719688

Epoch: 146| Step: 0
Training loss: 3.3768470796048264
Validation loss: 2.924844756317503

Epoch: 5| Step: 1
Training loss: 3.088362347102346
Validation loss: 2.922436159128335

Epoch: 5| Step: 2
Training loss: 3.31205688967658
Validation loss: 2.9239569307572593

Epoch: 5| Step: 3
Training loss: 3.2166969640487597
Validation loss: 2.924291850371791

Epoch: 5| Step: 4
Training loss: 3.482376414979499
Validation loss: 2.9235463381272417

Epoch: 5| Step: 5
Training loss: 2.9047378379724105
Validation loss: 2.921786290435934

Epoch: 5| Step: 6
Training loss: 3.7930580073657207
Validation loss: 2.921824942390274

Epoch: 5| Step: 7
Training loss: 3.4943919893689963
Validation loss: 2.9238512165670416

Epoch: 5| Step: 8
Training loss: 2.2491469355543723
Validation loss: 2.9227490835468775

Epoch: 5| Step: 9
Training loss: 3.2534602891143822
Validation loss: 2.9239616477814225

Epoch: 5| Step: 10
Training loss: 2.8592779424485566
Validation loss: 2.9215496224905992

Epoch: 147| Step: 0
Training loss: 3.0102468968516325
Validation loss: 2.9196981169477105

Epoch: 5| Step: 1
Training loss: 3.1119315980390736
Validation loss: 2.923227197010293

Epoch: 5| Step: 2
Training loss: 2.96216439064365
Validation loss: 2.9238851012877656

Epoch: 5| Step: 3
Training loss: 4.017429050467116
Validation loss: 2.9313695223303484

Epoch: 5| Step: 4
Training loss: 2.5560310400569035
Validation loss: 2.9337672401614205

Epoch: 5| Step: 5
Training loss: 2.7759879407043604
Validation loss: 2.933018607047928

Epoch: 5| Step: 6
Training loss: 2.6634372189933524
Validation loss: 2.929633274902804

Epoch: 5| Step: 7
Training loss: 3.2389056773665765
Validation loss: 2.927763816487733

Epoch: 5| Step: 8
Training loss: 3.4956935546962247
Validation loss: 2.9291747388137876

Epoch: 5| Step: 9
Training loss: 4.007623084278826
Validation loss: 2.925669972654782

Epoch: 5| Step: 10
Training loss: 3.071599714764158
Validation loss: 2.921555396391745

Epoch: 148| Step: 0
Training loss: 3.0401476023628904
Validation loss: 2.9217716251617296

Epoch: 5| Step: 1
Training loss: 3.4776238010947815
Validation loss: 2.9218099824985635

Epoch: 5| Step: 2
Training loss: 2.8457078167857683
Validation loss: 2.9202000382494853

Epoch: 5| Step: 3
Training loss: 3.0643708100699705
Validation loss: 2.9192076049735753

Epoch: 5| Step: 4
Training loss: 3.908147976403753
Validation loss: 2.9203269410570636

Epoch: 5| Step: 5
Training loss: 3.5123798227623597
Validation loss: 2.9198968453644114

Epoch: 5| Step: 6
Training loss: 3.552040405610671
Validation loss: 2.9226506640216825

Epoch: 5| Step: 7
Training loss: 3.022482235637803
Validation loss: 2.921055646691067

Epoch: 5| Step: 8
Training loss: 2.8217156214184196
Validation loss: 2.917773565568974

Epoch: 5| Step: 9
Training loss: 2.4786593348186226
Validation loss: 2.9190606085856485

Epoch: 5| Step: 10
Training loss: 3.3518642476435927
Validation loss: 2.919371299898935

Epoch: 149| Step: 0
Training loss: 3.3238086200894537
Validation loss: 2.919810887108624

Epoch: 5| Step: 1
Training loss: 3.303485913440203
Validation loss: 2.9187661561920413

Epoch: 5| Step: 2
Training loss: 3.2745094456078454
Validation loss: 2.918909021017326

Epoch: 5| Step: 3
Training loss: 3.1080369993877146
Validation loss: 2.9181937089141456

Epoch: 5| Step: 4
Training loss: 3.1075541469923347
Validation loss: 2.920267805119155

Epoch: 5| Step: 5
Training loss: 3.4102929995669737
Validation loss: 2.919996732593933

Epoch: 5| Step: 6
Training loss: 3.042950415892698
Validation loss: 2.920746968136603

Epoch: 5| Step: 7
Training loss: 3.010084844515051
Validation loss: 2.9200815247496767

Epoch: 5| Step: 8
Training loss: 3.6035352091269996
Validation loss: 2.9183549667805333

Epoch: 5| Step: 9
Training loss: 3.2005916346557886
Validation loss: 2.918621361613922

Epoch: 5| Step: 10
Training loss: 2.7554806801235125
Validation loss: 2.9221854271749135

Epoch: 150| Step: 0
Training loss: 2.772871276652114
Validation loss: 2.9196518249120254

Epoch: 5| Step: 1
Training loss: 3.848001501404277
Validation loss: 2.925825248396306

Epoch: 5| Step: 2
Training loss: 2.785574219574407
Validation loss: 2.922012751391354

Epoch: 5| Step: 3
Training loss: 3.2045390659664577
Validation loss: 2.924285461189617

Epoch: 5| Step: 4
Training loss: 3.5232007947357835
Validation loss: 2.918702155077659

Epoch: 5| Step: 5
Training loss: 3.2449145510668824
Validation loss: 2.91888015245029

Epoch: 5| Step: 6
Training loss: 3.280039536772837
Validation loss: 2.9147342764329

Epoch: 5| Step: 7
Training loss: 3.096936675072511
Validation loss: 2.9136819683118267

Epoch: 5| Step: 8
Training loss: 3.3563317997516893
Validation loss: 2.9143051683797383

Epoch: 5| Step: 9
Training loss: 3.0323921490113612
Validation loss: 2.914274365526326

Epoch: 5| Step: 10
Training loss: 2.907373026783821
Validation loss: 2.9161451837460097

Epoch: 151| Step: 0
Training loss: 3.238251652599588
Validation loss: 2.9143458196252126

Epoch: 5| Step: 1
Training loss: 4.006915075648836
Validation loss: 2.915500000283294

Epoch: 5| Step: 2
Training loss: 3.5871081467196118
Validation loss: 2.9157978395755113

Epoch: 5| Step: 3
Training loss: 2.145904712662619
Validation loss: 2.9176105278779287

Epoch: 5| Step: 4
Training loss: 3.077596086478664
Validation loss: 2.9133300951744023

Epoch: 5| Step: 5
Training loss: 3.0869948495142867
Validation loss: 2.912995066371609

Epoch: 5| Step: 6
Training loss: 2.0808325317324234
Validation loss: 2.912651630348445

Epoch: 5| Step: 7
Training loss: 3.9997289088892627
Validation loss: 2.9141663330462286

Epoch: 5| Step: 8
Training loss: 3.038928815946282
Validation loss: 2.9136813770439045

Epoch: 5| Step: 9
Training loss: 3.3666455038431597
Validation loss: 2.91439592652795

Epoch: 5| Step: 10
Training loss: 2.983083715243077
Validation loss: 2.9159962254186156

Epoch: 152| Step: 0
Training loss: 3.510559909211018
Validation loss: 2.9185020900641825

Epoch: 5| Step: 1
Training loss: 3.224670298674928
Validation loss: 2.9217366665152786

Epoch: 5| Step: 2
Training loss: 3.7250693346777775
Validation loss: 2.9206649470764003

Epoch: 5| Step: 3
Training loss: 2.8880425542089707
Validation loss: 2.9184801943018903

Epoch: 5| Step: 4
Training loss: 2.8491940211987266
Validation loss: 2.919225918845471

Epoch: 5| Step: 5
Training loss: 2.971589346874827
Validation loss: 2.9210201335760106

Epoch: 5| Step: 6
Training loss: 3.4191222941821255
Validation loss: 2.9259707895779457

Epoch: 5| Step: 7
Training loss: 3.6601080468911014
Validation loss: 2.9273347127383307

Epoch: 5| Step: 8
Training loss: 3.218920360612214
Validation loss: 2.9236687973359476

Epoch: 5| Step: 9
Training loss: 2.7007825106043213
Validation loss: 2.916465636912332

Epoch: 5| Step: 10
Training loss: 2.793565123583291
Validation loss: 2.9157384394485444

Epoch: 153| Step: 0
Training loss: 2.962612674678966
Validation loss: 2.911772247643312

Epoch: 5| Step: 1
Training loss: 3.853323698218772
Validation loss: 2.912123610031182

Epoch: 5| Step: 2
Training loss: 4.036567197582692
Validation loss: 2.9101355586693156

Epoch: 5| Step: 3
Training loss: 3.068181431574428
Validation loss: 2.9105127295061024

Epoch: 5| Step: 4
Training loss: 3.1055389204434647
Validation loss: 2.9119350813409524

Epoch: 5| Step: 5
Training loss: 3.1339246340747486
Validation loss: 2.909001048100339

Epoch: 5| Step: 6
Training loss: 3.1179166242256318
Validation loss: 2.909619325420716

Epoch: 5| Step: 7
Training loss: 3.401154232450366
Validation loss: 2.9088438880699075

Epoch: 5| Step: 8
Training loss: 2.617878108218514
Validation loss: 2.909122329789387

Epoch: 5| Step: 9
Training loss: 2.5249470544684005
Validation loss: 2.909064429854582

Epoch: 5| Step: 10
Training loss: 3.0390480649159106
Validation loss: 2.9094104552016047

Epoch: 154| Step: 0
Training loss: 3.3966797941913187
Validation loss: 2.9094726993022966

Epoch: 5| Step: 1
Training loss: 3.1897201286165164
Validation loss: 2.907353957516241

Epoch: 5| Step: 2
Training loss: 3.2322752397820342
Validation loss: 2.907695561154752

Epoch: 5| Step: 3
Training loss: 3.1844663956902988
Validation loss: 2.9086790771445625

Epoch: 5| Step: 4
Training loss: 3.1483705575040557
Validation loss: 2.9087560361371945

Epoch: 5| Step: 5
Training loss: 2.8337844788650126
Validation loss: 2.909338846404221

Epoch: 5| Step: 6
Training loss: 3.3119764094134534
Validation loss: 2.9077292814769637

Epoch: 5| Step: 7
Training loss: 3.3776175626882736
Validation loss: 2.90767536963961

Epoch: 5| Step: 8
Training loss: 2.548281322303587
Validation loss: 2.906591816292432

Epoch: 5| Step: 9
Training loss: 3.427744808344164
Validation loss: 2.907408405031751

Epoch: 5| Step: 10
Training loss: 3.4415776429812617
Validation loss: 2.9084238299618295

Epoch: 155| Step: 0
Training loss: 3.274494300994597
Validation loss: 2.909235127453469

Epoch: 5| Step: 1
Training loss: 3.076834316073801
Validation loss: 2.908227687583127

Epoch: 5| Step: 2
Training loss: 2.3865623110683316
Validation loss: 2.9077398737706455

Epoch: 5| Step: 3
Training loss: 2.907375158908157
Validation loss: 2.907375508089661

Epoch: 5| Step: 4
Training loss: 2.743369171198959
Validation loss: 2.9135261562655392

Epoch: 5| Step: 5
Training loss: 3.3018053260685862
Validation loss: 2.909926314959402

Epoch: 5| Step: 6
Training loss: 3.2558867619855207
Validation loss: 2.9100510070494883

Epoch: 5| Step: 7
Training loss: 3.561438151270111
Validation loss: 2.91141465612721

Epoch: 5| Step: 8
Training loss: 3.5232223140533105
Validation loss: 2.9101339095582923

Epoch: 5| Step: 9
Training loss: 2.944524280097548
Validation loss: 2.9081016575772636

Epoch: 5| Step: 10
Training loss: 3.994704436635053
Validation loss: 2.9066474334945624

Epoch: 156| Step: 0
Training loss: 2.4532612562303266
Validation loss: 2.9035841497646326

Epoch: 5| Step: 1
Training loss: 3.2558338917156595
Validation loss: 2.906233864345915

Epoch: 5| Step: 2
Training loss: 3.317970796480709
Validation loss: 2.9046888786365206

Epoch: 5| Step: 3
Training loss: 3.333800012980727
Validation loss: 2.90291565522509

Epoch: 5| Step: 4
Training loss: 3.853696034882936
Validation loss: 2.9044760707313593

Epoch: 5| Step: 5
Training loss: 2.878951963892484
Validation loss: 2.903151708771654

Epoch: 5| Step: 6
Training loss: 3.4397244278734704
Validation loss: 2.902020121701642

Epoch: 5| Step: 7
Training loss: 3.2197261182040187
Validation loss: 2.901687069252571

Epoch: 5| Step: 8
Training loss: 3.430609437945779
Validation loss: 2.905197622541039

Epoch: 5| Step: 9
Training loss: 2.6285964307129084
Validation loss: 2.9028720408309527

Epoch: 5| Step: 10
Training loss: 3.025654928386002
Validation loss: 2.9007855612678695

Epoch: 157| Step: 0
Training loss: 3.334558420758316
Validation loss: 2.9028342316212767

Epoch: 5| Step: 1
Training loss: 3.198113219012281
Validation loss: 2.90441956414617

Epoch: 5| Step: 2
Training loss: 2.7378574538592377
Validation loss: 2.9071712429730714

Epoch: 5| Step: 3
Training loss: 3.1933961078735953
Validation loss: 2.9049988893102925

Epoch: 5| Step: 4
Training loss: 3.444635649128805
Validation loss: 2.9048912779087632

Epoch: 5| Step: 5
Training loss: 3.3761011375988703
Validation loss: 2.9067250583637505

Epoch: 5| Step: 6
Training loss: 2.9047384946059944
Validation loss: 2.9101347623038523

Epoch: 5| Step: 7
Training loss: 2.8715271914531617
Validation loss: 2.9090625651089037

Epoch: 5| Step: 8
Training loss: 3.207884141927477
Validation loss: 2.9114730851904396

Epoch: 5| Step: 9
Training loss: 3.1221663788688243
Validation loss: 2.9049362175247997

Epoch: 5| Step: 10
Training loss: 3.6897472710629393
Validation loss: 2.906769997851504

Epoch: 158| Step: 0
Training loss: 3.515656195608122
Validation loss: 2.9005678935545713

Epoch: 5| Step: 1
Training loss: 3.387964285814289
Validation loss: 2.899776628673161

Epoch: 5| Step: 2
Training loss: 3.451923558357946
Validation loss: 2.9002361160467123

Epoch: 5| Step: 3
Training loss: 3.75711668555548
Validation loss: 2.896438998004781

Epoch: 5| Step: 4
Training loss: 3.1875333597270097
Validation loss: 2.8981071504811498

Epoch: 5| Step: 5
Training loss: 3.031717952513279
Validation loss: 2.899721083914567

Epoch: 5| Step: 6
Training loss: 2.1611255312942186
Validation loss: 2.8986641383097176

Epoch: 5| Step: 7
Training loss: 3.534062303763521
Validation loss: 2.898240897613265

Epoch: 5| Step: 8
Training loss: 3.0425705459427848
Validation loss: 2.8993204179113947

Epoch: 5| Step: 9
Training loss: 3.003659559421035
Validation loss: 2.8987150230491348

Epoch: 5| Step: 10
Training loss: 2.596622944154836
Validation loss: 2.897935785024229

Epoch: 159| Step: 0
Training loss: 3.2040621247287158
Validation loss: 2.898627503574409

Epoch: 5| Step: 1
Training loss: 3.1123886456160745
Validation loss: 2.900883294488309

Epoch: 5| Step: 2
Training loss: 3.2613634841140744
Validation loss: 2.8997414198894473

Epoch: 5| Step: 3
Training loss: 3.102963993317235
Validation loss: 2.8979004512547957

Epoch: 5| Step: 4
Training loss: 3.4454856361950017
Validation loss: 2.900238891623397

Epoch: 5| Step: 5
Training loss: 3.293638548150701
Validation loss: 2.8992741285610384

Epoch: 5| Step: 6
Training loss: 2.7319690691815306
Validation loss: 2.900242013702022

Epoch: 5| Step: 7
Training loss: 3.01192314354866
Validation loss: 2.8999010808931827

Epoch: 5| Step: 8
Training loss: 3.8462372462693772
Validation loss: 2.899349883549583

Epoch: 5| Step: 9
Training loss: 2.675100599162059
Validation loss: 2.899467246200792

Epoch: 5| Step: 10
Training loss: 3.2203696907069874
Validation loss: 2.8966058347111234

Epoch: 160| Step: 0
Training loss: 3.096439618128508
Validation loss: 2.8972271899069106

Epoch: 5| Step: 1
Training loss: 3.4450419140218997
Validation loss: 2.89620238583484

Epoch: 5| Step: 2
Training loss: 2.5826500224790117
Validation loss: 2.898171413564033

Epoch: 5| Step: 3
Training loss: 3.0132039684051266
Validation loss: 2.8966981704930057

Epoch: 5| Step: 4
Training loss: 3.5708437468036758
Validation loss: 2.895672083151481

Epoch: 5| Step: 5
Training loss: 3.437071894950638
Validation loss: 2.8977498986128207

Epoch: 5| Step: 6
Training loss: 3.404168148966497
Validation loss: 2.8963709842862864

Epoch: 5| Step: 7
Training loss: 2.5332442539849764
Validation loss: 2.895579573876379

Epoch: 5| Step: 8
Training loss: 3.067123037740367
Validation loss: 2.8949958639065585

Epoch: 5| Step: 9
Training loss: 3.2897309192666806
Validation loss: 2.8950243392573802

Epoch: 5| Step: 10
Training loss: 3.425347782493082
Validation loss: 2.897851295896014

Epoch: 161| Step: 0
Training loss: 3.5246551507317125
Validation loss: 2.894934266715815

Epoch: 5| Step: 1
Training loss: 2.973027250019399
Validation loss: 2.9004289645740857

Epoch: 5| Step: 2
Training loss: 3.6235123574377934
Validation loss: 2.8972738145782193

Epoch: 5| Step: 3
Training loss: 2.7970727605537955
Validation loss: 2.8967372757962995

Epoch: 5| Step: 4
Training loss: 3.1835187095738173
Validation loss: 2.900432666274855

Epoch: 5| Step: 5
Training loss: 3.2754495850853873
Validation loss: 2.8971146547578974

Epoch: 5| Step: 6
Training loss: 3.5578805520741064
Validation loss: 2.901236283119747

Epoch: 5| Step: 7
Training loss: 3.0369768610560475
Validation loss: 2.897876753033514

Epoch: 5| Step: 8
Training loss: 3.0618497197045267
Validation loss: 2.899518195536487

Epoch: 5| Step: 9
Training loss: 2.8027726546275264
Validation loss: 2.896327273109381

Epoch: 5| Step: 10
Training loss: 3.017589660424958
Validation loss: 2.8996601918377287

Epoch: 162| Step: 0
Training loss: 3.5088704644137487
Validation loss: 2.8988409570588543

Epoch: 5| Step: 1
Training loss: 3.313536715671199
Validation loss: 2.897325039619816

Epoch: 5| Step: 2
Training loss: 3.976038090690355
Validation loss: 2.893583617362485

Epoch: 5| Step: 3
Training loss: 3.8367538671142833
Validation loss: 2.894092381457705

Epoch: 5| Step: 4
Training loss: 2.9039436951635573
Validation loss: 2.8948594030848245

Epoch: 5| Step: 5
Training loss: 2.7131975850288703
Validation loss: 2.8940325437979575

Epoch: 5| Step: 6
Training loss: 3.126688996691428
Validation loss: 2.893997669963229

Epoch: 5| Step: 7
Training loss: 2.788498679907864
Validation loss: 2.8963992744059817

Epoch: 5| Step: 8
Training loss: 3.047995649780213
Validation loss: 2.892497239092525

Epoch: 5| Step: 9
Training loss: 2.1602018327370245
Validation loss: 2.8937321905474307

Epoch: 5| Step: 10
Training loss: 3.1993981987599662
Validation loss: 2.8960755837733085

Epoch: 163| Step: 0
Training loss: 2.758684663400752
Validation loss: 2.890954258909361

Epoch: 5| Step: 1
Training loss: 3.3548556423824833
Validation loss: 2.8912807431430907

Epoch: 5| Step: 2
Training loss: 2.949895475443162
Validation loss: 2.892644265715231

Epoch: 5| Step: 3
Training loss: 2.863427464185424
Validation loss: 2.888605228865476

Epoch: 5| Step: 4
Training loss: 3.1930018793585
Validation loss: 2.890613141488692

Epoch: 5| Step: 5
Training loss: 3.4745115252435546
Validation loss: 2.8881295591650544

Epoch: 5| Step: 6
Training loss: 3.271487581621563
Validation loss: 2.890449498643264

Epoch: 5| Step: 7
Training loss: 3.1625825411311834
Validation loss: 2.8887733885875297

Epoch: 5| Step: 8
Training loss: 3.2920525883939
Validation loss: 2.888479583474101

Epoch: 5| Step: 9
Training loss: 3.206734609882042
Validation loss: 2.890717403550182

Epoch: 5| Step: 10
Training loss: 3.4383283137329363
Validation loss: 2.886805926286048

Epoch: 164| Step: 0
Training loss: 3.0740180331751685
Validation loss: 2.8889310893922384

Epoch: 5| Step: 1
Training loss: 3.1386598730421587
Validation loss: 2.8939521423580863

Epoch: 5| Step: 2
Training loss: 3.3206189541480757
Validation loss: 2.8916657245825124

Epoch: 5| Step: 3
Training loss: 3.6095189978208846
Validation loss: 2.8937471113215123

Epoch: 5| Step: 4
Training loss: 3.3722317963795407
Validation loss: 2.8913009345481777

Epoch: 5| Step: 5
Training loss: 2.9335724566991033
Validation loss: 2.89116118872833

Epoch: 5| Step: 6
Training loss: 3.1093815942435574
Validation loss: 2.8877541256076693

Epoch: 5| Step: 7
Training loss: 2.51165439173233
Validation loss: 2.887135239359964

Epoch: 5| Step: 8
Training loss: 3.600650431896277
Validation loss: 2.8866699619592224

Epoch: 5| Step: 9
Training loss: 3.0206530462376224
Validation loss: 2.885443695345729

Epoch: 5| Step: 10
Training loss: 3.143952537974318
Validation loss: 2.886817158375945

Epoch: 165| Step: 0
Training loss: 2.916871708520079
Validation loss: 2.8859155730836332

Epoch: 5| Step: 1
Training loss: 3.7467905933840746
Validation loss: 2.884484502375202

Epoch: 5| Step: 2
Training loss: 2.9710531837328067
Validation loss: 2.8870594653332815

Epoch: 5| Step: 3
Training loss: 3.187535154859371
Validation loss: 2.887527474425958

Epoch: 5| Step: 4
Training loss: 2.958311662907994
Validation loss: 2.8863324248152256

Epoch: 5| Step: 5
Training loss: 3.0636272302166754
Validation loss: 2.8861726900490705

Epoch: 5| Step: 6
Training loss: 3.0984835391873147
Validation loss: 2.884039680924796

Epoch: 5| Step: 7
Training loss: 2.477305977592637
Validation loss: 2.886759216024079

Epoch: 5| Step: 8
Training loss: 3.164985427943427
Validation loss: 2.8855508654871658

Epoch: 5| Step: 9
Training loss: 3.7218015316006574
Validation loss: 2.892633304406289

Epoch: 5| Step: 10
Training loss: 3.486665118516781
Validation loss: 2.889213510511418

Epoch: 166| Step: 0
Training loss: 3.2323348388017967
Validation loss: 2.8910296714769324

Epoch: 5| Step: 1
Training loss: 3.329398900901002
Validation loss: 2.8920095013238707

Epoch: 5| Step: 2
Training loss: 3.702862307731619
Validation loss: 2.8898608544909488

Epoch: 5| Step: 3
Training loss: 2.885551495391505
Validation loss: 2.8874027064097416

Epoch: 5| Step: 4
Training loss: 3.369550190232677
Validation loss: 2.8861542854665885

Epoch: 5| Step: 5
Training loss: 2.685773871798553
Validation loss: 2.88820841490646

Epoch: 5| Step: 6
Training loss: 2.8722946043094733
Validation loss: 2.890043741777912

Epoch: 5| Step: 7
Training loss: 3.35034399401537
Validation loss: 2.888798703862389

Epoch: 5| Step: 8
Training loss: 3.1055508968596603
Validation loss: 2.891508399008463

Epoch: 5| Step: 9
Training loss: 3.3990672963936146
Validation loss: 2.8913910803761405

Epoch: 5| Step: 10
Training loss: 2.752130550082475
Validation loss: 2.8866693225298845

Epoch: 167| Step: 0
Training loss: 3.396871131256062
Validation loss: 2.887550520689116

Epoch: 5| Step: 1
Training loss: 3.1519853844376398
Validation loss: 2.8852119685641493

Epoch: 5| Step: 2
Training loss: 2.290309319074298
Validation loss: 2.883575965303146

Epoch: 5| Step: 3
Training loss: 3.086381556757298
Validation loss: 2.8847163311397015

Epoch: 5| Step: 4
Training loss: 3.242640158065978
Validation loss: 2.883845274151156

Epoch: 5| Step: 5
Training loss: 3.2287319916249904
Validation loss: 2.8849250271250284

Epoch: 5| Step: 6
Training loss: 2.999836917259231
Validation loss: 2.886082328818073

Epoch: 5| Step: 7
Training loss: 3.365481340464561
Validation loss: 2.8818149770006394

Epoch: 5| Step: 8
Training loss: 3.246209207953449
Validation loss: 2.881818088793094

Epoch: 5| Step: 9
Training loss: 3.5991332494219668
Validation loss: 2.8840361519651854

Epoch: 5| Step: 10
Training loss: 3.130272499141932
Validation loss: 2.883833063287197

Epoch: 168| Step: 0
Training loss: 3.102844588257587
Validation loss: 2.881801379549078

Epoch: 5| Step: 1
Training loss: 2.7274479780821728
Validation loss: 2.883086806335265

Epoch: 5| Step: 2
Training loss: 3.0090579934482102
Validation loss: 2.8806767269276796

Epoch: 5| Step: 3
Training loss: 3.197088741193679
Validation loss: 2.8808988341195723

Epoch: 5| Step: 4
Training loss: 3.8267508395393395
Validation loss: 2.880244525295662

Epoch: 5| Step: 5
Training loss: 3.3450863743508443
Validation loss: 2.8808308343879667

Epoch: 5| Step: 6
Training loss: 3.168942303060975
Validation loss: 2.883879261791102

Epoch: 5| Step: 7
Training loss: 2.658911235818326
Validation loss: 2.879738874207903

Epoch: 5| Step: 8
Training loss: 3.4038640336383987
Validation loss: 2.878725103255738

Epoch: 5| Step: 9
Training loss: 3.2052623037993673
Validation loss: 2.878836998339166

Epoch: 5| Step: 10
Training loss: 3.086441192081543
Validation loss: 2.8784192775484785

Epoch: 169| Step: 0
Training loss: 3.205147007324627
Validation loss: 2.8782770723786153

Epoch: 5| Step: 1
Training loss: 3.171078586659592
Validation loss: 2.8788732945136344

Epoch: 5| Step: 2
Training loss: 3.264220743465851
Validation loss: 2.8818714566671937

Epoch: 5| Step: 3
Training loss: 2.603221375878324
Validation loss: 2.8854239462862865

Epoch: 5| Step: 4
Training loss: 3.6012062012360246
Validation loss: 2.8868042727283263

Epoch: 5| Step: 5
Training loss: 2.6498506539924764
Validation loss: 2.9038548774724653

Epoch: 5| Step: 6
Training loss: 3.4216564927381117
Validation loss: 2.908768205832901

Epoch: 5| Step: 7
Training loss: 3.3779234763422226
Validation loss: 2.913605985001534

Epoch: 5| Step: 8
Training loss: 2.8278974578536276
Validation loss: 2.9030045316771425

Epoch: 5| Step: 9
Training loss: 3.2957889160043945
Validation loss: 2.8971332666827645

Epoch: 5| Step: 10
Training loss: 3.400254879542063
Validation loss: 2.886502078475683

Epoch: 170| Step: 0
Training loss: 3.0101341106156054
Validation loss: 2.8865207259678574

Epoch: 5| Step: 1
Training loss: 3.1280682569115177
Validation loss: 2.8809834137429107

Epoch: 5| Step: 2
Training loss: 3.053443753051914
Validation loss: 2.879605754483719

Epoch: 5| Step: 3
Training loss: 3.685447768358127
Validation loss: 2.8800187821328405

Epoch: 5| Step: 4
Training loss: 3.198334773230481
Validation loss: 2.874515423949073

Epoch: 5| Step: 5
Training loss: 3.059108335194672
Validation loss: 2.8760291812606393

Epoch: 5| Step: 6
Training loss: 2.83155303074443
Validation loss: 2.875569600574643

Epoch: 5| Step: 7
Training loss: 2.9107644079307695
Validation loss: 2.877231830203776

Epoch: 5| Step: 8
Training loss: 3.513788582865811
Validation loss: 2.8745102253425

Epoch: 5| Step: 9
Training loss: 3.2693190420324827
Validation loss: 2.8772634163139856

Epoch: 5| Step: 10
Training loss: 3.156649271572352
Validation loss: 2.876775859212482

Epoch: 171| Step: 0
Training loss: 2.688706947595596
Validation loss: 2.8772852332481795

Epoch: 5| Step: 1
Training loss: 3.3944136727605447
Validation loss: 2.873456052626255

Epoch: 5| Step: 2
Training loss: 2.4885909098919563
Validation loss: 2.881421041239937

Epoch: 5| Step: 3
Training loss: 3.489584138025599
Validation loss: 2.8819274886689623

Epoch: 5| Step: 4
Training loss: 3.20239934377442
Validation loss: 2.8780953008165513

Epoch: 5| Step: 5
Training loss: 3.851846123518583
Validation loss: 2.875505969095327

Epoch: 5| Step: 6
Training loss: 3.7579034806180314
Validation loss: 2.877102636284838

Epoch: 5| Step: 7
Training loss: 3.1340685678465725
Validation loss: 2.8748779921928267

Epoch: 5| Step: 8
Training loss: 2.8413775262437526
Validation loss: 2.879780271558555

Epoch: 5| Step: 9
Training loss: 3.0718252711573615
Validation loss: 2.875957910821367

Epoch: 5| Step: 10
Training loss: 2.4859823149760207
Validation loss: 2.8776374835382144

Epoch: 172| Step: 0
Training loss: 2.860598609807588
Validation loss: 2.8816621356396297

Epoch: 5| Step: 1
Training loss: 3.2619634662128307
Validation loss: 2.876984687437506

Epoch: 5| Step: 2
Training loss: 3.098753457015534
Validation loss: 2.8761469696312494

Epoch: 5| Step: 3
Training loss: 3.51413596938538
Validation loss: 2.8762908559348785

Epoch: 5| Step: 4
Training loss: 3.5847636776208343
Validation loss: 2.871703058274233

Epoch: 5| Step: 5
Training loss: 3.0106416154038276
Validation loss: 2.8742198447355243

Epoch: 5| Step: 6
Training loss: 2.7132843149367227
Validation loss: 2.872822756147306

Epoch: 5| Step: 7
Training loss: 3.184365021125649
Validation loss: 2.8765144282945747

Epoch: 5| Step: 8
Training loss: 3.29608897018719
Validation loss: 2.873949013067864

Epoch: 5| Step: 9
Training loss: 3.5401501868334506
Validation loss: 2.873335873438268

Epoch: 5| Step: 10
Training loss: 2.487947977644495
Validation loss: 2.875461341613125

Epoch: 173| Step: 0
Training loss: 2.702463057950995
Validation loss: 2.876294406875482

Epoch: 5| Step: 1
Training loss: 3.3549767378840594
Validation loss: 2.8716720225276764

Epoch: 5| Step: 2
Training loss: 3.4440907498408992
Validation loss: 2.874103697122551

Epoch: 5| Step: 3
Training loss: 3.497314512775414
Validation loss: 2.873634447444109

Epoch: 5| Step: 4
Training loss: 2.971071640522193
Validation loss: 2.8767125351336653

Epoch: 5| Step: 5
Training loss: 3.13734864861538
Validation loss: 2.8718745759453537

Epoch: 5| Step: 6
Training loss: 2.827128450787512
Validation loss: 2.8734267015316757

Epoch: 5| Step: 7
Training loss: 2.9709562435824832
Validation loss: 2.8746023772545937

Epoch: 5| Step: 8
Training loss: 2.9756245574598297
Validation loss: 2.8733308734468803

Epoch: 5| Step: 9
Training loss: 3.431627007567603
Validation loss: 2.882979220026308

Epoch: 5| Step: 10
Training loss: 3.416865335286485
Validation loss: 2.8791903008936295

Epoch: 174| Step: 0
Training loss: 2.976600786899021
Validation loss: 2.8750701751276866

Epoch: 5| Step: 1
Training loss: 3.5379690876974785
Validation loss: 2.8756996318263273

Epoch: 5| Step: 2
Training loss: 3.0100542706130953
Validation loss: 2.876104321998652

Epoch: 5| Step: 3
Training loss: 3.5105847658986344
Validation loss: 2.878842996825826

Epoch: 5| Step: 4
Training loss: 3.2553963975622433
Validation loss: 2.8835727967303892

Epoch: 5| Step: 5
Training loss: 3.044839815082514
Validation loss: 2.8806453900531825

Epoch: 5| Step: 6
Training loss: 2.6149068888029983
Validation loss: 2.881329314715277

Epoch: 5| Step: 7
Training loss: 3.722777934052023
Validation loss: 2.8746064118654977

Epoch: 5| Step: 8
Training loss: 3.2167263150655443
Validation loss: 2.8712514343333853

Epoch: 5| Step: 9
Training loss: 2.9204955082959896
Validation loss: 2.8708594540172205

Epoch: 5| Step: 10
Training loss: 2.750170529020007
Validation loss: 2.8702146287954364

Epoch: 175| Step: 0
Training loss: 3.1219366699481577
Validation loss: 2.8680207177727355

Epoch: 5| Step: 1
Training loss: 2.8205083636379817
Validation loss: 2.8682058834365245

Epoch: 5| Step: 2
Training loss: 2.98470076934961
Validation loss: 2.8722951514370405

Epoch: 5| Step: 3
Training loss: 2.8985793086729563
Validation loss: 2.870669301284489

Epoch: 5| Step: 4
Training loss: 3.358561572577164
Validation loss: 2.869184757505506

Epoch: 5| Step: 5
Training loss: 3.4182388286152747
Validation loss: 2.8692033111471065

Epoch: 5| Step: 6
Training loss: 3.3158365396076843
Validation loss: 2.8669347395425113

Epoch: 5| Step: 7
Training loss: 3.1086777715264438
Validation loss: 2.8697116503348927

Epoch: 5| Step: 8
Training loss: 2.7850176548012997
Validation loss: 2.8721717041427004

Epoch: 5| Step: 9
Training loss: 3.4221233121056343
Validation loss: 2.870242463071295

Epoch: 5| Step: 10
Training loss: 3.4965593592709494
Validation loss: 2.869007290529972

Epoch: 176| Step: 0
Training loss: 3.380126450560296
Validation loss: 2.8663053972700916

Epoch: 5| Step: 1
Training loss: 3.043078282237204
Validation loss: 2.8665738960969747

Epoch: 5| Step: 2
Training loss: 3.336271675756938
Validation loss: 2.8674407620914573

Epoch: 5| Step: 3
Training loss: 3.8025288499368486
Validation loss: 2.866532289243925

Epoch: 5| Step: 4
Training loss: 3.2281400135499885
Validation loss: 2.8668021430731536

Epoch: 5| Step: 5
Training loss: 3.2422458873225306
Validation loss: 2.863598520506569

Epoch: 5| Step: 6
Training loss: 2.607967522494993
Validation loss: 2.865251926171773

Epoch: 5| Step: 7
Training loss: 3.095576816232366
Validation loss: 2.866551706088989

Epoch: 5| Step: 8
Training loss: 2.7321613179356965
Validation loss: 2.8674452636388432

Epoch: 5| Step: 9
Training loss: 3.2388026205460494
Validation loss: 2.865800494622553

Epoch: 5| Step: 10
Training loss: 2.8326327822908994
Validation loss: 2.864646167830422

Epoch: 177| Step: 0
Training loss: 3.2760162756845097
Validation loss: 2.8645226253814906

Epoch: 5| Step: 1
Training loss: 2.9474612222309515
Validation loss: 2.864492030921402

Epoch: 5| Step: 2
Training loss: 2.6191937855809337
Validation loss: 2.8681746650486506

Epoch: 5| Step: 3
Training loss: 3.5783844566394825
Validation loss: 2.864868866383503

Epoch: 5| Step: 4
Training loss: 2.8681808538727926
Validation loss: 2.8657951665971555

Epoch: 5| Step: 5
Training loss: 2.39283191814019
Validation loss: 2.867772286845524

Epoch: 5| Step: 6
Training loss: 2.603600605796126
Validation loss: 2.8654751591789895

Epoch: 5| Step: 7
Training loss: 3.3709904907961525
Validation loss: 2.865433769882964

Epoch: 5| Step: 8
Training loss: 4.136292461731822
Validation loss: 2.866790907681782

Epoch: 5| Step: 9
Training loss: 3.3083089550539024
Validation loss: 2.8688963095648536

Epoch: 5| Step: 10
Training loss: 3.2370869789163565
Validation loss: 2.870087534292164

Epoch: 178| Step: 0
Training loss: 3.0205068653005305
Validation loss: 2.86848186988105

Epoch: 5| Step: 1
Training loss: 3.093889175521275
Validation loss: 2.8702284428044162

Epoch: 5| Step: 2
Training loss: 3.5972108844854978
Validation loss: 2.866700653626859

Epoch: 5| Step: 3
Training loss: 2.8474249935570044
Validation loss: 2.8642162266010702

Epoch: 5| Step: 4
Training loss: 3.3501683605646475
Validation loss: 2.863389742950976

Epoch: 5| Step: 5
Training loss: 2.7036881935085053
Validation loss: 2.8603795967191252

Epoch: 5| Step: 6
Training loss: 3.5188534980581245
Validation loss: 2.8617675909666396

Epoch: 5| Step: 7
Training loss: 3.1667487150571967
Validation loss: 2.8603687412108796

Epoch: 5| Step: 8
Training loss: 3.1705048707191583
Validation loss: 2.8604080949210102

Epoch: 5| Step: 9
Training loss: 2.5915587027611737
Validation loss: 2.8605737117412016

Epoch: 5| Step: 10
Training loss: 3.5812080793606818
Validation loss: 2.857768642600537

Epoch: 179| Step: 0
Training loss: 4.063560230115264
Validation loss: 2.8626528275560585

Epoch: 5| Step: 1
Training loss: 3.052351504751235
Validation loss: 2.8576441604850786

Epoch: 5| Step: 2
Training loss: 2.9876515242325405
Validation loss: 2.8588928321791296

Epoch: 5| Step: 3
Training loss: 2.816014361794652
Validation loss: 2.859071563609891

Epoch: 5| Step: 4
Training loss: 3.1200349656615525
Validation loss: 2.8592316468120775

Epoch: 5| Step: 5
Training loss: 3.4438755905595593
Validation loss: 2.8606606272942656

Epoch: 5| Step: 6
Training loss: 2.8431506520923517
Validation loss: 2.85961383907166

Epoch: 5| Step: 7
Training loss: 2.5145149388107524
Validation loss: 2.860112939204222

Epoch: 5| Step: 8
Training loss: 3.437261399744829
Validation loss: 2.86141848221463

Epoch: 5| Step: 9
Training loss: 3.122899532122661
Validation loss: 2.865006896145996

Epoch: 5| Step: 10
Training loss: 3.056061652685071
Validation loss: 2.8658840760535207

Epoch: 180| Step: 0
Training loss: 2.6471446434769614
Validation loss: 2.870629168395691

Epoch: 5| Step: 1
Training loss: 3.7028711932157945
Validation loss: 2.8772207121668774

Epoch: 5| Step: 2
Training loss: 3.187244779055448
Validation loss: 2.8859169233424176

Epoch: 5| Step: 3
Training loss: 3.078431399824081
Validation loss: 2.8718185513344565

Epoch: 5| Step: 4
Training loss: 3.3246031560202085
Validation loss: 2.8696652425083222

Epoch: 5| Step: 5
Training loss: 2.7138257210533046
Validation loss: 2.862130769985578

Epoch: 5| Step: 6
Training loss: 3.6043036697603124
Validation loss: 2.8589148574533985

Epoch: 5| Step: 7
Training loss: 2.6534624619748017
Validation loss: 2.858765191288654

Epoch: 5| Step: 8
Training loss: 3.041399922279813
Validation loss: 2.8592295397572958

Epoch: 5| Step: 9
Training loss: 3.4443410598115443
Validation loss: 2.857414704675644

Epoch: 5| Step: 10
Training loss: 3.171002498196256
Validation loss: 2.85794440074034

Epoch: 181| Step: 0
Training loss: 3.478207591156712
Validation loss: 2.8574528654517084

Epoch: 5| Step: 1
Training loss: 3.073787828657109
Validation loss: 2.857479531218398

Epoch: 5| Step: 2
Training loss: 2.8804015128738927
Validation loss: 2.855978687345306

Epoch: 5| Step: 3
Training loss: 3.9563172007754708
Validation loss: 2.858562793225575

Epoch: 5| Step: 4
Training loss: 2.796989054991577
Validation loss: 2.8550771744943524

Epoch: 5| Step: 5
Training loss: 2.863862898427362
Validation loss: 2.859971874728958

Epoch: 5| Step: 6
Training loss: 2.6440315619704315
Validation loss: 2.8573849914205582

Epoch: 5| Step: 7
Training loss: 3.3925396132493164
Validation loss: 2.861367927825165

Epoch: 5| Step: 8
Training loss: 2.7532802438428337
Validation loss: 2.8599980240010496

Epoch: 5| Step: 9
Training loss: 3.430287788707311
Validation loss: 2.861677888892944

Epoch: 5| Step: 10
Training loss: 3.2150568839301643
Validation loss: 2.8604881432622022

Epoch: 182| Step: 0
Training loss: 3.251897844640877
Validation loss: 2.8632203619292054

Epoch: 5| Step: 1
Training loss: 3.043203479493696
Validation loss: 2.8635645105984966

Epoch: 5| Step: 2
Training loss: 3.1764469364008754
Validation loss: 2.8622427817683223

Epoch: 5| Step: 3
Training loss: 3.3177826701908386
Validation loss: 2.8632626427630052

Epoch: 5| Step: 4
Training loss: 2.6196315911129067
Validation loss: 2.862981958041832

Epoch: 5| Step: 5
Training loss: 3.336687276232239
Validation loss: 2.8605301911357333

Epoch: 5| Step: 6
Training loss: 3.336380725870689
Validation loss: 2.859789638893386

Epoch: 5| Step: 7
Training loss: 3.3470263250140286
Validation loss: 2.864421801594675

Epoch: 5| Step: 8
Training loss: 2.512652803395765
Validation loss: 2.8614169035793924

Epoch: 5| Step: 9
Training loss: 3.4815309147522986
Validation loss: 2.8649945226681846

Epoch: 5| Step: 10
Training loss: 3.1059784860744015
Validation loss: 2.862395534247207

Epoch: 183| Step: 0
Training loss: 3.193769982680423
Validation loss: 2.8587314763120006

Epoch: 5| Step: 1
Training loss: 3.1630906107656895
Validation loss: 2.855940429673358

Epoch: 5| Step: 2
Training loss: 3.428619148853267
Validation loss: 2.856503445244376

Epoch: 5| Step: 3
Training loss: 2.861492436088551
Validation loss: 2.855943289591195

Epoch: 5| Step: 4
Training loss: 3.145932396008978
Validation loss: 2.8589236712817985

Epoch: 5| Step: 5
Training loss: 3.3512622903316047
Validation loss: 2.8641564145977116

Epoch: 5| Step: 6
Training loss: 3.3191241841842287
Validation loss: 2.8638535993990555

Epoch: 5| Step: 7
Training loss: 2.8580672812207157
Validation loss: 2.858342328131137

Epoch: 5| Step: 8
Training loss: 3.311868859389948
Validation loss: 2.8555006028783776

Epoch: 5| Step: 9
Training loss: 3.2025098256445066
Validation loss: 2.853655901833884

Epoch: 5| Step: 10
Training loss: 2.7293829989900247
Validation loss: 2.854964396678204

Epoch: 184| Step: 0
Training loss: 2.7817666077607033
Validation loss: 2.8548714330735243

Epoch: 5| Step: 1
Training loss: 3.1988932126040925
Validation loss: 2.859248693276475

Epoch: 5| Step: 2
Training loss: 2.835056809221154
Validation loss: 2.863562262594605

Epoch: 5| Step: 3
Training loss: 2.6960780728861797
Validation loss: 2.8634484939249636

Epoch: 5| Step: 4
Training loss: 3.234732198110634
Validation loss: 2.865630803418978

Epoch: 5| Step: 5
Training loss: 3.37901265412304
Validation loss: 2.863579758661144

Epoch: 5| Step: 6
Training loss: 3.3974062001554923
Validation loss: 2.8599312044806466

Epoch: 5| Step: 7
Training loss: 3.3765088699791463
Validation loss: 2.8608954099386814

Epoch: 5| Step: 8
Training loss: 3.8585315354084138
Validation loss: 2.8586562986249398

Epoch: 5| Step: 9
Training loss: 2.6288044925398233
Validation loss: 2.8544329459231195

Epoch: 5| Step: 10
Training loss: 3.0359903610739907
Validation loss: 2.855345524253084

Epoch: 185| Step: 0
Training loss: 3.1023357205850197
Validation loss: 2.8546336233423686

Epoch: 5| Step: 1
Training loss: 3.01733444859575
Validation loss: 2.852033392885888

Epoch: 5| Step: 2
Training loss: 2.9485921636224104
Validation loss: 2.8605238378839117

Epoch: 5| Step: 3
Training loss: 3.809649918660057
Validation loss: 2.853048187319167

Epoch: 5| Step: 4
Training loss: 3.3286850149162253
Validation loss: 2.852672596934901

Epoch: 5| Step: 5
Training loss: 2.504144094897547
Validation loss: 2.8531385102384754

Epoch: 5| Step: 6
Training loss: 3.1978445303833847
Validation loss: 2.85328461344188

Epoch: 5| Step: 7
Training loss: 3.0783917461554258
Validation loss: 2.8527762371539853

Epoch: 5| Step: 8
Training loss: 3.2737821338383024
Validation loss: 2.8513211289607465

Epoch: 5| Step: 9
Training loss: 3.340827877211181
Validation loss: 2.8486363907178456

Epoch: 5| Step: 10
Training loss: 2.7908846675616346
Validation loss: 2.8494168189880575

Epoch: 186| Step: 0
Training loss: 2.851973830564476
Validation loss: 2.850624544925276

Epoch: 5| Step: 1
Training loss: 2.637824836722897
Validation loss: 2.8470661058168805

Epoch: 5| Step: 2
Training loss: 2.9853279230132097
Validation loss: 2.846611924037617

Epoch: 5| Step: 3
Training loss: 3.149974665464217
Validation loss: 2.847628907069406

Epoch: 5| Step: 4
Training loss: 3.0708364568631468
Validation loss: 2.8490924938968964

Epoch: 5| Step: 5
Training loss: 2.608947170613137
Validation loss: 2.8479545510505795

Epoch: 5| Step: 6
Training loss: 3.5854570320394408
Validation loss: 2.847671516625444

Epoch: 5| Step: 7
Training loss: 3.5795354603549434
Validation loss: 2.846868198040358

Epoch: 5| Step: 8
Training loss: 2.9929580692268964
Validation loss: 2.8461903393390062

Epoch: 5| Step: 9
Training loss: 3.731360076354087
Validation loss: 2.847787120980828

Epoch: 5| Step: 10
Training loss: 3.2080145012772734
Validation loss: 2.846791329248469

Epoch: 187| Step: 0
Training loss: 3.2401356282515907
Validation loss: 2.8493928075029356

Epoch: 5| Step: 1
Training loss: 3.516145523531608
Validation loss: 2.848557294495873

Epoch: 5| Step: 2
Training loss: 3.320108277267222
Validation loss: 2.8490246105559134

Epoch: 5| Step: 3
Training loss: 3.1063845261853733
Validation loss: 2.8523423406705475

Epoch: 5| Step: 4
Training loss: 2.6453025966398074
Validation loss: 2.851792165082384

Epoch: 5| Step: 5
Training loss: 3.084594125123765
Validation loss: 2.8539121658204007

Epoch: 5| Step: 6
Training loss: 3.0423183701025565
Validation loss: 2.851387884120734

Epoch: 5| Step: 7
Training loss: 2.829732364359967
Validation loss: 2.852622956998528

Epoch: 5| Step: 8
Training loss: 2.680978625242575
Validation loss: 2.849822935840642

Epoch: 5| Step: 9
Training loss: 3.2819310526001297
Validation loss: 2.8504817400782025

Epoch: 5| Step: 10
Training loss: 3.75525741791975
Validation loss: 2.8473551103814594

Epoch: 188| Step: 0
Training loss: 3.650311987097735
Validation loss: 2.846094445420829

Epoch: 5| Step: 1
Training loss: 2.4758874592941593
Validation loss: 2.846205084202664

Epoch: 5| Step: 2
Training loss: 3.46742539417011
Validation loss: 2.845336876079836

Epoch: 5| Step: 3
Training loss: 3.4867872432722637
Validation loss: 2.846487661915958

Epoch: 5| Step: 4
Training loss: 3.092303930310232
Validation loss: 2.8459172402060147

Epoch: 5| Step: 5
Training loss: 3.37009553949328
Validation loss: 2.846128850992935

Epoch: 5| Step: 6
Training loss: 2.634070393067035
Validation loss: 2.8464643093079

Epoch: 5| Step: 7
Training loss: 2.8186507890585526
Validation loss: 2.8475443954800475

Epoch: 5| Step: 8
Training loss: 3.1740190747847072
Validation loss: 2.8466553287184735

Epoch: 5| Step: 9
Training loss: 3.372053343517252
Validation loss: 2.847573031138133

Epoch: 5| Step: 10
Training loss: 2.7293794175329116
Validation loss: 2.846528684551482

Epoch: 189| Step: 0
Training loss: 3.055985665152917
Validation loss: 2.846281102355458

Epoch: 5| Step: 1
Training loss: 3.5001903209711354
Validation loss: 2.8458251611649343

Epoch: 5| Step: 2
Training loss: 3.260698462710356
Validation loss: 2.847598778406516

Epoch: 5| Step: 3
Training loss: 3.075186629175578
Validation loss: 2.84465953296114

Epoch: 5| Step: 4
Training loss: 2.8925955988879704
Validation loss: 2.845486104787777

Epoch: 5| Step: 5
Training loss: 3.415809167083281
Validation loss: 2.8496380807707293

Epoch: 5| Step: 6
Training loss: 2.913143882469292
Validation loss: 2.8476236980907195

Epoch: 5| Step: 7
Training loss: 3.1999600288755743
Validation loss: 2.842127341884897

Epoch: 5| Step: 8
Training loss: 2.579971854182053
Validation loss: 2.845601197468079

Epoch: 5| Step: 9
Training loss: 3.193865833309477
Validation loss: 2.84610562559973

Epoch: 5| Step: 10
Training loss: 3.390774068763708
Validation loss: 2.8433874179241556

Epoch: 190| Step: 0
Training loss: 2.5325643635560775
Validation loss: 2.8432134482494207

Epoch: 5| Step: 1
Training loss: 2.95039459434312
Validation loss: 2.8437071928516353

Epoch: 5| Step: 2
Training loss: 2.6314846958046614
Validation loss: 2.8491998769445925

Epoch: 5| Step: 3
Training loss: 3.4646404770118258
Validation loss: 2.8426655357262933

Epoch: 5| Step: 4
Training loss: 3.391331471618577
Validation loss: 2.8465242183734474

Epoch: 5| Step: 5
Training loss: 3.092558660297782
Validation loss: 2.849607987745011

Epoch: 5| Step: 6
Training loss: 3.0113496665565127
Validation loss: 2.846727031988855

Epoch: 5| Step: 7
Training loss: 3.784864353384801
Validation loss: 2.849008250681715

Epoch: 5| Step: 8
Training loss: 3.1293496949925244
Validation loss: 2.8481407089344035

Epoch: 5| Step: 9
Training loss: 3.3282712805752555
Validation loss: 2.8467435481607026

Epoch: 5| Step: 10
Training loss: 2.955597664796808
Validation loss: 2.846610905466011

Epoch: 191| Step: 0
Training loss: 2.88898417323852
Validation loss: 2.8459998949489447

Epoch: 5| Step: 1
Training loss: 2.476045091172224
Validation loss: 2.8468858012059144

Epoch: 5| Step: 2
Training loss: 3.304068432983625
Validation loss: 2.8450920646015008

Epoch: 5| Step: 3
Training loss: 3.3697979714257498
Validation loss: 2.844817288409754

Epoch: 5| Step: 4
Training loss: 3.3229487466409613
Validation loss: 2.8444534805516546

Epoch: 5| Step: 5
Training loss: 3.0468740609974514
Validation loss: 2.8440525083798365

Epoch: 5| Step: 6
Training loss: 2.9632753991155494
Validation loss: 2.844624239487099

Epoch: 5| Step: 7
Training loss: 3.0288417727633172
Validation loss: 2.8453924103039743

Epoch: 5| Step: 8
Training loss: 3.4945995355693427
Validation loss: 2.847341313252982

Epoch: 5| Step: 9
Training loss: 2.9276558710914324
Validation loss: 2.84976857196889

Epoch: 5| Step: 10
Training loss: 3.6062440710167762
Validation loss: 2.8490241723381873

Epoch: 192| Step: 0
Training loss: 3.0938828565026086
Validation loss: 2.8498718419285027

Epoch: 5| Step: 1
Training loss: 3.8113237661477712
Validation loss: 2.8471531473847063

Epoch: 5| Step: 2
Training loss: 2.7284725461602406
Validation loss: 2.849330232557178

Epoch: 5| Step: 3
Training loss: 3.1318988181148475
Validation loss: 2.8452293697627167

Epoch: 5| Step: 4
Training loss: 3.0473033114918184
Validation loss: 2.8408125876912256

Epoch: 5| Step: 5
Training loss: 3.096495979896571
Validation loss: 2.8428634844769314

Epoch: 5| Step: 6
Training loss: 2.931737238685339
Validation loss: 2.8399243364591817

Epoch: 5| Step: 7
Training loss: 3.391409928135963
Validation loss: 2.8451990264718328

Epoch: 5| Step: 8
Training loss: 3.004882653812557
Validation loss: 2.8399108390411767

Epoch: 5| Step: 9
Training loss: 3.122084516457758
Validation loss: 2.841169399592606

Epoch: 5| Step: 10
Training loss: 2.962553765819053
Validation loss: 2.8392819689632076

Epoch: 193| Step: 0
Training loss: 3.172172194214642
Validation loss: 2.8377180488320413

Epoch: 5| Step: 1
Training loss: 3.183966080125485
Validation loss: 2.8374176289539923

Epoch: 5| Step: 2
Training loss: 2.7059690474990563
Validation loss: 2.8355478626835797

Epoch: 5| Step: 3
Training loss: 3.4723310801078306
Validation loss: 2.8375904709400412

Epoch: 5| Step: 4
Training loss: 2.8937140378097466
Validation loss: 2.836513074764562

Epoch: 5| Step: 5
Training loss: 3.540844601237437
Validation loss: 2.83491614922983

Epoch: 5| Step: 6
Training loss: 2.67800975360191
Validation loss: 2.837106879733877

Epoch: 5| Step: 7
Training loss: 3.1282199292636514
Validation loss: 2.8363637070292844

Epoch: 5| Step: 8
Training loss: 3.520794539077986
Validation loss: 2.836777933654433

Epoch: 5| Step: 9
Training loss: 3.054601019296131
Validation loss: 2.8337518562664616

Epoch: 5| Step: 10
Training loss: 2.965958095612067
Validation loss: 2.836194331771025

Epoch: 194| Step: 0
Training loss: 3.308289064612429
Validation loss: 2.834834178749763

Epoch: 5| Step: 1
Training loss: 3.597085748061373
Validation loss: 2.836677047370495

Epoch: 5| Step: 2
Training loss: 2.6580870614931054
Validation loss: 2.8399014976926518

Epoch: 5| Step: 3
Training loss: 2.865335391187513
Validation loss: 2.8403211257477197

Epoch: 5| Step: 4
Training loss: 2.307574723378073
Validation loss: 2.8403719680919943

Epoch: 5| Step: 5
Training loss: 2.925071558932863
Validation loss: 2.848603375727931

Epoch: 5| Step: 6
Training loss: 3.622862744857803
Validation loss: 2.8476412407694043

Epoch: 5| Step: 7
Training loss: 3.0617572117185814
Validation loss: 2.8423631494130923

Epoch: 5| Step: 8
Training loss: 3.4295256626466513
Validation loss: 2.839625632410149

Epoch: 5| Step: 9
Training loss: 3.301434442119115
Validation loss: 2.8353056147615687

Epoch: 5| Step: 10
Training loss: 3.140522969424738
Validation loss: 2.833554978239722

Epoch: 195| Step: 0
Training loss: 3.4287027322512897
Validation loss: 2.8341955918379447

Epoch: 5| Step: 1
Training loss: 2.934896898424598
Validation loss: 2.834146206288251

Epoch: 5| Step: 2
Training loss: 3.1602250552614675
Validation loss: 2.833511707643546

Epoch: 5| Step: 3
Training loss: 3.6853472357909576
Validation loss: 2.837902439134819

Epoch: 5| Step: 4
Training loss: 3.2304833629789655
Validation loss: 2.8350495425439988

Epoch: 5| Step: 5
Training loss: 2.6785939824199283
Validation loss: 2.8356945015432196

Epoch: 5| Step: 6
Training loss: 3.645194006676939
Validation loss: 2.8366344091326794

Epoch: 5| Step: 7
Training loss: 3.1574225938601033
Validation loss: 2.834326445770365

Epoch: 5| Step: 8
Training loss: 2.2879142094380494
Validation loss: 2.8354863383917417

Epoch: 5| Step: 9
Training loss: 3.3686516006055314
Validation loss: 2.8346077214309107

Epoch: 5| Step: 10
Training loss: 2.4945653973400748
Validation loss: 2.8319544999101383

Epoch: 196| Step: 0
Training loss: 2.6135743665315645
Validation loss: 2.83484614398495

Epoch: 5| Step: 1
Training loss: 3.3138046574410844
Validation loss: 2.8316564544037965

Epoch: 5| Step: 2
Training loss: 3.282748942642791
Validation loss: 2.835507997582855

Epoch: 5| Step: 3
Training loss: 3.0635156309769718
Validation loss: 2.832762574453652

Epoch: 5| Step: 4
Training loss: 3.122640863666512
Validation loss: 2.8327784209006426

Epoch: 5| Step: 5
Training loss: 3.4340028486556613
Validation loss: 2.8335827392553106

Epoch: 5| Step: 6
Training loss: 3.365186765115917
Validation loss: 2.830839679071458

Epoch: 5| Step: 7
Training loss: 2.945911296008866
Validation loss: 2.834746280516954

Epoch: 5| Step: 8
Training loss: 3.3957597377423756
Validation loss: 2.8328050854472333

Epoch: 5| Step: 9
Training loss: 3.1357703194296325
Validation loss: 2.8325701439103526

Epoch: 5| Step: 10
Training loss: 2.5585438963714155
Validation loss: 2.8325171015769963

Epoch: 197| Step: 0
Training loss: 2.891330612252875
Validation loss: 2.8321939541447465

Epoch: 5| Step: 1
Training loss: 3.1576886816726835
Validation loss: 2.833363072011846

Epoch: 5| Step: 2
Training loss: 3.623229284912812
Validation loss: 2.8301273577951567

Epoch: 5| Step: 3
Training loss: 2.758055678930771
Validation loss: 2.8342990031892383

Epoch: 5| Step: 4
Training loss: 3.5804100236565084
Validation loss: 2.830043665157251

Epoch: 5| Step: 5
Training loss: 2.553690117774835
Validation loss: 2.8314022758961577

Epoch: 5| Step: 6
Training loss: 3.0757494439613913
Validation loss: 2.8314900117486523

Epoch: 5| Step: 7
Training loss: 3.5693685339653856
Validation loss: 2.828304945191341

Epoch: 5| Step: 8
Training loss: 3.385104277454135
Validation loss: 2.8305918585364718

Epoch: 5| Step: 9
Training loss: 2.9410773064220996
Validation loss: 2.8294507798151125

Epoch: 5| Step: 10
Training loss: 2.5285558609256173
Validation loss: 2.828391025966675

Epoch: 198| Step: 0
Training loss: 2.9056784775428883
Validation loss: 2.8329426920202976

Epoch: 5| Step: 1
Training loss: 2.4552088348383845
Validation loss: 2.8365145877254285

Epoch: 5| Step: 2
Training loss: 3.0102671725807633
Validation loss: 2.836926573815306

Epoch: 5| Step: 3
Training loss: 3.2088533120488805
Validation loss: 2.8327660659285696

Epoch: 5| Step: 4
Training loss: 3.1371699064559215
Validation loss: 2.834532549695914

Epoch: 5| Step: 5
Training loss: 3.2378779069243677
Validation loss: 2.8385981948219836

Epoch: 5| Step: 6
Training loss: 3.4959132995067908
Validation loss: 2.83225259642188

Epoch: 5| Step: 7
Training loss: 2.869552426944217
Validation loss: 2.829839135846369

Epoch: 5| Step: 8
Training loss: 3.1090354542347174
Validation loss: 2.831305678295359

Epoch: 5| Step: 9
Training loss: 3.4827354234370267
Validation loss: 2.829129874663935

Epoch: 5| Step: 10
Training loss: 3.3731537466783914
Validation loss: 2.829098461592214

Epoch: 199| Step: 0
Training loss: 2.9671244135975496
Validation loss: 2.8302992455501697

Epoch: 5| Step: 1
Training loss: 3.5800918437322395
Validation loss: 2.8288436418050744

Epoch: 5| Step: 2
Training loss: 3.0092473558587165
Validation loss: 2.827185264876172

Epoch: 5| Step: 3
Training loss: 2.759694610783519
Validation loss: 2.826700526592594

Epoch: 5| Step: 4
Training loss: 3.091191168015857
Validation loss: 2.829587826514915

Epoch: 5| Step: 5
Training loss: 3.025446891877107
Validation loss: 2.831936124081679

Epoch: 5| Step: 6
Training loss: 3.0188244859813635
Validation loss: 2.8344096112685575

Epoch: 5| Step: 7
Training loss: 3.1955173865107787
Validation loss: 2.8339652289391344

Epoch: 5| Step: 8
Training loss: 2.7030715496092825
Validation loss: 2.8311482285057097

Epoch: 5| Step: 9
Training loss: 3.1030715615088105
Validation loss: 2.8268949264901404

Epoch: 5| Step: 10
Training loss: 3.8757698770950983
Validation loss: 2.825860727386138

Epoch: 200| Step: 0
Training loss: 2.916296708394748
Validation loss: 2.824573789826578

Epoch: 5| Step: 1
Training loss: 3.6503270094192657
Validation loss: 2.823680739014083

Epoch: 5| Step: 2
Training loss: 2.3295912253880044
Validation loss: 2.8256284628694273

Epoch: 5| Step: 3
Training loss: 2.166412619833484
Validation loss: 2.823775163436428

Epoch: 5| Step: 4
Training loss: 2.978250500495412
Validation loss: 2.8236360532741327

Epoch: 5| Step: 5
Training loss: 3.7569284648324306
Validation loss: 2.82572449154844

Epoch: 5| Step: 6
Training loss: 3.3942990415668364
Validation loss: 2.8251451335059317

Epoch: 5| Step: 7
Training loss: 2.7089834068863174
Validation loss: 2.822811608951052

Epoch: 5| Step: 8
Training loss: 2.9988734991316233
Validation loss: 2.8230951597341942

Epoch: 5| Step: 9
Training loss: 3.6209020142064565
Validation loss: 2.8234671293764073

Epoch: 5| Step: 10
Training loss: 3.4190953779370026
Validation loss: 2.8247214312922035

Epoch: 201| Step: 0
Training loss: 3.1651808281175056
Validation loss: 2.822262651019171

Epoch: 5| Step: 1
Training loss: 3.2331151305305577
Validation loss: 2.821940313416987

Epoch: 5| Step: 2
Training loss: 3.3447540772134703
Validation loss: 2.825546025155895

Epoch: 5| Step: 3
Training loss: 3.1799857634699533
Validation loss: 2.827550185705032

Epoch: 5| Step: 4
Training loss: 2.348787412888532
Validation loss: 2.826061523264205

Epoch: 5| Step: 5
Training loss: 3.1518879576293206
Validation loss: 2.8251250146531905

Epoch: 5| Step: 6
Training loss: 3.3116305667757118
Validation loss: 2.8268988206091623

Epoch: 5| Step: 7
Training loss: 3.15643340229445
Validation loss: 2.8259232005984805

Epoch: 5| Step: 8
Training loss: 2.8695630618855015
Validation loss: 2.8249516686172744

Epoch: 5| Step: 9
Training loss: 3.2769767910435506
Validation loss: 2.8224976276313

Epoch: 5| Step: 10
Training loss: 3.1775286419745847
Validation loss: 2.8191574113298805

Epoch: 202| Step: 0
Training loss: 3.427341919083951
Validation loss: 2.8210349349730297

Epoch: 5| Step: 1
Training loss: 2.817229638654624
Validation loss: 2.8216145327561457

Epoch: 5| Step: 2
Training loss: 2.917841447660253
Validation loss: 2.822986727390292

Epoch: 5| Step: 3
Training loss: 2.8233257902811015
Validation loss: 2.8223206984891176

Epoch: 5| Step: 4
Training loss: 3.2077533313257347
Validation loss: 2.822713410438382

Epoch: 5| Step: 5
Training loss: 3.0975481858711973
Validation loss: 2.8212191525646397

Epoch: 5| Step: 6
Training loss: 3.3772871956468085
Validation loss: 2.820371916525161

Epoch: 5| Step: 7
Training loss: 2.74507697478662
Validation loss: 2.8179040862462785

Epoch: 5| Step: 8
Training loss: 2.931229086600002
Validation loss: 2.819439285569686

Epoch: 5| Step: 9
Training loss: 3.27810518242416
Validation loss: 2.822461716421448

Epoch: 5| Step: 10
Training loss: 3.647680036508503
Validation loss: 2.8241685064516266

Epoch: 203| Step: 0
Training loss: 3.4830960376958457
Validation loss: 2.820500793161757

Epoch: 5| Step: 1
Training loss: 3.0919370637536234
Validation loss: 2.8222142439082876

Epoch: 5| Step: 2
Training loss: 3.3006232048886486
Validation loss: 2.827681817697877

Epoch: 5| Step: 3
Training loss: 2.1717272372031573
Validation loss: 2.819412137268476

Epoch: 5| Step: 4
Training loss: 3.532015017122203
Validation loss: 2.820116891839051

Epoch: 5| Step: 5
Training loss: 3.029949420469026
Validation loss: 2.8209097015803284

Epoch: 5| Step: 6
Training loss: 3.3413535113272124
Validation loss: 2.8218930064001966

Epoch: 5| Step: 7
Training loss: 3.458017878718404
Validation loss: 2.820751467012861

Epoch: 5| Step: 8
Training loss: 3.1273007887615596
Validation loss: 2.820881313275154

Epoch: 5| Step: 9
Training loss: 3.0897957548520356
Validation loss: 2.818914371470328

Epoch: 5| Step: 10
Training loss: 2.196383829137394
Validation loss: 2.8177145068385885

Epoch: 204| Step: 0
Training loss: 3.279590877510873
Validation loss: 2.81748356073417

Epoch: 5| Step: 1
Training loss: 2.9507910169016114
Validation loss: 2.82078737000408

Epoch: 5| Step: 2
Training loss: 3.249879834814645
Validation loss: 2.8194957408693737

Epoch: 5| Step: 3
Training loss: 3.6299047502784076
Validation loss: 2.821600816007703

Epoch: 5| Step: 4
Training loss: 2.764807197650397
Validation loss: 2.8222652752803645

Epoch: 5| Step: 5
Training loss: 2.729829683405694
Validation loss: 2.8197014623126675

Epoch: 5| Step: 6
Training loss: 2.4167223847203365
Validation loss: 2.8205386617002244

Epoch: 5| Step: 7
Training loss: 3.3247293691995394
Validation loss: 2.820142279351105

Epoch: 5| Step: 8
Training loss: 3.0739213928119584
Validation loss: 2.8209946621256625

Epoch: 5| Step: 9
Training loss: 3.1301093485198574
Validation loss: 2.8244035169329824

Epoch: 5| Step: 10
Training loss: 3.583259463472937
Validation loss: 2.8195451393522166

Epoch: 205| Step: 0
Training loss: 2.722522704955425
Validation loss: 2.8203699240566413

Epoch: 5| Step: 1
Training loss: 3.0544681714239057
Validation loss: 2.8152718306203277

Epoch: 5| Step: 2
Training loss: 3.7552115783818474
Validation loss: 2.818794275206255

Epoch: 5| Step: 3
Training loss: 3.2895408880496366
Validation loss: 2.8175406057019483

Epoch: 5| Step: 4
Training loss: 3.1245768451296896
Validation loss: 2.818735207415931

Epoch: 5| Step: 5
Training loss: 2.5647533092884593
Validation loss: 2.822536098814297

Epoch: 5| Step: 6
Training loss: 3.4334318190093907
Validation loss: 2.8274489420579667

Epoch: 5| Step: 7
Training loss: 2.8278513401891323
Validation loss: 2.8228237840789046

Epoch: 5| Step: 8
Training loss: 3.1525550591835954
Validation loss: 2.82009219544072

Epoch: 5| Step: 9
Training loss: 3.4945620116925173
Validation loss: 2.816808235208723

Epoch: 5| Step: 10
Training loss: 2.5170611908074547
Validation loss: 2.815766725968873

Epoch: 206| Step: 0
Training loss: 3.3333601632627916
Validation loss: 2.814938619882089

Epoch: 5| Step: 1
Training loss: 3.0763036306109255
Validation loss: 2.811029611791198

Epoch: 5| Step: 2
Training loss: 2.6615831578514406
Validation loss: 2.8122283148032037

Epoch: 5| Step: 3
Training loss: 2.604686522412131
Validation loss: 2.8138703848569757

Epoch: 5| Step: 4
Training loss: 2.862109101770408
Validation loss: 2.8132488406890115

Epoch: 5| Step: 5
Training loss: 3.140602377435236
Validation loss: 2.812384539459447

Epoch: 5| Step: 6
Training loss: 3.5361395548472037
Validation loss: 2.810458904042528

Epoch: 5| Step: 7
Training loss: 3.492679296764011
Validation loss: 2.812041043077617

Epoch: 5| Step: 8
Training loss: 3.519889584673567
Validation loss: 2.8140517863497356

Epoch: 5| Step: 9
Training loss: 2.6704330568906287
Validation loss: 2.813078467380668

Epoch: 5| Step: 10
Training loss: 3.1811530557486734
Validation loss: 2.812434592449239

Epoch: 207| Step: 0
Training loss: 3.124192247900769
Validation loss: 2.8111244228568877

Epoch: 5| Step: 1
Training loss: 3.0294575848428407
Validation loss: 2.8132393051013005

Epoch: 5| Step: 2
Training loss: 3.16843637573451
Validation loss: 2.8111339528510113

Epoch: 5| Step: 3
Training loss: 2.718907143447069
Validation loss: 2.814665665406086

Epoch: 5| Step: 4
Training loss: 3.288116246472649
Validation loss: 2.8161683664167447

Epoch: 5| Step: 5
Training loss: 2.817913609687816
Validation loss: 2.8151525278686087

Epoch: 5| Step: 6
Training loss: 2.865633260034868
Validation loss: 2.8143585572444874

Epoch: 5| Step: 7
Training loss: 2.8767446117368896
Validation loss: 2.8171120987202434

Epoch: 5| Step: 8
Training loss: 3.684278600465384
Validation loss: 2.816792038621627

Epoch: 5| Step: 9
Training loss: 3.556669315764976
Validation loss: 2.813369847988815

Epoch: 5| Step: 10
Training loss: 2.915734678047465
Validation loss: 2.8169946758298243

Epoch: 208| Step: 0
Training loss: 2.837210041304916
Validation loss: 2.817497312085523

Epoch: 5| Step: 1
Training loss: 2.6066304466612498
Validation loss: 2.8146777072697984

Epoch: 5| Step: 2
Training loss: 3.2976161611831936
Validation loss: 2.8124326909806014

Epoch: 5| Step: 3
Training loss: 3.4950948129871984
Validation loss: 2.8144792909353686

Epoch: 5| Step: 4
Training loss: 3.129650775086419
Validation loss: 2.8105652228395326

Epoch: 5| Step: 5
Training loss: 2.814090024992485
Validation loss: 2.809072338691349

Epoch: 5| Step: 6
Training loss: 3.4192950830618978
Validation loss: 2.811287615670172

Epoch: 5| Step: 7
Training loss: 3.4836774050756016
Validation loss: 2.811727555823819

Epoch: 5| Step: 8
Training loss: 2.7378814013523476
Validation loss: 2.8088684509054938

Epoch: 5| Step: 9
Training loss: 2.853974625932457
Validation loss: 2.80961496098816

Epoch: 5| Step: 10
Training loss: 3.388189610180294
Validation loss: 2.8101250505406434

Epoch: 209| Step: 0
Training loss: 2.7040514819080426
Validation loss: 2.8085634380911917

Epoch: 5| Step: 1
Training loss: 3.48517999630269
Validation loss: 2.8088187067534984

Epoch: 5| Step: 2
Training loss: 2.8872623164127043
Validation loss: 2.8119899765859655

Epoch: 5| Step: 3
Training loss: 2.929931142212716
Validation loss: 2.8116329064250345

Epoch: 5| Step: 4
Training loss: 2.5165579825000393
Validation loss: 2.810945582193385

Epoch: 5| Step: 5
Training loss: 3.5981829296045333
Validation loss: 2.810511037305922

Epoch: 5| Step: 6
Training loss: 2.680477459636826
Validation loss: 2.809289855371252

Epoch: 5| Step: 7
Training loss: 3.4891726731408927
Validation loss: 2.810361540054622

Epoch: 5| Step: 8
Training loss: 3.7637714556915793
Validation loss: 2.810777358584489

Epoch: 5| Step: 9
Training loss: 3.0427274204287995
Validation loss: 2.812005416789865

Epoch: 5| Step: 10
Training loss: 2.765039155624204
Validation loss: 2.8130409322132266

Epoch: 210| Step: 0
Training loss: 2.9996743025411416
Validation loss: 2.8075504553926653

Epoch: 5| Step: 1
Training loss: 3.371327132437778
Validation loss: 2.8091442182501694

Epoch: 5| Step: 2
Training loss: 3.1400358492025764
Validation loss: 2.808368226599512

Epoch: 5| Step: 3
Training loss: 2.9441351118285417
Validation loss: 2.806540183580458

Epoch: 5| Step: 4
Training loss: 2.9889595010004077
Validation loss: 2.808558238810172

Epoch: 5| Step: 5
Training loss: 3.0909218239649467
Validation loss: 2.804419175250369

Epoch: 5| Step: 6
Training loss: 3.107114804271221
Validation loss: 2.8049374675596757

Epoch: 5| Step: 7
Training loss: 2.884871742399092
Validation loss: 2.8055289905624794

Epoch: 5| Step: 8
Training loss: 3.192529338322485
Validation loss: 2.8080070001713406

Epoch: 5| Step: 9
Training loss: 3.323308907600513
Validation loss: 2.8084065837063927

Epoch: 5| Step: 10
Training loss: 3.1343323785502575
Validation loss: 2.808277759115926

Epoch: 211| Step: 0
Training loss: 3.054215728934692
Validation loss: 2.81253537756251

Epoch: 5| Step: 1
Training loss: 3.449963395297701
Validation loss: 2.808387003107326

Epoch: 5| Step: 2
Training loss: 2.9037443455063427
Validation loss: 2.8072008689043884

Epoch: 5| Step: 3
Training loss: 2.9653564331518
Validation loss: 2.8129518727000455

Epoch: 5| Step: 4
Training loss: 3.3142059539724866
Validation loss: 2.8098149470689417

Epoch: 5| Step: 5
Training loss: 3.073284390101874
Validation loss: 2.8102148290976787

Epoch: 5| Step: 6
Training loss: 3.314958200090488
Validation loss: 2.810512999365138

Epoch: 5| Step: 7
Training loss: 3.0895020576911
Validation loss: 2.8119714538818408

Epoch: 5| Step: 8
Training loss: 2.6256267162772318
Validation loss: 2.812438565840004

Epoch: 5| Step: 9
Training loss: 2.781496615673683
Validation loss: 2.8047875836587517

Epoch: 5| Step: 10
Training loss: 3.5534939617139494
Validation loss: 2.8091540004521462

Epoch: 212| Step: 0
Training loss: 3.0145492611541123
Validation loss: 2.8099648009301186

Epoch: 5| Step: 1
Training loss: 2.565103836188642
Validation loss: 2.805944736760829

Epoch: 5| Step: 2
Training loss: 3.0579597917187455
Validation loss: 2.807951540034686

Epoch: 5| Step: 3
Training loss: 3.6347955357111603
Validation loss: 2.8063756385909007

Epoch: 5| Step: 4
Training loss: 3.0123694047281107
Validation loss: 2.8056409539819347

Epoch: 5| Step: 5
Training loss: 2.9865800789929113
Validation loss: 2.806362241081747

Epoch: 5| Step: 6
Training loss: 2.716969751250725
Validation loss: 2.805827714520371

Epoch: 5| Step: 7
Training loss: 3.132289167343342
Validation loss: 2.806715568253063

Epoch: 5| Step: 8
Training loss: 3.2175898266563654
Validation loss: 2.803924518008504

Epoch: 5| Step: 9
Training loss: 3.8319629348125037
Validation loss: 2.8046414403543647

Epoch: 5| Step: 10
Training loss: 2.691388355743761
Validation loss: 2.813717675809233

Epoch: 213| Step: 0
Training loss: 2.7720467532510114
Validation loss: 2.806872431281279

Epoch: 5| Step: 1
Training loss: 3.222541723817267
Validation loss: 2.806944046599187

Epoch: 5| Step: 2
Training loss: 3.4388204639333098
Validation loss: 2.806852757778416

Epoch: 5| Step: 3
Training loss: 3.093110606078539
Validation loss: 2.803966506211212

Epoch: 5| Step: 4
Training loss: 2.8242434847475377
Validation loss: 2.805074903071434

Epoch: 5| Step: 5
Training loss: 2.824992093775666
Validation loss: 2.8024984228335668

Epoch: 5| Step: 6
Training loss: 3.1922966264845822
Validation loss: 2.8049155421455523

Epoch: 5| Step: 7
Training loss: 2.779495028457546
Validation loss: 2.8030358506423667

Epoch: 5| Step: 8
Training loss: 3.7865934841937516
Validation loss: 2.8042165846648675

Epoch: 5| Step: 9
Training loss: 3.0316523648666194
Validation loss: 2.802520411066535

Epoch: 5| Step: 10
Training loss: 3.021404677106222
Validation loss: 2.800125560420989

Epoch: 214| Step: 0
Training loss: 3.3344485960313133
Validation loss: 2.8017040678687053

Epoch: 5| Step: 1
Training loss: 3.4201876168348697
Validation loss: 2.8022162085755435

Epoch: 5| Step: 2
Training loss: 2.9949181748359006
Validation loss: 2.8036291656614694

Epoch: 5| Step: 3
Training loss: 3.1986202662978287
Validation loss: 2.8018880018873755

Epoch: 5| Step: 4
Training loss: 3.3282182707275947
Validation loss: 2.8023578018224105

Epoch: 5| Step: 5
Training loss: 2.6326925097552945
Validation loss: 2.802069252296862

Epoch: 5| Step: 6
Training loss: 2.953608397626253
Validation loss: 2.8027245877711637

Epoch: 5| Step: 7
Training loss: 3.0162616907518434
Validation loss: 2.804525657196028

Epoch: 5| Step: 8
Training loss: 3.0853530523493746
Validation loss: 2.803163847937201

Epoch: 5| Step: 9
Training loss: 2.913442428111698
Validation loss: 2.807048831775714

Epoch: 5| Step: 10
Training loss: 3.1902340401922196
Validation loss: 2.8058026182424056

Epoch: 215| Step: 0
Training loss: 2.425256546450514
Validation loss: 2.81443254896358

Epoch: 5| Step: 1
Training loss: 2.455916741746128
Validation loss: 2.8090518811271386

Epoch: 5| Step: 2
Training loss: 3.0405817230689007
Validation loss: 2.805532113866086

Epoch: 5| Step: 3
Training loss: 3.0785673956359405
Validation loss: 2.803464246805341

Epoch: 5| Step: 4
Training loss: 3.3708744972334155
Validation loss: 2.801438522086954

Epoch: 5| Step: 5
Training loss: 2.8740116576699637
Validation loss: 2.7989933738067765

Epoch: 5| Step: 6
Training loss: 3.7209396967933857
Validation loss: 2.7978133878068743

Epoch: 5| Step: 7
Training loss: 3.814688632802732
Validation loss: 2.7971211518324655

Epoch: 5| Step: 8
Training loss: 3.1997427598555555
Validation loss: 2.7987003425338606

Epoch: 5| Step: 9
Training loss: 2.84491747691202
Validation loss: 2.7965351795884676

Epoch: 5| Step: 10
Training loss: 2.9950248472682817
Validation loss: 2.7972633310839203

Epoch: 216| Step: 0
Training loss: 3.6023578551691973
Validation loss: 2.794719283020161

Epoch: 5| Step: 1
Training loss: 2.5980333556455966
Validation loss: 2.79425662485059

Epoch: 5| Step: 2
Training loss: 3.1849872932599808
Validation loss: 2.7996112855077655

Epoch: 5| Step: 3
Training loss: 3.345188437544023
Validation loss: 2.796454955325509

Epoch: 5| Step: 4
Training loss: 3.5231335291032613
Validation loss: 2.796833913618989

Epoch: 5| Step: 5
Training loss: 2.9367871332591777
Validation loss: 2.799235403099017

Epoch: 5| Step: 6
Training loss: 3.270732481225745
Validation loss: 2.7965189105055566

Epoch: 5| Step: 7
Training loss: 2.9215642590445556
Validation loss: 2.7982718272067517

Epoch: 5| Step: 8
Training loss: 2.767631707921218
Validation loss: 2.798790009425996

Epoch: 5| Step: 9
Training loss: 2.965821437942246
Validation loss: 2.7993130557588386

Epoch: 5| Step: 10
Training loss: 2.7797255034740944
Validation loss: 2.8061195200505042

Epoch: 217| Step: 0
Training loss: 3.251679939961158
Validation loss: 2.8010084349812012

Epoch: 5| Step: 1
Training loss: 2.666055509946614
Validation loss: 2.803556048308989

Epoch: 5| Step: 2
Training loss: 3.0984886176759128
Validation loss: 2.797587689975992

Epoch: 5| Step: 3
Training loss: 3.184597713629816
Validation loss: 2.7968814593357574

Epoch: 5| Step: 4
Training loss: 2.756744264327725
Validation loss: 2.798678217113809

Epoch: 5| Step: 5
Training loss: 2.4197624591231146
Validation loss: 2.799178132538763

Epoch: 5| Step: 6
Training loss: 3.5463810379295855
Validation loss: 2.7983820078173087

Epoch: 5| Step: 7
Training loss: 2.9749222689178816
Validation loss: 2.7994436601283956

Epoch: 5| Step: 8
Training loss: 3.54890928033926
Validation loss: 2.792976753997291

Epoch: 5| Step: 9
Training loss: 3.569769686581247
Validation loss: 2.7947324657369026

Epoch: 5| Step: 10
Training loss: 2.763232732060541
Validation loss: 2.7972272691297824

Epoch: 218| Step: 0
Training loss: 2.598230926505327
Validation loss: 2.7951976893162818

Epoch: 5| Step: 1
Training loss: 3.4817577163042155
Validation loss: 2.795859099131044

Epoch: 5| Step: 2
Training loss: 3.175828396117604
Validation loss: 2.7941026658329884

Epoch: 5| Step: 3
Training loss: 3.4849127794951307
Validation loss: 2.795996202438977

Epoch: 5| Step: 4
Training loss: 2.3857114073945653
Validation loss: 2.794397749862328

Epoch: 5| Step: 5
Training loss: 3.427707943719319
Validation loss: 2.7985931983262597

Epoch: 5| Step: 6
Training loss: 2.8601841849927285
Validation loss: 2.802855086223784

Epoch: 5| Step: 7
Training loss: 3.094408061621973
Validation loss: 2.8029953758936186

Epoch: 5| Step: 8
Training loss: 2.7832401313329234
Validation loss: 2.800409004264939

Epoch: 5| Step: 9
Training loss: 2.6316676155009704
Validation loss: 2.7987093982051428

Epoch: 5| Step: 10
Training loss: 3.9331066508087145
Validation loss: 2.795831456860849

Epoch: 219| Step: 0
Training loss: 3.29660033035522
Validation loss: 2.792995102523786

Epoch: 5| Step: 1
Training loss: 2.5070276666308335
Validation loss: 2.7924317652388844

Epoch: 5| Step: 2
Training loss: 3.042870966817871
Validation loss: 2.7945913264379234

Epoch: 5| Step: 3
Training loss: 2.9470832823916004
Validation loss: 2.7949637911524072

Epoch: 5| Step: 4
Training loss: 3.748472411234428
Validation loss: 2.7918439685448244

Epoch: 5| Step: 5
Training loss: 3.305857638349937
Validation loss: 2.7920864513855723

Epoch: 5| Step: 6
Training loss: 2.9514906463035393
Validation loss: 2.7924743081592087

Epoch: 5| Step: 7
Training loss: 3.2908758026213643
Validation loss: 2.789725610674355

Epoch: 5| Step: 8
Training loss: 3.0728018184256243
Validation loss: 2.7905439063750324

Epoch: 5| Step: 9
Training loss: 2.2844130652474695
Validation loss: 2.7961752767817507

Epoch: 5| Step: 10
Training loss: 3.383857407092989
Validation loss: 2.7925139283103073

Epoch: 220| Step: 0
Training loss: 3.383430265970478
Validation loss: 2.792427826726861

Epoch: 5| Step: 1
Training loss: 2.877846179756378
Validation loss: 2.796801455831197

Epoch: 5| Step: 2
Training loss: 3.42191095202646
Validation loss: 2.7989701003042433

Epoch: 5| Step: 3
Training loss: 3.7019597405171973
Validation loss: 2.7981788307980455

Epoch: 5| Step: 4
Training loss: 2.6513221357532926
Validation loss: 2.7977425568034544

Epoch: 5| Step: 5
Training loss: 3.3134113713469815
Validation loss: 2.804388473583942

Epoch: 5| Step: 6
Training loss: 2.9461636312689614
Validation loss: 2.8051391131936314

Epoch: 5| Step: 7
Training loss: 2.7709995783981394
Validation loss: 2.795692257472892

Epoch: 5| Step: 8
Training loss: 2.976984109330621
Validation loss: 2.793286823312619

Epoch: 5| Step: 9
Training loss: 2.904801530738959
Validation loss: 2.7932313003552234

Epoch: 5| Step: 10
Training loss: 2.866340865613464
Validation loss: 2.78970665985835

Epoch: 221| Step: 0
Training loss: 3.1878513815686635
Validation loss: 2.794760238126274

Epoch: 5| Step: 1
Training loss: 2.9333104226633715
Validation loss: 2.7890339153035204

Epoch: 5| Step: 2
Training loss: 2.8287541653833808
Validation loss: 2.7912612501889167

Epoch: 5| Step: 3
Training loss: 3.0835610039313024
Validation loss: 2.7945829234262543

Epoch: 5| Step: 4
Training loss: 3.3407109791010403
Validation loss: 2.7927870420755823

Epoch: 5| Step: 5
Training loss: 2.95492999102027
Validation loss: 2.7924494049306414

Epoch: 5| Step: 6
Training loss: 3.045916910412081
Validation loss: 2.79129061112129

Epoch: 5| Step: 7
Training loss: 3.1193471516531877
Validation loss: 2.7927840835191224

Epoch: 5| Step: 8
Training loss: 3.4259847408740964
Validation loss: 2.790510924343769

Epoch: 5| Step: 9
Training loss: 3.402221957806854
Validation loss: 2.786879086557602

Epoch: 5| Step: 10
Training loss: 2.4966575212739803
Validation loss: 2.79055393384215

Epoch: 222| Step: 0
Training loss: 2.9785697356765186
Validation loss: 2.7898631422126328

Epoch: 5| Step: 1
Training loss: 2.6840469888249374
Validation loss: 2.7889009261559576

Epoch: 5| Step: 2
Training loss: 3.177319443897918
Validation loss: 2.787200119344494

Epoch: 5| Step: 3
Training loss: 2.577429475309715
Validation loss: 2.7893702858048277

Epoch: 5| Step: 4
Training loss: 3.514889924237229
Validation loss: 2.790890681474482

Epoch: 5| Step: 5
Training loss: 3.1244161441884515
Validation loss: 2.78934808362048

Epoch: 5| Step: 6
Training loss: 3.407097947155143
Validation loss: 2.7873148056822794

Epoch: 5| Step: 7
Training loss: 2.805965971644542
Validation loss: 2.7989251794241468

Epoch: 5| Step: 8
Training loss: 3.149622540338198
Validation loss: 2.7948394735955437

Epoch: 5| Step: 9
Training loss: 3.4339248098363155
Validation loss: 2.7978963549296503

Epoch: 5| Step: 10
Training loss: 2.9797267965236993
Validation loss: 2.7923034559421653

Epoch: 223| Step: 0
Training loss: 3.469690418779873
Validation loss: 2.7890079592114385

Epoch: 5| Step: 1
Training loss: 3.3775966686360652
Validation loss: 2.7966747944421493

Epoch: 5| Step: 2
Training loss: 2.200856765897727
Validation loss: 2.788416685373215

Epoch: 5| Step: 3
Training loss: 2.921636071865519
Validation loss: 2.7854697852911463

Epoch: 5| Step: 4
Training loss: 3.42579600419072
Validation loss: 2.785738823572378

Epoch: 5| Step: 5
Training loss: 3.0551020738496817
Validation loss: 2.789484873728441

Epoch: 5| Step: 6
Training loss: 3.2544897318807124
Validation loss: 2.786436668559417

Epoch: 5| Step: 7
Training loss: 3.3643598610248424
Validation loss: 2.783300522555666

Epoch: 5| Step: 8
Training loss: 2.747917947679693
Validation loss: 2.7870487103311463

Epoch: 5| Step: 9
Training loss: 3.1647964944845133
Validation loss: 2.7860394302215776

Epoch: 5| Step: 10
Training loss: 2.7083798526779073
Validation loss: 2.7832754248723877

Epoch: 224| Step: 0
Training loss: 2.9817960291079775
Validation loss: 2.7845690267437107

Epoch: 5| Step: 1
Training loss: 2.6906182584777802
Validation loss: 2.7839715750756837

Epoch: 5| Step: 2
Training loss: 3.78829350484265
Validation loss: 2.785294123135947

Epoch: 5| Step: 3
Training loss: 3.296697096521884
Validation loss: 2.786187426593078

Epoch: 5| Step: 4
Training loss: 3.2360570099928445
Validation loss: 2.7838817301803926

Epoch: 5| Step: 5
Training loss: 3.229353835721484
Validation loss: 2.781768756901338

Epoch: 5| Step: 6
Training loss: 3.2060386245980492
Validation loss: 2.785917128150607

Epoch: 5| Step: 7
Training loss: 2.1636660656882882
Validation loss: 2.7815966121119953

Epoch: 5| Step: 8
Training loss: 2.307640743902196
Validation loss: 2.7860203889989807

Epoch: 5| Step: 9
Training loss: 3.6217102381938946
Validation loss: 2.78484765139933

Epoch: 5| Step: 10
Training loss: 3.0343363672030588
Validation loss: 2.7866226682983726

Epoch: 225| Step: 0
Training loss: 2.799353753171308
Validation loss: 2.7871979596751895

Epoch: 5| Step: 1
Training loss: 3.149761972062628
Validation loss: 2.7843742479157805

Epoch: 5| Step: 2
Training loss: 2.882425256373796
Validation loss: 2.7883048513668274

Epoch: 5| Step: 3
Training loss: 3.179500789924784
Validation loss: 2.7848608403407047

Epoch: 5| Step: 4
Training loss: 3.115490597319675
Validation loss: 2.7863844234465436

Epoch: 5| Step: 5
Training loss: 3.5681331335213256
Validation loss: 2.7835476933560543

Epoch: 5| Step: 6
Training loss: 3.094023104856955
Validation loss: 2.7870320676049762

Epoch: 5| Step: 7
Training loss: 3.2018062202770157
Validation loss: 2.786038037998191

Epoch: 5| Step: 8
Training loss: 2.773482889153236
Validation loss: 2.790949559633066

Epoch: 5| Step: 9
Training loss: 2.600881768137928
Validation loss: 2.790550907691417

Epoch: 5| Step: 10
Training loss: 3.519058382062211
Validation loss: 2.7908460200315064

Epoch: 226| Step: 0
Training loss: 2.8439129793183806
Validation loss: 2.7829428932852753

Epoch: 5| Step: 1
Training loss: 3.006369821932356
Validation loss: 2.783103625669399

Epoch: 5| Step: 2
Training loss: 3.346663872108458
Validation loss: 2.7806908549053415

Epoch: 5| Step: 3
Training loss: 3.193319804561789
Validation loss: 2.781364439485319

Epoch: 5| Step: 4
Training loss: 3.057803074934775
Validation loss: 2.7877572664019667

Epoch: 5| Step: 5
Training loss: 2.7079578041496837
Validation loss: 2.7826325696116623

Epoch: 5| Step: 6
Training loss: 3.358428821831148
Validation loss: 2.7822142336738125

Epoch: 5| Step: 7
Training loss: 2.778174424992274
Validation loss: 2.7817860264578496

Epoch: 5| Step: 8
Training loss: 3.208684200240809
Validation loss: 2.783946457657804

Epoch: 5| Step: 9
Training loss: 3.2753865487079583
Validation loss: 2.7813851615285174

Epoch: 5| Step: 10
Training loss: 3.098304093913607
Validation loss: 2.781024370193245

Epoch: 227| Step: 0
Training loss: 3.139147358682986
Validation loss: 2.786269194599422

Epoch: 5| Step: 1
Training loss: 2.8551441013292953
Validation loss: 2.7833726209501113

Epoch: 5| Step: 2
Training loss: 3.1710363322245434
Validation loss: 2.783053453238936

Epoch: 5| Step: 3
Training loss: 3.1511179680952184
Validation loss: 2.782449645844146

Epoch: 5| Step: 4
Training loss: 2.830913201987998
Validation loss: 2.7843576812767172

Epoch: 5| Step: 5
Training loss: 2.5512689238187076
Validation loss: 2.7820732609962078

Epoch: 5| Step: 6
Training loss: 2.98666421858937
Validation loss: 2.781359865904413

Epoch: 5| Step: 7
Training loss: 3.24795438505191
Validation loss: 2.779550238284931

Epoch: 5| Step: 8
Training loss: 3.3649396363238844
Validation loss: 2.78652453492931

Epoch: 5| Step: 9
Training loss: 3.5554650430947086
Validation loss: 2.7819254950022843

Epoch: 5| Step: 10
Training loss: 2.9183310165120124
Validation loss: 2.7817522042362985

Epoch: 228| Step: 0
Training loss: 3.328642755629461
Validation loss: 2.7848120261242877

Epoch: 5| Step: 1
Training loss: 3.19261745968672
Validation loss: 2.780037219513335

Epoch: 5| Step: 2
Training loss: 2.8814905955717025
Validation loss: 2.7785046568470366

Epoch: 5| Step: 3
Training loss: 3.307341824048593
Validation loss: 2.781955787523167

Epoch: 5| Step: 4
Training loss: 2.6250521336782646
Validation loss: 2.7801029964468036

Epoch: 5| Step: 5
Training loss: 3.1731147034714517
Validation loss: 2.7782847271739235

Epoch: 5| Step: 6
Training loss: 2.950340290162948
Validation loss: 2.7815791294001504

Epoch: 5| Step: 7
Training loss: 2.9699216438001357
Validation loss: 2.778001719253082

Epoch: 5| Step: 8
Training loss: 3.5467112499197926
Validation loss: 2.776057660813779

Epoch: 5| Step: 9
Training loss: 2.8395055598362227
Validation loss: 2.7777346999065156

Epoch: 5| Step: 10
Training loss: 2.9556560669764815
Validation loss: 2.7785003719680237

Epoch: 229| Step: 0
Training loss: 3.031262584542176
Validation loss: 2.7788080637344788

Epoch: 5| Step: 1
Training loss: 2.761589079622445
Validation loss: 2.7772372588118848

Epoch: 5| Step: 2
Training loss: 2.9773484841846876
Validation loss: 2.7785704156245767

Epoch: 5| Step: 3
Training loss: 3.402608342180075
Validation loss: 2.778067175717188

Epoch: 5| Step: 4
Training loss: 2.759228307814483
Validation loss: 2.778710428445795

Epoch: 5| Step: 5
Training loss: 3.251059286177164
Validation loss: 2.774658389185076

Epoch: 5| Step: 6
Training loss: 2.723253575919313
Validation loss: 2.7760484656834175

Epoch: 5| Step: 7
Training loss: 3.488187064579186
Validation loss: 2.77671993854748

Epoch: 5| Step: 8
Training loss: 3.0659120197849
Validation loss: 2.7770954500672285

Epoch: 5| Step: 9
Training loss: 2.9348705779204414
Validation loss: 2.7738183875726423

Epoch: 5| Step: 10
Training loss: 3.419027877198581
Validation loss: 2.775540479991141

Epoch: 230| Step: 0
Training loss: 2.714392140101828
Validation loss: 2.776156739481839

Epoch: 5| Step: 1
Training loss: 2.7369175016871186
Validation loss: 2.7759836519406615

Epoch: 5| Step: 2
Training loss: 3.5215658896728907
Validation loss: 2.7782725423361003

Epoch: 5| Step: 3
Training loss: 3.3304075911524054
Validation loss: 2.7767993148829455

Epoch: 5| Step: 4
Training loss: 3.701362802215953
Validation loss: 2.777378863707811

Epoch: 5| Step: 5
Training loss: 3.109493694244434
Validation loss: 2.775607240016577

Epoch: 5| Step: 6
Training loss: 3.2066395900267852
Validation loss: 2.7741232311259094

Epoch: 5| Step: 7
Training loss: 2.219092006919623
Validation loss: 2.7721084758877637

Epoch: 5| Step: 8
Training loss: 3.176904308507355
Validation loss: 2.7744365708450127

Epoch: 5| Step: 9
Training loss: 2.969827396245238
Validation loss: 2.776264395910961

Epoch: 5| Step: 10
Training loss: 2.881247822063558
Validation loss: 2.7725374038262074

Epoch: 231| Step: 0
Training loss: 3.34221678190882
Validation loss: 2.774828262025758

Epoch: 5| Step: 1
Training loss: 3.3091733530656335
Validation loss: 2.775330757222309

Epoch: 5| Step: 2
Training loss: 2.5575561283101464
Validation loss: 2.7734376765517865

Epoch: 5| Step: 3
Training loss: 2.978951204062276
Validation loss: 2.7772179255423963

Epoch: 5| Step: 4
Training loss: 1.9722927853970733
Validation loss: 2.769452455886812

Epoch: 5| Step: 5
Training loss: 3.5141233500855797
Validation loss: 2.7755596485281435

Epoch: 5| Step: 6
Training loss: 3.067833285331743
Validation loss: 2.77298066003197

Epoch: 5| Step: 7
Training loss: 3.254355226752994
Validation loss: 2.774269777074857

Epoch: 5| Step: 8
Training loss: 3.2692733899958806
Validation loss: 2.7727787782115407

Epoch: 5| Step: 9
Training loss: 3.015391128247053
Validation loss: 2.778194209300639

Epoch: 5| Step: 10
Training loss: 3.2961679577300678
Validation loss: 2.781334406903965

Epoch: 232| Step: 0
Training loss: 2.8853520318422587
Validation loss: 2.7804085653619923

Epoch: 5| Step: 1
Training loss: 3.55662989942095
Validation loss: 2.7819681902948266

Epoch: 5| Step: 2
Training loss: 2.86197181726171
Validation loss: 2.780207759575708

Epoch: 5| Step: 3
Training loss: 2.5388132765306666
Validation loss: 2.7810573236917664

Epoch: 5| Step: 4
Training loss: 2.963888584920702
Validation loss: 2.7802760396147383

Epoch: 5| Step: 5
Training loss: 2.9763045712354166
Validation loss: 2.786186371669595

Epoch: 5| Step: 6
Training loss: 3.2611546925266928
Validation loss: 2.784715472239883

Epoch: 5| Step: 7
Training loss: 3.356950887739544
Validation loss: 2.7852247005067765

Epoch: 5| Step: 8
Training loss: 2.6610251196672308
Validation loss: 2.7871569100037576

Epoch: 5| Step: 9
Training loss: 3.4907548598515405
Validation loss: 2.7786298233298172

Epoch: 5| Step: 10
Training loss: 3.149835697309297
Validation loss: 2.777668153452326

Epoch: 233| Step: 0
Training loss: 2.7378565830373596
Validation loss: 2.771058761699732

Epoch: 5| Step: 1
Training loss: 2.9909383292770473
Validation loss: 2.7695675161438977

Epoch: 5| Step: 2
Training loss: 2.8947549545597537
Validation loss: 2.770038821748468

Epoch: 5| Step: 3
Training loss: 3.2047744597824246
Validation loss: 2.768519247968021

Epoch: 5| Step: 4
Training loss: 2.9750293377623818
Validation loss: 2.7673772099126004

Epoch: 5| Step: 5
Training loss: 2.967843650195683
Validation loss: 2.7714335815110687

Epoch: 5| Step: 6
Training loss: 2.7720768559357882
Validation loss: 2.7690046343657766

Epoch: 5| Step: 7
Training loss: 3.537790638337437
Validation loss: 2.7709663156269384

Epoch: 5| Step: 8
Training loss: 3.20972131868228
Validation loss: 2.768824222186241

Epoch: 5| Step: 9
Training loss: 3.4202212165093706
Validation loss: 2.767483022625351

Epoch: 5| Step: 10
Training loss: 3.0330231190047794
Validation loss: 2.768279948878295

Epoch: 234| Step: 0
Training loss: 2.621029439441345
Validation loss: 2.766023445290673

Epoch: 5| Step: 1
Training loss: 3.048642159557072
Validation loss: 2.7666834812626915

Epoch: 5| Step: 2
Training loss: 3.374271596789287
Validation loss: 2.769532314507275

Epoch: 5| Step: 3
Training loss: 2.817698950525669
Validation loss: 2.7724827783679737

Epoch: 5| Step: 4
Training loss: 3.3872106562277886
Validation loss: 2.772897418926193

Epoch: 5| Step: 5
Training loss: 3.1896573414221905
Validation loss: 2.775414222776939

Epoch: 5| Step: 6
Training loss: 2.54436401904554
Validation loss: 2.771935993827631

Epoch: 5| Step: 7
Training loss: 3.499364795264551
Validation loss: 2.774065742472436

Epoch: 5| Step: 8
Training loss: 2.9841056023082593
Validation loss: 2.776295034609151

Epoch: 5| Step: 9
Training loss: 2.9419492749704275
Validation loss: 2.777546353151113

Epoch: 5| Step: 10
Training loss: 3.2835661933027604
Validation loss: 2.7731412432105573

Epoch: 235| Step: 0
Training loss: 3.2095012933384086
Validation loss: 2.7728714190318384

Epoch: 5| Step: 1
Training loss: 3.182395288223607
Validation loss: 2.769488002888906

Epoch: 5| Step: 2
Training loss: 2.6500519189606937
Validation loss: 2.769619133417495

Epoch: 5| Step: 3
Training loss: 3.155554213172854
Validation loss: 2.7659782882487054

Epoch: 5| Step: 4
Training loss: 3.126626926351219
Validation loss: 2.768775346532974

Epoch: 5| Step: 5
Training loss: 2.6970327001901135
Validation loss: 2.7684943487215796

Epoch: 5| Step: 6
Training loss: 3.1709298665962433
Validation loss: 2.768431928773884

Epoch: 5| Step: 7
Training loss: 3.3698274039604623
Validation loss: 2.764105815526373

Epoch: 5| Step: 8
Training loss: 3.023607668166234
Validation loss: 2.7643044708738436

Epoch: 5| Step: 9
Training loss: 3.0617273095496262
Validation loss: 2.7671492093398293

Epoch: 5| Step: 10
Training loss: 3.096519694650811
Validation loss: 2.7663321606281235

Epoch: 236| Step: 0
Training loss: 3.097831730724696
Validation loss: 2.76519627275454

Epoch: 5| Step: 1
Training loss: 3.0044913050829978
Validation loss: 2.7646016876009307

Epoch: 5| Step: 2
Training loss: 3.413575021958942
Validation loss: 2.7639743612870538

Epoch: 5| Step: 3
Training loss: 3.5958232704160293
Validation loss: 2.764336985639501

Epoch: 5| Step: 4
Training loss: 2.511789466253974
Validation loss: 2.768605006929853

Epoch: 5| Step: 5
Training loss: 2.578994326978333
Validation loss: 2.7654832113377426

Epoch: 5| Step: 6
Training loss: 3.167486302226496
Validation loss: 2.7644267526003268

Epoch: 5| Step: 7
Training loss: 3.358818256464028
Validation loss: 2.7613741018595395

Epoch: 5| Step: 8
Training loss: 2.675812881171388
Validation loss: 2.7642467019683226

Epoch: 5| Step: 9
Training loss: 3.323819379652674
Validation loss: 2.761502145651044

Epoch: 5| Step: 10
Training loss: 2.7890057384367646
Validation loss: 2.7646333865575885

Epoch: 237| Step: 0
Training loss: 3.3857406382946413
Validation loss: 2.7626803613436053

Epoch: 5| Step: 1
Training loss: 3.0434820601635075
Validation loss: 2.7630739083516507

Epoch: 5| Step: 2
Training loss: 2.9525912978279396
Validation loss: 2.7690712584825206

Epoch: 5| Step: 3
Training loss: 3.105491474956161
Validation loss: 2.7655430290264458

Epoch: 5| Step: 4
Training loss: 3.131534153880712
Validation loss: 2.7656848572615416

Epoch: 5| Step: 5
Training loss: 2.9751771120836827
Validation loss: 2.765447096504859

Epoch: 5| Step: 6
Training loss: 2.6745522454122934
Validation loss: 2.7655562525582624

Epoch: 5| Step: 7
Training loss: 3.1253207232879454
Validation loss: 2.762611795818421

Epoch: 5| Step: 8
Training loss: 2.9682189466429123
Validation loss: 2.7685802167939553

Epoch: 5| Step: 9
Training loss: 3.1751669351741403
Validation loss: 2.768653067048463

Epoch: 5| Step: 10
Training loss: 3.2083453553870402
Validation loss: 2.7654465653190607

Epoch: 238| Step: 0
Training loss: 3.53645346430058
Validation loss: 2.7676196920094114

Epoch: 5| Step: 1
Training loss: 2.7744775675535145
Validation loss: 2.764139208155334

Epoch: 5| Step: 2
Training loss: 3.141798113460218
Validation loss: 2.761164394035743

Epoch: 5| Step: 3
Training loss: 3.2804170550392944
Validation loss: 2.760823277721078

Epoch: 5| Step: 4
Training loss: 2.5143134447680264
Validation loss: 2.7591178328905004

Epoch: 5| Step: 5
Training loss: 2.941623796217266
Validation loss: 2.757864709114926

Epoch: 5| Step: 6
Training loss: 3.4520978824091717
Validation loss: 2.759551005918695

Epoch: 5| Step: 7
Training loss: 2.563102837340936
Validation loss: 2.759222117113747

Epoch: 5| Step: 8
Training loss: 2.951231980484882
Validation loss: 2.760375011003642

Epoch: 5| Step: 9
Training loss: 3.0426042409450167
Validation loss: 2.759953874523895

Epoch: 5| Step: 10
Training loss: 3.4240877147740822
Validation loss: 2.760299561876838

Epoch: 239| Step: 0
Training loss: 3.2384923997241817
Validation loss: 2.760837991005321

Epoch: 5| Step: 1
Training loss: 3.4070051563560937
Validation loss: 2.759673187068883

Epoch: 5| Step: 2
Training loss: 2.9367184512378475
Validation loss: 2.7607486097288096

Epoch: 5| Step: 3
Training loss: 3.001275586102981
Validation loss: 2.7595076544220083

Epoch: 5| Step: 4
Training loss: 2.912546044505519
Validation loss: 2.7598179392907385

Epoch: 5| Step: 5
Training loss: 2.682916591893307
Validation loss: 2.762206971386702

Epoch: 5| Step: 6
Training loss: 3.211312302296502
Validation loss: 2.759298688313452

Epoch: 5| Step: 7
Training loss: 2.7648283247397485
Validation loss: 2.7579678880922587

Epoch: 5| Step: 8
Training loss: 3.274730053907399
Validation loss: 2.760755139660425

Epoch: 5| Step: 9
Training loss: 2.9458457403357854
Validation loss: 2.7634645809912595

Epoch: 5| Step: 10
Training loss: 3.3160509474076574
Validation loss: 2.761240991220366

Epoch: 240| Step: 0
Training loss: 3.0628260224861865
Validation loss: 2.765026756652198

Epoch: 5| Step: 1
Training loss: 3.2128187919401476
Validation loss: 2.762349793172025

Epoch: 5| Step: 2
Training loss: 2.405243105586763
Validation loss: 2.772126504767984

Epoch: 5| Step: 3
Training loss: 3.1088833060709438
Validation loss: 2.7795064719116853

Epoch: 5| Step: 4
Training loss: 3.376318921116944
Validation loss: 2.7806161202163615

Epoch: 5| Step: 5
Training loss: 2.772378208797852
Validation loss: 2.781715672088706

Epoch: 5| Step: 6
Training loss: 2.9221400176437204
Validation loss: 2.7727349188226835

Epoch: 5| Step: 7
Training loss: 3.3044986174873903
Validation loss: 2.7719706784716687

Epoch: 5| Step: 8
Training loss: 3.368743607722005
Validation loss: 2.764535317428733

Epoch: 5| Step: 9
Training loss: 3.1300133735931657
Validation loss: 2.763224660461705

Epoch: 5| Step: 10
Training loss: 2.9708227049506823
Validation loss: 2.7615866010047463

Epoch: 241| Step: 0
Training loss: 3.4516391232759402
Validation loss: 2.7629476845697893

Epoch: 5| Step: 1
Training loss: 2.6168541539402583
Validation loss: 2.7661048959918966

Epoch: 5| Step: 2
Training loss: 2.673644344459068
Validation loss: 2.767601597644777

Epoch: 5| Step: 3
Training loss: 2.9701290742203943
Validation loss: 2.7686241151469733

Epoch: 5| Step: 4
Training loss: 3.061236373852349
Validation loss: 2.7740300979478443

Epoch: 5| Step: 5
Training loss: 4.050698377889029
Validation loss: 2.7699863571275856

Epoch: 5| Step: 6
Training loss: 2.6620202612847406
Validation loss: 2.7616798363443005

Epoch: 5| Step: 7
Training loss: 3.046795183750236
Validation loss: 2.7601801706902975

Epoch: 5| Step: 8
Training loss: 3.0715127787658756
Validation loss: 2.7592062997777655

Epoch: 5| Step: 9
Training loss: 2.6875579295457626
Validation loss: 2.758025232659093

Epoch: 5| Step: 10
Training loss: 3.2507431941152953
Validation loss: 2.755655290863631

Epoch: 242| Step: 0
Training loss: 2.9492679010804954
Validation loss: 2.756538411703068

Epoch: 5| Step: 1
Training loss: 3.169356525467348
Validation loss: 2.7602774760065043

Epoch: 5| Step: 2
Training loss: 2.935612985522622
Validation loss: 2.761825245016241

Epoch: 5| Step: 3
Training loss: 2.6865355956933623
Validation loss: 2.77057234998169

Epoch: 5| Step: 4
Training loss: 2.940462606974892
Validation loss: 2.777775108035319

Epoch: 5| Step: 5
Training loss: 3.5123712699352003
Validation loss: 2.785082922900762

Epoch: 5| Step: 6
Training loss: 3.3130813664267236
Validation loss: 2.7781488343709997

Epoch: 5| Step: 7
Training loss: 2.470834938121701
Validation loss: 2.7744405339728595

Epoch: 5| Step: 8
Training loss: 3.365768523064902
Validation loss: 2.772273934900104

Epoch: 5| Step: 9
Training loss: 3.2225714655040254
Validation loss: 2.7645464166369713

Epoch: 5| Step: 10
Training loss: 3.0525992589960036
Validation loss: 2.7756968687762464

Epoch: 243| Step: 0
Training loss: 2.942158029239516
Validation loss: 2.771499334162261

Epoch: 5| Step: 1
Training loss: 3.012684707993897
Validation loss: 2.777756701427063

Epoch: 5| Step: 2
Training loss: 3.4953341037046797
Validation loss: 2.783937373303447

Epoch: 5| Step: 3
Training loss: 2.9926257098953033
Validation loss: 2.774736422905193

Epoch: 5| Step: 4
Training loss: 2.7759169979384035
Validation loss: 2.7639261465381355

Epoch: 5| Step: 5
Training loss: 3.0722668666558204
Validation loss: 2.7620639621530305

Epoch: 5| Step: 6
Training loss: 3.019249195975294
Validation loss: 2.7536706943988247

Epoch: 5| Step: 7
Training loss: 3.240084561315883
Validation loss: 2.756063103577477

Epoch: 5| Step: 8
Training loss: 3.0620658722512584
Validation loss: 2.759259699647186

Epoch: 5| Step: 9
Training loss: 2.930185179082684
Validation loss: 2.7565747948432446

Epoch: 5| Step: 10
Training loss: 3.234582277004848
Validation loss: 2.7547880442590125

Epoch: 244| Step: 0
Training loss: 3.0131716853926287
Validation loss: 2.7541098801054353

Epoch: 5| Step: 1
Training loss: 3.1966059149205703
Validation loss: 2.755768130761223

Epoch: 5| Step: 2
Training loss: 3.2253566456026235
Validation loss: 2.7565977845812206

Epoch: 5| Step: 3
Training loss: 2.521967787613282
Validation loss: 2.7548665012340967

Epoch: 5| Step: 4
Training loss: 3.0314733678575005
Validation loss: 2.7531665365639553

Epoch: 5| Step: 5
Training loss: 2.787441434373292
Validation loss: 2.7522767767006555

Epoch: 5| Step: 6
Training loss: 2.8776123783230307
Validation loss: 2.755507995907842

Epoch: 5| Step: 7
Training loss: 3.498502683522099
Validation loss: 2.756885327970979

Epoch: 5| Step: 8
Training loss: 3.4000215193123573
Validation loss: 2.7606137955052237

Epoch: 5| Step: 9
Training loss: 2.871135768453159
Validation loss: 2.7702823109216084

Epoch: 5| Step: 10
Training loss: 3.2277161980987037
Validation loss: 2.7584413103631586

Epoch: 245| Step: 0
Training loss: 3.6721141980766094
Validation loss: 2.761682143144761

Epoch: 5| Step: 1
Training loss: 2.14275994307459
Validation loss: 2.754179215777668

Epoch: 5| Step: 2
Training loss: 3.405373556789225
Validation loss: 2.750318711047735

Epoch: 5| Step: 3
Training loss: 3.0717712509005106
Validation loss: 2.7519033991362383

Epoch: 5| Step: 4
Training loss: 2.9986764849372993
Validation loss: 2.752741031191683

Epoch: 5| Step: 5
Training loss: 3.2254327823729265
Validation loss: 2.750705969574487

Epoch: 5| Step: 6
Training loss: 3.1468248804641332
Validation loss: 2.7512318983290993

Epoch: 5| Step: 7
Training loss: 2.937190587407111
Validation loss: 2.752369526376426

Epoch: 5| Step: 8
Training loss: 2.970548867779606
Validation loss: 2.7543414424045416

Epoch: 5| Step: 9
Training loss: 2.865476508333651
Validation loss: 2.7514316406482786

Epoch: 5| Step: 10
Training loss: 3.0956205627791613
Validation loss: 2.749759538640019

Epoch: 246| Step: 0
Training loss: 3.062455001811873
Validation loss: 2.7479976568570743

Epoch: 5| Step: 1
Training loss: 3.287649254257296
Validation loss: 2.7495483184113985

Epoch: 5| Step: 2
Training loss: 3.0970787866638494
Validation loss: 2.750990536335408

Epoch: 5| Step: 3
Training loss: 3.2856383996102134
Validation loss: 2.748402097724782

Epoch: 5| Step: 4
Training loss: 3.4448049435255386
Validation loss: 2.7506466978645236

Epoch: 5| Step: 5
Training loss: 2.469881595136524
Validation loss: 2.754352012135204

Epoch: 5| Step: 6
Training loss: 2.4716977254811483
Validation loss: 2.750916997473264

Epoch: 5| Step: 7
Training loss: 2.7998874573569466
Validation loss: 2.751617014964502

Epoch: 5| Step: 8
Training loss: 2.536557508301344
Validation loss: 2.7543187130647198

Epoch: 5| Step: 9
Training loss: 3.557128470583793
Validation loss: 2.7551947301282276

Epoch: 5| Step: 10
Training loss: 3.408699624696886
Validation loss: 2.758758885447881

Epoch: 247| Step: 0
Training loss: 2.7329960424992663
Validation loss: 2.754750646404723

Epoch: 5| Step: 1
Training loss: 3.503194985554119
Validation loss: 2.75280999064638

Epoch: 5| Step: 2
Training loss: 2.8023438929315025
Validation loss: 2.7498709563539863

Epoch: 5| Step: 3
Training loss: 3.017549839319291
Validation loss: 2.7465992527648564

Epoch: 5| Step: 4
Training loss: 2.789324836254246
Validation loss: 2.7497279982602594

Epoch: 5| Step: 5
Training loss: 3.306688501019326
Validation loss: 2.7481973422645383

Epoch: 5| Step: 6
Training loss: 3.5765345341100288
Validation loss: 2.7508608849330622

Epoch: 5| Step: 7
Training loss: 3.057292325194687
Validation loss: 2.7516180295694133

Epoch: 5| Step: 8
Training loss: 2.9135514289293254
Validation loss: 2.752018516804232

Epoch: 5| Step: 9
Training loss: 3.066327564177539
Validation loss: 2.7519512422936963

Epoch: 5| Step: 10
Training loss: 2.75776840909558
Validation loss: 2.7492633151668215

Epoch: 248| Step: 0
Training loss: 3.3066484121105884
Validation loss: 2.7475162884242654

Epoch: 5| Step: 1
Training loss: 3.034037930185481
Validation loss: 2.7457109566466937

Epoch: 5| Step: 2
Training loss: 2.990514382097376
Validation loss: 2.75136218821547

Epoch: 5| Step: 3
Training loss: 3.0435544430930244
Validation loss: 2.7515235700184513

Epoch: 5| Step: 4
Training loss: 3.502744143878566
Validation loss: 2.752907820015055

Epoch: 5| Step: 5
Training loss: 3.501779648781197
Validation loss: 2.7577631772627926

Epoch: 5| Step: 6
Training loss: 3.044044940922515
Validation loss: 2.7654196707759193

Epoch: 5| Step: 7
Training loss: 3.0754192097557795
Validation loss: 2.766160308198036

Epoch: 5| Step: 8
Training loss: 2.811492315546097
Validation loss: 2.773272418236836

Epoch: 5| Step: 9
Training loss: 2.6750161072433247
Validation loss: 2.771347745419829

Epoch: 5| Step: 10
Training loss: 2.418762175457889
Validation loss: 2.7727051681578363

Epoch: 249| Step: 0
Training loss: 3.191598090355571
Validation loss: 2.76771816870492

Epoch: 5| Step: 1
Training loss: 2.9055539189713557
Validation loss: 2.763528340443599

Epoch: 5| Step: 2
Training loss: 3.0227154009905965
Validation loss: 2.7572585785411

Epoch: 5| Step: 3
Training loss: 3.0673064835994226
Validation loss: 2.752594113024742

Epoch: 5| Step: 4
Training loss: 3.242056014370724
Validation loss: 2.7567447609222016

Epoch: 5| Step: 5
Training loss: 3.0146726379312896
Validation loss: 2.754046717109884

Epoch: 5| Step: 6
Training loss: 3.2644289007380194
Validation loss: 2.750982267598295

Epoch: 5| Step: 7
Training loss: 3.0739739791970058
Validation loss: 2.7494182167035564

Epoch: 5| Step: 8
Training loss: 3.2933924211254215
Validation loss: 2.7545917673338125

Epoch: 5| Step: 9
Training loss: 2.695762088154553
Validation loss: 2.7466581273994035

Epoch: 5| Step: 10
Training loss: 2.714904960106952
Validation loss: 2.7419563483277423

Epoch: 250| Step: 0
Training loss: 3.3460079662184845
Validation loss: 2.744109793583137

Epoch: 5| Step: 1
Training loss: 3.3900951903265337
Validation loss: 2.741987358226278

Epoch: 5| Step: 2
Training loss: 2.8251557332552086
Validation loss: 2.7427901828166767

Epoch: 5| Step: 3
Training loss: 2.8655771831820265
Validation loss: 2.7438716619549477

Epoch: 5| Step: 4
Training loss: 3.425326761961331
Validation loss: 2.7396420942318365

Epoch: 5| Step: 5
Training loss: 3.1686029704817704
Validation loss: 2.74351593767583

Epoch: 5| Step: 6
Training loss: 2.992973523197137
Validation loss: 2.7402174900469602

Epoch: 5| Step: 7
Training loss: 3.1979882711704786
Validation loss: 2.7402881193149775

Epoch: 5| Step: 8
Training loss: 2.6863935100124863
Validation loss: 2.7388766752297684

Epoch: 5| Step: 9
Training loss: 2.923135251069461
Validation loss: 2.741991407522625

Epoch: 5| Step: 10
Training loss: 2.5976178847613314
Validation loss: 2.7442548052881124

Testing loss: 2.9588505109296492
