Epoch: 1| Step: 0
Training loss: 5.110845978167296
Validation loss: 5.861081555216552

Epoch: 5| Step: 1
Training loss: 5.9586799716375545
Validation loss: 5.851584805123337

Epoch: 5| Step: 2
Training loss: 6.367239023947973
Validation loss: 5.842395417751066

Epoch: 5| Step: 3
Training loss: 6.12393615203005
Validation loss: 5.834677459040775

Epoch: 5| Step: 4
Training loss: 6.613940526611256
Validation loss: 5.827502703426896

Epoch: 5| Step: 5
Training loss: 6.306859886537671
Validation loss: 5.820498168653101

Epoch: 5| Step: 6
Training loss: 5.500201481683314
Validation loss: 5.813762944386515

Epoch: 5| Step: 7
Training loss: 5.249643404521281
Validation loss: 5.807077905189887

Epoch: 5| Step: 8
Training loss: 5.955473028784702
Validation loss: 5.799422332149081

Epoch: 5| Step: 9
Training loss: 5.0073550486998855
Validation loss: 5.791932960467875

Epoch: 5| Step: 10
Training loss: 5.9838937112681
Validation loss: 5.783675527784799

Epoch: 2| Step: 0
Training loss: 5.826551946096972
Validation loss: 5.77504706134291

Epoch: 5| Step: 1
Training loss: 6.032153126197198
Validation loss: 5.764962448494305

Epoch: 5| Step: 2
Training loss: 5.629145302815513
Validation loss: 5.755517114891611

Epoch: 5| Step: 3
Training loss: 6.796232907889579
Validation loss: 5.743964888691466

Epoch: 5| Step: 4
Training loss: 5.598328150097301
Validation loss: 5.7319580091693565

Epoch: 5| Step: 5
Training loss: 4.586841604607872
Validation loss: 5.71875865730981

Epoch: 5| Step: 6
Training loss: 6.1850439264068315
Validation loss: 5.704263353431334

Epoch: 5| Step: 7
Training loss: 5.30358227998872
Validation loss: 5.689770998462511

Epoch: 5| Step: 8
Training loss: 5.807856191614981
Validation loss: 5.672999454828283

Epoch: 5| Step: 9
Training loss: 5.973070747757375
Validation loss: 5.655499260904798

Epoch: 5| Step: 10
Training loss: 5.142798987317139
Validation loss: 5.63675325366189

Epoch: 3| Step: 0
Training loss: 6.445504850349498
Validation loss: 5.616375501307217

Epoch: 5| Step: 1
Training loss: 5.708412039926526
Validation loss: 5.595121533472339

Epoch: 5| Step: 2
Training loss: 6.454319582417085
Validation loss: 5.572204427792568

Epoch: 5| Step: 3
Training loss: 5.919139864527603
Validation loss: 5.548166772408045

Epoch: 5| Step: 4
Training loss: 5.052277404623246
Validation loss: 5.523547574017307

Epoch: 5| Step: 5
Training loss: 5.595349983402967
Validation loss: 5.497277332643666

Epoch: 5| Step: 6
Training loss: 4.172529647840669
Validation loss: 5.47007690270646

Epoch: 5| Step: 7
Training loss: 5.2786784937155105
Validation loss: 5.442788092638246

Epoch: 5| Step: 8
Training loss: 5.856776116350256
Validation loss: 5.413297378032271

Epoch: 5| Step: 9
Training loss: 4.790960685579822
Validation loss: 5.382950517677036

Epoch: 5| Step: 10
Training loss: 5.217192640184931
Validation loss: 5.354199117271146

Epoch: 4| Step: 0
Training loss: 5.147674272430129
Validation loss: 5.323108486702849

Epoch: 5| Step: 1
Training loss: 4.739418490830451
Validation loss: 5.292193577024059

Epoch: 5| Step: 2
Training loss: 6.330779246596791
Validation loss: 5.2588176930845085

Epoch: 5| Step: 3
Training loss: 5.72622342426401
Validation loss: 5.226847466187262

Epoch: 5| Step: 4
Training loss: 4.058257014649053
Validation loss: 5.19245873296904

Epoch: 5| Step: 5
Training loss: 4.813287843892578
Validation loss: 5.161377504148245

Epoch: 5| Step: 6
Training loss: 5.4340040873321565
Validation loss: 5.128114599780878

Epoch: 5| Step: 7
Training loss: 5.4341904664255765
Validation loss: 5.093764661864346

Epoch: 5| Step: 8
Training loss: 5.522141710628732
Validation loss: 5.060044045743592

Epoch: 5| Step: 9
Training loss: 5.302768545585115
Validation loss: 5.027668964549559

Epoch: 5| Step: 10
Training loss: 4.424164627447405
Validation loss: 4.9942935291993145

Epoch: 5| Step: 0
Training loss: 5.939231218622636
Validation loss: 4.960113542231697

Epoch: 5| Step: 1
Training loss: 5.314572277927402
Validation loss: 4.928144065224991

Epoch: 5| Step: 2
Training loss: 4.573375959800127
Validation loss: 4.89512127594373

Epoch: 5| Step: 3
Training loss: 4.674274963622366
Validation loss: 4.863700290995518

Epoch: 5| Step: 4
Training loss: 5.467940788344708
Validation loss: 4.8349749726638835

Epoch: 5| Step: 5
Training loss: 4.742702299075523
Validation loss: 4.8047754380550485

Epoch: 5| Step: 6
Training loss: 4.578489529935874
Validation loss: 4.77018254820007

Epoch: 5| Step: 7
Training loss: 4.471110967362665
Validation loss: 4.736618669683863

Epoch: 5| Step: 8
Training loss: 3.0501605194876404
Validation loss: 4.701403093501601

Epoch: 5| Step: 9
Training loss: 4.8278328520151845
Validation loss: 4.670757449085826

Epoch: 5| Step: 10
Training loss: 5.662312499051431
Validation loss: 4.642706353354274

Epoch: 6| Step: 0
Training loss: 4.98821662974491
Validation loss: 4.6173421913192225

Epoch: 5| Step: 1
Training loss: 4.964514504597345
Validation loss: 4.594325005279871

Epoch: 5| Step: 2
Training loss: 4.344290720265233
Validation loss: 4.569792011732332

Epoch: 5| Step: 3
Training loss: 5.32983728901209
Validation loss: 4.544646685434512

Epoch: 5| Step: 4
Training loss: 3.5319985465611614
Validation loss: 4.522034717335746

Epoch: 5| Step: 5
Training loss: 4.131960458305949
Validation loss: 4.503312847803469

Epoch: 5| Step: 6
Training loss: 4.4910931921195685
Validation loss: 4.481880307298769

Epoch: 5| Step: 7
Training loss: 5.270824547962612
Validation loss: 4.466471392814283

Epoch: 5| Step: 8
Training loss: 4.555576453639119
Validation loss: 4.446056280746675

Epoch: 5| Step: 9
Training loss: 4.54662225289527
Validation loss: 4.426480527466395

Epoch: 5| Step: 10
Training loss: 4.234874512886135
Validation loss: 4.404151816653567

Epoch: 7| Step: 0
Training loss: 5.1984435319650535
Validation loss: 4.392530850710734

Epoch: 5| Step: 1
Training loss: 2.887912281542885
Validation loss: 4.372013316019262

Epoch: 5| Step: 2
Training loss: 4.1116022956385265
Validation loss: 4.356181270619614

Epoch: 5| Step: 3
Training loss: 4.7460364821004815
Validation loss: 4.34113222086311

Epoch: 5| Step: 4
Training loss: 4.541301234297805
Validation loss: 4.328380688076454

Epoch: 5| Step: 5
Training loss: 4.221574981894647
Validation loss: 4.31714630100763

Epoch: 5| Step: 6
Training loss: 3.829720051944989
Validation loss: 4.302543432987215

Epoch: 5| Step: 7
Training loss: 4.683660944185423
Validation loss: 4.293496242596177

Epoch: 5| Step: 8
Training loss: 4.6130253190280825
Validation loss: 4.279802739298696

Epoch: 5| Step: 9
Training loss: 5.272846646586912
Validation loss: 4.268054682325462

Epoch: 5| Step: 10
Training loss: 4.160222270602896
Validation loss: 4.258825362020006

Epoch: 8| Step: 0
Training loss: 5.282098284429868
Validation loss: 4.254777013961481

Epoch: 5| Step: 1
Training loss: 4.627692392596246
Validation loss: 4.234309728714438

Epoch: 5| Step: 2
Training loss: 4.689725017172578
Validation loss: 4.225049487039723

Epoch: 5| Step: 3
Training loss: 4.790302358812309
Validation loss: 4.2119096642913405

Epoch: 5| Step: 4
Training loss: 4.207766101239961
Validation loss: 4.203496715648583

Epoch: 5| Step: 5
Training loss: 3.438284767043333
Validation loss: 4.189496290127623

Epoch: 5| Step: 6
Training loss: 5.266924145999902
Validation loss: 4.178844801132899

Epoch: 5| Step: 7
Training loss: 4.081127011839692
Validation loss: 4.166806014817449

Epoch: 5| Step: 8
Training loss: 3.4905304188153545
Validation loss: 4.159605879781317

Epoch: 5| Step: 9
Training loss: 3.5167291560353604
Validation loss: 4.1387751980436365

Epoch: 5| Step: 10
Training loss: 3.528591674539212
Validation loss: 4.1299716302465965

Epoch: 9| Step: 0
Training loss: 3.600593618618061
Validation loss: 4.122054088792942

Epoch: 5| Step: 1
Training loss: 4.78180167811447
Validation loss: 4.114419343462625

Epoch: 5| Step: 2
Training loss: 4.466985394127962
Validation loss: 4.1047148704080785

Epoch: 5| Step: 3
Training loss: 4.401349311624727
Validation loss: 4.094273837798782

Epoch: 5| Step: 4
Training loss: 4.636664861865667
Validation loss: 4.080448773342328

Epoch: 5| Step: 5
Training loss: 3.9556470221637112
Validation loss: 4.084563256964172

Epoch: 5| Step: 6
Training loss: 3.206540254836011
Validation loss: 4.06268487829879

Epoch: 5| Step: 7
Training loss: 3.953344648086627
Validation loss: 4.057860417979259

Epoch: 5| Step: 8
Training loss: 4.146549003338193
Validation loss: 4.045890712161129

Epoch: 5| Step: 9
Training loss: 4.492718209140017
Validation loss: 4.042702740710361

Epoch: 5| Step: 10
Training loss: 4.54785439341897
Validation loss: 4.023732490529616

Epoch: 10| Step: 0
Training loss: 4.283790447221143
Validation loss: 4.0060514338825195

Epoch: 5| Step: 1
Training loss: 3.6504239345641176
Validation loss: 3.997613621856437

Epoch: 5| Step: 2
Training loss: 4.59612477480286
Validation loss: 3.99282651801096

Epoch: 5| Step: 3
Training loss: 3.718372229613903
Validation loss: 3.985250042274081

Epoch: 5| Step: 4
Training loss: 3.139293179502373
Validation loss: 3.9692840746504263

Epoch: 5| Step: 5
Training loss: 4.897256565869124
Validation loss: 3.9558861041852964

Epoch: 5| Step: 6
Training loss: 3.714862233786823
Validation loss: 3.941947699892535

Epoch: 5| Step: 7
Training loss: 3.8975295727716914
Validation loss: 3.928299005313631

Epoch: 5| Step: 8
Training loss: 4.331612294115012
Validation loss: 3.94710881453389

Epoch: 5| Step: 9
Training loss: 4.105770256084959
Validation loss: 3.9080272912007197

Epoch: 5| Step: 10
Training loss: 4.671237863836736
Validation loss: 3.908727926577225

Epoch: 11| Step: 0
Training loss: 3.9678182634604857
Validation loss: 3.909373501807306

Epoch: 5| Step: 1
Training loss: 3.943954747805098
Validation loss: 3.9031764464383283

Epoch: 5| Step: 2
Training loss: 3.4871973487488623
Validation loss: 3.8816277148159615

Epoch: 5| Step: 3
Training loss: 4.708297369265416
Validation loss: 3.8651033398854606

Epoch: 5| Step: 4
Training loss: 4.728124338415973
Validation loss: 3.8456277903396856

Epoch: 5| Step: 5
Training loss: 4.178598993045125
Validation loss: 3.8540850793949373

Epoch: 5| Step: 6
Training loss: 2.801964333050609
Validation loss: 3.836732936999639

Epoch: 5| Step: 7
Training loss: 3.9683674305029473
Validation loss: 3.821595986186455

Epoch: 5| Step: 8
Training loss: 3.8929049387706205
Validation loss: 3.8143282870106847

Epoch: 5| Step: 9
Training loss: 3.8561355648032687
Validation loss: 3.807433063095723

Epoch: 5| Step: 10
Training loss: 4.2987018932369505
Validation loss: 3.7979933999268667

Epoch: 12| Step: 0
Training loss: 4.586430329806179
Validation loss: 3.784817960718076

Epoch: 5| Step: 1
Training loss: 4.740973076712346
Validation loss: 3.777989762994079

Epoch: 5| Step: 2
Training loss: 3.523243427218239
Validation loss: 3.7655605194394712

Epoch: 5| Step: 3
Training loss: 3.3651861983275255
Validation loss: 3.757500012876947

Epoch: 5| Step: 4
Training loss: 3.343249987713554
Validation loss: 3.754774715469353

Epoch: 5| Step: 5
Training loss: 2.814798560244306
Validation loss: 3.7510808747420503

Epoch: 5| Step: 6
Training loss: 4.003681872523959
Validation loss: 3.7456299178786776

Epoch: 5| Step: 7
Training loss: 4.146397895647884
Validation loss: 3.735266161548341

Epoch: 5| Step: 8
Training loss: 4.399668871817585
Validation loss: 3.7290281108598666

Epoch: 5| Step: 9
Training loss: 3.940359863267666
Validation loss: 3.721057033181775

Epoch: 5| Step: 10
Training loss: 3.9143738765553535
Validation loss: 3.7147416141019174

Epoch: 13| Step: 0
Training loss: 4.428983440658471
Validation loss: 3.723287856467564

Epoch: 5| Step: 1
Training loss: 3.7548884001096265
Validation loss: 3.69610924972296

Epoch: 5| Step: 2
Training loss: 4.639285321279165
Validation loss: 3.692319098338102

Epoch: 5| Step: 3
Training loss: 3.3053387660753484
Validation loss: 3.6909204397202533

Epoch: 5| Step: 4
Training loss: 4.662596198922762
Validation loss: 3.6873314751015362

Epoch: 5| Step: 5
Training loss: 2.8602310316765376
Validation loss: 3.677944148242529

Epoch: 5| Step: 6
Training loss: 2.744231937287492
Validation loss: 3.671114762010326

Epoch: 5| Step: 7
Training loss: 3.663576919491624
Validation loss: 3.664382273770067

Epoch: 5| Step: 8
Training loss: 3.918195845315925
Validation loss: 3.6547782171720575

Epoch: 5| Step: 9
Training loss: 4.2562972145990825
Validation loss: 3.6509465873482925

Epoch: 5| Step: 10
Training loss: 3.7248833350019166
Validation loss: 3.645047666682878

Epoch: 14| Step: 0
Training loss: 3.9711265356979517
Validation loss: 3.6414157825971807

Epoch: 5| Step: 1
Training loss: 4.456104660339172
Validation loss: 3.635302420229987

Epoch: 5| Step: 2
Training loss: 3.3922292544247648
Validation loss: 3.628994942294364

Epoch: 5| Step: 3
Training loss: 3.9912513187644016
Validation loss: 3.6194438369125863

Epoch: 5| Step: 4
Training loss: 3.1236860946340395
Validation loss: 3.613358795211923

Epoch: 5| Step: 5
Training loss: 3.32623022166052
Validation loss: 3.61068842322718

Epoch: 5| Step: 6
Training loss: 3.7874435269517397
Validation loss: 3.609333291123751

Epoch: 5| Step: 7
Training loss: 4.105815085222188
Validation loss: 3.5976160171512888

Epoch: 5| Step: 8
Training loss: 4.356594935680129
Validation loss: 3.5933341157951815

Epoch: 5| Step: 9
Training loss: 4.079075961846586
Validation loss: 3.5871943906146018

Epoch: 5| Step: 10
Training loss: 2.784312415998394
Validation loss: 3.5826635347611218

Epoch: 15| Step: 0
Training loss: 3.9435356746901267
Validation loss: 3.580514615280734

Epoch: 5| Step: 1
Training loss: 4.251887182969372
Validation loss: 3.5676140741852223

Epoch: 5| Step: 2
Training loss: 3.4052755379348985
Validation loss: 3.5626312977188848

Epoch: 5| Step: 3
Training loss: 3.6810411688697617
Validation loss: 3.5583800402104706

Epoch: 5| Step: 4
Training loss: 3.2413208320195617
Validation loss: 3.5510455041920226

Epoch: 5| Step: 5
Training loss: 3.5992459938073122
Validation loss: 3.554110144049466

Epoch: 5| Step: 6
Training loss: 2.986723130861782
Validation loss: 3.5541620034896515

Epoch: 5| Step: 7
Training loss: 5.095579041285809
Validation loss: 3.5358729062404723

Epoch: 5| Step: 8
Training loss: 3.2212831473430654
Validation loss: 3.528922166490844

Epoch: 5| Step: 9
Training loss: 3.849650250686717
Validation loss: 3.5292456758621467

Epoch: 5| Step: 10
Training loss: 3.5202000667329494
Validation loss: 3.524868083304544

Epoch: 16| Step: 0
Training loss: 4.209488939811983
Validation loss: 3.5200330845777974

Epoch: 5| Step: 1
Training loss: 3.1414711794419903
Validation loss: 3.5173959619010255

Epoch: 5| Step: 2
Training loss: 3.491624620377171
Validation loss: 3.5155781812752047

Epoch: 5| Step: 3
Training loss: 2.8969775530492283
Validation loss: 3.5138225103029592

Epoch: 5| Step: 4
Training loss: 4.185729834064116
Validation loss: 3.5099263993453373

Epoch: 5| Step: 5
Training loss: 3.7142694231870768
Validation loss: 3.5080902627658554

Epoch: 5| Step: 6
Training loss: 3.523475528351114
Validation loss: 3.4951820356631442

Epoch: 5| Step: 7
Training loss: 2.8540292600055404
Validation loss: 3.489940029397332

Epoch: 5| Step: 8
Training loss: 3.942374345885137
Validation loss: 3.4892602150458827

Epoch: 5| Step: 9
Training loss: 4.0235974918887445
Validation loss: 3.4806458146988217

Epoch: 5| Step: 10
Training loss: 4.56890106577638
Validation loss: 3.475778090946082

Epoch: 17| Step: 0
Training loss: 3.1899120703749237
Validation loss: 3.474070776865997

Epoch: 5| Step: 1
Training loss: 3.4210775482567657
Validation loss: 3.469469832554255

Epoch: 5| Step: 2
Training loss: 4.010465283119824
Validation loss: 3.4679432301859974

Epoch: 5| Step: 3
Training loss: 3.935259469189262
Validation loss: 3.4606880215292617

Epoch: 5| Step: 4
Training loss: 3.1305873512323994
Validation loss: 3.4603559764304075

Epoch: 5| Step: 5
Training loss: 3.477268790176529
Validation loss: 3.45372865124448

Epoch: 5| Step: 6
Training loss: 3.854638904130683
Validation loss: 3.4521782996780686

Epoch: 5| Step: 7
Training loss: 3.4762463372302794
Validation loss: 3.4474339975282735

Epoch: 5| Step: 8
Training loss: 4.028543199326264
Validation loss: 3.442630899438525

Epoch: 5| Step: 9
Training loss: 3.29478467871598
Validation loss: 3.441320993558538

Epoch: 5| Step: 10
Training loss: 4.482152939917004
Validation loss: 3.437259420289846

Epoch: 18| Step: 0
Training loss: 3.2075611192524818
Validation loss: 3.4358537649244107

Epoch: 5| Step: 1
Training loss: 3.1742756595528356
Validation loss: 3.4318817793713654

Epoch: 5| Step: 2
Training loss: 4.486422931763817
Validation loss: 3.4286001373198514

Epoch: 5| Step: 3
Training loss: 3.483658515925264
Validation loss: 3.428502444519631

Epoch: 5| Step: 4
Training loss: 4.229401430025155
Validation loss: 3.4273902722451295

Epoch: 5| Step: 5
Training loss: 3.716321777512829
Validation loss: 3.4172618886734667

Epoch: 5| Step: 6
Training loss: 3.6493689840756844
Validation loss: 3.4184606395885853

Epoch: 5| Step: 7
Training loss: 3.5228947731088223
Validation loss: 3.4138857381162167

Epoch: 5| Step: 8
Training loss: 3.2426179531175685
Validation loss: 3.409498923363531

Epoch: 5| Step: 9
Training loss: 3.065932705025602
Validation loss: 3.4083418498948395

Epoch: 5| Step: 10
Training loss: 4.067644822931026
Validation loss: 3.407327759004401

Epoch: 19| Step: 0
Training loss: 2.688382469606392
Validation loss: 3.4044359473251795

Epoch: 5| Step: 1
Training loss: 3.509492807287728
Validation loss: 3.4024630453685423

Epoch: 5| Step: 2
Training loss: 4.439499525439433
Validation loss: 3.3987509788814667

Epoch: 5| Step: 3
Training loss: 3.3442100137169506
Validation loss: 3.3933245774897993

Epoch: 5| Step: 4
Training loss: 3.591157990182167
Validation loss: 3.3890228606994723

Epoch: 5| Step: 5
Training loss: 3.620445547346861
Validation loss: 3.380287246216536

Epoch: 5| Step: 6
Training loss: 3.812215075242637
Validation loss: 3.3741265780528638

Epoch: 5| Step: 7
Training loss: 3.633065819880905
Validation loss: 3.3752404556086666

Epoch: 5| Step: 8
Training loss: 3.3774511125642115
Validation loss: 3.3692216169274407

Epoch: 5| Step: 9
Training loss: 3.3728424522775655
Validation loss: 3.3686778072887966

Epoch: 5| Step: 10
Training loss: 4.1525380474003395
Validation loss: 3.3631655729245624

Epoch: 20| Step: 0
Training loss: 3.167131456764735
Validation loss: 3.361721084037715

Epoch: 5| Step: 1
Training loss: 3.518675163381171
Validation loss: 3.359079550294739

Epoch: 5| Step: 2
Training loss: 3.6842070278351886
Validation loss: 3.3559490220526036

Epoch: 5| Step: 3
Training loss: 3.637304273235693
Validation loss: 3.352101133238586

Epoch: 5| Step: 4
Training loss: 4.309031321629739
Validation loss: 3.3540373338851976

Epoch: 5| Step: 5
Training loss: 3.857999239821134
Validation loss: 3.348877932515197

Epoch: 5| Step: 6
Training loss: 4.477527241498845
Validation loss: 3.347075565773092

Epoch: 5| Step: 7
Training loss: 3.44304196370988
Validation loss: 3.3421570390757935

Epoch: 5| Step: 8
Training loss: 3.107956145636267
Validation loss: 3.3394346638978893

Epoch: 5| Step: 9
Training loss: 3.0975555749915338
Validation loss: 3.337587150077119

Epoch: 5| Step: 10
Training loss: 2.544671257835739
Validation loss: 3.3380098752357332

Epoch: 21| Step: 0
Training loss: 3.360167228079457
Validation loss: 3.334310936366425

Epoch: 5| Step: 1
Training loss: 3.9766615459945296
Validation loss: 3.3377873662823783

Epoch: 5| Step: 2
Training loss: 3.3994310351755983
Validation loss: 3.3262350726603964

Epoch: 5| Step: 3
Training loss: 3.059663354145067
Validation loss: 3.3180214790505924

Epoch: 5| Step: 4
Training loss: 3.210737458840578
Validation loss: 3.3188593429969444

Epoch: 5| Step: 5
Training loss: 3.1466265219482166
Validation loss: 3.3160177704069618

Epoch: 5| Step: 6
Training loss: 3.74719005847723
Validation loss: 3.314350109145603

Epoch: 5| Step: 7
Training loss: 4.069135909523163
Validation loss: 3.3086753818001076

Epoch: 5| Step: 8
Training loss: 3.5952226358163726
Validation loss: 3.3055913588938926

Epoch: 5| Step: 9
Training loss: 3.4627443853956166
Validation loss: 3.302094989224355

Epoch: 5| Step: 10
Training loss: 3.98850756982891
Validation loss: 3.303134976803085

Epoch: 22| Step: 0
Training loss: 3.437083548548413
Validation loss: 3.2967274740765866

Epoch: 5| Step: 1
Training loss: 3.4834548351020427
Validation loss: 3.2920818734184687

Epoch: 5| Step: 2
Training loss: 3.9926216501562464
Validation loss: 3.288182721895654

Epoch: 5| Step: 3
Training loss: 2.9902914628572437
Validation loss: 3.285638842795861

Epoch: 5| Step: 4
Training loss: 3.515443788732552
Validation loss: 3.2836744688955646

Epoch: 5| Step: 5
Training loss: 4.0714821919517075
Validation loss: 3.281807203978412

Epoch: 5| Step: 6
Training loss: 3.433354461629602
Validation loss: 3.2760797412937688

Epoch: 5| Step: 7
Training loss: 2.9318580826348715
Validation loss: 3.275647228643652

Epoch: 5| Step: 8
Training loss: 3.7254510337633295
Validation loss: 3.2752758372433877

Epoch: 5| Step: 9
Training loss: 3.34420787492793
Validation loss: 3.273100043572475

Epoch: 5| Step: 10
Training loss: 3.7304443358576105
Validation loss: 3.2709336608669752

Epoch: 23| Step: 0
Training loss: 3.3286781388654334
Validation loss: 3.2659224343192013

Epoch: 5| Step: 1
Training loss: 3.0352908856983087
Validation loss: 3.2649136872696727

Epoch: 5| Step: 2
Training loss: 3.4802828309893434
Validation loss: 3.2637188409758107

Epoch: 5| Step: 3
Training loss: 3.1425128785372483
Validation loss: 3.2608664871113313

Epoch: 5| Step: 4
Training loss: 4.255099434861837
Validation loss: 3.2614864835273223

Epoch: 5| Step: 5
Training loss: 3.864525450952493
Validation loss: 3.2582926028165717

Epoch: 5| Step: 6
Training loss: 3.6478508879988802
Validation loss: 3.2558740929152816

Epoch: 5| Step: 7
Training loss: 3.1872735036524493
Validation loss: 3.2534452309051014

Epoch: 5| Step: 8
Training loss: 2.7021000854004273
Validation loss: 3.252288528494649

Epoch: 5| Step: 9
Training loss: 3.581871902765344
Validation loss: 3.2490895939009135

Epoch: 5| Step: 10
Training loss: 4.149084123407279
Validation loss: 3.2487153858238997

Epoch: 24| Step: 0
Training loss: 3.6800209104939015
Validation loss: 3.2475690671706645

Epoch: 5| Step: 1
Training loss: 3.647138670711389
Validation loss: 3.2442151759120073

Epoch: 5| Step: 2
Training loss: 3.0694361399389116
Validation loss: 3.24182420699914

Epoch: 5| Step: 3
Training loss: 3.4678659773188336
Validation loss: 3.24261803059718

Epoch: 5| Step: 4
Training loss: 4.203736214707316
Validation loss: 3.2398321075140455

Epoch: 5| Step: 5
Training loss: 3.0673857661260056
Validation loss: 3.2380706977138374

Epoch: 5| Step: 6
Training loss: 3.759659977208853
Validation loss: 3.2379274386153187

Epoch: 5| Step: 7
Training loss: 2.898069949636033
Validation loss: 3.234347524392984

Epoch: 5| Step: 8
Training loss: 3.1427295522676286
Validation loss: 3.2346203329372947

Epoch: 5| Step: 9
Training loss: 3.4857302369416088
Validation loss: 3.231995909854677

Epoch: 5| Step: 10
Training loss: 3.819065631615145
Validation loss: 3.2304477835054666

Epoch: 25| Step: 0
Training loss: 3.639984729441376
Validation loss: 3.2281348952227398

Epoch: 5| Step: 1
Training loss: 3.5933431643868774
Validation loss: 3.2277030737465657

Epoch: 5| Step: 2
Training loss: 3.2229465423231662
Validation loss: 3.2259150355532284

Epoch: 5| Step: 3
Training loss: 3.0534877909055056
Validation loss: 3.2222136862894826

Epoch: 5| Step: 4
Training loss: 3.0094042244796424
Validation loss: 3.2209310448793516

Epoch: 5| Step: 5
Training loss: 4.155500071852721
Validation loss: 3.218965943091062

Epoch: 5| Step: 6
Training loss: 2.860448416922428
Validation loss: 3.218039713327717

Epoch: 5| Step: 7
Training loss: 3.8597235271287995
Validation loss: 3.217636140275693

Epoch: 5| Step: 8
Training loss: 3.6747497992429543
Validation loss: 3.2163209065495217

Epoch: 5| Step: 9
Training loss: 3.1684514253037364
Validation loss: 3.2133228677386794

Epoch: 5| Step: 10
Training loss: 3.809063723006331
Validation loss: 3.2128505801663145

Epoch: 26| Step: 0
Training loss: 3.3131151887654497
Validation loss: 3.2119422496090024

Epoch: 5| Step: 1
Training loss: 3.7819420047309604
Validation loss: 3.213522245364007

Epoch: 5| Step: 2
Training loss: 3.000074703558015
Validation loss: 3.2386844636867718

Epoch: 5| Step: 3
Training loss: 3.712121264729591
Validation loss: 3.2365373585438593

Epoch: 5| Step: 4
Training loss: 3.4488042666627194
Validation loss: 3.2089996466349007

Epoch: 5| Step: 5
Training loss: 3.371030663245878
Validation loss: 3.215425621811726

Epoch: 5| Step: 6
Training loss: 3.490495446788363
Validation loss: 3.2212235300761782

Epoch: 5| Step: 7
Training loss: 3.294962251299367
Validation loss: 3.2342968638472054

Epoch: 5| Step: 8
Training loss: 3.642728795266908
Validation loss: 3.238281956166951

Epoch: 5| Step: 9
Training loss: 3.5936190373980526
Validation loss: 3.2298598583824054

Epoch: 5| Step: 10
Training loss: 3.6040516359057486
Validation loss: 3.2222594704088117

Epoch: 27| Step: 0
Training loss: 3.0062538765547218
Validation loss: 3.21356085224773

Epoch: 5| Step: 1
Training loss: 4.048430979527265
Validation loss: 3.210801330095035

Epoch: 5| Step: 2
Training loss: 4.243741532374883
Validation loss: 3.2050363300050977

Epoch: 5| Step: 3
Training loss: 3.4685051634014443
Validation loss: 3.200141832165662

Epoch: 5| Step: 4
Training loss: 3.028613644945747
Validation loss: 3.2005829727424575

Epoch: 5| Step: 5
Training loss: 2.637975864962289
Validation loss: 3.2010168870307076

Epoch: 5| Step: 6
Training loss: 2.8818251823863186
Validation loss: 3.204745791255141

Epoch: 5| Step: 7
Training loss: 3.9568853172513596
Validation loss: 3.206710395891746

Epoch: 5| Step: 8
Training loss: 3.704567543768143
Validation loss: 3.200249428795505

Epoch: 5| Step: 9
Training loss: 2.794763375299164
Validation loss: 3.2006550611903397

Epoch: 5| Step: 10
Training loss: 3.9402850761490904
Validation loss: 3.196119796039558

Epoch: 28| Step: 0
Training loss: 3.9773179931046405
Validation loss: 3.192922700225781

Epoch: 5| Step: 1
Training loss: 3.624564572195217
Validation loss: 3.1923051213576263

Epoch: 5| Step: 2
Training loss: 3.464763653333646
Validation loss: 3.192563691007993

Epoch: 5| Step: 3
Training loss: 3.9191362157200103
Validation loss: 3.1927422772604706

Epoch: 5| Step: 4
Training loss: 3.319611311530848
Validation loss: 3.1916882487047995

Epoch: 5| Step: 5
Training loss: 3.300736755432355
Validation loss: 3.1902845116828127

Epoch: 5| Step: 6
Training loss: 3.073266857473671
Validation loss: 3.188224656220942

Epoch: 5| Step: 7
Training loss: 3.2975331594146198
Validation loss: 3.186836096324865

Epoch: 5| Step: 8
Training loss: 3.031198717450384
Validation loss: 3.1868882369330063

Epoch: 5| Step: 9
Training loss: 3.440902967597586
Validation loss: 3.1843346681858167

Epoch: 5| Step: 10
Training loss: 3.388609396938445
Validation loss: 3.184577831371596

Epoch: 29| Step: 0
Training loss: 3.2046698589760063
Validation loss: 3.1817541949285677

Epoch: 5| Step: 1
Training loss: 3.3387839258684733
Validation loss: 3.1819762645978384

Epoch: 5| Step: 2
Training loss: 3.429599352422911
Validation loss: 3.1809094067045645

Epoch: 5| Step: 3
Training loss: 3.525055710372599
Validation loss: 3.180154148228117

Epoch: 5| Step: 4
Training loss: 3.4851437392071176
Validation loss: 3.17893480120294

Epoch: 5| Step: 5
Training loss: 3.5084800170051023
Validation loss: 3.176727404629093

Epoch: 5| Step: 6
Training loss: 3.0741399539218817
Validation loss: 3.175966797621983

Epoch: 5| Step: 7
Training loss: 4.0102032228948215
Validation loss: 3.1754478070967234

Epoch: 5| Step: 8
Training loss: 2.5658311359147907
Validation loss: 3.174117788167217

Epoch: 5| Step: 9
Training loss: 3.8164224926886954
Validation loss: 3.172747995548102

Epoch: 5| Step: 10
Training loss: 3.743752679839791
Validation loss: 3.1738456788441365

Epoch: 30| Step: 0
Training loss: 3.317133703527803
Validation loss: 3.1719489273612678

Epoch: 5| Step: 1
Training loss: 3.3498197706335695
Validation loss: 3.172131674145979

Epoch: 5| Step: 2
Training loss: 2.9860226541670327
Validation loss: 3.1715551756926073

Epoch: 5| Step: 3
Training loss: 3.5733282595451357
Validation loss: 3.169749159148781

Epoch: 5| Step: 4
Training loss: 3.1497279095075283
Validation loss: 3.1691985101540383

Epoch: 5| Step: 5
Training loss: 4.187816778698448
Validation loss: 3.167542158990487

Epoch: 5| Step: 6
Training loss: 3.3795451888669503
Validation loss: 3.1676960881871503

Epoch: 5| Step: 7
Training loss: 2.8298648098308417
Validation loss: 3.1659977006065443

Epoch: 5| Step: 8
Training loss: 3.72176424849814
Validation loss: 3.1646469639837633

Epoch: 5| Step: 9
Training loss: 3.317864015640445
Validation loss: 3.1635105491749402

Epoch: 5| Step: 10
Training loss: 3.8071832323962376
Validation loss: 3.1626956306068617

Epoch: 31| Step: 0
Training loss: 3.832839864951168
Validation loss: 3.1616723978334447

Epoch: 5| Step: 1
Training loss: 3.221868541278156
Validation loss: 3.16122043366827

Epoch: 5| Step: 2
Training loss: 3.574986309745558
Validation loss: 3.159155112261281

Epoch: 5| Step: 3
Training loss: 3.369523868601352
Validation loss: 3.158153229367106

Epoch: 5| Step: 4
Training loss: 3.394089998246766
Validation loss: 3.1572641623472215

Epoch: 5| Step: 5
Training loss: 2.7625568850084723
Validation loss: 3.1578298615223455

Epoch: 5| Step: 6
Training loss: 3.843529671657819
Validation loss: 3.1558385503855617

Epoch: 5| Step: 7
Training loss: 3.286089425558677
Validation loss: 3.151663221284476

Epoch: 5| Step: 8
Training loss: 2.9587695556819513
Validation loss: 3.151034571653979

Epoch: 5| Step: 9
Training loss: 3.9911525153618106
Validation loss: 3.1507977780352747

Epoch: 5| Step: 10
Training loss: 3.1994970105159175
Validation loss: 3.1488463059212926

Epoch: 32| Step: 0
Training loss: 3.1546578498947144
Validation loss: 3.1484723728514

Epoch: 5| Step: 1
Training loss: 3.893772675033357
Validation loss: 3.1474493681686457

Epoch: 5| Step: 2
Training loss: 3.636814595566683
Validation loss: 3.150169321911114

Epoch: 5| Step: 3
Training loss: 3.8891143930236773
Validation loss: 3.1482846942513785

Epoch: 5| Step: 4
Training loss: 3.308822317684176
Validation loss: 3.1515411238755022

Epoch: 5| Step: 5
Training loss: 2.532169128072622
Validation loss: 3.1521841962528248

Epoch: 5| Step: 6
Training loss: 4.208042827185199
Validation loss: 3.150013579160112

Epoch: 5| Step: 7
Training loss: 2.690280451850129
Validation loss: 3.1457661018013763

Epoch: 5| Step: 8
Training loss: 3.4309407857456486
Validation loss: 3.1461211683164563

Epoch: 5| Step: 9
Training loss: 3.392775736814531
Validation loss: 3.14303463776375

Epoch: 5| Step: 10
Training loss: 3.0254065437464512
Validation loss: 3.140526822406071

Epoch: 33| Step: 0
Training loss: 3.9634799359293655
Validation loss: 3.142083430337659

Epoch: 5| Step: 1
Training loss: 3.51558308894289
Validation loss: 3.14463943441076

Epoch: 5| Step: 2
Training loss: 3.3816011651922655
Validation loss: 3.145337694404613

Epoch: 5| Step: 3
Training loss: 2.849655893533086
Validation loss: 3.1408768590992

Epoch: 5| Step: 4
Training loss: 2.850744009780913
Validation loss: 3.1404718761596357

Epoch: 5| Step: 5
Training loss: 3.1570768878359625
Validation loss: 3.139376631434617

Epoch: 5| Step: 6
Training loss: 3.108397363679912
Validation loss: 3.1387541280975055

Epoch: 5| Step: 7
Training loss: 3.9653090330823195
Validation loss: 3.142208150318288

Epoch: 5| Step: 8
Training loss: 2.678584903501495
Validation loss: 3.138624731888618

Epoch: 5| Step: 9
Training loss: 3.507773350282644
Validation loss: 3.13852032710609

Epoch: 5| Step: 10
Training loss: 4.299393793002065
Validation loss: 3.1362779000234076

Epoch: 34| Step: 0
Training loss: 3.0911984180754413
Validation loss: 3.1351253897650477

Epoch: 5| Step: 1
Training loss: 3.1303559753500347
Validation loss: 3.1365492046793566

Epoch: 5| Step: 2
Training loss: 3.2213929815685667
Validation loss: 3.134248422599864

Epoch: 5| Step: 3
Training loss: 3.9370879911395917
Validation loss: 3.1334332334563344

Epoch: 5| Step: 4
Training loss: 3.139875635733609
Validation loss: 3.1342291215087617

Epoch: 5| Step: 5
Training loss: 2.6671284236075206
Validation loss: 3.133522417855888

Epoch: 5| Step: 6
Training loss: 3.5923090160469853
Validation loss: 3.133331017786801

Epoch: 5| Step: 7
Training loss: 3.2327959564508433
Validation loss: 3.1354661917925495

Epoch: 5| Step: 8
Training loss: 3.791234225810383
Validation loss: 3.1376744450820278

Epoch: 5| Step: 9
Training loss: 3.2188277744415146
Validation loss: 3.1371839194717115

Epoch: 5| Step: 10
Training loss: 4.294029375563032
Validation loss: 3.1354543247372786

Epoch: 35| Step: 0
Training loss: 3.085006380244602
Validation loss: 3.133247458835288

Epoch: 5| Step: 1
Training loss: 2.649422791435353
Validation loss: 3.131051402689459

Epoch: 5| Step: 2
Training loss: 3.679084485447706
Validation loss: 3.131824595312964

Epoch: 5| Step: 3
Training loss: 3.655215255514776
Validation loss: 3.1275359047227744

Epoch: 5| Step: 4
Training loss: 3.7198696214121774
Validation loss: 3.1282345576719424

Epoch: 5| Step: 5
Training loss: 3.251084366876208
Validation loss: 3.1280093775045477

Epoch: 5| Step: 6
Training loss: 3.4514483355684384
Validation loss: 3.1274712125237722

Epoch: 5| Step: 7
Training loss: 3.3171285285325753
Validation loss: 3.1288389748401024

Epoch: 5| Step: 8
Training loss: 2.89525056825248
Validation loss: 3.1271497703000235

Epoch: 5| Step: 9
Training loss: 3.590615406471763
Validation loss: 3.1280680405475847

Epoch: 5| Step: 10
Training loss: 3.9912172695004213
Validation loss: 3.126016196462933

Epoch: 36| Step: 0
Training loss: 4.105882444145424
Validation loss: 3.129012436408067

Epoch: 5| Step: 1
Training loss: 3.6319279732137177
Validation loss: 3.1244037805941853

Epoch: 5| Step: 2
Training loss: 3.0726741026925426
Validation loss: 3.1259121168724113

Epoch: 5| Step: 3
Training loss: 3.6875655604854565
Validation loss: 3.125407388035757

Epoch: 5| Step: 4
Training loss: 3.465932165486918
Validation loss: 3.125659859834713

Epoch: 5| Step: 5
Training loss: 3.5432225717893173
Validation loss: 3.1261146345949413

Epoch: 5| Step: 6
Training loss: 3.876368127306595
Validation loss: 3.1286074663790466

Epoch: 5| Step: 7
Training loss: 3.348679803366705
Validation loss: 3.126385763407212

Epoch: 5| Step: 8
Training loss: 2.6834484877272007
Validation loss: 3.1215879915624196

Epoch: 5| Step: 9
Training loss: 3.1896933694633924
Validation loss: 3.125414780192752

Epoch: 5| Step: 10
Training loss: 2.131486864994892
Validation loss: 3.1220120549045793

Epoch: 37| Step: 0
Training loss: 3.4666341566126437
Validation loss: 3.1215454154234323

Epoch: 5| Step: 1
Training loss: 2.76454158618245
Validation loss: 3.1214718432880715

Epoch: 5| Step: 2
Training loss: 3.4093582950116357
Validation loss: 3.1201442377055124

Epoch: 5| Step: 3
Training loss: 4.029428706414005
Validation loss: 3.125003442249658

Epoch: 5| Step: 4
Training loss: 3.334681111292903
Validation loss: 3.1329806191697673

Epoch: 5| Step: 5
Training loss: 3.1973240869731474
Validation loss: 3.131857359518049

Epoch: 5| Step: 6
Training loss: 3.370820601305279
Validation loss: 3.1286068534535185

Epoch: 5| Step: 7
Training loss: 4.127552283248772
Validation loss: 3.123307976364079

Epoch: 5| Step: 8
Training loss: 3.549981189731677
Validation loss: 3.1153488466808277

Epoch: 5| Step: 9
Training loss: 3.21259571333621
Validation loss: 3.117866652051693

Epoch: 5| Step: 10
Training loss: 2.3263514374965335
Validation loss: 3.1163806959346325

Epoch: 38| Step: 0
Training loss: 3.425682144732386
Validation loss: 3.113847684694795

Epoch: 5| Step: 1
Training loss: 3.222978943360962
Validation loss: 3.116671253161708

Epoch: 5| Step: 2
Training loss: 3.6027218489732644
Validation loss: 3.1163186868140396

Epoch: 5| Step: 3
Training loss: 3.20082329649586
Validation loss: 3.1167434629838864

Epoch: 5| Step: 4
Training loss: 2.6217864211422595
Validation loss: 3.113970155217684

Epoch: 5| Step: 5
Training loss: 3.325817042187966
Validation loss: 3.1165944335904006

Epoch: 5| Step: 6
Training loss: 3.4723450872087995
Validation loss: 3.1118011169670208

Epoch: 5| Step: 7
Training loss: 4.0795093978173265
Validation loss: 3.1120957815294146

Epoch: 5| Step: 8
Training loss: 3.4744526493778203
Validation loss: 3.112153290617374

Epoch: 5| Step: 9
Training loss: 3.4076244136182483
Validation loss: 3.112859654715399

Epoch: 5| Step: 10
Training loss: 3.2191163382339063
Validation loss: 3.117363026851342

Epoch: 39| Step: 0
Training loss: 3.3069610350337433
Validation loss: 3.1190803178804827

Epoch: 5| Step: 1
Training loss: 3.227358371218544
Validation loss: 3.1260602477338875

Epoch: 5| Step: 2
Training loss: 2.9187316305820006
Validation loss: 3.1232192127711484

Epoch: 5| Step: 3
Training loss: 3.0654271986490373
Validation loss: 3.120929970045948

Epoch: 5| Step: 4
Training loss: 3.0992793753031043
Validation loss: 3.1266166344708712

Epoch: 5| Step: 5
Training loss: 3.167251900920076
Validation loss: 3.1334401828750034

Epoch: 5| Step: 6
Training loss: 4.155380731759595
Validation loss: 3.140279835109334

Epoch: 5| Step: 7
Training loss: 2.6177660857657155
Validation loss: 3.1210366660374005

Epoch: 5| Step: 8
Training loss: 3.398600256519334
Validation loss: 3.1059805256100774

Epoch: 5| Step: 9
Training loss: 4.262900575849744
Validation loss: 3.1061393650909825

Epoch: 5| Step: 10
Training loss: 3.7072218754497923
Validation loss: 3.1059734594510124

Epoch: 40| Step: 0
Training loss: 3.4143779966762633
Validation loss: 3.1078649852971183

Epoch: 5| Step: 1
Training loss: 3.4686783791786104
Validation loss: 3.1025418347488953

Epoch: 5| Step: 2
Training loss: 4.1198881437802095
Validation loss: 3.104123492593446

Epoch: 5| Step: 3
Training loss: 3.1522428550787485
Validation loss: 3.1063242866786127

Epoch: 5| Step: 4
Training loss: 2.761357090860552
Validation loss: 3.0943950694451026

Epoch: 5| Step: 5
Training loss: 3.9844657139642745
Validation loss: 3.095586552095408

Epoch: 5| Step: 6
Training loss: 2.6637099583738633
Validation loss: 3.094881271240479

Epoch: 5| Step: 7
Training loss: 3.5421934446630754
Validation loss: 3.08923496633366

Epoch: 5| Step: 8
Training loss: 3.8305782009159555
Validation loss: 3.0879586660813216

Epoch: 5| Step: 9
Training loss: 2.577319395025974
Validation loss: 3.087467846041428

Epoch: 5| Step: 10
Training loss: 3.069055197897108
Validation loss: 3.0863144112327214

Epoch: 41| Step: 0
Training loss: 3.765092867532946
Validation loss: 3.0963151774877162

Epoch: 5| Step: 1
Training loss: 3.0686886596764515
Validation loss: 3.093866657018672

Epoch: 5| Step: 2
Training loss: 2.888485668440664
Validation loss: 3.0956995276067936

Epoch: 5| Step: 3
Training loss: 3.2444863132347437
Validation loss: 3.0914196155061835

Epoch: 5| Step: 4
Training loss: 2.928936589964806
Validation loss: 3.0939051760209226

Epoch: 5| Step: 5
Training loss: 3.622735467159402
Validation loss: 3.0937561469308577

Epoch: 5| Step: 6
Training loss: 3.2942604436697986
Validation loss: 3.0796212769276194

Epoch: 5| Step: 7
Training loss: 3.8247074987731904
Validation loss: 3.0753523450573192

Epoch: 5| Step: 8
Training loss: 2.6865377255901857
Validation loss: 3.0737228301062824

Epoch: 5| Step: 9
Training loss: 3.7167093784860255
Validation loss: 3.0762497556652244

Epoch: 5| Step: 10
Training loss: 3.6375502015939536
Validation loss: 3.076831463170881

Epoch: 42| Step: 0
Training loss: 2.4960077835108367
Validation loss: 3.0773774625974797

Epoch: 5| Step: 1
Training loss: 2.910584529622383
Validation loss: 3.0747208582710637

Epoch: 5| Step: 2
Training loss: 3.193673233333911
Validation loss: 3.0739157182924264

Epoch: 5| Step: 3
Training loss: 2.996722338212012
Validation loss: 3.067361089805518

Epoch: 5| Step: 4
Training loss: 3.7233394224093743
Validation loss: 3.069136858447924

Epoch: 5| Step: 5
Training loss: 3.289636702262658
Validation loss: 3.0680382421631935

Epoch: 5| Step: 6
Training loss: 3.4564394686814897
Validation loss: 3.06891918487496

Epoch: 5| Step: 7
Training loss: 3.9998429982844694
Validation loss: 3.0738092799122843

Epoch: 5| Step: 8
Training loss: 3.674086533766588
Validation loss: 3.0791550928155567

Epoch: 5| Step: 9
Training loss: 3.1951959490796704
Validation loss: 3.076100199577801

Epoch: 5| Step: 10
Training loss: 3.641461845125778
Validation loss: 3.077271087304043

Epoch: 43| Step: 0
Training loss: 2.552190184140467
Validation loss: 3.067704792808644

Epoch: 5| Step: 1
Training loss: 3.186530769940614
Validation loss: 3.062223773994523

Epoch: 5| Step: 2
Training loss: 3.6005360098331844
Validation loss: 3.0643967243608548

Epoch: 5| Step: 3
Training loss: 2.88002354797697
Validation loss: 3.0642991899150185

Epoch: 5| Step: 4
Training loss: 3.8798893261885294
Validation loss: 3.061609543474627

Epoch: 5| Step: 5
Training loss: 3.8521841913157844
Validation loss: 3.061789543445098

Epoch: 5| Step: 6
Training loss: 3.2945509398217787
Validation loss: 3.0597363094445034

Epoch: 5| Step: 7
Training loss: 3.4658617246662966
Validation loss: 3.0588469441830886

Epoch: 5| Step: 8
Training loss: 2.8098969175226465
Validation loss: 3.0586980039377334

Epoch: 5| Step: 9
Training loss: 3.4985792818767374
Validation loss: 3.058604285857299

Epoch: 5| Step: 10
Training loss: 3.3815797317132112
Validation loss: 3.0569545554891313

Epoch: 44| Step: 0
Training loss: 3.438211540793144
Validation loss: 3.0558486324969736

Epoch: 5| Step: 1
Training loss: 2.661068394432472
Validation loss: 3.056225181123325

Epoch: 5| Step: 2
Training loss: 3.2601766447173905
Validation loss: 3.0569276489039536

Epoch: 5| Step: 3
Training loss: 3.7194314540654867
Validation loss: 3.058572973216581

Epoch: 5| Step: 4
Training loss: 3.0199347025399375
Validation loss: 3.058223431373337

Epoch: 5| Step: 5
Training loss: 3.7614396131344225
Validation loss: 3.065945413109366

Epoch: 5| Step: 6
Training loss: 3.5458797453290716
Validation loss: 3.064377069475517

Epoch: 5| Step: 7
Training loss: 2.642080504034846
Validation loss: 3.0637472750695736

Epoch: 5| Step: 8
Training loss: 3.3567358251402917
Validation loss: 3.0577368864461416

Epoch: 5| Step: 9
Training loss: 3.478864888943999
Validation loss: 3.056732945648602

Epoch: 5| Step: 10
Training loss: 3.5553519833090683
Validation loss: 3.057634050238245

Epoch: 45| Step: 0
Training loss: 3.0022266389914867
Validation loss: 3.053876016396792

Epoch: 5| Step: 1
Training loss: 3.631283674231703
Validation loss: 3.0549711812148757

Epoch: 5| Step: 2
Training loss: 3.0744828882614392
Validation loss: 3.0491570150820135

Epoch: 5| Step: 3
Training loss: 3.323148777108814
Validation loss: 3.0483138581342675

Epoch: 5| Step: 4
Training loss: 3.1059938382728114
Validation loss: 3.051795950702551

Epoch: 5| Step: 5
Training loss: 3.7866475068086696
Validation loss: 3.0494335907416605

Epoch: 5| Step: 6
Training loss: 4.413738623695978
Validation loss: 3.0561649847110237

Epoch: 5| Step: 7
Training loss: 3.033057548925304
Validation loss: 3.053930468203751

Epoch: 5| Step: 8
Training loss: 3.0900634996130134
Validation loss: 3.055419563077545

Epoch: 5| Step: 9
Training loss: 2.9003901317865743
Validation loss: 3.058369430722829

Epoch: 5| Step: 10
Training loss: 2.7664978891237424
Validation loss: 3.0556855503768574

Epoch: 46| Step: 0
Training loss: 3.443914082074626
Validation loss: 3.06044172910023

Epoch: 5| Step: 1
Training loss: 4.385838190088489
Validation loss: 3.051528923708076

Epoch: 5| Step: 2
Training loss: 3.3938015591408917
Validation loss: 3.0441002381071836

Epoch: 5| Step: 3
Training loss: 3.0162798709077965
Validation loss: 3.0460927223532677

Epoch: 5| Step: 4
Training loss: 4.156275469479644
Validation loss: 3.0453693263429975

Epoch: 5| Step: 5
Training loss: 3.1870647956095235
Validation loss: 3.047136832430821

Epoch: 5| Step: 6
Training loss: 3.1418369668662294
Validation loss: 3.043815791349362

Epoch: 5| Step: 7
Training loss: 2.508619517310147
Validation loss: 3.043748584457331

Epoch: 5| Step: 8
Training loss: 2.8356415565281474
Validation loss: 3.0397707893566905

Epoch: 5| Step: 9
Training loss: 2.6909200508775513
Validation loss: 3.039858719155559

Epoch: 5| Step: 10
Training loss: 3.3299184632270986
Validation loss: 3.040406026696309

Epoch: 47| Step: 0
Training loss: 3.2940195744204432
Validation loss: 3.039263306908754

Epoch: 5| Step: 1
Training loss: 2.9257294226259107
Validation loss: 3.039212477580307

Epoch: 5| Step: 2
Training loss: 3.3800945684080848
Validation loss: 3.0374525283810083

Epoch: 5| Step: 3
Training loss: 3.192042087822416
Validation loss: 3.0390347010982364

Epoch: 5| Step: 4
Training loss: 3.4004408270095166
Validation loss: 3.0390234191627292

Epoch: 5| Step: 5
Training loss: 3.6097657623802863
Validation loss: 3.045772600220056

Epoch: 5| Step: 6
Training loss: 3.120078369281218
Validation loss: 3.0449431372711597

Epoch: 5| Step: 7
Training loss: 3.5926813278149203
Validation loss: 3.0569659892904597

Epoch: 5| Step: 8
Training loss: 3.189468075401274
Validation loss: 3.069411778276576

Epoch: 5| Step: 9
Training loss: 3.9708663223887
Validation loss: 3.057205854444491

Epoch: 5| Step: 10
Training loss: 2.452382455200144
Validation loss: 3.0353890009048117

Epoch: 48| Step: 0
Training loss: 3.4931633799709285
Validation loss: 3.031017022609165

Epoch: 5| Step: 1
Training loss: 2.619113680183921
Validation loss: 3.032675866665131

Epoch: 5| Step: 2
Training loss: 3.455046934479763
Validation loss: 3.032135589129518

Epoch: 5| Step: 3
Training loss: 3.2872239725827708
Validation loss: 3.0355618586558584

Epoch: 5| Step: 4
Training loss: 3.0084730339547194
Validation loss: 3.0320025179039165

Epoch: 5| Step: 5
Training loss: 2.7925564121432607
Validation loss: 3.048065386331324

Epoch: 5| Step: 6
Training loss: 3.631711468944711
Validation loss: 3.04997486223163

Epoch: 5| Step: 7
Training loss: 2.813143508195961
Validation loss: 3.0454277191920758

Epoch: 5| Step: 8
Training loss: 3.480110740872737
Validation loss: 3.036170054362387

Epoch: 5| Step: 9
Training loss: 3.2465147257297144
Validation loss: 3.0282130503497435

Epoch: 5| Step: 10
Training loss: 4.477475697309268
Validation loss: 3.0326831433386316

Epoch: 49| Step: 0
Training loss: 4.254131328698775
Validation loss: 3.035096584277403

Epoch: 5| Step: 1
Training loss: 2.5163586417487886
Validation loss: 3.037398720572028

Epoch: 5| Step: 2
Training loss: 2.610541077430015
Validation loss: 3.0491152587802928

Epoch: 5| Step: 3
Training loss: 3.6414634164850033
Validation loss: 3.0577922831212794

Epoch: 5| Step: 4
Training loss: 3.709646928134927
Validation loss: 3.0636471208676936

Epoch: 5| Step: 5
Training loss: 2.978099836501361
Validation loss: 3.0615179853519496

Epoch: 5| Step: 6
Training loss: 3.4924482892521955
Validation loss: 3.045559937826324

Epoch: 5| Step: 7
Training loss: 2.8286491456302434
Validation loss: 3.0298820430733624

Epoch: 5| Step: 8
Training loss: 3.3492396559350874
Validation loss: 3.0308090462644603

Epoch: 5| Step: 9
Training loss: 3.510276693539978
Validation loss: 3.029385933065743

Epoch: 5| Step: 10
Training loss: 3.1607430081913597
Validation loss: 3.028372060290748

Epoch: 50| Step: 0
Training loss: 3.3354130138319236
Validation loss: 3.033218972318615

Epoch: 5| Step: 1
Training loss: 2.8721639494044036
Validation loss: 3.038773844344747

Epoch: 5| Step: 2
Training loss: 3.2497708166450403
Validation loss: 3.0347938960591896

Epoch: 5| Step: 3
Training loss: 3.6545917630550533
Validation loss: 3.0318171574535993

Epoch: 5| Step: 4
Training loss: 3.2185951862325517
Validation loss: 3.022958279827556

Epoch: 5| Step: 5
Training loss: 3.1136007300592645
Validation loss: 3.023826362769406

Epoch: 5| Step: 6
Training loss: 3.4211108604294225
Validation loss: 3.0215782432373444

Epoch: 5| Step: 7
Training loss: 4.234001340250516
Validation loss: 3.0255754903266756

Epoch: 5| Step: 8
Training loss: 3.4395030341353343
Validation loss: 3.025457604174726

Epoch: 5| Step: 9
Training loss: 2.7762369131357767
Validation loss: 3.02207908587239

Epoch: 5| Step: 10
Training loss: 2.7073658217611776
Validation loss: 3.0233145809622

Epoch: 51| Step: 0
Training loss: 3.2411439985837815
Validation loss: 3.022925338573807

Epoch: 5| Step: 1
Training loss: 3.3113139206335367
Validation loss: 3.025065842592185

Epoch: 5| Step: 2
Training loss: 3.537305248277936
Validation loss: 3.0263568121812163

Epoch: 5| Step: 3
Training loss: 3.2814258346674317
Validation loss: 3.021849899475341

Epoch: 5| Step: 4
Training loss: 2.702393625796645
Validation loss: 3.0217644879755086

Epoch: 5| Step: 5
Training loss: 3.4419109827352785
Validation loss: 3.023066123604088

Epoch: 5| Step: 6
Training loss: 3.5941451145737364
Validation loss: 3.024721148337095

Epoch: 5| Step: 7
Training loss: 3.0318272621046884
Validation loss: 3.030625683610131

Epoch: 5| Step: 8
Training loss: 3.7663110131893367
Validation loss: 3.0343938165971336

Epoch: 5| Step: 9
Training loss: 2.9996196187784943
Validation loss: 3.02015989701609

Epoch: 5| Step: 10
Training loss: 3.232517612111319
Validation loss: 3.012872945617508

Epoch: 52| Step: 0
Training loss: 3.466516824075943
Validation loss: 3.0116408902898013

Epoch: 5| Step: 1
Training loss: 2.8876061424134027
Validation loss: 3.0101561040589147

Epoch: 5| Step: 2
Training loss: 3.1690240083159993
Validation loss: 3.012650909817258

Epoch: 5| Step: 3
Training loss: 2.4749834580302132
Validation loss: 3.0111501269802217

Epoch: 5| Step: 4
Training loss: 3.5099772886753273
Validation loss: 3.011018349661742

Epoch: 5| Step: 5
Training loss: 3.6689923597928438
Validation loss: 3.009505423998493

Epoch: 5| Step: 6
Training loss: 2.9346975390994032
Validation loss: 3.009130360994733

Epoch: 5| Step: 7
Training loss: 3.57849985349686
Validation loss: 3.0080243418937425

Epoch: 5| Step: 8
Training loss: 3.0807487033580307
Validation loss: 3.009104829529068

Epoch: 5| Step: 9
Training loss: 3.463940559687739
Validation loss: 3.0076271915231922

Epoch: 5| Step: 10
Training loss: 3.7972256219925105
Validation loss: 3.00794860335875

Epoch: 53| Step: 0
Training loss: 3.4951205982363214
Validation loss: 3.0060085802858096

Epoch: 5| Step: 1
Training loss: 3.324100980902625
Validation loss: 3.006025011032489

Epoch: 5| Step: 2
Training loss: 3.276999927258833
Validation loss: 3.0034720366521754

Epoch: 5| Step: 3
Training loss: 3.2678553799364636
Validation loss: 3.0039911639385632

Epoch: 5| Step: 4
Training loss: 3.748524057486907
Validation loss: 3.002716302847802

Epoch: 5| Step: 5
Training loss: 3.025977987034132
Validation loss: 3.0028434433029587

Epoch: 5| Step: 6
Training loss: 3.282120943285384
Validation loss: 3.001499824860116

Epoch: 5| Step: 7
Training loss: 2.442868897800957
Validation loss: 3.0027688299702477

Epoch: 5| Step: 8
Training loss: 3.8645617269372985
Validation loss: 3.004761294709861

Epoch: 5| Step: 9
Training loss: 3.4766136594287076
Validation loss: 3.001010227335896

Epoch: 5| Step: 10
Training loss: 2.515741096803047
Validation loss: 3.003529804970809

Epoch: 54| Step: 0
Training loss: 3.425094970722955
Validation loss: 3.002585254241033

Epoch: 5| Step: 1
Training loss: 3.622913286157442
Validation loss: 3.0032558633448336

Epoch: 5| Step: 2
Training loss: 3.429871156680411
Validation loss: 3.004051195717991

Epoch: 5| Step: 3
Training loss: 3.7041959220037035
Validation loss: 3.0065603939247323

Epoch: 5| Step: 4
Training loss: 3.4538801239274974
Validation loss: 3.001337197739679

Epoch: 5| Step: 5
Training loss: 2.349946642330791
Validation loss: 3.0007177685490807

Epoch: 5| Step: 6
Training loss: 3.217596940104482
Validation loss: 2.9997289066815105

Epoch: 5| Step: 7
Training loss: 3.170910618191495
Validation loss: 2.9995923312217645

Epoch: 5| Step: 8
Training loss: 3.134632219464694
Validation loss: 2.9979397867550865

Epoch: 5| Step: 9
Training loss: 3.1272298867898316
Validation loss: 2.994101288319959

Epoch: 5| Step: 10
Training loss: 3.214317454832278
Validation loss: 2.997909790209958

Epoch: 55| Step: 0
Training loss: 3.5592751881685554
Validation loss: 2.996535727924796

Epoch: 5| Step: 1
Training loss: 3.5647412661790483
Validation loss: 2.9992630832826803

Epoch: 5| Step: 2
Training loss: 3.5982680075014692
Validation loss: 2.9967019088155022

Epoch: 5| Step: 3
Training loss: 3.114893630953282
Validation loss: 2.9977077525214684

Epoch: 5| Step: 4
Training loss: 3.9933813889105765
Validation loss: 2.998466277394131

Epoch: 5| Step: 5
Training loss: 2.8971767099702332
Validation loss: 2.998353155749665

Epoch: 5| Step: 6
Training loss: 2.551640084109718
Validation loss: 2.9941684845301184

Epoch: 5| Step: 7
Training loss: 3.0516751551306056
Validation loss: 2.9931358287491205

Epoch: 5| Step: 8
Training loss: 3.0848539743841887
Validation loss: 2.9950518100885053

Epoch: 5| Step: 9
Training loss: 2.676792371402229
Validation loss: 2.993533522888033

Epoch: 5| Step: 10
Training loss: 3.6488080051015648
Validation loss: 2.994254235423993

Epoch: 56| Step: 0
Training loss: 2.8464609156930067
Validation loss: 2.9921951681539136

Epoch: 5| Step: 1
Training loss: 3.661947782893174
Validation loss: 2.9930707695126264

Epoch: 5| Step: 2
Training loss: 2.827318782648724
Validation loss: 2.9947885586944047

Epoch: 5| Step: 3
Training loss: 3.702063557248738
Validation loss: 2.9924223610689773

Epoch: 5| Step: 4
Training loss: 3.210996604059895
Validation loss: 2.998032339914001

Epoch: 5| Step: 5
Training loss: 3.39530263549102
Validation loss: 2.9947404714580514

Epoch: 5| Step: 6
Training loss: 3.0789974931865918
Validation loss: 2.993910919125033

Epoch: 5| Step: 7
Training loss: 2.961637952583438
Validation loss: 2.9938474994266704

Epoch: 5| Step: 8
Training loss: 3.2232768992783396
Validation loss: 2.9928884696957883

Epoch: 5| Step: 9
Training loss: 3.553551930567807
Validation loss: 2.989955518057407

Epoch: 5| Step: 10
Training loss: 3.40219953299222
Validation loss: 2.988677449093539

Epoch: 57| Step: 0
Training loss: 3.8488041593501805
Validation loss: 2.9870299616336706

Epoch: 5| Step: 1
Training loss: 3.63378853760746
Validation loss: 2.9885196898166346

Epoch: 5| Step: 2
Training loss: 3.5877571891014615
Validation loss: 2.9890205731449067

Epoch: 5| Step: 3
Training loss: 2.728455069763566
Validation loss: 2.989203461336986

Epoch: 5| Step: 4
Training loss: 3.3726752009598306
Validation loss: 2.9901008433877685

Epoch: 5| Step: 5
Training loss: 3.189190435016125
Validation loss: 2.9887968194059393

Epoch: 5| Step: 6
Training loss: 3.255852052237566
Validation loss: 2.9898793509625214

Epoch: 5| Step: 7
Training loss: 3.0731597976622975
Validation loss: 2.988787197150336

Epoch: 5| Step: 8
Training loss: 2.9612933828220243
Validation loss: 2.990053358099539

Epoch: 5| Step: 9
Training loss: 2.9108807167661834
Validation loss: 2.9894941446066867

Epoch: 5| Step: 10
Training loss: 3.165045540769751
Validation loss: 2.992986710659025

Epoch: 58| Step: 0
Training loss: 3.535456489753817
Validation loss: 2.994237889919199

Epoch: 5| Step: 1
Training loss: 2.7450100101920736
Validation loss: 2.990723871327518

Epoch: 5| Step: 2
Training loss: 2.8999430815274
Validation loss: 2.9932121339507693

Epoch: 5| Step: 3
Training loss: 3.262280663611552
Validation loss: 2.991689711659165

Epoch: 5| Step: 4
Training loss: 3.5496952087227296
Validation loss: 2.9909796875128496

Epoch: 5| Step: 5
Training loss: 3.419101653764394
Validation loss: 2.989786547988473

Epoch: 5| Step: 6
Training loss: 3.6054916298451314
Validation loss: 2.9841101142901505

Epoch: 5| Step: 7
Training loss: 3.2610640365550467
Validation loss: 2.9864184060648173

Epoch: 5| Step: 8
Training loss: 3.3829303394963315
Validation loss: 2.986328658961529

Epoch: 5| Step: 9
Training loss: 3.247339480149992
Validation loss: 2.9831316328813826

Epoch: 5| Step: 10
Training loss: 2.7396533700865002
Validation loss: 2.981133352615103

Epoch: 59| Step: 0
Training loss: 3.579877266085302
Validation loss: 2.9803349434215156

Epoch: 5| Step: 1
Training loss: 3.457184627600384
Validation loss: 2.9802939217571804

Epoch: 5| Step: 2
Training loss: 3.125292649871187
Validation loss: 2.9835675493815357

Epoch: 5| Step: 3
Training loss: 3.71273676570018
Validation loss: 2.9834415311906453

Epoch: 5| Step: 4
Training loss: 3.5120193641319926
Validation loss: 2.9803443718988816

Epoch: 5| Step: 5
Training loss: 2.903165431403234
Validation loss: 2.978176795519303

Epoch: 5| Step: 6
Training loss: 3.2846449954251797
Validation loss: 2.9768742757721105

Epoch: 5| Step: 7
Training loss: 2.277712967061707
Validation loss: 2.9770135675278255

Epoch: 5| Step: 8
Training loss: 3.833070759833444
Validation loss: 2.976177862196295

Epoch: 5| Step: 9
Training loss: 3.3188073909416533
Validation loss: 2.97526306998081

Epoch: 5| Step: 10
Training loss: 2.2588257941241694
Validation loss: 2.974378885626737

Epoch: 60| Step: 0
Training loss: 3.27769524709246
Validation loss: 2.9756969325648304

Epoch: 5| Step: 1
Training loss: 2.895710857920843
Validation loss: 2.9747783703457444

Epoch: 5| Step: 2
Training loss: 3.471537526757073
Validation loss: 2.9756207821581495

Epoch: 5| Step: 3
Training loss: 2.845019214478087
Validation loss: 2.9755863476017024

Epoch: 5| Step: 4
Training loss: 3.582158642815441
Validation loss: 2.9764596498593012

Epoch: 5| Step: 5
Training loss: 3.1580290360085272
Validation loss: 2.9751490281858852

Epoch: 5| Step: 6
Training loss: 3.37287327198736
Validation loss: 2.9731814769512543

Epoch: 5| Step: 7
Training loss: 2.993541281796988
Validation loss: 2.9753132831745606

Epoch: 5| Step: 8
Training loss: 3.0537874500728055
Validation loss: 2.9740840692118815

Epoch: 5| Step: 9
Training loss: 3.814387995275706
Validation loss: 2.972698922472411

Epoch: 5| Step: 10
Training loss: 3.170998889211931
Validation loss: 2.9730557911416158

Epoch: 61| Step: 0
Training loss: 3.3091819987874094
Validation loss: 2.9720479956761197

Epoch: 5| Step: 1
Training loss: 3.4921091228795578
Validation loss: 2.971253475617704

Epoch: 5| Step: 2
Training loss: 3.1282787670104493
Validation loss: 2.9700061193759257

Epoch: 5| Step: 3
Training loss: 3.0735534180665374
Validation loss: 2.9724064242367207

Epoch: 5| Step: 4
Training loss: 2.250634210001484
Validation loss: 2.971330503248172

Epoch: 5| Step: 5
Training loss: 3.021957468921382
Validation loss: 2.970892241537863

Epoch: 5| Step: 6
Training loss: 3.415964116383746
Validation loss: 2.9689414937856116

Epoch: 5| Step: 7
Training loss: 2.9759661860647184
Validation loss: 2.969707052801899

Epoch: 5| Step: 8
Training loss: 3.643652578003547
Validation loss: 2.9707013610798794

Epoch: 5| Step: 9
Training loss: 3.602552430977839
Validation loss: 2.9679613206753994

Epoch: 5| Step: 10
Training loss: 3.59749043731797
Validation loss: 2.968528771266763

Epoch: 62| Step: 0
Training loss: 3.584163318293365
Validation loss: 2.9711030539039176

Epoch: 5| Step: 1
Training loss: 2.986909918188863
Validation loss: 2.970612628678058

Epoch: 5| Step: 2
Training loss: 2.8054690321452362
Validation loss: 2.970272621483092

Epoch: 5| Step: 3
Training loss: 3.415396772265195
Validation loss: 2.967556624737363

Epoch: 5| Step: 4
Training loss: 3.193549903528693
Validation loss: 2.968626749257622

Epoch: 5| Step: 5
Training loss: 3.349895640783185
Validation loss: 2.9701340355516015

Epoch: 5| Step: 6
Training loss: 3.3746310844831413
Validation loss: 2.9686722508316823

Epoch: 5| Step: 7
Training loss: 2.988155187802602
Validation loss: 2.966989409877051

Epoch: 5| Step: 8
Training loss: 3.2316203157885797
Validation loss: 2.967942801354974

Epoch: 5| Step: 9
Training loss: 3.3332700405469713
Validation loss: 2.9686301379356075

Epoch: 5| Step: 10
Training loss: 3.379421587327124
Validation loss: 2.9655165761586915

Epoch: 63| Step: 0
Training loss: 3.6373210535243015
Validation loss: 2.9632381746110403

Epoch: 5| Step: 1
Training loss: 3.196970465195835
Validation loss: 2.963810651999889

Epoch: 5| Step: 2
Training loss: 3.009950507127798
Validation loss: 2.961869404013417

Epoch: 5| Step: 3
Training loss: 2.8656211129165294
Validation loss: 2.961742570793686

Epoch: 5| Step: 4
Training loss: 3.1277487300821134
Validation loss: 2.9596712922054653

Epoch: 5| Step: 5
Training loss: 2.9692392046562657
Validation loss: 2.9618433785967713

Epoch: 5| Step: 6
Training loss: 3.3867421220899128
Validation loss: 2.9629916879185587

Epoch: 5| Step: 7
Training loss: 3.4492563524281032
Validation loss: 2.9613725498091554

Epoch: 5| Step: 8
Training loss: 3.442817597764164
Validation loss: 2.959906942212353

Epoch: 5| Step: 9
Training loss: 3.226469098602725
Validation loss: 2.9607206602820786

Epoch: 5| Step: 10
Training loss: 3.265796711618942
Validation loss: 2.9587796862563103

Epoch: 64| Step: 0
Training loss: 3.435305501798353
Validation loss: 2.9593763308101897

Epoch: 5| Step: 1
Training loss: 2.7072820726151026
Validation loss: 2.9595220004213707

Epoch: 5| Step: 2
Training loss: 3.2343372582339027
Validation loss: 2.9650754198078486

Epoch: 5| Step: 3
Training loss: 2.9602512178266296
Validation loss: 2.96430169231603

Epoch: 5| Step: 4
Training loss: 3.1926872082623827
Validation loss: 2.9689150856632507

Epoch: 5| Step: 5
Training loss: 3.5308073323378637
Validation loss: 2.9583097772095157

Epoch: 5| Step: 6
Training loss: 3.5661995400630486
Validation loss: 2.9570317615089143

Epoch: 5| Step: 7
Training loss: 3.633297992382766
Validation loss: 2.956623287394854

Epoch: 5| Step: 8
Training loss: 3.403541117747478
Validation loss: 2.957604880267925

Epoch: 5| Step: 9
Training loss: 2.9518869216681436
Validation loss: 2.9556356351920754

Epoch: 5| Step: 10
Training loss: 2.75460611743551
Validation loss: 2.9557786113504063

Epoch: 65| Step: 0
Training loss: 3.615953667554843
Validation loss: 2.9558648549594215

Epoch: 5| Step: 1
Training loss: 3.238655390828044
Validation loss: 2.956076363485695

Epoch: 5| Step: 2
Training loss: 2.8212075120991122
Validation loss: 2.9554236327812324

Epoch: 5| Step: 3
Training loss: 3.197624433421147
Validation loss: 2.9553992525265373

Epoch: 5| Step: 4
Training loss: 3.5906079696105317
Validation loss: 2.9549658175537563

Epoch: 5| Step: 5
Training loss: 2.726437278867002
Validation loss: 2.9551729930237425

Epoch: 5| Step: 6
Training loss: 3.277933824635788
Validation loss: 2.956497310417532

Epoch: 5| Step: 7
Training loss: 3.5845306229668767
Validation loss: 2.953652302645681

Epoch: 5| Step: 8
Training loss: 3.195384428152074
Validation loss: 2.9536817952139125

Epoch: 5| Step: 9
Training loss: 3.003063386251323
Validation loss: 2.956538705612814

Epoch: 5| Step: 10
Training loss: 3.1871120740409427
Validation loss: 2.9546177877092026

Epoch: 66| Step: 0
Training loss: 2.3749933744639287
Validation loss: 2.953651320119173

Epoch: 5| Step: 1
Training loss: 3.3441601082833916
Validation loss: 2.9532854329934413

Epoch: 5| Step: 2
Training loss: 2.8616482396125895
Validation loss: 2.9528451007672207

Epoch: 5| Step: 3
Training loss: 3.245082362559527
Validation loss: 2.952058660251963

Epoch: 5| Step: 4
Training loss: 3.3649814397744984
Validation loss: 2.951623801031895

Epoch: 5| Step: 5
Training loss: 3.165341116555256
Validation loss: 2.9512493954885684

Epoch: 5| Step: 6
Training loss: 3.3417209636687857
Validation loss: 2.951460999378603

Epoch: 5| Step: 7
Training loss: 4.014592494403157
Validation loss: 2.949400034011039

Epoch: 5| Step: 8
Training loss: 3.3852499270336667
Validation loss: 2.949129969306336

Epoch: 5| Step: 9
Training loss: 2.9066070009226395
Validation loss: 2.949567671559426

Epoch: 5| Step: 10
Training loss: 3.294821293894953
Validation loss: 2.9518974024084588

Epoch: 67| Step: 0
Training loss: 3.9902281609410744
Validation loss: 2.9518190399961863

Epoch: 5| Step: 1
Training loss: 3.3684563956476983
Validation loss: 2.957753642156044

Epoch: 5| Step: 2
Training loss: 2.9703138549095245
Validation loss: 2.9550615098780284

Epoch: 5| Step: 3
Training loss: 3.131539331039632
Validation loss: 2.9482294520598784

Epoch: 5| Step: 4
Training loss: 2.5151000808005377
Validation loss: 2.9474330743001924

Epoch: 5| Step: 5
Training loss: 3.1670555745949964
Validation loss: 2.9450986820529934

Epoch: 5| Step: 6
Training loss: 3.1273376876463534
Validation loss: 2.944423097882782

Epoch: 5| Step: 7
Training loss: 3.1363438516427538
Validation loss: 2.9445207931550583

Epoch: 5| Step: 8
Training loss: 3.738532270177195
Validation loss: 2.9459865444302595

Epoch: 5| Step: 9
Training loss: 3.041767710919087
Validation loss: 2.946143251996506

Epoch: 5| Step: 10
Training loss: 3.0990102726192768
Validation loss: 2.9441517877421473

Epoch: 68| Step: 0
Training loss: 3.44275388624994
Validation loss: 2.944751675554181

Epoch: 5| Step: 1
Training loss: 2.909229678940647
Validation loss: 2.9433961602199576

Epoch: 5| Step: 2
Training loss: 3.6662479219323454
Validation loss: 2.9435131741231175

Epoch: 5| Step: 3
Training loss: 3.1326997123069096
Validation loss: 2.9422405829835356

Epoch: 5| Step: 4
Training loss: 3.565159524395396
Validation loss: 2.9404464724851525

Epoch: 5| Step: 5
Training loss: 2.768060075554478
Validation loss: 2.942134496676396

Epoch: 5| Step: 6
Training loss: 3.021810562093718
Validation loss: 2.9416825403148166

Epoch: 5| Step: 7
Training loss: 3.6463252289772607
Validation loss: 2.9423612116356717

Epoch: 5| Step: 8
Training loss: 2.9077533402284765
Validation loss: 2.942748659587035

Epoch: 5| Step: 9
Training loss: 3.174686482486887
Validation loss: 2.942568168093424

Epoch: 5| Step: 10
Training loss: 3.081442657080763
Validation loss: 2.945530527104669

Epoch: 69| Step: 0
Training loss: 2.468961972178238
Validation loss: 2.952470874410537

Epoch: 5| Step: 1
Training loss: 3.5015003530765516
Validation loss: 2.9571788504623924

Epoch: 5| Step: 2
Training loss: 3.0267754002784
Validation loss: 2.9590676808916476

Epoch: 5| Step: 3
Training loss: 2.9035017904411093
Validation loss: 2.959746686242179

Epoch: 5| Step: 4
Training loss: 3.559914437026569
Validation loss: 2.9543200777425365

Epoch: 5| Step: 5
Training loss: 3.717468938640028
Validation loss: 2.9546675083964313

Epoch: 5| Step: 6
Training loss: 3.278625601336669
Validation loss: 2.962272635456594

Epoch: 5| Step: 7
Training loss: 3.639804207283463
Validation loss: 2.963297999881102

Epoch: 5| Step: 8
Training loss: 3.262835757930138
Validation loss: 2.9417818124368873

Epoch: 5| Step: 9
Training loss: 2.705511902551196
Validation loss: 2.939344219501098

Epoch: 5| Step: 10
Training loss: 3.2054786036742287
Validation loss: 2.937116215162483

Epoch: 70| Step: 0
Training loss: 2.802095538447198
Validation loss: 2.934978667628892

Epoch: 5| Step: 1
Training loss: 3.2704764655391587
Validation loss: 2.937745046769241

Epoch: 5| Step: 2
Training loss: 3.3829764311012025
Validation loss: 2.9392042302200165

Epoch: 5| Step: 3
Training loss: 3.1926488243311275
Validation loss: 2.9390026779390097

Epoch: 5| Step: 4
Training loss: 3.209184228265761
Validation loss: 2.938293479027618

Epoch: 5| Step: 5
Training loss: 2.867001893898771
Validation loss: 2.938891178928891

Epoch: 5| Step: 6
Training loss: 3.321804869118741
Validation loss: 2.9421499553269372

Epoch: 5| Step: 7
Training loss: 3.399811565562928
Validation loss: 2.935747512721222

Epoch: 5| Step: 8
Training loss: 3.2258192042129457
Validation loss: 2.935767772044364

Epoch: 5| Step: 9
Training loss: 3.405462331431064
Validation loss: 2.933466211601963

Epoch: 5| Step: 10
Training loss: 3.3255886388610776
Validation loss: 2.9348764164596575

Epoch: 71| Step: 0
Training loss: 2.870402433245934
Validation loss: 2.9438820288123004

Epoch: 5| Step: 1
Training loss: 2.891225061766739
Validation loss: 2.960035251946851

Epoch: 5| Step: 2
Training loss: 3.2706257618604897
Validation loss: 2.9814952788396094

Epoch: 5| Step: 3
Training loss: 2.8469513699686386
Validation loss: 2.987930089982491

Epoch: 5| Step: 4
Training loss: 3.8831052612215604
Validation loss: 2.984377750583801

Epoch: 5| Step: 5
Training loss: 3.7347051881517004
Validation loss: 2.938461204049208

Epoch: 5| Step: 6
Training loss: 3.2348812278393684
Validation loss: 2.9289046420578932

Epoch: 5| Step: 7
Training loss: 3.4892666952990066
Validation loss: 2.936266067216385

Epoch: 5| Step: 8
Training loss: 2.9940485731732056
Validation loss: 2.9509837212475114

Epoch: 5| Step: 9
Training loss: 3.1283571140020205
Validation loss: 2.970571333809836

Epoch: 5| Step: 10
Training loss: 2.9843064544954596
Validation loss: 2.9825733985303646

Epoch: 72| Step: 0
Training loss: 3.4767311998219577
Validation loss: 2.983332069420995

Epoch: 5| Step: 1
Training loss: 3.7157739864474233
Validation loss: 2.9772723476048193

Epoch: 5| Step: 2
Training loss: 2.6229952468392708
Validation loss: 2.9560373823279438

Epoch: 5| Step: 3
Training loss: 3.423892467218443
Validation loss: 2.9420276432101806

Epoch: 5| Step: 4
Training loss: 3.1889492554956056
Validation loss: 2.929796055686499

Epoch: 5| Step: 5
Training loss: 3.317810264630484
Validation loss: 2.9301967908304127

Epoch: 5| Step: 6
Training loss: 3.0499352370093322
Validation loss: 2.93154816026241

Epoch: 5| Step: 7
Training loss: 2.503933672821751
Validation loss: 2.933579700423711

Epoch: 5| Step: 8
Training loss: 3.7103826168210747
Validation loss: 2.9303070957645745

Epoch: 5| Step: 9
Training loss: 2.8621565833506013
Validation loss: 2.933915498954093

Epoch: 5| Step: 10
Training loss: 3.4445208896507977
Validation loss: 2.929730340678595

Epoch: 73| Step: 0
Training loss: 3.2927532736440717
Validation loss: 2.9328118927987163

Epoch: 5| Step: 1
Training loss: 2.3095453305334934
Validation loss: 2.929485622874896

Epoch: 5| Step: 2
Training loss: 2.8764807163694854
Validation loss: 2.9317493881879324

Epoch: 5| Step: 3
Training loss: 3.345321286086153
Validation loss: 2.9321277202246456

Epoch: 5| Step: 4
Training loss: 3.5760988054045186
Validation loss: 2.9312574968321514

Epoch: 5| Step: 5
Training loss: 2.6087929082100874
Validation loss: 2.924979310742145

Epoch: 5| Step: 6
Training loss: 3.3653074888676824
Validation loss: 2.9259715632337833

Epoch: 5| Step: 7
Training loss: 3.134256310844777
Validation loss: 2.929496434916899

Epoch: 5| Step: 8
Training loss: 3.4644638937071894
Validation loss: 2.934332023182788

Epoch: 5| Step: 9
Training loss: 3.370559172607323
Validation loss: 2.9541276752128343

Epoch: 5| Step: 10
Training loss: 3.880417021530847
Validation loss: 2.946993008091155

Epoch: 74| Step: 0
Training loss: 3.070257055349811
Validation loss: 2.935307290259606

Epoch: 5| Step: 1
Training loss: 3.503085275198493
Validation loss: 2.9286944809153845

Epoch: 5| Step: 2
Training loss: 3.3307164092288097
Validation loss: 2.9315530530892038

Epoch: 5| Step: 3
Training loss: 2.8458649871391324
Validation loss: 2.929917621065553

Epoch: 5| Step: 4
Training loss: 3.6212732297332004
Validation loss: 2.9326038780515615

Epoch: 5| Step: 5
Training loss: 3.667545184459724
Validation loss: 2.930890566994251

Epoch: 5| Step: 6
Training loss: 2.994176616813193
Validation loss: 2.9284500162146134

Epoch: 5| Step: 7
Training loss: 3.4533926053158503
Validation loss: 2.9231479914742504

Epoch: 5| Step: 8
Training loss: 3.0492700797746957
Validation loss: 2.9209346314176554

Epoch: 5| Step: 9
Training loss: 2.8203343102623606
Validation loss: 2.920382037716661

Epoch: 5| Step: 10
Training loss: 2.837840216990373
Validation loss: 2.91923560265179

Epoch: 75| Step: 0
Training loss: 2.913901480554706
Validation loss: 2.9175480795531366

Epoch: 5| Step: 1
Training loss: 2.919342738867353
Validation loss: 2.9158889556943794

Epoch: 5| Step: 2
Training loss: 3.7207023560530703
Validation loss: 2.9172661307369108

Epoch: 5| Step: 3
Training loss: 3.6028875532430202
Validation loss: 2.9195596390484306

Epoch: 5| Step: 4
Training loss: 3.3905257109418323
Validation loss: 2.9277171791358265

Epoch: 5| Step: 5
Training loss: 2.8822201169288233
Validation loss: 2.9255024957505604

Epoch: 5| Step: 6
Training loss: 3.224164833928745
Validation loss: 2.926477106649989

Epoch: 5| Step: 7
Training loss: 3.091667784684657
Validation loss: 2.9239227768203424

Epoch: 5| Step: 8
Training loss: 3.3834384400776987
Validation loss: 2.9178860279208596

Epoch: 5| Step: 9
Training loss: 2.9044354424324554
Validation loss: 2.9176639176314865

Epoch: 5| Step: 10
Training loss: 3.107383972358801
Validation loss: 2.9126069717307077

Epoch: 76| Step: 0
Training loss: 3.6196780106885216
Validation loss: 2.911129215991185

Epoch: 5| Step: 1
Training loss: 3.360651527769738
Validation loss: 2.91181679580353

Epoch: 5| Step: 2
Training loss: 2.6720770151608977
Validation loss: 2.9127554080718063

Epoch: 5| Step: 3
Training loss: 3.0975466464689085
Validation loss: 2.9104771952097526

Epoch: 5| Step: 4
Training loss: 2.7007133883645094
Validation loss: 2.9111304312664528

Epoch: 5| Step: 5
Training loss: 2.790574548143507
Validation loss: 2.9113041434824782

Epoch: 5| Step: 6
Training loss: 3.283542958133814
Validation loss: 2.9128444701181575

Epoch: 5| Step: 7
Training loss: 3.1933048721935244
Validation loss: 2.9121145918785034

Epoch: 5| Step: 8
Training loss: 3.1112591579573747
Validation loss: 2.9135866142504803

Epoch: 5| Step: 9
Training loss: 3.6507512665033053
Validation loss: 2.911042569079538

Epoch: 5| Step: 10
Training loss: 3.5803799249666914
Validation loss: 2.909552204864013

Epoch: 77| Step: 0
Training loss: 2.940407795034327
Validation loss: 2.9094270138132106

Epoch: 5| Step: 1
Training loss: 3.601297960475094
Validation loss: 2.909270161420333

Epoch: 5| Step: 2
Training loss: 3.368302941604407
Validation loss: 2.908617717727495

Epoch: 5| Step: 3
Training loss: 2.98503944230339
Validation loss: 2.9082894263382317

Epoch: 5| Step: 4
Training loss: 2.677006038831384
Validation loss: 2.906589394294242

Epoch: 5| Step: 5
Training loss: 3.4554326558583606
Validation loss: 2.904721584478751

Epoch: 5| Step: 6
Training loss: 3.4007149617810866
Validation loss: 2.905278679889607

Epoch: 5| Step: 7
Training loss: 3.0154341405053264
Validation loss: 2.905888164752766

Epoch: 5| Step: 8
Training loss: 3.0960549139628384
Validation loss: 2.907758147899277

Epoch: 5| Step: 9
Training loss: 3.1653054139122636
Validation loss: 2.903958582009091

Epoch: 5| Step: 10
Training loss: 3.348872601413868
Validation loss: 2.9069490503898407

Epoch: 78| Step: 0
Training loss: 3.0122073082777674
Validation loss: 2.904317427856652

Epoch: 5| Step: 1
Training loss: 3.30654126562733
Validation loss: 2.9058896274777104

Epoch: 5| Step: 2
Training loss: 3.0377647943815345
Validation loss: 2.9044125813446153

Epoch: 5| Step: 3
Training loss: 3.7243886561174584
Validation loss: 2.906989051370212

Epoch: 5| Step: 4
Training loss: 3.7006209393714
Validation loss: 2.9046239398071156

Epoch: 5| Step: 5
Training loss: 2.8571672097939387
Validation loss: 2.9075513491561593

Epoch: 5| Step: 6
Training loss: 3.124171185256595
Validation loss: 2.905176082285251

Epoch: 5| Step: 7
Training loss: 3.10150238670689
Validation loss: 2.904871376890507

Epoch: 5| Step: 8
Training loss: 3.1174857778461864
Validation loss: 2.902741310296293

Epoch: 5| Step: 9
Training loss: 2.761205385399443
Validation loss: 2.9031114924336148

Epoch: 5| Step: 10
Training loss: 3.2352371909493223
Validation loss: 2.9057650726637734

Epoch: 79| Step: 0
Training loss: 3.6621190104039907
Validation loss: 2.899368890513448

Epoch: 5| Step: 1
Training loss: 3.003469050901254
Validation loss: 2.9001649940818774

Epoch: 5| Step: 2
Training loss: 2.3654095610829424
Validation loss: 2.8996753393851575

Epoch: 5| Step: 3
Training loss: 3.5234186886710286
Validation loss: 2.899256302321846

Epoch: 5| Step: 4
Training loss: 3.288756585109125
Validation loss: 2.897446203076663

Epoch: 5| Step: 5
Training loss: 3.174136403297483
Validation loss: 2.8968191238786094

Epoch: 5| Step: 6
Training loss: 3.678479168352649
Validation loss: 2.8969431323619

Epoch: 5| Step: 7
Training loss: 3.306053654802447
Validation loss: 2.8977556482753326

Epoch: 5| Step: 8
Training loss: 2.7132557567625697
Validation loss: 2.8965249825064263

Epoch: 5| Step: 9
Training loss: 2.9067546447365085
Validation loss: 2.894854054153637

Epoch: 5| Step: 10
Training loss: 3.211047985097335
Validation loss: 2.896174461142347

Epoch: 80| Step: 0
Training loss: 3.723496429322806
Validation loss: 2.895678639937093

Epoch: 5| Step: 1
Training loss: 2.8015637867419834
Validation loss: 2.8975828800488643

Epoch: 5| Step: 2
Training loss: 3.084147955703633
Validation loss: 2.9003629218320754

Epoch: 5| Step: 3
Training loss: 3.2986376059734104
Validation loss: 2.9045103902319056

Epoch: 5| Step: 4
Training loss: 2.3682981598631603
Validation loss: 2.9118234500593236

Epoch: 5| Step: 5
Training loss: 3.445473180644075
Validation loss: 2.9035396439341716

Epoch: 5| Step: 6
Training loss: 3.0245885900260907
Validation loss: 2.892487979828169

Epoch: 5| Step: 7
Training loss: 2.9137186865185667
Validation loss: 2.893405518649461

Epoch: 5| Step: 8
Training loss: 3.667675847555465
Validation loss: 2.8932755609999985

Epoch: 5| Step: 9
Training loss: 3.3823797288307063
Validation loss: 2.892922609486262

Epoch: 5| Step: 10
Training loss: 3.1346220274742778
Validation loss: 2.891505762228736

Epoch: 81| Step: 0
Training loss: 2.9383660521031656
Validation loss: 2.8925332574996356

Epoch: 5| Step: 1
Training loss: 3.827986235925689
Validation loss: 2.8910845931333142

Epoch: 5| Step: 2
Training loss: 3.2813941560595667
Validation loss: 2.891451616391802

Epoch: 5| Step: 3
Training loss: 3.4633386691079573
Validation loss: 2.8890691231109877

Epoch: 5| Step: 4
Training loss: 3.3989756892458036
Validation loss: 2.8888902118586226

Epoch: 5| Step: 5
Training loss: 3.191263706941376
Validation loss: 2.8896864041532573

Epoch: 5| Step: 6
Training loss: 2.8036540473100975
Validation loss: 2.8890800402645076

Epoch: 5| Step: 7
Training loss: 2.8453148529193832
Validation loss: 2.8870334794753214

Epoch: 5| Step: 8
Training loss: 2.858533057824552
Validation loss: 2.888967089255886

Epoch: 5| Step: 9
Training loss: 2.860168346972335
Validation loss: 2.8873248941375254

Epoch: 5| Step: 10
Training loss: 3.394062040536349
Validation loss: 2.887250057845982

Epoch: 82| Step: 0
Training loss: 3.5672952603118184
Validation loss: 2.889133265122944

Epoch: 5| Step: 1
Training loss: 2.961187427611652
Validation loss: 2.8881386770645467

Epoch: 5| Step: 2
Training loss: 2.6195430346917012
Validation loss: 2.8908864575700712

Epoch: 5| Step: 3
Training loss: 3.040625163094966
Validation loss: 2.894926654424189

Epoch: 5| Step: 4
Training loss: 3.82456748860764
Validation loss: 2.902757024660572

Epoch: 5| Step: 5
Training loss: 2.7010539505621978
Validation loss: 2.905033646964209

Epoch: 5| Step: 6
Training loss: 3.35955313276812
Validation loss: 2.8904431162524316

Epoch: 5| Step: 7
Training loss: 3.307079847065711
Validation loss: 2.8875139367247966

Epoch: 5| Step: 8
Training loss: 3.0600362715721854
Validation loss: 2.8863225977530225

Epoch: 5| Step: 9
Training loss: 3.299661913806074
Validation loss: 2.8853941394149683

Epoch: 5| Step: 10
Training loss: 3.016345002393114
Validation loss: 2.886365943514499

Epoch: 83| Step: 0
Training loss: 2.8724655922205944
Validation loss: 2.890645064728023

Epoch: 5| Step: 1
Training loss: 3.602805760873869
Validation loss: 2.8895301543594556

Epoch: 5| Step: 2
Training loss: 3.3261128105075835
Validation loss: 2.888343886099395

Epoch: 5| Step: 3
Training loss: 2.6903919362709874
Validation loss: 2.8889824002431506

Epoch: 5| Step: 4
Training loss: 3.4515124392041465
Validation loss: 2.8910208207423302

Epoch: 5| Step: 5
Training loss: 3.727482392277824
Validation loss: 2.8918782841687043

Epoch: 5| Step: 6
Training loss: 2.8624907647529447
Validation loss: 2.8899709975515404

Epoch: 5| Step: 7
Training loss: 2.960355273654235
Validation loss: 2.890291667810369

Epoch: 5| Step: 8
Training loss: 2.859268936941708
Validation loss: 2.8883603098610107

Epoch: 5| Step: 9
Training loss: 3.249070694914809
Validation loss: 2.8889922022850105

Epoch: 5| Step: 10
Training loss: 3.2898720947725884
Validation loss: 2.8871587518178714

Epoch: 84| Step: 0
Training loss: 3.45937641147216
Validation loss: 2.888024675509161

Epoch: 5| Step: 1
Training loss: 3.3107253305054307
Validation loss: 2.886667160902436

Epoch: 5| Step: 2
Training loss: 3.126697231975673
Validation loss: 2.8852310722181578

Epoch: 5| Step: 3
Training loss: 3.0141482517508518
Validation loss: 2.883373388348511

Epoch: 5| Step: 4
Training loss: 3.0736545689720556
Validation loss: 2.8839260711465333

Epoch: 5| Step: 5
Training loss: 3.3000223043439387
Validation loss: 2.881765355110631

Epoch: 5| Step: 6
Training loss: 3.179945726711244
Validation loss: 2.8790281859375093

Epoch: 5| Step: 7
Training loss: 2.991645146312898
Validation loss: 2.8801554155957882

Epoch: 5| Step: 8
Training loss: 3.492332097074579
Validation loss: 2.8799853969688565

Epoch: 5| Step: 9
Training loss: 3.1836970961945146
Validation loss: 2.8790055834683828

Epoch: 5| Step: 10
Training loss: 2.707442347369756
Validation loss: 2.8804337940417777

Epoch: 85| Step: 0
Training loss: 3.4905401180264004
Validation loss: 2.8780994917550533

Epoch: 5| Step: 1
Training loss: 3.718668319702693
Validation loss: 2.8772179322054328

Epoch: 5| Step: 2
Training loss: 2.8567629697836927
Validation loss: 2.87995185474832

Epoch: 5| Step: 3
Training loss: 3.007506991637515
Validation loss: 2.881455801266474

Epoch: 5| Step: 4
Training loss: 2.4428065320240098
Validation loss: 2.8800934093263586

Epoch: 5| Step: 5
Training loss: 3.4533794878915547
Validation loss: 2.8771509966946236

Epoch: 5| Step: 6
Training loss: 3.2215254585696513
Validation loss: 2.8798525815154057

Epoch: 5| Step: 7
Training loss: 3.107264430231177
Validation loss: 2.8812755052664056

Epoch: 5| Step: 8
Training loss: 3.1674869043912
Validation loss: 2.8765788208413925

Epoch: 5| Step: 9
Training loss: 3.285227952825552
Validation loss: 2.8781227693901714

Epoch: 5| Step: 10
Training loss: 2.923365737955825
Validation loss: 2.8737009242488334

Epoch: 86| Step: 0
Training loss: 2.765397660561464
Validation loss: 2.873249289560193

Epoch: 5| Step: 1
Training loss: 2.840097450142539
Validation loss: 2.872843712649745

Epoch: 5| Step: 2
Training loss: 2.427962988280698
Validation loss: 2.870565564043437

Epoch: 5| Step: 3
Training loss: 2.9931941716980717
Validation loss: 2.873370616178837

Epoch: 5| Step: 4
Training loss: 3.669650698677624
Validation loss: 2.8725350983332816

Epoch: 5| Step: 5
Training loss: 3.3140249520872107
Validation loss: 2.8699326034023773

Epoch: 5| Step: 6
Training loss: 3.7370103292018775
Validation loss: 2.8698153040990233

Epoch: 5| Step: 7
Training loss: 3.7757033343398834
Validation loss: 2.871069939448827

Epoch: 5| Step: 8
Training loss: 2.652797654517394
Validation loss: 2.8726870438339147

Epoch: 5| Step: 9
Training loss: 2.7175849084302017
Validation loss: 2.8699182877326486

Epoch: 5| Step: 10
Training loss: 3.6557897294343125
Validation loss: 2.870203749747646

Epoch: 87| Step: 0
Training loss: 2.996563532677239
Validation loss: 2.8720379774960856

Epoch: 5| Step: 1
Training loss: 2.65220082140899
Validation loss: 2.8819334077794663

Epoch: 5| Step: 2
Training loss: 3.8189918404027767
Validation loss: 2.8749388464888144

Epoch: 5| Step: 3
Training loss: 2.4974834173528344
Validation loss: 2.869122702677189

Epoch: 5| Step: 4
Training loss: 3.242178381481906
Validation loss: 2.8678612235053453

Epoch: 5| Step: 5
Training loss: 2.9424711328741786
Validation loss: 2.866872951674299

Epoch: 5| Step: 6
Training loss: 3.4626616237115497
Validation loss: 2.8656816440243893

Epoch: 5| Step: 7
Training loss: 3.526723340329671
Validation loss: 2.8681381771718906

Epoch: 5| Step: 8
Training loss: 3.4104844117859074
Validation loss: 2.8643728324684656

Epoch: 5| Step: 9
Training loss: 3.113030360126815
Validation loss: 2.865622862791811

Epoch: 5| Step: 10
Training loss: 2.843119960200987
Validation loss: 2.8639000405292196

Epoch: 88| Step: 0
Training loss: 2.8386898083774557
Validation loss: 2.8629920765435948

Epoch: 5| Step: 1
Training loss: 3.234018352213483
Validation loss: 2.8671741541727105

Epoch: 5| Step: 2
Training loss: 3.2682933947975874
Validation loss: 2.87091396322206

Epoch: 5| Step: 3
Training loss: 4.157594162269767
Validation loss: 2.873498496894273

Epoch: 5| Step: 4
Training loss: 3.1846348470251216
Validation loss: 2.872464765776728

Epoch: 5| Step: 5
Training loss: 3.025583535650796
Validation loss: 2.87323886812651

Epoch: 5| Step: 6
Training loss: 3.320305319385618
Validation loss: 2.8672281996507403

Epoch: 5| Step: 7
Training loss: 2.1848040725541544
Validation loss: 2.8644663021460457

Epoch: 5| Step: 8
Training loss: 3.2029552879964305
Validation loss: 2.867085016473368

Epoch: 5| Step: 9
Training loss: 2.6012897520313722
Validation loss: 2.863492389170011

Epoch: 5| Step: 10
Training loss: 3.3547474770943344
Validation loss: 2.8652496070182085

Epoch: 89| Step: 0
Training loss: 3.1812854097865078
Validation loss: 2.865946557024286

Epoch: 5| Step: 1
Training loss: 2.9101085684537593
Validation loss: 2.8628623976245002

Epoch: 5| Step: 2
Training loss: 3.170378834804566
Validation loss: 2.8600081279612466

Epoch: 5| Step: 3
Training loss: 3.2172406555794186
Validation loss: 2.8606308948798156

Epoch: 5| Step: 4
Training loss: 3.152769379084114
Validation loss: 2.8615150917793137

Epoch: 5| Step: 5
Training loss: 3.0230430325982653
Validation loss: 2.860248051569913

Epoch: 5| Step: 6
Training loss: 3.4619037321337407
Validation loss: 2.8582979026494444

Epoch: 5| Step: 7
Training loss: 3.4550873716930393
Validation loss: 2.8591621911921346

Epoch: 5| Step: 8
Training loss: 3.523633050672765
Validation loss: 2.8599968407812324

Epoch: 5| Step: 9
Training loss: 2.9641250724401558
Validation loss: 2.862819557463637

Epoch: 5| Step: 10
Training loss: 2.388271095421504
Validation loss: 2.861561400642955

Epoch: 90| Step: 0
Training loss: 2.7755979048487256
Validation loss: 2.860727579434186

Epoch: 5| Step: 1
Training loss: 2.8342416279798597
Validation loss: 2.8669574183972952

Epoch: 5| Step: 2
Training loss: 3.6547052755653384
Validation loss: 2.864542691267813

Epoch: 5| Step: 3
Training loss: 3.3802374714603047
Validation loss: 2.858964377383652

Epoch: 5| Step: 4
Training loss: 2.8354725522250055
Validation loss: 2.857407618669258

Epoch: 5| Step: 5
Training loss: 2.7435090013470727
Validation loss: 2.856443490587945

Epoch: 5| Step: 6
Training loss: 3.272585081855162
Validation loss: 2.856291526466891

Epoch: 5| Step: 7
Training loss: 3.7112358535491845
Validation loss: 2.852575199897154

Epoch: 5| Step: 8
Training loss: 2.943033404104646
Validation loss: 2.854588163932956

Epoch: 5| Step: 9
Training loss: 3.3217908014229267
Validation loss: 2.852479514332386

Epoch: 5| Step: 10
Training loss: 3.003196602720962
Validation loss: 2.8535881836494403

Epoch: 91| Step: 0
Training loss: 2.7626525940328004
Validation loss: 2.854091671745153

Epoch: 5| Step: 1
Training loss: 3.4968116406793524
Validation loss: 2.851010584129125

Epoch: 5| Step: 2
Training loss: 4.106430797573931
Validation loss: 2.85277597564751

Epoch: 5| Step: 3
Training loss: 2.6068689795941067
Validation loss: 2.8522795248399464

Epoch: 5| Step: 4
Training loss: 2.888775372924036
Validation loss: 2.849833502275034

Epoch: 5| Step: 5
Training loss: 3.1266319591274114
Validation loss: 2.8514059224099704

Epoch: 5| Step: 6
Training loss: 3.3986434698718746
Validation loss: 2.85533421325467

Epoch: 5| Step: 7
Training loss: 3.2131138315323917
Validation loss: 2.8556131808647183

Epoch: 5| Step: 8
Training loss: 2.842782159789951
Validation loss: 2.8568895039575755

Epoch: 5| Step: 9
Training loss: 2.668318584511776
Validation loss: 2.8595707332870934

Epoch: 5| Step: 10
Training loss: 3.2632446374681816
Validation loss: 2.8585648155731693

Epoch: 92| Step: 0
Training loss: 3.668657167160247
Validation loss: 2.852958936254243

Epoch: 5| Step: 1
Training loss: 3.2397225075088114
Validation loss: 2.851949116087688

Epoch: 5| Step: 2
Training loss: 3.1162198125461207
Validation loss: 2.8522931731481056

Epoch: 5| Step: 3
Training loss: 3.3358148556751126
Validation loss: 2.855917505344604

Epoch: 5| Step: 4
Training loss: 3.1038927985782494
Validation loss: 2.8519942786792125

Epoch: 5| Step: 5
Training loss: 2.666695912518664
Validation loss: 2.8523781632931415

Epoch: 5| Step: 6
Training loss: 3.6917375688367455
Validation loss: 2.8589521965503217

Epoch: 5| Step: 7
Training loss: 3.102120683153562
Validation loss: 2.8505015549513772

Epoch: 5| Step: 8
Training loss: 3.207086857674874
Validation loss: 2.8485623172720693

Epoch: 5| Step: 9
Training loss: 2.893686683571783
Validation loss: 2.851133749062136

Epoch: 5| Step: 10
Training loss: 2.1773084557570686
Validation loss: 2.8476012145673426

Epoch: 93| Step: 0
Training loss: 2.4866441644190775
Validation loss: 2.8490589883914708

Epoch: 5| Step: 1
Training loss: 3.0570203063909345
Validation loss: 2.8462598322849213

Epoch: 5| Step: 2
Training loss: 2.877259237522693
Validation loss: 2.847195002314601

Epoch: 5| Step: 3
Training loss: 3.3490834704681647
Validation loss: 2.847742774799294

Epoch: 5| Step: 4
Training loss: 3.0083486103997883
Validation loss: 2.845197052290579

Epoch: 5| Step: 5
Training loss: 3.4534075176955827
Validation loss: 2.8476795721275714

Epoch: 5| Step: 6
Training loss: 3.6246556085564388
Validation loss: 2.8484926599987244

Epoch: 5| Step: 7
Training loss: 3.1280688666643397
Validation loss: 2.849118230133413

Epoch: 5| Step: 8
Training loss: 3.1056901576929437
Validation loss: 2.851020507729189

Epoch: 5| Step: 9
Training loss: 3.1271412951853823
Validation loss: 2.851424494634896

Epoch: 5| Step: 10
Training loss: 3.26360904945889
Validation loss: 2.847795816211912

Epoch: 94| Step: 0
Training loss: 2.9867486751173806
Validation loss: 2.8540957587044673

Epoch: 5| Step: 1
Training loss: 2.822799220345827
Validation loss: 2.8532338403584863

Epoch: 5| Step: 2
Training loss: 2.6652421325275495
Validation loss: 2.84969354286896

Epoch: 5| Step: 3
Training loss: 3.659228554392476
Validation loss: 2.851171033608172

Epoch: 5| Step: 4
Training loss: 3.375665245896867
Validation loss: 2.860024635561079

Epoch: 5| Step: 5
Training loss: 3.741085646843253
Validation loss: 2.859352969304351

Epoch: 5| Step: 6
Training loss: 3.036065906708939
Validation loss: 2.8584288541293916

Epoch: 5| Step: 7
Training loss: 3.3921023196046844
Validation loss: 2.8563505320411706

Epoch: 5| Step: 8
Training loss: 2.7809987329715393
Validation loss: 2.8455276954880038

Epoch: 5| Step: 9
Training loss: 3.4292573072490913
Validation loss: 2.8422053181818208

Epoch: 5| Step: 10
Training loss: 2.2510856552333287
Validation loss: 2.839802261570585

Epoch: 95| Step: 0
Training loss: 3.0013078381972123
Validation loss: 2.839100576744744

Epoch: 5| Step: 1
Training loss: 3.300785728316119
Validation loss: 2.839512827749692

Epoch: 5| Step: 2
Training loss: 3.113426750736582
Validation loss: 2.8418071898166875

Epoch: 5| Step: 3
Training loss: 3.2023242973114647
Validation loss: 2.8400710011965598

Epoch: 5| Step: 4
Training loss: 2.6445743438950973
Validation loss: 2.8386074925933857

Epoch: 5| Step: 5
Training loss: 2.4939567958206825
Validation loss: 2.837204243942408

Epoch: 5| Step: 6
Training loss: 3.6730338357955437
Validation loss: 2.8389590407059275

Epoch: 5| Step: 7
Training loss: 2.829836669899538
Validation loss: 2.838315705970041

Epoch: 5| Step: 8
Training loss: 3.1303940568223627
Validation loss: 2.837153366518202

Epoch: 5| Step: 9
Training loss: 3.6864949812643455
Validation loss: 2.8387982261085734

Epoch: 5| Step: 10
Training loss: 3.2453234845463625
Validation loss: 2.8358490483575265

Epoch: 96| Step: 0
Training loss: 3.432427843061985
Validation loss: 2.836081006457655

Epoch: 5| Step: 1
Training loss: 3.2017047990086653
Validation loss: 2.8370498107113566

Epoch: 5| Step: 2
Training loss: 2.328969712593999
Validation loss: 2.834517416707012

Epoch: 5| Step: 3
Training loss: 3.304927303189908
Validation loss: 2.8349192654774753

Epoch: 5| Step: 4
Training loss: 2.5114994694934962
Validation loss: 2.8343296087956804

Epoch: 5| Step: 5
Training loss: 2.753756211975544
Validation loss: 2.834108765612039

Epoch: 5| Step: 6
Training loss: 3.070232982430853
Validation loss: 2.83405718131749

Epoch: 5| Step: 7
Training loss: 3.5853832207109284
Validation loss: 2.831874037902702

Epoch: 5| Step: 8
Training loss: 3.145688051485834
Validation loss: 2.835023901044084

Epoch: 5| Step: 9
Training loss: 3.524300277196547
Validation loss: 2.8330212613639674

Epoch: 5| Step: 10
Training loss: 3.397792851484134
Validation loss: 2.8326049033595933

Epoch: 97| Step: 0
Training loss: 3.6736739276850803
Validation loss: 2.8331572250512993

Epoch: 5| Step: 1
Training loss: 2.8431680943310527
Validation loss: 2.8333087922492597

Epoch: 5| Step: 2
Training loss: 3.0117466154677173
Validation loss: 2.83276311202161

Epoch: 5| Step: 3
Training loss: 3.2345663557713102
Validation loss: 2.8346820727052107

Epoch: 5| Step: 4
Training loss: 2.5927058496663844
Validation loss: 2.832044999510387

Epoch: 5| Step: 5
Training loss: 3.5319340136229775
Validation loss: 2.832738074278438

Epoch: 5| Step: 6
Training loss: 2.982371351692229
Validation loss: 2.830269900703911

Epoch: 5| Step: 7
Training loss: 2.7222880000862912
Validation loss: 2.830013951687114

Epoch: 5| Step: 8
Training loss: 2.991021868004373
Validation loss: 2.832063810043234

Epoch: 5| Step: 9
Training loss: 2.7637749642599463
Validation loss: 2.8303887003002726

Epoch: 5| Step: 10
Training loss: 3.966738453918029
Validation loss: 2.83907275590753

Epoch: 98| Step: 0
Training loss: 2.877025885610376
Validation loss: 2.84316384739383

Epoch: 5| Step: 1
Training loss: 2.890300010763879
Validation loss: 2.8374899342842523

Epoch: 5| Step: 2
Training loss: 3.579173904666236
Validation loss: 2.8453154169479573

Epoch: 5| Step: 3
Training loss: 3.0814539534288112
Validation loss: 2.8618018739530604

Epoch: 5| Step: 4
Training loss: 3.345938991020072
Validation loss: 2.8741280409150125

Epoch: 5| Step: 5
Training loss: 3.616940978117361
Validation loss: 2.831834623521539

Epoch: 5| Step: 6
Training loss: 2.932331814443092
Validation loss: 2.8325570730306917

Epoch: 5| Step: 7
Training loss: 3.0831913958347785
Validation loss: 2.8369713872763964

Epoch: 5| Step: 8
Training loss: 3.405025997202661
Validation loss: 2.8390740995491663

Epoch: 5| Step: 9
Training loss: 2.6856447070248524
Validation loss: 2.8479492652528213

Epoch: 5| Step: 10
Training loss: 2.928583776467905
Validation loss: 2.8728360150525347

Epoch: 99| Step: 0
Training loss: 3.854745412452581
Validation loss: 2.8769911281995486

Epoch: 5| Step: 1
Training loss: 2.8835392064444934
Validation loss: 2.877229570603025

Epoch: 5| Step: 2
Training loss: 3.720922780999773
Validation loss: 2.8525897481932976

Epoch: 5| Step: 3
Training loss: 3.596643891520214
Validation loss: 2.8428849630186646

Epoch: 5| Step: 4
Training loss: 2.2024886923596054
Validation loss: 2.8320845856699

Epoch: 5| Step: 5
Training loss: 2.789593985216479
Validation loss: 2.8304468510289373

Epoch: 5| Step: 6
Training loss: 2.7920174639245836
Validation loss: 2.8295836815068016

Epoch: 5| Step: 7
Training loss: 2.555834498132076
Validation loss: 2.8305442994141847

Epoch: 5| Step: 8
Training loss: 3.5262975482513825
Validation loss: 2.8298500187814963

Epoch: 5| Step: 9
Training loss: 3.2898803563958694
Validation loss: 2.828811724392755

Epoch: 5| Step: 10
Training loss: 3.0129873174431454
Validation loss: 2.8297948798367623

Epoch: 100| Step: 0
Training loss: 3.119515450827134
Validation loss: 2.8352678928191484

Epoch: 5| Step: 1
Training loss: 3.3985489048730013
Validation loss: 2.8378881660494075

Epoch: 5| Step: 2
Training loss: 2.8642826176794127
Validation loss: 2.8505457961591327

Epoch: 5| Step: 3
Training loss: 2.8056067870176276
Validation loss: 2.8580993320734587

Epoch: 5| Step: 4
Training loss: 2.6976168747013243
Validation loss: 2.8305743234051057

Epoch: 5| Step: 5
Training loss: 3.6457353996565742
Validation loss: 2.822310435989688

Epoch: 5| Step: 6
Training loss: 2.8912841045447886
Validation loss: 2.820585566974164

Epoch: 5| Step: 7
Training loss: 3.365646115717622
Validation loss: 2.826922226926499

Epoch: 5| Step: 8
Training loss: 3.3705628508573446
Validation loss: 2.8271709494729045

Epoch: 5| Step: 9
Training loss: 3.2016765017526363
Validation loss: 2.8343492263479746

Epoch: 5| Step: 10
Training loss: 3.0037771923979024
Validation loss: 2.8342229856711927

Testing loss: 3.024840763899634
