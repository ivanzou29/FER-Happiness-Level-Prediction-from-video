Epoch: 1| Step: 0
Training loss: 4.429120063781738
Validation loss: 5.260426613592332

Epoch: 6| Step: 1
Training loss: 5.771063804626465
Validation loss: 5.251821215434741

Epoch: 6| Step: 2
Training loss: 5.244894981384277
Validation loss: 5.24447347271827

Epoch: 6| Step: 3
Training loss: 5.15030574798584
Validation loss: 5.237359554536881

Epoch: 6| Step: 4
Training loss: 5.414376735687256
Validation loss: 5.230550432717928

Epoch: 6| Step: 5
Training loss: 5.085386276245117
Validation loss: 5.223591394321893

Epoch: 6| Step: 6
Training loss: 4.1418256759643555
Validation loss: 5.2166203888513705

Epoch: 6| Step: 7
Training loss: 5.255077362060547
Validation loss: 5.208761184446273

Epoch: 6| Step: 8
Training loss: 5.494991302490234
Validation loss: 5.2005750543327744

Epoch: 6| Step: 9
Training loss: 3.7876193523406982
Validation loss: 5.191502832597302

Epoch: 6| Step: 10
Training loss: 5.292757034301758
Validation loss: 5.181813050341862

Epoch: 6| Step: 11
Training loss: 4.210869312286377
Validation loss: 5.1709694606001655

Epoch: 6| Step: 12
Training loss: 6.2076873779296875
Validation loss: 5.159211738135225

Epoch: 6| Step: 13
Training loss: 4.2698798179626465
Validation loss: 5.146334258458948

Epoch: 2| Step: 0
Training loss: 3.871631622314453
Validation loss: 5.132436711301086

Epoch: 6| Step: 1
Training loss: 3.754204273223877
Validation loss: 5.117329248818018

Epoch: 6| Step: 2
Training loss: 5.9329400062561035
Validation loss: 5.100944734388782

Epoch: 6| Step: 3
Training loss: 5.274702072143555
Validation loss: 5.083731512869558

Epoch: 6| Step: 4
Training loss: 4.05429744720459
Validation loss: 5.064322005036057

Epoch: 6| Step: 5
Training loss: 3.4202423095703125
Validation loss: 5.044206501335226

Epoch: 6| Step: 6
Training loss: 4.670096397399902
Validation loss: 5.023384027583624

Epoch: 6| Step: 7
Training loss: 5.14697265625
Validation loss: 5.000593149533835

Epoch: 6| Step: 8
Training loss: 5.685141086578369
Validation loss: 4.976327808954382

Epoch: 6| Step: 9
Training loss: 4.090793609619141
Validation loss: 4.95152247336603

Epoch: 6| Step: 10
Training loss: 5.75557804107666
Validation loss: 4.9259906379125455

Epoch: 6| Step: 11
Training loss: 5.695209980010986
Validation loss: 4.899032408191312

Epoch: 6| Step: 12
Training loss: 5.028814315795898
Validation loss: 4.870672579734556

Epoch: 6| Step: 13
Training loss: 4.742597579956055
Validation loss: 4.842425407901887

Epoch: 3| Step: 0
Training loss: 4.607470512390137
Validation loss: 4.812642476891958

Epoch: 6| Step: 1
Training loss: 4.403596878051758
Validation loss: 4.7832395594607116

Epoch: 6| Step: 2
Training loss: 5.079928398132324
Validation loss: 4.753413343942293

Epoch: 6| Step: 3
Training loss: 3.6397922039031982
Validation loss: 4.724648275683003

Epoch: 6| Step: 4
Training loss: 4.911949157714844
Validation loss: 4.69558806573191

Epoch: 6| Step: 5
Training loss: 4.784070014953613
Validation loss: 4.666221616088703

Epoch: 6| Step: 6
Training loss: 4.425779819488525
Validation loss: 4.635112649650984

Epoch: 6| Step: 7
Training loss: 2.675259828567505
Validation loss: 4.606314397627307

Epoch: 6| Step: 8
Training loss: 5.205704689025879
Validation loss: 4.5758565164381455

Epoch: 6| Step: 9
Training loss: 4.653511047363281
Validation loss: 4.545773475400863

Epoch: 6| Step: 10
Training loss: 4.513429641723633
Validation loss: 4.514226044377973

Epoch: 6| Step: 11
Training loss: 3.7565276622772217
Validation loss: 4.482946113873553

Epoch: 6| Step: 12
Training loss: 3.9158458709716797
Validation loss: 4.448784300076064

Epoch: 6| Step: 13
Training loss: 5.963613510131836
Validation loss: 4.416995079286637

Epoch: 4| Step: 0
Training loss: 4.842932224273682
Validation loss: 4.38599956163796

Epoch: 6| Step: 1
Training loss: 3.319981098175049
Validation loss: 4.3551607849777385

Epoch: 6| Step: 2
Training loss: 4.468600273132324
Validation loss: 4.327278316661876

Epoch: 6| Step: 3
Training loss: 3.6511900424957275
Validation loss: 4.301338564965032

Epoch: 6| Step: 4
Training loss: 3.854640483856201
Validation loss: 4.276874211526686

Epoch: 6| Step: 5
Training loss: 4.6937971115112305
Validation loss: 4.254518849875337

Epoch: 6| Step: 6
Training loss: 2.7438149452209473
Validation loss: 4.232176742246074

Epoch: 6| Step: 7
Training loss: 4.93617057800293
Validation loss: 4.210035826570245

Epoch: 6| Step: 8
Training loss: 3.139190435409546
Validation loss: 4.189305182426207

Epoch: 6| Step: 9
Training loss: 4.2540740966796875
Validation loss: 4.1698840613006265

Epoch: 6| Step: 10
Training loss: 3.9380648136138916
Validation loss: 4.153316990021737

Epoch: 6| Step: 11
Training loss: 3.858647584915161
Validation loss: 4.13658179518997

Epoch: 6| Step: 12
Training loss: 5.128903388977051
Validation loss: 4.12007463106545

Epoch: 6| Step: 13
Training loss: 3.7712008953094482
Validation loss: 4.103817098884172

Epoch: 5| Step: 0
Training loss: 4.0035719871521
Validation loss: 4.085443276231007

Epoch: 6| Step: 1
Training loss: 3.0138659477233887
Validation loss: 4.063758686024656

Epoch: 6| Step: 2
Training loss: 4.177130699157715
Validation loss: 4.03542923158215

Epoch: 6| Step: 3
Training loss: 3.1771621704101562
Validation loss: 4.006748817300283

Epoch: 6| Step: 4
Training loss: 3.648369789123535
Validation loss: 3.9849077142694944

Epoch: 6| Step: 5
Training loss: 3.9809441566467285
Validation loss: 3.9672587020422823

Epoch: 6| Step: 6
Training loss: 4.188363552093506
Validation loss: 3.9502827172638266

Epoch: 6| Step: 7
Training loss: 3.5214104652404785
Validation loss: 3.9343278587505384

Epoch: 6| Step: 8
Training loss: 4.546750545501709
Validation loss: 3.9190633066238894

Epoch: 6| Step: 9
Training loss: 4.608570575714111
Validation loss: 3.906015514045633

Epoch: 6| Step: 10
Training loss: 3.7702102661132812
Validation loss: 3.8900091878829466

Epoch: 6| Step: 11
Training loss: 2.6475770473480225
Validation loss: 3.8729844298414005

Epoch: 6| Step: 12
Training loss: 4.73384952545166
Validation loss: 3.857899414595737

Epoch: 6| Step: 13
Training loss: 2.8746728897094727
Validation loss: 3.8436620619989212

Epoch: 6| Step: 0
Training loss: 3.136852264404297
Validation loss: 3.8302221759673087

Epoch: 6| Step: 1
Training loss: 3.9453036785125732
Validation loss: 3.814829029062743

Epoch: 6| Step: 2
Training loss: 5.184500694274902
Validation loss: 3.7983894194326093

Epoch: 6| Step: 3
Training loss: 3.993351936340332
Validation loss: 3.7973855233961538

Epoch: 6| Step: 4
Training loss: 2.5496842861175537
Validation loss: 3.784506418371713

Epoch: 6| Step: 5
Training loss: 3.8757128715515137
Validation loss: 3.7685436407725015

Epoch: 6| Step: 6
Training loss: 3.043869972229004
Validation loss: 3.7526799581384145

Epoch: 6| Step: 7
Training loss: 4.10938835144043
Validation loss: 3.74656315260036

Epoch: 6| Step: 8
Training loss: 3.937256097793579
Validation loss: 3.7356519955460743

Epoch: 6| Step: 9
Training loss: 3.2319185733795166
Validation loss: 3.721346101453227

Epoch: 6| Step: 10
Training loss: 3.761549949645996
Validation loss: 3.7015677985324653

Epoch: 6| Step: 11
Training loss: 2.7496886253356934
Validation loss: 3.6885434735205864

Epoch: 6| Step: 12
Training loss: 4.466550827026367
Validation loss: 3.6834560004613732

Epoch: 6| Step: 13
Training loss: 2.530700206756592
Validation loss: 3.664888499885477

Epoch: 7| Step: 0
Training loss: 3.418945074081421
Validation loss: 3.6509059885496735

Epoch: 6| Step: 1
Training loss: 2.9563655853271484
Validation loss: 3.640395556726763

Epoch: 6| Step: 2
Training loss: 3.287240505218506
Validation loss: 3.6297111536866877

Epoch: 6| Step: 3
Training loss: 3.0368971824645996
Validation loss: 3.618058484087708

Epoch: 6| Step: 4
Training loss: 3.173248291015625
Validation loss: 3.602336601544452

Epoch: 6| Step: 5
Training loss: 3.7524266242980957
Validation loss: 3.5908240477244058

Epoch: 6| Step: 6
Training loss: 4.695952415466309
Validation loss: 3.5791564449187248

Epoch: 6| Step: 7
Training loss: 2.9123549461364746
Validation loss: 3.5670166118170625

Epoch: 6| Step: 8
Training loss: 3.6881046295166016
Validation loss: 3.5568195978800454

Epoch: 6| Step: 9
Training loss: 2.9973790645599365
Validation loss: 3.545989877434187

Epoch: 6| Step: 10
Training loss: 3.901900291442871
Validation loss: 3.5333411873027845

Epoch: 6| Step: 11
Training loss: 3.706045389175415
Validation loss: 3.5225363803166214

Epoch: 6| Step: 12
Training loss: 3.3882334232330322
Validation loss: 3.508337051637711

Epoch: 6| Step: 13
Training loss: 4.366788387298584
Validation loss: 3.4990901998294297

Epoch: 8| Step: 0
Training loss: 3.3121633529663086
Validation loss: 3.485852938826366

Epoch: 6| Step: 1
Training loss: 2.1621508598327637
Validation loss: 3.4797912977075063

Epoch: 6| Step: 2
Training loss: 4.23675537109375
Validation loss: 3.4690222842718965

Epoch: 6| Step: 3
Training loss: 2.946162700653076
Validation loss: 3.4576443856762302

Epoch: 6| Step: 4
Training loss: 3.7720425128936768
Validation loss: 3.4457878502466346

Epoch: 6| Step: 5
Training loss: 3.610743522644043
Validation loss: 3.439540642564015

Epoch: 6| Step: 6
Training loss: 4.067307472229004
Validation loss: 3.4268073933098906

Epoch: 6| Step: 7
Training loss: 3.2653002738952637
Validation loss: 3.4185447821053128

Epoch: 6| Step: 8
Training loss: 3.184150218963623
Validation loss: 3.4193379135542017

Epoch: 6| Step: 9
Training loss: 3.1249866485595703
Validation loss: 3.4015460680889826

Epoch: 6| Step: 10
Training loss: 2.6998863220214844
Validation loss: 3.390688221941712

Epoch: 6| Step: 11
Training loss: 2.9272871017456055
Validation loss: 3.3816924889882407

Epoch: 6| Step: 12
Training loss: 4.2191057205200195
Validation loss: 3.3765895905033236

Epoch: 6| Step: 13
Training loss: 3.950718879699707
Validation loss: 3.367253823946881

Epoch: 9| Step: 0
Training loss: 3.9981465339660645
Validation loss: 3.3553517198049896

Epoch: 6| Step: 1
Training loss: 2.9963619709014893
Validation loss: 3.3484094527459916

Epoch: 6| Step: 2
Training loss: 3.0379750728607178
Validation loss: 3.3401771335191626

Epoch: 6| Step: 3
Training loss: 3.3009285926818848
Validation loss: 3.3315497008703088

Epoch: 6| Step: 4
Training loss: 3.627310276031494
Validation loss: 3.3304920401624454

Epoch: 6| Step: 5
Training loss: 3.3568196296691895
Validation loss: 3.3154130904905257

Epoch: 6| Step: 6
Training loss: 2.6609585285186768
Validation loss: 3.3077842676511375

Epoch: 6| Step: 7
Training loss: 2.9112610816955566
Validation loss: 3.2973741305771695

Epoch: 6| Step: 8
Training loss: 3.015507221221924
Validation loss: 3.2918520640301447

Epoch: 6| Step: 9
Training loss: 3.4462738037109375
Validation loss: 3.283961157644949

Epoch: 6| Step: 10
Training loss: 3.441664218902588
Validation loss: 3.2785056585906656

Epoch: 6| Step: 11
Training loss: 3.924135208129883
Validation loss: 3.2730951360476914

Epoch: 6| Step: 12
Training loss: 2.8263370990753174
Validation loss: 3.2627156139701925

Epoch: 6| Step: 13
Training loss: 3.3143179416656494
Validation loss: 3.253536219237953

Epoch: 10| Step: 0
Training loss: 3.730276584625244
Validation loss: 3.2406058644735687

Epoch: 6| Step: 1
Training loss: 3.590993881225586
Validation loss: 3.229673990639307

Epoch: 6| Step: 2
Training loss: 3.8054277896881104
Validation loss: 3.2250340010530207

Epoch: 6| Step: 3
Training loss: 3.550921678543091
Validation loss: 3.207935776761783

Epoch: 6| Step: 4
Training loss: 3.190398931503296
Validation loss: 3.19740189531798

Epoch: 6| Step: 5
Training loss: 3.9288582801818848
Validation loss: 3.189719036061277

Epoch: 6| Step: 6
Training loss: 2.9940032958984375
Validation loss: 3.181638709960445

Epoch: 6| Step: 7
Training loss: 3.229182243347168
Validation loss: 3.1765170071714666

Epoch: 6| Step: 8
Training loss: 2.7131175994873047
Validation loss: 3.170507602794196

Epoch: 6| Step: 9
Training loss: 2.6881444454193115
Validation loss: 3.1618286512231313

Epoch: 6| Step: 10
Training loss: 2.8343698978424072
Validation loss: 3.161919199010377

Epoch: 6| Step: 11
Training loss: 2.2519707679748535
Validation loss: 3.148451087295368

Epoch: 6| Step: 12
Training loss: 3.5803067684173584
Validation loss: 3.140055005268384

Epoch: 6| Step: 13
Training loss: 1.980714201927185
Validation loss: 3.1357055735844437

Epoch: 11| Step: 0
Training loss: 3.4612221717834473
Validation loss: 3.1307826324175765

Epoch: 6| Step: 1
Training loss: 3.829422950744629
Validation loss: 3.1251366471731536

Epoch: 6| Step: 2
Training loss: 3.483567714691162
Validation loss: 3.11977042177672

Epoch: 6| Step: 3
Training loss: 2.653881072998047
Validation loss: 3.1098293130115797

Epoch: 6| Step: 4
Training loss: 2.65767765045166
Validation loss: 3.1022480046877297

Epoch: 6| Step: 5
Training loss: 3.2193188667297363
Validation loss: 3.1028796908675984

Epoch: 6| Step: 6
Training loss: 3.8549585342407227
Validation loss: 3.0987018154513453

Epoch: 6| Step: 7
Training loss: 3.654860019683838
Validation loss: 3.093368491818828

Epoch: 6| Step: 8
Training loss: 3.5194761753082275
Validation loss: 3.090514403517528

Epoch: 6| Step: 9
Training loss: 2.0758376121520996
Validation loss: 3.1172948319424867

Epoch: 6| Step: 10
Training loss: 2.012625217437744
Validation loss: 3.088217250762447

Epoch: 6| Step: 11
Training loss: 3.0684056282043457
Validation loss: 3.076962319753503

Epoch: 6| Step: 12
Training loss: 3.298952579498291
Validation loss: 3.071944969956593

Epoch: 6| Step: 13
Training loss: 2.914517402648926
Validation loss: 3.068757713481944

Epoch: 12| Step: 0
Training loss: 2.6585493087768555
Validation loss: 3.0641156832377114

Epoch: 6| Step: 1
Training loss: 2.871964454650879
Validation loss: 3.0607498307381906

Epoch: 6| Step: 2
Training loss: 3.1038084030151367
Validation loss: 3.0540499610285603

Epoch: 6| Step: 3
Training loss: 2.8593392372131348
Validation loss: 3.0528507437757266

Epoch: 6| Step: 4
Training loss: 2.0514655113220215
Validation loss: 3.049524958415698

Epoch: 6| Step: 5
Training loss: 4.3155388832092285
Validation loss: 3.044706500986571

Epoch: 6| Step: 6
Training loss: 4.037605285644531
Validation loss: 3.053880153163787

Epoch: 6| Step: 7
Training loss: 2.676464319229126
Validation loss: 3.0361887357568227

Epoch: 6| Step: 8
Training loss: 2.868929386138916
Validation loss: 3.0322529321075766

Epoch: 6| Step: 9
Training loss: 3.4182820320129395
Validation loss: 3.031789387426069

Epoch: 6| Step: 10
Training loss: 3.002412796020508
Validation loss: 3.029829325214509

Epoch: 6| Step: 11
Training loss: 3.399979591369629
Validation loss: 3.026702888550297

Epoch: 6| Step: 12
Training loss: 3.1090424060821533
Validation loss: 3.021962568324099

Epoch: 6| Step: 13
Training loss: 2.661707878112793
Validation loss: 3.017067583658362

Epoch: 13| Step: 0
Training loss: 2.6749982833862305
Validation loss: 3.017217630981117

Epoch: 6| Step: 1
Training loss: 3.225520133972168
Validation loss: 3.0388204154147895

Epoch: 6| Step: 2
Training loss: 3.3339123725891113
Validation loss: 3.0470802809602473

Epoch: 6| Step: 3
Training loss: 2.929705858230591
Validation loss: 3.0350503460053475

Epoch: 6| Step: 4
Training loss: 3.8204238414764404
Validation loss: 3.015493821072322

Epoch: 6| Step: 5
Training loss: 3.3533077239990234
Validation loss: 2.996650459945843

Epoch: 6| Step: 6
Training loss: 2.5840659141540527
Validation loss: 3.0137658837021037

Epoch: 6| Step: 7
Training loss: 2.925948143005371
Validation loss: 3.0520416485366

Epoch: 6| Step: 8
Training loss: 3.3810973167419434
Validation loss: 3.01473928266956

Epoch: 6| Step: 9
Training loss: 2.741542100906372
Validation loss: 3.0095383531303814

Epoch: 6| Step: 10
Training loss: 3.4957966804504395
Validation loss: 3.0145535058872674

Epoch: 6| Step: 11
Training loss: 3.4467275142669678
Validation loss: 3.0130996601555937

Epoch: 6| Step: 12
Training loss: 2.0151760578155518
Validation loss: 2.9990940273448987

Epoch: 6| Step: 13
Training loss: 3.2699623107910156
Validation loss: 2.9987401808461835

Epoch: 14| Step: 0
Training loss: 2.6080703735351562
Validation loss: 2.9976314754896265

Epoch: 6| Step: 1
Training loss: 2.919504404067993
Validation loss: 2.9837344948963453

Epoch: 6| Step: 2
Training loss: 3.547819137573242
Validation loss: 2.9827910930879655

Epoch: 6| Step: 3
Training loss: 2.8842806816101074
Validation loss: 2.981643363993655

Epoch: 6| Step: 4
Training loss: 3.2641494274139404
Validation loss: 2.980701164532733

Epoch: 6| Step: 5
Training loss: 3.4763472080230713
Validation loss: 2.9811688520575084

Epoch: 6| Step: 6
Training loss: 2.713090658187866
Validation loss: 2.9747728814360914

Epoch: 6| Step: 7
Training loss: 2.6179583072662354
Validation loss: 2.9652544221570416

Epoch: 6| Step: 8
Training loss: 2.668185234069824
Validation loss: 2.9614391249995076

Epoch: 6| Step: 9
Training loss: 4.634025573730469
Validation loss: 2.955717735393073

Epoch: 6| Step: 10
Training loss: 3.2752115726470947
Validation loss: 2.9533663180566605

Epoch: 6| Step: 11
Training loss: 2.4562783241271973
Validation loss: 2.94745127103662

Epoch: 6| Step: 12
Training loss: 2.8530802726745605
Validation loss: 2.942359385951873

Epoch: 6| Step: 13
Training loss: 2.3971433639526367
Validation loss: 2.9372830903658302

Epoch: 15| Step: 0
Training loss: 3.221620559692383
Validation loss: 2.936358497988793

Epoch: 6| Step: 1
Training loss: 3.369053840637207
Validation loss: 2.932288472370435

Epoch: 6| Step: 2
Training loss: 3.06973934173584
Validation loss: 2.926688209656746

Epoch: 6| Step: 3
Training loss: 3.2824435234069824
Validation loss: 2.9226883226825344

Epoch: 6| Step: 4
Training loss: 2.687544584274292
Validation loss: 2.922625954433154

Epoch: 6| Step: 5
Training loss: 2.5903921127319336
Validation loss: 2.9178118603203886

Epoch: 6| Step: 6
Training loss: 3.2623977661132812
Validation loss: 2.9170906723186536

Epoch: 6| Step: 7
Training loss: 2.5111544132232666
Validation loss: 2.915711179856331

Epoch: 6| Step: 8
Training loss: 3.2821574211120605
Validation loss: 2.9105750924797467

Epoch: 6| Step: 9
Training loss: 2.8995769023895264
Validation loss: 2.9107112115429294

Epoch: 6| Step: 10
Training loss: 2.4284603595733643
Validation loss: 2.9047965875235935

Epoch: 6| Step: 11
Training loss: 2.711911678314209
Validation loss: 2.9001793143569783

Epoch: 6| Step: 12
Training loss: 3.7630929946899414
Validation loss: 2.9008899734866236

Epoch: 6| Step: 13
Training loss: 3.0498292446136475
Validation loss: 2.8982296912900862

Epoch: 16| Step: 0
Training loss: 3.3727364540100098
Validation loss: 2.896262848249046

Epoch: 6| Step: 1
Training loss: 2.7532529830932617
Validation loss: 2.8918419679005942

Epoch: 6| Step: 2
Training loss: 3.0417840480804443
Validation loss: 2.8883070048465522

Epoch: 6| Step: 3
Training loss: 2.8589720726013184
Validation loss: 2.887935023153982

Epoch: 6| Step: 4
Training loss: 3.08143949508667
Validation loss: 2.888307689338602

Epoch: 6| Step: 5
Training loss: 3.1053249835968018
Validation loss: 2.8888973523211736

Epoch: 6| Step: 6
Training loss: 3.9070076942443848
Validation loss: 2.8817640376347367

Epoch: 6| Step: 7
Training loss: 2.6424169540405273
Validation loss: 2.87884097970942

Epoch: 6| Step: 8
Training loss: 2.857886791229248
Validation loss: 2.877255319267191

Epoch: 6| Step: 9
Training loss: 2.9460368156433105
Validation loss: 2.8787701463186615

Epoch: 6| Step: 10
Training loss: 3.164055347442627
Validation loss: 2.8693496155482467

Epoch: 6| Step: 11
Training loss: 3.0240631103515625
Validation loss: 2.868931144796392

Epoch: 6| Step: 12
Training loss: 2.1130049228668213
Validation loss: 2.864336388085478

Epoch: 6| Step: 13
Training loss: 2.8558123111724854
Validation loss: 2.8678471298627954

Epoch: 17| Step: 0
Training loss: 2.3966751098632812
Validation loss: 2.874487410309494

Epoch: 6| Step: 1
Training loss: 2.7195792198181152
Validation loss: 2.8776710776872534

Epoch: 6| Step: 2
Training loss: 2.7284884452819824
Validation loss: 2.8724648798665693

Epoch: 6| Step: 3
Training loss: 2.316300392150879
Validation loss: 2.876521728372061

Epoch: 6| Step: 4
Training loss: 2.9202699661254883
Validation loss: 2.873623514688143

Epoch: 6| Step: 5
Training loss: 2.171656608581543
Validation loss: 2.870988284387896

Epoch: 6| Step: 6
Training loss: 3.3303089141845703
Validation loss: 2.867347022538544

Epoch: 6| Step: 7
Training loss: 4.279165267944336
Validation loss: 2.861604049641599

Epoch: 6| Step: 8
Training loss: 3.8922855854034424
Validation loss: 2.86108834000044

Epoch: 6| Step: 9
Training loss: 2.8592958450317383
Validation loss: 2.857915534768053

Epoch: 6| Step: 10
Training loss: 2.5047600269317627
Validation loss: 2.878595459845758

Epoch: 6| Step: 11
Training loss: 3.675116539001465
Validation loss: 2.876895243121732

Epoch: 6| Step: 12
Training loss: 2.6202611923217773
Validation loss: 2.8541505388034287

Epoch: 6| Step: 13
Training loss: 3.379582166671753
Validation loss: 2.8500572891645533

Epoch: 18| Step: 0
Training loss: 2.580735445022583
Validation loss: 2.8503907393383723

Epoch: 6| Step: 1
Training loss: 2.6471481323242188
Validation loss: 2.8497629806559575

Epoch: 6| Step: 2
Training loss: 2.982053279876709
Validation loss: 2.8503925441413798

Epoch: 6| Step: 3
Training loss: 2.329113483428955
Validation loss: 2.850795292085217

Epoch: 6| Step: 4
Training loss: 2.6522016525268555
Validation loss: 2.8458925985520884

Epoch: 6| Step: 5
Training loss: 2.353991985321045
Validation loss: 2.840842262391121

Epoch: 6| Step: 6
Training loss: 3.9629456996917725
Validation loss: 2.8369705959032943

Epoch: 6| Step: 7
Training loss: 3.2421841621398926
Validation loss: 2.8374687266606156

Epoch: 6| Step: 8
Training loss: 3.051788330078125
Validation loss: 2.8417822853211434

Epoch: 6| Step: 9
Training loss: 3.3042640686035156
Validation loss: 2.8339604921238397

Epoch: 6| Step: 10
Training loss: 3.426136016845703
Validation loss: 2.8317071930054696

Epoch: 6| Step: 11
Training loss: 3.092360496520996
Validation loss: 2.826488451291156

Epoch: 6| Step: 12
Training loss: 3.0633177757263184
Validation loss: 2.8266576233730523

Epoch: 6| Step: 13
Training loss: 2.4639673233032227
Validation loss: 2.8256517584605882

Epoch: 19| Step: 0
Training loss: 2.9026193618774414
Validation loss: 2.827087592053157

Epoch: 6| Step: 1
Training loss: 2.3470067977905273
Validation loss: 2.8295702882992324

Epoch: 6| Step: 2
Training loss: 3.2516746520996094
Validation loss: 2.830895993017381

Epoch: 6| Step: 3
Training loss: 2.729513645172119
Validation loss: 2.8286878524288053

Epoch: 6| Step: 4
Training loss: 2.423349618911743
Validation loss: 2.8245222389057116

Epoch: 6| Step: 5
Training loss: 2.6346371173858643
Validation loss: 2.823174653514739

Epoch: 6| Step: 6
Training loss: 2.6858720779418945
Validation loss: 2.8242880246972524

Epoch: 6| Step: 7
Training loss: 2.6569883823394775
Validation loss: 2.8227518271374445

Epoch: 6| Step: 8
Training loss: 4.360085487365723
Validation loss: 2.8195437333917104

Epoch: 6| Step: 9
Training loss: 2.928835868835449
Validation loss: 2.8156630377615652

Epoch: 6| Step: 10
Training loss: 2.7243237495422363
Validation loss: 2.8115403498372724

Epoch: 6| Step: 11
Training loss: 2.9458229541778564
Validation loss: 2.807558341692853

Epoch: 6| Step: 12
Training loss: 3.1847305297851562
Validation loss: 2.807872644034765

Epoch: 6| Step: 13
Training loss: 3.879791736602783
Validation loss: 2.806735807849515

Epoch: 20| Step: 0
Training loss: 3.7987890243530273
Validation loss: 2.8186637175980436

Epoch: 6| Step: 1
Training loss: 3.8322224617004395
Validation loss: 2.815958094853227

Epoch: 6| Step: 2
Training loss: 3.570195198059082
Validation loss: 2.8076425111421974

Epoch: 6| Step: 3
Training loss: 2.545691967010498
Validation loss: 2.80796673733701

Epoch: 6| Step: 4
Training loss: 2.814152956008911
Validation loss: 2.8077276496477026

Epoch: 6| Step: 5
Training loss: 2.66044545173645
Validation loss: 2.803305284951323

Epoch: 6| Step: 6
Training loss: 2.7355141639709473
Validation loss: 2.8042524245477494

Epoch: 6| Step: 7
Training loss: 3.299185276031494
Validation loss: 2.806495420394405

Epoch: 6| Step: 8
Training loss: 3.5117170810699463
Validation loss: 2.808181196130732

Epoch: 6| Step: 9
Training loss: 1.965516448020935
Validation loss: 2.805457627901467

Epoch: 6| Step: 10
Training loss: 2.197185516357422
Validation loss: 2.804985111759555

Epoch: 6| Step: 11
Training loss: 2.4962401390075684
Validation loss: 2.803152976497527

Epoch: 6| Step: 12
Training loss: 2.547210454940796
Validation loss: 2.8024864453141407

Epoch: 6| Step: 13
Training loss: 3.3911855220794678
Validation loss: 2.8006480022143294

Epoch: 21| Step: 0
Training loss: 3.09466552734375
Validation loss: 2.8025056700552664

Epoch: 6| Step: 1
Training loss: 2.769331455230713
Validation loss: 2.7994496335265455

Epoch: 6| Step: 2
Training loss: 2.4731030464172363
Validation loss: 2.7939236189729426

Epoch: 6| Step: 3
Training loss: 2.67984938621521
Validation loss: 2.7939838799097205

Epoch: 6| Step: 4
Training loss: 3.027583599090576
Validation loss: 2.792930905536939

Epoch: 6| Step: 5
Training loss: 3.138868808746338
Validation loss: 2.791038800311345

Epoch: 6| Step: 6
Training loss: 2.392036199569702
Validation loss: 2.791020765099474

Epoch: 6| Step: 7
Training loss: 3.1660826206207275
Validation loss: 2.790933996118525

Epoch: 6| Step: 8
Training loss: 3.3978207111358643
Validation loss: 2.789476820217666

Epoch: 6| Step: 9
Training loss: 2.7520997524261475
Validation loss: 2.7869583714392876

Epoch: 6| Step: 10
Training loss: 3.2031311988830566
Validation loss: 2.784970942363944

Epoch: 6| Step: 11
Training loss: 3.0058250427246094
Validation loss: 2.78286676509406

Epoch: 6| Step: 12
Training loss: 3.1983823776245117
Validation loss: 2.791977472202752

Epoch: 6| Step: 13
Training loss: 2.5171287059783936
Validation loss: 2.787400286684754

Epoch: 22| Step: 0
Training loss: 2.687894344329834
Validation loss: 2.781567232583159

Epoch: 6| Step: 1
Training loss: 3.148470878601074
Validation loss: 2.7804212467644804

Epoch: 6| Step: 2
Training loss: 3.369345188140869
Validation loss: 2.7799444378063245

Epoch: 6| Step: 3
Training loss: 2.7186083793640137
Validation loss: 2.7805397074709655

Epoch: 6| Step: 4
Training loss: 2.835958480834961
Validation loss: 2.7784182615177606

Epoch: 6| Step: 5
Training loss: 3.244816303253174
Validation loss: 2.779067721418155

Epoch: 6| Step: 6
Training loss: 2.641798496246338
Validation loss: 2.7774036084451983

Epoch: 6| Step: 7
Training loss: 3.8322174549102783
Validation loss: 2.777365151272025

Epoch: 6| Step: 8
Training loss: 2.755396842956543
Validation loss: 2.7788974136434574

Epoch: 6| Step: 9
Training loss: 2.827677011489868
Validation loss: 2.7764426533893873

Epoch: 6| Step: 10
Training loss: 3.35247540473938
Validation loss: 2.7761054885002876

Epoch: 6| Step: 11
Training loss: 1.5983445644378662
Validation loss: 2.776494561984975

Epoch: 6| Step: 12
Training loss: 2.772021770477295
Validation loss: 2.774759349002633

Epoch: 6| Step: 13
Training loss: 3.22603702545166
Validation loss: 2.771915164045108

Epoch: 23| Step: 0
Training loss: 3.806453227996826
Validation loss: 2.7688382056451615

Epoch: 6| Step: 1
Training loss: 2.947774887084961
Validation loss: 2.7685678184673352

Epoch: 6| Step: 2
Training loss: 3.100759983062744
Validation loss: 2.7678162820877565

Epoch: 6| Step: 3
Training loss: 3.053236246109009
Validation loss: 2.7654235260460966

Epoch: 6| Step: 4
Training loss: 2.59128999710083
Validation loss: 2.7649595711820867

Epoch: 6| Step: 5
Training loss: 3.149646043777466
Validation loss: 2.7619026348155034

Epoch: 6| Step: 6
Training loss: 3.105803966522217
Validation loss: 2.7639663501452376

Epoch: 6| Step: 7
Training loss: 2.482219696044922
Validation loss: 2.7654289276369157

Epoch: 6| Step: 8
Training loss: 3.193821430206299
Validation loss: 2.7593594904868834

Epoch: 6| Step: 9
Training loss: 2.0375399589538574
Validation loss: 2.760407781088224

Epoch: 6| Step: 10
Training loss: 3.0941858291625977
Validation loss: 2.7864545545270367

Epoch: 6| Step: 11
Training loss: 2.4335906505584717
Validation loss: 2.760958410078479

Epoch: 6| Step: 12
Training loss: 3.2057018280029297
Validation loss: 2.7638014977978123

Epoch: 6| Step: 13
Training loss: 2.379664659500122
Validation loss: 2.7649640883168867

Epoch: 24| Step: 0
Training loss: 2.9676995277404785
Validation loss: 2.7699816329504854

Epoch: 6| Step: 1
Training loss: 2.8682596683502197
Validation loss: 2.774092141018119

Epoch: 6| Step: 2
Training loss: 2.4257469177246094
Validation loss: 2.778263202277563

Epoch: 6| Step: 3
Training loss: 2.8820595741271973
Validation loss: 2.7847430834206204

Epoch: 6| Step: 4
Training loss: 3.5147979259490967
Validation loss: 2.7952699635618474

Epoch: 6| Step: 5
Training loss: 2.920548915863037
Validation loss: 2.7913954206692275

Epoch: 6| Step: 6
Training loss: 2.988431692123413
Validation loss: 2.786598600367064

Epoch: 6| Step: 7
Training loss: 2.677513599395752
Validation loss: 2.780146388597386

Epoch: 6| Step: 8
Training loss: 3.318375587463379
Validation loss: 2.776221339420606

Epoch: 6| Step: 9
Training loss: 2.430671215057373
Validation loss: 2.7718784475839264

Epoch: 6| Step: 10
Training loss: 3.5963947772979736
Validation loss: 2.766635766593359

Epoch: 6| Step: 11
Training loss: 3.290412187576294
Validation loss: 2.762353625348819

Epoch: 6| Step: 12
Training loss: 2.5529115200042725
Validation loss: 2.75829331849211

Epoch: 6| Step: 13
Training loss: 2.0104846954345703
Validation loss: 2.7547302143548125

Epoch: 25| Step: 0
Training loss: 2.974478244781494
Validation loss: 2.7528389346215034

Epoch: 6| Step: 1
Training loss: 2.435347557067871
Validation loss: 2.7516896622155302

Epoch: 6| Step: 2
Training loss: 2.5186686515808105
Validation loss: 2.7492324716301373

Epoch: 6| Step: 3
Training loss: 2.9420454502105713
Validation loss: 2.7489481126108477

Epoch: 6| Step: 4
Training loss: 3.128166675567627
Validation loss: 2.750711940949963

Epoch: 6| Step: 5
Training loss: 3.532528877258301
Validation loss: 2.747164764711934

Epoch: 6| Step: 6
Training loss: 2.956141471862793
Validation loss: 2.745803548443702

Epoch: 6| Step: 7
Training loss: 2.5370569229125977
Validation loss: 2.7453843701270317

Epoch: 6| Step: 8
Training loss: 2.94881534576416
Validation loss: 2.7428489731204126

Epoch: 6| Step: 9
Training loss: 3.364434242248535
Validation loss: 2.741985454354235

Epoch: 6| Step: 10
Training loss: 2.510744571685791
Validation loss: 2.7413875518306607

Epoch: 6| Step: 11
Training loss: 3.1874542236328125
Validation loss: 2.740064255652889

Epoch: 6| Step: 12
Training loss: 2.574536085128784
Validation loss: 2.739164467780821

Epoch: 6| Step: 13
Training loss: 3.0546140670776367
Validation loss: 2.7393519493841354

Epoch: 26| Step: 0
Training loss: 3.221158266067505
Validation loss: 2.738197495860438

Epoch: 6| Step: 1
Training loss: 3.2341270446777344
Validation loss: 2.7376650379550074

Epoch: 6| Step: 2
Training loss: 3.6575849056243896
Validation loss: 2.7357069882013465

Epoch: 6| Step: 3
Training loss: 2.720132827758789
Validation loss: 2.7354027814762567

Epoch: 6| Step: 4
Training loss: 3.145627975463867
Validation loss: 2.736180595172349

Epoch: 6| Step: 5
Training loss: 2.8208680152893066
Validation loss: 2.7372274142439648

Epoch: 6| Step: 6
Training loss: 2.399646282196045
Validation loss: 2.7437842148606495

Epoch: 6| Step: 7
Training loss: 2.0945897102355957
Validation loss: 2.7430511956573813

Epoch: 6| Step: 8
Training loss: 1.880617618560791
Validation loss: 2.7342421085603776

Epoch: 6| Step: 9
Training loss: 1.8501207828521729
Validation loss: 2.732909184630199

Epoch: 6| Step: 10
Training loss: 3.252933979034424
Validation loss: 2.7339828962920816

Epoch: 6| Step: 11
Training loss: 3.6487765312194824
Validation loss: 2.7353161483682613

Epoch: 6| Step: 12
Training loss: 3.5712997913360596
Validation loss: 2.7361883322397866

Epoch: 6| Step: 13
Training loss: 3.088371753692627
Validation loss: 2.735602307063277

Epoch: 27| Step: 0
Training loss: 2.932866334915161
Validation loss: 2.73467154400323

Epoch: 6| Step: 1
Training loss: 2.4702320098876953
Validation loss: 2.733597255522205

Epoch: 6| Step: 2
Training loss: 3.034928321838379
Validation loss: 2.734075948756228

Epoch: 6| Step: 3
Training loss: 3.3815417289733887
Validation loss: 2.7342923430986303

Epoch: 6| Step: 4
Training loss: 2.7727513313293457
Validation loss: 2.7317623220464236

Epoch: 6| Step: 5
Training loss: 3.7136991024017334
Validation loss: 2.7320689052663822

Epoch: 6| Step: 6
Training loss: 3.1329846382141113
Validation loss: 2.7304554318868988

Epoch: 6| Step: 7
Training loss: 2.3178391456604004
Validation loss: 2.730151166198074

Epoch: 6| Step: 8
Training loss: 2.844747304916382
Validation loss: 2.7276427027999715

Epoch: 6| Step: 9
Training loss: 2.540048122406006
Validation loss: 2.729663061839278

Epoch: 6| Step: 10
Training loss: 3.4921953678131104
Validation loss: 2.727816786817325

Epoch: 6| Step: 11
Training loss: 2.0274672508239746
Validation loss: 2.726538106959353

Epoch: 6| Step: 12
Training loss: 2.486177444458008
Validation loss: 2.7286014761976016

Epoch: 6| Step: 13
Training loss: 3.635057210922241
Validation loss: 2.7314291102911836

Epoch: 28| Step: 0
Training loss: 3.363948345184326
Validation loss: 2.726063507859425

Epoch: 6| Step: 1
Training loss: 1.988135576248169
Validation loss: 2.726257348573336

Epoch: 6| Step: 2
Training loss: 2.5119690895080566
Validation loss: 2.7242525085326164

Epoch: 6| Step: 3
Training loss: 3.0960865020751953
Validation loss: 2.7243017817056305

Epoch: 6| Step: 4
Training loss: 3.449404239654541
Validation loss: 2.722602746819937

Epoch: 6| Step: 5
Training loss: 2.9811954498291016
Validation loss: 2.7229308979485625

Epoch: 6| Step: 6
Training loss: 2.4435973167419434
Validation loss: 2.7222838401794434

Epoch: 6| Step: 7
Training loss: 4.215553283691406
Validation loss: 2.721717026925856

Epoch: 6| Step: 8
Training loss: 2.7033705711364746
Validation loss: 2.71916268461494

Epoch: 6| Step: 9
Training loss: 2.1403002738952637
Validation loss: 2.7159629303921937

Epoch: 6| Step: 10
Training loss: 3.0926742553710938
Validation loss: 2.717216871118033

Epoch: 6| Step: 11
Training loss: 2.268174409866333
Validation loss: 2.7145384255275933

Epoch: 6| Step: 12
Training loss: 3.039119243621826
Validation loss: 2.7158637123723186

Epoch: 6| Step: 13
Training loss: 3.16729736328125
Validation loss: 2.7132096803316506

Epoch: 29| Step: 0
Training loss: 3.105222702026367
Validation loss: 2.7094521804522445

Epoch: 6| Step: 1
Training loss: 3.0046029090881348
Validation loss: 2.706242558776691

Epoch: 6| Step: 2
Training loss: 2.613908290863037
Validation loss: 2.708141747341361

Epoch: 6| Step: 3
Training loss: 2.7449116706848145
Validation loss: 2.7018977467731764

Epoch: 6| Step: 4
Training loss: 3.16443133354187
Validation loss: 2.7037460573257937

Epoch: 6| Step: 5
Training loss: 2.297201633453369
Validation loss: 2.6983700977858676

Epoch: 6| Step: 6
Training loss: 3.2806549072265625
Validation loss: 2.7002031367312194

Epoch: 6| Step: 7
Training loss: 2.8659534454345703
Validation loss: 2.6993161298895396

Epoch: 6| Step: 8
Training loss: 2.9360246658325195
Validation loss: 2.697077651177683

Epoch: 6| Step: 9
Training loss: 3.6867222785949707
Validation loss: 2.6938024003018617

Epoch: 6| Step: 10
Training loss: 2.018373966217041
Validation loss: 2.696313109449161

Epoch: 6| Step: 11
Training loss: 2.1745667457580566
Validation loss: 2.697364389255483

Epoch: 6| Step: 12
Training loss: 2.4214704036712646
Validation loss: 2.6998094743297947

Epoch: 6| Step: 13
Training loss: 4.681177139282227
Validation loss: 2.6970879390675533

Epoch: 30| Step: 0
Training loss: 2.9553661346435547
Validation loss: 2.696988133973973

Epoch: 6| Step: 1
Training loss: 3.4908337593078613
Validation loss: 2.693088318711968

Epoch: 6| Step: 2
Training loss: 2.6482324600219727
Validation loss: 2.693410147902786

Epoch: 6| Step: 3
Training loss: 2.5674057006835938
Validation loss: 2.69570485238106

Epoch: 6| Step: 4
Training loss: 2.9010138511657715
Validation loss: 2.6980785169909076

Epoch: 6| Step: 5
Training loss: 2.843172788619995
Validation loss: 2.7042864240625852

Epoch: 6| Step: 6
Training loss: 3.67631459236145
Validation loss: 2.6955939339053248

Epoch: 6| Step: 7
Training loss: 2.6092703342437744
Validation loss: 2.6934200409919984

Epoch: 6| Step: 8
Training loss: 2.7382378578186035
Validation loss: 2.6898502585708455

Epoch: 6| Step: 9
Training loss: 2.8100814819335938
Validation loss: 2.6878389466193413

Epoch: 6| Step: 10
Training loss: 2.3764052391052246
Validation loss: 2.6878076420035413

Epoch: 6| Step: 11
Training loss: 2.3792197704315186
Validation loss: 2.685919007947368

Epoch: 6| Step: 12
Training loss: 3.3804852962493896
Validation loss: 2.685502726544616

Epoch: 6| Step: 13
Training loss: 2.61708927154541
Validation loss: 2.6856583574766755

Epoch: 31| Step: 0
Training loss: 3.5916566848754883
Validation loss: 2.6914640267690024

Epoch: 6| Step: 1
Training loss: 3.0464940071105957
Validation loss: 2.6912651651649067

Epoch: 6| Step: 2
Training loss: 3.216087818145752
Validation loss: 2.685446282868744

Epoch: 6| Step: 3
Training loss: 2.6728219985961914
Validation loss: 2.68325533405427

Epoch: 6| Step: 4
Training loss: 2.350785732269287
Validation loss: 2.683438524123161

Epoch: 6| Step: 5
Training loss: 2.287081003189087
Validation loss: 2.682296973402782

Epoch: 6| Step: 6
Training loss: 2.841660737991333
Validation loss: 2.6848737655147428

Epoch: 6| Step: 7
Training loss: 2.2608602046966553
Validation loss: 2.6849587168744815

Epoch: 6| Step: 8
Training loss: 2.8254003524780273
Validation loss: 2.689429585651685

Epoch: 6| Step: 9
Training loss: 2.9021482467651367
Validation loss: 2.6904492993508615

Epoch: 6| Step: 10
Training loss: 3.2115635871887207
Validation loss: 2.691651431463098

Epoch: 6| Step: 11
Training loss: 2.657081365585327
Validation loss: 2.6862109707247828

Epoch: 6| Step: 12
Training loss: 3.534013032913208
Validation loss: 2.68557487251938

Epoch: 6| Step: 13
Training loss: 2.518996000289917
Validation loss: 2.6824586442721787

Epoch: 32| Step: 0
Training loss: 3.534404754638672
Validation loss: 2.680899420092183

Epoch: 6| Step: 1
Training loss: 2.6695351600646973
Validation loss: 2.677675421519946

Epoch: 6| Step: 2
Training loss: 3.1210215091705322
Validation loss: 2.6783428833048832

Epoch: 6| Step: 3
Training loss: 2.5098161697387695
Validation loss: 2.6758040407652497

Epoch: 6| Step: 4
Training loss: 3.8327579498291016
Validation loss: 2.6768767756800496

Epoch: 6| Step: 5
Training loss: 2.898010730743408
Validation loss: 2.6777075336825464

Epoch: 6| Step: 6
Training loss: 2.603433132171631
Validation loss: 2.6784206667254047

Epoch: 6| Step: 7
Training loss: 1.6428258419036865
Validation loss: 2.6783380559695664

Epoch: 6| Step: 8
Training loss: 2.119821310043335
Validation loss: 2.675687938608149

Epoch: 6| Step: 9
Training loss: 3.023743152618408
Validation loss: 2.675476351091939

Epoch: 6| Step: 10
Training loss: 3.4370615482330322
Validation loss: 2.6747926024980444

Epoch: 6| Step: 11
Training loss: 2.751708507537842
Validation loss: 2.6752138547999884

Epoch: 6| Step: 12
Training loss: 3.4026191234588623
Validation loss: 2.673655838094732

Epoch: 6| Step: 13
Training loss: 2.0380849838256836
Validation loss: 2.6754119780755814

Epoch: 33| Step: 0
Training loss: 2.761509895324707
Validation loss: 2.6851336904751357

Epoch: 6| Step: 1
Training loss: 3.2032501697540283
Validation loss: 2.7254573145220355

Epoch: 6| Step: 2
Training loss: 3.501248359680176
Validation loss: 2.70650892103872

Epoch: 6| Step: 3
Training loss: 3.2937283515930176
Validation loss: 2.6789623332279984

Epoch: 6| Step: 4
Training loss: 2.7174909114837646
Validation loss: 2.6715400859873784

Epoch: 6| Step: 5
Training loss: 2.972224235534668
Validation loss: 2.6702365157424763

Epoch: 6| Step: 6
Training loss: 2.635530948638916
Validation loss: 2.669851913247057

Epoch: 6| Step: 7
Training loss: 2.4200315475463867
Validation loss: 2.6707320290227092

Epoch: 6| Step: 8
Training loss: 3.2110073566436768
Validation loss: 2.676233814608666

Epoch: 6| Step: 9
Training loss: 3.5020830631256104
Validation loss: 2.6775047625264814

Epoch: 6| Step: 10
Training loss: 2.47379732131958
Validation loss: 2.6732489114166587

Epoch: 6| Step: 11
Training loss: 2.3501574993133545
Validation loss: 2.669578234354655

Epoch: 6| Step: 12
Training loss: 2.298417806625366
Validation loss: 2.668735980987549

Epoch: 6| Step: 13
Training loss: 2.4215033054351807
Validation loss: 2.669810966778827

Epoch: 34| Step: 0
Training loss: 3.410956621170044
Validation loss: 2.687788612099104

Epoch: 6| Step: 1
Training loss: 2.457796812057495
Validation loss: 2.689812239780221

Epoch: 6| Step: 2
Training loss: 2.7675256729125977
Validation loss: 2.664528641649472

Epoch: 6| Step: 3
Training loss: 3.072078227996826
Validation loss: 2.659163651927825

Epoch: 6| Step: 4
Training loss: 3.6197643280029297
Validation loss: 2.66088330617515

Epoch: 6| Step: 5
Training loss: 2.3607559204101562
Validation loss: 2.6676816735216367

Epoch: 6| Step: 6
Training loss: 2.305868148803711
Validation loss: 2.6753056946621148

Epoch: 6| Step: 7
Training loss: 3.036994218826294
Validation loss: 2.68238555231402

Epoch: 6| Step: 8
Training loss: 2.39925479888916
Validation loss: 2.676841564075921

Epoch: 6| Step: 9
Training loss: 3.4329190254211426
Validation loss: 2.671686698031682

Epoch: 6| Step: 10
Training loss: 2.7285335063934326
Validation loss: 2.6618491654754965

Epoch: 6| Step: 11
Training loss: 2.125899314880371
Validation loss: 2.6599790434683523

Epoch: 6| Step: 12
Training loss: 3.161623477935791
Validation loss: 2.6724497092667447

Epoch: 6| Step: 13
Training loss: 3.13546085357666
Validation loss: 2.675606263581143

Epoch: 35| Step: 0
Training loss: 2.9624481201171875
Validation loss: 2.6742047545730427

Epoch: 6| Step: 1
Training loss: 2.0650975704193115
Validation loss: 2.6623938698922434

Epoch: 6| Step: 2
Training loss: 3.1391828060150146
Validation loss: 2.660433289825275

Epoch: 6| Step: 3
Training loss: 3.622981309890747
Validation loss: 2.6577766633802846

Epoch: 6| Step: 4
Training loss: 3.6165103912353516
Validation loss: 2.657313562208606

Epoch: 6| Step: 5
Training loss: 2.5281219482421875
Validation loss: 2.6568815990160872

Epoch: 6| Step: 6
Training loss: 2.7531657218933105
Validation loss: 2.653392748166156

Epoch: 6| Step: 7
Training loss: 2.6052637100219727
Validation loss: 2.6537735308370283

Epoch: 6| Step: 8
Training loss: 2.859132766723633
Validation loss: 2.6520268019809516

Epoch: 6| Step: 9
Training loss: 2.749174118041992
Validation loss: 2.6533580659538187

Epoch: 6| Step: 10
Training loss: 2.6239466667175293
Validation loss: 2.6503795987816265

Epoch: 6| Step: 11
Training loss: 2.4192652702331543
Validation loss: 2.6512700255199144

Epoch: 6| Step: 12
Training loss: 2.6460609436035156
Validation loss: 2.6474455659107496

Epoch: 6| Step: 13
Training loss: 3.4017350673675537
Validation loss: 2.6463850390526558

Epoch: 36| Step: 0
Training loss: 2.712873935699463
Validation loss: 2.649208814867081

Epoch: 6| Step: 1
Training loss: 3.2438817024230957
Validation loss: 2.644997186558221

Epoch: 6| Step: 2
Training loss: 2.7383222579956055
Validation loss: 2.6445945334690872

Epoch: 6| Step: 3
Training loss: 2.5791635513305664
Validation loss: 2.6510393670810166

Epoch: 6| Step: 4
Training loss: 2.4796841144561768
Validation loss: 2.655438579538817

Epoch: 6| Step: 5
Training loss: 2.498295307159424
Validation loss: 2.6548542771288144

Epoch: 6| Step: 6
Training loss: 2.630892276763916
Validation loss: 2.6452285089800434

Epoch: 6| Step: 7
Training loss: 2.846107006072998
Validation loss: 2.645753273399927

Epoch: 6| Step: 8
Training loss: 2.9153223037719727
Validation loss: 2.638307535520164

Epoch: 6| Step: 9
Training loss: 3.20609188079834
Validation loss: 2.638860551259851

Epoch: 6| Step: 10
Training loss: 3.120551586151123
Validation loss: 2.641995986302694

Epoch: 6| Step: 11
Training loss: 3.145003318786621
Validation loss: 2.635606327364522

Epoch: 6| Step: 12
Training loss: 2.507242202758789
Validation loss: 2.638458549335439

Epoch: 6| Step: 13
Training loss: 3.116823434829712
Validation loss: 2.6369017862504527

Epoch: 37| Step: 0
Training loss: 3.245443820953369
Validation loss: 2.640034347452143

Epoch: 6| Step: 1
Training loss: 3.0571043491363525
Validation loss: 2.6406245949447795

Epoch: 6| Step: 2
Training loss: 2.7732324600219727
Validation loss: 2.6442598732568885

Epoch: 6| Step: 3
Training loss: 2.5040316581726074
Validation loss: 2.6429985723187848

Epoch: 6| Step: 4
Training loss: 2.6816296577453613
Validation loss: 2.648919520839568

Epoch: 6| Step: 5
Training loss: 2.2326622009277344
Validation loss: 2.6507212705509637

Epoch: 6| Step: 6
Training loss: 2.789827585220337
Validation loss: 2.6517227388197377

Epoch: 6| Step: 7
Training loss: 3.5840039253234863
Validation loss: 2.6531964655845397

Epoch: 6| Step: 8
Training loss: 2.6968560218811035
Validation loss: 2.644357876111102

Epoch: 6| Step: 9
Training loss: 2.928642511367798
Validation loss: 2.6408271635732343

Epoch: 6| Step: 10
Training loss: 2.6836929321289062
Validation loss: 2.641120203079716

Epoch: 6| Step: 11
Training loss: 3.1848201751708984
Validation loss: 2.636640018032443

Epoch: 6| Step: 12
Training loss: 2.8841724395751953
Validation loss: 2.638671516090311

Epoch: 6| Step: 13
Training loss: 2.0540173053741455
Validation loss: 2.632890296238725

Epoch: 38| Step: 0
Training loss: 2.9975616931915283
Validation loss: 2.653392002146731

Epoch: 6| Step: 1
Training loss: 2.4800925254821777
Validation loss: 2.647644909479285

Epoch: 6| Step: 2
Training loss: 2.6217458248138428
Validation loss: 2.6390728130135486

Epoch: 6| Step: 3
Training loss: 2.724637985229492
Validation loss: 2.6309890721433904

Epoch: 6| Step: 4
Training loss: 3.037738084793091
Validation loss: 2.634202249588505

Epoch: 6| Step: 5
Training loss: 2.39509916305542
Validation loss: 2.631866342277937

Epoch: 6| Step: 6
Training loss: 2.809518814086914
Validation loss: 2.634152594433036

Epoch: 6| Step: 7
Training loss: 4.051298141479492
Validation loss: 2.632485220509191

Epoch: 6| Step: 8
Training loss: 3.166254758834839
Validation loss: 2.6331612038356003

Epoch: 6| Step: 9
Training loss: 2.823972702026367
Validation loss: 2.6263768262760614

Epoch: 6| Step: 10
Training loss: 2.569955348968506
Validation loss: 2.630853452990132

Epoch: 6| Step: 11
Training loss: 2.7535455226898193
Validation loss: 2.629048455146051

Epoch: 6| Step: 12
Training loss: 2.5391862392425537
Validation loss: 2.6290497677300566

Epoch: 6| Step: 13
Training loss: 2.484243392944336
Validation loss: 2.62336746082511

Epoch: 39| Step: 0
Training loss: 2.734272003173828
Validation loss: 2.6225915211503223

Epoch: 6| Step: 1
Training loss: 2.954878091812134
Validation loss: 2.621586699639597

Epoch: 6| Step: 2
Training loss: 2.7761645317077637
Validation loss: 2.624041962367232

Epoch: 6| Step: 3
Training loss: 2.985443353652954
Validation loss: 2.624715369234803

Epoch: 6| Step: 4
Training loss: 2.320126533508301
Validation loss: 2.620332899913993

Epoch: 6| Step: 5
Training loss: 2.695732831954956
Validation loss: 2.624071728798651

Epoch: 6| Step: 6
Training loss: 2.097308397293091
Validation loss: 2.6347368199338197

Epoch: 6| Step: 7
Training loss: 3.7834863662719727
Validation loss: 2.6384772459665933

Epoch: 6| Step: 8
Training loss: 2.7482998371124268
Validation loss: 2.629047752708517

Epoch: 6| Step: 9
Training loss: 2.9443812370300293
Validation loss: 2.629707303098453

Epoch: 6| Step: 10
Training loss: 3.529120922088623
Validation loss: 2.624946004600935

Epoch: 6| Step: 11
Training loss: 2.1639301776885986
Validation loss: 2.6213702540243826

Epoch: 6| Step: 12
Training loss: 2.5084657669067383
Validation loss: 2.6198145394684165

Epoch: 6| Step: 13
Training loss: 3.427821159362793
Validation loss: 2.617281183119743

Epoch: 40| Step: 0
Training loss: 2.8090596199035645
Validation loss: 2.617649011714484

Epoch: 6| Step: 1
Training loss: 2.284533977508545
Validation loss: 2.618446934607721

Epoch: 6| Step: 2
Training loss: 3.128019332885742
Validation loss: 2.618004580979706

Epoch: 6| Step: 3
Training loss: 2.0959038734436035
Validation loss: 2.6248737201895764

Epoch: 6| Step: 4
Training loss: 3.9163737297058105
Validation loss: 2.621782559220509

Epoch: 6| Step: 5
Training loss: 2.4753541946411133
Validation loss: 2.6160583239729687

Epoch: 6| Step: 6
Training loss: 2.5685362815856934
Validation loss: 2.615908358686714

Epoch: 6| Step: 7
Training loss: 2.54659104347229
Validation loss: 2.6188193418646373

Epoch: 6| Step: 8
Training loss: 3.0280513763427734
Validation loss: 2.6165862121889667

Epoch: 6| Step: 9
Training loss: 2.755852222442627
Validation loss: 2.6228228615176294

Epoch: 6| Step: 10
Training loss: 3.3024978637695312
Validation loss: 2.629596100058607

Epoch: 6| Step: 11
Training loss: 3.376966953277588
Validation loss: 2.6397576947366037

Epoch: 6| Step: 12
Training loss: 2.6065421104431152
Validation loss: 2.640253710490401

Epoch: 6| Step: 13
Training loss: 2.2112302780151367
Validation loss: 2.6192529791144916

Epoch: 41| Step: 0
Training loss: 2.695650577545166
Validation loss: 2.615209074430568

Epoch: 6| Step: 1
Training loss: 2.696516752243042
Validation loss: 2.6130157670667096

Epoch: 6| Step: 2
Training loss: 3.0591835975646973
Validation loss: 2.6119887546826432

Epoch: 6| Step: 3
Training loss: 2.773519515991211
Validation loss: 2.615568889084683

Epoch: 6| Step: 4
Training loss: 2.989917278289795
Validation loss: 2.61513848714931

Epoch: 6| Step: 5
Training loss: 2.587460517883301
Validation loss: 2.612579014993483

Epoch: 6| Step: 6
Training loss: 2.2349369525909424
Validation loss: 2.6170857901214273

Epoch: 6| Step: 7
Training loss: 2.8880810737609863
Validation loss: 2.6303015447431997

Epoch: 6| Step: 8
Training loss: 2.891655921936035
Validation loss: 2.6361510189630653

Epoch: 6| Step: 9
Training loss: 3.304932117462158
Validation loss: 2.64619202767649

Epoch: 6| Step: 10
Training loss: 2.8589391708374023
Validation loss: 2.6500120547509964

Epoch: 6| Step: 11
Training loss: 2.5529825687408447
Validation loss: 2.6283385010175806

Epoch: 6| Step: 12
Training loss: 3.7338173389434814
Validation loss: 2.61408979405639

Epoch: 6| Step: 13
Training loss: 1.4764246940612793
Validation loss: 2.6142704307392077

Epoch: 42| Step: 0
Training loss: 3.020599365234375
Validation loss: 2.6257838459425074

Epoch: 6| Step: 1
Training loss: 2.544100761413574
Validation loss: 2.644005342196393

Epoch: 6| Step: 2
Training loss: 2.5646886825561523
Validation loss: 2.665404132617417

Epoch: 6| Step: 3
Training loss: 3.076416015625
Validation loss: 2.68445945555164

Epoch: 6| Step: 4
Training loss: 2.027676582336426
Validation loss: 2.6780026856289116

Epoch: 6| Step: 5
Training loss: 3.844496250152588
Validation loss: 2.6806092339177288

Epoch: 6| Step: 6
Training loss: 2.4057765007019043
Validation loss: 2.6635491053263345

Epoch: 6| Step: 7
Training loss: 3.1830759048461914
Validation loss: 2.640743363288141

Epoch: 6| Step: 8
Training loss: 3.1517744064331055
Validation loss: 2.6141799572975404

Epoch: 6| Step: 9
Training loss: 2.7737553119659424
Validation loss: 2.6132485276909283

Epoch: 6| Step: 10
Training loss: 2.897108554840088
Validation loss: 2.6187290530050955

Epoch: 6| Step: 11
Training loss: 2.5570342540740967
Validation loss: 2.6309578111094813

Epoch: 6| Step: 12
Training loss: 2.048870325088501
Validation loss: 2.6322822622073594

Epoch: 6| Step: 13
Training loss: 4.096217632293701
Validation loss: 2.6519012040989374

Epoch: 43| Step: 0
Training loss: 2.668179512023926
Validation loss: 2.638107761260002

Epoch: 6| Step: 1
Training loss: 3.2485315799713135
Validation loss: 2.6305581626071723

Epoch: 6| Step: 2
Training loss: 2.327359914779663
Validation loss: 2.620993229650682

Epoch: 6| Step: 3
Training loss: 3.2488536834716797
Validation loss: 2.609193012278567

Epoch: 6| Step: 4
Training loss: 3.0733437538146973
Validation loss: 2.609642490263908

Epoch: 6| Step: 5
Training loss: 2.5913944244384766
Validation loss: 2.607437313243907

Epoch: 6| Step: 6
Training loss: 2.9050683975219727
Validation loss: 2.6050257477709042

Epoch: 6| Step: 7
Training loss: 3.010305166244507
Validation loss: 2.6056539909813994

Epoch: 6| Step: 8
Training loss: 1.7777535915374756
Validation loss: 2.6020282340306107

Epoch: 6| Step: 9
Training loss: 3.2618627548217773
Validation loss: 2.6102758735738774

Epoch: 6| Step: 10
Training loss: 2.794102668762207
Validation loss: 2.6048799432734007

Epoch: 6| Step: 11
Training loss: 3.290639877319336
Validation loss: 2.6060753330107658

Epoch: 6| Step: 12
Training loss: 2.4216413497924805
Validation loss: 2.600206646867978

Epoch: 6| Step: 13
Training loss: 2.467479944229126
Validation loss: 2.6020863927820677

Epoch: 44| Step: 0
Training loss: 2.853949546813965
Validation loss: 2.5990303177987375

Epoch: 6| Step: 1
Training loss: 2.4859657287597656
Validation loss: 2.599805578108757

Epoch: 6| Step: 2
Training loss: 3.094083547592163
Validation loss: 2.600967299553656

Epoch: 6| Step: 3
Training loss: 3.0025601387023926
Validation loss: 2.601443918802405

Epoch: 6| Step: 4
Training loss: 2.416656494140625
Validation loss: 2.597929705855667

Epoch: 6| Step: 5
Training loss: 2.5551576614379883
Validation loss: 2.595627207909861

Epoch: 6| Step: 6
Training loss: 2.3958740234375
Validation loss: 2.592196318411058

Epoch: 6| Step: 7
Training loss: 3.2561163902282715
Validation loss: 2.5951872282130743

Epoch: 6| Step: 8
Training loss: 3.1760940551757812
Validation loss: 2.595632322372929

Epoch: 6| Step: 9
Training loss: 2.050091505050659
Validation loss: 2.595477011895949

Epoch: 6| Step: 10
Training loss: 3.3888485431671143
Validation loss: 2.595050581039921

Epoch: 6| Step: 11
Training loss: 2.9116833209991455
Validation loss: 2.6002291710146013

Epoch: 6| Step: 12
Training loss: 2.809434413909912
Validation loss: 2.592201066273515

Epoch: 6| Step: 13
Training loss: 2.749446392059326
Validation loss: 2.5926226057032102

Epoch: 45| Step: 0
Training loss: 2.500103235244751
Validation loss: 2.5905261629371235

Epoch: 6| Step: 1
Training loss: 3.027150869369507
Validation loss: 2.5899235715148268

Epoch: 6| Step: 2
Training loss: 2.3216493129730225
Validation loss: 2.596660106412826

Epoch: 6| Step: 3
Training loss: 2.5565974712371826
Validation loss: 2.61630940950045

Epoch: 6| Step: 4
Training loss: 2.9821455478668213
Validation loss: 2.637516934384582

Epoch: 6| Step: 5
Training loss: 2.5381460189819336
Validation loss: 2.6264971994584605

Epoch: 6| Step: 6
Training loss: 2.899061679840088
Validation loss: 2.620628777370658

Epoch: 6| Step: 7
Training loss: 2.8791885375976562
Validation loss: 2.5951325380673973

Epoch: 6| Step: 8
Training loss: 3.8874006271362305
Validation loss: 2.586060611150598

Epoch: 6| Step: 9
Training loss: 2.81375789642334
Validation loss: 2.588536326603223

Epoch: 6| Step: 10
Training loss: 2.3898138999938965
Validation loss: 2.591981610944194

Epoch: 6| Step: 11
Training loss: 2.544802188873291
Validation loss: 2.5931426555879655

Epoch: 6| Step: 12
Training loss: 2.9088921546936035
Validation loss: 2.5957843821535826

Epoch: 6| Step: 13
Training loss: 2.9576785564422607
Validation loss: 2.5946510171377533

Epoch: 46| Step: 0
Training loss: 3.5996437072753906
Validation loss: 2.592083751514394

Epoch: 6| Step: 1
Training loss: 3.0792651176452637
Validation loss: 2.5913584924513295

Epoch: 6| Step: 2
Training loss: 2.9305734634399414
Validation loss: 2.5889080801317768

Epoch: 6| Step: 3
Training loss: 2.936316728591919
Validation loss: 2.5857616624524518

Epoch: 6| Step: 4
Training loss: 2.7801365852355957
Validation loss: 2.5854201829561623

Epoch: 6| Step: 5
Training loss: 2.5045089721679688
Validation loss: 2.588904560253184

Epoch: 6| Step: 6
Training loss: 3.2113776206970215
Validation loss: 2.5830740005739274

Epoch: 6| Step: 7
Training loss: 3.3010144233703613
Validation loss: 2.584636006304013

Epoch: 6| Step: 8
Training loss: 2.9409074783325195
Validation loss: 2.5828781999567503

Epoch: 6| Step: 9
Training loss: 1.859097957611084
Validation loss: 2.5850995304763957

Epoch: 6| Step: 10
Training loss: 2.6075265407562256
Validation loss: 2.586335197571785

Epoch: 6| Step: 11
Training loss: 1.926384687423706
Validation loss: 2.5860302371363484

Epoch: 6| Step: 12
Training loss: 2.1661696434020996
Validation loss: 2.5930730091628207

Epoch: 6| Step: 13
Training loss: 3.3487322330474854
Validation loss: 2.595203843168033

Epoch: 47| Step: 0
Training loss: 3.196171283721924
Validation loss: 2.5954101572754564

Epoch: 6| Step: 1
Training loss: 2.9701778888702393
Validation loss: 2.5950602857015466

Epoch: 6| Step: 2
Training loss: 2.7209982872009277
Validation loss: 2.5890990611045592

Epoch: 6| Step: 3
Training loss: 3.5285520553588867
Validation loss: 2.5857302886183544

Epoch: 6| Step: 4
Training loss: 3.303187131881714
Validation loss: 2.5843104213796635

Epoch: 6| Step: 5
Training loss: 2.910966396331787
Validation loss: 2.582386874383496

Epoch: 6| Step: 6
Training loss: 2.632732629776001
Validation loss: 2.5857840558534027

Epoch: 6| Step: 7
Training loss: 2.3025412559509277
Validation loss: 2.583561681932019

Epoch: 6| Step: 8
Training loss: 2.0681746006011963
Validation loss: 2.5824380536233225

Epoch: 6| Step: 9
Training loss: 3.1744320392608643
Validation loss: 2.5807044685527845

Epoch: 6| Step: 10
Training loss: 2.8483974933624268
Validation loss: 2.575992218909725

Epoch: 6| Step: 11
Training loss: 2.122459650039673
Validation loss: 2.5719845961498957

Epoch: 6| Step: 12
Training loss: 2.632650375366211
Validation loss: 2.572201596793308

Epoch: 6| Step: 13
Training loss: 2.2816178798675537
Validation loss: 2.5744483214552685

Epoch: 48| Step: 0
Training loss: 2.9738869667053223
Validation loss: 2.581409328727312

Epoch: 6| Step: 1
Training loss: 2.7565665245056152
Validation loss: 2.5881433871484574

Epoch: 6| Step: 2
Training loss: 3.015918254852295
Validation loss: 2.5995657931091967

Epoch: 6| Step: 3
Training loss: 2.3965601921081543
Validation loss: 2.5799075147157073

Epoch: 6| Step: 4
Training loss: 2.818558931350708
Validation loss: 2.571211579025433

Epoch: 6| Step: 5
Training loss: 2.4714956283569336
Validation loss: 2.570442868817237

Epoch: 6| Step: 6
Training loss: 2.8503479957580566
Validation loss: 2.568768480772613

Epoch: 6| Step: 7
Training loss: 2.868539571762085
Validation loss: 2.5682379045794086

Epoch: 6| Step: 8
Training loss: 3.2732090950012207
Validation loss: 2.5653833394409506

Epoch: 6| Step: 9
Training loss: 3.0282578468322754
Validation loss: 2.566544730176208

Epoch: 6| Step: 10
Training loss: 1.9670723676681519
Validation loss: 2.5694126262459704

Epoch: 6| Step: 11
Training loss: 2.0653676986694336
Validation loss: 2.5678600675316265

Epoch: 6| Step: 12
Training loss: 3.187689781188965
Validation loss: 2.5718598058146815

Epoch: 6| Step: 13
Training loss: 3.3878397941589355
Validation loss: 2.5724832575808287

Epoch: 49| Step: 0
Training loss: 2.552081823348999
Validation loss: 2.5722632741415374

Epoch: 6| Step: 1
Training loss: 3.0249457359313965
Validation loss: 2.5665017353591097

Epoch: 6| Step: 2
Training loss: 2.686446189880371
Validation loss: 2.567754143027849

Epoch: 6| Step: 3
Training loss: 2.9611480236053467
Validation loss: 2.569196326758272

Epoch: 6| Step: 4
Training loss: 2.8640904426574707
Validation loss: 2.5678374562212216

Epoch: 6| Step: 5
Training loss: 1.9675838947296143
Validation loss: 2.574805069995183

Epoch: 6| Step: 6
Training loss: 2.5587270259857178
Validation loss: 2.5708187075071436

Epoch: 6| Step: 7
Training loss: 2.8606743812561035
Validation loss: 2.5770570565295476

Epoch: 6| Step: 8
Training loss: 2.086454391479492
Validation loss: 2.572480232484879

Epoch: 6| Step: 9
Training loss: 2.6750824451446533
Validation loss: 2.5674446718667143

Epoch: 6| Step: 10
Training loss: 3.5791749954223633
Validation loss: 2.561895403810727

Epoch: 6| Step: 11
Training loss: 3.1255481243133545
Validation loss: 2.561569049794187

Epoch: 6| Step: 12
Training loss: 2.7894511222839355
Validation loss: 2.564104410909837

Epoch: 6| Step: 13
Training loss: 3.0769753456115723
Validation loss: 2.5636776903624177

Epoch: 50| Step: 0
Training loss: 3.555715799331665
Validation loss: 2.571251130873157

Epoch: 6| Step: 1
Training loss: 2.9768729209899902
Validation loss: 2.561777389177712

Epoch: 6| Step: 2
Training loss: 2.146975517272949
Validation loss: 2.557837232466667

Epoch: 6| Step: 3
Training loss: 2.5015201568603516
Validation loss: 2.5636083285013833

Epoch: 6| Step: 4
Training loss: 2.8405961990356445
Validation loss: 2.559538907902215

Epoch: 6| Step: 5
Training loss: 2.270892858505249
Validation loss: 2.5603917439778647

Epoch: 6| Step: 6
Training loss: 2.8128137588500977
Validation loss: 2.556553312527236

Epoch: 6| Step: 7
Training loss: 2.5726194381713867
Validation loss: 2.5583335430391374

Epoch: 6| Step: 8
Training loss: 2.5653235912323
Validation loss: 2.556370068621892

Epoch: 6| Step: 9
Training loss: 3.3326425552368164
Validation loss: 2.558859214987806

Epoch: 6| Step: 10
Training loss: 3.4010066986083984
Validation loss: 2.553632656733195

Epoch: 6| Step: 11
Training loss: 2.8872756958007812
Validation loss: 2.5564527562869492

Epoch: 6| Step: 12
Training loss: 2.1401031017303467
Validation loss: 2.554235350701117

Epoch: 6| Step: 13
Training loss: 2.5533604621887207
Validation loss: 2.5555392439647386

Epoch: 51| Step: 0
Training loss: 2.8761982917785645
Validation loss: 2.5556862200460126

Epoch: 6| Step: 1
Training loss: 3.142733335494995
Validation loss: 2.5539389233435354

Epoch: 6| Step: 2
Training loss: 3.6531829833984375
Validation loss: 2.552071932823427

Epoch: 6| Step: 3
Training loss: 2.0097169876098633
Validation loss: 2.5514011280511015

Epoch: 6| Step: 4
Training loss: 2.149819850921631
Validation loss: 2.554948450416647

Epoch: 6| Step: 5
Training loss: 3.4553403854370117
Validation loss: 2.5546893535121793

Epoch: 6| Step: 6
Training loss: 2.750666856765747
Validation loss: 2.5524859838588263

Epoch: 6| Step: 7
Training loss: 2.647484302520752
Validation loss: 2.5561678589031263

Epoch: 6| Step: 8
Training loss: 2.9118685722351074
Validation loss: 2.5578098040755077

Epoch: 6| Step: 9
Training loss: 2.4447922706604004
Validation loss: 2.5582918120968725

Epoch: 6| Step: 10
Training loss: 2.288264513015747
Validation loss: 2.5566979223682034

Epoch: 6| Step: 11
Training loss: 2.6893138885498047
Validation loss: 2.559752841149607

Epoch: 6| Step: 12
Training loss: 3.4201087951660156
Validation loss: 2.555466695498395

Epoch: 6| Step: 13
Training loss: 1.5736967325210571
Validation loss: 2.5542154568497852

Epoch: 52| Step: 0
Training loss: 2.3646090030670166
Validation loss: 2.5517119951145624

Epoch: 6| Step: 1
Training loss: 2.6697609424591064
Validation loss: 2.5527184676098567

Epoch: 6| Step: 2
Training loss: 3.1428885459899902
Validation loss: 2.5494541916795956

Epoch: 6| Step: 3
Training loss: 3.385132312774658
Validation loss: 2.547695744422174

Epoch: 6| Step: 4
Training loss: 3.0658841133117676
Validation loss: 2.550811234340873

Epoch: 6| Step: 5
Training loss: 2.339036464691162
Validation loss: 2.549352735601446

Epoch: 6| Step: 6
Training loss: 2.7427241802215576
Validation loss: 2.5472445411066853

Epoch: 6| Step: 7
Training loss: 2.435534954071045
Validation loss: 2.545097876620549

Epoch: 6| Step: 8
Training loss: 3.208029270172119
Validation loss: 2.5477997141499675

Epoch: 6| Step: 9
Training loss: 2.698058605194092
Validation loss: 2.5478090342654975

Epoch: 6| Step: 10
Training loss: 2.1910462379455566
Validation loss: 2.550145015921644

Epoch: 6| Step: 11
Training loss: 2.7909646034240723
Validation loss: 2.5477164022384153

Epoch: 6| Step: 12
Training loss: 2.8769431114196777
Validation loss: 2.541531193640924

Epoch: 6| Step: 13
Training loss: 2.516072988510132
Validation loss: 2.544094890676519

Epoch: 53| Step: 0
Training loss: 2.6558475494384766
Validation loss: 2.54514810603152

Epoch: 6| Step: 1
Training loss: 2.6455955505371094
Validation loss: 2.5454829277530795

Epoch: 6| Step: 2
Training loss: 2.494645595550537
Validation loss: 2.5482529670961442

Epoch: 6| Step: 3
Training loss: 2.4126672744750977
Validation loss: 2.55248507120276

Epoch: 6| Step: 4
Training loss: 2.983356475830078
Validation loss: 2.554804922432028

Epoch: 6| Step: 5
Training loss: 2.9131484031677246
Validation loss: 2.5837017105471705

Epoch: 6| Step: 6
Training loss: 2.9974372386932373
Validation loss: 2.6109896859815045

Epoch: 6| Step: 7
Training loss: 2.708376407623291
Validation loss: 2.6011824736031155

Epoch: 6| Step: 8
Training loss: 3.2478551864624023
Validation loss: 2.5953282566480738

Epoch: 6| Step: 9
Training loss: 2.395901679992676
Validation loss: 2.567650225854689

Epoch: 6| Step: 10
Training loss: 3.131058692932129
Validation loss: 2.543369711086314

Epoch: 6| Step: 11
Training loss: 3.024094343185425
Validation loss: 2.5370630500137166

Epoch: 6| Step: 12
Training loss: 2.4516091346740723
Validation loss: 2.539402554112096

Epoch: 6| Step: 13
Training loss: 2.358344078063965
Validation loss: 2.5550522035168064

Epoch: 54| Step: 0
Training loss: 4.173100471496582
Validation loss: 2.5621529497126097

Epoch: 6| Step: 1
Training loss: 2.553016424179077
Validation loss: 2.5649218149082635

Epoch: 6| Step: 2
Training loss: 2.6170220375061035
Validation loss: 2.5632853213176934

Epoch: 6| Step: 3
Training loss: 2.7446799278259277
Validation loss: 2.569600910268804

Epoch: 6| Step: 4
Training loss: 2.5127663612365723
Validation loss: 2.5694431592059392

Epoch: 6| Step: 5
Training loss: 2.618804454803467
Validation loss: 2.569710364905737

Epoch: 6| Step: 6
Training loss: 3.0537185668945312
Validation loss: 2.584770033436437

Epoch: 6| Step: 7
Training loss: 1.9529359340667725
Validation loss: 2.568513847166492

Epoch: 6| Step: 8
Training loss: 2.474165916442871
Validation loss: 2.5491978301796863

Epoch: 6| Step: 9
Training loss: 2.6814823150634766
Validation loss: 2.549487767680999

Epoch: 6| Step: 10
Training loss: 3.495565176010132
Validation loss: 2.554073387576688

Epoch: 6| Step: 11
Training loss: 2.931166410446167
Validation loss: 2.5518840564194547

Epoch: 6| Step: 12
Training loss: 2.437163829803467
Validation loss: 2.55250294234163

Epoch: 6| Step: 13
Training loss: 2.029287099838257
Validation loss: 2.554692973372757

Epoch: 55| Step: 0
Training loss: 2.7493531703948975
Validation loss: 2.5463924613050235

Epoch: 6| Step: 1
Training loss: 3.0168533325195312
Validation loss: 2.5438133003891155

Epoch: 6| Step: 2
Training loss: 2.6345739364624023
Validation loss: 2.5465820732937066

Epoch: 6| Step: 3
Training loss: 3.0544257164001465
Validation loss: 2.541621423536731

Epoch: 6| Step: 4
Training loss: 2.10076904296875
Validation loss: 2.5372767333061463

Epoch: 6| Step: 5
Training loss: 2.5435831546783447
Validation loss: 2.536075476677187

Epoch: 6| Step: 6
Training loss: 2.7312214374542236
Validation loss: 2.5423567935984623

Epoch: 6| Step: 7
Training loss: 3.8268165588378906
Validation loss: 2.5452833303841214

Epoch: 6| Step: 8
Training loss: 1.6475014686584473
Validation loss: 2.5500838654015654

Epoch: 6| Step: 9
Training loss: 1.9784748554229736
Validation loss: 2.559610523203368

Epoch: 6| Step: 10
Training loss: 3.1039717197418213
Validation loss: 2.5578138571913525

Epoch: 6| Step: 11
Training loss: 3.288710355758667
Validation loss: 2.5515475196223103

Epoch: 6| Step: 12
Training loss: 2.577702522277832
Validation loss: 2.5480102082734466

Epoch: 6| Step: 13
Training loss: 3.2490122318267822
Validation loss: 2.5445208241862636

Epoch: 56| Step: 0
Training loss: 2.1246800422668457
Validation loss: 2.535230664796727

Epoch: 6| Step: 1
Training loss: 2.1458637714385986
Validation loss: 2.53584522585715

Epoch: 6| Step: 2
Training loss: 3.100660800933838
Validation loss: 2.5290511141541185

Epoch: 6| Step: 3
Training loss: 2.430039882659912
Validation loss: 2.528553106451547

Epoch: 6| Step: 4
Training loss: 3.0015904903411865
Validation loss: 2.536470919527033

Epoch: 6| Step: 5
Training loss: 3.1007080078125
Validation loss: 2.5489809154182352

Epoch: 6| Step: 6
Training loss: 3.4083380699157715
Validation loss: 2.5658504578375045

Epoch: 6| Step: 7
Training loss: 3.369466781616211
Validation loss: 2.5527844557198147

Epoch: 6| Step: 8
Training loss: 2.762167453765869
Validation loss: 2.550862140552972

Epoch: 6| Step: 9
Training loss: 2.42509126663208
Validation loss: 2.549814321661508

Epoch: 6| Step: 10
Training loss: 2.43174409866333
Validation loss: 2.5463347588815997

Epoch: 6| Step: 11
Training loss: 2.4915177822113037
Validation loss: 2.5456871089114936

Epoch: 6| Step: 12
Training loss: 2.866522789001465
Validation loss: 2.550885587610224

Epoch: 6| Step: 13
Training loss: 2.560776710510254
Validation loss: 2.545377867196196

Epoch: 57| Step: 0
Training loss: 3.0713086128234863
Validation loss: 2.5406561884828793

Epoch: 6| Step: 1
Training loss: 3.0006184577941895
Validation loss: 2.533072507509621

Epoch: 6| Step: 2
Training loss: 2.1934523582458496
Validation loss: 2.5295897042879494

Epoch: 6| Step: 3
Training loss: 2.8629093170166016
Validation loss: 2.5315250965856735

Epoch: 6| Step: 4
Training loss: 3.400381088256836
Validation loss: 2.538188995853547

Epoch: 6| Step: 5
Training loss: 2.881646156311035
Validation loss: 2.537158530245545

Epoch: 6| Step: 6
Training loss: 2.765324115753174
Validation loss: 2.538418305817471

Epoch: 6| Step: 7
Training loss: 2.240867853164673
Validation loss: 2.5402801780290503

Epoch: 6| Step: 8
Training loss: 2.433227062225342
Validation loss: 2.5379091116689865

Epoch: 6| Step: 9
Training loss: 2.8696274757385254
Validation loss: 2.5362088295721237

Epoch: 6| Step: 10
Training loss: 2.5904335975646973
Validation loss: 2.537572422335225

Epoch: 6| Step: 11
Training loss: 2.6479592323303223
Validation loss: 2.5332885352514123

Epoch: 6| Step: 12
Training loss: 3.1832447052001953
Validation loss: 2.532551514205112

Epoch: 6| Step: 13
Training loss: 1.6914668083190918
Validation loss: 2.535777384235013

Epoch: 58| Step: 0
Training loss: 3.4019415378570557
Validation loss: 2.534131949947726

Epoch: 6| Step: 1
Training loss: 2.251129627227783
Validation loss: 2.5293290486899753

Epoch: 6| Step: 2
Training loss: 2.6480631828308105
Validation loss: 2.5274949304519163

Epoch: 6| Step: 3
Training loss: 2.2691431045532227
Validation loss: 2.5244694679014144

Epoch: 6| Step: 4
Training loss: 3.7515878677368164
Validation loss: 2.520994934984433

Epoch: 6| Step: 5
Training loss: 2.769026756286621
Validation loss: 2.5215189123666413

Epoch: 6| Step: 6
Training loss: 2.7822046279907227
Validation loss: 2.5265690459999988

Epoch: 6| Step: 7
Training loss: 3.1146793365478516
Validation loss: 2.532168065347979

Epoch: 6| Step: 8
Training loss: 2.545719623565674
Validation loss: 2.5612132472376667

Epoch: 6| Step: 9
Training loss: 2.6579349040985107
Validation loss: 2.57043122219783

Epoch: 6| Step: 10
Training loss: 2.918303966522217
Validation loss: 2.575548443742978

Epoch: 6| Step: 11
Training loss: 2.4569592475891113
Validation loss: 2.5483513826965005

Epoch: 6| Step: 12
Training loss: 1.8612525463104248
Validation loss: 2.5344348184524046

Epoch: 6| Step: 13
Training loss: 2.8719921112060547
Validation loss: 2.538382309739308

Epoch: 59| Step: 0
Training loss: 3.3271701335906982
Validation loss: 2.5393220583597818

Epoch: 6| Step: 1
Training loss: 2.2854630947113037
Validation loss: 2.5425351306956303

Epoch: 6| Step: 2
Training loss: 2.9558157920837402
Validation loss: 2.5463504739986953

Epoch: 6| Step: 3
Training loss: 2.5252609252929688
Validation loss: 2.5465584621634534

Epoch: 6| Step: 4
Training loss: 2.7648873329162598
Validation loss: 2.5435060788226385

Epoch: 6| Step: 5
Training loss: 2.4422502517700195
Validation loss: 2.5392963476078485

Epoch: 6| Step: 6
Training loss: 3.052980422973633
Validation loss: 2.546533692267633

Epoch: 6| Step: 7
Training loss: 1.9703513383865356
Validation loss: 2.5386935357124574

Epoch: 6| Step: 8
Training loss: 2.6859965324401855
Validation loss: 2.528427562405986

Epoch: 6| Step: 9
Training loss: 2.747213363647461
Validation loss: 2.530533206078314

Epoch: 6| Step: 10
Training loss: 2.8000175952911377
Validation loss: 2.522370046184909

Epoch: 6| Step: 11
Training loss: 2.1296749114990234
Validation loss: 2.5265703432021605

Epoch: 6| Step: 12
Training loss: 3.3656527996063232
Validation loss: 2.5226954901090233

Epoch: 6| Step: 13
Training loss: 3.428677558898926
Validation loss: 2.515826315008184

Epoch: 60| Step: 0
Training loss: 3.127133846282959
Validation loss: 2.5206899642944336

Epoch: 6| Step: 1
Training loss: 2.5969996452331543
Validation loss: 2.5277395812414025

Epoch: 6| Step: 2
Training loss: 3.3624958992004395
Validation loss: 2.5429571572170464

Epoch: 6| Step: 3
Training loss: 2.9547739028930664
Validation loss: 2.586290944007135

Epoch: 6| Step: 4
Training loss: 3.3269662857055664
Validation loss: 2.5983924609358593

Epoch: 6| Step: 5
Training loss: 2.8742318153381348
Validation loss: 2.571223343572309

Epoch: 6| Step: 6
Training loss: 2.5596706867218018
Validation loss: 2.5469369939578477

Epoch: 6| Step: 7
Training loss: 2.5022339820861816
Validation loss: 2.530993725663872

Epoch: 6| Step: 8
Training loss: 1.9289982318878174
Validation loss: 2.5255410568688506

Epoch: 6| Step: 9
Training loss: 2.2538187503814697
Validation loss: 2.5248638968313895

Epoch: 6| Step: 10
Training loss: 3.2305710315704346
Validation loss: 2.528077535731818

Epoch: 6| Step: 11
Training loss: 2.1428864002227783
Validation loss: 2.530718744442027

Epoch: 6| Step: 12
Training loss: 2.7823572158813477
Validation loss: 2.533745388830862

Epoch: 6| Step: 13
Training loss: 2.309866189956665
Validation loss: 2.542564762535916

Epoch: 61| Step: 0
Training loss: 2.3703227043151855
Validation loss: 2.550252036381793

Epoch: 6| Step: 1
Training loss: 2.6997628211975098
Validation loss: 2.5498510765772995

Epoch: 6| Step: 2
Training loss: 2.2870521545410156
Validation loss: 2.56947914502954

Epoch: 6| Step: 3
Training loss: 3.2196226119995117
Validation loss: 2.5541883335318616

Epoch: 6| Step: 4
Training loss: 2.9602599143981934
Validation loss: 2.552209349088771

Epoch: 6| Step: 5
Training loss: 3.8112354278564453
Validation loss: 2.6034250669581915

Epoch: 6| Step: 6
Training loss: 2.570641040802002
Validation loss: 2.6038662797661236

Epoch: 6| Step: 7
Training loss: 2.361774444580078
Validation loss: 2.583069419348112

Epoch: 6| Step: 8
Training loss: 2.1950066089630127
Validation loss: 2.550167276013282

Epoch: 6| Step: 9
Training loss: 2.4765419960021973
Validation loss: 2.5262031093720467

Epoch: 6| Step: 10
Training loss: 3.4022598266601562
Validation loss: 2.52727940774733

Epoch: 6| Step: 11
Training loss: 3.164243221282959
Validation loss: 2.525294519239856

Epoch: 6| Step: 12
Training loss: 2.2010385990142822
Validation loss: 2.527404567246796

Epoch: 6| Step: 13
Training loss: 2.483783721923828
Validation loss: 2.5404402158593618

Epoch: 62| Step: 0
Training loss: 2.7928717136383057
Validation loss: 2.532486720751691

Epoch: 6| Step: 1
Training loss: 2.2668137550354004
Validation loss: 2.5212122317283385

Epoch: 6| Step: 2
Training loss: 2.5177628993988037
Validation loss: 2.5184803649943364

Epoch: 6| Step: 3
Training loss: 2.3574228286743164
Validation loss: 2.5180899404710337

Epoch: 6| Step: 4
Training loss: 2.2051150798797607
Validation loss: 2.5158661206563315

Epoch: 6| Step: 5
Training loss: 3.03094482421875
Validation loss: 2.5122123636225218

Epoch: 6| Step: 6
Training loss: 3.3399746417999268
Validation loss: 2.515962867326634

Epoch: 6| Step: 7
Training loss: 3.009518623352051
Validation loss: 2.5136931045081026

Epoch: 6| Step: 8
Training loss: 2.9624598026275635
Validation loss: 2.5135235094255015

Epoch: 6| Step: 9
Training loss: 2.5038514137268066
Validation loss: 2.508783976236979

Epoch: 6| Step: 10
Training loss: 2.5809803009033203
Validation loss: 2.511919916317027

Epoch: 6| Step: 11
Training loss: 2.733480453491211
Validation loss: 2.522289478650657

Epoch: 6| Step: 12
Training loss: 2.7206151485443115
Validation loss: 2.528586797816779

Epoch: 6| Step: 13
Training loss: 3.2946267127990723
Validation loss: 2.528063351108182

Epoch: 63| Step: 0
Training loss: 2.411181926727295
Validation loss: 2.5277209512649046

Epoch: 6| Step: 1
Training loss: 3.55466365814209
Validation loss: 2.5290202786845546

Epoch: 6| Step: 2
Training loss: 2.7084739208221436
Validation loss: 2.5331246006873345

Epoch: 6| Step: 3
Training loss: 2.215291976928711
Validation loss: 2.525288615175473

Epoch: 6| Step: 4
Training loss: 2.0823473930358887
Validation loss: 2.530412050985521

Epoch: 6| Step: 5
Training loss: 2.523021697998047
Validation loss: 2.520742613782165

Epoch: 6| Step: 6
Training loss: 2.8824243545532227
Validation loss: 2.518442428240212

Epoch: 6| Step: 7
Training loss: 2.804546356201172
Validation loss: 2.5188186425034718

Epoch: 6| Step: 8
Training loss: 2.833958148956299
Validation loss: 2.517271872489683

Epoch: 6| Step: 9
Training loss: 3.799931049346924
Validation loss: 2.5179012667748237

Epoch: 6| Step: 10
Training loss: 2.268803358078003
Validation loss: 2.515112684619042

Epoch: 6| Step: 11
Training loss: 2.753337860107422
Validation loss: 2.514260071580128

Epoch: 6| Step: 12
Training loss: 2.455995559692383
Validation loss: 2.511385799736105

Epoch: 6| Step: 13
Training loss: 2.5281858444213867
Validation loss: 2.509367658245948

Epoch: 64| Step: 0
Training loss: 2.1821036338806152
Validation loss: 2.5091999294937297

Epoch: 6| Step: 1
Training loss: 2.5627095699310303
Validation loss: 2.510662991513488

Epoch: 6| Step: 2
Training loss: 2.700509548187256
Validation loss: 2.5150746478829333

Epoch: 6| Step: 3
Training loss: 3.0332820415496826
Validation loss: 2.5178681599196566

Epoch: 6| Step: 4
Training loss: 1.6435209512710571
Validation loss: 2.5127619774110856

Epoch: 6| Step: 5
Training loss: 3.5055925846099854
Validation loss: 2.5075278435983965

Epoch: 6| Step: 6
Training loss: 3.6067850589752197
Validation loss: 2.50548566028636

Epoch: 6| Step: 7
Training loss: 2.2031586170196533
Validation loss: 2.5066316179049912

Epoch: 6| Step: 8
Training loss: 2.4557809829711914
Validation loss: 2.5015016883932133

Epoch: 6| Step: 9
Training loss: 2.8336715698242188
Validation loss: 2.5061201895436933

Epoch: 6| Step: 10
Training loss: 2.4046597480773926
Validation loss: 2.499482516319521

Epoch: 6| Step: 11
Training loss: 3.512578010559082
Validation loss: 2.5091417733059136

Epoch: 6| Step: 12
Training loss: 3.100170612335205
Validation loss: 2.5129830478340067

Epoch: 6| Step: 13
Training loss: 1.7118878364562988
Validation loss: 2.528740313745314

Epoch: 65| Step: 0
Training loss: 2.7581892013549805
Validation loss: 2.558111244632352

Epoch: 6| Step: 1
Training loss: 2.750514507293701
Validation loss: 2.550641011166316

Epoch: 6| Step: 2
Training loss: 3.554022789001465
Validation loss: 2.5488417097317275

Epoch: 6| Step: 3
Training loss: 2.9824283123016357
Validation loss: 2.5226061267237507

Epoch: 6| Step: 4
Training loss: 2.091275691986084
Validation loss: 2.5073126849307807

Epoch: 6| Step: 5
Training loss: 2.9625046253204346
Validation loss: 2.4990861979863976

Epoch: 6| Step: 6
Training loss: 2.839804172515869
Validation loss: 2.4960950061839116

Epoch: 6| Step: 7
Training loss: 2.858889102935791
Validation loss: 2.4970356982241393

Epoch: 6| Step: 8
Training loss: 2.101421356201172
Validation loss: 2.497863179893904

Epoch: 6| Step: 9
Training loss: 2.6176517009735107
Validation loss: 2.4987406499924196

Epoch: 6| Step: 10
Training loss: 3.108661651611328
Validation loss: 2.497380365607559

Epoch: 6| Step: 11
Training loss: 2.604764461517334
Validation loss: 2.498234607840097

Epoch: 6| Step: 12
Training loss: 2.1173839569091797
Validation loss: 2.496006642618487

Epoch: 6| Step: 13
Training loss: 2.595505714416504
Validation loss: 2.4958252291525564

Epoch: 66| Step: 0
Training loss: 2.3772695064544678
Validation loss: 2.4923008795707458

Epoch: 6| Step: 1
Training loss: 3.574059009552002
Validation loss: 2.493997440543226

Epoch: 6| Step: 2
Training loss: 2.5567679405212402
Validation loss: 2.493020160223848

Epoch: 6| Step: 3
Training loss: 2.949841260910034
Validation loss: 2.492350088652744

Epoch: 6| Step: 4
Training loss: 3.4203813076019287
Validation loss: 2.494827401253485

Epoch: 6| Step: 5
Training loss: 2.8255529403686523
Validation loss: 2.493134647287348

Epoch: 6| Step: 6
Training loss: 2.4717941284179688
Validation loss: 2.491539260392548

Epoch: 6| Step: 7
Training loss: 2.1861572265625
Validation loss: 2.4938175088615826

Epoch: 6| Step: 8
Training loss: 1.725034236907959
Validation loss: 2.4946090175259497

Epoch: 6| Step: 9
Training loss: 2.779927968978882
Validation loss: 2.502894578441497

Epoch: 6| Step: 10
Training loss: 3.431987762451172
Validation loss: 2.5116884810950166

Epoch: 6| Step: 11
Training loss: 2.725156307220459
Validation loss: 2.5217123851981214

Epoch: 6| Step: 12
Training loss: 2.1394410133361816
Validation loss: 2.5220444792060444

Epoch: 6| Step: 13
Training loss: 2.6793370246887207
Validation loss: 2.515645016906082

Epoch: 67| Step: 0
Training loss: 2.572550058364868
Validation loss: 2.507914645697481

Epoch: 6| Step: 1
Training loss: 2.660895824432373
Validation loss: 2.4980388520866312

Epoch: 6| Step: 2
Training loss: 2.3739566802978516
Validation loss: 2.494061618722895

Epoch: 6| Step: 3
Training loss: 3.121046781539917
Validation loss: 2.489140154213034

Epoch: 6| Step: 4
Training loss: 2.1680006980895996
Validation loss: 2.4955193675974363

Epoch: 6| Step: 5
Training loss: 2.596874237060547
Validation loss: 2.4950240427447903

Epoch: 6| Step: 6
Training loss: 3.146761417388916
Validation loss: 2.4979439268830004

Epoch: 6| Step: 7
Training loss: 2.3746516704559326
Validation loss: 2.501046292243465

Epoch: 6| Step: 8
Training loss: 2.4036850929260254
Validation loss: 2.5013294476334766

Epoch: 6| Step: 9
Training loss: 3.0845465660095215
Validation loss: 2.5131180183861845

Epoch: 6| Step: 10
Training loss: 3.254749059677124
Validation loss: 2.518341020871234

Epoch: 6| Step: 11
Training loss: 2.8979334831237793
Validation loss: 2.5201665457858833

Epoch: 6| Step: 12
Training loss: 2.4360225200653076
Validation loss: 2.5093033852115756

Epoch: 6| Step: 13
Training loss: 2.5380373001098633
Validation loss: 2.5039920371065856

Epoch: 68| Step: 0
Training loss: 3.2519121170043945
Validation loss: 2.5106383908179497

Epoch: 6| Step: 1
Training loss: 3.1978774070739746
Validation loss: 2.508820867025724

Epoch: 6| Step: 2
Training loss: 2.67303466796875
Validation loss: 2.5119479471637356

Epoch: 6| Step: 3
Training loss: 2.648900032043457
Validation loss: 2.5060070278824016

Epoch: 6| Step: 4
Training loss: 2.444826364517212
Validation loss: 2.505886536772533

Epoch: 6| Step: 5
Training loss: 2.6642966270446777
Validation loss: 2.5148740301850023

Epoch: 6| Step: 6
Training loss: 2.7950546741485596
Validation loss: 2.5124869167163806

Epoch: 6| Step: 7
Training loss: 2.195891857147217
Validation loss: 2.5277559526505007

Epoch: 6| Step: 8
Training loss: 3.0729527473449707
Validation loss: 2.5772402183983916

Epoch: 6| Step: 9
Training loss: 2.6412086486816406
Validation loss: 2.5664969285329184

Epoch: 6| Step: 10
Training loss: 3.6792964935302734
Validation loss: 2.533839166805308

Epoch: 6| Step: 11
Training loss: 1.8077367544174194
Validation loss: 2.5217372755850516

Epoch: 6| Step: 12
Training loss: 2.2379229068756104
Validation loss: 2.5022348665422007

Epoch: 6| Step: 13
Training loss: 2.3883256912231445
Validation loss: 2.5009425865706576

Epoch: 69| Step: 0
Training loss: 2.842195749282837
Validation loss: 2.50018484105346

Epoch: 6| Step: 1
Training loss: 2.12817645072937
Validation loss: 2.50240409246055

Epoch: 6| Step: 2
Training loss: 1.857468843460083
Validation loss: 2.5051722090731383

Epoch: 6| Step: 3
Training loss: 3.239699125289917
Validation loss: 2.5128602468839256

Epoch: 6| Step: 4
Training loss: 2.6622793674468994
Validation loss: 2.5142138952850015

Epoch: 6| Step: 5
Training loss: 2.559760093688965
Validation loss: 2.5120000082959413

Epoch: 6| Step: 6
Training loss: 2.803804636001587
Validation loss: 2.517134363933276

Epoch: 6| Step: 7
Training loss: 2.352206230163574
Validation loss: 2.513940829102711

Epoch: 6| Step: 8
Training loss: 3.066929817199707
Validation loss: 2.5095522865172355

Epoch: 6| Step: 9
Training loss: 2.8368477821350098
Validation loss: 2.5150229366876746

Epoch: 6| Step: 10
Training loss: 3.0186901092529297
Validation loss: 2.5219472685167865

Epoch: 6| Step: 11
Training loss: 2.7386245727539062
Validation loss: 2.5165991475505214

Epoch: 6| Step: 12
Training loss: 3.1847310066223145
Validation loss: 2.5179343300481

Epoch: 6| Step: 13
Training loss: 2.273066997528076
Validation loss: 2.5100698676160587

Epoch: 70| Step: 0
Training loss: 2.32672119140625
Validation loss: 2.4966767475169194

Epoch: 6| Step: 1
Training loss: 1.7728136777877808
Validation loss: 2.48868711533085

Epoch: 6| Step: 2
Training loss: 2.8207175731658936
Validation loss: 2.4855819286838656

Epoch: 6| Step: 3
Training loss: 2.7409567832946777
Validation loss: 2.4858746246625016

Epoch: 6| Step: 4
Training loss: 2.471820116043091
Validation loss: 2.486737676846084

Epoch: 6| Step: 5
Training loss: 1.8112595081329346
Validation loss: 2.484677009685065

Epoch: 6| Step: 6
Training loss: 3.316927194595337
Validation loss: 2.487341711598058

Epoch: 6| Step: 7
Training loss: 3.8508663177490234
Validation loss: 2.48550594493907

Epoch: 6| Step: 8
Training loss: 2.907533645629883
Validation loss: 2.4886932424319688

Epoch: 6| Step: 9
Training loss: 3.1016554832458496
Validation loss: 2.4853320711402485

Epoch: 6| Step: 10
Training loss: 2.8037335872650146
Validation loss: 2.490211538089219

Epoch: 6| Step: 11
Training loss: 2.729954719543457
Validation loss: 2.488457061911142

Epoch: 6| Step: 12
Training loss: 2.047682523727417
Validation loss: 2.4948999471561883

Epoch: 6| Step: 13
Training loss: 3.172136068344116
Validation loss: 2.501788121397777

Epoch: 71| Step: 0
Training loss: 2.4598217010498047
Validation loss: 2.5184486476323937

Epoch: 6| Step: 1
Training loss: 3.2417798042297363
Validation loss: 2.5025624100879957

Epoch: 6| Step: 2
Training loss: 3.0998260974884033
Validation loss: 2.4918856056787635

Epoch: 6| Step: 3
Training loss: 2.3608272075653076
Validation loss: 2.488346386981267

Epoch: 6| Step: 4
Training loss: 2.5699639320373535
Validation loss: 2.4886505398699033

Epoch: 6| Step: 5
Training loss: 2.494673013687134
Validation loss: 2.489172625285323

Epoch: 6| Step: 6
Training loss: 2.449906349182129
Validation loss: 2.4900514336042505

Epoch: 6| Step: 7
Training loss: 2.282001495361328
Validation loss: 2.484795634464551

Epoch: 6| Step: 8
Training loss: 2.901073455810547
Validation loss: 2.4809399727852113

Epoch: 6| Step: 9
Training loss: 2.097808361053467
Validation loss: 2.4828811102015997

Epoch: 6| Step: 10
Training loss: 2.9869017601013184
Validation loss: 2.48395658821188

Epoch: 6| Step: 11
Training loss: 2.9434285163879395
Validation loss: 2.48294093531947

Epoch: 6| Step: 12
Training loss: 3.3923895359039307
Validation loss: 2.484512895666143

Epoch: 6| Step: 13
Training loss: 2.037533760070801
Validation loss: 2.4872243840207338

Epoch: 72| Step: 0
Training loss: 3.0149221420288086
Validation loss: 2.491036234363433

Epoch: 6| Step: 1
Training loss: 2.4501144886016846
Validation loss: 2.4867566221503803

Epoch: 6| Step: 2
Training loss: 2.289609670639038
Validation loss: 2.485527717938987

Epoch: 6| Step: 3
Training loss: 2.628871440887451
Validation loss: 2.487871052116476

Epoch: 6| Step: 4
Training loss: 2.0540826320648193
Validation loss: 2.478897766400409

Epoch: 6| Step: 5
Training loss: 1.9676471948623657
Validation loss: 2.480809373240317

Epoch: 6| Step: 6
Training loss: 2.7339653968811035
Validation loss: 2.4833182545118433

Epoch: 6| Step: 7
Training loss: 2.6656768321990967
Validation loss: 2.4936948924936275

Epoch: 6| Step: 8
Training loss: 3.5381879806518555
Validation loss: 2.513479745516213

Epoch: 6| Step: 9
Training loss: 3.1006813049316406
Validation loss: 2.541732822695086

Epoch: 6| Step: 10
Training loss: 2.7748849391937256
Validation loss: 2.5512546672615954

Epoch: 6| Step: 11
Training loss: 2.818387508392334
Validation loss: 2.56293478960632

Epoch: 6| Step: 12
Training loss: 2.773801803588867
Validation loss: 2.5265496084767003

Epoch: 6| Step: 13
Training loss: 3.063936471939087
Validation loss: 2.4925692440361105

Epoch: 73| Step: 0
Training loss: 2.87225341796875
Validation loss: 2.4781920756063154

Epoch: 6| Step: 1
Training loss: 2.9378039836883545
Validation loss: 2.480161859143165

Epoch: 6| Step: 2
Training loss: 3.294796943664551
Validation loss: 2.4727980654726744

Epoch: 6| Step: 3
Training loss: 2.8463938236236572
Validation loss: 2.4735180331814672

Epoch: 6| Step: 4
Training loss: 2.131300210952759
Validation loss: 2.4781928652076313

Epoch: 6| Step: 5
Training loss: 2.469093084335327
Validation loss: 2.47626970916666

Epoch: 6| Step: 6
Training loss: 2.5857226848602295
Validation loss: 2.479472978140718

Epoch: 6| Step: 7
Training loss: 2.8987197875976562
Validation loss: 2.477023204167684

Epoch: 6| Step: 8
Training loss: 2.7185721397399902
Validation loss: 2.478245166040236

Epoch: 6| Step: 9
Training loss: 2.6837754249572754
Validation loss: 2.473728051749609

Epoch: 6| Step: 10
Training loss: 2.703033685684204
Validation loss: 2.4736640222610964

Epoch: 6| Step: 11
Training loss: 3.0802671909332275
Validation loss: 2.471468835748652

Epoch: 6| Step: 12
Training loss: 2.2493836879730225
Validation loss: 2.47625256353809

Epoch: 6| Step: 13
Training loss: 1.6553984880447388
Validation loss: 2.4738137029832408

Epoch: 74| Step: 0
Training loss: 2.461013078689575
Validation loss: 2.476678043283442

Epoch: 6| Step: 1
Training loss: 3.003251075744629
Validation loss: 2.4761896441059728

Epoch: 6| Step: 2
Training loss: 2.86995267868042
Validation loss: 2.4782113849475818

Epoch: 6| Step: 3
Training loss: 2.1611108779907227
Validation loss: 2.488036378737419

Epoch: 6| Step: 4
Training loss: 2.287667751312256
Validation loss: 2.486249654523788

Epoch: 6| Step: 5
Training loss: 2.832319974899292
Validation loss: 2.488053837130147

Epoch: 6| Step: 6
Training loss: 3.5400161743164062
Validation loss: 2.496634793537919

Epoch: 6| Step: 7
Training loss: 2.709855079650879
Validation loss: 2.4988217610184864

Epoch: 6| Step: 8
Training loss: 2.5053505897521973
Validation loss: 2.5041941904252574

Epoch: 6| Step: 9
Training loss: 2.1373794078826904
Validation loss: 2.503785087216285

Epoch: 6| Step: 10
Training loss: 3.2080492973327637
Validation loss: 2.5019461416429087

Epoch: 6| Step: 11
Training loss: 2.6701269149780273
Validation loss: 2.5015529586422827

Epoch: 6| Step: 12
Training loss: 2.3969264030456543
Validation loss: 2.500017217410508

Epoch: 6| Step: 13
Training loss: 2.725736141204834
Validation loss: 2.4867714015386437

Epoch: 75| Step: 0
Training loss: 3.145785093307495
Validation loss: 2.478306375524049

Epoch: 6| Step: 1
Training loss: 2.69113826751709
Validation loss: 2.4712196114242717

Epoch: 6| Step: 2
Training loss: 2.649472713470459
Validation loss: 2.4710246234811764

Epoch: 6| Step: 3
Training loss: 1.9701751470565796
Validation loss: 2.4711870839518886

Epoch: 6| Step: 4
Training loss: 2.5526180267333984
Validation loss: 2.4758656768388647

Epoch: 6| Step: 5
Training loss: 3.7097344398498535
Validation loss: 2.476461838650447

Epoch: 6| Step: 6
Training loss: 1.6499989032745361
Validation loss: 2.483607122975011

Epoch: 6| Step: 7
Training loss: 2.3361544609069824
Validation loss: 2.476740829406246

Epoch: 6| Step: 8
Training loss: 2.677621364593506
Validation loss: 2.4710182656524

Epoch: 6| Step: 9
Training loss: 2.3516292572021484
Validation loss: 2.471245499067409

Epoch: 6| Step: 10
Training loss: 2.9814796447753906
Validation loss: 2.468182445854269

Epoch: 6| Step: 11
Training loss: 2.4359490871429443
Validation loss: 2.4675517876942954

Epoch: 6| Step: 12
Training loss: 3.219194173812866
Validation loss: 2.470948388499598

Epoch: 6| Step: 13
Training loss: 3.6399214267730713
Validation loss: 2.466561422553114

Epoch: 76| Step: 0
Training loss: 2.7072839736938477
Validation loss: 2.474151906146798

Epoch: 6| Step: 1
Training loss: 2.5359110832214355
Validation loss: 2.475351672018728

Epoch: 6| Step: 2
Training loss: 2.5755558013916016
Validation loss: 2.4769998263287287

Epoch: 6| Step: 3
Training loss: 2.5103344917297363
Validation loss: 2.479929816338324

Epoch: 6| Step: 4
Training loss: 2.9194889068603516
Validation loss: 2.4782029505698913

Epoch: 6| Step: 5
Training loss: 2.7541236877441406
Validation loss: 2.4900412995328187

Epoch: 6| Step: 6
Training loss: 2.6022348403930664
Validation loss: 2.491080179009386

Epoch: 6| Step: 7
Training loss: 2.598085880279541
Validation loss: 2.4984372597868725

Epoch: 6| Step: 8
Training loss: 2.9865646362304688
Validation loss: 2.4904626518167476

Epoch: 6| Step: 9
Training loss: 2.5738039016723633
Validation loss: 2.4941804075753815

Epoch: 6| Step: 10
Training loss: 2.9330923557281494
Validation loss: 2.480613736696141

Epoch: 6| Step: 11
Training loss: 2.6243691444396973
Validation loss: 2.4785466360789474

Epoch: 6| Step: 12
Training loss: 2.8371942043304443
Validation loss: 2.4689540375945387

Epoch: 6| Step: 13
Training loss: 2.0253405570983887
Validation loss: 2.466346089557935

Epoch: 77| Step: 0
Training loss: 2.074828863143921
Validation loss: 2.4633260132164083

Epoch: 6| Step: 1
Training loss: 2.492483615875244
Validation loss: 2.4630880227652927

Epoch: 6| Step: 2
Training loss: 2.8871989250183105
Validation loss: 2.462883985170754

Epoch: 6| Step: 3
Training loss: 3.248779535293579
Validation loss: 2.466153214054723

Epoch: 6| Step: 4
Training loss: 2.354268789291382
Validation loss: 2.4685064003031743

Epoch: 6| Step: 5
Training loss: 3.538288116455078
Validation loss: 2.4751674282935356

Epoch: 6| Step: 6
Training loss: 2.431864023208618
Validation loss: 2.466161694577945

Epoch: 6| Step: 7
Training loss: 2.839621067047119
Validation loss: 2.4653014444535777

Epoch: 6| Step: 8
Training loss: 2.4922330379486084
Validation loss: 2.4660705520260717

Epoch: 6| Step: 9
Training loss: 2.7161669731140137
Validation loss: 2.46133767661228

Epoch: 6| Step: 10
Training loss: 2.7034692764282227
Validation loss: 2.463644281510384

Epoch: 6| Step: 11
Training loss: 3.1194772720336914
Validation loss: 2.4675456734113794

Epoch: 6| Step: 12
Training loss: 2.0432229042053223
Validation loss: 2.4845577773227485

Epoch: 6| Step: 13
Training loss: 2.353224754333496
Validation loss: 2.4938562429079445

Epoch: 78| Step: 0
Training loss: 2.18061900138855
Validation loss: 2.5024928713357575

Epoch: 6| Step: 1
Training loss: 1.967839002609253
Validation loss: 2.488086321020639

Epoch: 6| Step: 2
Training loss: 2.77655029296875
Validation loss: 2.4726243378013693

Epoch: 6| Step: 3
Training loss: 2.703735828399658
Validation loss: 2.4615767848107124

Epoch: 6| Step: 4
Training loss: 3.2595577239990234
Validation loss: 2.4520705694793374

Epoch: 6| Step: 5
Training loss: 3.1064443588256836
Validation loss: 2.4479994684137325

Epoch: 6| Step: 6
Training loss: 2.396315097808838
Validation loss: 2.4508321900521555

Epoch: 6| Step: 7
Training loss: 2.8669075965881348
Validation loss: 2.4520237433013095

Epoch: 6| Step: 8
Training loss: 3.2578141689300537
Validation loss: 2.452013292620259

Epoch: 6| Step: 9
Training loss: 3.326183319091797
Validation loss: 2.4555690416725735

Epoch: 6| Step: 10
Training loss: 2.2933857440948486
Validation loss: 2.446481661130023

Epoch: 6| Step: 11
Training loss: 2.732795238494873
Validation loss: 2.4503396967405915

Epoch: 6| Step: 12
Training loss: 2.4667744636535645
Validation loss: 2.4511405242386686

Epoch: 6| Step: 13
Training loss: 1.9518394470214844
Validation loss: 2.447603766636182

Epoch: 79| Step: 0
Training loss: 2.4430503845214844
Validation loss: 2.4514425621237805

Epoch: 6| Step: 1
Training loss: 2.3828084468841553
Validation loss: 2.455276830222017

Epoch: 6| Step: 2
Training loss: 2.816505193710327
Validation loss: 2.4581368482241066

Epoch: 6| Step: 3
Training loss: 2.3153767585754395
Validation loss: 2.4687622336931128

Epoch: 6| Step: 4
Training loss: 2.5326085090637207
Validation loss: 2.4820947724003948

Epoch: 6| Step: 5
Training loss: 3.583611488342285
Validation loss: 2.5114337372523483

Epoch: 6| Step: 6
Training loss: 3.0996007919311523
Validation loss: 2.514309831844863

Epoch: 6| Step: 7
Training loss: 2.130805492401123
Validation loss: 2.503433001938687

Epoch: 6| Step: 8
Training loss: 2.669053316116333
Validation loss: 2.500060284009544

Epoch: 6| Step: 9
Training loss: 2.360944986343384
Validation loss: 2.500235488337855

Epoch: 6| Step: 10
Training loss: 2.700054407119751
Validation loss: 2.4994654988729827

Epoch: 6| Step: 11
Training loss: 3.329744338989258
Validation loss: 2.479415600017835

Epoch: 6| Step: 12
Training loss: 2.2269890308380127
Validation loss: 2.4783595967036423

Epoch: 6| Step: 13
Training loss: 2.791215419769287
Validation loss: 2.4853873586141937

Epoch: 80| Step: 0
Training loss: 2.759005546569824
Validation loss: 2.4979758698453187

Epoch: 6| Step: 1
Training loss: 2.210906744003296
Validation loss: 2.5018683710405902

Epoch: 6| Step: 2
Training loss: 2.108442544937134
Validation loss: 2.5096476308761106

Epoch: 6| Step: 3
Training loss: 2.3772010803222656
Validation loss: 2.513749304638114

Epoch: 6| Step: 4
Training loss: 2.3470826148986816
Validation loss: 2.5140677754597

Epoch: 6| Step: 5
Training loss: 2.797706127166748
Validation loss: 2.5020778512441986

Epoch: 6| Step: 6
Training loss: 2.4860498905181885
Validation loss: 2.480073123849848

Epoch: 6| Step: 7
Training loss: 2.9612560272216797
Validation loss: 2.4731418958274265

Epoch: 6| Step: 8
Training loss: 2.664607048034668
Validation loss: 2.477044233711817

Epoch: 6| Step: 9
Training loss: 2.6676158905029297
Validation loss: 2.4713036193642566

Epoch: 6| Step: 10
Training loss: 3.313063621520996
Validation loss: 2.4631487067027757

Epoch: 6| Step: 11
Training loss: 2.708810329437256
Validation loss: 2.4586092989931823

Epoch: 6| Step: 12
Training loss: 2.874983310699463
Validation loss: 2.461996745037776

Epoch: 6| Step: 13
Training loss: 3.40610408782959
Validation loss: 2.4637664941049393

Epoch: 81| Step: 0
Training loss: 2.7114500999450684
Validation loss: 2.46188872860324

Epoch: 6| Step: 1
Training loss: 2.4590442180633545
Validation loss: 2.469191981900123

Epoch: 6| Step: 2
Training loss: 2.3448843955993652
Validation loss: 2.4755612598952426

Epoch: 6| Step: 3
Training loss: 2.926586389541626
Validation loss: 2.4630058862829722

Epoch: 6| Step: 4
Training loss: 2.30942964553833
Validation loss: 2.4588157515372

Epoch: 6| Step: 5
Training loss: 2.511603355407715
Validation loss: 2.451227189392172

Epoch: 6| Step: 6
Training loss: 2.6374611854553223
Validation loss: 2.4506532017902662

Epoch: 6| Step: 7
Training loss: 2.813537836074829
Validation loss: 2.4503393378309024

Epoch: 6| Step: 8
Training loss: 2.365865707397461
Validation loss: 2.448170456835019

Epoch: 6| Step: 9
Training loss: 2.4957704544067383
Validation loss: 2.4546764076396985

Epoch: 6| Step: 10
Training loss: 3.316345691680908
Validation loss: 2.460324659142443

Epoch: 6| Step: 11
Training loss: 2.964381217956543
Validation loss: 2.472331985350578

Epoch: 6| Step: 12
Training loss: 2.365675449371338
Validation loss: 2.485260384057158

Epoch: 6| Step: 13
Training loss: 3.541240930557251
Validation loss: 2.4920586411670973

Epoch: 82| Step: 0
Training loss: 2.573427200317383
Validation loss: 2.500894561890633

Epoch: 6| Step: 1
Training loss: 1.4766511917114258
Validation loss: 2.484282224409042

Epoch: 6| Step: 2
Training loss: 2.5359554290771484
Validation loss: 2.482994087280766

Epoch: 6| Step: 3
Training loss: 3.232501268386841
Validation loss: 2.4654444622737106

Epoch: 6| Step: 4
Training loss: 2.7490737438201904
Validation loss: 2.4584537782976703

Epoch: 6| Step: 5
Training loss: 3.2013697624206543
Validation loss: 2.45014129659181

Epoch: 6| Step: 6
Training loss: 3.4572594165802
Validation loss: 2.4446011127964145

Epoch: 6| Step: 7
Training loss: 2.1195154190063477
Validation loss: 2.444868387714509

Epoch: 6| Step: 8
Training loss: 2.3933870792388916
Validation loss: 2.44560754940074

Epoch: 6| Step: 9
Training loss: 2.534298896789551
Validation loss: 2.446904549034693

Epoch: 6| Step: 10
Training loss: 2.57246732711792
Validation loss: 2.4509649456188245

Epoch: 6| Step: 11
Training loss: 3.1187405586242676
Validation loss: 2.452671020261703

Epoch: 6| Step: 12
Training loss: 2.471287488937378
Validation loss: 2.4496903727131505

Epoch: 6| Step: 13
Training loss: 2.9958090782165527
Validation loss: 2.448787661008937

Epoch: 83| Step: 0
Training loss: 2.2493889331817627
Validation loss: 2.4490959746863252

Epoch: 6| Step: 1
Training loss: 2.3987836837768555
Validation loss: 2.449437855392374

Epoch: 6| Step: 2
Training loss: 2.7143564224243164
Validation loss: 2.4556104970234696

Epoch: 6| Step: 3
Training loss: 2.8391425609588623
Validation loss: 2.456482018193891

Epoch: 6| Step: 4
Training loss: 3.266136884689331
Validation loss: 2.4523022097925984

Epoch: 6| Step: 5
Training loss: 2.326570749282837
Validation loss: 2.452643081706057

Epoch: 6| Step: 6
Training loss: 2.969078540802002
Validation loss: 2.4596097289874987

Epoch: 6| Step: 7
Training loss: 2.215134620666504
Validation loss: 2.468994802044284

Epoch: 6| Step: 8
Training loss: 2.280158281326294
Validation loss: 2.4809662552290064

Epoch: 6| Step: 9
Training loss: 2.4581458568573
Validation loss: 2.507081554782006

Epoch: 6| Step: 10
Training loss: 2.483614683151245
Validation loss: 2.513925411367929

Epoch: 6| Step: 11
Training loss: 3.542860746383667
Validation loss: 2.493625389632358

Epoch: 6| Step: 12
Training loss: 2.6905288696289062
Validation loss: 2.4796150935593473

Epoch: 6| Step: 13
Training loss: 2.970163106918335
Validation loss: 2.4750695420849707

Epoch: 84| Step: 0
Training loss: 3.1563820838928223
Validation loss: 2.459972189318749

Epoch: 6| Step: 1
Training loss: 2.432452440261841
Validation loss: 2.4497557891312467

Epoch: 6| Step: 2
Training loss: 2.0016634464263916
Validation loss: 2.4382298941253335

Epoch: 6| Step: 3
Training loss: 3.251953125
Validation loss: 2.4355119377054195

Epoch: 6| Step: 4
Training loss: 2.6809678077697754
Validation loss: 2.431878105286629

Epoch: 6| Step: 5
Training loss: 2.0924177169799805
Validation loss: 2.435581945603894

Epoch: 6| Step: 6
Training loss: 2.4979324340820312
Validation loss: 2.439410117364699

Epoch: 6| Step: 7
Training loss: 2.721548080444336
Validation loss: 2.4448793344600226

Epoch: 6| Step: 8
Training loss: 2.8604142665863037
Validation loss: 2.4521717307388142

Epoch: 6| Step: 9
Training loss: 2.6911187171936035
Validation loss: 2.454433141216155

Epoch: 6| Step: 10
Training loss: 2.6075034141540527
Validation loss: 2.4506366765627297

Epoch: 6| Step: 11
Training loss: 2.968085765838623
Validation loss: 2.4454556870204147

Epoch: 6| Step: 12
Training loss: 2.550638198852539
Validation loss: 2.442394742401697

Epoch: 6| Step: 13
Training loss: 2.850666046142578
Validation loss: 2.44603955617515

Epoch: 85| Step: 0
Training loss: 3.0241172313690186
Validation loss: 2.4453295943557576

Epoch: 6| Step: 1
Training loss: 2.5102291107177734
Validation loss: 2.4432372303419214

Epoch: 6| Step: 2
Training loss: 3.0417051315307617
Validation loss: 2.442595169108401

Epoch: 6| Step: 3
Training loss: 1.9210129976272583
Validation loss: 2.4450583637401624

Epoch: 6| Step: 4
Training loss: 2.6542580127716064
Validation loss: 2.450504554215298

Epoch: 6| Step: 5
Training loss: 2.082294225692749
Validation loss: 2.4667967493816088

Epoch: 6| Step: 6
Training loss: 3.098555564880371
Validation loss: 2.4984481437231905

Epoch: 6| Step: 7
Training loss: 2.3706910610198975
Validation loss: 2.5019799099173596

Epoch: 6| Step: 8
Training loss: 3.0479893684387207
Validation loss: 2.468861492731238

Epoch: 6| Step: 9
Training loss: 2.504549980163574
Validation loss: 2.454656329206241

Epoch: 6| Step: 10
Training loss: 2.79091477394104
Validation loss: 2.446628321883499

Epoch: 6| Step: 11
Training loss: 2.297753095626831
Validation loss: 2.449034244783463

Epoch: 6| Step: 12
Training loss: 2.994584083557129
Validation loss: 2.439812596126269

Epoch: 6| Step: 13
Training loss: 3.279536247253418
Validation loss: 2.4416297866452124

Epoch: 86| Step: 0
Training loss: 2.3090286254882812
Validation loss: 2.435680291985953

Epoch: 6| Step: 1
Training loss: 1.917086124420166
Validation loss: 2.4391627132251696

Epoch: 6| Step: 2
Training loss: 2.6498899459838867
Validation loss: 2.438065154578096

Epoch: 6| Step: 3
Training loss: 3.061452627182007
Validation loss: 2.435203949610392

Epoch: 6| Step: 4
Training loss: 2.176332473754883
Validation loss: 2.4369464612776235

Epoch: 6| Step: 5
Training loss: 2.3162741661071777
Validation loss: 2.435752845579578

Epoch: 6| Step: 6
Training loss: 1.9973474740982056
Validation loss: 2.4382884963866203

Epoch: 6| Step: 7
Training loss: 2.8977608680725098
Validation loss: 2.4425064979061

Epoch: 6| Step: 8
Training loss: 2.9808197021484375
Validation loss: 2.4511505326917096

Epoch: 6| Step: 9
Training loss: 2.9586610794067383
Validation loss: 2.455021737724222

Epoch: 6| Step: 10
Training loss: 3.2292466163635254
Validation loss: 2.471173322328957

Epoch: 6| Step: 11
Training loss: 3.3029162883758545
Validation loss: 2.467778771154342

Epoch: 6| Step: 12
Training loss: 2.420473575592041
Validation loss: 2.4606169859568277

Epoch: 6| Step: 13
Training loss: 3.173800230026245
Validation loss: 2.4438063380538777

Epoch: 87| Step: 0
Training loss: 2.196244478225708
Validation loss: 2.4318632233527397

Epoch: 6| Step: 1
Training loss: 1.7767748832702637
Validation loss: 2.431432818853727

Epoch: 6| Step: 2
Training loss: 3.610546112060547
Validation loss: 2.4314936091822963

Epoch: 6| Step: 3
Training loss: 3.4376912117004395
Validation loss: 2.4285939278141147

Epoch: 6| Step: 4
Training loss: 2.753615140914917
Validation loss: 2.4260266057906614

Epoch: 6| Step: 5
Training loss: 2.4955058097839355
Validation loss: 2.4246389430056334

Epoch: 6| Step: 6
Training loss: 2.6417593955993652
Validation loss: 2.4251915383082565

Epoch: 6| Step: 7
Training loss: 2.5376479625701904
Validation loss: 2.424453722533359

Epoch: 6| Step: 8
Training loss: 3.0325915813446045
Validation loss: 2.4259821599529636

Epoch: 6| Step: 9
Training loss: 2.7299773693084717
Validation loss: 2.4220611305646997

Epoch: 6| Step: 10
Training loss: 2.65958309173584
Validation loss: 2.4241308268680366

Epoch: 6| Step: 11
Training loss: 2.5265233516693115
Validation loss: 2.4217359045500397

Epoch: 6| Step: 12
Training loss: 2.1487019062042236
Validation loss: 2.4196610194380566

Epoch: 6| Step: 13
Training loss: 2.6637399196624756
Validation loss: 2.4208849117320073

Epoch: 88| Step: 0
Training loss: 3.3279833793640137
Validation loss: 2.424664194865893

Epoch: 6| Step: 1
Training loss: 2.210610866546631
Validation loss: 2.420261388183922

Epoch: 6| Step: 2
Training loss: 2.955780506134033
Validation loss: 2.419948811172157

Epoch: 6| Step: 3
Training loss: 1.8609468936920166
Validation loss: 2.422541520928824

Epoch: 6| Step: 4
Training loss: 2.530585765838623
Validation loss: 2.423456158689273

Epoch: 6| Step: 5
Training loss: 2.585186004638672
Validation loss: 2.42639176307186

Epoch: 6| Step: 6
Training loss: 2.756192445755005
Validation loss: 2.421898989267247

Epoch: 6| Step: 7
Training loss: 2.9927244186401367
Validation loss: 2.419836805712792

Epoch: 6| Step: 8
Training loss: 2.1755480766296387
Validation loss: 2.4209752185370332

Epoch: 6| Step: 9
Training loss: 2.310586929321289
Validation loss: 2.4154291845137075

Epoch: 6| Step: 10
Training loss: 3.1332404613494873
Validation loss: 2.413434934872453

Epoch: 6| Step: 11
Training loss: 2.6665873527526855
Validation loss: 2.4203018398695093

Epoch: 6| Step: 12
Training loss: 3.123203754425049
Validation loss: 2.419645522230415

Epoch: 6| Step: 13
Training loss: 2.44671893119812
Validation loss: 2.423049831903109

Epoch: 89| Step: 0
Training loss: 2.5691943168640137
Validation loss: 2.426962706350511

Epoch: 6| Step: 1
Training loss: 3.03955078125
Validation loss: 2.425887318067653

Epoch: 6| Step: 2
Training loss: 2.241945743560791
Validation loss: 2.4285186567614154

Epoch: 6| Step: 3
Training loss: 2.402865171432495
Validation loss: 2.433399144039359

Epoch: 6| Step: 4
Training loss: 2.1277687549591064
Validation loss: 2.43179214385248

Epoch: 6| Step: 5
Training loss: 2.802286386489868
Validation loss: 2.4430166521380023

Epoch: 6| Step: 6
Training loss: 2.606543779373169
Validation loss: 2.440415297785113

Epoch: 6| Step: 7
Training loss: 2.2772278785705566
Validation loss: 2.4453808517866236

Epoch: 6| Step: 8
Training loss: 3.550487995147705
Validation loss: 2.4446667471239643

Epoch: 6| Step: 9
Training loss: 3.1804442405700684
Validation loss: 2.4563350062216482

Epoch: 6| Step: 10
Training loss: 2.9251368045806885
Validation loss: 2.454802005521713

Epoch: 6| Step: 11
Training loss: 2.607985496520996
Validation loss: 2.447449089378439

Epoch: 6| Step: 12
Training loss: 2.2652249336242676
Validation loss: 2.429942742470772

Epoch: 6| Step: 13
Training loss: 2.583786964416504
Validation loss: 2.426832140132945

Epoch: 90| Step: 0
Training loss: 2.7820684909820557
Validation loss: 2.4250437905711513

Epoch: 6| Step: 1
Training loss: 2.94724702835083
Validation loss: 2.4239829612034622

Epoch: 6| Step: 2
Training loss: 3.164325714111328
Validation loss: 2.4429583446953886

Epoch: 6| Step: 3
Training loss: 2.5570359230041504
Validation loss: 2.459748729582756

Epoch: 6| Step: 4
Training loss: 2.8984875679016113
Validation loss: 2.48268392521848

Epoch: 6| Step: 5
Training loss: 2.3694210052490234
Validation loss: 2.453875167395479

Epoch: 6| Step: 6
Training loss: 2.5427472591400146
Validation loss: 2.4391056799119517

Epoch: 6| Step: 7
Training loss: 2.197085380554199
Validation loss: 2.4235610859368437

Epoch: 6| Step: 8
Training loss: 2.7887887954711914
Validation loss: 2.413273008920813

Epoch: 6| Step: 9
Training loss: 2.52925968170166
Validation loss: 2.411074451220933

Epoch: 6| Step: 10
Training loss: 3.097773551940918
Validation loss: 2.4040792475464525

Epoch: 6| Step: 11
Training loss: 2.8580288887023926
Validation loss: 2.409960774965184

Epoch: 6| Step: 12
Training loss: 1.9659357070922852
Validation loss: 2.4170362411006803

Epoch: 6| Step: 13
Training loss: 2.331176280975342
Validation loss: 2.4187510475035636

Epoch: 91| Step: 0
Training loss: 2.987579345703125
Validation loss: 2.436243421287947

Epoch: 6| Step: 1
Training loss: 2.383253812789917
Validation loss: 2.4314407353760092

Epoch: 6| Step: 2
Training loss: 3.181793212890625
Validation loss: 2.4391942895868772

Epoch: 6| Step: 3
Training loss: 1.9012681245803833
Validation loss: 2.4311165809631348

Epoch: 6| Step: 4
Training loss: 2.423301935195923
Validation loss: 2.4268124872638333

Epoch: 6| Step: 5
Training loss: 3.3315541744232178
Validation loss: 2.419763142062772

Epoch: 6| Step: 6
Training loss: 2.6507084369659424
Validation loss: 2.414408358194495

Epoch: 6| Step: 7
Training loss: 1.7936174869537354
Validation loss: 2.4103781484788462

Epoch: 6| Step: 8
Training loss: 3.121893882751465
Validation loss: 2.41214047708819

Epoch: 6| Step: 9
Training loss: 3.1982405185699463
Validation loss: 2.409502754929245

Epoch: 6| Step: 10
Training loss: 2.5777812004089355
Validation loss: 2.41502203992618

Epoch: 6| Step: 11
Training loss: 2.273728847503662
Validation loss: 2.4156459634022047

Epoch: 6| Step: 12
Training loss: 2.3826563358306885
Validation loss: 2.4173056156404558

Epoch: 6| Step: 13
Training loss: 3.3079991340637207
Validation loss: 2.4192159342509445

Epoch: 92| Step: 0
Training loss: 2.8314456939697266
Validation loss: 2.417530508451564

Epoch: 6| Step: 1
Training loss: 2.204113006591797
Validation loss: 2.426590799003519

Epoch: 6| Step: 2
Training loss: 3.496306896209717
Validation loss: 2.4344944748827206

Epoch: 6| Step: 3
Training loss: 2.137685775756836
Validation loss: 2.45022415602079

Epoch: 6| Step: 4
Training loss: 2.703150749206543
Validation loss: 2.4382134586252193

Epoch: 6| Step: 5
Training loss: 2.8490636348724365
Validation loss: 2.434005969314165

Epoch: 6| Step: 6
Training loss: 2.400174617767334
Validation loss: 2.4250181310920307

Epoch: 6| Step: 7
Training loss: 3.112809658050537
Validation loss: 2.414405802244781

Epoch: 6| Step: 8
Training loss: 3.3693435192108154
Validation loss: 2.4027128540059572

Epoch: 6| Step: 9
Training loss: 1.6513466835021973
Validation loss: 2.40154371723052

Epoch: 6| Step: 10
Training loss: 2.7238292694091797
Validation loss: 2.3999315436168382

Epoch: 6| Step: 11
Training loss: 2.5823917388916016
Validation loss: 2.3970258466659056

Epoch: 6| Step: 12
Training loss: 2.3660335540771484
Validation loss: 2.393694644333214

Epoch: 6| Step: 13
Training loss: 2.9148898124694824
Validation loss: 2.400157597757155

Epoch: 93| Step: 0
Training loss: 2.399580955505371
Validation loss: 2.4008465710506646

Epoch: 6| Step: 1
Training loss: 3.2212533950805664
Validation loss: 2.403985559299428

Epoch: 6| Step: 2
Training loss: 2.0148205757141113
Validation loss: 2.4009381007122736

Epoch: 6| Step: 3
Training loss: 2.81309175491333
Validation loss: 2.4042935397035334

Epoch: 6| Step: 4
Training loss: 2.3514108657836914
Validation loss: 2.4051065983310824

Epoch: 6| Step: 5
Training loss: 2.82430362701416
Validation loss: 2.4030912486455773

Epoch: 6| Step: 6
Training loss: 3.818462371826172
Validation loss: 2.4035925442172634

Epoch: 6| Step: 7
Training loss: 2.727296829223633
Validation loss: 2.4061634143193564

Epoch: 6| Step: 8
Training loss: 2.5088303089141846
Validation loss: 2.404631350630073

Epoch: 6| Step: 9
Training loss: 2.699925422668457
Validation loss: 2.4035690522963002

Epoch: 6| Step: 10
Training loss: 2.4180526733398438
Validation loss: 2.3995290969007756

Epoch: 6| Step: 11
Training loss: 2.1556851863861084
Validation loss: 2.3944897420944704

Epoch: 6| Step: 12
Training loss: 3.0843732357025146
Validation loss: 2.39477740692836

Epoch: 6| Step: 13
Training loss: 1.627968430519104
Validation loss: 2.3980571890390046

Epoch: 94| Step: 0
Training loss: 2.430957794189453
Validation loss: 2.397777421500093

Epoch: 6| Step: 1
Training loss: 2.197211265563965
Validation loss: 2.4023781130390782

Epoch: 6| Step: 2
Training loss: 2.931326389312744
Validation loss: 2.4029193257772796

Epoch: 6| Step: 3
Training loss: 2.523324489593506
Validation loss: 2.4078509499949794

Epoch: 6| Step: 4
Training loss: 2.0002973079681396
Validation loss: 2.405268088463814

Epoch: 6| Step: 5
Training loss: 2.7586982250213623
Validation loss: 2.4052830229523363

Epoch: 6| Step: 6
Training loss: 2.3899707794189453
Validation loss: 2.403100206005958

Epoch: 6| Step: 7
Training loss: 2.1663856506347656
Validation loss: 2.4014720788566013

Epoch: 6| Step: 8
Training loss: 2.4655346870422363
Validation loss: 2.4031137074193647

Epoch: 6| Step: 9
Training loss: 3.015660285949707
Validation loss: 2.4027415911356607

Epoch: 6| Step: 10
Training loss: 3.5468907356262207
Validation loss: 2.4056411584218345

Epoch: 6| Step: 11
Training loss: 2.980494499206543
Validation loss: 2.416910586818572

Epoch: 6| Step: 12
Training loss: 2.847489833831787
Validation loss: 2.4201370516131

Epoch: 6| Step: 13
Training loss: 2.7060117721557617
Validation loss: 2.422646427667269

Epoch: 95| Step: 0
Training loss: 2.5432515144348145
Validation loss: 2.40724419265665

Epoch: 6| Step: 1
Training loss: 2.9448673725128174
Validation loss: 2.403737873159429

Epoch: 6| Step: 2
Training loss: 2.688297748565674
Validation loss: 2.4076325585765224

Epoch: 6| Step: 3
Training loss: 3.2874574661254883
Validation loss: 2.40576490535531

Epoch: 6| Step: 4
Training loss: 1.9990599155426025
Validation loss: 2.412705400938629

Epoch: 6| Step: 5
Training loss: 3.0758166313171387
Validation loss: 2.424534602831769

Epoch: 6| Step: 6
Training loss: 2.584641456604004
Validation loss: 2.434055382205594

Epoch: 6| Step: 7
Training loss: 2.278616428375244
Validation loss: 2.4828480853829333

Epoch: 6| Step: 8
Training loss: 2.2721567153930664
Validation loss: 2.4886535598385717

Epoch: 6| Step: 9
Training loss: 1.9781296253204346
Validation loss: 2.4835160650232786

Epoch: 6| Step: 10
Training loss: 2.9507429599761963
Validation loss: 2.5036748096507084

Epoch: 6| Step: 11
Training loss: 3.273832082748413
Validation loss: 2.4864193880429832

Epoch: 6| Step: 12
Training loss: 2.6025898456573486
Validation loss: 2.438692920951433

Epoch: 6| Step: 13
Training loss: 2.411522626876831
Validation loss: 2.419731891283425

Epoch: 96| Step: 0
Training loss: 2.9467597007751465
Validation loss: 2.3996036232158704

Epoch: 6| Step: 1
Training loss: 3.116677761077881
Validation loss: 2.401681423187256

Epoch: 6| Step: 2
Training loss: 2.6210854053497314
Validation loss: 2.40483840562964

Epoch: 6| Step: 3
Training loss: 1.856102466583252
Validation loss: 2.4065242813479517

Epoch: 6| Step: 4
Training loss: 3.376732349395752
Validation loss: 2.4060291295410483

Epoch: 6| Step: 5
Training loss: 1.9413373470306396
Validation loss: 2.4015857019732074

Epoch: 6| Step: 6
Training loss: 1.6170918941497803
Validation loss: 2.4005844541775283

Epoch: 6| Step: 7
Training loss: 3.033945322036743
Validation loss: 2.4005031739511797

Epoch: 6| Step: 8
Training loss: 2.6887459754943848
Validation loss: 2.40200815662261

Epoch: 6| Step: 9
Training loss: 2.6607816219329834
Validation loss: 2.3997171822414605

Epoch: 6| Step: 10
Training loss: 2.618122100830078
Validation loss: 2.404295802116394

Epoch: 6| Step: 11
Training loss: 2.7790637016296387
Validation loss: 2.4141121218281407

Epoch: 6| Step: 12
Training loss: 2.554811477661133
Validation loss: 2.425069998669368

Epoch: 6| Step: 13
Training loss: 3.705730438232422
Validation loss: 2.4330874591745357

Epoch: 97| Step: 0
Training loss: 2.9203319549560547
Validation loss: 2.442316142461633

Epoch: 6| Step: 1
Training loss: 2.0596210956573486
Validation loss: 2.441881589992072

Epoch: 6| Step: 2
Training loss: 2.675874710083008
Validation loss: 2.4468403606004614

Epoch: 6| Step: 3
Training loss: 3.331772804260254
Validation loss: 2.471225312961045

Epoch: 6| Step: 4
Training loss: 2.4260849952697754
Validation loss: 2.493533172915059

Epoch: 6| Step: 5
Training loss: 1.9894194602966309
Validation loss: 2.495735050529562

Epoch: 6| Step: 6
Training loss: 3.685595989227295
Validation loss: 2.494412053015924

Epoch: 6| Step: 7
Training loss: 2.9573006629943848
Validation loss: 2.46958904112539

Epoch: 6| Step: 8
Training loss: 1.9720385074615479
Validation loss: 2.4388883190770305

Epoch: 6| Step: 9
Training loss: 2.777815103530884
Validation loss: 2.4093493466736167

Epoch: 6| Step: 10
Training loss: 2.6817626953125
Validation loss: 2.414956658117233

Epoch: 6| Step: 11
Training loss: 3.076173782348633
Validation loss: 2.412565085195726

Epoch: 6| Step: 12
Training loss: 2.3250255584716797
Validation loss: 2.401666659180836

Epoch: 6| Step: 13
Training loss: 2.074146270751953
Validation loss: 2.4081701335086616

Epoch: 98| Step: 0
Training loss: 2.544740915298462
Validation loss: 2.4101727957366617

Epoch: 6| Step: 1
Training loss: 2.632894515991211
Validation loss: 2.396048476619105

Epoch: 6| Step: 2
Training loss: 2.862126350402832
Validation loss: 2.396281385934481

Epoch: 6| Step: 3
Training loss: 2.288571834564209
Validation loss: 2.3893328392377464

Epoch: 6| Step: 4
Training loss: 2.4173364639282227
Validation loss: 2.3884783996048795

Epoch: 6| Step: 5
Training loss: 2.0874533653259277
Validation loss: 2.385185997973206

Epoch: 6| Step: 6
Training loss: 3.2477197647094727
Validation loss: 2.3862587687789754

Epoch: 6| Step: 7
Training loss: 2.872344970703125
Validation loss: 2.383661646996775

Epoch: 6| Step: 8
Training loss: 2.9491472244262695
Validation loss: 2.379423200443227

Epoch: 6| Step: 9
Training loss: 2.496277332305908
Validation loss: 2.3861233982988583

Epoch: 6| Step: 10
Training loss: 2.8310728073120117
Validation loss: 2.38674751404793

Epoch: 6| Step: 11
Training loss: 2.3133273124694824
Validation loss: 2.3893124954674834

Epoch: 6| Step: 12
Training loss: 2.2441956996917725
Validation loss: 2.3970224857330322

Epoch: 6| Step: 13
Training loss: 3.5171456336975098
Validation loss: 2.409019236923546

Epoch: 99| Step: 0
Training loss: 2.0126800537109375
Validation loss: 2.4288119372501167

Epoch: 6| Step: 1
Training loss: 3.8384342193603516
Validation loss: 2.4464212899566977

Epoch: 6| Step: 2
Training loss: 2.9072442054748535
Validation loss: 2.4496507183198006

Epoch: 6| Step: 3
Training loss: 1.8154504299163818
Validation loss: 2.440354472847395

Epoch: 6| Step: 4
Training loss: 1.9457671642303467
Validation loss: 2.4255580389371483

Epoch: 6| Step: 5
Training loss: 1.89815354347229
Validation loss: 2.424983952635078

Epoch: 6| Step: 6
Training loss: 3.5198440551757812
Validation loss: 2.4038996555471934

Epoch: 6| Step: 7
Training loss: 2.7413296699523926
Validation loss: 2.3926743538148942

Epoch: 6| Step: 8
Training loss: 2.724125862121582
Validation loss: 2.380993245750345

Epoch: 6| Step: 9
Training loss: 2.473794937133789
Validation loss: 2.380389500689763

Epoch: 6| Step: 10
Training loss: 2.5243988037109375
Validation loss: 2.3831595143964215

Epoch: 6| Step: 11
Training loss: 2.371690273284912
Validation loss: 2.377451609539729

Epoch: 6| Step: 12
Training loss: 3.5814762115478516
Validation loss: 2.3769664072221324

Epoch: 6| Step: 13
Training loss: 2.6921916007995605
Validation loss: 2.3838612956385457

Epoch: 100| Step: 0
Training loss: 2.7780044078826904
Validation loss: 2.389948688527589

Epoch: 6| Step: 1
Training loss: 2.8978214263916016
Validation loss: 2.390983448233656

Epoch: 6| Step: 2
Training loss: 2.516669511795044
Validation loss: 2.4068427701150217

Epoch: 6| Step: 3
Training loss: 2.706827163696289
Validation loss: 2.4101742877755115

Epoch: 6| Step: 4
Training loss: 3.390974998474121
Validation loss: 2.4162193229121547

Epoch: 6| Step: 5
Training loss: 2.1733574867248535
Validation loss: 2.404531125099428

Epoch: 6| Step: 6
Training loss: 2.017765998840332
Validation loss: 2.394565038783576

Epoch: 6| Step: 7
Training loss: 2.7803516387939453
Validation loss: 2.3827553628593363

Epoch: 6| Step: 8
Training loss: 2.109165906906128
Validation loss: 2.3759037551059516

Epoch: 6| Step: 9
Training loss: 2.9674341678619385
Validation loss: 2.375169530991585

Epoch: 6| Step: 10
Training loss: 2.5129318237304688
Validation loss: 2.375225064575031

Epoch: 6| Step: 11
Training loss: 3.0036239624023438
Validation loss: 2.373330355972372

Epoch: 6| Step: 12
Training loss: 2.0874998569488525
Validation loss: 2.375125100535731

Epoch: 6| Step: 13
Training loss: 3.6290524005889893
Validation loss: 2.3772048181103123

Epoch: 101| Step: 0
Training loss: 2.3023314476013184
Validation loss: 2.3850307592781643

Epoch: 6| Step: 1
Training loss: 2.7819299697875977
Validation loss: 2.381205807449997

Epoch: 6| Step: 2
Training loss: 2.8826277256011963
Validation loss: 2.390003263309438

Epoch: 6| Step: 3
Training loss: 2.7654778957366943
Validation loss: 2.3921148495007585

Epoch: 6| Step: 4
Training loss: 2.8406496047973633
Validation loss: 2.3813524425670667

Epoch: 6| Step: 5
Training loss: 2.5695953369140625
Validation loss: 2.3755189500829226

Epoch: 6| Step: 6
Training loss: 2.242976427078247
Validation loss: 2.3727286220878683

Epoch: 6| Step: 7
Training loss: 2.747684955596924
Validation loss: 2.3763151245732463

Epoch: 6| Step: 8
Training loss: 2.2225027084350586
Validation loss: 2.374954826088362

Epoch: 6| Step: 9
Training loss: 2.393014669418335
Validation loss: 2.37112093997258

Epoch: 6| Step: 10
Training loss: 2.7664265632629395
Validation loss: 2.3744053379181893

Epoch: 6| Step: 11
Training loss: 2.7538814544677734
Validation loss: 2.374368413802116

Epoch: 6| Step: 12
Training loss: 2.4246251583099365
Validation loss: 2.372325538307108

Epoch: 6| Step: 13
Training loss: 3.5043628215789795
Validation loss: 2.3706892100713586

Epoch: 102| Step: 0
Training loss: 2.8263320922851562
Validation loss: 2.373574949079944

Epoch: 6| Step: 1
Training loss: 2.371070623397827
Validation loss: 2.374701835775888

Epoch: 6| Step: 2
Training loss: 2.1238746643066406
Validation loss: 2.3739455258974465

Epoch: 6| Step: 3
Training loss: 2.3849000930786133
Validation loss: 2.3735935559836765

Epoch: 6| Step: 4
Training loss: 2.0105645656585693
Validation loss: 2.374236431173099

Epoch: 6| Step: 5
Training loss: 2.417919635772705
Validation loss: 2.3752523160749868

Epoch: 6| Step: 6
Training loss: 1.7284139394760132
Validation loss: 2.3754257361094155

Epoch: 6| Step: 7
Training loss: 2.8419480323791504
Validation loss: 2.3741040306706584

Epoch: 6| Step: 8
Training loss: 3.9053025245666504
Validation loss: 2.3725901214025353

Epoch: 6| Step: 9
Training loss: 2.2392330169677734
Validation loss: 2.376932831220729

Epoch: 6| Step: 10
Training loss: 3.4987940788269043
Validation loss: 2.385375858635031

Epoch: 6| Step: 11
Training loss: 2.8656671047210693
Validation loss: 2.387614614220076

Epoch: 6| Step: 12
Training loss: 2.706271171569824
Validation loss: 2.3859225857642388

Epoch: 6| Step: 13
Training loss: 3.049527883529663
Validation loss: 2.397139569764496

Epoch: 103| Step: 0
Training loss: 2.3061113357543945
Validation loss: 2.3965428465156147

Epoch: 6| Step: 1
Training loss: 3.426891326904297
Validation loss: 2.386702122226838

Epoch: 6| Step: 2
Training loss: 1.816481351852417
Validation loss: 2.375772483887211

Epoch: 6| Step: 3
Training loss: 2.2512307167053223
Validation loss: 2.3756513595581055

Epoch: 6| Step: 4
Training loss: 2.86415696144104
Validation loss: 2.3695025726031234

Epoch: 6| Step: 5
Training loss: 2.626579761505127
Validation loss: 2.3663981345392044

Epoch: 6| Step: 6
Training loss: 3.0545759201049805
Validation loss: 2.3675312201182046

Epoch: 6| Step: 7
Training loss: 2.141834259033203
Validation loss: 2.3722249384849303

Epoch: 6| Step: 8
Training loss: 2.757739543914795
Validation loss: 2.378336229631978

Epoch: 6| Step: 9
Training loss: 2.3528995513916016
Validation loss: 2.397075976094892

Epoch: 6| Step: 10
Training loss: 3.420490264892578
Validation loss: 2.399094235512518

Epoch: 6| Step: 11
Training loss: 2.2080307006835938
Validation loss: 2.3776610256523214

Epoch: 6| Step: 12
Training loss: 2.7076690196990967
Validation loss: 2.3718163121131157

Epoch: 6| Step: 13
Training loss: 2.8153412342071533
Validation loss: 2.3718367545835433

Epoch: 104| Step: 0
Training loss: 2.8776636123657227
Validation loss: 2.3678451661140687

Epoch: 6| Step: 1
Training loss: 3.1249918937683105
Validation loss: 2.3626718880027853

Epoch: 6| Step: 2
Training loss: 2.238060474395752
Validation loss: 2.361547247056038

Epoch: 6| Step: 3
Training loss: 1.5014152526855469
Validation loss: 2.369323253631592

Epoch: 6| Step: 4
Training loss: 2.193560838699341
Validation loss: 2.366747474157682

Epoch: 6| Step: 5
Training loss: 2.195622444152832
Validation loss: 2.383664643892678

Epoch: 6| Step: 6
Training loss: 2.8779540061950684
Validation loss: 2.3886180116284277

Epoch: 6| Step: 7
Training loss: 2.5459251403808594
Validation loss: 2.3870678665817424

Epoch: 6| Step: 8
Training loss: 3.18241024017334
Validation loss: 2.3796433120645504

Epoch: 6| Step: 9
Training loss: 3.243680000305176
Validation loss: 2.3856937167465047

Epoch: 6| Step: 10
Training loss: 2.5976617336273193
Validation loss: 2.389795313599289

Epoch: 6| Step: 11
Training loss: 2.4865660667419434
Validation loss: 2.38623873905469

Epoch: 6| Step: 12
Training loss: 2.867969512939453
Validation loss: 2.3955342026167017

Epoch: 6| Step: 13
Training loss: 3.0982720851898193
Validation loss: 2.3947687610503166

Epoch: 105| Step: 0
Training loss: 2.355152130126953
Validation loss: 2.393593152364095

Epoch: 6| Step: 1
Training loss: 2.832157611846924
Validation loss: 2.3852008286342827

Epoch: 6| Step: 2
Training loss: 2.3420257568359375
Validation loss: 2.3723678742685625

Epoch: 6| Step: 3
Training loss: 2.273531198501587
Validation loss: 2.366100747098205

Epoch: 6| Step: 4
Training loss: 2.885571002960205
Validation loss: 2.3752276435975106

Epoch: 6| Step: 5
Training loss: 2.8787076473236084
Validation loss: 2.3750849795597855

Epoch: 6| Step: 6
Training loss: 2.6251235008239746
Validation loss: 2.378103471571399

Epoch: 6| Step: 7
Training loss: 2.365995407104492
Validation loss: 2.386198551424088

Epoch: 6| Step: 8
Training loss: 3.3815789222717285
Validation loss: 2.3915431191844325

Epoch: 6| Step: 9
Training loss: 3.071139097213745
Validation loss: 2.381822637332383

Epoch: 6| Step: 10
Training loss: 2.185044288635254
Validation loss: 2.3984459830868627

Epoch: 6| Step: 11
Training loss: 2.1163010597229004
Validation loss: 2.3958859264209704

Epoch: 6| Step: 12
Training loss: 2.5698766708374023
Validation loss: 2.4211137563951555

Epoch: 6| Step: 13
Training loss: 2.8286633491516113
Validation loss: 2.4281042006707962

Epoch: 106| Step: 0
Training loss: 2.342653274536133
Validation loss: 2.443039445466893

Epoch: 6| Step: 1
Training loss: 2.3118906021118164
Validation loss: 2.4638715738891275

Epoch: 6| Step: 2
Training loss: 3.4891061782836914
Validation loss: 2.4750674847633607

Epoch: 6| Step: 3
Training loss: 3.056741714477539
Validation loss: 2.445512822879258

Epoch: 6| Step: 4
Training loss: 2.3005146980285645
Validation loss: 2.417085309182444

Epoch: 6| Step: 5
Training loss: 2.263397216796875
Validation loss: 2.3922279893711047

Epoch: 6| Step: 6
Training loss: 2.64854097366333
Validation loss: 2.3794398102709042

Epoch: 6| Step: 7
Training loss: 2.8347647190093994
Validation loss: 2.3628354892935803

Epoch: 6| Step: 8
Training loss: 1.9744423627853394
Validation loss: 2.3691222642057683

Epoch: 6| Step: 9
Training loss: 1.8805148601531982
Validation loss: 2.3786042018603255

Epoch: 6| Step: 10
Training loss: 2.837125062942505
Validation loss: 2.379892644061837

Epoch: 6| Step: 11
Training loss: 2.5291714668273926
Validation loss: 2.40594922086244

Epoch: 6| Step: 12
Training loss: 3.458219289779663
Validation loss: 2.4044405106575257

Epoch: 6| Step: 13
Training loss: 3.3010342121124268
Validation loss: 2.394574071771355

Epoch: 107| Step: 0
Training loss: 2.4291446208953857
Validation loss: 2.3628905024579776

Epoch: 6| Step: 1
Training loss: 2.802874803543091
Validation loss: 2.357616788597517

Epoch: 6| Step: 2
Training loss: 2.800896167755127
Validation loss: 2.3552067561816146

Epoch: 6| Step: 3
Training loss: 2.6429383754730225
Validation loss: 2.3537409792664232

Epoch: 6| Step: 4
Training loss: 2.9529058933258057
Validation loss: 2.356494818964312

Epoch: 6| Step: 5
Training loss: 2.991511821746826
Validation loss: 2.36715672093053

Epoch: 6| Step: 6
Training loss: 3.4883015155792236
Validation loss: 2.383392508311938

Epoch: 6| Step: 7
Training loss: 2.4076359272003174
Validation loss: 2.400002012970627

Epoch: 6| Step: 8
Training loss: 2.2814579010009766
Validation loss: 2.405470399446385

Epoch: 6| Step: 9
Training loss: 3.1030642986297607
Validation loss: 2.416847892986831

Epoch: 6| Step: 10
Training loss: 2.473787784576416
Validation loss: 2.405628160763812

Epoch: 6| Step: 11
Training loss: 1.900158405303955
Validation loss: 2.392275433386526

Epoch: 6| Step: 12
Training loss: 2.3953843116760254
Validation loss: 2.3818537496751353

Epoch: 6| Step: 13
Training loss: 2.094761371612549
Validation loss: 2.382247704331593

Epoch: 108| Step: 0
Training loss: 3.6364262104034424
Validation loss: 2.40032261161394

Epoch: 6| Step: 1
Training loss: 2.3662726879119873
Validation loss: 2.3981910469711467

Epoch: 6| Step: 2
Training loss: 2.099508047103882
Validation loss: 2.389149219759049

Epoch: 6| Step: 3
Training loss: 2.7302262783050537
Validation loss: 2.3781547418204685

Epoch: 6| Step: 4
Training loss: 2.610339641571045
Validation loss: 2.368628450619277

Epoch: 6| Step: 5
Training loss: 2.7516393661499023
Validation loss: 2.357410148907733

Epoch: 6| Step: 6
Training loss: 2.3443775177001953
Validation loss: 2.3554438698676323

Epoch: 6| Step: 7
Training loss: 2.1599597930908203
Validation loss: 2.355521568688013

Epoch: 6| Step: 8
Training loss: 1.921615481376648
Validation loss: 2.3650338239567255

Epoch: 6| Step: 9
Training loss: 2.6308867931365967
Validation loss: 2.383445468000186

Epoch: 6| Step: 10
Training loss: 3.2645232677459717
Validation loss: 2.3924226119954097

Epoch: 6| Step: 11
Training loss: 2.5378060340881348
Validation loss: 2.404584446261006

Epoch: 6| Step: 12
Training loss: 2.614189624786377
Validation loss: 2.414134251174106

Epoch: 6| Step: 13
Training loss: 3.1168954372406006
Validation loss: 2.421236034362547

Epoch: 109| Step: 0
Training loss: 2.731602191925049
Validation loss: 2.434587937529369

Epoch: 6| Step: 1
Training loss: 2.8829309940338135
Validation loss: 2.420447649494294

Epoch: 6| Step: 2
Training loss: 3.0044822692871094
Validation loss: 2.423228738128498

Epoch: 6| Step: 3
Training loss: 3.0959744453430176
Validation loss: 2.4241198134678665

Epoch: 6| Step: 4
Training loss: 1.8020035028457642
Validation loss: 2.412385294514318

Epoch: 6| Step: 5
Training loss: 2.5505027770996094
Validation loss: 2.4092232898999284

Epoch: 6| Step: 6
Training loss: 2.20963454246521
Validation loss: 2.4061234535709506

Epoch: 6| Step: 7
Training loss: 2.6482505798339844
Validation loss: 2.4122956798922632

Epoch: 6| Step: 8
Training loss: 2.038686513900757
Validation loss: 2.4195245081378567

Epoch: 6| Step: 9
Training loss: 2.4952144622802734
Validation loss: 2.444497821151569

Epoch: 6| Step: 10
Training loss: 2.4680018424987793
Validation loss: 2.474755638389177

Epoch: 6| Step: 11
Training loss: 2.9547805786132812
Validation loss: 2.547857633201025

Epoch: 6| Step: 12
Training loss: 2.59647798538208
Validation loss: 2.5363061581888506

Epoch: 6| Step: 13
Training loss: 3.613413095474243
Validation loss: 2.5030038715690694

Epoch: 110| Step: 0
Training loss: 2.3685343265533447
Validation loss: 2.483843359895932

Epoch: 6| Step: 1
Training loss: 2.0519890785217285
Validation loss: 2.470141354427543

Epoch: 6| Step: 2
Training loss: 3.040309429168701
Validation loss: 2.4386065621529855

Epoch: 6| Step: 3
Training loss: 2.7477002143859863
Validation loss: 2.4244326340254916

Epoch: 6| Step: 4
Training loss: 2.5162434577941895
Validation loss: 2.40789633668879

Epoch: 6| Step: 5
Training loss: 3.0634171962738037
Validation loss: 2.3977512749292518

Epoch: 6| Step: 6
Training loss: 3.317718029022217
Validation loss: 2.3753929984185005

Epoch: 6| Step: 7
Training loss: 3.2645158767700195
Validation loss: 2.3643437431704615

Epoch: 6| Step: 8
Training loss: 2.607523202896118
Validation loss: 2.3593911060722927

Epoch: 6| Step: 9
Training loss: 2.087804079055786
Validation loss: 2.353864319862858

Epoch: 6| Step: 10
Training loss: 2.138563632965088
Validation loss: 2.3480109860820155

Epoch: 6| Step: 11
Training loss: 2.5677051544189453
Validation loss: 2.3511307290805283

Epoch: 6| Step: 12
Training loss: 2.851346969604492
Validation loss: 2.352587133325556

Epoch: 6| Step: 13
Training loss: 1.8314204216003418
Validation loss: 2.347861046432167

Epoch: 111| Step: 0
Training loss: 2.50227689743042
Validation loss: 2.3574196574508504

Epoch: 6| Step: 1
Training loss: 2.5526015758514404
Validation loss: 2.356915191937518

Epoch: 6| Step: 2
Training loss: 2.8252663612365723
Validation loss: 2.360585452407919

Epoch: 6| Step: 3
Training loss: 3.072397232055664
Validation loss: 2.361280961703229

Epoch: 6| Step: 4
Training loss: 2.389108657836914
Validation loss: 2.361810120203162

Epoch: 6| Step: 5
Training loss: 2.0191636085510254
Validation loss: 2.3589056358542493

Epoch: 6| Step: 6
Training loss: 2.6517038345336914
Validation loss: 2.3708221681656374

Epoch: 6| Step: 7
Training loss: 2.470885992050171
Validation loss: 2.363277937776299

Epoch: 6| Step: 8
Training loss: 2.947460651397705
Validation loss: 2.3572858841188493

Epoch: 6| Step: 9
Training loss: 2.4093477725982666
Validation loss: 2.3496429740741687

Epoch: 6| Step: 10
Training loss: 2.603686809539795
Validation loss: 2.3521560597163376

Epoch: 6| Step: 11
Training loss: 2.4388985633850098
Validation loss: 2.356803168532669

Epoch: 6| Step: 12
Training loss: 3.121004104614258
Validation loss: 2.3516559959739767

Epoch: 6| Step: 13
Training loss: 2.488675355911255
Validation loss: 2.350867494460075

Epoch: 112| Step: 0
Training loss: 2.1215643882751465
Validation loss: 2.3467252049394833

Epoch: 6| Step: 1
Training loss: 2.9852454662323
Validation loss: 2.3470955920475784

Epoch: 6| Step: 2
Training loss: 1.9274272918701172
Validation loss: 2.3443680091570784

Epoch: 6| Step: 3
Training loss: 2.4930198192596436
Validation loss: 2.3400665611349125

Epoch: 6| Step: 4
Training loss: 1.9193220138549805
Validation loss: 2.3433603009869977

Epoch: 6| Step: 5
Training loss: 2.9564695358276367
Validation loss: 2.343359831840761

Epoch: 6| Step: 6
Training loss: 2.1563963890075684
Validation loss: 2.3424912216842815

Epoch: 6| Step: 7
Training loss: 3.00789475440979
Validation loss: 2.342347655245053

Epoch: 6| Step: 8
Training loss: 2.703578233718872
Validation loss: 2.3449139287394862

Epoch: 6| Step: 9
Training loss: 2.8150033950805664
Validation loss: 2.344291497302312

Epoch: 6| Step: 10
Training loss: 2.497018575668335
Validation loss: 2.344747479243945

Epoch: 6| Step: 11
Training loss: 2.38630747795105
Validation loss: 2.3448554520965903

Epoch: 6| Step: 12
Training loss: 3.1481504440307617
Validation loss: 2.3535340550125285

Epoch: 6| Step: 13
Training loss: 3.865990161895752
Validation loss: 2.366569939480033

Epoch: 113| Step: 0
Training loss: 2.500458240509033
Validation loss: 2.376770604041315

Epoch: 6| Step: 1
Training loss: 2.642465114593506
Validation loss: 2.38278841715987

Epoch: 6| Step: 2
Training loss: 3.0090889930725098
Validation loss: 2.395101862569009

Epoch: 6| Step: 3
Training loss: 2.8769373893737793
Validation loss: 2.3955373789674494

Epoch: 6| Step: 4
Training loss: 2.812471389770508
Validation loss: 2.389634652804303

Epoch: 6| Step: 5
Training loss: 2.836822986602783
Validation loss: 2.3951739393254763

Epoch: 6| Step: 6
Training loss: 2.277250289916992
Validation loss: 2.3935934574373308

Epoch: 6| Step: 7
Training loss: 2.487091064453125
Validation loss: 2.390990641809279

Epoch: 6| Step: 8
Training loss: 1.589435338973999
Validation loss: 2.401620941777383

Epoch: 6| Step: 9
Training loss: 2.662158966064453
Validation loss: 2.3895364858770884

Epoch: 6| Step: 10
Training loss: 2.4405579566955566
Validation loss: 2.3823961647607947

Epoch: 6| Step: 11
Training loss: 2.528179168701172
Validation loss: 2.381393976109002

Epoch: 6| Step: 12
Training loss: 3.1027259826660156
Validation loss: 2.3844038363425963

Epoch: 6| Step: 13
Training loss: 2.9254863262176514
Validation loss: 2.380022887260683

Epoch: 114| Step: 0
Training loss: 2.4573240280151367
Validation loss: 2.3829257975342455

Epoch: 6| Step: 1
Training loss: 2.913238763809204
Validation loss: 2.3891563415527344

Epoch: 6| Step: 2
Training loss: 2.843562602996826
Validation loss: 2.386397777065154

Epoch: 6| Step: 3
Training loss: 2.2675764560699463
Validation loss: 2.3832492956551175

Epoch: 6| Step: 4
Training loss: 2.6012206077575684
Validation loss: 2.3721308503099667

Epoch: 6| Step: 5
Training loss: 2.741065263748169
Validation loss: 2.3799534125994612

Epoch: 6| Step: 6
Training loss: 2.309061050415039
Validation loss: 2.380349761696272

Epoch: 6| Step: 7
Training loss: 2.2874066829681396
Validation loss: 2.3861200066022974

Epoch: 6| Step: 8
Training loss: 2.8853540420532227
Validation loss: 2.388089769630022

Epoch: 6| Step: 9
Training loss: 2.8585972785949707
Validation loss: 2.3860439805574316

Epoch: 6| Step: 10
Training loss: 2.3614401817321777
Validation loss: 2.3827611682235554

Epoch: 6| Step: 11
Training loss: 2.660511016845703
Validation loss: 2.3831330550614225

Epoch: 6| Step: 12
Training loss: 2.4150071144104004
Validation loss: 2.3907355928933747

Epoch: 6| Step: 13
Training loss: 2.8229966163635254
Validation loss: 2.3995349971196984

Epoch: 115| Step: 0
Training loss: 2.245638847351074
Validation loss: 2.4026150703430176

Epoch: 6| Step: 1
Training loss: 2.3407645225524902
Validation loss: 2.399779642781904

Epoch: 6| Step: 2
Training loss: 2.4838953018188477
Validation loss: 2.382504568305067

Epoch: 6| Step: 3
Training loss: 2.878976583480835
Validation loss: 2.366663077826141

Epoch: 6| Step: 4
Training loss: 2.781770706176758
Validation loss: 2.349544558473813

Epoch: 6| Step: 5
Training loss: 2.463334083557129
Validation loss: 2.3442848062002533

Epoch: 6| Step: 6
Training loss: 2.867823839187622
Validation loss: 2.3325844323763283

Epoch: 6| Step: 7
Training loss: 2.7239952087402344
Validation loss: 2.332115437394829

Epoch: 6| Step: 8
Training loss: 2.4332051277160645
Validation loss: 2.331402781189129

Epoch: 6| Step: 9
Training loss: 2.161179304122925
Validation loss: 2.3348042375297955

Epoch: 6| Step: 10
Training loss: 3.1670899391174316
Validation loss: 2.3375063993597545

Epoch: 6| Step: 11
Training loss: 2.851656675338745
Validation loss: 2.336817426066245

Epoch: 6| Step: 12
Training loss: 2.057105541229248
Validation loss: 2.339085376390847

Epoch: 6| Step: 13
Training loss: 3.3503284454345703
Validation loss: 2.3357162193585466

Epoch: 116| Step: 0
Training loss: 2.721555233001709
Validation loss: 2.3352018402468775

Epoch: 6| Step: 1
Training loss: 2.944704532623291
Validation loss: 2.331065998282484

Epoch: 6| Step: 2
Training loss: 2.9145898818969727
Validation loss: 2.3363541582579255

Epoch: 6| Step: 3
Training loss: 3.087622880935669
Validation loss: 2.333539165476317

Epoch: 6| Step: 4
Training loss: 2.330328941345215
Validation loss: 2.338655335928804

Epoch: 6| Step: 5
Training loss: 3.0678765773773193
Validation loss: 2.3368263757357033

Epoch: 6| Step: 6
Training loss: 2.8404998779296875
Validation loss: 2.3390338549049954

Epoch: 6| Step: 7
Training loss: 2.4073500633239746
Validation loss: 2.33600648244222

Epoch: 6| Step: 8
Training loss: 1.8003779649734497
Validation loss: 2.3384199911548245

Epoch: 6| Step: 9
Training loss: 2.9012951850891113
Validation loss: 2.3461684411571873

Epoch: 6| Step: 10
Training loss: 2.278024196624756
Validation loss: 2.3563676188069005

Epoch: 6| Step: 11
Training loss: 3.1136250495910645
Validation loss: 2.3654931642675914

Epoch: 6| Step: 12
Training loss: 1.9252204895019531
Validation loss: 2.3854145619177047

Epoch: 6| Step: 13
Training loss: 1.9204992055892944
Validation loss: 2.3800661897146576

Epoch: 117| Step: 0
Training loss: 3.123849391937256
Validation loss: 2.3592068713198424

Epoch: 6| Step: 1
Training loss: 2.1745338439941406
Validation loss: 2.348944784492575

Epoch: 6| Step: 2
Training loss: 2.663327693939209
Validation loss: 2.337699597881686

Epoch: 6| Step: 3
Training loss: 2.1438634395599365
Validation loss: 2.3238983974661878

Epoch: 6| Step: 4
Training loss: 2.427840232849121
Validation loss: 2.3303281786621257

Epoch: 6| Step: 5
Training loss: 2.4718575477600098
Validation loss: 2.330490158450219

Epoch: 6| Step: 6
Training loss: 3.135470390319824
Validation loss: 2.336515798363634

Epoch: 6| Step: 7
Training loss: 2.3642818927764893
Validation loss: 2.331730265771189

Epoch: 6| Step: 8
Training loss: 2.990098476409912
Validation loss: 2.337488243656774

Epoch: 6| Step: 9
Training loss: 2.042044162750244
Validation loss: 2.338638259518531

Epoch: 6| Step: 10
Training loss: 3.3546371459960938
Validation loss: 2.3414307999354538

Epoch: 6| Step: 11
Training loss: 3.0454163551330566
Validation loss: 2.333192966317618

Epoch: 6| Step: 12
Training loss: 2.687539577484131
Validation loss: 2.3332109246202695

Epoch: 6| Step: 13
Training loss: 1.696051001548767
Validation loss: 2.32803512132296

Epoch: 118| Step: 0
Training loss: 2.6748955249786377
Validation loss: 2.3185126473826747

Epoch: 6| Step: 1
Training loss: 2.3713581562042236
Validation loss: 2.32098695283295

Epoch: 6| Step: 2
Training loss: 2.7079102993011475
Validation loss: 2.3242829461251535

Epoch: 6| Step: 3
Training loss: 2.4870834350585938
Validation loss: 2.3310706333447526

Epoch: 6| Step: 4
Training loss: 1.714781403541565
Validation loss: 2.3342263878032727

Epoch: 6| Step: 5
Training loss: 2.834134101867676
Validation loss: 2.3309376060321765

Epoch: 6| Step: 6
Training loss: 2.0496158599853516
Validation loss: 2.331398799855222

Epoch: 6| Step: 7
Training loss: 3.164968967437744
Validation loss: 2.3490130773154636

Epoch: 6| Step: 8
Training loss: 2.3396458625793457
Validation loss: 2.359829971867223

Epoch: 6| Step: 9
Training loss: 2.6681666374206543
Validation loss: 2.3747464892684773

Epoch: 6| Step: 10
Training loss: 2.6946587562561035
Validation loss: 2.3849053985329083

Epoch: 6| Step: 11
Training loss: 2.3730878829956055
Validation loss: 2.3817351812957437

Epoch: 6| Step: 12
Training loss: 3.3722872734069824
Validation loss: 2.400302572916913

Epoch: 6| Step: 13
Training loss: 3.4039881229400635
Validation loss: 2.3869560956954956

Epoch: 119| Step: 0
Training loss: 2.9194321632385254
Validation loss: 2.372732934131417

Epoch: 6| Step: 1
Training loss: 2.1546378135681152
Validation loss: 2.3672522293624056

Epoch: 6| Step: 2
Training loss: 2.5305466651916504
Validation loss: 2.3733273603582896

Epoch: 6| Step: 3
Training loss: 2.65277099609375
Validation loss: 2.3678203808364047

Epoch: 6| Step: 4
Training loss: 2.306880474090576
Validation loss: 2.375664193143127

Epoch: 6| Step: 5
Training loss: 2.6037826538085938
Validation loss: 2.3771873853539907

Epoch: 6| Step: 6
Training loss: 2.5921483039855957
Validation loss: 2.380260887966361

Epoch: 6| Step: 7
Training loss: 2.7749481201171875
Validation loss: 2.3602884123402257

Epoch: 6| Step: 8
Training loss: 2.2956559658050537
Validation loss: 2.367655279815838

Epoch: 6| Step: 9
Training loss: 3.0894265174865723
Validation loss: 2.363834347776187

Epoch: 6| Step: 10
Training loss: 2.5475645065307617
Validation loss: 2.372053797527026

Epoch: 6| Step: 11
Training loss: 2.3120040893554688
Validation loss: 2.365590759502944

Epoch: 6| Step: 12
Training loss: 2.836818218231201
Validation loss: 2.359947450699345

Epoch: 6| Step: 13
Training loss: 2.9686224460601807
Validation loss: 2.3438557822217225

Epoch: 120| Step: 0
Training loss: 2.7216954231262207
Validation loss: 2.3446617895557034

Epoch: 6| Step: 1
Training loss: 2.6004245281219482
Validation loss: 2.333325457829301

Epoch: 6| Step: 2
Training loss: 2.7038867473602295
Validation loss: 2.3301036537334485

Epoch: 6| Step: 3
Training loss: 2.062554359436035
Validation loss: 2.326166396499962

Epoch: 6| Step: 4
Training loss: 2.6160149574279785
Validation loss: 2.317041704731603

Epoch: 6| Step: 5
Training loss: 3.0268306732177734
Validation loss: 2.3165560845405824

Epoch: 6| Step: 6
Training loss: 2.5074071884155273
Validation loss: 2.3144797484079995

Epoch: 6| Step: 7
Training loss: 2.360433340072632
Validation loss: 2.312404881241501

Epoch: 6| Step: 8
Training loss: 2.910104274749756
Validation loss: 2.3157299667276363

Epoch: 6| Step: 9
Training loss: 2.6350650787353516
Validation loss: 2.312400794798328

Epoch: 6| Step: 10
Training loss: 2.425462245941162
Validation loss: 2.3262396576584026

Epoch: 6| Step: 11
Training loss: 2.7267003059387207
Validation loss: 2.3481798223269883

Epoch: 6| Step: 12
Training loss: 2.4538674354553223
Validation loss: 2.368863905629804

Epoch: 6| Step: 13
Training loss: 2.4929704666137695
Validation loss: 2.3999978316727506

Epoch: 121| Step: 0
Training loss: 2.3786017894744873
Validation loss: 2.4378319991532194

Epoch: 6| Step: 1
Training loss: 3.1316795349121094
Validation loss: 2.4367410521353445

Epoch: 6| Step: 2
Training loss: 2.6556663513183594
Validation loss: 2.422320060832526

Epoch: 6| Step: 3
Training loss: 2.3645524978637695
Validation loss: 2.396383270140617

Epoch: 6| Step: 4
Training loss: 2.4576971530914307
Validation loss: 2.3826992229748796

Epoch: 6| Step: 5
Training loss: 2.4088306427001953
Validation loss: 2.373708865975821

Epoch: 6| Step: 6
Training loss: 2.9980673789978027
Validation loss: 2.377009376402824

Epoch: 6| Step: 7
Training loss: 2.8143792152404785
Validation loss: 2.373633602614044

Epoch: 6| Step: 8
Training loss: 3.174473285675049
Validation loss: 2.3675155626830233

Epoch: 6| Step: 9
Training loss: 2.614626169204712
Validation loss: 2.370824142168927

Epoch: 6| Step: 10
Training loss: 2.241852045059204
Validation loss: 2.3576065673623035

Epoch: 6| Step: 11
Training loss: 3.063930034637451
Validation loss: 2.3492226895465644

Epoch: 6| Step: 12
Training loss: 1.8277610540390015
Validation loss: 2.3190398164974746

Epoch: 6| Step: 13
Training loss: 2.374303102493286
Validation loss: 2.32210353625718

Epoch: 122| Step: 0
Training loss: 2.1974830627441406
Validation loss: 2.339983150523196

Epoch: 6| Step: 1
Training loss: 2.0731406211853027
Validation loss: 2.364176134909353

Epoch: 6| Step: 2
Training loss: 3.3258109092712402
Validation loss: 2.3559414827695457

Epoch: 6| Step: 3
Training loss: 2.7345800399780273
Validation loss: 2.3573389232799573

Epoch: 6| Step: 4
Training loss: 3.1090292930603027
Validation loss: 2.3703728991170085

Epoch: 6| Step: 5
Training loss: 2.7470903396606445
Validation loss: 2.3701903102218465

Epoch: 6| Step: 6
Training loss: 3.0042619705200195
Validation loss: 2.36998733141089

Epoch: 6| Step: 7
Training loss: 2.8784360885620117
Validation loss: 2.399659918200585

Epoch: 6| Step: 8
Training loss: 2.8974623680114746
Validation loss: 2.421369093720631

Epoch: 6| Step: 9
Training loss: 1.9490925073623657
Validation loss: 2.4326632971404702

Epoch: 6| Step: 10
Training loss: 2.4017140865325928
Validation loss: 2.411646525065104

Epoch: 6| Step: 11
Training loss: 1.9771860837936401
Validation loss: 2.39097926949942

Epoch: 6| Step: 12
Training loss: 2.9594547748565674
Validation loss: 2.3839838838064544

Epoch: 6| Step: 13
Training loss: 1.477157473564148
Validation loss: 2.390489755138274

Epoch: 123| Step: 0
Training loss: 2.679443836212158
Validation loss: 2.392278666137367

Epoch: 6| Step: 1
Training loss: 3.2397871017456055
Validation loss: 2.385511072733069

Epoch: 6| Step: 2
Training loss: 2.4863953590393066
Validation loss: 2.3628016287280666

Epoch: 6| Step: 3
Training loss: 2.3313162326812744
Validation loss: 2.343593905048986

Epoch: 6| Step: 4
Training loss: 2.4555373191833496
Validation loss: 2.337394996355939

Epoch: 6| Step: 5
Training loss: 2.9380838871002197
Validation loss: 2.330519914627075

Epoch: 6| Step: 6
Training loss: 2.117161273956299
Validation loss: 2.3265400522498676

Epoch: 6| Step: 7
Training loss: 2.846357822418213
Validation loss: 2.3217287704508793

Epoch: 6| Step: 8
Training loss: 2.051445245742798
Validation loss: 2.3221120270349647

Epoch: 6| Step: 9
Training loss: 2.6103687286376953
Validation loss: 2.327673045537805

Epoch: 6| Step: 10
Training loss: 3.7547178268432617
Validation loss: 2.328133357468472

Epoch: 6| Step: 11
Training loss: 1.919111967086792
Validation loss: 2.32560206485051

Epoch: 6| Step: 12
Training loss: 2.378920316696167
Validation loss: 2.32880901264888

Epoch: 6| Step: 13
Training loss: 1.9739691019058228
Validation loss: 2.33174366335715

Epoch: 124| Step: 0
Training loss: 2.794562816619873
Validation loss: 2.329092235975368

Epoch: 6| Step: 1
Training loss: 2.4498400688171387
Validation loss: 2.339309364236811

Epoch: 6| Step: 2
Training loss: 2.2983357906341553
Validation loss: 2.3445666938699703

Epoch: 6| Step: 3
Training loss: 2.8482697010040283
Validation loss: 2.341629805103425

Epoch: 6| Step: 4
Training loss: 2.7479805946350098
Validation loss: 2.34727983320913

Epoch: 6| Step: 5
Training loss: 2.2470617294311523
Validation loss: 2.3468479828167985

Epoch: 6| Step: 6
Training loss: 2.8893256187438965
Validation loss: 2.3512355063551214

Epoch: 6| Step: 7
Training loss: 2.6093907356262207
Validation loss: 2.3463072212793494

Epoch: 6| Step: 8
Training loss: 2.7393240928649902
Validation loss: 2.343050164561118

Epoch: 6| Step: 9
Training loss: 2.121105194091797
Validation loss: 2.3353216955738683

Epoch: 6| Step: 10
Training loss: 2.643622636795044
Validation loss: 2.332578356548022

Epoch: 6| Step: 11
Training loss: 2.380206346511841
Validation loss: 2.335697538109236

Epoch: 6| Step: 12
Training loss: 2.721365451812744
Validation loss: 2.3355783493288103

Epoch: 6| Step: 13
Training loss: 2.424206018447876
Validation loss: 2.3286242023591073

Epoch: 125| Step: 0
Training loss: 1.836134672164917
Validation loss: 2.329340478425385

Epoch: 6| Step: 1
Training loss: 2.472228527069092
Validation loss: 2.33317405434065

Epoch: 6| Step: 2
Training loss: 2.465705633163452
Validation loss: 2.327395341729605

Epoch: 6| Step: 3
Training loss: 3.3558127880096436
Validation loss: 2.332671341075692

Epoch: 6| Step: 4
Training loss: 3.1658501625061035
Validation loss: 2.3289739957419773

Epoch: 6| Step: 5
Training loss: 3.071934461593628
Validation loss: 2.3278268691032165

Epoch: 6| Step: 6
Training loss: 2.4935762882232666
Validation loss: 2.329899400793096

Epoch: 6| Step: 7
Training loss: 2.6406149864196777
Validation loss: 2.3323154910918205

Epoch: 6| Step: 8
Training loss: 2.3613414764404297
Validation loss: 2.335916196146319

Epoch: 6| Step: 9
Training loss: 2.804590940475464
Validation loss: 2.338700907204741

Epoch: 6| Step: 10
Training loss: 2.72414493560791
Validation loss: 2.34437297749263

Epoch: 6| Step: 11
Training loss: 2.065542221069336
Validation loss: 2.3455400236191286

Epoch: 6| Step: 12
Training loss: 2.6526265144348145
Validation loss: 2.3598347581842893

Epoch: 6| Step: 13
Training loss: 1.4512648582458496
Validation loss: 2.3600683417371524

Epoch: 126| Step: 0
Training loss: 3.1174397468566895
Validation loss: 2.363048561157719

Epoch: 6| Step: 1
Training loss: 2.5880942344665527
Validation loss: 2.3576501441258255

Epoch: 6| Step: 2
Training loss: 2.825178623199463
Validation loss: 2.3533017135435537

Epoch: 6| Step: 3
Training loss: 2.799724578857422
Validation loss: 2.3537613679003972

Epoch: 6| Step: 4
Training loss: 2.267634153366089
Validation loss: 2.339810966163553

Epoch: 6| Step: 5
Training loss: 2.80818247795105
Validation loss: 2.350020347102996

Epoch: 6| Step: 6
Training loss: 2.4487407207489014
Validation loss: 2.353310045375619

Epoch: 6| Step: 7
Training loss: 2.1302294731140137
Validation loss: 2.357400886474117

Epoch: 6| Step: 8
Training loss: 2.2861855030059814
Validation loss: 2.365412953079388

Epoch: 6| Step: 9
Training loss: 2.288148880004883
Validation loss: 2.384528657441498

Epoch: 6| Step: 10
Training loss: 2.5033493041992188
Validation loss: 2.3953924768714496

Epoch: 6| Step: 11
Training loss: 3.1259355545043945
Validation loss: 2.4028383454968854

Epoch: 6| Step: 12
Training loss: 2.7508907318115234
Validation loss: 2.385638598472841

Epoch: 6| Step: 13
Training loss: 1.6983883380889893
Validation loss: 2.3667767509337394

Epoch: 127| Step: 0
Training loss: 2.9802405834198
Validation loss: 2.3779200635930544

Epoch: 6| Step: 1
Training loss: 2.780210494995117
Validation loss: 2.3518954528275358

Epoch: 6| Step: 2
Training loss: 2.7629809379577637
Validation loss: 2.3387064933776855

Epoch: 6| Step: 3
Training loss: 2.744560718536377
Validation loss: 2.3203383414976058

Epoch: 6| Step: 4
Training loss: 2.6049652099609375
Validation loss: 2.3138538150377173

Epoch: 6| Step: 5
Training loss: 2.4931817054748535
Validation loss: 2.313441907205889

Epoch: 6| Step: 6
Training loss: 1.8808223009109497
Validation loss: 2.3056054858751196

Epoch: 6| Step: 7
Training loss: 2.2247109413146973
Validation loss: 2.29771182357624

Epoch: 6| Step: 8
Training loss: 3.033916711807251
Validation loss: 2.3024797849757697

Epoch: 6| Step: 9
Training loss: 2.7683308124542236
Validation loss: 2.299371883433352

Epoch: 6| Step: 10
Training loss: 2.277419328689575
Validation loss: 2.302294054339009

Epoch: 6| Step: 11
Training loss: 2.9820785522460938
Validation loss: 2.3141471365446686

Epoch: 6| Step: 12
Training loss: 2.083934783935547
Validation loss: 2.3096942927247737

Epoch: 6| Step: 13
Training loss: 2.7622838020324707
Validation loss: 2.310575444211242

Epoch: 128| Step: 0
Training loss: 2.662360668182373
Validation loss: 2.3073536042244203

Epoch: 6| Step: 1
Training loss: 2.646197557449341
Validation loss: 2.303586952147945

Epoch: 6| Step: 2
Training loss: 2.6404829025268555
Validation loss: 2.305073220242736

Epoch: 6| Step: 3
Training loss: 2.6533758640289307
Validation loss: 2.3047526523631108

Epoch: 6| Step: 4
Training loss: 2.1357388496398926
Validation loss: 2.313088813135701

Epoch: 6| Step: 5
Training loss: 2.3715600967407227
Validation loss: 2.309667759044196

Epoch: 6| Step: 6
Training loss: 1.13982093334198
Validation loss: 2.320510241293138

Epoch: 6| Step: 7
Training loss: 2.814927101135254
Validation loss: 2.321294735836726

Epoch: 6| Step: 8
Training loss: 3.004183292388916
Validation loss: 2.318264592078424

Epoch: 6| Step: 9
Training loss: 2.636867046356201
Validation loss: 2.318295141702057

Epoch: 6| Step: 10
Training loss: 3.237396001815796
Validation loss: 2.3104245406325146

Epoch: 6| Step: 11
Training loss: 2.778336524963379
Validation loss: 2.316045172752873

Epoch: 6| Step: 12
Training loss: 2.1899027824401855
Validation loss: 2.3134976901033872

Epoch: 6| Step: 13
Training loss: 3.332730293273926
Validation loss: 2.3112319387415403

Epoch: 129| Step: 0
Training loss: 2.7834010124206543
Validation loss: 2.312478824328351

Epoch: 6| Step: 1
Training loss: 2.3033645153045654
Validation loss: 2.305788961789941

Epoch: 6| Step: 2
Training loss: 2.9612159729003906
Validation loss: 2.299064346539077

Epoch: 6| Step: 3
Training loss: 2.520188331604004
Validation loss: 2.3017131897710983

Epoch: 6| Step: 4
Training loss: 2.9273433685302734
Validation loss: 2.294318122248496

Epoch: 6| Step: 5
Training loss: 2.9231035709381104
Validation loss: 2.2942072653001353

Epoch: 6| Step: 6
Training loss: 1.956107258796692
Validation loss: 2.2948921290777062

Epoch: 6| Step: 7
Training loss: 2.2107455730438232
Validation loss: 2.2926980077579455

Epoch: 6| Step: 8
Training loss: 2.9043240547180176
Validation loss: 2.2915207955145065

Epoch: 6| Step: 9
Training loss: 2.317629814147949
Validation loss: 2.2932382783582135

Epoch: 6| Step: 10
Training loss: 2.966074228286743
Validation loss: 2.2967234914020827

Epoch: 6| Step: 11
Training loss: 2.3944740295410156
Validation loss: 2.2959647588832404

Epoch: 6| Step: 12
Training loss: 2.608747959136963
Validation loss: 2.299004429130144

Epoch: 6| Step: 13
Training loss: 1.7721521854400635
Validation loss: 2.300990189275434

Epoch: 130| Step: 0
Training loss: 1.8448407649993896
Validation loss: 2.3042445951892483

Epoch: 6| Step: 1
Training loss: 2.6121253967285156
Validation loss: 2.310922722662649

Epoch: 6| Step: 2
Training loss: 2.526215076446533
Validation loss: 2.3110828630385862

Epoch: 6| Step: 3
Training loss: 3.191725730895996
Validation loss: 2.302918508488645

Epoch: 6| Step: 4
Training loss: 2.8521931171417236
Validation loss: 2.2985663490910686

Epoch: 6| Step: 5
Training loss: 2.7188754081726074
Validation loss: 2.295003124462661

Epoch: 6| Step: 6
Training loss: 2.840623140335083
Validation loss: 2.298912827686597

Epoch: 6| Step: 7
Training loss: 2.89207124710083
Validation loss: 2.3026719888051352

Epoch: 6| Step: 8
Training loss: 2.507719039916992
Validation loss: 2.3012751738230386

Epoch: 6| Step: 9
Training loss: 1.9921880960464478
Validation loss: 2.2981390722336306

Epoch: 6| Step: 10
Training loss: 3.047531843185425
Validation loss: 2.3036403527823825

Epoch: 6| Step: 11
Training loss: 2.0122387409210205
Validation loss: 2.296996239692934

Epoch: 6| Step: 12
Training loss: 2.16487717628479
Validation loss: 2.306502244805777

Epoch: 6| Step: 13
Training loss: 2.6725072860717773
Validation loss: 2.3124447073987735

Epoch: 131| Step: 0
Training loss: 2.8111746311187744
Validation loss: 2.3156702928645636

Epoch: 6| Step: 1
Training loss: 2.325348377227783
Validation loss: 2.31794822344216

Epoch: 6| Step: 2
Training loss: 2.2878170013427734
Validation loss: 2.3250627876609884

Epoch: 6| Step: 3
Training loss: 2.5051896572113037
Validation loss: 2.325343426837716

Epoch: 6| Step: 4
Training loss: 3.0160818099975586
Validation loss: 2.331725858872937

Epoch: 6| Step: 5
Training loss: 2.496377468109131
Validation loss: 2.337086057150236

Epoch: 6| Step: 6
Training loss: 2.048219919204712
Validation loss: 2.3334058817996772

Epoch: 6| Step: 7
Training loss: 2.7724907398223877
Validation loss: 2.3317625086794616

Epoch: 6| Step: 8
Training loss: 3.2254772186279297
Validation loss: 2.3271103443637973

Epoch: 6| Step: 9
Training loss: 2.1584811210632324
Validation loss: 2.322482890980218

Epoch: 6| Step: 10
Training loss: 2.325446605682373
Validation loss: 2.3430068697980655

Epoch: 6| Step: 11
Training loss: 2.5226712226867676
Validation loss: 2.355617469356906

Epoch: 6| Step: 12
Training loss: 2.5348000526428223
Validation loss: 2.3758337266983522

Epoch: 6| Step: 13
Training loss: 3.021416664123535
Validation loss: 2.3738583903158865

Epoch: 132| Step: 0
Training loss: 2.0062010288238525
Validation loss: 2.3630400806344967

Epoch: 6| Step: 1
Training loss: 3.1012043952941895
Validation loss: 2.360949347096105

Epoch: 6| Step: 2
Training loss: 3.186371088027954
Validation loss: 2.346915280947121

Epoch: 6| Step: 3
Training loss: 2.9650516510009766
Validation loss: 2.3355965204136346

Epoch: 6| Step: 4
Training loss: 2.1045081615448
Validation loss: 2.332647967082198

Epoch: 6| Step: 5
Training loss: 2.8896312713623047
Validation loss: 2.332928708804551

Epoch: 6| Step: 6
Training loss: 1.735105037689209
Validation loss: 2.3285536842961467

Epoch: 6| Step: 7
Training loss: 2.418430805206299
Validation loss: 2.3371171746202695

Epoch: 6| Step: 8
Training loss: 2.72340726852417
Validation loss: 2.331545243981064

Epoch: 6| Step: 9
Training loss: 2.8729233741760254
Validation loss: 2.341955689973729

Epoch: 6| Step: 10
Training loss: 2.2744216918945312
Validation loss: 2.32565470921096

Epoch: 6| Step: 11
Training loss: 3.3621816635131836
Validation loss: 2.3226410342801

Epoch: 6| Step: 12
Training loss: 1.6540155410766602
Validation loss: 2.3111741594088975

Epoch: 6| Step: 13
Training loss: 2.224966526031494
Validation loss: 2.3175602369411017

Epoch: 133| Step: 0
Training loss: 2.218684673309326
Validation loss: 2.3265080862147833

Epoch: 6| Step: 1
Training loss: 3.1492903232574463
Validation loss: 2.3303333277343423

Epoch: 6| Step: 2
Training loss: 2.820066452026367
Validation loss: 2.337236842801494

Epoch: 6| Step: 3
Training loss: 2.6633522510528564
Validation loss: 2.3367538195784374

Epoch: 6| Step: 4
Training loss: 2.3689732551574707
Validation loss: 2.336621830540319

Epoch: 6| Step: 5
Training loss: 2.0003297328948975
Validation loss: 2.329703679648779

Epoch: 6| Step: 6
Training loss: 2.623471260070801
Validation loss: 2.3244773418672624

Epoch: 6| Step: 7
Training loss: 1.8118469715118408
Validation loss: 2.3133138149015364

Epoch: 6| Step: 8
Training loss: 3.2389755249023438
Validation loss: 2.3043936042375464

Epoch: 6| Step: 9
Training loss: 1.9730348587036133
Validation loss: 2.29756667793438

Epoch: 6| Step: 10
Training loss: 3.523956298828125
Validation loss: 2.2980750658178843

Epoch: 6| Step: 11
Training loss: 2.3526268005371094
Validation loss: 2.302417749999672

Epoch: 6| Step: 12
Training loss: 2.4217891693115234
Validation loss: 2.30828784870845

Epoch: 6| Step: 13
Training loss: 2.5297183990478516
Validation loss: 2.3271006153475855

Epoch: 134| Step: 0
Training loss: 2.6365137100219727
Validation loss: 2.335164728985038

Epoch: 6| Step: 1
Training loss: 3.057924509048462
Validation loss: 2.3575616805784163

Epoch: 6| Step: 2
Training loss: 2.809347152709961
Validation loss: 2.3623754824361494

Epoch: 6| Step: 3
Training loss: 2.262863874435425
Validation loss: 2.335570953225577

Epoch: 6| Step: 4
Training loss: 2.43855881690979
Validation loss: 2.3228461511673464

Epoch: 6| Step: 5
Training loss: 2.6990723609924316
Validation loss: 2.3152436107717533

Epoch: 6| Step: 6
Training loss: 2.8710265159606934
Validation loss: 2.31769710458735

Epoch: 6| Step: 7
Training loss: 2.5860586166381836
Validation loss: 2.3170268176704325

Epoch: 6| Step: 8
Training loss: 2.975498676300049
Validation loss: 2.3213252867421796

Epoch: 6| Step: 9
Training loss: 2.8957109451293945
Validation loss: 2.314186088500484

Epoch: 6| Step: 10
Training loss: 2.114943504333496
Validation loss: 2.3262578825796805

Epoch: 6| Step: 11
Training loss: 1.8798779249191284
Validation loss: 2.325839663064608

Epoch: 6| Step: 12
Training loss: 2.3162877559661865
Validation loss: 2.321993121536829

Epoch: 6| Step: 13
Training loss: 1.9389997720718384
Validation loss: 2.310085690149697

Epoch: 135| Step: 0
Training loss: 2.803420066833496
Validation loss: 2.305048732347386

Epoch: 6| Step: 1
Training loss: 2.743767738342285
Validation loss: 2.3014112531497912

Epoch: 6| Step: 2
Training loss: 2.236172676086426
Validation loss: 2.3045828060437272

Epoch: 6| Step: 3
Training loss: 2.2436816692352295
Validation loss: 2.2960156932953866

Epoch: 6| Step: 4
Training loss: 2.3453898429870605
Validation loss: 2.2927097633320797

Epoch: 6| Step: 5
Training loss: 3.5637075901031494
Validation loss: 2.3002920176393244

Epoch: 6| Step: 6
Training loss: 2.304136276245117
Validation loss: 2.277214527130127

Epoch: 6| Step: 7
Training loss: 2.061662197113037
Validation loss: 2.2732971586206907

Epoch: 6| Step: 8
Training loss: 3.0348730087280273
Validation loss: 2.262879815152896

Epoch: 6| Step: 9
Training loss: 2.2736740112304688
Validation loss: 2.2535942216073312

Epoch: 6| Step: 10
Training loss: 2.4198217391967773
Validation loss: 2.253245040934573

Epoch: 6| Step: 11
Training loss: 2.4721951484680176
Validation loss: 2.2534564720687045

Epoch: 6| Step: 12
Training loss: 2.4694981575012207
Validation loss: 2.25523111128038

Epoch: 6| Step: 13
Training loss: 3.0932438373565674
Validation loss: 2.2564516951960902

Epoch: 136| Step: 0
Training loss: 2.5604944229125977
Validation loss: 2.255955167995986

Epoch: 6| Step: 1
Training loss: 2.7927675247192383
Validation loss: 2.2560317272781045

Epoch: 6| Step: 2
Training loss: 2.757201671600342
Validation loss: 2.256108122487222

Epoch: 6| Step: 3
Training loss: 2.2341432571411133
Validation loss: 2.258809294751895

Epoch: 6| Step: 4
Training loss: 2.800874710083008
Validation loss: 2.256213777808733

Epoch: 6| Step: 5
Training loss: 2.7971229553222656
Validation loss: 2.2593120862078924

Epoch: 6| Step: 6
Training loss: 2.471220016479492
Validation loss: 2.2556630385819303

Epoch: 6| Step: 7
Training loss: 1.9640538692474365
Validation loss: 2.2526205355121243

Epoch: 6| Step: 8
Training loss: 3.137462615966797
Validation loss: 2.2590613672810216

Epoch: 6| Step: 9
Training loss: 2.5162763595581055
Validation loss: 2.2566116907263316

Epoch: 6| Step: 10
Training loss: 2.020963668823242
Validation loss: 2.258986116737448

Epoch: 6| Step: 11
Training loss: 3.0278337001800537
Validation loss: 2.265241346051616

Epoch: 6| Step: 12
Training loss: 2.2498435974121094
Validation loss: 2.262439627801218

Epoch: 6| Step: 13
Training loss: 2.3763554096221924
Validation loss: 2.2672854110758793

Epoch: 137| Step: 0
Training loss: 1.9776208400726318
Validation loss: 2.2647982412768948

Epoch: 6| Step: 1
Training loss: 2.573225259780884
Validation loss: 2.2689996175868536

Epoch: 6| Step: 2
Training loss: 2.4767935276031494
Validation loss: 2.2709717827458538

Epoch: 6| Step: 3
Training loss: 1.6136748790740967
Validation loss: 2.26672423783169

Epoch: 6| Step: 4
Training loss: 2.4041061401367188
Validation loss: 2.281192215540076

Epoch: 6| Step: 5
Training loss: 3.0203614234924316
Validation loss: 2.2967147750239216

Epoch: 6| Step: 6
Training loss: 2.8750126361846924
Validation loss: 2.2945601837609404

Epoch: 6| Step: 7
Training loss: 2.7270736694335938
Validation loss: 2.292638326203951

Epoch: 6| Step: 8
Training loss: 2.7770907878875732
Validation loss: 2.294793249458395

Epoch: 6| Step: 9
Training loss: 2.519883632659912
Validation loss: 2.295209692370507

Epoch: 6| Step: 10
Training loss: 2.3768081665039062
Validation loss: 2.2935464356535222

Epoch: 6| Step: 11
Training loss: 2.4951024055480957
Validation loss: 2.2820800350558375

Epoch: 6| Step: 12
Training loss: 2.9332385063171387
Validation loss: 2.2800666786009267

Epoch: 6| Step: 13
Training loss: 3.307565450668335
Validation loss: 2.2834227495296027

Epoch: 138| Step: 0
Training loss: 1.8959184885025024
Validation loss: 2.2661639105889106

Epoch: 6| Step: 1
Training loss: 2.262725830078125
Validation loss: 2.279883882050873

Epoch: 6| Step: 2
Training loss: 1.7576838731765747
Validation loss: 2.285174298030074

Epoch: 6| Step: 3
Training loss: 2.943779468536377
Validation loss: 2.297957760031505

Epoch: 6| Step: 4
Training loss: 2.7968311309814453
Validation loss: 2.299605679768388

Epoch: 6| Step: 5
Training loss: 2.0494303703308105
Validation loss: 2.2927813632513887

Epoch: 6| Step: 6
Training loss: 2.005150318145752
Validation loss: 2.29891453507126

Epoch: 6| Step: 7
Training loss: 2.9557816982269287
Validation loss: 2.30479904144041

Epoch: 6| Step: 8
Training loss: 2.690708637237549
Validation loss: 2.301266038289634

Epoch: 6| Step: 9
Training loss: 2.539764404296875
Validation loss: 2.3051842797187065

Epoch: 6| Step: 10
Training loss: 3.4945714473724365
Validation loss: 2.307856208534651

Epoch: 6| Step: 11
Training loss: 2.836750030517578
Validation loss: 2.304720155654415

Epoch: 6| Step: 12
Training loss: 2.740840435028076
Validation loss: 2.302402501465172

Epoch: 6| Step: 13
Training loss: 2.6580967903137207
Validation loss: 2.305103922402987

Epoch: 139| Step: 0
Training loss: 2.147399425506592
Validation loss: 2.3027245254926783

Epoch: 6| Step: 1
Training loss: 2.4234423637390137
Validation loss: 2.2991454883288314

Epoch: 6| Step: 2
Training loss: 2.4155404567718506
Validation loss: 2.284336102906094

Epoch: 6| Step: 3
Training loss: 3.027845859527588
Validation loss: 2.2854878902435303

Epoch: 6| Step: 4
Training loss: 2.4605093002319336
Validation loss: 2.286229231024301

Epoch: 6| Step: 5
Training loss: 2.7072863578796387
Validation loss: 2.278169614012523

Epoch: 6| Step: 6
Training loss: 2.690688133239746
Validation loss: 2.271813561839442

Epoch: 6| Step: 7
Training loss: 2.648624897003174
Validation loss: 2.2796245005822953

Epoch: 6| Step: 8
Training loss: 2.620454788208008
Validation loss: 2.2762159250115834

Epoch: 6| Step: 9
Training loss: 2.9326629638671875
Validation loss: 2.2777950109974032

Epoch: 6| Step: 10
Training loss: 2.7201290130615234
Validation loss: 2.280530491182881

Epoch: 6| Step: 11
Training loss: 2.077007293701172
Validation loss: 2.2778320363772813

Epoch: 6| Step: 12
Training loss: 2.2060205936431885
Validation loss: 2.2737503949032036

Epoch: 6| Step: 13
Training loss: 2.191807985305786
Validation loss: 2.271705107022357

Epoch: 140| Step: 0
Training loss: 2.54437518119812
Validation loss: 2.2651214317608903

Epoch: 6| Step: 1
Training loss: 2.231191873550415
Validation loss: 2.267079827606037

Epoch: 6| Step: 2
Training loss: 2.855314254760742
Validation loss: 2.2671929328672347

Epoch: 6| Step: 3
Training loss: 1.9813485145568848
Validation loss: 2.267923790921447

Epoch: 6| Step: 4
Training loss: 2.8588314056396484
Validation loss: 2.2691159120170017

Epoch: 6| Step: 5
Training loss: 2.002115249633789
Validation loss: 2.265804477917251

Epoch: 6| Step: 6
Training loss: 2.2162399291992188
Validation loss: 2.2684217319693616

Epoch: 6| Step: 7
Training loss: 1.710418939590454
Validation loss: 2.2712416033590994

Epoch: 6| Step: 8
Training loss: 2.6045615673065186
Validation loss: 2.2678486377962175

Epoch: 6| Step: 9
Training loss: 2.660539388656616
Validation loss: 2.271615869255476

Epoch: 6| Step: 10
Training loss: 3.3277885913848877
Validation loss: 2.2731845583966983

Epoch: 6| Step: 11
Training loss: 2.9072675704956055
Validation loss: 2.2801023144875803

Epoch: 6| Step: 12
Training loss: 2.6608219146728516
Validation loss: 2.282362663617698

Epoch: 6| Step: 13
Training loss: 3.1403424739837646
Validation loss: 2.2813152856724237

Epoch: 141| Step: 0
Training loss: 2.962334632873535
Validation loss: 2.27683328300394

Epoch: 6| Step: 1
Training loss: 1.8491814136505127
Validation loss: 2.283018840256558

Epoch: 6| Step: 2
Training loss: 3.2568106651306152
Validation loss: 2.2692353110159598

Epoch: 6| Step: 3
Training loss: 2.623274326324463
Validation loss: 2.260120613600618

Epoch: 6| Step: 4
Training loss: 2.7307865619659424
Validation loss: 2.2482519149780273

Epoch: 6| Step: 5
Training loss: 2.5360615253448486
Validation loss: 2.255286355172434

Epoch: 6| Step: 6
Training loss: 3.1379189491271973
Validation loss: 2.2463359909672893

Epoch: 6| Step: 7
Training loss: 2.5790181159973145
Validation loss: 2.2535513754813903

Epoch: 6| Step: 8
Training loss: 2.47048282623291
Validation loss: 2.2548244371209094

Epoch: 6| Step: 9
Training loss: 2.86409592628479
Validation loss: 2.254664421081543

Epoch: 6| Step: 10
Training loss: 1.801936149597168
Validation loss: 2.2609890455840738

Epoch: 6| Step: 11
Training loss: 2.085231065750122
Validation loss: 2.2592438677305817

Epoch: 6| Step: 12
Training loss: 2.2762932777404785
Validation loss: 2.261654664111394

Epoch: 6| Step: 13
Training loss: 2.309589385986328
Validation loss: 2.257234650273477

Epoch: 142| Step: 0
Training loss: 2.6320457458496094
Validation loss: 2.2683032712628766

Epoch: 6| Step: 1
Training loss: 2.5370256900787354
Validation loss: 2.276530191462527

Epoch: 6| Step: 2
Training loss: 1.9999244213104248
Validation loss: 2.284873195873794

Epoch: 6| Step: 3
Training loss: 2.4246985912323
Validation loss: 2.293845151060371

Epoch: 6| Step: 4
Training loss: 2.3622241020202637
Validation loss: 2.290315874161259

Epoch: 6| Step: 5
Training loss: 2.452850580215454
Validation loss: 2.2923223677501885

Epoch: 6| Step: 6
Training loss: 2.73508358001709
Validation loss: 2.2866288103083128

Epoch: 6| Step: 7
Training loss: 2.424328088760376
Validation loss: 2.2810033931527087

Epoch: 6| Step: 8
Training loss: 2.218897819519043
Validation loss: 2.272885758389709

Epoch: 6| Step: 9
Training loss: 2.7058846950531006
Validation loss: 2.267590707348239

Epoch: 6| Step: 10
Training loss: 2.9239840507507324
Validation loss: 2.260903784023818

Epoch: 6| Step: 11
Training loss: 2.63822078704834
Validation loss: 2.2517960417655205

Epoch: 6| Step: 12
Training loss: 2.921596050262451
Validation loss: 2.25766400624347

Epoch: 6| Step: 13
Training loss: 2.1150364875793457
Validation loss: 2.248756741964689

Epoch: 143| Step: 0
Training loss: 2.464700937271118
Validation loss: 2.255806671675815

Epoch: 6| Step: 1
Training loss: 3.2214317321777344
Validation loss: 2.2646585408077446

Epoch: 6| Step: 2
Training loss: 2.2770018577575684
Validation loss: 2.2677564313334804

Epoch: 6| Step: 3
Training loss: 2.1870346069335938
Validation loss: 2.2644337633604645

Epoch: 6| Step: 4
Training loss: 2.1340296268463135
Validation loss: 2.2703785281027518

Epoch: 6| Step: 5
Training loss: 3.538607597351074
Validation loss: 2.2818170234721196

Epoch: 6| Step: 6
Training loss: 2.6104817390441895
Validation loss: 2.2787614663441977

Epoch: 6| Step: 7
Training loss: 2.1770174503326416
Validation loss: 2.274680542689498

Epoch: 6| Step: 8
Training loss: 2.586745262145996
Validation loss: 2.272422400853967

Epoch: 6| Step: 9
Training loss: 2.702904224395752
Validation loss: 2.2717415402012486

Epoch: 6| Step: 10
Training loss: 2.450188159942627
Validation loss: 2.269386501722438

Epoch: 6| Step: 11
Training loss: 2.0130696296691895
Validation loss: 2.2583999890153126

Epoch: 6| Step: 12
Training loss: 2.4598374366760254
Validation loss: 2.2708003238965104

Epoch: 6| Step: 13
Training loss: 2.539339780807495
Validation loss: 2.2705077304634997

Epoch: 144| Step: 0
Training loss: 2.8404979705810547
Validation loss: 2.27446380225561

Epoch: 6| Step: 1
Training loss: 2.626603603363037
Validation loss: 2.2790365949753792

Epoch: 6| Step: 2
Training loss: 1.9862083196640015
Validation loss: 2.285438617070516

Epoch: 6| Step: 3
Training loss: 3.0113306045532227
Validation loss: 2.2869782499087754

Epoch: 6| Step: 4
Training loss: 3.025176525115967
Validation loss: 2.2792234446412776

Epoch: 6| Step: 5
Training loss: 2.1510322093963623
Validation loss: 2.25198503463499

Epoch: 6| Step: 6
Training loss: 2.0497570037841797
Validation loss: 2.247823138390818

Epoch: 6| Step: 7
Training loss: 2.628504753112793
Validation loss: 2.24282439549764

Epoch: 6| Step: 8
Training loss: 2.1996545791625977
Validation loss: 2.2349747726994176

Epoch: 6| Step: 9
Training loss: 2.856431007385254
Validation loss: 2.227512405764672

Epoch: 6| Step: 10
Training loss: 2.209642171859741
Validation loss: 2.2256547815056256

Epoch: 6| Step: 11
Training loss: 3.0368969440460205
Validation loss: 2.227193042796145

Epoch: 6| Step: 12
Training loss: 2.2850301265716553
Validation loss: 2.2371019829985914

Epoch: 6| Step: 13
Training loss: 2.3667783737182617
Validation loss: 2.2447336450699837

Epoch: 145| Step: 0
Training loss: 2.6733360290527344
Validation loss: 2.2296527201129543

Epoch: 6| Step: 1
Training loss: 2.6903152465820312
Validation loss: 2.2217158348329606

Epoch: 6| Step: 2
Training loss: 1.8185741901397705
Validation loss: 2.2240996488960842

Epoch: 6| Step: 3
Training loss: 2.2963104248046875
Validation loss: 2.233276694051681

Epoch: 6| Step: 4
Training loss: 3.0752506256103516
Validation loss: 2.2462671392707416

Epoch: 6| Step: 5
Training loss: 2.9678843021392822
Validation loss: 2.2412422369885188

Epoch: 6| Step: 6
Training loss: 2.372793674468994
Validation loss: 2.239431837553619

Epoch: 6| Step: 7
Training loss: 2.0295567512512207
Validation loss: 2.236725071425079

Epoch: 6| Step: 8
Training loss: 2.4565889835357666
Validation loss: 2.228137203442153

Epoch: 6| Step: 9
Training loss: 2.5336971282958984
Validation loss: 2.2295954047992663

Epoch: 6| Step: 10
Training loss: 2.5530405044555664
Validation loss: 2.232689481909557

Epoch: 6| Step: 11
Training loss: 2.227102279663086
Validation loss: 2.229338953571935

Epoch: 6| Step: 12
Training loss: 2.7590575218200684
Validation loss: 2.2326198060025453

Epoch: 6| Step: 13
Training loss: 3.0411903858184814
Validation loss: 2.249875822374898

Epoch: 146| Step: 0
Training loss: 2.748854637145996
Validation loss: 2.246580772502448

Epoch: 6| Step: 1
Training loss: 2.841611862182617
Validation loss: 2.24845980059716

Epoch: 6| Step: 2
Training loss: 2.2760868072509766
Validation loss: 2.2335381661691973

Epoch: 6| Step: 3
Training loss: 2.963832139968872
Validation loss: 2.23230149925396

Epoch: 6| Step: 4
Training loss: 2.969501495361328
Validation loss: 2.233235051555018

Epoch: 6| Step: 5
Training loss: 1.7323440313339233
Validation loss: 2.232359734914636

Epoch: 6| Step: 6
Training loss: 2.38535475730896
Validation loss: 2.221569538116455

Epoch: 6| Step: 7
Training loss: 1.872398853302002
Validation loss: 2.2319973617471676

Epoch: 6| Step: 8
Training loss: 2.557401657104492
Validation loss: 2.2365088065465293

Epoch: 6| Step: 9
Training loss: 2.934227228164673
Validation loss: 2.230836714467695

Epoch: 6| Step: 10
Training loss: 1.746103048324585
Validation loss: 2.228609028682914

Epoch: 6| Step: 11
Training loss: 2.5463314056396484
Validation loss: 2.219193086829237

Epoch: 6| Step: 12
Training loss: 2.767392635345459
Validation loss: 2.2321195012779644

Epoch: 6| Step: 13
Training loss: 3.4059841632843018
Validation loss: 2.2523522043740876

Epoch: 147| Step: 0
Training loss: 2.1673519611358643
Validation loss: 2.2506760653629097

Epoch: 6| Step: 1
Training loss: 2.462651252746582
Validation loss: 2.2688887606384935

Epoch: 6| Step: 2
Training loss: 2.7102866172790527
Validation loss: 2.2598993470591884

Epoch: 6| Step: 3
Training loss: 2.820460796356201
Validation loss: 2.2740022879774853

Epoch: 6| Step: 4
Training loss: 2.641969680786133
Validation loss: 2.274512634482435

Epoch: 6| Step: 5
Training loss: 2.4394450187683105
Validation loss: 2.270645367201938

Epoch: 6| Step: 6
Training loss: 2.352226734161377
Validation loss: 2.262462995385611

Epoch: 6| Step: 7
Training loss: 2.659454107284546
Validation loss: 2.25906773408254

Epoch: 6| Step: 8
Training loss: 2.248969316482544
Validation loss: 2.25715531328673

Epoch: 6| Step: 9
Training loss: 2.2534995079040527
Validation loss: 2.2551779670100056

Epoch: 6| Step: 10
Training loss: 2.1992154121398926
Validation loss: 2.265503127087829

Epoch: 6| Step: 11
Training loss: 3.0327963829040527
Validation loss: 2.263783170330909

Epoch: 6| Step: 12
Training loss: 2.7385284900665283
Validation loss: 2.2534593074552474

Epoch: 6| Step: 13
Training loss: 2.557793140411377
Validation loss: 2.2601258754730225

Epoch: 148| Step: 0
Training loss: 3.0483498573303223
Validation loss: 2.2622082720520678

Epoch: 6| Step: 1
Training loss: 2.5763943195343018
Validation loss: 2.251259162861814

Epoch: 6| Step: 2
Training loss: 2.7442283630371094
Validation loss: 2.256950137435749

Epoch: 6| Step: 3
Training loss: 1.926934838294983
Validation loss: 2.258745047353929

Epoch: 6| Step: 4
Training loss: 2.6444711685180664
Validation loss: 2.268645232723605

Epoch: 6| Step: 5
Training loss: 2.626750946044922
Validation loss: 2.2560139035665863

Epoch: 6| Step: 6
Training loss: 2.562840700149536
Validation loss: 2.2577984320220126

Epoch: 6| Step: 7
Training loss: 2.018219470977783
Validation loss: 2.2619699329458256

Epoch: 6| Step: 8
Training loss: 3.055288791656494
Validation loss: 2.2491007774106917

Epoch: 6| Step: 9
Training loss: 2.908174753189087
Validation loss: 2.251972375377532

Epoch: 6| Step: 10
Training loss: 1.7046623229980469
Validation loss: 2.2501003460217546

Epoch: 6| Step: 11
Training loss: 1.860439658164978
Validation loss: 2.2442640412238335

Epoch: 6| Step: 12
Training loss: 2.837372064590454
Validation loss: 2.235365890687512

Epoch: 6| Step: 13
Training loss: 2.4973511695861816
Validation loss: 2.2566073120281263

Epoch: 149| Step: 0
Training loss: 3.016284465789795
Validation loss: 2.2691490457903956

Epoch: 6| Step: 1
Training loss: 2.083308696746826
Validation loss: 2.2783727645874023

Epoch: 6| Step: 2
Training loss: 2.8701987266540527
Validation loss: 2.2904775937398276

Epoch: 6| Step: 3
Training loss: 2.7414145469665527
Validation loss: 2.2952077170853973

Epoch: 6| Step: 4
Training loss: 2.5715019702911377
Validation loss: 2.308662591441985

Epoch: 6| Step: 5
Training loss: 2.883983612060547
Validation loss: 2.3057671054717033

Epoch: 6| Step: 6
Training loss: 2.528526782989502
Validation loss: 2.2736633849400345

Epoch: 6| Step: 7
Training loss: 2.830601453781128
Validation loss: 2.2564260754533993

Epoch: 6| Step: 8
Training loss: 2.3052964210510254
Validation loss: 2.264281544634091

Epoch: 6| Step: 9
Training loss: 1.8461899757385254
Validation loss: 2.257265060178695

Epoch: 6| Step: 10
Training loss: 2.099302291870117
Validation loss: 2.291531152622674

Epoch: 6| Step: 11
Training loss: 2.73272442817688
Validation loss: 2.281839996255854

Epoch: 6| Step: 12
Training loss: 2.1319468021392822
Validation loss: 2.271581344707038

Epoch: 6| Step: 13
Training loss: 2.618109703063965
Validation loss: 2.2601997954871065

Epoch: 150| Step: 0
Training loss: 2.726369619369507
Validation loss: 2.2632575317095687

Epoch: 6| Step: 1
Training loss: 2.838597297668457
Validation loss: 2.2552579577251146

Epoch: 6| Step: 2
Training loss: 2.466240406036377
Validation loss: 2.2455849134793846

Epoch: 6| Step: 3
Training loss: 2.363452434539795
Validation loss: 2.243218978246053

Epoch: 6| Step: 4
Training loss: 2.4368395805358887
Validation loss: 2.239951479819513

Epoch: 6| Step: 5
Training loss: 2.2662360668182373
Validation loss: 2.227914341034428

Epoch: 6| Step: 6
Training loss: 2.382159471511841
Validation loss: 2.230622619710943

Epoch: 6| Step: 7
Training loss: 2.292161703109741
Validation loss: 2.2148414606689126

Epoch: 6| Step: 8
Training loss: 2.2968456745147705
Validation loss: 2.226379725240892

Epoch: 6| Step: 9
Training loss: 2.4139881134033203
Validation loss: 2.2237746689909246

Epoch: 6| Step: 10
Training loss: 2.754441499710083
Validation loss: 2.222759582663095

Epoch: 6| Step: 11
Training loss: 2.8233447074890137
Validation loss: 2.2331603022031885

Epoch: 6| Step: 12
Training loss: 2.4861931800842285
Validation loss: 2.229054738116521

Epoch: 6| Step: 13
Training loss: 2.2869653701782227
Validation loss: 2.226625186140819

Epoch: 151| Step: 0
Training loss: 2.2406020164489746
Validation loss: 2.2180226707971222

Epoch: 6| Step: 1
Training loss: 2.4244909286499023
Validation loss: 2.2143426300376974

Epoch: 6| Step: 2
Training loss: 2.0737876892089844
Validation loss: 2.2121259422712427

Epoch: 6| Step: 3
Training loss: 3.017075300216675
Validation loss: 2.209414384698355

Epoch: 6| Step: 4
Training loss: 2.08089542388916
Validation loss: 2.216239342125513

Epoch: 6| Step: 5
Training loss: 2.35734224319458
Validation loss: 2.212593524686752

Epoch: 6| Step: 6
Training loss: 2.618957996368408
Validation loss: 2.22152986321398

Epoch: 6| Step: 7
Training loss: 2.47464919090271
Validation loss: 2.222822038076257

Epoch: 6| Step: 8
Training loss: 2.137564182281494
Validation loss: 2.226904889588715

Epoch: 6| Step: 9
Training loss: 2.650261402130127
Validation loss: 2.222601270162931

Epoch: 6| Step: 10
Training loss: 2.5001273155212402
Validation loss: 2.221896923998351

Epoch: 6| Step: 11
Training loss: 2.5748941898345947
Validation loss: 2.2311533779226322

Epoch: 6| Step: 12
Training loss: 2.9317798614501953
Validation loss: 2.2377746182103313

Epoch: 6| Step: 13
Training loss: 2.8315529823303223
Validation loss: 2.2389664957600255

Epoch: 152| Step: 0
Training loss: 3.2837765216827393
Validation loss: 2.233972103365006

Epoch: 6| Step: 1
Training loss: 2.2399606704711914
Validation loss: 2.227607903941985

Epoch: 6| Step: 2
Training loss: 2.5838279724121094
Validation loss: 2.2254107844445015

Epoch: 6| Step: 3
Training loss: 2.874521255493164
Validation loss: 2.2169304637498755

Epoch: 6| Step: 4
Training loss: 2.341628074645996
Validation loss: 2.214255694420107

Epoch: 6| Step: 5
Training loss: 2.358717441558838
Validation loss: 2.2088238372597644

Epoch: 6| Step: 6
Training loss: 3.153386354446411
Validation loss: 2.201327985332858

Epoch: 6| Step: 7
Training loss: 2.134366989135742
Validation loss: 2.195236773901088

Epoch: 6| Step: 8
Training loss: 2.4569411277770996
Validation loss: 2.189803905384515

Epoch: 6| Step: 9
Training loss: 2.0686898231506348
Validation loss: 2.194477044126039

Epoch: 6| Step: 10
Training loss: 1.9395142793655396
Validation loss: 2.194708219138525

Epoch: 6| Step: 11
Training loss: 2.3387186527252197
Validation loss: 2.197946051115631

Epoch: 6| Step: 12
Training loss: 2.398620367050171
Validation loss: 2.1994536615187124

Epoch: 6| Step: 13
Training loss: 2.9000165462493896
Validation loss: 2.198119919787171

Epoch: 153| Step: 0
Training loss: 3.4153714179992676
Validation loss: 2.2131352360530565

Epoch: 6| Step: 1
Training loss: 2.603071928024292
Validation loss: 2.2208464017478367

Epoch: 6| Step: 2
Training loss: 2.5161147117614746
Validation loss: 2.229963602558259

Epoch: 6| Step: 3
Training loss: 2.816986322402954
Validation loss: 2.2506571892769105

Epoch: 6| Step: 4
Training loss: 2.5995450019836426
Validation loss: 2.2623051545953237

Epoch: 6| Step: 5
Training loss: 2.2009263038635254
Validation loss: 2.2736003885986986

Epoch: 6| Step: 6
Training loss: 1.8319597244262695
Validation loss: 2.288030542353148

Epoch: 6| Step: 7
Training loss: 1.2572417259216309
Validation loss: 2.294610035034918

Epoch: 6| Step: 8
Training loss: 2.6222023963928223
Validation loss: 2.3029929578945203

Epoch: 6| Step: 9
Training loss: 2.90895414352417
Validation loss: 2.316092907741506

Epoch: 6| Step: 10
Training loss: 2.5395708084106445
Validation loss: 2.331888908980995

Epoch: 6| Step: 11
Training loss: 3.530210494995117
Validation loss: 2.3334762024623092

Epoch: 6| Step: 12
Training loss: 1.7626590728759766
Validation loss: 2.338548650023758

Epoch: 6| Step: 13
Training loss: 2.8513777256011963
Validation loss: 2.3306159511689217

Epoch: 154| Step: 0
Training loss: 2.2428219318389893
Validation loss: 2.3193043457564486

Epoch: 6| Step: 1
Training loss: 2.489631414413452
Validation loss: 2.3053309135539557

Epoch: 6| Step: 2
Training loss: 2.791046142578125
Validation loss: 2.295675813510854

Epoch: 6| Step: 3
Training loss: 1.9392080307006836
Validation loss: 2.2877951078517462

Epoch: 6| Step: 4
Training loss: 2.4224748611450195
Validation loss: 2.2734847607151156

Epoch: 6| Step: 5
Training loss: 2.332367181777954
Validation loss: 2.2612390287460817

Epoch: 6| Step: 6
Training loss: 1.9655829668045044
Validation loss: 2.236724974006735

Epoch: 6| Step: 7
Training loss: 2.427847385406494
Validation loss: 2.22438036241839

Epoch: 6| Step: 8
Training loss: 2.918846845626831
Validation loss: 2.2261504486042965

Epoch: 6| Step: 9
Training loss: 2.450089693069458
Validation loss: 2.212188918103454

Epoch: 6| Step: 10
Training loss: 2.4751369953155518
Validation loss: 2.211996614292104

Epoch: 6| Step: 11
Training loss: 2.729099988937378
Validation loss: 2.219368150157313

Epoch: 6| Step: 12
Training loss: 3.2743139266967773
Validation loss: 2.216264145348662

Epoch: 6| Step: 13
Training loss: 2.5146260261535645
Validation loss: 2.215691581849129

Epoch: 155| Step: 0
Training loss: 2.8485655784606934
Validation loss: 2.230263069111814

Epoch: 6| Step: 1
Training loss: 2.5782546997070312
Validation loss: 2.2266876056630123

Epoch: 6| Step: 2
Training loss: 2.13261079788208
Validation loss: 2.226117072566863

Epoch: 6| Step: 3
Training loss: 2.4392406940460205
Validation loss: 2.2218861925986504

Epoch: 6| Step: 4
Training loss: 2.082921266555786
Validation loss: 2.2212520568601546

Epoch: 6| Step: 5
Training loss: 3.1078484058380127
Validation loss: 2.220606642384683

Epoch: 6| Step: 6
Training loss: 2.74179744720459
Validation loss: 2.216237650122694

Epoch: 6| Step: 7
Training loss: 2.4226274490356445
Validation loss: 2.2275486325704925

Epoch: 6| Step: 8
Training loss: 3.037635087966919
Validation loss: 2.2313415106906684

Epoch: 6| Step: 9
Training loss: 2.055715560913086
Validation loss: 2.232886634847169

Epoch: 6| Step: 10
Training loss: 2.6619389057159424
Validation loss: 2.2255123866501676

Epoch: 6| Step: 11
Training loss: 2.342203378677368
Validation loss: 2.227723434407224

Epoch: 6| Step: 12
Training loss: 1.6089386940002441
Validation loss: 2.237035976943149

Epoch: 6| Step: 13
Training loss: 2.8813655376434326
Validation loss: 2.2397633983242895

Epoch: 156| Step: 0
Training loss: 2.3672938346862793
Validation loss: 2.2477208234930552

Epoch: 6| Step: 1
Training loss: 2.6004552841186523
Validation loss: 2.235897680764557

Epoch: 6| Step: 2
Training loss: 2.959379196166992
Validation loss: 2.2257828738099787

Epoch: 6| Step: 3
Training loss: 2.599219799041748
Validation loss: 2.221934222405957

Epoch: 6| Step: 4
Training loss: 2.252175807952881
Validation loss: 2.2143332035310808

Epoch: 6| Step: 5
Training loss: 2.2903053760528564
Validation loss: 2.200143893559774

Epoch: 6| Step: 6
Training loss: 2.577399730682373
Validation loss: 2.2025954210630028

Epoch: 6| Step: 7
Training loss: 2.5067217350006104
Validation loss: 2.2091421337537867

Epoch: 6| Step: 8
Training loss: 2.0661020278930664
Validation loss: 2.2247319029223536

Epoch: 6| Step: 9
Training loss: 1.7528510093688965
Validation loss: 2.227591774796927

Epoch: 6| Step: 10
Training loss: 2.831529378890991
Validation loss: 2.2332979274052445

Epoch: 6| Step: 11
Training loss: 2.081831455230713
Validation loss: 2.2170728842417398

Epoch: 6| Step: 12
Training loss: 2.844376564025879
Validation loss: 2.2146204107551166

Epoch: 6| Step: 13
Training loss: 3.72255539894104
Validation loss: 2.198767464648011

Epoch: 157| Step: 0
Training loss: 2.3153579235076904
Validation loss: 2.2062299431011243

Epoch: 6| Step: 1
Training loss: 2.671501398086548
Validation loss: 2.2011542730433966

Epoch: 6| Step: 2
Training loss: 2.5962252616882324
Validation loss: 2.2015373886272473

Epoch: 6| Step: 3
Training loss: 2.423166036605835
Validation loss: 2.219111850184779

Epoch: 6| Step: 4
Training loss: 2.368920087814331
Validation loss: 2.2160929351724605

Epoch: 6| Step: 5
Training loss: 1.980189323425293
Validation loss: 2.2110749906109226

Epoch: 6| Step: 6
Training loss: 2.815657615661621
Validation loss: 2.2113424603657057

Epoch: 6| Step: 7
Training loss: 2.009945869445801
Validation loss: 2.2069895767396495

Epoch: 6| Step: 8
Training loss: 1.2907112836837769
Validation loss: 2.2031861953837897

Epoch: 6| Step: 9
Training loss: 3.1935887336730957
Validation loss: 2.20827724600351

Epoch: 6| Step: 10
Training loss: 2.6869332790374756
Validation loss: 2.2209273435736216

Epoch: 6| Step: 11
Training loss: 2.9730091094970703
Validation loss: 2.216089358893774

Epoch: 6| Step: 12
Training loss: 3.218076229095459
Validation loss: 2.242703906951412

Epoch: 6| Step: 13
Training loss: 1.9352864027023315
Validation loss: 2.2655755653176257

Epoch: 158| Step: 0
Training loss: 2.213425636291504
Validation loss: 2.289963491501347

Epoch: 6| Step: 1
Training loss: 2.310089588165283
Validation loss: 2.3050165227664414

Epoch: 6| Step: 2
Training loss: 2.0893032550811768
Validation loss: 2.333629569699687

Epoch: 6| Step: 3
Training loss: 2.630660057067871
Validation loss: 2.344935959385287

Epoch: 6| Step: 4
Training loss: 2.564087390899658
Validation loss: 2.3381649909480924

Epoch: 6| Step: 5
Training loss: 2.683116912841797
Validation loss: 2.3237941598379486

Epoch: 6| Step: 6
Training loss: 2.6376383304595947
Validation loss: 2.2997351256749963

Epoch: 6| Step: 7
Training loss: 2.4821717739105225
Validation loss: 2.2610045684281217

Epoch: 6| Step: 8
Training loss: 2.5521790981292725
Validation loss: 2.238448094296199

Epoch: 6| Step: 9
Training loss: 2.931417465209961
Validation loss: 2.2211576789937992

Epoch: 6| Step: 10
Training loss: 2.7858567237854004
Validation loss: 2.211490842603868

Epoch: 6| Step: 11
Training loss: 1.9544870853424072
Validation loss: 2.2139835716575704

Epoch: 6| Step: 12
Training loss: 2.570289373397827
Validation loss: 2.2073498925855084

Epoch: 6| Step: 13
Training loss: 2.645203113555908
Validation loss: 2.2120016800459994

Epoch: 159| Step: 0
Training loss: 2.4113121032714844
Validation loss: 2.2178533256694837

Epoch: 6| Step: 1
Training loss: 2.0428009033203125
Validation loss: 2.2065270434143724

Epoch: 6| Step: 2
Training loss: 2.5605521202087402
Validation loss: 2.208316885015016

Epoch: 6| Step: 3
Training loss: 2.0672030448913574
Validation loss: 2.1966470749147478

Epoch: 6| Step: 4
Training loss: 2.7940478324890137
Validation loss: 2.1990074188478532

Epoch: 6| Step: 5
Training loss: 2.09873628616333
Validation loss: 2.194469751850251

Epoch: 6| Step: 6
Training loss: 3.0315985679626465
Validation loss: 2.202553674738894

Epoch: 6| Step: 7
Training loss: 2.91574764251709
Validation loss: 2.193548074332617

Epoch: 6| Step: 8
Training loss: 1.870339274406433
Validation loss: 2.197750381244126

Epoch: 6| Step: 9
Training loss: 2.1696763038635254
Validation loss: 2.1926415710039038

Epoch: 6| Step: 10
Training loss: 3.090574264526367
Validation loss: 2.187157948811849

Epoch: 6| Step: 11
Training loss: 2.5826873779296875
Validation loss: 2.1939801195616364

Epoch: 6| Step: 12
Training loss: 2.2601985931396484
Validation loss: 2.1888336186767905

Epoch: 6| Step: 13
Training loss: 2.8048951625823975
Validation loss: 2.2025863739752

Epoch: 160| Step: 0
Training loss: 2.9788665771484375
Validation loss: 2.2053657911157094

Epoch: 6| Step: 1
Training loss: 1.5926134586334229
Validation loss: 2.210701970643895

Epoch: 6| Step: 2
Training loss: 2.457357883453369
Validation loss: 2.2157219238178705

Epoch: 6| Step: 3
Training loss: 2.8419783115386963
Validation loss: 2.2328489698389524

Epoch: 6| Step: 4
Training loss: 2.957897424697876
Validation loss: 2.2361702790824314

Epoch: 6| Step: 5
Training loss: 3.1091666221618652
Validation loss: 2.2412011854110228

Epoch: 6| Step: 6
Training loss: 3.2782232761383057
Validation loss: 2.236954373698081

Epoch: 6| Step: 7
Training loss: 2.617300510406494
Validation loss: 2.2448723675102316

Epoch: 6| Step: 8
Training loss: 2.298739433288574
Validation loss: 2.2463013408004597

Epoch: 6| Step: 9
Training loss: 2.252715826034546
Validation loss: 2.244617323721609

Epoch: 6| Step: 10
Training loss: 1.6053590774536133
Validation loss: 2.242522132012152

Epoch: 6| Step: 11
Training loss: 2.3311595916748047
Validation loss: 2.248818620558708

Epoch: 6| Step: 12
Training loss: 1.6773921251296997
Validation loss: 2.2360897307754843

Epoch: 6| Step: 13
Training loss: 2.594693422317505
Validation loss: 2.2366809819334295

Epoch: 161| Step: 0
Training loss: 2.969475746154785
Validation loss: 2.2454483560336533

Epoch: 6| Step: 1
Training loss: 2.3741908073425293
Validation loss: 2.2421845492496284

Epoch: 6| Step: 2
Training loss: 2.7736148834228516
Validation loss: 2.2457066069367113

Epoch: 6| Step: 3
Training loss: 2.190629005432129
Validation loss: 2.2423864423587756

Epoch: 6| Step: 4
Training loss: 1.4275462627410889
Validation loss: 2.240824963456841

Epoch: 6| Step: 5
Training loss: 2.9389896392822266
Validation loss: 2.2405803690674486

Epoch: 6| Step: 6
Training loss: 2.560962438583374
Validation loss: 2.2438672998900056

Epoch: 6| Step: 7
Training loss: 2.324230194091797
Validation loss: 2.251849115535777

Epoch: 6| Step: 8
Training loss: 2.549304485321045
Validation loss: 2.237296142885762

Epoch: 6| Step: 9
Training loss: 2.5055322647094727
Validation loss: 2.2301617001974456

Epoch: 6| Step: 10
Training loss: 2.5710740089416504
Validation loss: 2.2223960609846216

Epoch: 6| Step: 11
Training loss: 2.3058533668518066
Validation loss: 2.203016327273461

Epoch: 6| Step: 12
Training loss: 2.9831955432891846
Validation loss: 2.211903320845737

Epoch: 6| Step: 13
Training loss: 1.162466049194336
Validation loss: 2.2055032189174364

Epoch: 162| Step: 0
Training loss: 2.6772403717041016
Validation loss: 2.2132180660001692

Epoch: 6| Step: 1
Training loss: 2.393038749694824
Validation loss: 2.2133786550132175

Epoch: 6| Step: 2
Training loss: 2.536482334136963
Validation loss: 2.220386561527047

Epoch: 6| Step: 3
Training loss: 1.5693857669830322
Validation loss: 2.237083735004548

Epoch: 6| Step: 4
Training loss: 2.989628314971924
Validation loss: 2.247943342372935

Epoch: 6| Step: 5
Training loss: 2.518838882446289
Validation loss: 2.2503303584232124

Epoch: 6| Step: 6
Training loss: 1.9622883796691895
Validation loss: 2.2639053124253468

Epoch: 6| Step: 7
Training loss: 2.1725845336914062
Validation loss: 2.282790255802934

Epoch: 6| Step: 8
Training loss: 2.259355306625366
Validation loss: 2.281641593543432

Epoch: 6| Step: 9
Training loss: 2.7737770080566406
Validation loss: 2.2789370603458856

Epoch: 6| Step: 10
Training loss: 2.718205451965332
Validation loss: 2.2733677100109797

Epoch: 6| Step: 11
Training loss: 2.902275323867798
Validation loss: 2.260235813356215

Epoch: 6| Step: 12
Training loss: 2.2148890495300293
Validation loss: 2.261222690664312

Epoch: 6| Step: 13
Training loss: 2.815995931625366
Validation loss: 2.2510376373926797

Epoch: 163| Step: 0
Training loss: 2.739560127258301
Validation loss: 2.2532655680051414

Epoch: 6| Step: 1
Training loss: 2.047179698944092
Validation loss: 2.218894194531184

Epoch: 6| Step: 2
Training loss: 2.8703935146331787
Validation loss: 2.2155335872404036

Epoch: 6| Step: 3
Training loss: 2.5125784873962402
Validation loss: 2.200986639145882

Epoch: 6| Step: 4
Training loss: 2.4464309215545654
Validation loss: 2.182643431489186

Epoch: 6| Step: 5
Training loss: 2.3450675010681152
Validation loss: 2.180910782147479

Epoch: 6| Step: 6
Training loss: 2.8800878524780273
Validation loss: 2.169223295745029

Epoch: 6| Step: 7
Training loss: 2.6151700019836426
Validation loss: 2.1738529128413044

Epoch: 6| Step: 8
Training loss: 2.4825897216796875
Validation loss: 2.1721212684467273

Epoch: 6| Step: 9
Training loss: 3.0582690238952637
Validation loss: 2.1822953352364163

Epoch: 6| Step: 10
Training loss: 2.3893966674804688
Validation loss: 2.183173897445843

Epoch: 6| Step: 11
Training loss: 2.212209939956665
Validation loss: 2.1863148263705674

Epoch: 6| Step: 12
Training loss: 1.784523844718933
Validation loss: 2.191157502512778

Epoch: 6| Step: 13
Training loss: 1.8748283386230469
Validation loss: 2.1945956342963764

Epoch: 164| Step: 0
Training loss: 2.283231019973755
Validation loss: 2.198634596281154

Epoch: 6| Step: 1
Training loss: 2.451397657394409
Validation loss: 2.191317496761199

Epoch: 6| Step: 2
Training loss: 3.0948190689086914
Validation loss: 2.20705549563131

Epoch: 6| Step: 3
Training loss: 2.599788188934326
Validation loss: 2.196658234442434

Epoch: 6| Step: 4
Training loss: 2.279414176940918
Validation loss: 2.1977607511704966

Epoch: 6| Step: 5
Training loss: 2.4159412384033203
Validation loss: 2.183937426536314

Epoch: 6| Step: 6
Training loss: 2.044069290161133
Validation loss: 2.192746577724334

Epoch: 6| Step: 7
Training loss: 2.6094846725463867
Validation loss: 2.188005047459756

Epoch: 6| Step: 8
Training loss: 2.380688190460205
Validation loss: 2.1952391055322464

Epoch: 6| Step: 9
Training loss: 2.8574156761169434
Validation loss: 2.1933857856258268

Epoch: 6| Step: 10
Training loss: 2.2612340450286865
Validation loss: 2.190628958004777

Epoch: 6| Step: 11
Training loss: 2.359639883041382
Validation loss: 2.1890671432659192

Epoch: 6| Step: 12
Training loss: 2.6491217613220215
Validation loss: 2.1930551464839647

Epoch: 6| Step: 13
Training loss: 1.826363444328308
Validation loss: 2.193326593727194

Epoch: 165| Step: 0
Training loss: 2.7834086418151855
Validation loss: 2.209768054305866

Epoch: 6| Step: 1
Training loss: 2.29465389251709
Validation loss: 2.2082704395376225

Epoch: 6| Step: 2
Training loss: 2.5440831184387207
Validation loss: 2.2258650718196744

Epoch: 6| Step: 3
Training loss: 2.329314947128296
Validation loss: 2.259540870625486

Epoch: 6| Step: 4
Training loss: 2.561321496963501
Validation loss: 2.27833233341094

Epoch: 6| Step: 5
Training loss: 2.0930628776550293
Validation loss: 2.2815402271927043

Epoch: 6| Step: 6
Training loss: 2.783785820007324
Validation loss: 2.288800625390904

Epoch: 6| Step: 7
Training loss: 2.636302947998047
Validation loss: 2.2668776307054745

Epoch: 6| Step: 8
Training loss: 2.16878342628479
Validation loss: 2.2563902024299867

Epoch: 6| Step: 9
Training loss: 2.4234769344329834
Validation loss: 2.2510596347111527

Epoch: 6| Step: 10
Training loss: 2.3216822147369385
Validation loss: 2.2491199508790047

Epoch: 6| Step: 11
Training loss: 3.1028027534484863
Validation loss: 2.2476322215090514

Epoch: 6| Step: 12
Training loss: 1.6757466793060303
Validation loss: 2.236053552678836

Epoch: 6| Step: 13
Training loss: 2.578155279159546
Validation loss: 2.2286809900755524

Epoch: 166| Step: 0
Training loss: 2.4859395027160645
Validation loss: 2.224703663138933

Epoch: 6| Step: 1
Training loss: 2.179600238800049
Validation loss: 2.2260653588079635

Epoch: 6| Step: 2
Training loss: 2.6971731185913086
Validation loss: 2.220840877102267

Epoch: 6| Step: 3
Training loss: 2.1839945316314697
Validation loss: 2.2139620050307243

Epoch: 6| Step: 4
Training loss: 2.164936065673828
Validation loss: 2.213739623305618

Epoch: 6| Step: 5
Training loss: 2.651395797729492
Validation loss: 2.217484620309645

Epoch: 6| Step: 6
Training loss: 2.294419288635254
Validation loss: 2.212687346243089

Epoch: 6| Step: 7
Training loss: 2.8171322345733643
Validation loss: 2.2190407271026285

Epoch: 6| Step: 8
Training loss: 2.7467784881591797
Validation loss: 2.2139816643089376

Epoch: 6| Step: 9
Training loss: 2.6815247535705566
Validation loss: 2.2137474142095095

Epoch: 6| Step: 10
Training loss: 2.1404671669006348
Validation loss: 2.210566479672668

Epoch: 6| Step: 11
Training loss: 1.4365177154541016
Validation loss: 2.2096203680961364

Epoch: 6| Step: 12
Training loss: 2.7694075107574463
Validation loss: 2.2090459126298145

Epoch: 6| Step: 13
Training loss: 3.038346529006958
Validation loss: 2.2084195536951863

Epoch: 167| Step: 0
Training loss: 2.938415288925171
Validation loss: 2.213613023040115

Epoch: 6| Step: 1
Training loss: 2.256883144378662
Validation loss: 2.2116181465887252

Epoch: 6| Step: 2
Training loss: 2.2001805305480957
Validation loss: 2.2127077118042977

Epoch: 6| Step: 3
Training loss: 1.9902340173721313
Validation loss: 2.207176487932923

Epoch: 6| Step: 4
Training loss: 2.2071475982666016
Validation loss: 2.211737932697419

Epoch: 6| Step: 5
Training loss: 2.1404950618743896
Validation loss: 2.2128448511964534

Epoch: 6| Step: 6
Training loss: 2.7183170318603516
Validation loss: 2.1960537382351455

Epoch: 6| Step: 7
Training loss: 3.406991481781006
Validation loss: 2.2037875780495266

Epoch: 6| Step: 8
Training loss: 2.440194606781006
Validation loss: 2.208087618632983

Epoch: 6| Step: 9
Training loss: 2.556741714477539
Validation loss: 2.237791015255836

Epoch: 6| Step: 10
Training loss: 2.4357779026031494
Validation loss: 2.2206078985685944

Epoch: 6| Step: 11
Training loss: 2.5946807861328125
Validation loss: 2.239386563659996

Epoch: 6| Step: 12
Training loss: 1.8330228328704834
Validation loss: 2.246023731846963

Epoch: 6| Step: 13
Training loss: 2.2537598609924316
Validation loss: 2.2460887419280184

Epoch: 168| Step: 0
Training loss: 2.896782636642456
Validation loss: 2.277645036738406

Epoch: 6| Step: 1
Training loss: 2.9467804431915283
Validation loss: 2.2787769122790267

Epoch: 6| Step: 2
Training loss: 1.4727412462234497
Validation loss: 2.2787220119148173

Epoch: 6| Step: 3
Training loss: 2.6020565032958984
Validation loss: 2.2509112614457325

Epoch: 6| Step: 4
Training loss: 2.19512677192688
Validation loss: 2.232958225793736

Epoch: 6| Step: 5
Training loss: 2.1564180850982666
Validation loss: 2.216451898697884

Epoch: 6| Step: 6
Training loss: 2.5535993576049805
Validation loss: 2.2196335792541504

Epoch: 6| Step: 7
Training loss: 2.5836377143859863
Validation loss: 2.2155327963572677

Epoch: 6| Step: 8
Training loss: 1.765405297279358
Validation loss: 2.2116757259573987

Epoch: 6| Step: 9
Training loss: 2.8504834175109863
Validation loss: 2.2096120106276644

Epoch: 6| Step: 10
Training loss: 2.631686210632324
Validation loss: 2.2089440284236783

Epoch: 6| Step: 11
Training loss: 2.5079264640808105
Validation loss: 2.2102014018643286

Epoch: 6| Step: 12
Training loss: 2.607926845550537
Validation loss: 2.210437972058532

Epoch: 6| Step: 13
Training loss: 2.687819242477417
Validation loss: 2.2079880955398723

Epoch: 169| Step: 0
Training loss: 1.822524070739746
Validation loss: 2.198525649245067

Epoch: 6| Step: 1
Training loss: 2.2005767822265625
Validation loss: 2.1919258089475733

Epoch: 6| Step: 2
Training loss: 2.2193946838378906
Validation loss: 2.189098365845219

Epoch: 6| Step: 3
Training loss: 3.0362377166748047
Validation loss: 2.195409615834554

Epoch: 6| Step: 4
Training loss: 2.0067524909973145
Validation loss: 2.195694572182112

Epoch: 6| Step: 5
Training loss: 2.4678022861480713
Validation loss: 2.196037197625765

Epoch: 6| Step: 6
Training loss: 3.1269116401672363
Validation loss: 2.204277028319656

Epoch: 6| Step: 7
Training loss: 2.5026586055755615
Validation loss: 2.2123309348219182

Epoch: 6| Step: 8
Training loss: 2.724043846130371
Validation loss: 2.204268063268354

Epoch: 6| Step: 9
Training loss: 2.9287028312683105
Validation loss: 2.2058008947680072

Epoch: 6| Step: 10
Training loss: 1.8984098434448242
Validation loss: 2.2010459515356247

Epoch: 6| Step: 11
Training loss: 2.5456130504608154
Validation loss: 2.200450554970772

Epoch: 6| Step: 12
Training loss: 2.080460548400879
Validation loss: 2.200890638495004

Epoch: 6| Step: 13
Training loss: 2.3209402561187744
Validation loss: 2.208405702344833

Epoch: 170| Step: 0
Training loss: 1.9165713787078857
Validation loss: 2.2068027270737516

Epoch: 6| Step: 1
Training loss: 2.455040454864502
Validation loss: 2.210538189898255

Epoch: 6| Step: 2
Training loss: 2.7732691764831543
Validation loss: 2.2122913727196316

Epoch: 6| Step: 3
Training loss: 2.5301709175109863
Validation loss: 2.2164943295140422

Epoch: 6| Step: 4
Training loss: 3.2627055644989014
Validation loss: 2.2178722248282483

Epoch: 6| Step: 5
Training loss: 1.6034878492355347
Validation loss: 2.2018478813991753

Epoch: 6| Step: 6
Training loss: 1.865535855293274
Validation loss: 2.213568074728853

Epoch: 6| Step: 7
Training loss: 2.8461263179779053
Validation loss: 2.204234430866857

Epoch: 6| Step: 8
Training loss: 2.5904228687286377
Validation loss: 2.2001298896728025

Epoch: 6| Step: 9
Training loss: 1.7889978885650635
Validation loss: 2.2001667612342426

Epoch: 6| Step: 10
Training loss: 2.3659026622772217
Validation loss: 2.1906641862725698

Epoch: 6| Step: 11
Training loss: 1.9963102340698242
Validation loss: 2.1890178342019357

Epoch: 6| Step: 12
Training loss: 2.5311293601989746
Validation loss: 2.192362900703184

Epoch: 6| Step: 13
Training loss: 4.068122386932373
Validation loss: 2.1912774450035504

Epoch: 171| Step: 0
Training loss: 2.4721198081970215
Validation loss: 2.1997994120403

Epoch: 6| Step: 1
Training loss: 2.397268056869507
Validation loss: 2.1984950803941294

Epoch: 6| Step: 2
Training loss: 2.6038479804992676
Validation loss: 2.1992647506857432

Epoch: 6| Step: 3
Training loss: 2.289368152618408
Validation loss: 2.1961615841875792

Epoch: 6| Step: 4
Training loss: 2.399728298187256
Validation loss: 2.20963656133221

Epoch: 6| Step: 5
Training loss: 2.102219343185425
Validation loss: 2.2134858856918993

Epoch: 6| Step: 6
Training loss: 1.8909509181976318
Validation loss: 2.2089691367200626

Epoch: 6| Step: 7
Training loss: 2.4168074131011963
Validation loss: 2.2180724502891622

Epoch: 6| Step: 8
Training loss: 2.9532570838928223
Validation loss: 2.220595395693215

Epoch: 6| Step: 9
Training loss: 2.4640064239501953
Validation loss: 2.2180746268200617

Epoch: 6| Step: 10
Training loss: 2.0894932746887207
Validation loss: 2.216836993412305

Epoch: 6| Step: 11
Training loss: 2.5678818225860596
Validation loss: 2.209301781910722

Epoch: 6| Step: 12
Training loss: 2.0961802005767822
Validation loss: 2.210060243965477

Epoch: 6| Step: 13
Training loss: 3.4313104152679443
Validation loss: 2.1974006314431467

Epoch: 172| Step: 0
Training loss: 2.2312800884246826
Validation loss: 2.2064396873597176

Epoch: 6| Step: 1
Training loss: 2.9307327270507812
Validation loss: 2.2172424665061374

Epoch: 6| Step: 2
Training loss: 2.0611109733581543
Validation loss: 2.192098266334944

Epoch: 6| Step: 3
Training loss: 2.6176555156707764
Validation loss: 2.202835211189844

Epoch: 6| Step: 4
Training loss: 2.792736053466797
Validation loss: 2.1887920953894175

Epoch: 6| Step: 5
Training loss: 2.7685060501098633
Validation loss: 2.1957371542530675

Epoch: 6| Step: 6
Training loss: 2.1752371788024902
Validation loss: 2.1937171028506373

Epoch: 6| Step: 7
Training loss: 2.714240312576294
Validation loss: 2.198842406272888

Epoch: 6| Step: 8
Training loss: 2.4726932048797607
Validation loss: 2.1970282882772465

Epoch: 6| Step: 9
Training loss: 2.2411184310913086
Validation loss: 2.1990956132129957

Epoch: 6| Step: 10
Training loss: 2.349799156188965
Validation loss: 2.2028899910629436

Epoch: 6| Step: 11
Training loss: 2.6131486892700195
Validation loss: 2.207693710122057

Epoch: 6| Step: 12
Training loss: 1.3733904361724854
Validation loss: 2.2115169904565297

Epoch: 6| Step: 13
Training loss: 2.3012077808380127
Validation loss: 2.2223458469554944

Epoch: 173| Step: 0
Training loss: 2.344259023666382
Validation loss: 2.225031150284634

Epoch: 6| Step: 1
Training loss: 2.644723653793335
Validation loss: 2.2278048761429323

Epoch: 6| Step: 2
Training loss: 2.3643736839294434
Validation loss: 2.26565231046369

Epoch: 6| Step: 3
Training loss: 2.2350895404815674
Validation loss: 2.2820909228376163

Epoch: 6| Step: 4
Training loss: 2.2628846168518066
Validation loss: 2.2663655127248457

Epoch: 6| Step: 5
Training loss: 2.211048126220703
Validation loss: 2.2599545448057112

Epoch: 6| Step: 6
Training loss: 2.2704968452453613
Validation loss: 2.2329197186295704

Epoch: 6| Step: 7
Training loss: 2.9095935821533203
Validation loss: 2.2098507778618925

Epoch: 6| Step: 8
Training loss: 2.2164664268493652
Validation loss: 2.205095378301477

Epoch: 6| Step: 9
Training loss: 1.7077891826629639
Validation loss: 2.202491198816607

Epoch: 6| Step: 10
Training loss: 2.610220193862915
Validation loss: 2.2103320398638324

Epoch: 6| Step: 11
Training loss: 2.942379951477051
Validation loss: 2.1913978002404653

Epoch: 6| Step: 12
Training loss: 2.9539880752563477
Validation loss: 2.191466527600442

Epoch: 6| Step: 13
Training loss: 1.8793730735778809
Validation loss: 2.1937136150175527

Epoch: 174| Step: 0
Training loss: 2.141622304916382
Validation loss: 2.182692082979346

Epoch: 6| Step: 1
Training loss: 2.5632424354553223
Validation loss: 2.1863085428873696

Epoch: 6| Step: 2
Training loss: 2.117849826812744
Validation loss: 2.182132379983061

Epoch: 6| Step: 3
Training loss: 2.1279046535491943
Validation loss: 2.195687752898021

Epoch: 6| Step: 4
Training loss: 2.9641966819763184
Validation loss: 2.198257697525845

Epoch: 6| Step: 5
Training loss: 2.49562931060791
Validation loss: 2.1898021492906796

Epoch: 6| Step: 6
Training loss: 1.601307988166809
Validation loss: 2.198423321529101

Epoch: 6| Step: 7
Training loss: 1.9696478843688965
Validation loss: 2.1909287591134348

Epoch: 6| Step: 8
Training loss: 2.1015665531158447
Validation loss: 2.184958650219825

Epoch: 6| Step: 9
Training loss: 2.710115909576416
Validation loss: 2.1985777090954524

Epoch: 6| Step: 10
Training loss: 2.7139668464660645
Validation loss: 2.2110016422887004

Epoch: 6| Step: 11
Training loss: 2.679381847381592
Validation loss: 2.218125920141897

Epoch: 6| Step: 12
Training loss: 2.6220943927764893
Validation loss: 2.2234878181129374

Epoch: 6| Step: 13
Training loss: 3.029967784881592
Validation loss: 2.213373271367883

Epoch: 175| Step: 0
Training loss: 2.623375654220581
Validation loss: 2.2070959460350776

Epoch: 6| Step: 1
Training loss: 2.2830703258514404
Validation loss: 2.1947824967804777

Epoch: 6| Step: 2
Training loss: 2.722602367401123
Validation loss: 2.1950105287695445

Epoch: 6| Step: 3
Training loss: 2.627960681915283
Validation loss: 2.1872786501402497

Epoch: 6| Step: 4
Training loss: 2.5985491275787354
Validation loss: 2.19068919715061

Epoch: 6| Step: 5
Training loss: 2.6018662452697754
Validation loss: 2.1936663478933354

Epoch: 6| Step: 6
Training loss: 2.0152697563171387
Validation loss: 2.2073708708568285

Epoch: 6| Step: 7
Training loss: 2.6926050186157227
Validation loss: 2.197449884107036

Epoch: 6| Step: 8
Training loss: 2.5362401008605957
Validation loss: 2.1910058272782194

Epoch: 6| Step: 9
Training loss: 2.3230013847351074
Validation loss: 2.1926784182107575

Epoch: 6| Step: 10
Training loss: 1.8814098834991455
Validation loss: 2.175974040903071

Epoch: 6| Step: 11
Training loss: 3.186718702316284
Validation loss: 2.18173417481043

Epoch: 6| Step: 12
Training loss: 1.6594139337539673
Validation loss: 2.187296962225309

Epoch: 6| Step: 13
Training loss: 1.2892869710922241
Validation loss: 2.1825184206808768

Epoch: 176| Step: 0
Training loss: 2.619143486022949
Validation loss: 2.1910438281233593

Epoch: 6| Step: 1
Training loss: 3.202824831008911
Validation loss: 2.198497672234812

Epoch: 6| Step: 2
Training loss: 1.9975957870483398
Validation loss: 2.192643686007428

Epoch: 6| Step: 3
Training loss: 3.7005209922790527
Validation loss: 2.19284011215292

Epoch: 6| Step: 4
Training loss: 2.4639601707458496
Validation loss: 2.1966124144933556

Epoch: 6| Step: 5
Training loss: 1.9424967765808105
Validation loss: 2.203117084759538

Epoch: 6| Step: 6
Training loss: 2.5150723457336426
Validation loss: 2.1940668449606946

Epoch: 6| Step: 7
Training loss: 1.8999552726745605
Validation loss: 2.2113636668010423

Epoch: 6| Step: 8
Training loss: 3.025070905685425
Validation loss: 2.2214034744488296

Epoch: 6| Step: 9
Training loss: 1.4700572490692139
Validation loss: 2.2078772732006606

Epoch: 6| Step: 10
Training loss: 2.5145294666290283
Validation loss: 2.202899762379226

Epoch: 6| Step: 11
Training loss: 2.33546781539917
Validation loss: 2.1922299195361394

Epoch: 6| Step: 12
Training loss: 1.7483421564102173
Validation loss: 2.1976106423203663

Epoch: 6| Step: 13
Training loss: 1.8758574724197388
Validation loss: 2.1850947154465543

Epoch: 177| Step: 0
Training loss: 2.2890567779541016
Validation loss: 2.1895626360370266

Epoch: 6| Step: 1
Training loss: 2.828620672225952
Validation loss: 2.184636183964309

Epoch: 6| Step: 2
Training loss: 2.7930257320404053
Validation loss: 2.199388304064351

Epoch: 6| Step: 3
Training loss: 2.595580577850342
Validation loss: 2.186763560900124

Epoch: 6| Step: 4
Training loss: 2.2154393196105957
Validation loss: 2.1895617028718353

Epoch: 6| Step: 5
Training loss: 2.3526206016540527
Validation loss: 2.1856929896980204

Epoch: 6| Step: 6
Training loss: 2.5577056407928467
Validation loss: 2.202030224184836

Epoch: 6| Step: 7
Training loss: 1.696643352508545
Validation loss: 2.188843004165157

Epoch: 6| Step: 8
Training loss: 2.8777377605438232
Validation loss: 2.1930584420440016

Epoch: 6| Step: 9
Training loss: 2.1839447021484375
Validation loss: 2.191837638937017

Epoch: 6| Step: 10
Training loss: 2.4765260219573975
Validation loss: 2.196188942078621

Epoch: 6| Step: 11
Training loss: 2.066833019256592
Validation loss: 2.209357674403857

Epoch: 6| Step: 12
Training loss: 2.3779776096343994
Validation loss: 2.2089354325366277

Epoch: 6| Step: 13
Training loss: 1.7164427042007446
Validation loss: 2.1951782088125906

Epoch: 178| Step: 0
Training loss: 2.90144681930542
Validation loss: 2.185492181008862

Epoch: 6| Step: 1
Training loss: 2.6400139331817627
Validation loss: 2.193448298720903

Epoch: 6| Step: 2
Training loss: 2.3511552810668945
Validation loss: 2.190485180065196

Epoch: 6| Step: 3
Training loss: 2.223587989807129
Validation loss: 2.1929707411796815

Epoch: 6| Step: 4
Training loss: 2.2395529747009277
Validation loss: 2.183390937825685

Epoch: 6| Step: 5
Training loss: 2.44299054145813
Validation loss: 2.185835393526221

Epoch: 6| Step: 6
Training loss: 2.451270818710327
Validation loss: 2.1887320805621404

Epoch: 6| Step: 7
Training loss: 2.148524761199951
Validation loss: 2.1778786028585126

Epoch: 6| Step: 8
Training loss: 2.533329963684082
Validation loss: 2.186862063664262

Epoch: 6| Step: 9
Training loss: 1.9799458980560303
Validation loss: 2.1851510360676754

Epoch: 6| Step: 10
Training loss: 1.9672750234603882
Validation loss: 2.191475986152567

Epoch: 6| Step: 11
Training loss: 2.220018148422241
Validation loss: 2.1855943664427726

Epoch: 6| Step: 12
Training loss: 2.816089630126953
Validation loss: 2.1995231207980903

Epoch: 6| Step: 13
Training loss: 2.4301486015319824
Validation loss: 2.1866741872602895

Epoch: 179| Step: 0
Training loss: 2.698930025100708
Validation loss: 2.1869230411385976

Epoch: 6| Step: 1
Training loss: 2.301112651824951
Validation loss: 2.184249690783921

Epoch: 6| Step: 2
Training loss: 2.246985912322998
Validation loss: 2.1728148703934043

Epoch: 6| Step: 3
Training loss: 2.038713216781616
Validation loss: 2.1748616541585615

Epoch: 6| Step: 4
Training loss: 2.0851809978485107
Validation loss: 2.1829917584696124

Epoch: 6| Step: 5
Training loss: 2.1432695388793945
Validation loss: 2.1810442093879945

Epoch: 6| Step: 6
Training loss: 2.470867872238159
Validation loss: 2.181043373641147

Epoch: 6| Step: 7
Training loss: 2.722414970397949
Validation loss: 2.184965064448695

Epoch: 6| Step: 8
Training loss: 2.538266658782959
Validation loss: 2.1816220591145177

Epoch: 6| Step: 9
Training loss: 2.4078543186187744
Validation loss: 2.176547053039715

Epoch: 6| Step: 10
Training loss: 2.697462320327759
Validation loss: 2.180008393461986

Epoch: 6| Step: 11
Training loss: 1.9608314037322998
Validation loss: 2.1773504493057088

Epoch: 6| Step: 12
Training loss: 2.6367902755737305
Validation loss: 2.1866201995521464

Epoch: 6| Step: 13
Training loss: 2.040721893310547
Validation loss: 2.16684151464893

Epoch: 180| Step: 0
Training loss: 2.868734359741211
Validation loss: 2.1839412335426576

Epoch: 6| Step: 1
Training loss: 3.5609066486358643
Validation loss: 2.178803297781175

Epoch: 6| Step: 2
Training loss: 2.835874557495117
Validation loss: 2.1828771586059244

Epoch: 6| Step: 3
Training loss: 1.63546884059906
Validation loss: 2.177667925434728

Epoch: 6| Step: 4
Training loss: 1.8901724815368652
Validation loss: 2.176787640458794

Epoch: 6| Step: 5
Training loss: 2.0927000045776367
Validation loss: 2.1816293039629535

Epoch: 6| Step: 6
Training loss: 3.196782350540161
Validation loss: 2.1901560957713793

Epoch: 6| Step: 7
Training loss: 2.953089475631714
Validation loss: 2.1946756173205633

Epoch: 6| Step: 8
Training loss: 2.1961207389831543
Validation loss: 2.1932134859023558

Epoch: 6| Step: 9
Training loss: 1.7985129356384277
Validation loss: 2.1865571596289195

Epoch: 6| Step: 10
Training loss: 2.2415473461151123
Validation loss: 2.1797103394744215

Epoch: 6| Step: 11
Training loss: 1.2099385261535645
Validation loss: 2.1728646729582097

Epoch: 6| Step: 12
Training loss: 2.584860324859619
Validation loss: 2.184452623449346

Epoch: 6| Step: 13
Training loss: 1.9379305839538574
Validation loss: 2.181727924654561

Epoch: 181| Step: 0
Training loss: 2.25050687789917
Validation loss: 2.1864674962976927

Epoch: 6| Step: 1
Training loss: 2.7645790576934814
Validation loss: 2.1817137246490805

Epoch: 6| Step: 2
Training loss: 2.16324782371521
Validation loss: 2.1796034254053587

Epoch: 6| Step: 3
Training loss: 1.9527010917663574
Validation loss: 2.177925968682894

Epoch: 6| Step: 4
Training loss: 2.913356065750122
Validation loss: 2.183994564958798

Epoch: 6| Step: 5
Training loss: 2.198132038116455
Validation loss: 2.1803837232692267

Epoch: 6| Step: 6
Training loss: 2.415351390838623
Validation loss: 2.1748798072979016

Epoch: 6| Step: 7
Training loss: 2.058485746383667
Validation loss: 2.1705175407471193

Epoch: 6| Step: 8
Training loss: 2.2433440685272217
Validation loss: 2.1788196973903204

Epoch: 6| Step: 9
Training loss: 1.9548542499542236
Validation loss: 2.2048466410688174

Epoch: 6| Step: 10
Training loss: 2.6058435440063477
Validation loss: 2.2442244099032496

Epoch: 6| Step: 11
Training loss: 2.3971290588378906
Validation loss: 2.2729302811366257

Epoch: 6| Step: 12
Training loss: 2.5635883808135986
Validation loss: 2.2790092563116424

Epoch: 6| Step: 13
Training loss: 2.9809954166412354
Validation loss: 2.2507618883604645

Epoch: 182| Step: 0
Training loss: 2.1832544803619385
Validation loss: 2.2484342180272585

Epoch: 6| Step: 1
Training loss: 2.0618531703948975
Validation loss: 2.2014241244203303

Epoch: 6| Step: 2
Training loss: 2.095028877258301
Validation loss: 2.183798219567986

Epoch: 6| Step: 3
Training loss: 2.1600751876831055
Validation loss: 2.1587140355058896

Epoch: 6| Step: 4
Training loss: 2.388731002807617
Validation loss: 2.1700379604934366

Epoch: 6| Step: 5
Training loss: 2.6751906871795654
Validation loss: 2.176109157582765

Epoch: 6| Step: 6
Training loss: 3.090562582015991
Validation loss: 2.191140538902693

Epoch: 6| Step: 7
Training loss: 2.433136224746704
Validation loss: 2.19337607583692

Epoch: 6| Step: 8
Training loss: 2.678556203842163
Validation loss: 2.1985103725105204

Epoch: 6| Step: 9
Training loss: 2.65747332572937
Validation loss: 2.191556630596038

Epoch: 6| Step: 10
Training loss: 1.9438905715942383
Validation loss: 2.168025020630129

Epoch: 6| Step: 11
Training loss: 2.0202739238739014
Validation loss: 2.1771127870005946

Epoch: 6| Step: 12
Training loss: 2.422581195831299
Validation loss: 2.1580386905259985

Epoch: 6| Step: 13
Training loss: 2.1894655227661133
Validation loss: 2.171938278341806

Epoch: 183| Step: 0
Training loss: 1.5242817401885986
Validation loss: 2.179840971064824

Epoch: 6| Step: 1
Training loss: 2.072950601577759
Validation loss: 2.1943854696007183

Epoch: 6| Step: 2
Training loss: 2.8044893741607666
Validation loss: 2.223997735208081

Epoch: 6| Step: 3
Training loss: 2.3404688835144043
Validation loss: 2.2176375081462245

Epoch: 6| Step: 4
Training loss: 2.347024917602539
Validation loss: 2.2292455934709117

Epoch: 6| Step: 5
Training loss: 2.374354124069214
Validation loss: 2.2239275042728712

Epoch: 6| Step: 6
Training loss: 2.5985193252563477
Validation loss: 2.2057049658990677

Epoch: 6| Step: 7
Training loss: 3.1244444847106934
Validation loss: 2.1945552018380936

Epoch: 6| Step: 8
Training loss: 2.1623950004577637
Validation loss: 2.1736067354038195

Epoch: 6| Step: 9
Training loss: 2.8386611938476562
Validation loss: 2.166023803013627

Epoch: 6| Step: 10
Training loss: 1.9548982381820679
Validation loss: 2.16533564495784

Epoch: 6| Step: 11
Training loss: 1.807130217552185
Validation loss: 2.1748830259487195

Epoch: 6| Step: 12
Training loss: 2.563999652862549
Validation loss: 2.1692436997608473

Epoch: 6| Step: 13
Training loss: 3.063626289367676
Validation loss: 2.163671214093444

Epoch: 184| Step: 0
Training loss: 2.9174656867980957
Validation loss: 2.158910702633601

Epoch: 6| Step: 1
Training loss: 2.694797992706299
Validation loss: 2.153824516521987

Epoch: 6| Step: 2
Training loss: 1.8147121667861938
Validation loss: 2.15047437144864

Epoch: 6| Step: 3
Training loss: 2.5028841495513916
Validation loss: 2.1470963954925537

Epoch: 6| Step: 4
Training loss: 2.250913143157959
Validation loss: 2.1407866657421155

Epoch: 6| Step: 5
Training loss: 2.3560738563537598
Validation loss: 2.1362929267268025

Epoch: 6| Step: 6
Training loss: 2.7332818508148193
Validation loss: 2.1562391865637993

Epoch: 6| Step: 7
Training loss: 2.4110774993896484
Validation loss: 2.1432112622004684

Epoch: 6| Step: 8
Training loss: 1.6568175554275513
Validation loss: 2.1544455277022494

Epoch: 6| Step: 9
Training loss: 2.234192132949829
Validation loss: 2.161739657002111

Epoch: 6| Step: 10
Training loss: 2.6719534397125244
Validation loss: 2.1649223168691

Epoch: 6| Step: 11
Training loss: 2.4421043395996094
Validation loss: 2.170294571948308

Epoch: 6| Step: 12
Training loss: 2.116103172302246
Validation loss: 2.178279571635749

Epoch: 6| Step: 13
Training loss: 1.9775159358978271
Validation loss: 2.1809431763105493

Epoch: 185| Step: 0
Training loss: 2.0855188369750977
Validation loss: 2.180933088384649

Epoch: 6| Step: 1
Training loss: 2.1519134044647217
Validation loss: 2.1834701363758375

Epoch: 6| Step: 2
Training loss: 2.0092411041259766
Validation loss: 2.1855038007100425

Epoch: 6| Step: 3
Training loss: 2.2232532501220703
Validation loss: 2.1815929848660707

Epoch: 6| Step: 4
Training loss: 1.7141027450561523
Validation loss: 2.1828769663328766

Epoch: 6| Step: 5
Training loss: 3.182631731033325
Validation loss: 2.1868935400439846

Epoch: 6| Step: 6
Training loss: 2.2970783710479736
Validation loss: 2.1746018086710284

Epoch: 6| Step: 7
Training loss: 2.212268829345703
Validation loss: 2.1803882045130574

Epoch: 6| Step: 8
Training loss: 3.2138049602508545
Validation loss: 2.1827637110987017

Epoch: 6| Step: 9
Training loss: 2.723724365234375
Validation loss: 2.1885270021295034

Epoch: 6| Step: 10
Training loss: 2.691701650619507
Validation loss: 2.1806893066693376

Epoch: 6| Step: 11
Training loss: 2.227424383163452
Validation loss: 2.1723193148131013

Epoch: 6| Step: 12
Training loss: 2.2860188484191895
Validation loss: 2.159531085721908

Epoch: 6| Step: 13
Training loss: 1.57026207447052
Validation loss: 2.163092076137502

Epoch: 186| Step: 0
Training loss: 2.0517563819885254
Validation loss: 2.156438681387132

Epoch: 6| Step: 1
Training loss: 2.299569845199585
Validation loss: 2.1573519783635295

Epoch: 6| Step: 2
Training loss: 2.106846809387207
Validation loss: 2.166591731450891

Epoch: 6| Step: 3
Training loss: 2.5069777965545654
Validation loss: 2.1531695986306794

Epoch: 6| Step: 4
Training loss: 2.3017821311950684
Validation loss: 2.151872395187296

Epoch: 6| Step: 5
Training loss: 2.906589984893799
Validation loss: 2.155350862010833

Epoch: 6| Step: 6
Training loss: 1.796110987663269
Validation loss: 2.155882863588231

Epoch: 6| Step: 7
Training loss: 2.1290342807769775
Validation loss: 2.153543628672118

Epoch: 6| Step: 8
Training loss: 2.4914486408233643
Validation loss: 2.1620089495053856

Epoch: 6| Step: 9
Training loss: 2.9441421031951904
Validation loss: 2.167593233046993

Epoch: 6| Step: 10
Training loss: 2.308077812194824
Validation loss: 2.1582393082239295

Epoch: 6| Step: 11
Training loss: 2.573166847229004
Validation loss: 2.1704974994864514

Epoch: 6| Step: 12
Training loss: 2.092966318130493
Validation loss: 2.172155270012476

Epoch: 6| Step: 13
Training loss: 2.033141613006592
Validation loss: 2.1694539003474738

Epoch: 187| Step: 0
Training loss: 1.8075222969055176
Validation loss: 2.170155595707637

Epoch: 6| Step: 1
Training loss: 1.9312208890914917
Validation loss: 2.1740102152670584

Epoch: 6| Step: 2
Training loss: 1.9897950887680054
Validation loss: 2.1583673287463445

Epoch: 6| Step: 3
Training loss: 2.7422070503234863
Validation loss: 2.1541639271602837

Epoch: 6| Step: 4
Training loss: 2.871755361557007
Validation loss: 2.154974547765588

Epoch: 6| Step: 5
Training loss: 2.430845260620117
Validation loss: 2.151567227096968

Epoch: 6| Step: 6
Training loss: 1.8527145385742188
Validation loss: 2.172325695714643

Epoch: 6| Step: 7
Training loss: 1.7503876686096191
Validation loss: 2.173181390249601

Epoch: 6| Step: 8
Training loss: 2.7489829063415527
Validation loss: 2.1677303365481797

Epoch: 6| Step: 9
Training loss: 2.2646355628967285
Validation loss: 2.180999784059422

Epoch: 6| Step: 10
Training loss: 2.819766044616699
Validation loss: 2.176142672056793

Epoch: 6| Step: 11
Training loss: 3.3241186141967773
Validation loss: 2.1875653728362052

Epoch: 6| Step: 12
Training loss: 2.2681493759155273
Validation loss: 2.2235513374369633

Epoch: 6| Step: 13
Training loss: 1.7146848440170288
Validation loss: 2.22858876182187

Epoch: 188| Step: 0
Training loss: 1.4549119472503662
Validation loss: 2.2257555197643977

Epoch: 6| Step: 1
Training loss: 2.3727049827575684
Validation loss: 2.2220946511914654

Epoch: 6| Step: 2
Training loss: 2.605747699737549
Validation loss: 2.2129958829572125

Epoch: 6| Step: 3
Training loss: 2.5067532062530518
Validation loss: 2.203184881517964

Epoch: 6| Step: 4
Training loss: 2.200637102127075
Validation loss: 2.1896401746298677

Epoch: 6| Step: 5
Training loss: 2.0522708892822266
Validation loss: 2.1721404970333142

Epoch: 6| Step: 6
Training loss: 2.3037755489349365
Validation loss: 2.1705508411571546

Epoch: 6| Step: 7
Training loss: 2.301358222961426
Validation loss: 2.166462463717307

Epoch: 6| Step: 8
Training loss: 3.1227469444274902
Validation loss: 2.1786566780459498

Epoch: 6| Step: 9
Training loss: 3.1135993003845215
Validation loss: 2.1701150222491195

Epoch: 6| Step: 10
Training loss: 2.1556873321533203
Validation loss: 2.1688256404733144

Epoch: 6| Step: 11
Training loss: 1.8267576694488525
Validation loss: 2.1525163035238943

Epoch: 6| Step: 12
Training loss: 2.673823833465576
Validation loss: 2.165494180494739

Epoch: 6| Step: 13
Training loss: 2.0882253646850586
Validation loss: 2.161577534931962

Epoch: 189| Step: 0
Training loss: 3.069448947906494
Validation loss: 2.155986960216235

Epoch: 6| Step: 1
Training loss: 1.7591663599014282
Validation loss: 2.1622524594747894

Epoch: 6| Step: 2
Training loss: 2.1574904918670654
Validation loss: 2.154612528380527

Epoch: 6| Step: 3
Training loss: 2.101430892944336
Validation loss: 2.168566842232981

Epoch: 6| Step: 4
Training loss: 2.4470577239990234
Validation loss: 2.1816920042037964

Epoch: 6| Step: 5
Training loss: 2.7637858390808105
Validation loss: 2.174669886148104

Epoch: 6| Step: 6
Training loss: 1.7478432655334473
Validation loss: 2.17079226175944

Epoch: 6| Step: 7
Training loss: 2.9956600666046143
Validation loss: 2.1856312572315173

Epoch: 6| Step: 8
Training loss: 2.2761621475219727
Validation loss: 2.182299442188714

Epoch: 6| Step: 9
Training loss: 2.616809129714966
Validation loss: 2.171298325702708

Epoch: 6| Step: 10
Training loss: 1.7350207567214966
Validation loss: 2.1708160805445846

Epoch: 6| Step: 11
Training loss: 1.914368987083435
Validation loss: 2.171695183682185

Epoch: 6| Step: 12
Training loss: 2.626837730407715
Validation loss: 2.156924743806162

Epoch: 6| Step: 13
Training loss: 2.4029948711395264
Validation loss: 2.1580082883117018

Epoch: 190| Step: 0
Training loss: 1.8787508010864258
Validation loss: 2.1537818857418594

Epoch: 6| Step: 1
Training loss: 2.7851786613464355
Validation loss: 2.1473969157024095

Epoch: 6| Step: 2
Training loss: 2.6066694259643555
Validation loss: 2.1368950490028626

Epoch: 6| Step: 3
Training loss: 2.686981439590454
Validation loss: 2.1472801290532595

Epoch: 6| Step: 4
Training loss: 2.129265546798706
Validation loss: 2.1436875020304034

Epoch: 6| Step: 5
Training loss: 1.7482211589813232
Validation loss: 2.148971152561967

Epoch: 6| Step: 6
Training loss: 2.296402931213379
Validation loss: 2.158200676723193

Epoch: 6| Step: 7
Training loss: 2.3215456008911133
Validation loss: 2.1727994206131145

Epoch: 6| Step: 8
Training loss: 2.7498230934143066
Validation loss: 2.1906372167730845

Epoch: 6| Step: 9
Training loss: 2.688925266265869
Validation loss: 2.1986568127909014

Epoch: 6| Step: 10
Training loss: 1.6436066627502441
Validation loss: 2.2113004012774398

Epoch: 6| Step: 11
Training loss: 2.4658937454223633
Validation loss: 2.1790858673793014

Epoch: 6| Step: 12
Training loss: 3.015183925628662
Validation loss: 2.1698536360135643

Epoch: 6| Step: 13
Training loss: 1.540987253189087
Validation loss: 2.154358063974688

Epoch: 191| Step: 0
Training loss: 2.829982280731201
Validation loss: 2.1707013409624816

Epoch: 6| Step: 1
Training loss: 2.3190274238586426
Validation loss: 2.1707547787697083

Epoch: 6| Step: 2
Training loss: 1.4861735105514526
Validation loss: 2.167110045750936

Epoch: 6| Step: 3
Training loss: 2.2358994483947754
Validation loss: 2.168335094246813

Epoch: 6| Step: 4
Training loss: 2.0299766063690186
Validation loss: 2.1637097763758835

Epoch: 6| Step: 5
Training loss: 2.4678077697753906
Validation loss: 2.159781289357011

Epoch: 6| Step: 6
Training loss: 2.4693777561187744
Validation loss: 2.159231170531242

Epoch: 6| Step: 7
Training loss: 2.665619373321533
Validation loss: 2.1579096266018447

Epoch: 6| Step: 8
Training loss: 2.5749096870422363
Validation loss: 2.1542020997693463

Epoch: 6| Step: 9
Training loss: 1.6446993350982666
Validation loss: 2.14057433220648

Epoch: 6| Step: 10
Training loss: 2.7366483211517334
Validation loss: 2.1480676640746412

Epoch: 6| Step: 11
Training loss: 2.4404778480529785
Validation loss: 2.1458099067852063

Epoch: 6| Step: 12
Training loss: 2.2812604904174805
Validation loss: 2.1472569665601178

Epoch: 6| Step: 13
Training loss: 2.49690318107605
Validation loss: 2.144015242976527

Epoch: 192| Step: 0
Training loss: 2.162795066833496
Validation loss: 2.1433350398976314

Epoch: 6| Step: 1
Training loss: 2.234584331512451
Validation loss: 2.151317229834936

Epoch: 6| Step: 2
Training loss: 2.170542001724243
Validation loss: 2.160676387048537

Epoch: 6| Step: 3
Training loss: 1.6889007091522217
Validation loss: 2.1706893751698155

Epoch: 6| Step: 4
Training loss: 2.2905735969543457
Validation loss: 2.1680382092793784

Epoch: 6| Step: 5
Training loss: 2.338306427001953
Validation loss: 2.1656936778817126

Epoch: 6| Step: 6
Training loss: 2.566453456878662
Validation loss: 2.144940076335784

Epoch: 6| Step: 7
Training loss: 1.955078363418579
Validation loss: 2.152782699113251

Epoch: 6| Step: 8
Training loss: 1.9609687328338623
Validation loss: 2.141343121887535

Epoch: 6| Step: 9
Training loss: 2.967034339904785
Validation loss: 2.1340949535369873

Epoch: 6| Step: 10
Training loss: 2.665536880493164
Validation loss: 2.1540759481409544

Epoch: 6| Step: 11
Training loss: 2.6747379302978516
Validation loss: 2.1521732781523015

Epoch: 6| Step: 12
Training loss: 2.5359134674072266
Validation loss: 2.148450024666325

Epoch: 6| Step: 13
Training loss: 1.7797499895095825
Validation loss: 2.1515034142360894

Epoch: 193| Step: 0
Training loss: 1.8207662105560303
Validation loss: 2.16830305258433

Epoch: 6| Step: 1
Training loss: 2.0423293113708496
Validation loss: 2.1634792486826577

Epoch: 6| Step: 2
Training loss: 2.7516791820526123
Validation loss: 2.152987234054073

Epoch: 6| Step: 3
Training loss: 1.7270662784576416
Validation loss: 2.148546388072352

Epoch: 6| Step: 4
Training loss: 1.7916111946105957
Validation loss: 2.149944151601484

Epoch: 6| Step: 5
Training loss: 2.115464448928833
Validation loss: 2.1517157644353886

Epoch: 6| Step: 6
Training loss: 2.0930066108703613
Validation loss: 2.161826556728732

Epoch: 6| Step: 7
Training loss: 2.6563665866851807
Validation loss: 2.149720581628943

Epoch: 6| Step: 8
Training loss: 3.004559278488159
Validation loss: 2.167948304965932

Epoch: 6| Step: 9
Training loss: 2.7315375804901123
Validation loss: 2.155686778406943

Epoch: 6| Step: 10
Training loss: 2.266324520111084
Validation loss: 2.156775197675151

Epoch: 6| Step: 11
Training loss: 2.449457883834839
Validation loss: 2.1597909004457536

Epoch: 6| Step: 12
Training loss: 2.2316441535949707
Validation loss: 2.148846508354269

Epoch: 6| Step: 13
Training loss: 2.681286334991455
Validation loss: 2.148287950023528

Epoch: 194| Step: 0
Training loss: 2.171870470046997
Validation loss: 2.1396469749430174

Epoch: 6| Step: 1
Training loss: 2.6198694705963135
Validation loss: 2.137048080403318

Epoch: 6| Step: 2
Training loss: 2.95954966545105
Validation loss: 2.1406649056301323

Epoch: 6| Step: 3
Training loss: 2.818418025970459
Validation loss: 2.1421505123056392

Epoch: 6| Step: 4
Training loss: 1.7334439754486084
Validation loss: 2.1433478914281374

Epoch: 6| Step: 5
Training loss: 2.438786029815674
Validation loss: 2.143108052592124

Epoch: 6| Step: 6
Training loss: 1.8090131282806396
Validation loss: 2.145418365796407

Epoch: 6| Step: 7
Training loss: 2.2095563411712646
Validation loss: 2.1540088294654764

Epoch: 6| Step: 8
Training loss: 2.6711063385009766
Validation loss: 2.146312106040216

Epoch: 6| Step: 9
Training loss: 1.8931517601013184
Validation loss: 2.1445949051969793

Epoch: 6| Step: 10
Training loss: 2.2348427772521973
Validation loss: 2.1577253316038396

Epoch: 6| Step: 11
Training loss: 2.7168893814086914
Validation loss: 2.1393179175674275

Epoch: 6| Step: 12
Training loss: 2.001633882522583
Validation loss: 2.1680607757260724

Epoch: 6| Step: 13
Training loss: 1.7592344284057617
Validation loss: 2.1556037036321496

Epoch: 195| Step: 0
Training loss: 2.121732711791992
Validation loss: 2.158418283667616

Epoch: 6| Step: 1
Training loss: 1.8048069477081299
Validation loss: 2.173234906247867

Epoch: 6| Step: 2
Training loss: 2.2802443504333496
Validation loss: 2.1583843205564763

Epoch: 6| Step: 3
Training loss: 2.6792197227478027
Validation loss: 2.150557679514731

Epoch: 6| Step: 4
Training loss: 2.5986547470092773
Validation loss: 2.1473406771177888

Epoch: 6| Step: 5
Training loss: 1.309494972229004
Validation loss: 2.1351297209339757

Epoch: 6| Step: 6
Training loss: 2.368988037109375
Validation loss: 2.141105187836514

Epoch: 6| Step: 7
Training loss: 3.0857884883880615
Validation loss: 2.146544292408933

Epoch: 6| Step: 8
Training loss: 1.6294151544570923
Validation loss: 2.1465652758075344

Epoch: 6| Step: 9
Training loss: 2.617797374725342
Validation loss: 2.1318337327690533

Epoch: 6| Step: 10
Training loss: 2.7673959732055664
Validation loss: 2.142375930663078

Epoch: 6| Step: 11
Training loss: 2.318054676055908
Validation loss: 2.1459348663207023

Epoch: 6| Step: 12
Training loss: 2.0383553504943848
Validation loss: 2.1441179988204793

Epoch: 6| Step: 13
Training loss: 3.1119840145111084
Validation loss: 2.1458582673021542

Epoch: 196| Step: 0
Training loss: 2.463524103164673
Validation loss: 2.1366048910284556

Epoch: 6| Step: 1
Training loss: 2.3453946113586426
Validation loss: 2.1543836926901214

Epoch: 6| Step: 2
Training loss: 2.573037624359131
Validation loss: 2.14279261455741

Epoch: 6| Step: 3
Training loss: 2.0332586765289307
Validation loss: 2.1415241456800893

Epoch: 6| Step: 4
Training loss: 1.7056589126586914
Validation loss: 2.161071208215529

Epoch: 6| Step: 5
Training loss: 2.4943642616271973
Validation loss: 2.1803305251623994

Epoch: 6| Step: 6
Training loss: 2.6886515617370605
Validation loss: 2.1884243026856454

Epoch: 6| Step: 7
Training loss: 2.0791659355163574
Validation loss: 2.1921188216055594

Epoch: 6| Step: 8
Training loss: 1.799899935722351
Validation loss: 2.2001971993395077

Epoch: 6| Step: 9
Training loss: 2.3541736602783203
Validation loss: 2.2046814541662894

Epoch: 6| Step: 10
Training loss: 2.235590934753418
Validation loss: 2.193757405845068

Epoch: 6| Step: 11
Training loss: 2.5105276107788086
Validation loss: 2.160205048899497

Epoch: 6| Step: 12
Training loss: 2.673245429992676
Validation loss: 2.156856111300889

Epoch: 6| Step: 13
Training loss: 2.3480050563812256
Validation loss: 2.1585847831541494

Epoch: 197| Step: 0
Training loss: 1.4638490676879883
Validation loss: 2.149274259485224

Epoch: 6| Step: 1
Training loss: 2.1302402019500732
Validation loss: 2.1364262796217397

Epoch: 6| Step: 2
Training loss: 2.131742000579834
Validation loss: 2.1444310013965895

Epoch: 6| Step: 3
Training loss: 2.5376791954040527
Validation loss: 2.1857758747634066

Epoch: 6| Step: 4
Training loss: 2.178898334503174
Validation loss: 2.177354233239287

Epoch: 6| Step: 5
Training loss: 2.2762489318847656
Validation loss: 2.1615510473969164

Epoch: 6| Step: 6
Training loss: 2.458189010620117
Validation loss: 2.1485140528730167

Epoch: 6| Step: 7
Training loss: 2.5486998558044434
Validation loss: 2.133978025887602

Epoch: 6| Step: 8
Training loss: 2.665248155593872
Validation loss: 2.1520697967980498

Epoch: 6| Step: 9
Training loss: 2.462925910949707
Validation loss: 2.1670456855527815

Epoch: 6| Step: 10
Training loss: 2.749377965927124
Validation loss: 2.183437225639179

Epoch: 6| Step: 11
Training loss: 2.181518316268921
Validation loss: 2.168436001705867

Epoch: 6| Step: 12
Training loss: 2.6277565956115723
Validation loss: 2.1663004147109164

Epoch: 6| Step: 13
Training loss: 2.149531364440918
Validation loss: 2.148467880423351

Epoch: 198| Step: 0
Training loss: 1.7143404483795166
Validation loss: 2.134223122750559

Epoch: 6| Step: 1
Training loss: 2.529543876647949
Validation loss: 2.1348534066190004

Epoch: 6| Step: 2
Training loss: 1.8605568408966064
Validation loss: 2.121369634905169

Epoch: 6| Step: 3
Training loss: 2.4376440048217773
Validation loss: 2.126949441048407

Epoch: 6| Step: 4
Training loss: 2.352570056915283
Validation loss: 2.1474163019528953

Epoch: 6| Step: 5
Training loss: 2.4076108932495117
Validation loss: 2.18334178258014

Epoch: 6| Step: 6
Training loss: 2.5606935024261475
Validation loss: 2.2094032674707393

Epoch: 6| Step: 7
Training loss: 3.0965301990509033
Validation loss: 2.236973952221614

Epoch: 6| Step: 8
Training loss: 2.518925666809082
Validation loss: 2.215353165903399

Epoch: 6| Step: 9
Training loss: 2.2588539123535156
Validation loss: 2.1933011854848554

Epoch: 6| Step: 10
Training loss: 2.5631351470947266
Validation loss: 2.193011886330061

Epoch: 6| Step: 11
Training loss: 2.3536996841430664
Validation loss: 2.208804879137265

Epoch: 6| Step: 12
Training loss: 1.8914544582366943
Validation loss: 2.1844111334893013

Epoch: 6| Step: 13
Training loss: 1.8129888772964478
Validation loss: 2.1843119616149576

Epoch: 199| Step: 0
Training loss: 2.912705421447754
Validation loss: 2.173498171632008

Epoch: 6| Step: 1
Training loss: 2.5870823860168457
Validation loss: 2.1407191291932137

Epoch: 6| Step: 2
Training loss: 2.6262686252593994
Validation loss: 2.1243435452061314

Epoch: 6| Step: 3
Training loss: 1.9319618940353394
Validation loss: 2.1285475120749524

Epoch: 6| Step: 4
Training loss: 2.5988309383392334
Validation loss: 2.121097231423983

Epoch: 6| Step: 5
Training loss: 2.689199447631836
Validation loss: 2.141023992210306

Epoch: 6| Step: 6
Training loss: 1.8987126350402832
Validation loss: 2.125178230706082

Epoch: 6| Step: 7
Training loss: 1.972348928451538
Validation loss: 2.1276956988919165

Epoch: 6| Step: 8
Training loss: 2.2299013137817383
Validation loss: 2.1382988191420034

Epoch: 6| Step: 9
Training loss: 2.3750252723693848
Validation loss: 2.1536078606882403

Epoch: 6| Step: 10
Training loss: 2.3034815788269043
Validation loss: 2.1525069103446057

Epoch: 6| Step: 11
Training loss: 2.4000141620635986
Validation loss: 2.1377006192361154

Epoch: 6| Step: 12
Training loss: 2.0625555515289307
Validation loss: 2.1273829578071513

Epoch: 6| Step: 13
Training loss: 0.8702296614646912
Validation loss: 2.1317860618714364

Epoch: 200| Step: 0
Training loss: 1.656807780265808
Validation loss: 2.1392871551616217

Epoch: 6| Step: 1
Training loss: 1.1986191272735596
Validation loss: 2.1218246080542125

Epoch: 6| Step: 2
Training loss: 2.4595775604248047
Validation loss: 2.127669603593888

Epoch: 6| Step: 3
Training loss: 3.096304416656494
Validation loss: 2.1223010709208827

Epoch: 6| Step: 4
Training loss: 2.294154644012451
Validation loss: 2.125368336195587

Epoch: 6| Step: 5
Training loss: 2.089167356491089
Validation loss: 2.145754805175207

Epoch: 6| Step: 6
Training loss: 3.108386516571045
Validation loss: 2.1442400306783695

Epoch: 6| Step: 7
Training loss: 2.220468044281006
Validation loss: 2.145274208438012

Epoch: 6| Step: 8
Training loss: 2.1858410835266113
Validation loss: 2.1462006902181976

Epoch: 6| Step: 9
Training loss: 2.6119654178619385
Validation loss: 2.1586165684525684

Epoch: 6| Step: 10
Training loss: 1.776963710784912
Validation loss: 2.1359072372477543

Epoch: 6| Step: 11
Training loss: 2.68167781829834
Validation loss: 2.1447167704182286

Epoch: 6| Step: 12
Training loss: 2.341813802719116
Validation loss: 2.1516097412314465

Epoch: 6| Step: 13
Training loss: 2.3347058296203613
Validation loss: 2.151416006908622

Epoch: 201| Step: 0
Training loss: 2.7262096405029297
Validation loss: 2.155376208725796

Epoch: 6| Step: 1
Training loss: 2.5623865127563477
Validation loss: 2.184405547316356

Epoch: 6| Step: 2
Training loss: 1.6213631629943848
Validation loss: 2.1879110515758557

Epoch: 6| Step: 3
Training loss: 2.5538485050201416
Validation loss: 2.180503401705014

Epoch: 6| Step: 4
Training loss: 1.946346402168274
Validation loss: 2.1587206061168382

Epoch: 6| Step: 5
Training loss: 2.404325485229492
Validation loss: 2.150211880283971

Epoch: 6| Step: 6
Training loss: 2.1304221153259277
Validation loss: 2.1544915809426257

Epoch: 6| Step: 7
Training loss: 1.7306157350540161
Validation loss: 2.144761288037864

Epoch: 6| Step: 8
Training loss: 2.262129306793213
Validation loss: 2.1729412207039456

Epoch: 6| Step: 9
Training loss: 2.764822006225586
Validation loss: 2.1890923771806943

Epoch: 6| Step: 10
Training loss: 2.285222053527832
Validation loss: 2.1971167877156246

Epoch: 6| Step: 11
Training loss: 2.542130947113037
Validation loss: 2.211581801855436

Epoch: 6| Step: 12
Training loss: 2.5397849082946777
Validation loss: 2.1965136476742324

Epoch: 6| Step: 13
Training loss: 2.2099363803863525
Validation loss: 2.15391303390585

Epoch: 202| Step: 0
Training loss: 1.8344018459320068
Validation loss: 2.141274413754863

Epoch: 6| Step: 1
Training loss: 2.4408984184265137
Validation loss: 2.1519592590229486

Epoch: 6| Step: 2
Training loss: 1.917079210281372
Validation loss: 2.1739829817125873

Epoch: 6| Step: 3
Training loss: 2.3213047981262207
Validation loss: 2.2004699104575702

Epoch: 6| Step: 4
Training loss: 2.469602346420288
Validation loss: 2.2061477797005766

Epoch: 6| Step: 5
Training loss: 2.8496389389038086
Validation loss: 2.197368360334827

Epoch: 6| Step: 6
Training loss: 2.474276065826416
Validation loss: 2.174188401109429

Epoch: 6| Step: 7
Training loss: 2.8438236713409424
Validation loss: 2.1502942423666678

Epoch: 6| Step: 8
Training loss: 2.0172529220581055
Validation loss: 2.120505861056748

Epoch: 6| Step: 9
Training loss: 2.3558292388916016
Validation loss: 2.1326991332474576

Epoch: 6| Step: 10
Training loss: 2.340439796447754
Validation loss: 2.1401597017882974

Epoch: 6| Step: 11
Training loss: 2.397125482559204
Validation loss: 2.1417264169262302

Epoch: 6| Step: 12
Training loss: 1.7917120456695557
Validation loss: 2.180566895392633

Epoch: 6| Step: 13
Training loss: 2.638950824737549
Validation loss: 2.1994326653019076

Epoch: 203| Step: 0
Training loss: 2.9302546977996826
Validation loss: 2.2070978867110385

Epoch: 6| Step: 1
Training loss: 2.470872402191162
Validation loss: 2.1479132534355245

Epoch: 6| Step: 2
Training loss: 2.1563522815704346
Validation loss: 2.1312573878995833

Epoch: 6| Step: 3
Training loss: 1.7599984407424927
Validation loss: 2.1172412774896108

Epoch: 6| Step: 4
Training loss: 1.7954015731811523
Validation loss: 2.097846027343504

Epoch: 6| Step: 5
Training loss: 2.3070085048675537
Validation loss: 2.111305558553306

Epoch: 6| Step: 6
Training loss: 2.780216693878174
Validation loss: 2.1161735750013784

Epoch: 6| Step: 7
Training loss: 2.530230760574341
Validation loss: 2.1577698825508036

Epoch: 6| Step: 8
Training loss: 1.9576748609542847
Validation loss: 2.1683409419111026

Epoch: 6| Step: 9
Training loss: 2.4187352657318115
Validation loss: 2.17287011813092

Epoch: 6| Step: 10
Training loss: 2.9678213596343994
Validation loss: 2.188330106837775

Epoch: 6| Step: 11
Training loss: 2.289306640625
Validation loss: 2.208534356086485

Epoch: 6| Step: 12
Training loss: 2.6079745292663574
Validation loss: 2.1997655540384273

Epoch: 6| Step: 13
Training loss: 1.7755906581878662
Validation loss: 2.1824601183655443

Epoch: 204| Step: 0
Training loss: 2.5002150535583496
Validation loss: 2.158879556963521

Epoch: 6| Step: 1
Training loss: 3.0059564113616943
Validation loss: 2.133700710470958

Epoch: 6| Step: 2
Training loss: 2.2176599502563477
Validation loss: 2.1155449305811236

Epoch: 6| Step: 3
Training loss: 1.8210148811340332
Validation loss: 2.1131842879838842

Epoch: 6| Step: 4
Training loss: 2.54583740234375
Validation loss: 2.1225289298642065

Epoch: 6| Step: 5
Training loss: 2.3964550495147705
Validation loss: 2.129993531011766

Epoch: 6| Step: 6
Training loss: 1.731683373451233
Validation loss: 2.15657304692012

Epoch: 6| Step: 7
Training loss: 2.2747278213500977
Validation loss: 2.205757846114456

Epoch: 6| Step: 8
Training loss: 3.0893869400024414
Validation loss: 2.201166496481947

Epoch: 6| Step: 9
Training loss: 2.1967523097991943
Validation loss: 2.156336566453339

Epoch: 6| Step: 10
Training loss: 1.902136206626892
Validation loss: 2.136547642369424

Epoch: 6| Step: 11
Training loss: 1.6178302764892578
Validation loss: 2.128351708894135

Epoch: 6| Step: 12
Training loss: 2.4805593490600586
Validation loss: 2.125403174790003

Epoch: 6| Step: 13
Training loss: 2.798335075378418
Validation loss: 2.13130082109923

Epoch: 205| Step: 0
Training loss: 2.1839354038238525
Validation loss: 2.132480154755295

Epoch: 6| Step: 1
Training loss: 1.516023874282837
Validation loss: 2.128312676183639

Epoch: 6| Step: 2
Training loss: 1.895714282989502
Validation loss: 2.129158426356572

Epoch: 6| Step: 3
Training loss: 2.603020191192627
Validation loss: 2.130643266503529

Epoch: 6| Step: 4
Training loss: 2.2189059257507324
Validation loss: 2.1217228289573424

Epoch: 6| Step: 5
Training loss: 2.4688732624053955
Validation loss: 2.1240803157129595

Epoch: 6| Step: 6
Training loss: 1.9469678401947021
Validation loss: 2.1199709728199947

Epoch: 6| Step: 7
Training loss: 2.5654804706573486
Validation loss: 2.121299300142514

Epoch: 6| Step: 8
Training loss: 2.567135810852051
Validation loss: 2.1320107906095442

Epoch: 6| Step: 9
Training loss: 1.8633259534835815
Validation loss: 2.1324388314318914

Epoch: 6| Step: 10
Training loss: 2.6076555252075195
Validation loss: 2.1245070247239966

Epoch: 6| Step: 11
Training loss: 2.4338574409484863
Validation loss: 2.1088727827995055

Epoch: 6| Step: 12
Training loss: 2.371664524078369
Validation loss: 2.103084733409266

Epoch: 6| Step: 13
Training loss: 2.79341197013855
Validation loss: 2.106729345936929

Epoch: 206| Step: 0
Training loss: 2.6858413219451904
Validation loss: 2.0964964102673274

Epoch: 6| Step: 1
Training loss: 2.764012098312378
Validation loss: 2.108662889849755

Epoch: 6| Step: 2
Training loss: 1.9486526250839233
Validation loss: 2.0978610592503704

Epoch: 6| Step: 3
Training loss: 2.3550775051116943
Validation loss: 2.1027973569849485

Epoch: 6| Step: 4
Training loss: 2.548102617263794
Validation loss: 2.112522550808486

Epoch: 6| Step: 5
Training loss: 2.5573019981384277
Validation loss: 2.0846841668569915

Epoch: 6| Step: 6
Training loss: 2.7119946479797363
Validation loss: 2.087679663012105

Epoch: 6| Step: 7
Training loss: 1.814145565032959
Validation loss: 2.093821621710254

Epoch: 6| Step: 8
Training loss: 2.0762031078338623
Validation loss: 2.0920543183562574

Epoch: 6| Step: 9
Training loss: 2.0208590030670166
Validation loss: 2.1042325342855146

Epoch: 6| Step: 10
Training loss: 2.801473617553711
Validation loss: 2.112991334289633

Epoch: 6| Step: 11
Training loss: 1.7977519035339355
Validation loss: 2.109871728445894

Epoch: 6| Step: 12
Training loss: 1.683979868888855
Validation loss: 2.1226061287746636

Epoch: 6| Step: 13
Training loss: 2.211498498916626
Validation loss: 2.146965501128986

Epoch: 207| Step: 0
Training loss: 2.616987705230713
Validation loss: 2.1370748422479116

Epoch: 6| Step: 1
Training loss: 2.8950953483581543
Validation loss: 2.1561653511498564

Epoch: 6| Step: 2
Training loss: 2.1507067680358887
Validation loss: 2.1817023010664087

Epoch: 6| Step: 3
Training loss: 2.652322769165039
Validation loss: 2.198213351670132

Epoch: 6| Step: 4
Training loss: 1.4792025089263916
Validation loss: 2.1623594555803525

Epoch: 6| Step: 5
Training loss: 2.5877153873443604
Validation loss: 2.145809781166815

Epoch: 6| Step: 6
Training loss: 1.8535404205322266
Validation loss: 2.134382765780213

Epoch: 6| Step: 7
Training loss: 2.194840908050537
Validation loss: 2.1048241071803595

Epoch: 6| Step: 8
Training loss: 2.727398157119751
Validation loss: 2.0897237023999615

Epoch: 6| Step: 9
Training loss: 1.8741062879562378
Validation loss: 2.1087991165858444

Epoch: 6| Step: 10
Training loss: 2.312316656112671
Validation loss: 2.102367784387322

Epoch: 6| Step: 11
Training loss: 2.2933199405670166
Validation loss: 2.095447131382522

Epoch: 6| Step: 12
Training loss: 2.2718136310577393
Validation loss: 2.110816673565936

Epoch: 6| Step: 13
Training loss: 1.8610129356384277
Validation loss: 2.11625607808431

Epoch: 208| Step: 0
Training loss: 1.7829104661941528
Validation loss: 2.116885180114418

Epoch: 6| Step: 1
Training loss: 2.594775915145874
Validation loss: 2.1157821724491734

Epoch: 6| Step: 2
Training loss: 1.798459768295288
Validation loss: 2.1184759165651057

Epoch: 6| Step: 3
Training loss: 2.5142338275909424
Validation loss: 2.1264502104892524

Epoch: 6| Step: 4
Training loss: 2.2544784545898438
Validation loss: 2.1263796347443775

Epoch: 6| Step: 5
Training loss: 2.8557982444763184
Validation loss: 2.1591817384125083

Epoch: 6| Step: 6
Training loss: 3.0430479049682617
Validation loss: 2.1388193330457135

Epoch: 6| Step: 7
Training loss: 2.7998557090759277
Validation loss: 2.148396275376761

Epoch: 6| Step: 8
Training loss: 1.698469638824463
Validation loss: 2.139999733176283

Epoch: 6| Step: 9
Training loss: 2.5327413082122803
Validation loss: 2.1417867637449697

Epoch: 6| Step: 10
Training loss: 1.627742052078247
Validation loss: 2.152176426303002

Epoch: 6| Step: 11
Training loss: 2.3560338020324707
Validation loss: 2.1487751186534925

Epoch: 6| Step: 12
Training loss: 1.388309359550476
Validation loss: 2.1566249747430124

Epoch: 6| Step: 13
Training loss: 2.4728431701660156
Validation loss: 2.1576551339959584

Epoch: 209| Step: 0
Training loss: 2.5606651306152344
Validation loss: 2.163954634820261

Epoch: 6| Step: 1
Training loss: 2.377159595489502
Validation loss: 2.158179780488373

Epoch: 6| Step: 2
Training loss: 2.701448917388916
Validation loss: 2.152654304299303

Epoch: 6| Step: 3
Training loss: 1.878763198852539
Validation loss: 2.13558118830445

Epoch: 6| Step: 4
Training loss: 1.9170818328857422
Validation loss: 2.1190133005060177

Epoch: 6| Step: 5
Training loss: 1.9357893466949463
Validation loss: 2.1201486613160823

Epoch: 6| Step: 6
Training loss: 2.49560546875
Validation loss: 2.160297396362469

Epoch: 6| Step: 7
Training loss: 2.168450117111206
Validation loss: 2.1992464245006604

Epoch: 6| Step: 8
Training loss: 2.6034889221191406
Validation loss: 2.2474108408856135

Epoch: 6| Step: 9
Training loss: 2.5731863975524902
Validation loss: 2.2330855349058747

Epoch: 6| Step: 10
Training loss: 2.017188310623169
Validation loss: 2.1962144131301553

Epoch: 6| Step: 11
Training loss: 1.5852899551391602
Validation loss: 2.1588702406934512

Epoch: 6| Step: 12
Training loss: 3.265784740447998
Validation loss: 2.1283789539849884

Epoch: 6| Step: 13
Training loss: 1.5325102806091309
Validation loss: 2.1223582375434136

Epoch: 210| Step: 0
Training loss: 2.312002182006836
Validation loss: 2.1317482507357033

Epoch: 6| Step: 1
Training loss: 2.2447140216827393
Validation loss: 2.1256864647711478

Epoch: 6| Step: 2
Training loss: 2.0182607173919678
Validation loss: 2.148724591860207

Epoch: 6| Step: 3
Training loss: 1.7695271968841553
Validation loss: 2.148406110784059

Epoch: 6| Step: 4
Training loss: 3.5258331298828125
Validation loss: 2.1458030426374046

Epoch: 6| Step: 5
Training loss: 2.250901222229004
Validation loss: 2.159923190711647

Epoch: 6| Step: 6
Training loss: 2.0293173789978027
Validation loss: 2.168931461149646

Epoch: 6| Step: 7
Training loss: 2.8406460285186768
Validation loss: 2.1533494995486353

Epoch: 6| Step: 8
Training loss: 2.1717586517333984
Validation loss: 2.1511209203350927

Epoch: 6| Step: 9
Training loss: 2.2564444541931152
Validation loss: 2.1293748706899662

Epoch: 6| Step: 10
Training loss: 2.177114963531494
Validation loss: 2.108790374571277

Epoch: 6| Step: 11
Training loss: 2.092122793197632
Validation loss: 2.1030675813715947

Epoch: 6| Step: 12
Training loss: 2.485170602798462
Validation loss: 2.118730855244462

Epoch: 6| Step: 13
Training loss: 1.1960177421569824
Validation loss: 2.143765744342599

Epoch: 211| Step: 0
Training loss: 1.8247861862182617
Validation loss: 2.1985510010873117

Epoch: 6| Step: 1
Training loss: 1.873429536819458
Validation loss: 2.182984390566426

Epoch: 6| Step: 2
Training loss: 2.664074182510376
Validation loss: 2.172392560589698

Epoch: 6| Step: 3
Training loss: 2.6048970222473145
Validation loss: 2.1356353195764686

Epoch: 6| Step: 4
Training loss: 2.594834804534912
Validation loss: 2.119699731949837

Epoch: 6| Step: 5
Training loss: 2.3828229904174805
Validation loss: 2.10223251645283

Epoch: 6| Step: 6
Training loss: 2.440821886062622
Validation loss: 2.0905253079629715

Epoch: 6| Step: 7
Training loss: 2.2292215824127197
Validation loss: 2.094239075978597

Epoch: 6| Step: 8
Training loss: 2.1843276023864746
Validation loss: 2.106842149970352

Epoch: 6| Step: 9
Training loss: 1.4640350341796875
Validation loss: 2.106377132477299

Epoch: 6| Step: 10
Training loss: 2.0362632274627686
Validation loss: 2.1104879353636052

Epoch: 6| Step: 11
Training loss: 2.750243902206421
Validation loss: 2.1149795209207842

Epoch: 6| Step: 12
Training loss: 2.60988712310791
Validation loss: 2.1117838569866714

Epoch: 6| Step: 13
Training loss: 2.3418030738830566
Validation loss: 2.111370071288078

Epoch: 212| Step: 0
Training loss: 2.954010486602783
Validation loss: 2.111756276058894

Epoch: 6| Step: 1
Training loss: 2.6209681034088135
Validation loss: 2.102922502384391

Epoch: 6| Step: 2
Training loss: 2.36755633354187
Validation loss: 2.1048834554610716

Epoch: 6| Step: 3
Training loss: 1.9127634763717651
Validation loss: 2.0973986451343825

Epoch: 6| Step: 4
Training loss: 2.2498342990875244
Validation loss: 2.0970761442697174

Epoch: 6| Step: 5
Training loss: 1.9785910844802856
Validation loss: 2.089345178296489

Epoch: 6| Step: 6
Training loss: 1.927126169204712
Validation loss: 2.0963024375259236

Epoch: 6| Step: 7
Training loss: 1.7703423500061035
Validation loss: 2.114195223777525

Epoch: 6| Step: 8
Training loss: 2.275052070617676
Validation loss: 2.117510323883385

Epoch: 6| Step: 9
Training loss: 2.6300110816955566
Validation loss: 2.1134177164364885

Epoch: 6| Step: 10
Training loss: 1.345956802368164
Validation loss: 2.1361357704285653

Epoch: 6| Step: 11
Training loss: 2.3289709091186523
Validation loss: 2.1195077973027385

Epoch: 6| Step: 12
Training loss: 2.431950330734253
Validation loss: 2.1395535981783302

Epoch: 6| Step: 13
Training loss: 2.7623558044433594
Validation loss: 2.136421808632471

Epoch: 213| Step: 0
Training loss: 2.048981189727783
Validation loss: 2.1475975616003877

Epoch: 6| Step: 1
Training loss: 2.835362434387207
Validation loss: 2.166453348693027

Epoch: 6| Step: 2
Training loss: 1.4788330793380737
Validation loss: 2.1670346542071273

Epoch: 6| Step: 3
Training loss: 2.545720100402832
Validation loss: 2.1513869967511905

Epoch: 6| Step: 4
Training loss: 1.5365056991577148
Validation loss: 2.1329463758776264

Epoch: 6| Step: 5
Training loss: 2.68707013130188
Validation loss: 2.124626500632173

Epoch: 6| Step: 6
Training loss: 2.4038896560668945
Validation loss: 2.1099116597124326

Epoch: 6| Step: 7
Training loss: 2.7379393577575684
Validation loss: 2.1121956597092333

Epoch: 6| Step: 8
Training loss: 1.9033699035644531
Validation loss: 2.0959933932109545

Epoch: 6| Step: 9
Training loss: 2.2216062545776367
Validation loss: 2.0904816735175347

Epoch: 6| Step: 10
Training loss: 2.456308603286743
Validation loss: 2.1058400292550363

Epoch: 6| Step: 11
Training loss: 2.6382079124450684
Validation loss: 2.0968922427905503

Epoch: 6| Step: 12
Training loss: 2.2001657485961914
Validation loss: 2.108919148804039

Epoch: 6| Step: 13
Training loss: 1.47922682762146
Validation loss: 2.0982583825306227

Epoch: 214| Step: 0
Training loss: 2.5897860527038574
Validation loss: 2.0897453523451284

Epoch: 6| Step: 1
Training loss: 2.4768428802490234
Validation loss: 2.091857969119985

Epoch: 6| Step: 2
Training loss: 2.653773546218872
Validation loss: 2.0977963734698553

Epoch: 6| Step: 3
Training loss: 1.461805820465088
Validation loss: 2.1064515626558693

Epoch: 6| Step: 4
Training loss: 1.8182955980300903
Validation loss: 2.1228454330916047

Epoch: 6| Step: 5
Training loss: 1.963839054107666
Validation loss: 2.1163509661151516

Epoch: 6| Step: 6
Training loss: 2.3940093517303467
Validation loss: 2.1103748736842984

Epoch: 6| Step: 7
Training loss: 1.8820868730545044
Validation loss: 2.1038422994716193

Epoch: 6| Step: 8
Training loss: 2.429594039916992
Validation loss: 2.097587095793857

Epoch: 6| Step: 9
Training loss: 2.5865485668182373
Validation loss: 2.0977611490475234

Epoch: 6| Step: 10
Training loss: 2.3857858180999756
Validation loss: 2.091688649628752

Epoch: 6| Step: 11
Training loss: 1.9790233373641968
Validation loss: 2.102770648976808

Epoch: 6| Step: 12
Training loss: 2.2542552947998047
Validation loss: 2.1008956688706593

Epoch: 6| Step: 13
Training loss: 1.9957940578460693
Validation loss: 2.1104334323636946

Epoch: 215| Step: 0
Training loss: 1.7560145854949951
Validation loss: 2.101839424461447

Epoch: 6| Step: 1
Training loss: 1.6089401245117188
Validation loss: 2.1016686219041065

Epoch: 6| Step: 2
Training loss: 2.635009765625
Validation loss: 2.1197581470653577

Epoch: 6| Step: 3
Training loss: 2.2527663707733154
Validation loss: 2.1192628029854066

Epoch: 6| Step: 4
Training loss: 2.0407323837280273
Validation loss: 2.126851227975661

Epoch: 6| Step: 5
Training loss: 2.1267712116241455
Validation loss: 2.1204427980607554

Epoch: 6| Step: 6
Training loss: 2.826716184616089
Validation loss: 2.1301171497632096

Epoch: 6| Step: 7
Training loss: 2.1272523403167725
Validation loss: 2.1242004004857873

Epoch: 6| Step: 8
Training loss: 1.5184122323989868
Validation loss: 2.1205722003854732

Epoch: 6| Step: 9
Training loss: 2.154639959335327
Validation loss: 2.1287101289277435

Epoch: 6| Step: 10
Training loss: 2.933505058288574
Validation loss: 2.127931591003172

Epoch: 6| Step: 11
Training loss: 2.162320852279663
Validation loss: 2.130052497310023

Epoch: 6| Step: 12
Training loss: 2.6568591594696045
Validation loss: 2.1141226317292903

Epoch: 6| Step: 13
Training loss: 2.1240017414093018
Validation loss: 2.116966583395517

Epoch: 216| Step: 0
Training loss: 2.2919387817382812
Validation loss: 2.1184200215083298

Epoch: 6| Step: 1
Training loss: 1.5001721382141113
Validation loss: 2.106463888640045

Epoch: 6| Step: 2
Training loss: 2.253568649291992
Validation loss: 2.0982643635042253

Epoch: 6| Step: 3
Training loss: 2.121251106262207
Validation loss: 2.0834567111025573

Epoch: 6| Step: 4
Training loss: 1.6867923736572266
Validation loss: 2.088670120444349

Epoch: 6| Step: 5
Training loss: 2.5094003677368164
Validation loss: 2.073814243398687

Epoch: 6| Step: 6
Training loss: 1.811943531036377
Validation loss: 2.088705938349488

Epoch: 6| Step: 7
Training loss: 2.8427042961120605
Validation loss: 2.0935444742120723

Epoch: 6| Step: 8
Training loss: 2.1266121864318848
Validation loss: 2.0891953463195474

Epoch: 6| Step: 9
Training loss: 2.687281608581543
Validation loss: 2.1039793465727117

Epoch: 6| Step: 10
Training loss: 2.293543815612793
Validation loss: 2.1238379427181777

Epoch: 6| Step: 11
Training loss: 2.180954933166504
Validation loss: 2.126610871284239

Epoch: 6| Step: 12
Training loss: 2.43707013130188
Validation loss: 2.131413052158971

Epoch: 6| Step: 13
Training loss: 2.2476449012756348
Validation loss: 2.1375813509828303

Epoch: 217| Step: 0
Training loss: 2.2008681297302246
Validation loss: 2.1266476800364833

Epoch: 6| Step: 1
Training loss: 2.5951404571533203
Validation loss: 2.1269742417079147

Epoch: 6| Step: 2
Training loss: 1.3537135124206543
Validation loss: 2.120210124600318

Epoch: 6| Step: 3
Training loss: 1.7053077220916748
Validation loss: 2.1000097849035777

Epoch: 6| Step: 4
Training loss: 2.1866443157196045
Validation loss: 2.101066590637289

Epoch: 6| Step: 5
Training loss: 2.64752459526062
Validation loss: 2.116556244511758

Epoch: 6| Step: 6
Training loss: 2.212891101837158
Validation loss: 2.110157552585807

Epoch: 6| Step: 7
Training loss: 2.560361385345459
Validation loss: 2.1003193470739547

Epoch: 6| Step: 8
Training loss: 1.7077357769012451
Validation loss: 2.111140686978576

Epoch: 6| Step: 9
Training loss: 2.4842991828918457
Validation loss: 2.1174397955658617

Epoch: 6| Step: 10
Training loss: 1.9724023342132568
Validation loss: 2.1137272927068893

Epoch: 6| Step: 11
Training loss: 2.5521390438079834
Validation loss: 2.1094797452290854

Epoch: 6| Step: 12
Training loss: 2.3140017986297607
Validation loss: 2.1066239572340444

Epoch: 6| Step: 13
Training loss: 2.613954782485962
Validation loss: 2.0936381214408466

Epoch: 218| Step: 0
Training loss: 1.6835756301879883
Validation loss: 2.078218860010947

Epoch: 6| Step: 1
Training loss: 2.6967148780822754
Validation loss: 2.0812098800495105

Epoch: 6| Step: 2
Training loss: 2.3901114463806152
Validation loss: 2.0919479875154394

Epoch: 6| Step: 3
Training loss: 2.123990058898926
Validation loss: 2.0932882037214053

Epoch: 6| Step: 4
Training loss: 2.468291759490967
Validation loss: 2.095576863135061

Epoch: 6| Step: 5
Training loss: 1.788239598274231
Validation loss: 2.1219367852774997

Epoch: 6| Step: 6
Training loss: 2.9150023460388184
Validation loss: 2.1360363216810327

Epoch: 6| Step: 7
Training loss: 2.026759147644043
Validation loss: 2.140338187576622

Epoch: 6| Step: 8
Training loss: 1.5960917472839355
Validation loss: 2.136779523664905

Epoch: 6| Step: 9
Training loss: 2.299175262451172
Validation loss: 2.1330495137040333

Epoch: 6| Step: 10
Training loss: 2.908600330352783
Validation loss: 2.1248635579180974

Epoch: 6| Step: 11
Training loss: 3.011389970779419
Validation loss: 2.1152161039331907

Epoch: 6| Step: 12
Training loss: 1.6063075065612793
Validation loss: 2.108178451497068

Epoch: 6| Step: 13
Training loss: 2.8784234523773193
Validation loss: 2.0724006788704985

Epoch: 219| Step: 0
Training loss: 1.8877875804901123
Validation loss: 2.0683169903293734

Epoch: 6| Step: 1
Training loss: 1.8017700910568237
Validation loss: 2.0706645186229418

Epoch: 6| Step: 2
Training loss: 2.477271795272827
Validation loss: 2.065620437745125

Epoch: 6| Step: 3
Training loss: 2.7133994102478027
Validation loss: 2.0903979834689888

Epoch: 6| Step: 4
Training loss: 2.1202001571655273
Validation loss: 2.1290058230841034

Epoch: 6| Step: 5
Training loss: 3.098729133605957
Validation loss: 2.1563818390651415

Epoch: 6| Step: 6
Training loss: 2.4464735984802246
Validation loss: 2.1876418821273313

Epoch: 6| Step: 7
Training loss: 2.029834747314453
Validation loss: 2.2173424818182506

Epoch: 6| Step: 8
Training loss: 1.7819880247116089
Validation loss: 2.2038711065887124

Epoch: 6| Step: 9
Training loss: 2.354466438293457
Validation loss: 2.164666291206114

Epoch: 6| Step: 10
Training loss: 2.6886696815490723
Validation loss: 2.143634855106313

Epoch: 6| Step: 11
Training loss: 2.3330347537994385
Validation loss: 2.1076491827605874

Epoch: 6| Step: 12
Training loss: 1.7314174175262451
Validation loss: 2.097725086314704

Epoch: 6| Step: 13
Training loss: 2.97517991065979
Validation loss: 2.088011710874496

Epoch: 220| Step: 0
Training loss: 1.8036134243011475
Validation loss: 2.087839013786726

Epoch: 6| Step: 1
Training loss: 2.443516492843628
Validation loss: 2.10975912309462

Epoch: 6| Step: 2
Training loss: 1.4203853607177734
Validation loss: 2.124580370482578

Epoch: 6| Step: 3
Training loss: 2.4954004287719727
Validation loss: 2.135082197445695

Epoch: 6| Step: 4
Training loss: 1.6728358268737793
Validation loss: 2.1096018898871636

Epoch: 6| Step: 5
Training loss: 2.94551420211792
Validation loss: 2.0825576397680465

Epoch: 6| Step: 6
Training loss: 2.548128843307495
Validation loss: 2.066627992096768

Epoch: 6| Step: 7
Training loss: 2.6468324661254883
Validation loss: 2.0666400360804733

Epoch: 6| Step: 8
Training loss: 2.552041530609131
Validation loss: 2.079769524194861

Epoch: 6| Step: 9
Training loss: 1.8806958198547363
Validation loss: 2.0799477946373726

Epoch: 6| Step: 10
Training loss: 2.446179151535034
Validation loss: 2.106853510743828

Epoch: 6| Step: 11
Training loss: 2.1070213317871094
Validation loss: 2.098731340900544

Epoch: 6| Step: 12
Training loss: 2.124789237976074
Validation loss: 2.1150432440542404

Epoch: 6| Step: 13
Training loss: 1.9709688425064087
Validation loss: 2.1344920178895355

Epoch: 221| Step: 0
Training loss: 1.9387667179107666
Validation loss: 2.1448669971958285

Epoch: 6| Step: 1
Training loss: 1.8392503261566162
Validation loss: 2.1458902230826755

Epoch: 6| Step: 2
Training loss: 2.760622024536133
Validation loss: 2.1729365471870667

Epoch: 6| Step: 3
Training loss: 2.988907814025879
Validation loss: 2.173403045182587

Epoch: 6| Step: 4
Training loss: 2.4136972427368164
Validation loss: 2.1509419589914303

Epoch: 6| Step: 5
Training loss: 1.6330472230911255
Validation loss: 2.149024078922887

Epoch: 6| Step: 6
Training loss: 2.959892749786377
Validation loss: 2.141390618457589

Epoch: 6| Step: 7
Training loss: 1.7823834419250488
Validation loss: 2.123439300444818

Epoch: 6| Step: 8
Training loss: 2.50852108001709
Validation loss: 2.0819142941505677

Epoch: 6| Step: 9
Training loss: 2.5859270095825195
Validation loss: 2.083865605374818

Epoch: 6| Step: 10
Training loss: 1.2128896713256836
Validation loss: 2.0851791648454565

Epoch: 6| Step: 11
Training loss: 2.8215575218200684
Validation loss: 2.089448851923789

Epoch: 6| Step: 12
Training loss: 1.5318859815597534
Validation loss: 2.1146909780399774

Epoch: 6| Step: 13
Training loss: 1.9874738454818726
Validation loss: 2.0985739051654773

Epoch: 222| Step: 0
Training loss: 2.8494186401367188
Validation loss: 2.104080218140797

Epoch: 6| Step: 1
Training loss: 2.424436569213867
Validation loss: 2.10419637157071

Epoch: 6| Step: 2
Training loss: 2.690666437149048
Validation loss: 2.0955461943021385

Epoch: 6| Step: 3
Training loss: 2.73130202293396
Validation loss: 2.0830903578830022

Epoch: 6| Step: 4
Training loss: 1.7591183185577393
Validation loss: 2.072825898406326

Epoch: 6| Step: 5
Training loss: 2.0478031635284424
Validation loss: 2.0678215616492817

Epoch: 6| Step: 6
Training loss: 2.01462459564209
Validation loss: 2.0754059168600265

Epoch: 6| Step: 7
Training loss: 1.3853846788406372
Validation loss: 2.078731293319374

Epoch: 6| Step: 8
Training loss: 2.1388986110687256
Validation loss: 2.0776191642207484

Epoch: 6| Step: 9
Training loss: 1.9577369689941406
Validation loss: 2.0843442909179197

Epoch: 6| Step: 10
Training loss: 2.520402669906616
Validation loss: 2.08741791530322

Epoch: 6| Step: 11
Training loss: 2.2960965633392334
Validation loss: 2.09375568871857

Epoch: 6| Step: 12
Training loss: 2.04085111618042
Validation loss: 2.0950358272880636

Epoch: 6| Step: 13
Training loss: 2.1199655532836914
Validation loss: 2.107189521994642

Epoch: 223| Step: 0
Training loss: 1.9856622219085693
Validation loss: 2.0986530729519424

Epoch: 6| Step: 1
Training loss: 1.9852535724639893
Validation loss: 2.112399370439591

Epoch: 6| Step: 2
Training loss: 1.8243331909179688
Validation loss: 2.0979975269686792

Epoch: 6| Step: 3
Training loss: 2.5151965618133545
Validation loss: 2.0989649449625323

Epoch: 6| Step: 4
Training loss: 2.4363045692443848
Validation loss: 2.083855234166627

Epoch: 6| Step: 5
Training loss: 1.9896831512451172
Validation loss: 2.0826335607036466

Epoch: 6| Step: 6
Training loss: 2.202014684677124
Validation loss: 2.085617252575454

Epoch: 6| Step: 7
Training loss: 1.5963231325149536
Validation loss: 2.0708879796407555

Epoch: 6| Step: 8
Training loss: 2.223223924636841
Validation loss: 2.0766744588011052

Epoch: 6| Step: 9
Training loss: 2.3920648097991943
Validation loss: 2.079419171938332

Epoch: 6| Step: 10
Training loss: 1.8794043064117432
Validation loss: 2.0791036172579695

Epoch: 6| Step: 11
Training loss: 2.8369126319885254
Validation loss: 2.0775862586113716

Epoch: 6| Step: 12
Training loss: 2.453204393386841
Validation loss: 2.1008404211331437

Epoch: 6| Step: 13
Training loss: 2.6208064556121826
Validation loss: 2.1056531962528022

Epoch: 224| Step: 0
Training loss: 1.6696507930755615
Validation loss: 2.104077995464366

Epoch: 6| Step: 1
Training loss: 2.8743934631347656
Validation loss: 2.109590191994944

Epoch: 6| Step: 2
Training loss: 2.539398431777954
Validation loss: 2.113492533724795

Epoch: 6| Step: 3
Training loss: 1.894095778465271
Validation loss: 2.118932798344602

Epoch: 6| Step: 4
Training loss: 1.4931080341339111
Validation loss: 2.115148339220273

Epoch: 6| Step: 5
Training loss: 2.3474621772766113
Validation loss: 2.1152853504303963

Epoch: 6| Step: 6
Training loss: 2.0746333599090576
Validation loss: 2.1233854755278556

Epoch: 6| Step: 7
Training loss: 2.1642355918884277
Validation loss: 2.110745173628612

Epoch: 6| Step: 8
Training loss: 2.3051280975341797
Validation loss: 2.1016694038145003

Epoch: 6| Step: 9
Training loss: 2.3089723587036133
Validation loss: 2.104688731572961

Epoch: 6| Step: 10
Training loss: 2.1558947563171387
Validation loss: 2.1221483445936635

Epoch: 6| Step: 11
Training loss: 2.217329740524292
Validation loss: 2.1133186804350985

Epoch: 6| Step: 12
Training loss: 2.682138204574585
Validation loss: 2.093710219988259

Epoch: 6| Step: 13
Training loss: 2.2226486206054688
Validation loss: 2.1055958732481925

Epoch: 225| Step: 0
Training loss: 2.4012513160705566
Validation loss: 2.070985162129966

Epoch: 6| Step: 1
Training loss: 1.2472940683364868
Validation loss: 2.080788243201471

Epoch: 6| Step: 2
Training loss: 2.128445625305176
Validation loss: 2.042962284498317

Epoch: 6| Step: 3
Training loss: 2.0690550804138184
Validation loss: 2.0493137016091296

Epoch: 6| Step: 4
Training loss: 2.0086913108825684
Validation loss: 2.0547584615727907

Epoch: 6| Step: 5
Training loss: 2.018209934234619
Validation loss: 2.058137583476241

Epoch: 6| Step: 6
Training loss: 1.643157958984375
Validation loss: 2.0715387072614444

Epoch: 6| Step: 7
Training loss: 1.5550129413604736
Validation loss: 2.084321910335172

Epoch: 6| Step: 8
Training loss: 3.0360093116760254
Validation loss: 2.0843243393846738

Epoch: 6| Step: 9
Training loss: 2.050471544265747
Validation loss: 2.0867606773171374

Epoch: 6| Step: 10
Training loss: 1.6194063425064087
Validation loss: 2.079970521311606

Epoch: 6| Step: 11
Training loss: 2.7148284912109375
Validation loss: 2.0862593843090917

Epoch: 6| Step: 12
Training loss: 3.1045217514038086
Validation loss: 2.084778203759142

Epoch: 6| Step: 13
Training loss: 3.398972988128662
Validation loss: 2.094833694478517

Epoch: 226| Step: 0
Training loss: 2.3716678619384766
Validation loss: 2.1162500907016057

Epoch: 6| Step: 1
Training loss: 1.8725485801696777
Validation loss: 2.1143364137218845

Epoch: 6| Step: 2
Training loss: 2.7431774139404297
Validation loss: 2.1436382698756393

Epoch: 6| Step: 3
Training loss: 1.2661237716674805
Validation loss: 2.150479498729911

Epoch: 6| Step: 4
Training loss: 2.5922391414642334
Validation loss: 2.162797425382881

Epoch: 6| Step: 5
Training loss: 2.3713982105255127
Validation loss: 2.1683343738637944

Epoch: 6| Step: 6
Training loss: 2.1916441917419434
Validation loss: 2.184445365782707

Epoch: 6| Step: 7
Training loss: 2.9527997970581055
Validation loss: 2.182044970091953

Epoch: 6| Step: 8
Training loss: 2.131608009338379
Validation loss: 2.1783212154142317

Epoch: 6| Step: 9
Training loss: 2.246053457260132
Validation loss: 2.1720770225729993

Epoch: 6| Step: 10
Training loss: 1.9307596683502197
Validation loss: 2.179984836168187

Epoch: 6| Step: 11
Training loss: 2.0861105918884277
Validation loss: 2.1400731353349585

Epoch: 6| Step: 12
Training loss: 1.801347017288208
Validation loss: 2.086200285983342

Epoch: 6| Step: 13
Training loss: 2.2611727714538574
Validation loss: 2.0834512044024724

Epoch: 227| Step: 0
Training loss: 1.4289770126342773
Validation loss: 2.086455116989792

Epoch: 6| Step: 1
Training loss: 2.3391847610473633
Validation loss: 2.079304074728361

Epoch: 6| Step: 2
Training loss: 2.414763927459717
Validation loss: 2.086395637963408

Epoch: 6| Step: 3
Training loss: 2.9431827068328857
Validation loss: 2.073167713739539

Epoch: 6| Step: 4
Training loss: 2.273118495941162
Validation loss: 2.07354909886596

Epoch: 6| Step: 5
Training loss: 1.260878324508667
Validation loss: 2.0714072822242655

Epoch: 6| Step: 6
Training loss: 2.4410319328308105
Validation loss: 2.0532601456488333

Epoch: 6| Step: 7
Training loss: 2.510449171066284
Validation loss: 2.0556897988883396

Epoch: 6| Step: 8
Training loss: 1.6559001207351685
Validation loss: 2.051897041259273

Epoch: 6| Step: 9
Training loss: 2.6792922019958496
Validation loss: 2.057113742315641

Epoch: 6| Step: 10
Training loss: 1.3735222816467285
Validation loss: 2.0666925445679696

Epoch: 6| Step: 11
Training loss: 2.6716501712799072
Validation loss: 2.0606432627606135

Epoch: 6| Step: 12
Training loss: 2.3585996627807617
Validation loss: 2.072897485507432

Epoch: 6| Step: 13
Training loss: 2.2066335678100586
Validation loss: 2.095621955010199

Epoch: 228| Step: 0
Training loss: 2.153272867202759
Validation loss: 2.0858101383332284

Epoch: 6| Step: 1
Training loss: 1.9526257514953613
Validation loss: 2.098838713861281

Epoch: 6| Step: 2
Training loss: 2.627798557281494
Validation loss: 2.0961713944711993

Epoch: 6| Step: 3
Training loss: 1.9012755155563354
Validation loss: 2.1046110814617527

Epoch: 6| Step: 4
Training loss: 2.0653374195098877
Validation loss: 2.1190143246804514

Epoch: 6| Step: 5
Training loss: 2.296445369720459
Validation loss: 2.112418856672061

Epoch: 6| Step: 6
Training loss: 2.3831448554992676
Validation loss: 2.1025177932554677

Epoch: 6| Step: 7
Training loss: 1.3805899620056152
Validation loss: 2.098355306092129

Epoch: 6| Step: 8
Training loss: 1.976008653640747
Validation loss: 2.1010565783387873

Epoch: 6| Step: 9
Training loss: 2.366558790206909
Validation loss: 2.080858624109658

Epoch: 6| Step: 10
Training loss: 2.169323444366455
Validation loss: 2.064514849775581

Epoch: 6| Step: 11
Training loss: 2.095897912979126
Validation loss: 2.065573534657878

Epoch: 6| Step: 12
Training loss: 2.4531075954437256
Validation loss: 2.072094835260863

Epoch: 6| Step: 13
Training loss: 2.673295736312866
Validation loss: 2.082914308835101

Epoch: 229| Step: 0
Training loss: 3.254439353942871
Validation loss: 2.092060940240019

Epoch: 6| Step: 1
Training loss: 2.1889986991882324
Validation loss: 2.1068148612976074

Epoch: 6| Step: 2
Training loss: 2.360652446746826
Validation loss: 2.117956085871625

Epoch: 6| Step: 3
Training loss: 2.292586326599121
Validation loss: 2.116526908771966

Epoch: 6| Step: 4
Training loss: 2.4258556365966797
Validation loss: 2.0881626593169345

Epoch: 6| Step: 5
Training loss: 1.8473575115203857
Validation loss: 2.078698976065523

Epoch: 6| Step: 6
Training loss: 2.0841357707977295
Validation loss: 2.057714803244478

Epoch: 6| Step: 7
Training loss: 1.9778705835342407
Validation loss: 2.0518479424138225

Epoch: 6| Step: 8
Training loss: 2.307314157485962
Validation loss: 2.0583729936230566

Epoch: 6| Step: 9
Training loss: 1.5442239046096802
Validation loss: 2.079871549401232

Epoch: 6| Step: 10
Training loss: 2.2540082931518555
Validation loss: 2.0832652020198044

Epoch: 6| Step: 11
Training loss: 2.4409542083740234
Validation loss: 2.088715241801354

Epoch: 6| Step: 12
Training loss: 1.8172318935394287
Validation loss: 2.12058767964763

Epoch: 6| Step: 13
Training loss: 1.7897944450378418
Validation loss: 2.108951691658266

Epoch: 230| Step: 0
Training loss: 1.8626370429992676
Validation loss: 2.105475489811231

Epoch: 6| Step: 1
Training loss: 2.894082546234131
Validation loss: 2.0815740682745494

Epoch: 6| Step: 2
Training loss: 2.401472806930542
Validation loss: 2.0727264676042783

Epoch: 6| Step: 3
Training loss: 2.053067445755005
Validation loss: 2.0704327860186176

Epoch: 6| Step: 4
Training loss: 2.918301582336426
Validation loss: 2.0781469780911683

Epoch: 6| Step: 5
Training loss: 1.6251403093338013
Validation loss: 2.087327923825992

Epoch: 6| Step: 6
Training loss: 2.1212692260742188
Validation loss: 2.092041798817214

Epoch: 6| Step: 7
Training loss: 1.861322045326233
Validation loss: 2.1014499856579687

Epoch: 6| Step: 8
Training loss: 1.5858951807022095
Validation loss: 2.1106280408879763

Epoch: 6| Step: 9
Training loss: 2.059917449951172
Validation loss: 2.144821592556533

Epoch: 6| Step: 10
Training loss: 2.7449841499328613
Validation loss: 2.155857318191118

Epoch: 6| Step: 11
Training loss: 2.401399850845337
Validation loss: 2.150292895173514

Epoch: 6| Step: 12
Training loss: 1.8400514125823975
Validation loss: 2.1305047914546025

Epoch: 6| Step: 13
Training loss: 2.0590760707855225
Validation loss: 2.1317645183173557

Epoch: 231| Step: 0
Training loss: 1.8776555061340332
Validation loss: 2.111674793304936

Epoch: 6| Step: 1
Training loss: 2.230116367340088
Validation loss: 2.1141719254114295

Epoch: 6| Step: 2
Training loss: 2.4507017135620117
Validation loss: 2.1086867727259153

Epoch: 6| Step: 3
Training loss: 2.0634818077087402
Validation loss: 2.1033884812426824

Epoch: 6| Step: 4
Training loss: 2.5195727348327637
Validation loss: 2.0968319754446707

Epoch: 6| Step: 5
Training loss: 1.826392650604248
Validation loss: 2.0799452617604244

Epoch: 6| Step: 6
Training loss: 2.041592597961426
Validation loss: 2.080302748628842

Epoch: 6| Step: 7
Training loss: 2.110067367553711
Validation loss: 2.0717233739873415

Epoch: 6| Step: 8
Training loss: 2.1074962615966797
Validation loss: 2.059707442919413

Epoch: 6| Step: 9
Training loss: 2.13547420501709
Validation loss: 2.0584671830618255

Epoch: 6| Step: 10
Training loss: 2.3076844215393066
Validation loss: 2.0514035968370337

Epoch: 6| Step: 11
Training loss: 2.1959474086761475
Validation loss: 2.0435366348553727

Epoch: 6| Step: 12
Training loss: 2.4131016731262207
Validation loss: 2.0414690138191305

Epoch: 6| Step: 13
Training loss: 2.0023889541625977
Validation loss: 2.0445574252836165

Epoch: 232| Step: 0
Training loss: 1.7306864261627197
Validation loss: 2.0537871340269684

Epoch: 6| Step: 1
Training loss: 1.9810062646865845
Validation loss: 2.0486092785353303

Epoch: 6| Step: 2
Training loss: 2.0455739498138428
Validation loss: 2.052569978980608

Epoch: 6| Step: 3
Training loss: 2.3070907592773438
Validation loss: 2.068581417042722

Epoch: 6| Step: 4
Training loss: 2.8125107288360596
Validation loss: 2.08022557022751

Epoch: 6| Step: 5
Training loss: 2.5921988487243652
Validation loss: 2.0926164632202475

Epoch: 6| Step: 6
Training loss: 2.3183155059814453
Validation loss: 2.083969385393204

Epoch: 6| Step: 7
Training loss: 2.2727556228637695
Validation loss: 2.0613632766149377

Epoch: 6| Step: 8
Training loss: 1.8742473125457764
Validation loss: 2.0602283118873514

Epoch: 6| Step: 9
Training loss: 2.0514819622039795
Validation loss: 2.060408781933528

Epoch: 6| Step: 10
Training loss: 2.0614919662475586
Validation loss: 2.0827890570445726

Epoch: 6| Step: 11
Training loss: 1.8369271755218506
Validation loss: 2.100512353322839

Epoch: 6| Step: 12
Training loss: 2.0957188606262207
Validation loss: 2.111329411947599

Epoch: 6| Step: 13
Training loss: 2.234544277191162
Validation loss: 2.110598735911872

Epoch: 233| Step: 0
Training loss: 2.5223519802093506
Validation loss: 2.1018320732219244

Epoch: 6| Step: 1
Training loss: 2.314068555831909
Validation loss: 2.093637384394164

Epoch: 6| Step: 2
Training loss: 1.9028892517089844
Validation loss: 2.105149870277733

Epoch: 6| Step: 3
Training loss: 2.288450002670288
Validation loss: 2.118063795951105

Epoch: 6| Step: 4
Training loss: 2.2474279403686523
Validation loss: 2.1101904761406685

Epoch: 6| Step: 5
Training loss: 2.15878963470459
Validation loss: 2.1236851035907702

Epoch: 6| Step: 6
Training loss: 2.8008885383605957
Validation loss: 2.138736496689499

Epoch: 6| Step: 7
Training loss: 1.7598085403442383
Validation loss: 2.111733131511237

Epoch: 6| Step: 8
Training loss: 2.1868371963500977
Validation loss: 2.08891712978322

Epoch: 6| Step: 9
Training loss: 1.811220645904541
Validation loss: 2.0714332134492937

Epoch: 6| Step: 10
Training loss: 1.680060625076294
Validation loss: 2.0615814808876283

Epoch: 6| Step: 11
Training loss: 1.8158057928085327
Validation loss: 2.044171307676582

Epoch: 6| Step: 12
Training loss: 2.8167426586151123
Validation loss: 2.0548918785587436

Epoch: 6| Step: 13
Training loss: 1.8289227485656738
Validation loss: 2.057777771385767

Epoch: 234| Step: 0
Training loss: 1.870544195175171
Validation loss: 2.0714673175606677

Epoch: 6| Step: 1
Training loss: 1.87040114402771
Validation loss: 2.062151937074559

Epoch: 6| Step: 2
Training loss: 2.137131452560425
Validation loss: 2.0869674246798278

Epoch: 6| Step: 3
Training loss: 2.523167848587036
Validation loss: 2.0611466861540273

Epoch: 6| Step: 4
Training loss: 1.916978120803833
Validation loss: 2.0651246604099067

Epoch: 6| Step: 5
Training loss: 2.682600498199463
Validation loss: 2.0649394758286013

Epoch: 6| Step: 6
Training loss: 1.3880186080932617
Validation loss: 2.064064771898331

Epoch: 6| Step: 7
Training loss: 2.1714658737182617
Validation loss: 2.06223556815937

Epoch: 6| Step: 8
Training loss: 2.164290428161621
Validation loss: 2.059786001841227

Epoch: 6| Step: 9
Training loss: 2.757990837097168
Validation loss: 2.066675857831073

Epoch: 6| Step: 10
Training loss: 2.2422633171081543
Validation loss: 2.05794027543837

Epoch: 6| Step: 11
Training loss: 2.0230166912078857
Validation loss: 2.0709572479289067

Epoch: 6| Step: 12
Training loss: 2.047427177429199
Validation loss: 2.082648818210889

Epoch: 6| Step: 13
Training loss: 2.1256215572357178
Validation loss: 2.0926008275760117

Epoch: 235| Step: 0
Training loss: 1.9368836879730225
Validation loss: 2.0801160668814056

Epoch: 6| Step: 1
Training loss: 1.8654521703720093
Validation loss: 2.087415959245415

Epoch: 6| Step: 2
Training loss: 2.445648193359375
Validation loss: 2.075465286931684

Epoch: 6| Step: 3
Training loss: 2.1471123695373535
Validation loss: 2.07369642103872

Epoch: 6| Step: 4
Training loss: 2.179445743560791
Validation loss: 2.0815346497361378

Epoch: 6| Step: 5
Training loss: 2.00948166847229
Validation loss: 2.083227389602251

Epoch: 6| Step: 6
Training loss: 2.6727495193481445
Validation loss: 2.087969929941239

Epoch: 6| Step: 7
Training loss: 3.1524856090545654
Validation loss: 2.1092580031323176

Epoch: 6| Step: 8
Training loss: 1.9897148609161377
Validation loss: 2.115177167359219

Epoch: 6| Step: 9
Training loss: 2.036790609359741
Validation loss: 2.1109938185702086

Epoch: 6| Step: 10
Training loss: 1.450596570968628
Validation loss: 2.092763682847382

Epoch: 6| Step: 11
Training loss: 2.3092050552368164
Validation loss: 2.0782153965324484

Epoch: 6| Step: 12
Training loss: 1.7298531532287598
Validation loss: 2.080400595100977

Epoch: 6| Step: 13
Training loss: 2.252974510192871
Validation loss: 2.0499524890735583

Epoch: 236| Step: 0
Training loss: 2.0643999576568604
Validation loss: 2.060230432018157

Epoch: 6| Step: 1
Training loss: 1.5984442234039307
Validation loss: 2.0571734918061124

Epoch: 6| Step: 2
Training loss: 1.665290117263794
Validation loss: 2.065110416822536

Epoch: 6| Step: 3
Training loss: 2.2910709381103516
Validation loss: 2.0649604323089763

Epoch: 6| Step: 4
Training loss: 2.614438533782959
Validation loss: 2.082021974748181

Epoch: 6| Step: 5
Training loss: 2.5728979110717773
Validation loss: 2.0750794615796817

Epoch: 6| Step: 6
Training loss: 2.0632247924804688
Validation loss: 2.0848404040900608

Epoch: 6| Step: 7
Training loss: 1.9621965885162354
Validation loss: 2.0842575937189083

Epoch: 6| Step: 8
Training loss: 2.0876669883728027
Validation loss: 2.0872546024219965

Epoch: 6| Step: 9
Training loss: 1.7243871688842773
Validation loss: 2.08825623091831

Epoch: 6| Step: 10
Training loss: 2.2607626914978027
Validation loss: 2.0897692095848823

Epoch: 6| Step: 11
Training loss: 2.2098500728607178
Validation loss: 2.089620873492251

Epoch: 6| Step: 12
Training loss: 2.6908059120178223
Validation loss: 2.0791472465761247

Epoch: 6| Step: 13
Training loss: 1.912487506866455
Validation loss: 2.080204966247723

Epoch: 237| Step: 0
Training loss: 2.2460193634033203
Validation loss: 2.0654274058598343

Epoch: 6| Step: 1
Training loss: 2.371506452560425
Validation loss: 2.069357413117604

Epoch: 6| Step: 2
Training loss: 2.1842708587646484
Validation loss: 2.0566606906152542

Epoch: 6| Step: 3
Training loss: 2.289458990097046
Validation loss: 2.0480789433243456

Epoch: 6| Step: 4
Training loss: 1.55838942527771
Validation loss: 2.048856906993415

Epoch: 6| Step: 5
Training loss: 1.9962791204452515
Validation loss: 2.0473689315139607

Epoch: 6| Step: 6
Training loss: 2.131094455718994
Validation loss: 2.0508908905008787

Epoch: 6| Step: 7
Training loss: 1.845537781715393
Validation loss: 2.0430533757773777

Epoch: 6| Step: 8
Training loss: 1.9563277959823608
Validation loss: 2.0582703890339022

Epoch: 6| Step: 9
Training loss: 2.4927704334259033
Validation loss: 2.0522298223228863

Epoch: 6| Step: 10
Training loss: 3.016021728515625
Validation loss: 2.0468187639790196

Epoch: 6| Step: 11
Training loss: 2.3236165046691895
Validation loss: 2.0548100086950485

Epoch: 6| Step: 12
Training loss: 1.1935070753097534
Validation loss: 2.064089887885637

Epoch: 6| Step: 13
Training loss: 2.433356523513794
Validation loss: 2.0889971897166264

Epoch: 238| Step: 0
Training loss: 1.860188603401184
Validation loss: 2.1193726934412473

Epoch: 6| Step: 1
Training loss: 2.2012062072753906
Validation loss: 2.157465705307581

Epoch: 6| Step: 2
Training loss: 1.8902989625930786
Validation loss: 2.1969374943805

Epoch: 6| Step: 3
Training loss: 2.789745807647705
Validation loss: 2.2575750735498246

Epoch: 6| Step: 4
Training loss: 1.519366979598999
Validation loss: 2.2707527786172848

Epoch: 6| Step: 5
Training loss: 1.3896843194961548
Validation loss: 2.2542438814716954

Epoch: 6| Step: 6
Training loss: 2.5389914512634277
Validation loss: 2.2460327456074376

Epoch: 6| Step: 7
Training loss: 3.2262067794799805
Validation loss: 2.215200606212821

Epoch: 6| Step: 8
Training loss: 1.9059464931488037
Validation loss: 2.1549870455136864

Epoch: 6| Step: 9
Training loss: 1.9728202819824219
Validation loss: 2.1099664472764537

Epoch: 6| Step: 10
Training loss: 1.9649658203125
Validation loss: 2.0956796369244977

Epoch: 6| Step: 11
Training loss: 2.592633008956909
Validation loss: 2.072101107207678

Epoch: 6| Step: 12
Training loss: 2.7871737480163574
Validation loss: 2.094139081175609

Epoch: 6| Step: 13
Training loss: 1.936230182647705
Validation loss: 2.0677744291161977

Epoch: 239| Step: 0
Training loss: 2.509561538696289
Validation loss: 2.0631583941880094

Epoch: 6| Step: 1
Training loss: 2.0635578632354736
Validation loss: 2.0518364137218845

Epoch: 6| Step: 2
Training loss: 1.9136638641357422
Validation loss: 2.060423138321087

Epoch: 6| Step: 3
Training loss: 2.4483680725097656
Validation loss: 2.04998936576228

Epoch: 6| Step: 4
Training loss: 2.265106439590454
Validation loss: 2.0442239981825634

Epoch: 6| Step: 5
Training loss: 1.773447036743164
Validation loss: 2.0523362531456897

Epoch: 6| Step: 6
Training loss: 1.7103976011276245
Validation loss: 2.0673426710149294

Epoch: 6| Step: 7
Training loss: 2.0291123390197754
Validation loss: 2.068425860456241

Epoch: 6| Step: 8
Training loss: 1.5623105764389038
Validation loss: 2.0640260506701726

Epoch: 6| Step: 9
Training loss: 2.0113325119018555
Validation loss: 2.0425630666876353

Epoch: 6| Step: 10
Training loss: 2.584991216659546
Validation loss: 2.038715979104401

Epoch: 6| Step: 11
Training loss: 2.936743974685669
Validation loss: 2.056323528289795

Epoch: 6| Step: 12
Training loss: 2.0382330417633057
Validation loss: 2.0754004704054965

Epoch: 6| Step: 13
Training loss: 2.109325647354126
Validation loss: 2.083624848755457

Epoch: 240| Step: 0
Training loss: 3.383955955505371
Validation loss: 2.0931630314037366

Epoch: 6| Step: 1
Training loss: 2.080275297164917
Validation loss: 2.0952786835291053

Epoch: 6| Step: 2
Training loss: 2.1115355491638184
Validation loss: 2.083355877989082

Epoch: 6| Step: 3
Training loss: 2.2269515991210938
Validation loss: 2.0807823506734704

Epoch: 6| Step: 4
Training loss: 1.7256792783737183
Validation loss: 2.0629982717575563

Epoch: 6| Step: 5
Training loss: 1.851881742477417
Validation loss: 2.0624306112207393

Epoch: 6| Step: 6
Training loss: 2.5236382484436035
Validation loss: 2.0418603368984756

Epoch: 6| Step: 7
Training loss: 1.8529303073883057
Validation loss: 2.0519073009490967

Epoch: 6| Step: 8
Training loss: 1.5496070384979248
Validation loss: 2.0453035805815007

Epoch: 6| Step: 9
Training loss: 1.8681678771972656
Validation loss: 2.0644966171633814

Epoch: 6| Step: 10
Training loss: 2.14656662940979
Validation loss: 2.069205948101577

Epoch: 6| Step: 11
Training loss: 2.6112852096557617
Validation loss: 2.054485344117688

Epoch: 6| Step: 12
Training loss: 1.8787026405334473
Validation loss: 2.0399572721091648

Epoch: 6| Step: 13
Training loss: 1.7103755474090576
Validation loss: 2.04871045133119

Epoch: 241| Step: 0
Training loss: 2.1693921089172363
Validation loss: 2.0324256163771435

Epoch: 6| Step: 1
Training loss: 2.1328296661376953
Validation loss: 2.0347045647200717

Epoch: 6| Step: 2
Training loss: 2.0244975090026855
Validation loss: 2.0518863970233547

Epoch: 6| Step: 3
Training loss: 1.9878425598144531
Validation loss: 2.0517026737172115

Epoch: 6| Step: 4
Training loss: 2.598210573196411
Validation loss: 2.0291583409873386

Epoch: 6| Step: 5
Training loss: 1.9876477718353271
Validation loss: 2.0296612606253674

Epoch: 6| Step: 6
Training loss: 1.643147349357605
Validation loss: 2.0391308158956547

Epoch: 6| Step: 7
Training loss: 1.3529990911483765
Validation loss: 2.034253999751101

Epoch: 6| Step: 8
Training loss: 1.79025137424469
Validation loss: 2.0432742898182203

Epoch: 6| Step: 9
Training loss: 2.491886615753174
Validation loss: 2.048588175927439

Epoch: 6| Step: 10
Training loss: 2.8118813037872314
Validation loss: 2.0657845030548754

Epoch: 6| Step: 11
Training loss: 1.998600721359253
Validation loss: 2.0637997927204257

Epoch: 6| Step: 12
Training loss: 2.1101083755493164
Validation loss: 2.0715939460262174

Epoch: 6| Step: 13
Training loss: 2.441948890686035
Validation loss: 2.0793024480983777

Epoch: 242| Step: 0
Training loss: 2.268099308013916
Validation loss: 2.0958192425389446

Epoch: 6| Step: 1
Training loss: 2.416191339492798
Validation loss: 2.1099278696121706

Epoch: 6| Step: 2
Training loss: 2.724304437637329
Validation loss: 2.11775847916962

Epoch: 6| Step: 3
Training loss: 2.1684505939483643
Validation loss: 2.122363269969981

Epoch: 6| Step: 4
Training loss: 2.4372942447662354
Validation loss: 2.125883799727245

Epoch: 6| Step: 5
Training loss: 1.8753855228424072
Validation loss: 2.106492365560224

Epoch: 6| Step: 6
Training loss: 2.0640344619750977
Validation loss: 2.110718293856549

Epoch: 6| Step: 7
Training loss: 2.1627631187438965
Validation loss: 2.0736059834880214

Epoch: 6| Step: 8
Training loss: 1.6337355375289917
Validation loss: 2.0629041284643193

Epoch: 6| Step: 9
Training loss: 1.6790094375610352
Validation loss: 2.0511291129614717

Epoch: 6| Step: 10
Training loss: 2.2661805152893066
Validation loss: 2.0593677566897486

Epoch: 6| Step: 11
Training loss: 1.6466325521469116
Validation loss: 2.062946927162909

Epoch: 6| Step: 12
Training loss: 2.335261821746826
Validation loss: 2.0591738967485327

Epoch: 6| Step: 13
Training loss: 2.2015984058380127
Validation loss: 2.0684058973866124

Epoch: 243| Step: 0
Training loss: 1.6806232929229736
Validation loss: 2.0321215660341325

Epoch: 6| Step: 1
Training loss: 2.1916229724884033
Validation loss: 2.0465198204081547

Epoch: 6| Step: 2
Training loss: 2.0454444885253906
Validation loss: 2.053517372377457

Epoch: 6| Step: 3
Training loss: 1.6436610221862793
Validation loss: 2.051438449531473

Epoch: 6| Step: 4
Training loss: 1.3760005235671997
Validation loss: 2.0661542415618896

Epoch: 6| Step: 5
Training loss: 2.4313063621520996
Validation loss: 2.0791082843657462

Epoch: 6| Step: 6
Training loss: 3.3868050575256348
Validation loss: 2.089686280937605

Epoch: 6| Step: 7
Training loss: 0.8731569647789001
Validation loss: 2.083818079322897

Epoch: 6| Step: 8
Training loss: 1.9835716485977173
Validation loss: 2.1088303058378157

Epoch: 6| Step: 9
Training loss: 2.6842775344848633
Validation loss: 2.09206618673058

Epoch: 6| Step: 10
Training loss: 1.7447786331176758
Validation loss: 2.0797255064851496

Epoch: 6| Step: 11
Training loss: 3.2778143882751465
Validation loss: 2.0602597011032926

Epoch: 6| Step: 12
Training loss: 1.9636893272399902
Validation loss: 2.054999887302358

Epoch: 6| Step: 13
Training loss: 2.236233949661255
Validation loss: 2.0719272808362077

Epoch: 244| Step: 0
Training loss: 2.7719016075134277
Validation loss: 2.0765434747101157

Epoch: 6| Step: 1
Training loss: 2.1612915992736816
Validation loss: 2.086340353053103

Epoch: 6| Step: 2
Training loss: 2.2408366203308105
Validation loss: 2.120801479585709

Epoch: 6| Step: 3
Training loss: 1.928335189819336
Validation loss: 2.0888711675520866

Epoch: 6| Step: 4
Training loss: 2.379183292388916
Validation loss: 2.077278034661406

Epoch: 6| Step: 5
Training loss: 1.8285081386566162
Validation loss: 2.0630167145882883

Epoch: 6| Step: 6
Training loss: 1.6641554832458496
Validation loss: 2.0318201177863666

Epoch: 6| Step: 7
Training loss: 2.2051637172698975
Validation loss: 2.037016018744438

Epoch: 6| Step: 8
Training loss: 2.425588607788086
Validation loss: 2.05476039455783

Epoch: 6| Step: 9
Training loss: 1.9648863077163696
Validation loss: 2.0698015510395007

Epoch: 6| Step: 10
Training loss: 1.8746205568313599
Validation loss: 2.082535751404301

Epoch: 6| Step: 11
Training loss: 2.8599965572357178
Validation loss: 2.1011056259114254

Epoch: 6| Step: 12
Training loss: 1.729621171951294
Validation loss: 2.0712106407329602

Epoch: 6| Step: 13
Training loss: 1.5956475734710693
Validation loss: 2.0596947926346973

Epoch: 245| Step: 0
Training loss: 1.8667796850204468
Validation loss: 2.036222537358602

Epoch: 6| Step: 1
Training loss: 2.4691033363342285
Validation loss: 2.0522680013410506

Epoch: 6| Step: 2
Training loss: 2.7579078674316406
Validation loss: 2.0529417350728023

Epoch: 6| Step: 3
Training loss: 2.3475570678710938
Validation loss: 2.0818932312791065

Epoch: 6| Step: 4
Training loss: 2.257215738296509
Validation loss: 2.097345180408929

Epoch: 6| Step: 5
Training loss: 1.9116871356964111
Validation loss: 2.0684668799882293

Epoch: 6| Step: 6
Training loss: 2.1933233737945557
Validation loss: 2.0422499923295874

Epoch: 6| Step: 7
Training loss: 2.0894503593444824
Validation loss: 2.0314563602529545

Epoch: 6| Step: 8
Training loss: 2.2578654289245605
Validation loss: 2.026037916060417

Epoch: 6| Step: 9
Training loss: 1.6493178606033325
Validation loss: 2.030404531827537

Epoch: 6| Step: 10
Training loss: 1.40348482131958
Validation loss: 2.046567701524304

Epoch: 6| Step: 11
Training loss: 2.2462520599365234
Validation loss: 2.0757580546922583

Epoch: 6| Step: 12
Training loss: 2.2687578201293945
Validation loss: 2.0767478737779843

Epoch: 6| Step: 13
Training loss: 1.7048649787902832
Validation loss: 2.112670683091687

Epoch: 246| Step: 0
Training loss: 2.302136182785034
Validation loss: 2.114918995929021

Epoch: 6| Step: 1
Training loss: 2.2277252674102783
Validation loss: 2.1185237207720355

Epoch: 6| Step: 2
Training loss: 2.2167820930480957
Validation loss: 2.118298151159799

Epoch: 6| Step: 3
Training loss: 1.7321789264678955
Validation loss: 2.1190510744689615

Epoch: 6| Step: 4
Training loss: 1.954086422920227
Validation loss: 2.124984159264513

Epoch: 6| Step: 5
Training loss: 2.189837694168091
Validation loss: 2.122204619069253

Epoch: 6| Step: 6
Training loss: 1.3681484460830688
Validation loss: 2.1122480105328303

Epoch: 6| Step: 7
Training loss: 1.7972133159637451
Validation loss: 2.1030004626961163

Epoch: 6| Step: 8
Training loss: 2.5745716094970703
Validation loss: 2.082771223078492

Epoch: 6| Step: 9
Training loss: 2.0370779037475586
Validation loss: 2.071512617090697

Epoch: 6| Step: 10
Training loss: 2.574443817138672
Validation loss: 2.079343600939679

Epoch: 6| Step: 11
Training loss: 2.7081613540649414
Validation loss: 2.070069738613662

Epoch: 6| Step: 12
Training loss: 2.069108009338379
Validation loss: 2.0481632704375894

Epoch: 6| Step: 13
Training loss: 1.467617392539978
Validation loss: 2.0448076699369695

Epoch: 247| Step: 0
Training loss: 1.718195915222168
Validation loss: 2.029755607728035

Epoch: 6| Step: 1
Training loss: 1.929109811782837
Validation loss: 2.025085421018703

Epoch: 6| Step: 2
Training loss: 2.288666248321533
Validation loss: 2.025024355098765

Epoch: 6| Step: 3
Training loss: 2.402576446533203
Validation loss: 2.0252940193299325

Epoch: 6| Step: 4
Training loss: 2.167851448059082
Validation loss: 2.013810057793894

Epoch: 6| Step: 5
Training loss: 2.114299774169922
Validation loss: 2.0186075164425756

Epoch: 6| Step: 6
Training loss: 1.771767497062683
Validation loss: 2.0227026516391384

Epoch: 6| Step: 7
Training loss: 2.541046142578125
Validation loss: 2.0258802226794663

Epoch: 6| Step: 8
Training loss: 2.357677459716797
Validation loss: 2.025768465893243

Epoch: 6| Step: 9
Training loss: 1.8632949590682983
Validation loss: 2.0356285264415126

Epoch: 6| Step: 10
Training loss: 1.6774648427963257
Validation loss: 2.0403565975927536

Epoch: 6| Step: 11
Training loss: 2.217719316482544
Validation loss: 2.045366323122414

Epoch: 6| Step: 12
Training loss: 2.1107730865478516
Validation loss: 2.066304865703788

Epoch: 6| Step: 13
Training loss: 1.7889485359191895
Validation loss: 2.073950716244277

Epoch: 248| Step: 0
Training loss: 2.437683582305908
Validation loss: 2.0840969829149145

Epoch: 6| Step: 1
Training loss: 1.9337682723999023
Validation loss: 2.0867584290043

Epoch: 6| Step: 2
Training loss: 2.0346455574035645
Validation loss: 2.094041770504367

Epoch: 6| Step: 3
Training loss: 2.1273231506347656
Validation loss: 2.091866029206143

Epoch: 6| Step: 4
Training loss: 2.159254312515259
Validation loss: 2.0880923373724825

Epoch: 6| Step: 5
Training loss: 2.334007740020752
Validation loss: 2.0754135193363314

Epoch: 6| Step: 6
Training loss: 1.926012635231018
Validation loss: 2.056622343678628

Epoch: 6| Step: 7
Training loss: 1.4200608730316162
Validation loss: 2.0482010021004626

Epoch: 6| Step: 8
Training loss: 2.091268301010132
Validation loss: 2.0322897254779773

Epoch: 6| Step: 9
Training loss: 1.8472506999969482
Validation loss: 2.033449786965565

Epoch: 6| Step: 10
Training loss: 2.804043769836426
Validation loss: 2.0284203842122066

Epoch: 6| Step: 11
Training loss: 1.9160451889038086
Validation loss: 2.023833215877574

Epoch: 6| Step: 12
Training loss: 2.0844504833221436
Validation loss: 2.00744596604378

Epoch: 6| Step: 13
Training loss: 2.126546621322632
Validation loss: 2.017929051512031

Epoch: 249| Step: 0
Training loss: 2.43182373046875
Validation loss: 2.007796843846639

Epoch: 6| Step: 1
Training loss: 2.1910107135772705
Validation loss: 2.021325592071779

Epoch: 6| Step: 2
Training loss: 2.3040146827697754
Validation loss: 2.025099774842621

Epoch: 6| Step: 3
Training loss: 1.651017665863037
Validation loss: 2.032363686510312

Epoch: 6| Step: 4
Training loss: 1.8939602375030518
Validation loss: 2.0313436728651806

Epoch: 6| Step: 5
Training loss: 2.250311851501465
Validation loss: 2.0418895662471814

Epoch: 6| Step: 6
Training loss: 1.4652775526046753
Validation loss: 2.041294078673086

Epoch: 6| Step: 7
Training loss: 2.493849992752075
Validation loss: 2.0542069378719536

Epoch: 6| Step: 8
Training loss: 1.7501025199890137
Validation loss: 2.0534694733158236

Epoch: 6| Step: 9
Training loss: 2.039217948913574
Validation loss: 2.049093492569462

Epoch: 6| Step: 10
Training loss: 2.433030366897583
Validation loss: 2.0453526294359596

Epoch: 6| Step: 11
Training loss: 2.321789264678955
Validation loss: 2.0670632854584725

Epoch: 6| Step: 12
Training loss: 2.0974433422088623
Validation loss: 2.08185480230598

Epoch: 6| Step: 13
Training loss: 1.7926627397537231
Validation loss: 2.1159269091903523

Epoch: 250| Step: 0
Training loss: 2.1783981323242188
Validation loss: 2.151624707765477

Epoch: 6| Step: 1
Training loss: 2.0953004360198975
Validation loss: 2.156058839572373

Epoch: 6| Step: 2
Training loss: 2.75907564163208
Validation loss: 2.1725354835551274

Epoch: 6| Step: 3
Training loss: 1.9544974565505981
Validation loss: 2.1732104375798214

Epoch: 6| Step: 4
Training loss: 2.9242870807647705
Validation loss: 2.1586974077327277

Epoch: 6| Step: 5
Training loss: 2.2445340156555176
Validation loss: 2.1291937853700373

Epoch: 6| Step: 6
Training loss: 2.0699644088745117
Validation loss: 2.107859483329199

Epoch: 6| Step: 7
Training loss: 2.9724369049072266
Validation loss: 2.0895672459756174

Epoch: 6| Step: 8
Training loss: 1.9607024192810059
Validation loss: 2.0727304668836695

Epoch: 6| Step: 9
Training loss: 1.6884031295776367
Validation loss: 2.0637038189877748

Epoch: 6| Step: 10
Training loss: 1.4593682289123535
Validation loss: 2.05101849186805

Epoch: 6| Step: 11
Training loss: 1.8323575258255005
Validation loss: 2.0550594740016486

Epoch: 6| Step: 12
Training loss: 1.6302800178527832
Validation loss: 2.059795082256358

Epoch: 6| Step: 13
Training loss: 1.3518739938735962
Validation loss: 2.0490485673309653

Epoch: 251| Step: 0
Training loss: 1.6771869659423828
Validation loss: 2.048407229044104

Epoch: 6| Step: 1
Training loss: 2.436361789703369
Validation loss: 2.0628395670203754

Epoch: 6| Step: 2
Training loss: 2.320875883102417
Validation loss: 2.054014972461167

Epoch: 6| Step: 3
Training loss: 1.7024917602539062
Validation loss: 2.051851499465204

Epoch: 6| Step: 4
Training loss: 1.7798418998718262
Validation loss: 2.05096064459893

Epoch: 6| Step: 5
Training loss: 2.327476978302002
Validation loss: 2.0509901918390745

Epoch: 6| Step: 6
Training loss: 2.0278267860412598
Validation loss: 2.0804433784177228

Epoch: 6| Step: 7
Training loss: 2.5298359394073486
Validation loss: 2.0810909437876877

Epoch: 6| Step: 8
Training loss: 1.7665441036224365
Validation loss: 2.078370023799199

Epoch: 6| Step: 9
Training loss: 1.390554428100586
Validation loss: 2.081668552531991

Epoch: 6| Step: 10
Training loss: 2.7085585594177246
Validation loss: 2.081438946467574

Epoch: 6| Step: 11
Training loss: 1.8529962301254272
Validation loss: 2.0928476651509604

Epoch: 6| Step: 12
Training loss: 2.2896761894226074
Validation loss: 2.0744862248820644

Epoch: 6| Step: 13
Training loss: 2.4564831256866455
Validation loss: 2.071429862770983

Epoch: 252| Step: 0
Training loss: 2.2407596111297607
Validation loss: 2.062050255396033

Epoch: 6| Step: 1
Training loss: 1.3256855010986328
Validation loss: 2.0584933655236357

Epoch: 6| Step: 2
Training loss: 2.162332534790039
Validation loss: 2.048956803096238

Epoch: 6| Step: 3
Training loss: 2.3090500831604004
Validation loss: 2.0587364653105378

Epoch: 6| Step: 4
Training loss: 1.8016180992126465
Validation loss: 2.0591584174863753

Epoch: 6| Step: 5
Training loss: 2.1138689517974854
Validation loss: 2.0689463359053417

Epoch: 6| Step: 6
Training loss: 1.833432912826538
Validation loss: 2.0518995587543776

Epoch: 6| Step: 7
Training loss: 2.478830337524414
Validation loss: 2.058241344267322

Epoch: 6| Step: 8
Training loss: 1.945820927619934
Validation loss: 2.052997014855826

Epoch: 6| Step: 9
Training loss: 1.7204453945159912
Validation loss: 2.0670943388374905

Epoch: 6| Step: 10
Training loss: 2.7988121509552
Validation loss: 2.060432130290616

Epoch: 6| Step: 11
Training loss: 1.994454264640808
Validation loss: 2.067352460276696

Epoch: 6| Step: 12
Training loss: 2.1759350299835205
Validation loss: 2.0545253612661876

Epoch: 6| Step: 13
Training loss: 2.271670341491699
Validation loss: 2.0515195400484147

Epoch: 253| Step: 0
Training loss: 1.7019248008728027
Validation loss: 2.0432409086535053

Epoch: 6| Step: 1
Training loss: 2.31339430809021
Validation loss: 2.0393990137243785

Epoch: 6| Step: 2
Training loss: 1.7145441770553589
Validation loss: 2.043804003346351

Epoch: 6| Step: 3
Training loss: 1.792999029159546
Validation loss: 2.0345568836376233

Epoch: 6| Step: 4
Training loss: 2.4946229457855225
Validation loss: 2.0440444997561875

Epoch: 6| Step: 5
Training loss: 2.7941784858703613
Validation loss: 2.0500232840097077

Epoch: 6| Step: 6
Training loss: 1.866121768951416
Validation loss: 2.056131283442179

Epoch: 6| Step: 7
Training loss: 2.10048770904541
Validation loss: 2.053759838945122

Epoch: 6| Step: 8
Training loss: 2.1263232231140137
Validation loss: 2.063631473049041

Epoch: 6| Step: 9
Training loss: 1.7731825113296509
Validation loss: 2.0552663572372927

Epoch: 6| Step: 10
Training loss: 1.8233766555786133
Validation loss: 2.0617415571725495

Epoch: 6| Step: 11
Training loss: 2.083383560180664
Validation loss: 2.0487348161717898

Epoch: 6| Step: 12
Training loss: 2.127110004425049
Validation loss: 2.0418547084254604

Epoch: 6| Step: 13
Training loss: 2.4118282794952393
Validation loss: 2.029347518438934

Epoch: 254| Step: 0
Training loss: 1.9959074258804321
Validation loss: 2.054888176661666

Epoch: 6| Step: 1
Training loss: 2.952188491821289
Validation loss: 2.0422037134888353

Epoch: 6| Step: 2
Training loss: 2.5717763900756836
Validation loss: 2.0406375085153887

Epoch: 6| Step: 3
Training loss: 2.0447282791137695
Validation loss: 2.037225786075797

Epoch: 6| Step: 4
Training loss: 2.589177131652832
Validation loss: 2.0526941181511007

Epoch: 6| Step: 5
Training loss: 2.1108193397521973
Validation loss: 2.029261468559183

Epoch: 6| Step: 6
Training loss: 1.5376728773117065
Validation loss: 2.039853770245788

Epoch: 6| Step: 7
Training loss: 1.8865292072296143
Validation loss: 2.0451090361482356

Epoch: 6| Step: 8
Training loss: 1.9891433715820312
Validation loss: 2.0481541951497397

Epoch: 6| Step: 9
Training loss: 1.0342718362808228
Validation loss: 2.0469308335294008

Epoch: 6| Step: 10
Training loss: 2.1951026916503906
Validation loss: 2.0428451927759315

Epoch: 6| Step: 11
Training loss: 1.7110209465026855
Validation loss: 2.027164187482608

Epoch: 6| Step: 12
Training loss: 1.949154019355774
Validation loss: 2.0222847602700673

Epoch: 6| Step: 13
Training loss: 2.295682430267334
Validation loss: 2.0258043504530385

Epoch: 255| Step: 0
Training loss: 2.5024142265319824
Validation loss: 2.037805744396743

Epoch: 6| Step: 1
Training loss: 2.7385663986206055
Validation loss: 2.0704576302600164

Epoch: 6| Step: 2
Training loss: 2.6778032779693604
Validation loss: 2.106242705416936

Epoch: 6| Step: 3
Training loss: 1.419116735458374
Validation loss: 2.118089460557507

Epoch: 6| Step: 4
Training loss: 1.8724510669708252
Validation loss: 2.1241077876860097

Epoch: 6| Step: 5
Training loss: 1.3019884824752808
Validation loss: 2.0918259389938845

Epoch: 6| Step: 6
Training loss: 1.2152442932128906
Validation loss: 2.102025024352535

Epoch: 6| Step: 7
Training loss: 2.1321237087249756
Validation loss: 2.0961597119608233

Epoch: 6| Step: 8
Training loss: 2.273186445236206
Validation loss: 2.11369631367345

Epoch: 6| Step: 9
Training loss: 1.7477326393127441
Validation loss: 2.144342968540807

Epoch: 6| Step: 10
Training loss: 2.356900453567505
Validation loss: 2.1529803404244046

Epoch: 6| Step: 11
Training loss: 2.397935390472412
Validation loss: 2.1702139736503683

Epoch: 6| Step: 12
Training loss: 2.3026814460754395
Validation loss: 2.172333340491018

Epoch: 6| Step: 13
Training loss: 2.2478325366973877
Validation loss: 2.1757843045778174

Epoch: 256| Step: 0
Training loss: 2.1867804527282715
Validation loss: 2.1173640797215123

Epoch: 6| Step: 1
Training loss: 1.8684639930725098
Validation loss: 2.081993602937268

Epoch: 6| Step: 2
Training loss: 2.1123602390289307
Validation loss: 2.0661016741106586

Epoch: 6| Step: 3
Training loss: 2.402031183242798
Validation loss: 2.03165667159583

Epoch: 6| Step: 4
Training loss: 1.8069126605987549
Validation loss: 2.0595385425834247

Epoch: 6| Step: 5
Training loss: 1.99675714969635
Validation loss: 2.0762110397379887

Epoch: 6| Step: 6
Training loss: 2.462873935699463
Validation loss: 2.1169465998167634

Epoch: 6| Step: 7
Training loss: 1.9287891387939453
Validation loss: 2.0963831127330823

Epoch: 6| Step: 8
Training loss: 2.102123260498047
Validation loss: 2.1099135914156513

Epoch: 6| Step: 9
Training loss: 2.52587890625
Validation loss: 2.081500614843061

Epoch: 6| Step: 10
Training loss: 2.4423322677612305
Validation loss: 2.04607670153341

Epoch: 6| Step: 11
Training loss: 2.085759162902832
Validation loss: 2.0392058228933685

Epoch: 6| Step: 12
Training loss: 1.7080649137496948
Validation loss: 2.04548377888177

Epoch: 6| Step: 13
Training loss: 1.7265632152557373
Validation loss: 2.057479945562219

Epoch: 257| Step: 0
Training loss: 1.876694679260254
Validation loss: 2.067498178892238

Epoch: 6| Step: 1
Training loss: 1.7113397121429443
Validation loss: 2.0763831779521

Epoch: 6| Step: 2
Training loss: 2.495471239089966
Validation loss: 2.0788368819862284

Epoch: 6| Step: 3
Training loss: 1.6902345418930054
Validation loss: 2.072475826868447

Epoch: 6| Step: 4
Training loss: 1.8978478908538818
Validation loss: 2.0608310238007577

Epoch: 6| Step: 5
Training loss: 2.7411603927612305
Validation loss: 2.051200928226594

Epoch: 6| Step: 6
Training loss: 1.8881371021270752
Validation loss: 2.067265405449816

Epoch: 6| Step: 7
Training loss: 2.2812602519989014
Validation loss: 2.052250764703238

Epoch: 6| Step: 8
Training loss: 1.4868319034576416
Validation loss: 2.054568144582933

Epoch: 6| Step: 9
Training loss: 2.239548444747925
Validation loss: 2.060297804494058

Epoch: 6| Step: 10
Training loss: 2.082488536834717
Validation loss: 2.0673940925187964

Epoch: 6| Step: 11
Training loss: 2.291501522064209
Validation loss: 2.0658351503392702

Epoch: 6| Step: 12
Training loss: 2.163297414779663
Validation loss: 2.0689121023301156

Epoch: 6| Step: 13
Training loss: 1.8956637382507324
Validation loss: 2.062323825333708

Epoch: 258| Step: 0
Training loss: 1.581337571144104
Validation loss: 2.072215823717015

Epoch: 6| Step: 1
Training loss: 2.084941864013672
Validation loss: 2.0827039672482397

Epoch: 6| Step: 2
Training loss: 1.9806714057922363
Validation loss: 2.0521000944158083

Epoch: 6| Step: 3
Training loss: 2.2322301864624023
Validation loss: 2.0361014886568953

Epoch: 6| Step: 4
Training loss: 2.1580004692077637
Validation loss: 2.023793174374488

Epoch: 6| Step: 5
Training loss: 2.3968353271484375
Validation loss: 2.0178344185634325

Epoch: 6| Step: 6
Training loss: 2.228921413421631
Validation loss: 2.01126814657642

Epoch: 6| Step: 7
Training loss: 1.5177398920059204
Validation loss: 2.0156075108435845

Epoch: 6| Step: 8
Training loss: 1.5097177028656006
Validation loss: 2.0026685217375397

Epoch: 6| Step: 9
Training loss: 2.836578130722046
Validation loss: 2.0265624894890735

Epoch: 6| Step: 10
Training loss: 2.2768714427948
Validation loss: 2.0261890939486924

Epoch: 6| Step: 11
Training loss: 1.973357915878296
Validation loss: 2.0224508905923493

Epoch: 6| Step: 12
Training loss: 1.9612526893615723
Validation loss: 2.040965868580726

Epoch: 6| Step: 13
Training loss: 1.947643518447876
Validation loss: 2.045702129281977

Epoch: 259| Step: 0
Training loss: 2.4450314044952393
Validation loss: 2.0564071850110124

Epoch: 6| Step: 1
Training loss: 1.9466300010681152
Validation loss: 2.064722845631261

Epoch: 6| Step: 2
Training loss: 2.2098793983459473
Validation loss: 2.071973140521716

Epoch: 6| Step: 3
Training loss: 1.8942288160324097
Validation loss: 2.088357320395849

Epoch: 6| Step: 4
Training loss: 1.6483638286590576
Validation loss: 2.1025741292584326

Epoch: 6| Step: 5
Training loss: 2.3107903003692627
Validation loss: 2.1092707469899166

Epoch: 6| Step: 6
Training loss: 1.4104764461517334
Validation loss: 2.1110643084331224

Epoch: 6| Step: 7
Training loss: 2.3911805152893066
Validation loss: 2.1161446596986506

Epoch: 6| Step: 8
Training loss: 2.0787465572357178
Validation loss: 2.0936562797074676

Epoch: 6| Step: 9
Training loss: 2.268782615661621
Validation loss: 2.09417531054507

Epoch: 6| Step: 10
Training loss: 1.8662407398223877
Validation loss: 2.0838636505988335

Epoch: 6| Step: 11
Training loss: 1.6584995985031128
Validation loss: 2.0503709290617254

Epoch: 6| Step: 12
Training loss: 2.1636757850646973
Validation loss: 2.038673661088431

Epoch: 6| Step: 13
Training loss: 2.093989372253418
Validation loss: 2.0404045120362313

Epoch: 260| Step: 0
Training loss: 1.6209208965301514
Validation loss: 2.0239938766725603

Epoch: 6| Step: 1
Training loss: 2.006763458251953
Validation loss: 2.00797265319414

Epoch: 6| Step: 2
Training loss: 2.5056052207946777
Validation loss: 2.00222086393705

Epoch: 6| Step: 3
Training loss: 1.9114950895309448
Validation loss: 2.0017024137640513

Epoch: 6| Step: 4
Training loss: 2.3179354667663574
Validation loss: 1.9941550326603714

Epoch: 6| Step: 5
Training loss: 2.1429104804992676
Validation loss: 2.003789551796452

Epoch: 6| Step: 6
Training loss: 1.8831076622009277
Validation loss: 2.0119480561184626

Epoch: 6| Step: 7
Training loss: 1.5178074836730957
Validation loss: 2.013827123949605

Epoch: 6| Step: 8
Training loss: 2.372206926345825
Validation loss: 2.032960157240591

Epoch: 6| Step: 9
Training loss: 2.1610989570617676
Validation loss: 2.0284012979076755

Epoch: 6| Step: 10
Training loss: 2.232949733734131
Validation loss: 2.0171228121685725

Epoch: 6| Step: 11
Training loss: 1.8054119348526
Validation loss: 2.045655378731348

Epoch: 6| Step: 12
Training loss: 1.6971430778503418
Validation loss: 2.044961303792974

Epoch: 6| Step: 13
Training loss: 2.6808841228485107
Validation loss: 2.038027763366699

Epoch: 261| Step: 0
Training loss: 1.8462481498718262
Validation loss: 2.026972834781934

Epoch: 6| Step: 1
Training loss: 1.9926602840423584
Validation loss: 2.0728395062108196

Epoch: 6| Step: 2
Training loss: 1.9200215339660645
Validation loss: 2.106998333366968

Epoch: 6| Step: 3
Training loss: 2.294682502746582
Validation loss: 2.1155336915805774

Epoch: 6| Step: 4
Training loss: 2.143003463745117
Validation loss: 2.1090269652746056

Epoch: 6| Step: 5
Training loss: 2.020793914794922
Validation loss: 2.090023676554362

Epoch: 6| Step: 6
Training loss: 1.8046077489852905
Validation loss: 2.0764664603817846

Epoch: 6| Step: 7
Training loss: 2.278312921524048
Validation loss: 2.070727822601154

Epoch: 6| Step: 8
Training loss: 3.0183193683624268
Validation loss: 2.082911724685341

Epoch: 6| Step: 9
Training loss: 2.179673194885254
Validation loss: 2.113150486382105

Epoch: 6| Step: 10
Training loss: 1.4527456760406494
Validation loss: 2.119353892982647

Epoch: 6| Step: 11
Training loss: 1.8698391914367676
Validation loss: 2.137730185703565

Epoch: 6| Step: 12
Training loss: 2.2402358055114746
Validation loss: 2.130346590472806

Epoch: 6| Step: 13
Training loss: 2.1505753993988037
Validation loss: 2.108038065254047

Epoch: 262| Step: 0
Training loss: 2.2141380310058594
Validation loss: 2.079085639728013

Epoch: 6| Step: 1
Training loss: 2.5259931087493896
Validation loss: 2.049316575450282

Epoch: 6| Step: 2
Training loss: 1.8790593147277832
Validation loss: 2.041623136048676

Epoch: 6| Step: 3
Training loss: 0.8980092406272888
Validation loss: 2.0247717365141837

Epoch: 6| Step: 4
Training loss: 1.5028008222579956
Validation loss: 2.0382806498517274

Epoch: 6| Step: 5
Training loss: 2.401825428009033
Validation loss: 2.043522882205184

Epoch: 6| Step: 6
Training loss: 1.9587702751159668
Validation loss: 2.0365412286532822

Epoch: 6| Step: 7
Training loss: 2.216733455657959
Validation loss: 2.0417618059342906

Epoch: 6| Step: 8
Training loss: 2.242173194885254
Validation loss: 2.03667119754258

Epoch: 6| Step: 9
Training loss: 1.5200793743133545
Validation loss: 2.031711064359193

Epoch: 6| Step: 10
Training loss: 2.479503631591797
Validation loss: 2.050010411970077

Epoch: 6| Step: 11
Training loss: 1.7877137660980225
Validation loss: 2.058407514326034

Epoch: 6| Step: 12
Training loss: 2.3211376667022705
Validation loss: 2.056440407230008

Epoch: 6| Step: 13
Training loss: 2.3588104248046875
Validation loss: 2.0606606737259896

Epoch: 263| Step: 0
Training loss: 1.8918371200561523
Validation loss: 2.0624818571152224

Epoch: 6| Step: 1
Training loss: 2.5079333782196045
Validation loss: 2.0860046853301344

Epoch: 6| Step: 2
Training loss: 2.3900911808013916
Validation loss: 2.0795263013532086

Epoch: 6| Step: 3
Training loss: 1.649482011795044
Validation loss: 2.0724828332983036

Epoch: 6| Step: 4
Training loss: 1.9346728324890137
Validation loss: 2.060762748923353

Epoch: 6| Step: 5
Training loss: 1.8971734046936035
Validation loss: 2.076228282784903

Epoch: 6| Step: 6
Training loss: 2.1892261505126953
Validation loss: 2.0935424168904624

Epoch: 6| Step: 7
Training loss: 1.8297107219696045
Validation loss: 2.120450671001147

Epoch: 6| Step: 8
Training loss: 2.050534725189209
Validation loss: 2.1253451224296325

Epoch: 6| Step: 9
Training loss: 1.4517121315002441
Validation loss: 2.1168777045383247

Epoch: 6| Step: 10
Training loss: 2.3159427642822266
Validation loss: 2.10210169002574

Epoch: 6| Step: 11
Training loss: 2.0029945373535156
Validation loss: 2.104091159759029

Epoch: 6| Step: 12
Training loss: 1.9260978698730469
Validation loss: 2.101552168528239

Epoch: 6| Step: 13
Training loss: 2.432403326034546
Validation loss: 2.0735595533924718

Epoch: 264| Step: 0
Training loss: 1.8083010911941528
Validation loss: 2.0558832153197257

Epoch: 6| Step: 1
Training loss: 2.0497031211853027
Validation loss: 2.045784577246635

Epoch: 6| Step: 2
Training loss: 2.2862462997436523
Validation loss: 2.0430279803532425

Epoch: 6| Step: 3
Training loss: 1.707460880279541
Validation loss: 2.030967685484117

Epoch: 6| Step: 4
Training loss: 2.2150020599365234
Validation loss: 2.029873310878713

Epoch: 6| Step: 5
Training loss: 1.6667134761810303
Validation loss: 2.021851670357489

Epoch: 6| Step: 6
Training loss: 2.1808576583862305
Validation loss: 2.0281435622963855

Epoch: 6| Step: 7
Training loss: 2.3712377548217773
Validation loss: 2.016481448245305

Epoch: 6| Step: 8
Training loss: 2.0138702392578125
Validation loss: 2.0166907938577796

Epoch: 6| Step: 9
Training loss: 2.2690675258636475
Validation loss: 2.017808541174858

Epoch: 6| Step: 10
Training loss: 2.2227189540863037
Validation loss: 2.0362570234524306

Epoch: 6| Step: 11
Training loss: 1.9746946096420288
Validation loss: 2.067673765203004

Epoch: 6| Step: 12
Training loss: 1.9489463567733765
Validation loss: 2.0974628438231764

Epoch: 6| Step: 13
Training loss: 1.1338905096054077
Validation loss: 2.080090909875849

Epoch: 265| Step: 0
Training loss: 1.6992859840393066
Validation loss: 2.0810008741194204

Epoch: 6| Step: 1
Training loss: 2.033217430114746
Validation loss: 2.055949698212326

Epoch: 6| Step: 2
Training loss: 2.030865430831909
Validation loss: 2.020796907845364

Epoch: 6| Step: 3
Training loss: 2.378159284591675
Validation loss: 2.031927301037696

Epoch: 6| Step: 4
Training loss: 2.5012216567993164
Validation loss: 2.0279531709609495

Epoch: 6| Step: 5
Training loss: 2.1284115314483643
Validation loss: 2.030526143248363

Epoch: 6| Step: 6
Training loss: 1.6489920616149902
Validation loss: 2.0453723105051185

Epoch: 6| Step: 7
Training loss: 2.1884841918945312
Validation loss: 2.050026273214689

Epoch: 6| Step: 8
Training loss: 1.6784433126449585
Validation loss: 2.0492899046149304

Epoch: 6| Step: 9
Training loss: 2.028414249420166
Validation loss: 2.032088182305777

Epoch: 6| Step: 10
Training loss: 2.1291346549987793
Validation loss: 2.0094680760496404

Epoch: 6| Step: 11
Training loss: 2.222430467605591
Validation loss: 2.009182144236821

Epoch: 6| Step: 12
Training loss: 2.005495548248291
Validation loss: 2.0011968151215584

Epoch: 6| Step: 13
Training loss: 1.0393527746200562
Validation loss: 1.9943413042253064

Epoch: 266| Step: 0
Training loss: 1.9929423332214355
Validation loss: 2.0047788491813083

Epoch: 6| Step: 1
Training loss: 2.810068368911743
Validation loss: 2.005416698353265

Epoch: 6| Step: 2
Training loss: 1.4926131963729858
Validation loss: 2.0182261133706696

Epoch: 6| Step: 3
Training loss: 1.9761831760406494
Validation loss: 2.0155229953027542

Epoch: 6| Step: 4
Training loss: 2.026705265045166
Validation loss: 2.018136162911692

Epoch: 6| Step: 5
Training loss: 1.8904304504394531
Validation loss: 2.008550695193711

Epoch: 6| Step: 6
Training loss: 2.0548207759857178
Validation loss: 2.0123299501275502

Epoch: 6| Step: 7
Training loss: 1.7851314544677734
Validation loss: 2.0248944464550225

Epoch: 6| Step: 8
Training loss: 2.117889881134033
Validation loss: 2.0429032592363257

Epoch: 6| Step: 9
Training loss: 1.4649486541748047
Validation loss: 2.051841151329779

Epoch: 6| Step: 10
Training loss: 1.6706194877624512
Validation loss: 2.062091924810922

Epoch: 6| Step: 11
Training loss: 2.0544328689575195
Validation loss: 2.071072264384198

Epoch: 6| Step: 12
Training loss: 2.059813976287842
Validation loss: 2.077955825354463

Epoch: 6| Step: 13
Training loss: 2.9517431259155273
Validation loss: 2.098865721815376

Epoch: 267| Step: 0
Training loss: 2.2312612533569336
Validation loss: 2.098406881414434

Epoch: 6| Step: 1
Training loss: 2.1417391300201416
Validation loss: 2.1050683606055474

Epoch: 6| Step: 2
Training loss: 2.8012914657592773
Validation loss: 2.082812037519229

Epoch: 6| Step: 3
Training loss: 2.1244959831237793
Validation loss: 2.094331927196954

Epoch: 6| Step: 4
Training loss: 2.503795862197876
Validation loss: 2.0745017502897527

Epoch: 6| Step: 5
Training loss: 1.3844325542449951
Validation loss: 2.070951379755492

Epoch: 6| Step: 6
Training loss: 1.8430854082107544
Validation loss: 2.0413018503496723

Epoch: 6| Step: 7
Training loss: 2.199239730834961
Validation loss: 2.005404560796676

Epoch: 6| Step: 8
Training loss: 1.7834174633026123
Validation loss: 1.9891923268636067

Epoch: 6| Step: 9
Training loss: 1.4046045541763306
Validation loss: 1.989236818846836

Epoch: 6| Step: 10
Training loss: 2.1730551719665527
Validation loss: 1.997848472287578

Epoch: 6| Step: 11
Training loss: 1.4275619983673096
Validation loss: 2.00194784133665

Epoch: 6| Step: 12
Training loss: 2.1644368171691895
Validation loss: 2.0116106156379945

Epoch: 6| Step: 13
Training loss: 1.6582669019699097
Validation loss: 2.005971931642102

Epoch: 268| Step: 0
Training loss: 1.6313353776931763
Validation loss: 2.0103253818327382

Epoch: 6| Step: 1
Training loss: 1.9958829879760742
Validation loss: 1.9905413504569762

Epoch: 6| Step: 2
Training loss: 2.150796890258789
Validation loss: 2.0089927668212564

Epoch: 6| Step: 3
Training loss: 2.1904354095458984
Validation loss: 2.0268236667879167

Epoch: 6| Step: 4
Training loss: 1.6579318046569824
Validation loss: 2.027876066905196

Epoch: 6| Step: 5
Training loss: 2.499660015106201
Validation loss: 2.047335333721612

Epoch: 6| Step: 6
Training loss: 2.243598222732544
Validation loss: 2.059291826781406

Epoch: 6| Step: 7
Training loss: 2.0864620208740234
Validation loss: 2.0754318980760473

Epoch: 6| Step: 8
Training loss: 2.5133113861083984
Validation loss: 2.090992150768157

Epoch: 6| Step: 9
Training loss: 1.9617609977722168
Validation loss: 2.1079256893486105

Epoch: 6| Step: 10
Training loss: 1.8349639177322388
Validation loss: 2.0977049309720277

Epoch: 6| Step: 11
Training loss: 1.7408736944198608
Validation loss: 2.106877093674034

Epoch: 6| Step: 12
Training loss: 1.5554308891296387
Validation loss: 2.105485875119445

Epoch: 6| Step: 13
Training loss: 2.0627431869506836
Validation loss: 2.0965262753989107

Epoch: 269| Step: 0
Training loss: 1.768747091293335
Validation loss: 2.102154480513706

Epoch: 6| Step: 1
Training loss: 2.0647478103637695
Validation loss: 2.0737404759212206

Epoch: 6| Step: 2
Training loss: 2.6620254516601562
Validation loss: 2.066831822036415

Epoch: 6| Step: 3
Training loss: 1.842004418373108
Validation loss: 2.035227788391934

Epoch: 6| Step: 4
Training loss: 2.3933169841766357
Validation loss: 2.015426387069046

Epoch: 6| Step: 5
Training loss: 1.7177250385284424
Validation loss: 1.999189410158383

Epoch: 6| Step: 6
Training loss: 2.1086249351501465
Validation loss: 1.9928336835676623

Epoch: 6| Step: 7
Training loss: 1.9901776313781738
Validation loss: 1.9907331441038398

Epoch: 6| Step: 8
Training loss: 1.6909703016281128
Validation loss: 1.9808124406363374

Epoch: 6| Step: 9
Training loss: 2.121612548828125
Validation loss: 1.985350194797721

Epoch: 6| Step: 10
Training loss: 1.8247098922729492
Validation loss: 1.9807900151898783

Epoch: 6| Step: 11
Training loss: 1.9379191398620605
Validation loss: 1.9849437872568767

Epoch: 6| Step: 12
Training loss: 1.7604868412017822
Validation loss: 1.9938336572339457

Epoch: 6| Step: 13
Training loss: 2.030318260192871
Validation loss: 2.0116850958075574

Epoch: 270| Step: 0
Training loss: 1.976510763168335
Validation loss: 2.0260530415401665

Epoch: 6| Step: 1
Training loss: 1.5074563026428223
Validation loss: 2.0443962402241205

Epoch: 6| Step: 2
Training loss: 1.6435561180114746
Validation loss: 2.0541944837057464

Epoch: 6| Step: 3
Training loss: 2.2056918144226074
Validation loss: 2.0567255571324337

Epoch: 6| Step: 4
Training loss: 1.8512535095214844
Validation loss: 2.0627456365093106

Epoch: 6| Step: 5
Training loss: 1.4177095890045166
Validation loss: 2.0521349471102477

Epoch: 6| Step: 6
Training loss: 2.3442516326904297
Validation loss: 2.0673183189925326

Epoch: 6| Step: 7
Training loss: 1.662264347076416
Validation loss: 2.0606331927801973

Epoch: 6| Step: 8
Training loss: 2.9022984504699707
Validation loss: 2.038651627878989

Epoch: 6| Step: 9
Training loss: 1.9070348739624023
Validation loss: 2.032867149640155

Epoch: 6| Step: 10
Training loss: 2.313070297241211
Validation loss: 2.0366159690323697

Epoch: 6| Step: 11
Training loss: 1.861161231994629
Validation loss: 2.027358470424529

Epoch: 6| Step: 12
Training loss: 2.2989084720611572
Validation loss: 2.0302045063305925

Epoch: 6| Step: 13
Training loss: 1.83256995677948
Validation loss: 2.0264772343379196

Epoch: 271| Step: 0
Training loss: 2.1624794006347656
Validation loss: 2.0366466558107765

Epoch: 6| Step: 1
Training loss: 1.9791734218597412
Validation loss: 2.0324573850118988

Epoch: 6| Step: 2
Training loss: 1.3347442150115967
Validation loss: 2.0310965904625515

Epoch: 6| Step: 3
Training loss: 2.0482747554779053
Validation loss: 2.041190060236121

Epoch: 6| Step: 4
Training loss: 1.2476187944412231
Validation loss: 2.0391038745962162

Epoch: 6| Step: 5
Training loss: 2.388099193572998
Validation loss: 2.0592626653691775

Epoch: 6| Step: 6
Training loss: 1.9053257703781128
Validation loss: 2.0530561888089744

Epoch: 6| Step: 7
Training loss: 2.570436716079712
Validation loss: 2.0557588326033724

Epoch: 6| Step: 8
Training loss: 2.090512275695801
Validation loss: 2.048900277383866

Epoch: 6| Step: 9
Training loss: 1.143817663192749
Validation loss: 2.063213958535143

Epoch: 6| Step: 10
Training loss: 1.411624789237976
Validation loss: 2.07167883329494

Epoch: 6| Step: 11
Training loss: 2.108309030532837
Validation loss: 2.080911615843414

Epoch: 6| Step: 12
Training loss: 2.923461437225342
Validation loss: 2.072644164485316

Epoch: 6| Step: 13
Training loss: 2.4282073974609375
Validation loss: 2.0598730656408493

Epoch: 272| Step: 0
Training loss: 2.138225555419922
Validation loss: 2.0309064695912022

Epoch: 6| Step: 1
Training loss: 1.757614254951477
Validation loss: 2.0140526345981065

Epoch: 6| Step: 2
Training loss: 1.7260187864303589
Validation loss: 2.0151572099295993

Epoch: 6| Step: 3
Training loss: 1.930500864982605
Validation loss: 1.9982626233049618

Epoch: 6| Step: 4
Training loss: 1.3716633319854736
Validation loss: 1.9902563864184963

Epoch: 6| Step: 5
Training loss: 2.090376853942871
Validation loss: 1.984868908441195

Epoch: 6| Step: 6
Training loss: 2.26101016998291
Validation loss: 1.9879028463876376

Epoch: 6| Step: 7
Training loss: 2.055022716522217
Validation loss: 1.9742156151802308

Epoch: 6| Step: 8
Training loss: 2.0414531230926514
Validation loss: 1.9790808821237216

Epoch: 6| Step: 9
Training loss: 1.9582945108413696
Validation loss: 1.9842258781515143

Epoch: 6| Step: 10
Training loss: 1.8209067583084106
Validation loss: 1.9888283168115923

Epoch: 6| Step: 11
Training loss: 2.2024853229522705
Validation loss: 1.998325099227249

Epoch: 6| Step: 12
Training loss: 2.291757583618164
Validation loss: 1.9846452282321068

Epoch: 6| Step: 13
Training loss: 1.8064417839050293
Validation loss: 1.9924279746188913

Epoch: 273| Step: 0
Training loss: 2.5915322303771973
Validation loss: 1.9905683122655398

Epoch: 6| Step: 1
Training loss: 1.9083759784698486
Validation loss: 1.9912101196986374

Epoch: 6| Step: 2
Training loss: 1.6025323867797852
Validation loss: 1.9889028303084835

Epoch: 6| Step: 3
Training loss: 1.8793392181396484
Validation loss: 1.988937936803346

Epoch: 6| Step: 4
Training loss: 1.423095941543579
Validation loss: 1.9899418674489504

Epoch: 6| Step: 5
Training loss: 1.7642548084259033
Validation loss: 1.996495816015428

Epoch: 6| Step: 6
Training loss: 2.0010499954223633
Validation loss: 2.003805902696425

Epoch: 6| Step: 7
Training loss: 2.330822467803955
Validation loss: 2.0030960293226343

Epoch: 6| Step: 8
Training loss: 2.4315366744995117
Validation loss: 2.001553414970316

Epoch: 6| Step: 9
Training loss: 1.4795570373535156
Validation loss: 2.0045176488096996

Epoch: 6| Step: 10
Training loss: 2.310760021209717
Validation loss: 2.0057788754022248

Epoch: 6| Step: 11
Training loss: 2.10270357131958
Validation loss: 2.020772830132515

Epoch: 6| Step: 12
Training loss: 1.4724234342575073
Validation loss: 2.003428222030722

Epoch: 6| Step: 13
Training loss: 1.7653287649154663
Validation loss: 2.0112731443938388

Epoch: 274| Step: 0
Training loss: 1.9145101308822632
Validation loss: 2.0237468058063137

Epoch: 6| Step: 1
Training loss: 2.0806281566619873
Validation loss: 2.0352522814145653

Epoch: 6| Step: 2
Training loss: 2.220496416091919
Validation loss: 2.035507686676518

Epoch: 6| Step: 3
Training loss: 1.6907808780670166
Validation loss: 2.05736017739901

Epoch: 6| Step: 4
Training loss: 1.7797406911849976
Validation loss: 2.0516971208715953

Epoch: 6| Step: 5
Training loss: 2.1365270614624023
Validation loss: 2.045537162852544

Epoch: 6| Step: 6
Training loss: 1.5817749500274658
Validation loss: 2.035579285314006

Epoch: 6| Step: 7
Training loss: 2.1019725799560547
Validation loss: 2.047615256360782

Epoch: 6| Step: 8
Training loss: 2.68973708152771
Validation loss: 2.026038973562179

Epoch: 6| Step: 9
Training loss: 1.7179701328277588
Validation loss: 2.0103495864457983

Epoch: 6| Step: 10
Training loss: 1.879670262336731
Validation loss: 2.030590175300516

Epoch: 6| Step: 11
Training loss: 1.5588144063949585
Validation loss: 2.0048109972348778

Epoch: 6| Step: 12
Training loss: 2.0494191646575928
Validation loss: 2.0040308685712915

Epoch: 6| Step: 13
Training loss: 1.7226296663284302
Validation loss: 2.0019875982756257

Epoch: 275| Step: 0
Training loss: 1.2471917867660522
Validation loss: 2.0057341924277683

Epoch: 6| Step: 1
Training loss: 2.0727028846740723
Validation loss: 2.0002013226991058

Epoch: 6| Step: 2
Training loss: 2.28373646736145
Validation loss: 2.0091922270354403

Epoch: 6| Step: 3
Training loss: 2.452775001525879
Validation loss: 2.0148292100557716

Epoch: 6| Step: 4
Training loss: 1.7212355136871338
Validation loss: 2.0099953554009877

Epoch: 6| Step: 5
Training loss: 2.151873826980591
Validation loss: 2.001705320932532

Epoch: 6| Step: 6
Training loss: 2.398900270462036
Validation loss: 2.0190094876033005

Epoch: 6| Step: 7
Training loss: 2.0664596557617188
Validation loss: 2.0196312242938625

Epoch: 6| Step: 8
Training loss: 1.0818538665771484
Validation loss: 2.014145025642969

Epoch: 6| Step: 9
Training loss: 1.7181851863861084
Validation loss: 1.9962311431925783

Epoch: 6| Step: 10
Training loss: 2.5084383487701416
Validation loss: 1.998989325697704

Epoch: 6| Step: 11
Training loss: 1.6614848375320435
Validation loss: 2.008643845076202

Epoch: 6| Step: 12
Training loss: 1.4907052516937256
Validation loss: 2.0010321012107273

Epoch: 6| Step: 13
Training loss: 2.7330713272094727
Validation loss: 1.9972260485413253

Epoch: 276| Step: 0
Training loss: 1.5527753829956055
Validation loss: 2.000186648420108

Epoch: 6| Step: 1
Training loss: 1.344689965248108
Validation loss: 2.003498251720141

Epoch: 6| Step: 2
Training loss: 2.354037284851074
Validation loss: 2.0057230790456138

Epoch: 6| Step: 3
Training loss: 2.228731632232666
Validation loss: 2.0130734110391266

Epoch: 6| Step: 4
Training loss: 2.0392367839813232
Validation loss: 2.021022051893255

Epoch: 6| Step: 5
Training loss: 1.0368527173995972
Validation loss: 2.070013794847714

Epoch: 6| Step: 6
Training loss: 2.1527316570281982
Validation loss: 2.0749587564058203

Epoch: 6| Step: 7
Training loss: 2.5241565704345703
Validation loss: 2.099722557170417

Epoch: 6| Step: 8
Training loss: 2.6249265670776367
Validation loss: 2.0842858617023756

Epoch: 6| Step: 9
Training loss: 1.6905372142791748
Validation loss: 2.051203263703213

Epoch: 6| Step: 10
Training loss: 1.4102799892425537
Validation loss: 2.0359245192620063

Epoch: 6| Step: 11
Training loss: 2.5372791290283203
Validation loss: 2.014181481894626

Epoch: 6| Step: 12
Training loss: 1.825432300567627
Validation loss: 2.0063985034983647

Epoch: 6| Step: 13
Training loss: 2.26198673248291
Validation loss: 1.9936560020651868

Epoch: 277| Step: 0
Training loss: 1.99228036403656
Validation loss: 1.99911029108109

Epoch: 6| Step: 1
Training loss: 2.0141611099243164
Validation loss: 1.9812354092956872

Epoch: 6| Step: 2
Training loss: 1.4447298049926758
Validation loss: 1.9854774116187968

Epoch: 6| Step: 3
Training loss: 2.1499552726745605
Validation loss: 1.969482365474906

Epoch: 6| Step: 4
Training loss: 1.9087554216384888
Validation loss: 1.962141329242337

Epoch: 6| Step: 5
Training loss: 1.5920096635818481
Validation loss: 1.986620556923651

Epoch: 6| Step: 6
Training loss: 2.124063014984131
Validation loss: 1.9995841941525858

Epoch: 6| Step: 7
Training loss: 2.1035776138305664
Validation loss: 2.0122331496207946

Epoch: 6| Step: 8
Training loss: 1.5036594867706299
Validation loss: 2.0094152624889086

Epoch: 6| Step: 9
Training loss: 1.7082463502883911
Validation loss: 2.013615572324363

Epoch: 6| Step: 10
Training loss: 1.5766196250915527
Validation loss: 2.0074402721979285

Epoch: 6| Step: 11
Training loss: 1.8458130359649658
Validation loss: 1.9900339175296087

Epoch: 6| Step: 12
Training loss: 2.5570905208587646
Validation loss: 2.0146903619971326

Epoch: 6| Step: 13
Training loss: 3.006277084350586
Validation loss: 2.01179612323802

Epoch: 278| Step: 0
Training loss: 2.2955617904663086
Validation loss: 2.0134903692430064

Epoch: 6| Step: 1
Training loss: 1.5102791786193848
Validation loss: 2.0290246676373225

Epoch: 6| Step: 2
Training loss: 2.1448795795440674
Validation loss: 2.0350380892394693

Epoch: 6| Step: 3
Training loss: 2.357929229736328
Validation loss: 2.019981861114502

Epoch: 6| Step: 4
Training loss: 2.1948204040527344
Validation loss: 2.0207174644675305

Epoch: 6| Step: 5
Training loss: 1.4557695388793945
Validation loss: 2.0151746349949993

Epoch: 6| Step: 6
Training loss: 2.0609662532806396
Validation loss: 2.012947743938815

Epoch: 6| Step: 7
Training loss: 1.9237797260284424
Validation loss: 1.9821868429901779

Epoch: 6| Step: 8
Training loss: 2.2877371311187744
Validation loss: 1.9919862080645818

Epoch: 6| Step: 9
Training loss: 1.8295612335205078
Validation loss: 1.9855027352609942

Epoch: 6| Step: 10
Training loss: 1.8808724880218506
Validation loss: 1.9909446316380655

Epoch: 6| Step: 11
Training loss: 0.9753548502922058
Validation loss: 1.9779448945035216

Epoch: 6| Step: 12
Training loss: 2.117453098297119
Validation loss: 1.9734623637250674

Epoch: 6| Step: 13
Training loss: 1.6911089420318604
Validation loss: 1.9891327145279094

Epoch: 279| Step: 0
Training loss: 2.4135396480560303
Validation loss: 1.9905169766436341

Epoch: 6| Step: 1
Training loss: 1.46132493019104
Validation loss: 2.0159139376814648

Epoch: 6| Step: 2
Training loss: 1.9260687828063965
Validation loss: 2.007525464539887

Epoch: 6| Step: 3
Training loss: 1.990260124206543
Validation loss: 2.006946755993751

Epoch: 6| Step: 4
Training loss: 2.283627510070801
Validation loss: 2.0278002497970418

Epoch: 6| Step: 5
Training loss: 2.120434284210205
Validation loss: 2.0257138180476364

Epoch: 6| Step: 6
Training loss: 1.3291194438934326
Validation loss: 2.0261808979895806

Epoch: 6| Step: 7
Training loss: 1.761182427406311
Validation loss: 2.052459542469312

Epoch: 6| Step: 8
Training loss: 1.4307210445404053
Validation loss: 2.035032546648415

Epoch: 6| Step: 9
Training loss: 2.7306606769561768
Validation loss: 2.0315359023309525

Epoch: 6| Step: 10
Training loss: 1.4616503715515137
Validation loss: 2.0533515907103017

Epoch: 6| Step: 11
Training loss: 2.0042710304260254
Validation loss: 2.056142455788069

Epoch: 6| Step: 12
Training loss: 2.0328609943389893
Validation loss: 2.0431521848965715

Epoch: 6| Step: 13
Training loss: 2.0762345790863037
Validation loss: 2.0138664348151094

Epoch: 280| Step: 0
Training loss: 2.035684823989868
Validation loss: 2.0161338160114903

Epoch: 6| Step: 1
Training loss: 1.2544656991958618
Validation loss: 2.017339584647968

Epoch: 6| Step: 2
Training loss: 2.027984619140625
Validation loss: 2.004190871792455

Epoch: 6| Step: 3
Training loss: 1.9897167682647705
Validation loss: 2.001334326241606

Epoch: 6| Step: 4
Training loss: 2.2566518783569336
Validation loss: 2.0012283863559848

Epoch: 6| Step: 5
Training loss: 2.328727960586548
Validation loss: 1.9873666942760508

Epoch: 6| Step: 6
Training loss: 2.0595569610595703
Validation loss: 1.9895068753150202

Epoch: 6| Step: 7
Training loss: 2.0051817893981934
Validation loss: 1.9730343382845643

Epoch: 6| Step: 8
Training loss: 2.575550079345703
Validation loss: 1.9668340093346053

Epoch: 6| Step: 9
Training loss: 1.3899787664413452
Validation loss: 1.9807167476223362

Epoch: 6| Step: 10
Training loss: 1.696604609489441
Validation loss: 1.9778891994107155

Epoch: 6| Step: 11
Training loss: 1.9695545434951782
Validation loss: 1.978026843840076

Epoch: 6| Step: 12
Training loss: 1.7414112091064453
Validation loss: 1.9862865068579232

Epoch: 6| Step: 13
Training loss: 1.5102778673171997
Validation loss: 2.0043109514380015

Epoch: 281| Step: 0
Training loss: 2.4410974979400635
Validation loss: 2.0011098256675144

Epoch: 6| Step: 1
Training loss: 1.6217784881591797
Validation loss: 2.022725587250084

Epoch: 6| Step: 2
Training loss: 1.6956523656845093
Validation loss: 2.043491304561656

Epoch: 6| Step: 3
Training loss: 2.3246548175811768
Validation loss: 2.0491494850445817

Epoch: 6| Step: 4
Training loss: 2.250519275665283
Validation loss: 2.0441767195219636

Epoch: 6| Step: 5
Training loss: 2.424290180206299
Validation loss: 2.049543047464022

Epoch: 6| Step: 6
Training loss: 1.6157112121582031
Validation loss: 2.0446173016742994

Epoch: 6| Step: 7
Training loss: 1.5470964908599854
Validation loss: 2.027958764824816

Epoch: 6| Step: 8
Training loss: 2.1002097129821777
Validation loss: 2.0252794322147163

Epoch: 6| Step: 9
Training loss: 1.7910658121109009
Validation loss: 2.0266732195372223

Epoch: 6| Step: 10
Training loss: 1.4565848112106323
Validation loss: 2.0200609378917243

Epoch: 6| Step: 11
Training loss: 1.9303369522094727
Validation loss: 2.0369955237193773

Epoch: 6| Step: 12
Training loss: 1.7531250715255737
Validation loss: 2.014030432188383

Epoch: 6| Step: 13
Training loss: 1.6297749280929565
Validation loss: 2.0144240651079404

Epoch: 282| Step: 0
Training loss: 2.190934181213379
Validation loss: 2.0031644221275084

Epoch: 6| Step: 1
Training loss: 1.489803671836853
Validation loss: 2.0118481010519047

Epoch: 6| Step: 2
Training loss: 1.8333892822265625
Validation loss: 2.0151782984374673

Epoch: 6| Step: 3
Training loss: 1.6023870706558228
Validation loss: 2.0240943790763937

Epoch: 6| Step: 4
Training loss: 2.4104557037353516
Validation loss: 2.0213590616820962

Epoch: 6| Step: 5
Training loss: 2.0711474418640137
Validation loss: 2.0341688586819555

Epoch: 6| Step: 6
Training loss: 1.6932611465454102
Validation loss: 2.0376769470912155

Epoch: 6| Step: 7
Training loss: 2.2835123538970947
Validation loss: 2.0456632721808647

Epoch: 6| Step: 8
Training loss: 1.584397315979004
Validation loss: 2.0493223256962274

Epoch: 6| Step: 9
Training loss: 2.2121670246124268
Validation loss: 2.024072818858649

Epoch: 6| Step: 10
Training loss: 1.9139373302459717
Validation loss: 2.0158467728604554

Epoch: 6| Step: 11
Training loss: 1.807915449142456
Validation loss: 2.0230834291827295

Epoch: 6| Step: 12
Training loss: 2.179938316345215
Validation loss: 1.9989520247264574

Epoch: 6| Step: 13
Training loss: 1.3771748542785645
Validation loss: 1.992744312491468

Epoch: 283| Step: 0
Training loss: 2.341500997543335
Validation loss: 1.9834851193171676

Epoch: 6| Step: 1
Training loss: 2.2771401405334473
Validation loss: 1.9855345231230541

Epoch: 6| Step: 2
Training loss: 2.430213451385498
Validation loss: 1.984211084663227

Epoch: 6| Step: 3
Training loss: 2.128391742706299
Validation loss: 1.9733431403354933

Epoch: 6| Step: 4
Training loss: 1.0105080604553223
Validation loss: 1.9568450027896511

Epoch: 6| Step: 5
Training loss: 1.9332389831542969
Validation loss: 1.9654588519885976

Epoch: 6| Step: 6
Training loss: 1.6603682041168213
Validation loss: 1.9582314170816892

Epoch: 6| Step: 7
Training loss: 2.0879483222961426
Validation loss: 1.9671290959081342

Epoch: 6| Step: 8
Training loss: 1.3509063720703125
Validation loss: 1.9873596801552722

Epoch: 6| Step: 9
Training loss: 2.20628023147583
Validation loss: 2.002257239434027

Epoch: 6| Step: 10
Training loss: 2.053814649581909
Validation loss: 2.0018427833434074

Epoch: 6| Step: 11
Training loss: 1.5727105140686035
Validation loss: 2.0146103148819297

Epoch: 6| Step: 12
Training loss: 2.1352243423461914
Validation loss: 1.996926312805504

Epoch: 6| Step: 13
Training loss: 1.5550999641418457
Validation loss: 1.9993335803349812

Epoch: 284| Step: 0
Training loss: 2.7292890548706055
Validation loss: 2.002376102632092

Epoch: 6| Step: 1
Training loss: 1.888871669769287
Validation loss: 2.0021466362860894

Epoch: 6| Step: 2
Training loss: 2.2652747631073
Validation loss: 2.009100465364354

Epoch: 6| Step: 3
Training loss: 1.3082667589187622
Validation loss: 2.004876898181054

Epoch: 6| Step: 4
Training loss: 1.791878342628479
Validation loss: 2.008959170310728

Epoch: 6| Step: 5
Training loss: 2.0837366580963135
Validation loss: 2.008733421243647

Epoch: 6| Step: 6
Training loss: 1.3161978721618652
Validation loss: 2.0137944003587127

Epoch: 6| Step: 7
Training loss: 1.7985680103302002
Validation loss: 2.0054646538149927

Epoch: 6| Step: 8
Training loss: 2.2175374031066895
Validation loss: 2.003930404622068

Epoch: 6| Step: 9
Training loss: 1.9365432262420654
Validation loss: 1.9789345020888953

Epoch: 6| Step: 10
Training loss: 1.7913591861724854
Validation loss: 1.9773331572932582

Epoch: 6| Step: 11
Training loss: 1.8919711112976074
Validation loss: 1.980510736024508

Epoch: 6| Step: 12
Training loss: 2.042870283126831
Validation loss: 1.9604638673925912

Epoch: 6| Step: 13
Training loss: 1.2390451431274414
Validation loss: 2.0003447455744587

Epoch: 285| Step: 0
Training loss: 1.6779698133468628
Validation loss: 1.9977659281863962

Epoch: 6| Step: 1
Training loss: 2.171764850616455
Validation loss: 2.029942504821285

Epoch: 6| Step: 2
Training loss: 1.725253701210022
Validation loss: 2.0705154916291595

Epoch: 6| Step: 3
Training loss: 2.315432548522949
Validation loss: 2.0772006947507142

Epoch: 6| Step: 4
Training loss: 2.147671937942505
Validation loss: 2.0269804782764886

Epoch: 6| Step: 5
Training loss: 1.1357707977294922
Validation loss: 1.993270501013725

Epoch: 6| Step: 6
Training loss: 1.4313496351242065
Validation loss: 1.966624931622577

Epoch: 6| Step: 7
Training loss: 1.863998532295227
Validation loss: 1.9731565560064008

Epoch: 6| Step: 8
Training loss: 1.9837387800216675
Validation loss: 1.965999682744344

Epoch: 6| Step: 9
Training loss: 1.6941158771514893
Validation loss: 1.9973061366747784

Epoch: 6| Step: 10
Training loss: 1.7333290576934814
Validation loss: 1.9985224303378855

Epoch: 6| Step: 11
Training loss: 2.753769874572754
Validation loss: 1.990875054431218

Epoch: 6| Step: 12
Training loss: 2.228693962097168
Validation loss: 1.9933564188659831

Epoch: 6| Step: 13
Training loss: 1.4359310865402222
Validation loss: 2.002997059975901

Epoch: 286| Step: 0
Training loss: 1.7290645837783813
Validation loss: 2.0005733607917704

Epoch: 6| Step: 1
Training loss: 1.4826266765594482
Validation loss: 2.010188196295051

Epoch: 6| Step: 2
Training loss: 2.1800389289855957
Validation loss: 2.024092694764496

Epoch: 6| Step: 3
Training loss: 2.0113701820373535
Validation loss: 2.027823705827036

Epoch: 6| Step: 4
Training loss: 2.965789318084717
Validation loss: 2.014331543317405

Epoch: 6| Step: 5
Training loss: 2.473559856414795
Validation loss: 1.9970619024768952

Epoch: 6| Step: 6
Training loss: 1.482686996459961
Validation loss: 1.9808222183617212

Epoch: 6| Step: 7
Training loss: 1.507035255432129
Validation loss: 1.9725828516867854

Epoch: 6| Step: 8
Training loss: 1.837456226348877
Validation loss: 1.97256669434168

Epoch: 6| Step: 9
Training loss: 1.9882737398147583
Validation loss: 1.9582859034179358

Epoch: 6| Step: 10
Training loss: 1.510243535041809
Validation loss: 1.9740401083423245

Epoch: 6| Step: 11
Training loss: 1.4906482696533203
Validation loss: 1.9800233815305976

Epoch: 6| Step: 12
Training loss: 2.149967670440674
Validation loss: 1.9721183443582186

Epoch: 6| Step: 13
Training loss: 1.5599184036254883
Validation loss: 1.9819576586446455

Epoch: 287| Step: 0
Training loss: 2.0615153312683105
Validation loss: 1.983050738611529

Epoch: 6| Step: 1
Training loss: 2.0320682525634766
Validation loss: 2.02478128094827

Epoch: 6| Step: 2
Training loss: 2.056089401245117
Validation loss: 2.041045135067355

Epoch: 6| Step: 3
Training loss: 1.5397570133209229
Validation loss: 2.057400588066347

Epoch: 6| Step: 4
Training loss: 1.792049765586853
Validation loss: 2.0850504393218667

Epoch: 6| Step: 5
Training loss: 1.973709225654602
Validation loss: 2.086886595654231

Epoch: 6| Step: 6
Training loss: 1.9164050817489624
Validation loss: 2.09238504081644

Epoch: 6| Step: 7
Training loss: 1.8827086687088013
Validation loss: 2.070578053433408

Epoch: 6| Step: 8
Training loss: 2.0095913410186768
Validation loss: 2.049786626651723

Epoch: 6| Step: 9
Training loss: 2.0005836486816406
Validation loss: 2.029228692413658

Epoch: 6| Step: 10
Training loss: 2.133401870727539
Validation loss: 2.0180608226406958

Epoch: 6| Step: 11
Training loss: 2.0099875926971436
Validation loss: 1.9958557903125722

Epoch: 6| Step: 12
Training loss: 1.4963254928588867
Validation loss: 1.9801593621571858

Epoch: 6| Step: 13
Training loss: 1.3047375679016113
Validation loss: 1.980811030633988

Epoch: 288| Step: 0
Training loss: 2.103549003601074
Validation loss: 1.9698359427913543

Epoch: 6| Step: 1
Training loss: 1.5606993436813354
Validation loss: 1.9686186057265087

Epoch: 6| Step: 2
Training loss: 1.4609640836715698
Validation loss: 1.9804578519636584

Epoch: 6| Step: 3
Training loss: 2.604763984680176
Validation loss: 1.9815863742623279

Epoch: 6| Step: 4
Training loss: 1.9237558841705322
Validation loss: 1.978628045769148

Epoch: 6| Step: 5
Training loss: 2.598147392272949
Validation loss: 1.9652240571155344

Epoch: 6| Step: 6
Training loss: 1.65952467918396
Validation loss: 1.9694055985378962

Epoch: 6| Step: 7
Training loss: 2.153998374938965
Validation loss: 1.9629378241877402

Epoch: 6| Step: 8
Training loss: 1.360701084136963
Validation loss: 1.9795963123280516

Epoch: 6| Step: 9
Training loss: 1.7553479671478271
Validation loss: 1.9661259817820724

Epoch: 6| Step: 10
Training loss: 1.891953706741333
Validation loss: 1.980960666492421

Epoch: 6| Step: 11
Training loss: 1.1968765258789062
Validation loss: 1.9767939006128619

Epoch: 6| Step: 12
Training loss: 1.9722572565078735
Validation loss: 1.9994876102734638

Epoch: 6| Step: 13
Training loss: 2.188504219055176
Validation loss: 2.0181914029582853

Epoch: 289| Step: 0
Training loss: 1.6773951053619385
Validation loss: 2.00216652629196

Epoch: 6| Step: 1
Training loss: 2.233205556869507
Validation loss: 2.007825279748568

Epoch: 6| Step: 2
Training loss: 1.9507066011428833
Validation loss: 2.0016875664393106

Epoch: 6| Step: 3
Training loss: 1.8063249588012695
Validation loss: 2.0032060018149753

Epoch: 6| Step: 4
Training loss: 2.1543989181518555
Validation loss: 2.000469151363578

Epoch: 6| Step: 5
Training loss: 1.65822434425354
Validation loss: 1.998567263285319

Epoch: 6| Step: 6
Training loss: 1.5683887004852295
Validation loss: 2.00146827390117

Epoch: 6| Step: 7
Training loss: 0.8700723648071289
Validation loss: 1.9957861361965057

Epoch: 6| Step: 8
Training loss: 1.703490972518921
Validation loss: 2.006085072794268

Epoch: 6| Step: 9
Training loss: 1.953542709350586
Validation loss: 1.9781431421156852

Epoch: 6| Step: 10
Training loss: 1.8957979679107666
Validation loss: 1.9865829021699968

Epoch: 6| Step: 11
Training loss: 2.4546282291412354
Validation loss: 1.959943280425123

Epoch: 6| Step: 12
Training loss: 2.3731415271759033
Validation loss: 1.967020998718918

Epoch: 6| Step: 13
Training loss: 1.8975234031677246
Validation loss: 1.9555772325044036

Epoch: 290| Step: 0
Training loss: 1.8607361316680908
Validation loss: 1.9585879643758137

Epoch: 6| Step: 1
Training loss: 1.40022611618042
Validation loss: 1.9580513367088892

Epoch: 6| Step: 2
Training loss: 1.4256713390350342
Validation loss: 1.9593291667199904

Epoch: 6| Step: 3
Training loss: 2.234306812286377
Validation loss: 1.9741996219081264

Epoch: 6| Step: 4
Training loss: 2.215231418609619
Validation loss: 1.9706409438963859

Epoch: 6| Step: 5
Training loss: 1.3709105253219604
Validation loss: 1.9783442033234464

Epoch: 6| Step: 6
Training loss: 2.00064754486084
Validation loss: 1.9950227660517539

Epoch: 6| Step: 7
Training loss: 2.6315345764160156
Validation loss: 2.009504234918984

Epoch: 6| Step: 8
Training loss: 2.515855312347412
Validation loss: 2.017168600072143

Epoch: 6| Step: 9
Training loss: 2.0498695373535156
Validation loss: 1.9876704421094669

Epoch: 6| Step: 10
Training loss: 1.6753573417663574
Validation loss: 2.007621019117294

Epoch: 6| Step: 11
Training loss: 2.098076343536377
Validation loss: 2.0227983997714136

Epoch: 6| Step: 12
Training loss: 1.8447067737579346
Validation loss: 1.9851983516447005

Epoch: 6| Step: 13
Training loss: 0.7502511739730835
Validation loss: 1.95911955577071

Epoch: 291| Step: 0
Training loss: 1.55645751953125
Validation loss: 1.9750911830573954

Epoch: 6| Step: 1
Training loss: 1.4367289543151855
Validation loss: 1.965525932209466

Epoch: 6| Step: 2
Training loss: 1.4933316707611084
Validation loss: 1.992512228668377

Epoch: 6| Step: 3
Training loss: 2.1118195056915283
Validation loss: 2.0083084439718597

Epoch: 6| Step: 4
Training loss: 1.916577696800232
Validation loss: 2.005436540931784

Epoch: 6| Step: 5
Training loss: 2.585257053375244
Validation loss: 1.996296791620152

Epoch: 6| Step: 6
Training loss: 1.3012349605560303
Validation loss: 2.0063290211462204

Epoch: 6| Step: 7
Training loss: 1.670623779296875
Validation loss: 1.98640561872913

Epoch: 6| Step: 8
Training loss: 1.1548616886138916
Validation loss: 1.9879410894968177

Epoch: 6| Step: 9
Training loss: 2.817605972290039
Validation loss: 1.9823390591529109

Epoch: 6| Step: 10
Training loss: 2.688081741333008
Validation loss: 1.9591749124629523

Epoch: 6| Step: 11
Training loss: 2.1062428951263428
Validation loss: 1.9704797370459444

Epoch: 6| Step: 12
Training loss: 1.6879692077636719
Validation loss: 1.9935896268454931

Epoch: 6| Step: 13
Training loss: 1.5801026821136475
Validation loss: 2.0134255732259443

Epoch: 292| Step: 0
Training loss: 1.5285664796829224
Validation loss: 2.028389473115244

Epoch: 6| Step: 1
Training loss: 1.7795751094818115
Validation loss: 2.0225750425810456

Epoch: 6| Step: 2
Training loss: 1.6819205284118652
Validation loss: 2.032010168157598

Epoch: 6| Step: 3
Training loss: 2.70103120803833
Validation loss: 2.0085656437822568

Epoch: 6| Step: 4
Training loss: 1.6967133283615112
Validation loss: 1.9775919965518418

Epoch: 6| Step: 5
Training loss: 1.4389989376068115
Validation loss: 1.9615728880769463

Epoch: 6| Step: 6
Training loss: 2.291200876235962
Validation loss: 1.953862996511562

Epoch: 6| Step: 7
Training loss: 2.0795559883117676
Validation loss: 1.9412922090099705

Epoch: 6| Step: 8
Training loss: 1.9451494216918945
Validation loss: 1.9473804094458138

Epoch: 6| Step: 9
Training loss: 2.1439342498779297
Validation loss: 1.9466027752045663

Epoch: 6| Step: 10
Training loss: 1.3494229316711426
Validation loss: 1.951838957366123

Epoch: 6| Step: 11
Training loss: 2.612020492553711
Validation loss: 1.9579221599845475

Epoch: 6| Step: 12
Training loss: 1.2459542751312256
Validation loss: 1.958733279217956

Epoch: 6| Step: 13
Training loss: 1.9314939975738525
Validation loss: 1.9536307921973608

Epoch: 293| Step: 0
Training loss: 2.235653877258301
Validation loss: 1.9721407121227634

Epoch: 6| Step: 1
Training loss: 1.9343100786209106
Validation loss: 1.9622901601176108

Epoch: 6| Step: 2
Training loss: 2.039107322692871
Validation loss: 1.9909327030181885

Epoch: 6| Step: 3
Training loss: 1.489309549331665
Validation loss: 1.9999414951570573

Epoch: 6| Step: 4
Training loss: 2.0267903804779053
Validation loss: 2.0108636502296693

Epoch: 6| Step: 5
Training loss: 1.2851452827453613
Validation loss: 2.0077010790506997

Epoch: 6| Step: 6
Training loss: 1.8525192737579346
Validation loss: 2.0065843033534225

Epoch: 6| Step: 7
Training loss: 1.5421795845031738
Validation loss: 2.0144372947754396

Epoch: 6| Step: 8
Training loss: 2.3670554161071777
Validation loss: 1.9964749787443428

Epoch: 6| Step: 9
Training loss: 1.3133981227874756
Validation loss: 2.023146960043138

Epoch: 6| Step: 10
Training loss: 2.5491509437561035
Validation loss: 2.0132983653776106

Epoch: 6| Step: 11
Training loss: 1.2416660785675049
Validation loss: 2.0102787863823677

Epoch: 6| Step: 12
Training loss: 1.7037471532821655
Validation loss: 2.0131137909427768

Epoch: 6| Step: 13
Training loss: 3.0034399032592773
Validation loss: 2.001593615419121

Epoch: 294| Step: 0
Training loss: 2.598496437072754
Validation loss: 1.9854976848889423

Epoch: 6| Step: 1
Training loss: 1.7578976154327393
Validation loss: 1.964055318986216

Epoch: 6| Step: 2
Training loss: 1.9444680213928223
Validation loss: 1.959478509041571

Epoch: 6| Step: 3
Training loss: 1.938355803489685
Validation loss: 1.9513181563346618

Epoch: 6| Step: 4
Training loss: 2.385035514831543
Validation loss: 1.9671752619486984

Epoch: 6| Step: 5
Training loss: 1.7056918144226074
Validation loss: 1.964873153676269

Epoch: 6| Step: 6
Training loss: 2.1837716102600098
Validation loss: 1.9833269683263635

Epoch: 6| Step: 7
Training loss: 1.4297940731048584
Validation loss: 1.9991991237927509

Epoch: 6| Step: 8
Training loss: 1.540238618850708
Validation loss: 2.00168441700679

Epoch: 6| Step: 9
Training loss: 1.759403944015503
Validation loss: 2.015848039298929

Epoch: 6| Step: 10
Training loss: 2.017961025238037
Validation loss: 2.014421457885414

Epoch: 6| Step: 11
Training loss: 1.5833463668823242
Validation loss: 2.010532427859563

Epoch: 6| Step: 12
Training loss: 2.039944887161255
Validation loss: 2.0045292146744265

Epoch: 6| Step: 13
Training loss: 0.32469144463539124
Validation loss: 1.9879548908561788

Epoch: 295| Step: 0
Training loss: 1.7936464548110962
Validation loss: 1.9784676054472565

Epoch: 6| Step: 1
Training loss: 2.2190892696380615
Validation loss: 1.9771671013165546

Epoch: 6| Step: 2
Training loss: 1.7443950176239014
Validation loss: 1.9853432639952628

Epoch: 6| Step: 3
Training loss: 1.717086672782898
Validation loss: 1.9938197187198106

Epoch: 6| Step: 4
Training loss: 1.6012868881225586
Validation loss: 1.977428743916173

Epoch: 6| Step: 5
Training loss: 1.9516823291778564
Validation loss: 1.9748635599690099

Epoch: 6| Step: 6
Training loss: 1.7216274738311768
Validation loss: 1.960405848359549

Epoch: 6| Step: 7
Training loss: 2.2015490531921387
Validation loss: 1.9717276980800014

Epoch: 6| Step: 8
Training loss: 2.1748900413513184
Validation loss: 1.9909900683228687

Epoch: 6| Step: 9
Training loss: 2.0588788986206055
Validation loss: 1.9952898999696136

Epoch: 6| Step: 10
Training loss: 1.6803005933761597
Validation loss: 2.0160778158454487

Epoch: 6| Step: 11
Training loss: 1.9571460485458374
Validation loss: 2.080320401858258

Epoch: 6| Step: 12
Training loss: 1.7061420679092407
Validation loss: 2.093182759900247

Epoch: 6| Step: 13
Training loss: 1.1088857650756836
Validation loss: 2.1254368161642425

Epoch: 296| Step: 0
Training loss: 1.5969693660736084
Validation loss: 2.1222733861656597

Epoch: 6| Step: 1
Training loss: 2.085184097290039
Validation loss: 2.074703524189611

Epoch: 6| Step: 2
Training loss: 2.0650417804718018
Validation loss: 2.031021132264086

Epoch: 6| Step: 3
Training loss: 2.6566548347473145
Validation loss: 1.980192586939822

Epoch: 6| Step: 4
Training loss: 1.7061376571655273
Validation loss: 1.9614087048397268

Epoch: 6| Step: 5
Training loss: 1.3121116161346436
Validation loss: 1.9427930744745399

Epoch: 6| Step: 6
Training loss: 1.6818091869354248
Validation loss: 1.9544980102969753

Epoch: 6| Step: 7
Training loss: 1.558690071105957
Validation loss: 1.9462717694620932

Epoch: 6| Step: 8
Training loss: 2.018484115600586
Validation loss: 1.9581755771431872

Epoch: 6| Step: 9
Training loss: 2.1455025672912598
Validation loss: 1.9656632561837473

Epoch: 6| Step: 10
Training loss: 2.5046396255493164
Validation loss: 1.9709428138630365

Epoch: 6| Step: 11
Training loss: 1.6053262948989868
Validation loss: 1.9748780932477725

Epoch: 6| Step: 12
Training loss: 2.1798086166381836
Validation loss: 1.9688800650258218

Epoch: 6| Step: 13
Training loss: 1.4946751594543457
Validation loss: 1.969486290408719

Epoch: 297| Step: 0
Training loss: 1.8982672691345215
Validation loss: 1.974267921140117

Epoch: 6| Step: 1
Training loss: 1.9129974842071533
Validation loss: 2.007351016485563

Epoch: 6| Step: 2
Training loss: 2.0862011909484863
Validation loss: 2.023329573292886

Epoch: 6| Step: 3
Training loss: 1.8887803554534912
Validation loss: 2.0821661974794123

Epoch: 6| Step: 4
Training loss: 2.1025445461273193
Validation loss: 2.103761156400045

Epoch: 6| Step: 5
Training loss: 0.8353068232536316
Validation loss: 2.0731543674263904

Epoch: 6| Step: 6
Training loss: 2.162203550338745
Validation loss: 2.071836899685603

Epoch: 6| Step: 7
Training loss: 2.0106401443481445
Validation loss: 2.0215299488395773

Epoch: 6| Step: 8
Training loss: 1.7020399570465088
Validation loss: 2.015625707564815

Epoch: 6| Step: 9
Training loss: 2.5869202613830566
Validation loss: 2.0022535144641833

Epoch: 6| Step: 10
Training loss: 2.1274709701538086
Validation loss: 1.98031993450657

Epoch: 6| Step: 11
Training loss: 1.6883041858673096
Validation loss: 1.9855269591013591

Epoch: 6| Step: 12
Training loss: 1.7328472137451172
Validation loss: 2.010643641153971

Epoch: 6| Step: 13
Training loss: 2.1715335845947266
Validation loss: 1.9871807124025078

Epoch: 298| Step: 0
Training loss: 1.9510014057159424
Validation loss: 1.9927846154858988

Epoch: 6| Step: 1
Training loss: 1.6908855438232422
Validation loss: 1.996309580341462

Epoch: 6| Step: 2
Training loss: 1.6513020992279053
Validation loss: 2.0089502898595666

Epoch: 6| Step: 3
Training loss: 1.5493052005767822
Validation loss: 2.0207585583450975

Epoch: 6| Step: 4
Training loss: 2.886699676513672
Validation loss: 2.0364619083301996

Epoch: 6| Step: 5
Training loss: 1.7426306009292603
Validation loss: 2.0323377142670336

Epoch: 6| Step: 6
Training loss: 1.0179885625839233
Validation loss: 2.027925637460524

Epoch: 6| Step: 7
Training loss: 1.9656898975372314
Validation loss: 2.0169042797498804

Epoch: 6| Step: 8
Training loss: 1.5865447521209717
Validation loss: 2.010235401891893

Epoch: 6| Step: 9
Training loss: 2.1178793907165527
Validation loss: 1.9934462501156716

Epoch: 6| Step: 10
Training loss: 2.57590651512146
Validation loss: 2.0133846447031987

Epoch: 6| Step: 11
Training loss: 2.0714778900146484
Validation loss: 1.9782263027724398

Epoch: 6| Step: 12
Training loss: 1.42238187789917
Validation loss: 1.9775683187669324

Epoch: 6| Step: 13
Training loss: 1.3274635076522827
Validation loss: 1.9803344229216218

Epoch: 299| Step: 0
Training loss: 2.4379193782806396
Validation loss: 1.9806633226333126

Epoch: 6| Step: 1
Training loss: 1.6486753225326538
Validation loss: 1.95743425174426

Epoch: 6| Step: 2
Training loss: 2.1793012619018555
Validation loss: 1.9679761317468458

Epoch: 6| Step: 3
Training loss: 2.122164249420166
Validation loss: 1.9624488917730187

Epoch: 6| Step: 4
Training loss: 2.10384464263916
Validation loss: 1.9446133810986754

Epoch: 6| Step: 5
Training loss: 1.8228697776794434
Validation loss: 1.9505083278943134

Epoch: 6| Step: 6
Training loss: 1.1160426139831543
Validation loss: 1.9637930547037432

Epoch: 6| Step: 7
Training loss: 1.8755491971969604
Validation loss: 1.9968498265871437

Epoch: 6| Step: 8
Training loss: 1.3389818668365479
Validation loss: 1.9913120731230705

Epoch: 6| Step: 9
Training loss: 2.255492687225342
Validation loss: 2.0418382190888926

Epoch: 6| Step: 10
Training loss: 1.5141704082489014
Validation loss: 2.045268012631324

Epoch: 6| Step: 11
Training loss: 1.7381227016448975
Validation loss: 2.0451042318856842

Epoch: 6| Step: 12
Training loss: 2.1236729621887207
Validation loss: 2.041419913691859

Epoch: 6| Step: 13
Training loss: 1.2183374166488647
Validation loss: 2.05232431298943

Epoch: 300| Step: 0
Training loss: 1.3719263076782227
Validation loss: 2.0500923202883814

Epoch: 6| Step: 1
Training loss: 1.583411455154419
Validation loss: 2.048125884866202

Epoch: 6| Step: 2
Training loss: 1.8414862155914307
Validation loss: 2.0466583454480736

Epoch: 6| Step: 3
Training loss: 1.828803539276123
Validation loss: 2.0303226440183577

Epoch: 6| Step: 4
Training loss: 2.1021037101745605
Validation loss: 2.014273980612396

Epoch: 6| Step: 5
Training loss: 2.224658727645874
Validation loss: 1.9902032793209117

Epoch: 6| Step: 6
Training loss: 2.118288040161133
Validation loss: 1.974279393431961

Epoch: 6| Step: 7
Training loss: 2.324403762817383
Validation loss: 1.9770354609335623

Epoch: 6| Step: 8
Training loss: 1.469893455505371
Validation loss: 1.960688062893447

Epoch: 6| Step: 9
Training loss: 2.2657108306884766
Validation loss: 1.9760625618760304

Epoch: 6| Step: 10
Training loss: 1.937171220779419
Validation loss: 1.9782142562250937

Epoch: 6| Step: 11
Training loss: 1.2346614599227905
Validation loss: 1.9580078868455784

Epoch: 6| Step: 12
Training loss: 1.8084365129470825
Validation loss: 1.9705958161302792

Epoch: 6| Step: 13
Training loss: 0.7013684511184692
Validation loss: 1.9960759532067083

Testing loss: 2.2753768258624607
