Epoch: 1| Step: 0
Training loss: 5.941060815484155
Validation loss: 5.796063324014129

Epoch: 6| Step: 1
Training loss: 6.691102955765098
Validation loss: 5.79172619535045

Epoch: 6| Step: 2
Training loss: 6.515113865405517
Validation loss: 5.787357448502978

Epoch: 6| Step: 3
Training loss: 4.746110226951851
Validation loss: 5.7828623466966596

Epoch: 6| Step: 4
Training loss: 4.085008679757767
Validation loss: 5.778377877795378

Epoch: 6| Step: 5
Training loss: 5.047375727989937
Validation loss: 5.773876019616165

Epoch: 6| Step: 6
Training loss: 6.936378732058305
Validation loss: 5.769207966698703

Epoch: 6| Step: 7
Training loss: 5.000988290389734
Validation loss: 5.764091594815208

Epoch: 6| Step: 8
Training loss: 6.480133802186362
Validation loss: 5.758516692985874

Epoch: 6| Step: 9
Training loss: 5.929604832571812
Validation loss: 5.752711473122022

Epoch: 6| Step: 10
Training loss: 5.935004422604746
Validation loss: 5.74652908844497

Epoch: 6| Step: 11
Training loss: 5.588330589875502
Validation loss: 5.739619693700859

Epoch: 6| Step: 12
Training loss: 5.877670006023393
Validation loss: 5.732365756057049

Epoch: 6| Step: 13
Training loss: 5.636059887104234
Validation loss: 5.72442270647874

Epoch: 2| Step: 0
Training loss: 6.699257755444028
Validation loss: 5.715362770415725

Epoch: 6| Step: 1
Training loss: 5.57388221243424
Validation loss: 5.706189242060639

Epoch: 6| Step: 2
Training loss: 3.9021866072745888
Validation loss: 5.696063936280259

Epoch: 6| Step: 3
Training loss: 5.101342282646479
Validation loss: 5.684849401461598

Epoch: 6| Step: 4
Training loss: 6.290932551453986
Validation loss: 5.673136133697666

Epoch: 6| Step: 5
Training loss: 5.000917350539182
Validation loss: 5.660355965780339

Epoch: 6| Step: 6
Training loss: 6.114246504267014
Validation loss: 5.646977797854284

Epoch: 6| Step: 7
Training loss: 6.589290322048512
Validation loss: 5.631515200843654

Epoch: 6| Step: 8
Training loss: 5.619964549811475
Validation loss: 5.615365308635932

Epoch: 6| Step: 9
Training loss: 4.029402671826636
Validation loss: 5.597950649446462

Epoch: 6| Step: 10
Training loss: 5.0667823293099366
Validation loss: 5.5789713520957696

Epoch: 6| Step: 11
Training loss: 6.031203195657122
Validation loss: 5.559498859329794

Epoch: 6| Step: 12
Training loss: 6.581787249742953
Validation loss: 5.538506817735583

Epoch: 6| Step: 13
Training loss: 6.017037045111663
Validation loss: 5.5173064092388175

Epoch: 3| Step: 0
Training loss: 5.846739631525219
Validation loss: 5.494607231832887

Epoch: 6| Step: 1
Training loss: 6.641893835582177
Validation loss: 5.470587061538991

Epoch: 6| Step: 2
Training loss: 5.358994539953184
Validation loss: 5.444974931347544

Epoch: 6| Step: 3
Training loss: 5.607232409830322
Validation loss: 5.419100319617943

Epoch: 6| Step: 4
Training loss: 3.8457207318508835
Validation loss: 5.393984290091823

Epoch: 6| Step: 5
Training loss: 5.999720884824625
Validation loss: 5.366165941119491

Epoch: 6| Step: 6
Training loss: 5.1737931028212545
Validation loss: 5.340257838354875

Epoch: 6| Step: 7
Training loss: 5.149060409905714
Validation loss: 5.312230347866105

Epoch: 6| Step: 8
Training loss: 5.48975180476583
Validation loss: 5.283899166952412

Epoch: 6| Step: 9
Training loss: 6.107658906197457
Validation loss: 5.25494372911938

Epoch: 6| Step: 10
Training loss: 4.738269978861285
Validation loss: 5.224927286422343

Epoch: 6| Step: 11
Training loss: 5.161726938515149
Validation loss: 5.194734135398968

Epoch: 6| Step: 12
Training loss: 4.536667314950269
Validation loss: 5.1632414362680175

Epoch: 6| Step: 13
Training loss: 4.856600150074144
Validation loss: 5.131143081164841

Epoch: 4| Step: 0
Training loss: 5.014353558303005
Validation loss: 5.093600932968066

Epoch: 6| Step: 1
Training loss: 4.49234926678842
Validation loss: 5.056330636795304

Epoch: 6| Step: 2
Training loss: 4.962033128276481
Validation loss: 5.014140754919658

Epoch: 6| Step: 3
Training loss: 5.074394287644054
Validation loss: 4.973076848880474

Epoch: 6| Step: 4
Training loss: 4.822317439094863
Validation loss: 4.9287852541093295

Epoch: 6| Step: 5
Training loss: 6.709433266005152
Validation loss: 4.889229255647493

Epoch: 6| Step: 6
Training loss: 4.552284824035138
Validation loss: 4.84778732893771

Epoch: 6| Step: 7
Training loss: 3.8554694920686976
Validation loss: 4.812064613663449

Epoch: 6| Step: 8
Training loss: 4.8523160929667855
Validation loss: 4.778048410753301

Epoch: 6| Step: 9
Training loss: 5.872332028016266
Validation loss: 4.746017275971068

Epoch: 6| Step: 10
Training loss: 4.264073351674654
Validation loss: 4.712105561486548

Epoch: 6| Step: 11
Training loss: 5.057723441060217
Validation loss: 4.67699242504491

Epoch: 6| Step: 12
Training loss: 4.508160714859871
Validation loss: 4.6442940338490395

Epoch: 6| Step: 13
Training loss: 3.685255240266688
Validation loss: 4.616802470409288

Epoch: 5| Step: 0
Training loss: 5.391908354651075
Validation loss: 4.595150407432215

Epoch: 6| Step: 1
Training loss: 4.9005793949044145
Validation loss: 4.576628198996082

Epoch: 6| Step: 2
Training loss: 3.906743377045249
Validation loss: 4.560833318491516

Epoch: 6| Step: 3
Training loss: 5.042967615341662
Validation loss: 4.5458575478570715

Epoch: 6| Step: 4
Training loss: 4.566198652653873
Validation loss: 4.5284714533041

Epoch: 6| Step: 5
Training loss: 4.971874861894051
Validation loss: 4.516534055729163

Epoch: 6| Step: 6
Training loss: 3.981510583802417
Validation loss: 4.500195256307436

Epoch: 6| Step: 7
Training loss: 3.5910453902211965
Validation loss: 4.485248489892223

Epoch: 6| Step: 8
Training loss: 3.843730275173284
Validation loss: 4.473231856134377

Epoch: 6| Step: 9
Training loss: 5.062576858502218
Validation loss: 4.462250026541274

Epoch: 6| Step: 10
Training loss: 4.702218510154151
Validation loss: 4.44922026655861

Epoch: 6| Step: 11
Training loss: 4.403609546562254
Validation loss: 4.436838586307438

Epoch: 6| Step: 12
Training loss: 5.367678424088827
Validation loss: 4.42799231948288

Epoch: 6| Step: 13
Training loss: 3.978928736951416
Validation loss: 4.415300267409881

Epoch: 6| Step: 0
Training loss: 4.191194185863175
Validation loss: 4.40515564147646

Epoch: 6| Step: 1
Training loss: 4.274511003691383
Validation loss: 4.393042623278054

Epoch: 6| Step: 2
Training loss: 4.531064154661378
Validation loss: 4.38356505842451

Epoch: 6| Step: 3
Training loss: 3.7215027438011035
Validation loss: 4.372013991523559

Epoch: 6| Step: 4
Training loss: 5.284197103527712
Validation loss: 4.3616116903566615

Epoch: 6| Step: 5
Training loss: 5.756224538806848
Validation loss: 4.352346803129171

Epoch: 6| Step: 6
Training loss: 3.6655827278373
Validation loss: 4.338241919954528

Epoch: 6| Step: 7
Training loss: 3.9942543964924075
Validation loss: 4.330225013506339

Epoch: 6| Step: 8
Training loss: 4.209988007517064
Validation loss: 4.3195564174964405

Epoch: 6| Step: 9
Training loss: 4.1929472608390554
Validation loss: 4.311444451030575

Epoch: 6| Step: 10
Training loss: 4.816596727402433
Validation loss: 4.302280534231397

Epoch: 6| Step: 11
Training loss: 5.1443683016263835
Validation loss: 4.2952435851103035

Epoch: 6| Step: 12
Training loss: 4.526747156550268
Validation loss: 4.291740736226109

Epoch: 6| Step: 13
Training loss: 2.589498965872856
Validation loss: 4.282400804257305

Epoch: 7| Step: 0
Training loss: 4.652994541160911
Validation loss: 4.280829753688867

Epoch: 6| Step: 1
Training loss: 4.496711589078895
Validation loss: 4.273152750969085

Epoch: 6| Step: 2
Training loss: 4.987386815978611
Validation loss: 4.2605503323162255

Epoch: 6| Step: 3
Training loss: 4.536439226229255
Validation loss: 4.252219465698168

Epoch: 6| Step: 4
Training loss: 3.4792916890293393
Validation loss: 4.249422957100944

Epoch: 6| Step: 5
Training loss: 4.00592317721009
Validation loss: 4.246877590976291

Epoch: 6| Step: 6
Training loss: 4.293198000589493
Validation loss: 4.231782875163802

Epoch: 6| Step: 7
Training loss: 4.204607507121257
Validation loss: 4.219716169956771

Epoch: 6| Step: 8
Training loss: 4.427098292905178
Validation loss: 4.213614911949241

Epoch: 6| Step: 9
Training loss: 3.477035387431255
Validation loss: 4.207604856418408

Epoch: 6| Step: 10
Training loss: 4.0884106009628525
Validation loss: 4.195592545238723

Epoch: 6| Step: 11
Training loss: 4.970832052601055
Validation loss: 4.18410432995403

Epoch: 6| Step: 12
Training loss: 4.65463208245271
Validation loss: 4.170386566554474

Epoch: 6| Step: 13
Training loss: 4.511058993630936
Validation loss: 4.156609713870954

Epoch: 8| Step: 0
Training loss: 4.625814417710638
Validation loss: 4.145711175474435

Epoch: 6| Step: 1
Training loss: 4.6409716749586565
Validation loss: 4.137780982425287

Epoch: 6| Step: 2
Training loss: 4.4001938343701745
Validation loss: 4.129467935659107

Epoch: 6| Step: 3
Training loss: 4.279302892154031
Validation loss: 4.114987031762231

Epoch: 6| Step: 4
Training loss: 4.70615307225572
Validation loss: 4.099684715003755

Epoch: 6| Step: 5
Training loss: 4.06837297090263
Validation loss: 4.0886136286604735

Epoch: 6| Step: 6
Training loss: 4.200351409743241
Validation loss: 4.078016135796691

Epoch: 6| Step: 7
Training loss: 3.400471116131632
Validation loss: 4.0700709232079735

Epoch: 6| Step: 8
Training loss: 3.877913456510354
Validation loss: 4.0614660583322815

Epoch: 6| Step: 9
Training loss: 4.489648144365556
Validation loss: 4.053850235337212

Epoch: 6| Step: 10
Training loss: 3.760393869994886
Validation loss: 4.04900743152864

Epoch: 6| Step: 11
Training loss: 4.780054279482077
Validation loss: 4.043172272758197

Epoch: 6| Step: 12
Training loss: 3.845146855797756
Validation loss: 4.035424427540838

Epoch: 6| Step: 13
Training loss: 3.5781949631959846
Validation loss: 4.026429013138396

Epoch: 9| Step: 0
Training loss: 3.998753234156034
Validation loss: 4.022787887964145

Epoch: 6| Step: 1
Training loss: 3.8905133457325083
Validation loss: 4.014479341445811

Epoch: 6| Step: 2
Training loss: 4.557706221844347
Validation loss: 4.0114101185712014

Epoch: 6| Step: 3
Training loss: 3.291095893401684
Validation loss: 4.007452244744571

Epoch: 6| Step: 4
Training loss: 4.260262608560238
Validation loss: 3.9983651835073877

Epoch: 6| Step: 5
Training loss: 4.907734445888186
Validation loss: 3.9931537980734655

Epoch: 6| Step: 6
Training loss: 4.184192091097181
Validation loss: 3.989063038915183

Epoch: 6| Step: 7
Training loss: 3.9664848050867882
Validation loss: 3.980457905387836

Epoch: 6| Step: 8
Training loss: 4.54206368113884
Validation loss: 3.9768944293581487

Epoch: 6| Step: 9
Training loss: 3.632759865000076
Validation loss: 3.971958260533946

Epoch: 6| Step: 10
Training loss: 3.7096988578380223
Validation loss: 3.9656189703837526

Epoch: 6| Step: 11
Training loss: 4.796405980544203
Validation loss: 3.957458253426943

Epoch: 6| Step: 12
Training loss: 3.9667572064578582
Validation loss: 3.95343050120168

Epoch: 6| Step: 13
Training loss: 3.7548988133599255
Validation loss: 3.945555318619342

Epoch: 10| Step: 0
Training loss: 3.640197597841437
Validation loss: 3.9367941337466275

Epoch: 6| Step: 1
Training loss: 3.6346252512691164
Validation loss: 3.9325973894982194

Epoch: 6| Step: 2
Training loss: 4.724223820951884
Validation loss: 3.932692186928776

Epoch: 6| Step: 3
Training loss: 4.163227391194362
Validation loss: 3.9252252914724126

Epoch: 6| Step: 4
Training loss: 4.247146546115366
Validation loss: 3.9184590603980314

Epoch: 6| Step: 5
Training loss: 4.608941733477208
Validation loss: 3.9139182978079896

Epoch: 6| Step: 6
Training loss: 3.4883405759407844
Validation loss: 3.9075001386023183

Epoch: 6| Step: 7
Training loss: 3.9534257012995453
Validation loss: 3.904225931783621

Epoch: 6| Step: 8
Training loss: 3.5747566193652
Validation loss: 3.899582343117674

Epoch: 6| Step: 9
Training loss: 4.449152730798602
Validation loss: 3.8951382142189357

Epoch: 6| Step: 10
Training loss: 4.807329645416689
Validation loss: 3.8891410450458435

Epoch: 6| Step: 11
Training loss: 4.125739522591843
Validation loss: 3.8841801829382234

Epoch: 6| Step: 12
Training loss: 3.623056482677625
Validation loss: 3.878343466209147

Epoch: 6| Step: 13
Training loss: 3.111182832648069
Validation loss: 3.872888223170433

Epoch: 11| Step: 0
Training loss: 3.521512539751485
Validation loss: 3.87023056554067

Epoch: 6| Step: 1
Training loss: 4.339573450881515
Validation loss: 3.8651276343805434

Epoch: 6| Step: 2
Training loss: 2.9698211343766867
Validation loss: 3.8606199126828376

Epoch: 6| Step: 3
Training loss: 4.07200730782923
Validation loss: 3.855252873757634

Epoch: 6| Step: 4
Training loss: 4.427859943562981
Validation loss: 3.8522933682191023

Epoch: 6| Step: 5
Training loss: 4.353134446637049
Validation loss: 3.8509826243605936

Epoch: 6| Step: 6
Training loss: 3.577872588070979
Validation loss: 3.8436805884904284

Epoch: 6| Step: 7
Training loss: 3.731763620984104
Validation loss: 3.839369187506964

Epoch: 6| Step: 8
Training loss: 4.202742435104735
Validation loss: 3.833229447856899

Epoch: 6| Step: 9
Training loss: 4.299017132941688
Validation loss: 3.832751593558115

Epoch: 6| Step: 10
Training loss: 3.369212663405568
Validation loss: 3.8249336861584395

Epoch: 6| Step: 11
Training loss: 4.50372816992643
Validation loss: 3.8234447069751942

Epoch: 6| Step: 12
Training loss: 4.704731511594621
Validation loss: 3.8194942403749796

Epoch: 6| Step: 13
Training loss: 3.354260050419443
Validation loss: 3.8146930897994618

Epoch: 12| Step: 0
Training loss: 3.526501864553002
Validation loss: 3.813347356331471

Epoch: 6| Step: 1
Training loss: 3.5419780519517357
Validation loss: 3.80823685582261

Epoch: 6| Step: 2
Training loss: 3.954017990634801
Validation loss: 3.8039607374546516

Epoch: 6| Step: 3
Training loss: 3.4421155980064153
Validation loss: 3.8008883596624354

Epoch: 6| Step: 4
Training loss: 3.305326359458215
Validation loss: 3.795688187259422

Epoch: 6| Step: 5
Training loss: 4.760409944336177
Validation loss: 3.792506557091227

Epoch: 6| Step: 6
Training loss: 3.881951035046807
Validation loss: 3.7849378454335834

Epoch: 6| Step: 7
Training loss: 4.393179913757081
Validation loss: 3.7818057503471016

Epoch: 6| Step: 8
Training loss: 4.072763945829327
Validation loss: 3.778265256171568

Epoch: 6| Step: 9
Training loss: 3.8075073570736433
Validation loss: 3.771407351158684

Epoch: 6| Step: 10
Training loss: 4.7827977685910215
Validation loss: 3.770717627006117

Epoch: 6| Step: 11
Training loss: 3.6589543701062373
Validation loss: 3.765079020785026

Epoch: 6| Step: 12
Training loss: 4.016687393662619
Validation loss: 3.762341724659276

Epoch: 6| Step: 13
Training loss: 3.961323314889903
Validation loss: 3.758843004575391

Epoch: 13| Step: 0
Training loss: 4.233277125748876
Validation loss: 3.756807029832954

Epoch: 6| Step: 1
Training loss: 4.781441479008971
Validation loss: 3.758253873430697

Epoch: 6| Step: 2
Training loss: 3.8579778574797072
Validation loss: 3.748141481085465

Epoch: 6| Step: 3
Training loss: 3.3654256579233466
Validation loss: 3.7432433947434207

Epoch: 6| Step: 4
Training loss: 3.3249571144952266
Validation loss: 3.7361024799870632

Epoch: 6| Step: 5
Training loss: 3.907438539886861
Validation loss: 3.740490382493031

Epoch: 6| Step: 6
Training loss: 3.997063154693689
Validation loss: 3.7306426021673786

Epoch: 6| Step: 7
Training loss: 4.520679430239035
Validation loss: 3.7217457728142413

Epoch: 6| Step: 8
Training loss: 4.44117648990692
Validation loss: 3.7180075479493815

Epoch: 6| Step: 9
Training loss: 3.8962002069781327
Validation loss: 3.7129651480905435

Epoch: 6| Step: 10
Training loss: 3.6441931531949523
Validation loss: 3.7064992681425366

Epoch: 6| Step: 11
Training loss: 2.3590780917668237
Validation loss: 3.698950515743291

Epoch: 6| Step: 12
Training loss: 3.699762934745337
Validation loss: 3.695625747522398

Epoch: 6| Step: 13
Training loss: 4.3110169887645995
Validation loss: 3.688202852341518

Epoch: 14| Step: 0
Training loss: 3.261027481014779
Validation loss: 3.682438837439339

Epoch: 6| Step: 1
Training loss: 4.1051340012046715
Validation loss: 3.681073578465295

Epoch: 6| Step: 2
Training loss: 3.403184824015753
Validation loss: 3.6784196138512018

Epoch: 6| Step: 3
Training loss: 4.550068680800324
Validation loss: 3.675532455998018

Epoch: 6| Step: 4
Training loss: 3.74251113798208
Validation loss: 3.6690999013836136

Epoch: 6| Step: 5
Training loss: 3.9047069706303517
Validation loss: 3.6634479716398225

Epoch: 6| Step: 6
Training loss: 3.1468036662467216
Validation loss: 3.6580699461066715

Epoch: 6| Step: 7
Training loss: 3.4900958391818993
Validation loss: 3.6541488537769498

Epoch: 6| Step: 8
Training loss: 4.518727223614582
Validation loss: 3.6556588210243883

Epoch: 6| Step: 9
Training loss: 3.5936618959988302
Validation loss: 3.6535861416145803

Epoch: 6| Step: 10
Training loss: 3.3236343103125114
Validation loss: 3.6531385264955953

Epoch: 6| Step: 11
Training loss: 3.8303597291778257
Validation loss: 3.648694933049865

Epoch: 6| Step: 12
Training loss: 4.611792185988875
Validation loss: 3.643709444587115

Epoch: 6| Step: 13
Training loss: 4.165281879462178
Validation loss: 3.637176900370812

Epoch: 15| Step: 0
Training loss: 3.567621665328854
Validation loss: 3.6338509753007773

Epoch: 6| Step: 1
Training loss: 3.985310882158833
Validation loss: 3.630775673681094

Epoch: 6| Step: 2
Training loss: 2.9761536485119144
Validation loss: 3.6306686266092356

Epoch: 6| Step: 3
Training loss: 4.33471002473466
Validation loss: 3.632483173270948

Epoch: 6| Step: 4
Training loss: 2.642015801913114
Validation loss: 3.626941975440536

Epoch: 6| Step: 5
Training loss: 2.782273864879569
Validation loss: 3.621382689610758

Epoch: 6| Step: 6
Training loss: 5.106563062654392
Validation loss: 3.6187139314173122

Epoch: 6| Step: 7
Training loss: 3.9222003452266057
Validation loss: 3.617708463363428

Epoch: 6| Step: 8
Training loss: 4.080775543254472
Validation loss: 3.615447395931555

Epoch: 6| Step: 9
Training loss: 3.5370717628539308
Validation loss: 3.6131016059967864

Epoch: 6| Step: 10
Training loss: 4.029360069411733
Validation loss: 3.6121829696303274

Epoch: 6| Step: 11
Training loss: 3.706986229063418
Validation loss: 3.608281676379188

Epoch: 6| Step: 12
Training loss: 4.23794416502266
Validation loss: 3.607810691601003

Epoch: 6| Step: 13
Training loss: 3.7527150815640717
Validation loss: 3.6036194464092217

Epoch: 16| Step: 0
Training loss: 3.955881718131456
Validation loss: 3.5992644444430635

Epoch: 6| Step: 1
Training loss: 4.6578126883674695
Validation loss: 3.5965510797665496

Epoch: 6| Step: 2
Training loss: 3.3507989756212493
Validation loss: 3.5960323524821547

Epoch: 6| Step: 3
Training loss: 4.278441015794744
Validation loss: 3.592850838806721

Epoch: 6| Step: 4
Training loss: 4.220997529572046
Validation loss: 3.589689980132735

Epoch: 6| Step: 5
Training loss: 4.395954196708668
Validation loss: 3.5877141399171935

Epoch: 6| Step: 6
Training loss: 3.50429108376514
Validation loss: 3.586548074108942

Epoch: 6| Step: 7
Training loss: 2.6842230401864473
Validation loss: 3.5825201262689506

Epoch: 6| Step: 8
Training loss: 3.7578268387931346
Validation loss: 3.582729492382238

Epoch: 6| Step: 9
Training loss: 3.4601367859455516
Validation loss: 3.5805371791647294

Epoch: 6| Step: 10
Training loss: 3.9585318398476224
Validation loss: 3.5777234929899184

Epoch: 6| Step: 11
Training loss: 3.334333476386321
Validation loss: 3.5756635484227957

Epoch: 6| Step: 12
Training loss: 4.03540770937205
Validation loss: 3.575441801614409

Epoch: 6| Step: 13
Training loss: 1.9600107503129065
Validation loss: 3.5727750765151187

Epoch: 17| Step: 0
Training loss: 3.63187414376415
Validation loss: 3.5713195479140682

Epoch: 6| Step: 1
Training loss: 3.6139816677555308
Validation loss: 3.5703935360637673

Epoch: 6| Step: 2
Training loss: 3.1666958623510637
Validation loss: 3.5692049094043146

Epoch: 6| Step: 3
Training loss: 3.4481272714761926
Validation loss: 3.5641272382879023

Epoch: 6| Step: 4
Training loss: 4.0404992269131235
Validation loss: 3.5633130846676395

Epoch: 6| Step: 5
Training loss: 3.9366100456005353
Validation loss: 3.5614163719368914

Epoch: 6| Step: 6
Training loss: 3.9667014294124203
Validation loss: 3.5578504789572065

Epoch: 6| Step: 7
Training loss: 3.752195732696695
Validation loss: 3.5605572143740813

Epoch: 6| Step: 8
Training loss: 3.8439541894284854
Validation loss: 3.5561982689349065

Epoch: 6| Step: 9
Training loss: 3.026190241428872
Validation loss: 3.5564730571983647

Epoch: 6| Step: 10
Training loss: 4.5944300556892905
Validation loss: 3.5521425227766206

Epoch: 6| Step: 11
Training loss: 4.486973876713848
Validation loss: 3.5482308916443177

Epoch: 6| Step: 12
Training loss: 3.614539740718235
Validation loss: 3.546540255044365

Epoch: 6| Step: 13
Training loss: 2.6807446410362057
Validation loss: 3.546916678634023

Epoch: 18| Step: 0
Training loss: 3.392748471004003
Validation loss: 3.5447560834465413

Epoch: 6| Step: 1
Training loss: 4.391559542097999
Validation loss: 3.549938664591799

Epoch: 6| Step: 2
Training loss: 4.575304223456908
Validation loss: 3.541418990294449

Epoch: 6| Step: 3
Training loss: 2.8438616720218173
Validation loss: 3.5372638260187586

Epoch: 6| Step: 4
Training loss: 3.820222880866648
Validation loss: 3.534116518966226

Epoch: 6| Step: 5
Training loss: 2.610374579023106
Validation loss: 3.534169906396259

Epoch: 6| Step: 6
Training loss: 3.3466405050868677
Validation loss: 3.5319998762867257

Epoch: 6| Step: 7
Training loss: 3.518071658403869
Validation loss: 3.5315411754642687

Epoch: 6| Step: 8
Training loss: 3.695477923507308
Validation loss: 3.5308030063639926

Epoch: 6| Step: 9
Training loss: 3.49074201942673
Validation loss: 3.5276306127999946

Epoch: 6| Step: 10
Training loss: 4.227681066604686
Validation loss: 3.5261505910378697

Epoch: 6| Step: 11
Training loss: 2.9033607149055616
Validation loss: 3.523883968553876

Epoch: 6| Step: 12
Training loss: 4.647944268737843
Validation loss: 3.52550572037663

Epoch: 6| Step: 13
Training loss: 4.479525080099151
Validation loss: 3.520461596132017

Epoch: 19| Step: 0
Training loss: 2.9371162326193385
Validation loss: 3.520549367826923

Epoch: 6| Step: 1
Training loss: 3.575401635717231
Validation loss: 3.5263859002237083

Epoch: 6| Step: 2
Training loss: 3.8814962754306026
Validation loss: 3.5265735294103906

Epoch: 6| Step: 3
Training loss: 4.065387110747203
Validation loss: 3.5228867799490775

Epoch: 6| Step: 4
Training loss: 3.4594041170102687
Validation loss: 3.5163463046727954

Epoch: 6| Step: 5
Training loss: 3.770572941397167
Validation loss: 3.510100193071383

Epoch: 6| Step: 6
Training loss: 3.6649296431924556
Validation loss: 3.50855954385316

Epoch: 6| Step: 7
Training loss: 3.970355092270189
Validation loss: 3.510492877504782

Epoch: 6| Step: 8
Training loss: 3.354384863412314
Validation loss: 3.5094227279999832

Epoch: 6| Step: 9
Training loss: 4.306764852587543
Validation loss: 3.5079103402258855

Epoch: 6| Step: 10
Training loss: 3.080760311808745
Validation loss: 3.5072036245059977

Epoch: 6| Step: 11
Training loss: 4.762317147336621
Validation loss: 3.506313799425216

Epoch: 6| Step: 12
Training loss: 3.508023737810784
Validation loss: 3.502871508844064

Epoch: 6| Step: 13
Training loss: 3.123171614779401
Validation loss: 3.501686236414061

Epoch: 20| Step: 0
Training loss: 3.6581350830397996
Validation loss: 3.500602254309966

Epoch: 6| Step: 1
Training loss: 3.898188948113638
Validation loss: 3.50065103678445

Epoch: 6| Step: 2
Training loss: 4.282130686818671
Validation loss: 3.4999214931185776

Epoch: 6| Step: 3
Training loss: 3.5642085746588785
Validation loss: 3.4971650841062054

Epoch: 6| Step: 4
Training loss: 2.5301990917712867
Validation loss: 3.497999444297836

Epoch: 6| Step: 5
Training loss: 4.0271723032735895
Validation loss: 3.49494230835374

Epoch: 6| Step: 6
Training loss: 4.101554129455744
Validation loss: 3.4948865626588645

Epoch: 6| Step: 7
Training loss: 2.6627498312493345
Validation loss: 3.4930555108133152

Epoch: 6| Step: 8
Training loss: 3.6723836343609806
Validation loss: 3.491610438044169

Epoch: 6| Step: 9
Training loss: 4.211847380391755
Validation loss: 3.4900876342784013

Epoch: 6| Step: 10
Training loss: 3.949955932757673
Validation loss: 3.4910198464744027

Epoch: 6| Step: 11
Training loss: 3.497333600855633
Validation loss: 3.490447732791569

Epoch: 6| Step: 12
Training loss: 4.025540115416216
Validation loss: 3.4916251152452777

Epoch: 6| Step: 13
Training loss: 3.0458458360518885
Validation loss: 3.4888660960483495

Epoch: 21| Step: 0
Training loss: 3.189863637562759
Validation loss: 3.4856146548668723

Epoch: 6| Step: 1
Training loss: 3.3005099393859356
Validation loss: 3.486609091955012

Epoch: 6| Step: 2
Training loss: 3.227298975799921
Validation loss: 3.4873688936224805

Epoch: 6| Step: 3
Training loss: 3.1428011666304365
Validation loss: 3.4846942199339543

Epoch: 6| Step: 4
Training loss: 3.783734978909728
Validation loss: 3.484708974820463

Epoch: 6| Step: 5
Training loss: 2.5866740580908707
Validation loss: 3.483779568671521

Epoch: 6| Step: 6
Training loss: 3.9703522098841844
Validation loss: 3.4816097567987465

Epoch: 6| Step: 7
Training loss: 3.8367653009864333
Validation loss: 3.4819900780280375

Epoch: 6| Step: 8
Training loss: 4.070321403391174
Validation loss: 3.4796396756407018

Epoch: 6| Step: 9
Training loss: 3.6525393183770163
Validation loss: 3.479670306816301

Epoch: 6| Step: 10
Training loss: 4.634125650479667
Validation loss: 3.4794437832796143

Epoch: 6| Step: 11
Training loss: 4.477300400025702
Validation loss: 3.4772913560644994

Epoch: 6| Step: 12
Training loss: 3.5013166403429414
Validation loss: 3.4761439522332904

Epoch: 6| Step: 13
Training loss: 3.980082993912028
Validation loss: 3.4762069278813614

Epoch: 22| Step: 0
Training loss: 3.1573269961117387
Validation loss: 3.476704630769872

Epoch: 6| Step: 1
Training loss: 3.5609084472542345
Validation loss: 3.47515457327725

Epoch: 6| Step: 2
Training loss: 3.4107267027167394
Validation loss: 3.47376115184034

Epoch: 6| Step: 3
Training loss: 3.4791250321567753
Validation loss: 3.474561208219242

Epoch: 6| Step: 4
Training loss: 3.920634404053638
Validation loss: 3.4727567712187404

Epoch: 6| Step: 5
Training loss: 4.033964677269256
Validation loss: 3.471735792536135

Epoch: 6| Step: 6
Training loss: 4.300649310036222
Validation loss: 3.4715611430792435

Epoch: 6| Step: 7
Training loss: 3.5308200270583834
Validation loss: 3.4691655128986705

Epoch: 6| Step: 8
Training loss: 3.4834982277811055
Validation loss: 3.4699399341466193

Epoch: 6| Step: 9
Training loss: 4.065417371956184
Validation loss: 3.470179432427959

Epoch: 6| Step: 10
Training loss: 3.7136614950927176
Validation loss: 3.4701899398401164

Epoch: 6| Step: 11
Training loss: 3.8303858717515227
Validation loss: 3.4667103587356047

Epoch: 6| Step: 12
Training loss: 3.312434645673836
Validation loss: 3.4656685243140015

Epoch: 6| Step: 13
Training loss: 3.648381169474467
Validation loss: 3.465365944466996

Epoch: 23| Step: 0
Training loss: 3.7319234677938153
Validation loss: 3.4650185131192877

Epoch: 6| Step: 1
Training loss: 3.7852807118017906
Validation loss: 3.46564237790586

Epoch: 6| Step: 2
Training loss: 3.4399891944094545
Validation loss: 3.4657598510025287

Epoch: 6| Step: 3
Training loss: 4.0858635102496565
Validation loss: 3.4642386196077344

Epoch: 6| Step: 4
Training loss: 3.406317893935247
Validation loss: 3.4639516077890895

Epoch: 6| Step: 5
Training loss: 3.262539953228333
Validation loss: 3.4625449946845763

Epoch: 6| Step: 6
Training loss: 3.3648060035049783
Validation loss: 3.461072041689856

Epoch: 6| Step: 7
Training loss: 4.230090010747222
Validation loss: 3.461305582462829

Epoch: 6| Step: 8
Training loss: 3.6309879438220602
Validation loss: 3.461010035061648

Epoch: 6| Step: 9
Training loss: 3.4246112909199615
Validation loss: 3.4645989718129973

Epoch: 6| Step: 10
Training loss: 3.3448748256372958
Validation loss: 3.4589305060143665

Epoch: 6| Step: 11
Training loss: 2.9225616464239788
Validation loss: 3.459128631718585

Epoch: 6| Step: 12
Training loss: 4.289230815871453
Validation loss: 3.4571824059458764

Epoch: 6| Step: 13
Training loss: 4.73214961460176
Validation loss: 3.4589310648532563

Epoch: 24| Step: 0
Training loss: 3.6033242771859455
Validation loss: 3.458433708476801

Epoch: 6| Step: 1
Training loss: 3.945001268858035
Validation loss: 3.457446680865332

Epoch: 6| Step: 2
Training loss: 4.1402306710817
Validation loss: 3.4554407234430897

Epoch: 6| Step: 3
Training loss: 4.108808239047385
Validation loss: 3.4548639705423034

Epoch: 6| Step: 4
Training loss: 3.2187245192028437
Validation loss: 3.454288767457581

Epoch: 6| Step: 5
Training loss: 3.7070801292549365
Validation loss: 3.4546014735029984

Epoch: 6| Step: 6
Training loss: 3.420717365809828
Validation loss: 3.4518694677807638

Epoch: 6| Step: 7
Training loss: 2.955039236515018
Validation loss: 3.451328201923002

Epoch: 6| Step: 8
Training loss: 3.7141597852214505
Validation loss: 3.4529994009474225

Epoch: 6| Step: 9
Training loss: 3.5927831261336474
Validation loss: 3.4510080335879323

Epoch: 6| Step: 10
Training loss: 3.815436561174062
Validation loss: 3.4506983599634315

Epoch: 6| Step: 11
Training loss: 3.8183240337638775
Validation loss: 3.448533180783186

Epoch: 6| Step: 12
Training loss: 3.886691023377862
Validation loss: 3.4505108190458125

Epoch: 6| Step: 13
Training loss: 2.9864419699625193
Validation loss: 3.4490743255731378

Epoch: 25| Step: 0
Training loss: 4.418587800627647
Validation loss: 3.4472637211949113

Epoch: 6| Step: 1
Training loss: 3.2491007807990604
Validation loss: 3.44846803376847

Epoch: 6| Step: 2
Training loss: 3.314468087031639
Validation loss: 3.446807271427929

Epoch: 6| Step: 3
Training loss: 3.2010518133563526
Validation loss: 3.444731766571263

Epoch: 6| Step: 4
Training loss: 4.244811537370413
Validation loss: 3.4446519658397436

Epoch: 6| Step: 5
Training loss: 3.663619740622904
Validation loss: 3.447022997392919

Epoch: 6| Step: 6
Training loss: 3.184149982562096
Validation loss: 3.4466523687601605

Epoch: 6| Step: 7
Training loss: 3.9437025354494413
Validation loss: 3.44463109734508

Epoch: 6| Step: 8
Training loss: 3.4770544497000904
Validation loss: 3.4495021465014983

Epoch: 6| Step: 9
Training loss: 3.2873268168852916
Validation loss: 3.4448833461054162

Epoch: 6| Step: 10
Training loss: 3.912932882036037
Validation loss: 3.440580365714605

Epoch: 6| Step: 11
Training loss: 3.5534545101476223
Validation loss: 3.4426444420686404

Epoch: 6| Step: 12
Training loss: 3.854396311473863
Validation loss: 3.441716962301476

Epoch: 6| Step: 13
Training loss: 3.7785992118891567
Validation loss: 3.4418683885888153

Epoch: 26| Step: 0
Training loss: 3.5220722674657
Validation loss: 3.4420340786879766

Epoch: 6| Step: 1
Training loss: 3.306013269728968
Validation loss: 3.441639968429644

Epoch: 6| Step: 2
Training loss: 3.928753781731024
Validation loss: 3.4404487648105513

Epoch: 6| Step: 3
Training loss: 3.666745502895969
Validation loss: 3.4400593810287505

Epoch: 6| Step: 4
Training loss: 4.431063860385501
Validation loss: 3.4375041107719952

Epoch: 6| Step: 5
Training loss: 3.901466186947921
Validation loss: 3.4366874219173518

Epoch: 6| Step: 6
Training loss: 3.19196381011563
Validation loss: 3.437043626010499

Epoch: 6| Step: 7
Training loss: 3.829697515629434
Validation loss: 3.4398834616525553

Epoch: 6| Step: 8
Training loss: 3.215486816758856
Validation loss: 3.4418065082298765

Epoch: 6| Step: 9
Training loss: 3.293743653264165
Validation loss: 3.466479880713712

Epoch: 6| Step: 10
Training loss: 3.835319142894949
Validation loss: 3.451329345089358

Epoch: 6| Step: 11
Training loss: 3.413644865492044
Validation loss: 3.435682584103552

Epoch: 6| Step: 12
Training loss: 3.9272068452848083
Validation loss: 3.4436026046794823

Epoch: 6| Step: 13
Training loss: 3.657037503457789
Validation loss: 3.4641321380092793

Epoch: 27| Step: 0
Training loss: 3.838476766230023
Validation loss: 3.491049029537665

Epoch: 6| Step: 1
Training loss: 3.8412721912700114
Validation loss: 3.4824650008104796

Epoch: 6| Step: 2
Training loss: 4.069539236469894
Validation loss: 3.4603979933307736

Epoch: 6| Step: 3
Training loss: 3.7332353329284493
Validation loss: 3.441210599397296

Epoch: 6| Step: 4
Training loss: 3.916728134214034
Validation loss: 3.4368593083124086

Epoch: 6| Step: 5
Training loss: 4.128999331894846
Validation loss: 3.440960812700394

Epoch: 6| Step: 6
Training loss: 2.2287953741960793
Validation loss: 3.448748795072411

Epoch: 6| Step: 7
Training loss: 2.910326651890321
Validation loss: 3.453288114406641

Epoch: 6| Step: 8
Training loss: 3.57355537303543
Validation loss: 3.453048646560017

Epoch: 6| Step: 9
Training loss: 4.346004203053534
Validation loss: 3.4411928598354775

Epoch: 6| Step: 10
Training loss: 3.149924558916876
Validation loss: 3.442907438229282

Epoch: 6| Step: 11
Training loss: 3.4891928990515835
Validation loss: 3.4438192385866797

Epoch: 6| Step: 12
Training loss: 3.734243733800424
Validation loss: 3.4550293312556892

Epoch: 6| Step: 13
Training loss: 4.0939473111890425
Validation loss: 3.4338643108376163

Epoch: 28| Step: 0
Training loss: 4.069876209972725
Validation loss: 3.4328198892963235

Epoch: 6| Step: 1
Training loss: 3.5998144313880527
Validation loss: 3.435209837040513

Epoch: 6| Step: 2
Training loss: 3.289121649928343
Validation loss: 3.438498931155063

Epoch: 6| Step: 3
Training loss: 4.211925723269564
Validation loss: 3.449348216218641

Epoch: 6| Step: 4
Training loss: 3.3506546747266537
Validation loss: 3.4501363426828138

Epoch: 6| Step: 5
Training loss: 3.317946077668594
Validation loss: 3.439774333072357

Epoch: 6| Step: 6
Training loss: 2.684200568077346
Validation loss: 3.4358504886058685

Epoch: 6| Step: 7
Training loss: 3.2305094890493495
Validation loss: 3.4338979827426708

Epoch: 6| Step: 8
Training loss: 3.617991677320533
Validation loss: 3.432504390803399

Epoch: 6| Step: 9
Training loss: 4.4528937028747455
Validation loss: 3.4301371785444323

Epoch: 6| Step: 10
Training loss: 3.4309254977510317
Validation loss: 3.432909544828429

Epoch: 6| Step: 11
Training loss: 4.368794427080971
Validation loss: 3.43181796941723

Epoch: 6| Step: 12
Training loss: 3.2650413174081465
Validation loss: 3.429710390910272

Epoch: 6| Step: 13
Training loss: 3.99892768791813
Validation loss: 3.426564177509481

Epoch: 29| Step: 0
Training loss: 3.9307999297170264
Validation loss: 3.425689752543228

Epoch: 6| Step: 1
Training loss: 3.3910193148090744
Validation loss: 3.4234511088511077

Epoch: 6| Step: 2
Training loss: 3.5258900972787535
Validation loss: 3.423021568802101

Epoch: 6| Step: 3
Training loss: 4.281298783295857
Validation loss: 3.425792198160384

Epoch: 6| Step: 4
Training loss: 3.0810851759089775
Validation loss: 3.4256986056010703

Epoch: 6| Step: 5
Training loss: 3.1456785016556936
Validation loss: 3.419840181974176

Epoch: 6| Step: 6
Training loss: 3.8307844616572733
Validation loss: 3.419678356884799

Epoch: 6| Step: 7
Training loss: 2.8580275732569604
Validation loss: 3.4190593010785615

Epoch: 6| Step: 8
Training loss: 4.402760524027351
Validation loss: 3.417544469514268

Epoch: 6| Step: 9
Training loss: 4.086098779008105
Validation loss: 3.416189831750382

Epoch: 6| Step: 10
Training loss: 3.5332776215197725
Validation loss: 3.418105356513104

Epoch: 6| Step: 11
Training loss: 3.345870441945149
Validation loss: 3.416967094132843

Epoch: 6| Step: 12
Training loss: 3.75516929376902
Validation loss: 3.4177671221491295

Epoch: 6| Step: 13
Training loss: 3.3165205541531932
Validation loss: 3.4197033628869615

Epoch: 30| Step: 0
Training loss: 2.797007978464094
Validation loss: 3.414052041362684

Epoch: 6| Step: 1
Training loss: 4.44003825059515
Validation loss: 3.4189020453183243

Epoch: 6| Step: 2
Training loss: 4.361588329816223
Validation loss: 3.4162309547864402

Epoch: 6| Step: 3
Training loss: 3.578772074064716
Validation loss: 3.415598133233195

Epoch: 6| Step: 4
Training loss: 3.2512225272584665
Validation loss: 3.4126565847344463

Epoch: 6| Step: 5
Training loss: 3.2334655367641396
Validation loss: 3.410766677735684

Epoch: 6| Step: 6
Training loss: 3.43700114011593
Validation loss: 3.4119746607998316

Epoch: 6| Step: 7
Training loss: 2.9413999276264224
Validation loss: 3.41009756661566

Epoch: 6| Step: 8
Training loss: 3.27160491265813
Validation loss: 3.412530218927624

Epoch: 6| Step: 9
Training loss: 4.832351957639767
Validation loss: 3.417490070347586

Epoch: 6| Step: 10
Training loss: 3.646461752365216
Validation loss: 3.41907407302915

Epoch: 6| Step: 11
Training loss: 3.144169719123993
Validation loss: 3.412529987544664

Epoch: 6| Step: 12
Training loss: 3.956749743194967
Validation loss: 3.4150967511495183

Epoch: 6| Step: 13
Training loss: 3.228162318085058
Validation loss: 3.4106691897003536

Epoch: 31| Step: 0
Training loss: 3.9049283652872435
Validation loss: 3.4112320999746464

Epoch: 6| Step: 1
Training loss: 3.986607423573937
Validation loss: 3.410696618921039

Epoch: 6| Step: 2
Training loss: 2.7221903463906454
Validation loss: 3.407288100276547

Epoch: 6| Step: 3
Training loss: 3.138527240755893
Validation loss: 3.4066207336276033

Epoch: 6| Step: 4
Training loss: 4.020204063284502
Validation loss: 3.4049222815284717

Epoch: 6| Step: 5
Training loss: 4.600099081547983
Validation loss: 3.4048017237944683

Epoch: 6| Step: 6
Training loss: 3.7660890665244002
Validation loss: 3.4039853483394493

Epoch: 6| Step: 7
Training loss: 3.812472233905679
Validation loss: 3.4034921756880667

Epoch: 6| Step: 8
Training loss: 2.2479802709236383
Validation loss: 3.4026659808957493

Epoch: 6| Step: 9
Training loss: 3.6288408123641207
Validation loss: 3.4026183100966017

Epoch: 6| Step: 10
Training loss: 4.0798499891341455
Validation loss: 3.4026542184638786

Epoch: 6| Step: 11
Training loss: 2.9250935661805153
Validation loss: 3.4013267628379915

Epoch: 6| Step: 12
Training loss: 3.569518687609556
Validation loss: 3.4055704682910197

Epoch: 6| Step: 13
Training loss: 3.834075164885936
Validation loss: 3.4037066911935687

Epoch: 32| Step: 0
Training loss: 3.33789833920627
Validation loss: 3.4049250711030576

Epoch: 6| Step: 1
Training loss: 4.158234316170005
Validation loss: 3.4014670102534166

Epoch: 6| Step: 2
Training loss: 3.652005070777874
Validation loss: 3.401937352131721

Epoch: 6| Step: 3
Training loss: 2.933922394935973
Validation loss: 3.401275414669342

Epoch: 6| Step: 4
Training loss: 4.136467224485547
Validation loss: 3.3989860057136463

Epoch: 6| Step: 5
Training loss: 4.29987311065108
Validation loss: 3.3974849427241693

Epoch: 6| Step: 6
Training loss: 4.2234430277086465
Validation loss: 3.3988936300494643

Epoch: 6| Step: 7
Training loss: 3.597963599580158
Validation loss: 3.3966564904816403

Epoch: 6| Step: 8
Training loss: 2.9815978864907446
Validation loss: 3.397229874110598

Epoch: 6| Step: 9
Training loss: 2.7679973707407113
Validation loss: 3.3969939227989143

Epoch: 6| Step: 10
Training loss: 3.0966451950341716
Validation loss: 3.397009232186545

Epoch: 6| Step: 11
Training loss: 3.357502970179354
Validation loss: 3.395914158455951

Epoch: 6| Step: 12
Training loss: 3.942110299327068
Validation loss: 3.396680598753644

Epoch: 6| Step: 13
Training loss: 3.9103253887229026
Validation loss: 3.3968284447896617

Epoch: 33| Step: 0
Training loss: 3.7458949190422888
Validation loss: 3.3952345318564885

Epoch: 6| Step: 1
Training loss: 3.431566423233773
Validation loss: 3.394700286673168

Epoch: 6| Step: 2
Training loss: 3.1748024345866352
Validation loss: 3.39368387352496

Epoch: 6| Step: 3
Training loss: 3.621369615764446
Validation loss: 3.391625912300958

Epoch: 6| Step: 4
Training loss: 3.0910648291412626
Validation loss: 3.393473787545216

Epoch: 6| Step: 5
Training loss: 3.393967066895593
Validation loss: 3.3945615344555957

Epoch: 6| Step: 6
Training loss: 3.813099298120129
Validation loss: 3.3923086000672757

Epoch: 6| Step: 7
Training loss: 3.5620119530178984
Validation loss: 3.394099044005527

Epoch: 6| Step: 8
Training loss: 3.5690742198423338
Validation loss: 3.3921195797785706

Epoch: 6| Step: 9
Training loss: 3.3988213684063977
Validation loss: 3.389701798100975

Epoch: 6| Step: 10
Training loss: 3.7081007866685334
Validation loss: 3.391319430996517

Epoch: 6| Step: 11
Training loss: 3.7321648222250188
Validation loss: 3.392580298281745

Epoch: 6| Step: 12
Training loss: 4.622303975943221
Validation loss: 3.3875356903514837

Epoch: 6| Step: 13
Training loss: 3.5573064860551415
Validation loss: 3.389820441767625

Epoch: 34| Step: 0
Training loss: 2.7721950273150364
Validation loss: 3.3885384563421015

Epoch: 6| Step: 1
Training loss: 4.076114787573408
Validation loss: 3.39002802416251

Epoch: 6| Step: 2
Training loss: 2.364505066325551
Validation loss: 3.388223568024568

Epoch: 6| Step: 3
Training loss: 3.9472354244113106
Validation loss: 3.3873992178407417

Epoch: 6| Step: 4
Training loss: 3.9951916643174137
Validation loss: 3.3884353459161667

Epoch: 6| Step: 5
Training loss: 4.273421432213851
Validation loss: 3.390606154991553

Epoch: 6| Step: 6
Training loss: 3.5421356937774595
Validation loss: 3.388081536016392

Epoch: 6| Step: 7
Training loss: 3.826587601840646
Validation loss: 3.3873043570948216

Epoch: 6| Step: 8
Training loss: 3.7180318699989816
Validation loss: 3.3892434854938975

Epoch: 6| Step: 9
Training loss: 1.9449691775902576
Validation loss: 3.387256510972585

Epoch: 6| Step: 10
Training loss: 3.505238291521231
Validation loss: 3.384460285858836

Epoch: 6| Step: 11
Training loss: 3.3757899737361243
Validation loss: 3.3873194847388706

Epoch: 6| Step: 12
Training loss: 4.174471957683783
Validation loss: 3.389692528842362

Epoch: 6| Step: 13
Training loss: 4.503987982373102
Validation loss: 3.389264375822129

Epoch: 35| Step: 0
Training loss: 2.9195008449589155
Validation loss: 3.3868760838371843

Epoch: 6| Step: 1
Training loss: 2.8290504922362327
Validation loss: 3.382514190764114

Epoch: 6| Step: 2
Training loss: 3.044540998067856
Validation loss: 3.3831211765737574

Epoch: 6| Step: 3
Training loss: 3.6193174348843744
Validation loss: 3.382728915709562

Epoch: 6| Step: 4
Training loss: 3.992696531805638
Validation loss: 3.3810872974160366

Epoch: 6| Step: 5
Training loss: 3.938114299992717
Validation loss: 3.381579736261927

Epoch: 6| Step: 6
Training loss: 3.4248548101015728
Validation loss: 3.3806193766854866

Epoch: 6| Step: 7
Training loss: 3.9798618261994534
Validation loss: 3.3818312519167733

Epoch: 6| Step: 8
Training loss: 3.180054889421163
Validation loss: 3.376564055420799

Epoch: 6| Step: 9
Training loss: 4.630634072308143
Validation loss: 3.380467154271197

Epoch: 6| Step: 10
Training loss: 3.896272168798593
Validation loss: 3.3760001957637726

Epoch: 6| Step: 11
Training loss: 3.626796671790513
Validation loss: 3.3775429482868473

Epoch: 6| Step: 12
Training loss: 3.531178701575571
Validation loss: 3.376148663429467

Epoch: 6| Step: 13
Training loss: 3.3639257081635954
Validation loss: 3.3777598282562526

Epoch: 36| Step: 0
Training loss: 3.7605891447939888
Validation loss: 3.3750102894883294

Epoch: 6| Step: 1
Training loss: 3.208087482363071
Validation loss: 3.3752460002688216

Epoch: 6| Step: 2
Training loss: 4.280218515254808
Validation loss: 3.3751907469437366

Epoch: 6| Step: 3
Training loss: 2.883689850244784
Validation loss: 3.3745023055855943

Epoch: 6| Step: 4
Training loss: 3.302763250169458
Validation loss: 3.3768523817259233

Epoch: 6| Step: 5
Training loss: 4.055466887551344
Validation loss: 3.376991327127653

Epoch: 6| Step: 6
Training loss: 3.1346947397554032
Validation loss: 3.3771388676096117

Epoch: 6| Step: 7
Training loss: 3.674450040395873
Validation loss: 3.3813260691497025

Epoch: 6| Step: 8
Training loss: 3.5036407336080786
Validation loss: 3.3817458452035

Epoch: 6| Step: 9
Training loss: 3.574164585057479
Validation loss: 3.3751519859058314

Epoch: 6| Step: 10
Training loss: 3.1320687264883396
Validation loss: 3.371788064336097

Epoch: 6| Step: 11
Training loss: 3.665301603472951
Validation loss: 3.3713982587781137

Epoch: 6| Step: 12
Training loss: 3.7662246669825077
Validation loss: 3.3709868251807746

Epoch: 6| Step: 13
Training loss: 4.585953720557983
Validation loss: 3.370867956695976

Epoch: 37| Step: 0
Training loss: 2.777346239477831
Validation loss: 3.3715089085976815

Epoch: 6| Step: 1
Training loss: 3.8204841185170904
Validation loss: 3.3714409706653754

Epoch: 6| Step: 2
Training loss: 3.5693675988250346
Validation loss: 3.372023877192802

Epoch: 6| Step: 3
Training loss: 3.196290852714897
Validation loss: 3.3735906133708142

Epoch: 6| Step: 4
Training loss: 3.8950736109152344
Validation loss: 3.371943701455388

Epoch: 6| Step: 5
Training loss: 4.311265409358561
Validation loss: 3.3745232233554128

Epoch: 6| Step: 6
Training loss: 3.3906019359454613
Validation loss: 3.3699189316580282

Epoch: 6| Step: 7
Training loss: 3.6777797540183648
Validation loss: 3.369114709546094

Epoch: 6| Step: 8
Training loss: 3.404391280335447
Validation loss: 3.36936112428824

Epoch: 6| Step: 9
Training loss: 3.5286085664064513
Validation loss: 3.3663590646960055

Epoch: 6| Step: 10
Training loss: 2.878871964104268
Validation loss: 3.365923271681172

Epoch: 6| Step: 11
Training loss: 3.381957053897092
Validation loss: 3.366754189966612

Epoch: 6| Step: 12
Training loss: 4.255825313941258
Validation loss: 3.365857225697007

Epoch: 6| Step: 13
Training loss: 4.10480596271945
Validation loss: 3.3649156450075077

Epoch: 38| Step: 0
Training loss: 3.5037701600522624
Validation loss: 3.3665339143917605

Epoch: 6| Step: 1
Training loss: 4.980719777681151
Validation loss: 3.366865865012074

Epoch: 6| Step: 2
Training loss: 3.5607185594407627
Validation loss: 3.3650099560275937

Epoch: 6| Step: 3
Training loss: 2.5251866942022665
Validation loss: 3.365154665240172

Epoch: 6| Step: 4
Training loss: 3.4248619107441423
Validation loss: 3.3627609676205306

Epoch: 6| Step: 5
Training loss: 3.1923949112171317
Validation loss: 3.362315534313791

Epoch: 6| Step: 6
Training loss: 3.63079068927939
Validation loss: 3.3628671507504895

Epoch: 6| Step: 7
Training loss: 3.616799912583777
Validation loss: 3.364793436727708

Epoch: 6| Step: 8
Training loss: 3.770525011696722
Validation loss: 3.3640357837797636

Epoch: 6| Step: 9
Training loss: 3.5461199120537454
Validation loss: 3.363286677172229

Epoch: 6| Step: 10
Training loss: 3.526677504909233
Validation loss: 3.362766564876494

Epoch: 6| Step: 11
Training loss: 3.811579859025456
Validation loss: 3.361870016061885

Epoch: 6| Step: 12
Training loss: 3.761061312860597
Validation loss: 3.3607779082079148

Epoch: 6| Step: 13
Training loss: 2.27623081657961
Validation loss: 3.3612363191345866

Epoch: 39| Step: 0
Training loss: 3.7168789812922705
Validation loss: 3.3603502472455573

Epoch: 6| Step: 1
Training loss: 3.705386987982887
Validation loss: 3.360753385248621

Epoch: 6| Step: 2
Training loss: 3.4746855394529583
Validation loss: 3.3619743164060045

Epoch: 6| Step: 3
Training loss: 4.240408452351429
Validation loss: 3.361744587215466

Epoch: 6| Step: 4
Training loss: 2.867503800992434
Validation loss: 3.3603275643657913

Epoch: 6| Step: 5
Training loss: 4.1720951322277395
Validation loss: 3.3605571188458527

Epoch: 6| Step: 6
Training loss: 3.6422223037503523
Validation loss: 3.3584713414182215

Epoch: 6| Step: 7
Training loss: 2.8233146433866567
Validation loss: 3.363250244823983

Epoch: 6| Step: 8
Training loss: 3.5789041129028627
Validation loss: 3.3652544758346665

Epoch: 6| Step: 9
Training loss: 3.351815594273518
Validation loss: 3.3600403562027625

Epoch: 6| Step: 10
Training loss: 3.1427155933458533
Validation loss: 3.3590245263674086

Epoch: 6| Step: 11
Training loss: 4.239937032555916
Validation loss: 3.3586379871787364

Epoch: 6| Step: 12
Training loss: 3.1664684802494993
Validation loss: 3.355992547793884

Epoch: 6| Step: 13
Training loss: 3.826156296827335
Validation loss: 3.3555190678896567

Epoch: 40| Step: 0
Training loss: 4.034734594983061
Validation loss: 3.3555337245712455

Epoch: 6| Step: 1
Training loss: 4.023383693890827
Validation loss: 3.352760673495383

Epoch: 6| Step: 2
Training loss: 3.771377664693115
Validation loss: 3.355722545862549

Epoch: 6| Step: 3
Training loss: 3.005648064575415
Validation loss: 3.3540358663430667

Epoch: 6| Step: 4
Training loss: 3.9270596828136406
Validation loss: 3.3516762629988124

Epoch: 6| Step: 5
Training loss: 3.4189821321389284
Validation loss: 3.35579148956484

Epoch: 6| Step: 6
Training loss: 3.6502597350630888
Validation loss: 3.3524923811361464

Epoch: 6| Step: 7
Training loss: 3.3247543244199296
Validation loss: 3.3509821484097584

Epoch: 6| Step: 8
Training loss: 4.382405144839489
Validation loss: 3.3485052968806435

Epoch: 6| Step: 9
Training loss: 2.7992786329732793
Validation loss: 3.349098357398487

Epoch: 6| Step: 10
Training loss: 3.5609962903769117
Validation loss: 3.3443747469565577

Epoch: 6| Step: 11
Training loss: 3.5304149889498344
Validation loss: 3.3428432242133916

Epoch: 6| Step: 12
Training loss: 3.268211107343448
Validation loss: 3.3408805427191735

Epoch: 6| Step: 13
Training loss: 2.6999196358482713
Validation loss: 3.3398489281782666

Epoch: 41| Step: 0
Training loss: 3.8966096862681976
Validation loss: 3.3417458165497105

Epoch: 6| Step: 1
Training loss: 3.538760679734856
Validation loss: 3.3444520744003485

Epoch: 6| Step: 2
Training loss: 4.071633269248109
Validation loss: 3.3427091137460354

Epoch: 6| Step: 3
Training loss: 3.072284715402783
Validation loss: 3.346054249232157

Epoch: 6| Step: 4
Training loss: 3.654132197067788
Validation loss: 3.3484407356435724

Epoch: 6| Step: 5
Training loss: 2.8636267897210534
Validation loss: 3.3360016546160938

Epoch: 6| Step: 6
Training loss: 3.6406483137833185
Validation loss: 3.33618641289463

Epoch: 6| Step: 7
Training loss: 2.8650895844678868
Validation loss: 3.3308903068289863

Epoch: 6| Step: 8
Training loss: 3.4285382059167944
Validation loss: 3.3318565163283846

Epoch: 6| Step: 9
Training loss: 3.5772106884854367
Validation loss: 3.3300925410673794

Epoch: 6| Step: 10
Training loss: 3.8333572442235044
Validation loss: 3.332331390436948

Epoch: 6| Step: 11
Training loss: 3.5699759226609507
Validation loss: 3.3398347829667046

Epoch: 6| Step: 12
Training loss: 3.729948221210337
Validation loss: 3.331847590892653

Epoch: 6| Step: 13
Training loss: 4.232698566174966
Validation loss: 3.332420396892531

Epoch: 42| Step: 0
Training loss: 3.6966965645996233
Validation loss: 3.3319053842040596

Epoch: 6| Step: 1
Training loss: 3.2097673720445226
Validation loss: 3.329780396082575

Epoch: 6| Step: 2
Training loss: 4.2824166372083265
Validation loss: 3.3287451997787447

Epoch: 6| Step: 3
Training loss: 2.740766455937319
Validation loss: 3.3305325944839947

Epoch: 6| Step: 4
Training loss: 2.724291536120776
Validation loss: 3.328753856278881

Epoch: 6| Step: 5
Training loss: 3.044811156231502
Validation loss: 3.3280729121918973

Epoch: 6| Step: 6
Training loss: 3.052127790073023
Validation loss: 3.3270560229055617

Epoch: 6| Step: 7
Training loss: 3.7263220623512567
Validation loss: 3.327041824074382

Epoch: 6| Step: 8
Training loss: 3.593467369575805
Validation loss: 3.326934344192363

Epoch: 6| Step: 9
Training loss: 3.8750473757893356
Validation loss: 3.3281768466643697

Epoch: 6| Step: 10
Training loss: 4.160605765400395
Validation loss: 3.327314137184096

Epoch: 6| Step: 11
Training loss: 3.179365362021894
Validation loss: 3.324379003235678

Epoch: 6| Step: 12
Training loss: 3.7101268645854093
Validation loss: 3.325292806958049

Epoch: 6| Step: 13
Training loss: 4.859284133306881
Validation loss: 3.3258822214199983

Epoch: 43| Step: 0
Training loss: 2.820219677694726
Validation loss: 3.3250947265676856

Epoch: 6| Step: 1
Training loss: 4.2436291684461676
Validation loss: 3.3210422798197956

Epoch: 6| Step: 2
Training loss: 3.2415632635130573
Validation loss: 3.3220251749845073

Epoch: 6| Step: 3
Training loss: 2.814608482928027
Validation loss: 3.322142665781281

Epoch: 6| Step: 4
Training loss: 3.5954332473153885
Validation loss: 3.321811444519

Epoch: 6| Step: 5
Training loss: 3.0581152530704285
Validation loss: 3.322923668307435

Epoch: 6| Step: 6
Training loss: 3.360337656175817
Validation loss: 3.320426538428456

Epoch: 6| Step: 7
Training loss: 4.114510116247632
Validation loss: 3.320596762642915

Epoch: 6| Step: 8
Training loss: 4.3995487848753365
Validation loss: 3.319281485090946

Epoch: 6| Step: 9
Training loss: 3.4160588972209225
Validation loss: 3.3209193339754215

Epoch: 6| Step: 10
Training loss: 3.309139346340824
Validation loss: 3.320047728895586

Epoch: 6| Step: 11
Training loss: 3.7015779378173748
Validation loss: 3.320191247452474

Epoch: 6| Step: 12
Training loss: 3.4750745696704852
Validation loss: 3.3178568513620044

Epoch: 6| Step: 13
Training loss: 3.9168971108895523
Validation loss: 3.3195603674895313

Epoch: 44| Step: 0
Training loss: 3.6011294023843803
Validation loss: 3.319999066397314

Epoch: 6| Step: 1
Training loss: 3.9486803240544437
Validation loss: 3.323229525263791

Epoch: 6| Step: 2
Training loss: 3.554690048719897
Validation loss: 3.322487026854607

Epoch: 6| Step: 3
Training loss: 3.3547439236419954
Validation loss: 3.318408905169349

Epoch: 6| Step: 4
Training loss: 3.68414852620781
Validation loss: 3.3144137070248387

Epoch: 6| Step: 5
Training loss: 3.617211755790704
Validation loss: 3.3152718937495345

Epoch: 6| Step: 6
Training loss: 4.289970927106607
Validation loss: 3.313654218090866

Epoch: 6| Step: 7
Training loss: 4.26348085276967
Validation loss: 3.3120616716477054

Epoch: 6| Step: 8
Training loss: 3.084225413860572
Validation loss: 3.311831239046927

Epoch: 6| Step: 9
Training loss: 3.007475915877386
Validation loss: 3.3146917514527834

Epoch: 6| Step: 10
Training loss: 2.7632967529207115
Validation loss: 3.312517839021142

Epoch: 6| Step: 11
Training loss: 2.5917822485987534
Validation loss: 3.313612840965953

Epoch: 6| Step: 12
Training loss: 3.654881800085362
Validation loss: 3.3107850551273676

Epoch: 6| Step: 13
Training loss: 4.002944101241127
Validation loss: 3.310943708473164

Epoch: 45| Step: 0
Training loss: 4.409256795249081
Validation loss: 3.311149351218468

Epoch: 6| Step: 1
Training loss: 3.449524257863803
Validation loss: 3.3137097153290425

Epoch: 6| Step: 2
Training loss: 3.502275000022307
Validation loss: 3.3127564826062463

Epoch: 6| Step: 3
Training loss: 3.4232129133440488
Validation loss: 3.3152887914683933

Epoch: 6| Step: 4
Training loss: 3.4767270852895455
Validation loss: 3.3135386854779876

Epoch: 6| Step: 5
Training loss: 3.3898019099241465
Validation loss: 3.313546714788283

Epoch: 6| Step: 6
Training loss: 3.5800945075576474
Validation loss: 3.3128432507945407

Epoch: 6| Step: 7
Training loss: 3.440363714152435
Validation loss: 3.3104321787257955

Epoch: 6| Step: 8
Training loss: 2.931368658270972
Validation loss: 3.310671040795262

Epoch: 6| Step: 9
Training loss: 4.892478323582897
Validation loss: 3.31471915970913

Epoch: 6| Step: 10
Training loss: 3.6268860744509053
Validation loss: 3.31026321460546

Epoch: 6| Step: 11
Training loss: 2.259358968717438
Validation loss: 3.3063819513253376

Epoch: 6| Step: 12
Training loss: 3.038295462730321
Validation loss: 3.3086411901960844

Epoch: 6| Step: 13
Training loss: 3.482156363660168
Validation loss: 3.321068757207273

Epoch: 46| Step: 0
Training loss: 4.2320460146906465
Validation loss: 3.324906878447649

Epoch: 6| Step: 1
Training loss: 3.5552492473374295
Validation loss: 3.305781431406711

Epoch: 6| Step: 2
Training loss: 3.615210369737293
Validation loss: 3.3058780459313

Epoch: 6| Step: 3
Training loss: 3.0195890472920928
Validation loss: 3.3083804489983417

Epoch: 6| Step: 4
Training loss: 4.7719452518670415
Validation loss: 3.3087907402145276

Epoch: 6| Step: 5
Training loss: 3.695456891132179
Validation loss: 3.309728833529034

Epoch: 6| Step: 6
Training loss: 2.9477435129667073
Validation loss: 3.308491323470928

Epoch: 6| Step: 7
Training loss: 3.180644123411942
Validation loss: 3.3102128546935083

Epoch: 6| Step: 8
Training loss: 3.9911954061356725
Validation loss: 3.3126502487646525

Epoch: 6| Step: 9
Training loss: 3.3810782623394644
Validation loss: 3.310527447150943

Epoch: 6| Step: 10
Training loss: 3.585294113118682
Validation loss: 3.3054181887285035

Epoch: 6| Step: 11
Training loss: 3.2767186438265923
Validation loss: 3.302310523664499

Epoch: 6| Step: 12
Training loss: 2.325431545774778
Validation loss: 3.303589738339054

Epoch: 6| Step: 13
Training loss: 3.189208376966972
Validation loss: 3.303615419734186

Epoch: 47| Step: 0
Training loss: 4.164613268644301
Validation loss: 3.3041672165284197

Epoch: 6| Step: 1
Training loss: 3.334039581503236
Validation loss: 3.3040754471503155

Epoch: 6| Step: 2
Training loss: 3.3201191924427
Validation loss: 3.303974991069085

Epoch: 6| Step: 3
Training loss: 3.422957575703134
Validation loss: 3.3036163850912508

Epoch: 6| Step: 4
Training loss: 3.46204559980186
Validation loss: 3.302065480900408

Epoch: 6| Step: 5
Training loss: 3.252975275733163
Validation loss: 3.303653288835181

Epoch: 6| Step: 6
Training loss: 3.332610496984215
Validation loss: 3.301349949095039

Epoch: 6| Step: 7
Training loss: 3.676908119645159
Validation loss: 3.3008981688737538

Epoch: 6| Step: 8
Training loss: 4.228204827637034
Validation loss: 3.300196856061764

Epoch: 6| Step: 9
Training loss: 3.5008091672411186
Validation loss: 3.302598071477148

Epoch: 6| Step: 10
Training loss: 3.610186068740465
Validation loss: 3.3012207802659312

Epoch: 6| Step: 11
Training loss: 3.419882276862415
Validation loss: 3.2962357578279993

Epoch: 6| Step: 12
Training loss: 3.1313649778899713
Validation loss: 3.295409640084906

Epoch: 6| Step: 13
Training loss: 3.3088200119099587
Validation loss: 3.2989562552680836

Epoch: 48| Step: 0
Training loss: 3.7011370896287517
Validation loss: 3.29751021235795

Epoch: 6| Step: 1
Training loss: 4.164155025062576
Validation loss: 3.2997365707180712

Epoch: 6| Step: 2
Training loss: 3.8882625408462133
Validation loss: 3.2973209202592573

Epoch: 6| Step: 3
Training loss: 3.39221632219086
Validation loss: 3.2955635143822084

Epoch: 6| Step: 4
Training loss: 3.8165544307370123
Validation loss: 3.294114287109838

Epoch: 6| Step: 5
Training loss: 3.8006344616920695
Validation loss: 3.2935707848794396

Epoch: 6| Step: 6
Training loss: 3.1856151318560983
Validation loss: 3.2945950884002055

Epoch: 6| Step: 7
Training loss: 3.245535498401877
Validation loss: 3.2932440416994213

Epoch: 6| Step: 8
Training loss: 2.7280351656775506
Validation loss: 3.2900902852147977

Epoch: 6| Step: 9
Training loss: 4.174626846541057
Validation loss: 3.2929423861075375

Epoch: 6| Step: 10
Training loss: 3.9134633106263004
Validation loss: 3.2918695631589205

Epoch: 6| Step: 11
Training loss: 2.9034341275937994
Validation loss: 3.290755581318446

Epoch: 6| Step: 12
Training loss: 3.018532887740758
Validation loss: 3.293376063378997

Epoch: 6| Step: 13
Training loss: 2.662874376365776
Validation loss: 3.2942279919730115

Epoch: 49| Step: 0
Training loss: 3.693274680083899
Validation loss: 3.2935909883778884

Epoch: 6| Step: 1
Training loss: 3.2012691424839037
Validation loss: 3.2928869390325994

Epoch: 6| Step: 2
Training loss: 2.9763061733464182
Validation loss: 3.293729348966422

Epoch: 6| Step: 3
Training loss: 3.6781863250416817
Validation loss: 3.291837457037395

Epoch: 6| Step: 4
Training loss: 3.300136598014052
Validation loss: 3.292150153253472

Epoch: 6| Step: 5
Training loss: 3.2272406135651304
Validation loss: 3.289773344871369

Epoch: 6| Step: 6
Training loss: 3.596129981071218
Validation loss: 3.2904347853114784

Epoch: 6| Step: 7
Training loss: 3.4484930257816595
Validation loss: 3.287739952248704

Epoch: 6| Step: 8
Training loss: 3.7978106315292424
Validation loss: 3.2895485317175512

Epoch: 6| Step: 9
Training loss: 3.915427938679649
Validation loss: 3.2905456318372712

Epoch: 6| Step: 10
Training loss: 4.3378141174027585
Validation loss: 3.289344306104856

Epoch: 6| Step: 11
Training loss: 2.7176802712089874
Validation loss: 3.2876295881660544

Epoch: 6| Step: 12
Training loss: 3.3391552310218153
Validation loss: 3.286707734072694

Epoch: 6| Step: 13
Training loss: 3.9331570849829234
Validation loss: 3.287557025353858

Epoch: 50| Step: 0
Training loss: 3.375376786286511
Validation loss: 3.285467799905528

Epoch: 6| Step: 1
Training loss: 3.498179779850624
Validation loss: 3.2945723154147157

Epoch: 6| Step: 2
Training loss: 3.020828106755087
Validation loss: 3.3089719943237754

Epoch: 6| Step: 3
Training loss: 3.805521848085343
Validation loss: 3.336009045819957

Epoch: 6| Step: 4
Training loss: 3.980841172814644
Validation loss: 3.3070207950797745

Epoch: 6| Step: 5
Training loss: 1.9513129411476164
Validation loss: 3.2847335926118024

Epoch: 6| Step: 6
Training loss: 4.072639371338274
Validation loss: 3.282824580811035

Epoch: 6| Step: 7
Training loss: 2.8563760341492004
Validation loss: 3.283056985312739

Epoch: 6| Step: 8
Training loss: 4.28875253248682
Validation loss: 3.2837468661155036

Epoch: 6| Step: 9
Training loss: 3.3703681810330774
Validation loss: 3.2891588261989

Epoch: 6| Step: 10
Training loss: 4.2188643828533055
Validation loss: 3.287521286874483

Epoch: 6| Step: 11
Training loss: 2.5135743686168075
Validation loss: 3.290746475849364

Epoch: 6| Step: 12
Training loss: 3.5597449909986447
Validation loss: 3.2871348731907495

Epoch: 6| Step: 13
Training loss: 4.225317018792999
Validation loss: 3.282634149787079

Epoch: 51| Step: 0
Training loss: 3.577487272377219
Validation loss: 3.282095670153406

Epoch: 6| Step: 1
Training loss: 3.460725868247332
Validation loss: 3.281320245931365

Epoch: 6| Step: 2
Training loss: 3.863703597600663
Validation loss: 3.277011671325086

Epoch: 6| Step: 3
Training loss: 3.145848726820178
Validation loss: 3.2772100921175276

Epoch: 6| Step: 4
Training loss: 3.4060629697075893
Validation loss: 3.2758869006965914

Epoch: 6| Step: 5
Training loss: 2.78842378029189
Validation loss: 3.278004029012469

Epoch: 6| Step: 6
Training loss: 4.2844177555591365
Validation loss: 3.2787100466285426

Epoch: 6| Step: 7
Training loss: 3.7253076771904206
Validation loss: 3.277444395018179

Epoch: 6| Step: 8
Training loss: 4.210535033744018
Validation loss: 3.280199675623682

Epoch: 6| Step: 9
Training loss: 3.2636008674389463
Validation loss: 3.2769874070928213

Epoch: 6| Step: 10
Training loss: 3.4080444648779102
Validation loss: 3.2767801352241435

Epoch: 6| Step: 11
Training loss: 3.222837648777235
Validation loss: 3.2769960626288395

Epoch: 6| Step: 12
Training loss: 2.863132863278553
Validation loss: 3.278575071364074

Epoch: 6| Step: 13
Training loss: 3.727927032100419
Validation loss: 3.2792500125236344

Epoch: 52| Step: 0
Training loss: 3.494459944709022
Validation loss: 3.277490120968272

Epoch: 6| Step: 1
Training loss: 2.7474268232047137
Validation loss: 3.279250060993778

Epoch: 6| Step: 2
Training loss: 3.3680342386276836
Validation loss: 3.275492654314739

Epoch: 6| Step: 3
Training loss: 3.5098755341113757
Validation loss: 3.2758923192698264

Epoch: 6| Step: 4
Training loss: 3.0881219399642994
Validation loss: 3.277020078805233

Epoch: 6| Step: 5
Training loss: 3.7932966033641176
Validation loss: 3.2757036249345313

Epoch: 6| Step: 6
Training loss: 3.4590333130625477
Validation loss: 3.272969397194648

Epoch: 6| Step: 7
Training loss: 3.3710878091452576
Validation loss: 3.276218727168733

Epoch: 6| Step: 8
Training loss: 2.9864450036398837
Validation loss: 3.2748927757873094

Epoch: 6| Step: 9
Training loss: 4.373434604154543
Validation loss: 3.274654272612198

Epoch: 6| Step: 10
Training loss: 3.8439747814419034
Validation loss: 3.2764980473602527

Epoch: 6| Step: 11
Training loss: 3.7694619286048203
Validation loss: 3.2754597615215975

Epoch: 6| Step: 12
Training loss: 3.667043550946868
Validation loss: 3.2719863689142783

Epoch: 6| Step: 13
Training loss: 3.1759285417584504
Validation loss: 3.2740811291735366

Epoch: 53| Step: 0
Training loss: 3.733338407671977
Validation loss: 3.271321206943656

Epoch: 6| Step: 1
Training loss: 3.885102178341932
Validation loss: 3.274762470230051

Epoch: 6| Step: 2
Training loss: 3.5844529347149368
Validation loss: 3.2724440223182083

Epoch: 6| Step: 3
Training loss: 3.0594046383786844
Validation loss: 3.2739944330783364

Epoch: 6| Step: 4
Training loss: 2.9635404152132865
Validation loss: 3.269148649365583

Epoch: 6| Step: 5
Training loss: 3.5567447955039224
Validation loss: 3.267754238743126

Epoch: 6| Step: 6
Training loss: 3.528651268686235
Validation loss: 3.267725110311606

Epoch: 6| Step: 7
Training loss: 3.819620455915233
Validation loss: 3.265954487495635

Epoch: 6| Step: 8
Training loss: 3.184354838568566
Validation loss: 3.266213607908408

Epoch: 6| Step: 9
Training loss: 3.994554627840842
Validation loss: 3.266018778151482

Epoch: 6| Step: 10
Training loss: 3.5080090576020146
Validation loss: 3.2656720736961837

Epoch: 6| Step: 11
Training loss: 3.2379478586674644
Validation loss: 3.2651557787410406

Epoch: 6| Step: 12
Training loss: 2.825903763144146
Validation loss: 3.2654567384104456

Epoch: 6| Step: 13
Training loss: 4.162412277076295
Validation loss: 3.2640180080628034

Epoch: 54| Step: 0
Training loss: 3.167120466007508
Validation loss: 3.2647317476319238

Epoch: 6| Step: 1
Training loss: 3.3041809992501414
Validation loss: 3.2638197828203297

Epoch: 6| Step: 2
Training loss: 2.7397807718549174
Validation loss: 3.26395873622882

Epoch: 6| Step: 3
Training loss: 3.859896481761467
Validation loss: 3.2635996215957843

Epoch: 6| Step: 4
Training loss: 3.2578249411951443
Validation loss: 3.2657974039862263

Epoch: 6| Step: 5
Training loss: 3.4236420549838877
Validation loss: 3.2614068541243886

Epoch: 6| Step: 6
Training loss: 4.5508235814823
Validation loss: 3.2646413888809445

Epoch: 6| Step: 7
Training loss: 4.129677634600872
Validation loss: 3.2624708572360324

Epoch: 6| Step: 8
Training loss: 2.0776723497789273
Validation loss: 3.261884675261412

Epoch: 6| Step: 9
Training loss: 3.182615539419257
Validation loss: 3.2603165900358673

Epoch: 6| Step: 10
Training loss: 3.7997083100248594
Validation loss: 3.2606206821769534

Epoch: 6| Step: 11
Training loss: 3.454904503392746
Validation loss: 3.260793831905724

Epoch: 6| Step: 12
Training loss: 4.005833187231563
Validation loss: 3.266126602508196

Epoch: 6| Step: 13
Training loss: 3.1777763903184306
Validation loss: 3.266930036515223

Epoch: 55| Step: 0
Training loss: 3.5822870959783075
Validation loss: 3.270388090419089

Epoch: 6| Step: 1
Training loss: 3.8234197855462257
Validation loss: 3.268777678778425

Epoch: 6| Step: 2
Training loss: 4.060016283650934
Validation loss: 3.2665138469642074

Epoch: 6| Step: 3
Training loss: 3.355295800757885
Validation loss: 3.2649280769838436

Epoch: 6| Step: 4
Training loss: 3.2373525578568523
Validation loss: 3.2578116343869317

Epoch: 6| Step: 5
Training loss: 3.2911878953891933
Validation loss: 3.2573052852954083

Epoch: 6| Step: 6
Training loss: 3.7895102324870455
Validation loss: 3.2571238651647674

Epoch: 6| Step: 7
Training loss: 2.610558795231043
Validation loss: 3.256198638636288

Epoch: 6| Step: 8
Training loss: 3.9573204484645843
Validation loss: 3.254203547725823

Epoch: 6| Step: 9
Training loss: 4.1210095148381685
Validation loss: 3.2548259703820026

Epoch: 6| Step: 10
Training loss: 2.140250959922166
Validation loss: 3.254967840683653

Epoch: 6| Step: 11
Training loss: 3.471261704575913
Validation loss: 3.2538802519087398

Epoch: 6| Step: 12
Training loss: 3.7644076457120983
Validation loss: 3.2538728600866995

Epoch: 6| Step: 13
Training loss: 2.855177670109702
Validation loss: 3.253321241907371

Epoch: 56| Step: 0
Training loss: 2.5309855005036606
Validation loss: 3.2530435898986885

Epoch: 6| Step: 1
Training loss: 4.137906315609117
Validation loss: 3.2515101477867794

Epoch: 6| Step: 2
Training loss: 3.101571263221641
Validation loss: 3.2522228423386945

Epoch: 6| Step: 3
Training loss: 2.966956309491537
Validation loss: 3.251961068291463

Epoch: 6| Step: 4
Training loss: 3.6744018950291553
Validation loss: 3.2515446373919463

Epoch: 6| Step: 5
Training loss: 4.173350555416887
Validation loss: 3.249834829508077

Epoch: 6| Step: 6
Training loss: 3.337505606314419
Validation loss: 3.2509634595022314

Epoch: 6| Step: 7
Training loss: 3.335381562053995
Validation loss: 3.248035897580159

Epoch: 6| Step: 8
Training loss: 3.775291350786744
Validation loss: 3.249956386264057

Epoch: 6| Step: 9
Training loss: 3.8353789441465413
Validation loss: 3.247271107563867

Epoch: 6| Step: 10
Training loss: 3.682872519572509
Validation loss: 3.2480226564324868

Epoch: 6| Step: 11
Training loss: 2.864875713801523
Validation loss: 3.2479123919465174

Epoch: 6| Step: 12
Training loss: 3.6686479388570095
Validation loss: 3.248249707490343

Epoch: 6| Step: 13
Training loss: 3.2359793549340026
Validation loss: 3.2482647400631417

Epoch: 57| Step: 0
Training loss: 2.932298803687797
Validation loss: 3.2576627093171324

Epoch: 6| Step: 1
Training loss: 1.9854311798088293
Validation loss: 3.2897629555504833

Epoch: 6| Step: 2
Training loss: 3.0989302604536415
Validation loss: 3.324782575008512

Epoch: 6| Step: 3
Training loss: 4.395224337705615
Validation loss: 3.2743935699970104

Epoch: 6| Step: 4
Training loss: 4.005087716312397
Validation loss: 3.2472736259893957

Epoch: 6| Step: 5
Training loss: 4.3144146635621565
Validation loss: 3.2448571961820503

Epoch: 6| Step: 6
Training loss: 2.7392256083779865
Validation loss: 3.287432213866604

Epoch: 6| Step: 7
Training loss: 3.984565520873853
Validation loss: 3.3724761194417017

Epoch: 6| Step: 8
Training loss: 2.5430280031019215
Validation loss: 3.267928645370359

Epoch: 6| Step: 9
Training loss: 3.389747752254373
Validation loss: 3.272147948607667

Epoch: 6| Step: 10
Training loss: 4.107825853885436
Validation loss: 3.2622519566380825

Epoch: 6| Step: 11
Training loss: 3.8146571326013876
Validation loss: 3.253679774893559

Epoch: 6| Step: 12
Training loss: 3.5455893988850202
Validation loss: 3.2538733643257864

Epoch: 6| Step: 13
Training loss: 3.1572486128598998
Validation loss: 3.2652318904011124

Epoch: 58| Step: 0
Training loss: 3.1277926364663946
Validation loss: 3.290539219896716

Epoch: 6| Step: 1
Training loss: 4.083825114212968
Validation loss: 3.2985918700702817

Epoch: 6| Step: 2
Training loss: 3.713229658048126
Validation loss: 3.2782740397750048

Epoch: 6| Step: 3
Training loss: 2.499074573895528
Validation loss: 3.246991867584655

Epoch: 6| Step: 4
Training loss: 3.551326294414786
Validation loss: 3.2396774212383375

Epoch: 6| Step: 5
Training loss: 3.6970022584321662
Validation loss: 3.2386517828243773

Epoch: 6| Step: 6
Training loss: 3.740379326703295
Validation loss: 3.240299123750197

Epoch: 6| Step: 7
Training loss: 2.9591629226246936
Validation loss: 3.238529409118477

Epoch: 6| Step: 8
Training loss: 3.5988975479285097
Validation loss: 3.239843096904724

Epoch: 6| Step: 9
Training loss: 4.250468508758218
Validation loss: 3.237715262290161

Epoch: 6| Step: 10
Training loss: 3.530778971627136
Validation loss: 3.242379724601368

Epoch: 6| Step: 11
Training loss: 3.5048568269707503
Validation loss: 3.2388565682719364

Epoch: 6| Step: 12
Training loss: 3.2725416610082547
Validation loss: 3.238901823480442

Epoch: 6| Step: 13
Training loss: 2.6320821501831015
Validation loss: 3.2352324364740834

Epoch: 59| Step: 0
Training loss: 3.2948183994292135
Validation loss: 3.2387311057338004

Epoch: 6| Step: 1
Training loss: 3.148467790254417
Validation loss: 3.2365649723943024

Epoch: 6| Step: 2
Training loss: 4.231677783432119
Validation loss: 3.2357865330293687

Epoch: 6| Step: 3
Training loss: 3.3755755463572488
Validation loss: 3.2371461994955846

Epoch: 6| Step: 4
Training loss: 3.6363580281040986
Validation loss: 3.236288591977994

Epoch: 6| Step: 5
Training loss: 3.186748640477157
Validation loss: 3.2351085735927207

Epoch: 6| Step: 6
Training loss: 3.0480233400407397
Validation loss: 3.234857666753725

Epoch: 6| Step: 7
Training loss: 2.9568627333401727
Validation loss: 3.233636695027955

Epoch: 6| Step: 8
Training loss: 2.7420559495633725
Validation loss: 3.2342132041220477

Epoch: 6| Step: 9
Training loss: 3.65667852515144
Validation loss: 3.235009624419146

Epoch: 6| Step: 10
Training loss: 4.192330833484258
Validation loss: 3.2428947933484866

Epoch: 6| Step: 11
Training loss: 3.8479157491014035
Validation loss: 3.2480757083093637

Epoch: 6| Step: 12
Training loss: 2.9719750805679044
Validation loss: 3.251601713478773

Epoch: 6| Step: 13
Training loss: 4.426700398956218
Validation loss: 3.24973995282166

Epoch: 60| Step: 0
Training loss: 3.2024505649536077
Validation loss: 3.2303232355962015

Epoch: 6| Step: 1
Training loss: 3.521435898602141
Validation loss: 3.2336257543119884

Epoch: 6| Step: 2
Training loss: 3.6276924394582757
Validation loss: 3.233956009679992

Epoch: 6| Step: 3
Training loss: 3.9170446551662397
Validation loss: 3.2363693479551063

Epoch: 6| Step: 4
Training loss: 3.573122083506946
Validation loss: 3.2412805215017606

Epoch: 6| Step: 5
Training loss: 3.189388089938982
Validation loss: 3.239361926398872

Epoch: 6| Step: 6
Training loss: 2.2588540812896882
Validation loss: 3.239014762050678

Epoch: 6| Step: 7
Training loss: 3.054960506951873
Validation loss: 3.2413074400552477

Epoch: 6| Step: 8
Training loss: 3.6840078337562265
Validation loss: 3.2379246777694144

Epoch: 6| Step: 9
Training loss: 3.9210295354795566
Validation loss: 3.2382310215014063

Epoch: 6| Step: 10
Training loss: 3.5818025439017402
Validation loss: 3.230733362129333

Epoch: 6| Step: 11
Training loss: 3.0722907684325547
Validation loss: 3.2250804747677555

Epoch: 6| Step: 12
Training loss: 4.2711570555030445
Validation loss: 3.2243940722344373

Epoch: 6| Step: 13
Training loss: 3.473395184230404
Validation loss: 3.223566204436293

Epoch: 61| Step: 0
Training loss: 3.7483090720968275
Validation loss: 3.2241661395372634

Epoch: 6| Step: 1
Training loss: 3.31175252290222
Validation loss: 3.224599187551173

Epoch: 6| Step: 2
Training loss: 2.7457684124771475
Validation loss: 3.2262473818184914

Epoch: 6| Step: 3
Training loss: 3.9697240400130362
Validation loss: 3.2281492717852402

Epoch: 6| Step: 4
Training loss: 3.3869427493595112
Validation loss: 3.2311477575456213

Epoch: 6| Step: 5
Training loss: 3.03675185672034
Validation loss: 3.225715457494254

Epoch: 6| Step: 6
Training loss: 3.515048509591336
Validation loss: 3.2226582037608122

Epoch: 6| Step: 7
Training loss: 3.434189329256925
Validation loss: 3.2229326953817212

Epoch: 6| Step: 8
Training loss: 4.1508055858735124
Validation loss: 3.223609320301999

Epoch: 6| Step: 9
Training loss: 3.6763831202255957
Validation loss: 3.225133691795542

Epoch: 6| Step: 10
Training loss: 3.6205593402005007
Validation loss: 3.222938778879867

Epoch: 6| Step: 11
Training loss: 2.795376509418139
Validation loss: 3.223706484958518

Epoch: 6| Step: 12
Training loss: 3.284621767887599
Validation loss: 3.222708154722117

Epoch: 6| Step: 13
Training loss: 3.668386027333032
Validation loss: 3.2209412678079428

Epoch: 62| Step: 0
Training loss: 3.6113136006502136
Validation loss: 3.2257298758349533

Epoch: 6| Step: 1
Training loss: 3.9057365385193603
Validation loss: 3.2207602159283213

Epoch: 6| Step: 2
Training loss: 3.021466068343055
Validation loss: 3.219583997672

Epoch: 6| Step: 3
Training loss: 3.8131760795109493
Validation loss: 3.2204610973847956

Epoch: 6| Step: 4
Training loss: 3.605329219478126
Validation loss: 3.2217315188331517

Epoch: 6| Step: 5
Training loss: 2.935540215135077
Validation loss: 3.2226627635921057

Epoch: 6| Step: 6
Training loss: 3.7131802176566095
Validation loss: 3.21990357692506

Epoch: 6| Step: 7
Training loss: 3.9343612513101216
Validation loss: 3.2186460843601825

Epoch: 6| Step: 8
Training loss: 3.5107288768871454
Validation loss: 3.216757360160972

Epoch: 6| Step: 9
Training loss: 3.284968566976395
Validation loss: 3.2173540589013534

Epoch: 6| Step: 10
Training loss: 3.039475753654841
Validation loss: 3.2155280924334466

Epoch: 6| Step: 11
Training loss: 3.180460018257481
Validation loss: 3.216765879697584

Epoch: 6| Step: 12
Training loss: 3.634077741909317
Validation loss: 3.216673080086843

Epoch: 6| Step: 13
Training loss: 2.695073921591127
Validation loss: 3.2128831668012534

Epoch: 63| Step: 0
Training loss: 2.422693815558229
Validation loss: 3.216574268351875

Epoch: 6| Step: 1
Training loss: 2.572275727990078
Validation loss: 3.2141560243654577

Epoch: 6| Step: 2
Training loss: 3.9740263940158314
Validation loss: 3.2150792457391626

Epoch: 6| Step: 3
Training loss: 3.8424970864338897
Validation loss: 3.218453885587147

Epoch: 6| Step: 4
Training loss: 4.129494963425201
Validation loss: 3.215999121888221

Epoch: 6| Step: 5
Training loss: 3.6717253958884917
Validation loss: 3.213657627488875

Epoch: 6| Step: 6
Training loss: 3.218764221752562
Validation loss: 3.2156126472724353

Epoch: 6| Step: 7
Training loss: 3.2122773208329165
Validation loss: 3.21568424731493

Epoch: 6| Step: 8
Training loss: 3.4237250635158887
Validation loss: 3.2146879346876767

Epoch: 6| Step: 9
Training loss: 3.6206607497992294
Validation loss: 3.2134828019469355

Epoch: 6| Step: 10
Training loss: 3.5169500269936456
Validation loss: 3.2148873169675825

Epoch: 6| Step: 11
Training loss: 3.54641438320693
Validation loss: 3.218453230827784

Epoch: 6| Step: 12
Training loss: 2.5886052595241766
Validation loss: 3.233779301496369

Epoch: 6| Step: 13
Training loss: 4.6038911947058905
Validation loss: 3.219554708539463

Epoch: 64| Step: 0
Training loss: 2.942135663419158
Validation loss: 3.2145931658740214

Epoch: 6| Step: 1
Training loss: 3.516957077280736
Validation loss: 3.2099797249267006

Epoch: 6| Step: 2
Training loss: 3.1334109222328883
Validation loss: 3.2092913563794476

Epoch: 6| Step: 3
Training loss: 2.848405820468462
Validation loss: 3.2090167820001967

Epoch: 6| Step: 4
Training loss: 3.0727470394235405
Validation loss: 3.2108038388007754

Epoch: 6| Step: 5
Training loss: 3.4553883587401284
Validation loss: 3.2154285670156537

Epoch: 6| Step: 6
Training loss: 3.956439050192198
Validation loss: 3.2132389060737347

Epoch: 6| Step: 7
Training loss: 3.5805442660594125
Validation loss: 3.2186552910511166

Epoch: 6| Step: 8
Training loss: 3.598718542270898
Validation loss: 3.210865653585307

Epoch: 6| Step: 9
Training loss: 3.818253350310291
Validation loss: 3.2116735804451495

Epoch: 6| Step: 10
Training loss: 3.5135485132857354
Validation loss: 3.2074843636367576

Epoch: 6| Step: 11
Training loss: 4.17389849905576
Validation loss: 3.2080172870649846

Epoch: 6| Step: 12
Training loss: 3.026521120591064
Validation loss: 3.2064457505130184

Epoch: 6| Step: 13
Training loss: 3.530752096267226
Validation loss: 3.205345033962811

Epoch: 65| Step: 0
Training loss: 3.2949589228059453
Validation loss: 3.2062612415074994

Epoch: 6| Step: 1
Training loss: 3.2137744557515866
Validation loss: 3.2073591985732968

Epoch: 6| Step: 2
Training loss: 3.0693755528086957
Validation loss: 3.2052439046317316

Epoch: 6| Step: 3
Training loss: 3.4447901323282575
Validation loss: 3.2048741264761724

Epoch: 6| Step: 4
Training loss: 3.944000448989069
Validation loss: 3.2055069665368494

Epoch: 6| Step: 5
Training loss: 3.250078053637532
Validation loss: 3.205616459995657

Epoch: 6| Step: 6
Training loss: 3.439207034646307
Validation loss: 3.209316648464504

Epoch: 6| Step: 7
Training loss: 3.634773758638804
Validation loss: 3.211937718457125

Epoch: 6| Step: 8
Training loss: 4.134705656154632
Validation loss: 3.2107862283157504

Epoch: 6| Step: 9
Training loss: 3.0777054708948635
Validation loss: 3.2156572513921615

Epoch: 6| Step: 10
Training loss: 3.8893737006365336
Validation loss: 3.2073687725685374

Epoch: 6| Step: 11
Training loss: 3.724408372837374
Validation loss: 3.20748746519597

Epoch: 6| Step: 12
Training loss: 3.0853318791112656
Validation loss: 3.2027275425118913

Epoch: 6| Step: 13
Training loss: 2.1806801343941435
Validation loss: 3.2016886053860225

Epoch: 66| Step: 0
Training loss: 3.8139574360705333
Validation loss: 3.2014994516581963

Epoch: 6| Step: 1
Training loss: 3.3419371351976075
Validation loss: 3.201287263389562

Epoch: 6| Step: 2
Training loss: 4.532240976295492
Validation loss: 3.200261669202032

Epoch: 6| Step: 3
Training loss: 3.0809003836658313
Validation loss: 3.2007039778844155

Epoch: 6| Step: 4
Training loss: 4.045374293792835
Validation loss: 3.2007756094720277

Epoch: 6| Step: 5
Training loss: 3.43423501060021
Validation loss: 3.199803979923965

Epoch: 6| Step: 6
Training loss: 3.376136023452334
Validation loss: 3.199070844487095

Epoch: 6| Step: 7
Training loss: 3.0308889586957566
Validation loss: 3.1993829614236344

Epoch: 6| Step: 8
Training loss: 2.98921841156449
Validation loss: 3.196917297386913

Epoch: 6| Step: 9
Training loss: 3.4615411856224885
Validation loss: 3.198138742183766

Epoch: 6| Step: 10
Training loss: 2.0738067505137896
Validation loss: 3.1973755193475606

Epoch: 6| Step: 11
Training loss: 3.1282639814631574
Validation loss: 3.19968109874741

Epoch: 6| Step: 12
Training loss: 3.6103291096813326
Validation loss: 3.197133278192158

Epoch: 6| Step: 13
Training loss: 3.968979235659429
Validation loss: 3.1971280877737867

Epoch: 67| Step: 0
Training loss: 3.479541659371498
Validation loss: 3.1957277999437874

Epoch: 6| Step: 1
Training loss: 2.9306451885221967
Validation loss: 3.195840843589634

Epoch: 6| Step: 2
Training loss: 2.846336278600346
Validation loss: 3.1958982984365227

Epoch: 6| Step: 3
Training loss: 3.533071132743908
Validation loss: 3.194845859963167

Epoch: 6| Step: 4
Training loss: 4.1297205877115175
Validation loss: 3.1963806878116015

Epoch: 6| Step: 5
Training loss: 2.7990945714501816
Validation loss: 3.195652006367257

Epoch: 6| Step: 6
Training loss: 3.568327838359547
Validation loss: 3.1952397165484268

Epoch: 6| Step: 7
Training loss: 3.8618726794977807
Validation loss: 3.196186202062135

Epoch: 6| Step: 8
Training loss: 3.192425232491948
Validation loss: 3.196514328145361

Epoch: 6| Step: 9
Training loss: 3.832208440730113
Validation loss: 3.1950346084264254

Epoch: 6| Step: 10
Training loss: 3.481243967705094
Validation loss: 3.1953217217718746

Epoch: 6| Step: 11
Training loss: 3.2143762000532465
Validation loss: 3.1947014080369183

Epoch: 6| Step: 12
Training loss: 3.288761804748715
Validation loss: 3.1937569965659733

Epoch: 6| Step: 13
Training loss: 3.900031549375031
Validation loss: 3.19536743068708

Epoch: 68| Step: 0
Training loss: 3.6521565272033913
Validation loss: 3.1948512346357756

Epoch: 6| Step: 1
Training loss: 3.116100762409139
Validation loss: 3.194381492788673

Epoch: 6| Step: 2
Training loss: 3.1564997205995473
Validation loss: 3.196211352411462

Epoch: 6| Step: 3
Training loss: 4.302963105302636
Validation loss: 3.1960709776291316

Epoch: 6| Step: 4
Training loss: 3.108350728849632
Validation loss: 3.1962056720239307

Epoch: 6| Step: 5
Training loss: 4.032504101045797
Validation loss: 3.1949394396013475

Epoch: 6| Step: 6
Training loss: 2.9758109197642226
Validation loss: 3.195244753579965

Epoch: 6| Step: 7
Training loss: 2.1995279152415317
Validation loss: 3.1958469786588446

Epoch: 6| Step: 8
Training loss: 3.866355359491564
Validation loss: 3.197039770787996

Epoch: 6| Step: 9
Training loss: 3.887570695142277
Validation loss: 3.1948245136450635

Epoch: 6| Step: 10
Training loss: 2.753595515907932
Validation loss: 3.1996877007731714

Epoch: 6| Step: 11
Training loss: 3.7101230088891755
Validation loss: 3.198092240800792

Epoch: 6| Step: 12
Training loss: 3.211072635823453
Validation loss: 3.19677599287282

Epoch: 6| Step: 13
Training loss: 3.7639770700808257
Validation loss: 3.1903301465187925

Epoch: 69| Step: 0
Training loss: 4.473733324188762
Validation loss: 3.188677192994866

Epoch: 6| Step: 1
Training loss: 3.850467549457633
Validation loss: 3.188163247575594

Epoch: 6| Step: 2
Training loss: 2.7892447446804556
Validation loss: 3.1873779675654843

Epoch: 6| Step: 3
Training loss: 3.5170149704498224
Validation loss: 3.186573552633259

Epoch: 6| Step: 4
Training loss: 3.0046663550368335
Validation loss: 3.1859861619905527

Epoch: 6| Step: 5
Training loss: 3.323360417471524
Validation loss: 3.1865636329694844

Epoch: 6| Step: 6
Training loss: 3.4690139257701893
Validation loss: 3.1828824948183194

Epoch: 6| Step: 7
Training loss: 3.2970408899596495
Validation loss: 3.1855064912581934

Epoch: 6| Step: 8
Training loss: 4.366126079924946
Validation loss: 3.1838627571555893

Epoch: 6| Step: 9
Training loss: 2.580579294625455
Validation loss: 3.1837343512159846

Epoch: 6| Step: 10
Training loss: 3.5098369508351457
Validation loss: 3.1816108503952623

Epoch: 6| Step: 11
Training loss: 3.1590615016050023
Validation loss: 3.181516896443686

Epoch: 6| Step: 12
Training loss: 2.624446265535569
Validation loss: 3.182529710769957

Epoch: 6| Step: 13
Training loss: 3.4662723799986215
Validation loss: 3.182548938038528

Epoch: 70| Step: 0
Training loss: 2.9384712074664567
Validation loss: 3.1809886688763958

Epoch: 6| Step: 1
Training loss: 2.9617062177219355
Validation loss: 3.1818772648627665

Epoch: 6| Step: 2
Training loss: 2.7980129548237134
Validation loss: 3.181590590096813

Epoch: 6| Step: 3
Training loss: 3.620523780317933
Validation loss: 3.1806404657226683

Epoch: 6| Step: 4
Training loss: 3.861364924979547
Validation loss: 3.1809876654986957

Epoch: 6| Step: 5
Training loss: 2.9714678721134513
Validation loss: 3.1801286266273476

Epoch: 6| Step: 6
Training loss: 4.308269249877886
Validation loss: 3.1789362713544502

Epoch: 6| Step: 7
Training loss: 3.2560175426488582
Validation loss: 3.1786693442433456

Epoch: 6| Step: 8
Training loss: 3.2293302104923303
Validation loss: 3.178850906279789

Epoch: 6| Step: 9
Training loss: 3.1187480184973038
Validation loss: 3.1820599522445767

Epoch: 6| Step: 10
Training loss: 3.514431763647986
Validation loss: 3.1803118610345065

Epoch: 6| Step: 11
Training loss: 3.231023996739251
Validation loss: 3.1785219972122984

Epoch: 6| Step: 12
Training loss: 3.950422003693173
Validation loss: 3.1772298605926172

Epoch: 6| Step: 13
Training loss: 4.09996341595959
Validation loss: 3.1793708144695176

Epoch: 71| Step: 0
Training loss: 3.0599673951350446
Validation loss: 3.1781282629376104

Epoch: 6| Step: 1
Training loss: 3.280254830719035
Validation loss: 3.1774372459808657

Epoch: 6| Step: 2
Training loss: 3.5918336485763662
Validation loss: 3.1765008148611575

Epoch: 6| Step: 3
Training loss: 3.468225525392331
Validation loss: 3.1760553389711474

Epoch: 6| Step: 4
Training loss: 3.9484938683541317
Validation loss: 3.1757809254865945

Epoch: 6| Step: 5
Training loss: 3.403721422067759
Validation loss: 3.175415311817374

Epoch: 6| Step: 6
Training loss: 4.082452925663539
Validation loss: 3.1744550905113234

Epoch: 6| Step: 7
Training loss: 3.121359879435283
Validation loss: 3.17535904616122

Epoch: 6| Step: 8
Training loss: 3.2013780249362807
Validation loss: 3.1741853393761508

Epoch: 6| Step: 9
Training loss: 2.926991109424639
Validation loss: 3.1738037342683554

Epoch: 6| Step: 10
Training loss: 3.506755848126462
Validation loss: 3.174513987100443

Epoch: 6| Step: 11
Training loss: 3.0883272985436125
Validation loss: 3.1724758867161804

Epoch: 6| Step: 12
Training loss: 3.5800930424539184
Validation loss: 3.1720614372181934

Epoch: 6| Step: 13
Training loss: 3.4567450280965213
Validation loss: 3.172913853271311

Epoch: 72| Step: 0
Training loss: 2.674190477182198
Validation loss: 3.1731046867939168

Epoch: 6| Step: 1
Training loss: 3.4271387870654006
Validation loss: 3.1717948343736575

Epoch: 6| Step: 2
Training loss: 3.169443636184695
Validation loss: 3.1732228893298933

Epoch: 6| Step: 3
Training loss: 3.7428166571354606
Validation loss: 3.171665738594888

Epoch: 6| Step: 4
Training loss: 3.5803579500997222
Validation loss: 3.1750361508898495

Epoch: 6| Step: 5
Training loss: 2.5596921470431315
Validation loss: 3.171430225912722

Epoch: 6| Step: 6
Training loss: 3.8893594790122474
Validation loss: 3.169570951648321

Epoch: 6| Step: 7
Training loss: 2.678813291256795
Validation loss: 3.1742072024703267

Epoch: 6| Step: 8
Training loss: 3.7799481128986487
Validation loss: 3.172223779009303

Epoch: 6| Step: 9
Training loss: 3.408191372651657
Validation loss: 3.1659794263011567

Epoch: 6| Step: 10
Training loss: 3.4372908095083923
Validation loss: 3.1693373322182765

Epoch: 6| Step: 11
Training loss: 3.6313158459364585
Validation loss: 3.1680451557103173

Epoch: 6| Step: 12
Training loss: 4.096653731108176
Validation loss: 3.168349028565172

Epoch: 6| Step: 13
Training loss: 3.282869647698382
Validation loss: 3.1676235717742296

Epoch: 73| Step: 0
Training loss: 3.098399358178941
Validation loss: 3.166915830860187

Epoch: 6| Step: 1
Training loss: 3.024962205887191
Validation loss: 3.16836140354121

Epoch: 6| Step: 2
Training loss: 3.3940961798199902
Validation loss: 3.170154526223307

Epoch: 6| Step: 3
Training loss: 3.353889280107895
Validation loss: 3.1673312474802557

Epoch: 6| Step: 4
Training loss: 4.1980807869431445
Validation loss: 3.171076426495495

Epoch: 6| Step: 5
Training loss: 3.829543617686471
Validation loss: 3.17391744407506

Epoch: 6| Step: 6
Training loss: 3.4866283298181537
Validation loss: 3.1727403274386066

Epoch: 6| Step: 7
Training loss: 3.4254847608123464
Validation loss: 3.1644236976403657

Epoch: 6| Step: 8
Training loss: 3.5230030544764768
Validation loss: 3.162796753797926

Epoch: 6| Step: 9
Training loss: 3.3443956553919705
Validation loss: 3.163166897650356

Epoch: 6| Step: 10
Training loss: 4.000182147647213
Validation loss: 3.162907770377439

Epoch: 6| Step: 11
Training loss: 3.371000675406172
Validation loss: 3.16246050050786

Epoch: 6| Step: 12
Training loss: 2.552178600375634
Validation loss: 3.160698024932353

Epoch: 6| Step: 13
Training loss: 2.2953420700754927
Validation loss: 3.1620530785086443

Epoch: 74| Step: 0
Training loss: 2.832842522539388
Validation loss: 3.1642058455105726

Epoch: 6| Step: 1
Training loss: 3.1139613692595356
Validation loss: 3.1627343399623102

Epoch: 6| Step: 2
Training loss: 3.4770155022193014
Validation loss: 3.1637810224752663

Epoch: 6| Step: 3
Training loss: 3.712842849672901
Validation loss: 3.1639918765206754

Epoch: 6| Step: 4
Training loss: 3.57130001109205
Validation loss: 3.1645658537533508

Epoch: 6| Step: 5
Training loss: 3.967778845484562
Validation loss: 3.1639342093276035

Epoch: 6| Step: 6
Training loss: 4.023267546091923
Validation loss: 3.1635951823427906

Epoch: 6| Step: 7
Training loss: 3.908979027177315
Validation loss: 3.161197056691007

Epoch: 6| Step: 8
Training loss: 3.6644968779867195
Validation loss: 3.161884812197556

Epoch: 6| Step: 9
Training loss: 3.1350719646851624
Validation loss: 3.1614739442866866

Epoch: 6| Step: 10
Training loss: 2.4120745822389495
Validation loss: 3.1599546954060416

Epoch: 6| Step: 11
Training loss: 2.889496619131972
Validation loss: 3.160015842576642

Epoch: 6| Step: 12
Training loss: 3.0741154460684843
Validation loss: 3.1592870927801204

Epoch: 6| Step: 13
Training loss: 3.612873710125016
Validation loss: 3.1580305475518564

Epoch: 75| Step: 0
Training loss: 3.8329443665131206
Validation loss: 3.158082905602399

Epoch: 6| Step: 1
Training loss: 2.758726492653284
Validation loss: 3.1564989815171907

Epoch: 6| Step: 2
Training loss: 3.616781059483525
Validation loss: 3.1561080687897602

Epoch: 6| Step: 3
Training loss: 3.4521447080513803
Validation loss: 3.155686193188276

Epoch: 6| Step: 4
Training loss: 3.260759735745683
Validation loss: 3.1545777229644516

Epoch: 6| Step: 5
Training loss: 3.0342656501843526
Validation loss: 3.1550881850620027

Epoch: 6| Step: 6
Training loss: 3.8329417540087958
Validation loss: 3.151957398857815

Epoch: 6| Step: 7
Training loss: 3.1491534836482993
Validation loss: 3.153196560513428

Epoch: 6| Step: 8
Training loss: 3.5893756283124016
Validation loss: 3.1548915243468367

Epoch: 6| Step: 9
Training loss: 4.699756721531142
Validation loss: 3.153707841208164

Epoch: 6| Step: 10
Training loss: 3.0288457085652194
Validation loss: 3.1520828033547237

Epoch: 6| Step: 11
Training loss: 3.483737767543334
Validation loss: 3.152251311501936

Epoch: 6| Step: 12
Training loss: 2.839974212798051
Validation loss: 3.151642613916356

Epoch: 6| Step: 13
Training loss: 1.518557906070745
Validation loss: 3.150854809369266

Epoch: 76| Step: 0
Training loss: 3.7000090934023073
Validation loss: 3.1513344504191796

Epoch: 6| Step: 1
Training loss: 3.852335699440863
Validation loss: 3.149208434720473

Epoch: 6| Step: 2
Training loss: 3.4867791746913834
Validation loss: 3.1496416241920486

Epoch: 6| Step: 3
Training loss: 3.807836713623901
Validation loss: 3.149159933541599

Epoch: 6| Step: 4
Training loss: 3.939098215451928
Validation loss: 3.1505340864329603

Epoch: 6| Step: 5
Training loss: 2.7122229790633328
Validation loss: 3.1509707809091534

Epoch: 6| Step: 6
Training loss: 3.488798745996031
Validation loss: 3.1482137127589778

Epoch: 6| Step: 7
Training loss: 3.3621139361462613
Validation loss: 3.1474963962094114

Epoch: 6| Step: 8
Training loss: 3.44317062128892
Validation loss: 3.149103782474954

Epoch: 6| Step: 9
Training loss: 3.178004463783236
Validation loss: 3.147317725340222

Epoch: 6| Step: 10
Training loss: 2.9680277698790887
Validation loss: 3.146299401952236

Epoch: 6| Step: 11
Training loss: 2.400327652182008
Validation loss: 3.146010906377402

Epoch: 6| Step: 12
Training loss: 2.9713573049026665
Validation loss: 3.144874681487668

Epoch: 6| Step: 13
Training loss: 4.236776311512557
Validation loss: 3.1475872704624406

Epoch: 77| Step: 0
Training loss: 3.025494804583382
Validation loss: 3.1476936883610622

Epoch: 6| Step: 1
Training loss: 3.2866589242664728
Validation loss: 3.147269326168669

Epoch: 6| Step: 2
Training loss: 3.5244472097274024
Validation loss: 3.147985352369844

Epoch: 6| Step: 3
Training loss: 3.5566246706894358
Validation loss: 3.1549260219527473

Epoch: 6| Step: 4
Training loss: 3.0824619470925247
Validation loss: 3.1558673991851145

Epoch: 6| Step: 5
Training loss: 3.8644577101916724
Validation loss: 3.1537637111457184

Epoch: 6| Step: 6
Training loss: 3.8407856745434676
Validation loss: 3.1546199898121627

Epoch: 6| Step: 7
Training loss: 3.0302358287526805
Validation loss: 3.151357500314156

Epoch: 6| Step: 8
Training loss: 3.3383097377126685
Validation loss: 3.153602652167193

Epoch: 6| Step: 9
Training loss: 2.920624327607489
Validation loss: 3.1462995420997943

Epoch: 6| Step: 10
Training loss: 2.9256303287385044
Validation loss: 3.1563952589322186

Epoch: 6| Step: 11
Training loss: 4.148677955454746
Validation loss: 3.170948696497077

Epoch: 6| Step: 12
Training loss: 3.5674774466472
Validation loss: 3.159283429839654

Epoch: 6| Step: 13
Training loss: 3.076789527525712
Validation loss: 3.139936341948766

Epoch: 78| Step: 0
Training loss: 3.034768019582094
Validation loss: 3.1432732771183134

Epoch: 6| Step: 1
Training loss: 3.612256109855174
Validation loss: 3.14267083823609

Epoch: 6| Step: 2
Training loss: 2.9374370162380052
Validation loss: 3.141338228424896

Epoch: 6| Step: 3
Training loss: 3.3772098229684357
Validation loss: 3.1445126797349334

Epoch: 6| Step: 4
Training loss: 3.6373947285628696
Validation loss: 3.146460301905414

Epoch: 6| Step: 5
Training loss: 3.6080819327954083
Validation loss: 3.1550877934168913

Epoch: 6| Step: 6
Training loss: 3.368308887370959
Validation loss: 3.164661197187399

Epoch: 6| Step: 7
Training loss: 3.471309782728418
Validation loss: 3.1591262439830814

Epoch: 6| Step: 8
Training loss: 3.2701014451089603
Validation loss: 3.150547668954549

Epoch: 6| Step: 9
Training loss: 3.943638693905831
Validation loss: 3.1403457818690383

Epoch: 6| Step: 10
Training loss: 2.862143588470101
Validation loss: 3.140593822709988

Epoch: 6| Step: 11
Training loss: 3.5135918057337476
Validation loss: 3.1376585125433945

Epoch: 6| Step: 12
Training loss: 3.4709667648794835
Validation loss: 3.137663547234346

Epoch: 6| Step: 13
Training loss: 3.3190652816066897
Validation loss: 3.1369916640628928

Epoch: 79| Step: 0
Training loss: 3.78767542668844
Validation loss: 3.1379786332014863

Epoch: 6| Step: 1
Training loss: 3.8768041779086673
Validation loss: 3.1399597318826316

Epoch: 6| Step: 2
Training loss: 4.140925788750561
Validation loss: 3.1436521589093305

Epoch: 6| Step: 3
Training loss: 3.1557906921369367
Validation loss: 3.1472477321011283

Epoch: 6| Step: 4
Training loss: 3.260406705375949
Validation loss: 3.146028486681534

Epoch: 6| Step: 5
Training loss: 3.3177270494509044
Validation loss: 3.146216774101942

Epoch: 6| Step: 6
Training loss: 3.737462383578536
Validation loss: 3.147192521155709

Epoch: 6| Step: 7
Training loss: 3.3760973241436396
Validation loss: 3.1471970249662755

Epoch: 6| Step: 8
Training loss: 3.1300855835740413
Validation loss: 3.143329298266735

Epoch: 6| Step: 9
Training loss: 3.514638262132742
Validation loss: 3.143356874581119

Epoch: 6| Step: 10
Training loss: 2.719297858099486
Validation loss: 3.140584879405511

Epoch: 6| Step: 11
Training loss: 3.357192355083814
Validation loss: 3.1358602990323194

Epoch: 6| Step: 12
Training loss: 2.6529633777217345
Validation loss: 3.1345758441423714

Epoch: 6| Step: 13
Training loss: 2.9824679208135065
Validation loss: 3.1326008345870537

Epoch: 80| Step: 0
Training loss: 3.695134422737502
Validation loss: 3.134054735584172

Epoch: 6| Step: 1
Training loss: 4.071263646965825
Validation loss: 3.1322149406957975

Epoch: 6| Step: 2
Training loss: 4.034866957805114
Validation loss: 3.1311594960903903

Epoch: 6| Step: 3
Training loss: 3.8059480995251755
Validation loss: 3.1303197934273608

Epoch: 6| Step: 4
Training loss: 3.12456188945548
Validation loss: 3.1310031876698408

Epoch: 6| Step: 5
Training loss: 3.33834944641318
Validation loss: 3.1342980346187925

Epoch: 6| Step: 6
Training loss: 3.6154111121372665
Validation loss: 3.131323815147216

Epoch: 6| Step: 7
Training loss: 2.3866252475035714
Validation loss: 3.130855926087414

Epoch: 6| Step: 8
Training loss: 2.592518525604596
Validation loss: 3.1328632091941153

Epoch: 6| Step: 9
Training loss: 2.162230890541348
Validation loss: 3.1306960502438117

Epoch: 6| Step: 10
Training loss: 2.7173706589619413
Validation loss: 3.1301747863674314

Epoch: 6| Step: 11
Training loss: 3.5952813907688217
Validation loss: 3.1294412928066375

Epoch: 6| Step: 12
Training loss: 3.584640900145453
Validation loss: 3.130373605900879

Epoch: 6| Step: 13
Training loss: 4.253156051129992
Validation loss: 3.130292583821865

Epoch: 81| Step: 0
Training loss: 3.1159549274441183
Validation loss: 3.130218331123408

Epoch: 6| Step: 1
Training loss: 2.723019284272877
Validation loss: 3.1267762646759056

Epoch: 6| Step: 2
Training loss: 3.5111668782158003
Validation loss: 3.1273270488896596

Epoch: 6| Step: 3
Training loss: 3.872284583841223
Validation loss: 3.1271019640567292

Epoch: 6| Step: 4
Training loss: 3.087055708698565
Validation loss: 3.1277735947051717

Epoch: 6| Step: 5
Training loss: 2.579177641549946
Validation loss: 3.127027735615182

Epoch: 6| Step: 6
Training loss: 3.1728012160806256
Validation loss: 3.1262960851302837

Epoch: 6| Step: 7
Training loss: 3.181231449575243
Validation loss: 3.129095831530629

Epoch: 6| Step: 8
Training loss: 3.226315394215082
Validation loss: 3.128990246055491

Epoch: 6| Step: 9
Training loss: 3.619779181516051
Validation loss: 3.127237097566733

Epoch: 6| Step: 10
Training loss: 4.191704759873399
Validation loss: 3.1290287177540836

Epoch: 6| Step: 11
Training loss: 3.6486868599541333
Validation loss: 3.136059915656559

Epoch: 6| Step: 12
Training loss: 3.358819392189849
Validation loss: 3.1371172761867987

Epoch: 6| Step: 13
Training loss: 3.90836710206974
Validation loss: 3.1314831489114483

Epoch: 82| Step: 0
Training loss: 2.805544156553908
Validation loss: 3.127047616503055

Epoch: 6| Step: 1
Training loss: 3.8628445369792086
Validation loss: 3.1227003828541613

Epoch: 6| Step: 2
Training loss: 3.309004180564326
Validation loss: 3.1235820908810505

Epoch: 6| Step: 3
Training loss: 3.731097582798295
Validation loss: 3.122922241881955

Epoch: 6| Step: 4
Training loss: 3.865157887539068
Validation loss: 3.1231159429155695

Epoch: 6| Step: 5
Training loss: 2.3602110537214953
Validation loss: 3.1207003015547854

Epoch: 6| Step: 6
Training loss: 3.493257840726458
Validation loss: 3.1220230558336213

Epoch: 6| Step: 7
Training loss: 3.6471564516902024
Validation loss: 3.121604467671002

Epoch: 6| Step: 8
Training loss: 3.4882290314015645
Validation loss: 3.1214992365496013

Epoch: 6| Step: 9
Training loss: 3.5293532146945434
Validation loss: 3.123596634313873

Epoch: 6| Step: 10
Training loss: 3.250899263828329
Validation loss: 3.122019956822375

Epoch: 6| Step: 11
Training loss: 3.1454001795850854
Validation loss: 3.122018044367954

Epoch: 6| Step: 12
Training loss: 2.754095409200585
Validation loss: 3.120834490748753

Epoch: 6| Step: 13
Training loss: 3.9532757756726897
Validation loss: 3.1194924779406934

Epoch: 83| Step: 0
Training loss: 3.74242207662
Validation loss: 3.1204227437380334

Epoch: 6| Step: 1
Training loss: 3.825398996523759
Validation loss: 3.12011143266629

Epoch: 6| Step: 2
Training loss: 3.656847000288706
Validation loss: 3.1194357279238307

Epoch: 6| Step: 3
Training loss: 2.7985727282832444
Validation loss: 3.118456444658525

Epoch: 6| Step: 4
Training loss: 3.3262214768945397
Validation loss: 3.1179863443315354

Epoch: 6| Step: 5
Training loss: 3.0726123378941725
Validation loss: 3.1173734899077097

Epoch: 6| Step: 6
Training loss: 3.968741229190296
Validation loss: 3.1168815879448077

Epoch: 6| Step: 7
Training loss: 3.4372490531181503
Validation loss: 3.1163577657508896

Epoch: 6| Step: 8
Training loss: 2.464462033078983
Validation loss: 3.119287865998438

Epoch: 6| Step: 9
Training loss: 2.856996641504906
Validation loss: 3.115028013500651

Epoch: 6| Step: 10
Training loss: 3.5850927484025346
Validation loss: 3.118187693033374

Epoch: 6| Step: 11
Training loss: 3.884670987134392
Validation loss: 3.115289521144732

Epoch: 6| Step: 12
Training loss: 3.247658986817015
Validation loss: 3.1177048865595065

Epoch: 6| Step: 13
Training loss: 2.556870767071898
Validation loss: 3.1163975500139105

Epoch: 84| Step: 0
Training loss: 3.8162119570952884
Validation loss: 3.120347454304075

Epoch: 6| Step: 1
Training loss: 4.124876078275905
Validation loss: 3.1182835123449517

Epoch: 6| Step: 2
Training loss: 2.7333914595525437
Validation loss: 3.117293702356334

Epoch: 6| Step: 3
Training loss: 3.1156794597798005
Validation loss: 3.1178452407988013

Epoch: 6| Step: 4
Training loss: 2.3530706594406197
Validation loss: 3.115720445776293

Epoch: 6| Step: 5
Training loss: 3.5138816749656185
Validation loss: 3.1169133305941368

Epoch: 6| Step: 6
Training loss: 3.123015880132702
Validation loss: 3.117481648040081

Epoch: 6| Step: 7
Training loss: 3.3294980078005385
Validation loss: 3.1123118364824283

Epoch: 6| Step: 8
Training loss: 3.4254148802810414
Validation loss: 3.1152912789058695

Epoch: 6| Step: 9
Training loss: 3.1001926731407683
Validation loss: 3.1104173484322195

Epoch: 6| Step: 10
Training loss: 3.603716754210863
Validation loss: 3.112042660485299

Epoch: 6| Step: 11
Training loss: 3.3436440424307894
Validation loss: 3.1128193228545196

Epoch: 6| Step: 12
Training loss: 3.456265639533586
Validation loss: 3.1124514875186655

Epoch: 6| Step: 13
Training loss: 3.9708360611278106
Validation loss: 3.1119950958488207

Epoch: 85| Step: 0
Training loss: 3.9788218377112035
Validation loss: 3.1114087906047394

Epoch: 6| Step: 1
Training loss: 3.267496257333283
Validation loss: 3.111056432143393

Epoch: 6| Step: 2
Training loss: 3.3067869907708816
Validation loss: 3.1109742823287485

Epoch: 6| Step: 3
Training loss: 2.8559970601812026
Validation loss: 3.1079037424197

Epoch: 6| Step: 4
Training loss: 3.291822711448908
Validation loss: 3.108695054961727

Epoch: 6| Step: 5
Training loss: 2.5767555992633375
Validation loss: 3.1085726801018647

Epoch: 6| Step: 6
Training loss: 3.828594692765502
Validation loss: 3.108796738134118

Epoch: 6| Step: 7
Training loss: 3.2658354038920794
Validation loss: 3.108418150527593

Epoch: 6| Step: 8
Training loss: 3.5774824739955897
Validation loss: 3.1080319266029384

Epoch: 6| Step: 9
Training loss: 3.3595001907087414
Validation loss: 3.1083308364205804

Epoch: 6| Step: 10
Training loss: 3.0825900307383436
Validation loss: 3.1067555949988335

Epoch: 6| Step: 11
Training loss: 3.027555751145459
Validation loss: 3.1075467791716713

Epoch: 6| Step: 12
Training loss: 4.221675960160568
Validation loss: 3.108319295470824

Epoch: 6| Step: 13
Training loss: 2.969176251780238
Validation loss: 3.1078288252949298

Epoch: 86| Step: 0
Training loss: 2.7379663044128835
Validation loss: 3.105363791037335

Epoch: 6| Step: 1
Training loss: 3.052033737526104
Validation loss: 3.1046772369237097

Epoch: 6| Step: 2
Training loss: 3.5647979820334785
Validation loss: 3.102791395584171

Epoch: 6| Step: 3
Training loss: 3.278177621308172
Validation loss: 3.1102793147294125

Epoch: 6| Step: 4
Training loss: 4.391207944786431
Validation loss: 3.108567311298666

Epoch: 6| Step: 5
Training loss: 3.6071077962895335
Validation loss: 3.1047814842163537

Epoch: 6| Step: 6
Training loss: 3.3692490358463796
Validation loss: 3.1040544530210754

Epoch: 6| Step: 7
Training loss: 3.7774674593560884
Validation loss: 3.104763011438411

Epoch: 6| Step: 8
Training loss: 3.634829381745368
Validation loss: 3.1037007756002306

Epoch: 6| Step: 9
Training loss: 3.510714615460228
Validation loss: 3.1012373109292484

Epoch: 6| Step: 10
Training loss: 3.0112625746347654
Validation loss: 3.1016473572298087

Epoch: 6| Step: 11
Training loss: 3.1424573421086652
Validation loss: 3.099797742863403

Epoch: 6| Step: 12
Training loss: 2.8840584065611528
Validation loss: 3.0993871557427886

Epoch: 6| Step: 13
Training loss: 2.0432754198904073
Validation loss: 3.099811921515749

Epoch: 87| Step: 0
Training loss: 3.6934639498845363
Validation loss: 3.0994564183841082

Epoch: 6| Step: 1
Training loss: 3.0685365311286574
Validation loss: 3.0992495621855993

Epoch: 6| Step: 2
Training loss: 3.131980271755947
Validation loss: 3.0977289154865537

Epoch: 6| Step: 3
Training loss: 3.1992947635772686
Validation loss: 3.0979542534777083

Epoch: 6| Step: 4
Training loss: 3.0505727386531003
Validation loss: 3.0986960773276704

Epoch: 6| Step: 5
Training loss: 3.966566311076987
Validation loss: 3.096796294588736

Epoch: 6| Step: 6
Training loss: 2.4471239686780506
Validation loss: 3.0982163731355423

Epoch: 6| Step: 7
Training loss: 3.6096952221992327
Validation loss: 3.09838012998312

Epoch: 6| Step: 8
Training loss: 3.264862847711627
Validation loss: 3.0968666590538376

Epoch: 6| Step: 9
Training loss: 3.4350913191960153
Validation loss: 3.0963053495274173

Epoch: 6| Step: 10
Training loss: 3.6240027798943037
Validation loss: 3.0957546871765893

Epoch: 6| Step: 11
Training loss: 3.294472926679475
Validation loss: 3.096283661667078

Epoch: 6| Step: 12
Training loss: 4.004090601701073
Validation loss: 3.0955358368242902

Epoch: 6| Step: 13
Training loss: 2.425525301639132
Validation loss: 3.0962068164984924

Epoch: 88| Step: 0
Training loss: 2.7559016796950053
Validation loss: 3.0941230894510654

Epoch: 6| Step: 1
Training loss: 3.4120480248580893
Validation loss: 3.0965013481035957

Epoch: 6| Step: 2
Training loss: 3.6901142745686073
Validation loss: 3.093198242903707

Epoch: 6| Step: 3
Training loss: 3.522655730206216
Validation loss: 3.0923706871281094

Epoch: 6| Step: 4
Training loss: 3.584979691920094
Validation loss: 3.0979801466877728

Epoch: 6| Step: 5
Training loss: 4.139752220442097
Validation loss: 3.0955002317859805

Epoch: 6| Step: 6
Training loss: 3.1984486753476298
Validation loss: 3.0930954750522432

Epoch: 6| Step: 7
Training loss: 3.411839649739159
Validation loss: 3.0915856968188336

Epoch: 6| Step: 8
Training loss: 2.389231356634368
Validation loss: 3.092485943787665

Epoch: 6| Step: 9
Training loss: 3.800753021919521
Validation loss: 3.093053311098838

Epoch: 6| Step: 10
Training loss: 3.4489349213894975
Validation loss: 3.0924805769002552

Epoch: 6| Step: 11
Training loss: 3.4051360662444417
Validation loss: 3.0917617708484393

Epoch: 6| Step: 12
Training loss: 2.610911025729782
Validation loss: 3.091099279376762

Epoch: 6| Step: 13
Training loss: 2.977314370980576
Validation loss: 3.091349156082258

Epoch: 89| Step: 0
Training loss: 2.966024332122904
Validation loss: 3.0914450692043247

Epoch: 6| Step: 1
Training loss: 2.8435883528490873
Validation loss: 3.0918770203571904

Epoch: 6| Step: 2
Training loss: 3.674904729944699
Validation loss: 3.091602415741678

Epoch: 6| Step: 3
Training loss: 3.1101625298228486
Validation loss: 3.0905773310008273

Epoch: 6| Step: 4
Training loss: 3.7034353134255684
Validation loss: 3.0923075913443996

Epoch: 6| Step: 5
Training loss: 3.5156610783739044
Validation loss: 3.089855911705744

Epoch: 6| Step: 6
Training loss: 3.248902355583079
Validation loss: 3.0889947499381596

Epoch: 6| Step: 7
Training loss: 2.7535787184715783
Validation loss: 3.08933034429213

Epoch: 6| Step: 8
Training loss: 2.9813685427595744
Validation loss: 3.0886305365111326

Epoch: 6| Step: 9
Training loss: 2.774327610794479
Validation loss: 3.0896842478434023

Epoch: 6| Step: 10
Training loss: 4.08252557563129
Validation loss: 3.0876791090816105

Epoch: 6| Step: 11
Training loss: 3.435697186832235
Validation loss: 3.0885265168535376

Epoch: 6| Step: 12
Training loss: 3.9107450943123343
Validation loss: 3.089086550966694

Epoch: 6| Step: 13
Training loss: 3.7370396767567637
Validation loss: 3.0883225752338848

Epoch: 90| Step: 0
Training loss: 2.1815407370681377
Validation loss: 3.0870794262152534

Epoch: 6| Step: 1
Training loss: 3.423229210844706
Validation loss: 3.0874239125665346

Epoch: 6| Step: 2
Training loss: 3.7049321782832556
Validation loss: 3.0852138025325058

Epoch: 6| Step: 3
Training loss: 2.82027107694433
Validation loss: 3.088144359230454

Epoch: 6| Step: 4
Training loss: 3.9905678884650904
Validation loss: 3.0871833094488212

Epoch: 6| Step: 5
Training loss: 2.8142872535806474
Validation loss: 3.087239664989233

Epoch: 6| Step: 6
Training loss: 3.1112605373132096
Validation loss: 3.084616840139544

Epoch: 6| Step: 7
Training loss: 3.152127737138873
Validation loss: 3.084182787427697

Epoch: 6| Step: 8
Training loss: 3.3703408754274617
Validation loss: 3.0848666211426883

Epoch: 6| Step: 9
Training loss: 4.077483027999985
Validation loss: 3.083117939532571

Epoch: 6| Step: 10
Training loss: 3.899117511771794
Validation loss: 3.082515812433006

Epoch: 6| Step: 11
Training loss: 3.517681418961589
Validation loss: 3.0823145471743962

Epoch: 6| Step: 12
Training loss: 3.268581822228269
Validation loss: 3.0823865638095422

Epoch: 6| Step: 13
Training loss: 2.671153724088601
Validation loss: 3.0821065571316177

Epoch: 91| Step: 0
Training loss: 2.760178456134801
Validation loss: 3.0824149597986885

Epoch: 6| Step: 1
Training loss: 3.940914792591413
Validation loss: 3.0806260122580147

Epoch: 6| Step: 2
Training loss: 3.091233279826616
Validation loss: 3.081422240686038

Epoch: 6| Step: 3
Training loss: 2.8288647437665504
Validation loss: 3.079974047065791

Epoch: 6| Step: 4
Training loss: 3.278929262078231
Validation loss: 3.0799087761994968

Epoch: 6| Step: 5
Training loss: 3.4776619190773674
Validation loss: 3.0804924908015066

Epoch: 6| Step: 6
Training loss: 3.5446835104089116
Validation loss: 3.0799946661659128

Epoch: 6| Step: 7
Training loss: 3.404386237980149
Validation loss: 3.0805450498995177

Epoch: 6| Step: 8
Training loss: 3.150639145207751
Validation loss: 3.078914451357659

Epoch: 6| Step: 9
Training loss: 2.939413056464864
Validation loss: 3.0785660232831003

Epoch: 6| Step: 10
Training loss: 3.4333515450695185
Validation loss: 3.0813404106845894

Epoch: 6| Step: 11
Training loss: 4.041932375848539
Validation loss: 3.0787914956461195

Epoch: 6| Step: 12
Training loss: 3.4265648044729766
Validation loss: 3.0786653823791594

Epoch: 6| Step: 13
Training loss: 3.1164961504741844
Validation loss: 3.07914072995743

Epoch: 92| Step: 0
Training loss: 3.1018790364589863
Validation loss: 3.0795138819305707

Epoch: 6| Step: 1
Training loss: 2.8236258109901002
Validation loss: 3.0767587749114726

Epoch: 6| Step: 2
Training loss: 3.604254719682085
Validation loss: 3.076311165761229

Epoch: 6| Step: 3
Training loss: 2.2606688913941673
Validation loss: 3.076388954567471

Epoch: 6| Step: 4
Training loss: 2.3374919503629257
Validation loss: 3.0760512515819656

Epoch: 6| Step: 5
Training loss: 3.985601857109051
Validation loss: 3.07548007794121

Epoch: 6| Step: 6
Training loss: 3.4326634454119986
Validation loss: 3.0772713788851727

Epoch: 6| Step: 7
Training loss: 3.8907235374381703
Validation loss: 3.0735408498723915

Epoch: 6| Step: 8
Training loss: 3.077784330618899
Validation loss: 3.0753464864494178

Epoch: 6| Step: 9
Training loss: 3.4835427149823976
Validation loss: 3.0747475874728534

Epoch: 6| Step: 10
Training loss: 4.10328670046535
Validation loss: 3.073912112081448

Epoch: 6| Step: 11
Training loss: 3.1048624850426774
Validation loss: 3.0752467150108695

Epoch: 6| Step: 12
Training loss: 3.747261573378139
Validation loss: 3.072609382617522

Epoch: 6| Step: 13
Training loss: 3.0108985031286886
Validation loss: 3.0728539834669295

Epoch: 93| Step: 0
Training loss: 2.8135579132850084
Validation loss: 3.074262571980857

Epoch: 6| Step: 1
Training loss: 3.4620188795398037
Validation loss: 3.0717509788713038

Epoch: 6| Step: 2
Training loss: 3.1352319673567606
Validation loss: 3.073798022192135

Epoch: 6| Step: 3
Training loss: 3.022356495570289
Validation loss: 3.0728872354445733

Epoch: 6| Step: 4
Training loss: 3.4927773201570016
Validation loss: 3.0715442699795856

Epoch: 6| Step: 5
Training loss: 3.302342369597313
Validation loss: 3.072308371716874

Epoch: 6| Step: 6
Training loss: 2.9759158736202935
Validation loss: 3.070934626838153

Epoch: 6| Step: 7
Training loss: 3.2970202084061713
Validation loss: 3.069170305225868

Epoch: 6| Step: 8
Training loss: 3.2110126421598455
Validation loss: 3.068637259260106

Epoch: 6| Step: 9
Training loss: 3.574082135367284
Validation loss: 3.069508311732072

Epoch: 6| Step: 10
Training loss: 3.645994099296779
Validation loss: 3.067673541303037

Epoch: 6| Step: 11
Training loss: 3.427278337273975
Validation loss: 3.0682818137566836

Epoch: 6| Step: 12
Training loss: 3.2767558974427407
Validation loss: 3.06876111470598

Epoch: 6| Step: 13
Training loss: 4.266841058346033
Validation loss: 3.0682167553810666

Epoch: 94| Step: 0
Training loss: 3.609192154121348
Validation loss: 3.0674087414615223

Epoch: 6| Step: 1
Training loss: 2.958279747992541
Validation loss: 3.066914092680755

Epoch: 6| Step: 2
Training loss: 3.3328953614197583
Validation loss: 3.0670017959709996

Epoch: 6| Step: 3
Training loss: 3.233167339927464
Validation loss: 3.0656029888505745

Epoch: 6| Step: 4
Training loss: 3.100214206308977
Validation loss: 3.067732288455025

Epoch: 6| Step: 5
Training loss: 3.2331114433943835
Validation loss: 3.067730759997047

Epoch: 6| Step: 6
Training loss: 3.3790657138130062
Validation loss: 3.0654484399569157

Epoch: 6| Step: 7
Training loss: 3.9186991565089087
Validation loss: 3.063514101252036

Epoch: 6| Step: 8
Training loss: 2.5785103249867416
Validation loss: 3.066748758446044

Epoch: 6| Step: 9
Training loss: 3.6691141341000466
Validation loss: 3.069886885175782

Epoch: 6| Step: 10
Training loss: 3.385813450180235
Validation loss: 3.06622969651631

Epoch: 6| Step: 11
Training loss: 2.9548359107917634
Validation loss: 3.068918977706618

Epoch: 6| Step: 12
Training loss: 3.4508732837635843
Validation loss: 3.0666116967921266

Epoch: 6| Step: 13
Training loss: 3.7759238318988584
Validation loss: 3.0697632939544124

Epoch: 95| Step: 0
Training loss: 3.6978874671033934
Validation loss: 3.0659022666179006

Epoch: 6| Step: 1
Training loss: 3.5138339078988645
Validation loss: 3.0646785841715043

Epoch: 6| Step: 2
Training loss: 3.9785620078527857
Validation loss: 3.0639349777687244

Epoch: 6| Step: 3
Training loss: 2.5961268002440785
Validation loss: 3.0618963678419

Epoch: 6| Step: 4
Training loss: 3.2595631677692234
Validation loss: 3.0598120748052233

Epoch: 6| Step: 5
Training loss: 3.518004972409914
Validation loss: 3.06179954248195

Epoch: 6| Step: 6
Training loss: 2.407895801051346
Validation loss: 3.060123326684092

Epoch: 6| Step: 7
Training loss: 4.704925902023354
Validation loss: 3.0602875771597864

Epoch: 6| Step: 8
Training loss: 3.2081720551087445
Validation loss: 3.0607706025042636

Epoch: 6| Step: 9
Training loss: 2.36903696863355
Validation loss: 3.0602175821433346

Epoch: 6| Step: 10
Training loss: 3.090483511221162
Validation loss: 3.059223934945784

Epoch: 6| Step: 11
Training loss: 3.18906199760377
Validation loss: 3.0610937741117215

Epoch: 6| Step: 12
Training loss: 3.0899857248513554
Validation loss: 3.0594732710767047

Epoch: 6| Step: 13
Training loss: 3.118102434160397
Validation loss: 3.061385955997268

Epoch: 96| Step: 0
Training loss: 2.990088939555992
Validation loss: 3.06044686233851

Epoch: 6| Step: 1
Training loss: 2.911870955615685
Validation loss: 3.0593264596148524

Epoch: 6| Step: 2
Training loss: 3.36897106683841
Validation loss: 3.059666199595217

Epoch: 6| Step: 3
Training loss: 2.843800470931327
Validation loss: 3.059334519252645

Epoch: 6| Step: 4
Training loss: 3.110617537931199
Validation loss: 3.0609933890353043

Epoch: 6| Step: 5
Training loss: 4.018619593377718
Validation loss: 3.0556123406312863

Epoch: 6| Step: 6
Training loss: 3.4951252368323766
Validation loss: 3.0570601919881026

Epoch: 6| Step: 7
Training loss: 3.4568447601535106
Validation loss: 3.056810555872757

Epoch: 6| Step: 8
Training loss: 3.637139088137813
Validation loss: 3.0592201991235055

Epoch: 6| Step: 9
Training loss: 3.3375897570481214
Validation loss: 3.0539702313025954

Epoch: 6| Step: 10
Training loss: 3.856741682513835
Validation loss: 3.055752501444105

Epoch: 6| Step: 11
Training loss: 3.278316676206279
Validation loss: 3.054800423778115

Epoch: 6| Step: 12
Training loss: 3.0815805315929796
Validation loss: 3.0572331241887007

Epoch: 6| Step: 13
Training loss: 2.5058287383040465
Validation loss: 3.0510212669636845

Epoch: 97| Step: 0
Training loss: 3.1358994189403537
Validation loss: 3.0537905301800174

Epoch: 6| Step: 1
Training loss: 3.3502149029024815
Validation loss: 3.0537845840340325

Epoch: 6| Step: 2
Training loss: 3.5967024906791387
Validation loss: 3.0556518788100497

Epoch: 6| Step: 3
Training loss: 3.489544920448948
Validation loss: 3.056100072722492

Epoch: 6| Step: 4
Training loss: 3.9747623348561745
Validation loss: 3.0604039080599508

Epoch: 6| Step: 5
Training loss: 3.2896142347324697
Validation loss: 3.0565770214657584

Epoch: 6| Step: 6
Training loss: 2.7611224921555024
Validation loss: 3.055651179936952

Epoch: 6| Step: 7
Training loss: 3.7581882090719096
Validation loss: 3.053529247297884

Epoch: 6| Step: 8
Training loss: 2.209043736423331
Validation loss: 3.052455891260632

Epoch: 6| Step: 9
Training loss: 2.864085169159809
Validation loss: 3.055697705407551

Epoch: 6| Step: 10
Training loss: 3.1354464068010914
Validation loss: 3.048810211244842

Epoch: 6| Step: 11
Training loss: 3.1842047918200866
Validation loss: 3.0487906274144208

Epoch: 6| Step: 12
Training loss: 3.66215468721967
Validation loss: 3.04690704286784

Epoch: 6| Step: 13
Training loss: 3.8988073628404702
Validation loss: 3.0502007082686164

Epoch: 98| Step: 0
Training loss: 2.982237364851662
Validation loss: 3.052210756877405

Epoch: 6| Step: 1
Training loss: 3.0271038526420226
Validation loss: 3.0544735648145895

Epoch: 6| Step: 2
Training loss: 3.0182117179693186
Validation loss: 3.0680835795986754

Epoch: 6| Step: 3
Training loss: 3.4005380036538972
Validation loss: 3.0641253002761863

Epoch: 6| Step: 4
Training loss: 3.870023300337326
Validation loss: 3.0560411472604256

Epoch: 6| Step: 5
Training loss: 3.5309959927916714
Validation loss: 3.0498283988196886

Epoch: 6| Step: 6
Training loss: 3.2955060530317417
Validation loss: 3.0492045964239303

Epoch: 6| Step: 7
Training loss: 3.375256140137463
Validation loss: 3.048240713557038

Epoch: 6| Step: 8
Training loss: 2.6327077239154764
Validation loss: 3.0447817536438553

Epoch: 6| Step: 9
Training loss: 3.7028825253965603
Validation loss: 3.042809601346175

Epoch: 6| Step: 10
Training loss: 3.510457220701666
Validation loss: 3.0465003739079393

Epoch: 6| Step: 11
Training loss: 3.1265660748706763
Validation loss: 3.0456655966503714

Epoch: 6| Step: 12
Training loss: 2.909439961397563
Validation loss: 3.044055608826458

Epoch: 6| Step: 13
Training loss: 4.153979606332248
Validation loss: 3.04298586409275

Epoch: 99| Step: 0
Training loss: 3.2304234345843
Validation loss: 3.0451596412776762

Epoch: 6| Step: 1
Training loss: 3.8670003209909285
Validation loss: 3.045805545199409

Epoch: 6| Step: 2
Training loss: 2.995506418047126
Validation loss: 3.0449323133506128

Epoch: 6| Step: 3
Training loss: 3.6045583317386805
Validation loss: 3.0444339377375127

Epoch: 6| Step: 4
Training loss: 3.834691484318814
Validation loss: 3.045281376346037

Epoch: 6| Step: 5
Training loss: 2.4187960834696676
Validation loss: 3.0439513376630933

Epoch: 6| Step: 6
Training loss: 3.2025187593218862
Validation loss: 3.041489545548259

Epoch: 6| Step: 7
Training loss: 3.193437917134263
Validation loss: 3.043523501227004

Epoch: 6| Step: 8
Training loss: 3.0658154349717526
Validation loss: 3.0408934620304806

Epoch: 6| Step: 9
Training loss: 3.046316868451589
Validation loss: 3.044016343647504

Epoch: 6| Step: 10
Training loss: 3.2750431028834766
Validation loss: 3.044334841622263

Epoch: 6| Step: 11
Training loss: 3.2811008964448756
Validation loss: 3.0424003766889016

Epoch: 6| Step: 12
Training loss: 3.2239456464099794
Validation loss: 3.0429857849000643

Epoch: 6| Step: 13
Training loss: 4.17907345263102
Validation loss: 3.040770395420126

Epoch: 100| Step: 0
Training loss: 3.596736297451928
Validation loss: 3.041279130207801

Epoch: 6| Step: 1
Training loss: 2.2761624185638363
Validation loss: 3.0414881893382044

Epoch: 6| Step: 2
Training loss: 3.614843016575528
Validation loss: 3.0414429401261693

Epoch: 6| Step: 3
Training loss: 3.23475696317031
Validation loss: 3.0387986743474995

Epoch: 6| Step: 4
Training loss: 3.443679664848959
Validation loss: 3.03966398018217

Epoch: 6| Step: 5
Training loss: 2.863420470055014
Validation loss: 3.039751955239252

Epoch: 6| Step: 6
Training loss: 3.1782025143033015
Validation loss: 3.039084724429152

Epoch: 6| Step: 7
Training loss: 2.4898536780081324
Validation loss: 3.0377449368002543

Epoch: 6| Step: 8
Training loss: 3.105429595124623
Validation loss: 3.040911655104362

Epoch: 6| Step: 9
Training loss: 3.3772298722632756
Validation loss: 3.0388659755255403

Epoch: 6| Step: 10
Training loss: 4.560325208745697
Validation loss: 3.0379820901204995

Epoch: 6| Step: 11
Training loss: 3.282456530408809
Validation loss: 3.0382214491777404

Epoch: 6| Step: 12
Training loss: 3.9277313399338722
Validation loss: 3.035178381403295

Epoch: 6| Step: 13
Training loss: 2.0127113041804656
Validation loss: 3.0383266645609024

Epoch: 101| Step: 0
Training loss: 3.459557527242719
Validation loss: 3.037390027101475

Epoch: 6| Step: 1
Training loss: 2.963760198079249
Validation loss: 3.0360127929178993

Epoch: 6| Step: 2
Training loss: 3.129889058837371
Validation loss: 3.03699569381239

Epoch: 6| Step: 3
Training loss: 2.8894078346943117
Validation loss: 3.0356257842749224

Epoch: 6| Step: 4
Training loss: 3.0981914351379594
Validation loss: 3.036414291092544

Epoch: 6| Step: 5
Training loss: 3.5649317422674964
Validation loss: 3.035658325068332

Epoch: 6| Step: 6
Training loss: 3.671162507752169
Validation loss: 3.036013999580055

Epoch: 6| Step: 7
Training loss: 2.8780600806586474
Validation loss: 3.0352400515037763

Epoch: 6| Step: 8
Training loss: 3.1800217511374855
Validation loss: 3.0345450125131284

Epoch: 6| Step: 9
Training loss: 3.3345335389105237
Validation loss: 3.0333062840657186

Epoch: 6| Step: 10
Training loss: 2.906430146571463
Validation loss: 3.0328641534262575

Epoch: 6| Step: 11
Training loss: 3.644944146124758
Validation loss: 3.0331547838278006

Epoch: 6| Step: 12
Training loss: 3.8300240924764686
Validation loss: 3.032349294441212

Epoch: 6| Step: 13
Training loss: 3.679005942428779
Validation loss: 3.0331051706747894

Epoch: 102| Step: 0
Training loss: 3.5692732819825674
Validation loss: 3.033505867999667

Epoch: 6| Step: 1
Training loss: 3.103394858313464
Validation loss: 3.031329598040877

Epoch: 6| Step: 2
Training loss: 2.487574598257703
Validation loss: 3.031957058638106

Epoch: 6| Step: 3
Training loss: 3.3994561433584747
Validation loss: 3.0328095457039996

Epoch: 6| Step: 4
Training loss: 3.0406195174948967
Validation loss: 3.029538453604641

Epoch: 6| Step: 5
Training loss: 3.4560153653898222
Validation loss: 3.031081844190806

Epoch: 6| Step: 6
Training loss: 2.652299703645224
Validation loss: 3.0282327723365303

Epoch: 6| Step: 7
Training loss: 2.810843933821352
Validation loss: 3.0271833276601816

Epoch: 6| Step: 8
Training loss: 3.702992883570851
Validation loss: 3.027792503607373

Epoch: 6| Step: 9
Training loss: 3.4275090070142866
Validation loss: 3.028380952342704

Epoch: 6| Step: 10
Training loss: 3.5244397685402244
Validation loss: 3.027503835287285

Epoch: 6| Step: 11
Training loss: 3.289669606046078
Validation loss: 3.026683932726708

Epoch: 6| Step: 12
Training loss: 3.968058127823499
Validation loss: 3.0278605100190283

Epoch: 6| Step: 13
Training loss: 3.555761288280387
Validation loss: 3.029377890223569

Epoch: 103| Step: 0
Training loss: 3.170199849179896
Validation loss: 3.0264929176447564

Epoch: 6| Step: 1
Training loss: 3.147365643191677
Validation loss: 3.0278892251661054

Epoch: 6| Step: 2
Training loss: 3.9229101509503375
Validation loss: 3.0282093465368174

Epoch: 6| Step: 3
Training loss: 3.5818946670900207
Validation loss: 3.0267519030626624

Epoch: 6| Step: 4
Training loss: 3.781556676613151
Validation loss: 3.028287988306153

Epoch: 6| Step: 5
Training loss: 3.9161076789367453
Validation loss: 3.026490010511277

Epoch: 6| Step: 6
Training loss: 3.4760268580954152
Validation loss: 3.030384878612836

Epoch: 6| Step: 7
Training loss: 2.589672146228393
Validation loss: 3.0306263857164626

Epoch: 6| Step: 8
Training loss: 3.6875729311180345
Validation loss: 3.0446127950333635

Epoch: 6| Step: 9
Training loss: 1.812710651126887
Validation loss: 3.031390223353611

Epoch: 6| Step: 10
Training loss: 3.040425051537787
Validation loss: 3.024918344307991

Epoch: 6| Step: 11
Training loss: 3.232301941458947
Validation loss: 3.023935147146556

Epoch: 6| Step: 12
Training loss: 3.494750582154573
Validation loss: 3.0217319960863125

Epoch: 6| Step: 13
Training loss: 1.9850502967707995
Validation loss: 3.022449330757501

Epoch: 104| Step: 0
Training loss: 3.6578322679326876
Validation loss: 3.0213068120388105

Epoch: 6| Step: 1
Training loss: 3.517748111089151
Validation loss: 3.0218093658790854

Epoch: 6| Step: 2
Training loss: 2.984434596560129
Validation loss: 3.022470873256877

Epoch: 6| Step: 3
Training loss: 3.7228227640159544
Validation loss: 3.022979454886194

Epoch: 6| Step: 4
Training loss: 3.190805703182415
Validation loss: 3.0239136540770275

Epoch: 6| Step: 5
Training loss: 3.279350094025426
Validation loss: 3.023565434381446

Epoch: 6| Step: 6
Training loss: 3.629636758752628
Validation loss: 3.0238340507319217

Epoch: 6| Step: 7
Training loss: 3.171614763079416
Validation loss: 3.024326095629665

Epoch: 6| Step: 8
Training loss: 3.4865837452244537
Validation loss: 3.0234666785677247

Epoch: 6| Step: 9
Training loss: 3.1947991068309465
Validation loss: 3.0236050821471006

Epoch: 6| Step: 10
Training loss: 3.939873479564178
Validation loss: 3.0217965570206626

Epoch: 6| Step: 11
Training loss: 2.565612577345553
Validation loss: 3.022881835859862

Epoch: 6| Step: 12
Training loss: 2.413190171735779
Validation loss: 3.023942650016285

Epoch: 6| Step: 13
Training loss: 2.765036913744353
Validation loss: 3.0216880570758367

Epoch: 105| Step: 0
Training loss: 3.977285982580514
Validation loss: 3.0209919639976626

Epoch: 6| Step: 1
Training loss: 3.820226375802608
Validation loss: 3.021985855866241

Epoch: 6| Step: 2
Training loss: 3.3917442619076685
Validation loss: 3.0206677644283277

Epoch: 6| Step: 3
Training loss: 3.2277865177925507
Validation loss: 3.0181679111810586

Epoch: 6| Step: 4
Training loss: 2.468333341953536
Validation loss: 3.0193671912208906

Epoch: 6| Step: 5
Training loss: 2.8434632544520326
Validation loss: 3.018687763853642

Epoch: 6| Step: 6
Training loss: 3.3352167212945742
Validation loss: 3.0216648698486748

Epoch: 6| Step: 7
Training loss: 3.579723284378921
Validation loss: 3.018776886927122

Epoch: 6| Step: 8
Training loss: 3.6055941244791425
Validation loss: 3.018738404602474

Epoch: 6| Step: 9
Training loss: 3.080629830305353
Validation loss: 3.0229571697208666

Epoch: 6| Step: 10
Training loss: 3.461009969878255
Validation loss: 3.019636168297676

Epoch: 6| Step: 11
Training loss: 3.2518371378057953
Validation loss: 3.014390222841668

Epoch: 6| Step: 12
Training loss: 2.641736219996705
Validation loss: 3.0155375792779204

Epoch: 6| Step: 13
Training loss: 2.7451994349949747
Validation loss: 3.013573869402465

Epoch: 106| Step: 0
Training loss: 3.2735174711013775
Validation loss: 3.0130963272392077

Epoch: 6| Step: 1
Training loss: 3.1523484391906726
Validation loss: 3.019647682276869

Epoch: 6| Step: 2
Training loss: 3.46962211574079
Validation loss: 3.01387516639423

Epoch: 6| Step: 3
Training loss: 3.558462163542048
Validation loss: 3.012097725849748

Epoch: 6| Step: 4
Training loss: 3.2310551361413884
Validation loss: 3.014808013217561

Epoch: 6| Step: 5
Training loss: 2.694811965242684
Validation loss: 3.013755108519811

Epoch: 6| Step: 6
Training loss: 3.9408390480129674
Validation loss: 3.012472669603158

Epoch: 6| Step: 7
Training loss: 3.8693491433274345
Validation loss: 3.0130421074428098

Epoch: 6| Step: 8
Training loss: 3.1720559956441425
Validation loss: 3.0115817852990574

Epoch: 6| Step: 9
Training loss: 3.2539625220224284
Validation loss: 3.0124444534245205

Epoch: 6| Step: 10
Training loss: 2.5255498872767848
Validation loss: 3.011486539659902

Epoch: 6| Step: 11
Training loss: 3.092504231258079
Validation loss: 3.0114056083790675

Epoch: 6| Step: 12
Training loss: 3.199159726447285
Validation loss: 3.0096649146471184

Epoch: 6| Step: 13
Training loss: 3.335335956449187
Validation loss: 3.0101240506738636

Epoch: 107| Step: 0
Training loss: 3.2641849536852585
Validation loss: 3.0094394629952226

Epoch: 6| Step: 1
Training loss: 3.5539372920577685
Validation loss: 3.009215340501991

Epoch: 6| Step: 2
Training loss: 3.4028283528485823
Validation loss: 3.0182736064814524

Epoch: 6| Step: 3
Training loss: 3.0106427240909177
Validation loss: 3.0190150258449644

Epoch: 6| Step: 4
Training loss: 3.683402419557143
Validation loss: 3.0184956677785935

Epoch: 6| Step: 5
Training loss: 3.173838040849895
Validation loss: 3.020539798131373

Epoch: 6| Step: 6
Training loss: 2.792693267254218
Validation loss: 3.029117979158385

Epoch: 6| Step: 7
Training loss: 4.080644669557674
Validation loss: 3.033836584750138

Epoch: 6| Step: 8
Training loss: 2.829891769981596
Validation loss: 3.0310377531483303

Epoch: 6| Step: 9
Training loss: 2.787087048104992
Validation loss: 3.0260452395588855

Epoch: 6| Step: 10
Training loss: 3.2357885248142124
Validation loss: 3.020096000555917

Epoch: 6| Step: 11
Training loss: 3.8659177602989088
Validation loss: 3.0109697868390954

Epoch: 6| Step: 12
Training loss: 2.6326965849853927
Validation loss: 3.0064533198571968

Epoch: 6| Step: 13
Training loss: 3.3809651535120406
Validation loss: 3.00563382213191

Epoch: 108| Step: 0
Training loss: 3.2249818490870483
Validation loss: 3.0062007877937975

Epoch: 6| Step: 1
Training loss: 3.1853148506280875
Validation loss: 3.006252734696581

Epoch: 6| Step: 2
Training loss: 2.7263179986406416
Validation loss: 3.0068475908701986

Epoch: 6| Step: 3
Training loss: 3.182182663935688
Validation loss: 3.007816478661094

Epoch: 6| Step: 4
Training loss: 3.8227496340205565
Validation loss: 3.0070816974079904

Epoch: 6| Step: 5
Training loss: 3.300432500529553
Validation loss: 3.0083049889299183

Epoch: 6| Step: 6
Training loss: 3.4431646663079483
Validation loss: 3.0085140983078613

Epoch: 6| Step: 7
Training loss: 3.50651407318359
Validation loss: 3.0067679347335554

Epoch: 6| Step: 8
Training loss: 3.5448357858003825
Validation loss: 3.005806601666093

Epoch: 6| Step: 9
Training loss: 3.0348589934472114
Validation loss: 3.0074599414342167

Epoch: 6| Step: 10
Training loss: 2.807982398121976
Validation loss: 3.0070354027278334

Epoch: 6| Step: 11
Training loss: 3.2271162024429527
Validation loss: 3.00752435014321

Epoch: 6| Step: 12
Training loss: 3.385629234487369
Validation loss: 3.0084844457938447

Epoch: 6| Step: 13
Training loss: 3.5063727807835585
Validation loss: 3.0083828386815843

Epoch: 109| Step: 0
Training loss: 3.2003757494619505
Validation loss: 3.0049951559878156

Epoch: 6| Step: 1
Training loss: 3.596602924572839
Validation loss: 3.0054163337338005

Epoch: 6| Step: 2
Training loss: 3.244106818476022
Validation loss: 3.006502542289251

Epoch: 6| Step: 3
Training loss: 3.155146037498793
Validation loss: 3.0070200960503413

Epoch: 6| Step: 4
Training loss: 2.4620372434227082
Validation loss: 3.0039911724726784

Epoch: 6| Step: 5
Training loss: 3.104869856756089
Validation loss: 3.0049996536667187

Epoch: 6| Step: 6
Training loss: 3.483587338496637
Validation loss: 3.006425430056736

Epoch: 6| Step: 7
Training loss: 2.9272186863421905
Validation loss: 3.0025946598094406

Epoch: 6| Step: 8
Training loss: 3.6477438289727915
Validation loss: 3.0046487496492142

Epoch: 6| Step: 9
Training loss: 2.869982944397972
Validation loss: 3.0052884994127678

Epoch: 6| Step: 10
Training loss: 3.3347849228349618
Validation loss: 3.0030918339878214

Epoch: 6| Step: 11
Training loss: 3.46771513477108
Validation loss: 3.0076790038348546

Epoch: 6| Step: 12
Training loss: 3.690245172269387
Validation loss: 3.010511179179609

Epoch: 6| Step: 13
Training loss: 3.67364848710204
Validation loss: 3.013931202539869

Epoch: 110| Step: 0
Training loss: 3.621318789570424
Validation loss: 3.0088786389540894

Epoch: 6| Step: 1
Training loss: 3.303387613963638
Validation loss: 3.008626216731643

Epoch: 6| Step: 2
Training loss: 2.6472350685187753
Validation loss: 3.0029007669732466

Epoch: 6| Step: 3
Training loss: 3.500823196605913
Validation loss: 2.998998690210038

Epoch: 6| Step: 4
Training loss: 2.9427905225950908
Validation loss: 3.0006892598597146

Epoch: 6| Step: 5
Training loss: 2.9011962593751903
Validation loss: 3.002079466024326

Epoch: 6| Step: 6
Training loss: 3.985453859758223
Validation loss: 3.0038982806074763

Epoch: 6| Step: 7
Training loss: 3.477384800048367
Validation loss: 2.999762725676

Epoch: 6| Step: 8
Training loss: 3.4862870927207203
Validation loss: 2.9994010293167963

Epoch: 6| Step: 9
Training loss: 3.4630091819542317
Validation loss: 2.9956604598454044

Epoch: 6| Step: 10
Training loss: 3.7295971556238223
Validation loss: 2.999681500307749

Epoch: 6| Step: 11
Training loss: 2.544740964676174
Validation loss: 2.998183498627825

Epoch: 6| Step: 12
Training loss: 2.343298601550612
Validation loss: 3.003125654379738

Epoch: 6| Step: 13
Training loss: 3.426659152941747
Validation loss: 3.0027640864820118

Epoch: 111| Step: 0
Training loss: 2.882812665406923
Validation loss: 3.0049130670464232

Epoch: 6| Step: 1
Training loss: 3.385220346871825
Validation loss: 2.998889739867662

Epoch: 6| Step: 2
Training loss: 3.3201927253212826
Validation loss: 3.00266427854181

Epoch: 6| Step: 3
Training loss: 3.2679197289029642
Validation loss: 3.0070304204358815

Epoch: 6| Step: 4
Training loss: 2.9758625158629
Validation loss: 3.003685184967667

Epoch: 6| Step: 5
Training loss: 3.2301761812990084
Validation loss: 2.9961406672377238

Epoch: 6| Step: 6
Training loss: 3.585242243500441
Validation loss: 2.9937013060942097

Epoch: 6| Step: 7
Training loss: 3.260936529052473
Validation loss: 2.9937139388664855

Epoch: 6| Step: 8
Training loss: 3.723957934968656
Validation loss: 2.992093549382399

Epoch: 6| Step: 9
Training loss: 3.231534881134394
Validation loss: 2.9946509583505674

Epoch: 6| Step: 10
Training loss: 3.1329360899484002
Validation loss: 2.9956540243369263

Epoch: 6| Step: 11
Training loss: 3.4942956488109056
Validation loss: 2.9938523221213575

Epoch: 6| Step: 12
Training loss: 3.429889368881112
Validation loss: 2.9933664462617737

Epoch: 6| Step: 13
Training loss: 2.2355916372214106
Validation loss: 2.9937662651392065

Epoch: 112| Step: 0
Training loss: 2.363109941815432
Validation loss: 2.9931650217782058

Epoch: 6| Step: 1
Training loss: 3.1279731340157038
Validation loss: 2.993378203455609

Epoch: 6| Step: 2
Training loss: 3.1212550803109935
Validation loss: 2.9936636575133786

Epoch: 6| Step: 3
Training loss: 3.086632449933332
Validation loss: 2.991216672925232

Epoch: 6| Step: 4
Training loss: 2.8567092225841715
Validation loss: 2.9907125528720333

Epoch: 6| Step: 5
Training loss: 3.8464916345011213
Validation loss: 2.985906506818509

Epoch: 6| Step: 6
Training loss: 3.0533363105170825
Validation loss: 2.992153753035019

Epoch: 6| Step: 7
Training loss: 4.123327436347842
Validation loss: 2.9937634341232893

Epoch: 6| Step: 8
Training loss: 3.466210337706673
Validation loss: 2.998064902239613

Epoch: 6| Step: 9
Training loss: 3.447729806744215
Validation loss: 2.9943136670335573

Epoch: 6| Step: 10
Training loss: 3.415680316501551
Validation loss: 2.998822143358767

Epoch: 6| Step: 11
Training loss: 2.900915027824363
Validation loss: 3.0007216489700785

Epoch: 6| Step: 12
Training loss: 3.552880802670678
Validation loss: 3.003161384854069

Epoch: 6| Step: 13
Training loss: 2.6265746343855447
Validation loss: 3.0018127563588037

Epoch: 113| Step: 0
Training loss: 3.4213777642441157
Validation loss: 2.99272802502112

Epoch: 6| Step: 1
Training loss: 3.5101677479015447
Validation loss: 2.987162363788331

Epoch: 6| Step: 2
Training loss: 3.2988178621158446
Validation loss: 2.9877198557036366

Epoch: 6| Step: 3
Training loss: 2.170571684002693
Validation loss: 2.9918423801710654

Epoch: 6| Step: 4
Training loss: 3.7873880048755364
Validation loss: 3.0089914739530346

Epoch: 6| Step: 5
Training loss: 3.918537193738053
Validation loss: 3.009707562401457

Epoch: 6| Step: 6
Training loss: 3.6814976348226924
Validation loss: 2.98969348745838

Epoch: 6| Step: 7
Training loss: 2.8641982126001704
Validation loss: 2.991673989695037

Epoch: 6| Step: 8
Training loss: 3.4104739256386254
Validation loss: 3.0282131434741246

Epoch: 6| Step: 9
Training loss: 3.1947629871123837
Validation loss: 3.1804893232287803

Epoch: 6| Step: 10
Training loss: 2.500704856690097
Validation loss: 3.1741305541781544

Epoch: 6| Step: 11
Training loss: 3.633004788467775
Validation loss: 3.088411181328789

Epoch: 6| Step: 12
Training loss: 3.082507271986255
Validation loss: 2.9905178634177214

Epoch: 6| Step: 13
Training loss: 3.0863831017284236
Validation loss: 2.981712453725354

Epoch: 114| Step: 0
Training loss: 3.5513449579183147
Validation loss: 2.984917485989596

Epoch: 6| Step: 1
Training loss: 3.174226837936564
Validation loss: 2.995103593429911

Epoch: 6| Step: 2
Training loss: 2.356020532256263
Validation loss: 3.0029702488463976

Epoch: 6| Step: 3
Training loss: 3.511162804036605
Validation loss: 3.0190313976937326

Epoch: 6| Step: 4
Training loss: 3.342049995436494
Validation loss: 2.993138968700723

Epoch: 6| Step: 5
Training loss: 3.437316612206928
Validation loss: 2.9903207110884873

Epoch: 6| Step: 6
Training loss: 2.6197670138483966
Validation loss: 2.989506655377126

Epoch: 6| Step: 7
Training loss: 3.129815473144552
Validation loss: 3.000683814224121

Epoch: 6| Step: 8
Training loss: 3.076472734543435
Validation loss: 3.013856173852964

Epoch: 6| Step: 9
Training loss: 3.2254490443627786
Validation loss: 3.023107019412634

Epoch: 6| Step: 10
Training loss: 3.410012223565799
Validation loss: 2.9927792557972777

Epoch: 6| Step: 11
Training loss: 3.3541420566453692
Validation loss: 2.982647768427519

Epoch: 6| Step: 12
Training loss: 3.8996192501737506
Validation loss: 2.9774199279431572

Epoch: 6| Step: 13
Training loss: 3.5033406255073283
Validation loss: 2.978313277922849

Epoch: 115| Step: 0
Training loss: 3.3445884152583663
Validation loss: 2.9789296695667113

Epoch: 6| Step: 1
Training loss: 2.7061623504047287
Validation loss: 2.9816428204004075

Epoch: 6| Step: 2
Training loss: 3.3639422928966787
Validation loss: 2.985977851417

Epoch: 6| Step: 3
Training loss: 2.518054428797018
Validation loss: 2.9828610949844254

Epoch: 6| Step: 4
Training loss: 3.8272103598827627
Validation loss: 2.973050506152526

Epoch: 6| Step: 5
Training loss: 3.866857649482311
Validation loss: 2.9766225595863514

Epoch: 6| Step: 6
Training loss: 3.2012347342630996
Validation loss: 2.9787612101017777

Epoch: 6| Step: 7
Training loss: 3.290310656829355
Validation loss: 2.986988565016563

Epoch: 6| Step: 8
Training loss: 2.693374157948689
Validation loss: 2.9920097201230424

Epoch: 6| Step: 9
Training loss: 3.9013924875978776
Validation loss: 3.004606236572769

Epoch: 6| Step: 10
Training loss: 3.335558688880736
Validation loss: 2.994265866697643

Epoch: 6| Step: 11
Training loss: 3.337593043026938
Validation loss: 2.982596593982054

Epoch: 6| Step: 12
Training loss: 2.8873473684421493
Validation loss: 2.983719481281497

Epoch: 6| Step: 13
Training loss: 2.7550395392265092
Validation loss: 2.9797239969077896

Epoch: 116| Step: 0
Training loss: 3.4161286899706265
Validation loss: 2.9779520987437436

Epoch: 6| Step: 1
Training loss: 3.3960471680761226
Validation loss: 2.977109135015531

Epoch: 6| Step: 2
Training loss: 3.84216945996108
Validation loss: 2.9747280412586723

Epoch: 6| Step: 3
Training loss: 3.804614683233825
Validation loss: 2.9723632671568745

Epoch: 6| Step: 4
Training loss: 3.2989755600934285
Validation loss: 2.972885425922404

Epoch: 6| Step: 5
Training loss: 3.465005313929767
Validation loss: 2.973314152618982

Epoch: 6| Step: 6
Training loss: 3.137193161751929
Validation loss: 2.972029197326584

Epoch: 6| Step: 7
Training loss: 2.6529438761250463
Validation loss: 2.9688984184535068

Epoch: 6| Step: 8
Training loss: 3.754526077210428
Validation loss: 2.9703321298671486

Epoch: 6| Step: 9
Training loss: 2.1910284740107286
Validation loss: 2.9726750193745777

Epoch: 6| Step: 10
Training loss: 2.7274096902499334
Validation loss: 2.9741166523813334

Epoch: 6| Step: 11
Training loss: 3.16523250093467
Validation loss: 2.9728146294801707

Epoch: 6| Step: 12
Training loss: 3.7618901262234314
Validation loss: 2.9736323081573346

Epoch: 6| Step: 13
Training loss: 1.4009914412825861
Validation loss: 2.971062889308906

Epoch: 117| Step: 0
Training loss: 2.8670577765698155
Validation loss: 2.972647720778951

Epoch: 6| Step: 1
Training loss: 3.798345210508887
Validation loss: 2.9767065827520187

Epoch: 6| Step: 2
Training loss: 3.234088534877829
Validation loss: 2.9736894276534205

Epoch: 6| Step: 3
Training loss: 4.12438590362629
Validation loss: 2.9683058107945195

Epoch: 6| Step: 4
Training loss: 3.883406349990996
Validation loss: 2.9715317875648113

Epoch: 6| Step: 5
Training loss: 3.2653490159808327
Validation loss: 2.964691492398591

Epoch: 6| Step: 6
Training loss: 3.2191458153170753
Validation loss: 2.968942670717357

Epoch: 6| Step: 7
Training loss: 1.8277889497113418
Validation loss: 2.968379524227485

Epoch: 6| Step: 8
Training loss: 2.8713812236501726
Validation loss: 2.966789391792744

Epoch: 6| Step: 9
Training loss: 3.175753172202524
Validation loss: 2.963843958780662

Epoch: 6| Step: 10
Training loss: 3.4032293802862816
Validation loss: 2.9660712254197796

Epoch: 6| Step: 11
Training loss: 3.8683345442187513
Validation loss: 2.96395289042802

Epoch: 6| Step: 12
Training loss: 2.2823824227373914
Validation loss: 2.9616389627569157

Epoch: 6| Step: 13
Training loss: 2.483624710893199
Validation loss: 2.9651639521903332

Epoch: 118| Step: 0
Training loss: 4.04928411114164
Validation loss: 2.9647604109852055

Epoch: 6| Step: 1
Training loss: 3.2753536470221842
Validation loss: 2.9632681181095037

Epoch: 6| Step: 2
Training loss: 3.7391063134463556
Validation loss: 2.967308479417524

Epoch: 6| Step: 3
Training loss: 3.3637741737815436
Validation loss: 2.9649736895103986

Epoch: 6| Step: 4
Training loss: 3.769506456362762
Validation loss: 2.969015794998071

Epoch: 6| Step: 5
Training loss: 2.7176913250037225
Validation loss: 2.9718640163706005

Epoch: 6| Step: 6
Training loss: 2.981030092585922
Validation loss: 2.9753202253774607

Epoch: 6| Step: 7
Training loss: 2.3698636781140467
Validation loss: 2.979664999595897

Epoch: 6| Step: 8
Training loss: 3.4138082937755
Validation loss: 2.9887647857007273

Epoch: 6| Step: 9
Training loss: 2.6431372615577606
Validation loss: 2.9933829892232087

Epoch: 6| Step: 10
Training loss: 2.9782549834730454
Validation loss: 2.9920563415382544

Epoch: 6| Step: 11
Training loss: 3.0360126637231124
Validation loss: 2.988943825572521

Epoch: 6| Step: 12
Training loss: 2.9900096806398175
Validation loss: 2.9871384923208595

Epoch: 6| Step: 13
Training loss: 4.044376972064187
Validation loss: 2.9688133487732165

Epoch: 119| Step: 0
Training loss: 2.996254808456261
Validation loss: 2.961169871931649

Epoch: 6| Step: 1
Training loss: 2.961357147352343
Validation loss: 2.9623976771175133

Epoch: 6| Step: 2
Training loss: 3.2828314466987307
Validation loss: 2.963140368840424

Epoch: 6| Step: 3
Training loss: 3.5270557983068707
Validation loss: 2.9735017158753876

Epoch: 6| Step: 4
Training loss: 2.114144140275638
Validation loss: 3.0293272936219307

Epoch: 6| Step: 5
Training loss: 3.529011109461908
Validation loss: 3.053180364009242

Epoch: 6| Step: 6
Training loss: 3.6187561456763175
Validation loss: 3.119965629049126

Epoch: 6| Step: 7
Training loss: 2.9628452405678676
Validation loss: 3.009358578888673

Epoch: 6| Step: 8
Training loss: 3.9559099241055424
Validation loss: 2.961828248643213

Epoch: 6| Step: 9
Training loss: 3.28951769508233
Validation loss: 2.9596253707333613

Epoch: 6| Step: 10
Training loss: 3.0892362708774295
Validation loss: 2.9596141022583553

Epoch: 6| Step: 11
Training loss: 2.496700684689585
Validation loss: 2.958251865056104

Epoch: 6| Step: 12
Training loss: 3.334799793645233
Validation loss: 2.9568838883999033

Epoch: 6| Step: 13
Training loss: 4.591466634631422
Validation loss: 2.964634467609315

Epoch: 120| Step: 0
Training loss: 3.2107257262698496
Validation loss: 2.976340863144863

Epoch: 6| Step: 1
Training loss: 3.9585336467184598
Validation loss: 2.974853696058167

Epoch: 6| Step: 2
Training loss: 2.665784173217838
Validation loss: 2.969644177179692

Epoch: 6| Step: 3
Training loss: 3.4860224229153847
Validation loss: 2.9631424816016914

Epoch: 6| Step: 4
Training loss: 3.6337545506541047
Validation loss: 2.9688062851410906

Epoch: 6| Step: 5
Training loss: 3.622453255361658
Validation loss: 2.9605101520697

Epoch: 6| Step: 6
Training loss: 2.5762098192452956
Validation loss: 2.9610185812559022

Epoch: 6| Step: 7
Training loss: 2.4990736198678762
Validation loss: 2.9525742953543825

Epoch: 6| Step: 8
Training loss: 3.487573088286836
Validation loss: 2.9598758872437387

Epoch: 6| Step: 9
Training loss: 3.1161133103243794
Validation loss: 2.953872603395878

Epoch: 6| Step: 10
Training loss: 2.614980376190018
Validation loss: 2.953459130087198

Epoch: 6| Step: 11
Training loss: 3.4404521403255424
Validation loss: 2.957472787113863

Epoch: 6| Step: 12
Training loss: 3.135935760482359
Validation loss: 2.9521813461379263

Epoch: 6| Step: 13
Training loss: 3.736035859501545
Validation loss: 2.9526598224823917

Epoch: 121| Step: 0
Training loss: 3.5466467157916566
Validation loss: 2.954573532609009

Epoch: 6| Step: 1
Training loss: 2.6998094279533187
Validation loss: 2.951734748729095

Epoch: 6| Step: 2
Training loss: 3.500465089686828
Validation loss: 2.95098359528006

Epoch: 6| Step: 3
Training loss: 2.930633798994025
Validation loss: 2.9537287121756504

Epoch: 6| Step: 4
Training loss: 2.9829513589420884
Validation loss: 2.9502662215981883

Epoch: 6| Step: 5
Training loss: 3.165720413442094
Validation loss: 2.954436325784568

Epoch: 6| Step: 6
Training loss: 3.107170205082047
Validation loss: 2.9517409377960577

Epoch: 6| Step: 7
Training loss: 3.54278288062444
Validation loss: 2.951292175085292

Epoch: 6| Step: 8
Training loss: 4.07196843002762
Validation loss: 2.9494848813501093

Epoch: 6| Step: 9
Training loss: 3.382623609947206
Validation loss: 2.9477592648579165

Epoch: 6| Step: 10
Training loss: 2.4220984571181496
Validation loss: 2.946712593389248

Epoch: 6| Step: 11
Training loss: 3.573416597999921
Validation loss: 2.946182184811926

Epoch: 6| Step: 12
Training loss: 3.2973912996389387
Validation loss: 2.9474854524419323

Epoch: 6| Step: 13
Training loss: 2.2459476854680687
Validation loss: 2.9451618928022167

Epoch: 122| Step: 0
Training loss: 3.1514380003471016
Validation loss: 2.946294580829444

Epoch: 6| Step: 1
Training loss: 2.7865118764326127
Validation loss: 2.94524239342721

Epoch: 6| Step: 2
Training loss: 4.003118491483902
Validation loss: 2.9447679866877543

Epoch: 6| Step: 3
Training loss: 3.3022685836348797
Validation loss: 2.9443959091354186

Epoch: 6| Step: 4
Training loss: 3.005007696919414
Validation loss: 2.941326493316326

Epoch: 6| Step: 5
Training loss: 3.886767087089504
Validation loss: 2.942555146727214

Epoch: 6| Step: 6
Training loss: 2.54771400159263
Validation loss: 2.941066630222795

Epoch: 6| Step: 7
Training loss: 2.4751478902385298
Validation loss: 2.9411702168336045

Epoch: 6| Step: 8
Training loss: 2.8088710685139877
Validation loss: 2.9442553250184287

Epoch: 6| Step: 9
Training loss: 3.669063189524092
Validation loss: 2.9475892596545874

Epoch: 6| Step: 10
Training loss: 3.6102114282125477
Validation loss: 2.9440893720930172

Epoch: 6| Step: 11
Training loss: 3.5432157083427995
Validation loss: 2.9407084634658514

Epoch: 6| Step: 12
Training loss: 2.9999202081877385
Validation loss: 2.939560275253634

Epoch: 6| Step: 13
Training loss: 2.8288556414409527
Validation loss: 2.9395755494719644

Epoch: 123| Step: 0
Training loss: 3.3810683901486382
Validation loss: 2.938885706015692

Epoch: 6| Step: 1
Training loss: 3.669501263774317
Validation loss: 2.9373613410782116

Epoch: 6| Step: 2
Training loss: 3.0892736244122596
Validation loss: 2.9386737898401236

Epoch: 6| Step: 3
Training loss: 3.946069021681825
Validation loss: 2.937625130925183

Epoch: 6| Step: 4
Training loss: 2.49337826207254
Validation loss: 2.936987825041322

Epoch: 6| Step: 5
Training loss: 2.8442127563902955
Validation loss: 2.9363241597957646

Epoch: 6| Step: 6
Training loss: 3.4511547422820352
Validation loss: 2.936502010044485

Epoch: 6| Step: 7
Training loss: 2.482826566086158
Validation loss: 2.936677367660541

Epoch: 6| Step: 8
Training loss: 2.655255928276447
Validation loss: 2.9379084819521615

Epoch: 6| Step: 9
Training loss: 3.957632036157248
Validation loss: 2.9353342880785895

Epoch: 6| Step: 10
Training loss: 3.4843279232385918
Validation loss: 2.936725222788411

Epoch: 6| Step: 11
Training loss: 3.449500481752162
Validation loss: 2.934047826103141

Epoch: 6| Step: 12
Training loss: 2.5753646407226154
Validation loss: 2.9378488246700307

Epoch: 6| Step: 13
Training loss: 3.076034688161204
Validation loss: 2.939322660848254

Epoch: 124| Step: 0
Training loss: 3.0107748133165764
Validation loss: 2.939437910324097

Epoch: 6| Step: 1
Training loss: 3.357737155244725
Validation loss: 2.9372199611668215

Epoch: 6| Step: 2
Training loss: 2.457965133593523
Validation loss: 2.9349796389367744

Epoch: 6| Step: 3
Training loss: 3.294055184805937
Validation loss: 2.9381256187851497

Epoch: 6| Step: 4
Training loss: 3.1246471968816687
Validation loss: 2.9422312354201225

Epoch: 6| Step: 5
Training loss: 2.946411575334418
Validation loss: 2.948314767850013

Epoch: 6| Step: 6
Training loss: 3.4107444579245723
Validation loss: 2.94838922019826

Epoch: 6| Step: 7
Training loss: 3.930728236083281
Validation loss: 2.937880774791846

Epoch: 6| Step: 8
Training loss: 3.63634530843104
Validation loss: 2.936724280865527

Epoch: 6| Step: 9
Training loss: 3.0144012023558924
Validation loss: 2.946250433904488

Epoch: 6| Step: 10
Training loss: 3.4204060785240684
Validation loss: 2.947766131932552

Epoch: 6| Step: 11
Training loss: 3.1210243876249053
Validation loss: 2.946798657775214

Epoch: 6| Step: 12
Training loss: 3.297887854451256
Validation loss: 2.941974796682135

Epoch: 6| Step: 13
Training loss: 2.594854740053624
Validation loss: 2.9369879114565323

Epoch: 125| Step: 0
Training loss: 3.384634606433519
Validation loss: 2.9376253892418713

Epoch: 6| Step: 1
Training loss: 3.11887002534337
Validation loss: 2.9380275066787487

Epoch: 6| Step: 2
Training loss: 3.595518522895735
Validation loss: 2.937917873810426

Epoch: 6| Step: 3
Training loss: 3.233418493689685
Validation loss: 2.9369581373382987

Epoch: 6| Step: 4
Training loss: 3.977779419565365
Validation loss: 2.9381318155782603

Epoch: 6| Step: 5
Training loss: 3.5518924665583755
Validation loss: 2.937381011500904

Epoch: 6| Step: 6
Training loss: 3.2029913153314773
Validation loss: 2.935173103607104

Epoch: 6| Step: 7
Training loss: 2.515562826774402
Validation loss: 2.9328062914081463

Epoch: 6| Step: 8
Training loss: 3.039420217138074
Validation loss: 2.9337734548987857

Epoch: 6| Step: 9
Training loss: 2.785462692972288
Validation loss: 2.9341785833320744

Epoch: 6| Step: 10
Training loss: 3.273186357646745
Validation loss: 2.9319589972184454

Epoch: 6| Step: 11
Training loss: 2.369466559498321
Validation loss: 2.931126103759793

Epoch: 6| Step: 12
Training loss: 3.8081895819202205
Validation loss: 2.931273758863652

Epoch: 6| Step: 13
Training loss: 2.5911841512687075
Validation loss: 2.9330378835518847

Epoch: 126| Step: 0
Training loss: 3.252119107062876
Validation loss: 2.9297096878360076

Epoch: 6| Step: 1
Training loss: 3.190354807862102
Validation loss: 2.9300965671234613

Epoch: 6| Step: 2
Training loss: 3.3578411060249036
Validation loss: 2.927930205283743

Epoch: 6| Step: 3
Training loss: 3.881124640020533
Validation loss: 2.9294737982795107

Epoch: 6| Step: 4
Training loss: 3.4651096246285427
Validation loss: 2.926608584931107

Epoch: 6| Step: 5
Training loss: 3.871119617487363
Validation loss: 2.926217552636961

Epoch: 6| Step: 6
Training loss: 2.8893233384207573
Validation loss: 2.928654230170716

Epoch: 6| Step: 7
Training loss: 2.8245103192227847
Validation loss: 2.925439854846266

Epoch: 6| Step: 8
Training loss: 3.0186791642686295
Validation loss: 2.9274323512672793

Epoch: 6| Step: 9
Training loss: 3.2019442731402896
Validation loss: 2.926163583017838

Epoch: 6| Step: 10
Training loss: 3.4586918350143203
Validation loss: 2.925850686447134

Epoch: 6| Step: 11
Training loss: 2.6039806960777674
Validation loss: 2.9236491012985666

Epoch: 6| Step: 12
Training loss: 2.69652956698558
Validation loss: 2.9243427161098574

Epoch: 6| Step: 13
Training loss: 2.9132712264027916
Validation loss: 2.9334845273447843

Epoch: 127| Step: 0
Training loss: 3.5055521115788064
Validation loss: 2.9365559904505223

Epoch: 6| Step: 1
Training loss: 3.369545095739435
Validation loss: 2.942924237350819

Epoch: 6| Step: 2
Training loss: 3.0509866213084775
Validation loss: 2.9546552388204486

Epoch: 6| Step: 3
Training loss: 2.884569909153012
Validation loss: 2.952501834475894

Epoch: 6| Step: 4
Training loss: 3.1023950492327548
Validation loss: 2.93145268597882

Epoch: 6| Step: 5
Training loss: 2.7855980992104206
Validation loss: 2.9231601600130603

Epoch: 6| Step: 6
Training loss: 3.9490813430441634
Validation loss: 2.9208764688599427

Epoch: 6| Step: 7
Training loss: 2.5560198468078044
Validation loss: 2.9204982909528776

Epoch: 6| Step: 8
Training loss: 2.7262030859211563
Validation loss: 2.920663166980125

Epoch: 6| Step: 9
Training loss: 3.36220498758479
Validation loss: 2.92338969082376

Epoch: 6| Step: 10
Training loss: 3.173546862537357
Validation loss: 2.9236037653600806

Epoch: 6| Step: 11
Training loss: 3.7020537682023384
Validation loss: 2.929472263318913

Epoch: 6| Step: 12
Training loss: 3.2119480594031575
Validation loss: 2.930726439537112

Epoch: 6| Step: 13
Training loss: 3.4440550293463685
Validation loss: 2.9330189514284064

Epoch: 128| Step: 0
Training loss: 2.9433193596421434
Validation loss: 2.9283330482403724

Epoch: 6| Step: 1
Training loss: 3.091788855209119
Validation loss: 2.9213116435965056

Epoch: 6| Step: 2
Training loss: 2.815472452008941
Validation loss: 2.921192289695736

Epoch: 6| Step: 3
Training loss: 3.215616126460667
Validation loss: 2.92083777451224

Epoch: 6| Step: 4
Training loss: 3.2907009076151095
Validation loss: 2.9194809153238346

Epoch: 6| Step: 5
Training loss: 3.5983410244662655
Validation loss: 2.9192049809184555

Epoch: 6| Step: 6
Training loss: 4.062571363555891
Validation loss: 2.920989125948454

Epoch: 6| Step: 7
Training loss: 3.509058401852945
Validation loss: 2.9218244571820846

Epoch: 6| Step: 8
Training loss: 3.332085344025294
Validation loss: 2.9189988192396714

Epoch: 6| Step: 9
Training loss: 2.79855943815636
Validation loss: 2.917138555180846

Epoch: 6| Step: 10
Training loss: 2.8738243352925434
Validation loss: 2.921407892015663

Epoch: 6| Step: 11
Training loss: 2.7490057448364933
Validation loss: 2.9276381156518374

Epoch: 6| Step: 12
Training loss: 3.181979915917562
Validation loss: 2.9236356116022466

Epoch: 6| Step: 13
Training loss: 3.294461058098893
Validation loss: 2.929564475043504

Epoch: 129| Step: 0
Training loss: 3.2762503181000358
Validation loss: 2.9381399406693345

Epoch: 6| Step: 1
Training loss: 2.6901882831806407
Validation loss: 2.9321015890747084

Epoch: 6| Step: 2
Training loss: 2.978953124887312
Validation loss: 2.927484476010434

Epoch: 6| Step: 3
Training loss: 3.117359586855871
Validation loss: 2.9316688248703704

Epoch: 6| Step: 4
Training loss: 3.1806025957370525
Validation loss: 2.9351710100171937

Epoch: 6| Step: 5
Training loss: 3.074449542639198
Validation loss: 2.9342957341619678

Epoch: 6| Step: 6
Training loss: 3.5754263083495355
Validation loss: 2.937141969148167

Epoch: 6| Step: 7
Training loss: 3.3803585040684414
Validation loss: 2.9338410602891987

Epoch: 6| Step: 8
Training loss: 3.2334171664456823
Validation loss: 2.923144902630608

Epoch: 6| Step: 9
Training loss: 3.16321331920685
Validation loss: 2.917466542365224

Epoch: 6| Step: 10
Training loss: 3.2256490601320627
Validation loss: 2.91655829502237

Epoch: 6| Step: 11
Training loss: 3.286489318282439
Validation loss: 2.916753980908866

Epoch: 6| Step: 12
Training loss: 3.3092785411461856
Validation loss: 2.9155937459833656

Epoch: 6| Step: 13
Training loss: 3.512131782318549
Validation loss: 2.915226626259159

Epoch: 130| Step: 0
Training loss: 3.2210883378069677
Validation loss: 2.9143161625338765

Epoch: 6| Step: 1
Training loss: 3.1661478588015983
Validation loss: 2.9139378933491615

Epoch: 6| Step: 2
Training loss: 3.246946367465253
Validation loss: 2.9141334525713334

Epoch: 6| Step: 3
Training loss: 3.0929527411416338
Validation loss: 2.917593295191062

Epoch: 6| Step: 4
Training loss: 3.2564695961503856
Validation loss: 2.9182913449335106

Epoch: 6| Step: 5
Training loss: 3.553609898476038
Validation loss: 2.917365585181698

Epoch: 6| Step: 6
Training loss: 3.4623863339272543
Validation loss: 2.9163503015282664

Epoch: 6| Step: 7
Training loss: 3.1842330945921344
Validation loss: 2.9139931820716987

Epoch: 6| Step: 8
Training loss: 2.9003697455582635
Validation loss: 2.9128118475607616

Epoch: 6| Step: 9
Training loss: 2.860636448502838
Validation loss: 2.911731479466095

Epoch: 6| Step: 10
Training loss: 3.2475400564822956
Validation loss: 2.9126673114886596

Epoch: 6| Step: 11
Training loss: 3.0046488981103145
Validation loss: 2.91247554090837

Epoch: 6| Step: 12
Training loss: 3.128097829786473
Validation loss: 2.911170489273354

Epoch: 6| Step: 13
Training loss: 3.6503847468100745
Validation loss: 2.9109214123116036

Epoch: 131| Step: 0
Training loss: 3.443238756617206
Validation loss: 2.9105611760176986

Epoch: 6| Step: 1
Training loss: 3.301980932595407
Validation loss: 2.910436035414074

Epoch: 6| Step: 2
Training loss: 3.282861949433836
Validation loss: 2.91034850461193

Epoch: 6| Step: 3
Training loss: 3.3588208118465848
Validation loss: 2.911670514550719

Epoch: 6| Step: 4
Training loss: 3.4449594191332786
Validation loss: 2.9104999434808674

Epoch: 6| Step: 5
Training loss: 2.3124358709567705
Validation loss: 2.9117194304516394

Epoch: 6| Step: 6
Training loss: 2.3461179850797254
Validation loss: 2.911865373810222

Epoch: 6| Step: 7
Training loss: 3.3172422328176405
Validation loss: 2.9082160119194493

Epoch: 6| Step: 8
Training loss: 2.926549100259633
Validation loss: 2.9105308378076105

Epoch: 6| Step: 9
Training loss: 3.477461452201921
Validation loss: 2.9089394822007835

Epoch: 6| Step: 10
Training loss: 3.0371164401545636
Validation loss: 2.908141209867983

Epoch: 6| Step: 11
Training loss: 3.925144124877711
Validation loss: 2.9081133319369625

Epoch: 6| Step: 12
Training loss: 3.056126872509789
Validation loss: 2.910591986459179

Epoch: 6| Step: 13
Training loss: 3.226537080900176
Validation loss: 2.9155264516939443

Epoch: 132| Step: 0
Training loss: 3.0455441429384855
Validation loss: 2.9091141421589053

Epoch: 6| Step: 1
Training loss: 3.3852154168197224
Validation loss: 2.912895902755216

Epoch: 6| Step: 2
Training loss: 3.8968765711532645
Validation loss: 2.915156430211721

Epoch: 6| Step: 3
Training loss: 3.5624630574770415
Validation loss: 2.9179680453865466

Epoch: 6| Step: 4
Training loss: 3.2247590204147185
Validation loss: 2.917087929418258

Epoch: 6| Step: 5
Training loss: 2.9026392995443437
Validation loss: 2.9276362579204105

Epoch: 6| Step: 6
Training loss: 3.0860144496932964
Validation loss: 2.9159444316141174

Epoch: 6| Step: 7
Training loss: 2.93961744894719
Validation loss: 2.9212525741041575

Epoch: 6| Step: 8
Training loss: 3.603478309003943
Validation loss: 2.9200730772506374

Epoch: 6| Step: 9
Training loss: 2.9187964882916173
Validation loss: 2.9195610404822006

Epoch: 6| Step: 10
Training loss: 2.6694417659954706
Validation loss: 2.9175971719394034

Epoch: 6| Step: 11
Training loss: 3.1576335631669297
Validation loss: 2.923573811091388

Epoch: 6| Step: 12
Training loss: 3.0673207856968863
Validation loss: 2.904769989896848

Epoch: 6| Step: 13
Training loss: 3.037705930157696
Validation loss: 2.9038523569617993

Epoch: 133| Step: 0
Training loss: 2.8713881983897704
Validation loss: 2.9021103524030223

Epoch: 6| Step: 1
Training loss: 3.054825021131162
Validation loss: 2.9019019903474295

Epoch: 6| Step: 2
Training loss: 3.0512835568993735
Validation loss: 2.900544158793027

Epoch: 6| Step: 3
Training loss: 3.3877998923123487
Validation loss: 2.900117725504696

Epoch: 6| Step: 4
Training loss: 3.1354027596774654
Validation loss: 2.901516052178619

Epoch: 6| Step: 5
Training loss: 3.4125462008412395
Validation loss: 2.9005002568385234

Epoch: 6| Step: 6
Training loss: 2.976892808424025
Validation loss: 2.9035587064669484

Epoch: 6| Step: 7
Training loss: 3.6947924387116973
Validation loss: 2.901974128953668

Epoch: 6| Step: 8
Training loss: 2.866689196949034
Validation loss: 2.901303733906367

Epoch: 6| Step: 9
Training loss: 3.8069349853318935
Validation loss: 2.9007041052694853

Epoch: 6| Step: 10
Training loss: 2.3338570915214625
Validation loss: 2.8967735105224994

Epoch: 6| Step: 11
Training loss: 3.6194400900203587
Validation loss: 2.901499374201023

Epoch: 6| Step: 12
Training loss: 3.1237412015463577
Validation loss: 2.9019080648374085

Epoch: 6| Step: 13
Training loss: 2.9950915554107804
Validation loss: 2.9002645611621403

Epoch: 134| Step: 0
Training loss: 2.829884355965743
Validation loss: 2.9015232001063995

Epoch: 6| Step: 1
Training loss: 2.980157398445061
Validation loss: 2.9011632787372927

Epoch: 6| Step: 2
Training loss: 2.8881376544978123
Validation loss: 2.9026015500117257

Epoch: 6| Step: 3
Training loss: 3.52332165309831
Validation loss: 2.8972110659419643

Epoch: 6| Step: 4
Training loss: 1.9559499224042642
Validation loss: 2.8963945293113302

Epoch: 6| Step: 5
Training loss: 3.406057509836694
Validation loss: 2.8982630732111963

Epoch: 6| Step: 6
Training loss: 3.441806661669635
Validation loss: 2.899980250387866

Epoch: 6| Step: 7
Training loss: 3.402947460969555
Validation loss: 2.8978381656016583

Epoch: 6| Step: 8
Training loss: 3.2925322798853336
Validation loss: 2.8991897606715464

Epoch: 6| Step: 9
Training loss: 3.0844500469751743
Validation loss: 2.8969955862252936

Epoch: 6| Step: 10
Training loss: 4.065628959542413
Validation loss: 2.895346448266849

Epoch: 6| Step: 11
Training loss: 3.324127088419361
Validation loss: 2.898266130192961

Epoch: 6| Step: 12
Training loss: 2.8236750373498603
Validation loss: 2.8954452965256574

Epoch: 6| Step: 13
Training loss: 3.1077395024460266
Validation loss: 2.892702685742527

Epoch: 135| Step: 0
Training loss: 3.2755299437890493
Validation loss: 2.8946441760772155

Epoch: 6| Step: 1
Training loss: 3.5929642854991695
Validation loss: 2.894699578247271

Epoch: 6| Step: 2
Training loss: 3.438910039063962
Validation loss: 2.893004808297584

Epoch: 6| Step: 3
Training loss: 3.6532648404051717
Validation loss: 2.8936006944661634

Epoch: 6| Step: 4
Training loss: 3.1950770060493006
Validation loss: 2.896081697925604

Epoch: 6| Step: 5
Training loss: 2.624348332486953
Validation loss: 2.8938779770873113

Epoch: 6| Step: 6
Training loss: 3.2527196215664573
Validation loss: 2.8922436351488057

Epoch: 6| Step: 7
Training loss: 2.552578490093811
Validation loss: 2.8945354977383744

Epoch: 6| Step: 8
Training loss: 2.546062690987877
Validation loss: 2.8933937264680587

Epoch: 6| Step: 9
Training loss: 3.2854188140558946
Validation loss: 2.904748821561694

Epoch: 6| Step: 10
Training loss: 3.8030576250162627
Validation loss: 2.9262748906528366

Epoch: 6| Step: 11
Training loss: 2.794089779257202
Validation loss: 2.9124203113996843

Epoch: 6| Step: 12
Training loss: 2.96661653654913
Validation loss: 2.907763734062444

Epoch: 6| Step: 13
Training loss: 3.530378115884088
Validation loss: 2.8953235251533864

Epoch: 136| Step: 0
Training loss: 3.1151918222995
Validation loss: 2.889320607369684

Epoch: 6| Step: 1
Training loss: 3.135161092656053
Validation loss: 2.8901174164491863

Epoch: 6| Step: 2
Training loss: 3.3127553589477907
Validation loss: 2.8902108962023765

Epoch: 6| Step: 3
Training loss: 3.1879483075994615
Validation loss: 2.8899235391733686

Epoch: 6| Step: 4
Training loss: 3.8283083502010062
Validation loss: 2.891611240408156

Epoch: 6| Step: 5
Training loss: 2.943649024608424
Validation loss: 2.8930969311438344

Epoch: 6| Step: 6
Training loss: 3.640140353839986
Validation loss: 2.8970212004342017

Epoch: 6| Step: 7
Training loss: 2.398077226351337
Validation loss: 2.900924333540779

Epoch: 6| Step: 8
Training loss: 3.343049163100833
Validation loss: 2.8997692766370284

Epoch: 6| Step: 9
Training loss: 3.1173010019083853
Validation loss: 2.8952658619491958

Epoch: 6| Step: 10
Training loss: 2.6925817837421193
Validation loss: 2.890734831040745

Epoch: 6| Step: 11
Training loss: 3.2354363068530843
Validation loss: 2.8892698144954827

Epoch: 6| Step: 12
Training loss: 3.2082937824404114
Validation loss: 2.8899915822110867

Epoch: 6| Step: 13
Training loss: 3.3746812457982145
Validation loss: 2.890586546354157

Epoch: 137| Step: 0
Training loss: 3.136123695795041
Validation loss: 2.885450238058126

Epoch: 6| Step: 1
Training loss: 2.9992003964704455
Validation loss: 2.8878216631470455

Epoch: 6| Step: 2
Training loss: 2.5327705243331193
Validation loss: 2.885859979183005

Epoch: 6| Step: 3
Training loss: 3.0681929321601533
Validation loss: 2.885865417628839

Epoch: 6| Step: 4
Training loss: 2.7799972112902367
Validation loss: 2.8866112901753453

Epoch: 6| Step: 5
Training loss: 3.1112438317402886
Validation loss: 2.9046436915959544

Epoch: 6| Step: 6
Training loss: 2.7278405284807286
Validation loss: 2.9123847176339805

Epoch: 6| Step: 7
Training loss: 3.9198048511898054
Validation loss: 2.927885424216524

Epoch: 6| Step: 8
Training loss: 3.508737285007967
Validation loss: 2.9044129909039116

Epoch: 6| Step: 9
Training loss: 3.477543587428606
Validation loss: 2.893914070440201

Epoch: 6| Step: 10
Training loss: 3.0976203829792217
Validation loss: 2.883573251923996

Epoch: 6| Step: 11
Training loss: 3.452344435074327
Validation loss: 2.884628721994636

Epoch: 6| Step: 12
Training loss: 3.3738692473360787
Validation loss: 2.8889600034376866

Epoch: 6| Step: 13
Training loss: 3.2856057457144754
Validation loss: 2.888850647137088

Epoch: 138| Step: 0
Training loss: 2.856947572028806
Validation loss: 2.893619172177509

Epoch: 6| Step: 1
Training loss: 3.6758956648140373
Validation loss: 2.8920212202551254

Epoch: 6| Step: 2
Training loss: 3.268402524608346
Validation loss: 2.892330093597291

Epoch: 6| Step: 3
Training loss: 3.155063519450532
Validation loss: 2.8968749791501622

Epoch: 6| Step: 4
Training loss: 3.5555708573594904
Validation loss: 2.8966724498792105

Epoch: 6| Step: 5
Training loss: 3.142267964611831
Validation loss: 2.8986436072783066

Epoch: 6| Step: 6
Training loss: 2.8901521863102952
Validation loss: 2.8989971922803717

Epoch: 6| Step: 7
Training loss: 3.3833954553272227
Validation loss: 2.8905140419516644

Epoch: 6| Step: 8
Training loss: 2.6419627395763117
Validation loss: 2.883493645293245

Epoch: 6| Step: 9
Training loss: 2.4451492791347973
Validation loss: 2.8842678327777254

Epoch: 6| Step: 10
Training loss: 3.575410304499334
Validation loss: 2.8828663741336

Epoch: 6| Step: 11
Training loss: 2.7552833090221545
Validation loss: 2.8811110054969977

Epoch: 6| Step: 12
Training loss: 3.4525546470256256
Validation loss: 2.879370507545966

Epoch: 6| Step: 13
Training loss: 3.8601992572487838
Validation loss: 2.8790581192657143

Epoch: 139| Step: 0
Training loss: 3.5896179327438418
Validation loss: 2.8787615700428413

Epoch: 6| Step: 1
Training loss: 3.1482289436876343
Validation loss: 2.8758810030140443

Epoch: 6| Step: 2
Training loss: 3.321708690826001
Validation loss: 2.8737716922186536

Epoch: 6| Step: 3
Training loss: 2.6090338021337076
Validation loss: 2.8788329865770845

Epoch: 6| Step: 4
Training loss: 2.7198482356086804
Validation loss: 2.8773510759771175

Epoch: 6| Step: 5
Training loss: 3.1649608702447907
Validation loss: 2.8806073798856326

Epoch: 6| Step: 6
Training loss: 3.3430554390525895
Validation loss: 2.8837234174398585

Epoch: 6| Step: 7
Training loss: 2.9048685051314274
Validation loss: 2.87701859127599

Epoch: 6| Step: 8
Training loss: 3.6641370688457537
Validation loss: 2.875667231543935

Epoch: 6| Step: 9
Training loss: 3.445731278137878
Validation loss: 2.8770446782825903

Epoch: 6| Step: 10
Training loss: 3.4913238891256273
Validation loss: 2.8691737843080607

Epoch: 6| Step: 11
Training loss: 3.1211698329470368
Validation loss: 2.8697887860078555

Epoch: 6| Step: 12
Training loss: 2.65058087514369
Validation loss: 2.8709881502283134

Epoch: 6| Step: 13
Training loss: 3.0311540411478584
Validation loss: 2.8704352627065357

Epoch: 140| Step: 0
Training loss: 3.693888028788376
Validation loss: 2.868927906130319

Epoch: 6| Step: 1
Training loss: 2.999591481686604
Validation loss: 2.8690204151628897

Epoch: 6| Step: 2
Training loss: 3.21400264522916
Validation loss: 2.8669479147968375

Epoch: 6| Step: 3
Training loss: 2.613181621209059
Validation loss: 2.867186455655043

Epoch: 6| Step: 4
Training loss: 3.4977063429131503
Validation loss: 2.8654277504828674

Epoch: 6| Step: 5
Training loss: 2.989332305967011
Validation loss: 2.8667062580907006

Epoch: 6| Step: 6
Training loss: 2.2554867919792225
Validation loss: 2.8647990633070997

Epoch: 6| Step: 7
Training loss: 3.26800508782167
Validation loss: 2.8645912699808527

Epoch: 6| Step: 8
Training loss: 3.3656347814787932
Validation loss: 2.8639223799842526

Epoch: 6| Step: 9
Training loss: 3.4641555739215915
Validation loss: 2.8643050955654616

Epoch: 6| Step: 10
Training loss: 3.4602477202186437
Validation loss: 2.8636399434900714

Epoch: 6| Step: 11
Training loss: 2.834767670438149
Validation loss: 2.861461175814532

Epoch: 6| Step: 12
Training loss: 3.0207738059306393
Validation loss: 2.864756513415296

Epoch: 6| Step: 13
Training loss: 3.503562748805058
Validation loss: 2.8649785143796036

Epoch: 141| Step: 0
Training loss: 3.7800588702103384
Validation loss: 2.86373939156656

Epoch: 6| Step: 1
Training loss: 2.324992382898466
Validation loss: 2.8631565482225776

Epoch: 6| Step: 2
Training loss: 3.231854179756411
Validation loss: 2.8665296124975184

Epoch: 6| Step: 3
Training loss: 3.561538031014453
Validation loss: 2.8631158668018584

Epoch: 6| Step: 4
Training loss: 3.3734900310997213
Validation loss: 2.8625853419081224

Epoch: 6| Step: 5
Training loss: 3.3512187505828104
Validation loss: 2.8638906735893475

Epoch: 6| Step: 6
Training loss: 2.8016748426031772
Validation loss: 2.864634702041061

Epoch: 6| Step: 7
Training loss: 3.2618364324297855
Validation loss: 2.863074478320529

Epoch: 6| Step: 8
Training loss: 2.9740267788592742
Validation loss: 2.8694677373130792

Epoch: 6| Step: 9
Training loss: 3.1977407467114514
Validation loss: 2.8690711635360224

Epoch: 6| Step: 10
Training loss: 3.3051942116697877
Validation loss: 2.8725417543388843

Epoch: 6| Step: 11
Training loss: 2.7277516392501955
Validation loss: 2.8733166594695203

Epoch: 6| Step: 12
Training loss: 3.1989708735722147
Validation loss: 2.873638510177701

Epoch: 6| Step: 13
Training loss: 2.709374672648796
Validation loss: 2.87009746339003

Epoch: 142| Step: 0
Training loss: 3.1428175527382756
Validation loss: 2.8777018928257245

Epoch: 6| Step: 1
Training loss: 1.8544235337311847
Validation loss: 2.8736290768476294

Epoch: 6| Step: 2
Training loss: 3.1197526745702584
Validation loss: 2.866899965307758

Epoch: 6| Step: 3
Training loss: 3.265483506345179
Validation loss: 2.8790728382708974

Epoch: 6| Step: 4
Training loss: 2.835621377439415
Validation loss: 2.878468559902045

Epoch: 6| Step: 5
Training loss: 2.763964914482894
Validation loss: 2.871460162570886

Epoch: 6| Step: 6
Training loss: 3.1836213093132293
Validation loss: 2.8662041523047352

Epoch: 6| Step: 7
Training loss: 3.8385298102034846
Validation loss: 2.8543598572843027

Epoch: 6| Step: 8
Training loss: 3.1889787123727102
Validation loss: 2.857117086248885

Epoch: 6| Step: 9
Training loss: 2.5923513295171654
Validation loss: 2.8552517434270768

Epoch: 6| Step: 10
Training loss: 3.5462363588207246
Validation loss: 2.855239000848714

Epoch: 6| Step: 11
Training loss: 3.180314885509939
Validation loss: 2.854753821146618

Epoch: 6| Step: 12
Training loss: 3.6286393674147948
Validation loss: 2.856607928278895

Epoch: 6| Step: 13
Training loss: 3.8587169008902196
Validation loss: 2.8563652477923056

Epoch: 143| Step: 0
Training loss: 3.050392350772658
Validation loss: 2.8570410746582366

Epoch: 6| Step: 1
Training loss: 2.976723814270123
Validation loss: 2.8594684115991464

Epoch: 6| Step: 2
Training loss: 3.2046490276822825
Validation loss: 2.860499379211423

Epoch: 6| Step: 3
Training loss: 3.727674786098311
Validation loss: 2.8603244529632623

Epoch: 6| Step: 4
Training loss: 2.907014643666036
Validation loss: 2.8580811700872975

Epoch: 6| Step: 5
Training loss: 3.443452155496339
Validation loss: 2.859571216507239

Epoch: 6| Step: 6
Training loss: 3.1672067348985786
Validation loss: 2.8594339249110083

Epoch: 6| Step: 7
Training loss: 3.0747654585052326
Validation loss: 2.858549827746277

Epoch: 6| Step: 8
Training loss: 3.047051996812141
Validation loss: 2.8577482061994686

Epoch: 6| Step: 9
Training loss: 3.27220724289867
Validation loss: 2.8544236799414455

Epoch: 6| Step: 10
Training loss: 2.722030064121796
Validation loss: 2.8540450045424812

Epoch: 6| Step: 11
Training loss: 3.1973563002566694
Validation loss: 2.8528346154033644

Epoch: 6| Step: 12
Training loss: 3.2834044150260113
Validation loss: 2.8532424453136764

Epoch: 6| Step: 13
Training loss: 3.0630480217576985
Validation loss: 2.8528659962628677

Epoch: 144| Step: 0
Training loss: 3.2968175801705177
Validation loss: 2.8523142148734464

Epoch: 6| Step: 1
Training loss: 3.0320578216434235
Validation loss: 2.8521852764786644

Epoch: 6| Step: 2
Training loss: 2.8364768448047095
Validation loss: 2.851722454552531

Epoch: 6| Step: 3
Training loss: 3.2235680232432005
Validation loss: 2.850550747080974

Epoch: 6| Step: 4
Training loss: 3.4704838448947983
Validation loss: 2.8523758282797895

Epoch: 6| Step: 5
Training loss: 3.5657590715509166
Validation loss: 2.8506575994590357

Epoch: 6| Step: 6
Training loss: 3.552093431266385
Validation loss: 2.8481982325991346

Epoch: 6| Step: 7
Training loss: 2.5541948782611037
Validation loss: 2.844469599845981

Epoch: 6| Step: 8
Training loss: 3.0715501925953164
Validation loss: 2.8465000527973827

Epoch: 6| Step: 9
Training loss: 2.8131971554845245
Validation loss: 2.8479730683685784

Epoch: 6| Step: 10
Training loss: 3.3420204609507667
Validation loss: 2.846623759614819

Epoch: 6| Step: 11
Training loss: 3.178977493384057
Validation loss: 2.849115420951988

Epoch: 6| Step: 12
Training loss: 3.4072597301964747
Validation loss: 2.8505011826143445

Epoch: 6| Step: 13
Training loss: 2.0292564586326547
Validation loss: 2.8507216749700612

Epoch: 145| Step: 0
Training loss: 2.796444396217975
Validation loss: 2.855766892111837

Epoch: 6| Step: 1
Training loss: 2.8250282151155113
Validation loss: 2.8555567061385214

Epoch: 6| Step: 2
Training loss: 3.596017669396701
Validation loss: 2.8630735712647066

Epoch: 6| Step: 3
Training loss: 3.1171608830513056
Validation loss: 2.8510598367134694

Epoch: 6| Step: 4
Training loss: 2.9063874899223516
Validation loss: 2.8473750856670943

Epoch: 6| Step: 5
Training loss: 3.070692664918261
Validation loss: 2.84727294607239

Epoch: 6| Step: 6
Training loss: 3.738308036492981
Validation loss: 2.846996797337831

Epoch: 6| Step: 7
Training loss: 2.555882259116613
Validation loss: 2.848533694259009

Epoch: 6| Step: 8
Training loss: 2.4654949313475063
Validation loss: 2.8529104587040464

Epoch: 6| Step: 9
Training loss: 3.7426324313067587
Validation loss: 2.850395349686912

Epoch: 6| Step: 10
Training loss: 3.624230138650192
Validation loss: 2.850330884587204

Epoch: 6| Step: 11
Training loss: 2.827289774100957
Validation loss: 2.848319787438988

Epoch: 6| Step: 12
Training loss: 3.103140710520087
Validation loss: 2.845887648329088

Epoch: 6| Step: 13
Training loss: 3.6691826222494677
Validation loss: 2.8464170631238823

Epoch: 146| Step: 0
Training loss: 3.2438545812899293
Validation loss: 2.844083306487492

Epoch: 6| Step: 1
Training loss: 3.7535282067707225
Validation loss: 2.8453045021642955

Epoch: 6| Step: 2
Training loss: 2.9705023161605077
Validation loss: 2.842313078682402

Epoch: 6| Step: 3
Training loss: 3.2067875461701503
Validation loss: 2.841506321706687

Epoch: 6| Step: 4
Training loss: 2.9672822235077865
Validation loss: 2.8431119657195203

Epoch: 6| Step: 5
Training loss: 2.4265248607067034
Validation loss: 2.842465353597222

Epoch: 6| Step: 6
Training loss: 3.09190467747745
Validation loss: 2.839317006956594

Epoch: 6| Step: 7
Training loss: 3.1434265091625506
Validation loss: 2.8421096623418314

Epoch: 6| Step: 8
Training loss: 3.6464569139800207
Validation loss: 2.840387886712406

Epoch: 6| Step: 9
Training loss: 2.6420949422279167
Validation loss: 2.8410479340544326

Epoch: 6| Step: 10
Training loss: 3.7047871267758583
Validation loss: 2.8392020785002274

Epoch: 6| Step: 11
Training loss: 2.751342272461195
Validation loss: 2.8436292018428446

Epoch: 6| Step: 12
Training loss: 2.8380357950653594
Validation loss: 2.845268900433059

Epoch: 6| Step: 13
Training loss: 3.512434397454754
Validation loss: 2.8453758033987486

Epoch: 147| Step: 0
Training loss: 3.0109224169620106
Validation loss: 2.8468964811990825

Epoch: 6| Step: 1
Training loss: 2.5349137905893793
Validation loss: 2.8521539483520617

Epoch: 6| Step: 2
Training loss: 3.694321481352234
Validation loss: 2.855300181226725

Epoch: 6| Step: 3
Training loss: 3.621766325247567
Validation loss: 2.8509421574666676

Epoch: 6| Step: 4
Training loss: 1.4492431803081067
Validation loss: 2.8470981765131818

Epoch: 6| Step: 5
Training loss: 2.843990776851845
Validation loss: 2.8416575220721296

Epoch: 6| Step: 6
Training loss: 3.185965972967728
Validation loss: 2.8385784278123167

Epoch: 6| Step: 7
Training loss: 3.0940867539358603
Validation loss: 2.839961134471184

Epoch: 6| Step: 8
Training loss: 3.14893180052776
Validation loss: 2.8408935455314586

Epoch: 6| Step: 9
Training loss: 3.305002905401433
Validation loss: 2.838455072131826

Epoch: 6| Step: 10
Training loss: 3.7191845295384716
Validation loss: 2.8369872418421025

Epoch: 6| Step: 11
Training loss: 3.0396983601848793
Validation loss: 2.835269214754809

Epoch: 6| Step: 12
Training loss: 3.389931884801485
Validation loss: 2.8357605758753155

Epoch: 6| Step: 13
Training loss: 3.4886400608520978
Validation loss: 2.839783917565909

Epoch: 148| Step: 0
Training loss: 3.0066949526971003
Validation loss: 2.831394213017718

Epoch: 6| Step: 1
Training loss: 2.934285779415209
Validation loss: 2.8371797206788143

Epoch: 6| Step: 2
Training loss: 3.229826304014128
Validation loss: 2.833069801440646

Epoch: 6| Step: 3
Training loss: 3.0580171745621363
Validation loss: 2.8329143193223336

Epoch: 6| Step: 4
Training loss: 3.38996283046634
Validation loss: 2.8361552956072633

Epoch: 6| Step: 5
Training loss: 3.6714714964880124
Validation loss: 2.833374306046532

Epoch: 6| Step: 6
Training loss: 3.1417513673193067
Validation loss: 2.833100932492965

Epoch: 6| Step: 7
Training loss: 3.2587808683782207
Validation loss: 2.8274216485207675

Epoch: 6| Step: 8
Training loss: 3.6195237460800698
Validation loss: 2.833940421639408

Epoch: 6| Step: 9
Training loss: 2.7039462038365683
Validation loss: 2.8306289590059213

Epoch: 6| Step: 10
Training loss: 3.2328166063742647
Validation loss: 2.8317466036640497

Epoch: 6| Step: 11
Training loss: 2.8768729038798577
Validation loss: 2.830196334806972

Epoch: 6| Step: 12
Training loss: 2.781267058930962
Validation loss: 2.834144442405787

Epoch: 6| Step: 13
Training loss: 2.630717998010922
Validation loss: 2.8343160024252265

Epoch: 149| Step: 0
Training loss: 2.462150831689046
Validation loss: 2.842111984141158

Epoch: 6| Step: 1
Training loss: 3.0189239957276137
Validation loss: 2.8423357600732455

Epoch: 6| Step: 2
Training loss: 3.903552046809844
Validation loss: 2.847257336062259

Epoch: 6| Step: 3
Training loss: 2.621096933650032
Validation loss: 2.8322032494059157

Epoch: 6| Step: 4
Training loss: 3.710151669468706
Validation loss: 2.837671955256527

Epoch: 6| Step: 5
Training loss: 2.2658456629139048
Validation loss: 2.827727184735821

Epoch: 6| Step: 6
Training loss: 3.609652421866883
Validation loss: 2.8321730200078

Epoch: 6| Step: 7
Training loss: 2.9666284308666246
Validation loss: 2.8297609728021595

Epoch: 6| Step: 8
Training loss: 2.8779465875818686
Validation loss: 2.8283633916485043

Epoch: 6| Step: 9
Training loss: 2.228112467640947
Validation loss: 2.8282783179841364

Epoch: 6| Step: 10
Training loss: 3.1490953387658367
Validation loss: 2.8259158650753213

Epoch: 6| Step: 11
Training loss: 3.909928931641633
Validation loss: 2.8265219349859105

Epoch: 6| Step: 12
Training loss: 2.8800218923054546
Validation loss: 2.8272797073616838

Epoch: 6| Step: 13
Training loss: 3.893268590959285
Validation loss: 2.826039319956113

Epoch: 150| Step: 0
Training loss: 3.189178473659483
Validation loss: 2.825289422252954

Epoch: 6| Step: 1
Training loss: 2.9951670182009793
Validation loss: 2.827126487564404

Epoch: 6| Step: 2
Training loss: 2.5170727467441907
Validation loss: 2.8262238581097594

Epoch: 6| Step: 3
Training loss: 3.0423920345662534
Validation loss: 2.8232481461075087

Epoch: 6| Step: 4
Training loss: 2.8100728052013575
Validation loss: 2.8247265631585337

Epoch: 6| Step: 5
Training loss: 3.314251994210448
Validation loss: 2.8223018184770536

Epoch: 6| Step: 6
Training loss: 2.8643879956777356
Validation loss: 2.8220785814855076

Epoch: 6| Step: 7
Training loss: 2.809970311452617
Validation loss: 2.8225910598515864

Epoch: 6| Step: 8
Training loss: 3.48089918906433
Validation loss: 2.8218933443556953

Epoch: 6| Step: 9
Training loss: 3.538499800050996
Validation loss: 2.8228209460055336

Epoch: 6| Step: 10
Training loss: 3.392514313321149
Validation loss: 2.8243029792384635

Epoch: 6| Step: 11
Training loss: 3.252605274323437
Validation loss: 2.824718941818628

Epoch: 6| Step: 12
Training loss: 3.400609096496222
Validation loss: 2.825727986276129

Epoch: 6| Step: 13
Training loss: 2.9565097041507076
Validation loss: 2.8215347462654345

Epoch: 151| Step: 0
Training loss: 2.966047482399208
Validation loss: 2.824848707356591

Epoch: 6| Step: 1
Training loss: 3.3298981290705867
Validation loss: 2.822121322456399

Epoch: 6| Step: 2
Training loss: 3.274011675385646
Validation loss: 2.8247158742178393

Epoch: 6| Step: 3
Training loss: 2.896122833344662
Validation loss: 2.8207418259130845

Epoch: 6| Step: 4
Training loss: 3.6448596344387174
Validation loss: 2.825171931802159

Epoch: 6| Step: 5
Training loss: 2.7926680823193744
Validation loss: 2.8187677245941023

Epoch: 6| Step: 6
Training loss: 2.8226973576301475
Validation loss: 2.8197360149073565

Epoch: 6| Step: 7
Training loss: 3.3940715939507347
Validation loss: 2.82217252174456

Epoch: 6| Step: 8
Training loss: 2.9574803120980797
Validation loss: 2.819673692826235

Epoch: 6| Step: 9
Training loss: 2.6502009909360456
Validation loss: 2.8257088641112333

Epoch: 6| Step: 10
Training loss: 3.1615709832539456
Validation loss: 2.819441462368933

Epoch: 6| Step: 11
Training loss: 3.1292549158106313
Validation loss: 2.8220493955256307

Epoch: 6| Step: 12
Training loss: 2.8944156021304965
Validation loss: 2.821197542697363

Epoch: 6| Step: 13
Training loss: 4.052645424475652
Validation loss: 2.820736121943743

Epoch: 152| Step: 0
Training loss: 2.926466002250684
Validation loss: 2.8273344166019583

Epoch: 6| Step: 1
Training loss: 3.7867192839159154
Validation loss: 2.8255730047390655

Epoch: 6| Step: 2
Training loss: 2.5910365607193535
Validation loss: 2.8230457098566974

Epoch: 6| Step: 3
Training loss: 3.27874994857503
Validation loss: 2.8194483210031875

Epoch: 6| Step: 4
Training loss: 3.860380837030095
Validation loss: 2.8118652119603036

Epoch: 6| Step: 5
Training loss: 2.1738696921213965
Validation loss: 2.815344009472135

Epoch: 6| Step: 6
Training loss: 3.0031651648019757
Validation loss: 2.810690697324861

Epoch: 6| Step: 7
Training loss: 1.9279922266522482
Validation loss: 2.812365600036304

Epoch: 6| Step: 8
Training loss: 3.042429649774687
Validation loss: 2.8091954824871963

Epoch: 6| Step: 9
Training loss: 3.3166197583381374
Validation loss: 2.8170587325662346

Epoch: 6| Step: 10
Training loss: 3.184530033908494
Validation loss: 2.8168525987820585

Epoch: 6| Step: 11
Training loss: 2.9169619456186773
Validation loss: 2.8317805453157296

Epoch: 6| Step: 12
Training loss: 3.668650018476667
Validation loss: 2.8187391619206443

Epoch: 6| Step: 13
Training loss: 3.575003515922045
Validation loss: 2.8186769696884006

Epoch: 153| Step: 0
Training loss: 3.116934782793112
Validation loss: 2.8234929230432644

Epoch: 6| Step: 1
Training loss: 1.9725776883335242
Validation loss: 2.83321052233231

Epoch: 6| Step: 2
Training loss: 3.6328416392480545
Validation loss: 2.836908721791722

Epoch: 6| Step: 3
Training loss: 2.9219546383699058
Validation loss: 2.8475847231763063

Epoch: 6| Step: 4
Training loss: 3.4075852323131284
Validation loss: 2.8572722131771524

Epoch: 6| Step: 5
Training loss: 2.8901822137643443
Validation loss: 2.8494301616135935

Epoch: 6| Step: 6
Training loss: 3.074958372997349
Validation loss: 2.8292953851451794

Epoch: 6| Step: 7
Training loss: 3.2028114723652794
Validation loss: 2.830820267224917

Epoch: 6| Step: 8
Training loss: 2.8804839532925333
Validation loss: 2.8157995414575088

Epoch: 6| Step: 9
Training loss: 3.4569737316454434
Validation loss: 2.810825010467297

Epoch: 6| Step: 10
Training loss: 3.2007756246899555
Validation loss: 2.8097695225670525

Epoch: 6| Step: 11
Training loss: 3.4388226825405765
Validation loss: 2.8078352843791183

Epoch: 6| Step: 12
Training loss: 3.101106778350662
Validation loss: 2.807380987774414

Epoch: 6| Step: 13
Training loss: 3.155651526790104
Validation loss: 2.808927015205191

Epoch: 154| Step: 0
Training loss: 3.176722538374327
Validation loss: 2.8084164597618857

Epoch: 6| Step: 1
Training loss: 2.6952657944322893
Validation loss: 2.805300643707901

Epoch: 6| Step: 2
Training loss: 3.704778889430228
Validation loss: 2.80877530699484

Epoch: 6| Step: 3
Training loss: 3.044140180139596
Validation loss: 2.8058777867124047

Epoch: 6| Step: 4
Training loss: 3.0282020582663365
Validation loss: 2.806421483422323

Epoch: 6| Step: 5
Training loss: 2.987263504946599
Validation loss: 2.808075419522108

Epoch: 6| Step: 6
Training loss: 3.837422691336896
Validation loss: 2.805090534877631

Epoch: 6| Step: 7
Training loss: 3.3966635096881284
Validation loss: 2.808025836611628

Epoch: 6| Step: 8
Training loss: 3.195219975929682
Validation loss: 2.8117028386212883

Epoch: 6| Step: 9
Training loss: 2.707620751954301
Validation loss: 2.817754268849932

Epoch: 6| Step: 10
Training loss: 2.7534820013419132
Validation loss: 2.8276129407295145

Epoch: 6| Step: 11
Training loss: 2.810513027642132
Validation loss: 2.837844513449899

Epoch: 6| Step: 12
Training loss: 3.5178169707396694
Validation loss: 2.837196408086974

Epoch: 6| Step: 13
Training loss: 1.85025229151367
Validation loss: 2.8005010331643017

Epoch: 155| Step: 0
Training loss: 3.7882795331104973
Validation loss: 2.8079675922350793

Epoch: 6| Step: 1
Training loss: 3.3546229618795653
Validation loss: 2.8150838342905855

Epoch: 6| Step: 2
Training loss: 3.076161644328226
Validation loss: 2.837490165577399

Epoch: 6| Step: 3
Training loss: 3.2226038703129576
Validation loss: 2.861647071408886

Epoch: 6| Step: 4
Training loss: 3.488469339833867
Validation loss: 2.840734887219764

Epoch: 6| Step: 5
Training loss: 2.4258712776420097
Validation loss: 2.8211430334094367

Epoch: 6| Step: 6
Training loss: 2.656763363765189
Validation loss: 2.821043812624863

Epoch: 6| Step: 7
Training loss: 2.902112579380903
Validation loss: 2.821210502640157

Epoch: 6| Step: 8
Training loss: 3.156020052247835
Validation loss: 2.8174491825171075

Epoch: 6| Step: 9
Training loss: 2.875434510940735
Validation loss: 2.8133197779222696

Epoch: 6| Step: 10
Training loss: 3.573148373281657
Validation loss: 2.8144025176455147

Epoch: 6| Step: 11
Training loss: 3.4354341715098173
Validation loss: 2.810783581667452

Epoch: 6| Step: 12
Training loss: 2.654260945305017
Validation loss: 2.8093497431932186

Epoch: 6| Step: 13
Training loss: 2.8393235182666023
Validation loss: 2.8134420660682635

Epoch: 156| Step: 0
Training loss: 2.558169450595047
Validation loss: 2.8117939818301028

Epoch: 6| Step: 1
Training loss: 2.9576745889294553
Validation loss: 2.810748741163827

Epoch: 6| Step: 2
Training loss: 3.205771641433089
Validation loss: 2.8090242263082823

Epoch: 6| Step: 3
Training loss: 2.846250168603918
Validation loss: 2.8147208866870024

Epoch: 6| Step: 4
Training loss: 2.7475881403772737
Validation loss: 2.817413144628941

Epoch: 6| Step: 5
Training loss: 3.5974295976548323
Validation loss: 2.820729869013175

Epoch: 6| Step: 6
Training loss: 3.5702060541691534
Validation loss: 2.8228323046391597

Epoch: 6| Step: 7
Training loss: 3.234399620367873
Validation loss: 2.816400750249443

Epoch: 6| Step: 8
Training loss: 2.996713586623097
Validation loss: 2.8217765492493085

Epoch: 6| Step: 9
Training loss: 3.7827294348034872
Validation loss: 2.8179062633216803

Epoch: 6| Step: 10
Training loss: 3.156239122428657
Validation loss: 2.8114870532930683

Epoch: 6| Step: 11
Training loss: 3.029998835698776
Validation loss: 2.8155517401425527

Epoch: 6| Step: 12
Training loss: 3.3777830164294302
Validation loss: 2.8133868752715894

Epoch: 6| Step: 13
Training loss: 1.476318742926453
Validation loss: 2.8077813821640834

Epoch: 157| Step: 0
Training loss: 3.2162608178880085
Validation loss: 2.805585701099998

Epoch: 6| Step: 1
Training loss: 3.1378281319149735
Validation loss: 2.808150386562855

Epoch: 6| Step: 2
Training loss: 3.6068611142901412
Validation loss: 2.806475296658431

Epoch: 6| Step: 3
Training loss: 3.7640162153553494
Validation loss: 2.8080992767062987

Epoch: 6| Step: 4
Training loss: 3.2296554851744608
Validation loss: 2.8086974732558105

Epoch: 6| Step: 5
Training loss: 3.006120478324213
Validation loss: 2.8064944539579697

Epoch: 6| Step: 6
Training loss: 2.3517488424793638
Validation loss: 2.8048387593451185

Epoch: 6| Step: 7
Training loss: 3.4149749723665104
Validation loss: 2.8074679689849553

Epoch: 6| Step: 8
Training loss: 2.981797308436412
Validation loss: 2.8070015916186546

Epoch: 6| Step: 9
Training loss: 1.9877490097578863
Validation loss: 2.807858521834744

Epoch: 6| Step: 10
Training loss: 3.0588497283728406
Validation loss: 2.8137690872318557

Epoch: 6| Step: 11
Training loss: 3.44092957467755
Validation loss: 2.8107702443880545

Epoch: 6| Step: 12
Training loss: 3.177911885935944
Validation loss: 2.80979894374287

Epoch: 6| Step: 13
Training loss: 2.7040888660996627
Validation loss: 2.805134845237429

Epoch: 158| Step: 0
Training loss: 3.1741550312411517
Validation loss: 2.802509743085715

Epoch: 6| Step: 1
Training loss: 3.2796057077997673
Validation loss: 2.803487591818342

Epoch: 6| Step: 2
Training loss: 4.026994455103044
Validation loss: 2.803876696735594

Epoch: 6| Step: 3
Training loss: 3.339726531888546
Validation loss: 2.8112360722337923

Epoch: 6| Step: 4
Training loss: 2.885902464880648
Validation loss: 2.8164490943457876

Epoch: 6| Step: 5
Training loss: 3.2842373282835715
Validation loss: 2.816669704782452

Epoch: 6| Step: 6
Training loss: 3.3127182222856915
Validation loss: 2.824402605627074

Epoch: 6| Step: 7
Training loss: 2.911081379535586
Validation loss: 2.828059429867333

Epoch: 6| Step: 8
Training loss: 2.9710899367045935
Validation loss: 2.828486622781121

Epoch: 6| Step: 9
Training loss: 2.731264623258014
Validation loss: 2.8158645339882966

Epoch: 6| Step: 10
Training loss: 2.9499556069347452
Validation loss: 2.818032252440737

Epoch: 6| Step: 11
Training loss: 2.8620181348587317
Validation loss: 2.8175497009073127

Epoch: 6| Step: 12
Training loss: 2.7758497466448877
Validation loss: 2.800491751683892

Epoch: 6| Step: 13
Training loss: 2.7305446281313626
Validation loss: 2.806763205977448

Epoch: 159| Step: 0
Training loss: 3.144714880847504
Validation loss: 2.7984714274891593

Epoch: 6| Step: 1
Training loss: 2.3188780386808547
Validation loss: 2.794178866532909

Epoch: 6| Step: 2
Training loss: 2.9595504370373003
Validation loss: 2.789156361964636

Epoch: 6| Step: 3
Training loss: 2.881740463779821
Validation loss: 2.7946168618978042

Epoch: 6| Step: 4
Training loss: 2.8395948970015334
Validation loss: 2.793655114972406

Epoch: 6| Step: 5
Training loss: 3.376903703459209
Validation loss: 2.7909468572429867

Epoch: 6| Step: 6
Training loss: 3.3597318238002933
Validation loss: 2.790146772249731

Epoch: 6| Step: 7
Training loss: 2.4084573504801847
Validation loss: 2.7904135487795925

Epoch: 6| Step: 8
Training loss: 3.1853623047292654
Validation loss: 2.790238597537102

Epoch: 6| Step: 9
Training loss: 2.8846099129649376
Validation loss: 2.7881420672567603

Epoch: 6| Step: 10
Training loss: 3.315047238388772
Validation loss: 2.787962874631517

Epoch: 6| Step: 11
Training loss: 3.400665745349972
Validation loss: 2.7927594235582984

Epoch: 6| Step: 12
Training loss: 3.144214912756846
Validation loss: 2.789086291862385

Epoch: 6| Step: 13
Training loss: 4.487066756987803
Validation loss: 2.788255982514688

Epoch: 160| Step: 0
Training loss: 2.722896001650306
Validation loss: 2.7906891334698227

Epoch: 6| Step: 1
Training loss: 3.3327326869215876
Validation loss: 2.785316713834741

Epoch: 6| Step: 2
Training loss: 2.7942456720978557
Validation loss: 2.787346234378491

Epoch: 6| Step: 3
Training loss: 3.5599669435659407
Validation loss: 2.789325438258148

Epoch: 6| Step: 4
Training loss: 3.2248404943957203
Validation loss: 2.787404040511371

Epoch: 6| Step: 5
Training loss: 3.3241814545131705
Validation loss: 2.7925895453571536

Epoch: 6| Step: 6
Training loss: 2.882650396653429
Validation loss: 2.794294818776416

Epoch: 6| Step: 7
Training loss: 3.1342290781574462
Validation loss: 2.8036472341622334

Epoch: 6| Step: 8
Training loss: 2.7247826305801226
Validation loss: 2.801222465898064

Epoch: 6| Step: 9
Training loss: 3.4167469914616313
Validation loss: 2.7959753649592507

Epoch: 6| Step: 10
Training loss: 2.9956355136151207
Validation loss: 2.7867249637370515

Epoch: 6| Step: 11
Training loss: 3.112121289358391
Validation loss: 2.78568641352361

Epoch: 6| Step: 12
Training loss: 2.865893329133973
Validation loss: 2.788851085074828

Epoch: 6| Step: 13
Training loss: 3.2678162738230694
Validation loss: 2.786856462528444

Epoch: 161| Step: 0
Training loss: 3.2119979406708876
Validation loss: 2.7926693381290506

Epoch: 6| Step: 1
Training loss: 2.9550269728202507
Validation loss: 2.785922123989281

Epoch: 6| Step: 2
Training loss: 2.9907436622349035
Validation loss: 2.7856759571637606

Epoch: 6| Step: 3
Training loss: 3.047288446007195
Validation loss: 2.7854461263642403

Epoch: 6| Step: 4
Training loss: 3.39474153031983
Validation loss: 2.78671270724969

Epoch: 6| Step: 5
Training loss: 3.4476187462996
Validation loss: 2.785821738028773

Epoch: 6| Step: 6
Training loss: 3.38267280695439
Validation loss: 2.7891983914161576

Epoch: 6| Step: 7
Training loss: 3.613258947355156
Validation loss: 2.789339182293565

Epoch: 6| Step: 8
Training loss: 2.7738178690806827
Validation loss: 2.7834989150558576

Epoch: 6| Step: 9
Training loss: 3.4887696337583085
Validation loss: 2.7866002675846198

Epoch: 6| Step: 10
Training loss: 2.3774658252012792
Validation loss: 2.784592022888093

Epoch: 6| Step: 11
Training loss: 2.5662121750189666
Validation loss: 2.786339027320189

Epoch: 6| Step: 12
Training loss: 2.5458193972674925
Validation loss: 2.778186641634773

Epoch: 6| Step: 13
Training loss: 3.3752995110879835
Validation loss: 2.784147316071338

Epoch: 162| Step: 0
Training loss: 2.3527824811151548
Validation loss: 2.7828825265442543

Epoch: 6| Step: 1
Training loss: 4.086531236737109
Validation loss: 2.781745955835379

Epoch: 6| Step: 2
Training loss: 3.4081419843638403
Validation loss: 2.782476623163945

Epoch: 6| Step: 3
Training loss: 2.6345654546599704
Validation loss: 2.781878348891964

Epoch: 6| Step: 4
Training loss: 2.913342752623298
Validation loss: 2.7872786462856123

Epoch: 6| Step: 5
Training loss: 2.908253953027117
Validation loss: 2.784845743061955

Epoch: 6| Step: 6
Training loss: 3.464990176232354
Validation loss: 2.791763395514074

Epoch: 6| Step: 7
Training loss: 3.2493647908297825
Validation loss: 2.7968672693094967

Epoch: 6| Step: 8
Training loss: 2.8576793541611227
Validation loss: 2.7865558253382106

Epoch: 6| Step: 9
Training loss: 2.9878023449482107
Validation loss: 2.7957373788494686

Epoch: 6| Step: 10
Training loss: 3.444868063428013
Validation loss: 2.799382879953207

Epoch: 6| Step: 11
Training loss: 2.7834246416781037
Validation loss: 2.7906135218849237

Epoch: 6| Step: 12
Training loss: 3.1927309683681386
Validation loss: 2.785666914341064

Epoch: 6| Step: 13
Training loss: 2.279510880257089
Validation loss: 2.7834135901178803

Epoch: 163| Step: 0
Training loss: 3.4420290155068867
Validation loss: 2.780759246619658

Epoch: 6| Step: 1
Training loss: 2.9527146796104446
Validation loss: 2.7793996835698085

Epoch: 6| Step: 2
Training loss: 3.006729842690199
Validation loss: 2.7782592141569546

Epoch: 6| Step: 3
Training loss: 3.463076513887621
Validation loss: 2.776754561588414

Epoch: 6| Step: 4
Training loss: 2.9497941220098145
Validation loss: 2.776054275324914

Epoch: 6| Step: 5
Training loss: 2.9070653284459467
Validation loss: 2.7780319110605594

Epoch: 6| Step: 6
Training loss: 3.475731225231437
Validation loss: 2.7777426891947825

Epoch: 6| Step: 7
Training loss: 3.382888053067947
Validation loss: 2.780458845449902

Epoch: 6| Step: 8
Training loss: 3.434198354494495
Validation loss: 2.7809237009577332

Epoch: 6| Step: 9
Training loss: 2.23394856685216
Validation loss: 2.781787313905951

Epoch: 6| Step: 10
Training loss: 2.838504858682414
Validation loss: 2.7824062392666993

Epoch: 6| Step: 11
Training loss: 2.858632809564214
Validation loss: 2.7798492666970835

Epoch: 6| Step: 12
Training loss: 3.1616825901958374
Validation loss: 2.779868119635774

Epoch: 6| Step: 13
Training loss: 3.0097543764492105
Validation loss: 2.776237445950717

Epoch: 164| Step: 0
Training loss: 2.0387044424162695
Validation loss: 2.7747263650696783

Epoch: 6| Step: 1
Training loss: 3.218950580161866
Validation loss: 2.773801792084934

Epoch: 6| Step: 2
Training loss: 3.1610113809411464
Validation loss: 2.7771843458516066

Epoch: 6| Step: 3
Training loss: 3.5244562744251025
Validation loss: 2.782867013194976

Epoch: 6| Step: 4
Training loss: 3.617713445075316
Validation loss: 2.7846232567577975

Epoch: 6| Step: 5
Training loss: 3.304946059625066
Validation loss: 2.7898749612425737

Epoch: 6| Step: 6
Training loss: 2.3920160372907726
Validation loss: 2.790990672932895

Epoch: 6| Step: 7
Training loss: 3.055701514331847
Validation loss: 2.798195213913784

Epoch: 6| Step: 8
Training loss: 2.940813184629321
Validation loss: 2.8070397189852656

Epoch: 6| Step: 9
Training loss: 2.69930248434249
Validation loss: 2.8087068408008085

Epoch: 6| Step: 10
Training loss: 2.4929398026036482
Validation loss: 2.7994508818647224

Epoch: 6| Step: 11
Training loss: 3.5936041760920565
Validation loss: 2.787729708407743

Epoch: 6| Step: 12
Training loss: 3.3641255700151977
Validation loss: 2.7829672791243567

Epoch: 6| Step: 13
Training loss: 3.5903683881969366
Validation loss: 2.7749302550167565

Epoch: 165| Step: 0
Training loss: 2.827151810770872
Validation loss: 2.7719949629208016

Epoch: 6| Step: 1
Training loss: 2.542370703906404
Validation loss: 2.7721580215029005

Epoch: 6| Step: 2
Training loss: 2.7386526598709917
Validation loss: 2.77172036737177

Epoch: 6| Step: 3
Training loss: 3.2425035437547645
Validation loss: 2.7716747458679363

Epoch: 6| Step: 4
Training loss: 2.359732695490114
Validation loss: 2.7715022710400024

Epoch: 6| Step: 5
Training loss: 3.1777628854552313
Validation loss: 2.7725744082732624

Epoch: 6| Step: 6
Training loss: 3.3836312305362495
Validation loss: 2.772557280139324

Epoch: 6| Step: 7
Training loss: 3.0404736691931147
Validation loss: 2.7731887819092798

Epoch: 6| Step: 8
Training loss: 3.773592675219041
Validation loss: 2.7693782936389293

Epoch: 6| Step: 9
Training loss: 3.218654594118517
Validation loss: 2.7699192543103055

Epoch: 6| Step: 10
Training loss: 3.5492624994294175
Validation loss: 2.7700154734119695

Epoch: 6| Step: 11
Training loss: 3.0521507559523573
Validation loss: 2.768329488002815

Epoch: 6| Step: 12
Training loss: 3.1569527325286204
Validation loss: 2.7680259119615873

Epoch: 6| Step: 13
Training loss: 2.7941292865853233
Validation loss: 2.776727098436823

Epoch: 166| Step: 0
Training loss: 3.3479649013106028
Validation loss: 2.778773410925033

Epoch: 6| Step: 1
Training loss: 3.759653255220128
Validation loss: 2.772716212471799

Epoch: 6| Step: 2
Training loss: 3.0978121820482567
Validation loss: 2.772886720186866

Epoch: 6| Step: 3
Training loss: 3.1357969304821367
Validation loss: 2.774517303327093

Epoch: 6| Step: 4
Training loss: 3.475592934498787
Validation loss: 2.7876316912604167

Epoch: 6| Step: 5
Training loss: 3.287254144446496
Validation loss: 2.784666929822189

Epoch: 6| Step: 6
Training loss: 2.6841158296574728
Validation loss: 2.782459848977341

Epoch: 6| Step: 7
Training loss: 2.8561523287244204
Validation loss: 2.7889439853016293

Epoch: 6| Step: 8
Training loss: 3.1175708200445365
Validation loss: 2.774006287852618

Epoch: 6| Step: 9
Training loss: 3.2408726979189124
Validation loss: 2.768155184961419

Epoch: 6| Step: 10
Training loss: 2.758767457050354
Validation loss: 2.7698845014033555

Epoch: 6| Step: 11
Training loss: 2.4258549628368584
Validation loss: 2.7669542632628903

Epoch: 6| Step: 12
Training loss: 2.635726809942637
Validation loss: 2.7666537651367085

Epoch: 6| Step: 13
Training loss: 3.2565199668690346
Validation loss: 2.7661266934395026

Epoch: 167| Step: 0
Training loss: 2.639535171161734
Validation loss: 2.768280393395262

Epoch: 6| Step: 1
Training loss: 3.1863383251951483
Validation loss: 2.765703549992281

Epoch: 6| Step: 2
Training loss: 3.2702816702478072
Validation loss: 2.765908889192562

Epoch: 6| Step: 3
Training loss: 2.8055575835553217
Validation loss: 2.766774003699018

Epoch: 6| Step: 4
Training loss: 2.4117151594614104
Validation loss: 2.7661515653417084

Epoch: 6| Step: 5
Training loss: 3.177171316127206
Validation loss: 2.7687789723996112

Epoch: 6| Step: 6
Training loss: 3.500716817203718
Validation loss: 2.7731735175497274

Epoch: 6| Step: 7
Training loss: 2.9516161742613374
Validation loss: 2.7714403064222957

Epoch: 6| Step: 8
Training loss: 3.5848724844798134
Validation loss: 2.7699296211413884

Epoch: 6| Step: 9
Training loss: 3.0316111555953986
Validation loss: 2.7716917684631888

Epoch: 6| Step: 10
Training loss: 2.6309294262957117
Validation loss: 2.7699430819522775

Epoch: 6| Step: 11
Training loss: 2.8201753789056534
Validation loss: 2.766431978213468

Epoch: 6| Step: 12
Training loss: 3.6455987182695297
Validation loss: 2.762054703729421

Epoch: 6| Step: 13
Training loss: 3.421231283318554
Validation loss: 2.7645399809748272

Epoch: 168| Step: 0
Training loss: 3.0694274403219515
Validation loss: 2.7619990123803952

Epoch: 6| Step: 1
Training loss: 3.302720226074808
Validation loss: 2.7634564377095217

Epoch: 6| Step: 2
Training loss: 3.078761310936071
Validation loss: 2.763364702140671

Epoch: 6| Step: 3
Training loss: 3.4108939055777476
Validation loss: 2.7637757007636123

Epoch: 6| Step: 4
Training loss: 2.8079325570161004
Validation loss: 2.761981345287938

Epoch: 6| Step: 5
Training loss: 2.5464941570844863
Validation loss: 2.773372607675799

Epoch: 6| Step: 6
Training loss: 2.389967684666979
Validation loss: 2.78162033050818

Epoch: 6| Step: 7
Training loss: 3.5129777902389185
Validation loss: 2.7972094157792515

Epoch: 6| Step: 8
Training loss: 3.478160568014313
Validation loss: 2.800332335923053

Epoch: 6| Step: 9
Training loss: 3.418279980249784
Validation loss: 2.7933872108198474

Epoch: 6| Step: 10
Training loss: 2.6251725639661454
Validation loss: 2.7828558958556133

Epoch: 6| Step: 11
Training loss: 3.5413678809897537
Validation loss: 2.7761450596676176

Epoch: 6| Step: 12
Training loss: 2.8074996578661335
Validation loss: 2.768741873707905

Epoch: 6| Step: 13
Training loss: 2.681570386973911
Validation loss: 2.7620272457077575

Epoch: 169| Step: 0
Training loss: 2.806306504528181
Validation loss: 2.759416020769621

Epoch: 6| Step: 1
Training loss: 2.9513938714278307
Validation loss: 2.763786658319533

Epoch: 6| Step: 2
Training loss: 3.43392550413968
Validation loss: 2.7646524786422924

Epoch: 6| Step: 3
Training loss: 3.2373205952663455
Validation loss: 2.7657691784038043

Epoch: 6| Step: 4
Training loss: 3.026565865281912
Validation loss: 2.7644512461328232

Epoch: 6| Step: 5
Training loss: 3.217154246191286
Validation loss: 2.7657863133528644

Epoch: 6| Step: 6
Training loss: 2.5018575443113438
Validation loss: 2.766626079403451

Epoch: 6| Step: 7
Training loss: 3.436212194407545
Validation loss: 2.7615109306135266

Epoch: 6| Step: 8
Training loss: 3.4663807793868573
Validation loss: 2.7617106498409987

Epoch: 6| Step: 9
Training loss: 3.0365529032005267
Validation loss: 2.758238017690107

Epoch: 6| Step: 10
Training loss: 2.511605694778968
Validation loss: 2.7610000798716983

Epoch: 6| Step: 11
Training loss: 3.0590688986774177
Validation loss: 2.7607318697439784

Epoch: 6| Step: 12
Training loss: 3.2960111381194426
Validation loss: 2.7576654931804

Epoch: 6| Step: 13
Training loss: 3.009689577640818
Validation loss: 2.7574968779939706

Epoch: 170| Step: 0
Training loss: 3.1191186109899425
Validation loss: 2.7570291925637878

Epoch: 6| Step: 1
Training loss: 3.8261003395080215
Validation loss: 2.7584599499487377

Epoch: 6| Step: 2
Training loss: 2.4943105808504833
Validation loss: 2.758696367886493

Epoch: 6| Step: 3
Training loss: 3.0645477299769115
Validation loss: 2.7567210377415385

Epoch: 6| Step: 4
Training loss: 3.2641675699359527
Validation loss: 2.754601579464743

Epoch: 6| Step: 5
Training loss: 3.211555811247839
Validation loss: 2.7618378073431646

Epoch: 6| Step: 6
Training loss: 3.150835889081937
Validation loss: 2.7511492254804892

Epoch: 6| Step: 7
Training loss: 3.0131413010649046
Validation loss: 2.755359461202654

Epoch: 6| Step: 8
Training loss: 2.9706405241801583
Validation loss: 2.758565465323884

Epoch: 6| Step: 9
Training loss: 2.792435772600312
Validation loss: 2.7565931206187324

Epoch: 6| Step: 10
Training loss: 2.977776547648364
Validation loss: 2.756410889753246

Epoch: 6| Step: 11
Training loss: 2.238972236001149
Validation loss: 2.7609455028509666

Epoch: 6| Step: 12
Training loss: 3.5721891383538664
Validation loss: 2.757676914733775

Epoch: 6| Step: 13
Training loss: 3.101348792720104
Validation loss: 2.7629288265905454

Epoch: 171| Step: 0
Training loss: 3.277966700423742
Validation loss: 2.766384573151807

Epoch: 6| Step: 1
Training loss: 3.5908597519166032
Validation loss: 2.7657664921947642

Epoch: 6| Step: 2
Training loss: 2.3279708708877576
Validation loss: 2.767727865756845

Epoch: 6| Step: 3
Training loss: 3.3180626281291032
Validation loss: 2.7680758348890606

Epoch: 6| Step: 4
Training loss: 2.39159837242029
Validation loss: 2.7633849524329004

Epoch: 6| Step: 5
Training loss: 3.013273122517883
Validation loss: 2.7557421013565917

Epoch: 6| Step: 6
Training loss: 2.7735016291551498
Validation loss: 2.7671491148413656

Epoch: 6| Step: 7
Training loss: 3.360919544095747
Validation loss: 2.7626262063380813

Epoch: 6| Step: 8
Training loss: 2.825292697023184
Validation loss: 2.7583968856336223

Epoch: 6| Step: 9
Training loss: 3.8544872391183085
Validation loss: 2.7595779144588213

Epoch: 6| Step: 10
Training loss: 3.107756380290817
Validation loss: 2.76238370632136

Epoch: 6| Step: 11
Training loss: 2.663978731958304
Validation loss: 2.756581895456324

Epoch: 6| Step: 12
Training loss: 3.1738786053677805
Validation loss: 2.755134908291455

Epoch: 6| Step: 13
Training loss: 2.872004731644582
Validation loss: 2.7550431319916577

Epoch: 172| Step: 0
Training loss: 3.18914812151565
Validation loss: 2.751824244677903

Epoch: 6| Step: 1
Training loss: 2.8125596781862914
Validation loss: 2.7537207579457386

Epoch: 6| Step: 2
Training loss: 3.6511073013624253
Validation loss: 2.753376170115685

Epoch: 6| Step: 3
Training loss: 2.504826845134986
Validation loss: 2.7511183621833792

Epoch: 6| Step: 4
Training loss: 3.1819457486824936
Validation loss: 2.7532786758324326

Epoch: 6| Step: 5
Training loss: 2.9632945480068416
Validation loss: 2.7671880516409813

Epoch: 6| Step: 6
Training loss: 2.922103138549243
Validation loss: 2.7716137822166917

Epoch: 6| Step: 7
Training loss: 3.0556759222964156
Validation loss: 2.7879310712737486

Epoch: 6| Step: 8
Training loss: 2.5792052808920514
Validation loss: 2.7942167055390157

Epoch: 6| Step: 9
Training loss: 3.2943652394554883
Validation loss: 2.789397387358249

Epoch: 6| Step: 10
Training loss: 2.827011057623931
Validation loss: 2.76975320665165

Epoch: 6| Step: 11
Training loss: 3.2648778909512473
Validation loss: 2.763651430153015

Epoch: 6| Step: 12
Training loss: 3.037665430909336
Validation loss: 2.74833541749844

Epoch: 6| Step: 13
Training loss: 3.787971260791587
Validation loss: 2.747410793328837

Epoch: 173| Step: 0
Training loss: 2.771609711450846
Validation loss: 2.745079727002764

Epoch: 6| Step: 1
Training loss: 3.1638278450313324
Validation loss: 2.7443512600235214

Epoch: 6| Step: 2
Training loss: 2.9450600918142524
Validation loss: 2.74363798914987

Epoch: 6| Step: 3
Training loss: 3.4427218915448243
Validation loss: 2.7457961750038673

Epoch: 6| Step: 4
Training loss: 2.879037592672588
Validation loss: 2.74721105448253

Epoch: 6| Step: 5
Training loss: 3.216528116381718
Validation loss: 2.7469068827641814

Epoch: 6| Step: 6
Training loss: 3.2505717141467647
Validation loss: 2.7477889937844386

Epoch: 6| Step: 7
Training loss: 3.133948369908781
Validation loss: 2.7454514058616155

Epoch: 6| Step: 8
Training loss: 3.2301764765380976
Validation loss: 2.7450474342841105

Epoch: 6| Step: 9
Training loss: 3.495238607663218
Validation loss: 2.7438313739934896

Epoch: 6| Step: 10
Training loss: 2.4918824968878246
Validation loss: 2.7440063476407763

Epoch: 6| Step: 11
Training loss: 2.9853239298381764
Validation loss: 2.7469266132226

Epoch: 6| Step: 12
Training loss: 2.4819159663788497
Validation loss: 2.749091566060478

Epoch: 6| Step: 13
Training loss: 3.4181163472596015
Validation loss: 2.742172629616953

Epoch: 174| Step: 0
Training loss: 3.181889102194951
Validation loss: 2.742429999456312

Epoch: 6| Step: 1
Training loss: 3.0249647280315455
Validation loss: 2.755494116620475

Epoch: 6| Step: 2
Training loss: 2.942638367127769
Validation loss: 2.7433175067083493

Epoch: 6| Step: 3
Training loss: 3.1687143297463782
Validation loss: 2.74028439587561

Epoch: 6| Step: 4
Training loss: 3.1964358567918225
Validation loss: 2.7462389407315926

Epoch: 6| Step: 5
Training loss: 2.6578341080080445
Validation loss: 2.7500870719765502

Epoch: 6| Step: 6
Training loss: 2.994412782447024
Validation loss: 2.7492916298599273

Epoch: 6| Step: 7
Training loss: 3.4733725325068074
Validation loss: 2.74121956771456

Epoch: 6| Step: 8
Training loss: 2.184960771640626
Validation loss: 2.751358728546036

Epoch: 6| Step: 9
Training loss: 3.018506190719689
Validation loss: 2.74659306346724

Epoch: 6| Step: 10
Training loss: 3.257327695492167
Validation loss: 2.7512907698050095

Epoch: 6| Step: 11
Training loss: 3.3368323240464557
Validation loss: 2.746788793834097

Epoch: 6| Step: 12
Training loss: 3.240883879956864
Validation loss: 2.7431115072357573

Epoch: 6| Step: 13
Training loss: 2.8951614661640432
Validation loss: 2.7469633999157037

Epoch: 175| Step: 0
Training loss: 2.0520241304432525
Validation loss: 2.754134378822164

Epoch: 6| Step: 1
Training loss: 3.051075392450183
Validation loss: 2.7546614324273606

Epoch: 6| Step: 2
Training loss: 3.137081139558216
Validation loss: 2.7524139459335335

Epoch: 6| Step: 3
Training loss: 3.3242678072724186
Validation loss: 2.767720662209338

Epoch: 6| Step: 4
Training loss: 3.234599672337089
Validation loss: 2.7672132192636725

Epoch: 6| Step: 5
Training loss: 2.269645543593688
Validation loss: 2.7679652814862568

Epoch: 6| Step: 6
Training loss: 2.948852354620452
Validation loss: 2.771591834603991

Epoch: 6| Step: 7
Training loss: 3.030508992969618
Validation loss: 2.7613171536401637

Epoch: 6| Step: 8
Training loss: 3.1058443046303035
Validation loss: 2.769948685976579

Epoch: 6| Step: 9
Training loss: 3.623041215671119
Validation loss: 2.7570505066447777

Epoch: 6| Step: 10
Training loss: 2.908092120058709
Validation loss: 2.7341645790622175

Epoch: 6| Step: 11
Training loss: 3.13146852503598
Validation loss: 2.7346803453068667

Epoch: 6| Step: 12
Training loss: 3.249289801834948
Validation loss: 2.739404625181244

Epoch: 6| Step: 13
Training loss: 3.705245557670795
Validation loss: 2.741399146326558

Epoch: 176| Step: 0
Training loss: 3.0612084915755156
Validation loss: 2.745797259916818

Epoch: 6| Step: 1
Training loss: 3.4543639847214176
Validation loss: 2.7550781902849093

Epoch: 6| Step: 2
Training loss: 3.2355813250837118
Validation loss: 2.757891181409736

Epoch: 6| Step: 3
Training loss: 2.409065185102005
Validation loss: 2.759901191254428

Epoch: 6| Step: 4
Training loss: 3.281588291713114
Validation loss: 2.7497428706712213

Epoch: 6| Step: 5
Training loss: 3.351154435932011
Validation loss: 2.7500178251686265

Epoch: 6| Step: 6
Training loss: 2.8761776709715132
Validation loss: 2.742848706462871

Epoch: 6| Step: 7
Training loss: 2.561018166426605
Validation loss: 2.7425760029540958

Epoch: 6| Step: 8
Training loss: 3.3674642002210664
Validation loss: 2.7408382542757925

Epoch: 6| Step: 9
Training loss: 2.799295326524831
Validation loss: 2.7374083969980765

Epoch: 6| Step: 10
Training loss: 3.2083877129508163
Validation loss: 2.736992509312826

Epoch: 6| Step: 11
Training loss: 2.965217978842085
Validation loss: 2.735522253077426

Epoch: 6| Step: 12
Training loss: 3.5072627327049086
Validation loss: 2.733672484174554

Epoch: 6| Step: 13
Training loss: 2.5891459403811212
Validation loss: 2.730726723476833

Epoch: 177| Step: 0
Training loss: 2.4137888139066495
Validation loss: 2.7400431015394693

Epoch: 6| Step: 1
Training loss: 2.9583155313591982
Validation loss: 2.7632457050187873

Epoch: 6| Step: 2
Training loss: 3.446040416124069
Validation loss: 2.775980650540937

Epoch: 6| Step: 3
Training loss: 3.127788367817193
Validation loss: 2.7691856282128047

Epoch: 6| Step: 4
Training loss: 3.468047612190104
Validation loss: 2.7452310470149928

Epoch: 6| Step: 5
Training loss: 3.585400243998983
Validation loss: 2.73233902426715

Epoch: 6| Step: 6
Training loss: 2.5275001536443797
Validation loss: 2.7357462801876564

Epoch: 6| Step: 7
Training loss: 3.433542088455209
Validation loss: 2.73459100623057

Epoch: 6| Step: 8
Training loss: 3.0261757449431497
Validation loss: 2.737408472856282

Epoch: 6| Step: 9
Training loss: 3.0286019940646125
Validation loss: 2.7392366922166187

Epoch: 6| Step: 10
Training loss: 2.8460660452990374
Validation loss: 2.7436720476231615

Epoch: 6| Step: 11
Training loss: 3.0494322389053496
Validation loss: 2.7417263048332483

Epoch: 6| Step: 12
Training loss: 3.028964724799077
Validation loss: 2.7450942099460844

Epoch: 6| Step: 13
Training loss: 2.521357479197036
Validation loss: 2.7400637955166642

Epoch: 178| Step: 0
Training loss: 2.978888936646514
Validation loss: 2.746028849142409

Epoch: 6| Step: 1
Training loss: 3.123449322295035
Validation loss: 2.7431985950641176

Epoch: 6| Step: 2
Training loss: 2.6627949582621064
Validation loss: 2.7410459659305957

Epoch: 6| Step: 3
Training loss: 3.293449466320537
Validation loss: 2.741974712901914

Epoch: 6| Step: 4
Training loss: 3.1500016106495448
Validation loss: 2.7371130650688418

Epoch: 6| Step: 5
Training loss: 2.943840002801981
Validation loss: 2.738589029907303

Epoch: 6| Step: 6
Training loss: 3.5160923625979077
Validation loss: 2.7386141692226666

Epoch: 6| Step: 7
Training loss: 2.8618506882037478
Validation loss: 2.7379329184184447

Epoch: 6| Step: 8
Training loss: 2.6758372057333597
Validation loss: 2.7367180452213606

Epoch: 6| Step: 9
Training loss: 3.2666176195420005
Validation loss: 2.7358322662199206

Epoch: 6| Step: 10
Training loss: 2.770563490116206
Validation loss: 2.7349933268534694

Epoch: 6| Step: 11
Training loss: 3.2093571767339957
Validation loss: 2.737203655534174

Epoch: 6| Step: 12
Training loss: 3.5865466030639706
Validation loss: 2.7368719009428966

Epoch: 6| Step: 13
Training loss: 2.5255687677343928
Validation loss: 2.7325636819954964

Epoch: 179| Step: 0
Training loss: 2.985826868136667
Validation loss: 2.732302743442054

Epoch: 6| Step: 1
Training loss: 2.8801978848608702
Validation loss: 2.7325050403329434

Epoch: 6| Step: 2
Training loss: 2.6975772796393556
Validation loss: 2.7325015764903937

Epoch: 6| Step: 3
Training loss: 2.6609790666596163
Validation loss: 2.7327809439924913

Epoch: 6| Step: 4
Training loss: 2.8071554477649183
Validation loss: 2.730724870260146

Epoch: 6| Step: 5
Training loss: 2.951657369531873
Validation loss: 2.7321072232726973

Epoch: 6| Step: 6
Training loss: 3.613880070734143
Validation loss: 2.733100817845427

Epoch: 6| Step: 7
Training loss: 3.084649157490149
Validation loss: 2.7348125533096224

Epoch: 6| Step: 8
Training loss: 3.7746552265694113
Validation loss: 2.740517590358366

Epoch: 6| Step: 9
Training loss: 3.579752056550419
Validation loss: 2.7392803701342365

Epoch: 6| Step: 10
Training loss: 3.0936573669745395
Validation loss: 2.732332902122812

Epoch: 6| Step: 11
Training loss: 2.091769406149884
Validation loss: 2.744063969023416

Epoch: 6| Step: 12
Training loss: 3.2066666538717015
Validation loss: 2.7320708605479167

Epoch: 6| Step: 13
Training loss: 2.8873204493329503
Validation loss: 2.731552877509445

Epoch: 180| Step: 0
Training loss: 3.1244813107135934
Validation loss: 2.726805204409282

Epoch: 6| Step: 1
Training loss: 2.9748911733517467
Validation loss: 2.730613265617986

Epoch: 6| Step: 2
Training loss: 2.71714226551803
Validation loss: 2.732278294803239

Epoch: 6| Step: 3
Training loss: 2.9358359960334073
Validation loss: 2.7347860010424756

Epoch: 6| Step: 4
Training loss: 3.4815478979889405
Validation loss: 2.74415217010962

Epoch: 6| Step: 5
Training loss: 2.9453678682420064
Validation loss: 2.735203920228694

Epoch: 6| Step: 6
Training loss: 2.9845469160643887
Validation loss: 2.7254709017339205

Epoch: 6| Step: 7
Training loss: 3.0919409192400957
Validation loss: 2.724327524642407

Epoch: 6| Step: 8
Training loss: 3.9711757665701652
Validation loss: 2.7266663501200865

Epoch: 6| Step: 9
Training loss: 2.160930584436523
Validation loss: 2.726831417900627

Epoch: 6| Step: 10
Training loss: 3.3313594377874254
Validation loss: 2.7283949698360335

Epoch: 6| Step: 11
Training loss: 2.8115717733666328
Validation loss: 2.730437707869048

Epoch: 6| Step: 12
Training loss: 2.8626330215663534
Validation loss: 2.7302241486853234

Epoch: 6| Step: 13
Training loss: 3.2311714266109393
Validation loss: 2.7298318612266397

Epoch: 181| Step: 0
Training loss: 2.859822889592792
Validation loss: 2.7258082456449957

Epoch: 6| Step: 1
Training loss: 2.6542172002448177
Validation loss: 2.7249842128576707

Epoch: 6| Step: 2
Training loss: 2.682741698995461
Validation loss: 2.72524647019075

Epoch: 6| Step: 3
Training loss: 2.753221012653914
Validation loss: 2.724724380336544

Epoch: 6| Step: 4
Training loss: 3.2849491158409974
Validation loss: 2.725572897221832

Epoch: 6| Step: 5
Training loss: 2.4411932524273907
Validation loss: 2.7273918413981484

Epoch: 6| Step: 6
Training loss: 2.9105501254008157
Validation loss: 2.7381422623637217

Epoch: 6| Step: 7
Training loss: 3.570853895545848
Validation loss: 2.7385534881102114

Epoch: 6| Step: 8
Training loss: 3.174205205964982
Validation loss: 2.725121320289424

Epoch: 6| Step: 9
Training loss: 3.567981986064512
Validation loss: 2.7239719566914786

Epoch: 6| Step: 10
Training loss: 3.4456121266839177
Validation loss: 2.724847799921913

Epoch: 6| Step: 11
Training loss: 2.835916986732801
Validation loss: 2.7223381859143276

Epoch: 6| Step: 12
Training loss: 2.9902748787875684
Validation loss: 2.7259533158676033

Epoch: 6| Step: 13
Training loss: 3.563646098709256
Validation loss: 2.72533677029564

Epoch: 182| Step: 0
Training loss: 2.6259253551161903
Validation loss: 2.7237418710343473

Epoch: 6| Step: 1
Training loss: 2.309926637417618
Validation loss: 2.727046010819661

Epoch: 6| Step: 2
Training loss: 3.1192724000616128
Validation loss: 2.7343392824808155

Epoch: 6| Step: 3
Training loss: 3.2545175699383018
Validation loss: 2.7438753263361932

Epoch: 6| Step: 4
Training loss: 3.2846550122500706
Validation loss: 2.7499468799207554

Epoch: 6| Step: 5
Training loss: 3.547437446800837
Validation loss: 2.7505463144202817

Epoch: 6| Step: 6
Training loss: 2.7561575703249837
Validation loss: 2.7350426721585603

Epoch: 6| Step: 7
Training loss: 3.079901787566793
Validation loss: 2.732250293585477

Epoch: 6| Step: 8
Training loss: 3.386368149294124
Validation loss: 2.7232517712762307

Epoch: 6| Step: 9
Training loss: 2.7999198152777276
Validation loss: 2.7259367750677175

Epoch: 6| Step: 10
Training loss: 3.2987373479591113
Validation loss: 2.7209933856320028

Epoch: 6| Step: 11
Training loss: 2.578375324465439
Validation loss: 2.728617066972463

Epoch: 6| Step: 12
Training loss: 3.25975567797314
Validation loss: 2.72701808654885

Epoch: 6| Step: 13
Training loss: 3.233217483752247
Validation loss: 2.7234392444258435

Epoch: 183| Step: 0
Training loss: 3.3650399637329023
Validation loss: 2.7297637224997113

Epoch: 6| Step: 1
Training loss: 3.1840697137494653
Validation loss: 2.7344003440045714

Epoch: 6| Step: 2
Training loss: 3.2068772087320037
Validation loss: 2.7368780639842005

Epoch: 6| Step: 3
Training loss: 3.4620958719008503
Validation loss: 2.738575309201307

Epoch: 6| Step: 4
Training loss: 3.519076539196143
Validation loss: 2.7313946595215035

Epoch: 6| Step: 5
Training loss: 3.211546605757442
Validation loss: 2.7253644945009414

Epoch: 6| Step: 6
Training loss: 2.785243392800908
Validation loss: 2.724264372207317

Epoch: 6| Step: 7
Training loss: 2.6285879954266185
Validation loss: 2.7280311078821686

Epoch: 6| Step: 8
Training loss: 2.9982682634056785
Validation loss: 2.7178542533643597

Epoch: 6| Step: 9
Training loss: 2.9783276708115376
Validation loss: 2.7216324161685597

Epoch: 6| Step: 10
Training loss: 2.752575795085474
Validation loss: 2.7188050280188194

Epoch: 6| Step: 11
Training loss: 2.4438187299268352
Validation loss: 2.7131797532331596

Epoch: 6| Step: 12
Training loss: 2.850635116482251
Validation loss: 2.7204649253336313

Epoch: 6| Step: 13
Training loss: 2.984421974331717
Validation loss: 2.720767632132626

Epoch: 184| Step: 0
Training loss: 2.8711170013939453
Validation loss: 2.722073147913541

Epoch: 6| Step: 1
Training loss: 3.1046556091974504
Validation loss: 2.7201390436181994

Epoch: 6| Step: 2
Training loss: 2.7388025677300805
Validation loss: 2.7245977094434863

Epoch: 6| Step: 3
Training loss: 2.8773150867004986
Validation loss: 2.7320580332635798

Epoch: 6| Step: 4
Training loss: 3.345069981229285
Validation loss: 2.7304895756901244

Epoch: 6| Step: 5
Training loss: 3.391271151664061
Validation loss: 2.7355776634404347

Epoch: 6| Step: 6
Training loss: 3.5563526319768615
Validation loss: 2.722356960630625

Epoch: 6| Step: 7
Training loss: 3.109863242917353
Validation loss: 2.728489704866177

Epoch: 6| Step: 8
Training loss: 2.952165397269759
Validation loss: 2.732091973357345

Epoch: 6| Step: 9
Training loss: 3.155203919750278
Validation loss: 2.7237727955868727

Epoch: 6| Step: 10
Training loss: 2.837777541782997
Validation loss: 2.7167185170399204

Epoch: 6| Step: 11
Training loss: 2.6496384859911197
Validation loss: 2.719179125469388

Epoch: 6| Step: 12
Training loss: 3.02847005258018
Validation loss: 2.714129252388062

Epoch: 6| Step: 13
Training loss: 2.6593815912149332
Validation loss: 2.71326653189856

Epoch: 185| Step: 0
Training loss: 3.3881903138556537
Validation loss: 2.715706951207056

Epoch: 6| Step: 1
Training loss: 3.000288631541738
Validation loss: 2.718847225658671

Epoch: 6| Step: 2
Training loss: 3.5004355295862184
Validation loss: 2.717870143459954

Epoch: 6| Step: 3
Training loss: 2.499119221982247
Validation loss: 2.719772853668351

Epoch: 6| Step: 4
Training loss: 3.568297637756163
Validation loss: 2.713552708347752

Epoch: 6| Step: 5
Training loss: 3.0425136553944534
Validation loss: 2.7135476869739112

Epoch: 6| Step: 6
Training loss: 3.105662828054987
Validation loss: 2.7096568682790245

Epoch: 6| Step: 7
Training loss: 2.5194661449921725
Validation loss: 2.7120138737671557

Epoch: 6| Step: 8
Training loss: 2.8400475849946916
Validation loss: 2.712107013519881

Epoch: 6| Step: 9
Training loss: 3.120072256131881
Validation loss: 2.71129434049218

Epoch: 6| Step: 10
Training loss: 3.0985098549016836
Validation loss: 2.7121141209048716

Epoch: 6| Step: 11
Training loss: 3.213591951855778
Validation loss: 2.712550021616193

Epoch: 6| Step: 12
Training loss: 3.0787950744922554
Validation loss: 2.7089857897891676

Epoch: 6| Step: 13
Training loss: 1.548041395225327
Validation loss: 2.7088226668270634

Epoch: 186| Step: 0
Training loss: 3.350946400886802
Validation loss: 2.720123673826829

Epoch: 6| Step: 1
Training loss: 3.1170224406585283
Validation loss: 2.7168641358409444

Epoch: 6| Step: 2
Training loss: 3.39081049117292
Validation loss: 2.7142794124256557

Epoch: 6| Step: 3
Training loss: 2.976754730505343
Validation loss: 2.7100216978697116

Epoch: 6| Step: 4
Training loss: 3.0571837701338986
Validation loss: 2.7101546878391796

Epoch: 6| Step: 5
Training loss: 2.8506812837343123
Validation loss: 2.707417396795249

Epoch: 6| Step: 6
Training loss: 2.6870271133627917
Validation loss: 2.7083185490535207

Epoch: 6| Step: 7
Training loss: 2.4932031744202496
Validation loss: 2.711709083677006

Epoch: 6| Step: 8
Training loss: 2.839375579316678
Validation loss: 2.716939098388489

Epoch: 6| Step: 9
Training loss: 2.855355193962987
Validation loss: 2.7146903961961004

Epoch: 6| Step: 10
Training loss: 3.039654436297332
Validation loss: 2.7118964614334504

Epoch: 6| Step: 11
Training loss: 3.1530968051402177
Validation loss: 2.716058311640732

Epoch: 6| Step: 12
Training loss: 3.3352776261147614
Validation loss: 2.716483137040215

Epoch: 6| Step: 13
Training loss: 3.457724015818479
Validation loss: 2.719671905670029

Epoch: 187| Step: 0
Training loss: 3.510787416042112
Validation loss: 2.7234313956491674

Epoch: 6| Step: 1
Training loss: 2.7719269413258525
Validation loss: 2.722208326347645

Epoch: 6| Step: 2
Training loss: 3.4248006498140584
Validation loss: 2.730028442088309

Epoch: 6| Step: 3
Training loss: 3.38061875181772
Validation loss: 2.752392286715455

Epoch: 6| Step: 4
Training loss: 2.6232789164921364
Validation loss: 2.768620786311695

Epoch: 6| Step: 5
Training loss: 3.202275605510853
Validation loss: 2.76317030087665

Epoch: 6| Step: 6
Training loss: 3.158787075922596
Validation loss: 2.7470997220634024

Epoch: 6| Step: 7
Training loss: 2.1521483400121357
Validation loss: 2.718725609590391

Epoch: 6| Step: 8
Training loss: 2.830060939065313
Validation loss: 2.710273627581484

Epoch: 6| Step: 9
Training loss: 3.488031359155358
Validation loss: 2.705441184117233

Epoch: 6| Step: 10
Training loss: 2.362145622357594
Validation loss: 2.704895789090047

Epoch: 6| Step: 11
Training loss: 3.605010858061757
Validation loss: 2.7045059380219048

Epoch: 6| Step: 12
Training loss: 2.9627011967193857
Validation loss: 2.7053602210807086

Epoch: 6| Step: 13
Training loss: 2.3857096085449525
Validation loss: 2.7045900518107895

Epoch: 188| Step: 0
Training loss: 3.596334838078641
Validation loss: 2.7032384071552746

Epoch: 6| Step: 1
Training loss: 2.0972274825119284
Validation loss: 2.7046745525524205

Epoch: 6| Step: 2
Training loss: 3.1282319712759925
Validation loss: 2.7054007986095456

Epoch: 6| Step: 3
Training loss: 2.6088620898115726
Validation loss: 2.7030359505201966

Epoch: 6| Step: 4
Training loss: 3.3349845293363933
Validation loss: 2.70171710514219

Epoch: 6| Step: 5
Training loss: 3.102738087976187
Validation loss: 2.708677860303764

Epoch: 6| Step: 6
Training loss: 3.3033482067441815
Validation loss: 2.707454396473785

Epoch: 6| Step: 7
Training loss: 3.215397690875242
Validation loss: 2.7068160231245932

Epoch: 6| Step: 8
Training loss: 3.5940832895722954
Validation loss: 2.707720274595789

Epoch: 6| Step: 9
Training loss: 2.6560257760945785
Validation loss: 2.704756819471072

Epoch: 6| Step: 10
Training loss: 2.6988170010128614
Validation loss: 2.702811547387703

Epoch: 6| Step: 11
Training loss: 2.620854692316479
Validation loss: 2.704407989181605

Epoch: 6| Step: 12
Training loss: 2.956396803325937
Validation loss: 2.709889925538407

Epoch: 6| Step: 13
Training loss: 3.3731762232274165
Validation loss: 2.7338720160816954

Epoch: 189| Step: 0
Training loss: 3.7108362445067447
Validation loss: 2.7446445726811675

Epoch: 6| Step: 1
Training loss: 3.5913741509673325
Validation loss: 2.727953463558284

Epoch: 6| Step: 2
Training loss: 2.9989657208606872
Validation loss: 2.7026651278037006

Epoch: 6| Step: 3
Training loss: 3.5415711932309977
Validation loss: 2.7026575525911456

Epoch: 6| Step: 4
Training loss: 2.983719838712699
Validation loss: 2.699022128772028

Epoch: 6| Step: 5
Training loss: 2.721998006535458
Validation loss: 2.703590792517449

Epoch: 6| Step: 6
Training loss: 2.7256480435082
Validation loss: 2.704300853664246

Epoch: 6| Step: 7
Training loss: 2.7518477734447613
Validation loss: 2.704523579602788

Epoch: 6| Step: 8
Training loss: 2.900060153205777
Validation loss: 2.7076448608295323

Epoch: 6| Step: 9
Training loss: 3.33913323948231
Validation loss: 2.7085930689478905

Epoch: 6| Step: 10
Training loss: 3.1460174270894137
Validation loss: 2.7189445393001286

Epoch: 6| Step: 11
Training loss: 2.1236296330335804
Validation loss: 2.72051638113742

Epoch: 6| Step: 12
Training loss: 2.8122433863238294
Validation loss: 2.7072272185173043

Epoch: 6| Step: 13
Training loss: 2.6735290404655045
Validation loss: 2.7159797879543377

Epoch: 190| Step: 0
Training loss: 2.762770478138614
Validation loss: 2.723850838613384

Epoch: 6| Step: 1
Training loss: 3.0332512295968144
Validation loss: 2.7157791062060914

Epoch: 6| Step: 2
Training loss: 2.6433275827711684
Validation loss: 2.7181784378269342

Epoch: 6| Step: 3
Training loss: 3.5706888413693907
Validation loss: 2.708494440655596

Epoch: 6| Step: 4
Training loss: 3.0360663778816366
Validation loss: 2.7106965232645104

Epoch: 6| Step: 5
Training loss: 2.8895753346511013
Validation loss: 2.7101851620341564

Epoch: 6| Step: 6
Training loss: 3.2960708866922293
Validation loss: 2.706738749569249

Epoch: 6| Step: 7
Training loss: 2.646609505373221
Validation loss: 2.710171187800485

Epoch: 6| Step: 8
Training loss: 3.2606221257190344
Validation loss: 2.7097426150038393

Epoch: 6| Step: 9
Training loss: 2.153412984294121
Validation loss: 2.711532745399835

Epoch: 6| Step: 10
Training loss: 3.020101436654588
Validation loss: 2.714633786986899

Epoch: 6| Step: 11
Training loss: 3.2537265833313573
Validation loss: 2.733323686249059

Epoch: 6| Step: 12
Training loss: 3.7909645576319595
Validation loss: 2.728883074921401

Epoch: 6| Step: 13
Training loss: 2.422921231616228
Validation loss: 2.709750516675109

Epoch: 191| Step: 0
Training loss: 2.785922294228606
Validation loss: 2.6953524840559018

Epoch: 6| Step: 1
Training loss: 2.97602434875413
Validation loss: 2.691882680587912

Epoch: 6| Step: 2
Training loss: 2.9741976898305467
Validation loss: 2.6933218932794687

Epoch: 6| Step: 3
Training loss: 3.260482462421221
Validation loss: 2.698966430497912

Epoch: 6| Step: 4
Training loss: 3.003683689638019
Validation loss: 2.7034861394345886

Epoch: 6| Step: 5
Training loss: 3.638773566077662
Validation loss: 2.7018506983922337

Epoch: 6| Step: 6
Training loss: 3.2566764918334976
Validation loss: 2.7014529602526602

Epoch: 6| Step: 7
Training loss: 2.4864765611376503
Validation loss: 2.7033288705607217

Epoch: 6| Step: 8
Training loss: 3.116448259775762
Validation loss: 2.6973659041737332

Epoch: 6| Step: 9
Training loss: 3.5670942163154717
Validation loss: 2.7022133804540482

Epoch: 6| Step: 10
Training loss: 2.970891240551157
Validation loss: 2.697389078256641

Epoch: 6| Step: 11
Training loss: 2.580168220743129
Validation loss: 2.700382539827382

Epoch: 6| Step: 12
Training loss: 2.7783995176264913
Validation loss: 2.700978045988129

Epoch: 6| Step: 13
Training loss: 2.7940319251855907
Validation loss: 2.6974433587961477

Epoch: 192| Step: 0
Training loss: 3.421000329671898
Validation loss: 2.6968907854114934

Epoch: 6| Step: 1
Training loss: 2.726827176864007
Validation loss: 2.6980734208784733

Epoch: 6| Step: 2
Training loss: 2.630899158564965
Validation loss: 2.6984450028474303

Epoch: 6| Step: 3
Training loss: 2.977965817595394
Validation loss: 2.6965672156520433

Epoch: 6| Step: 4
Training loss: 2.9375795394193225
Validation loss: 2.6939267455912472

Epoch: 6| Step: 5
Training loss: 3.0600545033107536
Validation loss: 2.6929129299874175

Epoch: 6| Step: 6
Training loss: 2.260359545101691
Validation loss: 2.692509174667779

Epoch: 6| Step: 7
Training loss: 3.118281657614626
Validation loss: 2.696469870708077

Epoch: 6| Step: 8
Training loss: 2.928648904446823
Validation loss: 2.6983418337313174

Epoch: 6| Step: 9
Training loss: 3.2599515410490065
Validation loss: 2.699922755984941

Epoch: 6| Step: 10
Training loss: 2.967745641168365
Validation loss: 2.695711347648183

Epoch: 6| Step: 11
Training loss: 3.29567837807024
Validation loss: 2.69772234275571

Epoch: 6| Step: 12
Training loss: 3.4682307499079315
Validation loss: 2.6958224267931223

Epoch: 6| Step: 13
Training loss: 3.2997409603290735
Validation loss: 2.7026107178416368

Epoch: 193| Step: 0
Training loss: 3.007888911874366
Validation loss: 2.7071679731008165

Epoch: 6| Step: 1
Training loss: 3.25727587335066
Validation loss: 2.7074848764433277

Epoch: 6| Step: 2
Training loss: 2.8270088648891543
Validation loss: 2.717042099164119

Epoch: 6| Step: 3
Training loss: 3.079894975382636
Validation loss: 2.7054784799331153

Epoch: 6| Step: 4
Training loss: 2.8740070120899137
Validation loss: 2.7087219268717404

Epoch: 6| Step: 5
Training loss: 2.9960533248780297
Validation loss: 2.710113115399315

Epoch: 6| Step: 6
Training loss: 3.8870764792975456
Validation loss: 2.7047730291541225

Epoch: 6| Step: 7
Training loss: 2.9658526286002806
Validation loss: 2.7055341995439237

Epoch: 6| Step: 8
Training loss: 2.7386869600702433
Validation loss: 2.696007129816958

Epoch: 6| Step: 9
Training loss: 2.6446504326564044
Validation loss: 2.7037054535615117

Epoch: 6| Step: 10
Training loss: 3.5201351820390507
Validation loss: 2.701792575247231

Epoch: 6| Step: 11
Training loss: 2.6227709070437246
Validation loss: 2.6945026833167764

Epoch: 6| Step: 12
Training loss: 2.420993669182537
Validation loss: 2.694004942380108

Epoch: 6| Step: 13
Training loss: 3.2697182149537283
Validation loss: 2.6887369621694046

Epoch: 194| Step: 0
Training loss: 2.771047502620586
Validation loss: 2.687253466147042

Epoch: 6| Step: 1
Training loss: 2.799429126854134
Validation loss: 2.68684401331882

Epoch: 6| Step: 2
Training loss: 3.5350742393802266
Validation loss: 2.68516360175882

Epoch: 6| Step: 3
Training loss: 2.833182012967666
Validation loss: 2.691189630630727

Epoch: 6| Step: 4
Training loss: 3.289635832554667
Validation loss: 2.6903515735628076

Epoch: 6| Step: 5
Training loss: 3.3804108373390385
Validation loss: 2.6873214797843272

Epoch: 6| Step: 6
Training loss: 2.927103189602404
Validation loss: 2.6876083575394647

Epoch: 6| Step: 7
Training loss: 3.375856502782719
Validation loss: 2.689803685047733

Epoch: 6| Step: 8
Training loss: 2.378677733020671
Validation loss: 2.692522244636091

Epoch: 6| Step: 9
Training loss: 2.795826464974788
Validation loss: 2.685995954059439

Epoch: 6| Step: 10
Training loss: 3.0727448668650807
Validation loss: 2.6862409704131407

Epoch: 6| Step: 11
Training loss: 2.5456813519237294
Validation loss: 2.6949541864046065

Epoch: 6| Step: 12
Training loss: 3.0379658659674242
Validation loss: 2.7016625337506532

Epoch: 6| Step: 13
Training loss: 3.5181929640339136
Validation loss: 2.707560639317288

Epoch: 195| Step: 0
Training loss: 2.649728286056742
Validation loss: 2.7185304293984225

Epoch: 6| Step: 1
Training loss: 3.093642878363645
Validation loss: 2.70915969534579

Epoch: 6| Step: 2
Training loss: 3.2933521703678164
Validation loss: 2.7119078933008915

Epoch: 6| Step: 3
Training loss: 3.7925211743522484
Validation loss: 2.7081505504737136

Epoch: 6| Step: 4
Training loss: 2.1728678019056074
Validation loss: 2.6923892435350267

Epoch: 6| Step: 5
Training loss: 2.4399688151195917
Validation loss: 2.68270662998416

Epoch: 6| Step: 6
Training loss: 3.2390352298602556
Validation loss: 2.677400881304108

Epoch: 6| Step: 7
Training loss: 3.4210284853866897
Validation loss: 2.682666061815457

Epoch: 6| Step: 8
Training loss: 2.9250112419238423
Validation loss: 2.680473110828227

Epoch: 6| Step: 9
Training loss: 2.882647419159769
Validation loss: 2.6802156156905026

Epoch: 6| Step: 10
Training loss: 3.0492832154543725
Validation loss: 2.6787659515752233

Epoch: 6| Step: 11
Training loss: 2.6058403333523765
Validation loss: 2.684791939535318

Epoch: 6| Step: 12
Training loss: 3.370575724700809
Validation loss: 2.682873860651156

Epoch: 6| Step: 13
Training loss: 2.8404496712707257
Validation loss: 2.6859932796977652

Epoch: 196| Step: 0
Training loss: 3.0558901709548523
Validation loss: 2.680476189521475

Epoch: 6| Step: 1
Training loss: 2.117742261663283
Validation loss: 2.683063488187075

Epoch: 6| Step: 2
Training loss: 3.2208591698666766
Validation loss: 2.681262918365587

Epoch: 6| Step: 3
Training loss: 3.142021665744884
Validation loss: 2.683215027505999

Epoch: 6| Step: 4
Training loss: 2.9531392092085404
Validation loss: 2.6797365377662854

Epoch: 6| Step: 5
Training loss: 3.220842144465927
Validation loss: 2.6821040035985235

Epoch: 6| Step: 6
Training loss: 2.5438630250007215
Validation loss: 2.6787701203641805

Epoch: 6| Step: 7
Training loss: 2.4184199144922083
Validation loss: 2.6829811666734993

Epoch: 6| Step: 8
Training loss: 3.186154698727165
Validation loss: 2.6840588764710276

Epoch: 6| Step: 9
Training loss: 3.439426783775481
Validation loss: 2.6874584605924188

Epoch: 6| Step: 10
Training loss: 2.944186129325272
Validation loss: 2.7048710368073734

Epoch: 6| Step: 11
Training loss: 3.0831598456435994
Validation loss: 2.699575433009012

Epoch: 6| Step: 12
Training loss: 3.711155421232972
Validation loss: 2.703953668302701

Epoch: 6| Step: 13
Training loss: 2.835061014046989
Validation loss: 2.705012438139356

Epoch: 197| Step: 0
Training loss: 3.8389188597546298
Validation loss: 2.701808096761888

Epoch: 6| Step: 1
Training loss: 3.0596289119228683
Validation loss: 2.700151008984687

Epoch: 6| Step: 2
Training loss: 2.921100044498768
Validation loss: 2.6914018188346738

Epoch: 6| Step: 3
Training loss: 2.556594556797037
Validation loss: 2.694224502094291

Epoch: 6| Step: 4
Training loss: 2.7363619315586525
Validation loss: 2.6896695525292875

Epoch: 6| Step: 5
Training loss: 3.317989766606973
Validation loss: 2.6928686875432506

Epoch: 6| Step: 6
Training loss: 3.625229532275457
Validation loss: 2.7060546003417683

Epoch: 6| Step: 7
Training loss: 3.054840318218288
Validation loss: 2.7086933622393867

Epoch: 6| Step: 8
Training loss: 2.677063482980323
Validation loss: 2.707234124700568

Epoch: 6| Step: 9
Training loss: 2.914226455780554
Validation loss: 2.711515956848131

Epoch: 6| Step: 10
Training loss: 2.3807741545774053
Validation loss: 2.686909879096782

Epoch: 6| Step: 11
Training loss: 2.575824983160166
Validation loss: 2.6821920218488513

Epoch: 6| Step: 12
Training loss: 2.8244272579821073
Validation loss: 2.6760138738461303

Epoch: 6| Step: 13
Training loss: 3.6675546755677426
Validation loss: 2.6788590577681175

Epoch: 198| Step: 0
Training loss: 2.9263281521144244
Validation loss: 2.6784725084218985

Epoch: 6| Step: 1
Training loss: 2.188200811115014
Validation loss: 2.682373083551371

Epoch: 6| Step: 2
Training loss: 2.0901378389015184
Validation loss: 2.682520302047154

Epoch: 6| Step: 3
Training loss: 3.1591882908982543
Validation loss: 2.682888492109961

Epoch: 6| Step: 4
Training loss: 3.008507744830983
Validation loss: 2.6834301945650876

Epoch: 6| Step: 5
Training loss: 2.6892819374360464
Validation loss: 2.681880261731467

Epoch: 6| Step: 6
Training loss: 2.99412533631126
Validation loss: 2.687507858322113

Epoch: 6| Step: 7
Training loss: 2.948601058038013
Validation loss: 2.681506019143346

Epoch: 6| Step: 8
Training loss: 3.309820855124576
Validation loss: 2.6830890206723885

Epoch: 6| Step: 9
Training loss: 3.2176734086785426
Validation loss: 2.679545413797939

Epoch: 6| Step: 10
Training loss: 3.646147243972937
Validation loss: 2.6775074147243867

Epoch: 6| Step: 11
Training loss: 3.054750876000973
Validation loss: 2.678011980265062

Epoch: 6| Step: 12
Training loss: 3.559250269605869
Validation loss: 2.674155898076346

Epoch: 6| Step: 13
Training loss: 3.2676223414428396
Validation loss: 2.675420868726996

Epoch: 199| Step: 0
Training loss: 3.3169479736443384
Validation loss: 2.675225089639748

Epoch: 6| Step: 1
Training loss: 3.369827120956545
Validation loss: 2.678168382923983

Epoch: 6| Step: 2
Training loss: 2.937339291336082
Validation loss: 2.683672895546766

Epoch: 6| Step: 3
Training loss: 3.0593404236068023
Validation loss: 2.6853880037242037

Epoch: 6| Step: 4
Training loss: 3.071060671903552
Validation loss: 2.684157992900107

Epoch: 6| Step: 5
Training loss: 2.876480882140506
Validation loss: 2.684834213427385

Epoch: 6| Step: 6
Training loss: 2.5158268628369425
Validation loss: 2.6933537686708933

Epoch: 6| Step: 7
Training loss: 3.214098337555048
Validation loss: 2.6830805990494575

Epoch: 6| Step: 8
Training loss: 2.8199377260028164
Validation loss: 2.6841895535329634

Epoch: 6| Step: 9
Training loss: 3.011549651746031
Validation loss: 2.6889003149445383

Epoch: 6| Step: 10
Training loss: 2.982945923895989
Validation loss: 2.682303463967354

Epoch: 6| Step: 11
Training loss: 2.803110343358944
Validation loss: 2.6814525106784606

Epoch: 6| Step: 12
Training loss: 3.135381620259819
Validation loss: 2.6771712277760016

Epoch: 6| Step: 13
Training loss: 2.873288515925951
Validation loss: 2.6747368118128785

Epoch: 200| Step: 0
Training loss: 3.001133227890807
Validation loss: 2.6740133281201377

Epoch: 6| Step: 1
Training loss: 3.3222604579986275
Validation loss: 2.675679741258797

Epoch: 6| Step: 2
Training loss: 3.136766179202441
Validation loss: 2.67606482593353

Epoch: 6| Step: 3
Training loss: 2.8188126821378536
Validation loss: 2.6806127536022757

Epoch: 6| Step: 4
Training loss: 2.8593836716483945
Validation loss: 2.687917352137176

Epoch: 6| Step: 5
Training loss: 2.6974180097024973
Validation loss: 2.6732637415634493

Epoch: 6| Step: 6
Training loss: 3.136075344581908
Validation loss: 2.68432240555014

Epoch: 6| Step: 7
Training loss: 3.2306609275327123
Validation loss: 2.6762980621384664

Epoch: 6| Step: 8
Training loss: 2.954084613846008
Validation loss: 2.674304039604674

Epoch: 6| Step: 9
Training loss: 2.9686565183678377
Validation loss: 2.670339326655303

Epoch: 6| Step: 10
Training loss: 3.389780528298152
Validation loss: 2.6719844507610273

Epoch: 6| Step: 11
Training loss: 2.2936395187172045
Validation loss: 2.6704154838621204

Epoch: 6| Step: 12
Training loss: 3.0339342011248975
Validation loss: 2.676604393323128

Epoch: 6| Step: 13
Training loss: 3.2500660229359006
Validation loss: 2.675225188343585

Epoch: 201| Step: 0
Training loss: 3.0393563645780137
Validation loss: 2.6734655664429177

Epoch: 6| Step: 1
Training loss: 3.3217429995215775
Validation loss: 2.6754637554165743

Epoch: 6| Step: 2
Training loss: 3.182934951486679
Validation loss: 2.6749578552943625

Epoch: 6| Step: 3
Training loss: 3.349409785872175
Validation loss: 2.676078749309266

Epoch: 6| Step: 4
Training loss: 2.9043425176095754
Validation loss: 2.673982915305866

Epoch: 6| Step: 5
Training loss: 2.1730622264450785
Validation loss: 2.6757472979310215

Epoch: 6| Step: 6
Training loss: 2.971129096575998
Validation loss: 2.6727161399165835

Epoch: 6| Step: 7
Training loss: 3.0565535755376243
Validation loss: 2.6748617045063816

Epoch: 6| Step: 8
Training loss: 2.9164181921341688
Validation loss: 2.672220758119015

Epoch: 6| Step: 9
Training loss: 3.0137775672085314
Validation loss: 2.673389267894659

Epoch: 6| Step: 10
Training loss: 2.7856662277994895
Validation loss: 2.6722777065016445

Epoch: 6| Step: 11
Training loss: 3.1168703764029617
Validation loss: 2.674020976808917

Epoch: 6| Step: 12
Training loss: 3.152962511637663
Validation loss: 2.677963145460318

Epoch: 6| Step: 13
Training loss: 3.14512926184767
Validation loss: 2.6759711894936284

Epoch: 202| Step: 0
Training loss: 2.7525427073700413
Validation loss: 2.6978616158123674

Epoch: 6| Step: 1
Training loss: 2.6467103080450483
Validation loss: 2.7141587969202274

Epoch: 6| Step: 2
Training loss: 3.377176783729933
Validation loss: 2.7158258903863164

Epoch: 6| Step: 3
Training loss: 2.6740213439991165
Validation loss: 2.7028100847866816

Epoch: 6| Step: 4
Training loss: 3.2560485894704008
Validation loss: 2.693088931043563

Epoch: 6| Step: 5
Training loss: 3.874100611509167
Validation loss: 2.667948565341203

Epoch: 6| Step: 6
Training loss: 3.278911956498564
Validation loss: 2.669902987934377

Epoch: 6| Step: 7
Training loss: 3.0182174054833584
Validation loss: 2.661204210331909

Epoch: 6| Step: 8
Training loss: 2.694632889580125
Validation loss: 2.6693290320333873

Epoch: 6| Step: 9
Training loss: 3.129252782484114
Validation loss: 2.66752531247043

Epoch: 6| Step: 10
Training loss: 2.5863467350785574
Validation loss: 2.6662680830509906

Epoch: 6| Step: 11
Training loss: 3.4235696297884415
Validation loss: 2.669341721852737

Epoch: 6| Step: 12
Training loss: 2.5175350354208645
Validation loss: 2.6737608611748978

Epoch: 6| Step: 13
Training loss: 2.1586498229744304
Validation loss: 2.670890451602193

Epoch: 203| Step: 0
Training loss: 3.2120512355741795
Validation loss: 2.6783327909112056

Epoch: 6| Step: 1
Training loss: 3.367457403353949
Validation loss: 2.686420336366038

Epoch: 6| Step: 2
Training loss: 2.8274491487849684
Validation loss: 2.676719352219389

Epoch: 6| Step: 3
Training loss: 3.215885109571526
Validation loss: 2.6781544120202465

Epoch: 6| Step: 4
Training loss: 2.9515211806224744
Validation loss: 2.6684181059451584

Epoch: 6| Step: 5
Training loss: 3.096669986532818
Validation loss: 2.6718385803430933

Epoch: 6| Step: 6
Training loss: 2.7257938558560886
Validation loss: 2.668418378793668

Epoch: 6| Step: 7
Training loss: 3.3918927191557398
Validation loss: 2.6728195519476343

Epoch: 6| Step: 8
Training loss: 2.51910358909844
Validation loss: 2.66362537558872

Epoch: 6| Step: 9
Training loss: 3.150924268484969
Validation loss: 2.678203953597577

Epoch: 6| Step: 10
Training loss: 2.6856813709219014
Validation loss: 2.6783858563216523

Epoch: 6| Step: 11
Training loss: 3.1496334407605637
Validation loss: 2.688425309730226

Epoch: 6| Step: 12
Training loss: 2.717974058772706
Validation loss: 2.7013846001409694

Epoch: 6| Step: 13
Training loss: 2.8419339595909454
Validation loss: 2.7159041457246897

Epoch: 204| Step: 0
Training loss: 3.1588525900505307
Validation loss: 2.7395964915820765

Epoch: 6| Step: 1
Training loss: 2.9526187523354697
Validation loss: 2.7701604598073764

Epoch: 6| Step: 2
Training loss: 2.850740329890956
Validation loss: 2.755890863812719

Epoch: 6| Step: 3
Training loss: 2.0442369073535067
Validation loss: 2.7504251362167547

Epoch: 6| Step: 4
Training loss: 2.6787387069058246
Validation loss: 2.6955477932402907

Epoch: 6| Step: 5
Training loss: 3.184538119614573
Validation loss: 2.6756541735213144

Epoch: 6| Step: 6
Training loss: 3.0756593695094026
Validation loss: 2.664243083883055

Epoch: 6| Step: 7
Training loss: 3.0516328099398953
Validation loss: 2.664944002595597

Epoch: 6| Step: 8
Training loss: 3.3825139361064136
Validation loss: 2.6765076407823614

Epoch: 6| Step: 9
Training loss: 3.1593048118092213
Validation loss: 2.69115644357392

Epoch: 6| Step: 10
Training loss: 3.2741453730071277
Validation loss: 2.718014225392189

Epoch: 6| Step: 11
Training loss: 3.4408605621386426
Validation loss: 2.6866470284450235

Epoch: 6| Step: 12
Training loss: 2.72021637757148
Validation loss: 2.675905693962232

Epoch: 6| Step: 13
Training loss: 3.263304693728259
Validation loss: 2.66895880907609

Epoch: 205| Step: 0
Training loss: 2.9046152090482273
Validation loss: 2.6643460059469155

Epoch: 6| Step: 1
Training loss: 3.125314925537755
Validation loss: 2.674025352408955

Epoch: 6| Step: 2
Training loss: 2.4135784169970314
Validation loss: 2.705565606049779

Epoch: 6| Step: 3
Training loss: 3.1004618269943935
Validation loss: 2.7456468291906604

Epoch: 6| Step: 4
Training loss: 3.135595745325055
Validation loss: 2.7680657519259855

Epoch: 6| Step: 5
Training loss: 3.1291567812855328
Validation loss: 2.8014077712821797

Epoch: 6| Step: 6
Training loss: 2.9046675773212347
Validation loss: 2.7870683893320627

Epoch: 6| Step: 7
Training loss: 3.282646535956818
Validation loss: 2.7735173113539986

Epoch: 6| Step: 8
Training loss: 3.279227223659136
Validation loss: 2.7341072385039378

Epoch: 6| Step: 9
Training loss: 3.1233681041800025
Validation loss: 2.7188434143953484

Epoch: 6| Step: 10
Training loss: 3.3042576287068894
Validation loss: 2.695197141371373

Epoch: 6| Step: 11
Training loss: 2.8851545377757746
Validation loss: 2.6843721694622893

Epoch: 6| Step: 12
Training loss: 3.0181504185266412
Validation loss: 2.6757784552485084

Epoch: 6| Step: 13
Training loss: 2.185961372948625
Validation loss: 2.662736931899937

Epoch: 206| Step: 0
Training loss: 3.2837677514939987
Validation loss: 2.6667250471748956

Epoch: 6| Step: 1
Training loss: 2.6040769230955765
Validation loss: 2.664925565095093

Epoch: 6| Step: 2
Training loss: 2.7609383048211282
Validation loss: 2.6649415745401086

Epoch: 6| Step: 3
Training loss: 3.5413094433913197
Validation loss: 2.663944961475708

Epoch: 6| Step: 4
Training loss: 3.0650725167238506
Validation loss: 2.669100232298772

Epoch: 6| Step: 5
Training loss: 3.1667469081416355
Validation loss: 2.6692093550322507

Epoch: 6| Step: 6
Training loss: 3.2774633447152612
Validation loss: 2.668771365677375

Epoch: 6| Step: 7
Training loss: 2.794614251119649
Validation loss: 2.6699960008804577

Epoch: 6| Step: 8
Training loss: 2.946245202637992
Validation loss: 2.664484012052852

Epoch: 6| Step: 9
Training loss: 2.8642268473437005
Validation loss: 2.669207021139086

Epoch: 6| Step: 10
Training loss: 3.2356013677425564
Validation loss: 2.6675847771343855

Epoch: 6| Step: 11
Training loss: 3.0268182507617682
Validation loss: 2.663012278714427

Epoch: 6| Step: 12
Training loss: 2.5000329969135886
Validation loss: 2.659743342824495

Epoch: 6| Step: 13
Training loss: 3.0862068155325795
Validation loss: 2.6652640267291137

Epoch: 207| Step: 0
Training loss: 2.491237255930903
Validation loss: 2.661641437640749

Epoch: 6| Step: 1
Training loss: 3.2530170521704043
Validation loss: 2.660785657869107

Epoch: 6| Step: 2
Training loss: 2.501055113345701
Validation loss: 2.6562207890544514

Epoch: 6| Step: 3
Training loss: 2.991550307990701
Validation loss: 2.6630428139289157

Epoch: 6| Step: 4
Training loss: 3.736321616279289
Validation loss: 2.665167999476289

Epoch: 6| Step: 5
Training loss: 3.014287464216237
Validation loss: 2.6672380499222825

Epoch: 6| Step: 6
Training loss: 3.3574394860285643
Validation loss: 2.67342203110288

Epoch: 6| Step: 7
Training loss: 2.59010343558657
Validation loss: 2.673881465810937

Epoch: 6| Step: 8
Training loss: 2.5111472516380196
Validation loss: 2.6828672787620045

Epoch: 6| Step: 9
Training loss: 3.0212981469354827
Validation loss: 2.6942279171402173

Epoch: 6| Step: 10
Training loss: 3.3635935710368763
Validation loss: 2.704131008021604

Epoch: 6| Step: 11
Training loss: 3.095789227657083
Validation loss: 2.668164367811961

Epoch: 6| Step: 12
Training loss: 2.962782795602961
Validation loss: 2.6630083904289052

Epoch: 6| Step: 13
Training loss: 3.002511244982293
Validation loss: 2.6564049942765804

Epoch: 208| Step: 0
Training loss: 3.0939978297989774
Validation loss: 2.661280914096105

Epoch: 6| Step: 1
Training loss: 2.906645717137053
Validation loss: 2.661334382124717

Epoch: 6| Step: 2
Training loss: 3.377406922137188
Validation loss: 2.657847648467722

Epoch: 6| Step: 3
Training loss: 2.4053454990410588
Validation loss: 2.6593903645534476

Epoch: 6| Step: 4
Training loss: 2.5480493751664492
Validation loss: 2.659276574005241

Epoch: 6| Step: 5
Training loss: 3.227439631836425
Validation loss: 2.6568373492197623

Epoch: 6| Step: 6
Training loss: 2.563035862416141
Validation loss: 2.657435189079444

Epoch: 6| Step: 7
Training loss: 2.753349951431457
Validation loss: 2.6574493750265105

Epoch: 6| Step: 8
Training loss: 2.7429100888682507
Validation loss: 2.654169353289861

Epoch: 6| Step: 9
Training loss: 3.452767608237505
Validation loss: 2.6587503130176344

Epoch: 6| Step: 10
Training loss: 3.193223489559173
Validation loss: 2.6584513335594786

Epoch: 6| Step: 11
Training loss: 2.6489905396030107
Validation loss: 2.659173775804027

Epoch: 6| Step: 12
Training loss: 3.7518706424350396
Validation loss: 2.6550512418612064

Epoch: 6| Step: 13
Training loss: 3.290746986903053
Validation loss: 2.658137051342517

Epoch: 209| Step: 0
Training loss: 3.392240640372499
Validation loss: 2.664151690707219

Epoch: 6| Step: 1
Training loss: 2.86975066241667
Validation loss: 2.6543845124402634

Epoch: 6| Step: 2
Training loss: 2.624786549927103
Validation loss: 2.663834152561248

Epoch: 6| Step: 3
Training loss: 3.1673163366625157
Validation loss: 2.675088288371432

Epoch: 6| Step: 4
Training loss: 3.0438813982101256
Validation loss: 2.6806671868784675

Epoch: 6| Step: 5
Training loss: 2.3855612987221555
Validation loss: 2.6854392056327683

Epoch: 6| Step: 6
Training loss: 3.3772473800008576
Validation loss: 2.6843752198081505

Epoch: 6| Step: 7
Training loss: 2.8988290198422013
Validation loss: 2.6779332035111345

Epoch: 6| Step: 8
Training loss: 2.95373367414834
Validation loss: 2.6680354949265963

Epoch: 6| Step: 9
Training loss: 3.390645954401336
Validation loss: 2.6642760577112288

Epoch: 6| Step: 10
Training loss: 2.539416291457224
Validation loss: 2.662817586949036

Epoch: 6| Step: 11
Training loss: 3.245088534095212
Validation loss: 2.6612116126151197

Epoch: 6| Step: 12
Training loss: 3.2485138356174126
Validation loss: 2.6689792905834624

Epoch: 6| Step: 13
Training loss: 2.2289364657274358
Validation loss: 2.666440007808598

Epoch: 210| Step: 0
Training loss: 3.2681387393594767
Validation loss: 2.6664764877410003

Epoch: 6| Step: 1
Training loss: 3.489200415407432
Validation loss: 2.670335835936595

Epoch: 6| Step: 2
Training loss: 3.128381959038989
Validation loss: 2.6702933478790802

Epoch: 6| Step: 3
Training loss: 2.543888517540195
Validation loss: 2.65977246014375

Epoch: 6| Step: 4
Training loss: 2.9947839532282914
Validation loss: 2.656503853198109

Epoch: 6| Step: 5
Training loss: 2.6014305287472963
Validation loss: 2.655160419632661

Epoch: 6| Step: 6
Training loss: 3.233738933436653
Validation loss: 2.6544862579861572

Epoch: 6| Step: 7
Training loss: 2.6145022152985966
Validation loss: 2.6542318901890036

Epoch: 6| Step: 8
Training loss: 3.1579381375091047
Validation loss: 2.6550573761270484

Epoch: 6| Step: 9
Training loss: 3.1058390846400483
Validation loss: 2.6522846279670964

Epoch: 6| Step: 10
Training loss: 2.8103532863640552
Validation loss: 2.6470876628415443

Epoch: 6| Step: 11
Training loss: 2.49031728569085
Validation loss: 2.651736804730687

Epoch: 6| Step: 12
Training loss: 2.858019564861284
Validation loss: 2.6529204297611164

Epoch: 6| Step: 13
Training loss: 3.683836199810422
Validation loss: 2.6490521729368175

Epoch: 211| Step: 0
Training loss: 3.2358165237601857
Validation loss: 2.6626041780008687

Epoch: 6| Step: 1
Training loss: 2.582840831529664
Validation loss: 2.6614169609290212

Epoch: 6| Step: 2
Training loss: 2.4836177031594007
Validation loss: 2.677143250590459

Epoch: 6| Step: 3
Training loss: 3.3541868379037703
Validation loss: 2.6867954163310404

Epoch: 6| Step: 4
Training loss: 2.7022294341515343
Validation loss: 2.706268734911975

Epoch: 6| Step: 5
Training loss: 2.905966139846199
Validation loss: 2.7151230365132095

Epoch: 6| Step: 6
Training loss: 3.032605998552409
Validation loss: 2.7369499671367965

Epoch: 6| Step: 7
Training loss: 3.331700513196129
Validation loss: 2.7208991169795516

Epoch: 6| Step: 8
Training loss: 2.6066291661341494
Validation loss: 2.703561761184999

Epoch: 6| Step: 9
Training loss: 3.579620182198624
Validation loss: 2.6677775152232654

Epoch: 6| Step: 10
Training loss: 2.399394288717107
Validation loss: 2.657844789524722

Epoch: 6| Step: 11
Training loss: 3.198104422128275
Validation loss: 2.6457364412846593

Epoch: 6| Step: 12
Training loss: 2.96282238715093
Validation loss: 2.645560846370375

Epoch: 6| Step: 13
Training loss: 3.431600745223952
Validation loss: 2.6456825543469065

Epoch: 212| Step: 0
Training loss: 3.0583927872896273
Validation loss: 2.642261712193536

Epoch: 6| Step: 1
Training loss: 3.77240064445897
Validation loss: 2.6476800520101804

Epoch: 6| Step: 2
Training loss: 3.05938842895179
Validation loss: 2.647903245719379

Epoch: 6| Step: 3
Training loss: 3.0374210111920537
Validation loss: 2.647383347203283

Epoch: 6| Step: 4
Training loss: 2.807731655275245
Validation loss: 2.645979842267862

Epoch: 6| Step: 5
Training loss: 2.6138527648660137
Validation loss: 2.6391998841411364

Epoch: 6| Step: 6
Training loss: 3.195576029685262
Validation loss: 2.6446033965432085

Epoch: 6| Step: 7
Training loss: 2.990594105974506
Validation loss: 2.647287738529639

Epoch: 6| Step: 8
Training loss: 2.6587283073225447
Validation loss: 2.662343180916699

Epoch: 6| Step: 9
Training loss: 3.169781976175847
Validation loss: 2.6806794079737095

Epoch: 6| Step: 10
Training loss: 2.9948919041762085
Validation loss: 2.704602653913951

Epoch: 6| Step: 11
Training loss: 2.791169554067474
Validation loss: 2.723541158803138

Epoch: 6| Step: 12
Training loss: 2.389639458056791
Validation loss: 2.734141010638706

Epoch: 6| Step: 13
Training loss: 3.2502957722985575
Validation loss: 2.7679177493990794

Epoch: 213| Step: 0
Training loss: 3.612266142248392
Validation loss: 2.7835749833009977

Epoch: 6| Step: 1
Training loss: 2.6083159896062713
Validation loss: 2.756397937640953

Epoch: 6| Step: 2
Training loss: 2.2576338225417714
Validation loss: 2.759567835747907

Epoch: 6| Step: 3
Training loss: 3.6995170174929224
Validation loss: 2.730097907629531

Epoch: 6| Step: 4
Training loss: 3.6181043612230384
Validation loss: 2.7176346896313235

Epoch: 6| Step: 5
Training loss: 2.5866775606194725
Validation loss: 2.689055995646454

Epoch: 6| Step: 6
Training loss: 3.3554617867269863
Validation loss: 2.6820459572091977

Epoch: 6| Step: 7
Training loss: 2.9059464490961715
Validation loss: 2.6748850476791373

Epoch: 6| Step: 8
Training loss: 3.1422048362432
Validation loss: 2.660330151095638

Epoch: 6| Step: 9
Training loss: 3.046540540286776
Validation loss: 2.654314964258328

Epoch: 6| Step: 10
Training loss: 1.7554091914980812
Validation loss: 2.649749379642435

Epoch: 6| Step: 11
Training loss: 2.5058105654285265
Validation loss: 2.6543812721336906

Epoch: 6| Step: 12
Training loss: 3.2476569312679704
Validation loss: 2.6552412700662362

Epoch: 6| Step: 13
Training loss: 3.603953066690683
Validation loss: 2.6525259938050367

Epoch: 214| Step: 0
Training loss: 3.410458266265327
Validation loss: 2.6558707008054987

Epoch: 6| Step: 1
Training loss: 2.804242622136568
Validation loss: 2.6635640881327887

Epoch: 6| Step: 2
Training loss: 2.7676877879704764
Validation loss: 2.6597947126201

Epoch: 6| Step: 3
Training loss: 2.6760018584924925
Validation loss: 2.6601557132089835

Epoch: 6| Step: 4
Training loss: 3.377406922137188
Validation loss: 2.660795923836302

Epoch: 6| Step: 5
Training loss: 2.71138933357515
Validation loss: 2.6526808712865626

Epoch: 6| Step: 6
Training loss: 3.444984610734957
Validation loss: 2.64918308989888

Epoch: 6| Step: 7
Training loss: 3.577222951935141
Validation loss: 2.649735708788918

Epoch: 6| Step: 8
Training loss: 3.2460183916399403
Validation loss: 2.6495296573599236

Epoch: 6| Step: 9
Training loss: 2.3401995405884746
Validation loss: 2.6477277267286854

Epoch: 6| Step: 10
Training loss: 2.2120203392652704
Validation loss: 2.6477103941756583

Epoch: 6| Step: 11
Training loss: 3.12210803684786
Validation loss: 2.6453335407619756

Epoch: 6| Step: 12
Training loss: 2.4559862495124416
Validation loss: 2.646831620292833

Epoch: 6| Step: 13
Training loss: 3.898975159410633
Validation loss: 2.6434440227632634

Epoch: 215| Step: 0
Training loss: 3.2014182405006615
Validation loss: 2.6450711865114234

Epoch: 6| Step: 1
Training loss: 2.6901265106799594
Validation loss: 2.6441342701776924

Epoch: 6| Step: 2
Training loss: 2.6783451021035196
Validation loss: 2.6414496341749834

Epoch: 6| Step: 3
Training loss: 3.3675961700051564
Validation loss: 2.6445588131510593

Epoch: 6| Step: 4
Training loss: 2.9365258732218864
Validation loss: 2.6435677590006037

Epoch: 6| Step: 5
Training loss: 3.572371742503597
Validation loss: 2.6454934975916307

Epoch: 6| Step: 6
Training loss: 3.295430377644378
Validation loss: 2.6465009813151346

Epoch: 6| Step: 7
Training loss: 2.7571035019489174
Validation loss: 2.6639046878929244

Epoch: 6| Step: 8
Training loss: 2.99921025371615
Validation loss: 2.6632241927597753

Epoch: 6| Step: 9
Training loss: 2.837089871918973
Validation loss: 2.6589124593489104

Epoch: 6| Step: 10
Training loss: 2.880724970381669
Validation loss: 2.650058038679262

Epoch: 6| Step: 11
Training loss: 2.5329042845185583
Validation loss: 2.6308474964289923

Epoch: 6| Step: 12
Training loss: 2.5429160585818895
Validation loss: 2.633836480569556

Epoch: 6| Step: 13
Training loss: 3.5870273238822468
Validation loss: 2.6312310965010033

Epoch: 216| Step: 0
Training loss: 2.807585937326085
Validation loss: 2.6352097089846227

Epoch: 6| Step: 1
Training loss: 3.1934459802858584
Validation loss: 2.636663631590801

Epoch: 6| Step: 2
Training loss: 3.0538686449922334
Validation loss: 2.635224108941058

Epoch: 6| Step: 3
Training loss: 3.184311712083463
Validation loss: 2.6302670961531174

Epoch: 6| Step: 4
Training loss: 2.905772508342533
Validation loss: 2.633863193982085

Epoch: 6| Step: 5
Training loss: 2.9895296169510415
Validation loss: 2.6332235102210793

Epoch: 6| Step: 6
Training loss: 2.8219868347379955
Validation loss: 2.6348865609319767

Epoch: 6| Step: 7
Training loss: 2.8748542085253432
Validation loss: 2.629043295410771

Epoch: 6| Step: 8
Training loss: 3.3469721875296004
Validation loss: 2.6312558088403395

Epoch: 6| Step: 9
Training loss: 3.0800528903234667
Validation loss: 2.6309178169831946

Epoch: 6| Step: 10
Training loss: 2.512662861418413
Validation loss: 2.638839625870423

Epoch: 6| Step: 11
Training loss: 2.95328388089468
Validation loss: 2.628605955365987

Epoch: 6| Step: 12
Training loss: 3.069966459308521
Validation loss: 2.6385268154208656

Epoch: 6| Step: 13
Training loss: 2.835950951242204
Validation loss: 2.657163320379132

Epoch: 217| Step: 0
Training loss: 2.7554067000651052
Validation loss: 2.673011350559223

Epoch: 6| Step: 1
Training loss: 3.3497437564151946
Validation loss: 2.7470012397563375

Epoch: 6| Step: 2
Training loss: 3.2615386364940933
Validation loss: 2.775870250339519

Epoch: 6| Step: 3
Training loss: 2.9868668144578474
Validation loss: 2.760518502423176

Epoch: 6| Step: 4
Training loss: 2.4102770312941684
Validation loss: 2.7335620324370518

Epoch: 6| Step: 5
Training loss: 2.800078704272805
Validation loss: 2.7069814319593295

Epoch: 6| Step: 6
Training loss: 2.9425766276815684
Validation loss: 2.662916859568347

Epoch: 6| Step: 7
Training loss: 3.007451023327702
Validation loss: 2.6463557337974724

Epoch: 6| Step: 8
Training loss: 3.4988026614517342
Validation loss: 2.633958340975452

Epoch: 6| Step: 9
Training loss: 2.9654751031293913
Validation loss: 2.624909919447136

Epoch: 6| Step: 10
Training loss: 3.3995536286794446
Validation loss: 2.6319254683305995

Epoch: 6| Step: 11
Training loss: 2.363986630429385
Validation loss: 2.6470570413930794

Epoch: 6| Step: 12
Training loss: 3.298762499809795
Validation loss: 2.678900241505044

Epoch: 6| Step: 13
Training loss: 2.7281285900953165
Validation loss: 2.6874863504271596

Epoch: 218| Step: 0
Training loss: 3.1948185098169417
Validation loss: 2.712341453818603

Epoch: 6| Step: 1
Training loss: 2.6896828945967455
Validation loss: 2.6847300084947876

Epoch: 6| Step: 2
Training loss: 3.2766854644681174
Validation loss: 2.6733337116381835

Epoch: 6| Step: 3
Training loss: 3.100260348308658
Validation loss: 2.656609849484234

Epoch: 6| Step: 4
Training loss: 3.139585712096982
Validation loss: 2.6571852724638925

Epoch: 6| Step: 5
Training loss: 3.2399566696943003
Validation loss: 2.646010443240828

Epoch: 6| Step: 6
Training loss: 2.5684354937627143
Validation loss: 2.649239414853357

Epoch: 6| Step: 7
Training loss: 3.136266920485755
Validation loss: 2.6541835953274706

Epoch: 6| Step: 8
Training loss: 2.8143457078521226
Validation loss: 2.6655366455518377

Epoch: 6| Step: 9
Training loss: 2.999192765032166
Validation loss: 2.6868205202409277

Epoch: 6| Step: 10
Training loss: 3.2977574329085684
Validation loss: 2.665635642834574

Epoch: 6| Step: 11
Training loss: 2.9393416779641144
Validation loss: 2.652273185589085

Epoch: 6| Step: 12
Training loss: 2.771752675829064
Validation loss: 2.6546299336441077

Epoch: 6| Step: 13
Training loss: 2.546381522271184
Validation loss: 2.664171748245399

Epoch: 219| Step: 0
Training loss: 3.063908467173072
Validation loss: 2.659441814429433

Epoch: 6| Step: 1
Training loss: 3.3084640387427964
Validation loss: 2.6688553406260507

Epoch: 6| Step: 2
Training loss: 3.4883331944270743
Validation loss: 2.6527838640773678

Epoch: 6| Step: 3
Training loss: 3.04216351217992
Validation loss: 2.6324416280004437

Epoch: 6| Step: 4
Training loss: 2.8571718827544377
Validation loss: 2.621505624496917

Epoch: 6| Step: 5
Training loss: 3.103229219006124
Validation loss: 2.624218552428551

Epoch: 6| Step: 6
Training loss: 2.739637096346473
Validation loss: 2.625680251298861

Epoch: 6| Step: 7
Training loss: 3.352716989571026
Validation loss: 2.6222941549814673

Epoch: 6| Step: 8
Training loss: 2.740983834693222
Validation loss: 2.6256303679803663

Epoch: 6| Step: 9
Training loss: 2.7537309306727304
Validation loss: 2.626828343604499

Epoch: 6| Step: 10
Training loss: 3.127566237567725
Validation loss: 2.6206382633351164

Epoch: 6| Step: 11
Training loss: 3.2567543854575933
Validation loss: 2.6228253067396805

Epoch: 6| Step: 12
Training loss: 1.7440595618672476
Validation loss: 2.6231509472618404

Epoch: 6| Step: 13
Training loss: 2.3930165414648954
Validation loss: 2.6242586554937097

Epoch: 220| Step: 0
Training loss: 3.6226171356912946
Validation loss: 2.6231059406152237

Epoch: 6| Step: 1
Training loss: 2.646568786851454
Validation loss: 2.6213409873043148

Epoch: 6| Step: 2
Training loss: 3.034963633588078
Validation loss: 2.6194800601329002

Epoch: 6| Step: 3
Training loss: 3.187399769123416
Validation loss: 2.6202275782348203

Epoch: 6| Step: 4
Training loss: 2.4420233595072154
Validation loss: 2.6258699076362455

Epoch: 6| Step: 5
Training loss: 2.4814101467770944
Validation loss: 2.6219194338383236

Epoch: 6| Step: 6
Training loss: 2.456392772301031
Validation loss: 2.6279738057559343

Epoch: 6| Step: 7
Training loss: 2.975945356174984
Validation loss: 2.6262470048241893

Epoch: 6| Step: 8
Training loss: 3.027900181978251
Validation loss: 2.623096714601976

Epoch: 6| Step: 9
Training loss: 3.3619321095398806
Validation loss: 2.6225452909425226

Epoch: 6| Step: 10
Training loss: 3.222265305358967
Validation loss: 2.6348448235133803

Epoch: 6| Step: 11
Training loss: 3.0499252310171348
Validation loss: 2.620691691896869

Epoch: 6| Step: 12
Training loss: 3.193131502286361
Validation loss: 2.6154553836341172

Epoch: 6| Step: 13
Training loss: 2.306037946840439
Validation loss: 2.61907763293477

Epoch: 221| Step: 0
Training loss: 2.2144601748777024
Validation loss: 2.613131567972489

Epoch: 6| Step: 1
Training loss: 2.9485941042244668
Validation loss: 2.6125640137492727

Epoch: 6| Step: 2
Training loss: 2.8989341289804225
Validation loss: 2.609458894973166

Epoch: 6| Step: 3
Training loss: 3.1726644501325327
Validation loss: 2.614681683442309

Epoch: 6| Step: 4
Training loss: 2.896390536557318
Validation loss: 2.6115478631300846

Epoch: 6| Step: 5
Training loss: 2.653411515472237
Validation loss: 2.6094566972506694

Epoch: 6| Step: 6
Training loss: 2.927732746309587
Validation loss: 2.606922269461599

Epoch: 6| Step: 7
Training loss: 2.3309863639442514
Validation loss: 2.608887720568556

Epoch: 6| Step: 8
Training loss: 3.046325164481209
Validation loss: 2.6071851478399055

Epoch: 6| Step: 9
Training loss: 3.596248388518767
Validation loss: 2.62067336272724

Epoch: 6| Step: 10
Training loss: 3.168703795929479
Validation loss: 2.632350472733952

Epoch: 6| Step: 11
Training loss: 2.870916701067409
Validation loss: 2.6159701360914784

Epoch: 6| Step: 12
Training loss: 2.9374607164718696
Validation loss: 2.6098962108158066

Epoch: 6| Step: 13
Training loss: 3.876274514562101
Validation loss: 2.611677254896838

Epoch: 222| Step: 0
Training loss: 2.719523002088182
Validation loss: 2.609037722710912

Epoch: 6| Step: 1
Training loss: 2.7581230183275935
Validation loss: 2.606303968598939

Epoch: 6| Step: 2
Training loss: 2.5922497926370363
Validation loss: 2.610097274160409

Epoch: 6| Step: 3
Training loss: 3.24681213729261
Validation loss: 2.6093908609968417

Epoch: 6| Step: 4
Training loss: 2.241352417579627
Validation loss: 2.611239920221331

Epoch: 6| Step: 5
Training loss: 2.684833623323877
Validation loss: 2.618017107717686

Epoch: 6| Step: 6
Training loss: 3.1929080935905767
Validation loss: 2.6214441874809546

Epoch: 6| Step: 7
Training loss: 2.3451318354850894
Validation loss: 2.617991087491427

Epoch: 6| Step: 8
Training loss: 3.5137150302206686
Validation loss: 2.6256462176800563

Epoch: 6| Step: 9
Training loss: 3.4413874059501106
Validation loss: 2.6410985751236633

Epoch: 6| Step: 10
Training loss: 3.4330784885180234
Validation loss: 2.6909574383927075

Epoch: 6| Step: 11
Training loss: 3.177169815303916
Validation loss: 2.7370641270623204

Epoch: 6| Step: 12
Training loss: 3.2800127875846385
Validation loss: 2.754997459511544

Epoch: 6| Step: 13
Training loss: 2.835735891863147
Validation loss: 2.749789422885984

Epoch: 223| Step: 0
Training loss: 2.638746326901162
Validation loss: 2.760734061260498

Epoch: 6| Step: 1
Training loss: 3.518329580339038
Validation loss: 2.7285140202082028

Epoch: 6| Step: 2
Training loss: 3.3857789457101104
Validation loss: 2.6889398184937163

Epoch: 6| Step: 3
Training loss: 2.864129288264589
Validation loss: 2.6628820195028227

Epoch: 6| Step: 4
Training loss: 2.953563839231682
Validation loss: 2.6364079458194047

Epoch: 6| Step: 5
Training loss: 3.1447414162104175
Validation loss: 2.614394392197304

Epoch: 6| Step: 6
Training loss: 3.010001834856152
Validation loss: 2.6142752540698484

Epoch: 6| Step: 7
Training loss: 3.0666677958721347
Validation loss: 2.612496685723284

Epoch: 6| Step: 8
Training loss: 3.29960454247456
Validation loss: 2.610845361653889

Epoch: 6| Step: 9
Training loss: 2.8125435719823644
Validation loss: 2.614361758064865

Epoch: 6| Step: 10
Training loss: 2.710571528200458
Validation loss: 2.6125187942983645

Epoch: 6| Step: 11
Training loss: 2.5700748414894328
Validation loss: 2.623238161262014

Epoch: 6| Step: 12
Training loss: 2.8525154925100344
Validation loss: 2.625344431088942

Epoch: 6| Step: 13
Training loss: 2.4741170946009468
Validation loss: 2.6367097407969093

Epoch: 224| Step: 0
Training loss: 3.058879970444081
Validation loss: 2.6485888397093595

Epoch: 6| Step: 1
Training loss: 3.0893029512512
Validation loss: 2.635682695016292

Epoch: 6| Step: 2
Training loss: 2.7131926640999224
Validation loss: 2.640199931281553

Epoch: 6| Step: 3
Training loss: 3.311282383957332
Validation loss: 2.6318016805391635

Epoch: 6| Step: 4
Training loss: 2.690322990171045
Validation loss: 2.628163739437435

Epoch: 6| Step: 5
Training loss: 2.619052234042837
Validation loss: 2.6270855433345695

Epoch: 6| Step: 6
Training loss: 2.7343177135461163
Validation loss: 2.626815286400593

Epoch: 6| Step: 7
Training loss: 2.538551631297978
Validation loss: 2.6136231248693695

Epoch: 6| Step: 8
Training loss: 2.9693101856349777
Validation loss: 2.6292151659513214

Epoch: 6| Step: 9
Training loss: 3.582710226722858
Validation loss: 2.614936302436843

Epoch: 6| Step: 10
Training loss: 2.440249432962635
Validation loss: 2.6224609279589113

Epoch: 6| Step: 11
Training loss: 2.9596434007238512
Validation loss: 2.6213910901405675

Epoch: 6| Step: 12
Training loss: 3.2925852849830206
Validation loss: 2.617561197332275

Epoch: 6| Step: 13
Training loss: 3.31867319366602
Validation loss: 2.6273917705426197

Epoch: 225| Step: 0
Training loss: 3.1651513004146583
Validation loss: 2.6235887481191447

Epoch: 6| Step: 1
Training loss: 3.018687536252853
Validation loss: 2.626861250320209

Epoch: 6| Step: 2
Training loss: 3.0137740863864386
Validation loss: 2.6238657375412724

Epoch: 6| Step: 3
Training loss: 2.762132497654816
Validation loss: 2.6365826772248675

Epoch: 6| Step: 4
Training loss: 2.8244862621025275
Validation loss: 2.636571335889379

Epoch: 6| Step: 5
Training loss: 2.8158101417901302
Validation loss: 2.6608262571051373

Epoch: 6| Step: 6
Training loss: 2.6132177507700067
Validation loss: 2.6369447293628783

Epoch: 6| Step: 7
Training loss: 2.7816209867127304
Validation loss: 2.646918185753549

Epoch: 6| Step: 8
Training loss: 3.1135799020610593
Validation loss: 2.6517247064439946

Epoch: 6| Step: 9
Training loss: 2.8197285478223857
Validation loss: 2.637286609920273

Epoch: 6| Step: 10
Training loss: 2.936894618210555
Validation loss: 2.6214856512436397

Epoch: 6| Step: 11
Training loss: 2.9744859395556498
Validation loss: 2.6090637830996792

Epoch: 6| Step: 12
Training loss: 3.278234494892551
Validation loss: 2.610022902791529

Epoch: 6| Step: 13
Training loss: 3.3371063971860617
Validation loss: 2.6090027822012427

Epoch: 226| Step: 0
Training loss: 3.4293699356467187
Validation loss: 2.607041878329362

Epoch: 6| Step: 1
Training loss: 3.2006162169324237
Validation loss: 2.6114819019110334

Epoch: 6| Step: 2
Training loss: 3.07571642213638
Validation loss: 2.617392893705591

Epoch: 6| Step: 3
Training loss: 3.043594707310848
Validation loss: 2.6094848814031235

Epoch: 6| Step: 4
Training loss: 2.9447681520969513
Validation loss: 2.609847466345218

Epoch: 6| Step: 5
Training loss: 2.7069394755253975
Validation loss: 2.6127630997502678

Epoch: 6| Step: 6
Training loss: 2.5850504941454227
Validation loss: 2.6047387629678074

Epoch: 6| Step: 7
Training loss: 3.0904319772336364
Validation loss: 2.597032704667401

Epoch: 6| Step: 8
Training loss: 2.918275298698555
Validation loss: 2.6035776633026217

Epoch: 6| Step: 9
Training loss: 2.7403634898083165
Validation loss: 2.598236045432355

Epoch: 6| Step: 10
Training loss: 3.293705288838715
Validation loss: 2.599056855494412

Epoch: 6| Step: 11
Training loss: 2.83283040314039
Validation loss: 2.5975779378866015

Epoch: 6| Step: 12
Training loss: 2.5975616208386576
Validation loss: 2.6014744381158215

Epoch: 6| Step: 13
Training loss: 2.605495835925552
Validation loss: 2.6135402802265553

Epoch: 227| Step: 0
Training loss: 2.936388008184023
Validation loss: 2.6422443661004094

Epoch: 6| Step: 1
Training loss: 2.872269370280096
Validation loss: 2.664592871640504

Epoch: 6| Step: 2
Training loss: 2.5426028877678193
Validation loss: 2.7063191439125607

Epoch: 6| Step: 3
Training loss: 2.8289016584534505
Validation loss: 2.7614220418057887

Epoch: 6| Step: 4
Training loss: 3.0915100003123475
Validation loss: 2.735436070798109

Epoch: 6| Step: 5
Training loss: 3.1764070051557223
Validation loss: 2.7207512388347865

Epoch: 6| Step: 6
Training loss: 1.9266268902712862
Validation loss: 2.7962926177053666

Epoch: 6| Step: 7
Training loss: 3.3585108865479407
Validation loss: 2.8592166588941765

Epoch: 6| Step: 8
Training loss: 3.5117077514340416
Validation loss: 2.8752125843809155

Epoch: 6| Step: 9
Training loss: 2.8256136033727586
Validation loss: 2.814085157506499

Epoch: 6| Step: 10
Training loss: 3.225113882966843
Validation loss: 2.759037792693519

Epoch: 6| Step: 11
Training loss: 3.5829298250575077
Validation loss: 2.705254862216658

Epoch: 6| Step: 12
Training loss: 2.8005811973641803
Validation loss: 2.6752384673304435

Epoch: 6| Step: 13
Training loss: 3.0403419292294838
Validation loss: 2.6388250085956724

Epoch: 228| Step: 0
Training loss: 3.185658240695896
Validation loss: 2.6595151836317483

Epoch: 6| Step: 1
Training loss: 3.4092075212359196
Validation loss: 2.650794057663199

Epoch: 6| Step: 2
Training loss: 3.3105867726670315
Validation loss: 2.638780689953777

Epoch: 6| Step: 3
Training loss: 2.269700797440029
Validation loss: 2.634849531739778

Epoch: 6| Step: 4
Training loss: 2.8416842828318307
Validation loss: 2.6233070762535564

Epoch: 6| Step: 5
Training loss: 2.7484237314891056
Validation loss: 2.616209049220574

Epoch: 6| Step: 6
Training loss: 2.9136016726778644
Validation loss: 2.601722222380296

Epoch: 6| Step: 7
Training loss: 3.0226931579813274
Validation loss: 2.6036020256639736

Epoch: 6| Step: 8
Training loss: 2.959017732639944
Validation loss: 2.611953239732238

Epoch: 6| Step: 9
Training loss: 2.980198519194007
Validation loss: 2.6290854827945846

Epoch: 6| Step: 10
Training loss: 3.185978844389808
Validation loss: 2.6293756879848726

Epoch: 6| Step: 11
Training loss: 3.2009001657874134
Validation loss: 2.6353363757046258

Epoch: 6| Step: 12
Training loss: 2.81419194509961
Validation loss: 2.649857524927697

Epoch: 6| Step: 13
Training loss: 2.366577170475262
Validation loss: 2.654067946227376

Epoch: 229| Step: 0
Training loss: 3.335293352530857
Validation loss: 2.661117144295149

Epoch: 6| Step: 1
Training loss: 2.8854964666429224
Validation loss: 2.643289751423088

Epoch: 6| Step: 2
Training loss: 2.9463649660321316
Validation loss: 2.6276803598276524

Epoch: 6| Step: 3
Training loss: 2.0724251961639215
Validation loss: 2.618980263631119

Epoch: 6| Step: 4
Training loss: 2.838223295410242
Validation loss: 2.617193332176463

Epoch: 6| Step: 5
Training loss: 2.683385316175431
Validation loss: 2.6195184105246803

Epoch: 6| Step: 6
Training loss: 2.770298086302085
Validation loss: 2.6082286737318015

Epoch: 6| Step: 7
Training loss: 3.051453578585252
Validation loss: 2.610052472633258

Epoch: 6| Step: 8
Training loss: 2.5724318095104675
Validation loss: 2.6052939894202236

Epoch: 6| Step: 9
Training loss: 3.5743807062862905
Validation loss: 2.602466517211927

Epoch: 6| Step: 10
Training loss: 2.951738789081325
Validation loss: 2.6043968578039873

Epoch: 6| Step: 11
Training loss: 3.113463354588226
Validation loss: 2.6035302878907607

Epoch: 6| Step: 12
Training loss: 3.006364587832478
Validation loss: 2.611939984496996

Epoch: 6| Step: 13
Training loss: 3.5346819649039967
Validation loss: 2.5999154681370116

Epoch: 230| Step: 0
Training loss: 3.012286932917106
Validation loss: 2.6005114952264403

Epoch: 6| Step: 1
Training loss: 2.677536437483896
Validation loss: 2.6024932787731587

Epoch: 6| Step: 2
Training loss: 1.8481883276886293
Validation loss: 2.6081820777278604

Epoch: 6| Step: 3
Training loss: 3.0324047288135954
Validation loss: 2.6153127210737046

Epoch: 6| Step: 4
Training loss: 3.0837229061598737
Validation loss: 2.6168321299969035

Epoch: 6| Step: 5
Training loss: 3.2244654900042002
Validation loss: 2.6269211563096806

Epoch: 6| Step: 6
Training loss: 2.577190067812206
Validation loss: 2.6331236428958986

Epoch: 6| Step: 7
Training loss: 2.648007338257271
Validation loss: 2.6275716666775626

Epoch: 6| Step: 8
Training loss: 3.043079379106622
Validation loss: 2.6386314323349196

Epoch: 6| Step: 9
Training loss: 3.109275624589748
Validation loss: 2.6437357296443738

Epoch: 6| Step: 10
Training loss: 2.920996385958015
Validation loss: 2.6275312336608962

Epoch: 6| Step: 11
Training loss: 3.5338207778346593
Validation loss: 2.638626067266571

Epoch: 6| Step: 12
Training loss: 3.294415175501075
Validation loss: 2.626989406718337

Epoch: 6| Step: 13
Training loss: 3.1579227358430098
Validation loss: 2.6146824188015

Epoch: 231| Step: 0
Training loss: 3.1339867120301643
Validation loss: 2.605482715108592

Epoch: 6| Step: 1
Training loss: 2.4427791061939503
Validation loss: 2.605578909284918

Epoch: 6| Step: 2
Training loss: 2.5438019168438943
Validation loss: 2.5994773736252768

Epoch: 6| Step: 3
Training loss: 3.1670540689779956
Validation loss: 2.6008209558165016

Epoch: 6| Step: 4
Training loss: 3.349338318114408
Validation loss: 2.5989118871069765

Epoch: 6| Step: 5
Training loss: 2.7380397107830095
Validation loss: 2.5957655791487064

Epoch: 6| Step: 6
Training loss: 3.239148584041725
Validation loss: 2.5918191472886654

Epoch: 6| Step: 7
Training loss: 3.2560667487948436
Validation loss: 2.595366893077142

Epoch: 6| Step: 8
Training loss: 2.5489373779266913
Validation loss: 2.593352207122855

Epoch: 6| Step: 9
Training loss: 2.1897458128407314
Validation loss: 2.5922641483926148

Epoch: 6| Step: 10
Training loss: 2.5885810362945225
Validation loss: 2.5939305036717006

Epoch: 6| Step: 11
Training loss: 2.971531578783247
Validation loss: 2.594228738625675

Epoch: 6| Step: 12
Training loss: 3.2379111894158608
Validation loss: 2.596105781505003

Epoch: 6| Step: 13
Training loss: 3.8777795482535513
Validation loss: 2.591616547182376

Epoch: 232| Step: 0
Training loss: 3.0507931287780905
Validation loss: 2.5922570397520213

Epoch: 6| Step: 1
Training loss: 3.271985152903404
Validation loss: 2.5951135023834597

Epoch: 6| Step: 2
Training loss: 2.952019863123863
Validation loss: 2.5911674189842073

Epoch: 6| Step: 3
Training loss: 2.105163665352973
Validation loss: 2.5966019748479767

Epoch: 6| Step: 4
Training loss: 2.620138753318115
Validation loss: 2.593818793117789

Epoch: 6| Step: 5
Training loss: 3.0405530240830765
Validation loss: 2.5907339031542564

Epoch: 6| Step: 6
Training loss: 3.733068516966728
Validation loss: 2.5908542801504812

Epoch: 6| Step: 7
Training loss: 2.8925276809198723
Validation loss: 2.5881961616605733

Epoch: 6| Step: 8
Training loss: 2.9704421190197072
Validation loss: 2.5886703359863783

Epoch: 6| Step: 9
Training loss: 3.1129289568947485
Validation loss: 2.5923015426067058

Epoch: 6| Step: 10
Training loss: 2.8633313766608994
Validation loss: 2.5962814321031282

Epoch: 6| Step: 11
Training loss: 2.6124406725704215
Validation loss: 2.5876624194846185

Epoch: 6| Step: 12
Training loss: 2.903338214448256
Validation loss: 2.594215748583578

Epoch: 6| Step: 13
Training loss: 2.571102959967884
Validation loss: 2.5867379938529464

Epoch: 233| Step: 0
Training loss: 3.0878674616659683
Validation loss: 2.5920856798146024

Epoch: 6| Step: 1
Training loss: 2.9144381774429045
Validation loss: 2.6006664282627816

Epoch: 6| Step: 2
Training loss: 3.633156643225539
Validation loss: 2.5904847561029674

Epoch: 6| Step: 3
Training loss: 2.808994057768216
Validation loss: 2.597011624159687

Epoch: 6| Step: 4
Training loss: 2.88565163510634
Validation loss: 2.601757055712097

Epoch: 6| Step: 5
Training loss: 2.7506719115178444
Validation loss: 2.5988727206700752

Epoch: 6| Step: 6
Training loss: 2.4914052088230814
Validation loss: 2.614144389444753

Epoch: 6| Step: 7
Training loss: 2.765283940724198
Validation loss: 2.6172917778241307

Epoch: 6| Step: 8
Training loss: 3.2010747535221227
Validation loss: 2.640797464217109

Epoch: 6| Step: 9
Training loss: 2.187830872716697
Validation loss: 2.612960877460439

Epoch: 6| Step: 10
Training loss: 2.757893245044487
Validation loss: 2.593782039503258

Epoch: 6| Step: 11
Training loss: 3.550612711080226
Validation loss: 2.5860098398151146

Epoch: 6| Step: 12
Training loss: 3.1981803130942255
Validation loss: 2.5863977229730337

Epoch: 6| Step: 13
Training loss: 2.3933436076157117
Validation loss: 2.5866146937713785

Epoch: 234| Step: 0
Training loss: 2.9372425372335496
Validation loss: 2.582616004496542

Epoch: 6| Step: 1
Training loss: 2.70665691038857
Validation loss: 2.5787682231476134

Epoch: 6| Step: 2
Training loss: 3.1969031965666046
Validation loss: 2.5823199824800556

Epoch: 6| Step: 3
Training loss: 2.67073516625621
Validation loss: 2.5766220460106504

Epoch: 6| Step: 4
Training loss: 2.690671424598129
Validation loss: 2.581017741199058

Epoch: 6| Step: 5
Training loss: 3.1097456361329225
Validation loss: 2.581987207565898

Epoch: 6| Step: 6
Training loss: 3.0978252658217307
Validation loss: 2.58239002616682

Epoch: 6| Step: 7
Training loss: 2.7537504111491833
Validation loss: 2.588376882279833

Epoch: 6| Step: 8
Training loss: 3.6326976470839676
Validation loss: 2.5906683223911964

Epoch: 6| Step: 9
Training loss: 3.3745424878883177
Validation loss: 2.599737000198809

Epoch: 6| Step: 10
Training loss: 2.9572339410490143
Validation loss: 2.5891656789290596

Epoch: 6| Step: 11
Training loss: 2.482966665639513
Validation loss: 2.6052736498121023

Epoch: 6| Step: 12
Training loss: 2.480644544244281
Validation loss: 2.618579534586567

Epoch: 6| Step: 13
Training loss: 2.5304099678827345
Validation loss: 2.6176945353909225

Epoch: 235| Step: 0
Training loss: 2.7391317790747505
Validation loss: 2.5986419497654523

Epoch: 6| Step: 1
Training loss: 1.6282921234871832
Validation loss: 2.5807859364594417

Epoch: 6| Step: 2
Training loss: 3.4211330219043594
Validation loss: 2.5777384980699063

Epoch: 6| Step: 3
Training loss: 2.507897301306688
Validation loss: 2.582457320123875

Epoch: 6| Step: 4
Training loss: 2.774017359332037
Validation loss: 2.5820461470904723

Epoch: 6| Step: 5
Training loss: 3.0404830789720942
Validation loss: 2.58567853820056

Epoch: 6| Step: 6
Training loss: 3.45356492222125
Validation loss: 2.580096451429535

Epoch: 6| Step: 7
Training loss: 3.1346655333514364
Validation loss: 2.584876805793781

Epoch: 6| Step: 8
Training loss: 3.3173616828054637
Validation loss: 2.5852533549577172

Epoch: 6| Step: 9
Training loss: 2.9001639023864785
Validation loss: 2.580996159395986

Epoch: 6| Step: 10
Training loss: 3.0274921208601215
Validation loss: 2.592099579551471

Epoch: 6| Step: 11
Training loss: 2.9247611575955212
Validation loss: 2.5900101696142106

Epoch: 6| Step: 12
Training loss: 2.8381723892835518
Validation loss: 2.605320040024548

Epoch: 6| Step: 13
Training loss: 2.9312931797775783
Validation loss: 2.598569910306017

Epoch: 236| Step: 0
Training loss: 2.5308733059369737
Validation loss: 2.5987167405578835

Epoch: 6| Step: 1
Training loss: 3.1173135449923817
Validation loss: 2.5949791759403324

Epoch: 6| Step: 2
Training loss: 2.9524444926290596
Validation loss: 2.6058461151722017

Epoch: 6| Step: 3
Training loss: 2.997859031930886
Validation loss: 2.6038690504419617

Epoch: 6| Step: 4
Training loss: 2.6572300617569296
Validation loss: 2.610654779784456

Epoch: 6| Step: 5
Training loss: 2.293699495762593
Validation loss: 2.6043898531528953

Epoch: 6| Step: 6
Training loss: 2.537734779057475
Validation loss: 2.6045729827563644

Epoch: 6| Step: 7
Training loss: 3.207047902666875
Validation loss: 2.622526242545907

Epoch: 6| Step: 8
Training loss: 3.268422074216335
Validation loss: 2.632821329741693

Epoch: 6| Step: 9
Training loss: 3.1206506598418677
Validation loss: 2.6295339013091605

Epoch: 6| Step: 10
Training loss: 2.7791695689615614
Validation loss: 2.6110595203700213

Epoch: 6| Step: 11
Training loss: 3.2946269248727815
Validation loss: 2.6149211015451232

Epoch: 6| Step: 12
Training loss: 3.3263983747381998
Validation loss: 2.600005083536648

Epoch: 6| Step: 13
Training loss: 2.7197240202804545
Validation loss: 2.596773737698011

Epoch: 237| Step: 0
Training loss: 2.8107700537638256
Validation loss: 2.59447337111882

Epoch: 6| Step: 1
Training loss: 3.2624857292009333
Validation loss: 2.5800028346393438

Epoch: 6| Step: 2
Training loss: 2.7576011166055983
Validation loss: 2.575035364418098

Epoch: 6| Step: 3
Training loss: 2.7224280372545726
Validation loss: 2.576606235023395

Epoch: 6| Step: 4
Training loss: 2.783294697643763
Validation loss: 2.568697767308234

Epoch: 6| Step: 5
Training loss: 2.2977316160789556
Validation loss: 2.5684283301510353

Epoch: 6| Step: 6
Training loss: 3.390989784974552
Validation loss: 2.5674298214494757

Epoch: 6| Step: 7
Training loss: 2.8464939168050583
Validation loss: 2.570671204378347

Epoch: 6| Step: 8
Training loss: 3.4337402590240966
Validation loss: 2.5664450987961875

Epoch: 6| Step: 9
Training loss: 2.767006480555085
Validation loss: 2.5658237701978392

Epoch: 6| Step: 10
Training loss: 2.928992756166158
Validation loss: 2.5658563272662933

Epoch: 6| Step: 11
Training loss: 2.9401278814413017
Validation loss: 2.563945285648791

Epoch: 6| Step: 12
Training loss: 2.4486505801555865
Validation loss: 2.5641208742695243

Epoch: 6| Step: 13
Training loss: 3.5791559191813698
Validation loss: 2.5636286347222472

Epoch: 238| Step: 0
Training loss: 2.2531136056133088
Validation loss: 2.5668159932312036

Epoch: 6| Step: 1
Training loss: 3.3383785848713647
Validation loss: 2.5603537186253367

Epoch: 6| Step: 2
Training loss: 3.186658411560645
Validation loss: 2.5628928606930925

Epoch: 6| Step: 3
Training loss: 2.78900813201999
Validation loss: 2.5596673737679354

Epoch: 6| Step: 4
Training loss: 2.629878460936801
Validation loss: 2.565800334048377

Epoch: 6| Step: 5
Training loss: 3.3366441179314528
Validation loss: 2.56613578350769

Epoch: 6| Step: 6
Training loss: 2.771847035160513
Validation loss: 2.56132774441667

Epoch: 6| Step: 7
Training loss: 3.0599628760385924
Validation loss: 2.5656725704971013

Epoch: 6| Step: 8
Training loss: 2.3341482192752667
Validation loss: 2.56769468428711

Epoch: 6| Step: 9
Training loss: 3.0631530999539223
Validation loss: 2.568885358894767

Epoch: 6| Step: 10
Training loss: 3.6022389866807956
Validation loss: 2.58086542213716

Epoch: 6| Step: 11
Training loss: 2.6974622031914524
Validation loss: 2.580766613118651

Epoch: 6| Step: 12
Training loss: 2.4142704846312117
Validation loss: 2.5865180827305485

Epoch: 6| Step: 13
Training loss: 3.241118399599837
Validation loss: 2.5773227023768825

Epoch: 239| Step: 0
Training loss: 2.2182631697283663
Validation loss: 2.584433011594035

Epoch: 6| Step: 1
Training loss: 2.789109515480391
Validation loss: 2.5894638963639034

Epoch: 6| Step: 2
Training loss: 3.2793893534086496
Validation loss: 2.579366216749821

Epoch: 6| Step: 3
Training loss: 3.187232810396959
Validation loss: 2.5745964497092966

Epoch: 6| Step: 4
Training loss: 2.3002731202543956
Validation loss: 2.5677417035014365

Epoch: 6| Step: 5
Training loss: 3.115988134956541
Validation loss: 2.5693059559307785

Epoch: 6| Step: 6
Training loss: 3.017023898587958
Validation loss: 2.5638141468785696

Epoch: 6| Step: 7
Training loss: 3.552820272807103
Validation loss: 2.5633321131857176

Epoch: 6| Step: 8
Training loss: 2.9225838357274663
Validation loss: 2.5609794485278656

Epoch: 6| Step: 9
Training loss: 2.889798432814961
Validation loss: 2.560324556069322

Epoch: 6| Step: 10
Training loss: 1.9013409801336518
Validation loss: 2.5614960207110764

Epoch: 6| Step: 11
Training loss: 2.975213814112367
Validation loss: 2.55794214441324

Epoch: 6| Step: 12
Training loss: 3.1249079881473643
Validation loss: 2.5601136966502263

Epoch: 6| Step: 13
Training loss: 3.352282609028645
Validation loss: 2.5603643031742385

Epoch: 240| Step: 0
Training loss: 3.0262204947406075
Validation loss: 2.560442390780927

Epoch: 6| Step: 1
Training loss: 2.5518651648450317
Validation loss: 2.5657492645623887

Epoch: 6| Step: 2
Training loss: 2.3172018347802874
Validation loss: 2.569540895977773

Epoch: 6| Step: 3
Training loss: 3.1204076974985813
Validation loss: 2.581558008182999

Epoch: 6| Step: 4
Training loss: 2.6395687722093273
Validation loss: 2.5848190346954474

Epoch: 6| Step: 5
Training loss: 3.140896154436517
Validation loss: 2.5878751978817793

Epoch: 6| Step: 6
Training loss: 3.439953847176314
Validation loss: 2.5960748895252816

Epoch: 6| Step: 7
Training loss: 2.2290822544931226
Validation loss: 2.596700548567038

Epoch: 6| Step: 8
Training loss: 2.6320222749724076
Validation loss: 2.61858959105638

Epoch: 6| Step: 9
Training loss: 3.0384133241314086
Validation loss: 2.6167715276829173

Epoch: 6| Step: 10
Training loss: 3.3229021093992377
Validation loss: 2.614541250557862

Epoch: 6| Step: 11
Training loss: 3.160516857419095
Validation loss: 2.6231076441011973

Epoch: 6| Step: 12
Training loss: 2.8580140590762393
Validation loss: 2.618423303855598

Epoch: 6| Step: 13
Training loss: 3.305369349630323
Validation loss: 2.630930680379032

Epoch: 241| Step: 0
Training loss: 2.7610047967434577
Validation loss: 2.6253588246134383

Epoch: 6| Step: 1
Training loss: 3.1042140129284777
Validation loss: 2.617352190806585

Epoch: 6| Step: 2
Training loss: 3.0788028183749594
Validation loss: 2.6293224992606037

Epoch: 6| Step: 3
Training loss: 2.7855861166229556
Validation loss: 2.6105521007407093

Epoch: 6| Step: 4
Training loss: 3.3516464400728383
Validation loss: 2.6084716296168478

Epoch: 6| Step: 5
Training loss: 2.727228034260152
Validation loss: 2.6002242109176827

Epoch: 6| Step: 6
Training loss: 3.3226278691769338
Validation loss: 2.5903482082715765

Epoch: 6| Step: 7
Training loss: 3.136832761295837
Validation loss: 2.582581838158786

Epoch: 6| Step: 8
Training loss: 3.0453091241182704
Validation loss: 2.585641878080951

Epoch: 6| Step: 9
Training loss: 2.9778715043793005
Validation loss: 2.5852052807952015

Epoch: 6| Step: 10
Training loss: 2.8248811106012908
Validation loss: 2.5764148269233766

Epoch: 6| Step: 11
Training loss: 3.215731195859417
Validation loss: 2.5673388722635275

Epoch: 6| Step: 12
Training loss: 1.1199483835724104
Validation loss: 2.566254047675337

Epoch: 6| Step: 13
Training loss: 2.7539905724568396
Validation loss: 2.566687762852005

Epoch: 242| Step: 0
Training loss: 2.8673385039851063
Validation loss: 2.570522552733232

Epoch: 6| Step: 1
Training loss: 2.849245232473925
Validation loss: 2.5692812010164787

Epoch: 6| Step: 2
Training loss: 2.7009893370851823
Validation loss: 2.5691296225408724

Epoch: 6| Step: 3
Training loss: 2.693804155765664
Validation loss: 2.5793047957753226

Epoch: 6| Step: 4
Training loss: 2.647507225653538
Validation loss: 2.585593605899819

Epoch: 6| Step: 5
Training loss: 3.240561056655786
Validation loss: 2.5835922447550552

Epoch: 6| Step: 6
Training loss: 3.403043585189616
Validation loss: 2.588404569480003

Epoch: 6| Step: 7
Training loss: 2.6708184545839484
Validation loss: 2.576397792745238

Epoch: 6| Step: 8
Training loss: 2.684802986461174
Validation loss: 2.5774299646775463

Epoch: 6| Step: 9
Training loss: 3.2310685658383105
Validation loss: 2.5744369055626892

Epoch: 6| Step: 10
Training loss: 3.355014543800269
Validation loss: 2.5851240260006665

Epoch: 6| Step: 11
Training loss: 2.676754962261343
Validation loss: 2.5833835583692584

Epoch: 6| Step: 12
Training loss: 2.499747835793385
Validation loss: 2.5824968060001976

Epoch: 6| Step: 13
Training loss: 3.2013847275654266
Validation loss: 2.58234577442356

Epoch: 243| Step: 0
Training loss: 2.8956538814863886
Validation loss: 2.5804400856368495

Epoch: 6| Step: 1
Training loss: 2.7603324637376145
Validation loss: 2.5807663935851988

Epoch: 6| Step: 2
Training loss: 2.50839141153244
Validation loss: 2.5893228932941432

Epoch: 6| Step: 3
Training loss: 2.962497592071971
Validation loss: 2.592046422100584

Epoch: 6| Step: 4
Training loss: 3.074472496873765
Validation loss: 2.5879580840042373

Epoch: 6| Step: 5
Training loss: 3.0597546787034506
Validation loss: 2.5854125876050484

Epoch: 6| Step: 6
Training loss: 2.7441523541508674
Validation loss: 2.573904791234536

Epoch: 6| Step: 7
Training loss: 3.5163963997445906
Validation loss: 2.573977739132114

Epoch: 6| Step: 8
Training loss: 3.1814967451353207
Validation loss: 2.566110810691677

Epoch: 6| Step: 9
Training loss: 2.2552605697067842
Validation loss: 2.5697141463850355

Epoch: 6| Step: 10
Training loss: 3.108593406399202
Validation loss: 2.5795295923845214

Epoch: 6| Step: 11
Training loss: 3.1866877399795905
Validation loss: 2.5775332410933505

Epoch: 6| Step: 12
Training loss: 2.220942099402622
Validation loss: 2.5752473802946176

Epoch: 6| Step: 13
Training loss: 3.342565308805189
Validation loss: 2.5781347906648313

Epoch: 244| Step: 0
Training loss: 2.935199404803611
Validation loss: 2.573938471167537

Epoch: 6| Step: 1
Training loss: 2.576643824638526
Validation loss: 2.577818302470841

Epoch: 6| Step: 2
Training loss: 3.1856537502189686
Validation loss: 2.5733643211659563

Epoch: 6| Step: 3
Training loss: 2.7315569497822234
Validation loss: 2.567901803389755

Epoch: 6| Step: 4
Training loss: 2.4789323028147576
Validation loss: 2.5731692336944016

Epoch: 6| Step: 5
Training loss: 3.1491490925357986
Validation loss: 2.5660916241069582

Epoch: 6| Step: 6
Training loss: 3.075902145912719
Validation loss: 2.571148550855133

Epoch: 6| Step: 7
Training loss: 2.6336684830574066
Validation loss: 2.5660623209549933

Epoch: 6| Step: 8
Training loss: 3.7798807486640493
Validation loss: 2.567104870648266

Epoch: 6| Step: 9
Training loss: 2.291700073923462
Validation loss: 2.5776755300675345

Epoch: 6| Step: 10
Training loss: 3.111141297405876
Validation loss: 2.5801075412210137

Epoch: 6| Step: 11
Training loss: 2.0491616093140204
Validation loss: 2.571058178926812

Epoch: 6| Step: 12
Training loss: 3.2726633253496864
Validation loss: 2.577860231249808

Epoch: 6| Step: 13
Training loss: 3.219226542630369
Validation loss: 2.585273357746583

Epoch: 245| Step: 0
Training loss: 2.296298519114076
Validation loss: 2.589879905200719

Epoch: 6| Step: 1
Training loss: 2.913988864162639
Validation loss: 2.5954029654112736

Epoch: 6| Step: 2
Training loss: 2.0427509724240385
Validation loss: 2.6034075329895514

Epoch: 6| Step: 3
Training loss: 2.251602979371605
Validation loss: 2.626674458882203

Epoch: 6| Step: 4
Training loss: 2.812576801522997
Validation loss: 2.632039069934541

Epoch: 6| Step: 5
Training loss: 3.213712880392413
Validation loss: 2.626691305605996

Epoch: 6| Step: 6
Training loss: 3.1082304568477506
Validation loss: 2.6421054399479234

Epoch: 6| Step: 7
Training loss: 3.284191012469323
Validation loss: 2.645885327168801

Epoch: 6| Step: 8
Training loss: 2.7269943463693895
Validation loss: 2.5957706703459325

Epoch: 6| Step: 9
Training loss: 2.9873870509036387
Validation loss: 2.5873189112065815

Epoch: 6| Step: 10
Training loss: 2.631636359692764
Validation loss: 2.569144789023196

Epoch: 6| Step: 11
Training loss: 3.403295232825454
Validation loss: 2.5590372777798227

Epoch: 6| Step: 12
Training loss: 3.6938367804387973
Validation loss: 2.564184471067305

Epoch: 6| Step: 13
Training loss: 2.9205374690759176
Validation loss: 2.5596311443617465

Epoch: 246| Step: 0
Training loss: 3.222527814675526
Validation loss: 2.55847657865414

Epoch: 6| Step: 1
Training loss: 3.501007752432544
Validation loss: 2.5558728105047535

Epoch: 6| Step: 2
Training loss: 3.1283273911525553
Validation loss: 2.560810729837572

Epoch: 6| Step: 3
Training loss: 2.250185640941914
Validation loss: 2.5604662754667693

Epoch: 6| Step: 4
Training loss: 2.7545611962212835
Validation loss: 2.559338025171031

Epoch: 6| Step: 5
Training loss: 2.7166448752186505
Validation loss: 2.554788270947079

Epoch: 6| Step: 6
Training loss: 2.9961472249139187
Validation loss: 2.5633377088530236

Epoch: 6| Step: 7
Training loss: 3.2541222472014546
Validation loss: 2.562780522464428

Epoch: 6| Step: 8
Training loss: 3.03207606435092
Validation loss: 2.5576728015658006

Epoch: 6| Step: 9
Training loss: 2.769766083353275
Validation loss: 2.5536452813546218

Epoch: 6| Step: 10
Training loss: 2.804249593822623
Validation loss: 2.559700816380883

Epoch: 6| Step: 11
Training loss: 2.8171301135048794
Validation loss: 2.5625668308638248

Epoch: 6| Step: 12
Training loss: 2.3233491184276702
Validation loss: 2.567916903246984

Epoch: 6| Step: 13
Training loss: 3.31693474789996
Validation loss: 2.5839187578642484

Epoch: 247| Step: 0
Training loss: 2.3777377762009517
Validation loss: 2.5757957897430126

Epoch: 6| Step: 1
Training loss: 3.1442403907601744
Validation loss: 2.5792124533359204

Epoch: 6| Step: 2
Training loss: 3.0772133653595204
Validation loss: 2.57973743876665

Epoch: 6| Step: 3
Training loss: 3.444250518371273
Validation loss: 2.569152174156628

Epoch: 6| Step: 4
Training loss: 2.391530183448908
Validation loss: 2.564423273287043

Epoch: 6| Step: 5
Training loss: 2.5044008620478326
Validation loss: 2.5723683513343043

Epoch: 6| Step: 6
Training loss: 3.011092975682273
Validation loss: 2.5644137471775106

Epoch: 6| Step: 7
Training loss: 3.2652987814596917
Validation loss: 2.5590209173502916

Epoch: 6| Step: 8
Training loss: 2.973474377450065
Validation loss: 2.563525775177258

Epoch: 6| Step: 9
Training loss: 2.8858367026611655
Validation loss: 2.5659416411120732

Epoch: 6| Step: 10
Training loss: 3.3776257508626713
Validation loss: 2.5578732112610405

Epoch: 6| Step: 11
Training loss: 2.7637626282581587
Validation loss: 2.5657255359696634

Epoch: 6| Step: 12
Training loss: 2.8418799319370245
Validation loss: 2.566917907972561

Epoch: 6| Step: 13
Training loss: 1.7861025783176137
Validation loss: 2.5561932223287784

Epoch: 248| Step: 0
Training loss: 3.283125858884097
Validation loss: 2.5567186217834093

Epoch: 6| Step: 1
Training loss: 3.1431247764431065
Validation loss: 2.556590371289897

Epoch: 6| Step: 2
Training loss: 2.973952703698882
Validation loss: 2.5533707553088916

Epoch: 6| Step: 3
Training loss: 2.8037114477206955
Validation loss: 2.5533803246254747

Epoch: 6| Step: 4
Training loss: 2.9920490123283896
Validation loss: 2.549482865931954

Epoch: 6| Step: 5
Training loss: 3.0158757713292537
Validation loss: 2.5538846223465295

Epoch: 6| Step: 6
Training loss: 3.1870680871686026
Validation loss: 2.553928814138865

Epoch: 6| Step: 7
Training loss: 2.536855730470872
Validation loss: 2.551359822871208

Epoch: 6| Step: 8
Training loss: 2.6656981338539665
Validation loss: 2.5552590433199343

Epoch: 6| Step: 9
Training loss: 2.4429817182283915
Validation loss: 2.5517845924890183

Epoch: 6| Step: 10
Training loss: 2.7768242587567142
Validation loss: 2.5510945574251465

Epoch: 6| Step: 11
Training loss: 2.9911527512807066
Validation loss: 2.5576133605053593

Epoch: 6| Step: 12
Training loss: 3.040979403535488
Validation loss: 2.5562167585939286

Epoch: 6| Step: 13
Training loss: 2.573905034261507
Validation loss: 2.558089704164149

Epoch: 249| Step: 0
Training loss: 3.0808121623545817
Validation loss: 2.5515687582369284

Epoch: 6| Step: 1
Training loss: 2.8951245728144857
Validation loss: 2.586614487618806

Epoch: 6| Step: 2
Training loss: 2.6755928808582072
Validation loss: 2.5871894595782585

Epoch: 6| Step: 3
Training loss: 2.740166857017447
Validation loss: 2.6320312739218337

Epoch: 6| Step: 4
Training loss: 2.7559988309639056
Validation loss: 2.6345519531525774

Epoch: 6| Step: 5
Training loss: 2.598876391223078
Validation loss: 2.5617504859550726

Epoch: 6| Step: 6
Training loss: 2.7821071032729905
Validation loss: 2.548856458552427

Epoch: 6| Step: 7
Training loss: 2.801020102644299
Validation loss: 2.5463137823328754

Epoch: 6| Step: 8
Training loss: 2.7228382985619928
Validation loss: 2.556774359673796

Epoch: 6| Step: 9
Training loss: 3.3512797914437926
Validation loss: 2.566684478753361

Epoch: 6| Step: 10
Training loss: 3.015936484581252
Validation loss: 2.57620552131387

Epoch: 6| Step: 11
Training loss: 3.4191635746437896
Validation loss: 2.579623370450707

Epoch: 6| Step: 12
Training loss: 3.0375142603409953
Validation loss: 2.5827743773718352

Epoch: 6| Step: 13
Training loss: 2.893001095320293
Validation loss: 2.5735756329682036

Epoch: 250| Step: 0
Training loss: 3.1365416442354066
Validation loss: 2.5584983684537135

Epoch: 6| Step: 1
Training loss: 2.5318655513605015
Validation loss: 2.5562903837428954

Epoch: 6| Step: 2
Training loss: 2.5881154088697254
Validation loss: 2.568884837960447

Epoch: 6| Step: 3
Training loss: 2.7195428152695946
Validation loss: 2.5653740157463862

Epoch: 6| Step: 4
Training loss: 2.2530888442102732
Validation loss: 2.5762333995259197

Epoch: 6| Step: 5
Training loss: 2.6881818571731912
Validation loss: 2.5981700393115266

Epoch: 6| Step: 6
Training loss: 3.5440217359664206
Validation loss: 2.617102320727787

Epoch: 6| Step: 7
Training loss: 2.949190617105057
Validation loss: 2.6264466002574878

Epoch: 6| Step: 8
Training loss: 3.0250290420020853
Validation loss: 2.6189482142595395

Epoch: 6| Step: 9
Training loss: 3.048546591741954
Validation loss: 2.6293758971223107

Epoch: 6| Step: 10
Training loss: 2.8907017053272948
Validation loss: 2.6379951467944807

Epoch: 6| Step: 11
Training loss: 3.2515856469360225
Validation loss: 2.618382018748355

Epoch: 6| Step: 12
Training loss: 2.939739753207647
Validation loss: 2.587178000809419

Epoch: 6| Step: 13
Training loss: 3.079121694550424
Validation loss: 2.575610800171641

Epoch: 251| Step: 0
Training loss: 2.7101210538283724
Validation loss: 2.5654680334532642

Epoch: 6| Step: 1
Training loss: 2.835229538332687
Validation loss: 2.550327265588033

Epoch: 6| Step: 2
Training loss: 2.3262395200334445
Validation loss: 2.5526362697627727

Epoch: 6| Step: 3
Training loss: 3.514291060949815
Validation loss: 2.5502691461060514

Epoch: 6| Step: 4
Training loss: 3.0494314570594483
Validation loss: 2.553953826772023

Epoch: 6| Step: 5
Training loss: 2.762819235467397
Validation loss: 2.548483829066234

Epoch: 6| Step: 6
Training loss: 3.1646779156518368
Validation loss: 2.5547564398352276

Epoch: 6| Step: 7
Training loss: 2.803829816412597
Validation loss: 2.55157461681759

Epoch: 6| Step: 8
Training loss: 2.8820209191732538
Validation loss: 2.5536849296323227

Epoch: 6| Step: 9
Training loss: 2.5917332173559626
Validation loss: 2.5521887246211366

Epoch: 6| Step: 10
Training loss: 3.1786465827298875
Validation loss: 2.5483714899312377

Epoch: 6| Step: 11
Training loss: 3.186240452257879
Validation loss: 2.5454456055911283

Epoch: 6| Step: 12
Training loss: 3.0855011064066593
Validation loss: 2.552932726404811

Epoch: 6| Step: 13
Training loss: 2.135093614906682
Validation loss: 2.5488695268824517

Epoch: 252| Step: 0
Training loss: 2.6150476618374743
Validation loss: 2.5534205211867196

Epoch: 6| Step: 1
Training loss: 3.204271660230854
Validation loss: 2.560776826188435

Epoch: 6| Step: 2
Training loss: 3.096212004704486
Validation loss: 2.564346003711713

Epoch: 6| Step: 3
Training loss: 2.8170430261144794
Validation loss: 2.579532953550451

Epoch: 6| Step: 4
Training loss: 3.124444530710744
Validation loss: 2.5882203865112743

Epoch: 6| Step: 5
Training loss: 2.6121272574089733
Validation loss: 2.5961781421313677

Epoch: 6| Step: 6
Training loss: 2.978663706616075
Validation loss: 2.6095455163824064

Epoch: 6| Step: 7
Training loss: 3.0997398267287215
Validation loss: 2.6107945684147653

Epoch: 6| Step: 8
Training loss: 2.750234420495057
Validation loss: 2.642460732950558

Epoch: 6| Step: 9
Training loss: 3.2043744883379706
Validation loss: 2.630866949388112

Epoch: 6| Step: 10
Training loss: 2.602787313734472
Validation loss: 2.5702329473012746

Epoch: 6| Step: 11
Training loss: 3.0502960561678987
Validation loss: 2.5691513748748696

Epoch: 6| Step: 12
Training loss: 3.0964494738122355
Validation loss: 2.5667728523031155

Epoch: 6| Step: 13
Training loss: 1.833226641527095
Validation loss: 2.5500186855139058

Epoch: 253| Step: 0
Training loss: 2.848157213308063
Validation loss: 2.5509414827301944

Epoch: 6| Step: 1
Training loss: 3.247585720372818
Validation loss: 2.543691826546949

Epoch: 6| Step: 2
Training loss: 2.841522853788277
Validation loss: 2.5419829696440175

Epoch: 6| Step: 3
Training loss: 2.877320224107512
Validation loss: 2.5414421568073045

Epoch: 6| Step: 4
Training loss: 2.790027868070166
Validation loss: 2.5433029883384286

Epoch: 6| Step: 5
Training loss: 3.333215965747855
Validation loss: 2.539975246195458

Epoch: 6| Step: 6
Training loss: 2.733156292306803
Validation loss: 2.537304571670092

Epoch: 6| Step: 7
Training loss: 2.282853908280759
Validation loss: 2.5360313791147346

Epoch: 6| Step: 8
Training loss: 2.981342472585592
Validation loss: 2.554417918351957

Epoch: 6| Step: 9
Training loss: 2.6027489325264974
Validation loss: 2.5499034908368663

Epoch: 6| Step: 10
Training loss: 3.2389851761019686
Validation loss: 2.5584290184102327

Epoch: 6| Step: 11
Training loss: 2.7348540840069195
Validation loss: 2.5577791990378937

Epoch: 6| Step: 12
Training loss: 2.542292679367566
Validation loss: 2.573883246403948

Epoch: 6| Step: 13
Training loss: 3.630252452930688
Validation loss: 2.5853699890234725

Epoch: 254| Step: 0
Training loss: 3.02468806778644
Validation loss: 2.574371768049047

Epoch: 6| Step: 1
Training loss: 2.7060362733663896
Validation loss: 2.583794010566871

Epoch: 6| Step: 2
Training loss: 2.79102433819275
Validation loss: 2.573534671381333

Epoch: 6| Step: 3
Training loss: 3.3935753427878588
Validation loss: 2.582590331393303

Epoch: 6| Step: 4
Training loss: 2.5188997172118373
Validation loss: 2.5760885598957435

Epoch: 6| Step: 5
Training loss: 3.2116059955540486
Validation loss: 2.578650771518311

Epoch: 6| Step: 6
Training loss: 2.6474961489900672
Validation loss: 2.6054292609946854

Epoch: 6| Step: 7
Training loss: 2.8199672329128487
Validation loss: 2.615586961877924

Epoch: 6| Step: 8
Training loss: 2.8064214505366487
Validation loss: 2.6155666797683534

Epoch: 6| Step: 9
Training loss: 3.130029521961352
Validation loss: 2.6112690109272245

Epoch: 6| Step: 10
Training loss: 2.983767142979725
Validation loss: 2.572144076051969

Epoch: 6| Step: 11
Training loss: 2.472667338510633
Validation loss: 2.5544726004881864

Epoch: 6| Step: 12
Training loss: 3.226422101307525
Validation loss: 2.5536286353998245

Epoch: 6| Step: 13
Training loss: 2.803937636417918
Validation loss: 2.5588211450740603

Epoch: 255| Step: 0
Training loss: 2.848344047381892
Validation loss: 2.555228064851453

Epoch: 6| Step: 1
Training loss: 2.790910979138414
Validation loss: 2.550442255167274

Epoch: 6| Step: 2
Training loss: 3.197926540960088
Validation loss: 2.551178899796829

Epoch: 6| Step: 3
Training loss: 2.3832557140951303
Validation loss: 2.559311500516945

Epoch: 6| Step: 4
Training loss: 2.9219141666826793
Validation loss: 2.568469864248106

Epoch: 6| Step: 5
Training loss: 3.1042109407344074
Validation loss: 2.586256908100093

Epoch: 6| Step: 6
Training loss: 3.2637785295447044
Validation loss: 2.6074670815743914

Epoch: 6| Step: 7
Training loss: 2.7647865015696014
Validation loss: 2.6174662221674314

Epoch: 6| Step: 8
Training loss: 2.813553167887153
Validation loss: 2.61746226426358

Epoch: 6| Step: 9
Training loss: 2.7525106586800825
Validation loss: 2.6266977130129905

Epoch: 6| Step: 10
Training loss: 3.2909288343989775
Validation loss: 2.6404183104140486

Epoch: 6| Step: 11
Training loss: 2.821934706350939
Validation loss: 2.6318956309032

Epoch: 6| Step: 12
Training loss: 3.059113790799321
Validation loss: 2.6142942537359097

Epoch: 6| Step: 13
Training loss: 2.931261946729053
Validation loss: 2.6108908339617125

Epoch: 256| Step: 0
Training loss: 2.899493166601526
Validation loss: 2.595917196747328

Epoch: 6| Step: 1
Training loss: 3.0021929673015757
Validation loss: 2.5873688792056124

Epoch: 6| Step: 2
Training loss: 2.8822315323299463
Validation loss: 2.588925047497286

Epoch: 6| Step: 3
Training loss: 2.970860584307039
Validation loss: 2.583942772796233

Epoch: 6| Step: 4
Training loss: 3.4710993328646302
Validation loss: 2.5925436484871374

Epoch: 6| Step: 5
Training loss: 2.2531561437986056
Validation loss: 2.6112479088828784

Epoch: 6| Step: 6
Training loss: 3.2547688342630026
Validation loss: 2.6085347598658557

Epoch: 6| Step: 7
Training loss: 3.120426493373833
Validation loss: 2.604025986019718

Epoch: 6| Step: 8
Training loss: 3.208961788569326
Validation loss: 2.6200229517646787

Epoch: 6| Step: 9
Training loss: 2.8069905890458893
Validation loss: 2.640347552543012

Epoch: 6| Step: 10
Training loss: 2.0886770253700293
Validation loss: 2.704181155398811

Epoch: 6| Step: 11
Training loss: 3.2122761332959793
Validation loss: 2.767568328307685

Epoch: 6| Step: 12
Training loss: 2.966240876606166
Validation loss: 2.7639948464109567

Epoch: 6| Step: 13
Training loss: 2.7490875290874657
Validation loss: 2.7214416260621137

Epoch: 257| Step: 0
Training loss: 2.9241758049377937
Validation loss: 2.6950321935726596

Epoch: 6| Step: 1
Training loss: 2.40743781162962
Validation loss: 2.6554580810918753

Epoch: 6| Step: 2
Training loss: 2.7624367477977656
Validation loss: 2.609532273477373

Epoch: 6| Step: 3
Training loss: 2.669992330161519
Validation loss: 2.5987101734022535

Epoch: 6| Step: 4
Training loss: 2.925990994807875
Validation loss: 2.5878435815616627

Epoch: 6| Step: 5
Training loss: 2.9139119536346936
Validation loss: 2.580091568766332

Epoch: 6| Step: 6
Training loss: 2.9019970693225114
Validation loss: 2.570790602159584

Epoch: 6| Step: 7
Training loss: 2.987519689518995
Validation loss: 2.570427106176181

Epoch: 6| Step: 8
Training loss: 3.2308409913445972
Validation loss: 2.5581608532325992

Epoch: 6| Step: 9
Training loss: 3.5361394200003855
Validation loss: 2.5674876712918806

Epoch: 6| Step: 10
Training loss: 2.550315358726265
Validation loss: 2.556135124896592

Epoch: 6| Step: 11
Training loss: 3.118232112229188
Validation loss: 2.558662412251761

Epoch: 6| Step: 12
Training loss: 2.947164019330437
Validation loss: 2.554600757597505

Epoch: 6| Step: 13
Training loss: 2.740186955972242
Validation loss: 2.5563774679442095

Epoch: 258| Step: 0
Training loss: 2.9902318235619423
Validation loss: 2.5550764789416682

Epoch: 6| Step: 1
Training loss: 2.7833756456947
Validation loss: 2.563498829828404

Epoch: 6| Step: 2
Training loss: 2.972715760686758
Validation loss: 2.5581215128406556

Epoch: 6| Step: 3
Training loss: 2.7213618568907987
Validation loss: 2.570627277467871

Epoch: 6| Step: 4
Training loss: 3.022393886826948
Validation loss: 2.5912847089145794

Epoch: 6| Step: 5
Training loss: 2.908352327330321
Validation loss: 2.598794967058005

Epoch: 6| Step: 6
Training loss: 2.5618919953831583
Validation loss: 2.6335554608557934

Epoch: 6| Step: 7
Training loss: 3.3222070651805478
Validation loss: 2.685732339579663

Epoch: 6| Step: 8
Training loss: 2.429778364144505
Validation loss: 2.725626455646545

Epoch: 6| Step: 9
Training loss: 3.0185595845257107
Validation loss: 2.7245880066131516

Epoch: 6| Step: 10
Training loss: 3.272826800133468
Validation loss: 2.7351885254291957

Epoch: 6| Step: 11
Training loss: 3.080429531218294
Validation loss: 2.7018120658450044

Epoch: 6| Step: 12
Training loss: 3.250147302663938
Validation loss: 2.688249911216196

Epoch: 6| Step: 13
Training loss: 2.896327975906485
Validation loss: 2.664713883522142

Epoch: 259| Step: 0
Training loss: 2.9915783613201485
Validation loss: 2.6429452844400805

Epoch: 6| Step: 1
Training loss: 3.0087123565157383
Validation loss: 2.619369630064877

Epoch: 6| Step: 2
Training loss: 2.875469003652586
Validation loss: 2.5996324619779863

Epoch: 6| Step: 3
Training loss: 2.8270399846965804
Validation loss: 2.5898039791911738

Epoch: 6| Step: 4
Training loss: 3.095084162786441
Validation loss: 2.58184993676276

Epoch: 6| Step: 5
Training loss: 2.866351179756828
Validation loss: 2.5692750021478403

Epoch: 6| Step: 6
Training loss: 2.4171253514453093
Validation loss: 2.566602831394152

Epoch: 6| Step: 7
Training loss: 2.565482102386133
Validation loss: 2.553414728085613

Epoch: 6| Step: 8
Training loss: 2.808603172657829
Validation loss: 2.538931855152847

Epoch: 6| Step: 9
Training loss: 3.603233231228299
Validation loss: 2.536831479987238

Epoch: 6| Step: 10
Training loss: 2.337795475526952
Validation loss: 2.536808208521317

Epoch: 6| Step: 11
Training loss: 3.127052853558794
Validation loss: 2.5359851720692235

Epoch: 6| Step: 12
Training loss: 3.0893773475621074
Validation loss: 2.5407813083668427

Epoch: 6| Step: 13
Training loss: 2.8873265598276094
Validation loss: 2.535281637098692

Epoch: 260| Step: 0
Training loss: 2.8963044329958323
Validation loss: 2.541492173411499

Epoch: 6| Step: 1
Training loss: 3.106118648829743
Validation loss: 2.551225349164207

Epoch: 6| Step: 2
Training loss: 2.3363710339229717
Validation loss: 2.554552599330089

Epoch: 6| Step: 3
Training loss: 3.0145530574379342
Validation loss: 2.562493637161099

Epoch: 6| Step: 4
Training loss: 2.928242156495121
Validation loss: 2.569458910358049

Epoch: 6| Step: 5
Training loss: 1.8693607722856627
Validation loss: 2.588042506820397

Epoch: 6| Step: 6
Training loss: 2.950821881649531
Validation loss: 2.6103996056770096

Epoch: 6| Step: 7
Training loss: 3.9281026932136864
Validation loss: 2.609983230253747

Epoch: 6| Step: 8
Training loss: 3.3751113308098932
Validation loss: 2.601759084546418

Epoch: 6| Step: 9
Training loss: 3.102921733364577
Validation loss: 2.5742986002775887

Epoch: 6| Step: 10
Training loss: 2.8002671284634926
Validation loss: 2.5593034018281653

Epoch: 6| Step: 11
Training loss: 2.8628175784189756
Validation loss: 2.544241563347739

Epoch: 6| Step: 12
Training loss: 2.291823560950447
Validation loss: 2.5452200870903794

Epoch: 6| Step: 13
Training loss: 2.465987869461803
Validation loss: 2.5426080440763323

Epoch: 261| Step: 0
Training loss: 2.942043929362681
Validation loss: 2.541947609678763

Epoch: 6| Step: 1
Training loss: 2.9479288880507117
Validation loss: 2.549436491910829

Epoch: 6| Step: 2
Training loss: 2.673931735631792
Validation loss: 2.546260987968505

Epoch: 6| Step: 3
Training loss: 2.6048738867166374
Validation loss: 2.5417839324490092

Epoch: 6| Step: 4
Training loss: 2.953001312410584
Validation loss: 2.548469395189351

Epoch: 6| Step: 5
Training loss: 2.8872344055890893
Validation loss: 2.542367434781146

Epoch: 6| Step: 6
Training loss: 3.030402468148005
Validation loss: 2.544212804568712

Epoch: 6| Step: 7
Training loss: 2.5421837973728896
Validation loss: 2.5455798387754625

Epoch: 6| Step: 8
Training loss: 3.3996736930891505
Validation loss: 2.5536054115967737

Epoch: 6| Step: 9
Training loss: 3.1280350252029603
Validation loss: 2.5519095774590586

Epoch: 6| Step: 10
Training loss: 3.076047244499119
Validation loss: 2.5319604305868437

Epoch: 6| Step: 11
Training loss: 2.5693099550900254
Validation loss: 2.526333369589418

Epoch: 6| Step: 12
Training loss: 2.57714640222305
Validation loss: 2.5253127438147818

Epoch: 6| Step: 13
Training loss: 3.0501201856103113
Validation loss: 2.5232785483854685

Epoch: 262| Step: 0
Training loss: 3.375652250205706
Validation loss: 2.528992261149411

Epoch: 6| Step: 1
Training loss: 2.7430390777307583
Validation loss: 2.5282962204609447

Epoch: 6| Step: 2
Training loss: 2.882974925027091
Validation loss: 2.529963464287902

Epoch: 6| Step: 3
Training loss: 3.104598934789877
Validation loss: 2.5277528880665128

Epoch: 6| Step: 4
Training loss: 2.658207430194897
Validation loss: 2.5270962737025964

Epoch: 6| Step: 5
Training loss: 3.1611178789325205
Validation loss: 2.531522494382079

Epoch: 6| Step: 6
Training loss: 2.705071250273304
Validation loss: 2.528286173931714

Epoch: 6| Step: 7
Training loss: 2.415231168751915
Validation loss: 2.536129568691939

Epoch: 6| Step: 8
Training loss: 2.83647600425981
Validation loss: 2.556965873457516

Epoch: 6| Step: 9
Training loss: 2.2591295459849117
Validation loss: 2.560258595901032

Epoch: 6| Step: 10
Training loss: 2.8162056141152267
Validation loss: 2.5818570914338124

Epoch: 6| Step: 11
Training loss: 3.0513307513686625
Validation loss: 2.579384038865557

Epoch: 6| Step: 12
Training loss: 2.7746280317768144
Validation loss: 2.587377607405309

Epoch: 6| Step: 13
Training loss: 3.7822085339987956
Validation loss: 2.582077131452772

Epoch: 263| Step: 0
Training loss: 2.430149635448687
Validation loss: 2.5607838209926967

Epoch: 6| Step: 1
Training loss: 2.4654567337154294
Validation loss: 2.53165247148343

Epoch: 6| Step: 2
Training loss: 3.1446935007636463
Validation loss: 2.5305854211559864

Epoch: 6| Step: 3
Training loss: 2.953554636870792
Validation loss: 2.524696603118408

Epoch: 6| Step: 4
Training loss: 3.2525821111871487
Validation loss: 2.524677288133462

Epoch: 6| Step: 5
Training loss: 2.939364065044097
Validation loss: 2.5222267734339017

Epoch: 6| Step: 6
Training loss: 2.738604429930108
Validation loss: 2.5279840293338007

Epoch: 6| Step: 7
Training loss: 2.837146007622254
Validation loss: 2.522603724101372

Epoch: 6| Step: 8
Training loss: 3.102987043957919
Validation loss: 2.5262639443415544

Epoch: 6| Step: 9
Training loss: 2.8713880323247385
Validation loss: 2.5228878728017192

Epoch: 6| Step: 10
Training loss: 3.040344752288555
Validation loss: 2.5181835495478313

Epoch: 6| Step: 11
Training loss: 2.295730097873331
Validation loss: 2.526014232497095

Epoch: 6| Step: 12
Training loss: 3.369871835280722
Validation loss: 2.5201326347444692

Epoch: 6| Step: 13
Training loss: 2.6684209794997167
Validation loss: 2.518019857829052

Epoch: 264| Step: 0
Training loss: 3.037978736607146
Validation loss: 2.528783106834008

Epoch: 6| Step: 1
Training loss: 2.6906548546033067
Validation loss: 2.5338491871389475

Epoch: 6| Step: 2
Training loss: 3.3524811737191906
Validation loss: 2.5438733849028896

Epoch: 6| Step: 3
Training loss: 2.488379364235197
Validation loss: 2.5668089779108696

Epoch: 6| Step: 4
Training loss: 2.9389969278470724
Validation loss: 2.581790567271295

Epoch: 6| Step: 5
Training loss: 2.880704444986544
Validation loss: 2.602446209685375

Epoch: 6| Step: 6
Training loss: 2.863026606333196
Validation loss: 2.6250746257856674

Epoch: 6| Step: 7
Training loss: 2.5685217280256922
Validation loss: 2.616584813494339

Epoch: 6| Step: 8
Training loss: 2.87402194428478
Validation loss: 2.6094856752078064

Epoch: 6| Step: 9
Training loss: 2.874065413121519
Validation loss: 2.6011299449455856

Epoch: 6| Step: 10
Training loss: 3.3507232682344994
Validation loss: 2.6014889981990716

Epoch: 6| Step: 11
Training loss: 2.4108323890780006
Validation loss: 2.5769268395206506

Epoch: 6| Step: 12
Training loss: 3.182631420889084
Validation loss: 2.5801422063240094

Epoch: 6| Step: 13
Training loss: 2.6876275675460497
Validation loss: 2.543318937817814

Epoch: 265| Step: 0
Training loss: 2.6080657049807203
Validation loss: 2.5328564991584313

Epoch: 6| Step: 1
Training loss: 2.9824431393008313
Validation loss: 2.5279529326342023

Epoch: 6| Step: 2
Training loss: 2.7098583525065316
Validation loss: 2.525043543989735

Epoch: 6| Step: 3
Training loss: 2.553079361431807
Validation loss: 2.5203812713432647

Epoch: 6| Step: 4
Training loss: 2.8765077369197325
Validation loss: 2.528371931151555

Epoch: 6| Step: 5
Training loss: 2.8589217029910086
Validation loss: 2.5270685975330296

Epoch: 6| Step: 6
Training loss: 3.489731575773023
Validation loss: 2.5338845306132924

Epoch: 6| Step: 7
Training loss: 3.120268635066614
Validation loss: 2.5237865886575386

Epoch: 6| Step: 8
Training loss: 1.8941667029060105
Validation loss: 2.5200866336388175

Epoch: 6| Step: 9
Training loss: 3.1676523448073457
Validation loss: 2.5236654678671866

Epoch: 6| Step: 10
Training loss: 3.147607736599492
Validation loss: 2.526621109767699

Epoch: 6| Step: 11
Training loss: 3.0245286810800427
Validation loss: 2.5185706461094135

Epoch: 6| Step: 12
Training loss: 3.1251843207360137
Validation loss: 2.524422674255033

Epoch: 6| Step: 13
Training loss: 2.169592666718234
Validation loss: 2.5305186898637797

Epoch: 266| Step: 0
Training loss: 2.610745007526344
Validation loss: 2.5430802970313775

Epoch: 6| Step: 1
Training loss: 3.067614585769564
Validation loss: 2.538352945161893

Epoch: 6| Step: 2
Training loss: 2.758170042554044
Validation loss: 2.5462344700589203

Epoch: 6| Step: 3
Training loss: 2.5561521105688767
Validation loss: 2.5714583897330776

Epoch: 6| Step: 4
Training loss: 3.2183991768764093
Validation loss: 2.5690467576229477

Epoch: 6| Step: 5
Training loss: 2.9545607533092153
Validation loss: 2.578170805791724

Epoch: 6| Step: 6
Training loss: 3.0145177834499237
Validation loss: 2.5856313761870164

Epoch: 6| Step: 7
Training loss: 2.5667172596226346
Validation loss: 2.5761134121037657

Epoch: 6| Step: 8
Training loss: 2.738129572129846
Validation loss: 2.557188281878407

Epoch: 6| Step: 9
Training loss: 2.9627506069626612
Validation loss: 2.551030524256599

Epoch: 6| Step: 10
Training loss: 2.5837549870428598
Validation loss: 2.5426027818990367

Epoch: 6| Step: 11
Training loss: 2.7050936371396386
Validation loss: 2.5364064560869197

Epoch: 6| Step: 12
Training loss: 3.5966122051519602
Validation loss: 2.5292877162891534

Epoch: 6| Step: 13
Training loss: 2.6679936822533334
Validation loss: 2.5277276891900633

Epoch: 267| Step: 0
Training loss: 2.7004242563712455
Validation loss: 2.5233375801041693

Epoch: 6| Step: 1
Training loss: 2.9748549482101856
Validation loss: 2.5185273373556525

Epoch: 6| Step: 2
Training loss: 2.695566801154459
Validation loss: 2.5133893537176504

Epoch: 6| Step: 3
Training loss: 2.6244259161119707
Validation loss: 2.5118184360212066

Epoch: 6| Step: 4
Training loss: 2.344750762903537
Validation loss: 2.5214933841294296

Epoch: 6| Step: 5
Training loss: 2.648476389371556
Validation loss: 2.514955194394185

Epoch: 6| Step: 6
Training loss: 3.3996736930891505
Validation loss: 2.5150851622865953

Epoch: 6| Step: 7
Training loss: 2.7326773468848704
Validation loss: 2.5172291978656824

Epoch: 6| Step: 8
Training loss: 2.442258445016796
Validation loss: 2.515928343517309

Epoch: 6| Step: 9
Training loss: 3.0469354085558056
Validation loss: 2.515201583669524

Epoch: 6| Step: 10
Training loss: 3.182285606432616
Validation loss: 2.5176200367109307

Epoch: 6| Step: 11
Training loss: 3.104744228080915
Validation loss: 2.523817872806245

Epoch: 6| Step: 12
Training loss: 3.222845194508435
Validation loss: 2.517538849003108

Epoch: 6| Step: 13
Training loss: 2.9833503282229867
Validation loss: 2.5366341306191957

Epoch: 268| Step: 0
Training loss: 3.1741583361874808
Validation loss: 2.5502601732897494

Epoch: 6| Step: 1
Training loss: 2.0267311890687774
Validation loss: 2.5738565349859344

Epoch: 6| Step: 2
Training loss: 2.904911676531613
Validation loss: 2.5839628070613925

Epoch: 6| Step: 3
Training loss: 3.539051855883897
Validation loss: 2.6366143450011728

Epoch: 6| Step: 4
Training loss: 2.5222008098789446
Validation loss: 2.6664981468337934

Epoch: 6| Step: 5
Training loss: 2.684613474155122
Validation loss: 2.682966439212101

Epoch: 6| Step: 6
Training loss: 3.056700528566364
Validation loss: 2.679560763764517

Epoch: 6| Step: 7
Training loss: 3.328804340785652
Validation loss: 2.654122062801952

Epoch: 6| Step: 8
Training loss: 2.74871215141992
Validation loss: 2.5982292540703518

Epoch: 6| Step: 9
Training loss: 2.851036713084465
Validation loss: 2.5858391088535475

Epoch: 6| Step: 10
Training loss: 2.7952217884815074
Validation loss: 2.542377840103846

Epoch: 6| Step: 11
Training loss: 2.6363472683915647
Validation loss: 2.5150892721238094

Epoch: 6| Step: 12
Training loss: 2.851194593132878
Validation loss: 2.5250391914561314

Epoch: 6| Step: 13
Training loss: 2.865441063288969
Validation loss: 2.5335289011657354

Epoch: 269| Step: 0
Training loss: 3.0113441244183545
Validation loss: 2.5392681008924036

Epoch: 6| Step: 1
Training loss: 2.9713154198775085
Validation loss: 2.543425948849085

Epoch: 6| Step: 2
Training loss: 3.1524875990936057
Validation loss: 2.565321268868033

Epoch: 6| Step: 3
Training loss: 2.856690360749605
Validation loss: 2.5571995121188795

Epoch: 6| Step: 4
Training loss: 3.1097037750177066
Validation loss: 2.553328430407009

Epoch: 6| Step: 5
Training loss: 2.9901925949277484
Validation loss: 2.530580554400115

Epoch: 6| Step: 6
Training loss: 2.96120449664032
Validation loss: 2.524928639460577

Epoch: 6| Step: 7
Training loss: 2.649738003717025
Validation loss: 2.51997097102346

Epoch: 6| Step: 8
Training loss: 2.4430319782464207
Validation loss: 2.5191547687093467

Epoch: 6| Step: 9
Training loss: 2.7857975161348896
Validation loss: 2.524356053236998

Epoch: 6| Step: 10
Training loss: 2.9633402473818173
Validation loss: 2.5391732079892333

Epoch: 6| Step: 11
Training loss: 3.5177731880864385
Validation loss: 2.5796270117468616

Epoch: 6| Step: 12
Training loss: 2.1903711277978064
Validation loss: 2.638025725716811

Epoch: 6| Step: 13
Training loss: 3.3339790831369105
Validation loss: 2.693617527628034

Epoch: 270| Step: 0
Training loss: 3.1820704273459826
Validation loss: 2.7410888022743602

Epoch: 6| Step: 1
Training loss: 2.892121953236934
Validation loss: 2.710609810809179

Epoch: 6| Step: 2
Training loss: 2.731608708131232
Validation loss: 2.627278957431748

Epoch: 6| Step: 3
Training loss: 3.1259129525803138
Validation loss: 2.556815444382998

Epoch: 6| Step: 4
Training loss: 3.1525751759265255
Validation loss: 2.526807114975349

Epoch: 6| Step: 5
Training loss: 2.2022434933059953
Validation loss: 2.5186751746383558

Epoch: 6| Step: 6
Training loss: 2.352518590677324
Validation loss: 2.518809789201759

Epoch: 6| Step: 7
Training loss: 3.085837678864177
Validation loss: 2.513271733482734

Epoch: 6| Step: 8
Training loss: 2.910020412884721
Validation loss: 2.511320981053859

Epoch: 6| Step: 9
Training loss: 3.082115104511195
Validation loss: 2.516939160706902

Epoch: 6| Step: 10
Training loss: 3.334701130299081
Validation loss: 2.5226249944942496

Epoch: 6| Step: 11
Training loss: 2.978421649388382
Validation loss: 2.5251912038417164

Epoch: 6| Step: 12
Training loss: 2.5921614964648487
Validation loss: 2.5332716537095488

Epoch: 6| Step: 13
Training loss: 3.104927601238964
Validation loss: 2.53135817749966

Epoch: 271| Step: 0
Training loss: 2.1544812452978865
Validation loss: 2.5363194119177717

Epoch: 6| Step: 1
Training loss: 2.4426127878032853
Validation loss: 2.5349174050890646

Epoch: 6| Step: 2
Training loss: 3.179325467431173
Validation loss: 2.545142018958111

Epoch: 6| Step: 3
Training loss: 2.775592149670235
Validation loss: 2.5521964601645246

Epoch: 6| Step: 4
Training loss: 3.4610006012341525
Validation loss: 2.5700875894629696

Epoch: 6| Step: 5
Training loss: 2.7850093508551432
Validation loss: 2.5964988674509373

Epoch: 6| Step: 6
Training loss: 2.4494601530753477
Validation loss: 2.6275580228846347

Epoch: 6| Step: 7
Training loss: 3.608141932062027
Validation loss: 2.659773050024245

Epoch: 6| Step: 8
Training loss: 2.8290631334764873
Validation loss: 2.6806860143614912

Epoch: 6| Step: 9
Training loss: 3.1862391053616244
Validation loss: 2.6785155041741224

Epoch: 6| Step: 10
Training loss: 2.7926322254100926
Validation loss: 2.583386562234351

Epoch: 6| Step: 11
Training loss: 3.0956566070045963
Validation loss: 2.525725355389072

Epoch: 6| Step: 12
Training loss: 2.736228271230804
Validation loss: 2.51503952449854

Epoch: 6| Step: 13
Training loss: 2.823595835685118
Validation loss: 2.509996221626372

Epoch: 272| Step: 0
Training loss: 3.1854932863556615
Validation loss: 2.5119378235771

Epoch: 6| Step: 1
Training loss: 2.8154608506123053
Validation loss: 2.517010879189063

Epoch: 6| Step: 2
Training loss: 3.0798647848396703
Validation loss: 2.513933124793993

Epoch: 6| Step: 3
Training loss: 2.673352552409861
Validation loss: 2.525161778349898

Epoch: 6| Step: 4
Training loss: 2.5833736744673916
Validation loss: 2.520395181020086

Epoch: 6| Step: 5
Training loss: 3.013079107188651
Validation loss: 2.51991090005653

Epoch: 6| Step: 6
Training loss: 2.5757618564087355
Validation loss: 2.521575932934941

Epoch: 6| Step: 7
Training loss: 3.2971885495893267
Validation loss: 2.523481515881303

Epoch: 6| Step: 8
Training loss: 3.409286965021173
Validation loss: 2.5231426166658895

Epoch: 6| Step: 9
Training loss: 3.2497728708570084
Validation loss: 2.5293221058808317

Epoch: 6| Step: 10
Training loss: 2.2115020570342234
Validation loss: 2.5167174859047647

Epoch: 6| Step: 11
Training loss: 2.935938968221593
Validation loss: 2.523498588261217

Epoch: 6| Step: 12
Training loss: 2.6782572407606344
Validation loss: 2.519392939532307

Epoch: 6| Step: 13
Training loss: 2.796153822682822
Validation loss: 2.5075851049568185

Epoch: 273| Step: 0
Training loss: 3.2322731744497677
Validation loss: 2.5068511617919773

Epoch: 6| Step: 1
Training loss: 2.5702066602627
Validation loss: 2.508115645648051

Epoch: 6| Step: 2
Training loss: 3.0016951540100507
Validation loss: 2.506907663795236

Epoch: 6| Step: 3
Training loss: 3.0031516686246773
Validation loss: 2.5062933709926885

Epoch: 6| Step: 4
Training loss: 2.9660551991178226
Validation loss: 2.5092416194492895

Epoch: 6| Step: 5
Training loss: 2.70071144620706
Validation loss: 2.5104312344006163

Epoch: 6| Step: 6
Training loss: 3.3072646893379725
Validation loss: 2.5172391663122893

Epoch: 6| Step: 7
Training loss: 2.892132670059516
Validation loss: 2.514155127689506

Epoch: 6| Step: 8
Training loss: 3.216470448203285
Validation loss: 2.519434055858489

Epoch: 6| Step: 9
Training loss: 2.4626698043292423
Validation loss: 2.521987140121827

Epoch: 6| Step: 10
Training loss: 2.9636244044405666
Validation loss: 2.5194916930880864

Epoch: 6| Step: 11
Training loss: 2.6572034134534657
Validation loss: 2.525397038685395

Epoch: 6| Step: 12
Training loss: 2.051981837930297
Validation loss: 2.524178296169915

Epoch: 6| Step: 13
Training loss: 3.1683141705854734
Validation loss: 2.523312218264636

Epoch: 274| Step: 0
Training loss: 3.053017396309423
Validation loss: 2.5284597893350913

Epoch: 6| Step: 1
Training loss: 3.006480370337402
Validation loss: 2.523746929819286

Epoch: 6| Step: 2
Training loss: 3.322874413742842
Validation loss: 2.5207734042794883

Epoch: 6| Step: 3
Training loss: 3.188931162558027
Validation loss: 2.526432767140927

Epoch: 6| Step: 4
Training loss: 3.269338586159988
Validation loss: 2.5230124023538982

Epoch: 6| Step: 5
Training loss: 2.8023427869137336
Validation loss: 2.522822718248242

Epoch: 6| Step: 6
Training loss: 2.9004664144664307
Validation loss: 2.5236948874414664

Epoch: 6| Step: 7
Training loss: 2.820998850652169
Validation loss: 2.5222135975526885

Epoch: 6| Step: 8
Training loss: 1.9769023859356503
Validation loss: 2.5185231262478283

Epoch: 6| Step: 9
Training loss: 2.3111996474281957
Validation loss: 2.516591711733858

Epoch: 6| Step: 10
Training loss: 2.816837865001949
Validation loss: 2.521248983436997

Epoch: 6| Step: 11
Training loss: 2.724404079127167
Validation loss: 2.5310141006469586

Epoch: 6| Step: 12
Training loss: 2.928600221419266
Validation loss: 2.5418305181995464

Epoch: 6| Step: 13
Training loss: 2.6095126909487165
Validation loss: 2.546275664422341

Epoch: 275| Step: 0
Training loss: 3.1251095561850595
Validation loss: 2.581774395710875

Epoch: 6| Step: 1
Training loss: 2.7382274410168694
Validation loss: 2.590140347305102

Epoch: 6| Step: 2
Training loss: 2.971793130896193
Validation loss: 2.6012163864144524

Epoch: 6| Step: 3
Training loss: 2.4262628000541815
Validation loss: 2.603715368400166

Epoch: 6| Step: 4
Training loss: 2.7713805401675153
Validation loss: 2.5945692571111825

Epoch: 6| Step: 5
Training loss: 2.732968213730848
Validation loss: 2.5774797344921914

Epoch: 6| Step: 6
Training loss: 2.931090809743181
Validation loss: 2.580924301855411

Epoch: 6| Step: 7
Training loss: 2.825473364271596
Validation loss: 2.5503508781026167

Epoch: 6| Step: 8
Training loss: 2.7818712547892392
Validation loss: 2.5357413785364438

Epoch: 6| Step: 9
Training loss: 3.1291576955965534
Validation loss: 2.523303929867147

Epoch: 6| Step: 10
Training loss: 3.127553583138948
Validation loss: 2.5237624482601864

Epoch: 6| Step: 11
Training loss: 2.6400723753747353
Validation loss: 2.5188395209538657

Epoch: 6| Step: 12
Training loss: 3.4042587759629415
Validation loss: 2.515618220005314

Epoch: 6| Step: 13
Training loss: 2.4819456494549077
Validation loss: 2.5180082848583387

Epoch: 276| Step: 0
Training loss: 2.8281584679746654
Validation loss: 2.5145025320362384

Epoch: 6| Step: 1
Training loss: 2.9006375499898525
Validation loss: 2.5138370695385754

Epoch: 6| Step: 2
Training loss: 2.746549522377055
Validation loss: 2.5212369860230064

Epoch: 6| Step: 3
Training loss: 2.52079374634316
Validation loss: 2.512276954650014

Epoch: 6| Step: 4
Training loss: 2.6915556003894463
Validation loss: 2.516104893230721

Epoch: 6| Step: 5
Training loss: 2.9159636240549234
Validation loss: 2.512126132423056

Epoch: 6| Step: 6
Training loss: 3.103475062667591
Validation loss: 2.519375466900187

Epoch: 6| Step: 7
Training loss: 2.5186650642859774
Validation loss: 2.525109442279621

Epoch: 6| Step: 8
Training loss: 3.0842747325117377
Validation loss: 2.527514478547206

Epoch: 6| Step: 9
Training loss: 3.2037601492516736
Validation loss: 2.5321933493004023

Epoch: 6| Step: 10
Training loss: 2.097113341928968
Validation loss: 2.5410712432468414

Epoch: 6| Step: 11
Training loss: 3.4758005057221872
Validation loss: 2.5402229528493323

Epoch: 6| Step: 12
Training loss: 3.1756088754341785
Validation loss: 2.544671237686648

Epoch: 6| Step: 13
Training loss: 2.7059737172397544
Validation loss: 2.5443067638912233

Epoch: 277| Step: 0
Training loss: 3.414465559642299
Validation loss: 2.5536633055656854

Epoch: 6| Step: 1
Training loss: 2.971076455317959
Validation loss: 2.535068102080793

Epoch: 6| Step: 2
Training loss: 2.8974744322655073
Validation loss: 2.5220945490291697

Epoch: 6| Step: 3
Training loss: 2.7479533469003297
Validation loss: 2.5268579660825083

Epoch: 6| Step: 4
Training loss: 3.1371124514561246
Validation loss: 2.5230340391597914

Epoch: 6| Step: 5
Training loss: 2.6298750159441617
Validation loss: 2.518436857553649

Epoch: 6| Step: 6
Training loss: 3.1461212498022118
Validation loss: 2.5267811609452555

Epoch: 6| Step: 7
Training loss: 2.301747557949421
Validation loss: 2.5297118952168356

Epoch: 6| Step: 8
Training loss: 2.75653928592336
Validation loss: 2.5180464275070005

Epoch: 6| Step: 9
Training loss: 3.0293028565181115
Validation loss: 2.5331107020173778

Epoch: 6| Step: 10
Training loss: 2.8421854599016867
Validation loss: 2.5288528025310524

Epoch: 6| Step: 11
Training loss: 2.692330565722209
Validation loss: 2.532552530084251

Epoch: 6| Step: 12
Training loss: 2.614658876419458
Validation loss: 2.5382193216200486

Epoch: 6| Step: 13
Training loss: 2.728710039294418
Validation loss: 2.5289346569643483

Epoch: 278| Step: 0
Training loss: 2.513720057691863
Validation loss: 2.512608728416793

Epoch: 6| Step: 1
Training loss: 2.983158842414723
Validation loss: 2.5039923077535633

Epoch: 6| Step: 2
Training loss: 2.799462682394539
Validation loss: 2.5065584837139174

Epoch: 6| Step: 3
Training loss: 3.2247423113402935
Validation loss: 2.507520058859947

Epoch: 6| Step: 4
Training loss: 2.9361994684839763
Validation loss: 2.502999180253266

Epoch: 6| Step: 5
Training loss: 2.7364643071204653
Validation loss: 2.506932672103256

Epoch: 6| Step: 6
Training loss: 3.0898823307681416
Validation loss: 2.509292478137645

Epoch: 6| Step: 7
Training loss: 3.3870693144146626
Validation loss: 2.5190155928668374

Epoch: 6| Step: 8
Training loss: 3.2238367866114106
Validation loss: 2.513298418638073

Epoch: 6| Step: 9
Training loss: 2.781403783768516
Validation loss: 2.5191017430267513

Epoch: 6| Step: 10
Training loss: 2.1404777531901273
Validation loss: 2.5225452666907926

Epoch: 6| Step: 11
Training loss: 2.4673008588921204
Validation loss: 2.528977672943919

Epoch: 6| Step: 12
Training loss: 2.977496944140861
Validation loss: 2.544054222897257

Epoch: 6| Step: 13
Training loss: 2.552124510971346
Validation loss: 2.533941586221226

Epoch: 279| Step: 0
Training loss: 2.6411287628526887
Validation loss: 2.532317785698322

Epoch: 6| Step: 1
Training loss: 2.7736812860505284
Validation loss: 2.521900557889802

Epoch: 6| Step: 2
Training loss: 3.148496565726196
Validation loss: 2.5285665441083496

Epoch: 6| Step: 3
Training loss: 3.4838970865845202
Validation loss: 2.5366906109857608

Epoch: 6| Step: 4
Training loss: 2.810930365086354
Validation loss: 2.571502285498303

Epoch: 6| Step: 5
Training loss: 2.4887947738352256
Validation loss: 2.5798381643436366

Epoch: 6| Step: 6
Training loss: 2.931571659748442
Validation loss: 2.6014706258734566

Epoch: 6| Step: 7
Training loss: 2.611143141295302
Validation loss: 2.6190453987740763

Epoch: 6| Step: 8
Training loss: 2.9844123877934563
Validation loss: 2.5904314398282495

Epoch: 6| Step: 9
Training loss: 2.9893145999792203
Validation loss: 2.5626111860587

Epoch: 6| Step: 10
Training loss: 2.024232450473464
Validation loss: 2.544977963927131

Epoch: 6| Step: 11
Training loss: 2.6872428948488314
Validation loss: 2.535809209824647

Epoch: 6| Step: 12
Training loss: 3.1859752523702722
Validation loss: 2.525966362464508

Epoch: 6| Step: 13
Training loss: 3.41756303395628
Validation loss: 2.5213925666687076

Epoch: 280| Step: 0
Training loss: 2.8089225905478314
Validation loss: 2.5149633176479416

Epoch: 6| Step: 1
Training loss: 3.03332479985752
Validation loss: 2.5209936770485597

Epoch: 6| Step: 2
Training loss: 2.8185762677500894
Validation loss: 2.515654922253384

Epoch: 6| Step: 3
Training loss: 3.258377721407727
Validation loss: 2.5130614891038676

Epoch: 6| Step: 4
Training loss: 3.089799767336694
Validation loss: 2.5169024659817265

Epoch: 6| Step: 5
Training loss: 2.5000288961647894
Validation loss: 2.524078070427329

Epoch: 6| Step: 6
Training loss: 3.018304928653496
Validation loss: 2.532024802251921

Epoch: 6| Step: 7
Training loss: 2.99151619733799
Validation loss: 2.528621295598556

Epoch: 6| Step: 8
Training loss: 3.2720035152463054
Validation loss: 2.5254344809642877

Epoch: 6| Step: 9
Training loss: 2.2310565768479917
Validation loss: 2.5147019964739448

Epoch: 6| Step: 10
Training loss: 3.1544729839092582
Validation loss: 2.5226558458997013

Epoch: 6| Step: 11
Training loss: 2.5277799203418785
Validation loss: 2.5088599062926704

Epoch: 6| Step: 12
Training loss: 2.4636258412686374
Validation loss: 2.5188433518990028

Epoch: 6| Step: 13
Training loss: 2.696949867809474
Validation loss: 2.524096467264635

Epoch: 281| Step: 0
Training loss: 3.042714569875944
Validation loss: 2.5176528444413497

Epoch: 6| Step: 1
Training loss: 2.8065599232156253
Validation loss: 2.5206019313053996

Epoch: 6| Step: 2
Training loss: 2.9578179102957485
Validation loss: 2.5270904877176084

Epoch: 6| Step: 3
Training loss: 2.86893353841234
Validation loss: 2.52018378125071

Epoch: 6| Step: 4
Training loss: 3.480123209471266
Validation loss: 2.527068317031473

Epoch: 6| Step: 5
Training loss: 2.740509998166186
Validation loss: 2.515049194808575

Epoch: 6| Step: 6
Training loss: 2.9674072441381343
Validation loss: 2.517627684995932

Epoch: 6| Step: 7
Training loss: 3.0783680466486527
Validation loss: 2.519231556019936

Epoch: 6| Step: 8
Training loss: 2.596678952966237
Validation loss: 2.524358069127198

Epoch: 6| Step: 9
Training loss: 2.8285367044296357
Validation loss: 2.5144741192826374

Epoch: 6| Step: 10
Training loss: 2.7686800704632826
Validation loss: 2.519784095937717

Epoch: 6| Step: 11
Training loss: 2.817054282459297
Validation loss: 2.5170772912907093

Epoch: 6| Step: 12
Training loss: 2.08994106173117
Validation loss: 2.5206253778210774

Epoch: 6| Step: 13
Training loss: 3.0474292740035347
Validation loss: 2.5073340420225443

Epoch: 282| Step: 0
Training loss: 2.650320188504215
Validation loss: 2.5077083355044345

Epoch: 6| Step: 1
Training loss: 2.8301544495078086
Validation loss: 2.5115680698183778

Epoch: 6| Step: 2
Training loss: 3.1669890256401887
Validation loss: 2.5140455002257363

Epoch: 6| Step: 3
Training loss: 2.7100293839892142
Validation loss: 2.5074254234525073

Epoch: 6| Step: 4
Training loss: 3.3851008967318372
Validation loss: 2.519035683503875

Epoch: 6| Step: 5
Training loss: 2.7899498476285762
Validation loss: 2.5301589619820777

Epoch: 6| Step: 6
Training loss: 2.8143951812433974
Validation loss: 2.5388603358406177

Epoch: 6| Step: 7
Training loss: 2.6952171419386057
Validation loss: 2.533691683994683

Epoch: 6| Step: 8
Training loss: 2.687906456307378
Validation loss: 2.5576191841905827

Epoch: 6| Step: 9
Training loss: 2.431943771891849
Validation loss: 2.545673420347735

Epoch: 6| Step: 10
Training loss: 3.0058484291040957
Validation loss: 2.543220072214686

Epoch: 6| Step: 11
Training loss: 2.8140803665364946
Validation loss: 2.543582241475427

Epoch: 6| Step: 12
Training loss: 2.9518053446637778
Validation loss: 2.5347316673403633

Epoch: 6| Step: 13
Training loss: 3.0800694554411914
Validation loss: 2.527712261016954

Epoch: 283| Step: 0
Training loss: 2.660661960207986
Validation loss: 2.5253385982225733

Epoch: 6| Step: 1
Training loss: 2.644420536941182
Validation loss: 2.5396258712512103

Epoch: 6| Step: 2
Training loss: 3.0740318386933296
Validation loss: 2.541200039891939

Epoch: 6| Step: 3
Training loss: 3.4239368932826624
Validation loss: 2.5463073236726554

Epoch: 6| Step: 4
Training loss: 2.783180681104681
Validation loss: 2.5191107337087835

Epoch: 6| Step: 5
Training loss: 2.7264166413126163
Validation loss: 2.5210055139314576

Epoch: 6| Step: 6
Training loss: 2.835673506458297
Validation loss: 2.5214718855950005

Epoch: 6| Step: 7
Training loss: 2.318732857448004
Validation loss: 2.5149856363284004

Epoch: 6| Step: 8
Training loss: 3.365111381421869
Validation loss: 2.5190787463962963

Epoch: 6| Step: 9
Training loss: 2.8436701836755596
Validation loss: 2.5025587748874263

Epoch: 6| Step: 10
Training loss: 2.205312738363159
Validation loss: 2.5036464718492573

Epoch: 6| Step: 11
Training loss: 3.159623562084121
Validation loss: 2.493843042294763

Epoch: 6| Step: 12
Training loss: 2.7986158355681425
Validation loss: 2.492199725723072

Epoch: 6| Step: 13
Training loss: 2.934365568460698
Validation loss: 2.509400499879617

Epoch: 284| Step: 0
Training loss: 2.7994806523282154
Validation loss: 2.5030324582083026

Epoch: 6| Step: 1
Training loss: 3.392234033716122
Validation loss: 2.5046731587299687

Epoch: 6| Step: 2
Training loss: 2.9488271289034946
Validation loss: 2.5240705005971678

Epoch: 6| Step: 3
Training loss: 2.8629086864857847
Validation loss: 2.5128366962147473

Epoch: 6| Step: 4
Training loss: 2.58696410669672
Validation loss: 2.5194017719622788

Epoch: 6| Step: 5
Training loss: 2.637912417886249
Validation loss: 2.5316494305378265

Epoch: 6| Step: 6
Training loss: 2.76390703366797
Validation loss: 2.5452178218126598

Epoch: 6| Step: 7
Training loss: 2.5608544997799014
Validation loss: 2.5503733675881

Epoch: 6| Step: 8
Training loss: 3.1875251320240845
Validation loss: 2.5812312381643245

Epoch: 6| Step: 9
Training loss: 2.6633443004142046
Validation loss: 2.553332902391598

Epoch: 6| Step: 10
Training loss: 2.7825663162650485
Validation loss: 2.523327278125824

Epoch: 6| Step: 11
Training loss: 2.903599668857142
Validation loss: 2.502019720588987

Epoch: 6| Step: 12
Training loss: 2.8604794229808532
Validation loss: 2.49173311214958

Epoch: 6| Step: 13
Training loss: 3.21519629583703
Validation loss: 2.4938170515395917

Epoch: 285| Step: 0
Training loss: 3.400112256833563
Validation loss: 2.4942435163070473

Epoch: 6| Step: 1
Training loss: 3.0781652767431553
Validation loss: 2.4983785600964636

Epoch: 6| Step: 2
Training loss: 2.86777982907881
Validation loss: 2.494207684087288

Epoch: 6| Step: 3
Training loss: 3.1965308816158844
Validation loss: 2.4965860231656984

Epoch: 6| Step: 4
Training loss: 2.7689671553967585
Validation loss: 2.5019555493343106

Epoch: 6| Step: 5
Training loss: 2.5209698495601565
Validation loss: 2.500255940779912

Epoch: 6| Step: 6
Training loss: 3.00534027356506
Validation loss: 2.4941842503059743

Epoch: 6| Step: 7
Training loss: 3.1507904877398363
Validation loss: 2.493856985884547

Epoch: 6| Step: 8
Training loss: 2.4452021272265334
Validation loss: 2.4962598623518977

Epoch: 6| Step: 9
Training loss: 3.0231163780936465
Validation loss: 2.4945152589100505

Epoch: 6| Step: 10
Training loss: 2.230103150449662
Validation loss: 2.5021519894557387

Epoch: 6| Step: 11
Training loss: 3.0279806537690446
Validation loss: 2.505647695263726

Epoch: 6| Step: 12
Training loss: 2.7469397770487998
Validation loss: 2.4986165689918454

Epoch: 6| Step: 13
Training loss: 2.200486354821112
Validation loss: 2.5003766514471364

Epoch: 286| Step: 0
Training loss: 3.3005009819992077
Validation loss: 2.519176771419466

Epoch: 6| Step: 1
Training loss: 2.8132111392068184
Validation loss: 2.5081090508041672

Epoch: 6| Step: 2
Training loss: 2.9547116492952332
Validation loss: 2.513514813858611

Epoch: 6| Step: 3
Training loss: 2.6418233104998046
Validation loss: 2.5122290524608073

Epoch: 6| Step: 4
Training loss: 2.622101227704155
Validation loss: 2.5145931595197255

Epoch: 6| Step: 5
Training loss: 2.8518701674775513
Validation loss: 2.5156943998838246

Epoch: 6| Step: 6
Training loss: 3.315333899573559
Validation loss: 2.5261286522760917

Epoch: 6| Step: 7
Training loss: 3.105091000020483
Validation loss: 2.5171890568496225

Epoch: 6| Step: 8
Training loss: 2.8710379458862523
Validation loss: 2.521479260899115

Epoch: 6| Step: 9
Training loss: 2.4993622920177567
Validation loss: 2.5240320132509484

Epoch: 6| Step: 10
Training loss: 3.2286647939866273
Validation loss: 2.5220963400536967

Epoch: 6| Step: 11
Training loss: 2.597902673491414
Validation loss: 2.5180278826201303

Epoch: 6| Step: 12
Training loss: 2.2996423360290676
Validation loss: 2.5124507212521543

Epoch: 6| Step: 13
Training loss: 2.5315386760604492
Validation loss: 2.5130078201853894

Epoch: 287| Step: 0
Training loss: 3.186832283243955
Validation loss: 2.515991549065893

Epoch: 6| Step: 1
Training loss: 2.624840867804909
Validation loss: 2.530751767606394

Epoch: 6| Step: 2
Training loss: 3.160501468319545
Validation loss: 2.553588350756325

Epoch: 6| Step: 3
Training loss: 3.259970117443713
Validation loss: 2.5552980500521816

Epoch: 6| Step: 4
Training loss: 3.251297911657983
Validation loss: 2.534271503996286

Epoch: 6| Step: 5
Training loss: 2.6308359033207327
Validation loss: 2.5484037357860347

Epoch: 6| Step: 6
Training loss: 2.9818208159986987
Validation loss: 2.5127756782898847

Epoch: 6| Step: 7
Training loss: 2.8178385612210812
Validation loss: 2.509012826379339

Epoch: 6| Step: 8
Training loss: 2.5658829850879914
Validation loss: 2.505105824155873

Epoch: 6| Step: 9
Training loss: 3.304977512485104
Validation loss: 2.487296269838664

Epoch: 6| Step: 10
Training loss: 2.500248133743058
Validation loss: 2.493924043347012

Epoch: 6| Step: 11
Training loss: 2.1163045583453
Validation loss: 2.4869401180167756

Epoch: 6| Step: 12
Training loss: 2.6186194303095434
Validation loss: 2.4868584534265326

Epoch: 6| Step: 13
Training loss: 2.6630928310840827
Validation loss: 2.4942941370996365

Epoch: 288| Step: 0
Training loss: 2.4476971683436415
Validation loss: 2.4899510198629504

Epoch: 6| Step: 1
Training loss: 2.884701655149314
Validation loss: 2.491848903360827

Epoch: 6| Step: 2
Training loss: 3.3541237174812752
Validation loss: 2.490778711524971

Epoch: 6| Step: 3
Training loss: 2.7265307580362674
Validation loss: 2.486081691380044

Epoch: 6| Step: 4
Training loss: 2.0185278755551805
Validation loss: 2.500878247461802

Epoch: 6| Step: 5
Training loss: 2.3820607484746956
Validation loss: 2.4898008489321333

Epoch: 6| Step: 6
Training loss: 2.5059857236268295
Validation loss: 2.5064792830034945

Epoch: 6| Step: 7
Training loss: 3.483975922178332
Validation loss: 2.5222388667648734

Epoch: 6| Step: 8
Training loss: 3.2456257066114373
Validation loss: 2.5171301192595545

Epoch: 6| Step: 9
Training loss: 2.620340389678788
Validation loss: 2.5448565451530913

Epoch: 6| Step: 10
Training loss: 3.2620178451003192
Validation loss: 2.57847264227794

Epoch: 6| Step: 11
Training loss: 2.845100501351924
Validation loss: 2.599069613217095

Epoch: 6| Step: 12
Training loss: 3.0026951445498953
Validation loss: 2.593129885106265

Epoch: 6| Step: 13
Training loss: 2.734130238068758
Validation loss: 2.5571486738842117

Epoch: 289| Step: 0
Training loss: 2.760867407124377
Validation loss: 2.550228025297506

Epoch: 6| Step: 1
Training loss: 3.3690483456565437
Validation loss: 2.5629760896186795

Epoch: 6| Step: 2
Training loss: 3.0350842952177044
Validation loss: 2.5566451924673825

Epoch: 6| Step: 3
Training loss: 2.5035341078513
Validation loss: 2.5183814611700925

Epoch: 6| Step: 4
Training loss: 2.5145494519352822
Validation loss: 2.5097821175383017

Epoch: 6| Step: 5
Training loss: 3.4452898020439964
Validation loss: 2.4930692749608747

Epoch: 6| Step: 6
Training loss: 2.5246339211561053
Validation loss: 2.485832945906511

Epoch: 6| Step: 7
Training loss: 2.967342966836984
Validation loss: 2.48342881411087

Epoch: 6| Step: 8
Training loss: 2.902092369560273
Validation loss: 2.494913999442436

Epoch: 6| Step: 9
Training loss: 2.5169806766609413
Validation loss: 2.4905511735077734

Epoch: 6| Step: 10
Training loss: 2.805226393758489
Validation loss: 2.492421748203962

Epoch: 6| Step: 11
Training loss: 3.2450059520978374
Validation loss: 2.4917881225452594

Epoch: 6| Step: 12
Training loss: 2.4856312772361293
Validation loss: 2.4836291153609285

Epoch: 6| Step: 13
Training loss: 2.5815461549979153
Validation loss: 2.4875494932413327

Epoch: 290| Step: 0
Training loss: 3.2177098639869364
Validation loss: 2.4872884437689655

Epoch: 6| Step: 1
Training loss: 2.6217183990451
Validation loss: 2.4958845479005762

Epoch: 6| Step: 2
Training loss: 2.334951339312665
Validation loss: 2.502451945316943

Epoch: 6| Step: 3
Training loss: 3.084407069571913
Validation loss: 2.510474867655191

Epoch: 6| Step: 4
Training loss: 2.6593074480704626
Validation loss: 2.5179885586595914

Epoch: 6| Step: 5
Training loss: 2.4391303845378745
Validation loss: 2.52746768775655

Epoch: 6| Step: 6
Training loss: 2.5582752291597406
Validation loss: 2.545285296812993

Epoch: 6| Step: 7
Training loss: 3.4272852937657934
Validation loss: 2.566500702366341

Epoch: 6| Step: 8
Training loss: 3.0748512170044693
Validation loss: 2.5498506652291417

Epoch: 6| Step: 9
Training loss: 2.9257744049277403
Validation loss: 2.5607929761785075

Epoch: 6| Step: 10
Training loss: 2.728609994117884
Validation loss: 2.5313149659977934

Epoch: 6| Step: 11
Training loss: 3.0745413585492205
Validation loss: 2.530216351863353

Epoch: 6| Step: 12
Training loss: 3.009142930697737
Validation loss: 2.50194913088873

Epoch: 6| Step: 13
Training loss: 2.235676419778828
Validation loss: 2.4958783249219665

Epoch: 291| Step: 0
Training loss: 2.6035196543245265
Validation loss: 2.495776381315237

Epoch: 6| Step: 1
Training loss: 2.654924308718042
Validation loss: 2.4960152237861464

Epoch: 6| Step: 2
Training loss: 2.4979713792405884
Validation loss: 2.5008502201512157

Epoch: 6| Step: 3
Training loss: 2.972853224214847
Validation loss: 2.5086727901027768

Epoch: 6| Step: 4
Training loss: 3.269177708259922
Validation loss: 2.5465373083311675

Epoch: 6| Step: 5
Training loss: 3.1180223002049225
Validation loss: 2.5527101799550724

Epoch: 6| Step: 6
Training loss: 2.488522600239563
Validation loss: 2.5714597894642526

Epoch: 6| Step: 7
Training loss: 2.147777220093392
Validation loss: 2.5872896978601947

Epoch: 6| Step: 8
Training loss: 3.0552167897324707
Validation loss: 2.6013517054472386

Epoch: 6| Step: 9
Training loss: 3.5136398475124544
Validation loss: 2.6051668932939296

Epoch: 6| Step: 10
Training loss: 2.9732516240181495
Validation loss: 2.5596333077443276

Epoch: 6| Step: 11
Training loss: 2.989058888299079
Validation loss: 2.5301133873630914

Epoch: 6| Step: 12
Training loss: 3.139596343609424
Validation loss: 2.5126614309737443

Epoch: 6| Step: 13
Training loss: 2.6088033266927733
Validation loss: 2.511843102518503

Epoch: 292| Step: 0
Training loss: 2.7323546002540633
Validation loss: 2.50377577042614

Epoch: 6| Step: 1
Training loss: 3.32568929310782
Validation loss: 2.5116559615653764

Epoch: 6| Step: 2
Training loss: 3.5124428143716386
Validation loss: 2.5184276257559697

Epoch: 6| Step: 3
Training loss: 2.5645661746787973
Validation loss: 2.5269684570060016

Epoch: 6| Step: 4
Training loss: 2.318945793666515
Validation loss: 2.514272924800239

Epoch: 6| Step: 5
Training loss: 3.0224484740756763
Validation loss: 2.5252776326422612

Epoch: 6| Step: 6
Training loss: 3.1114669740086716
Validation loss: 2.5200363325744535

Epoch: 6| Step: 7
Training loss: 3.1641242880733964
Validation loss: 2.510033563741571

Epoch: 6| Step: 8
Training loss: 2.2742529386560317
Validation loss: 2.4986301083682303

Epoch: 6| Step: 9
Training loss: 2.862749453673737
Validation loss: 2.4999478575693477

Epoch: 6| Step: 10
Training loss: 3.325457726429701
Validation loss: 2.5156714475167004

Epoch: 6| Step: 11
Training loss: 2.0734479086067754
Validation loss: 2.5169616808542927

Epoch: 6| Step: 12
Training loss: 2.74927433149604
Validation loss: 2.5619758462058937

Epoch: 6| Step: 13
Training loss: 2.6750783177970052
Validation loss: 2.55976579942364

Epoch: 293| Step: 0
Training loss: 2.4977584326361857
Validation loss: 2.5460888602876106

Epoch: 6| Step: 1
Training loss: 2.804155304551782
Validation loss: 2.5208471228855376

Epoch: 6| Step: 2
Training loss: 3.037434669074626
Validation loss: 2.518746651320757

Epoch: 6| Step: 3
Training loss: 2.466146037428356
Validation loss: 2.499814849068043

Epoch: 6| Step: 4
Training loss: 2.336210815362329
Validation loss: 2.50164612442785

Epoch: 6| Step: 5
Training loss: 3.3967443699008504
Validation loss: 2.4857456509784623

Epoch: 6| Step: 6
Training loss: 2.971138886463204
Validation loss: 2.484705340572469

Epoch: 6| Step: 7
Training loss: 2.8332449581350803
Validation loss: 2.487167915269079

Epoch: 6| Step: 8
Training loss: 3.084836816660616
Validation loss: 2.480166548914776

Epoch: 6| Step: 9
Training loss: 3.2000801314811462
Validation loss: 2.4922024558006215

Epoch: 6| Step: 10
Training loss: 2.2531482076309444
Validation loss: 2.4936213488921024

Epoch: 6| Step: 11
Training loss: 3.1868966223399737
Validation loss: 2.4923713650460675

Epoch: 6| Step: 12
Training loss: 2.585634888059996
Validation loss: 2.493444282666218

Epoch: 6| Step: 13
Training loss: 3.0749938840727733
Validation loss: 2.503723698950021

Epoch: 294| Step: 0
Training loss: 2.559042109451178
Validation loss: 2.5319649595495273

Epoch: 6| Step: 1
Training loss: 3.4842397894519817
Validation loss: 2.543132678595162

Epoch: 6| Step: 2
Training loss: 2.498249776442621
Validation loss: 2.5621363213934427

Epoch: 6| Step: 3
Training loss: 2.731536612759511
Validation loss: 2.5513568777613216

Epoch: 6| Step: 4
Training loss: 3.0373363937460756
Validation loss: 2.554865952006304

Epoch: 6| Step: 5
Training loss: 3.2303245355411945
Validation loss: 2.5497847598733077

Epoch: 6| Step: 6
Training loss: 2.656747030991496
Validation loss: 2.5230630078434446

Epoch: 6| Step: 7
Training loss: 2.5698376248789354
Validation loss: 2.5222005054581333

Epoch: 6| Step: 8
Training loss: 2.778199827132667
Validation loss: 2.496173791691523

Epoch: 6| Step: 9
Training loss: 2.940598335104679
Validation loss: 2.496904749974586

Epoch: 6| Step: 10
Training loss: 2.7910040073673534
Validation loss: 2.492892241508649

Epoch: 6| Step: 11
Training loss: 2.663140996147697
Validation loss: 2.487134932180107

Epoch: 6| Step: 12
Training loss: 2.943714143247153
Validation loss: 2.488156083621692

Epoch: 6| Step: 13
Training loss: 2.6886906315178245
Validation loss: 2.5014076330855115

Epoch: 295| Step: 0
Training loss: 2.8390813378657502
Validation loss: 2.503223869297926

Epoch: 6| Step: 1
Training loss: 2.8936695458451642
Validation loss: 2.5212631598144553

Epoch: 6| Step: 2
Training loss: 2.2136726849246355
Validation loss: 2.5281564019981997

Epoch: 6| Step: 3
Training loss: 3.065255929738155
Validation loss: 2.5840702114092076

Epoch: 6| Step: 4
Training loss: 3.0674435944411633
Validation loss: 2.6765365967993913

Epoch: 6| Step: 5
Training loss: 2.716759314644206
Validation loss: 2.7879617858971106

Epoch: 6| Step: 6
Training loss: 3.428323600531452
Validation loss: 2.8575059607831226

Epoch: 6| Step: 7
Training loss: 3.2952254810664074
Validation loss: 2.889769687731543

Epoch: 6| Step: 8
Training loss: 2.865675691345542
Validation loss: 2.796362876695551

Epoch: 6| Step: 9
Training loss: 2.605542778095871
Validation loss: 2.6084450414328746

Epoch: 6| Step: 10
Training loss: 3.2314566747212603
Validation loss: 2.511553148697752

Epoch: 6| Step: 11
Training loss: 1.759672410128316
Validation loss: 2.4880862401804724

Epoch: 6| Step: 12
Training loss: 3.4986183981831966
Validation loss: 2.4971126495202216

Epoch: 6| Step: 13
Training loss: 2.827871068861608
Validation loss: 2.510255739935058

Epoch: 296| Step: 0
Training loss: 3.475127123147251
Validation loss: 2.540923517464677

Epoch: 6| Step: 1
Training loss: 2.7035619129042963
Validation loss: 2.5457380454567473

Epoch: 6| Step: 2
Training loss: 3.0793799925651983
Validation loss: 2.546597767974723

Epoch: 6| Step: 3
Training loss: 2.7799635065551347
Validation loss: 2.5365037771045627

Epoch: 6| Step: 4
Training loss: 2.600714284642632
Validation loss: 2.5244073822763937

Epoch: 6| Step: 5
Training loss: 3.1567228359661783
Validation loss: 2.511243255628555

Epoch: 6| Step: 6
Training loss: 2.847288508276819
Validation loss: 2.5014726331540214

Epoch: 6| Step: 7
Training loss: 2.6951618539478903
Validation loss: 2.4979425249577285

Epoch: 6| Step: 8
Training loss: 3.3879828640302905
Validation loss: 2.500358652209575

Epoch: 6| Step: 9
Training loss: 3.1064034069104487
Validation loss: 2.4959416859003434

Epoch: 6| Step: 10
Training loss: 2.614390686557154
Validation loss: 2.4922247540650826

Epoch: 6| Step: 11
Training loss: 2.825519858270761
Validation loss: 2.4926795665285613

Epoch: 6| Step: 12
Training loss: 2.4188650808631196
Validation loss: 2.487852772913651

Epoch: 6| Step: 13
Training loss: 2.7543193534352564
Validation loss: 2.4955600340795674

Epoch: 297| Step: 0
Training loss: 2.560769962511924
Validation loss: 2.5080743028863743

Epoch: 6| Step: 1
Training loss: 3.0984972356981224
Validation loss: 2.5231074458283373

Epoch: 6| Step: 2
Training loss: 2.2089059075433988
Validation loss: 2.540331122648843

Epoch: 6| Step: 3
Training loss: 2.9970820859576506
Validation loss: 2.573210663372863

Epoch: 6| Step: 4
Training loss: 3.429035376765936
Validation loss: 2.627006592004204

Epoch: 6| Step: 5
Training loss: 2.737610738944344
Validation loss: 2.620343977328626

Epoch: 6| Step: 6
Training loss: 2.763095021787392
Validation loss: 2.5980424940325686

Epoch: 6| Step: 7
Training loss: 2.888530900570358
Validation loss: 2.5595874115914086

Epoch: 6| Step: 8
Training loss: 2.6711251617664376
Validation loss: 2.545251945807126

Epoch: 6| Step: 9
Training loss: 3.274933466344679
Validation loss: 2.5096542582033785

Epoch: 6| Step: 10
Training loss: 2.5117352664576518
Validation loss: 2.5033558727974707

Epoch: 6| Step: 11
Training loss: 2.964682110990329
Validation loss: 2.501835567583563

Epoch: 6| Step: 12
Training loss: 3.006383779487481
Validation loss: 2.4890849192540703

Epoch: 6| Step: 13
Training loss: 2.5850963319282942
Validation loss: 2.495990890799006

Epoch: 298| Step: 0
Training loss: 2.5205564320548057
Validation loss: 2.4833061657240085

Epoch: 6| Step: 1
Training loss: 3.1573692829924993
Validation loss: 2.4866084453834985

Epoch: 6| Step: 2
Training loss: 3.0348831898364965
Validation loss: 2.4878933573742668

Epoch: 6| Step: 3
Training loss: 2.6400395935152883
Validation loss: 2.4881519663894482

Epoch: 6| Step: 4
Training loss: 3.1490641460166446
Validation loss: 2.4819038852228976

Epoch: 6| Step: 5
Training loss: 3.0275160611244014
Validation loss: 2.4967821926720033

Epoch: 6| Step: 6
Training loss: 3.098493234476506
Validation loss: 2.4885776579103585

Epoch: 6| Step: 7
Training loss: 2.49599173610493
Validation loss: 2.4899027540498695

Epoch: 6| Step: 8
Training loss: 2.5266913348715723
Validation loss: 2.504744301121706

Epoch: 6| Step: 9
Training loss: 2.8435128920081585
Validation loss: 2.5236648207769465

Epoch: 6| Step: 10
Training loss: 2.763137301987324
Validation loss: 2.541086853627627

Epoch: 6| Step: 11
Training loss: 2.7737783303174255
Validation loss: 2.5355195710835177

Epoch: 6| Step: 12
Training loss: 2.6407341567733145
Validation loss: 2.5279994578765272

Epoch: 6| Step: 13
Training loss: 3.1225585555732014
Validation loss: 2.549604209684105

Epoch: 299| Step: 0
Training loss: 2.1562883677731732
Validation loss: 2.6190791687239066

Epoch: 6| Step: 1
Training loss: 3.003764016463604
Validation loss: 2.6965496289734445

Epoch: 6| Step: 2
Training loss: 3.115172229493769
Validation loss: 2.6802360150029485

Epoch: 6| Step: 3
Training loss: 2.1893067664061245
Validation loss: 2.625479825724988

Epoch: 6| Step: 4
Training loss: 3.4429879510221624
Validation loss: 2.6034302770848807

Epoch: 6| Step: 5
Training loss: 2.796907392772438
Validation loss: 2.5940279583747925

Epoch: 6| Step: 6
Training loss: 2.7850987239851572
Validation loss: 2.546544435872649

Epoch: 6| Step: 7
Training loss: 2.775173707628664
Validation loss: 2.5259245466138793

Epoch: 6| Step: 8
Training loss: 3.2206986833845965
Validation loss: 2.486005349643336

Epoch: 6| Step: 9
Training loss: 2.7721173650327935
Validation loss: 2.4884160272973155

Epoch: 6| Step: 10
Training loss: 2.9646644186233404
Validation loss: 2.4836620954615385

Epoch: 6| Step: 11
Training loss: 2.847400711378226
Validation loss: 2.4816501528994612

Epoch: 6| Step: 12
Training loss: 3.0385879891445366
Validation loss: 2.494088756321213

Epoch: 6| Step: 13
Training loss: 2.6030102616355886
Validation loss: 2.4907821687822858

Epoch: 300| Step: 0
Training loss: 2.961818916158491
Validation loss: 2.5000216565168314

Epoch: 6| Step: 1
Training loss: 2.5741434505951575
Validation loss: 2.5040578949341

Epoch: 6| Step: 2
Training loss: 3.59844253016264
Validation loss: 2.5180600639949224

Epoch: 6| Step: 3
Training loss: 2.9859410515988167
Validation loss: 2.5010507877421664

Epoch: 6| Step: 4
Training loss: 2.851472032758006
Validation loss: 2.5056811641558383

Epoch: 6| Step: 5
Training loss: 3.0451335919018883
Validation loss: 2.4919354294620506

Epoch: 6| Step: 6
Training loss: 3.556324474982887
Validation loss: 2.497267706655118

Epoch: 6| Step: 7
Training loss: 2.4305407629622553
Validation loss: 2.493144402968044

Epoch: 6| Step: 8
Training loss: 2.866645948941381
Validation loss: 2.505982854090889

Epoch: 6| Step: 9
Training loss: 2.885012895631315
Validation loss: 2.5129151456553522

Epoch: 6| Step: 10
Training loss: 2.5184095621174682
Validation loss: 2.518904975983056

Epoch: 6| Step: 11
Training loss: 2.720704001312224
Validation loss: 2.5446168345589997

Epoch: 6| Step: 12
Training loss: 2.081446008931806
Validation loss: 2.5628619870018037

Epoch: 6| Step: 13
Training loss: 2.7959522451325536
Validation loss: 2.5873891802254385

Epoch: 301| Step: 0
Training loss: 2.5579008372624266
Validation loss: 2.594832993737883

Epoch: 6| Step: 1
Training loss: 3.017443805161841
Validation loss: 2.5672677958111527

Epoch: 6| Step: 2
Training loss: 2.9126948606605465
Validation loss: 2.5434336203283587

Epoch: 6| Step: 3
Training loss: 3.1135437590276265
Validation loss: 2.5512996278072833

Epoch: 6| Step: 4
Training loss: 2.58025646531868
Validation loss: 2.5359843673885445

Epoch: 6| Step: 5
Training loss: 2.702783463792177
Validation loss: 2.5297482647954217

Epoch: 6| Step: 6
Training loss: 2.9526764059703567
Validation loss: 2.530736876525927

Epoch: 6| Step: 7
Training loss: 2.3370113902502014
Validation loss: 2.517444328504525

Epoch: 6| Step: 8
Training loss: 3.16253263434056
Validation loss: 2.5127168657205137

Epoch: 6| Step: 9
Training loss: 2.9449569528020985
Validation loss: 2.4984053114609037

Epoch: 6| Step: 10
Training loss: 3.150455102893339
Validation loss: 2.4965394690736646

Epoch: 6| Step: 11
Training loss: 2.8217010038854875
Validation loss: 2.4939405142088122

Epoch: 6| Step: 12
Training loss: 2.907188346081114
Validation loss: 2.508785923332552

Epoch: 6| Step: 13
Training loss: 1.9846784104403519
Validation loss: 2.504101396607231

Epoch: 302| Step: 0
Training loss: 2.8847456242430383
Validation loss: 2.506280099072608

Epoch: 6| Step: 1
Training loss: 2.1333791797400528
Validation loss: 2.5316568602409744

Epoch: 6| Step: 2
Training loss: 3.242434866787064
Validation loss: 2.531252202830995

Epoch: 6| Step: 3
Training loss: 2.2232577242522438
Validation loss: 2.5500777607304674

Epoch: 6| Step: 4
Training loss: 2.3441835129674176
Validation loss: 2.535383401800252

Epoch: 6| Step: 5
Training loss: 2.7686185852965752
Validation loss: 2.572533569537852

Epoch: 6| Step: 6
Training loss: 2.4944182071943777
Validation loss: 2.557913272072873

Epoch: 6| Step: 7
Training loss: 3.0883850435339215
Validation loss: 2.586752393081323

Epoch: 6| Step: 8
Training loss: 2.941854941707166
Validation loss: 2.5853020241907743

Epoch: 6| Step: 9
Training loss: 2.896047424159936
Validation loss: 2.580847252154651

Epoch: 6| Step: 10
Training loss: 3.5096115562490438
Validation loss: 2.539601214158661

Epoch: 6| Step: 11
Training loss: 2.9461856428132536
Validation loss: 2.5059354658638924

Epoch: 6| Step: 12
Training loss: 3.269993538573061
Validation loss: 2.47988966956086

Epoch: 6| Step: 13
Training loss: 2.8140502048289493
Validation loss: 2.486261773147837

Epoch: 303| Step: 0
Training loss: 2.642056590604013
Validation loss: 2.484218924525205

Epoch: 6| Step: 1
Training loss: 3.077736767137191
Validation loss: 2.4861358843303347

Epoch: 6| Step: 2
Training loss: 3.0743172422576173
Validation loss: 2.4875708840503967

Epoch: 6| Step: 3
Training loss: 2.520911685787319
Validation loss: 2.486340787846128

Epoch: 6| Step: 4
Training loss: 2.9729481778059843
Validation loss: 2.4869660579724844

Epoch: 6| Step: 5
Training loss: 2.520207750445926
Validation loss: 2.486320008722025

Epoch: 6| Step: 6
Training loss: 2.837554218597672
Validation loss: 2.4915809938728777

Epoch: 6| Step: 7
Training loss: 3.3316927846394035
Validation loss: 2.4865042277367113

Epoch: 6| Step: 8
Training loss: 2.059223230815701
Validation loss: 2.478445263706254

Epoch: 6| Step: 9
Training loss: 2.8377851032085193
Validation loss: 2.4916652616128623

Epoch: 6| Step: 10
Training loss: 2.7720931112496463
Validation loss: 2.5069254401209506

Epoch: 6| Step: 11
Training loss: 3.1452916333661873
Validation loss: 2.503495198291451

Epoch: 6| Step: 12
Training loss: 2.658529313455872
Validation loss: 2.5200087451994673

Epoch: 6| Step: 13
Training loss: 3.388456292674185
Validation loss: 2.5284293585527893

Epoch: 304| Step: 0
Training loss: 2.6600661745659764
Validation loss: 2.5317536438789827

Epoch: 6| Step: 1
Training loss: 2.5902632291610814
Validation loss: 2.540483538939998

Epoch: 6| Step: 2
Training loss: 2.9228885952903707
Validation loss: 2.5850824074278163

Epoch: 6| Step: 3
Training loss: 3.0658238337719474
Validation loss: 2.6206441641353604

Epoch: 6| Step: 4
Training loss: 3.4370466453532433
Validation loss: 2.6189926492411635

Epoch: 6| Step: 5
Training loss: 2.8033559714668397
Validation loss: 2.607438593432115

Epoch: 6| Step: 6
Training loss: 3.0326838297525636
Validation loss: 2.626669166015732

Epoch: 6| Step: 7
Training loss: 3.0156034953086865
Validation loss: 2.6502784552136895

Epoch: 6| Step: 8
Training loss: 2.295634966505908
Validation loss: 2.607026347216823

Epoch: 6| Step: 9
Training loss: 3.055249720979276
Validation loss: 2.587871952558359

Epoch: 6| Step: 10
Training loss: 3.240036584153085
Validation loss: 2.539723102213124

Epoch: 6| Step: 11
Training loss: 2.2469057423235346
Validation loss: 2.5042648003681784

Epoch: 6| Step: 12
Training loss: 2.4002128268290517
Validation loss: 2.4999577498198553

Epoch: 6| Step: 13
Training loss: 2.946687493775701
Validation loss: 2.4834232252387674

Epoch: 305| Step: 0
Training loss: 2.679212700511118
Validation loss: 2.486346288704147

Epoch: 6| Step: 1
Training loss: 2.4967932161345967
Validation loss: 2.489115851642196

Epoch: 6| Step: 2
Training loss: 2.7543068019594457
Validation loss: 2.4867030214577723

Epoch: 6| Step: 3
Training loss: 2.838652349058172
Validation loss: 2.484369049508859

Epoch: 6| Step: 4
Training loss: 2.8031168075322728
Validation loss: 2.487468144445803

Epoch: 6| Step: 5
Training loss: 3.5153455835142586
Validation loss: 2.5091382805735556

Epoch: 6| Step: 6
Training loss: 3.1651812800700005
Validation loss: 2.503254626972912

Epoch: 6| Step: 7
Training loss: 2.5756465211342676
Validation loss: 2.506928071329597

Epoch: 6| Step: 8
Training loss: 2.7712333409587697
Validation loss: 2.534610077343808

Epoch: 6| Step: 9
Training loss: 2.828707471688825
Validation loss: 2.536332636824094

Epoch: 6| Step: 10
Training loss: 3.2367372593775166
Validation loss: 2.5258409909881294

Epoch: 6| Step: 11
Training loss: 2.3936947330638585
Validation loss: 2.5248596182841534

Epoch: 6| Step: 12
Training loss: 2.7047223790221073
Validation loss: 2.535866358606949

Epoch: 6| Step: 13
Training loss: 2.882497548005516
Validation loss: 2.550766404490993

Epoch: 306| Step: 0
Training loss: 3.300506905435089
Validation loss: 2.5659634294632645

Epoch: 6| Step: 1
Training loss: 2.227075992735091
Validation loss: 2.547445905022667

Epoch: 6| Step: 2
Training loss: 2.720349071767376
Validation loss: 2.528902972836099

Epoch: 6| Step: 3
Training loss: 2.2497073089113266
Validation loss: 2.5224065645317095

Epoch: 6| Step: 4
Training loss: 2.937888911048563
Validation loss: 2.5117547906852935

Epoch: 6| Step: 5
Training loss: 2.685483841589806
Validation loss: 2.502025705436716

Epoch: 6| Step: 6
Training loss: 3.345431466550719
Validation loss: 2.484061641050757

Epoch: 6| Step: 7
Training loss: 2.9510458433959
Validation loss: 2.4927774387440147

Epoch: 6| Step: 8
Training loss: 3.3647568286928777
Validation loss: 2.4900750170554504

Epoch: 6| Step: 9
Training loss: 2.8734139753149313
Validation loss: 2.4974344830899815

Epoch: 6| Step: 10
Training loss: 2.804157345110594
Validation loss: 2.4986043633802013

Epoch: 6| Step: 11
Training loss: 2.5204667594608097
Validation loss: 2.5114147847149004

Epoch: 6| Step: 12
Training loss: 2.9572863449867546
Validation loss: 2.5289466330660915

Epoch: 6| Step: 13
Training loss: 2.3303025066483225
Validation loss: 2.541020596873674

Epoch: 307| Step: 0
Training loss: 2.6047373235430484
Validation loss: 2.5731819713192623

Epoch: 6| Step: 1
Training loss: 2.5358716428505748
Validation loss: 2.568424073097707

Epoch: 6| Step: 2
Training loss: 2.61921581413561
Validation loss: 2.580380882906741

Epoch: 6| Step: 3
Training loss: 2.6420819478577036
Validation loss: 2.600866838472609

Epoch: 6| Step: 4
Training loss: 2.8328659195657857
Validation loss: 2.5897423702040276

Epoch: 6| Step: 5
Training loss: 2.5516212096879687
Validation loss: 2.5791998458838847

Epoch: 6| Step: 6
Training loss: 2.9547713600172227
Validation loss: 2.5529205813983307

Epoch: 6| Step: 7
Training loss: 2.6670896274194607
Validation loss: 2.5140191513559538

Epoch: 6| Step: 8
Training loss: 2.939919307405837
Validation loss: 2.495149920202119

Epoch: 6| Step: 9
Training loss: 2.7325059879164075
Validation loss: 2.477329514114228

Epoch: 6| Step: 10
Training loss: 3.4874668516272282
Validation loss: 2.493910604860618

Epoch: 6| Step: 11
Training loss: 2.9775629239676067
Validation loss: 2.498909201610908

Epoch: 6| Step: 12
Training loss: 3.1505204875784205
Validation loss: 2.4994492959983776

Epoch: 6| Step: 13
Training loss: 3.197332587732266
Validation loss: 2.503793462501668

Epoch: 308| Step: 0
Training loss: 2.898431412929508
Validation loss: 2.5081027237445266

Epoch: 6| Step: 1
Training loss: 2.800196204804297
Validation loss: 2.489262650878709

Epoch: 6| Step: 2
Training loss: 2.585736500284081
Validation loss: 2.4808354795318106

Epoch: 6| Step: 3
Training loss: 2.589318407726125
Validation loss: 2.4752162209955593

Epoch: 6| Step: 4
Training loss: 3.1232062723159344
Validation loss: 2.4848055769213393

Epoch: 6| Step: 5
Training loss: 3.0057024800163545
Validation loss: 2.4794332823313163

Epoch: 6| Step: 6
Training loss: 2.928816927944133
Validation loss: 2.48375867980824

Epoch: 6| Step: 7
Training loss: 2.7216185421571613
Validation loss: 2.4888650876943195

Epoch: 6| Step: 8
Training loss: 2.563752031330139
Validation loss: 2.4911853772265564

Epoch: 6| Step: 9
Training loss: 2.217975750005465
Validation loss: 2.501070686481497

Epoch: 6| Step: 10
Training loss: 2.9429653539351923
Validation loss: 2.5146965341959246

Epoch: 6| Step: 11
Training loss: 3.110882570939993
Validation loss: 2.5297339495014515

Epoch: 6| Step: 12
Training loss: 2.9928315667179075
Validation loss: 2.537835422090321

Epoch: 6| Step: 13
Training loss: 3.3941265255616204
Validation loss: 2.539054153971369

Epoch: 309| Step: 0
Training loss: 2.7699943553440134
Validation loss: 2.5341473071861222

Epoch: 6| Step: 1
Training loss: 3.1215369300203637
Validation loss: 2.532354114307962

Epoch: 6| Step: 2
Training loss: 2.918401438384789
Validation loss: 2.519499182045913

Epoch: 6| Step: 3
Training loss: 2.8361733919089236
Validation loss: 2.5166606561004548

Epoch: 6| Step: 4
Training loss: 2.937129869882943
Validation loss: 2.5179965021002477

Epoch: 6| Step: 5
Training loss: 2.776932440452794
Validation loss: 2.514349057752621

Epoch: 6| Step: 6
Training loss: 3.087916567727834
Validation loss: 2.511691052895836

Epoch: 6| Step: 7
Training loss: 2.3966343964096217
Validation loss: 2.5221641225867537

Epoch: 6| Step: 8
Training loss: 2.7620662918366907
Validation loss: 2.50356766643856

Epoch: 6| Step: 9
Training loss: 3.045817186666778
Validation loss: 2.518622008570743

Epoch: 6| Step: 10
Training loss: 2.622366174241622
Validation loss: 2.493735131035311

Epoch: 6| Step: 11
Training loss: 2.9406046592017008
Validation loss: 2.4992469073737715

Epoch: 6| Step: 12
Training loss: 2.379054072756105
Validation loss: 2.4996972218587645

Epoch: 6| Step: 13
Training loss: 2.6820800599019017
Validation loss: 2.512658581305155

Epoch: 310| Step: 0
Training loss: 3.201163533393647
Validation loss: 2.5173483664916447

Epoch: 6| Step: 1
Training loss: 2.4383013459526115
Validation loss: 2.512403627466727

Epoch: 6| Step: 2
Training loss: 2.075130054120973
Validation loss: 2.5263339693168545

Epoch: 6| Step: 3
Training loss: 2.8027834578944772
Validation loss: 2.551435174727839

Epoch: 6| Step: 4
Training loss: 3.39866283152042
Validation loss: 2.542949631769088

Epoch: 6| Step: 5
Training loss: 3.0675779011603765
Validation loss: 2.5077437294689

Epoch: 6| Step: 6
Training loss: 2.0306392044786956
Validation loss: 2.478805494657746

Epoch: 6| Step: 7
Training loss: 2.4257378075191136
Validation loss: 2.463761647866904

Epoch: 6| Step: 8
Training loss: 2.9476024518637853
Validation loss: 2.4683209305089004

Epoch: 6| Step: 9
Training loss: 2.8459678636721617
Validation loss: 2.4662675174025135

Epoch: 6| Step: 10
Training loss: 2.9345215652149204
Validation loss: 2.4752673210146185

Epoch: 6| Step: 11
Training loss: 3.1775449990628513
Validation loss: 2.476858977693453

Epoch: 6| Step: 12
Training loss: 2.790031628036341
Validation loss: 2.4732734876467877

Epoch: 6| Step: 13
Training loss: 3.5946537374194136
Validation loss: 2.4827812398592894

Epoch: 311| Step: 0
Training loss: 2.8640352221832486
Validation loss: 2.474559811248725

Epoch: 6| Step: 1
Training loss: 3.554754570967517
Validation loss: 2.4771017911597575

Epoch: 6| Step: 2
Training loss: 2.3773880045893296
Validation loss: 2.4718910786454384

Epoch: 6| Step: 3
Training loss: 3.1320212261508655
Validation loss: 2.4889433667197824

Epoch: 6| Step: 4
Training loss: 2.910843367393215
Validation loss: 2.495151793241926

Epoch: 6| Step: 5
Training loss: 2.826028288994601
Validation loss: 2.5004335437704484

Epoch: 6| Step: 6
Training loss: 2.4790616587564456
Validation loss: 2.521511641218074

Epoch: 6| Step: 7
Training loss: 2.5895570622219193
Validation loss: 2.534637829457356

Epoch: 6| Step: 8
Training loss: 2.3414574155158827
Validation loss: 2.5457394069641572

Epoch: 6| Step: 9
Training loss: 3.0424045730207383
Validation loss: 2.526654089794286

Epoch: 6| Step: 10
Training loss: 2.875312788160749
Validation loss: 2.536471321345766

Epoch: 6| Step: 11
Training loss: 2.2581170216621875
Validation loss: 2.537042767813217

Epoch: 6| Step: 12
Training loss: 2.850157174578238
Validation loss: 2.543750400668655

Epoch: 6| Step: 13
Training loss: 3.6805393018703527
Validation loss: 2.55719957026497

Epoch: 312| Step: 0
Training loss: 2.3330953908125176
Validation loss: 2.5377235253125057

Epoch: 6| Step: 1
Training loss: 3.6667046689462817
Validation loss: 2.5282389847240463

Epoch: 6| Step: 2
Training loss: 3.0652568631096515
Validation loss: 2.490240138009223

Epoch: 6| Step: 3
Training loss: 3.130745298481242
Validation loss: 2.4823210022638835

Epoch: 6| Step: 4
Training loss: 2.651355317652988
Validation loss: 2.485161055678585

Epoch: 6| Step: 5
Training loss: 2.683203700786534
Validation loss: 2.4718323211119686

Epoch: 6| Step: 6
Training loss: 2.7611727464816624
Validation loss: 2.4703085400778315

Epoch: 6| Step: 7
Training loss: 2.720386670200855
Validation loss: 2.4720123779284857

Epoch: 6| Step: 8
Training loss: 2.7235309175543634
Validation loss: 2.4743875010612575

Epoch: 6| Step: 9
Training loss: 3.1351121182143413
Validation loss: 2.479856654796805

Epoch: 6| Step: 10
Training loss: 2.7952562474688563
Validation loss: 2.4756722216961227

Epoch: 6| Step: 11
Training loss: 2.904982259568165
Validation loss: 2.4993452352966363

Epoch: 6| Step: 12
Training loss: 2.6813082673115054
Validation loss: 2.522557712162512

Epoch: 6| Step: 13
Training loss: 1.8497148139330293
Validation loss: 2.5295746106354438

Epoch: 313| Step: 0
Training loss: 2.7399009452791185
Validation loss: 2.5587653340451686

Epoch: 6| Step: 1
Training loss: 2.2561788489622536
Validation loss: 2.576055420591607

Epoch: 6| Step: 2
Training loss: 2.5923742299486405
Validation loss: 2.575768405435733

Epoch: 6| Step: 3
Training loss: 3.0429794056697257
Validation loss: 2.569791594732593

Epoch: 6| Step: 4
Training loss: 2.0195978327092226
Validation loss: 2.5518586880874117

Epoch: 6| Step: 5
Training loss: 3.4137095393294214
Validation loss: 2.5426990899168715

Epoch: 6| Step: 6
Training loss: 2.9577993708025434
Validation loss: 2.5227542573089083

Epoch: 6| Step: 7
Training loss: 2.9887951776718835
Validation loss: 2.518287237998344

Epoch: 6| Step: 8
Training loss: 2.6528530165658335
Validation loss: 2.5119842841605995

Epoch: 6| Step: 9
Training loss: 2.951276574085873
Validation loss: 2.501773295553242

Epoch: 6| Step: 10
Training loss: 2.926730604175749
Validation loss: 2.5074648946688636

Epoch: 6| Step: 11
Training loss: 3.096027191239845
Validation loss: 2.4898406036678424

Epoch: 6| Step: 12
Training loss: 2.687295772865692
Validation loss: 2.474773603127725

Epoch: 6| Step: 13
Training loss: 3.2109490832934315
Validation loss: 2.4774880952235425

Epoch: 314| Step: 0
Training loss: 3.0922949866242964
Validation loss: 2.4651756938723803

Epoch: 6| Step: 1
Training loss: 3.239577085891702
Validation loss: 2.4694246009318435

Epoch: 6| Step: 2
Training loss: 2.8820339898799325
Validation loss: 2.465773539359967

Epoch: 6| Step: 3
Training loss: 2.986311199571886
Validation loss: 2.479554872287047

Epoch: 6| Step: 4
Training loss: 2.485156913884352
Validation loss: 2.4885195972461562

Epoch: 6| Step: 5
Training loss: 2.7214124950138627
Validation loss: 2.508290271868408

Epoch: 6| Step: 6
Training loss: 2.5813997682437275
Validation loss: 2.5143213865643905

Epoch: 6| Step: 7
Training loss: 3.126959529681917
Validation loss: 2.5322585755786546

Epoch: 6| Step: 8
Training loss: 3.1690911163973055
Validation loss: 2.55101209755256

Epoch: 6| Step: 9
Training loss: 2.2987333292768906
Validation loss: 2.5599965468041783

Epoch: 6| Step: 10
Training loss: 2.482306236857177
Validation loss: 2.533931830181713

Epoch: 6| Step: 11
Training loss: 3.3689601684009225
Validation loss: 2.55745498225627

Epoch: 6| Step: 12
Training loss: 2.124929090326549
Validation loss: 2.599484694280511

Epoch: 6| Step: 13
Training loss: 2.2479237407564767
Validation loss: 2.5802674103567886

Epoch: 315| Step: 0
Training loss: 3.053862711590466
Validation loss: 2.5724436897435345

Epoch: 6| Step: 1
Training loss: 2.9610494225115787
Validation loss: 2.546862442848287

Epoch: 6| Step: 2
Training loss: 3.0316416693844035
Validation loss: 2.49945070938804

Epoch: 6| Step: 3
Training loss: 2.439821849166485
Validation loss: 2.5007427455581936

Epoch: 6| Step: 4
Training loss: 2.4768618814879972
Validation loss: 2.4829170302054924

Epoch: 6| Step: 5
Training loss: 2.8128894960061874
Validation loss: 2.485960476342707

Epoch: 6| Step: 6
Training loss: 2.853283673623772
Validation loss: 2.4778211045550957

Epoch: 6| Step: 7
Training loss: 2.242594186937614
Validation loss: 2.4878169115066786

Epoch: 6| Step: 8
Training loss: 2.71246664140994
Validation loss: 2.4900183050335536

Epoch: 6| Step: 9
Training loss: 2.7221051264467158
Validation loss: 2.497118848376708

Epoch: 6| Step: 10
Training loss: 3.0201412241169847
Validation loss: 2.503315339320414

Epoch: 6| Step: 11
Training loss: 2.7393224807150456
Validation loss: 2.53143522961488

Epoch: 6| Step: 12
Training loss: 3.143110970985233
Validation loss: 2.5385160942694416

Epoch: 6| Step: 13
Training loss: 3.131939469075298
Validation loss: 2.6047550158635517

Epoch: 316| Step: 0
Training loss: 2.2035009185186643
Validation loss: 2.624376569667446

Epoch: 6| Step: 1
Training loss: 2.6838487173615255
Validation loss: 2.658827982350929

Epoch: 6| Step: 2
Training loss: 2.9928298141267042
Validation loss: 2.671281252666535

Epoch: 6| Step: 3
Training loss: 2.821148016847944
Validation loss: 2.646900017856885

Epoch: 6| Step: 4
Training loss: 3.1503794244802443
Validation loss: 2.5929042832507037

Epoch: 6| Step: 5
Training loss: 3.0307185700191925
Validation loss: 2.54402937292108

Epoch: 6| Step: 6
Training loss: 2.9983606627828374
Validation loss: 2.5077113860581592

Epoch: 6| Step: 7
Training loss: 3.0748090359077267
Validation loss: 2.4938944442472684

Epoch: 6| Step: 8
Training loss: 2.723010791259856
Validation loss: 2.489593560071705

Epoch: 6| Step: 9
Training loss: 2.7937785648532696
Validation loss: 2.4822801562889922

Epoch: 6| Step: 10
Training loss: 2.3383197183500397
Validation loss: 2.48682909083567

Epoch: 6| Step: 11
Training loss: 3.0509080066796783
Validation loss: 2.4840261521809133

Epoch: 6| Step: 12
Training loss: 2.651344886531442
Validation loss: 2.4787786636340523

Epoch: 6| Step: 13
Training loss: 3.3332577378919854
Validation loss: 2.4769337967990857

Epoch: 317| Step: 0
Training loss: 2.8883588826377014
Validation loss: 2.49185596613578

Epoch: 6| Step: 1
Training loss: 2.689002925339225
Validation loss: 2.482982818908034

Epoch: 6| Step: 2
Training loss: 2.8713965016291065
Validation loss: 2.4878013563923957

Epoch: 6| Step: 3
Training loss: 2.667380316926507
Validation loss: 2.4774779947724843

Epoch: 6| Step: 4
Training loss: 2.611447362238923
Validation loss: 2.477601602173642

Epoch: 6| Step: 5
Training loss: 2.967971217753646
Validation loss: 2.485194955205452

Epoch: 6| Step: 6
Training loss: 2.8117313606252874
Validation loss: 2.502503679582657

Epoch: 6| Step: 7
Training loss: 2.5590650284596625
Validation loss: 2.5129487299512303

Epoch: 6| Step: 8
Training loss: 2.9371961071197967
Validation loss: 2.526088011282355

Epoch: 6| Step: 9
Training loss: 2.972968066349714
Validation loss: 2.5437886128565426

Epoch: 6| Step: 10
Training loss: 3.2840244734081017
Validation loss: 2.5266620831041187

Epoch: 6| Step: 11
Training loss: 2.6783087828705203
Validation loss: 2.5217051702274573

Epoch: 6| Step: 12
Training loss: 2.7298897714683785
Validation loss: 2.5211541617380337

Epoch: 6| Step: 13
Training loss: 2.3768423864919206
Validation loss: 2.5237785679561386

Epoch: 318| Step: 0
Training loss: 3.285249869773705
Validation loss: 2.5079632821326485

Epoch: 6| Step: 1
Training loss: 2.3622885392430706
Validation loss: 2.4931917042451093

Epoch: 6| Step: 2
Training loss: 2.450191517565066
Validation loss: 2.4912165130171955

Epoch: 6| Step: 3
Training loss: 3.0613715759285607
Validation loss: 2.4894102828203586

Epoch: 6| Step: 4
Training loss: 2.9093686670220076
Validation loss: 2.4897384808026137

Epoch: 6| Step: 5
Training loss: 2.210138291049672
Validation loss: 2.4986551379633886

Epoch: 6| Step: 6
Training loss: 2.6891584380356615
Validation loss: 2.535235945248156

Epoch: 6| Step: 7
Training loss: 2.0869594170975296
Validation loss: 2.552162807718032

Epoch: 6| Step: 8
Training loss: 2.419398659955291
Validation loss: 2.572317505929329

Epoch: 6| Step: 9
Training loss: 2.5443555856187507
Validation loss: 2.5889136914731647

Epoch: 6| Step: 10
Training loss: 3.0446835192748596
Validation loss: 2.617061514371197

Epoch: 6| Step: 11
Training loss: 3.34871867713077
Validation loss: 2.6461912650565114

Epoch: 6| Step: 12
Training loss: 3.3046410379232367
Validation loss: 2.6098033201521744

Epoch: 6| Step: 13
Training loss: 3.5266113872798757
Validation loss: 2.5554250336365647

Epoch: 319| Step: 0
Training loss: 3.0327531685938784
Validation loss: 2.5097441128306435

Epoch: 6| Step: 1
Training loss: 2.8564252803784758
Validation loss: 2.4890281764331754

Epoch: 6| Step: 2
Training loss: 2.604433142697561
Validation loss: 2.470814955663996

Epoch: 6| Step: 3
Training loss: 3.162314904868924
Validation loss: 2.4617958354645726

Epoch: 6| Step: 4
Training loss: 2.2358127050008596
Validation loss: 2.466568768946791

Epoch: 6| Step: 5
Training loss: 2.9764862451272376
Validation loss: 2.4792303294480917

Epoch: 6| Step: 6
Training loss: 3.3040307657227235
Validation loss: 2.467548808676625

Epoch: 6| Step: 7
Training loss: 2.3333427792312524
Validation loss: 2.471554245678307

Epoch: 6| Step: 8
Training loss: 2.7394071650460727
Validation loss: 2.473068064339901

Epoch: 6| Step: 9
Training loss: 2.6350747189432906
Validation loss: 2.473629648408779

Epoch: 6| Step: 10
Training loss: 2.9438798491071276
Validation loss: 2.4750345752845386

Epoch: 6| Step: 11
Training loss: 2.5247848267982875
Validation loss: 2.467648565892046

Epoch: 6| Step: 12
Training loss: 2.8469622568268926
Validation loss: 2.476777326937961

Epoch: 6| Step: 13
Training loss: 3.514849089724217
Validation loss: 2.4772662969780126

Epoch: 320| Step: 0
Training loss: 2.993172824467192
Validation loss: 2.4806868252127106

Epoch: 6| Step: 1
Training loss: 2.875907423033533
Validation loss: 2.469507073545935

Epoch: 6| Step: 2
Training loss: 3.2889717433848804
Validation loss: 2.480224416473337

Epoch: 6| Step: 3
Training loss: 2.7743886256973673
Validation loss: 2.489363708845346

Epoch: 6| Step: 4
Training loss: 3.228324796802878
Validation loss: 2.52533210520552

Epoch: 6| Step: 5
Training loss: 2.6236430702755813
Validation loss: 2.550548936172985

Epoch: 6| Step: 6
Training loss: 2.4061980799238247
Validation loss: 2.5848885782484605

Epoch: 6| Step: 7
Training loss: 2.7976400511783197
Validation loss: 2.606084246728098

Epoch: 6| Step: 8
Training loss: 3.055694180050921
Validation loss: 2.640467448327077

Epoch: 6| Step: 9
Training loss: 2.620414907493573
Validation loss: 2.648750984780059

Epoch: 6| Step: 10
Training loss: 2.376803666919408
Validation loss: 2.6314094587698498

Epoch: 6| Step: 11
Training loss: 2.9078440242741417
Validation loss: 2.608306905887847

Epoch: 6| Step: 12
Training loss: 2.79147029774405
Validation loss: 2.573601855213791

Epoch: 6| Step: 13
Training loss: 2.626839492779335
Validation loss: 2.569185778690419

Epoch: 321| Step: 0
Training loss: 2.899703661806486
Validation loss: 2.530730872458016

Epoch: 6| Step: 1
Training loss: 2.745298528228622
Validation loss: 2.5198475567853733

Epoch: 6| Step: 2
Training loss: 2.2599885479459676
Validation loss: 2.493785840276377

Epoch: 6| Step: 3
Training loss: 2.2228704526960166
Validation loss: 2.4944508113518404

Epoch: 6| Step: 4
Training loss: 2.8099132085951775
Validation loss: 2.480793178878941

Epoch: 6| Step: 5
Training loss: 2.9593972097528196
Validation loss: 2.4971285778194967

Epoch: 6| Step: 6
Training loss: 1.4824463210270253
Validation loss: 2.4887480616403206

Epoch: 6| Step: 7
Training loss: 3.1898528746157457
Validation loss: 2.502666598652485

Epoch: 6| Step: 8
Training loss: 2.9915407442955333
Validation loss: 2.500363854622853

Epoch: 6| Step: 9
Training loss: 3.098706830929291
Validation loss: 2.5099427348527983

Epoch: 6| Step: 10
Training loss: 3.4639212875938026
Validation loss: 2.5189718032512824

Epoch: 6| Step: 11
Training loss: 2.9812887321211377
Validation loss: 2.5302519877296645

Epoch: 6| Step: 12
Training loss: 2.631786293594867
Validation loss: 2.5328301273507443

Epoch: 6| Step: 13
Training loss: 3.0405193063492812
Validation loss: 2.5174718737159107

Epoch: 322| Step: 0
Training loss: 2.4655525651355585
Validation loss: 2.5305547403788617

Epoch: 6| Step: 1
Training loss: 2.836040904784492
Validation loss: 2.5190091817613323

Epoch: 6| Step: 2
Training loss: 2.6785293612128642
Validation loss: 2.520070182088648

Epoch: 6| Step: 3
Training loss: 3.2408412114468828
Validation loss: 2.4965531963366305

Epoch: 6| Step: 4
Training loss: 2.6638138730550907
Validation loss: 2.504160349070122

Epoch: 6| Step: 5
Training loss: 3.117596821692464
Validation loss: 2.4912593940696173

Epoch: 6| Step: 6
Training loss: 2.661944310758646
Validation loss: 2.496312377070808

Epoch: 6| Step: 7
Training loss: 2.9521663663965168
Validation loss: 2.493907216701773

Epoch: 6| Step: 8
Training loss: 2.8647215838738664
Validation loss: 2.494544660519222

Epoch: 6| Step: 9
Training loss: 2.441732400089629
Validation loss: 2.511327922712197

Epoch: 6| Step: 10
Training loss: 2.857041537668192
Validation loss: 2.513985687413976

Epoch: 6| Step: 11
Training loss: 2.9389829747556075
Validation loss: 2.542971989620595

Epoch: 6| Step: 12
Training loss: 2.6871224071587596
Validation loss: 2.532492698333596

Epoch: 6| Step: 13
Training loss: 2.582650391740909
Validation loss: 2.5409666382066702

Epoch: 323| Step: 0
Training loss: 2.3828026943317706
Validation loss: 2.55486111344057

Epoch: 6| Step: 1
Training loss: 2.0063475968339306
Validation loss: 2.5855651375221966

Epoch: 6| Step: 2
Training loss: 3.2908913065354595
Validation loss: 2.580767749526812

Epoch: 6| Step: 3
Training loss: 2.8464439961927783
Validation loss: 2.5585048744955725

Epoch: 6| Step: 4
Training loss: 3.1123204681216654
Validation loss: 2.564276856804492

Epoch: 6| Step: 5
Training loss: 2.247007499257889
Validation loss: 2.5461340935749006

Epoch: 6| Step: 6
Training loss: 2.3611340565283347
Validation loss: 2.5356116150793544

Epoch: 6| Step: 7
Training loss: 3.279698468281296
Validation loss: 2.5364994123992113

Epoch: 6| Step: 8
Training loss: 2.3054174269493344
Validation loss: 2.5297457389008247

Epoch: 6| Step: 9
Training loss: 2.9899519494830153
Validation loss: 2.5246631050331803

Epoch: 6| Step: 10
Training loss: 2.9057605290206143
Validation loss: 2.525780079148812

Epoch: 6| Step: 11
Training loss: 3.3292191547048553
Validation loss: 2.5177788252488726

Epoch: 6| Step: 12
Training loss: 2.5232869862172302
Validation loss: 2.502211582085967

Epoch: 6| Step: 13
Training loss: 3.2735926334156518
Validation loss: 2.5157168914311026

Epoch: 324| Step: 0
Training loss: 2.4793202542299104
Validation loss: 2.486650395557738

Epoch: 6| Step: 1
Training loss: 2.8142703100865885
Validation loss: 2.4821467024849015

Epoch: 6| Step: 2
Training loss: 2.8045375433231734
Validation loss: 2.472671059552754

Epoch: 6| Step: 3
Training loss: 3.1631879940216105
Validation loss: 2.487844620906219

Epoch: 6| Step: 4
Training loss: 2.3247073902048925
Validation loss: 2.492678832202454

Epoch: 6| Step: 5
Training loss: 2.8697165994582208
Validation loss: 2.507812456042747

Epoch: 6| Step: 6
Training loss: 3.564594121783258
Validation loss: 2.504510291369481

Epoch: 6| Step: 7
Training loss: 2.3836138269009637
Validation loss: 2.5583576413143128

Epoch: 6| Step: 8
Training loss: 3.01329907468153
Validation loss: 2.568623964332366

Epoch: 6| Step: 9
Training loss: 2.8980831124950006
Validation loss: 2.5871816968723635

Epoch: 6| Step: 10
Training loss: 3.0890928723275293
Validation loss: 2.6138369074053025

Epoch: 6| Step: 11
Training loss: 2.3532912277943248
Validation loss: 2.611154042284263

Epoch: 6| Step: 12
Training loss: 2.6078682392396404
Validation loss: 2.6204593665204254

Epoch: 6| Step: 13
Training loss: 2.506494764138762
Validation loss: 2.6220976053058225

Epoch: 325| Step: 0
Training loss: 3.011602218886931
Validation loss: 2.5765330849359707

Epoch: 6| Step: 1
Training loss: 2.8409564371498557
Validation loss: 2.5668466201134157

Epoch: 6| Step: 2
Training loss: 2.923591639881026
Validation loss: 2.5322015271015963

Epoch: 6| Step: 3
Training loss: 2.425478512459819
Validation loss: 2.5093139911138835

Epoch: 6| Step: 4
Training loss: 2.5734198897963037
Validation loss: 2.487817524641023

Epoch: 6| Step: 5
Training loss: 3.108234905767444
Validation loss: 2.4723306030065153

Epoch: 6| Step: 6
Training loss: 2.745802102806147
Validation loss: 2.4751730702896766

Epoch: 6| Step: 7
Training loss: 2.5769180709492425
Validation loss: 2.475097192741302

Epoch: 6| Step: 8
Training loss: 2.3499483670994663
Validation loss: 2.474872046206666

Epoch: 6| Step: 9
Training loss: 3.306270427676807
Validation loss: 2.484325731175507

Epoch: 6| Step: 10
Training loss: 2.9435236428738305
Validation loss: 2.471122234361179

Epoch: 6| Step: 11
Training loss: 3.2584911343996974
Validation loss: 2.481224974567047

Epoch: 6| Step: 12
Training loss: 2.5788344823078297
Validation loss: 2.4732161384734703

Epoch: 6| Step: 13
Training loss: 2.5979055184678566
Validation loss: 2.474378875756822

Epoch: 326| Step: 0
Training loss: 3.445400799162576
Validation loss: 2.4780104924418094

Epoch: 6| Step: 1
Training loss: 2.671913905167226
Validation loss: 2.49646036435279

Epoch: 6| Step: 2
Training loss: 2.1851056755577045
Validation loss: 2.51679448916404

Epoch: 6| Step: 3
Training loss: 2.9665949980690587
Validation loss: 2.5491868445558294

Epoch: 6| Step: 4
Training loss: 2.3261509661371385
Validation loss: 2.563022920330383

Epoch: 6| Step: 5
Training loss: 2.7677753084803762
Validation loss: 2.601811812006239

Epoch: 6| Step: 6
Training loss: 2.461443942804576
Validation loss: 2.5935364116481403

Epoch: 6| Step: 7
Training loss: 2.8682825975144257
Validation loss: 2.5989155058172413

Epoch: 6| Step: 8
Training loss: 2.994131547350476
Validation loss: 2.5930289491731227

Epoch: 6| Step: 9
Training loss: 2.6601972982905835
Validation loss: 2.5891152485462063

Epoch: 6| Step: 10
Training loss: 2.7877859405152106
Validation loss: 2.591477709499041

Epoch: 6| Step: 11
Training loss: 2.321479067410431
Validation loss: 2.596299824856849

Epoch: 6| Step: 12
Training loss: 2.9868537235719503
Validation loss: 2.5929481521175544

Epoch: 6| Step: 13
Training loss: 3.509988428515192
Validation loss: 2.5757644859744637

Epoch: 327| Step: 0
Training loss: 3.125796102208685
Validation loss: 2.5348889845050806

Epoch: 6| Step: 1
Training loss: 2.958961330613649
Validation loss: 2.502356631608081

Epoch: 6| Step: 2
Training loss: 2.9284711016440066
Validation loss: 2.476103225884202

Epoch: 6| Step: 3
Training loss: 2.653654558331512
Validation loss: 2.466031254700971

Epoch: 6| Step: 4
Training loss: 2.87862184690657
Validation loss: 2.4684195950961225

Epoch: 6| Step: 5
Training loss: 2.8891743086970636
Validation loss: 2.4741312840644403

Epoch: 6| Step: 6
Training loss: 2.981224594167904
Validation loss: 2.463852979504541

Epoch: 6| Step: 7
Training loss: 2.3721496141604708
Validation loss: 2.464942131512229

Epoch: 6| Step: 8
Training loss: 2.8200511864149282
Validation loss: 2.468310425911933

Epoch: 6| Step: 9
Training loss: 2.965798929016179
Validation loss: 2.4708281752933665

Epoch: 6| Step: 10
Training loss: 2.571417110281334
Validation loss: 2.467735996107825

Epoch: 6| Step: 11
Training loss: 2.7090267956416367
Validation loss: 2.4708974285604293

Epoch: 6| Step: 12
Training loss: 2.9959484398330662
Validation loss: 2.478651582321874

Epoch: 6| Step: 13
Training loss: 2.4383735069707986
Validation loss: 2.464080757459831

Epoch: 328| Step: 0
Training loss: 2.886216054050136
Validation loss: 2.4707630149401396

Epoch: 6| Step: 1
Training loss: 2.2338687349856716
Validation loss: 2.477694676165384

Epoch: 6| Step: 2
Training loss: 2.826909346674418
Validation loss: 2.4800251902727632

Epoch: 6| Step: 3
Training loss: 3.039264740870742
Validation loss: 2.493262105918809

Epoch: 6| Step: 4
Training loss: 2.7886374440854915
Validation loss: 2.4954305419888976

Epoch: 6| Step: 5
Training loss: 2.346414907489897
Validation loss: 2.521541656288063

Epoch: 6| Step: 6
Training loss: 2.6736897334529086
Validation loss: 2.5289052689476805

Epoch: 6| Step: 7
Training loss: 2.9902267206792956
Validation loss: 2.5472042490724074

Epoch: 6| Step: 8
Training loss: 2.3216645382855208
Validation loss: 2.524888015196109

Epoch: 6| Step: 9
Training loss: 2.86280008933587
Validation loss: 2.526300368124663

Epoch: 6| Step: 10
Training loss: 3.3324913074010873
Validation loss: 2.519397549087757

Epoch: 6| Step: 11
Training loss: 3.191028362486437
Validation loss: 2.5088379326585475

Epoch: 6| Step: 12
Training loss: 2.702406947733303
Validation loss: 2.5021437436681455

Epoch: 6| Step: 13
Training loss: 2.6331319643440567
Validation loss: 2.510691872296705

Epoch: 329| Step: 0
Training loss: 2.837223486514018
Validation loss: 2.502104580928947

Epoch: 6| Step: 1
Training loss: 3.1438113318465186
Validation loss: 2.50866711644579

Epoch: 6| Step: 2
Training loss: 2.395615100596312
Validation loss: 2.504542759030134

Epoch: 6| Step: 3
Training loss: 2.557854139283857
Validation loss: 2.5136563977817428

Epoch: 6| Step: 4
Training loss: 2.775454623124066
Validation loss: 2.5233607228270074

Epoch: 6| Step: 5
Training loss: 2.6460519134665077
Validation loss: 2.5466339271025613

Epoch: 6| Step: 6
Training loss: 3.209290167737611
Validation loss: 2.552947442579637

Epoch: 6| Step: 7
Training loss: 2.7670312959081977
Validation loss: 2.5638124829906443

Epoch: 6| Step: 8
Training loss: 2.8745022218423255
Validation loss: 2.6128118521319403

Epoch: 6| Step: 9
Training loss: 2.8150687461033854
Validation loss: 2.6411628658354163

Epoch: 6| Step: 10
Training loss: 2.286171399116369
Validation loss: 2.6292675056372223

Epoch: 6| Step: 11
Training loss: 2.8604637532944084
Validation loss: 2.6662378953449783

Epoch: 6| Step: 12
Training loss: 2.9423294948807674
Validation loss: 2.6373421993929442

Epoch: 6| Step: 13
Training loss: 2.8737010509276253
Validation loss: 2.5830452920842624

Epoch: 330| Step: 0
Training loss: 3.210224750054397
Validation loss: 2.5120755923588676

Epoch: 6| Step: 1
Training loss: 2.97656121842164
Validation loss: 2.4950677989188543

Epoch: 6| Step: 2
Training loss: 2.511115919894375
Validation loss: 2.497126478349189

Epoch: 6| Step: 3
Training loss: 2.8298014524655217
Validation loss: 2.477399673229382

Epoch: 6| Step: 4
Training loss: 2.8703426286822054
Validation loss: 2.472981191686025

Epoch: 6| Step: 5
Training loss: 2.669004538053769
Validation loss: 2.4864955939432463

Epoch: 6| Step: 6
Training loss: 2.645764467639759
Validation loss: 2.495656152828185

Epoch: 6| Step: 7
Training loss: 2.5392181818257664
Validation loss: 2.5078205032739724

Epoch: 6| Step: 8
Training loss: 2.593324373551739
Validation loss: 2.522418448650533

Epoch: 6| Step: 9
Training loss: 2.6644099839535866
Validation loss: 2.5462280997993147

Epoch: 6| Step: 10
Training loss: 2.7874327099807985
Validation loss: 2.5357826331650446

Epoch: 6| Step: 11
Training loss: 3.058077363018
Validation loss: 2.5351682594073393

Epoch: 6| Step: 12
Training loss: 2.936427143675999
Validation loss: 2.5352373538548854

Epoch: 6| Step: 13
Training loss: 2.470282163681041
Validation loss: 2.54802999523049

Epoch: 331| Step: 0
Training loss: 2.354069384249971
Validation loss: 2.547225988861534

Epoch: 6| Step: 1
Training loss: 3.0481250252800933
Validation loss: 2.554274372927419

Epoch: 6| Step: 2
Training loss: 2.8170317697246836
Validation loss: 2.5364594545547408

Epoch: 6| Step: 3
Training loss: 3.0990465851513878
Validation loss: 2.5202912720989836

Epoch: 6| Step: 4
Training loss: 3.524878230595682
Validation loss: 2.5247043558781557

Epoch: 6| Step: 5
Training loss: 3.0413011479339427
Validation loss: 2.5060224370287947

Epoch: 6| Step: 6
Training loss: 2.6694042538429
Validation loss: 2.499504664786933

Epoch: 6| Step: 7
Training loss: 2.6878142062304744
Validation loss: 2.4922445509753777

Epoch: 6| Step: 8
Training loss: 2.437000712585971
Validation loss: 2.492541637983126

Epoch: 6| Step: 9
Training loss: 2.279181810104394
Validation loss: 2.490070040237029

Epoch: 6| Step: 10
Training loss: 2.675482383799779
Validation loss: 2.5030062689218737

Epoch: 6| Step: 11
Training loss: 1.9182138072785213
Validation loss: 2.500139403814705

Epoch: 6| Step: 12
Training loss: 3.081528539235449
Validation loss: 2.5257040278744434

Epoch: 6| Step: 13
Training loss: 2.918065979753512
Validation loss: 2.5367683752961274

Epoch: 332| Step: 0
Training loss: 2.8704127327950237
Validation loss: 2.590887586380708

Epoch: 6| Step: 1
Training loss: 2.4934767494502186
Validation loss: 2.627623503468606

Epoch: 6| Step: 2
Training loss: 2.8812931678169598
Validation loss: 2.5602717942787945

Epoch: 6| Step: 3
Training loss: 2.353315441434601
Validation loss: 2.492742213828048

Epoch: 6| Step: 4
Training loss: 3.11137241636122
Validation loss: 2.472992234681818

Epoch: 6| Step: 5
Training loss: 2.9512188931045236
Validation loss: 2.4547756732312873

Epoch: 6| Step: 6
Training loss: 3.068254630512457
Validation loss: 2.458806386754492

Epoch: 6| Step: 7
Training loss: 2.5793282215340207
Validation loss: 2.454651939911697

Epoch: 6| Step: 8
Training loss: 3.040508798886054
Validation loss: 2.467631408395282

Epoch: 6| Step: 9
Training loss: 3.146153835786651
Validation loss: 2.464954815818422

Epoch: 6| Step: 10
Training loss: 2.7720015986109057
Validation loss: 2.4683224663636443

Epoch: 6| Step: 11
Training loss: 3.462140634114354
Validation loss: 2.4570520342311597

Epoch: 6| Step: 12
Training loss: 2.4555753873462476
Validation loss: 2.4539292700078628

Epoch: 6| Step: 13
Training loss: 1.961602937780797
Validation loss: 2.463556702020815

Epoch: 333| Step: 0
Training loss: 2.385600575738552
Validation loss: 2.4725931466668887

Epoch: 6| Step: 1
Training loss: 3.1656503719657443
Validation loss: 2.49208084203788

Epoch: 6| Step: 2
Training loss: 2.602018115954775
Validation loss: 2.5106275821588895

Epoch: 6| Step: 3
Training loss: 2.0779439517439724
Validation loss: 2.5281280777966972

Epoch: 6| Step: 4
Training loss: 2.9159538124518605
Validation loss: 2.551668022739838

Epoch: 6| Step: 5
Training loss: 2.8938447084026637
Validation loss: 2.60410091653493

Epoch: 6| Step: 6
Training loss: 2.363776137814177
Validation loss: 2.6366398051546676

Epoch: 6| Step: 7
Training loss: 2.794110258287516
Validation loss: 2.60008959142557

Epoch: 6| Step: 8
Training loss: 3.0797046926048517
Validation loss: 2.5554791344405103

Epoch: 6| Step: 9
Training loss: 2.512777766725492
Validation loss: 2.511249976995479

Epoch: 6| Step: 10
Training loss: 3.039908872292599
Validation loss: 2.476842193994443

Epoch: 6| Step: 11
Training loss: 2.923767129979178
Validation loss: 2.454261135770173

Epoch: 6| Step: 12
Training loss: 3.0481686706731055
Validation loss: 2.4574230866413855

Epoch: 6| Step: 13
Training loss: 3.078154742876607
Validation loss: 2.459678070065584

Epoch: 334| Step: 0
Training loss: 2.837931118785857
Validation loss: 2.455230856158024

Epoch: 6| Step: 1
Training loss: 2.6038738442140454
Validation loss: 2.451166592235892

Epoch: 6| Step: 2
Training loss: 2.6510081910503622
Validation loss: 2.452463082015841

Epoch: 6| Step: 3
Training loss: 2.622506274133092
Validation loss: 2.4620251448999055

Epoch: 6| Step: 4
Training loss: 2.980872050705669
Validation loss: 2.4569770400999125

Epoch: 6| Step: 5
Training loss: 2.664826314394368
Validation loss: 2.457576479471336

Epoch: 6| Step: 6
Training loss: 2.8020746923452866
Validation loss: 2.4726872712664925

Epoch: 6| Step: 7
Training loss: 2.9710098499505886
Validation loss: 2.4742459210442957

Epoch: 6| Step: 8
Training loss: 2.7117544916424707
Validation loss: 2.5004815529983895

Epoch: 6| Step: 9
Training loss: 2.5182752213841137
Validation loss: 2.4996025066829657

Epoch: 6| Step: 10
Training loss: 2.8051976667036826
Validation loss: 2.530303292910808

Epoch: 6| Step: 11
Training loss: 2.885701042695258
Validation loss: 2.5258779983771187

Epoch: 6| Step: 12
Training loss: 3.0893940170292384
Validation loss: 2.5216785852179204

Epoch: 6| Step: 13
Training loss: 2.8814346618393447
Validation loss: 2.5157615814603553

Epoch: 335| Step: 0
Training loss: 2.58322600685229
Validation loss: 2.5326866348037385

Epoch: 6| Step: 1
Training loss: 2.4477322339860694
Validation loss: 2.522190873239434

Epoch: 6| Step: 2
Training loss: 3.0240711267775384
Validation loss: 2.520185229805074

Epoch: 6| Step: 3
Training loss: 3.04059473945952
Validation loss: 2.5189867872891214

Epoch: 6| Step: 4
Training loss: 2.413959982463677
Validation loss: 2.5296557454830593

Epoch: 6| Step: 5
Training loss: 2.1405507095699643
Validation loss: 2.5272651580642953

Epoch: 6| Step: 6
Training loss: 2.8837158111146217
Validation loss: 2.512557071104341

Epoch: 6| Step: 7
Training loss: 2.711243186228075
Validation loss: 2.5157176343182504

Epoch: 6| Step: 8
Training loss: 3.5424850116808395
Validation loss: 2.5025379972507262

Epoch: 6| Step: 9
Training loss: 2.9426239451683633
Validation loss: 2.5119388727360397

Epoch: 6| Step: 10
Training loss: 2.33655624105144
Validation loss: 2.5211841363229133

Epoch: 6| Step: 11
Training loss: 2.68584426620425
Validation loss: 2.5189793731376824

Epoch: 6| Step: 12
Training loss: 2.6020840875173006
Validation loss: 2.539097831486563

Epoch: 6| Step: 13
Training loss: 3.031450088032206
Validation loss: 2.5198724153075274

Epoch: 336| Step: 0
Training loss: 2.9698513196727396
Validation loss: 2.508329765247242

Epoch: 6| Step: 1
Training loss: 2.248316028698987
Validation loss: 2.5016349717060655

Epoch: 6| Step: 2
Training loss: 2.2136947638730318
Validation loss: 2.5152937708551657

Epoch: 6| Step: 3
Training loss: 2.702199259212173
Validation loss: 2.5092410207450517

Epoch: 6| Step: 4
Training loss: 2.6622950264559044
Validation loss: 2.5164142334402984

Epoch: 6| Step: 5
Training loss: 2.8025972445764693
Validation loss: 2.5248312865442504

Epoch: 6| Step: 6
Training loss: 2.727630668328316
Validation loss: 2.5421817996518357

Epoch: 6| Step: 7
Training loss: 2.854758616596717
Validation loss: 2.5319018591204974

Epoch: 6| Step: 8
Training loss: 3.149308531419908
Validation loss: 2.5207394625065205

Epoch: 6| Step: 9
Training loss: 2.227209378688073
Validation loss: 2.507626362751092

Epoch: 6| Step: 10
Training loss: 2.6575135759812514
Validation loss: 2.5052686446144135

Epoch: 6| Step: 11
Training loss: 2.8310277384238214
Validation loss: 2.5019136580235037

Epoch: 6| Step: 12
Training loss: 3.376961032379406
Validation loss: 2.48142827209471

Epoch: 6| Step: 13
Training loss: 2.688230903063127
Validation loss: 2.475602313937716

Epoch: 337| Step: 0
Training loss: 3.1579597299145092
Validation loss: 2.4687015844903777

Epoch: 6| Step: 1
Training loss: 2.5257119714101237
Validation loss: 2.4736629297198913

Epoch: 6| Step: 2
Training loss: 2.9849392821815566
Validation loss: 2.4653962568203984

Epoch: 6| Step: 3
Training loss: 2.3298995660247783
Validation loss: 2.4730278927772105

Epoch: 6| Step: 4
Training loss: 2.995021344651726
Validation loss: 2.468522455568543

Epoch: 6| Step: 5
Training loss: 2.742903308962402
Validation loss: 2.4771891495617058

Epoch: 6| Step: 6
Training loss: 2.6652552823439364
Validation loss: 2.4779001152724978

Epoch: 6| Step: 7
Training loss: 2.4918970399163656
Validation loss: 2.4721914593033634

Epoch: 6| Step: 8
Training loss: 2.141412075164231
Validation loss: 2.481525225418653

Epoch: 6| Step: 9
Training loss: 2.7224429250852404
Validation loss: 2.48374706383306

Epoch: 6| Step: 10
Training loss: 2.569131597311948
Validation loss: 2.4975623090143393

Epoch: 6| Step: 11
Training loss: 3.1666014480567273
Validation loss: 2.5227186318871757

Epoch: 6| Step: 12
Training loss: 2.9840880251012596
Validation loss: 2.5374846007726832

Epoch: 6| Step: 13
Training loss: 2.6238117253283826
Validation loss: 2.5592986437739507

Epoch: 338| Step: 0
Training loss: 3.02766615596729
Validation loss: 2.5795678798004946

Epoch: 6| Step: 1
Training loss: 2.5338793626233693
Validation loss: 2.5745222457487915

Epoch: 6| Step: 2
Training loss: 2.940158533765538
Validation loss: 2.5579983316912664

Epoch: 6| Step: 3
Training loss: 2.9369321233629506
Validation loss: 2.5351264274710443

Epoch: 6| Step: 4
Training loss: 2.744815013190237
Validation loss: 2.5426847371334795

Epoch: 6| Step: 5
Training loss: 2.827806402143568
Validation loss: 2.5633155501389266

Epoch: 6| Step: 6
Training loss: 3.125418673125925
Validation loss: 2.5741379670544595

Epoch: 6| Step: 7
Training loss: 2.7362277484266118
Validation loss: 2.517125639991097

Epoch: 6| Step: 8
Training loss: 1.925123121609554
Validation loss: 2.4817464725912086

Epoch: 6| Step: 9
Training loss: 2.5111200974827814
Validation loss: 2.4630546425757047

Epoch: 6| Step: 10
Training loss: 2.861012807924735
Validation loss: 2.4633163140604424

Epoch: 6| Step: 11
Training loss: 2.5825098837767664
Validation loss: 2.4705807279196286

Epoch: 6| Step: 12
Training loss: 2.826788148998585
Validation loss: 2.467180119758869

Epoch: 6| Step: 13
Training loss: 2.971867901686285
Validation loss: 2.466380732062459

Epoch: 339| Step: 0
Training loss: 2.95098072495818
Validation loss: 2.4664990054118197

Epoch: 6| Step: 1
Training loss: 3.273001630438268
Validation loss: 2.4772910239618287

Epoch: 6| Step: 2
Training loss: 2.456267755264678
Validation loss: 2.471825094297306

Epoch: 6| Step: 3
Training loss: 2.588484417431302
Validation loss: 2.4760975521438544

Epoch: 6| Step: 4
Training loss: 2.5105748634564815
Validation loss: 2.4943164279709635

Epoch: 6| Step: 5
Training loss: 2.9417443961301406
Validation loss: 2.5154590341755627

Epoch: 6| Step: 6
Training loss: 2.2609613234102506
Validation loss: 2.5324150735259567

Epoch: 6| Step: 7
Training loss: 2.7524916025253656
Validation loss: 2.515686101673944

Epoch: 6| Step: 8
Training loss: 2.407055212271184
Validation loss: 2.526549436792524

Epoch: 6| Step: 9
Training loss: 2.9534970003793806
Validation loss: 2.5248994190542606

Epoch: 6| Step: 10
Training loss: 3.088543450717936
Validation loss: 2.5090588792926893

Epoch: 6| Step: 11
Training loss: 2.926239996318184
Validation loss: 2.5023257870820332

Epoch: 6| Step: 12
Training loss: 2.2697750623730872
Validation loss: 2.4911451556427986

Epoch: 6| Step: 13
Training loss: 2.711749743935928
Validation loss: 2.4754199136153674

Epoch: 340| Step: 0
Training loss: 2.7258259562671756
Validation loss: 2.4803299295047845

Epoch: 6| Step: 1
Training loss: 2.0112628901740104
Validation loss: 2.472227139318478

Epoch: 6| Step: 2
Training loss: 2.8237577829848957
Validation loss: 2.477265598442827

Epoch: 6| Step: 3
Training loss: 3.2229435833080484
Validation loss: 2.4712438660008456

Epoch: 6| Step: 4
Training loss: 3.0429499457859297
Validation loss: 2.4709847728724723

Epoch: 6| Step: 5
Training loss: 2.869860159627195
Validation loss: 2.4821141009275443

Epoch: 6| Step: 6
Training loss: 2.153695846647275
Validation loss: 2.5029310395174944

Epoch: 6| Step: 7
Training loss: 2.4828744831354497
Validation loss: 2.510744797350622

Epoch: 6| Step: 8
Training loss: 2.864993719124026
Validation loss: 2.508405521580379

Epoch: 6| Step: 9
Training loss: 3.20404873065823
Validation loss: 2.5267119884649776

Epoch: 6| Step: 10
Training loss: 2.590395861386627
Validation loss: 2.546194363436162

Epoch: 6| Step: 11
Training loss: 2.7973342603688605
Validation loss: 2.5708125712937684

Epoch: 6| Step: 12
Training loss: 2.796057555014229
Validation loss: 2.5866627060598013

Epoch: 6| Step: 13
Training loss: 2.1731326626457963
Validation loss: 2.594389668438947

Epoch: 341| Step: 0
Training loss: 2.6013520759964455
Validation loss: 2.572703493462512

Epoch: 6| Step: 1
Training loss: 2.3334630407884824
Validation loss: 2.5735298310573613

Epoch: 6| Step: 2
Training loss: 2.9786500994233815
Validation loss: 2.5532447564643546

Epoch: 6| Step: 3
Training loss: 3.2454623309441057
Validation loss: 2.545708185764616

Epoch: 6| Step: 4
Training loss: 3.0360484732677193
Validation loss: 2.545232907174582

Epoch: 6| Step: 5
Training loss: 2.870863551039395
Validation loss: 2.5898106986070824

Epoch: 6| Step: 6
Training loss: 2.5322272215760324
Validation loss: 2.5664024241244383

Epoch: 6| Step: 7
Training loss: 2.4452095375687515
Validation loss: 2.5822787863149426

Epoch: 6| Step: 8
Training loss: 2.6790185210074378
Validation loss: 2.596741071673378

Epoch: 6| Step: 9
Training loss: 2.748452184485004
Validation loss: 2.5958031085930835

Epoch: 6| Step: 10
Training loss: 2.8839544086741444
Validation loss: 2.568680200401174

Epoch: 6| Step: 11
Training loss: 2.7569289913005974
Validation loss: 2.5172559642980037

Epoch: 6| Step: 12
Training loss: 2.8551911977156093
Validation loss: 2.515264139883064

Epoch: 6| Step: 13
Training loss: 2.4002139194837295
Validation loss: 2.483859739802926

Epoch: 342| Step: 0
Training loss: 2.2009181880902577
Validation loss: 2.495361481587268

Epoch: 6| Step: 1
Training loss: 2.8445909535240905
Validation loss: 2.484833146573329

Epoch: 6| Step: 2
Training loss: 2.8118383688998523
Validation loss: 2.491182788562771

Epoch: 6| Step: 3
Training loss: 2.331798343753202
Validation loss: 2.4999256543415713

Epoch: 6| Step: 4
Training loss: 2.6922939038185585
Validation loss: 2.490997106278901

Epoch: 6| Step: 5
Training loss: 3.160711477800281
Validation loss: 2.4980854979219385

Epoch: 6| Step: 6
Training loss: 2.5515374877974537
Validation loss: 2.5006569932250717

Epoch: 6| Step: 7
Training loss: 3.403895412985532
Validation loss: 2.4989738357969222

Epoch: 6| Step: 8
Training loss: 2.624949863500001
Validation loss: 2.522451201085722

Epoch: 6| Step: 9
Training loss: 2.47126815426477
Validation loss: 2.508772428546499

Epoch: 6| Step: 10
Training loss: 2.702525783560506
Validation loss: 2.5261008137835037

Epoch: 6| Step: 11
Training loss: 2.9921314045002894
Validation loss: 2.5483381259972164

Epoch: 6| Step: 12
Training loss: 2.7137557010599536
Validation loss: 2.5578691882072166

Epoch: 6| Step: 13
Training loss: 2.9081426220935267
Validation loss: 2.5775453613837254

Epoch: 343| Step: 0
Training loss: 3.043040675046555
Validation loss: 2.5869665554175953

Epoch: 6| Step: 1
Training loss: 2.762216396359743
Validation loss: 2.59372683002132

Epoch: 6| Step: 2
Training loss: 2.805821266643098
Validation loss: 2.606831029235645

Epoch: 6| Step: 3
Training loss: 2.7227683352107945
Validation loss: 2.5864756128718036

Epoch: 6| Step: 4
Training loss: 2.151640235311069
Validation loss: 2.543499799105617

Epoch: 6| Step: 5
Training loss: 3.2053096113464363
Validation loss: 2.5111495221278095

Epoch: 6| Step: 6
Training loss: 2.362643876311704
Validation loss: 2.4920882714056436

Epoch: 6| Step: 7
Training loss: 2.5701629687934626
Validation loss: 2.4839626627139073

Epoch: 6| Step: 8
Training loss: 2.7188554063730863
Validation loss: 2.4858983140260595

Epoch: 6| Step: 9
Training loss: 2.223172575339947
Validation loss: 2.48613085941053

Epoch: 6| Step: 10
Training loss: 3.009930070844183
Validation loss: 2.4823273361699107

Epoch: 6| Step: 11
Training loss: 2.6432988099693535
Validation loss: 2.4865384553704724

Epoch: 6| Step: 12
Training loss: 3.0237331985063616
Validation loss: 2.494124583568398

Epoch: 6| Step: 13
Training loss: 3.101778344780053
Validation loss: 2.4937430006112957

Epoch: 344| Step: 0
Training loss: 2.708043381257573
Validation loss: 2.4956053501012376

Epoch: 6| Step: 1
Training loss: 2.71471465098848
Validation loss: 2.4870104966812647

Epoch: 6| Step: 2
Training loss: 2.6291061257366053
Validation loss: 2.494184405510917

Epoch: 6| Step: 3
Training loss: 2.86817387133367
Validation loss: 2.4913432832036397

Epoch: 6| Step: 4
Training loss: 2.6733592411539426
Validation loss: 2.4826112356456975

Epoch: 6| Step: 5
Training loss: 2.705895828435471
Validation loss: 2.489125064440801

Epoch: 6| Step: 6
Training loss: 2.454772687437875
Validation loss: 2.47245193153357

Epoch: 6| Step: 7
Training loss: 2.785518157258887
Validation loss: 2.484090344897659

Epoch: 6| Step: 8
Training loss: 2.095015413869451
Validation loss: 2.4805350976503107

Epoch: 6| Step: 9
Training loss: 3.1557689337903945
Validation loss: 2.5001411480179256

Epoch: 6| Step: 10
Training loss: 2.941602885245536
Validation loss: 2.509844890543149

Epoch: 6| Step: 11
Training loss: 2.363577932855999
Validation loss: 2.5160194403146456

Epoch: 6| Step: 12
Training loss: 2.983686277798202
Validation loss: 2.493081722586271

Epoch: 6| Step: 13
Training loss: 2.971361316847271
Validation loss: 2.5021675946983146

Epoch: 345| Step: 0
Training loss: 3.03510534766679
Validation loss: 2.5025769918643657

Epoch: 6| Step: 1
Training loss: 2.7025782743370184
Validation loss: 2.5088573956430413

Epoch: 6| Step: 2
Training loss: 2.6036202022671833
Validation loss: 2.5014437751891374

Epoch: 6| Step: 3
Training loss: 3.185923167631905
Validation loss: 2.499705204964345

Epoch: 6| Step: 4
Training loss: 2.3822156815336277
Validation loss: 2.5070919227967985

Epoch: 6| Step: 5
Training loss: 3.0206607813169177
Validation loss: 2.4881717869466904

Epoch: 6| Step: 6
Training loss: 2.4969774093919863
Validation loss: 2.4949620152099237

Epoch: 6| Step: 7
Training loss: 2.4937410206262602
Validation loss: 2.541518610678808

Epoch: 6| Step: 8
Training loss: 2.957680715294172
Validation loss: 2.561243097651759

Epoch: 6| Step: 9
Training loss: 2.9060485113706296
Validation loss: 2.551676170779541

Epoch: 6| Step: 10
Training loss: 2.174316351423899
Validation loss: 2.541732769743152

Epoch: 6| Step: 11
Training loss: 2.747554124849196
Validation loss: 2.5246188640120244

Epoch: 6| Step: 12
Training loss: 2.580527740737412
Validation loss: 2.502453609025617

Epoch: 6| Step: 13
Training loss: 2.7186928227868723
Validation loss: 2.4756301455559173

Epoch: 346| Step: 0
Training loss: 3.0008556417327927
Validation loss: 2.4672729156529427

Epoch: 6| Step: 1
Training loss: 2.3094974304700266
Validation loss: 2.474914088104166

Epoch: 6| Step: 2
Training loss: 3.100927023561913
Validation loss: 2.4639855606926924

Epoch: 6| Step: 3
Training loss: 3.1346046858024827
Validation loss: 2.451285137401102

Epoch: 6| Step: 4
Training loss: 2.4025460010772908
Validation loss: 2.4673299946265628

Epoch: 6| Step: 5
Training loss: 2.4299584142635133
Validation loss: 2.4626734884274546

Epoch: 6| Step: 6
Training loss: 2.49844464556905
Validation loss: 2.4748216149795788

Epoch: 6| Step: 7
Training loss: 2.756091047967222
Validation loss: 2.465738965258973

Epoch: 6| Step: 8
Training loss: 2.7497520334982095
Validation loss: 2.4762299612236776

Epoch: 6| Step: 9
Training loss: 2.6233387186107433
Validation loss: 2.4864189226037556

Epoch: 6| Step: 10
Training loss: 2.505511693107681
Validation loss: 2.488465155386373

Epoch: 6| Step: 11
Training loss: 3.021221442886636
Validation loss: 2.510017724485479

Epoch: 6| Step: 12
Training loss: 2.6906792222074425
Validation loss: 2.5269439178628224

Epoch: 6| Step: 13
Training loss: 2.7133583011774998
Validation loss: 2.513940076575596

Epoch: 347| Step: 0
Training loss: 2.7680725646678055
Validation loss: 2.52359197990699

Epoch: 6| Step: 1
Training loss: 2.6434792887289595
Validation loss: 2.51460744988258

Epoch: 6| Step: 2
Training loss: 2.989157474681999
Validation loss: 2.5448245948504464

Epoch: 6| Step: 3
Training loss: 2.22343787744858
Validation loss: 2.518379113726645

Epoch: 6| Step: 4
Training loss: 2.992414421062499
Validation loss: 2.5190382694964253

Epoch: 6| Step: 5
Training loss: 2.8942426159228978
Validation loss: 2.5346763479325993

Epoch: 6| Step: 6
Training loss: 2.6144201422799065
Validation loss: 2.532829567623737

Epoch: 6| Step: 7
Training loss: 2.4481666166786975
Validation loss: 2.5165312147561356

Epoch: 6| Step: 8
Training loss: 2.6284433215181937
Validation loss: 2.508191726323701

Epoch: 6| Step: 9
Training loss: 2.049845629206419
Validation loss: 2.509374893996171

Epoch: 6| Step: 10
Training loss: 3.0912400670244846
Validation loss: 2.4902119436104284

Epoch: 6| Step: 11
Training loss: 3.088534496142516
Validation loss: 2.501000278079513

Epoch: 6| Step: 12
Training loss: 2.8787432641278934
Validation loss: 2.48278863303567

Epoch: 6| Step: 13
Training loss: 1.9981707313609316
Validation loss: 2.484764963693636

Epoch: 348| Step: 0
Training loss: 2.482601564448374
Validation loss: 2.480711699468616

Epoch: 6| Step: 1
Training loss: 2.5740566636779203
Validation loss: 2.4730178953969406

Epoch: 6| Step: 2
Training loss: 2.9547145541690916
Validation loss: 2.498876441207696

Epoch: 6| Step: 3
Training loss: 1.990127994887554
Validation loss: 2.5165956225028188

Epoch: 6| Step: 4
Training loss: 2.6282597238525325
Validation loss: 2.5215965287929603

Epoch: 6| Step: 5
Training loss: 2.6565075917723333
Validation loss: 2.5366727835142027

Epoch: 6| Step: 6
Training loss: 3.304763973424418
Validation loss: 2.5321727282664312

Epoch: 6| Step: 7
Training loss: 2.2804659188368324
Validation loss: 2.5569401293000906

Epoch: 6| Step: 8
Training loss: 2.62734680629329
Validation loss: 2.5560598037742204

Epoch: 6| Step: 9
Training loss: 2.070800493416185
Validation loss: 2.5304559363271695

Epoch: 6| Step: 10
Training loss: 2.8786117423776503
Validation loss: 2.5151843112553927

Epoch: 6| Step: 11
Training loss: 2.9816730510997993
Validation loss: 2.4825298876767814

Epoch: 6| Step: 12
Training loss: 3.307044376930302
Validation loss: 2.471981595536051

Epoch: 6| Step: 13
Training loss: 3.1541673190789363
Validation loss: 2.4691435901381547

Epoch: 349| Step: 0
Training loss: 3.125843086956295
Validation loss: 2.4695553995590247

Epoch: 6| Step: 1
Training loss: 2.9251274733194887
Validation loss: 2.469178145637855

Epoch: 6| Step: 2
Training loss: 2.4562514482256086
Validation loss: 2.461158113606322

Epoch: 6| Step: 3
Training loss: 2.6985157383729637
Validation loss: 2.4725979409302803

Epoch: 6| Step: 4
Training loss: 2.6915134358758994
Validation loss: 2.467594094713463

Epoch: 6| Step: 5
Training loss: 2.1306918713881555
Validation loss: 2.488144654061033

Epoch: 6| Step: 6
Training loss: 3.315427386320998
Validation loss: 2.4944085093177377

Epoch: 6| Step: 7
Training loss: 2.5185220279180887
Validation loss: 2.517343715503425

Epoch: 6| Step: 8
Training loss: 3.0766246256602767
Validation loss: 2.546662362580457

Epoch: 6| Step: 9
Training loss: 2.325218280677195
Validation loss: 2.5895789944106156

Epoch: 6| Step: 10
Training loss: 2.269983138303268
Validation loss: 2.6424764128191383

Epoch: 6| Step: 11
Training loss: 2.611321368668803
Validation loss: 2.6944129844610316

Epoch: 6| Step: 12
Training loss: 2.853716144135367
Validation loss: 2.6970597058802697

Epoch: 6| Step: 13
Training loss: 2.8255174956177482
Validation loss: 2.751072355701058

Epoch: 350| Step: 0
Training loss: 2.3517395155680982
Validation loss: 2.8424513902320196

Epoch: 6| Step: 1
Training loss: 2.431978084327432
Validation loss: 2.7853062229520176

Epoch: 6| Step: 2
Training loss: 2.253242381684966
Validation loss: 2.7429048062631503

Epoch: 6| Step: 3
Training loss: 3.338004050607206
Validation loss: 2.6751756011855745

Epoch: 6| Step: 4
Training loss: 3.115161208486392
Validation loss: 2.612208236556029

Epoch: 6| Step: 5
Training loss: 3.028412109873186
Validation loss: 2.583017906226467

Epoch: 6| Step: 6
Training loss: 2.3322676086775136
Validation loss: 2.515165618875631

Epoch: 6| Step: 7
Training loss: 2.129553236336007
Validation loss: 2.4955554657581547

Epoch: 6| Step: 8
Training loss: 2.7097854145015363
Validation loss: 2.4716200121781364

Epoch: 6| Step: 9
Training loss: 2.3916610766444077
Validation loss: 2.4630671284355725

Epoch: 6| Step: 10
Training loss: 3.1783828495717987
Validation loss: 2.4620865303096418

Epoch: 6| Step: 11
Training loss: 2.979369274443592
Validation loss: 2.4668289432037933

Epoch: 6| Step: 12
Training loss: 2.8175425783340167
Validation loss: 2.4533630071705086

Epoch: 6| Step: 13
Training loss: 2.7860037649749487
Validation loss: 2.4556580087586424

Epoch: 351| Step: 0
Training loss: 2.8176471658908318
Validation loss: 2.459037391771141

Epoch: 6| Step: 1
Training loss: 2.4993359637520904
Validation loss: 2.4630655203486356

Epoch: 6| Step: 2
Training loss: 2.7939454831680304
Validation loss: 2.471281776045292

Epoch: 6| Step: 3
Training loss: 2.566088234345525
Validation loss: 2.4776583386954973

Epoch: 6| Step: 4
Training loss: 3.505675618660963
Validation loss: 2.4848035031495015

Epoch: 6| Step: 5
Training loss: 2.7356308151368074
Validation loss: 2.507173924271548

Epoch: 6| Step: 6
Training loss: 2.110736774696377
Validation loss: 2.5139388620292498

Epoch: 6| Step: 7
Training loss: 2.5234953221171366
Validation loss: 2.5336701867697635

Epoch: 6| Step: 8
Training loss: 2.712262448223478
Validation loss: 2.5725051041226212

Epoch: 6| Step: 9
Training loss: 2.8090341193577233
Validation loss: 2.557040226968027

Epoch: 6| Step: 10
Training loss: 2.396983348879313
Validation loss: 2.5366462098384854

Epoch: 6| Step: 11
Training loss: 3.0743847115106004
Validation loss: 2.5152132042090294

Epoch: 6| Step: 12
Training loss: 2.9705477441284267
Validation loss: 2.502745242934322

Epoch: 6| Step: 13
Training loss: 2.9534041661306816
Validation loss: 2.485168907016031

Epoch: 352| Step: 0
Training loss: 2.808483052625521
Validation loss: 2.474505808193586

Epoch: 6| Step: 1
Training loss: 2.127375116863009
Validation loss: 2.478864353726748

Epoch: 6| Step: 2
Training loss: 3.190654315869851
Validation loss: 2.4864296883663153

Epoch: 6| Step: 3
Training loss: 2.5919363276113865
Validation loss: 2.5049739440870527

Epoch: 6| Step: 4
Training loss: 2.2519654061080994
Validation loss: 2.4993430607589073

Epoch: 6| Step: 5
Training loss: 3.0206339452426776
Validation loss: 2.4969744206735753

Epoch: 6| Step: 6
Training loss: 2.934833371373
Validation loss: 2.4828429092214312

Epoch: 6| Step: 7
Training loss: 2.399027599594157
Validation loss: 2.467389975272885

Epoch: 6| Step: 8
Training loss: 2.7797617841790374
Validation loss: 2.4822667528792643

Epoch: 6| Step: 9
Training loss: 2.649502250421349
Validation loss: 2.5117912891219234

Epoch: 6| Step: 10
Training loss: 2.7336620164203786
Validation loss: 2.5333585212742027

Epoch: 6| Step: 11
Training loss: 2.872681885647189
Validation loss: 2.5495974134644865

Epoch: 6| Step: 12
Training loss: 2.7477577778592734
Validation loss: 2.5936723784717346

Epoch: 6| Step: 13
Training loss: 2.514872657631066
Validation loss: 2.6105918245364257

Epoch: 353| Step: 0
Training loss: 1.8559420654528478
Validation loss: 2.620045358865912

Epoch: 6| Step: 1
Training loss: 2.918677227411846
Validation loss: 2.671557725386585

Epoch: 6| Step: 2
Training loss: 3.3988150551319647
Validation loss: 2.7526294185808755

Epoch: 6| Step: 3
Training loss: 2.5748131026800585
Validation loss: 2.7710000881657595

Epoch: 6| Step: 4
Training loss: 3.336275248883988
Validation loss: 2.81181693766572

Epoch: 6| Step: 5
Training loss: 2.9904314670105245
Validation loss: 2.753916359671017

Epoch: 6| Step: 6
Training loss: 3.0724735953528755
Validation loss: 2.623941691601658

Epoch: 6| Step: 7
Training loss: 2.2161854711649336
Validation loss: 2.553495344382179

Epoch: 6| Step: 8
Training loss: 2.8205625470764186
Validation loss: 2.4982201208448696

Epoch: 6| Step: 9
Training loss: 2.2149651711095855
Validation loss: 2.4687893969361054

Epoch: 6| Step: 10
Training loss: 2.7242574047412624
Validation loss: 2.4674143908269066

Epoch: 6| Step: 11
Training loss: 2.937015737021877
Validation loss: 2.466558736032365

Epoch: 6| Step: 12
Training loss: 3.115875044328658
Validation loss: 2.472636498953263

Epoch: 6| Step: 13
Training loss: 2.300195797588734
Validation loss: 2.479880131961556

Epoch: 354| Step: 0
Training loss: 2.9961620258375214
Validation loss: 2.490060508685689

Epoch: 6| Step: 1
Training loss: 2.8538508182450344
Validation loss: 2.5087834555272592

Epoch: 6| Step: 2
Training loss: 2.662290996532822
Validation loss: 2.514899392059045

Epoch: 6| Step: 3
Training loss: 3.536049880577842
Validation loss: 2.559284004938625

Epoch: 6| Step: 4
Training loss: 2.592465001957973
Validation loss: 2.580824943786662

Epoch: 6| Step: 5
Training loss: 2.5353306032952334
Validation loss: 2.580987203013918

Epoch: 6| Step: 6
Training loss: 3.152550521554665
Validation loss: 2.552448433599248

Epoch: 6| Step: 7
Training loss: 2.610751491383652
Validation loss: 2.53474535566056

Epoch: 6| Step: 8
Training loss: 2.5074696529297755
Validation loss: 2.5100765165474668

Epoch: 6| Step: 9
Training loss: 2.652980902075732
Validation loss: 2.4944087837282884

Epoch: 6| Step: 10
Training loss: 1.8424433587942373
Validation loss: 2.483999195905505

Epoch: 6| Step: 11
Training loss: 2.6746513709939586
Validation loss: 2.4644172397863686

Epoch: 6| Step: 12
Training loss: 2.353555538108135
Validation loss: 2.483792205226865

Epoch: 6| Step: 13
Training loss: 3.317667259708631
Validation loss: 2.4652457610731973

Epoch: 355| Step: 0
Training loss: 2.6417537285771306
Validation loss: 2.5172059855309374

Epoch: 6| Step: 1
Training loss: 3.0520601412745836
Validation loss: 2.539252141113084

Epoch: 6| Step: 2
Training loss: 2.922577635791981
Validation loss: 2.58176561580002

Epoch: 6| Step: 3
Training loss: 2.342531930386254
Validation loss: 2.617466652139798

Epoch: 6| Step: 4
Training loss: 2.3937029004754597
Validation loss: 2.6420009761217074

Epoch: 6| Step: 5
Training loss: 2.8033234831114933
Validation loss: 2.645451106712744

Epoch: 6| Step: 6
Training loss: 2.8213578503318053
Validation loss: 2.583675599687708

Epoch: 6| Step: 7
Training loss: 2.8277562359395514
Validation loss: 2.593629731702177

Epoch: 6| Step: 8
Training loss: 2.8202151971236447
Validation loss: 2.6036812726567975

Epoch: 6| Step: 9
Training loss: 2.767232481614041
Validation loss: 2.6094224667715897

Epoch: 6| Step: 10
Training loss: 1.8714541922284977
Validation loss: 2.576257942850084

Epoch: 6| Step: 11
Training loss: 2.9678156938522617
Validation loss: 2.565441637133027

Epoch: 6| Step: 12
Training loss: 2.744263648265488
Validation loss: 2.5444269716278725

Epoch: 6| Step: 13
Training loss: 2.6473104503811076
Validation loss: 2.5211754118214404

Epoch: 356| Step: 0
Training loss: 2.4767579203138532
Validation loss: 2.501641485237756

Epoch: 6| Step: 1
Training loss: 2.6732654188413005
Validation loss: 2.4893319942759495

Epoch: 6| Step: 2
Training loss: 2.734589660937907
Validation loss: 2.4823569162162338

Epoch: 6| Step: 3
Training loss: 2.86379113542842
Validation loss: 2.472580168723432

Epoch: 6| Step: 4
Training loss: 3.3811809314153534
Validation loss: 2.4808754492348277

Epoch: 6| Step: 5
Training loss: 2.730748589273389
Validation loss: 2.465807630566637

Epoch: 6| Step: 6
Training loss: 2.4441562636845857
Validation loss: 2.4706695516745985

Epoch: 6| Step: 7
Training loss: 2.6430086291284525
Validation loss: 2.474365726901539

Epoch: 6| Step: 8
Training loss: 3.0154183272463966
Validation loss: 2.472340450737477

Epoch: 6| Step: 9
Training loss: 2.4189031271553665
Validation loss: 2.4732079454777876

Epoch: 6| Step: 10
Training loss: 2.986157429259512
Validation loss: 2.4950153145170177

Epoch: 6| Step: 11
Training loss: 2.462613168042736
Validation loss: 2.5180765653293693

Epoch: 6| Step: 12
Training loss: 2.3806156224561588
Validation loss: 2.557110561087061

Epoch: 6| Step: 13
Training loss: 2.2067525231906724
Validation loss: 2.553222291768816

Epoch: 357| Step: 0
Training loss: 2.831465123911083
Validation loss: 2.5644454734135835

Epoch: 6| Step: 1
Training loss: 2.6415856775169337
Validation loss: 2.559763734301462

Epoch: 6| Step: 2
Training loss: 2.801103517514574
Validation loss: 2.539590053479973

Epoch: 6| Step: 3
Training loss: 2.8771962608882684
Validation loss: 2.5140053124546857

Epoch: 6| Step: 4
Training loss: 2.5622434720289236
Validation loss: 2.4693035462067745

Epoch: 6| Step: 5
Training loss: 2.278660074825287
Validation loss: 2.4615683074466785

Epoch: 6| Step: 6
Training loss: 2.980046033567706
Validation loss: 2.456865549984696

Epoch: 6| Step: 7
Training loss: 2.748678930455853
Validation loss: 2.4571542802807875

Epoch: 6| Step: 8
Training loss: 2.884030795405142
Validation loss: 2.4503817592981934

Epoch: 6| Step: 9
Training loss: 2.368194768647578
Validation loss: 2.460497647126963

Epoch: 6| Step: 10
Training loss: 2.429167271696335
Validation loss: 2.4685177094707544

Epoch: 6| Step: 11
Training loss: 3.162115406881214
Validation loss: 2.496060912588526

Epoch: 6| Step: 12
Training loss: 2.403372393946297
Validation loss: 2.5373896644084035

Epoch: 6| Step: 13
Training loss: 2.9067492312624466
Validation loss: 2.5608757918314433

Epoch: 358| Step: 0
Training loss: 2.839270448600811
Validation loss: 2.5932212673189916

Epoch: 6| Step: 1
Training loss: 2.621410822557685
Validation loss: 2.6545904468152357

Epoch: 6| Step: 2
Training loss: 3.4930552656823695
Validation loss: 2.7245625205231976

Epoch: 6| Step: 3
Training loss: 3.1975037911924264
Validation loss: 2.70443542078836

Epoch: 6| Step: 4
Training loss: 2.566805780860035
Validation loss: 2.6602109789859605

Epoch: 6| Step: 5
Training loss: 1.981803549564581
Validation loss: 2.6351915440307043

Epoch: 6| Step: 6
Training loss: 2.964902613360828
Validation loss: 2.5969526264557414

Epoch: 6| Step: 7
Training loss: 2.539937311735545
Validation loss: 2.551062994767876

Epoch: 6| Step: 8
Training loss: 2.75566575135943
Validation loss: 2.5060909990535225

Epoch: 6| Step: 9
Training loss: 2.9159897881683587
Validation loss: 2.474005058810173

Epoch: 6| Step: 10
Training loss: 2.4245862981534816
Validation loss: 2.464965839130559

Epoch: 6| Step: 11
Training loss: 2.555047432744731
Validation loss: 2.462542122301087

Epoch: 6| Step: 12
Training loss: 2.241456660345026
Validation loss: 2.4665947745116887

Epoch: 6| Step: 13
Training loss: 2.676168995628651
Validation loss: 2.4629496510184543

Epoch: 359| Step: 0
Training loss: 2.589944828874501
Validation loss: 2.4617815634456472

Epoch: 6| Step: 1
Training loss: 3.008011293653836
Validation loss: 2.4660536991648594

Epoch: 6| Step: 2
Training loss: 2.4473468739630233
Validation loss: 2.4621763810123127

Epoch: 6| Step: 3
Training loss: 2.6311396596067858
Validation loss: 2.47894278308453

Epoch: 6| Step: 4
Training loss: 2.81420736411273
Validation loss: 2.486439091035806

Epoch: 6| Step: 5
Training loss: 2.1591816750754083
Validation loss: 2.5208713125569506

Epoch: 6| Step: 6
Training loss: 2.553448764625383
Validation loss: 2.5364467811527756

Epoch: 6| Step: 7
Training loss: 2.9054441257632417
Validation loss: 2.568987573744832

Epoch: 6| Step: 8
Training loss: 2.8157406257148883
Validation loss: 2.5897265581459044

Epoch: 6| Step: 9
Training loss: 2.6003148291785645
Validation loss: 2.627481687951528

Epoch: 6| Step: 10
Training loss: 2.142836382174968
Validation loss: 2.607380672318404

Epoch: 6| Step: 11
Training loss: 2.9226123878921815
Validation loss: 2.6691449868554282

Epoch: 6| Step: 12
Training loss: 2.7798769701347745
Validation loss: 2.6903537538010545

Epoch: 6| Step: 13
Training loss: 3.1505560550664264
Validation loss: 2.713635340970682

Epoch: 360| Step: 0
Training loss: 2.95918902706062
Validation loss: 2.7488650024130012

Epoch: 6| Step: 1
Training loss: 2.7174190025576523
Validation loss: 2.827957604326044

Epoch: 6| Step: 2
Training loss: 3.071536065435262
Validation loss: 2.847759517339668

Epoch: 6| Step: 3
Training loss: 3.096887096146596
Validation loss: 2.884760660815462

Epoch: 6| Step: 4
Training loss: 2.3645619350815124
Validation loss: 2.8977757503293162

Epoch: 6| Step: 5
Training loss: 3.054897759657506
Validation loss: 2.910723897791493

Epoch: 6| Step: 6
Training loss: 3.2950305570305622
Validation loss: 2.8680070826316184

Epoch: 6| Step: 7
Training loss: 2.9156501270123227
Validation loss: 2.7593154156240165

Epoch: 6| Step: 8
Training loss: 2.6133256802965845
Validation loss: 2.631235632407677

Epoch: 6| Step: 9
Training loss: 3.165044787483252
Validation loss: 2.55912276185262

Epoch: 6| Step: 10
Training loss: 1.8430561764538864
Validation loss: 2.5051264858343054

Epoch: 6| Step: 11
Training loss: 2.482752720165366
Validation loss: 2.4804369335864833

Epoch: 6| Step: 12
Training loss: 2.693958594793436
Validation loss: 2.4800528285717625

Epoch: 6| Step: 13
Training loss: 2.5479509386163035
Validation loss: 2.4635038314196755

Epoch: 361| Step: 0
Training loss: 2.9082105033171177
Validation loss: 2.467937345594217

Epoch: 6| Step: 1
Training loss: 2.1549904503135004
Validation loss: 2.478566908336718

Epoch: 6| Step: 2
Training loss: 3.0054744997061262
Validation loss: 2.4705406606691995

Epoch: 6| Step: 3
Training loss: 2.3983389868370297
Validation loss: 2.4758173898667244

Epoch: 6| Step: 4
Training loss: 3.0915058358063483
Validation loss: 2.4764007332303617

Epoch: 6| Step: 5
Training loss: 2.848829825581386
Validation loss: 2.4817781028068215

Epoch: 6| Step: 6
Training loss: 2.4478553493747137
Validation loss: 2.4991174729625225

Epoch: 6| Step: 7
Training loss: 2.475545873073238
Validation loss: 2.5392591608841464

Epoch: 6| Step: 8
Training loss: 2.7791757456694572
Validation loss: 2.576014718374625

Epoch: 6| Step: 9
Training loss: 2.9199339595276688
Validation loss: 2.5990969502788626

Epoch: 6| Step: 10
Training loss: 2.550592996797988
Validation loss: 2.6269067547550433

Epoch: 6| Step: 11
Training loss: 3.1706991788043695
Validation loss: 2.5956968652803183

Epoch: 6| Step: 12
Training loss: 2.4815124718811723
Validation loss: 2.6149475434909055

Epoch: 6| Step: 13
Training loss: 2.410904482246418
Validation loss: 2.6407838673988504

Epoch: 362| Step: 0
Training loss: 2.684448639078351
Validation loss: 2.6622521154060235

Epoch: 6| Step: 1
Training loss: 2.6408990119654607
Validation loss: 2.672875007631685

Epoch: 6| Step: 2
Training loss: 2.5461347943603156
Validation loss: 2.679772872088661

Epoch: 6| Step: 3
Training loss: 2.7376394785007037
Validation loss: 2.707923771738792

Epoch: 6| Step: 4
Training loss: 2.634921895702766
Validation loss: 2.707549178679445

Epoch: 6| Step: 5
Training loss: 3.1200180014066525
Validation loss: 2.666617647484445

Epoch: 6| Step: 6
Training loss: 2.9045812266230016
Validation loss: 2.669157603593733

Epoch: 6| Step: 7
Training loss: 2.803487877125771
Validation loss: 2.6299800267282456

Epoch: 6| Step: 8
Training loss: 3.0681292121564554
Validation loss: 2.60700564449525

Epoch: 6| Step: 9
Training loss: 2.666450750033827
Validation loss: 2.5664962303515417

Epoch: 6| Step: 10
Training loss: 2.57504486118978
Validation loss: 2.5309428977342274

Epoch: 6| Step: 11
Training loss: 1.8645876097674496
Validation loss: 2.4927558231630744

Epoch: 6| Step: 12
Training loss: 2.7378606758977786
Validation loss: 2.4883874135271085

Epoch: 6| Step: 13
Training loss: 3.0306778200612534
Validation loss: 2.47045919645868

Epoch: 363| Step: 0
Training loss: 2.096312819047466
Validation loss: 2.465334371490762

Epoch: 6| Step: 1
Training loss: 2.413304873591986
Validation loss: 2.4680351685577264

Epoch: 6| Step: 2
Training loss: 2.836858426466066
Validation loss: 2.4585472368090118

Epoch: 6| Step: 3
Training loss: 2.9392136789932866
Validation loss: 2.4512003573844936

Epoch: 6| Step: 4
Training loss: 2.4358117541535025
Validation loss: 2.4559770199196063

Epoch: 6| Step: 5
Training loss: 2.4891892338042547
Validation loss: 2.4619455143318594

Epoch: 6| Step: 6
Training loss: 2.4121730286388607
Validation loss: 2.464845925851448

Epoch: 6| Step: 7
Training loss: 2.990848729804427
Validation loss: 2.4613739944361273

Epoch: 6| Step: 8
Training loss: 2.7882813286667734
Validation loss: 2.487461663883087

Epoch: 6| Step: 9
Training loss: 2.9466099802954178
Validation loss: 2.48118147167123

Epoch: 6| Step: 10
Training loss: 2.592801943404974
Validation loss: 2.5312936126585734

Epoch: 6| Step: 11
Training loss: 2.788602390324013
Validation loss: 2.566472321871298

Epoch: 6| Step: 12
Training loss: 3.105159182683665
Validation loss: 2.6121652937384847

Epoch: 6| Step: 13
Training loss: 3.2727628390469987
Validation loss: 2.642620817104756

Epoch: 364| Step: 0
Training loss: 3.1071401260940252
Validation loss: 2.647992490827492

Epoch: 6| Step: 1
Training loss: 2.3774162850548173
Validation loss: 2.566516351859578

Epoch: 6| Step: 2
Training loss: 2.734656270410847
Validation loss: 2.5327264041800848

Epoch: 6| Step: 3
Training loss: 2.4271189369133395
Validation loss: 2.4826233882254263

Epoch: 6| Step: 4
Training loss: 2.1831492072160383
Validation loss: 2.4750331293074166

Epoch: 6| Step: 5
Training loss: 2.6982397133991554
Validation loss: 2.450258497773843

Epoch: 6| Step: 6
Training loss: 3.044203775720803
Validation loss: 2.44061853576731

Epoch: 6| Step: 7
Training loss: 2.4579299229377956
Validation loss: 2.438291873832447

Epoch: 6| Step: 8
Training loss: 2.7624458963610974
Validation loss: 2.443579302139764

Epoch: 6| Step: 9
Training loss: 3.144970975660052
Validation loss: 2.4457489476519494

Epoch: 6| Step: 10
Training loss: 2.8078049359779604
Validation loss: 2.463547877498324

Epoch: 6| Step: 11
Training loss: 3.0475253462578427
Validation loss: 2.4769411732738327

Epoch: 6| Step: 12
Training loss: 2.5316398226244194
Validation loss: 2.4869604914811845

Epoch: 6| Step: 13
Training loss: 2.380292717059034
Validation loss: 2.4882094401098023

Epoch: 365| Step: 0
Training loss: 2.5506308541935296
Validation loss: 2.510009599525219

Epoch: 6| Step: 1
Training loss: 2.2024829551219094
Validation loss: 2.535890799278722

Epoch: 6| Step: 2
Training loss: 3.4629302821333288
Validation loss: 2.5462580973706923

Epoch: 6| Step: 3
Training loss: 2.5756403191714203
Validation loss: 2.550796698443837

Epoch: 6| Step: 4
Training loss: 2.5982361569277623
Validation loss: 2.5508542616916428

Epoch: 6| Step: 5
Training loss: 2.696976742201095
Validation loss: 2.544994777268979

Epoch: 6| Step: 6
Training loss: 2.792603539551178
Validation loss: 2.5500783186822362

Epoch: 6| Step: 7
Training loss: 2.6164726533661664
Validation loss: 2.5527972436855944

Epoch: 6| Step: 8
Training loss: 2.432584060204485
Validation loss: 2.5583738466580774

Epoch: 6| Step: 9
Training loss: 2.7967859179412855
Validation loss: 2.550550138311644

Epoch: 6| Step: 10
Training loss: 2.51776041890567
Validation loss: 2.585796580750139

Epoch: 6| Step: 11
Training loss: 3.058227361216871
Validation loss: 2.5919040298878695

Epoch: 6| Step: 12
Training loss: 2.522007209120149
Validation loss: 2.599414740893505

Epoch: 6| Step: 13
Training loss: 2.2525397907091516
Validation loss: 2.5972366767647634

Epoch: 366| Step: 0
Training loss: 2.212787191426463
Validation loss: 2.575704169510736

Epoch: 6| Step: 1
Training loss: 2.9466611167659824
Validation loss: 2.5728117385146314

Epoch: 6| Step: 2
Training loss: 2.4604695193056405
Validation loss: 2.5350137851268513

Epoch: 6| Step: 3
Training loss: 3.11482474285648
Validation loss: 2.5309159840749627

Epoch: 6| Step: 4
Training loss: 2.3233977590829387
Validation loss: 2.526286367157752

Epoch: 6| Step: 5
Training loss: 2.394828740568994
Validation loss: 2.514687040936466

Epoch: 6| Step: 6
Training loss: 2.6918487849397197
Validation loss: 2.5064229401099922

Epoch: 6| Step: 7
Training loss: 2.3410781890182926
Validation loss: 2.4996168971062906

Epoch: 6| Step: 8
Training loss: 2.5922309379778117
Validation loss: 2.512366419558203

Epoch: 6| Step: 9
Training loss: 2.5609993611207975
Validation loss: 2.504271878288334

Epoch: 6| Step: 10
Training loss: 3.0484794891453255
Validation loss: 2.5273858923187307

Epoch: 6| Step: 11
Training loss: 2.8178403380398995
Validation loss: 2.542429518200305

Epoch: 6| Step: 12
Training loss: 2.833322038814996
Validation loss: 2.5416728812601845

Epoch: 6| Step: 13
Training loss: 2.870267538965533
Validation loss: 2.546757115350436

Epoch: 367| Step: 0
Training loss: 2.5863624062316575
Validation loss: 2.5668678005385432

Epoch: 6| Step: 1
Training loss: 2.2518394156976105
Validation loss: 2.539569987150838

Epoch: 6| Step: 2
Training loss: 2.4842360355690682
Validation loss: 2.5481307950437455

Epoch: 6| Step: 3
Training loss: 3.091356681096625
Validation loss: 2.5444942278091474

Epoch: 6| Step: 4
Training loss: 2.5389956421486053
Validation loss: 2.5459023908569653

Epoch: 6| Step: 5
Training loss: 1.5313469992296196
Validation loss: 2.5342873428982156

Epoch: 6| Step: 6
Training loss: 2.6209623983248247
Validation loss: 2.5221512523297163

Epoch: 6| Step: 7
Training loss: 2.6547357169763144
Validation loss: 2.5174873605728925

Epoch: 6| Step: 8
Training loss: 3.327436635641464
Validation loss: 2.5320034457865637

Epoch: 6| Step: 9
Training loss: 3.373535968991887
Validation loss: 2.5309168916600475

Epoch: 6| Step: 10
Training loss: 2.7687018568964032
Validation loss: 2.5663936665439486

Epoch: 6| Step: 11
Training loss: 2.2069521729472883
Validation loss: 2.5826067827369066

Epoch: 6| Step: 12
Training loss: 2.6710948139644892
Validation loss: 2.581979175037719

Epoch: 6| Step: 13
Training loss: 2.7880994485771575
Validation loss: 2.5720926899814534

Epoch: 368| Step: 0
Training loss: 2.6439803435710223
Validation loss: 2.553175261712637

Epoch: 6| Step: 1
Training loss: 1.9891476645146022
Validation loss: 2.5547939064003544

Epoch: 6| Step: 2
Training loss: 2.4613958991472433
Validation loss: 2.557241479217323

Epoch: 6| Step: 3
Training loss: 3.447563975448045
Validation loss: 2.529538585677514

Epoch: 6| Step: 4
Training loss: 2.673797807876883
Validation loss: 2.539818577170691

Epoch: 6| Step: 5
Training loss: 2.516152652348795
Validation loss: 2.569678896652697

Epoch: 6| Step: 6
Training loss: 2.7336784129456912
Validation loss: 2.5642780685034974

Epoch: 6| Step: 7
Training loss: 3.0104471136927184
Validation loss: 2.556065511144888

Epoch: 6| Step: 8
Training loss: 2.344472544874833
Validation loss: 2.5464152083334324

Epoch: 6| Step: 9
Training loss: 2.6363699675277696
Validation loss: 2.547335703501943

Epoch: 6| Step: 10
Training loss: 2.8535166276307273
Validation loss: 2.524969048332186

Epoch: 6| Step: 11
Training loss: 2.8561860526040395
Validation loss: 2.513307492811579

Epoch: 6| Step: 12
Training loss: 2.4039112962552656
Validation loss: 2.5191618373591544

Epoch: 6| Step: 13
Training loss: 2.0527710770684178
Validation loss: 2.5179522019795573

Epoch: 369| Step: 0
Training loss: 2.856800358543491
Validation loss: 2.5194267295149517

Epoch: 6| Step: 1
Training loss: 2.5993558672645456
Validation loss: 2.518015912619798

Epoch: 6| Step: 2
Training loss: 2.4698090032330784
Validation loss: 2.548011591097121

Epoch: 6| Step: 3
Training loss: 2.804191949361007
Validation loss: 2.542559991392703

Epoch: 6| Step: 4
Training loss: 2.9676283474220373
Validation loss: 2.541596665032839

Epoch: 6| Step: 5
Training loss: 2.8422067667773128
Validation loss: 2.547221323485513

Epoch: 6| Step: 6
Training loss: 2.323139356764304
Validation loss: 2.534520193426416

Epoch: 6| Step: 7
Training loss: 2.9676386308947897
Validation loss: 2.524505142508208

Epoch: 6| Step: 8
Training loss: 2.223866754890198
Validation loss: 2.487557762672081

Epoch: 6| Step: 9
Training loss: 2.55718517405453
Validation loss: 2.4782857600911434

Epoch: 6| Step: 10
Training loss: 2.708475451530881
Validation loss: 2.449757060675154

Epoch: 6| Step: 11
Training loss: 2.219883588883291
Validation loss: 2.4521880812938246

Epoch: 6| Step: 12
Training loss: 2.9069414854351048
Validation loss: 2.4583537075004207

Epoch: 6| Step: 13
Training loss: 2.5794074365726782
Validation loss: 2.455337364927898

Epoch: 370| Step: 0
Training loss: 2.105999768162033
Validation loss: 2.4569166111633907

Epoch: 6| Step: 1
Training loss: 2.95291782843293
Validation loss: 2.4481288042136597

Epoch: 6| Step: 2
Training loss: 2.8598015472277734
Validation loss: 2.469522418444812

Epoch: 6| Step: 3
Training loss: 3.0085627425227153
Validation loss: 2.497836088103745

Epoch: 6| Step: 4
Training loss: 2.5925829916226264
Validation loss: 2.515512994754134

Epoch: 6| Step: 5
Training loss: 2.2026866720290195
Validation loss: 2.5590784203265997

Epoch: 6| Step: 6
Training loss: 2.3043459881704007
Validation loss: 2.6326532499215745

Epoch: 6| Step: 7
Training loss: 2.5493772419449474
Validation loss: 2.7100966254899963

Epoch: 6| Step: 8
Training loss: 2.4475370288576626
Validation loss: 2.7263139081988315

Epoch: 6| Step: 9
Training loss: 2.3942193828567735
Validation loss: 2.80627044093659

Epoch: 6| Step: 10
Training loss: 2.6406056781490768
Validation loss: 2.8506910969668975

Epoch: 6| Step: 11
Training loss: 3.0247889610635927
Validation loss: 2.9326638020009903

Epoch: 6| Step: 12
Training loss: 3.456240530156274
Validation loss: 2.9191439375997295

Epoch: 6| Step: 13
Training loss: 3.623429846251754
Validation loss: 2.8345183699827827

Epoch: 371| Step: 0
Training loss: 3.5404174097386685
Validation loss: 2.669791723410446

Epoch: 6| Step: 1
Training loss: 3.3023436691396073
Validation loss: 2.544574934290653

Epoch: 6| Step: 2
Training loss: 2.6750452519092014
Validation loss: 2.489513874222016

Epoch: 6| Step: 3
Training loss: 2.656126759979988
Validation loss: 2.467918211217223

Epoch: 6| Step: 4
Training loss: 2.7207374762278667
Validation loss: 2.476308245223604

Epoch: 6| Step: 5
Training loss: 2.505962794868742
Validation loss: 2.476266228548946

Epoch: 6| Step: 6
Training loss: 2.528163770984285
Validation loss: 2.522828268614364

Epoch: 6| Step: 7
Training loss: 2.6279373083780246
Validation loss: 2.5421100863761397

Epoch: 6| Step: 8
Training loss: 2.4372979104802006
Validation loss: 2.5773055787081587

Epoch: 6| Step: 9
Training loss: 2.359894954153916
Validation loss: 2.611780481592162

Epoch: 6| Step: 10
Training loss: 3.154371854758995
Validation loss: 2.5717531838170786

Epoch: 6| Step: 11
Training loss: 2.585520362055294
Validation loss: 2.5427959064514667

Epoch: 6| Step: 12
Training loss: 2.8157992191587002
Validation loss: 2.4764400602138705

Epoch: 6| Step: 13
Training loss: 3.197587749121215
Validation loss: 2.4732077081044057

Epoch: 372| Step: 0
Training loss: 2.4999236095201547
Validation loss: 2.4923524213406156

Epoch: 6| Step: 1
Training loss: 1.9977138088797206
Validation loss: 2.572205127819998

Epoch: 6| Step: 2
Training loss: 2.5779099808240353
Validation loss: 2.6811527687680616

Epoch: 6| Step: 3
Training loss: 2.8499801635051862
Validation loss: 2.7723997821543054

Epoch: 6| Step: 4
Training loss: 3.2793524205204956
Validation loss: 2.9420261156707603

Epoch: 6| Step: 5
Training loss: 3.0958479116378097
Validation loss: 2.9860025726864006

Epoch: 6| Step: 6
Training loss: 2.030353054670869
Validation loss: 2.926519706995786

Epoch: 6| Step: 7
Training loss: 2.575367973479134
Validation loss: 2.9252678829733605

Epoch: 6| Step: 8
Training loss: 2.8339914417770267
Validation loss: 2.831198060241269

Epoch: 6| Step: 9
Training loss: 2.7270249463721425
Validation loss: 2.7366993456080437

Epoch: 6| Step: 10
Training loss: 2.925529112602382
Validation loss: 2.636839376627688

Epoch: 6| Step: 11
Training loss: 2.6264477325182756
Validation loss: 2.5229076938085657

Epoch: 6| Step: 12
Training loss: 2.86580181678716
Validation loss: 2.4751814421778735

Epoch: 6| Step: 13
Training loss: 3.3813115197189076
Validation loss: 2.440020815108094

Epoch: 373| Step: 0
Training loss: 2.270180482957559
Validation loss: 2.4400970206378916

Epoch: 6| Step: 1
Training loss: 2.2609471930537945
Validation loss: 2.443525933190577

Epoch: 6| Step: 2
Training loss: 2.624184981478364
Validation loss: 2.4551709836022386

Epoch: 6| Step: 3
Training loss: 2.691563484017212
Validation loss: 2.457580827350153

Epoch: 6| Step: 4
Training loss: 3.3405543948813547
Validation loss: 2.454794485003919

Epoch: 6| Step: 5
Training loss: 3.1672491909769493
Validation loss: 2.473664762028938

Epoch: 6| Step: 6
Training loss: 2.9819311551411554
Validation loss: 2.4502765375558333

Epoch: 6| Step: 7
Training loss: 3.0051371776987335
Validation loss: 2.473803810427653

Epoch: 6| Step: 8
Training loss: 1.7936113656198596
Validation loss: 2.462542627212483

Epoch: 6| Step: 9
Training loss: 3.294243218629111
Validation loss: 2.462198344180667

Epoch: 6| Step: 10
Training loss: 2.4719198615901816
Validation loss: 2.466539902770873

Epoch: 6| Step: 11
Training loss: 2.5886386006330624
Validation loss: 2.481789781712681

Epoch: 6| Step: 12
Training loss: 2.635777193722472
Validation loss: 2.503695998387933

Epoch: 6| Step: 13
Training loss: 2.9067679323119164
Validation loss: 2.537691449845094

Epoch: 374| Step: 0
Training loss: 2.883650329745818
Validation loss: 2.5671736193267

Epoch: 6| Step: 1
Training loss: 2.747082983829201
Validation loss: 2.6071060255443235

Epoch: 6| Step: 2
Training loss: 3.0819999973661014
Validation loss: 2.617057758630189

Epoch: 6| Step: 3
Training loss: 2.8686180599680067
Validation loss: 2.606420390497354

Epoch: 6| Step: 4
Training loss: 2.560371165935661
Validation loss: 2.6196863153296452

Epoch: 6| Step: 5
Training loss: 2.2275723492895985
Validation loss: 2.5861965607700736

Epoch: 6| Step: 6
Training loss: 2.2537401690191983
Validation loss: 2.5782946956169903

Epoch: 6| Step: 7
Training loss: 3.0611273355702138
Validation loss: 2.573795487030207

Epoch: 6| Step: 8
Training loss: 2.275902529260177
Validation loss: 2.550979373142692

Epoch: 6| Step: 9
Training loss: 2.1913092008646213
Validation loss: 2.5717346703354753

Epoch: 6| Step: 10
Training loss: 3.0630223354281214
Validation loss: 2.5525321105458763

Epoch: 6| Step: 11
Training loss: 2.9161062156264865
Validation loss: 2.5760741488291132

Epoch: 6| Step: 12
Training loss: 2.056461279313727
Validation loss: 2.559114270875009

Epoch: 6| Step: 13
Training loss: 3.152522236853758
Validation loss: 2.5680707120729767

Epoch: 375| Step: 0
Training loss: 2.2620024033794235
Validation loss: 2.5395111136975914

Epoch: 6| Step: 1
Training loss: 2.6900264486267647
Validation loss: 2.5143277081715025

Epoch: 6| Step: 2
Training loss: 2.2470399671326726
Validation loss: 2.494036941042835

Epoch: 6| Step: 3
Training loss: 2.7706039352872596
Validation loss: 2.4957420605521623

Epoch: 6| Step: 4
Training loss: 2.184706402744457
Validation loss: 2.4959384710013723

Epoch: 6| Step: 5
Training loss: 3.1184952748458414
Validation loss: 2.4901501623042077

Epoch: 6| Step: 6
Training loss: 2.554308475293614
Validation loss: 2.5045915011867943

Epoch: 6| Step: 7
Training loss: 2.1623895561812825
Validation loss: 2.4946022438755913

Epoch: 6| Step: 8
Training loss: 3.187407249148409
Validation loss: 2.5125098298309636

Epoch: 6| Step: 9
Training loss: 2.342573251952942
Validation loss: 2.5053746280801166

Epoch: 6| Step: 10
Training loss: 2.5667417820759635
Validation loss: 2.522355092123227

Epoch: 6| Step: 11
Training loss: 2.6958343442967054
Validation loss: 2.547583092979702

Epoch: 6| Step: 12
Training loss: 3.2621833150635635
Validation loss: 2.546456329804019

Epoch: 6| Step: 13
Training loss: 2.504770305404652
Validation loss: 2.546329450179119

Epoch: 376| Step: 0
Training loss: 2.8349449585645963
Validation loss: 2.559792496636356

Epoch: 6| Step: 1
Training loss: 2.9305840099654765
Validation loss: 2.559487086009362

Epoch: 6| Step: 2
Training loss: 3.091267678425823
Validation loss: 2.5601476521397557

Epoch: 6| Step: 3
Training loss: 2.5013645262952386
Validation loss: 2.5504931974269573

Epoch: 6| Step: 4
Training loss: 2.219410113070588
Validation loss: 2.545471098395485

Epoch: 6| Step: 5
Training loss: 2.759953173226332
Validation loss: 2.5116990121701175

Epoch: 6| Step: 6
Training loss: 2.5546164779823326
Validation loss: 2.507504056502908

Epoch: 6| Step: 7
Training loss: 2.905499761405151
Validation loss: 2.5069627154896486

Epoch: 6| Step: 8
Training loss: 2.6100024536822835
Validation loss: 2.4860147977448346

Epoch: 6| Step: 9
Training loss: 2.769226487881864
Validation loss: 2.4897741199250705

Epoch: 6| Step: 10
Training loss: 1.9188726280366224
Validation loss: 2.4966930236382447

Epoch: 6| Step: 11
Training loss: 2.270562520342252
Validation loss: 2.4957330324243543

Epoch: 6| Step: 12
Training loss: 2.9145533580388383
Validation loss: 2.508733253811631

Epoch: 6| Step: 13
Training loss: 2.561880269358107
Validation loss: 2.509216547820802

Epoch: 377| Step: 0
Training loss: 2.492794524978384
Validation loss: 2.5204170498265954

Epoch: 6| Step: 1
Training loss: 2.461283147849251
Validation loss: 2.505672407160393

Epoch: 6| Step: 2
Training loss: 2.4684756162728334
Validation loss: 2.5229485374357408

Epoch: 6| Step: 3
Training loss: 2.86722109408538
Validation loss: 2.5170679363602604

Epoch: 6| Step: 4
Training loss: 3.429522603791524
Validation loss: 2.524426577970161

Epoch: 6| Step: 5
Training loss: 2.83277216197192
Validation loss: 2.50982476923625

Epoch: 6| Step: 6
Training loss: 2.271377101736622
Validation loss: 2.5024438910663314

Epoch: 6| Step: 7
Training loss: 2.7755366588295742
Validation loss: 2.5028717200872674

Epoch: 6| Step: 8
Training loss: 2.307458485470629
Validation loss: 2.5141953548721823

Epoch: 6| Step: 9
Training loss: 2.480297268924902
Validation loss: 2.506546477351532

Epoch: 6| Step: 10
Training loss: 2.6025224810388754
Validation loss: 2.541154486741859

Epoch: 6| Step: 11
Training loss: 3.1602657945128243
Validation loss: 2.5616177696692564

Epoch: 6| Step: 12
Training loss: 2.3609609768077044
Validation loss: 2.5492776820879817

Epoch: 6| Step: 13
Training loss: 1.197893335972137
Validation loss: 2.5336622084865823

Epoch: 378| Step: 0
Training loss: 2.543594119382834
Validation loss: 2.536900820171323

Epoch: 6| Step: 1
Training loss: 2.6496347067633055
Validation loss: 2.516829701364941

Epoch: 6| Step: 2
Training loss: 2.1352158862989747
Validation loss: 2.5247816628418422

Epoch: 6| Step: 3
Training loss: 2.910439373811592
Validation loss: 2.5200252388603257

Epoch: 6| Step: 4
Training loss: 2.3158705608189276
Validation loss: 2.4915369808631276

Epoch: 6| Step: 5
Training loss: 2.736777596109188
Validation loss: 2.5044464459812685

Epoch: 6| Step: 6
Training loss: 2.2424793651571284
Validation loss: 2.4922462137831882

Epoch: 6| Step: 7
Training loss: 2.5088082591592338
Validation loss: 2.4935335298350374

Epoch: 6| Step: 8
Training loss: 2.5032367733730054
Validation loss: 2.5075694250585454

Epoch: 6| Step: 9
Training loss: 3.311722430249415
Validation loss: 2.5173813895848056

Epoch: 6| Step: 10
Training loss: 1.9710124503661288
Validation loss: 2.550447785633786

Epoch: 6| Step: 11
Training loss: 3.112963881643661
Validation loss: 2.6097880756105982

Epoch: 6| Step: 12
Training loss: 2.773697789832427
Validation loss: 2.6549560647817003

Epoch: 6| Step: 13
Training loss: 2.8054770205829165
Validation loss: 2.637183709875576

Epoch: 379| Step: 0
Training loss: 2.671793261610652
Validation loss: 2.6220069977672793

Epoch: 6| Step: 1
Training loss: 2.421685389818071
Validation loss: 2.5616482195151713

Epoch: 6| Step: 2
Training loss: 2.503822265740028
Validation loss: 2.5211570495960416

Epoch: 6| Step: 3
Training loss: 2.6482424143730543
Validation loss: 2.4629808512670217

Epoch: 6| Step: 4
Training loss: 3.0856791327759954
Validation loss: 2.4493274722486054

Epoch: 6| Step: 5
Training loss: 2.5375233841744067
Validation loss: 2.4409275341314007

Epoch: 6| Step: 6
Training loss: 2.5793483721479626
Validation loss: 2.4313181423160986

Epoch: 6| Step: 7
Training loss: 2.6537090040679825
Validation loss: 2.4311566856337645

Epoch: 6| Step: 8
Training loss: 3.101080023379172
Validation loss: 2.4421697069478228

Epoch: 6| Step: 9
Training loss: 2.5851505614950447
Validation loss: 2.4346149083572652

Epoch: 6| Step: 10
Training loss: 2.6332482223598905
Validation loss: 2.4373146851223093

Epoch: 6| Step: 11
Training loss: 2.9998537663741054
Validation loss: 2.461152717905422

Epoch: 6| Step: 12
Training loss: 2.4994230558330917
Validation loss: 2.4484328393171753

Epoch: 6| Step: 13
Training loss: 1.8901379801322968
Validation loss: 2.4629388258190064

Epoch: 380| Step: 0
Training loss: 2.659079267866118
Validation loss: 2.473555792208659

Epoch: 6| Step: 1
Training loss: 2.381953750705859
Validation loss: 2.4987862912002448

Epoch: 6| Step: 2
Training loss: 2.733607854858536
Validation loss: 2.5294633938585203

Epoch: 6| Step: 3
Training loss: 2.2351463426985734
Validation loss: 2.5402927827625628

Epoch: 6| Step: 4
Training loss: 2.4995154864965987
Validation loss: 2.56503327698938

Epoch: 6| Step: 5
Training loss: 2.185065304197098
Validation loss: 2.5686867006149146

Epoch: 6| Step: 6
Training loss: 2.802046103153333
Validation loss: 2.576765401100776

Epoch: 6| Step: 7
Training loss: 2.74725013575587
Validation loss: 2.569283042464233

Epoch: 6| Step: 8
Training loss: 2.938543256191043
Validation loss: 2.5671269891642057

Epoch: 6| Step: 9
Training loss: 2.86296881289056
Validation loss: 2.555308548695312

Epoch: 6| Step: 10
Training loss: 2.363105099000749
Validation loss: 2.567804915601427

Epoch: 6| Step: 11
Training loss: 3.015662000359961
Validation loss: 2.60734313056914

Epoch: 6| Step: 12
Training loss: 2.0289849196654313
Validation loss: 2.5800072772807465

Epoch: 6| Step: 13
Training loss: 2.795259232757171
Validation loss: 2.5795869790704646

Epoch: 381| Step: 0
Training loss: 2.082149080016211
Validation loss: 2.5639257388971104

Epoch: 6| Step: 1
Training loss: 2.44493212194165
Validation loss: 2.55058612581896

Epoch: 6| Step: 2
Training loss: 3.0309443368863147
Validation loss: 2.490153536014275

Epoch: 6| Step: 3
Training loss: 2.423498089719743
Validation loss: 2.492193104192493

Epoch: 6| Step: 4
Training loss: 2.737928773230808
Validation loss: 2.4778258824952863

Epoch: 6| Step: 5
Training loss: 2.7927693329158068
Validation loss: 2.469339751226857

Epoch: 6| Step: 6
Training loss: 3.1351364534362838
Validation loss: 2.4579246129782026

Epoch: 6| Step: 7
Training loss: 2.3855773893846766
Validation loss: 2.4558639561581757

Epoch: 6| Step: 8
Training loss: 2.625977561215643
Validation loss: 2.4674967737458657

Epoch: 6| Step: 9
Training loss: 2.471199076334792
Validation loss: 2.4546585415607547

Epoch: 6| Step: 10
Training loss: 2.2705962264371755
Validation loss: 2.4704947411667653

Epoch: 6| Step: 11
Training loss: 2.393138387049335
Validation loss: 2.4842853964674263

Epoch: 6| Step: 12
Training loss: 2.907064016229778
Validation loss: 2.4884104176890984

Epoch: 6| Step: 13
Training loss: 3.0153247110548715
Validation loss: 2.519757653446145

Epoch: 382| Step: 0
Training loss: 2.5082861907516807
Validation loss: 2.5221582231341695

Epoch: 6| Step: 1
Training loss: 2.678329524061449
Validation loss: 2.5450097853819806

Epoch: 6| Step: 2
Training loss: 2.7561487469056494
Validation loss: 2.5826463953714365

Epoch: 6| Step: 3
Training loss: 2.4631268163411533
Validation loss: 2.6305259068572706

Epoch: 6| Step: 4
Training loss: 2.7539663321792545
Validation loss: 2.6554370058214523

Epoch: 6| Step: 5
Training loss: 2.807423736541925
Validation loss: 2.6684884413324856

Epoch: 6| Step: 6
Training loss: 2.450173515870567
Validation loss: 2.6541711469504823

Epoch: 6| Step: 7
Training loss: 2.5815702595286485
Validation loss: 2.618556805569361

Epoch: 6| Step: 8
Training loss: 2.4925347448010684
Validation loss: 2.6312362204040283

Epoch: 6| Step: 9
Training loss: 2.838167181014483
Validation loss: 2.5949514042771895

Epoch: 6| Step: 10
Training loss: 2.7196122479342106
Validation loss: 2.5813425460013044

Epoch: 6| Step: 11
Training loss: 2.4834040057817046
Validation loss: 2.5793481097556583

Epoch: 6| Step: 12
Training loss: 2.5809634218162447
Validation loss: 2.550007037596026

Epoch: 6| Step: 13
Training loss: 1.5049823032491982
Validation loss: 2.5452278941748006

Epoch: 383| Step: 0
Training loss: 2.5084285751798006
Validation loss: 2.5422724125213123

Epoch: 6| Step: 1
Training loss: 2.6407304550873385
Validation loss: 2.5412569019986218

Epoch: 6| Step: 2
Training loss: 2.5957194744711773
Validation loss: 2.5437549791874132

Epoch: 6| Step: 3
Training loss: 2.4081465938024684
Validation loss: 2.556259719642012

Epoch: 6| Step: 4
Training loss: 1.9707202438049525
Validation loss: 2.5403102023488358

Epoch: 6| Step: 5
Training loss: 2.892070182180866
Validation loss: 2.5386482470045717

Epoch: 6| Step: 6
Training loss: 2.216131142292271
Validation loss: 2.586003211641087

Epoch: 6| Step: 7
Training loss: 2.5213383780835277
Validation loss: 2.6100923189507275

Epoch: 6| Step: 8
Training loss: 2.5940412794430134
Validation loss: 2.556005993589701

Epoch: 6| Step: 9
Training loss: 2.7539401870692615
Validation loss: 2.5434655205725845

Epoch: 6| Step: 10
Training loss: 2.674527998307909
Validation loss: 2.5286417651307156

Epoch: 6| Step: 11
Training loss: 3.07173989387887
Validation loss: 2.5006463210073164

Epoch: 6| Step: 12
Training loss: 2.858682183719388
Validation loss: 2.49814539998435

Epoch: 6| Step: 13
Training loss: 1.944731660096607
Validation loss: 2.493022127666529

Epoch: 384| Step: 0
Training loss: 2.500462107864995
Validation loss: 2.4777196378845914

Epoch: 6| Step: 1
Training loss: 2.364553263692916
Validation loss: 2.4848154629083683

Epoch: 6| Step: 2
Training loss: 2.617440009390624
Validation loss: 2.467681840602816

Epoch: 6| Step: 3
Training loss: 2.624168627647264
Validation loss: 2.4679050040476715

Epoch: 6| Step: 4
Training loss: 2.4308705286269405
Validation loss: 2.4785027463349794

Epoch: 6| Step: 5
Training loss: 2.4703765532690367
Validation loss: 2.4727900076088063

Epoch: 6| Step: 6
Training loss: 3.237073574188117
Validation loss: 2.480624318365673

Epoch: 6| Step: 7
Training loss: 2.6586005189211415
Validation loss: 2.493848613983312

Epoch: 6| Step: 8
Training loss: 2.672360203283103
Validation loss: 2.5537346883838032

Epoch: 6| Step: 9
Training loss: 2.250866405249273
Validation loss: 2.592202343708133

Epoch: 6| Step: 10
Training loss: 3.244015833081084
Validation loss: 2.6289275028530326

Epoch: 6| Step: 11
Training loss: 1.905011759844349
Validation loss: 2.6573273232401746

Epoch: 6| Step: 12
Training loss: 2.6961510279940133
Validation loss: 2.6514080044390065

Epoch: 6| Step: 13
Training loss: 2.7145546299511563
Validation loss: 2.6012636393835367

Epoch: 385| Step: 0
Training loss: 2.8204201125645523
Validation loss: 2.5905310192597013

Epoch: 6| Step: 1
Training loss: 3.332479431134654
Validation loss: 2.56897935686945

Epoch: 6| Step: 2
Training loss: 2.839364663369141
Validation loss: 2.5633350935426575

Epoch: 6| Step: 3
Training loss: 1.7579368038731493
Validation loss: 2.529956682186099

Epoch: 6| Step: 4
Training loss: 2.235546311893822
Validation loss: 2.509171998179647

Epoch: 6| Step: 5
Training loss: 2.430643267789715
Validation loss: 2.503965627852422

Epoch: 6| Step: 6
Training loss: 2.667379959394297
Validation loss: 2.493195010087642

Epoch: 6| Step: 7
Training loss: 3.153573289200117
Validation loss: 2.491888508140034

Epoch: 6| Step: 8
Training loss: 2.501856877234883
Validation loss: 2.50269740210156

Epoch: 6| Step: 9
Training loss: 2.3223506311975446
Validation loss: 2.498198144956828

Epoch: 6| Step: 10
Training loss: 2.2580990724951846
Validation loss: 2.4995145234063383

Epoch: 6| Step: 11
Training loss: 2.42883599867749
Validation loss: 2.52136145374782

Epoch: 6| Step: 12
Training loss: 2.6078898149278085
Validation loss: 2.544858303032675

Epoch: 6| Step: 13
Training loss: 1.897846773649343
Validation loss: 2.561152348175896

Epoch: 386| Step: 0
Training loss: 2.8113269478871112
Validation loss: 2.5657447502714796

Epoch: 6| Step: 1
Training loss: 2.228454535513751
Validation loss: 2.545099940988242

Epoch: 6| Step: 2
Training loss: 2.32539853197673
Validation loss: 2.5140350174080326

Epoch: 6| Step: 3
Training loss: 2.4137441678324905
Validation loss: 2.490803343478038

Epoch: 6| Step: 4
Training loss: 2.585483107736468
Validation loss: 2.4749388499830167

Epoch: 6| Step: 5
Training loss: 2.7948973925869107
Validation loss: 2.466490396175653

Epoch: 6| Step: 6
Training loss: 2.3665348575941687
Validation loss: 2.4533943554575264

Epoch: 6| Step: 7
Training loss: 2.61634589940358
Validation loss: 2.4642977232196603

Epoch: 6| Step: 8
Training loss: 2.69294913793582
Validation loss: 2.47968003240308

Epoch: 6| Step: 9
Training loss: 2.9242498365090563
Validation loss: 2.500131368774631

Epoch: 6| Step: 10
Training loss: 2.6830612609386972
Validation loss: 2.514304312028064

Epoch: 6| Step: 11
Training loss: 2.5122148608205253
Validation loss: 2.52021390597475

Epoch: 6| Step: 12
Training loss: 2.303637766595755
Validation loss: 2.5314843907236244

Epoch: 6| Step: 13
Training loss: 2.818093396363045
Validation loss: 2.576634284012332

Epoch: 387| Step: 0
Training loss: 2.9338775375593826
Validation loss: 2.5967131845857256

Epoch: 6| Step: 1
Training loss: 2.4505407242705832
Validation loss: 2.6237399646163557

Epoch: 6| Step: 2
Training loss: 2.8799571548029976
Validation loss: 2.6050813455819943

Epoch: 6| Step: 3
Training loss: 2.643420663796463
Validation loss: 2.5717417071090183

Epoch: 6| Step: 4
Training loss: 2.65785088261917
Validation loss: 2.5855243291941585

Epoch: 6| Step: 5
Training loss: 2.4817409346795274
Validation loss: 2.582338452833757

Epoch: 6| Step: 6
Training loss: 2.627118118947239
Validation loss: 2.5537893610568787

Epoch: 6| Step: 7
Training loss: 2.7449613708112715
Validation loss: 2.547661466680873

Epoch: 6| Step: 8
Training loss: 2.5901727481806076
Validation loss: 2.5420649771325774

Epoch: 6| Step: 9
Training loss: 1.833617152295101
Validation loss: 2.5318234674048328

Epoch: 6| Step: 10
Training loss: 2.2698369304549026
Validation loss: 2.509139814177123

Epoch: 6| Step: 11
Training loss: 2.6411093544150646
Validation loss: 2.5051850897778154

Epoch: 6| Step: 12
Training loss: 2.2361444256224665
Validation loss: 2.4837458644552406

Epoch: 6| Step: 13
Training loss: 2.8472607080189745
Validation loss: 2.5044697233475013

Epoch: 388| Step: 0
Training loss: 2.2229903628697687
Validation loss: 2.529919389927821

Epoch: 6| Step: 1
Training loss: 2.6634858253979776
Validation loss: 2.5366793990973497

Epoch: 6| Step: 2
Training loss: 2.8455613623963703
Validation loss: 2.5680933967725177

Epoch: 6| Step: 3
Training loss: 3.092484957289133
Validation loss: 2.5774337463339556

Epoch: 6| Step: 4
Training loss: 2.363221323814084
Validation loss: 2.550195368232294

Epoch: 6| Step: 5
Training loss: 2.533773506556108
Validation loss: 2.553040004995399

Epoch: 6| Step: 6
Training loss: 2.1431892796107688
Validation loss: 2.5422059012801115

Epoch: 6| Step: 7
Training loss: 2.5991151771284575
Validation loss: 2.5250210786628213

Epoch: 6| Step: 8
Training loss: 2.60963319882969
Validation loss: 2.5369896597651382

Epoch: 6| Step: 9
Training loss: 2.440198529405966
Validation loss: 2.5275047818860408

Epoch: 6| Step: 10
Training loss: 2.8241378751495128
Validation loss: 2.514059238973067

Epoch: 6| Step: 11
Training loss: 2.1053752135270063
Validation loss: 2.5259619465663707

Epoch: 6| Step: 12
Training loss: 2.5017270798306535
Validation loss: 2.4996027610365457

Epoch: 6| Step: 13
Training loss: 2.525828737283886
Validation loss: 2.5018841303912946

Epoch: 389| Step: 0
Training loss: 2.48478848837073
Validation loss: 2.506766637015392

Epoch: 6| Step: 1
Training loss: 2.562854556234105
Validation loss: 2.523266374693343

Epoch: 6| Step: 2
Training loss: 2.123937004347704
Validation loss: 2.5460433744688102

Epoch: 6| Step: 3
Training loss: 2.5438682734856144
Validation loss: 2.5556214756405

Epoch: 6| Step: 4
Training loss: 2.7807366401003675
Validation loss: 2.572829939338855

Epoch: 6| Step: 5
Training loss: 2.5348793666208875
Validation loss: 2.6041244224485456

Epoch: 6| Step: 6
Training loss: 2.4824257167063113
Validation loss: 2.585252426782511

Epoch: 6| Step: 7
Training loss: 2.502295393987195
Validation loss: 2.613097686822225

Epoch: 6| Step: 8
Training loss: 2.2630184570112726
Validation loss: 2.620299565262794

Epoch: 6| Step: 9
Training loss: 2.7546595199297763
Validation loss: 2.6347055811383724

Epoch: 6| Step: 10
Training loss: 2.7224149884419186
Validation loss: 2.609689007987421

Epoch: 6| Step: 11
Training loss: 2.6219488304027765
Validation loss: 2.594543425620817

Epoch: 6| Step: 12
Training loss: 2.3560477536774678
Validation loss: 2.519194721686623

Epoch: 6| Step: 13
Training loss: 2.3823609971829285
Validation loss: 2.512699045684071

Epoch: 390| Step: 0
Training loss: 2.3719386397558013
Validation loss: 2.47270495613278

Epoch: 6| Step: 1
Training loss: 2.536813720203591
Validation loss: 2.4746256335838273

Epoch: 6| Step: 2
Training loss: 2.6895100373539846
Validation loss: 2.4467067659990502

Epoch: 6| Step: 3
Training loss: 3.0393565214655545
Validation loss: 2.4556703724996467

Epoch: 6| Step: 4
Training loss: 2.6311508051280854
Validation loss: 2.453921428413734

Epoch: 6| Step: 5
Training loss: 2.5022752898370615
Validation loss: 2.50792340885144

Epoch: 6| Step: 6
Training loss: 2.513966837237124
Validation loss: 2.5394014390710855

Epoch: 6| Step: 7
Training loss: 2.2546121163035804
Validation loss: 2.5637868365815075

Epoch: 6| Step: 8
Training loss: 2.6418275521401053
Validation loss: 2.5999122910894212

Epoch: 6| Step: 9
Training loss: 2.605214531204882
Validation loss: 2.645844508360567

Epoch: 6| Step: 10
Training loss: 2.795441073450753
Validation loss: 2.6311273029206768

Epoch: 6| Step: 11
Training loss: 2.1274676860861073
Validation loss: 2.653531023867023

Epoch: 6| Step: 12
Training loss: 2.6002938324613853
Validation loss: 2.6319702520845945

Epoch: 6| Step: 13
Training loss: 1.44645456092266
Validation loss: 2.5608859397557255

Epoch: 391| Step: 0
Training loss: 2.5086042158632607
Validation loss: 2.522684617711711

Epoch: 6| Step: 1
Training loss: 3.087770482620871
Validation loss: 2.469523696879299

Epoch: 6| Step: 2
Training loss: 1.7503497591634898
Validation loss: 2.471909235388735

Epoch: 6| Step: 3
Training loss: 2.6497683261871403
Validation loss: 2.453623693610717

Epoch: 6| Step: 4
Training loss: 2.4281180363264343
Validation loss: 2.446269021015494

Epoch: 6| Step: 5
Training loss: 2.6995552615059237
Validation loss: 2.448172750978514

Epoch: 6| Step: 6
Training loss: 2.5892565307475897
Validation loss: 2.479445945235744

Epoch: 6| Step: 7
Training loss: 1.9008313694126677
Validation loss: 2.5148724833150577

Epoch: 6| Step: 8
Training loss: 2.3764586737611246
Validation loss: 2.547998281924191

Epoch: 6| Step: 9
Training loss: 2.672186403922288
Validation loss: 2.5623648653131825

Epoch: 6| Step: 10
Training loss: 2.1138381647258644
Validation loss: 2.578101108871641

Epoch: 6| Step: 11
Training loss: 2.688277376100631
Validation loss: 2.5719780314346194

Epoch: 6| Step: 12
Training loss: 2.823400439561179
Validation loss: 2.58687927011861

Epoch: 6| Step: 13
Training loss: 2.4970654430498573
Validation loss: 2.6089689633827233

Epoch: 392| Step: 0
Training loss: 2.211351012256525
Validation loss: 2.6667128361530126

Epoch: 6| Step: 1
Training loss: 3.0369357240348283
Validation loss: 2.737277199427228

Epoch: 6| Step: 2
Training loss: 2.1387474569264313
Validation loss: 2.747728720550526

Epoch: 6| Step: 3
Training loss: 2.872082432342245
Validation loss: 2.7413974247006143

Epoch: 6| Step: 4
Training loss: 2.549944099112734
Validation loss: 2.6964765011577643

Epoch: 6| Step: 5
Training loss: 2.6378653286851192
Validation loss: 2.5743450726541974

Epoch: 6| Step: 6
Training loss: 2.33760893868755
Validation loss: 2.528253107711334

Epoch: 6| Step: 7
Training loss: 2.3523115314873184
Validation loss: 2.4746744449526696

Epoch: 6| Step: 8
Training loss: 2.3590480754783725
Validation loss: 2.428529531826777

Epoch: 6| Step: 9
Training loss: 2.508941111220579
Validation loss: 2.4370104032727475

Epoch: 6| Step: 10
Training loss: 2.760171113998595
Validation loss: 2.432573622863047

Epoch: 6| Step: 11
Training loss: 2.8185360880204953
Validation loss: 2.450614678851713

Epoch: 6| Step: 12
Training loss: 2.1872405852039862
Validation loss: 2.4671283092951555

Epoch: 6| Step: 13
Training loss: 3.1965763791579462
Validation loss: 2.499716222715797

Epoch: 393| Step: 0
Training loss: 2.045343889268064
Validation loss: 2.5222066350326986

Epoch: 6| Step: 1
Training loss: 2.6969163628474986
Validation loss: 2.5671907177061994

Epoch: 6| Step: 2
Training loss: 2.336548486116308
Validation loss: 2.585207090571221

Epoch: 6| Step: 3
Training loss: 2.735646241183804
Validation loss: 2.6343917552839597

Epoch: 6| Step: 4
Training loss: 2.5109087407685236
Validation loss: 2.648693642834979

Epoch: 6| Step: 5
Training loss: 2.6750280503558144
Validation loss: 2.649296111162779

Epoch: 6| Step: 6
Training loss: 2.9501610469501314
Validation loss: 2.6148663834857153

Epoch: 6| Step: 7
Training loss: 2.2805749599897664
Validation loss: 2.5155471833542915

Epoch: 6| Step: 8
Training loss: 3.025022736771312
Validation loss: 2.5027374723439646

Epoch: 6| Step: 9
Training loss: 2.1758796491579284
Validation loss: 2.497064049869986

Epoch: 6| Step: 10
Training loss: 2.2036396264247506
Validation loss: 2.4976313855444587

Epoch: 6| Step: 11
Training loss: 2.8003566106134494
Validation loss: 2.468906605827285

Epoch: 6| Step: 12
Training loss: 1.655974527158488
Validation loss: 2.467406327143904

Epoch: 6| Step: 13
Training loss: 2.423529767186734
Validation loss: 2.4464668160713234

Epoch: 394| Step: 0
Training loss: 2.249527139778513
Validation loss: 2.4468495476400207

Epoch: 6| Step: 1
Training loss: 3.017266177747321
Validation loss: 2.4437989325411094

Epoch: 6| Step: 2
Training loss: 2.6785290051688375
Validation loss: 2.450256973352819

Epoch: 6| Step: 3
Training loss: 2.398256574634649
Validation loss: 2.460505028074083

Epoch: 6| Step: 4
Training loss: 2.442498193308729
Validation loss: 2.5288788974991183

Epoch: 6| Step: 5
Training loss: 1.8632612247310638
Validation loss: 2.5325357667480817

Epoch: 6| Step: 6
Training loss: 2.39269939504528
Validation loss: 2.5706818461720355

Epoch: 6| Step: 7
Training loss: 2.9948664293770384
Validation loss: 2.6259089642858586

Epoch: 6| Step: 8
Training loss: 1.8680434559458199
Validation loss: 2.5875201268439025

Epoch: 6| Step: 9
Training loss: 2.9092447581573833
Validation loss: 2.5368390198236472

Epoch: 6| Step: 10
Training loss: 2.747247705790327
Validation loss: 2.499421504984853

Epoch: 6| Step: 11
Training loss: 2.421519099511316
Validation loss: 2.4706699355976367

Epoch: 6| Step: 12
Training loss: 2.5399919422652624
Validation loss: 2.4830563843855034

Epoch: 6| Step: 13
Training loss: 2.7185180389720704
Validation loss: 2.466766059741539

Epoch: 395| Step: 0
Training loss: 2.6611828944541926
Validation loss: 2.4846822381371845

Epoch: 6| Step: 1
Training loss: 2.5517748172629924
Validation loss: 2.472751145099627

Epoch: 6| Step: 2
Training loss: 2.8536424549906902
Validation loss: 2.50549283852246

Epoch: 6| Step: 3
Training loss: 2.3267687232835135
Validation loss: 2.543096166253051

Epoch: 6| Step: 4
Training loss: 2.3393857886687046
Validation loss: 2.5796637116306655

Epoch: 6| Step: 5
Training loss: 2.4413672848453056
Validation loss: 2.6379539911220378

Epoch: 6| Step: 6
Training loss: 2.6661741775483527
Validation loss: 2.635296406195404

Epoch: 6| Step: 7
Training loss: 2.0605814709403187
Validation loss: 2.6447880483730994

Epoch: 6| Step: 8
Training loss: 2.318058858932215
Validation loss: 2.644708159855064

Epoch: 6| Step: 9
Training loss: 2.511333714898896
Validation loss: 2.6454293634867296

Epoch: 6| Step: 10
Training loss: 3.0413136908858363
Validation loss: 2.6574715157572704

Epoch: 6| Step: 11
Training loss: 2.1921020056108085
Validation loss: 2.674550090634244

Epoch: 6| Step: 12
Training loss: 2.3774440637661005
Validation loss: 2.6569038701051864

Epoch: 6| Step: 13
Training loss: 2.4509473720645008
Validation loss: 2.618385259545607

Epoch: 396| Step: 0
Training loss: 2.53327841782863
Validation loss: 2.6320153701401514

Epoch: 6| Step: 1
Training loss: 2.8250032340512288
Validation loss: 2.615697337001902

Epoch: 6| Step: 2
Training loss: 2.6075721954562643
Validation loss: 2.5860087215721683

Epoch: 6| Step: 3
Training loss: 2.9196001468865895
Validation loss: 2.5284609036262697

Epoch: 6| Step: 4
Training loss: 2.6982573854982768
Validation loss: 2.508158076287191

Epoch: 6| Step: 5
Training loss: 1.7077869689094005
Validation loss: 2.485157977444128

Epoch: 6| Step: 6
Training loss: 2.4460338954370506
Validation loss: 2.462254504820835

Epoch: 6| Step: 7
Training loss: 2.739198104017261
Validation loss: 2.4846574918488074

Epoch: 6| Step: 8
Training loss: 2.2372202863554085
Validation loss: 2.4887294241074938

Epoch: 6| Step: 9
Training loss: 2.783190618118829
Validation loss: 2.54351018971675

Epoch: 6| Step: 10
Training loss: 1.9418319757297624
Validation loss: 2.547430190705863

Epoch: 6| Step: 11
Training loss: 2.615320251285618
Validation loss: 2.587660457864608

Epoch: 6| Step: 12
Training loss: 2.614952020879673
Validation loss: 2.633123548455538

Epoch: 6| Step: 13
Training loss: 1.9396421833991913
Validation loss: 2.6332082805429766

Epoch: 397| Step: 0
Training loss: 2.187339340849702
Validation loss: 2.6754319102683213

Epoch: 6| Step: 1
Training loss: 2.432843185946687
Validation loss: 2.689084451409721

Epoch: 6| Step: 2
Training loss: 2.6716859984893295
Validation loss: 2.689808221779987

Epoch: 6| Step: 3
Training loss: 1.8625795334597486
Validation loss: 2.679262374658365

Epoch: 6| Step: 4
Training loss: 2.666212897634984
Validation loss: 2.6478793277516828

Epoch: 6| Step: 5
Training loss: 2.731112031921833
Validation loss: 2.5469378794463595

Epoch: 6| Step: 6
Training loss: 2.7804864413927723
Validation loss: 2.515083145079811

Epoch: 6| Step: 7
Training loss: 2.5951569199938738
Validation loss: 2.486367271246698

Epoch: 6| Step: 8
Training loss: 2.776750246311217
Validation loss: 2.4476248841944397

Epoch: 6| Step: 9
Training loss: 2.426448318732844
Validation loss: 2.443274771148277

Epoch: 6| Step: 10
Training loss: 2.743098528776212
Validation loss: 2.442890380761724

Epoch: 6| Step: 11
Training loss: 2.1161239599107837
Validation loss: 2.4258932566962526

Epoch: 6| Step: 12
Training loss: 2.781325435686953
Validation loss: 2.4413853714245017

Epoch: 6| Step: 13
Training loss: 2.538489549989137
Validation loss: 2.445335716481481

Epoch: 398| Step: 0
Training loss: 2.4596701613328706
Validation loss: 2.4990063025521256

Epoch: 6| Step: 1
Training loss: 2.6460598425639748
Validation loss: 2.5314054493309217

Epoch: 6| Step: 2
Training loss: 2.546509886238027
Validation loss: 2.550462121367375

Epoch: 6| Step: 3
Training loss: 2.147288178021342
Validation loss: 2.573401641341844

Epoch: 6| Step: 4
Training loss: 2.6946320932684875
Validation loss: 2.5585339766309225

Epoch: 6| Step: 5
Training loss: 2.2424005812569012
Validation loss: 2.550160340285457

Epoch: 6| Step: 6
Training loss: 2.3663802076526945
Validation loss: 2.544481122902384

Epoch: 6| Step: 7
Training loss: 2.6989269844176995
Validation loss: 2.537996792339715

Epoch: 6| Step: 8
Training loss: 2.865200091925948
Validation loss: 2.532145111125694

Epoch: 6| Step: 9
Training loss: 2.262868532968179
Validation loss: 2.533363081131882

Epoch: 6| Step: 10
Training loss: 2.592295503119655
Validation loss: 2.5293071496231945

Epoch: 6| Step: 11
Training loss: 2.599452907516502
Validation loss: 2.556653064937016

Epoch: 6| Step: 12
Training loss: 2.279031380143162
Validation loss: 2.568850523923852

Epoch: 6| Step: 13
Training loss: 1.770770045626799
Validation loss: 2.592606437818348

Epoch: 399| Step: 0
Training loss: 2.5766459528430543
Validation loss: 2.6218888010257295

Epoch: 6| Step: 1
Training loss: 2.320592689936489
Validation loss: 2.669091585965412

Epoch: 6| Step: 2
Training loss: 2.526892030608072
Validation loss: 2.6639643118067418

Epoch: 6| Step: 3
Training loss: 2.3220385158869985
Validation loss: 2.6798332617421976

Epoch: 6| Step: 4
Training loss: 2.15415786751205
Validation loss: 2.6746323725921273

Epoch: 6| Step: 5
Training loss: 2.1685304206260665
Validation loss: 2.7204230034566126

Epoch: 6| Step: 6
Training loss: 2.5578274809737103
Validation loss: 2.6899914269341783

Epoch: 6| Step: 7
Training loss: 2.6072787699200726
Validation loss: 2.673388809517593

Epoch: 6| Step: 8
Training loss: 2.3237394463769894
Validation loss: 2.6368237565740706

Epoch: 6| Step: 9
Training loss: 2.6256117335009104
Validation loss: 2.529073721820665

Epoch: 6| Step: 10
Training loss: 2.7481629564701837
Validation loss: 2.4499414537636635

Epoch: 6| Step: 11
Training loss: 2.659871762561858
Validation loss: 2.4310435431543267

Epoch: 6| Step: 12
Training loss: 2.9000673878173653
Validation loss: 2.4172421457246966

Epoch: 6| Step: 13
Training loss: 2.8198326315485978
Validation loss: 2.4196655356962684

Epoch: 400| Step: 0
Training loss: 2.392069560905411
Validation loss: 2.419839134179991

Epoch: 6| Step: 1
Training loss: 2.5930032229567157
Validation loss: 2.434256801131245

Epoch: 6| Step: 2
Training loss: 2.6421161481809454
Validation loss: 2.4301849474311643

Epoch: 6| Step: 3
Training loss: 2.7510852406315407
Validation loss: 2.424110222126846

Epoch: 6| Step: 4
Training loss: 2.979226989846737
Validation loss: 2.4366522614525854

Epoch: 6| Step: 5
Training loss: 2.3201204470905314
Validation loss: 2.4397925509531517

Epoch: 6| Step: 6
Training loss: 2.5167152459043285
Validation loss: 2.4618847272962574

Epoch: 6| Step: 7
Training loss: 2.2833916004663593
Validation loss: 2.4864456361264913

Epoch: 6| Step: 8
Training loss: 2.130613653768786
Validation loss: 2.5606776174440395

Epoch: 6| Step: 9
Training loss: 2.676346456044733
Validation loss: 2.5895543456825947

Epoch: 6| Step: 10
Training loss: 2.9176043138593992
Validation loss: 2.613522102970906

Epoch: 6| Step: 11
Training loss: 2.5521544050843312
Validation loss: 2.6525223839613212

Epoch: 6| Step: 12
Training loss: 2.4779124145916067
Validation loss: 2.668778706626489

Epoch: 6| Step: 13
Training loss: 2.43524525357054
Validation loss: 2.651459146072498

Epoch: 401| Step: 0
Training loss: 1.88285998525928
Validation loss: 2.6194799534564495

Epoch: 6| Step: 1
Training loss: 2.3780524063559842
Validation loss: 2.6059104748050737

Epoch: 6| Step: 2
Training loss: 2.4214595315258487
Validation loss: 2.561792160342501

Epoch: 6| Step: 3
Training loss: 2.0959679542013667
Validation loss: 2.509584748492122

Epoch: 6| Step: 4
Training loss: 2.1453240046293396
Validation loss: 2.484184641196798

Epoch: 6| Step: 5
Training loss: 2.9290461537588666
Validation loss: 2.454707914982811

Epoch: 6| Step: 6
Training loss: 2.6250847394072068
Validation loss: 2.441010596720539

Epoch: 6| Step: 7
Training loss: 3.07619388632998
Validation loss: 2.461543947427504

Epoch: 6| Step: 8
Training loss: 2.6726148149968822
Validation loss: 2.4444238890097174

Epoch: 6| Step: 9
Training loss: 2.0149146905829904
Validation loss: 2.4627994450441872

Epoch: 6| Step: 10
Training loss: 2.225465738650283
Validation loss: 2.473333336595998

Epoch: 6| Step: 11
Training loss: 2.6201908017344646
Validation loss: 2.468882289139116

Epoch: 6| Step: 12
Training loss: 2.5237535213844557
Validation loss: 2.4865670883552755

Epoch: 6| Step: 13
Training loss: 2.7634872536611166
Validation loss: 2.475239495673956

Epoch: 402| Step: 0
Training loss: 2.210449811978742
Validation loss: 2.485629779150239

Epoch: 6| Step: 1
Training loss: 2.6047207560758925
Validation loss: 2.516565390542052

Epoch: 6| Step: 2
Training loss: 2.6451932678570778
Validation loss: 2.527107835995495

Epoch: 6| Step: 3
Training loss: 2.571237507791174
Validation loss: 2.571166951400991

Epoch: 6| Step: 4
Training loss: 2.594535249168854
Validation loss: 2.560549384026625

Epoch: 6| Step: 5
Training loss: 1.8753361718492738
Validation loss: 2.5574906169894973

Epoch: 6| Step: 6
Training loss: 2.291906887526478
Validation loss: 2.55079153054727

Epoch: 6| Step: 7
Training loss: 1.9897520250103315
Validation loss: 2.5195635546220374

Epoch: 6| Step: 8
Training loss: 2.354172686903916
Validation loss: 2.4873055945072355

Epoch: 6| Step: 9
Training loss: 2.4400310580043607
Validation loss: 2.493043741452673

Epoch: 6| Step: 10
Training loss: 2.5180197743433976
Validation loss: 2.507020094401844

Epoch: 6| Step: 11
Training loss: 3.0926422293667115
Validation loss: 2.524123917538266

Epoch: 6| Step: 12
Training loss: 3.0392084160222557
Validation loss: 2.557780947033867

Epoch: 6| Step: 13
Training loss: 1.196878193186193
Validation loss: 2.5803554011725853

Epoch: 403| Step: 0
Training loss: 2.6636955478353035
Validation loss: 2.5844368960859674

Epoch: 6| Step: 1
Training loss: 2.59773995400855
Validation loss: 2.589655592265844

Epoch: 6| Step: 2
Training loss: 2.0586847795486833
Validation loss: 2.575575755562591

Epoch: 6| Step: 3
Training loss: 2.642301670452445
Validation loss: 2.5928843576219114

Epoch: 6| Step: 4
Training loss: 2.3571504122129965
Validation loss: 2.544003413203764

Epoch: 6| Step: 5
Training loss: 2.4423133080624133
Validation loss: 2.5366445675450646

Epoch: 6| Step: 6
Training loss: 2.5416186802404233
Validation loss: 2.554539597204938

Epoch: 6| Step: 7
Training loss: 1.8578928962938421
Validation loss: 2.5585826982192

Epoch: 6| Step: 8
Training loss: 2.385405283627288
Validation loss: 2.542803770380296

Epoch: 6| Step: 9
Training loss: 1.88434921171088
Validation loss: 2.5194229910364427

Epoch: 6| Step: 10
Training loss: 2.6399276986480813
Validation loss: 2.5119567726672

Epoch: 6| Step: 11
Training loss: 2.530256570916623
Validation loss: 2.4962018935898223

Epoch: 6| Step: 12
Training loss: 2.753711709800897
Validation loss: 2.4903002565802903

Epoch: 6| Step: 13
Training loss: 2.3283139350572735
Validation loss: 2.48251734067278

Epoch: 404| Step: 0
Training loss: 2.1502553566390397
Validation loss: 2.507383651133663

Epoch: 6| Step: 1
Training loss: 2.474221937624989
Validation loss: 2.532436309090655

Epoch: 6| Step: 2
Training loss: 2.3306779624954754
Validation loss: 2.5616897754749197

Epoch: 6| Step: 3
Training loss: 2.6674056122087477
Validation loss: 2.5607210512762895

Epoch: 6| Step: 4
Training loss: 1.9189720870229758
Validation loss: 2.5408210100693394

Epoch: 6| Step: 5
Training loss: 2.3178431668155137
Validation loss: 2.529791710294438

Epoch: 6| Step: 6
Training loss: 2.505410443333185
Validation loss: 2.5114532362517017

Epoch: 6| Step: 7
Training loss: 2.323331467980284
Validation loss: 2.527450365278

Epoch: 6| Step: 8
Training loss: 2.810133298515575
Validation loss: 2.5127830831993148

Epoch: 6| Step: 9
Training loss: 2.234401889452492
Validation loss: 2.515278025877403

Epoch: 6| Step: 10
Training loss: 2.361340544031393
Validation loss: 2.565485652833383

Epoch: 6| Step: 11
Training loss: 2.8333647857117046
Validation loss: 2.5797857768020003

Epoch: 6| Step: 12
Training loss: 2.3114743406805345
Validation loss: 2.6257935441305533

Epoch: 6| Step: 13
Training loss: 2.4867671749710363
Validation loss: 2.6671742868138524

Epoch: 405| Step: 0
Training loss: 2.412950179242183
Validation loss: 2.7084827217822256

Epoch: 6| Step: 1
Training loss: 2.394547877790708
Validation loss: 2.7452746295611212

Epoch: 6| Step: 2
Training loss: 2.7870337536824055
Validation loss: 2.727377208993585

Epoch: 6| Step: 3
Training loss: 1.7004544380004223
Validation loss: 2.63393019386374

Epoch: 6| Step: 4
Training loss: 2.5423731421346583
Validation loss: 2.5582653654972494

Epoch: 6| Step: 5
Training loss: 1.8177790222705186
Validation loss: 2.5035822357962485

Epoch: 6| Step: 6
Training loss: 2.5941016636722787
Validation loss: 2.453935369008194

Epoch: 6| Step: 7
Training loss: 2.6286991032105074
Validation loss: 2.453081376049907

Epoch: 6| Step: 8
Training loss: 2.6033723051969635
Validation loss: 2.4524754566368903

Epoch: 6| Step: 9
Training loss: 2.3696161785055105
Validation loss: 2.454177421684007

Epoch: 6| Step: 10
Training loss: 2.8005762597141697
Validation loss: 2.482440361608018

Epoch: 6| Step: 11
Training loss: 2.8042995854051274
Validation loss: 2.509167866900703

Epoch: 6| Step: 12
Training loss: 2.197468198127337
Validation loss: 2.4699913819775365

Epoch: 6| Step: 13
Training loss: 2.1847995983901436
Validation loss: 2.522861793094533

Epoch: 406| Step: 0
Training loss: 2.7704350082410696
Validation loss: 2.539980386642619

Epoch: 6| Step: 1
Training loss: 2.7066281942004196
Validation loss: 2.5485863456168447

Epoch: 6| Step: 2
Training loss: 2.4790848363199243
Validation loss: 2.555096816802118

Epoch: 6| Step: 3
Training loss: 2.8127458253028816
Validation loss: 2.5697588780212435

Epoch: 6| Step: 4
Training loss: 1.9047843426563567
Validation loss: 2.586433555640918

Epoch: 6| Step: 5
Training loss: 2.7909841035166725
Validation loss: 2.6107557265523877

Epoch: 6| Step: 6
Training loss: 2.2433957556116546
Validation loss: 2.640231382834991

Epoch: 6| Step: 7
Training loss: 2.1068808043973415
Validation loss: 2.672197502000343

Epoch: 6| Step: 8
Training loss: 2.853074266164397
Validation loss: 2.6618817971038875

Epoch: 6| Step: 9
Training loss: 2.1421139404666714
Validation loss: 2.644069708484034

Epoch: 6| Step: 10
Training loss: 1.76691585378843
Validation loss: 2.596169076179618

Epoch: 6| Step: 11
Training loss: 1.8407078230508769
Validation loss: 2.5507644104765665

Epoch: 6| Step: 12
Training loss: 2.557551840129054
Validation loss: 2.5289756212015067

Epoch: 6| Step: 13
Training loss: 2.2421909026542126
Validation loss: 2.4947902283728705

Epoch: 407| Step: 0
Training loss: 1.9255624766787023
Validation loss: 2.468648291336325

Epoch: 6| Step: 1
Training loss: 1.8742267285678447
Validation loss: 2.4462864090353262

Epoch: 6| Step: 2
Training loss: 2.5786218337856415
Validation loss: 2.4454685394531634

Epoch: 6| Step: 3
Training loss: 2.4547189769997053
Validation loss: 2.4314431379261654

Epoch: 6| Step: 4
Training loss: 2.224058972358988
Validation loss: 2.448088188856053

Epoch: 6| Step: 5
Training loss: 2.489184253154994
Validation loss: 2.482420813366132

Epoch: 6| Step: 6
Training loss: 2.5708461775579945
Validation loss: 2.5447072337833894

Epoch: 6| Step: 7
Training loss: 2.7584746433106986
Validation loss: 2.605560323263918

Epoch: 6| Step: 8
Training loss: 2.2127805111752967
Validation loss: 2.671771736598644

Epoch: 6| Step: 9
Training loss: 2.439164302639282
Validation loss: 2.708948922697356

Epoch: 6| Step: 10
Training loss: 2.2025779964912573
Validation loss: 2.7380643195802308

Epoch: 6| Step: 11
Training loss: 2.879386375277261
Validation loss: 2.746355030475252

Epoch: 6| Step: 12
Training loss: 2.6457659094522383
Validation loss: 2.6807868659073915

Epoch: 6| Step: 13
Training loss: 3.2392021682739536
Validation loss: 2.5960013646806797

Epoch: 408| Step: 0
Training loss: 2.204580705355506
Validation loss: 2.5517901963992404

Epoch: 6| Step: 1
Training loss: 2.542216059190813
Validation loss: 2.4946238670938667

Epoch: 6| Step: 2
Training loss: 2.696758998882358
Validation loss: 2.4858681955059656

Epoch: 6| Step: 3
Training loss: 2.078065340720242
Validation loss: 2.493687328096263

Epoch: 6| Step: 4
Training loss: 2.122875497984714
Validation loss: 2.497235718272928

Epoch: 6| Step: 5
Training loss: 2.978503137781201
Validation loss: 2.5084398223814244

Epoch: 6| Step: 6
Training loss: 2.0745236734808006
Validation loss: 2.5325425611764523

Epoch: 6| Step: 7
Training loss: 2.1561291425807694
Validation loss: 2.4977193951261447

Epoch: 6| Step: 8
Training loss: 2.2694713696247386
Validation loss: 2.5211816287944626

Epoch: 6| Step: 9
Training loss: 2.3840925936862805
Validation loss: 2.485591254053005

Epoch: 6| Step: 10
Training loss: 2.9206127357347857
Validation loss: 2.4704278582059755

Epoch: 6| Step: 11
Training loss: 1.6053905607243268
Validation loss: 2.4578345004533237

Epoch: 6| Step: 12
Training loss: 2.53478399285657
Validation loss: 2.47342414999792

Epoch: 6| Step: 13
Training loss: 2.8804995140706975
Validation loss: 2.4619541769479905

Epoch: 409| Step: 0
Training loss: 2.379823103990425
Validation loss: 2.5033999673137637

Epoch: 6| Step: 1
Training loss: 2.3286171207408324
Validation loss: 2.5845375892849485

Epoch: 6| Step: 2
Training loss: 2.3680400257465237
Validation loss: 2.6551233458664263

Epoch: 6| Step: 3
Training loss: 2.597455514594826
Validation loss: 2.6973992096678163

Epoch: 6| Step: 4
Training loss: 2.6845475768635296
Validation loss: 2.6739557331169603

Epoch: 6| Step: 5
Training loss: 2.2382530223937236
Validation loss: 2.6207276592303606

Epoch: 6| Step: 6
Training loss: 2.181971512088421
Validation loss: 2.569848770911831

Epoch: 6| Step: 7
Training loss: 2.1856535611946803
Validation loss: 2.511725016917371

Epoch: 6| Step: 8
Training loss: 2.9746658009257554
Validation loss: 2.482434480318405

Epoch: 6| Step: 9
Training loss: 2.7746254539319235
Validation loss: 2.456477005756701

Epoch: 6| Step: 10
Training loss: 2.672843177679121
Validation loss: 2.459094429421984

Epoch: 6| Step: 11
Training loss: 2.1990764023023033
Validation loss: 2.449984498986803

Epoch: 6| Step: 12
Training loss: 2.2578853608621077
Validation loss: 2.4724440439604396

Epoch: 6| Step: 13
Training loss: 2.0909300075585477
Validation loss: 2.4711378280700917

Epoch: 410| Step: 0
Training loss: 2.3700098517168886
Validation loss: 2.5082387121481666

Epoch: 6| Step: 1
Training loss: 2.4027387092760857
Validation loss: 2.5302051193918103

Epoch: 6| Step: 2
Training loss: 2.928637181517505
Validation loss: 2.575185958642045

Epoch: 6| Step: 3
Training loss: 2.282643558796711
Validation loss: 2.6523652828628674

Epoch: 6| Step: 4
Training loss: 2.6687080397869556
Validation loss: 2.704850825181731

Epoch: 6| Step: 5
Training loss: 2.7413989723872123
Validation loss: 2.7155344108966295

Epoch: 6| Step: 6
Training loss: 2.212936414361047
Validation loss: 2.6922793177610798

Epoch: 6| Step: 7
Training loss: 2.523102634756973
Validation loss: 2.6586250404994094

Epoch: 6| Step: 8
Training loss: 2.9656317145027384
Validation loss: 2.639369212853358

Epoch: 6| Step: 9
Training loss: 2.2617545907404173
Validation loss: 2.6209409361195015

Epoch: 6| Step: 10
Training loss: 2.32924916821324
Validation loss: 2.6033555055059363

Epoch: 6| Step: 11
Training loss: 1.9355329557316736
Validation loss: 2.557691278511228

Epoch: 6| Step: 12
Training loss: 1.7076067270907307
Validation loss: 2.5189316635434333

Epoch: 6| Step: 13
Training loss: 2.2724618817480313
Validation loss: 2.5244747442810396

Epoch: 411| Step: 0
Training loss: 2.705800050327724
Validation loss: 2.4961239495200465

Epoch: 6| Step: 1
Training loss: 2.4932879944961304
Validation loss: 2.5011306554226764

Epoch: 6| Step: 2
Training loss: 2.4536545297372343
Validation loss: 2.4873755397445567

Epoch: 6| Step: 3
Training loss: 2.2824887609466242
Validation loss: 2.505615533520845

Epoch: 6| Step: 4
Training loss: 2.1370034873694745
Validation loss: 2.5226115706919296

Epoch: 6| Step: 5
Training loss: 2.9217561911841066
Validation loss: 2.5416391510048126

Epoch: 6| Step: 6
Training loss: 1.8597957872245605
Validation loss: 2.5996683015632893

Epoch: 6| Step: 7
Training loss: 2.2326143170143826
Validation loss: 2.631743561135661

Epoch: 6| Step: 8
Training loss: 2.439074667900863
Validation loss: 2.653308262014251

Epoch: 6| Step: 9
Training loss: 2.091761313598281
Validation loss: 2.667343884916809

Epoch: 6| Step: 10
Training loss: 2.7706624506599185
Validation loss: 2.669317804859182

Epoch: 6| Step: 11
Training loss: 2.542161476456913
Validation loss: 2.646080728026272

Epoch: 6| Step: 12
Training loss: 1.8165065286499604
Validation loss: 2.6197637542103354

Epoch: 6| Step: 13
Training loss: 2.4492889345568494
Validation loss: 2.588131279307414

Epoch: 412| Step: 0
Training loss: 1.466194201722373
Validation loss: 2.529954424521403

Epoch: 6| Step: 1
Training loss: 2.496729810024043
Validation loss: 2.530698325441449

Epoch: 6| Step: 2
Training loss: 2.0388403292817374
Validation loss: 2.5385568493590904

Epoch: 6| Step: 3
Training loss: 2.7649062779910314
Validation loss: 2.5352844684171796

Epoch: 6| Step: 4
Training loss: 2.919478305564225
Validation loss: 2.533387267669845

Epoch: 6| Step: 5
Training loss: 2.498662400038804
Validation loss: 2.531478278043801

Epoch: 6| Step: 6
Training loss: 2.207821864751459
Validation loss: 2.5555773993895077

Epoch: 6| Step: 7
Training loss: 2.597986094248898
Validation loss: 2.576738530526036

Epoch: 6| Step: 8
Training loss: 2.389768359718228
Validation loss: 2.5978007723346517

Epoch: 6| Step: 9
Training loss: 2.5858458534435105
Validation loss: 2.5970561254981597

Epoch: 6| Step: 10
Training loss: 2.1325287682581755
Validation loss: 2.604274392801887

Epoch: 6| Step: 11
Training loss: 2.8164551792841483
Validation loss: 2.6036513621445

Epoch: 6| Step: 12
Training loss: 1.6084387565149854
Validation loss: 2.567212761086164

Epoch: 6| Step: 13
Training loss: 1.59695322102713
Validation loss: 2.557387597782765

Epoch: 413| Step: 0
Training loss: 2.9030236825006557
Validation loss: 2.5462229910953322

Epoch: 6| Step: 1
Training loss: 2.0490924966468578
Validation loss: 2.520271774331275

Epoch: 6| Step: 2
Training loss: 2.4137466372165735
Validation loss: 2.5380396860423313

Epoch: 6| Step: 3
Training loss: 2.283838762835263
Validation loss: 2.5182734602184507

Epoch: 6| Step: 4
Training loss: 2.073415252175232
Validation loss: 2.530518163057448

Epoch: 6| Step: 5
Training loss: 2.322789267109833
Validation loss: 2.542140460289302

Epoch: 6| Step: 6
Training loss: 2.291671151821487
Validation loss: 2.5734582073439674

Epoch: 6| Step: 7
Training loss: 2.0613282082770734
Validation loss: 2.585988256054687

Epoch: 6| Step: 8
Training loss: 2.260372202446161
Validation loss: 2.613078462618212

Epoch: 6| Step: 9
Training loss: 1.5294764621565824
Validation loss: 2.595339291510908

Epoch: 6| Step: 10
Training loss: 2.8747483848264026
Validation loss: 2.5746326626959775

Epoch: 6| Step: 11
Training loss: 2.941885413951121
Validation loss: 2.5537385402646366

Epoch: 6| Step: 12
Training loss: 2.0388719023858215
Validation loss: 2.5409386363930384

Epoch: 6| Step: 13
Training loss: 2.7035769928117066
Validation loss: 2.5344218934505434

Epoch: 414| Step: 0
Training loss: 2.685186055306285
Validation loss: 2.520621055289797

Epoch: 6| Step: 1
Training loss: 1.7554143526267407
Validation loss: 2.5491291672225422

Epoch: 6| Step: 2
Training loss: 2.043768819086533
Validation loss: 2.5789909387681482

Epoch: 6| Step: 3
Training loss: 2.3115084816465368
Validation loss: 2.595939254937021

Epoch: 6| Step: 4
Training loss: 2.27272069583288
Validation loss: 2.6072001952098502

Epoch: 6| Step: 5
Training loss: 2.7617710653527086
Validation loss: 2.6203820293995603

Epoch: 6| Step: 6
Training loss: 2.428297816819512
Validation loss: 2.5905356397901502

Epoch: 6| Step: 7
Training loss: 2.4958919151024506
Validation loss: 2.5644062324327024

Epoch: 6| Step: 8
Training loss: 2.0604384551971044
Validation loss: 2.560421118154212

Epoch: 6| Step: 9
Training loss: 2.400865847645364
Validation loss: 2.558657439590742

Epoch: 6| Step: 10
Training loss: 2.5715984617605163
Validation loss: 2.537745386222037

Epoch: 6| Step: 11
Training loss: 2.153064420204953
Validation loss: 2.5344501837290125

Epoch: 6| Step: 12
Training loss: 2.480560445217066
Validation loss: 2.5336849240143575

Epoch: 6| Step: 13
Training loss: 2.4239961256997145
Validation loss: 2.5016087862357237

Epoch: 415| Step: 0
Training loss: 2.5863025787894065
Validation loss: 2.492396971786164

Epoch: 6| Step: 1
Training loss: 2.5247750059295195
Validation loss: 2.497722585152223

Epoch: 6| Step: 2
Training loss: 2.226944525888941
Validation loss: 2.5037784858335494

Epoch: 6| Step: 3
Training loss: 1.9321347058922307
Validation loss: 2.50606611993637

Epoch: 6| Step: 4
Training loss: 2.008175828173507
Validation loss: 2.569161317483201

Epoch: 6| Step: 5
Training loss: 1.9587523911588738
Validation loss: 2.5823402090244443

Epoch: 6| Step: 6
Training loss: 2.5580602191520727
Validation loss: 2.630624292102675

Epoch: 6| Step: 7
Training loss: 2.3863626017712747
Validation loss: 2.612570508792527

Epoch: 6| Step: 8
Training loss: 2.612938281078196
Validation loss: 2.6243236234836935

Epoch: 6| Step: 9
Training loss: 2.5612186857052754
Validation loss: 2.610666447780621

Epoch: 6| Step: 10
Training loss: 2.07111386318506
Validation loss: 2.5794180502747377

Epoch: 6| Step: 11
Training loss: 2.5350983176643482
Validation loss: 2.5616338382980075

Epoch: 6| Step: 12
Training loss: 2.082698636330213
Validation loss: 2.559254916340664

Epoch: 6| Step: 13
Training loss: 2.7949321114854473
Validation loss: 2.524915304055965

Epoch: 416| Step: 0
Training loss: 2.798174678658857
Validation loss: 2.529338190144595

Epoch: 6| Step: 1
Training loss: 1.879106284931475
Validation loss: 2.504522427254823

Epoch: 6| Step: 2
Training loss: 2.0292080519239923
Validation loss: 2.513172073484649

Epoch: 6| Step: 3
Training loss: 2.6106405330138323
Validation loss: 2.5357236717784772

Epoch: 6| Step: 4
Training loss: 1.4056791206413037
Validation loss: 2.552981436144708

Epoch: 6| Step: 5
Training loss: 2.3045849793471427
Validation loss: 2.590713084586147

Epoch: 6| Step: 6
Training loss: 1.9206834526365695
Validation loss: 2.5716219138553305

Epoch: 6| Step: 7
Training loss: 2.4385397234135873
Validation loss: 2.5929394298159893

Epoch: 6| Step: 8
Training loss: 2.4622953997975663
Validation loss: 2.612271510072516

Epoch: 6| Step: 9
Training loss: 2.7102423664397564
Validation loss: 2.639730112662376

Epoch: 6| Step: 10
Training loss: 2.424801442777481
Validation loss: 2.63315152991521

Epoch: 6| Step: 11
Training loss: 2.322498665964259
Validation loss: 2.609404350235067

Epoch: 6| Step: 12
Training loss: 2.1485109628775416
Validation loss: 2.5812520552419462

Epoch: 6| Step: 13
Training loss: 3.0219855555574795
Validation loss: 2.5729857839808234

Epoch: 417| Step: 0
Training loss: 2.4303378004591916
Validation loss: 2.58588112469556

Epoch: 6| Step: 1
Training loss: 2.1706056247223198
Validation loss: 2.582025036565364

Epoch: 6| Step: 2
Training loss: 2.0575395523292896
Validation loss: 2.5987716220735404

Epoch: 6| Step: 3
Training loss: 2.340808293865162
Validation loss: 2.6093751748801983

Epoch: 6| Step: 4
Training loss: 2.3042053752864615
Validation loss: 2.5813786047623632

Epoch: 6| Step: 5
Training loss: 2.5564677250669687
Validation loss: 2.5844176223620234

Epoch: 6| Step: 6
Training loss: 2.101310175953661
Validation loss: 2.573562110337428

Epoch: 6| Step: 7
Training loss: 2.2704201301953866
Validation loss: 2.597846449288992

Epoch: 6| Step: 8
Training loss: 2.4026189382845877
Validation loss: 2.5695506255665035

Epoch: 6| Step: 9
Training loss: 2.754671550494675
Validation loss: 2.587571968431949

Epoch: 6| Step: 10
Training loss: 1.9440773102650402
Validation loss: 2.588997096883537

Epoch: 6| Step: 11
Training loss: 2.2960345748331723
Validation loss: 2.559955569229081

Epoch: 6| Step: 12
Training loss: 2.1368241920467077
Validation loss: 2.573368591963602

Epoch: 6| Step: 13
Training loss: 2.5291028747390216
Validation loss: 2.5577387572539396

Epoch: 418| Step: 0
Training loss: 2.4108045006074064
Validation loss: 2.496071414403695

Epoch: 6| Step: 1
Training loss: 2.698411304587495
Validation loss: 2.4623820695403187

Epoch: 6| Step: 2
Training loss: 2.019103368296243
Validation loss: 2.472467296520137

Epoch: 6| Step: 3
Training loss: 2.4252669669213414
Validation loss: 2.4642408013234456

Epoch: 6| Step: 4
Training loss: 2.384008088885416
Validation loss: 2.4741105396920546

Epoch: 6| Step: 5
Training loss: 2.242220356663933
Validation loss: 2.522013039803596

Epoch: 6| Step: 6
Training loss: 2.2890935381454804
Validation loss: 2.5759727953841356

Epoch: 6| Step: 7
Training loss: 1.929876526751984
Validation loss: 2.630961390130272

Epoch: 6| Step: 8
Training loss: 2.3463379876654726
Validation loss: 2.691208345443028

Epoch: 6| Step: 9
Training loss: 2.64747912866076
Validation loss: 2.7004819884150546

Epoch: 6| Step: 10
Training loss: 2.3192299523481705
Validation loss: 2.7014824517249636

Epoch: 6| Step: 11
Training loss: 2.2880665562159304
Validation loss: 2.6722346286123115

Epoch: 6| Step: 12
Training loss: 2.3439981964937635
Validation loss: 2.634776360144425

Epoch: 6| Step: 13
Training loss: 2.5286433609159085
Validation loss: 2.5981309485231776

Epoch: 419| Step: 0
Training loss: 1.6615332782866932
Validation loss: 2.5294832621562566

Epoch: 6| Step: 1
Training loss: 2.267420090483838
Validation loss: 2.482869443354854

Epoch: 6| Step: 2
Training loss: 1.8775810279072969
Validation loss: 2.45475746860757

Epoch: 6| Step: 3
Training loss: 2.5386594481779636
Validation loss: 2.437105754335631

Epoch: 6| Step: 4
Training loss: 2.3033969175153337
Validation loss: 2.443406674781619

Epoch: 6| Step: 5
Training loss: 2.6254196739774875
Validation loss: 2.4550427173473333

Epoch: 6| Step: 6
Training loss: 2.1693185813994633
Validation loss: 2.479506350339193

Epoch: 6| Step: 7
Training loss: 2.202901625976627
Validation loss: 2.498564424880637

Epoch: 6| Step: 8
Training loss: 2.2332585886883307
Validation loss: 2.513858256038852

Epoch: 6| Step: 9
Training loss: 2.3598610080587283
Validation loss: 2.554906259652149

Epoch: 6| Step: 10
Training loss: 2.8237975506876
Validation loss: 2.5561455895122442

Epoch: 6| Step: 11
Training loss: 2.322373216862104
Validation loss: 2.6055887128902304

Epoch: 6| Step: 12
Training loss: 2.655637872511652
Validation loss: 2.664518225504119

Epoch: 6| Step: 13
Training loss: 2.1456787152432333
Validation loss: 2.6922953987945246

Epoch: 420| Step: 0
Training loss: 2.681341167047111
Validation loss: 2.722943348961021

Epoch: 6| Step: 1
Training loss: 2.3523301807368204
Validation loss: 2.723866933727096

Epoch: 6| Step: 2
Training loss: 2.198952260649762
Validation loss: 2.665754139673165

Epoch: 6| Step: 3
Training loss: 1.6067392932469236
Validation loss: 2.615266834540286

Epoch: 6| Step: 4
Training loss: 2.773380848480604
Validation loss: 2.5836752831613556

Epoch: 6| Step: 5
Training loss: 2.395112954902533
Validation loss: 2.549684298937166

Epoch: 6| Step: 6
Training loss: 2.188640406210612
Validation loss: 2.5008812499665907

Epoch: 6| Step: 7
Training loss: 2.818985645399729
Validation loss: 2.490298532250246

Epoch: 6| Step: 8
Training loss: 2.3500389664036896
Validation loss: 2.511123157163723

Epoch: 6| Step: 9
Training loss: 2.2826416787238566
Validation loss: 2.4903755762104103

Epoch: 6| Step: 10
Training loss: 1.85234021299516
Validation loss: 2.520990785952651

Epoch: 6| Step: 11
Training loss: 2.242949565618061
Validation loss: 2.4914745733618355

Epoch: 6| Step: 12
Training loss: 2.2533338008218013
Validation loss: 2.5125867589987667

Epoch: 6| Step: 13
Training loss: 2.2475415680195074
Validation loss: 2.517104163224166

Epoch: 421| Step: 0
Training loss: 2.372259868210947
Validation loss: 2.5699210917589186

Epoch: 6| Step: 1
Training loss: 2.2195243021645807
Validation loss: 2.5875703762939066

Epoch: 6| Step: 2
Training loss: 2.0332608173551177
Validation loss: 2.628127958735925

Epoch: 6| Step: 3
Training loss: 2.2918993976210906
Validation loss: 2.621276566427938

Epoch: 6| Step: 4
Training loss: 2.1926814158426744
Validation loss: 2.6706220635578206

Epoch: 6| Step: 5
Training loss: 2.4449247107586105
Validation loss: 2.686069845371188

Epoch: 6| Step: 6
Training loss: 2.350277267494272
Validation loss: 2.648644289730583

Epoch: 6| Step: 7
Training loss: 1.8202720277404598
Validation loss: 2.630141086910692

Epoch: 6| Step: 8
Training loss: 2.99914109332463
Validation loss: 2.6318237185078033

Epoch: 6| Step: 9
Training loss: 2.0948103312213027
Validation loss: 2.590156575506877

Epoch: 6| Step: 10
Training loss: 1.9660185985364584
Validation loss: 2.562720684690249

Epoch: 6| Step: 11
Training loss: 2.249541871796364
Validation loss: 2.5457321009376845

Epoch: 6| Step: 12
Training loss: 2.5306538951351865
Validation loss: 2.549885513442835

Epoch: 6| Step: 13
Training loss: 2.02085576258007
Validation loss: 2.5349450496720873

Epoch: 422| Step: 0
Training loss: 2.3946112017328827
Validation loss: 2.525725448770141

Epoch: 6| Step: 1
Training loss: 1.7250997984392658
Validation loss: 2.5243128924892684

Epoch: 6| Step: 2
Training loss: 2.0864430932795988
Validation loss: 2.5201041491521634

Epoch: 6| Step: 3
Training loss: 2.751364456146156
Validation loss: 2.5136862414815497

Epoch: 6| Step: 4
Training loss: 2.3910998701794877
Validation loss: 2.533517971769107

Epoch: 6| Step: 5
Training loss: 2.7943491692182096
Validation loss: 2.536200566605132

Epoch: 6| Step: 6
Training loss: 1.8296763692593825
Validation loss: 2.533505412163533

Epoch: 6| Step: 7
Training loss: 1.7518613997553107
Validation loss: 2.53442401766005

Epoch: 6| Step: 8
Training loss: 2.8359193407218193
Validation loss: 2.5044208733852016

Epoch: 6| Step: 9
Training loss: 2.622481091252063
Validation loss: 2.51915883425395

Epoch: 6| Step: 10
Training loss: 2.233925087187575
Validation loss: 2.5170467096547755

Epoch: 6| Step: 11
Training loss: 2.2220563296809988
Validation loss: 2.5697064855229073

Epoch: 6| Step: 12
Training loss: 1.7554689510058434
Validation loss: 2.640768946348941

Epoch: 6| Step: 13
Training loss: 2.44368428876097
Validation loss: 2.655471795857354

Epoch: 423| Step: 0
Training loss: 2.3220587430517043
Validation loss: 2.693377839633676

Epoch: 6| Step: 1
Training loss: 2.038152849883871
Validation loss: 2.6951242099056456

Epoch: 6| Step: 2
Training loss: 2.5965259817826327
Validation loss: 2.660679933927159

Epoch: 6| Step: 3
Training loss: 1.5033216256632402
Validation loss: 2.647865369372208

Epoch: 6| Step: 4
Training loss: 2.3827548661062736
Validation loss: 2.621810253491346

Epoch: 6| Step: 5
Training loss: 1.6940755946419062
Validation loss: 2.607623523367052

Epoch: 6| Step: 6
Training loss: 2.9503528965795716
Validation loss: 2.6037233555331647

Epoch: 6| Step: 7
Training loss: 2.823903848443049
Validation loss: 2.5792019570698366

Epoch: 6| Step: 8
Training loss: 1.9608143923593506
Validation loss: 2.5739382002557427

Epoch: 6| Step: 9
Training loss: 2.0268704664924826
Validation loss: 2.5580483192212258

Epoch: 6| Step: 10
Training loss: 2.2627214439308934
Validation loss: 2.5451921340870367

Epoch: 6| Step: 11
Training loss: 2.346742982363995
Validation loss: 2.534399419204905

Epoch: 6| Step: 12
Training loss: 2.4119419302331666
Validation loss: 2.507884815793565

Epoch: 6| Step: 13
Training loss: 2.2879234839162814
Validation loss: 2.517535639280868

Epoch: 424| Step: 0
Training loss: 2.1837446402891754
Validation loss: 2.5356210845948013

Epoch: 6| Step: 1
Training loss: 2.8331353922497016
Validation loss: 2.5801415167624673

Epoch: 6| Step: 2
Training loss: 2.5396982189434327
Validation loss: 2.6589608322255365

Epoch: 6| Step: 3
Training loss: 1.4156069251247614
Validation loss: 2.6986617789085408

Epoch: 6| Step: 4
Training loss: 2.176333016746351
Validation loss: 2.7212756595080774

Epoch: 6| Step: 5
Training loss: 2.6123154570455576
Validation loss: 2.7152097436290976

Epoch: 6| Step: 6
Training loss: 1.818264771324778
Validation loss: 2.6309565287837717

Epoch: 6| Step: 7
Training loss: 2.058421755704873
Validation loss: 2.5969089269158725

Epoch: 6| Step: 8
Training loss: 2.527327524218587
Validation loss: 2.542527591768038

Epoch: 6| Step: 9
Training loss: 2.039843296502427
Validation loss: 2.4952788597328337

Epoch: 6| Step: 10
Training loss: 2.3056285941058983
Validation loss: 2.4834285023566065

Epoch: 6| Step: 11
Training loss: 2.8369453257743804
Validation loss: 2.455379475061982

Epoch: 6| Step: 12
Training loss: 2.1881272642793466
Validation loss: 2.4689558220379904

Epoch: 6| Step: 13
Training loss: 2.1432441225762218
Validation loss: 2.458564810668234

Epoch: 425| Step: 0
Training loss: 2.045007217506413
Validation loss: 2.4768586397538557

Epoch: 6| Step: 1
Training loss: 2.079034362538348
Validation loss: 2.4854718015698656

Epoch: 6| Step: 2
Training loss: 2.5664781534233856
Validation loss: 2.524772028793435

Epoch: 6| Step: 3
Training loss: 2.445641638691643
Validation loss: 2.5422335503059728

Epoch: 6| Step: 4
Training loss: 2.2858270166049985
Validation loss: 2.607996402971525

Epoch: 6| Step: 5
Training loss: 1.9356626597243065
Validation loss: 2.6278900218972954

Epoch: 6| Step: 6
Training loss: 2.289905379893402
Validation loss: 2.630145509193528

Epoch: 6| Step: 7
Training loss: 1.916134207475016
Validation loss: 2.653221002574324

Epoch: 6| Step: 8
Training loss: 2.2534516667814875
Validation loss: 2.6713414364972365

Epoch: 6| Step: 9
Training loss: 2.1651355272826374
Validation loss: 2.6857681895000516

Epoch: 6| Step: 10
Training loss: 2.4188333423065767
Validation loss: 2.661571735221475

Epoch: 6| Step: 11
Training loss: 2.291345388837852
Validation loss: 2.6444109344947315

Epoch: 6| Step: 12
Training loss: 2.4728747327077754
Validation loss: 2.620938985712585

Epoch: 6| Step: 13
Training loss: 2.579408083593316
Validation loss: 2.560031427147578

Epoch: 426| Step: 0
Training loss: 1.802835414117303
Validation loss: 2.5178258785693837

Epoch: 6| Step: 1
Training loss: 2.3824669759408996
Validation loss: 2.5247532317331194

Epoch: 6| Step: 2
Training loss: 2.465604202318169
Validation loss: 2.5242840463097562

Epoch: 6| Step: 3
Training loss: 2.1513645277729814
Validation loss: 2.4978550353799487

Epoch: 6| Step: 4
Training loss: 2.2448867341081176
Validation loss: 2.488152957575611

Epoch: 6| Step: 5
Training loss: 2.0464361754157028
Validation loss: 2.495933660970675

Epoch: 6| Step: 6
Training loss: 2.537494163318555
Validation loss: 2.4997217197792527

Epoch: 6| Step: 7
Training loss: 2.275332784940823
Validation loss: 2.515218166950923

Epoch: 6| Step: 8
Training loss: 2.060490640894391
Validation loss: 2.556246540664862

Epoch: 6| Step: 9
Training loss: 2.411691631020086
Validation loss: 2.5852576913957983

Epoch: 6| Step: 10
Training loss: 2.3749145693220988
Validation loss: 2.6605093935730575

Epoch: 6| Step: 11
Training loss: 1.96729794192994
Validation loss: 2.674862136753713

Epoch: 6| Step: 12
Training loss: 2.5195034291705283
Validation loss: 2.710561941621701

Epoch: 6| Step: 13
Training loss: 2.3722756470861595
Validation loss: 2.7591423944572218

Epoch: 427| Step: 0
Training loss: 2.0360833983062676
Validation loss: 2.7802349900949364

Epoch: 6| Step: 1
Training loss: 2.2023364881251664
Validation loss: 2.775854891746405

Epoch: 6| Step: 2
Training loss: 2.286822997422255
Validation loss: 2.729030400637759

Epoch: 6| Step: 3
Training loss: 2.1227858733022513
Validation loss: 2.702060102520607

Epoch: 6| Step: 4
Training loss: 2.643566772748973
Validation loss: 2.663787379156725

Epoch: 6| Step: 5
Training loss: 2.5737987864586986
Validation loss: 2.6259278192478974

Epoch: 6| Step: 6
Training loss: 2.5793239695494976
Validation loss: 2.568221057860719

Epoch: 6| Step: 7
Training loss: 1.7800150153780483
Validation loss: 2.507202973954862

Epoch: 6| Step: 8
Training loss: 2.032362647864323
Validation loss: 2.5205132540473447

Epoch: 6| Step: 9
Training loss: 1.8698336314076358
Validation loss: 2.534593992145237

Epoch: 6| Step: 10
Training loss: 2.4381354066205687
Validation loss: 2.559334874881901

Epoch: 6| Step: 11
Training loss: 2.211760997739269
Validation loss: 2.576907918509972

Epoch: 6| Step: 12
Training loss: 2.5491329551613426
Validation loss: 2.625973410148719

Epoch: 6| Step: 13
Training loss: 1.8750058491933506
Validation loss: 2.64909547006244

Epoch: 428| Step: 0
Training loss: 1.5147381577029633
Validation loss: 2.628874246549711

Epoch: 6| Step: 1
Training loss: 2.544986797216078
Validation loss: 2.6194242980960847

Epoch: 6| Step: 2
Training loss: 2.048561973485353
Validation loss: 2.6114042851773176

Epoch: 6| Step: 3
Training loss: 2.5494459784545556
Validation loss: 2.593647680674865

Epoch: 6| Step: 4
Training loss: 2.1312838375504124
Validation loss: 2.58715811332379

Epoch: 6| Step: 5
Training loss: 2.1114372062912126
Validation loss: 2.595957849600418

Epoch: 6| Step: 6
Training loss: 2.14026042868764
Validation loss: 2.5882134787325763

Epoch: 6| Step: 7
Training loss: 2.4771926030173446
Validation loss: 2.605139135764525

Epoch: 6| Step: 8
Training loss: 2.480387240294629
Validation loss: 2.58245431219976

Epoch: 6| Step: 9
Training loss: 2.034981220355536
Validation loss: 2.5863660667852377

Epoch: 6| Step: 10
Training loss: 2.3135489069656328
Validation loss: 2.601057601831865

Epoch: 6| Step: 11
Training loss: 2.58559781981178
Validation loss: 2.596417345029219

Epoch: 6| Step: 12
Training loss: 2.1757503486781173
Validation loss: 2.5881678259145415

Epoch: 6| Step: 13
Training loss: 1.5317104192357593
Validation loss: 2.5784849261796903

Epoch: 429| Step: 0
Training loss: 2.4447324997306468
Validation loss: 2.559380550188938

Epoch: 6| Step: 1
Training loss: 1.9215997018034081
Validation loss: 2.55866884072688

Epoch: 6| Step: 2
Training loss: 1.8840824134117233
Validation loss: 2.5827906657517037

Epoch: 6| Step: 3
Training loss: 1.6377954696937334
Validation loss: 2.574936185325414

Epoch: 6| Step: 4
Training loss: 2.521344713617413
Validation loss: 2.586151296622369

Epoch: 6| Step: 5
Training loss: 2.323213144949041
Validation loss: 2.578524531546154

Epoch: 6| Step: 6
Training loss: 2.2007773586532644
Validation loss: 2.56671567951843

Epoch: 6| Step: 7
Training loss: 2.308730687761316
Validation loss: 2.5938182890514083

Epoch: 6| Step: 8
Training loss: 2.5016423552787006
Validation loss: 2.585522999543945

Epoch: 6| Step: 9
Training loss: 2.65391527679139
Validation loss: 2.5451921854567034

Epoch: 6| Step: 10
Training loss: 1.9974166159479085
Validation loss: 2.59047288735427

Epoch: 6| Step: 11
Training loss: 2.2741367798385186
Validation loss: 2.5803332077759844

Epoch: 6| Step: 12
Training loss: 2.3302594327773574
Validation loss: 2.5917879895724703

Epoch: 6| Step: 13
Training loss: 1.5367338116775073
Validation loss: 2.6087896358427627

Epoch: 430| Step: 0
Training loss: 2.0518977150660462
Validation loss: 2.6039750538545277

Epoch: 6| Step: 1
Training loss: 1.6245451804207076
Validation loss: 2.641932868982519

Epoch: 6| Step: 2
Training loss: 1.7908044854928276
Validation loss: 2.669755521159142

Epoch: 6| Step: 3
Training loss: 2.9444122152743883
Validation loss: 2.6704595030965517

Epoch: 6| Step: 4
Training loss: 2.2097283281803657
Validation loss: 2.675477619637374

Epoch: 6| Step: 5
Training loss: 2.4163658239841506
Validation loss: 2.6685577536591216

Epoch: 6| Step: 6
Training loss: 2.504795624700945
Validation loss: 2.676118540795007

Epoch: 6| Step: 7
Training loss: 2.3183203985574194
Validation loss: 2.6379498248870994

Epoch: 6| Step: 8
Training loss: 2.6614411733612853
Validation loss: 2.627767062528666

Epoch: 6| Step: 9
Training loss: 2.0827760205290136
Validation loss: 2.578077469105133

Epoch: 6| Step: 10
Training loss: 1.9834114799277296
Validation loss: 2.5492272007662695

Epoch: 6| Step: 11
Training loss: 1.967268128746272
Validation loss: 2.5447583356798305

Epoch: 6| Step: 12
Training loss: 2.2760012089838395
Validation loss: 2.5562750216519916

Epoch: 6| Step: 13
Training loss: 1.503296646818036
Validation loss: 2.5729197712647407

Epoch: 431| Step: 0
Training loss: 2.359405921581831
Validation loss: 2.609731084853198

Epoch: 6| Step: 1
Training loss: 1.620864006216422
Validation loss: 2.6371981486308202

Epoch: 6| Step: 2
Training loss: 2.4162388346138295
Validation loss: 2.647718671715975

Epoch: 6| Step: 3
Training loss: 1.7785121556580619
Validation loss: 2.6442294101896606

Epoch: 6| Step: 4
Training loss: 2.4176783472053627
Validation loss: 2.6945635211059513

Epoch: 6| Step: 5
Training loss: 2.3554624744034354
Validation loss: 2.643961705582997

Epoch: 6| Step: 6
Training loss: 2.0949555527517454
Validation loss: 2.6486176063434193

Epoch: 6| Step: 7
Training loss: 2.7392675607001236
Validation loss: 2.6709207211001096

Epoch: 6| Step: 8
Training loss: 1.9149246453979567
Validation loss: 2.6365252009262186

Epoch: 6| Step: 9
Training loss: 2.546709207392517
Validation loss: 2.6280027931686636

Epoch: 6| Step: 10
Training loss: 1.3703794874044566
Validation loss: 2.634065409960849

Epoch: 6| Step: 11
Training loss: 1.8739318348182812
Validation loss: 2.5849666539532237

Epoch: 6| Step: 12
Training loss: 2.3774880878458933
Validation loss: 2.5722088967262393

Epoch: 6| Step: 13
Training loss: 2.817986794824572
Validation loss: 2.5653790983048266

Epoch: 432| Step: 0
Training loss: 1.9104586558856458
Validation loss: 2.558730835206251

Epoch: 6| Step: 1
Training loss: 3.081402732669542
Validation loss: 2.559854958633668

Epoch: 6| Step: 2
Training loss: 1.9575518069957034
Validation loss: 2.566463489611815

Epoch: 6| Step: 3
Training loss: 2.1334593075075916
Validation loss: 2.5534410338797935

Epoch: 6| Step: 4
Training loss: 1.6499000316738017
Validation loss: 2.605079607674316

Epoch: 6| Step: 5
Training loss: 2.2989734224539564
Validation loss: 2.6073399389744094

Epoch: 6| Step: 6
Training loss: 1.990562344557638
Validation loss: 2.6224597128384057

Epoch: 6| Step: 7
Training loss: 2.03642985786634
Validation loss: 2.6070819810945496

Epoch: 6| Step: 8
Training loss: 2.4022348766932664
Validation loss: 2.5937296973692945

Epoch: 6| Step: 9
Training loss: 2.4585875902319962
Validation loss: 2.6138884751857305

Epoch: 6| Step: 10
Training loss: 1.8704776904487015
Validation loss: 2.6300716764674776

Epoch: 6| Step: 11
Training loss: 2.622312987053432
Validation loss: 2.657163536495121

Epoch: 6| Step: 12
Training loss: 1.7265216252938802
Validation loss: 2.6686856858364494

Epoch: 6| Step: 13
Training loss: 2.061913609231384
Validation loss: 2.695359886719481

Epoch: 433| Step: 0
Training loss: 2.087065887997671
Validation loss: 2.7043269345424004

Epoch: 6| Step: 1
Training loss: 2.7976066442212737
Validation loss: 2.7103197718448686

Epoch: 6| Step: 2
Training loss: 2.361130825284547
Validation loss: 2.721183149182016

Epoch: 6| Step: 3
Training loss: 2.4836867236758193
Validation loss: 2.6855377088522703

Epoch: 6| Step: 4
Training loss: 2.545642203374248
Validation loss: 2.65943491716534

Epoch: 6| Step: 5
Training loss: 2.0344239306681615
Validation loss: 2.656722474709834

Epoch: 6| Step: 6
Training loss: 1.8996037170338447
Validation loss: 2.6648278825014464

Epoch: 6| Step: 7
Training loss: 2.2799019161676606
Validation loss: 2.6638881092312126

Epoch: 6| Step: 8
Training loss: 2.1496627365662375
Validation loss: 2.645374123725118

Epoch: 6| Step: 9
Training loss: 1.9110854059654276
Validation loss: 2.6185854282778047

Epoch: 6| Step: 10
Training loss: 1.6854293269501983
Validation loss: 2.5980223270765004

Epoch: 6| Step: 11
Training loss: 1.9547822558811287
Validation loss: 2.611870238571268

Epoch: 6| Step: 12
Training loss: 1.9051080003296197
Validation loss: 2.563686021348588

Epoch: 6| Step: 13
Training loss: 2.441798406004559
Validation loss: 2.571822555354761

Epoch: 434| Step: 0
Training loss: 2.2840982710479425
Validation loss: 2.591038594979756

Epoch: 6| Step: 1
Training loss: 2.424266200779867
Validation loss: 2.618130998491066

Epoch: 6| Step: 2
Training loss: 1.9422622727649463
Validation loss: 2.622040593669811

Epoch: 6| Step: 3
Training loss: 2.1458322716373917
Validation loss: 2.6393494971683675

Epoch: 6| Step: 4
Training loss: 2.6834939774313638
Validation loss: 2.702680642410172

Epoch: 6| Step: 5
Training loss: 2.3164515370256877
Validation loss: 2.720919130250214

Epoch: 6| Step: 6
Training loss: 1.6492907589254258
Validation loss: 2.711957393969189

Epoch: 6| Step: 7
Training loss: 2.146685631630725
Validation loss: 2.7003362684752275

Epoch: 6| Step: 8
Training loss: 1.9318637699725159
Validation loss: 2.676667298701127

Epoch: 6| Step: 9
Training loss: 2.5189092770329884
Validation loss: 2.6715785199499353

Epoch: 6| Step: 10
Training loss: 2.1312545284100075
Validation loss: 2.6646485177770707

Epoch: 6| Step: 11
Training loss: 2.0956605762951206
Validation loss: 2.663314846740658

Epoch: 6| Step: 12
Training loss: 1.953871317371595
Validation loss: 2.652438875838513

Epoch: 6| Step: 13
Training loss: 1.9187327803544234
Validation loss: 2.6470842576780513

Epoch: 435| Step: 0
Training loss: 1.9061443737345547
Validation loss: 2.6588205117226367

Epoch: 6| Step: 1
Training loss: 2.00810791692226
Validation loss: 2.6558913344038646

Epoch: 6| Step: 2
Training loss: 2.154135842413282
Validation loss: 2.662065458446709

Epoch: 6| Step: 3
Training loss: 1.99604615156602
Validation loss: 2.64884037843985

Epoch: 6| Step: 4
Training loss: 1.887240698984128
Validation loss: 2.645571478599291

Epoch: 6| Step: 5
Training loss: 1.9853873486537421
Validation loss: 2.6359575776737603

Epoch: 6| Step: 6
Training loss: 2.5860141155037644
Validation loss: 2.6282149275949673

Epoch: 6| Step: 7
Training loss: 1.9034550297652806
Validation loss: 2.6284647829352177

Epoch: 6| Step: 8
Training loss: 2.144297213543063
Validation loss: 2.642773583163742

Epoch: 6| Step: 9
Training loss: 2.122984547476609
Validation loss: 2.6278531536167646

Epoch: 6| Step: 10
Training loss: 2.0918312960374084
Validation loss: 2.591643225910036

Epoch: 6| Step: 11
Training loss: 2.2186038546718616
Validation loss: 2.6183781562219193

Epoch: 6| Step: 12
Training loss: 2.291047261077395
Validation loss: 2.6084803412594777

Epoch: 6| Step: 13
Training loss: 3.160454244438442
Validation loss: 2.6028718199357415

Epoch: 436| Step: 0
Training loss: 1.8262180261339116
Validation loss: 2.6222776915943444

Epoch: 6| Step: 1
Training loss: 0.8427371904660858
Validation loss: 2.6349250937792132

Epoch: 6| Step: 2
Training loss: 2.202729967562424
Validation loss: 2.634647873658829

Epoch: 6| Step: 3
Training loss: 2.0253030432486363
Validation loss: 2.639484003430952

Epoch: 6| Step: 4
Training loss: 2.5326946515877418
Validation loss: 2.6734290581766706

Epoch: 6| Step: 5
Training loss: 2.699021946402638
Validation loss: 2.6632624291961173

Epoch: 6| Step: 6
Training loss: 1.8249090877515926
Validation loss: 2.6529541144570237

Epoch: 6| Step: 7
Training loss: 2.2646530697451546
Validation loss: 2.6138576413493113

Epoch: 6| Step: 8
Training loss: 2.129779377646598
Validation loss: 2.5952615080997017

Epoch: 6| Step: 9
Training loss: 2.4854971792434895
Validation loss: 2.5864941050903725

Epoch: 6| Step: 10
Training loss: 2.375911236675168
Validation loss: 2.5846818205581417

Epoch: 6| Step: 11
Training loss: 2.0100465213079683
Validation loss: 2.6097396056478113

Epoch: 6| Step: 12
Training loss: 2.211596603012029
Validation loss: 2.6383226520805967

Epoch: 6| Step: 13
Training loss: 2.156578812890569
Validation loss: 2.6785038340761465

Epoch: 437| Step: 0
Training loss: 1.877411245592426
Validation loss: 2.6803361670905184

Epoch: 6| Step: 1
Training loss: 2.0373325536528357
Validation loss: 2.6912770431015867

Epoch: 6| Step: 2
Training loss: 1.8412106370829553
Validation loss: 2.7438490757295604

Epoch: 6| Step: 3
Training loss: 1.9101543777550256
Validation loss: 2.756119165083999

Epoch: 6| Step: 4
Training loss: 2.130523683170591
Validation loss: 2.7498417600894096

Epoch: 6| Step: 5
Training loss: 2.060809280536913
Validation loss: 2.747565223609177

Epoch: 6| Step: 6
Training loss: 2.3863866796660793
Validation loss: 2.7044467827650127

Epoch: 6| Step: 7
Training loss: 2.555208018992721
Validation loss: 2.676581206900262

Epoch: 6| Step: 8
Training loss: 2.117030852318688
Validation loss: 2.6478656114200616

Epoch: 6| Step: 9
Training loss: 2.7349315839784674
Validation loss: 2.597365457877282

Epoch: 6| Step: 10
Training loss: 2.0496127623494975
Validation loss: 2.574753071595511

Epoch: 6| Step: 11
Training loss: 2.073337173621903
Validation loss: 2.5356538965056816

Epoch: 6| Step: 12
Training loss: 2.036195573822897
Validation loss: 2.546348542027237

Epoch: 6| Step: 13
Training loss: 1.719606012974777
Validation loss: 2.5473191662706682

Epoch: 438| Step: 0
Training loss: 1.8087289977946888
Validation loss: 2.5315332612503707

Epoch: 6| Step: 1
Training loss: 2.0817405970170832
Validation loss: 2.516063672064926

Epoch: 6| Step: 2
Training loss: 1.9916094371388955
Validation loss: 2.526748288095724

Epoch: 6| Step: 3
Training loss: 1.889947186494061
Validation loss: 2.560867117461605

Epoch: 6| Step: 4
Training loss: 1.8262935495895671
Validation loss: 2.5895909642741928

Epoch: 6| Step: 5
Training loss: 2.2129047389981826
Validation loss: 2.6340571810021647

Epoch: 6| Step: 6
Training loss: 2.4526944116652936
Validation loss: 2.655445880046408

Epoch: 6| Step: 7
Training loss: 2.258895561455256
Validation loss: 2.6845896521548034

Epoch: 6| Step: 8
Training loss: 2.1058070772640294
Validation loss: 2.671921632785912

Epoch: 6| Step: 9
Training loss: 2.6833686123378904
Validation loss: 2.66150909337535

Epoch: 6| Step: 10
Training loss: 2.2553455642870706
Validation loss: 2.6330687685811878

Epoch: 6| Step: 11
Training loss: 2.028285754023724
Validation loss: 2.6268498162640515

Epoch: 6| Step: 12
Training loss: 2.2763200556172825
Validation loss: 2.5694916937453556

Epoch: 6| Step: 13
Training loss: 2.143283724331858
Validation loss: 2.617102817370837

Epoch: 439| Step: 0
Training loss: 2.059318516235955
Validation loss: 2.604740606906669

Epoch: 6| Step: 1
Training loss: 2.3103904380949185
Validation loss: 2.642734686507709

Epoch: 6| Step: 2
Training loss: 2.2443519273685792
Validation loss: 2.6748981855519443

Epoch: 6| Step: 3
Training loss: 2.2241613457698164
Validation loss: 2.6730572614841015

Epoch: 6| Step: 4
Training loss: 2.2266179663458656
Validation loss: 2.7092048526967516

Epoch: 6| Step: 5
Training loss: 2.312155826834757
Validation loss: 2.7099690986857032

Epoch: 6| Step: 6
Training loss: 2.3534559566800817
Validation loss: 2.7059181563717325

Epoch: 6| Step: 7
Training loss: 1.623384993643051
Validation loss: 2.7010306285364973

Epoch: 6| Step: 8
Training loss: 2.017903777112904
Validation loss: 2.7265077583037707

Epoch: 6| Step: 9
Training loss: 1.8164810001210194
Validation loss: 2.6862446313351818

Epoch: 6| Step: 10
Training loss: 2.3714488736069845
Validation loss: 2.6938764834572946

Epoch: 6| Step: 11
Training loss: 1.8141705279585902
Validation loss: 2.6395530420461704

Epoch: 6| Step: 12
Training loss: 2.1825077311060985
Validation loss: 2.633850060692013

Epoch: 6| Step: 13
Training loss: 2.3434001407171032
Validation loss: 2.6166635854888556

Epoch: 440| Step: 0
Training loss: 2.384301892680936
Validation loss: 2.6369314510064656

Epoch: 6| Step: 1
Training loss: 1.87945402729612
Validation loss: 2.6302378754046654

Epoch: 6| Step: 2
Training loss: 2.241756278117614
Validation loss: 2.653343619097217

Epoch: 6| Step: 3
Training loss: 2.2519971672839816
Validation loss: 2.639587267365847

Epoch: 6| Step: 4
Training loss: 2.1610165309176637
Validation loss: 2.6518556616135607

Epoch: 6| Step: 5
Training loss: 1.6870789179136092
Validation loss: 2.636086174889512

Epoch: 6| Step: 6
Training loss: 2.0373403943040995
Validation loss: 2.6200601953926017

Epoch: 6| Step: 7
Training loss: 2.117239638246105
Validation loss: 2.612601440245463

Epoch: 6| Step: 8
Training loss: 2.8339290179702883
Validation loss: 2.614819376334787

Epoch: 6| Step: 9
Training loss: 2.2526123987536235
Validation loss: 2.6542922659813746

Epoch: 6| Step: 10
Training loss: 1.8347028760959327
Validation loss: 2.6673059895627165

Epoch: 6| Step: 11
Training loss: 2.448283964697652
Validation loss: 2.710051234207161

Epoch: 6| Step: 12
Training loss: 1.4607369188320045
Validation loss: 2.7255078312836107

Epoch: 6| Step: 13
Training loss: 0.9958731014233132
Validation loss: 2.7624768043234313

Epoch: 441| Step: 0
Training loss: 2.536996041601188
Validation loss: 2.7973102609683385

Epoch: 6| Step: 1
Training loss: 2.01827343963957
Validation loss: 2.744564449468812

Epoch: 6| Step: 2
Training loss: 1.0996587007073522
Validation loss: 2.7485317102776086

Epoch: 6| Step: 3
Training loss: 2.2194872423782006
Validation loss: 2.660302442013478

Epoch: 6| Step: 4
Training loss: 1.9951503487630478
Validation loss: 2.6632363177412266

Epoch: 6| Step: 5
Training loss: 1.730232584318479
Validation loss: 2.6379270790914084

Epoch: 6| Step: 6
Training loss: 1.9203464042582037
Validation loss: 2.599879635903168

Epoch: 6| Step: 7
Training loss: 2.0950424987561083
Validation loss: 2.6124563186918133

Epoch: 6| Step: 8
Training loss: 2.9635658374911347
Validation loss: 2.6157594499971495

Epoch: 6| Step: 9
Training loss: 2.0860024202795424
Validation loss: 2.652162288236135

Epoch: 6| Step: 10
Training loss: 2.2109723307423703
Validation loss: 2.6684632005077837

Epoch: 6| Step: 11
Training loss: 1.7303732679904436
Validation loss: 2.691677839265575

Epoch: 6| Step: 12
Training loss: 2.444224740279349
Validation loss: 2.6807184072305152

Epoch: 6| Step: 13
Training loss: 1.6657521440886363
Validation loss: 2.6844785637453388

Epoch: 442| Step: 0
Training loss: 1.8785339113433366
Validation loss: 2.6999512225552933

Epoch: 6| Step: 1
Training loss: 2.620090434719458
Validation loss: 2.6356776809149847

Epoch: 6| Step: 2
Training loss: 1.8832961604858078
Validation loss: 2.6710420644028305

Epoch: 6| Step: 3
Training loss: 2.1595874334089467
Validation loss: 2.6065370009536766

Epoch: 6| Step: 4
Training loss: 2.5461026758375205
Validation loss: 2.599348657694178

Epoch: 6| Step: 5
Training loss: 1.2177449508308575
Validation loss: 2.652591974310502

Epoch: 6| Step: 6
Training loss: 1.8633965350620096
Validation loss: 2.629939544956424

Epoch: 6| Step: 7
Training loss: 2.1815300267120525
Validation loss: 2.6623556093792224

Epoch: 6| Step: 8
Training loss: 1.659913240486497
Validation loss: 2.692783474545658

Epoch: 6| Step: 9
Training loss: 2.2846305568540037
Validation loss: 2.7007066525084524

Epoch: 6| Step: 10
Training loss: 2.1049511897936193
Validation loss: 2.727863917330007

Epoch: 6| Step: 11
Training loss: 2.1640407960540124
Validation loss: 2.741512426189476

Epoch: 6| Step: 12
Training loss: 2.5744528772513005
Validation loss: 2.781147301310104

Epoch: 6| Step: 13
Training loss: 1.5010548697143988
Validation loss: 2.7247032151425543

Epoch: 443| Step: 0
Training loss: 2.1662764809250645
Validation loss: 2.694492003452421

Epoch: 6| Step: 1
Training loss: 1.6695921812242727
Validation loss: 2.702038905908425

Epoch: 6| Step: 2
Training loss: 2.244351289985618
Validation loss: 2.7003839173513287

Epoch: 6| Step: 3
Training loss: 2.043951611388407
Validation loss: 2.628170122282566

Epoch: 6| Step: 4
Training loss: 2.100454839768051
Validation loss: 2.609885862508649

Epoch: 6| Step: 5
Training loss: 1.8775492821941775
Validation loss: 2.5949115556546607

Epoch: 6| Step: 6
Training loss: 2.546673351332328
Validation loss: 2.5963564597380624

Epoch: 6| Step: 7
Training loss: 1.8611626246267727
Validation loss: 2.6597407297779414

Epoch: 6| Step: 8
Training loss: 1.5542159395699668
Validation loss: 2.6937169908986416

Epoch: 6| Step: 9
Training loss: 1.8234655879847514
Validation loss: 2.7456552820632956

Epoch: 6| Step: 10
Training loss: 2.5535713580700294
Validation loss: 2.7729306317215947

Epoch: 6| Step: 11
Training loss: 2.048502384324999
Validation loss: 2.76164762076943

Epoch: 6| Step: 12
Training loss: 2.3208210705673444
Validation loss: 2.7318022951275953

Epoch: 6| Step: 13
Training loss: 2.3330685147371923
Validation loss: 2.735484759588324

Epoch: 444| Step: 0
Training loss: 2.0596661606431126
Validation loss: 2.7236000075855125

Epoch: 6| Step: 1
Training loss: 1.4926703505687111
Validation loss: 2.70842037834084

Epoch: 6| Step: 2
Training loss: 2.0431055201888073
Validation loss: 2.7051831107288686

Epoch: 6| Step: 3
Training loss: 2.1651829872591946
Validation loss: 2.7173370812469217

Epoch: 6| Step: 4
Training loss: 2.213814201781018
Validation loss: 2.693062684214788

Epoch: 6| Step: 5
Training loss: 2.3442728095281837
Validation loss: 2.6999845464819443

Epoch: 6| Step: 6
Training loss: 1.9441066819459119
Validation loss: 2.7131951330694215

Epoch: 6| Step: 7
Training loss: 1.8916233043770188
Validation loss: 2.7035512195177374

Epoch: 6| Step: 8
Training loss: 2.271351174855042
Validation loss: 2.7031531473828565

Epoch: 6| Step: 9
Training loss: 2.33863435036237
Validation loss: 2.7195475305177865

Epoch: 6| Step: 10
Training loss: 1.793836994254714
Validation loss: 2.7191239136291587

Epoch: 6| Step: 11
Training loss: 2.322290059467226
Validation loss: 2.687692411631506

Epoch: 6| Step: 12
Training loss: 1.5549641272034698
Validation loss: 2.681185147392534

Epoch: 6| Step: 13
Training loss: 2.434249471187387
Validation loss: 2.6689497655804044

Epoch: 445| Step: 0
Training loss: 1.811734662761281
Validation loss: 2.617617804107864

Epoch: 6| Step: 1
Training loss: 2.190894626453128
Validation loss: 2.5887584095808682

Epoch: 6| Step: 2
Training loss: 2.2777752475672783
Validation loss: 2.5641124613316895

Epoch: 6| Step: 3
Training loss: 2.215852161378648
Validation loss: 2.5414608738088704

Epoch: 6| Step: 4
Training loss: 2.265702029267045
Validation loss: 2.6071325910011436

Epoch: 6| Step: 5
Training loss: 2.077714004603212
Validation loss: 2.6109590262103994

Epoch: 6| Step: 6
Training loss: 2.1936045889196385
Validation loss: 2.647369064708922

Epoch: 6| Step: 7
Training loss: 2.4892543644542617
Validation loss: 2.6860057428494812

Epoch: 6| Step: 8
Training loss: 1.6540770041173798
Validation loss: 2.6798581840596523

Epoch: 6| Step: 9
Training loss: 1.8828193379511464
Validation loss: 2.7312966443543445

Epoch: 6| Step: 10
Training loss: 2.47162113549894
Validation loss: 2.696215241118418

Epoch: 6| Step: 11
Training loss: 1.5120910659190074
Validation loss: 2.6709430697824774

Epoch: 6| Step: 12
Training loss: 1.6474097062462558
Validation loss: 2.7126437586738055

Epoch: 6| Step: 13
Training loss: 1.7408914577823458
Validation loss: 2.704420735272761

Epoch: 446| Step: 0
Training loss: 2.318292322771924
Validation loss: 2.718644157653042

Epoch: 6| Step: 1
Training loss: 2.160721496245728
Validation loss: 2.6960633323390963

Epoch: 6| Step: 2
Training loss: 1.5710435370829658
Validation loss: 2.6720362069346275

Epoch: 6| Step: 3
Training loss: 2.1871975280906812
Validation loss: 2.6713473102298284

Epoch: 6| Step: 4
Training loss: 1.5229651868251526
Validation loss: 2.6486927533451183

Epoch: 6| Step: 5
Training loss: 1.7536571980051388
Validation loss: 2.6524414052254874

Epoch: 6| Step: 6
Training loss: 1.8027847630163496
Validation loss: 2.6333692737331846

Epoch: 6| Step: 7
Training loss: 2.0584241880476077
Validation loss: 2.6132429876018324

Epoch: 6| Step: 8
Training loss: 2.141441022610782
Validation loss: 2.615576575316838

Epoch: 6| Step: 9
Training loss: 2.386882470442116
Validation loss: 2.5773470891096912

Epoch: 6| Step: 10
Training loss: 2.221219045651979
Validation loss: 2.6068507017319416

Epoch: 6| Step: 11
Training loss: 2.077949803360135
Validation loss: 2.6332171839229903

Epoch: 6| Step: 12
Training loss: 2.299395054581729
Validation loss: 2.614025561600919

Epoch: 6| Step: 13
Training loss: 1.7904598992146685
Validation loss: 2.646988475491312

Epoch: 447| Step: 0
Training loss: 2.0056852359826114
Validation loss: 2.657498391931301

Epoch: 6| Step: 1
Training loss: 2.466234881610422
Validation loss: 2.679107184146809

Epoch: 6| Step: 2
Training loss: 1.5994243957357162
Validation loss: 2.6784997596274382

Epoch: 6| Step: 3
Training loss: 2.319792615401838
Validation loss: 2.6894818529923588

Epoch: 6| Step: 4
Training loss: 2.0021110360739343
Validation loss: 2.6928184180367523

Epoch: 6| Step: 5
Training loss: 2.2324353315293255
Validation loss: 2.680324046772186

Epoch: 6| Step: 6
Training loss: 2.251229480097066
Validation loss: 2.699966154566218

Epoch: 6| Step: 7
Training loss: 1.5198536508778304
Validation loss: 2.68381481099332

Epoch: 6| Step: 8
Training loss: 2.07588545509343
Validation loss: 2.661642204332168

Epoch: 6| Step: 9
Training loss: 1.7956177666927058
Validation loss: 2.6455140783974733

Epoch: 6| Step: 10
Training loss: 1.6420041055384058
Validation loss: 2.640813148136711

Epoch: 6| Step: 11
Training loss: 2.142956542933982
Validation loss: 2.680002303634447

Epoch: 6| Step: 12
Training loss: 1.914739496824109
Validation loss: 2.6796433960491193

Epoch: 6| Step: 13
Training loss: 2.3197835711123953
Validation loss: 2.6851634136744797

Epoch: 448| Step: 0
Training loss: 2.384685043235716
Validation loss: 2.6613767704637756

Epoch: 6| Step: 1
Training loss: 1.558957929776408
Validation loss: 2.7074258260435204

Epoch: 6| Step: 2
Training loss: 2.205824044148834
Validation loss: 2.702241027401526

Epoch: 6| Step: 3
Training loss: 1.6535653723017618
Validation loss: 2.673472595320114

Epoch: 6| Step: 4
Training loss: 2.0705943941340927
Validation loss: 2.686521813349762

Epoch: 6| Step: 5
Training loss: 2.0120922741823297
Validation loss: 2.6736657191975315

Epoch: 6| Step: 6
Training loss: 1.308778026758008
Validation loss: 2.667974918945514

Epoch: 6| Step: 7
Training loss: 2.438704364296835
Validation loss: 2.648746390307902

Epoch: 6| Step: 8
Training loss: 2.159919932788794
Validation loss: 2.647648068278276

Epoch: 6| Step: 9
Training loss: 2.22428558109856
Validation loss: 2.604772501379994

Epoch: 6| Step: 10
Training loss: 1.7974750346226098
Validation loss: 2.6343782684567087

Epoch: 6| Step: 11
Training loss: 2.5159185960879404
Validation loss: 2.63724917747285

Epoch: 6| Step: 12
Training loss: 1.6703622694603024
Validation loss: 2.669625850251921

Epoch: 6| Step: 13
Training loss: 1.9445253181290412
Validation loss: 2.669301074457226

Epoch: 449| Step: 0
Training loss: 2.16415548296969
Validation loss: 2.708856059540346

Epoch: 6| Step: 1
Training loss: 2.2481287486448367
Validation loss: 2.758498827243057

Epoch: 6| Step: 2
Training loss: 2.2776334130146605
Validation loss: 2.76669998648019

Epoch: 6| Step: 3
Training loss: 1.8361525389357591
Validation loss: 2.7475146895986184

Epoch: 6| Step: 4
Training loss: 2.222484615517268
Validation loss: 2.717098082649409

Epoch: 6| Step: 5
Training loss: 1.9684827108440262
Validation loss: 2.676493788601913

Epoch: 6| Step: 6
Training loss: 1.9692427608894003
Validation loss: 2.6660865478265263

Epoch: 6| Step: 7
Training loss: 1.7327741503449074
Validation loss: 2.657625968052228

Epoch: 6| Step: 8
Training loss: 2.3553039594355987
Validation loss: 2.637802503872466

Epoch: 6| Step: 9
Training loss: 2.035663212109205
Validation loss: 2.6427788544474446

Epoch: 6| Step: 10
Training loss: 1.6885724368656017
Validation loss: 2.6323918221668414

Epoch: 6| Step: 11
Training loss: 1.9106492106582424
Validation loss: 2.6462934302458554

Epoch: 6| Step: 12
Training loss: 1.9051399125511133
Validation loss: 2.6713364782910505

Epoch: 6| Step: 13
Training loss: 2.11329050114946
Validation loss: 2.71635578926454

Epoch: 450| Step: 0
Training loss: 1.550764030918258
Validation loss: 2.7620563270883456

Epoch: 6| Step: 1
Training loss: 2.070619495590636
Validation loss: 2.8004775772047013

Epoch: 6| Step: 2
Training loss: 1.9958422478123028
Validation loss: 2.7905802320011444

Epoch: 6| Step: 3
Training loss: 2.3403766006246656
Validation loss: 2.7956254883102587

Epoch: 6| Step: 4
Training loss: 2.39226979040012
Validation loss: 2.7493782039667556

Epoch: 6| Step: 5
Training loss: 1.98141047793508
Validation loss: 2.689683626607104

Epoch: 6| Step: 6
Training loss: 1.6518677370775572
Validation loss: 2.649506010486259

Epoch: 6| Step: 7
Training loss: 2.532102558999776
Validation loss: 2.59616775593109

Epoch: 6| Step: 8
Training loss: 2.514277126712501
Validation loss: 2.5772844850566194

Epoch: 6| Step: 9
Training loss: 1.9536047384451434
Validation loss: 2.6045566396464026

Epoch: 6| Step: 10
Training loss: 1.9227700979045186
Validation loss: 2.6093909631734165

Epoch: 6| Step: 11
Training loss: 1.9812394848854382
Validation loss: 2.600174492919626

Epoch: 6| Step: 12
Training loss: 1.8544811310722278
Validation loss: 2.6555242484375654

Epoch: 6| Step: 13
Training loss: 1.0677013986253774
Validation loss: 2.685322630468501

Testing loss: 2.554451710496749
