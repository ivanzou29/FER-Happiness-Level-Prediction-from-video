Epoch: 1| Step: 0
Training loss: 4.328003883361816
Validation loss: 5.232089570773545

Epoch: 5| Step: 1
Training loss: 4.053984642028809
Validation loss: 5.221452149011755

Epoch: 5| Step: 2
Training loss: 5.278672695159912
Validation loss: 5.210699799240277

Epoch: 5| Step: 3
Training loss: 4.964632034301758
Validation loss: 5.199825450938235

Epoch: 5| Step: 4
Training loss: 5.525793075561523
Validation loss: 5.18895342529461

Epoch: 5| Step: 5
Training loss: 4.972723960876465
Validation loss: 5.177138964335124

Epoch: 5| Step: 6
Training loss: 5.173133850097656
Validation loss: 5.1645979778741

Epoch: 5| Step: 7
Training loss: 4.226513862609863
Validation loss: 5.150820465498073

Epoch: 5| Step: 8
Training loss: 5.757781505584717
Validation loss: 5.136439979717296

Epoch: 5| Step: 9
Training loss: 5.546567440032959
Validation loss: 5.120490104921402

Epoch: 5| Step: 10
Training loss: 4.791040897369385
Validation loss: 5.103975162711195

Epoch: 2| Step: 0
Training loss: 4.797305107116699
Validation loss: 5.0852331346081145

Epoch: 5| Step: 1
Training loss: 4.397907257080078
Validation loss: 5.066314630610968

Epoch: 5| Step: 2
Training loss: 4.949134826660156
Validation loss: 5.045283384220575

Epoch: 5| Step: 3
Training loss: 4.917296409606934
Validation loss: 5.023114388988864

Epoch: 5| Step: 4
Training loss: 4.8969316482543945
Validation loss: 4.998455303971485

Epoch: 5| Step: 5
Training loss: 3.95489764213562
Validation loss: 4.972890171953427

Epoch: 5| Step: 6
Training loss: 5.4022698402404785
Validation loss: 4.946170468484202

Epoch: 5| Step: 7
Training loss: 4.829671382904053
Validation loss: 4.917877007556218

Epoch: 5| Step: 8
Training loss: 6.3054890632629395
Validation loss: 4.888472844195622

Epoch: 5| Step: 9
Training loss: 3.028414726257324
Validation loss: 4.8575583734819965

Epoch: 5| Step: 10
Training loss: 4.837779521942139
Validation loss: 4.824318703784738

Epoch: 3| Step: 0
Training loss: 4.788435459136963
Validation loss: 4.790862242380778

Epoch: 5| Step: 1
Training loss: 4.290563583374023
Validation loss: 4.757312313202889

Epoch: 5| Step: 2
Training loss: 4.998298645019531
Validation loss: 4.722919766620923

Epoch: 5| Step: 3
Training loss: 4.646669387817383
Validation loss: 4.688582974095499

Epoch: 5| Step: 4
Training loss: 4.198029518127441
Validation loss: 4.654426010706091

Epoch: 5| Step: 5
Training loss: 4.32835054397583
Validation loss: 4.618967933039511

Epoch: 5| Step: 6
Training loss: 5.694487571716309
Validation loss: 4.584817450533631

Epoch: 5| Step: 7
Training loss: 3.3588714599609375
Validation loss: 4.550381727116083

Epoch: 5| Step: 8
Training loss: 3.254908323287964
Validation loss: 4.516088906154837

Epoch: 5| Step: 9
Training loss: 4.412762641906738
Validation loss: 4.479301293690999

Epoch: 5| Step: 10
Training loss: 4.537232875823975
Validation loss: 4.4433929894560125

Epoch: 4| Step: 0
Training loss: 4.426592826843262
Validation loss: 4.404875652764433

Epoch: 5| Step: 1
Training loss: 3.376183271408081
Validation loss: 4.365191269946354

Epoch: 5| Step: 2
Training loss: 3.734769105911255
Validation loss: 4.323627874415408

Epoch: 5| Step: 3
Training loss: 3.6681454181671143
Validation loss: 4.286117461419875

Epoch: 5| Step: 4
Training loss: 4.220465183258057
Validation loss: 4.249199949285035

Epoch: 5| Step: 5
Training loss: 4.592452049255371
Validation loss: 4.2136661109103954

Epoch: 5| Step: 6
Training loss: 4.221932888031006
Validation loss: 4.181978264162617

Epoch: 5| Step: 7
Training loss: 3.7372829914093018
Validation loss: 4.150216963983351

Epoch: 5| Step: 8
Training loss: 3.8550937175750732
Validation loss: 4.1197930766690165

Epoch: 5| Step: 9
Training loss: 4.630154609680176
Validation loss: 4.089898191472535

Epoch: 5| Step: 10
Training loss: 3.9121530055999756
Validation loss: 4.0593502265150825

Epoch: 5| Step: 0
Training loss: 4.321013450622559
Validation loss: 4.0289245318341

Epoch: 5| Step: 1
Training loss: 3.688080310821533
Validation loss: 3.999236609346123

Epoch: 5| Step: 2
Training loss: 4.358108043670654
Validation loss: 3.967711607615153

Epoch: 5| Step: 3
Training loss: 3.0338120460510254
Validation loss: 3.9349468959275113

Epoch: 5| Step: 4
Training loss: 3.4842586517333984
Validation loss: 3.90462427754556

Epoch: 5| Step: 5
Training loss: 2.618429660797119
Validation loss: 3.8755056422243834

Epoch: 5| Step: 6
Training loss: 4.040924072265625
Validation loss: 3.8488671446359284

Epoch: 5| Step: 7
Training loss: 4.393247127532959
Validation loss: 3.8233396314805552

Epoch: 5| Step: 8
Training loss: 3.613067626953125
Validation loss: 3.798180510920863

Epoch: 5| Step: 9
Training loss: 4.144734859466553
Validation loss: 3.772832288536974

Epoch: 5| Step: 10
Training loss: 3.458853244781494
Validation loss: 3.7542464912578626

Epoch: 6| Step: 0
Training loss: 4.232231616973877
Validation loss: 3.732357317401517

Epoch: 5| Step: 1
Training loss: 3.133779525756836
Validation loss: 3.714402985829179

Epoch: 5| Step: 2
Training loss: 3.396733045578003
Validation loss: 3.699665379780595

Epoch: 5| Step: 3
Training loss: 4.381117343902588
Validation loss: 3.6849046112388693

Epoch: 5| Step: 4
Training loss: 3.227588176727295
Validation loss: 3.6692046144957184

Epoch: 5| Step: 5
Training loss: 3.434546709060669
Validation loss: 3.653215395506992

Epoch: 5| Step: 6
Training loss: 3.257289171218872
Validation loss: 3.6375499386941232

Epoch: 5| Step: 7
Training loss: 4.269360542297363
Validation loss: 3.624306986408849

Epoch: 5| Step: 8
Training loss: 2.744784116744995
Validation loss: 3.6133494556591077

Epoch: 5| Step: 9
Training loss: 3.4376349449157715
Validation loss: 3.6052961144396054

Epoch: 5| Step: 10
Training loss: 3.781548500061035
Validation loss: 3.5949810730513705

Epoch: 7| Step: 0
Training loss: 4.217348098754883
Validation loss: 3.582183668690343

Epoch: 5| Step: 1
Training loss: 3.6367835998535156
Validation loss: 3.5742838972358295

Epoch: 5| Step: 2
Training loss: 3.397625684738159
Validation loss: 3.5634692304877826

Epoch: 5| Step: 3
Training loss: 2.971667528152466
Validation loss: 3.5526825792046

Epoch: 5| Step: 4
Training loss: 3.86773943901062
Validation loss: 3.5401150744448424

Epoch: 5| Step: 5
Training loss: 2.408108711242676
Validation loss: 3.5192872196115474

Epoch: 5| Step: 6
Training loss: 2.8655781745910645
Validation loss: 3.5134264064091507

Epoch: 5| Step: 7
Training loss: 3.7626423835754395
Validation loss: 3.506928636181739

Epoch: 5| Step: 8
Training loss: 3.4995148181915283
Validation loss: 3.500536790458105

Epoch: 5| Step: 9
Training loss: 3.5534768104553223
Validation loss: 3.4914634817390033

Epoch: 5| Step: 10
Training loss: 3.948529005050659
Validation loss: 3.476666958101334

Epoch: 8| Step: 0
Training loss: 3.3172996044158936
Validation loss: 3.4662130699362805

Epoch: 5| Step: 1
Training loss: 3.0281636714935303
Validation loss: 3.4601295942901285

Epoch: 5| Step: 2
Training loss: 3.431398868560791
Validation loss: 3.450839886101343

Epoch: 5| Step: 3
Training loss: 2.969818592071533
Validation loss: 3.443031580217423

Epoch: 5| Step: 4
Training loss: 4.075535774230957
Validation loss: 3.4340542234400266

Epoch: 5| Step: 5
Training loss: 2.6004281044006348
Validation loss: 3.424469329977548

Epoch: 5| Step: 6
Training loss: 3.1598880290985107
Validation loss: 3.4140080713456675

Epoch: 5| Step: 7
Training loss: 3.9739699363708496
Validation loss: 3.4129233719200216

Epoch: 5| Step: 8
Training loss: 4.506734371185303
Validation loss: 3.395050871756769

Epoch: 5| Step: 9
Training loss: 3.315380811691284
Validation loss: 3.3878861088906564

Epoch: 5| Step: 10
Training loss: 2.5585474967956543
Validation loss: 3.3855109650601625

Epoch: 9| Step: 0
Training loss: 4.260110855102539
Validation loss: 3.3777878438272784

Epoch: 5| Step: 1
Training loss: 2.696150541305542
Validation loss: 3.3723843661687707

Epoch: 5| Step: 2
Training loss: 3.9695022106170654
Validation loss: 3.3678136384615334

Epoch: 5| Step: 3
Training loss: 2.6195740699768066
Validation loss: 3.36430299410256

Epoch: 5| Step: 4
Training loss: 2.848339557647705
Validation loss: 3.357427171481553

Epoch: 5| Step: 5
Training loss: 4.10260009765625
Validation loss: 3.351741357516217

Epoch: 5| Step: 6
Training loss: 2.870793581008911
Validation loss: 3.345418176343364

Epoch: 5| Step: 7
Training loss: 3.820615768432617
Validation loss: 3.3392390487014607

Epoch: 5| Step: 8
Training loss: 2.65037202835083
Validation loss: 3.330150196629186

Epoch: 5| Step: 9
Training loss: 3.1654109954833984
Validation loss: 3.3264748921958347

Epoch: 5| Step: 10
Training loss: 3.4599337577819824
Validation loss: 3.3200117593170493

Epoch: 10| Step: 0
Training loss: 3.6267178058624268
Validation loss: 3.3134162246540027

Epoch: 5| Step: 1
Training loss: 3.300044536590576
Validation loss: 3.3055084187497377

Epoch: 5| Step: 2
Training loss: 3.0025997161865234
Validation loss: 3.30151129025285

Epoch: 5| Step: 3
Training loss: 2.4735639095306396
Validation loss: 3.294852351629606

Epoch: 5| Step: 4
Training loss: 3.7891879081726074
Validation loss: 3.2875176373348443

Epoch: 5| Step: 5
Training loss: 3.860708236694336
Validation loss: 3.278515382479596

Epoch: 5| Step: 6
Training loss: 3.2130908966064453
Validation loss: 3.2735138759818128

Epoch: 5| Step: 7
Training loss: 3.2880942821502686
Validation loss: 3.26643604616965

Epoch: 5| Step: 8
Training loss: 2.1234631538391113
Validation loss: 3.2612289818384315

Epoch: 5| Step: 9
Training loss: 4.031500816345215
Validation loss: 3.256272574906708

Epoch: 5| Step: 10
Training loss: 3.084986925125122
Validation loss: 3.248943631367017

Epoch: 11| Step: 0
Training loss: 3.307933807373047
Validation loss: 3.242776004217004

Epoch: 5| Step: 1
Training loss: 2.8650715351104736
Validation loss: 3.2377589159114386

Epoch: 5| Step: 2
Training loss: 3.5261051654815674
Validation loss: 3.228092747349893

Epoch: 5| Step: 3
Training loss: 3.4992079734802246
Validation loss: 3.22517454495994

Epoch: 5| Step: 4
Training loss: 2.6157937049865723
Validation loss: 3.219668798549201

Epoch: 5| Step: 5
Training loss: 2.4341025352478027
Validation loss: 3.2148993963836343

Epoch: 5| Step: 6
Training loss: 3.4215025901794434
Validation loss: 3.206906582719536

Epoch: 5| Step: 7
Training loss: 4.391152381896973
Validation loss: 3.1994488982744116

Epoch: 5| Step: 8
Training loss: 3.5076968669891357
Validation loss: 3.193196624837896

Epoch: 5| Step: 9
Training loss: 2.533684015274048
Validation loss: 3.191683720516902

Epoch: 5| Step: 10
Training loss: 3.1731791496276855
Validation loss: 3.1870113752221547

Epoch: 12| Step: 0
Training loss: 3.5172340869903564
Validation loss: 3.1822719830338673

Epoch: 5| Step: 1
Training loss: 3.5428738594055176
Validation loss: 3.17502075113276

Epoch: 5| Step: 2
Training loss: 2.5817911624908447
Validation loss: 3.1673507921157347

Epoch: 5| Step: 3
Training loss: 2.938354730606079
Validation loss: 3.158945273327571

Epoch: 5| Step: 4
Training loss: 3.205120086669922
Validation loss: 3.158219809173256

Epoch: 5| Step: 5
Training loss: 2.960339069366455
Validation loss: 3.1580006102079987

Epoch: 5| Step: 6
Training loss: 3.3423526287078857
Validation loss: 3.1475499983756774

Epoch: 5| Step: 7
Training loss: 3.1321136951446533
Validation loss: 3.1419035183486117

Epoch: 5| Step: 8
Training loss: 3.1777055263519287
Validation loss: 3.1343077177642495

Epoch: 5| Step: 9
Training loss: 2.805959701538086
Validation loss: 3.1346407936465357

Epoch: 5| Step: 10
Training loss: 3.6936092376708984
Validation loss: 3.1298719554819088

Epoch: 13| Step: 0
Training loss: 3.1235270500183105
Validation loss: 3.1221111641135266

Epoch: 5| Step: 1
Training loss: 3.336932420730591
Validation loss: 3.117717545519593

Epoch: 5| Step: 2
Training loss: 2.376311779022217
Validation loss: 3.1128701907332226

Epoch: 5| Step: 3
Training loss: 3.416034698486328
Validation loss: 3.1069871892211256

Epoch: 5| Step: 4
Training loss: 3.4646923542022705
Validation loss: 3.1004034473050024

Epoch: 5| Step: 5
Training loss: 3.9027838706970215
Validation loss: 3.097716285336402

Epoch: 5| Step: 6
Training loss: 2.7436606884002686
Validation loss: 3.0946975164515997

Epoch: 5| Step: 7
Training loss: 2.6854636669158936
Validation loss: 3.0862824378475064

Epoch: 5| Step: 8
Training loss: 3.3290748596191406
Validation loss: 3.0842699235485447

Epoch: 5| Step: 9
Training loss: 2.366997003555298
Validation loss: 3.07571437281947

Epoch: 5| Step: 10
Training loss: 3.722522258758545
Validation loss: 3.0720061896949686

Epoch: 14| Step: 0
Training loss: 3.2548346519470215
Validation loss: 3.0697517677020003

Epoch: 5| Step: 1
Training loss: 2.851600170135498
Validation loss: 3.0653245218338503

Epoch: 5| Step: 2
Training loss: 3.64373779296875
Validation loss: 3.060023030927104

Epoch: 5| Step: 3
Training loss: 3.1931488513946533
Validation loss: 3.056787085789506

Epoch: 5| Step: 4
Training loss: 3.058377504348755
Validation loss: 3.0535455954972135

Epoch: 5| Step: 5
Training loss: 2.9297173023223877
Validation loss: 3.0465584416543283

Epoch: 5| Step: 6
Training loss: 2.4453794956207275
Validation loss: 3.040719411706412

Epoch: 5| Step: 7
Training loss: 2.8022549152374268
Validation loss: 3.03664820168608

Epoch: 5| Step: 8
Training loss: 3.182982921600342
Validation loss: 3.0347398737425446

Epoch: 5| Step: 9
Training loss: 3.4462833404541016
Validation loss: 3.0288883947557017

Epoch: 5| Step: 10
Training loss: 3.227052688598633
Validation loss: 3.0208277061421382

Epoch: 15| Step: 0
Training loss: 3.3777217864990234
Validation loss: 3.016926619314378

Epoch: 5| Step: 1
Training loss: 3.1101841926574707
Validation loss: 3.015289329713391

Epoch: 5| Step: 2
Training loss: 3.028611421585083
Validation loss: 3.012014317256148

Epoch: 5| Step: 3
Training loss: 3.6191229820251465
Validation loss: 3.007400292222218

Epoch: 5| Step: 4
Training loss: 2.863193988800049
Validation loss: 3.0016582371086202

Epoch: 5| Step: 5
Training loss: 2.2269272804260254
Validation loss: 2.9969449658547678

Epoch: 5| Step: 6
Training loss: 2.8051934242248535
Validation loss: 2.995681557604062

Epoch: 5| Step: 7
Training loss: 2.993129253387451
Validation loss: 2.988959022747573

Epoch: 5| Step: 8
Training loss: 3.036907196044922
Validation loss: 2.986731380544683

Epoch: 5| Step: 9
Training loss: 3.2558960914611816
Validation loss: 2.9829201954667286

Epoch: 5| Step: 10
Training loss: 3.3792736530303955
Validation loss: 2.978920744311425

Epoch: 16| Step: 0
Training loss: 2.8550620079040527
Validation loss: 2.9713917265656176

Epoch: 5| Step: 1
Training loss: 3.223107099533081
Validation loss: 2.967338946557814

Epoch: 5| Step: 2
Training loss: 3.232459545135498
Validation loss: 2.9667680366064912

Epoch: 5| Step: 3
Training loss: 2.9820756912231445
Validation loss: 2.9638006994801183

Epoch: 5| Step: 4
Training loss: 2.9656481742858887
Validation loss: 2.960580418186803

Epoch: 5| Step: 5
Training loss: 2.5431015491485596
Validation loss: 2.9577940997257026

Epoch: 5| Step: 6
Training loss: 3.6422810554504395
Validation loss: 2.955664719304731

Epoch: 5| Step: 7
Training loss: 2.948453903198242
Validation loss: 2.9485825005398003

Epoch: 5| Step: 8
Training loss: 2.967258930206299
Validation loss: 2.946278425955003

Epoch: 5| Step: 9
Training loss: 3.1786367893218994
Validation loss: 2.9393439728726625

Epoch: 5| Step: 10
Training loss: 2.8195483684539795
Validation loss: 2.9368715055527224

Epoch: 17| Step: 0
Training loss: 2.760183334350586
Validation loss: 2.935351930638795

Epoch: 5| Step: 1
Training loss: 2.6329779624938965
Validation loss: 2.931142125078427

Epoch: 5| Step: 2
Training loss: 3.134436845779419
Validation loss: 2.927317867996872

Epoch: 5| Step: 3
Training loss: 3.022122859954834
Validation loss: 2.9238076338204007

Epoch: 5| Step: 4
Training loss: 3.524792194366455
Validation loss: 2.921406794619817

Epoch: 5| Step: 5
Training loss: 3.797856092453003
Validation loss: 2.9195577072840866

Epoch: 5| Step: 6
Training loss: 2.4956440925598145
Validation loss: 2.913751494499945

Epoch: 5| Step: 7
Training loss: 3.1503472328186035
Validation loss: 2.914333281978484

Epoch: 5| Step: 8
Training loss: 2.774784803390503
Validation loss: 2.9100557988689792

Epoch: 5| Step: 9
Training loss: 2.7226452827453613
Validation loss: 2.9093980122638006

Epoch: 5| Step: 10
Training loss: 3.0941507816314697
Validation loss: 2.9044932319271948

Epoch: 18| Step: 0
Training loss: 2.843200922012329
Validation loss: 2.8997089093731296

Epoch: 5| Step: 1
Training loss: 2.8276350498199463
Validation loss: 2.8953964992236068

Epoch: 5| Step: 2
Training loss: 3.595733642578125
Validation loss: 2.8944049163531234

Epoch: 5| Step: 3
Training loss: 2.470278263092041
Validation loss: 2.8915995961876324

Epoch: 5| Step: 4
Training loss: 2.5443055629730225
Validation loss: 2.8890853107616468

Epoch: 5| Step: 5
Training loss: 2.744976043701172
Validation loss: 2.885695239549042

Epoch: 5| Step: 6
Training loss: 3.511188507080078
Validation loss: 2.884065915179509

Epoch: 5| Step: 7
Training loss: 3.2137794494628906
Validation loss: 2.8772731493878108

Epoch: 5| Step: 8
Training loss: 3.07195782661438
Validation loss: 2.877372372534967

Epoch: 5| Step: 9
Training loss: 3.0510787963867188
Validation loss: 2.872441389227426

Epoch: 5| Step: 10
Training loss: 2.9894423484802246
Validation loss: 2.873238278973487

Epoch: 19| Step: 0
Training loss: 2.9936466217041016
Validation loss: 2.8680661160458802

Epoch: 5| Step: 1
Training loss: 3.428621768951416
Validation loss: 2.8674916733977613

Epoch: 5| Step: 2
Training loss: 3.0273678302764893
Validation loss: 2.8661795098294496

Epoch: 5| Step: 3
Training loss: 3.1521623134613037
Validation loss: 2.863563883689142

Epoch: 5| Step: 4
Training loss: 2.4369847774505615
Validation loss: 2.8591938813527427

Epoch: 5| Step: 5
Training loss: 3.1410160064697266
Validation loss: 2.857238297821373

Epoch: 5| Step: 6
Training loss: 2.5783679485321045
Validation loss: 2.8555076122283936

Epoch: 5| Step: 7
Training loss: 2.700676441192627
Validation loss: 2.8529779218858287

Epoch: 5| Step: 8
Training loss: 3.8565571308135986
Validation loss: 2.8513511970479

Epoch: 5| Step: 9
Training loss: 2.8995790481567383
Validation loss: 2.851590571864959

Epoch: 5| Step: 10
Training loss: 2.3606255054473877
Validation loss: 2.847950002198578

Epoch: 20| Step: 0
Training loss: 2.9546399116516113
Validation loss: 2.846958816692393

Epoch: 5| Step: 1
Training loss: 3.3795464038848877
Validation loss: 2.845173376862721

Epoch: 5| Step: 2
Training loss: 2.822815179824829
Validation loss: 2.8387951850891113

Epoch: 5| Step: 3
Training loss: 3.0174694061279297
Validation loss: 2.837757836106003

Epoch: 5| Step: 4
Training loss: 3.3787879943847656
Validation loss: 2.8348338962883077

Epoch: 5| Step: 5
Training loss: 3.075792074203491
Validation loss: 2.8349859073597896

Epoch: 5| Step: 6
Training loss: 3.0717194080352783
Validation loss: 2.8347434843740156

Epoch: 5| Step: 7
Training loss: 1.9972083568572998
Validation loss: 2.835272732601371

Epoch: 5| Step: 8
Training loss: 2.9150428771972656
Validation loss: 2.841568536655877

Epoch: 5| Step: 9
Training loss: 3.122371196746826
Validation loss: 2.8333646866583053

Epoch: 5| Step: 10
Training loss: 2.7249207496643066
Validation loss: 2.825643201028147

Epoch: 21| Step: 0
Training loss: 2.6515822410583496
Validation loss: 2.821667035420736

Epoch: 5| Step: 1
Training loss: 3.202800750732422
Validation loss: 2.8236777551712526

Epoch: 5| Step: 2
Training loss: 2.9194655418395996
Validation loss: 2.8220838859517086

Epoch: 5| Step: 3
Training loss: 2.9330055713653564
Validation loss: 2.8215720653533936

Epoch: 5| Step: 4
Training loss: 3.0920863151550293
Validation loss: 2.8204244593138337

Epoch: 5| Step: 5
Training loss: 2.8459420204162598
Validation loss: 2.8175435476405646

Epoch: 5| Step: 6
Training loss: 2.806689977645874
Validation loss: 2.8170870247707573

Epoch: 5| Step: 7
Training loss: 2.6564698219299316
Validation loss: 2.8135549047941804

Epoch: 5| Step: 8
Training loss: 3.565373182296753
Validation loss: 2.8128040118884017

Epoch: 5| Step: 9
Training loss: 3.1790664196014404
Validation loss: 2.8115487765240412

Epoch: 5| Step: 10
Training loss: 2.469527006149292
Validation loss: 2.8130815670054448

Epoch: 22| Step: 0
Training loss: 2.8310160636901855
Validation loss: 2.8085494451625372

Epoch: 5| Step: 1
Training loss: 3.3780112266540527
Validation loss: 2.804939287965016

Epoch: 5| Step: 2
Training loss: 3.724970579147339
Validation loss: 2.8037496536008772

Epoch: 5| Step: 3
Training loss: 2.320521116256714
Validation loss: 2.8037346306667534

Epoch: 5| Step: 4
Training loss: 3.155555009841919
Validation loss: 2.803360918516754

Epoch: 5| Step: 5
Training loss: 2.9288432598114014
Validation loss: 2.8030556196807535

Epoch: 5| Step: 6
Training loss: 2.7554259300231934
Validation loss: 2.801966920975716

Epoch: 5| Step: 7
Training loss: 2.4149022102355957
Validation loss: 2.7957328416967906

Epoch: 5| Step: 8
Training loss: 2.403061628341675
Validation loss: 2.7992091178894043

Epoch: 5| Step: 9
Training loss: 3.0502161979675293
Validation loss: 2.805503378632248

Epoch: 5| Step: 10
Training loss: 3.383237838745117
Validation loss: 2.8015973952508744

Epoch: 23| Step: 0
Training loss: 3.090033769607544
Validation loss: 2.796811244821036

Epoch: 5| Step: 1
Training loss: 3.124967098236084
Validation loss: 2.7928352432866252

Epoch: 5| Step: 2
Training loss: 2.828892230987549
Validation loss: 2.7904574717244794

Epoch: 5| Step: 3
Training loss: 2.9775466918945312
Validation loss: 2.7887571934730775

Epoch: 5| Step: 4
Training loss: 2.2586989402770996
Validation loss: 2.786754656863469

Epoch: 5| Step: 5
Training loss: 2.3729262351989746
Validation loss: 2.790793113811042

Epoch: 5| Step: 6
Training loss: 3.618511199951172
Validation loss: 2.791310892310194

Epoch: 5| Step: 7
Training loss: 2.893247127532959
Validation loss: 2.790475501809069

Epoch: 5| Step: 8
Training loss: 2.737323045730591
Validation loss: 2.784944426628851

Epoch: 5| Step: 9
Training loss: 3.0871541500091553
Validation loss: 2.7832011868876796

Epoch: 5| Step: 10
Training loss: 3.2386391162872314
Validation loss: 2.7818688859221754

Epoch: 24| Step: 0
Training loss: 2.7255871295928955
Validation loss: 2.7831027353963544

Epoch: 5| Step: 1
Training loss: 2.237786054611206
Validation loss: 2.7873554588646017

Epoch: 5| Step: 2
Training loss: 2.9833335876464844
Validation loss: 2.7847393405052925

Epoch: 5| Step: 3
Training loss: 3.487746477127075
Validation loss: 2.7886963557171565

Epoch: 5| Step: 4
Training loss: 2.633591890335083
Validation loss: 2.7784279905339724

Epoch: 5| Step: 5
Training loss: 3.110302448272705
Validation loss: 2.776233411604358

Epoch: 5| Step: 6
Training loss: 3.5093982219696045
Validation loss: 2.775274074205788

Epoch: 5| Step: 7
Training loss: 2.6874754428863525
Validation loss: 2.781088698294855

Epoch: 5| Step: 8
Training loss: 2.1361775398254395
Validation loss: 2.7761193347233597

Epoch: 5| Step: 9
Training loss: 3.2855491638183594
Validation loss: 2.7758701693627144

Epoch: 5| Step: 10
Training loss: 3.366609573364258
Validation loss: 2.7736541917247157

Epoch: 25| Step: 0
Training loss: 2.9009642601013184
Validation loss: 2.7721715691269084

Epoch: 5| Step: 1
Training loss: 2.3914694786071777
Validation loss: 2.770507425390264

Epoch: 5| Step: 2
Training loss: 2.084843873977661
Validation loss: 2.772396059446437

Epoch: 5| Step: 3
Training loss: 3.5648245811462402
Validation loss: 2.774688743775891

Epoch: 5| Step: 4
Training loss: 3.320262908935547
Validation loss: 2.7746398295125654

Epoch: 5| Step: 5
Training loss: 3.1554808616638184
Validation loss: 2.769556409569197

Epoch: 5| Step: 6
Training loss: 2.6458239555358887
Validation loss: 2.765444761963301

Epoch: 5| Step: 7
Training loss: 3.349052906036377
Validation loss: 2.7623406815272507

Epoch: 5| Step: 8
Training loss: 2.851210117340088
Validation loss: 2.763565159613086

Epoch: 5| Step: 9
Training loss: 2.4487195014953613
Validation loss: 2.7650651701035036

Epoch: 5| Step: 10
Training loss: 3.387035608291626
Validation loss: 2.76571237656378

Epoch: 26| Step: 0
Training loss: 2.307191848754883
Validation loss: 2.762168509985811

Epoch: 5| Step: 1
Training loss: 2.442173480987549
Validation loss: 2.75974081664957

Epoch: 5| Step: 2
Training loss: 3.6604549884796143
Validation loss: 2.7589926104391775

Epoch: 5| Step: 3
Training loss: 3.5171685218811035
Validation loss: 2.757209575304421

Epoch: 5| Step: 4
Training loss: 2.6449854373931885
Validation loss: 2.7564677320500857

Epoch: 5| Step: 5
Training loss: 2.7634003162384033
Validation loss: 2.75715289320997

Epoch: 5| Step: 6
Training loss: 2.4869751930236816
Validation loss: 2.7605381499054613

Epoch: 5| Step: 7
Training loss: 2.7453198432922363
Validation loss: 2.759900757061538

Epoch: 5| Step: 8
Training loss: 2.5779354572296143
Validation loss: 2.7554055798438286

Epoch: 5| Step: 9
Training loss: 3.878054141998291
Validation loss: 2.753841805201705

Epoch: 5| Step: 10
Training loss: 2.9188406467437744
Validation loss: 2.7531098140183317

Epoch: 27| Step: 0
Training loss: 3.786287307739258
Validation loss: 2.7514100100404475

Epoch: 5| Step: 1
Training loss: 2.358851194381714
Validation loss: 2.7517355180555776

Epoch: 5| Step: 2
Training loss: 2.6234147548675537
Validation loss: 2.7508195497656382

Epoch: 5| Step: 3
Training loss: 3.675751209259033
Validation loss: 2.7493188945196008

Epoch: 5| Step: 4
Training loss: 3.0829343795776367
Validation loss: 2.749340077882172

Epoch: 5| Step: 5
Training loss: 2.935176372528076
Validation loss: 2.7469424509233042

Epoch: 5| Step: 6
Training loss: 2.101132869720459
Validation loss: 2.745694770607897

Epoch: 5| Step: 7
Training loss: 2.6966896057128906
Validation loss: 2.745574951171875

Epoch: 5| Step: 8
Training loss: 3.115480899810791
Validation loss: 2.7441027113186416

Epoch: 5| Step: 9
Training loss: 2.476457118988037
Validation loss: 2.7455651144827566

Epoch: 5| Step: 10
Training loss: 3.063986301422119
Validation loss: 2.743501568353304

Epoch: 28| Step: 0
Training loss: 2.791769504547119
Validation loss: 2.741875079370314

Epoch: 5| Step: 1
Training loss: 3.058270215988159
Validation loss: 2.7446369124997045

Epoch: 5| Step: 2
Training loss: 3.425093412399292
Validation loss: 2.7460326456254527

Epoch: 5| Step: 3
Training loss: 2.6885128021240234
Validation loss: 2.7426175302074802

Epoch: 5| Step: 4
Training loss: 2.281803607940674
Validation loss: 2.754512327973561

Epoch: 5| Step: 5
Training loss: 3.3154189586639404
Validation loss: 2.764415899912516

Epoch: 5| Step: 6
Training loss: 2.6063168048858643
Validation loss: 2.7548762675254577

Epoch: 5| Step: 7
Training loss: 3.132856845855713
Validation loss: 2.7438959665195917

Epoch: 5| Step: 8
Training loss: 2.511228322982788
Validation loss: 2.7439312268328924

Epoch: 5| Step: 9
Training loss: 3.102626085281372
Validation loss: 2.7409332567645657

Epoch: 5| Step: 10
Training loss: 2.9525558948516846
Validation loss: 2.7453012081884567

Epoch: 29| Step: 0
Training loss: 2.745173692703247
Validation loss: 2.74553192815473

Epoch: 5| Step: 1
Training loss: 2.8941614627838135
Validation loss: 2.7417452976267827

Epoch: 5| Step: 2
Training loss: 2.8382556438446045
Validation loss: 2.7406373254714476

Epoch: 5| Step: 3
Training loss: 2.470041513442993
Validation loss: 2.737303057024556

Epoch: 5| Step: 4
Training loss: 2.46671724319458
Validation loss: 2.7396912344040407

Epoch: 5| Step: 5
Training loss: 2.9450597763061523
Validation loss: 2.745067827163204

Epoch: 5| Step: 6
Training loss: 3.183173656463623
Validation loss: 2.747346270468927

Epoch: 5| Step: 7
Training loss: 3.4657299518585205
Validation loss: 2.743236975003314

Epoch: 5| Step: 8
Training loss: 3.005918264389038
Validation loss: 2.742235242679555

Epoch: 5| Step: 9
Training loss: 2.7617135047912598
Validation loss: 2.736991610578311

Epoch: 5| Step: 10
Training loss: 3.0681090354919434
Validation loss: 2.7396069854818363

Epoch: 30| Step: 0
Training loss: 2.412614107131958
Validation loss: 2.7355827644307125

Epoch: 5| Step: 1
Training loss: 2.5118775367736816
Validation loss: 2.7381820396710466

Epoch: 5| Step: 2
Training loss: 3.2770180702209473
Validation loss: 2.73499886451229

Epoch: 5| Step: 3
Training loss: 3.453808546066284
Validation loss: 2.7333780360478226

Epoch: 5| Step: 4
Training loss: 2.759202480316162
Validation loss: 2.734344677258563

Epoch: 5| Step: 5
Training loss: 2.869568347930908
Validation loss: 2.731103692003476

Epoch: 5| Step: 6
Training loss: 2.7810654640197754
Validation loss: 2.7355314864907214

Epoch: 5| Step: 7
Training loss: 3.0877349376678467
Validation loss: 2.7361084261248187

Epoch: 5| Step: 8
Training loss: 2.9049274921417236
Validation loss: 2.7479925181276057

Epoch: 5| Step: 9
Training loss: 2.816136121749878
Validation loss: 2.744230972823276

Epoch: 5| Step: 10
Training loss: 2.880610227584839
Validation loss: 2.7319553513680734

Epoch: 31| Step: 0
Training loss: 2.240638256072998
Validation loss: 2.72979897581121

Epoch: 5| Step: 1
Training loss: 3.00264048576355
Validation loss: 2.7377029106181157

Epoch: 5| Step: 2
Training loss: 2.735581159591675
Validation loss: 2.7453778866798646

Epoch: 5| Step: 3
Training loss: 2.8834946155548096
Validation loss: 2.74270357624177

Epoch: 5| Step: 4
Training loss: 1.886087417602539
Validation loss: 2.739759747700025

Epoch: 5| Step: 5
Training loss: 3.216564178466797
Validation loss: 2.739528594478484

Epoch: 5| Step: 6
Training loss: 3.9406418800354004
Validation loss: 2.7393355010658182

Epoch: 5| Step: 7
Training loss: 2.3294363021850586
Validation loss: 2.7407468672721618

Epoch: 5| Step: 8
Training loss: 2.2561118602752686
Validation loss: 2.7389135847809496

Epoch: 5| Step: 9
Training loss: 4.2000298500061035
Validation loss: 2.7460924809978855

Epoch: 5| Step: 10
Training loss: 3.102071523666382
Validation loss: 2.7338091070934007

Epoch: 32| Step: 0
Training loss: 3.2829062938690186
Validation loss: 2.7326807873223418

Epoch: 5| Step: 1
Training loss: 3.3290982246398926
Validation loss: 2.726908063375822

Epoch: 5| Step: 2
Training loss: 2.5003037452697754
Validation loss: 2.7263054847717285

Epoch: 5| Step: 3
Training loss: 2.8643136024475098
Validation loss: 2.7296367845227643

Epoch: 5| Step: 4
Training loss: 1.9343593120574951
Validation loss: 2.728519597361165

Epoch: 5| Step: 5
Training loss: 2.8114097118377686
Validation loss: 2.728980043882965

Epoch: 5| Step: 6
Training loss: 3.608163833618164
Validation loss: 2.727658756317631

Epoch: 5| Step: 7
Training loss: 2.818830966949463
Validation loss: 2.726039504492155

Epoch: 5| Step: 8
Training loss: 2.5031228065490723
Validation loss: 2.719330567185597

Epoch: 5| Step: 9
Training loss: 3.0821361541748047
Validation loss: 2.7203225807477067

Epoch: 5| Step: 10
Training loss: 2.912245273590088
Validation loss: 2.7180704839767946

Epoch: 33| Step: 0
Training loss: 2.7915027141571045
Validation loss: 2.7169574153038765

Epoch: 5| Step: 1
Training loss: 3.763171434402466
Validation loss: 2.717149019241333

Epoch: 5| Step: 2
Training loss: 2.8223876953125
Validation loss: 2.7198875386227845

Epoch: 5| Step: 3
Training loss: 2.0039591789245605
Validation loss: 2.7244038812575804

Epoch: 5| Step: 4
Training loss: 1.949251413345337
Validation loss: 2.725281015519173

Epoch: 5| Step: 5
Training loss: 2.6787281036376953
Validation loss: 2.729518764762468

Epoch: 5| Step: 6
Training loss: 3.4395804405212402
Validation loss: 2.7254116432641142

Epoch: 5| Step: 7
Training loss: 2.7996981143951416
Validation loss: 2.717846352566955

Epoch: 5| Step: 8
Training loss: 2.976776361465454
Validation loss: 2.7183622698630057

Epoch: 5| Step: 9
Training loss: 3.035598039627075
Validation loss: 2.7165171202792915

Epoch: 5| Step: 10
Training loss: 3.4399538040161133
Validation loss: 2.7199051098157

Epoch: 34| Step: 0
Training loss: 2.782453775405884
Validation loss: 2.7163379602534796

Epoch: 5| Step: 1
Training loss: 2.526104688644409
Validation loss: 2.718052033455141

Epoch: 5| Step: 2
Training loss: 2.0470149517059326
Validation loss: 2.715005851561023

Epoch: 5| Step: 3
Training loss: 3.9056434631347656
Validation loss: 2.7154180003750708

Epoch: 5| Step: 4
Training loss: 3.4480576515197754
Validation loss: 2.7133096059163413

Epoch: 5| Step: 5
Training loss: 3.1746466159820557
Validation loss: 2.71469783782959

Epoch: 5| Step: 6
Training loss: 3.3969104290008545
Validation loss: 2.7123886000725532

Epoch: 5| Step: 7
Training loss: 2.922316074371338
Validation loss: 2.7126984442434003

Epoch: 5| Step: 8
Training loss: 2.6555683612823486
Validation loss: 2.7098127539439867

Epoch: 5| Step: 9
Training loss: 2.1300172805786133
Validation loss: 2.7106926646283878

Epoch: 5| Step: 10
Training loss: 2.5676167011260986
Validation loss: 2.7118174414480887

Epoch: 35| Step: 0
Training loss: 3.2571778297424316
Validation loss: 2.713794216032951

Epoch: 5| Step: 1
Training loss: 3.2063534259796143
Validation loss: 2.716952678977802

Epoch: 5| Step: 2
Training loss: 2.479793071746826
Validation loss: 2.7174783983538227

Epoch: 5| Step: 3
Training loss: 2.775245428085327
Validation loss: 2.709013646648776

Epoch: 5| Step: 4
Training loss: 3.1710212230682373
Validation loss: 2.7092730947720107

Epoch: 5| Step: 5
Training loss: 2.8167519569396973
Validation loss: 2.70941940687036

Epoch: 5| Step: 6
Training loss: 3.466470241546631
Validation loss: 2.7069530076878046

Epoch: 5| Step: 7
Training loss: 2.468529224395752
Validation loss: 2.7072671921022478

Epoch: 5| Step: 8
Training loss: 2.420708179473877
Validation loss: 2.704100255043276

Epoch: 5| Step: 9
Training loss: 2.485161542892456
Validation loss: 2.70514008819416

Epoch: 5| Step: 10
Training loss: 2.9697184562683105
Validation loss: 2.7012458462868967

Epoch: 36| Step: 0
Training loss: 2.041529417037964
Validation loss: 2.7059423385127896

Epoch: 5| Step: 1
Training loss: 2.481987476348877
Validation loss: 2.7046999956971858

Epoch: 5| Step: 2
Training loss: 2.5802507400512695
Validation loss: 2.704062372125605

Epoch: 5| Step: 3
Training loss: 2.9224414825439453
Validation loss: 2.703610840664115

Epoch: 5| Step: 4
Training loss: 2.889683723449707
Validation loss: 2.702564726593674

Epoch: 5| Step: 5
Training loss: 2.9867565631866455
Validation loss: 2.7035342160091607

Epoch: 5| Step: 6
Training loss: 2.5544564723968506
Validation loss: 2.705887084366173

Epoch: 5| Step: 7
Training loss: 4.213013648986816
Validation loss: 2.7097172403848298

Epoch: 5| Step: 8
Training loss: 2.372708559036255
Validation loss: 2.7076905568440757

Epoch: 5| Step: 9
Training loss: 3.4328315258026123
Validation loss: 2.704479222656578

Epoch: 5| Step: 10
Training loss: 3.010903835296631
Validation loss: 2.7005927639622844

Epoch: 37| Step: 0
Training loss: 2.4588372707366943
Validation loss: 2.7012293133684384

Epoch: 5| Step: 1
Training loss: 3.2499866485595703
Validation loss: 2.701765150152227

Epoch: 5| Step: 2
Training loss: 3.0532946586608887
Validation loss: 2.702857922482234

Epoch: 5| Step: 3
Training loss: 3.385138750076294
Validation loss: 2.697631477027811

Epoch: 5| Step: 4
Training loss: 3.2414588928222656
Validation loss: 2.694512795376521

Epoch: 5| Step: 5
Training loss: 1.9811760187149048
Validation loss: 2.6961911057913177

Epoch: 5| Step: 6
Training loss: 2.7333128452301025
Validation loss: 2.6975871260448168

Epoch: 5| Step: 7
Training loss: 3.0254805088043213
Validation loss: 2.7089242524998163

Epoch: 5| Step: 8
Training loss: 2.6645967960357666
Validation loss: 2.708199370291925

Epoch: 5| Step: 9
Training loss: 2.0001060962677
Validation loss: 2.7085117037578295

Epoch: 5| Step: 10
Training loss: 3.7863657474517822
Validation loss: 2.7084676193934616

Epoch: 38| Step: 0
Training loss: 2.780547618865967
Validation loss: 2.702739738648938

Epoch: 5| Step: 1
Training loss: 2.385180950164795
Validation loss: 2.6953731301010295

Epoch: 5| Step: 2
Training loss: 2.960449457168579
Validation loss: 2.6909486145101567

Epoch: 5| Step: 3
Training loss: 3.197439193725586
Validation loss: 2.6931194002910326

Epoch: 5| Step: 4
Training loss: 2.7105259895324707
Validation loss: 2.6901942145439888

Epoch: 5| Step: 5
Training loss: 2.6988797187805176
Validation loss: 2.6922939131336827

Epoch: 5| Step: 6
Training loss: 3.02235746383667
Validation loss: 2.694592588691301

Epoch: 5| Step: 7
Training loss: 2.8832240104675293
Validation loss: 2.6999179470923638

Epoch: 5| Step: 8
Training loss: 2.5507118701934814
Validation loss: 2.695016784052695

Epoch: 5| Step: 9
Training loss: 3.3735175132751465
Validation loss: 2.6938915611595236

Epoch: 5| Step: 10
Training loss: 2.8072402477264404
Validation loss: 2.6969830092563423

Epoch: 39| Step: 0
Training loss: 3.2392401695251465
Validation loss: 2.6936362815159622

Epoch: 5| Step: 1
Training loss: 3.482382297515869
Validation loss: 2.6924050777189192

Epoch: 5| Step: 2
Training loss: 3.1200032234191895
Validation loss: 2.69087831435665

Epoch: 5| Step: 3
Training loss: 2.3197014331817627
Validation loss: 2.688356763573103

Epoch: 5| Step: 4
Training loss: 2.754791736602783
Validation loss: 2.6981257623241794

Epoch: 5| Step: 5
Training loss: 2.683880567550659
Validation loss: 2.697630731008386

Epoch: 5| Step: 6
Training loss: 2.774947166442871
Validation loss: 2.6914441072812645

Epoch: 5| Step: 7
Training loss: 2.914389133453369
Validation loss: 2.6936343331490793

Epoch: 5| Step: 8
Training loss: 2.339364528656006
Validation loss: 2.701274066843012

Epoch: 5| Step: 9
Training loss: 2.919438600540161
Validation loss: 2.7122285955695697

Epoch: 5| Step: 10
Training loss: 2.8480031490325928
Validation loss: 2.7090527139684206

Epoch: 40| Step: 0
Training loss: 2.681910514831543
Validation loss: 2.7087437286171863

Epoch: 5| Step: 1
Training loss: 2.8486483097076416
Validation loss: 2.6929068770459903

Epoch: 5| Step: 2
Training loss: 2.662755012512207
Validation loss: 2.6990869968168196

Epoch: 5| Step: 3
Training loss: 2.9784178733825684
Validation loss: 2.7090428183155675

Epoch: 5| Step: 4
Training loss: 2.755680561065674
Validation loss: 2.724081103519727

Epoch: 5| Step: 5
Training loss: 3.437960147857666
Validation loss: 2.707330663998922

Epoch: 5| Step: 6
Training loss: 3.085343837738037
Validation loss: 2.692342722287742

Epoch: 5| Step: 7
Training loss: 3.0666728019714355
Validation loss: 2.685565521640162

Epoch: 5| Step: 8
Training loss: 2.5187482833862305
Validation loss: 2.6834165973048054

Epoch: 5| Step: 9
Training loss: 2.909299850463867
Validation loss: 2.6860160417454217

Epoch: 5| Step: 10
Training loss: 2.404655933380127
Validation loss: 2.692259439858057

Epoch: 41| Step: 0
Training loss: 3.765393018722534
Validation loss: 2.706986658034786

Epoch: 5| Step: 1
Training loss: 2.4962382316589355
Validation loss: 2.706055202791768

Epoch: 5| Step: 2
Training loss: 1.5686194896697998
Validation loss: 2.714801085892544

Epoch: 5| Step: 3
Training loss: 3.445439100265503
Validation loss: 2.7192077021445

Epoch: 5| Step: 4
Training loss: 3.117155075073242
Validation loss: 2.7236057096912014

Epoch: 5| Step: 5
Training loss: 3.221465587615967
Validation loss: 2.6995714582422727

Epoch: 5| Step: 6
Training loss: 2.585888385772705
Validation loss: 2.6882245566255305

Epoch: 5| Step: 7
Training loss: 2.358570098876953
Validation loss: 2.684725561449605

Epoch: 5| Step: 8
Training loss: 3.3188862800598145
Validation loss: 2.6869818651547996

Epoch: 5| Step: 9
Training loss: 2.3787167072296143
Validation loss: 2.6935054512434107

Epoch: 5| Step: 10
Training loss: 3.108189344406128
Validation loss: 2.7005246377760366

Epoch: 42| Step: 0
Training loss: 2.23264479637146
Validation loss: 2.693156760226014

Epoch: 5| Step: 1
Training loss: 3.384873151779175
Validation loss: 2.6866351789043796

Epoch: 5| Step: 2
Training loss: 2.6050188541412354
Validation loss: 2.680863034340643

Epoch: 5| Step: 3
Training loss: 2.378264904022217
Validation loss: 2.674534877141317

Epoch: 5| Step: 4
Training loss: 3.437079906463623
Validation loss: 2.6735422611236572

Epoch: 5| Step: 5
Training loss: 4.104222297668457
Validation loss: 2.6858987269863004

Epoch: 5| Step: 6
Training loss: 2.2978386878967285
Validation loss: 2.6933087379701677

Epoch: 5| Step: 7
Training loss: 2.478854179382324
Validation loss: 2.6938508249098256

Epoch: 5| Step: 8
Training loss: 2.854739189147949
Validation loss: 2.6839502652486167

Epoch: 5| Step: 9
Training loss: 2.495476245880127
Validation loss: 2.6782216589937926

Epoch: 5| Step: 10
Training loss: 3.0899550914764404
Validation loss: 2.678332713342482

Epoch: 43| Step: 0
Training loss: 2.723872423171997
Validation loss: 2.672404812228295

Epoch: 5| Step: 1
Training loss: 2.588076114654541
Validation loss: 2.66842915678537

Epoch: 5| Step: 2
Training loss: 3.2806878089904785
Validation loss: 2.667353606993152

Epoch: 5| Step: 3
Training loss: 2.5046846866607666
Validation loss: 2.666889577783564

Epoch: 5| Step: 4
Training loss: 2.9951272010803223
Validation loss: 2.6666221182833434

Epoch: 5| Step: 5
Training loss: 3.0040371417999268
Validation loss: 2.6673000269038702

Epoch: 5| Step: 6
Training loss: 2.17927885055542
Validation loss: 2.6671709706706386

Epoch: 5| Step: 7
Training loss: 3.907884120941162
Validation loss: 2.6659942134734123

Epoch: 5| Step: 8
Training loss: 2.908088207244873
Validation loss: 2.667557583060316

Epoch: 5| Step: 9
Training loss: 2.575654983520508
Validation loss: 2.664287208228983

Epoch: 5| Step: 10
Training loss: 2.4102203845977783
Validation loss: 2.666755768560594

Epoch: 44| Step: 0
Training loss: 2.693937301635742
Validation loss: 2.6627831151408534

Epoch: 5| Step: 1
Training loss: 2.754274845123291
Validation loss: 2.661666198443341

Epoch: 5| Step: 2
Training loss: 2.237562894821167
Validation loss: 2.6586927880523024

Epoch: 5| Step: 3
Training loss: 2.812671422958374
Validation loss: 2.660729269827566

Epoch: 5| Step: 4
Training loss: 2.9555296897888184
Validation loss: 2.6647712697264967

Epoch: 5| Step: 5
Training loss: 2.7982585430145264
Validation loss: 2.669634942085512

Epoch: 5| Step: 6
Training loss: 2.889085292816162
Validation loss: 2.669404440028693

Epoch: 5| Step: 7
Training loss: 2.4782896041870117
Validation loss: 2.6670757698756393

Epoch: 5| Step: 8
Training loss: 3.4730992317199707
Validation loss: 2.6672939254391577

Epoch: 5| Step: 9
Training loss: 2.5896944999694824
Validation loss: 2.6644069866467546

Epoch: 5| Step: 10
Training loss: 3.566981554031372
Validation loss: 2.665527751368861

Epoch: 45| Step: 0
Training loss: 2.111124038696289
Validation loss: 2.6687105419815227

Epoch: 5| Step: 1
Training loss: 2.370490550994873
Validation loss: 2.6700117998225714

Epoch: 5| Step: 2
Training loss: 2.713466167449951
Validation loss: 2.671569114090294

Epoch: 5| Step: 3
Training loss: 2.866194248199463
Validation loss: 2.671365778933289

Epoch: 5| Step: 4
Training loss: 3.064230442047119
Validation loss: 2.6668785028560187

Epoch: 5| Step: 5
Training loss: 3.398754835128784
Validation loss: 2.6713612489802863

Epoch: 5| Step: 6
Training loss: 2.5417697429656982
Validation loss: 2.664468639640398

Epoch: 5| Step: 7
Training loss: 2.656196117401123
Validation loss: 2.6654975414276123

Epoch: 5| Step: 8
Training loss: 3.102708339691162
Validation loss: 2.661939331280288

Epoch: 5| Step: 9
Training loss: 2.884385585784912
Validation loss: 2.6664973894755044

Epoch: 5| Step: 10
Training loss: 3.516502618789673
Validation loss: 2.667794978746804

Epoch: 46| Step: 0
Training loss: 2.2629451751708984
Validation loss: 2.66776454576882

Epoch: 5| Step: 1
Training loss: 2.9753763675689697
Validation loss: 2.671462376912435

Epoch: 5| Step: 2
Training loss: 2.4214320182800293
Validation loss: 2.672010039770475

Epoch: 5| Step: 3
Training loss: 3.3548195362091064
Validation loss: 2.670614573263353

Epoch: 5| Step: 4
Training loss: 2.8471803665161133
Validation loss: 2.666695879351708

Epoch: 5| Step: 5
Training loss: 3.052885055541992
Validation loss: 2.665804409211682

Epoch: 5| Step: 6
Training loss: 3.121737003326416
Validation loss: 2.66300021448443

Epoch: 5| Step: 7
Training loss: 3.7953827381134033
Validation loss: 2.662577541925574

Epoch: 5| Step: 8
Training loss: 2.232997179031372
Validation loss: 2.659156709588984

Epoch: 5| Step: 9
Training loss: 2.0121006965637207
Validation loss: 2.664936060546547

Epoch: 5| Step: 10
Training loss: 2.9721152782440186
Validation loss: 2.670261880402924

Epoch: 47| Step: 0
Training loss: 2.457547903060913
Validation loss: 2.669465413657568

Epoch: 5| Step: 1
Training loss: 2.6804442405700684
Validation loss: 2.656286093496507

Epoch: 5| Step: 2
Training loss: 3.301762342453003
Validation loss: 2.6563619952048025

Epoch: 5| Step: 3
Training loss: 3.22917103767395
Validation loss: 2.657182747317899

Epoch: 5| Step: 4
Training loss: 3.0607407093048096
Validation loss: 2.65706628881475

Epoch: 5| Step: 5
Training loss: 2.443833589553833
Validation loss: 2.6530579443900817

Epoch: 5| Step: 6
Training loss: 2.188558340072632
Validation loss: 2.6532982395541285

Epoch: 5| Step: 7
Training loss: 3.2984280586242676
Validation loss: 2.6503114520862536

Epoch: 5| Step: 8
Training loss: 2.4312307834625244
Validation loss: 2.6524392584318757

Epoch: 5| Step: 9
Training loss: 2.7610325813293457
Validation loss: 2.6582356806724303

Epoch: 5| Step: 10
Training loss: 3.1052029132843018
Validation loss: 2.655567425553517

Epoch: 48| Step: 0
Training loss: 3.6942687034606934
Validation loss: 2.6534627406827864

Epoch: 5| Step: 1
Training loss: 2.482731342315674
Validation loss: 2.6526372971073275

Epoch: 5| Step: 2
Training loss: 2.99407696723938
Validation loss: 2.6501637940765708

Epoch: 5| Step: 3
Training loss: 2.816270351409912
Validation loss: 2.648510589394518

Epoch: 5| Step: 4
Training loss: 3.1074042320251465
Validation loss: 2.6493769384199575

Epoch: 5| Step: 5
Training loss: 2.0945751667022705
Validation loss: 2.6519999914271857

Epoch: 5| Step: 6
Training loss: 2.781045913696289
Validation loss: 2.6556663359365156

Epoch: 5| Step: 7
Training loss: 3.5113208293914795
Validation loss: 2.651041200084071

Epoch: 5| Step: 8
Training loss: 1.9563888311386108
Validation loss: 2.6484306550795034

Epoch: 5| Step: 9
Training loss: 2.6819119453430176
Validation loss: 2.649605287018643

Epoch: 5| Step: 10
Training loss: 2.7563674449920654
Validation loss: 2.660736617221627

Epoch: 49| Step: 0
Training loss: 2.8350141048431396
Validation loss: 2.690377617395052

Epoch: 5| Step: 1
Training loss: 3.531904935836792
Validation loss: 2.7121543525367655

Epoch: 5| Step: 2
Training loss: 3.6521763801574707
Validation loss: 2.7015211248910553

Epoch: 5| Step: 3
Training loss: 1.9400981664657593
Validation loss: 2.6699690831604825

Epoch: 5| Step: 4
Training loss: 2.2353885173797607
Validation loss: 2.6458541321498092

Epoch: 5| Step: 5
Training loss: 3.127190589904785
Validation loss: 2.657009683629518

Epoch: 5| Step: 6
Training loss: 2.665365695953369
Validation loss: 2.691798917708858

Epoch: 5| Step: 7
Training loss: 2.705249309539795
Validation loss: 2.7005469106858775

Epoch: 5| Step: 8
Training loss: 2.960951328277588
Validation loss: 2.7016138645910446

Epoch: 5| Step: 9
Training loss: 3.1808319091796875
Validation loss: 2.6741955331576768

Epoch: 5| Step: 10
Training loss: 2.2901785373687744
Validation loss: 2.658750157202444

Epoch: 50| Step: 0
Training loss: 3.003159999847412
Validation loss: 2.648131690999513

Epoch: 5| Step: 1
Training loss: 2.562868118286133
Validation loss: 2.661106606965424

Epoch: 5| Step: 2
Training loss: 2.169771432876587
Validation loss: 2.6801989591249855

Epoch: 5| Step: 3
Training loss: 3.446317195892334
Validation loss: 2.7437142966895975

Epoch: 5| Step: 4
Training loss: 3.35357666015625
Validation loss: 2.748660559295326

Epoch: 5| Step: 5
Training loss: 3.0748298168182373
Validation loss: 2.7045038797522105

Epoch: 5| Step: 6
Training loss: 2.4862060546875
Validation loss: 2.6983851002108667

Epoch: 5| Step: 7
Training loss: 2.93259859085083
Validation loss: 2.7306333639288463

Epoch: 5| Step: 8
Training loss: 2.892944812774658
Validation loss: 2.7240602957305087

Epoch: 5| Step: 9
Training loss: 2.4733738899230957
Validation loss: 2.7208082188842115

Epoch: 5| Step: 10
Training loss: 2.8694710731506348
Validation loss: 2.7067672719237623

Epoch: 51| Step: 0
Training loss: 2.228067636489868
Validation loss: 2.6995598705866004

Epoch: 5| Step: 1
Training loss: 2.681938409805298
Validation loss: 2.682327934490737

Epoch: 5| Step: 2
Training loss: 2.614279270172119
Validation loss: 2.6898900385825866

Epoch: 5| Step: 3
Training loss: 3.217952013015747
Validation loss: 2.7291911596892984

Epoch: 5| Step: 4
Training loss: 3.2067646980285645
Validation loss: 2.7299736110113

Epoch: 5| Step: 5
Training loss: 3.686549425125122
Validation loss: 2.6752941582792547

Epoch: 5| Step: 6
Training loss: 2.668229579925537
Validation loss: 2.642957282322709

Epoch: 5| Step: 7
Training loss: 3.608738660812378
Validation loss: 2.646410534458776

Epoch: 5| Step: 8
Training loss: 2.0542898178100586
Validation loss: 2.6514244002680623

Epoch: 5| Step: 9
Training loss: 2.2560131549835205
Validation loss: 2.669645570939587

Epoch: 5| Step: 10
Training loss: 3.0198657512664795
Validation loss: 2.669168408199023

Epoch: 52| Step: 0
Training loss: 3.1557722091674805
Validation loss: 2.67404535765289

Epoch: 5| Step: 1
Training loss: 3.1919898986816406
Validation loss: 2.6836839081138693

Epoch: 5| Step: 2
Training loss: 3.122882843017578
Validation loss: 2.6901184743450535

Epoch: 5| Step: 3
Training loss: 2.279942512512207
Validation loss: 2.679182429467478

Epoch: 5| Step: 4
Training loss: 2.472745656967163
Validation loss: 2.6645712724295993

Epoch: 5| Step: 5
Training loss: 2.6207356452941895
Validation loss: 2.6583146202948784

Epoch: 5| Step: 6
Training loss: 2.9463419914245605
Validation loss: 2.651074017247846

Epoch: 5| Step: 7
Training loss: 2.5471537113189697
Validation loss: 2.646309409090268

Epoch: 5| Step: 8
Training loss: 3.0101771354675293
Validation loss: 2.6426884307656238

Epoch: 5| Step: 9
Training loss: 2.386286497116089
Validation loss: 2.634536794436875

Epoch: 5| Step: 10
Training loss: 3.1529088020324707
Validation loss: 2.636320291026946

Epoch: 53| Step: 0
Training loss: 3.4770398139953613
Validation loss: 2.634970736759965

Epoch: 5| Step: 1
Training loss: 2.262852668762207
Validation loss: 2.6393065144938808

Epoch: 5| Step: 2
Training loss: 2.417952060699463
Validation loss: 2.640753984451294

Epoch: 5| Step: 3
Training loss: 2.2281718254089355
Validation loss: 2.640429481383293

Epoch: 5| Step: 4
Training loss: 2.349047899246216
Validation loss: 2.632926551244592

Epoch: 5| Step: 5
Training loss: 2.6140849590301514
Validation loss: 2.6324766476949057

Epoch: 5| Step: 6
Training loss: 3.1718297004699707
Validation loss: 2.6303566245622534

Epoch: 5| Step: 7
Training loss: 3.3359787464141846
Validation loss: 2.6293418330530964

Epoch: 5| Step: 8
Training loss: 2.8189942836761475
Validation loss: 2.639247607159358

Epoch: 5| Step: 9
Training loss: 3.5175743103027344
Validation loss: 2.640381056775329

Epoch: 5| Step: 10
Training loss: 2.5699102878570557
Validation loss: 2.64948094788418

Epoch: 54| Step: 0
Training loss: 2.5295567512512207
Validation loss: 2.6448916466005388

Epoch: 5| Step: 1
Training loss: 3.116488456726074
Validation loss: 2.65196047547043

Epoch: 5| Step: 2
Training loss: 2.6004161834716797
Validation loss: 2.650621111674975

Epoch: 5| Step: 3
Training loss: 2.89473295211792
Validation loss: 2.6476196191644155

Epoch: 5| Step: 4
Training loss: 2.9404423236846924
Validation loss: 2.6389617484102965

Epoch: 5| Step: 5
Training loss: 2.691242218017578
Validation loss: 2.637517272785146

Epoch: 5| Step: 6
Training loss: 3.0738565921783447
Validation loss: 2.6301112072442168

Epoch: 5| Step: 7
Training loss: 2.9052040576934814
Validation loss: 2.6245142746997137

Epoch: 5| Step: 8
Training loss: 2.87206768989563
Validation loss: 2.6233687041908182

Epoch: 5| Step: 9
Training loss: 2.200336456298828
Validation loss: 2.625099766638971

Epoch: 5| Step: 10
Training loss: 2.824922561645508
Validation loss: 2.623007143697431

Epoch: 55| Step: 0
Training loss: 2.6472983360290527
Validation loss: 2.623625465618667

Epoch: 5| Step: 1
Training loss: 3.385812282562256
Validation loss: 2.6254265487834973

Epoch: 5| Step: 2
Training loss: 2.8330230712890625
Validation loss: 2.6224286633153118

Epoch: 5| Step: 3
Training loss: 2.433171510696411
Validation loss: 2.6255379389691096

Epoch: 5| Step: 4
Training loss: 2.8093819618225098
Validation loss: 2.6237168235163533

Epoch: 5| Step: 5
Training loss: 2.90840482711792
Validation loss: 2.6205272546378513

Epoch: 5| Step: 6
Training loss: 2.52913761138916
Validation loss: 2.6172594972836074

Epoch: 5| Step: 7
Training loss: 2.7705490589141846
Validation loss: 2.617260732958394

Epoch: 5| Step: 8
Training loss: 2.3368959426879883
Validation loss: 2.6212420002106698

Epoch: 5| Step: 9
Training loss: 3.0962507724761963
Validation loss: 2.6200236530714136

Epoch: 5| Step: 10
Training loss: 2.8617467880249023
Validation loss: 2.6269901516616985

Epoch: 56| Step: 0
Training loss: 2.014775037765503
Validation loss: 2.6365884965465916

Epoch: 5| Step: 1
Training loss: 2.9729857444763184
Validation loss: 2.6337926874878588

Epoch: 5| Step: 2
Training loss: 2.703591823577881
Validation loss: 2.642568947166525

Epoch: 5| Step: 3
Training loss: 3.4357776641845703
Validation loss: 2.63855141721746

Epoch: 5| Step: 4
Training loss: 3.040879011154175
Validation loss: 2.642837183449858

Epoch: 5| Step: 5
Training loss: 2.8838202953338623
Validation loss: 2.6501938912176315

Epoch: 5| Step: 6
Training loss: 2.805515766143799
Validation loss: 2.6683657861525014

Epoch: 5| Step: 7
Training loss: 2.494990825653076
Validation loss: 2.6964953330255326

Epoch: 5| Step: 8
Training loss: 2.876629114151001
Validation loss: 2.6759588949141966

Epoch: 5| Step: 9
Training loss: 2.792773723602295
Validation loss: 2.6457689090441634

Epoch: 5| Step: 10
Training loss: 2.699206829071045
Validation loss: 2.628289004807831

Epoch: 57| Step: 0
Training loss: 3.2214932441711426
Validation loss: 2.616690622862949

Epoch: 5| Step: 1
Training loss: 2.7797913551330566
Validation loss: 2.6135404930319837

Epoch: 5| Step: 2
Training loss: 2.1638922691345215
Validation loss: 2.613893380729101

Epoch: 5| Step: 3
Training loss: 2.464506149291992
Validation loss: 2.6240023336102887

Epoch: 5| Step: 4
Training loss: 2.944936752319336
Validation loss: 2.6270711857785463

Epoch: 5| Step: 5
Training loss: 3.225543260574341
Validation loss: 2.626513760576966

Epoch: 5| Step: 6
Training loss: 2.5786194801330566
Validation loss: 2.6276367607937066

Epoch: 5| Step: 7
Training loss: 3.2470383644104004
Validation loss: 2.6258700457952355

Epoch: 5| Step: 8
Training loss: 3.041198968887329
Validation loss: 2.619809732642225

Epoch: 5| Step: 9
Training loss: 2.2324929237365723
Validation loss: 2.6125950121110484

Epoch: 5| Step: 10
Training loss: 2.704604387283325
Validation loss: 2.609490325373988

Epoch: 58| Step: 0
Training loss: 2.9007363319396973
Validation loss: 2.6094022591908774

Epoch: 5| Step: 1
Training loss: 2.3758704662323
Validation loss: 2.6169223964855237

Epoch: 5| Step: 2
Training loss: 2.1596627235412598
Validation loss: 2.625627999664635

Epoch: 5| Step: 3
Training loss: 2.862456798553467
Validation loss: 2.6272975526830202

Epoch: 5| Step: 4
Training loss: 3.116750717163086
Validation loss: 2.6262259688428653

Epoch: 5| Step: 5
Training loss: 2.547983407974243
Validation loss: 2.626772616499214

Epoch: 5| Step: 6
Training loss: 3.469647169113159
Validation loss: 2.625897974096319

Epoch: 5| Step: 7
Training loss: 2.682154417037964
Validation loss: 2.6203974498215543

Epoch: 5| Step: 8
Training loss: 3.1861026287078857
Validation loss: 2.6154177317055325

Epoch: 5| Step: 9
Training loss: 3.029332399368286
Validation loss: 2.6150963152608564

Epoch: 5| Step: 10
Training loss: 2.1064507961273193
Validation loss: 2.6156038033064974

Epoch: 59| Step: 0
Training loss: 3.6120738983154297
Validation loss: 2.6081451139142438

Epoch: 5| Step: 1
Training loss: 2.631680727005005
Validation loss: 2.6096455333053425

Epoch: 5| Step: 2
Training loss: 1.9149891138076782
Validation loss: 2.6055570981835805

Epoch: 5| Step: 3
Training loss: 2.3814139366149902
Validation loss: 2.6041824535657

Epoch: 5| Step: 4
Training loss: 2.9069581031799316
Validation loss: 2.602111808715328

Epoch: 5| Step: 5
Training loss: 3.1523563861846924
Validation loss: 2.6000096721033894

Epoch: 5| Step: 6
Training loss: 2.6093225479125977
Validation loss: 2.600900734624555

Epoch: 5| Step: 7
Training loss: 2.7920289039611816
Validation loss: 2.601766400439765

Epoch: 5| Step: 8
Training loss: 2.876096725463867
Validation loss: 2.604066643663632

Epoch: 5| Step: 9
Training loss: 2.579916000366211
Validation loss: 2.622338218073691

Epoch: 5| Step: 10
Training loss: 3.017014503479004
Validation loss: 2.611037095387777

Epoch: 60| Step: 0
Training loss: 2.7709527015686035
Validation loss: 2.6040765367528445

Epoch: 5| Step: 1
Training loss: 2.894507884979248
Validation loss: 2.606081962585449

Epoch: 5| Step: 2
Training loss: 2.694990634918213
Validation loss: 2.602747981266309

Epoch: 5| Step: 3
Training loss: 2.7102975845336914
Validation loss: 2.602625100843368

Epoch: 5| Step: 4
Training loss: 2.9431467056274414
Validation loss: 2.6067118413986696

Epoch: 5| Step: 5
Training loss: 2.491931915283203
Validation loss: 2.6061922145146195

Epoch: 5| Step: 6
Training loss: 2.8016929626464844
Validation loss: 2.6084044710282357

Epoch: 5| Step: 7
Training loss: 2.3073318004608154
Validation loss: 2.6059251626332602

Epoch: 5| Step: 8
Training loss: 2.6160190105438232
Validation loss: 2.6047008499022453

Epoch: 5| Step: 9
Training loss: 2.6953790187835693
Validation loss: 2.6073847663018013

Epoch: 5| Step: 10
Training loss: 3.548715591430664
Validation loss: 2.609532097334503

Epoch: 61| Step: 0
Training loss: 2.9319522380828857
Validation loss: 2.611437000254149

Epoch: 5| Step: 1
Training loss: 3.2336502075195312
Validation loss: 2.6124218061406124

Epoch: 5| Step: 2
Training loss: 3.1863551139831543
Validation loss: 2.6169412264259915

Epoch: 5| Step: 3
Training loss: 2.466953992843628
Validation loss: 2.6160576446082002

Epoch: 5| Step: 4
Training loss: 2.5585732460021973
Validation loss: 2.605329111058225

Epoch: 5| Step: 5
Training loss: 2.7222466468811035
Validation loss: 2.6027378266857517

Epoch: 5| Step: 6
Training loss: 2.0041306018829346
Validation loss: 2.6004716504004692

Epoch: 5| Step: 7
Training loss: 2.151520013809204
Validation loss: 2.599836790433494

Epoch: 5| Step: 8
Training loss: 3.0926384925842285
Validation loss: 2.5985115061524096

Epoch: 5| Step: 9
Training loss: 3.4097118377685547
Validation loss: 2.5983516605951453

Epoch: 5| Step: 10
Training loss: 2.640181064605713
Validation loss: 2.5974245481593634

Epoch: 62| Step: 0
Training loss: 2.891793727874756
Validation loss: 2.5920732995515228

Epoch: 5| Step: 1
Training loss: 2.4217886924743652
Validation loss: 2.5923039400449364

Epoch: 5| Step: 2
Training loss: 2.392826557159424
Validation loss: 2.592765967051188

Epoch: 5| Step: 3
Training loss: 2.6107211112976074
Validation loss: 2.593313047962804

Epoch: 5| Step: 4
Training loss: 1.7587388753890991
Validation loss: 2.592273840340235

Epoch: 5| Step: 5
Training loss: 2.515820026397705
Validation loss: 2.59394867702197

Epoch: 5| Step: 6
Training loss: 3.7397327423095703
Validation loss: 2.5894477162309872

Epoch: 5| Step: 7
Training loss: 3.8964362144470215
Validation loss: 2.5907362250871557

Epoch: 5| Step: 8
Training loss: 2.3535590171813965
Validation loss: 2.5896984377214984

Epoch: 5| Step: 9
Training loss: 2.8437962532043457
Validation loss: 2.588720367800805

Epoch: 5| Step: 10
Training loss: 2.880599021911621
Validation loss: 2.586736971332181

Epoch: 63| Step: 0
Training loss: 3.5538582801818848
Validation loss: 2.584750331858153

Epoch: 5| Step: 1
Training loss: 2.2438952922821045
Validation loss: 2.589337448919973

Epoch: 5| Step: 2
Training loss: 2.709554672241211
Validation loss: 2.585083161630938

Epoch: 5| Step: 3
Training loss: 2.067176103591919
Validation loss: 2.585866758900304

Epoch: 5| Step: 4
Training loss: 2.7263059616088867
Validation loss: 2.583645236107611

Epoch: 5| Step: 5
Training loss: 2.9556705951690674
Validation loss: 2.583728418555311

Epoch: 5| Step: 6
Training loss: 2.844235897064209
Validation loss: 2.585343563428489

Epoch: 5| Step: 7
Training loss: 3.1357173919677734
Validation loss: 2.5848739006186046

Epoch: 5| Step: 8
Training loss: 2.6869187355041504
Validation loss: 2.5875711338494414

Epoch: 5| Step: 9
Training loss: 2.489180088043213
Validation loss: 2.5871513428226596

Epoch: 5| Step: 10
Training loss: 2.8606114387512207
Validation loss: 2.5829144062534457

Epoch: 64| Step: 0
Training loss: 2.887679100036621
Validation loss: 2.5786879498471498

Epoch: 5| Step: 1
Training loss: 2.544318675994873
Validation loss: 2.5848428357032036

Epoch: 5| Step: 2
Training loss: 2.8240790367126465
Validation loss: 2.5827996782077256

Epoch: 5| Step: 3
Training loss: 2.8886401653289795
Validation loss: 2.580468987905851

Epoch: 5| Step: 4
Training loss: 3.355250597000122
Validation loss: 2.5804742741328415

Epoch: 5| Step: 5
Training loss: 2.7853798866271973
Validation loss: 2.580423960121729

Epoch: 5| Step: 6
Training loss: 2.5728325843811035
Validation loss: 2.57983212829918

Epoch: 5| Step: 7
Training loss: 2.675950050354004
Validation loss: 2.582314122107721

Epoch: 5| Step: 8
Training loss: 2.2738871574401855
Validation loss: 2.5827348027178036

Epoch: 5| Step: 9
Training loss: 2.943115711212158
Validation loss: 2.579688690041983

Epoch: 5| Step: 10
Training loss: 2.4130403995513916
Validation loss: 2.5795890785032705

Epoch: 65| Step: 0
Training loss: 2.3063127994537354
Validation loss: 2.580122214491649

Epoch: 5| Step: 1
Training loss: 2.5743613243103027
Validation loss: 2.5769341094519502

Epoch: 5| Step: 2
Training loss: 2.6033778190612793
Validation loss: 2.5794090763215096

Epoch: 5| Step: 3
Training loss: 2.287376880645752
Validation loss: 2.5771238598772275

Epoch: 5| Step: 4
Training loss: 2.9508137702941895
Validation loss: 2.5739954107551166

Epoch: 5| Step: 5
Training loss: 2.7724990844726562
Validation loss: 2.572524147648965

Epoch: 5| Step: 6
Training loss: 2.703263998031616
Validation loss: 2.574628842774258

Epoch: 5| Step: 7
Training loss: 2.789562702178955
Validation loss: 2.5709204186675367

Epoch: 5| Step: 8
Training loss: 3.3886730670928955
Validation loss: 2.5751824968604633

Epoch: 5| Step: 9
Training loss: 2.849163055419922
Validation loss: 2.570513589407808

Epoch: 5| Step: 10
Training loss: 2.9963746070861816
Validation loss: 2.5710228079108783

Epoch: 66| Step: 0
Training loss: 2.952831745147705
Validation loss: 2.5715560938722346

Epoch: 5| Step: 1
Training loss: 2.728559970855713
Validation loss: 2.5725760280445056

Epoch: 5| Step: 2
Training loss: 3.2230639457702637
Validation loss: 2.5688090708947953

Epoch: 5| Step: 3
Training loss: 3.5074074268341064
Validation loss: 2.573127326144967

Epoch: 5| Step: 4
Training loss: 2.4986562728881836
Validation loss: 2.573241654262748

Epoch: 5| Step: 5
Training loss: 2.1672556400299072
Validation loss: 2.57106650388369

Epoch: 5| Step: 6
Training loss: 2.876772403717041
Validation loss: 2.567545839535293

Epoch: 5| Step: 7
Training loss: 2.6575732231140137
Validation loss: 2.5749279119635142

Epoch: 5| Step: 8
Training loss: 2.7963593006134033
Validation loss: 2.581433044966831

Epoch: 5| Step: 9
Training loss: 2.7803165912628174
Validation loss: 2.5914046431100495

Epoch: 5| Step: 10
Training loss: 1.832476019859314
Validation loss: 2.609079494271227

Epoch: 67| Step: 0
Training loss: 2.830256223678589
Validation loss: 2.6227740985091015

Epoch: 5| Step: 1
Training loss: 3.150698184967041
Validation loss: 2.5986861977525937

Epoch: 5| Step: 2
Training loss: 2.6453394889831543
Validation loss: 2.583852691035117

Epoch: 5| Step: 3
Training loss: 2.9243788719177246
Validation loss: 2.573794575147731

Epoch: 5| Step: 4
Training loss: 2.7741143703460693
Validation loss: 2.568908711915375

Epoch: 5| Step: 5
Training loss: 3.1324501037597656
Validation loss: 2.5638873115662606

Epoch: 5| Step: 6
Training loss: 3.0348563194274902
Validation loss: 2.566676380813763

Epoch: 5| Step: 7
Training loss: 2.361830949783325
Validation loss: 2.568049676956669

Epoch: 5| Step: 8
Training loss: 2.258469820022583
Validation loss: 2.56388843956814

Epoch: 5| Step: 9
Training loss: 2.3865089416503906
Validation loss: 2.5657164101959555

Epoch: 5| Step: 10
Training loss: 2.85115122795105
Validation loss: 2.564672016328381

Epoch: 68| Step: 0
Training loss: 1.974230170249939
Validation loss: 2.568355344956921

Epoch: 5| Step: 1
Training loss: 2.3533546924591064
Validation loss: 2.5676428861515497

Epoch: 5| Step: 2
Training loss: 2.3345251083374023
Validation loss: 2.5719876263731267

Epoch: 5| Step: 3
Training loss: 3.0812034606933594
Validation loss: 2.5709029936021373

Epoch: 5| Step: 4
Training loss: 2.788846254348755
Validation loss: 2.5736247185737855

Epoch: 5| Step: 5
Training loss: 2.6564743518829346
Validation loss: 2.5774857100620063

Epoch: 5| Step: 6
Training loss: 2.748278856277466
Validation loss: 2.5746107203986055

Epoch: 5| Step: 7
Training loss: 3.3539092540740967
Validation loss: 2.569204863681588

Epoch: 5| Step: 8
Training loss: 2.521287441253662
Validation loss: 2.5631044756981636

Epoch: 5| Step: 9
Training loss: 3.354579210281372
Validation loss: 2.563028294553039

Epoch: 5| Step: 10
Training loss: 3.070521116256714
Validation loss: 2.5660159331496044

Epoch: 69| Step: 0
Training loss: 2.8578240871429443
Validation loss: 2.570728240474578

Epoch: 5| Step: 1
Training loss: 2.277742624282837
Validation loss: 2.5875545470945296

Epoch: 5| Step: 2
Training loss: 3.1698734760284424
Validation loss: 2.602368467597551

Epoch: 5| Step: 3
Training loss: 2.772963762283325
Validation loss: 2.611952361240182

Epoch: 5| Step: 4
Training loss: 2.9389421939849854
Validation loss: 2.6040916519780315

Epoch: 5| Step: 5
Training loss: 2.524223804473877
Validation loss: 2.600453597243114

Epoch: 5| Step: 6
Training loss: 2.686561107635498
Validation loss: 2.588265562570223

Epoch: 5| Step: 7
Training loss: 2.9642465114593506
Validation loss: 2.5702965259552

Epoch: 5| Step: 8
Training loss: 3.398911237716675
Validation loss: 2.558972038248534

Epoch: 5| Step: 9
Training loss: 1.899205207824707
Validation loss: 2.555587330172139

Epoch: 5| Step: 10
Training loss: 2.7703804969787598
Validation loss: 2.565021414910593

Epoch: 70| Step: 0
Training loss: 2.3037641048431396
Validation loss: 2.5771636809072187

Epoch: 5| Step: 1
Training loss: 2.649993419647217
Validation loss: 2.578571511853126

Epoch: 5| Step: 2
Training loss: 3.8060336112976074
Validation loss: 2.5750107355015253

Epoch: 5| Step: 3
Training loss: 2.4418015480041504
Validation loss: 2.5666314658298286

Epoch: 5| Step: 4
Training loss: 1.9830478429794312
Validation loss: 2.560589377598096

Epoch: 5| Step: 5
Training loss: 3.374809741973877
Validation loss: 2.552291177934216

Epoch: 5| Step: 6
Training loss: 3.4611868858337402
Validation loss: 2.5521247643296436

Epoch: 5| Step: 7
Training loss: 2.342740535736084
Validation loss: 2.5548191608921176

Epoch: 5| Step: 8
Training loss: 2.56217622756958
Validation loss: 2.547560355996573

Epoch: 5| Step: 9
Training loss: 2.6492233276367188
Validation loss: 2.5513862666263374

Epoch: 5| Step: 10
Training loss: 2.6070895195007324
Validation loss: 2.557033625982141

Epoch: 71| Step: 0
Training loss: 2.865381956100464
Validation loss: 2.5612801774855583

Epoch: 5| Step: 1
Training loss: 2.588082790374756
Validation loss: 2.5587470736554874

Epoch: 5| Step: 2
Training loss: 2.74177885055542
Validation loss: 2.5579995596280662

Epoch: 5| Step: 3
Training loss: 1.9120047092437744
Validation loss: 2.5557325373413744

Epoch: 5| Step: 4
Training loss: 2.2716243267059326
Validation loss: 2.551037275662986

Epoch: 5| Step: 5
Training loss: 2.796867847442627
Validation loss: 2.549543539683024

Epoch: 5| Step: 6
Training loss: 3.8440451622009277
Validation loss: 2.546752501559514

Epoch: 5| Step: 7
Training loss: 2.4284470081329346
Validation loss: 2.5497091303589525

Epoch: 5| Step: 8
Training loss: 2.9523472785949707
Validation loss: 2.5492814817736225

Epoch: 5| Step: 9
Training loss: 2.957691192626953
Validation loss: 2.551407365388768

Epoch: 5| Step: 10
Training loss: 2.710749626159668
Validation loss: 2.5472300129552043

Epoch: 72| Step: 0
Training loss: 2.7499942779541016
Validation loss: 2.5541360890993507

Epoch: 5| Step: 1
Training loss: 3.2292354106903076
Validation loss: 2.559707615965156

Epoch: 5| Step: 2
Training loss: 2.0984671115875244
Validation loss: 2.561572874746015

Epoch: 5| Step: 3
Training loss: 2.470139741897583
Validation loss: 2.566360927397205

Epoch: 5| Step: 4
Training loss: 2.695478916168213
Validation loss: 2.566068906937876

Epoch: 5| Step: 5
Training loss: 3.1924936771392822
Validation loss: 2.560091967223793

Epoch: 5| Step: 6
Training loss: 3.4533157348632812
Validation loss: 2.555081375183598

Epoch: 5| Step: 7
Training loss: 2.7147326469421387
Validation loss: 2.549194235955515

Epoch: 5| Step: 8
Training loss: 2.9802136421203613
Validation loss: 2.5481073676898913

Epoch: 5| Step: 9
Training loss: 1.8952305316925049
Validation loss: 2.5474400622870332

Epoch: 5| Step: 10
Training loss: 2.5034313201904297
Validation loss: 2.5411108309222805

Epoch: 73| Step: 0
Training loss: 2.0739684104919434
Validation loss: 2.5402369345388105

Epoch: 5| Step: 1
Training loss: 2.30098032951355
Validation loss: 2.54362379863698

Epoch: 5| Step: 2
Training loss: 3.015944004058838
Validation loss: 2.54208267119623

Epoch: 5| Step: 3
Training loss: 2.5293402671813965
Validation loss: 2.5428650532999346

Epoch: 5| Step: 4
Training loss: 2.794243335723877
Validation loss: 2.5406503959368636

Epoch: 5| Step: 5
Training loss: 2.1256661415100098
Validation loss: 2.53917557449751

Epoch: 5| Step: 6
Training loss: 2.8957107067108154
Validation loss: 2.5396866388218378

Epoch: 5| Step: 7
Training loss: 3.2521934509277344
Validation loss: 2.540301207573183

Epoch: 5| Step: 8
Training loss: 2.908066749572754
Validation loss: 2.5394579928408385

Epoch: 5| Step: 9
Training loss: 2.780945301055908
Validation loss: 2.5425071741945002

Epoch: 5| Step: 10
Training loss: 3.417327880859375
Validation loss: 2.544940451140045

Epoch: 74| Step: 0
Training loss: 2.1606955528259277
Validation loss: 2.553471524228332

Epoch: 5| Step: 1
Training loss: 2.548353672027588
Validation loss: 2.543625908513223

Epoch: 5| Step: 2
Training loss: 3.3219552040100098
Validation loss: 2.541546283229705

Epoch: 5| Step: 3
Training loss: 2.841853141784668
Validation loss: 2.541421887695148

Epoch: 5| Step: 4
Training loss: 3.1622061729431152
Validation loss: 2.5412087209763063

Epoch: 5| Step: 5
Training loss: 2.866525888442993
Validation loss: 2.536209252572829

Epoch: 5| Step: 6
Training loss: 3.468693256378174
Validation loss: 2.536899002649451

Epoch: 5| Step: 7
Training loss: 2.0852158069610596
Validation loss: 2.5366630682381253

Epoch: 5| Step: 8
Training loss: 2.878941059112549
Validation loss: 2.5333636012128604

Epoch: 5| Step: 9
Training loss: 2.214921236038208
Validation loss: 2.5347775772053707

Epoch: 5| Step: 10
Training loss: 2.3238022327423096
Validation loss: 2.530562352108699

Epoch: 75| Step: 0
Training loss: 2.590043544769287
Validation loss: 2.53564110366247

Epoch: 5| Step: 1
Training loss: 2.859525203704834
Validation loss: 2.5312243456481607

Epoch: 5| Step: 2
Training loss: 2.838101387023926
Validation loss: 2.53150107783656

Epoch: 5| Step: 3
Training loss: 1.9680507183074951
Validation loss: 2.5304715069391395

Epoch: 5| Step: 4
Training loss: 2.124422550201416
Validation loss: 2.532910044475268

Epoch: 5| Step: 5
Training loss: 3.0208096504211426
Validation loss: 2.529490678541122

Epoch: 5| Step: 6
Training loss: 2.7083449363708496
Validation loss: 2.532832145690918

Epoch: 5| Step: 7
Training loss: 2.852900981903076
Validation loss: 2.532201797731461

Epoch: 5| Step: 8
Training loss: 2.7719390392303467
Validation loss: 2.5292331505847234

Epoch: 5| Step: 9
Training loss: 2.752962112426758
Validation loss: 2.52899000465229

Epoch: 5| Step: 10
Training loss: 3.509815216064453
Validation loss: 2.531470106494042

Epoch: 76| Step: 0
Training loss: 2.0233898162841797
Validation loss: 2.5336015429548038

Epoch: 5| Step: 1
Training loss: 2.463840961456299
Validation loss: 2.5283087786807807

Epoch: 5| Step: 2
Training loss: 2.9389567375183105
Validation loss: 2.5309511230837916

Epoch: 5| Step: 3
Training loss: 2.6248793601989746
Validation loss: 2.526711348564394

Epoch: 5| Step: 4
Training loss: 2.8766276836395264
Validation loss: 2.528279435250067

Epoch: 5| Step: 5
Training loss: 3.714674711227417
Validation loss: 2.5289492273843415

Epoch: 5| Step: 6
Training loss: 2.9830806255340576
Validation loss: 2.523286957894602

Epoch: 5| Step: 7
Training loss: 2.1227922439575195
Validation loss: 2.524856344346077

Epoch: 5| Step: 8
Training loss: 2.755321741104126
Validation loss: 2.5258792959233767

Epoch: 5| Step: 9
Training loss: 2.764185905456543
Validation loss: 2.523428414457588

Epoch: 5| Step: 10
Training loss: 2.6029915809631348
Validation loss: 2.5219186634145756

Epoch: 77| Step: 0
Training loss: 2.189743757247925
Validation loss: 2.5286747127450924

Epoch: 5| Step: 1
Training loss: 2.44380521774292
Validation loss: 2.5391940045100387

Epoch: 5| Step: 2
Training loss: 2.5316414833068848
Validation loss: 2.544157874199652

Epoch: 5| Step: 3
Training loss: 2.7290334701538086
Validation loss: 2.5535191361622145

Epoch: 5| Step: 4
Training loss: 2.4403445720672607
Validation loss: 2.554131184854815

Epoch: 5| Step: 5
Training loss: 2.3798768520355225
Validation loss: 2.5505124830430552

Epoch: 5| Step: 6
Training loss: 3.5434975624084473
Validation loss: 2.5416447295937488

Epoch: 5| Step: 7
Training loss: 2.5184712409973145
Validation loss: 2.5321291697922574

Epoch: 5| Step: 8
Training loss: 3.2319443225860596
Validation loss: 2.521588617755521

Epoch: 5| Step: 9
Training loss: 3.237511396408081
Validation loss: 2.5212602846084105

Epoch: 5| Step: 10
Training loss: 2.658416748046875
Validation loss: 2.517216992634599

Epoch: 78| Step: 0
Training loss: 2.8863017559051514
Validation loss: 2.5173136547047603

Epoch: 5| Step: 1
Training loss: 3.2723026275634766
Validation loss: 2.517085511197326

Epoch: 5| Step: 2
Training loss: 2.8794336318969727
Validation loss: 2.5165504640148533

Epoch: 5| Step: 3
Training loss: 2.403411388397217
Validation loss: 2.51815604394482

Epoch: 5| Step: 4
Training loss: 2.51200532913208
Validation loss: 2.51939974036268

Epoch: 5| Step: 5
Training loss: 2.9009997844696045
Validation loss: 2.5236477595503612

Epoch: 5| Step: 6
Training loss: 2.0802221298217773
Validation loss: 2.5212712492994083

Epoch: 5| Step: 7
Training loss: 2.6348421573638916
Validation loss: 2.521614625889768

Epoch: 5| Step: 8
Training loss: 3.3060555458068848
Validation loss: 2.5322718517754668

Epoch: 5| Step: 9
Training loss: 2.7382900714874268
Validation loss: 2.5337887374303674

Epoch: 5| Step: 10
Training loss: 2.1763834953308105
Validation loss: 2.5326020179256314

Epoch: 79| Step: 0
Training loss: 2.6011385917663574
Validation loss: 2.529187533163255

Epoch: 5| Step: 1
Training loss: 3.0121264457702637
Validation loss: 2.528461597299063

Epoch: 5| Step: 2
Training loss: 3.151557207107544
Validation loss: 2.523062272738385

Epoch: 5| Step: 3
Training loss: 2.3950581550598145
Validation loss: 2.5154607962536555

Epoch: 5| Step: 4
Training loss: 2.556694507598877
Validation loss: 2.517312302384325

Epoch: 5| Step: 5
Training loss: 3.139444351196289
Validation loss: 2.5188710022998113

Epoch: 5| Step: 6
Training loss: 2.9777050018310547
Validation loss: 2.522399119151536

Epoch: 5| Step: 7
Training loss: 2.259906053543091
Validation loss: 2.5209487433074624

Epoch: 5| Step: 8
Training loss: 2.53416109085083
Validation loss: 2.5285518400130735

Epoch: 5| Step: 9
Training loss: 2.1271872520446777
Validation loss: 2.5321489687888854

Epoch: 5| Step: 10
Training loss: 3.1231751441955566
Validation loss: 2.526874085908295

Epoch: 80| Step: 0
Training loss: 3.0072896480560303
Validation loss: 2.522553860500295

Epoch: 5| Step: 1
Training loss: 2.8665428161621094
Validation loss: 2.5200827813917592

Epoch: 5| Step: 2
Training loss: 3.0167884826660156
Validation loss: 2.5172471487393944

Epoch: 5| Step: 3
Training loss: 2.7527711391448975
Validation loss: 2.5201563527507167

Epoch: 5| Step: 4
Training loss: 2.003840446472168
Validation loss: 2.519091793285903

Epoch: 5| Step: 5
Training loss: 2.8070147037506104
Validation loss: 2.520368604249852

Epoch: 5| Step: 6
Training loss: 2.8562700748443604
Validation loss: 2.521534360865111

Epoch: 5| Step: 7
Training loss: 2.690310478210449
Validation loss: 2.5269838994549167

Epoch: 5| Step: 8
Training loss: 2.663663864135742
Validation loss: 2.523728694967044

Epoch: 5| Step: 9
Training loss: 2.646733045578003
Validation loss: 2.522999537888394

Epoch: 5| Step: 10
Training loss: 2.5370078086853027
Validation loss: 2.5163382868612967

Epoch: 81| Step: 0
Training loss: 2.6456801891326904
Validation loss: 2.5192748654273247

Epoch: 5| Step: 1
Training loss: 1.9016094207763672
Validation loss: 2.518324536661948

Epoch: 5| Step: 2
Training loss: 3.0428683757781982
Validation loss: 2.5131466286156767

Epoch: 5| Step: 3
Training loss: 2.629318952560425
Validation loss: 2.5176771994559997

Epoch: 5| Step: 4
Training loss: 3.4680771827697754
Validation loss: 2.5197840736758326

Epoch: 5| Step: 5
Training loss: 2.9745168685913086
Validation loss: 2.5182406338312293

Epoch: 5| Step: 6
Training loss: 1.949493408203125
Validation loss: 2.524447689774216

Epoch: 5| Step: 7
Training loss: 2.7245242595672607
Validation loss: 2.5366752019492527

Epoch: 5| Step: 8
Training loss: 3.066974639892578
Validation loss: 2.532448330233174

Epoch: 5| Step: 9
Training loss: 2.799726963043213
Validation loss: 2.52120473307948

Epoch: 5| Step: 10
Training loss: 2.5334532260894775
Validation loss: 2.521948988719653

Epoch: 82| Step: 0
Training loss: 2.382704734802246
Validation loss: 2.5195614343048423

Epoch: 5| Step: 1
Training loss: 3.2359747886657715
Validation loss: 2.5097878235642628

Epoch: 5| Step: 2
Training loss: 3.0619726181030273
Validation loss: 2.512359780649985

Epoch: 5| Step: 3
Training loss: 2.3074874877929688
Validation loss: 2.5124243074847805

Epoch: 5| Step: 4
Training loss: 2.901712656021118
Validation loss: 2.510420935128325

Epoch: 5| Step: 5
Training loss: 1.7646642923355103
Validation loss: 2.512963274473785

Epoch: 5| Step: 6
Training loss: 2.7933125495910645
Validation loss: 2.514848509142476

Epoch: 5| Step: 7
Training loss: 2.445133686065674
Validation loss: 2.51492251119306

Epoch: 5| Step: 8
Training loss: 3.0418572425842285
Validation loss: 2.510680208923996

Epoch: 5| Step: 9
Training loss: 2.486509323120117
Validation loss: 2.5101560623415056

Epoch: 5| Step: 10
Training loss: 3.4506945610046387
Validation loss: 2.5097959631232807

Epoch: 83| Step: 0
Training loss: 2.997472047805786
Validation loss: 2.5086743293269986

Epoch: 5| Step: 1
Training loss: 2.43518328666687
Validation loss: 2.5089456753064225

Epoch: 5| Step: 2
Training loss: 2.8374438285827637
Validation loss: 2.512070045676283

Epoch: 5| Step: 3
Training loss: 2.6556663513183594
Validation loss: 2.5131363407258065

Epoch: 5| Step: 4
Training loss: 2.217611074447632
Validation loss: 2.509701116110689

Epoch: 5| Step: 5
Training loss: 2.453773021697998
Validation loss: 2.5118477805968253

Epoch: 5| Step: 6
Training loss: 2.8966164588928223
Validation loss: 2.5195485597015708

Epoch: 5| Step: 7
Training loss: 3.433537006378174
Validation loss: 2.5226670234434065

Epoch: 5| Step: 8
Training loss: 2.2802724838256836
Validation loss: 2.526682907535184

Epoch: 5| Step: 9
Training loss: 3.026235342025757
Validation loss: 2.5190093081484557

Epoch: 5| Step: 10
Training loss: 2.3731720447540283
Validation loss: 2.51324559796241

Epoch: 84| Step: 0
Training loss: 2.5679965019226074
Validation loss: 2.511062258033342

Epoch: 5| Step: 1
Training loss: 3.528733015060425
Validation loss: 2.5048324369615123

Epoch: 5| Step: 2
Training loss: 2.388357639312744
Validation loss: 2.508321121174802

Epoch: 5| Step: 3
Training loss: 2.7729618549346924
Validation loss: 2.500299704972134

Epoch: 5| Step: 4
Training loss: 2.047579288482666
Validation loss: 2.508051541543776

Epoch: 5| Step: 5
Training loss: 2.962040901184082
Validation loss: 2.5049253791891117

Epoch: 5| Step: 6
Training loss: 3.1642534732818604
Validation loss: 2.5157100769781295

Epoch: 5| Step: 7
Training loss: 2.8289895057678223
Validation loss: 2.5189523991718086

Epoch: 5| Step: 8
Training loss: 2.680351972579956
Validation loss: 2.5099935941798712

Epoch: 5| Step: 9
Training loss: 2.1618425846099854
Validation loss: 2.510530707656696

Epoch: 5| Step: 10
Training loss: 2.5147416591644287
Validation loss: 2.507656443503595

Epoch: 85| Step: 0
Training loss: 3.2792160511016846
Validation loss: 2.510167924306726

Epoch: 5| Step: 1
Training loss: 2.6805005073547363
Validation loss: 2.510725349508306

Epoch: 5| Step: 2
Training loss: 2.054809093475342
Validation loss: 2.5086795001901607

Epoch: 5| Step: 3
Training loss: 2.6612353324890137
Validation loss: 2.507127005566833

Epoch: 5| Step: 4
Training loss: 2.8108458518981934
Validation loss: 2.5111690849386235

Epoch: 5| Step: 5
Training loss: 2.26029896736145
Validation loss: 2.515530881061349

Epoch: 5| Step: 6
Training loss: 2.5365047454833984
Validation loss: 2.505085055546094

Epoch: 5| Step: 7
Training loss: 2.5318827629089355
Validation loss: 2.502839196112848

Epoch: 5| Step: 8
Training loss: 3.0515670776367188
Validation loss: 2.499494578248711

Epoch: 5| Step: 9
Training loss: 3.06013822555542
Validation loss: 2.4993434657332716

Epoch: 5| Step: 10
Training loss: 2.7377688884735107
Validation loss: 2.5010902958531536

Epoch: 86| Step: 0
Training loss: 2.552772283554077
Validation loss: 2.501506077345981

Epoch: 5| Step: 1
Training loss: 2.7514214515686035
Validation loss: 2.500016684173256

Epoch: 5| Step: 2
Training loss: 2.9857177734375
Validation loss: 2.4980744341368317

Epoch: 5| Step: 3
Training loss: 2.8675103187561035
Validation loss: 2.5007768907854633

Epoch: 5| Step: 4
Training loss: 3.235496997833252
Validation loss: 2.4966299251843522

Epoch: 5| Step: 5
Training loss: 2.7314512729644775
Validation loss: 2.5074339835874495

Epoch: 5| Step: 6
Training loss: 2.8056187629699707
Validation loss: 2.5021809634341987

Epoch: 5| Step: 7
Training loss: 2.1013801097869873
Validation loss: 2.5034727127321306

Epoch: 5| Step: 8
Training loss: 2.747274875640869
Validation loss: 2.5047218415044967

Epoch: 5| Step: 9
Training loss: 2.3148958683013916
Validation loss: 2.500494549351354

Epoch: 5| Step: 10
Training loss: 2.52707839012146
Validation loss: 2.5009983611363236

Epoch: 87| Step: 0
Training loss: 2.707432746887207
Validation loss: 2.4980343913519256

Epoch: 5| Step: 1
Training loss: 3.0825891494750977
Validation loss: 2.493276831924274

Epoch: 5| Step: 2
Training loss: 2.478605031967163
Validation loss: 2.498155568235664

Epoch: 5| Step: 3
Training loss: 2.0119121074676514
Validation loss: 2.49834797715628

Epoch: 5| Step: 4
Training loss: 2.316486358642578
Validation loss: 2.4955420442806777

Epoch: 5| Step: 5
Training loss: 2.499207019805908
Validation loss: 2.4973034422884703

Epoch: 5| Step: 6
Training loss: 2.5360333919525146
Validation loss: 2.5008031937383834

Epoch: 5| Step: 7
Training loss: 2.563190221786499
Validation loss: 2.4994248805507535

Epoch: 5| Step: 8
Training loss: 3.6268973350524902
Validation loss: 2.4956512681899534

Epoch: 5| Step: 9
Training loss: 2.8484106063842773
Validation loss: 2.493738293647766

Epoch: 5| Step: 10
Training loss: 2.9309067726135254
Validation loss: 2.496757630378969

Epoch: 88| Step: 0
Training loss: 3.065530776977539
Validation loss: 2.494543170416227

Epoch: 5| Step: 1
Training loss: 2.468146562576294
Validation loss: 2.4973635827341387

Epoch: 5| Step: 2
Training loss: 2.5257651805877686
Validation loss: 2.4943353796517975

Epoch: 5| Step: 3
Training loss: 2.827892541885376
Validation loss: 2.4953973370213665

Epoch: 5| Step: 4
Training loss: 1.9103786945343018
Validation loss: 2.4967004868292038

Epoch: 5| Step: 5
Training loss: 2.5723819732666016
Validation loss: 2.494603023734144

Epoch: 5| Step: 6
Training loss: 2.7844290733337402
Validation loss: 2.500967235975368

Epoch: 5| Step: 7
Training loss: 2.7574963569641113
Validation loss: 2.5022224149396344

Epoch: 5| Step: 8
Training loss: 2.5734901428222656
Validation loss: 2.49972782340101

Epoch: 5| Step: 9
Training loss: 3.2179114818573
Validation loss: 2.507561832345942

Epoch: 5| Step: 10
Training loss: 2.8577895164489746
Validation loss: 2.5166667456267984

Epoch: 89| Step: 0
Training loss: 3.020880937576294
Validation loss: 2.518432383896202

Epoch: 5| Step: 1
Training loss: 2.5626370906829834
Validation loss: 2.516381966170444

Epoch: 5| Step: 2
Training loss: 2.9340062141418457
Validation loss: 2.5109147051329255

Epoch: 5| Step: 3
Training loss: 2.25947642326355
Validation loss: 2.498938311812698

Epoch: 5| Step: 4
Training loss: 2.3223063945770264
Validation loss: 2.4879680654054046

Epoch: 5| Step: 5
Training loss: 2.3082942962646484
Validation loss: 2.4849906070258028

Epoch: 5| Step: 6
Training loss: 2.441542148590088
Validation loss: 2.4890383533252183

Epoch: 5| Step: 7
Training loss: 3.51493763923645
Validation loss: 2.489245988989389

Epoch: 5| Step: 8
Training loss: 2.7944254875183105
Validation loss: 2.491430805575463

Epoch: 5| Step: 9
Training loss: 2.790924072265625
Validation loss: 2.4922714669217347

Epoch: 5| Step: 10
Training loss: 2.538256883621216
Validation loss: 2.490722658813641

Epoch: 90| Step: 0
Training loss: 2.5702950954437256
Validation loss: 2.49091947719615

Epoch: 5| Step: 1
Training loss: 2.344780445098877
Validation loss: 2.489331283876973

Epoch: 5| Step: 2
Training loss: 2.5228781700134277
Validation loss: 2.492567995543121

Epoch: 5| Step: 3
Training loss: 2.367845058441162
Validation loss: 2.4939122712740334

Epoch: 5| Step: 4
Training loss: 2.8373706340789795
Validation loss: 2.5198527330993326

Epoch: 5| Step: 5
Training loss: 2.535031795501709
Validation loss: 2.5241767667954966

Epoch: 5| Step: 6
Training loss: 3.605665683746338
Validation loss: 2.5297567229117117

Epoch: 5| Step: 7
Training loss: 2.727109432220459
Validation loss: 2.5163759518695135

Epoch: 5| Step: 8
Training loss: 3.0352234840393066
Validation loss: 2.5005575969655025

Epoch: 5| Step: 9
Training loss: 2.567326068878174
Validation loss: 2.484371277593797

Epoch: 5| Step: 10
Training loss: 2.569963216781616
Validation loss: 2.4873630923609578

Epoch: 91| Step: 0
Training loss: 2.9807381629943848
Validation loss: 2.485189535284555

Epoch: 5| Step: 1
Training loss: 1.8662402629852295
Validation loss: 2.4863796951950237

Epoch: 5| Step: 2
Training loss: 2.633807420730591
Validation loss: 2.48914695555164

Epoch: 5| Step: 3
Training loss: 2.8280320167541504
Validation loss: 2.487096463480303

Epoch: 5| Step: 4
Training loss: 2.6748509407043457
Validation loss: 2.48903250950639

Epoch: 5| Step: 5
Training loss: 3.060488700866699
Validation loss: 2.4908838502822386

Epoch: 5| Step: 6
Training loss: 2.620462417602539
Validation loss: 2.4907688530542518

Epoch: 5| Step: 7
Training loss: 2.5058798789978027
Validation loss: 2.493901288637551

Epoch: 5| Step: 8
Training loss: 2.463728666305542
Validation loss: 2.4900849070600284

Epoch: 5| Step: 9
Training loss: 3.377988815307617
Validation loss: 2.488360483159301

Epoch: 5| Step: 10
Training loss: 2.47221302986145
Validation loss: 2.483727111611315

Epoch: 92| Step: 0
Training loss: 2.7106902599334717
Validation loss: 2.482432652545232

Epoch: 5| Step: 1
Training loss: 1.3530607223510742
Validation loss: 2.4841030874559955

Epoch: 5| Step: 2
Training loss: 2.9654908180236816
Validation loss: 2.4832488541961997

Epoch: 5| Step: 3
Training loss: 2.317258834838867
Validation loss: 2.4801509175249326

Epoch: 5| Step: 4
Training loss: 3.1237597465515137
Validation loss: 2.481225582861131

Epoch: 5| Step: 5
Training loss: 3.070082902908325
Validation loss: 2.4839388170549945

Epoch: 5| Step: 6
Training loss: 2.316972255706787
Validation loss: 2.487955157474805

Epoch: 5| Step: 7
Training loss: 3.084178924560547
Validation loss: 2.4868654692044823

Epoch: 5| Step: 8
Training loss: 2.8268344402313232
Validation loss: 2.4905915311587754

Epoch: 5| Step: 9
Training loss: 3.345057964324951
Validation loss: 2.498846148931852

Epoch: 5| Step: 10
Training loss: 2.337130308151245
Validation loss: 2.499175553680748

Epoch: 93| Step: 0
Training loss: 3.114906072616577
Validation loss: 2.503528989771361

Epoch: 5| Step: 1
Training loss: 3.239989757537842
Validation loss: 2.5065641736471527

Epoch: 5| Step: 2
Training loss: 2.6316511631011963
Validation loss: 2.5017765516875894

Epoch: 5| Step: 3
Training loss: 2.471247434616089
Validation loss: 2.5040251439617527

Epoch: 5| Step: 4
Training loss: 2.393266201019287
Validation loss: 2.498137890651662

Epoch: 5| Step: 5
Training loss: 3.269416093826294
Validation loss: 2.489905911107217

Epoch: 5| Step: 6
Training loss: 2.7499263286590576
Validation loss: 2.479977015526064

Epoch: 5| Step: 7
Training loss: 1.8668928146362305
Validation loss: 2.4739801576060634

Epoch: 5| Step: 8
Training loss: 2.4181110858917236
Validation loss: 2.4754896266486055

Epoch: 5| Step: 9
Training loss: 2.984823226928711
Validation loss: 2.4742691337421374

Epoch: 5| Step: 10
Training loss: 2.2984189987182617
Validation loss: 2.4764942174316733

Epoch: 94| Step: 0
Training loss: 2.227566719055176
Validation loss: 2.478764357105378

Epoch: 5| Step: 1
Training loss: 2.259929895401001
Validation loss: 2.4759096612212477

Epoch: 5| Step: 2
Training loss: 2.8161282539367676
Validation loss: 2.4803870954821186

Epoch: 5| Step: 3
Training loss: 3.1472039222717285
Validation loss: 2.4781058860081497

Epoch: 5| Step: 4
Training loss: 3.0373241901397705
Validation loss: 2.4854452635652278

Epoch: 5| Step: 5
Training loss: 2.50648832321167
Validation loss: 2.487041317006593

Epoch: 5| Step: 6
Training loss: 2.7340919971466064
Validation loss: 2.485244768922047

Epoch: 5| Step: 7
Training loss: 2.34757137298584
Validation loss: 2.484401438825874

Epoch: 5| Step: 8
Training loss: 3.599247694015503
Validation loss: 2.4817600647608438

Epoch: 5| Step: 9
Training loss: 2.4650847911834717
Validation loss: 2.485264819155457

Epoch: 5| Step: 10
Training loss: 2.2379560470581055
Validation loss: 2.49365835548729

Epoch: 95| Step: 0
Training loss: 2.6810925006866455
Validation loss: 2.492454646736063

Epoch: 5| Step: 1
Training loss: 2.4707822799682617
Validation loss: 2.4780636243922736

Epoch: 5| Step: 2
Training loss: 1.9351383447647095
Validation loss: 2.471820205770513

Epoch: 5| Step: 3
Training loss: 3.2569637298583984
Validation loss: 2.471246665523898

Epoch: 5| Step: 4
Training loss: 2.4599788188934326
Validation loss: 2.4720593908781647

Epoch: 5| Step: 5
Training loss: 2.709465742111206
Validation loss: 2.4716684151721258

Epoch: 5| Step: 6
Training loss: 2.8979573249816895
Validation loss: 2.472640391319029

Epoch: 5| Step: 7
Training loss: 3.0574002265930176
Validation loss: 2.471902597335077

Epoch: 5| Step: 8
Training loss: 3.0090503692626953
Validation loss: 2.473560820343674

Epoch: 5| Step: 9
Training loss: 2.8620946407318115
Validation loss: 2.4709792085873183

Epoch: 5| Step: 10
Training loss: 2.0468509197235107
Validation loss: 2.4692887131885817

Epoch: 96| Step: 0
Training loss: 1.9986670017242432
Validation loss: 2.4743032224716677

Epoch: 5| Step: 1
Training loss: 2.4208576679229736
Validation loss: 2.47392669288061

Epoch: 5| Step: 2
Training loss: 3.065904140472412
Validation loss: 2.4763519738310125

Epoch: 5| Step: 3
Training loss: 2.81484055519104
Validation loss: 2.482182641183176

Epoch: 5| Step: 4
Training loss: 2.7272849082946777
Validation loss: 2.487105579786403

Epoch: 5| Step: 5
Training loss: 2.6177518367767334
Validation loss: 2.482196182333013

Epoch: 5| Step: 6
Training loss: 2.62577486038208
Validation loss: 2.473715356601182

Epoch: 5| Step: 7
Training loss: 3.032762050628662
Validation loss: 2.470049173601212

Epoch: 5| Step: 8
Training loss: 3.2353057861328125
Validation loss: 2.4713934980412966

Epoch: 5| Step: 9
Training loss: 2.606921672821045
Validation loss: 2.4747949364364787

Epoch: 5| Step: 10
Training loss: 2.230231761932373
Validation loss: 2.473189530834075

Epoch: 97| Step: 0
Training loss: 3.0823237895965576
Validation loss: 2.476600598263484

Epoch: 5| Step: 1
Training loss: 2.26469087600708
Validation loss: 2.4794129607498006

Epoch: 5| Step: 2
Training loss: 2.1451916694641113
Validation loss: 2.479373208938106

Epoch: 5| Step: 3
Training loss: 2.4301695823669434
Validation loss: 2.477101179861253

Epoch: 5| Step: 4
Training loss: 2.2010350227355957
Validation loss: 2.4811411314113165

Epoch: 5| Step: 5
Training loss: 2.9159576892852783
Validation loss: 2.4842065636829664

Epoch: 5| Step: 6
Training loss: 3.2967140674591064
Validation loss: 2.494551166411369

Epoch: 5| Step: 7
Training loss: 2.6511826515197754
Validation loss: 2.4927087137776036

Epoch: 5| Step: 8
Training loss: 2.6584396362304688
Validation loss: 2.4862527437107538

Epoch: 5| Step: 9
Training loss: 2.961578845977783
Validation loss: 2.4814045352320515

Epoch: 5| Step: 10
Training loss: 2.9550952911376953
Validation loss: 2.473005405036352

Epoch: 98| Step: 0
Training loss: 3.3056769371032715
Validation loss: 2.470815194550381

Epoch: 5| Step: 1
Training loss: 2.8293724060058594
Validation loss: 2.466484103151547

Epoch: 5| Step: 2
Training loss: 2.791687250137329
Validation loss: 2.4638253078665784

Epoch: 5| Step: 3
Training loss: 2.5493035316467285
Validation loss: 2.466864867876935

Epoch: 5| Step: 4
Training loss: 2.662731647491455
Validation loss: 2.4647681456740185

Epoch: 5| Step: 5
Training loss: 2.1873836517333984
Validation loss: 2.464560306200417

Epoch: 5| Step: 6
Training loss: 2.7268199920654297
Validation loss: 2.460192057394212

Epoch: 5| Step: 7
Training loss: 1.9660818576812744
Validation loss: 2.4646431425566315

Epoch: 5| Step: 8
Training loss: 3.1470725536346436
Validation loss: 2.472601721363683

Epoch: 5| Step: 9
Training loss: 2.842686891555786
Validation loss: 2.4828039933276433

Epoch: 5| Step: 10
Training loss: 2.310270309448242
Validation loss: 2.4854193810493714

Epoch: 99| Step: 0
Training loss: 2.2228634357452393
Validation loss: 2.4800955992872997

Epoch: 5| Step: 1
Training loss: 3.0808472633361816
Validation loss: 2.46865746026398

Epoch: 5| Step: 2
Training loss: 2.566868305206299
Validation loss: 2.4632031968844834

Epoch: 5| Step: 3
Training loss: 2.6877031326293945
Validation loss: 2.462777071101691

Epoch: 5| Step: 4
Training loss: 2.7747154235839844
Validation loss: 2.4623785147102932

Epoch: 5| Step: 5
Training loss: 2.49739670753479
Validation loss: 2.467733165269257

Epoch: 5| Step: 6
Training loss: 3.1167831420898438
Validation loss: 2.473402033569992

Epoch: 5| Step: 7
Training loss: 3.062894105911255
Validation loss: 2.4724607698379026

Epoch: 5| Step: 8
Training loss: 2.4738264083862305
Validation loss: 2.4757892265114734

Epoch: 5| Step: 9
Training loss: 2.4142258167266846
Validation loss: 2.479182417674731

Epoch: 5| Step: 10
Training loss: 2.599226713180542
Validation loss: 2.4670660803394933

Epoch: 100| Step: 0
Training loss: 2.4270694255828857
Validation loss: 2.456270007676976

Epoch: 5| Step: 1
Training loss: 2.876918315887451
Validation loss: 2.455253706183485

Epoch: 5| Step: 2
Training loss: 3.037848711013794
Validation loss: 2.463171056521836

Epoch: 5| Step: 3
Training loss: 3.0135035514831543
Validation loss: 2.500525197675151

Epoch: 5| Step: 4
Training loss: 2.1088521480560303
Validation loss: 2.5093382891788276

Epoch: 5| Step: 5
Training loss: 2.298552989959717
Validation loss: 2.520566737780007

Epoch: 5| Step: 6
Training loss: 2.367357015609741
Validation loss: 2.5382922028982513

Epoch: 5| Step: 7
Training loss: 2.8231847286224365
Validation loss: 2.5332283358420096

Epoch: 5| Step: 8
Training loss: 3.1083948612213135
Validation loss: 2.499289422906855

Epoch: 5| Step: 9
Training loss: 3.0240676403045654
Validation loss: 2.46873910709094

Epoch: 5| Step: 10
Training loss: 2.276949882507324
Validation loss: 2.4584788276303198

Epoch: 101| Step: 0
Training loss: 2.5648715496063232
Validation loss: 2.451371200623051

Epoch: 5| Step: 1
Training loss: 2.2728803157806396
Validation loss: 2.4512763459195375

Epoch: 5| Step: 2
Training loss: 3.334158420562744
Validation loss: 2.460207026491883

Epoch: 5| Step: 3
Training loss: 2.9458701610565186
Validation loss: 2.467119247682633

Epoch: 5| Step: 4
Training loss: 2.2501583099365234
Validation loss: 2.4832320059499433

Epoch: 5| Step: 5
Training loss: 1.893682837486267
Validation loss: 2.478201235494306

Epoch: 5| Step: 6
Training loss: 2.829756498336792
Validation loss: 2.472667481309624

Epoch: 5| Step: 7
Training loss: 3.0372977256774902
Validation loss: 2.4615770206656507

Epoch: 5| Step: 8
Training loss: 2.860718011856079
Validation loss: 2.4555034047813824

Epoch: 5| Step: 9
Training loss: 2.74955153465271
Validation loss: 2.4508910256047405

Epoch: 5| Step: 10
Training loss: 2.799154758453369
Validation loss: 2.4498790694821264

Epoch: 102| Step: 0
Training loss: 2.090013027191162
Validation loss: 2.4539893006765716

Epoch: 5| Step: 1
Training loss: 3.0278563499450684
Validation loss: 2.457488650916725

Epoch: 5| Step: 2
Training loss: 2.7714273929595947
Validation loss: 2.4553905366569437

Epoch: 5| Step: 3
Training loss: 2.754335403442383
Validation loss: 2.472036718040384

Epoch: 5| Step: 4
Training loss: 3.421292781829834
Validation loss: 2.483381791781354

Epoch: 5| Step: 5
Training loss: 2.8383946418762207
Validation loss: 2.4742127900482505

Epoch: 5| Step: 6
Training loss: 2.7374768257141113
Validation loss: 2.4685963046166206

Epoch: 5| Step: 7
Training loss: 2.202491521835327
Validation loss: 2.4636356830596924

Epoch: 5| Step: 8
Training loss: 2.40287446975708
Validation loss: 2.4614840066561134

Epoch: 5| Step: 9
Training loss: 2.908639907836914
Validation loss: 2.458276638420679

Epoch: 5| Step: 10
Training loss: 2.1157500743865967
Validation loss: 2.4540321391115905

Epoch: 103| Step: 0
Training loss: 2.7128829956054688
Validation loss: 2.450730739101287

Epoch: 5| Step: 1
Training loss: 1.8243224620819092
Validation loss: 2.444158064421787

Epoch: 5| Step: 2
Training loss: 3.464226245880127
Validation loss: 2.448804888674008

Epoch: 5| Step: 3
Training loss: 2.8231966495513916
Validation loss: 2.44648495540824

Epoch: 5| Step: 4
Training loss: 2.4970054626464844
Validation loss: 2.450931461908484

Epoch: 5| Step: 5
Training loss: 2.5122711658477783
Validation loss: 2.4567356442892425

Epoch: 5| Step: 6
Training loss: 2.812886953353882
Validation loss: 2.4522482861754713

Epoch: 5| Step: 7
Training loss: 2.56589937210083
Validation loss: 2.453243286378922

Epoch: 5| Step: 8
Training loss: 2.8936607837677
Validation loss: 2.461185383540328

Epoch: 5| Step: 9
Training loss: 2.909982681274414
Validation loss: 2.4580105248317925

Epoch: 5| Step: 10
Training loss: 2.158289670944214
Validation loss: 2.451513772369713

Epoch: 104| Step: 0
Training loss: 2.869800567626953
Validation loss: 2.457947205471736

Epoch: 5| Step: 1
Training loss: 2.8709285259246826
Validation loss: 2.4507394349703224

Epoch: 5| Step: 2
Training loss: 2.702547788619995
Validation loss: 2.451453302496223

Epoch: 5| Step: 3
Training loss: 3.190237045288086
Validation loss: 2.4472127396573304

Epoch: 5| Step: 4
Training loss: 3.0437653064727783
Validation loss: 2.450249969318349

Epoch: 5| Step: 5
Training loss: 2.3358826637268066
Validation loss: 2.448603440356511

Epoch: 5| Step: 6
Training loss: 2.404299259185791
Validation loss: 2.44834598290023

Epoch: 5| Step: 7
Training loss: 2.0276827812194824
Validation loss: 2.4594297883331135

Epoch: 5| Step: 8
Training loss: 2.81016206741333
Validation loss: 2.474148181176955

Epoch: 5| Step: 9
Training loss: 2.816061496734619
Validation loss: 2.4717207544593403

Epoch: 5| Step: 10
Training loss: 2.1882216930389404
Validation loss: 2.4795644308931086

Epoch: 105| Step: 0
Training loss: 2.7363429069519043
Validation loss: 2.4716096821651665

Epoch: 5| Step: 1
Training loss: 2.7354626655578613
Validation loss: 2.4652166930578088

Epoch: 5| Step: 2
Training loss: 2.0654983520507812
Validation loss: 2.4569626982494066

Epoch: 5| Step: 3
Training loss: 2.2509753704071045
Validation loss: 2.4519765171953427

Epoch: 5| Step: 4
Training loss: 2.8346195220947266
Validation loss: 2.4448068821302025

Epoch: 5| Step: 5
Training loss: 2.974254846572876
Validation loss: 2.4507138652186238

Epoch: 5| Step: 6
Training loss: 2.339184522628784
Validation loss: 2.4466243918224047

Epoch: 5| Step: 7
Training loss: 3.056647539138794
Validation loss: 2.4447873817977084

Epoch: 5| Step: 8
Training loss: 2.457852840423584
Validation loss: 2.4452161891486055

Epoch: 5| Step: 9
Training loss: 3.0899059772491455
Validation loss: 2.4436728697951122

Epoch: 5| Step: 10
Training loss: 2.7671964168548584
Validation loss: 2.4418423765449115

Epoch: 106| Step: 0
Training loss: 2.0531296730041504
Validation loss: 2.4454293609947286

Epoch: 5| Step: 1
Training loss: 2.429624319076538
Validation loss: 2.448311062269313

Epoch: 5| Step: 2
Training loss: 2.812328338623047
Validation loss: 2.4447744815580306

Epoch: 5| Step: 3
Training loss: 2.91884446144104
Validation loss: 2.4456936800351707

Epoch: 5| Step: 4
Training loss: 2.6490206718444824
Validation loss: 2.4429013395822174

Epoch: 5| Step: 5
Training loss: 2.5512070655822754
Validation loss: 2.4437962860189457

Epoch: 5| Step: 6
Training loss: 2.408698558807373
Validation loss: 2.442627127452563

Epoch: 5| Step: 7
Training loss: 3.544593095779419
Validation loss: 2.443450007387387

Epoch: 5| Step: 8
Training loss: 2.811678409576416
Validation loss: 2.4407982569868847

Epoch: 5| Step: 9
Training loss: 2.4138739109039307
Validation loss: 2.443499408742433

Epoch: 5| Step: 10
Training loss: 2.766254425048828
Validation loss: 2.4423622854294313

Epoch: 107| Step: 0
Training loss: 3.111266613006592
Validation loss: 2.4397091198992986

Epoch: 5| Step: 1
Training loss: 3.517131805419922
Validation loss: 2.4444936347264115

Epoch: 5| Step: 2
Training loss: 2.7393221855163574
Validation loss: 2.4446083371357252

Epoch: 5| Step: 3
Training loss: 2.2928524017333984
Validation loss: 2.4417841306296726

Epoch: 5| Step: 4
Training loss: 2.2493577003479004
Validation loss: 2.4476743769902054

Epoch: 5| Step: 5
Training loss: 2.561016798019409
Validation loss: 2.4494400152596096

Epoch: 5| Step: 6
Training loss: 2.2665600776672363
Validation loss: 2.445784056058494

Epoch: 5| Step: 7
Training loss: 2.557396650314331
Validation loss: 2.4596229740368423

Epoch: 5| Step: 8
Training loss: 3.4233055114746094
Validation loss: 2.4480504476895897

Epoch: 5| Step: 9
Training loss: 1.7334630489349365
Validation loss: 2.448084895328809

Epoch: 5| Step: 10
Training loss: 2.7542617321014404
Validation loss: 2.44530959539516

Epoch: 108| Step: 0
Training loss: 2.70259952545166
Validation loss: 2.444907057669855

Epoch: 5| Step: 1
Training loss: 2.5267131328582764
Validation loss: 2.4441927504795853

Epoch: 5| Step: 2
Training loss: 2.802309989929199
Validation loss: 2.443194386779621

Epoch: 5| Step: 3
Training loss: 2.9774718284606934
Validation loss: 2.444715035858975

Epoch: 5| Step: 4
Training loss: 2.8364791870117188
Validation loss: 2.4378577099051526

Epoch: 5| Step: 5
Training loss: 2.905836343765259
Validation loss: 2.4406953678336194

Epoch: 5| Step: 6
Training loss: 2.168816328048706
Validation loss: 2.4413607043604695

Epoch: 5| Step: 7
Training loss: 2.3879857063293457
Validation loss: 2.4384476805246003

Epoch: 5| Step: 8
Training loss: 2.7117714881896973
Validation loss: 2.4384543049720024

Epoch: 5| Step: 9
Training loss: 2.7341039180755615
Validation loss: 2.4440785479801956

Epoch: 5| Step: 10
Training loss: 2.352803945541382
Validation loss: 2.445179688033237

Epoch: 109| Step: 0
Training loss: 2.8898110389709473
Validation loss: 2.440791522302935

Epoch: 5| Step: 1
Training loss: 2.6784400939941406
Validation loss: 2.4397177926955687

Epoch: 5| Step: 2
Training loss: 2.657694101333618
Validation loss: 2.452807434143559

Epoch: 5| Step: 3
Training loss: 2.589987277984619
Validation loss: 2.450701052142728

Epoch: 5| Step: 4
Training loss: 2.1104955673217773
Validation loss: 2.444918458179761

Epoch: 5| Step: 5
Training loss: 2.806494951248169
Validation loss: 2.446350095092609

Epoch: 5| Step: 6
Training loss: 2.4362454414367676
Validation loss: 2.4531142865457842

Epoch: 5| Step: 7
Training loss: 2.501901626586914
Validation loss: 2.4491982434385564

Epoch: 5| Step: 8
Training loss: 3.1661248207092285
Validation loss: 2.4473017646420385

Epoch: 5| Step: 9
Training loss: 2.6997344493865967
Validation loss: 2.4460209377350344

Epoch: 5| Step: 10
Training loss: 2.5861451625823975
Validation loss: 2.442822056431924

Epoch: 110| Step: 0
Training loss: 3.1494927406311035
Validation loss: 2.445225084981611

Epoch: 5| Step: 1
Training loss: 2.4418864250183105
Validation loss: 2.4387896471126105

Epoch: 5| Step: 2
Training loss: 2.5147883892059326
Validation loss: 2.4369602459733204

Epoch: 5| Step: 3
Training loss: 2.1452715396881104
Validation loss: 2.4378380442178376

Epoch: 5| Step: 4
Training loss: 3.623490810394287
Validation loss: 2.4319506076074417

Epoch: 5| Step: 5
Training loss: 2.598207950592041
Validation loss: 2.4331749869931127

Epoch: 5| Step: 6
Training loss: 2.503523588180542
Validation loss: 2.435177618457425

Epoch: 5| Step: 7
Training loss: 2.5744435787200928
Validation loss: 2.4309171579217397

Epoch: 5| Step: 8
Training loss: 2.644906759262085
Validation loss: 2.432498775502687

Epoch: 5| Step: 9
Training loss: 2.2256031036376953
Validation loss: 2.4370417620546077

Epoch: 5| Step: 10
Training loss: 2.774266004562378
Validation loss: 2.4461670742240003

Epoch: 111| Step: 0
Training loss: 2.883558988571167
Validation loss: 2.4616676120347876

Epoch: 5| Step: 1
Training loss: 2.7689192295074463
Validation loss: 2.4699759611519436

Epoch: 5| Step: 2
Training loss: 3.034877061843872
Validation loss: 2.44566810131073

Epoch: 5| Step: 3
Training loss: 2.889716148376465
Validation loss: 2.4338055118437736

Epoch: 5| Step: 4
Training loss: 2.54616117477417
Validation loss: 2.426621357599894

Epoch: 5| Step: 5
Training loss: 2.275667667388916
Validation loss: 2.424068545782438

Epoch: 5| Step: 6
Training loss: 2.392392635345459
Validation loss: 2.429153093727686

Epoch: 5| Step: 7
Training loss: 3.16619610786438
Validation loss: 2.4252822758049093

Epoch: 5| Step: 8
Training loss: 2.3286800384521484
Validation loss: 2.4306926188930387

Epoch: 5| Step: 9
Training loss: 2.433907985687256
Validation loss: 2.4363394911571215

Epoch: 5| Step: 10
Training loss: 2.468596935272217
Validation loss: 2.442585232437298

Epoch: 112| Step: 0
Training loss: 2.403629779815674
Validation loss: 2.444023311779063

Epoch: 5| Step: 1
Training loss: 2.889373779296875
Validation loss: 2.4451745453701226

Epoch: 5| Step: 2
Training loss: 3.0127251148223877
Validation loss: 2.437349816804291

Epoch: 5| Step: 3
Training loss: 2.9660451412200928
Validation loss: 2.4394310443632063

Epoch: 5| Step: 4
Training loss: 2.9008948802948
Validation loss: 2.4371149591220322

Epoch: 5| Step: 5
Training loss: 2.8719382286071777
Validation loss: 2.4329353301755843

Epoch: 5| Step: 6
Training loss: 2.2696211338043213
Validation loss: 2.4314797770592476

Epoch: 5| Step: 7
Training loss: 2.6719374656677246
Validation loss: 2.4248673582589753

Epoch: 5| Step: 8
Training loss: 2.2014365196228027
Validation loss: 2.4260241164956042

Epoch: 5| Step: 9
Training loss: 2.241133451461792
Validation loss: 2.4233486190918954

Epoch: 5| Step: 10
Training loss: 2.7741470336914062
Validation loss: 2.4242279965390443

Epoch: 113| Step: 0
Training loss: 2.661914587020874
Validation loss: 2.4212700192646315

Epoch: 5| Step: 1
Training loss: 2.3505587577819824
Validation loss: 2.422041344386275

Epoch: 5| Step: 2
Training loss: 2.4690446853637695
Validation loss: 2.4241998887831167

Epoch: 5| Step: 3
Training loss: 2.680553913116455
Validation loss: 2.4243641668750393

Epoch: 5| Step: 4
Training loss: 2.654731273651123
Validation loss: 2.426768284971996

Epoch: 5| Step: 5
Training loss: 2.2939741611480713
Validation loss: 2.432469170580628

Epoch: 5| Step: 6
Training loss: 2.696183681488037
Validation loss: 2.421614816111903

Epoch: 5| Step: 7
Training loss: 3.6785531044006348
Validation loss: 2.4247457160744617

Epoch: 5| Step: 8
Training loss: 2.763472080230713
Validation loss: 2.423776941914712

Epoch: 5| Step: 9
Training loss: 2.298372745513916
Validation loss: 2.4213049309228056

Epoch: 5| Step: 10
Training loss: 2.541139602661133
Validation loss: 2.4257430132999214

Epoch: 114| Step: 0
Training loss: 1.9864431619644165
Validation loss: 2.426594400918612

Epoch: 5| Step: 1
Training loss: 2.416674852371216
Validation loss: 2.4318369524453276

Epoch: 5| Step: 2
Training loss: 3.127350091934204
Validation loss: 2.430567897776122

Epoch: 5| Step: 3
Training loss: 3.4864368438720703
Validation loss: 2.426352490660965

Epoch: 5| Step: 4
Training loss: 2.1275794506073
Validation loss: 2.423093495830413

Epoch: 5| Step: 5
Training loss: 2.681023359298706
Validation loss: 2.4256224632263184

Epoch: 5| Step: 6
Training loss: 2.509369373321533
Validation loss: 2.426983689749113

Epoch: 5| Step: 7
Training loss: 2.992871046066284
Validation loss: 2.421475843716693

Epoch: 5| Step: 8
Training loss: 2.7038402557373047
Validation loss: 2.4299988926097913

Epoch: 5| Step: 9
Training loss: 2.3479204177856445
Validation loss: 2.4274676076827513

Epoch: 5| Step: 10
Training loss: 2.6171789169311523
Validation loss: 2.4473302646349837

Epoch: 115| Step: 0
Training loss: 2.6554956436157227
Validation loss: 2.4681041625238236

Epoch: 5| Step: 1
Training loss: 2.171617031097412
Validation loss: 2.476822901797551

Epoch: 5| Step: 2
Training loss: 3.4168899059295654
Validation loss: 2.481126598132554

Epoch: 5| Step: 3
Training loss: 1.96999990940094
Validation loss: 2.4539704604815413

Epoch: 5| Step: 4
Training loss: 3.322969436645508
Validation loss: 2.429364319770567

Epoch: 5| Step: 5
Training loss: 2.2616260051727295
Validation loss: 2.4290824064644436

Epoch: 5| Step: 6
Training loss: 3.091001510620117
Validation loss: 2.4191378585753904

Epoch: 5| Step: 7
Training loss: 2.4017324447631836
Validation loss: 2.4216648891407955

Epoch: 5| Step: 8
Training loss: 2.7550241947174072
Validation loss: 2.419308626523582

Epoch: 5| Step: 9
Training loss: 2.4668526649475098
Validation loss: 2.4193788548951507

Epoch: 5| Step: 10
Training loss: 2.6374900341033936
Validation loss: 2.420197266404347

Epoch: 116| Step: 0
Training loss: 2.232924461364746
Validation loss: 2.4255518990178264

Epoch: 5| Step: 1
Training loss: 2.836884021759033
Validation loss: 2.4257961344975296

Epoch: 5| Step: 2
Training loss: 2.4678444862365723
Validation loss: 2.4245281886028986

Epoch: 5| Step: 3
Training loss: 2.33469557762146
Validation loss: 2.417871223982944

Epoch: 5| Step: 4
Training loss: 2.477142095565796
Validation loss: 2.4202630084048034

Epoch: 5| Step: 5
Training loss: 2.571368455886841
Validation loss: 2.4141981781169934

Epoch: 5| Step: 6
Training loss: 2.6308090686798096
Validation loss: 2.415431002134918

Epoch: 5| Step: 7
Training loss: 2.7177107334136963
Validation loss: 2.410686275010468

Epoch: 5| Step: 8
Training loss: 2.533308267593384
Validation loss: 2.412574532211468

Epoch: 5| Step: 9
Training loss: 3.2597923278808594
Validation loss: 2.4170799537371566

Epoch: 5| Step: 10
Training loss: 3.0104596614837646
Validation loss: 2.4173262978112824

Epoch: 117| Step: 0
Training loss: 3.089722156524658
Validation loss: 2.426236552576865

Epoch: 5| Step: 1
Training loss: 2.485541820526123
Validation loss: 2.4277159629329557

Epoch: 5| Step: 2
Training loss: 2.6295604705810547
Validation loss: 2.4364919098474647

Epoch: 5| Step: 3
Training loss: 2.5868868827819824
Validation loss: 2.4381878875917002

Epoch: 5| Step: 4
Training loss: 2.9203293323516846
Validation loss: 2.4350536459235737

Epoch: 5| Step: 5
Training loss: 3.3238778114318848
Validation loss: 2.4268507265275523

Epoch: 5| Step: 6
Training loss: 2.5600085258483887
Validation loss: 2.41979972521464

Epoch: 5| Step: 7
Training loss: 2.2521519660949707
Validation loss: 2.4119569358005317

Epoch: 5| Step: 8
Training loss: 2.200774669647217
Validation loss: 2.4124749142636537

Epoch: 5| Step: 9
Training loss: 2.7179477214813232
Validation loss: 2.4177513378922657

Epoch: 5| Step: 10
Training loss: 2.1493120193481445
Validation loss: 2.4185053610032603

Epoch: 118| Step: 0
Training loss: 3.156968116760254
Validation loss: 2.423948598164384

Epoch: 5| Step: 1
Training loss: 2.171873092651367
Validation loss: 2.4382144046086136

Epoch: 5| Step: 2
Training loss: 2.4156553745269775
Validation loss: 2.4336003795746834

Epoch: 5| Step: 3
Training loss: 2.9534926414489746
Validation loss: 2.4402633943865375

Epoch: 5| Step: 4
Training loss: 2.257133722305298
Validation loss: 2.440041152379846

Epoch: 5| Step: 5
Training loss: 2.474613666534424
Validation loss: 2.4348176628030758

Epoch: 5| Step: 6
Training loss: 2.290518283843994
Validation loss: 2.4231091955656647

Epoch: 5| Step: 7
Training loss: 3.265629529953003
Validation loss: 2.424140960939469

Epoch: 5| Step: 8
Training loss: 2.9935715198516846
Validation loss: 2.4142026849972305

Epoch: 5| Step: 9
Training loss: 2.9008779525756836
Validation loss: 2.4202686561051237

Epoch: 5| Step: 10
Training loss: 2.0499935150146484
Validation loss: 2.4136273860931396

Epoch: 119| Step: 0
Training loss: 3.0840651988983154
Validation loss: 2.4180748270403956

Epoch: 5| Step: 1
Training loss: 3.1624016761779785
Validation loss: 2.4338853692495697

Epoch: 5| Step: 2
Training loss: 2.58453106880188
Validation loss: 2.4387364259330173

Epoch: 5| Step: 3
Training loss: 2.8433892726898193
Validation loss: 2.4365039025583575

Epoch: 5| Step: 4
Training loss: 2.2953481674194336
Validation loss: 2.432006933355844

Epoch: 5| Step: 5
Training loss: 2.2749099731445312
Validation loss: 2.431946337863963

Epoch: 5| Step: 6
Training loss: 2.427898645401001
Validation loss: 2.436145192833357

Epoch: 5| Step: 7
Training loss: 1.9438918828964233
Validation loss: 2.4263843874777518

Epoch: 5| Step: 8
Training loss: 3.0592758655548096
Validation loss: 2.41603756976384

Epoch: 5| Step: 9
Training loss: 2.526818037033081
Validation loss: 2.4124073366965018

Epoch: 5| Step: 10
Training loss: 2.815217971801758
Validation loss: 2.4061565860625236

Epoch: 120| Step: 0
Training loss: 2.470741033554077
Validation loss: 2.4020973405530377

Epoch: 5| Step: 1
Training loss: 2.039886236190796
Validation loss: 2.4023319931440454

Epoch: 5| Step: 2
Training loss: 2.4405410289764404
Validation loss: 2.4022578603477887

Epoch: 5| Step: 3
Training loss: 2.7300422191619873
Validation loss: 2.400996833719233

Epoch: 5| Step: 4
Training loss: 3.0245361328125
Validation loss: 2.4105997957209104

Epoch: 5| Step: 5
Training loss: 2.220551013946533
Validation loss: 2.417949458604218

Epoch: 5| Step: 6
Training loss: 2.7720956802368164
Validation loss: 2.426755315514021

Epoch: 5| Step: 7
Training loss: 3.474964141845703
Validation loss: 2.4436181822130756

Epoch: 5| Step: 8
Training loss: 3.2077369689941406
Validation loss: 2.4664208478825067

Epoch: 5| Step: 9
Training loss: 1.78897225856781
Validation loss: 2.4743405362611175

Epoch: 5| Step: 10
Training loss: 2.783198356628418
Validation loss: 2.4710441738046627

Epoch: 121| Step: 0
Training loss: 1.992803931236267
Validation loss: 2.455370299277767

Epoch: 5| Step: 1
Training loss: 2.5897109508514404
Validation loss: 2.4379081649164998

Epoch: 5| Step: 2
Training loss: 2.5143415927886963
Validation loss: 2.4309888373139086

Epoch: 5| Step: 3
Training loss: 2.5768380165100098
Validation loss: 2.428385667903449

Epoch: 5| Step: 4
Training loss: 2.366555690765381
Validation loss: 2.4355536468567385

Epoch: 5| Step: 5
Training loss: 2.795245885848999
Validation loss: 2.4299559516291462

Epoch: 5| Step: 6
Training loss: 2.2629001140594482
Validation loss: 2.41973037873545

Epoch: 5| Step: 7
Training loss: 2.906691074371338
Validation loss: 2.4143834139711116

Epoch: 5| Step: 8
Training loss: 3.307250499725342
Validation loss: 2.4079346451708066

Epoch: 5| Step: 9
Training loss: 2.767817974090576
Validation loss: 2.4020248971959597

Epoch: 5| Step: 10
Training loss: 2.94222092628479
Validation loss: 2.3964822138509443

Epoch: 122| Step: 0
Training loss: 2.1760005950927734
Validation loss: 2.3951182262871855

Epoch: 5| Step: 1
Training loss: 2.8866164684295654
Validation loss: 2.3975646982910814

Epoch: 5| Step: 2
Training loss: 2.5056965351104736
Validation loss: 2.403986354028025

Epoch: 5| Step: 3
Training loss: 3.250102996826172
Validation loss: 2.411655843898814

Epoch: 5| Step: 4
Training loss: 2.504704713821411
Validation loss: 2.4011883197292203

Epoch: 5| Step: 5
Training loss: 2.97735857963562
Validation loss: 2.392846494592646

Epoch: 5| Step: 6
Training loss: 1.8381801843643188
Validation loss: 2.389799661533807

Epoch: 5| Step: 7
Training loss: 3.434417724609375
Validation loss: 2.391141553078928

Epoch: 5| Step: 8
Training loss: 2.7579703330993652
Validation loss: 2.3906251461275163

Epoch: 5| Step: 9
Training loss: 2.6582157611846924
Validation loss: 2.391755650120397

Epoch: 5| Step: 10
Training loss: 1.8800703287124634
Validation loss: 2.392859487123387

Epoch: 123| Step: 0
Training loss: 2.46867036819458
Validation loss: 2.3921304082357757

Epoch: 5| Step: 1
Training loss: 2.6411337852478027
Validation loss: 2.393364114146079

Epoch: 5| Step: 2
Training loss: 2.3185958862304688
Validation loss: 2.3975641471083446

Epoch: 5| Step: 3
Training loss: 2.234065532684326
Validation loss: 2.4035755536889516

Epoch: 5| Step: 4
Training loss: 2.448455572128296
Validation loss: 2.4432720599635953

Epoch: 5| Step: 5
Training loss: 2.6497445106506348
Validation loss: 2.433147374019828

Epoch: 5| Step: 6
Training loss: 2.7277159690856934
Validation loss: 2.437041421090403

Epoch: 5| Step: 7
Training loss: 2.7652900218963623
Validation loss: 2.49980483260206

Epoch: 5| Step: 8
Training loss: 3.321429491043091
Validation loss: 2.5134246092970653

Epoch: 5| Step: 9
Training loss: 2.8389413356781006
Validation loss: 2.4996078886011595

Epoch: 5| Step: 10
Training loss: 2.9153566360473633
Validation loss: 2.458884798070436

Epoch: 124| Step: 0
Training loss: 3.4379093647003174
Validation loss: 2.4366735899320213

Epoch: 5| Step: 1
Training loss: 2.8108127117156982
Validation loss: 2.392669798225485

Epoch: 5| Step: 2
Training loss: 2.26719069480896
Validation loss: 2.405800514323737

Epoch: 5| Step: 3
Training loss: 2.3564281463623047
Validation loss: 2.4153401544017177

Epoch: 5| Step: 4
Training loss: 2.9713215827941895
Validation loss: 2.410271276709854

Epoch: 5| Step: 5
Training loss: 3.0053582191467285
Validation loss: 2.409255709699405

Epoch: 5| Step: 6
Training loss: 2.443310260772705
Validation loss: 2.4028614362080893

Epoch: 5| Step: 7
Training loss: 2.6333937644958496
Validation loss: 2.400144418080648

Epoch: 5| Step: 8
Training loss: 2.6209654808044434
Validation loss: 2.4026553502646824

Epoch: 5| Step: 9
Training loss: 2.449597120285034
Validation loss: 2.4071373606240876

Epoch: 5| Step: 10
Training loss: 2.175043821334839
Validation loss: 2.4159716226721324

Epoch: 125| Step: 0
Training loss: 2.9162025451660156
Validation loss: 2.4288630152261383

Epoch: 5| Step: 1
Training loss: 2.1814749240875244
Validation loss: 2.4447957418298207

Epoch: 5| Step: 2
Training loss: 2.5803439617156982
Validation loss: 2.448016879379108

Epoch: 5| Step: 3
Training loss: 2.503800868988037
Validation loss: 2.474427092459894

Epoch: 5| Step: 4
Training loss: 2.975543260574341
Validation loss: 2.4742104878989597

Epoch: 5| Step: 5
Training loss: 2.3586690425872803
Validation loss: 2.4638112014339817

Epoch: 5| Step: 6
Training loss: 2.5851669311523438
Validation loss: 2.4612115967658257

Epoch: 5| Step: 7
Training loss: 2.5224502086639404
Validation loss: 2.453075126935077

Epoch: 5| Step: 8
Training loss: 2.734095811843872
Validation loss: 2.447996452290525

Epoch: 5| Step: 9
Training loss: 2.398054838180542
Validation loss: 2.4471848446835756

Epoch: 5| Step: 10
Training loss: 3.613248586654663
Validation loss: 2.4400571930793022

Testing loss: 2.579570929209391
