Epoch: 1| Step: 0
Training loss: 4.524064064025879
Validation loss: 5.185951776401971

Epoch: 6| Step: 1
Training loss: 3.2945022583007812
Validation loss: 5.181560044647545

Epoch: 6| Step: 2
Training loss: 5.1910223960876465
Validation loss: 5.177911676386351

Epoch: 6| Step: 3
Training loss: 5.099478721618652
Validation loss: 5.17425198196083

Epoch: 6| Step: 4
Training loss: 4.072353363037109
Validation loss: 5.17083263909945

Epoch: 6| Step: 5
Training loss: 5.141637802124023
Validation loss: 5.167539796521587

Epoch: 6| Step: 6
Training loss: 4.926216125488281
Validation loss: 5.164239734731694

Epoch: 6| Step: 7
Training loss: 6.488101959228516
Validation loss: 5.160711606343587

Epoch: 6| Step: 8
Training loss: 4.591265678405762
Validation loss: 5.156764358602544

Epoch: 6| Step: 9
Training loss: 6.414281368255615
Validation loss: 5.152766417431575

Epoch: 6| Step: 10
Training loss: 5.671898365020752
Validation loss: 5.148652763776882

Epoch: 6| Step: 11
Training loss: 4.33042049407959
Validation loss: 5.144086755732054

Epoch: 6| Step: 12
Training loss: 5.5453033447265625
Validation loss: 5.139422688432919

Epoch: 6| Step: 13
Training loss: 3.466218948364258
Validation loss: 5.134234659133419

Epoch: 2| Step: 0
Training loss: 4.899158477783203
Validation loss: 5.129083571895476

Epoch: 6| Step: 1
Training loss: 5.123559951782227
Validation loss: 5.123708514757054

Epoch: 6| Step: 2
Training loss: 5.453197956085205
Validation loss: 5.1175713539123535

Epoch: 6| Step: 3
Training loss: 3.4939475059509277
Validation loss: 5.111449323674684

Epoch: 6| Step: 4
Training loss: 4.455842018127441
Validation loss: 5.105337107053367

Epoch: 6| Step: 5
Training loss: 6.168540000915527
Validation loss: 5.098687146299628

Epoch: 6| Step: 6
Training loss: 4.949620246887207
Validation loss: 5.091618804521458

Epoch: 6| Step: 7
Training loss: 5.431457042694092
Validation loss: 5.084354369871078

Epoch: 6| Step: 8
Training loss: 5.04219913482666
Validation loss: 5.076351375990017

Epoch: 6| Step: 9
Training loss: 5.431768417358398
Validation loss: 5.068274026275963

Epoch: 6| Step: 10
Training loss: 5.361080169677734
Validation loss: 5.059640945926789

Epoch: 6| Step: 11
Training loss: 3.2029571533203125
Validation loss: 5.051093142519715

Epoch: 6| Step: 12
Training loss: 4.414986610412598
Validation loss: 5.04159830462548

Epoch: 6| Step: 13
Training loss: 4.948094844818115
Validation loss: 5.031515946952245

Epoch: 3| Step: 0
Training loss: 5.7987847328186035
Validation loss: 5.021366380876111

Epoch: 6| Step: 1
Training loss: 5.167963981628418
Validation loss: 5.011818967839723

Epoch: 6| Step: 2
Training loss: 4.4043731689453125
Validation loss: 4.999751890859296

Epoch: 6| Step: 3
Training loss: 5.410402297973633
Validation loss: 4.9876395604943715

Epoch: 6| Step: 4
Training loss: 4.74005126953125
Validation loss: 4.975593515621719

Epoch: 6| Step: 5
Training loss: 4.629826068878174
Validation loss: 4.962075520587224

Epoch: 6| Step: 6
Training loss: 3.6604630947113037
Validation loss: 4.948682887579805

Epoch: 6| Step: 7
Training loss: 4.268349647521973
Validation loss: 4.934422539126489

Epoch: 6| Step: 8
Training loss: 4.620433807373047
Validation loss: 4.920482538079702

Epoch: 6| Step: 9
Training loss: 4.72224235534668
Validation loss: 4.904792903572001

Epoch: 6| Step: 10
Training loss: 4.809547424316406
Validation loss: 4.889671253901656

Epoch: 6| Step: 11
Training loss: 5.638620853424072
Validation loss: 4.872659457627163

Epoch: 6| Step: 12
Training loss: 3.996575355529785
Validation loss: 4.856213092803955

Epoch: 6| Step: 13
Training loss: 4.131696701049805
Validation loss: 4.838206932108889

Epoch: 4| Step: 0
Training loss: 5.549653053283691
Validation loss: 4.820442374034594

Epoch: 6| Step: 1
Training loss: 4.9769206047058105
Validation loss: 4.801139395724061

Epoch: 6| Step: 2
Training loss: 4.55942440032959
Validation loss: 4.781632151654971

Epoch: 6| Step: 3
Training loss: 5.234035015106201
Validation loss: 4.7619908804534585

Epoch: 6| Step: 4
Training loss: 4.669818878173828
Validation loss: 4.741240132239557

Epoch: 6| Step: 5
Training loss: 4.7219743728637695
Validation loss: 4.721007054851901

Epoch: 6| Step: 6
Training loss: 3.9249956607818604
Validation loss: 4.699351961894702

Epoch: 6| Step: 7
Training loss: 3.9407269954681396
Validation loss: 4.676851093128163

Epoch: 6| Step: 8
Training loss: 4.859140872955322
Validation loss: 4.655705111001128

Epoch: 6| Step: 9
Training loss: 2.847533702850342
Validation loss: 4.6326994331934115

Epoch: 6| Step: 10
Training loss: 4.287938594818115
Validation loss: 4.611500232450424

Epoch: 6| Step: 11
Training loss: 4.77960205078125
Validation loss: 4.587589110097578

Epoch: 6| Step: 12
Training loss: 3.801175355911255
Validation loss: 4.56496323308637

Epoch: 6| Step: 13
Training loss: 4.513737678527832
Validation loss: 4.540671456244684

Epoch: 5| Step: 0
Training loss: 5.209789752960205
Validation loss: 4.516838945368285

Epoch: 6| Step: 1
Training loss: 5.7938666343688965
Validation loss: 4.492111003527078

Epoch: 6| Step: 2
Training loss: 4.132401466369629
Validation loss: 4.469305402489119

Epoch: 6| Step: 3
Training loss: 3.8505373001098633
Validation loss: 4.4428294089532665

Epoch: 6| Step: 4
Training loss: 3.631600856781006
Validation loss: 4.420070781502672

Epoch: 6| Step: 5
Training loss: 3.3931384086608887
Validation loss: 4.398170173809093

Epoch: 6| Step: 6
Training loss: 3.6738717555999756
Validation loss: 4.375220685876826

Epoch: 6| Step: 7
Training loss: 3.0609991550445557
Validation loss: 4.354241812100974

Epoch: 6| Step: 8
Training loss: 3.4682159423828125
Validation loss: 4.329951065842823

Epoch: 6| Step: 9
Training loss: 4.967378616333008
Validation loss: 4.307640329484017

Epoch: 6| Step: 10
Training loss: 4.3127031326293945
Validation loss: 4.286973455900787

Epoch: 6| Step: 11
Training loss: 3.484744071960449
Validation loss: 4.263448253754647

Epoch: 6| Step: 12
Training loss: 4.443626403808594
Validation loss: 4.242993077924175

Epoch: 6| Step: 13
Training loss: 5.5302581787109375
Validation loss: 4.221018422034479

Epoch: 6| Step: 0
Training loss: 4.333285808563232
Validation loss: 4.199102391478836

Epoch: 6| Step: 1
Training loss: 4.5329976081848145
Validation loss: 4.178070506741924

Epoch: 6| Step: 2
Training loss: 5.022562503814697
Validation loss: 4.156107184707477

Epoch: 6| Step: 3
Training loss: 4.105147361755371
Validation loss: 4.135265211905202

Epoch: 6| Step: 4
Training loss: 4.356648921966553
Validation loss: 4.112320564126455

Epoch: 6| Step: 5
Training loss: 3.7965736389160156
Validation loss: 4.091187620675692

Epoch: 6| Step: 6
Training loss: 3.5413758754730225
Validation loss: 4.071815811177736

Epoch: 6| Step: 7
Training loss: 4.558992385864258
Validation loss: 4.0500388863266155

Epoch: 6| Step: 8
Training loss: 3.1960015296936035
Validation loss: 4.027493948577552

Epoch: 6| Step: 9
Training loss: 2.192695379257202
Validation loss: 4.006509752683742

Epoch: 6| Step: 10
Training loss: 2.359095573425293
Validation loss: 3.988060200086204

Epoch: 6| Step: 11
Training loss: 4.438586235046387
Validation loss: 3.969887597586519

Epoch: 6| Step: 12
Training loss: 4.20926570892334
Validation loss: 3.953415955266645

Epoch: 6| Step: 13
Training loss: 4.072357654571533
Validation loss: 3.9359336463353967

Epoch: 7| Step: 0
Training loss: 3.629382848739624
Validation loss: 3.9199711174093266

Epoch: 6| Step: 1
Training loss: 3.665919303894043
Validation loss: 3.902752886536301

Epoch: 6| Step: 2
Training loss: 2.831019878387451
Validation loss: 3.8905671104308097

Epoch: 6| Step: 3
Training loss: 4.1104230880737305
Validation loss: 3.8758211930592856

Epoch: 6| Step: 4
Training loss: 3.5050504207611084
Validation loss: 3.8585977913230978

Epoch: 6| Step: 5
Training loss: 4.314807891845703
Validation loss: 3.8457525314823275

Epoch: 6| Step: 6
Training loss: 2.5797157287597656
Validation loss: 3.831389340021277

Epoch: 6| Step: 7
Training loss: 4.493221282958984
Validation loss: 3.8182316185325704

Epoch: 6| Step: 8
Training loss: 4.211816787719727
Validation loss: 3.8036146215213242

Epoch: 6| Step: 9
Training loss: 3.1434943675994873
Validation loss: 3.786373030754828

Epoch: 6| Step: 10
Training loss: 3.0537774562835693
Validation loss: 3.772711415444651

Epoch: 6| Step: 11
Training loss: 4.455507278442383
Validation loss: 3.7563751128412064

Epoch: 6| Step: 12
Training loss: 3.808969020843506
Validation loss: 3.744986782791794

Epoch: 6| Step: 13
Training loss: 4.1311445236206055
Validation loss: 3.723972607684392

Epoch: 8| Step: 0
Training loss: 3.429034471511841
Validation loss: 3.7104389257328485

Epoch: 6| Step: 1
Training loss: 2.9743618965148926
Validation loss: 3.6978685548228603

Epoch: 6| Step: 2
Training loss: 3.162069797515869
Validation loss: 3.6829356480670232

Epoch: 6| Step: 3
Training loss: 4.290580749511719
Validation loss: 3.6691980567029727

Epoch: 6| Step: 4
Training loss: 4.295015811920166
Validation loss: 3.6537312230756207

Epoch: 6| Step: 5
Training loss: 3.016453742980957
Validation loss: 3.642253875732422

Epoch: 6| Step: 6
Training loss: 4.099736213684082
Validation loss: 3.628958986651513

Epoch: 6| Step: 7
Training loss: 3.0997557640075684
Validation loss: 3.6151218311761015

Epoch: 6| Step: 8
Training loss: 4.478664398193359
Validation loss: 3.603408767331031

Epoch: 6| Step: 9
Training loss: 3.503540277481079
Validation loss: 3.5928471985683648

Epoch: 6| Step: 10
Training loss: 3.4985475540161133
Validation loss: 3.579230180350683

Epoch: 6| Step: 11
Training loss: 2.998940944671631
Validation loss: 3.5689938145299114

Epoch: 6| Step: 12
Training loss: 2.8021864891052246
Validation loss: 3.5568696042542816

Epoch: 6| Step: 13
Training loss: 4.003883361816406
Validation loss: 3.5442775987809703

Epoch: 9| Step: 0
Training loss: 4.823525905609131
Validation loss: 3.532587866629324

Epoch: 6| Step: 1
Training loss: 3.0715227127075195
Validation loss: 3.5225640701991257

Epoch: 6| Step: 2
Training loss: 2.3467795848846436
Validation loss: 3.5100110705180834

Epoch: 6| Step: 3
Training loss: 3.6476833820343018
Validation loss: 3.498681970821914

Epoch: 6| Step: 4
Training loss: 2.841397285461426
Validation loss: 3.4858930110931396

Epoch: 6| Step: 5
Training loss: 4.013489723205566
Validation loss: 3.4705989283900105

Epoch: 6| Step: 6
Training loss: 2.753387928009033
Validation loss: 3.4538298832472933

Epoch: 6| Step: 7
Training loss: 2.683887481689453
Validation loss: 3.438691964713476

Epoch: 6| Step: 8
Training loss: 2.8493034839630127
Validation loss: 3.424569724708475

Epoch: 6| Step: 9
Training loss: 4.735184669494629
Validation loss: 3.4146312334204234

Epoch: 6| Step: 10
Training loss: 2.879549026489258
Validation loss: 3.4024988323129635

Epoch: 6| Step: 11
Training loss: 3.367504358291626
Validation loss: 3.395929608293759

Epoch: 6| Step: 12
Training loss: 3.738546848297119
Validation loss: 3.3868737733492287

Epoch: 6| Step: 13
Training loss: 3.957157611846924
Validation loss: 3.3764481852131505

Epoch: 10| Step: 0
Training loss: 3.962026357650757
Validation loss: 3.367629135808637

Epoch: 6| Step: 1
Training loss: 2.5203065872192383
Validation loss: 3.3566093752461095

Epoch: 6| Step: 2
Training loss: 4.193559646606445
Validation loss: 3.349436044692993

Epoch: 6| Step: 3
Training loss: 2.5975611209869385
Validation loss: 3.340907612154561

Epoch: 6| Step: 4
Training loss: 3.387302875518799
Validation loss: 3.329810204044465

Epoch: 6| Step: 5
Training loss: 3.530545711517334
Validation loss: 3.324909246096047

Epoch: 6| Step: 6
Training loss: 2.598039150238037
Validation loss: 3.3185773203449864

Epoch: 6| Step: 7
Training loss: 3.424374580383301
Validation loss: 3.30999675104695

Epoch: 6| Step: 8
Training loss: 2.692913055419922
Validation loss: 3.30171626101258

Epoch: 6| Step: 9
Training loss: 3.1715753078460693
Validation loss: 3.29416032760374

Epoch: 6| Step: 10
Training loss: 4.023731708526611
Validation loss: 3.2902357373186337

Epoch: 6| Step: 11
Training loss: 2.7863433361053467
Validation loss: 3.279998230677779

Epoch: 6| Step: 12
Training loss: 3.237952709197998
Validation loss: 3.274413234444075

Epoch: 6| Step: 13
Training loss: 4.1130523681640625
Validation loss: 3.2661544481913247

Epoch: 11| Step: 0
Training loss: 3.641988754272461
Validation loss: 3.260112198450232

Epoch: 6| Step: 1
Training loss: 2.86378812789917
Validation loss: 3.2514900161374

Epoch: 6| Step: 2
Training loss: 4.040914535522461
Validation loss: 3.2525140854620163

Epoch: 6| Step: 3
Training loss: 3.479733943939209
Validation loss: 3.2462431948672057

Epoch: 6| Step: 4
Training loss: 3.460651159286499
Validation loss: 3.2394796033059396

Epoch: 6| Step: 5
Training loss: 3.483116626739502
Validation loss: 3.233069363460746

Epoch: 6| Step: 6
Training loss: 3.211123466491699
Validation loss: 3.225715893571095

Epoch: 6| Step: 7
Training loss: 3.1062257289886475
Validation loss: 3.2199184484379266

Epoch: 6| Step: 8
Training loss: 4.000402450561523
Validation loss: 3.2141086645023798

Epoch: 6| Step: 9
Training loss: 3.747061252593994
Validation loss: 3.2124613767029135

Epoch: 6| Step: 10
Training loss: 2.5989584922790527
Validation loss: 3.2040453572427072

Epoch: 6| Step: 11
Training loss: 2.0395002365112305
Validation loss: 3.1972054640452066

Epoch: 6| Step: 12
Training loss: 2.5308470726013184
Validation loss: 3.197283593557214

Epoch: 6| Step: 13
Training loss: 2.3928682804107666
Validation loss: 3.193304074707852

Epoch: 12| Step: 0
Training loss: 2.585034132003784
Validation loss: 3.1898926919506443

Epoch: 6| Step: 1
Training loss: 2.9207301139831543
Validation loss: 3.1829822627446984

Epoch: 6| Step: 2
Training loss: 3.9055116176605225
Validation loss: 3.17499287666813

Epoch: 6| Step: 3
Training loss: 3.568789005279541
Validation loss: 3.1717885796741774

Epoch: 6| Step: 4
Training loss: 2.703761100769043
Validation loss: 3.1669993938938266

Epoch: 6| Step: 5
Training loss: 3.0601582527160645
Validation loss: 3.159398853137929

Epoch: 6| Step: 6
Training loss: 2.9421112537384033
Validation loss: 3.156352209788497

Epoch: 6| Step: 7
Training loss: 3.969024658203125
Validation loss: 3.1514041295615574

Epoch: 6| Step: 8
Training loss: 3.9861392974853516
Validation loss: 3.147680131337976

Epoch: 6| Step: 9
Training loss: 2.9572527408599854
Validation loss: 3.14164613908337

Epoch: 6| Step: 10
Training loss: 2.7012269496917725
Validation loss: 3.141555101640763

Epoch: 6| Step: 11
Training loss: 3.490377426147461
Validation loss: 3.1317802782981627

Epoch: 6| Step: 12
Training loss: 2.4431443214416504
Validation loss: 3.1292534541058283

Epoch: 6| Step: 13
Training loss: 2.8834564685821533
Validation loss: 3.1234668454816266

Epoch: 13| Step: 0
Training loss: 2.5088725090026855
Validation loss: 3.123888664348151

Epoch: 6| Step: 1
Training loss: 2.9788260459899902
Validation loss: 3.117604653040568

Epoch: 6| Step: 2
Training loss: 4.264494895935059
Validation loss: 3.11034200268407

Epoch: 6| Step: 3
Training loss: 2.5597705841064453
Validation loss: 3.105396075915265

Epoch: 6| Step: 4
Training loss: 3.35630202293396
Validation loss: 3.1030531391020744

Epoch: 6| Step: 5
Training loss: 3.7480695247650146
Validation loss: 3.0954299152538343

Epoch: 6| Step: 6
Training loss: 3.192178249359131
Validation loss: 3.089999496295888

Epoch: 6| Step: 7
Training loss: 3.7101516723632812
Validation loss: 3.088822687825849

Epoch: 6| Step: 8
Training loss: 3.2204957008361816
Validation loss: 3.083278320168936

Epoch: 6| Step: 9
Training loss: 3.833329200744629
Validation loss: 3.074941599240867

Epoch: 6| Step: 10
Training loss: 2.244795322418213
Validation loss: 3.0745658182328746

Epoch: 6| Step: 11
Training loss: 2.8059046268463135
Validation loss: 3.0713778208660822

Epoch: 6| Step: 12
Training loss: 2.2096643447875977
Validation loss: 3.0661045530790925

Epoch: 6| Step: 13
Training loss: 2.80633544921875
Validation loss: 3.064498888548984

Epoch: 14| Step: 0
Training loss: 2.5653116703033447
Validation loss: 3.0602004297317995

Epoch: 6| Step: 1
Training loss: 3.535646915435791
Validation loss: 3.055676378229613

Epoch: 6| Step: 2
Training loss: 3.1870083808898926
Validation loss: 3.0507213633547545

Epoch: 6| Step: 3
Training loss: 3.3339428901672363
Validation loss: 3.0463197872202885

Epoch: 6| Step: 4
Training loss: 2.9266273975372314
Validation loss: 3.047680890688332

Epoch: 6| Step: 5
Training loss: 2.35646390914917
Validation loss: 3.0428394527845484

Epoch: 6| Step: 6
Training loss: 2.7085366249084473
Validation loss: 3.0484007148332495

Epoch: 6| Step: 7
Training loss: 3.850696325302124
Validation loss: 3.0326544110492994

Epoch: 6| Step: 8
Training loss: 3.13755202293396
Validation loss: 3.02584195393388

Epoch: 6| Step: 9
Training loss: 1.9528610706329346
Validation loss: 3.0224052372799126

Epoch: 6| Step: 10
Training loss: 3.67586612701416
Validation loss: 3.020899982862575

Epoch: 6| Step: 11
Training loss: 3.045509099960327
Validation loss: 3.012149126298966

Epoch: 6| Step: 12
Training loss: 3.7616348266601562
Validation loss: 3.0097375787714475

Epoch: 6| Step: 13
Training loss: 2.7324588298797607
Validation loss: 3.0050422863293718

Epoch: 15| Step: 0
Training loss: 4.130703926086426
Validation loss: 3.0017004910335747

Epoch: 6| Step: 1
Training loss: 2.926921844482422
Validation loss: 3.000466803068756

Epoch: 6| Step: 2
Training loss: 2.395988941192627
Validation loss: 2.9910597391025995

Epoch: 6| Step: 3
Training loss: 3.638853073120117
Validation loss: 2.9897817642458024

Epoch: 6| Step: 4
Training loss: 2.434185028076172
Validation loss: 2.9879550190382105

Epoch: 6| Step: 5
Training loss: 3.2643086910247803
Validation loss: 2.9831657281485935

Epoch: 6| Step: 6
Training loss: 2.492518424987793
Validation loss: 2.979447921117147

Epoch: 6| Step: 7
Training loss: 2.939596176147461
Validation loss: 2.974210636590117

Epoch: 6| Step: 8
Training loss: 3.294520854949951
Validation loss: 2.9687440446628037

Epoch: 6| Step: 9
Training loss: 3.283803939819336
Validation loss: 2.965832387247393

Epoch: 6| Step: 10
Training loss: 3.0210676193237305
Validation loss: 2.9612633489793345

Epoch: 6| Step: 11
Training loss: 2.75799560546875
Validation loss: 2.9610283092785905

Epoch: 6| Step: 12
Training loss: 2.6100924015045166
Validation loss: 2.9608859298049763

Epoch: 6| Step: 13
Training loss: 3.5098555088043213
Validation loss: 2.953227017515449

Epoch: 16| Step: 0
Training loss: 3.346525192260742
Validation loss: 2.9540975760388117

Epoch: 6| Step: 1
Training loss: 2.804353952407837
Validation loss: 2.9501753776304183

Epoch: 6| Step: 2
Training loss: 2.1026229858398438
Validation loss: 2.943758487701416

Epoch: 6| Step: 3
Training loss: 3.112638473510742
Validation loss: 2.9461398124694824

Epoch: 6| Step: 4
Training loss: 3.0326812267303467
Validation loss: 2.9439158260181384

Epoch: 6| Step: 5
Training loss: 3.549978256225586
Validation loss: 2.9441828650812947

Epoch: 6| Step: 6
Training loss: 2.7920637130737305
Validation loss: 2.9419264716486775

Epoch: 6| Step: 7
Training loss: 3.285191535949707
Validation loss: 2.941714414986231

Epoch: 6| Step: 8
Training loss: 2.243931531906128
Validation loss: 2.935056040363927

Epoch: 6| Step: 9
Training loss: 4.05150032043457
Validation loss: 2.9306373160372496

Epoch: 6| Step: 10
Training loss: 2.9516735076904297
Validation loss: 2.924872775231638

Epoch: 6| Step: 11
Training loss: 2.6028690338134766
Validation loss: 2.922950260100826

Epoch: 6| Step: 12
Training loss: 2.8564248085021973
Validation loss: 2.9195000817698817

Epoch: 6| Step: 13
Training loss: 3.654658079147339
Validation loss: 2.918064240486391

Epoch: 17| Step: 0
Training loss: 2.7704615592956543
Validation loss: 2.9160047141454553

Epoch: 6| Step: 1
Training loss: 3.0611510276794434
Validation loss: 2.916667945923344

Epoch: 6| Step: 2
Training loss: 2.800171375274658
Validation loss: 2.915691944860643

Epoch: 6| Step: 3
Training loss: 3.0627787113189697
Validation loss: 2.9162319603786675

Epoch: 6| Step: 4
Training loss: 3.5729503631591797
Validation loss: 2.9112533523190405

Epoch: 6| Step: 5
Training loss: 2.3764877319335938
Validation loss: 2.9080543389884372

Epoch: 6| Step: 6
Training loss: 3.3962504863739014
Validation loss: 2.9032537680800243

Epoch: 6| Step: 7
Training loss: 4.319690704345703
Validation loss: 2.898875741548436

Epoch: 6| Step: 8
Training loss: 1.883625864982605
Validation loss: 2.8986895853473293

Epoch: 6| Step: 9
Training loss: 2.5886342525482178
Validation loss: 2.8967011974703882

Epoch: 6| Step: 10
Training loss: 2.6283888816833496
Validation loss: 2.8952528020387054

Epoch: 6| Step: 11
Training loss: 3.925394296646118
Validation loss: 2.891503377627301

Epoch: 6| Step: 12
Training loss: 2.266772747039795
Validation loss: 2.8828005252345914

Epoch: 6| Step: 13
Training loss: 3.343874931335449
Validation loss: 2.8848304261443434

Epoch: 18| Step: 0
Training loss: 2.7338368892669678
Validation loss: 2.8854654912025697

Epoch: 6| Step: 1
Training loss: 3.9558985233306885
Validation loss: 2.8962832163738947

Epoch: 6| Step: 2
Training loss: 2.9966533184051514
Validation loss: 2.891774490315427

Epoch: 6| Step: 3
Training loss: 3.2843070030212402
Validation loss: 2.8882113989963325

Epoch: 6| Step: 4
Training loss: 2.9191412925720215
Validation loss: 2.8855905327745663

Epoch: 6| Step: 5
Training loss: 3.1314468383789062
Validation loss: 2.8914038032613774

Epoch: 6| Step: 6
Training loss: 2.4002087116241455
Validation loss: 2.8770260426305954

Epoch: 6| Step: 7
Training loss: 2.1722426414489746
Validation loss: 2.8733369868288756

Epoch: 6| Step: 8
Training loss: 2.9054794311523438
Validation loss: 2.8692012756101546

Epoch: 6| Step: 9
Training loss: 3.4227161407470703
Validation loss: 2.868022826410109

Epoch: 6| Step: 10
Training loss: 2.6737217903137207
Validation loss: 2.861110036091138

Epoch: 6| Step: 11
Training loss: 2.925469398498535
Validation loss: 2.861224748755014

Epoch: 6| Step: 12
Training loss: 2.496568202972412
Validation loss: 2.8661156597957818

Epoch: 6| Step: 13
Training loss: 3.9314210414886475
Validation loss: 2.865797383810884

Epoch: 19| Step: 0
Training loss: 2.149606466293335
Validation loss: 2.8601561105379494

Epoch: 6| Step: 1
Training loss: 2.9935545921325684
Validation loss: 2.859305038247057

Epoch: 6| Step: 2
Training loss: 3.3646750450134277
Validation loss: 2.8574314989069456

Epoch: 6| Step: 3
Training loss: 2.608665943145752
Validation loss: 2.8503433478775846

Epoch: 6| Step: 4
Training loss: 2.901334285736084
Validation loss: 2.848355580401677

Epoch: 6| Step: 5
Training loss: 3.6169071197509766
Validation loss: 2.8480583211427093

Epoch: 6| Step: 6
Training loss: 3.6985507011413574
Validation loss: 2.8448167693230415

Epoch: 6| Step: 7
Training loss: 2.135193109512329
Validation loss: 2.8459344346036195

Epoch: 6| Step: 8
Training loss: 3.6826109886169434
Validation loss: 2.8445303004275084

Epoch: 6| Step: 9
Training loss: 3.15910005569458
Validation loss: 2.8438903747066373

Epoch: 6| Step: 10
Training loss: 2.2044918537139893
Validation loss: 2.8443415985312512

Epoch: 6| Step: 11
Training loss: 2.6793198585510254
Validation loss: 2.844246728445894

Epoch: 6| Step: 12
Training loss: 3.0775115489959717
Validation loss: 2.841463973445277

Epoch: 6| Step: 13
Training loss: 2.9993908405303955
Validation loss: 2.8334008160457818

Epoch: 20| Step: 0
Training loss: 2.9347054958343506
Validation loss: 2.828112945761732

Epoch: 6| Step: 1
Training loss: 4.098793983459473
Validation loss: 2.828781650912377

Epoch: 6| Step: 2
Training loss: 3.4520368576049805
Validation loss: 2.8261329332987466

Epoch: 6| Step: 3
Training loss: 2.8176605701446533
Validation loss: 2.823825564435733

Epoch: 6| Step: 4
Training loss: 2.7836813926696777
Validation loss: 2.8185360893126457

Epoch: 6| Step: 5
Training loss: 2.84770131111145
Validation loss: 2.8176937385271956

Epoch: 6| Step: 6
Training loss: 2.099018096923828
Validation loss: 2.816900453259868

Epoch: 6| Step: 7
Training loss: 2.414860486984253
Validation loss: 2.811872333608648

Epoch: 6| Step: 8
Training loss: 2.676797866821289
Validation loss: 2.8125314763797227

Epoch: 6| Step: 9
Training loss: 2.9880945682525635
Validation loss: 2.8179135066206737

Epoch: 6| Step: 10
Training loss: 2.5020089149475098
Validation loss: 2.814454109438004

Epoch: 6| Step: 11
Training loss: 3.1117987632751465
Validation loss: 2.8111029030174337

Epoch: 6| Step: 12
Training loss: 3.5908267498016357
Validation loss: 2.811474420691049

Epoch: 6| Step: 13
Training loss: 2.4796688556671143
Validation loss: 2.808391022425826

Epoch: 21| Step: 0
Training loss: 2.488135814666748
Validation loss: 2.8022548819100983

Epoch: 6| Step: 1
Training loss: 2.7268288135528564
Validation loss: 2.8034057283914215

Epoch: 6| Step: 2
Training loss: 2.038194417953491
Validation loss: 2.8022700740445043

Epoch: 6| Step: 3
Training loss: 3.628567695617676
Validation loss: 2.7998600365013204

Epoch: 6| Step: 4
Training loss: 3.286040782928467
Validation loss: 2.8049769965551232

Epoch: 6| Step: 5
Training loss: 3.1658687591552734
Validation loss: 2.7994677610294794

Epoch: 6| Step: 6
Training loss: 2.576124668121338
Validation loss: 2.7948520234836045

Epoch: 6| Step: 7
Training loss: 2.2954773902893066
Validation loss: 2.7957940050350722

Epoch: 6| Step: 8
Training loss: 2.826728343963623
Validation loss: 2.796848363773797

Epoch: 6| Step: 9
Training loss: 2.7125627994537354
Validation loss: 2.7925316313261628

Epoch: 6| Step: 10
Training loss: 3.5342445373535156
Validation loss: 2.7906132308385705

Epoch: 6| Step: 11
Training loss: 2.73907732963562
Validation loss: 2.789822898885255

Epoch: 6| Step: 12
Training loss: 3.102959156036377
Validation loss: 2.786783697784588

Epoch: 6| Step: 13
Training loss: 4.25178337097168
Validation loss: 2.7867580152327016

Epoch: 22| Step: 0
Training loss: 3.3921000957489014
Validation loss: 2.790601950819774

Epoch: 6| Step: 1
Training loss: 2.8845267295837402
Validation loss: 2.786422437237155

Epoch: 6| Step: 2
Training loss: 2.491240978240967
Validation loss: 2.784864846096244

Epoch: 6| Step: 3
Training loss: 3.7530624866485596
Validation loss: 2.784642357980051

Epoch: 6| Step: 4
Training loss: 3.1727547645568848
Validation loss: 2.784854386442451

Epoch: 6| Step: 5
Training loss: 2.2466838359832764
Validation loss: 2.780254779323455

Epoch: 6| Step: 6
Training loss: 2.6573855876922607
Validation loss: 2.7841443297683552

Epoch: 6| Step: 7
Training loss: 3.47652530670166
Validation loss: 2.783369602695588

Epoch: 6| Step: 8
Training loss: 2.3918066024780273
Validation loss: 2.7818592568879486

Epoch: 6| Step: 9
Training loss: 2.492464542388916
Validation loss: 2.781339696658555

Epoch: 6| Step: 10
Training loss: 3.453578472137451
Validation loss: 2.775394126933108

Epoch: 6| Step: 11
Training loss: 3.6061482429504395
Validation loss: 2.7698532791547876

Epoch: 6| Step: 12
Training loss: 2.083763360977173
Validation loss: 2.7677208838924283

Epoch: 6| Step: 13
Training loss: 2.2653260231018066
Validation loss: 2.7660630672208724

Epoch: 23| Step: 0
Training loss: 1.885421872138977
Validation loss: 2.7673849444235525

Epoch: 6| Step: 1
Training loss: 3.010188579559326
Validation loss: 2.776546142434561

Epoch: 6| Step: 2
Training loss: 3.2356057167053223
Validation loss: 2.7824169717809206

Epoch: 6| Step: 3
Training loss: 3.368112087249756
Validation loss: 2.782610977849653

Epoch: 6| Step: 4
Training loss: 3.599400520324707
Validation loss: 2.771811067417104

Epoch: 6| Step: 5
Training loss: 2.5051116943359375
Validation loss: 2.7624430605160293

Epoch: 6| Step: 6
Training loss: 3.1543502807617188
Validation loss: 2.7649885736485964

Epoch: 6| Step: 7
Training loss: 3.079765796661377
Validation loss: 2.7681096497402398

Epoch: 6| Step: 8
Training loss: 3.2744243144989014
Validation loss: 2.769802931816347

Epoch: 6| Step: 9
Training loss: 2.3435537815093994
Validation loss: 2.775069293155465

Epoch: 6| Step: 10
Training loss: 2.592038154602051
Validation loss: 2.776854345875402

Epoch: 6| Step: 11
Training loss: 2.635911464691162
Validation loss: 2.760880788167318

Epoch: 6| Step: 12
Training loss: 2.8095295429229736
Validation loss: 2.7548127276923067

Epoch: 6| Step: 13
Training loss: 3.046168088912964
Validation loss: 2.7552271966011292

Epoch: 24| Step: 0
Training loss: 3.2984800338745117
Validation loss: 2.7567753202171734

Epoch: 6| Step: 1
Training loss: 3.100201368331909
Validation loss: 2.752020917912965

Epoch: 6| Step: 2
Training loss: 2.469424247741699
Validation loss: 2.754498997042256

Epoch: 6| Step: 3
Training loss: 2.837545394897461
Validation loss: 2.752823857850926

Epoch: 6| Step: 4
Training loss: 3.169034242630005
Validation loss: 2.750717314340735

Epoch: 6| Step: 5
Training loss: 3.079596757888794
Validation loss: 2.7507397743963424

Epoch: 6| Step: 6
Training loss: 2.2004776000976562
Validation loss: 2.7490528065671205

Epoch: 6| Step: 7
Training loss: 3.4915385246276855
Validation loss: 2.7429228803162933

Epoch: 6| Step: 8
Training loss: 2.5803768634796143
Validation loss: 2.7466508137282504

Epoch: 6| Step: 9
Training loss: 2.407102584838867
Validation loss: 2.750163855091218

Epoch: 6| Step: 10
Training loss: 3.2313108444213867
Validation loss: 2.7466573356300272

Epoch: 6| Step: 11
Training loss: 3.489201068878174
Validation loss: 2.7462178225158365

Epoch: 6| Step: 12
Training loss: 2.458562135696411
Validation loss: 2.739832601239604

Epoch: 6| Step: 13
Training loss: 2.371306896209717
Validation loss: 2.736365731044482

Epoch: 25| Step: 0
Training loss: 2.205134630203247
Validation loss: 2.736010600161809

Epoch: 6| Step: 1
Training loss: 2.395089626312256
Validation loss: 2.7331485697018203

Epoch: 6| Step: 2
Training loss: 3.17492938041687
Validation loss: 2.7333387687642086

Epoch: 6| Step: 3
Training loss: 2.2466330528259277
Validation loss: 2.7374463927361274

Epoch: 6| Step: 4
Training loss: 3.3745675086975098
Validation loss: 2.7384031203485306

Epoch: 6| Step: 5
Training loss: 2.7201809883117676
Validation loss: 2.7370155934364564

Epoch: 6| Step: 6
Training loss: 2.680086851119995
Validation loss: 2.737656198522096

Epoch: 6| Step: 7
Training loss: 3.159024715423584
Validation loss: 2.737055801576184

Epoch: 6| Step: 8
Training loss: 3.1689252853393555
Validation loss: 2.7315580588515087

Epoch: 6| Step: 9
Training loss: 3.29095458984375
Validation loss: 2.7308055867430983

Epoch: 6| Step: 10
Training loss: 3.2531697750091553
Validation loss: 2.7289799028827297

Epoch: 6| Step: 11
Training loss: 2.741156578063965
Validation loss: 2.729952786558418

Epoch: 6| Step: 12
Training loss: 2.5875179767608643
Validation loss: 2.7340980037566154

Epoch: 6| Step: 13
Training loss: 3.569650888442993
Validation loss: 2.7381896075382026

Epoch: 26| Step: 0
Training loss: 2.4618136882781982
Validation loss: 2.740858598421979

Epoch: 6| Step: 1
Training loss: 2.853309392929077
Validation loss: 2.7412408474952943

Epoch: 6| Step: 2
Training loss: 2.8758254051208496
Validation loss: 2.735673148144958

Epoch: 6| Step: 3
Training loss: 3.088977098464966
Validation loss: 2.7286282867513676

Epoch: 6| Step: 4
Training loss: 3.124546527862549
Validation loss: 2.7242939882380988

Epoch: 6| Step: 5
Training loss: 1.9823625087738037
Validation loss: 2.720649967911423

Epoch: 6| Step: 6
Training loss: 2.3156723976135254
Validation loss: 2.7199342250823975

Epoch: 6| Step: 7
Training loss: 3.298997640609741
Validation loss: 2.7171751940122215

Epoch: 6| Step: 8
Training loss: 3.4594039916992188
Validation loss: 2.7163901277767715

Epoch: 6| Step: 9
Training loss: 3.046574592590332
Validation loss: 2.7172016866745485

Epoch: 6| Step: 10
Training loss: 2.217121124267578
Validation loss: 2.7149349771520144

Epoch: 6| Step: 11
Training loss: 3.0763044357299805
Validation loss: 2.7148251225871425

Epoch: 6| Step: 12
Training loss: 3.416175365447998
Validation loss: 2.7114722190364713

Epoch: 6| Step: 13
Training loss: 3.0091965198516846
Validation loss: 2.709772773968276

Epoch: 27| Step: 0
Training loss: 2.103254795074463
Validation loss: 2.7071494748515468

Epoch: 6| Step: 1
Training loss: 3.291627883911133
Validation loss: 2.714973234361218

Epoch: 6| Step: 2
Training loss: 2.1236860752105713
Validation loss: 2.726955126690608

Epoch: 6| Step: 3
Training loss: 3.813462257385254
Validation loss: 2.717497779477027

Epoch: 6| Step: 4
Training loss: 2.8541269302368164
Validation loss: 2.7165255520933416

Epoch: 6| Step: 5
Training loss: 2.462913751602173
Validation loss: 2.709718058186193

Epoch: 6| Step: 6
Training loss: 3.1487953662872314
Validation loss: 2.705782764701433

Epoch: 6| Step: 7
Training loss: 2.988909959793091
Validation loss: 2.7092782681988132

Epoch: 6| Step: 8
Training loss: 3.4606680870056152
Validation loss: 2.7182595012008504

Epoch: 6| Step: 9
Training loss: 2.773477077484131
Validation loss: 2.720856125636767

Epoch: 6| Step: 10
Training loss: 2.7412161827087402
Validation loss: 2.7194946273680656

Epoch: 6| Step: 11
Training loss: 2.949610710144043
Validation loss: 2.7101126640073714

Epoch: 6| Step: 12
Training loss: 2.542659282684326
Validation loss: 2.702223306061119

Epoch: 6| Step: 13
Training loss: 2.77313494682312
Validation loss: 2.698779539395404

Epoch: 28| Step: 0
Training loss: 2.5328176021575928
Validation loss: 2.704441608921174

Epoch: 6| Step: 1
Training loss: 3.278313159942627
Validation loss: 2.7094674059139785

Epoch: 6| Step: 2
Training loss: 2.5614447593688965
Validation loss: 2.7181513463297198

Epoch: 6| Step: 3
Training loss: 3.807704448699951
Validation loss: 2.7078914898698048

Epoch: 6| Step: 4
Training loss: 3.4394869804382324
Validation loss: 2.706316945373371

Epoch: 6| Step: 5
Training loss: 3.2856717109680176
Validation loss: 2.7041232547452374

Epoch: 6| Step: 6
Training loss: 2.530275344848633
Validation loss: 2.6964531842098443

Epoch: 6| Step: 7
Training loss: 2.746811866760254
Validation loss: 2.696475123846403

Epoch: 6| Step: 8
Training loss: 2.8517253398895264
Validation loss: 2.69409187634786

Epoch: 6| Step: 9
Training loss: 2.8675379753112793
Validation loss: 2.6935955862845145

Epoch: 6| Step: 10
Training loss: 2.9590134620666504
Validation loss: 2.708999600461734

Epoch: 6| Step: 11
Training loss: 2.5104751586914062
Validation loss: 2.7201625275355514

Epoch: 6| Step: 12
Training loss: 2.417113780975342
Validation loss: 2.7198287671612156

Epoch: 6| Step: 13
Training loss: 1.850659728050232
Validation loss: 2.70815751629491

Epoch: 29| Step: 0
Training loss: 3.2819504737854004
Validation loss: 2.7040764080580844

Epoch: 6| Step: 1
Training loss: 3.5793328285217285
Validation loss: 2.697849453136485

Epoch: 6| Step: 2
Training loss: 3.148848056793213
Validation loss: 2.694188707618303

Epoch: 6| Step: 3
Training loss: 2.678623676300049
Validation loss: 2.691489624720748

Epoch: 6| Step: 4
Training loss: 2.282005786895752
Validation loss: 2.6928274477681806

Epoch: 6| Step: 5
Training loss: 2.480916976928711
Validation loss: 2.6927198927889586

Epoch: 6| Step: 6
Training loss: 2.3034629821777344
Validation loss: 2.694875876108805

Epoch: 6| Step: 7
Training loss: 2.585736036300659
Validation loss: 2.6925520153455835

Epoch: 6| Step: 8
Training loss: 2.734872817993164
Validation loss: 2.6960866246172177

Epoch: 6| Step: 9
Training loss: 2.0739498138427734
Validation loss: 2.6929341516187115

Epoch: 6| Step: 10
Training loss: 3.686234712600708
Validation loss: 2.6956181295456423

Epoch: 6| Step: 11
Training loss: 3.6145479679107666
Validation loss: 2.6929201208135134

Epoch: 6| Step: 12
Training loss: 3.0291006565093994
Validation loss: 2.6863442390195784

Epoch: 6| Step: 13
Training loss: 2.024444341659546
Validation loss: 2.687348165819722

Epoch: 30| Step: 0
Training loss: 3.1651229858398438
Validation loss: 2.688574435890362

Epoch: 6| Step: 1
Training loss: 2.7219228744506836
Validation loss: 2.686782172931138

Epoch: 6| Step: 2
Training loss: 1.9144456386566162
Validation loss: 2.6906856054900796

Epoch: 6| Step: 3
Training loss: 3.272564172744751
Validation loss: 2.697881611444617

Epoch: 6| Step: 4
Training loss: 2.196071147918701
Validation loss: 2.6921732579508135

Epoch: 6| Step: 5
Training loss: 3.573683023452759
Validation loss: 2.6873007359043246

Epoch: 6| Step: 6
Training loss: 2.8990604877471924
Validation loss: 2.68412608228704

Epoch: 6| Step: 7
Training loss: 3.363117218017578
Validation loss: 2.6839344783495833

Epoch: 6| Step: 8
Training loss: 2.6610445976257324
Validation loss: 2.681921843559511

Epoch: 6| Step: 9
Training loss: 2.6261796951293945
Validation loss: 2.6834024690812632

Epoch: 6| Step: 10
Training loss: 2.5814859867095947
Validation loss: 2.683116635968608

Epoch: 6| Step: 11
Training loss: 3.3593766689300537
Validation loss: 2.6831073658440703

Epoch: 6| Step: 12
Training loss: 2.8023877143859863
Validation loss: 2.687126995414816

Epoch: 6| Step: 13
Training loss: 2.5526673793792725
Validation loss: 2.6849631135181715

Epoch: 31| Step: 0
Training loss: 2.7655177116394043
Validation loss: 2.684683526715925

Epoch: 6| Step: 1
Training loss: 2.2881033420562744
Validation loss: 2.6807333371972524

Epoch: 6| Step: 2
Training loss: 2.5136775970458984
Validation loss: 2.6820924282073975

Epoch: 6| Step: 3
Training loss: 2.246480703353882
Validation loss: 2.680472348325996

Epoch: 6| Step: 4
Training loss: 2.905306100845337
Validation loss: 2.6846071622704946

Epoch: 6| Step: 5
Training loss: 2.96744966506958
Validation loss: 2.678941839484758

Epoch: 6| Step: 6
Training loss: 3.896416425704956
Validation loss: 2.680742884194979

Epoch: 6| Step: 7
Training loss: 2.9961483478546143
Validation loss: 2.6768856535675707

Epoch: 6| Step: 8
Training loss: 3.619948387145996
Validation loss: 2.6752262397478987

Epoch: 6| Step: 9
Training loss: 2.65142822265625
Validation loss: 2.6777338725264355

Epoch: 6| Step: 10
Training loss: 2.911299705505371
Validation loss: 2.6856616209912043

Epoch: 6| Step: 11
Training loss: 1.931553840637207
Validation loss: 2.68761545355602

Epoch: 6| Step: 12
Training loss: 3.0427894592285156
Validation loss: 2.68319901856043

Epoch: 6| Step: 13
Training loss: 3.1140620708465576
Validation loss: 2.6799755455345236

Epoch: 32| Step: 0
Training loss: 3.1533737182617188
Validation loss: 2.676054108527399

Epoch: 6| Step: 1
Training loss: 2.7944796085357666
Validation loss: 2.6720343559019026

Epoch: 6| Step: 2
Training loss: 2.848947048187256
Validation loss: 2.6695066523808304

Epoch: 6| Step: 3
Training loss: 3.403869390487671
Validation loss: 2.6637360306196314

Epoch: 6| Step: 4
Training loss: 2.5675666332244873
Validation loss: 2.6685268032935356

Epoch: 6| Step: 5
Training loss: 2.021407127380371
Validation loss: 2.6666276172925065

Epoch: 6| Step: 6
Training loss: 2.9451828002929688
Validation loss: 2.6680499533171296

Epoch: 6| Step: 7
Training loss: 2.770705461502075
Validation loss: 2.6738597936527704

Epoch: 6| Step: 8
Training loss: 2.5092685222625732
Validation loss: 2.6712443520945888

Epoch: 6| Step: 9
Training loss: 3.4534010887145996
Validation loss: 2.672975940089072

Epoch: 6| Step: 10
Training loss: 2.7439537048339844
Validation loss: 2.672780547090756

Epoch: 6| Step: 11
Training loss: 3.275453805923462
Validation loss: 2.6741973610334497

Epoch: 6| Step: 12
Training loss: 1.9907042980194092
Validation loss: 2.668030138938658

Epoch: 6| Step: 13
Training loss: 3.3570189476013184
Validation loss: 2.673770889159172

Epoch: 33| Step: 0
Training loss: 3.277702808380127
Validation loss: 2.6748421909988567

Epoch: 6| Step: 1
Training loss: 2.593872547149658
Validation loss: 2.673914099252352

Epoch: 6| Step: 2
Training loss: 3.1484274864196777
Validation loss: 2.667123189536474

Epoch: 6| Step: 3
Training loss: 2.752901077270508
Validation loss: 2.66345468900537

Epoch: 6| Step: 4
Training loss: 2.173264980316162
Validation loss: 2.663711747815532

Epoch: 6| Step: 5
Training loss: 2.650674819946289
Validation loss: 2.6660147302894184

Epoch: 6| Step: 6
Training loss: 3.605532169342041
Validation loss: 2.6706538584924515

Epoch: 6| Step: 7
Training loss: 3.497335433959961
Validation loss: 2.674446749430831

Epoch: 6| Step: 8
Training loss: 2.517078161239624
Validation loss: 2.6671579935217418

Epoch: 6| Step: 9
Training loss: 2.841341257095337
Validation loss: 2.6693206166708343

Epoch: 6| Step: 10
Training loss: 2.329951286315918
Validation loss: 2.6651690442075013

Epoch: 6| Step: 11
Training loss: 3.084102153778076
Validation loss: 2.6663783237498295

Epoch: 6| Step: 12
Training loss: 2.3889408111572266
Validation loss: 2.6641268576345136

Epoch: 6| Step: 13
Training loss: 2.582120418548584
Validation loss: 2.663802323802825

Epoch: 34| Step: 0
Training loss: 2.397608757019043
Validation loss: 2.663749423078311

Epoch: 6| Step: 1
Training loss: 3.3798766136169434
Validation loss: 2.6633924309925368

Epoch: 6| Step: 2
Training loss: 3.6165599822998047
Validation loss: 2.66708557580107

Epoch: 6| Step: 3
Training loss: 2.831662654876709
Validation loss: 2.664067304262551

Epoch: 6| Step: 4
Training loss: 3.560431718826294
Validation loss: 2.663300868003599

Epoch: 6| Step: 5
Training loss: 1.9280955791473389
Validation loss: 2.6693213806357434

Epoch: 6| Step: 6
Training loss: 2.779125452041626
Validation loss: 2.6677627730113205

Epoch: 6| Step: 7
Training loss: 2.8578405380249023
Validation loss: 2.667253525026383

Epoch: 6| Step: 8
Training loss: 2.43058443069458
Validation loss: 2.665757317696848

Epoch: 6| Step: 9
Training loss: 2.539663791656494
Validation loss: 2.6638468593679447

Epoch: 6| Step: 10
Training loss: 3.285475492477417
Validation loss: 2.6613112444518716

Epoch: 6| Step: 11
Training loss: 2.5966575145721436
Validation loss: 2.6616278694521998

Epoch: 6| Step: 12
Training loss: 2.9075357913970947
Validation loss: 2.6581483117995726

Epoch: 6| Step: 13
Training loss: 1.9485793113708496
Validation loss: 2.654953961731285

Epoch: 35| Step: 0
Training loss: 2.8439126014709473
Validation loss: 2.654671702333676

Epoch: 6| Step: 1
Training loss: 2.1654610633850098
Validation loss: 2.6516400793547272

Epoch: 6| Step: 2
Training loss: 3.670943021774292
Validation loss: 2.6523197261236047

Epoch: 6| Step: 3
Training loss: 3.3014798164367676
Validation loss: 2.6486903954577703

Epoch: 6| Step: 4
Training loss: 2.533100128173828
Validation loss: 2.650388517687398

Epoch: 6| Step: 5
Training loss: 3.145056962966919
Validation loss: 2.6494746105645293

Epoch: 6| Step: 6
Training loss: 3.6752562522888184
Validation loss: 2.6446268302138134

Epoch: 6| Step: 7
Training loss: 2.9196548461914062
Validation loss: 2.6439379081931165

Epoch: 6| Step: 8
Training loss: 2.523223638534546
Validation loss: 2.6445081054523425

Epoch: 6| Step: 9
Training loss: 2.0480504035949707
Validation loss: 2.644783050783219

Epoch: 6| Step: 10
Training loss: 2.4465341567993164
Validation loss: 2.6443302221195673

Epoch: 6| Step: 11
Training loss: 2.9820809364318848
Validation loss: 2.6398033916309314

Epoch: 6| Step: 12
Training loss: 2.9345502853393555
Validation loss: 2.6421522273812243

Epoch: 6| Step: 13
Training loss: 1.7782219648361206
Validation loss: 2.640862305959066

Epoch: 36| Step: 0
Training loss: 3.310138702392578
Validation loss: 2.6462539370341966

Epoch: 6| Step: 1
Training loss: 2.3048105239868164
Validation loss: 2.647124300720871

Epoch: 6| Step: 2
Training loss: 3.0394363403320312
Validation loss: 2.659984124604092

Epoch: 6| Step: 3
Training loss: 2.903331995010376
Validation loss: 2.65635577324898

Epoch: 6| Step: 4
Training loss: 2.886861801147461
Validation loss: 2.658373050792243

Epoch: 6| Step: 5
Training loss: 3.979186534881592
Validation loss: 2.656158935639166

Epoch: 6| Step: 6
Training loss: 3.5638809204101562
Validation loss: 2.654908687837662

Epoch: 6| Step: 7
Training loss: 2.4491729736328125
Validation loss: 2.642712208532518

Epoch: 6| Step: 8
Training loss: 2.253080368041992
Validation loss: 2.641433004410036

Epoch: 6| Step: 9
Training loss: 2.321828842163086
Validation loss: 2.6433322916748705

Epoch: 6| Step: 10
Training loss: 1.9458048343658447
Validation loss: 2.6396940882487963

Epoch: 6| Step: 11
Training loss: 2.505126953125
Validation loss: 2.6411828533295663

Epoch: 6| Step: 12
Training loss: 3.38606333732605
Validation loss: 2.6407992814176824

Epoch: 6| Step: 13
Training loss: 2.2537789344787598
Validation loss: 2.6379270297224804

Epoch: 37| Step: 0
Training loss: 2.753385305404663
Validation loss: 2.636574505477823

Epoch: 6| Step: 1
Training loss: 2.8028738498687744
Validation loss: 2.6366699793005504

Epoch: 6| Step: 2
Training loss: 3.055715322494507
Validation loss: 2.634104456952823

Epoch: 6| Step: 3
Training loss: 2.8704631328582764
Validation loss: 2.6372326932927614

Epoch: 6| Step: 4
Training loss: 2.6082513332366943
Validation loss: 2.6379008857152795

Epoch: 6| Step: 5
Training loss: 2.178406238555908
Validation loss: 2.6414492668644076

Epoch: 6| Step: 6
Training loss: 2.831188678741455
Validation loss: 2.6424770662861485

Epoch: 6| Step: 7
Training loss: 2.7362470626831055
Validation loss: 2.6372275147386777

Epoch: 6| Step: 8
Training loss: 2.7932777404785156
Validation loss: 2.641254681412892

Epoch: 6| Step: 9
Training loss: 2.7865915298461914
Validation loss: 2.640298407564881

Epoch: 6| Step: 10
Training loss: 3.174088478088379
Validation loss: 2.6358659139243503

Epoch: 6| Step: 11
Training loss: 2.7500648498535156
Validation loss: 2.642151194234048

Epoch: 6| Step: 12
Training loss: 2.5929489135742188
Validation loss: 2.6395694491683797

Epoch: 6| Step: 13
Training loss: 3.7975387573242188
Validation loss: 2.643769133475519

Epoch: 38| Step: 0
Training loss: 2.1534299850463867
Validation loss: 2.6513373672321277

Epoch: 6| Step: 1
Training loss: 2.8413901329040527
Validation loss: 2.6533400832965808

Epoch: 6| Step: 2
Training loss: 2.713182210922241
Validation loss: 2.6496868595000236

Epoch: 6| Step: 3
Training loss: 2.2820723056793213
Validation loss: 2.6716827423341813

Epoch: 6| Step: 4
Training loss: 2.2684719562530518
Validation loss: 2.6717682166766097

Epoch: 6| Step: 5
Training loss: 3.176377773284912
Validation loss: 2.6734920547854517

Epoch: 6| Step: 6
Training loss: 2.7491068840026855
Validation loss: 2.6747421013411654

Epoch: 6| Step: 7
Training loss: 2.6758155822753906
Validation loss: 2.679787548639441

Epoch: 6| Step: 8
Training loss: 3.1023077964782715
Validation loss: 2.6795381986966698

Epoch: 6| Step: 9
Training loss: 2.0208888053894043
Validation loss: 2.667215775418025

Epoch: 6| Step: 10
Training loss: 3.4679694175720215
Validation loss: 2.64307572508371

Epoch: 6| Step: 11
Training loss: 2.7722537517547607
Validation loss: 2.6414497129378782

Epoch: 6| Step: 12
Training loss: 3.0511748790740967
Validation loss: 2.6413132016376784

Epoch: 6| Step: 13
Training loss: 4.919623374938965
Validation loss: 2.6401617245007585

Epoch: 39| Step: 0
Training loss: 3.0350050926208496
Validation loss: 2.6329849612328315

Epoch: 6| Step: 1
Training loss: 2.670903205871582
Validation loss: 2.634925103956653

Epoch: 6| Step: 2
Training loss: 2.7173333168029785
Validation loss: 2.636658214753674

Epoch: 6| Step: 3
Training loss: 2.7969141006469727
Validation loss: 2.6298007042177263

Epoch: 6| Step: 4
Training loss: 3.0376057624816895
Validation loss: 2.63315644315494

Epoch: 6| Step: 5
Training loss: 3.2202072143554688
Validation loss: 2.6382264014213317

Epoch: 6| Step: 6
Training loss: 2.546546459197998
Validation loss: 2.6469323353100846

Epoch: 6| Step: 7
Training loss: 3.038203477859497
Validation loss: 2.648391813360235

Epoch: 6| Step: 8
Training loss: 2.76944637298584
Validation loss: 2.6413959892847205

Epoch: 6| Step: 9
Training loss: 1.8890511989593506
Validation loss: 2.6471374291245655

Epoch: 6| Step: 10
Training loss: 3.7838196754455566
Validation loss: 2.647643827622937

Epoch: 6| Step: 11
Training loss: 2.9512290954589844
Validation loss: 2.643905025656505

Epoch: 6| Step: 12
Training loss: 2.2854819297790527
Validation loss: 2.639220914533061

Epoch: 6| Step: 13
Training loss: 2.2792413234710693
Validation loss: 2.6446990889887654

Epoch: 40| Step: 0
Training loss: 2.8918237686157227
Validation loss: 2.655067495120469

Epoch: 6| Step: 1
Training loss: 2.609757900238037
Validation loss: 2.6414549376374934

Epoch: 6| Step: 2
Training loss: 3.2334587574005127
Validation loss: 2.6319520755480696

Epoch: 6| Step: 3
Training loss: 2.2069895267486572
Validation loss: 2.630460375098772

Epoch: 6| Step: 4
Training loss: 2.5815768241882324
Validation loss: 2.63233519113192

Epoch: 6| Step: 5
Training loss: 3.0369677543640137
Validation loss: 2.626635930871451

Epoch: 6| Step: 6
Training loss: 3.1706418991088867
Validation loss: 2.6282605458331365

Epoch: 6| Step: 7
Training loss: 2.927034854888916
Validation loss: 2.627352945266231

Epoch: 6| Step: 8
Training loss: 2.847658634185791
Validation loss: 2.6298844199026785

Epoch: 6| Step: 9
Training loss: 1.8784453868865967
Validation loss: 2.6256237183847735

Epoch: 6| Step: 10
Training loss: 2.3008384704589844
Validation loss: 2.6265928335087274

Epoch: 6| Step: 11
Training loss: 3.3489623069763184
Validation loss: 2.623837245407925

Epoch: 6| Step: 12
Training loss: 2.8912925720214844
Validation loss: 2.622982846793308

Epoch: 6| Step: 13
Training loss: 3.605455160140991
Validation loss: 2.6236201178643013

Epoch: 41| Step: 0
Training loss: 3.3484559059143066
Validation loss: 2.624524603607834

Epoch: 6| Step: 1
Training loss: 2.9587578773498535
Validation loss: 2.6239751641468336

Epoch: 6| Step: 2
Training loss: 2.6056065559387207
Validation loss: 2.6189028165673696

Epoch: 6| Step: 3
Training loss: 2.8891959190368652
Validation loss: 2.6191976275495303

Epoch: 6| Step: 4
Training loss: 3.027688503265381
Validation loss: 2.6188491339324624

Epoch: 6| Step: 5
Training loss: 3.3822898864746094
Validation loss: 2.620785974687146

Epoch: 6| Step: 6
Training loss: 2.8875298500061035
Validation loss: 2.6182126998901367

Epoch: 6| Step: 7
Training loss: 2.5869743824005127
Validation loss: 2.621075386642128

Epoch: 6| Step: 8
Training loss: 2.3834328651428223
Validation loss: 2.6201370249512377

Epoch: 6| Step: 9
Training loss: 2.128065824508667
Validation loss: 2.6174647141528387

Epoch: 6| Step: 10
Training loss: 2.6395745277404785
Validation loss: 2.6152682778655842

Epoch: 6| Step: 11
Training loss: 3.000746011734009
Validation loss: 2.619450056424705

Epoch: 6| Step: 12
Training loss: 2.749720811843872
Validation loss: 2.6160182850335234

Epoch: 6| Step: 13
Training loss: 2.314760208129883
Validation loss: 2.613181755106936

Epoch: 42| Step: 0
Training loss: 2.712648868560791
Validation loss: 2.607976972415883

Epoch: 6| Step: 1
Training loss: 3.6529541015625
Validation loss: 2.612779689091508

Epoch: 6| Step: 2
Training loss: 3.010582447052002
Validation loss: 2.6096152579912575

Epoch: 6| Step: 3
Training loss: 2.81864595413208
Validation loss: 2.61021008799153

Epoch: 6| Step: 4
Training loss: 2.6222171783447266
Validation loss: 2.6103081985186507

Epoch: 6| Step: 5
Training loss: 2.4075427055358887
Validation loss: 2.6098753124155025

Epoch: 6| Step: 6
Training loss: 3.188048839569092
Validation loss: 2.6061997439271662

Epoch: 6| Step: 7
Training loss: 2.7476565837860107
Validation loss: 2.609178263653991

Epoch: 6| Step: 8
Training loss: 2.746659755706787
Validation loss: 2.606473130564536

Epoch: 6| Step: 9
Training loss: 2.600341796875
Validation loss: 2.6050103864362164

Epoch: 6| Step: 10
Training loss: 2.405608892440796
Validation loss: 2.606580864998602

Epoch: 6| Step: 11
Training loss: 3.199977159500122
Validation loss: 2.6038527001616774

Epoch: 6| Step: 12
Training loss: 2.3667731285095215
Validation loss: 2.608342127133441

Epoch: 6| Step: 13
Training loss: 2.312593936920166
Validation loss: 2.608160312457751

Epoch: 43| Step: 0
Training loss: 2.6967673301696777
Validation loss: 2.609108735156316

Epoch: 6| Step: 1
Training loss: 2.7666094303131104
Validation loss: 2.609536450396302

Epoch: 6| Step: 2
Training loss: 2.736417770385742
Validation loss: 2.6162859086067445

Epoch: 6| Step: 3
Training loss: 3.094938278198242
Validation loss: 2.6149123868634625

Epoch: 6| Step: 4
Training loss: 2.705355405807495
Validation loss: 2.6136282977237495

Epoch: 6| Step: 5
Training loss: 3.135110855102539
Validation loss: 2.6111611986673005

Epoch: 6| Step: 6
Training loss: 2.839864492416382
Validation loss: 2.6140063757537515

Epoch: 6| Step: 7
Training loss: 2.68141508102417
Validation loss: 2.608474367408342

Epoch: 6| Step: 8
Training loss: 2.89369535446167
Validation loss: 2.6106194450009252

Epoch: 6| Step: 9
Training loss: 3.436589241027832
Validation loss: 2.608057568150182

Epoch: 6| Step: 10
Training loss: 2.472093105316162
Validation loss: 2.6114807231451875

Epoch: 6| Step: 11
Training loss: 2.3520689010620117
Validation loss: 2.6092775355103197

Epoch: 6| Step: 12
Training loss: 2.500159978866577
Validation loss: 2.6103508651897473

Epoch: 6| Step: 13
Training loss: 2.4234933853149414
Validation loss: 2.6040556533362276

Epoch: 44| Step: 0
Training loss: 2.711158275604248
Validation loss: 2.6011524277348674

Epoch: 6| Step: 1
Training loss: 2.7042291164398193
Validation loss: 2.6069954646530973

Epoch: 6| Step: 2
Training loss: 2.8788535594940186
Validation loss: 2.598428428813975

Epoch: 6| Step: 3
Training loss: 2.892101287841797
Validation loss: 2.603576260228311

Epoch: 6| Step: 4
Training loss: 3.2383413314819336
Validation loss: 2.6003856402571484

Epoch: 6| Step: 5
Training loss: 3.3445048332214355
Validation loss: 2.5983861595071773

Epoch: 6| Step: 6
Training loss: 2.53889799118042
Validation loss: 2.594847913711302

Epoch: 6| Step: 7
Training loss: 2.9080073833465576
Validation loss: 2.594753352544641

Epoch: 6| Step: 8
Training loss: 2.0571298599243164
Validation loss: 2.5913337840828845

Epoch: 6| Step: 9
Training loss: 3.626809597015381
Validation loss: 2.592509992661015

Epoch: 6| Step: 10
Training loss: 2.6316909790039062
Validation loss: 2.5891825793891825

Epoch: 6| Step: 11
Training loss: 2.229349136352539
Validation loss: 2.594511288468556

Epoch: 6| Step: 12
Training loss: 2.038966655731201
Validation loss: 2.593649423250588

Epoch: 6| Step: 13
Training loss: 3.208486318588257
Validation loss: 2.5989164126816617

Epoch: 45| Step: 0
Training loss: 2.5892081260681152
Validation loss: 2.6045449062060286

Epoch: 6| Step: 1
Training loss: 3.6224944591522217
Validation loss: 2.601913418821109

Epoch: 6| Step: 2
Training loss: 3.275646209716797
Validation loss: 2.5985363760302143

Epoch: 6| Step: 3
Training loss: 2.8544766902923584
Validation loss: 2.5940182055196455

Epoch: 6| Step: 4
Training loss: 2.658931255340576
Validation loss: 2.5943900128846527

Epoch: 6| Step: 5
Training loss: 1.8033928871154785
Validation loss: 2.586937553139143

Epoch: 6| Step: 6
Training loss: 3.145223617553711
Validation loss: 2.5824034496020247

Epoch: 6| Step: 7
Training loss: 2.744901180267334
Validation loss: 2.583321696968489

Epoch: 6| Step: 8
Training loss: 3.3963606357574463
Validation loss: 2.580548301819832

Epoch: 6| Step: 9
Training loss: 2.7678091526031494
Validation loss: 2.578853578977687

Epoch: 6| Step: 10
Training loss: 2.563070058822632
Validation loss: 2.5810563231027253

Epoch: 6| Step: 11
Training loss: 1.6040544509887695
Validation loss: 2.585041730634628

Epoch: 6| Step: 12
Training loss: 3.0986673831939697
Validation loss: 2.579119360575112

Epoch: 6| Step: 13
Training loss: 2.406179428100586
Validation loss: 2.580514943727883

Epoch: 46| Step: 0
Training loss: 2.6911189556121826
Validation loss: 2.5801567262218845

Epoch: 6| Step: 1
Training loss: 2.6099884510040283
Validation loss: 2.5786348081404165

Epoch: 6| Step: 2
Training loss: 2.4883406162261963
Validation loss: 2.579319130989813

Epoch: 6| Step: 3
Training loss: 3.224351406097412
Validation loss: 2.5802444898954002

Epoch: 6| Step: 4
Training loss: 2.927699327468872
Validation loss: 2.5819632545594247

Epoch: 6| Step: 5
Training loss: 2.9296457767486572
Validation loss: 2.580785387305803

Epoch: 6| Step: 6
Training loss: 3.505964994430542
Validation loss: 2.5783719990843084

Epoch: 6| Step: 7
Training loss: 2.506221294403076
Validation loss: 2.5744596091649865

Epoch: 6| Step: 8
Training loss: 2.6449923515319824
Validation loss: 2.5743587529787453

Epoch: 6| Step: 9
Training loss: 2.416797161102295
Validation loss: 2.5736791087735083

Epoch: 6| Step: 10
Training loss: 2.3945600986480713
Validation loss: 2.574313099666308

Epoch: 6| Step: 11
Training loss: 2.3847873210906982
Validation loss: 2.57562727825616

Epoch: 6| Step: 12
Training loss: 3.1448283195495605
Validation loss: 2.5762027540514545

Epoch: 6| Step: 13
Training loss: 2.835845947265625
Validation loss: 2.5740913729513846

Epoch: 47| Step: 0
Training loss: 2.995892286300659
Validation loss: 2.582393987204439

Epoch: 6| Step: 1
Training loss: 3.6126675605773926
Validation loss: 2.5925098260243735

Epoch: 6| Step: 2
Training loss: 3.2640278339385986
Validation loss: 2.588861991000432

Epoch: 6| Step: 3
Training loss: 3.3470163345336914
Validation loss: 2.5905818695663125

Epoch: 6| Step: 4
Training loss: 2.2337801456451416
Validation loss: 2.5834820731993644

Epoch: 6| Step: 5
Training loss: 2.169264793395996
Validation loss: 2.5901828837651077

Epoch: 6| Step: 6
Training loss: 2.7931160926818848
Validation loss: 2.584330274212745

Epoch: 6| Step: 7
Training loss: 3.129396438598633
Validation loss: 2.582146047264017

Epoch: 6| Step: 8
Training loss: 2.5846824645996094
Validation loss: 2.585292411106889

Epoch: 6| Step: 9
Training loss: 2.6335668563842773
Validation loss: 2.588353982535742

Epoch: 6| Step: 10
Training loss: 2.1670286655426025
Validation loss: 2.587311024306923

Epoch: 6| Step: 11
Training loss: 1.822744369506836
Validation loss: 2.58336397909349

Epoch: 6| Step: 12
Training loss: 2.994304656982422
Validation loss: 2.577030917649628

Epoch: 6| Step: 13
Training loss: 2.7798967361450195
Validation loss: 2.5688416547672723

Epoch: 48| Step: 0
Training loss: 2.001554012298584
Validation loss: 2.5692590385354976

Epoch: 6| Step: 1
Training loss: 3.134692907333374
Validation loss: 2.5763696624386694

Epoch: 6| Step: 2
Training loss: 2.691126585006714
Validation loss: 2.5788897724561792

Epoch: 6| Step: 3
Training loss: 3.3183343410491943
Validation loss: 2.586917413178311

Epoch: 6| Step: 4
Training loss: 2.545308828353882
Validation loss: 2.5967085182025866

Epoch: 6| Step: 5
Training loss: 2.782522201538086
Validation loss: 2.606512536284744

Epoch: 6| Step: 6
Training loss: 2.91803240776062
Validation loss: 2.6016797763045116

Epoch: 6| Step: 7
Training loss: 3.360621929168701
Validation loss: 2.5987200557544665

Epoch: 6| Step: 8
Training loss: 2.7296957969665527
Validation loss: 2.5884742762452815

Epoch: 6| Step: 9
Training loss: 2.1902575492858887
Validation loss: 2.5816633983324935

Epoch: 6| Step: 10
Training loss: 2.29660701751709
Validation loss: 2.5779207855142574

Epoch: 6| Step: 11
Training loss: 3.3646819591522217
Validation loss: 2.5704717995018087

Epoch: 6| Step: 12
Training loss: 2.8332128524780273
Validation loss: 2.5717205027098298

Epoch: 6| Step: 13
Training loss: 2.2904927730560303
Validation loss: 2.5788033188030286

Epoch: 49| Step: 0
Training loss: 2.442718982696533
Validation loss: 2.615397084143854

Epoch: 6| Step: 1
Training loss: 3.3085460662841797
Validation loss: 2.651023439181748

Epoch: 6| Step: 2
Training loss: 2.764735460281372
Validation loss: 2.672237039894186

Epoch: 6| Step: 3
Training loss: 2.884805202484131
Validation loss: 2.729103693398096

Epoch: 6| Step: 4
Training loss: 2.0988502502441406
Validation loss: 2.714874359869188

Epoch: 6| Step: 5
Training loss: 2.4315667152404785
Validation loss: 2.690978568087342

Epoch: 6| Step: 6
Training loss: 2.6378250122070312
Validation loss: 2.6616357347016693

Epoch: 6| Step: 7
Training loss: 2.6392898559570312
Validation loss: 2.6366399513777865

Epoch: 6| Step: 8
Training loss: 2.734572410583496
Validation loss: 2.596528399375177

Epoch: 6| Step: 9
Training loss: 3.5579986572265625
Validation loss: 2.567739702040149

Epoch: 6| Step: 10
Training loss: 3.581296682357788
Validation loss: 2.5683396990581224

Epoch: 6| Step: 11
Training loss: 3.0548949241638184
Validation loss: 2.564462056723974

Epoch: 6| Step: 12
Training loss: 2.074981689453125
Validation loss: 2.5654568954180648

Epoch: 6| Step: 13
Training loss: 2.2944366931915283
Validation loss: 2.5684104324668966

Epoch: 50| Step: 0
Training loss: 2.602034568786621
Validation loss: 2.5783871502004643

Epoch: 6| Step: 1
Training loss: 3.012036085128784
Validation loss: 2.581794890024329

Epoch: 6| Step: 2
Training loss: 3.2658281326293945
Validation loss: 2.582473590809812

Epoch: 6| Step: 3
Training loss: 2.7080650329589844
Validation loss: 2.585717680633709

Epoch: 6| Step: 4
Training loss: 2.7931456565856934
Validation loss: 2.585191188320037

Epoch: 6| Step: 5
Training loss: 2.2341742515563965
Validation loss: 2.581069754016015

Epoch: 6| Step: 6
Training loss: 3.0174849033355713
Validation loss: 2.57641887921159

Epoch: 6| Step: 7
Training loss: 2.6710753440856934
Validation loss: 2.578495348653486

Epoch: 6| Step: 8
Training loss: 2.7881317138671875
Validation loss: 2.575743918777794

Epoch: 6| Step: 9
Training loss: 2.9338104724884033
Validation loss: 2.5739031196922384

Epoch: 6| Step: 10
Training loss: 2.8601646423339844
Validation loss: 2.571146224134712

Epoch: 6| Step: 11
Training loss: 2.728801727294922
Validation loss: 2.5631108899270334

Epoch: 6| Step: 12
Training loss: 2.576962947845459
Validation loss: 2.5604852655882477

Epoch: 6| Step: 13
Training loss: 2.273855686187744
Validation loss: 2.5588701309696322

Epoch: 51| Step: 0
Training loss: 2.703904151916504
Validation loss: 2.560317864982031

Epoch: 6| Step: 1
Training loss: 2.6990132331848145
Validation loss: 2.559191098777197

Epoch: 6| Step: 2
Training loss: 2.8248233795166016
Validation loss: 2.5591011944637505

Epoch: 6| Step: 3
Training loss: 2.320732831954956
Validation loss: 2.5674595704642673

Epoch: 6| Step: 4
Training loss: 3.4529309272766113
Validation loss: 2.576851637132706

Epoch: 6| Step: 5
Training loss: 2.219479560852051
Validation loss: 2.601336666332778

Epoch: 6| Step: 6
Training loss: 2.277134418487549
Validation loss: 2.6060124058877268

Epoch: 6| Step: 7
Training loss: 2.962498188018799
Validation loss: 2.6105124335135184

Epoch: 6| Step: 8
Training loss: 3.115070343017578
Validation loss: 2.5870048358876216

Epoch: 6| Step: 9
Training loss: 2.7800567150115967
Validation loss: 2.57683777552779

Epoch: 6| Step: 10
Training loss: 3.3080673217773438
Validation loss: 2.5619250856420046

Epoch: 6| Step: 11
Training loss: 2.682955265045166
Validation loss: 2.5588577562762844

Epoch: 6| Step: 12
Training loss: 2.836477756500244
Validation loss: 2.5541106295841995

Epoch: 6| Step: 13
Training loss: 2.161257743835449
Validation loss: 2.5560350597545667

Epoch: 52| Step: 0
Training loss: 2.7735493183135986
Validation loss: 2.5564105408166045

Epoch: 6| Step: 1
Training loss: 2.6447701454162598
Validation loss: 2.561011686119982

Epoch: 6| Step: 2
Training loss: 2.9558608531951904
Validation loss: 2.5622462739226637

Epoch: 6| Step: 3
Training loss: 3.6986007690429688
Validation loss: 2.5621592870322605

Epoch: 6| Step: 4
Training loss: 2.4057092666625977
Validation loss: 2.5611935020774923

Epoch: 6| Step: 5
Training loss: 2.4984967708587646
Validation loss: 2.556849338675058

Epoch: 6| Step: 6
Training loss: 2.3639259338378906
Validation loss: 2.5648898296458746

Epoch: 6| Step: 7
Training loss: 2.4589812755584717
Validation loss: 2.564040337839434

Epoch: 6| Step: 8
Training loss: 2.763009548187256
Validation loss: 2.5618146952762397

Epoch: 6| Step: 9
Training loss: 3.013737201690674
Validation loss: 2.563352782239196

Epoch: 6| Step: 10
Training loss: 2.3560242652893066
Validation loss: 2.5649065253555134

Epoch: 6| Step: 11
Training loss: 2.839782476425171
Validation loss: 2.559997186865858

Epoch: 6| Step: 12
Training loss: 3.0952281951904297
Validation loss: 2.5566372256125174

Epoch: 6| Step: 13
Training loss: 2.536363124847412
Validation loss: 2.5561045421067106

Epoch: 53| Step: 0
Training loss: 2.0154457092285156
Validation loss: 2.5574125397589897

Epoch: 6| Step: 1
Training loss: 2.985304594039917
Validation loss: 2.5599349160348215

Epoch: 6| Step: 2
Training loss: 3.0758237838745117
Validation loss: 2.562325013581143

Epoch: 6| Step: 3
Training loss: 4.226962089538574
Validation loss: 2.5709253946940103

Epoch: 6| Step: 4
Training loss: 2.4339041709899902
Validation loss: 2.571067807494953

Epoch: 6| Step: 5
Training loss: 3.087540626525879
Validation loss: 2.5800885179991364

Epoch: 6| Step: 6
Training loss: 3.0577964782714844
Validation loss: 2.5753291191593295

Epoch: 6| Step: 7
Training loss: 1.4221585988998413
Validation loss: 2.568205325834213

Epoch: 6| Step: 8
Training loss: 2.1250576972961426
Validation loss: 2.562601443259947

Epoch: 6| Step: 9
Training loss: 2.4531784057617188
Validation loss: 2.5534724420116794

Epoch: 6| Step: 10
Training loss: 2.851773262023926
Validation loss: 2.549814321661508

Epoch: 6| Step: 11
Training loss: 3.0329155921936035
Validation loss: 2.55058362150705

Epoch: 6| Step: 12
Training loss: 3.28729510307312
Validation loss: 2.5523390680231075

Epoch: 6| Step: 13
Training loss: 1.972013235092163
Validation loss: 2.5508795374183246

Epoch: 54| Step: 0
Training loss: 2.795978307723999
Validation loss: 2.548416106931625

Epoch: 6| Step: 1
Training loss: 3.095343589782715
Validation loss: 2.5506995416456655

Epoch: 6| Step: 2
Training loss: 2.0428874492645264
Validation loss: 2.551166034513904

Epoch: 6| Step: 3
Training loss: 3.444650650024414
Validation loss: 2.5495946791864212

Epoch: 6| Step: 4
Training loss: 2.3627500534057617
Validation loss: 2.5474502553222

Epoch: 6| Step: 5
Training loss: 2.7189643383026123
Validation loss: 2.54636525851424

Epoch: 6| Step: 6
Training loss: 3.5661303997039795
Validation loss: 2.547887420141569

Epoch: 6| Step: 7
Training loss: 3.229710340499878
Validation loss: 2.5441816596574682

Epoch: 6| Step: 8
Training loss: 2.821732521057129
Validation loss: 2.5455599984815045

Epoch: 6| Step: 9
Training loss: 2.2784619331359863
Validation loss: 2.5421082742752565

Epoch: 6| Step: 10
Training loss: 2.3039729595184326
Validation loss: 2.5417925593673543

Epoch: 6| Step: 11
Training loss: 2.561126708984375
Validation loss: 2.542281068781371

Epoch: 6| Step: 12
Training loss: 2.356494903564453
Validation loss: 2.545751393482249

Epoch: 6| Step: 13
Training loss: 2.6649365425109863
Validation loss: 2.543134581658148

Epoch: 55| Step: 0
Training loss: 2.4750404357910156
Validation loss: 2.5463209536767777

Epoch: 6| Step: 1
Training loss: 2.7234153747558594
Validation loss: 2.5484304402464177

Epoch: 6| Step: 2
Training loss: 2.086441993713379
Validation loss: 2.5488662181362027

Epoch: 6| Step: 3
Training loss: 2.8373641967773438
Validation loss: 2.5511249906273297

Epoch: 6| Step: 4
Training loss: 3.7434306144714355
Validation loss: 2.5497434087978896

Epoch: 6| Step: 5
Training loss: 3.017882823944092
Validation loss: 2.5510784323497484

Epoch: 6| Step: 6
Training loss: 3.2432761192321777
Validation loss: 2.5481576355554725

Epoch: 6| Step: 7
Training loss: 2.3886775970458984
Validation loss: 2.5546773838740524

Epoch: 6| Step: 8
Training loss: 2.388002395629883
Validation loss: 2.548070525610319

Epoch: 6| Step: 9
Training loss: 2.0135674476623535
Validation loss: 2.5526714735133673

Epoch: 6| Step: 10
Training loss: 2.9649674892425537
Validation loss: 2.550701064448203

Epoch: 6| Step: 11
Training loss: 2.8355743885040283
Validation loss: 2.544534408917991

Epoch: 6| Step: 12
Training loss: 2.9810943603515625
Validation loss: 2.5412968922686834

Epoch: 6| Step: 13
Training loss: 2.331883668899536
Validation loss: 2.5417053494402158

Epoch: 56| Step: 0
Training loss: 2.182452440261841
Validation loss: 2.543789453403924

Epoch: 6| Step: 1
Training loss: 3.0810675621032715
Validation loss: 2.5457413324745755

Epoch: 6| Step: 2
Training loss: 2.648343563079834
Validation loss: 2.542997988321448

Epoch: 6| Step: 3
Training loss: 2.743588447570801
Validation loss: 2.5458900338859967

Epoch: 6| Step: 4
Training loss: 3.0391697883605957
Validation loss: 2.54374760453419

Epoch: 6| Step: 5
Training loss: 2.80989408493042
Validation loss: 2.5448083749381443

Epoch: 6| Step: 6
Training loss: 2.0476410388946533
Validation loss: 2.5468286750137166

Epoch: 6| Step: 7
Training loss: 3.115730047225952
Validation loss: 2.5472803500390824

Epoch: 6| Step: 8
Training loss: 3.4359989166259766
Validation loss: 2.5428391015657814

Epoch: 6| Step: 9
Training loss: 3.500454902648926
Validation loss: 2.5439790346289195

Epoch: 6| Step: 10
Training loss: 1.5311256647109985
Validation loss: 2.5464866956075034

Epoch: 6| Step: 11
Training loss: 1.626537799835205
Validation loss: 2.5458962173872095

Epoch: 6| Step: 12
Training loss: 3.0663039684295654
Validation loss: 2.5458028213952177

Epoch: 6| Step: 13
Training loss: 3.818059206008911
Validation loss: 2.5428284291298158

Epoch: 57| Step: 0
Training loss: 2.249213218688965
Validation loss: 2.542150543582055

Epoch: 6| Step: 1
Training loss: 3.79632306098938
Validation loss: 2.541570278906053

Epoch: 6| Step: 2
Training loss: 2.2561378479003906
Validation loss: 2.5433570928471063

Epoch: 6| Step: 3
Training loss: 2.6871204376220703
Validation loss: 2.5428797455244165

Epoch: 6| Step: 4
Training loss: 3.0447726249694824
Validation loss: 2.543636478403563

Epoch: 6| Step: 5
Training loss: 2.2161169052124023
Validation loss: 2.5459015600142942

Epoch: 6| Step: 6
Training loss: 2.7366626262664795
Validation loss: 2.5454263110314646

Epoch: 6| Step: 7
Training loss: 2.821614980697632
Validation loss: 2.545260972874139

Epoch: 6| Step: 8
Training loss: 2.619595766067505
Validation loss: 2.546339455471244

Epoch: 6| Step: 9
Training loss: 2.6110196113586426
Validation loss: 2.5542271060328328

Epoch: 6| Step: 10
Training loss: 2.8181159496307373
Validation loss: 2.552411135806832

Epoch: 6| Step: 11
Training loss: 3.2852470874786377
Validation loss: 2.5484614090252946

Epoch: 6| Step: 12
Training loss: 2.4489407539367676
Validation loss: 2.5477605122391895

Epoch: 6| Step: 13
Training loss: 2.299574851989746
Validation loss: 2.540662083574521

Epoch: 58| Step: 0
Training loss: 2.890078544616699
Validation loss: 2.542079110299387

Epoch: 6| Step: 1
Training loss: 2.960937261581421
Validation loss: 2.53501937466283

Epoch: 6| Step: 2
Training loss: 2.1349730491638184
Validation loss: 2.542180061340332

Epoch: 6| Step: 3
Training loss: 2.1448421478271484
Validation loss: 2.550311557708248

Epoch: 6| Step: 4
Training loss: 3.541574478149414
Validation loss: 2.552259293935632

Epoch: 6| Step: 5
Training loss: 3.0788075923919678
Validation loss: 2.5518436508793987

Epoch: 6| Step: 6
Training loss: 1.7608777284622192
Validation loss: 2.549401398627989

Epoch: 6| Step: 7
Training loss: 3.2974843978881836
Validation loss: 2.54745037581331

Epoch: 6| Step: 8
Training loss: 2.7391834259033203
Validation loss: 2.5430792121477026

Epoch: 6| Step: 9
Training loss: 2.9278564453125
Validation loss: 2.538411742897444

Epoch: 6| Step: 10
Training loss: 2.7147598266601562
Validation loss: 2.529280401045276

Epoch: 6| Step: 11
Training loss: 2.761582851409912
Validation loss: 2.5211702418583695

Epoch: 6| Step: 12
Training loss: 2.404775619506836
Validation loss: 2.523634410673572

Epoch: 6| Step: 13
Training loss: 2.7003235816955566
Validation loss: 2.5257945945186

Epoch: 59| Step: 0
Training loss: 2.587493896484375
Validation loss: 2.525283962167719

Epoch: 6| Step: 1
Training loss: 2.9371070861816406
Validation loss: 2.5386020957782702

Epoch: 6| Step: 2
Training loss: 2.4833791255950928
Validation loss: 2.5294774527190835

Epoch: 6| Step: 3
Training loss: 2.7505300045013428
Validation loss: 2.527767865888534

Epoch: 6| Step: 4
Training loss: 2.462726593017578
Validation loss: 2.5283801914543234

Epoch: 6| Step: 5
Training loss: 2.2886672019958496
Validation loss: 2.5188953863677157

Epoch: 6| Step: 6
Training loss: 2.926671266555786
Validation loss: 2.5197075874574724

Epoch: 6| Step: 7
Training loss: 2.705240488052368
Validation loss: 2.516216967695503

Epoch: 6| Step: 8
Training loss: 3.1791434288024902
Validation loss: 2.5153886272061254

Epoch: 6| Step: 9
Training loss: 3.205219268798828
Validation loss: 2.5160455191007225

Epoch: 6| Step: 10
Training loss: 2.4704480171203613
Validation loss: 2.516191569707727

Epoch: 6| Step: 11
Training loss: 2.809102773666382
Validation loss: 2.516243383448611

Epoch: 6| Step: 12
Training loss: 2.615176200866699
Validation loss: 2.51626685614227

Epoch: 6| Step: 13
Training loss: 2.4978435039520264
Validation loss: 2.5163716193168395

Epoch: 60| Step: 0
Training loss: 2.5628299713134766
Validation loss: 2.5151277460077757

Epoch: 6| Step: 1
Training loss: 2.828508138656616
Validation loss: 2.518195721410936

Epoch: 6| Step: 2
Training loss: 1.4989216327667236
Validation loss: 2.513663876441217

Epoch: 6| Step: 3
Training loss: 3.080120801925659
Validation loss: 2.5137278982388076

Epoch: 6| Step: 4
Training loss: 2.8173270225524902
Validation loss: 2.514327364583169

Epoch: 6| Step: 5
Training loss: 2.712292194366455
Validation loss: 2.5080437865308536

Epoch: 6| Step: 6
Training loss: 1.6193724870681763
Validation loss: 2.511446314473306

Epoch: 6| Step: 7
Training loss: 2.9024875164031982
Validation loss: 2.511740158962947

Epoch: 6| Step: 8
Training loss: 3.0310378074645996
Validation loss: 2.5147750505837063

Epoch: 6| Step: 9
Training loss: 2.683838367462158
Validation loss: 2.5148493551438853

Epoch: 6| Step: 10
Training loss: 2.9078311920166016
Validation loss: 2.511914325016801

Epoch: 6| Step: 11
Training loss: 2.6070404052734375
Validation loss: 2.5146815648642917

Epoch: 6| Step: 12
Training loss: 3.5065102577209473
Validation loss: 2.513606858509843

Epoch: 6| Step: 13
Training loss: 3.492774486541748
Validation loss: 2.510588135770572

Epoch: 61| Step: 0
Training loss: 3.0551066398620605
Validation loss: 2.507544561098981

Epoch: 6| Step: 1
Training loss: 2.9406251907348633
Validation loss: 2.510572318107851

Epoch: 6| Step: 2
Training loss: 3.3207764625549316
Validation loss: 2.5137197817525556

Epoch: 6| Step: 3
Training loss: 2.5538432598114014
Validation loss: 2.5090231690355527

Epoch: 6| Step: 4
Training loss: 3.2545814514160156
Validation loss: 2.518500740810107

Epoch: 6| Step: 5
Training loss: 2.294253349304199
Validation loss: 2.523127273846698

Epoch: 6| Step: 6
Training loss: 2.070993185043335
Validation loss: 2.533025883859204

Epoch: 6| Step: 7
Training loss: 1.870302438735962
Validation loss: 2.532496590768137

Epoch: 6| Step: 8
Training loss: 2.2879223823547363
Validation loss: 2.5366388161977134

Epoch: 6| Step: 9
Training loss: 2.6570491790771484
Validation loss: 2.5276674609030447

Epoch: 6| Step: 10
Training loss: 2.231520175933838
Validation loss: 2.5350533480285318

Epoch: 6| Step: 11
Training loss: 3.349562168121338
Validation loss: 2.5372300404374317

Epoch: 6| Step: 12
Training loss: 2.8210842609405518
Validation loss: 2.5406879660903767

Epoch: 6| Step: 13
Training loss: 3.8319222927093506
Validation loss: 2.5393293083354993

Epoch: 62| Step: 0
Training loss: 2.577251434326172
Validation loss: 2.5440701566716677

Epoch: 6| Step: 1
Training loss: 2.216665506362915
Validation loss: 2.5398534984998804

Epoch: 6| Step: 2
Training loss: 2.9669101238250732
Validation loss: 2.538056540232833

Epoch: 6| Step: 3
Training loss: 2.599820375442505
Validation loss: 2.5407354575331493

Epoch: 6| Step: 4
Training loss: 3.290647506713867
Validation loss: 2.539131969533941

Epoch: 6| Step: 5
Training loss: 3.3072335720062256
Validation loss: 2.5377059162303968

Epoch: 6| Step: 6
Training loss: 3.2103748321533203
Validation loss: 2.5421601642844496

Epoch: 6| Step: 7
Training loss: 2.1925950050354004
Validation loss: 2.5395720287035872

Epoch: 6| Step: 8
Training loss: 2.1346821784973145
Validation loss: 2.5406561231100433

Epoch: 6| Step: 9
Training loss: 3.726471185684204
Validation loss: 2.5393481203304824

Epoch: 6| Step: 10
Training loss: 1.9718613624572754
Validation loss: 2.5367084164773264

Epoch: 6| Step: 11
Training loss: 3.2836594581604004
Validation loss: 2.5400093857960035

Epoch: 6| Step: 12
Training loss: 2.410022020339966
Validation loss: 2.5404842694600425

Epoch: 6| Step: 13
Training loss: 1.9960681200027466
Validation loss: 2.542036276991649

Epoch: 63| Step: 0
Training loss: 3.4256086349487305
Validation loss: 2.5428889554033995

Epoch: 6| Step: 1
Training loss: 2.377927541732788
Validation loss: 2.542998170339933

Epoch: 6| Step: 2
Training loss: 2.4995312690734863
Validation loss: 2.5431708494822183

Epoch: 6| Step: 3
Training loss: 2.606661081314087
Validation loss: 2.5471542573744252

Epoch: 6| Step: 4
Training loss: 2.5929036140441895
Validation loss: 2.5473259238786596

Epoch: 6| Step: 5
Training loss: 2.3839259147644043
Validation loss: 2.5472920581858647

Epoch: 6| Step: 6
Training loss: 2.6592257022857666
Validation loss: 2.5491518025757163

Epoch: 6| Step: 7
Training loss: 3.155183792114258
Validation loss: 2.5566385740874917

Epoch: 6| Step: 8
Training loss: 2.3116519451141357
Validation loss: 2.5544805911279496

Epoch: 6| Step: 9
Training loss: 3.9275693893432617
Validation loss: 2.551968882160802

Epoch: 6| Step: 10
Training loss: 2.49682354927063
Validation loss: 2.5476090574777253

Epoch: 6| Step: 11
Training loss: 1.8641899824142456
Validation loss: 2.5460845770374423

Epoch: 6| Step: 12
Training loss: 2.988767147064209
Validation loss: 2.5463898002460437

Epoch: 6| Step: 13
Training loss: 2.920578956604004
Validation loss: 2.5441532647737892

Epoch: 64| Step: 0
Training loss: 2.4036006927490234
Validation loss: 2.5416723451306744

Epoch: 6| Step: 1
Training loss: 3.164180278778076
Validation loss: 2.5376549895091722

Epoch: 6| Step: 2
Training loss: 2.1748857498168945
Validation loss: 2.5406669186007593

Epoch: 6| Step: 3
Training loss: 2.9902167320251465
Validation loss: 2.536196921461372

Epoch: 6| Step: 4
Training loss: 3.3044190406799316
Validation loss: 2.540779044551234

Epoch: 6| Step: 5
Training loss: 3.3170697689056396
Validation loss: 2.537985746578504

Epoch: 6| Step: 6
Training loss: 2.802769422531128
Validation loss: 2.535853511543684

Epoch: 6| Step: 7
Training loss: 2.3272955417633057
Validation loss: 2.5366675520455964

Epoch: 6| Step: 8
Training loss: 2.6963181495666504
Validation loss: 2.5359119625501734

Epoch: 6| Step: 9
Training loss: 2.5687875747680664
Validation loss: 2.5367107493903047

Epoch: 6| Step: 10
Training loss: 2.379612922668457
Validation loss: 2.5337657646466325

Epoch: 6| Step: 11
Training loss: 2.5635769367218018
Validation loss: 2.534774213708857

Epoch: 6| Step: 12
Training loss: 3.012108325958252
Validation loss: 2.5308495003690004

Epoch: 6| Step: 13
Training loss: 2.2087810039520264
Validation loss: 2.5270658744278776

Epoch: 65| Step: 0
Training loss: 2.903759479522705
Validation loss: 2.5164497180651595

Epoch: 6| Step: 1
Training loss: 2.4009530544281006
Validation loss: 2.5120335496881956

Epoch: 6| Step: 2
Training loss: 3.084564685821533
Validation loss: 2.512166800037507

Epoch: 6| Step: 3
Training loss: 3.028731346130371
Validation loss: 2.5128299779789423

Epoch: 6| Step: 4
Training loss: 2.6263351440429688
Validation loss: 2.511966695067703

Epoch: 6| Step: 5
Training loss: 2.1369314193725586
Validation loss: 2.5109574974224134

Epoch: 6| Step: 6
Training loss: 1.75545334815979
Validation loss: 2.508303749945856

Epoch: 6| Step: 7
Training loss: 3.059354305267334
Validation loss: 2.508917054822368

Epoch: 6| Step: 8
Training loss: 3.1638598442077637
Validation loss: 2.5037453866774038

Epoch: 6| Step: 9
Training loss: 2.6437952518463135
Validation loss: 2.5009566942850747

Epoch: 6| Step: 10
Training loss: 1.9970347881317139
Validation loss: 2.5001623707432903

Epoch: 6| Step: 11
Training loss: 2.860865354537964
Validation loss: 2.498742595795662

Epoch: 6| Step: 12
Training loss: 3.1289472579956055
Validation loss: 2.4945233816741617

Epoch: 6| Step: 13
Training loss: 3.225188732147217
Validation loss: 2.501151592500748

Epoch: 66| Step: 0
Training loss: 2.7030229568481445
Validation loss: 2.4982395787392893

Epoch: 6| Step: 1
Training loss: 2.784454584121704
Validation loss: 2.5002484219048613

Epoch: 6| Step: 2
Training loss: 2.6028199195861816
Validation loss: 2.4981090253399265

Epoch: 6| Step: 3
Training loss: 2.892397403717041
Validation loss: 2.5037535108545774

Epoch: 6| Step: 4
Training loss: 1.985006332397461
Validation loss: 2.5088642143434092

Epoch: 6| Step: 5
Training loss: 2.3293652534484863
Validation loss: 2.512861156976351

Epoch: 6| Step: 6
Training loss: 2.2176527976989746
Validation loss: 2.519503515253785

Epoch: 6| Step: 7
Training loss: 2.8702073097229004
Validation loss: 2.5139111857260428

Epoch: 6| Step: 8
Training loss: 3.116826057434082
Validation loss: 2.5156342162880847

Epoch: 6| Step: 9
Training loss: 3.011475086212158
Validation loss: 2.5370411539590485

Epoch: 6| Step: 10
Training loss: 3.0043692588806152
Validation loss: 2.5299222700057493

Epoch: 6| Step: 11
Training loss: 2.7291879653930664
Validation loss: 2.535617369477467

Epoch: 6| Step: 12
Training loss: 3.051011323928833
Validation loss: 2.5379472727416665

Epoch: 6| Step: 13
Training loss: 2.568089723587036
Validation loss: 2.534707392415693

Epoch: 67| Step: 0
Training loss: 2.741413116455078
Validation loss: 2.52564501249662

Epoch: 6| Step: 1
Training loss: 3.1418979167938232
Validation loss: 2.5248863158687467

Epoch: 6| Step: 2
Training loss: 3.256166934967041
Validation loss: 2.512177267382222

Epoch: 6| Step: 3
Training loss: 1.7795933485031128
Validation loss: 2.508947482673071

Epoch: 6| Step: 4
Training loss: 2.574247360229492
Validation loss: 2.50831703729527

Epoch: 6| Step: 5
Training loss: 2.7790026664733887
Validation loss: 2.50714587396191

Epoch: 6| Step: 6
Training loss: 2.8604116439819336
Validation loss: 2.509814654627154

Epoch: 6| Step: 7
Training loss: 3.018474578857422
Validation loss: 2.521499723516485

Epoch: 6| Step: 8
Training loss: 1.994126796722412
Validation loss: 2.518262734977148

Epoch: 6| Step: 9
Training loss: 3.190786123275757
Validation loss: 2.525773863638601

Epoch: 6| Step: 10
Training loss: 2.939342975616455
Validation loss: 2.5303048574796287

Epoch: 6| Step: 11
Training loss: 2.8697309494018555
Validation loss: 2.5203387070727605

Epoch: 6| Step: 12
Training loss: 2.3297877311706543
Validation loss: 2.5086811819384174

Epoch: 6| Step: 13
Training loss: 2.054379463195801
Validation loss: 2.503688407200639

Epoch: 68| Step: 0
Training loss: 2.9068479537963867
Validation loss: 2.4995849619629564

Epoch: 6| Step: 1
Training loss: 3.6229124069213867
Validation loss: 2.4970606168111167

Epoch: 6| Step: 2
Training loss: 2.7626733779907227
Validation loss: 2.4972884308907295

Epoch: 6| Step: 3
Training loss: 2.5335893630981445
Validation loss: 2.4916697573918167

Epoch: 6| Step: 4
Training loss: 2.4808502197265625
Validation loss: 2.497080433753229

Epoch: 6| Step: 5
Training loss: 2.7009692192077637
Validation loss: 2.504859491061139

Epoch: 6| Step: 6
Training loss: 2.1875109672546387
Validation loss: 2.514040941833168

Epoch: 6| Step: 7
Training loss: 2.485747814178467
Validation loss: 2.5067126392036356

Epoch: 6| Step: 8
Training loss: 2.3581933975219727
Validation loss: 2.509146785223356

Epoch: 6| Step: 9
Training loss: 2.485767126083374
Validation loss: 2.5016380561295377

Epoch: 6| Step: 10
Training loss: 3.231321096420288
Validation loss: 2.50373859559336

Epoch: 6| Step: 11
Training loss: 2.8254051208496094
Validation loss: 2.4968060883142615

Epoch: 6| Step: 12
Training loss: 2.550560712814331
Validation loss: 2.4910478027918006

Epoch: 6| Step: 13
Training loss: 2.509341239929199
Validation loss: 2.4984793739934124

Epoch: 69| Step: 0
Training loss: 2.187394142150879
Validation loss: 2.504573932258032

Epoch: 6| Step: 1
Training loss: 2.4634897708892822
Validation loss: 2.506432922937537

Epoch: 6| Step: 2
Training loss: 2.505120038986206
Validation loss: 2.5141942898432412

Epoch: 6| Step: 3
Training loss: 2.2197978496551514
Validation loss: 2.5445752605315177

Epoch: 6| Step: 4
Training loss: 3.4220569133758545
Validation loss: 2.5117730171449724

Epoch: 6| Step: 5
Training loss: 2.256774663925171
Validation loss: 2.512828570540233

Epoch: 6| Step: 6
Training loss: 2.9904258251190186
Validation loss: 2.494241024858208

Epoch: 6| Step: 7
Training loss: 3.5237205028533936
Validation loss: 2.488309644883679

Epoch: 6| Step: 8
Training loss: 3.3983707427978516
Validation loss: 2.49074754663693

Epoch: 6| Step: 9
Training loss: 2.7780961990356445
Validation loss: 2.485063822038712

Epoch: 6| Step: 10
Training loss: 2.515869379043579
Validation loss: 2.4830788514947377

Epoch: 6| Step: 11
Training loss: 2.3618147373199463
Validation loss: 2.483082225245814

Epoch: 6| Step: 12
Training loss: 2.1673073768615723
Validation loss: 2.4868254353923183

Epoch: 6| Step: 13
Training loss: 3.124150514602661
Validation loss: 2.485000280923741

Epoch: 70| Step: 0
Training loss: 3.3091769218444824
Validation loss: 2.4851513626754924

Epoch: 6| Step: 1
Training loss: 3.229715347290039
Validation loss: 2.484493919598159

Epoch: 6| Step: 2
Training loss: 2.3699429035186768
Validation loss: 2.4846532293545303

Epoch: 6| Step: 3
Training loss: 3.396892786026001
Validation loss: 2.4809678985226538

Epoch: 6| Step: 4
Training loss: 1.8498635292053223
Validation loss: 2.4832538353499545

Epoch: 6| Step: 5
Training loss: 3.030529499053955
Validation loss: 2.4829175933714835

Epoch: 6| Step: 6
Training loss: 3.207484245300293
Validation loss: 2.4911847012017363

Epoch: 6| Step: 7
Training loss: 2.3287394046783447
Validation loss: 2.496899620179207

Epoch: 6| Step: 8
Training loss: 2.3220973014831543
Validation loss: 2.5041934469694733

Epoch: 6| Step: 9
Training loss: 2.7383790016174316
Validation loss: 2.507702842835457

Epoch: 6| Step: 10
Training loss: 2.263392925262451
Validation loss: 2.512455553136846

Epoch: 6| Step: 11
Training loss: 2.415113687515259
Validation loss: 2.512242765836818

Epoch: 6| Step: 12
Training loss: 2.4021482467651367
Validation loss: 2.5068122186968402

Epoch: 6| Step: 13
Training loss: 3.0537335872650146
Validation loss: 2.504565377389231

Epoch: 71| Step: 0
Training loss: 2.3927299976348877
Validation loss: 2.5002655598425094

Epoch: 6| Step: 1
Training loss: 2.1854283809661865
Validation loss: 2.497222669662968

Epoch: 6| Step: 2
Training loss: 3.461432695388794
Validation loss: 2.500790342207878

Epoch: 6| Step: 3
Training loss: 2.9795103073120117
Validation loss: 2.4962465891274075

Epoch: 6| Step: 4
Training loss: 2.308962106704712
Validation loss: 2.494319869625953

Epoch: 6| Step: 5
Training loss: 3.114842414855957
Validation loss: 2.4915947862850722

Epoch: 6| Step: 6
Training loss: 2.5916342735290527
Validation loss: 2.488514395170314

Epoch: 6| Step: 7
Training loss: 2.4210057258605957
Validation loss: 2.4881250012305474

Epoch: 6| Step: 8
Training loss: 2.836601734161377
Validation loss: 2.4834745955723587

Epoch: 6| Step: 9
Training loss: 2.362748622894287
Validation loss: 2.483184337615967

Epoch: 6| Step: 10
Training loss: 2.779977321624756
Validation loss: 2.4850105957318376

Epoch: 6| Step: 11
Training loss: 2.6945242881774902
Validation loss: 2.482833395722092

Epoch: 6| Step: 12
Training loss: 2.793736219406128
Validation loss: 2.481027364730835

Epoch: 6| Step: 13
Training loss: 2.682225465774536
Validation loss: 2.4862362851378736

Epoch: 72| Step: 0
Training loss: 1.9942147731781006
Validation loss: 2.482455268982918

Epoch: 6| Step: 1
Training loss: 2.327241897583008
Validation loss: 2.4828944206237793

Epoch: 6| Step: 2
Training loss: 2.4908294677734375
Validation loss: 2.483725170935354

Epoch: 6| Step: 3
Training loss: 2.6891045570373535
Validation loss: 2.4850949036177767

Epoch: 6| Step: 4
Training loss: 2.758030891418457
Validation loss: 2.4856010790794127

Epoch: 6| Step: 5
Training loss: 2.874772310256958
Validation loss: 2.4846756278827624

Epoch: 6| Step: 6
Training loss: 3.699822187423706
Validation loss: 2.4888375523269817

Epoch: 6| Step: 7
Training loss: 2.3860301971435547
Validation loss: 2.4828306590357134

Epoch: 6| Step: 8
Training loss: 2.701382637023926
Validation loss: 2.4863076620204474

Epoch: 6| Step: 9
Training loss: 3.2129874229431152
Validation loss: 2.4830049340442946

Epoch: 6| Step: 10
Training loss: 2.1330838203430176
Validation loss: 2.4804698164745043

Epoch: 6| Step: 11
Training loss: 2.940502166748047
Validation loss: 2.4881458769562426

Epoch: 6| Step: 12
Training loss: 3.020810604095459
Validation loss: 2.494797078512048

Epoch: 6| Step: 13
Training loss: 2.2214765548706055
Validation loss: 2.50398777889949

Epoch: 73| Step: 0
Training loss: 2.7107059955596924
Validation loss: 2.493319421686152

Epoch: 6| Step: 1
Training loss: 2.830004930496216
Validation loss: 2.4946394415311914

Epoch: 6| Step: 2
Training loss: 2.953533887863159
Validation loss: 2.4835407093007076

Epoch: 6| Step: 3
Training loss: 2.4431912899017334
Validation loss: 2.473875314958634

Epoch: 6| Step: 4
Training loss: 2.4827499389648438
Validation loss: 2.4823135714377127

Epoch: 6| Step: 5
Training loss: 2.9865188598632812
Validation loss: 2.4797252044882825

Epoch: 6| Step: 6
Training loss: 2.5855400562286377
Validation loss: 2.4761980528472574

Epoch: 6| Step: 7
Training loss: 2.202996015548706
Validation loss: 2.4761022495967087

Epoch: 6| Step: 8
Training loss: 2.8617329597473145
Validation loss: 2.4759086306377123

Epoch: 6| Step: 9
Training loss: 2.4346065521240234
Validation loss: 2.4751545434357016

Epoch: 6| Step: 10
Training loss: 2.271454334259033
Validation loss: 2.4731672169059835

Epoch: 6| Step: 11
Training loss: 3.0894250869750977
Validation loss: 2.471216858074229

Epoch: 6| Step: 12
Training loss: 3.1009349822998047
Validation loss: 2.480787515640259

Epoch: 6| Step: 13
Training loss: 2.674727201461792
Validation loss: 2.4804999956520657

Epoch: 74| Step: 0
Training loss: 2.717895030975342
Validation loss: 2.488220025134343

Epoch: 6| Step: 1
Training loss: 2.961411714553833
Validation loss: 2.49638319271867

Epoch: 6| Step: 2
Training loss: 2.6885671615600586
Validation loss: 2.49792024653445

Epoch: 6| Step: 3
Training loss: 2.8379337787628174
Validation loss: 2.499415737326427

Epoch: 6| Step: 4
Training loss: 2.348475217819214
Validation loss: 2.5009037089604202

Epoch: 6| Step: 5
Training loss: 2.635061264038086
Validation loss: 2.5028771303033315

Epoch: 6| Step: 6
Training loss: 2.1545708179473877
Validation loss: 2.5091354154771373

Epoch: 6| Step: 7
Training loss: 2.5950958728790283
Validation loss: 2.512107080028903

Epoch: 6| Step: 8
Training loss: 3.0576510429382324
Validation loss: 2.5181011666533766

Epoch: 6| Step: 9
Training loss: 2.6629064083099365
Validation loss: 2.5006108130178144

Epoch: 6| Step: 10
Training loss: 3.132875442504883
Validation loss: 2.5010200315906155

Epoch: 6| Step: 11
Training loss: 3.0296108722686768
Validation loss: 2.496965459598008

Epoch: 6| Step: 12
Training loss: 1.998402714729309
Validation loss: 2.4886686622455554

Epoch: 6| Step: 13
Training loss: 2.8400511741638184
Validation loss: 2.4845865644434446

Epoch: 75| Step: 0
Training loss: 2.9453210830688477
Validation loss: 2.4819861868376374

Epoch: 6| Step: 1
Training loss: 2.4031710624694824
Validation loss: 2.4866725219193326

Epoch: 6| Step: 2
Training loss: 2.73675274848938
Validation loss: 2.477461907171434

Epoch: 6| Step: 3
Training loss: 2.7038049697875977
Validation loss: 2.4837949609243744

Epoch: 6| Step: 4
Training loss: 2.463742256164551
Validation loss: 2.484249007317328

Epoch: 6| Step: 5
Training loss: 2.8010330200195312
Validation loss: 2.487613308814264

Epoch: 6| Step: 6
Training loss: 2.7388150691986084
Validation loss: 2.4859174169519895

Epoch: 6| Step: 7
Training loss: 3.1858582496643066
Validation loss: 2.493505306141351

Epoch: 6| Step: 8
Training loss: 1.0605783462524414
Validation loss: 2.4862144352287374

Epoch: 6| Step: 9
Training loss: 2.70987606048584
Validation loss: 2.494685023061691

Epoch: 6| Step: 10
Training loss: 3.1697816848754883
Validation loss: 2.493956627384309

Epoch: 6| Step: 11
Training loss: 2.3821370601654053
Validation loss: 2.5002999331361506

Epoch: 6| Step: 12
Training loss: 3.053973913192749
Validation loss: 2.5012693405151367

Epoch: 6| Step: 13
Training loss: 3.6036741733551025
Validation loss: 2.5040180119135047

Epoch: 76| Step: 0
Training loss: 2.4258971214294434
Validation loss: 2.496746637487924

Epoch: 6| Step: 1
Training loss: 2.386392831802368
Validation loss: 2.4970286866670013

Epoch: 6| Step: 2
Training loss: 2.950986385345459
Validation loss: 2.492345658681726

Epoch: 6| Step: 3
Training loss: 2.5338850021362305
Validation loss: 2.4907658100128174

Epoch: 6| Step: 4
Training loss: 2.4030141830444336
Validation loss: 2.496102476632723

Epoch: 6| Step: 5
Training loss: 3.279559373855591
Validation loss: 2.4901347519249044

Epoch: 6| Step: 6
Training loss: 2.9366447925567627
Validation loss: 2.488970459148448

Epoch: 6| Step: 7
Training loss: 2.9810988903045654
Validation loss: 2.4825671590784544

Epoch: 6| Step: 8
Training loss: 2.33443021774292
Validation loss: 2.4895849202268865

Epoch: 6| Step: 9
Training loss: 2.1839401721954346
Validation loss: 2.488711598098919

Epoch: 6| Step: 10
Training loss: 2.5706984996795654
Validation loss: 2.48892621327472

Epoch: 6| Step: 11
Training loss: 2.8722951412200928
Validation loss: 2.487085514171149

Epoch: 6| Step: 12
Training loss: 3.235358238220215
Validation loss: 2.4910664173864547

Epoch: 6| Step: 13
Training loss: 2.1444318294525146
Validation loss: 2.4952510864503923

Epoch: 77| Step: 0
Training loss: 2.9771981239318848
Validation loss: 2.494198799133301

Epoch: 6| Step: 1
Training loss: 1.966975450515747
Validation loss: 2.4925122030319704

Epoch: 6| Step: 2
Training loss: 2.0596673488616943
Validation loss: 2.494953634918377

Epoch: 6| Step: 3
Training loss: 3.084622859954834
Validation loss: 2.4992065942415627

Epoch: 6| Step: 4
Training loss: 3.626246929168701
Validation loss: 2.5087942000358336

Epoch: 6| Step: 5
Training loss: 2.8172430992126465
Validation loss: 2.509158706152311

Epoch: 6| Step: 6
Training loss: 2.8149688243865967
Validation loss: 2.511705977942354

Epoch: 6| Step: 7
Training loss: 2.625331401824951
Validation loss: 2.4998433871935775

Epoch: 6| Step: 8
Training loss: 2.830585479736328
Validation loss: 2.4993942655542845

Epoch: 6| Step: 9
Training loss: 2.581775665283203
Validation loss: 2.4970308990888697

Epoch: 6| Step: 10
Training loss: 3.1856460571289062
Validation loss: 2.4881742410762335

Epoch: 6| Step: 11
Training loss: 2.2462010383605957
Validation loss: 2.491353424646521

Epoch: 6| Step: 12
Training loss: 2.1743054389953613
Validation loss: 2.4822208086649575

Epoch: 6| Step: 13
Training loss: 2.3113253116607666
Validation loss: 2.4838338308436896

Epoch: 78| Step: 0
Training loss: 2.9702839851379395
Validation loss: 2.478011818342311

Epoch: 6| Step: 1
Training loss: 2.6482276916503906
Validation loss: 2.4779732099143406

Epoch: 6| Step: 2
Training loss: 2.2630019187927246
Validation loss: 2.470044159120129

Epoch: 6| Step: 3
Training loss: 3.1219568252563477
Validation loss: 2.4787983945620957

Epoch: 6| Step: 4
Training loss: 2.3949577808380127
Validation loss: 2.475832975038918

Epoch: 6| Step: 5
Training loss: 2.727261781692505
Validation loss: 2.4768185154084237

Epoch: 6| Step: 6
Training loss: 2.520923614501953
Validation loss: 2.478515858291298

Epoch: 6| Step: 7
Training loss: 2.2505366802215576
Validation loss: 2.4806306951789447

Epoch: 6| Step: 8
Training loss: 2.1164205074310303
Validation loss: 2.4827795874687935

Epoch: 6| Step: 9
Training loss: 2.832365036010742
Validation loss: 2.482862710952759

Epoch: 6| Step: 10
Training loss: 2.679065227508545
Validation loss: 2.483255567089204

Epoch: 6| Step: 11
Training loss: 3.4052562713623047
Validation loss: 2.4841085275014243

Epoch: 6| Step: 12
Training loss: 3.439877986907959
Validation loss: 2.475196171832341

Epoch: 6| Step: 13
Training loss: 1.8774893283843994
Validation loss: 2.480177471714635

Epoch: 79| Step: 0
Training loss: 3.238572120666504
Validation loss: 2.4768342920528945

Epoch: 6| Step: 1
Training loss: 3.0538485050201416
Validation loss: 2.476686300769929

Epoch: 6| Step: 2
Training loss: 2.3929591178894043
Validation loss: 2.476441062906737

Epoch: 6| Step: 3
Training loss: 2.88326358795166
Validation loss: 2.4780639397200717

Epoch: 6| Step: 4
Training loss: 2.4358010292053223
Validation loss: 2.4831621262335006

Epoch: 6| Step: 5
Training loss: 2.629777193069458
Validation loss: 2.4872605851901475

Epoch: 6| Step: 6
Training loss: 2.4491147994995117
Validation loss: 2.4838519070738103

Epoch: 6| Step: 7
Training loss: 2.7647695541381836
Validation loss: 2.4905286476176274

Epoch: 6| Step: 8
Training loss: 3.3419370651245117
Validation loss: 2.4888676571589645

Epoch: 6| Step: 9
Training loss: 2.308457374572754
Validation loss: 2.4911415371843564

Epoch: 6| Step: 10
Training loss: 2.4679009914398193
Validation loss: 2.483071470773348

Epoch: 6| Step: 11
Training loss: 1.9541168212890625
Validation loss: 2.482010251732283

Epoch: 6| Step: 12
Training loss: 3.217258930206299
Validation loss: 2.490355671093028

Epoch: 6| Step: 13
Training loss: 2.21217679977417
Validation loss: 2.4775942064100698

Epoch: 80| Step: 0
Training loss: 2.8672399520874023
Validation loss: 2.487895670757499

Epoch: 6| Step: 1
Training loss: 2.6671504974365234
Validation loss: 2.4892241493348153

Epoch: 6| Step: 2
Training loss: 2.866976261138916
Validation loss: 2.486832859695599

Epoch: 6| Step: 3
Training loss: 3.2025413513183594
Validation loss: 2.5010302656440326

Epoch: 6| Step: 4
Training loss: 2.4968652725219727
Validation loss: 2.5031337994401173

Epoch: 6| Step: 5
Training loss: 1.8060485124588013
Validation loss: 2.4909793561504734

Epoch: 6| Step: 6
Training loss: 2.0259156227111816
Validation loss: 2.4868980992224907

Epoch: 6| Step: 7
Training loss: 3.4208688735961914
Validation loss: 2.4920249216018187

Epoch: 6| Step: 8
Training loss: 2.5607194900512695
Validation loss: 2.487775625721101

Epoch: 6| Step: 9
Training loss: 3.4173312187194824
Validation loss: 2.485129435857137

Epoch: 6| Step: 10
Training loss: 2.6578803062438965
Validation loss: 2.4803798506336827

Epoch: 6| Step: 11
Training loss: 2.7453958988189697
Validation loss: 2.4820022993190314

Epoch: 6| Step: 12
Training loss: 2.4665489196777344
Validation loss: 2.480020753798946

Epoch: 6| Step: 13
Training loss: 2.0198302268981934
Validation loss: 2.4758697914820846

Epoch: 81| Step: 0
Training loss: 1.592741847038269
Validation loss: 2.4818673672214633

Epoch: 6| Step: 1
Training loss: 2.4236981868743896
Validation loss: 2.483096391923966

Epoch: 6| Step: 2
Training loss: 3.1998610496520996
Validation loss: 2.479526771012173

Epoch: 6| Step: 3
Training loss: 3.0362794399261475
Validation loss: 2.4784011443456015

Epoch: 6| Step: 4
Training loss: 2.231191635131836
Validation loss: 2.4778543749163227

Epoch: 6| Step: 5
Training loss: 3.2357676029205322
Validation loss: 2.4734425211465485

Epoch: 6| Step: 6
Training loss: 1.8562055826187134
Validation loss: 2.4752114742032942

Epoch: 6| Step: 7
Training loss: 3.2804341316223145
Validation loss: 2.4739720385561705

Epoch: 6| Step: 8
Training loss: 2.044976234436035
Validation loss: 2.476018092965567

Epoch: 6| Step: 9
Training loss: 3.181427001953125
Validation loss: 2.481054195793726

Epoch: 6| Step: 10
Training loss: 3.2632012367248535
Validation loss: 2.488010134748233

Epoch: 6| Step: 11
Training loss: 2.872267246246338
Validation loss: 2.501407656618344

Epoch: 6| Step: 12
Training loss: 2.2959418296813965
Validation loss: 2.4916436031300533

Epoch: 6| Step: 13
Training loss: 3.1988630294799805
Validation loss: 2.507022650011124

Epoch: 82| Step: 0
Training loss: 2.131824016571045
Validation loss: 2.5065447130510883

Epoch: 6| Step: 1
Training loss: 2.8943934440612793
Validation loss: 2.500011387691703

Epoch: 6| Step: 2
Training loss: 3.2809925079345703
Validation loss: 2.5048053649164017

Epoch: 6| Step: 3
Training loss: 3.793574094772339
Validation loss: 2.496916445352698

Epoch: 6| Step: 4
Training loss: 2.1554455757141113
Validation loss: 2.4935411432737946

Epoch: 6| Step: 5
Training loss: 2.873103380203247
Validation loss: 2.486065944035848

Epoch: 6| Step: 6
Training loss: 2.6025843620300293
Validation loss: 2.4836622335577525

Epoch: 6| Step: 7
Training loss: 2.5720326900482178
Validation loss: 2.479790528615316

Epoch: 6| Step: 8
Training loss: 3.38553524017334
Validation loss: 2.4791812255818355

Epoch: 6| Step: 9
Training loss: 2.902981996536255
Validation loss: 2.4760413118588027

Epoch: 6| Step: 10
Training loss: 1.9209825992584229
Validation loss: 2.478197115723805

Epoch: 6| Step: 11
Training loss: 2.798624277114868
Validation loss: 2.480676797128493

Epoch: 6| Step: 12
Training loss: 2.5776491165161133
Validation loss: 2.4757386151180474

Epoch: 6| Step: 13
Training loss: 0.5801886320114136
Validation loss: 2.479494478112908

Epoch: 83| Step: 0
Training loss: 2.3395440578460693
Validation loss: 2.482268807708576

Epoch: 6| Step: 1
Training loss: 3.235201835632324
Validation loss: 2.478713548311623

Epoch: 6| Step: 2
Training loss: 2.5053391456604004
Validation loss: 2.4786878196142053

Epoch: 6| Step: 3
Training loss: 2.17600417137146
Validation loss: 2.481845271202826

Epoch: 6| Step: 4
Training loss: 2.19755220413208
Validation loss: 2.477377624921901

Epoch: 6| Step: 5
Training loss: 3.1640849113464355
Validation loss: 2.4839916613794144

Epoch: 6| Step: 6
Training loss: 2.5832316875457764
Validation loss: 2.483000070818009

Epoch: 6| Step: 7
Training loss: 1.9955787658691406
Validation loss: 2.4845708980355212

Epoch: 6| Step: 8
Training loss: 2.5241289138793945
Validation loss: 2.487653696408836

Epoch: 6| Step: 9
Training loss: 3.62776780128479
Validation loss: 2.4882287517670663

Epoch: 6| Step: 10
Training loss: 3.0652222633361816
Validation loss: 2.484275069288028

Epoch: 6| Step: 11
Training loss: 2.605184555053711
Validation loss: 2.488215192671745

Epoch: 6| Step: 12
Training loss: 2.1652190685272217
Validation loss: 2.488318794517107

Epoch: 6| Step: 13
Training loss: 3.533754587173462
Validation loss: 2.4934867876832203

Epoch: 84| Step: 0
Training loss: 2.5982539653778076
Validation loss: 2.4864673845229612

Epoch: 6| Step: 1
Training loss: 2.4828104972839355
Validation loss: 2.4839863623342207

Epoch: 6| Step: 2
Training loss: 1.9051578044891357
Validation loss: 2.4767019594869306

Epoch: 6| Step: 3
Training loss: 2.875337600708008
Validation loss: 2.469591002310476

Epoch: 6| Step: 4
Training loss: 3.6947858333587646
Validation loss: 2.4755246703342726

Epoch: 6| Step: 5
Training loss: 2.9618730545043945
Validation loss: 2.470415066647273

Epoch: 6| Step: 6
Training loss: 2.7670631408691406
Validation loss: 2.467655743322065

Epoch: 6| Step: 7
Training loss: 2.4371891021728516
Validation loss: 2.46964172650409

Epoch: 6| Step: 8
Training loss: 2.3138785362243652
Validation loss: 2.4665213220862934

Epoch: 6| Step: 9
Training loss: 2.773200511932373
Validation loss: 2.46773442914409

Epoch: 6| Step: 10
Training loss: 2.3078079223632812
Validation loss: 2.467808905468192

Epoch: 6| Step: 11
Training loss: 2.452124834060669
Validation loss: 2.467520941970169

Epoch: 6| Step: 12
Training loss: 2.7084736824035645
Validation loss: 2.4725366664189163

Epoch: 6| Step: 13
Training loss: 3.4089791774749756
Validation loss: 2.486568053563436

Epoch: 85| Step: 0
Training loss: 2.723750591278076
Validation loss: 2.490051015730827

Epoch: 6| Step: 1
Training loss: 2.9656307697296143
Validation loss: 2.4946710550656883

Epoch: 6| Step: 2
Training loss: 2.1572790145874023
Validation loss: 2.4997032252691125

Epoch: 6| Step: 3
Training loss: 2.3498926162719727
Validation loss: 2.504446365500009

Epoch: 6| Step: 4
Training loss: 2.181429147720337
Validation loss: 2.502971626097156

Epoch: 6| Step: 5
Training loss: 2.823418617248535
Validation loss: 2.5134133741419804

Epoch: 6| Step: 6
Training loss: 2.786987781524658
Validation loss: 2.5050486108308196

Epoch: 6| Step: 7
Training loss: 2.102786064147949
Validation loss: 2.498162784884053

Epoch: 6| Step: 8
Training loss: 2.796112060546875
Validation loss: 2.4976354234962055

Epoch: 6| Step: 9
Training loss: 2.488292694091797
Validation loss: 2.49108116216557

Epoch: 6| Step: 10
Training loss: 3.2528328895568848
Validation loss: 2.478464008659445

Epoch: 6| Step: 11
Training loss: 2.8653335571289062
Validation loss: 2.4790999633009716

Epoch: 6| Step: 12
Training loss: 3.1376466751098633
Validation loss: 2.475126681789275

Epoch: 6| Step: 13
Training loss: 2.7135419845581055
Validation loss: 2.4687929153442383

Epoch: 86| Step: 0
Training loss: 2.926377773284912
Validation loss: 2.4730796249963904

Epoch: 6| Step: 1
Training loss: 3.1694507598876953
Validation loss: 2.4689031467642835

Epoch: 6| Step: 2
Training loss: 3.8451383113861084
Validation loss: 2.4636993767112814

Epoch: 6| Step: 3
Training loss: 2.3859007358551025
Validation loss: 2.463511000397385

Epoch: 6| Step: 4
Training loss: 1.7779700756072998
Validation loss: 2.4612100290995773

Epoch: 6| Step: 5
Training loss: 2.485952377319336
Validation loss: 2.4615394710212626

Epoch: 6| Step: 6
Training loss: 1.7243990898132324
Validation loss: 2.4583435314957813

Epoch: 6| Step: 7
Training loss: 2.4088478088378906
Validation loss: 2.460613137932234

Epoch: 6| Step: 8
Training loss: 3.1744749546051025
Validation loss: 2.4687680377755115

Epoch: 6| Step: 9
Training loss: 2.23210072517395
Validation loss: 2.4748492010178103

Epoch: 6| Step: 10
Training loss: 2.967672348022461
Validation loss: 2.4812491581004155

Epoch: 6| Step: 11
Training loss: 2.6894025802612305
Validation loss: 2.4866912082959245

Epoch: 6| Step: 12
Training loss: 2.8621039390563965
Validation loss: 2.481238095991073

Epoch: 6| Step: 13
Training loss: 2.991563558578491
Validation loss: 2.4987511506644626

Epoch: 87| Step: 0
Training loss: 2.4614086151123047
Validation loss: 2.508719362238402

Epoch: 6| Step: 1
Training loss: 3.7899160385131836
Validation loss: 2.5208470001015613

Epoch: 6| Step: 2
Training loss: 2.826509714126587
Validation loss: 2.504909352589679

Epoch: 6| Step: 3
Training loss: 2.8905887603759766
Validation loss: 2.5129196002919185

Epoch: 6| Step: 4
Training loss: 2.522235870361328
Validation loss: 2.5028593001827115

Epoch: 6| Step: 5
Training loss: 2.4974842071533203
Validation loss: 2.505701388082197

Epoch: 6| Step: 6
Training loss: 3.0533766746520996
Validation loss: 2.4881803835591962

Epoch: 6| Step: 7
Training loss: 2.3714723587036133
Validation loss: 2.475319826474754

Epoch: 6| Step: 8
Training loss: 3.333671808242798
Validation loss: 2.4638098080952964

Epoch: 6| Step: 9
Training loss: 2.0563130378723145
Validation loss: 2.4578694835785897

Epoch: 6| Step: 10
Training loss: 2.848315715789795
Validation loss: 2.4578652958716116

Epoch: 6| Step: 11
Training loss: 2.402583599090576
Validation loss: 2.4689928690592446

Epoch: 6| Step: 12
Training loss: 2.229384183883667
Validation loss: 2.4679834765772664

Epoch: 6| Step: 13
Training loss: 2.0202298164367676
Validation loss: 2.4771392883793

Epoch: 88| Step: 0
Training loss: 3.1992344856262207
Validation loss: 2.466250733662677

Epoch: 6| Step: 1
Training loss: 2.6539418697357178
Validation loss: 2.461085693810576

Epoch: 6| Step: 2
Training loss: 2.6268436908721924
Validation loss: 2.4562498369524555

Epoch: 6| Step: 3
Training loss: 3.054964065551758
Validation loss: 2.4531760215759277

Epoch: 6| Step: 4
Training loss: 2.7332797050476074
Validation loss: 2.453597443078154

Epoch: 6| Step: 5
Training loss: 2.414094924926758
Validation loss: 2.4568115665066625

Epoch: 6| Step: 6
Training loss: 2.828617572784424
Validation loss: 2.4611562554554274

Epoch: 6| Step: 7
Training loss: 3.097916603088379
Validation loss: 2.4670261670184392

Epoch: 6| Step: 8
Training loss: 2.509129762649536
Validation loss: 2.4902644823956233

Epoch: 6| Step: 9
Training loss: 2.4787795543670654
Validation loss: 2.5097337025468067

Epoch: 6| Step: 10
Training loss: 2.408261775970459
Validation loss: 2.533128753785164

Epoch: 6| Step: 11
Training loss: 3.0615956783294678
Validation loss: 2.5347111635310675

Epoch: 6| Step: 12
Training loss: 2.452669858932495
Validation loss: 2.5092633667812554

Epoch: 6| Step: 13
Training loss: 1.5868010520935059
Validation loss: 2.4759883726796796

Epoch: 89| Step: 0
Training loss: 3.032519817352295
Validation loss: 2.4622995417605162

Epoch: 6| Step: 1
Training loss: 2.639237880706787
Validation loss: 2.455024439801452

Epoch: 6| Step: 2
Training loss: 2.5159752368927
Validation loss: 2.4518645681360716

Epoch: 6| Step: 3
Training loss: 2.735266923904419
Validation loss: 2.450723671144055

Epoch: 6| Step: 4
Training loss: 2.536595344543457
Validation loss: 2.451967062488679

Epoch: 6| Step: 5
Training loss: 2.3457727432250977
Validation loss: 2.4566139687774

Epoch: 6| Step: 6
Training loss: 2.4992904663085938
Validation loss: 2.4643465934261197

Epoch: 6| Step: 7
Training loss: 3.7432680130004883
Validation loss: 2.4648341645476637

Epoch: 6| Step: 8
Training loss: 2.373208522796631
Validation loss: 2.4558565821698917

Epoch: 6| Step: 9
Training loss: 1.5692722797393799
Validation loss: 2.4639795057235228

Epoch: 6| Step: 10
Training loss: 2.294832706451416
Validation loss: 2.466665626854025

Epoch: 6| Step: 11
Training loss: 3.298853874206543
Validation loss: 2.4606314474536526

Epoch: 6| Step: 12
Training loss: 2.904897689819336
Validation loss: 2.4554695185794624

Epoch: 6| Step: 13
Training loss: 2.963174343109131
Validation loss: 2.4548177411479335

Epoch: 90| Step: 0
Training loss: 2.4705162048339844
Validation loss: 2.453628586184594

Epoch: 6| Step: 1
Training loss: 2.677804946899414
Validation loss: 2.4564710714483775

Epoch: 6| Step: 2
Training loss: 3.6077661514282227
Validation loss: 2.461707094664215

Epoch: 6| Step: 3
Training loss: 1.4423691034317017
Validation loss: 2.4649221897125244

Epoch: 6| Step: 4
Training loss: 2.293818473815918
Validation loss: 2.471242671371788

Epoch: 6| Step: 5
Training loss: 2.832685708999634
Validation loss: 2.4691125295495473

Epoch: 6| Step: 6
Training loss: 2.379350423812866
Validation loss: 2.4770040922267462

Epoch: 6| Step: 7
Training loss: 2.460598945617676
Validation loss: 2.48935503344382

Epoch: 6| Step: 8
Training loss: 2.6363344192504883
Validation loss: 2.4893130974103044

Epoch: 6| Step: 9
Training loss: 2.0981101989746094
Validation loss: 2.498912170369138

Epoch: 6| Step: 10
Training loss: 3.667602062225342
Validation loss: 2.498748540878296

Epoch: 6| Step: 11
Training loss: 2.9686827659606934
Validation loss: 2.4946471593713246

Epoch: 6| Step: 12
Training loss: 2.6327311992645264
Validation loss: 2.490219695593721

Epoch: 6| Step: 13
Training loss: 3.5112295150756836
Validation loss: 2.4703116186203493

Epoch: 91| Step: 0
Training loss: 2.8781566619873047
Validation loss: 2.4668567334451983

Epoch: 6| Step: 1
Training loss: 2.467866897583008
Validation loss: 2.456874350065826

Epoch: 6| Step: 2
Training loss: 2.8106160163879395
Validation loss: 2.4605321704700427

Epoch: 6| Step: 3
Training loss: 2.720003128051758
Validation loss: 2.464708787138744

Epoch: 6| Step: 4
Training loss: 2.57541823387146
Validation loss: 2.4654762270630046

Epoch: 6| Step: 5
Training loss: 2.723109722137451
Validation loss: 2.4630619941219205

Epoch: 6| Step: 6
Training loss: 2.8260765075683594
Validation loss: 2.468241765934934

Epoch: 6| Step: 7
Training loss: 2.469451665878296
Validation loss: 2.462147799871301

Epoch: 6| Step: 8
Training loss: 1.8068596124649048
Validation loss: 2.4657544269356677

Epoch: 6| Step: 9
Training loss: 2.3343982696533203
Validation loss: 2.458931323020689

Epoch: 6| Step: 10
Training loss: 2.2689294815063477
Validation loss: 2.466224672973797

Epoch: 6| Step: 11
Training loss: 3.4745283126831055
Validation loss: 2.465758054487167

Epoch: 6| Step: 12
Training loss: 3.279728412628174
Validation loss: 2.4665299666825162

Epoch: 6| Step: 13
Training loss: 2.4405908584594727
Validation loss: 2.4687554079999208

Epoch: 92| Step: 0
Training loss: 2.929063320159912
Validation loss: 2.4731771484498055

Epoch: 6| Step: 1
Training loss: 2.493417263031006
Validation loss: 2.471952058935678

Epoch: 6| Step: 2
Training loss: 2.853036403656006
Validation loss: 2.471305178057763

Epoch: 6| Step: 3
Training loss: 3.1705892086029053
Validation loss: 2.471206380474952

Epoch: 6| Step: 4
Training loss: 3.0307652950286865
Validation loss: 2.4779268003279165

Epoch: 6| Step: 5
Training loss: 2.6597397327423096
Validation loss: 2.459095608803534

Epoch: 6| Step: 6
Training loss: 2.899693012237549
Validation loss: 2.457254330317179

Epoch: 6| Step: 7
Training loss: 2.394986391067505
Validation loss: 2.454972638878771

Epoch: 6| Step: 8
Training loss: 2.5125203132629395
Validation loss: 2.45098889002236

Epoch: 6| Step: 9
Training loss: 2.6644740104675293
Validation loss: 2.45660017254532

Epoch: 6| Step: 10
Training loss: 2.3652915954589844
Validation loss: 2.4526656340527278

Epoch: 6| Step: 11
Training loss: 2.5392889976501465
Validation loss: 2.4538742034666

Epoch: 6| Step: 12
Training loss: 2.3257932662963867
Validation loss: 2.461756108909525

Epoch: 6| Step: 13
Training loss: 2.191290855407715
Validation loss: 2.4665248688831123

Epoch: 93| Step: 0
Training loss: 2.3659706115722656
Validation loss: 2.4636731583585023

Epoch: 6| Step: 1
Training loss: 2.7373552322387695
Validation loss: 2.46384584775535

Epoch: 6| Step: 2
Training loss: 2.8493499755859375
Validation loss: 2.467135783164732

Epoch: 6| Step: 3
Training loss: 2.743889808654785
Validation loss: 2.4586654247776156

Epoch: 6| Step: 4
Training loss: 2.320138454437256
Validation loss: 2.460812909628755

Epoch: 6| Step: 5
Training loss: 2.267425537109375
Validation loss: 2.4660159567350983

Epoch: 6| Step: 6
Training loss: 3.166074275970459
Validation loss: 2.460993597584386

Epoch: 6| Step: 7
Training loss: 2.649934768676758
Validation loss: 2.462007535401211

Epoch: 6| Step: 8
Training loss: 2.396728515625
Validation loss: 2.4652953429888655

Epoch: 6| Step: 9
Training loss: 3.0752551555633545
Validation loss: 2.469808404163648

Epoch: 6| Step: 10
Training loss: 3.1865508556365967
Validation loss: 2.4625470958730227

Epoch: 6| Step: 11
Training loss: 2.066009044647217
Validation loss: 2.4590267468524236

Epoch: 6| Step: 12
Training loss: 2.7456419467926025
Validation loss: 2.4553638581306703

Epoch: 6| Step: 13
Training loss: 2.815380334854126
Validation loss: 2.4563331962913595

Epoch: 94| Step: 0
Training loss: 3.5139663219451904
Validation loss: 2.4493816873078704

Epoch: 6| Step: 1
Training loss: 2.0910558700561523
Validation loss: 2.4534489775216706

Epoch: 6| Step: 2
Training loss: 3.201188087463379
Validation loss: 2.4517535676238356

Epoch: 6| Step: 3
Training loss: 2.236689329147339
Validation loss: 2.455324629301666

Epoch: 6| Step: 4
Training loss: 2.394061326980591
Validation loss: 2.4599939084822133

Epoch: 6| Step: 5
Training loss: 3.5803372859954834
Validation loss: 2.460957573306176

Epoch: 6| Step: 6
Training loss: 2.851409435272217
Validation loss: 2.456957019785399

Epoch: 6| Step: 7
Training loss: 2.347622871398926
Validation loss: 2.464304231828259

Epoch: 6| Step: 8
Training loss: 3.473926305770874
Validation loss: 2.469480832417806

Epoch: 6| Step: 9
Training loss: 1.9425048828125
Validation loss: 2.4728920075201217

Epoch: 6| Step: 10
Training loss: 1.9836252927780151
Validation loss: 2.4603399743315992

Epoch: 6| Step: 11
Training loss: 2.1809945106506348
Validation loss: 2.4585035129259993

Epoch: 6| Step: 12
Training loss: 2.1073265075683594
Validation loss: 2.460757747773201

Epoch: 6| Step: 13
Training loss: 3.7332797050476074
Validation loss: 2.4573954177159134

Epoch: 95| Step: 0
Training loss: 2.150872230529785
Validation loss: 2.4553632710569646

Epoch: 6| Step: 1
Training loss: 3.1035099029541016
Validation loss: 2.453606087674377

Epoch: 6| Step: 2
Training loss: 3.126556873321533
Validation loss: 2.4523896683928785

Epoch: 6| Step: 3
Training loss: 1.9603018760681152
Validation loss: 2.4520609378814697

Epoch: 6| Step: 4
Training loss: 2.8534185886383057
Validation loss: 2.449578280090004

Epoch: 6| Step: 5
Training loss: 2.644991874694824
Validation loss: 2.4509329898383028

Epoch: 6| Step: 6
Training loss: 2.3788232803344727
Validation loss: 2.4585965064264115

Epoch: 6| Step: 7
Training loss: 2.414032459259033
Validation loss: 2.4583211534766742

Epoch: 6| Step: 8
Training loss: 3.293172597885132
Validation loss: 2.470150475860924

Epoch: 6| Step: 9
Training loss: 1.8183293342590332
Validation loss: 2.481778657564553

Epoch: 6| Step: 10
Training loss: 2.791208267211914
Validation loss: 2.4879251782612135

Epoch: 6| Step: 11
Training loss: 2.668510675430298
Validation loss: 2.502302174927086

Epoch: 6| Step: 12
Training loss: 3.235502004623413
Validation loss: 2.5070788693684403

Epoch: 6| Step: 13
Training loss: 2.937709331512451
Validation loss: 2.5279099607980378

Epoch: 96| Step: 0
Training loss: 2.5057551860809326
Validation loss: 2.5100811425075737

Epoch: 6| Step: 1
Training loss: 1.954632043838501
Validation loss: 2.486424474306004

Epoch: 6| Step: 2
Training loss: 2.6597952842712402
Validation loss: 2.469644413199476

Epoch: 6| Step: 3
Training loss: 2.94006609916687
Validation loss: 2.460104327048025

Epoch: 6| Step: 4
Training loss: 2.430403709411621
Validation loss: 2.4523450097730084

Epoch: 6| Step: 5
Training loss: 2.7719006538391113
Validation loss: 2.445428717520929

Epoch: 6| Step: 6
Training loss: 2.1480398178100586
Validation loss: 2.440717174160865

Epoch: 6| Step: 7
Training loss: 3.1276869773864746
Validation loss: 2.446808825257004

Epoch: 6| Step: 8
Training loss: 2.5397467613220215
Validation loss: 2.4474513992186515

Epoch: 6| Step: 9
Training loss: 3.168400287628174
Validation loss: 2.4524610773209603

Epoch: 6| Step: 10
Training loss: 2.2507858276367188
Validation loss: 2.4480773659162622

Epoch: 6| Step: 11
Training loss: 2.793586254119873
Validation loss: 2.447850981066304

Epoch: 6| Step: 12
Training loss: 3.201551675796509
Validation loss: 2.4468619285091275

Epoch: 6| Step: 13
Training loss: 2.897090435028076
Validation loss: 2.444939415941956

Epoch: 97| Step: 0
Training loss: 2.633427143096924
Validation loss: 2.4426311369865172

Epoch: 6| Step: 1
Training loss: 2.195937156677246
Validation loss: 2.4449856306916926

Epoch: 6| Step: 2
Training loss: 3.242560386657715
Validation loss: 2.4396552091003745

Epoch: 6| Step: 3
Training loss: 2.4837732315063477
Validation loss: 2.438287091511552

Epoch: 6| Step: 4
Training loss: 2.4354190826416016
Validation loss: 2.4399220738359677

Epoch: 6| Step: 5
Training loss: 2.1046559810638428
Validation loss: 2.4371113495160173

Epoch: 6| Step: 6
Training loss: 2.853597640991211
Validation loss: 2.4411165073353756

Epoch: 6| Step: 7
Training loss: 2.2566514015197754
Validation loss: 2.443962094604328

Epoch: 6| Step: 8
Training loss: 3.007256269454956
Validation loss: 2.449808333509712

Epoch: 6| Step: 9
Training loss: 3.423550844192505
Validation loss: 2.4529328307797833

Epoch: 6| Step: 10
Training loss: 2.662217140197754
Validation loss: 2.4609373525906633

Epoch: 6| Step: 11
Training loss: 1.9873039722442627
Validation loss: 2.4620555062447824

Epoch: 6| Step: 12
Training loss: 3.073401927947998
Validation loss: 2.4750278457518546

Epoch: 6| Step: 13
Training loss: 2.9415252208709717
Validation loss: 2.4790389794175343

Epoch: 98| Step: 0
Training loss: 1.9608227014541626
Validation loss: 2.482196359224217

Epoch: 6| Step: 1
Training loss: 2.0414252281188965
Validation loss: 2.481395685544578

Epoch: 6| Step: 2
Training loss: 2.742164134979248
Validation loss: 2.484552324459117

Epoch: 6| Step: 3
Training loss: 2.5719692707061768
Validation loss: 2.4859933135330037

Epoch: 6| Step: 4
Training loss: 2.5858335494995117
Validation loss: 2.48245402561721

Epoch: 6| Step: 5
Training loss: 3.089416027069092
Validation loss: 2.4702272235706286

Epoch: 6| Step: 6
Training loss: 3.846992254257202
Validation loss: 2.4659450028532293

Epoch: 6| Step: 7
Training loss: 3.0938525199890137
Validation loss: 2.452200182022587

Epoch: 6| Step: 8
Training loss: 3.5652174949645996
Validation loss: 2.4508183848473335

Epoch: 6| Step: 9
Training loss: 1.933876872062683
Validation loss: 2.442900590999152

Epoch: 6| Step: 10
Training loss: 2.636582851409912
Validation loss: 2.4460948744127826

Epoch: 6| Step: 11
Training loss: 1.9734001159667969
Validation loss: 2.437303061126381

Epoch: 6| Step: 12
Training loss: 2.720348834991455
Validation loss: 2.4389321419500534

Epoch: 6| Step: 13
Training loss: 2.3731186389923096
Validation loss: 2.440779620601285

Epoch: 99| Step: 0
Training loss: 2.039731025695801
Validation loss: 2.439068812195973

Epoch: 6| Step: 1
Training loss: 2.451303720474243
Validation loss: 2.4406401008687992

Epoch: 6| Step: 2
Training loss: 2.006256103515625
Validation loss: 2.4448280488291094

Epoch: 6| Step: 3
Training loss: 3.055330514907837
Validation loss: 2.451572472049344

Epoch: 6| Step: 4
Training loss: 3.1277804374694824
Validation loss: 2.4507344153619584

Epoch: 6| Step: 5
Training loss: 3.167851448059082
Validation loss: 2.4576695760091147

Epoch: 6| Step: 6
Training loss: 3.055940628051758
Validation loss: 2.4524741608609437

Epoch: 6| Step: 7
Training loss: 3.374380111694336
Validation loss: 2.4521144000432824

Epoch: 6| Step: 8
Training loss: 2.202366352081299
Validation loss: 2.4538462777291574

Epoch: 6| Step: 9
Training loss: 1.9867305755615234
Validation loss: 2.4632628322929464

Epoch: 6| Step: 10
Training loss: 2.6179747581481934
Validation loss: 2.456382510482624

Epoch: 6| Step: 11
Training loss: 2.397331476211548
Validation loss: 2.462107612240699

Epoch: 6| Step: 12
Training loss: 2.644804000854492
Validation loss: 2.447454342278101

Epoch: 6| Step: 13
Training loss: 3.107865333557129
Validation loss: 2.4527574021329164

Epoch: 100| Step: 0
Training loss: 3.0352468490600586
Validation loss: 2.4417121641097532

Epoch: 6| Step: 1
Training loss: 1.969668984413147
Validation loss: 2.4423946821561424

Epoch: 6| Step: 2
Training loss: 3.312753200531006
Validation loss: 2.4498419915476153

Epoch: 6| Step: 3
Training loss: 2.741641044616699
Validation loss: 2.4530286968395276

Epoch: 6| Step: 4
Training loss: 2.3168249130249023
Validation loss: 2.450270075951853

Epoch: 6| Step: 5
Training loss: 3.2167530059814453
Validation loss: 2.448173902368033

Epoch: 6| Step: 6
Training loss: 3.098818063735962
Validation loss: 2.443273200783678

Epoch: 6| Step: 7
Training loss: 2.8755712509155273
Validation loss: 2.442791579872049

Epoch: 6| Step: 8
Training loss: 2.3789167404174805
Validation loss: 2.43621741571734

Epoch: 6| Step: 9
Training loss: 2.587462902069092
Validation loss: 2.4373375754202566

Epoch: 6| Step: 10
Training loss: 2.8839831352233887
Validation loss: 2.433914197388516

Epoch: 6| Step: 11
Training loss: 2.286637544631958
Validation loss: 2.4350194751575427

Epoch: 6| Step: 12
Training loss: 1.4449481964111328
Validation loss: 2.431645926608834

Epoch: 6| Step: 13
Training loss: 3.203618288040161
Validation loss: 2.429995375294839

Epoch: 101| Step: 0
Training loss: 1.7574903964996338
Validation loss: 2.432348756379979

Epoch: 6| Step: 1
Training loss: 2.5868449211120605
Validation loss: 2.43285398585822

Epoch: 6| Step: 2
Training loss: 3.2085013389587402
Validation loss: 2.4275981431366294

Epoch: 6| Step: 3
Training loss: 1.738825798034668
Validation loss: 2.4311489289806736

Epoch: 6| Step: 4
Training loss: 2.583660125732422
Validation loss: 2.432244071396448

Epoch: 6| Step: 5
Training loss: 2.8015875816345215
Validation loss: 2.4371127338819605

Epoch: 6| Step: 6
Training loss: 2.4918603897094727
Validation loss: 2.4407453742078555

Epoch: 6| Step: 7
Training loss: 2.8995516300201416
Validation loss: 2.4496362722048195

Epoch: 6| Step: 8
Training loss: 2.99166202545166
Validation loss: 2.4473545910209737

Epoch: 6| Step: 9
Training loss: 2.4490957260131836
Validation loss: 2.4471655455968713

Epoch: 6| Step: 10
Training loss: 2.8170790672302246
Validation loss: 2.4461191623441634

Epoch: 6| Step: 11
Training loss: 3.16774320602417
Validation loss: 2.45206690860051

Epoch: 6| Step: 12
Training loss: 2.750229835510254
Validation loss: 2.4489262104034424

Epoch: 6| Step: 13
Training loss: 2.9160618782043457
Validation loss: 2.4562636088299494

Epoch: 102| Step: 0
Training loss: 2.573608875274658
Validation loss: 2.4577244558641986

Epoch: 6| Step: 1
Training loss: 2.22172474861145
Validation loss: 2.463208178038238

Epoch: 6| Step: 2
Training loss: 3.6029324531555176
Validation loss: 2.4693284880730415

Epoch: 6| Step: 3
Training loss: 3.4254941940307617
Validation loss: 2.472196514888476

Epoch: 6| Step: 4
Training loss: 3.131096839904785
Validation loss: 2.4769110602717244

Epoch: 6| Step: 5
Training loss: 2.626041889190674
Validation loss: 2.4931620474784606

Epoch: 6| Step: 6
Training loss: 2.333277702331543
Validation loss: 2.4815381419274116

Epoch: 6| Step: 7
Training loss: 2.301593542098999
Validation loss: 2.4895478628015004

Epoch: 6| Step: 8
Training loss: 2.856386184692383
Validation loss: 2.479848074656661

Epoch: 6| Step: 9
Training loss: 1.9640252590179443
Validation loss: 2.4693902538668726

Epoch: 6| Step: 10
Training loss: 2.3714749813079834
Validation loss: 2.463357256304833

Epoch: 6| Step: 11
Training loss: 2.8545379638671875
Validation loss: 2.4558385725944274

Epoch: 6| Step: 12
Training loss: 2.6198604106903076
Validation loss: 2.449335734049479

Epoch: 6| Step: 13
Training loss: 1.924336314201355
Validation loss: 2.443009107343612

Epoch: 103| Step: 0
Training loss: 2.821676254272461
Validation loss: 2.4385992070680023

Epoch: 6| Step: 1
Training loss: 2.950368642807007
Validation loss: 2.427780318003829

Epoch: 6| Step: 2
Training loss: 2.988248348236084
Validation loss: 2.4283553464438326

Epoch: 6| Step: 3
Training loss: 1.8256129026412964
Validation loss: 2.430623028867988

Epoch: 6| Step: 4
Training loss: 3.4443256855010986
Validation loss: 2.4284178697934715

Epoch: 6| Step: 5
Training loss: 2.756472587585449
Validation loss: 2.4250382889983473

Epoch: 6| Step: 6
Training loss: 2.191978931427002
Validation loss: 2.4269769627560853

Epoch: 6| Step: 7
Training loss: 2.6140072345733643
Validation loss: 2.4213394811076503

Epoch: 6| Step: 8
Training loss: 2.261666774749756
Validation loss: 2.4211860292701313

Epoch: 6| Step: 9
Training loss: 3.1773056983947754
Validation loss: 2.4212737673072406

Epoch: 6| Step: 10
Training loss: 2.1236627101898193
Validation loss: 2.422609826569916

Epoch: 6| Step: 11
Training loss: 2.7614498138427734
Validation loss: 2.421412298756261

Epoch: 6| Step: 12
Training loss: 2.390524387359619
Validation loss: 2.4221374347645748

Epoch: 6| Step: 13
Training loss: 2.887751579284668
Validation loss: 2.425286691675904

Epoch: 104| Step: 0
Training loss: 2.0707006454467773
Validation loss: 2.4300309816996255

Epoch: 6| Step: 1
Training loss: 2.9393792152404785
Validation loss: 2.428423604657573

Epoch: 6| Step: 2
Training loss: 2.796607255935669
Validation loss: 2.437071415685838

Epoch: 6| Step: 3
Training loss: 2.665475845336914
Validation loss: 2.4343792494907173

Epoch: 6| Step: 4
Training loss: 2.331676483154297
Validation loss: 2.438009492812618

Epoch: 6| Step: 5
Training loss: 2.3974642753601074
Validation loss: 2.446579171765235

Epoch: 6| Step: 6
Training loss: 2.3180789947509766
Validation loss: 2.4373652089026665

Epoch: 6| Step: 7
Training loss: 2.957749366760254
Validation loss: 2.4375507831573486

Epoch: 6| Step: 8
Training loss: 2.2741899490356445
Validation loss: 2.4344452376006753

Epoch: 6| Step: 9
Training loss: 2.3408350944519043
Validation loss: 2.4311530666966594

Epoch: 6| Step: 10
Training loss: 2.937382459640503
Validation loss: 2.437649881967934

Epoch: 6| Step: 11
Training loss: 3.2527177333831787
Validation loss: 2.427028453478249

Epoch: 6| Step: 12
Training loss: 3.2329883575439453
Validation loss: 2.4206799999360116

Epoch: 6| Step: 13
Training loss: 2.4692623615264893
Validation loss: 2.416602914051343

Epoch: 105| Step: 0
Training loss: 2.713407039642334
Validation loss: 2.418921737260716

Epoch: 6| Step: 1
Training loss: 2.594780445098877
Validation loss: 2.415480077907603

Epoch: 6| Step: 2
Training loss: 2.7714548110961914
Validation loss: 2.41754715160657

Epoch: 6| Step: 3
Training loss: 3.0242791175842285
Validation loss: 2.418169552280057

Epoch: 6| Step: 4
Training loss: 2.4956278800964355
Validation loss: 2.4193981001454015

Epoch: 6| Step: 5
Training loss: 3.1012840270996094
Validation loss: 2.418790222496115

Epoch: 6| Step: 6
Training loss: 2.4826555252075195
Validation loss: 2.420547849388533

Epoch: 6| Step: 7
Training loss: 2.4592137336730957
Validation loss: 2.4184269225725563

Epoch: 6| Step: 8
Training loss: 2.7803759574890137
Validation loss: 2.4189640040038736

Epoch: 6| Step: 9
Training loss: 2.665299892425537
Validation loss: 2.4212270372657367

Epoch: 6| Step: 10
Training loss: 1.7909810543060303
Validation loss: 2.420991033636114

Epoch: 6| Step: 11
Training loss: 2.5716593265533447
Validation loss: 2.4254111295105307

Epoch: 6| Step: 12
Training loss: 3.411294460296631
Validation loss: 2.4268819337250083

Epoch: 6| Step: 13
Training loss: 1.8412766456604004
Validation loss: 2.4286788612283687

Epoch: 106| Step: 0
Training loss: 3.0841643810272217
Validation loss: 2.4331184279534126

Epoch: 6| Step: 1
Training loss: 2.335101842880249
Validation loss: 2.4429159472065587

Epoch: 6| Step: 2
Training loss: 2.7779111862182617
Validation loss: 2.4497482289550123

Epoch: 6| Step: 3
Training loss: 1.8926312923431396
Validation loss: 2.4535850171119935

Epoch: 6| Step: 4
Training loss: 2.869927406311035
Validation loss: 2.451933414705338

Epoch: 6| Step: 5
Training loss: 2.325514078140259
Validation loss: 2.4509248092610347

Epoch: 6| Step: 6
Training loss: 2.337216377258301
Validation loss: 2.4480105087321293

Epoch: 6| Step: 7
Training loss: 3.645575523376465
Validation loss: 2.4512696266174316

Epoch: 6| Step: 8
Training loss: 2.1951889991760254
Validation loss: 2.4496543817622687

Epoch: 6| Step: 9
Training loss: 2.3168578147888184
Validation loss: 2.447589376921295

Epoch: 6| Step: 10
Training loss: 3.247035503387451
Validation loss: 2.4466150165886007

Epoch: 6| Step: 11
Training loss: 2.3399648666381836
Validation loss: 2.4498851478740735

Epoch: 6| Step: 12
Training loss: 3.061710834503174
Validation loss: 2.4545680169136292

Epoch: 6| Step: 13
Training loss: 2.470860004425049
Validation loss: 2.447391144690975

Epoch: 107| Step: 0
Training loss: 2.9013428688049316
Validation loss: 2.436712844397432

Epoch: 6| Step: 1
Training loss: 2.636975049972534
Validation loss: 2.4316157653767574

Epoch: 6| Step: 2
Training loss: 4.2584943771362305
Validation loss: 2.4382650365111647

Epoch: 6| Step: 3
Training loss: 2.450946807861328
Validation loss: 2.425883412361145

Epoch: 6| Step: 4
Training loss: 2.5336356163024902
Validation loss: 2.4337675443259617

Epoch: 6| Step: 5
Training loss: 2.3533883094787598
Validation loss: 2.4301818416964625

Epoch: 6| Step: 6
Training loss: 1.8095340728759766
Validation loss: 2.434899719812537

Epoch: 6| Step: 7
Training loss: 2.3609087467193604
Validation loss: 2.436304364153134

Epoch: 6| Step: 8
Training loss: 3.522447109222412
Validation loss: 2.4426998169191423

Epoch: 6| Step: 9
Training loss: 3.209096908569336
Validation loss: 2.4395596904139363

Epoch: 6| Step: 10
Training loss: 2.4897286891937256
Validation loss: 2.4502017946653467

Epoch: 6| Step: 11
Training loss: 2.2875099182128906
Validation loss: 2.4432214716429352

Epoch: 6| Step: 12
Training loss: 1.9324091672897339
Validation loss: 2.439019118585894

Epoch: 6| Step: 13
Training loss: 2.068147659301758
Validation loss: 2.4389060581884077

Epoch: 108| Step: 0
Training loss: 3.5234527587890625
Validation loss: 2.4393205937518867

Epoch: 6| Step: 1
Training loss: 2.4176928997039795
Validation loss: 2.442034039446103

Epoch: 6| Step: 2
Training loss: 2.159430503845215
Validation loss: 2.4396868521167385

Epoch: 6| Step: 3
Training loss: 2.947317123413086
Validation loss: 2.4564410255801294

Epoch: 6| Step: 4
Training loss: 2.2018983364105225
Validation loss: 2.457714460229361

Epoch: 6| Step: 5
Training loss: 2.7984466552734375
Validation loss: 2.4658098246461604

Epoch: 6| Step: 6
Training loss: 2.709648609161377
Validation loss: 2.4674384824691282

Epoch: 6| Step: 7
Training loss: 1.9599205255508423
Validation loss: 2.4801981244035947

Epoch: 6| Step: 8
Training loss: 3.130466938018799
Validation loss: 2.488162584202264

Epoch: 6| Step: 9
Training loss: 2.2100698947906494
Validation loss: 2.4887276875075472

Epoch: 6| Step: 10
Training loss: 3.174808979034424
Validation loss: 2.4885706901550293

Epoch: 6| Step: 11
Training loss: 2.4243526458740234
Validation loss: 2.4759345874991467

Epoch: 6| Step: 12
Training loss: 3.0294370651245117
Validation loss: 2.467834731583954

Epoch: 6| Step: 13
Training loss: 2.0002338886260986
Validation loss: 2.458592132855487

Epoch: 109| Step: 0
Training loss: 2.7220118045806885
Validation loss: 2.453973836796258

Epoch: 6| Step: 1
Training loss: 3.4976956844329834
Validation loss: 2.445037785396781

Epoch: 6| Step: 2
Training loss: 2.4392001628875732
Validation loss: 2.443202195628997

Epoch: 6| Step: 3
Training loss: 3.0207443237304688
Validation loss: 2.431762180020732

Epoch: 6| Step: 4
Training loss: 3.0530200004577637
Validation loss: 2.4315316113092567

Epoch: 6| Step: 5
Training loss: 2.0229132175445557
Validation loss: 2.429891683722055

Epoch: 6| Step: 6
Training loss: 2.9003705978393555
Validation loss: 2.4285974861473165

Epoch: 6| Step: 7
Training loss: 2.335343837738037
Validation loss: 2.4248792022787113

Epoch: 6| Step: 8
Training loss: 2.8828468322753906
Validation loss: 2.4249577496641423

Epoch: 6| Step: 9
Training loss: 2.2091188430786133
Validation loss: 2.424522025610811

Epoch: 6| Step: 10
Training loss: 2.8297619819641113
Validation loss: 2.4224063170853483

Epoch: 6| Step: 11
Training loss: 2.297513484954834
Validation loss: 2.423271084344515

Epoch: 6| Step: 12
Training loss: 1.7598145008087158
Validation loss: 2.428039288008085

Epoch: 6| Step: 13
Training loss: 3.066516876220703
Validation loss: 2.4223479506789998

Epoch: 110| Step: 0
Training loss: 2.6425368785858154
Validation loss: 2.422623377974315

Epoch: 6| Step: 1
Training loss: 3.392688751220703
Validation loss: 2.423234437101631

Epoch: 6| Step: 2
Training loss: 2.8575057983398438
Validation loss: 2.4173533339654245

Epoch: 6| Step: 3
Training loss: 3.06301212310791
Validation loss: 2.419812653654365

Epoch: 6| Step: 4
Training loss: 3.069359302520752
Validation loss: 2.4190029046868764

Epoch: 6| Step: 5
Training loss: 2.4706597328186035
Validation loss: 2.4135264145430697

Epoch: 6| Step: 6
Training loss: 2.33697509765625
Validation loss: 2.4066449057671333

Epoch: 6| Step: 7
Training loss: 2.9079604148864746
Validation loss: 2.4126056086632515

Epoch: 6| Step: 8
Training loss: 2.497836112976074
Validation loss: 2.412613732840425

Epoch: 6| Step: 9
Training loss: 2.2212278842926025
Validation loss: 2.413279684641028

Epoch: 6| Step: 10
Training loss: 3.290849208831787
Validation loss: 2.413814947169314

Epoch: 6| Step: 11
Training loss: 1.7029545307159424
Validation loss: 2.415811602787305

Epoch: 6| Step: 12
Training loss: 1.6680119037628174
Validation loss: 2.4172810072539956

Epoch: 6| Step: 13
Training loss: 2.7918384075164795
Validation loss: 2.4156111645442184

Epoch: 111| Step: 0
Training loss: 2.963942050933838
Validation loss: 2.4173999422339985

Epoch: 6| Step: 1
Training loss: 2.1763882637023926
Validation loss: 2.4196635036058325

Epoch: 6| Step: 2
Training loss: 2.38462495803833
Validation loss: 2.4281292012942735

Epoch: 6| Step: 3
Training loss: 2.615312099456787
Validation loss: 2.432872636343843

Epoch: 6| Step: 4
Training loss: 2.7321019172668457
Validation loss: 2.438234069014108

Epoch: 6| Step: 5
Training loss: 2.5493791103363037
Validation loss: 2.4319469980014268

Epoch: 6| Step: 6
Training loss: 2.194728374481201
Validation loss: 2.4361858137192263

Epoch: 6| Step: 7
Training loss: 2.8857827186584473
Validation loss: 2.4320885724918817

Epoch: 6| Step: 8
Training loss: 3.0325355529785156
Validation loss: 2.4302446483283915

Epoch: 6| Step: 9
Training loss: 2.531144618988037
Validation loss: 2.4340044734298543

Epoch: 6| Step: 10
Training loss: 3.25249981880188
Validation loss: 2.436216585097774

Epoch: 6| Step: 11
Training loss: 2.616900682449341
Validation loss: 2.4338773091634116

Epoch: 6| Step: 12
Training loss: 2.6206369400024414
Validation loss: 2.4342948505955357

Epoch: 6| Step: 13
Training loss: 2.0969438552856445
Validation loss: 2.434117414618051

Epoch: 112| Step: 0
Training loss: 2.5000412464141846
Validation loss: 2.4342137972513833

Epoch: 6| Step: 1
Training loss: 2.2353832721710205
Validation loss: 2.424148964625533

Epoch: 6| Step: 2
Training loss: 2.8622732162475586
Validation loss: 2.4299337376830397

Epoch: 6| Step: 3
Training loss: 2.670620918273926
Validation loss: 2.4270214675575175

Epoch: 6| Step: 4
Training loss: 2.806488037109375
Validation loss: 2.4199919354531074

Epoch: 6| Step: 5
Training loss: 2.513570785522461
Validation loss: 2.4215474949088147

Epoch: 6| Step: 6
Training loss: 1.8056299686431885
Validation loss: 2.4192848154293594

Epoch: 6| Step: 7
Training loss: 3.7155447006225586
Validation loss: 2.4196199037695445

Epoch: 6| Step: 8
Training loss: 2.127316951751709
Validation loss: 2.413050987387216

Epoch: 6| Step: 9
Training loss: 3.2407045364379883
Validation loss: 2.419165380539433

Epoch: 6| Step: 10
Training loss: 2.1503758430480957
Validation loss: 2.416880633241387

Epoch: 6| Step: 11
Training loss: 3.274416446685791
Validation loss: 2.4162074058286604

Epoch: 6| Step: 12
Training loss: 2.1218786239624023
Validation loss: 2.423407180334932

Epoch: 6| Step: 13
Training loss: 2.997236728668213
Validation loss: 2.433444857597351

Epoch: 113| Step: 0
Training loss: 1.51169753074646
Validation loss: 2.4340875353864444

Epoch: 6| Step: 1
Training loss: 2.9890408515930176
Validation loss: 2.4486269643229823

Epoch: 6| Step: 2
Training loss: 3.066037178039551
Validation loss: 2.439720748573221

Epoch: 6| Step: 3
Training loss: 2.9594082832336426
Validation loss: 2.4418499341575046

Epoch: 6| Step: 4
Training loss: 2.22383713722229
Validation loss: 2.449190678135041

Epoch: 6| Step: 5
Training loss: 3.1439859867095947
Validation loss: 2.4473561599690425

Epoch: 6| Step: 6
Training loss: 2.5272912979125977
Validation loss: 2.442278710744714

Epoch: 6| Step: 7
Training loss: 2.9542672634124756
Validation loss: 2.4398367251119306

Epoch: 6| Step: 8
Training loss: 1.9079229831695557
Validation loss: 2.439007459148284

Epoch: 6| Step: 9
Training loss: 3.040745973587036
Validation loss: 2.438470809690414

Epoch: 6| Step: 10
Training loss: 2.8943674564361572
Validation loss: 2.4327072251227593

Epoch: 6| Step: 11
Training loss: 1.9376554489135742
Validation loss: 2.434785645495179

Epoch: 6| Step: 12
Training loss: 3.221327781677246
Validation loss: 2.4272516773593042

Epoch: 6| Step: 13
Training loss: 2.3654282093048096
Validation loss: 2.430506496019261

Epoch: 114| Step: 0
Training loss: 2.0774755477905273
Validation loss: 2.4308762396535566

Epoch: 6| Step: 1
Training loss: 1.9690378904342651
Validation loss: 2.4270933340954524

Epoch: 6| Step: 2
Training loss: 3.314228057861328
Validation loss: 2.42513592268831

Epoch: 6| Step: 3
Training loss: 2.1274006366729736
Validation loss: 2.4220849211497972

Epoch: 6| Step: 4
Training loss: 3.0900120735168457
Validation loss: 2.4190835542576288

Epoch: 6| Step: 5
Training loss: 2.6470699310302734
Validation loss: 2.4170923989306212

Epoch: 6| Step: 6
Training loss: 3.297027587890625
Validation loss: 2.4090640416709324

Epoch: 6| Step: 7
Training loss: 1.8075578212738037
Validation loss: 2.408660629744171

Epoch: 6| Step: 8
Training loss: 1.7446694374084473
Validation loss: 2.408033917027135

Epoch: 6| Step: 9
Training loss: 2.97145676612854
Validation loss: 2.411552770163423

Epoch: 6| Step: 10
Training loss: 3.10068941116333
Validation loss: 2.4102270910816808

Epoch: 6| Step: 11
Training loss: 3.0038890838623047
Validation loss: 2.4083351986382597

Epoch: 6| Step: 12
Training loss: 2.820035934448242
Validation loss: 2.406846307939099

Epoch: 6| Step: 13
Training loss: 2.8948800563812256
Validation loss: 2.4014435660454536

Epoch: 115| Step: 0
Training loss: 3.0250635147094727
Validation loss: 2.404646873474121

Epoch: 6| Step: 1
Training loss: 1.973511815071106
Validation loss: 2.4040329892148256

Epoch: 6| Step: 2
Training loss: 3.024799346923828
Validation loss: 2.4060289103497743

Epoch: 6| Step: 3
Training loss: 2.4575300216674805
Validation loss: 2.4059846452487412

Epoch: 6| Step: 4
Training loss: 3.3684585094451904
Validation loss: 2.412898789169968

Epoch: 6| Step: 5
Training loss: 2.7354257106781006
Validation loss: 2.41707202183303

Epoch: 6| Step: 6
Training loss: 2.756878614425659
Validation loss: 2.4132382972266084

Epoch: 6| Step: 7
Training loss: 2.631683111190796
Validation loss: 2.4161101797575593

Epoch: 6| Step: 8
Training loss: 2.7514562606811523
Validation loss: 2.4140631947466122

Epoch: 6| Step: 9
Training loss: 2.2887206077575684
Validation loss: 2.409056968586419

Epoch: 6| Step: 10
Training loss: 2.2608609199523926
Validation loss: 2.4122863431130686

Epoch: 6| Step: 11
Training loss: 2.874718189239502
Validation loss: 2.4161828538422943

Epoch: 6| Step: 12
Training loss: 2.205169677734375
Validation loss: 2.4149420889475013

Epoch: 6| Step: 13
Training loss: 2.1980366706848145
Validation loss: 2.4227662599214943

Epoch: 116| Step: 0
Training loss: 2.160999298095703
Validation loss: 2.435968839994041

Epoch: 6| Step: 1
Training loss: 2.6153018474578857
Validation loss: 2.4436720648119525

Epoch: 6| Step: 2
Training loss: 3.2300848960876465
Validation loss: 2.442562198126188

Epoch: 6| Step: 3
Training loss: 3.7148633003234863
Validation loss: 2.4496814294527938

Epoch: 6| Step: 4
Training loss: 2.7773633003234863
Validation loss: 2.455920793676889

Epoch: 6| Step: 5
Training loss: 1.5994179248809814
Validation loss: 2.4646343723420174

Epoch: 6| Step: 6
Training loss: 2.8243532180786133
Validation loss: 2.4659035846751225

Epoch: 6| Step: 7
Training loss: 2.2688512802124023
Validation loss: 2.4574631619197067

Epoch: 6| Step: 8
Training loss: 3.0442538261413574
Validation loss: 2.4503610698125695

Epoch: 6| Step: 9
Training loss: 2.215826988220215
Validation loss: 2.444613195234729

Epoch: 6| Step: 10
Training loss: 2.8023152351379395
Validation loss: 2.4484330659271567

Epoch: 6| Step: 11
Training loss: 1.9367311000823975
Validation loss: 2.4484250853138585

Epoch: 6| Step: 12
Training loss: 2.483766794204712
Validation loss: 2.431199035336894

Epoch: 6| Step: 13
Training loss: 3.609391212463379
Validation loss: 2.437758586739981

Epoch: 117| Step: 0
Training loss: 2.8184890747070312
Validation loss: 2.422078514611849

Epoch: 6| Step: 1
Training loss: 2.372873306274414
Validation loss: 2.419836708294448

Epoch: 6| Step: 2
Training loss: 2.5718564987182617
Validation loss: 2.4121661801492014

Epoch: 6| Step: 3
Training loss: 1.7004690170288086
Validation loss: 2.4103920536656536

Epoch: 6| Step: 4
Training loss: 2.8138489723205566
Validation loss: 2.403790468810707

Epoch: 6| Step: 5
Training loss: 2.610126495361328
Validation loss: 2.405156425250474

Epoch: 6| Step: 6
Training loss: 2.5363855361938477
Validation loss: 2.400596364851921

Epoch: 6| Step: 7
Training loss: 3.1648449897766113
Validation loss: 2.3975476552081365

Epoch: 6| Step: 8
Training loss: 2.547015905380249
Validation loss: 2.3945713581577426

Epoch: 6| Step: 9
Training loss: 2.7059736251831055
Validation loss: 2.4004382728248514

Epoch: 6| Step: 10
Training loss: 3.1239798069000244
Validation loss: 2.400124975430068

Epoch: 6| Step: 11
Training loss: 2.2294156551361084
Validation loss: 2.3945424787459837

Epoch: 6| Step: 12
Training loss: 3.3024325370788574
Validation loss: 2.3998672449460594

Epoch: 6| Step: 13
Training loss: 1.9214401245117188
Validation loss: 2.3945943437596804

Epoch: 118| Step: 0
Training loss: 3.0394506454467773
Validation loss: 2.4007076268555014

Epoch: 6| Step: 1
Training loss: 2.639258861541748
Validation loss: 2.4020114355189826

Epoch: 6| Step: 2
Training loss: 2.6282706260681152
Validation loss: 2.4104769640071417

Epoch: 6| Step: 3
Training loss: 2.1681196689605713
Validation loss: 2.4063916667815177

Epoch: 6| Step: 4
Training loss: 2.550415515899658
Validation loss: 2.4015113871584655

Epoch: 6| Step: 5
Training loss: 2.6396474838256836
Validation loss: 2.402069430197439

Epoch: 6| Step: 6
Training loss: 2.8497674465179443
Validation loss: 2.4088598784580024

Epoch: 6| Step: 7
Training loss: 3.487245559692383
Validation loss: 2.414533794567149

Epoch: 6| Step: 8
Training loss: 2.830037832260132
Validation loss: 2.416873493502217

Epoch: 6| Step: 9
Training loss: 2.4290547370910645
Validation loss: 2.4159447403364283

Epoch: 6| Step: 10
Training loss: 2.440734386444092
Validation loss: 2.4152222961507817

Epoch: 6| Step: 11
Training loss: 1.927722454071045
Validation loss: 2.414861732913602

Epoch: 6| Step: 12
Training loss: 2.9388427734375
Validation loss: 2.416815998733685

Epoch: 6| Step: 13
Training loss: 1.8314435482025146
Validation loss: 2.4142726877684235

Epoch: 119| Step: 0
Training loss: 2.471057891845703
Validation loss: 2.4109161079570813

Epoch: 6| Step: 1
Training loss: 2.966651439666748
Validation loss: 2.4102283729019987

Epoch: 6| Step: 2
Training loss: 2.757561206817627
Validation loss: 2.4078275901015087

Epoch: 6| Step: 3
Training loss: 2.785031795501709
Validation loss: 2.4047442661818637

Epoch: 6| Step: 4
Training loss: 2.0766396522521973
Validation loss: 2.405905908153903

Epoch: 6| Step: 5
Training loss: 2.6926612854003906
Validation loss: 2.4084532183985554

Epoch: 6| Step: 6
Training loss: 3.1534242630004883
Validation loss: 2.412966848701559

Epoch: 6| Step: 7
Training loss: 3.0076308250427246
Validation loss: 2.4102043105709936

Epoch: 6| Step: 8
Training loss: 2.389133930206299
Validation loss: 2.4084009688387633

Epoch: 6| Step: 9
Training loss: 2.633920669555664
Validation loss: 2.4128726579809703

Epoch: 6| Step: 10
Training loss: 2.626616954803467
Validation loss: 2.4149556365064395

Epoch: 6| Step: 11
Training loss: 1.9931821823120117
Validation loss: 2.413642357754451

Epoch: 6| Step: 12
Training loss: 2.7684082984924316
Validation loss: 2.41347405474673

Epoch: 6| Step: 13
Training loss: 2.1310977935791016
Validation loss: 2.4155839566261537

Epoch: 120| Step: 0
Training loss: 3.0225276947021484
Validation loss: 2.4272682512960126

Epoch: 6| Step: 1
Training loss: 3.0573325157165527
Validation loss: 2.4300390571676274

Epoch: 6| Step: 2
Training loss: 2.8712620735168457
Validation loss: 2.43323415581898

Epoch: 6| Step: 3
Training loss: 2.887111186981201
Validation loss: 2.4385507286235852

Epoch: 6| Step: 4
Training loss: 1.7306766510009766
Validation loss: 2.4512823448386243

Epoch: 6| Step: 5
Training loss: 2.267305374145508
Validation loss: 2.4494064802764566

Epoch: 6| Step: 6
Training loss: 2.7428674697875977
Validation loss: 2.4535655360068045

Epoch: 6| Step: 7
Training loss: 2.7021307945251465
Validation loss: 2.447590115249798

Epoch: 6| Step: 8
Training loss: 2.616212844848633
Validation loss: 2.4328742796374905

Epoch: 6| Step: 9
Training loss: 2.0092430114746094
Validation loss: 2.4313777082709858

Epoch: 6| Step: 10
Training loss: 2.776550769805908
Validation loss: 2.4197249309990996

Epoch: 6| Step: 11
Training loss: 3.1775600910186768
Validation loss: 2.408649495852891

Epoch: 6| Step: 12
Training loss: 2.192479133605957
Validation loss: 2.4028439829426427

Epoch: 6| Step: 13
Training loss: 2.5916669368743896
Validation loss: 2.403671277466641

Epoch: 121| Step: 0
Training loss: 2.8321828842163086
Validation loss: 2.4135153242336806

Epoch: 6| Step: 1
Training loss: 2.4012811183929443
Validation loss: 2.4214349023757444

Epoch: 6| Step: 2
Training loss: 3.139059543609619
Validation loss: 2.437373899644421

Epoch: 6| Step: 3
Training loss: 2.225093364715576
Validation loss: 2.4465924488600863

Epoch: 6| Step: 4
Training loss: 2.680164337158203
Validation loss: 2.458139427246586

Epoch: 6| Step: 5
Training loss: 2.5961949825286865
Validation loss: 2.454010216138696

Epoch: 6| Step: 6
Training loss: 2.3110511302948
Validation loss: 2.4430838682318248

Epoch: 6| Step: 7
Training loss: 2.6843271255493164
Validation loss: 2.4310183063630135

Epoch: 6| Step: 8
Training loss: 2.303816795349121
Validation loss: 2.427779331002184

Epoch: 6| Step: 9
Training loss: 3.2364320755004883
Validation loss: 2.427634075123777

Epoch: 6| Step: 10
Training loss: 3.0178256034851074
Validation loss: 2.421256563996756

Epoch: 6| Step: 11
Training loss: 2.6101396083831787
Validation loss: 2.420397158591978

Epoch: 6| Step: 12
Training loss: 2.4799983501434326
Validation loss: 2.4204050597324165

Epoch: 6| Step: 13
Training loss: 1.9009854793548584
Validation loss: 2.4303162764477473

Epoch: 122| Step: 0
Training loss: 2.5651679039001465
Validation loss: 2.422957868986232

Epoch: 6| Step: 1
Training loss: 2.000063419342041
Validation loss: 2.439639563201576

Epoch: 6| Step: 2
Training loss: 2.890887975692749
Validation loss: 2.4171011537633915

Epoch: 6| Step: 3
Training loss: 2.825988292694092
Validation loss: 2.414611006295809

Epoch: 6| Step: 4
Training loss: 2.812112331390381
Validation loss: 2.405866330669772

Epoch: 6| Step: 5
Training loss: 2.7582650184631348
Validation loss: 2.407232073045546

Epoch: 6| Step: 6
Training loss: 2.3304624557495117
Validation loss: 2.40392816194924

Epoch: 6| Step: 7
Training loss: 2.6992974281311035
Validation loss: 2.4094549891769246

Epoch: 6| Step: 8
Training loss: 2.9991402626037598
Validation loss: 2.4160358675064577

Epoch: 6| Step: 9
Training loss: 2.2379183769226074
Validation loss: 2.4108484457897883

Epoch: 6| Step: 10
Training loss: 2.6645071506500244
Validation loss: 2.4020691866515786

Epoch: 6| Step: 11
Training loss: 3.2495861053466797
Validation loss: 2.404858150789815

Epoch: 6| Step: 12
Training loss: 2.3556833267211914
Validation loss: 2.4040188097184703

Epoch: 6| Step: 13
Training loss: 2.1791937351226807
Validation loss: 2.399073580259918

Epoch: 123| Step: 0
Training loss: 3.124049425125122
Validation loss: 2.3975976487641693

Epoch: 6| Step: 1
Training loss: 2.7804160118103027
Validation loss: 2.397675944912818

Epoch: 6| Step: 2
Training loss: 1.9990756511688232
Validation loss: 2.3975720661942677

Epoch: 6| Step: 3
Training loss: 3.438793897628784
Validation loss: 2.39142067586222

Epoch: 6| Step: 4
Training loss: 3.1446075439453125
Validation loss: 2.39792795847821

Epoch: 6| Step: 5
Training loss: 2.8477206230163574
Validation loss: 2.4009668186146724

Epoch: 6| Step: 6
Training loss: 2.668121814727783
Validation loss: 2.4000068710696314

Epoch: 6| Step: 7
Training loss: 2.7025489807128906
Validation loss: 2.395461292677028

Epoch: 6| Step: 8
Training loss: 2.098295211791992
Validation loss: 2.395527365387127

Epoch: 6| Step: 9
Training loss: 2.2950103282928467
Validation loss: 2.401980459049184

Epoch: 6| Step: 10
Training loss: 2.8042261600494385
Validation loss: 2.400902663507769

Epoch: 6| Step: 11
Training loss: 1.8230202198028564
Validation loss: 2.3985903801456576

Epoch: 6| Step: 12
Training loss: 2.8299179077148438
Validation loss: 2.3990251223246255

Epoch: 6| Step: 13
Training loss: 1.7824482917785645
Validation loss: 2.4051633573347524

Epoch: 124| Step: 0
Training loss: 2.483408212661743
Validation loss: 2.413203175349902

Epoch: 6| Step: 1
Training loss: 2.9158358573913574
Validation loss: 2.4205001990000405

Epoch: 6| Step: 2
Training loss: 2.6344571113586426
Validation loss: 2.419010854536487

Epoch: 6| Step: 3
Training loss: 2.9043595790863037
Validation loss: 2.4121771089492308

Epoch: 6| Step: 4
Training loss: 2.64192533493042
Validation loss: 2.408052630321954

Epoch: 6| Step: 5
Training loss: 1.721548318862915
Validation loss: 2.4185934887137464

Epoch: 6| Step: 6
Training loss: 2.654589891433716
Validation loss: 2.4243496412871988

Epoch: 6| Step: 7
Training loss: 2.9959235191345215
Validation loss: 2.4216356533829884

Epoch: 6| Step: 8
Training loss: 2.116274356842041
Validation loss: 2.4145401857232534

Epoch: 6| Step: 9
Training loss: 3.2021665573120117
Validation loss: 2.411726620889479

Epoch: 6| Step: 10
Training loss: 2.967120885848999
Validation loss: 2.3966271326106083

Epoch: 6| Step: 11
Training loss: 2.8730368614196777
Validation loss: 2.4054086387798352

Epoch: 6| Step: 12
Training loss: 2.3236923217773438
Validation loss: 2.3944085233954975

Epoch: 6| Step: 13
Training loss: 1.8175536394119263
Validation loss: 2.394760931691816

Epoch: 125| Step: 0
Training loss: 2.437222957611084
Validation loss: 2.3946965227844896

Epoch: 6| Step: 1
Training loss: 3.648338794708252
Validation loss: 2.3981056136469685

Epoch: 6| Step: 2
Training loss: 1.823348045349121
Validation loss: 2.399237281532698

Epoch: 6| Step: 3
Training loss: 2.718132734298706
Validation loss: 2.400587028072726

Epoch: 6| Step: 4
Training loss: 2.277042865753174
Validation loss: 2.410149097442627

Epoch: 6| Step: 5
Training loss: 2.4865729808807373
Validation loss: 2.42274643528846

Epoch: 6| Step: 6
Training loss: 2.5619747638702393
Validation loss: 2.4321133975059754

Epoch: 6| Step: 7
Training loss: 2.1726903915405273
Validation loss: 2.446468681417486

Epoch: 6| Step: 8
Training loss: 2.3413820266723633
Validation loss: 2.4472378915356052

Epoch: 6| Step: 9
Training loss: 2.941138744354248
Validation loss: 2.4453532823952298

Epoch: 6| Step: 10
Training loss: 2.5924363136291504
Validation loss: 2.4564847792348554

Epoch: 6| Step: 11
Training loss: 3.2676477432250977
Validation loss: 2.440255472736974

Epoch: 6| Step: 12
Training loss: 2.8482744693756104
Validation loss: 2.4361905256907144

Epoch: 6| Step: 13
Training loss: 2.5588700771331787
Validation loss: 2.419214884440104

Epoch: 126| Step: 0
Training loss: 2.8391690254211426
Validation loss: 2.415536977911508

Epoch: 6| Step: 1
Training loss: 2.5242185592651367
Validation loss: 2.4094258687829457

Epoch: 6| Step: 2
Training loss: 2.847853660583496
Validation loss: 2.4026695502701627

Epoch: 6| Step: 3
Training loss: 2.928201198577881
Validation loss: 2.400746924902803

Epoch: 6| Step: 4
Training loss: 2.298163890838623
Validation loss: 2.4001075990738405

Epoch: 6| Step: 5
Training loss: 2.1627049446105957
Validation loss: 2.3977833819645706

Epoch: 6| Step: 6
Training loss: 2.8042545318603516
Validation loss: 2.3964431772949877

Epoch: 6| Step: 7
Training loss: 2.125715732574463
Validation loss: 2.396978232168382

Epoch: 6| Step: 8
Training loss: 2.8236870765686035
Validation loss: 2.397980184965236

Epoch: 6| Step: 9
Training loss: 2.32096004486084
Validation loss: 2.3893485940912718

Epoch: 6| Step: 10
Training loss: 3.2130253314971924
Validation loss: 2.392395752732472

Epoch: 6| Step: 11
Training loss: 2.8761048316955566
Validation loss: 2.3891236218073035

Epoch: 6| Step: 12
Training loss: 2.3372273445129395
Validation loss: 2.3864084443738385

Epoch: 6| Step: 13
Training loss: 2.6466588973999023
Validation loss: 2.384971833998157

Epoch: 127| Step: 0
Training loss: 2.159823417663574
Validation loss: 2.389962416823192

Epoch: 6| Step: 1
Training loss: 2.643542766571045
Validation loss: 2.395901390301284

Epoch: 6| Step: 2
Training loss: 3.0825490951538086
Validation loss: 2.4018251178085164

Epoch: 6| Step: 3
Training loss: 2.9663233757019043
Validation loss: 2.4223862412155315

Epoch: 6| Step: 4
Training loss: 1.8508388996124268
Validation loss: 2.42677826522499

Epoch: 6| Step: 5
Training loss: 2.3156402111053467
Validation loss: 2.430448485958961

Epoch: 6| Step: 6
Training loss: 2.645172119140625
Validation loss: 2.4375264618986394

Epoch: 6| Step: 7
Training loss: 2.606112241744995
Validation loss: 2.4332681112391974

Epoch: 6| Step: 8
Training loss: 3.052356719970703
Validation loss: 2.41847562789917

Epoch: 6| Step: 9
Training loss: 1.9126038551330566
Validation loss: 2.412588986017371

Epoch: 6| Step: 10
Training loss: 2.766143560409546
Validation loss: 2.409058855425927

Epoch: 6| Step: 11
Training loss: 3.123546600341797
Validation loss: 2.4059594420976538

Epoch: 6| Step: 12
Training loss: 2.4575204849243164
Validation loss: 2.4038790759219917

Epoch: 6| Step: 13
Training loss: 3.2773654460906982
Validation loss: 2.4058495695872972

Epoch: 128| Step: 0
Training loss: 3.0318751335144043
Validation loss: 2.4108708263725362

Epoch: 6| Step: 1
Training loss: 2.788540840148926
Validation loss: 2.4051312272266676

Epoch: 6| Step: 2
Training loss: 1.9947361946105957
Validation loss: 2.4056809948336695

Epoch: 6| Step: 3
Training loss: 2.2784440517425537
Validation loss: 2.4032360174322642

Epoch: 6| Step: 4
Training loss: 3.0003910064697266
Validation loss: 2.393400033315023

Epoch: 6| Step: 5
Training loss: 2.186013698577881
Validation loss: 2.3979668078884

Epoch: 6| Step: 6
Training loss: 2.83499813079834
Validation loss: 2.3924413496448147

Epoch: 6| Step: 7
Training loss: 2.9278242588043213
Validation loss: 2.393103886676091

Epoch: 6| Step: 8
Training loss: 2.755624532699585
Validation loss: 2.388622460826751

Epoch: 6| Step: 9
Training loss: 3.0792465209960938
Validation loss: 2.389043390109975

Epoch: 6| Step: 10
Training loss: 1.8920607566833496
Validation loss: 2.389996220988612

Epoch: 6| Step: 11
Training loss: 3.3017044067382812
Validation loss: 2.3872787542240594

Epoch: 6| Step: 12
Training loss: 2.198330879211426
Validation loss: 2.3907790542930685

Epoch: 6| Step: 13
Training loss: 1.89586341381073
Validation loss: 2.3917131257313553

Epoch: 129| Step: 0
Training loss: 1.9146535396575928
Validation loss: 2.393443766460624

Epoch: 6| Step: 1
Training loss: 2.675126314163208
Validation loss: 2.3956669299833235

Epoch: 6| Step: 2
Training loss: 3.2363202571868896
Validation loss: 2.4163471011705298

Epoch: 6| Step: 3
Training loss: 3.2970118522644043
Validation loss: 2.4223850645044798

Epoch: 6| Step: 4
Training loss: 2.921719789505005
Validation loss: 2.4136507024047194

Epoch: 6| Step: 5
Training loss: 2.4600110054016113
Validation loss: 2.420400942525556

Epoch: 6| Step: 6
Training loss: 2.0653178691864014
Validation loss: 2.4072490302465295

Epoch: 6| Step: 7
Training loss: 2.5375945568084717
Validation loss: 2.4006476556101153

Epoch: 6| Step: 8
Training loss: 3.127626895904541
Validation loss: 2.398422279665547

Epoch: 6| Step: 9
Training loss: 2.761556625366211
Validation loss: 2.3931685340019966

Epoch: 6| Step: 10
Training loss: 2.353929042816162
Validation loss: 2.390369374264953

Epoch: 6| Step: 11
Training loss: 2.3432717323303223
Validation loss: 2.3965770916272233

Epoch: 6| Step: 12
Training loss: 2.249316692352295
Validation loss: 2.391723494375906

Epoch: 6| Step: 13
Training loss: 2.6655898094177246
Validation loss: 2.3983416249675136

Epoch: 130| Step: 0
Training loss: 2.914811134338379
Validation loss: 2.3949871601596957

Epoch: 6| Step: 1
Training loss: 3.2794580459594727
Validation loss: 2.3958880362972135

Epoch: 6| Step: 2
Training loss: 2.5480587482452393
Validation loss: 2.3942026489524433

Epoch: 6| Step: 3
Training loss: 2.235750675201416
Validation loss: 2.3902999662583873

Epoch: 6| Step: 4
Training loss: 3.0832202434539795
Validation loss: 2.39091888038061

Epoch: 6| Step: 5
Training loss: 3.3249428272247314
Validation loss: 2.3927565902791996

Epoch: 6| Step: 6
Training loss: 2.1729683876037598
Validation loss: 2.3938554999648884

Epoch: 6| Step: 7
Training loss: 2.0483365058898926
Validation loss: 2.3915470953910583

Epoch: 6| Step: 8
Training loss: 3.273571014404297
Validation loss: 2.39636750887799

Epoch: 6| Step: 9
Training loss: 2.070310592651367
Validation loss: 2.384347802849226

Epoch: 6| Step: 10
Training loss: 2.508981704711914
Validation loss: 2.398156158385738

Epoch: 6| Step: 11
Training loss: 2.251026153564453
Validation loss: 2.403080842828238

Epoch: 6| Step: 12
Training loss: 2.3179051876068115
Validation loss: 2.3964500401609685

Epoch: 6| Step: 13
Training loss: 2.197181463241577
Validation loss: 2.3994536092204433

Epoch: 131| Step: 0
Training loss: 3.299053907394409
Validation loss: 2.406395040532594

Epoch: 6| Step: 1
Training loss: 2.2251229286193848
Validation loss: 2.4142824501119633

Epoch: 6| Step: 2
Training loss: 3.2718544006347656
Validation loss: 2.410750432681012

Epoch: 6| Step: 3
Training loss: 2.974720001220703
Validation loss: 2.408300943272088

Epoch: 6| Step: 4
Training loss: 1.8505632877349854
Validation loss: 2.4185818831125894

Epoch: 6| Step: 5
Training loss: 3.079106330871582
Validation loss: 2.4058542020859255

Epoch: 6| Step: 6
Training loss: 1.4402519464492798
Validation loss: 2.407011542268979

Epoch: 6| Step: 7
Training loss: 2.341757297515869
Validation loss: 2.4041738151222147

Epoch: 6| Step: 8
Training loss: 3.039076805114746
Validation loss: 2.4059356002397436

Epoch: 6| Step: 9
Training loss: 2.9224050045013428
Validation loss: 2.3940179194173505

Epoch: 6| Step: 10
Training loss: 2.767338275909424
Validation loss: 2.3968441819631927

Epoch: 6| Step: 11
Training loss: 2.7251527309417725
Validation loss: 2.399036997108049

Epoch: 6| Step: 12
Training loss: 2.211909294128418
Validation loss: 2.3935175967472855

Epoch: 6| Step: 13
Training loss: 1.8051128387451172
Validation loss: 2.396332110128095

Epoch: 132| Step: 0
Training loss: 2.7048873901367188
Validation loss: 2.4015650108296382

Epoch: 6| Step: 1
Training loss: 2.3009324073791504
Validation loss: 2.406540750175394

Epoch: 6| Step: 2
Training loss: 3.407866954803467
Validation loss: 2.4124875248119397

Epoch: 6| Step: 3
Training loss: 2.926259756088257
Validation loss: 2.408793303274339

Epoch: 6| Step: 4
Training loss: 2.156141519546509
Validation loss: 2.4068471001040552

Epoch: 6| Step: 5
Training loss: 2.8539772033691406
Validation loss: 2.40429441390499

Epoch: 6| Step: 6
Training loss: 2.099066972732544
Validation loss: 2.397927289368004

Epoch: 6| Step: 7
Training loss: 2.6469597816467285
Validation loss: 2.4033453259416806

Epoch: 6| Step: 8
Training loss: 2.8761682510375977
Validation loss: 2.3983871142069497

Epoch: 6| Step: 9
Training loss: 1.7270803451538086
Validation loss: 2.3997664554144746

Epoch: 6| Step: 10
Training loss: 2.7377822399139404
Validation loss: 2.3952579254745157

Epoch: 6| Step: 11
Training loss: 2.597790241241455
Validation loss: 2.3881985628476707

Epoch: 6| Step: 12
Training loss: 3.119112491607666
Validation loss: 2.3896845412510697

Epoch: 6| Step: 13
Training loss: 1.9301668405532837
Validation loss: 2.3882984166504233

Epoch: 133| Step: 0
Training loss: 2.53635835647583
Validation loss: 2.3908796336061213

Epoch: 6| Step: 1
Training loss: 3.170599937438965
Validation loss: 2.3942622369335544

Epoch: 6| Step: 2
Training loss: 2.1989943981170654
Validation loss: 2.3952810674585323

Epoch: 6| Step: 3
Training loss: 2.2831156253814697
Validation loss: 2.404518246650696

Epoch: 6| Step: 4
Training loss: 2.558079242706299
Validation loss: 2.391212909452377

Epoch: 6| Step: 5
Training loss: 2.032261848449707
Validation loss: 2.3858817264597905

Epoch: 6| Step: 6
Training loss: 2.778589963912964
Validation loss: 2.3935643908798054

Epoch: 6| Step: 7
Training loss: 2.3975272178649902
Validation loss: 2.389592824443694

Epoch: 6| Step: 8
Training loss: 3.1669669151306152
Validation loss: 2.400128197926347

Epoch: 6| Step: 9
Training loss: 2.8023009300231934
Validation loss: 2.4048142689530567

Epoch: 6| Step: 10
Training loss: 2.214776039123535
Validation loss: 2.4075187816414783

Epoch: 6| Step: 11
Training loss: 2.8611831665039062
Validation loss: 2.4145921122643257

Epoch: 6| Step: 12
Training loss: 3.209257125854492
Validation loss: 2.413335730952601

Epoch: 6| Step: 13
Training loss: 1.9017224311828613
Validation loss: 2.413316261383795

Epoch: 134| Step: 0
Training loss: 2.3877310752868652
Validation loss: 2.409615465389785

Epoch: 6| Step: 1
Training loss: 2.4239892959594727
Validation loss: 2.404811833494453

Epoch: 6| Step: 2
Training loss: 2.628488063812256
Validation loss: 2.3981708839375484

Epoch: 6| Step: 3
Training loss: 2.707559585571289
Validation loss: 2.388791386799146

Epoch: 6| Step: 4
Training loss: 2.2983992099761963
Validation loss: 2.374274771700623

Epoch: 6| Step: 5
Training loss: 2.6770310401916504
Validation loss: 2.384635612528811

Epoch: 6| Step: 6
Training loss: 2.7630996704101562
Validation loss: 2.3877997936741

Epoch: 6| Step: 7
Training loss: 2.3965704441070557
Validation loss: 2.411052021929013

Epoch: 6| Step: 8
Training loss: 2.3349666595458984
Validation loss: 2.4244032982856996

Epoch: 6| Step: 9
Training loss: 3.5196845531463623
Validation loss: 2.47050223042888

Epoch: 6| Step: 10
Training loss: 2.2675535678863525
Validation loss: 2.4698600871588594

Epoch: 6| Step: 11
Training loss: 2.780836820602417
Validation loss: 2.459086964207311

Epoch: 6| Step: 12
Training loss: 2.917337656021118
Validation loss: 2.4264217858673423

Epoch: 6| Step: 13
Training loss: 2.5264790058135986
Validation loss: 2.39585357071251

Epoch: 135| Step: 0
Training loss: 2.495755195617676
Validation loss: 2.369992668910693

Epoch: 6| Step: 1
Training loss: 2.500283718109131
Validation loss: 2.3620180570951073

Epoch: 6| Step: 2
Training loss: 2.8367435932159424
Validation loss: 2.3714430973094

Epoch: 6| Step: 3
Training loss: 2.403550624847412
Validation loss: 2.3830048294477564

Epoch: 6| Step: 4
Training loss: 1.7794252634048462
Validation loss: 2.39675752065515

Epoch: 6| Step: 5
Training loss: 2.5734293460845947
Validation loss: 2.395002941931448

Epoch: 6| Step: 6
Training loss: 2.83613920211792
Validation loss: 2.405271666024321

Epoch: 6| Step: 7
Training loss: 2.580179214477539
Validation loss: 2.415950826419297

Epoch: 6| Step: 8
Training loss: 2.5851635932922363
Validation loss: 2.4145585311356412

Epoch: 6| Step: 9
Training loss: 2.3691353797912598
Validation loss: 2.418937806160219

Epoch: 6| Step: 10
Training loss: 3.058703899383545
Validation loss: 2.4143470436014156

Epoch: 6| Step: 11
Training loss: 3.0521273612976074
Validation loss: 2.4044466249404417

Epoch: 6| Step: 12
Training loss: 2.8232831954956055
Validation loss: 2.4003224911228305

Epoch: 6| Step: 13
Training loss: 2.935305118560791
Validation loss: 2.3968801677867932

Epoch: 136| Step: 0
Training loss: 2.6987128257751465
Validation loss: 2.3880060718905542

Epoch: 6| Step: 1
Training loss: 2.8585309982299805
Validation loss: 2.3832501980566208

Epoch: 6| Step: 2
Training loss: 2.2922444343566895
Validation loss: 2.375520395976241

Epoch: 6| Step: 3
Training loss: 2.026142120361328
Validation loss: 2.37180854171835

Epoch: 6| Step: 4
Training loss: 2.9677910804748535
Validation loss: 2.3736395835876465

Epoch: 6| Step: 5
Training loss: 2.5846714973449707
Validation loss: 2.378146853498233

Epoch: 6| Step: 6
Training loss: 2.2541582584381104
Validation loss: 2.3906864889206423

Epoch: 6| Step: 7
Training loss: 2.6750106811523438
Validation loss: 2.3977475679048927

Epoch: 6| Step: 8
Training loss: 2.596680164337158
Validation loss: 2.413754592659653

Epoch: 6| Step: 9
Training loss: 2.815962314605713
Validation loss: 2.4194547181488364

Epoch: 6| Step: 10
Training loss: 2.8043813705444336
Validation loss: 2.4285041516827

Epoch: 6| Step: 11
Training loss: 2.2268524169921875
Validation loss: 2.421459428725704

Epoch: 6| Step: 12
Training loss: 3.1864805221557617
Validation loss: 2.4153190594847485

Epoch: 6| Step: 13
Training loss: 2.6578800678253174
Validation loss: 2.4011306839604534

Epoch: 137| Step: 0
Training loss: 2.9728941917419434
Validation loss: 2.401781689736151

Epoch: 6| Step: 1
Training loss: 3.625678300857544
Validation loss: 2.3831930339977307

Epoch: 6| Step: 2
Training loss: 2.120758295059204
Validation loss: 2.369973700533631

Epoch: 6| Step: 3
Training loss: 2.90848708152771
Validation loss: 2.3744684855143228

Epoch: 6| Step: 4
Training loss: 2.9407966136932373
Validation loss: 2.376123365535531

Epoch: 6| Step: 5
Training loss: 2.511861562728882
Validation loss: 2.3763668357685046

Epoch: 6| Step: 6
Training loss: 2.159419059753418
Validation loss: 2.372402065543718

Epoch: 6| Step: 7
Training loss: 2.496135711669922
Validation loss: 2.3739661144953903

Epoch: 6| Step: 8
Training loss: 2.249610662460327
Validation loss: 2.37217072004913

Epoch: 6| Step: 9
Training loss: 2.3782455921173096
Validation loss: 2.3672340095684095

Epoch: 6| Step: 10
Training loss: 2.289999485015869
Validation loss: 2.3679299046916347

Epoch: 6| Step: 11
Training loss: 2.1089999675750732
Validation loss: 2.367307734745805

Epoch: 6| Step: 12
Training loss: 3.190436363220215
Validation loss: 2.369645034113238

Epoch: 6| Step: 13
Training loss: 2.4704790115356445
Validation loss: 2.362479338081934

Epoch: 138| Step: 0
Training loss: 2.155611515045166
Validation loss: 2.361812542843562

Epoch: 6| Step: 1
Training loss: 2.3252477645874023
Validation loss: 2.3622037005680863

Epoch: 6| Step: 2
Training loss: 2.5352883338928223
Validation loss: 2.3667029975562968

Epoch: 6| Step: 3
Training loss: 3.5873641967773438
Validation loss: 2.3772967348816576

Epoch: 6| Step: 4
Training loss: 1.9571692943572998
Validation loss: 2.3958557959525817

Epoch: 6| Step: 5
Training loss: 3.0069217681884766
Validation loss: 2.408378157564389

Epoch: 6| Step: 6
Training loss: 2.155327796936035
Validation loss: 2.416711805969156

Epoch: 6| Step: 7
Training loss: 3.303654670715332
Validation loss: 2.4002729385129866

Epoch: 6| Step: 8
Training loss: 2.5002636909484863
Validation loss: 2.4028974912499868

Epoch: 6| Step: 9
Training loss: 3.0216777324676514
Validation loss: 2.392289102718394

Epoch: 6| Step: 10
Training loss: 1.8255985975265503
Validation loss: 2.4039992978495937

Epoch: 6| Step: 11
Training loss: 3.0001425743103027
Validation loss: 2.408472368794103

Epoch: 6| Step: 12
Training loss: 2.64391827583313
Validation loss: 2.3985763903587096

Epoch: 6| Step: 13
Training loss: 2.3197195529937744
Validation loss: 2.400918153024489

Epoch: 139| Step: 0
Training loss: 2.6371021270751953
Validation loss: 2.388735161032728

Epoch: 6| Step: 1
Training loss: 2.7923152446746826
Validation loss: 2.378379629504296

Epoch: 6| Step: 2
Training loss: 2.5877108573913574
Validation loss: 2.3834845378834713

Epoch: 6| Step: 3
Training loss: 2.649428367614746
Validation loss: 2.3795398230193765

Epoch: 6| Step: 4
Training loss: 2.336416482925415
Validation loss: 2.373795732375114

Epoch: 6| Step: 5
Training loss: 1.95554518699646
Validation loss: 2.3708662961118963

Epoch: 6| Step: 6
Training loss: 2.4678118228912354
Validation loss: 2.3719050653519167

Epoch: 6| Step: 7
Training loss: 2.7472527027130127
Validation loss: 2.3642169249955045

Epoch: 6| Step: 8
Training loss: 2.778341770172119
Validation loss: 2.3691558760981404

Epoch: 6| Step: 9
Training loss: 2.423590660095215
Validation loss: 2.3693882829399517

Epoch: 6| Step: 10
Training loss: 2.7141225337982178
Validation loss: 2.3704240065748974

Epoch: 6| Step: 11
Training loss: 2.727022886276245
Validation loss: 2.3733656970403527

Epoch: 6| Step: 12
Training loss: 2.659691572189331
Validation loss: 2.3722552073899137

Epoch: 6| Step: 13
Training loss: 2.974215030670166
Validation loss: 2.3850336485011603

Epoch: 140| Step: 0
Training loss: 2.9769530296325684
Validation loss: 2.37742902258391

Epoch: 6| Step: 1
Training loss: 3.780092239379883
Validation loss: 2.379132729704662

Epoch: 6| Step: 2
Training loss: 2.3073854446411133
Validation loss: 2.3726140517060474

Epoch: 6| Step: 3
Training loss: 2.3922672271728516
Validation loss: 2.3652620674461446

Epoch: 6| Step: 4
Training loss: 2.5081443786621094
Validation loss: 2.370101505710233

Epoch: 6| Step: 5
Training loss: 2.251814365386963
Validation loss: 2.3641468837697017

Epoch: 6| Step: 6
Training loss: 2.8942816257476807
Validation loss: 2.3657705271115868

Epoch: 6| Step: 7
Training loss: 2.4103939533233643
Validation loss: 2.3656352040588216

Epoch: 6| Step: 8
Training loss: 2.6860127449035645
Validation loss: 2.3705991852668022

Epoch: 6| Step: 9
Training loss: 2.2868261337280273
Validation loss: 2.3734280832352175

Epoch: 6| Step: 10
Training loss: 2.8445258140563965
Validation loss: 2.381208148053897

Epoch: 6| Step: 11
Training loss: 1.9612400531768799
Validation loss: 2.3871015400014897

Epoch: 6| Step: 12
Training loss: 2.5970847606658936
Validation loss: 2.4056389780454737

Epoch: 6| Step: 13
Training loss: 2.185237407684326
Validation loss: 2.4057264507457776

Epoch: 141| Step: 0
Training loss: 2.005401849746704
Validation loss: 2.4199937748652633

Epoch: 6| Step: 1
Training loss: 2.3591268062591553
Validation loss: 2.425123865886401

Epoch: 6| Step: 2
Training loss: 3.0979955196380615
Validation loss: 2.4134572218823176

Epoch: 6| Step: 3
Training loss: 2.72225284576416
Validation loss: 2.41796899098222

Epoch: 6| Step: 4
Training loss: 2.8685286045074463
Validation loss: 2.4082649395030034

Epoch: 6| Step: 5
Training loss: 2.5338852405548096
Validation loss: 2.4025939920897126

Epoch: 6| Step: 6
Training loss: 2.076498031616211
Validation loss: 2.393633960395731

Epoch: 6| Step: 7
Training loss: 3.0419445037841797
Validation loss: 2.386757419955346

Epoch: 6| Step: 8
Training loss: 3.559177875518799
Validation loss: 2.3830129100430395

Epoch: 6| Step: 9
Training loss: 2.7810277938842773
Validation loss: 2.3803983939591276

Epoch: 6| Step: 10
Training loss: 2.05766224861145
Validation loss: 2.376896668505925

Epoch: 6| Step: 11
Training loss: 2.6982359886169434
Validation loss: 2.3714868099458757

Epoch: 6| Step: 12
Training loss: 2.0754270553588867
Validation loss: 2.365415269328702

Epoch: 6| Step: 13
Training loss: 2.448639392852783
Validation loss: 2.3691867807860016

Epoch: 142| Step: 0
Training loss: 3.2756295204162598
Validation loss: 2.3653077130676596

Epoch: 6| Step: 1
Training loss: 2.5495433807373047
Validation loss: 2.36434668366627

Epoch: 6| Step: 2
Training loss: 2.942081928253174
Validation loss: 2.361318354965538

Epoch: 6| Step: 3
Training loss: 3.106764793395996
Validation loss: 2.3631907714310514

Epoch: 6| Step: 4
Training loss: 3.1148324012756348
Validation loss: 2.3596180690232145

Epoch: 6| Step: 5
Training loss: 2.4775443077087402
Validation loss: 2.3597095897120814

Epoch: 6| Step: 6
Training loss: 2.439066171646118
Validation loss: 2.358398614391204

Epoch: 6| Step: 7
Training loss: 1.9538156986236572
Validation loss: 2.3574771650375856

Epoch: 6| Step: 8
Training loss: 2.2539236545562744
Validation loss: 2.3507521306314776

Epoch: 6| Step: 9
Training loss: 2.874507188796997
Validation loss: 2.3545757955120457

Epoch: 6| Step: 10
Training loss: 2.2938499450683594
Validation loss: 2.3527366320292153

Epoch: 6| Step: 11
Training loss: 2.299656391143799
Validation loss: 2.3533266846851637

Epoch: 6| Step: 12
Training loss: 2.4891982078552246
Validation loss: 2.357889509970142

Epoch: 6| Step: 13
Training loss: 2.1693294048309326
Validation loss: 2.3558485610510713

Epoch: 143| Step: 0
Training loss: 2.7875571250915527
Validation loss: 2.3612996250070553

Epoch: 6| Step: 1
Training loss: 3.167314052581787
Validation loss: 2.3686404356392483

Epoch: 6| Step: 2
Training loss: 2.639322280883789
Validation loss: 2.37380809937754

Epoch: 6| Step: 3
Training loss: 2.279802083969116
Validation loss: 2.3768773104554866

Epoch: 6| Step: 4
Training loss: 2.653455972671509
Validation loss: 2.3793579968073035

Epoch: 6| Step: 5
Training loss: 2.4390363693237305
Validation loss: 2.38609407794091

Epoch: 6| Step: 6
Training loss: 2.733726978302002
Validation loss: 2.38972980489013

Epoch: 6| Step: 7
Training loss: 2.845764636993408
Validation loss: 2.4009494473857265

Epoch: 6| Step: 8
Training loss: 2.6337714195251465
Validation loss: 2.401662939338274

Epoch: 6| Step: 9
Training loss: 2.4839911460876465
Validation loss: 2.3952303163466917

Epoch: 6| Step: 10
Training loss: 2.50449800491333
Validation loss: 2.389890622067195

Epoch: 6| Step: 11
Training loss: 2.4071526527404785
Validation loss: 2.3929488992178314

Epoch: 6| Step: 12
Training loss: 2.182743787765503
Validation loss: 2.394610002476682

Epoch: 6| Step: 13
Training loss: 2.4394991397857666
Validation loss: 2.3909599524672314

Epoch: 144| Step: 0
Training loss: 3.294102430343628
Validation loss: 2.3867844945640972

Epoch: 6| Step: 1
Training loss: 2.3886184692382812
Validation loss: 2.3837502028352473

Epoch: 6| Step: 2
Training loss: 3.9561855792999268
Validation loss: 2.3782459638452016

Epoch: 6| Step: 3
Training loss: 2.2997217178344727
Validation loss: 2.3830097208740892

Epoch: 6| Step: 4
Training loss: 2.878939151763916
Validation loss: 2.3752192733108357

Epoch: 6| Step: 5
Training loss: 2.091616153717041
Validation loss: 2.370882644448229

Epoch: 6| Step: 6
Training loss: 1.755028247833252
Validation loss: 2.379958155334637

Epoch: 6| Step: 7
Training loss: 2.618229389190674
Validation loss: 2.3817675267496417

Epoch: 6| Step: 8
Training loss: 2.3029069900512695
Validation loss: 2.378796115998299

Epoch: 6| Step: 9
Training loss: 2.2549219131469727
Validation loss: 2.3762280043735298

Epoch: 6| Step: 10
Training loss: 2.1739044189453125
Validation loss: 2.3711833851311797

Epoch: 6| Step: 11
Training loss: 3.0356016159057617
Validation loss: 2.3745828085048224

Epoch: 6| Step: 12
Training loss: 2.4087908267974854
Validation loss: 2.3750270797360327

Epoch: 6| Step: 13
Training loss: 2.696457862854004
Validation loss: 2.3799326240375476

Epoch: 145| Step: 0
Training loss: 1.362255573272705
Validation loss: 2.3731329159070085

Epoch: 6| Step: 1
Training loss: 2.245208740234375
Validation loss: 2.3702251577890046

Epoch: 6| Step: 2
Training loss: 2.6332688331604004
Validation loss: 2.376676933739775

Epoch: 6| Step: 3
Training loss: 2.101057291030884
Validation loss: 2.379794056697558

Epoch: 6| Step: 4
Training loss: 2.9423441886901855
Validation loss: 2.3835233796027397

Epoch: 6| Step: 5
Training loss: 2.8073835372924805
Validation loss: 2.3832256524793562

Epoch: 6| Step: 6
Training loss: 2.4862635135650635
Validation loss: 2.3717961952250493

Epoch: 6| Step: 7
Training loss: 3.0358495712280273
Validation loss: 2.3674344837024646

Epoch: 6| Step: 8
Training loss: 2.9857115745544434
Validation loss: 2.3763315370005946

Epoch: 6| Step: 9
Training loss: 3.4760184288024902
Validation loss: 2.3739815296665316

Epoch: 6| Step: 10
Training loss: 3.0016493797302246
Validation loss: 2.365251633428758

Epoch: 6| Step: 11
Training loss: 2.154362201690674
Validation loss: 2.368518667836343

Epoch: 6| Step: 12
Training loss: 2.227099895477295
Validation loss: 2.370624772963985

Epoch: 6| Step: 13
Training loss: 2.809270143508911
Validation loss: 2.3742877103949107

Epoch: 146| Step: 0
Training loss: 2.4064154624938965
Validation loss: 2.3782463701822425

Epoch: 6| Step: 1
Training loss: 3.3084805011749268
Validation loss: 2.3745796372813563

Epoch: 6| Step: 2
Training loss: 2.460946559906006
Validation loss: 2.380868575906241

Epoch: 6| Step: 3
Training loss: 3.0803048610687256
Validation loss: 2.3738693037340717

Epoch: 6| Step: 4
Training loss: 2.524078369140625
Validation loss: 2.3734737186021704

Epoch: 6| Step: 5
Training loss: 2.915754556655884
Validation loss: 2.3790374366186

Epoch: 6| Step: 6
Training loss: 2.149552822113037
Validation loss: 2.3755763756331576

Epoch: 6| Step: 7
Training loss: 2.1055281162261963
Validation loss: 2.3852941964262273

Epoch: 6| Step: 8
Training loss: 2.2991864681243896
Validation loss: 2.390545678395097

Epoch: 6| Step: 9
Training loss: 2.229524850845337
Validation loss: 2.4007018766095563

Epoch: 6| Step: 10
Training loss: 2.4751675128936768
Validation loss: 2.400229448913246

Epoch: 6| Step: 11
Training loss: 2.345128297805786
Validation loss: 2.3962409983399096

Epoch: 6| Step: 12
Training loss: 3.088590383529663
Validation loss: 2.39381056703547

Epoch: 6| Step: 13
Training loss: 2.7734148502349854
Validation loss: 2.3842934690495974

Epoch: 147| Step: 0
Training loss: 2.5180935859680176
Validation loss: 2.3792077315750944

Epoch: 6| Step: 1
Training loss: 2.7739195823669434
Validation loss: 2.368324774567799

Epoch: 6| Step: 2
Training loss: 2.6430907249450684
Validation loss: 2.3671652629811275

Epoch: 6| Step: 3
Training loss: 2.695868968963623
Validation loss: 2.363130743785571

Epoch: 6| Step: 4
Training loss: 1.7710192203521729
Validation loss: 2.35721484820048

Epoch: 6| Step: 5
Training loss: 3.133608818054199
Validation loss: 2.361217442379203

Epoch: 6| Step: 6
Training loss: 2.9686455726623535
Validation loss: 2.36089329565725

Epoch: 6| Step: 7
Training loss: 3.04295015335083
Validation loss: 2.3654403558341404

Epoch: 6| Step: 8
Training loss: 2.40547513961792
Validation loss: 2.354930308557326

Epoch: 6| Step: 9
Training loss: 1.8630486726760864
Validation loss: 2.3584116787038822

Epoch: 6| Step: 10
Training loss: 2.174546480178833
Validation loss: 2.3614908854166665

Epoch: 6| Step: 11
Training loss: 3.2486538887023926
Validation loss: 2.358715590610299

Epoch: 6| Step: 12
Training loss: 2.161883592605591
Validation loss: 2.3651403265614666

Epoch: 6| Step: 13
Training loss: 2.5736873149871826
Validation loss: 2.374296816446448

Epoch: 148| Step: 0
Training loss: 1.7709145545959473
Validation loss: 2.37044854574306

Epoch: 6| Step: 1
Training loss: 2.534827709197998
Validation loss: 2.3720803145439393

Epoch: 6| Step: 2
Training loss: 3.7037885189056396
Validation loss: 2.372389765195949

Epoch: 6| Step: 3
Training loss: 2.37212872505188
Validation loss: 2.380473482993341

Epoch: 6| Step: 4
Training loss: 1.9771714210510254
Validation loss: 2.3785029713825514

Epoch: 6| Step: 5
Training loss: 2.5698599815368652
Validation loss: 2.387650232161245

Epoch: 6| Step: 6
Training loss: 3.326007843017578
Validation loss: 2.376724209836734

Epoch: 6| Step: 7
Training loss: 2.693704128265381
Validation loss: 2.381014541913104

Epoch: 6| Step: 8
Training loss: 2.956057071685791
Validation loss: 2.3865979204895678

Epoch: 6| Step: 9
Training loss: 2.5296366214752197
Validation loss: 2.3809591160025647

Epoch: 6| Step: 10
Training loss: 1.8975635766983032
Validation loss: 2.3793619140501945

Epoch: 6| Step: 11
Training loss: 3.0357484817504883
Validation loss: 2.366047633591519

Epoch: 6| Step: 12
Training loss: 2.356525421142578
Validation loss: 2.3662248042321976

Epoch: 6| Step: 13
Training loss: 2.2265946865081787
Validation loss: 2.3528309150408675

Epoch: 149| Step: 0
Training loss: 1.7323685884475708
Validation loss: 2.346851876986924

Epoch: 6| Step: 1
Training loss: 3.1078598499298096
Validation loss: 2.350153814079941

Epoch: 6| Step: 2
Training loss: 2.9321231842041016
Validation loss: 2.346807749040665

Epoch: 6| Step: 3
Training loss: 3.178300380706787
Validation loss: 2.348777950450938

Epoch: 6| Step: 4
Training loss: 2.6048946380615234
Validation loss: 2.3479867340416036

Epoch: 6| Step: 5
Training loss: 2.4731674194335938
Validation loss: 2.3448891075708533

Epoch: 6| Step: 6
Training loss: 2.28191876411438
Validation loss: 2.3578063339315434

Epoch: 6| Step: 7
Training loss: 3.2961831092834473
Validation loss: 2.359736070838026

Epoch: 6| Step: 8
Training loss: 2.490652084350586
Validation loss: 2.3612980509317048

Epoch: 6| Step: 9
Training loss: 2.078727960586548
Validation loss: 2.3677959980503207

Epoch: 6| Step: 10
Training loss: 2.4739644527435303
Validation loss: 2.37344168847607

Epoch: 6| Step: 11
Training loss: 2.8818159103393555
Validation loss: 2.3721961180369058

Epoch: 6| Step: 12
Training loss: 2.2743754386901855
Validation loss: 2.3770665148253083

Epoch: 6| Step: 13
Training loss: 2.1489028930664062
Validation loss: 2.3769025084792927

Epoch: 150| Step: 0
Training loss: 1.9577233791351318
Validation loss: 2.384412593739007

Epoch: 6| Step: 1
Training loss: 3.3280014991760254
Validation loss: 2.3886275265806463

Epoch: 6| Step: 2
Training loss: 2.2888083457946777
Validation loss: 2.3844972605346353

Epoch: 6| Step: 3
Training loss: 3.0798797607421875
Validation loss: 2.386824346357776

Epoch: 6| Step: 4
Training loss: 1.925256371498108
Validation loss: 2.387722287126767

Epoch: 6| Step: 5
Training loss: 3.57186222076416
Validation loss: 2.391603005829678

Epoch: 6| Step: 6
Training loss: 2.356441020965576
Validation loss: 2.39699807218326

Epoch: 6| Step: 7
Training loss: 2.665940523147583
Validation loss: 2.3960421085357666

Epoch: 6| Step: 8
Training loss: 2.751297950744629
Validation loss: 2.3965443539363083

Epoch: 6| Step: 9
Training loss: 2.4178261756896973
Validation loss: 2.387903615992556

Epoch: 6| Step: 10
Training loss: 2.162410020828247
Validation loss: 2.390109169867731

Epoch: 6| Step: 11
Training loss: 2.416217803955078
Validation loss: 2.3736341281603743

Epoch: 6| Step: 12
Training loss: 2.417320966720581
Validation loss: 2.371325636422762

Epoch: 6| Step: 13
Training loss: 2.7035562992095947
Validation loss: 2.370171352099347

Testing loss: 2.539523246553209
