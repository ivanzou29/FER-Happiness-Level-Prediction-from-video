Epoch: 1| Step: 0
Training loss: 4.781455993652344
Validation loss: 5.218759649543352

Epoch: 6| Step: 1
Training loss: 5.32634162902832
Validation loss: 5.212891558165191

Epoch: 6| Step: 2
Training loss: 4.450222969055176
Validation loss: 5.207270012106947

Epoch: 6| Step: 3
Training loss: 4.6342267990112305
Validation loss: 5.201494580955916

Epoch: 6| Step: 4
Training loss: 4.795130729675293
Validation loss: 5.196297512259535

Epoch: 6| Step: 5
Training loss: 5.02388858795166
Validation loss: 5.190556177528956

Epoch: 6| Step: 6
Training loss: 4.344456672668457
Validation loss: 5.185338574071085

Epoch: 6| Step: 7
Training loss: 5.566931247711182
Validation loss: 5.1797361220082925

Epoch: 6| Step: 8
Training loss: 5.115549087524414
Validation loss: 5.174268635370398

Epoch: 6| Step: 9
Training loss: 4.957462310791016
Validation loss: 5.168573676898915

Epoch: 6| Step: 10
Training loss: 5.671811103820801
Validation loss: 5.162091870461741

Epoch: 6| Step: 11
Training loss: 4.985702037811279
Validation loss: 5.155569363665837

Epoch: 6| Step: 12
Training loss: 4.391809463500977
Validation loss: 5.14840716187672

Epoch: 6| Step: 13
Training loss: 6.156479835510254
Validation loss: 5.141233772359868

Epoch: 2| Step: 0
Training loss: 4.6023359298706055
Validation loss: 5.1336255688821115

Epoch: 6| Step: 1
Training loss: 5.275515556335449
Validation loss: 5.124965196014733

Epoch: 6| Step: 2
Training loss: 4.231653213500977
Validation loss: 5.116075638801821

Epoch: 6| Step: 3
Training loss: 4.774084091186523
Validation loss: 5.107095056964505

Epoch: 6| Step: 4
Training loss: 5.63597297668457
Validation loss: 5.097423245829921

Epoch: 6| Step: 5
Training loss: 4.814857006072998
Validation loss: 5.086417331490465

Epoch: 6| Step: 6
Training loss: 5.110659599304199
Validation loss: 5.075193917879495

Epoch: 6| Step: 7
Training loss: 4.7193708419799805
Validation loss: 5.063349805852418

Epoch: 6| Step: 8
Training loss: 4.860982894897461
Validation loss: 5.051724967136178

Epoch: 6| Step: 9
Training loss: 4.233002662658691
Validation loss: 5.0398129596505115

Epoch: 6| Step: 10
Training loss: 4.768556594848633
Validation loss: 5.027291554276661

Epoch: 6| Step: 11
Training loss: 5.51407527923584
Validation loss: 5.012862179868964

Epoch: 6| Step: 12
Training loss: 5.7457146644592285
Validation loss: 4.998573375004594

Epoch: 6| Step: 13
Training loss: 2.9034056663513184
Validation loss: 4.984214423805155

Epoch: 3| Step: 0
Training loss: 4.819456100463867
Validation loss: 4.968763777004775

Epoch: 6| Step: 1
Training loss: 3.764047145843506
Validation loss: 4.953920005470194

Epoch: 6| Step: 2
Training loss: 5.485655784606934
Validation loss: 4.936781344875213

Epoch: 6| Step: 3
Training loss: 3.2042558193206787
Validation loss: 4.919917306592388

Epoch: 6| Step: 4
Training loss: 5.206049919128418
Validation loss: 4.902731833919402

Epoch: 6| Step: 5
Training loss: 5.195276260375977
Validation loss: 4.884533430940362

Epoch: 6| Step: 6
Training loss: 4.96339225769043
Validation loss: 4.8654274017580095

Epoch: 6| Step: 7
Training loss: 4.592891693115234
Validation loss: 4.847565789376536

Epoch: 6| Step: 8
Training loss: 4.433600425720215
Validation loss: 4.8274371085628385

Epoch: 6| Step: 9
Training loss: 5.544647216796875
Validation loss: 4.80723213893111

Epoch: 6| Step: 10
Training loss: 4.8802595138549805
Validation loss: 4.785534294702673

Epoch: 6| Step: 11
Training loss: 4.0588483810424805
Validation loss: 4.763787151664816

Epoch: 6| Step: 12
Training loss: 3.6842823028564453
Validation loss: 4.740816229133196

Epoch: 6| Step: 13
Training loss: 5.557048797607422
Validation loss: 4.7177477857118015

Epoch: 4| Step: 0
Training loss: 4.109488487243652
Validation loss: 4.694098800741216

Epoch: 6| Step: 1
Training loss: 3.167412519454956
Validation loss: 4.670225981743105

Epoch: 6| Step: 2
Training loss: 4.685933589935303
Validation loss: 4.644704131669895

Epoch: 6| Step: 3
Training loss: 3.694518804550171
Validation loss: 4.620668580455165

Epoch: 6| Step: 4
Training loss: 4.724616050720215
Validation loss: 4.5953307767068186

Epoch: 6| Step: 5
Training loss: 4.263588905334473
Validation loss: 4.569731297031526

Epoch: 6| Step: 6
Training loss: 5.536452293395996
Validation loss: 4.54415685643432

Epoch: 6| Step: 7
Training loss: 4.141257286071777
Validation loss: 4.51795087322112

Epoch: 6| Step: 8
Training loss: 4.111527442932129
Validation loss: 4.490747497927758

Epoch: 6| Step: 9
Training loss: 4.744053840637207
Validation loss: 4.463976019172258

Epoch: 6| Step: 10
Training loss: 4.706354141235352
Validation loss: 4.436932574036301

Epoch: 6| Step: 11
Training loss: 4.657525062561035
Validation loss: 4.4104508174363

Epoch: 6| Step: 12
Training loss: 4.181858062744141
Validation loss: 4.380833548884238

Epoch: 6| Step: 13
Training loss: 3.192466974258423
Validation loss: 4.353447175795032

Epoch: 5| Step: 0
Training loss: 2.694047451019287
Validation loss: 4.326987563922841

Epoch: 6| Step: 1
Training loss: 4.788605690002441
Validation loss: 4.297493145030032

Epoch: 6| Step: 2
Training loss: 3.840449810028076
Validation loss: 4.2687493754971415

Epoch: 6| Step: 3
Training loss: 5.40384578704834
Validation loss: 4.24175166058284

Epoch: 6| Step: 4
Training loss: 3.628920555114746
Validation loss: 4.215188575047319

Epoch: 6| Step: 5
Training loss: 3.1406874656677246
Validation loss: 4.185130144960137

Epoch: 6| Step: 6
Training loss: 4.28141450881958
Validation loss: 4.158587737749982

Epoch: 6| Step: 7
Training loss: 4.219635486602783
Validation loss: 4.133170268868887

Epoch: 6| Step: 8
Training loss: 4.404390335083008
Validation loss: 4.10846350526297

Epoch: 6| Step: 9
Training loss: 4.025411605834961
Validation loss: 4.084526838794831

Epoch: 6| Step: 10
Training loss: 3.1771371364593506
Validation loss: 4.060089365128548

Epoch: 6| Step: 11
Training loss: 3.8053300380706787
Validation loss: 4.038235187530518

Epoch: 6| Step: 12
Training loss: 4.402578353881836
Validation loss: 4.017624306422408

Epoch: 6| Step: 13
Training loss: 3.714548349380493
Validation loss: 3.9980437268492994

Epoch: 6| Step: 0
Training loss: 4.4227614402771
Validation loss: 3.9787395026094172

Epoch: 6| Step: 1
Training loss: 4.141731262207031
Validation loss: 3.9591441333934827

Epoch: 6| Step: 2
Training loss: 4.2664408683776855
Validation loss: 3.9402296978940248

Epoch: 6| Step: 3
Training loss: 3.340397357940674
Validation loss: 3.9220902073767876

Epoch: 6| Step: 4
Training loss: 4.560728073120117
Validation loss: 3.902334449111774

Epoch: 6| Step: 5
Training loss: 2.679306745529175
Validation loss: 3.887244160457324

Epoch: 6| Step: 6
Training loss: 3.8270912170410156
Validation loss: 3.869526452915643

Epoch: 6| Step: 7
Training loss: 3.8182754516601562
Validation loss: 3.855205223124514

Epoch: 6| Step: 8
Training loss: 3.3087122440338135
Validation loss: 3.8394458447733233

Epoch: 6| Step: 9
Training loss: 4.109776973724365
Validation loss: 3.825782258023498

Epoch: 6| Step: 10
Training loss: 4.689839839935303
Validation loss: 3.8137988813461794

Epoch: 6| Step: 11
Training loss: 1.9226138591766357
Validation loss: 3.799606056623561

Epoch: 6| Step: 12
Training loss: 3.1880688667297363
Validation loss: 3.7887809558581282

Epoch: 6| Step: 13
Training loss: 4.503366470336914
Validation loss: 3.779459786671464

Epoch: 7| Step: 0
Training loss: 4.013360977172852
Validation loss: 3.765007116461313

Epoch: 6| Step: 1
Training loss: 3.2642593383789062
Validation loss: 3.7572507166093394

Epoch: 6| Step: 2
Training loss: 3.019558906555176
Validation loss: 3.7444443548879316

Epoch: 6| Step: 3
Training loss: 3.3916971683502197
Validation loss: 3.7349793270070064

Epoch: 6| Step: 4
Training loss: 3.655257225036621
Validation loss: 3.725763008158694

Epoch: 6| Step: 5
Training loss: 4.031550884246826
Validation loss: 3.716432553465648

Epoch: 6| Step: 6
Training loss: 4.08107328414917
Validation loss: 3.707295569040442

Epoch: 6| Step: 7
Training loss: 4.484336853027344
Validation loss: 3.6996921518797516

Epoch: 6| Step: 8
Training loss: 3.8788905143737793
Validation loss: 3.690830017930718

Epoch: 6| Step: 9
Training loss: 3.5880298614501953
Validation loss: 3.683078699214484

Epoch: 6| Step: 10
Training loss: 2.578087568283081
Validation loss: 3.6739464216334845

Epoch: 6| Step: 11
Training loss: 3.3343405723571777
Validation loss: 3.6659669235188472

Epoch: 6| Step: 12
Training loss: 3.988497257232666
Validation loss: 3.6580753480234454

Epoch: 6| Step: 13
Training loss: 2.883610725402832
Validation loss: 3.6498753537413893

Epoch: 8| Step: 0
Training loss: 3.7657394409179688
Validation loss: 3.6417875700099493

Epoch: 6| Step: 1
Training loss: 2.467874050140381
Validation loss: 3.6326557846479517

Epoch: 6| Step: 2
Training loss: 3.9807894229888916
Validation loss: 3.624671895016906

Epoch: 6| Step: 3
Training loss: 3.1527791023254395
Validation loss: 3.6171286285564466

Epoch: 6| Step: 4
Training loss: 4.027246952056885
Validation loss: 3.604818405643586

Epoch: 6| Step: 5
Training loss: 4.016262531280518
Validation loss: 3.5916697107335573

Epoch: 6| Step: 6
Training loss: 3.2556755542755127
Validation loss: 3.568804863960512

Epoch: 6| Step: 7
Training loss: 3.262063980102539
Validation loss: 3.559300317559191

Epoch: 6| Step: 8
Training loss: 3.873002052307129
Validation loss: 3.5517802828101703

Epoch: 6| Step: 9
Training loss: 3.774289608001709
Validation loss: 3.543843315493676

Epoch: 6| Step: 10
Training loss: 2.8724889755249023
Validation loss: 3.536399707999281

Epoch: 6| Step: 11
Training loss: 3.972733974456787
Validation loss: 3.529811643785046

Epoch: 6| Step: 12
Training loss: 3.1703455448150635
Validation loss: 3.5222878533024944

Epoch: 6| Step: 13
Training loss: 3.1554384231567383
Validation loss: 3.516027045506303

Epoch: 9| Step: 0
Training loss: 4.1616315841674805
Validation loss: 3.509629403391192

Epoch: 6| Step: 1
Training loss: 3.1168575286865234
Validation loss: 3.5061526836887484

Epoch: 6| Step: 2
Training loss: 3.070490598678589
Validation loss: 3.4970218212373796

Epoch: 6| Step: 3
Training loss: 3.324037551879883
Validation loss: 3.4925861871370705

Epoch: 6| Step: 4
Training loss: 3.212491035461426
Validation loss: 3.483729898288686

Epoch: 6| Step: 5
Training loss: 4.462076187133789
Validation loss: 3.477343184973604

Epoch: 6| Step: 6
Training loss: 2.6684980392456055
Validation loss: 3.468971090932046

Epoch: 6| Step: 7
Training loss: 3.3528261184692383
Validation loss: 3.4608201801135974

Epoch: 6| Step: 8
Training loss: 3.052992820739746
Validation loss: 3.4558049786475395

Epoch: 6| Step: 9
Training loss: 3.321364164352417
Validation loss: 3.4494655234839326

Epoch: 6| Step: 10
Training loss: 3.352933406829834
Validation loss: 3.442618323910621

Epoch: 6| Step: 11
Training loss: 3.5797276496887207
Validation loss: 3.438863085162255

Epoch: 6| Step: 12
Training loss: 3.800736904144287
Validation loss: 3.433344038583899

Epoch: 6| Step: 13
Training loss: 2.9979546070098877
Validation loss: 3.4287566164488434

Epoch: 10| Step: 0
Training loss: 3.6778674125671387
Validation loss: 3.429865739678824

Epoch: 6| Step: 1
Training loss: 2.7044620513916016
Validation loss: 3.4210388686067317

Epoch: 6| Step: 2
Training loss: 3.2771432399749756
Validation loss: 3.409699498966176

Epoch: 6| Step: 3
Training loss: 2.25708270072937
Validation loss: 3.400965408612323

Epoch: 6| Step: 4
Training loss: 2.659874439239502
Validation loss: 3.395680414733066

Epoch: 6| Step: 5
Training loss: 3.1792659759521484
Validation loss: 3.394577175058344

Epoch: 6| Step: 6
Training loss: 3.0584681034088135
Validation loss: 3.3886348765383483

Epoch: 6| Step: 7
Training loss: 4.288567543029785
Validation loss: 3.3841506332479496

Epoch: 6| Step: 8
Training loss: 3.4110465049743652
Validation loss: 3.3791943237345707

Epoch: 6| Step: 9
Training loss: 2.8608062267303467
Validation loss: 3.3731591727143977

Epoch: 6| Step: 10
Training loss: 4.286435604095459
Validation loss: 3.371012777410528

Epoch: 6| Step: 11
Training loss: 4.009702205657959
Validation loss: 3.366354742357808

Epoch: 6| Step: 12
Training loss: 4.0440993309021
Validation loss: 3.363008288926976

Epoch: 6| Step: 13
Training loss: 2.844041585922241
Validation loss: 3.3587562678962626

Epoch: 11| Step: 0
Training loss: 2.2430877685546875
Validation loss: 3.352819001802834

Epoch: 6| Step: 1
Training loss: 3.517003059387207
Validation loss: 3.3485235783361618

Epoch: 6| Step: 2
Training loss: 3.4535071849823
Validation loss: 3.345357561624178

Epoch: 6| Step: 3
Training loss: 4.1426239013671875
Validation loss: 3.3405514327428674

Epoch: 6| Step: 4
Training loss: 4.559726715087891
Validation loss: 3.33647257538252

Epoch: 6| Step: 5
Training loss: 4.056262016296387
Validation loss: 3.3320715555580716

Epoch: 6| Step: 6
Training loss: 3.020003080368042
Validation loss: 3.3303705876873386

Epoch: 6| Step: 7
Training loss: 2.869520664215088
Validation loss: 3.3271996718581005

Epoch: 6| Step: 8
Training loss: 3.7733287811279297
Validation loss: 3.3229662244037916

Epoch: 6| Step: 9
Training loss: 3.1611135005950928
Validation loss: 3.3221351100552465

Epoch: 6| Step: 10
Training loss: 2.7120604515075684
Validation loss: 3.3160813905859507

Epoch: 6| Step: 11
Training loss: 2.9265708923339844
Validation loss: 3.3170287737282376

Epoch: 6| Step: 12
Training loss: 2.567899227142334
Validation loss: 3.307270311540173

Epoch: 6| Step: 13
Training loss: 2.9565861225128174
Validation loss: 3.3038789995255007

Epoch: 12| Step: 0
Training loss: 4.150707721710205
Validation loss: 3.301756748589136

Epoch: 6| Step: 1
Training loss: 3.3515334129333496
Validation loss: 3.30032241728998

Epoch: 6| Step: 2
Training loss: 3.114226818084717
Validation loss: 3.297054265135078

Epoch: 6| Step: 3
Training loss: 3.481992483139038
Validation loss: 3.293386761860181

Epoch: 6| Step: 4
Training loss: 2.7272744178771973
Validation loss: 3.2868804931640625

Epoch: 6| Step: 5
Training loss: 3.040254592895508
Validation loss: 3.286473415231192

Epoch: 6| Step: 6
Training loss: 2.696934223175049
Validation loss: 3.282187395198371

Epoch: 6| Step: 7
Training loss: 3.9111804962158203
Validation loss: 3.281763699746901

Epoch: 6| Step: 8
Training loss: 2.978029727935791
Validation loss: 3.2759337348322712

Epoch: 6| Step: 9
Training loss: 1.9786401987075806
Validation loss: 3.275424829093359

Epoch: 6| Step: 10
Training loss: 3.9183857440948486
Validation loss: 3.275977211613809

Epoch: 6| Step: 11
Training loss: 3.8832733631134033
Validation loss: 3.2684437049332487

Epoch: 6| Step: 12
Training loss: 2.587423801422119
Validation loss: 3.266446887805898

Epoch: 6| Step: 13
Training loss: 4.154714107513428
Validation loss: 3.263463371543474

Epoch: 13| Step: 0
Training loss: 2.362612724304199
Validation loss: 3.2595326439026864

Epoch: 6| Step: 1
Training loss: 3.044184684753418
Validation loss: 3.2559939404969573

Epoch: 6| Step: 2
Training loss: 3.5392861366271973
Validation loss: 3.2548533306326917

Epoch: 6| Step: 3
Training loss: 2.9702115058898926
Validation loss: 3.2512016757842033

Epoch: 6| Step: 4
Training loss: 2.4632575511932373
Validation loss: 3.2499570590193554

Epoch: 6| Step: 5
Training loss: 2.8915514945983887
Validation loss: 3.2460488221978627

Epoch: 6| Step: 6
Training loss: 4.205630302429199
Validation loss: 3.244059242228026

Epoch: 6| Step: 7
Training loss: 3.678363800048828
Validation loss: 3.2452077070871987

Epoch: 6| Step: 8
Training loss: 2.746332883834839
Validation loss: 3.2535502115885415

Epoch: 6| Step: 9
Training loss: 4.39569091796875
Validation loss: 3.248151333101334

Epoch: 6| Step: 10
Training loss: 3.0545871257781982
Validation loss: 3.24169006142565

Epoch: 6| Step: 11
Training loss: 3.4886984825134277
Validation loss: 3.235793544400123

Epoch: 6| Step: 12
Training loss: 3.1904866695404053
Validation loss: 3.2347579822745374

Epoch: 6| Step: 13
Training loss: 3.1706881523132324
Validation loss: 3.2315630605143886

Epoch: 14| Step: 0
Training loss: 2.985640048980713
Validation loss: 3.231896323542441

Epoch: 6| Step: 1
Training loss: 3.041738510131836
Validation loss: 3.2277907248466247

Epoch: 6| Step: 2
Training loss: 2.84506893157959
Validation loss: 3.225686816759007

Epoch: 6| Step: 3
Training loss: 3.198483467102051
Validation loss: 3.2253321319498043

Epoch: 6| Step: 4
Training loss: 4.112725734710693
Validation loss: 3.2223843323287142

Epoch: 6| Step: 5
Training loss: 3.5536866188049316
Validation loss: 3.2217501235264603

Epoch: 6| Step: 6
Training loss: 3.05631685256958
Validation loss: 3.2183200133744108

Epoch: 6| Step: 7
Training loss: 3.0345852375030518
Validation loss: 3.2135708690971456

Epoch: 6| Step: 8
Training loss: 3.6718270778656006
Validation loss: 3.211553919699884

Epoch: 6| Step: 9
Training loss: 3.4653820991516113
Validation loss: 3.2079281627490954

Epoch: 6| Step: 10
Training loss: 2.111663341522217
Validation loss: 3.2041146832127727

Epoch: 6| Step: 11
Training loss: 3.7504186630249023
Validation loss: 3.201385813374673

Epoch: 6| Step: 12
Training loss: 2.796489953994751
Validation loss: 3.1996105947802143

Epoch: 6| Step: 13
Training loss: 3.3426475524902344
Validation loss: 3.1978306719051894

Epoch: 15| Step: 0
Training loss: 3.0850958824157715
Validation loss: 3.1983412337559525

Epoch: 6| Step: 1
Training loss: 2.3531689643859863
Validation loss: 3.1920059727084253

Epoch: 6| Step: 2
Training loss: 3.214026689529419
Validation loss: 3.1918146738442044

Epoch: 6| Step: 3
Training loss: 2.878081798553467
Validation loss: 3.1892414016108357

Epoch: 6| Step: 4
Training loss: 3.2004191875457764
Validation loss: 3.1883079672372467

Epoch: 6| Step: 5
Training loss: 2.9297051429748535
Validation loss: 3.186858897568077

Epoch: 6| Step: 6
Training loss: 3.4636995792388916
Validation loss: 3.1945560773213706

Epoch: 6| Step: 7
Training loss: 1.612754225730896
Validation loss: 3.202958973505164

Epoch: 6| Step: 8
Training loss: 3.49129581451416
Validation loss: 3.2276826597029165

Epoch: 6| Step: 9
Training loss: 3.301705837249756
Validation loss: 3.21146152352774

Epoch: 6| Step: 10
Training loss: 4.548861503601074
Validation loss: 3.17783522605896

Epoch: 6| Step: 11
Training loss: 3.66852068901062
Validation loss: 3.176471289768014

Epoch: 6| Step: 12
Training loss: 2.9967026710510254
Validation loss: 3.1724896661696897

Epoch: 6| Step: 13
Training loss: 4.549711227416992
Validation loss: 3.182645031200942

Epoch: 16| Step: 0
Training loss: 3.2027125358581543
Validation loss: 3.1705517204858924

Epoch: 6| Step: 1
Training loss: 2.4762585163116455
Validation loss: 3.1718017721688874

Epoch: 6| Step: 2
Training loss: 3.7162981033325195
Validation loss: 3.1739055161835044

Epoch: 6| Step: 3
Training loss: 3.3161211013793945
Validation loss: 3.170634538896622

Epoch: 6| Step: 4
Training loss: 2.8823087215423584
Validation loss: 3.1733878427936184

Epoch: 6| Step: 5
Training loss: 3.505957841873169
Validation loss: 3.181772744783791

Epoch: 6| Step: 6
Training loss: 2.8460850715637207
Validation loss: 3.188095187628141

Epoch: 6| Step: 7
Training loss: 3.2382779121398926
Validation loss: 3.1797248163530902

Epoch: 6| Step: 8
Training loss: 2.8224525451660156
Validation loss: 3.1725278439060336

Epoch: 6| Step: 9
Training loss: 3.2329039573669434
Validation loss: 3.168411857338362

Epoch: 6| Step: 10
Training loss: 2.2971010208129883
Validation loss: 3.1630824201850483

Epoch: 6| Step: 11
Training loss: 3.299659013748169
Validation loss: 3.161028556926276

Epoch: 6| Step: 12
Training loss: 3.910609483718872
Validation loss: 3.159428350387081

Epoch: 6| Step: 13
Training loss: 4.163898944854736
Validation loss: 3.1565526429043023

Epoch: 17| Step: 0
Training loss: 4.137923240661621
Validation loss: 3.1539601638752925

Epoch: 6| Step: 1
Training loss: 3.388302803039551
Validation loss: 3.1527203872639644

Epoch: 6| Step: 2
Training loss: 2.5066170692443848
Validation loss: 3.149836835040841

Epoch: 6| Step: 3
Training loss: 4.427136421203613
Validation loss: 3.146732694359236

Epoch: 6| Step: 4
Training loss: 2.9665727615356445
Validation loss: 3.143384859126101

Epoch: 6| Step: 5
Training loss: 2.69873309135437
Validation loss: 3.1436765014484362

Epoch: 6| Step: 6
Training loss: 3.068854808807373
Validation loss: 3.1428697775768977

Epoch: 6| Step: 7
Training loss: 2.0777249336242676
Validation loss: 3.1399427921541276

Epoch: 6| Step: 8
Training loss: 3.0040273666381836
Validation loss: 3.140598063827843

Epoch: 6| Step: 9
Training loss: 3.2298519611358643
Validation loss: 3.141133213555941

Epoch: 6| Step: 10
Training loss: 3.8270506858825684
Validation loss: 3.1385794531914497

Epoch: 6| Step: 11
Training loss: 2.7103824615478516
Validation loss: 3.1354667653319654

Epoch: 6| Step: 12
Training loss: 2.907985210418701
Validation loss: 3.1350356865954656

Epoch: 6| Step: 13
Training loss: 3.3138575553894043
Validation loss: 3.1317458178407405

Epoch: 18| Step: 0
Training loss: 2.420057535171509
Validation loss: 3.1312910074828775

Epoch: 6| Step: 1
Training loss: 3.152928590774536
Validation loss: 3.12684569820281

Epoch: 6| Step: 2
Training loss: 3.0577263832092285
Validation loss: 3.1259875015545915

Epoch: 6| Step: 3
Training loss: 4.116491794586182
Validation loss: 3.128405401783605

Epoch: 6| Step: 4
Training loss: 1.71014404296875
Validation loss: 3.122797725021198

Epoch: 6| Step: 5
Training loss: 3.6854560375213623
Validation loss: 3.1166383425394693

Epoch: 6| Step: 6
Training loss: 3.0194835662841797
Validation loss: 3.1175522573532595

Epoch: 6| Step: 7
Training loss: 2.6291356086730957
Validation loss: 3.116854360026698

Epoch: 6| Step: 8
Training loss: 3.5318548679351807
Validation loss: 3.111353361478416

Epoch: 6| Step: 9
Training loss: 2.9322385787963867
Validation loss: 3.10883266182356

Epoch: 6| Step: 10
Training loss: 3.1235294342041016
Validation loss: 3.108865394387194

Epoch: 6| Step: 11
Training loss: 3.8975963592529297
Validation loss: 3.1036603322593113

Epoch: 6| Step: 12
Training loss: 3.633728265762329
Validation loss: 3.10252627506051

Epoch: 6| Step: 13
Training loss: 2.8767025470733643
Validation loss: 3.0994534287401425

Epoch: 19| Step: 0
Training loss: 1.8286253213882446
Validation loss: 3.104000650426393

Epoch: 6| Step: 1
Training loss: 2.5321996212005615
Validation loss: 3.0975383635490172

Epoch: 6| Step: 2
Training loss: 3.9956159591674805
Validation loss: 3.0972003885494765

Epoch: 6| Step: 3
Training loss: 2.435194253921509
Validation loss: 3.0962347907404744

Epoch: 6| Step: 4
Training loss: 2.9920482635498047
Validation loss: 3.0975399068606797

Epoch: 6| Step: 5
Training loss: 3.308259963989258
Validation loss: 3.0943584903593986

Epoch: 6| Step: 6
Training loss: 2.832512855529785
Validation loss: 3.097499524393389

Epoch: 6| Step: 7
Training loss: 3.4498331546783447
Validation loss: 3.097048182641306

Epoch: 6| Step: 8
Training loss: 2.976924419403076
Validation loss: 3.096397287102156

Epoch: 6| Step: 9
Training loss: 3.545114755630493
Validation loss: 3.094963824877175

Epoch: 6| Step: 10
Training loss: 4.3379621505737305
Validation loss: 3.0924795468648276

Epoch: 6| Step: 11
Training loss: 3.5588903427124023
Validation loss: 3.0893987455675678

Epoch: 6| Step: 12
Training loss: 2.2814345359802246
Validation loss: 3.085330791370843

Epoch: 6| Step: 13
Training loss: 4.040315628051758
Validation loss: 3.0811738993531916

Epoch: 20| Step: 0
Training loss: 3.1104164123535156
Validation loss: 3.075410996713946

Epoch: 6| Step: 1
Training loss: 3.398073673248291
Validation loss: 3.0794357253659155

Epoch: 6| Step: 2
Training loss: 2.882960319519043
Validation loss: 3.0767035202313493

Epoch: 6| Step: 3
Training loss: 2.939270496368408
Validation loss: 3.0723657479850193

Epoch: 6| Step: 4
Training loss: 2.8119359016418457
Validation loss: 3.0699614299240934

Epoch: 6| Step: 5
Training loss: 4.300536155700684
Validation loss: 3.067544106514223

Epoch: 6| Step: 6
Training loss: 2.7098917961120605
Validation loss: 3.0679694708957466

Epoch: 6| Step: 7
Training loss: 2.389087677001953
Validation loss: 3.065199985299059

Epoch: 6| Step: 8
Training loss: 3.230419635772705
Validation loss: 3.062323647160684

Epoch: 6| Step: 9
Training loss: 3.4400532245635986
Validation loss: 3.071142191527992

Epoch: 6| Step: 10
Training loss: 3.2837841510772705
Validation loss: 3.070552133744763

Epoch: 6| Step: 11
Training loss: 2.412424087524414
Validation loss: 3.063365346641951

Epoch: 6| Step: 12
Training loss: 3.804856777191162
Validation loss: 3.064003518832627

Epoch: 6| Step: 13
Training loss: 2.4814610481262207
Validation loss: 3.0604572167960544

Epoch: 21| Step: 0
Training loss: 2.992567539215088
Validation loss: 3.060186847563713

Epoch: 6| Step: 1
Training loss: 3.6509928703308105
Validation loss: 3.0520684411448817

Epoch: 6| Step: 2
Training loss: 2.7127883434295654
Validation loss: 3.0462772436039423

Epoch: 6| Step: 3
Training loss: 2.654038429260254
Validation loss: 3.044900027654504

Epoch: 6| Step: 4
Training loss: 2.572272300720215
Validation loss: 3.0431224940925516

Epoch: 6| Step: 5
Training loss: 3.2667651176452637
Validation loss: 3.0403603199989564

Epoch: 6| Step: 6
Training loss: 2.936546802520752
Validation loss: 3.040825964302145

Epoch: 6| Step: 7
Training loss: 3.0520100593566895
Validation loss: 3.03994232608426

Epoch: 6| Step: 8
Training loss: 4.183878421783447
Validation loss: 3.0384851732561664

Epoch: 6| Step: 9
Training loss: 2.7255678176879883
Validation loss: 3.037300027826781

Epoch: 6| Step: 10
Training loss: 2.8661863803863525
Validation loss: 3.037084707649805

Epoch: 6| Step: 11
Training loss: 3.1838977336883545
Validation loss: 3.033750646857805

Epoch: 6| Step: 12
Training loss: 2.7200369834899902
Validation loss: 3.0316088430343138

Epoch: 6| Step: 13
Training loss: 4.242864608764648
Validation loss: 3.0333420871406473

Epoch: 22| Step: 0
Training loss: 3.6396327018737793
Validation loss: 3.0317397886706936

Epoch: 6| Step: 1
Training loss: 2.1232526302337646
Validation loss: 3.0320890718890774

Epoch: 6| Step: 2
Training loss: 3.2289159297943115
Validation loss: 3.03300565801641

Epoch: 6| Step: 3
Training loss: 2.852362632751465
Validation loss: 3.042912485778973

Epoch: 6| Step: 4
Training loss: 3.660572052001953
Validation loss: 3.039726887979815

Epoch: 6| Step: 5
Training loss: 3.0640201568603516
Validation loss: 3.0333948853195354

Epoch: 6| Step: 6
Training loss: 3.0770490169525146
Validation loss: 3.0265613960963424

Epoch: 6| Step: 7
Training loss: 2.206627368927002
Validation loss: 3.0223995203612954

Epoch: 6| Step: 8
Training loss: 3.7760682106018066
Validation loss: 3.0159349056982223

Epoch: 6| Step: 9
Training loss: 3.0292809009552
Validation loss: 3.0186724483325915

Epoch: 6| Step: 10
Training loss: 4.1646881103515625
Validation loss: 3.014682310883717

Epoch: 6| Step: 11
Training loss: 2.161895275115967
Validation loss: 3.013829979845273

Epoch: 6| Step: 12
Training loss: 3.7497291564941406
Validation loss: 3.0114959747560563

Epoch: 6| Step: 13
Training loss: 1.7406938076019287
Validation loss: 3.0156277533500426

Epoch: 23| Step: 0
Training loss: 3.3667099475860596
Validation loss: 3.0235636875193608

Epoch: 6| Step: 1
Training loss: 2.8768885135650635
Validation loss: 3.0311244790272047

Epoch: 6| Step: 2
Training loss: 3.273655414581299
Validation loss: 3.0197034138505177

Epoch: 6| Step: 3
Training loss: 3.5933706760406494
Validation loss: 3.02128126031609

Epoch: 6| Step: 4
Training loss: 3.032101631164551
Validation loss: 3.0167303187872774

Epoch: 6| Step: 5
Training loss: 2.3348276615142822
Validation loss: 3.01501125930458

Epoch: 6| Step: 6
Training loss: 2.386855363845825
Validation loss: 3.0147035916646323

Epoch: 6| Step: 7
Training loss: 3.233895778656006
Validation loss: 3.0133286804281254

Epoch: 6| Step: 8
Training loss: 2.3528122901916504
Validation loss: 3.0100574826681488

Epoch: 6| Step: 9
Training loss: 3.1629724502563477
Validation loss: 3.011197720804522

Epoch: 6| Step: 10
Training loss: 3.6987409591674805
Validation loss: 3.009763776615102

Epoch: 6| Step: 11
Training loss: 3.477067470550537
Validation loss: 3.006591089310185

Epoch: 6| Step: 12
Training loss: 2.8962414264678955
Validation loss: 3.003811033823157

Epoch: 6| Step: 13
Training loss: 3.4565486907958984
Validation loss: 3.000158086899788

Epoch: 24| Step: 0
Training loss: 2.884359836578369
Validation loss: 3.0020942739261094

Epoch: 6| Step: 1
Training loss: 3.153416633605957
Validation loss: 3.007425067245319

Epoch: 6| Step: 2
Training loss: 4.520186424255371
Validation loss: 3.0110394108679985

Epoch: 6| Step: 3
Training loss: 3.3554587364196777
Validation loss: 3.007698356464345

Epoch: 6| Step: 4
Training loss: 1.774111270904541
Validation loss: 3.0071817136579946

Epoch: 6| Step: 5
Training loss: 3.0841188430786133
Validation loss: 3.0053132759627474

Epoch: 6| Step: 6
Training loss: 2.9857053756713867
Validation loss: 3.0022864521190686

Epoch: 6| Step: 7
Training loss: 3.029271125793457
Validation loss: 2.9999374728049

Epoch: 6| Step: 8
Training loss: 2.8896241188049316
Validation loss: 2.996056290083034

Epoch: 6| Step: 9
Training loss: 3.3193116188049316
Validation loss: 2.99454661082196

Epoch: 6| Step: 10
Training loss: 2.4631752967834473
Validation loss: 2.9958568696052796

Epoch: 6| Step: 11
Training loss: 3.855778932571411
Validation loss: 2.9897874811644196

Epoch: 6| Step: 12
Training loss: 2.912172555923462
Validation loss: 2.9919656579212477

Epoch: 6| Step: 13
Training loss: 2.3173437118530273
Validation loss: 2.99040973571039

Epoch: 25| Step: 0
Training loss: 3.8035855293273926
Validation loss: 2.9906535379348265

Epoch: 6| Step: 1
Training loss: 4.963747978210449
Validation loss: 2.9889879918867543

Epoch: 6| Step: 2
Training loss: 3.8123550415039062
Validation loss: 2.990656204121087

Epoch: 6| Step: 3
Training loss: 2.1913561820983887
Validation loss: 2.9906631105689594

Epoch: 6| Step: 4
Training loss: 3.535987138748169
Validation loss: 2.992093865589429

Epoch: 6| Step: 5
Training loss: 2.1908040046691895
Validation loss: 2.9946147293172856

Epoch: 6| Step: 6
Training loss: 2.200364828109741
Validation loss: 2.995137522297521

Epoch: 6| Step: 7
Training loss: 3.1526730060577393
Validation loss: 3.0008338882077124

Epoch: 6| Step: 8
Training loss: 2.0385825634002686
Validation loss: 3.001706738625803

Epoch: 6| Step: 9
Training loss: 2.657545566558838
Validation loss: 3.0054130579835627

Epoch: 6| Step: 10
Training loss: 3.1654200553894043
Validation loss: 2.989713330422678

Epoch: 6| Step: 11
Training loss: 2.5046122074127197
Validation loss: 2.9859241721450642

Epoch: 6| Step: 12
Training loss: 3.969676971435547
Validation loss: 2.982246252798265

Epoch: 6| Step: 13
Training loss: 2.230271816253662
Validation loss: 2.9832282681618967

Epoch: 26| Step: 0
Training loss: 4.385653495788574
Validation loss: 2.987630118605911

Epoch: 6| Step: 1
Training loss: 3.193922996520996
Validation loss: 2.9815497116375993

Epoch: 6| Step: 2
Training loss: 3.203035354614258
Validation loss: 2.983543321650515

Epoch: 6| Step: 3
Training loss: 3.4734044075012207
Validation loss: 2.9882592155087377

Epoch: 6| Step: 4
Training loss: 3.2395896911621094
Validation loss: 2.9864626187150196

Epoch: 6| Step: 5
Training loss: 2.740542411804199
Validation loss: 2.9777795883917038

Epoch: 6| Step: 6
Training loss: 3.325897216796875
Validation loss: 2.972485068023846

Epoch: 6| Step: 7
Training loss: 2.5187878608703613
Validation loss: 2.9699912865956626

Epoch: 6| Step: 8
Training loss: 2.9521312713623047
Validation loss: 2.9670656342660227

Epoch: 6| Step: 9
Training loss: 2.630690813064575
Validation loss: 2.96612944141511

Epoch: 6| Step: 10
Training loss: 2.86295485496521
Validation loss: 2.980518615374001

Epoch: 6| Step: 11
Training loss: 3.0003373622894287
Validation loss: 2.978787563180411

Epoch: 6| Step: 12
Training loss: 2.2703816890716553
Validation loss: 2.9953159260493454

Epoch: 6| Step: 13
Training loss: 2.8406810760498047
Validation loss: 3.0080324706210884

Epoch: 27| Step: 0
Training loss: 2.589125394821167
Validation loss: 2.9850760480409027

Epoch: 6| Step: 1
Training loss: 3.8347854614257812
Validation loss: 2.9718604626194125

Epoch: 6| Step: 2
Training loss: 3.3897228240966797
Validation loss: 2.967953602472941

Epoch: 6| Step: 3
Training loss: 2.7617297172546387
Validation loss: 2.9688557860671834

Epoch: 6| Step: 4
Training loss: 2.692554473876953
Validation loss: 2.9645640798794326

Epoch: 6| Step: 5
Training loss: 2.621729850769043
Validation loss: 2.9679252204074653

Epoch: 6| Step: 6
Training loss: 3.864532470703125
Validation loss: 2.971315565929618

Epoch: 6| Step: 7
Training loss: 2.7029049396514893
Validation loss: 2.971419829194264

Epoch: 6| Step: 8
Training loss: 2.6704280376434326
Validation loss: 2.966901389501428

Epoch: 6| Step: 9
Training loss: 3.0823545455932617
Validation loss: 2.9661373707555954

Epoch: 6| Step: 10
Training loss: 2.9248011112213135
Validation loss: 2.9640413509902133

Epoch: 6| Step: 11
Training loss: 3.250664472579956
Validation loss: 2.9613877880957817

Epoch: 6| Step: 12
Training loss: 2.8863918781280518
Validation loss: 2.9601657800776984

Epoch: 6| Step: 13
Training loss: 3.4891586303710938
Validation loss: 2.959108857698338

Epoch: 28| Step: 0
Training loss: 2.618410587310791
Validation loss: 2.955605588933473

Epoch: 6| Step: 1
Training loss: 3.2537035942077637
Validation loss: 2.9565896116277224

Epoch: 6| Step: 2
Training loss: 3.1623783111572266
Validation loss: 2.9565219007512575

Epoch: 6| Step: 3
Training loss: 3.5484704971313477
Validation loss: 2.961739827227849

Epoch: 6| Step: 4
Training loss: 3.0858240127563477
Validation loss: 2.963644089237336

Epoch: 6| Step: 5
Training loss: 2.629749059677124
Validation loss: 2.9602856046410015

Epoch: 6| Step: 6
Training loss: 3.0162408351898193
Validation loss: 2.9624769149288053

Epoch: 6| Step: 7
Training loss: 2.6397314071655273
Validation loss: 2.953694410221551

Epoch: 6| Step: 8
Training loss: 3.462972640991211
Validation loss: 2.9502492976445023

Epoch: 6| Step: 9
Training loss: 2.798936605453491
Validation loss: 2.9455217238395446

Epoch: 6| Step: 10
Training loss: 2.937377691268921
Validation loss: 2.948822772631081

Epoch: 6| Step: 11
Training loss: 2.4692907333374023
Validation loss: 2.9475045127253376

Epoch: 6| Step: 12
Training loss: 3.8746979236602783
Validation loss: 2.9496413097586682

Epoch: 6| Step: 13
Training loss: 2.847522497177124
Validation loss: 2.9503089202347623

Epoch: 29| Step: 0
Training loss: 2.695138931274414
Validation loss: 2.9478740102501324

Epoch: 6| Step: 1
Training loss: 3.074439525604248
Validation loss: 2.9486619400721725

Epoch: 6| Step: 2
Training loss: 3.5403945446014404
Validation loss: 2.9467664226408927

Epoch: 6| Step: 3
Training loss: 3.268761157989502
Validation loss: 2.9455497880135812

Epoch: 6| Step: 4
Training loss: 2.5670166015625
Validation loss: 2.9435525786492134

Epoch: 6| Step: 5
Training loss: 2.8393306732177734
Validation loss: 2.944941382254324

Epoch: 6| Step: 6
Training loss: 3.9884958267211914
Validation loss: 2.9430225331296205

Epoch: 6| Step: 7
Training loss: 2.3259077072143555
Validation loss: 2.9431947764529975

Epoch: 6| Step: 8
Training loss: 3.3499748706817627
Validation loss: 2.9398405500637588

Epoch: 6| Step: 9
Training loss: 2.3723745346069336
Validation loss: 2.9419166247049966

Epoch: 6| Step: 10
Training loss: 2.639573335647583
Validation loss: 2.9432408809661865

Epoch: 6| Step: 11
Training loss: 3.4014434814453125
Validation loss: 2.9416744145013953

Epoch: 6| Step: 12
Training loss: 3.2820544242858887
Validation loss: 2.9434055615496892

Epoch: 6| Step: 13
Training loss: 2.9360201358795166
Validation loss: 2.94167241742534

Epoch: 30| Step: 0
Training loss: 3.1561009883880615
Validation loss: 2.9455617371425835

Epoch: 6| Step: 1
Training loss: 2.7398717403411865
Validation loss: 2.945295472298899

Epoch: 6| Step: 2
Training loss: 2.468118667602539
Validation loss: 2.945461896158034

Epoch: 6| Step: 3
Training loss: 2.661445379257202
Validation loss: 2.942662590293474

Epoch: 6| Step: 4
Training loss: 3.8437182903289795
Validation loss: 2.938198943291941

Epoch: 6| Step: 5
Training loss: 3.28471302986145
Validation loss: 2.940604717500748

Epoch: 6| Step: 6
Training loss: 2.6062240600585938
Validation loss: 2.9375498756285636

Epoch: 6| Step: 7
Training loss: 3.228133201599121
Validation loss: 2.9353684712481756

Epoch: 6| Step: 8
Training loss: 2.2485058307647705
Validation loss: 2.933110608849474

Epoch: 6| Step: 9
Training loss: 2.429105520248413
Validation loss: 2.935975718241866

Epoch: 6| Step: 10
Training loss: 3.7952561378479004
Validation loss: 2.9315688584440496

Epoch: 6| Step: 11
Training loss: 2.946300983428955
Validation loss: 2.9313065672433503

Epoch: 6| Step: 12
Training loss: 3.696078300476074
Validation loss: 2.9323398656742548

Epoch: 6| Step: 13
Training loss: 3.2066164016723633
Validation loss: 2.9280219078063965

Epoch: 31| Step: 0
Training loss: 2.3792262077331543
Validation loss: 2.9298545724602154

Epoch: 6| Step: 1
Training loss: 3.329644203186035
Validation loss: 2.931166571955527

Epoch: 6| Step: 2
Training loss: 3.1576764583587646
Validation loss: 2.9295808294767975

Epoch: 6| Step: 3
Training loss: 2.7339065074920654
Validation loss: 2.9283244302195888

Epoch: 6| Step: 4
Training loss: 2.6837940216064453
Validation loss: 2.9269822284739506

Epoch: 6| Step: 5
Training loss: 3.612222194671631
Validation loss: 2.9295466458925636

Epoch: 6| Step: 6
Training loss: 3.293858528137207
Validation loss: 2.926368510851296

Epoch: 6| Step: 7
Training loss: 3.7905197143554688
Validation loss: 2.925491653462892

Epoch: 6| Step: 8
Training loss: 2.3805112838745117
Validation loss: 2.9261441743502052

Epoch: 6| Step: 9
Training loss: 2.3530220985412598
Validation loss: 2.9266291074855353

Epoch: 6| Step: 10
Training loss: 3.792071580886841
Validation loss: 2.9275246948324223

Epoch: 6| Step: 11
Training loss: 3.3445587158203125
Validation loss: 2.9253509429193314

Epoch: 6| Step: 12
Training loss: 2.7952053546905518
Validation loss: 2.9280578449208248

Epoch: 6| Step: 13
Training loss: 2.1310527324676514
Validation loss: 2.925595739836334

Epoch: 32| Step: 0
Training loss: 3.8530631065368652
Validation loss: 2.9302343245475524

Epoch: 6| Step: 1
Training loss: 3.5751700401306152
Validation loss: 2.9227946317324074

Epoch: 6| Step: 2
Training loss: 2.8155899047851562
Validation loss: 2.923833836791336

Epoch: 6| Step: 3
Training loss: 3.26994252204895
Validation loss: 2.918538462731146

Epoch: 6| Step: 4
Training loss: 1.9879205226898193
Validation loss: 2.9166519564967

Epoch: 6| Step: 5
Training loss: 2.1739635467529297
Validation loss: 2.918497162480508

Epoch: 6| Step: 6
Training loss: 2.851874589920044
Validation loss: 2.9201190958740892

Epoch: 6| Step: 7
Training loss: 3.111847400665283
Validation loss: 2.9239187445691837

Epoch: 6| Step: 8
Training loss: 2.406236410140991
Validation loss: 2.919833355052497

Epoch: 6| Step: 9
Training loss: 3.5480897426605225
Validation loss: 2.917175787751393

Epoch: 6| Step: 10
Training loss: 3.310295581817627
Validation loss: 2.918273707871796

Epoch: 6| Step: 11
Training loss: 2.739755153656006
Validation loss: 2.91675389710293

Epoch: 6| Step: 12
Training loss: 3.082335948944092
Validation loss: 2.916871481044318

Epoch: 6| Step: 13
Training loss: 3.67812442779541
Validation loss: 2.9196219777548187

Epoch: 33| Step: 0
Training loss: 2.6942925453186035
Validation loss: 2.924139371482275

Epoch: 6| Step: 1
Training loss: 3.2629966735839844
Validation loss: 2.921622314760762

Epoch: 6| Step: 2
Training loss: 2.7189016342163086
Validation loss: 2.92064469604082

Epoch: 6| Step: 3
Training loss: 2.1689486503601074
Validation loss: 2.9148753714817826

Epoch: 6| Step: 4
Training loss: 3.4020586013793945
Validation loss: 2.9175801866797992

Epoch: 6| Step: 5
Training loss: 3.176438331604004
Validation loss: 2.915197354491039

Epoch: 6| Step: 6
Training loss: 3.3257668018341064
Validation loss: 2.9158085110366985

Epoch: 6| Step: 7
Training loss: 3.271902084350586
Validation loss: 2.91240966960948

Epoch: 6| Step: 8
Training loss: 3.208719253540039
Validation loss: 2.914472246682772

Epoch: 6| Step: 9
Training loss: 2.201434373855591
Validation loss: 2.9146252268104145

Epoch: 6| Step: 10
Training loss: 3.1174662113189697
Validation loss: 2.9148123187403523

Epoch: 6| Step: 11
Training loss: 3.1950855255126953
Validation loss: 2.9114279747009277

Epoch: 6| Step: 12
Training loss: 3.2976913452148438
Validation loss: 2.913527778399888

Epoch: 6| Step: 13
Training loss: 3.034721851348877
Validation loss: 2.9036405855609524

Epoch: 34| Step: 0
Training loss: 3.06266450881958
Validation loss: 2.9056363310865176

Epoch: 6| Step: 1
Training loss: 3.84175968170166
Validation loss: 2.9012630498537453

Epoch: 6| Step: 2
Training loss: 4.15677547454834
Validation loss: 2.902687805955128

Epoch: 6| Step: 3
Training loss: 2.8604824542999268
Validation loss: 2.903792970923967

Epoch: 6| Step: 4
Training loss: 3.439051389694214
Validation loss: 2.8996733901321248

Epoch: 6| Step: 5
Training loss: 2.825260639190674
Validation loss: 2.900579837060744

Epoch: 6| Step: 6
Training loss: 3.524256467819214
Validation loss: 2.8991713088045836

Epoch: 6| Step: 7
Training loss: 2.625119686126709
Validation loss: 2.8976371954846125

Epoch: 6| Step: 8
Training loss: 1.600988507270813
Validation loss: 2.898544983197284

Epoch: 6| Step: 9
Training loss: 2.735809803009033
Validation loss: 2.897505678156371

Epoch: 6| Step: 10
Training loss: 2.3450534343719482
Validation loss: 2.8992001830890612

Epoch: 6| Step: 11
Training loss: 2.8999874591827393
Validation loss: 2.902331575270622

Epoch: 6| Step: 12
Training loss: 3.171938180923462
Validation loss: 2.9094949460798696

Epoch: 6| Step: 13
Training loss: 2.7518815994262695
Validation loss: 2.903415915786579

Epoch: 35| Step: 0
Training loss: 2.550164222717285
Validation loss: 2.898034708474272

Epoch: 6| Step: 1
Training loss: 3.4594383239746094
Validation loss: 2.8936323786294587

Epoch: 6| Step: 2
Training loss: 3.5127100944519043
Validation loss: 2.8929161307632283

Epoch: 6| Step: 3
Training loss: 3.6018013954162598
Validation loss: 2.892622968201996

Epoch: 6| Step: 4
Training loss: 3.2991585731506348
Validation loss: 2.8886845804029897

Epoch: 6| Step: 5
Training loss: 2.4068901538848877
Validation loss: 2.891356942474201

Epoch: 6| Step: 6
Training loss: 3.277379274368286
Validation loss: 2.8887811322366037

Epoch: 6| Step: 7
Training loss: 2.6738340854644775
Validation loss: 2.8858332736517793

Epoch: 6| Step: 8
Training loss: 2.1155338287353516
Validation loss: 2.8846383017878376

Epoch: 6| Step: 9
Training loss: 3.2972757816314697
Validation loss: 2.886575401470225

Epoch: 6| Step: 10
Training loss: 3.490499973297119
Validation loss: 2.8876429885946293

Epoch: 6| Step: 11
Training loss: 2.9331393241882324
Validation loss: 2.885279640074699

Epoch: 6| Step: 12
Training loss: 1.9918112754821777
Validation loss: 2.8822790679111274

Epoch: 6| Step: 13
Training loss: 3.3799526691436768
Validation loss: 2.878202756245931

Epoch: 36| Step: 0
Training loss: 2.845216751098633
Validation loss: 2.8800628339090655

Epoch: 6| Step: 1
Training loss: 3.207892894744873
Validation loss: 2.8752730918186966

Epoch: 6| Step: 2
Training loss: 3.45416259765625
Validation loss: 2.8763640260183685

Epoch: 6| Step: 3
Training loss: 3.309687614440918
Validation loss: 2.8737782457823395

Epoch: 6| Step: 4
Training loss: 3.6480584144592285
Validation loss: 2.8751992512774724

Epoch: 6| Step: 5
Training loss: 2.9353010654449463
Validation loss: 2.8746492939610637

Epoch: 6| Step: 6
Training loss: 2.496286392211914
Validation loss: 2.8744596588996147

Epoch: 6| Step: 7
Training loss: 2.8811397552490234
Validation loss: 2.87244354268556

Epoch: 6| Step: 8
Training loss: 3.4343996047973633
Validation loss: 2.8725798258217434

Epoch: 6| Step: 9
Training loss: 2.2170345783233643
Validation loss: 2.8735033286515104

Epoch: 6| Step: 10
Training loss: 2.5533533096313477
Validation loss: 2.8791905731283207

Epoch: 6| Step: 11
Training loss: 2.5450711250305176
Validation loss: 2.887384017308553

Epoch: 6| Step: 12
Training loss: 3.226388931274414
Validation loss: 2.9040855823024625

Epoch: 6| Step: 13
Training loss: 2.941826581954956
Validation loss: 2.907780231968049

Epoch: 37| Step: 0
Training loss: 2.8159687519073486
Validation loss: 2.8832794184325845

Epoch: 6| Step: 1
Training loss: 3.7015395164489746
Validation loss: 2.870230077415384

Epoch: 6| Step: 2
Training loss: 3.829228401184082
Validation loss: 2.8708026921877297

Epoch: 6| Step: 3
Training loss: 2.9978184700012207
Validation loss: 2.8719576276758665

Epoch: 6| Step: 4
Training loss: 2.8849124908447266
Validation loss: 2.8690572015700804

Epoch: 6| Step: 5
Training loss: 3.1657228469848633
Validation loss: 2.873933910041727

Epoch: 6| Step: 6
Training loss: 2.483734130859375
Validation loss: 2.8716867405881166

Epoch: 6| Step: 7
Training loss: 3.189884662628174
Validation loss: 2.8728750059681554

Epoch: 6| Step: 8
Training loss: 2.926243543624878
Validation loss: 2.8737724134998937

Epoch: 6| Step: 9
Training loss: 2.4567770957946777
Validation loss: 2.8677047503891813

Epoch: 6| Step: 10
Training loss: 3.3619165420532227
Validation loss: 2.865711622340705

Epoch: 6| Step: 11
Training loss: 2.435774803161621
Validation loss: 2.8664256603487077

Epoch: 6| Step: 12
Training loss: 2.8844213485717773
Validation loss: 2.873034620797762

Epoch: 6| Step: 13
Training loss: 2.1523845195770264
Validation loss: 2.8715895093897337

Epoch: 38| Step: 0
Training loss: 2.2489514350891113
Validation loss: 2.8726264481903403

Epoch: 6| Step: 1
Training loss: 2.3810601234436035
Validation loss: 2.869459590604228

Epoch: 6| Step: 2
Training loss: 2.040977716445923
Validation loss: 2.868050918784193

Epoch: 6| Step: 3
Training loss: 2.9832773208618164
Validation loss: 2.8659122759296047

Epoch: 6| Step: 4
Training loss: 3.1340084075927734
Validation loss: 2.8714974669999975

Epoch: 6| Step: 5
Training loss: 3.2294483184814453
Validation loss: 2.868290767874769

Epoch: 6| Step: 6
Training loss: 2.5869638919830322
Validation loss: 2.8630275111044607

Epoch: 6| Step: 7
Training loss: 3.7122485637664795
Validation loss: 2.8654410377625497

Epoch: 6| Step: 8
Training loss: 3.899745225906372
Validation loss: 2.8626610694393033

Epoch: 6| Step: 9
Training loss: 2.903311252593994
Validation loss: 2.86086360357141

Epoch: 6| Step: 10
Training loss: 2.7050771713256836
Validation loss: 2.8560215221938265

Epoch: 6| Step: 11
Training loss: 3.556553602218628
Validation loss: 2.857130506987213

Epoch: 6| Step: 12
Training loss: 3.1480765342712402
Validation loss: 2.858204492958643

Epoch: 6| Step: 13
Training loss: 3.027864694595337
Validation loss: 2.8554143444184334

Epoch: 39| Step: 0
Training loss: 3.113842010498047
Validation loss: 2.858520943631408

Epoch: 6| Step: 1
Training loss: 2.9908814430236816
Validation loss: 2.8613310501139653

Epoch: 6| Step: 2
Training loss: 2.9380269050598145
Validation loss: 2.8864123411076044

Epoch: 6| Step: 3
Training loss: 3.6708903312683105
Validation loss: 2.860229117895967

Epoch: 6| Step: 4
Training loss: 3.222179889678955
Validation loss: 2.8569237160426315

Epoch: 6| Step: 5
Training loss: 2.5397281646728516
Validation loss: 2.851155573321927

Epoch: 6| Step: 6
Training loss: 2.8104875087738037
Validation loss: 2.8506443885064896

Epoch: 6| Step: 7
Training loss: 3.5181350708007812
Validation loss: 2.85213105909286

Epoch: 6| Step: 8
Training loss: 3.7367920875549316
Validation loss: 2.8487779043054067

Epoch: 6| Step: 9
Training loss: 3.4729433059692383
Validation loss: 2.850701332092285

Epoch: 6| Step: 10
Training loss: 2.0883922576904297
Validation loss: 2.850860770030688

Epoch: 6| Step: 11
Training loss: 2.7485032081604004
Validation loss: 2.8540160117610807

Epoch: 6| Step: 12
Training loss: 2.359750747680664
Validation loss: 2.852994636822772

Epoch: 6| Step: 13
Training loss: 1.725688099861145
Validation loss: 2.8540422531866256

Epoch: 40| Step: 0
Training loss: 2.301318645477295
Validation loss: 2.8519155543337584

Epoch: 6| Step: 1
Training loss: 3.434197425842285
Validation loss: 2.8498527362782466

Epoch: 6| Step: 2
Training loss: 2.6368699073791504
Validation loss: 2.851923309346681

Epoch: 6| Step: 3
Training loss: 3.1533517837524414
Validation loss: 2.847841501235962

Epoch: 6| Step: 4
Training loss: 3.338749408721924
Validation loss: 2.8489931245003977

Epoch: 6| Step: 5
Training loss: 2.3284921646118164
Validation loss: 2.847784644813948

Epoch: 6| Step: 6
Training loss: 2.8801913261413574
Validation loss: 2.8479838217458417

Epoch: 6| Step: 7
Training loss: 2.994868755340576
Validation loss: 2.8487855798454693

Epoch: 6| Step: 8
Training loss: 3.5008187294006348
Validation loss: 2.8522301540579846

Epoch: 6| Step: 9
Training loss: 3.537473201751709
Validation loss: 2.849307060241699

Epoch: 6| Step: 10
Training loss: 2.675718307495117
Validation loss: 2.8493881661404847

Epoch: 6| Step: 11
Training loss: 3.047327756881714
Validation loss: 2.8476912360037527

Epoch: 6| Step: 12
Training loss: 2.891176700592041
Validation loss: 2.8444372223269556

Epoch: 6| Step: 13
Training loss: 2.4297711849212646
Validation loss: 2.844599195705947

Epoch: 41| Step: 0
Training loss: 3.103569984436035
Validation loss: 2.842014892126924

Epoch: 6| Step: 1
Training loss: 2.600450038909912
Validation loss: 2.839582804710634

Epoch: 6| Step: 2
Training loss: 2.613243579864502
Validation loss: 2.8399971223646596

Epoch: 6| Step: 3
Training loss: 2.8245372772216797
Validation loss: 2.841766736840689

Epoch: 6| Step: 4
Training loss: 3.358273506164551
Validation loss: 2.8423510674507386

Epoch: 6| Step: 5
Training loss: 2.307549476623535
Validation loss: 2.8426399512957503

Epoch: 6| Step: 6
Training loss: 3.01690673828125
Validation loss: 2.8397072310088785

Epoch: 6| Step: 7
Training loss: 3.404695510864258
Validation loss: 2.838417012204406

Epoch: 6| Step: 8
Training loss: 2.3928043842315674
Validation loss: 2.8365089252430904

Epoch: 6| Step: 9
Training loss: 3.5299739837646484
Validation loss: 2.8385567562554472

Epoch: 6| Step: 10
Training loss: 2.375521421432495
Validation loss: 2.839751958847046

Epoch: 6| Step: 11
Training loss: 3.2285447120666504
Validation loss: 2.836959715812437

Epoch: 6| Step: 12
Training loss: 3.710728406906128
Validation loss: 2.838181775103333

Epoch: 6| Step: 13
Training loss: 2.786162853240967
Validation loss: 2.8373549369073685

Epoch: 42| Step: 0
Training loss: 3.8635878562927246
Validation loss: 2.835196856529482

Epoch: 6| Step: 1
Training loss: 2.180278778076172
Validation loss: 2.8337711749538297

Epoch: 6| Step: 2
Training loss: 2.700044631958008
Validation loss: 2.831486407146659

Epoch: 6| Step: 3
Training loss: 3.6640079021453857
Validation loss: 2.832968968217091

Epoch: 6| Step: 4
Training loss: 2.9103145599365234
Validation loss: 2.830398739025157

Epoch: 6| Step: 5
Training loss: 3.1963860988616943
Validation loss: 2.8316596143989154

Epoch: 6| Step: 6
Training loss: 2.6665148735046387
Validation loss: 2.8349851357039584

Epoch: 6| Step: 7
Training loss: 3.4718451499938965
Validation loss: 2.833930548801217

Epoch: 6| Step: 8
Training loss: 2.6792399883270264
Validation loss: 2.8297906742301038

Epoch: 6| Step: 9
Training loss: 3.2530431747436523
Validation loss: 2.8304036842879428

Epoch: 6| Step: 10
Training loss: 2.6027932167053223
Validation loss: 2.8298057484370407

Epoch: 6| Step: 11
Training loss: 3.1894006729125977
Validation loss: 2.8326369562456684

Epoch: 6| Step: 12
Training loss: 2.218353271484375
Validation loss: 2.838420691028718

Epoch: 6| Step: 13
Training loss: 2.3928864002227783
Validation loss: 2.8453954137781614

Epoch: 43| Step: 0
Training loss: 3.0504956245422363
Validation loss: 2.8620055926743375

Epoch: 6| Step: 1
Training loss: 2.1400609016418457
Validation loss: 2.87211872172612

Epoch: 6| Step: 2
Training loss: 2.5335214138031006
Validation loss: 2.8830318092018046

Epoch: 6| Step: 3
Training loss: 1.7740061283111572
Validation loss: 2.8665587748250654

Epoch: 6| Step: 4
Training loss: 3.12973690032959
Validation loss: 2.854852689209805

Epoch: 6| Step: 5
Training loss: 3.181332588195801
Validation loss: 2.8340340763010006

Epoch: 6| Step: 6
Training loss: 2.633688449859619
Validation loss: 2.828563472276093

Epoch: 6| Step: 7
Training loss: 3.536235809326172
Validation loss: 2.826673517944992

Epoch: 6| Step: 8
Training loss: 3.1125845909118652
Validation loss: 2.8265571850602345

Epoch: 6| Step: 9
Training loss: 3.4071173667907715
Validation loss: 2.8282320499420166

Epoch: 6| Step: 10
Training loss: 3.2509613037109375
Validation loss: 2.8293912436372493

Epoch: 6| Step: 11
Training loss: 3.2228171825408936
Validation loss: 2.825660818366594

Epoch: 6| Step: 12
Training loss: 2.8144350051879883
Validation loss: 2.827858381373908

Epoch: 6| Step: 13
Training loss: 3.94637131690979
Validation loss: 2.8250304268252466

Epoch: 44| Step: 0
Training loss: 2.0867955684661865
Validation loss: 2.8230084116740892

Epoch: 6| Step: 1
Training loss: 3.1705894470214844
Validation loss: 2.824123215931718

Epoch: 6| Step: 2
Training loss: 2.050877809524536
Validation loss: 2.822208337886359

Epoch: 6| Step: 3
Training loss: 3.538273334503174
Validation loss: 2.82719257057354

Epoch: 6| Step: 4
Training loss: 3.1187329292297363
Validation loss: 2.8269719334058863

Epoch: 6| Step: 5
Training loss: 3.1199727058410645
Validation loss: 2.825197112175726

Epoch: 6| Step: 6
Training loss: 3.554971694946289
Validation loss: 2.826487648871637

Epoch: 6| Step: 7
Training loss: 1.869835376739502
Validation loss: 2.825207564138597

Epoch: 6| Step: 8
Training loss: 3.1292531490325928
Validation loss: 2.8273111415165726

Epoch: 6| Step: 9
Training loss: 3.544640064239502
Validation loss: 2.8252431756706646

Epoch: 6| Step: 10
Training loss: 2.896331787109375
Validation loss: 2.8216059387371106

Epoch: 6| Step: 11
Training loss: 2.991421699523926
Validation loss: 2.823289509742491

Epoch: 6| Step: 12
Training loss: 3.3988404273986816
Validation loss: 2.821915764962473

Epoch: 6| Step: 13
Training loss: 2.475053071975708
Validation loss: 2.8178270504038823

Epoch: 45| Step: 0
Training loss: 2.8339829444885254
Validation loss: 2.8192995978939916

Epoch: 6| Step: 1
Training loss: 2.466912269592285
Validation loss: 2.813993389888476

Epoch: 6| Step: 2
Training loss: 2.2830111980438232
Validation loss: 2.8141644693190053

Epoch: 6| Step: 3
Training loss: 3.5331451892852783
Validation loss: 2.810318580237768

Epoch: 6| Step: 4
Training loss: 2.963332414627075
Validation loss: 2.8125567692582325

Epoch: 6| Step: 5
Training loss: 3.234504222869873
Validation loss: 2.8087840362261702

Epoch: 6| Step: 6
Training loss: 3.399016857147217
Validation loss: 2.8101382947737172

Epoch: 6| Step: 7
Training loss: 3.4168431758880615
Validation loss: 2.805478649754678

Epoch: 6| Step: 8
Training loss: 3.311004877090454
Validation loss: 2.805959842538321

Epoch: 6| Step: 9
Training loss: 3.433523654937744
Validation loss: 2.802994930615989

Epoch: 6| Step: 10
Training loss: 2.34134840965271
Validation loss: 2.80712233051177

Epoch: 6| Step: 11
Training loss: 2.8068737983703613
Validation loss: 2.802107016245524

Epoch: 6| Step: 12
Training loss: 2.667841911315918
Validation loss: 2.8027764879247195

Epoch: 6| Step: 13
Training loss: 1.8521137237548828
Validation loss: 2.801433804214642

Epoch: 46| Step: 0
Training loss: 2.975172996520996
Validation loss: 2.799598034992013

Epoch: 6| Step: 1
Training loss: 3.0638036727905273
Validation loss: 2.8032472210545696

Epoch: 6| Step: 2
Training loss: 1.8125457763671875
Validation loss: 2.8031197696603756

Epoch: 6| Step: 3
Training loss: 3.6660406589508057
Validation loss: 2.8021414972120717

Epoch: 6| Step: 4
Training loss: 2.983769416809082
Validation loss: 2.8026879449044504

Epoch: 6| Step: 5
Training loss: 2.6276865005493164
Validation loss: 2.80655002081266

Epoch: 6| Step: 6
Training loss: 2.798083782196045
Validation loss: 2.806716675399452

Epoch: 6| Step: 7
Training loss: 1.9947984218597412
Validation loss: 2.8226232964505433

Epoch: 6| Step: 8
Training loss: 3.0881991386413574
Validation loss: 2.8030284886719077

Epoch: 6| Step: 9
Training loss: 2.9289498329162598
Validation loss: 2.7967106757625455

Epoch: 6| Step: 10
Training loss: 3.7125353813171387
Validation loss: 2.792156224609703

Epoch: 6| Step: 11
Training loss: 3.07721209526062
Validation loss: 2.797305086607574

Epoch: 6| Step: 12
Training loss: 3.4285788536071777
Validation loss: 2.7976610609280166

Epoch: 6| Step: 13
Training loss: 2.6139464378356934
Validation loss: 2.7992750316537838

Epoch: 47| Step: 0
Training loss: 2.9161458015441895
Validation loss: 2.8064771313821115

Epoch: 6| Step: 1
Training loss: 3.096815586090088
Validation loss: 2.797941418104274

Epoch: 6| Step: 2
Training loss: 3.405411958694458
Validation loss: 2.7943409258319485

Epoch: 6| Step: 3
Training loss: 2.3400468826293945
Validation loss: 2.7919794718424478

Epoch: 6| Step: 4
Training loss: 3.0716209411621094
Validation loss: 2.7875680000551286

Epoch: 6| Step: 5
Training loss: 2.8904011249542236
Validation loss: 2.790232627622543

Epoch: 6| Step: 6
Training loss: 3.5470004081726074
Validation loss: 2.78382610249263

Epoch: 6| Step: 7
Training loss: 2.8390188217163086
Validation loss: 2.7857230914536344

Epoch: 6| Step: 8
Training loss: 2.612117290496826
Validation loss: 2.785900141603203

Epoch: 6| Step: 9
Training loss: 3.246194839477539
Validation loss: 2.7959000013207875

Epoch: 6| Step: 10
Training loss: 2.5785489082336426
Validation loss: 2.7995353078329437

Epoch: 6| Step: 11
Training loss: 2.4105849266052246
Validation loss: 2.7942698078770793

Epoch: 6| Step: 12
Training loss: 3.3474295139312744
Validation loss: 2.801007701504615

Epoch: 6| Step: 13
Training loss: 2.3028199672698975
Validation loss: 2.792463720485728

Epoch: 48| Step: 0
Training loss: 2.8861083984375
Validation loss: 2.7884973505491852

Epoch: 6| Step: 1
Training loss: 2.937817096710205
Validation loss: 2.7829560336246284

Epoch: 6| Step: 2
Training loss: 3.3177037239074707
Validation loss: 2.7719322891645533

Epoch: 6| Step: 3
Training loss: 1.754203200340271
Validation loss: 2.770404790037422

Epoch: 6| Step: 4
Training loss: 3.38899827003479
Validation loss: 2.7728236644498763

Epoch: 6| Step: 5
Training loss: 2.8937954902648926
Validation loss: 2.77105164271529

Epoch: 6| Step: 6
Training loss: 2.192551612854004
Validation loss: 2.7708115603334162

Epoch: 6| Step: 7
Training loss: 2.423410415649414
Validation loss: 2.7675948194278184

Epoch: 6| Step: 8
Training loss: 3.105553150177002
Validation loss: 2.773196158870574

Epoch: 6| Step: 9
Training loss: 4.197720527648926
Validation loss: 2.77125189381261

Epoch: 6| Step: 10
Training loss: 2.3243117332458496
Validation loss: 2.772728248309064

Epoch: 6| Step: 11
Training loss: 3.4193482398986816
Validation loss: 2.7724772807090514

Epoch: 6| Step: 12
Training loss: 2.9305543899536133
Validation loss: 2.771128213533791

Epoch: 6| Step: 13
Training loss: 3.0268473625183105
Validation loss: 2.76678890310308

Epoch: 49| Step: 0
Training loss: 3.1772685050964355
Validation loss: 2.758486214504447

Epoch: 6| Step: 1
Training loss: 3.3453922271728516
Validation loss: 2.761775516694592

Epoch: 6| Step: 2
Training loss: 2.602696418762207
Validation loss: 2.7605230731348835

Epoch: 6| Step: 3
Training loss: 2.4492831230163574
Validation loss: 2.756744382201984

Epoch: 6| Step: 4
Training loss: 3.2772231101989746
Validation loss: 2.7547574248365176

Epoch: 6| Step: 5
Training loss: 2.4963674545288086
Validation loss: 2.7561169029563986

Epoch: 6| Step: 6
Training loss: 3.5025558471679688
Validation loss: 2.7552969660810245

Epoch: 6| Step: 7
Training loss: 2.014671802520752
Validation loss: 2.756896495819092

Epoch: 6| Step: 8
Training loss: 3.2870616912841797
Validation loss: 2.754145619689777

Epoch: 6| Step: 9
Training loss: 3.0755035877227783
Validation loss: 2.753466116484775

Epoch: 6| Step: 10
Training loss: 3.1319260597229004
Validation loss: 2.762900388368996

Epoch: 6| Step: 11
Training loss: 2.863823413848877
Validation loss: 2.7672625434014106

Epoch: 6| Step: 12
Training loss: 2.5191965103149414
Validation loss: 2.776925115175145

Epoch: 6| Step: 13
Training loss: 2.8487422466278076
Validation loss: 2.790653080068609

Epoch: 50| Step: 0
Training loss: 3.671037435531616
Validation loss: 2.78440870008161

Epoch: 6| Step: 1
Training loss: 2.5599544048309326
Validation loss: 2.7573468454422487

Epoch: 6| Step: 2
Training loss: 2.6905934810638428
Validation loss: 2.757612710357994

Epoch: 6| Step: 3
Training loss: 3.129641056060791
Validation loss: 2.745168206512287

Epoch: 6| Step: 4
Training loss: 2.3633079528808594
Validation loss: 2.746007473238053

Epoch: 6| Step: 5
Training loss: 3.5497803688049316
Validation loss: 2.743958693678661

Epoch: 6| Step: 6
Training loss: 2.7164595127105713
Validation loss: 2.746050447546026

Epoch: 6| Step: 7
Training loss: 2.822909355163574
Validation loss: 2.745269319062592

Epoch: 6| Step: 8
Training loss: 2.8412036895751953
Validation loss: 2.746012480028214

Epoch: 6| Step: 9
Training loss: 2.4080870151519775
Validation loss: 2.7449768256115656

Epoch: 6| Step: 10
Training loss: 2.290264129638672
Validation loss: 2.7442788257393786

Epoch: 6| Step: 11
Training loss: 3.776381015777588
Validation loss: 2.7398679589712494

Epoch: 6| Step: 12
Training loss: 3.27896785736084
Validation loss: 2.7385565516769246

Epoch: 6| Step: 13
Training loss: 1.9838223457336426
Validation loss: 2.736734236440351

Epoch: 51| Step: 0
Training loss: 2.4991679191589355
Validation loss: 2.734895065266599

Epoch: 6| Step: 1
Training loss: 2.5714876651763916
Validation loss: 2.735753761824741

Epoch: 6| Step: 2
Training loss: 2.6479339599609375
Validation loss: 2.734734845417802

Epoch: 6| Step: 3
Training loss: 3.324401617050171
Validation loss: 2.7337039465545327

Epoch: 6| Step: 4
Training loss: 2.1364924907684326
Validation loss: 2.7332986734246694

Epoch: 6| Step: 5
Training loss: 3.4819822311401367
Validation loss: 2.7298712563771073

Epoch: 6| Step: 6
Training loss: 3.3943138122558594
Validation loss: 2.7304522504088697

Epoch: 6| Step: 7
Training loss: 3.3468751907348633
Validation loss: 2.729466228074925

Epoch: 6| Step: 8
Training loss: 3.1934878826141357
Validation loss: 2.7281108184527327

Epoch: 6| Step: 9
Training loss: 3.0049352645874023
Validation loss: 2.7300035286975164

Epoch: 6| Step: 10
Training loss: 2.849435806274414
Validation loss: 2.728493203399002

Epoch: 6| Step: 11
Training loss: 3.0794668197631836
Validation loss: 2.7366851324676187

Epoch: 6| Step: 12
Training loss: 2.3930211067199707
Validation loss: 2.7316138077807683

Epoch: 6| Step: 13
Training loss: 2.0377845764160156
Validation loss: 2.7326479624676447

Epoch: 52| Step: 0
Training loss: 3.515622138977051
Validation loss: 2.72987610806701

Epoch: 6| Step: 1
Training loss: 2.7640316486358643
Validation loss: 2.7328770699039584

Epoch: 6| Step: 2
Training loss: 3.202023983001709
Validation loss: 2.7272926325439126

Epoch: 6| Step: 3
Training loss: 3.249234437942505
Validation loss: 2.7279738944063903

Epoch: 6| Step: 4
Training loss: 2.703947067260742
Validation loss: 2.73036035414665

Epoch: 6| Step: 5
Training loss: 2.244706630706787
Validation loss: 2.7286059574414323

Epoch: 6| Step: 6
Training loss: 2.7826642990112305
Validation loss: 2.725809725381995

Epoch: 6| Step: 7
Training loss: 2.927476644515991
Validation loss: 2.723916979246242

Epoch: 6| Step: 8
Training loss: 2.5257482528686523
Validation loss: 2.721916757604127

Epoch: 6| Step: 9
Training loss: 2.55608868598938
Validation loss: 2.720033750739149

Epoch: 6| Step: 10
Training loss: 3.08347749710083
Validation loss: 2.7219340365420104

Epoch: 6| Step: 11
Training loss: 3.010472059249878
Validation loss: 2.721936023363503

Epoch: 6| Step: 12
Training loss: 2.77058482170105
Validation loss: 2.7216797208273285

Epoch: 6| Step: 13
Training loss: 2.93184232711792
Validation loss: 2.721567210330758

Epoch: 53| Step: 0
Training loss: 2.577880859375
Validation loss: 2.720510744279431

Epoch: 6| Step: 1
Training loss: 2.4235198497772217
Validation loss: 2.7206219575738393

Epoch: 6| Step: 2
Training loss: 3.7050771713256836
Validation loss: 2.7198434593856975

Epoch: 6| Step: 3
Training loss: 2.8775157928466797
Validation loss: 2.7213173835508284

Epoch: 6| Step: 4
Training loss: 2.960839033126831
Validation loss: 2.718455586382138

Epoch: 6| Step: 5
Training loss: 2.5442252159118652
Validation loss: 2.719249358741186

Epoch: 6| Step: 6
Training loss: 2.821422576904297
Validation loss: 2.719203446501045

Epoch: 6| Step: 7
Training loss: 2.185610771179199
Validation loss: 2.7182139453067573

Epoch: 6| Step: 8
Training loss: 3.746494770050049
Validation loss: 2.718621894877444

Epoch: 6| Step: 9
Training loss: 3.071341037750244
Validation loss: 2.7225441573768534

Epoch: 6| Step: 10
Training loss: 3.7216849327087402
Validation loss: 2.725560272893598

Epoch: 6| Step: 11
Training loss: 2.487471580505371
Validation loss: 2.7293636414312545

Epoch: 6| Step: 12
Training loss: 2.3395814895629883
Validation loss: 2.723712703233124

Epoch: 6| Step: 13
Training loss: 2.631354570388794
Validation loss: 2.7288154325177594

Epoch: 54| Step: 0
Training loss: 2.4836111068725586
Validation loss: 2.7231658940674155

Epoch: 6| Step: 1
Training loss: 2.8370304107666016
Validation loss: 2.7193817143799155

Epoch: 6| Step: 2
Training loss: 2.4370312690734863
Validation loss: 2.7160989007642193

Epoch: 6| Step: 3
Training loss: 3.485701084136963
Validation loss: 2.7139648186263217

Epoch: 6| Step: 4
Training loss: 3.076528310775757
Validation loss: 2.713588681272281

Epoch: 6| Step: 5
Training loss: 2.880417823791504
Validation loss: 2.7163932144000964

Epoch: 6| Step: 6
Training loss: 3.2716777324676514
Validation loss: 2.7137467015174126

Epoch: 6| Step: 7
Training loss: 2.356297492980957
Validation loss: 2.7138468783388854

Epoch: 6| Step: 8
Training loss: 2.296555995941162
Validation loss: 2.7188734367329586

Epoch: 6| Step: 9
Training loss: 3.024088144302368
Validation loss: 2.717199146106679

Epoch: 6| Step: 10
Training loss: 3.235757827758789
Validation loss: 2.717697866501347

Epoch: 6| Step: 11
Training loss: 3.0481679439544678
Validation loss: 2.7184802537323325

Epoch: 6| Step: 12
Training loss: 3.1979610919952393
Validation loss: 2.718763377076836

Epoch: 6| Step: 13
Training loss: 2.309664011001587
Validation loss: 2.7226573241654264

Epoch: 55| Step: 0
Training loss: 3.1120052337646484
Validation loss: 2.721535533987066

Epoch: 6| Step: 1
Training loss: 2.2941744327545166
Validation loss: 2.720164388738653

Epoch: 6| Step: 2
Training loss: 2.6383891105651855
Validation loss: 2.714116665624803

Epoch: 6| Step: 3
Training loss: 2.363805055618286
Validation loss: 2.7194733055689

Epoch: 6| Step: 4
Training loss: 2.6392982006073
Validation loss: 2.7163358683227212

Epoch: 6| Step: 5
Training loss: 2.7602458000183105
Validation loss: 2.7161220171118297

Epoch: 6| Step: 6
Training loss: 2.69868540763855
Validation loss: 2.717453069584344

Epoch: 6| Step: 7
Training loss: 3.7817392349243164
Validation loss: 2.7152964812453075

Epoch: 6| Step: 8
Training loss: 1.9366265535354614
Validation loss: 2.711437461196735

Epoch: 6| Step: 9
Training loss: 3.4603333473205566
Validation loss: 2.71040786979019

Epoch: 6| Step: 10
Training loss: 3.9186906814575195
Validation loss: 2.7112749135622414

Epoch: 6| Step: 11
Training loss: 3.54624605178833
Validation loss: 2.7075740483499344

Epoch: 6| Step: 12
Training loss: 3.126748561859131
Validation loss: 2.7114350616291003

Epoch: 6| Step: 13
Training loss: 1.0992722511291504
Validation loss: 2.707133072678761

Epoch: 56| Step: 0
Training loss: 2.9715189933776855
Validation loss: 2.7101151276660222

Epoch: 6| Step: 1
Training loss: 2.3808770179748535
Validation loss: 2.7074859091030654

Epoch: 6| Step: 2
Training loss: 2.6200382709503174
Validation loss: 2.710599071236067

Epoch: 6| Step: 3
Training loss: 3.6594858169555664
Validation loss: 2.710634991686831

Epoch: 6| Step: 4
Training loss: 3.2320663928985596
Validation loss: 2.707492474586733

Epoch: 6| Step: 5
Training loss: 2.9579572677612305
Validation loss: 2.7049560546875

Epoch: 6| Step: 6
Training loss: 2.2316770553588867
Validation loss: 2.70917123235682

Epoch: 6| Step: 7
Training loss: 2.9593822956085205
Validation loss: 2.7107899445359425

Epoch: 6| Step: 8
Training loss: 2.3976240158081055
Validation loss: 2.7115441214653755

Epoch: 6| Step: 9
Training loss: 2.5094573497772217
Validation loss: 2.7140324397753646

Epoch: 6| Step: 10
Training loss: 3.185581684112549
Validation loss: 2.713123201042093

Epoch: 6| Step: 11
Training loss: 2.4723806381225586
Validation loss: 2.7157498277643675

Epoch: 6| Step: 12
Training loss: 2.8792285919189453
Validation loss: 2.7132250942209715

Epoch: 6| Step: 13
Training loss: 4.261699199676514
Validation loss: 2.716636857678813

Epoch: 57| Step: 0
Training loss: 2.159719228744507
Validation loss: 2.7146213900658394

Epoch: 6| Step: 1
Training loss: 2.05707049369812
Validation loss: 2.707310591974566

Epoch: 6| Step: 2
Training loss: 3.072012186050415
Validation loss: 2.7135582098396878

Epoch: 6| Step: 3
Training loss: 2.58579683303833
Validation loss: 2.707779181900845

Epoch: 6| Step: 4
Training loss: 2.6751067638397217
Validation loss: 2.708498752245339

Epoch: 6| Step: 5
Training loss: 3.1739768981933594
Validation loss: 2.7066244181766304

Epoch: 6| Step: 6
Training loss: 3.026115655899048
Validation loss: 2.7034672178247923

Epoch: 6| Step: 7
Training loss: 3.1398723125457764
Validation loss: 2.7079140601619596

Epoch: 6| Step: 8
Training loss: 3.102395534515381
Validation loss: 2.707587067798902

Epoch: 6| Step: 9
Training loss: 2.9950454235076904
Validation loss: 2.704772241653935

Epoch: 6| Step: 10
Training loss: 2.7789669036865234
Validation loss: 2.7046826808683333

Epoch: 6| Step: 11
Training loss: 3.325002670288086
Validation loss: 2.7051489481361966

Epoch: 6| Step: 12
Training loss: 2.7296061515808105
Validation loss: 2.7071132788094143

Epoch: 6| Step: 13
Training loss: 3.51786732673645
Validation loss: 2.7031424250653995

Epoch: 58| Step: 0
Training loss: 1.846116065979004
Validation loss: 2.704050669106104

Epoch: 6| Step: 1
Training loss: 3.76546573638916
Validation loss: 2.705240762361916

Epoch: 6| Step: 2
Training loss: 2.8338325023651123
Validation loss: 2.7016442847508255

Epoch: 6| Step: 3
Training loss: 2.9556915760040283
Validation loss: 2.7053403649278867

Epoch: 6| Step: 4
Training loss: 3.2057859897613525
Validation loss: 2.7029458579196723

Epoch: 6| Step: 5
Training loss: 2.2042930126190186
Validation loss: 2.7042325055727394

Epoch: 6| Step: 6
Training loss: 3.3956105709075928
Validation loss: 2.703909074106524

Epoch: 6| Step: 7
Training loss: 2.986720085144043
Validation loss: 2.6999277555814354

Epoch: 6| Step: 8
Training loss: 3.378955841064453
Validation loss: 2.7050793965657554

Epoch: 6| Step: 9
Training loss: 3.0379350185394287
Validation loss: 2.7023918833783878

Epoch: 6| Step: 10
Training loss: 1.9566290378570557
Validation loss: 2.70172639559674

Epoch: 6| Step: 11
Training loss: 2.8898887634277344
Validation loss: 2.7010283931609123

Epoch: 6| Step: 12
Training loss: 3.105973482131958
Validation loss: 2.7005529531868557

Epoch: 6| Step: 13
Training loss: 2.0611793994903564
Validation loss: 2.701672428397722

Epoch: 59| Step: 0
Training loss: 2.792555809020996
Validation loss: 2.702093514063025

Epoch: 6| Step: 1
Training loss: 3.1449265480041504
Validation loss: 2.698849206329674

Epoch: 6| Step: 2
Training loss: 2.615992307662964
Validation loss: 2.7018519422059417

Epoch: 6| Step: 3
Training loss: 2.7723400592803955
Validation loss: 2.7003833709224576

Epoch: 6| Step: 4
Training loss: 2.5199780464172363
Validation loss: 2.700358324153449

Epoch: 6| Step: 5
Training loss: 2.683163642883301
Validation loss: 2.700118835254382

Epoch: 6| Step: 6
Training loss: 2.543414831161499
Validation loss: 2.702958227485739

Epoch: 6| Step: 7
Training loss: 2.789456367492676
Validation loss: 2.6998679471272293

Epoch: 6| Step: 8
Training loss: 3.288862943649292
Validation loss: 2.7069810282799507

Epoch: 6| Step: 9
Training loss: 2.0382542610168457
Validation loss: 2.7048211712991037

Epoch: 6| Step: 10
Training loss: 3.316041946411133
Validation loss: 2.7054171126375914

Epoch: 6| Step: 11
Training loss: 2.733808755874634
Validation loss: 2.700878458638345

Epoch: 6| Step: 12
Training loss: 4.166719436645508
Validation loss: 2.6987035659051712

Epoch: 6| Step: 13
Training loss: 2.376999616622925
Validation loss: 2.6946202913920083

Epoch: 60| Step: 0
Training loss: 2.976623058319092
Validation loss: 2.6944500169446393

Epoch: 6| Step: 1
Training loss: 3.005101203918457
Validation loss: 2.6954027837322605

Epoch: 6| Step: 2
Training loss: 3.3510489463806152
Validation loss: 2.693350335603119

Epoch: 6| Step: 3
Training loss: 2.3329734802246094
Validation loss: 2.6955547871128207

Epoch: 6| Step: 4
Training loss: 3.224257469177246
Validation loss: 2.6900113013482865

Epoch: 6| Step: 5
Training loss: 2.5194919109344482
Validation loss: 2.694788955873059

Epoch: 6| Step: 6
Training loss: 2.559202194213867
Validation loss: 2.6930547734742523

Epoch: 6| Step: 7
Training loss: 2.8099398612976074
Validation loss: 2.691934367661835

Epoch: 6| Step: 8
Training loss: 3.3415145874023438
Validation loss: 2.695584563798802

Epoch: 6| Step: 9
Training loss: 3.8856024742126465
Validation loss: 2.702283018378801

Epoch: 6| Step: 10
Training loss: 1.9952731132507324
Validation loss: 2.7059053041601695

Epoch: 6| Step: 11
Training loss: 2.480740547180176
Validation loss: 2.7052786965523996

Epoch: 6| Step: 12
Training loss: 2.7201106548309326
Validation loss: 2.7060046708712013

Epoch: 6| Step: 13
Training loss: 2.6502952575683594
Validation loss: 2.7106297144325833

Epoch: 61| Step: 0
Training loss: 3.103555679321289
Validation loss: 2.7035245741567304

Epoch: 6| Step: 1
Training loss: 2.255314350128174
Validation loss: 2.694406952909244

Epoch: 6| Step: 2
Training loss: 3.185889720916748
Validation loss: 2.690135186718356

Epoch: 6| Step: 3
Training loss: 1.8116669654846191
Validation loss: 2.6909177482769056

Epoch: 6| Step: 4
Training loss: 2.6496055126190186
Validation loss: 2.6890905518685617

Epoch: 6| Step: 5
Training loss: 2.7809717655181885
Validation loss: 2.690525101077172

Epoch: 6| Step: 6
Training loss: 3.409073829650879
Validation loss: 2.692675026514197

Epoch: 6| Step: 7
Training loss: 2.7194719314575195
Validation loss: 2.6910864050670336

Epoch: 6| Step: 8
Training loss: 3.4458417892456055
Validation loss: 2.6956935185258106

Epoch: 6| Step: 9
Training loss: 3.2614121437072754
Validation loss: 2.692338130807364

Epoch: 6| Step: 10
Training loss: 1.9717202186584473
Validation loss: 2.694114436385452

Epoch: 6| Step: 11
Training loss: 3.146674156188965
Validation loss: 2.694398000676145

Epoch: 6| Step: 12
Training loss: 2.8984885215759277
Validation loss: 2.6947923065513693

Epoch: 6| Step: 13
Training loss: 3.656588554382324
Validation loss: 2.6940716082049954

Epoch: 62| Step: 0
Training loss: 3.0823638439178467
Validation loss: 2.698755297609555

Epoch: 6| Step: 1
Training loss: 3.6108312606811523
Validation loss: 2.700777671670401

Epoch: 6| Step: 2
Training loss: 2.572786808013916
Validation loss: 2.7003025675332673

Epoch: 6| Step: 3
Training loss: 2.9801080226898193
Validation loss: 2.699387429862894

Epoch: 6| Step: 4
Training loss: 2.7150447368621826
Validation loss: 2.6934201102102957

Epoch: 6| Step: 5
Training loss: 2.0336334705352783
Validation loss: 2.6918140226794827

Epoch: 6| Step: 6
Training loss: 2.760382652282715
Validation loss: 2.689859482549852

Epoch: 6| Step: 7
Training loss: 3.5287246704101562
Validation loss: 2.6880625089009604

Epoch: 6| Step: 8
Training loss: 2.463012456893921
Validation loss: 2.685957993230512

Epoch: 6| Step: 9
Training loss: 2.6593451499938965
Validation loss: 2.6876863510377946

Epoch: 6| Step: 10
Training loss: 2.5330889225006104
Validation loss: 2.690200226281279

Epoch: 6| Step: 11
Training loss: 3.341919422149658
Validation loss: 2.6908094780419463

Epoch: 6| Step: 12
Training loss: 2.887566566467285
Validation loss: 2.6878101312985985

Epoch: 6| Step: 13
Training loss: 2.631239175796509
Validation loss: 2.6880850125384588

Epoch: 63| Step: 0
Training loss: 2.7776875495910645
Validation loss: 2.6872926271089943

Epoch: 6| Step: 1
Training loss: 2.654503583908081
Validation loss: 2.6868080913379626

Epoch: 6| Step: 2
Training loss: 2.593611478805542
Validation loss: 2.6877490525604575

Epoch: 6| Step: 3
Training loss: 3.0800280570983887
Validation loss: 2.6906226527306343

Epoch: 6| Step: 4
Training loss: 2.9649593830108643
Validation loss: 2.6913985718962965

Epoch: 6| Step: 5
Training loss: 2.769805908203125
Validation loss: 2.694584761896441

Epoch: 6| Step: 6
Training loss: 2.98183536529541
Validation loss: 2.693328765130812

Epoch: 6| Step: 7
Training loss: 3.3867597579956055
Validation loss: 2.6878169890372985

Epoch: 6| Step: 8
Training loss: 2.5559704303741455
Validation loss: 2.6879242953433784

Epoch: 6| Step: 9
Training loss: 3.316833257675171
Validation loss: 2.6852909211189515

Epoch: 6| Step: 10
Training loss: 3.2380189895629883
Validation loss: 2.6841914243595575

Epoch: 6| Step: 11
Training loss: 2.7822508811950684
Validation loss: 2.6859646151142735

Epoch: 6| Step: 12
Training loss: 2.34989595413208
Validation loss: 2.682173175196494

Epoch: 6| Step: 13
Training loss: 2.0467262268066406
Validation loss: 2.6836275336562947

Epoch: 64| Step: 0
Training loss: 2.030277967453003
Validation loss: 2.6842604273109028

Epoch: 6| Step: 1
Training loss: 3.6882190704345703
Validation loss: 2.682182927285471

Epoch: 6| Step: 2
Training loss: 2.7668991088867188
Validation loss: 2.6804703076680503

Epoch: 6| Step: 3
Training loss: 2.852046489715576
Validation loss: 2.682220002656342

Epoch: 6| Step: 4
Training loss: 2.242128372192383
Validation loss: 2.683770259221395

Epoch: 6| Step: 5
Training loss: 3.3657662868499756
Validation loss: 2.6848149145803144

Epoch: 6| Step: 6
Training loss: 2.90451717376709
Validation loss: 2.6898194615558912

Epoch: 6| Step: 7
Training loss: 3.0388102531433105
Validation loss: 2.692356394183251

Epoch: 6| Step: 8
Training loss: 2.6303651332855225
Validation loss: 2.6954849253418627

Epoch: 6| Step: 9
Training loss: 2.4527578353881836
Validation loss: 2.690553044760099

Epoch: 6| Step: 10
Training loss: 3.51920485496521
Validation loss: 2.6832744741952546

Epoch: 6| Step: 11
Training loss: 2.8460657596588135
Validation loss: 2.681764966698103

Epoch: 6| Step: 12
Training loss: 2.8209238052368164
Validation loss: 2.6838994513275805

Epoch: 6| Step: 13
Training loss: 2.467632532119751
Validation loss: 2.6853707016155286

Epoch: 65| Step: 0
Training loss: 2.327341318130493
Validation loss: 2.6785033723359466

Epoch: 6| Step: 1
Training loss: 3.237746238708496
Validation loss: 2.6822716138696157

Epoch: 6| Step: 2
Training loss: 2.3473570346832275
Validation loss: 2.6843649700123775

Epoch: 6| Step: 3
Training loss: 3.300750255584717
Validation loss: 2.683333860930576

Epoch: 6| Step: 4
Training loss: 2.307149887084961
Validation loss: 2.6839472837345575

Epoch: 6| Step: 5
Training loss: 3.2048511505126953
Validation loss: 2.6807967847393406

Epoch: 6| Step: 6
Training loss: 2.907153606414795
Validation loss: 2.6763922732363463

Epoch: 6| Step: 7
Training loss: 3.171391010284424
Validation loss: 2.6822881647335586

Epoch: 6| Step: 8
Training loss: 2.3157594203948975
Validation loss: 2.678816674858011

Epoch: 6| Step: 9
Training loss: 2.79288387298584
Validation loss: 2.6796613303563928

Epoch: 6| Step: 10
Training loss: 2.442784309387207
Validation loss: 2.680277124527962

Epoch: 6| Step: 11
Training loss: 3.2355329990386963
Validation loss: 2.680171835807062

Epoch: 6| Step: 12
Training loss: 2.761838436126709
Validation loss: 2.680964549382528

Epoch: 6| Step: 13
Training loss: 3.857267141342163
Validation loss: 2.680658881382276

Epoch: 66| Step: 0
Training loss: 3.1267805099487305
Validation loss: 2.6762503834180933

Epoch: 6| Step: 1
Training loss: 2.585803508758545
Validation loss: 2.679120220163817

Epoch: 6| Step: 2
Training loss: 2.845592498779297
Validation loss: 2.677534585357994

Epoch: 6| Step: 3
Training loss: 3.376586437225342
Validation loss: 2.6786874776245444

Epoch: 6| Step: 4
Training loss: 3.2035839557647705
Validation loss: 2.682656249692363

Epoch: 6| Step: 5
Training loss: 2.3509521484375
Validation loss: 2.683222468181323

Epoch: 6| Step: 6
Training loss: 2.892094612121582
Validation loss: 2.6808076725211194

Epoch: 6| Step: 7
Training loss: 2.5732247829437256
Validation loss: 2.6826017261833273

Epoch: 6| Step: 8
Training loss: 3.4176840782165527
Validation loss: 2.6797876229850193

Epoch: 6| Step: 9
Training loss: 1.6601319313049316
Validation loss: 2.6790287417750203

Epoch: 6| Step: 10
Training loss: 2.9452333450317383
Validation loss: 2.6760163922463693

Epoch: 6| Step: 11
Training loss: 3.0972867012023926
Validation loss: 2.6742990196392102

Epoch: 6| Step: 12
Training loss: 2.836719512939453
Validation loss: 2.6784474849700928

Epoch: 6| Step: 13
Training loss: 2.828045606613159
Validation loss: 2.67247619423815

Epoch: 67| Step: 0
Training loss: 2.858463764190674
Validation loss: 2.6788811324745097

Epoch: 6| Step: 1
Training loss: 2.7702813148498535
Validation loss: 2.6758103985940256

Epoch: 6| Step: 2
Training loss: 2.6963870525360107
Validation loss: 2.6765884455814155

Epoch: 6| Step: 3
Training loss: 2.9392237663269043
Validation loss: 2.674073508990708

Epoch: 6| Step: 4
Training loss: 3.2070274353027344
Validation loss: 2.6753071097917456

Epoch: 6| Step: 5
Training loss: 2.3131465911865234
Validation loss: 2.676060261264924

Epoch: 6| Step: 6
Training loss: 3.549344539642334
Validation loss: 2.6765761298518025

Epoch: 6| Step: 7
Training loss: 2.7923803329467773
Validation loss: 2.678644326425368

Epoch: 6| Step: 8
Training loss: 2.5035462379455566
Validation loss: 2.681273209151401

Epoch: 6| Step: 9
Training loss: 2.9951181411743164
Validation loss: 2.6777281761169434

Epoch: 6| Step: 10
Training loss: 3.2554640769958496
Validation loss: 2.675433502402357

Epoch: 6| Step: 11
Training loss: 2.4554648399353027
Validation loss: 2.673965415646953

Epoch: 6| Step: 12
Training loss: 3.0492100715637207
Validation loss: 2.6766664802387194

Epoch: 6| Step: 13
Training loss: 1.936431646347046
Validation loss: 2.674064008138513

Epoch: 68| Step: 0
Training loss: 2.8804612159729004
Validation loss: 2.6754107757281234

Epoch: 6| Step: 1
Training loss: 3.9953432083129883
Validation loss: 2.6740527947743735

Epoch: 6| Step: 2
Training loss: 2.494171619415283
Validation loss: 2.6722347633813017

Epoch: 6| Step: 3
Training loss: 1.9178094863891602
Validation loss: 2.6698065188623246

Epoch: 6| Step: 4
Training loss: 2.203793525695801
Validation loss: 2.670657011770433

Epoch: 6| Step: 5
Training loss: 3.222945213317871
Validation loss: 2.671695286227811

Epoch: 6| Step: 6
Training loss: 2.763486385345459
Validation loss: 2.6739974867913032

Epoch: 6| Step: 7
Training loss: 2.3925998210906982
Validation loss: 2.6778283990839475

Epoch: 6| Step: 8
Training loss: 2.9064033031463623
Validation loss: 2.675037343014953

Epoch: 6| Step: 9
Training loss: 3.2942442893981934
Validation loss: 2.678002554883239

Epoch: 6| Step: 10
Training loss: 2.8788399696350098
Validation loss: 2.6723202223418863

Epoch: 6| Step: 11
Training loss: 3.737288475036621
Validation loss: 2.6711610927376697

Epoch: 6| Step: 12
Training loss: 2.3592560291290283
Validation loss: 2.672837418894614

Epoch: 6| Step: 13
Training loss: 2.482926368713379
Validation loss: 2.6712115259580713

Epoch: 69| Step: 0
Training loss: 2.8432886600494385
Validation loss: 2.670217260237663

Epoch: 6| Step: 1
Training loss: 3.7564334869384766
Validation loss: 2.6685472714003695

Epoch: 6| Step: 2
Training loss: 3.07112455368042
Validation loss: 2.6707080743646108

Epoch: 6| Step: 3
Training loss: 2.9666433334350586
Validation loss: 2.673802742394068

Epoch: 6| Step: 4
Training loss: 2.9071850776672363
Validation loss: 2.672054160025812

Epoch: 6| Step: 5
Training loss: 3.068105697631836
Validation loss: 2.674696465974213

Epoch: 6| Step: 6
Training loss: 2.2346043586730957
Validation loss: 2.6718502531769457

Epoch: 6| Step: 7
Training loss: 3.3494980335235596
Validation loss: 2.6720861901519117

Epoch: 6| Step: 8
Training loss: 2.0544698238372803
Validation loss: 2.6699348880398657

Epoch: 6| Step: 9
Training loss: 3.098162889480591
Validation loss: 2.6709163624753236

Epoch: 6| Step: 10
Training loss: 2.6145339012145996
Validation loss: 2.6679776996694584

Epoch: 6| Step: 11
Training loss: 2.5297775268554688
Validation loss: 2.669562796110748

Epoch: 6| Step: 12
Training loss: 3.175374984741211
Validation loss: 2.6681449669663624

Epoch: 6| Step: 13
Training loss: 1.525949239730835
Validation loss: 2.6712356331527873

Epoch: 70| Step: 0
Training loss: 2.8386898040771484
Validation loss: 2.6770766627404

Epoch: 6| Step: 1
Training loss: 2.0714855194091797
Validation loss: 2.6764439049587456

Epoch: 6| Step: 2
Training loss: 3.04135799407959
Validation loss: 2.6758584078922065

Epoch: 6| Step: 3
Training loss: 3.0296926498413086
Validation loss: 2.670781199650098

Epoch: 6| Step: 4
Training loss: 3.552694320678711
Validation loss: 2.671263135889525

Epoch: 6| Step: 5
Training loss: 2.9639697074890137
Validation loss: 2.6716337870526057

Epoch: 6| Step: 6
Training loss: 2.4775137901306152
Validation loss: 2.6684936592655797

Epoch: 6| Step: 7
Training loss: 2.6412699222564697
Validation loss: 2.668962655528899

Epoch: 6| Step: 8
Training loss: 3.025200366973877
Validation loss: 2.665368474939818

Epoch: 6| Step: 9
Training loss: 2.2496607303619385
Validation loss: 2.667584334650347

Epoch: 6| Step: 10
Training loss: 3.435844898223877
Validation loss: 2.6679035207276702

Epoch: 6| Step: 11
Training loss: 2.636404514312744
Validation loss: 2.6681194433601956

Epoch: 6| Step: 12
Training loss: 2.4742095470428467
Validation loss: 2.6656791061483402

Epoch: 6| Step: 13
Training loss: 3.5351955890655518
Validation loss: 2.663995929943618

Epoch: 71| Step: 0
Training loss: 3.7096872329711914
Validation loss: 2.6620665391286216

Epoch: 6| Step: 1
Training loss: 2.6097967624664307
Validation loss: 2.6648486942373295

Epoch: 6| Step: 2
Training loss: 3.2522764205932617
Validation loss: 2.664300493014756

Epoch: 6| Step: 3
Training loss: 2.6118037700653076
Validation loss: 2.663978015222857

Epoch: 6| Step: 4
Training loss: 2.833977222442627
Validation loss: 2.668796613652219

Epoch: 6| Step: 5
Training loss: 2.7437903881073
Validation loss: 2.668189940914031

Epoch: 6| Step: 6
Training loss: 2.754072904586792
Validation loss: 2.667912693433864

Epoch: 6| Step: 7
Training loss: 2.8749547004699707
Validation loss: 2.66927194851701

Epoch: 6| Step: 8
Training loss: 3.524087429046631
Validation loss: 2.6644869183981292

Epoch: 6| Step: 9
Training loss: 2.4679903984069824
Validation loss: 2.6688880561500468

Epoch: 6| Step: 10
Training loss: 2.6073055267333984
Validation loss: 2.664359954095656

Epoch: 6| Step: 11
Training loss: 2.5928125381469727
Validation loss: 2.6647468613040064

Epoch: 6| Step: 12
Training loss: 2.506208658218384
Validation loss: 2.6689778092086955

Epoch: 6| Step: 13
Training loss: 2.248621702194214
Validation loss: 2.6622700409222673

Epoch: 72| Step: 0
Training loss: 2.900906562805176
Validation loss: 2.6627958307984056

Epoch: 6| Step: 1
Training loss: 3.3058042526245117
Validation loss: 2.66037388770811

Epoch: 6| Step: 2
Training loss: 2.0168867111206055
Validation loss: 2.661819983554143

Epoch: 6| Step: 3
Training loss: 2.4737565517425537
Validation loss: 2.664972571916478

Epoch: 6| Step: 4
Training loss: 3.525747776031494
Validation loss: 2.6645365120262228

Epoch: 6| Step: 5
Training loss: 2.7458648681640625
Validation loss: 2.664823301376835

Epoch: 6| Step: 6
Training loss: 3.1033267974853516
Validation loss: 2.6672299600416616

Epoch: 6| Step: 7
Training loss: 2.52217435836792
Validation loss: 2.677424564156481

Epoch: 6| Step: 8
Training loss: 3.452167510986328
Validation loss: 2.6787014904842583

Epoch: 6| Step: 9
Training loss: 2.3785135746002197
Validation loss: 2.686672543966642

Epoch: 6| Step: 10
Training loss: 2.866488218307495
Validation loss: 2.6839214704369985

Epoch: 6| Step: 11
Training loss: 2.3622941970825195
Validation loss: 2.6686769659801195

Epoch: 6| Step: 12
Training loss: 2.8860716819763184
Validation loss: 2.661964585704188

Epoch: 6| Step: 13
Training loss: 3.2732303142547607
Validation loss: 2.6630815177835445

Epoch: 73| Step: 0
Training loss: 2.901405096054077
Validation loss: 2.6606729492064445

Epoch: 6| Step: 1
Training loss: 3.322986125946045
Validation loss: 2.6664667385880665

Epoch: 6| Step: 2
Training loss: 2.16435170173645
Validation loss: 2.667540873250654

Epoch: 6| Step: 3
Training loss: 3.9512758255004883
Validation loss: 2.6654611710579164

Epoch: 6| Step: 4
Training loss: 2.3879387378692627
Validation loss: 2.66504809933324

Epoch: 6| Step: 5
Training loss: 2.744380474090576
Validation loss: 2.66579254211918

Epoch: 6| Step: 6
Training loss: 2.163440227508545
Validation loss: 2.6681808092260875

Epoch: 6| Step: 7
Training loss: 2.1455588340759277
Validation loss: 2.6699354828044934

Epoch: 6| Step: 8
Training loss: 1.9066519737243652
Validation loss: 2.6652473506107124

Epoch: 6| Step: 9
Training loss: 2.986750364303589
Validation loss: 2.664181455489128

Epoch: 6| Step: 10
Training loss: 3.713797092437744
Validation loss: 2.662439771877822

Epoch: 6| Step: 11
Training loss: 3.803542375564575
Validation loss: 2.6622453133265176

Epoch: 6| Step: 12
Training loss: 2.7903976440429688
Validation loss: 2.6642448338129188

Epoch: 6| Step: 13
Training loss: 2.721595048904419
Validation loss: 2.6665991403723277

Epoch: 74| Step: 0
Training loss: 2.5733442306518555
Validation loss: 2.665811692514727

Epoch: 6| Step: 1
Training loss: 3.3535213470458984
Validation loss: 2.669712133305047

Epoch: 6| Step: 2
Training loss: 3.4194066524505615
Validation loss: 2.671401193065028

Epoch: 6| Step: 3
Training loss: 2.5372226238250732
Validation loss: 2.663255947892384

Epoch: 6| Step: 4
Training loss: 2.2256228923797607
Validation loss: 2.6635444395003782

Epoch: 6| Step: 5
Training loss: 2.7615787982940674
Validation loss: 2.6625948311180196

Epoch: 6| Step: 6
Training loss: 3.2011313438415527
Validation loss: 2.662009587851904

Epoch: 6| Step: 7
Training loss: 2.698716640472412
Validation loss: 2.659189506243634

Epoch: 6| Step: 8
Training loss: 2.7704997062683105
Validation loss: 2.6617817519813456

Epoch: 6| Step: 9
Training loss: 2.5026354789733887
Validation loss: 2.6590573531325146

Epoch: 6| Step: 10
Training loss: 2.514537811279297
Validation loss: 2.661750652456796

Epoch: 6| Step: 11
Training loss: 2.5651421546936035
Validation loss: 2.662669938097718

Epoch: 6| Step: 12
Training loss: 3.866260290145874
Validation loss: 2.6607574544927126

Epoch: 6| Step: 13
Training loss: 2.45729923248291
Validation loss: 2.6605567803946872

Epoch: 75| Step: 0
Training loss: 2.9338061809539795
Validation loss: 2.661069772576773

Epoch: 6| Step: 1
Training loss: 2.485145330429077
Validation loss: 2.6606335127225487

Epoch: 6| Step: 2
Training loss: 3.5512635707855225
Validation loss: 2.658217268605386

Epoch: 6| Step: 3
Training loss: 2.3818089962005615
Validation loss: 2.6552363518745667

Epoch: 6| Step: 4
Training loss: 2.5720601081848145
Validation loss: 2.660640437115905

Epoch: 6| Step: 5
Training loss: 3.079683303833008
Validation loss: 2.6543763683688257

Epoch: 6| Step: 6
Training loss: 3.09987211227417
Validation loss: 2.6576618789344706

Epoch: 6| Step: 7
Training loss: 3.022897720336914
Validation loss: 2.6574312486956195

Epoch: 6| Step: 8
Training loss: 3.4175705909729004
Validation loss: 2.6528118271981516

Epoch: 6| Step: 9
Training loss: 2.3588995933532715
Validation loss: 2.6533152595643075

Epoch: 6| Step: 10
Training loss: 2.9641880989074707
Validation loss: 2.6553094079417567

Epoch: 6| Step: 11
Training loss: 3.0665793418884277
Validation loss: 2.654080455021192

Epoch: 6| Step: 12
Training loss: 2.1704535484313965
Validation loss: 2.6474692795866277

Epoch: 6| Step: 13
Training loss: 2.152984619140625
Validation loss: 2.6560053979196856

Epoch: 76| Step: 0
Training loss: 2.63590145111084
Validation loss: 2.6559159114796627

Epoch: 6| Step: 1
Training loss: 2.8550102710723877
Validation loss: 2.6574134185749996

Epoch: 6| Step: 2
Training loss: 2.9688875675201416
Validation loss: 2.6530707190113683

Epoch: 6| Step: 3
Training loss: 2.2348239421844482
Validation loss: 2.658591224301246

Epoch: 6| Step: 4
Training loss: 2.975050449371338
Validation loss: 2.65641180674235

Epoch: 6| Step: 5
Training loss: 2.8174991607666016
Validation loss: 2.6644829909006753

Epoch: 6| Step: 6
Training loss: 2.5082945823669434
Validation loss: 2.6608151184615267

Epoch: 6| Step: 7
Training loss: 3.4182214736938477
Validation loss: 2.659594028226791

Epoch: 6| Step: 8
Training loss: 2.945953607559204
Validation loss: 2.6518423275281022

Epoch: 6| Step: 9
Training loss: 3.1420464515686035
Validation loss: 2.6508373906535487

Epoch: 6| Step: 10
Training loss: 2.7103097438812256
Validation loss: 2.6525040211216098

Epoch: 6| Step: 11
Training loss: 3.0438194274902344
Validation loss: 2.6507567897919686

Epoch: 6| Step: 12
Training loss: 2.153254747390747
Validation loss: 2.652868991257042

Epoch: 6| Step: 13
Training loss: 3.375565528869629
Validation loss: 2.6545654932657876

Epoch: 77| Step: 0
Training loss: 2.590628147125244
Validation loss: 2.6508345296305995

Epoch: 6| Step: 1
Training loss: 2.5377910137176514
Validation loss: 2.649860703816978

Epoch: 6| Step: 2
Training loss: 2.9617669582366943
Validation loss: 2.652325548151488

Epoch: 6| Step: 3
Training loss: 2.7762646675109863
Validation loss: 2.648267069170552

Epoch: 6| Step: 4
Training loss: 3.2827794551849365
Validation loss: 2.6496089261065245

Epoch: 6| Step: 5
Training loss: 2.6017656326293945
Validation loss: 2.6520148720792545

Epoch: 6| Step: 6
Training loss: 3.062497615814209
Validation loss: 2.650257246468657

Epoch: 6| Step: 7
Training loss: 3.2664222717285156
Validation loss: 2.6512241235343357

Epoch: 6| Step: 8
Training loss: 3.5868070125579834
Validation loss: 2.6503701171567364

Epoch: 6| Step: 9
Training loss: 2.9110023975372314
Validation loss: 2.647785968677972

Epoch: 6| Step: 10
Training loss: 3.46854829788208
Validation loss: 2.647399563943186

Epoch: 6| Step: 11
Training loss: 2.397841453552246
Validation loss: 2.64667324866018

Epoch: 6| Step: 12
Training loss: 1.4014700651168823
Validation loss: 2.6433673315150763

Epoch: 6| Step: 13
Training loss: 2.510100841522217
Validation loss: 2.6452226843885196

Epoch: 78| Step: 0
Training loss: 2.9803128242492676
Validation loss: 2.6533073814966346

Epoch: 6| Step: 1
Training loss: 2.9563262462615967
Validation loss: 2.657818394322549

Epoch: 6| Step: 2
Training loss: 3.360851287841797
Validation loss: 2.657997556912002

Epoch: 6| Step: 3
Training loss: 2.215496778488159
Validation loss: 2.6604453978999967

Epoch: 6| Step: 4
Training loss: 3.042200803756714
Validation loss: 2.6638630385039956

Epoch: 6| Step: 5
Training loss: 2.3541574478149414
Validation loss: 2.667713781838776

Epoch: 6| Step: 6
Training loss: 3.2739644050598145
Validation loss: 2.6635915387061333

Epoch: 6| Step: 7
Training loss: 2.702353000640869
Validation loss: 2.658601507063835

Epoch: 6| Step: 8
Training loss: 2.609095573425293
Validation loss: 2.656039899395358

Epoch: 6| Step: 9
Training loss: 2.429637908935547
Validation loss: 2.649488790060884

Epoch: 6| Step: 10
Training loss: 3.3716087341308594
Validation loss: 2.6502151489257812

Epoch: 6| Step: 11
Training loss: 2.142336845397949
Validation loss: 2.649960979338615

Epoch: 6| Step: 12
Training loss: 3.1015069484710693
Validation loss: 2.647342081992857

Epoch: 6| Step: 13
Training loss: 2.8900346755981445
Validation loss: 2.645132198128649

Epoch: 79| Step: 0
Training loss: 2.2616360187530518
Validation loss: 2.646170308513026

Epoch: 6| Step: 1
Training loss: 2.9909112453460693
Validation loss: 2.643100905162032

Epoch: 6| Step: 2
Training loss: 3.1205883026123047
Validation loss: 2.6414914387528614

Epoch: 6| Step: 3
Training loss: 2.3915634155273438
Validation loss: 2.643789017072288

Epoch: 6| Step: 4
Training loss: 2.7270259857177734
Validation loss: 2.6412551967046594

Epoch: 6| Step: 5
Training loss: 2.8676319122314453
Validation loss: 2.6406353289081204

Epoch: 6| Step: 6
Training loss: 3.7192087173461914
Validation loss: 2.6437792214014197

Epoch: 6| Step: 7
Training loss: 2.6071369647979736
Validation loss: 2.6424751179192656

Epoch: 6| Step: 8
Training loss: 3.2499656677246094
Validation loss: 2.6417795509420414

Epoch: 6| Step: 9
Training loss: 3.015991687774658
Validation loss: 2.6432294461034958

Epoch: 6| Step: 10
Training loss: 2.8702850341796875
Validation loss: 2.6420602875371135

Epoch: 6| Step: 11
Training loss: 2.2283518314361572
Validation loss: 2.6417136371776624

Epoch: 6| Step: 12
Training loss: 2.8116798400878906
Validation loss: 2.6432995283475487

Epoch: 6| Step: 13
Training loss: 2.368472099304199
Validation loss: 2.6424197535361014

Epoch: 80| Step: 0
Training loss: 3.347714900970459
Validation loss: 2.641909892841052

Epoch: 6| Step: 1
Training loss: 3.3489179611206055
Validation loss: 2.6407047548601703

Epoch: 6| Step: 2
Training loss: 2.8621175289154053
Validation loss: 2.639834750083185

Epoch: 6| Step: 3
Training loss: 2.7605056762695312
Validation loss: 2.636186320294616

Epoch: 6| Step: 4
Training loss: 2.584916114807129
Validation loss: 2.6395859000503377

Epoch: 6| Step: 5
Training loss: 2.324586868286133
Validation loss: 2.6388612588246665

Epoch: 6| Step: 6
Training loss: 2.802438735961914
Validation loss: 2.638350543155465

Epoch: 6| Step: 7
Training loss: 2.3774924278259277
Validation loss: 2.6452357410102763

Epoch: 6| Step: 8
Training loss: 3.3019156455993652
Validation loss: 2.6453584676147788

Epoch: 6| Step: 9
Training loss: 2.3876430988311768
Validation loss: 2.6428280440709924

Epoch: 6| Step: 10
Training loss: 3.141414165496826
Validation loss: 2.641805471912507

Epoch: 6| Step: 11
Training loss: 2.70210337638855
Validation loss: 2.643885097196025

Epoch: 6| Step: 12
Training loss: 3.0646462440490723
Validation loss: 2.640752136066396

Epoch: 6| Step: 13
Training loss: 1.9974474906921387
Validation loss: 2.6425966729399977

Epoch: 81| Step: 0
Training loss: 2.0855069160461426
Validation loss: 2.63842132014613

Epoch: 6| Step: 1
Training loss: 3.5263619422912598
Validation loss: 2.650148948033651

Epoch: 6| Step: 2
Training loss: 1.9367929697036743
Validation loss: 2.6532578699050413

Epoch: 6| Step: 3
Training loss: 3.183405876159668
Validation loss: 2.6526808097798336

Epoch: 6| Step: 4
Training loss: 3.6632461547851562
Validation loss: 2.6404236273099015

Epoch: 6| Step: 5
Training loss: 3.039677143096924
Validation loss: 2.6344998241752706

Epoch: 6| Step: 6
Training loss: 2.6892952919006348
Validation loss: 2.6283943166014967

Epoch: 6| Step: 7
Training loss: 2.422687530517578
Validation loss: 2.6288629783097135

Epoch: 6| Step: 8
Training loss: 2.091718912124634
Validation loss: 2.628529005153205

Epoch: 6| Step: 9
Training loss: 3.2732534408569336
Validation loss: 2.63698903206856

Epoch: 6| Step: 10
Training loss: 2.345137357711792
Validation loss: 2.6367103438223563

Epoch: 6| Step: 11
Training loss: 2.6508514881134033
Validation loss: 2.6286880303454656

Epoch: 6| Step: 12
Training loss: 3.416963577270508
Validation loss: 2.627411621873097

Epoch: 6| Step: 13
Training loss: 3.11690616607666
Validation loss: 2.622916477982716

Epoch: 82| Step: 0
Training loss: 2.3243672847747803
Validation loss: 2.623689848889587

Epoch: 6| Step: 1
Training loss: 2.3042409420013428
Validation loss: 2.6217613579124532

Epoch: 6| Step: 2
Training loss: 2.278634548187256
Validation loss: 2.6190846299612396

Epoch: 6| Step: 3
Training loss: 3.823991298675537
Validation loss: 2.6199960477890505

Epoch: 6| Step: 4
Training loss: 2.4664974212646484
Validation loss: 2.6180846973132064

Epoch: 6| Step: 5
Training loss: 3.7560863494873047
Validation loss: 2.62007704857857

Epoch: 6| Step: 6
Training loss: 2.596346378326416
Validation loss: 2.619539947919948

Epoch: 6| Step: 7
Training loss: 2.645280122756958
Validation loss: 2.617112067437941

Epoch: 6| Step: 8
Training loss: 3.068639039993286
Validation loss: 2.6182852227200746

Epoch: 6| Step: 9
Training loss: 2.8639636039733887
Validation loss: 2.6171137927680888

Epoch: 6| Step: 10
Training loss: 2.9649949073791504
Validation loss: 2.615702759835028

Epoch: 6| Step: 11
Training loss: 3.09260892868042
Validation loss: 2.616207820112987

Epoch: 6| Step: 12
Training loss: 2.584287405014038
Validation loss: 2.613874525152227

Epoch: 6| Step: 13
Training loss: 2.1144518852233887
Validation loss: 2.621100423156574

Epoch: 83| Step: 0
Training loss: 2.786691665649414
Validation loss: 2.622688211420531

Epoch: 6| Step: 1
Training loss: 2.897956609725952
Validation loss: 2.6299273839560886

Epoch: 6| Step: 2
Training loss: 3.636826992034912
Validation loss: 2.6179179606899137

Epoch: 6| Step: 3
Training loss: 1.704399585723877
Validation loss: 2.616217913166169

Epoch: 6| Step: 4
Training loss: 2.2891101837158203
Validation loss: 2.6175912708364506

Epoch: 6| Step: 5
Training loss: 3.3639748096466064
Validation loss: 2.618802177008762

Epoch: 6| Step: 6
Training loss: 2.5041699409484863
Validation loss: 2.619477048996956

Epoch: 6| Step: 7
Training loss: 2.9986777305603027
Validation loss: 2.618664597952238

Epoch: 6| Step: 8
Training loss: 2.997661590576172
Validation loss: 2.619157511700866

Epoch: 6| Step: 9
Training loss: 2.8765485286712646
Validation loss: 2.612955262584071

Epoch: 6| Step: 10
Training loss: 2.962679862976074
Validation loss: 2.614059953279393

Epoch: 6| Step: 11
Training loss: 2.74550199508667
Validation loss: 2.6153605727739233

Epoch: 6| Step: 12
Training loss: 2.4842638969421387
Validation loss: 2.618855796834474

Epoch: 6| Step: 13
Training loss: 2.852855682373047
Validation loss: 2.615880766222554

Epoch: 84| Step: 0
Training loss: 3.4507763385772705
Validation loss: 2.6181774908496487

Epoch: 6| Step: 1
Training loss: 3.271573066711426
Validation loss: 2.616545905349075

Epoch: 6| Step: 2
Training loss: 3.031069278717041
Validation loss: 2.6172865180559057

Epoch: 6| Step: 3
Training loss: 3.8044369220733643
Validation loss: 2.6176676109272945

Epoch: 6| Step: 4
Training loss: 3.2385737895965576
Validation loss: 2.6124669172430552

Epoch: 6| Step: 5
Training loss: 2.213538646697998
Validation loss: 2.6168914225793656

Epoch: 6| Step: 6
Training loss: 1.9230425357818604
Validation loss: 2.618384607376591

Epoch: 6| Step: 7
Training loss: 3.099797010421753
Validation loss: 2.617961355434951

Epoch: 6| Step: 8
Training loss: 2.8998069763183594
Validation loss: 2.6182974384677027

Epoch: 6| Step: 9
Training loss: 1.4897408485412598
Validation loss: 2.6217447352665726

Epoch: 6| Step: 10
Training loss: 2.3417019844055176
Validation loss: 2.6254878787584204

Epoch: 6| Step: 11
Training loss: 2.6143195629119873
Validation loss: 2.6179659930608605

Epoch: 6| Step: 12
Training loss: 3.3261685371398926
Validation loss: 2.6208384370291107

Epoch: 6| Step: 13
Training loss: 1.9871221780776978
Validation loss: 2.618332391144127

Epoch: 85| Step: 0
Training loss: 2.154839038848877
Validation loss: 2.609623121958907

Epoch: 6| Step: 1
Training loss: 2.2103073596954346
Validation loss: 2.6100096548757246

Epoch: 6| Step: 2
Training loss: 2.6066017150878906
Validation loss: 2.603475273296397

Epoch: 6| Step: 3
Training loss: 2.5541694164276123
Validation loss: 2.607142504825387

Epoch: 6| Step: 4
Training loss: 3.3609046936035156
Validation loss: 2.6065650165721936

Epoch: 6| Step: 5
Training loss: 3.28061580657959
Validation loss: 2.605347156524658

Epoch: 6| Step: 6
Training loss: 2.6653363704681396
Validation loss: 2.6089435726083736

Epoch: 6| Step: 7
Training loss: 3.7662479877471924
Validation loss: 2.6080586987157024

Epoch: 6| Step: 8
Training loss: 2.201162338256836
Validation loss: 2.607592039210822

Epoch: 6| Step: 9
Training loss: 3.3481693267822266
Validation loss: 2.610107514166063

Epoch: 6| Step: 10
Training loss: 2.545804023742676
Validation loss: 2.6085336182707097

Epoch: 6| Step: 11
Training loss: 2.9583568572998047
Validation loss: 2.607412527966243

Epoch: 6| Step: 12
Training loss: 2.6602933406829834
Validation loss: 2.6083095176245576

Epoch: 6| Step: 13
Training loss: 2.667713165283203
Validation loss: 2.6106185349085

Epoch: 86| Step: 0
Training loss: 2.5694212913513184
Validation loss: 2.612529359838014

Epoch: 6| Step: 1
Training loss: 2.2571802139282227
Validation loss: 2.614299064041466

Epoch: 6| Step: 2
Training loss: 2.8740711212158203
Validation loss: 2.614100561347059

Epoch: 6| Step: 3
Training loss: 2.847963809967041
Validation loss: 2.616510119489444

Epoch: 6| Step: 4
Training loss: 3.4890494346618652
Validation loss: 2.615685655224708

Epoch: 6| Step: 5
Training loss: 2.639349937438965
Validation loss: 2.6173985670971613

Epoch: 6| Step: 6
Training loss: 2.8587799072265625
Validation loss: 2.617027941570487

Epoch: 6| Step: 7
Training loss: 3.0630249977111816
Validation loss: 2.6200579161285074

Epoch: 6| Step: 8
Training loss: 2.1909611225128174
Validation loss: 2.613167514083206

Epoch: 6| Step: 9
Training loss: 2.1282060146331787
Validation loss: 2.6101295384027625

Epoch: 6| Step: 10
Training loss: 3.522897720336914
Validation loss: 2.6075897652615785

Epoch: 6| Step: 11
Training loss: 2.842007637023926
Validation loss: 2.607798448172949

Epoch: 6| Step: 12
Training loss: 2.6781229972839355
Validation loss: 2.6015858316934235

Epoch: 6| Step: 13
Training loss: 3.282902717590332
Validation loss: 2.6042766827408985

Epoch: 87| Step: 0
Training loss: 2.320603132247925
Validation loss: 2.603779528730659

Epoch: 6| Step: 1
Training loss: 3.422912120819092
Validation loss: 2.6060158668025846

Epoch: 6| Step: 2
Training loss: 3.6778430938720703
Validation loss: 2.603746565439368

Epoch: 6| Step: 3
Training loss: 2.379843235015869
Validation loss: 2.6034749272049114

Epoch: 6| Step: 4
Training loss: 2.515562057495117
Validation loss: 2.6033888324614494

Epoch: 6| Step: 5
Training loss: 2.4033384323120117
Validation loss: 2.605981737054804

Epoch: 6| Step: 6
Training loss: 2.764744758605957
Validation loss: 2.6032337527121268

Epoch: 6| Step: 7
Training loss: 3.156174898147583
Validation loss: 2.604230493627569

Epoch: 6| Step: 8
Training loss: 2.81394362449646
Validation loss: 2.6040030576849498

Epoch: 6| Step: 9
Training loss: 2.918405532836914
Validation loss: 2.610489724784769

Epoch: 6| Step: 10
Training loss: 3.388791084289551
Validation loss: 2.6087888825324272

Epoch: 6| Step: 11
Training loss: 2.567899703979492
Validation loss: 2.611837979285948

Epoch: 6| Step: 12
Training loss: 2.190291166305542
Validation loss: 2.618398363872241

Epoch: 6| Step: 13
Training loss: 2.236443042755127
Validation loss: 2.6133913891289824

Epoch: 88| Step: 0
Training loss: 2.6186819076538086
Validation loss: 2.6112188139269428

Epoch: 6| Step: 1
Training loss: 2.8115768432617188
Validation loss: 2.6036911882380003

Epoch: 6| Step: 2
Training loss: 3.4982385635375977
Validation loss: 2.598112629305932

Epoch: 6| Step: 3
Training loss: 1.8309345245361328
Validation loss: 2.598746379216512

Epoch: 6| Step: 4
Training loss: 2.099646806716919
Validation loss: 2.5982662734164985

Epoch: 6| Step: 5
Training loss: 2.9872336387634277
Validation loss: 2.5974867138811337

Epoch: 6| Step: 6
Training loss: 3.858269214630127
Validation loss: 2.5959499959022767

Epoch: 6| Step: 7
Training loss: 3.025768756866455
Validation loss: 2.59605485393155

Epoch: 6| Step: 8
Training loss: 2.531215190887451
Validation loss: 2.596103314430483

Epoch: 6| Step: 9
Training loss: 2.944201946258545
Validation loss: 2.5976168801707606

Epoch: 6| Step: 10
Training loss: 2.9838247299194336
Validation loss: 2.596261347493818

Epoch: 6| Step: 11
Training loss: 2.6258649826049805
Validation loss: 2.5966555251870105

Epoch: 6| Step: 12
Training loss: 2.0450592041015625
Validation loss: 2.598303697442496

Epoch: 6| Step: 13
Training loss: 3.301302433013916
Validation loss: 2.5974811853901034

Epoch: 89| Step: 0
Training loss: 2.665334701538086
Validation loss: 2.5954522522546912

Epoch: 6| Step: 1
Training loss: 3.4788854122161865
Validation loss: 2.5951201685013308

Epoch: 6| Step: 2
Training loss: 2.4904513359069824
Validation loss: 2.595707767753191

Epoch: 6| Step: 3
Training loss: 2.0667312145233154
Validation loss: 2.5922823426544026

Epoch: 6| Step: 4
Training loss: 2.5717833042144775
Validation loss: 2.594379139202897

Epoch: 6| Step: 5
Training loss: 2.825068473815918
Validation loss: 2.597024184401317

Epoch: 6| Step: 6
Training loss: 2.91019606590271
Validation loss: 2.596461357608918

Epoch: 6| Step: 7
Training loss: 1.9405347108840942
Validation loss: 2.597948205086493

Epoch: 6| Step: 8
Training loss: 2.622793674468994
Validation loss: 2.5962624831866195

Epoch: 6| Step: 9
Training loss: 3.314013957977295
Validation loss: 2.594367678447436

Epoch: 6| Step: 10
Training loss: 3.3361058235168457
Validation loss: 2.5937658432991273

Epoch: 6| Step: 11
Training loss: 3.5685510635375977
Validation loss: 2.592708251809561

Epoch: 6| Step: 12
Training loss: 2.435088872909546
Validation loss: 2.593700234607984

Epoch: 6| Step: 13
Training loss: 2.555483818054199
Validation loss: 2.589988059895013

Epoch: 90| Step: 0
Training loss: 2.2504990100860596
Validation loss: 2.5888203472219486

Epoch: 6| Step: 1
Training loss: 3.009751319885254
Validation loss: 2.5904823631368656

Epoch: 6| Step: 2
Training loss: 2.84529709815979
Validation loss: 2.592607303332257

Epoch: 6| Step: 3
Training loss: 2.5716376304626465
Validation loss: 2.594558226164951

Epoch: 6| Step: 4
Training loss: 3.1709303855895996
Validation loss: 2.589575257352603

Epoch: 6| Step: 5
Training loss: 4.107538223266602
Validation loss: 2.592549234308222

Epoch: 6| Step: 6
Training loss: 2.734811305999756
Validation loss: 2.5902468619808072

Epoch: 6| Step: 7
Training loss: 2.6965370178222656
Validation loss: 2.590288931323636

Epoch: 6| Step: 8
Training loss: 2.1718523502349854
Validation loss: 2.5886315658528316

Epoch: 6| Step: 9
Training loss: 2.1484665870666504
Validation loss: 2.588137957357591

Epoch: 6| Step: 10
Training loss: 3.0389926433563232
Validation loss: 2.5885051091512046

Epoch: 6| Step: 11
Training loss: 3.3132238388061523
Validation loss: 2.5974169033829884

Epoch: 6| Step: 12
Training loss: 2.376132011413574
Validation loss: 2.591073925777148

Epoch: 6| Step: 13
Training loss: 2.0930211544036865
Validation loss: 2.6043538790877148

Epoch: 91| Step: 0
Training loss: 2.549050807952881
Validation loss: 2.606345761206842

Epoch: 6| Step: 1
Training loss: 2.9161384105682373
Validation loss: 2.616710014240716

Epoch: 6| Step: 2
Training loss: 3.0335519313812256
Validation loss: 2.6634666535162155

Epoch: 6| Step: 3
Training loss: 3.3870835304260254
Validation loss: 2.663739945298882

Epoch: 6| Step: 4
Training loss: 3.002917766571045
Validation loss: 2.656593512463313

Epoch: 6| Step: 5
Training loss: 2.9722542762756348
Validation loss: 2.638045649374685

Epoch: 6| Step: 6
Training loss: 2.2358922958374023
Validation loss: 2.60501516249872

Epoch: 6| Step: 7
Training loss: 2.3457682132720947
Validation loss: 2.59929213728956

Epoch: 6| Step: 8
Training loss: 2.810054302215576
Validation loss: 2.5972185903979885

Epoch: 6| Step: 9
Training loss: 3.0165481567382812
Validation loss: 2.5934844734848186

Epoch: 6| Step: 10
Training loss: 2.6461565494537354
Validation loss: 2.5873507145912416

Epoch: 6| Step: 11
Training loss: 2.735640287399292
Validation loss: 2.5860563888344714

Epoch: 6| Step: 12
Training loss: 2.5267481803894043
Validation loss: 2.588849042051582

Epoch: 6| Step: 13
Training loss: 2.8250486850738525
Validation loss: 2.5882812110326623

Epoch: 92| Step: 0
Training loss: 2.233811378479004
Validation loss: 2.591314915687807

Epoch: 6| Step: 1
Training loss: 3.868893623352051
Validation loss: 2.5897962021571335

Epoch: 6| Step: 2
Training loss: 3.089292526245117
Validation loss: 2.5902118631588515

Epoch: 6| Step: 3
Training loss: 2.4654767513275146
Validation loss: 2.591637606261879

Epoch: 6| Step: 4
Training loss: 2.4484610557556152
Validation loss: 2.5916974467615925

Epoch: 6| Step: 5
Training loss: 2.6665749549865723
Validation loss: 2.5926537001004784

Epoch: 6| Step: 6
Training loss: 3.099626302719116
Validation loss: 2.5922205499423447

Epoch: 6| Step: 7
Training loss: 2.238862991333008
Validation loss: 2.590010613523504

Epoch: 6| Step: 8
Training loss: 2.869053363800049
Validation loss: 2.5840202352052093

Epoch: 6| Step: 9
Training loss: 2.635376214981079
Validation loss: 2.585068172024142

Epoch: 6| Step: 10
Training loss: 2.6541643142700195
Validation loss: 2.5900897851554294

Epoch: 6| Step: 11
Training loss: 3.170985221862793
Validation loss: 2.5932483468004452

Epoch: 6| Step: 12
Training loss: 2.8582215309143066
Validation loss: 2.593099201879194

Epoch: 6| Step: 13
Training loss: 2.428887128829956
Validation loss: 2.59798494462044

Epoch: 93| Step: 0
Training loss: 2.882906198501587
Validation loss: 2.6015804172844015

Epoch: 6| Step: 1
Training loss: 2.7736170291900635
Validation loss: 2.592023390595631

Epoch: 6| Step: 2
Training loss: 2.624176025390625
Validation loss: 2.589495419174112

Epoch: 6| Step: 3
Training loss: 2.6281795501708984
Validation loss: 2.584896505519908

Epoch: 6| Step: 4
Training loss: 2.5837011337280273
Validation loss: 2.5884231290509625

Epoch: 6| Step: 5
Training loss: 2.2943058013916016
Validation loss: 2.5830000574870775

Epoch: 6| Step: 6
Training loss: 3.205843925476074
Validation loss: 2.5864833606186735

Epoch: 6| Step: 7
Training loss: 2.950778007507324
Validation loss: 2.5852102028426303

Epoch: 6| Step: 8
Training loss: 2.856858253479004
Validation loss: 2.5886965464520197

Epoch: 6| Step: 9
Training loss: 1.6141600608825684
Validation loss: 2.5845704514493226

Epoch: 6| Step: 10
Training loss: 2.442981719970703
Validation loss: 2.586241214506088

Epoch: 6| Step: 11
Training loss: 3.866380214691162
Validation loss: 2.582332952048189

Epoch: 6| Step: 12
Training loss: 2.603242874145508
Validation loss: 2.5834230863919823

Epoch: 6| Step: 13
Training loss: 4.0460686683654785
Validation loss: 2.5866892158344226

Epoch: 94| Step: 0
Training loss: 2.759514331817627
Validation loss: 2.587106304783975

Epoch: 6| Step: 1
Training loss: 2.6321423053741455
Validation loss: 2.5860256892378612

Epoch: 6| Step: 2
Training loss: 2.8895444869995117
Validation loss: 2.58856786194668

Epoch: 6| Step: 3
Training loss: 2.4390316009521484
Validation loss: 2.5847864381728636

Epoch: 6| Step: 4
Training loss: 2.2994747161865234
Validation loss: 2.584448152972806

Epoch: 6| Step: 5
Training loss: 2.971266984939575
Validation loss: 2.583730912977649

Epoch: 6| Step: 6
Training loss: 3.0266683101654053
Validation loss: 2.5854184012259207

Epoch: 6| Step: 7
Training loss: 2.372390031814575
Validation loss: 2.5856091463437645

Epoch: 6| Step: 8
Training loss: 2.9033608436584473
Validation loss: 2.5835073096777803

Epoch: 6| Step: 9
Training loss: 2.333569049835205
Validation loss: 2.580252480763261

Epoch: 6| Step: 10
Training loss: 3.457754135131836
Validation loss: 2.580228582505257

Epoch: 6| Step: 11
Training loss: 3.0764379501342773
Validation loss: 2.5861732677746843

Epoch: 6| Step: 12
Training loss: 2.866687297821045
Validation loss: 2.591457318234187

Epoch: 6| Step: 13
Training loss: 2.600804567337036
Validation loss: 2.590470083298222

Epoch: 95| Step: 0
Training loss: 2.487527847290039
Validation loss: 2.6013808429882093

Epoch: 6| Step: 1
Training loss: 2.409346580505371
Validation loss: 2.616955634086363

Epoch: 6| Step: 2
Training loss: 2.3414077758789062
Validation loss: 2.6278825934215257

Epoch: 6| Step: 3
Training loss: 3.2280240058898926
Validation loss: 2.6353986135093113

Epoch: 6| Step: 4
Training loss: 2.9638195037841797
Validation loss: 2.6600373406564035

Epoch: 6| Step: 5
Training loss: 3.617481231689453
Validation loss: 2.658826853639336

Epoch: 6| Step: 6
Training loss: 3.319267988204956
Validation loss: 2.6280558032374226

Epoch: 6| Step: 7
Training loss: 2.587857723236084
Validation loss: 2.6237166184251026

Epoch: 6| Step: 8
Training loss: 1.7551932334899902
Validation loss: 2.5994704410594

Epoch: 6| Step: 9
Training loss: 2.00447416305542
Validation loss: 2.5923433098741757

Epoch: 6| Step: 10
Training loss: 3.549347400665283
Validation loss: 2.58338600333019

Epoch: 6| Step: 11
Training loss: 2.6086294651031494
Validation loss: 2.5839120546976724

Epoch: 6| Step: 12
Training loss: 3.042330265045166
Validation loss: 2.5812715356067946

Epoch: 6| Step: 13
Training loss: 2.9260177612304688
Validation loss: 2.58325433474715

Epoch: 96| Step: 0
Training loss: 2.5146336555480957
Validation loss: 2.590065151132563

Epoch: 6| Step: 1
Training loss: 3.1589274406433105
Validation loss: 2.5972743034362793

Epoch: 6| Step: 2
Training loss: 3.1922011375427246
Validation loss: 2.5908071405144146

Epoch: 6| Step: 3
Training loss: 2.6649045944213867
Validation loss: 2.5889627523319696

Epoch: 6| Step: 4
Training loss: 3.2478911876678467
Validation loss: 2.5969890471427672

Epoch: 6| Step: 5
Training loss: 2.673089027404785
Validation loss: 2.5887486165569675

Epoch: 6| Step: 6
Training loss: 3.026430606842041
Validation loss: 2.5828249069952194

Epoch: 6| Step: 7
Training loss: 2.354736328125
Validation loss: 2.581269197566535

Epoch: 6| Step: 8
Training loss: 2.7878475189208984
Validation loss: 2.5758716675543014

Epoch: 6| Step: 9
Training loss: 2.4389259815216064
Validation loss: 2.57852925280089

Epoch: 6| Step: 10
Training loss: 2.9523584842681885
Validation loss: 2.5776578918580086

Epoch: 6| Step: 11
Training loss: 2.3164334297180176
Validation loss: 2.585099579185568

Epoch: 6| Step: 12
Training loss: 2.705500602722168
Validation loss: 2.5984414546720442

Epoch: 6| Step: 13
Training loss: 2.881349563598633
Validation loss: 2.5951091345920356

Epoch: 97| Step: 0
Training loss: 2.6306357383728027
Validation loss: 2.602606547776089

Epoch: 6| Step: 1
Training loss: 2.498872756958008
Validation loss: 2.6064143129574355

Epoch: 6| Step: 2
Training loss: 2.522327423095703
Validation loss: 2.610519496343469

Epoch: 6| Step: 3
Training loss: 2.8368887901306152
Validation loss: 2.6213950931384997

Epoch: 6| Step: 4
Training loss: 3.236849069595337
Validation loss: 2.629441733001381

Epoch: 6| Step: 5
Training loss: 2.963378429412842
Validation loss: 2.621656992102182

Epoch: 6| Step: 6
Training loss: 2.293205499649048
Validation loss: 2.6205844417695077

Epoch: 6| Step: 7
Training loss: 2.652117967605591
Validation loss: 2.6192189032031643

Epoch: 6| Step: 8
Training loss: 3.3814382553100586
Validation loss: 2.6057064148687545

Epoch: 6| Step: 9
Training loss: 2.739450454711914
Validation loss: 2.5941234173313266

Epoch: 6| Step: 10
Training loss: 2.9744315147399902
Validation loss: 2.586980237755724

Epoch: 6| Step: 11
Training loss: 3.0993454456329346
Validation loss: 2.58189251858701

Epoch: 6| Step: 12
Training loss: 2.2382915019989014
Validation loss: 2.5744830510949575

Epoch: 6| Step: 13
Training loss: 2.938408613204956
Validation loss: 2.5807569642220773

Epoch: 98| Step: 0
Training loss: 2.522336959838867
Validation loss: 2.5819213082713466

Epoch: 6| Step: 1
Training loss: 2.5024220943450928
Validation loss: 2.5807905966235745

Epoch: 6| Step: 2
Training loss: 2.3441901206970215
Validation loss: 2.5786925772184968

Epoch: 6| Step: 3
Training loss: 3.25423526763916
Validation loss: 2.5815046628316245

Epoch: 6| Step: 4
Training loss: 2.8658504486083984
Validation loss: 2.5755155701791086

Epoch: 6| Step: 5
Training loss: 3.0781774520874023
Validation loss: 2.5832222533482376

Epoch: 6| Step: 6
Training loss: 3.9061145782470703
Validation loss: 2.581867398754243

Epoch: 6| Step: 7
Training loss: 2.563157320022583
Validation loss: 2.577395833948607

Epoch: 6| Step: 8
Training loss: 2.682260513305664
Validation loss: 2.5734641346880185

Epoch: 6| Step: 9
Training loss: 2.5178709030151367
Validation loss: 2.5772270566673687

Epoch: 6| Step: 10
Training loss: 2.7752251625061035
Validation loss: 2.5701997459575696

Epoch: 6| Step: 11
Training loss: 1.9401133060455322
Validation loss: 2.574914837396273

Epoch: 6| Step: 12
Training loss: 2.6266555786132812
Validation loss: 2.5760255449561664

Epoch: 6| Step: 13
Training loss: 3.358741521835327
Validation loss: 2.576721924607472

Epoch: 99| Step: 0
Training loss: 2.218623638153076
Validation loss: 2.5705456502975954

Epoch: 6| Step: 1
Training loss: 2.4683713912963867
Validation loss: 2.5747276275388655

Epoch: 6| Step: 2
Training loss: 3.099897623062134
Validation loss: 2.5734092086874027

Epoch: 6| Step: 3
Training loss: 3.0205397605895996
Validation loss: 2.5745334753426175

Epoch: 6| Step: 4
Training loss: 2.7950479984283447
Validation loss: 2.5763934273873605

Epoch: 6| Step: 5
Training loss: 2.608569860458374
Validation loss: 2.5779290994008384

Epoch: 6| Step: 6
Training loss: 2.3290202617645264
Validation loss: 2.578309392416349

Epoch: 6| Step: 7
Training loss: 3.3850204944610596
Validation loss: 2.578493559232322

Epoch: 6| Step: 8
Training loss: 3.379539966583252
Validation loss: 2.58481700189652

Epoch: 6| Step: 9
Training loss: 2.4415640830993652
Validation loss: 2.5768636836800525

Epoch: 6| Step: 10
Training loss: 2.0388424396514893
Validation loss: 2.5741961412532355

Epoch: 6| Step: 11
Training loss: 2.591179370880127
Validation loss: 2.572911770113053

Epoch: 6| Step: 12
Training loss: 3.4254376888275146
Validation loss: 2.5689188716232136

Epoch: 6| Step: 13
Training loss: 2.7519009113311768
Validation loss: 2.569564219444029

Epoch: 100| Step: 0
Training loss: 2.7011489868164062
Validation loss: 2.5707312271159184

Epoch: 6| Step: 1
Training loss: 3.215562105178833
Validation loss: 2.5695258596892

Epoch: 6| Step: 2
Training loss: 2.8667335510253906
Validation loss: 2.5702451582877868

Epoch: 6| Step: 3
Training loss: 2.1544301509857178
Validation loss: 2.5712861604588007

Epoch: 6| Step: 4
Training loss: 2.525733709335327
Validation loss: 2.5700652804425967

Epoch: 6| Step: 5
Training loss: 2.9621589183807373
Validation loss: 2.5710873219274704

Epoch: 6| Step: 6
Training loss: 2.366140127182007
Validation loss: 2.565981709828941

Epoch: 6| Step: 7
Training loss: 2.1282355785369873
Validation loss: 2.5683263578722553

Epoch: 6| Step: 8
Training loss: 2.7379143238067627
Validation loss: 2.5660383162959928

Epoch: 6| Step: 9
Training loss: 2.43837833404541
Validation loss: 2.5686907229884977

Epoch: 6| Step: 10
Training loss: 2.369349718093872
Validation loss: 2.56747265015879

Epoch: 6| Step: 11
Training loss: 4.016162872314453
Validation loss: 2.5680221178198375

Epoch: 6| Step: 12
Training loss: 3.0544724464416504
Validation loss: 2.5727004645973124

Epoch: 6| Step: 13
Training loss: 3.1410887241363525
Validation loss: 2.5813117950193343

Epoch: 101| Step: 0
Training loss: 3.0173661708831787
Validation loss: 2.5823702094375447

Epoch: 6| Step: 1
Training loss: 3.7114369869232178
Validation loss: 2.590351258554766

Epoch: 6| Step: 2
Training loss: 3.2021028995513916
Validation loss: 2.6073758217596237

Epoch: 6| Step: 3
Training loss: 2.6365389823913574
Validation loss: 2.6063992336232173

Epoch: 6| Step: 4
Training loss: 2.325162410736084
Validation loss: 2.6019540755979476

Epoch: 6| Step: 5
Training loss: 3.2087249755859375
Validation loss: 2.590335025582262

Epoch: 6| Step: 6
Training loss: 3.1838271617889404
Validation loss: 2.578892215605705

Epoch: 6| Step: 7
Training loss: 2.7620697021484375
Validation loss: 2.565530523177116

Epoch: 6| Step: 8
Training loss: 2.8175625801086426
Validation loss: 2.5595837921224613

Epoch: 6| Step: 9
Training loss: 2.145148754119873
Validation loss: 2.564002062684746

Epoch: 6| Step: 10
Training loss: 2.3514351844787598
Validation loss: 2.5680181005949616

Epoch: 6| Step: 11
Training loss: 2.2545864582061768
Validation loss: 2.5708321191931285

Epoch: 6| Step: 12
Training loss: 2.3874940872192383
Validation loss: 2.57005795099402

Epoch: 6| Step: 13
Training loss: 2.6793432235717773
Validation loss: 2.5698120286387782

Epoch: 102| Step: 0
Training loss: 1.8220865726470947
Validation loss: 2.569520964417406

Epoch: 6| Step: 1
Training loss: 2.947277545928955
Validation loss: 2.5686197973066762

Epoch: 6| Step: 2
Training loss: 3.022801399230957
Validation loss: 2.5714705836388374

Epoch: 6| Step: 3
Training loss: 3.8013365268707275
Validation loss: 2.5675277222869215

Epoch: 6| Step: 4
Training loss: 2.2395143508911133
Validation loss: 2.5709473497124127

Epoch: 6| Step: 5
Training loss: 2.062249183654785
Validation loss: 2.580232779184977

Epoch: 6| Step: 6
Training loss: 2.8512015342712402
Validation loss: 2.5785452627366587

Epoch: 6| Step: 7
Training loss: 2.812533140182495
Validation loss: 2.5722755514165407

Epoch: 6| Step: 8
Training loss: 3.3523900508880615
Validation loss: 2.5702848075538554

Epoch: 6| Step: 9
Training loss: 3.082829713821411
Validation loss: 2.569339595815187

Epoch: 6| Step: 10
Training loss: 3.2602295875549316
Validation loss: 2.566469530905447

Epoch: 6| Step: 11
Training loss: 2.4161839485168457
Validation loss: 2.570243643176171

Epoch: 6| Step: 12
Training loss: 2.134281635284424
Validation loss: 2.569635460453649

Epoch: 6| Step: 13
Training loss: 2.790170907974243
Validation loss: 2.5646876212089293

Epoch: 103| Step: 0
Training loss: 3.3647923469543457
Validation loss: 2.5673343981465986

Epoch: 6| Step: 1
Training loss: 2.832688331604004
Validation loss: 2.5652347303205922

Epoch: 6| Step: 2
Training loss: 2.428098440170288
Validation loss: 2.5665792957428963

Epoch: 6| Step: 3
Training loss: 3.3893115520477295
Validation loss: 2.5716000090363207

Epoch: 6| Step: 4
Training loss: 2.938462257385254
Validation loss: 2.569675666029735

Epoch: 6| Step: 5
Training loss: 2.0010061264038086
Validation loss: 2.5690979521761657

Epoch: 6| Step: 6
Training loss: 2.696075677871704
Validation loss: 2.564771777840071

Epoch: 6| Step: 7
Training loss: 2.685051202774048
Validation loss: 2.562795159637287

Epoch: 6| Step: 8
Training loss: 3.2285492420196533
Validation loss: 2.560237597393733

Epoch: 6| Step: 9
Training loss: 2.476006507873535
Validation loss: 2.5639063645434637

Epoch: 6| Step: 10
Training loss: 2.8545479774475098
Validation loss: 2.5587128131620345

Epoch: 6| Step: 11
Training loss: 2.4573800563812256
Validation loss: 2.5609576830299954

Epoch: 6| Step: 12
Training loss: 2.4029622077941895
Validation loss: 2.5609858856406262

Epoch: 6| Step: 13
Training loss: 2.643362283706665
Validation loss: 2.568869134431244

Epoch: 104| Step: 0
Training loss: 2.8980069160461426
Validation loss: 2.5665443610119563

Epoch: 6| Step: 1
Training loss: 2.4560203552246094
Validation loss: 2.571457278343939

Epoch: 6| Step: 2
Training loss: 3.1872339248657227
Validation loss: 2.5712794385930544

Epoch: 6| Step: 3
Training loss: 2.34161376953125
Validation loss: 2.5648392579888784

Epoch: 6| Step: 4
Training loss: 2.496615409851074
Validation loss: 2.5585660216628865

Epoch: 6| Step: 5
Training loss: 3.170926809310913
Validation loss: 2.555374112180484

Epoch: 6| Step: 6
Training loss: 4.235830307006836
Validation loss: 2.556591723554878

Epoch: 6| Step: 7
Training loss: 2.1517934799194336
Validation loss: 2.558846168620612

Epoch: 6| Step: 8
Training loss: 1.9799517393112183
Validation loss: 2.5592617014402985

Epoch: 6| Step: 9
Training loss: 3.253727912902832
Validation loss: 2.5585028381757837

Epoch: 6| Step: 10
Training loss: 3.1178267002105713
Validation loss: 2.559720003476707

Epoch: 6| Step: 11
Training loss: 2.4557254314422607
Validation loss: 2.557664926334094

Epoch: 6| Step: 12
Training loss: 2.3992919921875
Validation loss: 2.5569527482473724

Epoch: 6| Step: 13
Training loss: 2.1277153491973877
Validation loss: 2.558838721244566

Epoch: 105| Step: 0
Training loss: 2.651150941848755
Validation loss: 2.555552795369138

Epoch: 6| Step: 1
Training loss: 3.499279499053955
Validation loss: 2.5569502999705653

Epoch: 6| Step: 2
Training loss: 2.664729356765747
Validation loss: 2.5636147170938473

Epoch: 6| Step: 3
Training loss: 2.724452018737793
Validation loss: 2.5704931956465527

Epoch: 6| Step: 4
Training loss: 2.92225980758667
Validation loss: 2.5754810353761077

Epoch: 6| Step: 5
Training loss: 2.5179789066314697
Validation loss: 2.5843174585732083

Epoch: 6| Step: 6
Training loss: 2.0299923419952393
Validation loss: 2.585966638339463

Epoch: 6| Step: 7
Training loss: 2.792423963546753
Validation loss: 2.5850577841522875

Epoch: 6| Step: 8
Training loss: 3.2764711380004883
Validation loss: 2.585253225859775

Epoch: 6| Step: 9
Training loss: 2.5344104766845703
Validation loss: 2.5757921729036557

Epoch: 6| Step: 10
Training loss: 3.0951943397521973
Validation loss: 2.5649322540529313

Epoch: 6| Step: 11
Training loss: 2.7313201427459717
Validation loss: 2.5633593707956295

Epoch: 6| Step: 12
Training loss: 2.33562970161438
Validation loss: 2.5600327522523942

Epoch: 6| Step: 13
Training loss: 2.658088207244873
Validation loss: 2.5557211111950617

Epoch: 106| Step: 0
Training loss: 3.6113858222961426
Validation loss: 2.553860769476942

Epoch: 6| Step: 1
Training loss: 2.795062303543091
Validation loss: 2.553318879937613

Epoch: 6| Step: 2
Training loss: 2.8446664810180664
Validation loss: 2.553108217895672

Epoch: 6| Step: 3
Training loss: 2.1286659240722656
Validation loss: 2.5522999096942205

Epoch: 6| Step: 4
Training loss: 2.56485915184021
Validation loss: 2.552099714996994

Epoch: 6| Step: 5
Training loss: 2.3883233070373535
Validation loss: 2.555093701167773

Epoch: 6| Step: 6
Training loss: 2.996464729309082
Validation loss: 2.559359132602651

Epoch: 6| Step: 7
Training loss: 2.8007659912109375
Validation loss: 2.5598901061601538

Epoch: 6| Step: 8
Training loss: 2.398674488067627
Validation loss: 2.557070732116699

Epoch: 6| Step: 9
Training loss: 2.023155927658081
Validation loss: 2.5579019900291198

Epoch: 6| Step: 10
Training loss: 2.961210250854492
Validation loss: 2.5527733705377065

Epoch: 6| Step: 11
Training loss: 3.6348347663879395
Validation loss: 2.5547433976204164

Epoch: 6| Step: 12
Training loss: 2.713656187057495
Validation loss: 2.556276821321057

Epoch: 6| Step: 13
Training loss: 2.4738500118255615
Validation loss: 2.5550815008019887

Epoch: 107| Step: 0
Training loss: 2.8841850757598877
Validation loss: 2.553644944262761

Epoch: 6| Step: 1
Training loss: 3.388171672821045
Validation loss: 2.553770770308792

Epoch: 6| Step: 2
Training loss: 3.1144890785217285
Validation loss: 2.553349451352191

Epoch: 6| Step: 3
Training loss: 2.657249689102173
Validation loss: 2.55578290518894

Epoch: 6| Step: 4
Training loss: 2.856721878051758
Validation loss: 2.557142837073213

Epoch: 6| Step: 5
Training loss: 2.444866180419922
Validation loss: 2.5534337028380363

Epoch: 6| Step: 6
Training loss: 1.5381137132644653
Validation loss: 2.5605280142958446

Epoch: 6| Step: 7
Training loss: 2.9981789588928223
Validation loss: 2.554931148405998

Epoch: 6| Step: 8
Training loss: 2.6098194122314453
Validation loss: 2.561125442545901

Epoch: 6| Step: 9
Training loss: 3.508061647415161
Validation loss: 2.564395461031186

Epoch: 6| Step: 10
Training loss: 2.325911521911621
Validation loss: 2.5646497793095087

Epoch: 6| Step: 11
Training loss: 2.8107151985168457
Validation loss: 2.5600276224074827

Epoch: 6| Step: 12
Training loss: 2.4272191524505615
Validation loss: 2.5603561760276876

Epoch: 6| Step: 13
Training loss: 2.780488967895508
Validation loss: 2.553800267557944

Epoch: 108| Step: 0
Training loss: 2.536649465560913
Validation loss: 2.5531155627260924

Epoch: 6| Step: 1
Training loss: 3.2137527465820312
Validation loss: 2.5522403947768675

Epoch: 6| Step: 2
Training loss: 2.3168439865112305
Validation loss: 2.554779842335691

Epoch: 6| Step: 3
Training loss: 2.89615535736084
Validation loss: 2.554038498991279

Epoch: 6| Step: 4
Training loss: 1.970332384109497
Validation loss: 2.5604490516006306

Epoch: 6| Step: 5
Training loss: 2.4318642616271973
Validation loss: 2.558803235330889

Epoch: 6| Step: 6
Training loss: 2.8529391288757324
Validation loss: 2.5512161947065786

Epoch: 6| Step: 7
Training loss: 2.8635823726654053
Validation loss: 2.551000605347336

Epoch: 6| Step: 8
Training loss: 2.364260196685791
Validation loss: 2.5515962390489477

Epoch: 6| Step: 9
Training loss: 3.306563138961792
Validation loss: 2.5497590726421726

Epoch: 6| Step: 10
Training loss: 3.044462203979492
Validation loss: 2.5491659179810555

Epoch: 6| Step: 11
Training loss: 3.2142741680145264
Validation loss: 2.547745702087238

Epoch: 6| Step: 12
Training loss: 2.361212730407715
Validation loss: 2.5498181466133363

Epoch: 6| Step: 13
Training loss: 3.237882137298584
Validation loss: 2.5476514626574773

Epoch: 109| Step: 0
Training loss: 2.513089895248413
Validation loss: 2.545187170787524

Epoch: 6| Step: 1
Training loss: 2.361894130706787
Validation loss: 2.5466656582329863

Epoch: 6| Step: 2
Training loss: 2.697016716003418
Validation loss: 2.5453938976410897

Epoch: 6| Step: 3
Training loss: 2.272163152694702
Validation loss: 2.548660368047735

Epoch: 6| Step: 4
Training loss: 2.945805072784424
Validation loss: 2.549314732192665

Epoch: 6| Step: 5
Training loss: 2.52465558052063
Validation loss: 2.552071202185846

Epoch: 6| Step: 6
Training loss: 2.773291826248169
Validation loss: 2.551359625272853

Epoch: 6| Step: 7
Training loss: 2.7867798805236816
Validation loss: 2.556878843615132

Epoch: 6| Step: 8
Training loss: 2.3586037158966064
Validation loss: 2.5592483141089

Epoch: 6| Step: 9
Training loss: 2.5593037605285645
Validation loss: 2.559332657885808

Epoch: 6| Step: 10
Training loss: 3.325183629989624
Validation loss: 2.5604393943663566

Epoch: 6| Step: 11
Training loss: 3.189737558364868
Validation loss: 2.5597808232871433

Epoch: 6| Step: 12
Training loss: 2.8960461616516113
Validation loss: 2.5577971473816903

Epoch: 6| Step: 13
Training loss: 3.384659767150879
Validation loss: 2.5619918684805594

Epoch: 110| Step: 0
Training loss: 2.3052573204040527
Validation loss: 2.56520483057986

Epoch: 6| Step: 1
Training loss: 2.3392608165740967
Validation loss: 2.567831177865305

Epoch: 6| Step: 2
Training loss: 3.0978798866271973
Validation loss: 2.5679944817737868

Epoch: 6| Step: 3
Training loss: 2.055053234100342
Validation loss: 2.56244570209134

Epoch: 6| Step: 4
Training loss: 3.2174901962280273
Validation loss: 2.564511522170036

Epoch: 6| Step: 5
Training loss: 1.9817129373550415
Validation loss: 2.566615007256949

Epoch: 6| Step: 6
Training loss: 3.298959255218506
Validation loss: 2.557590215436874

Epoch: 6| Step: 7
Training loss: 2.7848920822143555
Validation loss: 2.5528490671547512

Epoch: 6| Step: 8
Training loss: 2.638887882232666
Validation loss: 2.5477941420770462

Epoch: 6| Step: 9
Training loss: 2.87650990486145
Validation loss: 2.550173100604806

Epoch: 6| Step: 10
Training loss: 3.1112899780273438
Validation loss: 2.538631082862936

Epoch: 6| Step: 11
Training loss: 2.7995898723602295
Validation loss: 2.5413639109621764

Epoch: 6| Step: 12
Training loss: 2.5410447120666504
Validation loss: 2.5412616601554294

Epoch: 6| Step: 13
Training loss: 3.7630882263183594
Validation loss: 2.540847957775157

Epoch: 111| Step: 0
Training loss: 3.407785415649414
Validation loss: 2.545870593799058

Epoch: 6| Step: 1
Training loss: 2.278435468673706
Validation loss: 2.543650757881903

Epoch: 6| Step: 2
Training loss: 2.0669455528259277
Validation loss: 2.5444658033309446

Epoch: 6| Step: 3
Training loss: 3.9592020511627197
Validation loss: 2.542679053480907

Epoch: 6| Step: 4
Training loss: 2.952275276184082
Validation loss: 2.5439257621765137

Epoch: 6| Step: 5
Training loss: 2.091641426086426
Validation loss: 2.5483226442849762

Epoch: 6| Step: 6
Training loss: 2.5394279956817627
Validation loss: 2.5475641886393228

Epoch: 6| Step: 7
Training loss: 2.072798490524292
Validation loss: 2.550514498064595

Epoch: 6| Step: 8
Training loss: 3.2484283447265625
Validation loss: 2.551167654734786

Epoch: 6| Step: 9
Training loss: 2.0252602100372314
Validation loss: 2.552026056474255

Epoch: 6| Step: 10
Training loss: 3.185495376586914
Validation loss: 2.5547817035387923

Epoch: 6| Step: 11
Training loss: 3.6185555458068848
Validation loss: 2.5606132040741625

Epoch: 6| Step: 12
Training loss: 2.3763198852539062
Validation loss: 2.5615060355073664

Epoch: 6| Step: 13
Training loss: 2.257073402404785
Validation loss: 2.5591559897186937

Epoch: 112| Step: 0
Training loss: 2.697786331176758
Validation loss: 2.571405477421258

Epoch: 6| Step: 1
Training loss: 3.1165642738342285
Validation loss: 2.574208405710036

Epoch: 6| Step: 2
Training loss: 2.9553236961364746
Validation loss: 2.5753457725688977

Epoch: 6| Step: 3
Training loss: 3.675678014755249
Validation loss: 2.575326896482898

Epoch: 6| Step: 4
Training loss: 2.5305986404418945
Validation loss: 2.5693196378728396

Epoch: 6| Step: 5
Training loss: 2.813107967376709
Validation loss: 2.5725260972976685

Epoch: 6| Step: 6
Training loss: 2.299039363861084
Validation loss: 2.560413950233049

Epoch: 6| Step: 7
Training loss: 2.0027904510498047
Validation loss: 2.548317378567111

Epoch: 6| Step: 8
Training loss: 2.969158172607422
Validation loss: 2.538965081655851

Epoch: 6| Step: 9
Training loss: 2.509084463119507
Validation loss: 2.5405294074807117

Epoch: 6| Step: 10
Training loss: 2.831756114959717
Validation loss: 2.542872187911823

Epoch: 6| Step: 11
Training loss: 2.49824857711792
Validation loss: 2.5414063571601786

Epoch: 6| Step: 12
Training loss: 2.589146852493286
Validation loss: 2.549917415906024

Epoch: 6| Step: 13
Training loss: 3.120936393737793
Validation loss: 2.552587186136553

Epoch: 113| Step: 0
Training loss: 2.736626386642456
Validation loss: 2.5517131974620204

Epoch: 6| Step: 1
Training loss: 2.4531173706054688
Validation loss: 2.5469042613942134

Epoch: 6| Step: 2
Training loss: 3.4427924156188965
Validation loss: 2.5418163730252172

Epoch: 6| Step: 3
Training loss: 3.579817056655884
Validation loss: 2.543698667198099

Epoch: 6| Step: 4
Training loss: 2.2715511322021484
Validation loss: 2.5464172312008437

Epoch: 6| Step: 5
Training loss: 2.7312498092651367
Validation loss: 2.545879130722374

Epoch: 6| Step: 6
Training loss: 2.124268054962158
Validation loss: 2.5437165434642504

Epoch: 6| Step: 7
Training loss: 2.9433987140655518
Validation loss: 2.5384117941702566

Epoch: 6| Step: 8
Training loss: 2.499465227127075
Validation loss: 2.535871726210399

Epoch: 6| Step: 9
Training loss: 3.0071048736572266
Validation loss: 2.5430699086958364

Epoch: 6| Step: 10
Training loss: 2.463714122772217
Validation loss: 2.5455445474193943

Epoch: 6| Step: 11
Training loss: 2.261570930480957
Validation loss: 2.543192337918025

Epoch: 6| Step: 12
Training loss: 2.0489871501922607
Validation loss: 2.539181904126239

Epoch: 6| Step: 13
Training loss: 4.529191493988037
Validation loss: 2.5415944078917145

Epoch: 114| Step: 0
Training loss: 3.031977415084839
Validation loss: 2.5412703855063326

Epoch: 6| Step: 1
Training loss: 3.4111881256103516
Validation loss: 2.5415694175227994

Epoch: 6| Step: 2
Training loss: 1.9662740230560303
Validation loss: 2.5363098165040374

Epoch: 6| Step: 3
Training loss: 1.6525030136108398
Validation loss: 2.5354802736672024

Epoch: 6| Step: 4
Training loss: 3.0499658584594727
Validation loss: 2.5361614842568674

Epoch: 6| Step: 5
Training loss: 1.933739185333252
Validation loss: 2.535056790997905

Epoch: 6| Step: 6
Training loss: 3.301562547683716
Validation loss: 2.5346128735491025

Epoch: 6| Step: 7
Training loss: 2.5618391036987305
Validation loss: 2.534357019650039

Epoch: 6| Step: 8
Training loss: 3.7979929447174072
Validation loss: 2.5370318171798543

Epoch: 6| Step: 9
Training loss: 2.7829813957214355
Validation loss: 2.5389341180042555

Epoch: 6| Step: 10
Training loss: 2.6600189208984375
Validation loss: 2.5334121027300434

Epoch: 6| Step: 11
Training loss: 2.1785378456115723
Validation loss: 2.538025076671313

Epoch: 6| Step: 12
Training loss: 3.139214038848877
Validation loss: 2.536831581464378

Epoch: 6| Step: 13
Training loss: 2.7012033462524414
Validation loss: 2.538971557412096

Epoch: 115| Step: 0
Training loss: 2.2926530838012695
Validation loss: 2.536159243634952

Epoch: 6| Step: 1
Training loss: 3.809966802597046
Validation loss: 2.536535768098729

Epoch: 6| Step: 2
Training loss: 2.6282339096069336
Validation loss: 2.538985824072233

Epoch: 6| Step: 3
Training loss: 3.223862648010254
Validation loss: 2.5387702347129903

Epoch: 6| Step: 4
Training loss: 2.542079210281372
Validation loss: 2.5370693386241956

Epoch: 6| Step: 5
Training loss: 3.018254280090332
Validation loss: 2.542759697924378

Epoch: 6| Step: 6
Training loss: 3.2287240028381348
Validation loss: 2.539708588712959

Epoch: 6| Step: 7
Training loss: 2.6044182777404785
Validation loss: 2.5353256656277563

Epoch: 6| Step: 8
Training loss: 2.935458183288574
Validation loss: 2.5335094339104107

Epoch: 6| Step: 9
Training loss: 2.3442180156707764
Validation loss: 2.535583160256827

Epoch: 6| Step: 10
Training loss: 2.348994731903076
Validation loss: 2.535805512500066

Epoch: 6| Step: 11
Training loss: 2.3281772136688232
Validation loss: 2.537402476033857

Epoch: 6| Step: 12
Training loss: 2.4323184490203857
Validation loss: 2.5311357769914853

Epoch: 6| Step: 13
Training loss: 2.0868334770202637
Validation loss: 2.528212190956198

Epoch: 116| Step: 0
Training loss: 2.2731523513793945
Validation loss: 2.527057168304279

Epoch: 6| Step: 1
Training loss: 2.26517391204834
Validation loss: 2.530134995778402

Epoch: 6| Step: 2
Training loss: 3.3420958518981934
Validation loss: 2.5276141781960764

Epoch: 6| Step: 3
Training loss: 2.8240084648132324
Validation loss: 2.531289244210848

Epoch: 6| Step: 4
Training loss: 2.5386362075805664
Validation loss: 2.5288225707187446

Epoch: 6| Step: 5
Training loss: 3.6480588912963867
Validation loss: 2.5330042890323106

Epoch: 6| Step: 6
Training loss: 2.406017780303955
Validation loss: 2.5304108460744223

Epoch: 6| Step: 7
Training loss: 2.8589768409729004
Validation loss: 2.5371874634937575

Epoch: 6| Step: 8
Training loss: 2.509819746017456
Validation loss: 2.53375405393621

Epoch: 6| Step: 9
Training loss: 2.3015060424804688
Validation loss: 2.536681613614482

Epoch: 6| Step: 10
Training loss: 3.0080628395080566
Validation loss: 2.5378785774271977

Epoch: 6| Step: 11
Training loss: 3.303900718688965
Validation loss: 2.5422345310129146

Epoch: 6| Step: 12
Training loss: 2.238523006439209
Validation loss: 2.5391025081757577

Epoch: 6| Step: 13
Training loss: 2.712797164916992
Validation loss: 2.536486933308263

Epoch: 117| Step: 0
Training loss: 2.430803060531616
Validation loss: 2.5332753722385695

Epoch: 6| Step: 1
Training loss: 2.760080337524414
Validation loss: 2.5373541308987524

Epoch: 6| Step: 2
Training loss: 3.241340398788452
Validation loss: 2.534840850419896

Epoch: 6| Step: 3
Training loss: 2.5657527446746826
Validation loss: 2.5283803709091677

Epoch: 6| Step: 4
Training loss: 2.3092312812805176
Validation loss: 2.52697887087381

Epoch: 6| Step: 5
Training loss: 3.7377562522888184
Validation loss: 2.527527609179097

Epoch: 6| Step: 6
Training loss: 2.2654836177825928
Validation loss: 2.5309577988040064

Epoch: 6| Step: 7
Training loss: 2.188744068145752
Validation loss: 2.527849881879745

Epoch: 6| Step: 8
Training loss: 2.99804425239563
Validation loss: 2.5303657516356437

Epoch: 6| Step: 9
Training loss: 3.474416971206665
Validation loss: 2.524526293559741

Epoch: 6| Step: 10
Training loss: 2.692183017730713
Validation loss: 2.526262229488742

Epoch: 6| Step: 11
Training loss: 2.4058499336242676
Validation loss: 2.5281290931086384

Epoch: 6| Step: 12
Training loss: 2.4605417251586914
Validation loss: 2.5349026187773673

Epoch: 6| Step: 13
Training loss: 2.4089927673339844
Validation loss: 2.5295082446067565

Epoch: 118| Step: 0
Training loss: 3.475825309753418
Validation loss: 2.5287752664217384

Epoch: 6| Step: 1
Training loss: 1.995903491973877
Validation loss: 2.534445131978681

Epoch: 6| Step: 2
Training loss: 3.3889002799987793
Validation loss: 2.5367811059439056

Epoch: 6| Step: 3
Training loss: 3.3770875930786133
Validation loss: 2.540900786717733

Epoch: 6| Step: 4
Training loss: 3.4377241134643555
Validation loss: 2.5399301026457097

Epoch: 6| Step: 5
Training loss: 3.049119234085083
Validation loss: 2.5423408374991467

Epoch: 6| Step: 6
Training loss: 2.868165969848633
Validation loss: 2.541093341765865

Epoch: 6| Step: 7
Training loss: 2.0376968383789062
Validation loss: 2.5452426325890327

Epoch: 6| Step: 8
Training loss: 2.7354543209075928
Validation loss: 2.543538228158028

Epoch: 6| Step: 9
Training loss: 2.2563705444335938
Validation loss: 2.5460190414100565

Epoch: 6| Step: 10
Training loss: 2.0411224365234375
Validation loss: 2.5407975335274973

Epoch: 6| Step: 11
Training loss: 1.9619449377059937
Validation loss: 2.5388056411538074

Epoch: 6| Step: 12
Training loss: 2.856454849243164
Validation loss: 2.54367160284391

Epoch: 6| Step: 13
Training loss: 2.587501049041748
Validation loss: 2.5408116002236643

Epoch: 119| Step: 0
Training loss: 2.162580966949463
Validation loss: 2.5322278802112868

Epoch: 6| Step: 1
Training loss: 3.0542197227478027
Validation loss: 2.525233450756278

Epoch: 6| Step: 2
Training loss: 2.5055768489837646
Validation loss: 2.5261160019905335

Epoch: 6| Step: 3
Training loss: 2.8185298442840576
Validation loss: 2.5249157874814925

Epoch: 6| Step: 4
Training loss: 3.2711915969848633
Validation loss: 2.5221969850601687

Epoch: 6| Step: 5
Training loss: 2.7340986728668213
Validation loss: 2.527914308732556

Epoch: 6| Step: 6
Training loss: 3.0581889152526855
Validation loss: 2.5280508815601306

Epoch: 6| Step: 7
Training loss: 2.2905917167663574
Validation loss: 2.5325073734406502

Epoch: 6| Step: 8
Training loss: 3.3558449745178223
Validation loss: 2.5361255086878294

Epoch: 6| Step: 9
Training loss: 1.6145594120025635
Validation loss: 2.5267481803894043

Epoch: 6| Step: 10
Training loss: 2.7149949073791504
Validation loss: 2.530979146239578

Epoch: 6| Step: 11
Training loss: 2.578903913497925
Validation loss: 2.5289660935760825

Epoch: 6| Step: 12
Training loss: 3.5179572105407715
Validation loss: 2.525050042777933

Epoch: 6| Step: 13
Training loss: 2.0788090229034424
Validation loss: 2.523977341190461

Epoch: 120| Step: 0
Training loss: 2.9662928581237793
Validation loss: 2.5189022710246425

Epoch: 6| Step: 1
Training loss: 3.0183050632476807
Validation loss: 2.5223544489952827

Epoch: 6| Step: 2
Training loss: 2.911147117614746
Validation loss: 2.521171849261048

Epoch: 6| Step: 3
Training loss: 2.8362584114074707
Validation loss: 2.526702583477061

Epoch: 6| Step: 4
Training loss: 3.71785306930542
Validation loss: 2.52789500195493

Epoch: 6| Step: 5
Training loss: 3.826216220855713
Validation loss: 2.529226913247057

Epoch: 6| Step: 6
Training loss: 2.6481666564941406
Validation loss: 2.5306645618971957

Epoch: 6| Step: 7
Training loss: 2.791947841644287
Validation loss: 2.52986410356337

Epoch: 6| Step: 8
Training loss: 1.9626407623291016
Validation loss: 2.5300118948823664

Epoch: 6| Step: 9
Training loss: 2.5139517784118652
Validation loss: 2.5306057673628612

Epoch: 6| Step: 10
Training loss: 2.43180251121521
Validation loss: 2.5303366132961806

Epoch: 6| Step: 11
Training loss: 2.311893939971924
Validation loss: 2.528170521541308

Epoch: 6| Step: 12
Training loss: 1.8102948665618896
Validation loss: 2.5271929592214604

Epoch: 6| Step: 13
Training loss: 2.1513986587524414
Validation loss: 2.531613765224334

Epoch: 121| Step: 0
Training loss: 2.2268779277801514
Validation loss: 2.529023785744944

Epoch: 6| Step: 1
Training loss: 3.1587905883789062
Validation loss: 2.5324428619876986

Epoch: 6| Step: 2
Training loss: 3.1266188621520996
Validation loss: 2.532511459883823

Epoch: 6| Step: 3
Training loss: 2.8949522972106934
Validation loss: 2.5363827008073048

Epoch: 6| Step: 4
Training loss: 2.4032084941864014
Validation loss: 2.531216500907816

Epoch: 6| Step: 5
Training loss: 3.279533863067627
Validation loss: 2.529984304981847

Epoch: 6| Step: 6
Training loss: 2.481372356414795
Validation loss: 2.525373471680508

Epoch: 6| Step: 7
Training loss: 2.569713830947876
Validation loss: 2.525151926984069

Epoch: 6| Step: 8
Training loss: 2.245882987976074
Validation loss: 2.5234508232403825

Epoch: 6| Step: 9
Training loss: 2.471628427505493
Validation loss: 2.5245933891624532

Epoch: 6| Step: 10
Training loss: 2.824124336242676
Validation loss: 2.524637714509041

Epoch: 6| Step: 11
Training loss: 2.5222370624542236
Validation loss: 2.5266923058417534

Epoch: 6| Step: 12
Training loss: 3.113372802734375
Validation loss: 2.53231620019482

Epoch: 6| Step: 13
Training loss: 2.810967445373535
Validation loss: 2.53962690343139

Epoch: 122| Step: 0
Training loss: 3.2419726848602295
Validation loss: 2.5342695200315086

Epoch: 6| Step: 1
Training loss: 2.8724560737609863
Validation loss: 2.5402320866943686

Epoch: 6| Step: 2
Training loss: 2.119938850402832
Validation loss: 2.540528905007147

Epoch: 6| Step: 3
Training loss: 2.642700433731079
Validation loss: 2.550941821067564

Epoch: 6| Step: 4
Training loss: 3.077465534210205
Validation loss: 2.554040813958773

Epoch: 6| Step: 5
Training loss: 2.825127601623535
Validation loss: 2.5611849907905824

Epoch: 6| Step: 6
Training loss: 1.4181575775146484
Validation loss: 2.560055927563739

Epoch: 6| Step: 7
Training loss: 2.575718641281128
Validation loss: 2.54824504288294

Epoch: 6| Step: 8
Training loss: 2.7208847999572754
Validation loss: 2.5358171104103007

Epoch: 6| Step: 9
Training loss: 2.5018539428710938
Validation loss: 2.5206353792580227

Epoch: 6| Step: 10
Training loss: 3.020803213119507
Validation loss: 2.5207500585945706

Epoch: 6| Step: 11
Training loss: 3.192063570022583
Validation loss: 2.51752987728324

Epoch: 6| Step: 12
Training loss: 2.899986982345581
Validation loss: 2.5172772945896273

Epoch: 6| Step: 13
Training loss: 3.281865358352661
Validation loss: 2.52649510804043

Epoch: 123| Step: 0
Training loss: 2.5684452056884766
Validation loss: 2.5287440797334075

Epoch: 6| Step: 1
Training loss: 3.015549898147583
Validation loss: 2.526695683438291

Epoch: 6| Step: 2
Training loss: 3.1538524627685547
Validation loss: 2.5256598559758996

Epoch: 6| Step: 3
Training loss: 2.537372589111328
Validation loss: 2.522340223353396

Epoch: 6| Step: 4
Training loss: 2.63277006149292
Validation loss: 2.522690575609925

Epoch: 6| Step: 5
Training loss: 2.356328010559082
Validation loss: 2.520470275673815

Epoch: 6| Step: 6
Training loss: 2.5977232456207275
Validation loss: 2.5194159015532462

Epoch: 6| Step: 7
Training loss: 2.162860870361328
Validation loss: 2.5147909836102555

Epoch: 6| Step: 8
Training loss: 3.275071859359741
Validation loss: 2.5145024150930424

Epoch: 6| Step: 9
Training loss: 3.0645687580108643
Validation loss: 2.513765240228304

Epoch: 6| Step: 10
Training loss: 2.121957302093506
Validation loss: 2.511681459283316

Epoch: 6| Step: 11
Training loss: 2.8549726009368896
Validation loss: 2.5158908059520106

Epoch: 6| Step: 12
Training loss: 2.382671356201172
Validation loss: 2.514562245338194

Epoch: 6| Step: 13
Training loss: 3.848036766052246
Validation loss: 2.5182556260016655

Epoch: 124| Step: 0
Training loss: 2.5419061183929443
Validation loss: 2.5146590868631997

Epoch: 6| Step: 1
Training loss: 2.5488779544830322
Validation loss: 2.5187618860634426

Epoch: 6| Step: 2
Training loss: 2.3764801025390625
Validation loss: 2.517165817240233

Epoch: 6| Step: 3
Training loss: 2.45609974861145
Validation loss: 2.5228217289011967

Epoch: 6| Step: 4
Training loss: 2.176668882369995
Validation loss: 2.5221099802242812

Epoch: 6| Step: 5
Training loss: 2.821657419204712
Validation loss: 2.528271254672799

Epoch: 6| Step: 6
Training loss: 2.824199914932251
Validation loss: 2.5340926467731433

Epoch: 6| Step: 7
Training loss: 2.755289316177368
Validation loss: 2.5327463355115665

Epoch: 6| Step: 8
Training loss: 2.8739547729492188
Validation loss: 2.5315220663624425

Epoch: 6| Step: 9
Training loss: 2.866997480392456
Validation loss: 2.527686098570465

Epoch: 6| Step: 10
Training loss: 3.0049030780792236
Validation loss: 2.5238687658822663

Epoch: 6| Step: 11
Training loss: 2.70068359375
Validation loss: 2.51728759273406

Epoch: 6| Step: 12
Training loss: 2.5805370807647705
Validation loss: 2.5148495012714016

Epoch: 6| Step: 13
Training loss: 3.987122058868408
Validation loss: 2.513430546688777

Epoch: 125| Step: 0
Training loss: 2.6587488651275635
Validation loss: 2.511604014263358

Epoch: 6| Step: 1
Training loss: 1.9729551076889038
Validation loss: 2.5103865515801216

Epoch: 6| Step: 2
Training loss: 2.6585874557495117
Validation loss: 2.511795441309611

Epoch: 6| Step: 3
Training loss: 3.1132760047912598
Validation loss: 2.510561386744181

Epoch: 6| Step: 4
Training loss: 2.902054786682129
Validation loss: 2.5116971462003645

Epoch: 6| Step: 5
Training loss: 2.503161907196045
Validation loss: 2.5123669998620146

Epoch: 6| Step: 6
Training loss: 2.5290818214416504
Validation loss: 2.5114062011882825

Epoch: 6| Step: 7
Training loss: 2.792914628982544
Validation loss: 2.5116596452651487

Epoch: 6| Step: 8
Training loss: 2.542067050933838
Validation loss: 2.5115234185290594

Epoch: 6| Step: 9
Training loss: 2.8119964599609375
Validation loss: 2.5115908756051013

Epoch: 6| Step: 10
Training loss: 2.9193856716156006
Validation loss: 2.513163830644341

Epoch: 6| Step: 11
Training loss: 3.2209391593933105
Validation loss: 2.5137579030888055

Epoch: 6| Step: 12
Training loss: 2.9988932609558105
Validation loss: 2.518694962224653

Epoch: 6| Step: 13
Training loss: 1.9745831489562988
Validation loss: 2.5286011567679783

Epoch: 126| Step: 0
Training loss: 3.0009765625
Validation loss: 2.535822904238137

Epoch: 6| Step: 1
Training loss: 3.1485137939453125
Validation loss: 2.539809721772389

Epoch: 6| Step: 2
Training loss: 2.973583221435547
Validation loss: 2.541766874251827

Epoch: 6| Step: 3
Training loss: 2.8607380390167236
Validation loss: 2.5443156560262046

Epoch: 6| Step: 4
Training loss: 2.0617194175720215
Validation loss: 2.5520706843304377

Epoch: 6| Step: 5
Training loss: 2.235605239868164
Validation loss: 2.5489286556038806

Epoch: 6| Step: 6
Training loss: 2.4352715015411377
Validation loss: 2.5533267656962075

Epoch: 6| Step: 7
Training loss: 2.9004530906677246
Validation loss: 2.545478475991116

Epoch: 6| Step: 8
Training loss: 2.8228325843811035
Validation loss: 2.5377069903958227

Epoch: 6| Step: 9
Training loss: 2.8178439140319824
Validation loss: 2.5255369422256306

Epoch: 6| Step: 10
Training loss: 2.871171474456787
Validation loss: 2.52186680352816

Epoch: 6| Step: 11
Training loss: 2.895345687866211
Validation loss: 2.5182337120015132

Epoch: 6| Step: 12
Training loss: 2.6198391914367676
Validation loss: 2.5147826722873154

Epoch: 6| Step: 13
Training loss: 2.2806029319763184
Validation loss: 2.5176229528201524

Epoch: 127| Step: 0
Training loss: 2.7380013465881348
Validation loss: 2.517140967871553

Epoch: 6| Step: 1
Training loss: 2.8243653774261475
Validation loss: 2.5164812046994447

Epoch: 6| Step: 2
Training loss: 2.57497501373291
Validation loss: 2.5144394136244252

Epoch: 6| Step: 3
Training loss: 3.0700864791870117
Validation loss: 2.5139627610483477

Epoch: 6| Step: 4
Training loss: 2.3084988594055176
Validation loss: 2.5119066699858634

Epoch: 6| Step: 5
Training loss: 2.9435977935791016
Validation loss: 2.514514374476607

Epoch: 6| Step: 6
Training loss: 2.2830166816711426
Validation loss: 2.514087038655435

Epoch: 6| Step: 7
Training loss: 1.772680640220642
Validation loss: 2.5118839817662395

Epoch: 6| Step: 8
Training loss: 2.965832233428955
Validation loss: 2.509126196625412

Epoch: 6| Step: 9
Training loss: 3.1177732944488525
Validation loss: 2.5105962061112925

Epoch: 6| Step: 10
Training loss: 3.401686668395996
Validation loss: 2.517537901478429

Epoch: 6| Step: 11
Training loss: 2.4881339073181152
Validation loss: 2.5189484114288003

Epoch: 6| Step: 12
Training loss: 2.7717480659484863
Validation loss: 2.519467000038393

Epoch: 6| Step: 13
Training loss: 2.6839334964752197
Validation loss: 2.516897552756853

Epoch: 128| Step: 0
Training loss: 2.1022801399230957
Validation loss: 2.5287657783877466

Epoch: 6| Step: 1
Training loss: 2.7960314750671387
Validation loss: 2.524624688650972

Epoch: 6| Step: 2
Training loss: 3.0941858291625977
Validation loss: 2.5226275254321355

Epoch: 6| Step: 3
Training loss: 2.3020248413085938
Validation loss: 2.522028530797651

Epoch: 6| Step: 4
Training loss: 3.145125389099121
Validation loss: 2.5201618235598326

Epoch: 6| Step: 5
Training loss: 2.945544958114624
Validation loss: 2.523152166797269

Epoch: 6| Step: 6
Training loss: 2.3839564323425293
Validation loss: 2.5201239355148806

Epoch: 6| Step: 7
Training loss: 2.086127519607544
Validation loss: 2.517290246102118

Epoch: 6| Step: 8
Training loss: 2.655888557434082
Validation loss: 2.517059405644735

Epoch: 6| Step: 9
Training loss: 3.0124144554138184
Validation loss: 2.5174601718943608

Epoch: 6| Step: 10
Training loss: 2.34419584274292
Validation loss: 2.508450911891076

Epoch: 6| Step: 11
Training loss: 2.167323112487793
Validation loss: 2.5111559078257573

Epoch: 6| Step: 12
Training loss: 3.9086453914642334
Validation loss: 2.506417623130224

Epoch: 6| Step: 13
Training loss: 3.1572654247283936
Validation loss: 2.5052904082882788

Epoch: 129| Step: 0
Training loss: 2.606370210647583
Validation loss: 2.5043474525533695

Epoch: 6| Step: 1
Training loss: 2.2396621704101562
Validation loss: 2.502134515393165

Epoch: 6| Step: 2
Training loss: 2.50069260597229
Validation loss: 2.501922158784764

Epoch: 6| Step: 3
Training loss: 2.4315004348754883
Validation loss: 2.5010930850941646

Epoch: 6| Step: 4
Training loss: 2.5907864570617676
Validation loss: 2.5020719215434086

Epoch: 6| Step: 5
Training loss: 2.6680638790130615
Validation loss: 2.501720948885846

Epoch: 6| Step: 6
Training loss: 2.620433807373047
Validation loss: 2.5059734313718733

Epoch: 6| Step: 7
Training loss: 2.893172264099121
Validation loss: 2.503940572020828

Epoch: 6| Step: 8
Training loss: 2.8720481395721436
Validation loss: 2.5005056678607898

Epoch: 6| Step: 9
Training loss: 3.2292914390563965
Validation loss: 2.501081846093619

Epoch: 6| Step: 10
Training loss: 3.0528876781463623
Validation loss: 2.501216839718562

Epoch: 6| Step: 11
Training loss: 3.1981701850891113
Validation loss: 2.502235730489095

Epoch: 6| Step: 12
Training loss: 2.8138654232025146
Validation loss: 2.5023577649106263

Epoch: 6| Step: 13
Training loss: 1.6427193880081177
Validation loss: 2.5023578418198453

Epoch: 130| Step: 0
Training loss: 2.257188558578491
Validation loss: 2.5040332143024733

Epoch: 6| Step: 1
Training loss: 2.3335046768188477
Validation loss: 2.4976504669394544

Epoch: 6| Step: 2
Training loss: 2.6830317974090576
Validation loss: 2.503339816165227

Epoch: 6| Step: 3
Training loss: 2.7153148651123047
Validation loss: 2.5068662346050306

Epoch: 6| Step: 4
Training loss: 3.5109167098999023
Validation loss: 2.504290780713481

Epoch: 6| Step: 5
Training loss: 2.8851897716522217
Validation loss: 2.5044969743297947

Epoch: 6| Step: 6
Training loss: 2.4275808334350586
Validation loss: 2.5055183185044156

Epoch: 6| Step: 7
Training loss: 2.7238993644714355
Validation loss: 2.507178391179731

Epoch: 6| Step: 8
Training loss: 3.3850884437561035
Validation loss: 2.5098164107209895

Epoch: 6| Step: 9
Training loss: 2.7111334800720215
Validation loss: 2.517652565433133

Epoch: 6| Step: 10
Training loss: 2.720167636871338
Validation loss: 2.5147579895552767

Epoch: 6| Step: 11
Training loss: 2.571589231491089
Validation loss: 2.5129591290668776

Epoch: 6| Step: 12
Training loss: 2.217529535293579
Validation loss: 2.5084788696740263

Epoch: 6| Step: 13
Training loss: 2.7175323963165283
Validation loss: 2.505292031072801

Epoch: 131| Step: 0
Training loss: 3.4690465927124023
Validation loss: 2.4995651988572973

Epoch: 6| Step: 1
Training loss: 2.401851177215576
Validation loss: 2.501251910322456

Epoch: 6| Step: 2
Training loss: 2.6120047569274902
Validation loss: 2.5049539381457913

Epoch: 6| Step: 3
Training loss: 2.454514980316162
Validation loss: 2.504672537567795

Epoch: 6| Step: 4
Training loss: 2.368257522583008
Validation loss: 2.507092132363268

Epoch: 6| Step: 5
Training loss: 2.5118861198425293
Validation loss: 2.5086233180056334

Epoch: 6| Step: 6
Training loss: 3.5122246742248535
Validation loss: 2.5048137916031705

Epoch: 6| Step: 7
Training loss: 2.9922142028808594
Validation loss: 2.5052698453267417

Epoch: 6| Step: 8
Training loss: 2.680258274078369
Validation loss: 2.5059249298546904

Epoch: 6| Step: 9
Training loss: 2.7291595935821533
Validation loss: 2.502990663692515

Epoch: 6| Step: 10
Training loss: 2.668213367462158
Validation loss: 2.5045871273163827

Epoch: 6| Step: 11
Training loss: 2.4954781532287598
Validation loss: 2.5043850406523673

Epoch: 6| Step: 12
Training loss: 1.8396265506744385
Validation loss: 2.511059579028878

Epoch: 6| Step: 13
Training loss: 3.511826753616333
Validation loss: 2.5144259570747294

Epoch: 132| Step: 0
Training loss: 2.423342704772949
Validation loss: 2.5087295783463346

Epoch: 6| Step: 1
Training loss: 3.102816104888916
Validation loss: 2.5181512473731913

Epoch: 6| Step: 2
Training loss: 2.6177282333374023
Validation loss: 2.5159332726591375

Epoch: 6| Step: 3
Training loss: 2.5103697776794434
Validation loss: 2.512364831022037

Epoch: 6| Step: 4
Training loss: 2.4479267597198486
Validation loss: 2.518289481439898

Epoch: 6| Step: 5
Training loss: 3.2505204677581787
Validation loss: 2.51393457125592

Epoch: 6| Step: 6
Training loss: 3.0294747352600098
Validation loss: 2.5151372827509397

Epoch: 6| Step: 7
Training loss: 2.454078197479248
Validation loss: 2.512205430256423

Epoch: 6| Step: 8
Training loss: 1.9879018068313599
Validation loss: 2.5087943153996624

Epoch: 6| Step: 9
Training loss: 2.795464515686035
Validation loss: 2.504403350173786

Epoch: 6| Step: 10
Training loss: 2.4353294372558594
Validation loss: 2.5031501862310592

Epoch: 6| Step: 11
Training loss: 3.1279706954956055
Validation loss: 2.502618723018195

Epoch: 6| Step: 12
Training loss: 2.5370750427246094
Validation loss: 2.5014127992814585

Epoch: 6| Step: 13
Training loss: 3.3947248458862305
Validation loss: 2.5047675819807154

Epoch: 133| Step: 0
Training loss: 2.159278392791748
Validation loss: 2.5039215933892036

Epoch: 6| Step: 1
Training loss: 2.871760606765747
Validation loss: 2.4984123732454036

Epoch: 6| Step: 2
Training loss: 2.9702706336975098
Validation loss: 2.4997945806031585

Epoch: 6| Step: 3
Training loss: 3.484614372253418
Validation loss: 2.5024023261121524

Epoch: 6| Step: 4
Training loss: 2.996709108352661
Validation loss: 2.5018234970749065

Epoch: 6| Step: 5
Training loss: 1.5610514879226685
Validation loss: 2.497638092246107

Epoch: 6| Step: 6
Training loss: 2.1821560859680176
Validation loss: 2.5054898467115176

Epoch: 6| Step: 7
Training loss: 2.80305552482605
Validation loss: 2.5097984883093063

Epoch: 6| Step: 8
Training loss: 2.88082218170166
Validation loss: 2.516407702558784

Epoch: 6| Step: 9
Training loss: 2.2415080070495605
Validation loss: 2.510831353484943

Epoch: 6| Step: 10
Training loss: 2.630251407623291
Validation loss: 2.5218116160362

Epoch: 6| Step: 11
Training loss: 2.9224109649658203
Validation loss: 2.5160364668856383

Epoch: 6| Step: 12
Training loss: 3.5448505878448486
Validation loss: 2.5150443623142857

Epoch: 6| Step: 13
Training loss: 2.3643503189086914
Validation loss: 2.507263734776487

Epoch: 134| Step: 0
Training loss: 2.514404296875
Validation loss: 2.500493875113867

Epoch: 6| Step: 1
Training loss: 2.4403223991394043
Validation loss: 2.5031881152942614

Epoch: 6| Step: 2
Training loss: 2.6842174530029297
Validation loss: 2.4969483370422036

Epoch: 6| Step: 3
Training loss: 2.6518006324768066
Validation loss: 2.506483498439994

Epoch: 6| Step: 4
Training loss: 3.0004770755767822
Validation loss: 2.5113926420929613

Epoch: 6| Step: 5
Training loss: 2.897871494293213
Validation loss: 2.5175290005181425

Epoch: 6| Step: 6
Training loss: 3.470242500305176
Validation loss: 2.510038157945038

Epoch: 6| Step: 7
Training loss: 2.8465278148651123
Validation loss: 2.5070510064401934

Epoch: 6| Step: 8
Training loss: 2.5669779777526855
Validation loss: 2.506886556584348

Epoch: 6| Step: 9
Training loss: 2.6465539932250977
Validation loss: 2.5028000326566797

Epoch: 6| Step: 10
Training loss: 1.9938691854476929
Validation loss: 2.500368554105041

Epoch: 6| Step: 11
Training loss: 2.566465377807617
Validation loss: 2.5001362472452144

Epoch: 6| Step: 12
Training loss: 2.9296677112579346
Validation loss: 2.499167611522059

Epoch: 6| Step: 13
Training loss: 2.7039237022399902
Validation loss: 2.4999358448930966

Epoch: 135| Step: 0
Training loss: 2.283132314682007
Validation loss: 2.501284727486231

Epoch: 6| Step: 1
Training loss: 2.357865333557129
Validation loss: 2.504572340237197

Epoch: 6| Step: 2
Training loss: 2.6579620838165283
Validation loss: 2.506469429180186

Epoch: 6| Step: 3
Training loss: 2.9210362434387207
Validation loss: 2.50831711933177

Epoch: 6| Step: 4
Training loss: 2.476283311843872
Validation loss: 2.513566832388601

Epoch: 6| Step: 5
Training loss: 2.787415027618408
Validation loss: 2.5188688334598335

Epoch: 6| Step: 6
Training loss: 3.021315097808838
Validation loss: 2.5238341413518435

Epoch: 6| Step: 7
Training loss: 2.6444191932678223
Validation loss: 2.5165737623809488

Epoch: 6| Step: 8
Training loss: 3.067589282989502
Validation loss: 2.515349021521948

Epoch: 6| Step: 9
Training loss: 2.260676622390747
Validation loss: 2.5078597735333186

Epoch: 6| Step: 10
Training loss: 3.276843309402466
Validation loss: 2.5063862851870957

Epoch: 6| Step: 11
Training loss: 3.0659360885620117
Validation loss: 2.511169525884813

Epoch: 6| Step: 12
Training loss: 2.587214231491089
Validation loss: 2.505951771172144

Epoch: 6| Step: 13
Training loss: 2.0593128204345703
Validation loss: 2.501142527467461

Epoch: 136| Step: 0
Training loss: 2.764673948287964
Validation loss: 2.502248812747258

Epoch: 6| Step: 1
Training loss: 2.58302640914917
Validation loss: 2.500663459941905

Epoch: 6| Step: 2
Training loss: 2.724606990814209
Validation loss: 2.5042600170258553

Epoch: 6| Step: 3
Training loss: 2.9409103393554688
Validation loss: 2.4986774690689577

Epoch: 6| Step: 4
Training loss: 2.968499183654785
Validation loss: 2.4996638246761855

Epoch: 6| Step: 5
Training loss: 3.065448045730591
Validation loss: 2.5041104311584146

Epoch: 6| Step: 6
Training loss: 1.9151166677474976
Validation loss: 2.5071118890598254

Epoch: 6| Step: 7
Training loss: 1.9726943969726562
Validation loss: 2.514906060311102

Epoch: 6| Step: 8
Training loss: 2.831660032272339
Validation loss: 2.5120475715206516

Epoch: 6| Step: 9
Training loss: 3.580953598022461
Validation loss: 2.515795769230012

Epoch: 6| Step: 10
Training loss: 2.6954360008239746
Validation loss: 2.509739286156111

Epoch: 6| Step: 11
Training loss: 2.580087661743164
Validation loss: 2.5044320296215754

Epoch: 6| Step: 12
Training loss: 2.334453582763672
Validation loss: 2.4982097277077298

Epoch: 6| Step: 13
Training loss: 2.8658816814422607
Validation loss: 2.500169943737727

Epoch: 137| Step: 0
Training loss: 2.9735684394836426
Validation loss: 2.50208733799637

Epoch: 6| Step: 1
Training loss: 1.8682209253311157
Validation loss: 2.4977240857257637

Epoch: 6| Step: 2
Training loss: 2.687619686126709
Validation loss: 2.4987392938265236

Epoch: 6| Step: 3
Training loss: 3.0413784980773926
Validation loss: 2.505427224661714

Epoch: 6| Step: 4
Training loss: 2.4891891479492188
Validation loss: 2.508567105057419

Epoch: 6| Step: 5
Training loss: 2.201160430908203
Validation loss: 2.5153114949503252

Epoch: 6| Step: 6
Training loss: 2.569269895553589
Validation loss: 2.519502939716462

Epoch: 6| Step: 7
Training loss: 3.046658992767334
Validation loss: 2.5129026764182636

Epoch: 6| Step: 8
Training loss: 2.4596428871154785
Validation loss: 2.51420622487222

Epoch: 6| Step: 9
Training loss: 2.688776731491089
Validation loss: 2.5085388845013035

Epoch: 6| Step: 10
Training loss: 2.4789440631866455
Validation loss: 2.5052908261617026

Epoch: 6| Step: 11
Training loss: 3.6042098999023438
Validation loss: 2.504065611029184

Epoch: 6| Step: 12
Training loss: 3.11411714553833
Validation loss: 2.5046315064994236

Epoch: 6| Step: 13
Training loss: 2.332982063293457
Validation loss: 2.4995260905194026

Epoch: 138| Step: 0
Training loss: 2.4148478507995605
Validation loss: 2.5031537778915895

Epoch: 6| Step: 1
Training loss: 1.7581260204315186
Validation loss: 2.496128264293876

Epoch: 6| Step: 2
Training loss: 2.2248847484588623
Validation loss: 2.4968105413580455

Epoch: 6| Step: 3
Training loss: 2.949934959411621
Validation loss: 2.4988640123798

Epoch: 6| Step: 4
Training loss: 2.488406181335449
Validation loss: 2.5053659818505727

Epoch: 6| Step: 5
Training loss: 2.8695907592773438
Validation loss: 2.5038876430962675

Epoch: 6| Step: 6
Training loss: 2.600538730621338
Validation loss: 2.5046736501878306

Epoch: 6| Step: 7
Training loss: 3.2552404403686523
Validation loss: 2.4966319017512824

Epoch: 6| Step: 8
Training loss: 2.465287208557129
Validation loss: 2.503619647795154

Epoch: 6| Step: 9
Training loss: 3.480436325073242
Validation loss: 2.5087987710070867

Epoch: 6| Step: 10
Training loss: 2.2491061687469482
Validation loss: 2.5039537055518037

Epoch: 6| Step: 11
Training loss: 2.573681354522705
Validation loss: 2.502906278897357

Epoch: 6| Step: 12
Training loss: 3.27291202545166
Validation loss: 2.4968076623896116

Epoch: 6| Step: 13
Training loss: 3.4350087642669678
Validation loss: 2.491764137821813

Epoch: 139| Step: 0
Training loss: 3.4555277824401855
Validation loss: 2.490982623510463

Epoch: 6| Step: 1
Training loss: 2.401622772216797
Validation loss: 2.4855412334524174

Epoch: 6| Step: 2
Training loss: 2.4838333129882812
Validation loss: 2.489426282144362

Epoch: 6| Step: 3
Training loss: 2.213923931121826
Validation loss: 2.4903780542394167

Epoch: 6| Step: 4
Training loss: 2.154885768890381
Validation loss: 2.491013978117256

Epoch: 6| Step: 5
Training loss: 2.9098877906799316
Validation loss: 2.4882169051836898

Epoch: 6| Step: 6
Training loss: 2.476339340209961
Validation loss: 2.490788577705301

Epoch: 6| Step: 7
Training loss: 2.493372917175293
Validation loss: 2.4856643369120937

Epoch: 6| Step: 8
Training loss: 2.802996873855591
Validation loss: 2.4910833104964225

Epoch: 6| Step: 9
Training loss: 2.9448904991149902
Validation loss: 2.484915553882558

Epoch: 6| Step: 10
Training loss: 2.4984490871429443
Validation loss: 2.4927085804682907

Epoch: 6| Step: 11
Training loss: 3.2754504680633545
Validation loss: 2.4980641385560394

Epoch: 6| Step: 12
Training loss: 2.9562387466430664
Validation loss: 2.5054399377556256

Epoch: 6| Step: 13
Training loss: 2.5984511375427246
Validation loss: 2.4993721592810845

Epoch: 140| Step: 0
Training loss: 2.895697593688965
Validation loss: 2.504857929803992

Epoch: 6| Step: 1
Training loss: 2.3920044898986816
Validation loss: 2.5107046045282835

Epoch: 6| Step: 2
Training loss: 3.506406545639038
Validation loss: 2.5113917525096605

Epoch: 6| Step: 3
Training loss: 3.011669158935547
Validation loss: 2.5156709148037817

Epoch: 6| Step: 4
Training loss: 3.025582790374756
Validation loss: 2.5148471170856106

Epoch: 6| Step: 5
Training loss: 2.589927911758423
Validation loss: 2.504672873404718

Epoch: 6| Step: 6
Training loss: 2.224503993988037
Validation loss: 2.497038354155838

Epoch: 6| Step: 7
Training loss: 2.237351894378662
Validation loss: 2.4977458856439076

Epoch: 6| Step: 8
Training loss: 3.176299571990967
Validation loss: 2.491519715196343

Epoch: 6| Step: 9
Training loss: 2.5583319664001465
Validation loss: 2.4942428822158487

Epoch: 6| Step: 10
Training loss: 2.590116024017334
Validation loss: 2.490161108714278

Epoch: 6| Step: 11
Training loss: 2.9688539505004883
Validation loss: 2.493686786261938

Epoch: 6| Step: 12
Training loss: 2.699993133544922
Validation loss: 2.4905803177946355

Epoch: 6| Step: 13
Training loss: 1.0547369718551636
Validation loss: 2.4900490981276318

Epoch: 141| Step: 0
Training loss: 2.15995192527771
Validation loss: 2.491476115360055

Epoch: 6| Step: 1
Training loss: 2.20528507232666
Validation loss: 2.4925027098706973

Epoch: 6| Step: 2
Training loss: 2.082563638687134
Validation loss: 2.4935730964906755

Epoch: 6| Step: 3
Training loss: 2.4596598148345947
Validation loss: 2.488831158607237

Epoch: 6| Step: 4
Training loss: 3.0464601516723633
Validation loss: 2.4939583193871284

Epoch: 6| Step: 5
Training loss: 3.134089469909668
Validation loss: 2.4901912186735418

Epoch: 6| Step: 6
Training loss: 2.7043824195861816
Validation loss: 2.491638127193656

Epoch: 6| Step: 7
Training loss: 2.7551727294921875
Validation loss: 2.495276710038544

Epoch: 6| Step: 8
Training loss: 2.252260208129883
Validation loss: 2.4897507954669256

Epoch: 6| Step: 9
Training loss: 3.22925066947937
Validation loss: 2.49651893877214

Epoch: 6| Step: 10
Training loss: 3.2922627925872803
Validation loss: 2.4962744815375215

Epoch: 6| Step: 11
Training loss: 2.542297840118408
Validation loss: 2.4967570868871545

Epoch: 6| Step: 12
Training loss: 3.2822160720825195
Validation loss: 2.507716481403638

Epoch: 6| Step: 13
Training loss: 2.203219413757324
Validation loss: 2.5001515855071363

Epoch: 142| Step: 0
Training loss: 2.169529914855957
Validation loss: 2.5026578877561834

Epoch: 6| Step: 1
Training loss: 3.105677843093872
Validation loss: 2.50867175286816

Epoch: 6| Step: 2
Training loss: 1.7202131748199463
Validation loss: 2.4997818982729347

Epoch: 6| Step: 3
Training loss: 2.72012996673584
Validation loss: 2.497400919596354

Epoch: 6| Step: 4
Training loss: 2.4108681678771973
Validation loss: 2.4963839028471257

Epoch: 6| Step: 5
Training loss: 2.724968671798706
Validation loss: 2.493334577929589

Epoch: 6| Step: 6
Training loss: 2.7389333248138428
Validation loss: 2.4920778684718634

Epoch: 6| Step: 7
Training loss: 2.6853623390197754
Validation loss: 2.4970774060936383

Epoch: 6| Step: 8
Training loss: 3.158477306365967
Validation loss: 2.500099789711737

Epoch: 6| Step: 9
Training loss: 3.306906223297119
Validation loss: 2.498817031101514

Epoch: 6| Step: 10
Training loss: 2.8939433097839355
Validation loss: 2.492331909876998

Epoch: 6| Step: 11
Training loss: 3.0784220695495605
Validation loss: 2.4988988522560365

Epoch: 6| Step: 12
Training loss: 2.112325429916382
Validation loss: 2.4952777431857203

Epoch: 6| Step: 13
Training loss: 2.8476920127868652
Validation loss: 2.491381665711762

Epoch: 143| Step: 0
Training loss: 2.406670570373535
Validation loss: 2.484302928370814

Epoch: 6| Step: 1
Training loss: 2.573382616043091
Validation loss: 2.4820906654480965

Epoch: 6| Step: 2
Training loss: 2.558544158935547
Validation loss: 2.4851886815922235

Epoch: 6| Step: 3
Training loss: 2.5739972591400146
Validation loss: 2.480010537691014

Epoch: 6| Step: 4
Training loss: 2.5089621543884277
Validation loss: 2.4827290619573286

Epoch: 6| Step: 5
Training loss: 3.413209915161133
Validation loss: 2.480885200603034

Epoch: 6| Step: 6
Training loss: 2.8701369762420654
Validation loss: 2.4841391194251274

Epoch: 6| Step: 7
Training loss: 2.32852840423584
Validation loss: 2.481911600276988

Epoch: 6| Step: 8
Training loss: 2.5783395767211914
Validation loss: 2.4847555032340427

Epoch: 6| Step: 9
Training loss: 1.9341410398483276
Validation loss: 2.4830743446145007

Epoch: 6| Step: 10
Training loss: 3.0393009185791016
Validation loss: 2.485533647639777

Epoch: 6| Step: 11
Training loss: 3.095402717590332
Validation loss: 2.4852186787512993

Epoch: 6| Step: 12
Training loss: 2.8275156021118164
Validation loss: 2.4904755674382693

Epoch: 6| Step: 13
Training loss: 3.047471523284912
Validation loss: 2.4898764394944712

Epoch: 144| Step: 0
Training loss: 3.079744815826416
Validation loss: 2.5053770490871963

Epoch: 6| Step: 1
Training loss: 2.167534351348877
Validation loss: 2.5069496349621843

Epoch: 6| Step: 2
Training loss: 2.8012945652008057
Validation loss: 2.4876784919410624

Epoch: 6| Step: 3
Training loss: 2.2343039512634277
Validation loss: 2.482961190644131

Epoch: 6| Step: 4
Training loss: 2.7949419021606445
Validation loss: 2.4868262929301106

Epoch: 6| Step: 5
Training loss: 2.949923515319824
Validation loss: 2.479524830336212

Epoch: 6| Step: 6
Training loss: 2.3180043697357178
Validation loss: 2.4815629784778883

Epoch: 6| Step: 7
Training loss: 2.34407377243042
Validation loss: 2.4881289492371264

Epoch: 6| Step: 8
Training loss: 2.573890209197998
Validation loss: 2.4883452128338557

Epoch: 6| Step: 9
Training loss: 3.02587890625
Validation loss: 2.499232430611887

Epoch: 6| Step: 10
Training loss: 3.457270383834839
Validation loss: 2.4986553653593986

Epoch: 6| Step: 11
Training loss: 2.6491856575012207
Validation loss: 2.5015485209803425

Epoch: 6| Step: 12
Training loss: 2.4130029678344727
Validation loss: 2.4996553082619943

Epoch: 6| Step: 13
Training loss: 2.8135528564453125
Validation loss: 2.4999148794399795

Epoch: 145| Step: 0
Training loss: 2.0548582077026367
Validation loss: 2.494926098854311

Epoch: 6| Step: 1
Training loss: 3.369180202484131
Validation loss: 2.501771339806177

Epoch: 6| Step: 2
Training loss: 3.427978992462158
Validation loss: 2.4966106748068206

Epoch: 6| Step: 3
Training loss: 2.4426350593566895
Validation loss: 2.4967010739029094

Epoch: 6| Step: 4
Training loss: 2.718066930770874
Validation loss: 2.4943962968805784

Epoch: 6| Step: 5
Training loss: 2.7978978157043457
Validation loss: 2.4898182858702955

Epoch: 6| Step: 6
Training loss: 1.7312273979187012
Validation loss: 2.4899438042794504

Epoch: 6| Step: 7
Training loss: 2.840275526046753
Validation loss: 2.4801911256646596

Epoch: 6| Step: 8
Training loss: 2.0585989952087402
Validation loss: 2.48191802219678

Epoch: 6| Step: 9
Training loss: 3.000039577484131
Validation loss: 2.4812796936240247

Epoch: 6| Step: 10
Training loss: 2.3749465942382812
Validation loss: 2.4822533745919504

Epoch: 6| Step: 11
Training loss: 2.8292102813720703
Validation loss: 2.4842347124571442

Epoch: 6| Step: 12
Training loss: 3.123359441757202
Validation loss: 2.4875369533415763

Epoch: 6| Step: 13
Training loss: 2.925852060317993
Validation loss: 2.4863053470529537

Epoch: 146| Step: 0
Training loss: 3.248849868774414
Validation loss: 2.4897678539317143

Epoch: 6| Step: 1
Training loss: 2.615269899368286
Validation loss: 2.488375417647823

Epoch: 6| Step: 2
Training loss: 2.8133840560913086
Validation loss: 2.4974444348325013

Epoch: 6| Step: 3
Training loss: 2.2112369537353516
Validation loss: 2.4999805906767487

Epoch: 6| Step: 4
Training loss: 2.6395907402038574
Validation loss: 2.50425209024901

Epoch: 6| Step: 5
Training loss: 3.1220297813415527
Validation loss: 2.502833607376263

Epoch: 6| Step: 6
Training loss: 1.7613334655761719
Validation loss: 2.498029634516726

Epoch: 6| Step: 7
Training loss: 2.325782060623169
Validation loss: 2.493041989623859

Epoch: 6| Step: 8
Training loss: 2.2989296913146973
Validation loss: 2.489912474027244

Epoch: 6| Step: 9
Training loss: 3.053399085998535
Validation loss: 2.4897009993112214

Epoch: 6| Step: 10
Training loss: 2.799191474914551
Validation loss: 2.489590770454817

Epoch: 6| Step: 11
Training loss: 2.18780255317688
Validation loss: 2.4844952501276487

Epoch: 6| Step: 12
Training loss: 3.195455551147461
Validation loss: 2.4798349436893257

Epoch: 6| Step: 13
Training loss: 3.6344587802886963
Validation loss: 2.484852324249924

Epoch: 147| Step: 0
Training loss: 2.8126986026763916
Validation loss: 2.4791279505657893

Epoch: 6| Step: 1
Training loss: 3.5048258304595947
Validation loss: 2.48003448465819

Epoch: 6| Step: 2
Training loss: 2.1710891723632812
Validation loss: 2.4768850367556334

Epoch: 6| Step: 3
Training loss: 2.265331745147705
Validation loss: 2.4842046281342864

Epoch: 6| Step: 4
Training loss: 2.9387264251708984
Validation loss: 2.4828223746309996

Epoch: 6| Step: 5
Training loss: 2.4492814540863037
Validation loss: 2.487015252472252

Epoch: 6| Step: 6
Training loss: 3.2978434562683105
Validation loss: 2.490432513657437

Epoch: 6| Step: 7
Training loss: 2.244764804840088
Validation loss: 2.494152371601392

Epoch: 6| Step: 8
Training loss: 2.4485812187194824
Validation loss: 2.4971194651819046

Epoch: 6| Step: 9
Training loss: 2.397052764892578
Validation loss: 2.48882540323401

Epoch: 6| Step: 10
Training loss: 3.1302051544189453
Validation loss: 2.4799519379933677

Epoch: 6| Step: 11
Training loss: 2.15950345993042
Validation loss: 2.4795346875344553

Epoch: 6| Step: 12
Training loss: 2.866480827331543
Validation loss: 2.4842273881358485

Epoch: 6| Step: 13
Training loss: 3.005061626434326
Validation loss: 2.4787521721214376

Epoch: 148| Step: 0
Training loss: 1.991006851196289
Validation loss: 2.4736455819940053

Epoch: 6| Step: 1
Training loss: 2.8994126319885254
Validation loss: 2.477494521807599

Epoch: 6| Step: 2
Training loss: 2.829989433288574
Validation loss: 2.482659711632677

Epoch: 6| Step: 3
Training loss: 1.991598129272461
Validation loss: 2.4801168262317614

Epoch: 6| Step: 4
Training loss: 3.1663894653320312
Validation loss: 2.4831793667167745

Epoch: 6| Step: 5
Training loss: 2.7226505279541016
Validation loss: 2.4824178911024526

Epoch: 6| Step: 6
Training loss: 2.149587392807007
Validation loss: 2.4882655553920294

Epoch: 6| Step: 7
Training loss: 3.3452303409576416
Validation loss: 2.4798822479863323

Epoch: 6| Step: 8
Training loss: 3.1919240951538086
Validation loss: 2.4748105336261053

Epoch: 6| Step: 9
Training loss: 1.8881251811981201
Validation loss: 2.4742552644462994

Epoch: 6| Step: 10
Training loss: 3.1974997520446777
Validation loss: 2.4725664456685386

Epoch: 6| Step: 11
Training loss: 3.0216081142425537
Validation loss: 2.473754388029857

Epoch: 6| Step: 12
Training loss: 2.8958733081817627
Validation loss: 2.4720039470221407

Epoch: 6| Step: 13
Training loss: 1.9937502145767212
Validation loss: 2.4732363967485327

Epoch: 149| Step: 0
Training loss: 3.0501327514648438
Validation loss: 2.469606635391071

Epoch: 6| Step: 1
Training loss: 3.309986114501953
Validation loss: 2.47133707743819

Epoch: 6| Step: 2
Training loss: 2.422886610031128
Validation loss: 2.4753092847844607

Epoch: 6| Step: 3
Training loss: 3.068016529083252
Validation loss: 2.4747917421402468

Epoch: 6| Step: 4
Training loss: 2.8922958374023438
Validation loss: 2.4831433424385647

Epoch: 6| Step: 5
Training loss: 2.9090638160705566
Validation loss: 2.480812777755081

Epoch: 6| Step: 6
Training loss: 2.1149282455444336
Validation loss: 2.48484347456245

Epoch: 6| Step: 7
Training loss: 2.981843948364258
Validation loss: 2.4849947165417414

Epoch: 6| Step: 8
Training loss: 2.891312599182129
Validation loss: 2.4872666879366805

Epoch: 6| Step: 9
Training loss: 1.8218822479248047
Validation loss: 2.480566345235353

Epoch: 6| Step: 10
Training loss: 2.539604425430298
Validation loss: 2.479673675311509

Epoch: 6| Step: 11
Training loss: 3.0637335777282715
Validation loss: 2.475997336449162

Epoch: 6| Step: 12
Training loss: 2.2542080879211426
Validation loss: 2.477588451036843

Epoch: 6| Step: 13
Training loss: 1.8426481485366821
Validation loss: 2.4817613734993884

Epoch: 150| Step: 0
Training loss: 3.4954299926757812
Validation loss: 2.481576786246351

Epoch: 6| Step: 1
Training loss: 2.255190372467041
Validation loss: 2.481056164669734

Epoch: 6| Step: 2
Training loss: 3.111903190612793
Validation loss: 2.481162021237035

Epoch: 6| Step: 3
Training loss: 2.0651566982269287
Validation loss: 2.4886917196294314

Epoch: 6| Step: 4
Training loss: 2.7075424194335938
Validation loss: 2.4902671870364936

Epoch: 6| Step: 5
Training loss: 2.192237615585327
Validation loss: 2.494271683436568

Epoch: 6| Step: 6
Training loss: 2.781816005706787
Validation loss: 2.4993226117985223

Epoch: 6| Step: 7
Training loss: 2.0978991985321045
Validation loss: 2.498839964148819

Epoch: 6| Step: 8
Training loss: 3.356682062149048
Validation loss: 2.5028856415902414

Epoch: 6| Step: 9
Training loss: 2.5598788261413574
Validation loss: 2.500835228991765

Epoch: 6| Step: 10
Training loss: 3.164137840270996
Validation loss: 2.497419165026757

Epoch: 6| Step: 11
Training loss: 2.4887990951538086
Validation loss: 2.4890392749540267

Epoch: 6| Step: 12
Training loss: 2.2423980236053467
Validation loss: 2.4871489745314403

Epoch: 6| Step: 13
Training loss: 3.208828926086426
Validation loss: 2.4787442235536474

Epoch: 151| Step: 0
Training loss: 3.5742406845092773
Validation loss: 2.4756126839627504

Epoch: 6| Step: 1
Training loss: 3.4278059005737305
Validation loss: 2.4711782957917903

Epoch: 6| Step: 2
Training loss: 3.0891106128692627
Validation loss: 2.4710400463432394

Epoch: 6| Step: 3
Training loss: 2.9873015880584717
Validation loss: 2.4689039132928334

Epoch: 6| Step: 4
Training loss: 2.363326072692871
Validation loss: 2.4715370132077124

Epoch: 6| Step: 5
Training loss: 2.951910972595215
Validation loss: 2.4694773458665416

Epoch: 6| Step: 6
Training loss: 2.297670602798462
Validation loss: 2.477121614640759

Epoch: 6| Step: 7
Training loss: 2.3645858764648438
Validation loss: 2.4770334971848356

Epoch: 6| Step: 8
Training loss: 2.134097099304199
Validation loss: 2.473171854531893

Epoch: 6| Step: 9
Training loss: 1.9046921730041504
Validation loss: 2.4771671448984454

Epoch: 6| Step: 10
Training loss: 2.4844679832458496
Validation loss: 2.4753340687803043

Epoch: 6| Step: 11
Training loss: 2.462632179260254
Validation loss: 2.4789327472768803

Epoch: 6| Step: 12
Training loss: 2.762484550476074
Validation loss: 2.483825727175641

Epoch: 6| Step: 13
Training loss: 2.6141090393066406
Validation loss: 2.4871969799841604

Epoch: 152| Step: 0
Training loss: 2.819502592086792
Validation loss: 2.4898878374407367

Epoch: 6| Step: 1
Training loss: 2.3938815593719482
Validation loss: 2.487405600086335

Epoch: 6| Step: 2
Training loss: 2.697005271911621
Validation loss: 2.4896459579467773

Epoch: 6| Step: 3
Training loss: 2.6149444580078125
Validation loss: 2.4903367411705757

Epoch: 6| Step: 4
Training loss: 2.210439682006836
Validation loss: 2.488774730313209

Epoch: 6| Step: 5
Training loss: 3.21846342086792
Validation loss: 2.488986688275491

Epoch: 6| Step: 6
Training loss: 2.3236083984375
Validation loss: 2.483791858919205

Epoch: 6| Step: 7
Training loss: 3.2856669425964355
Validation loss: 2.4940164371203353

Epoch: 6| Step: 8
Training loss: 3.0649938583374023
Validation loss: 2.4958521243064635

Epoch: 6| Step: 9
Training loss: 2.7983405590057373
Validation loss: 2.4937666744314213

Epoch: 6| Step: 10
Training loss: 2.4080262184143066
Validation loss: 2.4868779823344243

Epoch: 6| Step: 11
Training loss: 2.0406482219696045
Validation loss: 2.484596819005987

Epoch: 6| Step: 12
Training loss: 2.3022613525390625
Validation loss: 2.478335257499449

Epoch: 6| Step: 13
Training loss: 3.7594337463378906
Validation loss: 2.475398773788124

Epoch: 153| Step: 0
Training loss: 3.476309299468994
Validation loss: 2.46746160650766

Epoch: 6| Step: 1
Training loss: 2.664949655532837
Validation loss: 2.4641404510826193

Epoch: 6| Step: 2
Training loss: 2.070373773574829
Validation loss: 2.4688398440678916

Epoch: 6| Step: 3
Training loss: 3.118502140045166
Validation loss: 2.465858469727219

Epoch: 6| Step: 4
Training loss: 2.434464693069458
Validation loss: 2.4701591845481627

Epoch: 6| Step: 5
Training loss: 2.9993844032287598
Validation loss: 2.4649168573400027

Epoch: 6| Step: 6
Training loss: 2.934744358062744
Validation loss: 2.473370570008473

Epoch: 6| Step: 7
Training loss: 2.985811233520508
Validation loss: 2.4822979947572112

Epoch: 6| Step: 8
Training loss: 2.839529514312744
Validation loss: 2.4841594824226956

Epoch: 6| Step: 9
Training loss: 2.2831313610076904
Validation loss: 2.4942070643107095

Epoch: 6| Step: 10
Training loss: 2.7339160442352295
Validation loss: 2.5051433937523955

Epoch: 6| Step: 11
Training loss: 2.3193860054016113
Validation loss: 2.5022009829039216

Epoch: 6| Step: 12
Training loss: 2.870309829711914
Validation loss: 2.496486320290514

Epoch: 6| Step: 13
Training loss: 1.193213939666748
Validation loss: 2.4845383808177006

Epoch: 154| Step: 0
Training loss: 2.5394184589385986
Validation loss: 2.480429272497854

Epoch: 6| Step: 1
Training loss: 3.111171007156372
Validation loss: 2.479058737395912

Epoch: 6| Step: 2
Training loss: 1.9903074502944946
Validation loss: 2.4825014452780447

Epoch: 6| Step: 3
Training loss: 2.6738061904907227
Validation loss: 2.481304212283063

Epoch: 6| Step: 4
Training loss: 2.510016441345215
Validation loss: 2.4829619264089935

Epoch: 6| Step: 5
Training loss: 2.5445473194122314
Validation loss: 2.48629964423436

Epoch: 6| Step: 6
Training loss: 2.667234182357788
Validation loss: 2.4926853667023363

Epoch: 6| Step: 7
Training loss: 2.994704246520996
Validation loss: 2.486100455766083

Epoch: 6| Step: 8
Training loss: 2.8980138301849365
Validation loss: 2.4890678313470658

Epoch: 6| Step: 9
Training loss: 2.956477642059326
Validation loss: 2.482765192626625

Epoch: 6| Step: 10
Training loss: 3.08504581451416
Validation loss: 2.4783270064220635

Epoch: 6| Step: 11
Training loss: 2.4126346111297607
Validation loss: 2.4882304155698387

Epoch: 6| Step: 12
Training loss: 1.9721813201904297
Validation loss: 2.4793858271773144

Epoch: 6| Step: 13
Training loss: 3.435168504714966
Validation loss: 2.4771035512288413

Epoch: 155| Step: 0
Training loss: 3.5584189891815186
Validation loss: 2.480986043971072

Epoch: 6| Step: 1
Training loss: 2.7585177421569824
Validation loss: 2.4760655356991674

Epoch: 6| Step: 2
Training loss: 2.0624022483825684
Validation loss: 2.4759996603893977

Epoch: 6| Step: 3
Training loss: 3.3857011795043945
Validation loss: 2.4717629314750753

Epoch: 6| Step: 4
Training loss: 2.6977615356445312
Validation loss: 2.4760985989724436

Epoch: 6| Step: 5
Training loss: 3.2099435329437256
Validation loss: 2.467836638932587

Epoch: 6| Step: 6
Training loss: 2.7218613624572754
Validation loss: 2.473921616872152

Epoch: 6| Step: 7
Training loss: 3.405182361602783
Validation loss: 2.4717332240073913

Epoch: 6| Step: 8
Training loss: 1.8613333702087402
Validation loss: 2.474062914489418

Epoch: 6| Step: 9
Training loss: 2.2725367546081543
Validation loss: 2.4735496633796283

Epoch: 6| Step: 10
Training loss: 2.6646780967712402
Validation loss: 2.472658295785227

Epoch: 6| Step: 11
Training loss: 1.9067884683609009
Validation loss: 2.470813448711108

Epoch: 6| Step: 12
Training loss: 2.5260493755340576
Validation loss: 2.471544042710335

Epoch: 6| Step: 13
Training loss: 2.0083563327789307
Validation loss: 2.469052455758536

Epoch: 156| Step: 0
Training loss: 2.283639907836914
Validation loss: 2.464720759340512

Epoch: 6| Step: 1
Training loss: 2.5048255920410156
Validation loss: 2.470314759080128

Epoch: 6| Step: 2
Training loss: 3.0550737380981445
Validation loss: 2.465251486788514

Epoch: 6| Step: 3
Training loss: 3.4046630859375
Validation loss: 2.4598417410286526

Epoch: 6| Step: 4
Training loss: 2.9623448848724365
Validation loss: 2.46602963888517

Epoch: 6| Step: 5
Training loss: 1.730902910232544
Validation loss: 2.465932351286693

Epoch: 6| Step: 6
Training loss: 3.084730386734009
Validation loss: 2.465998113796275

Epoch: 6| Step: 7
Training loss: 2.62930965423584
Validation loss: 2.4636457171491397

Epoch: 6| Step: 8
Training loss: 3.036207675933838
Validation loss: 2.467137531567645

Epoch: 6| Step: 9
Training loss: 2.8459620475769043
Validation loss: 2.473449258394139

Epoch: 6| Step: 10
Training loss: 2.6292901039123535
Validation loss: 2.4718767904466197

Epoch: 6| Step: 11
Training loss: 2.0457444190979004
Validation loss: 2.4709920216632146

Epoch: 6| Step: 12
Training loss: 2.3091840744018555
Validation loss: 2.466382852164648

Epoch: 6| Step: 13
Training loss: 3.0015695095062256
Validation loss: 2.4700613175669024

Epoch: 157| Step: 0
Training loss: 3.060466766357422
Validation loss: 2.4732982958516767

Epoch: 6| Step: 1
Training loss: 3.4301977157592773
Validation loss: 2.476108069060951

Epoch: 6| Step: 2
Training loss: 2.35676908493042
Validation loss: 2.4764674530234387

Epoch: 6| Step: 3
Training loss: 1.858460783958435
Validation loss: 2.4783737428726687

Epoch: 6| Step: 4
Training loss: 2.932504177093506
Validation loss: 2.488271983720923

Epoch: 6| Step: 5
Training loss: 2.9043352603912354
Validation loss: 2.483481409729168

Epoch: 6| Step: 6
Training loss: 2.8070120811462402
Validation loss: 2.481657943417949

Epoch: 6| Step: 7
Training loss: 1.9097633361816406
Validation loss: 2.4808757228236042

Epoch: 6| Step: 8
Training loss: 3.01098895072937
Validation loss: 2.486051715830321

Epoch: 6| Step: 9
Training loss: 2.3683671951293945
Validation loss: 2.4753934029609925

Epoch: 6| Step: 10
Training loss: 2.8028316497802734
Validation loss: 2.469412813904465

Epoch: 6| Step: 11
Training loss: 2.4361538887023926
Validation loss: 2.475664110593898

Epoch: 6| Step: 12
Training loss: 2.83417010307312
Validation loss: 2.468426286533315

Epoch: 6| Step: 13
Training loss: 2.707991600036621
Validation loss: 2.4703789885326097

Epoch: 158| Step: 0
Training loss: 2.4335131645202637
Validation loss: 2.4663978930442565

Epoch: 6| Step: 1
Training loss: 2.080104351043701
Validation loss: 2.4645474905608804

Epoch: 6| Step: 2
Training loss: 2.252044439315796
Validation loss: 2.467707874954388

Epoch: 6| Step: 3
Training loss: 2.917379379272461
Validation loss: 2.472482673583492

Epoch: 6| Step: 4
Training loss: 1.5316258668899536
Validation loss: 2.467831101468814

Epoch: 6| Step: 5
Training loss: 2.4563679695129395
Validation loss: 2.468594986905334

Epoch: 6| Step: 6
Training loss: 2.548271656036377
Validation loss: 2.46726728511113

Epoch: 6| Step: 7
Training loss: 2.791825771331787
Validation loss: 2.476371278044998

Epoch: 6| Step: 8
Training loss: 3.1654820442199707
Validation loss: 2.4760775284100602

Epoch: 6| Step: 9
Training loss: 3.294224500656128
Validation loss: 2.470478939753707

Epoch: 6| Step: 10
Training loss: 3.529594659805298
Validation loss: 2.469747838153634

Epoch: 6| Step: 11
Training loss: 3.158703565597534
Validation loss: 2.47051880821105

Epoch: 6| Step: 12
Training loss: 2.3574893474578857
Validation loss: 2.468589211022982

Epoch: 6| Step: 13
Training loss: 2.9784555435180664
Validation loss: 2.460414381437404

Epoch: 159| Step: 0
Training loss: 2.803864002227783
Validation loss: 2.4684940307371077

Epoch: 6| Step: 1
Training loss: 2.805281639099121
Validation loss: 2.462915776878275

Epoch: 6| Step: 2
Training loss: 2.319660186767578
Validation loss: 2.4651302137682514

Epoch: 6| Step: 3
Training loss: 2.5158326625823975
Validation loss: 2.4648929795911236

Epoch: 6| Step: 4
Training loss: 1.9095954895019531
Validation loss: 2.464388270531931

Epoch: 6| Step: 5
Training loss: 2.4859957695007324
Validation loss: 2.4624063122657036

Epoch: 6| Step: 6
Training loss: 2.4614474773406982
Validation loss: 2.464400686243529

Epoch: 6| Step: 7
Training loss: 3.1547842025756836
Validation loss: 2.4605731182200934

Epoch: 6| Step: 8
Training loss: 2.2962839603424072
Validation loss: 2.4623362966763076

Epoch: 6| Step: 9
Training loss: 3.053302049636841
Validation loss: 2.4603675232138684

Epoch: 6| Step: 10
Training loss: 2.432368278503418
Validation loss: 2.4629779477273264

Epoch: 6| Step: 11
Training loss: 3.304110527038574
Validation loss: 2.465217128876717

Epoch: 6| Step: 12
Training loss: 3.0811054706573486
Validation loss: 2.4683694660022693

Epoch: 6| Step: 13
Training loss: 2.7102537155151367
Validation loss: 2.463615637953563

Epoch: 160| Step: 0
Training loss: 3.0485193729400635
Validation loss: 2.4668566385904946

Epoch: 6| Step: 1
Training loss: 2.7037079334259033
Validation loss: 2.460370276563911

Epoch: 6| Step: 2
Training loss: 3.322512149810791
Validation loss: 2.4676581428896998

Epoch: 6| Step: 3
Training loss: 3.3251633644104004
Validation loss: 2.4555298564254597

Epoch: 6| Step: 4
Training loss: 2.3701987266540527
Validation loss: 2.4614671199552474

Epoch: 6| Step: 5
Training loss: 2.158905506134033
Validation loss: 2.4586366940570135

Epoch: 6| Step: 6
Training loss: 2.2836809158325195
Validation loss: 2.4591001951566307

Epoch: 6| Step: 7
Training loss: 1.9960802793502808
Validation loss: 2.467335529224847

Epoch: 6| Step: 8
Training loss: 2.0042195320129395
Validation loss: 2.467017968495687

Epoch: 6| Step: 9
Training loss: 2.4648642539978027
Validation loss: 2.4692471411920365

Epoch: 6| Step: 10
Training loss: 3.5383479595184326
Validation loss: 2.4734911508457635

Epoch: 6| Step: 11
Training loss: 2.0942001342773438
Validation loss: 2.4714862838868172

Epoch: 6| Step: 12
Training loss: 2.9371163845062256
Validation loss: 2.469913153238194

Epoch: 6| Step: 13
Training loss: 3.2948522567749023
Validation loss: 2.472566414904851

Epoch: 161| Step: 0
Training loss: 2.6670994758605957
Validation loss: 2.466770884811237

Epoch: 6| Step: 1
Training loss: 2.501025915145874
Validation loss: 2.4641258562764814

Epoch: 6| Step: 2
Training loss: 2.446504592895508
Validation loss: 2.462010616897255

Epoch: 6| Step: 3
Training loss: 1.9860262870788574
Validation loss: 2.4573567554514897

Epoch: 6| Step: 4
Training loss: 2.903265953063965
Validation loss: 2.457494871590727

Epoch: 6| Step: 5
Training loss: 2.532334327697754
Validation loss: 2.4597394850946244

Epoch: 6| Step: 6
Training loss: 2.783748149871826
Validation loss: 2.4529707713793685

Epoch: 6| Step: 7
Training loss: 2.3739094734191895
Validation loss: 2.453429073415777

Epoch: 6| Step: 8
Training loss: 3.2202062606811523
Validation loss: 2.456061158128964

Epoch: 6| Step: 9
Training loss: 3.6400299072265625
Validation loss: 2.4561121386866414

Epoch: 6| Step: 10
Training loss: 2.861572504043579
Validation loss: 2.4552367143733527

Epoch: 6| Step: 11
Training loss: 2.692656993865967
Validation loss: 2.456444142967142

Epoch: 6| Step: 12
Training loss: 2.703348159790039
Validation loss: 2.455775187861535

Epoch: 6| Step: 13
Training loss: 1.4922510385513306
Validation loss: 2.45700232700635

Epoch: 162| Step: 0
Training loss: 2.339836597442627
Validation loss: 2.4582408705065326

Epoch: 6| Step: 1
Training loss: 2.9097042083740234
Validation loss: 2.461221971819478

Epoch: 6| Step: 2
Training loss: 2.3202264308929443
Validation loss: 2.4599950954478276

Epoch: 6| Step: 3
Training loss: 2.2335972785949707
Validation loss: 2.457381033128308

Epoch: 6| Step: 4
Training loss: 2.403043746948242
Validation loss: 2.459869920566518

Epoch: 6| Step: 5
Training loss: 1.997572422027588
Validation loss: 2.460173947836763

Epoch: 6| Step: 6
Training loss: 2.6923506259918213
Validation loss: 2.4640536308288574

Epoch: 6| Step: 7
Training loss: 3.509307861328125
Validation loss: 2.4578717011277393

Epoch: 6| Step: 8
Training loss: 2.706085443496704
Validation loss: 2.456813020090903

Epoch: 6| Step: 9
Training loss: 2.4481992721557617
Validation loss: 2.46382019083987

Epoch: 6| Step: 10
Training loss: 3.4547338485717773
Validation loss: 2.46118075360534

Epoch: 6| Step: 11
Training loss: 2.670362949371338
Validation loss: 2.4594211886006017

Epoch: 6| Step: 12
Training loss: 2.8088574409484863
Validation loss: 2.462461092138803

Epoch: 6| Step: 13
Training loss: 2.760488986968994
Validation loss: 2.4575027035128687

Epoch: 163| Step: 0
Training loss: 2.993648052215576
Validation loss: 2.457053884383171

Epoch: 6| Step: 1
Training loss: 2.0012288093566895
Validation loss: 2.454804512762254

Epoch: 6| Step: 2
Training loss: 2.7798686027526855
Validation loss: 2.45161590268535

Epoch: 6| Step: 3
Training loss: 3.2457361221313477
Validation loss: 2.447234333202403

Epoch: 6| Step: 4
Training loss: 1.8767826557159424
Validation loss: 2.4473048102471138

Epoch: 6| Step: 5
Training loss: 2.722688674926758
Validation loss: 2.450239396864368

Epoch: 6| Step: 6
Training loss: 2.550802707672119
Validation loss: 2.4506463773788942

Epoch: 6| Step: 7
Training loss: 2.7795119285583496
Validation loss: 2.4535224335167998

Epoch: 6| Step: 8
Training loss: 2.220210552215576
Validation loss: 2.460067818241735

Epoch: 6| Step: 9
Training loss: 2.7715306282043457
Validation loss: 2.461894086612168

Epoch: 6| Step: 10
Training loss: 2.936825752258301
Validation loss: 2.4625022693346907

Epoch: 6| Step: 11
Training loss: 3.196068286895752
Validation loss: 2.4623616100639425

Epoch: 6| Step: 12
Training loss: 2.8102378845214844
Validation loss: 2.4658415496990247

Epoch: 6| Step: 13
Training loss: 2.151049852371216
Validation loss: 2.4679012093492734

Epoch: 164| Step: 0
Training loss: 3.0648159980773926
Validation loss: 2.464077131722563

Epoch: 6| Step: 1
Training loss: 2.7364938259124756
Validation loss: 2.4625063237323555

Epoch: 6| Step: 2
Training loss: 2.9988293647766113
Validation loss: 2.455003830694383

Epoch: 6| Step: 3
Training loss: 2.9075417518615723
Validation loss: 2.4560902093046453

Epoch: 6| Step: 4
Training loss: 2.1009371280670166
Validation loss: 2.4547309003850466

Epoch: 6| Step: 5
Training loss: 2.9999208450317383
Validation loss: 2.4540256249007357

Epoch: 6| Step: 6
Training loss: 2.5466859340667725
Validation loss: 2.4485932191212973

Epoch: 6| Step: 7
Training loss: 2.4465038776397705
Validation loss: 2.4520368806777464

Epoch: 6| Step: 8
Training loss: 2.2899975776672363
Validation loss: 2.4511915637600805

Epoch: 6| Step: 9
Training loss: 2.1698684692382812
Validation loss: 2.4533593757178194

Epoch: 6| Step: 10
Training loss: 3.4900312423706055
Validation loss: 2.455982828652987

Epoch: 6| Step: 11
Training loss: 2.525312900543213
Validation loss: 2.4544507021545083

Epoch: 6| Step: 12
Training loss: 2.5411202907562256
Validation loss: 2.459925654113934

Epoch: 6| Step: 13
Training loss: 2.252946615219116
Validation loss: 2.460288829700921

Epoch: 165| Step: 0
Training loss: 3.034602403640747
Validation loss: 2.469227190940611

Epoch: 6| Step: 1
Training loss: 2.4763951301574707
Validation loss: 2.476215185657624

Epoch: 6| Step: 2
Training loss: 2.712405204772949
Validation loss: 2.4824550331279798

Epoch: 6| Step: 3
Training loss: 1.9880009889602661
Validation loss: 2.4777503269974903

Epoch: 6| Step: 4
Training loss: 2.7367119789123535
Validation loss: 2.493551900309901

Epoch: 6| Step: 5
Training loss: 2.645336627960205
Validation loss: 2.4957665371638473

Epoch: 6| Step: 6
Training loss: 2.4422109127044678
Validation loss: 2.513170042345601

Epoch: 6| Step: 7
Training loss: 2.4008069038391113
Validation loss: 2.4939234846381733

Epoch: 6| Step: 8
Training loss: 2.3078126907348633
Validation loss: 2.4735644222587667

Epoch: 6| Step: 9
Training loss: 1.8072359561920166
Validation loss: 2.467980977027647

Epoch: 6| Step: 10
Training loss: 3.8405144214630127
Validation loss: 2.4526778626185592

Epoch: 6| Step: 11
Training loss: 3.058938503265381
Validation loss: 2.451189402611025

Epoch: 6| Step: 12
Training loss: 2.873216152191162
Validation loss: 2.4480554262797036

Epoch: 6| Step: 13
Training loss: 3.134190559387207
Validation loss: 2.4446399570793234

Epoch: 166| Step: 0
Training loss: 2.8794748783111572
Validation loss: 2.4469967247337423

Epoch: 6| Step: 1
Training loss: 3.1807093620300293
Validation loss: 2.4468168725249586

Epoch: 6| Step: 2
Training loss: 2.814188003540039
Validation loss: 2.4413104467494513

Epoch: 6| Step: 3
Training loss: 2.1158952713012695
Validation loss: 2.4438466730938164

Epoch: 6| Step: 4
Training loss: 2.9811763763427734
Validation loss: 2.442057732612856

Epoch: 6| Step: 5
Training loss: 2.0824408531188965
Validation loss: 2.4496994582555627

Epoch: 6| Step: 6
Training loss: 2.567445993423462
Validation loss: 2.4425400405801754

Epoch: 6| Step: 7
Training loss: 2.112194776535034
Validation loss: 2.44208546351361

Epoch: 6| Step: 8
Training loss: 2.732351779937744
Validation loss: 2.4392512331726732

Epoch: 6| Step: 9
Training loss: 2.865091562271118
Validation loss: 2.4436750001804803

Epoch: 6| Step: 10
Training loss: 1.9242600202560425
Validation loss: 2.4453689154758247

Epoch: 6| Step: 11
Training loss: 3.4059367179870605
Validation loss: 2.444000421031829

Epoch: 6| Step: 12
Training loss: 2.884662628173828
Validation loss: 2.4542504561844694

Epoch: 6| Step: 13
Training loss: 2.7649340629577637
Validation loss: 2.450761607898179

Epoch: 167| Step: 0
Training loss: 2.5001602172851562
Validation loss: 2.4502869165071877

Epoch: 6| Step: 1
Training loss: 2.318042755126953
Validation loss: 2.44417747887232

Epoch: 6| Step: 2
Training loss: 2.1694839000701904
Validation loss: 2.441385366583383

Epoch: 6| Step: 3
Training loss: 2.9267570972442627
Validation loss: 2.443720316374174

Epoch: 6| Step: 4
Training loss: 2.836272716522217
Validation loss: 2.4455701894657587

Epoch: 6| Step: 5
Training loss: 3.4201831817626953
Validation loss: 2.4399601131357174

Epoch: 6| Step: 6
Training loss: 2.7079713344573975
Validation loss: 2.443096694125924

Epoch: 6| Step: 7
Training loss: 1.736181616783142
Validation loss: 2.442479807843444

Epoch: 6| Step: 8
Training loss: 3.509160041809082
Validation loss: 2.440896398277693

Epoch: 6| Step: 9
Training loss: 2.757972002029419
Validation loss: 2.445482874429354

Epoch: 6| Step: 10
Training loss: 1.9274790287017822
Validation loss: 2.4433551808839202

Epoch: 6| Step: 11
Training loss: 2.6997461318969727
Validation loss: 2.4479736717798377

Epoch: 6| Step: 12
Training loss: 2.9137985706329346
Validation loss: 2.448489260929887

Epoch: 6| Step: 13
Training loss: 2.751291036605835
Validation loss: 2.4682133838694584

Epoch: 168| Step: 0
Training loss: 2.8258771896362305
Validation loss: 2.464882722464941

Epoch: 6| Step: 1
Training loss: 3.038763999938965
Validation loss: 2.4688375201276553

Epoch: 6| Step: 2
Training loss: 2.185102701187134
Validation loss: 2.4560127719756095

Epoch: 6| Step: 3
Training loss: 2.8322255611419678
Validation loss: 2.4483471429476173

Epoch: 6| Step: 4
Training loss: 3.238813638687134
Validation loss: 2.445667851355768

Epoch: 6| Step: 5
Training loss: 2.7696995735168457
Validation loss: 2.441466931373842

Epoch: 6| Step: 6
Training loss: 2.0824217796325684
Validation loss: 2.441303881265784

Epoch: 6| Step: 7
Training loss: 2.3014931678771973
Validation loss: 2.4386422634124756

Epoch: 6| Step: 8
Training loss: 2.584357738494873
Validation loss: 2.4410397544983895

Epoch: 6| Step: 9
Training loss: 2.6466569900512695
Validation loss: 2.441493329181466

Epoch: 6| Step: 10
Training loss: 2.777801513671875
Validation loss: 2.4430032827520884

Epoch: 6| Step: 11
Training loss: 2.4078750610351562
Validation loss: 2.4524052912189114

Epoch: 6| Step: 12
Training loss: 2.6463029384613037
Validation loss: 2.4501719808065765

Epoch: 6| Step: 13
Training loss: 3.2096166610717773
Validation loss: 2.459585092400992

Epoch: 169| Step: 0
Training loss: 3.1238741874694824
Validation loss: 2.458120028177897

Epoch: 6| Step: 1
Training loss: 2.9557535648345947
Validation loss: 2.460289325765384

Epoch: 6| Step: 2
Training loss: 1.600419521331787
Validation loss: 2.4609516384781047

Epoch: 6| Step: 3
Training loss: 3.4880635738372803
Validation loss: 2.460477113723755

Epoch: 6| Step: 4
Training loss: 3.0723657608032227
Validation loss: 2.457212478883805

Epoch: 6| Step: 5
Training loss: 2.7256460189819336
Validation loss: 2.4557239214579263

Epoch: 6| Step: 6
Training loss: 2.985762119293213
Validation loss: 2.448817140312605

Epoch: 6| Step: 7
Training loss: 2.5899786949157715
Validation loss: 2.4490613834832304

Epoch: 6| Step: 8
Training loss: 2.6700973510742188
Validation loss: 2.45103431388896

Epoch: 6| Step: 9
Training loss: 2.5857789516448975
Validation loss: 2.446136038790467

Epoch: 6| Step: 10
Training loss: 2.5004043579101562
Validation loss: 2.442362457193354

Epoch: 6| Step: 11
Training loss: 1.7491661310195923
Validation loss: 2.441259317500617

Epoch: 6| Step: 12
Training loss: 2.7380709648132324
Validation loss: 2.4386029397287676

Epoch: 6| Step: 13
Training loss: 2.123882532119751
Validation loss: 2.4447696772954797

Epoch: 170| Step: 0
Training loss: 3.178506374359131
Validation loss: 2.4460146170790478

Epoch: 6| Step: 1
Training loss: 3.1689319610595703
Validation loss: 2.440299662210608

Epoch: 6| Step: 2
Training loss: 2.6043941974639893
Validation loss: 2.446041399432767

Epoch: 6| Step: 3
Training loss: 2.0501089096069336
Validation loss: 2.445510959112516

Epoch: 6| Step: 4
Training loss: 2.8019423484802246
Validation loss: 2.45054526739223

Epoch: 6| Step: 5
Training loss: 2.2956724166870117
Validation loss: 2.4561357728896605

Epoch: 6| Step: 6
Training loss: 2.447277784347534
Validation loss: 2.451220489317371

Epoch: 6| Step: 7
Training loss: 2.297401189804077
Validation loss: 2.4574906928564912

Epoch: 6| Step: 8
Training loss: 2.298945903778076
Validation loss: 2.465852857917868

Epoch: 6| Step: 9
Training loss: 2.4582602977752686
Validation loss: 2.4685282066304195

Epoch: 6| Step: 10
Training loss: 2.8426785469055176
Validation loss: 2.4710150995562152

Epoch: 6| Step: 11
Training loss: 2.487321376800537
Validation loss: 2.4660289441385577

Epoch: 6| Step: 12
Training loss: 3.296868324279785
Validation loss: 2.4646921183473323

Epoch: 6| Step: 13
Training loss: 2.983694553375244
Validation loss: 2.4589056968688965

Epoch: 171| Step: 0
Training loss: 3.264789581298828
Validation loss: 2.4529668438819145

Epoch: 6| Step: 1
Training loss: 2.2820839881896973
Validation loss: 2.450528719091928

Epoch: 6| Step: 2
Training loss: 2.7258307933807373
Validation loss: 2.4431414450368574

Epoch: 6| Step: 3
Training loss: 2.807615280151367
Validation loss: 2.4431596930309007

Epoch: 6| Step: 4
Training loss: 3.143207550048828
Validation loss: 2.4410443459787676

Epoch: 6| Step: 5
Training loss: 2.7495479583740234
Validation loss: 2.4374493065700737

Epoch: 6| Step: 6
Training loss: 2.530336856842041
Validation loss: 2.4369368565979825

Epoch: 6| Step: 7
Training loss: 2.971381664276123
Validation loss: 2.439256901382118

Epoch: 6| Step: 8
Training loss: 2.5358164310455322
Validation loss: 2.435881765939856

Epoch: 6| Step: 9
Training loss: 3.1860976219177246
Validation loss: 2.4368162744788715

Epoch: 6| Step: 10
Training loss: 2.9004108905792236
Validation loss: 2.4376427601742487

Epoch: 6| Step: 11
Training loss: 1.9021215438842773
Validation loss: 2.437834885812575

Epoch: 6| Step: 12
Training loss: 1.8847641944885254
Validation loss: 2.4414867713887203

Epoch: 6| Step: 13
Training loss: 1.8291568756103516
Validation loss: 2.4457553971198296

Epoch: 172| Step: 0
Training loss: 2.663893222808838
Validation loss: 2.443649349674102

Epoch: 6| Step: 1
Training loss: 2.4296326637268066
Validation loss: 2.44784971462783

Epoch: 6| Step: 2
Training loss: 2.2652149200439453
Validation loss: 2.4568585939304803

Epoch: 6| Step: 3
Training loss: 2.338655948638916
Validation loss: 2.4565274484695925

Epoch: 6| Step: 4
Training loss: 2.0742039680480957
Validation loss: 2.462162353659189

Epoch: 6| Step: 5
Training loss: 2.2325439453125
Validation loss: 2.4602540205883723

Epoch: 6| Step: 6
Training loss: 2.472346067428589
Validation loss: 2.466780029317384

Epoch: 6| Step: 7
Training loss: 2.273474931716919
Validation loss: 2.468078197971467

Epoch: 6| Step: 8
Training loss: 2.9731040000915527
Validation loss: 2.4652663917951685

Epoch: 6| Step: 9
Training loss: 2.5434961318969727
Validation loss: 2.463737944121002

Epoch: 6| Step: 10
Training loss: 3.7442514896392822
Validation loss: 2.449343435225948

Epoch: 6| Step: 11
Training loss: 2.9715025424957275
Validation loss: 2.4452532286285074

Epoch: 6| Step: 12
Training loss: 2.772157669067383
Validation loss: 2.437020863256147

Epoch: 6| Step: 13
Training loss: 3.8324809074401855
Validation loss: 2.435107059376214

Epoch: 173| Step: 0
Training loss: 2.2147324085235596
Validation loss: 2.4318201618809856

Epoch: 6| Step: 1
Training loss: 2.3822455406188965
Validation loss: 2.4337380752768567

Epoch: 6| Step: 2
Training loss: 2.8306941986083984
Validation loss: 2.4343707253856044

Epoch: 6| Step: 3
Training loss: 2.545135021209717
Validation loss: 2.432600005980461

Epoch: 6| Step: 4
Training loss: 1.927410364151001
Validation loss: 2.4361761513576714

Epoch: 6| Step: 5
Training loss: 2.35457181930542
Validation loss: 2.436181381184568

Epoch: 6| Step: 6
Training loss: 2.688610315322876
Validation loss: 2.4380308428118305

Epoch: 6| Step: 7
Training loss: 3.580422878265381
Validation loss: 2.4395091046569166

Epoch: 6| Step: 8
Training loss: 2.8939452171325684
Validation loss: 2.436920812053065

Epoch: 6| Step: 9
Training loss: 2.894282102584839
Validation loss: 2.4346909958829164

Epoch: 6| Step: 10
Training loss: 2.513106346130371
Validation loss: 2.443781752740183

Epoch: 6| Step: 11
Training loss: 2.419713258743286
Validation loss: 2.4372640860977994

Epoch: 6| Step: 12
Training loss: 3.0987706184387207
Validation loss: 2.443067514768211

Epoch: 6| Step: 13
Training loss: 2.924839973449707
Validation loss: 2.4476522348260366

Epoch: 174| Step: 0
Training loss: 3.1488757133483887
Validation loss: 2.449964387442476

Epoch: 6| Step: 1
Training loss: 2.2857632637023926
Validation loss: 2.4560065038742556

Epoch: 6| Step: 2
Training loss: 2.7804412841796875
Validation loss: 2.4618434213822886

Epoch: 6| Step: 3
Training loss: 2.7293639183044434
Validation loss: 2.4550639865218953

Epoch: 6| Step: 4
Training loss: 2.6703004837036133
Validation loss: 2.455844135694606

Epoch: 6| Step: 5
Training loss: 2.1582770347595215
Validation loss: 2.454474787558279

Epoch: 6| Step: 6
Training loss: 2.128070831298828
Validation loss: 2.4514740846490346

Epoch: 6| Step: 7
Training loss: 2.81610107421875
Validation loss: 2.4568548228151057

Epoch: 6| Step: 8
Training loss: 2.5763165950775146
Validation loss: 2.442635392629972

Epoch: 6| Step: 9
Training loss: 3.282437324523926
Validation loss: 2.444863478342692

Epoch: 6| Step: 10
Training loss: 2.070768356323242
Validation loss: 2.4468208564225065

Epoch: 6| Step: 11
Training loss: 3.113062620162964
Validation loss: 2.4444604701893304

Epoch: 6| Step: 12
Training loss: 3.256772994995117
Validation loss: 2.4578678659213486

Epoch: 6| Step: 13
Training loss: 1.5399584770202637
Validation loss: 2.450149151586717

Epoch: 175| Step: 0
Training loss: 3.222162961959839
Validation loss: 2.4420208623332362

Epoch: 6| Step: 1
Training loss: 2.756523847579956
Validation loss: 2.44912403116944

Epoch: 6| Step: 2
Training loss: 3.107626438140869
Validation loss: 2.4441592795874483

Epoch: 6| Step: 3
Training loss: 2.785714864730835
Validation loss: 2.436066086574267

Epoch: 6| Step: 4
Training loss: 2.673011064529419
Validation loss: 2.4282369267555977

Epoch: 6| Step: 5
Training loss: 2.123994827270508
Validation loss: 2.4281768747555312

Epoch: 6| Step: 6
Training loss: 2.862213134765625
Validation loss: 2.428320553994948

Epoch: 6| Step: 7
Training loss: 2.429429054260254
Validation loss: 2.4311965947510092

Epoch: 6| Step: 8
Training loss: 2.7840421199798584
Validation loss: 2.429382539564563

Epoch: 6| Step: 9
Training loss: 2.3495264053344727
Validation loss: 2.4362059229163715

Epoch: 6| Step: 10
Training loss: 2.289647102355957
Validation loss: 2.4289557626170497

Epoch: 6| Step: 11
Training loss: 2.6695749759674072
Validation loss: 2.4462092666215796

Epoch: 6| Step: 12
Training loss: 2.4830269813537598
Validation loss: 2.448200874431159

Epoch: 6| Step: 13
Training loss: 2.411433219909668
Validation loss: 2.4481968623335644

Epoch: 176| Step: 0
Training loss: 2.223881244659424
Validation loss: 2.447053737537835

Epoch: 6| Step: 1
Training loss: 3.0188214778900146
Validation loss: 2.443010999310401

Epoch: 6| Step: 2
Training loss: 1.795440435409546
Validation loss: 2.4373517779893774

Epoch: 6| Step: 3
Training loss: 2.668954372406006
Validation loss: 2.4318065181855233

Epoch: 6| Step: 4
Training loss: 1.7650094032287598
Validation loss: 2.427703680530671

Epoch: 6| Step: 5
Training loss: 2.7720947265625
Validation loss: 2.4307021287179764

Epoch: 6| Step: 6
Training loss: 3.0435171127319336
Validation loss: 2.431802575306226

Epoch: 6| Step: 7
Training loss: 3.351198196411133
Validation loss: 2.4297793936985794

Epoch: 6| Step: 8
Training loss: 2.6189026832580566
Validation loss: 2.4295827906618834

Epoch: 6| Step: 9
Training loss: 2.774003028869629
Validation loss: 2.432043388325681

Epoch: 6| Step: 10
Training loss: 3.4042959213256836
Validation loss: 2.423669756099742

Epoch: 6| Step: 11
Training loss: 2.33504581451416
Validation loss: 2.431971393605714

Epoch: 6| Step: 12
Training loss: 2.6300272941589355
Validation loss: 2.431954942723756

Epoch: 6| Step: 13
Training loss: 2.5885236263275146
Validation loss: 2.437060002357729

Epoch: 177| Step: 0
Training loss: 2.5627570152282715
Validation loss: 2.43667576389928

Epoch: 6| Step: 1
Training loss: 2.446354627609253
Validation loss: 2.438046560492567

Epoch: 6| Step: 2
Training loss: 2.5116710662841797
Validation loss: 2.4362605643528763

Epoch: 6| Step: 3
Training loss: 2.9069652557373047
Validation loss: 2.4431474567741476

Epoch: 6| Step: 4
Training loss: 2.868053913116455
Validation loss: 2.441347296519946

Epoch: 6| Step: 5
Training loss: 3.023991584777832
Validation loss: 2.4437257013013287

Epoch: 6| Step: 6
Training loss: 3.1907036304473877
Validation loss: 2.4357891339127735

Epoch: 6| Step: 7
Training loss: 2.457007884979248
Validation loss: 2.441392719104726

Epoch: 6| Step: 8
Training loss: 2.9150214195251465
Validation loss: 2.437139566226672

Epoch: 6| Step: 9
Training loss: 2.7038345336914062
Validation loss: 2.4458286916055987

Epoch: 6| Step: 10
Training loss: 1.9523653984069824
Validation loss: 2.4486544209141887

Epoch: 6| Step: 11
Training loss: 2.758350133895874
Validation loss: 2.437716437924293

Epoch: 6| Step: 12
Training loss: 1.9545704126358032
Validation loss: 2.4428380663676927

Epoch: 6| Step: 13
Training loss: 2.7779476642608643
Validation loss: 2.43946748651484

Epoch: 178| Step: 0
Training loss: 3.4878554344177246
Validation loss: 2.4384687126323743

Epoch: 6| Step: 1
Training loss: 2.354016065597534
Validation loss: 2.438984917056176

Epoch: 6| Step: 2
Training loss: 3.2370901107788086
Validation loss: 2.4372358091415895

Epoch: 6| Step: 3
Training loss: 2.462270736694336
Validation loss: 2.437144024397737

Epoch: 6| Step: 4
Training loss: 2.8149876594543457
Validation loss: 2.438040679500949

Epoch: 6| Step: 5
Training loss: 2.082026481628418
Validation loss: 2.4306557178497314

Epoch: 6| Step: 6
Training loss: 3.7654409408569336
Validation loss: 2.4317145911596154

Epoch: 6| Step: 7
Training loss: 1.753179907798767
Validation loss: 2.433729064080023

Epoch: 6| Step: 8
Training loss: 2.345940351486206
Validation loss: 2.436325437279158

Epoch: 6| Step: 9
Training loss: 2.768813133239746
Validation loss: 2.44915158261535

Epoch: 6| Step: 10
Training loss: 2.6288671493530273
Validation loss: 2.4527002047466975

Epoch: 6| Step: 11
Training loss: 2.9313859939575195
Validation loss: 2.45051985145897

Epoch: 6| Step: 12
Training loss: 1.7091102600097656
Validation loss: 2.444698226067328

Epoch: 6| Step: 13
Training loss: 2.5904698371887207
Validation loss: 2.45394713904268

Epoch: 179| Step: 0
Training loss: 2.610661268234253
Validation loss: 2.4484538314163045

Epoch: 6| Step: 1
Training loss: 2.6466786861419678
Validation loss: 2.4479979956021873

Epoch: 6| Step: 2
Training loss: 2.4723477363586426
Validation loss: 2.4361244734897407

Epoch: 6| Step: 3
Training loss: 3.497371196746826
Validation loss: 2.427749469716062

Epoch: 6| Step: 4
Training loss: 2.5366101264953613
Validation loss: 2.431167020592638

Epoch: 6| Step: 5
Training loss: 2.7565388679504395
Validation loss: 2.429963804060413

Epoch: 6| Step: 6
Training loss: 2.651939868927002
Validation loss: 2.4252081468541133

Epoch: 6| Step: 7
Training loss: 2.3418610095977783
Validation loss: 2.430956453405401

Epoch: 6| Step: 8
Training loss: 2.6773605346679688
Validation loss: 2.4325491433502524

Epoch: 6| Step: 9
Training loss: 2.723097801208496
Validation loss: 2.4364833498513825

Epoch: 6| Step: 10
Training loss: 1.921671986579895
Validation loss: 2.432042565397037

Epoch: 6| Step: 11
Training loss: 2.906550407409668
Validation loss: 2.4404983520507812

Epoch: 6| Step: 12
Training loss: 2.7487874031066895
Validation loss: 2.4385269867476596

Epoch: 6| Step: 13
Training loss: 2.1561763286590576
Validation loss: 2.4368474329671552

Epoch: 180| Step: 0
Training loss: 3.805276393890381
Validation loss: 2.432436539280799

Epoch: 6| Step: 1
Training loss: 2.0848803520202637
Validation loss: 2.43630894794259

Epoch: 6| Step: 2
Training loss: 1.9684584140777588
Validation loss: 2.4271674207461778

Epoch: 6| Step: 3
Training loss: 2.36970591545105
Validation loss: 2.4313504490801083

Epoch: 6| Step: 4
Training loss: 2.4967634677886963
Validation loss: 2.4287788175767466

Epoch: 6| Step: 5
Training loss: 2.3145766258239746
Validation loss: 2.4318314803543912

Epoch: 6| Step: 6
Training loss: 3.0968732833862305
Validation loss: 2.428327429679132

Epoch: 6| Step: 7
Training loss: 3.650071144104004
Validation loss: 2.43874260943423

Epoch: 6| Step: 8
Training loss: 2.9465246200561523
Validation loss: 2.4359795329391316

Epoch: 6| Step: 9
Training loss: 1.9722130298614502
Validation loss: 2.4396865085888932

Epoch: 6| Step: 10
Training loss: 2.9491536617279053
Validation loss: 2.4550280314619823

Epoch: 6| Step: 11
Training loss: 2.2269556522369385
Validation loss: 2.460289201428813

Epoch: 6| Step: 12
Training loss: 2.6863784790039062
Validation loss: 2.45789082588688

Epoch: 6| Step: 13
Training loss: 2.183542490005493
Validation loss: 2.452699217745053

Epoch: 181| Step: 0
Training loss: 2.9772701263427734
Validation loss: 2.4451058859466226

Epoch: 6| Step: 1
Training loss: 2.5883660316467285
Validation loss: 2.433000913230322

Epoch: 6| Step: 2
Training loss: 3.181030750274658
Validation loss: 2.4315952921426423

Epoch: 6| Step: 3
Training loss: 2.413261890411377
Validation loss: 2.4187041431344967

Epoch: 6| Step: 4
Training loss: 2.9576539993286133
Validation loss: 2.4166227720117055

Epoch: 6| Step: 5
Training loss: 3.2944533824920654
Validation loss: 2.415430335588353

Epoch: 6| Step: 6
Training loss: 2.2464208602905273
Validation loss: 2.4158049296307307

Epoch: 6| Step: 7
Training loss: 2.665020227432251
Validation loss: 2.415112010894283

Epoch: 6| Step: 8
Training loss: 2.3518428802490234
Validation loss: 2.412216471087548

Epoch: 6| Step: 9
Training loss: 2.8645191192626953
Validation loss: 2.4105552755376345

Epoch: 6| Step: 10
Training loss: 1.9526245594024658
Validation loss: 2.411683646581506

Epoch: 6| Step: 11
Training loss: 2.6848154067993164
Validation loss: 2.4121524313444733

Epoch: 6| Step: 12
Training loss: 2.293260097503662
Validation loss: 2.4113763327239663

Epoch: 6| Step: 13
Training loss: 2.324171781539917
Validation loss: 2.4134263735945507

Epoch: 182| Step: 0
Training loss: 3.6198112964630127
Validation loss: 2.411585610399964

Epoch: 6| Step: 1
Training loss: 2.958721160888672
Validation loss: 2.414661540780016

Epoch: 6| Step: 2
Training loss: 3.9273853302001953
Validation loss: 2.4232492087989725

Epoch: 6| Step: 3
Training loss: 2.0553085803985596
Validation loss: 2.4189541006600983

Epoch: 6| Step: 4
Training loss: 2.0928266048431396
Validation loss: 2.422711172411519

Epoch: 6| Step: 5
Training loss: 2.0768990516662598
Validation loss: 2.4129379051987843

Epoch: 6| Step: 6
Training loss: 3.2844812870025635
Validation loss: 2.4233267666191183

Epoch: 6| Step: 7
Training loss: 2.2688050270080566
Validation loss: 2.43222689372237

Epoch: 6| Step: 8
Training loss: 1.9785640239715576
Validation loss: 2.442590771182891

Epoch: 6| Step: 9
Training loss: 3.0093817710876465
Validation loss: 2.452506103823262

Epoch: 6| Step: 10
Training loss: 2.099578857421875
Validation loss: 2.45917938088858

Epoch: 6| Step: 11
Training loss: 2.073884963989258
Validation loss: 2.4484024329852034

Epoch: 6| Step: 12
Training loss: 3.269174098968506
Validation loss: 2.450977720240111

Epoch: 6| Step: 13
Training loss: 1.7528843879699707
Validation loss: 2.4608505438732844

Epoch: 183| Step: 0
Training loss: 3.180656909942627
Validation loss: 2.4577067487983295

Epoch: 6| Step: 1
Training loss: 2.2045559883117676
Validation loss: 2.4626697955592984

Epoch: 6| Step: 2
Training loss: 3.075949192047119
Validation loss: 2.460017465776013

Epoch: 6| Step: 3
Training loss: 2.774993896484375
Validation loss: 2.4541404529284407

Epoch: 6| Step: 4
Training loss: 2.152325391769409
Validation loss: 2.4391125402142926

Epoch: 6| Step: 5
Training loss: 2.1478993892669678
Validation loss: 2.4283165700974

Epoch: 6| Step: 6
Training loss: 3.880023241043091
Validation loss: 2.4235947414111068

Epoch: 6| Step: 7
Training loss: 2.5364925861358643
Validation loss: 2.423241728095598

Epoch: 6| Step: 8
Training loss: 2.486050605773926
Validation loss: 2.420239803611591

Epoch: 6| Step: 9
Training loss: 2.338238000869751
Validation loss: 2.417161556982225

Epoch: 6| Step: 10
Training loss: 3.27876615524292
Validation loss: 2.4136783563962547

Epoch: 6| Step: 11
Training loss: 1.937323808670044
Validation loss: 2.4213929201966975

Epoch: 6| Step: 12
Training loss: 2.595054864883423
Validation loss: 2.4238011221731863

Epoch: 6| Step: 13
Training loss: 2.2723135948181152
Validation loss: 2.4241391792092273

Epoch: 184| Step: 0
Training loss: 2.5632572174072266
Validation loss: 2.424683227333971

Epoch: 6| Step: 1
Training loss: 2.389861583709717
Validation loss: 2.4333993106760006

Epoch: 6| Step: 2
Training loss: 2.5130624771118164
Validation loss: 2.440703776574904

Epoch: 6| Step: 3
Training loss: 2.912741184234619
Validation loss: 2.444194173300138

Epoch: 6| Step: 4
Training loss: 2.095813751220703
Validation loss: 2.4487711050177134

Epoch: 6| Step: 5
Training loss: 2.7431037425994873
Validation loss: 2.461327378467847

Epoch: 6| Step: 6
Training loss: 2.010042190551758
Validation loss: 2.474071205303233

Epoch: 6| Step: 7
Training loss: 2.2351436614990234
Validation loss: 2.4687831042915263

Epoch: 6| Step: 8
Training loss: 3.756141185760498
Validation loss: 2.4673578431529384

Epoch: 6| Step: 9
Training loss: 3.239035129547119
Validation loss: 2.4794714758473058

Epoch: 6| Step: 10
Training loss: 2.158163070678711
Validation loss: 2.4656989856432845

Epoch: 6| Step: 11
Training loss: 2.6560616493225098
Validation loss: 2.445544494095669

Epoch: 6| Step: 12
Training loss: 2.8841187953948975
Validation loss: 2.444169636695616

Epoch: 6| Step: 13
Training loss: 2.9462783336639404
Validation loss: 2.4254648659818914

Epoch: 185| Step: 0
Training loss: 2.648728370666504
Validation loss: 2.4174651330517185

Epoch: 6| Step: 1
Training loss: 2.7777905464172363
Validation loss: 2.4208220999727965

Epoch: 6| Step: 2
Training loss: 3.1845083236694336
Validation loss: 2.4217493252087663

Epoch: 6| Step: 3
Training loss: 3.0486788749694824
Validation loss: 2.4198349804006596

Epoch: 6| Step: 4
Training loss: 2.392788887023926
Validation loss: 2.410109660958731

Epoch: 6| Step: 5
Training loss: 2.475515842437744
Validation loss: 2.417513079540704

Epoch: 6| Step: 6
Training loss: 2.6351122856140137
Validation loss: 2.4111747434062343

Epoch: 6| Step: 7
Training loss: 2.8126349449157715
Validation loss: 2.415922203371602

Epoch: 6| Step: 8
Training loss: 2.3380885124206543
Validation loss: 2.415927379362045

Epoch: 6| Step: 9
Training loss: 2.737288475036621
Validation loss: 2.4138115554727535

Epoch: 6| Step: 10
Training loss: 3.2140791416168213
Validation loss: 2.421113726913288

Epoch: 6| Step: 11
Training loss: 1.6088483333587646
Validation loss: 2.4213565703361266

Epoch: 6| Step: 12
Training loss: 2.9050936698913574
Validation loss: 2.4344727403374127

Epoch: 6| Step: 13
Training loss: 2.0618081092834473
Validation loss: 2.4182762407487437

Epoch: 186| Step: 0
Training loss: 2.3516845703125
Validation loss: 2.4210603185879287

Epoch: 6| Step: 1
Training loss: 2.4934611320495605
Validation loss: 2.4107056048608597

Epoch: 6| Step: 2
Training loss: 2.6938371658325195
Validation loss: 2.4141617308380785

Epoch: 6| Step: 3
Training loss: 1.9140628576278687
Validation loss: 2.408940866429319

Epoch: 6| Step: 4
Training loss: 2.669945240020752
Validation loss: 2.411538623994397

Epoch: 6| Step: 5
Training loss: 2.6267638206481934
Validation loss: 2.4137466646009877

Epoch: 6| Step: 6
Training loss: 3.7545480728149414
Validation loss: 2.4149117828697286

Epoch: 6| Step: 7
Training loss: 2.8184711933135986
Validation loss: 2.4153658600263697

Epoch: 6| Step: 8
Training loss: 2.6139514446258545
Validation loss: 2.416017686167071

Epoch: 6| Step: 9
Training loss: 2.8450894355773926
Validation loss: 2.418125775552565

Epoch: 6| Step: 10
Training loss: 2.868248701095581
Validation loss: 2.418969774758944

Epoch: 6| Step: 11
Training loss: 1.9735033512115479
Validation loss: 2.41909146565263

Epoch: 6| Step: 12
Training loss: 2.7509865760803223
Validation loss: 2.42487209714869

Epoch: 6| Step: 13
Training loss: 2.473015308380127
Validation loss: 2.425723744976905

Epoch: 187| Step: 0
Training loss: 3.075352668762207
Validation loss: 2.4273696971196

Epoch: 6| Step: 1
Training loss: 2.5244457721710205
Validation loss: 2.4324294623508247

Epoch: 6| Step: 2
Training loss: 2.383255958557129
Validation loss: 2.428659721087384

Epoch: 6| Step: 3
Training loss: 2.598886013031006
Validation loss: 2.4258583694375973

Epoch: 6| Step: 4
Training loss: 2.4814066886901855
Validation loss: 2.432390897504745

Epoch: 6| Step: 5
Training loss: 2.430569648742676
Validation loss: 2.430535826631772

Epoch: 6| Step: 6
Training loss: 2.765000343322754
Validation loss: 2.4205175369016585

Epoch: 6| Step: 7
Training loss: 3.3918333053588867
Validation loss: 2.4246625669540895

Epoch: 6| Step: 8
Training loss: 2.4931187629699707
Validation loss: 2.4173926538036716

Epoch: 6| Step: 9
Training loss: 2.5509514808654785
Validation loss: 2.416671376074514

Epoch: 6| Step: 10
Training loss: 2.691876173019409
Validation loss: 2.4144087273587465

Epoch: 6| Step: 11
Training loss: 2.2672462463378906
Validation loss: 2.414910874059123

Epoch: 6| Step: 12
Training loss: 2.6187634468078613
Validation loss: 2.412515896622853

Epoch: 6| Step: 13
Training loss: 2.5292420387268066
Validation loss: 2.4182599308670207

Epoch: 188| Step: 0
Training loss: 2.9093117713928223
Validation loss: 2.417842247152841

Epoch: 6| Step: 1
Training loss: 2.7825894355773926
Validation loss: 2.4189998513908795

Epoch: 6| Step: 2
Training loss: 3.3458657264709473
Validation loss: 2.4161410818817797

Epoch: 6| Step: 3
Training loss: 2.804664134979248
Validation loss: 2.42082477641362

Epoch: 6| Step: 4
Training loss: 2.5513429641723633
Validation loss: 2.41444763060539

Epoch: 6| Step: 5
Training loss: 1.9142663478851318
Validation loss: 2.412144971150224

Epoch: 6| Step: 6
Training loss: 2.7525272369384766
Validation loss: 2.4166603062742498

Epoch: 6| Step: 7
Training loss: 2.092625617980957
Validation loss: 2.4155496166598414

Epoch: 6| Step: 8
Training loss: 2.073984146118164
Validation loss: 2.41239591311383

Epoch: 6| Step: 9
Training loss: 3.3313076496124268
Validation loss: 2.4165230335727816

Epoch: 6| Step: 10
Training loss: 3.4812283515930176
Validation loss: 2.413015324582336

Epoch: 6| Step: 11
Training loss: 2.2849626541137695
Validation loss: 2.4157644958906275

Epoch: 6| Step: 12
Training loss: 1.9168273210525513
Validation loss: 2.4216054998418337

Epoch: 6| Step: 13
Training loss: 2.497129201889038
Validation loss: 2.4286508201270975

Epoch: 189| Step: 0
Training loss: 3.0462088584899902
Validation loss: 2.421523114686371

Epoch: 6| Step: 1
Training loss: 2.552701473236084
Validation loss: 2.424440606947868

Epoch: 6| Step: 2
Training loss: 2.48976731300354
Validation loss: 2.426429335789014

Epoch: 6| Step: 3
Training loss: 2.6557626724243164
Validation loss: 2.4271057344252065

Epoch: 6| Step: 4
Training loss: 1.8981389999389648
Validation loss: 2.4311398075472925

Epoch: 6| Step: 5
Training loss: 2.209407329559326
Validation loss: 2.4282660202313493

Epoch: 6| Step: 6
Training loss: 2.496915817260742
Validation loss: 2.430334796187698

Epoch: 6| Step: 7
Training loss: 3.44038724899292
Validation loss: 2.440973994552448

Epoch: 6| Step: 8
Training loss: 2.814249038696289
Validation loss: 2.4484317174521824

Epoch: 6| Step: 9
Training loss: 2.4325668811798096
Validation loss: 2.4486375547224477

Epoch: 6| Step: 10
Training loss: 3.045290470123291
Validation loss: 2.4428190364632556

Epoch: 6| Step: 11
Training loss: 2.77099609375
Validation loss: 2.4360413474421345

Epoch: 6| Step: 12
Training loss: 2.263190746307373
Validation loss: 2.4440895152348343

Epoch: 6| Step: 13
Training loss: 2.548161745071411
Validation loss: 2.4252174131331907

Epoch: 190| Step: 0
Training loss: 2.6357150077819824
Validation loss: 2.425094312237155

Epoch: 6| Step: 1
Training loss: 2.4706010818481445
Validation loss: 2.4133482133188555

Epoch: 6| Step: 2
Training loss: 2.670259714126587
Validation loss: 2.411034640445504

Epoch: 6| Step: 3
Training loss: 3.381153106689453
Validation loss: 2.4140747234385502

Epoch: 6| Step: 4
Training loss: 2.971588134765625
Validation loss: 2.413142752903764

Epoch: 6| Step: 5
Training loss: 1.6698254346847534
Validation loss: 2.4156217344345583

Epoch: 6| Step: 6
Training loss: 1.8712589740753174
Validation loss: 2.408999796836607

Epoch: 6| Step: 7
Training loss: 2.6226470470428467
Validation loss: 2.4064589623481996

Epoch: 6| Step: 8
Training loss: 3.3771965503692627
Validation loss: 2.408447657862017

Epoch: 6| Step: 9
Training loss: 2.241285800933838
Validation loss: 2.407297275399649

Epoch: 6| Step: 10
Training loss: 3.874945640563965
Validation loss: 2.407370751903903

Epoch: 6| Step: 11
Training loss: 2.6029276847839355
Validation loss: 2.406288044427031

Epoch: 6| Step: 12
Training loss: 1.956139087677002
Validation loss: 2.411235245325232

Epoch: 6| Step: 13
Training loss: 2.268531560897827
Validation loss: 2.4108769714191394

Epoch: 191| Step: 0
Training loss: 2.322633743286133
Validation loss: 2.4112700852014686

Epoch: 6| Step: 1
Training loss: 3.1762242317199707
Validation loss: 2.4101576523114274

Epoch: 6| Step: 2
Training loss: 2.684633255004883
Validation loss: 2.424377936188893

Epoch: 6| Step: 3
Training loss: 2.2508716583251953
Validation loss: 2.4250266500698623

Epoch: 6| Step: 4
Training loss: 2.036365509033203
Validation loss: 2.427870117208009

Epoch: 6| Step: 5
Training loss: 3.208414077758789
Validation loss: 2.432387269953246

Epoch: 6| Step: 6
Training loss: 3.2076659202575684
Validation loss: 2.429108432544175

Epoch: 6| Step: 7
Training loss: 2.4887514114379883
Validation loss: 2.4235025144392446

Epoch: 6| Step: 8
Training loss: 2.3520383834838867
Validation loss: 2.4301007665613645

Epoch: 6| Step: 9
Training loss: 2.66086483001709
Validation loss: 2.4256338534816617

Epoch: 6| Step: 10
Training loss: 3.110158920288086
Validation loss: 2.420998386157456

Epoch: 6| Step: 11
Training loss: 2.5906882286071777
Validation loss: 2.418571302967687

Epoch: 6| Step: 12
Training loss: 2.474839210510254
Validation loss: 2.4207407812918387

Epoch: 6| Step: 13
Training loss: 1.7776892185211182
Validation loss: 2.4220259804879465

Epoch: 192| Step: 0
Training loss: 2.5241575241088867
Validation loss: 2.417825554006843

Epoch: 6| Step: 1
Training loss: 2.4445505142211914
Validation loss: 2.4200412534898326

Epoch: 6| Step: 2
Training loss: 2.430785894393921
Validation loss: 2.4223559902560328

Epoch: 6| Step: 3
Training loss: 3.261366367340088
Validation loss: 2.415300169298726

Epoch: 6| Step: 4
Training loss: 2.3539419174194336
Validation loss: 2.4096000361186203

Epoch: 6| Step: 5
Training loss: 3.678898572921753
Validation loss: 2.4121553641493603

Epoch: 6| Step: 6
Training loss: 2.426971435546875
Validation loss: 2.416154320522021

Epoch: 6| Step: 7
Training loss: 2.7561426162719727
Validation loss: 2.4095020755644767

Epoch: 6| Step: 8
Training loss: 2.6787121295928955
Validation loss: 2.412916084771515

Epoch: 6| Step: 9
Training loss: 2.226414442062378
Validation loss: 2.4170324135852117

Epoch: 6| Step: 10
Training loss: 1.9609330892562866
Validation loss: 2.42157054972905

Epoch: 6| Step: 11
Training loss: 2.7581136226654053
Validation loss: 2.416874160048782

Epoch: 6| Step: 12
Training loss: 2.8110334873199463
Validation loss: 2.4262367935590845

Epoch: 6| Step: 13
Training loss: 2.1882529258728027
Validation loss: 2.441856522713938

Epoch: 193| Step: 0
Training loss: 2.5710508823394775
Validation loss: 2.4403380091472338

Epoch: 6| Step: 1
Training loss: 3.2126762866973877
Validation loss: 2.44946103454918

Epoch: 6| Step: 2
Training loss: 2.5576369762420654
Validation loss: 2.4460156399716615

Epoch: 6| Step: 3
Training loss: 2.2572097778320312
Validation loss: 2.4451959210057415

Epoch: 6| Step: 4
Training loss: 2.540339708328247
Validation loss: 2.4456829691445954

Epoch: 6| Step: 5
Training loss: 2.4385061264038086
Validation loss: 2.437240057094123

Epoch: 6| Step: 6
Training loss: 1.9563407897949219
Validation loss: 2.4307791648372525

Epoch: 6| Step: 7
Training loss: 2.39414644241333
Validation loss: 2.421352317256312

Epoch: 6| Step: 8
Training loss: 3.3688011169433594
Validation loss: 2.416100998078623

Epoch: 6| Step: 9
Training loss: 2.3791418075561523
Validation loss: 2.4159541463339202

Epoch: 6| Step: 10
Training loss: 2.907413959503174
Validation loss: 2.4031829782711562

Epoch: 6| Step: 11
Training loss: 2.5613765716552734
Validation loss: 2.4051522977890505

Epoch: 6| Step: 12
Training loss: 2.066624879837036
Validation loss: 2.4021401610425723

Epoch: 6| Step: 13
Training loss: 4.188239574432373
Validation loss: 2.3916392839083107

Epoch: 194| Step: 0
Training loss: 3.0712335109710693
Validation loss: 2.392044731365737

Epoch: 6| Step: 1
Training loss: 3.5580708980560303
Validation loss: 2.392855639098793

Epoch: 6| Step: 2
Training loss: 2.9511115550994873
Validation loss: 2.3961121677070536

Epoch: 6| Step: 3
Training loss: 1.9296424388885498
Validation loss: 2.394741245495376

Epoch: 6| Step: 4
Training loss: 3.4262681007385254
Validation loss: 2.3947755623889226

Epoch: 6| Step: 5
Training loss: 2.7332987785339355
Validation loss: 2.3961715852060625

Epoch: 6| Step: 6
Training loss: 2.9227194786071777
Validation loss: 2.395469670654625

Epoch: 6| Step: 7
Training loss: 2.306443214416504
Validation loss: 2.397474337649602

Epoch: 6| Step: 8
Training loss: 2.0953850746154785
Validation loss: 2.394552702544838

Epoch: 6| Step: 9
Training loss: 2.0578107833862305
Validation loss: 2.3982911417561192

Epoch: 6| Step: 10
Training loss: 2.5560598373413086
Validation loss: 2.3962802630598827

Epoch: 6| Step: 11
Training loss: 2.6914286613464355
Validation loss: 2.397289717069236

Epoch: 6| Step: 12
Training loss: 1.8377251625061035
Validation loss: 2.3994014493880735

Epoch: 6| Step: 13
Training loss: 2.2779786586761475
Validation loss: 2.4076255316375406

Epoch: 195| Step: 0
Training loss: 2.606339454650879
Validation loss: 2.4145233028678486

Epoch: 6| Step: 1
Training loss: 3.0959811210632324
Validation loss: 2.4194487679389214

Epoch: 6| Step: 2
Training loss: 2.225416660308838
Validation loss: 2.4249149086654826

Epoch: 6| Step: 3
Training loss: 2.298680543899536
Validation loss: 2.4347760831156084

Epoch: 6| Step: 4
Training loss: 2.5476346015930176
Validation loss: 2.4309219288569626

Epoch: 6| Step: 5
Training loss: 2.0844078063964844
Validation loss: 2.430253972289383

Epoch: 6| Step: 6
Training loss: 3.0396766662597656
Validation loss: 2.42867640654246

Epoch: 6| Step: 7
Training loss: 2.8214006423950195
Validation loss: 2.4296927503360215

Epoch: 6| Step: 8
Training loss: 3.346712589263916
Validation loss: 2.4191893582702964

Epoch: 6| Step: 9
Training loss: 2.2411837577819824
Validation loss: 2.41350112166456

Epoch: 6| Step: 10
Training loss: 2.396024465560913
Validation loss: 2.4037126956447477

Epoch: 6| Step: 11
Training loss: 2.6726160049438477
Validation loss: 2.3991839193528697

Epoch: 6| Step: 12
Training loss: 2.4812099933624268
Validation loss: 2.4039318971736456

Epoch: 6| Step: 13
Training loss: 2.729668617248535
Validation loss: 2.3993753771628104

Epoch: 196| Step: 0
Training loss: 2.578645706176758
Validation loss: 2.3977036681226505

Epoch: 6| Step: 1
Training loss: 2.4901480674743652
Validation loss: 2.4012274793399278

Epoch: 6| Step: 2
Training loss: 2.061617612838745
Validation loss: 2.399920117470526

Epoch: 6| Step: 3
Training loss: 2.4074978828430176
Validation loss: 2.39818670416391

Epoch: 6| Step: 4
Training loss: 2.8870668411254883
Validation loss: 2.401239251577726

Epoch: 6| Step: 5
Training loss: 2.7798585891723633
Validation loss: 2.402027699255174

Epoch: 6| Step: 6
Training loss: 2.4508512020111084
Validation loss: 2.403592309644145

Epoch: 6| Step: 7
Training loss: 2.9077818393707275
Validation loss: 2.407001177469889

Epoch: 6| Step: 8
Training loss: 2.8746047019958496
Validation loss: 2.395449048729353

Epoch: 6| Step: 9
Training loss: 2.2300095558166504
Validation loss: 2.398115937427808

Epoch: 6| Step: 10
Training loss: 2.923975706100464
Validation loss: 2.3985581628737913

Epoch: 6| Step: 11
Training loss: 2.916959285736084
Validation loss: 2.394220571364126

Epoch: 6| Step: 12
Training loss: 2.5641567707061768
Validation loss: 2.3922257884856193

Epoch: 6| Step: 13
Training loss: 2.627668857574463
Validation loss: 2.3923470294603737

Epoch: 197| Step: 0
Training loss: 2.829164505004883
Validation loss: 2.387090172818912

Epoch: 6| Step: 1
Training loss: 2.448533058166504
Validation loss: 2.391212435178859

Epoch: 6| Step: 2
Training loss: 2.5365724563598633
Validation loss: 2.3890139364427134

Epoch: 6| Step: 3
Training loss: 3.0855629444122314
Validation loss: 2.395320530860655

Epoch: 6| Step: 4
Training loss: 1.817034363746643
Validation loss: 2.393436339593703

Epoch: 6| Step: 5
Training loss: 3.316019296646118
Validation loss: 2.399132582449144

Epoch: 6| Step: 6
Training loss: 2.615267753601074
Validation loss: 2.4037093629119215

Epoch: 6| Step: 7
Training loss: 2.9033498764038086
Validation loss: 2.4015392180412047

Epoch: 6| Step: 8
Training loss: 2.3199281692504883
Validation loss: 2.4182136674081125

Epoch: 6| Step: 9
Training loss: 1.857891321182251
Validation loss: 2.410603400199644

Epoch: 6| Step: 10
Training loss: 2.8576836585998535
Validation loss: 2.4143027400457733

Epoch: 6| Step: 11
Training loss: 3.045429229736328
Validation loss: 2.4043486836136028

Epoch: 6| Step: 12
Training loss: 2.0288455486297607
Validation loss: 2.404128113100606

Epoch: 6| Step: 13
Training loss: 3.091390371322632
Validation loss: 2.400537265244351

Epoch: 198| Step: 0
Training loss: 2.5686004161834717
Validation loss: 2.3965747792233705

Epoch: 6| Step: 1
Training loss: 2.390458822250366
Validation loss: 2.3934728317363287

Epoch: 6| Step: 2
Training loss: 2.4953653812408447
Validation loss: 2.4003832929877826

Epoch: 6| Step: 3
Training loss: 2.6535091400146484
Validation loss: 2.4025833273446686

Epoch: 6| Step: 4
Training loss: 2.7364912033081055
Validation loss: 2.4002748048433693

Epoch: 6| Step: 5
Training loss: 2.0001425743103027
Validation loss: 2.40151039759318

Epoch: 6| Step: 6
Training loss: 3.113956928253174
Validation loss: 2.398377340327027

Epoch: 6| Step: 7
Training loss: 2.8124756813049316
Validation loss: 2.4007189196925007

Epoch: 6| Step: 8
Training loss: 3.254833698272705
Validation loss: 2.4022401737910446

Epoch: 6| Step: 9
Training loss: 2.4936277866363525
Validation loss: 2.4041612814831477

Epoch: 6| Step: 10
Training loss: 2.152164936065674
Validation loss: 2.4059880215634584

Epoch: 6| Step: 11
Training loss: 2.6905298233032227
Validation loss: 2.404031615103445

Epoch: 6| Step: 12
Training loss: 2.512364387512207
Validation loss: 2.3968722384463073

Epoch: 6| Step: 13
Training loss: 2.7057719230651855
Validation loss: 2.3969667726947415

Epoch: 199| Step: 0
Training loss: 2.2370777130126953
Validation loss: 2.399133431014194

Epoch: 6| Step: 1
Training loss: 2.621943950653076
Validation loss: 2.405508710492042

Epoch: 6| Step: 2
Training loss: 3.092867374420166
Validation loss: 2.4124055165116505

Epoch: 6| Step: 3
Training loss: 2.8844902515411377
Validation loss: 2.410267073621032

Epoch: 6| Step: 4
Training loss: 3.1036248207092285
Validation loss: 2.412227922870267

Epoch: 6| Step: 5
Training loss: 3.021430492401123
Validation loss: 2.409434897925264

Epoch: 6| Step: 6
Training loss: 3.0391640663146973
Validation loss: 2.411856710269887

Epoch: 6| Step: 7
Training loss: 2.207151174545288
Validation loss: 2.416201801710231

Epoch: 6| Step: 8
Training loss: 2.8899059295654297
Validation loss: 2.4155003229777017

Epoch: 6| Step: 9
Training loss: 2.633643627166748
Validation loss: 2.40825302626497

Epoch: 6| Step: 10
Training loss: 1.787410020828247
Validation loss: 2.405583873871834

Epoch: 6| Step: 11
Training loss: 2.074457883834839
Validation loss: 2.402468289098432

Epoch: 6| Step: 12
Training loss: 2.1878275871276855
Validation loss: 2.4128790824644026

Epoch: 6| Step: 13
Training loss: 2.82643461227417
Validation loss: 2.4038310845692954

Epoch: 200| Step: 0
Training loss: 2.267317533493042
Validation loss: 2.4042554158036427

Epoch: 6| Step: 1
Training loss: 2.613699197769165
Validation loss: 2.404687471287225

Epoch: 6| Step: 2
Training loss: 2.64254093170166
Validation loss: 2.399072313821444

Epoch: 6| Step: 3
Training loss: 2.7434492111206055
Validation loss: 2.4011597812816663

Epoch: 6| Step: 4
Training loss: 1.9600292444229126
Validation loss: 2.404030981884208

Epoch: 6| Step: 5
Training loss: 3.4926772117614746
Validation loss: 2.3966349401781635

Epoch: 6| Step: 6
Training loss: 2.897254705429077
Validation loss: 2.4003081501171155

Epoch: 6| Step: 7
Training loss: 2.8800556659698486
Validation loss: 2.3873124917348227

Epoch: 6| Step: 8
Training loss: 1.5772459506988525
Validation loss: 2.3905766702467397

Epoch: 6| Step: 9
Training loss: 2.2126994132995605
Validation loss: 2.3910007220442577

Epoch: 6| Step: 10
Training loss: 2.3541793823242188
Validation loss: 2.387804885064402

Epoch: 6| Step: 11
Training loss: 2.9437594413757324
Validation loss: 2.39565699074858

Epoch: 6| Step: 12
Training loss: 2.906515598297119
Validation loss: 2.395928495673723

Epoch: 6| Step: 13
Training loss: 3.1545114517211914
Validation loss: 2.399123235415387

Epoch: 201| Step: 0
Training loss: 2.801380157470703
Validation loss: 2.398181979374219

Epoch: 6| Step: 1
Training loss: 1.900594711303711
Validation loss: 2.4050835614563315

Epoch: 6| Step: 2
Training loss: 3.3416504859924316
Validation loss: 2.4057745959169123

Epoch: 6| Step: 3
Training loss: 2.4681224822998047
Validation loss: 2.4122197448566394

Epoch: 6| Step: 4
Training loss: 2.506810188293457
Validation loss: 2.416990121205648

Epoch: 6| Step: 5
Training loss: 2.382039785385132
Validation loss: 2.4198762960331415

Epoch: 6| Step: 6
Training loss: 2.874544620513916
Validation loss: 2.415604575987785

Epoch: 6| Step: 7
Training loss: 3.203218460083008
Validation loss: 2.419137700911491

Epoch: 6| Step: 8
Training loss: 2.090590476989746
Validation loss: 2.413984678124869

Epoch: 6| Step: 9
Training loss: 3.627894878387451
Validation loss: 2.415607221664921

Epoch: 6| Step: 10
Training loss: 2.1807594299316406
Validation loss: 2.407509716608191

Epoch: 6| Step: 11
Training loss: 2.4535534381866455
Validation loss: 2.403974458735476

Epoch: 6| Step: 12
Training loss: 2.5190212726593018
Validation loss: 2.397203378779914

Epoch: 6| Step: 13
Training loss: 1.7950373888015747
Validation loss: 2.3934087214931363

Epoch: 202| Step: 0
Training loss: 2.5825438499450684
Validation loss: 2.3967741227919057

Epoch: 6| Step: 1
Training loss: 2.891752243041992
Validation loss: 2.3993116271111274

Epoch: 6| Step: 2
Training loss: 2.5367181301116943
Validation loss: 2.3902808209901214

Epoch: 6| Step: 3
Training loss: 2.186612129211426
Validation loss: 2.394256232887186

Epoch: 6| Step: 4
Training loss: 2.746011257171631
Validation loss: 2.3877525380862656

Epoch: 6| Step: 5
Training loss: 3.1278319358825684
Validation loss: 2.3852739359742854

Epoch: 6| Step: 6
Training loss: 2.650869846343994
Validation loss: 2.385221669750829

Epoch: 6| Step: 7
Training loss: 2.83589768409729
Validation loss: 2.397900217322893

Epoch: 6| Step: 8
Training loss: 3.029534339904785
Validation loss: 2.402488144495154

Epoch: 6| Step: 9
Training loss: 2.592038154602051
Validation loss: 2.403832712481099

Epoch: 6| Step: 10
Training loss: 2.4914710521698
Validation loss: 2.413751120208412

Epoch: 6| Step: 11
Training loss: 2.753974437713623
Validation loss: 2.4048215368742585

Epoch: 6| Step: 12
Training loss: 2.1516106128692627
Validation loss: 2.410549271491266

Epoch: 6| Step: 13
Training loss: 1.4741710424423218
Validation loss: 2.4020967355338474

Epoch: 203| Step: 0
Training loss: 2.6083433628082275
Validation loss: 2.406142747530373

Epoch: 6| Step: 1
Training loss: 2.3086800575256348
Validation loss: 2.414801007957869

Epoch: 6| Step: 2
Training loss: 2.8633174896240234
Validation loss: 2.423198744814883

Epoch: 6| Step: 3
Training loss: 2.9413962364196777
Validation loss: 2.4219736386370916

Epoch: 6| Step: 4
Training loss: 2.5970993041992188
Validation loss: 2.4276790875260548

Epoch: 6| Step: 5
Training loss: 2.8026018142700195
Validation loss: 2.4155338579608547

Epoch: 6| Step: 6
Training loss: 2.9621665477752686
Validation loss: 2.4057876371568248

Epoch: 6| Step: 7
Training loss: 1.8050057888031006
Validation loss: 2.417786184177604

Epoch: 6| Step: 8
Training loss: 2.8788037300109863
Validation loss: 2.4184463588140344

Epoch: 6| Step: 9
Training loss: 3.0305933952331543
Validation loss: 2.4115875562032065

Epoch: 6| Step: 10
Training loss: 2.339250087738037
Validation loss: 2.4123388618551274

Epoch: 6| Step: 11
Training loss: 2.520991563796997
Validation loss: 2.41078540073928

Epoch: 6| Step: 12
Training loss: 2.5503170490264893
Validation loss: 2.4020995555385465

Epoch: 6| Step: 13
Training loss: 1.9800022840499878
Validation loss: 2.4018993890413673

Epoch: 204| Step: 0
Training loss: 2.074749231338501
Validation loss: 2.4061963250560146

Epoch: 6| Step: 1
Training loss: 2.979933500289917
Validation loss: 2.407081124603107

Epoch: 6| Step: 2
Training loss: 3.8982529640197754
Validation loss: 2.40690638044829

Epoch: 6| Step: 3
Training loss: 2.338285446166992
Validation loss: 2.4062828684365876

Epoch: 6| Step: 4
Training loss: 2.268756151199341
Validation loss: 2.404549962730818

Epoch: 6| Step: 5
Training loss: 2.3350844383239746
Validation loss: 2.398266291105619

Epoch: 6| Step: 6
Training loss: 2.248626947402954
Validation loss: 2.403241454914052

Epoch: 6| Step: 7
Training loss: 2.847080945968628
Validation loss: 2.4096362872790267

Epoch: 6| Step: 8
Training loss: 2.905661106109619
Validation loss: 2.4113438052515828

Epoch: 6| Step: 9
Training loss: 1.75999116897583
Validation loss: 2.406082260993219

Epoch: 6| Step: 10
Training loss: 3.11136531829834
Validation loss: 2.4112704159111105

Epoch: 6| Step: 11
Training loss: 2.697676658630371
Validation loss: 2.39600714560478

Epoch: 6| Step: 12
Training loss: 2.196388006210327
Validation loss: 2.400866993011967

Epoch: 6| Step: 13
Training loss: 2.9042978286743164
Validation loss: 2.3922583646671747

Epoch: 205| Step: 0
Training loss: 2.203108310699463
Validation loss: 2.3905297915140786

Epoch: 6| Step: 1
Training loss: 2.8004860877990723
Validation loss: 2.383545785821894

Epoch: 6| Step: 2
Training loss: 2.508314371109009
Validation loss: 2.3935891479574223

Epoch: 6| Step: 3
Training loss: 1.95366370677948
Validation loss: 2.392420494428245

Epoch: 6| Step: 4
Training loss: 2.2157013416290283
Validation loss: 2.388634499683175

Epoch: 6| Step: 5
Training loss: 2.4625637531280518
Validation loss: 2.3884444570028656

Epoch: 6| Step: 6
Training loss: 3.2046003341674805
Validation loss: 2.3908851249243623

Epoch: 6| Step: 7
Training loss: 3.0452961921691895
Validation loss: 2.3800642387841338

Epoch: 6| Step: 8
Training loss: 1.8367830514907837
Validation loss: 2.389862932184691

Epoch: 6| Step: 9
Training loss: 2.963578224182129
Validation loss: 2.3891271827041463

Epoch: 6| Step: 10
Training loss: 2.4492404460906982
Validation loss: 2.3966044713092107

Epoch: 6| Step: 11
Training loss: 2.939730167388916
Validation loss: 2.400107201709542

Epoch: 6| Step: 12
Training loss: 3.576812267303467
Validation loss: 2.405391126550654

Epoch: 6| Step: 13
Training loss: 1.9534478187561035
Validation loss: 2.4176814351030576

Epoch: 206| Step: 0
Training loss: 2.4295525550842285
Validation loss: 2.4129835841476277

Epoch: 6| Step: 1
Training loss: 2.802917957305908
Validation loss: 2.420447313657371

Epoch: 6| Step: 2
Training loss: 2.5702085494995117
Validation loss: 2.4106559407326484

Epoch: 6| Step: 3
Training loss: 2.4630067348480225
Validation loss: 2.4078165356830885

Epoch: 6| Step: 4
Training loss: 2.807570457458496
Validation loss: 2.395048474752775

Epoch: 6| Step: 5
Training loss: 3.3476333618164062
Validation loss: 2.3885858879294446

Epoch: 6| Step: 6
Training loss: 2.325721502304077
Validation loss: 2.3813485330150974

Epoch: 6| Step: 7
Training loss: 2.3147060871124268
Validation loss: 2.3793490317560013

Epoch: 6| Step: 8
Training loss: 2.8796658515930176
Validation loss: 2.377396047756236

Epoch: 6| Step: 9
Training loss: 1.8632121086120605
Validation loss: 2.376281287080498

Epoch: 6| Step: 10
Training loss: 2.7895314693450928
Validation loss: 2.3863620578601794

Epoch: 6| Step: 11
Training loss: 2.6479012966156006
Validation loss: 2.381596542173816

Epoch: 6| Step: 12
Training loss: 2.91139817237854
Validation loss: 2.385737826747279

Epoch: 6| Step: 13
Training loss: 2.044036626815796
Validation loss: 2.3848323552839217

Epoch: 207| Step: 0
Training loss: 3.2083184719085693
Validation loss: 2.3843071178723405

Epoch: 6| Step: 1
Training loss: 3.111785650253296
Validation loss: 2.3835873014183453

Epoch: 6| Step: 2
Training loss: 2.53682541847229
Validation loss: 2.380435787221437

Epoch: 6| Step: 3
Training loss: 2.516904354095459
Validation loss: 2.3877534251059256

Epoch: 6| Step: 4
Training loss: 2.223299026489258
Validation loss: 2.3826118002655687

Epoch: 6| Step: 5
Training loss: 2.28839111328125
Validation loss: 2.3917850858421734

Epoch: 6| Step: 6
Training loss: 2.816718339920044
Validation loss: 2.3861517880552556

Epoch: 6| Step: 7
Training loss: 2.6302618980407715
Validation loss: 2.390635677563247

Epoch: 6| Step: 8
Training loss: 3.114476442337036
Validation loss: 2.4026060335097776

Epoch: 6| Step: 9
Training loss: 2.5955519676208496
Validation loss: 2.400394347406203

Epoch: 6| Step: 10
Training loss: 2.259406566619873
Validation loss: 2.3960251449256815

Epoch: 6| Step: 11
Training loss: 2.3084521293640137
Validation loss: 2.399796624337473

Epoch: 6| Step: 12
Training loss: 2.128528356552124
Validation loss: 2.4022789898739068

Epoch: 6| Step: 13
Training loss: 2.5868709087371826
Validation loss: 2.395778750860563

Epoch: 208| Step: 0
Training loss: 2.6983563899993896
Validation loss: 2.3942921059105986

Epoch: 6| Step: 1
Training loss: 2.232736587524414
Validation loss: 2.397906785370201

Epoch: 6| Step: 2
Training loss: 2.180817127227783
Validation loss: 2.391487726601221

Epoch: 6| Step: 3
Training loss: 2.6273703575134277
Validation loss: 2.395302757140129

Epoch: 6| Step: 4
Training loss: 2.519965887069702
Validation loss: 2.3938694897518364

Epoch: 6| Step: 5
Training loss: 2.961076259613037
Validation loss: 2.3879096559298936

Epoch: 6| Step: 6
Training loss: 2.4723305702209473
Validation loss: 2.3880956249852336

Epoch: 6| Step: 7
Training loss: 2.745370864868164
Validation loss: 2.368969896788238

Epoch: 6| Step: 8
Training loss: 2.2911508083343506
Validation loss: 2.3782025485910396

Epoch: 6| Step: 9
Training loss: 2.02718186378479
Validation loss: 2.3803172008965605

Epoch: 6| Step: 10
Training loss: 2.9976253509521484
Validation loss: 2.377662807382563

Epoch: 6| Step: 11
Training loss: 2.9688944816589355
Validation loss: 2.374311529180055

Epoch: 6| Step: 12
Training loss: 3.1913580894470215
Validation loss: 2.372265402988721

Epoch: 6| Step: 13
Training loss: 2.413882255554199
Validation loss: 2.375113021942877

Epoch: 209| Step: 0
Training loss: 2.727083683013916
Validation loss: 2.379344645366874

Epoch: 6| Step: 1
Training loss: 3.15710186958313
Validation loss: 2.3746849670205066

Epoch: 6| Step: 2
Training loss: 2.205785036087036
Validation loss: 2.3760086669716785

Epoch: 6| Step: 3
Training loss: 2.5411319732666016
Validation loss: 2.3777645198247765

Epoch: 6| Step: 4
Training loss: 2.6061058044433594
Validation loss: 2.3778154004004692

Epoch: 6| Step: 5
Training loss: 2.6261324882507324
Validation loss: 2.387728060445478

Epoch: 6| Step: 6
Training loss: 2.5747973918914795
Validation loss: 2.385295260337091

Epoch: 6| Step: 7
Training loss: 2.6550405025482178
Validation loss: 2.390387655586325

Epoch: 6| Step: 8
Training loss: 2.3866677284240723
Validation loss: 2.3978776701035036

Epoch: 6| Step: 9
Training loss: 2.3766183853149414
Validation loss: 2.406016247246855

Epoch: 6| Step: 10
Training loss: 3.1027753353118896
Validation loss: 2.395999748219726

Epoch: 6| Step: 11
Training loss: 2.302539348602295
Validation loss: 2.4094865117021786

Epoch: 6| Step: 12
Training loss: 2.828885078430176
Validation loss: 2.3965940424191055

Epoch: 6| Step: 13
Training loss: 1.884412169456482
Validation loss: 2.3938949697761127

Epoch: 210| Step: 0
Training loss: 2.590907573699951
Validation loss: 2.3872755445459837

Epoch: 6| Step: 1
Training loss: 2.674999237060547
Validation loss: 2.386801068500806

Epoch: 6| Step: 2
Training loss: 3.1694488525390625
Validation loss: 2.390787878344136

Epoch: 6| Step: 3
Training loss: 2.6323978900909424
Validation loss: 2.3968551902360815

Epoch: 6| Step: 4
Training loss: 2.6786956787109375
Validation loss: 2.3876885034704722

Epoch: 6| Step: 5
Training loss: 2.606718063354492
Validation loss: 2.382858168694281

Epoch: 6| Step: 6
Training loss: 3.336996555328369
Validation loss: 2.387398391641596

Epoch: 6| Step: 7
Training loss: 2.2714412212371826
Validation loss: 2.3823902299327235

Epoch: 6| Step: 8
Training loss: 1.9480128288269043
Validation loss: 2.3819405468561317

Epoch: 6| Step: 9
Training loss: 2.2457170486450195
Validation loss: 2.3763813972473145

Epoch: 6| Step: 10
Training loss: 2.8883748054504395
Validation loss: 2.3764622083274265

Epoch: 6| Step: 11
Training loss: 3.1247549057006836
Validation loss: 2.376968317134406

Epoch: 6| Step: 12
Training loss: 2.0645499229431152
Validation loss: 2.3752595814325477

Epoch: 6| Step: 13
Training loss: 1.6549474000930786
Validation loss: 2.3792133920936176

Epoch: 211| Step: 0
Training loss: 1.8696002960205078
Validation loss: 2.3803826506419847

Epoch: 6| Step: 1
Training loss: 1.730475664138794
Validation loss: 2.3814697163079375

Epoch: 6| Step: 2
Training loss: 2.589326858520508
Validation loss: 2.383619054671257

Epoch: 6| Step: 3
Training loss: 3.3829193115234375
Validation loss: 2.3915982861672678

Epoch: 6| Step: 4
Training loss: 2.486884593963623
Validation loss: 2.39672988717274

Epoch: 6| Step: 5
Training loss: 3.0622944831848145
Validation loss: 2.3905105052455777

Epoch: 6| Step: 6
Training loss: 2.7154130935668945
Validation loss: 2.3901525543582056

Epoch: 6| Step: 7
Training loss: 1.9561418294906616
Validation loss: 2.3818404161801903

Epoch: 6| Step: 8
Training loss: 2.1050634384155273
Validation loss: 2.3742797682362218

Epoch: 6| Step: 9
Training loss: 2.1145124435424805
Validation loss: 2.384741014049899

Epoch: 6| Step: 10
Training loss: 3.24993896484375
Validation loss: 2.385619701877717

Epoch: 6| Step: 11
Training loss: 2.7947030067443848
Validation loss: 2.3723446271752797

Epoch: 6| Step: 12
Training loss: 3.10451602935791
Validation loss: 2.3889894690564883

Epoch: 6| Step: 13
Training loss: 3.60546612739563
Validation loss: 2.3901561921642673

Epoch: 212| Step: 0
Training loss: 2.5645875930786133
Validation loss: 2.379306572739796

Epoch: 6| Step: 1
Training loss: 3.4364943504333496
Validation loss: 2.3792682809214436

Epoch: 6| Step: 2
Training loss: 3.0013649463653564
Validation loss: 2.3771839372573362

Epoch: 6| Step: 3
Training loss: 2.175518035888672
Validation loss: 2.3799969944902646

Epoch: 6| Step: 4
Training loss: 2.3146419525146484
Validation loss: 2.3795369799419115

Epoch: 6| Step: 5
Training loss: 1.8014817237854004
Validation loss: 2.3843124502448627

Epoch: 6| Step: 6
Training loss: 2.1627492904663086
Validation loss: 2.377860915276312

Epoch: 6| Step: 7
Training loss: 1.839416265487671
Validation loss: 2.382285779522311

Epoch: 6| Step: 8
Training loss: 2.320124626159668
Validation loss: 2.3866671644231325

Epoch: 6| Step: 9
Training loss: 3.0352118015289307
Validation loss: 2.3955377224952943

Epoch: 6| Step: 10
Training loss: 2.987438678741455
Validation loss: 2.4115679238432195

Epoch: 6| Step: 11
Training loss: 2.825681209564209
Validation loss: 2.4070774714152017

Epoch: 6| Step: 12
Training loss: 3.0588722229003906
Validation loss: 2.429276548406129

Epoch: 6| Step: 13
Training loss: 2.88210391998291
Validation loss: 2.4500154526002946

Epoch: 213| Step: 0
Training loss: 2.5074307918548584
Validation loss: 2.4333658551657074

Epoch: 6| Step: 1
Training loss: 2.1913466453552246
Validation loss: 2.417805035909017

Epoch: 6| Step: 2
Training loss: 3.028085231781006
Validation loss: 2.409121844076341

Epoch: 6| Step: 3
Training loss: 2.2330307960510254
Validation loss: 2.401994187344787

Epoch: 6| Step: 4
Training loss: 2.197204113006592
Validation loss: 2.392333020446121

Epoch: 6| Step: 5
Training loss: 2.358725070953369
Validation loss: 2.3816015335821334

Epoch: 6| Step: 6
Training loss: 2.5108840465545654
Validation loss: 2.3789202500415105

Epoch: 6| Step: 7
Training loss: 2.489867925643921
Validation loss: 2.3880365458867883

Epoch: 6| Step: 8
Training loss: 2.8294625282287598
Validation loss: 2.386032137819516

Epoch: 6| Step: 9
Training loss: 3.0216307640075684
Validation loss: 2.385860845606814

Epoch: 6| Step: 10
Training loss: 2.6379027366638184
Validation loss: 2.3856375153346727

Epoch: 6| Step: 11
Training loss: 2.634549617767334
Validation loss: 2.3812335024597826

Epoch: 6| Step: 12
Training loss: 2.8090946674346924
Validation loss: 2.385814893630243

Epoch: 6| Step: 13
Training loss: 3.1653287410736084
Validation loss: 2.3853702263165544

Epoch: 214| Step: 0
Training loss: 2.7665228843688965
Validation loss: 2.384732013107628

Epoch: 6| Step: 1
Training loss: 2.6356430053710938
Validation loss: 2.381224680972356

Epoch: 6| Step: 2
Training loss: 2.8019652366638184
Validation loss: 2.378925438850157

Epoch: 6| Step: 3
Training loss: 2.5947718620300293
Validation loss: 2.3817037766979587

Epoch: 6| Step: 4
Training loss: 2.619852304458618
Validation loss: 2.388345218473865

Epoch: 6| Step: 5
Training loss: 1.836346983909607
Validation loss: 2.3879089406741563

Epoch: 6| Step: 6
Training loss: 2.5630314350128174
Validation loss: 2.398820043891989

Epoch: 6| Step: 7
Training loss: 2.0351080894470215
Validation loss: 2.407925710883192

Epoch: 6| Step: 8
Training loss: 3.0985491275787354
Validation loss: 2.4331230194337907

Epoch: 6| Step: 9
Training loss: 2.8287482261657715
Validation loss: 2.438860608685401

Epoch: 6| Step: 10
Training loss: 3.053557872772217
Validation loss: 2.4295287260445217

Epoch: 6| Step: 11
Training loss: 2.739961624145508
Validation loss: 2.42476583808981

Epoch: 6| Step: 12
Training loss: 2.3451967239379883
Validation loss: 2.405025520632344

Epoch: 6| Step: 13
Training loss: 2.358715295791626
Validation loss: 2.3973983564684467

Epoch: 215| Step: 0
Training loss: 2.8461742401123047
Validation loss: 2.397363449937554

Epoch: 6| Step: 1
Training loss: 1.776773452758789
Validation loss: 2.382437931594028

Epoch: 6| Step: 2
Training loss: 2.4528071880340576
Validation loss: 2.388852693701303

Epoch: 6| Step: 3
Training loss: 3.676804780960083
Validation loss: 2.384694878773023

Epoch: 6| Step: 4
Training loss: 2.850863218307495
Validation loss: 2.38161229061824

Epoch: 6| Step: 5
Training loss: 2.388435125350952
Validation loss: 2.371613512757004

Epoch: 6| Step: 6
Training loss: 2.8253695964813232
Validation loss: 2.3746476096491658

Epoch: 6| Step: 7
Training loss: 2.643789529800415
Validation loss: 2.373245088003015

Epoch: 6| Step: 8
Training loss: 2.6197192668914795
Validation loss: 2.3736367917829946

Epoch: 6| Step: 9
Training loss: 2.2662174701690674
Validation loss: 2.368469137017445

Epoch: 6| Step: 10
Training loss: 2.1624300479888916
Validation loss: 2.3762048111167005

Epoch: 6| Step: 11
Training loss: 1.8321473598480225
Validation loss: 2.3746291847639185

Epoch: 6| Step: 12
Training loss: 3.1899590492248535
Validation loss: 2.3781628095975487

Epoch: 6| Step: 13
Training loss: 2.6865358352661133
Validation loss: 2.3807655842073503

Epoch: 216| Step: 0
Training loss: 3.7699296474456787
Validation loss: 2.374921929451727

Epoch: 6| Step: 1
Training loss: 1.664189338684082
Validation loss: 2.3727295193620908

Epoch: 6| Step: 2
Training loss: 2.784517288208008
Validation loss: 2.3620542313462947

Epoch: 6| Step: 3
Training loss: 3.190585136413574
Validation loss: 2.3603435126684045

Epoch: 6| Step: 4
Training loss: 3.173680305480957
Validation loss: 2.3585621490273425

Epoch: 6| Step: 5
Training loss: 2.158013343811035
Validation loss: 2.3576895242096274

Epoch: 6| Step: 6
Training loss: 2.7871453762054443
Validation loss: 2.3613006555905907

Epoch: 6| Step: 7
Training loss: 1.9509059190750122
Validation loss: 2.359011188630135

Epoch: 6| Step: 8
Training loss: 1.4576082229614258
Validation loss: 2.3621781179981847

Epoch: 6| Step: 9
Training loss: 3.1489903926849365
Validation loss: 2.3607392131641345

Epoch: 6| Step: 10
Training loss: 3.0535640716552734
Validation loss: 2.3634103293059976

Epoch: 6| Step: 11
Training loss: 2.1081085205078125
Validation loss: 2.368369528042373

Epoch: 6| Step: 12
Training loss: 2.815349578857422
Validation loss: 2.3675524265535417

Epoch: 6| Step: 13
Training loss: 1.6806949377059937
Validation loss: 2.3798389229723202

Epoch: 217| Step: 0
Training loss: 2.2634291648864746
Validation loss: 2.386181310940814

Epoch: 6| Step: 1
Training loss: 2.1228206157684326
Validation loss: 2.386580090368948

Epoch: 6| Step: 2
Training loss: 2.5555882453918457
Validation loss: 2.388746110341882

Epoch: 6| Step: 3
Training loss: 2.968078374862671
Validation loss: 2.3819112316254647

Epoch: 6| Step: 4
Training loss: 2.810412883758545
Validation loss: 2.383359201492802

Epoch: 6| Step: 5
Training loss: 2.8891847133636475
Validation loss: 2.3824683555992703

Epoch: 6| Step: 6
Training loss: 3.3482470512390137
Validation loss: 2.3839097099919475

Epoch: 6| Step: 7
Training loss: 2.877622127532959
Validation loss: 2.3836012399324806

Epoch: 6| Step: 8
Training loss: 2.011342763900757
Validation loss: 2.3759948310031684

Epoch: 6| Step: 9
Training loss: 2.2279300689697266
Validation loss: 2.375991336760982

Epoch: 6| Step: 10
Training loss: 3.1981215476989746
Validation loss: 2.374301036198934

Epoch: 6| Step: 11
Training loss: 1.8079739809036255
Validation loss: 2.373392807540073

Epoch: 6| Step: 12
Training loss: 2.392808675765991
Validation loss: 2.38185041950595

Epoch: 6| Step: 13
Training loss: 2.8243908882141113
Validation loss: 2.378717714740384

Epoch: 218| Step: 0
Training loss: 3.3172121047973633
Validation loss: 2.372391075216314

Epoch: 6| Step: 1
Training loss: 1.9481580257415771
Validation loss: 2.3746580718665995

Epoch: 6| Step: 2
Training loss: 2.106065034866333
Validation loss: 2.3700576392553185

Epoch: 6| Step: 3
Training loss: 2.1419525146484375
Validation loss: 2.3676394980440856

Epoch: 6| Step: 4
Training loss: 2.432551145553589
Validation loss: 2.37815958710127

Epoch: 6| Step: 5
Training loss: 2.5113534927368164
Validation loss: 2.3795053523073912

Epoch: 6| Step: 6
Training loss: 2.5326321125030518
Validation loss: 2.3906024886715795

Epoch: 6| Step: 7
Training loss: 2.776343822479248
Validation loss: 2.4024923693749214

Epoch: 6| Step: 8
Training loss: 2.9597253799438477
Validation loss: 2.4063634641708864

Epoch: 6| Step: 9
Training loss: 1.944583773612976
Validation loss: 2.408995715520715

Epoch: 6| Step: 10
Training loss: 3.1845173835754395
Validation loss: 2.397175147969236

Epoch: 6| Step: 11
Training loss: 3.072726249694824
Validation loss: 2.385694847312025

Epoch: 6| Step: 12
Training loss: 3.102414131164551
Validation loss: 2.3818576771725892

Epoch: 6| Step: 13
Training loss: 1.921873927116394
Validation loss: 2.378051862921766

Epoch: 219| Step: 0
Training loss: 2.6055777072906494
Validation loss: 2.3737117526351765

Epoch: 6| Step: 1
Training loss: 2.2533838748931885
Validation loss: 2.363875881318123

Epoch: 6| Step: 2
Training loss: 2.8237972259521484
Validation loss: 2.3633714568230415

Epoch: 6| Step: 3
Training loss: 2.562493085861206
Validation loss: 2.3603624861727477

Epoch: 6| Step: 4
Training loss: 2.8728833198547363
Validation loss: 2.365776910576769

Epoch: 6| Step: 5
Training loss: 2.1928658485412598
Validation loss: 2.3666329563304944

Epoch: 6| Step: 6
Training loss: 3.0938239097595215
Validation loss: 2.3705211070276078

Epoch: 6| Step: 7
Training loss: 2.6186165809631348
Validation loss: 2.35536701192138

Epoch: 6| Step: 8
Training loss: 2.694340944290161
Validation loss: 2.362983016557591

Epoch: 6| Step: 9
Training loss: 2.225229263305664
Validation loss: 2.3630459693170365

Epoch: 6| Step: 10
Training loss: 2.109888792037964
Validation loss: 2.364484381932084

Epoch: 6| Step: 11
Training loss: 2.984488010406494
Validation loss: 2.3641091879977973

Epoch: 6| Step: 12
Training loss: 2.33089017868042
Validation loss: 2.362599056254151

Epoch: 6| Step: 13
Training loss: 2.8851640224456787
Validation loss: 2.3563874408762944

Epoch: 220| Step: 0
Training loss: 2.53299617767334
Validation loss: 2.3567526878849154

Epoch: 6| Step: 1
Training loss: 3.063227891921997
Validation loss: 2.361245355298442

Epoch: 6| Step: 2
Training loss: 2.458658218383789
Validation loss: 2.365072898967292

Epoch: 6| Step: 3
Training loss: 2.823106288909912
Validation loss: 2.367880718682402

Epoch: 6| Step: 4
Training loss: 2.362182140350342
Validation loss: 2.3693847476795153

Epoch: 6| Step: 5
Training loss: 2.702357053756714
Validation loss: 2.369379223033946

Epoch: 6| Step: 6
Training loss: 2.465106964111328
Validation loss: 2.3725528986223283

Epoch: 6| Step: 7
Training loss: 2.3982503414154053
Validation loss: 2.3727680072989514

Epoch: 6| Step: 8
Training loss: 2.400632381439209
Validation loss: 2.385709103717599

Epoch: 6| Step: 9
Training loss: 2.208272695541382
Validation loss: 2.3900361958370415

Epoch: 6| Step: 10
Training loss: 1.9389129877090454
Validation loss: 2.3838357951051448

Epoch: 6| Step: 11
Training loss: 2.7889695167541504
Validation loss: 2.383809160160762

Epoch: 6| Step: 12
Training loss: 3.785665512084961
Validation loss: 2.391804095237486

Epoch: 6| Step: 13
Training loss: 2.055051565170288
Validation loss: 2.40093828785804

Epoch: 221| Step: 0
Training loss: 2.135897159576416
Validation loss: 2.405094746620424

Epoch: 6| Step: 1
Training loss: 2.785452365875244
Validation loss: 2.418138309191632

Epoch: 6| Step: 2
Training loss: 2.4695780277252197
Validation loss: 2.404265688311669

Epoch: 6| Step: 3
Training loss: 2.0002267360687256
Validation loss: 2.3952380457232074

Epoch: 6| Step: 4
Training loss: 2.9106976985931396
Validation loss: 2.3868047960342897

Epoch: 6| Step: 5
Training loss: 2.8119795322418213
Validation loss: 2.3907243897837978

Epoch: 6| Step: 6
Training loss: 2.8800301551818848
Validation loss: 2.392481052747337

Epoch: 6| Step: 7
Training loss: 1.8939610719680786
Validation loss: 2.3771337745010213

Epoch: 6| Step: 8
Training loss: 3.307192802429199
Validation loss: 2.3778757792647167

Epoch: 6| Step: 9
Training loss: 2.386422872543335
Validation loss: 2.3722112896621868

Epoch: 6| Step: 10
Training loss: 2.351128101348877
Validation loss: 2.3706820395685013

Epoch: 6| Step: 11
Training loss: 2.938416004180908
Validation loss: 2.3666208969649447

Epoch: 6| Step: 12
Training loss: 3.102388858795166
Validation loss: 2.3694529917932328

Epoch: 6| Step: 13
Training loss: 1.98490571975708
Validation loss: 2.371248168330039

Epoch: 222| Step: 0
Training loss: 3.53515625
Validation loss: 2.3796762317739506

Epoch: 6| Step: 1
Training loss: 2.4972758293151855
Validation loss: 2.386275786225514

Epoch: 6| Step: 2
Training loss: 3.3920183181762695
Validation loss: 2.394985273320188

Epoch: 6| Step: 3
Training loss: 2.567256450653076
Validation loss: 2.403815802707467

Epoch: 6| Step: 4
Training loss: 1.9679739475250244
Validation loss: 2.4004506090635895

Epoch: 6| Step: 5
Training loss: 2.192509651184082
Validation loss: 2.405442294254098

Epoch: 6| Step: 6
Training loss: 2.3398988246917725
Validation loss: 2.405967035601216

Epoch: 6| Step: 7
Training loss: 2.4372382164001465
Validation loss: 2.399025470979752

Epoch: 6| Step: 8
Training loss: 2.7478880882263184
Validation loss: 2.383261985676263

Epoch: 6| Step: 9
Training loss: 2.7524478435516357
Validation loss: 2.3789059295449206

Epoch: 6| Step: 10
Training loss: 2.2906808853149414
Validation loss: 2.3781899508609565

Epoch: 6| Step: 11
Training loss: 2.8511505126953125
Validation loss: 2.380307989735757

Epoch: 6| Step: 12
Training loss: 2.482929229736328
Validation loss: 2.3742760586482223

Epoch: 6| Step: 13
Training loss: 1.675031065940857
Validation loss: 2.376317121649301

Epoch: 223| Step: 0
Training loss: 2.453556537628174
Validation loss: 2.3726013116939093

Epoch: 6| Step: 1
Training loss: 2.1358251571655273
Validation loss: 2.3695456007475495

Epoch: 6| Step: 2
Training loss: 2.8555731773376465
Validation loss: 2.3730341183241976

Epoch: 6| Step: 3
Training loss: 2.877591609954834
Validation loss: 2.3665469436235327

Epoch: 6| Step: 4
Training loss: 2.669558525085449
Validation loss: 2.365285610639921

Epoch: 6| Step: 5
Training loss: 3.0168771743774414
Validation loss: 2.3704106858981553

Epoch: 6| Step: 6
Training loss: 2.2579946517944336
Validation loss: 2.370864196490216

Epoch: 6| Step: 7
Training loss: 2.536217212677002
Validation loss: 2.364396574676678

Epoch: 6| Step: 8
Training loss: 2.8824338912963867
Validation loss: 2.3663137702531714

Epoch: 6| Step: 9
Training loss: 2.0592665672302246
Validation loss: 2.36592108972611

Epoch: 6| Step: 10
Training loss: 2.8456854820251465
Validation loss: 2.3654009039684007

Epoch: 6| Step: 11
Training loss: 1.9215571880340576
Validation loss: 2.3753096749705653

Epoch: 6| Step: 12
Training loss: 3.2008590698242188
Validation loss: 2.3804240380564043

Epoch: 6| Step: 13
Training loss: 2.187638998031616
Validation loss: 2.37977861332637

Epoch: 224| Step: 0
Training loss: 3.099236488342285
Validation loss: 2.369879509813042

Epoch: 6| Step: 1
Training loss: 2.187286615371704
Validation loss: 2.3718031965276247

Epoch: 6| Step: 2
Training loss: 2.6722307205200195
Validation loss: 2.375915191506827

Epoch: 6| Step: 3
Training loss: 2.5661821365356445
Validation loss: 2.379005145001155

Epoch: 6| Step: 4
Training loss: 2.2454121112823486
Validation loss: 2.3781849030525453

Epoch: 6| Step: 5
Training loss: 2.0643506050109863
Validation loss: 2.3790949800963044

Epoch: 6| Step: 6
Training loss: 2.3911795616149902
Validation loss: 2.38943790107645

Epoch: 6| Step: 7
Training loss: 2.4107041358947754
Validation loss: 2.385206768589635

Epoch: 6| Step: 8
Training loss: 2.5104470252990723
Validation loss: 2.385726123727778

Epoch: 6| Step: 9
Training loss: 2.292635440826416
Validation loss: 2.3886299389664845

Epoch: 6| Step: 10
Training loss: 2.8475160598754883
Validation loss: 2.3756013942021195

Epoch: 6| Step: 11
Training loss: 2.5451090335845947
Validation loss: 2.371044481954267

Epoch: 6| Step: 12
Training loss: 3.3358144760131836
Validation loss: 2.372016624737811

Epoch: 6| Step: 13
Training loss: 2.9044735431671143
Validation loss: 2.361809238310783

Epoch: 225| Step: 0
Training loss: 2.5473949909210205
Validation loss: 2.3659029442776918

Epoch: 6| Step: 1
Training loss: 2.309906005859375
Validation loss: 2.3605628321247716

Epoch: 6| Step: 2
Training loss: 2.5924630165100098
Validation loss: 2.359885325995825

Epoch: 6| Step: 3
Training loss: 3.5008068084716797
Validation loss: 2.3609270459862164

Epoch: 6| Step: 4
Training loss: 2.6350765228271484
Validation loss: 2.358460398130519

Epoch: 6| Step: 5
Training loss: 2.3306045532226562
Validation loss: 2.353726158859909

Epoch: 6| Step: 6
Training loss: 2.037714958190918
Validation loss: 2.357606908326508

Epoch: 6| Step: 7
Training loss: 2.8588948249816895
Validation loss: 2.3567048477870163

Epoch: 6| Step: 8
Training loss: 2.4183852672576904
Validation loss: 2.357216347930252

Epoch: 6| Step: 9
Training loss: 2.3793680667877197
Validation loss: 2.3498968872972714

Epoch: 6| Step: 10
Training loss: 2.5894174575805664
Validation loss: 2.351875456430579

Epoch: 6| Step: 11
Training loss: 2.8831605911254883
Validation loss: 2.351607668784357

Epoch: 6| Step: 12
Training loss: 2.796225070953369
Validation loss: 2.354874313518565

Epoch: 6| Step: 13
Training loss: 1.7135411500930786
Validation loss: 2.355973997423726

Epoch: 226| Step: 0
Training loss: 3.263500690460205
Validation loss: 2.361550454170473

Epoch: 6| Step: 1
Training loss: 2.701073408126831
Validation loss: 2.3602611967312392

Epoch: 6| Step: 2
Training loss: 2.9724297523498535
Validation loss: 2.3694687120376097

Epoch: 6| Step: 3
Training loss: 2.7543890476226807
Validation loss: 2.3659244250225764

Epoch: 6| Step: 4
Training loss: 2.6946983337402344
Validation loss: 2.368936323350476

Epoch: 6| Step: 5
Training loss: 2.467532157897949
Validation loss: 2.3799630441973285

Epoch: 6| Step: 6
Training loss: 1.6633440256118774
Validation loss: 2.3845530940640356

Epoch: 6| Step: 7
Training loss: 2.70493221282959
Validation loss: 2.3790706126920638

Epoch: 6| Step: 8
Training loss: 2.8603639602661133
Validation loss: 2.3765778413382908

Epoch: 6| Step: 9
Training loss: 2.5739243030548096
Validation loss: 2.3798506695737123

Epoch: 6| Step: 10
Training loss: 2.963228702545166
Validation loss: 2.3784247393249185

Epoch: 6| Step: 11
Training loss: 2.567164897918701
Validation loss: 2.366903333253758

Epoch: 6| Step: 12
Training loss: 1.8353536128997803
Validation loss: 2.373061300605856

Epoch: 6| Step: 13
Training loss: 1.3796324729919434
Validation loss: 2.3619654947711575

Epoch: 227| Step: 0
Training loss: 2.573312520980835
Validation loss: 2.3589229224830546

Epoch: 6| Step: 1
Training loss: 2.958975076675415
Validation loss: 2.3522402958203386

Epoch: 6| Step: 2
Training loss: 2.9674110412597656
Validation loss: 2.3517354611427552

Epoch: 6| Step: 3
Training loss: 2.1527175903320312
Validation loss: 2.3466254562459965

Epoch: 6| Step: 4
Training loss: 3.4109363555908203
Validation loss: 2.3505906238350818

Epoch: 6| Step: 5
Training loss: 2.284332752227783
Validation loss: 2.3482808041316208

Epoch: 6| Step: 6
Training loss: 2.261258602142334
Validation loss: 2.347466584174864

Epoch: 6| Step: 7
Training loss: 1.7598072290420532
Validation loss: 2.342410764386577

Epoch: 6| Step: 8
Training loss: 2.488129138946533
Validation loss: 2.3465261382441365

Epoch: 6| Step: 9
Training loss: 1.6900129318237305
Validation loss: 2.33335639328085

Epoch: 6| Step: 10
Training loss: 3.283104419708252
Validation loss: 2.344019172012165

Epoch: 6| Step: 11
Training loss: 2.197878122329712
Validation loss: 2.3407107630083637

Epoch: 6| Step: 12
Training loss: 3.307469606399536
Validation loss: 2.3582740009471936

Epoch: 6| Step: 13
Training loss: 2.5901684761047363
Validation loss: 2.3529318404454056

Epoch: 228| Step: 0
Training loss: 2.9317467212677
Validation loss: 2.358936858433549

Epoch: 6| Step: 1
Training loss: 2.3702940940856934
Validation loss: 2.3576095937400736

Epoch: 6| Step: 2
Training loss: 2.7299585342407227
Validation loss: 2.3563958496175785

Epoch: 6| Step: 3
Training loss: 2.7161450386047363
Validation loss: 2.351848135712326

Epoch: 6| Step: 4
Training loss: 2.246753692626953
Validation loss: 2.357042920204901

Epoch: 6| Step: 5
Training loss: 2.9687654972076416
Validation loss: 2.3529226139027584

Epoch: 6| Step: 6
Training loss: 1.904564619064331
Validation loss: 2.3514223585846605

Epoch: 6| Step: 7
Training loss: 2.972757339477539
Validation loss: 2.357936079784106

Epoch: 6| Step: 8
Training loss: 2.635641574859619
Validation loss: 2.353022313887073

Epoch: 6| Step: 9
Training loss: 1.9370068311691284
Validation loss: 2.3659771898741364

Epoch: 6| Step: 10
Training loss: 2.855424165725708
Validation loss: 2.3667809988862727

Epoch: 6| Step: 11
Training loss: 2.0790815353393555
Validation loss: 2.3587782177873837

Epoch: 6| Step: 12
Training loss: 2.676579713821411
Validation loss: 2.3720357828242804

Epoch: 6| Step: 13
Training loss: 3.034227132797241
Validation loss: 2.369821197243147

Epoch: 229| Step: 0
Training loss: 1.973456621170044
Validation loss: 2.373845774640319

Epoch: 6| Step: 1
Training loss: 2.7745566368103027
Validation loss: 2.3783281413457726

Epoch: 6| Step: 2
Training loss: 2.186685562133789
Validation loss: 2.378019312376617

Epoch: 6| Step: 3
Training loss: 2.6097445487976074
Validation loss: 2.370499728828348

Epoch: 6| Step: 4
Training loss: 3.1144063472747803
Validation loss: 2.3725059006803777

Epoch: 6| Step: 5
Training loss: 3.29715633392334
Validation loss: 2.377473141557427

Epoch: 6| Step: 6
Training loss: 1.8059641122817993
Validation loss: 2.3744694878978114

Epoch: 6| Step: 7
Training loss: 2.149848461151123
Validation loss: 2.3681171248036046

Epoch: 6| Step: 8
Training loss: 2.496669054031372
Validation loss: 2.371998002452235

Epoch: 6| Step: 9
Training loss: 2.50276517868042
Validation loss: 2.3676399543721187

Epoch: 6| Step: 10
Training loss: 3.1307506561279297
Validation loss: 2.356543938318888

Epoch: 6| Step: 11
Training loss: 3.2124814987182617
Validation loss: 2.360003215010448

Epoch: 6| Step: 12
Training loss: 2.4137682914733887
Validation loss: 2.3561684572568504

Epoch: 6| Step: 13
Training loss: 1.9117166996002197
Validation loss: 2.348579832302627

Epoch: 230| Step: 0
Training loss: 2.1531310081481934
Validation loss: 2.353510067027102

Epoch: 6| Step: 1
Training loss: 2.331408739089966
Validation loss: 2.35222283230033

Epoch: 6| Step: 2
Training loss: 3.469470262527466
Validation loss: 2.3471640053615777

Epoch: 6| Step: 3
Training loss: 2.182462692260742
Validation loss: 2.3562754815624607

Epoch: 6| Step: 4
Training loss: 2.893937587738037
Validation loss: 2.3585914770762124

Epoch: 6| Step: 5
Training loss: 3.1113028526306152
Validation loss: 2.3647887347846903

Epoch: 6| Step: 6
Training loss: 1.8799784183502197
Validation loss: 2.3674718795284146

Epoch: 6| Step: 7
Training loss: 2.9315357208251953
Validation loss: 2.3652485673145582

Epoch: 6| Step: 8
Training loss: 2.933466672897339
Validation loss: 2.376467212553947

Epoch: 6| Step: 9
Training loss: 2.3120298385620117
Validation loss: 2.3781295719967095

Epoch: 6| Step: 10
Training loss: 2.078735589981079
Validation loss: 2.3689675972025883

Epoch: 6| Step: 11
Training loss: 2.2483150959014893
Validation loss: 2.374412544312016

Epoch: 6| Step: 12
Training loss: 3.099470376968384
Validation loss: 2.36252881890984

Epoch: 6| Step: 13
Training loss: 2.1419742107391357
Validation loss: 2.3537751167051253

Epoch: 231| Step: 0
Training loss: 2.633452892303467
Validation loss: 2.3490086255535

Epoch: 6| Step: 1
Training loss: 2.642587661743164
Validation loss: 2.355552973285798

Epoch: 6| Step: 2
Training loss: 2.2638158798217773
Validation loss: 2.3522250113948697

Epoch: 6| Step: 3
Training loss: 2.806689500808716
Validation loss: 2.3533155097756335

Epoch: 6| Step: 4
Training loss: 2.30434513092041
Validation loss: 2.357344304361651

Epoch: 6| Step: 5
Training loss: 2.546873092651367
Validation loss: 2.351288503216159

Epoch: 6| Step: 6
Training loss: 2.6089890003204346
Validation loss: 2.360253764737037

Epoch: 6| Step: 7
Training loss: 2.7297558784484863
Validation loss: 2.3538753217266453

Epoch: 6| Step: 8
Training loss: 1.8634569644927979
Validation loss: 2.3483489456997124

Epoch: 6| Step: 9
Training loss: 2.8382668495178223
Validation loss: 2.3503336880796697

Epoch: 6| Step: 10
Training loss: 2.8427863121032715
Validation loss: 2.339825185396338

Epoch: 6| Step: 11
Training loss: 2.747504711151123
Validation loss: 2.341047836888221

Epoch: 6| Step: 12
Training loss: 2.192807912826538
Validation loss: 2.348713887635098

Epoch: 6| Step: 13
Training loss: 3.330209493637085
Validation loss: 2.343620595111642

Epoch: 232| Step: 0
Training loss: 3.6164608001708984
Validation loss: 2.3518277163146646

Epoch: 6| Step: 1
Training loss: 3.2371487617492676
Validation loss: 2.3584668892686085

Epoch: 6| Step: 2
Training loss: 2.837906837463379
Validation loss: 2.364361250272361

Epoch: 6| Step: 3
Training loss: 2.1279072761535645
Validation loss: 2.3595088758776264

Epoch: 6| Step: 4
Training loss: 2.295102596282959
Validation loss: 2.371460376247283

Epoch: 6| Step: 5
Training loss: 2.337524890899658
Validation loss: 2.3875647796097623

Epoch: 6| Step: 6
Training loss: 2.999328136444092
Validation loss: 2.381699046780986

Epoch: 6| Step: 7
Training loss: 2.191028118133545
Validation loss: 2.3673086166381836

Epoch: 6| Step: 8
Training loss: 2.4986274242401123
Validation loss: 2.353053016047324

Epoch: 6| Step: 9
Training loss: 2.6108384132385254
Validation loss: 2.343120877460767

Epoch: 6| Step: 10
Training loss: 2.9040493965148926
Validation loss: 2.3436070872891333

Epoch: 6| Step: 11
Training loss: 1.9485583305358887
Validation loss: 2.3514637639445644

Epoch: 6| Step: 12
Training loss: 2.456756114959717
Validation loss: 2.353079834292012

Epoch: 6| Step: 13
Training loss: 1.5006918907165527
Validation loss: 2.3598255495871268

Epoch: 233| Step: 0
Training loss: 2.240858316421509
Validation loss: 2.3565955982413342

Epoch: 6| Step: 1
Training loss: 2.5665292739868164
Validation loss: 2.3518593747128724

Epoch: 6| Step: 2
Training loss: 3.2096221446990967
Validation loss: 2.368305124262328

Epoch: 6| Step: 3
Training loss: 2.7134366035461426
Validation loss: 2.357682707489178

Epoch: 6| Step: 4
Training loss: 2.797368288040161
Validation loss: 2.3601842900758148

Epoch: 6| Step: 5
Training loss: 2.287799596786499
Validation loss: 2.3684530552997383

Epoch: 6| Step: 6
Training loss: 2.2428178787231445
Validation loss: 2.3639130528255174

Epoch: 6| Step: 7
Training loss: 2.3867151737213135
Validation loss: 2.3649053317244335

Epoch: 6| Step: 8
Training loss: 2.5389463901519775
Validation loss: 2.3651395766965804

Epoch: 6| Step: 9
Training loss: 3.3192925453186035
Validation loss: 2.363179411939395

Epoch: 6| Step: 10
Training loss: 1.50351881980896
Validation loss: 2.3688261457668838

Epoch: 6| Step: 11
Training loss: 3.237593650817871
Validation loss: 2.3667678909917034

Epoch: 6| Step: 12
Training loss: 2.6202433109283447
Validation loss: 2.370887347446975

Epoch: 6| Step: 13
Training loss: 2.048802375793457
Validation loss: 2.357599601950697

Epoch: 234| Step: 0
Training loss: 2.208312511444092
Validation loss: 2.366130421238561

Epoch: 6| Step: 1
Training loss: 2.0419702529907227
Validation loss: 2.354039215272473

Epoch: 6| Step: 2
Training loss: 3.207801103591919
Validation loss: 2.340869311363466

Epoch: 6| Step: 3
Training loss: 2.5902462005615234
Validation loss: 2.342769576657203

Epoch: 6| Step: 4
Training loss: 2.994342803955078
Validation loss: 2.3361783950559554

Epoch: 6| Step: 5
Training loss: 2.5932137966156006
Validation loss: 2.3285507796913065

Epoch: 6| Step: 6
Training loss: 2.075949192047119
Validation loss: 2.330217040995116

Epoch: 6| Step: 7
Training loss: 2.214024305343628
Validation loss: 2.332269327614897

Epoch: 6| Step: 8
Training loss: 2.2384514808654785
Validation loss: 2.350360055123606

Epoch: 6| Step: 9
Training loss: 2.9337563514709473
Validation loss: 2.364144056074081

Epoch: 6| Step: 10
Training loss: 3.330644130706787
Validation loss: 2.3619212873520388

Epoch: 6| Step: 11
Training loss: 2.8678436279296875
Validation loss: 2.364924200119511

Epoch: 6| Step: 12
Training loss: 2.366952657699585
Validation loss: 2.3562627325775805

Epoch: 6| Step: 13
Training loss: 2.250955820083618
Validation loss: 2.3552846472750426

Epoch: 235| Step: 0
Training loss: 2.188432216644287
Validation loss: 2.353415894251998

Epoch: 6| Step: 1
Training loss: 1.9589078426361084
Validation loss: 2.352090899662305

Epoch: 6| Step: 2
Training loss: 2.6441874504089355
Validation loss: 2.363723031936153

Epoch: 6| Step: 3
Training loss: 2.987459182739258
Validation loss: 2.3599531214724303

Epoch: 6| Step: 4
Training loss: 2.758666515350342
Validation loss: 2.361015642842939

Epoch: 6| Step: 5
Training loss: 2.495310068130493
Validation loss: 2.36655863126119

Epoch: 6| Step: 6
Training loss: 2.704327344894409
Validation loss: 2.3809452620885705

Epoch: 6| Step: 7
Training loss: 2.1463770866394043
Validation loss: 2.38423389773215

Epoch: 6| Step: 8
Training loss: 2.7628111839294434
Validation loss: 2.375714971173194

Epoch: 6| Step: 9
Training loss: 2.7446675300598145
Validation loss: 2.3698444545909925

Epoch: 6| Step: 10
Training loss: 2.218352794647217
Validation loss: 2.3696245198608725

Epoch: 6| Step: 11
Training loss: 2.6271209716796875
Validation loss: 2.353228730540122

Epoch: 6| Step: 12
Training loss: 3.203950881958008
Validation loss: 2.3503682869736866

Epoch: 6| Step: 13
Training loss: 2.2320775985717773
Validation loss: 2.353307290743756

Epoch: 236| Step: 0
Training loss: 2.337481737136841
Validation loss: 2.3516512583660822

Epoch: 6| Step: 1
Training loss: 3.5907464027404785
Validation loss: 2.3464777597817044

Epoch: 6| Step: 2
Training loss: 1.8410592079162598
Validation loss: 2.3487435079390004

Epoch: 6| Step: 3
Training loss: 2.0598034858703613
Validation loss: 2.3434858963053715

Epoch: 6| Step: 4
Training loss: 2.3753316402435303
Validation loss: 2.3465240745134253

Epoch: 6| Step: 5
Training loss: 2.6503989696502686
Validation loss: 2.3585347001270582

Epoch: 6| Step: 6
Training loss: 3.085965156555176
Validation loss: 2.3509216975140315

Epoch: 6| Step: 7
Training loss: 2.8781473636627197
Validation loss: 2.3472166984311995

Epoch: 6| Step: 8
Training loss: 2.298326015472412
Validation loss: 2.3545503129241285

Epoch: 6| Step: 9
Training loss: 1.4198884963989258
Validation loss: 2.353123903274536

Epoch: 6| Step: 10
Training loss: 3.0447850227355957
Validation loss: 2.3707710517350065

Epoch: 6| Step: 11
Training loss: 2.4440228939056396
Validation loss: 2.370771878509111

Epoch: 6| Step: 12
Training loss: 2.9910924434661865
Validation loss: 2.3577016861208024

Epoch: 6| Step: 13
Training loss: 2.9827334880828857
Validation loss: 2.367562596515943

Epoch: 237| Step: 0
Training loss: 2.3827896118164062
Validation loss: 2.3705745871349047

Epoch: 6| Step: 1
Training loss: 2.6358635425567627
Validation loss: 2.364159337935909

Epoch: 6| Step: 2
Training loss: 2.2723991870880127
Validation loss: 2.3698222996086202

Epoch: 6| Step: 3
Training loss: 3.244662046432495
Validation loss: 2.3669233937417307

Epoch: 6| Step: 4
Training loss: 1.6012775897979736
Validation loss: 2.369934871632566

Epoch: 6| Step: 5
Training loss: 2.443661689758301
Validation loss: 2.3733598019487117

Epoch: 6| Step: 6
Training loss: 2.2196319103240967
Validation loss: 2.356364737274826

Epoch: 6| Step: 7
Training loss: 3.49466872215271
Validation loss: 2.34963103776337

Epoch: 6| Step: 8
Training loss: 2.005955696105957
Validation loss: 2.351438037810787

Epoch: 6| Step: 9
Training loss: 3.1347475051879883
Validation loss: 2.3359533920082995

Epoch: 6| Step: 10
Training loss: 3.2407140731811523
Validation loss: 2.332004431755312

Epoch: 6| Step: 11
Training loss: 2.589372158050537
Validation loss: 2.323628258961503

Epoch: 6| Step: 12
Training loss: 2.1259002685546875
Validation loss: 2.328111025594896

Epoch: 6| Step: 13
Training loss: 2.435392141342163
Validation loss: 2.3271699797722603

Epoch: 238| Step: 0
Training loss: 2.330371856689453
Validation loss: 2.3295092531429824

Epoch: 6| Step: 1
Training loss: 2.8982598781585693
Validation loss: 2.325111795497197

Epoch: 6| Step: 2
Training loss: 2.041783571243286
Validation loss: 2.328133213904596

Epoch: 6| Step: 3
Training loss: 1.8207192420959473
Validation loss: 2.3349029787125124

Epoch: 6| Step: 4
Training loss: 2.885110378265381
Validation loss: 2.335868327848373

Epoch: 6| Step: 5
Training loss: 2.5161547660827637
Validation loss: 2.345486589657363

Epoch: 6| Step: 6
Training loss: 2.745224714279175
Validation loss: 2.3401923743627404

Epoch: 6| Step: 7
Training loss: 2.803246021270752
Validation loss: 2.341245653808758

Epoch: 6| Step: 8
Training loss: 2.8112969398498535
Validation loss: 2.351977325254871

Epoch: 6| Step: 9
Training loss: 3.218517303466797
Validation loss: 2.354550056560065

Epoch: 6| Step: 10
Training loss: 2.948697090148926
Validation loss: 2.3625820529076362

Epoch: 6| Step: 11
Training loss: 2.296963930130005
Validation loss: 2.35785565581373

Epoch: 6| Step: 12
Training loss: 1.9334371089935303
Validation loss: 2.3555913791861585

Epoch: 6| Step: 13
Training loss: 2.448213577270508
Validation loss: 2.3444295519141742

Epoch: 239| Step: 0
Training loss: 1.5612467527389526
Validation loss: 2.353567951469011

Epoch: 6| Step: 1
Training loss: 1.9896371364593506
Validation loss: 2.3568496524646716

Epoch: 6| Step: 2
Training loss: 2.7119407653808594
Validation loss: 2.3607847190672353

Epoch: 6| Step: 3
Training loss: 2.79085373878479
Validation loss: 2.365573493383264

Epoch: 6| Step: 4
Training loss: 3.3058111667633057
Validation loss: 2.3705911379988476

Epoch: 6| Step: 5
Training loss: 3.1208977699279785
Validation loss: 2.3679679760368924

Epoch: 6| Step: 6
Training loss: 3.386059045791626
Validation loss: 2.362095739251824

Epoch: 6| Step: 7
Training loss: 2.229356288909912
Validation loss: 2.3482874567790697

Epoch: 6| Step: 8
Training loss: 2.579136848449707
Validation loss: 2.3501356750406246

Epoch: 6| Step: 9
Training loss: 2.51181697845459
Validation loss: 2.3397737446651665

Epoch: 6| Step: 10
Training loss: 2.5366909503936768
Validation loss: 2.3417303357073056

Epoch: 6| Step: 11
Training loss: 1.9486255645751953
Validation loss: 2.334000374681206

Epoch: 6| Step: 12
Training loss: 2.399163246154785
Validation loss: 2.3355724785917547

Epoch: 6| Step: 13
Training loss: 2.665144920349121
Validation loss: 2.3402567499427387

Epoch: 240| Step: 0
Training loss: 3.253730297088623
Validation loss: 2.3369056050495436

Epoch: 6| Step: 1
Training loss: 2.897350788116455
Validation loss: 2.338284869347849

Epoch: 6| Step: 2
Training loss: 2.696815013885498
Validation loss: 2.3341253624167493

Epoch: 6| Step: 3
Training loss: 2.2544217109680176
Validation loss: 2.336920726683832

Epoch: 6| Step: 4
Training loss: 2.6218414306640625
Validation loss: 2.3374829753752677

Epoch: 6| Step: 5
Training loss: 2.185091018676758
Validation loss: 2.3405429470923638

Epoch: 6| Step: 6
Training loss: 2.764430522918701
Validation loss: 2.345334960568336

Epoch: 6| Step: 7
Training loss: 2.6569862365722656
Validation loss: 2.343647769702378

Epoch: 6| Step: 8
Training loss: 3.009939193725586
Validation loss: 2.350231328318196

Epoch: 6| Step: 9
Training loss: 2.0877065658569336
Validation loss: 2.3534932290354083

Epoch: 6| Step: 10
Training loss: 3.033769369125366
Validation loss: 2.3572868147204

Epoch: 6| Step: 11
Training loss: 2.2904655933380127
Validation loss: 2.3726336622750885

Epoch: 6| Step: 12
Training loss: 1.8862698078155518
Validation loss: 2.377227903694235

Epoch: 6| Step: 13
Training loss: 1.6957281827926636
Validation loss: 2.38180999858405

Epoch: 241| Step: 0
Training loss: 3.442336082458496
Validation loss: 2.377980124565863

Epoch: 6| Step: 1
Training loss: 2.3940811157226562
Validation loss: 2.3663594979111866

Epoch: 6| Step: 2
Training loss: 2.7879865169525146
Validation loss: 2.359249440572595

Epoch: 6| Step: 3
Training loss: 2.7342402935028076
Validation loss: 2.3599294283056773

Epoch: 6| Step: 4
Training loss: 2.0467939376831055
Validation loss: 2.347923937664237

Epoch: 6| Step: 5
Training loss: 2.2336490154266357
Validation loss: 2.3376480007684357

Epoch: 6| Step: 6
Training loss: 2.2878379821777344
Validation loss: 2.3290323006209506

Epoch: 6| Step: 7
Training loss: 3.324742078781128
Validation loss: 2.331834654654226

Epoch: 6| Step: 8
Training loss: 2.0259652137756348
Validation loss: 2.332613786061605

Epoch: 6| Step: 9
Training loss: 2.322300910949707
Validation loss: 2.3270392494816936

Epoch: 6| Step: 10
Training loss: 2.520902395248413
Validation loss: 2.3294065870264524

Epoch: 6| Step: 11
Training loss: 1.9237828254699707
Validation loss: 2.3264852569949244

Epoch: 6| Step: 12
Training loss: 2.4952797889709473
Validation loss: 2.331396374651181

Epoch: 6| Step: 13
Training loss: 3.731449604034424
Validation loss: 2.336236387170771

Epoch: 242| Step: 0
Training loss: 3.062251091003418
Validation loss: 2.344450560949182

Epoch: 6| Step: 1
Training loss: 3.087289810180664
Validation loss: 2.3343793371672272

Epoch: 6| Step: 2
Training loss: 3.1688575744628906
Validation loss: 2.3312432407051005

Epoch: 6| Step: 3
Training loss: 2.565380334854126
Validation loss: 2.328332934328305

Epoch: 6| Step: 4
Training loss: 2.628917932510376
Validation loss: 2.3321908417568413

Epoch: 6| Step: 5
Training loss: 2.1251864433288574
Validation loss: 2.331908020921933

Epoch: 6| Step: 6
Training loss: 2.545440196990967
Validation loss: 2.332027636548524

Epoch: 6| Step: 7
Training loss: 2.8188602924346924
Validation loss: 2.3397818611514185

Epoch: 6| Step: 8
Training loss: 2.4307990074157715
Validation loss: 2.3385956133565595

Epoch: 6| Step: 9
Training loss: 2.197291851043701
Validation loss: 2.336781976043537

Epoch: 6| Step: 10
Training loss: 1.4315987825393677
Validation loss: 2.3490701977924635

Epoch: 6| Step: 11
Training loss: 2.577085018157959
Validation loss: 2.3457832233880156

Epoch: 6| Step: 12
Training loss: 2.85591197013855
Validation loss: 2.344077717873358

Epoch: 6| Step: 13
Training loss: 1.7355087995529175
Validation loss: 2.336243070581908

Epoch: 243| Step: 0
Training loss: 2.520723819732666
Validation loss: 2.344778960750949

Epoch: 6| Step: 1
Training loss: 2.170448064804077
Validation loss: 2.3428735938123477

Epoch: 6| Step: 2
Training loss: 3.1865105628967285
Validation loss: 2.339057501926217

Epoch: 6| Step: 3
Training loss: 2.6240289211273193
Validation loss: 2.3375036690824773

Epoch: 6| Step: 4
Training loss: 2.0834202766418457
Validation loss: 2.334654972117434

Epoch: 6| Step: 5
Training loss: 2.562819004058838
Validation loss: 2.326173254238662

Epoch: 6| Step: 6
Training loss: 2.364226818084717
Validation loss: 2.3286551531924995

Epoch: 6| Step: 7
Training loss: 2.4840378761291504
Validation loss: 2.3241392822675806

Epoch: 6| Step: 8
Training loss: 2.92551851272583
Validation loss: 2.3285629390388407

Epoch: 6| Step: 9
Training loss: 2.580838680267334
Validation loss: 2.3307168624734365

Epoch: 6| Step: 10
Training loss: 2.542987823486328
Validation loss: 2.324047096313969

Epoch: 6| Step: 11
Training loss: 2.2981045246124268
Validation loss: 2.328135786517974

Epoch: 6| Step: 12
Training loss: 2.0735957622528076
Validation loss: 2.3396641644098426

Epoch: 6| Step: 13
Training loss: 3.7240240573883057
Validation loss: 2.333967278080602

Epoch: 244| Step: 0
Training loss: 2.63509464263916
Validation loss: 2.3381754352200415

Epoch: 6| Step: 1
Training loss: 2.965188980102539
Validation loss: 2.3350406731328657

Epoch: 6| Step: 2
Training loss: 2.3506646156311035
Validation loss: 2.347667340309389

Epoch: 6| Step: 3
Training loss: 2.535827875137329
Validation loss: 2.341962468239569

Epoch: 6| Step: 4
Training loss: 2.2868337631225586
Validation loss: 2.3453801857527865

Epoch: 6| Step: 5
Training loss: 2.476475954055786
Validation loss: 2.3392338957837833

Epoch: 6| Step: 6
Training loss: 3.0287997722625732
Validation loss: 2.3562062196834113

Epoch: 6| Step: 7
Training loss: 3.3080928325653076
Validation loss: 2.3517428367368636

Epoch: 6| Step: 8
Training loss: 1.7716097831726074
Validation loss: 2.3465697611531904

Epoch: 6| Step: 9
Training loss: 2.0437464714050293
Validation loss: 2.344932443352156

Epoch: 6| Step: 10
Training loss: 3.035729169845581
Validation loss: 2.3556704392997165

Epoch: 6| Step: 11
Training loss: 2.4074182510375977
Validation loss: 2.35498615618675

Epoch: 6| Step: 12
Training loss: 2.190286159515381
Validation loss: 2.357229189206195

Epoch: 6| Step: 13
Training loss: 2.545501232147217
Validation loss: 2.3754116976132957

Epoch: 245| Step: 0
Training loss: 2.4140472412109375
Validation loss: 2.3757485112836285

Epoch: 6| Step: 1
Training loss: 1.942910075187683
Validation loss: 2.3642416102911836

Epoch: 6| Step: 2
Training loss: 2.159785509109497
Validation loss: 2.3707644119057605

Epoch: 6| Step: 3
Training loss: 3.1561827659606934
Validation loss: 2.381879254053998

Epoch: 6| Step: 4
Training loss: 2.5982158184051514
Validation loss: 2.37642301026211

Epoch: 6| Step: 5
Training loss: 2.4826712608337402
Validation loss: 2.361996518668308

Epoch: 6| Step: 6
Training loss: 2.628983497619629
Validation loss: 2.3573027836379183

Epoch: 6| Step: 7
Training loss: 1.9562814235687256
Validation loss: 2.3481435083573863

Epoch: 6| Step: 8
Training loss: 2.416393756866455
Validation loss: 2.3408628381708616

Epoch: 6| Step: 9
Training loss: 2.9867591857910156
Validation loss: 2.3377339660480456

Epoch: 6| Step: 10
Training loss: 2.53611159324646
Validation loss: 2.3416540391983522

Epoch: 6| Step: 11
Training loss: 2.8694214820861816
Validation loss: 2.3327947355085805

Epoch: 6| Step: 12
Training loss: 2.915773391723633
Validation loss: 2.331770320092478

Epoch: 6| Step: 13
Training loss: 2.4260683059692383
Validation loss: 2.3322758520803144

Epoch: 246| Step: 0
Training loss: 2.221062421798706
Validation loss: 2.3293418089548745

Epoch: 6| Step: 1
Training loss: 2.6701133251190186
Validation loss: 2.317196014106915

Epoch: 6| Step: 2
Training loss: 2.1183922290802
Validation loss: 2.327087066506827

Epoch: 6| Step: 3
Training loss: 2.1823010444641113
Validation loss: 2.323169787724813

Epoch: 6| Step: 4
Training loss: 2.50587797164917
Validation loss: 2.3186989984204693

Epoch: 6| Step: 5
Training loss: 2.593564510345459
Validation loss: 2.326515249026719

Epoch: 6| Step: 6
Training loss: 2.7977209091186523
Validation loss: 2.325194643389794

Epoch: 6| Step: 7
Training loss: 2.432973623275757
Validation loss: 2.308548476106377

Epoch: 6| Step: 8
Training loss: 3.164153575897217
Validation loss: 2.3168250386432936

Epoch: 6| Step: 9
Training loss: 2.165848731994629
Validation loss: 2.3297963398759083

Epoch: 6| Step: 10
Training loss: 2.83154559135437
Validation loss: 2.32299050208061

Epoch: 6| Step: 11
Training loss: 2.2076199054718018
Validation loss: 2.331122648331427

Epoch: 6| Step: 12
Training loss: 2.7610015869140625
Validation loss: 2.343694681762367

Epoch: 6| Step: 13
Training loss: 3.082965612411499
Validation loss: 2.3483045921530774

Epoch: 247| Step: 0
Training loss: 2.415445327758789
Validation loss: 2.3645443762502363

Epoch: 6| Step: 1
Training loss: 2.7941977977752686
Validation loss: 2.362714804628844

Epoch: 6| Step: 2
Training loss: 2.651121139526367
Validation loss: 2.379082602839316

Epoch: 6| Step: 3
Training loss: 3.2873730659484863
Validation loss: 2.3770112734968945

Epoch: 6| Step: 4
Training loss: 2.3486523628234863
Validation loss: 2.357437187625516

Epoch: 6| Step: 5
Training loss: 2.5395941734313965
Validation loss: 2.3556550613013645

Epoch: 6| Step: 6
Training loss: 2.518230438232422
Validation loss: 2.34486710897056

Epoch: 6| Step: 7
Training loss: 3.0885002613067627
Validation loss: 2.339572488620717

Epoch: 6| Step: 8
Training loss: 1.965927243232727
Validation loss: 2.3439121092519453

Epoch: 6| Step: 9
Training loss: 1.5472545623779297
Validation loss: 2.3266160949583976

Epoch: 6| Step: 10
Training loss: 2.7985570430755615
Validation loss: 2.338579170165523

Epoch: 6| Step: 11
Training loss: 2.168522834777832
Validation loss: 2.3325660382547686

Epoch: 6| Step: 12
Training loss: 2.9651474952697754
Validation loss: 2.3275824054594962

Epoch: 6| Step: 13
Training loss: 2.370866537094116
Validation loss: 2.3231413184955554

Epoch: 248| Step: 0
Training loss: 2.134929895401001
Validation loss: 2.312026249465122

Epoch: 6| Step: 1
Training loss: 2.7956886291503906
Validation loss: 2.315153691076463

Epoch: 6| Step: 2
Training loss: 2.236748218536377
Validation loss: 2.3109650099149315

Epoch: 6| Step: 3
Training loss: 1.9992196559906006
Validation loss: 2.311987578227956

Epoch: 6| Step: 4
Training loss: 2.66762638092041
Validation loss: 2.311834978800948

Epoch: 6| Step: 5
Training loss: 1.7983355522155762
Validation loss: 2.3113236568307363

Epoch: 6| Step: 6
Training loss: 2.8564703464508057
Validation loss: 2.3226654734662784

Epoch: 6| Step: 7
Training loss: 2.8788318634033203
Validation loss: 2.3141518433888755

Epoch: 6| Step: 8
Training loss: 3.3500208854675293
Validation loss: 2.324411799830775

Epoch: 6| Step: 9
Training loss: 2.591806411743164
Validation loss: 2.326737557688067

Epoch: 6| Step: 10
Training loss: 2.84194016456604
Validation loss: 2.330590796727006

Epoch: 6| Step: 11
Training loss: 2.6155266761779785
Validation loss: 2.3383473324519333

Epoch: 6| Step: 12
Training loss: 2.392458200454712
Validation loss: 2.3414084052526825

Epoch: 6| Step: 13
Training loss: 2.099116325378418
Validation loss: 2.3390473704184256

Epoch: 249| Step: 0
Training loss: 3.010999917984009
Validation loss: 2.349876780663767

Epoch: 6| Step: 1
Training loss: 1.6941413879394531
Validation loss: 2.3592357379133984

Epoch: 6| Step: 2
Training loss: 2.520761251449585
Validation loss: 2.3532925575010237

Epoch: 6| Step: 3
Training loss: 2.296082019805908
Validation loss: 2.344064297214631

Epoch: 6| Step: 4
Training loss: 2.3654727935791016
Validation loss: 2.3461446582630114

Epoch: 6| Step: 5
Training loss: 2.5782151222229004
Validation loss: 2.3587610311405633

Epoch: 6| Step: 6
Training loss: 2.5196712017059326
Validation loss: 2.346445296400337

Epoch: 6| Step: 7
Training loss: 3.1259782314300537
Validation loss: 2.34482257340544

Epoch: 6| Step: 8
Training loss: 2.339625120162964
Validation loss: 2.3337989186727874

Epoch: 6| Step: 9
Training loss: 3.029839038848877
Validation loss: 2.3614075696596535

Epoch: 6| Step: 10
Training loss: 2.356501817703247
Validation loss: 2.355623827185682

Epoch: 6| Step: 11
Training loss: 2.909597396850586
Validation loss: 2.3554098785564466

Epoch: 6| Step: 12
Training loss: 2.266791820526123
Validation loss: 2.350561744423323

Epoch: 6| Step: 13
Training loss: 2.469717264175415
Validation loss: 2.351154186392343

Epoch: 250| Step: 0
Training loss: 2.679108142852783
Validation loss: 2.354363969577256

Epoch: 6| Step: 1
Training loss: 2.039874315261841
Validation loss: 2.3503665770253828

Epoch: 6| Step: 2
Training loss: 2.8757190704345703
Validation loss: 2.363085521164761

Epoch: 6| Step: 3
Training loss: 2.49143123626709
Validation loss: 2.377962097044914

Epoch: 6| Step: 4
Training loss: 2.4167630672454834
Validation loss: 2.3832910445428666

Epoch: 6| Step: 5
Training loss: 2.4215869903564453
Validation loss: 2.3832569455587738

Epoch: 6| Step: 6
Training loss: 2.1039626598358154
Validation loss: 2.3691463393549763

Epoch: 6| Step: 7
Training loss: 2.5917491912841797
Validation loss: 2.3568436407273814

Epoch: 6| Step: 8
Training loss: 3.0656795501708984
Validation loss: 2.3357980046221005

Epoch: 6| Step: 9
Training loss: 1.911468744277954
Validation loss: 2.3337793273310505

Epoch: 6| Step: 10
Training loss: 3.0216665267944336
Validation loss: 2.3295050410814184

Epoch: 6| Step: 11
Training loss: 2.509756565093994
Validation loss: 2.3276952261565835

Epoch: 6| Step: 12
Training loss: 3.068002462387085
Validation loss: 2.325968050187634

Epoch: 6| Step: 13
Training loss: 2.846752643585205
Validation loss: 2.3349725892466884

Epoch: 251| Step: 0
Training loss: 2.191127300262451
Validation loss: 2.3252871728712514

Epoch: 6| Step: 1
Training loss: 1.8084826469421387
Validation loss: 2.3255297778755106

Epoch: 6| Step: 2
Training loss: 2.8490092754364014
Validation loss: 2.324664810652374

Epoch: 6| Step: 3
Training loss: 2.543497323989868
Validation loss: 2.327128161666214

Epoch: 6| Step: 4
Training loss: 2.998225212097168
Validation loss: 2.3330252824291104

Epoch: 6| Step: 5
Training loss: 2.6468324661254883
Validation loss: 2.3270060490536433

Epoch: 6| Step: 6
Training loss: 2.8803751468658447
Validation loss: 2.328590226429765

Epoch: 6| Step: 7
Training loss: 2.106353282928467
Validation loss: 2.3262084709700717

Epoch: 6| Step: 8
Training loss: 3.0084848403930664
Validation loss: 2.3348029095639466

Epoch: 6| Step: 9
Training loss: 2.544869899749756
Validation loss: 2.3350130358049945

Epoch: 6| Step: 10
Training loss: 2.6251697540283203
Validation loss: 2.3384268053116335

Epoch: 6| Step: 11
Training loss: 2.7193305492401123
Validation loss: 2.3356720093757875

Epoch: 6| Step: 12
Training loss: 2.365405559539795
Validation loss: 2.3271951137050504

Epoch: 6| Step: 13
Training loss: 2.186070442199707
Validation loss: 2.34598026480726

Epoch: 252| Step: 0
Training loss: 2.524505138397217
Validation loss: 2.3445658196685133

Epoch: 6| Step: 1
Training loss: 2.853762149810791
Validation loss: 2.3402732546611498

Epoch: 6| Step: 2
Training loss: 2.28540301322937
Validation loss: 2.3490655858029603

Epoch: 6| Step: 3
Training loss: 2.611910343170166
Validation loss: 2.344316631235102

Epoch: 6| Step: 4
Training loss: 2.3111884593963623
Validation loss: 2.3506256329116

Epoch: 6| Step: 5
Training loss: 2.2626113891601562
Validation loss: 2.359629402878464

Epoch: 6| Step: 6
Training loss: 3.18701171875
Validation loss: 2.363575968691098

Epoch: 6| Step: 7
Training loss: 2.174699306488037
Validation loss: 2.3666636405452603

Epoch: 6| Step: 8
Training loss: 2.521648645401001
Validation loss: 2.3560292310612176

Epoch: 6| Step: 9
Training loss: 3.2259793281555176
Validation loss: 2.3616268609159734

Epoch: 6| Step: 10
Training loss: 1.89686119556427
Validation loss: 2.3487324304478143

Epoch: 6| Step: 11
Training loss: 2.42315936088562
Validation loss: 2.346969440419187

Epoch: 6| Step: 12
Training loss: 2.626643419265747
Validation loss: 2.352134943008423

Epoch: 6| Step: 13
Training loss: 2.311617851257324
Validation loss: 2.3259569983328543

Epoch: 253| Step: 0
Training loss: 2.4020254611968994
Validation loss: 2.316822349384267

Epoch: 6| Step: 1
Training loss: 1.9161760807037354
Validation loss: 2.311587702843451

Epoch: 6| Step: 2
Training loss: 2.4099490642547607
Validation loss: 2.317426532827398

Epoch: 6| Step: 3
Training loss: 2.2596845626831055
Validation loss: 2.3167754078424103

Epoch: 6| Step: 4
Training loss: 2.739983558654785
Validation loss: 2.322875843253187

Epoch: 6| Step: 5
Training loss: 2.705347776412964
Validation loss: 2.303530844308997

Epoch: 6| Step: 6
Training loss: 2.491574287414551
Validation loss: 2.30346352823319

Epoch: 6| Step: 7
Training loss: 2.2111940383911133
Validation loss: 2.3069389763698784

Epoch: 6| Step: 8
Training loss: 2.516873359680176
Validation loss: 2.3201379365818475

Epoch: 6| Step: 9
Training loss: 2.9909305572509766
Validation loss: 2.3096287993974585

Epoch: 6| Step: 10
Training loss: 2.384375810623169
Validation loss: 2.324459634801393

Epoch: 6| Step: 11
Training loss: 3.1970465183258057
Validation loss: 2.322375435982981

Epoch: 6| Step: 12
Training loss: 2.4720258712768555
Validation loss: 2.3322983390541485

Epoch: 6| Step: 13
Training loss: 2.797478675842285
Validation loss: 2.3433619186442387

Epoch: 254| Step: 0
Training loss: 3.058375835418701
Validation loss: 2.3434415837769866

Epoch: 6| Step: 1
Training loss: 2.275357723236084
Validation loss: 2.334182257293373

Epoch: 6| Step: 2
Training loss: 2.9596593379974365
Validation loss: 2.3336182102080314

Epoch: 6| Step: 3
Training loss: 2.5051932334899902
Validation loss: 2.326480496314264

Epoch: 6| Step: 4
Training loss: 2.065070629119873
Validation loss: 2.32372724112644

Epoch: 6| Step: 5
Training loss: 2.932429790496826
Validation loss: 2.307422279029764

Epoch: 6| Step: 6
Training loss: 1.6242458820343018
Validation loss: 2.309596159124887

Epoch: 6| Step: 7
Training loss: 3.6442532539367676
Validation loss: 2.311905740409769

Epoch: 6| Step: 8
Training loss: 2.0103306770324707
Validation loss: 2.311343546836607

Epoch: 6| Step: 9
Training loss: 2.5886974334716797
Validation loss: 2.303545231460243

Epoch: 6| Step: 10
Training loss: 2.205934762954712
Validation loss: 2.303708964778531

Epoch: 6| Step: 11
Training loss: 2.8170559406280518
Validation loss: 2.30178972213499

Epoch: 6| Step: 12
Training loss: 1.952662706375122
Validation loss: 2.300677014935401

Epoch: 6| Step: 13
Training loss: 2.836825370788574
Validation loss: 2.309276116791592

Epoch: 255| Step: 0
Training loss: 2.712252616882324
Validation loss: 2.3227633853112497

Epoch: 6| Step: 1
Training loss: 2.331171989440918
Validation loss: 2.335750472161078

Epoch: 6| Step: 2
Training loss: 3.145124912261963
Validation loss: 2.337897972394061

Epoch: 6| Step: 3
Training loss: 3.2544896602630615
Validation loss: 2.3445263985664613

Epoch: 6| Step: 4
Training loss: 2.6473073959350586
Validation loss: 2.3526578180251585

Epoch: 6| Step: 5
Training loss: 2.3396055698394775
Validation loss: 2.34052598860956

Epoch: 6| Step: 6
Training loss: 2.341341495513916
Validation loss: 2.3508503385769424

Epoch: 6| Step: 7
Training loss: 2.6856541633605957
Validation loss: 2.349097046800839

Epoch: 6| Step: 8
Training loss: 2.2300031185150146
Validation loss: 2.349531888961792

Epoch: 6| Step: 9
Training loss: 2.737842559814453
Validation loss: 2.3452622736653974

Epoch: 6| Step: 10
Training loss: 2.077040433883667
Validation loss: 2.347228209177653

Epoch: 6| Step: 11
Training loss: 2.229055881500244
Validation loss: 2.3395169524736303

Epoch: 6| Step: 12
Training loss: 2.2685859203338623
Validation loss: 2.338141638745544

Epoch: 6| Step: 13
Training loss: 2.1619508266448975
Validation loss: 2.351057042357742

Epoch: 256| Step: 0
Training loss: 2.467581033706665
Validation loss: 2.337677901790988

Epoch: 6| Step: 1
Training loss: 2.2541394233703613
Validation loss: 2.332491026129774

Epoch: 6| Step: 2
Training loss: 2.500108480453491
Validation loss: 2.3329758233921503

Epoch: 6| Step: 3
Training loss: 2.6430819034576416
Validation loss: 2.34207320726046

Epoch: 6| Step: 4
Training loss: 2.051156520843506
Validation loss: 2.330866798277824

Epoch: 6| Step: 5
Training loss: 2.887716770172119
Validation loss: 2.3270381035343295

Epoch: 6| Step: 6
Training loss: 3.2224206924438477
Validation loss: 2.323414610278222

Epoch: 6| Step: 7
Training loss: 2.430795192718506
Validation loss: 2.320922549052905

Epoch: 6| Step: 8
Training loss: 3.399052143096924
Validation loss: 2.3123576769264798

Epoch: 6| Step: 9
Training loss: 2.3588037490844727
Validation loss: 2.3159973723914034

Epoch: 6| Step: 10
Training loss: 2.1502349376678467
Validation loss: 2.3082039689504974

Epoch: 6| Step: 11
Training loss: 2.589571237564087
Validation loss: 2.3059782161507556

Epoch: 6| Step: 12
Training loss: 2.5656800270080566
Validation loss: 2.3126883891321

Epoch: 6| Step: 13
Training loss: 1.1162195205688477
Validation loss: 2.3074797763619372

Epoch: 257| Step: 0
Training loss: 2.5225844383239746
Validation loss: 2.307691935570009

Epoch: 6| Step: 1
Training loss: 2.2935874462127686
Validation loss: 2.3124559745993665

Epoch: 6| Step: 2
Training loss: 2.0432968139648438
Validation loss: 2.299971185704713

Epoch: 6| Step: 3
Training loss: 2.672464370727539
Validation loss: 2.3063559480892715

Epoch: 6| Step: 4
Training loss: 2.331576347351074
Validation loss: 2.306430434667936

Epoch: 6| Step: 5
Training loss: 3.236644983291626
Validation loss: 2.323765784181574

Epoch: 6| Step: 6
Training loss: 1.5481441020965576
Validation loss: 2.3193811370480444

Epoch: 6| Step: 7
Training loss: 2.2642292976379395
Validation loss: 2.3165196013706986

Epoch: 6| Step: 8
Training loss: 2.9141530990600586
Validation loss: 2.326141688131517

Epoch: 6| Step: 9
Training loss: 3.217195749282837
Validation loss: 2.3257042746390066

Epoch: 6| Step: 10
Training loss: 2.800271511077881
Validation loss: 2.3224884797168035

Epoch: 6| Step: 11
Training loss: 2.415471076965332
Validation loss: 2.324930065421648

Epoch: 6| Step: 12
Training loss: 2.3993468284606934
Validation loss: 2.3237913757242183

Epoch: 6| Step: 13
Training loss: 2.555327892303467
Validation loss: 2.3298326025726976

Epoch: 258| Step: 0
Training loss: 2.51641845703125
Validation loss: 2.3150459950970066

Epoch: 6| Step: 1
Training loss: 2.9641151428222656
Validation loss: 2.3254905285373813

Epoch: 6| Step: 2
Training loss: 2.112382650375366
Validation loss: 2.320015743214597

Epoch: 6| Step: 3
Training loss: 2.313896894454956
Validation loss: 2.320360927171605

Epoch: 6| Step: 4
Training loss: 2.41019344329834
Validation loss: 2.3161695490601244

Epoch: 6| Step: 5
Training loss: 2.616252899169922
Validation loss: 2.335028044639095

Epoch: 6| Step: 6
Training loss: 2.4963455200195312
Validation loss: 2.3381967788101523

Epoch: 6| Step: 7
Training loss: 3.263754367828369
Validation loss: 2.355314935407331

Epoch: 6| Step: 8
Training loss: 2.594053030014038
Validation loss: 2.3618237177530923

Epoch: 6| Step: 9
Training loss: 1.5893415212631226
Validation loss: 2.365418029087846

Epoch: 6| Step: 10
Training loss: 2.8864803314208984
Validation loss: 2.3667286237080893

Epoch: 6| Step: 11
Training loss: 2.2916018962860107
Validation loss: 2.370156988020866

Epoch: 6| Step: 12
Training loss: 2.383716583251953
Validation loss: 2.375637936335738

Epoch: 6| Step: 13
Training loss: 3.1255054473876953
Validation loss: 2.3693312829540623

Epoch: 259| Step: 0
Training loss: 2.7016332149505615
Validation loss: 2.349258040869108

Epoch: 6| Step: 1
Training loss: 3.36586856842041
Validation loss: 2.336339714706585

Epoch: 6| Step: 2
Training loss: 1.775863766670227
Validation loss: 2.345541392603228

Epoch: 6| Step: 3
Training loss: 2.163753032684326
Validation loss: 2.3245718043337584

Epoch: 6| Step: 4
Training loss: 2.7563693523406982
Validation loss: 2.3247497491939093

Epoch: 6| Step: 5
Training loss: 3.0664968490600586
Validation loss: 2.3233699772947576

Epoch: 6| Step: 6
Training loss: 2.333322048187256
Validation loss: 2.322640013951127

Epoch: 6| Step: 7
Training loss: 2.1715774536132812
Validation loss: 2.3123897070525796

Epoch: 6| Step: 8
Training loss: 2.8306429386138916
Validation loss: 2.315777696588988

Epoch: 6| Step: 9
Training loss: 2.481102705001831
Validation loss: 2.321505879843107

Epoch: 6| Step: 10
Training loss: 2.767911195755005
Validation loss: 2.312437657387026

Epoch: 6| Step: 11
Training loss: 2.6231255531311035
Validation loss: 2.312054080347861

Epoch: 6| Step: 12
Training loss: 2.0966196060180664
Validation loss: 2.3158425028606127

Epoch: 6| Step: 13
Training loss: 1.7134531736373901
Validation loss: 2.318375648990754

Epoch: 260| Step: 0
Training loss: 2.5808966159820557
Validation loss: 2.3218122836082213

Epoch: 6| Step: 1
Training loss: 2.353677749633789
Validation loss: 2.3248820138233963

Epoch: 6| Step: 2
Training loss: 2.821693181991577
Validation loss: 2.330167975476993

Epoch: 6| Step: 3
Training loss: 2.478623390197754
Validation loss: 2.3327189184004262

Epoch: 6| Step: 4
Training loss: 2.6686177253723145
Validation loss: 2.3305897174342984

Epoch: 6| Step: 5
Training loss: 2.6838386058807373
Validation loss: 2.3332709138111403

Epoch: 6| Step: 6
Training loss: 1.7931839227676392
Validation loss: 2.3390145045454784

Epoch: 6| Step: 7
Training loss: 2.9323582649230957
Validation loss: 2.3486410981865338

Epoch: 6| Step: 8
Training loss: 2.864349842071533
Validation loss: 2.3531396747917257

Epoch: 6| Step: 9
Training loss: 2.6543941497802734
Validation loss: 2.360480349550965

Epoch: 6| Step: 10
Training loss: 2.0521202087402344
Validation loss: 2.3583202362060547

Epoch: 6| Step: 11
Training loss: 2.176814317703247
Validation loss: 2.344418469295707

Epoch: 6| Step: 12
Training loss: 2.8395700454711914
Validation loss: 2.3419019970842587

Epoch: 6| Step: 13
Training loss: 2.1414196491241455
Validation loss: 2.335382261583882

Epoch: 261| Step: 0
Training loss: 2.7512478828430176
Validation loss: 2.3383275180734615

Epoch: 6| Step: 1
Training loss: 2.8994383811950684
Validation loss: 2.3313907372054232

Epoch: 6| Step: 2
Training loss: 2.2747652530670166
Validation loss: 2.3217288935056297

Epoch: 6| Step: 3
Training loss: 2.758146047592163
Validation loss: 2.3226774584862495

Epoch: 6| Step: 4
Training loss: 2.3582019805908203
Validation loss: 2.3150062125216246

Epoch: 6| Step: 5
Training loss: 2.16176438331604
Validation loss: 2.3133165554333757

Epoch: 6| Step: 6
Training loss: 2.3368892669677734
Validation loss: 2.3133415675932363

Epoch: 6| Step: 7
Training loss: 2.8942694664001465
Validation loss: 2.3133127535543134

Epoch: 6| Step: 8
Training loss: 2.4298088550567627
Validation loss: 2.314729767460977

Epoch: 6| Step: 9
Training loss: 2.3107380867004395
Validation loss: 2.305715771131618

Epoch: 6| Step: 10
Training loss: 3.019162178039551
Validation loss: 2.3133788954827095

Epoch: 6| Step: 11
Training loss: 1.5045297145843506
Validation loss: 2.310702867405389

Epoch: 6| Step: 12
Training loss: 2.8736042976379395
Validation loss: 2.3174036830984135

Epoch: 6| Step: 13
Training loss: 2.628415107727051
Validation loss: 2.323757815104659

Epoch: 262| Step: 0
Training loss: 2.5369348526000977
Validation loss: 2.321679684423631

Epoch: 6| Step: 1
Training loss: 2.4300649166107178
Validation loss: 2.326796152258432

Epoch: 6| Step: 2
Training loss: 2.336142063140869
Validation loss: 2.3205565124429683

Epoch: 6| Step: 3
Training loss: 2.8348917961120605
Validation loss: 2.311098003900179

Epoch: 6| Step: 4
Training loss: 2.902271270751953
Validation loss: 2.3175285605974096

Epoch: 6| Step: 5
Training loss: 3.042377471923828
Validation loss: 2.3144260978186004

Epoch: 6| Step: 6
Training loss: 3.130425214767456
Validation loss: 2.3292112670918947

Epoch: 6| Step: 7
Training loss: 1.6196600198745728
Validation loss: 2.3194314664410007

Epoch: 6| Step: 8
Training loss: 1.6356842517852783
Validation loss: 2.3401174288924023

Epoch: 6| Step: 9
Training loss: 2.3232884407043457
Validation loss: 2.3430033076194023

Epoch: 6| Step: 10
Training loss: 2.5338826179504395
Validation loss: 2.3488274364061255

Epoch: 6| Step: 11
Training loss: 2.5923023223876953
Validation loss: 2.3646023196558796

Epoch: 6| Step: 12
Training loss: 2.793757438659668
Validation loss: 2.3643948826738583

Epoch: 6| Step: 13
Training loss: 2.32680082321167
Validation loss: 2.386030243289086

Epoch: 263| Step: 0
Training loss: 2.966141700744629
Validation loss: 2.38478349613887

Epoch: 6| Step: 1
Training loss: 2.3255527019500732
Validation loss: 2.3824857793828493

Epoch: 6| Step: 2
Training loss: 2.940786600112915
Validation loss: 2.3682184091178318

Epoch: 6| Step: 3
Training loss: 1.567795991897583
Validation loss: 2.3617954382332425

Epoch: 6| Step: 4
Training loss: 1.7611329555511475
Validation loss: 2.350922461478941

Epoch: 6| Step: 5
Training loss: 2.885366678237915
Validation loss: 2.333149253681142

Epoch: 6| Step: 6
Training loss: 1.7014963626861572
Validation loss: 2.328349674901655

Epoch: 6| Step: 7
Training loss: 3.175662040710449
Validation loss: 2.307166835313202

Epoch: 6| Step: 8
Training loss: 2.2991678714752197
Validation loss: 2.29392328569966

Epoch: 6| Step: 9
Training loss: 2.323415756225586
Validation loss: 2.296593622494769

Epoch: 6| Step: 10
Training loss: 2.368055820465088
Validation loss: 2.27835653930582

Epoch: 6| Step: 11
Training loss: 3.129932403564453
Validation loss: 2.2884558246981714

Epoch: 6| Step: 12
Training loss: 3.4681742191314697
Validation loss: 2.2936578412209787

Epoch: 6| Step: 13
Training loss: 2.0154364109039307
Validation loss: 2.2947890925151047

Epoch: 264| Step: 0
Training loss: 2.3150908946990967
Validation loss: 2.2940004435918664

Epoch: 6| Step: 1
Training loss: 2.630829334259033
Validation loss: 2.2933656374613443

Epoch: 6| Step: 2
Training loss: 2.39666748046875
Validation loss: 2.29948547322263

Epoch: 6| Step: 3
Training loss: 2.7948477268218994
Validation loss: 2.286062071400304

Epoch: 6| Step: 4
Training loss: 1.944612979888916
Validation loss: 2.293943461551461

Epoch: 6| Step: 5
Training loss: 2.3619818687438965
Validation loss: 2.2977889840320875

Epoch: 6| Step: 6
Training loss: 2.4745421409606934
Validation loss: 2.3014339887967674

Epoch: 6| Step: 7
Training loss: 2.261690616607666
Validation loss: 2.3116962345697547

Epoch: 6| Step: 8
Training loss: 2.2465760707855225
Validation loss: 2.311108286662768

Epoch: 6| Step: 9
Training loss: 2.483370780944824
Validation loss: 2.306744780591739

Epoch: 6| Step: 10
Training loss: 3.3122811317443848
Validation loss: 2.3213540251537035

Epoch: 6| Step: 11
Training loss: 2.703040599822998
Validation loss: 2.320868948454498

Epoch: 6| Step: 12
Training loss: 2.5403010845184326
Validation loss: 2.3331492588084233

Epoch: 6| Step: 13
Training loss: 2.8386716842651367
Validation loss: 2.3415236908902406

Epoch: 265| Step: 0
Training loss: 2.47676682472229
Validation loss: 2.351946674367433

Epoch: 6| Step: 1
Training loss: 2.3951048851013184
Validation loss: 2.360637382794452

Epoch: 6| Step: 2
Training loss: 3.2597246170043945
Validation loss: 2.3691989875608876

Epoch: 6| Step: 3
Training loss: 2.755812168121338
Validation loss: 2.3659519739048456

Epoch: 6| Step: 4
Training loss: 2.693188190460205
Validation loss: 2.3652708735517276

Epoch: 6| Step: 5
Training loss: 2.6340222358703613
Validation loss: 2.3655001245519167

Epoch: 6| Step: 6
Training loss: 2.8147664070129395
Validation loss: 2.348623650048369

Epoch: 6| Step: 7
Training loss: 1.924825668334961
Validation loss: 2.3348328067410375

Epoch: 6| Step: 8
Training loss: 1.7011845111846924
Validation loss: 2.3404211485257713

Epoch: 6| Step: 9
Training loss: 2.553621530532837
Validation loss: 2.332229406602921

Epoch: 6| Step: 10
Training loss: 2.5263843536376953
Validation loss: 2.3169910548835673

Epoch: 6| Step: 11
Training loss: 3.253620147705078
Validation loss: 2.3070051362437587

Epoch: 6| Step: 12
Training loss: 1.7633411884307861
Validation loss: 2.3150991316764586

Epoch: 6| Step: 13
Training loss: 2.5938637256622314
Validation loss: 2.303985990503783

Epoch: 266| Step: 0
Training loss: 3.01566219329834
Validation loss: 2.2957625004553024

Epoch: 6| Step: 1
Training loss: 1.77096688747406
Validation loss: 2.3003190845571537

Epoch: 6| Step: 2
Training loss: 2.1398463249206543
Validation loss: 2.3093187257807744

Epoch: 6| Step: 3
Training loss: 1.9753659963607788
Validation loss: 2.3049538571347474

Epoch: 6| Step: 4
Training loss: 2.282031297683716
Validation loss: 2.3042383437515586

Epoch: 6| Step: 5
Training loss: 3.1909351348876953
Validation loss: 2.3054867918773363

Epoch: 6| Step: 6
Training loss: 2.443197250366211
Validation loss: 2.308286149014709

Epoch: 6| Step: 7
Training loss: 1.8982194662094116
Validation loss: 2.300307607138029

Epoch: 6| Step: 8
Training loss: 2.637669563293457
Validation loss: 2.306836335889755

Epoch: 6| Step: 9
Training loss: 2.533010482788086
Validation loss: 2.308805993808213

Epoch: 6| Step: 10
Training loss: 2.832606792449951
Validation loss: 2.307409704372447

Epoch: 6| Step: 11
Training loss: 2.5763638019561768
Validation loss: 2.3183232827853133

Epoch: 6| Step: 12
Training loss: 2.6899187564849854
Validation loss: 2.333421455916538

Epoch: 6| Step: 13
Training loss: 3.8822402954101562
Validation loss: 2.3418441639151624

Epoch: 267| Step: 0
Training loss: 2.8175158500671387
Validation loss: 2.3439011189245407

Epoch: 6| Step: 1
Training loss: 3.0076136589050293
Validation loss: 2.362201790655813

Epoch: 6| Step: 2
Training loss: 2.3769476413726807
Validation loss: 2.3684238156964703

Epoch: 6| Step: 3
Training loss: 2.1509735584259033
Validation loss: 2.3643335091170443

Epoch: 6| Step: 4
Training loss: 2.9655396938323975
Validation loss: 2.3705762765740834

Epoch: 6| Step: 5
Training loss: 1.9714993238449097
Validation loss: 2.3784319277732604

Epoch: 6| Step: 6
Training loss: 2.283581256866455
Validation loss: 2.355224665775094

Epoch: 6| Step: 7
Training loss: 2.2603135108947754
Validation loss: 2.3182861587052703

Epoch: 6| Step: 8
Training loss: 2.534172296524048
Validation loss: 2.301929763568345

Epoch: 6| Step: 9
Training loss: 2.3258886337280273
Validation loss: 2.2935390805685394

Epoch: 6| Step: 10
Training loss: 3.009586811065674
Validation loss: 2.3024792402021346

Epoch: 6| Step: 11
Training loss: 2.244940757751465
Validation loss: 2.2953901290893555

Epoch: 6| Step: 12
Training loss: 3.075028657913208
Validation loss: 2.291556809538154

Epoch: 6| Step: 13
Training loss: 2.0577852725982666
Validation loss: 2.297334319801741

Epoch: 268| Step: 0
Training loss: 2.4617714881896973
Validation loss: 2.3006076338470622

Epoch: 6| Step: 1
Training loss: 2.6462645530700684
Validation loss: 2.293789968695692

Epoch: 6| Step: 2
Training loss: 2.36013126373291
Validation loss: 2.2987945797622844

Epoch: 6| Step: 3
Training loss: 2.791640281677246
Validation loss: 2.2940958828054447

Epoch: 6| Step: 4
Training loss: 2.562699794769287
Validation loss: 2.2944461786618797

Epoch: 6| Step: 5
Training loss: 2.592268705368042
Validation loss: 2.2998713677929294

Epoch: 6| Step: 6
Training loss: 2.738241195678711
Validation loss: 2.299151405211418

Epoch: 6| Step: 7
Training loss: 2.2539589405059814
Validation loss: 2.306034641881143

Epoch: 6| Step: 8
Training loss: 2.870483636856079
Validation loss: 2.306581861229353

Epoch: 6| Step: 9
Training loss: 2.769749641418457
Validation loss: 2.329586144416563

Epoch: 6| Step: 10
Training loss: 2.8860912322998047
Validation loss: 2.3291512074009066

Epoch: 6| Step: 11
Training loss: 1.9929113388061523
Validation loss: 2.330293281103975

Epoch: 6| Step: 12
Training loss: 2.1539955139160156
Validation loss: 2.3391009351258636

Epoch: 6| Step: 13
Training loss: 1.9923166036605835
Validation loss: 2.3415054044415875

Epoch: 269| Step: 0
Training loss: 2.8743512630462646
Validation loss: 2.3419789627034175

Epoch: 6| Step: 1
Training loss: 1.785000205039978
Validation loss: 2.3323355643979964

Epoch: 6| Step: 2
Training loss: 2.4153122901916504
Validation loss: 2.326812408303702

Epoch: 6| Step: 3
Training loss: 1.8938267230987549
Validation loss: 2.326109440095963

Epoch: 6| Step: 4
Training loss: 2.7724475860595703
Validation loss: 2.314891597276093

Epoch: 6| Step: 5
Training loss: 3.179123640060425
Validation loss: 2.3096804952108734

Epoch: 6| Step: 6
Training loss: 2.3135528564453125
Validation loss: 2.3004989572750625

Epoch: 6| Step: 7
Training loss: 2.6531527042388916
Validation loss: 2.2909686462853545

Epoch: 6| Step: 8
Training loss: 3.2592387199401855
Validation loss: 2.2869670878174486

Epoch: 6| Step: 9
Training loss: 1.7893664836883545
Validation loss: 2.284370199326546

Epoch: 6| Step: 10
Training loss: 1.9488093852996826
Validation loss: 2.277723047041124

Epoch: 6| Step: 11
Training loss: 2.7700605392456055
Validation loss: 2.2829543595672934

Epoch: 6| Step: 12
Training loss: 2.461740493774414
Validation loss: 2.279873009650938

Epoch: 6| Step: 13
Training loss: 3.3842763900756836
Validation loss: 2.28485167923794

Epoch: 270| Step: 0
Training loss: 2.8708901405334473
Validation loss: 2.2789481301461496

Epoch: 6| Step: 1
Training loss: 2.06820011138916
Validation loss: 2.283406787021186

Epoch: 6| Step: 2
Training loss: 2.6680779457092285
Validation loss: 2.2848719114898355

Epoch: 6| Step: 3
Training loss: 2.4221174716949463
Validation loss: 2.3022039628797963

Epoch: 6| Step: 4
Training loss: 2.253021240234375
Validation loss: 2.3006741154578423

Epoch: 6| Step: 5
Training loss: 3.4887914657592773
Validation loss: 2.305413515337052

Epoch: 6| Step: 6
Training loss: 2.714536666870117
Validation loss: 2.3082103395974762

Epoch: 6| Step: 7
Training loss: 2.3834025859832764
Validation loss: 2.296234558987361

Epoch: 6| Step: 8
Training loss: 2.377389669418335
Validation loss: 2.3030559708995204

Epoch: 6| Step: 9
Training loss: 2.0744996070861816
Validation loss: 2.3040181244573286

Epoch: 6| Step: 10
Training loss: 2.6244373321533203
Validation loss: 2.3058465860223256

Epoch: 6| Step: 11
Training loss: 2.495950937271118
Validation loss: 2.2987981329682055

Epoch: 6| Step: 12
Training loss: 2.3566131591796875
Validation loss: 2.303711829646941

Epoch: 6| Step: 13
Training loss: 1.792549729347229
Validation loss: 2.3090881416874547

Epoch: 271| Step: 0
Training loss: 1.431451439857483
Validation loss: 2.3325297999125656

Epoch: 6| Step: 1
Training loss: 2.10976243019104
Validation loss: 2.36604021569734

Epoch: 6| Step: 2
Training loss: 3.1404170989990234
Validation loss: 2.387337392376315

Epoch: 6| Step: 3
Training loss: 2.9186911582946777
Validation loss: 2.410707740373509

Epoch: 6| Step: 4
Training loss: 3.4901275634765625
Validation loss: 2.3951922642287387

Epoch: 6| Step: 5
Training loss: 2.2554664611816406
Validation loss: 2.3789046425973215

Epoch: 6| Step: 6
Training loss: 2.9263904094696045
Validation loss: 2.3588571394643476

Epoch: 6| Step: 7
Training loss: 2.694139242172241
Validation loss: 2.3504890908477125

Epoch: 6| Step: 8
Training loss: 3.208861827850342
Validation loss: 2.343985378101308

Epoch: 6| Step: 9
Training loss: 1.5871696472167969
Validation loss: 2.3233168714789936

Epoch: 6| Step: 10
Training loss: 1.9328269958496094
Validation loss: 2.309349895805441

Epoch: 6| Step: 11
Training loss: 2.4185025691986084
Validation loss: 2.2963990626796598

Epoch: 6| Step: 12
Training loss: 2.3340003490448
Validation loss: 2.289192671416908

Epoch: 6| Step: 13
Training loss: 2.920712471008301
Validation loss: 2.2932372067564275

Epoch: 272| Step: 0
Training loss: 2.0931074619293213
Validation loss: 2.2913417944344143

Epoch: 6| Step: 1
Training loss: 2.4543473720550537
Validation loss: 2.2835818183037544

Epoch: 6| Step: 2
Training loss: 2.9917125701904297
Validation loss: 2.2911703919851654

Epoch: 6| Step: 3
Training loss: 2.4705872535705566
Validation loss: 2.284869573449576

Epoch: 6| Step: 4
Training loss: 2.8054428100585938
Validation loss: 2.2919376409181984

Epoch: 6| Step: 5
Training loss: 2.725062131881714
Validation loss: 2.2925822504105104

Epoch: 6| Step: 6
Training loss: 2.473053455352783
Validation loss: 2.286520532382432

Epoch: 6| Step: 7
Training loss: 1.8243050575256348
Validation loss: 2.28651064185686

Epoch: 6| Step: 8
Training loss: 2.4551258087158203
Validation loss: 2.2966937275343042

Epoch: 6| Step: 9
Training loss: 1.8870408535003662
Validation loss: 2.288487131877612

Epoch: 6| Step: 10
Training loss: 3.1040191650390625
Validation loss: 2.2918192186663227

Epoch: 6| Step: 11
Training loss: 2.462858200073242
Validation loss: 2.2882282913372083

Epoch: 6| Step: 12
Training loss: 2.518937349319458
Validation loss: 2.292247949108001

Epoch: 6| Step: 13
Training loss: 2.8210058212280273
Validation loss: 2.2997098379237677

Epoch: 273| Step: 0
Training loss: 2.673797607421875
Validation loss: 2.303722643083142

Epoch: 6| Step: 1
Training loss: 2.9212403297424316
Validation loss: 2.315949096474596

Epoch: 6| Step: 2
Training loss: 2.0533270835876465
Validation loss: 2.310716285500475

Epoch: 6| Step: 3
Training loss: 2.4367918968200684
Validation loss: 2.3207198240423716

Epoch: 6| Step: 4
Training loss: 2.4142465591430664
Validation loss: 2.317378472256404

Epoch: 6| Step: 5
Training loss: 2.2245070934295654
Validation loss: 2.3375139005722536

Epoch: 6| Step: 6
Training loss: 2.9051334857940674
Validation loss: 2.344686690197196

Epoch: 6| Step: 7
Training loss: 2.4573745727539062
Validation loss: 2.3235896787335797

Epoch: 6| Step: 8
Training loss: 2.1123056411743164
Validation loss: 2.3270992309816423

Epoch: 6| Step: 9
Training loss: 1.9748226404190063
Validation loss: 2.306642065766037

Epoch: 6| Step: 10
Training loss: 3.076634168624878
Validation loss: 2.3048007975342455

Epoch: 6| Step: 11
Training loss: 2.6227211952209473
Validation loss: 2.3037733301039665

Epoch: 6| Step: 12
Training loss: 2.3283021450042725
Validation loss: 2.291373255432293

Epoch: 6| Step: 13
Training loss: 2.883012056350708
Validation loss: 2.2875526541022846

Epoch: 274| Step: 0
Training loss: 2.0065393447875977
Validation loss: 2.2937777811481106

Epoch: 6| Step: 1
Training loss: 2.2892160415649414
Validation loss: 2.2876601936996623

Epoch: 6| Step: 2
Training loss: 2.4584014415740967
Validation loss: 2.2883124915502404

Epoch: 6| Step: 3
Training loss: 3.390085458755493
Validation loss: 2.290179580770513

Epoch: 6| Step: 4
Training loss: 3.349055290222168
Validation loss: 2.28211643362558

Epoch: 6| Step: 5
Training loss: 3.247138500213623
Validation loss: 2.284035257113877

Epoch: 6| Step: 6
Training loss: 2.4722189903259277
Validation loss: 2.2790644117580947

Epoch: 6| Step: 7
Training loss: 3.1461873054504395
Validation loss: 2.2883690172626125

Epoch: 6| Step: 8
Training loss: 1.8109409809112549
Validation loss: 2.2802546203777356

Epoch: 6| Step: 9
Training loss: 2.324573516845703
Validation loss: 2.286937339331514

Epoch: 6| Step: 10
Training loss: 1.6144442558288574
Validation loss: 2.307103159607098

Epoch: 6| Step: 11
Training loss: 2.450429916381836
Validation loss: 2.30741774394948

Epoch: 6| Step: 12
Training loss: 2.2109360694885254
Validation loss: 2.3293306750635945

Epoch: 6| Step: 13
Training loss: 1.771061897277832
Validation loss: 2.3401067513291554

Epoch: 275| Step: 0
Training loss: 3.22436261177063
Validation loss: 2.3593926224657285

Epoch: 6| Step: 1
Training loss: 2.1503005027770996
Validation loss: 2.374402503813467

Epoch: 6| Step: 2
Training loss: 2.3455567359924316
Validation loss: 2.380026391757432

Epoch: 6| Step: 3
Training loss: 2.368469715118408
Validation loss: 2.3537400819922007

Epoch: 6| Step: 4
Training loss: 2.530679941177368
Validation loss: 2.3486146862788866

Epoch: 6| Step: 5
Training loss: 2.6110329627990723
Validation loss: 2.3321226540432183

Epoch: 6| Step: 6
Training loss: 2.080021858215332
Validation loss: 2.3099722964789278

Epoch: 6| Step: 7
Training loss: 2.470848321914673
Validation loss: 2.3056464682343187

Epoch: 6| Step: 8
Training loss: 2.9448819160461426
Validation loss: 2.289965557795699

Epoch: 6| Step: 9
Training loss: 2.4675092697143555
Validation loss: 2.2832086727183354

Epoch: 6| Step: 10
Training loss: 2.3305583000183105
Validation loss: 2.2840290992490706

Epoch: 6| Step: 11
Training loss: 2.265657424926758
Validation loss: 2.280427663556991

Epoch: 6| Step: 12
Training loss: 2.547559976577759
Validation loss: 2.284485981028567

Epoch: 6| Step: 13
Training loss: 2.71465802192688
Validation loss: 2.2835925497034544

Epoch: 276| Step: 0
Training loss: 2.9867725372314453
Validation loss: 2.288461608271445

Epoch: 6| Step: 1
Training loss: 2.2752633094787598
Validation loss: 2.298392521437778

Epoch: 6| Step: 2
Training loss: 2.2588624954223633
Validation loss: 2.301217753400085

Epoch: 6| Step: 3
Training loss: 2.455310344696045
Validation loss: 2.2995184339502805

Epoch: 6| Step: 4
Training loss: 2.4663379192352295
Validation loss: 2.285713744419877

Epoch: 6| Step: 5
Training loss: 2.8252928256988525
Validation loss: 2.296715521043347

Epoch: 6| Step: 6
Training loss: 2.355682134628296
Validation loss: 2.2944428254199285

Epoch: 6| Step: 7
Training loss: 2.6069774627685547
Validation loss: 2.2864078680674234

Epoch: 6| Step: 8
Training loss: 2.1326136589050293
Validation loss: 2.2778256016392864

Epoch: 6| Step: 9
Training loss: 2.592845916748047
Validation loss: 2.285695952753867

Epoch: 6| Step: 10
Training loss: 2.620368003845215
Validation loss: 2.278523865566459

Epoch: 6| Step: 11
Training loss: 2.54764723777771
Validation loss: 2.2913723620035316

Epoch: 6| Step: 12
Training loss: 2.090023994445801
Validation loss: 2.300992627297678

Epoch: 6| Step: 13
Training loss: 2.8975541591644287
Validation loss: 2.2913818308102187

Epoch: 277| Step: 0
Training loss: 2.662684440612793
Validation loss: 2.295552110159269

Epoch: 6| Step: 1
Training loss: 2.2953667640686035
Validation loss: 2.2964349639031196

Epoch: 6| Step: 2
Training loss: 2.1491780281066895
Validation loss: 2.2960204770488124

Epoch: 6| Step: 3
Training loss: 2.2834553718566895
Validation loss: 2.300130868470797

Epoch: 6| Step: 4
Training loss: 2.6894073486328125
Validation loss: 2.3116857338977117

Epoch: 6| Step: 5
Training loss: 2.4938344955444336
Validation loss: 2.3196731126436623

Epoch: 6| Step: 6
Training loss: 2.2994308471679688
Validation loss: 2.3270260108414518

Epoch: 6| Step: 7
Training loss: 3.528494358062744
Validation loss: 2.320959071959219

Epoch: 6| Step: 8
Training loss: 1.5705124139785767
Validation loss: 2.3056613937500985

Epoch: 6| Step: 9
Training loss: 2.9330215454101562
Validation loss: 2.3015590560051704

Epoch: 6| Step: 10
Training loss: 2.259530544281006
Validation loss: 2.298976598247405

Epoch: 6| Step: 11
Training loss: 1.7479496002197266
Validation loss: 2.2938742355633805

Epoch: 6| Step: 12
Training loss: 2.83624267578125
Validation loss: 2.293517453696138

Epoch: 6| Step: 13
Training loss: 3.4391186237335205
Validation loss: 2.2951766060244654

Epoch: 278| Step: 0
Training loss: 2.2737317085266113
Validation loss: 2.291701909034483

Epoch: 6| Step: 1
Training loss: 2.503161907196045
Validation loss: 2.2914600628678516

Epoch: 6| Step: 2
Training loss: 3.0061745643615723
Validation loss: 2.292891292161839

Epoch: 6| Step: 3
Training loss: 1.7464654445648193
Validation loss: 2.2984378722406205

Epoch: 6| Step: 4
Training loss: 3.1022701263427734
Validation loss: 2.2977427539005073

Epoch: 6| Step: 5
Training loss: 2.7108821868896484
Validation loss: 2.292387382958525

Epoch: 6| Step: 6
Training loss: 2.754742383956909
Validation loss: 2.2893600771504063

Epoch: 6| Step: 7
Training loss: 2.365341901779175
Validation loss: 2.2920966558558966

Epoch: 6| Step: 8
Training loss: 2.615626096725464
Validation loss: 2.2781071355265956

Epoch: 6| Step: 9
Training loss: 2.3009085655212402
Validation loss: 2.276475860226539

Epoch: 6| Step: 10
Training loss: 2.6187760829925537
Validation loss: 2.2752616251668623

Epoch: 6| Step: 11
Training loss: 2.685255289077759
Validation loss: 2.2728991457211074

Epoch: 6| Step: 12
Training loss: 2.217911958694458
Validation loss: 2.279987940224268

Epoch: 6| Step: 13
Training loss: 2.073291301727295
Validation loss: 2.2746431545544694

Epoch: 279| Step: 0
Training loss: 2.7811243534088135
Validation loss: 2.289960971442602

Epoch: 6| Step: 1
Training loss: 2.982741594314575
Validation loss: 2.292347215837048

Epoch: 6| Step: 2
Training loss: 2.6425559520721436
Validation loss: 2.304490876454179

Epoch: 6| Step: 3
Training loss: 2.286159038543701
Validation loss: 2.307525952657064

Epoch: 6| Step: 4
Training loss: 1.830406665802002
Validation loss: 2.3122605457100818

Epoch: 6| Step: 5
Training loss: 2.9138712882995605
Validation loss: 2.324300940318774

Epoch: 6| Step: 6
Training loss: 2.7800469398498535
Validation loss: 2.3583202233878513

Epoch: 6| Step: 7
Training loss: 2.032893657684326
Validation loss: 2.3516804813056864

Epoch: 6| Step: 8
Training loss: 1.8660389184951782
Validation loss: 2.351495865852602

Epoch: 6| Step: 9
Training loss: 2.344305992126465
Validation loss: 2.3558670269545687

Epoch: 6| Step: 10
Training loss: 2.1718454360961914
Validation loss: 2.3535086800975185

Epoch: 6| Step: 11
Training loss: 3.3905367851257324
Validation loss: 2.3448834214159238

Epoch: 6| Step: 12
Training loss: 2.738436698913574
Validation loss: 2.3291959429299958

Epoch: 6| Step: 13
Training loss: 1.9616533517837524
Validation loss: 2.303742672807427

Epoch: 280| Step: 0
Training loss: 2.3865275382995605
Validation loss: 2.2957310215119393

Epoch: 6| Step: 1
Training loss: 2.430521011352539
Validation loss: 2.2829860115563996

Epoch: 6| Step: 2
Training loss: 2.6595120429992676
Validation loss: 2.2733468829944568

Epoch: 6| Step: 3
Training loss: 2.5917720794677734
Validation loss: 2.267595365483274

Epoch: 6| Step: 4
Training loss: 2.5513787269592285
Validation loss: 2.2775463135011735

Epoch: 6| Step: 5
Training loss: 2.3657140731811523
Validation loss: 2.2814401349713727

Epoch: 6| Step: 6
Training loss: 2.572450637817383
Validation loss: 2.2849312674614692

Epoch: 6| Step: 7
Training loss: 2.4569616317749023
Validation loss: 2.276002924929383

Epoch: 6| Step: 8
Training loss: 2.724763870239258
Validation loss: 2.2832307764278945

Epoch: 6| Step: 9
Training loss: 2.0850677490234375
Validation loss: 2.290542118010982

Epoch: 6| Step: 10
Training loss: 2.1776866912841797
Validation loss: 2.284736887101204

Epoch: 6| Step: 11
Training loss: 2.887176990509033
Validation loss: 2.287299140807121

Epoch: 6| Step: 12
Training loss: 2.249663829803467
Validation loss: 2.3026169743589175

Epoch: 6| Step: 13
Training loss: 2.8102540969848633
Validation loss: 2.314085065677602

Epoch: 281| Step: 0
Training loss: 2.3199715614318848
Validation loss: 2.3303644605862197

Epoch: 6| Step: 1
Training loss: 2.056849479675293
Validation loss: 2.3573233324994325

Epoch: 6| Step: 2
Training loss: 2.360994815826416
Validation loss: 2.381221409766905

Epoch: 6| Step: 3
Training loss: 3.0884974002838135
Validation loss: 2.4052917982942317

Epoch: 6| Step: 4
Training loss: 2.5569515228271484
Validation loss: 2.392151491616362

Epoch: 6| Step: 5
Training loss: 3.506432294845581
Validation loss: 2.3847681681315103

Epoch: 6| Step: 6
Training loss: 3.075029134750366
Validation loss: 2.3776008505975046

Epoch: 6| Step: 7
Training loss: 2.460409164428711
Validation loss: 2.343117549855222

Epoch: 6| Step: 8
Training loss: 2.123284339904785
Validation loss: 2.333623468234975

Epoch: 6| Step: 9
Training loss: 2.249258041381836
Validation loss: 2.305721882850893

Epoch: 6| Step: 10
Training loss: 2.679025888442993
Validation loss: 2.294244945690196

Epoch: 6| Step: 11
Training loss: 1.9570201635360718
Validation loss: 2.292310163538943

Epoch: 6| Step: 12
Training loss: 2.076378583908081
Validation loss: 2.294457321525902

Epoch: 6| Step: 13
Training loss: 2.26774001121521
Validation loss: 2.305004337782501

Epoch: 282| Step: 0
Training loss: 2.6100759506225586
Validation loss: 2.3059494200573174

Epoch: 6| Step: 1
Training loss: 3.6107101440429688
Validation loss: 2.322802392385339

Epoch: 6| Step: 2
Training loss: 2.480403423309326
Validation loss: 2.3345906734466553

Epoch: 6| Step: 3
Training loss: 2.6270947456359863
Validation loss: 2.3258280959180606

Epoch: 6| Step: 4
Training loss: 2.0357542037963867
Validation loss: 2.3276641394502375

Epoch: 6| Step: 5
Training loss: 2.6939234733581543
Validation loss: 2.314238823870177

Epoch: 6| Step: 6
Training loss: 2.9971137046813965
Validation loss: 2.3005569006807063

Epoch: 6| Step: 7
Training loss: 2.0725808143615723
Validation loss: 2.287221836787398

Epoch: 6| Step: 8
Training loss: 2.0491843223571777
Validation loss: 2.2775944227813394

Epoch: 6| Step: 9
Training loss: 1.7690582275390625
Validation loss: 2.277094925603559

Epoch: 6| Step: 10
Training loss: 2.4459056854248047
Validation loss: 2.28502546587298

Epoch: 6| Step: 11
Training loss: 2.4325361251831055
Validation loss: 2.2938650038934525

Epoch: 6| Step: 12
Training loss: 2.523205518722534
Validation loss: 2.3016695053346696

Epoch: 6| Step: 13
Training loss: 2.8188719749450684
Validation loss: 2.316212466968003

Epoch: 283| Step: 0
Training loss: 1.884204626083374
Validation loss: 2.3119797296421503

Epoch: 6| Step: 1
Training loss: 2.644697427749634
Validation loss: 2.314281766132642

Epoch: 6| Step: 2
Training loss: 1.642510175704956
Validation loss: 2.291172594152471

Epoch: 6| Step: 3
Training loss: 2.9506285190582275
Validation loss: 2.286324606146864

Epoch: 6| Step: 4
Training loss: 2.1663050651550293
Validation loss: 2.2867048786532496

Epoch: 6| Step: 5
Training loss: 2.3295562267303467
Validation loss: 2.2898542368283836

Epoch: 6| Step: 6
Training loss: 3.0542116165161133
Validation loss: 2.2825366861076763

Epoch: 6| Step: 7
Training loss: 2.5735132694244385
Validation loss: 2.289460987173101

Epoch: 6| Step: 8
Training loss: 2.7667171955108643
Validation loss: 2.301086502690469

Epoch: 6| Step: 9
Training loss: 2.2971181869506836
Validation loss: 2.3071729854870866

Epoch: 6| Step: 10
Training loss: 2.9120659828186035
Validation loss: 2.304466491104454

Epoch: 6| Step: 11
Training loss: 2.6150689125061035
Validation loss: 2.311172157205561

Epoch: 6| Step: 12
Training loss: 2.2616889476776123
Validation loss: 2.296137402134557

Epoch: 6| Step: 13
Training loss: 2.6780121326446533
Validation loss: 2.306889182777815

Epoch: 284| Step: 0
Training loss: 1.7343177795410156
Validation loss: 2.3052599532629854

Epoch: 6| Step: 1
Training loss: 2.612870454788208
Validation loss: 2.316057987110589

Epoch: 6| Step: 2
Training loss: 2.5257792472839355
Validation loss: 2.3109076535829933

Epoch: 6| Step: 3
Training loss: 2.7176990509033203
Validation loss: 2.3069040031843286

Epoch: 6| Step: 4
Training loss: 2.115994930267334
Validation loss: 2.3093375621303434

Epoch: 6| Step: 5
Training loss: 2.3420519828796387
Validation loss: 2.315232874244772

Epoch: 6| Step: 6
Training loss: 2.8165788650512695
Validation loss: 2.3137346877846667

Epoch: 6| Step: 7
Training loss: 2.8209078311920166
Validation loss: 2.3182356690847747

Epoch: 6| Step: 8
Training loss: 3.079763889312744
Validation loss: 2.293954059641848

Epoch: 6| Step: 9
Training loss: 2.376471519470215
Validation loss: 2.2872481358948575

Epoch: 6| Step: 10
Training loss: 2.3513429164886475
Validation loss: 2.277889382454657

Epoch: 6| Step: 11
Training loss: 2.7292940616607666
Validation loss: 2.2676683882231354

Epoch: 6| Step: 12
Training loss: 2.045215606689453
Validation loss: 2.271107035298501

Epoch: 6| Step: 13
Training loss: 2.291496753692627
Validation loss: 2.2652498227293774

Epoch: 285| Step: 0
Training loss: 1.9507015943527222
Validation loss: 2.2662284886965187

Epoch: 6| Step: 1
Training loss: 2.9694418907165527
Validation loss: 2.263239888734715

Epoch: 6| Step: 2
Training loss: 2.5173206329345703
Validation loss: 2.2707892899872153

Epoch: 6| Step: 3
Training loss: 2.921504020690918
Validation loss: 2.271652296025266

Epoch: 6| Step: 4
Training loss: 2.948212146759033
Validation loss: 2.275465355124525

Epoch: 6| Step: 5
Training loss: 1.6293888092041016
Validation loss: 2.274292322897142

Epoch: 6| Step: 6
Training loss: 2.1612508296966553
Validation loss: 2.2848945022911153

Epoch: 6| Step: 7
Training loss: 2.8102593421936035
Validation loss: 2.282308481072867

Epoch: 6| Step: 8
Training loss: 2.3198962211608887
Validation loss: 2.283208300990443

Epoch: 6| Step: 9
Training loss: 2.663796901702881
Validation loss: 2.279673079008697

Epoch: 6| Step: 10
Training loss: 2.7453365325927734
Validation loss: 2.2904023995963474

Epoch: 6| Step: 11
Training loss: 2.2580981254577637
Validation loss: 2.295472429644677

Epoch: 6| Step: 12
Training loss: 1.8493030071258545
Validation loss: 2.2976473403233353

Epoch: 6| Step: 13
Training loss: 3.0905580520629883
Validation loss: 2.305289601766935

Epoch: 286| Step: 0
Training loss: 2.4757578372955322
Validation loss: 2.31593825996563

Epoch: 6| Step: 1
Training loss: 2.562669277191162
Validation loss: 2.3296554985866753

Epoch: 6| Step: 2
Training loss: 1.4168469905853271
Validation loss: 2.3515944891078497

Epoch: 6| Step: 3
Training loss: 2.485670328140259
Validation loss: 2.34181147749706

Epoch: 6| Step: 4
Training loss: 2.503594398498535
Validation loss: 2.346040828253633

Epoch: 6| Step: 5
Training loss: 2.936471939086914
Validation loss: 2.3471714476103425

Epoch: 6| Step: 6
Training loss: 2.39479923248291
Validation loss: 2.324802980628065

Epoch: 6| Step: 7
Training loss: 2.346132278442383
Validation loss: 2.322087618612474

Epoch: 6| Step: 8
Training loss: 2.738628387451172
Validation loss: 2.2999846243089244

Epoch: 6| Step: 9
Training loss: 2.682466745376587
Validation loss: 2.2857324795056413

Epoch: 6| Step: 10
Training loss: 2.9885458946228027
Validation loss: 2.2718824366087556

Epoch: 6| Step: 11
Training loss: 2.1864495277404785
Validation loss: 2.262525943017775

Epoch: 6| Step: 12
Training loss: 2.106938123703003
Validation loss: 2.2708025042728712

Epoch: 6| Step: 13
Training loss: 3.0253472328186035
Validation loss: 2.258920077354677

Epoch: 287| Step: 0
Training loss: 2.4640841484069824
Validation loss: 2.261982666548862

Epoch: 6| Step: 1
Training loss: 2.643895149230957
Validation loss: 2.2694033397141324

Epoch: 6| Step: 2
Training loss: 2.444355010986328
Validation loss: 2.2686104646293064

Epoch: 6| Step: 3
Training loss: 2.8138427734375
Validation loss: 2.2708599669958955

Epoch: 6| Step: 4
Training loss: 3.4134397506713867
Validation loss: 2.27984344831077

Epoch: 6| Step: 5
Training loss: 2.416900157928467
Validation loss: 2.2865354220072427

Epoch: 6| Step: 6
Training loss: 2.1820878982543945
Validation loss: 2.278395475879792

Epoch: 6| Step: 7
Training loss: 2.5722696781158447
Validation loss: 2.297062188066462

Epoch: 6| Step: 8
Training loss: 2.2719600200653076
Validation loss: 2.2998614439400296

Epoch: 6| Step: 9
Training loss: 2.11781644821167
Validation loss: 2.3191128930737896

Epoch: 6| Step: 10
Training loss: 1.9107162952423096
Validation loss: 2.3125849308506137

Epoch: 6| Step: 11
Training loss: 2.509958267211914
Validation loss: 2.3222111348182923

Epoch: 6| Step: 12
Training loss: 2.798900842666626
Validation loss: 2.333186247015512

Epoch: 6| Step: 13
Training loss: 1.9240875244140625
Validation loss: 2.3449870437704106

Epoch: 288| Step: 0
Training loss: 2.1051387786865234
Validation loss: 2.343960410805159

Epoch: 6| Step: 1
Training loss: 2.3109798431396484
Validation loss: 2.3271130054227767

Epoch: 6| Step: 2
Training loss: 2.8502511978149414
Validation loss: 2.3220632512082338

Epoch: 6| Step: 3
Training loss: 2.267929792404175
Validation loss: 2.310635521847715

Epoch: 6| Step: 4
Training loss: 1.9477273225784302
Validation loss: 2.3036721675626692

Epoch: 6| Step: 5
Training loss: 2.5739803314208984
Validation loss: 2.307178223004905

Epoch: 6| Step: 6
Training loss: 2.9213693141937256
Validation loss: 2.3016876930831582

Epoch: 6| Step: 7
Training loss: 2.84602952003479
Validation loss: 2.2940633758421867

Epoch: 6| Step: 8
Training loss: 2.4941139221191406
Validation loss: 2.287436318653886

Epoch: 6| Step: 9
Training loss: 2.2541794776916504
Validation loss: 2.2882925746261433

Epoch: 6| Step: 10
Training loss: 1.685625433921814
Validation loss: 2.282027595786638

Epoch: 6| Step: 11
Training loss: 2.5595591068267822
Validation loss: 2.3002248912729244

Epoch: 6| Step: 12
Training loss: 2.6638994216918945
Validation loss: 2.2915594500880085

Epoch: 6| Step: 13
Training loss: 3.480807065963745
Validation loss: 2.2915964152223323

Epoch: 289| Step: 0
Training loss: 2.1414096355438232
Validation loss: 2.2985639597779963

Epoch: 6| Step: 1
Training loss: 2.215362548828125
Validation loss: 2.2960856524846887

Epoch: 6| Step: 2
Training loss: 2.347553014755249
Validation loss: 2.301661652903403

Epoch: 6| Step: 3
Training loss: 3.06288480758667
Validation loss: 2.3016086598878265

Epoch: 6| Step: 4
Training loss: 2.804743766784668
Validation loss: 2.3168275638293196

Epoch: 6| Step: 5
Training loss: 2.768049716949463
Validation loss: 2.3182528429133917

Epoch: 6| Step: 6
Training loss: 2.8000359535217285
Validation loss: 2.311752203972109

Epoch: 6| Step: 7
Training loss: 2.190382957458496
Validation loss: 2.298974032043129

Epoch: 6| Step: 8
Training loss: 2.198009729385376
Validation loss: 2.27908657955867

Epoch: 6| Step: 9
Training loss: 2.7814602851867676
Validation loss: 2.2752800654339533

Epoch: 6| Step: 10
Training loss: 2.4685049057006836
Validation loss: 2.2642417671859905

Epoch: 6| Step: 11
Training loss: 2.2204179763793945
Validation loss: 2.266372239717873

Epoch: 6| Step: 12
Training loss: 2.0715582370758057
Validation loss: 2.2616693588995163

Epoch: 6| Step: 13
Training loss: 2.359715461730957
Validation loss: 2.264605736219755

Epoch: 290| Step: 0
Training loss: 2.194885015487671
Validation loss: 2.2712714646452214

Epoch: 6| Step: 1
Training loss: 1.8369214534759521
Validation loss: 2.277280761349586

Epoch: 6| Step: 2
Training loss: 1.882416009902954
Validation loss: 2.2754274388795257

Epoch: 6| Step: 3
Training loss: 2.788609266281128
Validation loss: 2.282208417051582

Epoch: 6| Step: 4
Training loss: 2.3653857707977295
Validation loss: 2.296473272385136

Epoch: 6| Step: 5
Training loss: 2.4866838455200195
Validation loss: 2.292481889006912

Epoch: 6| Step: 6
Training loss: 2.5780062675476074
Validation loss: 2.3001303852245374

Epoch: 6| Step: 7
Training loss: 2.944695472717285
Validation loss: 2.2892100195730887

Epoch: 6| Step: 8
Training loss: 2.631945848464966
Validation loss: 2.300062002674226

Epoch: 6| Step: 9
Training loss: 2.5136404037475586
Validation loss: 2.29296879101825

Epoch: 6| Step: 10
Training loss: 2.331878900527954
Validation loss: 2.302204324353126

Epoch: 6| Step: 11
Training loss: 1.9749982357025146
Validation loss: 2.313580184854487

Epoch: 6| Step: 12
Training loss: 2.5801331996917725
Validation loss: 2.3246495698087957

Epoch: 6| Step: 13
Training loss: 4.458497047424316
Validation loss: 2.320746896087482

Epoch: 291| Step: 0
Training loss: 2.2896616458892822
Validation loss: 2.315708585964736

Epoch: 6| Step: 1
Training loss: 2.7829322814941406
Validation loss: 2.295979328052972

Epoch: 6| Step: 2
Training loss: 2.3182168006896973
Validation loss: 2.30430592003689

Epoch: 6| Step: 3
Training loss: 2.2864878177642822
Validation loss: 2.2934928017277874

Epoch: 6| Step: 4
Training loss: 1.602159023284912
Validation loss: 2.2895139327613254

Epoch: 6| Step: 5
Training loss: 3.4398069381713867
Validation loss: 2.2801586504905456

Epoch: 6| Step: 6
Training loss: 2.95025634765625
Validation loss: 2.261081462265343

Epoch: 6| Step: 7
Training loss: 2.0556859970092773
Validation loss: 2.250102484098045

Epoch: 6| Step: 8
Training loss: 2.1152448654174805
Validation loss: 2.254691288035403

Epoch: 6| Step: 9
Training loss: 2.389901638031006
Validation loss: 2.2573446881386543

Epoch: 6| Step: 10
Training loss: 2.8105435371398926
Validation loss: 2.245882926448699

Epoch: 6| Step: 11
Training loss: 2.3332929611206055
Validation loss: 2.2560861636233587

Epoch: 6| Step: 12
Training loss: 2.503255605697632
Validation loss: 2.257979962133592

Epoch: 6| Step: 13
Training loss: 2.8251473903656006
Validation loss: 2.2590093676761915

Epoch: 292| Step: 0
Training loss: 2.488666296005249
Validation loss: 2.264614138551938

Epoch: 6| Step: 1
Training loss: 1.5064010620117188
Validation loss: 2.2642866462789555

Epoch: 6| Step: 2
Training loss: 3.089794635772705
Validation loss: 2.267962560858778

Epoch: 6| Step: 3
Training loss: 1.9133055210113525
Validation loss: 2.263793812003187

Epoch: 6| Step: 4
Training loss: 2.189948797225952
Validation loss: 2.269841173643707

Epoch: 6| Step: 5
Training loss: 3.2263126373291016
Validation loss: 2.2731961319523473

Epoch: 6| Step: 6
Training loss: 2.831792116165161
Validation loss: 2.285515539107784

Epoch: 6| Step: 7
Training loss: 2.1375322341918945
Validation loss: 2.2824482328148297

Epoch: 6| Step: 8
Training loss: 2.1818761825561523
Validation loss: 2.2840048574632212

Epoch: 6| Step: 9
Training loss: 2.345156669616699
Validation loss: 2.2970583746510167

Epoch: 6| Step: 10
Training loss: 2.5506839752197266
Validation loss: 2.299730316285164

Epoch: 6| Step: 11
Training loss: 2.1443872451782227
Validation loss: 2.2909737710029847

Epoch: 6| Step: 12
Training loss: 2.9159069061279297
Validation loss: 2.3036879954799527

Epoch: 6| Step: 13
Training loss: 2.97456693649292
Validation loss: 2.2987415457284577

Epoch: 293| Step: 0
Training loss: 2.409247875213623
Validation loss: 2.307793603148512

Epoch: 6| Step: 1
Training loss: 2.887878894805908
Validation loss: 2.295308897572179

Epoch: 6| Step: 2
Training loss: 2.3797554969787598
Validation loss: 2.291668671433644

Epoch: 6| Step: 3
Training loss: 2.155416488647461
Validation loss: 2.2883662126397573

Epoch: 6| Step: 4
Training loss: 2.416825771331787
Validation loss: 2.280333075472104

Epoch: 6| Step: 5
Training loss: 2.352123498916626
Validation loss: 2.284699865566787

Epoch: 6| Step: 6
Training loss: 2.099562168121338
Validation loss: 2.27073242843792

Epoch: 6| Step: 7
Training loss: 3.0212769508361816
Validation loss: 2.2748996673091764

Epoch: 6| Step: 8
Training loss: 3.0212905406951904
Validation loss: 2.27397051934273

Epoch: 6| Step: 9
Training loss: 2.448453426361084
Validation loss: 2.270862125581311

Epoch: 6| Step: 10
Training loss: 1.4670252799987793
Validation loss: 2.2751656450251097

Epoch: 6| Step: 11
Training loss: 2.586926221847534
Validation loss: 2.26726121030828

Epoch: 6| Step: 12
Training loss: 2.644777774810791
Validation loss: 2.279476951527339

Epoch: 6| Step: 13
Training loss: 2.210099458694458
Validation loss: 2.269239984532838

Epoch: 294| Step: 0
Training loss: 2.400688648223877
Validation loss: 2.285120682049823

Epoch: 6| Step: 1
Training loss: 2.620924472808838
Validation loss: 2.2729036397831415

Epoch: 6| Step: 2
Training loss: 2.663205623626709
Validation loss: 2.2783250911261446

Epoch: 6| Step: 3
Training loss: 2.4242448806762695
Validation loss: 2.29448325275093

Epoch: 6| Step: 4
Training loss: 2.296708345413208
Validation loss: 2.2991124353101178

Epoch: 6| Step: 5
Training loss: 2.5254123210906982
Validation loss: 2.290294785653391

Epoch: 6| Step: 6
Training loss: 1.8194564580917358
Validation loss: 2.3139469854293333

Epoch: 6| Step: 7
Training loss: 1.5560176372528076
Validation loss: 2.323676045222949

Epoch: 6| Step: 8
Training loss: 2.1089670658111572
Validation loss: 2.321251964056364

Epoch: 6| Step: 9
Training loss: 3.7998881340026855
Validation loss: 2.3206513568919194

Epoch: 6| Step: 10
Training loss: 2.6905112266540527
Validation loss: 2.2999924664856284

Epoch: 6| Step: 11
Training loss: 2.4603261947631836
Validation loss: 2.301084300523163

Epoch: 6| Step: 12
Training loss: 1.9279537200927734
Validation loss: 2.2838381041762648

Epoch: 6| Step: 13
Training loss: 3.325256586074829
Validation loss: 2.2776215217446767

Epoch: 295| Step: 0
Training loss: 1.4696662425994873
Validation loss: 2.2818357380487586

Epoch: 6| Step: 1
Training loss: 3.044313430786133
Validation loss: 2.272137793161536

Epoch: 6| Step: 2
Training loss: 2.5315804481506348
Validation loss: 2.271585008149506

Epoch: 6| Step: 3
Training loss: 2.3522791862487793
Validation loss: 2.2621720029461767

Epoch: 6| Step: 4
Training loss: 1.6645293235778809
Validation loss: 2.259125755679223

Epoch: 6| Step: 5
Training loss: 2.7986021041870117
Validation loss: 2.258066487568681

Epoch: 6| Step: 6
Training loss: 2.436946392059326
Validation loss: 2.2599721057440645

Epoch: 6| Step: 7
Training loss: 3.1963839530944824
Validation loss: 2.25310577372069

Epoch: 6| Step: 8
Training loss: 2.6667935848236084
Validation loss: 2.263217692734093

Epoch: 6| Step: 9
Training loss: 3.131375312805176
Validation loss: 2.257472163887434

Epoch: 6| Step: 10
Training loss: 2.3192994594573975
Validation loss: 2.267122273804039

Epoch: 6| Step: 11
Training loss: 2.333465814590454
Validation loss: 2.266142829771965

Epoch: 6| Step: 12
Training loss: 1.9620782136917114
Validation loss: 2.2647107493492866

Epoch: 6| Step: 13
Training loss: 2.4857490062713623
Validation loss: 2.277198371066842

Epoch: 296| Step: 0
Training loss: 2.065347194671631
Validation loss: 2.288934343604631

Epoch: 6| Step: 1
Training loss: 2.3749263286590576
Validation loss: 2.286754831191032

Epoch: 6| Step: 2
Training loss: 1.783933401107788
Validation loss: 2.299277021038917

Epoch: 6| Step: 3
Training loss: 3.262830972671509
Validation loss: 2.299102760130359

Epoch: 6| Step: 4
Training loss: 3.4737014770507812
Validation loss: 2.3111392682598484

Epoch: 6| Step: 5
Training loss: 2.6479415893554688
Validation loss: 2.3141210489375617

Epoch: 6| Step: 6
Training loss: 2.7363739013671875
Validation loss: 2.3111455940431163

Epoch: 6| Step: 7
Training loss: 2.1417016983032227
Validation loss: 2.2960582933118268

Epoch: 6| Step: 8
Training loss: 2.119112730026245
Validation loss: 2.2939561182452786

Epoch: 6| Step: 9
Training loss: 2.476207733154297
Validation loss: 2.2939140796661377

Epoch: 6| Step: 10
Training loss: 2.0732765197753906
Validation loss: 2.2919229871483258

Epoch: 6| Step: 11
Training loss: 2.793527603149414
Validation loss: 2.2792720717768513

Epoch: 6| Step: 12
Training loss: 2.2294631004333496
Validation loss: 2.2943458428946872

Epoch: 6| Step: 13
Training loss: 1.7812023162841797
Validation loss: 2.301396426334176

Epoch: 297| Step: 0
Training loss: 2.435753345489502
Validation loss: 2.3013295486409175

Epoch: 6| Step: 1
Training loss: 2.3162808418273926
Validation loss: 2.303865337884554

Epoch: 6| Step: 2
Training loss: 1.9457730054855347
Validation loss: 2.2946436251363447

Epoch: 6| Step: 3
Training loss: 1.7245150804519653
Validation loss: 2.285919145871234

Epoch: 6| Step: 4
Training loss: 2.790030002593994
Validation loss: 2.2982245055578088

Epoch: 6| Step: 5
Training loss: 1.9736851453781128
Validation loss: 2.291344383711456

Epoch: 6| Step: 6
Training loss: 2.41042423248291
Validation loss: 2.303763046059557

Epoch: 6| Step: 7
Training loss: 3.043013334274292
Validation loss: 2.314465594548051

Epoch: 6| Step: 8
Training loss: 3.114663600921631
Validation loss: 2.323311346833424

Epoch: 6| Step: 9
Training loss: 2.301563024520874
Validation loss: 2.3271777219669794

Epoch: 6| Step: 10
Training loss: 2.6781277656555176
Validation loss: 2.3309438895153742

Epoch: 6| Step: 11
Training loss: 2.5174169540405273
Validation loss: 2.306815008963308

Epoch: 6| Step: 12
Training loss: 2.58736515045166
Validation loss: 2.315611634203183

Epoch: 6| Step: 13
Training loss: 2.6632425785064697
Validation loss: 2.293572259205644

Epoch: 298| Step: 0
Training loss: 1.989553451538086
Validation loss: 2.2632819708957466

Epoch: 6| Step: 1
Training loss: 2.6410224437713623
Validation loss: 2.2658683048781527

Epoch: 6| Step: 2
Training loss: 2.873680591583252
Validation loss: 2.2625712156295776

Epoch: 6| Step: 3
Training loss: 2.129162073135376
Validation loss: 2.2556214768399476

Epoch: 6| Step: 4
Training loss: 2.4869797229766846
Validation loss: 2.2510484431379583

Epoch: 6| Step: 5
Training loss: 2.040292739868164
Validation loss: 2.2554114928809543

Epoch: 6| Step: 6
Training loss: 2.377183437347412
Validation loss: 2.244471178259901

Epoch: 6| Step: 7
Training loss: 2.684382438659668
Validation loss: 2.252162851313109

Epoch: 6| Step: 8
Training loss: 2.195232391357422
Validation loss: 2.268413846210767

Epoch: 6| Step: 9
Training loss: 3.086902618408203
Validation loss: 2.271511923882269

Epoch: 6| Step: 10
Training loss: 2.4680795669555664
Validation loss: 2.268152818884901

Epoch: 6| Step: 11
Training loss: 2.7542810440063477
Validation loss: 2.261424761946483

Epoch: 6| Step: 12
Training loss: 1.6014670133590698
Validation loss: 2.2522005522122948

Epoch: 6| Step: 13
Training loss: 3.336886167526245
Validation loss: 2.259849230448405

Epoch: 299| Step: 0
Training loss: 2.708314895629883
Validation loss: 2.2684208834043114

Epoch: 6| Step: 1
Training loss: 2.873839855194092
Validation loss: 2.2677616034784625

Epoch: 6| Step: 2
Training loss: 2.422550916671753
Validation loss: 2.279441149004044

Epoch: 6| Step: 3
Training loss: 2.446002721786499
Validation loss: 2.2894026297394947

Epoch: 6| Step: 4
Training loss: 1.9584643840789795
Validation loss: 2.2888167609450636

Epoch: 6| Step: 5
Training loss: 1.8669726848602295
Validation loss: 2.2879449385468678

Epoch: 6| Step: 6
Training loss: 2.0724642276763916
Validation loss: 2.291724979236562

Epoch: 6| Step: 7
Training loss: 2.1077256202697754
Validation loss: 2.2986610474125033

Epoch: 6| Step: 8
Training loss: 2.0951614379882812
Validation loss: 2.31080340057291

Epoch: 6| Step: 9
Training loss: 2.268383741378784
Validation loss: 2.3018134441427005

Epoch: 6| Step: 10
Training loss: 3.210674524307251
Validation loss: 2.291196938483946

Epoch: 6| Step: 11
Training loss: 2.0499510765075684
Validation loss: 2.2896055790685836

Epoch: 6| Step: 12
Training loss: 3.5527563095092773
Validation loss: 2.278734818581612

Epoch: 6| Step: 13
Training loss: 2.465088367462158
Validation loss: 2.2780777049321

Epoch: 300| Step: 0
Training loss: 1.7367480993270874
Validation loss: 2.267221707169728

Epoch: 6| Step: 1
Training loss: 2.0323314666748047
Validation loss: 2.2664539506358485

Epoch: 6| Step: 2
Training loss: 2.069141387939453
Validation loss: 2.2575938035083074

Epoch: 6| Step: 3
Training loss: 2.3925201892852783
Validation loss: 2.2606244958857054

Epoch: 6| Step: 4
Training loss: 2.6093063354492188
Validation loss: 2.257390429896693

Epoch: 6| Step: 5
Training loss: 1.8502147197723389
Validation loss: 2.268867297839093

Epoch: 6| Step: 6
Training loss: 2.7388834953308105
Validation loss: 2.2658531127437467

Epoch: 6| Step: 7
Training loss: 3.3930130004882812
Validation loss: 2.277983542411558

Epoch: 6| Step: 8
Training loss: 2.383925437927246
Validation loss: 2.2814174262426232

Epoch: 6| Step: 9
Training loss: 2.0448925495147705
Validation loss: 2.293979690920922

Epoch: 6| Step: 10
Training loss: 2.9921340942382812
Validation loss: 2.3098291761131695

Epoch: 6| Step: 11
Training loss: 2.368903636932373
Validation loss: 2.2967510300297893

Epoch: 6| Step: 12
Training loss: 2.73403263092041
Validation loss: 2.290851413562734

Epoch: 6| Step: 13
Training loss: 2.8620126247406006
Validation loss: 2.3051164355329288

Epoch: 301| Step: 0
Training loss: 2.3597171306610107
Validation loss: 2.3049400237298783

Epoch: 6| Step: 1
Training loss: 2.8281497955322266
Validation loss: 2.2892449466131066

Epoch: 6| Step: 2
Training loss: 2.7061703205108643
Validation loss: 2.284918649222261

Epoch: 6| Step: 3
Training loss: 2.7827816009521484
Validation loss: 2.273349420998686

Epoch: 6| Step: 4
Training loss: 2.3804304599761963
Validation loss: 2.27031087106274

Epoch: 6| Step: 5
Training loss: 1.9783259630203247
Validation loss: 2.263955808454944

Epoch: 6| Step: 6
Training loss: 2.301255941390991
Validation loss: 2.269274673154277

Epoch: 6| Step: 7
Training loss: 2.281970500946045
Validation loss: 2.2716826469667497

Epoch: 6| Step: 8
Training loss: 1.9594703912734985
Validation loss: 2.266139370138927

Epoch: 6| Step: 9
Training loss: 2.1549220085144043
Validation loss: 2.2616671823686167

Epoch: 6| Step: 10
Training loss: 2.942354917526245
Validation loss: 2.2701661817489134

Epoch: 6| Step: 11
Training loss: 2.6818301677703857
Validation loss: 2.2700687723775066

Epoch: 6| Step: 12
Training loss: 2.593492031097412
Validation loss: 2.2656283737510763

Epoch: 6| Step: 13
Training loss: 1.977365255355835
Validation loss: 2.2640249139519146

Epoch: 302| Step: 0
Training loss: 2.3616392612457275
Validation loss: 2.267847130375524

Epoch: 6| Step: 1
Training loss: 2.643573522567749
Validation loss: 2.2683197554721626

Epoch: 6| Step: 2
Training loss: 2.7943613529205322
Validation loss: 2.2702127079809866

Epoch: 6| Step: 3
Training loss: 2.647914409637451
Validation loss: 2.272169941215105

Epoch: 6| Step: 4
Training loss: 2.4947104454040527
Validation loss: 2.2581368723223285

Epoch: 6| Step: 5
Training loss: 2.223597526550293
Validation loss: 2.2651549872531684

Epoch: 6| Step: 6
Training loss: 1.9931706190109253
Validation loss: 2.2513744061993015

Epoch: 6| Step: 7
Training loss: 2.5093698501586914
Validation loss: 2.2743629332511657

Epoch: 6| Step: 8
Training loss: 2.663928985595703
Validation loss: 2.2541480077210294

Epoch: 6| Step: 9
Training loss: 2.696296215057373
Validation loss: 2.260408737326181

Epoch: 6| Step: 10
Training loss: 2.485586643218994
Validation loss: 2.2592181415968042

Epoch: 6| Step: 11
Training loss: 2.7599687576293945
Validation loss: 2.2814857716201455

Epoch: 6| Step: 12
Training loss: 1.7388412952423096
Validation loss: 2.300416890011039

Epoch: 6| Step: 13
Training loss: 1.5152742862701416
Validation loss: 2.313908197546518

Epoch: 303| Step: 0
Training loss: 2.4476490020751953
Validation loss: 2.3182914795414096

Epoch: 6| Step: 1
Training loss: 3.3166842460632324
Validation loss: 2.3171705020371305

Epoch: 6| Step: 2
Training loss: 2.0404696464538574
Validation loss: 2.3220099890103905

Epoch: 6| Step: 3
Training loss: 2.6252050399780273
Validation loss: 2.3327377432136127

Epoch: 6| Step: 4
Training loss: 2.410684108734131
Validation loss: 2.3595702468707995

Epoch: 6| Step: 5
Training loss: 2.7473244667053223
Validation loss: 2.3765991964647846

Epoch: 6| Step: 6
Training loss: 2.4394514560699463
Validation loss: 2.3942076416425806

Epoch: 6| Step: 7
Training loss: 1.8571417331695557
Validation loss: 2.3810690654221403

Epoch: 6| Step: 8
Training loss: 1.8077565431594849
Validation loss: 2.3541250677518946

Epoch: 6| Step: 9
Training loss: 2.351762294769287
Validation loss: 2.326636909156717

Epoch: 6| Step: 10
Training loss: 2.8661859035491943
Validation loss: 2.2935841365527083

Epoch: 6| Step: 11
Training loss: 2.3652520179748535
Validation loss: 2.266695284074353

Epoch: 6| Step: 12
Training loss: 2.639967441558838
Validation loss: 2.265428040617256

Epoch: 6| Step: 13
Training loss: 2.1137890815734863
Validation loss: 2.259753555379888

Epoch: 304| Step: 0
Training loss: 2.1735024452209473
Validation loss: 2.2549275608472925

Epoch: 6| Step: 1
Training loss: 2.448072910308838
Validation loss: 2.2649701795270367

Epoch: 6| Step: 2
Training loss: 3.1495208740234375
Validation loss: 2.2673319847353044

Epoch: 6| Step: 3
Training loss: 2.523632049560547
Validation loss: 2.261642881619033

Epoch: 6| Step: 4
Training loss: 3.190495014190674
Validation loss: 2.257424710899271

Epoch: 6| Step: 5
Training loss: 2.3628907203674316
Validation loss: 2.2497104188447357

Epoch: 6| Step: 6
Training loss: 3.296018600463867
Validation loss: 2.2498881868136826

Epoch: 6| Step: 7
Training loss: 2.194411277770996
Validation loss: 2.249594424360542

Epoch: 6| Step: 8
Training loss: 2.6641974449157715
Validation loss: 2.2566595667151996

Epoch: 6| Step: 9
Training loss: 1.9159644842147827
Validation loss: 2.2491141890966766

Epoch: 6| Step: 10
Training loss: 1.694192886352539
Validation loss: 2.2611470299382366

Epoch: 6| Step: 11
Training loss: 2.303091526031494
Validation loss: 2.280689634302611

Epoch: 6| Step: 12
Training loss: 1.9888944625854492
Validation loss: 2.2884698144851194

Epoch: 6| Step: 13
Training loss: 2.3641750812530518
Validation loss: 2.2995295396415134

Epoch: 305| Step: 0
Training loss: 1.584696888923645
Validation loss: 2.2952909290149646

Epoch: 6| Step: 1
Training loss: 2.095654249191284
Validation loss: 2.293630640993836

Epoch: 6| Step: 2
Training loss: 2.022101879119873
Validation loss: 2.296720479124336

Epoch: 6| Step: 3
Training loss: 2.5271947383880615
Validation loss: 2.295528781029486

Epoch: 6| Step: 4
Training loss: 3.0986948013305664
Validation loss: 2.2898199327530397

Epoch: 6| Step: 5
Training loss: 2.9570446014404297
Validation loss: 2.271665588501961

Epoch: 6| Step: 6
Training loss: 2.1153740882873535
Validation loss: 2.2745902205026276

Epoch: 6| Step: 7
Training loss: 2.804841995239258
Validation loss: 2.2688155456255843

Epoch: 6| Step: 8
Training loss: 2.941633701324463
Validation loss: 2.272497956470777

Epoch: 6| Step: 9
Training loss: 2.482578754425049
Validation loss: 2.2779817504267537

Epoch: 6| Step: 10
Training loss: 2.4458513259887695
Validation loss: 2.2847498821955856

Epoch: 6| Step: 11
Training loss: 2.3179264068603516
Validation loss: 2.2774737701621106

Epoch: 6| Step: 12
Training loss: 1.936883807182312
Validation loss: 2.2780544424569733

Epoch: 6| Step: 13
Training loss: 2.729250431060791
Validation loss: 2.2730514387930594

Epoch: 306| Step: 0
Training loss: 2.7780966758728027
Validation loss: 2.252829013332244

Epoch: 6| Step: 1
Training loss: 2.4632842540740967
Validation loss: 2.2617871607503583

Epoch: 6| Step: 2
Training loss: 1.8635151386260986
Validation loss: 2.2521806122154318

Epoch: 6| Step: 3
Training loss: 2.4206247329711914
Validation loss: 2.2638102039214103

Epoch: 6| Step: 4
Training loss: 1.9984582662582397
Validation loss: 2.259230762399653

Epoch: 6| Step: 5
Training loss: 1.9656445980072021
Validation loss: 2.253188007621355

Epoch: 6| Step: 6
Training loss: 2.761047601699829
Validation loss: 2.252216077619983

Epoch: 6| Step: 7
Training loss: 2.67647647857666
Validation loss: 2.2361266100278465

Epoch: 6| Step: 8
Training loss: 2.8842506408691406
Validation loss: 2.2338237698360155

Epoch: 6| Step: 9
Training loss: 2.5010311603546143
Validation loss: 2.23645277689862

Epoch: 6| Step: 10
Training loss: 2.3420233726501465
Validation loss: 2.2408173058622625

Epoch: 6| Step: 11
Training loss: 2.5520949363708496
Validation loss: 2.2334981195388304

Epoch: 6| Step: 12
Training loss: 2.444908857345581
Validation loss: 2.2449941404404177

Epoch: 6| Step: 13
Training loss: 2.1651599407196045
Validation loss: 2.2421805550975185

Epoch: 307| Step: 0
Training loss: 2.235766887664795
Validation loss: 2.2481039416405464

Epoch: 6| Step: 1
Training loss: 2.1845219135284424
Validation loss: 2.256900711726117

Epoch: 6| Step: 2
Training loss: 2.1617431640625
Validation loss: 2.249926374804589

Epoch: 6| Step: 3
Training loss: 2.4807918071746826
Validation loss: 2.2690718789254465

Epoch: 6| Step: 4
Training loss: 3.1639866828918457
Validation loss: 2.2834314505259194

Epoch: 6| Step: 5
Training loss: 2.1535801887512207
Validation loss: 2.2883617467777704

Epoch: 6| Step: 6
Training loss: 1.969476580619812
Validation loss: 2.2864523959416214

Epoch: 6| Step: 7
Training loss: 2.7332611083984375
Validation loss: 2.276138469737063

Epoch: 6| Step: 8
Training loss: 2.0155234336853027
Validation loss: 2.281024181714622

Epoch: 6| Step: 9
Training loss: 2.8967814445495605
Validation loss: 2.2789196045167985

Epoch: 6| Step: 10
Training loss: 2.2710583209991455
Validation loss: 2.2896820268323346

Epoch: 6| Step: 11
Training loss: 2.264540433883667
Validation loss: 2.2807003554477485

Epoch: 6| Step: 12
Training loss: 2.7811617851257324
Validation loss: 2.27890367661753

Epoch: 6| Step: 13
Training loss: 2.734441041946411
Validation loss: 2.291014811044098

Epoch: 308| Step: 0
Training loss: 2.0161867141723633
Validation loss: 2.290671517772059

Epoch: 6| Step: 1
Training loss: 1.82145357131958
Validation loss: 2.269484148230604

Epoch: 6| Step: 2
Training loss: 2.5720877647399902
Validation loss: 2.2763735478924167

Epoch: 6| Step: 3
Training loss: 2.399092197418213
Validation loss: 2.2856265665382467

Epoch: 6| Step: 4
Training loss: 2.2277467250823975
Validation loss: 2.2677365759367585

Epoch: 6| Step: 5
Training loss: 2.525696277618408
Validation loss: 2.266176462173462

Epoch: 6| Step: 6
Training loss: 2.217866897583008
Validation loss: 2.2662477454831524

Epoch: 6| Step: 7
Training loss: 2.623539447784424
Validation loss: 2.252925495947561

Epoch: 6| Step: 8
Training loss: 2.0466582775115967
Validation loss: 2.2499809572773595

Epoch: 6| Step: 9
Training loss: 2.2647719383239746
Validation loss: 2.2538771193514586

Epoch: 6| Step: 10
Training loss: 3.2659335136413574
Validation loss: 2.254348571582507

Epoch: 6| Step: 11
Training loss: 2.539605140686035
Validation loss: 2.2557310224861227

Epoch: 6| Step: 12
Training loss: 2.4754252433776855
Validation loss: 2.250390150213754

Epoch: 6| Step: 13
Training loss: 3.028447389602661
Validation loss: 2.250115684283677

Epoch: 309| Step: 0
Training loss: 2.983405590057373
Validation loss: 2.245326026793449

Epoch: 6| Step: 1
Training loss: 2.257979393005371
Validation loss: 2.25373084827136

Epoch: 6| Step: 2
Training loss: 2.750311851501465
Validation loss: 2.2529447565796556

Epoch: 6| Step: 3
Training loss: 1.903852105140686
Validation loss: 2.267459205401841

Epoch: 6| Step: 4
Training loss: 1.7658272981643677
Validation loss: 2.2876811001890447

Epoch: 6| Step: 5
Training loss: 2.6489620208740234
Validation loss: 2.2740688875157344

Epoch: 6| Step: 6
Training loss: 1.8918945789337158
Validation loss: 2.279366126624487

Epoch: 6| Step: 7
Training loss: 2.6368589401245117
Validation loss: 2.276090645021008

Epoch: 6| Step: 8
Training loss: 2.774332284927368
Validation loss: 2.2694369516065045

Epoch: 6| Step: 9
Training loss: 2.8362371921539307
Validation loss: 2.29603055215651

Epoch: 6| Step: 10
Training loss: 2.3086395263671875
Validation loss: 2.309302560744747

Epoch: 6| Step: 11
Training loss: 2.194963216781616
Validation loss: 2.3414463304704234

Epoch: 6| Step: 12
Training loss: 2.543086528778076
Validation loss: 2.3492338990652435

Epoch: 6| Step: 13
Training loss: 2.382687568664551
Validation loss: 2.3681026633067797

Epoch: 310| Step: 0
Training loss: 2.588282585144043
Validation loss: 2.358014278514411

Epoch: 6| Step: 1
Training loss: 3.0702104568481445
Validation loss: 2.346395343862554

Epoch: 6| Step: 2
Training loss: 2.68859601020813
Validation loss: 2.3169487778858473

Epoch: 6| Step: 3
Training loss: 1.6460946798324585
Validation loss: 2.292007371943484

Epoch: 6| Step: 4
Training loss: 2.7518224716186523
Validation loss: 2.278357054597588

Epoch: 6| Step: 5
Training loss: 2.677908420562744
Validation loss: 2.2729256460743565

Epoch: 6| Step: 6
Training loss: 2.189314842224121
Validation loss: 2.2648657521893902

Epoch: 6| Step: 7
Training loss: 1.9461753368377686
Validation loss: 2.27492461153256

Epoch: 6| Step: 8
Training loss: 3.1592817306518555
Validation loss: 2.2584761881059214

Epoch: 6| Step: 9
Training loss: 2.3928170204162598
Validation loss: 2.2608946472085933

Epoch: 6| Step: 10
Training loss: 2.387601375579834
Validation loss: 2.258196992258872

Epoch: 6| Step: 11
Training loss: 1.8770458698272705
Validation loss: 2.253518186589723

Epoch: 6| Step: 12
Training loss: 1.7012035846710205
Validation loss: 2.2712487687346754

Epoch: 6| Step: 13
Training loss: 2.9640212059020996
Validation loss: 2.27260055593265

Epoch: 311| Step: 0
Training loss: 2.4176387786865234
Validation loss: 2.264959317381664

Epoch: 6| Step: 1
Training loss: 2.451700210571289
Validation loss: 2.276113369131601

Epoch: 6| Step: 2
Training loss: 2.673677921295166
Validation loss: 2.2702555630796697

Epoch: 6| Step: 3
Training loss: 2.3554701805114746
Validation loss: 2.2711413368102042

Epoch: 6| Step: 4
Training loss: 2.5249695777893066
Validation loss: 2.2653471936461744

Epoch: 6| Step: 5
Training loss: 1.8500608205795288
Validation loss: 2.2589599509393015

Epoch: 6| Step: 6
Training loss: 2.483818769454956
Validation loss: 2.265976426421955

Epoch: 6| Step: 7
Training loss: 2.364307165145874
Validation loss: 2.2514576283834313

Epoch: 6| Step: 8
Training loss: 2.6238932609558105
Validation loss: 2.2537292203595563

Epoch: 6| Step: 9
Training loss: 2.3302268981933594
Validation loss: 2.2492551547224804

Epoch: 6| Step: 10
Training loss: 2.2679834365844727
Validation loss: 2.2484840141829623

Epoch: 6| Step: 11
Training loss: 2.514803886413574
Validation loss: 2.245041754937941

Epoch: 6| Step: 12
Training loss: 2.3705649375915527
Validation loss: 2.250440900043775

Epoch: 6| Step: 13
Training loss: 2.1620140075683594
Validation loss: 2.2571910299280638

Epoch: 312| Step: 0
Training loss: 2.636253595352173
Validation loss: 2.256647684240854

Epoch: 6| Step: 1
Training loss: 3.109642267227173
Validation loss: 2.2667016495940504

Epoch: 6| Step: 2
Training loss: 2.39485502243042
Validation loss: 2.2683091394362913

Epoch: 6| Step: 3
Training loss: 2.4815938472747803
Validation loss: 2.276263988146218

Epoch: 6| Step: 4
Training loss: 2.1629228591918945
Validation loss: 2.2866801702848045

Epoch: 6| Step: 5
Training loss: 2.830289840698242
Validation loss: 2.29966260797234

Epoch: 6| Step: 6
Training loss: 2.5498626232147217
Validation loss: 2.316680474947858

Epoch: 6| Step: 7
Training loss: 2.342864513397217
Validation loss: 2.31384813913735

Epoch: 6| Step: 8
Training loss: 1.9138479232788086
Validation loss: 2.3138556095861618

Epoch: 6| Step: 9
Training loss: 2.588143825531006
Validation loss: 2.309243438064411

Epoch: 6| Step: 10
Training loss: 2.1660611629486084
Validation loss: 2.288296425214378

Epoch: 6| Step: 11
Training loss: 2.3743271827697754
Validation loss: 2.2828895814957155

Epoch: 6| Step: 12
Training loss: 2.2931289672851562
Validation loss: 2.2653778573518157

Epoch: 6| Step: 13
Training loss: 1.7159450054168701
Validation loss: 2.242536724254649

Epoch: 313| Step: 0
Training loss: 2.037874698638916
Validation loss: 2.242725464605516

Epoch: 6| Step: 1
Training loss: 3.0106539726257324
Validation loss: 2.2452584697354223

Epoch: 6| Step: 2
Training loss: 2.590275287628174
Validation loss: 2.26275667067497

Epoch: 6| Step: 3
Training loss: 2.5596466064453125
Validation loss: 2.255658621429115

Epoch: 6| Step: 4
Training loss: 2.262369394302368
Validation loss: 2.26999988607181

Epoch: 6| Step: 5
Training loss: 2.2339980602264404
Validation loss: 2.271687897302771

Epoch: 6| Step: 6
Training loss: 1.6512563228607178
Validation loss: 2.2736268274245726

Epoch: 6| Step: 7
Training loss: 2.6405842304229736
Validation loss: 2.271058068480543

Epoch: 6| Step: 8
Training loss: 3.6265628337860107
Validation loss: 2.267503523057507

Epoch: 6| Step: 9
Training loss: 2.033179759979248
Validation loss: 2.267800672079927

Epoch: 6| Step: 10
Training loss: 2.9379165172576904
Validation loss: 2.273984238665591

Epoch: 6| Step: 11
Training loss: 2.0955116748809814
Validation loss: 2.2831378239457325

Epoch: 6| Step: 12
Training loss: 2.136977195739746
Validation loss: 2.2768646773471626

Epoch: 6| Step: 13
Training loss: 1.7192339897155762
Validation loss: 2.2707545218929166

Epoch: 314| Step: 0
Training loss: 2.9768221378326416
Validation loss: 2.260296678030363

Epoch: 6| Step: 1
Training loss: 2.728724718093872
Validation loss: 2.2541856176109722

Epoch: 6| Step: 2
Training loss: 2.0340194702148438
Validation loss: 2.249332586924235

Epoch: 6| Step: 3
Training loss: 3.077171802520752
Validation loss: 2.2567370527534076

Epoch: 6| Step: 4
Training loss: 2.2769088745117188
Validation loss: 2.2534937858581543

Epoch: 6| Step: 5
Training loss: 2.5475192070007324
Validation loss: 2.2398456963159705

Epoch: 6| Step: 6
Training loss: 1.4000414609909058
Validation loss: 2.239059104714342

Epoch: 6| Step: 7
Training loss: 2.4132094383239746
Validation loss: 2.251810432762228

Epoch: 6| Step: 8
Training loss: 2.3129563331604004
Validation loss: 2.2403796667693765

Epoch: 6| Step: 9
Training loss: 2.6378939151763916
Validation loss: 2.241287672391502

Epoch: 6| Step: 10
Training loss: 2.214749574661255
Validation loss: 2.2440797180257817

Epoch: 6| Step: 11
Training loss: 1.6124367713928223
Validation loss: 2.2477526459642636

Epoch: 6| Step: 12
Training loss: 2.8686184883117676
Validation loss: 2.2381894255197174

Epoch: 6| Step: 13
Training loss: 2.6354782581329346
Validation loss: 2.252651265872422

Epoch: 315| Step: 0
Training loss: 2.6863296031951904
Validation loss: 2.2519212204922914

Epoch: 6| Step: 1
Training loss: 1.9167369604110718
Validation loss: 2.271200518454275

Epoch: 6| Step: 2
Training loss: 3.0300021171569824
Validation loss: 2.272502419769123

Epoch: 6| Step: 3
Training loss: 2.5861971378326416
Validation loss: 2.2726355419364026

Epoch: 6| Step: 4
Training loss: 2.5450711250305176
Validation loss: 2.275579192305124

Epoch: 6| Step: 5
Training loss: 2.683061122894287
Validation loss: 2.2761450044570433

Epoch: 6| Step: 6
Training loss: 2.0892200469970703
Validation loss: 2.263583808816889

Epoch: 6| Step: 7
Training loss: 1.7952759265899658
Validation loss: 2.269270080392079

Epoch: 6| Step: 8
Training loss: 2.0006933212280273
Validation loss: 2.268099251613822

Epoch: 6| Step: 9
Training loss: 1.9971927404403687
Validation loss: 2.260083237001973

Epoch: 6| Step: 10
Training loss: 3.0820155143737793
Validation loss: 2.2643231422670427

Epoch: 6| Step: 11
Training loss: 2.7067909240722656
Validation loss: 2.2539524814134

Epoch: 6| Step: 12
Training loss: 2.311689853668213
Validation loss: 2.2466974796787387

Epoch: 6| Step: 13
Training loss: 1.9198106527328491
Validation loss: 2.2486143266001055

Epoch: 316| Step: 0
Training loss: 1.6040258407592773
Validation loss: 2.2548780492556992

Epoch: 6| Step: 1
Training loss: 3.00921893119812
Validation loss: 2.2556611440515004

Epoch: 6| Step: 2
Training loss: 2.3568153381347656
Validation loss: 2.256081642643098

Epoch: 6| Step: 3
Training loss: 2.3586602210998535
Validation loss: 2.244171357923938

Epoch: 6| Step: 4
Training loss: 1.8482787609100342
Validation loss: 2.2246832283594276

Epoch: 6| Step: 5
Training loss: 3.0132150650024414
Validation loss: 2.233878340772403

Epoch: 6| Step: 6
Training loss: 2.196615695953369
Validation loss: 2.2337043798098

Epoch: 6| Step: 7
Training loss: 2.220494031906128
Validation loss: 2.228461586019044

Epoch: 6| Step: 8
Training loss: 2.568774461746216
Validation loss: 2.230331290152765

Epoch: 6| Step: 9
Training loss: 2.3905715942382812
Validation loss: 2.2283108772770053

Epoch: 6| Step: 10
Training loss: 2.664827823638916
Validation loss: 2.2312931335100563

Epoch: 6| Step: 11
Training loss: 2.2554075717926025
Validation loss: 2.2469208368691067

Epoch: 6| Step: 12
Training loss: 2.630758285522461
Validation loss: 2.2530392780098865

Epoch: 6| Step: 13
Training loss: 2.380521535873413
Validation loss: 2.273493584766183

Epoch: 317| Step: 0
Training loss: 2.180537700653076
Validation loss: 2.2720127797895864

Epoch: 6| Step: 1
Training loss: 2.7596330642700195
Validation loss: 2.302448293214203

Epoch: 6| Step: 2
Training loss: 2.643637180328369
Validation loss: 2.3297758307508243

Epoch: 6| Step: 3
Training loss: 3.1583924293518066
Validation loss: 2.3360653949040238

Epoch: 6| Step: 4
Training loss: 2.1238365173339844
Validation loss: 2.328495817799722

Epoch: 6| Step: 5
Training loss: 1.9538507461547852
Validation loss: 2.325937242918117

Epoch: 6| Step: 6
Training loss: 2.851806640625
Validation loss: 2.323052211474347

Epoch: 6| Step: 7
Training loss: 2.176162004470825
Validation loss: 2.3173258304595947

Epoch: 6| Step: 8
Training loss: 2.8159470558166504
Validation loss: 2.299768388912242

Epoch: 6| Step: 9
Training loss: 2.709941864013672
Validation loss: 2.294540059181952

Epoch: 6| Step: 10
Training loss: 1.6287363767623901
Validation loss: 2.2850278090405207

Epoch: 6| Step: 11
Training loss: 2.4677841663360596
Validation loss: 2.277194301287333

Epoch: 6| Step: 12
Training loss: 2.10134220123291
Validation loss: 2.2601682652709303

Epoch: 6| Step: 13
Training loss: 1.800086498260498
Validation loss: 2.251096228117584

Epoch: 318| Step: 0
Training loss: 2.2869977951049805
Validation loss: 2.2424699183433288

Epoch: 6| Step: 1
Training loss: 2.242389678955078
Validation loss: 2.2434977536560385

Epoch: 6| Step: 2
Training loss: 1.5988984107971191
Validation loss: 2.26020840162872

Epoch: 6| Step: 3
Training loss: 2.953735828399658
Validation loss: 2.2784415778293403

Epoch: 6| Step: 4
Training loss: 2.7173027992248535
Validation loss: 2.2871773345496065

Epoch: 6| Step: 5
Training loss: 2.031773567199707
Validation loss: 2.2910600875013616

Epoch: 6| Step: 6
Training loss: 2.5111327171325684
Validation loss: 2.290718706705237

Epoch: 6| Step: 7
Training loss: 1.9306511878967285
Validation loss: 2.283582866832774

Epoch: 6| Step: 8
Training loss: 2.9573121070861816
Validation loss: 2.290105335174068

Epoch: 6| Step: 9
Training loss: 2.110973358154297
Validation loss: 2.2690807132310766

Epoch: 6| Step: 10
Training loss: 2.0622386932373047
Validation loss: 2.2792918579552763

Epoch: 6| Step: 11
Training loss: 2.963822841644287
Validation loss: 2.27745904204666

Epoch: 6| Step: 12
Training loss: 2.6420059204101562
Validation loss: 2.2830369318685224

Epoch: 6| Step: 13
Training loss: 2.4261560440063477
Validation loss: 2.2778995601079797

Epoch: 319| Step: 0
Training loss: 2.2098355293273926
Validation loss: 2.296605320386989

Epoch: 6| Step: 1
Training loss: 2.6278557777404785
Validation loss: 2.271690217397546

Epoch: 6| Step: 2
Training loss: 2.4198803901672363
Validation loss: 2.2816088122706257

Epoch: 6| Step: 3
Training loss: 2.178257703781128
Validation loss: 2.288610113564358

Epoch: 6| Step: 4
Training loss: 2.3831868171691895
Validation loss: 2.282377145623648

Epoch: 6| Step: 5
Training loss: 3.316736936569214
Validation loss: 2.2703541376257457

Epoch: 6| Step: 6
Training loss: 2.5061745643615723
Validation loss: 2.2791931552271687

Epoch: 6| Step: 7
Training loss: 2.1208038330078125
Validation loss: 2.258612596860496

Epoch: 6| Step: 8
Training loss: 2.262814998626709
Validation loss: 2.2607675931786977

Epoch: 6| Step: 9
Training loss: 2.958763599395752
Validation loss: 2.2524417677233295

Epoch: 6| Step: 10
Training loss: 1.6341502666473389
Validation loss: 2.237327097564615

Epoch: 6| Step: 11
Training loss: 2.9489474296569824
Validation loss: 2.2297961634974324

Epoch: 6| Step: 12
Training loss: 1.9199323654174805
Validation loss: 2.2403516077226207

Epoch: 6| Step: 13
Training loss: 1.4534212350845337
Validation loss: 2.247237656706123

Epoch: 320| Step: 0
Training loss: 2.4560842514038086
Validation loss: 2.2640093141986477

Epoch: 6| Step: 1
Training loss: 2.2513656616210938
Validation loss: 2.2669270012968328

Epoch: 6| Step: 2
Training loss: 3.187974452972412
Validation loss: 2.2709241041573147

Epoch: 6| Step: 3
Training loss: 2.848872423171997
Validation loss: 2.286486828198997

Epoch: 6| Step: 4
Training loss: 1.9827736616134644
Validation loss: 2.3007305155518236

Epoch: 6| Step: 5
Training loss: 3.020211696624756
Validation loss: 2.2998454827134327

Epoch: 6| Step: 6
Training loss: 1.9942651987075806
Validation loss: 2.284167117969964

Epoch: 6| Step: 7
Training loss: 2.290083885192871
Validation loss: 2.273362551966021

Epoch: 6| Step: 8
Training loss: 1.8455203771591187
Validation loss: 2.27022748608743

Epoch: 6| Step: 9
Training loss: 2.394365072250366
Validation loss: 2.2656361441458426

Epoch: 6| Step: 10
Training loss: 2.626053810119629
Validation loss: 2.2635061817784465

Epoch: 6| Step: 11
Training loss: 1.6187759637832642
Validation loss: 2.265844909093713

Epoch: 6| Step: 12
Training loss: 2.2894582748413086
Validation loss: 2.2703603544542865

Epoch: 6| Step: 13
Training loss: 2.8802008628845215
Validation loss: 2.278517674374324

Epoch: 321| Step: 0
Training loss: 3.0379509925842285
Validation loss: 2.2703498486549623

Epoch: 6| Step: 1
Training loss: 2.384476661682129
Validation loss: 2.272651308326311

Epoch: 6| Step: 2
Training loss: 2.7626523971557617
Validation loss: 2.283254959250009

Epoch: 6| Step: 3
Training loss: 2.8016200065612793
Validation loss: 2.2702919693403345

Epoch: 6| Step: 4
Training loss: 2.7243857383728027
Validation loss: 2.2724332860721055

Epoch: 6| Step: 5
Training loss: 2.440615653991699
Validation loss: 2.2754767915253997

Epoch: 6| Step: 6
Training loss: 2.4901223182678223
Validation loss: 2.2907008227481636

Epoch: 6| Step: 7
Training loss: 2.052043914794922
Validation loss: 2.3053464222979803

Epoch: 6| Step: 8
Training loss: 2.714113712310791
Validation loss: 2.322568480686475

Epoch: 6| Step: 9
Training loss: 1.7875902652740479
Validation loss: 2.3030859449858307

Epoch: 6| Step: 10
Training loss: 3.247309923171997
Validation loss: 2.2939810240140526

Epoch: 6| Step: 11
Training loss: 0.8189700245857239
Validation loss: 2.291887644798525

Epoch: 6| Step: 12
Training loss: 1.5210304260253906
Validation loss: 2.284044340092649

Epoch: 6| Step: 13
Training loss: 2.501948356628418
Validation loss: 2.2632070510618147

Epoch: 322| Step: 0
Training loss: 2.6155505180358887
Validation loss: 2.254635300687564

Epoch: 6| Step: 1
Training loss: 2.2495875358581543
Validation loss: 2.2571619915705856

Epoch: 6| Step: 2
Training loss: 3.0121235847473145
Validation loss: 2.2487466617297103

Epoch: 6| Step: 3
Training loss: 3.1070170402526855
Validation loss: 2.2437279506396224

Epoch: 6| Step: 4
Training loss: 2.6006903648376465
Validation loss: 2.2417917482314573

Epoch: 6| Step: 5
Training loss: 1.9515074491500854
Validation loss: 2.236524979273478

Epoch: 6| Step: 6
Training loss: 2.617277145385742
Validation loss: 2.240527319651778

Epoch: 6| Step: 7
Training loss: 2.3223111629486084
Validation loss: 2.244659016209264

Epoch: 6| Step: 8
Training loss: 1.9059858322143555
Validation loss: 2.2548359465855423

Epoch: 6| Step: 9
Training loss: 2.1997454166412354
Validation loss: 2.2638944477163334

Epoch: 6| Step: 10
Training loss: 2.6974830627441406
Validation loss: 2.292157489766357

Epoch: 6| Step: 11
Training loss: 2.67948055267334
Validation loss: 2.2946053422907347

Epoch: 6| Step: 12
Training loss: 1.268450379371643
Validation loss: 2.2920010858966458

Epoch: 6| Step: 13
Training loss: 1.9608898162841797
Validation loss: 2.2776260914341098

Epoch: 323| Step: 0
Training loss: 2.7680559158325195
Validation loss: 2.2643690365616993

Epoch: 6| Step: 1
Training loss: 2.6743791103363037
Validation loss: 2.2606851029139694

Epoch: 6| Step: 2
Training loss: 2.5765833854675293
Validation loss: 2.246116779183829

Epoch: 6| Step: 3
Training loss: 2.244863271713257
Validation loss: 2.2498165484397643

Epoch: 6| Step: 4
Training loss: 3.285037040710449
Validation loss: 2.2629717319242415

Epoch: 6| Step: 5
Training loss: 2.1930904388427734
Validation loss: 2.269858180835683

Epoch: 6| Step: 6
Training loss: 2.501950263977051
Validation loss: 2.2759763015213834

Epoch: 6| Step: 7
Training loss: 1.7878042459487915
Validation loss: 2.2553281732784805

Epoch: 6| Step: 8
Training loss: 2.131887912750244
Validation loss: 2.2654525208216842

Epoch: 6| Step: 9
Training loss: 2.332909107208252
Validation loss: 2.24566912651062

Epoch: 6| Step: 10
Training loss: 2.5592198371887207
Validation loss: 2.2589231024506273

Epoch: 6| Step: 11
Training loss: 2.261596918106079
Validation loss: 2.2728173040574595

Epoch: 6| Step: 12
Training loss: 2.1421689987182617
Validation loss: 2.3036566011367308

Epoch: 6| Step: 13
Training loss: 1.5527609586715698
Validation loss: 2.319859148353659

Epoch: 324| Step: 0
Training loss: 2.476818084716797
Validation loss: 2.352602243423462

Epoch: 6| Step: 1
Training loss: 2.535576343536377
Validation loss: 2.3694888596893637

Epoch: 6| Step: 2
Training loss: 2.1863584518432617
Validation loss: 2.3611564790048907

Epoch: 6| Step: 3
Training loss: 1.9589951038360596
Validation loss: 2.368108223843318

Epoch: 6| Step: 4
Training loss: 2.5850486755371094
Validation loss: 2.34565624883098

Epoch: 6| Step: 5
Training loss: 2.3997387886047363
Validation loss: 2.3149287059742916

Epoch: 6| Step: 6
Training loss: 2.627095937728882
Validation loss: 2.2934474124703357

Epoch: 6| Step: 7
Training loss: 2.5018551349639893
Validation loss: 2.28132184602881

Epoch: 6| Step: 8
Training loss: 2.1939640045166016
Validation loss: 2.2831735816053165

Epoch: 6| Step: 9
Training loss: 1.9405862092971802
Validation loss: 2.2593836066543416

Epoch: 6| Step: 10
Training loss: 2.2942373752593994
Validation loss: 2.2408660406707437

Epoch: 6| Step: 11
Training loss: 3.3441271781921387
Validation loss: 2.2420714542429936

Epoch: 6| Step: 12
Training loss: 1.813633680343628
Validation loss: 2.224018927543394

Epoch: 6| Step: 13
Training loss: 3.0395407676696777
Validation loss: 2.2157636355328303

Epoch: 325| Step: 0
Training loss: 2.050832986831665
Validation loss: 2.2137754066016084

Epoch: 6| Step: 1
Training loss: 2.630714178085327
Validation loss: 2.20650061227942

Epoch: 6| Step: 2
Training loss: 2.477930784225464
Validation loss: 2.208371739233694

Epoch: 6| Step: 3
Training loss: 2.8097002506256104
Validation loss: 2.2097418462076495

Epoch: 6| Step: 4
Training loss: 2.242767333984375
Validation loss: 2.2243625861342236

Epoch: 6| Step: 5
Training loss: 2.5694758892059326
Validation loss: 2.242035024909563

Epoch: 6| Step: 6
Training loss: 2.7243220806121826
Validation loss: 2.244564390951587

Epoch: 6| Step: 7
Training loss: 1.8167238235473633
Validation loss: 2.2607728409510788

Epoch: 6| Step: 8
Training loss: 2.7423763275146484
Validation loss: 2.275791980886972

Epoch: 6| Step: 9
Training loss: 2.4083709716796875
Validation loss: 2.272028925598309

Epoch: 6| Step: 10
Training loss: 2.5392117500305176
Validation loss: 2.284090344623853

Epoch: 6| Step: 11
Training loss: 2.1327428817749023
Validation loss: 2.284709563819311

Epoch: 6| Step: 12
Training loss: 1.6354169845581055
Validation loss: 2.2763725301270843

Epoch: 6| Step: 13
Training loss: 2.4554853439331055
Validation loss: 2.274394184030512

Epoch: 326| Step: 0
Training loss: 2.6409740447998047
Validation loss: 2.2708992983705256

Epoch: 6| Step: 1
Training loss: 2.97530460357666
Validation loss: 2.2797089674139537

Epoch: 6| Step: 2
Training loss: 2.5101962089538574
Validation loss: 2.2572809521869948

Epoch: 6| Step: 3
Training loss: 3.080066204071045
Validation loss: 2.2667096609710367

Epoch: 6| Step: 4
Training loss: 1.8835127353668213
Validation loss: 2.262931634021062

Epoch: 6| Step: 5
Training loss: 1.8582050800323486
Validation loss: 2.2611216088776946

Epoch: 6| Step: 6
Training loss: 2.622066020965576
Validation loss: 2.261176311841575

Epoch: 6| Step: 7
Training loss: 2.401348114013672
Validation loss: 2.271654216192102

Epoch: 6| Step: 8
Training loss: 2.712385892868042
Validation loss: 2.2564495020015265

Epoch: 6| Step: 9
Training loss: 1.7614890336990356
Validation loss: 2.248631200482768

Epoch: 6| Step: 10
Training loss: 2.3265364170074463
Validation loss: 2.253536967821019

Epoch: 6| Step: 11
Training loss: 1.5727872848510742
Validation loss: 2.2531773633854364

Epoch: 6| Step: 12
Training loss: 2.466729164123535
Validation loss: 2.236524453727148

Epoch: 6| Step: 13
Training loss: 2.0980138778686523
Validation loss: 2.221275447517313

Epoch: 327| Step: 0
Training loss: 2.2857770919799805
Validation loss: 2.241141524366153

Epoch: 6| Step: 1
Training loss: 2.152726650238037
Validation loss: 2.243382538518598

Epoch: 6| Step: 2
Training loss: 1.8070569038391113
Validation loss: 2.2573353423867175

Epoch: 6| Step: 3
Training loss: 3.040396213531494
Validation loss: 2.2420933272248957

Epoch: 6| Step: 4
Training loss: 2.347280740737915
Validation loss: 2.239779669751403

Epoch: 6| Step: 5
Training loss: 2.5533876419067383
Validation loss: 2.250729348069878

Epoch: 6| Step: 6
Training loss: 1.8583619594573975
Validation loss: 2.262329439963064

Epoch: 6| Step: 7
Training loss: 2.5869975090026855
Validation loss: 2.276695159173781

Epoch: 6| Step: 8
Training loss: 2.631730556488037
Validation loss: 2.297549698942451

Epoch: 6| Step: 9
Training loss: 2.280109405517578
Validation loss: 2.3215653614331315

Epoch: 6| Step: 10
Training loss: 2.545097827911377
Validation loss: 2.3488120827623593

Epoch: 6| Step: 11
Training loss: 2.0165774822235107
Validation loss: 2.3505452602140364

Epoch: 6| Step: 12
Training loss: 2.31897234916687
Validation loss: 2.3711089241889214

Epoch: 6| Step: 13
Training loss: 3.064683198928833
Validation loss: 2.354015427251016

Epoch: 328| Step: 0
Training loss: 2.1830005645751953
Validation loss: 2.3468620443856842

Epoch: 6| Step: 1
Training loss: 2.655592203140259
Validation loss: 2.3407122191562446

Epoch: 6| Step: 2
Training loss: 2.4326372146606445
Validation loss: 2.3158024562302457

Epoch: 6| Step: 3
Training loss: 2.6650192737579346
Validation loss: 2.3059426802460865

Epoch: 6| Step: 4
Training loss: 2.778923988342285
Validation loss: 2.2972505464348743

Epoch: 6| Step: 5
Training loss: 1.0853123664855957
Validation loss: 2.2671215252209733

Epoch: 6| Step: 6
Training loss: 2.620645523071289
Validation loss: 2.2530970701607327

Epoch: 6| Step: 7
Training loss: 2.425933599472046
Validation loss: 2.2359700202941895

Epoch: 6| Step: 8
Training loss: 2.7853753566741943
Validation loss: 2.2249842074609574

Epoch: 6| Step: 9
Training loss: 2.239668130874634
Validation loss: 2.2228878903132614

Epoch: 6| Step: 10
Training loss: 1.876826524734497
Validation loss: 2.2004332542419434

Epoch: 6| Step: 11
Training loss: 3.1880581378936768
Validation loss: 2.203654235409152

Epoch: 6| Step: 12
Training loss: 1.8166351318359375
Validation loss: 2.217858688805693

Epoch: 6| Step: 13
Training loss: 2.4531500339508057
Validation loss: 2.2158450029229604

Epoch: 329| Step: 0
Training loss: 2.2616395950317383
Validation loss: 2.2333648076621433

Epoch: 6| Step: 1
Training loss: 1.9334356784820557
Validation loss: 2.222767987558919

Epoch: 6| Step: 2
Training loss: 2.1913533210754395
Validation loss: 2.2337342205867974

Epoch: 6| Step: 3
Training loss: 2.813237190246582
Validation loss: 2.239461165602489

Epoch: 6| Step: 4
Training loss: 2.3417465686798096
Validation loss: 2.2581209405775993

Epoch: 6| Step: 5
Training loss: 2.3918545246124268
Validation loss: 2.2614838077176

Epoch: 6| Step: 6
Training loss: 2.9986560344696045
Validation loss: 2.2743951248866257

Epoch: 6| Step: 7
Training loss: 1.5903764963150024
Validation loss: 2.2869162431327243

Epoch: 6| Step: 8
Training loss: 1.9064183235168457
Validation loss: 2.2910406820235716

Epoch: 6| Step: 9
Training loss: 2.0031235218048096
Validation loss: 2.277133067448934

Epoch: 6| Step: 10
Training loss: 1.7202956676483154
Validation loss: 2.2612581637597855

Epoch: 6| Step: 11
Training loss: 3.3089981079101562
Validation loss: 2.2590080538103656

Epoch: 6| Step: 12
Training loss: 3.0529909133911133
Validation loss: 2.260642018369449

Epoch: 6| Step: 13
Training loss: 2.4439074993133545
Validation loss: 2.2556471209372244

Epoch: 330| Step: 0
Training loss: 2.4170756340026855
Validation loss: 2.258770219741329

Epoch: 6| Step: 1
Training loss: 2.0215883255004883
Validation loss: 2.263516095376784

Epoch: 6| Step: 2
Training loss: 2.1544487476348877
Validation loss: 2.262434226210399

Epoch: 6| Step: 3
Training loss: 2.6027169227600098
Validation loss: 2.2696977943502445

Epoch: 6| Step: 4
Training loss: 1.967603325843811
Validation loss: 2.2741657918499363

Epoch: 6| Step: 5
Training loss: 2.486687183380127
Validation loss: 2.279535747343494

Epoch: 6| Step: 6
Training loss: 2.464972972869873
Validation loss: 2.2750881666778238

Epoch: 6| Step: 7
Training loss: 2.6851744651794434
Validation loss: 2.2713560340225056

Epoch: 6| Step: 8
Training loss: 2.2374181747436523
Validation loss: 2.2733970816417406

Epoch: 6| Step: 9
Training loss: 2.2837414741516113
Validation loss: 2.2524259526242494

Epoch: 6| Step: 10
Training loss: 2.398080587387085
Validation loss: 2.2572951701379593

Epoch: 6| Step: 11
Training loss: 2.293217182159424
Validation loss: 2.257863885612898

Epoch: 6| Step: 12
Training loss: 2.418360710144043
Validation loss: 2.254601811849943

Epoch: 6| Step: 13
Training loss: 2.651754140853882
Validation loss: 2.2422810549377115

Epoch: 331| Step: 0
Training loss: 2.343614101409912
Validation loss: 2.2517337593981015

Epoch: 6| Step: 1
Training loss: 1.7743487358093262
Validation loss: 2.2576275333281486

Epoch: 6| Step: 2
Training loss: 1.6098971366882324
Validation loss: 2.271198388068907

Epoch: 6| Step: 3
Training loss: 2.201625108718872
Validation loss: 2.2719552465664443

Epoch: 6| Step: 4
Training loss: 2.7438623905181885
Validation loss: 2.2804896472602763

Epoch: 6| Step: 5
Training loss: 2.3123507499694824
Validation loss: 2.2719152063451786

Epoch: 6| Step: 6
Training loss: 2.2707386016845703
Validation loss: 2.2586938565777195

Epoch: 6| Step: 7
Training loss: 2.093968391418457
Validation loss: 2.2339479538702194

Epoch: 6| Step: 8
Training loss: 2.5853610038757324
Validation loss: 2.2506893270759174

Epoch: 6| Step: 9
Training loss: 2.068462610244751
Validation loss: 2.252655108769735

Epoch: 6| Step: 10
Training loss: 3.2383062839508057
Validation loss: 2.254332078400479

Epoch: 6| Step: 11
Training loss: 2.801258087158203
Validation loss: 2.2655903780332176

Epoch: 6| Step: 12
Training loss: 2.580075740814209
Validation loss: 2.2598822680852746

Epoch: 6| Step: 13
Training loss: 2.157870054244995
Validation loss: 2.2687764859968618

Epoch: 332| Step: 0
Training loss: 2.9936254024505615
Validation loss: 2.2721083612852198

Epoch: 6| Step: 1
Training loss: 2.2288424968719482
Validation loss: 2.2784722299985987

Epoch: 6| Step: 2
Training loss: 2.9180164337158203
Validation loss: 2.2862039432730725

Epoch: 6| Step: 3
Training loss: 2.219109296798706
Validation loss: 2.293049353425221

Epoch: 6| Step: 4
Training loss: 2.695359230041504
Validation loss: 2.2962161546112387

Epoch: 6| Step: 5
Training loss: 2.4296200275421143
Validation loss: 2.2991911724049556

Epoch: 6| Step: 6
Training loss: 2.0310585498809814
Validation loss: 2.331547624321394

Epoch: 6| Step: 7
Training loss: 2.5028562545776367
Validation loss: 2.3534831693095546

Epoch: 6| Step: 8
Training loss: 2.8197391033172607
Validation loss: 2.3377906891607467

Epoch: 6| Step: 9
Training loss: 1.767346739768982
Validation loss: 2.3123539006838234

Epoch: 6| Step: 10
Training loss: 1.8743116855621338
Validation loss: 2.2754474506583264

Epoch: 6| Step: 11
Training loss: 2.300746440887451
Validation loss: 2.249175871572187

Epoch: 6| Step: 12
Training loss: 1.3750951290130615
Validation loss: 2.247956968122913

Epoch: 6| Step: 13
Training loss: 3.1619653701782227
Validation loss: 2.2489915714469007

Epoch: 333| Step: 0
Training loss: 2.357578754425049
Validation loss: 2.2496370653952322

Epoch: 6| Step: 1
Training loss: 2.4454147815704346
Validation loss: 2.282906222087081

Epoch: 6| Step: 2
Training loss: 1.7451339960098267
Validation loss: 2.27792864717463

Epoch: 6| Step: 3
Training loss: 1.8375256061553955
Validation loss: 2.2852356741505284

Epoch: 6| Step: 4
Training loss: 2.5415902137756348
Validation loss: 2.274266440381286

Epoch: 6| Step: 5
Training loss: 2.332768440246582
Validation loss: 2.257385923016456

Epoch: 6| Step: 6
Training loss: 2.371058940887451
Validation loss: 2.263044754664103

Epoch: 6| Step: 7
Training loss: 1.9489707946777344
Validation loss: 2.248136205057944

Epoch: 6| Step: 8
Training loss: 2.9602231979370117
Validation loss: 2.248987941331761

Epoch: 6| Step: 9
Training loss: 1.828324794769287
Validation loss: 2.2553418528649116

Epoch: 6| Step: 10
Training loss: 2.5175795555114746
Validation loss: 2.2520633051472325

Epoch: 6| Step: 11
Training loss: 3.229808807373047
Validation loss: 2.258463639085011

Epoch: 6| Step: 12
Training loss: 2.666558265686035
Validation loss: 2.252618516645124

Epoch: 6| Step: 13
Training loss: 2.1869421005249023
Validation loss: 2.2511562121811735

Epoch: 334| Step: 0
Training loss: 2.3167877197265625
Validation loss: 2.251275938044312

Epoch: 6| Step: 1
Training loss: 1.5829544067382812
Validation loss: 2.2566572927659556

Epoch: 6| Step: 2
Training loss: 2.2580456733703613
Validation loss: 2.2555588804265505

Epoch: 6| Step: 3
Training loss: 2.011381149291992
Validation loss: 2.259501741778466

Epoch: 6| Step: 4
Training loss: 2.2422494888305664
Validation loss: 2.2681641168491815

Epoch: 6| Step: 5
Training loss: 2.5397908687591553
Validation loss: 2.2737814329003774

Epoch: 6| Step: 6
Training loss: 3.0436501502990723
Validation loss: 2.260899107943299

Epoch: 6| Step: 7
Training loss: 2.587200164794922
Validation loss: 2.2775598264509633

Epoch: 6| Step: 8
Training loss: 2.321668863296509
Validation loss: 2.2728185089685584

Epoch: 6| Step: 9
Training loss: 2.7448482513427734
Validation loss: 2.277633679810391

Epoch: 6| Step: 10
Training loss: 3.044520854949951
Validation loss: 2.2763021402461554

Epoch: 6| Step: 11
Training loss: 2.222604513168335
Validation loss: 2.2660029472843295

Epoch: 6| Step: 12
Training loss: 2.2159440517425537
Validation loss: 2.2660297463017125

Epoch: 6| Step: 13
Training loss: 1.157139539718628
Validation loss: 2.251700255178636

Epoch: 335| Step: 0
Training loss: 2.1327545642852783
Validation loss: 2.242240523779264

Epoch: 6| Step: 1
Training loss: 2.5657167434692383
Validation loss: 2.258200458301011

Epoch: 6| Step: 2
Training loss: 2.228362798690796
Validation loss: 2.2560778689640824

Epoch: 6| Step: 3
Training loss: 2.647047996520996
Validation loss: 2.269328263498122

Epoch: 6| Step: 4
Training loss: 1.808512568473816
Validation loss: 2.268825166968889

Epoch: 6| Step: 5
Training loss: 3.0201218128204346
Validation loss: 2.261105955287974

Epoch: 6| Step: 6
Training loss: 1.7866817712783813
Validation loss: 2.250627961210025

Epoch: 6| Step: 7
Training loss: 2.182244300842285
Validation loss: 2.246570952476994

Epoch: 6| Step: 8
Training loss: 2.7512686252593994
Validation loss: 2.233095807413901

Epoch: 6| Step: 9
Training loss: 2.1437807083129883
Validation loss: 2.233847133574947

Epoch: 6| Step: 10
Training loss: 2.126253843307495
Validation loss: 2.2409938637928297

Epoch: 6| Step: 11
Training loss: 2.2264997959136963
Validation loss: 2.2392427921295166

Epoch: 6| Step: 12
Training loss: 2.2835116386413574
Validation loss: 2.251997264482642

Epoch: 6| Step: 13
Training loss: 3.0850472450256348
Validation loss: 2.2572929218251216

Epoch: 336| Step: 0
Training loss: 2.1613211631774902
Validation loss: 2.2582832382571314

Epoch: 6| Step: 1
Training loss: 2.063542604446411
Validation loss: 2.2718336941093527

Epoch: 6| Step: 2
Training loss: 2.6689844131469727
Validation loss: 2.296285871536501

Epoch: 6| Step: 3
Training loss: 2.1882095336914062
Validation loss: 2.2934111946372577

Epoch: 6| Step: 4
Training loss: 2.7808220386505127
Validation loss: 2.289453742324665

Epoch: 6| Step: 5
Training loss: 1.8262354135513306
Validation loss: 2.2854745900759132

Epoch: 6| Step: 6
Training loss: 2.476569175720215
Validation loss: 2.2572054580975602

Epoch: 6| Step: 7
Training loss: 2.117072105407715
Validation loss: 2.244609150835263

Epoch: 6| Step: 8
Training loss: 1.853883147239685
Validation loss: 2.236302202747714

Epoch: 6| Step: 9
Training loss: 2.4062647819519043
Validation loss: 2.2388097163169616

Epoch: 6| Step: 10
Training loss: 2.5346598625183105
Validation loss: 2.22240024997342

Epoch: 6| Step: 11
Training loss: 2.525444746017456
Validation loss: 2.2508741040383615

Epoch: 6| Step: 12
Training loss: 2.598691463470459
Validation loss: 2.2543702535731818

Epoch: 6| Step: 13
Training loss: 3.3921618461608887
Validation loss: 2.2608466635468187

Epoch: 337| Step: 0
Training loss: 2.532240867614746
Validation loss: 2.245287015873899

Epoch: 6| Step: 1
Training loss: 2.814882755279541
Validation loss: 2.253064858016147

Epoch: 6| Step: 2
Training loss: 1.9000049829483032
Validation loss: 2.2600473665422007

Epoch: 6| Step: 3
Training loss: 2.1944761276245117
Validation loss: 2.274450271360336

Epoch: 6| Step: 4
Training loss: 2.4018068313598633
Validation loss: 2.293495883223831

Epoch: 6| Step: 5
Training loss: 2.2317566871643066
Validation loss: 2.2902516113814486

Epoch: 6| Step: 6
Training loss: 2.6955814361572266
Validation loss: 2.2837947927495486

Epoch: 6| Step: 7
Training loss: 1.794825553894043
Validation loss: 2.260905550372216

Epoch: 6| Step: 8
Training loss: 2.4109694957733154
Validation loss: 2.2624266378341185

Epoch: 6| Step: 9
Training loss: 2.345871686935425
Validation loss: 2.252410811762656

Epoch: 6| Step: 10
Training loss: 1.92777419090271
Validation loss: 2.2514486979412776

Epoch: 6| Step: 11
Training loss: 2.6764092445373535
Validation loss: 2.2427956904134443

Epoch: 6| Step: 12
Training loss: 2.462428569793701
Validation loss: 2.2333244303221345

Epoch: 6| Step: 13
Training loss: 2.2955322265625
Validation loss: 2.2334189927706154

Epoch: 338| Step: 0
Training loss: 1.986724615097046
Validation loss: 2.2199974906060005

Epoch: 6| Step: 1
Training loss: 2.3706796169281006
Validation loss: 2.226849535460113

Epoch: 6| Step: 2
Training loss: 2.291327476501465
Validation loss: 2.2232209431227816

Epoch: 6| Step: 3
Training loss: 2.1354219913482666
Validation loss: 2.2199264803240375

Epoch: 6| Step: 4
Training loss: 2.697762966156006
Validation loss: 2.2186609621970885

Epoch: 6| Step: 5
Training loss: 2.8631110191345215
Validation loss: 2.2264058923208587

Epoch: 6| Step: 6
Training loss: 2.2294869422912598
Validation loss: 2.2495848055808776

Epoch: 6| Step: 7
Training loss: 2.651721954345703
Validation loss: 2.268214605187857

Epoch: 6| Step: 8
Training loss: 2.3498616218566895
Validation loss: 2.269579877135574

Epoch: 6| Step: 9
Training loss: 1.7243905067443848
Validation loss: 2.281793155977803

Epoch: 6| Step: 10
Training loss: 1.6496047973632812
Validation loss: 2.2756052811940513

Epoch: 6| Step: 11
Training loss: 2.657275676727295
Validation loss: 2.30895984044639

Epoch: 6| Step: 12
Training loss: 2.2321062088012695
Validation loss: 2.3125509959395214

Epoch: 6| Step: 13
Training loss: 2.872537136077881
Validation loss: 2.2961735302402126

Epoch: 339| Step: 0
Training loss: 2.183002471923828
Validation loss: 2.2917178728247203

Epoch: 6| Step: 1
Training loss: 2.611506223678589
Validation loss: 2.2751509630551903

Epoch: 6| Step: 2
Training loss: 2.7976720333099365
Validation loss: 2.274960275619261

Epoch: 6| Step: 3
Training loss: 1.9885718822479248
Validation loss: 2.260471033793624

Epoch: 6| Step: 4
Training loss: 1.7191184759140015
Validation loss: 2.256837021919989

Epoch: 6| Step: 5
Training loss: 1.5609807968139648
Validation loss: 2.256738244846303

Epoch: 6| Step: 6
Training loss: 2.1626923084259033
Validation loss: 2.234306873813752

Epoch: 6| Step: 7
Training loss: 3.303309440612793
Validation loss: 2.2331297628341185

Epoch: 6| Step: 8
Training loss: 2.710911273956299
Validation loss: 2.221799314662974

Epoch: 6| Step: 9
Training loss: 2.4330227375030518
Validation loss: 2.2265946224171627

Epoch: 6| Step: 10
Training loss: 2.85373592376709
Validation loss: 2.2250722198076147

Epoch: 6| Step: 11
Training loss: 2.4089038372039795
Validation loss: 2.237733451269006

Epoch: 6| Step: 12
Training loss: 2.0379891395568848
Validation loss: 2.2331571630252305

Epoch: 6| Step: 13
Training loss: 1.387757420539856
Validation loss: 2.2417737002013833

Epoch: 340| Step: 0
Training loss: 2.983163356781006
Validation loss: 2.233828636907762

Epoch: 6| Step: 1
Training loss: 1.9116179943084717
Validation loss: 2.2333156626711608

Epoch: 6| Step: 2
Training loss: 2.2916359901428223
Validation loss: 2.22119547987497

Epoch: 6| Step: 3
Training loss: 2.7001335620880127
Validation loss: 2.2069150145335863

Epoch: 6| Step: 4
Training loss: 2.641674518585205
Validation loss: 2.2196725517190914

Epoch: 6| Step: 5
Training loss: 2.6689577102661133
Validation loss: 2.2112563810040875

Epoch: 6| Step: 6
Training loss: 2.1330344676971436
Validation loss: 2.2119163108128372

Epoch: 6| Step: 7
Training loss: 2.5524911880493164
Validation loss: 2.219874721701427

Epoch: 6| Step: 8
Training loss: 2.7432644367218018
Validation loss: 2.238348263566212

Epoch: 6| Step: 9
Training loss: 1.6027915477752686
Validation loss: 2.2408703527142926

Epoch: 6| Step: 10
Training loss: 2.252509593963623
Validation loss: 2.249331171794604

Epoch: 6| Step: 11
Training loss: 1.683445692062378
Validation loss: 2.254814750404768

Epoch: 6| Step: 12
Training loss: 2.3655142784118652
Validation loss: 2.2733991030723817

Epoch: 6| Step: 13
Training loss: 1.6913669109344482
Validation loss: 2.2721291101107033

Epoch: 341| Step: 0
Training loss: 2.4015579223632812
Validation loss: 2.2782085941683863

Epoch: 6| Step: 1
Training loss: 2.3208534717559814
Validation loss: 2.286593242358136

Epoch: 6| Step: 2
Training loss: 2.6331005096435547
Validation loss: 2.288761185061547

Epoch: 6| Step: 3
Training loss: 2.7225773334503174
Validation loss: 2.2967853417960544

Epoch: 6| Step: 4
Training loss: 1.8375709056854248
Validation loss: 2.3090040581200713

Epoch: 6| Step: 5
Training loss: 2.5409774780273438
Validation loss: 2.302764597759452

Epoch: 6| Step: 6
Training loss: 1.7787244319915771
Validation loss: 2.284595854820744

Epoch: 6| Step: 7
Training loss: 1.4244107007980347
Validation loss: 2.279302253518053

Epoch: 6| Step: 8
Training loss: 2.502608060836792
Validation loss: 2.2673075852855558

Epoch: 6| Step: 9
Training loss: 2.415785312652588
Validation loss: 2.247784763254145

Epoch: 6| Step: 10
Training loss: 2.6087985038757324
Validation loss: 2.230729892689695

Epoch: 6| Step: 11
Training loss: 2.7625856399536133
Validation loss: 2.2260193209494314

Epoch: 6| Step: 12
Training loss: 2.084718704223633
Validation loss: 2.21525102661502

Epoch: 6| Step: 13
Training loss: 2.461794137954712
Validation loss: 2.204687149293961

Epoch: 342| Step: 0
Training loss: 2.2539095878601074
Validation loss: 2.19833025111947

Epoch: 6| Step: 1
Training loss: 1.6703898906707764
Validation loss: 2.200925137407036

Epoch: 6| Step: 2
Training loss: 2.6934924125671387
Validation loss: 2.1992569610636723

Epoch: 6| Step: 3
Training loss: 2.6916604042053223
Validation loss: 2.197319148689188

Epoch: 6| Step: 4
Training loss: 1.5896390676498413
Validation loss: 2.208162917885729

Epoch: 6| Step: 5
Training loss: 2.085815668106079
Validation loss: 2.207650348704348

Epoch: 6| Step: 6
Training loss: 1.5956921577453613
Validation loss: 2.215627495960523

Epoch: 6| Step: 7
Training loss: 2.770063638687134
Validation loss: 2.2195120626880276

Epoch: 6| Step: 8
Training loss: 2.368727922439575
Validation loss: 2.223122714668192

Epoch: 6| Step: 9
Training loss: 2.378775119781494
Validation loss: 2.2324849610687583

Epoch: 6| Step: 10
Training loss: 2.494755983352661
Validation loss: 2.2481794280390583

Epoch: 6| Step: 11
Training loss: 2.901416301727295
Validation loss: 2.266016490997807

Epoch: 6| Step: 12
Training loss: 2.1129868030548096
Validation loss: 2.2573512984860327

Epoch: 6| Step: 13
Training loss: 3.2046725749969482
Validation loss: 2.259953050203221

Epoch: 343| Step: 0
Training loss: 1.9644969701766968
Validation loss: 2.255441922013478

Epoch: 6| Step: 1
Training loss: 2.5789341926574707
Validation loss: 2.2638338073607414

Epoch: 6| Step: 2
Training loss: 2.0384881496429443
Validation loss: 2.289898359647361

Epoch: 6| Step: 3
Training loss: 1.8025468587875366
Validation loss: 2.281275854315809

Epoch: 6| Step: 4
Training loss: 2.2613534927368164
Validation loss: 2.2657969279955794

Epoch: 6| Step: 5
Training loss: 2.229424238204956
Validation loss: 2.265917606251214

Epoch: 6| Step: 6
Training loss: 2.036942958831787
Validation loss: 2.263151417496384

Epoch: 6| Step: 7
Training loss: 2.650179386138916
Validation loss: 2.2541813042856034

Epoch: 6| Step: 8
Training loss: 2.0280685424804688
Validation loss: 2.2575198194032073

Epoch: 6| Step: 9
Training loss: 2.827742099761963
Validation loss: 2.224829137966197

Epoch: 6| Step: 10
Training loss: 1.956729769706726
Validation loss: 2.2038138322932745

Epoch: 6| Step: 11
Training loss: 2.589644432067871
Validation loss: 2.2104125458707093

Epoch: 6| Step: 12
Training loss: 2.7020163536071777
Validation loss: 2.209394524174352

Epoch: 6| Step: 13
Training loss: 2.8083648681640625
Validation loss: 2.2042784485765683

Epoch: 344| Step: 0
Training loss: 2.4885926246643066
Validation loss: 2.1983166779241254

Epoch: 6| Step: 1
Training loss: 2.166379451751709
Validation loss: 2.2044740235933693

Epoch: 6| Step: 2
Training loss: 1.9661500453948975
Validation loss: 2.2189694822475476

Epoch: 6| Step: 3
Training loss: 2.7981302738189697
Validation loss: 2.21435349218307

Epoch: 6| Step: 4
Training loss: 1.6732146739959717
Validation loss: 2.245723437237483

Epoch: 6| Step: 5
Training loss: 2.4827351570129395
Validation loss: 2.252007238326534

Epoch: 6| Step: 6
Training loss: 2.407465934753418
Validation loss: 2.258187564470435

Epoch: 6| Step: 7
Training loss: 2.1093058586120605
Validation loss: 2.2834773627660607

Epoch: 6| Step: 8
Training loss: 1.8059170246124268
Validation loss: 2.2994375203245427

Epoch: 6| Step: 9
Training loss: 2.3782272338867188
Validation loss: 2.301892057541878

Epoch: 6| Step: 10
Training loss: 2.3473119735717773
Validation loss: 2.2861517731861403

Epoch: 6| Step: 11
Training loss: 2.3939459323883057
Validation loss: 2.262252752498914

Epoch: 6| Step: 12
Training loss: 2.8514904975891113
Validation loss: 2.2534474147263395

Epoch: 6| Step: 13
Training loss: 2.537236213684082
Validation loss: 2.252488583646795

Epoch: 345| Step: 0
Training loss: 2.050572395324707
Validation loss: 2.2349470264168194

Epoch: 6| Step: 1
Training loss: 2.268866539001465
Validation loss: 2.2546722376218407

Epoch: 6| Step: 2
Training loss: 2.3052947521209717
Validation loss: 2.251968865753502

Epoch: 6| Step: 3
Training loss: 2.3684210777282715
Validation loss: 2.2578924009876866

Epoch: 6| Step: 4
Training loss: 1.7998229265213013
Validation loss: 2.2572240393648864

Epoch: 6| Step: 5
Training loss: 1.9507925510406494
Validation loss: 2.245366100342043

Epoch: 6| Step: 6
Training loss: 2.8191494941711426
Validation loss: 2.24961914554719

Epoch: 6| Step: 7
Training loss: 2.556550979614258
Validation loss: 2.237529639274843

Epoch: 6| Step: 8
Training loss: 2.3755440711975098
Validation loss: 2.229514436055255

Epoch: 6| Step: 9
Training loss: 1.7607063055038452
Validation loss: 2.2324368543522333

Epoch: 6| Step: 10
Training loss: 2.9149277210235596
Validation loss: 2.2435817180141324

Epoch: 6| Step: 11
Training loss: 2.5798890590667725
Validation loss: 2.257973112085814

Epoch: 6| Step: 12
Training loss: 2.4085898399353027
Validation loss: 2.2731159233277842

Epoch: 6| Step: 13
Training loss: 2.121285915374756
Validation loss: 2.2699388355337162

Epoch: 346| Step: 0
Training loss: 2.103043794631958
Validation loss: 2.2521249119953444

Epoch: 6| Step: 1
Training loss: 3.1312079429626465
Validation loss: 2.235936395583614

Epoch: 6| Step: 2
Training loss: 2.514425277709961
Validation loss: 2.2251719813193045

Epoch: 6| Step: 3
Training loss: 1.7612520456314087
Validation loss: 2.219227934396395

Epoch: 6| Step: 4
Training loss: 2.5935916900634766
Validation loss: 2.2261007729397027

Epoch: 6| Step: 5
Training loss: 2.116492748260498
Validation loss: 2.1929065796636764

Epoch: 6| Step: 6
Training loss: 1.891019582748413
Validation loss: 2.1915519019608856

Epoch: 6| Step: 7
Training loss: 2.4171831607818604
Validation loss: 2.1975300619679112

Epoch: 6| Step: 8
Training loss: 2.794281005859375
Validation loss: 2.1939220377193984

Epoch: 6| Step: 9
Training loss: 2.1630640029907227
Validation loss: 2.208582308984572

Epoch: 6| Step: 10
Training loss: 2.1721725463867188
Validation loss: 2.2124637198704544

Epoch: 6| Step: 11
Training loss: 2.7981128692626953
Validation loss: 2.217248314170427

Epoch: 6| Step: 12
Training loss: 1.2608797550201416
Validation loss: 2.229732342945632

Epoch: 6| Step: 13
Training loss: 2.6344919204711914
Validation loss: 2.2369414401310745

Epoch: 347| Step: 0
Training loss: 1.5903085470199585
Validation loss: 2.240706177167995

Epoch: 6| Step: 1
Training loss: 2.2509512901306152
Validation loss: 2.2440853349624144

Epoch: 6| Step: 2
Training loss: 2.9263079166412354
Validation loss: 2.2566340354181107

Epoch: 6| Step: 3
Training loss: 1.9247651100158691
Validation loss: 2.2607456996876705

Epoch: 6| Step: 4
Training loss: 1.9361796379089355
Validation loss: 2.279634287280421

Epoch: 6| Step: 5
Training loss: 2.5751473903656006
Validation loss: 2.290543240885581

Epoch: 6| Step: 6
Training loss: 2.788588047027588
Validation loss: 2.28898988744264

Epoch: 6| Step: 7
Training loss: 2.156524419784546
Validation loss: 2.306966721370656

Epoch: 6| Step: 8
Training loss: 2.827862501144409
Validation loss: 2.2920728780890025

Epoch: 6| Step: 9
Training loss: 2.2390201091766357
Validation loss: 2.2867644781707437

Epoch: 6| Step: 10
Training loss: 2.728067636489868
Validation loss: 2.2836228775721725

Epoch: 6| Step: 11
Training loss: 2.495588779449463
Validation loss: 2.2711686767557615

Epoch: 6| Step: 12
Training loss: 1.189372181892395
Validation loss: 2.2729945682710215

Epoch: 6| Step: 13
Training loss: 2.7764124870300293
Validation loss: 2.234836329695999

Epoch: 348| Step: 0
Training loss: 2.123626947402954
Validation loss: 2.2324465936230076

Epoch: 6| Step: 1
Training loss: 1.8412110805511475
Validation loss: 2.2155613565957673

Epoch: 6| Step: 2
Training loss: 2.634199619293213
Validation loss: 2.2165261442943285

Epoch: 6| Step: 3
Training loss: 2.728146553039551
Validation loss: 2.225658760275892

Epoch: 6| Step: 4
Training loss: 2.3071646690368652
Validation loss: 2.216127029029272

Epoch: 6| Step: 5
Training loss: 2.32310152053833
Validation loss: 2.216786511482731

Epoch: 6| Step: 6
Training loss: 1.8073177337646484
Validation loss: 2.2040750313830633

Epoch: 6| Step: 7
Training loss: 2.255293130874634
Validation loss: 2.2129119057809152

Epoch: 6| Step: 8
Training loss: 2.5016870498657227
Validation loss: 2.223211755034744

Epoch: 6| Step: 9
Training loss: 2.1636319160461426
Validation loss: 2.219264168893137

Epoch: 6| Step: 10
Training loss: 2.7164270877838135
Validation loss: 2.2230091146243516

Epoch: 6| Step: 11
Training loss: 1.874181866645813
Validation loss: 2.2197173744119625

Epoch: 6| Step: 12
Training loss: 3.0123276710510254
Validation loss: 2.210422641487532

Epoch: 6| Step: 13
Training loss: 1.4258545637130737
Validation loss: 2.2088844186516217

Epoch: 349| Step: 0
Training loss: 2.7406725883483887
Validation loss: 2.2047671476999917

Epoch: 6| Step: 1
Training loss: 2.5922887325286865
Validation loss: 2.2015363964983212

Epoch: 6| Step: 2
Training loss: 2.0182299613952637
Validation loss: 2.2090124712195447

Epoch: 6| Step: 3
Training loss: 2.2372841835021973
Validation loss: 2.2061151150734193

Epoch: 6| Step: 4
Training loss: 2.2480814456939697
Validation loss: 2.2124344456580376

Epoch: 6| Step: 5
Training loss: 1.7784264087677002
Validation loss: 2.2312515140861593

Epoch: 6| Step: 6
Training loss: 2.8520050048828125
Validation loss: 2.2307370042288177

Epoch: 6| Step: 7
Training loss: 2.1829416751861572
Validation loss: 2.2278486080067132

Epoch: 6| Step: 8
Training loss: 1.8290431499481201
Validation loss: 2.2254654002446

Epoch: 6| Step: 9
Training loss: 2.3111414909362793
Validation loss: 2.211911465532036

Epoch: 6| Step: 10
Training loss: 2.05330753326416
Validation loss: 2.2083918151035102

Epoch: 6| Step: 11
Training loss: 3.206695556640625
Validation loss: 2.222974770812578

Epoch: 6| Step: 12
Training loss: 2.4229607582092285
Validation loss: 2.2248773856829573

Epoch: 6| Step: 13
Training loss: 0.917083203792572
Validation loss: 2.2324481548801547

Epoch: 350| Step: 0
Training loss: 2.0492849349975586
Validation loss: 2.2513482980830695

Epoch: 6| Step: 1
Training loss: 2.724278450012207
Validation loss: 2.2537675698598227

Epoch: 6| Step: 2
Training loss: 2.1193177700042725
Validation loss: 2.2658249998605378

Epoch: 6| Step: 3
Training loss: 1.6452696323394775
Validation loss: 2.269448111134191

Epoch: 6| Step: 4
Training loss: 1.5291005373001099
Validation loss: 2.27331793180076

Epoch: 6| Step: 5
Training loss: 3.2132229804992676
Validation loss: 2.2614515327638194

Epoch: 6| Step: 6
Training loss: 2.195596933364868
Validation loss: 2.2553870139583463

Epoch: 6| Step: 7
Training loss: 2.2532758712768555
Validation loss: 2.2526483587039414

Epoch: 6| Step: 8
Training loss: 2.6007795333862305
Validation loss: 2.2385643451444563

Epoch: 6| Step: 9
Training loss: 3.025808811187744
Validation loss: 2.2265776229161087

Epoch: 6| Step: 10
Training loss: 1.9364914894104004
Validation loss: 2.222623029062825

Epoch: 6| Step: 11
Training loss: 2.140557289123535
Validation loss: 2.2212929700010564

Epoch: 6| Step: 12
Training loss: 2.4635837078094482
Validation loss: 2.206739646132274

Epoch: 6| Step: 13
Training loss: 1.8793506622314453
Validation loss: 2.2300670018760105

Testing loss: 2.3934617201487223
