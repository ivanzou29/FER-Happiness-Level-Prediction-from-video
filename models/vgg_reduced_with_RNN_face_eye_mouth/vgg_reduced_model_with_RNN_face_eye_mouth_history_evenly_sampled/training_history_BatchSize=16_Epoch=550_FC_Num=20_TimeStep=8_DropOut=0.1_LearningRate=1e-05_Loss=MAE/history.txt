Epoch: 1| Step: 0
Training loss: 4.924693584442139
Validation loss: 5.092858099168347

Epoch: 6| Step: 1
Training loss: 4.723134994506836
Validation loss: 5.084200187395978

Epoch: 6| Step: 2
Training loss: 4.083110809326172
Validation loss: 5.07564309335524

Epoch: 6| Step: 3
Training loss: 4.491179466247559
Validation loss: 5.06662848687941

Epoch: 6| Step: 4
Training loss: 5.48246955871582
Validation loss: 5.057782870466991

Epoch: 6| Step: 5
Training loss: 5.360332012176514
Validation loss: 5.048342079244634

Epoch: 6| Step: 6
Training loss: 5.984997272491455
Validation loss: 5.0381575810012

Epoch: 6| Step: 7
Training loss: 5.188499450683594
Validation loss: 5.027574441766226

Epoch: 6| Step: 8
Training loss: 5.226434707641602
Validation loss: 5.015986586129793

Epoch: 6| Step: 9
Training loss: 5.384247779846191
Validation loss: 5.003374525295791

Epoch: 6| Step: 10
Training loss: 3.7264935970306396
Validation loss: 4.989604098822481

Epoch: 6| Step: 11
Training loss: 5.702197074890137
Validation loss: 4.974863944515105

Epoch: 6| Step: 12
Training loss: 3.1652026176452637
Validation loss: 4.959641056676065

Epoch: 6| Step: 13
Training loss: 3.564619302749634
Validation loss: 4.942740358332152

Epoch: 2| Step: 0
Training loss: 4.86163330078125
Validation loss: 4.924279028369535

Epoch: 6| Step: 1
Training loss: 5.169108867645264
Validation loss: 4.905077477937104

Epoch: 6| Step: 2
Training loss: 5.625152111053467
Validation loss: 4.884423294375019

Epoch: 6| Step: 3
Training loss: 5.1662492752075195
Validation loss: 4.86131344303008

Epoch: 6| Step: 4
Training loss: 4.265016078948975
Validation loss: 4.838202015046151

Epoch: 6| Step: 5
Training loss: 4.599147796630859
Validation loss: 4.811827808298091

Epoch: 6| Step: 6
Training loss: 5.909243583679199
Validation loss: 4.78572323501751

Epoch: 6| Step: 7
Training loss: 4.910135746002197
Validation loss: 4.757090609560731

Epoch: 6| Step: 8
Training loss: 4.0462327003479
Validation loss: 4.727195093708653

Epoch: 6| Step: 9
Training loss: 4.857665061950684
Validation loss: 4.696922127918531

Epoch: 6| Step: 10
Training loss: 4.9137115478515625
Validation loss: 4.6646769533875165

Epoch: 6| Step: 11
Training loss: 2.8893685340881348
Validation loss: 4.6320305178242345

Epoch: 6| Step: 12
Training loss: 1.9631527662277222
Validation loss: 4.597248964412238

Epoch: 6| Step: 13
Training loss: 4.668153762817383
Validation loss: 4.562290581323767

Epoch: 3| Step: 0
Training loss: 4.068682670593262
Validation loss: 4.526183441121091

Epoch: 6| Step: 1
Training loss: 3.4698896408081055
Validation loss: 4.487310127545428

Epoch: 6| Step: 2
Training loss: 4.0485382080078125
Validation loss: 4.448142328569966

Epoch: 6| Step: 3
Training loss: 3.663856267929077
Validation loss: 4.4060107918195826

Epoch: 6| Step: 4
Training loss: 3.880068063735962
Validation loss: 4.364488173556584

Epoch: 6| Step: 5
Training loss: 3.079349994659424
Validation loss: 4.322092799730198

Epoch: 6| Step: 6
Training loss: 6.1699018478393555
Validation loss: 4.2809897699663715

Epoch: 6| Step: 7
Training loss: 4.190873146057129
Validation loss: 4.240134987779843

Epoch: 6| Step: 8
Training loss: 4.243020057678223
Validation loss: 4.200198637541904

Epoch: 6| Step: 9
Training loss: 3.2267823219299316
Validation loss: 4.162158196972262

Epoch: 6| Step: 10
Training loss: 4.862971782684326
Validation loss: 4.1260833022415

Epoch: 6| Step: 11
Training loss: 3.7097532749176025
Validation loss: 4.090897431937597

Epoch: 6| Step: 12
Training loss: 4.829355239868164
Validation loss: 4.055299210292037

Epoch: 6| Step: 13
Training loss: 3.694634437561035
Validation loss: 4.020936732651085

Epoch: 4| Step: 0
Training loss: 2.6063523292541504
Validation loss: 3.9896582377854215

Epoch: 6| Step: 1
Training loss: 4.893258571624756
Validation loss: 3.9592975390854703

Epoch: 6| Step: 2
Training loss: 4.92962121963501
Validation loss: 3.9315990683852986

Epoch: 6| Step: 3
Training loss: 3.278474807739258
Validation loss: 3.9063553502482753

Epoch: 6| Step: 4
Training loss: 2.94682240486145
Validation loss: 3.883113614974483

Epoch: 6| Step: 5
Training loss: 3.363739490509033
Validation loss: 3.8589983832451606

Epoch: 6| Step: 6
Training loss: 3.2994813919067383
Validation loss: 3.836264305217292

Epoch: 6| Step: 7
Training loss: 3.279264211654663
Validation loss: 3.8117817191667456

Epoch: 6| Step: 8
Training loss: 4.380134582519531
Validation loss: 3.790264262947985

Epoch: 6| Step: 9
Training loss: 3.2285006046295166
Validation loss: 3.7672837062548568

Epoch: 6| Step: 10
Training loss: 4.360614776611328
Validation loss: 3.745369583047846

Epoch: 6| Step: 11
Training loss: 3.6392626762390137
Validation loss: 3.7256281529703448

Epoch: 6| Step: 12
Training loss: 3.7335779666900635
Validation loss: 3.70684471438008

Epoch: 6| Step: 13
Training loss: 4.368266582489014
Validation loss: 3.6891399224599204

Epoch: 5| Step: 0
Training loss: 3.380579710006714
Validation loss: 3.678756570303312

Epoch: 6| Step: 1
Training loss: 2.461688995361328
Validation loss: 3.6676556602601083

Epoch: 6| Step: 2
Training loss: 3.2396745681762695
Validation loss: 3.6517855121243383

Epoch: 6| Step: 3
Training loss: 4.049856185913086
Validation loss: 3.6338873627365276

Epoch: 6| Step: 4
Training loss: 4.159295082092285
Validation loss: 3.612048113217918

Epoch: 6| Step: 5
Training loss: 3.1885738372802734
Validation loss: 3.59678251512589

Epoch: 6| Step: 6
Training loss: 3.146672248840332
Validation loss: 3.590665130205052

Epoch: 6| Step: 7
Training loss: 4.249070644378662
Validation loss: 3.57711382578778

Epoch: 6| Step: 8
Training loss: 3.8855581283569336
Validation loss: 3.559544224892893

Epoch: 6| Step: 9
Training loss: 3.1570920944213867
Validation loss: 3.543895185634654

Epoch: 6| Step: 10
Training loss: 3.5643484592437744
Validation loss: 3.5287739640922955

Epoch: 6| Step: 11
Training loss: 3.48142671585083
Validation loss: 3.5122599755564043

Epoch: 6| Step: 12
Training loss: 3.1875152587890625
Validation loss: 3.497196287237188

Epoch: 6| Step: 13
Training loss: 4.050477504730225
Validation loss: 3.483393830637778

Epoch: 6| Step: 0
Training loss: 3.775266170501709
Validation loss: 3.473868329037902

Epoch: 6| Step: 1
Training loss: 2.8949074745178223
Validation loss: 3.4607441732960362

Epoch: 6| Step: 2
Training loss: 3.702949047088623
Validation loss: 3.448300669270177

Epoch: 6| Step: 3
Training loss: 2.788222312927246
Validation loss: 3.4381072187936432

Epoch: 6| Step: 4
Training loss: 3.324252128601074
Validation loss: 3.4264733893896944

Epoch: 6| Step: 5
Training loss: 4.2067461013793945
Validation loss: 3.4139271833563365

Epoch: 6| Step: 6
Training loss: 3.968270778656006
Validation loss: 3.4047439277813

Epoch: 6| Step: 7
Training loss: 3.802786350250244
Validation loss: 3.39303490167023

Epoch: 6| Step: 8
Training loss: 3.7205982208251953
Validation loss: 3.381925041957568

Epoch: 6| Step: 9
Training loss: 2.9359710216522217
Validation loss: 3.3714135026419036

Epoch: 6| Step: 10
Training loss: 2.5796868801116943
Validation loss: 3.3645087518999652

Epoch: 6| Step: 11
Training loss: 3.607093572616577
Validation loss: 3.3622817608617965

Epoch: 6| Step: 12
Training loss: 2.7916910648345947
Validation loss: 3.348073240249388

Epoch: 6| Step: 13
Training loss: 2.635164737701416
Validation loss: 3.337995513792961

Epoch: 7| Step: 0
Training loss: 2.9191718101501465
Validation loss: 3.3315742451657533

Epoch: 6| Step: 1
Training loss: 3.666961431503296
Validation loss: 3.3197516523381716

Epoch: 6| Step: 2
Training loss: 2.7260961532592773
Validation loss: 3.312117217689432

Epoch: 6| Step: 3
Training loss: 3.427379608154297
Validation loss: 3.308826167096374

Epoch: 6| Step: 4
Training loss: 2.4827651977539062
Validation loss: 3.2904390109482633

Epoch: 6| Step: 5
Training loss: 2.5549874305725098
Validation loss: 3.2875414279199417

Epoch: 6| Step: 6
Training loss: 3.9290785789489746
Validation loss: 3.2829935499416885

Epoch: 6| Step: 7
Training loss: 2.5763401985168457
Validation loss: 3.268233453073809

Epoch: 6| Step: 8
Training loss: 3.058669328689575
Validation loss: 3.257273366374354

Epoch: 6| Step: 9
Training loss: 3.184492588043213
Validation loss: 3.2406339312112458

Epoch: 6| Step: 10
Training loss: 5.15422248840332
Validation loss: 3.2311659935981996

Epoch: 6| Step: 11
Training loss: 3.0987532138824463
Validation loss: 3.222084060792

Epoch: 6| Step: 12
Training loss: 3.471658706665039
Validation loss: 3.218412655656056

Epoch: 6| Step: 13
Training loss: 3.24770188331604
Validation loss: 3.2135817773880495

Epoch: 8| Step: 0
Training loss: 3.065519094467163
Validation loss: 3.2079206025728615

Epoch: 6| Step: 1
Training loss: 4.011693000793457
Validation loss: 3.2007019442896687

Epoch: 6| Step: 2
Training loss: 2.514362335205078
Validation loss: 3.1915646778639926

Epoch: 6| Step: 3
Training loss: 2.6630020141601562
Validation loss: 3.1846804952108734

Epoch: 6| Step: 4
Training loss: 2.8818631172180176
Validation loss: 3.1750506329280075

Epoch: 6| Step: 5
Training loss: 2.7543387413024902
Validation loss: 3.168157595460133

Epoch: 6| Step: 6
Training loss: 3.727714776992798
Validation loss: 3.163926891101304

Epoch: 6| Step: 7
Training loss: 2.070521354675293
Validation loss: 3.1577092627043366

Epoch: 6| Step: 8
Training loss: 2.9609501361846924
Validation loss: 3.1506928577218005

Epoch: 6| Step: 9
Training loss: 2.7717909812927246
Validation loss: 3.14412514368693

Epoch: 6| Step: 10
Training loss: 3.3947880268096924
Validation loss: 3.1364875762693343

Epoch: 6| Step: 11
Training loss: 3.9735124111175537
Validation loss: 3.130513734714959

Epoch: 6| Step: 12
Training loss: 3.8624935150146484
Validation loss: 3.125246532501713

Epoch: 6| Step: 13
Training loss: 4.148069381713867
Validation loss: 3.122026192244663

Epoch: 9| Step: 0
Training loss: 2.368581771850586
Validation loss: 3.1178010202223256

Epoch: 6| Step: 1
Training loss: 4.033354759216309
Validation loss: 3.127903522983674

Epoch: 6| Step: 2
Training loss: 3.18247652053833
Validation loss: 3.100643104122531

Epoch: 6| Step: 3
Training loss: 2.4780421257019043
Validation loss: 3.0988739613563783

Epoch: 6| Step: 4
Training loss: 3.6928274631500244
Validation loss: 3.097349336070399

Epoch: 6| Step: 5
Training loss: 3.1655032634735107
Validation loss: 3.096123413373065

Epoch: 6| Step: 6
Training loss: 3.688145875930786
Validation loss: 3.0954990694599767

Epoch: 6| Step: 7
Training loss: 3.048022747039795
Validation loss: 3.0912207172762964

Epoch: 6| Step: 8
Training loss: 3.3706440925598145
Validation loss: 3.0890917983106387

Epoch: 6| Step: 9
Training loss: 2.8769631385803223
Validation loss: 3.0833693576115433

Epoch: 6| Step: 10
Training loss: 2.8046202659606934
Validation loss: 3.078286555505568

Epoch: 6| Step: 11
Training loss: 2.8065528869628906
Validation loss: 3.071027445536788

Epoch: 6| Step: 12
Training loss: 2.85996150970459
Validation loss: 3.06313411138391

Epoch: 6| Step: 13
Training loss: 3.510831117630005
Validation loss: 3.0602640516014508

Epoch: 10| Step: 0
Training loss: 2.618459701538086
Validation loss: 3.053801187904932

Epoch: 6| Step: 1
Training loss: 2.3473238945007324
Validation loss: 3.0530357437749065

Epoch: 6| Step: 2
Training loss: 3.248953342437744
Validation loss: 3.0491598549709527

Epoch: 6| Step: 3
Training loss: 3.18768572807312
Validation loss: 3.0359655016212055

Epoch: 6| Step: 4
Training loss: 2.915308713912964
Validation loss: 3.026919716147966

Epoch: 6| Step: 5
Training loss: 2.9056732654571533
Validation loss: 3.019471635100662

Epoch: 6| Step: 6
Training loss: 3.1176834106445312
Validation loss: 3.0156247974723898

Epoch: 6| Step: 7
Training loss: 2.834834098815918
Validation loss: 3.0216387856391167

Epoch: 6| Step: 8
Training loss: 3.0725903511047363
Validation loss: 3.0192683332709858

Epoch: 6| Step: 9
Training loss: 2.6898584365844727
Validation loss: 3.0110132284061883

Epoch: 6| Step: 10
Training loss: 3.7262420654296875
Validation loss: 3.002878559532986

Epoch: 6| Step: 11
Training loss: 2.4906041622161865
Validation loss: 2.9897776060206915

Epoch: 6| Step: 12
Training loss: 4.269783020019531
Validation loss: 2.9890305816486316

Epoch: 6| Step: 13
Training loss: 4.0960187911987305
Validation loss: 2.9891380187003844

Epoch: 11| Step: 0
Training loss: 2.8505663871765137
Validation loss: 2.9867653487831034

Epoch: 6| Step: 1
Training loss: 2.962355852127075
Validation loss: 2.9846718593310286

Epoch: 6| Step: 2
Training loss: 3.0514135360717773
Validation loss: 2.977365263046757

Epoch: 6| Step: 3
Training loss: 2.9420533180236816
Validation loss: 2.973742274827855

Epoch: 6| Step: 4
Training loss: 3.034881830215454
Validation loss: 2.9655166467030845

Epoch: 6| Step: 5
Training loss: 3.5070066452026367
Validation loss: 2.9602414356764926

Epoch: 6| Step: 6
Training loss: 2.811155319213867
Validation loss: 2.953972198629892

Epoch: 6| Step: 7
Training loss: 3.0325984954833984
Validation loss: 2.9499931361085627

Epoch: 6| Step: 8
Training loss: 3.290942430496216
Validation loss: 2.9442397958488873

Epoch: 6| Step: 9
Training loss: 3.58725905418396
Validation loss: 2.9355573654174805

Epoch: 6| Step: 10
Training loss: 2.3865206241607666
Validation loss: 2.928861597532867

Epoch: 6| Step: 11
Training loss: 2.6012275218963623
Validation loss: 2.9264840361892537

Epoch: 6| Step: 12
Training loss: 3.3056583404541016
Validation loss: 2.9181205123983402

Epoch: 6| Step: 13
Training loss: 3.0760908126831055
Validation loss: 2.9152243470632904

Epoch: 12| Step: 0
Training loss: 3.441089630126953
Validation loss: 2.908982792208272

Epoch: 6| Step: 1
Training loss: 3.067176103591919
Validation loss: 2.900728617945025

Epoch: 6| Step: 2
Training loss: 3.0800626277923584
Validation loss: 2.8925916328225085

Epoch: 6| Step: 3
Training loss: 3.9237115383148193
Validation loss: 2.889340977514944

Epoch: 6| Step: 4
Training loss: 2.660844564437866
Validation loss: 2.886864487842847

Epoch: 6| Step: 5
Training loss: 3.4442455768585205
Validation loss: 2.8811317925812094

Epoch: 6| Step: 6
Training loss: 2.6965503692626953
Validation loss: 2.8760552483220256

Epoch: 6| Step: 7
Training loss: 3.759209632873535
Validation loss: 2.8690030344070925

Epoch: 6| Step: 8
Training loss: 2.897968292236328
Validation loss: 2.864112082348075

Epoch: 6| Step: 9
Training loss: 3.0459349155426025
Validation loss: 2.8659405939040647

Epoch: 6| Step: 10
Training loss: 2.220179557800293
Validation loss: 2.8587416295082337

Epoch: 6| Step: 11
Training loss: 2.5517313480377197
Validation loss: 2.854541337618264

Epoch: 6| Step: 12
Training loss: 2.884737730026245
Validation loss: 2.848920960580149

Epoch: 6| Step: 13
Training loss: 1.3641339540481567
Validation loss: 2.8372917329111407

Epoch: 13| Step: 0
Training loss: 2.667058229446411
Validation loss: 2.8387257719552643

Epoch: 6| Step: 1
Training loss: 4.272310256958008
Validation loss: 2.830695152282715

Epoch: 6| Step: 2
Training loss: 2.80155348777771
Validation loss: 2.8235530084179294

Epoch: 6| Step: 3
Training loss: 3.1399452686309814
Validation loss: 2.827588904288507

Epoch: 6| Step: 4
Training loss: 2.4365663528442383
Validation loss: 2.8138685175167617

Epoch: 6| Step: 5
Training loss: 3.4042670726776123
Validation loss: 2.812583156811294

Epoch: 6| Step: 6
Training loss: 1.9060101509094238
Validation loss: 2.8089374778091267

Epoch: 6| Step: 7
Training loss: 2.5686118602752686
Validation loss: 2.806471368317963

Epoch: 6| Step: 8
Training loss: 3.814063549041748
Validation loss: 2.8001007444115094

Epoch: 6| Step: 9
Training loss: 3.212703227996826
Validation loss: 2.795505195535639

Epoch: 6| Step: 10
Training loss: 2.607988119125366
Validation loss: 2.798576106307327

Epoch: 6| Step: 11
Training loss: 2.81742525100708
Validation loss: 2.799012130306613

Epoch: 6| Step: 12
Training loss: 2.561779022216797
Validation loss: 2.812783815527475

Epoch: 6| Step: 13
Training loss: 2.9350979328155518
Validation loss: 2.844291197356357

Epoch: 14| Step: 0
Training loss: 2.989377975463867
Validation loss: 2.8296038796824794

Epoch: 6| Step: 1
Training loss: 2.510819911956787
Validation loss: 2.8116590899805867

Epoch: 6| Step: 2
Training loss: 2.879175901412964
Validation loss: 2.800613308465609

Epoch: 6| Step: 3
Training loss: 3.212925434112549
Validation loss: 2.7759147023641937

Epoch: 6| Step: 4
Training loss: 2.8729372024536133
Validation loss: 2.818312703922231

Epoch: 6| Step: 5
Training loss: 3.676252841949463
Validation loss: 2.8033706193329184

Epoch: 6| Step: 6
Training loss: 3.0981850624084473
Validation loss: 2.771567286983613

Epoch: 6| Step: 7
Training loss: 3.112718105316162
Validation loss: 2.7755458636950423

Epoch: 6| Step: 8
Training loss: 2.314866065979004
Validation loss: 2.780785337571175

Epoch: 6| Step: 9
Training loss: 2.9488425254821777
Validation loss: 2.801228251508487

Epoch: 6| Step: 10
Training loss: 3.119791269302368
Validation loss: 2.8023310553643013

Epoch: 6| Step: 11
Training loss: 2.8753228187561035
Validation loss: 2.800104407853978

Epoch: 6| Step: 12
Training loss: 2.347623348236084
Validation loss: 2.7822514990324616

Epoch: 6| Step: 13
Training loss: 3.1086678504943848
Validation loss: 2.7747822115498204

Epoch: 15| Step: 0
Training loss: 3.082974433898926
Validation loss: 2.7688132973127466

Epoch: 6| Step: 1
Training loss: 3.7005114555358887
Validation loss: 2.761079849735383

Epoch: 6| Step: 2
Training loss: 2.0611977577209473
Validation loss: 2.75434253292699

Epoch: 6| Step: 3
Training loss: 2.7816731929779053
Validation loss: 2.7508742578567995

Epoch: 6| Step: 4
Training loss: 4.091307640075684
Validation loss: 2.7422525805811726

Epoch: 6| Step: 5
Training loss: 2.3597116470336914
Validation loss: 2.738348353293634

Epoch: 6| Step: 6
Training loss: 2.1875362396240234
Validation loss: 2.7373444931481474

Epoch: 6| Step: 7
Training loss: 3.6224894523620605
Validation loss: 2.729634654137396

Epoch: 6| Step: 8
Training loss: 2.5607266426086426
Validation loss: 2.730214718849428

Epoch: 6| Step: 9
Training loss: 3.4775197505950928
Validation loss: 2.726845987381474

Epoch: 6| Step: 10
Training loss: 3.0185248851776123
Validation loss: 2.717896733232724

Epoch: 6| Step: 11
Training loss: 2.3951191902160645
Validation loss: 2.7125053303216093

Epoch: 6| Step: 12
Training loss: 2.523913621902466
Validation loss: 2.706126302801153

Epoch: 6| Step: 13
Training loss: 2.3784573078155518
Validation loss: 2.7029706560155398

Epoch: 16| Step: 0
Training loss: 4.087708473205566
Validation loss: 2.7002153037696757

Epoch: 6| Step: 1
Training loss: 2.1839962005615234
Validation loss: 2.697749096860168

Epoch: 6| Step: 2
Training loss: 2.891650438308716
Validation loss: 2.690390756053309

Epoch: 6| Step: 3
Training loss: 2.928248167037964
Validation loss: 2.69113814702598

Epoch: 6| Step: 4
Training loss: 2.397397041320801
Validation loss: 2.6807755577948784

Epoch: 6| Step: 5
Training loss: 3.0523180961608887
Validation loss: 2.68129478475099

Epoch: 6| Step: 6
Training loss: 2.8944311141967773
Validation loss: 2.678405936046313

Epoch: 6| Step: 7
Training loss: 2.5907721519470215
Validation loss: 2.6714742645140617

Epoch: 6| Step: 8
Training loss: 3.2730698585510254
Validation loss: 2.6698364762849707

Epoch: 6| Step: 9
Training loss: 2.3367955684661865
Validation loss: 2.6639596672468286

Epoch: 6| Step: 10
Training loss: 3.0433881282806396
Validation loss: 2.6695121154990247

Epoch: 6| Step: 11
Training loss: 3.2499828338623047
Validation loss: 2.662378949503745

Epoch: 6| Step: 12
Training loss: 2.967650890350342
Validation loss: 2.663711186378233

Epoch: 6| Step: 13
Training loss: 1.4121489524841309
Validation loss: 2.6649924196222776

Epoch: 17| Step: 0
Training loss: 3.5655620098114014
Validation loss: 2.651846683153542

Epoch: 6| Step: 1
Training loss: 2.149813175201416
Validation loss: 2.655958926805886

Epoch: 6| Step: 2
Training loss: 3.3258559703826904
Validation loss: 2.6701834765813683

Epoch: 6| Step: 3
Training loss: 3.29215145111084
Validation loss: 2.641014434958017

Epoch: 6| Step: 4
Training loss: 2.8035521507263184
Validation loss: 2.6488010601330827

Epoch: 6| Step: 5
Training loss: 2.4932456016540527
Validation loss: 2.6520767263186875

Epoch: 6| Step: 6
Training loss: 3.3598766326904297
Validation loss: 2.66177204860154

Epoch: 6| Step: 7
Training loss: 2.5960659980773926
Validation loss: 2.6559097689967

Epoch: 6| Step: 8
Training loss: 2.903743028640747
Validation loss: 2.6571672347284134

Epoch: 6| Step: 9
Training loss: 2.4569408893585205
Validation loss: 2.6485109534314883

Epoch: 6| Step: 10
Training loss: 2.3841426372528076
Validation loss: 2.6524520022894746

Epoch: 6| Step: 11
Training loss: 2.760082483291626
Validation loss: 2.6502310511886433

Epoch: 6| Step: 12
Training loss: 2.7969326972961426
Validation loss: 2.652782283803468

Epoch: 6| Step: 13
Training loss: 2.769165277481079
Validation loss: 2.6626400819388767

Epoch: 18| Step: 0
Training loss: 3.1386361122131348
Validation loss: 2.6419018225003312

Epoch: 6| Step: 1
Training loss: 3.816485643386841
Validation loss: 2.6487294473955707

Epoch: 6| Step: 2
Training loss: 1.819064974784851
Validation loss: 2.6578293205589376

Epoch: 6| Step: 3
Training loss: 2.988168716430664
Validation loss: 2.669269384876374

Epoch: 6| Step: 4
Training loss: 2.024567127227783
Validation loss: 2.6480868657430015

Epoch: 6| Step: 5
Training loss: 3.709481716156006
Validation loss: 2.631126198717343

Epoch: 6| Step: 6
Training loss: 3.010308265686035
Validation loss: 2.6202344509863083

Epoch: 6| Step: 7
Training loss: 2.9858238697052
Validation loss: 2.6266153935463197

Epoch: 6| Step: 8
Training loss: 3.056549072265625
Validation loss: 2.6304457546562277

Epoch: 6| Step: 9
Training loss: 3.1279149055480957
Validation loss: 2.6330846509625836

Epoch: 6| Step: 10
Training loss: 2.298929214477539
Validation loss: 2.6342246916986283

Epoch: 6| Step: 11
Training loss: 2.0093696117401123
Validation loss: 2.6291189142452773

Epoch: 6| Step: 12
Training loss: 3.075725555419922
Validation loss: 2.6204821832718386

Epoch: 6| Step: 13
Training loss: 2.353168487548828
Validation loss: 2.619744611042802

Epoch: 19| Step: 0
Training loss: 2.774214506149292
Validation loss: 2.6123812839549077

Epoch: 6| Step: 1
Training loss: 3.361727237701416
Validation loss: 2.6179588763944563

Epoch: 6| Step: 2
Training loss: 2.7519028186798096
Validation loss: 2.629263113903743

Epoch: 6| Step: 3
Training loss: 2.8214550018310547
Validation loss: 2.5935821251202653

Epoch: 6| Step: 4
Training loss: 2.410377264022827
Validation loss: 2.5957733354260846

Epoch: 6| Step: 5
Training loss: 2.8007569313049316
Validation loss: 2.6013569421665643

Epoch: 6| Step: 6
Training loss: 1.994268536567688
Validation loss: 2.604071940145185

Epoch: 6| Step: 7
Training loss: 3.443056344985962
Validation loss: 2.598670997927266

Epoch: 6| Step: 8
Training loss: 3.3776345252990723
Validation loss: 2.601944113290438

Epoch: 6| Step: 9
Training loss: 2.5547168254852295
Validation loss: 2.5993546875574256

Epoch: 6| Step: 10
Training loss: 2.937190532684326
Validation loss: 2.6067028071290705

Epoch: 6| Step: 11
Training loss: 2.1452062129974365
Validation loss: 2.6102632194437008

Epoch: 6| Step: 12
Training loss: 3.115147590637207
Validation loss: 2.603543968610866

Epoch: 6| Step: 13
Training loss: 2.763967752456665
Validation loss: 2.5974904696146646

Epoch: 20| Step: 0
Training loss: 2.2190184593200684
Validation loss: 2.578264961960495

Epoch: 6| Step: 1
Training loss: 2.7548513412475586
Validation loss: 2.5727985084697766

Epoch: 6| Step: 2
Training loss: 2.931278705596924
Validation loss: 2.577588055723457

Epoch: 6| Step: 3
Training loss: 2.4720089435577393
Validation loss: 2.6045273247585503

Epoch: 6| Step: 4
Training loss: 2.325302839279175
Validation loss: 2.6183217238354426

Epoch: 6| Step: 5
Training loss: 2.8317880630493164
Validation loss: 2.622371022419263

Epoch: 6| Step: 6
Training loss: 3.9237701892852783
Validation loss: 2.627444710782779

Epoch: 6| Step: 7
Training loss: 2.5078816413879395
Validation loss: 2.627741306058822

Epoch: 6| Step: 8
Training loss: 3.0414209365844727
Validation loss: 2.605351709550427

Epoch: 6| Step: 9
Training loss: 3.2979178428649902
Validation loss: 2.592192160185947

Epoch: 6| Step: 10
Training loss: 2.944338321685791
Validation loss: 2.5801743538148942

Epoch: 6| Step: 11
Training loss: 1.6702888011932373
Validation loss: 2.577454346482472

Epoch: 6| Step: 12
Training loss: 3.6732940673828125
Validation loss: 2.5858953050387803

Epoch: 6| Step: 13
Training loss: 2.4584999084472656
Validation loss: 2.614910028314078

Epoch: 21| Step: 0
Training loss: 2.4694294929504395
Validation loss: 2.653392150837888

Epoch: 6| Step: 1
Training loss: 3.169407606124878
Validation loss: 2.645085543714544

Epoch: 6| Step: 2
Training loss: 2.5405688285827637
Validation loss: 2.621025667395643

Epoch: 6| Step: 3
Training loss: 3.052140951156616
Validation loss: 2.5913234321019982

Epoch: 6| Step: 4
Training loss: 2.413983106613159
Validation loss: 2.577235437208606

Epoch: 6| Step: 5
Training loss: 3.4585418701171875
Validation loss: 2.5794952659196753

Epoch: 6| Step: 6
Training loss: 2.910604238510132
Validation loss: 2.5798945580759356

Epoch: 6| Step: 7
Training loss: 2.8987250328063965
Validation loss: 2.5888186603464107

Epoch: 6| Step: 8
Training loss: 2.7017862796783447
Validation loss: 2.59323880493

Epoch: 6| Step: 9
Training loss: 2.945969581604004
Validation loss: 2.595248371042231

Epoch: 6| Step: 10
Training loss: 2.4647884368896484
Validation loss: 2.60538883619411

Epoch: 6| Step: 11
Training loss: 2.9328603744506836
Validation loss: 2.5942139215366815

Epoch: 6| Step: 12
Training loss: 2.1881027221679688
Validation loss: 2.572962886543684

Epoch: 6| Step: 13
Training loss: 3.1993513107299805
Validation loss: 2.577565977650304

Epoch: 22| Step: 0
Training loss: 2.9097514152526855
Validation loss: 2.5797661606983473

Epoch: 6| Step: 1
Training loss: 2.6197211742401123
Validation loss: 2.5661196016496226

Epoch: 6| Step: 2
Training loss: 3.258803606033325
Validation loss: 2.560853212110458

Epoch: 6| Step: 3
Training loss: 2.726011276245117
Validation loss: 2.5654815884046656

Epoch: 6| Step: 4
Training loss: 3.020552158355713
Validation loss: 2.5563331188694125

Epoch: 6| Step: 5
Training loss: 2.9064035415649414
Validation loss: 2.54566547178453

Epoch: 6| Step: 6
Training loss: 2.464219570159912
Validation loss: 2.5432103987663024

Epoch: 6| Step: 7
Training loss: 3.4720330238342285
Validation loss: 2.548770932741063

Epoch: 6| Step: 8
Training loss: 2.6155128479003906
Validation loss: 2.5479029327310543

Epoch: 6| Step: 9
Training loss: 2.785918712615967
Validation loss: 2.54075280568933

Epoch: 6| Step: 10
Training loss: 2.3921749591827393
Validation loss: 2.538616135556211

Epoch: 6| Step: 11
Training loss: 2.5112574100494385
Validation loss: 2.5415503004545807

Epoch: 6| Step: 12
Training loss: 2.570549964904785
Validation loss: 2.5376538409981677

Epoch: 6| Step: 13
Training loss: 2.4309568405151367
Validation loss: 2.538837707170876

Epoch: 23| Step: 0
Training loss: 2.3615965843200684
Validation loss: 2.5394353251303396

Epoch: 6| Step: 1
Training loss: 2.6534066200256348
Validation loss: 2.537885932512181

Epoch: 6| Step: 2
Training loss: 2.8516483306884766
Validation loss: 2.5413660900567168

Epoch: 6| Step: 3
Training loss: 2.9531657695770264
Validation loss: 2.5397408470030753

Epoch: 6| Step: 4
Training loss: 2.501338005065918
Validation loss: 2.533051577947473

Epoch: 6| Step: 5
Training loss: 2.106520175933838
Validation loss: 2.5407227521301596

Epoch: 6| Step: 6
Training loss: 2.8971614837646484
Validation loss: 2.5422204207348567

Epoch: 6| Step: 7
Training loss: 3.0134406089782715
Validation loss: 2.537859901305168

Epoch: 6| Step: 8
Training loss: 2.6239089965820312
Validation loss: 2.533892575130668

Epoch: 6| Step: 9
Training loss: 2.8866703510284424
Validation loss: 2.532704263605097

Epoch: 6| Step: 10
Training loss: 2.82125186920166
Validation loss: 2.5288803500513874

Epoch: 6| Step: 11
Training loss: 3.7580299377441406
Validation loss: 2.525839149311025

Epoch: 6| Step: 12
Training loss: 2.0192477703094482
Validation loss: 2.5255723896846978

Epoch: 6| Step: 13
Training loss: 3.3862650394439697
Validation loss: 2.524643059699766

Epoch: 24| Step: 0
Training loss: 3.7236945629119873
Validation loss: 2.521696966181519

Epoch: 6| Step: 1
Training loss: 2.260798215866089
Validation loss: 2.521298316217238

Epoch: 6| Step: 2
Training loss: 2.4699018001556396
Validation loss: 2.530214294310539

Epoch: 6| Step: 3
Training loss: 2.834043502807617
Validation loss: 2.524248379533009

Epoch: 6| Step: 4
Training loss: 2.842381477355957
Validation loss: 2.5242149599136843

Epoch: 6| Step: 5
Training loss: 3.0655107498168945
Validation loss: 2.5224300225575766

Epoch: 6| Step: 6
Training loss: 2.3570635318756104
Validation loss: 2.51933269346914

Epoch: 6| Step: 7
Training loss: 2.5906028747558594
Validation loss: 2.516207625789027

Epoch: 6| Step: 8
Training loss: 2.479731559753418
Validation loss: 2.516645134136241

Epoch: 6| Step: 9
Training loss: 2.9295361042022705
Validation loss: 2.5254350170012443

Epoch: 6| Step: 10
Training loss: 2.944540023803711
Validation loss: 2.5426190027626614

Epoch: 6| Step: 11
Training loss: 2.6987626552581787
Validation loss: 2.5723159031201432

Epoch: 6| Step: 12
Training loss: 2.8801610469818115
Validation loss: 2.577396026221655

Epoch: 6| Step: 13
Training loss: 2.175795078277588
Validation loss: 2.5619851440511723

Epoch: 25| Step: 0
Training loss: 2.667166233062744
Validation loss: 2.545255978902181

Epoch: 6| Step: 1
Training loss: 2.943971633911133
Validation loss: 2.542748074377737

Epoch: 6| Step: 2
Training loss: 2.737945556640625
Validation loss: 2.517757946445096

Epoch: 6| Step: 3
Training loss: 2.7907819747924805
Validation loss: 2.507385371833719

Epoch: 6| Step: 4
Training loss: 2.4893739223480225
Validation loss: 2.5090681993833153

Epoch: 6| Step: 5
Training loss: 2.7072510719299316
Validation loss: 2.505155171117475

Epoch: 6| Step: 6
Training loss: 2.8736162185668945
Validation loss: 2.5042284175913823

Epoch: 6| Step: 7
Training loss: 2.908755302429199
Validation loss: 2.5031331764754428

Epoch: 6| Step: 8
Training loss: 2.424705982208252
Validation loss: 2.5032219476597284

Epoch: 6| Step: 9
Training loss: 3.5111241340637207
Validation loss: 2.502657767265074

Epoch: 6| Step: 10
Training loss: 2.5508761405944824
Validation loss: 2.510776609502813

Epoch: 6| Step: 11
Training loss: 2.5137877464294434
Validation loss: 2.5086256893732215

Epoch: 6| Step: 12
Training loss: 2.221302032470703
Validation loss: 2.5188384850819907

Epoch: 6| Step: 13
Training loss: 3.241384267807007
Validation loss: 2.5142881588269304

Epoch: 26| Step: 0
Training loss: 2.9606714248657227
Validation loss: 2.4979755852812078

Epoch: 6| Step: 1
Training loss: 3.460573673248291
Validation loss: 2.5057873777163926

Epoch: 6| Step: 2
Training loss: 3.4287192821502686
Validation loss: 2.5072942190272833

Epoch: 6| Step: 3
Training loss: 2.4385597705841064
Validation loss: 2.5049295784324728

Epoch: 6| Step: 4
Training loss: 1.4971535205841064
Validation loss: 2.495852329397714

Epoch: 6| Step: 5
Training loss: 2.7693395614624023
Validation loss: 2.4956878821055093

Epoch: 6| Step: 6
Training loss: 3.046916961669922
Validation loss: 2.5032535112032326

Epoch: 6| Step: 7
Training loss: 2.5026347637176514
Validation loss: 2.515489670538133

Epoch: 6| Step: 8
Training loss: 3.246352195739746
Validation loss: 2.5318783278106363

Epoch: 6| Step: 9
Training loss: 2.4410548210144043
Validation loss: 2.517162992108253

Epoch: 6| Step: 10
Training loss: 2.7914440631866455
Validation loss: 2.5146246853695122

Epoch: 6| Step: 11
Training loss: 2.2943806648254395
Validation loss: 2.493463626471899

Epoch: 6| Step: 12
Training loss: 2.575726270675659
Validation loss: 2.4931613488863875

Epoch: 6| Step: 13
Training loss: 2.8600964546203613
Validation loss: 2.490306305628951

Epoch: 27| Step: 0
Training loss: 2.683840751647949
Validation loss: 2.4932447095071115

Epoch: 6| Step: 1
Training loss: 2.298198699951172
Validation loss: 2.493294982499974

Epoch: 6| Step: 2
Training loss: 2.5327634811401367
Validation loss: 2.4949322644100396

Epoch: 6| Step: 3
Training loss: 2.9058375358581543
Validation loss: 2.494209538223923

Epoch: 6| Step: 4
Training loss: 2.072035074234009
Validation loss: 2.4978881138627247

Epoch: 6| Step: 5
Training loss: 2.6934943199157715
Validation loss: 2.498975787111508

Epoch: 6| Step: 6
Training loss: 3.318747043609619
Validation loss: 2.49580479180941

Epoch: 6| Step: 7
Training loss: 3.173872470855713
Validation loss: 2.49239706864921

Epoch: 6| Step: 8
Training loss: 2.907564163208008
Validation loss: 2.4903343005846907

Epoch: 6| Step: 9
Training loss: 3.028853416442871
Validation loss: 2.4906484644900084

Epoch: 6| Step: 10
Training loss: 2.9278790950775146
Validation loss: 2.4908516509558565

Epoch: 6| Step: 11
Training loss: 1.999147653579712
Validation loss: 2.490400063094272

Epoch: 6| Step: 12
Training loss: 2.3152976036071777
Validation loss: 2.4981710936433528

Epoch: 6| Step: 13
Training loss: 3.6999638080596924
Validation loss: 2.521660625293691

Epoch: 28| Step: 0
Training loss: 2.3446950912475586
Validation loss: 2.514302028122769

Epoch: 6| Step: 1
Training loss: 2.201110363006592
Validation loss: 2.510717163803757

Epoch: 6| Step: 2
Training loss: 3.0861072540283203
Validation loss: 2.5101857518637054

Epoch: 6| Step: 3
Training loss: 3.288754940032959
Validation loss: 2.507133468504875

Epoch: 6| Step: 4
Training loss: 2.2684643268585205
Validation loss: 2.5031546854203746

Epoch: 6| Step: 5
Training loss: 3.005455732345581
Validation loss: 2.515102699238767

Epoch: 6| Step: 6
Training loss: 2.630333423614502
Validation loss: 2.5301234209409325

Epoch: 6| Step: 7
Training loss: 3.4274682998657227
Validation loss: 2.5096132088732976

Epoch: 6| Step: 8
Training loss: 2.81179141998291
Validation loss: 2.4883336995237615

Epoch: 6| Step: 9
Training loss: 3.021312952041626
Validation loss: 2.4861170348300727

Epoch: 6| Step: 10
Training loss: 2.3892784118652344
Validation loss: 2.4906922847993913

Epoch: 6| Step: 11
Training loss: 2.502875804901123
Validation loss: 2.4948849498584704

Epoch: 6| Step: 12
Training loss: 2.497551441192627
Validation loss: 2.509070001622682

Epoch: 6| Step: 13
Training loss: 2.557276725769043
Validation loss: 2.505628107696451

Epoch: 29| Step: 0
Training loss: 3.5955042839050293
Validation loss: 2.515798194434053

Epoch: 6| Step: 1
Training loss: 2.703338623046875
Validation loss: 2.5131455185592815

Epoch: 6| Step: 2
Training loss: 2.110044002532959
Validation loss: 2.498916477285406

Epoch: 6| Step: 3
Training loss: 2.8415205478668213
Validation loss: 2.491085970273582

Epoch: 6| Step: 4
Training loss: 2.3761987686157227
Validation loss: 2.4829411916835333

Epoch: 6| Step: 5
Training loss: 2.1765003204345703
Validation loss: 2.4913808709831646

Epoch: 6| Step: 6
Training loss: 3.0559189319610596
Validation loss: 2.495279186515398

Epoch: 6| Step: 7
Training loss: 4.088788986206055
Validation loss: 2.489134498821792

Epoch: 6| Step: 8
Training loss: 2.938504934310913
Validation loss: 2.4977618878887546

Epoch: 6| Step: 9
Training loss: 1.771120309829712
Validation loss: 2.5289075143875612

Epoch: 6| Step: 10
Training loss: 2.8106536865234375
Validation loss: 2.5518768269528627

Epoch: 6| Step: 11
Training loss: 2.36503005027771
Validation loss: 2.571515360186177

Epoch: 6| Step: 12
Training loss: 2.3955554962158203
Validation loss: 2.526233514149984

Epoch: 6| Step: 13
Training loss: 2.9307210445404053
Validation loss: 2.508910056083433

Epoch: 30| Step: 0
Training loss: 2.2957937717437744
Validation loss: 2.486190278043029

Epoch: 6| Step: 1
Training loss: 2.5718793869018555
Validation loss: 2.47244292946272

Epoch: 6| Step: 2
Training loss: 2.4475274085998535
Validation loss: 2.4716254408641527

Epoch: 6| Step: 3
Training loss: 2.113612174987793
Validation loss: 2.475341578965546

Epoch: 6| Step: 4
Training loss: 3.009575366973877
Validation loss: 2.48558319768598

Epoch: 6| Step: 5
Training loss: 3.4672164916992188
Validation loss: 2.4863265739974154

Epoch: 6| Step: 6
Training loss: 2.316793203353882
Validation loss: 2.4812994028932307

Epoch: 6| Step: 7
Training loss: 2.4147634506225586
Validation loss: 2.487244770091067

Epoch: 6| Step: 8
Training loss: 3.6853461265563965
Validation loss: 2.4848693211873374

Epoch: 6| Step: 9
Training loss: 2.4154796600341797
Validation loss: 2.4827600217634633

Epoch: 6| Step: 10
Training loss: 2.0656635761260986
Validation loss: 2.4776283207760064

Epoch: 6| Step: 11
Training loss: 2.4640140533447266
Validation loss: 2.474066344640588

Epoch: 6| Step: 12
Training loss: 3.710601329803467
Validation loss: 2.476196413399071

Epoch: 6| Step: 13
Training loss: 3.2040939331054688
Validation loss: 2.4728836474880094

Epoch: 31| Step: 0
Training loss: 1.7493109703063965
Validation loss: 2.46758629686089

Epoch: 6| Step: 1
Training loss: 2.4660472869873047
Validation loss: 2.4757244279307704

Epoch: 6| Step: 2
Training loss: 3.2497787475585938
Validation loss: 2.5262467040810535

Epoch: 6| Step: 3
Training loss: 2.415651798248291
Validation loss: 2.5588363716679234

Epoch: 6| Step: 4
Training loss: 3.279305934906006
Validation loss: 2.5676124454826437

Epoch: 6| Step: 5
Training loss: 2.938095808029175
Validation loss: 2.5533243840740574

Epoch: 6| Step: 6
Training loss: 2.8488876819610596
Validation loss: 2.5384894288996214

Epoch: 6| Step: 7
Training loss: 2.4223337173461914
Validation loss: 2.533431214670981

Epoch: 6| Step: 8
Training loss: 2.8841114044189453
Validation loss: 2.528798260996419

Epoch: 6| Step: 9
Training loss: 2.3466644287109375
Validation loss: 2.528532346089681

Epoch: 6| Step: 10
Training loss: 3.0766825675964355
Validation loss: 2.526382484743672

Epoch: 6| Step: 11
Training loss: 2.857665538787842
Validation loss: 2.520292887123682

Epoch: 6| Step: 12
Training loss: 3.2678956985473633
Validation loss: 2.535553627116706

Epoch: 6| Step: 13
Training loss: 2.405094861984253
Validation loss: 2.5189572354798675

Epoch: 32| Step: 0
Training loss: 2.7340750694274902
Validation loss: 2.4902596422421035

Epoch: 6| Step: 1
Training loss: 3.5199527740478516
Validation loss: 2.4670756581009075

Epoch: 6| Step: 2
Training loss: 3.023308038711548
Validation loss: 2.454467036390817

Epoch: 6| Step: 3
Training loss: 2.30684757232666
Validation loss: 2.4616530582469

Epoch: 6| Step: 4
Training loss: 2.209160327911377
Validation loss: 2.473412121495893

Epoch: 6| Step: 5
Training loss: 2.9847898483276367
Validation loss: 2.4821597119813323

Epoch: 6| Step: 6
Training loss: 3.0876412391662598
Validation loss: 2.483934461429555

Epoch: 6| Step: 7
Training loss: 2.6399171352386475
Validation loss: 2.477742200256676

Epoch: 6| Step: 8
Training loss: 2.474034547805786
Validation loss: 2.4759282604340584

Epoch: 6| Step: 9
Training loss: 2.745016574859619
Validation loss: 2.4830340031654603

Epoch: 6| Step: 10
Training loss: 2.6069118976593018
Validation loss: 2.491252601787608

Epoch: 6| Step: 11
Training loss: 2.9558072090148926
Validation loss: 2.502917943462249

Epoch: 6| Step: 12
Training loss: 2.661686897277832
Validation loss: 2.511387248193064

Epoch: 6| Step: 13
Training loss: 1.7071585655212402
Validation loss: 2.4820476296127483

Epoch: 33| Step: 0
Training loss: 2.799971103668213
Validation loss: 2.469849222449846

Epoch: 6| Step: 1
Training loss: 3.1596007347106934
Validation loss: 2.460021957274406

Epoch: 6| Step: 2
Training loss: 3.1470518112182617
Validation loss: 2.4588691521716375

Epoch: 6| Step: 3
Training loss: 2.574291467666626
Validation loss: 2.4651598648358415

Epoch: 6| Step: 4
Training loss: 2.451511859893799
Validation loss: 2.4626645311232536

Epoch: 6| Step: 5
Training loss: 2.2511446475982666
Validation loss: 2.4587309693777435

Epoch: 6| Step: 6
Training loss: 2.534515380859375
Validation loss: 2.467750621098344

Epoch: 6| Step: 7
Training loss: 3.516180992126465
Validation loss: 2.4631579870818765

Epoch: 6| Step: 8
Training loss: 2.728398084640503
Validation loss: 2.4668291743083666

Epoch: 6| Step: 9
Training loss: 2.6190617084503174
Validation loss: 2.4762553809791483

Epoch: 6| Step: 10
Training loss: 2.6685471534729004
Validation loss: 2.4966590763420187

Epoch: 6| Step: 11
Training loss: 2.4656331539154053
Validation loss: 2.5123145041927213

Epoch: 6| Step: 12
Training loss: 2.033837080001831
Validation loss: 2.5068753560384116

Epoch: 6| Step: 13
Training loss: 2.8695335388183594
Validation loss: 2.5035776835615917

Epoch: 34| Step: 0
Training loss: 3.1276187896728516
Validation loss: 2.4912442212463706

Epoch: 6| Step: 1
Training loss: 2.5021395683288574
Validation loss: 2.464013122743176

Epoch: 6| Step: 2
Training loss: 2.264885425567627
Validation loss: 2.4519196120641564

Epoch: 6| Step: 3
Training loss: 3.3811302185058594
Validation loss: 2.450712711580338

Epoch: 6| Step: 4
Training loss: 2.6964144706726074
Validation loss: 2.4522285717789845

Epoch: 6| Step: 5
Training loss: 2.628826141357422
Validation loss: 2.4462550455524075

Epoch: 6| Step: 6
Training loss: 2.9137988090515137
Validation loss: 2.451674756183419

Epoch: 6| Step: 7
Training loss: 2.598576545715332
Validation loss: 2.452338262270856

Epoch: 6| Step: 8
Training loss: 2.3916361331939697
Validation loss: 2.4559678108461442

Epoch: 6| Step: 9
Training loss: 2.890092372894287
Validation loss: 2.4508937815184235

Epoch: 6| Step: 10
Training loss: 2.480781078338623
Validation loss: 2.4545758462721303

Epoch: 6| Step: 11
Training loss: 2.5705621242523193
Validation loss: 2.447666511740736

Epoch: 6| Step: 12
Training loss: 2.3943920135498047
Validation loss: 2.4476491225663053

Epoch: 6| Step: 13
Training loss: 2.6895029544830322
Validation loss: 2.458854442001671

Epoch: 35| Step: 0
Training loss: 2.11934757232666
Validation loss: 2.4415110439382572

Epoch: 6| Step: 1
Training loss: 3.066397190093994
Validation loss: 2.4443290054157214

Epoch: 6| Step: 2
Training loss: 2.313030242919922
Validation loss: 2.43844174826017

Epoch: 6| Step: 3
Training loss: 2.436793327331543
Validation loss: 2.4514981239072737

Epoch: 6| Step: 4
Training loss: 3.7404494285583496
Validation loss: 2.4579142934532574

Epoch: 6| Step: 5
Training loss: 2.8021702766418457
Validation loss: 2.468252461443665

Epoch: 6| Step: 6
Training loss: 2.908170223236084
Validation loss: 2.4715875476919194

Epoch: 6| Step: 7
Training loss: 2.509023666381836
Validation loss: 2.4734701674471617

Epoch: 6| Step: 8
Training loss: 2.6915578842163086
Validation loss: 2.473753821465277

Epoch: 6| Step: 9
Training loss: 2.1724493503570557
Validation loss: 2.4635490038061656

Epoch: 6| Step: 10
Training loss: 3.6491141319274902
Validation loss: 2.448777734592397

Epoch: 6| Step: 11
Training loss: 3.379025459289551
Validation loss: 2.428510788948305

Epoch: 6| Step: 12
Training loss: 1.4076794385910034
Validation loss: 2.4188804395737185

Epoch: 6| Step: 13
Training loss: 1.9056684970855713
Validation loss: 2.4211812096257366

Epoch: 36| Step: 0
Training loss: 2.4541401863098145
Validation loss: 2.4263750237803303

Epoch: 6| Step: 1
Training loss: 2.8169803619384766
Validation loss: 2.432273716054937

Epoch: 6| Step: 2
Training loss: 2.9170098304748535
Validation loss: 2.4383769317339827

Epoch: 6| Step: 3
Training loss: 3.7452104091644287
Validation loss: 2.4464301319532495

Epoch: 6| Step: 4
Training loss: 3.0954575538635254
Validation loss: 2.436205005133024

Epoch: 6| Step: 5
Training loss: 2.5243191719055176
Validation loss: 2.4290950041945263

Epoch: 6| Step: 6
Training loss: 3.1402065753936768
Validation loss: 2.4209788460885324

Epoch: 6| Step: 7
Training loss: 2.2999792098999023
Validation loss: 2.423661808813772

Epoch: 6| Step: 8
Training loss: 2.4645748138427734
Validation loss: 2.4234715495058285

Epoch: 6| Step: 9
Training loss: 2.249936103820801
Validation loss: 2.4202689816874843

Epoch: 6| Step: 10
Training loss: 2.5843920707702637
Validation loss: 2.424909722420477

Epoch: 6| Step: 11
Training loss: 2.344794988632202
Validation loss: 2.4172980477732997

Epoch: 6| Step: 12
Training loss: 2.778655529022217
Validation loss: 2.428514180644866

Epoch: 6| Step: 13
Training loss: 1.4888477325439453
Validation loss: 2.4254886386215047

Epoch: 37| Step: 0
Training loss: 2.987424373626709
Validation loss: 2.433433319932671

Epoch: 6| Step: 1
Training loss: 2.675483226776123
Validation loss: 2.420482171479092

Epoch: 6| Step: 2
Training loss: 2.765597343444824
Validation loss: 2.4160294199502594

Epoch: 6| Step: 3
Training loss: 2.0107131004333496
Validation loss: 2.4149177202614407

Epoch: 6| Step: 4
Training loss: 2.2883927822113037
Validation loss: 2.416243271161151

Epoch: 6| Step: 5
Training loss: 2.917541980743408
Validation loss: 2.4204651591598347

Epoch: 6| Step: 6
Training loss: 2.4691309928894043
Validation loss: 2.423012161767611

Epoch: 6| Step: 7
Training loss: 2.8817191123962402
Validation loss: 2.4244334287540887

Epoch: 6| Step: 8
Training loss: 2.4812169075012207
Validation loss: 2.435278631025745

Epoch: 6| Step: 9
Training loss: 2.6497550010681152
Validation loss: 2.449940535330003

Epoch: 6| Step: 10
Training loss: 2.7583043575286865
Validation loss: 2.4654220611818376

Epoch: 6| Step: 11
Training loss: 2.4822378158569336
Validation loss: 2.4811370603499876

Epoch: 6| Step: 12
Training loss: 2.8809585571289062
Validation loss: 2.472385270621187

Epoch: 6| Step: 13
Training loss: 3.164818286895752
Validation loss: 2.4361975500660558

Epoch: 38| Step: 0
Training loss: 2.8210153579711914
Validation loss: 2.4230722099222164

Epoch: 6| Step: 1
Training loss: 2.3976736068725586
Validation loss: 2.4104941993631344

Epoch: 6| Step: 2
Training loss: 2.975337028503418
Validation loss: 2.4114799243147655

Epoch: 6| Step: 3
Training loss: 2.300065517425537
Validation loss: 2.406351279186946

Epoch: 6| Step: 4
Training loss: 3.1829795837402344
Validation loss: 2.409929138357921

Epoch: 6| Step: 5
Training loss: 2.9841856956481934
Validation loss: 2.4231923113587084

Epoch: 6| Step: 6
Training loss: 2.376044750213623
Validation loss: 2.451499823601015

Epoch: 6| Step: 7
Training loss: 2.3794491291046143
Validation loss: 2.4869396404553483

Epoch: 6| Step: 8
Training loss: 2.158616542816162
Validation loss: 2.4883974290663198

Epoch: 6| Step: 9
Training loss: 3.0037784576416016
Validation loss: 2.5090141193841093

Epoch: 6| Step: 10
Training loss: 2.848109245300293
Validation loss: 2.5067993389662875

Epoch: 6| Step: 11
Training loss: 2.9853439331054688
Validation loss: 2.4961857129168767

Epoch: 6| Step: 12
Training loss: 2.038759231567383
Validation loss: 2.473579147810577

Epoch: 6| Step: 13
Training loss: 3.8899638652801514
Validation loss: 2.453084594459944

Epoch: 39| Step: 0
Training loss: 1.475850224494934
Validation loss: 2.443812693319013

Epoch: 6| Step: 1
Training loss: 2.9898455142974854
Validation loss: 2.4289707112055954

Epoch: 6| Step: 2
Training loss: 2.5630791187286377
Validation loss: 2.423278408665811

Epoch: 6| Step: 3
Training loss: 2.3660402297973633
Validation loss: 2.435745846840643

Epoch: 6| Step: 4
Training loss: 3.1977901458740234
Validation loss: 2.454086402411102

Epoch: 6| Step: 5
Training loss: 2.6376447677612305
Validation loss: 2.4736312256064465

Epoch: 6| Step: 6
Training loss: 3.137404441833496
Validation loss: 2.4825366979004233

Epoch: 6| Step: 7
Training loss: 2.950951099395752
Validation loss: 2.4338895197837584

Epoch: 6| Step: 8
Training loss: 2.854322910308838
Validation loss: 2.410828267374346

Epoch: 6| Step: 9
Training loss: 2.490086317062378
Validation loss: 2.4035571082945792

Epoch: 6| Step: 10
Training loss: 2.939850330352783
Validation loss: 2.3997094426103818

Epoch: 6| Step: 11
Training loss: 2.654451847076416
Validation loss: 2.3991349640712945

Epoch: 6| Step: 12
Training loss: 2.931483268737793
Validation loss: 2.398554612231511

Epoch: 6| Step: 13
Training loss: 1.8883980512619019
Validation loss: 2.39872916026782

Epoch: 40| Step: 0
Training loss: 3.412356376647949
Validation loss: 2.3945591475373957

Epoch: 6| Step: 1
Training loss: 3.171624183654785
Validation loss: 2.3930472071452806

Epoch: 6| Step: 2
Training loss: 3.258604049682617
Validation loss: 2.3919303365933

Epoch: 6| Step: 3
Training loss: 2.5754833221435547
Validation loss: 2.387659054930492

Epoch: 6| Step: 4
Training loss: 2.9468252658843994
Validation loss: 2.3905166451649

Epoch: 6| Step: 5
Training loss: 2.4270777702331543
Validation loss: 2.382880172421855

Epoch: 6| Step: 6
Training loss: 2.6760544776916504
Validation loss: 2.3864211446495465

Epoch: 6| Step: 7
Training loss: 2.8517870903015137
Validation loss: 2.3907636929583806

Epoch: 6| Step: 8
Training loss: 2.249882221221924
Validation loss: 2.4100461185619397

Epoch: 6| Step: 9
Training loss: 2.640408515930176
Validation loss: 2.4202256228334162

Epoch: 6| Step: 10
Training loss: 1.7032413482666016
Validation loss: 2.416570160978584

Epoch: 6| Step: 11
Training loss: 2.070457696914673
Validation loss: 2.437200597537461

Epoch: 6| Step: 12
Training loss: 2.926334857940674
Validation loss: 2.467697144836508

Epoch: 6| Step: 13
Training loss: 2.0302462577819824
Validation loss: 2.4636401155943513

Epoch: 41| Step: 0
Training loss: 2.2739639282226562
Validation loss: 2.4820748452217347

Epoch: 6| Step: 1
Training loss: 2.7607016563415527
Validation loss: 2.4631365499188824

Epoch: 6| Step: 2
Training loss: 1.7459263801574707
Validation loss: 2.4657089223143873

Epoch: 6| Step: 3
Training loss: 3.6383049488067627
Validation loss: 2.443553242632138

Epoch: 6| Step: 4
Training loss: 3.040212869644165
Validation loss: 2.4152182763622654

Epoch: 6| Step: 5
Training loss: 2.596273899078369
Validation loss: 2.4011011354384886

Epoch: 6| Step: 6
Training loss: 2.450122594833374
Validation loss: 2.3897781218251875

Epoch: 6| Step: 7
Training loss: 2.7402777671813965
Validation loss: 2.3871814256073325

Epoch: 6| Step: 8
Training loss: 3.1382627487182617
Validation loss: 2.391365461452033

Epoch: 6| Step: 9
Training loss: 2.9598538875579834
Validation loss: 2.3893667908125025

Epoch: 6| Step: 10
Training loss: 2.2684340476989746
Validation loss: 2.3918584854372087

Epoch: 6| Step: 11
Training loss: 2.4165141582489014
Validation loss: 2.3907733783927014

Epoch: 6| Step: 12
Training loss: 2.133854627609253
Validation loss: 2.3891307487282702

Epoch: 6| Step: 13
Training loss: 3.3459508419036865
Validation loss: 2.389845625046761

Epoch: 42| Step: 0
Training loss: 3.0291671752929688
Validation loss: 2.3854163026296966

Epoch: 6| Step: 1
Training loss: 3.2294235229492188
Validation loss: 2.3945117560766076

Epoch: 6| Step: 2
Training loss: 2.763429880142212
Validation loss: 2.4118101032831336

Epoch: 6| Step: 3
Training loss: 2.4836697578430176
Validation loss: 2.4301846258101927

Epoch: 6| Step: 4
Training loss: 2.499028205871582
Validation loss: 2.4460311884521158

Epoch: 6| Step: 5
Training loss: 2.3226511478424072
Validation loss: 2.4221781966506795

Epoch: 6| Step: 6
Training loss: 2.4750709533691406
Validation loss: 2.4020396535114577

Epoch: 6| Step: 7
Training loss: 2.247372627258301
Validation loss: 2.399448630630329

Epoch: 6| Step: 8
Training loss: 2.7855117321014404
Validation loss: 2.392518551118912

Epoch: 6| Step: 9
Training loss: 2.7507071495056152
Validation loss: 2.398223861571281

Epoch: 6| Step: 10
Training loss: 2.5081052780151367
Validation loss: 2.4018058520491405

Epoch: 6| Step: 11
Training loss: 2.515031576156616
Validation loss: 2.4088064726962837

Epoch: 6| Step: 12
Training loss: 2.9377591609954834
Validation loss: 2.416556486519434

Epoch: 6| Step: 13
Training loss: 2.1522717475891113
Validation loss: 2.424708740685576

Epoch: 43| Step: 0
Training loss: 3.434849977493286
Validation loss: 2.431211586921446

Epoch: 6| Step: 1
Training loss: 2.983072519302368
Validation loss: 2.4088259973833637

Epoch: 6| Step: 2
Training loss: 2.107085704803467
Validation loss: 2.38950268683895

Epoch: 6| Step: 3
Training loss: 2.927949905395508
Validation loss: 2.379948659609723

Epoch: 6| Step: 4
Training loss: 2.328714370727539
Validation loss: 2.369654937457013

Epoch: 6| Step: 5
Training loss: 2.8882081508636475
Validation loss: 2.3704271495983167

Epoch: 6| Step: 6
Training loss: 2.540524959564209
Validation loss: 2.3695422692965438

Epoch: 6| Step: 7
Training loss: 3.553215265274048
Validation loss: 2.377537037736626

Epoch: 6| Step: 8
Training loss: 2.353010416030884
Validation loss: 2.3867202446024907

Epoch: 6| Step: 9
Training loss: 2.4914703369140625
Validation loss: 2.3782122596617667

Epoch: 6| Step: 10
Training loss: 2.200953483581543
Validation loss: 2.383990172416933

Epoch: 6| Step: 11
Training loss: 2.040243625640869
Validation loss: 2.3936061115675074

Epoch: 6| Step: 12
Training loss: 2.3352043628692627
Validation loss: 2.3879819813595025

Epoch: 6| Step: 13
Training loss: 3.377080202102661
Validation loss: 2.393080388346026

Epoch: 44| Step: 0
Training loss: 3.6605985164642334
Validation loss: 2.397144648336595

Epoch: 6| Step: 1
Training loss: 2.6791200637817383
Validation loss: 2.4088716942776918

Epoch: 6| Step: 2
Training loss: 1.927883505821228
Validation loss: 2.3885390553423154

Epoch: 6| Step: 3
Training loss: 2.7320282459259033
Validation loss: 2.3870733809727493

Epoch: 6| Step: 4
Training loss: 2.5184121131896973
Validation loss: 2.3787480785000708

Epoch: 6| Step: 5
Training loss: 2.4862403869628906
Validation loss: 2.3789451840103313

Epoch: 6| Step: 6
Training loss: 2.73380184173584
Validation loss: 2.3686262869065806

Epoch: 6| Step: 7
Training loss: 2.698507785797119
Validation loss: 2.3689966381237073

Epoch: 6| Step: 8
Training loss: 2.3793888092041016
Validation loss: 2.3693282783672376

Epoch: 6| Step: 9
Training loss: 2.1139118671417236
Validation loss: 2.3708898457147742

Epoch: 6| Step: 10
Training loss: 3.2522120475769043
Validation loss: 2.3732056181917907

Epoch: 6| Step: 11
Training loss: 2.0449275970458984
Validation loss: 2.3705466690883843

Epoch: 6| Step: 12
Training loss: 3.1397173404693604
Validation loss: 2.375023321438861

Epoch: 6| Step: 13
Training loss: 2.3341734409332275
Validation loss: 2.378241826129216

Epoch: 45| Step: 0
Training loss: 2.0181217193603516
Validation loss: 2.398207208161713

Epoch: 6| Step: 1
Training loss: 2.498081684112549
Validation loss: 2.4404449027071715

Epoch: 6| Step: 2
Training loss: 2.5668933391571045
Validation loss: 2.4845680677762596

Epoch: 6| Step: 3
Training loss: 2.3239662647247314
Validation loss: 2.4877703189849854

Epoch: 6| Step: 4
Training loss: 2.316328525543213
Validation loss: 2.4817699309318297

Epoch: 6| Step: 5
Training loss: 2.7663984298706055
Validation loss: 2.4627341455028904

Epoch: 6| Step: 6
Training loss: 2.7550411224365234
Validation loss: 2.4367584848916657

Epoch: 6| Step: 7
Training loss: 2.731297254562378
Validation loss: 2.4098693786128873

Epoch: 6| Step: 8
Training loss: 2.428586959838867
Validation loss: 2.381518430607293

Epoch: 6| Step: 9
Training loss: 3.203213691711426
Validation loss: 2.3736506046787387

Epoch: 6| Step: 10
Training loss: 2.909369707107544
Validation loss: 2.3678798008990545

Epoch: 6| Step: 11
Training loss: 2.8939576148986816
Validation loss: 2.3698173261457876

Epoch: 6| Step: 12
Training loss: 2.747770071029663
Validation loss: 2.3692390252185125

Epoch: 6| Step: 13
Training loss: 3.0954694747924805
Validation loss: 2.3680396182562715

Epoch: 46| Step: 0
Training loss: 2.458737373352051
Validation loss: 2.3787914911905923

Epoch: 6| Step: 1
Training loss: 2.367220878601074
Validation loss: 2.3820543635276055

Epoch: 6| Step: 2
Training loss: 2.495393991470337
Validation loss: 2.3888183409167874

Epoch: 6| Step: 3
Training loss: 2.642703056335449
Validation loss: 2.3875192288429505

Epoch: 6| Step: 4
Training loss: 2.812666177749634
Validation loss: 2.399911683092835

Epoch: 6| Step: 5
Training loss: 3.0832929611206055
Validation loss: 2.410450276508126

Epoch: 6| Step: 6
Training loss: 3.5813822746276855
Validation loss: 2.3943598603689544

Epoch: 6| Step: 7
Training loss: 2.177555561065674
Validation loss: 2.367982595197616

Epoch: 6| Step: 8
Training loss: 1.9207944869995117
Validation loss: 2.3648925724849907

Epoch: 6| Step: 9
Training loss: 2.882768392562866
Validation loss: 2.3693009627762662

Epoch: 6| Step: 10
Training loss: 2.1725144386291504
Validation loss: 2.3804739444486556

Epoch: 6| Step: 11
Training loss: 2.4537158012390137
Validation loss: 2.4201072749271186

Epoch: 6| Step: 12
Training loss: 3.2413902282714844
Validation loss: 2.444446240701983

Epoch: 6| Step: 13
Training loss: 2.778876304626465
Validation loss: 2.456657478886266

Epoch: 47| Step: 0
Training loss: 1.9438763856887817
Validation loss: 2.472115326953191

Epoch: 6| Step: 1
Training loss: 3.1539371013641357
Validation loss: 2.487478038316132

Epoch: 6| Step: 2
Training loss: 2.5775856971740723
Validation loss: 2.452035911621586

Epoch: 6| Step: 3
Training loss: 2.6235008239746094
Validation loss: 2.432571377805484

Epoch: 6| Step: 4
Training loss: 2.9967942237854004
Validation loss: 2.4087539577996857

Epoch: 6| Step: 5
Training loss: 2.4054675102233887
Validation loss: 2.374284057207005

Epoch: 6| Step: 6
Training loss: 2.155162811279297
Validation loss: 2.3624959274004866

Epoch: 6| Step: 7
Training loss: 2.708963394165039
Validation loss: 2.3466795208633586

Epoch: 6| Step: 8
Training loss: 3.309864044189453
Validation loss: 2.3483407779406478

Epoch: 6| Step: 9
Training loss: 2.5117669105529785
Validation loss: 2.3644780266669487

Epoch: 6| Step: 10
Training loss: 2.365326404571533
Validation loss: 2.3748315124101538

Epoch: 6| Step: 11
Training loss: 2.8689768314361572
Validation loss: 2.3922293468188216

Epoch: 6| Step: 12
Training loss: 2.312452554702759
Validation loss: 2.42025883864331

Epoch: 6| Step: 13
Training loss: 3.3230457305908203
Validation loss: 2.4376846077621623

Epoch: 48| Step: 0
Training loss: 2.695769786834717
Validation loss: 2.499574666382164

Epoch: 6| Step: 1
Training loss: 2.398801565170288
Validation loss: 2.470531704605267

Epoch: 6| Step: 2
Training loss: 2.5514655113220215
Validation loss: 2.4377296124735186

Epoch: 6| Step: 3
Training loss: 2.834679126739502
Validation loss: 2.39052390795882

Epoch: 6| Step: 4
Training loss: 2.9719488620758057
Validation loss: 2.3600006180424846

Epoch: 6| Step: 5
Training loss: 2.7250607013702393
Validation loss: 2.350820715709399

Epoch: 6| Step: 6
Training loss: 2.242452383041382
Validation loss: 2.3460411794724

Epoch: 6| Step: 7
Training loss: 2.5126214027404785
Validation loss: 2.35026644122216

Epoch: 6| Step: 8
Training loss: 2.6864497661590576
Validation loss: 2.368374915533168

Epoch: 6| Step: 9
Training loss: 3.5206377506256104
Validation loss: 2.3815376015119654

Epoch: 6| Step: 10
Training loss: 2.270071029663086
Validation loss: 2.378400469339022

Epoch: 6| Step: 11
Training loss: 1.9920989274978638
Validation loss: 2.3939068266140517

Epoch: 6| Step: 12
Training loss: 2.8042311668395996
Validation loss: 2.3815075812801236

Epoch: 6| Step: 13
Training loss: 3.41968035697937
Validation loss: 2.373858259570214

Epoch: 49| Step: 0
Training loss: 2.8668336868286133
Validation loss: 2.362138609732351

Epoch: 6| Step: 1
Training loss: 2.6447856426239014
Validation loss: 2.3499180296415925

Epoch: 6| Step: 2
Training loss: 3.1825573444366455
Validation loss: 2.352812373509971

Epoch: 6| Step: 3
Training loss: 1.7104982137680054
Validation loss: 2.3597605202787664

Epoch: 6| Step: 4
Training loss: 2.885868787765503
Validation loss: 2.362620335753246

Epoch: 6| Step: 5
Training loss: 3.0964231491088867
Validation loss: 2.3661316748588317

Epoch: 6| Step: 6
Training loss: 3.8546056747436523
Validation loss: 2.3531168173718195

Epoch: 6| Step: 7
Training loss: 2.120868682861328
Validation loss: 2.3509574551736154

Epoch: 6| Step: 8
Training loss: 2.423433542251587
Validation loss: 2.3511636962172804

Epoch: 6| Step: 9
Training loss: 2.2137022018432617
Validation loss: 2.351964355796896

Epoch: 6| Step: 10
Training loss: 2.8420372009277344
Validation loss: 2.3529075909686346

Epoch: 6| Step: 11
Training loss: 2.235675573348999
Validation loss: 2.364647719167894

Epoch: 6| Step: 12
Training loss: 1.850170612335205
Validation loss: 2.3632337559935865

Epoch: 6| Step: 13
Training loss: 2.6212780475616455
Validation loss: 2.3872156707189416

Epoch: 50| Step: 0
Training loss: 2.7541770935058594
Validation loss: 2.388327826735794

Epoch: 6| Step: 1
Training loss: 2.5580787658691406
Validation loss: 2.396801616555901

Epoch: 6| Step: 2
Training loss: 2.468808650970459
Validation loss: 2.4257656117921234

Epoch: 6| Step: 3
Training loss: 2.9406847953796387
Validation loss: 2.4525208678296817

Epoch: 6| Step: 4
Training loss: 2.934377908706665
Validation loss: 2.43355288556827

Epoch: 6| Step: 5
Training loss: 2.3071885108947754
Validation loss: 2.4185875615765973

Epoch: 6| Step: 6
Training loss: 2.696321487426758
Validation loss: 2.395519386055649

Epoch: 6| Step: 7
Training loss: 2.269453763961792
Validation loss: 2.3783285438373523

Epoch: 6| Step: 8
Training loss: 2.499694347381592
Validation loss: 2.3651127020517984

Epoch: 6| Step: 9
Training loss: 2.7165584564208984
Validation loss: 2.3522353967030845

Epoch: 6| Step: 10
Training loss: 3.0805563926696777
Validation loss: 2.349048326092382

Epoch: 6| Step: 11
Training loss: 2.3982906341552734
Validation loss: 2.3537136713663735

Epoch: 6| Step: 12
Training loss: 2.6018972396850586
Validation loss: 2.358227645197222

Epoch: 6| Step: 13
Training loss: 2.1943817138671875
Validation loss: 2.362235233347903

Epoch: 51| Step: 0
Training loss: 1.8935357332229614
Validation loss: 2.3574543229995237

Epoch: 6| Step: 1
Training loss: 2.751096248626709
Validation loss: 2.3566823915768693

Epoch: 6| Step: 2
Training loss: 2.51412034034729
Validation loss: 2.3537377875338317

Epoch: 6| Step: 3
Training loss: 2.5575523376464844
Validation loss: 2.352222493899766

Epoch: 6| Step: 4
Training loss: 2.5594775676727295
Validation loss: 2.3480464463592856

Epoch: 6| Step: 5
Training loss: 2.2271437644958496
Validation loss: 2.3413568914577527

Epoch: 6| Step: 6
Training loss: 2.440105676651001
Validation loss: 2.3366882108872935

Epoch: 6| Step: 7
Training loss: 2.9939181804656982
Validation loss: 2.3403493076242428

Epoch: 6| Step: 8
Training loss: 2.7450742721557617
Validation loss: 2.3339928119413313

Epoch: 6| Step: 9
Training loss: 3.0679402351379395
Validation loss: 2.3345055528866347

Epoch: 6| Step: 10
Training loss: 2.280303955078125
Validation loss: 2.336036720583516

Epoch: 6| Step: 11
Training loss: 3.3494646549224854
Validation loss: 2.340463422959851

Epoch: 6| Step: 12
Training loss: 2.7848501205444336
Validation loss: 2.3539861786750054

Epoch: 6| Step: 13
Training loss: 2.109912872314453
Validation loss: 2.3598684072494507

Epoch: 52| Step: 0
Training loss: 3.1466188430786133
Validation loss: 2.3809048334757485

Epoch: 6| Step: 1
Training loss: 2.055675745010376
Validation loss: 2.410341952436714

Epoch: 6| Step: 2
Training loss: 3.331150770187378
Validation loss: 2.4370030613355738

Epoch: 6| Step: 3
Training loss: 2.125998020172119
Validation loss: 2.4212166852848505

Epoch: 6| Step: 4
Training loss: 2.7107808589935303
Validation loss: 2.394697550804384

Epoch: 6| Step: 5
Training loss: 2.899169445037842
Validation loss: 2.385245987164077

Epoch: 6| Step: 6
Training loss: 2.1539411544799805
Validation loss: 2.383025371900169

Epoch: 6| Step: 7
Training loss: 2.1814253330230713
Validation loss: 2.391854493848739

Epoch: 6| Step: 8
Training loss: 3.295224189758301
Validation loss: 2.3954339463223695

Epoch: 6| Step: 9
Training loss: 2.1528382301330566
Validation loss: 2.3983119328816733

Epoch: 6| Step: 10
Training loss: 2.819969654083252
Validation loss: 2.3862069729835755

Epoch: 6| Step: 11
Training loss: 2.7970337867736816
Validation loss: 2.367853936328683

Epoch: 6| Step: 12
Training loss: 2.5586957931518555
Validation loss: 2.360996684720439

Epoch: 6| Step: 13
Training loss: 2.0462331771850586
Validation loss: 2.3497852535657984

Epoch: 53| Step: 0
Training loss: 2.2046477794647217
Validation loss: 2.3434433757617907

Epoch: 6| Step: 1
Training loss: 2.694896936416626
Validation loss: 2.340961899808658

Epoch: 6| Step: 2
Training loss: 2.90449857711792
Validation loss: 2.3370823770441036

Epoch: 6| Step: 3
Training loss: 1.7152180671691895
Validation loss: 2.3375168154316563

Epoch: 6| Step: 4
Training loss: 2.9371023178100586
Validation loss: 2.330331387058381

Epoch: 6| Step: 5
Training loss: 2.937437057495117
Validation loss: 2.3327443958610616

Epoch: 6| Step: 6
Training loss: 2.8790502548217773
Validation loss: 2.336035792545606

Epoch: 6| Step: 7
Training loss: 2.7501306533813477
Validation loss: 2.343430801104474

Epoch: 6| Step: 8
Training loss: 2.7728464603424072
Validation loss: 2.338802917029268

Epoch: 6| Step: 9
Training loss: 2.2983016967773438
Validation loss: 2.3476271552424275

Epoch: 6| Step: 10
Training loss: 1.9489003419876099
Validation loss: 2.3565526111151582

Epoch: 6| Step: 11
Training loss: 2.5468716621398926
Validation loss: 2.358239096979941

Epoch: 6| Step: 12
Training loss: 2.6296021938323975
Validation loss: 2.3546401992920907

Epoch: 6| Step: 13
Training loss: 3.7015326023101807
Validation loss: 2.361248298357892

Epoch: 54| Step: 0
Training loss: 2.3202314376831055
Validation loss: 2.3653733294497252

Epoch: 6| Step: 1
Training loss: 2.579988956451416
Validation loss: 2.369736932939099

Epoch: 6| Step: 2
Training loss: 2.610335350036621
Validation loss: 2.3837633876390356

Epoch: 6| Step: 3
Training loss: 2.8769025802612305
Validation loss: 2.390087881395894

Epoch: 6| Step: 4
Training loss: 3.2481160163879395
Validation loss: 2.39045129283782

Epoch: 6| Step: 5
Training loss: 2.753286600112915
Validation loss: 2.384051912574358

Epoch: 6| Step: 6
Training loss: 2.754762649536133
Validation loss: 2.370600090231947

Epoch: 6| Step: 7
Training loss: 2.6975221633911133
Validation loss: 2.362894917047152

Epoch: 6| Step: 8
Training loss: 2.240504264831543
Validation loss: 2.359094483878023

Epoch: 6| Step: 9
Training loss: 2.899745225906372
Validation loss: 2.3564461482468473

Epoch: 6| Step: 10
Training loss: 2.2778573036193848
Validation loss: 2.3693482952733196

Epoch: 6| Step: 11
Training loss: 2.3687615394592285
Validation loss: 2.37676554213288

Epoch: 6| Step: 12
Training loss: 2.209791898727417
Validation loss: 2.4000758022390385

Epoch: 6| Step: 13
Training loss: 2.810352325439453
Validation loss: 2.420646518789312

Epoch: 55| Step: 0
Training loss: 2.7432310581207275
Validation loss: 2.464585429878645

Epoch: 6| Step: 1
Training loss: 2.3101701736450195
Validation loss: 2.459030492331392

Epoch: 6| Step: 2
Training loss: 3.4754722118377686
Validation loss: 2.4824887732023835

Epoch: 6| Step: 3
Training loss: 2.629575490951538
Validation loss: 2.4751902716134184

Epoch: 6| Step: 4
Training loss: 1.9245736598968506
Validation loss: 2.4401080557095107

Epoch: 6| Step: 5
Training loss: 2.766500949859619
Validation loss: 2.423450107215553

Epoch: 6| Step: 6
Training loss: 3.0502755641937256
Validation loss: 2.4181409497414865

Epoch: 6| Step: 7
Training loss: 2.7840375900268555
Validation loss: 2.376679605053317

Epoch: 6| Step: 8
Training loss: 2.310044288635254
Validation loss: 2.3508300922250234

Epoch: 6| Step: 9
Training loss: 2.4258806705474854
Validation loss: 2.33389889296665

Epoch: 6| Step: 10
Training loss: 2.347327947616577
Validation loss: 2.3282615266820437

Epoch: 6| Step: 11
Training loss: 2.6373701095581055
Validation loss: 2.326540700850948

Epoch: 6| Step: 12
Training loss: 3.230252265930176
Validation loss: 2.326225951153745

Epoch: 6| Step: 13
Training loss: 1.6765155792236328
Validation loss: 2.3258552038541405

Epoch: 56| Step: 0
Training loss: 2.2671942710876465
Validation loss: 2.3221414576294603

Epoch: 6| Step: 1
Training loss: 2.489328384399414
Validation loss: 2.327708690397201

Epoch: 6| Step: 2
Training loss: 2.688760995864868
Validation loss: 2.328719772318358

Epoch: 6| Step: 3
Training loss: 2.926165819168091
Validation loss: 2.3325127196568314

Epoch: 6| Step: 4
Training loss: 3.4369795322418213
Validation loss: 2.34045349654331

Epoch: 6| Step: 5
Training loss: 2.7772042751312256
Validation loss: 2.3460263359931206

Epoch: 6| Step: 6
Training loss: 2.057074546813965
Validation loss: 2.3489054300451793

Epoch: 6| Step: 7
Training loss: 2.715514659881592
Validation loss: 2.3489059812279156

Epoch: 6| Step: 8
Training loss: 2.7142157554626465
Validation loss: 2.3422050578619844

Epoch: 6| Step: 9
Training loss: 1.8328263759613037
Validation loss: 2.328769131373334

Epoch: 6| Step: 10
Training loss: 2.5922064781188965
Validation loss: 2.3288999706186275

Epoch: 6| Step: 11
Training loss: 3.0185489654541016
Validation loss: 2.3309028481924408

Epoch: 6| Step: 12
Training loss: 2.344693660736084
Validation loss: 2.3429076748509563

Epoch: 6| Step: 13
Training loss: 2.591989040374756
Validation loss: 2.347633769435267

Epoch: 57| Step: 0
Training loss: 2.6292152404785156
Validation loss: 2.3608369045360114

Epoch: 6| Step: 1
Training loss: 2.0368666648864746
Validation loss: 2.3746970212587746

Epoch: 6| Step: 2
Training loss: 2.534289598464966
Validation loss: 2.394372255571427

Epoch: 6| Step: 3
Training loss: 2.5820553302764893
Validation loss: 2.408637600560342

Epoch: 6| Step: 4
Training loss: 3.201385498046875
Validation loss: 2.412400858376616

Epoch: 6| Step: 5
Training loss: 2.3584823608398438
Validation loss: 2.420013073951967

Epoch: 6| Step: 6
Training loss: 3.3035717010498047
Validation loss: 2.402086414316649

Epoch: 6| Step: 7
Training loss: 2.675631046295166
Validation loss: 2.389570797643354

Epoch: 6| Step: 8
Training loss: 2.988736629486084
Validation loss: 2.3667331357156076

Epoch: 6| Step: 9
Training loss: 2.157268762588501
Validation loss: 2.3526114674024683

Epoch: 6| Step: 10
Training loss: 2.3214235305786133
Validation loss: 2.3506080514641217

Epoch: 6| Step: 11
Training loss: 2.2437140941619873
Validation loss: 2.3433327649229314

Epoch: 6| Step: 12
Training loss: 3.083707809448242
Validation loss: 2.343462541539182

Epoch: 6| Step: 13
Training loss: 2.039349317550659
Validation loss: 2.333371088068972

Epoch: 58| Step: 0
Training loss: 2.377983808517456
Validation loss: 2.36354164667027

Epoch: 6| Step: 1
Training loss: 2.167844772338867
Validation loss: 2.387952422582975

Epoch: 6| Step: 2
Training loss: 2.8084731101989746
Validation loss: 2.4138048105342413

Epoch: 6| Step: 3
Training loss: 2.5777640342712402
Validation loss: 2.4338120388728317

Epoch: 6| Step: 4
Training loss: 2.1914749145507812
Validation loss: 2.430682164366527

Epoch: 6| Step: 5
Training loss: 2.971177816390991
Validation loss: 2.407495184611249

Epoch: 6| Step: 6
Training loss: 2.856971263885498
Validation loss: 2.3992837539283176

Epoch: 6| Step: 7
Training loss: 2.4491686820983887
Validation loss: 2.375171316567288

Epoch: 6| Step: 8
Training loss: 2.931086778640747
Validation loss: 2.3705218274106263

Epoch: 6| Step: 9
Training loss: 2.5147366523742676
Validation loss: 2.351147856763614

Epoch: 6| Step: 10
Training loss: 2.6035056114196777
Validation loss: 2.342218518257141

Epoch: 6| Step: 11
Training loss: 2.4115946292877197
Validation loss: 2.3496133178792973

Epoch: 6| Step: 12
Training loss: 2.9684062004089355
Validation loss: 2.3432437373745825

Epoch: 6| Step: 13
Training loss: 2.5540385246276855
Validation loss: 2.347228891106062

Epoch: 59| Step: 0
Training loss: 2.32906436920166
Validation loss: 2.338210944206484

Epoch: 6| Step: 1
Training loss: 3.291381359100342
Validation loss: 2.338504540022983

Epoch: 6| Step: 2
Training loss: 2.8126230239868164
Validation loss: 2.342293582936769

Epoch: 6| Step: 3
Training loss: 3.091507911682129
Validation loss: 2.344470283036591

Epoch: 6| Step: 4
Training loss: 3.726011037826538
Validation loss: 2.3327574012100056

Epoch: 6| Step: 5
Training loss: 2.1148617267608643
Validation loss: 2.333608491446382

Epoch: 6| Step: 6
Training loss: 2.6712775230407715
Validation loss: 2.3283226067020046

Epoch: 6| Step: 7
Training loss: 1.972152590751648
Validation loss: 2.3243849713315248

Epoch: 6| Step: 8
Training loss: 1.7089192867279053
Validation loss: 2.3173590424240276

Epoch: 6| Step: 9
Training loss: 1.9689160585403442
Validation loss: 2.3105497296138475

Epoch: 6| Step: 10
Training loss: 2.362297534942627
Validation loss: 2.308779622918816

Epoch: 6| Step: 11
Training loss: 3.4569921493530273
Validation loss: 2.3159116134848645

Epoch: 6| Step: 12
Training loss: 2.5113420486450195
Validation loss: 2.3151750410756757

Epoch: 6| Step: 13
Training loss: 2.102620840072632
Validation loss: 2.3158874691173597

Epoch: 60| Step: 0
Training loss: 2.838517904281616
Validation loss: 2.3221002804335726

Epoch: 6| Step: 1
Training loss: 2.0796186923980713
Validation loss: 2.318602664496309

Epoch: 6| Step: 2
Training loss: 2.579756259918213
Validation loss: 2.3192222502923783

Epoch: 6| Step: 3
Training loss: 2.322730541229248
Validation loss: 2.3120600049213698

Epoch: 6| Step: 4
Training loss: 2.0581698417663574
Validation loss: 2.316572138058242

Epoch: 6| Step: 5
Training loss: 2.562666177749634
Validation loss: 2.3311299970073085

Epoch: 6| Step: 6
Training loss: 2.5362465381622314
Validation loss: 2.332057850335234

Epoch: 6| Step: 7
Training loss: 3.0132224559783936
Validation loss: 2.3289398608669156

Epoch: 6| Step: 8
Training loss: 2.5426502227783203
Validation loss: 2.3323687199623353

Epoch: 6| Step: 9
Training loss: 2.478816509246826
Validation loss: 2.340156650030485

Epoch: 6| Step: 10
Training loss: 2.7933640480041504
Validation loss: 2.328577544099541

Epoch: 6| Step: 11
Training loss: 2.633151054382324
Validation loss: 2.3186398962492585

Epoch: 6| Step: 12
Training loss: 3.663531541824341
Validation loss: 2.3156581950444046

Epoch: 6| Step: 13
Training loss: 1.7148175239562988
Validation loss: 2.3157311254932034

Epoch: 61| Step: 0
Training loss: 2.2554147243499756
Validation loss: 2.3085836543831775

Epoch: 6| Step: 1
Training loss: 2.5478365421295166
Validation loss: 2.3145296778730167

Epoch: 6| Step: 2
Training loss: 3.1025447845458984
Validation loss: 2.319665778067804

Epoch: 6| Step: 3
Training loss: 2.9465041160583496
Validation loss: 2.317320533978042

Epoch: 6| Step: 4
Training loss: 2.951296329498291
Validation loss: 2.3200949058737805

Epoch: 6| Step: 5
Training loss: 2.9600014686584473
Validation loss: 2.31962925387967

Epoch: 6| Step: 6
Training loss: 1.2768876552581787
Validation loss: 2.310296384237146

Epoch: 6| Step: 7
Training loss: 2.145798444747925
Validation loss: 2.307956381510663

Epoch: 6| Step: 8
Training loss: 2.3798630237579346
Validation loss: 2.3081943206889655

Epoch: 6| Step: 9
Training loss: 2.5840721130371094
Validation loss: 2.304253933250263

Epoch: 6| Step: 10
Training loss: 3.1424479484558105
Validation loss: 2.307893999161259

Epoch: 6| Step: 11
Training loss: 2.3597030639648438
Validation loss: 2.3091952877659954

Epoch: 6| Step: 12
Training loss: 2.5407042503356934
Validation loss: 2.304779957699519

Epoch: 6| Step: 13
Training loss: 3.1820058822631836
Validation loss: 2.309078170407203

Epoch: 62| Step: 0
Training loss: 2.54826283454895
Validation loss: 2.3079048856612174

Epoch: 6| Step: 1
Training loss: 2.658195734024048
Validation loss: 2.307249140995805

Epoch: 6| Step: 2
Training loss: 2.7593612670898438
Validation loss: 2.301908803242509

Epoch: 6| Step: 3
Training loss: 2.9641027450561523
Validation loss: 2.3063651259227465

Epoch: 6| Step: 4
Training loss: 2.4691884517669678
Validation loss: 2.3070616363197245

Epoch: 6| Step: 5
Training loss: 2.4914400577545166
Validation loss: 2.3054436714418474

Epoch: 6| Step: 6
Training loss: 2.717639923095703
Validation loss: 2.2981653085318943

Epoch: 6| Step: 7
Training loss: 2.564948797225952
Validation loss: 2.30165361332637

Epoch: 6| Step: 8
Training loss: 2.5619025230407715
Validation loss: 2.3053362190082507

Epoch: 6| Step: 9
Training loss: 2.2417502403259277
Validation loss: 2.315359002800398

Epoch: 6| Step: 10
Training loss: 2.717909336090088
Validation loss: 2.318713693208592

Epoch: 6| Step: 11
Training loss: 2.3464386463165283
Validation loss: 2.332479033418881

Epoch: 6| Step: 12
Training loss: 2.2056503295898438
Validation loss: 2.3553375454359156

Epoch: 6| Step: 13
Training loss: 2.8080997467041016
Validation loss: 2.364367467100902

Epoch: 63| Step: 0
Training loss: 2.3975636959075928
Validation loss: 2.3941746014420704

Epoch: 6| Step: 1
Training loss: 2.841463088989258
Validation loss: 2.4189467173750683

Epoch: 6| Step: 2
Training loss: 2.2334957122802734
Validation loss: 2.417949443222374

Epoch: 6| Step: 3
Training loss: 2.261833906173706
Validation loss: 2.4569990763100247

Epoch: 6| Step: 4
Training loss: 2.84012508392334
Validation loss: 2.4509761846193703

Epoch: 6| Step: 5
Training loss: 3.08188796043396
Validation loss: 2.4189060554709485

Epoch: 6| Step: 6
Training loss: 2.911466360092163
Validation loss: 2.386022042202693

Epoch: 6| Step: 7
Training loss: 2.254485607147217
Validation loss: 2.371656938265729

Epoch: 6| Step: 8
Training loss: 2.3644933700561523
Validation loss: 2.3660729059609036

Epoch: 6| Step: 9
Training loss: 2.981785774230957
Validation loss: 2.358555737362113

Epoch: 6| Step: 10
Training loss: 2.807976245880127
Validation loss: 2.3493268361655613

Epoch: 6| Step: 11
Training loss: 1.968245029449463
Validation loss: 2.338223252245175

Epoch: 6| Step: 12
Training loss: 3.025244951248169
Validation loss: 2.3288423451044227

Epoch: 6| Step: 13
Training loss: 1.7727795839309692
Validation loss: 2.3165902168520036

Epoch: 64| Step: 0
Training loss: 2.645632028579712
Validation loss: 2.3151662657337804

Epoch: 6| Step: 1
Training loss: 2.812837839126587
Validation loss: 2.3244164118202786

Epoch: 6| Step: 2
Training loss: 3.2104077339172363
Validation loss: 2.3297690755577496

Epoch: 6| Step: 3
Training loss: 2.952517032623291
Validation loss: 2.3364467338849138

Epoch: 6| Step: 4
Training loss: 2.3977017402648926
Validation loss: 2.3321636851115892

Epoch: 6| Step: 5
Training loss: 2.6987998485565186
Validation loss: 2.3369169696684806

Epoch: 6| Step: 6
Training loss: 2.403578281402588
Validation loss: 2.324160724557856

Epoch: 6| Step: 7
Training loss: 3.1431350708007812
Validation loss: 2.3211285837234987

Epoch: 6| Step: 8
Training loss: 1.976061463356018
Validation loss: 2.316906307333259

Epoch: 6| Step: 9
Training loss: 2.0748682022094727
Validation loss: 2.3257229430701143

Epoch: 6| Step: 10
Training loss: 2.58599853515625
Validation loss: 2.327850471260727

Epoch: 6| Step: 11
Training loss: 2.471644401550293
Validation loss: 2.330640213463896

Epoch: 6| Step: 12
Training loss: 2.2733826637268066
Validation loss: 2.335559844970703

Epoch: 6| Step: 13
Training loss: 2.502241849899292
Validation loss: 2.342986690100803

Epoch: 65| Step: 0
Training loss: 2.3344955444335938
Validation loss: 2.3441218406923356

Epoch: 6| Step: 1
Training loss: 2.5612130165100098
Validation loss: 2.3545765453769314

Epoch: 6| Step: 2
Training loss: 2.6247384548187256
Validation loss: 2.3476448956356255

Epoch: 6| Step: 3
Training loss: 3.3793845176696777
Validation loss: 2.3426120332492295

Epoch: 6| Step: 4
Training loss: 2.89140248298645
Validation loss: 2.3220499382224133

Epoch: 6| Step: 5
Training loss: 3.4336395263671875
Validation loss: 2.3185401347375687

Epoch: 6| Step: 6
Training loss: 2.2858238220214844
Validation loss: 2.3113800966611473

Epoch: 6| Step: 7
Training loss: 2.384239912033081
Validation loss: 2.3001773152300107

Epoch: 6| Step: 8
Training loss: 2.088649034500122
Validation loss: 2.298697722855435

Epoch: 6| Step: 9
Training loss: 2.279684066772461
Validation loss: 2.285784367592104

Epoch: 6| Step: 10
Training loss: 2.2209887504577637
Validation loss: 2.291599950482768

Epoch: 6| Step: 11
Training loss: 2.840632438659668
Validation loss: 2.3137880012553227

Epoch: 6| Step: 12
Training loss: 2.5626418590545654
Validation loss: 2.3316765703180784

Epoch: 6| Step: 13
Training loss: 1.7475860118865967
Validation loss: 2.324493218493718

Epoch: 66| Step: 0
Training loss: 3.0349280834198
Validation loss: 2.3297936941987727

Epoch: 6| Step: 1
Training loss: 2.2466723918914795
Validation loss: 2.334819250209357

Epoch: 6| Step: 2
Training loss: 2.1933226585388184
Validation loss: 2.338862654983356

Epoch: 6| Step: 3
Training loss: 2.8404898643493652
Validation loss: 2.331789949888824

Epoch: 6| Step: 4
Training loss: 1.8951804637908936
Validation loss: 2.3295811722355504

Epoch: 6| Step: 5
Training loss: 2.9584038257598877
Validation loss: 2.334061227818971

Epoch: 6| Step: 6
Training loss: 2.2032289505004883
Validation loss: 2.3217823992493334

Epoch: 6| Step: 7
Training loss: 2.8455491065979004
Validation loss: 2.3272094393289215

Epoch: 6| Step: 8
Training loss: 3.1146035194396973
Validation loss: 2.301506406517439

Epoch: 6| Step: 9
Training loss: 2.599865436553955
Validation loss: 2.292120656659526

Epoch: 6| Step: 10
Training loss: 2.49145770072937
Validation loss: 2.288193864207114

Epoch: 6| Step: 11
Training loss: 2.2753119468688965
Validation loss: 2.284027071409328

Epoch: 6| Step: 12
Training loss: 2.3891501426696777
Validation loss: 2.2819609347210137

Epoch: 6| Step: 13
Training loss: 3.0191051959991455
Validation loss: 2.2835650700394825

Epoch: 67| Step: 0
Training loss: 2.85335636138916
Validation loss: 2.2931661734016995

Epoch: 6| Step: 1
Training loss: 2.778304100036621
Validation loss: 2.2960832888080227

Epoch: 6| Step: 2
Training loss: 2.5884785652160645
Validation loss: 2.3095426226174958

Epoch: 6| Step: 3
Training loss: 2.4593112468719482
Validation loss: 2.320001543209117

Epoch: 6| Step: 4
Training loss: 1.4926966428756714
Validation loss: 2.326591596808485

Epoch: 6| Step: 5
Training loss: 3.6999547481536865
Validation loss: 2.3302082425804547

Epoch: 6| Step: 6
Training loss: 2.221031665802002
Validation loss: 2.3093674823802006

Epoch: 6| Step: 7
Training loss: 2.7432351112365723
Validation loss: 2.305142180894011

Epoch: 6| Step: 8
Training loss: 2.5373668670654297
Validation loss: 2.292802333831787

Epoch: 6| Step: 9
Training loss: 2.5872623920440674
Validation loss: 2.2997739263760146

Epoch: 6| Step: 10
Training loss: 2.391634225845337
Validation loss: 2.294082212191756

Epoch: 6| Step: 11
Training loss: 2.9915080070495605
Validation loss: 2.2947667439778647

Epoch: 6| Step: 12
Training loss: 1.8014591932296753
Validation loss: 2.3020463771717523

Epoch: 6| Step: 13
Training loss: 2.702965497970581
Validation loss: 2.3213054877455517

Epoch: 68| Step: 0
Training loss: 2.957798480987549
Validation loss: 2.332050347840914

Epoch: 6| Step: 1
Training loss: 1.9390738010406494
Validation loss: 2.338380911016977

Epoch: 6| Step: 2
Training loss: 2.6980032920837402
Validation loss: 2.353484333202403

Epoch: 6| Step: 3
Training loss: 2.647665023803711
Validation loss: 2.3883263962243193

Epoch: 6| Step: 4
Training loss: 2.9537580013275146
Validation loss: 2.404090912111344

Epoch: 6| Step: 5
Training loss: 2.222992181777954
Validation loss: 2.4253528143769953

Epoch: 6| Step: 6
Training loss: 3.050508499145508
Validation loss: 2.4022869730508454

Epoch: 6| Step: 7
Training loss: 2.4967525005340576
Validation loss: 2.3332651456197104

Epoch: 6| Step: 8
Training loss: 2.475074291229248
Validation loss: 2.3115943324181343

Epoch: 6| Step: 9
Training loss: 2.9093804359436035
Validation loss: 2.2921881355265135

Epoch: 6| Step: 10
Training loss: 2.0588133335113525
Validation loss: 2.279037696059032

Epoch: 6| Step: 11
Training loss: 2.474982738494873
Validation loss: 2.276076606524888

Epoch: 6| Step: 12
Training loss: 2.404578447341919
Validation loss: 2.268946921953591

Epoch: 6| Step: 13
Training loss: 2.8410089015960693
Validation loss: 2.2646421975986932

Epoch: 69| Step: 0
Training loss: 2.3603742122650146
Validation loss: 2.2698391099129953

Epoch: 6| Step: 1
Training loss: 2.0901498794555664
Validation loss: 2.2619573698248914

Epoch: 6| Step: 2
Training loss: 2.7384581565856934
Validation loss: 2.2636411651488273

Epoch: 6| Step: 3
Training loss: 2.4692463874816895
Validation loss: 2.262153774179438

Epoch: 6| Step: 4
Training loss: 2.038341999053955
Validation loss: 2.2650323273033224

Epoch: 6| Step: 5
Training loss: 3.0188403129577637
Validation loss: 2.2728839458957797

Epoch: 6| Step: 6
Training loss: 2.4369049072265625
Validation loss: 2.2723221368687128

Epoch: 6| Step: 7
Training loss: 2.9749481678009033
Validation loss: 2.286753095606322

Epoch: 6| Step: 8
Training loss: 3.0240814685821533
Validation loss: 2.2902879330419723

Epoch: 6| Step: 9
Training loss: 1.8562970161437988
Validation loss: 2.307588131197037

Epoch: 6| Step: 10
Training loss: 2.342532157897949
Validation loss: 2.31258394897625

Epoch: 6| Step: 11
Training loss: 2.8464560508728027
Validation loss: 2.3301196047054824

Epoch: 6| Step: 12
Training loss: 3.121096134185791
Validation loss: 2.3281982688493628

Epoch: 6| Step: 13
Training loss: 2.3012900352478027
Validation loss: 2.3410424186337377

Epoch: 70| Step: 0
Training loss: 3.2921016216278076
Validation loss: 2.359052901626915

Epoch: 6| Step: 1
Training loss: 2.674330949783325
Validation loss: 2.323741897459953

Epoch: 6| Step: 2
Training loss: 2.6999921798706055
Validation loss: 2.3064832559195896

Epoch: 6| Step: 3
Training loss: 3.001400947570801
Validation loss: 2.290459589291644

Epoch: 6| Step: 4
Training loss: 2.201892614364624
Validation loss: 2.282259436063869

Epoch: 6| Step: 5
Training loss: 2.130796432495117
Validation loss: 2.2652392156662478

Epoch: 6| Step: 6
Training loss: 2.271683692932129
Validation loss: 2.2675123881268244

Epoch: 6| Step: 7
Training loss: 2.700385570526123
Validation loss: 2.2635581852287374

Epoch: 6| Step: 8
Training loss: 2.071155309677124
Validation loss: 2.2714582361200804

Epoch: 6| Step: 9
Training loss: 2.467435359954834
Validation loss: 2.268233964520116

Epoch: 6| Step: 10
Training loss: 2.3594000339508057
Validation loss: 2.275784692456645

Epoch: 6| Step: 11
Training loss: 2.283433198928833
Validation loss: 2.2784517324098976

Epoch: 6| Step: 12
Training loss: 2.9831554889678955
Validation loss: 2.2736824045899096

Epoch: 6| Step: 13
Training loss: 2.8917665481567383
Validation loss: 2.280924904731012

Epoch: 71| Step: 0
Training loss: 2.627509593963623
Validation loss: 2.2786149953001287

Epoch: 6| Step: 1
Training loss: 2.2735517024993896
Validation loss: 2.275630258744763

Epoch: 6| Step: 2
Training loss: 2.1534595489501953
Validation loss: 2.2821915482962005

Epoch: 6| Step: 3
Training loss: 2.4228973388671875
Validation loss: 2.2800463476488666

Epoch: 6| Step: 4
Training loss: 3.136216640472412
Validation loss: 2.2787256958664104

Epoch: 6| Step: 5
Training loss: 2.487433433532715
Validation loss: 2.2809506667557584

Epoch: 6| Step: 6
Training loss: 2.0222654342651367
Validation loss: 2.28681359880714

Epoch: 6| Step: 7
Training loss: 2.7150769233703613
Validation loss: 2.294674406769455

Epoch: 6| Step: 8
Training loss: 2.7996745109558105
Validation loss: 2.29050721404373

Epoch: 6| Step: 9
Training loss: 2.788088321685791
Validation loss: 2.300757372251121

Epoch: 6| Step: 10
Training loss: 2.4207022190093994
Validation loss: 2.315777673516222

Epoch: 6| Step: 11
Training loss: 3.065572738647461
Validation loss: 2.3138866347651326

Epoch: 6| Step: 12
Training loss: 2.271528720855713
Validation loss: 2.3254096841299408

Epoch: 6| Step: 13
Training loss: 2.2833151817321777
Validation loss: 2.321990236159294

Epoch: 72| Step: 0
Training loss: 2.376136302947998
Validation loss: 2.326640967399843

Epoch: 6| Step: 1
Training loss: 1.8928406238555908
Validation loss: 2.3564427206593175

Epoch: 6| Step: 2
Training loss: 3.321124315261841
Validation loss: 2.3628646353239655

Epoch: 6| Step: 3
Training loss: 3.2946081161499023
Validation loss: 2.3688588693577755

Epoch: 6| Step: 4
Training loss: 2.3037660121917725
Validation loss: 2.3521169539420836

Epoch: 6| Step: 5
Training loss: 2.4629268646240234
Validation loss: 2.345059656327771

Epoch: 6| Step: 6
Training loss: 2.537923812866211
Validation loss: 2.340969362566548

Epoch: 6| Step: 7
Training loss: 2.0938987731933594
Validation loss: 2.3277658826561383

Epoch: 6| Step: 8
Training loss: 3.382352590560913
Validation loss: 2.31621189014886

Epoch: 6| Step: 9
Training loss: 2.0269687175750732
Validation loss: 2.3057063856432514

Epoch: 6| Step: 10
Training loss: 2.4868855476379395
Validation loss: 2.3069802509841097

Epoch: 6| Step: 11
Training loss: 2.8586220741271973
Validation loss: 2.294786468628914

Epoch: 6| Step: 12
Training loss: 2.491957187652588
Validation loss: 2.292461188890601

Epoch: 6| Step: 13
Training loss: 1.7380805015563965
Validation loss: 2.2826246523088023

Epoch: 73| Step: 0
Training loss: 2.305652141571045
Validation loss: 2.2778653995965117

Epoch: 6| Step: 1
Training loss: 3.0601747035980225
Validation loss: 2.2704046157098587

Epoch: 6| Step: 2
Training loss: 2.8502650260925293
Validation loss: 2.280322115908387

Epoch: 6| Step: 3
Training loss: 2.7961606979370117
Validation loss: 2.3055482090160413

Epoch: 6| Step: 4
Training loss: 3.1957361698150635
Validation loss: 2.33538902959516

Epoch: 6| Step: 5
Training loss: 2.7289905548095703
Validation loss: 2.3286622839589275

Epoch: 6| Step: 6
Training loss: 1.7302253246307373
Validation loss: 2.38168252155345

Epoch: 6| Step: 7
Training loss: 2.708310127258301
Validation loss: 2.4291935607951176

Epoch: 6| Step: 8
Training loss: 2.6223714351654053
Validation loss: 2.380889102976809

Epoch: 6| Step: 9
Training loss: 2.372352123260498
Validation loss: 2.331028543492799

Epoch: 6| Step: 10
Training loss: 2.736919403076172
Validation loss: 2.2771804589097218

Epoch: 6| Step: 11
Training loss: 2.4343833923339844
Validation loss: 2.264481847004224

Epoch: 6| Step: 12
Training loss: 2.6658475399017334
Validation loss: 2.2680502988958873

Epoch: 6| Step: 13
Training loss: 2.0038561820983887
Validation loss: 2.2729977125762613

Epoch: 74| Step: 0
Training loss: 2.3256311416625977
Validation loss: 2.274478184279575

Epoch: 6| Step: 1
Training loss: 2.256720542907715
Validation loss: 2.296656254799135

Epoch: 6| Step: 2
Training loss: 2.75718355178833
Validation loss: 2.3120551955315376

Epoch: 6| Step: 3
Training loss: 2.56821608543396
Validation loss: 2.3099340085060365

Epoch: 6| Step: 4
Training loss: 2.4861035346984863
Validation loss: 2.315607017086398

Epoch: 6| Step: 5
Training loss: 2.532435894012451
Validation loss: 2.3249358002857496

Epoch: 6| Step: 6
Training loss: 1.9855058193206787
Validation loss: 2.334912375737262

Epoch: 6| Step: 7
Training loss: 2.3779244422912598
Validation loss: 2.351054904281452

Epoch: 6| Step: 8
Training loss: 2.627142906188965
Validation loss: 2.3486079400585544

Epoch: 6| Step: 9
Training loss: 2.3434391021728516
Validation loss: 2.334772179203649

Epoch: 6| Step: 10
Training loss: 2.6391282081604004
Validation loss: 2.3078020823899137

Epoch: 6| Step: 11
Training loss: 2.5806384086608887
Validation loss: 2.3038218687939387

Epoch: 6| Step: 12
Training loss: 3.5870466232299805
Validation loss: 2.311542631477438

Epoch: 6| Step: 13
Training loss: 2.644986391067505
Validation loss: 2.321156119787565

Epoch: 75| Step: 0
Training loss: 3.0084164142608643
Validation loss: 2.306562433960617

Epoch: 6| Step: 1
Training loss: 3.049084424972534
Validation loss: 2.2852241044403403

Epoch: 6| Step: 2
Training loss: 2.681955099105835
Validation loss: 2.278535525004069

Epoch: 6| Step: 3
Training loss: 2.3804798126220703
Validation loss: 2.2715915082603373

Epoch: 6| Step: 4
Training loss: 2.4137158393859863
Validation loss: 2.269272745296519

Epoch: 6| Step: 5
Training loss: 2.077723979949951
Validation loss: 2.2744915869928177

Epoch: 6| Step: 6
Training loss: 2.1600139141082764
Validation loss: 2.2681362090572232

Epoch: 6| Step: 7
Training loss: 2.7486166954040527
Validation loss: 2.2698142784898

Epoch: 6| Step: 8
Training loss: 2.540522575378418
Validation loss: 2.2725600606651715

Epoch: 6| Step: 9
Training loss: 2.5945568084716797
Validation loss: 2.278678463351342

Epoch: 6| Step: 10
Training loss: 3.366697311401367
Validation loss: 2.281830664603941

Epoch: 6| Step: 11
Training loss: 1.9342398643493652
Validation loss: 2.2822985033835135

Epoch: 6| Step: 12
Training loss: 2.625880241394043
Validation loss: 2.2722313980902396

Epoch: 6| Step: 13
Training loss: 1.785642147064209
Validation loss: 2.2687713023154967

Epoch: 76| Step: 0
Training loss: 3.017808437347412
Validation loss: 2.2645377856428905

Epoch: 6| Step: 1
Training loss: 2.8313097953796387
Validation loss: 2.2831612620302426

Epoch: 6| Step: 2
Training loss: 2.4858391284942627
Validation loss: 2.3061245103036203

Epoch: 6| Step: 3
Training loss: 2.465885877609253
Validation loss: 2.3183752746992212

Epoch: 6| Step: 4
Training loss: 2.5281691551208496
Validation loss: 2.3374773353658695

Epoch: 6| Step: 5
Training loss: 3.070474624633789
Validation loss: 2.326695683181927

Epoch: 6| Step: 6
Training loss: 2.3070082664489746
Validation loss: 2.313272717178509

Epoch: 6| Step: 7
Training loss: 1.940325140953064
Validation loss: 2.283042033513387

Epoch: 6| Step: 8
Training loss: 2.7847630977630615
Validation loss: 2.2713069633771013

Epoch: 6| Step: 9
Training loss: 2.358971118927002
Validation loss: 2.2647565923711306

Epoch: 6| Step: 10
Training loss: 2.7002387046813965
Validation loss: 2.2629112056506577

Epoch: 6| Step: 11
Training loss: 2.0708794593811035
Validation loss: 2.2591544402542936

Epoch: 6| Step: 12
Training loss: 2.5245041847229004
Validation loss: 2.257766144250029

Epoch: 6| Step: 13
Training loss: 2.4146649837493896
Validation loss: 2.250692750817986

Epoch: 77| Step: 0
Training loss: 2.547931432723999
Validation loss: 2.2500287358478834

Epoch: 6| Step: 1
Training loss: 2.866724967956543
Validation loss: 2.2586353440438547

Epoch: 6| Step: 2
Training loss: 2.599679470062256
Validation loss: 2.257830391647995

Epoch: 6| Step: 3
Training loss: 4.05648136138916
Validation loss: 2.2602737026829876

Epoch: 6| Step: 4
Training loss: 1.6392138004302979
Validation loss: 2.255053799639466

Epoch: 6| Step: 5
Training loss: 2.763355255126953
Validation loss: 2.25834757538252

Epoch: 6| Step: 6
Training loss: 2.4245896339416504
Validation loss: 2.2556584009560208

Epoch: 6| Step: 7
Training loss: 2.1751723289489746
Validation loss: 2.2592074332698697

Epoch: 6| Step: 8
Training loss: 2.4156060218811035
Validation loss: 2.2522210126282065

Epoch: 6| Step: 9
Training loss: 2.164102077484131
Validation loss: 2.2622317857639764

Epoch: 6| Step: 10
Training loss: 2.7398841381073
Validation loss: 2.2828985644925024

Epoch: 6| Step: 11
Training loss: 2.570711612701416
Validation loss: 2.297065063189435

Epoch: 6| Step: 12
Training loss: 2.2169718742370605
Validation loss: 2.3349297200479815

Epoch: 6| Step: 13
Training loss: 1.6893980503082275
Validation loss: 2.3395945718211513

Epoch: 78| Step: 0
Training loss: 2.715419292449951
Validation loss: 2.3596256368903705

Epoch: 6| Step: 1
Training loss: 2.612515926361084
Validation loss: 2.3651821177492858

Epoch: 6| Step: 2
Training loss: 2.0790162086486816
Validation loss: 2.3734736340020293

Epoch: 6| Step: 3
Training loss: 2.139240026473999
Validation loss: 2.3691961483288835

Epoch: 6| Step: 4
Training loss: 3.6771743297576904
Validation loss: 2.352399810667961

Epoch: 6| Step: 5
Training loss: 2.054112672805786
Validation loss: 2.335275532096945

Epoch: 6| Step: 6
Training loss: 2.401416778564453
Validation loss: 2.3136720208711523

Epoch: 6| Step: 7
Training loss: 2.9974758625030518
Validation loss: 2.290495564860682

Epoch: 6| Step: 8
Training loss: 2.362746238708496
Validation loss: 2.275996505573232

Epoch: 6| Step: 9
Training loss: 2.099536418914795
Validation loss: 2.269624694701164

Epoch: 6| Step: 10
Training loss: 2.2644917964935303
Validation loss: 2.2674518451895764

Epoch: 6| Step: 11
Training loss: 1.9743068218231201
Validation loss: 2.2599446940165695

Epoch: 6| Step: 12
Training loss: 3.5600616931915283
Validation loss: 2.2566721516270793

Epoch: 6| Step: 13
Training loss: 2.535822629928589
Validation loss: 2.257639709339347

Epoch: 79| Step: 0
Training loss: 2.3208141326904297
Validation loss: 2.243844791125226

Epoch: 6| Step: 1
Training loss: 2.5682573318481445
Validation loss: 2.2518626259219263

Epoch: 6| Step: 2
Training loss: 2.2918267250061035
Validation loss: 2.246903442567395

Epoch: 6| Step: 3
Training loss: 3.005241870880127
Validation loss: 2.25642035084386

Epoch: 6| Step: 4
Training loss: 2.2863030433654785
Validation loss: 2.253264332330355

Epoch: 6| Step: 5
Training loss: 2.2824816703796387
Validation loss: 2.2684862716223604

Epoch: 6| Step: 6
Training loss: 3.161877393722534
Validation loss: 2.2756314277648926

Epoch: 6| Step: 7
Training loss: 2.111464500427246
Validation loss: 2.279616314877746

Epoch: 6| Step: 8
Training loss: 2.6739485263824463
Validation loss: 2.2854434674785984

Epoch: 6| Step: 9
Training loss: 2.123107433319092
Validation loss: 2.2772563221634075

Epoch: 6| Step: 10
Training loss: 2.8415589332580566
Validation loss: 2.2759554411775325

Epoch: 6| Step: 11
Training loss: 2.8023481369018555
Validation loss: 2.287849400633125

Epoch: 6| Step: 12
Training loss: 2.2603542804718018
Validation loss: 2.2906404208111506

Epoch: 6| Step: 13
Training loss: 2.3105735778808594
Validation loss: 2.3037804788158787

Epoch: 80| Step: 0
Training loss: 2.701953172683716
Validation loss: 2.3192038715526624

Epoch: 6| Step: 1
Training loss: 2.984457015991211
Validation loss: 2.3341289950955297

Epoch: 6| Step: 2
Training loss: 3.0769574642181396
Validation loss: 2.3155052149167625

Epoch: 6| Step: 3
Training loss: 2.5167016983032227
Validation loss: 2.284745813697897

Epoch: 6| Step: 4
Training loss: 3.1432368755340576
Validation loss: 2.2507516671252508

Epoch: 6| Step: 5
Training loss: 2.634964942932129
Validation loss: 2.235884775397598

Epoch: 6| Step: 6
Training loss: 2.713682174682617
Validation loss: 2.2318126565666607

Epoch: 6| Step: 7
Training loss: 2.024101972579956
Validation loss: 2.2451897180208595

Epoch: 6| Step: 8
Training loss: 2.8713860511779785
Validation loss: 2.2657265150418846

Epoch: 6| Step: 9
Training loss: 2.3448076248168945
Validation loss: 2.313961669962893

Epoch: 6| Step: 10
Training loss: 1.7242047786712646
Validation loss: 2.3093646803209857

Epoch: 6| Step: 11
Training loss: 2.854733467102051
Validation loss: 2.3298197664240354

Epoch: 6| Step: 12
Training loss: 1.958992600440979
Validation loss: 2.315801912738431

Epoch: 6| Step: 13
Training loss: 2.144604206085205
Validation loss: 2.31303672893073

Epoch: 81| Step: 0
Training loss: 2.609131336212158
Validation loss: 2.307964672324478

Epoch: 6| Step: 1
Training loss: 2.657531976699829
Validation loss: 2.302397325474729

Epoch: 6| Step: 2
Training loss: 2.357309103012085
Validation loss: 2.294018486494659

Epoch: 6| Step: 3
Training loss: 3.5240800380706787
Validation loss: 2.2999471361919115

Epoch: 6| Step: 4
Training loss: 3.7578165531158447
Validation loss: 2.2880004426484466

Epoch: 6| Step: 5
Training loss: 2.5517427921295166
Validation loss: 2.272056092498123

Epoch: 6| Step: 6
Training loss: 2.2976622581481934
Validation loss: 2.268005368530109

Epoch: 6| Step: 7
Training loss: 1.5558843612670898
Validation loss: 2.2809153654242076

Epoch: 6| Step: 8
Training loss: 2.391639232635498
Validation loss: 2.2814905617826726

Epoch: 6| Step: 9
Training loss: 3.0325071811676025
Validation loss: 2.2770164256454795

Epoch: 6| Step: 10
Training loss: 1.8607463836669922
Validation loss: 2.3073780818652083

Epoch: 6| Step: 11
Training loss: 1.7411608695983887
Validation loss: 2.3308820339941208

Epoch: 6| Step: 12
Training loss: 2.577854633331299
Validation loss: 2.3289125170758975

Epoch: 6| Step: 13
Training loss: 2.540391206741333
Validation loss: 2.3634726744826122

Epoch: 82| Step: 0
Training loss: 2.664802074432373
Validation loss: 2.374982105788364

Epoch: 6| Step: 1
Training loss: 2.511791229248047
Validation loss: 2.3692502283280894

Epoch: 6| Step: 2
Training loss: 2.4403059482574463
Validation loss: 2.382516812252742

Epoch: 6| Step: 3
Training loss: 1.8938491344451904
Validation loss: 2.3821359436999083

Epoch: 6| Step: 4
Training loss: 2.9589247703552246
Validation loss: 2.397696172037432

Epoch: 6| Step: 5
Training loss: 2.662567138671875
Validation loss: 2.391586742093486

Epoch: 6| Step: 6
Training loss: 2.2790489196777344
Validation loss: 2.36205046151274

Epoch: 6| Step: 7
Training loss: 1.8641066551208496
Validation loss: 2.329051302325341

Epoch: 6| Step: 8
Training loss: 3.2850160598754883
Validation loss: 2.2946728352577455

Epoch: 6| Step: 9
Training loss: 2.7334353923797607
Validation loss: 2.256374743676955

Epoch: 6| Step: 10
Training loss: 2.562163829803467
Validation loss: 2.251063331480949

Epoch: 6| Step: 11
Training loss: 2.644500255584717
Validation loss: 2.2469444800448675

Epoch: 6| Step: 12
Training loss: 2.180633068084717
Validation loss: 2.2458802012987036

Epoch: 6| Step: 13
Training loss: 3.1342172622680664
Validation loss: 2.255832338845858

Epoch: 83| Step: 0
Training loss: 2.2216172218322754
Validation loss: 2.262023869381156

Epoch: 6| Step: 1
Training loss: 2.6774322986602783
Validation loss: 2.279830627543952

Epoch: 6| Step: 2
Training loss: 2.132624387741089
Validation loss: 2.2816554320755826

Epoch: 6| Step: 3
Training loss: 2.011401653289795
Validation loss: 2.2790105855593117

Epoch: 6| Step: 4
Training loss: 2.497743606567383
Validation loss: 2.2780938225407756

Epoch: 6| Step: 5
Training loss: 3.5207619667053223
Validation loss: 2.2759522802086285

Epoch: 6| Step: 6
Training loss: 2.5263993740081787
Validation loss: 2.2737364615163496

Epoch: 6| Step: 7
Training loss: 2.292971134185791
Validation loss: 2.274058109970503

Epoch: 6| Step: 8
Training loss: 3.0190839767456055
Validation loss: 2.286005225232852

Epoch: 6| Step: 9
Training loss: 2.8107635974884033
Validation loss: 2.2759923165844334

Epoch: 6| Step: 10
Training loss: 2.3823494911193848
Validation loss: 2.274285547194942

Epoch: 6| Step: 11
Training loss: 2.5850753784179688
Validation loss: 2.287074109559418

Epoch: 6| Step: 12
Training loss: 2.0575551986694336
Validation loss: 2.277663507769185

Epoch: 6| Step: 13
Training loss: 2.930814027786255
Validation loss: 2.2815863727241434

Epoch: 84| Step: 0
Training loss: 2.2164995670318604
Validation loss: 2.272746724467124

Epoch: 6| Step: 1
Training loss: 2.0698790550231934
Validation loss: 2.26872613353114

Epoch: 6| Step: 2
Training loss: 2.170003652572632
Validation loss: 2.2658980302913214

Epoch: 6| Step: 3
Training loss: 2.478407144546509
Validation loss: 2.2367872140740834

Epoch: 6| Step: 4
Training loss: 2.953409194946289
Validation loss: 2.227835370648292

Epoch: 6| Step: 5
Training loss: 1.9228503704071045
Validation loss: 2.220695593023813

Epoch: 6| Step: 6
Training loss: 2.3206000328063965
Validation loss: 2.217972383704237

Epoch: 6| Step: 7
Training loss: 2.736785650253296
Validation loss: 2.2243688183446086

Epoch: 6| Step: 8
Training loss: 3.2492644786834717
Validation loss: 2.2136298187317385

Epoch: 6| Step: 9
Training loss: 2.801595687866211
Validation loss: 2.221302327289376

Epoch: 6| Step: 10
Training loss: 1.8863801956176758
Validation loss: 2.2197121061304563

Epoch: 6| Step: 11
Training loss: 2.9500732421875
Validation loss: 2.2379832447216077

Epoch: 6| Step: 12
Training loss: 2.388096809387207
Validation loss: 2.2437846352977138

Epoch: 6| Step: 13
Training loss: 3.3533942699432373
Validation loss: 2.277570519396054

Epoch: 85| Step: 0
Training loss: 2.6679916381835938
Validation loss: 2.272241271952147

Epoch: 6| Step: 1
Training loss: 2.5550920963287354
Validation loss: 2.2898537958821943

Epoch: 6| Step: 2
Training loss: 2.879593849182129
Validation loss: 2.2790149129847044

Epoch: 6| Step: 3
Training loss: 2.5816094875335693
Validation loss: 2.2619947541144585

Epoch: 6| Step: 4
Training loss: 2.2017745971679688
Validation loss: 2.2660448884451263

Epoch: 6| Step: 5
Training loss: 2.395744800567627
Validation loss: 2.278857046558011

Epoch: 6| Step: 6
Training loss: 2.5046257972717285
Validation loss: 2.286945435308641

Epoch: 6| Step: 7
Training loss: 2.9245622158050537
Validation loss: 2.285615013491723

Epoch: 6| Step: 8
Training loss: 1.8414931297302246
Validation loss: 2.2936584616220124

Epoch: 6| Step: 9
Training loss: 2.342507839202881
Validation loss: 2.305130381737986

Epoch: 6| Step: 10
Training loss: 2.267772674560547
Validation loss: 2.2812393198731127

Epoch: 6| Step: 11
Training loss: 2.4226126670837402
Validation loss: 2.2542865789064797

Epoch: 6| Step: 12
Training loss: 3.373349189758301
Validation loss: 2.239514281672816

Epoch: 6| Step: 13
Training loss: 1.928120493888855
Validation loss: 2.236969168468188

Epoch: 86| Step: 0
Training loss: 2.2779109477996826
Validation loss: 2.2340732671881236

Epoch: 6| Step: 1
Training loss: 2.591978073120117
Validation loss: 2.241826395834646

Epoch: 6| Step: 2
Training loss: 2.216959238052368
Validation loss: 2.231049899132021

Epoch: 6| Step: 3
Training loss: 3.0955915451049805
Validation loss: 2.231058386064345

Epoch: 6| Step: 4
Training loss: 2.994976758956909
Validation loss: 2.2341698010762534

Epoch: 6| Step: 5
Training loss: 2.120535135269165
Validation loss: 2.2303839037495274

Epoch: 6| Step: 6
Training loss: 2.5748820304870605
Validation loss: 2.2309654810095347

Epoch: 6| Step: 7
Training loss: 2.162130117416382
Validation loss: 2.231620047682075

Epoch: 6| Step: 8
Training loss: 2.4324374198913574
Validation loss: 2.234487638678602

Epoch: 6| Step: 9
Training loss: 2.155289649963379
Validation loss: 2.2275939987551783

Epoch: 6| Step: 10
Training loss: 3.006106376647949
Validation loss: 2.229129211876982

Epoch: 6| Step: 11
Training loss: 2.546617031097412
Validation loss: 2.2240260147279307

Epoch: 6| Step: 12
Training loss: 3.0535101890563965
Validation loss: 2.2155225328219834

Epoch: 6| Step: 13
Training loss: 2.2506117820739746
Validation loss: 2.2241205823036934

Epoch: 87| Step: 0
Training loss: 2.2647485733032227
Validation loss: 2.233095899704964

Epoch: 6| Step: 1
Training loss: 2.612778663635254
Validation loss: 2.242279944881316

Epoch: 6| Step: 2
Training loss: 2.2560524940490723
Validation loss: 2.280098758718019

Epoch: 6| Step: 3
Training loss: 2.607165813446045
Validation loss: 2.292337489384477

Epoch: 6| Step: 4
Training loss: 1.8452506065368652
Validation loss: 2.3056471065808366

Epoch: 6| Step: 5
Training loss: 2.4278621673583984
Validation loss: 2.2990205467388196

Epoch: 6| Step: 6
Training loss: 2.2209606170654297
Validation loss: 2.303387518851988

Epoch: 6| Step: 7
Training loss: 3.276428699493408
Validation loss: 2.3374328715826875

Epoch: 6| Step: 8
Training loss: 1.9922016859054565
Validation loss: 2.3273026276660222

Epoch: 6| Step: 9
Training loss: 2.0368685722351074
Validation loss: 2.3155141825317056

Epoch: 6| Step: 10
Training loss: 2.879138946533203
Validation loss: 2.3226777533049225

Epoch: 6| Step: 11
Training loss: 2.5613865852355957
Validation loss: 2.3243026682125625

Epoch: 6| Step: 12
Training loss: 3.2830491065979004
Validation loss: 2.30981602720035

Epoch: 6| Step: 13
Training loss: 3.242445230484009
Validation loss: 2.2964003470636185

Epoch: 88| Step: 0
Training loss: 1.9827206134796143
Validation loss: 2.263086542006462

Epoch: 6| Step: 1
Training loss: 2.2305474281311035
Validation loss: 2.2294039649348103

Epoch: 6| Step: 2
Training loss: 2.304553270339966
Validation loss: 2.2070573196616223

Epoch: 6| Step: 3
Training loss: 2.6465401649475098
Validation loss: 2.194771998672075

Epoch: 6| Step: 4
Training loss: 1.995794653892517
Validation loss: 2.196364455325629

Epoch: 6| Step: 5
Training loss: 2.181004285812378
Validation loss: 2.201593622084587

Epoch: 6| Step: 6
Training loss: 2.5766518115997314
Validation loss: 2.1953942724453506

Epoch: 6| Step: 7
Training loss: 2.3939647674560547
Validation loss: 2.201854384073647

Epoch: 6| Step: 8
Training loss: 2.8926970958709717
Validation loss: 2.204432100378057

Epoch: 6| Step: 9
Training loss: 3.0895161628723145
Validation loss: 2.201165347970942

Epoch: 6| Step: 10
Training loss: 2.6368088722229004
Validation loss: 2.2104414355370308

Epoch: 6| Step: 11
Training loss: 3.250676155090332
Validation loss: 2.201357605636761

Epoch: 6| Step: 12
Training loss: 2.387359619140625
Validation loss: 2.2070286222683486

Epoch: 6| Step: 13
Training loss: 2.752774238586426
Validation loss: 2.198056362008536

Epoch: 89| Step: 0
Training loss: 2.0015454292297363
Validation loss: 2.2116968247198288

Epoch: 6| Step: 1
Training loss: 2.0045676231384277
Validation loss: 2.2411805032401957

Epoch: 6| Step: 2
Training loss: 2.433016777038574
Validation loss: 2.27057861128161

Epoch: 6| Step: 3
Training loss: 2.602336883544922
Validation loss: 2.2995474569259153

Epoch: 6| Step: 4
Training loss: 3.213527202606201
Validation loss: 2.3329692297084357

Epoch: 6| Step: 5
Training loss: 2.561209201812744
Validation loss: 2.3614731552780315

Epoch: 6| Step: 6
Training loss: 2.8749728202819824
Validation loss: 2.371340406838284

Epoch: 6| Step: 7
Training loss: 2.410161018371582
Validation loss: 2.3780445873096423

Epoch: 6| Step: 8
Training loss: 2.4878785610198975
Validation loss: 2.354653343077629

Epoch: 6| Step: 9
Training loss: 2.6648454666137695
Validation loss: 2.334629005001437

Epoch: 6| Step: 10
Training loss: 2.221015453338623
Validation loss: 2.300870164748161

Epoch: 6| Step: 11
Training loss: 2.7776598930358887
Validation loss: 2.2743784125133226

Epoch: 6| Step: 12
Training loss: 2.437169313430786
Validation loss: 2.2786748716908116

Epoch: 6| Step: 13
Training loss: 3.0309855937957764
Validation loss: 2.279993995543449

Epoch: 90| Step: 0
Training loss: 3.2098071575164795
Validation loss: 2.282257339005829

Epoch: 6| Step: 1
Training loss: 2.4260990619659424
Validation loss: 2.312755592407719

Epoch: 6| Step: 2
Training loss: 2.390740156173706
Validation loss: 2.3272933139595935

Epoch: 6| Step: 3
Training loss: 2.3653817176818848
Validation loss: 2.3447542549461446

Epoch: 6| Step: 4
Training loss: 1.5424268245697021
Validation loss: 2.3793649750371135

Epoch: 6| Step: 5
Training loss: 2.627331256866455
Validation loss: 2.389820534695861

Epoch: 6| Step: 6
Training loss: 3.0618042945861816
Validation loss: 2.3847068253383843

Epoch: 6| Step: 7
Training loss: 3.1587300300598145
Validation loss: 2.38045847031378

Epoch: 6| Step: 8
Training loss: 2.2683324813842773
Validation loss: 2.35974407452409

Epoch: 6| Step: 9
Training loss: 2.0285024642944336
Validation loss: 2.355107674034693

Epoch: 6| Step: 10
Training loss: 2.7009212970733643
Validation loss: 2.3435264787366314

Epoch: 6| Step: 11
Training loss: 3.1054904460906982
Validation loss: 2.335305393383067

Epoch: 6| Step: 12
Training loss: 2.010577440261841
Validation loss: 2.3227471946388163

Epoch: 6| Step: 13
Training loss: 3.6552515029907227
Validation loss: 2.3370605207258657

Epoch: 91| Step: 0
Training loss: 3.278752326965332
Validation loss: 2.3559735513502553

Epoch: 6| Step: 1
Training loss: 2.1522343158721924
Validation loss: 2.349398346357448

Epoch: 6| Step: 2
Training loss: 3.2934622764587402
Validation loss: 2.3625565011014222

Epoch: 6| Step: 3
Training loss: 2.6316819190979004
Validation loss: 2.3551075304708173

Epoch: 6| Step: 4
Training loss: 2.358307123184204
Validation loss: 2.3372726594248125

Epoch: 6| Step: 5
Training loss: 2.7614970207214355
Validation loss: 2.3229491197934715

Epoch: 6| Step: 6
Training loss: 2.251072883605957
Validation loss: 2.3168946748138755

Epoch: 6| Step: 7
Training loss: 2.341320037841797
Validation loss: 2.3094228365088023

Epoch: 6| Step: 8
Training loss: 2.543663263320923
Validation loss: 2.3259565727685088

Epoch: 6| Step: 9
Training loss: 2.055630922317505
Validation loss: 2.3162807649181736

Epoch: 6| Step: 10
Training loss: 2.6934900283813477
Validation loss: 2.2853920664838565

Epoch: 6| Step: 11
Training loss: 1.7642967700958252
Validation loss: 2.2808388022966284

Epoch: 6| Step: 12
Training loss: 2.522697925567627
Validation loss: 2.2802729914265294

Epoch: 6| Step: 13
Training loss: 2.883448600769043
Validation loss: 2.248362410453058

Epoch: 92| Step: 0
Training loss: 2.5695488452911377
Validation loss: 2.2617470474653345

Epoch: 6| Step: 1
Training loss: 2.1357483863830566
Validation loss: 2.2441332442786104

Epoch: 6| Step: 2
Training loss: 2.1432430744171143
Validation loss: 2.2502031915931293

Epoch: 6| Step: 3
Training loss: 2.1249661445617676
Validation loss: 2.2321887195751233

Epoch: 6| Step: 4
Training loss: 2.4523134231567383
Validation loss: 2.234016405638828

Epoch: 6| Step: 5
Training loss: 2.1219210624694824
Validation loss: 2.2298762567581667

Epoch: 6| Step: 6
Training loss: 3.0351624488830566
Validation loss: 2.2244928370239916

Epoch: 6| Step: 7
Training loss: 2.436190128326416
Validation loss: 2.223006832984186

Epoch: 6| Step: 8
Training loss: 2.254396915435791
Validation loss: 2.2304688666456487

Epoch: 6| Step: 9
Training loss: 2.8029723167419434
Validation loss: 2.22815659610174

Epoch: 6| Step: 10
Training loss: 2.4563796520233154
Validation loss: 2.2326269713781213

Epoch: 6| Step: 11
Training loss: 2.8183817863464355
Validation loss: 2.234058105817405

Epoch: 6| Step: 12
Training loss: 2.803553581237793
Validation loss: 2.245744976946103

Epoch: 6| Step: 13
Training loss: 2.952824592590332
Validation loss: 2.2610435511476252

Epoch: 93| Step: 0
Training loss: 1.5237250328063965
Validation loss: 2.259486157407043

Epoch: 6| Step: 1
Training loss: 2.737208366394043
Validation loss: 2.261459958168768

Epoch: 6| Step: 2
Training loss: 3.067734479904175
Validation loss: 2.2828527471070648

Epoch: 6| Step: 3
Training loss: 2.38457989692688
Validation loss: 2.3139936488161803

Epoch: 6| Step: 4
Training loss: 2.2202253341674805
Validation loss: 2.327555133450416

Epoch: 6| Step: 5
Training loss: 2.9672772884368896
Validation loss: 2.3271754633995796

Epoch: 6| Step: 6
Training loss: 2.3527584075927734
Validation loss: 2.3127846846016507

Epoch: 6| Step: 7
Training loss: 1.9226789474487305
Validation loss: 2.285363058890066

Epoch: 6| Step: 8
Training loss: 2.3491687774658203
Validation loss: 2.2573228574568227

Epoch: 6| Step: 9
Training loss: 2.4229540824890137
Validation loss: 2.2522609413311048

Epoch: 6| Step: 10
Training loss: 2.6245338916778564
Validation loss: 2.2267149648358746

Epoch: 6| Step: 11
Training loss: 3.2402591705322266
Validation loss: 2.214827904137232

Epoch: 6| Step: 12
Training loss: 2.5049519538879395
Validation loss: 2.2200501298391693

Epoch: 6| Step: 13
Training loss: 2.6815900802612305
Validation loss: 2.212458631043793

Epoch: 94| Step: 0
Training loss: 2.371912956237793
Validation loss: 2.2114131886471986

Epoch: 6| Step: 1
Training loss: 3.480776786804199
Validation loss: 2.2155642406914824

Epoch: 6| Step: 2
Training loss: 3.0149590969085693
Validation loss: 2.2168650370772167

Epoch: 6| Step: 3
Training loss: 3.308621883392334
Validation loss: 2.2260747571145334

Epoch: 6| Step: 4
Training loss: 2.109375
Validation loss: 2.224329562597377

Epoch: 6| Step: 5
Training loss: 2.280632972717285
Validation loss: 2.221206541984312

Epoch: 6| Step: 6
Training loss: 2.360412359237671
Validation loss: 2.2185240355871056

Epoch: 6| Step: 7
Training loss: 2.5697226524353027
Validation loss: 2.2158456720331663

Epoch: 6| Step: 8
Training loss: 2.0901284217834473
Validation loss: 2.220519140202512

Epoch: 6| Step: 9
Training loss: 1.7377392053604126
Validation loss: 2.20580723977858

Epoch: 6| Step: 10
Training loss: 2.942281723022461
Validation loss: 2.194078499271024

Epoch: 6| Step: 11
Training loss: 2.224088191986084
Validation loss: 2.206789355124197

Epoch: 6| Step: 12
Training loss: 2.0230791568756104
Validation loss: 2.204824116922194

Epoch: 6| Step: 13
Training loss: 2.415431022644043
Validation loss: 2.2119001034767396

Epoch: 95| Step: 0
Training loss: 2.25325870513916
Validation loss: 2.2043244018349597

Epoch: 6| Step: 1
Training loss: 1.7857232093811035
Validation loss: 2.212182711529475

Epoch: 6| Step: 2
Training loss: 2.1773085594177246
Validation loss: 2.198951067463044

Epoch: 6| Step: 3
Training loss: 2.1488399505615234
Validation loss: 2.194334304460915

Epoch: 6| Step: 4
Training loss: 2.99477481842041
Validation loss: 2.189695281367148

Epoch: 6| Step: 5
Training loss: 2.408407688140869
Validation loss: 2.187300894850044

Epoch: 6| Step: 6
Training loss: 2.719747304916382
Validation loss: 2.1924203723989506

Epoch: 6| Step: 7
Training loss: 2.7884998321533203
Validation loss: 2.182239269697538

Epoch: 6| Step: 8
Training loss: 2.635737419128418
Validation loss: 2.1895725034898326

Epoch: 6| Step: 9
Training loss: 2.734072208404541
Validation loss: 2.1921787543963362

Epoch: 6| Step: 10
Training loss: 2.600654363632202
Validation loss: 2.1949136103353193

Epoch: 6| Step: 11
Training loss: 2.1950442790985107
Validation loss: 2.200709871066514

Epoch: 6| Step: 12
Training loss: 2.8295786380767822
Validation loss: 2.1961570170617875

Epoch: 6| Step: 13
Training loss: 2.447237968444824
Validation loss: 2.2100162454830703

Epoch: 96| Step: 0
Training loss: 2.450596809387207
Validation loss: 2.2228536887835433

Epoch: 6| Step: 1
Training loss: 2.7053611278533936
Validation loss: 2.2509354904133785

Epoch: 6| Step: 2
Training loss: 2.532457113265991
Validation loss: 2.2599523067474365

Epoch: 6| Step: 3
Training loss: 2.765117645263672
Validation loss: 2.270081150916315

Epoch: 6| Step: 4
Training loss: 2.7147274017333984
Validation loss: 2.274643482700471

Epoch: 6| Step: 5
Training loss: 2.075979709625244
Validation loss: 2.290606496154621

Epoch: 6| Step: 6
Training loss: 2.914360523223877
Validation loss: 2.3010276927742908

Epoch: 6| Step: 7
Training loss: 2.0039899349212646
Validation loss: 2.2787348583180416

Epoch: 6| Step: 8
Training loss: 2.580077886581421
Validation loss: 2.2833321517513645

Epoch: 6| Step: 9
Training loss: 2.509847640991211
Validation loss: 2.2951416738571657

Epoch: 6| Step: 10
Training loss: 1.8526520729064941
Validation loss: 2.2642983518620974

Epoch: 6| Step: 11
Training loss: 2.31193208694458
Validation loss: 2.2425012383409726

Epoch: 6| Step: 12
Training loss: 3.10666561126709
Validation loss: 2.2144415558025403

Epoch: 6| Step: 13
Training loss: 2.153918743133545
Validation loss: 2.2057743918511177

Epoch: 97| Step: 0
Training loss: 2.0376205444335938
Validation loss: 2.2037105150120233

Epoch: 6| Step: 1
Training loss: 1.8719403743743896
Validation loss: 2.1981220270997737

Epoch: 6| Step: 2
Training loss: 2.916736602783203
Validation loss: 2.1891871216476604

Epoch: 6| Step: 3
Training loss: 3.068610906600952
Validation loss: 2.1914792035215642

Epoch: 6| Step: 4
Training loss: 2.345827102661133
Validation loss: 2.193745743843817

Epoch: 6| Step: 5
Training loss: 2.159454345703125
Validation loss: 2.1822707371045182

Epoch: 6| Step: 6
Training loss: 3.078758716583252
Validation loss: 2.194548027489775

Epoch: 6| Step: 7
Training loss: 1.8503470420837402
Validation loss: 2.20019115683853

Epoch: 6| Step: 8
Training loss: 2.42879581451416
Validation loss: 2.197070167910668

Epoch: 6| Step: 9
Training loss: 2.6857962608337402
Validation loss: 2.1919709046681723

Epoch: 6| Step: 10
Training loss: 2.5701699256896973
Validation loss: 2.1867927889670096

Epoch: 6| Step: 11
Training loss: 2.8308751583099365
Validation loss: 2.183396057416034

Epoch: 6| Step: 12
Training loss: 2.4826533794403076
Validation loss: 2.196278584900723

Epoch: 6| Step: 13
Training loss: 2.135584831237793
Validation loss: 2.1963368487614456

Epoch: 98| Step: 0
Training loss: 1.5775034427642822
Validation loss: 2.2022465672544254

Epoch: 6| Step: 1
Training loss: 2.4839563369750977
Validation loss: 2.2062435188601093

Epoch: 6| Step: 2
Training loss: 3.0120673179626465
Validation loss: 2.212761422639252

Epoch: 6| Step: 3
Training loss: 2.9471774101257324
Validation loss: 2.2292829431513304

Epoch: 6| Step: 4
Training loss: 2.225433349609375
Validation loss: 2.2496391983442408

Epoch: 6| Step: 5
Training loss: 3.0292153358459473
Validation loss: 2.2546603884748233

Epoch: 6| Step: 6
Training loss: 1.965376615524292
Validation loss: 2.2340216252111618

Epoch: 6| Step: 7
Training loss: 2.801054000854492
Validation loss: 2.239814217372607

Epoch: 6| Step: 8
Training loss: 2.692748785018921
Validation loss: 2.2258981735475603

Epoch: 6| Step: 9
Training loss: 3.1240100860595703
Validation loss: 2.2004773437335925

Epoch: 6| Step: 10
Training loss: 2.454495429992676
Validation loss: 2.1903078402242353

Epoch: 6| Step: 11
Training loss: 2.0270605087280273
Validation loss: 2.1827918355182936

Epoch: 6| Step: 12
Training loss: 2.0221567153930664
Validation loss: 2.184625674319524

Epoch: 6| Step: 13
Training loss: 2.073530673980713
Validation loss: 2.1873307651089084

Epoch: 99| Step: 0
Training loss: 2.5352795124053955
Validation loss: 2.1907071733987458

Epoch: 6| Step: 1
Training loss: 2.201585292816162
Validation loss: 2.184395210717314

Epoch: 6| Step: 2
Training loss: 1.8958969116210938
Validation loss: 2.185782032628213

Epoch: 6| Step: 3
Training loss: 1.9273587465286255
Validation loss: 2.182363226849546

Epoch: 6| Step: 4
Training loss: 2.7642133235931396
Validation loss: 2.1900355072431665

Epoch: 6| Step: 5
Training loss: 2.561124324798584
Validation loss: 2.205055045825179

Epoch: 6| Step: 6
Training loss: 2.5699634552001953
Validation loss: 2.1982609354039675

Epoch: 6| Step: 7
Training loss: 2.651095390319824
Validation loss: 2.21619023430732

Epoch: 6| Step: 8
Training loss: 2.599560499191284
Validation loss: 2.2071169063609135

Epoch: 6| Step: 9
Training loss: 2.9482154846191406
Validation loss: 2.2160572467311734

Epoch: 6| Step: 10
Training loss: 2.2249159812927246
Validation loss: 2.20560707071776

Epoch: 6| Step: 11
Training loss: 2.201303005218506
Validation loss: 2.1960464536502795

Epoch: 6| Step: 12
Training loss: 2.9492347240448
Validation loss: 2.182976548389722

Epoch: 6| Step: 13
Training loss: 2.669933557510376
Validation loss: 2.1901537320947133

Epoch: 100| Step: 0
Training loss: 2.0691475868225098
Validation loss: 2.1770610270961637

Epoch: 6| Step: 1
Training loss: 2.038578987121582
Validation loss: 2.1856965608494257

Epoch: 6| Step: 2
Training loss: 3.215583324432373
Validation loss: 2.1790295723945863

Epoch: 6| Step: 3
Training loss: 2.660409688949585
Validation loss: 2.1896902284314557

Epoch: 6| Step: 4
Training loss: 2.886622905731201
Validation loss: 2.2060273898545133

Epoch: 6| Step: 5
Training loss: 2.3798108100891113
Validation loss: 2.2099142177130586

Epoch: 6| Step: 6
Training loss: 2.585829257965088
Validation loss: 2.2110761032309583

Epoch: 6| Step: 7
Training loss: 1.8799078464508057
Validation loss: 2.233585067974624

Epoch: 6| Step: 8
Training loss: 2.22316312789917
Validation loss: 2.267383801039829

Epoch: 6| Step: 9
Training loss: 2.2853214740753174
Validation loss: 2.2855744618241505

Epoch: 6| Step: 10
Training loss: 1.7894864082336426
Validation loss: 2.27361794440977

Epoch: 6| Step: 11
Training loss: 3.0008201599121094
Validation loss: 2.2453137161911174

Epoch: 6| Step: 12
Training loss: 2.676631450653076
Validation loss: 2.205192037807998

Epoch: 6| Step: 13
Training loss: 3.7699906826019287
Validation loss: 2.178922237888459

Epoch: 101| Step: 0
Training loss: 2.781853675842285
Validation loss: 2.1711711011907107

Epoch: 6| Step: 1
Training loss: 3.0557241439819336
Validation loss: 2.1671017959553707

Epoch: 6| Step: 2
Training loss: 2.452237606048584
Validation loss: 2.1618396518050984

Epoch: 6| Step: 3
Training loss: 2.2645511627197266
Validation loss: 2.184782963927074

Epoch: 6| Step: 4
Training loss: 3.0909552574157715
Validation loss: 2.200262341448056

Epoch: 6| Step: 5
Training loss: 3.210402011871338
Validation loss: 2.217141133482738

Epoch: 6| Step: 6
Training loss: 2.5591988563537598
Validation loss: 2.2247757809136504

Epoch: 6| Step: 7
Training loss: 2.358159065246582
Validation loss: 2.216551976819192

Epoch: 6| Step: 8
Training loss: 1.8637034893035889
Validation loss: 2.221266231229228

Epoch: 6| Step: 9
Training loss: 2.2376773357391357
Validation loss: 2.2106790696420977

Epoch: 6| Step: 10
Training loss: 1.7615456581115723
Validation loss: 2.191409851915093

Epoch: 6| Step: 11
Training loss: 2.008636474609375
Validation loss: 2.1913943803438576

Epoch: 6| Step: 12
Training loss: 2.522305488586426
Validation loss: 2.205355139188869

Epoch: 6| Step: 13
Training loss: 2.8766016960144043
Validation loss: 2.223748896711616

Epoch: 102| Step: 0
Training loss: 2.5436511039733887
Validation loss: 2.2288848841062157

Epoch: 6| Step: 1
Training loss: 2.8738417625427246
Validation loss: 2.2321393079655145

Epoch: 6| Step: 2
Training loss: 3.092369556427002
Validation loss: 2.246212749071019

Epoch: 6| Step: 3
Training loss: 2.384005546569824
Validation loss: 2.250087199672576

Epoch: 6| Step: 4
Training loss: 2.456902503967285
Validation loss: 2.2509350789490568

Epoch: 6| Step: 5
Training loss: 2.7795116901397705
Validation loss: 2.2428013919502177

Epoch: 6| Step: 6
Training loss: 1.8670076131820679
Validation loss: 2.2419558673776607

Epoch: 6| Step: 7
Training loss: 2.112393856048584
Validation loss: 2.2201149104743876

Epoch: 6| Step: 8
Training loss: 2.337137222290039
Validation loss: 2.2256349081634195

Epoch: 6| Step: 9
Training loss: 2.4417481422424316
Validation loss: 2.2096578254494617

Epoch: 6| Step: 10
Training loss: 2.2653846740722656
Validation loss: 2.1971018391270793

Epoch: 6| Step: 11
Training loss: 2.5341544151306152
Validation loss: 2.196146793262933

Epoch: 6| Step: 12
Training loss: 2.1466708183288574
Validation loss: 2.197242947034938

Epoch: 6| Step: 13
Training loss: 2.5701310634613037
Validation loss: 2.184306857406452

Epoch: 103| Step: 0
Training loss: 2.529463052749634
Validation loss: 2.1880704190141413

Epoch: 6| Step: 1
Training loss: 2.4198946952819824
Validation loss: 2.189241152937694

Epoch: 6| Step: 2
Training loss: 2.481132984161377
Validation loss: 2.195000917680802

Epoch: 6| Step: 3
Training loss: 2.4414188861846924
Validation loss: 2.183003822962443

Epoch: 6| Step: 4
Training loss: 2.4047865867614746
Validation loss: 2.17725811466094

Epoch: 6| Step: 5
Training loss: 1.8135472536087036
Validation loss: 2.1839747198166384

Epoch: 6| Step: 6
Training loss: 2.0510880947113037
Validation loss: 2.1780614109449488

Epoch: 6| Step: 7
Training loss: 2.762845277786255
Validation loss: 2.1866180768577

Epoch: 6| Step: 8
Training loss: 2.390122890472412
Validation loss: 2.1971114732885875

Epoch: 6| Step: 9
Training loss: 3.3374171257019043
Validation loss: 2.2172048399525304

Epoch: 6| Step: 10
Training loss: 2.4620437622070312
Validation loss: 2.2162469766473256

Epoch: 6| Step: 11
Training loss: 2.4490346908569336
Validation loss: 2.2153743800296577

Epoch: 6| Step: 12
Training loss: 2.062000036239624
Validation loss: 2.2296442895807247

Epoch: 6| Step: 13
Training loss: 2.852471351623535
Validation loss: 2.2276342684222805

Epoch: 104| Step: 0
Training loss: 2.1584043502807617
Validation loss: 2.2448100864246325

Epoch: 6| Step: 1
Training loss: 2.874452590942383
Validation loss: 2.2646014754490187

Epoch: 6| Step: 2
Training loss: 2.6416783332824707
Validation loss: 2.2828695722805556

Epoch: 6| Step: 3
Training loss: 3.094337224960327
Validation loss: 2.281332485137447

Epoch: 6| Step: 4
Training loss: 2.9978983402252197
Validation loss: 2.2735000015586935

Epoch: 6| Step: 5
Training loss: 2.929633378982544
Validation loss: 2.2525796762076755

Epoch: 6| Step: 6
Training loss: 1.7551701068878174
Validation loss: 2.229538490695338

Epoch: 6| Step: 7
Training loss: 1.9529447555541992
Validation loss: 2.2275423080690446

Epoch: 6| Step: 8
Training loss: 2.0998027324676514
Validation loss: 2.219958330995293

Epoch: 6| Step: 9
Training loss: 2.1485300064086914
Validation loss: 2.200214808987033

Epoch: 6| Step: 10
Training loss: 2.653385877609253
Validation loss: 2.206578769991475

Epoch: 6| Step: 11
Training loss: 2.8134419918060303
Validation loss: 2.1999646207337737

Epoch: 6| Step: 12
Training loss: 1.9741058349609375
Validation loss: 2.1893158971622424

Epoch: 6| Step: 13
Training loss: 2.4397003650665283
Validation loss: 2.1903466857889646

Epoch: 105| Step: 0
Training loss: 2.1405367851257324
Validation loss: 2.203064985172723

Epoch: 6| Step: 1
Training loss: 2.511368751525879
Validation loss: 2.2096743276042323

Epoch: 6| Step: 2
Training loss: 3.060555934906006
Validation loss: 2.2357638856416107

Epoch: 6| Step: 3
Training loss: 2.7378838062286377
Validation loss: 2.2334209988194127

Epoch: 6| Step: 4
Training loss: 2.376964569091797
Validation loss: 2.2537817262834117

Epoch: 6| Step: 5
Training loss: 2.1140377521514893
Validation loss: 2.2559401014799714

Epoch: 6| Step: 6
Training loss: 1.991409420967102
Validation loss: 2.2601861492280038

Epoch: 6| Step: 7
Training loss: 3.2641429901123047
Validation loss: 2.249483939140074

Epoch: 6| Step: 8
Training loss: 2.206848621368408
Validation loss: 2.2418643146432857

Epoch: 6| Step: 9
Training loss: 2.4760751724243164
Validation loss: 2.206796456408757

Epoch: 6| Step: 10
Training loss: 2.9085917472839355
Validation loss: 2.1817066772009737

Epoch: 6| Step: 11
Training loss: 2.2544784545898438
Validation loss: 2.1776090616820962

Epoch: 6| Step: 12
Training loss: 1.9264472723007202
Validation loss: 2.173746351272829

Epoch: 6| Step: 13
Training loss: 2.254220485687256
Validation loss: 2.180716772233286

Epoch: 106| Step: 0
Training loss: 2.3851449489593506
Validation loss: 2.1764442766866376

Epoch: 6| Step: 1
Training loss: 2.126899480819702
Validation loss: 2.1746690939831477

Epoch: 6| Step: 2
Training loss: 3.0769877433776855
Validation loss: 2.180541715314311

Epoch: 6| Step: 3
Training loss: 2.694457530975342
Validation loss: 2.177097425665907

Epoch: 6| Step: 4
Training loss: 2.432347536087036
Validation loss: 2.1847227516994683

Epoch: 6| Step: 5
Training loss: 2.327759265899658
Validation loss: 2.1858416167638635

Epoch: 6| Step: 6
Training loss: 2.960336923599243
Validation loss: 2.182727434301889

Epoch: 6| Step: 7
Training loss: 1.6038932800292969
Validation loss: 2.1890570604672996

Epoch: 6| Step: 8
Training loss: 2.027033567428589
Validation loss: 2.185033449562647

Epoch: 6| Step: 9
Training loss: 2.7650489807128906
Validation loss: 2.1961091564547632

Epoch: 6| Step: 10
Training loss: 2.0883052349090576
Validation loss: 2.1970038696001937

Epoch: 6| Step: 11
Training loss: 2.771636724472046
Validation loss: 2.1989949595543647

Epoch: 6| Step: 12
Training loss: 2.1193690299987793
Validation loss: 2.1930771963570708

Epoch: 6| Step: 13
Training loss: 2.9686107635498047
Validation loss: 2.196781648102627

Epoch: 107| Step: 0
Training loss: 2.6178274154663086
Validation loss: 2.190877999028852

Epoch: 6| Step: 1
Training loss: 3.1907896995544434
Validation loss: 2.191396403056319

Epoch: 6| Step: 2
Training loss: 2.1812081336975098
Validation loss: 2.1989843512094147

Epoch: 6| Step: 3
Training loss: 2.2078495025634766
Validation loss: 2.194744848435925

Epoch: 6| Step: 4
Training loss: 2.7180051803588867
Validation loss: 2.192752174151841

Epoch: 6| Step: 5
Training loss: 2.175960063934326
Validation loss: 2.1878977667900825

Epoch: 6| Step: 6
Training loss: 2.393517017364502
Validation loss: 2.180658108444624

Epoch: 6| Step: 7
Training loss: 2.4233882427215576
Validation loss: 2.1748744582617157

Epoch: 6| Step: 8
Training loss: 2.528686285018921
Validation loss: 2.1632197031410794

Epoch: 6| Step: 9
Training loss: 1.9468683004379272
Validation loss: 2.1747114991628997

Epoch: 6| Step: 10
Training loss: 2.391488552093506
Validation loss: 2.1740600806410595

Epoch: 6| Step: 11
Training loss: 3.3201916217803955
Validation loss: 2.189572108689175

Epoch: 6| Step: 12
Training loss: 1.3875758647918701
Validation loss: 2.19459673922549

Epoch: 6| Step: 13
Training loss: 2.848965883255005
Validation loss: 2.2020294948290755

Epoch: 108| Step: 0
Training loss: 2.588991641998291
Validation loss: 2.203660483001381

Epoch: 6| Step: 1
Training loss: 2.503195285797119
Validation loss: 2.206970648099017

Epoch: 6| Step: 2
Training loss: 2.2791478633880615
Validation loss: 2.2069564288662327

Epoch: 6| Step: 3
Training loss: 2.325927257537842
Validation loss: 2.225776732608836

Epoch: 6| Step: 4
Training loss: 2.7681503295898438
Validation loss: 2.219937427069551

Epoch: 6| Step: 5
Training loss: 2.7673001289367676
Validation loss: 2.2067079313339724

Epoch: 6| Step: 6
Training loss: 2.5894651412963867
Validation loss: 2.209491429790374

Epoch: 6| Step: 7
Training loss: 2.788076400756836
Validation loss: 2.1998417813290834

Epoch: 6| Step: 8
Training loss: 2.227306604385376
Validation loss: 2.17969911841936

Epoch: 6| Step: 9
Training loss: 1.4787864685058594
Validation loss: 2.162017865847516

Epoch: 6| Step: 10
Training loss: 2.771834373474121
Validation loss: 2.159677513184086

Epoch: 6| Step: 11
Training loss: 2.5206236839294434
Validation loss: 2.168134581658148

Epoch: 6| Step: 12
Training loss: 2.3760061264038086
Validation loss: 2.1570810887121383

Epoch: 6| Step: 13
Training loss: 1.6540040969848633
Validation loss: 2.1579881560417915

Epoch: 109| Step: 0
Training loss: 2.306580066680908
Validation loss: 2.194003628146264

Epoch: 6| Step: 1
Training loss: 2.7043070793151855
Validation loss: 2.271594293655888

Epoch: 6| Step: 2
Training loss: 3.52657151222229
Validation loss: 2.3500801132571314

Epoch: 6| Step: 3
Training loss: 2.508610963821411
Validation loss: 2.3604948802660872

Epoch: 6| Step: 4
Training loss: 1.7945232391357422
Validation loss: 2.4046751376121276

Epoch: 6| Step: 5
Training loss: 2.0306735038757324
Validation loss: 2.388946440912062

Epoch: 6| Step: 6
Training loss: 2.5654478073120117
Validation loss: 2.3560006644136164

Epoch: 6| Step: 7
Training loss: 2.529794216156006
Validation loss: 2.318842395659416

Epoch: 6| Step: 8
Training loss: 2.280686855316162
Validation loss: 2.2629815019587034

Epoch: 6| Step: 9
Training loss: 2.4325485229492188
Validation loss: 2.2172600018080844

Epoch: 6| Step: 10
Training loss: 2.635134696960449
Validation loss: 2.1907388817879463

Epoch: 6| Step: 11
Training loss: 2.2737255096435547
Validation loss: 2.174117249827231

Epoch: 6| Step: 12
Training loss: 2.71781325340271
Validation loss: 2.1611743973147486

Epoch: 6| Step: 13
Training loss: 2.282735586166382
Validation loss: 2.166886919288225

Epoch: 110| Step: 0
Training loss: 2.6476833820343018
Validation loss: 2.167721507369831

Epoch: 6| Step: 1
Training loss: 2.501394748687744
Validation loss: 2.157298139346543

Epoch: 6| Step: 2
Training loss: 1.7190005779266357
Validation loss: 2.1583167891348563

Epoch: 6| Step: 3
Training loss: 2.723069906234741
Validation loss: 2.159262034200853

Epoch: 6| Step: 4
Training loss: 2.733531951904297
Validation loss: 2.1587012519118605

Epoch: 6| Step: 5
Training loss: 3.290109157562256
Validation loss: 2.153797572658908

Epoch: 6| Step: 6
Training loss: 2.2288661003112793
Validation loss: 2.1385958912552043

Epoch: 6| Step: 7
Training loss: 2.1977124214172363
Validation loss: 2.136136048583574

Epoch: 6| Step: 8
Training loss: 2.3437790870666504
Validation loss: 2.1417193515326387

Epoch: 6| Step: 9
Training loss: 2.68196177482605
Validation loss: 2.1369735143517934

Epoch: 6| Step: 10
Training loss: 1.7092331647872925
Validation loss: 2.149410888712893

Epoch: 6| Step: 11
Training loss: 2.9825785160064697
Validation loss: 2.137109571887601

Epoch: 6| Step: 12
Training loss: 1.8212774991989136
Validation loss: 2.1491324568307526

Epoch: 6| Step: 13
Training loss: 3.0572707653045654
Validation loss: 2.177490444593532

Epoch: 111| Step: 0
Training loss: 2.2548398971557617
Validation loss: 2.185486940927403

Epoch: 6| Step: 1
Training loss: 2.503633975982666
Validation loss: 2.195828507023473

Epoch: 6| Step: 2
Training loss: 3.0212759971618652
Validation loss: 2.189686882880426

Epoch: 6| Step: 3
Training loss: 2.491025447845459
Validation loss: 2.199040497502973

Epoch: 6| Step: 4
Training loss: 2.616368532180786
Validation loss: 2.2005931151810514

Epoch: 6| Step: 5
Training loss: 2.5891480445861816
Validation loss: 2.197841477650468

Epoch: 6| Step: 6
Training loss: 1.704930067062378
Validation loss: 2.1967394941596576

Epoch: 6| Step: 7
Training loss: 2.905914783477783
Validation loss: 2.2023747736407864

Epoch: 6| Step: 8
Training loss: 2.2720837593078613
Validation loss: 2.1868796784390687

Epoch: 6| Step: 9
Training loss: 2.124049663543701
Validation loss: 2.2133162483092277

Epoch: 6| Step: 10
Training loss: 2.604253053665161
Validation loss: 2.2016055327589794

Epoch: 6| Step: 11
Training loss: 1.9304208755493164
Validation loss: 2.191037893295288

Epoch: 6| Step: 12
Training loss: 2.0755536556243896
Validation loss: 2.1847732272199405

Epoch: 6| Step: 13
Training loss: 2.860875129699707
Validation loss: 2.184097913003737

Epoch: 112| Step: 0
Training loss: 2.7625226974487305
Validation loss: 2.169768225762152

Epoch: 6| Step: 1
Training loss: 2.549299478530884
Validation loss: 2.1948708539368003

Epoch: 6| Step: 2
Training loss: 1.4605131149291992
Validation loss: 2.1988783844055666

Epoch: 6| Step: 3
Training loss: 2.9853904247283936
Validation loss: 2.208878952969787

Epoch: 6| Step: 4
Training loss: 2.4742965698242188
Validation loss: 2.2314952394013763

Epoch: 6| Step: 5
Training loss: 2.5742039680480957
Validation loss: 2.24397752874641

Epoch: 6| Step: 6
Training loss: 2.598605155944824
Validation loss: 2.2377483716575046

Epoch: 6| Step: 7
Training loss: 2.2842793464660645
Validation loss: 2.226077307936966

Epoch: 6| Step: 8
Training loss: 2.509270668029785
Validation loss: 2.1955664029685398

Epoch: 6| Step: 9
Training loss: 1.909747838973999
Validation loss: 2.1977971933221303

Epoch: 6| Step: 10
Training loss: 2.953723669052124
Validation loss: 2.184025764465332

Epoch: 6| Step: 11
Training loss: 2.6412034034729004
Validation loss: 2.1793531346064743

Epoch: 6| Step: 12
Training loss: 1.919642448425293
Validation loss: 2.1880353445647867

Epoch: 6| Step: 13
Training loss: 2.6289148330688477
Validation loss: 2.180726807604554

Epoch: 113| Step: 0
Training loss: 2.278660535812378
Validation loss: 2.1874975376231696

Epoch: 6| Step: 1
Training loss: 2.5407185554504395
Validation loss: 2.1841793034666326

Epoch: 6| Step: 2
Training loss: 2.216818332672119
Validation loss: 2.2106301528151318

Epoch: 6| Step: 3
Training loss: 2.1039419174194336
Validation loss: 2.232843291374945

Epoch: 6| Step: 4
Training loss: 2.7135210037231445
Validation loss: 2.258545552530596

Epoch: 6| Step: 5
Training loss: 1.78753662109375
Validation loss: 2.2520712601241244

Epoch: 6| Step: 6
Training loss: 2.9832701683044434
Validation loss: 2.242476796591154

Epoch: 6| Step: 7
Training loss: 2.4563896656036377
Validation loss: 2.245632610013408

Epoch: 6| Step: 8
Training loss: 3.1911377906799316
Validation loss: 2.2227229302929294

Epoch: 6| Step: 9
Training loss: 2.461493968963623
Validation loss: 2.1971526504844747

Epoch: 6| Step: 10
Training loss: 2.663717269897461
Validation loss: 2.1759450102365143

Epoch: 6| Step: 11
Training loss: 1.858856439590454
Validation loss: 2.1856829786813385

Epoch: 6| Step: 12
Training loss: 2.5980782508850098
Validation loss: 2.1992681205913587

Epoch: 6| Step: 13
Training loss: 1.9148709774017334
Validation loss: 2.185420504180334

Epoch: 114| Step: 0
Training loss: 2.321789026260376
Validation loss: 2.19899554662807

Epoch: 6| Step: 1
Training loss: 2.070831775665283
Validation loss: 2.177888826657367

Epoch: 6| Step: 2
Training loss: 2.455775499343872
Validation loss: 2.1729536646155903

Epoch: 6| Step: 3
Training loss: 2.5056049823760986
Validation loss: 2.1539708055475706

Epoch: 6| Step: 4
Training loss: 1.9484833478927612
Validation loss: 2.1447067183832966

Epoch: 6| Step: 5
Training loss: 2.494445323944092
Validation loss: 2.1418670864515406

Epoch: 6| Step: 6
Training loss: 2.6621766090393066
Validation loss: 2.1391902123728106

Epoch: 6| Step: 7
Training loss: 2.5587351322174072
Validation loss: 2.135199434013777

Epoch: 6| Step: 8
Training loss: 1.856176495552063
Validation loss: 2.1311645251448437

Epoch: 6| Step: 9
Training loss: 2.696047782897949
Validation loss: 2.1346686065837903

Epoch: 6| Step: 10
Training loss: 2.8254446983337402
Validation loss: 2.1503737613719

Epoch: 6| Step: 11
Training loss: 2.89847469329834
Validation loss: 2.154642388384829

Epoch: 6| Step: 12
Training loss: 2.0187182426452637
Validation loss: 2.1690000205911617

Epoch: 6| Step: 13
Training loss: 2.409961223602295
Validation loss: 2.183397916055495

Epoch: 115| Step: 0
Training loss: 2.2167465686798096
Validation loss: 2.1872600816911265

Epoch: 6| Step: 1
Training loss: 2.6561293601989746
Validation loss: 2.2011469307766167

Epoch: 6| Step: 2
Training loss: 2.2650232315063477
Validation loss: 2.197809402660657

Epoch: 6| Step: 3
Training loss: 2.0438523292541504
Validation loss: 2.1744447677366194

Epoch: 6| Step: 4
Training loss: 2.3849940299987793
Validation loss: 2.178178451394522

Epoch: 6| Step: 5
Training loss: 2.2982730865478516
Validation loss: 2.1712378763383433

Epoch: 6| Step: 6
Training loss: 2.1999807357788086
Validation loss: 2.167567555622388

Epoch: 6| Step: 7
Training loss: 2.117523670196533
Validation loss: 2.173484766355125

Epoch: 6| Step: 8
Training loss: 2.7014620304107666
Validation loss: 2.163762036190238

Epoch: 6| Step: 9
Training loss: 2.2105960845947266
Validation loss: 2.1607467436021373

Epoch: 6| Step: 10
Training loss: 2.0730271339416504
Validation loss: 2.1486511102286716

Epoch: 6| Step: 11
Training loss: 3.182368755340576
Validation loss: 2.137186368306478

Epoch: 6| Step: 12
Training loss: 2.3834080696105957
Validation loss: 2.1336394997053247

Epoch: 6| Step: 13
Training loss: 3.670071601867676
Validation loss: 2.1324436331308014

Epoch: 116| Step: 0
Training loss: 1.6753355264663696
Validation loss: 2.117357205319148

Epoch: 6| Step: 1
Training loss: 2.4684653282165527
Validation loss: 2.1282564593899633

Epoch: 6| Step: 2
Training loss: 1.6929163932800293
Validation loss: 2.127969644402945

Epoch: 6| Step: 3
Training loss: 2.5281033515930176
Validation loss: 2.131637150241483

Epoch: 6| Step: 4
Training loss: 3.0915303230285645
Validation loss: 2.129231733660544

Epoch: 6| Step: 5
Training loss: 2.357452869415283
Validation loss: 2.1371309193231727

Epoch: 6| Step: 6
Training loss: 2.0122954845428467
Validation loss: 2.1345931458216842

Epoch: 6| Step: 7
Training loss: 1.6669137477874756
Validation loss: 2.1312127318433536

Epoch: 6| Step: 8
Training loss: 2.9630584716796875
Validation loss: 2.131974154903043

Epoch: 6| Step: 9
Training loss: 2.17744779586792
Validation loss: 2.1438842819583033

Epoch: 6| Step: 10
Training loss: 2.520538330078125
Validation loss: 2.166323547722191

Epoch: 6| Step: 11
Training loss: 3.167057991027832
Validation loss: 2.200274472595543

Epoch: 6| Step: 12
Training loss: 2.5309228897094727
Validation loss: 2.2176559996861283

Epoch: 6| Step: 13
Training loss: 2.882126569747925
Validation loss: 2.2350331737149145

Epoch: 117| Step: 0
Training loss: 1.8707022666931152
Validation loss: 2.2241280412161224

Epoch: 6| Step: 1
Training loss: 2.4344370365142822
Validation loss: 2.200077441430861

Epoch: 6| Step: 2
Training loss: 3.028071641921997
Validation loss: 2.1768443443441905

Epoch: 6| Step: 3
Training loss: 2.038634777069092
Validation loss: 2.147990372873122

Epoch: 6| Step: 4
Training loss: 3.0119004249572754
Validation loss: 2.1462983879991757

Epoch: 6| Step: 5
Training loss: 2.1089563369750977
Validation loss: 2.1321865179205455

Epoch: 6| Step: 6
Training loss: 1.658540964126587
Validation loss: 2.1539122096953855

Epoch: 6| Step: 7
Training loss: 3.2273664474487305
Validation loss: 2.1531258052395237

Epoch: 6| Step: 8
Training loss: 3.0717897415161133
Validation loss: 2.154251116578297

Epoch: 6| Step: 9
Training loss: 2.1731197834014893
Validation loss: 2.1568691038316294

Epoch: 6| Step: 10
Training loss: 2.290630340576172
Validation loss: 2.1374206799332813

Epoch: 6| Step: 11
Training loss: 1.982201337814331
Validation loss: 2.142023132693383

Epoch: 6| Step: 12
Training loss: 2.3550760746002197
Validation loss: 2.1222287813822427

Epoch: 6| Step: 13
Training loss: 2.2833762168884277
Validation loss: 2.136659670901555

Epoch: 118| Step: 0
Training loss: 2.4826107025146484
Validation loss: 2.1354887613686184

Epoch: 6| Step: 1
Training loss: 1.6858667135238647
Validation loss: 2.1371581451867216

Epoch: 6| Step: 2
Training loss: 2.313342571258545
Validation loss: 2.155753666354764

Epoch: 6| Step: 3
Training loss: 2.5998663902282715
Validation loss: 2.1522777529173

Epoch: 6| Step: 4
Training loss: 2.6512534618377686
Validation loss: 2.1466163589108374

Epoch: 6| Step: 5
Training loss: 3.064340353012085
Validation loss: 2.128139789386462

Epoch: 6| Step: 6
Training loss: 2.2916736602783203
Validation loss: 2.136702593936715

Epoch: 6| Step: 7
Training loss: 1.9915039539337158
Validation loss: 2.1434636936392835

Epoch: 6| Step: 8
Training loss: 2.4139790534973145
Validation loss: 2.124309103976014

Epoch: 6| Step: 9
Training loss: 1.9965205192565918
Validation loss: 2.121546265899494

Epoch: 6| Step: 10
Training loss: 2.876338005065918
Validation loss: 2.124774447051428

Epoch: 6| Step: 11
Training loss: 2.5724081993103027
Validation loss: 2.126822656200778

Epoch: 6| Step: 12
Training loss: 2.4133763313293457
Validation loss: 2.1335820690278084

Epoch: 6| Step: 13
Training loss: 2.0542821884155273
Validation loss: 2.1633812971012567

Epoch: 119| Step: 0
Training loss: 2.3970675468444824
Validation loss: 2.1725313253300165

Epoch: 6| Step: 1
Training loss: 2.994314670562744
Validation loss: 2.183449319613877

Epoch: 6| Step: 2
Training loss: 1.9416685104370117
Validation loss: 2.18856950729124

Epoch: 6| Step: 3
Training loss: 1.434401273727417
Validation loss: 2.1905171076456704

Epoch: 6| Step: 4
Training loss: 2.049569606781006
Validation loss: 2.2025178581155758

Epoch: 6| Step: 5
Training loss: 3.1199421882629395
Validation loss: 2.2009179169131863

Epoch: 6| Step: 6
Training loss: 1.931178331375122
Validation loss: 2.190209411805676

Epoch: 6| Step: 7
Training loss: 2.681974172592163
Validation loss: 2.2198792452453286

Epoch: 6| Step: 8
Training loss: 3.114565372467041
Validation loss: 2.2098627577545824

Epoch: 6| Step: 9
Training loss: 2.1591928005218506
Validation loss: 2.1968378559235604

Epoch: 6| Step: 10
Training loss: 2.6108901500701904
Validation loss: 2.1745438063016502

Epoch: 6| Step: 11
Training loss: 2.347548246383667
Validation loss: 2.145515498294625

Epoch: 6| Step: 12
Training loss: 2.768827438354492
Validation loss: 2.128553339230117

Epoch: 6| Step: 13
Training loss: 1.8387491703033447
Validation loss: 2.126842237287952

Epoch: 120| Step: 0
Training loss: 3.1225204467773438
Validation loss: 2.1166742668356946

Epoch: 6| Step: 1
Training loss: 2.194467067718506
Validation loss: 2.111785956608352

Epoch: 6| Step: 2
Training loss: 2.0607428550720215
Validation loss: 2.111309605260049

Epoch: 6| Step: 3
Training loss: 2.9797191619873047
Validation loss: 2.105561843482397

Epoch: 6| Step: 4
Training loss: 2.7558140754699707
Validation loss: 2.115736510163994

Epoch: 6| Step: 5
Training loss: 2.1553311347961426
Validation loss: 2.1216191066208707

Epoch: 6| Step: 6
Training loss: 2.9347121715545654
Validation loss: 2.133179267247518

Epoch: 6| Step: 7
Training loss: 2.1164729595184326
Validation loss: 2.1375509667140182

Epoch: 6| Step: 8
Training loss: 2.5983059406280518
Validation loss: 2.1496829960935857

Epoch: 6| Step: 9
Training loss: 2.601123094558716
Validation loss: 2.1618920026286954

Epoch: 6| Step: 10
Training loss: 2.34598970413208
Validation loss: 2.167529612459162

Epoch: 6| Step: 11
Training loss: 1.7705345153808594
Validation loss: 2.1945723102938746

Epoch: 6| Step: 12
Training loss: 1.7895750999450684
Validation loss: 2.1924553045662503

Epoch: 6| Step: 13
Training loss: 2.377025604248047
Validation loss: 2.2094991053304365

Epoch: 121| Step: 0
Training loss: 2.133545160293579
Validation loss: 2.22623965560749

Epoch: 6| Step: 1
Training loss: 2.831613063812256
Validation loss: 2.2424296768762733

Epoch: 6| Step: 2
Training loss: 2.116027355194092
Validation loss: 2.250201929000116

Epoch: 6| Step: 3
Training loss: 2.800492763519287
Validation loss: 2.275469467204104

Epoch: 6| Step: 4
Training loss: 2.7551021575927734
Validation loss: 2.28777979522623

Epoch: 6| Step: 5
Training loss: 2.4324142932891846
Validation loss: 2.2961694707152662

Epoch: 6| Step: 6
Training loss: 2.1722254753112793
Validation loss: 2.3086814931643906

Epoch: 6| Step: 7
Training loss: 1.9414342641830444
Validation loss: 2.3477813402811685

Epoch: 6| Step: 8
Training loss: 3.354245185852051
Validation loss: 2.386536257241362

Epoch: 6| Step: 9
Training loss: 1.883122444152832
Validation loss: 2.3975573842243483

Epoch: 6| Step: 10
Training loss: 2.3698220252990723
Validation loss: 2.4138317851610083

Epoch: 6| Step: 11
Training loss: 3.0582633018493652
Validation loss: 2.4108528039788686

Epoch: 6| Step: 12
Training loss: 2.0636985301971436
Validation loss: 2.3660377571659703

Epoch: 6| Step: 13
Training loss: 2.9756736755371094
Validation loss: 2.3259657890565935

Epoch: 122| Step: 0
Training loss: 2.3536460399627686
Validation loss: 2.2882226538914505

Epoch: 6| Step: 1
Training loss: 2.3329522609710693
Validation loss: 2.256852647309662

Epoch: 6| Step: 2
Training loss: 2.2461142539978027
Validation loss: 2.2545391051999983

Epoch: 6| Step: 3
Training loss: 1.2689194679260254
Validation loss: 2.252334121734865

Epoch: 6| Step: 4
Training loss: 2.1820197105407715
Validation loss: 2.2454414444585002

Epoch: 6| Step: 5
Training loss: 2.464247703552246
Validation loss: 2.2401988339680496

Epoch: 6| Step: 6
Training loss: 2.619105339050293
Validation loss: 2.236195771924911

Epoch: 6| Step: 7
Training loss: 3.048701286315918
Validation loss: 2.231554792773339

Epoch: 6| Step: 8
Training loss: 3.330988883972168
Validation loss: 2.2179200059624127

Epoch: 6| Step: 9
Training loss: 2.8558878898620605
Validation loss: 2.1992713405239965

Epoch: 6| Step: 10
Training loss: 1.9617550373077393
Validation loss: 2.1736960834072483

Epoch: 6| Step: 11
Training loss: 2.382457733154297
Validation loss: 2.1524202823638916

Epoch: 6| Step: 12
Training loss: 2.2889795303344727
Validation loss: 2.1486162421523884

Epoch: 6| Step: 13
Training loss: 1.8452167510986328
Validation loss: 2.123068691581808

Epoch: 123| Step: 0
Training loss: 2.260439395904541
Validation loss: 2.124590701954339

Epoch: 6| Step: 1
Training loss: 2.6689014434814453
Validation loss: 2.125519426920081

Epoch: 6| Step: 2
Training loss: 2.607537031173706
Validation loss: 2.128276753169234

Epoch: 6| Step: 3
Training loss: 2.607297897338867
Validation loss: 2.124723188338741

Epoch: 6| Step: 4
Training loss: 3.335939407348633
Validation loss: 2.130986587975615

Epoch: 6| Step: 5
Training loss: 2.726015567779541
Validation loss: 2.138387494189765

Epoch: 6| Step: 6
Training loss: 1.8908014297485352
Validation loss: 2.1436195565808203

Epoch: 6| Step: 7
Training loss: 2.487116813659668
Validation loss: 2.1456852395047425

Epoch: 6| Step: 8
Training loss: 2.3716349601745605
Validation loss: 2.1610421621671287

Epoch: 6| Step: 9
Training loss: 2.010775089263916
Validation loss: 2.183494706307688

Epoch: 6| Step: 10
Training loss: 2.053861618041992
Validation loss: 2.208208137942899

Epoch: 6| Step: 11
Training loss: 2.24416446685791
Validation loss: 2.2217220337160173

Epoch: 6| Step: 12
Training loss: 1.9785842895507812
Validation loss: 2.206755345867526

Epoch: 6| Step: 13
Training loss: 1.9506585597991943
Validation loss: 2.204963417463405

Epoch: 124| Step: 0
Training loss: 2.2100746631622314
Validation loss: 2.1722934412699875

Epoch: 6| Step: 1
Training loss: 1.5969691276550293
Validation loss: 2.141170068453717

Epoch: 6| Step: 2
Training loss: 1.799938440322876
Validation loss: 2.125137595720189

Epoch: 6| Step: 3
Training loss: 2.155398368835449
Validation loss: 2.130330862537507

Epoch: 6| Step: 4
Training loss: 2.909029960632324
Validation loss: 2.1315313167469476

Epoch: 6| Step: 5
Training loss: 3.033717632293701
Validation loss: 2.1385078507085002

Epoch: 6| Step: 6
Training loss: 3.104804754257202
Validation loss: 2.161304571295297

Epoch: 6| Step: 7
Training loss: 2.4401185512542725
Validation loss: 2.156459302030584

Epoch: 6| Step: 8
Training loss: 2.137265205383301
Validation loss: 2.1711562013113372

Epoch: 6| Step: 9
Training loss: 3.1199989318847656
Validation loss: 2.1487973402905207

Epoch: 6| Step: 10
Training loss: 2.3270699977874756
Validation loss: 2.143592514017577

Epoch: 6| Step: 11
Training loss: 2.5023293495178223
Validation loss: 2.126732031504313

Epoch: 6| Step: 12
Training loss: 1.7383668422698975
Validation loss: 2.128611292890323

Epoch: 6| Step: 13
Training loss: 2.3100337982177734
Validation loss: 2.115245093581497

Epoch: 125| Step: 0
Training loss: 3.2311742305755615
Validation loss: 2.1349004366064586

Epoch: 6| Step: 1
Training loss: 2.1809000968933105
Validation loss: 2.153139591217041

Epoch: 6| Step: 2
Training loss: 1.9362478256225586
Validation loss: 2.1583812826423237

Epoch: 6| Step: 3
Training loss: 2.2205209732055664
Validation loss: 2.1866126880850842

Epoch: 6| Step: 4
Training loss: 2.3388900756835938
Validation loss: 2.1731020224991666

Epoch: 6| Step: 5
Training loss: 2.4449453353881836
Validation loss: 2.1522092973032305

Epoch: 6| Step: 6
Training loss: 2.320526123046875
Validation loss: 2.1434809392498386

Epoch: 6| Step: 7
Training loss: 2.2133307456970215
Validation loss: 2.1291657750324537

Epoch: 6| Step: 8
Training loss: 2.1512842178344727
Validation loss: 2.128904240105742

Epoch: 6| Step: 9
Training loss: 2.259523630142212
Validation loss: 2.1312569290079098

Epoch: 6| Step: 10
Training loss: 2.252009391784668
Validation loss: 2.1329918343533754

Epoch: 6| Step: 11
Training loss: 2.761847972869873
Validation loss: 2.139163649210366

Epoch: 6| Step: 12
Training loss: 2.2972609996795654
Validation loss: 2.1763701464540217

Epoch: 6| Step: 13
Training loss: 2.332031726837158
Validation loss: 2.1765129309828564

Epoch: 126| Step: 0
Training loss: 2.218379497528076
Validation loss: 2.166253851306054

Epoch: 6| Step: 1
Training loss: 2.216815233230591
Validation loss: 2.161780752161498

Epoch: 6| Step: 2
Training loss: 1.9116804599761963
Validation loss: 2.173841286731023

Epoch: 6| Step: 3
Training loss: 2.908438205718994
Validation loss: 2.1661034527645318

Epoch: 6| Step: 4
Training loss: 2.3675994873046875
Validation loss: 2.1594752034833355

Epoch: 6| Step: 5
Training loss: 2.1769590377807617
Validation loss: 2.1585642714654245

Epoch: 6| Step: 6
Training loss: 2.37461519241333
Validation loss: 2.1704791527922436

Epoch: 6| Step: 7
Training loss: 2.4842686653137207
Validation loss: 2.1741632184674664

Epoch: 6| Step: 8
Training loss: 2.209017038345337
Validation loss: 2.1731710126323085

Epoch: 6| Step: 9
Training loss: 1.9750643968582153
Validation loss: 2.1936735478780602

Epoch: 6| Step: 10
Training loss: 2.108729839324951
Validation loss: 2.188119944705758

Epoch: 6| Step: 11
Training loss: 2.849177360534668
Validation loss: 2.1945922592634797

Epoch: 6| Step: 12
Training loss: 2.3375325202941895
Validation loss: 2.184769399704472

Epoch: 6| Step: 13
Training loss: 3.005984306335449
Validation loss: 2.1747550913082656

Epoch: 127| Step: 0
Training loss: 2.5384879112243652
Validation loss: 2.164215208381735

Epoch: 6| Step: 1
Training loss: 2.6594796180725098
Validation loss: 2.1556575157309092

Epoch: 6| Step: 2
Training loss: 2.4273972511291504
Validation loss: 2.1602357766961537

Epoch: 6| Step: 3
Training loss: 2.7044317722320557
Validation loss: 2.143196690467096

Epoch: 6| Step: 4
Training loss: 2.5811450481414795
Validation loss: 2.125058497152021

Epoch: 6| Step: 5
Training loss: 3.1518394947052
Validation loss: 2.111953217496154

Epoch: 6| Step: 6
Training loss: 1.999855399131775
Validation loss: 2.0941912871535107

Epoch: 6| Step: 7
Training loss: 2.64909029006958
Validation loss: 2.0952494528985794

Epoch: 6| Step: 8
Training loss: 1.7844213247299194
Validation loss: 2.0962331692377725

Epoch: 6| Step: 9
Training loss: 2.336533546447754
Validation loss: 2.0911684805347073

Epoch: 6| Step: 10
Training loss: 2.2010717391967773
Validation loss: 2.0928337599641536

Epoch: 6| Step: 11
Training loss: 1.7274482250213623
Validation loss: 2.1076391102165304

Epoch: 6| Step: 12
Training loss: 2.264341115951538
Validation loss: 2.10006897423857

Epoch: 6| Step: 13
Training loss: 2.210888385772705
Validation loss: 2.0978151649557133

Epoch: 128| Step: 0
Training loss: 2.2017226219177246
Validation loss: 2.1066090035182174

Epoch: 6| Step: 1
Training loss: 2.2760403156280518
Validation loss: 2.1022485609977477

Epoch: 6| Step: 2
Training loss: 2.3740198612213135
Validation loss: 2.106581434126823

Epoch: 6| Step: 3
Training loss: 1.8050000667572021
Validation loss: 2.1191085564192904

Epoch: 6| Step: 4
Training loss: 2.1720423698425293
Validation loss: 2.1274670618836597

Epoch: 6| Step: 5
Training loss: 2.2291555404663086
Validation loss: 2.1320417850248274

Epoch: 6| Step: 6
Training loss: 2.700765609741211
Validation loss: 2.151098948653026

Epoch: 6| Step: 7
Training loss: 1.8360040187835693
Validation loss: 2.174027878751037

Epoch: 6| Step: 8
Training loss: 2.470158100128174
Validation loss: 2.193769508792508

Epoch: 6| Step: 9
Training loss: 1.6170697212219238
Validation loss: 2.2186386226325907

Epoch: 6| Step: 10
Training loss: 3.4294042587280273
Validation loss: 2.2593406759282595

Epoch: 6| Step: 11
Training loss: 2.322225570678711
Validation loss: 2.2735415145915043

Epoch: 6| Step: 12
Training loss: 2.962838888168335
Validation loss: 2.296908314510058

Epoch: 6| Step: 13
Training loss: 2.1119813919067383
Validation loss: 2.2853834526513213

Epoch: 129| Step: 0
Training loss: 2.0043888092041016
Validation loss: 2.268666369940645

Epoch: 6| Step: 1
Training loss: 2.293321132659912
Validation loss: 2.2528858953906643

Epoch: 6| Step: 2
Training loss: 2.138399839401245
Validation loss: 2.1963713015279462

Epoch: 6| Step: 3
Training loss: 2.543565273284912
Validation loss: 2.147240888687872

Epoch: 6| Step: 4
Training loss: 1.9945354461669922
Validation loss: 2.125548178149808

Epoch: 6| Step: 5
Training loss: 3.4540271759033203
Validation loss: 2.1150022809223463

Epoch: 6| Step: 6
Training loss: 2.2052860260009766
Validation loss: 2.1071527529788274

Epoch: 6| Step: 7
Training loss: 2.813138008117676
Validation loss: 2.1031032992947485

Epoch: 6| Step: 8
Training loss: 2.267979383468628
Validation loss: 2.1164374146410214

Epoch: 6| Step: 9
Training loss: 2.6779110431671143
Validation loss: 2.1389164450348064

Epoch: 6| Step: 10
Training loss: 2.50199556350708
Validation loss: 2.1707632157110397

Epoch: 6| Step: 11
Training loss: 1.9028024673461914
Validation loss: 2.1724249880800963

Epoch: 6| Step: 12
Training loss: 2.474151134490967
Validation loss: 2.1428438078972603

Epoch: 6| Step: 13
Training loss: 1.7901558876037598
Validation loss: 2.1390040510444233

Epoch: 130| Step: 0
Training loss: 2.282168388366699
Validation loss: 2.131008812176284

Epoch: 6| Step: 1
Training loss: 1.8438844680786133
Validation loss: 2.1229486285999255

Epoch: 6| Step: 2
Training loss: 1.7203173637390137
Validation loss: 2.150023821861513

Epoch: 6| Step: 3
Training loss: 2.7509868144989014
Validation loss: 2.158838742522783

Epoch: 6| Step: 4
Training loss: 2.63529372215271
Validation loss: 2.1616328108695244

Epoch: 6| Step: 5
Training loss: 2.21155047416687
Validation loss: 2.1354057301757154

Epoch: 6| Step: 6
Training loss: 2.1172895431518555
Validation loss: 2.1336836891789592

Epoch: 6| Step: 7
Training loss: 3.2211732864379883
Validation loss: 2.1351869080656316

Epoch: 6| Step: 8
Training loss: 2.6701927185058594
Validation loss: 2.1345614874234764

Epoch: 6| Step: 9
Training loss: 2.505073308944702
Validation loss: 2.1465493402173443

Epoch: 6| Step: 10
Training loss: 2.7773184776306152
Validation loss: 2.155006008763467

Epoch: 6| Step: 11
Training loss: 1.7967592477798462
Validation loss: 2.166140471735308

Epoch: 6| Step: 12
Training loss: 2.380898952484131
Validation loss: 2.170238135963358

Epoch: 6| Step: 13
Training loss: 1.4517977237701416
Validation loss: 2.180008008915891

Epoch: 131| Step: 0
Training loss: 2.2486259937286377
Validation loss: 2.200574582622897

Epoch: 6| Step: 1
Training loss: 2.108731985092163
Validation loss: 2.216228723526001

Epoch: 6| Step: 2
Training loss: 2.960951328277588
Validation loss: 2.213580128967121

Epoch: 6| Step: 3
Training loss: 2.3693103790283203
Validation loss: 2.1960034447331584

Epoch: 6| Step: 4
Training loss: 2.7380270957946777
Validation loss: 2.1841429792424685

Epoch: 6| Step: 5
Training loss: 2.2316317558288574
Validation loss: 2.1630241742698093

Epoch: 6| Step: 6
Training loss: 2.034628391265869
Validation loss: 2.145235908928738

Epoch: 6| Step: 7
Training loss: 2.260554313659668
Validation loss: 2.1226365053525535

Epoch: 6| Step: 8
Training loss: 2.4230551719665527
Validation loss: 2.1154477057918424

Epoch: 6| Step: 9
Training loss: 1.5488340854644775
Validation loss: 2.121216559922823

Epoch: 6| Step: 10
Training loss: 2.1346092224121094
Validation loss: 2.1233397606880433

Epoch: 6| Step: 11
Training loss: 2.927523612976074
Validation loss: 2.123997944657521

Epoch: 6| Step: 12
Training loss: 2.009988307952881
Validation loss: 2.1243415032663653

Epoch: 6| Step: 13
Training loss: 3.0195486545562744
Validation loss: 2.1341281552468576

Epoch: 132| Step: 0
Training loss: 2.1283977031707764
Validation loss: 2.122744106477307

Epoch: 6| Step: 1
Training loss: 2.705136775970459
Validation loss: 2.1222375900514665

Epoch: 6| Step: 2
Training loss: 2.6128952503204346
Validation loss: 2.1250057425550235

Epoch: 6| Step: 3
Training loss: 2.3107731342315674
Validation loss: 2.113752559948993

Epoch: 6| Step: 4
Training loss: 2.0184688568115234
Validation loss: 2.1148062816230198

Epoch: 6| Step: 5
Training loss: 1.9742393493652344
Validation loss: 2.136026940038127

Epoch: 6| Step: 6
Training loss: 2.0222840309143066
Validation loss: 2.16053533041349

Epoch: 6| Step: 7
Training loss: 2.2204906940460205
Validation loss: 2.191898033183108

Epoch: 6| Step: 8
Training loss: 2.841154098510742
Validation loss: 2.216222070878552

Epoch: 6| Step: 9
Training loss: 2.2679171562194824
Validation loss: 2.2381353942296838

Epoch: 6| Step: 10
Training loss: 2.2827842235565186
Validation loss: 2.2463283602909376

Epoch: 6| Step: 11
Training loss: 2.2192115783691406
Validation loss: 2.2379927942829747

Epoch: 6| Step: 12
Training loss: 2.324249744415283
Validation loss: 2.2080015700350524

Epoch: 6| Step: 13
Training loss: 2.839357614517212
Validation loss: 2.1705498080099783

Epoch: 133| Step: 0
Training loss: 2.165515899658203
Validation loss: 2.136630114688668

Epoch: 6| Step: 1
Training loss: 2.218453884124756
Validation loss: 2.130307888471952

Epoch: 6| Step: 2
Training loss: 2.1581311225891113
Validation loss: 2.141570597566584

Epoch: 6| Step: 3
Training loss: 2.1029553413391113
Validation loss: 2.125526830714236

Epoch: 6| Step: 4
Training loss: 1.777156949043274
Validation loss: 2.132954566709457

Epoch: 6| Step: 5
Training loss: 2.6069235801696777
Validation loss: 2.123794044217756

Epoch: 6| Step: 6
Training loss: 2.1621286869049072
Validation loss: 2.1181177221318728

Epoch: 6| Step: 7
Training loss: 2.403829574584961
Validation loss: 2.1149434120424333

Epoch: 6| Step: 8
Training loss: 2.3186733722686768
Validation loss: 2.11563443112117

Epoch: 6| Step: 9
Training loss: 2.010213851928711
Validation loss: 2.10671293094594

Epoch: 6| Step: 10
Training loss: 3.0137722492218018
Validation loss: 2.1113573851123935

Epoch: 6| Step: 11
Training loss: 2.00449275970459
Validation loss: 2.113703691831199

Epoch: 6| Step: 12
Training loss: 2.720820188522339
Validation loss: 2.100703024095105

Epoch: 6| Step: 13
Training loss: 2.624681234359741
Validation loss: 2.108107010523478

Epoch: 134| Step: 0
Training loss: 2.395285129547119
Validation loss: 2.11376864423034

Epoch: 6| Step: 1
Training loss: 2.800367832183838
Validation loss: 2.1053310260977796

Epoch: 6| Step: 2
Training loss: 3.0438618659973145
Validation loss: 2.1339693659095356

Epoch: 6| Step: 3
Training loss: 2.249886989593506
Validation loss: 2.1237637150672173

Epoch: 6| Step: 4
Training loss: 2.574469804763794
Validation loss: 2.1251081189801617

Epoch: 6| Step: 5
Training loss: 2.8036386966705322
Validation loss: 2.134745510675574

Epoch: 6| Step: 6
Training loss: 1.9429500102996826
Validation loss: 2.10154249078484

Epoch: 6| Step: 7
Training loss: 2.1070077419281006
Validation loss: 2.083626659967566

Epoch: 6| Step: 8
Training loss: 2.0114221572875977
Validation loss: 2.099453244158017

Epoch: 6| Step: 9
Training loss: 1.4321398735046387
Validation loss: 2.138098427044448

Epoch: 6| Step: 10
Training loss: 2.444683074951172
Validation loss: 2.1534566853636052

Epoch: 6| Step: 11
Training loss: 2.316152572631836
Validation loss: 2.1917912216596704

Epoch: 6| Step: 12
Training loss: 2.4128003120422363
Validation loss: 2.1913865253489506

Epoch: 6| Step: 13
Training loss: 2.083646059036255
Validation loss: 2.2003424526542745

Epoch: 135| Step: 0
Training loss: 2.3853092193603516
Validation loss: 2.241260843892251

Epoch: 6| Step: 1
Training loss: 2.7125394344329834
Validation loss: 2.2866579947933072

Epoch: 6| Step: 2
Training loss: 2.69783878326416
Validation loss: 2.3252139604219826

Epoch: 6| Step: 3
Training loss: 2.4456496238708496
Validation loss: 2.308640972260506

Epoch: 6| Step: 4
Training loss: 2.12337064743042
Validation loss: 2.3034692502790883

Epoch: 6| Step: 5
Training loss: 2.566805839538574
Validation loss: 2.2860845724741616

Epoch: 6| Step: 6
Training loss: 2.9336342811584473
Validation loss: 2.2396005981711933

Epoch: 6| Step: 7
Training loss: 2.2799479961395264
Validation loss: 2.218181916462478

Epoch: 6| Step: 8
Training loss: 2.1063921451568604
Validation loss: 2.1994226991489367

Epoch: 6| Step: 9
Training loss: 2.6968445777893066
Validation loss: 2.1709419860634753

Epoch: 6| Step: 10
Training loss: 1.7190463542938232
Validation loss: 2.160107917683099

Epoch: 6| Step: 11
Training loss: 2.462160110473633
Validation loss: 2.1325957134205806

Epoch: 6| Step: 12
Training loss: 1.646242618560791
Validation loss: 2.1204831869371477

Epoch: 6| Step: 13
Training loss: 2.4028306007385254
Validation loss: 2.1162074201850483

Epoch: 136| Step: 0
Training loss: 2.2224483489990234
Validation loss: 2.1029911874442972

Epoch: 6| Step: 1
Training loss: 1.5533952713012695
Validation loss: 2.0969417095184326

Epoch: 6| Step: 2
Training loss: 2.175347089767456
Validation loss: 2.087904699387089

Epoch: 6| Step: 3
Training loss: 2.1466565132141113
Validation loss: 2.097246484089923

Epoch: 6| Step: 4
Training loss: 2.2221484184265137
Validation loss: 2.0924499906519407

Epoch: 6| Step: 5
Training loss: 2.556166172027588
Validation loss: 2.1044310305708196

Epoch: 6| Step: 6
Training loss: 2.434429407119751
Validation loss: 2.103327830632528

Epoch: 6| Step: 7
Training loss: 2.577544927597046
Validation loss: 2.1091775483982538

Epoch: 6| Step: 8
Training loss: 3.2566845417022705
Validation loss: 2.098801334698995

Epoch: 6| Step: 9
Training loss: 2.1644251346588135
Validation loss: 2.1111327986563406

Epoch: 6| Step: 10
Training loss: 2.141038179397583
Validation loss: 2.126732559614284

Epoch: 6| Step: 11
Training loss: 2.179966688156128
Validation loss: 2.137408406503739

Epoch: 6| Step: 12
Training loss: 2.240018367767334
Validation loss: 2.1657501907758814

Epoch: 6| Step: 13
Training loss: 2.698228120803833
Validation loss: 2.1927726140586277

Epoch: 137| Step: 0
Training loss: 2.0213849544525146
Validation loss: 2.200019357024982

Epoch: 6| Step: 1
Training loss: 2.4643735885620117
Validation loss: 2.2098258951658845

Epoch: 6| Step: 2
Training loss: 2.2244303226470947
Validation loss: 2.21372954563428

Epoch: 6| Step: 3
Training loss: 2.6874027252197266
Validation loss: 2.215176525936332

Epoch: 6| Step: 4
Training loss: 2.4296157360076904
Validation loss: 2.210083635904456

Epoch: 6| Step: 5
Training loss: 2.175811529159546
Validation loss: 2.1914015893013246

Epoch: 6| Step: 6
Training loss: 2.4954521656036377
Validation loss: 2.1578779425672305

Epoch: 6| Step: 7
Training loss: 2.5852346420288086
Validation loss: 2.1466285054401686

Epoch: 6| Step: 8
Training loss: 1.27287757396698
Validation loss: 2.125089427476288

Epoch: 6| Step: 9
Training loss: 1.524285078048706
Validation loss: 2.108336340996527

Epoch: 6| Step: 10
Training loss: 2.6371936798095703
Validation loss: 2.113023886116602

Epoch: 6| Step: 11
Training loss: 2.604830265045166
Validation loss: 2.121857612363754

Epoch: 6| Step: 12
Training loss: 2.40981388092041
Validation loss: 2.1169433991114297

Epoch: 6| Step: 13
Training loss: 2.8359620571136475
Validation loss: 2.1289368162872973

Epoch: 138| Step: 0
Training loss: 2.0886178016662598
Validation loss: 2.1187910161992556

Epoch: 6| Step: 1
Training loss: 2.3240089416503906
Validation loss: 2.1269602878119356

Epoch: 6| Step: 2
Training loss: 2.3379104137420654
Validation loss: 2.1232142525334514

Epoch: 6| Step: 3
Training loss: 3.0545785427093506
Validation loss: 2.1158388583890853

Epoch: 6| Step: 4
Training loss: 2.0606658458709717
Validation loss: 2.11805284407831

Epoch: 6| Step: 5
Training loss: 2.517275810241699
Validation loss: 2.1349977703504663

Epoch: 6| Step: 6
Training loss: 1.4265156984329224
Validation loss: 2.1271869969624344

Epoch: 6| Step: 7
Training loss: 3.102381467819214
Validation loss: 2.136482787388627

Epoch: 6| Step: 8
Training loss: 2.803464889526367
Validation loss: 2.1519096730857767

Epoch: 6| Step: 9
Training loss: 1.89998197555542
Validation loss: 2.147988857761506

Epoch: 6| Step: 10
Training loss: 1.9528043270111084
Validation loss: 2.147475199032855

Epoch: 6| Step: 11
Training loss: 1.7276779413223267
Validation loss: 2.12457529447412

Epoch: 6| Step: 12
Training loss: 2.1779069900512695
Validation loss: 2.1407787389652704

Epoch: 6| Step: 13
Training loss: 2.4496450424194336
Validation loss: 2.1423816168180077

Epoch: 139| Step: 0
Training loss: 1.8483253717422485
Validation loss: 2.1279096629029963

Epoch: 6| Step: 1
Training loss: 1.6461026668548584
Validation loss: 2.121047350668138

Epoch: 6| Step: 2
Training loss: 2.4900593757629395
Validation loss: 2.1409562582610757

Epoch: 6| Step: 3
Training loss: 2.537654161453247
Validation loss: 2.1600903798175115

Epoch: 6| Step: 4
Training loss: 2.475792407989502
Validation loss: 2.1725121544253443

Epoch: 6| Step: 5
Training loss: 2.905198574066162
Validation loss: 2.1900423854909916

Epoch: 6| Step: 6
Training loss: 2.614426612854004
Validation loss: 2.187427341297109

Epoch: 6| Step: 7
Training loss: 1.4261901378631592
Validation loss: 2.196864829268507

Epoch: 6| Step: 8
Training loss: 2.594120979309082
Validation loss: 2.196106174940704

Epoch: 6| Step: 9
Training loss: 1.6419062614440918
Validation loss: 2.1847219223617227

Epoch: 6| Step: 10
Training loss: 2.1478137969970703
Validation loss: 2.1773995827603083

Epoch: 6| Step: 11
Training loss: 2.3429408073425293
Validation loss: 2.1659277126353276

Epoch: 6| Step: 12
Training loss: 2.351283073425293
Validation loss: 2.1679710303583453

Epoch: 6| Step: 13
Training loss: 3.305844306945801
Validation loss: 2.168008235193068

Epoch: 140| Step: 0
Training loss: 1.9100421667099
Validation loss: 2.1621529415089595

Epoch: 6| Step: 1
Training loss: 2.993452548980713
Validation loss: 2.1687502194476385

Epoch: 6| Step: 2
Training loss: 2.5066585540771484
Validation loss: 2.1756629533665155

Epoch: 6| Step: 3
Training loss: 1.4389781951904297
Validation loss: 2.1391123956249607

Epoch: 6| Step: 4
Training loss: 1.949779748916626
Validation loss: 2.1385238273169405

Epoch: 6| Step: 5
Training loss: 1.9603630304336548
Validation loss: 2.1323887507120767

Epoch: 6| Step: 6
Training loss: 2.7077412605285645
Validation loss: 2.120549043019613

Epoch: 6| Step: 7
Training loss: 2.143322229385376
Validation loss: 2.132159476639122

Epoch: 6| Step: 8
Training loss: 2.5768814086914062
Validation loss: 2.1317934041382163

Epoch: 6| Step: 9
Training loss: 2.7552831172943115
Validation loss: 2.1420161749726985

Epoch: 6| Step: 10
Training loss: 1.5707587003707886
Validation loss: 2.1651198581982682

Epoch: 6| Step: 11
Training loss: 2.3212907314300537
Validation loss: 2.1507955969020887

Epoch: 6| Step: 12
Training loss: 2.23503041267395
Validation loss: 2.1470809854486936

Epoch: 6| Step: 13
Training loss: 2.609412908554077
Validation loss: 2.1439919766559394

Epoch: 141| Step: 0
Training loss: 1.8756742477416992
Validation loss: 2.138081741589372

Epoch: 6| Step: 1
Training loss: 1.8488348722457886
Validation loss: 2.1254005406492498

Epoch: 6| Step: 2
Training loss: 2.15114164352417
Validation loss: 2.1302293064773723

Epoch: 6| Step: 3
Training loss: 2.123047351837158
Validation loss: 2.139748857867333

Epoch: 6| Step: 4
Training loss: 2.213258981704712
Validation loss: 2.155810333067371

Epoch: 6| Step: 5
Training loss: 2.020559787750244
Validation loss: 2.1733277202934347

Epoch: 6| Step: 6
Training loss: 2.3421268463134766
Validation loss: 2.1548342602227324

Epoch: 6| Step: 7
Training loss: 2.726288318634033
Validation loss: 2.114516788913358

Epoch: 6| Step: 8
Training loss: 2.3616156578063965
Validation loss: 2.0947421571259857

Epoch: 6| Step: 9
Training loss: 2.2024903297424316
Validation loss: 2.107822620740501

Epoch: 6| Step: 10
Training loss: 1.951913595199585
Validation loss: 2.1073407921739804

Epoch: 6| Step: 11
Training loss: 2.895458698272705
Validation loss: 2.1111155889367543

Epoch: 6| Step: 12
Training loss: 2.498166799545288
Validation loss: 2.1181250925987

Epoch: 6| Step: 13
Training loss: 2.4017255306243896
Validation loss: 2.1283454869383123

Epoch: 142| Step: 0
Training loss: 2.3028106689453125
Validation loss: 2.1298572350573797

Epoch: 6| Step: 1
Training loss: 1.816972255706787
Validation loss: 2.158065529279811

Epoch: 6| Step: 2
Training loss: 2.8094940185546875
Validation loss: 2.1650130287293465

Epoch: 6| Step: 3
Training loss: 1.4264618158340454
Validation loss: 2.1841561948099444

Epoch: 6| Step: 4
Training loss: 2.86391019821167
Validation loss: 2.178653847786688

Epoch: 6| Step: 5
Training loss: 2.1865954399108887
Validation loss: 2.1605416920877274

Epoch: 6| Step: 6
Training loss: 1.671433687210083
Validation loss: 2.1278160233651437

Epoch: 6| Step: 7
Training loss: 2.635650634765625
Validation loss: 2.1173978902960338

Epoch: 6| Step: 8
Training loss: 2.1871142387390137
Validation loss: 2.1046648794604885

Epoch: 6| Step: 9
Training loss: 2.703638792037964
Validation loss: 2.1186542844259613

Epoch: 6| Step: 10
Training loss: 2.9020943641662598
Validation loss: 2.1224691355100243

Epoch: 6| Step: 11
Training loss: 1.8730769157409668
Validation loss: 2.121721218991023

Epoch: 6| Step: 12
Training loss: 2.341216564178467
Validation loss: 2.1217279075294413

Epoch: 6| Step: 13
Training loss: 1.5238454341888428
Validation loss: 2.123266420056743

Epoch: 143| Step: 0
Training loss: 3.2222466468811035
Validation loss: 2.1192880445911038

Epoch: 6| Step: 1
Training loss: 2.456066846847534
Validation loss: 2.134050682026853

Epoch: 6| Step: 2
Training loss: 2.3103880882263184
Validation loss: 2.1191675175902662

Epoch: 6| Step: 3
Training loss: 2.2471771240234375
Validation loss: 2.1356940064378964

Epoch: 6| Step: 4
Training loss: 3.360252857208252
Validation loss: 2.150137424468994

Epoch: 6| Step: 5
Training loss: 1.604243278503418
Validation loss: 2.1753093363136373

Epoch: 6| Step: 6
Training loss: 2.529834270477295
Validation loss: 2.175993906554355

Epoch: 6| Step: 7
Training loss: 2.283154010772705
Validation loss: 2.2068639186120804

Epoch: 6| Step: 8
Training loss: 2.195241689682007
Validation loss: 2.2118918408629713

Epoch: 6| Step: 9
Training loss: 2.05245304107666
Validation loss: 2.1752545423405145

Epoch: 6| Step: 10
Training loss: 1.5805027484893799
Validation loss: 2.1524122427868586

Epoch: 6| Step: 11
Training loss: 1.78360116481781
Validation loss: 2.1522352849283526

Epoch: 6| Step: 12
Training loss: 1.7216688394546509
Validation loss: 2.1337272915788876

Epoch: 6| Step: 13
Training loss: 1.695483684539795
Validation loss: 2.128879794510462

Epoch: 144| Step: 0
Training loss: 1.4159759283065796
Validation loss: 2.144270009891961

Epoch: 6| Step: 1
Training loss: 2.115980386734009
Validation loss: 2.160694481224142

Epoch: 6| Step: 2
Training loss: 2.341355085372925
Validation loss: 2.1786090417574813

Epoch: 6| Step: 3
Training loss: 2.5839462280273438
Validation loss: 2.190499464670817

Epoch: 6| Step: 4
Training loss: 2.01254940032959
Validation loss: 2.2218983481007237

Epoch: 6| Step: 5
Training loss: 2.0956268310546875
Validation loss: 2.2048004058099564

Epoch: 6| Step: 6
Training loss: 2.3600614070892334
Validation loss: 2.1918977152916694

Epoch: 6| Step: 7
Training loss: 2.0550894737243652
Validation loss: 2.1826946145744732

Epoch: 6| Step: 8
Training loss: 2.092905044555664
Validation loss: 2.190530966686946

Epoch: 6| Step: 9
Training loss: 2.0755538940429688
Validation loss: 2.183549468235303

Epoch: 6| Step: 10
Training loss: 2.0714635848999023
Validation loss: 2.2159632354654293

Epoch: 6| Step: 11
Training loss: 2.9283199310302734
Validation loss: 2.1860666441661056

Epoch: 6| Step: 12
Training loss: 3.0731678009033203
Validation loss: 2.1528277499701387

Epoch: 6| Step: 13
Training loss: 1.4724791049957275
Validation loss: 2.136455343615624

Epoch: 145| Step: 0
Training loss: 1.7576630115509033
Validation loss: 2.098813315873505

Epoch: 6| Step: 1
Training loss: 2.4198131561279297
Validation loss: 2.103883551013085

Epoch: 6| Step: 2
Training loss: 2.4846878051757812
Validation loss: 2.095109772938554

Epoch: 6| Step: 3
Training loss: 2.4480223655700684
Validation loss: 2.109390292116391

Epoch: 6| Step: 4
Training loss: 2.4844062328338623
Validation loss: 2.1198837500746532

Epoch: 6| Step: 5
Training loss: 2.152298927307129
Validation loss: 2.118845162853118

Epoch: 6| Step: 6
Training loss: 2.312591552734375
Validation loss: 2.128628489791706

Epoch: 6| Step: 7
Training loss: 2.361506462097168
Validation loss: 2.1556519872398785

Epoch: 6| Step: 8
Training loss: 2.122727870941162
Validation loss: 2.15250248934633

Epoch: 6| Step: 9
Training loss: 1.8825989961624146
Validation loss: 2.1557452512043778

Epoch: 6| Step: 10
Training loss: 1.8900800943374634
Validation loss: 2.1618498986767185

Epoch: 6| Step: 11
Training loss: 2.389953136444092
Validation loss: 2.159662970932581

Epoch: 6| Step: 12
Training loss: 2.4768319129943848
Validation loss: 2.134061941536524

Epoch: 6| Step: 13
Training loss: 2.0826656818389893
Validation loss: 2.1237891784278293

Epoch: 146| Step: 0
Training loss: 2.457639217376709
Validation loss: 2.1321281643324

Epoch: 6| Step: 1
Training loss: 2.514186382293701
Validation loss: 2.13103663024082

Epoch: 6| Step: 2
Training loss: 2.4770240783691406
Validation loss: 2.131227977814213

Epoch: 6| Step: 3
Training loss: 1.739050030708313
Validation loss: 2.1197595686040898

Epoch: 6| Step: 4
Training loss: 2.0203664302825928
Validation loss: 2.1162873724455475

Epoch: 6| Step: 5
Training loss: 2.840325117111206
Validation loss: 2.1258417432026198

Epoch: 6| Step: 6
Training loss: 1.9169707298278809
Validation loss: 2.1222547151709117

Epoch: 6| Step: 7
Training loss: 2.432298183441162
Validation loss: 2.1268224280367614

Epoch: 6| Step: 8
Training loss: 2.0228443145751953
Validation loss: 2.1371567480025755

Epoch: 6| Step: 9
Training loss: 2.239236831665039
Validation loss: 2.1421957528719338

Epoch: 6| Step: 10
Training loss: 1.8616764545440674
Validation loss: 2.162322446864138

Epoch: 6| Step: 11
Training loss: 2.249544620513916
Validation loss: 2.194140059973604

Epoch: 6| Step: 12
Training loss: 2.378997802734375
Validation loss: 2.1948440433830343

Epoch: 6| Step: 13
Training loss: 1.645821452140808
Validation loss: 2.195857371053388

Epoch: 147| Step: 0
Training loss: 1.8027739524841309
Validation loss: 2.18566257082006

Epoch: 6| Step: 1
Training loss: 2.0622310638427734
Validation loss: 2.187592896082068

Epoch: 6| Step: 2
Training loss: 1.1424157619476318
Validation loss: 2.1683658630617204

Epoch: 6| Step: 3
Training loss: 2.457822799682617
Validation loss: 2.1592843532562256

Epoch: 6| Step: 4
Training loss: 2.373112201690674
Validation loss: 2.1596776323933757

Epoch: 6| Step: 5
Training loss: 2.6403818130493164
Validation loss: 2.164083065525178

Epoch: 6| Step: 6
Training loss: 2.3114142417907715
Validation loss: 2.143510380098897

Epoch: 6| Step: 7
Training loss: 2.3125154972076416
Validation loss: 2.1466999284682737

Epoch: 6| Step: 8
Training loss: 2.2319679260253906
Validation loss: 2.163742901176535

Epoch: 6| Step: 9
Training loss: 2.5838634967803955
Validation loss: 2.1958214159934752

Epoch: 6| Step: 10
Training loss: 2.097195625305176
Validation loss: 2.1843164069678194

Epoch: 6| Step: 11
Training loss: 2.538391590118408
Validation loss: 2.1849077337531635

Epoch: 6| Step: 12
Training loss: 2.138855457305908
Validation loss: 2.182318930984825

Epoch: 6| Step: 13
Training loss: 2.4231410026550293
Validation loss: 2.145812472989482

Epoch: 148| Step: 0
Training loss: 2.444880247116089
Validation loss: 2.1662140136123984

Epoch: 6| Step: 1
Training loss: 1.712531328201294
Validation loss: 2.189822022632886

Epoch: 6| Step: 2
Training loss: 2.6062862873077393
Validation loss: 2.2055241805250927

Epoch: 6| Step: 3
Training loss: 2.074700355529785
Validation loss: 2.216968023648826

Epoch: 6| Step: 4
Training loss: 2.7227816581726074
Validation loss: 2.188833882731776

Epoch: 6| Step: 5
Training loss: 2.8863778114318848
Validation loss: 2.180160419915312

Epoch: 6| Step: 6
Training loss: 1.8845016956329346
Validation loss: 2.1531755334587506

Epoch: 6| Step: 7
Training loss: 1.4766141176223755
Validation loss: 2.1397538569665726

Epoch: 6| Step: 8
Training loss: 1.9231598377227783
Validation loss: 2.1189532574786933

Epoch: 6| Step: 9
Training loss: 2.2253055572509766
Validation loss: 2.0929286890132452

Epoch: 6| Step: 10
Training loss: 2.202014923095703
Validation loss: 2.07751799655217

Epoch: 6| Step: 11
Training loss: 2.2590792179107666
Validation loss: 2.0779602553254817

Epoch: 6| Step: 12
Training loss: 1.7796130180358887
Validation loss: 2.0916338325828634

Epoch: 6| Step: 13
Training loss: 3.4149458408355713
Validation loss: 2.091698641418129

Epoch: 149| Step: 0
Training loss: 2.1583757400512695
Validation loss: 2.1084413733533633

Epoch: 6| Step: 1
Training loss: 2.5806214809417725
Validation loss: 2.1019267407796716

Epoch: 6| Step: 2
Training loss: 1.364918828010559
Validation loss: 2.114425551506781

Epoch: 6| Step: 3
Training loss: 1.5683462619781494
Validation loss: 2.1351153132736043

Epoch: 6| Step: 4
Training loss: 2.620063304901123
Validation loss: 2.1769056063826366

Epoch: 6| Step: 5
Training loss: 2.0567502975463867
Validation loss: 2.1809342368956535

Epoch: 6| Step: 6
Training loss: 2.1196846961975098
Validation loss: 2.170572019392444

Epoch: 6| Step: 7
Training loss: 2.8383679389953613
Validation loss: 2.174524986615745

Epoch: 6| Step: 8
Training loss: 2.4639201164245605
Validation loss: 2.146980344608266

Epoch: 6| Step: 9
Training loss: 2.1384177207946777
Validation loss: 2.1239480280107066

Epoch: 6| Step: 10
Training loss: 2.3358914852142334
Validation loss: 2.0928631367221957

Epoch: 6| Step: 11
Training loss: 2.1613802909851074
Validation loss: 2.0775584533650386

Epoch: 6| Step: 12
Training loss: 2.0929927825927734
Validation loss: 2.074599407052481

Epoch: 6| Step: 13
Training loss: 2.217458963394165
Validation loss: 2.059175761797095

Epoch: 150| Step: 0
Training loss: 1.9050467014312744
Validation loss: 2.056716985599969

Epoch: 6| Step: 1
Training loss: 2.508495330810547
Validation loss: 2.0586698465449835

Epoch: 6| Step: 2
Training loss: 2.6477677822113037
Validation loss: 2.0604319059720604

Epoch: 6| Step: 3
Training loss: 1.9126906394958496
Validation loss: 2.066138554644841

Epoch: 6| Step: 4
Training loss: 2.35406231880188
Validation loss: 2.084238516387119

Epoch: 6| Step: 5
Training loss: 2.495512008666992
Validation loss: 2.0937754236241823

Epoch: 6| Step: 6
Training loss: 2.192708730697632
Validation loss: 2.096197127014078

Epoch: 6| Step: 7
Training loss: 2.033588409423828
Validation loss: 2.103453384932651

Epoch: 6| Step: 8
Training loss: 1.807234287261963
Validation loss: 2.0998994688833914

Epoch: 6| Step: 9
Training loss: 2.424001455307007
Validation loss: 2.103363901056269

Epoch: 6| Step: 10
Training loss: 1.95022451877594
Validation loss: 2.124095839838828

Epoch: 6| Step: 11
Training loss: 2.003483772277832
Validation loss: 2.154379706228933

Epoch: 6| Step: 12
Training loss: 1.8452163934707642
Validation loss: 2.166260475753456

Epoch: 6| Step: 13
Training loss: 3.1314468383789062
Validation loss: 2.1772384861464142

Epoch: 151| Step: 0
Training loss: 1.9640986919403076
Validation loss: 2.1470874663322204

Epoch: 6| Step: 1
Training loss: 2.312580108642578
Validation loss: 2.143264303925217

Epoch: 6| Step: 2
Training loss: 2.8116109371185303
Validation loss: 2.125399770275239

Epoch: 6| Step: 3
Training loss: 1.9108879566192627
Validation loss: 2.113410811270437

Epoch: 6| Step: 4
Training loss: 2.324800968170166
Validation loss: 2.1015091480747348

Epoch: 6| Step: 5
Training loss: 1.8431727886199951
Validation loss: 2.1206874975594143

Epoch: 6| Step: 6
Training loss: 2.252699851989746
Validation loss: 2.1366956285251084

Epoch: 6| Step: 7
Training loss: 2.7824878692626953
Validation loss: 2.1720633276047243

Epoch: 6| Step: 8
Training loss: 1.892704725265503
Validation loss: 2.1785898939255746

Epoch: 6| Step: 9
Training loss: 1.7059521675109863
Validation loss: 2.164137594161495

Epoch: 6| Step: 10
Training loss: 1.4384100437164307
Validation loss: 2.1581861472898916

Epoch: 6| Step: 11
Training loss: 2.0570576190948486
Validation loss: 2.1398566512651342

Epoch: 6| Step: 12
Training loss: 2.6650338172912598
Validation loss: 2.1302255840711695

Epoch: 6| Step: 13
Training loss: 2.6897644996643066
Validation loss: 2.134852763145201

Epoch: 152| Step: 0
Training loss: 2.471743583679199
Validation loss: 2.1305650434186383

Epoch: 6| Step: 1
Training loss: 2.2627553939819336
Validation loss: 2.1537336354614585

Epoch: 6| Step: 2
Training loss: 2.831981658935547
Validation loss: 2.1401769320170083

Epoch: 6| Step: 3
Training loss: 1.6310696601867676
Validation loss: 2.150548081244192

Epoch: 6| Step: 4
Training loss: 1.9002419710159302
Validation loss: 2.1467286950798443

Epoch: 6| Step: 5
Training loss: 1.8236782550811768
Validation loss: 2.141922402125533

Epoch: 6| Step: 6
Training loss: 1.9837322235107422
Validation loss: 2.1369550869029057

Epoch: 6| Step: 7
Training loss: 2.779010057449341
Validation loss: 2.1240455822278093

Epoch: 6| Step: 8
Training loss: 1.613232135772705
Validation loss: 2.1051358612634803

Epoch: 6| Step: 9
Training loss: 2.1228713989257812
Validation loss: 2.1121737854455107

Epoch: 6| Step: 10
Training loss: 2.7494664192199707
Validation loss: 2.1000842612276793

Epoch: 6| Step: 11
Training loss: 2.66109037399292
Validation loss: 2.1009865601857505

Epoch: 6| Step: 12
Training loss: 1.5727509260177612
Validation loss: 2.0860058312774985

Epoch: 6| Step: 13
Training loss: 1.6698880195617676
Validation loss: 2.0774980809098933

Epoch: 153| Step: 0
Training loss: 2.211348056793213
Validation loss: 2.1142616541154924

Epoch: 6| Step: 1
Training loss: 2.239765167236328
Validation loss: 2.0951959010093444

Epoch: 6| Step: 2
Training loss: 2.7519278526306152
Validation loss: 2.1073579711298787

Epoch: 6| Step: 3
Training loss: 2.080193281173706
Validation loss: 2.0984077440795077

Epoch: 6| Step: 4
Training loss: 1.9269683361053467
Validation loss: 2.1075124920055432

Epoch: 6| Step: 5
Training loss: 2.750302314758301
Validation loss: 2.1252260349130117

Epoch: 6| Step: 6
Training loss: 1.6662307977676392
Validation loss: 2.127044523915937

Epoch: 6| Step: 7
Training loss: 2.0323405265808105
Validation loss: 2.1337351132464666

Epoch: 6| Step: 8
Training loss: 2.281658172607422
Validation loss: 2.1664385231592322

Epoch: 6| Step: 9
Training loss: 1.9524712562561035
Validation loss: 2.1918247412609797

Epoch: 6| Step: 10
Training loss: 2.609583854675293
Validation loss: 2.2187949688203874

Epoch: 6| Step: 11
Training loss: 2.8698935508728027
Validation loss: 2.198670752586857

Epoch: 6| Step: 12
Training loss: 1.242544174194336
Validation loss: 2.1887489236811155

Epoch: 6| Step: 13
Training loss: 1.5290250778198242
Validation loss: 2.1966282142105924

Epoch: 154| Step: 0
Training loss: 2.4009132385253906
Validation loss: 2.1650430745975946

Epoch: 6| Step: 1
Training loss: 1.7654348611831665
Validation loss: 2.1532202818060435

Epoch: 6| Step: 2
Training loss: 2.1364221572875977
Validation loss: 2.1279873937688847

Epoch: 6| Step: 3
Training loss: 1.6887112855911255
Validation loss: 2.11728104981043

Epoch: 6| Step: 4
Training loss: 2.680426597595215
Validation loss: 2.1197261451393046

Epoch: 6| Step: 5
Training loss: 2.3128952980041504
Validation loss: 2.126368840535482

Epoch: 6| Step: 6
Training loss: 2.5303077697753906
Validation loss: 2.1333518412805375

Epoch: 6| Step: 7
Training loss: 1.9422935247421265
Validation loss: 2.1211895532505487

Epoch: 6| Step: 8
Training loss: 2.029019355773926
Validation loss: 2.1269932126486175

Epoch: 6| Step: 9
Training loss: 2.44862699508667
Validation loss: 2.123980647774153

Epoch: 6| Step: 10
Training loss: 2.302680492401123
Validation loss: 2.102059482246317

Epoch: 6| Step: 11
Training loss: 2.503171920776367
Validation loss: 2.0782165476070937

Epoch: 6| Step: 12
Training loss: 2.162621021270752
Validation loss: 2.093312422434489

Epoch: 6| Step: 13
Training loss: 1.4477784633636475
Validation loss: 2.0941802365805513

Epoch: 155| Step: 0
Training loss: 2.2080230712890625
Validation loss: 2.0862605289746354

Epoch: 6| Step: 1
Training loss: 2.1386373043060303
Validation loss: 2.0861251661854405

Epoch: 6| Step: 2
Training loss: 2.694916009902954
Validation loss: 2.1236657814313005

Epoch: 6| Step: 3
Training loss: 2.0125486850738525
Validation loss: 2.1122042363689792

Epoch: 6| Step: 4
Training loss: 2.353973865509033
Validation loss: 2.1246344068998932

Epoch: 6| Step: 5
Training loss: 1.5841097831726074
Validation loss: 2.1470801497018464

Epoch: 6| Step: 6
Training loss: 2.2778444290161133
Validation loss: 2.1407527974856797

Epoch: 6| Step: 7
Training loss: 2.121384859085083
Validation loss: 2.13526588614269

Epoch: 6| Step: 8
Training loss: 2.2148098945617676
Validation loss: 2.112864745560513

Epoch: 6| Step: 9
Training loss: 2.256763219833374
Validation loss: 2.1232990064928607

Epoch: 6| Step: 10
Training loss: 2.1420178413391113
Validation loss: 2.1059568723042807

Epoch: 6| Step: 11
Training loss: 1.8224842548370361
Validation loss: 2.1086822786638812

Epoch: 6| Step: 12
Training loss: 2.6623380184173584
Validation loss: 2.1140158919877905

Epoch: 6| Step: 13
Training loss: 1.4778183698654175
Validation loss: 2.1010273092536518

Epoch: 156| Step: 0
Training loss: 1.4980387687683105
Validation loss: 2.0935925450376285

Epoch: 6| Step: 1
Training loss: 2.403606414794922
Validation loss: 2.0876864643507105

Epoch: 6| Step: 2
Training loss: 1.9953370094299316
Validation loss: 2.091073429712685

Epoch: 6| Step: 3
Training loss: 2.9731650352478027
Validation loss: 2.1031893222562728

Epoch: 6| Step: 4
Training loss: 2.182145357131958
Validation loss: 2.103949828814435

Epoch: 6| Step: 5
Training loss: 1.866294503211975
Validation loss: 2.0961325271155244

Epoch: 6| Step: 6
Training loss: 2.3007242679595947
Validation loss: 2.102918355695663

Epoch: 6| Step: 7
Training loss: 2.6609952449798584
Validation loss: 2.1051976475664365

Epoch: 6| Step: 8
Training loss: 2.0165693759918213
Validation loss: 2.0908387066215597

Epoch: 6| Step: 9
Training loss: 2.004274606704712
Validation loss: 2.115412768497262

Epoch: 6| Step: 10
Training loss: 2.7724852561950684
Validation loss: 2.122578383773886

Epoch: 6| Step: 11
Training loss: 1.655117392539978
Validation loss: 2.1194522765374955

Epoch: 6| Step: 12
Training loss: 2.063842296600342
Validation loss: 2.122725430355277

Epoch: 6| Step: 13
Training loss: 1.3217089176177979
Validation loss: 2.124668163637961

Epoch: 157| Step: 0
Training loss: 1.8535139560699463
Validation loss: 2.11377929231172

Epoch: 6| Step: 1
Training loss: 2.032057285308838
Validation loss: 2.0942008802967687

Epoch: 6| Step: 2
Training loss: 2.7322049140930176
Validation loss: 2.0914977571015716

Epoch: 6| Step: 3
Training loss: 2.35017728805542
Validation loss: 2.089393377304077

Epoch: 6| Step: 4
Training loss: 3.213632345199585
Validation loss: 2.1013393709736485

Epoch: 6| Step: 5
Training loss: 2.4179458618164062
Validation loss: 2.099757250919137

Epoch: 6| Step: 6
Training loss: 2.325129985809326
Validation loss: 2.108436079435451

Epoch: 6| Step: 7
Training loss: 1.6700619459152222
Validation loss: 2.0984685972172725

Epoch: 6| Step: 8
Training loss: 1.6737321615219116
Validation loss: 2.080671295042961

Epoch: 6| Step: 9
Training loss: 1.8637913465499878
Validation loss: 2.080928632008132

Epoch: 6| Step: 10
Training loss: 1.8720934391021729
Validation loss: 2.0694970597503004

Epoch: 6| Step: 11
Training loss: 2.2231359481811523
Validation loss: 2.0837437106717016

Epoch: 6| Step: 12
Training loss: 1.6162569522857666
Validation loss: 2.1070761244784117

Epoch: 6| Step: 13
Training loss: 1.6056550741195679
Validation loss: 2.1068637781245734

Epoch: 158| Step: 0
Training loss: 2.336874485015869
Validation loss: 2.1275178360682663

Epoch: 6| Step: 1
Training loss: 1.8878923654556274
Validation loss: 2.1347604105549474

Epoch: 6| Step: 2
Training loss: 2.2651925086975098
Validation loss: 2.143978238105774

Epoch: 6| Step: 3
Training loss: 2.454324722290039
Validation loss: 2.125369607761342

Epoch: 6| Step: 4
Training loss: 2.3802008628845215
Validation loss: 2.1090550986669396

Epoch: 6| Step: 5
Training loss: 1.6454485654830933
Validation loss: 2.085603052569974

Epoch: 6| Step: 6
Training loss: 2.268792152404785
Validation loss: 2.081924464112969

Epoch: 6| Step: 7
Training loss: 2.0617363452911377
Validation loss: 2.0789069180847495

Epoch: 6| Step: 8
Training loss: 2.224277973175049
Validation loss: 2.0717915463191208

Epoch: 6| Step: 9
Training loss: 2.0409646034240723
Validation loss: 2.0634298427130586

Epoch: 6| Step: 10
Training loss: 2.2489218711853027
Validation loss: 2.060370135050948

Epoch: 6| Step: 11
Training loss: 2.3179898262023926
Validation loss: 2.0760833473615747

Epoch: 6| Step: 12
Training loss: 1.6267812252044678
Validation loss: 2.078995863596598

Epoch: 6| Step: 13
Training loss: 1.61502206325531
Validation loss: 2.0699471978731054

Epoch: 159| Step: 0
Training loss: 2.068439483642578
Validation loss: 2.1090599260022564

Epoch: 6| Step: 1
Training loss: 2.797518730163574
Validation loss: 2.1746165675501667

Epoch: 6| Step: 2
Training loss: 2.2612762451171875
Validation loss: 2.1969940662384033

Epoch: 6| Step: 3
Training loss: 2.6465725898742676
Validation loss: 2.2223926513425765

Epoch: 6| Step: 4
Training loss: 1.8168585300445557
Validation loss: 2.2127510091309905

Epoch: 6| Step: 5
Training loss: 1.7418670654296875
Validation loss: 2.1823530786780903

Epoch: 6| Step: 6
Training loss: 2.4387452602386475
Validation loss: 2.1605413088234524

Epoch: 6| Step: 7
Training loss: 1.9155833721160889
Validation loss: 2.1475959977796

Epoch: 6| Step: 8
Training loss: 1.793370246887207
Validation loss: 2.1246523549479823

Epoch: 6| Step: 9
Training loss: 2.2404377460479736
Validation loss: 2.1198595595616165

Epoch: 6| Step: 10
Training loss: 2.04624605178833
Validation loss: 2.0824867192135064

Epoch: 6| Step: 11
Training loss: 1.9853713512420654
Validation loss: 2.0711446949230727

Epoch: 6| Step: 12
Training loss: 2.381551504135132
Validation loss: 2.0654225246880644

Epoch: 6| Step: 13
Training loss: 1.3272607326507568
Validation loss: 2.077252423891457

Epoch: 160| Step: 0
Training loss: 2.4445648193359375
Validation loss: 2.0775146176738124

Epoch: 6| Step: 1
Training loss: 1.8832648992538452
Validation loss: 2.1122294754110356

Epoch: 6| Step: 2
Training loss: 2.1468985080718994
Validation loss: 2.142202461919477

Epoch: 6| Step: 3
Training loss: 1.6035856008529663
Validation loss: 2.1680737195476407

Epoch: 6| Step: 4
Training loss: 1.9884898662567139
Validation loss: 2.221722915608396

Epoch: 6| Step: 5
Training loss: 2.1286911964416504
Validation loss: 2.2447420474021667

Epoch: 6| Step: 6
Training loss: 2.1732025146484375
Validation loss: 2.252735209721391

Epoch: 6| Step: 7
Training loss: 2.1401991844177246
Validation loss: 2.235460687709111

Epoch: 6| Step: 8
Training loss: 2.711827278137207
Validation loss: 2.2086454168442757

Epoch: 6| Step: 9
Training loss: 2.7337217330932617
Validation loss: 2.1729228983643236

Epoch: 6| Step: 10
Training loss: 2.54724383354187
Validation loss: 2.1618896145974436

Epoch: 6| Step: 11
Training loss: 1.7931888103485107
Validation loss: 2.143765575142317

Epoch: 6| Step: 12
Training loss: 1.7646934986114502
Validation loss: 2.121189159731711

Epoch: 6| Step: 13
Training loss: 2.0115747451782227
Validation loss: 2.1284488888197046

Epoch: 161| Step: 0
Training loss: 2.121659755706787
Validation loss: 2.1156571193407943

Epoch: 6| Step: 1
Training loss: 2.035512924194336
Validation loss: 2.1080043649160736

Epoch: 6| Step: 2
Training loss: 2.136751174926758
Validation loss: 2.1012922256223616

Epoch: 6| Step: 3
Training loss: 2.624518632888794
Validation loss: 2.1076496224249563

Epoch: 6| Step: 4
Training loss: 2.036371946334839
Validation loss: 2.0899182660605318

Epoch: 6| Step: 5
Training loss: 2.4683570861816406
Validation loss: 2.069845505940017

Epoch: 6| Step: 6
Training loss: 1.7305517196655273
Validation loss: 2.066248704028386

Epoch: 6| Step: 7
Training loss: 1.9524574279785156
Validation loss: 2.0662179108588927

Epoch: 6| Step: 8
Training loss: 2.5988218784332275
Validation loss: 2.0611465464356127

Epoch: 6| Step: 9
Training loss: 2.4547181129455566
Validation loss: 2.07638713108596

Epoch: 6| Step: 10
Training loss: 2.1136350631713867
Validation loss: 2.0969680919442126

Epoch: 6| Step: 11
Training loss: 2.8017067909240723
Validation loss: 2.089201081183649

Epoch: 6| Step: 12
Training loss: 1.5427659749984741
Validation loss: 2.094050895783209

Epoch: 6| Step: 13
Training loss: 1.8889312744140625
Validation loss: 2.091707606469431

Epoch: 162| Step: 0
Training loss: 2.1273701190948486
Validation loss: 2.116613659807431

Epoch: 6| Step: 1
Training loss: 2.2379186153411865
Validation loss: 2.142448330438265

Epoch: 6| Step: 2
Training loss: 1.8948345184326172
Validation loss: 2.1335528396791026

Epoch: 6| Step: 3
Training loss: 2.1392245292663574
Validation loss: 2.1449657204330608

Epoch: 6| Step: 4
Training loss: 1.862090826034546
Validation loss: 2.163364471927766

Epoch: 6| Step: 5
Training loss: 1.9404895305633545
Validation loss: 2.1508335182743687

Epoch: 6| Step: 6
Training loss: 2.154496192932129
Validation loss: 2.1245188841255764

Epoch: 6| Step: 7
Training loss: 2.4568512439727783
Validation loss: 2.1348855790271553

Epoch: 6| Step: 8
Training loss: 2.029658794403076
Validation loss: 2.1496621216497114

Epoch: 6| Step: 9
Training loss: 1.8046127557754517
Validation loss: 2.1369398011956164

Epoch: 6| Step: 10
Training loss: 2.2726101875305176
Validation loss: 2.1315082170630015

Epoch: 6| Step: 11
Training loss: 1.7290043830871582
Validation loss: 2.102781844395463

Epoch: 6| Step: 12
Training loss: 2.3353347778320312
Validation loss: 2.093232757301741

Epoch: 6| Step: 13
Training loss: 2.5944623947143555
Validation loss: 2.084350698737688

Epoch: 163| Step: 0
Training loss: 1.8115019798278809
Validation loss: 2.0789461904956448

Epoch: 6| Step: 1
Training loss: 2.2109808921813965
Validation loss: 2.0497996281552058

Epoch: 6| Step: 2
Training loss: 1.7412569522857666
Validation loss: 2.0515775244723082

Epoch: 6| Step: 3
Training loss: 1.5372846126556396
Validation loss: 2.0532866498475433

Epoch: 6| Step: 4
Training loss: 1.8698430061340332
Validation loss: 2.057557849473851

Epoch: 6| Step: 5
Training loss: 1.829939603805542
Validation loss: 2.061178639370908

Epoch: 6| Step: 6
Training loss: 2.5204172134399414
Validation loss: 2.0662033737346692

Epoch: 6| Step: 7
Training loss: 2.3008031845092773
Validation loss: 2.0732151757004442

Epoch: 6| Step: 8
Training loss: 1.7028491497039795
Validation loss: 2.086466855900262

Epoch: 6| Step: 9
Training loss: 2.6670584678649902
Validation loss: 2.1135765814012095

Epoch: 6| Step: 10
Training loss: 2.5594024658203125
Validation loss: 2.1463430799463743

Epoch: 6| Step: 11
Training loss: 1.9256587028503418
Validation loss: 2.158949557171073

Epoch: 6| Step: 12
Training loss: 2.5674989223480225
Validation loss: 2.151818670252318

Epoch: 6| Step: 13
Training loss: 2.114154815673828
Validation loss: 2.1319130710376206

Epoch: 164| Step: 0
Training loss: 2.3678159713745117
Validation loss: 2.10652345226657

Epoch: 6| Step: 1
Training loss: 2.2735674381256104
Validation loss: 2.0704682283504035

Epoch: 6| Step: 2
Training loss: 2.654531955718994
Validation loss: 2.081625674360542

Epoch: 6| Step: 3
Training loss: 2.3214516639709473
Validation loss: 2.0788447446720575

Epoch: 6| Step: 4
Training loss: 1.3946720361709595
Validation loss: 2.094306233108685

Epoch: 6| Step: 5
Training loss: 2.2473742961883545
Validation loss: 2.0819027962223178

Epoch: 6| Step: 6
Training loss: 1.9999070167541504
Validation loss: 2.062329371770223

Epoch: 6| Step: 7
Training loss: 2.111694574356079
Validation loss: 2.0651464141825193

Epoch: 6| Step: 8
Training loss: 2.15293550491333
Validation loss: 2.0737314788244103

Epoch: 6| Step: 9
Training loss: 2.4487051963806152
Validation loss: 2.068345605686147

Epoch: 6| Step: 10
Training loss: 1.8617892265319824
Validation loss: 2.070900878598613

Epoch: 6| Step: 11
Training loss: 1.8813257217407227
Validation loss: 2.080890135098529

Epoch: 6| Step: 12
Training loss: 2.014164447784424
Validation loss: 2.0849073061379055

Epoch: 6| Step: 13
Training loss: 1.8236571550369263
Validation loss: 2.100274593599381

Epoch: 165| Step: 0
Training loss: 1.697951078414917
Validation loss: 2.1105472528806297

Epoch: 6| Step: 1
Training loss: 1.2032092809677124
Validation loss: 2.1344914333794707

Epoch: 6| Step: 2
Training loss: 2.01058292388916
Validation loss: 2.1873368781100035

Epoch: 6| Step: 3
Training loss: 2.3311328887939453
Validation loss: 2.230212806373514

Epoch: 6| Step: 4
Training loss: 1.3380593061447144
Validation loss: 2.2648960954399517

Epoch: 6| Step: 5
Training loss: 2.5577919483184814
Validation loss: 2.2800371775063137

Epoch: 6| Step: 6
Training loss: 1.977240800857544
Validation loss: 2.277425435281569

Epoch: 6| Step: 7
Training loss: 2.052553176879883
Validation loss: 2.244901200776459

Epoch: 6| Step: 8
Training loss: 2.670013427734375
Validation loss: 2.2114511843650573

Epoch: 6| Step: 9
Training loss: 2.6973073482513428
Validation loss: 2.182847948484523

Epoch: 6| Step: 10
Training loss: 2.115616798400879
Validation loss: 2.147585863708168

Epoch: 6| Step: 11
Training loss: 2.7650296688079834
Validation loss: 2.117683836208877

Epoch: 6| Step: 12
Training loss: 2.1242599487304688
Validation loss: 2.10356919739836

Epoch: 6| Step: 13
Training loss: 2.3122735023498535
Validation loss: 2.0935644026725524

Epoch: 166| Step: 0
Training loss: 2.562633514404297
Validation loss: 2.0756462325331984

Epoch: 6| Step: 1
Training loss: 2.198214530944824
Validation loss: 2.0900784705274846

Epoch: 6| Step: 2
Training loss: 2.2859058380126953
Validation loss: 2.080223173223516

Epoch: 6| Step: 3
Training loss: 2.4976401329040527
Validation loss: 2.0968346813673615

Epoch: 6| Step: 4
Training loss: 1.8078359365463257
Validation loss: 2.1139697631200156

Epoch: 6| Step: 5
Training loss: 1.92355477809906
Validation loss: 2.113648768394224

Epoch: 6| Step: 6
Training loss: 2.225994825363159
Validation loss: 2.118066309600748

Epoch: 6| Step: 7
Training loss: 2.378221035003662
Validation loss: 2.101813929055327

Epoch: 6| Step: 8
Training loss: 2.271613359451294
Validation loss: 2.090898075411397

Epoch: 6| Step: 9
Training loss: 2.138792037963867
Validation loss: 2.0979767640431723

Epoch: 6| Step: 10
Training loss: 1.5629916191101074
Validation loss: 2.075078022095465

Epoch: 6| Step: 11
Training loss: 1.5834136009216309
Validation loss: 2.0987904238444504

Epoch: 6| Step: 12
Training loss: 1.968674659729004
Validation loss: 2.1033308839285247

Epoch: 6| Step: 13
Training loss: 1.3332444429397583
Validation loss: 2.1222238899559103

Epoch: 167| Step: 0
Training loss: 2.9790096282958984
Validation loss: 2.138405769102035

Epoch: 6| Step: 1
Training loss: 2.4961769580841064
Validation loss: 2.163977107694072

Epoch: 6| Step: 2
Training loss: 1.7268006801605225
Validation loss: 2.2077591265401533

Epoch: 6| Step: 3
Training loss: 1.7760013341903687
Validation loss: 2.205641322238471

Epoch: 6| Step: 4
Training loss: 2.2253847122192383
Validation loss: 2.2265401911991898

Epoch: 6| Step: 5
Training loss: 1.7567049264907837
Validation loss: 2.1969283729471187

Epoch: 6| Step: 6
Training loss: 1.8451790809631348
Validation loss: 2.154246509716075

Epoch: 6| Step: 7
Training loss: 2.1209254264831543
Validation loss: 2.1282052698955742

Epoch: 6| Step: 8
Training loss: 1.7937170267105103
Validation loss: 2.1125743517311673

Epoch: 6| Step: 9
Training loss: 2.146892786026001
Validation loss: 2.0852822975445817

Epoch: 6| Step: 10
Training loss: 1.5125908851623535
Validation loss: 2.09093201544977

Epoch: 6| Step: 11
Training loss: 2.718672275543213
Validation loss: 2.0825630439225065

Epoch: 6| Step: 12
Training loss: 1.8394405841827393
Validation loss: 2.0773294715471167

Epoch: 6| Step: 13
Training loss: 2.28999924659729
Validation loss: 2.0902220459394556

Epoch: 168| Step: 0
Training loss: 2.233668327331543
Validation loss: 2.1009557195889053

Epoch: 6| Step: 1
Training loss: 2.1146481037139893
Validation loss: 2.0807900326226347

Epoch: 6| Step: 2
Training loss: 1.6298580169677734
Validation loss: 2.095724108398602

Epoch: 6| Step: 3
Training loss: 2.5576977729797363
Validation loss: 2.105490488390769

Epoch: 6| Step: 4
Training loss: 2.231433868408203
Validation loss: 2.0892016451845885

Epoch: 6| Step: 5
Training loss: 2.0173656940460205
Validation loss: 2.095816666080106

Epoch: 6| Step: 6
Training loss: 2.6156246662139893
Validation loss: 2.1036903858184814

Epoch: 6| Step: 7
Training loss: 1.6577988862991333
Validation loss: 2.0962450222302507

Epoch: 6| Step: 8
Training loss: 1.7809704542160034
Validation loss: 2.0993897350885535

Epoch: 6| Step: 9
Training loss: 1.8664093017578125
Validation loss: 2.087734114739203

Epoch: 6| Step: 10
Training loss: 2.369720935821533
Validation loss: 2.084439203303347

Epoch: 6| Step: 11
Training loss: 1.3183313608169556
Validation loss: 2.083910124276274

Epoch: 6| Step: 12
Training loss: 2.002833604812622
Validation loss: 2.0745459384815668

Epoch: 6| Step: 13
Training loss: 3.0778160095214844
Validation loss: 2.090624947701731

Epoch: 169| Step: 0
Training loss: 2.3501791954040527
Validation loss: 2.082152182056058

Epoch: 6| Step: 1
Training loss: 1.8391228914260864
Validation loss: 2.0726510888786724

Epoch: 6| Step: 2
Training loss: 2.18290114402771
Validation loss: 2.0935217642015025

Epoch: 6| Step: 3
Training loss: 2.443673610687256
Validation loss: 2.074003968187558

Epoch: 6| Step: 4
Training loss: 2.348621368408203
Validation loss: 2.0952723513367357

Epoch: 6| Step: 5
Training loss: 1.319244146347046
Validation loss: 2.121890042417793

Epoch: 6| Step: 6
Training loss: 2.2739243507385254
Validation loss: 2.123544457138226

Epoch: 6| Step: 7
Training loss: 2.361968755722046
Validation loss: 2.1266305241533505

Epoch: 6| Step: 8
Training loss: 1.4780642986297607
Validation loss: 2.1092300197129608

Epoch: 6| Step: 9
Training loss: 2.4462270736694336
Validation loss: 2.099520525624675

Epoch: 6| Step: 10
Training loss: 1.9949203729629517
Validation loss: 2.097601188126431

Epoch: 6| Step: 11
Training loss: 1.6436604261398315
Validation loss: 2.097642269185794

Epoch: 6| Step: 12
Training loss: 2.0930795669555664
Validation loss: 2.0899315572554067

Epoch: 6| Step: 13
Training loss: 1.2468687295913696
Validation loss: 2.0943853970496886

Epoch: 170| Step: 0
Training loss: 1.9950017929077148
Validation loss: 2.0931634159498316

Epoch: 6| Step: 1
Training loss: 2.5194942951202393
Validation loss: 2.0953304613790205

Epoch: 6| Step: 2
Training loss: 2.7741124629974365
Validation loss: 2.0848552642330045

Epoch: 6| Step: 3
Training loss: 2.019439458847046
Validation loss: 2.0718432934053483

Epoch: 6| Step: 4
Training loss: 1.5325411558151245
Validation loss: 2.0523310489551996

Epoch: 6| Step: 5
Training loss: 1.7483489513397217
Validation loss: 2.053490900224255

Epoch: 6| Step: 6
Training loss: 2.2404520511627197
Validation loss: 2.042098992614336

Epoch: 6| Step: 7
Training loss: 1.728494644165039
Validation loss: 2.0432822935042845

Epoch: 6| Step: 8
Training loss: 1.445242166519165
Validation loss: 2.0486416996166272

Epoch: 6| Step: 9
Training loss: 2.6013991832733154
Validation loss: 2.065599767110681

Epoch: 6| Step: 10
Training loss: 1.8231258392333984
Validation loss: 2.0822337968375093

Epoch: 6| Step: 11
Training loss: 2.3879377841949463
Validation loss: 2.092102295608931

Epoch: 6| Step: 12
Training loss: 2.0527710914611816
Validation loss: 2.084148414673344

Epoch: 6| Step: 13
Training loss: 1.607475757598877
Validation loss: 2.0885657059249056

Epoch: 171| Step: 0
Training loss: 1.986167073249817
Validation loss: 2.075927206265029

Epoch: 6| Step: 1
Training loss: 2.42525577545166
Validation loss: 2.0805026536346762

Epoch: 6| Step: 2
Training loss: 1.5688974857330322
Validation loss: 2.0784527640188895

Epoch: 6| Step: 3
Training loss: 1.8832943439483643
Validation loss: 2.1110788340209634

Epoch: 6| Step: 4
Training loss: 2.0021474361419678
Validation loss: 2.1142505894425097

Epoch: 6| Step: 5
Training loss: 1.9821110963821411
Validation loss: 2.133357940181609

Epoch: 6| Step: 6
Training loss: 1.4251424074172974
Validation loss: 2.1438996176565848

Epoch: 6| Step: 7
Training loss: 1.9885976314544678
Validation loss: 2.146061343531455

Epoch: 6| Step: 8
Training loss: 2.3702809810638428
Validation loss: 2.11658541874219

Epoch: 6| Step: 9
Training loss: 2.2568836212158203
Validation loss: 2.0979732313463764

Epoch: 6| Step: 10
Training loss: 2.5196187496185303
Validation loss: 2.089760431679346

Epoch: 6| Step: 11
Training loss: 2.173336982727051
Validation loss: 2.07093035533864

Epoch: 6| Step: 12
Training loss: 2.1480116844177246
Validation loss: 2.060159347390616

Epoch: 6| Step: 13
Training loss: 1.7690916061401367
Validation loss: 2.0702858214737265

Epoch: 172| Step: 0
Training loss: 2.450969696044922
Validation loss: 2.090997939468712

Epoch: 6| Step: 1
Training loss: 1.4261727333068848
Validation loss: 2.121095936785462

Epoch: 6| Step: 2
Training loss: 2.228851795196533
Validation loss: 2.136322682903659

Epoch: 6| Step: 3
Training loss: 2.4223780632019043
Validation loss: 2.1555742858558573

Epoch: 6| Step: 4
Training loss: 1.3970894813537598
Validation loss: 2.129111418160059

Epoch: 6| Step: 5
Training loss: 2.0659677982330322
Validation loss: 2.148703735361817

Epoch: 6| Step: 6
Training loss: 2.013854503631592
Validation loss: 2.1274189743944394

Epoch: 6| Step: 7
Training loss: 0.9357866048812866
Validation loss: 2.114556666343443

Epoch: 6| Step: 8
Training loss: 2.0561587810516357
Validation loss: 2.127666422115859

Epoch: 6| Step: 9
Training loss: 2.2200348377227783
Validation loss: 2.127842621136737

Epoch: 6| Step: 10
Training loss: 2.3680715560913086
Validation loss: 2.1208378563645067

Epoch: 6| Step: 11
Training loss: 1.7744390964508057
Validation loss: 2.125490286016977

Epoch: 6| Step: 12
Training loss: 2.6164751052856445
Validation loss: 2.105333601274798

Epoch: 6| Step: 13
Training loss: 2.554471015930176
Validation loss: 2.111971406526463

Epoch: 173| Step: 0
Training loss: 1.7294955253601074
Validation loss: 2.09968912729653

Epoch: 6| Step: 1
Training loss: 2.0559895038604736
Validation loss: 2.0946140340579453

Epoch: 6| Step: 2
Training loss: 2.446443796157837
Validation loss: 2.075220287487071

Epoch: 6| Step: 3
Training loss: 1.6158173084259033
Validation loss: 2.0866768949775287

Epoch: 6| Step: 4
Training loss: 1.7193248271942139
Validation loss: 2.0875767892406834

Epoch: 6| Step: 5
Training loss: 2.0863330364227295
Validation loss: 2.108632105653004

Epoch: 6| Step: 6
Training loss: 1.923152208328247
Validation loss: 2.09580240198361

Epoch: 6| Step: 7
Training loss: 1.8428804874420166
Validation loss: 2.0915397354351577

Epoch: 6| Step: 8
Training loss: 1.4839041233062744
Validation loss: 2.1035391822937997

Epoch: 6| Step: 9
Training loss: 2.1332662105560303
Validation loss: 2.089329050433251

Epoch: 6| Step: 10
Training loss: 1.6782257556915283
Validation loss: 2.0744726119502896

Epoch: 6| Step: 11
Training loss: 1.7718193531036377
Validation loss: 2.053748707617483

Epoch: 6| Step: 12
Training loss: 2.5950136184692383
Validation loss: 2.0439130106279926

Epoch: 6| Step: 13
Training loss: 3.3149845600128174
Validation loss: 2.033614985404476

Epoch: 174| Step: 0
Training loss: 2.5866141319274902
Validation loss: 2.028448898305175

Epoch: 6| Step: 1
Training loss: 2.727640151977539
Validation loss: 2.021217421818805

Epoch: 6| Step: 2
Training loss: 1.7921440601348877
Validation loss: 2.0206746516689176

Epoch: 6| Step: 3
Training loss: 2.2081263065338135
Validation loss: 2.009692935533421

Epoch: 6| Step: 4
Training loss: 1.7616328001022339
Validation loss: 2.0142546674256683

Epoch: 6| Step: 5
Training loss: 1.350324273109436
Validation loss: 2.0205934662972727

Epoch: 6| Step: 6
Training loss: 1.9541213512420654
Validation loss: 2.0163254584035566

Epoch: 6| Step: 7
Training loss: 2.2690162658691406
Validation loss: 2.0434703698722263

Epoch: 6| Step: 8
Training loss: 2.114628791809082
Validation loss: 2.0695942935123237

Epoch: 6| Step: 9
Training loss: 1.7797974348068237
Validation loss: 2.111713291496359

Epoch: 6| Step: 10
Training loss: 1.2163259983062744
Validation loss: 2.1396767170198503

Epoch: 6| Step: 11
Training loss: 2.118072271347046
Validation loss: 2.1455322311770533

Epoch: 6| Step: 12
Training loss: 2.141972541809082
Validation loss: 2.15305483213035

Epoch: 6| Step: 13
Training loss: 1.83616304397583
Validation loss: 2.148538330549835

Epoch: 175| Step: 0
Training loss: 2.696523427963257
Validation loss: 2.1694432497024536

Epoch: 6| Step: 1
Training loss: 1.9381217956542969
Validation loss: 2.1351553470857683

Epoch: 6| Step: 2
Training loss: 2.8315300941467285
Validation loss: 2.097624897956848

Epoch: 6| Step: 3
Training loss: 1.9925312995910645
Validation loss: 2.087271011003884

Epoch: 6| Step: 4
Training loss: 1.4797742366790771
Validation loss: 2.0590507368887625

Epoch: 6| Step: 5
Training loss: 2.090693712234497
Validation loss: 2.039718266456358

Epoch: 6| Step: 6
Training loss: 2.2540252208709717
Validation loss: 2.0394688806226178

Epoch: 6| Step: 7
Training loss: 2.069723129272461
Validation loss: 2.0347170086317163

Epoch: 6| Step: 8
Training loss: 1.3448389768600464
Validation loss: 2.052022539159303

Epoch: 6| Step: 9
Training loss: 2.1607038974761963
Validation loss: 2.0515423692682737

Epoch: 6| Step: 10
Training loss: 2.001451015472412
Validation loss: 2.0583692442986274

Epoch: 6| Step: 11
Training loss: 0.9351670145988464
Validation loss: 2.0859378845460954

Epoch: 6| Step: 12
Training loss: 2.4117283821105957
Validation loss: 2.1059189522138206

Epoch: 6| Step: 13
Training loss: 1.7738195657730103
Validation loss: 2.1264455882451867

Epoch: 176| Step: 0
Training loss: 2.5451583862304688
Validation loss: 2.1286800830594954

Epoch: 6| Step: 1
Training loss: 1.737364411354065
Validation loss: 2.137212121358482

Epoch: 6| Step: 2
Training loss: 2.160801649093628
Validation loss: 2.1426865695625223

Epoch: 6| Step: 3
Training loss: 1.471784234046936
Validation loss: 2.1406195163726807

Epoch: 6| Step: 4
Training loss: 2.2632570266723633
Validation loss: 2.1143055769705

Epoch: 6| Step: 5
Training loss: 1.3283402919769287
Validation loss: 2.0821247370012346

Epoch: 6| Step: 6
Training loss: 1.634960651397705
Validation loss: 2.0688010313177623

Epoch: 6| Step: 7
Training loss: 2.376692533493042
Validation loss: 2.0603162627066336

Epoch: 6| Step: 8
Training loss: 1.3692591190338135
Validation loss: 2.0322425544902845

Epoch: 6| Step: 9
Training loss: 2.285893201828003
Validation loss: 2.025378772007522

Epoch: 6| Step: 10
Training loss: 2.6387906074523926
Validation loss: 2.0350717908592633

Epoch: 6| Step: 11
Training loss: 1.4528694152832031
Validation loss: 2.040400548647809

Epoch: 6| Step: 12
Training loss: 2.131070137023926
Validation loss: 2.048252290295016

Epoch: 6| Step: 13
Training loss: 2.6455724239349365
Validation loss: 2.063394836200181

Epoch: 177| Step: 0
Training loss: 1.6378090381622314
Validation loss: 2.0675886689975695

Epoch: 6| Step: 1
Training loss: 1.9468599557876587
Validation loss: 2.062308108934792

Epoch: 6| Step: 2
Training loss: 1.5180282592773438
Validation loss: 2.0919070961654826

Epoch: 6| Step: 3
Training loss: 1.7408463954925537
Validation loss: 2.10281640355305

Epoch: 6| Step: 4
Training loss: 1.7930678129196167
Validation loss: 2.108890312974171

Epoch: 6| Step: 5
Training loss: 1.8288830518722534
Validation loss: 2.1260981867390294

Epoch: 6| Step: 6
Training loss: 2.1376094818115234
Validation loss: 2.1342162983391875

Epoch: 6| Step: 7
Training loss: 2.3083901405334473
Validation loss: 2.1323286820483465

Epoch: 6| Step: 8
Training loss: 1.8125200271606445
Validation loss: 2.102604063608313

Epoch: 6| Step: 9
Training loss: 1.8973239660263062
Validation loss: 2.087524567880938

Epoch: 6| Step: 10
Training loss: 2.753915786743164
Validation loss: 2.1059295861951766

Epoch: 6| Step: 11
Training loss: 2.169759511947632
Validation loss: 2.0800990161075386

Epoch: 6| Step: 12
Training loss: 2.140204906463623
Validation loss: 2.0817489008749686

Epoch: 6| Step: 13
Training loss: 1.8349609375
Validation loss: 2.0677545891013196

Epoch: 178| Step: 0
Training loss: 2.159573554992676
Validation loss: 2.046091766767604

Epoch: 6| Step: 1
Training loss: 1.5777907371520996
Validation loss: 2.0419120378391717

Epoch: 6| Step: 2
Training loss: 2.558539390563965
Validation loss: 2.032247866353681

Epoch: 6| Step: 3
Training loss: 2.2761497497558594
Validation loss: 2.0294559540287143

Epoch: 6| Step: 4
Training loss: 2.2431416511535645
Validation loss: 2.0220937639154415

Epoch: 6| Step: 5
Training loss: 1.4704442024230957
Validation loss: 2.020484129587809

Epoch: 6| Step: 6
Training loss: 2.043440341949463
Validation loss: 2.012231655018304

Epoch: 6| Step: 7
Training loss: 2.5160839557647705
Validation loss: 2.0347180379334318

Epoch: 6| Step: 8
Training loss: 1.608483910560608
Validation loss: 2.034490223853819

Epoch: 6| Step: 9
Training loss: 2.363891363143921
Validation loss: 2.040184836233816

Epoch: 6| Step: 10
Training loss: 1.5849294662475586
Validation loss: 2.0589653112555064

Epoch: 6| Step: 11
Training loss: 1.4970998764038086
Validation loss: 2.06830995826311

Epoch: 6| Step: 12
Training loss: 2.083073139190674
Validation loss: 2.10937842758753

Epoch: 6| Step: 13
Training loss: 1.080060362815857
Validation loss: 2.129033762921569

Epoch: 179| Step: 0
Training loss: 1.9756156206130981
Validation loss: 2.141218218752133

Epoch: 6| Step: 1
Training loss: 2.2064783573150635
Validation loss: 2.1270353845370713

Epoch: 6| Step: 2
Training loss: 1.7392001152038574
Validation loss: 2.13746730742916

Epoch: 6| Step: 3
Training loss: 2.3417930603027344
Validation loss: 2.118950738701769

Epoch: 6| Step: 4
Training loss: 1.679762363433838
Validation loss: 2.0992347732667

Epoch: 6| Step: 5
Training loss: 2.1313726902008057
Validation loss: 2.0946305490309194

Epoch: 6| Step: 6
Training loss: 2.1324551105499268
Validation loss: 2.0989302524956326

Epoch: 6| Step: 7
Training loss: 2.118253707885742
Validation loss: 2.091269511048512

Epoch: 6| Step: 8
Training loss: 2.1282150745391846
Validation loss: 2.097582826050379

Epoch: 6| Step: 9
Training loss: 2.829228639602661
Validation loss: 2.0867820683346

Epoch: 6| Step: 10
Training loss: 1.988476276397705
Validation loss: 2.091874420001943

Epoch: 6| Step: 11
Training loss: 1.2653063535690308
Validation loss: 2.069290819988456

Epoch: 6| Step: 12
Training loss: 1.2476953268051147
Validation loss: 2.06486838991924

Epoch: 6| Step: 13
Training loss: 1.7949384450912476
Validation loss: 2.060389995574951

Epoch: 180| Step: 0
Training loss: 1.5789515972137451
Validation loss: 2.074169699863721

Epoch: 6| Step: 1
Training loss: 2.026728391647339
Validation loss: 2.0684855138101885

Epoch: 6| Step: 2
Training loss: 2.1924197673797607
Validation loss: 2.08938088468326

Epoch: 6| Step: 3
Training loss: 1.9776865243911743
Validation loss: 2.116070011610626

Epoch: 6| Step: 4
Training loss: 2.3237459659576416
Validation loss: 2.1378351501239243

Epoch: 6| Step: 5
Training loss: 2.6575846672058105
Validation loss: 2.1623812516530356

Epoch: 6| Step: 6
Training loss: 1.4210703372955322
Validation loss: 2.1622978436049594

Epoch: 6| Step: 7
Training loss: 2.028388261795044
Validation loss: 2.1513491138335197

Epoch: 6| Step: 8
Training loss: 2.156209945678711
Validation loss: 2.133845139575261

Epoch: 6| Step: 9
Training loss: 2.1010241508483887
Validation loss: 2.123300847186837

Epoch: 6| Step: 10
Training loss: 2.121371030807495
Validation loss: 2.1057646992386028

Epoch: 6| Step: 11
Training loss: 2.008452892303467
Validation loss: 2.0929236899140062

Epoch: 6| Step: 12
Training loss: 1.3618124723434448
Validation loss: 2.0555135742310555

Epoch: 6| Step: 13
Training loss: 1.2886205911636353
Validation loss: 2.052877647902376

Epoch: 181| Step: 0
Training loss: 1.8498024940490723
Validation loss: 2.0366949650549118

Epoch: 6| Step: 1
Training loss: 1.0713896751403809
Validation loss: 2.0237708783918813

Epoch: 6| Step: 2
Training loss: 1.840198040008545
Validation loss: 2.0212063020275486

Epoch: 6| Step: 3
Training loss: 2.7307467460632324
Validation loss: 2.011808115948913

Epoch: 6| Step: 4
Training loss: 2.133242607116699
Validation loss: 2.0133271960801977

Epoch: 6| Step: 5
Training loss: 1.8394548892974854
Validation loss: 2.0288563774478052

Epoch: 6| Step: 6
Training loss: 2.053123950958252
Validation loss: 2.0365048223926174

Epoch: 6| Step: 7
Training loss: 1.6710023880004883
Validation loss: 2.064338125208373

Epoch: 6| Step: 8
Training loss: 1.6048686504364014
Validation loss: 2.0568496847665436

Epoch: 6| Step: 9
Training loss: 1.6650915145874023
Validation loss: 2.076316959114485

Epoch: 6| Step: 10
Training loss: 2.4885470867156982
Validation loss: 2.061429738998413

Epoch: 6| Step: 11
Training loss: 2.225811243057251
Validation loss: 2.070771109673285

Epoch: 6| Step: 12
Training loss: 1.8199979066848755
Validation loss: 2.0759125601860786

Epoch: 6| Step: 13
Training loss: 2.3046934604644775
Validation loss: 2.070604165395101

Epoch: 182| Step: 0
Training loss: 2.6352224349975586
Validation loss: 2.0795389247196976

Epoch: 6| Step: 1
Training loss: 2.1762499809265137
Validation loss: 2.0796389156772244

Epoch: 6| Step: 2
Training loss: 1.9027395248413086
Validation loss: 2.075106987389185

Epoch: 6| Step: 3
Training loss: 1.465404748916626
Validation loss: 2.081025581206045

Epoch: 6| Step: 4
Training loss: 2.554488182067871
Validation loss: 2.06656478810054

Epoch: 6| Step: 5
Training loss: 1.8111069202423096
Validation loss: 2.07568625480898

Epoch: 6| Step: 6
Training loss: 2.0974345207214355
Validation loss: 2.088018386594711

Epoch: 6| Step: 7
Training loss: 2.0293502807617188
Validation loss: 2.0892349084218345

Epoch: 6| Step: 8
Training loss: 1.3185075521469116
Validation loss: 2.0894110997517905

Epoch: 6| Step: 9
Training loss: 2.3528575897216797
Validation loss: 2.0964965563948437

Epoch: 6| Step: 10
Training loss: 1.8354365825653076
Validation loss: 2.1081684789349957

Epoch: 6| Step: 11
Training loss: 1.8622610569000244
Validation loss: 2.109314416044502

Epoch: 6| Step: 12
Training loss: 1.2751359939575195
Validation loss: 2.1169025205796763

Epoch: 6| Step: 13
Training loss: 1.665473461151123
Validation loss: 2.1118870242949455

Epoch: 183| Step: 0
Training loss: 1.2040762901306152
Validation loss: 2.1089395630744194

Epoch: 6| Step: 1
Training loss: 1.514897346496582
Validation loss: 2.1048295408166866

Epoch: 6| Step: 2
Training loss: 2.0567829608917236
Validation loss: 2.0905756078740603

Epoch: 6| Step: 3
Training loss: 1.6624237298965454
Validation loss: 2.079988173259202

Epoch: 6| Step: 4
Training loss: 2.1678380966186523
Validation loss: 2.0668078750692387

Epoch: 6| Step: 5
Training loss: 1.9871091842651367
Validation loss: 2.060083422609555

Epoch: 6| Step: 6
Training loss: 2.530304431915283
Validation loss: 2.057694031346229

Epoch: 6| Step: 7
Training loss: 1.9709529876708984
Validation loss: 2.075895118457015

Epoch: 6| Step: 8
Training loss: 1.2873950004577637
Validation loss: 2.0659458227055048

Epoch: 6| Step: 9
Training loss: 1.6356945037841797
Validation loss: 2.0874869131272837

Epoch: 6| Step: 10
Training loss: 2.4669971466064453
Validation loss: 2.1015996189527613

Epoch: 6| Step: 11
Training loss: 2.0206170082092285
Validation loss: 2.099190902966325

Epoch: 6| Step: 12
Training loss: 2.193450450897217
Validation loss: 2.0815961668568272

Epoch: 6| Step: 13
Training loss: 2.5907344818115234
Validation loss: 2.0783236949674544

Epoch: 184| Step: 0
Training loss: 1.6577788591384888
Validation loss: 2.055094667660293

Epoch: 6| Step: 1
Training loss: 2.2731776237487793
Validation loss: 2.057481497846624

Epoch: 6| Step: 2
Training loss: 1.9931495189666748
Validation loss: 2.0479779422924085

Epoch: 6| Step: 3
Training loss: 1.880589485168457
Validation loss: 2.048499368852185

Epoch: 6| Step: 4
Training loss: 1.8843110799789429
Validation loss: 2.0692325035730996

Epoch: 6| Step: 5
Training loss: 2.85473370552063
Validation loss: 2.0711399573151783

Epoch: 6| Step: 6
Training loss: 1.4693299531936646
Validation loss: 2.068192549931106

Epoch: 6| Step: 7
Training loss: 2.0438523292541504
Validation loss: 2.0668672797500447

Epoch: 6| Step: 8
Training loss: 1.4582626819610596
Validation loss: 2.064973836304039

Epoch: 6| Step: 9
Training loss: 2.2499256134033203
Validation loss: 2.0571528788535827

Epoch: 6| Step: 10
Training loss: 1.6270266771316528
Validation loss: 2.04469112683368

Epoch: 6| Step: 11
Training loss: 1.2619723081588745
Validation loss: 2.033016353525141

Epoch: 6| Step: 12
Training loss: 2.18192720413208
Validation loss: 2.0327724410641577

Epoch: 6| Step: 13
Training loss: 1.6618822813034058
Validation loss: 2.0339485958058345

Epoch: 185| Step: 0
Training loss: 1.7004166841506958
Validation loss: 2.026842581328525

Epoch: 6| Step: 1
Training loss: 1.1360868215560913
Validation loss: 2.052118529555618

Epoch: 6| Step: 2
Training loss: 1.8000108003616333
Validation loss: 2.0778475551195044

Epoch: 6| Step: 3
Training loss: 1.8211710453033447
Validation loss: 2.1097456152721117

Epoch: 6| Step: 4
Training loss: 2.090339183807373
Validation loss: 2.109710015276427

Epoch: 6| Step: 5
Training loss: 1.8237768411636353
Validation loss: 2.1161285677263812

Epoch: 6| Step: 6
Training loss: 1.8429298400878906
Validation loss: 2.072979542516893

Epoch: 6| Step: 7
Training loss: 2.3388924598693848
Validation loss: 2.0621283797807592

Epoch: 6| Step: 8
Training loss: 1.9421640634536743
Validation loss: 2.024151150898267

Epoch: 6| Step: 9
Training loss: 2.2924582958221436
Validation loss: 2.023810822476623

Epoch: 6| Step: 10
Training loss: 2.4263763427734375
Validation loss: 2.0347329365309847

Epoch: 6| Step: 11
Training loss: 2.191844940185547
Validation loss: 2.0365063554497174

Epoch: 6| Step: 12
Training loss: 1.6881554126739502
Validation loss: 2.026485437987953

Epoch: 6| Step: 13
Training loss: 1.5427407026290894
Validation loss: 2.0195284428135043

Epoch: 186| Step: 0
Training loss: 1.7781498432159424
Validation loss: 2.024921945346299

Epoch: 6| Step: 1
Training loss: 1.145754098892212
Validation loss: 2.0445236839273924

Epoch: 6| Step: 2
Training loss: 1.7371830940246582
Validation loss: 2.053334907818866

Epoch: 6| Step: 3
Training loss: 1.65203857421875
Validation loss: 2.057617587427939

Epoch: 6| Step: 4
Training loss: 2.4434847831726074
Validation loss: 2.0382330071541572

Epoch: 6| Step: 5
Training loss: 2.1951146125793457
Validation loss: 2.0374672323144893

Epoch: 6| Step: 6
Training loss: 2.2647922039031982
Validation loss: 2.0464060037366805

Epoch: 6| Step: 7
Training loss: 1.7149288654327393
Validation loss: 2.0495162920285295

Epoch: 6| Step: 8
Training loss: 1.874762773513794
Validation loss: 2.0546302423682263

Epoch: 6| Step: 9
Training loss: 2.393909454345703
Validation loss: 2.0587326557405534

Epoch: 6| Step: 10
Training loss: 1.6055305004119873
Validation loss: 2.0702636985368628

Epoch: 6| Step: 11
Training loss: 1.7222949266433716
Validation loss: 2.079908888827088

Epoch: 6| Step: 12
Training loss: 1.9404717683792114
Validation loss: 2.091096290978052

Epoch: 6| Step: 13
Training loss: 2.2623589038848877
Validation loss: 2.096336410891625

Epoch: 187| Step: 0
Training loss: 1.4255322217941284
Validation loss: 2.0678660767052763

Epoch: 6| Step: 1
Training loss: 1.470035195350647
Validation loss: 2.060122424556363

Epoch: 6| Step: 2
Training loss: 2.2525634765625
Validation loss: 2.0691935375172603

Epoch: 6| Step: 3
Training loss: 1.8547625541687012
Validation loss: 2.05239341720458

Epoch: 6| Step: 4
Training loss: 1.8572899103164673
Validation loss: 2.048569324196026

Epoch: 6| Step: 5
Training loss: 2.2581188678741455
Validation loss: 2.05370032787323

Epoch: 6| Step: 6
Training loss: 1.9916927814483643
Validation loss: 2.0605040160558556

Epoch: 6| Step: 7
Training loss: 2.462860107421875
Validation loss: 2.0461099275978665

Epoch: 6| Step: 8
Training loss: 1.7140835523605347
Validation loss: 2.050038926063045

Epoch: 6| Step: 9
Training loss: 2.4018349647521973
Validation loss: 2.0575419754110356

Epoch: 6| Step: 10
Training loss: 1.4945213794708252
Validation loss: 2.0884163277123564

Epoch: 6| Step: 11
Training loss: 1.9887123107910156
Validation loss: 2.1017912562175463

Epoch: 6| Step: 12
Training loss: 1.7598865032196045
Validation loss: 2.132038467673845

Epoch: 6| Step: 13
Training loss: 1.404553771018982
Validation loss: 2.116101062426003

Epoch: 188| Step: 0
Training loss: 1.743457317352295
Validation loss: 2.0919655112810034

Epoch: 6| Step: 1
Training loss: 1.6530370712280273
Validation loss: 2.082263510714295

Epoch: 6| Step: 2
Training loss: 2.5450286865234375
Validation loss: 2.033132678718977

Epoch: 6| Step: 3
Training loss: 2.3931329250335693
Validation loss: 2.0219234394770798

Epoch: 6| Step: 4
Training loss: 2.3966636657714844
Validation loss: 2.013639429564117

Epoch: 6| Step: 5
Training loss: 1.5999994277954102
Validation loss: 2.001513955413654

Epoch: 6| Step: 6
Training loss: 2.0314581394195557
Validation loss: 2.000451067442535

Epoch: 6| Step: 7
Training loss: 1.4172873497009277
Validation loss: 2.023323832019683

Epoch: 6| Step: 8
Training loss: 1.4775432348251343
Validation loss: 2.0424282473902546

Epoch: 6| Step: 9
Training loss: 1.6721080541610718
Validation loss: 2.0615557188628824

Epoch: 6| Step: 10
Training loss: 1.4805134534835815
Validation loss: 2.0620872461667625

Epoch: 6| Step: 11
Training loss: 2.0876240730285645
Validation loss: 2.062906324222524

Epoch: 6| Step: 12
Training loss: 1.2602519989013672
Validation loss: 2.0869406615534136

Epoch: 6| Step: 13
Training loss: 2.9507861137390137
Validation loss: 2.07468593248757

Epoch: 189| Step: 0
Training loss: 1.6491196155548096
Validation loss: 2.0885855767034713

Epoch: 6| Step: 1
Training loss: 1.72617506980896
Validation loss: 2.073359348440683

Epoch: 6| Step: 2
Training loss: 1.9995393753051758
Validation loss: 2.0867524634125414

Epoch: 6| Step: 3
Training loss: 2.1137609481811523
Validation loss: 2.0930773596609793

Epoch: 6| Step: 4
Training loss: 1.4712436199188232
Validation loss: 2.0597114550170077

Epoch: 6| Step: 5
Training loss: 2.4123589992523193
Validation loss: 2.0733019049449632

Epoch: 6| Step: 6
Training loss: 2.361367702484131
Validation loss: 2.0621281285439768

Epoch: 6| Step: 7
Training loss: 2.167203903198242
Validation loss: 2.065390634280379

Epoch: 6| Step: 8
Training loss: 1.4987881183624268
Validation loss: 2.0442328453063965

Epoch: 6| Step: 9
Training loss: 1.5448216199874878
Validation loss: 2.0313743404162827

Epoch: 6| Step: 10
Training loss: 1.7101233005523682
Validation loss: 2.0284054920237553

Epoch: 6| Step: 11
Training loss: 1.9291826486587524
Validation loss: 2.0260051860604236

Epoch: 6| Step: 12
Training loss: 2.0003714561462402
Validation loss: 2.0282521786228305

Epoch: 6| Step: 13
Training loss: 1.4370688199996948
Validation loss: 2.030571045414094

Epoch: 190| Step: 0
Training loss: 2.3363101482391357
Validation loss: 1.9901250664905836

Epoch: 6| Step: 1
Training loss: 1.5051548480987549
Validation loss: 2.0198116225581013

Epoch: 6| Step: 2
Training loss: 1.7849324941635132
Validation loss: 2.0368805854551253

Epoch: 6| Step: 3
Training loss: 1.9609429836273193
Validation loss: 2.0637667563653763

Epoch: 6| Step: 4
Training loss: 2.133993148803711
Validation loss: 2.0557721045709427

Epoch: 6| Step: 5
Training loss: 1.8975201845169067
Validation loss: 2.0644163444478023

Epoch: 6| Step: 6
Training loss: 1.2851160764694214
Validation loss: 2.081941541805062

Epoch: 6| Step: 7
Training loss: 1.6466059684753418
Validation loss: 2.0806053120602845

Epoch: 6| Step: 8
Training loss: 1.8559943437576294
Validation loss: 2.066116858554143

Epoch: 6| Step: 9
Training loss: 1.7042531967163086
Validation loss: 2.063743596435875

Epoch: 6| Step: 10
Training loss: 1.8757734298706055
Validation loss: 2.048195849182785

Epoch: 6| Step: 11
Training loss: 2.007953643798828
Validation loss: 2.0648963348839873

Epoch: 6| Step: 12
Training loss: 1.9961389303207397
Validation loss: 2.0488371003058647

Epoch: 6| Step: 13
Training loss: 2.203373670578003
Validation loss: 2.0542067917444373

Epoch: 191| Step: 0
Training loss: 2.2277917861938477
Validation loss: 2.0336301198569675

Epoch: 6| Step: 1
Training loss: 1.740675687789917
Validation loss: 2.0422164137645433

Epoch: 6| Step: 2
Training loss: 2.0362367630004883
Validation loss: 2.0451466985928115

Epoch: 6| Step: 3
Training loss: 1.559002161026001
Validation loss: 2.050611583135461

Epoch: 6| Step: 4
Training loss: 1.887221097946167
Validation loss: 2.0622895225401847

Epoch: 6| Step: 5
Training loss: 1.838430404663086
Validation loss: 2.071456438751631

Epoch: 6| Step: 6
Training loss: 1.9380559921264648
Validation loss: 2.066563465261972

Epoch: 6| Step: 7
Training loss: 1.8328310251235962
Validation loss: 2.0529569836073023

Epoch: 6| Step: 8
Training loss: 1.8725123405456543
Validation loss: 2.0414485726305234

Epoch: 6| Step: 9
Training loss: 2.0238447189331055
Validation loss: 2.0357265536503126

Epoch: 6| Step: 10
Training loss: 1.3706722259521484
Validation loss: 2.020430782789825

Epoch: 6| Step: 11
Training loss: 1.8055938482284546
Validation loss: 2.031244401008852

Epoch: 6| Step: 12
Training loss: 2.002981662750244
Validation loss: 2.0160839275647233

Epoch: 6| Step: 13
Training loss: 1.39104163646698
Validation loss: 2.032711572544549

Epoch: 192| Step: 0
Training loss: 1.7776622772216797
Validation loss: 2.0376630060134397

Epoch: 6| Step: 1
Training loss: 2.083134889602661
Validation loss: 2.0460571242916967

Epoch: 6| Step: 2
Training loss: 2.285670757293701
Validation loss: 2.0450199329724876

Epoch: 6| Step: 3
Training loss: 2.200639009475708
Validation loss: 2.0757612054065993

Epoch: 6| Step: 4
Training loss: 2.033919095993042
Validation loss: 2.0635931325215164

Epoch: 6| Step: 5
Training loss: 1.7647321224212646
Validation loss: 2.078845365073091

Epoch: 6| Step: 6
Training loss: 1.100496530532837
Validation loss: 2.0814681335162093

Epoch: 6| Step: 7
Training loss: 2.3874852657318115
Validation loss: 2.0726426570646224

Epoch: 6| Step: 8
Training loss: 1.9661316871643066
Validation loss: 2.0712793796293196

Epoch: 6| Step: 9
Training loss: 1.730717658996582
Validation loss: 2.072360074648293

Epoch: 6| Step: 10
Training loss: 1.2964493036270142
Validation loss: 2.080629271845664

Epoch: 6| Step: 11
Training loss: 1.9739000797271729
Validation loss: 2.0650845086702736

Epoch: 6| Step: 12
Training loss: 1.813278317451477
Validation loss: 2.06373837173626

Epoch: 6| Step: 13
Training loss: 0.7415063381195068
Validation loss: 2.0629571560890443

Epoch: 193| Step: 0
Training loss: 1.6750271320343018
Validation loss: 2.042362536153486

Epoch: 6| Step: 1
Training loss: 1.4152238368988037
Validation loss: 2.0553994076226347

Epoch: 6| Step: 2
Training loss: 1.5201297998428345
Validation loss: 2.0697334453623784

Epoch: 6| Step: 3
Training loss: 2.9502360820770264
Validation loss: 2.0780169130653463

Epoch: 6| Step: 4
Training loss: 1.224245309829712
Validation loss: 2.0826300677432807

Epoch: 6| Step: 5
Training loss: 1.8376367092132568
Validation loss: 2.0843891712927047

Epoch: 6| Step: 6
Training loss: 1.8573966026306152
Validation loss: 2.0860987914505826

Epoch: 6| Step: 7
Training loss: 1.6247661113739014
Validation loss: 2.084870784513412

Epoch: 6| Step: 8
Training loss: 1.200437068939209
Validation loss: 2.090375825922976

Epoch: 6| Step: 9
Training loss: 2.485044002532959
Validation loss: 2.1080504591746996

Epoch: 6| Step: 10
Training loss: 1.9154902696609497
Validation loss: 2.106786274140881

Epoch: 6| Step: 11
Training loss: 1.823635220527649
Validation loss: 2.086581399363856

Epoch: 6| Step: 12
Training loss: 2.3017563819885254
Validation loss: 2.0629560639781337

Epoch: 6| Step: 13
Training loss: 1.79494047164917
Validation loss: 2.059401386527605

Epoch: 194| Step: 0
Training loss: 2.359482526779175
Validation loss: 2.051863434494183

Epoch: 6| Step: 1
Training loss: 1.7151178121566772
Validation loss: 2.0453554173951507

Epoch: 6| Step: 2
Training loss: 1.985425353050232
Validation loss: 2.0461087226867676

Epoch: 6| Step: 3
Training loss: 1.65290105342865
Validation loss: 2.0305554110516786

Epoch: 6| Step: 4
Training loss: 1.456207513809204
Validation loss: 2.023191426389961

Epoch: 6| Step: 5
Training loss: 2.1028599739074707
Validation loss: 2.029807254832278

Epoch: 6| Step: 6
Training loss: 1.8894442319869995
Validation loss: 2.0328953932690363

Epoch: 6| Step: 7
Training loss: 1.594562292098999
Validation loss: 2.033535830436214

Epoch: 6| Step: 8
Training loss: 1.715687870979309
Validation loss: 2.0425265283994776

Epoch: 6| Step: 9
Training loss: 1.2748794555664062
Validation loss: 2.037379672450404

Epoch: 6| Step: 10
Training loss: 2.4699065685272217
Validation loss: 2.0653141288347143

Epoch: 6| Step: 11
Training loss: 1.5243592262268066
Validation loss: 2.0563839840632614

Epoch: 6| Step: 12
Training loss: 1.2239794731140137
Validation loss: 2.0434819421460553

Epoch: 6| Step: 13
Training loss: 2.6411244869232178
Validation loss: 2.043775135470975

Epoch: 195| Step: 0
Training loss: 2.219968318939209
Validation loss: 2.0513858026073826

Epoch: 6| Step: 1
Training loss: 1.651692271232605
Validation loss: 2.0422179955308155

Epoch: 6| Step: 2
Training loss: 1.80746328830719
Validation loss: 2.0346732421587874

Epoch: 6| Step: 3
Training loss: 1.5884404182434082
Validation loss: 2.0202320057858705

Epoch: 6| Step: 4
Training loss: 1.4105072021484375
Validation loss: 2.023802279144205

Epoch: 6| Step: 5
Training loss: 0.8627157211303711
Validation loss: 2.0607594584905975

Epoch: 6| Step: 6
Training loss: 2.3379693031311035
Validation loss: 2.059314089436685

Epoch: 6| Step: 7
Training loss: 2.0011630058288574
Validation loss: 2.0646095134878673

Epoch: 6| Step: 8
Training loss: 2.0556676387786865
Validation loss: 2.0499364817014305

Epoch: 6| Step: 9
Training loss: 1.833524465560913
Validation loss: 2.06261864272497

Epoch: 6| Step: 10
Training loss: 1.3735060691833496
Validation loss: 2.0617986058676117

Epoch: 6| Step: 11
Training loss: 1.8125733137130737
Validation loss: 2.0728713004819808

Epoch: 6| Step: 12
Training loss: 2.2154805660247803
Validation loss: 2.0919867279709026

Epoch: 6| Step: 13
Training loss: 1.8472131490707397
Validation loss: 2.113570405590919

Epoch: 196| Step: 0
Training loss: 2.2244887351989746
Validation loss: 2.1391149361928306

Epoch: 6| Step: 1
Training loss: 1.130395770072937
Validation loss: 2.1240739860842304

Epoch: 6| Step: 2
Training loss: 1.6465463638305664
Validation loss: 2.10005828385712

Epoch: 6| Step: 3
Training loss: 1.9671478271484375
Validation loss: 2.068921544218576

Epoch: 6| Step: 4
Training loss: 2.1316564083099365
Validation loss: 2.050306740627494

Epoch: 6| Step: 5
Training loss: 1.6288121938705444
Validation loss: 2.0345184418462936

Epoch: 6| Step: 6
Training loss: 2.1717193126678467
Validation loss: 2.0323517578904347

Epoch: 6| Step: 7
Training loss: 2.291207790374756
Validation loss: 2.0193657849424627

Epoch: 6| Step: 8
Training loss: 2.0610995292663574
Validation loss: 2.0277364305270615

Epoch: 6| Step: 9
Training loss: 1.3637006282806396
Validation loss: 2.0146163355919624

Epoch: 6| Step: 10
Training loss: 1.6719671487808228
Validation loss: 2.011846357776273

Epoch: 6| Step: 11
Training loss: 1.3354343175888062
Validation loss: 2.033136849762291

Epoch: 6| Step: 12
Training loss: 1.424930453300476
Validation loss: 2.056195092457597

Epoch: 6| Step: 13
Training loss: 2.2805256843566895
Validation loss: 2.0942352535904094

Epoch: 197| Step: 0
Training loss: 2.147123336791992
Validation loss: 2.0963845342718144

Epoch: 6| Step: 1
Training loss: 1.1963787078857422
Validation loss: 2.097243478221278

Epoch: 6| Step: 2
Training loss: 1.135268211364746
Validation loss: 2.0809953776738976

Epoch: 6| Step: 3
Training loss: 1.449405312538147
Validation loss: 2.0669235414074314

Epoch: 6| Step: 4
Training loss: 1.8569573163986206
Validation loss: 2.055208675322994

Epoch: 6| Step: 5
Training loss: 2.537788152694702
Validation loss: 2.043495325631993

Epoch: 6| Step: 6
Training loss: 2.2508420944213867
Validation loss: 2.0458067565835933

Epoch: 6| Step: 7
Training loss: 2.070572853088379
Validation loss: 2.052596284497169

Epoch: 6| Step: 8
Training loss: 1.2275534868240356
Validation loss: 2.0529700299744964

Epoch: 6| Step: 9
Training loss: 2.1466171741485596
Validation loss: 2.0435811332477036

Epoch: 6| Step: 10
Training loss: 1.5311245918273926
Validation loss: 2.0431570570955992

Epoch: 6| Step: 11
Training loss: 1.9486160278320312
Validation loss: 2.041325298688745

Epoch: 6| Step: 12
Training loss: 1.590355634689331
Validation loss: 2.0284051356777066

Epoch: 6| Step: 13
Training loss: 2.106977939605713
Validation loss: 2.020572749517297

Epoch: 198| Step: 0
Training loss: 1.2066211700439453
Validation loss: 2.0229790838815833

Epoch: 6| Step: 1
Training loss: 1.9258828163146973
Validation loss: 2.018074280472212

Epoch: 6| Step: 2
Training loss: 2.1889774799346924
Validation loss: 2.018588530120029

Epoch: 6| Step: 3
Training loss: 1.872145414352417
Validation loss: 2.0109854423871605

Epoch: 6| Step: 4
Training loss: 1.7646665573120117
Validation loss: 2.016309074176255

Epoch: 6| Step: 5
Training loss: 2.0784811973571777
Validation loss: 2.0313114581569547

Epoch: 6| Step: 6
Training loss: 1.5443317890167236
Validation loss: 2.036529674324938

Epoch: 6| Step: 7
Training loss: 1.6458388566970825
Validation loss: 2.0389502022856023

Epoch: 6| Step: 8
Training loss: 2.145582675933838
Validation loss: 2.030258837566581

Epoch: 6| Step: 9
Training loss: 1.6738781929016113
Validation loss: 2.0315683067485852

Epoch: 6| Step: 10
Training loss: 1.4416390657424927
Validation loss: 2.0180756212562643

Epoch: 6| Step: 11
Training loss: 2.0554656982421875
Validation loss: 2.0211767958056543

Epoch: 6| Step: 12
Training loss: 1.7025952339172363
Validation loss: 2.013717509085132

Epoch: 6| Step: 13
Training loss: 2.1367740631103516
Validation loss: 2.029236424353815

Epoch: 199| Step: 0
Training loss: 1.9371311664581299
Validation loss: 2.0144857988562634

Epoch: 6| Step: 1
Training loss: 2.0046019554138184
Validation loss: 2.029417055909352

Epoch: 6| Step: 2
Training loss: 1.6750152111053467
Validation loss: 2.0435860374922394

Epoch: 6| Step: 3
Training loss: 1.3638978004455566
Validation loss: 2.0524355519202446

Epoch: 6| Step: 4
Training loss: 2.127683639526367
Validation loss: 2.0542259139399373

Epoch: 6| Step: 5
Training loss: 2.2641077041625977
Validation loss: 2.0431039512798352

Epoch: 6| Step: 6
Training loss: 1.4525479078292847
Validation loss: 2.0431679525683

Epoch: 6| Step: 7
Training loss: 1.448495864868164
Validation loss: 2.016784066795021

Epoch: 6| Step: 8
Training loss: 1.995927095413208
Validation loss: 2.033599445896764

Epoch: 6| Step: 9
Training loss: 1.6672890186309814
Validation loss: 2.0352727367031958

Epoch: 6| Step: 10
Training loss: 2.3423094749450684
Validation loss: 2.043298227812654

Epoch: 6| Step: 11
Training loss: 1.1547167301177979
Validation loss: 2.041216734916933

Epoch: 6| Step: 12
Training loss: 2.1571145057678223
Validation loss: 2.045615662810623

Epoch: 6| Step: 13
Training loss: 0.9997593760490417
Validation loss: 2.060745600731142

Epoch: 200| Step: 0
Training loss: 2.265761613845825
Validation loss: 2.0928238489294566

Epoch: 6| Step: 1
Training loss: 1.502833604812622
Validation loss: 2.0737105787441297

Epoch: 6| Step: 2
Training loss: 1.630270004272461
Validation loss: 2.054765596184679

Epoch: 6| Step: 3
Training loss: 1.4805102348327637
Validation loss: 2.0432569570438837

Epoch: 6| Step: 4
Training loss: 1.8546662330627441
Validation loss: 2.022037829122236

Epoch: 6| Step: 5
Training loss: 1.4016932249069214
Validation loss: 2.032590223896888

Epoch: 6| Step: 6
Training loss: 1.3697181940078735
Validation loss: 2.0371355472072477

Epoch: 6| Step: 7
Training loss: 2.4642903804779053
Validation loss: 2.027528021925239

Epoch: 6| Step: 8
Training loss: 1.8687925338745117
Validation loss: 2.0229288378069477

Epoch: 6| Step: 9
Training loss: 1.3313004970550537
Validation loss: 2.015446670593754

Epoch: 6| Step: 10
Training loss: 1.6249377727508545
Validation loss: 2.0268087528085195

Epoch: 6| Step: 11
Training loss: 2.1348049640655518
Validation loss: 2.0188004957732333

Epoch: 6| Step: 12
Training loss: 1.4776394367218018
Validation loss: 2.0145117185449086

Epoch: 6| Step: 13
Training loss: 2.2041380405426025
Validation loss: 2.0130814095979095

Epoch: 201| Step: 0
Training loss: 2.021479606628418
Validation loss: 2.001191299448731

Epoch: 6| Step: 1
Training loss: 1.758453369140625
Validation loss: 2.000651846649826

Epoch: 6| Step: 2
Training loss: 0.9960519671440125
Validation loss: 2.009359569959743

Epoch: 6| Step: 3
Training loss: 1.6011533737182617
Validation loss: 2.037036577860514

Epoch: 6| Step: 4
Training loss: 1.5868463516235352
Validation loss: 2.0260252875666462

Epoch: 6| Step: 5
Training loss: 2.558384418487549
Validation loss: 2.0346663331472747

Epoch: 6| Step: 6
Training loss: 1.2535887956619263
Validation loss: 2.0368324043930217

Epoch: 6| Step: 7
Training loss: 1.5513684749603271
Validation loss: 2.044841294647545

Epoch: 6| Step: 8
Training loss: 1.3846769332885742
Validation loss: 2.0329374985028337

Epoch: 6| Step: 9
Training loss: 1.5064176321029663
Validation loss: 2.0324662475175757

Epoch: 6| Step: 10
Training loss: 1.641374111175537
Validation loss: 2.0395189997970418

Epoch: 6| Step: 11
Training loss: 2.578268051147461
Validation loss: 2.0768282093027586

Epoch: 6| Step: 12
Training loss: 1.9902822971343994
Validation loss: 2.0560011043343493

Epoch: 6| Step: 13
Training loss: 1.7289477586746216
Validation loss: 2.068386516263408

Epoch: 202| Step: 0
Training loss: 1.6624016761779785
Validation loss: 2.0419349901137815

Epoch: 6| Step: 1
Training loss: 1.692875623703003
Validation loss: 2.023401742340416

Epoch: 6| Step: 2
Training loss: 1.7403051853179932
Validation loss: 2.033189050612911

Epoch: 6| Step: 3
Training loss: 1.6077446937561035
Validation loss: 2.0118522631224764

Epoch: 6| Step: 4
Training loss: 1.6107072830200195
Validation loss: 2.024678825050272

Epoch: 6| Step: 5
Training loss: 1.481074333190918
Validation loss: 2.017117379814066

Epoch: 6| Step: 6
Training loss: 1.3928053379058838
Validation loss: 2.0267034999785887

Epoch: 6| Step: 7
Training loss: 1.8436272144317627
Validation loss: 2.02555561706584

Epoch: 6| Step: 8
Training loss: 1.900928258895874
Validation loss: 2.0225416767981743

Epoch: 6| Step: 9
Training loss: 2.022995948791504
Validation loss: 2.020377779519686

Epoch: 6| Step: 10
Training loss: 2.0909016132354736
Validation loss: 2.0208390092337005

Epoch: 6| Step: 11
Training loss: 2.0112533569335938
Validation loss: 2.03770342949898

Epoch: 6| Step: 12
Training loss: 1.5573654174804688
Validation loss: 2.0317936584513676

Epoch: 6| Step: 13
Training loss: 1.4617122411727905
Validation loss: 2.0249299682596678

Epoch: 203| Step: 0
Training loss: 2.139084577560425
Validation loss: 2.042791401186297

Epoch: 6| Step: 1
Training loss: 0.6921094059944153
Validation loss: 2.053175808281027

Epoch: 6| Step: 2
Training loss: 2.352466583251953
Validation loss: 2.068427062803699

Epoch: 6| Step: 3
Training loss: 1.5130068063735962
Validation loss: 2.0636062673343125

Epoch: 6| Step: 4
Training loss: 2.18859601020813
Validation loss: 2.0570099494790517

Epoch: 6| Step: 5
Training loss: 1.9846365451812744
Validation loss: 2.039840472641812

Epoch: 6| Step: 6
Training loss: 1.9602679014205933
Validation loss: 2.056275121627315

Epoch: 6| Step: 7
Training loss: 1.1857028007507324
Validation loss: 2.0269991543985184

Epoch: 6| Step: 8
Training loss: 1.7659856081008911
Validation loss: 2.0258694566706175

Epoch: 6| Step: 9
Training loss: 1.1266448497772217
Validation loss: 2.0259043068014164

Epoch: 6| Step: 10
Training loss: 1.9071521759033203
Validation loss: 2.044469036081786

Epoch: 6| Step: 11
Training loss: 2.155463933944702
Validation loss: 2.0361073388848254

Epoch: 6| Step: 12
Training loss: 1.9228577613830566
Validation loss: 2.0287997607261903

Epoch: 6| Step: 13
Training loss: 1.0370360612869263
Validation loss: 2.0113223111757668

Epoch: 204| Step: 0
Training loss: 2.0091278553009033
Validation loss: 2.0087893227095246

Epoch: 6| Step: 1
Training loss: 1.180019736289978
Validation loss: 1.9847435899960097

Epoch: 6| Step: 2
Training loss: 2.0856690406799316
Validation loss: 1.9916869363477152

Epoch: 6| Step: 3
Training loss: 1.4528745412826538
Validation loss: 2.008164962132772

Epoch: 6| Step: 4
Training loss: 1.4479615688323975
Validation loss: 2.011326241236861

Epoch: 6| Step: 5
Training loss: 1.5482029914855957
Validation loss: 2.0114928599326842

Epoch: 6| Step: 6
Training loss: 2.541283369064331
Validation loss: 2.030440907324514

Epoch: 6| Step: 7
Training loss: 2.1450271606445312
Validation loss: 2.017990981378863

Epoch: 6| Step: 8
Training loss: 1.8780148029327393
Validation loss: 2.024771164822322

Epoch: 6| Step: 9
Training loss: 1.18588387966156
Validation loss: 2.028707012053459

Epoch: 6| Step: 10
Training loss: 1.709918737411499
Validation loss: 2.0405133257630053

Epoch: 6| Step: 11
Training loss: 1.6123230457305908
Validation loss: 2.071379215486588

Epoch: 6| Step: 12
Training loss: 1.2548398971557617
Validation loss: 2.0692522961606263

Epoch: 6| Step: 13
Training loss: 2.143857717514038
Validation loss: 2.070893088976542

Epoch: 205| Step: 0
Training loss: 1.8035739660263062
Validation loss: 2.0627717510346444

Epoch: 6| Step: 1
Training loss: 1.3022147417068481
Validation loss: 2.074449231547694

Epoch: 6| Step: 2
Training loss: 1.5976405143737793
Validation loss: 2.0585069515371837

Epoch: 6| Step: 3
Training loss: 1.350762128829956
Validation loss: 2.0664083060397895

Epoch: 6| Step: 4
Training loss: 1.4257140159606934
Validation loss: 2.0809120388441187

Epoch: 6| Step: 5
Training loss: 2.0094716548919678
Validation loss: 2.06847721017817

Epoch: 6| Step: 6
Training loss: 2.4588623046875
Validation loss: 2.070222347013412

Epoch: 6| Step: 7
Training loss: 2.0064034461975098
Validation loss: 2.0751674457262923

Epoch: 6| Step: 8
Training loss: 1.126145601272583
Validation loss: 2.0583445500302058

Epoch: 6| Step: 9
Training loss: 2.254652500152588
Validation loss: 2.042206892403223

Epoch: 6| Step: 10
Training loss: 1.805405855178833
Validation loss: 2.0334433881185388

Epoch: 6| Step: 11
Training loss: 1.635556936264038
Validation loss: 2.0573369405602895

Epoch: 6| Step: 12
Training loss: 1.732069969177246
Validation loss: 2.0431150031346146

Epoch: 6| Step: 13
Training loss: 1.039939522743225
Validation loss: 2.0466869954139955

Epoch: 206| Step: 0
Training loss: 1.6303446292877197
Validation loss: 2.024963350706203

Epoch: 6| Step: 1
Training loss: 1.8839128017425537
Validation loss: 2.0476084780949417

Epoch: 6| Step: 2
Training loss: 1.445260763168335
Validation loss: 2.060441852897726

Epoch: 6| Step: 3
Training loss: 1.4039897918701172
Validation loss: 2.0476309381505495

Epoch: 6| Step: 4
Training loss: 1.8865251541137695
Validation loss: 2.051145317733929

Epoch: 6| Step: 5
Training loss: 1.7272893190383911
Validation loss: 2.0220780552074475

Epoch: 6| Step: 6
Training loss: 1.2551169395446777
Validation loss: 2.0094192104954876

Epoch: 6| Step: 7
Training loss: 1.6986932754516602
Validation loss: 1.9975112407438216

Epoch: 6| Step: 8
Training loss: 1.5235021114349365
Validation loss: 2.0054693401500745

Epoch: 6| Step: 9
Training loss: 1.962174654006958
Validation loss: 2.007790211708315

Epoch: 6| Step: 10
Training loss: 2.1642839908599854
Validation loss: 2.0168779973060853

Epoch: 6| Step: 11
Training loss: 2.0881729125976562
Validation loss: 2.0007555587317354

Epoch: 6| Step: 12
Training loss: 1.8722114562988281
Validation loss: 2.0225523235977336

Epoch: 6| Step: 13
Training loss: 1.0156078338623047
Validation loss: 2.012884191287461

Epoch: 207| Step: 0
Training loss: 1.9020799398422241
Validation loss: 2.0050961227827173

Epoch: 6| Step: 1
Training loss: 1.4867184162139893
Validation loss: 2.013329239301784

Epoch: 6| Step: 2
Training loss: 1.5772666931152344
Validation loss: 2.008783572463579

Epoch: 6| Step: 3
Training loss: 1.8363471031188965
Validation loss: 2.024972459321381

Epoch: 6| Step: 4
Training loss: 1.7633624076843262
Validation loss: 2.028687628366614

Epoch: 6| Step: 5
Training loss: 1.2600575685501099
Validation loss: 2.035853168015839

Epoch: 6| Step: 6
Training loss: 1.4184422492980957
Validation loss: 2.0341177063603557

Epoch: 6| Step: 7
Training loss: 1.7947331666946411
Validation loss: 2.022097682440153

Epoch: 6| Step: 8
Training loss: 1.9668548107147217
Validation loss: 2.02107334649691

Epoch: 6| Step: 9
Training loss: 1.3935271501541138
Validation loss: 2.0078612450630433

Epoch: 6| Step: 10
Training loss: 1.9279818534851074
Validation loss: 2.0109663086552776

Epoch: 6| Step: 11
Training loss: 1.1432709693908691
Validation loss: 2.017894773073094

Epoch: 6| Step: 12
Training loss: 1.8040642738342285
Validation loss: 2.0085263072803454

Epoch: 6| Step: 13
Training loss: 2.6964023113250732
Validation loss: 2.01401948928833

Epoch: 208| Step: 0
Training loss: 1.918003797531128
Validation loss: 2.026250770015101

Epoch: 6| Step: 1
Training loss: 2.562441825866699
Validation loss: 2.029733233554389

Epoch: 6| Step: 2
Training loss: 1.6579115390777588
Validation loss: 2.03761044368949

Epoch: 6| Step: 3
Training loss: 1.6562952995300293
Validation loss: 2.0423760824306036

Epoch: 6| Step: 4
Training loss: 1.393423318862915
Validation loss: 2.010974271323091

Epoch: 6| Step: 5
Training loss: 1.6063547134399414
Validation loss: 2.010215078630755

Epoch: 6| Step: 6
Training loss: 1.7211167812347412
Validation loss: 2.0220939536248483

Epoch: 6| Step: 7
Training loss: 1.6215935945510864
Validation loss: 2.0209610949280443

Epoch: 6| Step: 8
Training loss: 1.5052560567855835
Validation loss: 2.0056677441443167

Epoch: 6| Step: 9
Training loss: 1.0689936876296997
Validation loss: 2.0201199439264115

Epoch: 6| Step: 10
Training loss: 1.664811372756958
Validation loss: 2.0330151229776363

Epoch: 6| Step: 11
Training loss: 1.2549138069152832
Validation loss: 2.0512402301193564

Epoch: 6| Step: 12
Training loss: 1.8945457935333252
Validation loss: 2.0438696799739713

Epoch: 6| Step: 13
Training loss: 2.1595895290374756
Validation loss: 2.0560622215270996

Epoch: 209| Step: 0
Training loss: 1.605830192565918
Validation loss: 2.064860399051379

Epoch: 6| Step: 1
Training loss: 2.042447090148926
Validation loss: 2.087772641130673

Epoch: 6| Step: 2
Training loss: 1.7831470966339111
Validation loss: 2.0711191854169293

Epoch: 6| Step: 3
Training loss: 1.2107062339782715
Validation loss: 2.081693164763912

Epoch: 6| Step: 4
Training loss: 1.8440227508544922
Validation loss: 2.0475263390489804

Epoch: 6| Step: 5
Training loss: 1.3125439882278442
Validation loss: 2.035142922914156

Epoch: 6| Step: 6
Training loss: 1.4594677686691284
Validation loss: 2.0355105297539824

Epoch: 6| Step: 7
Training loss: 1.83683180809021
Validation loss: 2.0355768178098943

Epoch: 6| Step: 8
Training loss: 1.28969407081604
Validation loss: 2.024151894354051

Epoch: 6| Step: 9
Training loss: 2.2655954360961914
Validation loss: 2.0059140061819427

Epoch: 6| Step: 10
Training loss: 2.3873915672302246
Validation loss: 1.9961317046996085

Epoch: 6| Step: 11
Training loss: 1.651963472366333
Validation loss: 2.0007194626715874

Epoch: 6| Step: 12
Training loss: 1.4285995960235596
Validation loss: 2.0156258972742225

Epoch: 6| Step: 13
Training loss: 1.1717395782470703
Validation loss: 2.0286149542818785

Epoch: 210| Step: 0
Training loss: 1.2934290170669556
Validation loss: 2.0333325145065144

Epoch: 6| Step: 1
Training loss: 1.6099083423614502
Validation loss: 2.048265403316867

Epoch: 6| Step: 2
Training loss: 2.11932373046875
Validation loss: 2.04057006425755

Epoch: 6| Step: 3
Training loss: 2.367804527282715
Validation loss: 2.0569977401405253

Epoch: 6| Step: 4
Training loss: 1.4867103099822998
Validation loss: 2.0382529176691526

Epoch: 6| Step: 5
Training loss: 2.0281317234039307
Validation loss: 2.0163807971503145

Epoch: 6| Step: 6
Training loss: 1.3531944751739502
Validation loss: 2.0099720134530017

Epoch: 6| Step: 7
Training loss: 1.9539016485214233
Validation loss: 1.9939607599730134

Epoch: 6| Step: 8
Training loss: 1.8750417232513428
Validation loss: 1.9993272468607912

Epoch: 6| Step: 9
Training loss: 0.938386082649231
Validation loss: 1.9882044356356385

Epoch: 6| Step: 10
Training loss: 1.7738476991653442
Validation loss: 1.9805307067850584

Epoch: 6| Step: 11
Training loss: 1.4379175901412964
Validation loss: 1.9909991846289685

Epoch: 6| Step: 12
Training loss: 1.3074924945831299
Validation loss: 2.0063651864246657

Epoch: 6| Step: 13
Training loss: 1.618019938468933
Validation loss: 2.0110625938702653

Epoch: 211| Step: 0
Training loss: 2.0718727111816406
Validation loss: 1.995386754312823

Epoch: 6| Step: 1
Training loss: 1.2849912643432617
Validation loss: 2.002369139784126

Epoch: 6| Step: 2
Training loss: 2.2010231018066406
Validation loss: 2.027534092626264

Epoch: 6| Step: 3
Training loss: 1.4449870586395264
Validation loss: 2.0438751020739154

Epoch: 6| Step: 4
Training loss: 1.6189625263214111
Validation loss: 2.0338114000135854

Epoch: 6| Step: 5
Training loss: 1.7850546836853027
Validation loss: 2.0497447649637857

Epoch: 6| Step: 6
Training loss: 1.2447614669799805
Validation loss: 2.089334272569226

Epoch: 6| Step: 7
Training loss: 1.339186191558838
Validation loss: 2.0935359103705293

Epoch: 6| Step: 8
Training loss: 1.468322515487671
Validation loss: 2.0697610660265853

Epoch: 6| Step: 9
Training loss: 1.562957763671875
Validation loss: 2.064165207647508

Epoch: 6| Step: 10
Training loss: 1.921403408050537
Validation loss: 2.0733879804611206

Epoch: 6| Step: 11
Training loss: 2.12722110748291
Validation loss: 2.0557444069975164

Epoch: 6| Step: 12
Training loss: 0.7805122137069702
Validation loss: 2.021807506520261

Epoch: 6| Step: 13
Training loss: 2.649118185043335
Validation loss: 1.9960311074410715

Epoch: 212| Step: 0
Training loss: 1.3973768949508667
Validation loss: 1.9914841139188377

Epoch: 6| Step: 1
Training loss: 1.3536443710327148
Validation loss: 1.9918814192536056

Epoch: 6| Step: 2
Training loss: 1.548508644104004
Validation loss: 1.9982338297751643

Epoch: 6| Step: 3
Training loss: 2.0440404415130615
Validation loss: 1.9810840711798718

Epoch: 6| Step: 4
Training loss: 1.9437365531921387
Validation loss: 2.0009372490708546

Epoch: 6| Step: 5
Training loss: 1.5956685543060303
Validation loss: 2.0117428033582625

Epoch: 6| Step: 6
Training loss: 1.389500379562378
Validation loss: 2.024912800840152

Epoch: 6| Step: 7
Training loss: 1.9103771448135376
Validation loss: 2.055008439607518

Epoch: 6| Step: 8
Training loss: 1.0690374374389648
Validation loss: 2.0671441247386317

Epoch: 6| Step: 9
Training loss: 1.58573579788208
Validation loss: 2.0296646113036783

Epoch: 6| Step: 10
Training loss: 1.9516316652297974
Validation loss: 2.042262291395536

Epoch: 6| Step: 11
Training loss: 1.8502259254455566
Validation loss: 2.0233204646777083

Epoch: 6| Step: 12
Training loss: 1.79754638671875
Validation loss: 2.0088406032131565

Epoch: 6| Step: 13
Training loss: 1.9043279886245728
Validation loss: 2.0027203277875016

Epoch: 213| Step: 0
Training loss: 0.9054273366928101
Validation loss: 1.9896928469340007

Epoch: 6| Step: 1
Training loss: 2.0543088912963867
Validation loss: 2.0125315830271733

Epoch: 6| Step: 2
Training loss: 1.1806490421295166
Validation loss: 2.0083998710878435

Epoch: 6| Step: 3
Training loss: 1.7852166891098022
Validation loss: 2.0050512283079085

Epoch: 6| Step: 4
Training loss: 1.534839391708374
Validation loss: 2.038992029364391

Epoch: 6| Step: 5
Training loss: 1.9586801528930664
Validation loss: 2.0405301483728553

Epoch: 6| Step: 6
Training loss: 1.7025090456008911
Validation loss: 2.036290996818132

Epoch: 6| Step: 7
Training loss: 2.2016072273254395
Validation loss: 2.0264940133658786

Epoch: 6| Step: 8
Training loss: 1.7248880863189697
Validation loss: 2.0388020879478863

Epoch: 6| Step: 9
Training loss: 1.1380420923233032
Validation loss: 2.043994603618499

Epoch: 6| Step: 10
Training loss: 1.7794302701950073
Validation loss: 2.0215056698809386

Epoch: 6| Step: 11
Training loss: 1.6431409120559692
Validation loss: 2.0222128463047806

Epoch: 6| Step: 12
Training loss: 1.9586944580078125
Validation loss: 2.0214392844066826

Epoch: 6| Step: 13
Training loss: 1.5279574394226074
Validation loss: 2.017252118356766

Epoch: 214| Step: 0
Training loss: 0.6676544547080994
Validation loss: 1.9996018422547208

Epoch: 6| Step: 1
Training loss: 1.3249326944351196
Validation loss: 1.9891405643955353

Epoch: 6| Step: 2
Training loss: 1.6889393329620361
Validation loss: 1.9787016889100433

Epoch: 6| Step: 3
Training loss: 1.873058557510376
Validation loss: 1.969480719617618

Epoch: 6| Step: 4
Training loss: 2.0304243564605713
Validation loss: 1.975597886629002

Epoch: 6| Step: 5
Training loss: 1.9987857341766357
Validation loss: 1.9825164784667313

Epoch: 6| Step: 6
Training loss: 1.5949617624282837
Validation loss: 2.017938006308771

Epoch: 6| Step: 7
Training loss: 1.2616064548492432
Validation loss: 2.0402916528845347

Epoch: 6| Step: 8
Training loss: 1.7879862785339355
Validation loss: 2.0613967334070513

Epoch: 6| Step: 9
Training loss: 1.629806399345398
Validation loss: 2.0475784501721783

Epoch: 6| Step: 10
Training loss: 1.735946536064148
Validation loss: 2.034479482199556

Epoch: 6| Step: 11
Training loss: 1.4656668901443481
Validation loss: 2.0128423142176803

Epoch: 6| Step: 12
Training loss: 1.8837260007858276
Validation loss: 2.0017053670780633

Epoch: 6| Step: 13
Training loss: 2.4751386642456055
Validation loss: 2.0119474139264835

Epoch: 215| Step: 0
Training loss: 1.3887332677841187
Validation loss: 2.026223503133302

Epoch: 6| Step: 1
Training loss: 2.1173765659332275
Validation loss: 2.027221361796061

Epoch: 6| Step: 2
Training loss: 1.523651361465454
Validation loss: 2.0381920709404895

Epoch: 6| Step: 3
Training loss: 2.6632332801818848
Validation loss: 2.0483441737390335

Epoch: 6| Step: 4
Training loss: 1.191271185874939
Validation loss: 2.0686044398174492

Epoch: 6| Step: 5
Training loss: 1.9463741779327393
Validation loss: 2.0697372292959564

Epoch: 6| Step: 6
Training loss: 1.344797968864441
Validation loss: 2.05435767737768

Epoch: 6| Step: 7
Training loss: 1.9573990106582642
Validation loss: 2.0464770140186435

Epoch: 6| Step: 8
Training loss: 1.292122721672058
Validation loss: 2.0402636528015137

Epoch: 6| Step: 9
Training loss: 1.646162748336792
Validation loss: 2.0251059096346617

Epoch: 6| Step: 10
Training loss: 1.6125421524047852
Validation loss: 2.017084055049445

Epoch: 6| Step: 11
Training loss: 1.3064119815826416
Validation loss: 2.00254084474297

Epoch: 6| Step: 12
Training loss: 1.406071662902832
Validation loss: 2.0154403640377905

Epoch: 6| Step: 13
Training loss: 1.8968830108642578
Validation loss: 2.014441672191825

Epoch: 216| Step: 0
Training loss: 1.3036859035491943
Validation loss: 2.032115351769232

Epoch: 6| Step: 1
Training loss: 1.3395519256591797
Validation loss: 2.0403277681719874

Epoch: 6| Step: 2
Training loss: 1.3857840299606323
Validation loss: 2.0669189781271

Epoch: 6| Step: 3
Training loss: 1.9393281936645508
Validation loss: 2.066931031083548

Epoch: 6| Step: 4
Training loss: 2.439779758453369
Validation loss: 2.054417694768598

Epoch: 6| Step: 5
Training loss: 1.198225736618042
Validation loss: 2.0547062966131393

Epoch: 6| Step: 6
Training loss: 1.7937219142913818
Validation loss: 2.024960858847505

Epoch: 6| Step: 7
Training loss: 2.634225845336914
Validation loss: 2.021258774624076

Epoch: 6| Step: 8
Training loss: 1.5505728721618652
Validation loss: 2.0011547970515426

Epoch: 6| Step: 9
Training loss: 1.3432049751281738
Validation loss: 1.9928699065280218

Epoch: 6| Step: 10
Training loss: 1.6186106204986572
Validation loss: 1.9831200709906958

Epoch: 6| Step: 11
Training loss: 1.2521061897277832
Validation loss: 1.9891337784387733

Epoch: 6| Step: 12
Training loss: 1.280686855316162
Validation loss: 2.0035166842963106

Epoch: 6| Step: 13
Training loss: 1.91328763961792
Validation loss: 2.022692245821799

Epoch: 217| Step: 0
Training loss: 1.3965706825256348
Validation loss: 2.064024879086402

Epoch: 6| Step: 1
Training loss: 1.2548673152923584
Validation loss: 2.046819871471774

Epoch: 6| Step: 2
Training loss: 1.9495718479156494
Validation loss: 2.0712717784348356

Epoch: 6| Step: 3
Training loss: 1.9301373958587646
Validation loss: 2.0577289929953952

Epoch: 6| Step: 4
Training loss: 1.6573166847229004
Validation loss: 2.0335658724590013

Epoch: 6| Step: 5
Training loss: 1.547553539276123
Validation loss: 2.024416700486214

Epoch: 6| Step: 6
Training loss: 1.7678024768829346
Validation loss: 2.015335936700144

Epoch: 6| Step: 7
Training loss: 1.5184903144836426
Validation loss: 2.0076115580015284

Epoch: 6| Step: 8
Training loss: 1.5502333641052246
Validation loss: 2.011156693581612

Epoch: 6| Step: 9
Training loss: 1.7876423597335815
Validation loss: 1.9954931838538057

Epoch: 6| Step: 10
Training loss: 1.68238365650177
Validation loss: 1.992158668015593

Epoch: 6| Step: 11
Training loss: 0.9712202548980713
Validation loss: 2.0024347074570192

Epoch: 6| Step: 12
Training loss: 1.5015357732772827
Validation loss: 2.0018460801852647

Epoch: 6| Step: 13
Training loss: 2.4739391803741455
Validation loss: 2.0000967594885055

Epoch: 218| Step: 0
Training loss: 1.1338951587677002
Validation loss: 2.016048046850389

Epoch: 6| Step: 1
Training loss: 1.863621473312378
Validation loss: 2.0151736403024323

Epoch: 6| Step: 2
Training loss: 2.234952926635742
Validation loss: 2.0094580393965527

Epoch: 6| Step: 3
Training loss: 1.7834887504577637
Validation loss: 2.017625521588069

Epoch: 6| Step: 4
Training loss: 1.2152433395385742
Validation loss: 2.0055449290942122

Epoch: 6| Step: 5
Training loss: 2.3810627460479736
Validation loss: 2.0174083914808048

Epoch: 6| Step: 6
Training loss: 1.6781738996505737
Validation loss: 2.0182607481556554

Epoch: 6| Step: 7
Training loss: 1.192469596862793
Validation loss: 1.9998861141102289

Epoch: 6| Step: 8
Training loss: 1.593732237815857
Validation loss: 1.994253109860164

Epoch: 6| Step: 9
Training loss: 1.8298003673553467
Validation loss: 2.0316513507596907

Epoch: 6| Step: 10
Training loss: 1.6434028148651123
Validation loss: 2.0355495586190173

Epoch: 6| Step: 11
Training loss: 1.1885499954223633
Validation loss: 2.0512081820477723

Epoch: 6| Step: 12
Training loss: 0.9851765036582947
Validation loss: 2.061311839729227

Epoch: 6| Step: 13
Training loss: 1.7323087453842163
Validation loss: 2.072692491674936

Epoch: 219| Step: 0
Training loss: 2.000725507736206
Validation loss: 2.0549877292366436

Epoch: 6| Step: 1
Training loss: 1.343008279800415
Validation loss: 2.0476268363255326

Epoch: 6| Step: 2
Training loss: 1.5291931629180908
Validation loss: 2.0429620588979414

Epoch: 6| Step: 3
Training loss: 1.6341735124588013
Validation loss: 2.017852016674575

Epoch: 6| Step: 4
Training loss: 1.7124522924423218
Validation loss: 1.9837071062416158

Epoch: 6| Step: 5
Training loss: 1.81063973903656
Validation loss: 2.0301929122658184

Epoch: 6| Step: 6
Training loss: 1.8183966875076294
Validation loss: 2.0184754889498473

Epoch: 6| Step: 7
Training loss: 1.3397449254989624
Validation loss: 2.006650445281818

Epoch: 6| Step: 8
Training loss: 1.0420622825622559
Validation loss: 2.0194022347850185

Epoch: 6| Step: 9
Training loss: 1.2599084377288818
Validation loss: 2.016849407585718

Epoch: 6| Step: 10
Training loss: 1.0138466358184814
Validation loss: 2.028138309396723

Epoch: 6| Step: 11
Training loss: 2.282383918762207
Validation loss: 2.041303183442803

Epoch: 6| Step: 12
Training loss: 1.7881343364715576
Validation loss: 2.0407209601453555

Epoch: 6| Step: 13
Training loss: 1.5533055067062378
Validation loss: 2.053907363645492

Epoch: 220| Step: 0
Training loss: 1.0720930099487305
Validation loss: 2.011485112610684

Epoch: 6| Step: 1
Training loss: 1.6390506029129028
Validation loss: 2.005633379823418

Epoch: 6| Step: 2
Training loss: 2.3005690574645996
Validation loss: 1.989911953608195

Epoch: 6| Step: 3
Training loss: 0.7203230857849121
Validation loss: 1.9720153167683592

Epoch: 6| Step: 4
Training loss: 1.5135356187820435
Validation loss: 1.9743516983524445

Epoch: 6| Step: 5
Training loss: 1.88872492313385
Validation loss: 1.9685797063253259

Epoch: 6| Step: 6
Training loss: 1.9012584686279297
Validation loss: 1.9747020147180046

Epoch: 6| Step: 7
Training loss: 1.460881233215332
Validation loss: 1.966549611860706

Epoch: 6| Step: 8
Training loss: 1.2825756072998047
Validation loss: 1.9981849270482217

Epoch: 6| Step: 9
Training loss: 1.6875426769256592
Validation loss: 2.021302494951474

Epoch: 6| Step: 10
Training loss: 1.2653977870941162
Validation loss: 2.030228434070464

Epoch: 6| Step: 11
Training loss: 1.8835506439208984
Validation loss: 2.0734542646715717

Epoch: 6| Step: 12
Training loss: 1.0061907768249512
Validation loss: 2.0578991905335458

Epoch: 6| Step: 13
Training loss: 3.3116133213043213
Validation loss: 2.0329921501939014

Epoch: 221| Step: 0
Training loss: 1.0482908487319946
Validation loss: 2.0202420706390054

Epoch: 6| Step: 1
Training loss: 1.7538232803344727
Validation loss: 1.9923634118931268

Epoch: 6| Step: 2
Training loss: 1.7560268640518188
Validation loss: 1.998807441803717

Epoch: 6| Step: 3
Training loss: 1.7087500095367432
Validation loss: 1.9693034592495169

Epoch: 6| Step: 4
Training loss: 1.3008701801300049
Validation loss: 1.9690710331804009

Epoch: 6| Step: 5
Training loss: 0.9602667093276978
Validation loss: 1.9593888405830628

Epoch: 6| Step: 6
Training loss: 1.879045844078064
Validation loss: 1.976700645621105

Epoch: 6| Step: 7
Training loss: 1.7548019886016846
Validation loss: 1.9591458805145756

Epoch: 6| Step: 8
Training loss: 1.6285004615783691
Validation loss: 1.9793833507004606

Epoch: 6| Step: 9
Training loss: 1.6505379676818848
Validation loss: 2.0069429592419694

Epoch: 6| Step: 10
Training loss: 1.4070966243743896
Validation loss: 2.067488729312856

Epoch: 6| Step: 11
Training loss: 2.447140693664551
Validation loss: 2.0448925059328795

Epoch: 6| Step: 12
Training loss: 1.090354323387146
Validation loss: 2.055348683429021

Epoch: 6| Step: 13
Training loss: 1.2575429677963257
Validation loss: 2.0679356898030927

Epoch: 222| Step: 0
Training loss: 2.1433916091918945
Validation loss: 2.102388387085289

Epoch: 6| Step: 1
Training loss: 1.2646982669830322
Validation loss: 2.088476639921947

Epoch: 6| Step: 2
Training loss: 1.7836180925369263
Validation loss: 2.1008656127478487

Epoch: 6| Step: 3
Training loss: 0.9165593981742859
Validation loss: 2.1117456959139917

Epoch: 6| Step: 4
Training loss: 1.8244056701660156
Validation loss: 2.082515137169951

Epoch: 6| Step: 5
Training loss: 1.1318423748016357
Validation loss: 2.0411975742668234

Epoch: 6| Step: 6
Training loss: 1.337973713874817
Validation loss: 2.0514974453115977

Epoch: 6| Step: 7
Training loss: 1.5953844785690308
Validation loss: 2.022951631135838

Epoch: 6| Step: 8
Training loss: 1.8852214813232422
Validation loss: 1.9802024313198623

Epoch: 6| Step: 9
Training loss: 1.431689977645874
Validation loss: 1.9712798198064168

Epoch: 6| Step: 10
Training loss: 1.692590355873108
Validation loss: 1.9510674681714786

Epoch: 6| Step: 11
Training loss: 1.1652348041534424
Validation loss: 1.9637307569544802

Epoch: 6| Step: 12
Training loss: 1.9097988605499268
Validation loss: 1.9727271423544934

Epoch: 6| Step: 13
Training loss: 1.8385941982269287
Validation loss: 1.9819859945645897

Epoch: 223| Step: 0
Training loss: 1.205594539642334
Validation loss: 1.9846454563961233

Epoch: 6| Step: 1
Training loss: 1.9412047863006592
Validation loss: 2.0059643599294845

Epoch: 6| Step: 2
Training loss: 1.4894572496414185
Validation loss: 2.048187768587502

Epoch: 6| Step: 3
Training loss: 1.8933652639389038
Validation loss: 2.036687002387098

Epoch: 6| Step: 4
Training loss: 1.378513216972351
Validation loss: 2.0702549770314205

Epoch: 6| Step: 5
Training loss: 1.7632091045379639
Validation loss: 2.074160119538666

Epoch: 6| Step: 6
Training loss: 1.5181140899658203
Validation loss: 2.035135543474587

Epoch: 6| Step: 7
Training loss: 1.2844138145446777
Validation loss: 2.029943245713429

Epoch: 6| Step: 8
Training loss: 1.635730266571045
Validation loss: 2.0164676225313576

Epoch: 6| Step: 9
Training loss: 1.8220865726470947
Validation loss: 2.0177823266675396

Epoch: 6| Step: 10
Training loss: 1.1020967960357666
Validation loss: 1.9921437591634772

Epoch: 6| Step: 11
Training loss: 1.5650594234466553
Validation loss: 1.9786645135571879

Epoch: 6| Step: 12
Training loss: 1.635729432106018
Validation loss: 1.9782770327342454

Epoch: 6| Step: 13
Training loss: 1.403181552886963
Validation loss: 1.9905893738551805

Epoch: 224| Step: 0
Training loss: 1.426633358001709
Validation loss: 1.9698674781348116

Epoch: 6| Step: 1
Training loss: 1.6719729900360107
Validation loss: 1.9750364980389994

Epoch: 6| Step: 2
Training loss: 1.198641061782837
Validation loss: 1.9728009828957178

Epoch: 6| Step: 3
Training loss: 2.113485813140869
Validation loss: 1.9981352552290885

Epoch: 6| Step: 4
Training loss: 1.8731859922409058
Validation loss: 1.9950483947671869

Epoch: 6| Step: 5
Training loss: 1.9561359882354736
Validation loss: 1.9863874502079462

Epoch: 6| Step: 6
Training loss: 1.7005759477615356
Validation loss: 1.9983165161584013

Epoch: 6| Step: 7
Training loss: 1.362962007522583
Validation loss: 1.9850164190415414

Epoch: 6| Step: 8
Training loss: 1.4025355577468872
Validation loss: 1.9924853065962433

Epoch: 6| Step: 9
Training loss: 0.6958244442939758
Validation loss: 1.9908887186358053

Epoch: 6| Step: 10
Training loss: 0.8510494232177734
Validation loss: 1.9638333141162831

Epoch: 6| Step: 11
Training loss: 2.0374653339385986
Validation loss: 1.9664419389540149

Epoch: 6| Step: 12
Training loss: 1.7275913953781128
Validation loss: 1.970942005034416

Epoch: 6| Step: 13
Training loss: 2.2903342247009277
Validation loss: 1.9975703352241105

Epoch: 225| Step: 0
Training loss: 1.9318795204162598
Validation loss: 2.0163337825447

Epoch: 6| Step: 1
Training loss: 1.7209937572479248
Validation loss: 2.0346976813449653

Epoch: 6| Step: 2
Training loss: 1.9505691528320312
Validation loss: 2.0528987684557514

Epoch: 6| Step: 3
Training loss: 1.2143547534942627
Validation loss: 2.0430603193980392

Epoch: 6| Step: 4
Training loss: 2.0852465629577637
Validation loss: 2.0361668448294363

Epoch: 6| Step: 5
Training loss: 1.5005319118499756
Validation loss: 2.0317689347010788

Epoch: 6| Step: 6
Training loss: 1.2216639518737793
Validation loss: 2.0234621340228665

Epoch: 6| Step: 7
Training loss: 0.9644106030464172
Validation loss: 2.030918464865736

Epoch: 6| Step: 8
Training loss: 1.0952190160751343
Validation loss: 2.015873521886846

Epoch: 6| Step: 9
Training loss: 1.7591674327850342
Validation loss: 2.0105541765048938

Epoch: 6| Step: 10
Training loss: 1.4689502716064453
Validation loss: 2.0253707234577467

Epoch: 6| Step: 11
Training loss: 0.872382402420044
Validation loss: 2.012521056718724

Epoch: 6| Step: 12
Training loss: 1.7726398706436157
Validation loss: 1.9881168296260219

Epoch: 6| Step: 13
Training loss: 2.269364595413208
Validation loss: 1.9770765766020744

Epoch: 226| Step: 0
Training loss: 1.5888564586639404
Validation loss: 1.9910327747303953

Epoch: 6| Step: 1
Training loss: 1.2816665172576904
Validation loss: 1.952304187641349

Epoch: 6| Step: 2
Training loss: 1.9352048635482788
Validation loss: 1.9598240749810332

Epoch: 6| Step: 3
Training loss: 1.2352489233016968
Validation loss: 1.9399503200284895

Epoch: 6| Step: 4
Training loss: 1.799770712852478
Validation loss: 1.9818229688111173

Epoch: 6| Step: 5
Training loss: 1.5928196907043457
Validation loss: 1.9794381062189739

Epoch: 6| Step: 6
Training loss: 1.3625317811965942
Validation loss: 2.017782618922572

Epoch: 6| Step: 7
Training loss: 1.4115395545959473
Validation loss: 2.0398585770719793

Epoch: 6| Step: 8
Training loss: 1.5837739706039429
Validation loss: 2.0374388258944274

Epoch: 6| Step: 9
Training loss: 1.7532413005828857
Validation loss: 2.0372819849239883

Epoch: 6| Step: 10
Training loss: 1.336645245552063
Validation loss: 2.023746730178915

Epoch: 6| Step: 11
Training loss: 0.8600854873657227
Validation loss: 2.0091592688714304

Epoch: 6| Step: 12
Training loss: 2.130718231201172
Validation loss: 2.002759345116154

Epoch: 6| Step: 13
Training loss: 1.8524060249328613
Validation loss: 2.0010169295854467

Epoch: 227| Step: 0
Training loss: 1.3299856185913086
Validation loss: 1.9833116826190744

Epoch: 6| Step: 1
Training loss: 1.5878196954727173
Validation loss: 1.9679412098341091

Epoch: 6| Step: 2
Training loss: 1.9618033170700073
Validation loss: 1.9748563176842147

Epoch: 6| Step: 3
Training loss: 1.4684422016143799
Validation loss: 1.9679649030008624

Epoch: 6| Step: 4
Training loss: 0.7548468112945557
Validation loss: 1.9838013930987286

Epoch: 6| Step: 5
Training loss: 1.7501062154769897
Validation loss: 2.014522135898631

Epoch: 6| Step: 6
Training loss: 1.6028741598129272
Validation loss: 2.0882160086785593

Epoch: 6| Step: 7
Training loss: 1.0476667881011963
Validation loss: 2.073916350641558

Epoch: 6| Step: 8
Training loss: 2.6463592052459717
Validation loss: 2.0827994154345606

Epoch: 6| Step: 9
Training loss: 1.3917293548583984
Validation loss: 2.0679540313700193

Epoch: 6| Step: 10
Training loss: 1.8455047607421875
Validation loss: 2.0639205824944282

Epoch: 6| Step: 11
Training loss: 1.6650032997131348
Validation loss: 2.032981449557889

Epoch: 6| Step: 12
Training loss: 1.23013436794281
Validation loss: 2.030698166098646

Epoch: 6| Step: 13
Training loss: 1.3688969612121582
Validation loss: 1.995342759675877

Epoch: 228| Step: 0
Training loss: 1.7967100143432617
Validation loss: 1.9739837390120312

Epoch: 6| Step: 1
Training loss: 0.941649854183197
Validation loss: 1.965470984417905

Epoch: 6| Step: 2
Training loss: 1.2197844982147217
Validation loss: 1.9516103267669678

Epoch: 6| Step: 3
Training loss: 1.4777929782867432
Validation loss: 1.967489129753523

Epoch: 6| Step: 4
Training loss: 1.695232629776001
Validation loss: 1.9430670943311465

Epoch: 6| Step: 5
Training loss: 1.0143487453460693
Validation loss: 1.9625761367941414

Epoch: 6| Step: 6
Training loss: 2.0333290100097656
Validation loss: 1.982410406553617

Epoch: 6| Step: 7
Training loss: 1.2655246257781982
Validation loss: 2.030745801105294

Epoch: 6| Step: 8
Training loss: 1.6782217025756836
Validation loss: 2.093431585578508

Epoch: 6| Step: 9
Training loss: 1.7226670980453491
Validation loss: 2.1011181595504924

Epoch: 6| Step: 10
Training loss: 1.5529088973999023
Validation loss: 2.1342876329216907

Epoch: 6| Step: 11
Training loss: 1.7615340948104858
Validation loss: 2.1000907523657686

Epoch: 6| Step: 12
Training loss: 1.87712562084198
Validation loss: 2.0447707214663104

Epoch: 6| Step: 13
Training loss: 1.0211292505264282
Validation loss: 2.0286671820507256

Epoch: 229| Step: 0
Training loss: 1.7981185913085938
Validation loss: 1.9975608651356032

Epoch: 6| Step: 1
Training loss: 1.0845650434494019
Validation loss: 1.9676908011077552

Epoch: 6| Step: 2
Training loss: 1.6149258613586426
Validation loss: 1.9622852494639735

Epoch: 6| Step: 3
Training loss: 1.164855718612671
Validation loss: 1.9279535226924445

Epoch: 6| Step: 4
Training loss: 1.2283945083618164
Validation loss: 1.9365109371882614

Epoch: 6| Step: 5
Training loss: 2.1286661624908447
Validation loss: 1.961605074585125

Epoch: 6| Step: 6
Training loss: 1.9717769622802734
Validation loss: 1.9472341178565897

Epoch: 6| Step: 7
Training loss: 1.9755967855453491
Validation loss: 1.968859628964496

Epoch: 6| Step: 8
Training loss: 1.4603209495544434
Validation loss: 2.0018941663926646

Epoch: 6| Step: 9
Training loss: 1.578059196472168
Validation loss: 2.038761326061782

Epoch: 6| Step: 10
Training loss: 1.5737838745117188
Validation loss: 2.0777703728727115

Epoch: 6| Step: 11
Training loss: 1.2642285823822021
Validation loss: 2.0804814177174724

Epoch: 6| Step: 12
Training loss: 1.2617321014404297
Validation loss: 2.0769878164414437

Epoch: 6| Step: 13
Training loss: 0.5482994318008423
Validation loss: 2.0495924667645524

Epoch: 230| Step: 0
Training loss: 2.088352680206299
Validation loss: 2.037692037961816

Epoch: 6| Step: 1
Training loss: 1.4323846101760864
Validation loss: 2.023471715629742

Epoch: 6| Step: 2
Training loss: 1.1716820001602173
Validation loss: 2.012711363454019

Epoch: 6| Step: 3
Training loss: 1.1793113946914673
Validation loss: 1.9634803495099467

Epoch: 6| Step: 4
Training loss: 1.7889935970306396
Validation loss: 1.9485743122716104

Epoch: 6| Step: 5
Training loss: 1.6264857053756714
Validation loss: 1.9463309728971092

Epoch: 6| Step: 6
Training loss: 1.4796637296676636
Validation loss: 1.9569929120361165

Epoch: 6| Step: 7
Training loss: 1.6230006217956543
Validation loss: 1.9321146806081135

Epoch: 6| Step: 8
Training loss: 1.3705873489379883
Validation loss: 1.9765889003712644

Epoch: 6| Step: 9
Training loss: 1.5079622268676758
Validation loss: 1.9774938578246741

Epoch: 6| Step: 10
Training loss: 1.3747591972351074
Validation loss: 2.0113592686191684

Epoch: 6| Step: 11
Training loss: 1.179185152053833
Validation loss: 2.030014236768087

Epoch: 6| Step: 12
Training loss: 1.16610848903656
Validation loss: 2.049213037695936

Epoch: 6| Step: 13
Training loss: 2.5094408988952637
Validation loss: 2.0246619293766637

Epoch: 231| Step: 0
Training loss: 1.3079830408096313
Validation loss: 1.992015654040921

Epoch: 6| Step: 1
Training loss: 2.20986270904541
Validation loss: 1.9943570859970585

Epoch: 6| Step: 2
Training loss: 1.5197200775146484
Validation loss: 1.9862814744313557

Epoch: 6| Step: 3
Training loss: 1.3387055397033691
Validation loss: 1.9611317137236237

Epoch: 6| Step: 4
Training loss: 1.0663137435913086
Validation loss: 1.9782924613644999

Epoch: 6| Step: 5
Training loss: 1.845198631286621
Validation loss: 1.9767238914325673

Epoch: 6| Step: 6
Training loss: 1.579209566116333
Validation loss: 1.9740159998657882

Epoch: 6| Step: 7
Training loss: 2.042875051498413
Validation loss: 1.991213567795292

Epoch: 6| Step: 8
Training loss: 1.3142669200897217
Validation loss: 1.9816584971643263

Epoch: 6| Step: 9
Training loss: 1.7411348819732666
Validation loss: 1.9961300357695548

Epoch: 6| Step: 10
Training loss: 0.8746495842933655
Validation loss: 2.0043771625846944

Epoch: 6| Step: 11
Training loss: 1.5711873769760132
Validation loss: 2.006549959541649

Epoch: 6| Step: 12
Training loss: 0.9440180063247681
Validation loss: 1.99349562070703

Epoch: 6| Step: 13
Training loss: 1.0289101600646973
Validation loss: 2.00372132947368

Epoch: 232| Step: 0
Training loss: 1.5083719491958618
Validation loss: 2.0005699152587564

Epoch: 6| Step: 1
Training loss: 1.716843605041504
Validation loss: 1.9893705088605163

Epoch: 6| Step: 2
Training loss: 0.921754002571106
Validation loss: 1.975671104205552

Epoch: 6| Step: 3
Training loss: 1.936957597732544
Validation loss: 1.9347037935769686

Epoch: 6| Step: 4
Training loss: 1.9916110038757324
Validation loss: 1.936404901166116

Epoch: 6| Step: 5
Training loss: 1.607431173324585
Validation loss: 1.9655053564297256

Epoch: 6| Step: 6
Training loss: 1.478503704071045
Validation loss: 1.9855981219199397

Epoch: 6| Step: 7
Training loss: 1.6657326221466064
Validation loss: 2.0098794685897006

Epoch: 6| Step: 8
Training loss: 1.2392303943634033
Validation loss: 2.0073172328292683

Epoch: 6| Step: 9
Training loss: 1.0947448015213013
Validation loss: 2.031780227538078

Epoch: 6| Step: 10
Training loss: 1.28995943069458
Validation loss: 2.0110697720640447

Epoch: 6| Step: 11
Training loss: 1.369120478630066
Validation loss: 2.013114324180029

Epoch: 6| Step: 12
Training loss: 1.562051773071289
Validation loss: 2.0184807367222284

Epoch: 6| Step: 13
Training loss: 0.9929699301719666
Validation loss: 2.01954920189355

Epoch: 233| Step: 0
Training loss: 1.294568419456482
Validation loss: 2.025728348762758

Epoch: 6| Step: 1
Training loss: 1.9070624113082886
Validation loss: 2.019839257322332

Epoch: 6| Step: 2
Training loss: 1.3331438302993774
Validation loss: 2.0227074520562285

Epoch: 6| Step: 3
Training loss: 1.7207705974578857
Validation loss: 2.017376597209643

Epoch: 6| Step: 4
Training loss: 1.2214351892471313
Validation loss: 2.012362023835541

Epoch: 6| Step: 5
Training loss: 1.704551339149475
Validation loss: 2.018734896054832

Epoch: 6| Step: 6
Training loss: 1.4474737644195557
Validation loss: 2.002500290511757

Epoch: 6| Step: 7
Training loss: 1.2130274772644043
Validation loss: 1.9976460215865925

Epoch: 6| Step: 8
Training loss: 1.4873827695846558
Validation loss: 1.9793700146418747

Epoch: 6| Step: 9
Training loss: 1.1945936679840088
Validation loss: 2.0057385813805366

Epoch: 6| Step: 10
Training loss: 1.1182359457015991
Validation loss: 1.9804977550301501

Epoch: 6| Step: 11
Training loss: 1.8659040927886963
Validation loss: 1.9951493099171629

Epoch: 6| Step: 12
Training loss: 1.394612193107605
Validation loss: 1.9988350406769784

Epoch: 6| Step: 13
Training loss: 1.590138554573059
Validation loss: 2.033496851562172

Epoch: 234| Step: 0
Training loss: 1.5887765884399414
Validation loss: 2.050181068399901

Epoch: 6| Step: 1
Training loss: 1.3179354667663574
Validation loss: 2.0746444976457985

Epoch: 6| Step: 2
Training loss: 1.923876404762268
Validation loss: 2.097229439725158

Epoch: 6| Step: 3
Training loss: 1.1649898290634155
Validation loss: 2.122052449052052

Epoch: 6| Step: 4
Training loss: 1.4624441862106323
Validation loss: 2.075181015076176

Epoch: 6| Step: 5
Training loss: 1.4090837240219116
Validation loss: 2.0516534671988538

Epoch: 6| Step: 6
Training loss: 1.471139669418335
Validation loss: 2.0274773002952657

Epoch: 6| Step: 7
Training loss: 1.1219528913497925
Validation loss: 1.9909442855465798

Epoch: 6| Step: 8
Training loss: 1.677280068397522
Validation loss: 1.9433258759078158

Epoch: 6| Step: 9
Training loss: 1.80880606174469
Validation loss: 1.9688562385497554

Epoch: 6| Step: 10
Training loss: 1.3554084300994873
Validation loss: 1.9826660822796565

Epoch: 6| Step: 11
Training loss: 1.2982592582702637
Validation loss: 1.95056358075911

Epoch: 6| Step: 12
Training loss: 1.1745798587799072
Validation loss: 1.9881279686445832

Epoch: 6| Step: 13
Training loss: 1.9111696481704712
Validation loss: 1.9746283485043434

Epoch: 235| Step: 0
Training loss: 1.5719910860061646
Validation loss: 1.9777539942854194

Epoch: 6| Step: 1
Training loss: 0.8193771839141846
Validation loss: 1.9866730654111473

Epoch: 6| Step: 2
Training loss: 1.898484468460083
Validation loss: 1.978064198647776

Epoch: 6| Step: 3
Training loss: 1.9313392639160156
Validation loss: 1.9756145323476484

Epoch: 6| Step: 4
Training loss: 1.561220645904541
Validation loss: 1.9721697056165306

Epoch: 6| Step: 5
Training loss: 1.0256445407867432
Validation loss: 1.9687298882392146

Epoch: 6| Step: 6
Training loss: 1.0415589809417725
Validation loss: 1.9730750412069342

Epoch: 6| Step: 7
Training loss: 1.1944154500961304
Validation loss: 1.9888669226759224

Epoch: 6| Step: 8
Training loss: 1.4133198261260986
Validation loss: 1.9663008489916403

Epoch: 6| Step: 9
Training loss: 1.1227059364318848
Validation loss: 1.9554764122091315

Epoch: 6| Step: 10
Training loss: 2.02018404006958
Validation loss: 1.960825607340823

Epoch: 6| Step: 11
Training loss: 2.0496785640716553
Validation loss: 1.944320478746968

Epoch: 6| Step: 12
Training loss: 1.4333735704421997
Validation loss: 1.944090045908446

Epoch: 6| Step: 13
Training loss: 0.8475997447967529
Validation loss: 1.95434066044387

Epoch: 236| Step: 0
Training loss: 1.5774441957473755
Validation loss: 1.9920894945821455

Epoch: 6| Step: 1
Training loss: 1.3174924850463867
Validation loss: 1.9979794922695364

Epoch: 6| Step: 2
Training loss: 1.8568772077560425
Validation loss: 2.027306910484068

Epoch: 6| Step: 3
Training loss: 1.250709891319275
Validation loss: 1.9942284527645315

Epoch: 6| Step: 4
Training loss: 1.6952884197235107
Validation loss: 2.014866329008533

Epoch: 6| Step: 5
Training loss: 1.4892151355743408
Validation loss: 2.0198890932144655

Epoch: 6| Step: 6
Training loss: 1.229841947555542
Validation loss: 1.99887175713816

Epoch: 6| Step: 7
Training loss: 1.0351918935775757
Validation loss: 1.9940729756509104

Epoch: 6| Step: 8
Training loss: 1.4009032249450684
Validation loss: 1.9758659267938266

Epoch: 6| Step: 9
Training loss: 1.420289397239685
Validation loss: 1.9362485639510616

Epoch: 6| Step: 10
Training loss: 0.8608900308609009
Validation loss: 1.9669310098053308

Epoch: 6| Step: 11
Training loss: 1.5779118537902832
Validation loss: 1.971477493163078

Epoch: 6| Step: 12
Training loss: 1.6644189357757568
Validation loss: 1.9952825602664743

Epoch: 6| Step: 13
Training loss: 1.6709870100021362
Validation loss: 1.9717381218428254

Epoch: 237| Step: 0
Training loss: 1.0757818222045898
Validation loss: 2.0016025471430954

Epoch: 6| Step: 1
Training loss: 2.1499240398406982
Validation loss: 2.003309260132492

Epoch: 6| Step: 2
Training loss: 1.6313109397888184
Validation loss: 2.0176233822299587

Epoch: 6| Step: 3
Training loss: 1.8667573928833008
Validation loss: 2.022223746904763

Epoch: 6| Step: 4
Training loss: 0.9874813556671143
Validation loss: 2.0270989389829737

Epoch: 6| Step: 5
Training loss: 1.4598608016967773
Validation loss: 2.028919671171455

Epoch: 6| Step: 6
Training loss: 1.7257559299468994
Validation loss: 1.987820412523003

Epoch: 6| Step: 7
Training loss: 0.9730930328369141
Validation loss: 2.000281685142107

Epoch: 6| Step: 8
Training loss: 1.2106170654296875
Validation loss: 1.9820883043350712

Epoch: 6| Step: 9
Training loss: 1.495811104774475
Validation loss: 1.9781148113230222

Epoch: 6| Step: 10
Training loss: 1.4161467552185059
Validation loss: 1.9684631337401688

Epoch: 6| Step: 11
Training loss: 1.0671290159225464
Validation loss: 1.9423173858273415

Epoch: 6| Step: 12
Training loss: 1.54693603515625
Validation loss: 1.9457374977809128

Epoch: 6| Step: 13
Training loss: 1.2964415550231934
Validation loss: 1.9744912885850476

Epoch: 238| Step: 0
Training loss: 1.8600059747695923
Validation loss: 1.9817590739137383

Epoch: 6| Step: 1
Training loss: 1.3432445526123047
Validation loss: 1.9936266009525587

Epoch: 6| Step: 2
Training loss: 0.978927493095398
Validation loss: 2.0412986637443624

Epoch: 6| Step: 3
Training loss: 1.2088751792907715
Validation loss: 2.02825661628477

Epoch: 6| Step: 4
Training loss: 1.255732774734497
Validation loss: 1.9702011474999048

Epoch: 6| Step: 5
Training loss: 0.959905743598938
Validation loss: 1.9676022273237987

Epoch: 6| Step: 6
Training loss: 1.283120036125183
Validation loss: 1.9312646850462882

Epoch: 6| Step: 7
Training loss: 1.5532877445220947
Validation loss: 1.918871279685728

Epoch: 6| Step: 8
Training loss: 1.479632019996643
Validation loss: 1.9181616370395949

Epoch: 6| Step: 9
Training loss: 1.6159285306930542
Validation loss: 1.9139951223968177

Epoch: 6| Step: 10
Training loss: 1.757464051246643
Validation loss: 1.9396062230551114

Epoch: 6| Step: 11
Training loss: 1.4363958835601807
Validation loss: 1.9223915582062097

Epoch: 6| Step: 12
Training loss: 1.395932674407959
Validation loss: 1.9490279254092966

Epoch: 6| Step: 13
Training loss: 1.8056199550628662
Validation loss: 1.9909499537560247

Epoch: 239| Step: 0
Training loss: 1.2864840030670166
Validation loss: 2.016395922630064

Epoch: 6| Step: 1
Training loss: 1.0304574966430664
Validation loss: 2.034131475674209

Epoch: 6| Step: 2
Training loss: 1.2090575695037842
Validation loss: 2.019865502593338

Epoch: 6| Step: 3
Training loss: 1.2579940557479858
Validation loss: 2.053569580918999

Epoch: 6| Step: 4
Training loss: 1.4263362884521484
Validation loss: 2.0604835505126626

Epoch: 6| Step: 5
Training loss: 1.6206477880477905
Validation loss: 2.0449587516887213

Epoch: 6| Step: 6
Training loss: 1.7734317779541016
Validation loss: 2.0249795221513316

Epoch: 6| Step: 7
Training loss: 1.7819381952285767
Validation loss: 2.0067042278987106

Epoch: 6| Step: 8
Training loss: 1.087080955505371
Validation loss: 1.9938525281926638

Epoch: 6| Step: 9
Training loss: 0.859333872795105
Validation loss: 1.986011246199249

Epoch: 6| Step: 10
Training loss: 1.4603960514068604
Validation loss: 1.9877548781774377

Epoch: 6| Step: 11
Training loss: 1.6401760578155518
Validation loss: 1.9824104847446564

Epoch: 6| Step: 12
Training loss: 1.520703911781311
Validation loss: 1.9712319374084473

Epoch: 6| Step: 13
Training loss: 1.855265498161316
Validation loss: 1.967383074504073

Epoch: 240| Step: 0
Training loss: 1.7022204399108887
Validation loss: 1.9424452576585995

Epoch: 6| Step: 1
Training loss: 0.8309895992279053
Validation loss: 1.935772770194597

Epoch: 6| Step: 2
Training loss: 1.5701494216918945
Validation loss: 1.9283531788856751

Epoch: 6| Step: 3
Training loss: 1.4110643863677979
Validation loss: 1.947231799043635

Epoch: 6| Step: 4
Training loss: 1.4590601921081543
Validation loss: 1.9151866705186906

Epoch: 6| Step: 5
Training loss: 1.6964643001556396
Validation loss: 1.9202572594406784

Epoch: 6| Step: 6
Training loss: 1.1982369422912598
Validation loss: 1.9366398678031018

Epoch: 6| Step: 7
Training loss: 1.5621724128723145
Validation loss: 1.929664065760951

Epoch: 6| Step: 8
Training loss: 1.2599601745605469
Validation loss: 1.9274040217040687

Epoch: 6| Step: 9
Training loss: 1.3082176446914673
Validation loss: 1.9311071839383853

Epoch: 6| Step: 10
Training loss: 1.246725082397461
Validation loss: 1.941757071402765

Epoch: 6| Step: 11
Training loss: 1.0212159156799316
Validation loss: 1.9855962773805023

Epoch: 6| Step: 12
Training loss: 1.6086550951004028
Validation loss: 2.0421118684994277

Epoch: 6| Step: 13
Training loss: 2.0827643871307373
Validation loss: 2.0896863475922616

Epoch: 241| Step: 0
Training loss: 1.470954418182373
Validation loss: 2.12145576425778

Epoch: 6| Step: 1
Training loss: 1.4395983219146729
Validation loss: 2.064037520398376

Epoch: 6| Step: 2
Training loss: 1.0297002792358398
Validation loss: 2.0594821232621388

Epoch: 6| Step: 3
Training loss: 1.1306183338165283
Validation loss: 2.0618684279021395

Epoch: 6| Step: 4
Training loss: 1.135256052017212
Validation loss: 2.046280937810098

Epoch: 6| Step: 5
Training loss: 1.409744143486023
Validation loss: 2.033942851968991

Epoch: 6| Step: 6
Training loss: 1.5177772045135498
Validation loss: 2.005221647600974

Epoch: 6| Step: 7
Training loss: 1.8419463634490967
Validation loss: 1.9925008255948302

Epoch: 6| Step: 8
Training loss: 1.7298482656478882
Validation loss: 2.000668775650763

Epoch: 6| Step: 9
Training loss: 1.8225877285003662
Validation loss: 1.9981773809720111

Epoch: 6| Step: 10
Training loss: 0.9563232064247131
Validation loss: 1.988137904033866

Epoch: 6| Step: 11
Training loss: 1.7102789878845215
Validation loss: 1.9739027971862464

Epoch: 6| Step: 12
Training loss: 1.397301197052002
Validation loss: 1.9543856061914915

Epoch: 6| Step: 13
Training loss: 1.4677698612213135
Validation loss: 1.9601861558934695

Epoch: 242| Step: 0
Training loss: 1.2180850505828857
Validation loss: 1.960940275140988

Epoch: 6| Step: 1
Training loss: 0.9273332357406616
Validation loss: 2.0142622634928715

Epoch: 6| Step: 2
Training loss: 1.9244707822799683
Validation loss: 2.006573671935707

Epoch: 6| Step: 3
Training loss: 1.1574325561523438
Validation loss: 2.0162133709076913

Epoch: 6| Step: 4
Training loss: 1.2715299129486084
Validation loss: 1.9922414646353772

Epoch: 6| Step: 5
Training loss: 1.3016653060913086
Validation loss: 1.9751942939655756

Epoch: 6| Step: 6
Training loss: 1.4699933528900146
Validation loss: 1.959861070879044

Epoch: 6| Step: 7
Training loss: 1.1195265054702759
Validation loss: 1.9593359347312682

Epoch: 6| Step: 8
Training loss: 1.5365111827850342
Validation loss: 1.9849607675306258

Epoch: 6| Step: 9
Training loss: 1.4144299030303955
Validation loss: 1.9629608020987561

Epoch: 6| Step: 10
Training loss: 1.2160141468048096
Validation loss: 1.958245877296694

Epoch: 6| Step: 11
Training loss: 2.2929458618164062
Validation loss: 1.9496742320317093

Epoch: 6| Step: 12
Training loss: 1.3663657903671265
Validation loss: 1.9553711081063876

Epoch: 6| Step: 13
Training loss: 1.3467720746994019
Validation loss: 1.9907902415080736

Epoch: 243| Step: 0
Training loss: 1.3434277772903442
Validation loss: 1.9746280254856232

Epoch: 6| Step: 1
Training loss: 1.2823052406311035
Validation loss: 1.9827399023117558

Epoch: 6| Step: 2
Training loss: 1.191723108291626
Validation loss: 2.0157435581248295

Epoch: 6| Step: 3
Training loss: 1.849062442779541
Validation loss: 2.060886211292718

Epoch: 6| Step: 4
Training loss: 1.3899497985839844
Validation loss: 2.0549924706899994

Epoch: 6| Step: 5
Training loss: 1.9140957593917847
Validation loss: 2.054374582024031

Epoch: 6| Step: 6
Training loss: 0.9975971579551697
Validation loss: 2.055600300911934

Epoch: 6| Step: 7
Training loss: 0.829021692276001
Validation loss: 2.0045059855266283

Epoch: 6| Step: 8
Training loss: 1.0766379833221436
Validation loss: 1.9845916519882858

Epoch: 6| Step: 9
Training loss: 1.4101219177246094
Validation loss: 1.9564720930591706

Epoch: 6| Step: 10
Training loss: 1.6991714239120483
Validation loss: 1.9496865887795725

Epoch: 6| Step: 11
Training loss: 1.104217529296875
Validation loss: 1.9476663502313758

Epoch: 6| Step: 12
Training loss: 2.070080280303955
Validation loss: 1.959218204662364

Epoch: 6| Step: 13
Training loss: 1.3596069812774658
Validation loss: 1.958212931950887

Epoch: 244| Step: 0
Training loss: 1.456554651260376
Validation loss: 1.9908497871891144

Epoch: 6| Step: 1
Training loss: 1.47444486618042
Validation loss: 2.0080683487717823

Epoch: 6| Step: 2
Training loss: 1.1474952697753906
Validation loss: 2.013831950003101

Epoch: 6| Step: 3
Training loss: 1.7628159523010254
Validation loss: 2.0317675272623696

Epoch: 6| Step: 4
Training loss: 1.793761968612671
Validation loss: 2.0253604535133607

Epoch: 6| Step: 5
Training loss: 1.069037675857544
Validation loss: 2.051945688903973

Epoch: 6| Step: 6
Training loss: 0.8995568752288818
Validation loss: 2.02910517620784

Epoch: 6| Step: 7
Training loss: 1.7416448593139648
Validation loss: 2.008307901761865

Epoch: 6| Step: 8
Training loss: 1.4895968437194824
Validation loss: 1.9880046101026638

Epoch: 6| Step: 9
Training loss: 1.706766128540039
Validation loss: 1.9680837815807712

Epoch: 6| Step: 10
Training loss: 1.1966255903244019
Validation loss: 1.9770431992828206

Epoch: 6| Step: 11
Training loss: 1.1929446458816528
Validation loss: 1.9704791448449577

Epoch: 6| Step: 12
Training loss: 1.1983972787857056
Validation loss: 1.9696625996661443

Epoch: 6| Step: 13
Training loss: 1.090767741203308
Validation loss: 1.9809892075036162

Epoch: 245| Step: 0
Training loss: 1.583608627319336
Validation loss: 1.9742943727841942

Epoch: 6| Step: 1
Training loss: 1.4520325660705566
Validation loss: 1.9580445199884393

Epoch: 6| Step: 2
Training loss: 1.3469313383102417
Validation loss: 1.9602062343269266

Epoch: 6| Step: 3
Training loss: 1.25816011428833
Validation loss: 2.001130780866069

Epoch: 6| Step: 4
Training loss: 1.3366830348968506
Validation loss: 2.008610697202785

Epoch: 6| Step: 5
Training loss: 1.052328109741211
Validation loss: 2.0401334096026678

Epoch: 6| Step: 6
Training loss: 1.1825380325317383
Validation loss: 2.0297988717274

Epoch: 6| Step: 7
Training loss: 1.1729488372802734
Validation loss: 2.0177888331874723

Epoch: 6| Step: 8
Training loss: 1.774017572402954
Validation loss: 2.013326016805505

Epoch: 6| Step: 9
Training loss: 1.3304814100265503
Validation loss: 1.9974141902821039

Epoch: 6| Step: 10
Training loss: 1.3647058010101318
Validation loss: 1.9665514448637604

Epoch: 6| Step: 11
Training loss: 0.6613259315490723
Validation loss: 2.030453766545942

Epoch: 6| Step: 12
Training loss: 1.5201655626296997
Validation loss: 1.9644009836258427

Epoch: 6| Step: 13
Training loss: 2.108180046081543
Validation loss: 1.995800502838627

Epoch: 246| Step: 0
Training loss: 1.8992865085601807
Validation loss: 1.9873295419959611

Epoch: 6| Step: 1
Training loss: 1.4833807945251465
Validation loss: 1.9804669003332815

Epoch: 6| Step: 2
Training loss: 1.3968080282211304
Validation loss: 1.9857913114691292

Epoch: 6| Step: 3
Training loss: 1.0016887187957764
Validation loss: 1.982955373743529

Epoch: 6| Step: 4
Training loss: 1.3578956127166748
Validation loss: 1.979790308142221

Epoch: 6| Step: 5
Training loss: 1.711916446685791
Validation loss: 1.9512965730441514

Epoch: 6| Step: 6
Training loss: 1.3026372194290161
Validation loss: 1.9699113856079757

Epoch: 6| Step: 7
Training loss: 1.0408213138580322
Validation loss: 1.9462760635601577

Epoch: 6| Step: 8
Training loss: 1.5374723672866821
Validation loss: 1.9804316656563872

Epoch: 6| Step: 9
Training loss: 1.160398244857788
Validation loss: 1.9794693005982267

Epoch: 6| Step: 10
Training loss: 1.0243228673934937
Validation loss: 1.9851292769114177

Epoch: 6| Step: 11
Training loss: 1.014932632446289
Validation loss: 1.995302451554165

Epoch: 6| Step: 12
Training loss: 1.5784988403320312
Validation loss: 2.0187176491624568

Epoch: 6| Step: 13
Training loss: 0.9155714511871338
Validation loss: 2.0245886079726683

Epoch: 247| Step: 0
Training loss: 1.2204176187515259
Validation loss: 2.02985530771235

Epoch: 6| Step: 1
Training loss: 0.8248120546340942
Validation loss: 2.025170276241918

Epoch: 6| Step: 2
Training loss: 1.0127639770507812
Validation loss: 2.0205323375681394

Epoch: 6| Step: 3
Training loss: 1.3313143253326416
Validation loss: 1.968818974751298

Epoch: 6| Step: 4
Training loss: 1.429405927658081
Validation loss: 1.9302765528361003

Epoch: 6| Step: 5
Training loss: 1.9952914714813232
Validation loss: 1.9393530302150275

Epoch: 6| Step: 6
Training loss: 1.0569051504135132
Validation loss: 1.93549390762083

Epoch: 6| Step: 7
Training loss: 1.83540940284729
Validation loss: 1.933006650658064

Epoch: 6| Step: 8
Training loss: 1.129168152809143
Validation loss: 1.9298824648703299

Epoch: 6| Step: 9
Training loss: 1.9644746780395508
Validation loss: 1.9421149569173013

Epoch: 6| Step: 10
Training loss: 1.1811842918395996
Validation loss: 1.948016889633671

Epoch: 6| Step: 11
Training loss: 0.9407498240470886
Validation loss: 1.943374538934359

Epoch: 6| Step: 12
Training loss: 1.5472395420074463
Validation loss: 1.9565513364730343

Epoch: 6| Step: 13
Training loss: 1.0377752780914307
Validation loss: 1.999647540430869

Epoch: 248| Step: 0
Training loss: 1.8090213537216187
Validation loss: 2.0007846175983386

Epoch: 6| Step: 1
Training loss: 1.2441132068634033
Validation loss: 2.0105855234207644

Epoch: 6| Step: 2
Training loss: 1.0471464395523071
Validation loss: 2.007275369859511

Epoch: 6| Step: 3
Training loss: 1.4989053010940552
Validation loss: 1.997192749413111

Epoch: 6| Step: 4
Training loss: 1.255857229232788
Validation loss: 1.9832311368757678

Epoch: 6| Step: 5
Training loss: 1.382144570350647
Validation loss: 1.9596819967351935

Epoch: 6| Step: 6
Training loss: 1.2626659870147705
Validation loss: 1.9701052981038247

Epoch: 6| Step: 7
Training loss: 1.0396772623062134
Validation loss: 1.9600859982993013

Epoch: 6| Step: 8
Training loss: 1.112781286239624
Validation loss: 1.963853624559218

Epoch: 6| Step: 9
Training loss: 1.761436939239502
Validation loss: 1.9858411127521145

Epoch: 6| Step: 10
Training loss: 1.0973987579345703
Validation loss: 2.014311884039192

Epoch: 6| Step: 11
Training loss: 1.3415180444717407
Validation loss: 2.0202745250476304

Epoch: 6| Step: 12
Training loss: 1.2449966669082642
Validation loss: 2.0238263683934368

Epoch: 6| Step: 13
Training loss: 1.5121217966079712
Validation loss: 2.0088836710940123

Epoch: 249| Step: 0
Training loss: 0.9574670791625977
Validation loss: 1.9752862325278662

Epoch: 6| Step: 1
Training loss: 1.3656235933303833
Validation loss: 1.9515057763745707

Epoch: 6| Step: 2
Training loss: 1.632336139678955
Validation loss: 1.980933504719888

Epoch: 6| Step: 3
Training loss: 1.6090812683105469
Validation loss: 1.976922071108254

Epoch: 6| Step: 4
Training loss: 1.338536024093628
Validation loss: 1.9788909778800061

Epoch: 6| Step: 5
Training loss: 1.4350767135620117
Validation loss: 1.9291466371987456

Epoch: 6| Step: 6
Training loss: 1.6900091171264648
Validation loss: 1.9294939156501525

Epoch: 6| Step: 7
Training loss: 0.907393217086792
Validation loss: 1.9130969316728654

Epoch: 6| Step: 8
Training loss: 1.6107590198516846
Validation loss: 1.9333478173901957

Epoch: 6| Step: 9
Training loss: 0.7991143465042114
Validation loss: 1.906346954325194

Epoch: 6| Step: 10
Training loss: 1.838313341140747
Validation loss: 1.8964739256007697

Epoch: 6| Step: 11
Training loss: 0.9495826363563538
Validation loss: 1.9039840031695623

Epoch: 6| Step: 12
Training loss: 1.2304737567901611
Validation loss: 1.8998227555264708

Epoch: 6| Step: 13
Training loss: 0.9223573207855225
Validation loss: 1.8967394739068963

Epoch: 250| Step: 0
Training loss: 0.7362456321716309
Validation loss: 1.9550552650164532

Epoch: 6| Step: 1
Training loss: 1.435334324836731
Validation loss: 1.9432519212845834

Epoch: 6| Step: 2
Training loss: 1.079971432685852
Validation loss: 1.9740437397392847

Epoch: 6| Step: 3
Training loss: 1.7421249151229858
Validation loss: 2.02637440799385

Epoch: 6| Step: 4
Training loss: 1.6729451417922974
Validation loss: 2.0782057956982682

Epoch: 6| Step: 5
Training loss: 1.1979763507843018
Validation loss: 2.0586488721191243

Epoch: 6| Step: 6
Training loss: 0.9535971879959106
Validation loss: 2.0537691654697543

Epoch: 6| Step: 7
Training loss: 1.4626777172088623
Validation loss: 2.0186604658762612

Epoch: 6| Step: 8
Training loss: 1.3902153968811035
Validation loss: 2.007043477027647

Epoch: 6| Step: 9
Training loss: 1.3493800163269043
Validation loss: 2.0103605408822336

Epoch: 6| Step: 10
Training loss: 1.2566297054290771
Validation loss: 2.023630210148391

Epoch: 6| Step: 11
Training loss: 1.4997859001159668
Validation loss: 1.9836515713763494

Epoch: 6| Step: 12
Training loss: 1.7441173791885376
Validation loss: 1.9852828928219375

Epoch: 6| Step: 13
Training loss: 1.139920711517334
Validation loss: 1.9899936773443734

Epoch: 251| Step: 0
Training loss: 1.3695335388183594
Validation loss: 2.0065078376441874

Epoch: 6| Step: 1
Training loss: 1.6154930591583252
Validation loss: 2.000859498977661

Epoch: 6| Step: 2
Training loss: 1.3023065328598022
Validation loss: 2.0208420394569315

Epoch: 6| Step: 3
Training loss: 0.9707962870597839
Validation loss: 2.0072367498951573

Epoch: 6| Step: 4
Training loss: 1.997084140777588
Validation loss: 2.0055333286203365

Epoch: 6| Step: 5
Training loss: 1.4034974575042725
Validation loss: 2.0251744126760833

Epoch: 6| Step: 6
Training loss: 1.0866389274597168
Validation loss: 2.0207464874431653

Epoch: 6| Step: 7
Training loss: 1.3892985582351685
Validation loss: 2.0277197002082743

Epoch: 6| Step: 8
Training loss: 1.367816686630249
Validation loss: 2.051868188765741

Epoch: 6| Step: 9
Training loss: 0.8379806280136108
Validation loss: 2.01592009041899

Epoch: 6| Step: 10
Training loss: 1.5823328495025635
Validation loss: 2.0099839459183397

Epoch: 6| Step: 11
Training loss: 1.5052076578140259
Validation loss: 2.0224984230533725

Epoch: 6| Step: 12
Training loss: 1.1271777153015137
Validation loss: 1.9587157054613995

Epoch: 6| Step: 13
Training loss: 0.6788821220397949
Validation loss: 1.936368074468387

Epoch: 252| Step: 0
Training loss: 1.2296249866485596
Validation loss: 1.93247357491524

Epoch: 6| Step: 1
Training loss: 1.793450117111206
Validation loss: 1.9120526634236819

Epoch: 6| Step: 2
Training loss: 1.0865821838378906
Validation loss: 1.9176786612438899

Epoch: 6| Step: 3
Training loss: 1.4677553176879883
Validation loss: 1.9057106279557752

Epoch: 6| Step: 4
Training loss: 1.8886715173721313
Validation loss: 1.894746441994944

Epoch: 6| Step: 5
Training loss: 1.1849806308746338
Validation loss: 1.9072511452500538

Epoch: 6| Step: 6
Training loss: 1.2774755954742432
Validation loss: 1.9651535198252688

Epoch: 6| Step: 7
Training loss: 1.6292986869812012
Validation loss: 2.0397881743728474

Epoch: 6| Step: 8
Training loss: 1.300592303276062
Validation loss: 2.10702855612642

Epoch: 6| Step: 9
Training loss: 1.1263636350631714
Validation loss: 2.1503220476130003

Epoch: 6| Step: 10
Training loss: 1.439399003982544
Validation loss: 2.1563905362159974

Epoch: 6| Step: 11
Training loss: 1.623181939125061
Validation loss: 2.1483111586622012

Epoch: 6| Step: 12
Training loss: 0.8464429378509521
Validation loss: 2.057782203920426

Epoch: 6| Step: 13
Training loss: 1.7724623680114746
Validation loss: 2.001745699554361

Epoch: 253| Step: 0
Training loss: 1.1172356605529785
Validation loss: 1.9601797826828495

Epoch: 6| Step: 1
Training loss: 2.195516347885132
Validation loss: 1.9547338524172384

Epoch: 6| Step: 2
Training loss: 2.012056589126587
Validation loss: 1.9562469592658422

Epoch: 6| Step: 3
Training loss: 1.1281615495681763
Validation loss: 1.9593170253179406

Epoch: 6| Step: 4
Training loss: 0.9513753652572632
Validation loss: 1.9294142235991776

Epoch: 6| Step: 5
Training loss: 1.4115831851959229
Validation loss: 1.9029493716455275

Epoch: 6| Step: 6
Training loss: 1.468308448791504
Validation loss: 1.916751051461825

Epoch: 6| Step: 7
Training loss: 1.248835563659668
Validation loss: 1.9138292497204197

Epoch: 6| Step: 8
Training loss: 1.0930231809616089
Validation loss: 1.9227527277443999

Epoch: 6| Step: 9
Training loss: 1.7113995552062988
Validation loss: 1.9281544557181738

Epoch: 6| Step: 10
Training loss: 1.233633279800415
Validation loss: 1.9469510252757738

Epoch: 6| Step: 11
Training loss: 1.3081843852996826
Validation loss: 1.9712025837231708

Epoch: 6| Step: 12
Training loss: 1.162257194519043
Validation loss: 1.9919808705647786

Epoch: 6| Step: 13
Training loss: 0.5324134826660156
Validation loss: 2.000595615756127

Epoch: 254| Step: 0
Training loss: 1.2186068296432495
Validation loss: 2.0622362680332635

Epoch: 6| Step: 1
Training loss: 1.662192702293396
Validation loss: 2.122982972411699

Epoch: 6| Step: 2
Training loss: 1.0443694591522217
Validation loss: 2.117823603332684

Epoch: 6| Step: 3
Training loss: 1.0319952964782715
Validation loss: 2.094482498784219

Epoch: 6| Step: 4
Training loss: 1.154600739479065
Validation loss: 2.0587668085610993

Epoch: 6| Step: 5
Training loss: 1.05332612991333
Validation loss: 2.0479963261594056

Epoch: 6| Step: 6
Training loss: 1.5982038974761963
Validation loss: 2.0756201872261624

Epoch: 6| Step: 7
Training loss: 1.657621145248413
Validation loss: 2.03691884650979

Epoch: 6| Step: 8
Training loss: 1.1579625606536865
Validation loss: 2.0150740608092277

Epoch: 6| Step: 9
Training loss: 2.225722312927246
Validation loss: 2.010148104800973

Epoch: 6| Step: 10
Training loss: 1.0163253545761108
Validation loss: 1.9754716452731882

Epoch: 6| Step: 11
Training loss: 1.788700819015503
Validation loss: 1.978339640043115

Epoch: 6| Step: 12
Training loss: 0.689853847026825
Validation loss: 1.977254142043411

Epoch: 6| Step: 13
Training loss: 1.4067890644073486
Validation loss: 1.9807541216573408

Epoch: 255| Step: 0
Training loss: 1.2279319763183594
Validation loss: 1.9616364048373314

Epoch: 6| Step: 1
Training loss: 1.386393666267395
Validation loss: 1.998644587814167

Epoch: 6| Step: 2
Training loss: 0.6583036184310913
Validation loss: 2.027302074176009

Epoch: 6| Step: 3
Training loss: 1.662811040878296
Validation loss: 2.0856859068716727

Epoch: 6| Step: 4
Training loss: 1.4354101419448853
Validation loss: 2.1268884084557973

Epoch: 6| Step: 5
Training loss: 1.7753770351409912
Validation loss: 2.1114008759939544

Epoch: 6| Step: 6
Training loss: 1.3933618068695068
Validation loss: 2.0318408396936234

Epoch: 6| Step: 7
Training loss: 1.1039438247680664
Validation loss: 2.0159170832685245

Epoch: 6| Step: 8
Training loss: 1.7036430835723877
Validation loss: 1.9702762685796267

Epoch: 6| Step: 9
Training loss: 1.5916072130203247
Validation loss: 1.9546497444952688

Epoch: 6| Step: 10
Training loss: 1.1525890827178955
Validation loss: 1.9412127643503168

Epoch: 6| Step: 11
Training loss: 0.7603600025177002
Validation loss: 1.943270076987564

Epoch: 6| Step: 12
Training loss: 1.4606406688690186
Validation loss: 1.9307489882233322

Epoch: 6| Step: 13
Training loss: 1.180173397064209
Validation loss: 1.8959372094882432

Epoch: 256| Step: 0
Training loss: 1.3315277099609375
Validation loss: 1.8973065512154692

Epoch: 6| Step: 1
Training loss: 0.9069236516952515
Validation loss: 1.9010153508955432

Epoch: 6| Step: 2
Training loss: 1.6052323579788208
Validation loss: 1.9050664773551367

Epoch: 6| Step: 3
Training loss: 1.4232161045074463
Validation loss: 1.9201888679176249

Epoch: 6| Step: 4
Training loss: 1.5346500873565674
Validation loss: 1.9753417738022343

Epoch: 6| Step: 5
Training loss: 1.4248460531234741
Validation loss: 1.9865378538767497

Epoch: 6| Step: 6
Training loss: 1.4991787672042847
Validation loss: 1.9942101150430658

Epoch: 6| Step: 7
Training loss: 1.2608096599578857
Validation loss: 1.9826400946545344

Epoch: 6| Step: 8
Training loss: 1.1772745847702026
Validation loss: 1.9846285325224682

Epoch: 6| Step: 9
Training loss: 1.1694691181182861
Validation loss: 2.017478915952867

Epoch: 6| Step: 10
Training loss: 1.0733877420425415
Validation loss: 1.9973180781128586

Epoch: 6| Step: 11
Training loss: 1.4812953472137451
Validation loss: 2.012173714176301

Epoch: 6| Step: 12
Training loss: 1.026731252670288
Validation loss: 1.9895428816477458

Epoch: 6| Step: 13
Training loss: 1.2618086338043213
Validation loss: 1.947991241690933

Epoch: 257| Step: 0
Training loss: 1.5856761932373047
Validation loss: 1.9574388727065055

Epoch: 6| Step: 1
Training loss: 1.5132230520248413
Validation loss: 1.959606606473205

Epoch: 6| Step: 2
Training loss: 1.532109022140503
Validation loss: 1.9419229261336788

Epoch: 6| Step: 3
Training loss: 1.4821958541870117
Validation loss: 1.9167777030698714

Epoch: 6| Step: 4
Training loss: 1.2353445291519165
Validation loss: 1.9464008808135986

Epoch: 6| Step: 5
Training loss: 0.7407712936401367
Validation loss: 1.9656224045702206

Epoch: 6| Step: 6
Training loss: 1.076357126235962
Validation loss: 1.9187462432410127

Epoch: 6| Step: 7
Training loss: 1.3249908685684204
Validation loss: 1.9270132933893511

Epoch: 6| Step: 8
Training loss: 1.4125316143035889
Validation loss: 1.9260564350312757

Epoch: 6| Step: 9
Training loss: 1.344038486480713
Validation loss: 1.9464556312048307

Epoch: 6| Step: 10
Training loss: 0.8341991901397705
Validation loss: 1.9686373356849916

Epoch: 6| Step: 11
Training loss: 1.386502742767334
Validation loss: 1.9707971516475882

Epoch: 6| Step: 12
Training loss: 1.1735169887542725
Validation loss: 1.990601465266238

Epoch: 6| Step: 13
Training loss: 0.9804774522781372
Validation loss: 2.0048217235072965

Epoch: 258| Step: 0
Training loss: 0.7231127023696899
Validation loss: 2.013542886703245

Epoch: 6| Step: 1
Training loss: 1.5360774993896484
Validation loss: 2.0289485326377292

Epoch: 6| Step: 2
Training loss: 1.0317485332489014
Validation loss: 2.004621967192619

Epoch: 6| Step: 3
Training loss: 1.436164140701294
Validation loss: 2.0370075651394424

Epoch: 6| Step: 4
Training loss: 1.6192269325256348
Validation loss: 2.0035800151927496

Epoch: 6| Step: 5
Training loss: 1.472730278968811
Validation loss: 2.01280406982668

Epoch: 6| Step: 6
Training loss: 1.3261373043060303
Validation loss: 2.000110673648055

Epoch: 6| Step: 7
Training loss: 1.328338861465454
Validation loss: 2.0031264828097437

Epoch: 6| Step: 8
Training loss: 1.1102721691131592
Validation loss: 1.983894686545095

Epoch: 6| Step: 9
Training loss: 0.784428596496582
Validation loss: 1.9734337611864972

Epoch: 6| Step: 10
Training loss: 1.144870638847351
Validation loss: 1.9323066562734625

Epoch: 6| Step: 11
Training loss: 1.320633888244629
Validation loss: 1.9202361106872559

Epoch: 6| Step: 12
Training loss: 1.3605008125305176
Validation loss: 1.9130279543579265

Epoch: 6| Step: 13
Training loss: 1.3415589332580566
Validation loss: 1.9048420588175456

Epoch: 259| Step: 0
Training loss: 1.451036810874939
Validation loss: 1.925862112352925

Epoch: 6| Step: 1
Training loss: 1.1566076278686523
Validation loss: 1.9267865239932973

Epoch: 6| Step: 2
Training loss: 0.8858518600463867
Validation loss: 1.9666327968720467

Epoch: 6| Step: 3
Training loss: 1.382222056388855
Validation loss: 1.9545882273745794

Epoch: 6| Step: 4
Training loss: 1.5517792701721191
Validation loss: 1.953084796987554

Epoch: 6| Step: 5
Training loss: 1.773953914642334
Validation loss: 1.946174693363969

Epoch: 6| Step: 6
Training loss: 1.3594073057174683
Validation loss: 1.958991950558078

Epoch: 6| Step: 7
Training loss: 0.9014633893966675
Validation loss: 1.94742202502425

Epoch: 6| Step: 8
Training loss: 1.556010365486145
Validation loss: 1.9438397551095614

Epoch: 6| Step: 9
Training loss: 0.7980070114135742
Validation loss: 1.962275407647574

Epoch: 6| Step: 10
Training loss: 1.2258152961730957
Validation loss: 1.9641165579518964

Epoch: 6| Step: 11
Training loss: 1.244519829750061
Validation loss: 1.9502733458754837

Epoch: 6| Step: 12
Training loss: 0.9799364805221558
Validation loss: 1.9158822849232664

Epoch: 6| Step: 13
Training loss: 0.981342613697052
Validation loss: 1.9310835625535698

Epoch: 260| Step: 0
Training loss: 1.1650307178497314
Validation loss: 1.934620480383596

Epoch: 6| Step: 1
Training loss: 1.3641226291656494
Validation loss: 1.924410948189356

Epoch: 6| Step: 2
Training loss: 0.9322536587715149
Validation loss: 1.9193359151963265

Epoch: 6| Step: 3
Training loss: 1.055911660194397
Validation loss: 1.931732472553048

Epoch: 6| Step: 4
Training loss: 1.5887818336486816
Validation loss: 1.9371578193479968

Epoch: 6| Step: 5
Training loss: 1.2625823020935059
Validation loss: 1.945462344795145

Epoch: 6| Step: 6
Training loss: 1.1303764581680298
Validation loss: 1.9169290809221164

Epoch: 6| Step: 7
Training loss: 1.2217435836791992
Validation loss: 1.9322970759484075

Epoch: 6| Step: 8
Training loss: 1.3342911005020142
Validation loss: 1.9383649505594724

Epoch: 6| Step: 9
Training loss: 1.0548148155212402
Validation loss: 1.9732507608270133

Epoch: 6| Step: 10
Training loss: 1.189170002937317
Validation loss: 2.0285171975371656

Epoch: 6| Step: 11
Training loss: 1.5656392574310303
Validation loss: 2.036181411435527

Epoch: 6| Step: 12
Training loss: 1.311375617980957
Validation loss: 2.0423832977971723

Epoch: 6| Step: 13
Training loss: 1.2698073387145996
Validation loss: 2.0351216921242337

Epoch: 261| Step: 0
Training loss: 1.1156880855560303
Validation loss: 1.996697561715239

Epoch: 6| Step: 1
Training loss: 0.7597736120223999
Validation loss: 2.0274909132270404

Epoch: 6| Step: 2
Training loss: 1.0255136489868164
Validation loss: 2.0171125114604993

Epoch: 6| Step: 3
Training loss: 1.8090088367462158
Validation loss: 2.014709717483931

Epoch: 6| Step: 4
Training loss: 1.7421804666519165
Validation loss: 2.015146827185026

Epoch: 6| Step: 5
Training loss: 1.1529226303100586
Validation loss: 2.005710744088696

Epoch: 6| Step: 6
Training loss: 1.419431209564209
Validation loss: 1.9820121718991188

Epoch: 6| Step: 7
Training loss: 0.8676384091377258
Validation loss: 1.9906509076395342

Epoch: 6| Step: 8
Training loss: 1.054020881652832
Validation loss: 1.9672015661834388

Epoch: 6| Step: 9
Training loss: 1.3577024936676025
Validation loss: 1.9720831430086525

Epoch: 6| Step: 10
Training loss: 1.011452555656433
Validation loss: 1.970366225447706

Epoch: 6| Step: 11
Training loss: 1.0276448726654053
Validation loss: 1.9647571579102547

Epoch: 6| Step: 12
Training loss: 1.5129902362823486
Validation loss: 1.9891677018134826

Epoch: 6| Step: 13
Training loss: 1.5508763790130615
Validation loss: 1.9875787253020911

Epoch: 262| Step: 0
Training loss: 1.5660715103149414
Validation loss: 2.004487206858973

Epoch: 6| Step: 1
Training loss: 1.361189603805542
Validation loss: 1.9917232515991374

Epoch: 6| Step: 2
Training loss: 1.2408223152160645
Validation loss: 1.9724591649988645

Epoch: 6| Step: 3
Training loss: 1.2600741386413574
Validation loss: 1.9377844846376808

Epoch: 6| Step: 4
Training loss: 1.2352122068405151
Validation loss: 1.982265897976455

Epoch: 6| Step: 5
Training loss: 0.8902477025985718
Validation loss: 1.954239317165908

Epoch: 6| Step: 6
Training loss: 1.3860135078430176
Validation loss: 1.9778467121944632

Epoch: 6| Step: 7
Training loss: 1.0825334787368774
Validation loss: 2.0029944399351716

Epoch: 6| Step: 8
Training loss: 1.6493785381317139
Validation loss: 2.0215656180535593

Epoch: 6| Step: 9
Training loss: 0.7668291330337524
Validation loss: 2.0284509402449413

Epoch: 6| Step: 10
Training loss: 1.1389288902282715
Validation loss: 2.044378397285297

Epoch: 6| Step: 11
Training loss: 1.4750421047210693
Validation loss: 2.065444979616391

Epoch: 6| Step: 12
Training loss: 1.6363040208816528
Validation loss: 2.0656049251556396

Epoch: 6| Step: 13
Training loss: 0.6905131340026855
Validation loss: 2.064372088319512

Epoch: 263| Step: 0
Training loss: 1.07181715965271
Validation loss: 2.0531593215081

Epoch: 6| Step: 1
Training loss: 0.3885776400566101
Validation loss: 2.009758021241875

Epoch: 6| Step: 2
Training loss: 1.4979004859924316
Validation loss: 1.9832789718463857

Epoch: 6| Step: 3
Training loss: 1.375220775604248
Validation loss: 1.9587717107547227

Epoch: 6| Step: 4
Training loss: 1.4160456657409668
Validation loss: 1.9586316001030706

Epoch: 6| Step: 5
Training loss: 1.6702982187271118
Validation loss: 1.9166245268237205

Epoch: 6| Step: 6
Training loss: 1.5024704933166504
Validation loss: 1.9469968029247817

Epoch: 6| Step: 7
Training loss: 1.2392373085021973
Validation loss: 1.9240094384839457

Epoch: 6| Step: 8
Training loss: 1.5475480556488037
Validation loss: 1.9763231867103166

Epoch: 6| Step: 9
Training loss: 1.2707741260528564
Validation loss: 1.9833917361433788

Epoch: 6| Step: 10
Training loss: 0.6815624237060547
Validation loss: 2.0099143341023433

Epoch: 6| Step: 11
Training loss: 1.1095569133758545
Validation loss: 1.9754589847339097

Epoch: 6| Step: 12
Training loss: 1.2738935947418213
Validation loss: 1.976313643558051

Epoch: 6| Step: 13
Training loss: 1.5396654605865479
Validation loss: 1.9982744724519792

Epoch: 264| Step: 0
Training loss: 0.9940546751022339
Validation loss: 1.9678259459874963

Epoch: 6| Step: 1
Training loss: 1.991466760635376
Validation loss: 1.9520036840951571

Epoch: 6| Step: 2
Training loss: 1.4647294282913208
Validation loss: 1.9266739558148127

Epoch: 6| Step: 3
Training loss: 1.6155427694320679
Validation loss: 1.9072765829742595

Epoch: 6| Step: 4
Training loss: 1.3527287244796753
Validation loss: 1.9207834966721073

Epoch: 6| Step: 5
Training loss: 1.3016893863677979
Validation loss: 1.9291670399327432

Epoch: 6| Step: 6
Training loss: 0.6543877124786377
Validation loss: 1.9537908108003679

Epoch: 6| Step: 7
Training loss: 1.603372573852539
Validation loss: 1.954516759482763

Epoch: 6| Step: 8
Training loss: 0.8467480540275574
Validation loss: 1.959109442208403

Epoch: 6| Step: 9
Training loss: 1.3977246284484863
Validation loss: 1.9561242095885738

Epoch: 6| Step: 10
Training loss: 0.7541742920875549
Validation loss: 1.998250263993458

Epoch: 6| Step: 11
Training loss: 1.4390969276428223
Validation loss: 1.9835921666955436

Epoch: 6| Step: 12
Training loss: 0.8682569265365601
Validation loss: 1.9620036412310857

Epoch: 6| Step: 13
Training loss: 0.6445735096931458
Validation loss: 2.000219391238305

Epoch: 265| Step: 0
Training loss: 0.9423160552978516
Validation loss: 1.952182380102014

Epoch: 6| Step: 1
Training loss: 1.6312719583511353
Validation loss: 1.9370691904457666

Epoch: 6| Step: 2
Training loss: 1.3668171167373657
Validation loss: 1.9794242587140811

Epoch: 6| Step: 3
Training loss: 1.3262969255447388
Validation loss: 1.9558132874068392

Epoch: 6| Step: 4
Training loss: 1.6243185997009277
Validation loss: 1.9739102163622457

Epoch: 6| Step: 5
Training loss: 1.1901450157165527
Validation loss: 1.9869840350202335

Epoch: 6| Step: 6
Training loss: 1.6114422082901
Validation loss: 2.00380418890266

Epoch: 6| Step: 7
Training loss: 0.7728968262672424
Validation loss: 2.014254696907536

Epoch: 6| Step: 8
Training loss: 1.0064702033996582
Validation loss: 2.042652540309455

Epoch: 6| Step: 9
Training loss: 1.2235102653503418
Validation loss: 2.032577141638725

Epoch: 6| Step: 10
Training loss: 0.804417610168457
Validation loss: 2.028207799439789

Epoch: 6| Step: 11
Training loss: 0.9848449230194092
Validation loss: 2.001500154054293

Epoch: 6| Step: 12
Training loss: 1.6731805801391602
Validation loss: 1.9741742085385066

Epoch: 6| Step: 13
Training loss: 1.0135217905044556
Validation loss: 1.9539965685977732

Epoch: 266| Step: 0
Training loss: 1.2333130836486816
Validation loss: 1.9250151213779245

Epoch: 6| Step: 1
Training loss: 1.1941132545471191
Validation loss: 1.9270127921976068

Epoch: 6| Step: 2
Training loss: 1.4256340265274048
Validation loss: 1.92079544836475

Epoch: 6| Step: 3
Training loss: 1.0616278648376465
Validation loss: 1.900452475393972

Epoch: 6| Step: 4
Training loss: 0.8932130336761475
Validation loss: 1.9438404139652048

Epoch: 6| Step: 5
Training loss: 1.2366352081298828
Validation loss: 1.9683055467503046

Epoch: 6| Step: 6
Training loss: 1.4156148433685303
Validation loss: 1.965456812612472

Epoch: 6| Step: 7
Training loss: 0.8231930732727051
Validation loss: 1.9636005816921112

Epoch: 6| Step: 8
Training loss: 1.4704999923706055
Validation loss: 1.9707397799338064

Epoch: 6| Step: 9
Training loss: 0.9551594257354736
Validation loss: 1.95975257888917

Epoch: 6| Step: 10
Training loss: 1.3473716974258423
Validation loss: 1.9470833655326598

Epoch: 6| Step: 11
Training loss: 1.370247483253479
Validation loss: 1.9613042364838302

Epoch: 6| Step: 12
Training loss: 1.2347726821899414
Validation loss: 1.9298403596365323

Epoch: 6| Step: 13
Training loss: 1.0593667030334473
Validation loss: 1.9454372339351202

Epoch: 267| Step: 0
Training loss: 0.9070286750793457
Validation loss: 1.9157510624136975

Epoch: 6| Step: 1
Training loss: 0.853810727596283
Validation loss: 1.9503330005112516

Epoch: 6| Step: 2
Training loss: 0.8820062875747681
Validation loss: 1.919175140319332

Epoch: 6| Step: 3
Training loss: 1.6578600406646729
Validation loss: 1.9367559571419992

Epoch: 6| Step: 4
Training loss: 1.5907847881317139
Validation loss: 1.9370446371775802

Epoch: 6| Step: 5
Training loss: 1.3911705017089844
Validation loss: 1.9355931679407756

Epoch: 6| Step: 6
Training loss: 0.9760792255401611
Validation loss: 1.9512881463573826

Epoch: 6| Step: 7
Training loss: 1.1470284461975098
Validation loss: 1.9599456723018358

Epoch: 6| Step: 8
Training loss: 1.3259766101837158
Validation loss: 1.960322005774385

Epoch: 6| Step: 9
Training loss: 1.4789156913757324
Validation loss: 1.9358935074139667

Epoch: 6| Step: 10
Training loss: 1.201143503189087
Validation loss: 1.9467583446092502

Epoch: 6| Step: 11
Training loss: 1.0555012226104736
Validation loss: 1.980276442343189

Epoch: 6| Step: 12
Training loss: 1.0155833959579468
Validation loss: 1.9976241127137215

Epoch: 6| Step: 13
Training loss: 1.0237157344818115
Validation loss: 1.9728119219503095

Epoch: 268| Step: 0
Training loss: 1.0717054605484009
Validation loss: 1.979437715263777

Epoch: 6| Step: 1
Training loss: 1.1057970523834229
Validation loss: 1.970537886824659

Epoch: 6| Step: 2
Training loss: 0.8114102482795715
Validation loss: 1.9589698468485186

Epoch: 6| Step: 3
Training loss: 1.5913841724395752
Validation loss: 1.9625723925969933

Epoch: 6| Step: 4
Training loss: 1.1768547296524048
Validation loss: 1.955228623523507

Epoch: 6| Step: 5
Training loss: 1.2392430305480957
Validation loss: 1.980366636348027

Epoch: 6| Step: 6
Training loss: 0.7984715700149536
Validation loss: 1.9719693712008897

Epoch: 6| Step: 7
Training loss: 1.264714002609253
Validation loss: 1.9756788643457557

Epoch: 6| Step: 8
Training loss: 1.615086555480957
Validation loss: 1.9709733365684428

Epoch: 6| Step: 9
Training loss: 0.9702672362327576
Validation loss: 1.9888545274734497

Epoch: 6| Step: 10
Training loss: 1.153843641281128
Validation loss: 1.9783074509712957

Epoch: 6| Step: 11
Training loss: 1.3585753440856934
Validation loss: 1.9440681895902079

Epoch: 6| Step: 12
Training loss: 0.9507765769958496
Validation loss: 1.947547802361109

Epoch: 6| Step: 13
Training loss: 1.5375057458877563
Validation loss: 1.9320354974398048

Epoch: 269| Step: 0
Training loss: 1.3248929977416992
Validation loss: 1.8815785954075475

Epoch: 6| Step: 1
Training loss: 1.0686917304992676
Validation loss: 1.912106413995066

Epoch: 6| Step: 2
Training loss: 1.6026197671890259
Validation loss: 1.9005579717697636

Epoch: 6| Step: 3
Training loss: 1.6155178546905518
Validation loss: 1.8907280045170938

Epoch: 6| Step: 4
Training loss: 1.1835050582885742
Validation loss: 1.8983034908130605

Epoch: 6| Step: 5
Training loss: 1.1180164813995361
Validation loss: 1.8942328409482074

Epoch: 6| Step: 6
Training loss: 0.777141809463501
Validation loss: 1.8836715913588

Epoch: 6| Step: 7
Training loss: 0.7485178709030151
Validation loss: 1.907861541676265

Epoch: 6| Step: 8
Training loss: 0.7283536195755005
Validation loss: 1.921990261282972

Epoch: 6| Step: 9
Training loss: 0.9143646955490112
Validation loss: 1.9658672937782862

Epoch: 6| Step: 10
Training loss: 1.671371579170227
Validation loss: 2.0192948925879692

Epoch: 6| Step: 11
Training loss: 1.5527806282043457
Validation loss: 2.0536332053522908

Epoch: 6| Step: 12
Training loss: 0.8942848443984985
Validation loss: 2.0444411308534685

Epoch: 6| Step: 13
Training loss: 1.7581393718719482
Validation loss: 2.0547194480895996

Epoch: 270| Step: 0
Training loss: 0.9643288850784302
Validation loss: 2.074883122597971

Epoch: 6| Step: 1
Training loss: 0.8836895823478699
Validation loss: 2.0096796199839604

Epoch: 6| Step: 2
Training loss: 0.7817166447639465
Validation loss: 1.9889192478631132

Epoch: 6| Step: 3
Training loss: 0.9115656614303589
Validation loss: 1.99287401476214

Epoch: 6| Step: 4
Training loss: 0.9996886253356934
Validation loss: 1.9870688953707296

Epoch: 6| Step: 5
Training loss: 1.383037805557251
Validation loss: 1.9607782133163945

Epoch: 6| Step: 6
Training loss: 1.3403345346450806
Validation loss: 1.934571413583653

Epoch: 6| Step: 7
Training loss: 1.9651628732681274
Validation loss: 1.9103481308106454

Epoch: 6| Step: 8
Training loss: 1.591747522354126
Validation loss: 1.9156671685557212

Epoch: 6| Step: 9
Training loss: 1.4610545635223389
Validation loss: 1.9076314203200802

Epoch: 6| Step: 10
Training loss: 1.0929547548294067
Validation loss: 1.8905034936884397

Epoch: 6| Step: 11
Training loss: 1.3668352365493774
Validation loss: 1.9176569728441135

Epoch: 6| Step: 12
Training loss: 0.6894797682762146
Validation loss: 1.908370972961508

Epoch: 6| Step: 13
Training loss: 0.8815631866455078
Validation loss: 1.922275747022321

Epoch: 271| Step: 0
Training loss: 1.4423284530639648
Validation loss: 1.9665887548077492

Epoch: 6| Step: 1
Training loss: 1.3451526165008545
Validation loss: 1.9735877026793778

Epoch: 6| Step: 2
Training loss: 1.1443263292312622
Validation loss: 1.972937833878302

Epoch: 6| Step: 3
Training loss: 1.149449110031128
Validation loss: 1.9674745862201979

Epoch: 6| Step: 4
Training loss: 1.347642421722412
Validation loss: 1.9773966881536669

Epoch: 6| Step: 5
Training loss: 1.27780020236969
Validation loss: 1.9682530356991677

Epoch: 6| Step: 6
Training loss: 1.1688907146453857
Validation loss: 1.9724913284342775

Epoch: 6| Step: 7
Training loss: 1.3798670768737793
Validation loss: 1.957721330786264

Epoch: 6| Step: 8
Training loss: 0.9225179553031921
Validation loss: 1.9679454513775405

Epoch: 6| Step: 9
Training loss: 1.05849027633667
Validation loss: 1.962819177617309

Epoch: 6| Step: 10
Training loss: 1.3489747047424316
Validation loss: 1.946553901959491

Epoch: 6| Step: 11
Training loss: 0.5564508438110352
Validation loss: 1.9144381400077575

Epoch: 6| Step: 12
Training loss: 1.2444201707839966
Validation loss: 1.9364223326406171

Epoch: 6| Step: 13
Training loss: 0.6311665773391724
Validation loss: 1.9483740073378368

Epoch: 272| Step: 0
Training loss: 1.6892144680023193
Validation loss: 1.973477404604676

Epoch: 6| Step: 1
Training loss: 1.2923150062561035
Validation loss: 2.007505355342742

Epoch: 6| Step: 2
Training loss: 1.1665582656860352
Validation loss: 2.0265910381911905

Epoch: 6| Step: 3
Training loss: 1.2939646244049072
Validation loss: 2.0404244225512267

Epoch: 6| Step: 4
Training loss: 1.2174748182296753
Validation loss: 2.0140647965092815

Epoch: 6| Step: 5
Training loss: 0.8576328158378601
Validation loss: 1.9925104443744948

Epoch: 6| Step: 6
Training loss: 0.8255681991577148
Validation loss: 1.9461569427162089

Epoch: 6| Step: 7
Training loss: 1.229000210762024
Validation loss: 1.9398699383581839

Epoch: 6| Step: 8
Training loss: 1.204243540763855
Validation loss: 1.9160919791908675

Epoch: 6| Step: 9
Training loss: 0.8801088333129883
Validation loss: 1.9183880757260066

Epoch: 6| Step: 10
Training loss: 1.2404067516326904
Validation loss: 1.921954398514122

Epoch: 6| Step: 11
Training loss: 0.8951339721679688
Validation loss: 1.9077115956173147

Epoch: 6| Step: 12
Training loss: 1.1436805725097656
Validation loss: 1.9363841036314606

Epoch: 6| Step: 13
Training loss: 1.7515760660171509
Validation loss: 1.9528032143910725

Epoch: 273| Step: 0
Training loss: 0.9757879972457886
Validation loss: 1.966962952767649

Epoch: 6| Step: 1
Training loss: 0.7767550945281982
Validation loss: 1.929349433991217

Epoch: 6| Step: 2
Training loss: 1.4441765546798706
Validation loss: 1.9512804900446246

Epoch: 6| Step: 3
Training loss: 0.9574453830718994
Validation loss: 1.9346190665357856

Epoch: 6| Step: 4
Training loss: 1.488997220993042
Validation loss: 1.9500596523284912

Epoch: 6| Step: 5
Training loss: 1.216775894165039
Validation loss: 1.9441122649818339

Epoch: 6| Step: 6
Training loss: 1.1544159650802612
Validation loss: 1.9402247846767466

Epoch: 6| Step: 7
Training loss: 1.540649652481079
Validation loss: 1.9309480779914445

Epoch: 6| Step: 8
Training loss: 1.228652834892273
Validation loss: 1.897173555948401

Epoch: 6| Step: 9
Training loss: 1.056971788406372
Validation loss: 1.8984254367889897

Epoch: 6| Step: 10
Training loss: 1.1932296752929688
Validation loss: 1.890566957894192

Epoch: 6| Step: 11
Training loss: 0.7376834154129028
Validation loss: 1.892921361871945

Epoch: 6| Step: 12
Training loss: 1.1403615474700928
Validation loss: 1.8941714135549401

Epoch: 6| Step: 13
Training loss: 1.2688767910003662
Validation loss: 1.8966908301076582

Epoch: 274| Step: 0
Training loss: 1.3482322692871094
Validation loss: 1.9063349769961448

Epoch: 6| Step: 1
Training loss: 1.2823692560195923
Validation loss: 1.9332231039642005

Epoch: 6| Step: 2
Training loss: 1.4382872581481934
Validation loss: 1.973613190394576

Epoch: 6| Step: 3
Training loss: 0.5043580532073975
Validation loss: 2.007234802810095

Epoch: 6| Step: 4
Training loss: 1.4984543323516846
Validation loss: 2.043460771601687

Epoch: 6| Step: 5
Training loss: 1.3325328826904297
Validation loss: 2.0636628109921693

Epoch: 6| Step: 6
Training loss: 1.6087589263916016
Validation loss: 2.051937355790087

Epoch: 6| Step: 7
Training loss: 0.9424279928207397
Validation loss: 2.059523126130463

Epoch: 6| Step: 8
Training loss: 1.4295400381088257
Validation loss: 1.99538968711771

Epoch: 6| Step: 9
Training loss: 1.1132299900054932
Validation loss: 1.9958159590280184

Epoch: 6| Step: 10
Training loss: 0.730646550655365
Validation loss: 1.9742892032028527

Epoch: 6| Step: 11
Training loss: 0.49782997369766235
Validation loss: 1.9422347840442453

Epoch: 6| Step: 12
Training loss: 1.4432858228683472
Validation loss: 1.943786923603345

Epoch: 6| Step: 13
Training loss: 0.8162857890129089
Validation loss: 1.9195904808659707

Epoch: 275| Step: 0
Training loss: 1.1772568225860596
Validation loss: 1.8939228532134846

Epoch: 6| Step: 1
Training loss: 0.8162912726402283
Validation loss: 1.9085425843474686

Epoch: 6| Step: 2
Training loss: 1.3538155555725098
Validation loss: 1.9209870766567927

Epoch: 6| Step: 3
Training loss: 1.185267448425293
Validation loss: 1.913768147909513

Epoch: 6| Step: 4
Training loss: 0.9468825459480286
Validation loss: 1.9540227715687086

Epoch: 6| Step: 5
Training loss: 1.5796656608581543
Validation loss: 1.9918393217107302

Epoch: 6| Step: 6
Training loss: 1.16652512550354
Validation loss: 1.9990207200409265

Epoch: 6| Step: 7
Training loss: 1.2694110870361328
Validation loss: 2.0553856741997505

Epoch: 6| Step: 8
Training loss: 1.3618793487548828
Validation loss: 1.9944563040169336

Epoch: 6| Step: 9
Training loss: 0.6271153092384338
Validation loss: 1.9714569507106658

Epoch: 6| Step: 10
Training loss: 0.8783857226371765
Validation loss: 1.9342685066243654

Epoch: 6| Step: 11
Training loss: 1.4913944005966187
Validation loss: 1.9166589411356116

Epoch: 6| Step: 12
Training loss: 1.095458984375
Validation loss: 1.9273676974799043

Epoch: 6| Step: 13
Training loss: 1.0057247877120972
Validation loss: 1.9204761148780904

Epoch: 276| Step: 0
Training loss: 1.1334359645843506
Validation loss: 1.9383931390700802

Epoch: 6| Step: 1
Training loss: 1.5304408073425293
Validation loss: 1.9377078817736717

Epoch: 6| Step: 2
Training loss: 1.8541237115859985
Validation loss: 1.9289887066810363

Epoch: 6| Step: 3
Training loss: 1.2535277605056763
Validation loss: 1.9466664868016397

Epoch: 6| Step: 4
Training loss: 0.6957789659500122
Validation loss: 1.9711484601420741

Epoch: 6| Step: 5
Training loss: 1.056896448135376
Validation loss: 1.9653639947214434

Epoch: 6| Step: 6
Training loss: 1.1634202003479004
Validation loss: 1.9941316625123382

Epoch: 6| Step: 7
Training loss: 0.6147583723068237
Validation loss: 1.945993036352178

Epoch: 6| Step: 8
Training loss: 1.6275599002838135
Validation loss: 1.9416936482152631

Epoch: 6| Step: 9
Training loss: 1.059887170791626
Validation loss: 1.9512971396087317

Epoch: 6| Step: 10
Training loss: 0.6848193407058716
Validation loss: 1.9474789916828115

Epoch: 6| Step: 11
Training loss: 1.085123062133789
Validation loss: 1.9990829729264783

Epoch: 6| Step: 12
Training loss: 1.190445899963379
Validation loss: 1.9902153374046407

Epoch: 6| Step: 13
Training loss: 1.5105069875717163
Validation loss: 1.973224550165156

Epoch: 277| Step: 0
Training loss: 0.6944909691810608
Validation loss: 1.9504407413544194

Epoch: 6| Step: 1
Training loss: 1.0372521877288818
Validation loss: 1.9578320390434676

Epoch: 6| Step: 2
Training loss: 0.9308198690414429
Validation loss: 1.9463576911598124

Epoch: 6| Step: 3
Training loss: 1.1767630577087402
Validation loss: 1.927621720939554

Epoch: 6| Step: 4
Training loss: 1.8678314685821533
Validation loss: 1.9434383787134641

Epoch: 6| Step: 5
Training loss: 1.2812261581420898
Validation loss: 1.9272049742360269

Epoch: 6| Step: 6
Training loss: 1.4215677976608276
Validation loss: 1.9172100226084392

Epoch: 6| Step: 7
Training loss: 1.1769092082977295
Validation loss: 1.9381523875780002

Epoch: 6| Step: 8
Training loss: 1.1083018779754639
Validation loss: 1.9451255952158282

Epoch: 6| Step: 9
Training loss: 1.027315616607666
Validation loss: 1.9610385907593595

Epoch: 6| Step: 10
Training loss: 1.301135540008545
Validation loss: 1.9729324310056624

Epoch: 6| Step: 11
Training loss: 1.1393215656280518
Validation loss: 2.026002865965648

Epoch: 6| Step: 12
Training loss: 1.2578308582305908
Validation loss: 2.01414510896129

Epoch: 6| Step: 13
Training loss: 0.6411738991737366
Validation loss: 1.9700712337288806

Epoch: 278| Step: 0
Training loss: 1.1643116474151611
Validation loss: 1.9516622917626494

Epoch: 6| Step: 1
Training loss: 1.1861827373504639
Validation loss: 1.927226915154406

Epoch: 6| Step: 2
Training loss: 0.9707362651824951
Validation loss: 1.9022078488462715

Epoch: 6| Step: 3
Training loss: 1.013685941696167
Validation loss: 1.8891511296713224

Epoch: 6| Step: 4
Training loss: 1.306203842163086
Validation loss: 1.88039703266595

Epoch: 6| Step: 5
Training loss: 0.6670171618461609
Validation loss: 1.8753614656386837

Epoch: 6| Step: 6
Training loss: 1.116563081741333
Validation loss: 1.8700313568115234

Epoch: 6| Step: 7
Training loss: 1.3939499855041504
Validation loss: 1.8912748495737712

Epoch: 6| Step: 8
Training loss: 0.8320143222808838
Validation loss: 1.8947098075702626

Epoch: 6| Step: 9
Training loss: 1.1396710872650146
Validation loss: 1.918555377632059

Epoch: 6| Step: 10
Training loss: 0.7306774854660034
Validation loss: 1.9374194863022014

Epoch: 6| Step: 11
Training loss: 1.1609690189361572
Validation loss: 1.986896296983124

Epoch: 6| Step: 12
Training loss: 1.6356945037841797
Validation loss: 2.0003586366612423

Epoch: 6| Step: 13
Training loss: 1.7377561330795288
Validation loss: 2.028234707411899

Epoch: 279| Step: 0
Training loss: 1.193972110748291
Validation loss: 2.062052252472088

Epoch: 6| Step: 1
Training loss: 0.7436195611953735
Validation loss: 2.061783767515613

Epoch: 6| Step: 2
Training loss: 1.021317720413208
Validation loss: 2.097596892746546

Epoch: 6| Step: 3
Training loss: 1.211108684539795
Validation loss: 2.067700065592284

Epoch: 6| Step: 4
Training loss: 0.9347840547561646
Validation loss: 2.0229311117561917

Epoch: 6| Step: 5
Training loss: 0.6695172786712646
Validation loss: 2.008855935065977

Epoch: 6| Step: 6
Training loss: 1.2504925727844238
Validation loss: 1.968611724915043

Epoch: 6| Step: 7
Training loss: 1.5080976486206055
Validation loss: 1.9427510769136491

Epoch: 6| Step: 8
Training loss: 0.8800632953643799
Validation loss: 1.9227970248909407

Epoch: 6| Step: 9
Training loss: 0.924400806427002
Validation loss: 1.9271525272759058

Epoch: 6| Step: 10
Training loss: 1.57539701461792
Validation loss: 1.9432823145261375

Epoch: 6| Step: 11
Training loss: 1.1777369976043701
Validation loss: 1.933544869064003

Epoch: 6| Step: 12
Training loss: 1.6902997493743896
Validation loss: 1.9513366004472137

Epoch: 6| Step: 13
Training loss: 1.5087578296661377
Validation loss: 1.9590157129431283

Epoch: 280| Step: 0
Training loss: 1.1731719970703125
Validation loss: 1.9211188439399964

Epoch: 6| Step: 1
Training loss: 1.239998698234558
Validation loss: 1.89838663096069

Epoch: 6| Step: 2
Training loss: 0.8974544405937195
Validation loss: 1.868345845130182

Epoch: 6| Step: 3
Training loss: 0.988290548324585
Validation loss: 1.9058805152934084

Epoch: 6| Step: 4
Training loss: 1.2245373725891113
Validation loss: 1.8438114479023924

Epoch: 6| Step: 5
Training loss: 1.3271427154541016
Validation loss: 1.8576266791230889

Epoch: 6| Step: 6
Training loss: 0.7097264528274536
Validation loss: 1.8898641281230475

Epoch: 6| Step: 7
Training loss: 1.2868140935897827
Validation loss: 1.9011151905982726

Epoch: 6| Step: 8
Training loss: 0.89324951171875
Validation loss: 1.8939559728868547

Epoch: 6| Step: 9
Training loss: 1.0523133277893066
Validation loss: 1.889940046495007

Epoch: 6| Step: 10
Training loss: 1.3192579746246338
Validation loss: 1.9423671307102326

Epoch: 6| Step: 11
Training loss: 1.4781696796417236
Validation loss: 1.9243375178306334

Epoch: 6| Step: 12
Training loss: 1.1832951307296753
Validation loss: 1.9446779028061898

Epoch: 6| Step: 13
Training loss: 1.1144344806671143
Validation loss: 1.9728390914137646

Epoch: 281| Step: 0
Training loss: 1.0321547985076904
Validation loss: 2.0113592891282934

Epoch: 6| Step: 1
Training loss: 0.7354991436004639
Validation loss: 2.036053478076894

Epoch: 6| Step: 2
Training loss: 0.721057653427124
Validation loss: 2.0694857233314106

Epoch: 6| Step: 3
Training loss: 1.0864715576171875
Validation loss: 2.0449433788176505

Epoch: 6| Step: 4
Training loss: 1.1648902893066406
Validation loss: 2.0208663158519293

Epoch: 6| Step: 5
Training loss: 1.141242265701294
Validation loss: 2.0151706177701234

Epoch: 6| Step: 6
Training loss: 1.5369755029678345
Validation loss: 2.0213337495762813

Epoch: 6| Step: 7
Training loss: 1.128269910812378
Validation loss: 1.9775372359060472

Epoch: 6| Step: 8
Training loss: 0.8733638525009155
Validation loss: 1.9627792950599425

Epoch: 6| Step: 9
Training loss: 1.4509990215301514
Validation loss: 1.9271696536771712

Epoch: 6| Step: 10
Training loss: 1.0679476261138916
Validation loss: 1.9120754862344393

Epoch: 6| Step: 11
Training loss: 0.8930432796478271
Validation loss: 1.9212128859694286

Epoch: 6| Step: 12
Training loss: 1.494948148727417
Validation loss: 1.9216491522327546

Epoch: 6| Step: 13
Training loss: 1.3515504598617554
Validation loss: 1.9183235219729844

Epoch: 282| Step: 0
Training loss: 1.4444509744644165
Validation loss: 1.9544224457074237

Epoch: 6| Step: 1
Training loss: 1.0656957626342773
Validation loss: 1.9655806864461591

Epoch: 6| Step: 2
Training loss: 1.2482926845550537
Validation loss: 1.987351479068879

Epoch: 6| Step: 3
Training loss: 0.7543948888778687
Validation loss: 1.9789658656684301

Epoch: 6| Step: 4
Training loss: 0.8840603232383728
Validation loss: 1.9693070355282034

Epoch: 6| Step: 5
Training loss: 0.5742908120155334
Validation loss: 1.9599863175422914

Epoch: 6| Step: 6
Training loss: 0.8437710404396057
Validation loss: 1.9459140890388078

Epoch: 6| Step: 7
Training loss: 1.6258082389831543
Validation loss: 1.936360292537238

Epoch: 6| Step: 8
Training loss: 1.25111985206604
Validation loss: 1.900432341842241

Epoch: 6| Step: 9
Training loss: 1.1565300226211548
Validation loss: 1.9083491512524184

Epoch: 6| Step: 10
Training loss: 1.502217411994934
Validation loss: 1.9481090063689857

Epoch: 6| Step: 11
Training loss: 0.8954786658287048
Validation loss: 1.928213506616572

Epoch: 6| Step: 12
Training loss: 1.0752928256988525
Validation loss: 1.9552089321997859

Epoch: 6| Step: 13
Training loss: 1.091601848602295
Validation loss: 1.9680933875422324

Epoch: 283| Step: 0
Training loss: 1.1090540885925293
Validation loss: 1.9649591625377696

Epoch: 6| Step: 1
Training loss: 1.3688607215881348
Validation loss: 1.9639198510877547

Epoch: 6| Step: 2
Training loss: 0.583189070224762
Validation loss: 1.94246591419302

Epoch: 6| Step: 3
Training loss: 0.9491577744483948
Validation loss: 1.9328801888291554

Epoch: 6| Step: 4
Training loss: 0.8979389071464539
Validation loss: 1.9320424333695443

Epoch: 6| Step: 5
Training loss: 1.4124418497085571
Validation loss: 1.9110336649802424

Epoch: 6| Step: 6
Training loss: 1.2505550384521484
Validation loss: 1.8638963930068477

Epoch: 6| Step: 7
Training loss: 1.079627275466919
Validation loss: 1.909826179986359

Epoch: 6| Step: 8
Training loss: 0.874049186706543
Validation loss: 1.8933015177326817

Epoch: 6| Step: 9
Training loss: 1.3834083080291748
Validation loss: 1.8921833525421798

Epoch: 6| Step: 10
Training loss: 1.390243411064148
Validation loss: 1.8912649180299492

Epoch: 6| Step: 11
Training loss: 0.9374260902404785
Validation loss: 1.9180849803391324

Epoch: 6| Step: 12
Training loss: 1.0448718070983887
Validation loss: 1.934593326301985

Epoch: 6| Step: 13
Training loss: 0.3966538608074188
Validation loss: 1.9733783583487234

Epoch: 284| Step: 0
Training loss: 0.6123948097229004
Validation loss: 1.971229899314142

Epoch: 6| Step: 1
Training loss: 1.5401110649108887
Validation loss: 1.9711055242887108

Epoch: 6| Step: 2
Training loss: 1.234096646308899
Validation loss: 1.9975959177940124

Epoch: 6| Step: 3
Training loss: 1.3513224124908447
Validation loss: 1.9543968605738815

Epoch: 6| Step: 4
Training loss: 0.8284027576446533
Validation loss: 1.911663927057738

Epoch: 6| Step: 5
Training loss: 0.9062974452972412
Validation loss: 1.949624664040022

Epoch: 6| Step: 6
Training loss: 1.0829756259918213
Validation loss: 1.9472935571465442

Epoch: 6| Step: 7
Training loss: 0.7176017761230469
Validation loss: 1.9058686123099378

Epoch: 6| Step: 8
Training loss: 1.0255024433135986
Validation loss: 1.933054413846744

Epoch: 6| Step: 9
Training loss: 1.479777216911316
Validation loss: 1.8982955845453406

Epoch: 6| Step: 10
Training loss: 1.4485359191894531
Validation loss: 1.8807050784428914

Epoch: 6| Step: 11
Training loss: 1.1089595556259155
Validation loss: 1.856050750260712

Epoch: 6| Step: 12
Training loss: 0.7657151222229004
Validation loss: 1.8675972595009753

Epoch: 6| Step: 13
Training loss: 0.9634808301925659
Validation loss: 1.8940338344984158

Epoch: 285| Step: 0
Training loss: 0.787316083908081
Validation loss: 1.8976397565616074

Epoch: 6| Step: 1
Training loss: 0.5260031223297119
Validation loss: 1.8967511218081239

Epoch: 6| Step: 2
Training loss: 1.8816996812820435
Validation loss: 1.8920342794028662

Epoch: 6| Step: 3
Training loss: 1.0974148511886597
Validation loss: 1.8948844889158845

Epoch: 6| Step: 4
Training loss: 1.84035325050354
Validation loss: 1.9202845378588604

Epoch: 6| Step: 5
Training loss: 0.9359985589981079
Validation loss: 1.914631853821457

Epoch: 6| Step: 6
Training loss: 1.528916597366333
Validation loss: 1.9187618788852487

Epoch: 6| Step: 7
Training loss: 0.5908584594726562
Validation loss: 1.896233840655255

Epoch: 6| Step: 8
Training loss: 1.7785654067993164
Validation loss: 1.9215356508890789

Epoch: 6| Step: 9
Training loss: 0.7972260117530823
Validation loss: 1.8950286501197404

Epoch: 6| Step: 10
Training loss: 0.9085434079170227
Validation loss: 1.8561555403535084

Epoch: 6| Step: 11
Training loss: 0.6947229504585266
Validation loss: 1.9065824067720802

Epoch: 6| Step: 12
Training loss: 0.8510918617248535
Validation loss: 1.9053909470958095

Epoch: 6| Step: 13
Training loss: 0.8069121837615967
Validation loss: 1.9189826442349343

Epoch: 286| Step: 0
Training loss: 1.3475477695465088
Validation loss: 1.9480123135351366

Epoch: 6| Step: 1
Training loss: 1.074449062347412
Validation loss: 1.9648765479364703

Epoch: 6| Step: 2
Training loss: 0.7476094961166382
Validation loss: 1.95625735739226

Epoch: 6| Step: 3
Training loss: 1.3191041946411133
Validation loss: 2.011481136404058

Epoch: 6| Step: 4
Training loss: 1.1567550897598267
Validation loss: 2.0043258705446796

Epoch: 6| Step: 5
Training loss: 1.16070556640625
Validation loss: 1.9913086852719706

Epoch: 6| Step: 6
Training loss: 1.1489073038101196
Validation loss: 1.9702037226769231

Epoch: 6| Step: 7
Training loss: 0.779853343963623
Validation loss: 1.9582576982436641

Epoch: 6| Step: 8
Training loss: 0.9158881902694702
Validation loss: 1.9232249759858655

Epoch: 6| Step: 9
Training loss: 1.095621943473816
Validation loss: 1.8935112132821033

Epoch: 6| Step: 10
Training loss: 1.2660247087478638
Validation loss: 1.8694592163126955

Epoch: 6| Step: 11
Training loss: 0.9196665287017822
Validation loss: 1.8719400513556697

Epoch: 6| Step: 12
Training loss: 0.8757845163345337
Validation loss: 1.8597932797606274

Epoch: 6| Step: 13
Training loss: 1.2220139503479004
Validation loss: 1.8504518962675525

Epoch: 287| Step: 0
Training loss: 1.3554003238677979
Validation loss: 1.866117731217415

Epoch: 6| Step: 1
Training loss: 1.2258005142211914
Validation loss: 1.8975262154815018

Epoch: 6| Step: 2
Training loss: 0.4378845989704132
Validation loss: 1.9273601232036468

Epoch: 6| Step: 3
Training loss: 1.055225133895874
Validation loss: 1.9660128585753902

Epoch: 6| Step: 4
Training loss: 1.050108790397644
Validation loss: 1.953741617100213

Epoch: 6| Step: 5
Training loss: 1.1449532508850098
Validation loss: 1.9857409359306417

Epoch: 6| Step: 6
Training loss: 1.0519100427627563
Validation loss: 1.9355651319667857

Epoch: 6| Step: 7
Training loss: 1.2559442520141602
Validation loss: 1.9428958149366482

Epoch: 6| Step: 8
Training loss: 1.2139949798583984
Validation loss: 1.8989495449168707

Epoch: 6| Step: 9
Training loss: 0.7963135838508606
Validation loss: 1.9171245412159992

Epoch: 6| Step: 10
Training loss: 1.193881630897522
Validation loss: 1.9112868937112952

Epoch: 6| Step: 11
Training loss: 0.971924901008606
Validation loss: 1.9178887208302815

Epoch: 6| Step: 12
Training loss: 0.9560184478759766
Validation loss: 1.903513575112948

Epoch: 6| Step: 13
Training loss: 1.2487428188323975
Validation loss: 1.9144320257248417

Epoch: 288| Step: 0
Training loss: 0.978607177734375
Validation loss: 1.9017796939419163

Epoch: 6| Step: 1
Training loss: 1.2473905086517334
Validation loss: 1.9599887427463327

Epoch: 6| Step: 2
Training loss: 1.0597084760665894
Validation loss: 1.9481918529797626

Epoch: 6| Step: 3
Training loss: 0.9620945453643799
Validation loss: 1.966006164909691

Epoch: 6| Step: 4
Training loss: 0.8265910148620605
Validation loss: 1.969434791995633

Epoch: 6| Step: 5
Training loss: 0.8559713363647461
Validation loss: 2.0183143000448904

Epoch: 6| Step: 6
Training loss: 1.0850142240524292
Validation loss: 2.0149669826671643

Epoch: 6| Step: 7
Training loss: 0.5825415849685669
Validation loss: 1.993649455808824

Epoch: 6| Step: 8
Training loss: 1.2947988510131836
Validation loss: 1.9479449487501574

Epoch: 6| Step: 9
Training loss: 1.1081867218017578
Validation loss: 1.969663909686509

Epoch: 6| Step: 10
Training loss: 1.0782071352005005
Validation loss: 1.9472804966793265

Epoch: 6| Step: 11
Training loss: 1.2433944940567017
Validation loss: 1.887941196400632

Epoch: 6| Step: 12
Training loss: 1.1191303730010986
Validation loss: 1.9133352746245682

Epoch: 6| Step: 13
Training loss: 1.0140948295593262
Validation loss: 1.9235062932455411

Epoch: 289| Step: 0
Training loss: 1.0592851638793945
Validation loss: 1.899861789518787

Epoch: 6| Step: 1
Training loss: 0.6996948719024658
Validation loss: 1.9018690252816806

Epoch: 6| Step: 2
Training loss: 0.8951172828674316
Validation loss: 1.9073428107846169

Epoch: 6| Step: 3
Training loss: 0.7756854295730591
Validation loss: 1.9085362508732786

Epoch: 6| Step: 4
Training loss: 1.2291680574417114
Validation loss: 1.9089984560525546

Epoch: 6| Step: 5
Training loss: 1.4855666160583496
Validation loss: 1.9257408867600143

Epoch: 6| Step: 6
Training loss: 1.3770232200622559
Validation loss: 1.8992188848474973

Epoch: 6| Step: 7
Training loss: 0.7041062116622925
Validation loss: 1.9299647987529795

Epoch: 6| Step: 8
Training loss: 1.0603969097137451
Validation loss: 1.9357091457613054

Epoch: 6| Step: 9
Training loss: 0.9352932572364807
Validation loss: 1.9438699624871696

Epoch: 6| Step: 10
Training loss: 0.6828793287277222
Validation loss: 1.9138779512015722

Epoch: 6| Step: 11
Training loss: 1.2571063041687012
Validation loss: 1.9414332246267667

Epoch: 6| Step: 12
Training loss: 1.211086392402649
Validation loss: 1.9641087439752394

Epoch: 6| Step: 13
Training loss: 1.2079339027404785
Validation loss: 1.944893349883377

Epoch: 290| Step: 0
Training loss: 0.7325062155723572
Validation loss: 1.9620459541197746

Epoch: 6| Step: 1
Training loss: 1.0136793851852417
Validation loss: 1.9375542850904568

Epoch: 6| Step: 2
Training loss: 0.8893182277679443
Validation loss: 1.8951115505669707

Epoch: 6| Step: 3
Training loss: 1.1933573484420776
Validation loss: 1.8861230445164505

Epoch: 6| Step: 4
Training loss: 1.2107993364334106
Validation loss: 1.8470731704465804

Epoch: 6| Step: 5
Training loss: 1.1135766506195068
Validation loss: 1.8640793831117692

Epoch: 6| Step: 6
Training loss: 0.9737833738327026
Validation loss: 1.854786233235431

Epoch: 6| Step: 7
Training loss: 0.8219711780548096
Validation loss: 1.9107992751623994

Epoch: 6| Step: 8
Training loss: 1.2336511611938477
Validation loss: 1.9361912653010378

Epoch: 6| Step: 9
Training loss: 1.2581666707992554
Validation loss: 1.9551838867125972

Epoch: 6| Step: 10
Training loss: 1.1925029754638672
Validation loss: 1.9719797347181587

Epoch: 6| Step: 11
Training loss: 0.6372848749160767
Validation loss: 1.953411607332127

Epoch: 6| Step: 12
Training loss: 1.1885830163955688
Validation loss: 1.9439283660663071

Epoch: 6| Step: 13
Training loss: 1.0328314304351807
Validation loss: 1.9561923191111574

Epoch: 291| Step: 0
Training loss: 1.1927368640899658
Validation loss: 1.9754273622266707

Epoch: 6| Step: 1
Training loss: 1.0164713859558105
Validation loss: 1.953571581071423

Epoch: 6| Step: 2
Training loss: 1.1702380180358887
Validation loss: 1.9594666752763974

Epoch: 6| Step: 3
Training loss: 1.0007765293121338
Validation loss: 1.9617803558226554

Epoch: 6| Step: 4
Training loss: 0.9504151344299316
Validation loss: 1.9650649870595625

Epoch: 6| Step: 5
Training loss: 1.1653180122375488
Validation loss: 1.986322214526515

Epoch: 6| Step: 6
Training loss: 1.0341254472732544
Validation loss: 1.9624556277387886

Epoch: 6| Step: 7
Training loss: 0.6731997728347778
Validation loss: 1.9545498765924925

Epoch: 6| Step: 8
Training loss: 1.3817585706710815
Validation loss: 1.9423612356185913

Epoch: 6| Step: 9
Training loss: 1.1990114450454712
Validation loss: 1.9268634832033547

Epoch: 6| Step: 10
Training loss: 0.7230793237686157
Validation loss: 1.9409285976040749

Epoch: 6| Step: 11
Training loss: 0.8765638470649719
Validation loss: 1.936861120244508

Epoch: 6| Step: 12
Training loss: 0.9235821962356567
Validation loss: 1.9491491676658712

Epoch: 6| Step: 13
Training loss: 1.375540018081665
Validation loss: 1.9179068931969263

Epoch: 292| Step: 0
Training loss: 0.756142258644104
Validation loss: 1.9131487543864916

Epoch: 6| Step: 1
Training loss: 0.9850118160247803
Validation loss: 1.8901658493985412

Epoch: 6| Step: 2
Training loss: 1.524500846862793
Validation loss: 1.909599595172431

Epoch: 6| Step: 3
Training loss: 1.6419932842254639
Validation loss: 1.9210425089764338

Epoch: 6| Step: 4
Training loss: 1.0631582736968994
Validation loss: 1.9388462599887644

Epoch: 6| Step: 5
Training loss: 0.5996261239051819
Validation loss: 1.933310160072901

Epoch: 6| Step: 6
Training loss: 1.3119893074035645
Validation loss: 1.9344485216243292

Epoch: 6| Step: 7
Training loss: 0.9529299736022949
Validation loss: 1.9490484550435057

Epoch: 6| Step: 8
Training loss: 0.8814120292663574
Validation loss: 1.9258941693972516

Epoch: 6| Step: 9
Training loss: 1.2831436395645142
Validation loss: 1.9063555412395026

Epoch: 6| Step: 10
Training loss: 0.8523452877998352
Validation loss: 1.9110180280541862

Epoch: 6| Step: 11
Training loss: 0.716771125793457
Validation loss: 1.9400639354541738

Epoch: 6| Step: 12
Training loss: 0.8993750214576721
Validation loss: 1.9370780106513732

Epoch: 6| Step: 13
Training loss: 0.8150553703308105
Validation loss: 1.9666259173424012

Epoch: 293| Step: 0
Training loss: 0.9269554615020752
Validation loss: 1.9754400163568475

Epoch: 6| Step: 1
Training loss: 0.8925241231918335
Validation loss: 1.9892383006311232

Epoch: 6| Step: 2
Training loss: 0.8265683650970459
Validation loss: 2.006328526363578

Epoch: 6| Step: 3
Training loss: 0.7630389332771301
Validation loss: 2.00674884293669

Epoch: 6| Step: 4
Training loss: 1.2490737438201904
Validation loss: 1.9730889566483036

Epoch: 6| Step: 5
Training loss: 0.5606334209442139
Validation loss: 1.941069213292932

Epoch: 6| Step: 6
Training loss: 0.8809306621551514
Validation loss: 1.9144577659586424

Epoch: 6| Step: 7
Training loss: 0.7558901309967041
Validation loss: 1.8856066144922727

Epoch: 6| Step: 8
Training loss: 0.5882858037948608
Validation loss: 1.9092700430141982

Epoch: 6| Step: 9
Training loss: 1.4421591758728027
Validation loss: 1.9077135145023305

Epoch: 6| Step: 10
Training loss: 1.2092623710632324
Validation loss: 1.9310184576178109

Epoch: 6| Step: 11
Training loss: 1.5557513236999512
Validation loss: 1.9216416958839662

Epoch: 6| Step: 12
Training loss: 1.1696600914001465
Validation loss: 1.915747042625181

Epoch: 6| Step: 13
Training loss: 1.3668842315673828
Validation loss: 1.9093877448830554

Epoch: 294| Step: 0
Training loss: 0.7249934673309326
Validation loss: 1.9189867306781072

Epoch: 6| Step: 1
Training loss: 0.6243199110031128
Validation loss: 1.9506182414229198

Epoch: 6| Step: 2
Training loss: 1.220565915107727
Validation loss: 1.9434047642574515

Epoch: 6| Step: 3
Training loss: 0.8835331201553345
Validation loss: 1.957865035662087

Epoch: 6| Step: 4
Training loss: 0.8207712769508362
Validation loss: 1.9539543249273812

Epoch: 6| Step: 5
Training loss: 1.2675858736038208
Validation loss: 1.904419666977339

Epoch: 6| Step: 6
Training loss: 1.769554853439331
Validation loss: 1.8907560199819586

Epoch: 6| Step: 7
Training loss: 0.9112769365310669
Validation loss: 1.9286765898427656

Epoch: 6| Step: 8
Training loss: 0.9752715826034546
Validation loss: 1.8899016072673183

Epoch: 6| Step: 9
Training loss: 1.0489802360534668
Validation loss: 1.9016709763516662

Epoch: 6| Step: 10
Training loss: 1.0240228176116943
Validation loss: 1.8631681088478333

Epoch: 6| Step: 11
Training loss: 0.8142467737197876
Validation loss: 1.859188796371542

Epoch: 6| Step: 12
Training loss: 0.6830369234085083
Validation loss: 1.885757407834453

Epoch: 6| Step: 13
Training loss: 1.5826961994171143
Validation loss: 1.9318263479458389

Epoch: 295| Step: 0
Training loss: 0.9159983396530151
Validation loss: 1.9102675876309794

Epoch: 6| Step: 1
Training loss: 0.9788371324539185
Validation loss: 1.9209370690007364

Epoch: 6| Step: 2
Training loss: 1.1819789409637451
Validation loss: 1.8948775722134499

Epoch: 6| Step: 3
Training loss: 1.0021145343780518
Validation loss: 1.8692091690596713

Epoch: 6| Step: 4
Training loss: 0.9076205492019653
Validation loss: 1.8854347980150612

Epoch: 6| Step: 5
Training loss: 1.3502473831176758
Validation loss: 1.8627325091310727

Epoch: 6| Step: 6
Training loss: 0.8671679496765137
Validation loss: 1.9000341212877663

Epoch: 6| Step: 7
Training loss: 1.0420012474060059
Validation loss: 1.8897773565784577

Epoch: 6| Step: 8
Training loss: 0.6603252291679382
Validation loss: 1.9462122712084042

Epoch: 6| Step: 9
Training loss: 0.7994435429573059
Validation loss: 1.9061079089359572

Epoch: 6| Step: 10
Training loss: 1.1326525211334229
Validation loss: 1.9069753846814554

Epoch: 6| Step: 11
Training loss: 1.2564351558685303
Validation loss: 1.9229489821259693

Epoch: 6| Step: 12
Training loss: 0.7067051529884338
Validation loss: 1.9141110399717927

Epoch: 6| Step: 13
Training loss: 1.1748909950256348
Validation loss: 1.907727986253718

Epoch: 296| Step: 0
Training loss: 0.8150374889373779
Validation loss: 1.8687809513461204

Epoch: 6| Step: 1
Training loss: 1.1652523279190063
Validation loss: 1.8816359568667669

Epoch: 6| Step: 2
Training loss: 1.3754925727844238
Validation loss: 1.90826319238191

Epoch: 6| Step: 3
Training loss: 0.9483866095542908
Validation loss: 1.9042730844149025

Epoch: 6| Step: 4
Training loss: 1.1869065761566162
Validation loss: 1.8868241694665724

Epoch: 6| Step: 5
Training loss: 0.9519339203834534
Validation loss: 1.9184816216909757

Epoch: 6| Step: 6
Training loss: 1.022443175315857
Validation loss: 1.9713685384360693

Epoch: 6| Step: 7
Training loss: 1.1020435094833374
Validation loss: 1.9674022159268778

Epoch: 6| Step: 8
Training loss: 0.9635917544364929
Validation loss: 1.9460110613094863

Epoch: 6| Step: 9
Training loss: 0.7129116058349609
Validation loss: 1.9748504751472062

Epoch: 6| Step: 10
Training loss: 0.9637490510940552
Validation loss: 1.9577925128321494

Epoch: 6| Step: 11
Training loss: 0.9988053441047668
Validation loss: 1.9111793912867063

Epoch: 6| Step: 12
Training loss: 0.7357738018035889
Validation loss: 1.900072850206847

Epoch: 6| Step: 13
Training loss: 0.724008321762085
Validation loss: 1.9196449454112718

Epoch: 297| Step: 0
Training loss: 0.8114994764328003
Validation loss: 1.9094885677419684

Epoch: 6| Step: 1
Training loss: 0.9533706903457642
Validation loss: 1.901782504973873

Epoch: 6| Step: 2
Training loss: 1.0846734046936035
Validation loss: 1.9048640112723074

Epoch: 6| Step: 3
Training loss: 1.1983751058578491
Validation loss: 1.9359666224448913

Epoch: 6| Step: 4
Training loss: 1.0129287242889404
Validation loss: 1.9400856623085596

Epoch: 6| Step: 5
Training loss: 1.095639944076538
Validation loss: 1.9172400671948668

Epoch: 6| Step: 6
Training loss: 0.8475192785263062
Validation loss: 1.9238562391650291

Epoch: 6| Step: 7
Training loss: 1.0920829772949219
Validation loss: 1.909809757304448

Epoch: 6| Step: 8
Training loss: 0.8653278350830078
Validation loss: 1.9354859359802739

Epoch: 6| Step: 9
Training loss: 1.0717763900756836
Validation loss: 1.941732141279405

Epoch: 6| Step: 10
Training loss: 0.7546923160552979
Validation loss: 1.927607286360956

Epoch: 6| Step: 11
Training loss: 1.0371137857437134
Validation loss: 1.9398662890157392

Epoch: 6| Step: 12
Training loss: 0.6793578863143921
Validation loss: 1.951590177833393

Epoch: 6| Step: 13
Training loss: 1.218457579612732
Validation loss: 1.9388426350009056

Epoch: 298| Step: 0
Training loss: 0.9415468573570251
Validation loss: 1.9096536251806444

Epoch: 6| Step: 1
Training loss: 0.9770150184631348
Validation loss: 1.9079655255040815

Epoch: 6| Step: 2
Training loss: 1.0297576189041138
Validation loss: 1.930409695512505

Epoch: 6| Step: 3
Training loss: 1.2561215162277222
Validation loss: 1.8921032720996487

Epoch: 6| Step: 4
Training loss: 0.916808009147644
Validation loss: 1.9192544132150628

Epoch: 6| Step: 5
Training loss: 1.2561559677124023
Validation loss: 1.9241457164928477

Epoch: 6| Step: 6
Training loss: 0.9100542068481445
Validation loss: 1.8979062790511756

Epoch: 6| Step: 7
Training loss: 1.079146146774292
Validation loss: 1.8722463295023928

Epoch: 6| Step: 8
Training loss: 1.1068241596221924
Validation loss: 1.8807818171798543

Epoch: 6| Step: 9
Training loss: 0.8598191142082214
Validation loss: 1.8845170082584504

Epoch: 6| Step: 10
Training loss: 0.35758885741233826
Validation loss: 1.884141323386982

Epoch: 6| Step: 11
Training loss: 1.7632884979248047
Validation loss: 1.908356253818799

Epoch: 6| Step: 12
Training loss: 0.6965065002441406
Validation loss: 1.908848270293205

Epoch: 6| Step: 13
Training loss: 0.7620015740394592
Validation loss: 1.9229698514425626

Epoch: 299| Step: 0
Training loss: 0.9540282487869263
Validation loss: 1.947347003926513

Epoch: 6| Step: 1
Training loss: 1.1713709831237793
Validation loss: 1.9455255154640443

Epoch: 6| Step: 2
Training loss: 1.1502535343170166
Validation loss: 1.9716953103260328

Epoch: 6| Step: 3
Training loss: 0.7236900925636292
Validation loss: 1.9770431108372186

Epoch: 6| Step: 4
Training loss: 1.006103754043579
Validation loss: 2.019622487406577

Epoch: 6| Step: 5
Training loss: 0.7402092814445496
Validation loss: 1.9964585714442755

Epoch: 6| Step: 6
Training loss: 1.1376254558563232
Validation loss: 1.9753451142259824

Epoch: 6| Step: 7
Training loss: 0.8927892446517944
Validation loss: 1.9804139855087444

Epoch: 6| Step: 8
Training loss: 1.2008755207061768
Validation loss: 1.9103908756727814

Epoch: 6| Step: 9
Training loss: 0.8976441621780396
Validation loss: 1.9061176571794736

Epoch: 6| Step: 10
Training loss: 0.8709709048271179
Validation loss: 1.8751065525957333

Epoch: 6| Step: 11
Training loss: 0.6404995918273926
Validation loss: 1.8559547931917253

Epoch: 6| Step: 12
Training loss: 1.013398289680481
Validation loss: 1.8548185889438917

Epoch: 6| Step: 13
Training loss: 1.1721367835998535
Validation loss: 1.850748554352791

Epoch: 300| Step: 0
Training loss: 1.177351951599121
Validation loss: 1.8449399458464755

Epoch: 6| Step: 1
Training loss: 0.9380786418914795
Validation loss: 1.9109518604893838

Epoch: 6| Step: 2
Training loss: 1.0108048915863037
Validation loss: 1.9222316049760388

Epoch: 6| Step: 3
Training loss: 1.1403254270553589
Validation loss: 1.9121056756665629

Epoch: 6| Step: 4
Training loss: 1.200756549835205
Validation loss: 1.9470970451190908

Epoch: 6| Step: 5
Training loss: 1.140209436416626
Validation loss: 1.9117390583920222

Epoch: 6| Step: 6
Training loss: 1.1599880456924438
Validation loss: 1.9170046544844104

Epoch: 6| Step: 7
Training loss: 0.80800461769104
Validation loss: 1.8985921336758522

Epoch: 6| Step: 8
Training loss: 0.6506770253181458
Validation loss: 1.91985482938828

Epoch: 6| Step: 9
Training loss: 0.4841599464416504
Validation loss: 1.9283392378078994

Epoch: 6| Step: 10
Training loss: 0.9113920331001282
Validation loss: 1.9691905308795232

Epoch: 6| Step: 11
Training loss: 0.8497353792190552
Validation loss: 1.9557886149293633

Epoch: 6| Step: 12
Training loss: 0.970008373260498
Validation loss: 1.9750808810675016

Epoch: 6| Step: 13
Training loss: 0.9829065799713135
Validation loss: 1.9739411723229192

Epoch: 301| Step: 0
Training loss: 1.0072275400161743
Validation loss: 1.97671635817456

Epoch: 6| Step: 1
Training loss: 1.1048059463500977
Validation loss: 1.9942971775608678

Epoch: 6| Step: 2
Training loss: 1.1890337467193604
Validation loss: 1.9564708304661576

Epoch: 6| Step: 3
Training loss: 0.9045706391334534
Validation loss: 1.9680746498928274

Epoch: 6| Step: 4
Training loss: 0.8828225135803223
Validation loss: 1.9566112987456783

Epoch: 6| Step: 5
Training loss: 0.9071481823921204
Validation loss: 1.9484726921204598

Epoch: 6| Step: 6
Training loss: 1.2151119709014893
Validation loss: 1.934045260952365

Epoch: 6| Step: 7
Training loss: 0.7057920694351196
Validation loss: 1.9172280552566692

Epoch: 6| Step: 8
Training loss: 0.7175093293190002
Validation loss: 1.9154588560904227

Epoch: 6| Step: 9
Training loss: 0.8858714699745178
Validation loss: 1.8871014143830986

Epoch: 6| Step: 10
Training loss: 0.7153468728065491
Validation loss: 1.8818715362138645

Epoch: 6| Step: 11
Training loss: 1.1977823972702026
Validation loss: 1.8380510422491259

Epoch: 6| Step: 12
Training loss: 0.6742169260978699
Validation loss: 1.8769948790150304

Epoch: 6| Step: 13
Training loss: 1.2257919311523438
Validation loss: 1.838968433359618

Epoch: 302| Step: 0
Training loss: 0.4903741478919983
Validation loss: 1.8484031846446376

Epoch: 6| Step: 1
Training loss: 0.9276407957077026
Validation loss: 1.8561426003774006

Epoch: 6| Step: 2
Training loss: 0.64471435546875
Validation loss: 1.8707044662967804

Epoch: 6| Step: 3
Training loss: 0.9412776231765747
Validation loss: 1.8936607248039656

Epoch: 6| Step: 4
Training loss: 0.6106904745101929
Validation loss: 1.8981769597658547

Epoch: 6| Step: 5
Training loss: 0.9236536622047424
Validation loss: 1.9241852221950408

Epoch: 6| Step: 6
Training loss: 0.8210098743438721
Validation loss: 1.8974304224855156

Epoch: 6| Step: 7
Training loss: 0.5913994312286377
Validation loss: 1.8746848003838652

Epoch: 6| Step: 8
Training loss: 1.4922747611999512
Validation loss: 1.857745542321154

Epoch: 6| Step: 9
Training loss: 1.4363105297088623
Validation loss: 1.8980654913892028

Epoch: 6| Step: 10
Training loss: 1.017669439315796
Validation loss: 1.854387621725759

Epoch: 6| Step: 11
Training loss: 1.0920624732971191
Validation loss: 1.8671399239570863

Epoch: 6| Step: 12
Training loss: 0.9079264998435974
Validation loss: 1.853839228230138

Epoch: 6| Step: 13
Training loss: 1.5268514156341553
Validation loss: 1.8765608085099088

Epoch: 303| Step: 0
Training loss: 1.574141025543213
Validation loss: 1.9034538012678905

Epoch: 6| Step: 1
Training loss: 0.827032208442688
Validation loss: 1.9093430093539658

Epoch: 6| Step: 2
Training loss: 1.0480659008026123
Validation loss: 1.9210803867668234

Epoch: 6| Step: 3
Training loss: 1.0660293102264404
Validation loss: 1.9099546888823151

Epoch: 6| Step: 4
Training loss: 1.0356760025024414
Validation loss: 1.926554387615573

Epoch: 6| Step: 5
Training loss: 1.059532880783081
Validation loss: 1.9176919626933273

Epoch: 6| Step: 6
Training loss: 0.775391697883606
Validation loss: 1.8864888196350427

Epoch: 6| Step: 7
Training loss: 0.5882304906845093
Validation loss: 1.901463052277924

Epoch: 6| Step: 8
Training loss: 0.8597826361656189
Validation loss: 1.886849763572857

Epoch: 6| Step: 9
Training loss: 1.073207139968872
Validation loss: 1.917041164572521

Epoch: 6| Step: 10
Training loss: 0.909673810005188
Validation loss: 1.9381983844182824

Epoch: 6| Step: 11
Training loss: 1.08968985080719
Validation loss: 1.9267412334360101

Epoch: 6| Step: 12
Training loss: 0.7982319593429565
Validation loss: 1.920122592679916

Epoch: 6| Step: 13
Training loss: 0.40083038806915283
Validation loss: 1.9036856543633245

Epoch: 304| Step: 0
Training loss: 0.5382874608039856
Validation loss: 1.915135819424865

Epoch: 6| Step: 1
Training loss: 1.1083723306655884
Validation loss: 1.9418944235770934

Epoch: 6| Step: 2
Training loss: 1.2683343887329102
Validation loss: 1.9274112345069967

Epoch: 6| Step: 3
Training loss: 0.692922830581665
Validation loss: 1.944186690033123

Epoch: 6| Step: 4
Training loss: 1.006523847579956
Validation loss: 1.9560406464402393

Epoch: 6| Step: 5
Training loss: 0.8603333830833435
Validation loss: 1.9468282473984586

Epoch: 6| Step: 6
Training loss: 0.7895703911781311
Validation loss: 1.944130128429782

Epoch: 6| Step: 7
Training loss: 0.9611181616783142
Validation loss: 1.9533726053853189

Epoch: 6| Step: 8
Training loss: 0.7843044996261597
Validation loss: 1.9757426579793294

Epoch: 6| Step: 9
Training loss: 0.8417847156524658
Validation loss: 1.9722572680442565

Epoch: 6| Step: 10
Training loss: 1.3744584321975708
Validation loss: 1.944521011844758

Epoch: 6| Step: 11
Training loss: 1.3837147951126099
Validation loss: 1.9159197627857167

Epoch: 6| Step: 12
Training loss: 0.6129205226898193
Validation loss: 1.8861397876534411

Epoch: 6| Step: 13
Training loss: 1.2411235570907593
Validation loss: 1.8494045695950907

Epoch: 305| Step: 0
Training loss: 0.6807276010513306
Validation loss: 1.906809001840571

Epoch: 6| Step: 1
Training loss: 0.9171521663665771
Validation loss: 1.9083804930410078

Epoch: 6| Step: 2
Training loss: 1.132004976272583
Validation loss: 1.933388610039988

Epoch: 6| Step: 3
Training loss: 0.9424828886985779
Validation loss: 1.9072348046046432

Epoch: 6| Step: 4
Training loss: 1.2908529043197632
Validation loss: 1.9305832232198408

Epoch: 6| Step: 5
Training loss: 0.6876648664474487
Validation loss: 1.930030522807952

Epoch: 6| Step: 6
Training loss: 1.1311209201812744
Validation loss: 1.936917810029881

Epoch: 6| Step: 7
Training loss: 0.8059787154197693
Validation loss: 1.9502302215945335

Epoch: 6| Step: 8
Training loss: 1.0494678020477295
Validation loss: 1.9622853289368332

Epoch: 6| Step: 9
Training loss: 0.7978603839874268
Validation loss: 2.0017580165657947

Epoch: 6| Step: 10
Training loss: 1.095900058746338
Validation loss: 1.9689590879665908

Epoch: 6| Step: 11
Training loss: 1.2352936267852783
Validation loss: 1.984447366447859

Epoch: 6| Step: 12
Training loss: 0.5038248300552368
Validation loss: 1.9351629595602713

Epoch: 6| Step: 13
Training loss: 1.1755945682525635
Validation loss: 1.935363592640046

Epoch: 306| Step: 0
Training loss: 0.5123764872550964
Validation loss: 1.9303784267876738

Epoch: 6| Step: 1
Training loss: 0.45656776428222656
Validation loss: 1.925112739686043

Epoch: 6| Step: 2
Training loss: 1.3334014415740967
Validation loss: 1.9226536135519705

Epoch: 6| Step: 3
Training loss: 0.7176927328109741
Validation loss: 1.8976513583173034

Epoch: 6| Step: 4
Training loss: 1.0150399208068848
Validation loss: 1.8755910088939052

Epoch: 6| Step: 5
Training loss: 1.102359414100647
Validation loss: 1.8905162234460153

Epoch: 6| Step: 6
Training loss: 0.7735937833786011
Validation loss: 1.8835339956386115

Epoch: 6| Step: 7
Training loss: 0.5553475022315979
Validation loss: 1.942014689086586

Epoch: 6| Step: 8
Training loss: 0.86628657579422
Validation loss: 1.9622603872770905

Epoch: 6| Step: 9
Training loss: 1.1548664569854736
Validation loss: 1.97875839407726

Epoch: 6| Step: 10
Training loss: 1.4141721725463867
Validation loss: 1.986584912064255

Epoch: 6| Step: 11
Training loss: 1.2716319561004639
Validation loss: 1.9188071271424652

Epoch: 6| Step: 12
Training loss: 0.7290002107620239
Validation loss: 1.8748896634706886

Epoch: 6| Step: 13
Training loss: 1.0866999626159668
Validation loss: 1.86337600984881

Epoch: 307| Step: 0
Training loss: 0.9773833155632019
Validation loss: 1.857599712187244

Epoch: 6| Step: 1
Training loss: 0.8633412718772888
Validation loss: 1.8175962996739212

Epoch: 6| Step: 2
Training loss: 1.0922462940216064
Validation loss: 1.8081007067875197

Epoch: 6| Step: 3
Training loss: 0.9490782022476196
Validation loss: 1.8052785281212098

Epoch: 6| Step: 4
Training loss: 0.8088758587837219
Validation loss: 1.8289339773116573

Epoch: 6| Step: 5
Training loss: 0.9613423347473145
Validation loss: 1.843920418011245

Epoch: 6| Step: 6
Training loss: 0.8253728747367859
Validation loss: 1.8341333725119149

Epoch: 6| Step: 7
Training loss: 1.0229214429855347
Validation loss: 1.830970298859381

Epoch: 6| Step: 8
Training loss: 0.609976053237915
Validation loss: 1.882232883925079

Epoch: 6| Step: 9
Training loss: 0.9777505397796631
Validation loss: 1.9199984842731106

Epoch: 6| Step: 10
Training loss: 1.1071183681488037
Validation loss: 1.9411364255412933

Epoch: 6| Step: 11
Training loss: 0.8122239708900452
Validation loss: 1.9556351374554377

Epoch: 6| Step: 12
Training loss: 1.271062970161438
Validation loss: 1.9427469532976869

Epoch: 6| Step: 13
Training loss: 0.29257932305336
Validation loss: 1.939295511091909

Epoch: 308| Step: 0
Training loss: 0.5844259858131409
Validation loss: 1.887243245237617

Epoch: 6| Step: 1
Training loss: 0.7612500786781311
Validation loss: 1.8501510645753594

Epoch: 6| Step: 2
Training loss: 1.222455620765686
Validation loss: 1.8512810276400657

Epoch: 6| Step: 3
Training loss: 1.4393293857574463
Validation loss: 1.8607172184093024

Epoch: 6| Step: 4
Training loss: 0.6980593204498291
Validation loss: 1.8473451137542725

Epoch: 6| Step: 5
Training loss: 0.9383531212806702
Validation loss: 1.8257511226079797

Epoch: 6| Step: 6
Training loss: 1.164250373840332
Validation loss: 1.8469670805879819

Epoch: 6| Step: 7
Training loss: 0.7495230436325073
Validation loss: 1.8401706295628701

Epoch: 6| Step: 8
Training loss: 1.1789660453796387
Validation loss: 1.847040880110956

Epoch: 6| Step: 9
Training loss: 0.7540953159332275
Validation loss: 1.8683241644213278

Epoch: 6| Step: 10
Training loss: 0.8354159593582153
Validation loss: 1.9166609138570807

Epoch: 6| Step: 11
Training loss: 1.1146700382232666
Validation loss: 1.9139125936774797

Epoch: 6| Step: 12
Training loss: 0.799810528755188
Validation loss: 1.9660376118075462

Epoch: 6| Step: 13
Training loss: 0.8956127166748047
Validation loss: 1.946127046820938

Epoch: 309| Step: 0
Training loss: 1.1308774948120117
Validation loss: 1.9185893112613308

Epoch: 6| Step: 1
Training loss: 1.096649408340454
Validation loss: 1.8986316996236001

Epoch: 6| Step: 2
Training loss: 0.7275940775871277
Validation loss: 1.897574770835138

Epoch: 6| Step: 3
Training loss: 1.0015171766281128
Validation loss: 1.9105577033053163

Epoch: 6| Step: 4
Training loss: 0.801052451133728
Validation loss: 1.9039499067491101

Epoch: 6| Step: 5
Training loss: 0.712401270866394
Validation loss: 1.9048785817238592

Epoch: 6| Step: 6
Training loss: 0.9430844783782959
Validation loss: 1.9071968691323393

Epoch: 6| Step: 7
Training loss: 1.3445805311203003
Validation loss: 1.906050564140402

Epoch: 6| Step: 8
Training loss: 1.104156732559204
Validation loss: 1.9311770739093903

Epoch: 6| Step: 9
Training loss: 0.7876207828521729
Validation loss: 1.9393355615677372

Epoch: 6| Step: 10
Training loss: 0.9342806339263916
Validation loss: 1.9486790164824455

Epoch: 6| Step: 11
Training loss: 0.4599045515060425
Validation loss: 1.9330488289556196

Epoch: 6| Step: 12
Training loss: 0.84852135181427
Validation loss: 1.8921206740922825

Epoch: 6| Step: 13
Training loss: 1.7551226615905762
Validation loss: 1.897127382216915

Epoch: 310| Step: 0
Training loss: 0.7264254093170166
Validation loss: 1.8483033205873223

Epoch: 6| Step: 1
Training loss: 0.841162919998169
Validation loss: 1.8286024280773696

Epoch: 6| Step: 2
Training loss: 1.1032110452651978
Validation loss: 1.7941374765929354

Epoch: 6| Step: 3
Training loss: 1.1420812606811523
Validation loss: 1.807712249858405

Epoch: 6| Step: 4
Training loss: 0.8712354898452759
Validation loss: 1.8314170555401874

Epoch: 6| Step: 5
Training loss: 0.9056673645973206
Validation loss: 1.8372613678696335

Epoch: 6| Step: 6
Training loss: 1.2354199886322021
Validation loss: 1.8416937012826242

Epoch: 6| Step: 7
Training loss: 1.1257983446121216
Validation loss: 1.799809842981318

Epoch: 6| Step: 8
Training loss: 0.7012513875961304
Validation loss: 1.8140968071517123

Epoch: 6| Step: 9
Training loss: 0.6542236804962158
Validation loss: 1.8532096147537231

Epoch: 6| Step: 10
Training loss: 1.2040455341339111
Validation loss: 1.8204654647457985

Epoch: 6| Step: 11
Training loss: 0.9756389260292053
Validation loss: 1.867373211409456

Epoch: 6| Step: 12
Training loss: 0.663407027721405
Validation loss: 1.865950753611903

Epoch: 6| Step: 13
Training loss: 0.40698930621147156
Validation loss: 1.8872071094410394

Epoch: 311| Step: 0
Training loss: 0.8613573312759399
Validation loss: 1.9109650350386096

Epoch: 6| Step: 1
Training loss: 1.0996671915054321
Validation loss: 1.9653754875224123

Epoch: 6| Step: 2
Training loss: 1.0842565298080444
Validation loss: 1.941974991111345

Epoch: 6| Step: 3
Training loss: 0.4248086214065552
Validation loss: 1.9365612576084752

Epoch: 6| Step: 4
Training loss: 1.2373350858688354
Validation loss: 1.888657066129869

Epoch: 6| Step: 5
Training loss: 0.8809605836868286
Validation loss: 1.8821669009424025

Epoch: 6| Step: 6
Training loss: 1.1215527057647705
Validation loss: 1.8516572970215992

Epoch: 6| Step: 7
Training loss: 0.922134518623352
Validation loss: 1.8601325352986653

Epoch: 6| Step: 8
Training loss: 0.9118928909301758
Validation loss: 1.8304320535352152

Epoch: 6| Step: 9
Training loss: 0.5114427804946899
Validation loss: 1.840689318154448

Epoch: 6| Step: 10
Training loss: 1.3185904026031494
Validation loss: 1.8477566344763643

Epoch: 6| Step: 11
Training loss: 0.6405518651008606
Validation loss: 1.8346810968973304

Epoch: 6| Step: 12
Training loss: 1.0210727453231812
Validation loss: 1.8598307473685152

Epoch: 6| Step: 13
Training loss: 0.4967128336429596
Validation loss: 1.8867707867776193

Epoch: 312| Step: 0
Training loss: 0.8867366313934326
Validation loss: 1.8584034763356692

Epoch: 6| Step: 1
Training loss: 1.0174205303192139
Validation loss: 1.8784012256130096

Epoch: 6| Step: 2
Training loss: 0.6585724353790283
Validation loss: 1.8705745602166781

Epoch: 6| Step: 3
Training loss: 1.1867563724517822
Validation loss: 1.8934499140708678

Epoch: 6| Step: 4
Training loss: 0.7499964833259583
Validation loss: 1.879675280663275

Epoch: 6| Step: 5
Training loss: 0.8647639751434326
Validation loss: 1.848762930080455

Epoch: 6| Step: 6
Training loss: 1.0608603954315186
Validation loss: 1.8320165462391351

Epoch: 6| Step: 7
Training loss: 0.6191835403442383
Validation loss: 1.8192505272485877

Epoch: 6| Step: 8
Training loss: 0.8505645990371704
Validation loss: 1.805260504445722

Epoch: 6| Step: 9
Training loss: 1.2316794395446777
Validation loss: 1.8168340395855647

Epoch: 6| Step: 10
Training loss: 0.9605199694633484
Validation loss: 1.85004376211474

Epoch: 6| Step: 11
Training loss: 0.9978170394897461
Validation loss: 1.871413830787905

Epoch: 6| Step: 12
Training loss: 0.6207431554794312
Validation loss: 1.9074335969904417

Epoch: 6| Step: 13
Training loss: 0.44164884090423584
Validation loss: 1.8910106715335642

Epoch: 313| Step: 0
Training loss: 1.0658429861068726
Validation loss: 1.92126404341831

Epoch: 6| Step: 1
Training loss: 0.5418050289154053
Validation loss: 1.9387754547980525

Epoch: 6| Step: 2
Training loss: 1.0714969635009766
Validation loss: 1.948836854709092

Epoch: 6| Step: 3
Training loss: 0.7527243494987488
Validation loss: 1.9432177671822168

Epoch: 6| Step: 4
Training loss: 0.8043244481086731
Validation loss: 1.944578980886808

Epoch: 6| Step: 5
Training loss: 1.2248177528381348
Validation loss: 1.9010294919372888

Epoch: 6| Step: 6
Training loss: 0.43993788957595825
Validation loss: 1.8737882183444114

Epoch: 6| Step: 7
Training loss: 1.1953569650650024
Validation loss: 1.8450126314675936

Epoch: 6| Step: 8
Training loss: 0.6293860077857971
Validation loss: 1.8784767645661549

Epoch: 6| Step: 9
Training loss: 1.172299861907959
Validation loss: 1.8455978772973503

Epoch: 6| Step: 10
Training loss: 0.8137474060058594
Validation loss: 1.8330881710975402

Epoch: 6| Step: 11
Training loss: 0.7545880079269409
Validation loss: 1.8233769875700756

Epoch: 6| Step: 12
Training loss: 1.113607406616211
Validation loss: 1.847184596523162

Epoch: 6| Step: 13
Training loss: 0.6707181930541992
Validation loss: 1.8789626834213093

Epoch: 314| Step: 0
Training loss: 0.493943452835083
Validation loss: 1.8921602118399836

Epoch: 6| Step: 1
Training loss: 0.870560884475708
Validation loss: 1.8760412226441086

Epoch: 6| Step: 2
Training loss: 0.8838391304016113
Validation loss: 1.9100274168035036

Epoch: 6| Step: 3
Training loss: 1.1854288578033447
Validation loss: 1.908084225910966

Epoch: 6| Step: 4
Training loss: 0.6867245435714722
Validation loss: 1.9339145588618454

Epoch: 6| Step: 5
Training loss: 1.1331782341003418
Validation loss: 1.9249422832201886

Epoch: 6| Step: 6
Training loss: 1.0699832439422607
Validation loss: 1.8904664747176632

Epoch: 6| Step: 7
Training loss: 0.7706607580184937
Validation loss: 1.8870295016996321

Epoch: 6| Step: 8
Training loss: 1.0342518091201782
Validation loss: 1.872906897657661

Epoch: 6| Step: 9
Training loss: 0.8900408744812012
Validation loss: 1.8460820092949817

Epoch: 6| Step: 10
Training loss: 0.5706111788749695
Validation loss: 1.8239156482040242

Epoch: 6| Step: 11
Training loss: 0.8054293394088745
Validation loss: 1.8300084734475741

Epoch: 6| Step: 12
Training loss: 1.0740984678268433
Validation loss: 1.8320091424449798

Epoch: 6| Step: 13
Training loss: 0.8942120671272278
Validation loss: 1.8689285734648347

Epoch: 315| Step: 0
Training loss: 0.4670819044113159
Validation loss: 1.9050936698913574

Epoch: 6| Step: 1
Training loss: 0.4741486608982086
Validation loss: 1.9235105899072462

Epoch: 6| Step: 2
Training loss: 0.9581311941146851
Validation loss: 1.9634047862022155

Epoch: 6| Step: 3
Training loss: 0.8014801740646362
Validation loss: 1.9546750822374899

Epoch: 6| Step: 4
Training loss: 1.0510494709014893
Validation loss: 1.9065099147058302

Epoch: 6| Step: 5
Training loss: 0.9491654634475708
Validation loss: 1.8631931966350925

Epoch: 6| Step: 6
Training loss: 0.7220801711082458
Validation loss: 1.831008034367715

Epoch: 6| Step: 7
Training loss: 0.7344456911087036
Validation loss: 1.8273521956577097

Epoch: 6| Step: 8
Training loss: 1.1436723470687866
Validation loss: 1.7782110129633257

Epoch: 6| Step: 9
Training loss: 0.5538803339004517
Validation loss: 1.8130698319404357

Epoch: 6| Step: 10
Training loss: 0.8718417882919312
Validation loss: 1.8296878235314482

Epoch: 6| Step: 11
Training loss: 1.088789939880371
Validation loss: 1.8537539192425307

Epoch: 6| Step: 12
Training loss: 1.0707690715789795
Validation loss: 1.8647603937374648

Epoch: 6| Step: 13
Training loss: 1.4038000106811523
Validation loss: 1.8892963150496125

Epoch: 316| Step: 0
Training loss: 0.6641458868980408
Validation loss: 1.8761959140018751

Epoch: 6| Step: 1
Training loss: 0.5098826289176941
Validation loss: 1.9008841719678653

Epoch: 6| Step: 2
Training loss: 0.7647302150726318
Validation loss: 1.8795357288852814

Epoch: 6| Step: 3
Training loss: 1.173269271850586
Validation loss: 1.8727685764271726

Epoch: 6| Step: 4
Training loss: 0.7933109998703003
Validation loss: 1.84512972575362

Epoch: 6| Step: 5
Training loss: 0.9932863712310791
Validation loss: 1.8440267744884695

Epoch: 6| Step: 6
Training loss: 1.1114284992218018
Validation loss: 1.8401443804464033

Epoch: 6| Step: 7
Training loss: 0.752803385257721
Validation loss: 1.8234751967973606

Epoch: 6| Step: 8
Training loss: 1.2162387371063232
Validation loss: 1.8640925217700262

Epoch: 6| Step: 9
Training loss: 0.46623149514198303
Validation loss: 1.872727019812471

Epoch: 6| Step: 10
Training loss: 1.3841227293014526
Validation loss: 1.8577018078937326

Epoch: 6| Step: 11
Training loss: 0.7380597591400146
Validation loss: 1.8789420345778107

Epoch: 6| Step: 12
Training loss: 0.672397792339325
Validation loss: 1.877403897623862

Epoch: 6| Step: 13
Training loss: 0.9565590620040894
Validation loss: 1.9002355093597083

Epoch: 317| Step: 0
Training loss: 0.6755585670471191
Validation loss: 1.865359607563224

Epoch: 6| Step: 1
Training loss: 0.38473251461982727
Validation loss: 1.8885231505158127

Epoch: 6| Step: 2
Training loss: 1.1474781036376953
Validation loss: 1.8848182667968094

Epoch: 6| Step: 3
Training loss: 0.8992512226104736
Validation loss: 1.8120911659732941

Epoch: 6| Step: 4
Training loss: 0.45180028676986694
Validation loss: 1.8246463434670561

Epoch: 6| Step: 5
Training loss: 1.2535349130630493
Validation loss: 1.805431891513127

Epoch: 6| Step: 6
Training loss: 0.7445191144943237
Validation loss: 1.8352490189254924

Epoch: 6| Step: 7
Training loss: 0.8678802251815796
Validation loss: 1.8288973044323664

Epoch: 6| Step: 8
Training loss: 1.23262619972229
Validation loss: 1.8707022320839666

Epoch: 6| Step: 9
Training loss: 0.6376219391822815
Validation loss: 1.8445478536749398

Epoch: 6| Step: 10
Training loss: 0.8952222466468811
Validation loss: 1.868245392717341

Epoch: 6| Step: 11
Training loss: 0.8753422498703003
Validation loss: 1.8817223618107457

Epoch: 6| Step: 12
Training loss: 0.8076961636543274
Validation loss: 1.871330681667533

Epoch: 6| Step: 13
Training loss: 0.8046289682388306
Validation loss: 1.881010922052527

Epoch: 318| Step: 0
Training loss: 0.9599702954292297
Validation loss: 1.840417879883961

Epoch: 6| Step: 1
Training loss: 0.8237494826316833
Validation loss: 1.8923422726251746

Epoch: 6| Step: 2
Training loss: 0.44898512959480286
Validation loss: 1.876017080840244

Epoch: 6| Step: 3
Training loss: 0.9335712194442749
Validation loss: 1.8283191445053264

Epoch: 6| Step: 4
Training loss: 0.6401398181915283
Validation loss: 1.8122159332357428

Epoch: 6| Step: 5
Training loss: 0.97257000207901
Validation loss: 1.7976028611583095

Epoch: 6| Step: 6
Training loss: 0.7646701335906982
Validation loss: 1.817354795753315

Epoch: 6| Step: 7
Training loss: 0.9482083320617676
Validation loss: 1.8171589130996375

Epoch: 6| Step: 8
Training loss: 0.9374445676803589
Validation loss: 1.8155593038887106

Epoch: 6| Step: 9
Training loss: 1.3340221643447876
Validation loss: 1.8637456688829648

Epoch: 6| Step: 10
Training loss: 0.7046256065368652
Validation loss: 1.8844300790499615

Epoch: 6| Step: 11
Training loss: 0.8066936731338501
Validation loss: 1.9074973367875623

Epoch: 6| Step: 12
Training loss: 0.6245461702346802
Validation loss: 1.91787503868021

Epoch: 6| Step: 13
Training loss: 0.9808142185211182
Validation loss: 1.9034378477322158

Epoch: 319| Step: 0
Training loss: 0.9156593680381775
Validation loss: 1.9305481436432048

Epoch: 6| Step: 1
Training loss: 0.5915367603302002
Validation loss: 1.8803529508652226

Epoch: 6| Step: 2
Training loss: 0.898415744304657
Validation loss: 1.8995991522266018

Epoch: 6| Step: 3
Training loss: 0.7115291953086853
Validation loss: 1.8648630983086043

Epoch: 6| Step: 4
Training loss: 0.6546741724014282
Validation loss: 1.8650417891881799

Epoch: 6| Step: 5
Training loss: 0.5356040000915527
Validation loss: 1.8709837441803308

Epoch: 6| Step: 6
Training loss: 0.8152445554733276
Validation loss: 1.8730799011004868

Epoch: 6| Step: 7
Training loss: 1.4426467418670654
Validation loss: 1.849177663044263

Epoch: 6| Step: 8
Training loss: 0.5686165690422058
Validation loss: 1.848547891903949

Epoch: 6| Step: 9
Training loss: 1.136819839477539
Validation loss: 1.857593555604258

Epoch: 6| Step: 10
Training loss: 0.5305669903755188
Validation loss: 1.8377130710950462

Epoch: 6| Step: 11
Training loss: 1.0578134059906006
Validation loss: 1.9146377360948952

Epoch: 6| Step: 12
Training loss: 1.1436119079589844
Validation loss: 1.8460595582121162

Epoch: 6| Step: 13
Training loss: 0.9414994716644287
Validation loss: 1.8579746920575377

Epoch: 320| Step: 0
Training loss: 0.888959527015686
Validation loss: 1.824179398116245

Epoch: 6| Step: 1
Training loss: 0.6227072477340698
Validation loss: 1.8044400638149631

Epoch: 6| Step: 2
Training loss: 0.965527355670929
Validation loss: 1.8059188960700907

Epoch: 6| Step: 3
Training loss: 1.2077785730361938
Validation loss: 1.8147098197731921

Epoch: 6| Step: 4
Training loss: 0.5551663041114807
Validation loss: 1.8117032807360414

Epoch: 6| Step: 5
Training loss: 0.9115363359451294
Validation loss: 1.8396753085556852

Epoch: 6| Step: 6
Training loss: 0.6606303453445435
Validation loss: 1.8982703865215342

Epoch: 6| Step: 7
Training loss: 0.8455721735954285
Validation loss: 1.926186607730004

Epoch: 6| Step: 8
Training loss: 1.0455584526062012
Validation loss: 1.9608405866930563

Epoch: 6| Step: 9
Training loss: 1.029496669769287
Validation loss: 1.9352187841169295

Epoch: 6| Step: 10
Training loss: 0.7430042028427124
Validation loss: 1.9443801885010095

Epoch: 6| Step: 11
Training loss: 0.8157660961151123
Validation loss: 1.9202726912754837

Epoch: 6| Step: 12
Training loss: 0.6534569263458252
Validation loss: 1.8861776013528146

Epoch: 6| Step: 13
Training loss: 0.8271044492721558
Validation loss: 1.8806676505714335

Epoch: 321| Step: 0
Training loss: 0.8123571872711182
Validation loss: 1.8688644004124466

Epoch: 6| Step: 1
Training loss: 0.6794260144233704
Validation loss: 1.8443872492800477

Epoch: 6| Step: 2
Training loss: 0.7573660016059875
Validation loss: 1.8191397933549778

Epoch: 6| Step: 3
Training loss: 0.7352446913719177
Validation loss: 1.816191986042966

Epoch: 6| Step: 4
Training loss: 1.1090461015701294
Validation loss: 1.8223769716037217

Epoch: 6| Step: 5
Training loss: 0.5180551409721375
Validation loss: 1.7916449116122337

Epoch: 6| Step: 6
Training loss: 0.6814937591552734
Validation loss: 1.8260321860672326

Epoch: 6| Step: 7
Training loss: 1.3023483753204346
Validation loss: 1.8220618001876339

Epoch: 6| Step: 8
Training loss: 1.0249288082122803
Validation loss: 1.8298307952060495

Epoch: 6| Step: 9
Training loss: 0.6040210127830505
Validation loss: 1.8346989590634581

Epoch: 6| Step: 10
Training loss: 0.5494779348373413
Validation loss: 1.8479931956978255

Epoch: 6| Step: 11
Training loss: 1.102962613105774
Validation loss: 1.8577454551573722

Epoch: 6| Step: 12
Training loss: 0.8630353212356567
Validation loss: 1.835945830550245

Epoch: 6| Step: 13
Training loss: 0.7926381826400757
Validation loss: 1.8171184229594406

Epoch: 322| Step: 0
Training loss: 1.1102184057235718
Validation loss: 1.847501604787765

Epoch: 6| Step: 1
Training loss: 0.929853618144989
Validation loss: 1.862302057204708

Epoch: 6| Step: 2
Training loss: 0.7239201664924622
Validation loss: 1.8667656606243503

Epoch: 6| Step: 3
Training loss: 0.6150052547454834
Validation loss: 1.8587265373558126

Epoch: 6| Step: 4
Training loss: 0.5504999160766602
Validation loss: 1.875127766721992

Epoch: 6| Step: 5
Training loss: 1.143038034439087
Validation loss: 1.8795323512887443

Epoch: 6| Step: 6
Training loss: 0.920116662979126
Validation loss: 1.8974134217026413

Epoch: 6| Step: 7
Training loss: 1.0577199459075928
Validation loss: 1.9071146249771118

Epoch: 6| Step: 8
Training loss: 0.6124909520149231
Validation loss: 1.9024706066295665

Epoch: 6| Step: 9
Training loss: 0.5796446204185486
Validation loss: 1.8584698265598667

Epoch: 6| Step: 10
Training loss: 1.070945382118225
Validation loss: 1.8899663738025132

Epoch: 6| Step: 11
Training loss: 0.615655243396759
Validation loss: 1.8541095513169483

Epoch: 6| Step: 12
Training loss: 0.886451005935669
Validation loss: 1.8786038083414878

Epoch: 6| Step: 13
Training loss: 0.7315648794174194
Validation loss: 1.8462700331082909

Epoch: 323| Step: 0
Training loss: 0.5325890183448792
Validation loss: 1.7980678132785264

Epoch: 6| Step: 1
Training loss: 0.6634488105773926
Validation loss: 1.8157229731159825

Epoch: 6| Step: 2
Training loss: 0.8384416699409485
Validation loss: 1.8218331003701815

Epoch: 6| Step: 3
Training loss: 1.1109192371368408
Validation loss: 1.7924350487288607

Epoch: 6| Step: 4
Training loss: 0.6065435409545898
Validation loss: 1.8003467411123297

Epoch: 6| Step: 5
Training loss: 0.7437606453895569
Validation loss: 1.8518205970846198

Epoch: 6| Step: 6
Training loss: 0.6641783714294434
Validation loss: 1.8594864222311205

Epoch: 6| Step: 7
Training loss: 0.9337989091873169
Validation loss: 1.8807509022374307

Epoch: 6| Step: 8
Training loss: 0.6900458931922913
Validation loss: 1.9246692913834766

Epoch: 6| Step: 9
Training loss: 0.8385663032531738
Validation loss: 1.9430599674101798

Epoch: 6| Step: 10
Training loss: 1.2623913288116455
Validation loss: 1.9514617586648593

Epoch: 6| Step: 11
Training loss: 0.9434700012207031
Validation loss: 1.9419236260075723

Epoch: 6| Step: 12
Training loss: 0.642339825630188
Validation loss: 1.915493675457534

Epoch: 6| Step: 13
Training loss: 1.241319179534912
Validation loss: 1.9089351405379593

Epoch: 324| Step: 0
Training loss: 0.6467976570129395
Validation loss: 1.8808838090588968

Epoch: 6| Step: 1
Training loss: 0.8868533968925476
Validation loss: 1.8689138825221727

Epoch: 6| Step: 2
Training loss: 1.0323758125305176
Validation loss: 1.8691183847765769

Epoch: 6| Step: 3
Training loss: 0.8361796736717224
Validation loss: 1.8226734745887019

Epoch: 6| Step: 4
Training loss: 0.8409662842750549
Validation loss: 1.8526901929609236

Epoch: 6| Step: 5
Training loss: 0.7732815742492676
Validation loss: 1.8357121508608583

Epoch: 6| Step: 6
Training loss: 0.7008340954780579
Validation loss: 1.8184367815653484

Epoch: 6| Step: 7
Training loss: 1.0736513137817383
Validation loss: 1.8311524198901268

Epoch: 6| Step: 8
Training loss: 0.742091178894043
Validation loss: 1.8750840399854927

Epoch: 6| Step: 9
Training loss: 0.5934215784072876
Validation loss: 1.8894617595980245

Epoch: 6| Step: 10
Training loss: 1.028351068496704
Validation loss: 1.8966180047681254

Epoch: 6| Step: 11
Training loss: 0.856404721736908
Validation loss: 1.8817015335124025

Epoch: 6| Step: 12
Training loss: 0.8087586164474487
Validation loss: 1.8473949150372577

Epoch: 6| Step: 13
Training loss: 0.6178730726242065
Validation loss: 1.8533889555162

Epoch: 325| Step: 0
Training loss: 1.156226396560669
Validation loss: 1.8495079496855378

Epoch: 6| Step: 1
Training loss: 0.9043065309524536
Validation loss: 1.8442012750974266

Epoch: 6| Step: 2
Training loss: 0.7760063409805298
Validation loss: 1.8779684856373777

Epoch: 6| Step: 3
Training loss: 0.1875116527080536
Validation loss: 1.9056772250001148

Epoch: 6| Step: 4
Training loss: 0.5607212781906128
Validation loss: 1.898223700061921

Epoch: 6| Step: 5
Training loss: 0.8328315615653992
Validation loss: 1.8882701396942139

Epoch: 6| Step: 6
Training loss: 0.9093341827392578
Validation loss: 1.8886557009912306

Epoch: 6| Step: 7
Training loss: 0.9643181562423706
Validation loss: 1.8529981105558333

Epoch: 6| Step: 8
Training loss: 1.0331701040267944
Validation loss: 1.8540566941743255

Epoch: 6| Step: 9
Training loss: 0.8229001760482788
Validation loss: 1.8135509273057342

Epoch: 6| Step: 10
Training loss: 0.8579474091529846
Validation loss: 1.8291019560188375

Epoch: 6| Step: 11
Training loss: 1.169520378112793
Validation loss: 1.8232241420335666

Epoch: 6| Step: 12
Training loss: 0.3263072967529297
Validation loss: 1.8116007389560822

Epoch: 6| Step: 13
Training loss: 1.1527395248413086
Validation loss: 1.8418262902126517

Epoch: 326| Step: 0
Training loss: 1.054687738418579
Validation loss: 1.8636400840615714

Epoch: 6| Step: 1
Training loss: 0.8683417439460754
Validation loss: 1.8852689381568664

Epoch: 6| Step: 2
Training loss: 0.7755563855171204
Validation loss: 1.887390589201322

Epoch: 6| Step: 3
Training loss: 0.6789497137069702
Validation loss: 1.8564509371275544

Epoch: 6| Step: 4
Training loss: 0.7588335871696472
Validation loss: 1.8923068482388732

Epoch: 6| Step: 5
Training loss: 0.9463038444519043
Validation loss: 1.8611456758232527

Epoch: 6| Step: 6
Training loss: 0.7893414497375488
Validation loss: 1.849744548079788

Epoch: 6| Step: 7
Training loss: 1.3393737077713013
Validation loss: 1.8973347756170458

Epoch: 6| Step: 8
Training loss: 0.8766824007034302
Validation loss: 1.8745287041510306

Epoch: 6| Step: 9
Training loss: 0.5861139893531799
Validation loss: 1.912322021299793

Epoch: 6| Step: 10
Training loss: 1.047942876815796
Validation loss: 1.9200775059320594

Epoch: 6| Step: 11
Training loss: 0.43824177980422974
Validation loss: 1.8705626303149807

Epoch: 6| Step: 12
Training loss: 0.5610041618347168
Validation loss: 1.8388283368079894

Epoch: 6| Step: 13
Training loss: 0.6357570886611938
Validation loss: 1.8443451953190628

Epoch: 327| Step: 0
Training loss: 0.7596901655197144
Validation loss: 1.8132452682782245

Epoch: 6| Step: 1
Training loss: 0.6890338659286499
Validation loss: 1.8243161068167737

Epoch: 6| Step: 2
Training loss: 0.49005571007728577
Validation loss: 1.8532518930332635

Epoch: 6| Step: 3
Training loss: 0.7644595503807068
Validation loss: 1.8574204175702986

Epoch: 6| Step: 4
Training loss: 0.7943001389503479
Validation loss: 1.8989782692283712

Epoch: 6| Step: 5
Training loss: 0.7303968667984009
Validation loss: 1.8675513600790372

Epoch: 6| Step: 6
Training loss: 0.7311967611312866
Validation loss: 1.8842782410242225

Epoch: 6| Step: 7
Training loss: 0.8544514179229736
Validation loss: 1.868005932018321

Epoch: 6| Step: 8
Training loss: 0.27134019136428833
Validation loss: 1.88743499530259

Epoch: 6| Step: 9
Training loss: 1.3861749172210693
Validation loss: 1.8580687456233527

Epoch: 6| Step: 10
Training loss: 0.5626860857009888
Validation loss: 1.8196689877458798

Epoch: 6| Step: 11
Training loss: 1.6046282052993774
Validation loss: 1.8699971027271722

Epoch: 6| Step: 12
Training loss: 0.9001433849334717
Validation loss: 1.8419969684334212

Epoch: 6| Step: 13
Training loss: 1.035296082496643
Validation loss: 1.8351383619411017

Epoch: 328| Step: 0
Training loss: 0.3779866695404053
Validation loss: 1.824373411234989

Epoch: 6| Step: 1
Training loss: 0.8109709620475769
Validation loss: 1.7974693185539656

Epoch: 6| Step: 2
Training loss: 0.9324495792388916
Validation loss: 1.8150065996313607

Epoch: 6| Step: 3
Training loss: 0.584263026714325
Validation loss: 1.7967982535721154

Epoch: 6| Step: 4
Training loss: 0.7806394100189209
Validation loss: 1.8321828790890273

Epoch: 6| Step: 5
Training loss: 1.008682131767273
Validation loss: 1.817364772160848

Epoch: 6| Step: 6
Training loss: 0.8384847640991211
Validation loss: 1.8403529428666638

Epoch: 6| Step: 7
Training loss: 0.7212036848068237
Validation loss: 1.8483584593701106

Epoch: 6| Step: 8
Training loss: 0.48881635069847107
Validation loss: 1.888697426806214

Epoch: 6| Step: 9
Training loss: 1.0101380348205566
Validation loss: 1.9107969678858274

Epoch: 6| Step: 10
Training loss: 1.0371313095092773
Validation loss: 1.8765747085694344

Epoch: 6| Step: 11
Training loss: 1.1691888570785522
Validation loss: 1.8774636048142628

Epoch: 6| Step: 12
Training loss: 0.6464356184005737
Validation loss: 1.8454325096581572

Epoch: 6| Step: 13
Training loss: 0.6005117297172546
Validation loss: 1.892836647648965

Epoch: 329| Step: 0
Training loss: 0.7223086357116699
Validation loss: 1.8761886012169622

Epoch: 6| Step: 1
Training loss: 0.9424591064453125
Validation loss: 1.8722693894499092

Epoch: 6| Step: 2
Training loss: 0.5648117661476135
Validation loss: 1.8648136379898235

Epoch: 6| Step: 3
Training loss: 0.6449530124664307
Validation loss: 1.840137432980281

Epoch: 6| Step: 4
Training loss: 0.958337664604187
Validation loss: 1.8392230618384577

Epoch: 6| Step: 5
Training loss: 0.5921664237976074
Validation loss: 1.8094374774604716

Epoch: 6| Step: 6
Training loss: 1.1016416549682617
Validation loss: 1.8260472205377394

Epoch: 6| Step: 7
Training loss: 1.016315221786499
Validation loss: 1.8223312260002218

Epoch: 6| Step: 8
Training loss: 0.8403638601303101
Validation loss: 1.8691909159383466

Epoch: 6| Step: 9
Training loss: 0.9591678977012634
Validation loss: 1.8697879006785731

Epoch: 6| Step: 10
Training loss: 0.504462480545044
Validation loss: 1.8719168952716294

Epoch: 6| Step: 11
Training loss: 0.3090806305408478
Validation loss: 1.923839266582202

Epoch: 6| Step: 12
Training loss: 1.0442537069320679
Validation loss: 1.9176917383747716

Epoch: 6| Step: 13
Training loss: 0.7243885397911072
Validation loss: 1.9524375341271842

Epoch: 330| Step: 0
Training loss: 0.5999463796615601
Validation loss: 1.92297153447264

Epoch: 6| Step: 1
Training loss: 0.9025743007659912
Validation loss: 1.898116950065859

Epoch: 6| Step: 2
Training loss: 0.9158583879470825
Validation loss: 1.8998377015513759

Epoch: 6| Step: 3
Training loss: 0.7961052060127258
Validation loss: 1.8899505881853

Epoch: 6| Step: 4
Training loss: 0.5716875791549683
Validation loss: 1.8645063484868696

Epoch: 6| Step: 5
Training loss: 0.8140736818313599
Validation loss: 1.8376968483771048

Epoch: 6| Step: 6
Training loss: 0.9219938516616821
Validation loss: 1.8503048035406298

Epoch: 6| Step: 7
Training loss: 0.4251841902732849
Validation loss: 1.8367711908073836

Epoch: 6| Step: 8
Training loss: 1.0566446781158447
Validation loss: 1.8123808291650587

Epoch: 6| Step: 9
Training loss: 0.4583355784416199
Validation loss: 1.7739642345777122

Epoch: 6| Step: 10
Training loss: 0.9443154335021973
Validation loss: 1.7727698536329373

Epoch: 6| Step: 11
Training loss: 0.8047578930854797
Validation loss: 1.7770409712227442

Epoch: 6| Step: 12
Training loss: 0.8402615189552307
Validation loss: 1.7805707557227022

Epoch: 6| Step: 13
Training loss: 1.2132933139801025
Validation loss: 1.8140786668305755

Epoch: 331| Step: 0
Training loss: 0.47540515661239624
Validation loss: 1.848965480763425

Epoch: 6| Step: 1
Training loss: 1.1360979080200195
Validation loss: 1.870525147325249

Epoch: 6| Step: 2
Training loss: 0.7251876592636108
Validation loss: 1.8648519131445116

Epoch: 6| Step: 3
Training loss: 0.7185277342796326
Validation loss: 1.85431533475076

Epoch: 6| Step: 4
Training loss: 0.7901808023452759
Validation loss: 1.8893230653578235

Epoch: 6| Step: 5
Training loss: 0.8139968514442444
Validation loss: 1.8828621679736721

Epoch: 6| Step: 6
Training loss: 0.5720621347427368
Validation loss: 1.8492496898097377

Epoch: 6| Step: 7
Training loss: 1.0478768348693848
Validation loss: 1.8737358598298923

Epoch: 6| Step: 8
Training loss: 0.7366678714752197
Validation loss: 1.865197927721085

Epoch: 6| Step: 9
Training loss: 1.1323436498641968
Validation loss: 1.874316587243029

Epoch: 6| Step: 10
Training loss: 0.6576803922653198
Validation loss: 1.8682547807693481

Epoch: 6| Step: 11
Training loss: 0.8701621294021606
Validation loss: 1.8504207839248001

Epoch: 6| Step: 12
Training loss: 0.363829106092453
Validation loss: 1.86938383758709

Epoch: 6| Step: 13
Training loss: 0.9613412022590637
Validation loss: 1.886424756819202

Epoch: 332| Step: 0
Training loss: 0.8689543008804321
Validation loss: 1.8871580349501742

Epoch: 6| Step: 1
Training loss: 1.491938829421997
Validation loss: 1.8782549160783009

Epoch: 6| Step: 2
Training loss: 0.8675887584686279
Validation loss: 1.844806158414451

Epoch: 6| Step: 3
Training loss: 1.1965419054031372
Validation loss: 1.8447434145917174

Epoch: 6| Step: 4
Training loss: 1.0618000030517578
Validation loss: 1.825324082887301

Epoch: 6| Step: 5
Training loss: 0.7060784101486206
Validation loss: 1.8042116870162308

Epoch: 6| Step: 6
Training loss: 0.4304581880569458
Validation loss: 1.7700253750688286

Epoch: 6| Step: 7
Training loss: 0.8090904355049133
Validation loss: 1.7723155713850451

Epoch: 6| Step: 8
Training loss: 0.6602113246917725
Validation loss: 1.782758197476787

Epoch: 6| Step: 9
Training loss: 0.5655992031097412
Validation loss: 1.773979663848877

Epoch: 6| Step: 10
Training loss: 0.6185342669487
Validation loss: 1.8190688446003904

Epoch: 6| Step: 11
Training loss: 0.6345564126968384
Validation loss: 1.8112423150770125

Epoch: 6| Step: 12
Training loss: 0.4189470708370209
Validation loss: 1.8401163367814914

Epoch: 6| Step: 13
Training loss: 0.6288378238677979
Validation loss: 1.8961058739692933

Epoch: 333| Step: 0
Training loss: 0.8284024596214294
Validation loss: 1.9166046060541624

Epoch: 6| Step: 1
Training loss: 0.5768742561340332
Validation loss: 1.9468669327356483

Epoch: 6| Step: 2
Training loss: 0.5208299160003662
Validation loss: 1.9539507140395462

Epoch: 6| Step: 3
Training loss: 0.8219562768936157
Validation loss: 1.9056049469978578

Epoch: 6| Step: 4
Training loss: 0.837241530418396
Validation loss: 1.8532449212125552

Epoch: 6| Step: 5
Training loss: 0.39613378047943115
Validation loss: 1.826829198868044

Epoch: 6| Step: 6
Training loss: 0.662065863609314
Validation loss: 1.8316582864330662

Epoch: 6| Step: 7
Training loss: 1.0514733791351318
Validation loss: 1.803848530656548

Epoch: 6| Step: 8
Training loss: 0.9451135993003845
Validation loss: 1.8035107325482111

Epoch: 6| Step: 9
Training loss: 1.049401044845581
Validation loss: 1.8161701143428843

Epoch: 6| Step: 10
Training loss: 0.5246843099594116
Validation loss: 1.799668030072284

Epoch: 6| Step: 11
Training loss: 0.8400650024414062
Validation loss: 1.7902450279522968

Epoch: 6| Step: 12
Training loss: 0.9389591217041016
Validation loss: 1.8112312862949986

Epoch: 6| Step: 13
Training loss: 1.2365647554397583
Validation loss: 1.7947862327739756

Epoch: 334| Step: 0
Training loss: 0.4539628028869629
Validation loss: 1.8398011807472474

Epoch: 6| Step: 1
Training loss: 0.6742204427719116
Validation loss: 1.864315693096448

Epoch: 6| Step: 2
Training loss: 0.6755844354629517
Validation loss: 1.87366985377445

Epoch: 6| Step: 3
Training loss: 0.43374598026275635
Validation loss: 1.889622192228994

Epoch: 6| Step: 4
Training loss: 1.212214708328247
Validation loss: 1.8544763800918416

Epoch: 6| Step: 5
Training loss: 0.4946865737438202
Validation loss: 1.8781141183709587

Epoch: 6| Step: 6
Training loss: 0.9373272061347961
Validation loss: 1.8527246700820101

Epoch: 6| Step: 7
Training loss: 0.9527103900909424
Validation loss: 1.7989324395374586

Epoch: 6| Step: 8
Training loss: 1.1251893043518066
Validation loss: 1.7909848869487803

Epoch: 6| Step: 9
Training loss: 0.6495565176010132
Validation loss: 1.7938366743826097

Epoch: 6| Step: 10
Training loss: 0.6432999968528748
Validation loss: 1.7759044029379403

Epoch: 6| Step: 11
Training loss: 0.7515784502029419
Validation loss: 1.7911832691520773

Epoch: 6| Step: 12
Training loss: 1.0600751638412476
Validation loss: 1.808362167368653

Epoch: 6| Step: 13
Training loss: 0.5050316452980042
Validation loss: 1.84613125811341

Epoch: 335| Step: 0
Training loss: 0.8364777565002441
Validation loss: 1.829279084359446

Epoch: 6| Step: 1
Training loss: 0.5858079791069031
Validation loss: 1.8274260413262151

Epoch: 6| Step: 2
Training loss: 0.5389101505279541
Validation loss: 1.8137393869379514

Epoch: 6| Step: 3
Training loss: 0.6666780710220337
Validation loss: 1.8274728931406492

Epoch: 6| Step: 4
Training loss: 0.6103190183639526
Validation loss: 1.8322855990420106

Epoch: 6| Step: 5
Training loss: 0.8159630298614502
Validation loss: 1.8162828209579631

Epoch: 6| Step: 6
Training loss: 0.43561381101608276
Validation loss: 1.8000200230588195

Epoch: 6| Step: 7
Training loss: 0.9860851168632507
Validation loss: 1.839350256868588

Epoch: 6| Step: 8
Training loss: 0.4822041094303131
Validation loss: 1.827622757163099

Epoch: 6| Step: 9
Training loss: 0.8291500210762024
Validation loss: 1.8263422840385026

Epoch: 6| Step: 10
Training loss: 1.1858232021331787
Validation loss: 1.7948467218747703

Epoch: 6| Step: 11
Training loss: 0.6031807065010071
Validation loss: 1.8046818202541721

Epoch: 6| Step: 12
Training loss: 0.8995121717453003
Validation loss: 1.8247055417747908

Epoch: 6| Step: 13
Training loss: 0.8708927631378174
Validation loss: 1.8215731959189139

Epoch: 336| Step: 0
Training loss: 0.6242811679840088
Validation loss: 1.8433993554884387

Epoch: 6| Step: 1
Training loss: 0.8655543923377991
Validation loss: 1.8323316407460037

Epoch: 6| Step: 2
Training loss: 0.8465558290481567
Validation loss: 1.83174809973727

Epoch: 6| Step: 3
Training loss: 0.6188786029815674
Validation loss: 1.8462798800519717

Epoch: 6| Step: 4
Training loss: 0.9891666173934937
Validation loss: 1.830137752717541

Epoch: 6| Step: 5
Training loss: 0.322602242231369
Validation loss: 1.8472524881362915

Epoch: 6| Step: 6
Training loss: 0.7860230207443237
Validation loss: 1.8687701353462793

Epoch: 6| Step: 7
Training loss: 0.9905841946601868
Validation loss: 1.854817419923762

Epoch: 6| Step: 8
Training loss: 0.6358057260513306
Validation loss: 1.8246705660256006

Epoch: 6| Step: 9
Training loss: 0.3749655485153198
Validation loss: 1.8286658064011605

Epoch: 6| Step: 10
Training loss: 0.9411003589630127
Validation loss: 1.8013693953073153

Epoch: 6| Step: 11
Training loss: 0.7211300730705261
Validation loss: 1.7777415860083796

Epoch: 6| Step: 12
Training loss: 1.0353024005889893
Validation loss: 1.8178133118537165

Epoch: 6| Step: 13
Training loss: 0.5346652865409851
Validation loss: 1.8265531024625223

Epoch: 337| Step: 0
Training loss: 0.5251939296722412
Validation loss: 1.8129630422079435

Epoch: 6| Step: 1
Training loss: 0.7585822939872742
Validation loss: 1.8337367632055794

Epoch: 6| Step: 2
Training loss: 0.6294569969177246
Validation loss: 1.8467274276159142

Epoch: 6| Step: 3
Training loss: 0.6622776985168457
Validation loss: 1.8885865519123692

Epoch: 6| Step: 4
Training loss: 0.7116147875785828
Validation loss: 1.8976930956686697

Epoch: 6| Step: 5
Training loss: 1.164592981338501
Validation loss: 1.9582869596378778

Epoch: 6| Step: 6
Training loss: 0.7999688386917114
Validation loss: 1.9705492924618464

Epoch: 6| Step: 7
Training loss: 0.7560126781463623
Validation loss: 1.9660701444072108

Epoch: 6| Step: 8
Training loss: 0.8618994951248169
Validation loss: 1.9982643165896017

Epoch: 6| Step: 9
Training loss: 0.8215680718421936
Validation loss: 1.9608593140878985

Epoch: 6| Step: 10
Training loss: 0.8504941463470459
Validation loss: 1.9899921635145783

Epoch: 6| Step: 11
Training loss: 0.6167529225349426
Validation loss: 1.9134113609149892

Epoch: 6| Step: 12
Training loss: 0.7966302633285522
Validation loss: 1.8938256694424538

Epoch: 6| Step: 13
Training loss: 0.4389600157737732
Validation loss: 1.798833216390302

Epoch: 338| Step: 0
Training loss: 0.7497853636741638
Validation loss: 1.7829788615626674

Epoch: 6| Step: 1
Training loss: 0.6860561370849609
Validation loss: 1.76473464504365

Epoch: 6| Step: 2
Training loss: 1.0284059047698975
Validation loss: 1.7703046849978867

Epoch: 6| Step: 3
Training loss: 0.4833642542362213
Validation loss: 1.7901474711715535

Epoch: 6| Step: 4
Training loss: 0.7050869464874268
Validation loss: 1.75339513568468

Epoch: 6| Step: 5
Training loss: 0.5738165974617004
Validation loss: 1.7868529801727624

Epoch: 6| Step: 6
Training loss: 0.7900286912918091
Validation loss: 1.7756728715794061

Epoch: 6| Step: 7
Training loss: 1.1091923713684082
Validation loss: 1.8416928078538628

Epoch: 6| Step: 8
Training loss: 0.6143897771835327
Validation loss: 1.812905211602488

Epoch: 6| Step: 9
Training loss: 0.5028001666069031
Validation loss: 1.8297046192230717

Epoch: 6| Step: 10
Training loss: 0.9392068386077881
Validation loss: 1.8761217363419072

Epoch: 6| Step: 11
Training loss: 1.014382243156433
Validation loss: 1.8501118306190736

Epoch: 6| Step: 12
Training loss: 0.7413920164108276
Validation loss: 1.821565762001981

Epoch: 6| Step: 13
Training loss: 0.6891307830810547
Validation loss: 1.8442763500316168

Epoch: 339| Step: 0
Training loss: 0.9609640836715698
Validation loss: 1.839489390773158

Epoch: 6| Step: 1
Training loss: 1.199249505996704
Validation loss: 1.8631017951555149

Epoch: 6| Step: 2
Training loss: 0.8641639351844788
Validation loss: 1.8363128836436937

Epoch: 6| Step: 3
Training loss: 0.6383966207504272
Validation loss: 1.8955216433412285

Epoch: 6| Step: 4
Training loss: 0.7745918035507202
Validation loss: 1.8846365046757523

Epoch: 6| Step: 5
Training loss: 0.859994649887085
Validation loss: 1.875381669690532

Epoch: 6| Step: 6
Training loss: 0.9522478580474854
Validation loss: 1.846099122878044

Epoch: 6| Step: 7
Training loss: 0.5251098871231079
Validation loss: 1.9022875011608165

Epoch: 6| Step: 8
Training loss: 0.503573477268219
Validation loss: 1.8786160176800144

Epoch: 6| Step: 9
Training loss: 0.7256580591201782
Validation loss: 1.8979215186129335

Epoch: 6| Step: 10
Training loss: 0.8086243867874146
Validation loss: 1.8753668364658151

Epoch: 6| Step: 11
Training loss: 0.49359315633773804
Validation loss: 1.8485060673888012

Epoch: 6| Step: 12
Training loss: 0.45556381344795227
Validation loss: 1.8384823940133537

Epoch: 6| Step: 13
Training loss: 0.522507905960083
Validation loss: 1.8425312196054766

Epoch: 340| Step: 0
Training loss: 0.3327030539512634
Validation loss: 1.8509384816692722

Epoch: 6| Step: 1
Training loss: 0.5677511692047119
Validation loss: 1.8085911645684192

Epoch: 6| Step: 2
Training loss: 0.8600155115127563
Validation loss: 1.8276230417272097

Epoch: 6| Step: 3
Training loss: 0.9471844434738159
Validation loss: 1.8794947349896995

Epoch: 6| Step: 4
Training loss: 1.1391547918319702
Validation loss: 1.8853074504483132

Epoch: 6| Step: 5
Training loss: 0.6549925804138184
Validation loss: 1.9347070250459897

Epoch: 6| Step: 6
Training loss: 0.7152644991874695
Validation loss: 1.934764031440981

Epoch: 6| Step: 7
Training loss: 0.9332593679428101
Validation loss: 1.924396425165156

Epoch: 6| Step: 8
Training loss: 1.2089083194732666
Validation loss: 1.9072511247409287

Epoch: 6| Step: 9
Training loss: 0.6748700737953186
Validation loss: 1.8586408579221336

Epoch: 6| Step: 10
Training loss: 0.6700519323348999
Validation loss: 1.8715855588195145

Epoch: 6| Step: 11
Training loss: 0.5080095529556274
Validation loss: 1.8143699361431984

Epoch: 6| Step: 12
Training loss: 0.4074908494949341
Validation loss: 1.8148229634889992

Epoch: 6| Step: 13
Training loss: 0.6130003333091736
Validation loss: 1.8300044280226513

Epoch: 341| Step: 0
Training loss: 1.0895224809646606
Validation loss: 1.833419494731452

Epoch: 6| Step: 1
Training loss: 0.921357274055481
Validation loss: 1.8404974937438965

Epoch: 6| Step: 2
Training loss: 0.5169126987457275
Validation loss: 1.854253202356318

Epoch: 6| Step: 3
Training loss: 0.6737894415855408
Validation loss: 1.8759364876695859

Epoch: 6| Step: 4
Training loss: 0.8518416881561279
Validation loss: 1.9140766000234952

Epoch: 6| Step: 5
Training loss: 0.6223037242889404
Validation loss: 1.9329631508037608

Epoch: 6| Step: 6
Training loss: 0.7768001556396484
Validation loss: 1.970113096698638

Epoch: 6| Step: 7
Training loss: 0.6843434572219849
Validation loss: 1.9317328083899714

Epoch: 6| Step: 8
Training loss: 1.0707412958145142
Validation loss: 1.9088527310279109

Epoch: 6| Step: 9
Training loss: 0.6276140809059143
Validation loss: 1.8438364844168387

Epoch: 6| Step: 10
Training loss: 0.6106196641921997
Validation loss: 1.8001675554501113

Epoch: 6| Step: 11
Training loss: 0.624496579170227
Validation loss: 1.8163378674496886

Epoch: 6| Step: 12
Training loss: 0.4867541193962097
Validation loss: 1.7890249119010022

Epoch: 6| Step: 13
Training loss: 0.7250072956085205
Validation loss: 1.8082679779298845

Epoch: 342| Step: 0
Training loss: 0.8656641840934753
Validation loss: 1.8077521683067403

Epoch: 6| Step: 1
Training loss: 0.628562331199646
Validation loss: 1.854921470406235

Epoch: 6| Step: 2
Training loss: 1.0390290021896362
Validation loss: 1.8728567297740648

Epoch: 6| Step: 3
Training loss: 0.9664211273193359
Validation loss: 1.864426439808261

Epoch: 6| Step: 4
Training loss: 0.6174582242965698
Validation loss: 1.8751387198766072

Epoch: 6| Step: 5
Training loss: 0.868370771408081
Validation loss: 1.8778797413713189

Epoch: 6| Step: 6
Training loss: 0.45799970626831055
Validation loss: 1.8682747105116486

Epoch: 6| Step: 7
Training loss: 0.6740419864654541
Validation loss: 1.8427220493234613

Epoch: 6| Step: 8
Training loss: 0.69456946849823
Validation loss: 1.876295801131956

Epoch: 6| Step: 9
Training loss: 0.5187106132507324
Validation loss: 1.8501093938786497

Epoch: 6| Step: 10
Training loss: 0.7240002155303955
Validation loss: 1.8248312832206808

Epoch: 6| Step: 11
Training loss: 0.6375767588615417
Validation loss: 1.8212953011194866

Epoch: 6| Step: 12
Training loss: 0.9284142255783081
Validation loss: 1.819252299365177

Epoch: 6| Step: 13
Training loss: 1.210447907447815
Validation loss: 1.7989265688004032

Epoch: 343| Step: 0
Training loss: 0.40554338693618774
Validation loss: 1.8011227782054613

Epoch: 6| Step: 1
Training loss: 0.7039269804954529
Validation loss: 1.7753231038329422

Epoch: 6| Step: 2
Training loss: 0.8590258955955505
Validation loss: 1.8556088068151986

Epoch: 6| Step: 3
Training loss: 0.6916050910949707
Validation loss: 1.8374109165642851

Epoch: 6| Step: 4
Training loss: 0.9944407939910889
Validation loss: 1.8535044782905168

Epoch: 6| Step: 5
Training loss: 0.7944942712783813
Validation loss: 1.889280608905259

Epoch: 6| Step: 6
Training loss: 1.0750499963760376
Validation loss: 1.8999934286199591

Epoch: 6| Step: 7
Training loss: 0.41891786456108093
Validation loss: 1.920168674120339

Epoch: 6| Step: 8
Training loss: 0.74921053647995
Validation loss: 1.8819270095517557

Epoch: 6| Step: 9
Training loss: 1.0552562475204468
Validation loss: 1.8720818309373752

Epoch: 6| Step: 10
Training loss: 0.6809535622596741
Validation loss: 1.8572110258122927

Epoch: 6| Step: 11
Training loss: 0.6043003797531128
Validation loss: 1.835019214178926

Epoch: 6| Step: 12
Training loss: 0.672200083732605
Validation loss: 1.8110841397316224

Epoch: 6| Step: 13
Training loss: 0.6984394788742065
Validation loss: 1.7951429479865617

Epoch: 344| Step: 0
Training loss: 0.8965054750442505
Validation loss: 1.8369380620218092

Epoch: 6| Step: 1
Training loss: 1.1432106494903564
Validation loss: 1.8008362554734754

Epoch: 6| Step: 2
Training loss: 0.52298504114151
Validation loss: 1.8435592318093905

Epoch: 6| Step: 3
Training loss: 1.031540036201477
Validation loss: 1.8205786110252462

Epoch: 6| Step: 4
Training loss: 0.39912092685699463
Validation loss: 1.8307341119294525

Epoch: 6| Step: 5
Training loss: 0.5482890605926514
Validation loss: 1.8456649959728282

Epoch: 6| Step: 6
Training loss: 0.9685134291648865
Validation loss: 1.8610559817283385

Epoch: 6| Step: 7
Training loss: 0.8277206420898438
Validation loss: 1.8405813619654665

Epoch: 6| Step: 8
Training loss: 0.9786838889122009
Validation loss: 1.8005658798320319

Epoch: 6| Step: 9
Training loss: 0.7684498429298401
Validation loss: 1.8115569827377156

Epoch: 6| Step: 10
Training loss: 0.33843857049942017
Validation loss: 1.7517916361490886

Epoch: 6| Step: 11
Training loss: 0.9771237373352051
Validation loss: 1.7822708045282671

Epoch: 6| Step: 12
Training loss: 0.3324389159679413
Validation loss: 1.7791214014894219

Epoch: 6| Step: 13
Training loss: 0.3955174684524536
Validation loss: 1.7667688349241852

Epoch: 345| Step: 0
Training loss: 0.5606403946876526
Validation loss: 1.8063590795763078

Epoch: 6| Step: 1
Training loss: 0.7256965637207031
Validation loss: 1.8269561439432123

Epoch: 6| Step: 2
Training loss: 0.8288730382919312
Validation loss: 1.8267151835144206

Epoch: 6| Step: 3
Training loss: 0.7422690391540527
Validation loss: 1.885079873505459

Epoch: 6| Step: 4
Training loss: 0.5314613580703735
Validation loss: 1.898233558541985

Epoch: 6| Step: 5
Training loss: 0.5659304857254028
Validation loss: 1.9313020808722383

Epoch: 6| Step: 6
Training loss: 0.9460009336471558
Validation loss: 1.879606382821196

Epoch: 6| Step: 7
Training loss: 0.5086597204208374
Validation loss: 1.8786825287726618

Epoch: 6| Step: 8
Training loss: 0.8176496028900146
Validation loss: 1.8713144410041072

Epoch: 6| Step: 9
Training loss: 0.7915952801704407
Validation loss: 1.856425710903701

Epoch: 6| Step: 10
Training loss: 1.124967098236084
Validation loss: 1.8046082476133942

Epoch: 6| Step: 11
Training loss: 0.6245599389076233
Validation loss: 1.8144350462062384

Epoch: 6| Step: 12
Training loss: 0.5866376161575317
Validation loss: 1.8178795358186126

Epoch: 6| Step: 13
Training loss: 0.5426257252693176
Validation loss: 1.8372246706357567

Epoch: 346| Step: 0
Training loss: 0.6527416706085205
Validation loss: 1.8379677546921598

Epoch: 6| Step: 1
Training loss: 0.4305472671985626
Validation loss: 1.843675736458071

Epoch: 6| Step: 2
Training loss: 0.8705836534500122
Validation loss: 1.8276673542555941

Epoch: 6| Step: 3
Training loss: 0.5867404937744141
Validation loss: 1.8934296677189488

Epoch: 6| Step: 4
Training loss: 0.6588515043258667
Validation loss: 1.824506757079914

Epoch: 6| Step: 5
Training loss: 0.41651660203933716
Validation loss: 1.8224752526129446

Epoch: 6| Step: 6
Training loss: 1.0021620988845825
Validation loss: 1.8447530679805304

Epoch: 6| Step: 7
Training loss: 0.8693099021911621
Validation loss: 1.8565632181782876

Epoch: 6| Step: 8
Training loss: 0.6512182950973511
Validation loss: 1.8553294366405857

Epoch: 6| Step: 9
Training loss: 0.7584378719329834
Validation loss: 1.8383241597042288

Epoch: 6| Step: 10
Training loss: 0.7521713972091675
Validation loss: 1.8415476506756199

Epoch: 6| Step: 11
Training loss: 0.8266927003860474
Validation loss: 1.8267699967148483

Epoch: 6| Step: 12
Training loss: 0.786267876625061
Validation loss: 1.8182414462489467

Epoch: 6| Step: 13
Training loss: 0.6325801610946655
Validation loss: 1.805317755668394

Epoch: 347| Step: 0
Training loss: 0.8435938358306885
Validation loss: 1.820526046137656

Epoch: 6| Step: 1
Training loss: 0.5663029551506042
Validation loss: 1.8587549194212882

Epoch: 6| Step: 2
Training loss: 0.40147802233695984
Validation loss: 1.8547602763739965

Epoch: 6| Step: 3
Training loss: 0.6902387738227844
Validation loss: 1.8310101852622083

Epoch: 6| Step: 4
Training loss: 0.8130500316619873
Validation loss: 1.8855889471628333

Epoch: 6| Step: 5
Training loss: 0.9189156293869019
Validation loss: 1.8829773946474957

Epoch: 6| Step: 6
Training loss: 0.4951789975166321
Validation loss: 1.8843666686806628

Epoch: 6| Step: 7
Training loss: 0.9402363300323486
Validation loss: 1.863379588691137

Epoch: 6| Step: 8
Training loss: 0.5334032773971558
Validation loss: 1.833836506771785

Epoch: 6| Step: 9
Training loss: 0.4772617220878601
Validation loss: 1.7888449225374448

Epoch: 6| Step: 10
Training loss: 0.8287004828453064
Validation loss: 1.809457314911709

Epoch: 6| Step: 11
Training loss: 0.6400339603424072
Validation loss: 1.7743057961105018

Epoch: 6| Step: 12
Training loss: 0.9345318078994751
Validation loss: 1.7945135011467883

Epoch: 6| Step: 13
Training loss: 0.18655602633953094
Validation loss: 1.797484810634326

Epoch: 348| Step: 0
Training loss: 0.4865836799144745
Validation loss: 1.7878536075674079

Epoch: 6| Step: 1
Training loss: 1.121903657913208
Validation loss: 1.8350976346641459

Epoch: 6| Step: 2
Training loss: 0.5620918273925781
Validation loss: 1.8322935283824962

Epoch: 6| Step: 3
Training loss: 0.9471272826194763
Validation loss: 1.8305816381208357

Epoch: 6| Step: 4
Training loss: 0.7813243865966797
Validation loss: 1.889120763347995

Epoch: 6| Step: 5
Training loss: 0.3824482858181
Validation loss: 1.8780502862827753

Epoch: 6| Step: 6
Training loss: 0.47882986068725586
Validation loss: 1.9294290927148634

Epoch: 6| Step: 7
Training loss: 0.7849517464637756
Validation loss: 1.9002743203152892

Epoch: 6| Step: 8
Training loss: 0.4027335047721863
Validation loss: 1.8919653969426309

Epoch: 6| Step: 9
Training loss: 0.8490554094314575
Validation loss: 1.876972262577344

Epoch: 6| Step: 10
Training loss: 0.3511736989021301
Validation loss: 1.8567535684954735

Epoch: 6| Step: 11
Training loss: 0.9918695688247681
Validation loss: 1.8257398425891835

Epoch: 6| Step: 12
Training loss: 0.9220653772354126
Validation loss: 1.8164815107981365

Epoch: 6| Step: 13
Training loss: 0.5186032056808472
Validation loss: 1.8036306660662416

Epoch: 349| Step: 0
Training loss: 0.6845747828483582
Validation loss: 1.7712470575045514

Epoch: 6| Step: 1
Training loss: 0.5175707340240479
Validation loss: 1.8216259684613956

Epoch: 6| Step: 2
Training loss: 0.4298155903816223
Validation loss: 1.8579871885238155

Epoch: 6| Step: 3
Training loss: 0.6672489047050476
Validation loss: 1.8764066234711678

Epoch: 6| Step: 4
Training loss: 0.735321581363678
Validation loss: 1.8607232762921242

Epoch: 6| Step: 5
Training loss: 0.9241795539855957
Validation loss: 1.811519730475641

Epoch: 6| Step: 6
Training loss: 0.9997362494468689
Validation loss: 1.8581106675568448

Epoch: 6| Step: 7
Training loss: 0.782780647277832
Validation loss: 1.858690429759282

Epoch: 6| Step: 8
Training loss: 0.8458392024040222
Validation loss: 1.8383678236315328

Epoch: 6| Step: 9
Training loss: 0.49333691596984863
Validation loss: 1.789125859096486

Epoch: 6| Step: 10
Training loss: 1.1336780786514282
Validation loss: 1.8121598382149973

Epoch: 6| Step: 11
Training loss: 0.6964999437332153
Validation loss: 1.808601761376986

Epoch: 6| Step: 12
Training loss: 0.46760839223861694
Validation loss: 1.7919463675509217

Epoch: 6| Step: 13
Training loss: 0.1617991030216217
Validation loss: 1.8484190253801243

Epoch: 350| Step: 0
Training loss: 0.4052105247974396
Validation loss: 1.8167626345029442

Epoch: 6| Step: 1
Training loss: 0.8977118134498596
Validation loss: 1.830560722658711

Epoch: 6| Step: 2
Training loss: 0.7044994831085205
Validation loss: 1.8296280484045706

Epoch: 6| Step: 3
Training loss: 0.7888848781585693
Validation loss: 1.8092424305536414

Epoch: 6| Step: 4
Training loss: 0.5651324987411499
Validation loss: 1.8066442076877882

Epoch: 6| Step: 5
Training loss: 0.5791009664535522
Validation loss: 1.7957854655481154

Epoch: 6| Step: 6
Training loss: 0.5774128437042236
Validation loss: 1.7972644323943763

Epoch: 6| Step: 7
Training loss: 1.1035449504852295
Validation loss: 1.7836475013404764

Epoch: 6| Step: 8
Training loss: 0.9537519216537476
Validation loss: 1.775393445004699

Epoch: 6| Step: 9
Training loss: 0.5917399525642395
Validation loss: 1.7488160684544554

Epoch: 6| Step: 10
Training loss: 0.8930824995040894
Validation loss: 1.7325666848049368

Epoch: 6| Step: 11
Training loss: 0.6744580268859863
Validation loss: 1.737377275702774

Epoch: 6| Step: 12
Training loss: 0.4912036657333374
Validation loss: 1.7641231090791765

Epoch: 6| Step: 13
Training loss: 0.11107998341321945
Validation loss: 1.7925685708240797

Epoch: 351| Step: 0
Training loss: 0.44922569394111633
Validation loss: 1.8101396676032775

Epoch: 6| Step: 1
Training loss: 1.0609415769577026
Validation loss: 1.8473401351641583

Epoch: 6| Step: 2
Training loss: 0.963790774345398
Validation loss: 1.901067400491366

Epoch: 6| Step: 3
Training loss: 0.7572200298309326
Validation loss: 1.925441934216407

Epoch: 6| Step: 4
Training loss: 0.6975822448730469
Validation loss: 1.8900066908969675

Epoch: 6| Step: 5
Training loss: 0.8657971620559692
Validation loss: 1.84739734408676

Epoch: 6| Step: 6
Training loss: 0.6068812608718872
Validation loss: 1.7773136900317283

Epoch: 6| Step: 7
Training loss: 0.4879664182662964
Validation loss: 1.8203030696479223

Epoch: 6| Step: 8
Training loss: 0.6873457431793213
Validation loss: 1.7420260303763933

Epoch: 6| Step: 9
Training loss: 1.1554174423217773
Validation loss: 1.7967781994932441

Epoch: 6| Step: 10
Training loss: 0.7476482391357422
Validation loss: 1.7745452670640842

Epoch: 6| Step: 11
Training loss: 0.41653725504875183
Validation loss: 1.796863240580405

Epoch: 6| Step: 12
Training loss: 0.2877351939678192
Validation loss: 1.7928736363687823

Epoch: 6| Step: 13
Training loss: 0.7356112599372864
Validation loss: 1.7976892379022413

Epoch: 352| Step: 0
Training loss: 0.7545266151428223
Validation loss: 1.8109944994731615

Epoch: 6| Step: 1
Training loss: 0.7927553653717041
Validation loss: 1.8227328677331247

Epoch: 6| Step: 2
Training loss: 0.5437653064727783
Validation loss: 1.8466690714641283

Epoch: 6| Step: 3
Training loss: 0.50296550989151
Validation loss: 1.8501949105211484

Epoch: 6| Step: 4
Training loss: 0.5021125674247742
Validation loss: 1.8388035066666142

Epoch: 6| Step: 5
Training loss: 0.8966301679611206
Validation loss: 1.860941489537557

Epoch: 6| Step: 6
Training loss: 0.8935961723327637
Validation loss: 1.8569860919829337

Epoch: 6| Step: 7
Training loss: 0.5490692853927612
Validation loss: 1.8316127228480514

Epoch: 6| Step: 8
Training loss: 0.3575848340988159
Validation loss: 1.8133652902418567

Epoch: 6| Step: 9
Training loss: 0.7836905717849731
Validation loss: 1.8218995448081725

Epoch: 6| Step: 10
Training loss: 0.5484756827354431
Validation loss: 1.8489830301653953

Epoch: 6| Step: 11
Training loss: 0.8305962681770325
Validation loss: 1.8308300766893613

Epoch: 6| Step: 12
Training loss: 0.5712413191795349
Validation loss: 1.8463618422067294

Epoch: 6| Step: 13
Training loss: 1.2610385417938232
Validation loss: 1.813393836380333

Epoch: 353| Step: 0
Training loss: 0.6032347083091736
Validation loss: 1.799878192204301

Epoch: 6| Step: 1
Training loss: 0.6056044101715088
Validation loss: 1.8358924260703466

Epoch: 6| Step: 2
Training loss: 0.6134788990020752
Validation loss: 1.7963537221313806

Epoch: 6| Step: 3
Training loss: 0.5159470438957214
Validation loss: 1.8062146427810832

Epoch: 6| Step: 4
Training loss: 0.6890560984611511
Validation loss: 1.8511491488384944

Epoch: 6| Step: 5
Training loss: 0.4877146780490875
Validation loss: 1.897632488640406

Epoch: 6| Step: 6
Training loss: 0.5042675733566284
Validation loss: 1.8810354535297682

Epoch: 6| Step: 7
Training loss: 0.8477314710617065
Validation loss: 1.8570782574274207

Epoch: 6| Step: 8
Training loss: 1.3319612741470337
Validation loss: 1.8200652189152215

Epoch: 6| Step: 9
Training loss: 0.5503221750259399
Validation loss: 1.8116028885687552

Epoch: 6| Step: 10
Training loss: 0.7922569513320923
Validation loss: 1.791517657618369

Epoch: 6| Step: 11
Training loss: 0.7406095266342163
Validation loss: 1.7677467458991594

Epoch: 6| Step: 12
Training loss: 0.8243590593338013
Validation loss: 1.7363911444141018

Epoch: 6| Step: 13
Training loss: 0.6206194162368774
Validation loss: 1.7556539402213147

Epoch: 354| Step: 0
Training loss: 0.44615745544433594
Validation loss: 1.7557493589257682

Epoch: 6| Step: 1
Training loss: 0.8730964660644531
Validation loss: 1.7754833326544812

Epoch: 6| Step: 2
Training loss: 0.6945701837539673
Validation loss: 1.7884968429483392

Epoch: 6| Step: 3
Training loss: 0.769829511642456
Validation loss: 1.7780915755097584

Epoch: 6| Step: 4
Training loss: 0.5054864287376404
Validation loss: 1.7817680553723407

Epoch: 6| Step: 5
Training loss: 0.34360599517822266
Validation loss: 1.8027557929356892

Epoch: 6| Step: 6
Training loss: 0.619168758392334
Validation loss: 1.7934791952051141

Epoch: 6| Step: 7
Training loss: 0.7556504011154175
Validation loss: 1.8174587359992407

Epoch: 6| Step: 8
Training loss: 1.0380359888076782
Validation loss: 1.8366159239122946

Epoch: 6| Step: 9
Training loss: 0.5262421369552612
Validation loss: 1.8520520143611456

Epoch: 6| Step: 10
Training loss: 0.6387432813644409
Validation loss: 1.8452118878723474

Epoch: 6| Step: 11
Training loss: 0.8936669826507568
Validation loss: 1.845356863032105

Epoch: 6| Step: 12
Training loss: 0.5731192827224731
Validation loss: 1.8287020280796995

Epoch: 6| Step: 13
Training loss: 0.6690373420715332
Validation loss: 1.8410325229808848

Epoch: 355| Step: 0
Training loss: 0.595680296421051
Validation loss: 1.8125513740765151

Epoch: 6| Step: 1
Training loss: 0.4288310706615448
Validation loss: 1.810644462544431

Epoch: 6| Step: 2
Training loss: 1.0224382877349854
Validation loss: 1.8121179726815992

Epoch: 6| Step: 3
Training loss: 0.8678301572799683
Validation loss: 1.7950121869323075

Epoch: 6| Step: 4
Training loss: 0.8535985946655273
Validation loss: 1.8032447727777625

Epoch: 6| Step: 5
Training loss: 0.6102963089942932
Validation loss: 1.8387517339439803

Epoch: 6| Step: 6
Training loss: 0.8977003693580627
Validation loss: 1.8299191818442395

Epoch: 6| Step: 7
Training loss: 0.4344998598098755
Validation loss: 1.8389899487136512

Epoch: 6| Step: 8
Training loss: 0.6452111005783081
Validation loss: 1.853014528110463

Epoch: 6| Step: 9
Training loss: 0.7095581293106079
Validation loss: 1.8857676393242293

Epoch: 6| Step: 10
Training loss: 0.536048412322998
Validation loss: 1.8126253645907167

Epoch: 6| Step: 11
Training loss: 0.4477540850639343
Validation loss: 1.8009547648891326

Epoch: 6| Step: 12
Training loss: 0.5167815089225769
Validation loss: 1.7882096293152019

Epoch: 6| Step: 13
Training loss: 0.4398152828216553
Validation loss: 1.7846491362458916

Epoch: 356| Step: 0
Training loss: 0.7423407435417175
Validation loss: 1.7939135477107058

Epoch: 6| Step: 1
Training loss: 0.6988758444786072
Validation loss: 1.7808376768583893

Epoch: 6| Step: 2
Training loss: 0.8503221273422241
Validation loss: 1.78489351272583

Epoch: 6| Step: 3
Training loss: 0.38670098781585693
Validation loss: 1.8027636889488465

Epoch: 6| Step: 4
Training loss: 0.5844354033470154
Validation loss: 1.7893393347340245

Epoch: 6| Step: 5
Training loss: 0.7868670225143433
Validation loss: 1.7930277060436945

Epoch: 6| Step: 6
Training loss: 0.5490984916687012
Validation loss: 1.8056174503859652

Epoch: 6| Step: 7
Training loss: 0.9957359433174133
Validation loss: 1.8285172408626926

Epoch: 6| Step: 8
Training loss: 0.6838583946228027
Validation loss: 1.8782251265741163

Epoch: 6| Step: 9
Training loss: 0.3198148310184479
Validation loss: 1.8430257099930958

Epoch: 6| Step: 10
Training loss: 0.9460675120353699
Validation loss: 1.8093752912295762

Epoch: 6| Step: 11
Training loss: 0.5441548824310303
Validation loss: 1.8177916413994246

Epoch: 6| Step: 12
Training loss: 0.40317368507385254
Validation loss: 1.755686584339347

Epoch: 6| Step: 13
Training loss: 0.7099214792251587
Validation loss: 1.745553142280989

Epoch: 357| Step: 0
Training loss: 0.649614691734314
Validation loss: 1.7243938465272226

Epoch: 6| Step: 1
Training loss: 0.6804519295692444
Validation loss: 1.7539887248828847

Epoch: 6| Step: 2
Training loss: 0.5048491954803467
Validation loss: 1.7318332784919328

Epoch: 6| Step: 3
Training loss: 0.9849676489830017
Validation loss: 1.7624446063913324

Epoch: 6| Step: 4
Training loss: 0.8066167831420898
Validation loss: 1.7741477207470966

Epoch: 6| Step: 5
Training loss: 0.5843713283538818
Validation loss: 1.7891828936915244

Epoch: 6| Step: 6
Training loss: 0.4553382396697998
Validation loss: 1.7841269162393385

Epoch: 6| Step: 7
Training loss: 0.9293215274810791
Validation loss: 1.8371759012181272

Epoch: 6| Step: 8
Training loss: 0.5258619785308838
Validation loss: 1.8365628129692488

Epoch: 6| Step: 9
Training loss: 0.5010374784469604
Validation loss: 1.8472573423898349

Epoch: 6| Step: 10
Training loss: 0.4700775444507599
Validation loss: 1.8463579736730105

Epoch: 6| Step: 11
Training loss: 1.0016555786132812
Validation loss: 1.808490377600475

Epoch: 6| Step: 12
Training loss: 0.4277294874191284
Validation loss: 1.7756640180464713

Epoch: 6| Step: 13
Training loss: 0.6732563376426697
Validation loss: 1.7959205514641219

Epoch: 358| Step: 0
Training loss: 0.43235665559768677
Validation loss: 1.7640214722643617

Epoch: 6| Step: 1
Training loss: 0.7923122644424438
Validation loss: 1.7894257012233938

Epoch: 6| Step: 2
Training loss: 0.5921100378036499
Validation loss: 1.8254100097123014

Epoch: 6| Step: 3
Training loss: 0.8586276769638062
Validation loss: 1.811428801987761

Epoch: 6| Step: 4
Training loss: 0.8855214715003967
Validation loss: 1.8358654258071736

Epoch: 6| Step: 5
Training loss: 0.6256260871887207
Validation loss: 1.8795675359746462

Epoch: 6| Step: 6
Training loss: 0.6558435559272766
Validation loss: 1.8540395498275757

Epoch: 6| Step: 7
Training loss: 0.6081995368003845
Validation loss: 1.8686571839035198

Epoch: 6| Step: 8
Training loss: 0.6323310136795044
Validation loss: 1.8144547093299128

Epoch: 6| Step: 9
Training loss: 0.7275224328041077
Validation loss: 1.829810619354248

Epoch: 6| Step: 10
Training loss: 0.6362448334693909
Validation loss: 1.8067257455600205

Epoch: 6| Step: 11
Training loss: 0.6167320013046265
Validation loss: 1.7956550762217531

Epoch: 6| Step: 12
Training loss: 0.5154082775115967
Validation loss: 1.7934037100884221

Epoch: 6| Step: 13
Training loss: 0.3171226680278778
Validation loss: 1.787326511516366

Epoch: 359| Step: 0
Training loss: 0.5998797416687012
Validation loss: 1.8058448260830295

Epoch: 6| Step: 1
Training loss: 0.6002296805381775
Validation loss: 1.8079569647389073

Epoch: 6| Step: 2
Training loss: 0.7743216156959534
Validation loss: 1.8418602097419001

Epoch: 6| Step: 3
Training loss: 0.9023846387863159
Validation loss: 1.874109898844073

Epoch: 6| Step: 4
Training loss: 0.7431228756904602
Validation loss: 1.833560796194179

Epoch: 6| Step: 5
Training loss: 0.5748206973075867
Validation loss: 1.840606362588944

Epoch: 6| Step: 6
Training loss: 0.6503495573997498
Validation loss: 1.831786048027777

Epoch: 6| Step: 7
Training loss: 0.6914474964141846
Validation loss: 1.8277947877043037

Epoch: 6| Step: 8
Training loss: 0.7040844559669495
Validation loss: 1.7718619351745934

Epoch: 6| Step: 9
Training loss: 0.862912654876709
Validation loss: 1.763803166727866

Epoch: 6| Step: 10
Training loss: 0.43201881647109985
Validation loss: 1.7565445630781111

Epoch: 6| Step: 11
Training loss: 0.5026659369468689
Validation loss: 1.7452638354352725

Epoch: 6| Step: 12
Training loss: 0.7454817295074463
Validation loss: 1.7578067715449999

Epoch: 6| Step: 13
Training loss: 0.23578354716300964
Validation loss: 1.7814315493388841

Epoch: 360| Step: 0
Training loss: 0.6557954549789429
Validation loss: 1.8001157776001961

Epoch: 6| Step: 1
Training loss: 0.5044713020324707
Validation loss: 1.8657128426336473

Epoch: 6| Step: 2
Training loss: 0.8456029891967773
Validation loss: 1.9130236871780888

Epoch: 6| Step: 3
Training loss: 0.49094218015670776
Validation loss: 1.9483808637947164

Epoch: 6| Step: 4
Training loss: 0.6882619261741638
Validation loss: 1.9286254503393685

Epoch: 6| Step: 5
Training loss: 1.0237040519714355
Validation loss: 1.9093393202750915

Epoch: 6| Step: 6
Training loss: 0.7161744832992554
Validation loss: 1.8691843837820075

Epoch: 6| Step: 7
Training loss: 0.41792309284210205
Validation loss: 1.8439221664141583

Epoch: 6| Step: 8
Training loss: 0.5220696926116943
Validation loss: 1.77868906528719

Epoch: 6| Step: 9
Training loss: 0.5718868374824524
Validation loss: 1.7438006503607637

Epoch: 6| Step: 10
Training loss: 0.6014255285263062
Validation loss: 1.728282033756215

Epoch: 6| Step: 11
Training loss: 0.8986177444458008
Validation loss: 1.7360469231041529

Epoch: 6| Step: 12
Training loss: 0.6299291253089905
Validation loss: 1.7449416447711248

Epoch: 6| Step: 13
Training loss: 0.8603203892707825
Validation loss: 1.7305448144994757

Epoch: 361| Step: 0
Training loss: 0.6606258749961853
Validation loss: 1.7492998838424683

Epoch: 6| Step: 1
Training loss: 0.5659629106521606
Validation loss: 1.7788099524795369

Epoch: 6| Step: 2
Training loss: 0.5640186667442322
Validation loss: 1.7677017898969754

Epoch: 6| Step: 3
Training loss: 0.8077288866043091
Validation loss: 1.8122421746612878

Epoch: 6| Step: 4
Training loss: 0.7273770570755005
Validation loss: 1.8799842019234934

Epoch: 6| Step: 5
Training loss: 0.961310863494873
Validation loss: 1.8348367432112336

Epoch: 6| Step: 6
Training loss: 0.49455127120018005
Validation loss: 1.868481687320176

Epoch: 6| Step: 7
Training loss: 0.931914210319519
Validation loss: 1.8399868870294223

Epoch: 6| Step: 8
Training loss: 0.5041676163673401
Validation loss: 1.8031871716181438

Epoch: 6| Step: 9
Training loss: 0.5474209189414978
Validation loss: 1.7785417341416883

Epoch: 6| Step: 10
Training loss: 0.42923063039779663
Validation loss: 1.766711405528489

Epoch: 6| Step: 11
Training loss: 0.7540459632873535
Validation loss: 1.7762919138836604

Epoch: 6| Step: 12
Training loss: 0.45925503969192505
Validation loss: 1.7623912647206297

Epoch: 6| Step: 13
Training loss: 0.6253857612609863
Validation loss: 1.7528211198827273

Epoch: 362| Step: 0
Training loss: 0.692008376121521
Validation loss: 1.7700481953159455

Epoch: 6| Step: 1
Training loss: 0.44200393557548523
Validation loss: 1.741816815509591

Epoch: 6| Step: 2
Training loss: 0.5146028995513916
Validation loss: 1.7633466656490038

Epoch: 6| Step: 3
Training loss: 0.8619740009307861
Validation loss: 1.7764543858907555

Epoch: 6| Step: 4
Training loss: 0.4124927818775177
Validation loss: 1.7892917497183687

Epoch: 6| Step: 5
Training loss: 0.7089284658432007
Validation loss: 1.8122838594580208

Epoch: 6| Step: 6
Training loss: 0.7644023895263672
Validation loss: 1.7979479284696682

Epoch: 6| Step: 7
Training loss: 0.7656775712966919
Validation loss: 1.8120618122880177

Epoch: 6| Step: 8
Training loss: 0.5513560771942139
Validation loss: 1.8326808509006296

Epoch: 6| Step: 9
Training loss: 0.6131834387779236
Validation loss: 1.8042205969492595

Epoch: 6| Step: 10
Training loss: 0.5973830223083496
Validation loss: 1.8279884015360186

Epoch: 6| Step: 11
Training loss: 0.5978893041610718
Validation loss: 1.828220034158358

Epoch: 6| Step: 12
Training loss: 0.8785656690597534
Validation loss: 1.8331601901720929

Epoch: 6| Step: 13
Training loss: 0.26029321551322937
Validation loss: 1.8334196511135306

Epoch: 363| Step: 0
Training loss: 0.41094478964805603
Validation loss: 1.8620972428270566

Epoch: 6| Step: 1
Training loss: 0.6234149932861328
Validation loss: 1.8438671314588158

Epoch: 6| Step: 2
Training loss: 1.0568971633911133
Validation loss: 1.841204265112518

Epoch: 6| Step: 3
Training loss: 0.5127986669540405
Validation loss: 1.8226304541351974

Epoch: 6| Step: 4
Training loss: 0.6078946590423584
Validation loss: 1.8543254662585515

Epoch: 6| Step: 5
Training loss: 0.6149711012840271
Validation loss: 1.836500024282804

Epoch: 6| Step: 6
Training loss: 0.7500104308128357
Validation loss: 1.8080961947800012

Epoch: 6| Step: 7
Training loss: 0.5844091176986694
Validation loss: 1.8105369075652091

Epoch: 6| Step: 8
Training loss: 0.642001748085022
Validation loss: 1.7956132042792536

Epoch: 6| Step: 9
Training loss: 0.8284279108047485
Validation loss: 1.7720252429285357

Epoch: 6| Step: 10
Training loss: 0.5836454629898071
Validation loss: 1.794394305957261

Epoch: 6| Step: 11
Training loss: 0.602297842502594
Validation loss: 1.7804364388988865

Epoch: 6| Step: 12
Training loss: 0.34698495268821716
Validation loss: 1.7785885289151182

Epoch: 6| Step: 13
Training loss: 0.5934664011001587
Validation loss: 1.7857804657310568

Epoch: 364| Step: 0
Training loss: 0.5810103416442871
Validation loss: 1.841932442880446

Epoch: 6| Step: 1
Training loss: 0.6966740489006042
Validation loss: 1.8780161949896044

Epoch: 6| Step: 2
Training loss: 0.31687068939208984
Validation loss: 1.8879240456447806

Epoch: 6| Step: 3
Training loss: 0.7926872372627258
Validation loss: 1.8927984327398322

Epoch: 6| Step: 4
Training loss: 0.9062264561653137
Validation loss: 1.855317706702858

Epoch: 6| Step: 5
Training loss: 0.25548043847084045
Validation loss: 1.8067832672467796

Epoch: 6| Step: 6
Training loss: 1.014716386795044
Validation loss: 1.7657804604499572

Epoch: 6| Step: 7
Training loss: 0.7435026168823242
Validation loss: 1.8016557424299178

Epoch: 6| Step: 8
Training loss: 0.7775144577026367
Validation loss: 1.7866462328100716

Epoch: 6| Step: 9
Training loss: 0.6279400587081909
Validation loss: 1.778006769636626

Epoch: 6| Step: 10
Training loss: 0.5283826589584351
Validation loss: 1.7959449880866594

Epoch: 6| Step: 11
Training loss: 0.5008030533790588
Validation loss: 1.762169986642817

Epoch: 6| Step: 12
Training loss: 0.7956928014755249
Validation loss: 1.796164838216638

Epoch: 6| Step: 13
Training loss: 0.18888571858406067
Validation loss: 1.7743511687042892

Epoch: 365| Step: 0
Training loss: 0.7342419028282166
Validation loss: 1.8186225224566717

Epoch: 6| Step: 1
Training loss: 0.7127472162246704
Validation loss: 1.8531381724983134

Epoch: 6| Step: 2
Training loss: 0.3673985004425049
Validation loss: 1.8917759490269486

Epoch: 6| Step: 3
Training loss: 0.929742157459259
Validation loss: 1.929031047769772

Epoch: 6| Step: 4
Training loss: 0.5289778113365173
Validation loss: 1.916147534565259

Epoch: 6| Step: 5
Training loss: 0.7837996482849121
Validation loss: 1.916660310119711

Epoch: 6| Step: 6
Training loss: 0.412550687789917
Validation loss: 1.862191802711897

Epoch: 6| Step: 7
Training loss: 0.3976461589336395
Validation loss: 1.846434804701036

Epoch: 6| Step: 8
Training loss: 0.46067512035369873
Validation loss: 1.8087116185054983

Epoch: 6| Step: 9
Training loss: 0.52649986743927
Validation loss: 1.7653922239939372

Epoch: 6| Step: 10
Training loss: 0.64644455909729
Validation loss: 1.755313322108279

Epoch: 6| Step: 11
Training loss: 0.7138082981109619
Validation loss: 1.754944142474923

Epoch: 6| Step: 12
Training loss: 0.6697489023208618
Validation loss: 1.7757425000590663

Epoch: 6| Step: 13
Training loss: 1.4562662839889526
Validation loss: 1.763816701468601

Epoch: 366| Step: 0
Training loss: 0.308076947927475
Validation loss: 1.7575563564095447

Epoch: 6| Step: 1
Training loss: 0.8184897303581238
Validation loss: 1.7788219964632423

Epoch: 6| Step: 2
Training loss: 0.5684013962745667
Validation loss: 1.7909773113907024

Epoch: 6| Step: 3
Training loss: 0.7096307873725891
Validation loss: 1.7951749960581462

Epoch: 6| Step: 4
Training loss: 0.6909842491149902
Validation loss: 1.8688848210919289

Epoch: 6| Step: 5
Training loss: 0.9459114074707031
Validation loss: 1.894930193501134

Epoch: 6| Step: 6
Training loss: 0.8502782583236694
Validation loss: 1.8826566973040182

Epoch: 6| Step: 7
Training loss: 0.44514843821525574
Validation loss: 1.8740031283388856

Epoch: 6| Step: 8
Training loss: 0.5170665979385376
Validation loss: 1.8346506088010726

Epoch: 6| Step: 9
Training loss: 0.5294748544692993
Validation loss: 1.839335036534135

Epoch: 6| Step: 10
Training loss: 0.6107392311096191
Validation loss: 1.813511876649754

Epoch: 6| Step: 11
Training loss: 0.8204803466796875
Validation loss: 1.7815930074261082

Epoch: 6| Step: 12
Training loss: 0.6951785683631897
Validation loss: 1.7550693891381706

Epoch: 6| Step: 13
Training loss: 0.1658371537923813
Validation loss: 1.7925098378171203

Epoch: 367| Step: 0
Training loss: 0.7941367030143738
Validation loss: 1.7648413271032355

Epoch: 6| Step: 1
Training loss: 0.6687873005867004
Validation loss: 1.7817120244426112

Epoch: 6| Step: 2
Training loss: 0.7489012479782104
Validation loss: 1.742611510779268

Epoch: 6| Step: 3
Training loss: 0.36600542068481445
Validation loss: 1.7935752740470312

Epoch: 6| Step: 4
Training loss: 0.7534739375114441
Validation loss: 1.8018342641092115

Epoch: 6| Step: 5
Training loss: 0.5170868039131165
Validation loss: 1.7858233067297167

Epoch: 6| Step: 6
Training loss: 0.6591274738311768
Validation loss: 1.8128489294359762

Epoch: 6| Step: 7
Training loss: 0.2589326798915863
Validation loss: 1.7923658663226711

Epoch: 6| Step: 8
Training loss: 0.6443091034889221
Validation loss: 1.7987478561298822

Epoch: 6| Step: 9
Training loss: 0.6915616989135742
Validation loss: 1.802041571627381

Epoch: 6| Step: 10
Training loss: 0.6505547761917114
Validation loss: 1.818615908263832

Epoch: 6| Step: 11
Training loss: 0.8972077369689941
Validation loss: 1.801131643274779

Epoch: 6| Step: 12
Training loss: 0.5548692941665649
Validation loss: 1.7736498540447605

Epoch: 6| Step: 13
Training loss: 0.27767935395240784
Validation loss: 1.7713927966292187

Epoch: 368| Step: 0
Training loss: 1.1966233253479004
Validation loss: 1.7491599680275045

Epoch: 6| Step: 1
Training loss: 0.6945125460624695
Validation loss: 1.7674498993863341

Epoch: 6| Step: 2
Training loss: 0.2713685631752014
Validation loss: 1.738801061466176

Epoch: 6| Step: 3
Training loss: 0.5343614816665649
Validation loss: 1.7693433735960273

Epoch: 6| Step: 4
Training loss: 0.5962704420089722
Validation loss: 1.7733790002843386

Epoch: 6| Step: 5
Training loss: 0.6079411506652832
Validation loss: 1.8050922629653767

Epoch: 6| Step: 6
Training loss: 0.6251695156097412
Validation loss: 1.7652508674129364

Epoch: 6| Step: 7
Training loss: 0.8279039263725281
Validation loss: 1.7894216532348304

Epoch: 6| Step: 8
Training loss: 0.6241641640663147
Validation loss: 1.788437097303329

Epoch: 6| Step: 9
Training loss: 0.5001915693283081
Validation loss: 1.8191413135938748

Epoch: 6| Step: 10
Training loss: 1.0393606424331665
Validation loss: 1.8069414797649588

Epoch: 6| Step: 11
Training loss: 0.33493340015411377
Validation loss: 1.808013887815578

Epoch: 6| Step: 12
Training loss: 0.29082971811294556
Validation loss: 1.8126998562966623

Epoch: 6| Step: 13
Training loss: 0.18980653584003448
Validation loss: 1.8066576732102262

Epoch: 369| Step: 0
Training loss: 0.8092149496078491
Validation loss: 1.8276810312783847

Epoch: 6| Step: 1
Training loss: 0.48011234402656555
Validation loss: 1.8355571441752936

Epoch: 6| Step: 2
Training loss: 0.5470513105392456
Validation loss: 1.8494206154218285

Epoch: 6| Step: 3
Training loss: 0.30533766746520996
Validation loss: 1.8092177119306339

Epoch: 6| Step: 4
Training loss: 0.5132091045379639
Validation loss: 1.816164226942165

Epoch: 6| Step: 5
Training loss: 0.41502857208251953
Validation loss: 1.814993360991119

Epoch: 6| Step: 6
Training loss: 0.7683088779449463
Validation loss: 1.7660571285473403

Epoch: 6| Step: 7
Training loss: 0.8419604301452637
Validation loss: 1.7756319122929727

Epoch: 6| Step: 8
Training loss: 0.6237783432006836
Validation loss: 1.7860171410345262

Epoch: 6| Step: 9
Training loss: 0.6305682063102722
Validation loss: 1.7654115897352978

Epoch: 6| Step: 10
Training loss: 0.6273936629295349
Validation loss: 1.7665190312170214

Epoch: 6| Step: 11
Training loss: 0.7752104997634888
Validation loss: 1.821907836903808

Epoch: 6| Step: 12
Training loss: 0.6219753623008728
Validation loss: 1.8397953766648487

Epoch: 6| Step: 13
Training loss: 0.44233882427215576
Validation loss: 1.8525779657466437

Epoch: 370| Step: 0
Training loss: 0.6187710165977478
Validation loss: 1.8845611438956311

Epoch: 6| Step: 1
Training loss: 0.45336800813674927
Validation loss: 1.8430688688831944

Epoch: 6| Step: 2
Training loss: 0.43313056230545044
Validation loss: 1.826100278926152

Epoch: 6| Step: 3
Training loss: 0.7785198092460632
Validation loss: 1.7965786764698644

Epoch: 6| Step: 4
Training loss: 0.4755927622318268
Validation loss: 1.8168468616342033

Epoch: 6| Step: 5
Training loss: 0.3789042830467224
Validation loss: 1.7946318823804137

Epoch: 6| Step: 6
Training loss: 0.45851215720176697
Validation loss: 1.771204871516074

Epoch: 6| Step: 7
Training loss: 0.5482079386711121
Validation loss: 1.775318153442875

Epoch: 6| Step: 8
Training loss: 1.1144325733184814
Validation loss: 1.7880077285151328

Epoch: 6| Step: 9
Training loss: 0.7511746287345886
Validation loss: 1.8105387521046463

Epoch: 6| Step: 10
Training loss: 0.5480583906173706
Validation loss: 1.8060862492489558

Epoch: 6| Step: 11
Training loss: 0.4115843176841736
Validation loss: 1.782833130128922

Epoch: 6| Step: 12
Training loss: 0.9364964962005615
Validation loss: 1.8219311006607548

Epoch: 6| Step: 13
Training loss: 0.790948748588562
Validation loss: 1.8445652300311672

Epoch: 371| Step: 0
Training loss: 0.5544308423995972
Validation loss: 1.790620582078093

Epoch: 6| Step: 1
Training loss: 0.7104474306106567
Validation loss: 1.7665782795157483

Epoch: 6| Step: 2
Training loss: 0.4245718717575073
Validation loss: 1.7749206571168796

Epoch: 6| Step: 3
Training loss: 0.6350698471069336
Validation loss: 1.776492303417575

Epoch: 6| Step: 4
Training loss: 0.7379088997840881
Validation loss: 1.7628901735428841

Epoch: 6| Step: 5
Training loss: 0.27217820286750793
Validation loss: 1.7894097130785707

Epoch: 6| Step: 6
Training loss: 0.5502877235412598
Validation loss: 1.7654274778981363

Epoch: 6| Step: 7
Training loss: 0.720792829990387
Validation loss: 1.7823777634610412

Epoch: 6| Step: 8
Training loss: 0.6310701370239258
Validation loss: 1.7525424906002578

Epoch: 6| Step: 9
Training loss: 0.7978619337081909
Validation loss: 1.7570637131250033

Epoch: 6| Step: 10
Training loss: 0.6378426551818848
Validation loss: 1.7815974630335325

Epoch: 6| Step: 11
Training loss: 0.4880926311016083
Validation loss: 1.7606523600957726

Epoch: 6| Step: 12
Training loss: 0.5130431652069092
Validation loss: 1.7499988758435814

Epoch: 6| Step: 13
Training loss: 0.7290304899215698
Validation loss: 1.7655034372883458

Epoch: 372| Step: 0
Training loss: 0.7225026488304138
Validation loss: 1.7449436738926878

Epoch: 6| Step: 1
Training loss: 0.5482465028762817
Validation loss: 1.7439191495218584

Epoch: 6| Step: 2
Training loss: 0.7107073664665222
Validation loss: 1.7762702665021342

Epoch: 6| Step: 3
Training loss: 0.3153381943702698
Validation loss: 1.8107249736785889

Epoch: 6| Step: 4
Training loss: 0.47990554571151733
Validation loss: 1.7986515286148235

Epoch: 6| Step: 5
Training loss: 0.3923351466655731
Validation loss: 1.8520470921711256

Epoch: 6| Step: 6
Training loss: 0.8169810771942139
Validation loss: 1.8857410441162765

Epoch: 6| Step: 7
Training loss: 0.818397581577301
Validation loss: 1.9049585788480696

Epoch: 6| Step: 8
Training loss: 0.46310725808143616
Validation loss: 1.8609598054680774

Epoch: 6| Step: 9
Training loss: 0.5742462277412415
Validation loss: 1.860645773590252

Epoch: 6| Step: 10
Training loss: 0.842439591884613
Validation loss: 1.819778807701603

Epoch: 6| Step: 11
Training loss: 0.46452438831329346
Validation loss: 1.7468530003742506

Epoch: 6| Step: 12
Training loss: 0.8833911418914795
Validation loss: 1.7655400165947535

Epoch: 6| Step: 13
Training loss: 0.8226561546325684
Validation loss: 1.7739531173500964

Epoch: 373| Step: 0
Training loss: 0.4198436737060547
Validation loss: 1.7425568116608487

Epoch: 6| Step: 1
Training loss: 0.4349433481693268
Validation loss: 1.74753092053116

Epoch: 6| Step: 2
Training loss: 0.8853955268859863
Validation loss: 1.7681698132586736

Epoch: 6| Step: 3
Training loss: 0.4011349678039551
Validation loss: 1.7390866202692832

Epoch: 6| Step: 4
Training loss: 0.548946738243103
Validation loss: 1.7461665112485167

Epoch: 6| Step: 5
Training loss: 0.8464601039886475
Validation loss: 1.7915169090353034

Epoch: 6| Step: 6
Training loss: 0.8445457220077515
Validation loss: 1.8077480017497976

Epoch: 6| Step: 7
Training loss: 0.7211062908172607
Validation loss: 1.7679426490619619

Epoch: 6| Step: 8
Training loss: 0.5943418145179749
Validation loss: 1.793216597649359

Epoch: 6| Step: 9
Training loss: 0.8672547340393066
Validation loss: 1.7641526101737894

Epoch: 6| Step: 10
Training loss: 0.7273517847061157
Validation loss: 1.766247841619676

Epoch: 6| Step: 11
Training loss: 0.6277309060096741
Validation loss: 1.7571362782550115

Epoch: 6| Step: 12
Training loss: 0.3118780553340912
Validation loss: 1.7653899615810764

Epoch: 6| Step: 13
Training loss: 0.5287654995918274
Validation loss: 1.811220989432386

Epoch: 374| Step: 0
Training loss: 0.7176144123077393
Validation loss: 1.78628368531504

Epoch: 6| Step: 1
Training loss: 0.7423142194747925
Validation loss: 1.7807728372594362

Epoch: 6| Step: 2
Training loss: 1.2837783098220825
Validation loss: 1.7607577808441655

Epoch: 6| Step: 3
Training loss: 0.8923423886299133
Validation loss: 1.7654804286136423

Epoch: 6| Step: 4
Training loss: 0.5750808715820312
Validation loss: 1.7548652977071784

Epoch: 6| Step: 5
Training loss: 0.7386248111724854
Validation loss: 1.7520570793459493

Epoch: 6| Step: 6
Training loss: 0.7402942776679993
Validation loss: 1.7725605054568219

Epoch: 6| Step: 7
Training loss: 0.689042866230011
Validation loss: 1.7928998880488898

Epoch: 6| Step: 8
Training loss: 0.7181215286254883
Validation loss: 1.8087192055999592

Epoch: 6| Step: 9
Training loss: 0.5722624063491821
Validation loss: 1.8298155479533698

Epoch: 6| Step: 10
Training loss: 0.29885804653167725
Validation loss: 1.8053110466208508

Epoch: 6| Step: 11
Training loss: 0.5760602951049805
Validation loss: 1.8007370784718504

Epoch: 6| Step: 12
Training loss: 0.241972416639328
Validation loss: 1.745927644032304

Epoch: 6| Step: 13
Training loss: 0.5231176018714905
Validation loss: 1.7307509940157655

Epoch: 375| Step: 0
Training loss: 0.7061930894851685
Validation loss: 1.7032632494485507

Epoch: 6| Step: 1
Training loss: 0.6905499696731567
Validation loss: 1.7097564692138343

Epoch: 6| Step: 2
Training loss: 0.9058226346969604
Validation loss: 1.7285020941047258

Epoch: 6| Step: 3
Training loss: 0.4372289180755615
Validation loss: 1.7507943171326832

Epoch: 6| Step: 4
Training loss: 0.6303582787513733
Validation loss: 1.7458496350114063

Epoch: 6| Step: 5
Training loss: 0.49271583557128906
Validation loss: 1.7774277079489924

Epoch: 6| Step: 6
Training loss: 0.33500292897224426
Validation loss: 1.7796425665578535

Epoch: 6| Step: 7
Training loss: 0.3376278877258301
Validation loss: 1.7822885231305194

Epoch: 6| Step: 8
Training loss: 0.49355581402778625
Validation loss: 1.7403051942907355

Epoch: 6| Step: 9
Training loss: 0.5492546558380127
Validation loss: 1.7503946083848194

Epoch: 6| Step: 10
Training loss: 0.7945811748504639
Validation loss: 1.766374188084756

Epoch: 6| Step: 11
Training loss: 0.448566198348999
Validation loss: 1.7680214938297067

Epoch: 6| Step: 12
Training loss: 0.5588458776473999
Validation loss: 1.7821122907823133

Epoch: 6| Step: 13
Training loss: 1.0723929405212402
Validation loss: 1.774214099171341

Epoch: 376| Step: 0
Training loss: 0.5074390172958374
Validation loss: 1.7802527476382513

Epoch: 6| Step: 1
Training loss: 0.7733299732208252
Validation loss: 1.834198578711479

Epoch: 6| Step: 2
Training loss: 0.5695505142211914
Validation loss: 1.8341333468755086

Epoch: 6| Step: 3
Training loss: 0.6750434041023254
Validation loss: 1.8530907784738848

Epoch: 6| Step: 4
Training loss: 0.525117039680481
Validation loss: 1.8773284906982093

Epoch: 6| Step: 5
Training loss: 0.6522918939590454
Validation loss: 1.8285896573015439

Epoch: 6| Step: 6
Training loss: 0.31893622875213623
Validation loss: 1.7918528446587183

Epoch: 6| Step: 7
Training loss: 0.7688102722167969
Validation loss: 1.8179629784758373

Epoch: 6| Step: 8
Training loss: 0.6111804246902466
Validation loss: 1.8240463669582079

Epoch: 6| Step: 9
Training loss: 0.4513801336288452
Validation loss: 1.809656568752822

Epoch: 6| Step: 10
Training loss: 0.5255882143974304
Validation loss: 1.7709519094036472

Epoch: 6| Step: 11
Training loss: 0.7715179920196533
Validation loss: 1.7800196588680308

Epoch: 6| Step: 12
Training loss: 0.5056257247924805
Validation loss: 1.754448301048689

Epoch: 6| Step: 13
Training loss: 0.6371157765388489
Validation loss: 1.74391225717401

Epoch: 377| Step: 0
Training loss: 0.6277295351028442
Validation loss: 1.76019077275389

Epoch: 6| Step: 1
Training loss: 0.514034628868103
Validation loss: 1.7824793015756915

Epoch: 6| Step: 2
Training loss: 0.8351110219955444
Validation loss: 1.7849169777285667

Epoch: 6| Step: 3
Training loss: 0.6041719913482666
Validation loss: 1.8311247300076228

Epoch: 6| Step: 4
Training loss: 0.5625367760658264
Validation loss: 1.8149793199313584

Epoch: 6| Step: 5
Training loss: 0.6526821851730347
Validation loss: 1.8033580446756015

Epoch: 6| Step: 6
Training loss: 0.3524247109889984
Validation loss: 1.7823640454200007

Epoch: 6| Step: 7
Training loss: 0.6273804903030396
Validation loss: 1.7905599840225712

Epoch: 6| Step: 8
Training loss: 0.6615643501281738
Validation loss: 1.789992086348995

Epoch: 6| Step: 9
Training loss: 0.7580221891403198
Validation loss: 1.81966995680204

Epoch: 6| Step: 10
Training loss: 0.6655944585800171
Validation loss: 1.7933728605188348

Epoch: 6| Step: 11
Training loss: 0.4289162755012512
Validation loss: 1.7531964278990222

Epoch: 6| Step: 12
Training loss: 0.5222439765930176
Validation loss: 1.767212337063205

Epoch: 6| Step: 13
Training loss: 0.37301886081695557
Validation loss: 1.732788739665862

Epoch: 378| Step: 0
Training loss: 0.5407401919364929
Validation loss: 1.754458926057303

Epoch: 6| Step: 1
Training loss: 0.6504703760147095
Validation loss: 1.780764070890283

Epoch: 6| Step: 2
Training loss: 0.49707990884780884
Validation loss: 1.7683995910870132

Epoch: 6| Step: 3
Training loss: 0.692718505859375
Validation loss: 1.7858756998533845

Epoch: 6| Step: 4
Training loss: 0.4119988977909088
Validation loss: 1.7744724212154266

Epoch: 6| Step: 5
Training loss: 0.2726513743400574
Validation loss: 1.8068657382842033

Epoch: 6| Step: 6
Training loss: 0.626450777053833
Validation loss: 1.8137784978394866

Epoch: 6| Step: 7
Training loss: 0.6031200289726257
Validation loss: 1.8055018840297576

Epoch: 6| Step: 8
Training loss: 0.5154969692230225
Validation loss: 1.7645860654051586

Epoch: 6| Step: 9
Training loss: 0.8638384342193604
Validation loss: 1.7710427481641051

Epoch: 6| Step: 10
Training loss: 0.7977637052536011
Validation loss: 1.7669907603212582

Epoch: 6| Step: 11
Training loss: 0.4594683349132538
Validation loss: 1.716996972278882

Epoch: 6| Step: 12
Training loss: 0.7093213796615601
Validation loss: 1.7283591301210466

Epoch: 6| Step: 13
Training loss: 0.5892400741577148
Validation loss: 1.7326177627809587

Epoch: 379| Step: 0
Training loss: 0.8571921586990356
Validation loss: 1.7613051027380011

Epoch: 6| Step: 1
Training loss: 0.12253594398498535
Validation loss: 1.7521442828639862

Epoch: 6| Step: 2
Training loss: 0.6030049324035645
Validation loss: 1.7403548058643137

Epoch: 6| Step: 3
Training loss: 0.5976543426513672
Validation loss: 1.7889154829004759

Epoch: 6| Step: 4
Training loss: 0.8848632574081421
Validation loss: 1.7993344414618708

Epoch: 6| Step: 5
Training loss: 0.37471306324005127
Validation loss: 1.7841831830240065

Epoch: 6| Step: 6
Training loss: 0.4590913951396942
Validation loss: 1.7679695019157984

Epoch: 6| Step: 7
Training loss: 0.5807915329933167
Validation loss: 1.7875565162269018

Epoch: 6| Step: 8
Training loss: 0.9942706227302551
Validation loss: 1.731200050282222

Epoch: 6| Step: 9
Training loss: 0.6034978628158569
Validation loss: 1.7750583438463108

Epoch: 6| Step: 10
Training loss: 0.4933704733848572
Validation loss: 1.7761898925227504

Epoch: 6| Step: 11
Training loss: 0.570203423500061
Validation loss: 1.8059195074983823

Epoch: 6| Step: 12
Training loss: 0.6077615022659302
Validation loss: 1.784602037040136

Epoch: 6| Step: 13
Training loss: 0.32619813084602356
Validation loss: 1.7697842428761144

Epoch: 380| Step: 0
Training loss: 0.8218589425086975
Validation loss: 1.7800555549642092

Epoch: 6| Step: 1
Training loss: 0.6026047468185425
Validation loss: 1.8001394271850586

Epoch: 6| Step: 2
Training loss: 0.507398247718811
Validation loss: 1.809581906564774

Epoch: 6| Step: 3
Training loss: 0.6753568649291992
Validation loss: 1.8334188153666835

Epoch: 6| Step: 4
Training loss: 0.5481454730033875
Validation loss: 1.8174044880815732

Epoch: 6| Step: 5
Training loss: 0.4016071856021881
Validation loss: 1.7967973832161195

Epoch: 6| Step: 6
Training loss: 0.5814963579177856
Validation loss: 1.8012340735363703

Epoch: 6| Step: 7
Training loss: 0.6561917066574097
Validation loss: 1.7417157247502317

Epoch: 6| Step: 8
Training loss: 0.8338807821273804
Validation loss: 1.7592103327474287

Epoch: 6| Step: 9
Training loss: 0.8315623998641968
Validation loss: 1.7916527883980864

Epoch: 6| Step: 10
Training loss: 0.3912816047668457
Validation loss: 1.769723617902366

Epoch: 6| Step: 11
Training loss: 0.481218159198761
Validation loss: 1.7440000016202208

Epoch: 6| Step: 12
Training loss: 0.22184991836547852
Validation loss: 1.7645035866768128

Epoch: 6| Step: 13
Training loss: 0.6748171448707581
Validation loss: 1.754462944563999

Epoch: 381| Step: 0
Training loss: 0.2617873549461365
Validation loss: 1.7798548847116449

Epoch: 6| Step: 1
Training loss: 0.705170750617981
Validation loss: 1.8220598851480792

Epoch: 6| Step: 2
Training loss: 0.5705426931381226
Validation loss: 1.8214620877337713

Epoch: 6| Step: 3
Training loss: 0.3801029622554779
Validation loss: 1.802941410772262

Epoch: 6| Step: 4
Training loss: 0.7539554834365845
Validation loss: 1.8160909875746696

Epoch: 6| Step: 5
Training loss: 0.5081565380096436
Validation loss: 1.7863574348470217

Epoch: 6| Step: 6
Training loss: 0.5994607210159302
Validation loss: 1.7410245069893457

Epoch: 6| Step: 7
Training loss: 0.7525908946990967
Validation loss: 1.763646351393833

Epoch: 6| Step: 8
Training loss: 0.7768605947494507
Validation loss: 1.7537799483986312

Epoch: 6| Step: 9
Training loss: 0.5169535875320435
Validation loss: 1.7585708595091296

Epoch: 6| Step: 10
Training loss: 0.583946943283081
Validation loss: 1.7296880714354976

Epoch: 6| Step: 11
Training loss: 0.437690794467926
Validation loss: 1.749608483365787

Epoch: 6| Step: 12
Training loss: 0.46363377571105957
Validation loss: 1.7384112214529386

Epoch: 6| Step: 13
Training loss: 0.6940942406654358
Validation loss: 1.7053699301135155

Epoch: 382| Step: 0
Training loss: 0.6783919334411621
Validation loss: 1.6819145320564188

Epoch: 6| Step: 1
Training loss: 0.7127678394317627
Validation loss: 1.7300476335710095

Epoch: 6| Step: 2
Training loss: 0.4492245316505432
Validation loss: 1.7346073658235612

Epoch: 6| Step: 3
Training loss: 0.6628812551498413
Validation loss: 1.7164257149542532

Epoch: 6| Step: 4
Training loss: 0.49450603127479553
Validation loss: 1.742955356515864

Epoch: 6| Step: 5
Training loss: 0.5998647212982178
Validation loss: 1.767544291352713

Epoch: 6| Step: 6
Training loss: 0.4056450128555298
Validation loss: 1.7731661418432831

Epoch: 6| Step: 7
Training loss: 0.6835728883743286
Validation loss: 1.8102239319073257

Epoch: 6| Step: 8
Training loss: 0.5384237766265869
Validation loss: 1.7567840571044593

Epoch: 6| Step: 9
Training loss: 0.37171003222465515
Validation loss: 1.7524299967673518

Epoch: 6| Step: 10
Training loss: 0.44999825954437256
Validation loss: 1.7758157560902257

Epoch: 6| Step: 11
Training loss: 0.745513916015625
Validation loss: 1.7470515030686573

Epoch: 6| Step: 12
Training loss: 0.6496590375900269
Validation loss: 1.7748305028484714

Epoch: 6| Step: 13
Training loss: 0.644514799118042
Validation loss: 1.7787380090323828

Epoch: 383| Step: 0
Training loss: 0.4772733747959137
Validation loss: 1.7498197209450506

Epoch: 6| Step: 1
Training loss: 0.6555085182189941
Validation loss: 1.7457721387186358

Epoch: 6| Step: 2
Training loss: 1.0945340394973755
Validation loss: 1.7597872505905807

Epoch: 6| Step: 3
Training loss: 0.5645148158073425
Validation loss: 1.75868482230812

Epoch: 6| Step: 4
Training loss: 0.5434129238128662
Validation loss: 1.7670520877325406

Epoch: 6| Step: 5
Training loss: 0.41649627685546875
Validation loss: 1.7978057258872575

Epoch: 6| Step: 6
Training loss: 0.4486005902290344
Validation loss: 1.8063908661565473

Epoch: 6| Step: 7
Training loss: 0.6413506269454956
Validation loss: 1.8022556074203984

Epoch: 6| Step: 8
Training loss: 0.4983971118927002
Validation loss: 1.8103550172621203

Epoch: 6| Step: 9
Training loss: 0.7683382034301758
Validation loss: 1.8137962074689968

Epoch: 6| Step: 10
Training loss: 0.2953053414821625
Validation loss: 1.8353162504011584

Epoch: 6| Step: 11
Training loss: 0.32142719626426697
Validation loss: 1.7996714012597197

Epoch: 6| Step: 12
Training loss: 0.6272097826004028
Validation loss: 1.8127794599020353

Epoch: 6| Step: 13
Training loss: 0.4211563467979431
Validation loss: 1.8142677378910843

Epoch: 384| Step: 0
Training loss: 0.31850409507751465
Validation loss: 1.8041236759513937

Epoch: 6| Step: 1
Training loss: 0.4818999171257019
Validation loss: 1.7985426572061354

Epoch: 6| Step: 2
Training loss: 0.32140570878982544
Validation loss: 1.8284243588806481

Epoch: 6| Step: 3
Training loss: 0.9361251592636108
Validation loss: 1.8090787074899162

Epoch: 6| Step: 4
Training loss: 0.6617199182510376
Validation loss: 1.8125716793921687

Epoch: 6| Step: 5
Training loss: 0.37717491388320923
Validation loss: 1.8287185789436422

Epoch: 6| Step: 6
Training loss: 0.5099878907203674
Validation loss: 1.8280197305064048

Epoch: 6| Step: 7
Training loss: 0.4362034201622009
Validation loss: 1.8097817564523349

Epoch: 6| Step: 8
Training loss: 0.7565833330154419
Validation loss: 1.8347525891437326

Epoch: 6| Step: 9
Training loss: 0.39289286732673645
Validation loss: 1.793096394949062

Epoch: 6| Step: 10
Training loss: 0.4547693133354187
Validation loss: 1.8319476830062045

Epoch: 6| Step: 11
Training loss: 0.8608535528182983
Validation loss: 1.7755922771269275

Epoch: 6| Step: 12
Training loss: 0.7901150584220886
Validation loss: 1.8061496967910438

Epoch: 6| Step: 13
Training loss: 0.48078325390815735
Validation loss: 1.7704337591766028

Epoch: 385| Step: 0
Training loss: 0.21286514401435852
Validation loss: 1.7329691533119447

Epoch: 6| Step: 1
Training loss: 0.307243287563324
Validation loss: 1.7541641573752127

Epoch: 6| Step: 2
Training loss: 0.6573302149772644
Validation loss: 1.7444726062077347

Epoch: 6| Step: 3
Training loss: 0.3645464777946472
Validation loss: 1.7385808357628443

Epoch: 6| Step: 4
Training loss: 0.6013149619102478
Validation loss: 1.7453651505131875

Epoch: 6| Step: 5
Training loss: 0.531287670135498
Validation loss: 1.7470395629123976

Epoch: 6| Step: 6
Training loss: 0.6270055770874023
Validation loss: 1.751326621219676

Epoch: 6| Step: 7
Training loss: 0.5267479419708252
Validation loss: 1.7221748610978485

Epoch: 6| Step: 8
Training loss: 0.5824775695800781
Validation loss: 1.7543478665813323

Epoch: 6| Step: 9
Training loss: 0.6194486618041992
Validation loss: 1.750784425325291

Epoch: 6| Step: 10
Training loss: 0.5505127906799316
Validation loss: 1.7638915495205951

Epoch: 6| Step: 11
Training loss: 0.7870367765426636
Validation loss: 1.7582776033750145

Epoch: 6| Step: 12
Training loss: 0.36859437823295593
Validation loss: 1.7578038938583866

Epoch: 6| Step: 13
Training loss: 1.0304949283599854
Validation loss: 1.7653596337123583

Epoch: 386| Step: 0
Training loss: 0.6598629355430603
Validation loss: 1.805010287992416

Epoch: 6| Step: 1
Training loss: 0.33130940794944763
Validation loss: 1.8479785932007657

Epoch: 6| Step: 2
Training loss: 0.49253958463668823
Validation loss: 1.8345085331188735

Epoch: 6| Step: 3
Training loss: 0.9046211242675781
Validation loss: 1.8358947807742703

Epoch: 6| Step: 4
Training loss: 0.502427339553833
Validation loss: 1.7849451739300963

Epoch: 6| Step: 5
Training loss: 0.4008370339870453
Validation loss: 1.7612608504551712

Epoch: 6| Step: 6
Training loss: 0.4196797311306
Validation loss: 1.7327208442072715

Epoch: 6| Step: 7
Training loss: 0.6676878929138184
Validation loss: 1.7390954520112725

Epoch: 6| Step: 8
Training loss: 0.5160359740257263
Validation loss: 1.7210587404107536

Epoch: 6| Step: 9
Training loss: 0.3345026969909668
Validation loss: 1.6928956995728195

Epoch: 6| Step: 10
Training loss: 0.6816718578338623
Validation loss: 1.674323731853116

Epoch: 6| Step: 11
Training loss: 0.7836025953292847
Validation loss: 1.6906827278034662

Epoch: 6| Step: 12
Training loss: 0.7945523858070374
Validation loss: 1.737438646695947

Epoch: 6| Step: 13
Training loss: 0.9366148710250854
Validation loss: 1.762573431896907

Epoch: 387| Step: 0
Training loss: 0.6628516316413879
Validation loss: 1.740734928397722

Epoch: 6| Step: 1
Training loss: 0.8686524629592896
Validation loss: 1.7521764437357585

Epoch: 6| Step: 2
Training loss: 0.38969719409942627
Validation loss: 1.7435362903020715

Epoch: 6| Step: 3
Training loss: 0.3605441451072693
Validation loss: 1.7996728215166318

Epoch: 6| Step: 4
Training loss: 0.4605189561843872
Validation loss: 1.822033679613503

Epoch: 6| Step: 5
Training loss: 0.32854899764060974
Validation loss: 1.8519827653002996

Epoch: 6| Step: 6
Training loss: 0.7967346906661987
Validation loss: 1.866356829161285

Epoch: 6| Step: 7
Training loss: 0.7530602216720581
Validation loss: 1.8736581494731288

Epoch: 6| Step: 8
Training loss: 0.6489851474761963
Validation loss: 1.8739120152688795

Epoch: 6| Step: 9
Training loss: 0.4888545870780945
Validation loss: 1.8320219427026727

Epoch: 6| Step: 10
Training loss: 0.611323356628418
Validation loss: 1.8539979688582882

Epoch: 6| Step: 11
Training loss: 0.6202731132507324
Validation loss: 1.7871084354257072

Epoch: 6| Step: 12
Training loss: 0.4847095012664795
Validation loss: 1.7805678703451668

Epoch: 6| Step: 13
Training loss: 0.7017036080360413
Validation loss: 1.7614988434699275

Epoch: 388| Step: 0
Training loss: 0.2180013209581375
Validation loss: 1.791655784012169

Epoch: 6| Step: 1
Training loss: 0.8015834093093872
Validation loss: 1.779761593828919

Epoch: 6| Step: 2
Training loss: 0.9298504590988159
Validation loss: 1.7318474528610066

Epoch: 6| Step: 3
Training loss: 0.30770039558410645
Validation loss: 1.7645420976864394

Epoch: 6| Step: 4
Training loss: 0.4067990779876709
Validation loss: 1.7825655039920603

Epoch: 6| Step: 5
Training loss: 0.818010687828064
Validation loss: 1.804895124127788

Epoch: 6| Step: 6
Training loss: 0.5636923313140869
Validation loss: 1.850613356918417

Epoch: 6| Step: 7
Training loss: 0.409464031457901
Validation loss: 1.8229479533369823

Epoch: 6| Step: 8
Training loss: 0.6496908664703369
Validation loss: 1.8539513567442536

Epoch: 6| Step: 9
Training loss: 0.37533819675445557
Validation loss: 1.8408649826562533

Epoch: 6| Step: 10
Training loss: 0.1716984659433365
Validation loss: 1.8435068002311132

Epoch: 6| Step: 11
Training loss: 0.7189195156097412
Validation loss: 1.8055884440739949

Epoch: 6| Step: 12
Training loss: 0.685848593711853
Validation loss: 1.8324440512605893

Epoch: 6| Step: 13
Training loss: 0.7036996483802795
Validation loss: 1.7841326549489012

Epoch: 389| Step: 0
Training loss: 0.5383432507514954
Validation loss: 1.7759173454776886

Epoch: 6| Step: 1
Training loss: 0.35940051078796387
Validation loss: 1.741683752306046

Epoch: 6| Step: 2
Training loss: 0.6985815763473511
Validation loss: 1.7477390355961298

Epoch: 6| Step: 3
Training loss: 0.25467222929000854
Validation loss: 1.7592267515838786

Epoch: 6| Step: 4
Training loss: 0.57581627368927
Validation loss: 1.7607033803898802

Epoch: 6| Step: 5
Training loss: 0.626639187335968
Validation loss: 1.797745567496105

Epoch: 6| Step: 6
Training loss: 0.4597436487674713
Validation loss: 1.7947396232235817

Epoch: 6| Step: 7
Training loss: 0.3536013960838318
Validation loss: 1.8128138114047307

Epoch: 6| Step: 8
Training loss: 0.25352904200553894
Validation loss: 1.7744863007658271

Epoch: 6| Step: 9
Training loss: 0.5749711990356445
Validation loss: 1.7772905659931961

Epoch: 6| Step: 10
Training loss: 0.7102774381637573
Validation loss: 1.7572329762161418

Epoch: 6| Step: 11
Training loss: 0.6068320274353027
Validation loss: 1.745674680638057

Epoch: 6| Step: 12
Training loss: 0.7289434671401978
Validation loss: 1.7531386754846061

Epoch: 6| Step: 13
Training loss: 0.8264505863189697
Validation loss: 1.7649552604203582

Epoch: 390| Step: 0
Training loss: 0.6795672178268433
Validation loss: 1.7590862679225143

Epoch: 6| Step: 1
Training loss: 0.766814112663269
Validation loss: 1.7328311986820673

Epoch: 6| Step: 2
Training loss: 0.568780243396759
Validation loss: 1.7851326824516378

Epoch: 6| Step: 3
Training loss: 0.30973702669143677
Validation loss: 1.7653320130481516

Epoch: 6| Step: 4
Training loss: 0.41461098194122314
Validation loss: 1.77960543991417

Epoch: 6| Step: 5
Training loss: 0.5973979830741882
Validation loss: 1.7616250861075617

Epoch: 6| Step: 6
Training loss: 0.5229002237319946
Validation loss: 1.7491338663203742

Epoch: 6| Step: 7
Training loss: 0.39032435417175293
Validation loss: 1.7584435209151237

Epoch: 6| Step: 8
Training loss: 0.49388691782951355
Validation loss: 1.7908959683551584

Epoch: 6| Step: 9
Training loss: 0.5742514133453369
Validation loss: 1.7489313258919665

Epoch: 6| Step: 10
Training loss: 0.6522466540336609
Validation loss: 1.813632845878601

Epoch: 6| Step: 11
Training loss: 0.5403553247451782
Validation loss: 1.8138526665267123

Epoch: 6| Step: 12
Training loss: 0.504596471786499
Validation loss: 1.8010187123411445

Epoch: 6| Step: 13
Training loss: 0.3588547706604004
Validation loss: 1.8135900164163241

Epoch: 391| Step: 0
Training loss: 0.5712577104568481
Validation loss: 1.8204708099365234

Epoch: 6| Step: 1
Training loss: 0.4822464883327484
Validation loss: 1.8153411444797312

Epoch: 6| Step: 2
Training loss: 0.44450587034225464
Validation loss: 1.80881070065242

Epoch: 6| Step: 3
Training loss: 0.4096496105194092
Validation loss: 1.7740283012390137

Epoch: 6| Step: 4
Training loss: 0.41429275274276733
Validation loss: 1.7676540459356

Epoch: 6| Step: 5
Training loss: 0.5060064792633057
Validation loss: 1.7803239591660038

Epoch: 6| Step: 6
Training loss: 0.5544397234916687
Validation loss: 1.764247218767802

Epoch: 6| Step: 7
Training loss: 0.7136306166648865
Validation loss: 1.7378311413590626

Epoch: 6| Step: 8
Training loss: 0.27604642510414124
Validation loss: 1.7741554872964018

Epoch: 6| Step: 9
Training loss: 0.6832597255706787
Validation loss: 1.7738229459331882

Epoch: 6| Step: 10
Training loss: 0.6662184596061707
Validation loss: 1.7669699038228681

Epoch: 6| Step: 11
Training loss: 0.5899832844734192
Validation loss: 1.762465335989511

Epoch: 6| Step: 12
Training loss: 0.6250789165496826
Validation loss: 1.7667704295086604

Epoch: 6| Step: 13
Training loss: 0.40534400939941406
Validation loss: 1.7250889373081986

Epoch: 392| Step: 0
Training loss: 0.39851781725883484
Validation loss: 1.7857094144308439

Epoch: 6| Step: 1
Training loss: 0.4195498824119568
Validation loss: 1.7456866848853327

Epoch: 6| Step: 2
Training loss: 0.5388280749320984
Validation loss: 1.7744643777929328

Epoch: 6| Step: 3
Training loss: 0.29904475808143616
Validation loss: 1.807163179561656

Epoch: 6| Step: 4
Training loss: 0.37955158948898315
Validation loss: 1.780041338295065

Epoch: 6| Step: 5
Training loss: 0.7464165687561035
Validation loss: 1.772161901638072

Epoch: 6| Step: 6
Training loss: 0.5988396406173706
Validation loss: 1.7857682294743036

Epoch: 6| Step: 7
Training loss: 0.2263091653585434
Validation loss: 1.7815974604698919

Epoch: 6| Step: 8
Training loss: 0.27584725618362427
Validation loss: 1.7543908011528753

Epoch: 6| Step: 9
Training loss: 0.7740912437438965
Validation loss: 1.765371245722617

Epoch: 6| Step: 10
Training loss: 0.7824380397796631
Validation loss: 1.7912261486053467

Epoch: 6| Step: 11
Training loss: 0.6993356943130493
Validation loss: 1.7843948000220842

Epoch: 6| Step: 12
Training loss: 0.5653639435768127
Validation loss: 1.7729962833466069

Epoch: 6| Step: 13
Training loss: 0.45768705010414124
Validation loss: 1.7383968445562548

Epoch: 393| Step: 0
Training loss: 0.47540298104286194
Validation loss: 1.8010966470164638

Epoch: 6| Step: 1
Training loss: 0.5836302638053894
Validation loss: 1.7677198392088695

Epoch: 6| Step: 2
Training loss: 0.7109370231628418
Validation loss: 1.80197936232372

Epoch: 6| Step: 3
Training loss: 0.37701359391212463
Validation loss: 1.8007347878589426

Epoch: 6| Step: 4
Training loss: 0.6254633069038391
Validation loss: 1.7703663149187643

Epoch: 6| Step: 5
Training loss: 0.5883926153182983
Validation loss: 1.7633033798586937

Epoch: 6| Step: 6
Training loss: 0.5348057746887207
Validation loss: 1.7407094214552192

Epoch: 6| Step: 7
Training loss: 0.4107085168361664
Validation loss: 1.770003027813409

Epoch: 6| Step: 8
Training loss: 0.5259689688682556
Validation loss: 1.733333706855774

Epoch: 6| Step: 9
Training loss: 0.3724784255027771
Validation loss: 1.7168625529094408

Epoch: 6| Step: 10
Training loss: 0.4117427170276642
Validation loss: 1.7061235750875166

Epoch: 6| Step: 11
Training loss: 0.291582316160202
Validation loss: 1.7524427431885914

Epoch: 6| Step: 12
Training loss: 0.8819410800933838
Validation loss: 1.7713774673400386

Epoch: 6| Step: 13
Training loss: 0.527616560459137
Validation loss: 1.8052322813259658

Epoch: 394| Step: 0
Training loss: 0.7779542803764343
Validation loss: 1.8025378821998514

Epoch: 6| Step: 1
Training loss: 0.4596315622329712
Validation loss: 1.7912027092390164

Epoch: 6| Step: 2
Training loss: 0.8209102153778076
Validation loss: 1.7986096682087067

Epoch: 6| Step: 3
Training loss: 0.4379681646823883
Validation loss: 1.8044926645935222

Epoch: 6| Step: 4
Training loss: 0.364501029253006
Validation loss: 1.8116611844749861

Epoch: 6| Step: 5
Training loss: 0.419430673122406
Validation loss: 1.7678981570787327

Epoch: 6| Step: 6
Training loss: 0.5726702213287354
Validation loss: 1.7761459017312655

Epoch: 6| Step: 7
Training loss: 0.39215677976608276
Validation loss: 1.7619499673125565

Epoch: 6| Step: 8
Training loss: 0.4692111313343048
Validation loss: 1.7142103673309408

Epoch: 6| Step: 9
Training loss: 0.3722039461135864
Validation loss: 1.735793181644973

Epoch: 6| Step: 10
Training loss: 0.704800546169281
Validation loss: 1.7575964978946153

Epoch: 6| Step: 11
Training loss: 0.5670828223228455
Validation loss: 1.7060845769861692

Epoch: 6| Step: 12
Training loss: 0.5054728388786316
Validation loss: 1.7429747427663496

Epoch: 6| Step: 13
Training loss: 0.3183130621910095
Validation loss: 1.7503579508873723

Epoch: 395| Step: 0
Training loss: 0.29272550344467163
Validation loss: 1.772887122246527

Epoch: 6| Step: 1
Training loss: 0.5993343591690063
Validation loss: 1.7662123390423354

Epoch: 6| Step: 2
Training loss: 0.6192513704299927
Validation loss: 1.7797747145416916

Epoch: 6| Step: 3
Training loss: 0.6481910943984985
Validation loss: 1.7998166814927132

Epoch: 6| Step: 4
Training loss: 0.45364874601364136
Validation loss: 1.8399400249604256

Epoch: 6| Step: 5
Training loss: 1.1597483158111572
Validation loss: 1.829332660603267

Epoch: 6| Step: 6
Training loss: 0.7031254172325134
Validation loss: 1.830649487433895

Epoch: 6| Step: 7
Training loss: 0.46034836769104004
Validation loss: 1.8306180533542429

Epoch: 6| Step: 8
Training loss: 0.169178768992424
Validation loss: 1.795117014197893

Epoch: 6| Step: 9
Training loss: 0.46488675475120544
Validation loss: 1.7924655252887356

Epoch: 6| Step: 10
Training loss: 0.32050466537475586
Validation loss: 1.7131728279975154

Epoch: 6| Step: 11
Training loss: 0.45762762427330017
Validation loss: 1.688107305957425

Epoch: 6| Step: 12
Training loss: 0.5998654365539551
Validation loss: 1.7286637726650442

Epoch: 6| Step: 13
Training loss: 0.3906800448894501
Validation loss: 1.6874026649741716

Epoch: 396| Step: 0
Training loss: 0.346227765083313
Validation loss: 1.7090909513094092

Epoch: 6| Step: 1
Training loss: 0.47779932618141174
Validation loss: 1.743217913053369

Epoch: 6| Step: 2
Training loss: 0.5123709440231323
Validation loss: 1.7575540055510819

Epoch: 6| Step: 3
Training loss: 0.527863621711731
Validation loss: 1.8040646378711989

Epoch: 6| Step: 4
Training loss: 0.6857450008392334
Validation loss: 1.7877485931560557

Epoch: 6| Step: 5
Training loss: 0.4339263439178467
Validation loss: 1.8133929980698453

Epoch: 6| Step: 6
Training loss: 0.5876355171203613
Validation loss: 1.8154289299441921

Epoch: 6| Step: 7
Training loss: 0.5621699094772339
Validation loss: 1.8433449242704658

Epoch: 6| Step: 8
Training loss: 0.5408346652984619
Validation loss: 1.796304113121443

Epoch: 6| Step: 9
Training loss: 0.539271354675293
Validation loss: 1.7839546536886564

Epoch: 6| Step: 10
Training loss: 0.5074264407157898
Validation loss: 1.7637054420286609

Epoch: 6| Step: 11
Training loss: 0.5171933174133301
Validation loss: 1.7117296444472445

Epoch: 6| Step: 12
Training loss: 0.41422051191329956
Validation loss: 1.706868927965882

Epoch: 6| Step: 13
Training loss: 0.8237740993499756
Validation loss: 1.7264719778491604

Epoch: 397| Step: 0
Training loss: 0.3990674912929535
Validation loss: 1.6886275173515402

Epoch: 6| Step: 1
Training loss: 0.6072745323181152
Validation loss: 1.7026339884727233

Epoch: 6| Step: 2
Training loss: 0.36108410358428955
Validation loss: 1.7405568335645942

Epoch: 6| Step: 3
Training loss: 0.46513867378234863
Validation loss: 1.7206562014036282

Epoch: 6| Step: 4
Training loss: 0.8955286741256714
Validation loss: 1.7403699608259304

Epoch: 6| Step: 5
Training loss: 0.43488651514053345
Validation loss: 1.7438454435717674

Epoch: 6| Step: 6
Training loss: 0.2013850063085556
Validation loss: 1.7471640007470244

Epoch: 6| Step: 7
Training loss: 0.3888998031616211
Validation loss: 1.7367908723892704

Epoch: 6| Step: 8
Training loss: 0.7381144165992737
Validation loss: 1.7240852437993532

Epoch: 6| Step: 9
Training loss: 0.22885139286518097
Validation loss: 1.7398579633364113

Epoch: 6| Step: 10
Training loss: 0.7129558324813843
Validation loss: 1.737555899927693

Epoch: 6| Step: 11
Training loss: 0.5215176939964294
Validation loss: 1.7640383012833134

Epoch: 6| Step: 12
Training loss: 0.5965794324874878
Validation loss: 1.7603946411481468

Epoch: 6| Step: 13
Training loss: 0.646748960018158
Validation loss: 1.7929466379586088

Epoch: 398| Step: 0
Training loss: 0.4982593059539795
Validation loss: 1.754603643571177

Epoch: 6| Step: 1
Training loss: 0.514865517616272
Validation loss: 1.7482723728302987

Epoch: 6| Step: 2
Training loss: 0.523830235004425
Validation loss: 1.7378789160841255

Epoch: 6| Step: 3
Training loss: 0.3532496690750122
Validation loss: 1.8021252270667785

Epoch: 6| Step: 4
Training loss: 0.4851536750793457
Validation loss: 1.771049012419998

Epoch: 6| Step: 5
Training loss: 0.3882368206977844
Validation loss: 1.7783741848443144

Epoch: 6| Step: 6
Training loss: 0.4055401086807251
Validation loss: 1.7815148971414054

Epoch: 6| Step: 7
Training loss: 0.175849050283432
Validation loss: 1.769255045921572

Epoch: 6| Step: 8
Training loss: 0.5224485397338867
Validation loss: 1.7619724747955159

Epoch: 6| Step: 9
Training loss: 0.8706199526786804
Validation loss: 1.8007975137361916

Epoch: 6| Step: 10
Training loss: 0.5314725041389465
Validation loss: 1.7458686469703593

Epoch: 6| Step: 11
Training loss: 0.5196893811225891
Validation loss: 1.7328493800214542

Epoch: 6| Step: 12
Training loss: 0.6888242363929749
Validation loss: 1.7597966117243613

Epoch: 6| Step: 13
Training loss: 0.4847450256347656
Validation loss: 1.7610157356467298

Epoch: 399| Step: 0
Training loss: 0.47569742798805237
Validation loss: 1.758962385116085

Epoch: 6| Step: 1
Training loss: 0.44714733958244324
Validation loss: 1.7092219084821723

Epoch: 6| Step: 2
Training loss: 0.4111466407775879
Validation loss: 1.7559802365559403

Epoch: 6| Step: 3
Training loss: 0.5643160343170166
Validation loss: 1.75259917782199

Epoch: 6| Step: 4
Training loss: 0.33603042364120483
Validation loss: 1.760641139040711

Epoch: 6| Step: 5
Training loss: 0.3123107850551605
Validation loss: 1.7724527184681227

Epoch: 6| Step: 6
Training loss: 0.4587986469268799
Validation loss: 1.7522475975815968

Epoch: 6| Step: 7
Training loss: 0.5192813873291016
Validation loss: 1.7704389569579915

Epoch: 6| Step: 8
Training loss: 0.536442220211029
Validation loss: 1.776540224270154

Epoch: 6| Step: 9
Training loss: 0.7466024160385132
Validation loss: 1.8029866705658615

Epoch: 6| Step: 10
Training loss: 0.5452368259429932
Validation loss: 1.7805976508766093

Epoch: 6| Step: 11
Training loss: 0.6360428929328918
Validation loss: 1.804071081581936

Epoch: 6| Step: 12
Training loss: 0.3500722646713257
Validation loss: 1.7932055714309856

Epoch: 6| Step: 13
Training loss: 0.6423375606536865
Validation loss: 1.7709500943460772

Epoch: 400| Step: 0
Training loss: 0.5863637924194336
Validation loss: 1.8132374184105986

Epoch: 6| Step: 1
Training loss: 0.30714550614356995
Validation loss: 1.790594131715836

Epoch: 6| Step: 2
Training loss: 0.7133564949035645
Validation loss: 1.7849235111667263

Epoch: 6| Step: 3
Training loss: 0.3254956901073456
Validation loss: 1.7924373918964016

Epoch: 6| Step: 4
Training loss: 0.5464425683021545
Validation loss: 1.7795293510601085

Epoch: 6| Step: 5
Training loss: 0.40628582239151
Validation loss: 1.7783034719446653

Epoch: 6| Step: 6
Training loss: 0.265887588262558
Validation loss: 1.8302519552169307

Epoch: 6| Step: 7
Training loss: 0.44184228777885437
Validation loss: 1.7734015128945793

Epoch: 6| Step: 8
Training loss: 0.48716646432876587
Validation loss: 1.8127993922079764

Epoch: 6| Step: 9
Training loss: 0.8414081335067749
Validation loss: 1.8136519770468436

Epoch: 6| Step: 10
Training loss: 0.5354122519493103
Validation loss: 1.7344744333656885

Epoch: 6| Step: 11
Training loss: 0.6048030853271484
Validation loss: 1.7464421397896224

Epoch: 6| Step: 12
Training loss: 0.4349028468132019
Validation loss: 1.7364633288434757

Epoch: 6| Step: 13
Training loss: 0.44223061203956604
Validation loss: 1.7647540812851281

Epoch: 401| Step: 0
Training loss: 0.5684314966201782
Validation loss: 1.7298138679996613

Epoch: 6| Step: 1
Training loss: 0.4481557011604309
Validation loss: 1.7235658322611163

Epoch: 6| Step: 2
Training loss: 0.42779064178466797
Validation loss: 1.7903673238651727

Epoch: 6| Step: 3
Training loss: 0.41060566902160645
Validation loss: 1.7764709790547688

Epoch: 6| Step: 4
Training loss: 0.3430035710334778
Validation loss: 1.7517150422578216

Epoch: 6| Step: 5
Training loss: 0.5832787752151489
Validation loss: 1.7677110869397399

Epoch: 6| Step: 6
Training loss: 0.662064254283905
Validation loss: 1.740020425088944

Epoch: 6| Step: 7
Training loss: 0.508130669593811
Validation loss: 1.757689578558809

Epoch: 6| Step: 8
Training loss: 0.298054963350296
Validation loss: 1.6932224727446032

Epoch: 6| Step: 9
Training loss: 0.46408748626708984
Validation loss: 1.7234882898228143

Epoch: 6| Step: 10
Training loss: 0.3732314705848694
Validation loss: 1.6969834617389146

Epoch: 6| Step: 11
Training loss: 0.6913449764251709
Validation loss: 1.7006530928355392

Epoch: 6| Step: 12
Training loss: 0.5290758013725281
Validation loss: 1.6986567307544012

Epoch: 6| Step: 13
Training loss: 0.6854360103607178
Validation loss: 1.700168171236592

Epoch: 402| Step: 0
Training loss: 0.6496456861495972
Validation loss: 1.6866024950499177

Epoch: 6| Step: 1
Training loss: 0.4333982467651367
Validation loss: 1.7072684944316905

Epoch: 6| Step: 2
Training loss: 0.486130952835083
Validation loss: 1.7196369171142578

Epoch: 6| Step: 3
Training loss: 0.40834271907806396
Validation loss: 1.7692049908381637

Epoch: 6| Step: 4
Training loss: 0.6532710194587708
Validation loss: 1.7612235161565966

Epoch: 6| Step: 5
Training loss: 0.5368945002555847
Validation loss: 1.7465632807823919

Epoch: 6| Step: 6
Training loss: 0.7689329385757446
Validation loss: 1.699542571139592

Epoch: 6| Step: 7
Training loss: 0.3634560704231262
Validation loss: 1.7173327848475466

Epoch: 6| Step: 8
Training loss: 0.41091644763946533
Validation loss: 1.7047994239355928

Epoch: 6| Step: 9
Training loss: 0.2238757163286209
Validation loss: 1.7373514957325433

Epoch: 6| Step: 10
Training loss: 0.5462509989738464
Validation loss: 1.735523804541557

Epoch: 6| Step: 11
Training loss: 0.6234309673309326
Validation loss: 1.68929712874915

Epoch: 6| Step: 12
Training loss: 0.39361700415611267
Validation loss: 1.7600389680554789

Epoch: 6| Step: 13
Training loss: 0.2706719636917114
Validation loss: 1.7080054757415608

Epoch: 403| Step: 0
Training loss: 0.7353395223617554
Validation loss: 1.7160487815897951

Epoch: 6| Step: 1
Training loss: 0.6903716921806335
Validation loss: 1.7094666419490692

Epoch: 6| Step: 2
Training loss: 0.49810004234313965
Validation loss: 1.7455534678633495

Epoch: 6| Step: 3
Training loss: 0.5280276536941528
Validation loss: 1.709086525824762

Epoch: 6| Step: 4
Training loss: 0.42493122816085815
Validation loss: 1.697436640339513

Epoch: 6| Step: 5
Training loss: 0.5693588852882385
Validation loss: 1.7386351041896368

Epoch: 6| Step: 6
Training loss: 0.4981844425201416
Validation loss: 1.7172029915676321

Epoch: 6| Step: 7
Training loss: 0.33058834075927734
Validation loss: 1.7275537483153804

Epoch: 6| Step: 8
Training loss: 0.47993409633636475
Validation loss: 1.7463154908149474

Epoch: 6| Step: 9
Training loss: 0.2480039894580841
Validation loss: 1.7514219309694024

Epoch: 6| Step: 10
Training loss: 0.521669328212738
Validation loss: 1.7837302851420578

Epoch: 6| Step: 11
Training loss: 0.32613450288772583
Validation loss: 1.783068928667294

Epoch: 6| Step: 12
Training loss: 0.2826923429965973
Validation loss: 1.7702150396121445

Epoch: 6| Step: 13
Training loss: 0.6438813805580139
Validation loss: 1.722861163077816

Epoch: 404| Step: 0
Training loss: 0.6808919906616211
Validation loss: 1.7395926073033323

Epoch: 6| Step: 1
Training loss: 0.2767498791217804
Validation loss: 1.7720327928502073

Epoch: 6| Step: 2
Training loss: 0.450758159160614
Validation loss: 1.74147698315241

Epoch: 6| Step: 3
Training loss: 0.47358590364456177
Validation loss: 1.755331127874313

Epoch: 6| Step: 4
Training loss: 0.28998976945877075
Validation loss: 1.7316448714143486

Epoch: 6| Step: 5
Training loss: 0.5093364119529724
Validation loss: 1.7243245801618021

Epoch: 6| Step: 6
Training loss: 0.5554615259170532
Validation loss: 1.7522060095622976

Epoch: 6| Step: 7
Training loss: 0.4772014319896698
Validation loss: 1.7390292395827591

Epoch: 6| Step: 8
Training loss: 0.4127030372619629
Validation loss: 1.775487212724583

Epoch: 6| Step: 9
Training loss: 0.35135984420776367
Validation loss: 1.767210978333668

Epoch: 6| Step: 10
Training loss: 0.6782093644142151
Validation loss: 1.8005191446632467

Epoch: 6| Step: 11
Training loss: 0.6753484010696411
Validation loss: 1.7684689901208366

Epoch: 6| Step: 12
Training loss: 0.40897446870803833
Validation loss: 1.7834423011349094

Epoch: 6| Step: 13
Training loss: 0.33663907647132874
Validation loss: 1.8052181864297518

Epoch: 405| Step: 0
Training loss: 0.5924214124679565
Validation loss: 1.7566844295429926

Epoch: 6| Step: 1
Training loss: 0.4695408344268799
Validation loss: 1.7846551249104161

Epoch: 6| Step: 2
Training loss: 0.1940779685974121
Validation loss: 1.765492094460354

Epoch: 6| Step: 3
Training loss: 0.3282468318939209
Validation loss: 1.7438458909270584

Epoch: 6| Step: 4
Training loss: 0.5495081543922424
Validation loss: 1.7561604105016237

Epoch: 6| Step: 5
Training loss: 0.4680761992931366
Validation loss: 1.7501222741219304

Epoch: 6| Step: 6
Training loss: 0.5861181616783142
Validation loss: 1.7244797932204379

Epoch: 6| Step: 7
Training loss: 0.3936803936958313
Validation loss: 1.7538106428679598

Epoch: 6| Step: 8
Training loss: 0.5190853476524353
Validation loss: 1.7595064755408996

Epoch: 6| Step: 9
Training loss: 0.4172617793083191
Validation loss: 1.7460509500195902

Epoch: 6| Step: 10
Training loss: 0.5425073504447937
Validation loss: 1.769136251941804

Epoch: 6| Step: 11
Training loss: 0.5993067026138306
Validation loss: 1.7661753982625983

Epoch: 6| Step: 12
Training loss: 0.4817991256713867
Validation loss: 1.7636465308486775

Epoch: 6| Step: 13
Training loss: 0.431742399930954
Validation loss: 1.7586765917398597

Epoch: 406| Step: 0
Training loss: 0.27541834115982056
Validation loss: 1.7410107607482581

Epoch: 6| Step: 1
Training loss: 0.36948224902153015
Validation loss: 1.7216855518279537

Epoch: 6| Step: 2
Training loss: 0.17134439945220947
Validation loss: 1.6563885186308174

Epoch: 6| Step: 3
Training loss: 0.4556936025619507
Validation loss: 1.65037436767291

Epoch: 6| Step: 4
Training loss: 0.6683056354522705
Validation loss: 1.6630231488135554

Epoch: 6| Step: 5
Training loss: 0.7260222434997559
Validation loss: 1.6340840760097708

Epoch: 6| Step: 6
Training loss: 0.3173373341560364
Validation loss: 1.7018092601530013

Epoch: 6| Step: 7
Training loss: 0.6482719779014587
Validation loss: 1.7381046061874719

Epoch: 6| Step: 8
Training loss: 0.8029013872146606
Validation loss: 1.729337057759685

Epoch: 6| Step: 9
Training loss: 0.440087229013443
Validation loss: 1.7931848956692604

Epoch: 6| Step: 10
Training loss: 0.6697753071784973
Validation loss: 1.8236464492736324

Epoch: 6| Step: 11
Training loss: 0.30077213048934937
Validation loss: 1.808398066028472

Epoch: 6| Step: 12
Training loss: 0.7600685358047485
Validation loss: 1.8019757809177521

Epoch: 6| Step: 13
Training loss: 0.5000927448272705
Validation loss: 1.824240187162994

Epoch: 407| Step: 0
Training loss: 0.5313303470611572
Validation loss: 1.8138631877078806

Epoch: 6| Step: 1
Training loss: 0.2621670663356781
Validation loss: 1.7968261831550187

Epoch: 6| Step: 2
Training loss: 0.44786226749420166
Validation loss: 1.8317173501496673

Epoch: 6| Step: 3
Training loss: 0.7028694152832031
Validation loss: 1.8142239278362644

Epoch: 6| Step: 4
Training loss: 0.7037156820297241
Validation loss: 1.802737751314717

Epoch: 6| Step: 5
Training loss: 0.35849976539611816
Validation loss: 1.7640433003825526

Epoch: 6| Step: 6
Training loss: 0.44107550382614136
Validation loss: 1.7788028460676952

Epoch: 6| Step: 7
Training loss: 0.4724234342575073
Validation loss: 1.8015504267907911

Epoch: 6| Step: 8
Training loss: 0.4778224527835846
Validation loss: 1.7570268748908915

Epoch: 6| Step: 9
Training loss: 0.5231512188911438
Validation loss: 1.7735170215688727

Epoch: 6| Step: 10
Training loss: 0.36645933985710144
Validation loss: 1.7615707907625424

Epoch: 6| Step: 11
Training loss: 0.6247658729553223
Validation loss: 1.737257521639588

Epoch: 6| Step: 12
Training loss: 0.32460153102874756
Validation loss: 1.7802331511692335

Epoch: 6| Step: 13
Training loss: 0.2942897379398346
Validation loss: 1.764859866070491

Epoch: 408| Step: 0
Training loss: 0.43836936354637146
Validation loss: 1.7708549114965624

Epoch: 6| Step: 1
Training loss: 0.6086692810058594
Validation loss: 1.7391826401474655

Epoch: 6| Step: 2
Training loss: 0.5355569124221802
Validation loss: 1.7312246599505026

Epoch: 6| Step: 3
Training loss: 0.34031277894973755
Validation loss: 1.7142155093531455

Epoch: 6| Step: 4
Training loss: 0.21041086316108704
Validation loss: 1.725142200787862

Epoch: 6| Step: 5
Training loss: 0.512414813041687
Validation loss: 1.6873706233116887

Epoch: 6| Step: 6
Training loss: 0.7321853041648865
Validation loss: 1.6898965181842927

Epoch: 6| Step: 7
Training loss: 0.4508688747882843
Validation loss: 1.6965423066128966

Epoch: 6| Step: 8
Training loss: 0.4486621022224426
Validation loss: 1.6810784147631737

Epoch: 6| Step: 9
Training loss: 0.3923710584640503
Validation loss: 1.6827581800440305

Epoch: 6| Step: 10
Training loss: 0.4534280598163605
Validation loss: 1.6947342977728894

Epoch: 6| Step: 11
Training loss: 0.6211155652999878
Validation loss: 1.7034544021852556

Epoch: 6| Step: 12
Training loss: 0.47952353954315186
Validation loss: 1.7191800366165817

Epoch: 6| Step: 13
Training loss: 0.326579213142395
Validation loss: 1.740985579388116

Epoch: 409| Step: 0
Training loss: 0.6412928104400635
Validation loss: 1.7936460612922587

Epoch: 6| Step: 1
Training loss: 0.21002531051635742
Validation loss: 1.7978908990019111

Epoch: 6| Step: 2
Training loss: 0.6118924021720886
Validation loss: 1.842073481570008

Epoch: 6| Step: 3
Training loss: 0.5513314008712769
Validation loss: 1.8396688251085178

Epoch: 6| Step: 4
Training loss: 0.3538632392883301
Validation loss: 1.8139816599507486

Epoch: 6| Step: 5
Training loss: 0.4787273705005646
Validation loss: 1.8024446592536023

Epoch: 6| Step: 6
Training loss: 0.3018420338630676
Validation loss: 1.773446798324585

Epoch: 6| Step: 7
Training loss: 0.43964359164237976
Validation loss: 1.7658134327139905

Epoch: 6| Step: 8
Training loss: 0.5156645774841309
Validation loss: 1.7615067010284753

Epoch: 6| Step: 9
Training loss: 0.512194037437439
Validation loss: 1.7613961491533505

Epoch: 6| Step: 10
Training loss: 0.6457728147506714
Validation loss: 1.746184004250393

Epoch: 6| Step: 11
Training loss: 0.7966604232788086
Validation loss: 1.7261817711655811

Epoch: 6| Step: 12
Training loss: 0.422294020652771
Validation loss: 1.7249010391132806

Epoch: 6| Step: 13
Training loss: 0.18687088787555695
Validation loss: 1.6921932825478174

Epoch: 410| Step: 0
Training loss: 0.27247512340545654
Validation loss: 1.6944889753095564

Epoch: 6| Step: 1
Training loss: 0.6073256731033325
Validation loss: 1.7340802095269645

Epoch: 6| Step: 2
Training loss: 0.43225234746932983
Validation loss: 1.7701821532300723

Epoch: 6| Step: 3
Training loss: 0.562119722366333
Validation loss: 1.8011542725306686

Epoch: 6| Step: 4
Training loss: 0.46647778153419495
Validation loss: 1.7799882914430352

Epoch: 6| Step: 5
Training loss: 0.3685658574104309
Validation loss: 1.787260938716191

Epoch: 6| Step: 6
Training loss: 0.3417520821094513
Validation loss: 1.7684055066877795

Epoch: 6| Step: 7
Training loss: 0.34077736735343933
Validation loss: 1.7796850781286917

Epoch: 6| Step: 8
Training loss: 0.19680863618850708
Validation loss: 1.785558113487818

Epoch: 6| Step: 9
Training loss: 0.5849187970161438
Validation loss: 1.7715265212520477

Epoch: 6| Step: 10
Training loss: 0.7112371921539307
Validation loss: 1.7231574250805763

Epoch: 6| Step: 11
Training loss: 0.523070216178894
Validation loss: 1.7601846084799817

Epoch: 6| Step: 12
Training loss: 0.6079804301261902
Validation loss: 1.7016617687799598

Epoch: 6| Step: 13
Training loss: 0.4329320192337036
Validation loss: 1.7160666296558995

Epoch: 411| Step: 0
Training loss: 0.6561598777770996
Validation loss: 1.6964899545074792

Epoch: 6| Step: 1
Training loss: 0.33829817175865173
Validation loss: 1.7236725579025924

Epoch: 6| Step: 2
Training loss: 0.36387619376182556
Validation loss: 1.7137443455316688

Epoch: 6| Step: 3
Training loss: 0.6210405230522156
Validation loss: 1.7424971724069247

Epoch: 6| Step: 4
Training loss: 0.6268365383148193
Validation loss: 1.790564311447964

Epoch: 6| Step: 5
Training loss: 0.5560481548309326
Validation loss: 1.7611829452617194

Epoch: 6| Step: 6
Training loss: 0.23215022683143616
Validation loss: 1.7839755550507577

Epoch: 6| Step: 7
Training loss: 0.44510167837142944
Validation loss: 1.7874426047007244

Epoch: 6| Step: 8
Training loss: 0.2382144331932068
Validation loss: 1.82031972049385

Epoch: 6| Step: 9
Training loss: 0.7817767858505249
Validation loss: 1.8038725801693496

Epoch: 6| Step: 10
Training loss: 0.34195515513420105
Validation loss: 1.7456014335796397

Epoch: 6| Step: 11
Training loss: 0.6506192088127136
Validation loss: 1.7247007072612803

Epoch: 6| Step: 12
Training loss: 0.4701341986656189
Validation loss: 1.6909638220264065

Epoch: 6| Step: 13
Training loss: 0.11423788964748383
Validation loss: 1.7073009091038858

Epoch: 412| Step: 0
Training loss: 0.7802513241767883
Validation loss: 1.6897396208137594

Epoch: 6| Step: 1
Training loss: 0.3872213661670685
Validation loss: 1.6702609216013262

Epoch: 6| Step: 2
Training loss: 0.524766206741333
Validation loss: 1.7089994889433666

Epoch: 6| Step: 3
Training loss: 0.5815805792808533
Validation loss: 1.7167449382043654

Epoch: 6| Step: 4
Training loss: 0.3615016043186188
Validation loss: 1.7067691228723014

Epoch: 6| Step: 5
Training loss: 0.5054163336753845
Validation loss: 1.756877859433492

Epoch: 6| Step: 6
Training loss: 0.6529473066329956
Validation loss: 1.738751951084342

Epoch: 6| Step: 7
Training loss: 0.16976016759872437
Validation loss: 1.7494666473839873

Epoch: 6| Step: 8
Training loss: 0.302548885345459
Validation loss: 1.7489179988061228

Epoch: 6| Step: 9
Training loss: 0.42428916692733765
Validation loss: 1.7827001797255648

Epoch: 6| Step: 10
Training loss: 0.4320406913757324
Validation loss: 1.7722289369952293

Epoch: 6| Step: 11
Training loss: 0.4431241452693939
Validation loss: 1.7651257002225487

Epoch: 6| Step: 12
Training loss: 0.34600409865379333
Validation loss: 1.772850013548328

Epoch: 6| Step: 13
Training loss: 0.3380078077316284
Validation loss: 1.7512718939012097

Epoch: 413| Step: 0
Training loss: 0.6148355603218079
Validation loss: 1.7699405493274811

Epoch: 6| Step: 1
Training loss: 0.17837810516357422
Validation loss: 1.7678500170348792

Epoch: 6| Step: 2
Training loss: 0.4895971417427063
Validation loss: 1.7147302384017615

Epoch: 6| Step: 3
Training loss: 0.40373533964157104
Validation loss: 1.7595395747051443

Epoch: 6| Step: 4
Training loss: 0.44287246465682983
Validation loss: 1.715573815889256

Epoch: 6| Step: 5
Training loss: 0.40687495470046997
Validation loss: 1.7468825783780826

Epoch: 6| Step: 6
Training loss: 0.6196539402008057
Validation loss: 1.7364183728412916

Epoch: 6| Step: 7
Training loss: 0.6546839475631714
Validation loss: 1.7191849908521097

Epoch: 6| Step: 8
Training loss: 0.3703305721282959
Validation loss: 1.723371264755085

Epoch: 6| Step: 9
Training loss: 0.32818537950515747
Validation loss: 1.759796170778172

Epoch: 6| Step: 10
Training loss: 0.35783353447914124
Validation loss: 1.7331402872198372

Epoch: 6| Step: 11
Training loss: 0.4957483410835266
Validation loss: 1.7490480689592258

Epoch: 6| Step: 12
Training loss: 0.3885396718978882
Validation loss: 1.733309732970371

Epoch: 6| Step: 13
Training loss: 0.3903161585330963
Validation loss: 1.7189405015719834

Epoch: 414| Step: 0
Training loss: 0.280096173286438
Validation loss: 1.7335769822520595

Epoch: 6| Step: 1
Training loss: 0.20745638012886047
Validation loss: 1.7364139223611483

Epoch: 6| Step: 2
Training loss: 0.3719562888145447
Validation loss: 1.7410760861571117

Epoch: 6| Step: 3
Training loss: 0.5516349673271179
Validation loss: 1.7641432669854933

Epoch: 6| Step: 4
Training loss: 0.3248461186885834
Validation loss: 1.7591548401822326

Epoch: 6| Step: 5
Training loss: 0.4168887138366699
Validation loss: 1.7438846108733967

Epoch: 6| Step: 6
Training loss: 0.5851380228996277
Validation loss: 1.7719770785300963

Epoch: 6| Step: 7
Training loss: 0.8270852565765381
Validation loss: 1.7234536114559378

Epoch: 6| Step: 8
Training loss: 0.38285723328590393
Validation loss: 1.7387328070978965

Epoch: 6| Step: 9
Training loss: 0.46909600496292114
Validation loss: 1.7290202071589809

Epoch: 6| Step: 10
Training loss: 0.5359679460525513
Validation loss: 1.7063529658061203

Epoch: 6| Step: 11
Training loss: 0.6571799516677856
Validation loss: 1.7104551997236026

Epoch: 6| Step: 12
Training loss: 0.5611783862113953
Validation loss: 1.7144015565995248

Epoch: 6| Step: 13
Training loss: 0.16114217042922974
Validation loss: 1.7366565324926888

Epoch: 415| Step: 0
Training loss: 0.46678081154823303
Validation loss: 1.734919991544498

Epoch: 6| Step: 1
Training loss: 0.6467175483703613
Validation loss: 1.743044316127736

Epoch: 6| Step: 2
Training loss: 0.19162581861019135
Validation loss: 1.761146412100843

Epoch: 6| Step: 3
Training loss: 0.2299097180366516
Validation loss: 1.7619275046933083

Epoch: 6| Step: 4
Training loss: 0.3068723976612091
Validation loss: 1.7686440355034285

Epoch: 6| Step: 5
Training loss: 0.34102725982666016
Validation loss: 1.7469730120833202

Epoch: 6| Step: 6
Training loss: 0.5212079286575317
Validation loss: 1.687742615258822

Epoch: 6| Step: 7
Training loss: 0.444469153881073
Validation loss: 1.7143209929107337

Epoch: 6| Step: 8
Training loss: 0.49275967478752136
Validation loss: 1.7084632381316154

Epoch: 6| Step: 9
Training loss: 0.40651360154151917
Validation loss: 1.678159624017695

Epoch: 6| Step: 10
Training loss: 0.6656032800674438
Validation loss: 1.6903592002007268

Epoch: 6| Step: 11
Training loss: 0.4690626859664917
Validation loss: 1.6773011556235693

Epoch: 6| Step: 12
Training loss: 0.5829678177833557
Validation loss: 1.689334915530297

Epoch: 6| Step: 13
Training loss: 0.509053647518158
Validation loss: 1.693077213020735

Epoch: 416| Step: 0
Training loss: 0.4570118486881256
Validation loss: 1.6638110709446732

Epoch: 6| Step: 1
Training loss: 0.2858837842941284
Validation loss: 1.7156709368510912

Epoch: 6| Step: 2
Training loss: 0.24955417215824127
Validation loss: 1.7626397891711163

Epoch: 6| Step: 3
Training loss: 0.5663557052612305
Validation loss: 1.7372768476445188

Epoch: 6| Step: 4
Training loss: 0.29607492685317993
Validation loss: 1.7689835358691472

Epoch: 6| Step: 5
Training loss: 0.3652775287628174
Validation loss: 1.7448948839659333

Epoch: 6| Step: 6
Training loss: 0.2233995795249939
Validation loss: 1.7248383542542816

Epoch: 6| Step: 7
Training loss: 0.5121670365333557
Validation loss: 1.6957680640682098

Epoch: 6| Step: 8
Training loss: 0.6822035312652588
Validation loss: 1.7085452348955217

Epoch: 6| Step: 9
Training loss: 0.5669310092926025
Validation loss: 1.6926220232440579

Epoch: 6| Step: 10
Training loss: 0.4778713285923004
Validation loss: 1.685110063963039

Epoch: 6| Step: 11
Training loss: 0.619371771812439
Validation loss: 1.6523505539022467

Epoch: 6| Step: 12
Training loss: 0.5827459096908569
Validation loss: 1.6919590670575377

Epoch: 6| Step: 13
Training loss: 0.34114113450050354
Validation loss: 1.7035073208552536

Epoch: 417| Step: 0
Training loss: 0.5446501970291138
Validation loss: 1.683150376043012

Epoch: 6| Step: 1
Training loss: 0.7329611778259277
Validation loss: 1.6979746036632086

Epoch: 6| Step: 2
Training loss: 0.4946610927581787
Validation loss: 1.7044580264758038

Epoch: 6| Step: 3
Training loss: 0.3903360366821289
Validation loss: 1.718706477072931

Epoch: 6| Step: 4
Training loss: 0.41319042444229126
Validation loss: 1.7009230531671995

Epoch: 6| Step: 5
Training loss: 0.1976807713508606
Validation loss: 1.6717904972773727

Epoch: 6| Step: 6
Training loss: 0.2101384550333023
Validation loss: 1.6705262109797487

Epoch: 6| Step: 7
Training loss: 0.5227001905441284
Validation loss: 1.7181219426534509

Epoch: 6| Step: 8
Training loss: 0.47558870911598206
Validation loss: 1.6988938059858096

Epoch: 6| Step: 9
Training loss: 0.4079449474811554
Validation loss: 1.6758612625060543

Epoch: 6| Step: 10
Training loss: 0.33580100536346436
Validation loss: 1.706026187507055

Epoch: 6| Step: 11
Training loss: 0.5245652198791504
Validation loss: 1.675556287970594

Epoch: 6| Step: 12
Training loss: 0.45237165689468384
Validation loss: 1.7059246724651707

Epoch: 6| Step: 13
Training loss: 0.27127882838249207
Validation loss: 1.6902321423253706

Epoch: 418| Step: 0
Training loss: 0.499789834022522
Validation loss: 1.7030705803184099

Epoch: 6| Step: 1
Training loss: 0.1727190911769867
Validation loss: 1.7417249730838242

Epoch: 6| Step: 2
Training loss: 0.2258215844631195
Validation loss: 1.7128636901096632

Epoch: 6| Step: 3
Training loss: 0.6538787484169006
Validation loss: 1.7524212534709642

Epoch: 6| Step: 4
Training loss: 0.4857177436351776
Validation loss: 1.7330529177060692

Epoch: 6| Step: 5
Training loss: 0.30025672912597656
Validation loss: 1.7696118534252208

Epoch: 6| Step: 6
Training loss: 0.4313737154006958
Validation loss: 1.759659364659299

Epoch: 6| Step: 7
Training loss: 0.5787739753723145
Validation loss: 1.7657900036022227

Epoch: 6| Step: 8
Training loss: 0.30410388112068176
Validation loss: 1.7791135952036867

Epoch: 6| Step: 9
Training loss: 0.600668728351593
Validation loss: 1.7583646658928163

Epoch: 6| Step: 10
Training loss: 0.390178382396698
Validation loss: 1.7466247697030344

Epoch: 6| Step: 11
Training loss: 0.665134608745575
Validation loss: 1.7553237458711028

Epoch: 6| Step: 12
Training loss: 0.4338102638721466
Validation loss: 1.7665777488421368

Epoch: 6| Step: 13
Training loss: 0.12886053323745728
Validation loss: 1.7922180878218783

Epoch: 419| Step: 0
Training loss: 0.4273661971092224
Validation loss: 1.8198418617248535

Epoch: 6| Step: 1
Training loss: 0.49090778827667236
Validation loss: 1.8222480743162093

Epoch: 6| Step: 2
Training loss: 0.43796536326408386
Validation loss: 1.7892729595143309

Epoch: 6| Step: 3
Training loss: 0.49222618341445923
Validation loss: 1.7476830033845798

Epoch: 6| Step: 4
Training loss: 0.2906836271286011
Validation loss: 1.751422348842826

Epoch: 6| Step: 5
Training loss: 0.43429315090179443
Validation loss: 1.7714220708416355

Epoch: 6| Step: 6
Training loss: 0.4778960943222046
Validation loss: 1.7465102429031043

Epoch: 6| Step: 7
Training loss: 0.49339672923088074
Validation loss: 1.70883527622428

Epoch: 6| Step: 8
Training loss: 0.23228442668914795
Validation loss: 1.741800638937181

Epoch: 6| Step: 9
Training loss: 0.5308669805526733
Validation loss: 1.7691643622613722

Epoch: 6| Step: 10
Training loss: 0.5769902467727661
Validation loss: 1.7507682820802093

Epoch: 6| Step: 11
Training loss: 0.41449812054634094
Validation loss: 1.7276674650048698

Epoch: 6| Step: 12
Training loss: 0.5534605979919434
Validation loss: 1.7470543999825754

Epoch: 6| Step: 13
Training loss: 0.31846314668655396
Validation loss: 1.759970167631744

Epoch: 420| Step: 0
Training loss: 0.4250800311565399
Validation loss: 1.755601090769614

Epoch: 6| Step: 1
Training loss: 0.42369773983955383
Validation loss: 1.7357925035620247

Epoch: 6| Step: 2
Training loss: 0.5594227313995361
Validation loss: 1.762300190105233

Epoch: 6| Step: 3
Training loss: 0.4418814480304718
Validation loss: 1.7655248885513635

Epoch: 6| Step: 4
Training loss: 0.3438553810119629
Validation loss: 1.7399528052217217

Epoch: 6| Step: 5
Training loss: 0.4304403066635132
Validation loss: 1.7384541316698956

Epoch: 6| Step: 6
Training loss: 0.4245258569717407
Validation loss: 1.7152190387889903

Epoch: 6| Step: 7
Training loss: 0.31404054164886475
Validation loss: 1.7518128477117068

Epoch: 6| Step: 8
Training loss: 0.4515049457550049
Validation loss: 1.7582533436436807

Epoch: 6| Step: 9
Training loss: 0.7232694625854492
Validation loss: 1.753022773291475

Epoch: 6| Step: 10
Training loss: 0.5497567653656006
Validation loss: 1.818825432049331

Epoch: 6| Step: 11
Training loss: 0.34987348318099976
Validation loss: 1.7704540888468425

Epoch: 6| Step: 12
Training loss: 0.3503068685531616
Validation loss: 1.770567782463566

Epoch: 6| Step: 13
Training loss: 0.3725045621395111
Validation loss: 1.7633861931421424

Epoch: 421| Step: 0
Training loss: 0.36663806438446045
Validation loss: 1.7628237226957917

Epoch: 6| Step: 1
Training loss: 0.4352032542228699
Validation loss: 1.730334758758545

Epoch: 6| Step: 2
Training loss: 0.5869863629341125
Validation loss: 1.7104128022347727

Epoch: 6| Step: 3
Training loss: 0.5011948943138123
Validation loss: 1.7295674341981129

Epoch: 6| Step: 4
Training loss: 0.47781649231910706
Validation loss: 1.7252725952415056

Epoch: 6| Step: 5
Training loss: 0.5874407887458801
Validation loss: 1.7113309752556585

Epoch: 6| Step: 6
Training loss: 0.5282788872718811
Validation loss: 1.7305726210276287

Epoch: 6| Step: 7
Training loss: 0.4322783648967743
Validation loss: 1.7196659952081659

Epoch: 6| Step: 8
Training loss: 0.5252726674079895
Validation loss: 1.6937215533307803

Epoch: 6| Step: 9
Training loss: 0.349681556224823
Validation loss: 1.6897953620520971

Epoch: 6| Step: 10
Training loss: 0.2624712586402893
Validation loss: 1.704047711946631

Epoch: 6| Step: 11
Training loss: 0.1990460455417633
Validation loss: 1.7134954531987507

Epoch: 6| Step: 12
Training loss: 0.6480483412742615
Validation loss: 1.7136099312895088

Epoch: 6| Step: 13
Training loss: 0.3356814384460449
Validation loss: 1.7676104640447965

Epoch: 422| Step: 0
Training loss: 0.21872641146183014
Validation loss: 1.8044482943832234

Epoch: 6| Step: 1
Training loss: 0.6358848214149475
Validation loss: 1.7736913491320867

Epoch: 6| Step: 2
Training loss: 0.4501921832561493
Validation loss: 1.759360638997888

Epoch: 6| Step: 3
Training loss: 0.3820663094520569
Validation loss: 1.7837545897371025

Epoch: 6| Step: 4
Training loss: 0.4022679924964905
Validation loss: 1.722171386082967

Epoch: 6| Step: 5
Training loss: 0.29533663392066956
Validation loss: 1.723636265723936

Epoch: 6| Step: 6
Training loss: 0.5900988578796387
Validation loss: 1.6990195115407307

Epoch: 6| Step: 7
Training loss: 0.5754910707473755
Validation loss: 1.6629680574581187

Epoch: 6| Step: 8
Training loss: 0.3641025125980377
Validation loss: 1.6568172285633702

Epoch: 6| Step: 9
Training loss: 0.7018600106239319
Validation loss: 1.6658682220725602

Epoch: 6| Step: 10
Training loss: 0.3959968686103821
Validation loss: 1.6632884112737512

Epoch: 6| Step: 11
Training loss: 0.49518507719039917
Validation loss: 1.7021582831618607

Epoch: 6| Step: 12
Training loss: 0.3289593458175659
Validation loss: 1.6820354743670392

Epoch: 6| Step: 13
Training loss: 0.39266666769981384
Validation loss: 1.752570204837348

Epoch: 423| Step: 0
Training loss: 0.4278942346572876
Validation loss: 1.7672147161217147

Epoch: 6| Step: 1
Training loss: 0.586471676826477
Validation loss: 1.7633160724434802

Epoch: 6| Step: 2
Training loss: 0.495749294757843
Validation loss: 1.7457246972668556

Epoch: 6| Step: 3
Training loss: 0.4215824007987976
Validation loss: 1.7763625319286058

Epoch: 6| Step: 4
Training loss: 0.4007248878479004
Validation loss: 1.759061586472296

Epoch: 6| Step: 5
Training loss: 0.4318945109844208
Validation loss: 1.7729338958699217

Epoch: 6| Step: 6
Training loss: 0.23606227338314056
Validation loss: 1.7572263235686927

Epoch: 6| Step: 7
Training loss: 0.5935332179069519
Validation loss: 1.7218449167025986

Epoch: 6| Step: 8
Training loss: 0.56246018409729
Validation loss: 1.7430083085131902

Epoch: 6| Step: 9
Training loss: 0.2553945779800415
Validation loss: 1.7277711424776303

Epoch: 6| Step: 10
Training loss: 0.37392956018447876
Validation loss: 1.7701515722018417

Epoch: 6| Step: 11
Training loss: 0.38987070322036743
Validation loss: 1.747561716264294

Epoch: 6| Step: 12
Training loss: 0.38093870878219604
Validation loss: 1.728084643681844

Epoch: 6| Step: 13
Training loss: 0.5347253680229187
Validation loss: 1.7418177384202198

Epoch: 424| Step: 0
Training loss: 0.43230417370796204
Validation loss: 1.6863420355704524

Epoch: 6| Step: 1
Training loss: 0.26625335216522217
Validation loss: 1.7067309066813479

Epoch: 6| Step: 2
Training loss: 0.2768755257129669
Validation loss: 1.685288547187723

Epoch: 6| Step: 3
Training loss: 0.4479442536830902
Validation loss: 1.704744811980955

Epoch: 6| Step: 4
Training loss: 0.5558650493621826
Validation loss: 1.699671551745425

Epoch: 6| Step: 5
Training loss: 0.6950794458389282
Validation loss: 1.7601336984224216

Epoch: 6| Step: 6
Training loss: 0.5261765718460083
Validation loss: 1.7523224994700441

Epoch: 6| Step: 7
Training loss: 0.44828787446022034
Validation loss: 1.8156958087798087

Epoch: 6| Step: 8
Training loss: 0.6219063997268677
Validation loss: 1.8532008265936246

Epoch: 6| Step: 9
Training loss: 0.518825888633728
Validation loss: 1.8530510458894955

Epoch: 6| Step: 10
Training loss: 0.4964260458946228
Validation loss: 1.8391915322631918

Epoch: 6| Step: 11
Training loss: 0.3537676930427551
Validation loss: 1.812768510592881

Epoch: 6| Step: 12
Training loss: 0.3941911458969116
Validation loss: 1.7787233501352289

Epoch: 6| Step: 13
Training loss: 0.3938084840774536
Validation loss: 1.7042019303127

Epoch: 425| Step: 0
Training loss: 0.5646967887878418
Validation loss: 1.6725680815276278

Epoch: 6| Step: 1
Training loss: 0.4142973721027374
Validation loss: 1.6621593788105955

Epoch: 6| Step: 2
Training loss: 0.5291263461112976
Validation loss: 1.6248592907382595

Epoch: 6| Step: 3
Training loss: 0.495344340801239
Validation loss: 1.6617139680411226

Epoch: 6| Step: 4
Training loss: 0.5730224251747131
Validation loss: 1.6444006658369494

Epoch: 6| Step: 5
Training loss: 0.34114205837249756
Validation loss: 1.6735084659309798

Epoch: 6| Step: 6
Training loss: 0.2986292541027069
Validation loss: 1.6770719097506614

Epoch: 6| Step: 7
Training loss: 0.447476863861084
Validation loss: 1.708155042381697

Epoch: 6| Step: 8
Training loss: 0.46015113592147827
Validation loss: 1.7286909831467496

Epoch: 6| Step: 9
Training loss: 0.5072588920593262
Validation loss: 1.7225622868025174

Epoch: 6| Step: 10
Training loss: 0.39174744486808777
Validation loss: 1.7390973362871396

Epoch: 6| Step: 11
Training loss: 0.12652496993541718
Validation loss: 1.7556177339246195

Epoch: 6| Step: 12
Training loss: 0.49018222093582153
Validation loss: 1.8105274336312407

Epoch: 6| Step: 13
Training loss: 0.2002878487110138
Validation loss: 1.7589573039803454

Epoch: 426| Step: 0
Training loss: 0.39687103033065796
Validation loss: 1.7353199130745345

Epoch: 6| Step: 1
Training loss: 0.45225510001182556
Validation loss: 1.7023844706114901

Epoch: 6| Step: 2
Training loss: 0.43217992782592773
Validation loss: 1.7004398248528922

Epoch: 6| Step: 3
Training loss: 0.2870010435581207
Validation loss: 1.6486877087623841

Epoch: 6| Step: 4
Training loss: 0.40945959091186523
Validation loss: 1.664761625310426

Epoch: 6| Step: 5
Training loss: 0.20082104206085205
Validation loss: 1.6645040640266993

Epoch: 6| Step: 6
Training loss: 0.5716426372528076
Validation loss: 1.6384405833418652

Epoch: 6| Step: 7
Training loss: 0.4587223529815674
Validation loss: 1.6485082641724618

Epoch: 6| Step: 8
Training loss: 0.7420970797538757
Validation loss: 1.6478417022253877

Epoch: 6| Step: 9
Training loss: 0.4510807394981384
Validation loss: 1.6409551161591724

Epoch: 6| Step: 10
Training loss: 0.28649795055389404
Validation loss: 1.687432849279014

Epoch: 6| Step: 11
Training loss: 0.4241982102394104
Validation loss: 1.6769387465651318

Epoch: 6| Step: 12
Training loss: 0.40940314531326294
Validation loss: 1.717961734341037

Epoch: 6| Step: 13
Training loss: 0.6418663859367371
Validation loss: 1.7029423713684082

Epoch: 427| Step: 0
Training loss: 0.27094322443008423
Validation loss: 1.6662944132281887

Epoch: 6| Step: 1
Training loss: 0.8363350629806519
Validation loss: 1.6947332979530416

Epoch: 6| Step: 2
Training loss: 0.3239741921424866
Validation loss: 1.6738577927312543

Epoch: 6| Step: 3
Training loss: 0.42072033882141113
Validation loss: 1.67355437432566

Epoch: 6| Step: 4
Training loss: 0.3489987850189209
Validation loss: 1.6723718168914958

Epoch: 6| Step: 5
Training loss: 0.46544110774993896
Validation loss: 1.6653942587555095

Epoch: 6| Step: 6
Training loss: 0.3337324261665344
Validation loss: 1.6986534646762315

Epoch: 6| Step: 7
Training loss: 0.43369102478027344
Validation loss: 1.6590275969556583

Epoch: 6| Step: 8
Training loss: 0.4826068878173828
Validation loss: 1.6672554221204532

Epoch: 6| Step: 9
Training loss: 0.27913764119148254
Validation loss: 1.6947805881500244

Epoch: 6| Step: 10
Training loss: 0.34071749448776245
Validation loss: 1.715880560618575

Epoch: 6| Step: 11
Training loss: 0.44030267000198364
Validation loss: 1.7468768768413092

Epoch: 6| Step: 12
Training loss: 0.39081308245658875
Validation loss: 1.7636876413899083

Epoch: 6| Step: 13
Training loss: 0.39108869433403015
Validation loss: 1.7661910518523185

Epoch: 428| Step: 0
Training loss: 0.5399115085601807
Validation loss: 1.7978631809193601

Epoch: 6| Step: 1
Training loss: 0.4115200638771057
Validation loss: 1.738037383684548

Epoch: 6| Step: 2
Training loss: 0.3219427466392517
Validation loss: 1.6778387536284745

Epoch: 6| Step: 3
Training loss: 0.2664351463317871
Validation loss: 1.6357847516254713

Epoch: 6| Step: 4
Training loss: 0.8207048177719116
Validation loss: 1.6504561324273386

Epoch: 6| Step: 5
Training loss: 0.5207626819610596
Validation loss: 1.6420760193178732

Epoch: 6| Step: 6
Training loss: 0.35172906517982483
Validation loss: 1.6542310560903242

Epoch: 6| Step: 7
Training loss: 0.3359137773513794
Validation loss: 1.6536551842125513

Epoch: 6| Step: 8
Training loss: 0.5468652844429016
Validation loss: 1.6623892232935915

Epoch: 6| Step: 9
Training loss: 0.4897504150867462
Validation loss: 1.6664282416784635

Epoch: 6| Step: 10
Training loss: 0.26846185326576233
Validation loss: 1.6760309767979447

Epoch: 6| Step: 11
Training loss: 0.28156211972236633
Validation loss: 1.7133341015026133

Epoch: 6| Step: 12
Training loss: 0.24175900220870972
Validation loss: 1.7229461439194218

Epoch: 6| Step: 13
Training loss: 0.23778469860553741
Validation loss: 1.757539818363805

Epoch: 429| Step: 0
Training loss: 0.3242688477039337
Validation loss: 1.7519654048386442

Epoch: 6| Step: 1
Training loss: 0.41164129972457886
Validation loss: 1.790282525042052

Epoch: 6| Step: 2
Training loss: 0.4390715956687927
Validation loss: 1.7712706122347104

Epoch: 6| Step: 3
Training loss: 0.5061010122299194
Validation loss: 1.7369266709973734

Epoch: 6| Step: 4
Training loss: 0.3116111159324646
Validation loss: 1.7267585274993733

Epoch: 6| Step: 5
Training loss: 0.3682699501514435
Validation loss: 1.7256795937015164

Epoch: 6| Step: 6
Training loss: 0.4584863781929016
Validation loss: 1.7451169965087727

Epoch: 6| Step: 7
Training loss: 0.26418036222457886
Validation loss: 1.7352854872262606

Epoch: 6| Step: 8
Training loss: 0.20808148384094238
Validation loss: 1.7125565146887174

Epoch: 6| Step: 9
Training loss: 0.5671724677085876
Validation loss: 1.68264046407515

Epoch: 6| Step: 10
Training loss: 0.4420616030693054
Validation loss: 1.6895475951574181

Epoch: 6| Step: 11
Training loss: 0.452715665102005
Validation loss: 1.6748523442975936

Epoch: 6| Step: 12
Training loss: 0.6260577440261841
Validation loss: 1.6638174851735432

Epoch: 6| Step: 13
Training loss: 0.33115625381469727
Validation loss: 1.7337610529315086

Epoch: 430| Step: 0
Training loss: 0.3827379047870636
Validation loss: 1.739819501035957

Epoch: 6| Step: 1
Training loss: 0.23104624450206757
Validation loss: 1.7657451796275314

Epoch: 6| Step: 2
Training loss: 0.3315185606479645
Validation loss: 1.7483704192664034

Epoch: 6| Step: 3
Training loss: 0.3629377782344818
Validation loss: 1.729855038786447

Epoch: 6| Step: 4
Training loss: 0.49754056334495544
Validation loss: 1.7502033992480206

Epoch: 6| Step: 5
Training loss: 0.3725881576538086
Validation loss: 1.764587458743844

Epoch: 6| Step: 6
Training loss: 0.28405171632766724
Validation loss: 1.7604547867210962

Epoch: 6| Step: 7
Training loss: 0.41802382469177246
Validation loss: 1.7889185374782932

Epoch: 6| Step: 8
Training loss: 0.44397205114364624
Validation loss: 1.7314032111116635

Epoch: 6| Step: 9
Training loss: 0.5692404508590698
Validation loss: 1.705041531593569

Epoch: 6| Step: 10
Training loss: 0.23002177476882935
Validation loss: 1.6895744992840676

Epoch: 6| Step: 11
Training loss: 0.591816782951355
Validation loss: 1.6620629051680207

Epoch: 6| Step: 12
Training loss: 0.46524786949157715
Validation loss: 1.6526720023924304

Epoch: 6| Step: 13
Training loss: 0.6358764171600342
Validation loss: 1.6562502614913448

Epoch: 431| Step: 0
Training loss: 0.3033129870891571
Validation loss: 1.6550148738327848

Epoch: 6| Step: 1
Training loss: 0.6018334031105042
Validation loss: 1.6669502386482813

Epoch: 6| Step: 2
Training loss: 0.43751996755599976
Validation loss: 1.6961091808093491

Epoch: 6| Step: 3
Training loss: 0.14884066581726074
Validation loss: 1.7130128350309146

Epoch: 6| Step: 4
Training loss: 0.3200722336769104
Validation loss: 1.722668807993653

Epoch: 6| Step: 5
Training loss: 0.23612962663173676
Validation loss: 1.7502571613557878

Epoch: 6| Step: 6
Training loss: 0.5155757069587708
Validation loss: 1.7810734010511828

Epoch: 6| Step: 7
Training loss: 0.36866649985313416
Validation loss: 1.7664167445193055

Epoch: 6| Step: 8
Training loss: 0.40432077646255493
Validation loss: 1.7380080338447326

Epoch: 6| Step: 9
Training loss: 0.5067372918128967
Validation loss: 1.728341806319452

Epoch: 6| Step: 10
Training loss: 0.280444473028183
Validation loss: 1.7010821411686559

Epoch: 6| Step: 11
Training loss: 0.5661782026290894
Validation loss: 1.7179446528034825

Epoch: 6| Step: 12
Training loss: 0.7051732540130615
Validation loss: 1.6777205569769746

Epoch: 6| Step: 13
Training loss: 0.198215052485466
Validation loss: 1.6757745640252226

Epoch: 432| Step: 0
Training loss: 0.2873307466506958
Validation loss: 1.6940632340728596

Epoch: 6| Step: 1
Training loss: 0.5524137020111084
Validation loss: 1.670222802828717

Epoch: 6| Step: 2
Training loss: 0.31137871742248535
Validation loss: 1.6739064160213675

Epoch: 6| Step: 3
Training loss: 0.41055312752723694
Validation loss: 1.664597031890705

Epoch: 6| Step: 4
Training loss: 0.1862495243549347
Validation loss: 1.6818941716224916

Epoch: 6| Step: 5
Training loss: 0.5380418300628662
Validation loss: 1.6924715401023946

Epoch: 6| Step: 6
Training loss: 0.39127403497695923
Validation loss: 1.7030923853638351

Epoch: 6| Step: 7
Training loss: 0.4949003756046295
Validation loss: 1.661781963481698

Epoch: 6| Step: 8
Training loss: 0.36647772789001465
Validation loss: 1.6489086151123047

Epoch: 6| Step: 9
Training loss: 0.39680755138397217
Validation loss: 1.6509680568530996

Epoch: 6| Step: 10
Training loss: 0.23928028345108032
Validation loss: 1.6847750730411981

Epoch: 6| Step: 11
Training loss: 0.4302591383457184
Validation loss: 1.6839188145053001

Epoch: 6| Step: 12
Training loss: 0.32224875688552856
Validation loss: 1.7558912064439507

Epoch: 6| Step: 13
Training loss: 0.7372211217880249
Validation loss: 1.7524478307334326

Epoch: 433| Step: 0
Training loss: 0.281665563583374
Validation loss: 1.7504893323426605

Epoch: 6| Step: 1
Training loss: 0.3715722858905792
Validation loss: 1.7343165618117138

Epoch: 6| Step: 2
Training loss: 0.2032136619091034
Validation loss: 1.7364582528350174

Epoch: 6| Step: 3
Training loss: 0.5061607360839844
Validation loss: 1.692223366870675

Epoch: 6| Step: 4
Training loss: 0.39111053943634033
Validation loss: 1.7267841677511893

Epoch: 6| Step: 5
Training loss: 0.10044127702713013
Validation loss: 1.680979915844497

Epoch: 6| Step: 6
Training loss: 0.3758344352245331
Validation loss: 1.675605640616468

Epoch: 6| Step: 7
Training loss: 0.5010581612586975
Validation loss: 1.6489016035551667

Epoch: 6| Step: 8
Training loss: 0.5030219554901123
Validation loss: 1.66775635750063

Epoch: 6| Step: 9
Training loss: 0.526443600654602
Validation loss: 1.6466501489762337

Epoch: 6| Step: 10
Training loss: 0.5488928556442261
Validation loss: 1.6786700141045354

Epoch: 6| Step: 11
Training loss: 0.40119320154190063
Validation loss: 1.7061808019556024

Epoch: 6| Step: 12
Training loss: 0.2737697660923004
Validation loss: 1.6798617955177062

Epoch: 6| Step: 13
Training loss: 0.32490840554237366
Validation loss: 1.7132162637608026

Epoch: 434| Step: 0
Training loss: 0.23011918365955353
Validation loss: 1.7351764196990638

Epoch: 6| Step: 1
Training loss: 0.3618357181549072
Validation loss: 1.7425036238085838

Epoch: 6| Step: 2
Training loss: 0.3639755845069885
Validation loss: 1.7518496000638573

Epoch: 6| Step: 3
Training loss: 0.44327181577682495
Validation loss: 1.7185597445375176

Epoch: 6| Step: 4
Training loss: 0.430294394493103
Validation loss: 1.7024166122559579

Epoch: 6| Step: 5
Training loss: 0.4496304392814636
Validation loss: 1.6987731597756828

Epoch: 6| Step: 6
Training loss: 0.22685818374156952
Validation loss: 1.7225441830132597

Epoch: 6| Step: 7
Training loss: 0.43814900517463684
Validation loss: 1.7274012565612793

Epoch: 6| Step: 8
Training loss: 0.27515584230422974
Validation loss: 1.7168187018363708

Epoch: 6| Step: 9
Training loss: 0.5798825025558472
Validation loss: 1.7028370236837735

Epoch: 6| Step: 10
Training loss: 0.2499053031206131
Validation loss: 1.7132678108830606

Epoch: 6| Step: 11
Training loss: 0.08364057540893555
Validation loss: 1.7249549294030795

Epoch: 6| Step: 12
Training loss: 0.7596426010131836
Validation loss: 1.7622876282661193

Epoch: 6| Step: 13
Training loss: 0.40721386671066284
Validation loss: 1.7640401291590866

Epoch: 435| Step: 0
Training loss: 0.3654896020889282
Validation loss: 1.7957504013533234

Epoch: 6| Step: 1
Training loss: 0.34881791472435
Validation loss: 1.7569958394573582

Epoch: 6| Step: 2
Training loss: 0.2801204323768616
Validation loss: 1.721268182159752

Epoch: 6| Step: 3
Training loss: 0.5444457530975342
Validation loss: 1.6691755498609235

Epoch: 6| Step: 4
Training loss: 0.41840803623199463
Validation loss: 1.6880786931642922

Epoch: 6| Step: 5
Training loss: 0.21572420001029968
Validation loss: 1.719515001261106

Epoch: 6| Step: 6
Training loss: 0.42449313402175903
Validation loss: 1.7124667834210139

Epoch: 6| Step: 7
Training loss: 0.3825124204158783
Validation loss: 1.7194975781184372

Epoch: 6| Step: 8
Training loss: 0.4504413306713104
Validation loss: 1.7513200634269304

Epoch: 6| Step: 9
Training loss: 0.48710668087005615
Validation loss: 1.720649137291857

Epoch: 6| Step: 10
Training loss: 0.28710055351257324
Validation loss: 1.7243326569116244

Epoch: 6| Step: 11
Training loss: 0.3504906892776489
Validation loss: 1.7268309811110139

Epoch: 6| Step: 12
Training loss: 0.6626657247543335
Validation loss: 1.71860731545315

Epoch: 6| Step: 13
Training loss: 0.3259114623069763
Validation loss: 1.729159890964467

Epoch: 436| Step: 0
Training loss: 0.3877740502357483
Validation loss: 1.709504719703428

Epoch: 6| Step: 1
Training loss: 0.37339162826538086
Validation loss: 1.6885709019117459

Epoch: 6| Step: 2
Training loss: 0.310889333486557
Validation loss: 1.7378901743119763

Epoch: 6| Step: 3
Training loss: 0.3634244203567505
Validation loss: 1.6971950992461173

Epoch: 6| Step: 4
Training loss: 0.2863672077655792
Validation loss: 1.6716865211404779

Epoch: 6| Step: 5
Training loss: 0.4232226610183716
Validation loss: 1.6750475463046823

Epoch: 6| Step: 6
Training loss: 0.7296141386032104
Validation loss: 1.6422464142563522

Epoch: 6| Step: 7
Training loss: 0.24928614497184753
Validation loss: 1.6677361778033677

Epoch: 6| Step: 8
Training loss: 0.5862365961074829
Validation loss: 1.6673919795661845

Epoch: 6| Step: 9
Training loss: 0.29790279269218445
Validation loss: 1.659645518948955

Epoch: 6| Step: 10
Training loss: 0.22330480813980103
Validation loss: 1.6618383123028664

Epoch: 6| Step: 11
Training loss: 0.5143700838088989
Validation loss: 1.6766909168612572

Epoch: 6| Step: 12
Training loss: 0.21997947990894318
Validation loss: 1.670048798284223

Epoch: 6| Step: 13
Training loss: 0.5212757587432861
Validation loss: 1.7031223709865282

Epoch: 437| Step: 0
Training loss: 0.3058934211730957
Validation loss: 1.7436343739109654

Epoch: 6| Step: 1
Training loss: 0.5561956763267517
Validation loss: 1.6832024320479362

Epoch: 6| Step: 2
Training loss: 0.2752331793308258
Validation loss: 1.7303741670423938

Epoch: 6| Step: 3
Training loss: 0.30880820751190186
Validation loss: 1.7324834498026038

Epoch: 6| Step: 4
Training loss: 0.2752041518688202
Validation loss: 1.7358346562231741

Epoch: 6| Step: 5
Training loss: 0.32519954442977905
Validation loss: 1.7380371952569613

Epoch: 6| Step: 6
Training loss: 0.6400521993637085
Validation loss: 1.748167981383621

Epoch: 6| Step: 7
Training loss: 0.4635516107082367
Validation loss: 1.7444615120528846

Epoch: 6| Step: 8
Training loss: 0.34359636902809143
Validation loss: 1.7368527843106178

Epoch: 6| Step: 9
Training loss: 0.2424919754266739
Validation loss: 1.6998142042467672

Epoch: 6| Step: 10
Training loss: 0.5192201137542725
Validation loss: 1.7014803578776698

Epoch: 6| Step: 11
Training loss: 0.41655051708221436
Validation loss: 1.7269883155822754

Epoch: 6| Step: 12
Training loss: 0.49180418252944946
Validation loss: 1.7387516947202786

Epoch: 6| Step: 13
Training loss: 0.404185026884079
Validation loss: 1.7283529184197868

Epoch: 438| Step: 0
Training loss: 0.5132810473442078
Validation loss: 1.7396738747114777

Epoch: 6| Step: 1
Training loss: 0.5425950884819031
Validation loss: 1.7469611193544121

Epoch: 6| Step: 2
Training loss: 0.3107588291168213
Validation loss: 1.7342109539175545

Epoch: 6| Step: 3
Training loss: 0.19415265321731567
Validation loss: 1.7672546986610658

Epoch: 6| Step: 4
Training loss: 0.35228294134140015
Validation loss: 1.7862038920002599

Epoch: 6| Step: 5
Training loss: 0.5424879193305969
Validation loss: 1.8086242086143904

Epoch: 6| Step: 6
Training loss: 0.29489707946777344
Validation loss: 1.818742795657086

Epoch: 6| Step: 7
Training loss: 0.3867916464805603
Validation loss: 1.7455030641248148

Epoch: 6| Step: 8
Training loss: 0.3076385259628296
Validation loss: 1.7467833129308556

Epoch: 6| Step: 9
Training loss: 0.249120831489563
Validation loss: 1.6739820908474665

Epoch: 6| Step: 10
Training loss: 0.49023881554603577
Validation loss: 1.6665772955904725

Epoch: 6| Step: 11
Training loss: 0.44005826115608215
Validation loss: 1.666281230988041

Epoch: 6| Step: 12
Training loss: 0.4417053759098053
Validation loss: 1.6540163883598902

Epoch: 6| Step: 13
Training loss: 0.24252711236476898
Validation loss: 1.6691965095458492

Epoch: 439| Step: 0
Training loss: 0.5830486416816711
Validation loss: 1.714195264283047

Epoch: 6| Step: 1
Training loss: 0.4121543765068054
Validation loss: 1.7104563290073025

Epoch: 6| Step: 2
Training loss: 0.4744718372821808
Validation loss: 1.687511077491186

Epoch: 6| Step: 3
Training loss: 0.16574601829051971
Validation loss: 1.710034926732381

Epoch: 6| Step: 4
Training loss: 0.45567411184310913
Validation loss: 1.7123313027043496

Epoch: 6| Step: 5
Training loss: 0.7963029742240906
Validation loss: 1.7255329470480643

Epoch: 6| Step: 6
Training loss: 0.47002023458480835
Validation loss: 1.7261436780293782

Epoch: 6| Step: 7
Training loss: 0.2354557365179062
Validation loss: 1.6957835087212183

Epoch: 6| Step: 8
Training loss: 0.1139059066772461
Validation loss: 1.6984665432283956

Epoch: 6| Step: 9
Training loss: 0.3299294114112854
Validation loss: 1.6716249245469288

Epoch: 6| Step: 10
Training loss: 0.2596723735332489
Validation loss: 1.670233207364236

Epoch: 6| Step: 11
Training loss: 0.44078344106674194
Validation loss: 1.6920248026488929

Epoch: 6| Step: 12
Training loss: 0.2782896161079407
Validation loss: 1.70259294971343

Epoch: 6| Step: 13
Training loss: 0.36140140891075134
Validation loss: 1.7267466270795433

Epoch: 440| Step: 0
Training loss: 0.21341249346733093
Validation loss: 1.7052409084894324

Epoch: 6| Step: 1
Training loss: 0.39046889543533325
Validation loss: 1.7188871688740228

Epoch: 6| Step: 2
Training loss: 0.5409403443336487
Validation loss: 1.7075682276038713

Epoch: 6| Step: 3
Training loss: 0.29055655002593994
Validation loss: 1.7222799767730057

Epoch: 6| Step: 4
Training loss: 0.3779180645942688
Validation loss: 1.7159971575583182

Epoch: 6| Step: 5
Training loss: 0.6039103269577026
Validation loss: 1.7221549211009857

Epoch: 6| Step: 6
Training loss: 0.316212922334671
Validation loss: 1.7427751941065635

Epoch: 6| Step: 7
Training loss: 0.47564056515693665
Validation loss: 1.7006148433172574

Epoch: 6| Step: 8
Training loss: 0.30358752608299255
Validation loss: 1.6808538385616836

Epoch: 6| Step: 9
Training loss: 0.3948124349117279
Validation loss: 1.6960415032602125

Epoch: 6| Step: 10
Training loss: 0.27812257409095764
Validation loss: 1.7068347520725702

Epoch: 6| Step: 11
Training loss: 0.16180077195167542
Validation loss: 1.711625369646216

Epoch: 6| Step: 12
Training loss: 0.40946686267852783
Validation loss: 1.6407165950344456

Epoch: 6| Step: 13
Training loss: 0.3813898265361786
Validation loss: 1.642868967466457

Epoch: 441| Step: 0
Training loss: 0.5822553634643555
Validation loss: 1.6952924497665898

Epoch: 6| Step: 1
Training loss: 0.19589199125766754
Validation loss: 1.7365984006594586

Epoch: 6| Step: 2
Training loss: 0.21949508786201477
Validation loss: 1.743982740627822

Epoch: 6| Step: 3
Training loss: 0.39144042134284973
Validation loss: 1.7639107383707517

Epoch: 6| Step: 4
Training loss: 0.26462119817733765
Validation loss: 1.7690573725649106

Epoch: 6| Step: 5
Training loss: 0.2842575013637543
Validation loss: 1.7288881181388773

Epoch: 6| Step: 6
Training loss: 0.18772636353969574
Validation loss: 1.726099564183143

Epoch: 6| Step: 7
Training loss: 0.3466574549674988
Validation loss: 1.7235362709209483

Epoch: 6| Step: 8
Training loss: 0.2345317006111145
Validation loss: 1.678164219343534

Epoch: 6| Step: 9
Training loss: 0.5336838364601135
Validation loss: 1.7236437682182557

Epoch: 6| Step: 10
Training loss: 0.605774998664856
Validation loss: 1.6646464947731263

Epoch: 6| Step: 11
Training loss: 0.46392351388931274
Validation loss: 1.676087438419301

Epoch: 6| Step: 12
Training loss: 0.36264050006866455
Validation loss: 1.6682091656551565

Epoch: 6| Step: 13
Training loss: 0.35473382472991943
Validation loss: 1.6931344783434303

Epoch: 442| Step: 0
Training loss: 0.3009377419948578
Validation loss: 1.688817379295185

Epoch: 6| Step: 1
Training loss: 0.4507408142089844
Validation loss: 1.6458900897733626

Epoch: 6| Step: 2
Training loss: 0.45371299982070923
Validation loss: 1.6799227601738387

Epoch: 6| Step: 3
Training loss: 0.46975284814834595
Validation loss: 1.6433313444096556

Epoch: 6| Step: 4
Training loss: 0.2687913775444031
Validation loss: 1.6401159007062194

Epoch: 6| Step: 5
Training loss: 0.4139130711555481
Validation loss: 1.6560596727555799

Epoch: 6| Step: 6
Training loss: 0.39254361391067505
Validation loss: 1.669224344274049

Epoch: 6| Step: 7
Training loss: 0.12280444800853729
Validation loss: 1.6855129670071345

Epoch: 6| Step: 8
Training loss: 0.3708127737045288
Validation loss: 1.6924573465060162

Epoch: 6| Step: 9
Training loss: 0.3376598656177521
Validation loss: 1.7512170525007351

Epoch: 6| Step: 10
Training loss: 0.38690048456192017
Validation loss: 1.7245175210378503

Epoch: 6| Step: 11
Training loss: 0.49311745166778564
Validation loss: 1.7153523955293881

Epoch: 6| Step: 12
Training loss: 0.44949620962142944
Validation loss: 1.722487400936824

Epoch: 6| Step: 13
Training loss: 0.4524020552635193
Validation loss: 1.6991456631691224

Epoch: 443| Step: 0
Training loss: 0.37247204780578613
Validation loss: 1.6981450344926567

Epoch: 6| Step: 1
Training loss: 0.302858829498291
Validation loss: 1.677396705073695

Epoch: 6| Step: 2
Training loss: 0.6415550112724304
Validation loss: 1.6818580435168358

Epoch: 6| Step: 3
Training loss: 0.3916562497615814
Validation loss: 1.6592437336521764

Epoch: 6| Step: 4
Training loss: 0.4588121473789215
Validation loss: 1.6545458480875979

Epoch: 6| Step: 5
Training loss: 0.4991373121738434
Validation loss: 1.6533967769274147

Epoch: 6| Step: 6
Training loss: 0.20537912845611572
Validation loss: 1.6500186663801952

Epoch: 6| Step: 7
Training loss: 0.48612233996391296
Validation loss: 1.677665437421491

Epoch: 6| Step: 8
Training loss: 0.168348491191864
Validation loss: 1.732310906533272

Epoch: 6| Step: 9
Training loss: 0.3328869342803955
Validation loss: 1.742216803694284

Epoch: 6| Step: 10
Training loss: 0.4364238381385803
Validation loss: 1.7720747340110041

Epoch: 6| Step: 11
Training loss: 0.4868110418319702
Validation loss: 1.7387286411818637

Epoch: 6| Step: 12
Training loss: 0.20430748164653778
Validation loss: 1.7181273429624495

Epoch: 6| Step: 13
Training loss: 0.18902993202209473
Validation loss: 1.7108965073862383

Epoch: 444| Step: 0
Training loss: 0.24929647147655487
Validation loss: 1.6873611096412904

Epoch: 6| Step: 1
Training loss: 0.6193687319755554
Validation loss: 1.709175311109071

Epoch: 6| Step: 2
Training loss: 0.17137888073921204
Validation loss: 1.7282106620009228

Epoch: 6| Step: 3
Training loss: 0.24370454251766205
Validation loss: 1.694066216868739

Epoch: 6| Step: 4
Training loss: 0.4889119863510132
Validation loss: 1.7382257561529837

Epoch: 6| Step: 5
Training loss: 0.3738805949687958
Validation loss: 1.7122371965839016

Epoch: 6| Step: 6
Training loss: 0.2542791962623596
Validation loss: 1.772258315035092

Epoch: 6| Step: 7
Training loss: 0.40867185592651367
Validation loss: 1.7533136862580494

Epoch: 6| Step: 8
Training loss: 0.3737410306930542
Validation loss: 1.7450153443121141

Epoch: 6| Step: 9
Training loss: 0.32179898023605347
Validation loss: 1.75631502110471

Epoch: 6| Step: 10
Training loss: 0.5251187682151794
Validation loss: 1.728802300268604

Epoch: 6| Step: 11
Training loss: 0.47853899002075195
Validation loss: 1.7237165679213822

Epoch: 6| Step: 12
Training loss: 0.41636529564857483
Validation loss: 1.675402206759299

Epoch: 6| Step: 13
Training loss: 0.4514230191707611
Validation loss: 1.7061999702966342

Epoch: 445| Step: 0
Training loss: 0.2080310732126236
Validation loss: 1.6470891019349456

Epoch: 6| Step: 1
Training loss: 0.20013990998268127
Validation loss: 1.649449025430987

Epoch: 6| Step: 2
Training loss: 0.23921826481819153
Validation loss: 1.6825991266517228

Epoch: 6| Step: 3
Training loss: 0.4134328365325928
Validation loss: 1.6844744259311306

Epoch: 6| Step: 4
Training loss: 0.5905694961547852
Validation loss: 1.6958659182312668

Epoch: 6| Step: 5
Training loss: 0.37555599212646484
Validation loss: 1.7351140476042224

Epoch: 6| Step: 6
Training loss: 0.46520140767097473
Validation loss: 1.7677130468430058

Epoch: 6| Step: 7
Training loss: 0.340341180562973
Validation loss: 1.783945991146949

Epoch: 6| Step: 8
Training loss: 0.5105770230293274
Validation loss: 1.7394402809040521

Epoch: 6| Step: 9
Training loss: 0.5554355382919312
Validation loss: 1.7097813044824908

Epoch: 6| Step: 10
Training loss: 0.34929853677749634
Validation loss: 1.7047192127473894

Epoch: 6| Step: 11
Training loss: 0.19748947024345398
Validation loss: 1.700936996808616

Epoch: 6| Step: 12
Training loss: 0.5004289746284485
Validation loss: 1.6727329069568264

Epoch: 6| Step: 13
Training loss: 0.4738609492778778
Validation loss: 1.6758614009426487

Epoch: 446| Step: 0
Training loss: 0.5929027795791626
Validation loss: 1.681698396641721

Epoch: 6| Step: 1
Training loss: 0.31564396619796753
Validation loss: 1.696146313862134

Epoch: 6| Step: 2
Training loss: 0.3616427183151245
Validation loss: 1.6973816733206473

Epoch: 6| Step: 3
Training loss: 0.41849789023399353
Validation loss: 1.691393579206159

Epoch: 6| Step: 4
Training loss: 0.3097797930240631
Validation loss: 1.7151115812281126

Epoch: 6| Step: 5
Training loss: 0.25021904706954956
Validation loss: 1.7127154437444543

Epoch: 6| Step: 6
Training loss: 0.3489152789115906
Validation loss: 1.7163581591780468

Epoch: 6| Step: 7
Training loss: 0.30352863669395447
Validation loss: 1.7269016876015613

Epoch: 6| Step: 8
Training loss: 0.5671252608299255
Validation loss: 1.7460767133261568

Epoch: 6| Step: 9
Training loss: 0.19462761282920837
Validation loss: 1.7510733783885997

Epoch: 6| Step: 10
Training loss: 0.25733911991119385
Validation loss: 1.7421872128722489

Epoch: 6| Step: 11
Training loss: 0.2560059726238251
Validation loss: 1.7066839241212415

Epoch: 6| Step: 12
Training loss: 0.41550496220588684
Validation loss: 1.7152556347590622

Epoch: 6| Step: 13
Training loss: 0.4224475622177124
Validation loss: 1.7155123051776682

Epoch: 447| Step: 0
Training loss: 0.3702089786529541
Validation loss: 1.7014897305478331

Epoch: 6| Step: 1
Training loss: 0.2532414197921753
Validation loss: 1.6977615779446018

Epoch: 6| Step: 2
Training loss: 0.36721813678741455
Validation loss: 1.699611863782329

Epoch: 6| Step: 3
Training loss: 0.48777180910110474
Validation loss: 1.6949354153807445

Epoch: 6| Step: 4
Training loss: 0.43646782636642456
Validation loss: 1.70457491823422

Epoch: 6| Step: 5
Training loss: 0.318036824464798
Validation loss: 1.7103006916661416

Epoch: 6| Step: 6
Training loss: 0.6040905714035034
Validation loss: 1.6949710435764764

Epoch: 6| Step: 7
Training loss: 0.24917373061180115
Validation loss: 1.6934217304311774

Epoch: 6| Step: 8
Training loss: 0.34391242265701294
Validation loss: 1.728705419007168

Epoch: 6| Step: 9
Training loss: 0.18227319419384003
Validation loss: 1.6932327849890596

Epoch: 6| Step: 10
Training loss: 0.423994243144989
Validation loss: 1.7040837618612474

Epoch: 6| Step: 11
Training loss: 0.36181244254112244
Validation loss: 1.7207914642108384

Epoch: 6| Step: 12
Training loss: 0.3923428952693939
Validation loss: 1.6970026967346028

Epoch: 6| Step: 13
Training loss: 0.4983697533607483
Validation loss: 1.685501358842337

Epoch: 448| Step: 0
Training loss: 0.18947620689868927
Validation loss: 1.7017535291692263

Epoch: 6| Step: 1
Training loss: 0.4541842043399811
Validation loss: 1.6853549377892607

Epoch: 6| Step: 2
Training loss: 0.5553503036499023
Validation loss: 1.685054898262024

Epoch: 6| Step: 3
Training loss: 0.24089720845222473
Validation loss: 1.6793682447043798

Epoch: 6| Step: 4
Training loss: 0.500652015209198
Validation loss: 1.656217630191516

Epoch: 6| Step: 5
Training loss: 0.3566914498806
Validation loss: 1.6703241627703431

Epoch: 6| Step: 6
Training loss: 0.3869355320930481
Validation loss: 1.6771482113868958

Epoch: 6| Step: 7
Training loss: 0.4296097755432129
Validation loss: 1.6298792298122118

Epoch: 6| Step: 8
Training loss: 0.24884355068206787
Validation loss: 1.6570920457122147

Epoch: 6| Step: 9
Training loss: 0.40944939851760864
Validation loss: 1.6723279786366287

Epoch: 6| Step: 10
Training loss: 0.35370928049087524
Validation loss: 1.6949005562772033

Epoch: 6| Step: 11
Training loss: 0.5430152416229248
Validation loss: 1.7228644970924623

Epoch: 6| Step: 12
Training loss: 0.22829201817512512
Validation loss: 1.724416982743048

Epoch: 6| Step: 13
Training loss: 0.2886360287666321
Validation loss: 1.7050492878883117

Epoch: 449| Step: 0
Training loss: 0.4137522280216217
Validation loss: 1.7561907127339353

Epoch: 6| Step: 1
Training loss: 0.48751920461654663
Validation loss: 1.7257970097244426

Epoch: 6| Step: 2
Training loss: 0.2723497450351715
Validation loss: 1.7788633710594588

Epoch: 6| Step: 3
Training loss: 0.42542678117752075
Validation loss: 1.7397086645967217

Epoch: 6| Step: 4
Training loss: 0.6725752949714661
Validation loss: 1.719145736386699

Epoch: 6| Step: 5
Training loss: 0.3220210671424866
Validation loss: 1.7104669129976662

Epoch: 6| Step: 6
Training loss: 0.4621211886405945
Validation loss: 1.7196835689647223

Epoch: 6| Step: 7
Training loss: 0.30331408977508545
Validation loss: 1.7436151607062227

Epoch: 6| Step: 8
Training loss: 0.24494892358779907
Validation loss: 1.7541902449823195

Epoch: 6| Step: 9
Training loss: 0.35511985421180725
Validation loss: 1.7591677981038247

Epoch: 6| Step: 10
Training loss: 0.388152539730072
Validation loss: 1.7464484091727965

Epoch: 6| Step: 11
Training loss: 0.43879783153533936
Validation loss: 1.7655706726094729

Epoch: 6| Step: 12
Training loss: 0.20949038863182068
Validation loss: 1.759639754090258

Epoch: 6| Step: 13
Training loss: 0.47612279653549194
Validation loss: 1.8175946999621648

Epoch: 450| Step: 0
Training loss: 0.5621258020401001
Validation loss: 1.7884873984962382

Epoch: 6| Step: 1
Training loss: 0.34489554166793823
Validation loss: 1.7537663752032864

Epoch: 6| Step: 2
Training loss: 0.32495665550231934
Validation loss: 1.7529682510642595

Epoch: 6| Step: 3
Training loss: 0.14661791920661926
Validation loss: 1.6994235900140577

Epoch: 6| Step: 4
Training loss: 0.25710874795913696
Validation loss: 1.711853972045324

Epoch: 6| Step: 5
Training loss: 0.5995262265205383
Validation loss: 1.7172382288081671

Epoch: 6| Step: 6
Training loss: 0.15927352011203766
Validation loss: 1.7317448303263674

Epoch: 6| Step: 7
Training loss: 0.39766326546669006
Validation loss: 1.6840866060667141

Epoch: 6| Step: 8
Training loss: 0.5482792854309082
Validation loss: 1.6762728050190916

Epoch: 6| Step: 9
Training loss: 0.31780269742012024
Validation loss: 1.6403397385792067

Epoch: 6| Step: 10
Training loss: 0.1902226209640503
Validation loss: 1.6291715829603133

Epoch: 6| Step: 11
Training loss: 0.4672200679779053
Validation loss: 1.6817077821300876

Epoch: 6| Step: 12
Training loss: 0.4279762804508209
Validation loss: 1.7109062979298253

Epoch: 6| Step: 13
Training loss: 0.3185326159000397
Validation loss: 1.7288218390557073

Epoch: 451| Step: 0
Training loss: 0.28979814052581787
Validation loss: 1.7288565968954435

Epoch: 6| Step: 1
Training loss: 0.5982251167297363
Validation loss: 1.7311520307294783

Epoch: 6| Step: 2
Training loss: 0.44991400837898254
Validation loss: 1.750177808987197

Epoch: 6| Step: 3
Training loss: 0.2077227085828781
Validation loss: 1.7327428915167367

Epoch: 6| Step: 4
Training loss: 0.3157345652580261
Validation loss: 1.732666577062299

Epoch: 6| Step: 5
Training loss: 0.39663267135620117
Validation loss: 1.7127307371426654

Epoch: 6| Step: 6
Training loss: 0.48316046595573425
Validation loss: 1.709058371923303

Epoch: 6| Step: 7
Training loss: 0.32650303840637207
Validation loss: 1.6861369263741277

Epoch: 6| Step: 8
Training loss: 0.4581697881221771
Validation loss: 1.6802249672592326

Epoch: 6| Step: 9
Training loss: 0.44360941648483276
Validation loss: 1.661976860415551

Epoch: 6| Step: 10
Training loss: 0.3622902035713196
Validation loss: 1.6450845169764694

Epoch: 6| Step: 11
Training loss: 0.2901727855205536
Validation loss: 1.6636959391255532

Epoch: 6| Step: 12
Training loss: 0.1831551045179367
Validation loss: 1.6367376042950539

Epoch: 6| Step: 13
Training loss: 0.07870057225227356
Validation loss: 1.6378983528383317

Epoch: 452| Step: 0
Training loss: 0.30032771825790405
Validation loss: 1.6920318872697893

Epoch: 6| Step: 1
Training loss: 0.573952317237854
Validation loss: 1.6987653534899476

Epoch: 6| Step: 2
Training loss: 0.5855984687805176
Validation loss: 1.7072370847066243

Epoch: 6| Step: 3
Training loss: 0.2838212847709656
Validation loss: 1.670459497359491

Epoch: 6| Step: 4
Training loss: 0.28290629386901855
Validation loss: 1.6675526031883814

Epoch: 6| Step: 5
Training loss: 0.18683460354804993
Validation loss: 1.6616729126181653

Epoch: 6| Step: 6
Training loss: 0.3037501573562622
Validation loss: 1.6579165304860761

Epoch: 6| Step: 7
Training loss: 0.5155979990959167
Validation loss: 1.6176812507772957

Epoch: 6| Step: 8
Training loss: 0.47704529762268066
Validation loss: 1.6476684001184279

Epoch: 6| Step: 9
Training loss: 0.32385122776031494
Validation loss: 1.6862421753585979

Epoch: 6| Step: 10
Training loss: 0.2777395248413086
Validation loss: 1.6817751610150902

Epoch: 6| Step: 11
Training loss: 0.4025461971759796
Validation loss: 1.6971141407566686

Epoch: 6| Step: 12
Training loss: 0.5271123647689819
Validation loss: 1.6967126784786102

Epoch: 6| Step: 13
Training loss: 0.19201204180717468
Validation loss: 1.6675371726353962

Epoch: 453| Step: 0
Training loss: 0.3996274471282959
Validation loss: 1.6817397084287418

Epoch: 6| Step: 1
Training loss: 0.2700173258781433
Validation loss: 1.7068332292700326

Epoch: 6| Step: 2
Training loss: 0.3127171993255615
Validation loss: 1.6804838693270119

Epoch: 6| Step: 3
Training loss: 0.2578155994415283
Validation loss: 1.67023294074561

Epoch: 6| Step: 4
Training loss: 0.3991791009902954
Validation loss: 1.6589908240943827

Epoch: 6| Step: 5
Training loss: 0.44474291801452637
Validation loss: 1.7091454959684802

Epoch: 6| Step: 6
Training loss: 0.1905226856470108
Validation loss: 1.6951423306618967

Epoch: 6| Step: 7
Training loss: 0.4290362596511841
Validation loss: 1.6769943647487189

Epoch: 6| Step: 8
Training loss: 0.5214815139770508
Validation loss: 1.6851079604958976

Epoch: 6| Step: 9
Training loss: 0.5076242685317993
Validation loss: 1.6701645133315877

Epoch: 6| Step: 10
Training loss: 0.6229936480522156
Validation loss: 1.6841800905043078

Epoch: 6| Step: 11
Training loss: 0.5844876766204834
Validation loss: 1.6654748749989334

Epoch: 6| Step: 12
Training loss: 0.33235904574394226
Validation loss: 1.6853563272824852

Epoch: 6| Step: 13
Training loss: 0.3084113597869873
Validation loss: 1.6863223506558327

Epoch: 454| Step: 0
Training loss: 0.32144173979759216
Validation loss: 1.6660620948319793

Epoch: 6| Step: 1
Training loss: 0.30421340465545654
Validation loss: 1.691121168034051

Epoch: 6| Step: 2
Training loss: 0.35684049129486084
Validation loss: 1.7432281868432158

Epoch: 6| Step: 3
Training loss: 0.4046087861061096
Validation loss: 1.7588971020073019

Epoch: 6| Step: 4
Training loss: 0.4365893304347992
Validation loss: 1.8001674311135405

Epoch: 6| Step: 5
Training loss: 0.360121488571167
Validation loss: 1.7749102859086887

Epoch: 6| Step: 6
Training loss: 0.31901928782463074
Validation loss: 1.789762294420632

Epoch: 6| Step: 7
Training loss: 0.384365975856781
Validation loss: 1.7304377901938655

Epoch: 6| Step: 8
Training loss: 0.37453609704971313
Validation loss: 1.7234077825341174

Epoch: 6| Step: 9
Training loss: 0.4782518148422241
Validation loss: 1.7185714334569953

Epoch: 6| Step: 10
Training loss: 0.24230335652828217
Validation loss: 1.6952367758238187

Epoch: 6| Step: 11
Training loss: 0.31805282831192017
Validation loss: 1.6715108861205399

Epoch: 6| Step: 12
Training loss: 0.434822678565979
Validation loss: 1.6798839210182108

Epoch: 6| Step: 13
Training loss: 0.33405011892318726
Validation loss: 1.6749667762428202

Epoch: 455| Step: 0
Training loss: 0.40643489360809326
Validation loss: 1.6650186149022912

Epoch: 6| Step: 1
Training loss: 0.31694531440734863
Validation loss: 1.7208050322789017

Epoch: 6| Step: 2
Training loss: 0.4563347399234772
Validation loss: 1.6973656685121599

Epoch: 6| Step: 3
Training loss: 0.1871674507856369
Validation loss: 1.7078004011543848

Epoch: 6| Step: 4
Training loss: 0.3103845417499542
Validation loss: 1.7103256935714393

Epoch: 6| Step: 5
Training loss: 0.6022827625274658
Validation loss: 1.735033582615596

Epoch: 6| Step: 6
Training loss: 0.37237095832824707
Validation loss: 1.7101238696805892

Epoch: 6| Step: 7
Training loss: 0.24100922048091888
Validation loss: 1.7096894428294191

Epoch: 6| Step: 8
Training loss: 0.48333728313446045
Validation loss: 1.692458083552699

Epoch: 6| Step: 9
Training loss: 0.3849060535430908
Validation loss: 1.6896796072683027

Epoch: 6| Step: 10
Training loss: 0.2838970720767975
Validation loss: 1.6896218112719956

Epoch: 6| Step: 11
Training loss: 0.2881777882575989
Validation loss: 1.6622664261889715

Epoch: 6| Step: 12
Training loss: 0.4235576391220093
Validation loss: 1.649917297465827

Epoch: 6| Step: 13
Training loss: 0.22260962426662445
Validation loss: 1.7393288945639005

Epoch: 456| Step: 0
Training loss: 0.39240002632141113
Validation loss: 1.7020436422799223

Epoch: 6| Step: 1
Training loss: 0.4530666172504425
Validation loss: 1.6924955447514851

Epoch: 6| Step: 2
Training loss: 0.23419439792633057
Validation loss: 1.6843595607306368

Epoch: 6| Step: 3
Training loss: 0.3003648519515991
Validation loss: 1.6554323396375101

Epoch: 6| Step: 4
Training loss: 0.4202069044113159
Validation loss: 1.6491335604780464

Epoch: 6| Step: 5
Training loss: 0.323193222284317
Validation loss: 1.6909322469465193

Epoch: 6| Step: 6
Training loss: 0.35010093450546265
Validation loss: 1.69784225186994

Epoch: 6| Step: 7
Training loss: 0.3546937108039856
Validation loss: 1.7233858851976291

Epoch: 6| Step: 8
Training loss: 0.3352017104625702
Validation loss: 1.7317662662075413

Epoch: 6| Step: 9
Training loss: 0.18742038309574127
Validation loss: 1.6979050046654158

Epoch: 6| Step: 10
Training loss: 0.6240171194076538
Validation loss: 1.7369991835727487

Epoch: 6| Step: 11
Training loss: 0.3626817464828491
Validation loss: 1.6963811241170412

Epoch: 6| Step: 12
Training loss: 0.20395396649837494
Validation loss: 1.7473112075559554

Epoch: 6| Step: 13
Training loss: 0.32263490557670593
Validation loss: 1.7159614537351875

Epoch: 457| Step: 0
Training loss: 0.396345317363739
Validation loss: 1.677449078970058

Epoch: 6| Step: 1
Training loss: 0.2714773118495941
Validation loss: 1.6784999780757452

Epoch: 6| Step: 2
Training loss: 0.1600038707256317
Validation loss: 1.6763014178122244

Epoch: 6| Step: 3
Training loss: 0.34356164932250977
Validation loss: 1.6065946394397366

Epoch: 6| Step: 4
Training loss: 0.3917217254638672
Validation loss: 1.6362351448305192

Epoch: 6| Step: 5
Training loss: 0.2455589324235916
Validation loss: 1.6295231619188864

Epoch: 6| Step: 6
Training loss: 0.3320547342300415
Validation loss: 1.6766933305289156

Epoch: 6| Step: 7
Training loss: 0.3165442943572998
Validation loss: 1.6496154236537155

Epoch: 6| Step: 8
Training loss: 0.4589865207672119
Validation loss: 1.6784393684838408

Epoch: 6| Step: 9
Training loss: 0.1594814658164978
Validation loss: 1.6445406265156244

Epoch: 6| Step: 10
Training loss: 0.5127385258674622
Validation loss: 1.6639742018074117

Epoch: 6| Step: 11
Training loss: 0.40065398812294006
Validation loss: 1.6966804227521342

Epoch: 6| Step: 12
Training loss: 0.35420066118240356
Validation loss: 1.6479135943997292

Epoch: 6| Step: 13
Training loss: 0.2396007627248764
Validation loss: 1.6757795528698993

Epoch: 458| Step: 0
Training loss: 0.2612285017967224
Validation loss: 1.6635546838083575

Epoch: 6| Step: 1
Training loss: 0.3172632157802582
Validation loss: 1.6666239564136793

Epoch: 6| Step: 2
Training loss: 0.21077176928520203
Validation loss: 1.6735476345144293

Epoch: 6| Step: 3
Training loss: 0.2255256474018097
Validation loss: 1.6540383356873707

Epoch: 6| Step: 4
Training loss: 0.3679681420326233
Validation loss: 1.688541417480797

Epoch: 6| Step: 5
Training loss: 0.2622430622577667
Validation loss: 1.6713865059678272

Epoch: 6| Step: 6
Training loss: 0.314701110124588
Validation loss: 1.709241154373333

Epoch: 6| Step: 7
Training loss: 0.2777707576751709
Validation loss: 1.7026401104465607

Epoch: 6| Step: 8
Training loss: 0.6044422388076782
Validation loss: 1.7416660567765594

Epoch: 6| Step: 9
Training loss: 0.4260651171207428
Validation loss: 1.7113637065374723

Epoch: 6| Step: 10
Training loss: 0.4364776909351349
Validation loss: 1.7100053589831117

Epoch: 6| Step: 11
Training loss: 0.2996442914009094
Validation loss: 1.705397564877746

Epoch: 6| Step: 12
Training loss: 0.16715137660503387
Validation loss: 1.709776355374244

Epoch: 6| Step: 13
Training loss: 0.5129305720329285
Validation loss: 1.716988335373581

Epoch: 459| Step: 0
Training loss: 0.3714216947555542
Validation loss: 1.7219833404787126

Epoch: 6| Step: 1
Training loss: 0.10636264830827713
Validation loss: 1.6686347159006263

Epoch: 6| Step: 2
Training loss: 0.4951801598072052
Validation loss: 1.693449527986588

Epoch: 6| Step: 3
Training loss: 0.24809393286705017
Validation loss: 1.7208060884988436

Epoch: 6| Step: 4
Training loss: 0.5804509520530701
Validation loss: 1.6989446904069634

Epoch: 6| Step: 5
Training loss: 0.2906205356121063
Validation loss: 1.7203428181268836

Epoch: 6| Step: 6
Training loss: 0.28579896688461304
Validation loss: 1.7155310005270026

Epoch: 6| Step: 7
Training loss: 0.32429468631744385
Validation loss: 1.7163236423205304

Epoch: 6| Step: 8
Training loss: 0.4622432291507721
Validation loss: 1.7396303274298226

Epoch: 6| Step: 9
Training loss: 0.18152469396591187
Validation loss: 1.7084759332800423

Epoch: 6| Step: 10
Training loss: 0.38921844959259033
Validation loss: 1.710611399783883

Epoch: 6| Step: 11
Training loss: 0.5137144923210144
Validation loss: 1.682945059191796

Epoch: 6| Step: 12
Training loss: 0.1871400773525238
Validation loss: 1.6549965252158463

Epoch: 6| Step: 13
Training loss: 0.48240533471107483
Validation loss: 1.6498891820189774

Epoch: 460| Step: 0
Training loss: 0.41702497005462646
Validation loss: 1.6704796129657375

Epoch: 6| Step: 1
Training loss: 0.3292251229286194
Validation loss: 1.6605093838066183

Epoch: 6| Step: 2
Training loss: 0.3693006932735443
Validation loss: 1.6983679866278043

Epoch: 6| Step: 3
Training loss: 0.3408946394920349
Validation loss: 1.6858740532270042

Epoch: 6| Step: 4
Training loss: 0.2813730835914612
Validation loss: 1.7073014090138097

Epoch: 6| Step: 5
Training loss: 0.35130032896995544
Validation loss: 1.7446584342628397

Epoch: 6| Step: 6
Training loss: 0.5743159055709839
Validation loss: 1.756868031717116

Epoch: 6| Step: 7
Training loss: 0.22301089763641357
Validation loss: 1.7287039961866153

Epoch: 6| Step: 8
Training loss: 0.3650127053260803
Validation loss: 1.7529890473170946

Epoch: 6| Step: 9
Training loss: 0.4083254337310791
Validation loss: 1.6947236061096191

Epoch: 6| Step: 10
Training loss: 0.31746068596839905
Validation loss: 1.6926053095889348

Epoch: 6| Step: 11
Training loss: 0.3754112720489502
Validation loss: 1.661805401566208

Epoch: 6| Step: 12
Training loss: 0.28193825483322144
Validation loss: 1.6768691552582609

Epoch: 6| Step: 13
Training loss: 0.23122051358222961
Validation loss: 1.6544918757612987

Epoch: 461| Step: 0
Training loss: 0.34707963466644287
Validation loss: 1.656239773637505

Epoch: 6| Step: 1
Training loss: 0.21130186319351196
Validation loss: 1.6343876290064987

Epoch: 6| Step: 2
Training loss: 0.46418267488479614
Validation loss: 1.6251724061145578

Epoch: 6| Step: 3
Training loss: 0.4616893231868744
Validation loss: 1.6750144830314062

Epoch: 6| Step: 4
Training loss: 0.30077219009399414
Validation loss: 1.6673062309142082

Epoch: 6| Step: 5
Training loss: 0.27236640453338623
Validation loss: 1.652274756021397

Epoch: 6| Step: 6
Training loss: 0.341531366109848
Validation loss: 1.6736238374504993

Epoch: 6| Step: 7
Training loss: 0.38664665818214417
Validation loss: 1.694899861530591

Epoch: 6| Step: 8
Training loss: 0.2052794247865677
Validation loss: 1.665226165966321

Epoch: 6| Step: 9
Training loss: 0.17909950017929077
Validation loss: 1.7039719422658284

Epoch: 6| Step: 10
Training loss: 0.4075755476951599
Validation loss: 1.6830781762317946

Epoch: 6| Step: 11
Training loss: 0.2963404059410095
Validation loss: 1.682828595561366

Epoch: 6| Step: 12
Training loss: 0.45312273502349854
Validation loss: 1.6705759186898508

Epoch: 6| Step: 13
Training loss: 0.4091661274433136
Validation loss: 1.6412988452501194

Epoch: 462| Step: 0
Training loss: 0.35554075241088867
Validation loss: 1.6596885406842796

Epoch: 6| Step: 1
Training loss: 0.31376218795776367
Validation loss: 1.663222130908761

Epoch: 6| Step: 2
Training loss: 0.33912718296051025
Validation loss: 1.6460717954943258

Epoch: 6| Step: 3
Training loss: 0.5138170719146729
Validation loss: 1.6414003128646522

Epoch: 6| Step: 4
Training loss: 0.5422152280807495
Validation loss: 1.6877785921096802

Epoch: 6| Step: 5
Training loss: 0.3203583359718323
Validation loss: 1.6533288878779258

Epoch: 6| Step: 6
Training loss: 0.29781877994537354
Validation loss: 1.655133883158366

Epoch: 6| Step: 7
Training loss: 0.20999228954315186
Validation loss: 1.670147503575971

Epoch: 6| Step: 8
Training loss: 0.18763655424118042
Validation loss: 1.7150885699897684

Epoch: 6| Step: 9
Training loss: 0.1357642412185669
Validation loss: 1.7172617297018729

Epoch: 6| Step: 10
Training loss: 0.42472711205482483
Validation loss: 1.7251688818777762

Epoch: 6| Step: 11
Training loss: 0.43653449416160583
Validation loss: 1.7247807313037176

Epoch: 6| Step: 12
Training loss: 0.29019612073898315
Validation loss: 1.7225607133680774

Epoch: 6| Step: 13
Training loss: 0.4963672459125519
Validation loss: 1.680575160570042

Epoch: 463| Step: 0
Training loss: 0.5092906355857849
Validation loss: 1.7041907643759122

Epoch: 6| Step: 1
Training loss: 0.2286214530467987
Validation loss: 1.6499098334261166

Epoch: 6| Step: 2
Training loss: 0.19761638343334198
Validation loss: 1.647179058803025

Epoch: 6| Step: 3
Training loss: 0.3146427869796753
Validation loss: 1.6954013468116842

Epoch: 6| Step: 4
Training loss: 0.16928347945213318
Validation loss: 1.6728041646301106

Epoch: 6| Step: 5
Training loss: 0.4138394594192505
Validation loss: 1.634753692534662

Epoch: 6| Step: 6
Training loss: 0.40584713220596313
Validation loss: 1.6274411768041632

Epoch: 6| Step: 7
Training loss: 0.23829156160354614
Validation loss: 1.6786296547100108

Epoch: 6| Step: 8
Training loss: 0.11339127272367477
Validation loss: 1.6046547094980876

Epoch: 6| Step: 9
Training loss: 0.41589856147766113
Validation loss: 1.6878133179039083

Epoch: 6| Step: 10
Training loss: 0.4407912492752075
Validation loss: 1.7145352760950725

Epoch: 6| Step: 11
Training loss: 0.5826907753944397
Validation loss: 1.7493662641894432

Epoch: 6| Step: 12
Training loss: 0.30266687273979187
Validation loss: 1.7658145786613546

Epoch: 6| Step: 13
Training loss: 0.3247177302837372
Validation loss: 1.7302259681045369

Epoch: 464| Step: 0
Training loss: 0.40386173129081726
Validation loss: 1.7270871259832894

Epoch: 6| Step: 1
Training loss: 0.313113808631897
Validation loss: 1.6881486690172585

Epoch: 6| Step: 2
Training loss: 0.33315348625183105
Validation loss: 1.660796626921623

Epoch: 6| Step: 3
Training loss: 0.28418710827827454
Validation loss: 1.705621825751438

Epoch: 6| Step: 4
Training loss: 0.4041104316711426
Validation loss: 1.6782526687909198

Epoch: 6| Step: 5
Training loss: 0.5430608987808228
Validation loss: 1.661025530548506

Epoch: 6| Step: 6
Training loss: 0.3913433253765106
Validation loss: 1.6998878986604753

Epoch: 6| Step: 7
Training loss: 0.3228458762168884
Validation loss: 1.7118189065687117

Epoch: 6| Step: 8
Training loss: 0.38188356161117554
Validation loss: 1.7024484526726507

Epoch: 6| Step: 9
Training loss: 0.17263565957546234
Validation loss: 1.6767071716247066

Epoch: 6| Step: 10
Training loss: 0.2315313220024109
Validation loss: 1.7220250970573836

Epoch: 6| Step: 11
Training loss: 0.2628161311149597
Validation loss: 1.65393356866734

Epoch: 6| Step: 12
Training loss: 0.3103004992008209
Validation loss: 1.6837026739633212

Epoch: 6| Step: 13
Training loss: 0.2738289535045624
Validation loss: 1.6768451044636388

Epoch: 465| Step: 0
Training loss: 0.18001607060432434
Validation loss: 1.6667151669020295

Epoch: 6| Step: 1
Training loss: 0.23686975240707397
Validation loss: 1.6822348256264963

Epoch: 6| Step: 2
Training loss: 0.20392905175685883
Validation loss: 1.663329662815217

Epoch: 6| Step: 3
Training loss: 0.27989402413368225
Validation loss: 1.6855882380598335

Epoch: 6| Step: 4
Training loss: 0.45246419310569763
Validation loss: 1.6959622483099661

Epoch: 6| Step: 5
Training loss: 0.2871067523956299
Validation loss: 1.6913584073384602

Epoch: 6| Step: 6
Training loss: 0.41574615240097046
Validation loss: 1.6895653688779442

Epoch: 6| Step: 7
Training loss: 0.2022266834974289
Validation loss: 1.7083610667977283

Epoch: 6| Step: 8
Training loss: 0.2864096760749817
Validation loss: 1.7205622350015948

Epoch: 6| Step: 9
Training loss: 0.5056915879249573
Validation loss: 1.7060437317817443

Epoch: 6| Step: 10
Training loss: 0.31325823068618774
Validation loss: 1.7090030165128811

Epoch: 6| Step: 11
Training loss: 0.5357728004455566
Validation loss: 1.6589090516490321

Epoch: 6| Step: 12
Training loss: 0.3076944947242737
Validation loss: 1.6985210372555641

Epoch: 6| Step: 13
Training loss: 0.2888135015964508
Validation loss: 1.7287363390768729

Epoch: 466| Step: 0
Training loss: 0.3463398814201355
Validation loss: 1.7568002247041272

Epoch: 6| Step: 1
Training loss: 0.2748609185218811
Validation loss: 1.7314891456275858

Epoch: 6| Step: 2
Training loss: 0.32986968755722046
Validation loss: 1.7048831088568575

Epoch: 6| Step: 3
Training loss: 0.3417907953262329
Validation loss: 1.6771783739007928

Epoch: 6| Step: 4
Training loss: 0.4378608763217926
Validation loss: 1.6803915398095244

Epoch: 6| Step: 5
Training loss: 0.3591556251049042
Validation loss: 1.6708525778144918

Epoch: 6| Step: 6
Training loss: 0.38180011510849
Validation loss: 1.6453839450754144

Epoch: 6| Step: 7
Training loss: 0.3306548297405243
Validation loss: 1.6589235362186228

Epoch: 6| Step: 8
Training loss: 0.26852691173553467
Validation loss: 1.6571519221028974

Epoch: 6| Step: 9
Training loss: 0.2822490334510803
Validation loss: 1.6678834089668848

Epoch: 6| Step: 10
Training loss: 0.4040490388870239
Validation loss: 1.6969522853051462

Epoch: 6| Step: 11
Training loss: 0.4664541184902191
Validation loss: 1.698414348786877

Epoch: 6| Step: 12
Training loss: 0.14222857356071472
Validation loss: 1.7189630962187243

Epoch: 6| Step: 13
Training loss: 0.4833800494670868
Validation loss: 1.646567807402662

Epoch: 467| Step: 0
Training loss: 0.1904475837945938
Validation loss: 1.6511240479766682

Epoch: 6| Step: 1
Training loss: 0.19111061096191406
Validation loss: 1.6668232333275579

Epoch: 6| Step: 2
Training loss: 0.3395479917526245
Validation loss: 1.6482187099354242

Epoch: 6| Step: 3
Training loss: 0.316473126411438
Validation loss: 1.6452099789855301

Epoch: 6| Step: 4
Training loss: 0.3272593021392822
Validation loss: 1.6735390514455817

Epoch: 6| Step: 5
Training loss: 0.4179942309856415
Validation loss: 1.6509599813850977

Epoch: 6| Step: 6
Training loss: 0.3916686177253723
Validation loss: 1.6660047141454553

Epoch: 6| Step: 7
Training loss: 0.19072802364826202
Validation loss: 1.6739002120110296

Epoch: 6| Step: 8
Training loss: 0.28774386644363403
Validation loss: 1.6868851492481847

Epoch: 6| Step: 9
Training loss: 0.3203493654727936
Validation loss: 1.6739341097493325

Epoch: 6| Step: 10
Training loss: 0.45016705989837646
Validation loss: 1.6781964519972443

Epoch: 6| Step: 11
Training loss: 0.4816538691520691
Validation loss: 1.6939773380115468

Epoch: 6| Step: 12
Training loss: 0.31140726804733276
Validation loss: 1.6783181005908596

Epoch: 6| Step: 13
Training loss: 0.23468515276908875
Validation loss: 1.6818197145256946

Epoch: 468| Step: 0
Training loss: 0.16530819237232208
Validation loss: 1.6452122516529535

Epoch: 6| Step: 1
Training loss: 0.4931665062904358
Validation loss: 1.637520174826345

Epoch: 6| Step: 2
Training loss: 0.3592889904975891
Validation loss: 1.6166084684351438

Epoch: 6| Step: 3
Training loss: 0.3511625826358795
Validation loss: 1.664185857260099

Epoch: 6| Step: 4
Training loss: 0.2150382697582245
Validation loss: 1.6387278162023073

Epoch: 6| Step: 5
Training loss: 0.5610618591308594
Validation loss: 1.6119596060886179

Epoch: 6| Step: 6
Training loss: 0.26782307028770447
Validation loss: 1.6270555603888728

Epoch: 6| Step: 7
Training loss: 0.28706857562065125
Validation loss: 1.598951356385344

Epoch: 6| Step: 8
Training loss: 0.2381601184606552
Validation loss: 1.600738848409345

Epoch: 6| Step: 9
Training loss: 0.23875495791435242
Validation loss: 1.6027366307473951

Epoch: 6| Step: 10
Training loss: 0.19972021877765656
Validation loss: 1.577471762575129

Epoch: 6| Step: 11
Training loss: 0.3542636036872864
Validation loss: 1.6726034149046867

Epoch: 6| Step: 12
Training loss: 0.2976309061050415
Validation loss: 1.6681808912625877

Epoch: 6| Step: 13
Training loss: 0.3923870623111725
Validation loss: 1.6588031630362234

Epoch: 469| Step: 0
Training loss: 0.1997670978307724
Validation loss: 1.6832033190675961

Epoch: 6| Step: 1
Training loss: 0.4607972502708435
Validation loss: 1.6483101819151191

Epoch: 6| Step: 2
Training loss: 0.32553601264953613
Validation loss: 1.6460533590726956

Epoch: 6| Step: 3
Training loss: 0.40002620220184326
Validation loss: 1.6423045665987077

Epoch: 6| Step: 4
Training loss: 0.18717846274375916
Validation loss: 1.6258605859612907

Epoch: 6| Step: 5
Training loss: 0.4097833037376404
Validation loss: 1.609633066320932

Epoch: 6| Step: 6
Training loss: 0.31357133388519287
Validation loss: 1.6001145173144597

Epoch: 6| Step: 7
Training loss: 0.29025915265083313
Validation loss: 1.6118428399485927

Epoch: 6| Step: 8
Training loss: 0.3361215889453888
Validation loss: 1.600920226625217

Epoch: 6| Step: 9
Training loss: 0.1644146740436554
Validation loss: 1.6035003059653825

Epoch: 6| Step: 10
Training loss: 0.18368421494960785
Validation loss: 1.618774139752952

Epoch: 6| Step: 11
Training loss: 0.43013444542884827
Validation loss: 1.6260649837473387

Epoch: 6| Step: 12
Training loss: 0.3199176788330078
Validation loss: 1.665465897129428

Epoch: 6| Step: 13
Training loss: 0.34638112783432007
Validation loss: 1.649986409371899

Epoch: 470| Step: 0
Training loss: 0.11173077672719955
Validation loss: 1.615296152330214

Epoch: 6| Step: 1
Training loss: 0.39826491475105286
Validation loss: 1.7001065041429253

Epoch: 6| Step: 2
Training loss: 0.15093505382537842
Validation loss: 1.6794847134620912

Epoch: 6| Step: 3
Training loss: 0.3929494619369507
Validation loss: 1.6805253618506975

Epoch: 6| Step: 4
Training loss: 0.25585681200027466
Validation loss: 1.703552601157978

Epoch: 6| Step: 5
Training loss: 0.45090997219085693
Validation loss: 1.6940267368029522

Epoch: 6| Step: 6
Training loss: 0.37569472193717957
Validation loss: 1.7476057903740996

Epoch: 6| Step: 7
Training loss: 0.26097142696380615
Validation loss: 1.7146712323670745

Epoch: 6| Step: 8
Training loss: 0.44470494985580444
Validation loss: 1.6765263195960753

Epoch: 6| Step: 9
Training loss: 0.3595053553581238
Validation loss: 1.6700325678753596

Epoch: 6| Step: 10
Training loss: 0.2620909512042999
Validation loss: 1.6429195455325547

Epoch: 6| Step: 11
Training loss: 0.22025401890277863
Validation loss: 1.6717226133551648

Epoch: 6| Step: 12
Training loss: 0.3228873014450073
Validation loss: 1.673751405490342

Epoch: 6| Step: 13
Training loss: 0.36030614376068115
Validation loss: 1.6818709783656622

Epoch: 471| Step: 0
Training loss: 0.277606725692749
Validation loss: 1.7238998207994687

Epoch: 6| Step: 1
Training loss: 0.38969308137893677
Validation loss: 1.70302426943215

Epoch: 6| Step: 2
Training loss: 0.44509828090667725
Validation loss: 1.7169168456908195

Epoch: 6| Step: 3
Training loss: 0.3902010917663574
Validation loss: 1.719799776231089

Epoch: 6| Step: 4
Training loss: 0.19000108540058136
Validation loss: 1.7018127915679768

Epoch: 6| Step: 5
Training loss: 0.2592608332633972
Validation loss: 1.6907319727764334

Epoch: 6| Step: 6
Training loss: 0.18455485999584198
Validation loss: 1.680140656809653

Epoch: 6| Step: 7
Training loss: 0.5165420174598694
Validation loss: 1.6773021618525188

Epoch: 6| Step: 8
Training loss: 0.34124141931533813
Validation loss: 1.6268016202475435

Epoch: 6| Step: 9
Training loss: 0.3064110279083252
Validation loss: 1.6300228282969484

Epoch: 6| Step: 10
Training loss: 0.4217294454574585
Validation loss: 1.6454944469595467

Epoch: 6| Step: 11
Training loss: 0.21872574090957642
Validation loss: 1.6496343478079765

Epoch: 6| Step: 12
Training loss: 0.38244855403900146
Validation loss: 1.6685605279860958

Epoch: 6| Step: 13
Training loss: 0.22399398684501648
Validation loss: 1.6991982665113223

Epoch: 472| Step: 0
Training loss: 0.41436123847961426
Validation loss: 1.7584356723293182

Epoch: 6| Step: 1
Training loss: 0.44048261642456055
Validation loss: 1.7176441607936737

Epoch: 6| Step: 2
Training loss: 0.2451370358467102
Validation loss: 1.7173606964849657

Epoch: 6| Step: 3
Training loss: 0.12488140165805817
Validation loss: 1.6956309080123901

Epoch: 6| Step: 4
Training loss: 0.5164701342582703
Validation loss: 1.700088502258383

Epoch: 6| Step: 5
Training loss: 0.23365873098373413
Validation loss: 1.7054169216463644

Epoch: 6| Step: 6
Training loss: 0.43664786219596863
Validation loss: 1.6711491448904878

Epoch: 6| Step: 7
Training loss: 0.373740017414093
Validation loss: 1.6214054963921989

Epoch: 6| Step: 8
Training loss: 0.4128330647945404
Validation loss: 1.645404322813916

Epoch: 6| Step: 9
Training loss: 0.20036929845809937
Validation loss: 1.6460655645657611

Epoch: 6| Step: 10
Training loss: 0.34049487113952637
Validation loss: 1.6740431042127712

Epoch: 6| Step: 11
Training loss: 0.1668766736984253
Validation loss: 1.6654727266680809

Epoch: 6| Step: 12
Training loss: 0.38445574045181274
Validation loss: 1.6790723864750197

Epoch: 6| Step: 13
Training loss: 0.30978304147720337
Validation loss: 1.7063009277466805

Epoch: 473| Step: 0
Training loss: 0.314892053604126
Validation loss: 1.714991295209495

Epoch: 6| Step: 1
Training loss: 0.2658260762691498
Validation loss: 1.7642093127773655

Epoch: 6| Step: 2
Training loss: 0.3683502674102783
Validation loss: 1.7165750636849353

Epoch: 6| Step: 3
Training loss: 0.19636298716068268
Validation loss: 1.7100962913164528

Epoch: 6| Step: 4
Training loss: 0.413194864988327
Validation loss: 1.6751155032906482

Epoch: 6| Step: 5
Training loss: 0.389840304851532
Validation loss: 1.6956834844363633

Epoch: 6| Step: 6
Training loss: 0.5568534731864929
Validation loss: 1.6961795360811296

Epoch: 6| Step: 7
Training loss: 0.224664106965065
Validation loss: 1.6839055630468553

Epoch: 6| Step: 8
Training loss: 0.27358266711235046
Validation loss: 1.6744843939299225

Epoch: 6| Step: 9
Training loss: 0.32944124937057495
Validation loss: 1.6943036779280631

Epoch: 6| Step: 10
Training loss: 0.3000638484954834
Validation loss: 1.6583632474304528

Epoch: 6| Step: 11
Training loss: 0.4258278012275696
Validation loss: 1.6787921485080515

Epoch: 6| Step: 12
Training loss: 0.3574974834918976
Validation loss: 1.670806272055513

Epoch: 6| Step: 13
Training loss: 0.16689316928386688
Validation loss: 1.6738672589743009

Epoch: 474| Step: 0
Training loss: 0.1765783429145813
Validation loss: 1.705190384259788

Epoch: 6| Step: 1
Training loss: 0.22336287796497345
Validation loss: 1.7121227877114409

Epoch: 6| Step: 2
Training loss: 0.2340594232082367
Validation loss: 1.6855599341853973

Epoch: 6| Step: 3
Training loss: 0.3508676290512085
Validation loss: 1.705183998230965

Epoch: 6| Step: 4
Training loss: 0.5060948133468628
Validation loss: 1.6244229911476054

Epoch: 6| Step: 5
Training loss: 0.528552770614624
Validation loss: 1.635453321600473

Epoch: 6| Step: 6
Training loss: 0.12627452611923218
Validation loss: 1.636448896059426

Epoch: 6| Step: 7
Training loss: 0.30426451563835144
Validation loss: 1.6396757492455103

Epoch: 6| Step: 8
Training loss: 0.33203813433647156
Validation loss: 1.6657201243985085

Epoch: 6| Step: 9
Training loss: 0.36045774817466736
Validation loss: 1.671000139687651

Epoch: 6| Step: 10
Training loss: 0.31648164987564087
Validation loss: 1.6248438319852274

Epoch: 6| Step: 11
Training loss: 0.2967187464237213
Validation loss: 1.6802025251491095

Epoch: 6| Step: 12
Training loss: 0.3117944598197937
Validation loss: 1.6348763050571564

Epoch: 6| Step: 13
Training loss: 0.5421361327171326
Validation loss: 1.6454355024522351

Epoch: 475| Step: 0
Training loss: 0.2594568729400635
Validation loss: 1.6491335322779994

Epoch: 6| Step: 1
Training loss: 0.3205265998840332
Validation loss: 1.6407655938979118

Epoch: 6| Step: 2
Training loss: 0.3734784424304962
Validation loss: 1.6656853998861005

Epoch: 6| Step: 3
Training loss: 0.32249340415000916
Validation loss: 1.6987633794866583

Epoch: 6| Step: 4
Training loss: 0.2571188509464264
Validation loss: 1.6725151436303252

Epoch: 6| Step: 5
Training loss: 0.3173353672027588
Validation loss: 1.697819749514262

Epoch: 6| Step: 6
Training loss: 0.3723064064979553
Validation loss: 1.7040444727866881

Epoch: 6| Step: 7
Training loss: 0.382185697555542
Validation loss: 1.6640183464173348

Epoch: 6| Step: 8
Training loss: 0.21265466511249542
Validation loss: 1.6749330361684163

Epoch: 6| Step: 9
Training loss: 0.3181084990501404
Validation loss: 1.6748092033529793

Epoch: 6| Step: 10
Training loss: 0.37185585498809814
Validation loss: 1.6489099276963102

Epoch: 6| Step: 11
Training loss: 0.158189058303833
Validation loss: 1.6587162786914456

Epoch: 6| Step: 12
Training loss: 0.2720121145248413
Validation loss: 1.6138880329747354

Epoch: 6| Step: 13
Training loss: 0.11908800154924393
Validation loss: 1.6245852465270667

Epoch: 476| Step: 0
Training loss: 0.4557282626628876
Validation loss: 1.6206218901500906

Epoch: 6| Step: 1
Training loss: 0.2698299288749695
Validation loss: 1.6572416841342885

Epoch: 6| Step: 2
Training loss: 0.18278533220291138
Validation loss: 1.6325285255268056

Epoch: 6| Step: 3
Training loss: 0.3483039140701294
Validation loss: 1.6413140425118067

Epoch: 6| Step: 4
Training loss: 0.2513832449913025
Validation loss: 1.6417786305950535

Epoch: 6| Step: 5
Training loss: 0.4205433428287506
Validation loss: 1.645375568379638

Epoch: 6| Step: 6
Training loss: 0.33729544281959534
Validation loss: 1.6580642115685247

Epoch: 6| Step: 7
Training loss: 0.3799229860305786
Validation loss: 1.7061794470715266

Epoch: 6| Step: 8
Training loss: 0.31596630811691284
Validation loss: 1.659130081053703

Epoch: 6| Step: 9
Training loss: 0.25215691328048706
Validation loss: 1.651046166496892

Epoch: 6| Step: 10
Training loss: 0.2565775215625763
Validation loss: 1.654584534706608

Epoch: 6| Step: 11
Training loss: 0.4145292043685913
Validation loss: 1.671927377741824

Epoch: 6| Step: 12
Training loss: 0.35284775495529175
Validation loss: 1.635941537477637

Epoch: 6| Step: 13
Training loss: 0.19803687930107117
Validation loss: 1.6488443369506507

Epoch: 477| Step: 0
Training loss: 0.2156023234128952
Validation loss: 1.6351772418586157

Epoch: 6| Step: 1
Training loss: 0.2577283978462219
Validation loss: 1.6543288359078028

Epoch: 6| Step: 2
Training loss: 0.1704835146665573
Validation loss: 1.6253730148397467

Epoch: 6| Step: 3
Training loss: 0.3295823633670807
Validation loss: 1.6017505276587702

Epoch: 6| Step: 4
Training loss: 0.32419145107269287
Validation loss: 1.6072911242003083

Epoch: 6| Step: 5
Training loss: 0.3135680556297302
Validation loss: 1.5916099202248357

Epoch: 6| Step: 6
Training loss: 0.4213395118713379
Validation loss: 1.6071664774289696

Epoch: 6| Step: 7
Training loss: 0.17995911836624146
Validation loss: 1.571458819091961

Epoch: 6| Step: 8
Training loss: 0.49355992674827576
Validation loss: 1.5899186723975725

Epoch: 6| Step: 9
Training loss: 0.4062185287475586
Validation loss: 1.5902078382430538

Epoch: 6| Step: 10
Training loss: 0.33342212438583374
Validation loss: 1.613683207060701

Epoch: 6| Step: 11
Training loss: 0.48357105255126953
Validation loss: 1.650297296944485

Epoch: 6| Step: 12
Training loss: 0.5318701267242432
Validation loss: 1.6541884535102434

Epoch: 6| Step: 13
Training loss: 0.15850049257278442
Validation loss: 1.6732078752210062

Epoch: 478| Step: 0
Training loss: 0.32684096693992615
Validation loss: 1.6954475987342097

Epoch: 6| Step: 1
Training loss: 0.4443548321723938
Validation loss: 1.6921772239028767

Epoch: 6| Step: 2
Training loss: 0.2957521677017212
Validation loss: 1.6720882667008268

Epoch: 6| Step: 3
Training loss: 0.2093871533870697
Validation loss: 1.6262416813963203

Epoch: 6| Step: 4
Training loss: 0.28471437096595764
Validation loss: 1.6236435905579598

Epoch: 6| Step: 5
Training loss: 0.3830990195274353
Validation loss: 1.6473934445329892

Epoch: 6| Step: 6
Training loss: 0.24713698029518127
Validation loss: 1.6093092195449337

Epoch: 6| Step: 7
Training loss: 0.28925174474716187
Validation loss: 1.6045075155073596

Epoch: 6| Step: 8
Training loss: 0.31137746572494507
Validation loss: 1.641581525084793

Epoch: 6| Step: 9
Training loss: 0.31645041704177856
Validation loss: 1.6051576252906554

Epoch: 6| Step: 10
Training loss: 0.2760184705257416
Validation loss: 1.617278197760223

Epoch: 6| Step: 11
Training loss: 0.47034952044487
Validation loss: 1.6231477760499524

Epoch: 6| Step: 12
Training loss: 0.19657714664936066
Validation loss: 1.6751891297678794

Epoch: 6| Step: 13
Training loss: 0.3141704797744751
Validation loss: 1.6931018041026207

Epoch: 479| Step: 0
Training loss: 0.329407274723053
Validation loss: 1.7406799729152391

Epoch: 6| Step: 1
Training loss: 0.23221585154533386
Validation loss: 1.7332405018550094

Epoch: 6| Step: 2
Training loss: 0.25253114104270935
Validation loss: 1.7384786894244533

Epoch: 6| Step: 3
Training loss: 0.38648369908332825
Validation loss: 1.7004521354552238

Epoch: 6| Step: 4
Training loss: 0.228655144572258
Validation loss: 1.7308496941802323

Epoch: 6| Step: 5
Training loss: 0.3719486892223358
Validation loss: 1.6758648483983931

Epoch: 6| Step: 6
Training loss: 0.20351159572601318
Validation loss: 1.6648704236553562

Epoch: 6| Step: 7
Training loss: 0.353983998298645
Validation loss: 1.647984347035808

Epoch: 6| Step: 8
Training loss: 0.27464044094085693
Validation loss: 1.687670002701462

Epoch: 6| Step: 9
Training loss: 0.2517712116241455
Validation loss: 1.6622278780065558

Epoch: 6| Step: 10
Training loss: 0.6072379350662231
Validation loss: 1.6748610811848794

Epoch: 6| Step: 11
Training loss: 0.22589759528636932
Validation loss: 1.6505985798374299

Epoch: 6| Step: 12
Training loss: 0.40140795707702637
Validation loss: 1.6532592440164218

Epoch: 6| Step: 13
Training loss: 0.2777874767780304
Validation loss: 1.6714453261385682

Epoch: 480| Step: 0
Training loss: 0.22837409377098083
Validation loss: 1.660540142366963

Epoch: 6| Step: 1
Training loss: 0.30150923132896423
Validation loss: 1.6743290039800829

Epoch: 6| Step: 2
Training loss: 0.12886352837085724
Validation loss: 1.6808399897749706

Epoch: 6| Step: 3
Training loss: 0.3327822983264923
Validation loss: 1.6652727844894573

Epoch: 6| Step: 4
Training loss: 0.4553180932998657
Validation loss: 1.6512349843978882

Epoch: 6| Step: 5
Training loss: 0.26202547550201416
Validation loss: 1.6365654430081766

Epoch: 6| Step: 6
Training loss: 0.1810685098171234
Validation loss: 1.6788173388409358

Epoch: 6| Step: 7
Training loss: 0.3299834728240967
Validation loss: 1.6476670952253445

Epoch: 6| Step: 8
Training loss: 0.2530284523963928
Validation loss: 1.6326240929224158

Epoch: 6| Step: 9
Training loss: 0.5112846493721008
Validation loss: 1.6287599327743694

Epoch: 6| Step: 10
Training loss: 0.2590864300727844
Validation loss: 1.6379008126515213

Epoch: 6| Step: 11
Training loss: 0.41732269525527954
Validation loss: 1.6672728830768215

Epoch: 6| Step: 12
Training loss: 0.3749409317970276
Validation loss: 1.6647719901095155

Epoch: 6| Step: 13
Training loss: 0.20289629697799683
Validation loss: 1.6828735874545189

Epoch: 481| Step: 0
Training loss: 0.277150422334671
Validation loss: 1.6715208125370804

Epoch: 6| Step: 1
Training loss: 0.30962908267974854
Validation loss: 1.6949959839543989

Epoch: 6| Step: 2
Training loss: 0.2870725393295288
Validation loss: 1.7003887507223314

Epoch: 6| Step: 3
Training loss: 0.32068800926208496
Validation loss: 1.6921105807827366

Epoch: 6| Step: 4
Training loss: 0.23912137746810913
Validation loss: 1.7208548668892152

Epoch: 6| Step: 5
Training loss: 0.3398008942604065
Validation loss: 1.704990433108422

Epoch: 6| Step: 6
Training loss: 0.2556389272212982
Validation loss: 1.715721627717377

Epoch: 6| Step: 7
Training loss: 0.4215015769004822
Validation loss: 1.6681949323223484

Epoch: 6| Step: 8
Training loss: 0.4077640473842621
Validation loss: 1.6590212288723196

Epoch: 6| Step: 9
Training loss: 0.2810841500759125
Validation loss: 1.679099311110794

Epoch: 6| Step: 10
Training loss: 0.28000009059906006
Validation loss: 1.6742954382332422

Epoch: 6| Step: 11
Training loss: 0.18588021397590637
Validation loss: 1.6832815126706195

Epoch: 6| Step: 12
Training loss: 0.29243355989456177
Validation loss: 1.654233447967037

Epoch: 6| Step: 13
Training loss: 0.2199256718158722
Validation loss: 1.7158167926214074

Epoch: 482| Step: 0
Training loss: 0.21726296842098236
Validation loss: 1.6975353969040738

Epoch: 6| Step: 1
Training loss: 0.31567275524139404
Validation loss: 1.648136822126245

Epoch: 6| Step: 2
Training loss: 0.37100404500961304
Validation loss: 1.6811108512263144

Epoch: 6| Step: 3
Training loss: 0.24078264832496643
Validation loss: 1.65870544474612

Epoch: 6| Step: 4
Training loss: 0.2916266918182373
Validation loss: 1.6632141432454508

Epoch: 6| Step: 5
Training loss: 0.26267534494400024
Validation loss: 1.6626242373579292

Epoch: 6| Step: 6
Training loss: 0.23583804070949554
Validation loss: 1.6445089911901822

Epoch: 6| Step: 7
Training loss: 0.3740350902080536
Validation loss: 1.6769003573284353

Epoch: 6| Step: 8
Training loss: 0.46478357911109924
Validation loss: 1.6548805595726095

Epoch: 6| Step: 9
Training loss: 0.25084829330444336
Validation loss: 1.6311356175330378

Epoch: 6| Step: 10
Training loss: 0.2644851803779602
Validation loss: 1.6692837745912614

Epoch: 6| Step: 11
Training loss: 0.4141584038734436
Validation loss: 1.6389808526603125

Epoch: 6| Step: 12
Training loss: 0.3530465364456177
Validation loss: 1.6352879667794833

Epoch: 6| Step: 13
Training loss: 0.37207144498825073
Validation loss: 1.634711020736284

Epoch: 483| Step: 0
Training loss: 0.4119822084903717
Validation loss: 1.6628537870222522

Epoch: 6| Step: 1
Training loss: 0.29398950934410095
Validation loss: 1.6425234207542994

Epoch: 6| Step: 2
Training loss: 0.2074836641550064
Validation loss: 1.6747082805120816

Epoch: 6| Step: 3
Training loss: 0.16566476225852966
Validation loss: 1.6873311624732068

Epoch: 6| Step: 4
Training loss: 0.3591322898864746
Validation loss: 1.6683174717810847

Epoch: 6| Step: 5
Training loss: 0.17331437766551971
Validation loss: 1.6577155231147684

Epoch: 6| Step: 6
Training loss: 0.27169710397720337
Validation loss: 1.6492931919713174

Epoch: 6| Step: 7
Training loss: 0.21780656278133392
Validation loss: 1.6187258740907073

Epoch: 6| Step: 8
Training loss: 0.2159024477005005
Validation loss: 1.5811692271181332

Epoch: 6| Step: 9
Training loss: 0.49702829122543335
Validation loss: 1.6288966824931483

Epoch: 6| Step: 10
Training loss: 0.45307695865631104
Validation loss: 1.6502643144258888

Epoch: 6| Step: 11
Training loss: 0.3190889358520508
Validation loss: 1.6068702641353811

Epoch: 6| Step: 12
Training loss: 0.4145438075065613
Validation loss: 1.6578906172065324

Epoch: 6| Step: 13
Training loss: 0.38445284962654114
Validation loss: 1.638309237777546

Epoch: 484| Step: 0
Training loss: 0.21982446312904358
Validation loss: 1.6119569860478884

Epoch: 6| Step: 1
Training loss: 0.22643674910068512
Validation loss: 1.6401597274247037

Epoch: 6| Step: 2
Training loss: 0.25021034479141235
Validation loss: 1.6274394950559061

Epoch: 6| Step: 3
Training loss: 0.14530524611473083
Validation loss: 1.6238619883855183

Epoch: 6| Step: 4
Training loss: 0.42002958059310913
Validation loss: 1.6171356247317406

Epoch: 6| Step: 5
Training loss: 0.4341190457344055
Validation loss: 1.602064892168968

Epoch: 6| Step: 6
Training loss: 0.314642071723938
Validation loss: 1.631263336827678

Epoch: 6| Step: 7
Training loss: 0.3302989900112152
Validation loss: 1.5976530441673853

Epoch: 6| Step: 8
Training loss: 0.23776410520076752
Validation loss: 1.6203958449825164

Epoch: 6| Step: 9
Training loss: 0.21800217032432556
Validation loss: 1.6200220059323054

Epoch: 6| Step: 10
Training loss: 0.4065403342247009
Validation loss: 1.6375760442467147

Epoch: 6| Step: 11
Training loss: 0.30371665954589844
Validation loss: 1.6182949171271375

Epoch: 6| Step: 12
Training loss: 0.45516425371170044
Validation loss: 1.63258913511871

Epoch: 6| Step: 13
Training loss: 0.40058475732803345
Validation loss: 1.6056974908357025

Epoch: 485| Step: 0
Training loss: 0.23837842047214508
Validation loss: 1.658057080161187

Epoch: 6| Step: 1
Training loss: 0.44286635518074036
Validation loss: 1.6529930663365189

Epoch: 6| Step: 2
Training loss: 0.3862776756286621
Validation loss: 1.6746391519423454

Epoch: 6| Step: 3
Training loss: 0.21827882528305054
Validation loss: 1.6924864707454559

Epoch: 6| Step: 4
Training loss: 0.40436989068984985
Validation loss: 1.6820460942483717

Epoch: 6| Step: 5
Training loss: 0.19575192034244537
Validation loss: 1.6924094346261793

Epoch: 6| Step: 6
Training loss: 0.38694995641708374
Validation loss: 1.7267620973689581

Epoch: 6| Step: 7
Training loss: 0.4581522047519684
Validation loss: 1.7274565933853068

Epoch: 6| Step: 8
Training loss: 0.22542381286621094
Validation loss: 1.7171864740310177

Epoch: 6| Step: 9
Training loss: 0.40813761949539185
Validation loss: 1.7397621081721397

Epoch: 6| Step: 10
Training loss: 0.19284161925315857
Validation loss: 1.695261178478118

Epoch: 6| Step: 11
Training loss: 0.16384059190750122
Validation loss: 1.6913738814733361

Epoch: 6| Step: 12
Training loss: 0.41354578733444214
Validation loss: 1.6859141498483636

Epoch: 6| Step: 13
Training loss: 0.20308834314346313
Validation loss: 1.68668842956584

Epoch: 486| Step: 0
Training loss: 0.3285948634147644
Validation loss: 1.6702034229873328

Epoch: 6| Step: 1
Training loss: 0.27909988164901733
Validation loss: 1.6795438566515524

Epoch: 6| Step: 2
Training loss: 0.290649950504303
Validation loss: 1.6678963156156643

Epoch: 6| Step: 3
Training loss: 0.37454017996788025
Validation loss: 1.6350479061885546

Epoch: 6| Step: 4
Training loss: 0.49832966923713684
Validation loss: 1.6617114954097296

Epoch: 6| Step: 5
Training loss: 0.24494332075119019
Validation loss: 1.6698291724728

Epoch: 6| Step: 6
Training loss: 0.1967398226261139
Validation loss: 1.6664659874413603

Epoch: 6| Step: 7
Training loss: 0.4116396903991699
Validation loss: 1.6737683511549426

Epoch: 6| Step: 8
Training loss: 0.33991333842277527
Validation loss: 1.706330527541458

Epoch: 6| Step: 9
Training loss: 0.28445732593536377
Validation loss: 1.6584700602357105

Epoch: 6| Step: 10
Training loss: 0.20966963469982147
Validation loss: 1.6756922121970885

Epoch: 6| Step: 11
Training loss: 0.3633240759372711
Validation loss: 1.6675862766081286

Epoch: 6| Step: 12
Training loss: 0.19346019625663757
Validation loss: 1.6988903732709988

Epoch: 6| Step: 13
Training loss: 0.2754993140697479
Validation loss: 1.6893835067749023

Epoch: 487| Step: 0
Training loss: 0.2555968761444092
Validation loss: 1.6994599732019569

Epoch: 6| Step: 1
Training loss: 0.2957301735877991
Validation loss: 1.7117870456428939

Epoch: 6| Step: 2
Training loss: 0.36870211362838745
Validation loss: 1.6707123402626283

Epoch: 6| Step: 3
Training loss: 0.23193222284317017
Validation loss: 1.6808668387833463

Epoch: 6| Step: 4
Training loss: 0.2676059603691101
Validation loss: 1.6758970368293025

Epoch: 6| Step: 5
Training loss: 0.18179292976856232
Validation loss: 1.6625255179661576

Epoch: 6| Step: 6
Training loss: 0.27323204278945923
Validation loss: 1.6670232216517131

Epoch: 6| Step: 7
Training loss: 0.3212500214576721
Validation loss: 1.6323688081515733

Epoch: 6| Step: 8
Training loss: 0.25004491209983826
Validation loss: 1.6344133346311507

Epoch: 6| Step: 9
Training loss: 0.2450328767299652
Validation loss: 1.636455351306546

Epoch: 6| Step: 10
Training loss: 0.17165330052375793
Validation loss: 1.6019456642930225

Epoch: 6| Step: 11
Training loss: 0.4815986752510071
Validation loss: 1.6195680575986062

Epoch: 6| Step: 12
Training loss: 0.32663434743881226
Validation loss: 1.6420215816907986

Epoch: 6| Step: 13
Training loss: 0.30353736877441406
Validation loss: 1.6079154232496857

Epoch: 488| Step: 0
Training loss: 0.24217694997787476
Validation loss: 1.640586660754296

Epoch: 6| Step: 1
Training loss: 0.42248982191085815
Validation loss: 1.6437154751951977

Epoch: 6| Step: 2
Training loss: 0.1312217116355896
Validation loss: 1.652549709043195

Epoch: 6| Step: 3
Training loss: 0.12483489513397217
Validation loss: 1.6800804304820236

Epoch: 6| Step: 4
Training loss: 0.28609615564346313
Validation loss: 1.706841625193114

Epoch: 6| Step: 5
Training loss: 0.3792373836040497
Validation loss: 1.7358936366214548

Epoch: 6| Step: 6
Training loss: 0.282848060131073
Validation loss: 1.7633827399182063

Epoch: 6| Step: 7
Training loss: 0.34962183237075806
Validation loss: 1.7250456066541775

Epoch: 6| Step: 8
Training loss: 0.3826241195201874
Validation loss: 1.6990795340589298

Epoch: 6| Step: 9
Training loss: 0.2500471770763397
Validation loss: 1.7009755565274147

Epoch: 6| Step: 10
Training loss: 0.29841795563697815
Validation loss: 1.6919121896066973

Epoch: 6| Step: 11
Training loss: 0.4384200870990753
Validation loss: 1.6802926448083693

Epoch: 6| Step: 12
Training loss: 0.337833046913147
Validation loss: 1.6328254233124435

Epoch: 6| Step: 13
Training loss: 0.1642429083585739
Validation loss: 1.6253483744077786

Epoch: 489| Step: 0
Training loss: 0.38355666399002075
Validation loss: 1.6450850720046668

Epoch: 6| Step: 1
Training loss: 0.23154398798942566
Validation loss: 1.6516490226150842

Epoch: 6| Step: 2
Training loss: 0.260318398475647
Validation loss: 1.680248361761852

Epoch: 6| Step: 3
Training loss: 0.2206851989030838
Validation loss: 1.6325925242516302

Epoch: 6| Step: 4
Training loss: 0.21914592385292053
Validation loss: 1.625307761853741

Epoch: 6| Step: 5
Training loss: 0.4765492081642151
Validation loss: 1.6598994090992918

Epoch: 6| Step: 6
Training loss: 0.3398939371109009
Validation loss: 1.6769685142783708

Epoch: 6| Step: 7
Training loss: 0.3455054759979248
Validation loss: 1.6703579438629972

Epoch: 6| Step: 8
Training loss: 0.3324336111545563
Validation loss: 1.659439867542636

Epoch: 6| Step: 9
Training loss: 0.2421429455280304
Validation loss: 1.6670923335577852

Epoch: 6| Step: 10
Training loss: 0.3200872540473938
Validation loss: 1.6339589049739223

Epoch: 6| Step: 11
Training loss: 0.3230053782463074
Validation loss: 1.625618370630408

Epoch: 6| Step: 12
Training loss: 0.17156192660331726
Validation loss: 1.6329729223764071

Epoch: 6| Step: 13
Training loss: 0.3408798575401306
Validation loss: 1.6194186441359981

Epoch: 490| Step: 0
Training loss: 0.2114734947681427
Validation loss: 1.61687292463036

Epoch: 6| Step: 1
Training loss: 0.39009177684783936
Validation loss: 1.6569353226692445

Epoch: 6| Step: 2
Training loss: 0.26960480213165283
Validation loss: 1.673675174354225

Epoch: 6| Step: 3
Training loss: 0.28495460748672485
Validation loss: 1.702838401640615

Epoch: 6| Step: 4
Training loss: 0.442496657371521
Validation loss: 1.6699328057227596

Epoch: 6| Step: 5
Training loss: 0.19374299049377441
Validation loss: 1.6825847318095546

Epoch: 6| Step: 6
Training loss: 0.27197912335395813
Validation loss: 1.6978650695534163

Epoch: 6| Step: 7
Training loss: 0.35319510102272034
Validation loss: 1.671499358069512

Epoch: 6| Step: 8
Training loss: 0.18571195006370544
Validation loss: 1.685312517227665

Epoch: 6| Step: 9
Training loss: 0.18275761604309082
Validation loss: 1.6996881013275476

Epoch: 6| Step: 10
Training loss: 0.32589468359947205
Validation loss: 1.693322809793616

Epoch: 6| Step: 11
Training loss: 0.2096254527568817
Validation loss: 1.6610108460149458

Epoch: 6| Step: 12
Training loss: 0.3053446412086487
Validation loss: 1.6441626407766854

Epoch: 6| Step: 13
Training loss: 0.5506168007850647
Validation loss: 1.6617804035063712

Epoch: 491| Step: 0
Training loss: 0.4399261474609375
Validation loss: 1.6405043396898495

Epoch: 6| Step: 1
Training loss: 0.32800978422164917
Validation loss: 1.6669873550374021

Epoch: 6| Step: 2
Training loss: 0.4916006922721863
Validation loss: 1.6549279036060456

Epoch: 6| Step: 3
Training loss: 0.32449138164520264
Validation loss: 1.6990410435584284

Epoch: 6| Step: 4
Training loss: 0.26905739307403564
Validation loss: 1.6708403684759652

Epoch: 6| Step: 5
Training loss: 0.10579081624746323
Validation loss: 1.6853485581695393

Epoch: 6| Step: 6
Training loss: 0.22824522852897644
Validation loss: 1.6720410072675316

Epoch: 6| Step: 7
Training loss: 0.14698287844657898
Validation loss: 1.6878882659378873

Epoch: 6| Step: 8
Training loss: 0.2638695538043976
Validation loss: 1.6967120170593262

Epoch: 6| Step: 9
Training loss: 0.3295162618160248
Validation loss: 1.6618631578260852

Epoch: 6| Step: 10
Training loss: 0.06016365438699722
Validation loss: 1.6735192101488832

Epoch: 6| Step: 11
Training loss: 0.4579978883266449
Validation loss: 1.654221724438411

Epoch: 6| Step: 12
Training loss: 0.337497740983963
Validation loss: 1.6344124014659593

Epoch: 6| Step: 13
Training loss: 0.12877076864242554
Validation loss: 1.6516271598877446

Epoch: 492| Step: 0
Training loss: 0.1184786781668663
Validation loss: 1.6470360217555877

Epoch: 6| Step: 1
Training loss: 0.23565682768821716
Validation loss: 1.662285694511988

Epoch: 6| Step: 2
Training loss: 0.3766362965106964
Validation loss: 1.6442088298900153

Epoch: 6| Step: 3
Training loss: 0.383417010307312
Validation loss: 1.6037639828138455

Epoch: 6| Step: 4
Training loss: 0.2809954285621643
Validation loss: 1.619308655620903

Epoch: 6| Step: 5
Training loss: 0.30366653203964233
Validation loss: 1.6394155986847416

Epoch: 6| Step: 6
Training loss: 0.17521172761917114
Validation loss: 1.5730756316133725

Epoch: 6| Step: 7
Training loss: 0.46875712275505066
Validation loss: 1.6293470718527352

Epoch: 6| Step: 8
Training loss: 0.4006066620349884
Validation loss: 1.6539605894396383

Epoch: 6| Step: 9
Training loss: 0.3174181580543518
Validation loss: 1.662037662280503

Epoch: 6| Step: 10
Training loss: 0.1885623335838318
Validation loss: 1.6682440875678934

Epoch: 6| Step: 11
Training loss: 0.25789350271224976
Validation loss: 1.669762606261879

Epoch: 6| Step: 12
Training loss: 0.34270745515823364
Validation loss: 1.6656945572104505

Epoch: 6| Step: 13
Training loss: 0.08878277242183685
Validation loss: 1.6286451611467587

Epoch: 493| Step: 0
Training loss: 0.29940521717071533
Validation loss: 1.6357071027960828

Epoch: 6| Step: 1
Training loss: 0.35949161648750305
Validation loss: 1.6013088559591642

Epoch: 6| Step: 2
Training loss: 0.3136301636695862
Validation loss: 1.615323951167445

Epoch: 6| Step: 3
Training loss: 0.46270811557769775
Validation loss: 1.6066466890355593

Epoch: 6| Step: 4
Training loss: 0.320881724357605
Validation loss: 1.6048177326879194

Epoch: 6| Step: 5
Training loss: 0.27883899211883545
Validation loss: 1.609062284551641

Epoch: 6| Step: 6
Training loss: 0.2789272964000702
Validation loss: 1.6207430567792667

Epoch: 6| Step: 7
Training loss: 0.24587851762771606
Validation loss: 1.6362711767996512

Epoch: 6| Step: 8
Training loss: 0.23555715382099152
Validation loss: 1.654248563192224

Epoch: 6| Step: 9
Training loss: 0.35064011812210083
Validation loss: 1.6801969389761648

Epoch: 6| Step: 10
Training loss: 0.23978663980960846
Validation loss: 1.733950679020215

Epoch: 6| Step: 11
Training loss: 0.41195282340049744
Validation loss: 1.7256502746253886

Epoch: 6| Step: 12
Training loss: 0.235559344291687
Validation loss: 1.7220383703067739

Epoch: 6| Step: 13
Training loss: 0.18000748753547668
Validation loss: 1.7564778866306427

Epoch: 494| Step: 0
Training loss: 0.2267017960548401
Validation loss: 1.73858049608046

Epoch: 6| Step: 1
Training loss: 0.33681464195251465
Validation loss: 1.7148402301214074

Epoch: 6| Step: 2
Training loss: 0.34169214963912964
Validation loss: 1.6901401319811422

Epoch: 6| Step: 3
Training loss: 0.29750490188598633
Validation loss: 1.682101188167449

Epoch: 6| Step: 4
Training loss: 0.3466324806213379
Validation loss: 1.6492655777162122

Epoch: 6| Step: 5
Training loss: 0.26237595081329346
Validation loss: 1.624693150161415

Epoch: 6| Step: 6
Training loss: 0.38860365748405457
Validation loss: 1.6365132447211974

Epoch: 6| Step: 7
Training loss: 0.300860196352005
Validation loss: 1.639608786952111

Epoch: 6| Step: 8
Training loss: 0.3876330256462097
Validation loss: 1.6653247969124907

Epoch: 6| Step: 9
Training loss: 0.224662646651268
Validation loss: 1.6613246907470047

Epoch: 6| Step: 10
Training loss: 0.3876870274543762
Validation loss: 1.6885284531501032

Epoch: 6| Step: 11
Training loss: 0.2544686794281006
Validation loss: 1.726394731511352

Epoch: 6| Step: 12
Training loss: 0.16951638460159302
Validation loss: 1.7018145463799919

Epoch: 6| Step: 13
Training loss: 0.2555729150772095
Validation loss: 1.71992826461792

Epoch: 495| Step: 0
Training loss: 0.48752832412719727
Validation loss: 1.7186520548277004

Epoch: 6| Step: 1
Training loss: 0.1741258203983307
Validation loss: 1.7181881679001676

Epoch: 6| Step: 2
Training loss: 0.2758384346961975
Validation loss: 1.7107963831193986

Epoch: 6| Step: 3
Training loss: 0.2597067952156067
Validation loss: 1.6774751947772117

Epoch: 6| Step: 4
Training loss: 0.19849893450737
Validation loss: 1.6574455486830844

Epoch: 6| Step: 5
Training loss: 0.2195228785276413
Validation loss: 1.659098409837292

Epoch: 6| Step: 6
Training loss: 0.09891679883003235
Validation loss: 1.6417103416176253

Epoch: 6| Step: 7
Training loss: 0.26643767952919006
Validation loss: 1.6306806123384865

Epoch: 6| Step: 8
Training loss: 0.275353342294693
Validation loss: 1.6810312764618986

Epoch: 6| Step: 9
Training loss: 0.3410002589225769
Validation loss: 1.6598765157884168

Epoch: 6| Step: 10
Training loss: 0.3042615056037903
Validation loss: 1.6634745046656618

Epoch: 6| Step: 11
Training loss: 0.31184038519859314
Validation loss: 1.6462139134765954

Epoch: 6| Step: 12
Training loss: 0.26714634895324707
Validation loss: 1.6358220243966708

Epoch: 6| Step: 13
Training loss: 0.3960460424423218
Validation loss: 1.6699497046009186

Epoch: 496| Step: 0
Training loss: 0.35926878452301025
Validation loss: 1.7131401928522254

Epoch: 6| Step: 1
Training loss: 0.4062776267528534
Validation loss: 1.734933465398768

Epoch: 6| Step: 2
Training loss: 0.20222704112529755
Validation loss: 1.74781895068384

Epoch: 6| Step: 3
Training loss: 0.29690441489219666
Validation loss: 1.7077354654189079

Epoch: 6| Step: 4
Training loss: 0.15286888182163239
Validation loss: 1.6778333956195461

Epoch: 6| Step: 5
Training loss: 0.2028760015964508
Validation loss: 1.6185068302257086

Epoch: 6| Step: 6
Training loss: 0.2993319034576416
Validation loss: 1.5986266879625217

Epoch: 6| Step: 7
Training loss: 0.3235885202884674
Validation loss: 1.5880915170074792

Epoch: 6| Step: 8
Training loss: 0.20003584027290344
Validation loss: 1.6329167953101538

Epoch: 6| Step: 9
Training loss: 0.2562079429626465
Validation loss: 1.6140242340744182

Epoch: 6| Step: 10
Training loss: 0.674282968044281
Validation loss: 1.6358464148736769

Epoch: 6| Step: 11
Training loss: 0.09980840981006622
Validation loss: 1.5910223402002805

Epoch: 6| Step: 12
Training loss: 0.2766837477684021
Validation loss: 1.6078537587196595

Epoch: 6| Step: 13
Training loss: 0.3261326551437378
Validation loss: 1.6067608287257533

Epoch: 497| Step: 0
Training loss: 0.23761340975761414
Validation loss: 1.6612932893537706

Epoch: 6| Step: 1
Training loss: 0.39411461353302
Validation loss: 1.6504753699866674

Epoch: 6| Step: 2
Training loss: 0.4040149748325348
Validation loss: 1.71109987074329

Epoch: 6| Step: 3
Training loss: 0.2643904685974121
Validation loss: 1.7253338906072802

Epoch: 6| Step: 4
Training loss: 0.2296651303768158
Validation loss: 1.7607437897753972

Epoch: 6| Step: 5
Training loss: 0.24989554286003113
Validation loss: 1.7302411961299118

Epoch: 6| Step: 6
Training loss: 0.15417680144309998
Validation loss: 1.719966503881639

Epoch: 6| Step: 7
Training loss: 0.3893250823020935
Validation loss: 1.6132377014365247

Epoch: 6| Step: 8
Training loss: 0.19919370114803314
Validation loss: 1.6473563640348372

Epoch: 6| Step: 9
Training loss: 0.41107383370399475
Validation loss: 1.5729150477276053

Epoch: 6| Step: 10
Training loss: 0.3943963050842285
Validation loss: 1.5854965397106704

Epoch: 6| Step: 11
Training loss: 0.3046930432319641
Validation loss: 1.5798995238478466

Epoch: 6| Step: 12
Training loss: 0.2617812156677246
Validation loss: 1.5928859172328826

Epoch: 6| Step: 13
Training loss: 0.3176957368850708
Validation loss: 1.613941349009032

Epoch: 498| Step: 0
Training loss: 0.2117735594511032
Validation loss: 1.6107909089775496

Epoch: 6| Step: 1
Training loss: 0.42981448769569397
Validation loss: 1.627145617238937

Epoch: 6| Step: 2
Training loss: 0.3134109079837799
Validation loss: 1.665071419490281

Epoch: 6| Step: 3
Training loss: 0.3044063448905945
Validation loss: 1.6731447917158886

Epoch: 6| Step: 4
Training loss: 0.33172154426574707
Validation loss: 1.6463086579435615

Epoch: 6| Step: 5
Training loss: 0.251509428024292
Validation loss: 1.6503706439848869

Epoch: 6| Step: 6
Training loss: 0.32534968852996826
Validation loss: 1.6533901486345517

Epoch: 6| Step: 7
Training loss: 0.1681291162967682
Validation loss: 1.6723601920630342

Epoch: 6| Step: 8
Training loss: 0.2458530068397522
Validation loss: 1.7042391018200946

Epoch: 6| Step: 9
Training loss: 0.35648536682128906
Validation loss: 1.720620568080615

Epoch: 6| Step: 10
Training loss: 0.44549137353897095
Validation loss: 1.7361294505416707

Epoch: 6| Step: 11
Training loss: 0.4129282236099243
Validation loss: 1.7008987088357248

Epoch: 6| Step: 12
Training loss: 0.45239323377609253
Validation loss: 1.7074890123900546

Epoch: 6| Step: 13
Training loss: 0.1477000117301941
Validation loss: 1.691315907304005

Epoch: 499| Step: 0
Training loss: 0.2650260329246521
Validation loss: 1.6884916443978586

Epoch: 6| Step: 1
Training loss: 0.22684961557388306
Validation loss: 1.6617674186665525

Epoch: 6| Step: 2
Training loss: 0.2530791759490967
Validation loss: 1.6710017688812748

Epoch: 6| Step: 3
Training loss: 0.2514170706272125
Validation loss: 1.7048202278793498

Epoch: 6| Step: 4
Training loss: 0.47886988520622253
Validation loss: 1.6754972396358367

Epoch: 6| Step: 5
Training loss: 0.5261990427970886
Validation loss: 1.668859815084806

Epoch: 6| Step: 6
Training loss: 0.32163190841674805
Validation loss: 1.653660205102736

Epoch: 6| Step: 7
Training loss: 0.16820254921913147
Validation loss: 1.6471771706816971

Epoch: 6| Step: 8
Training loss: 0.33820798993110657
Validation loss: 1.6324249031723186

Epoch: 6| Step: 9
Training loss: 0.1502404361963272
Validation loss: 1.6294842868722894

Epoch: 6| Step: 10
Training loss: 0.30531877279281616
Validation loss: 1.6561898134088004

Epoch: 6| Step: 11
Training loss: 0.16046816110610962
Validation loss: 1.6327816606849752

Epoch: 6| Step: 12
Training loss: 0.2976963222026825
Validation loss: 1.6504155230778519

Epoch: 6| Step: 13
Training loss: 0.33057355880737305
Validation loss: 1.6610960396387244

Epoch: 500| Step: 0
Training loss: 0.18668171763420105
Validation loss: 1.6388380501859932

Epoch: 6| Step: 1
Training loss: 0.44499972462654114
Validation loss: 1.6834650501128166

Epoch: 6| Step: 2
Training loss: 0.24269181489944458
Validation loss: 1.677426484323317

Epoch: 6| Step: 3
Training loss: 0.21058732271194458
Validation loss: 1.6410030267571891

Epoch: 6| Step: 4
Training loss: 0.18932563066482544
Validation loss: 1.6763991668660154

Epoch: 6| Step: 5
Training loss: 0.33529508113861084
Validation loss: 1.6252954877832884

Epoch: 6| Step: 6
Training loss: 0.1883423626422882
Validation loss: 1.6292107323164582

Epoch: 6| Step: 7
Training loss: 0.2987549304962158
Validation loss: 1.615791561783001

Epoch: 6| Step: 8
Training loss: 0.21818697452545166
Validation loss: 1.6212711154773671

Epoch: 6| Step: 9
Training loss: 0.21597892045974731
Validation loss: 1.6214834259402366

Epoch: 6| Step: 10
Training loss: 0.27963221073150635
Validation loss: 1.6263449268956338

Epoch: 6| Step: 11
Training loss: 0.4450032711029053
Validation loss: 1.6341668764750164

Epoch: 6| Step: 12
Training loss: 0.3095242977142334
Validation loss: 1.6480464345665389

Epoch: 6| Step: 13
Training loss: 0.2681320905685425
Validation loss: 1.6632996784743441

Epoch: 501| Step: 0
Training loss: 0.46095094084739685
Validation loss: 1.6803034197899602

Epoch: 6| Step: 1
Training loss: 0.25246354937553406
Validation loss: 1.6931582996922154

Epoch: 6| Step: 2
Training loss: 0.26417213678359985
Validation loss: 1.7332831223805745

Epoch: 6| Step: 3
Training loss: 0.2214628905057907
Validation loss: 1.6611604652097147

Epoch: 6| Step: 4
Training loss: 0.28341084718704224
Validation loss: 1.6734700613124396

Epoch: 6| Step: 5
Training loss: 0.3125012516975403
Validation loss: 1.6222165284618255

Epoch: 6| Step: 6
Training loss: 0.2899174094200134
Validation loss: 1.6375366962084206

Epoch: 6| Step: 7
Training loss: 0.3002449870109558
Validation loss: 1.6522033253023702

Epoch: 6| Step: 8
Training loss: 0.20528829097747803
Validation loss: 1.6424885385779924

Epoch: 6| Step: 9
Training loss: 0.23359765112400055
Validation loss: 1.6540379049957439

Epoch: 6| Step: 10
Training loss: 0.2174769639968872
Validation loss: 1.6264122006713704

Epoch: 6| Step: 11
Training loss: 0.3185228109359741
Validation loss: 1.5997630409015122

Epoch: 6| Step: 12
Training loss: 0.22889430820941925
Validation loss: 1.582850319083019

Epoch: 6| Step: 13
Training loss: 0.226862370967865
Validation loss: 1.6028364832683275

Epoch: 502| Step: 0
Training loss: 0.293053537607193
Validation loss: 1.6047520816967051

Epoch: 6| Step: 1
Training loss: 0.44511836767196655
Validation loss: 1.627463827850998

Epoch: 6| Step: 2
Training loss: 0.1964769810438156
Validation loss: 1.6539908955174107

Epoch: 6| Step: 3
Training loss: 0.3061034083366394
Validation loss: 1.6482133621810584

Epoch: 6| Step: 4
Training loss: 0.25015708804130554
Validation loss: 1.640316444058572

Epoch: 6| Step: 5
Training loss: 0.2585364878177643
Validation loss: 1.6500409803082865

Epoch: 6| Step: 6
Training loss: 0.28500527143478394
Validation loss: 1.5938628155698058

Epoch: 6| Step: 7
Training loss: 0.1673872470855713
Validation loss: 1.6220240182774042

Epoch: 6| Step: 8
Training loss: 0.3322980999946594
Validation loss: 1.612206348808863

Epoch: 6| Step: 9
Training loss: 0.18201525509357452
Validation loss: 1.640746155092793

Epoch: 6| Step: 10
Training loss: 0.2257687896490097
Validation loss: 1.6515716057951733

Epoch: 6| Step: 11
Training loss: 0.24459576606750488
Validation loss: 1.6518426659286662

Epoch: 6| Step: 12
Training loss: 0.20162275433540344
Validation loss: 1.6324440317769204

Epoch: 6| Step: 13
Training loss: 0.3246645927429199
Validation loss: 1.6473371072482037

Epoch: 503| Step: 0
Training loss: 0.2172461748123169
Validation loss: 1.6406717236324022

Epoch: 6| Step: 1
Training loss: 0.2247108370065689
Validation loss: 1.62398184627615

Epoch: 6| Step: 2
Training loss: 0.3762792944908142
Validation loss: 1.6767944789701892

Epoch: 6| Step: 3
Training loss: 0.25887635350227356
Validation loss: 1.6611670230024604

Epoch: 6| Step: 4
Training loss: 0.30557140707969666
Validation loss: 1.6418142446907618

Epoch: 6| Step: 5
Training loss: 0.25453102588653564
Validation loss: 1.6442039692273704

Epoch: 6| Step: 6
Training loss: 0.23185983300209045
Validation loss: 1.6628107704142088

Epoch: 6| Step: 7
Training loss: 0.312166690826416
Validation loss: 1.6272926087020545

Epoch: 6| Step: 8
Training loss: 0.3549671173095703
Validation loss: 1.612982556384097

Epoch: 6| Step: 9
Training loss: 0.38298946619033813
Validation loss: 1.5808203566458918

Epoch: 6| Step: 10
Training loss: 0.25221699476242065
Validation loss: 1.5821758431773032

Epoch: 6| Step: 11
Training loss: 0.3199538588523865
Validation loss: 1.5480282845035676

Epoch: 6| Step: 12
Training loss: 0.13519734144210815
Validation loss: 1.5840842275209324

Epoch: 6| Step: 13
Training loss: 0.26063627004623413
Validation loss: 1.5688594912969938

Epoch: 504| Step: 0
Training loss: 0.35069015622138977
Validation loss: 1.6014664890945598

Epoch: 6| Step: 1
Training loss: 0.3359582722187042
Validation loss: 1.6676027595355947

Epoch: 6| Step: 2
Training loss: 0.44610142707824707
Validation loss: 1.6665408918934483

Epoch: 6| Step: 3
Training loss: 0.36237022280693054
Validation loss: 1.6887857785788916

Epoch: 6| Step: 4
Training loss: 0.29306942224502563
Validation loss: 1.7025688848187845

Epoch: 6| Step: 5
Training loss: 0.2566273808479309
Validation loss: 1.6930442548567248

Epoch: 6| Step: 6
Training loss: 0.2565709352493286
Validation loss: 1.6822023853178947

Epoch: 6| Step: 7
Training loss: 0.14822793006896973
Validation loss: 1.6472749915174258

Epoch: 6| Step: 8
Training loss: 0.2487206757068634
Validation loss: 1.5845547465867893

Epoch: 6| Step: 9
Training loss: 0.1913115680217743
Validation loss: 1.5780831652302896

Epoch: 6| Step: 10
Training loss: 0.22196099162101746
Validation loss: 1.5922192014673704

Epoch: 6| Step: 11
Training loss: 0.32107388973236084
Validation loss: 1.6172722610094215

Epoch: 6| Step: 12
Training loss: 0.1764661818742752
Validation loss: 1.643940088569477

Epoch: 6| Step: 13
Training loss: 0.14477871358394623
Validation loss: 1.6575891279405164

Epoch: 505| Step: 0
Training loss: 0.17934854328632355
Validation loss: 1.6502535253442743

Epoch: 6| Step: 1
Training loss: 0.23268547654151917
Validation loss: 1.667504293944246

Epoch: 6| Step: 2
Training loss: 0.19765955209732056
Validation loss: 1.6615293692517024

Epoch: 6| Step: 3
Training loss: 0.2660177946090698
Validation loss: 1.643414681957614

Epoch: 6| Step: 4
Training loss: 0.3493382930755615
Validation loss: 1.6488373843572472

Epoch: 6| Step: 5
Training loss: 0.2658126950263977
Validation loss: 1.6728846027005104

Epoch: 6| Step: 6
Training loss: 0.22242915630340576
Validation loss: 1.7086955257641372

Epoch: 6| Step: 7
Training loss: 0.29331713914871216
Validation loss: 1.7141374349594116

Epoch: 6| Step: 8
Training loss: 0.3638526201248169
Validation loss: 1.7377034964100007

Epoch: 6| Step: 9
Training loss: 0.34942394495010376
Validation loss: 1.725149505881853

Epoch: 6| Step: 10
Training loss: 0.24638694524765015
Validation loss: 1.6954094158705844

Epoch: 6| Step: 11
Training loss: 0.20094221830368042
Validation loss: 1.6711549041091756

Epoch: 6| Step: 12
Training loss: 0.15774399042129517
Validation loss: 1.6369866786464569

Epoch: 6| Step: 13
Training loss: 0.4496775269508362
Validation loss: 1.6402495740562357

Epoch: 506| Step: 0
Training loss: 0.37317174673080444
Validation loss: 1.6189547572084653

Epoch: 6| Step: 1
Training loss: 0.15088552236557007
Validation loss: 1.6188837905083933

Epoch: 6| Step: 2
Training loss: 0.2746555209159851
Validation loss: 1.615215580950501

Epoch: 6| Step: 3
Training loss: 0.3372308611869812
Validation loss: 1.6039369952294134

Epoch: 6| Step: 4
Training loss: 0.3715962767601013
Validation loss: 1.5937185005475116

Epoch: 6| Step: 5
Training loss: 0.3657432794570923
Validation loss: 1.59024638898911

Epoch: 6| Step: 6
Training loss: 0.22833190858364105
Validation loss: 1.5805737408258582

Epoch: 6| Step: 7
Training loss: 0.2896384298801422
Validation loss: 1.5947181524768952

Epoch: 6| Step: 8
Training loss: 0.2583111524581909
Validation loss: 1.629257825113112

Epoch: 6| Step: 9
Training loss: 0.09189318120479584
Validation loss: 1.6231035071034585

Epoch: 6| Step: 10
Training loss: 0.3634665012359619
Validation loss: 1.6806316119368359

Epoch: 6| Step: 11
Training loss: 0.16421468555927277
Validation loss: 1.6786090039437818

Epoch: 6| Step: 12
Training loss: 0.19045837223529816
Validation loss: 1.6938560060275498

Epoch: 6| Step: 13
Training loss: 0.17564304172992706
Validation loss: 1.6783535390771844

Epoch: 507| Step: 0
Training loss: 0.2808598279953003
Validation loss: 1.6824126192318496

Epoch: 6| Step: 1
Training loss: 0.22601348161697388
Validation loss: 1.6700543383116364

Epoch: 6| Step: 2
Training loss: 0.22864273190498352
Validation loss: 1.7087650465708908

Epoch: 6| Step: 3
Training loss: 0.449764221906662
Validation loss: 1.6936516646415956

Epoch: 6| Step: 4
Training loss: 0.22788561880588531
Validation loss: 1.6600633167451428

Epoch: 6| Step: 5
Training loss: 0.43256139755249023
Validation loss: 1.6500187407257736

Epoch: 6| Step: 6
Training loss: 0.2691879868507385
Validation loss: 1.6259780083933184

Epoch: 6| Step: 7
Training loss: 0.376443088054657
Validation loss: 1.5992659996914607

Epoch: 6| Step: 8
Training loss: 0.4151981770992279
Validation loss: 1.6094223171152093

Epoch: 6| Step: 9
Training loss: 0.24619194865226746
Validation loss: 1.6226785157316475

Epoch: 6| Step: 10
Training loss: 0.22992143034934998
Validation loss: 1.5859863540177703

Epoch: 6| Step: 11
Training loss: 0.28326675295829773
Validation loss: 1.6177834926113006

Epoch: 6| Step: 12
Training loss: 0.1848004162311554
Validation loss: 1.6060894817434332

Epoch: 6| Step: 13
Training loss: 0.17805695533752441
Validation loss: 1.5561972215611448

Epoch: 508| Step: 0
Training loss: 0.13571172952651978
Validation loss: 1.568483216788179

Epoch: 6| Step: 1
Training loss: 0.1844429224729538
Validation loss: 1.6359977273530857

Epoch: 6| Step: 2
Training loss: 0.2920880913734436
Validation loss: 1.6556823227995185

Epoch: 6| Step: 3
Training loss: 0.34434568881988525
Validation loss: 1.7390629578662176

Epoch: 6| Step: 4
Training loss: 0.40244096517562866
Validation loss: 1.719703394879577

Epoch: 6| Step: 5
Training loss: 0.2574203610420227
Validation loss: 1.6788329398760231

Epoch: 6| Step: 6
Training loss: 0.3094606399536133
Validation loss: 1.6626427949115794

Epoch: 6| Step: 7
Training loss: 0.353460431098938
Validation loss: 1.6376102124491045

Epoch: 6| Step: 8
Training loss: 0.4427533745765686
Validation loss: 1.5998792148405505

Epoch: 6| Step: 9
Training loss: 0.3360758423805237
Validation loss: 1.559798870035397

Epoch: 6| Step: 10
Training loss: 0.3748735189437866
Validation loss: 1.5937815109888713

Epoch: 6| Step: 11
Training loss: 0.432834267616272
Validation loss: 1.6168260497431601

Epoch: 6| Step: 12
Training loss: 0.2803595960140228
Validation loss: 1.613833837611701

Epoch: 6| Step: 13
Training loss: 0.2765124440193176
Validation loss: 1.6116111086260887

Epoch: 509| Step: 0
Training loss: 0.19955497980117798
Validation loss: 1.6412779528607604

Epoch: 6| Step: 1
Training loss: 0.21920791268348694
Validation loss: 1.6510384018703173

Epoch: 6| Step: 2
Training loss: 0.3027012050151825
Validation loss: 1.712269793274582

Epoch: 6| Step: 3
Training loss: 0.35907986760139465
Validation loss: 1.7364206519178165

Epoch: 6| Step: 4
Training loss: 0.5862681865692139
Validation loss: 1.7519345616781583

Epoch: 6| Step: 5
Training loss: 0.2887403666973114
Validation loss: 1.7102326769982614

Epoch: 6| Step: 6
Training loss: 0.33231863379478455
Validation loss: 1.7014164296529626

Epoch: 6| Step: 7
Training loss: 0.4065122604370117
Validation loss: 1.717177387206785

Epoch: 6| Step: 8
Training loss: 0.13817131519317627
Validation loss: 1.6833809806454567

Epoch: 6| Step: 9
Training loss: 0.15627774596214294
Validation loss: 1.6445002209755681

Epoch: 6| Step: 10
Training loss: 0.41950827836990356
Validation loss: 1.6362017367475776

Epoch: 6| Step: 11
Training loss: 0.2888471484184265
Validation loss: 1.6085191516466038

Epoch: 6| Step: 12
Training loss: 0.15314364433288574
Validation loss: 1.5999750693639119

Epoch: 6| Step: 13
Training loss: 0.4643101096153259
Validation loss: 1.57568452178791

Epoch: 510| Step: 0
Training loss: 0.2703007757663727
Validation loss: 1.5624370908224454

Epoch: 6| Step: 1
Training loss: 0.281931072473526
Validation loss: 1.5816306350051716

Epoch: 6| Step: 2
Training loss: 0.3215130567550659
Validation loss: 1.55785326034792

Epoch: 6| Step: 3
Training loss: 0.47570404410362244
Validation loss: 1.5595817104462655

Epoch: 6| Step: 4
Training loss: 0.40616899728775024
Validation loss: 1.5971413261146956

Epoch: 6| Step: 5
Training loss: 0.24378134310245514
Validation loss: 1.6519226874074628

Epoch: 6| Step: 6
Training loss: 0.24861708283424377
Validation loss: 1.6435403311124412

Epoch: 6| Step: 7
Training loss: 0.20791032910346985
Validation loss: 1.649759695094119

Epoch: 6| Step: 8
Training loss: 0.3023832440376282
Validation loss: 1.6723732538120721

Epoch: 6| Step: 9
Training loss: 0.40958306193351746
Validation loss: 1.674907144679818

Epoch: 6| Step: 10
Training loss: 0.3562854826450348
Validation loss: 1.6313523131032144

Epoch: 6| Step: 11
Training loss: 0.1225307434797287
Validation loss: 1.6140191965205695

Epoch: 6| Step: 12
Training loss: 0.4238095283508301
Validation loss: 1.6372566082144295

Epoch: 6| Step: 13
Training loss: 0.28774476051330566
Validation loss: 1.6148661157136321

Epoch: 511| Step: 0
Training loss: 0.17933982610702515
Validation loss: 1.6441650775171095

Epoch: 6| Step: 1
Training loss: 0.24409881234169006
Validation loss: 1.605190271972328

Epoch: 6| Step: 2
Training loss: 0.13102853298187256
Validation loss: 1.6132224157292356

Epoch: 6| Step: 3
Training loss: 0.2644413113594055
Validation loss: 1.634064451340706

Epoch: 6| Step: 4
Training loss: 0.2237711250782013
Validation loss: 1.610661675853114

Epoch: 6| Step: 5
Training loss: 0.2398921549320221
Validation loss: 1.5768498233569566

Epoch: 6| Step: 6
Training loss: 0.3645317852497101
Validation loss: 1.5716064219833703

Epoch: 6| Step: 7
Training loss: 0.2467823326587677
Validation loss: 1.5880894609676894

Epoch: 6| Step: 8
Training loss: 0.27729785442352295
Validation loss: 1.642904875099018

Epoch: 6| Step: 9
Training loss: 0.3479418158531189
Validation loss: 1.608336793479099

Epoch: 6| Step: 10
Training loss: 0.37589210271835327
Validation loss: 1.670904637664877

Epoch: 6| Step: 11
Training loss: 0.10373754799365997
Validation loss: 1.6003437401146017

Epoch: 6| Step: 12
Training loss: 0.18343472480773926
Validation loss: 1.614456683076838

Epoch: 6| Step: 13
Training loss: 0.5262847542762756
Validation loss: 1.6220376414637412

Epoch: 512| Step: 0
Training loss: 0.2400229573249817
Validation loss: 1.6088097838945286

Epoch: 6| Step: 1
Training loss: 0.24001877009868622
Validation loss: 1.6337577014841058

Epoch: 6| Step: 2
Training loss: 0.1670653223991394
Validation loss: 1.6309701652937039

Epoch: 6| Step: 3
Training loss: 0.2220601588487625
Validation loss: 1.6305433947552916

Epoch: 6| Step: 4
Training loss: 0.2422550916671753
Validation loss: 1.6277107346442439

Epoch: 6| Step: 5
Training loss: 0.28022661805152893
Validation loss: 1.6009786449452883

Epoch: 6| Step: 6
Training loss: 0.3215389847755432
Validation loss: 1.5913577099000253

Epoch: 6| Step: 7
Training loss: 0.1671488881111145
Validation loss: 1.6114957294156473

Epoch: 6| Step: 8
Training loss: 0.2789565920829773
Validation loss: 1.6246515051011117

Epoch: 6| Step: 9
Training loss: 0.30967628955841064
Validation loss: 1.6067248531567153

Epoch: 6| Step: 10
Training loss: 0.3160838484764099
Validation loss: 1.5837656233900337

Epoch: 6| Step: 11
Training loss: 0.20138472318649292
Validation loss: 1.5664677363570019

Epoch: 6| Step: 12
Training loss: 0.18163779377937317
Validation loss: 1.5799146108729865

Epoch: 6| Step: 13
Training loss: 0.1849709302186966
Validation loss: 1.600809371599587

Epoch: 513| Step: 0
Training loss: 0.24767225980758667
Validation loss: 1.6028635540316183

Epoch: 6| Step: 1
Training loss: 0.4271790087223053
Validation loss: 1.6233060283045615

Epoch: 6| Step: 2
Training loss: 0.41722163558006287
Validation loss: 1.6166867158746208

Epoch: 6| Step: 3
Training loss: 0.36084887385368347
Validation loss: 1.635845672699713

Epoch: 6| Step: 4
Training loss: 0.3311988115310669
Validation loss: 1.677461862564087

Epoch: 6| Step: 5
Training loss: 0.24884720146656036
Validation loss: 1.6572652016916583

Epoch: 6| Step: 6
Training loss: 0.20951883494853973
Validation loss: 1.643814689369612

Epoch: 6| Step: 7
Training loss: 0.18453410267829895
Validation loss: 1.6181637407631002

Epoch: 6| Step: 8
Training loss: 0.17406870424747467
Validation loss: 1.6465204338873587

Epoch: 6| Step: 9
Training loss: 0.10638345032930374
Validation loss: 1.6233713652497979

Epoch: 6| Step: 10
Training loss: 0.28902363777160645
Validation loss: 1.6811460320667555

Epoch: 6| Step: 11
Training loss: 0.23927929997444153
Validation loss: 1.6875936126196256

Epoch: 6| Step: 12
Training loss: 0.3166193962097168
Validation loss: 1.7113251788641817

Epoch: 6| Step: 13
Training loss: 0.07580769062042236
Validation loss: 1.704125855558662

Epoch: 514| Step: 0
Training loss: 0.3001593053340912
Validation loss: 1.7411823554705548

Epoch: 6| Step: 1
Training loss: 0.22073353826999664
Validation loss: 1.7369164318166754

Epoch: 6| Step: 2
Training loss: 0.17552514374256134
Validation loss: 1.7126544214064074

Epoch: 6| Step: 3
Training loss: 0.14304140210151672
Validation loss: 1.7195742784007904

Epoch: 6| Step: 4
Training loss: 0.22887516021728516
Validation loss: 1.669950996675799

Epoch: 6| Step: 5
Training loss: 0.38420242071151733
Validation loss: 1.6541589908702399

Epoch: 6| Step: 6
Training loss: 0.19550266861915588
Validation loss: 1.5951212785577262

Epoch: 6| Step: 7
Training loss: 0.09917174279689789
Validation loss: 1.5820006734581404

Epoch: 6| Step: 8
Training loss: 0.33495908975601196
Validation loss: 1.5924040143207838

Epoch: 6| Step: 9
Training loss: 0.4272417426109314
Validation loss: 1.578282324216699

Epoch: 6| Step: 10
Training loss: 0.39437538385391235
Validation loss: 1.558998696265682

Epoch: 6| Step: 11
Training loss: 0.14520004391670227
Validation loss: 1.590127952637211

Epoch: 6| Step: 12
Training loss: 0.3528926372528076
Validation loss: 1.5861650051609162

Epoch: 6| Step: 13
Training loss: 0.1677216738462448
Validation loss: 1.5793775499507945

Epoch: 515| Step: 0
Training loss: 0.33681005239486694
Validation loss: 1.6049403605922576

Epoch: 6| Step: 1
Training loss: 0.19877874851226807
Validation loss: 1.6155162998425063

Epoch: 6| Step: 2
Training loss: 0.3001919388771057
Validation loss: 1.6054919919660013

Epoch: 6| Step: 3
Training loss: 0.28750431537628174
Validation loss: 1.6101539365706905

Epoch: 6| Step: 4
Training loss: 0.3247107267379761
Validation loss: 1.644111135954498

Epoch: 6| Step: 5
Training loss: 0.3642178177833557
Validation loss: 1.5986234423934773

Epoch: 6| Step: 6
Training loss: 0.2456117570400238
Validation loss: 1.5902090969906058

Epoch: 6| Step: 7
Training loss: 0.20551156997680664
Validation loss: 1.5883916808712868

Epoch: 6| Step: 8
Training loss: 0.3359454870223999
Validation loss: 1.6116720591821978

Epoch: 6| Step: 9
Training loss: 0.21130891144275665
Validation loss: 1.5543061943464382

Epoch: 6| Step: 10
Training loss: 0.2597549557685852
Validation loss: 1.571056608230837

Epoch: 6| Step: 11
Training loss: 0.23369409143924713
Validation loss: 1.5806584576124787

Epoch: 6| Step: 12
Training loss: 0.2010108232498169
Validation loss: 1.5916342402017245

Epoch: 6| Step: 13
Training loss: 0.328080415725708
Validation loss: 1.556288085958009

Epoch: 516| Step: 0
Training loss: 0.36313170194625854
Validation loss: 1.6105820748113817

Epoch: 6| Step: 1
Training loss: 0.32440394163131714
Validation loss: 1.5907139790955411

Epoch: 6| Step: 2
Training loss: 0.3004927635192871
Validation loss: 1.631015754515125

Epoch: 6| Step: 3
Training loss: 0.14247345924377441
Validation loss: 1.6590218441460722

Epoch: 6| Step: 4
Training loss: 0.4396528899669647
Validation loss: 1.6206144594377088

Epoch: 6| Step: 5
Training loss: 0.12689059972763062
Validation loss: 1.6444137057950419

Epoch: 6| Step: 6
Training loss: 0.1769459843635559
Validation loss: 1.6558122955342776

Epoch: 6| Step: 7
Training loss: 0.31883394718170166
Validation loss: 1.6689941908723565

Epoch: 6| Step: 8
Training loss: 0.17001327872276306
Validation loss: 1.6595802794220627

Epoch: 6| Step: 9
Training loss: 0.37474876642227173
Validation loss: 1.6191790962731967

Epoch: 6| Step: 10
Training loss: 0.1558838188648224
Validation loss: 1.6528646125588367

Epoch: 6| Step: 11
Training loss: 0.19871117174625397
Validation loss: 1.6518034934997559

Epoch: 6| Step: 12
Training loss: 0.29177016019821167
Validation loss: 1.6324786088799919

Epoch: 6| Step: 13
Training loss: 0.12206390500068665
Validation loss: 1.6136204132469751

Epoch: 517| Step: 0
Training loss: 0.1275186836719513
Validation loss: 1.6181806287457865

Epoch: 6| Step: 1
Training loss: 0.3414575457572937
Validation loss: 1.6111402370596444

Epoch: 6| Step: 2
Training loss: 0.22164656221866608
Validation loss: 1.558607106567711

Epoch: 6| Step: 3
Training loss: 0.1564902663230896
Validation loss: 1.6151771763319611

Epoch: 6| Step: 4
Training loss: 0.2943260073661804
Validation loss: 1.6030739122821438

Epoch: 6| Step: 5
Training loss: 0.23055323958396912
Validation loss: 1.5896982236575055

Epoch: 6| Step: 6
Training loss: 0.264639675617218
Validation loss: 1.606414988476743

Epoch: 6| Step: 7
Training loss: 0.29528912901878357
Validation loss: 1.5939075177715671

Epoch: 6| Step: 8
Training loss: 0.2561440169811249
Validation loss: 1.6563775308670536

Epoch: 6| Step: 9
Training loss: 0.19700564444065094
Validation loss: 1.613479104093326

Epoch: 6| Step: 10
Training loss: 0.11707282811403275
Validation loss: 1.6193822481298958

Epoch: 6| Step: 11
Training loss: 0.3846282362937927
Validation loss: 1.603592611128284

Epoch: 6| Step: 12
Training loss: 0.20994877815246582
Validation loss: 1.6355493632696008

Epoch: 6| Step: 13
Training loss: 0.22856706380844116
Validation loss: 1.6068134064315467

Epoch: 518| Step: 0
Training loss: 0.26943111419677734
Validation loss: 1.6207347223835606

Epoch: 6| Step: 1
Training loss: 0.12172258645296097
Validation loss: 1.625562524282804

Epoch: 6| Step: 2
Training loss: 0.34446823596954346
Validation loss: 1.5920279756669076

Epoch: 6| Step: 3
Training loss: 0.1692604422569275
Validation loss: 1.5969121750964914

Epoch: 6| Step: 4
Training loss: 0.31108585000038147
Validation loss: 1.5979844754742039

Epoch: 6| Step: 5
Training loss: 0.24176502227783203
Validation loss: 1.6123288011038175

Epoch: 6| Step: 6
Training loss: 0.3013492822647095
Validation loss: 1.6165542974266955

Epoch: 6| Step: 7
Training loss: 0.1544630229473114
Validation loss: 1.6177002024906937

Epoch: 6| Step: 8
Training loss: 0.17540660500526428
Validation loss: 1.6210996745735087

Epoch: 6| Step: 9
Training loss: 0.17147792875766754
Validation loss: 1.597303964758432

Epoch: 6| Step: 10
Training loss: 0.2964478135108948
Validation loss: 1.6548411423160183

Epoch: 6| Step: 11
Training loss: 0.24255900084972382
Validation loss: 1.6045309651282527

Epoch: 6| Step: 12
Training loss: 0.1818644106388092
Validation loss: 1.6019563777472383

Epoch: 6| Step: 13
Training loss: 0.3795793056488037
Validation loss: 1.5765407892965502

Epoch: 519| Step: 0
Training loss: 0.23428350687026978
Validation loss: 1.653786438767628

Epoch: 6| Step: 1
Training loss: 0.17579220235347748
Validation loss: 1.6047465993512062

Epoch: 6| Step: 2
Training loss: 0.29987528920173645
Validation loss: 1.616077543586813

Epoch: 6| Step: 3
Training loss: 0.343919962644577
Validation loss: 1.6115889459527948

Epoch: 6| Step: 4
Training loss: 0.17604918777942657
Validation loss: 1.572510665462863

Epoch: 6| Step: 5
Training loss: 0.21871674060821533
Validation loss: 1.5722908037965015

Epoch: 6| Step: 6
Training loss: 0.14996269345283508
Validation loss: 1.5997627255737141

Epoch: 6| Step: 7
Training loss: 0.21444754302501678
Validation loss: 1.5714567316475736

Epoch: 6| Step: 8
Training loss: 0.19976355135440826
Validation loss: 1.5739321965043263

Epoch: 6| Step: 9
Training loss: 0.24470147490501404
Validation loss: 1.6064075834007674

Epoch: 6| Step: 10
Training loss: 0.4347468912601471
Validation loss: 1.5942617911164478

Epoch: 6| Step: 11
Training loss: 0.2528461217880249
Validation loss: 1.5987852722085931

Epoch: 6| Step: 12
Training loss: 0.33136579394340515
Validation loss: 1.6167262984860329

Epoch: 6| Step: 13
Training loss: 0.1518387347459793
Validation loss: 1.636947718999719

Epoch: 520| Step: 0
Training loss: 0.1743815541267395
Validation loss: 1.6303350963900167

Epoch: 6| Step: 1
Training loss: 0.3007161021232605
Validation loss: 1.6582184735164847

Epoch: 6| Step: 2
Training loss: 0.20112024247646332
Validation loss: 1.6860032440513693

Epoch: 6| Step: 3
Training loss: 0.28415876626968384
Validation loss: 1.6562385187354138

Epoch: 6| Step: 4
Training loss: 0.1732688844203949
Validation loss: 1.6570219993591309

Epoch: 6| Step: 5
Training loss: 0.28354498744010925
Validation loss: 1.667428034608082

Epoch: 6| Step: 6
Training loss: 0.2636277675628662
Validation loss: 1.6347579468962967

Epoch: 6| Step: 7
Training loss: 0.1643502414226532
Validation loss: 1.626025156308246

Epoch: 6| Step: 8
Training loss: 0.16120415925979614
Validation loss: 1.6174061106097313

Epoch: 6| Step: 9
Training loss: 0.40522417426109314
Validation loss: 1.579076168357685

Epoch: 6| Step: 10
Training loss: 0.21097901463508606
Validation loss: 1.5827039659664195

Epoch: 6| Step: 11
Training loss: 0.14591068029403687
Validation loss: 1.5812546168604205

Epoch: 6| Step: 12
Training loss: 0.1710854172706604
Validation loss: 1.600866360049094

Epoch: 6| Step: 13
Training loss: 0.316498339176178
Validation loss: 1.6147267779996317

Epoch: 521| Step: 0
Training loss: 0.1856345534324646
Validation loss: 1.6127047718212169

Epoch: 6| Step: 1
Training loss: 0.17416605353355408
Validation loss: 1.6358168637880715

Epoch: 6| Step: 2
Training loss: 0.3049820363521576
Validation loss: 1.6108785290871896

Epoch: 6| Step: 3
Training loss: 0.1480391025543213
Validation loss: 1.6011700912188458

Epoch: 6| Step: 4
Training loss: 0.27104929089546204
Validation loss: 1.5716738636775682

Epoch: 6| Step: 5
Training loss: 0.23677007853984833
Validation loss: 1.5679426423964962

Epoch: 6| Step: 6
Training loss: 0.2063995748758316
Validation loss: 1.5911225067671908

Epoch: 6| Step: 7
Training loss: 0.2745181918144226
Validation loss: 1.6096139454072522

Epoch: 6| Step: 8
Training loss: 0.2897372245788574
Validation loss: 1.5804563273665726

Epoch: 6| Step: 9
Training loss: 0.21123814582824707
Validation loss: 1.6060598768213743

Epoch: 6| Step: 10
Training loss: 0.16480553150177002
Validation loss: 1.5918286820893646

Epoch: 6| Step: 11
Training loss: 0.28123074769973755
Validation loss: 1.6067105621419928

Epoch: 6| Step: 12
Training loss: 0.27535173296928406
Validation loss: 1.610192511671333

Epoch: 6| Step: 13
Training loss: 0.31034791469573975
Validation loss: 1.591359096188699

Epoch: 522| Step: 0
Training loss: 0.15236321091651917
Validation loss: 1.5858768557989469

Epoch: 6| Step: 1
Training loss: 0.3139598071575165
Validation loss: 1.577844242895803

Epoch: 6| Step: 2
Training loss: 0.1578424572944641
Validation loss: 1.5764375425154162

Epoch: 6| Step: 3
Training loss: 0.10985906422138214
Validation loss: 1.5985958691566222

Epoch: 6| Step: 4
Training loss: 0.32735252380371094
Validation loss: 1.5950890189857894

Epoch: 6| Step: 5
Training loss: 0.4496714174747467
Validation loss: 1.5644946098327637

Epoch: 6| Step: 6
Training loss: 0.20561377704143524
Validation loss: 1.5614677680436002

Epoch: 6| Step: 7
Training loss: 0.16329339146614075
Validation loss: 1.5518477039952432

Epoch: 6| Step: 8
Training loss: 0.16069579124450684
Validation loss: 1.5584610969789567

Epoch: 6| Step: 9
Training loss: 0.1766936182975769
Validation loss: 1.5926256090082147

Epoch: 6| Step: 10
Training loss: 0.30146336555480957
Validation loss: 1.5781243212761418

Epoch: 6| Step: 11
Training loss: 0.09874089807271957
Validation loss: 1.608901544283795

Epoch: 6| Step: 12
Training loss: 0.32359111309051514
Validation loss: 1.5810571614132132

Epoch: 6| Step: 13
Training loss: 0.13925153017044067
Validation loss: 1.6432191197590162

Epoch: 523| Step: 0
Training loss: 0.17765899002552032
Validation loss: 1.617085967012631

Epoch: 6| Step: 1
Training loss: 0.1542654037475586
Validation loss: 1.5900540172412831

Epoch: 6| Step: 2
Training loss: 0.17072030901908875
Validation loss: 1.5868289662945656

Epoch: 6| Step: 3
Training loss: 0.2474178671836853
Validation loss: 1.584592850618465

Epoch: 6| Step: 4
Training loss: 0.2382408231496811
Validation loss: 1.5697474812948575

Epoch: 6| Step: 5
Training loss: 0.26993072032928467
Validation loss: 1.578746840518008

Epoch: 6| Step: 6
Training loss: 0.20788954198360443
Validation loss: 1.5600837161464076

Epoch: 6| Step: 7
Training loss: 0.16836979985237122
Validation loss: 1.5486633264890282

Epoch: 6| Step: 8
Training loss: 0.35799241065979004
Validation loss: 1.5394958167947748

Epoch: 6| Step: 9
Training loss: 0.21232186257839203
Validation loss: 1.5852956207849647

Epoch: 6| Step: 10
Training loss: 0.2642751932144165
Validation loss: 1.5409235441556541

Epoch: 6| Step: 11
Training loss: 0.32690995931625366
Validation loss: 1.558698807993243

Epoch: 6| Step: 12
Training loss: 0.16878126561641693
Validation loss: 1.5988078117370605

Epoch: 6| Step: 13
Training loss: 0.22375886142253876
Validation loss: 1.5928244283122401

Epoch: 524| Step: 0
Training loss: 0.2706141769886017
Validation loss: 1.6275379196290047

Epoch: 6| Step: 1
Training loss: 0.23093301057815552
Validation loss: 1.6964477275007515

Epoch: 6| Step: 2
Training loss: 0.15857422351837158
Validation loss: 1.6800280963220904

Epoch: 6| Step: 3
Training loss: 0.3143463432788849
Validation loss: 1.6956098271954445

Epoch: 6| Step: 4
Training loss: 0.36591774225234985
Validation loss: 1.6680944888822493

Epoch: 6| Step: 5
Training loss: 0.21594244241714478
Validation loss: 1.682024202039165

Epoch: 6| Step: 6
Training loss: 0.2536141276359558
Validation loss: 1.6306217101312452

Epoch: 6| Step: 7
Training loss: 0.24657684564590454
Validation loss: 1.5843939499188495

Epoch: 6| Step: 8
Training loss: 0.22986024618148804
Validation loss: 1.5606588753320838

Epoch: 6| Step: 9
Training loss: 0.29765957593917847
Validation loss: 1.6084925090112994

Epoch: 6| Step: 10
Training loss: 0.15929880738258362
Validation loss: 1.5919323275166173

Epoch: 6| Step: 11
Training loss: 0.2138144075870514
Validation loss: 1.5939571472906298

Epoch: 6| Step: 12
Training loss: 0.10839288681745529
Validation loss: 1.553316593170166

Epoch: 6| Step: 13
Training loss: 0.28668323159217834
Validation loss: 1.5925921176069526

Epoch: 525| Step: 0
Training loss: 0.25615620613098145
Validation loss: 1.6045369102108864

Epoch: 6| Step: 1
Training loss: 0.17968085408210754
Validation loss: 1.6116931643537296

Epoch: 6| Step: 2
Training loss: 0.2565189599990845
Validation loss: 1.6155002911885579

Epoch: 6| Step: 3
Training loss: 0.1556839495897293
Validation loss: 1.6170914070580595

Epoch: 6| Step: 4
Training loss: 0.3544674515724182
Validation loss: 1.595596036603374

Epoch: 6| Step: 5
Training loss: 0.16180959343910217
Validation loss: 1.6103203886298723

Epoch: 6| Step: 6
Training loss: 0.08211326599121094
Validation loss: 1.5872736233536915

Epoch: 6| Step: 7
Training loss: 0.16141949594020844
Validation loss: 1.5879104919331049

Epoch: 6| Step: 8
Training loss: 0.267608106136322
Validation loss: 1.5488237168199273

Epoch: 6| Step: 9
Training loss: 0.24115118384361267
Validation loss: 1.6103808021032682

Epoch: 6| Step: 10
Training loss: 0.38179653882980347
Validation loss: 1.6041106639369842

Epoch: 6| Step: 11
Training loss: 0.25443488359451294
Validation loss: 1.5917631368483267

Epoch: 6| Step: 12
Training loss: 0.16966253519058228
Validation loss: 1.6062751303436935

Epoch: 6| Step: 13
Training loss: 0.1999076008796692
Validation loss: 1.6121930165957379

Epoch: 526| Step: 0
Training loss: 0.19193550944328308
Validation loss: 1.6105784472598825

Epoch: 6| Step: 1
Training loss: 0.24946343898773193
Validation loss: 1.6061917299865394

Epoch: 6| Step: 2
Training loss: 0.30171775817871094
Validation loss: 1.6322951227106073

Epoch: 6| Step: 3
Training loss: 0.19172796607017517
Validation loss: 1.6012970375758346

Epoch: 6| Step: 4
Training loss: 0.10139496624469757
Validation loss: 1.6345942033234464

Epoch: 6| Step: 5
Training loss: 0.40411099791526794
Validation loss: 1.5885515809059143

Epoch: 6| Step: 6
Training loss: 0.14720718562602997
Validation loss: 1.6505717154472106

Epoch: 6| Step: 7
Training loss: 0.18977954983711243
Validation loss: 1.6800610506406395

Epoch: 6| Step: 8
Training loss: 0.2610814869403839
Validation loss: 1.6808311157329108

Epoch: 6| Step: 9
Training loss: 0.18705719709396362
Validation loss: 1.679989613512511

Epoch: 6| Step: 10
Training loss: 0.43351349234580994
Validation loss: 1.711954939749933

Epoch: 6| Step: 11
Training loss: 0.3230046033859253
Validation loss: 1.6985136155159242

Epoch: 6| Step: 12
Training loss: 0.18164309859275818
Validation loss: 1.6386455887107438

Epoch: 6| Step: 13
Training loss: 0.1676168441772461
Validation loss: 1.6466083077974216

Epoch: 527| Step: 0
Training loss: 0.15427368879318237
Validation loss: 1.63088325659434

Epoch: 6| Step: 1
Training loss: 0.23998674750328064
Validation loss: 1.630954078448716

Epoch: 6| Step: 2
Training loss: 0.2171422839164734
Validation loss: 1.5882243667879412

Epoch: 6| Step: 3
Training loss: 0.18424499034881592
Validation loss: 1.5679893301379295

Epoch: 6| Step: 4
Training loss: 0.29749059677124023
Validation loss: 1.6012585701480988

Epoch: 6| Step: 5
Training loss: 0.2773287296295166
Validation loss: 1.5878035445367136

Epoch: 6| Step: 6
Training loss: 0.1226416826248169
Validation loss: 1.5814701780196159

Epoch: 6| Step: 7
Training loss: 0.2350897341966629
Validation loss: 1.607120539552422

Epoch: 6| Step: 8
Training loss: 0.3322679400444031
Validation loss: 1.5999316810279764

Epoch: 6| Step: 9
Training loss: 0.22697004675865173
Validation loss: 1.584522726715252

Epoch: 6| Step: 10
Training loss: 0.2185102105140686
Validation loss: 1.641629292118934

Epoch: 6| Step: 11
Training loss: 0.23531047999858856
Validation loss: 1.6510665570535967

Epoch: 6| Step: 12
Training loss: 0.3692471385002136
Validation loss: 1.6614004104368147

Epoch: 6| Step: 13
Training loss: 0.20067626237869263
Validation loss: 1.663977872940802

Epoch: 528| Step: 0
Training loss: 0.22042140364646912
Validation loss: 1.642252609293948

Epoch: 6| Step: 1
Training loss: 0.2621932327747345
Validation loss: 1.6174452048476025

Epoch: 6| Step: 2
Training loss: 0.22747398912906647
Validation loss: 1.6391445975149832

Epoch: 6| Step: 3
Training loss: 0.2592926621437073
Validation loss: 1.629156981745074

Epoch: 6| Step: 4
Training loss: 0.13729432225227356
Validation loss: 1.6676924843941965

Epoch: 6| Step: 5
Training loss: 0.18940654397010803
Validation loss: 1.6225803206043858

Epoch: 6| Step: 6
Training loss: 0.27343618869781494
Validation loss: 1.6091878580790695

Epoch: 6| Step: 7
Training loss: 0.2216757833957672
Validation loss: 1.590982869107236

Epoch: 6| Step: 8
Training loss: 0.11169388890266418
Validation loss: 1.6233078933531238

Epoch: 6| Step: 9
Training loss: 0.17007751762866974
Validation loss: 1.6201014159828104

Epoch: 6| Step: 10
Training loss: 0.3474957346916199
Validation loss: 1.6406358365089662

Epoch: 6| Step: 11
Training loss: 0.25825244188308716
Validation loss: 1.6223780711491902

Epoch: 6| Step: 12
Training loss: 0.1840931475162506
Validation loss: 1.6089684065952097

Epoch: 6| Step: 13
Training loss: 0.20886613428592682
Validation loss: 1.5873578722758959

Epoch: 529| Step: 0
Training loss: 0.2739640474319458
Validation loss: 1.6124440111139768

Epoch: 6| Step: 1
Training loss: 0.22698035836219788
Validation loss: 1.5935167253658336

Epoch: 6| Step: 2
Training loss: 0.27891793847084045
Validation loss: 1.5734333799731346

Epoch: 6| Step: 3
Training loss: 0.35320642590522766
Validation loss: 1.625029226785065

Epoch: 6| Step: 4
Training loss: 0.24555891752243042
Validation loss: 1.6243606716073968

Epoch: 6| Step: 5
Training loss: 0.3051360845565796
Validation loss: 1.6093226786582702

Epoch: 6| Step: 6
Training loss: 0.17738807201385498
Validation loss: 1.59233860687543

Epoch: 6| Step: 7
Training loss: 0.25842493772506714
Validation loss: 1.5708860517829977

Epoch: 6| Step: 8
Training loss: 0.15272679924964905
Validation loss: 1.5885485295326478

Epoch: 6| Step: 9
Training loss: 0.13570019602775574
Validation loss: 1.5761830063276394

Epoch: 6| Step: 10
Training loss: 0.1544213593006134
Validation loss: 1.552732011323334

Epoch: 6| Step: 11
Training loss: 0.25105929374694824
Validation loss: 1.5809139487563924

Epoch: 6| Step: 12
Training loss: 0.19798320531845093
Validation loss: 1.5650333153304232

Epoch: 6| Step: 13
Training loss: 0.13179893791675568
Validation loss: 1.5435377961845809

Epoch: 530| Step: 0
Training loss: 0.4238232672214508
Validation loss: 1.5818677756094164

Epoch: 6| Step: 1
Training loss: 0.25514405965805054
Validation loss: 1.537011686191764

Epoch: 6| Step: 2
Training loss: 0.15313151478767395
Validation loss: 1.5535920871201383

Epoch: 6| Step: 3
Training loss: 0.24149242043495178
Validation loss: 1.578241159839015

Epoch: 6| Step: 4
Training loss: 0.25916436314582825
Validation loss: 1.5967641415134552

Epoch: 6| Step: 5
Training loss: 0.28193873167037964
Validation loss: 1.5605721383966424

Epoch: 6| Step: 6
Training loss: 0.25015726685523987
Validation loss: 1.5829286985499884

Epoch: 6| Step: 7
Training loss: 0.1863432675600052
Validation loss: 1.6130551086959017

Epoch: 6| Step: 8
Training loss: 0.16683989763259888
Validation loss: 1.6183081596128401

Epoch: 6| Step: 9
Training loss: 0.13308775424957275
Validation loss: 1.6091325359959756

Epoch: 6| Step: 10
Training loss: 0.2892373204231262
Validation loss: 1.6385071944164973

Epoch: 6| Step: 11
Training loss: 0.24914535880088806
Validation loss: 1.6069488756118282

Epoch: 6| Step: 12
Training loss: 0.20289894938468933
Validation loss: 1.6118129261078373

Epoch: 6| Step: 13
Training loss: 0.13621947169303894
Validation loss: 1.5979837333002398

Epoch: 531| Step: 0
Training loss: 0.09260328114032745
Validation loss: 1.5726341355231501

Epoch: 6| Step: 1
Training loss: 0.21987292170524597
Validation loss: 1.5769549313411917

Epoch: 6| Step: 2
Training loss: 0.28379392623901367
Validation loss: 1.5712683649473294

Epoch: 6| Step: 3
Training loss: 0.3095798194408417
Validation loss: 1.6235259655983216

Epoch: 6| Step: 4
Training loss: 0.147945374250412
Validation loss: 1.6237137266384658

Epoch: 6| Step: 5
Training loss: 0.25147679448127747
Validation loss: 1.5560092131296794

Epoch: 6| Step: 6
Training loss: 0.37254369258880615
Validation loss: 1.5621653705514886

Epoch: 6| Step: 7
Training loss: 0.2946047782897949
Validation loss: 1.6092825846005512

Epoch: 6| Step: 8
Training loss: 0.19747737050056458
Validation loss: 1.6075490995119976

Epoch: 6| Step: 9
Training loss: 0.22166162729263306
Validation loss: 1.6030230855429044

Epoch: 6| Step: 10
Training loss: 0.19141921401023865
Validation loss: 1.5975040146099624

Epoch: 6| Step: 11
Training loss: 0.25620827078819275
Validation loss: 1.6131394319636847

Epoch: 6| Step: 12
Training loss: 0.15949197113513947
Validation loss: 1.6180497266912972

Epoch: 6| Step: 13
Training loss: 0.096280537545681
Validation loss: 1.6202508711045789

Epoch: 532| Step: 0
Training loss: 0.278936505317688
Validation loss: 1.6090862597188642

Epoch: 6| Step: 1
Training loss: 0.28811365365982056
Validation loss: 1.5872333113865187

Epoch: 6| Step: 2
Training loss: 0.1888284683227539
Validation loss: 1.6137259621773996

Epoch: 6| Step: 3
Training loss: 0.26806801557540894
Validation loss: 1.6106301751188052

Epoch: 6| Step: 4
Training loss: 0.1962297558784485
Validation loss: 1.5918522316922423

Epoch: 6| Step: 5
Training loss: 0.2349996715784073
Validation loss: 1.552157030310682

Epoch: 6| Step: 6
Training loss: 0.16624075174331665
Validation loss: 1.5556163582750546

Epoch: 6| Step: 7
Training loss: 0.16006210446357727
Validation loss: 1.548032541428843

Epoch: 6| Step: 8
Training loss: 0.2091600000858307
Validation loss: 1.5480695411723147

Epoch: 6| Step: 9
Training loss: 0.2520412504673004
Validation loss: 1.5723232018050326

Epoch: 6| Step: 10
Training loss: 0.1519675999879837
Validation loss: 1.584099208154986

Epoch: 6| Step: 11
Training loss: 0.07030661404132843
Validation loss: 1.5711041009554298

Epoch: 6| Step: 12
Training loss: 0.4131790101528168
Validation loss: 1.5946626406843945

Epoch: 6| Step: 13
Training loss: 0.336093544960022
Validation loss: 1.6154077245343117

Epoch: 533| Step: 0
Training loss: 0.10572317987680435
Validation loss: 1.6494593857437052

Epoch: 6| Step: 1
Training loss: 0.25603726506233215
Validation loss: 1.603797048650762

Epoch: 6| Step: 2
Training loss: 0.18144343793392181
Validation loss: 1.585005824283887

Epoch: 6| Step: 3
Training loss: 0.29029011726379395
Validation loss: 1.5883206539256598

Epoch: 6| Step: 4
Training loss: 0.2547916769981384
Validation loss: 1.5765115240568757

Epoch: 6| Step: 5
Training loss: 0.19048266112804413
Validation loss: 1.5906950017457366

Epoch: 6| Step: 6
Training loss: 0.22249943017959595
Validation loss: 1.6116812664975402

Epoch: 6| Step: 7
Training loss: 0.25706884264945984
Validation loss: 1.6168205661158408

Epoch: 6| Step: 8
Training loss: 0.29973945021629333
Validation loss: 1.640370843231037

Epoch: 6| Step: 9
Training loss: 0.24350634217262268
Validation loss: 1.6427462870074856

Epoch: 6| Step: 10
Training loss: 0.3495660722255707
Validation loss: 1.6317559801122195

Epoch: 6| Step: 11
Training loss: 0.1812024563550949
Validation loss: 1.6332769957921838

Epoch: 6| Step: 12
Training loss: 0.17333410680294037
Validation loss: 1.6783774014442199

Epoch: 6| Step: 13
Training loss: 0.30927208065986633
Validation loss: 1.668063017629808

Epoch: 534| Step: 0
Training loss: 0.32966241240501404
Validation loss: 1.6353715465914818

Epoch: 6| Step: 1
Training loss: 0.18536484241485596
Validation loss: 1.6392976263517975

Epoch: 6| Step: 2
Training loss: 0.3000027537345886
Validation loss: 1.631784850551236

Epoch: 6| Step: 3
Training loss: 0.19637346267700195
Validation loss: 1.6362686759682112

Epoch: 6| Step: 4
Training loss: 0.25014400482177734
Validation loss: 1.5803278735888902

Epoch: 6| Step: 5
Training loss: 0.19547025859355927
Validation loss: 1.5882563424366776

Epoch: 6| Step: 6
Training loss: 0.13992144167423248
Validation loss: 1.5779324526427894

Epoch: 6| Step: 7
Training loss: 0.22192493081092834
Validation loss: 1.571848641159714

Epoch: 6| Step: 8
Training loss: 0.23454225063323975
Validation loss: 1.5848346730714202

Epoch: 6| Step: 9
Training loss: 0.19724628329277039
Validation loss: 1.5576907370680122

Epoch: 6| Step: 10
Training loss: 0.3032175600528717
Validation loss: 1.5844924116647372

Epoch: 6| Step: 11
Training loss: 0.17078503966331482
Validation loss: 1.5719402810578704

Epoch: 6| Step: 12
Training loss: 0.17151477932929993
Validation loss: 1.5880423489437308

Epoch: 6| Step: 13
Training loss: 0.19951297342777252
Validation loss: 1.5971244355683685

Epoch: 535| Step: 0
Training loss: 0.16471198201179504
Validation loss: 1.6159315891163324

Epoch: 6| Step: 1
Training loss: 0.36951369047164917
Validation loss: 1.6295825653178717

Epoch: 6| Step: 2
Training loss: 0.20804889500141144
Validation loss: 1.6397172847101766

Epoch: 6| Step: 3
Training loss: 0.2517338693141937
Validation loss: 1.6302777349307973

Epoch: 6| Step: 4
Training loss: 0.297453910112381
Validation loss: 1.584285443828952

Epoch: 6| Step: 5
Training loss: 0.20506250858306885
Validation loss: 1.569551952423588

Epoch: 6| Step: 6
Training loss: 0.24491500854492188
Validation loss: 1.5626553252179136

Epoch: 6| Step: 7
Training loss: 0.2292238175868988
Validation loss: 1.5754125477165304

Epoch: 6| Step: 8
Training loss: 0.358130544424057
Validation loss: 1.5338196639091737

Epoch: 6| Step: 9
Training loss: 0.1339486539363861
Validation loss: 1.552071758495864

Epoch: 6| Step: 10
Training loss: 0.08483783900737762
Validation loss: 1.5311787243812316

Epoch: 6| Step: 11
Training loss: 0.23760508000850677
Validation loss: 1.538329033441441

Epoch: 6| Step: 12
Training loss: 0.11054819822311401
Validation loss: 1.5499945173981369

Epoch: 6| Step: 13
Training loss: 0.19708865880966187
Validation loss: 1.520750956509703

Epoch: 536| Step: 0
Training loss: 0.31013500690460205
Validation loss: 1.5534423294887747

Epoch: 6| Step: 1
Training loss: 0.24466732144355774
Validation loss: 1.5440195542509838

Epoch: 6| Step: 2
Training loss: 0.09539186954498291
Validation loss: 1.5750527760033965

Epoch: 6| Step: 3
Training loss: 0.2803134322166443
Validation loss: 1.5920939676223262

Epoch: 6| Step: 4
Training loss: 0.1486482322216034
Validation loss: 1.630251056404524

Epoch: 6| Step: 5
Training loss: 0.1674279421567917
Validation loss: 1.6391525781282814

Epoch: 6| Step: 6
Training loss: 0.1780705749988556
Validation loss: 1.6447511975483229

Epoch: 6| Step: 7
Training loss: 0.3061429560184479
Validation loss: 1.6268685120408253

Epoch: 6| Step: 8
Training loss: 0.2587234377861023
Validation loss: 1.6566518429786927

Epoch: 6| Step: 9
Training loss: 0.12267666310071945
Validation loss: 1.590858119790272

Epoch: 6| Step: 10
Training loss: 0.19002848863601685
Validation loss: 1.5815765447514032

Epoch: 6| Step: 11
Training loss: 0.3277081251144409
Validation loss: 1.5673412879308064

Epoch: 6| Step: 12
Training loss: 0.15575161576271057
Validation loss: 1.5716292076213385

Epoch: 6| Step: 13
Training loss: 0.29555410146713257
Validation loss: 1.5249010055295882

Epoch: 537| Step: 0
Training loss: 0.18313586711883545
Validation loss: 1.546234792278659

Epoch: 6| Step: 1
Training loss: 0.22066795825958252
Validation loss: 1.531809922187559

Epoch: 6| Step: 2
Training loss: 0.24462205171585083
Validation loss: 1.5250997774062618

Epoch: 6| Step: 3
Training loss: 0.26316559314727783
Validation loss: 1.5670087529766945

Epoch: 6| Step: 4
Training loss: 0.43416815996170044
Validation loss: 1.5851333551509406

Epoch: 6| Step: 5
Training loss: 0.12803706526756287
Validation loss: 1.626348062228131

Epoch: 6| Step: 6
Training loss: 0.12004241347312927
Validation loss: 1.6014339488039735

Epoch: 6| Step: 7
Training loss: 0.29863131046295166
Validation loss: 1.666201199254682

Epoch: 6| Step: 8
Training loss: 0.27763885259628296
Validation loss: 1.685881063502322

Epoch: 6| Step: 9
Training loss: 0.14280545711517334
Validation loss: 1.6553320948795607

Epoch: 6| Step: 10
Training loss: 0.22562074661254883
Validation loss: 1.6278909226899505

Epoch: 6| Step: 11
Training loss: 0.20656999945640564
Validation loss: 1.6249957366656231

Epoch: 6| Step: 12
Training loss: 0.1968560367822647
Validation loss: 1.6162609951470488

Epoch: 6| Step: 13
Training loss: 0.10932771116495132
Validation loss: 1.561555254843927

Epoch: 538| Step: 0
Training loss: 0.2035028636455536
Validation loss: 1.568234161664081

Epoch: 6| Step: 1
Training loss: 0.17286013066768646
Validation loss: 1.5667081186848302

Epoch: 6| Step: 2
Training loss: 0.16913072764873505
Validation loss: 1.555497141294582

Epoch: 6| Step: 3
Training loss: 0.14909598231315613
Validation loss: 1.568641362651702

Epoch: 6| Step: 4
Training loss: 0.2531239986419678
Validation loss: 1.593473078102194

Epoch: 6| Step: 5
Training loss: 0.2805996239185333
Validation loss: 1.5813956747772873

Epoch: 6| Step: 6
Training loss: 0.3785606324672699
Validation loss: 1.5597545203342233

Epoch: 6| Step: 7
Training loss: 0.14288456737995148
Validation loss: 1.587106584220804

Epoch: 6| Step: 8
Training loss: 0.3097982406616211
Validation loss: 1.5559961840670595

Epoch: 6| Step: 9
Training loss: 0.1334265172481537
Validation loss: 1.5711437912397488

Epoch: 6| Step: 10
Training loss: 0.18120208382606506
Validation loss: 1.542522874570662

Epoch: 6| Step: 11
Training loss: 0.2460484504699707
Validation loss: 1.5513813123908093

Epoch: 6| Step: 12
Training loss: 0.20817634463310242
Validation loss: 1.554485099290007

Epoch: 6| Step: 13
Training loss: 0.1636713296175003
Validation loss: 1.5846250416130148

Epoch: 539| Step: 0
Training loss: 0.14503628015518188
Validation loss: 1.5791198874032626

Epoch: 6| Step: 1
Training loss: 0.2137136459350586
Validation loss: 1.6085353641099827

Epoch: 6| Step: 2
Training loss: 0.20347312092781067
Validation loss: 1.6322065027811195

Epoch: 6| Step: 3
Training loss: 0.0576019287109375
Validation loss: 1.6366428316280406

Epoch: 6| Step: 4
Training loss: 0.19190029799938202
Validation loss: 1.6105277910027453

Epoch: 6| Step: 5
Training loss: 0.17115901410579681
Validation loss: 1.5961762564156645

Epoch: 6| Step: 6
Training loss: 0.2805934250354767
Validation loss: 1.5689829498208978

Epoch: 6| Step: 7
Training loss: 0.2908054292201996
Validation loss: 1.5969708619579193

Epoch: 6| Step: 8
Training loss: 0.19940415024757385
Validation loss: 1.5433941233542658

Epoch: 6| Step: 9
Training loss: 0.28792616724967957
Validation loss: 1.5607348565132386

Epoch: 6| Step: 10
Training loss: 0.2182852178812027
Validation loss: 1.56199949531145

Epoch: 6| Step: 11
Training loss: 0.19653303921222687
Validation loss: 1.5567759890710153

Epoch: 6| Step: 12
Training loss: 0.21745902299880981
Validation loss: 1.583506141939471

Epoch: 6| Step: 13
Training loss: 0.3427489995956421
Validation loss: 1.5809538172137352

Epoch: 540| Step: 0
Training loss: 0.3244786262512207
Validation loss: 1.5941104235187653

Epoch: 6| Step: 1
Training loss: 0.2872336208820343
Validation loss: 1.5888397860270675

Epoch: 6| Step: 2
Training loss: 0.22082921862602234
Validation loss: 1.5901596379536453

Epoch: 6| Step: 3
Training loss: 0.18550509214401245
Validation loss: 1.6085412963744132

Epoch: 6| Step: 4
Training loss: 0.26539403200149536
Validation loss: 1.6273696063667216

Epoch: 6| Step: 5
Training loss: 0.29121512174606323
Validation loss: 1.5898441499279392

Epoch: 6| Step: 6
Training loss: 0.2879110872745514
Validation loss: 1.573794355956457

Epoch: 6| Step: 7
Training loss: 0.1391030251979828
Validation loss: 1.5891499250165877

Epoch: 6| Step: 8
Training loss: 0.28209441900253296
Validation loss: 1.5875556943237141

Epoch: 6| Step: 9
Training loss: 0.3175910711288452
Validation loss: 1.5818652100460504

Epoch: 6| Step: 10
Training loss: 0.10283002257347107
Validation loss: 1.6156965327519242

Epoch: 6| Step: 11
Training loss: 0.21302145719528198
Validation loss: 1.6239484087113412

Epoch: 6| Step: 12
Training loss: 0.2915351092815399
Validation loss: 1.6363467631801483

Epoch: 6| Step: 13
Training loss: 0.13080400228500366
Validation loss: 1.6332516772772676

Epoch: 541| Step: 0
Training loss: 0.44876551628112793
Validation loss: 1.611022880000453

Epoch: 6| Step: 1
Training loss: 0.14919784665107727
Validation loss: 1.6147287404665382

Epoch: 6| Step: 2
Training loss: 0.22479376196861267
Validation loss: 1.595223928010592

Epoch: 6| Step: 3
Training loss: 0.18197982013225555
Validation loss: 1.607382728207496

Epoch: 6| Step: 4
Training loss: 0.14748388528823853
Validation loss: 1.6043842479746828

Epoch: 6| Step: 5
Training loss: 0.19220420718193054
Validation loss: 1.5975424570422019

Epoch: 6| Step: 6
Training loss: 0.07337424159049988
Validation loss: 1.5892108781363374

Epoch: 6| Step: 7
Training loss: 0.19152644276618958
Validation loss: 1.6072978537569764

Epoch: 6| Step: 8
Training loss: 0.21518298983573914
Validation loss: 1.5805369948828092

Epoch: 6| Step: 9
Training loss: 0.1876397579908371
Validation loss: 1.6164247028289302

Epoch: 6| Step: 10
Training loss: 0.34113186597824097
Validation loss: 1.5780957680876537

Epoch: 6| Step: 11
Training loss: 0.15353354811668396
Validation loss: 1.623749429179776

Epoch: 6| Step: 12
Training loss: 0.19462749361991882
Validation loss: 1.621910838670628

Epoch: 6| Step: 13
Training loss: 0.31229233741760254
Validation loss: 1.602338514020366

Epoch: 542| Step: 0
Training loss: 0.12281084060668945
Validation loss: 1.5801124854754376

Epoch: 6| Step: 1
Training loss: 0.21717935800552368
Validation loss: 1.596888647284559

Epoch: 6| Step: 2
Training loss: 0.17617279291152954
Validation loss: 1.583617998707679

Epoch: 6| Step: 3
Training loss: 0.2573586702346802
Validation loss: 1.5642316700309835

Epoch: 6| Step: 4
Training loss: 0.34390002489089966
Validation loss: 1.5712190892106743

Epoch: 6| Step: 5
Training loss: 0.12309586256742477
Validation loss: 1.5796036335729784

Epoch: 6| Step: 6
Training loss: 0.1528860181570053
Validation loss: 1.574351437630192

Epoch: 6| Step: 7
Training loss: 0.16661204397678375
Validation loss: 1.579099493642007

Epoch: 6| Step: 8
Training loss: 0.21535813808441162
Validation loss: 1.542989561634679

Epoch: 6| Step: 9
Training loss: 0.33920177817344666
Validation loss: 1.5582759893068703

Epoch: 6| Step: 10
Training loss: 0.19888556003570557
Validation loss: 1.5760856520745061

Epoch: 6| Step: 11
Training loss: 0.12100011110305786
Validation loss: 1.6080985684548654

Epoch: 6| Step: 12
Training loss: 0.17727230489253998
Validation loss: 1.61447908032325

Epoch: 6| Step: 13
Training loss: 0.3268616795539856
Validation loss: 1.606438398361206

Epoch: 543| Step: 0
Training loss: 0.22276043891906738
Validation loss: 1.6192100253156436

Epoch: 6| Step: 1
Training loss: 0.22067485749721527
Validation loss: 1.6004696526835043

Epoch: 6| Step: 2
Training loss: 0.20320847630500793
Validation loss: 1.5625560142660653

Epoch: 6| Step: 3
Training loss: 0.1311543583869934
Validation loss: 1.5467945042476858

Epoch: 6| Step: 4
Training loss: 0.31812965869903564
Validation loss: 1.5914258290362615

Epoch: 6| Step: 5
Training loss: 0.055404361337423325
Validation loss: 1.5566502309614612

Epoch: 6| Step: 6
Training loss: 0.17209534347057343
Validation loss: 1.582187726933469

Epoch: 6| Step: 7
Training loss: 0.21506603062152863
Validation loss: 1.5968192892689859

Epoch: 6| Step: 8
Training loss: 0.12648218870162964
Validation loss: 1.5957381315128778

Epoch: 6| Step: 9
Training loss: 0.2908090651035309
Validation loss: 1.6225037792677521

Epoch: 6| Step: 10
Training loss: 0.17196694016456604
Validation loss: 1.6386818193620252

Epoch: 6| Step: 11
Training loss: 0.25029316544532776
Validation loss: 1.6356357784681423

Epoch: 6| Step: 12
Training loss: 0.2397574484348297
Validation loss: 1.635425171544475

Epoch: 6| Step: 13
Training loss: 0.13796454668045044
Validation loss: 1.6353765431270804

Epoch: 544| Step: 0
Training loss: 0.24186700582504272
Validation loss: 1.6171397919295936

Epoch: 6| Step: 1
Training loss: 0.13493391871452332
Validation loss: 1.6131253524493145

Epoch: 6| Step: 2
Training loss: 0.16566681861877441
Validation loss: 1.5818288563400187

Epoch: 6| Step: 3
Training loss: 0.28714436292648315
Validation loss: 1.5768526818162651

Epoch: 6| Step: 4
Training loss: 0.20861393213272095
Validation loss: 1.5623467840174192

Epoch: 6| Step: 5
Training loss: 0.18047495186328888
Validation loss: 1.5702608580230384

Epoch: 6| Step: 6
Training loss: 0.1337175965309143
Validation loss: 1.536405009608115

Epoch: 6| Step: 7
Training loss: 0.133307546377182
Validation loss: 1.5923438892569592

Epoch: 6| Step: 8
Training loss: 0.3039647042751312
Validation loss: 1.577657611139359

Epoch: 6| Step: 9
Training loss: 0.24550767242908478
Validation loss: 1.5720148753094416

Epoch: 6| Step: 10
Training loss: 0.2177804559469223
Validation loss: 1.583995149981591

Epoch: 6| Step: 11
Training loss: 0.0998949408531189
Validation loss: 1.5983194305050759

Epoch: 6| Step: 12
Training loss: 0.15957759320735931
Validation loss: 1.650822336955737

Epoch: 6| Step: 13
Training loss: 0.2930842936038971
Validation loss: 1.6009851540288618

Epoch: 545| Step: 0
Training loss: 0.17601260542869568
Validation loss: 1.618340899226486

Epoch: 6| Step: 1
Training loss: 0.26509392261505127
Validation loss: 1.6189799180594824

Epoch: 6| Step: 2
Training loss: 0.2098698914051056
Validation loss: 1.603692497617455

Epoch: 6| Step: 3
Training loss: 0.2286737561225891
Validation loss: 1.6132485007727018

Epoch: 6| Step: 4
Training loss: 0.21776892244815826
Validation loss: 1.562612638678602

Epoch: 6| Step: 5
Training loss: 0.365882933139801
Validation loss: 1.551536129366967

Epoch: 6| Step: 6
Training loss: 0.21681100130081177
Validation loss: 1.5456556267635797

Epoch: 6| Step: 7
Training loss: 0.22434934973716736
Validation loss: 1.5480812441918157

Epoch: 6| Step: 8
Training loss: 0.22878670692443848
Validation loss: 1.5759197255616546

Epoch: 6| Step: 9
Training loss: 0.25088393688201904
Validation loss: 1.5732712982803263

Epoch: 6| Step: 10
Training loss: 0.3118916153907776
Validation loss: 1.609785036374164

Epoch: 6| Step: 11
Training loss: 0.3015965223312378
Validation loss: 1.5834418624959967

Epoch: 6| Step: 12
Training loss: 0.20121526718139648
Validation loss: 1.6400013867244925

Epoch: 6| Step: 13
Training loss: 0.1796126663684845
Validation loss: 1.6247395071932065

Epoch: 546| Step: 0
Training loss: 0.14827528595924377
Validation loss: 1.622476350876593

Epoch: 6| Step: 1
Training loss: 0.28153863549232483
Validation loss: 1.5989503834837226

Epoch: 6| Step: 2
Training loss: 0.1492525190114975
Validation loss: 1.5816549639548025

Epoch: 6| Step: 3
Training loss: 0.1345137506723404
Validation loss: 1.5749259648784515

Epoch: 6| Step: 4
Training loss: 0.17954647541046143
Validation loss: 1.5370607273553007

Epoch: 6| Step: 5
Training loss: 0.2355298399925232
Validation loss: 1.5535085278172647

Epoch: 6| Step: 6
Training loss: 0.17242178320884705
Validation loss: 1.5593950543352353

Epoch: 6| Step: 7
Training loss: 0.2978329062461853
Validation loss: 1.53113853931427

Epoch: 6| Step: 8
Training loss: 0.2762219309806824
Validation loss: 1.5505686344638947

Epoch: 6| Step: 9
Training loss: 0.13388890027999878
Validation loss: 1.5636847493469075

Epoch: 6| Step: 10
Training loss: 0.20169305801391602
Validation loss: 1.5576977217069237

Epoch: 6| Step: 11
Training loss: 0.18020714819431305
Validation loss: 1.5579696496327717

Epoch: 6| Step: 12
Training loss: 0.305345743894577
Validation loss: 1.5433181088457826

Epoch: 6| Step: 13
Training loss: 0.17773282527923584
Validation loss: 1.569506081201697

Epoch: 547| Step: 0
Training loss: 0.2281053364276886
Validation loss: 1.5523516785713933

Epoch: 6| Step: 1
Training loss: 0.19340960681438446
Validation loss: 1.6014172723216396

Epoch: 6| Step: 2
Training loss: 0.33247655630111694
Validation loss: 1.5794378826695104

Epoch: 6| Step: 3
Training loss: 0.3197333514690399
Validation loss: 1.5964935530898392

Epoch: 6| Step: 4
Training loss: 0.28389325737953186
Validation loss: 1.6086902695317422

Epoch: 6| Step: 5
Training loss: 0.12474428117275238
Validation loss: 1.5536030838566441

Epoch: 6| Step: 6
Training loss: 0.19336086511611938
Validation loss: 1.6046872843978226

Epoch: 6| Step: 7
Training loss: 0.3153773546218872
Validation loss: 1.5790512984798801

Epoch: 6| Step: 8
Training loss: 0.2594861686229706
Validation loss: 1.5447066573686496

Epoch: 6| Step: 9
Training loss: 0.1195015236735344
Validation loss: 1.5855143429130636

Epoch: 6| Step: 10
Training loss: 0.17094005644321442
Validation loss: 1.5748851953014251

Epoch: 6| Step: 11
Training loss: 0.24972017109394073
Validation loss: 1.577212918189264

Epoch: 6| Step: 12
Training loss: 0.1556406021118164
Validation loss: 1.5627654111513527

Epoch: 6| Step: 13
Training loss: 0.1947622150182724
Validation loss: 1.5980962220058645

Epoch: 548| Step: 0
Training loss: 0.20227095484733582
Validation loss: 1.577834568997865

Epoch: 6| Step: 1
Training loss: 0.1917070746421814
Validation loss: 1.5956951431048814

Epoch: 6| Step: 2
Training loss: 0.2645983397960663
Validation loss: 1.5865213979956925

Epoch: 6| Step: 3
Training loss: 0.14343014359474182
Validation loss: 1.572710281418216

Epoch: 6| Step: 4
Training loss: 0.3113700747489929
Validation loss: 1.6104423358876219

Epoch: 6| Step: 5
Training loss: 0.3024343252182007
Validation loss: 1.5832814734469178

Epoch: 6| Step: 6
Training loss: 0.1605018675327301
Validation loss: 1.5949720810818415

Epoch: 6| Step: 7
Training loss: 0.2816043794155121
Validation loss: 1.6023884973218363

Epoch: 6| Step: 8
Training loss: 0.35250914096832275
Validation loss: 1.5952891624102028

Epoch: 6| Step: 9
Training loss: 0.20495600998401642
Validation loss: 1.6153437078640025

Epoch: 6| Step: 10
Training loss: 0.1393968164920807
Validation loss: 1.6000141738563456

Epoch: 6| Step: 11
Training loss: 0.14452111721038818
Validation loss: 1.6225049995606946

Epoch: 6| Step: 12
Training loss: 0.16843804717063904
Validation loss: 1.624401355302462

Epoch: 6| Step: 13
Training loss: 0.10144979506731033
Validation loss: 1.61148456476068

Epoch: 549| Step: 0
Training loss: 0.2878696918487549
Validation loss: 1.590502304415549

Epoch: 6| Step: 1
Training loss: 0.1608874350786209
Validation loss: 1.583292422756072

Epoch: 6| Step: 2
Training loss: 0.27220186591148376
Validation loss: 1.6176238623998498

Epoch: 6| Step: 3
Training loss: 0.13172250986099243
Validation loss: 1.587773787078037

Epoch: 6| Step: 4
Training loss: 0.1786106824874878
Validation loss: 1.5841968149267218

Epoch: 6| Step: 5
Training loss: 0.22236955165863037
Validation loss: 1.5361696648341354

Epoch: 6| Step: 6
Training loss: 0.23049284517765045
Validation loss: 1.5455885843564106

Epoch: 6| Step: 7
Training loss: 0.12644687294960022
Validation loss: 1.573504868374076

Epoch: 6| Step: 8
Training loss: 0.20653638243675232
Validation loss: 1.5689701239267986

Epoch: 6| Step: 9
Training loss: 0.28310245275497437
Validation loss: 1.566426484815536

Epoch: 6| Step: 10
Training loss: 0.2041892409324646
Validation loss: 1.5838516553243

Epoch: 6| Step: 11
Training loss: 0.22636473178863525
Validation loss: 1.5770443113901282

Epoch: 6| Step: 12
Training loss: 0.20665554702281952
Validation loss: 1.5795433162361063

Epoch: 6| Step: 13
Training loss: 0.0734928697347641
Validation loss: 1.6170379871963172

Epoch: 550| Step: 0
Training loss: 0.14794310927391052
Validation loss: 1.6020671084362974

Epoch: 6| Step: 1
Training loss: 0.19217449426651
Validation loss: 1.6061532208996434

Epoch: 6| Step: 2
Training loss: 0.15863582491874695
Validation loss: 1.6080891368209675

Epoch: 6| Step: 3
Training loss: 0.1403810828924179
Validation loss: 1.623534151302871

Epoch: 6| Step: 4
Training loss: 0.34773606061935425
Validation loss: 1.6189175049463909

Epoch: 6| Step: 5
Training loss: 0.3252759575843811
Validation loss: 1.5921777525255758

Epoch: 6| Step: 6
Training loss: 0.1375325620174408
Validation loss: 1.5971930642281809

Epoch: 6| Step: 7
Training loss: 0.19449195265769958
Validation loss: 1.5508422992562736

Epoch: 6| Step: 8
Training loss: 0.13453426957130432
Validation loss: 1.566671823942533

Epoch: 6| Step: 9
Training loss: 0.23697200417518616
Validation loss: 1.5737769232001355

Epoch: 6| Step: 10
Training loss: 0.1473228633403778
Validation loss: 1.563280641391713

Epoch: 6| Step: 11
Training loss: 0.38400715589523315
Validation loss: 1.541566724418312

Epoch: 6| Step: 12
Training loss: 0.1637374609708786
Validation loss: 1.5596437300405195

Epoch: 6| Step: 13
Training loss: 0.3105607032775879
Validation loss: 1.5111617234445387

Testing loss: 1.9017265637715657
