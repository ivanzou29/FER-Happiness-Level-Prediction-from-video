Epoch: 1| Step: 0
Training loss: 5.796308710863394
Validation loss: 5.761519009517358

Epoch: 6| Step: 1
Training loss: 5.836612034310872
Validation loss: 5.756328832457457

Epoch: 6| Step: 2
Training loss: 5.006249527568056
Validation loss: 5.751450932058805

Epoch: 6| Step: 3
Training loss: 6.8177990384014215
Validation loss: 5.746635986686675

Epoch: 6| Step: 4
Training loss: 5.706322680174461
Validation loss: 5.7425781295714105

Epoch: 6| Step: 5
Training loss: 6.736058283682815
Validation loss: 5.738321386873599

Epoch: 6| Step: 6
Training loss: 4.4486301156654795
Validation loss: 5.734840436990236

Epoch: 6| Step: 7
Training loss: 5.196770714351745
Validation loss: 5.731645953410511

Epoch: 6| Step: 8
Training loss: 6.3770075610234
Validation loss: 5.7282864780668605

Epoch: 6| Step: 9
Training loss: 5.608528434605839
Validation loss: 5.725034541489648

Epoch: 6| Step: 10
Training loss: 5.873187495718426
Validation loss: 5.7222121063030436

Epoch: 6| Step: 11
Training loss: 5.589399809306137
Validation loss: 5.7187772360532545

Epoch: 6| Step: 12
Training loss: 5.469990965506225
Validation loss: 5.715273059198477

Epoch: 6| Step: 13
Training loss: 5.979101023385669
Validation loss: 5.712012198686579

Epoch: 2| Step: 0
Training loss: 6.6892190310317385
Validation loss: 5.708307054047633

Epoch: 6| Step: 1
Training loss: 6.034436900899495
Validation loss: 5.704471181910787

Epoch: 6| Step: 2
Training loss: 5.706977107674389
Validation loss: 5.700669817166428

Epoch: 6| Step: 3
Training loss: 5.481557268949531
Validation loss: 5.69635987273783

Epoch: 6| Step: 4
Training loss: 6.042583667837169
Validation loss: 5.6923823053908364

Epoch: 6| Step: 5
Training loss: 6.650054770796241
Validation loss: 5.687806124935794

Epoch: 6| Step: 6
Training loss: 5.284553893866325
Validation loss: 5.683360390326138

Epoch: 6| Step: 7
Training loss: 5.194040793898019
Validation loss: 5.678358083190226

Epoch: 6| Step: 8
Training loss: 5.082232976335976
Validation loss: 5.672790603502658

Epoch: 6| Step: 9
Training loss: 5.039523885732962
Validation loss: 5.667543865739226

Epoch: 6| Step: 10
Training loss: 5.594360318267449
Validation loss: 5.662096755344199

Epoch: 6| Step: 11
Training loss: 5.111486529416396
Validation loss: 5.656598540142568

Epoch: 6| Step: 12
Training loss: 6.645820864802257
Validation loss: 5.650409561022902

Epoch: 6| Step: 13
Training loss: 4.471588513723011
Validation loss: 5.64360712974573

Epoch: 3| Step: 0
Training loss: 5.466015290011066
Validation loss: 5.637115276504121

Epoch: 6| Step: 1
Training loss: 5.733992145449125
Validation loss: 5.630470658245851

Epoch: 6| Step: 2
Training loss: 6.3552547669685255
Validation loss: 5.62344401907835

Epoch: 6| Step: 3
Training loss: 5.644238949503449
Validation loss: 5.616535418246966

Epoch: 6| Step: 4
Training loss: 6.287796480685387
Validation loss: 5.608211494812699

Epoch: 6| Step: 5
Training loss: 5.384425924971381
Validation loss: 5.600526270111504

Epoch: 6| Step: 6
Training loss: 5.038312042894638
Validation loss: 5.591840010846161

Epoch: 6| Step: 7
Training loss: 6.358274172419758
Validation loss: 5.5837721776920715

Epoch: 6| Step: 8
Training loss: 5.660793102759197
Validation loss: 5.575487674702031

Epoch: 6| Step: 9
Training loss: 4.391734353013785
Validation loss: 5.566404988076989

Epoch: 6| Step: 10
Training loss: 5.646447724230326
Validation loss: 5.5572724951570915

Epoch: 6| Step: 11
Training loss: 5.3577091753306165
Validation loss: 5.547985268398741

Epoch: 6| Step: 12
Training loss: 5.404280993042258
Validation loss: 5.538683988936458

Epoch: 6| Step: 13
Training loss: 5.868767537018693
Validation loss: 5.529060794007012

Epoch: 4| Step: 0
Training loss: 4.9998237578802
Validation loss: 5.518599730943967

Epoch: 6| Step: 1
Training loss: 5.896193566342386
Validation loss: 5.508284192704354

Epoch: 6| Step: 2
Training loss: 4.864502780201074
Validation loss: 5.498066587505128

Epoch: 6| Step: 3
Training loss: 5.795005805446294
Validation loss: 5.487485153503688

Epoch: 6| Step: 4
Training loss: 6.743924833193333
Validation loss: 5.475853523930305

Epoch: 6| Step: 5
Training loss: 5.144967607372101
Validation loss: 5.463750561230983

Epoch: 6| Step: 6
Training loss: 4.61939518491216
Validation loss: 5.452081557608011

Epoch: 6| Step: 7
Training loss: 5.662407153044163
Validation loss: 5.439120407534585

Epoch: 6| Step: 8
Training loss: 5.310242476162426
Validation loss: 5.427035530879204

Epoch: 6| Step: 9
Training loss: 6.310041194243257
Validation loss: 5.413270800540662

Epoch: 6| Step: 10
Training loss: 4.46896809932704
Validation loss: 5.3999581432961135

Epoch: 6| Step: 11
Training loss: 5.417660881156902
Validation loss: 5.384612382326548

Epoch: 6| Step: 12
Training loss: 6.2828039268391525
Validation loss: 5.37041035333451

Epoch: 6| Step: 13
Training loss: 4.173797735836375
Validation loss: 5.3548009774491865

Epoch: 5| Step: 0
Training loss: 5.378411563240909
Validation loss: 5.3379089271827755

Epoch: 6| Step: 1
Training loss: 5.734512369033282
Validation loss: 5.323237488105255

Epoch: 6| Step: 2
Training loss: 5.1660758060057965
Validation loss: 5.3063108890157675

Epoch: 6| Step: 3
Training loss: 5.794652301932616
Validation loss: 5.290281488327518

Epoch: 6| Step: 4
Training loss: 4.939700059009011
Validation loss: 5.272448593993215

Epoch: 6| Step: 5
Training loss: 5.43529878105661
Validation loss: 5.254507861124051

Epoch: 6| Step: 6
Training loss: 3.906227661068937
Validation loss: 5.23682400466785

Epoch: 6| Step: 7
Training loss: 4.934608675235551
Validation loss: 5.217840445429016

Epoch: 6| Step: 8
Training loss: 4.763116895716067
Validation loss: 5.199669411265634

Epoch: 6| Step: 9
Training loss: 5.260344169293388
Validation loss: 5.178555715122749

Epoch: 6| Step: 10
Training loss: 5.508094206836139
Validation loss: 5.15943447903167

Epoch: 6| Step: 11
Training loss: 5.504021128314518
Validation loss: 5.139310370782545

Epoch: 6| Step: 12
Training loss: 5.283057631430091
Validation loss: 5.117369304684732

Epoch: 6| Step: 13
Training loss: 6.471793670364312
Validation loss: 5.096029939384497

Epoch: 6| Step: 0
Training loss: 5.548313867625158
Validation loss: 5.0728229427209754

Epoch: 6| Step: 1
Training loss: 5.163387283296178
Validation loss: 5.050845524586301

Epoch: 6| Step: 2
Training loss: 5.579160108080488
Validation loss: 5.027982520699318

Epoch: 6| Step: 3
Training loss: 4.5182639466045496
Validation loss: 5.0061143119608715

Epoch: 6| Step: 4
Training loss: 5.171831851099272
Validation loss: 4.98249612008447

Epoch: 6| Step: 5
Training loss: 4.9565887373899695
Validation loss: 4.961277871328498

Epoch: 6| Step: 6
Training loss: 4.131936454587134
Validation loss: 4.942295456552205

Epoch: 6| Step: 7
Training loss: 5.410400208849792
Validation loss: 4.918914042829375

Epoch: 6| Step: 8
Training loss: 4.601852848238503
Validation loss: 4.900923361805268

Epoch: 6| Step: 9
Training loss: 4.931746982145215
Validation loss: 4.8797719027506465

Epoch: 6| Step: 10
Training loss: 4.769676012596319
Validation loss: 4.860331186680666

Epoch: 6| Step: 11
Training loss: 6.004016803227445
Validation loss: 4.844519734427112

Epoch: 6| Step: 12
Training loss: 4.298542822625968
Validation loss: 4.822657857420767

Epoch: 6| Step: 13
Training loss: 4.366305840607777
Validation loss: 4.804687838283834

Epoch: 7| Step: 0
Training loss: 4.365126449309003
Validation loss: 4.787731939541878

Epoch: 6| Step: 1
Training loss: 4.249030956418594
Validation loss: 4.76926227987063

Epoch: 6| Step: 2
Training loss: 5.918363229426671
Validation loss: 4.754428513263874

Epoch: 6| Step: 3
Training loss: 5.224407487337679
Validation loss: 4.738578311019598

Epoch: 6| Step: 4
Training loss: 6.228850629905788
Validation loss: 4.721307637397757

Epoch: 6| Step: 5
Training loss: 5.70631131560191
Validation loss: 4.70344314586597

Epoch: 6| Step: 6
Training loss: 5.64543796107431
Validation loss: 4.689184003115633

Epoch: 6| Step: 7
Training loss: 3.761421992083161
Validation loss: 4.673553309111387

Epoch: 6| Step: 8
Training loss: 4.727273480875449
Validation loss: 4.660522485054885

Epoch: 6| Step: 9
Training loss: 3.3119535175323525
Validation loss: 4.647000662463106

Epoch: 6| Step: 10
Training loss: 4.19798264873639
Validation loss: 4.633999831311992

Epoch: 6| Step: 11
Training loss: 3.9553226197577342
Validation loss: 4.621822515067625

Epoch: 6| Step: 12
Training loss: 3.826737132824808
Validation loss: 4.611689856962595

Epoch: 6| Step: 13
Training loss: 4.641933064147035
Validation loss: 4.600053705862303

Epoch: 8| Step: 0
Training loss: 4.8277591702524925
Validation loss: 4.590032315854585

Epoch: 6| Step: 1
Training loss: 5.4200863924918385
Validation loss: 4.580287623169082

Epoch: 6| Step: 2
Training loss: 4.720231587822337
Validation loss: 4.568672742420897

Epoch: 6| Step: 3
Training loss: 4.110452140942468
Validation loss: 4.559676774217666

Epoch: 6| Step: 4
Training loss: 4.961148186963157
Validation loss: 4.547845660518702

Epoch: 6| Step: 5
Training loss: 4.7967018319847465
Validation loss: 4.5376625205720815

Epoch: 6| Step: 6
Training loss: 4.138806904799358
Validation loss: 4.528699900300677

Epoch: 6| Step: 7
Training loss: 4.604777898247374
Validation loss: 4.517734079760177

Epoch: 6| Step: 8
Training loss: 4.987109543280525
Validation loss: 4.5089795250205285

Epoch: 6| Step: 9
Training loss: 3.9733012378172927
Validation loss: 4.496995693261687

Epoch: 6| Step: 10
Training loss: 4.015571564196387
Validation loss: 4.4900803655471995

Epoch: 6| Step: 11
Training loss: 3.527485419012764
Validation loss: 4.478639169907674

Epoch: 6| Step: 12
Training loss: 4.953796918763779
Validation loss: 4.47016890063637

Epoch: 6| Step: 13
Training loss: 5.811598513026457
Validation loss: 4.461087872238424

Epoch: 9| Step: 0
Training loss: 4.024517262576636
Validation loss: 4.454645081281781

Epoch: 6| Step: 1
Training loss: 4.847223820484169
Validation loss: 4.443892050241309

Epoch: 6| Step: 2
Training loss: 4.309731963423899
Validation loss: 4.438752052770388

Epoch: 6| Step: 3
Training loss: 4.398138276622618
Validation loss: 4.429018561774758

Epoch: 6| Step: 4
Training loss: 5.72819431260915
Validation loss: 4.419573355415348

Epoch: 6| Step: 5
Training loss: 5.358478971710049
Validation loss: 4.409966475799953

Epoch: 6| Step: 6
Training loss: 5.001575221838319
Validation loss: 4.404486490703625

Epoch: 6| Step: 7
Training loss: 4.232297718601781
Validation loss: 4.392251401410359

Epoch: 6| Step: 8
Training loss: 3.952554171514891
Validation loss: 4.38560532239679

Epoch: 6| Step: 9
Training loss: 3.5900800459074653
Validation loss: 4.378887597450723

Epoch: 6| Step: 10
Training loss: 4.946605543459867
Validation loss: 4.371025150232206

Epoch: 6| Step: 11
Training loss: 4.128052015908342
Validation loss: 4.365296738445144

Epoch: 6| Step: 12
Training loss: 3.645653391439276
Validation loss: 4.356187497013066

Epoch: 6| Step: 13
Training loss: 4.455975393258166
Validation loss: 4.347825795281085

Epoch: 10| Step: 0
Training loss: 4.373159402862169
Validation loss: 4.33957811787249

Epoch: 6| Step: 1
Training loss: 5.15677228652178
Validation loss: 4.332914669804226

Epoch: 6| Step: 2
Training loss: 4.098244798429743
Validation loss: 4.321651619478371

Epoch: 6| Step: 3
Training loss: 3.8540939461660795
Validation loss: 4.317787114571612

Epoch: 6| Step: 4
Training loss: 5.002418695996827
Validation loss: 4.306417244196453

Epoch: 6| Step: 5
Training loss: 5.338255974793359
Validation loss: 4.2999766191522735

Epoch: 6| Step: 6
Training loss: 2.9636052576805922
Validation loss: 4.291894845524693

Epoch: 6| Step: 7
Training loss: 4.914355149523133
Validation loss: 4.285359936180736

Epoch: 6| Step: 8
Training loss: 4.286930520187155
Validation loss: 4.284599496342047

Epoch: 6| Step: 9
Training loss: 4.209335786881778
Validation loss: 4.273645533502242

Epoch: 6| Step: 10
Training loss: 4.3048709338752795
Validation loss: 4.265899429409402

Epoch: 6| Step: 11
Training loss: 4.434029955138599
Validation loss: 4.262408208684177

Epoch: 6| Step: 12
Training loss: 4.084737860534287
Validation loss: 4.261321090679758

Epoch: 6| Step: 13
Training loss: 4.167481126656729
Validation loss: 4.257343828730953

Epoch: 11| Step: 0
Training loss: 4.554526900376688
Validation loss: 4.249177296951771

Epoch: 6| Step: 1
Training loss: 4.707731000243567
Validation loss: 4.243316081473991

Epoch: 6| Step: 2
Training loss: 4.743119727923592
Validation loss: 4.233231151343345

Epoch: 6| Step: 3
Training loss: 4.135434218720952
Validation loss: 4.230011924285244

Epoch: 6| Step: 4
Training loss: 4.831450566993191
Validation loss: 4.225053137376943

Epoch: 6| Step: 5
Training loss: 3.1882199241088847
Validation loss: 4.221486178487852

Epoch: 6| Step: 6
Training loss: 3.263467468398814
Validation loss: 4.212445805316852

Epoch: 6| Step: 7
Training loss: 4.747246596738381
Validation loss: 4.2101902275941585

Epoch: 6| Step: 8
Training loss: 4.855147212239259
Validation loss: 4.207379980707362

Epoch: 6| Step: 9
Training loss: 5.344049456498869
Validation loss: 4.201832291442746

Epoch: 6| Step: 10
Training loss: 3.86725001429112
Validation loss: 4.19667412649444

Epoch: 6| Step: 11
Training loss: 3.4910380201932862
Validation loss: 4.191886754201666

Epoch: 6| Step: 12
Training loss: 4.547524317361281
Validation loss: 4.186599240300575

Epoch: 6| Step: 13
Training loss: 3.5196791944835084
Validation loss: 4.1840053541352775

Epoch: 12| Step: 0
Training loss: 3.306970119114078
Validation loss: 4.17855605646559

Epoch: 6| Step: 1
Training loss: 5.113731090554519
Validation loss: 4.175923683195147

Epoch: 6| Step: 2
Training loss: 4.742640968524103
Validation loss: 4.172859759307208

Epoch: 6| Step: 3
Training loss: 3.2110628349550088
Validation loss: 4.1698056282350615

Epoch: 6| Step: 4
Training loss: 4.373411053532935
Validation loss: 4.16494641550507

Epoch: 6| Step: 5
Training loss: 4.684821622500002
Validation loss: 4.1595647095245925

Epoch: 6| Step: 6
Training loss: 3.889078468666995
Validation loss: 4.155632780625096

Epoch: 6| Step: 7
Training loss: 5.377003495950043
Validation loss: 4.151655356845081

Epoch: 6| Step: 8
Training loss: 4.015782453366785
Validation loss: 4.14555753146162

Epoch: 6| Step: 9
Training loss: 3.8354494363164324
Validation loss: 4.141509304860638

Epoch: 6| Step: 10
Training loss: 4.0795215539335965
Validation loss: 4.137026703714547

Epoch: 6| Step: 11
Training loss: 2.6619650898914933
Validation loss: 4.136554807611984

Epoch: 6| Step: 12
Training loss: 5.18908244436142
Validation loss: 4.131366908574866

Epoch: 6| Step: 13
Training loss: 4.843688373788917
Validation loss: 4.124783659103567

Epoch: 13| Step: 0
Training loss: 2.773614840143386
Validation loss: 4.122779054396117

Epoch: 6| Step: 1
Training loss: 4.414837632439134
Validation loss: 4.116444176602567

Epoch: 6| Step: 2
Training loss: 4.2203549193333965
Validation loss: 4.1171573204199525

Epoch: 6| Step: 3
Training loss: 4.800206124330451
Validation loss: 4.106664286253066

Epoch: 6| Step: 4
Training loss: 4.992516257575264
Validation loss: 4.100346674495222

Epoch: 6| Step: 5
Training loss: 3.74987106101572
Validation loss: 4.094891295522465

Epoch: 6| Step: 6
Training loss: 4.743185274588403
Validation loss: 4.087018000267713

Epoch: 6| Step: 7
Training loss: 3.9777333872169303
Validation loss: 4.08226778083344

Epoch: 6| Step: 8
Training loss: 3.7498457559017275
Validation loss: 4.07643306015734

Epoch: 6| Step: 9
Training loss: 4.200027629216461
Validation loss: 4.064358267149499

Epoch: 6| Step: 10
Training loss: 4.292723047307929
Validation loss: 4.0574119188100095

Epoch: 6| Step: 11
Training loss: 4.245058215924936
Validation loss: 4.05502978672278

Epoch: 6| Step: 12
Training loss: 4.642884600212315
Validation loss: 4.047264922556566

Epoch: 6| Step: 13
Training loss: 3.6348856599185004
Validation loss: 4.0446886960647435

Epoch: 14| Step: 0
Training loss: 4.157656324134925
Validation loss: 4.040610413998118

Epoch: 6| Step: 1
Training loss: 3.9056387461205055
Validation loss: 4.0342660216223365

Epoch: 6| Step: 2
Training loss: 5.024631482935503
Validation loss: 4.025808806171523

Epoch: 6| Step: 3
Training loss: 3.775267858033698
Validation loss: 4.023657862802003

Epoch: 6| Step: 4
Training loss: 3.9391666094448623
Validation loss: 4.020152323402189

Epoch: 6| Step: 5
Training loss: 4.332790242910739
Validation loss: 4.014010879095968

Epoch: 6| Step: 6
Training loss: 5.267282287414687
Validation loss: 4.008390278045357

Epoch: 6| Step: 7
Training loss: 3.928180140045322
Validation loss: 4.001823137995982

Epoch: 6| Step: 8
Training loss: 4.187351508852751
Validation loss: 3.9977082627202942

Epoch: 6| Step: 9
Training loss: 3.0416872903481753
Validation loss: 3.9895119039628644

Epoch: 6| Step: 10
Training loss: 4.525698714291425
Validation loss: 3.9911725097883592

Epoch: 6| Step: 11
Training loss: 3.2823317424942964
Validation loss: 3.986337325296478

Epoch: 6| Step: 12
Training loss: 4.851207873764292
Validation loss: 3.9804360370261254

Epoch: 6| Step: 13
Training loss: 2.5203785026218326
Validation loss: 3.973631536367496

Epoch: 15| Step: 0
Training loss: 4.521969888214856
Validation loss: 3.9717297945216017

Epoch: 6| Step: 1
Training loss: 4.318627468639848
Validation loss: 3.9677153086308676

Epoch: 6| Step: 2
Training loss: 3.4123699959944243
Validation loss: 3.960508419713854

Epoch: 6| Step: 3
Training loss: 3.949585306152555
Validation loss: 3.950900716854163

Epoch: 6| Step: 4
Training loss: 3.7148822577854315
Validation loss: 3.948083769100394

Epoch: 6| Step: 5
Training loss: 3.6260655908727744
Validation loss: 3.9423274722433557

Epoch: 6| Step: 6
Training loss: 4.940473216630979
Validation loss: 3.9395580392169345

Epoch: 6| Step: 7
Training loss: 3.5136197623289456
Validation loss: 3.9355759640991184

Epoch: 6| Step: 8
Training loss: 4.835379375734172
Validation loss: 3.929535139445079

Epoch: 6| Step: 9
Training loss: 3.8997025205180917
Validation loss: 3.9212010557131887

Epoch: 6| Step: 10
Training loss: 4.32066280331346
Validation loss: 3.9183658578589475

Epoch: 6| Step: 11
Training loss: 4.189036983994231
Validation loss: 3.9159389693438222

Epoch: 6| Step: 12
Training loss: 3.7647854830762326
Validation loss: 3.9105994547347467

Epoch: 6| Step: 13
Training loss: 3.8366034836680156
Validation loss: 3.9119729530068352

Epoch: 16| Step: 0
Training loss: 3.515094089686731
Validation loss: 3.9032276298988533

Epoch: 6| Step: 1
Training loss: 3.7564858614836893
Validation loss: 3.8978428067386366

Epoch: 6| Step: 2
Training loss: 3.9160290192258467
Validation loss: 3.8886881586549737

Epoch: 6| Step: 3
Training loss: 4.230251204514444
Validation loss: 3.8873167383781873

Epoch: 6| Step: 4
Training loss: 3.7594822843722495
Validation loss: 3.881366957081877

Epoch: 6| Step: 5
Training loss: 3.869812723601372
Validation loss: 3.878885996762704

Epoch: 6| Step: 6
Training loss: 3.8676948599867935
Validation loss: 3.8722105104857962

Epoch: 6| Step: 7
Training loss: 4.086631584659942
Validation loss: 3.8676705663722704

Epoch: 6| Step: 8
Training loss: 3.614065186284737
Validation loss: 3.8669761284233193

Epoch: 6| Step: 9
Training loss: 4.8287965375418915
Validation loss: 3.864241248098844

Epoch: 6| Step: 10
Training loss: 4.214092933734422
Validation loss: 3.854008132525386

Epoch: 6| Step: 11
Training loss: 4.333864228421401
Validation loss: 3.852605028514516

Epoch: 6| Step: 12
Training loss: 4.609723818236828
Validation loss: 3.8533447551064803

Epoch: 6| Step: 13
Training loss: 3.3912634182589656
Validation loss: 3.849031813358043

Epoch: 17| Step: 0
Training loss: 4.176942183978704
Validation loss: 3.848596655486811

Epoch: 6| Step: 1
Training loss: 4.336933963131273
Validation loss: 3.8449933281928663

Epoch: 6| Step: 2
Training loss: 4.220544504047378
Validation loss: 3.8374065094775087

Epoch: 6| Step: 3
Training loss: 4.078333823751325
Validation loss: 3.83087580251507

Epoch: 6| Step: 4
Training loss: 3.1105240275477937
Validation loss: 3.8282515229710405

Epoch: 6| Step: 5
Training loss: 2.9720161540849004
Validation loss: 3.822384765796413

Epoch: 6| Step: 6
Training loss: 4.557229956799458
Validation loss: 3.8165200682791673

Epoch: 6| Step: 7
Training loss: 4.2731279613244135
Validation loss: 3.8149906941078098

Epoch: 6| Step: 8
Training loss: 3.3292896220991923
Validation loss: 3.810151317942895

Epoch: 6| Step: 9
Training loss: 4.138069026115028
Validation loss: 3.8067794075196417

Epoch: 6| Step: 10
Training loss: 4.7019572788571
Validation loss: 3.8009936816702274

Epoch: 6| Step: 11
Training loss: 3.5136865315494763
Validation loss: 3.797562318587972

Epoch: 6| Step: 12
Training loss: 4.026895226145512
Validation loss: 3.7950829147642753

Epoch: 6| Step: 13
Training loss: 3.950292484705617
Validation loss: 3.7895275605682692

Epoch: 18| Step: 0
Training loss: 3.505665417249655
Validation loss: 3.7899758969545214

Epoch: 6| Step: 1
Training loss: 3.9986944452202584
Validation loss: 3.7828372141791093

Epoch: 6| Step: 2
Training loss: 3.8252155068716363
Validation loss: 3.780383318613657

Epoch: 6| Step: 3
Training loss: 4.3157550855694025
Validation loss: 3.776035099667393

Epoch: 6| Step: 4
Training loss: 3.7461955799507036
Validation loss: 3.7735476005489885

Epoch: 6| Step: 5
Training loss: 3.930918445766906
Validation loss: 3.7704599010096227

Epoch: 6| Step: 6
Training loss: 3.4815572113416042
Validation loss: 3.766850315669469

Epoch: 6| Step: 7
Training loss: 4.036903379783207
Validation loss: 3.765720929061836

Epoch: 6| Step: 8
Training loss: 4.869945938468262
Validation loss: 3.764633901327615

Epoch: 6| Step: 9
Training loss: 4.600629365408751
Validation loss: 3.7607441493882274

Epoch: 6| Step: 10
Training loss: 4.166957743332274
Validation loss: 3.7502529236739015

Epoch: 6| Step: 11
Training loss: 4.296608656518025
Validation loss: 3.750146333854153

Epoch: 6| Step: 12
Training loss: 2.816883062668953
Validation loss: 3.7458463026336877

Epoch: 6| Step: 13
Training loss: 2.2588632639874078
Validation loss: 3.743872073143112

Epoch: 19| Step: 0
Training loss: 3.649888462818504
Validation loss: 3.741070317400432

Epoch: 6| Step: 1
Training loss: 4.610335324353155
Validation loss: 3.7377354152276863

Epoch: 6| Step: 2
Training loss: 3.999810452738594
Validation loss: 3.732031428491637

Epoch: 6| Step: 3
Training loss: 3.6511742989052616
Validation loss: 3.72758523133343

Epoch: 6| Step: 4
Training loss: 3.8644786865104654
Validation loss: 3.7253219002367026

Epoch: 6| Step: 5
Training loss: 2.9788401142405236
Validation loss: 3.7266056760587616

Epoch: 6| Step: 6
Training loss: 4.024692139787634
Validation loss: 3.7195561246105693

Epoch: 6| Step: 7
Training loss: 4.164757074825562
Validation loss: 3.7201311265137242

Epoch: 6| Step: 8
Training loss: 4.2688074781086405
Validation loss: 3.7163253936145764

Epoch: 6| Step: 9
Training loss: 3.4722964740867215
Validation loss: 3.7113391952846633

Epoch: 6| Step: 10
Training loss: 3.197908349704593
Validation loss: 3.7108127664998416

Epoch: 6| Step: 11
Training loss: 3.451343197502004
Validation loss: 3.709997758770979

Epoch: 6| Step: 12
Training loss: 4.257478753404808
Validation loss: 3.7060288950480746

Epoch: 6| Step: 13
Training loss: 5.113804195231566
Validation loss: 3.7042050742036943

Epoch: 20| Step: 0
Training loss: 4.06041628878523
Validation loss: 3.700458921525515

Epoch: 6| Step: 1
Training loss: 4.025726556064038
Validation loss: 3.6967132764046937

Epoch: 6| Step: 2
Training loss: 3.5396687575718264
Validation loss: 3.691692615553853

Epoch: 6| Step: 3
Training loss: 3.7481949594573605
Validation loss: 3.692649450789709

Epoch: 6| Step: 4
Training loss: 4.096635340381243
Validation loss: 3.690339626257758

Epoch: 6| Step: 5
Training loss: 3.0917496813162195
Validation loss: 3.6849131394577093

Epoch: 6| Step: 6
Training loss: 4.484150419027974
Validation loss: 3.6820590181906048

Epoch: 6| Step: 7
Training loss: 3.7405951502731583
Validation loss: 3.6830468699259633

Epoch: 6| Step: 8
Training loss: 3.7813952709697647
Validation loss: 3.678183840986361

Epoch: 6| Step: 9
Training loss: 4.494323541067874
Validation loss: 3.671858267308538

Epoch: 6| Step: 10
Training loss: 3.324701258497063
Validation loss: 3.67241600168687

Epoch: 6| Step: 11
Training loss: 3.5986104190704205
Validation loss: 3.672901774689702

Epoch: 6| Step: 12
Training loss: 3.155535173201066
Validation loss: 3.6720652443486212

Epoch: 6| Step: 13
Training loss: 5.179688972944738
Validation loss: 3.6726004270337453

Epoch: 21| Step: 0
Training loss: 3.2137225248036994
Validation loss: 3.6719996919669584

Epoch: 6| Step: 1
Training loss: 4.467875361713074
Validation loss: 3.6642640208820567

Epoch: 6| Step: 2
Training loss: 3.1930365256332913
Validation loss: 3.661380912930697

Epoch: 6| Step: 3
Training loss: 3.7840674126489446
Validation loss: 3.656390337217972

Epoch: 6| Step: 4
Training loss: 3.822726308187277
Validation loss: 3.6500823015168073

Epoch: 6| Step: 5
Training loss: 4.096149702197479
Validation loss: 3.651140888055996

Epoch: 6| Step: 6
Training loss: 3.770229452825534
Validation loss: 3.6472585500571033

Epoch: 6| Step: 7
Training loss: 3.8043275384776654
Validation loss: 3.642969176624963

Epoch: 6| Step: 8
Training loss: 4.754495802019484
Validation loss: 3.641110864489322

Epoch: 6| Step: 9
Training loss: 3.1500815365850117
Validation loss: 3.6402571677759465

Epoch: 6| Step: 10
Training loss: 3.2171257883890507
Validation loss: 3.646469470427004

Epoch: 6| Step: 11
Training loss: 3.905252558200937
Validation loss: 3.6485969375288483

Epoch: 6| Step: 12
Training loss: 4.136080569281253
Validation loss: 3.6409309262543177

Epoch: 6| Step: 13
Training loss: 4.169461927575659
Validation loss: 3.6375977648820146

Epoch: 22| Step: 0
Training loss: 3.458879879579848
Validation loss: 3.631033028747328

Epoch: 6| Step: 1
Training loss: 3.513899587448245
Validation loss: 3.63004416034224

Epoch: 6| Step: 2
Training loss: 4.104854751972357
Validation loss: 3.630785218541937

Epoch: 6| Step: 3
Training loss: 3.3393448663401837
Validation loss: 3.6267634265579005

Epoch: 6| Step: 4
Training loss: 4.444846076831966
Validation loss: 3.6227584077907946

Epoch: 6| Step: 5
Training loss: 3.621410302540393
Validation loss: 3.622277998457602

Epoch: 6| Step: 6
Training loss: 4.666183832712653
Validation loss: 3.6199926715224375

Epoch: 6| Step: 7
Training loss: 3.9117700255339676
Validation loss: 3.6174872301724172

Epoch: 6| Step: 8
Training loss: 3.0713168532625814
Validation loss: 3.612952304313003

Epoch: 6| Step: 9
Training loss: 3.8258640385512255
Validation loss: 3.6161727614147785

Epoch: 6| Step: 10
Training loss: 4.045402347278598
Validation loss: 3.608469889674075

Epoch: 6| Step: 11
Training loss: 3.6868356655859533
Validation loss: 3.6114876107283838

Epoch: 6| Step: 12
Training loss: 4.017528987986462
Validation loss: 3.603212726218326

Epoch: 6| Step: 13
Training loss: 2.951316158420776
Validation loss: 3.597215984380937

Epoch: 23| Step: 0
Training loss: 4.19664119657181
Validation loss: 3.596688182399648

Epoch: 6| Step: 1
Training loss: 3.9310683749746183
Validation loss: 3.5943663294649495

Epoch: 6| Step: 2
Training loss: 4.264063287261745
Validation loss: 3.5943210199871287

Epoch: 6| Step: 3
Training loss: 3.5010859303436686
Validation loss: 3.591054406743423

Epoch: 6| Step: 4
Training loss: 3.2595283508799904
Validation loss: 3.593615066684543

Epoch: 6| Step: 5
Training loss: 4.096347363420461
Validation loss: 3.5938763767901047

Epoch: 6| Step: 6
Training loss: 2.9736591106185237
Validation loss: 3.5877156090543267

Epoch: 6| Step: 7
Training loss: 3.4764722490918945
Validation loss: 3.5939136683649284

Epoch: 6| Step: 8
Training loss: 3.634415861311705
Validation loss: 3.6031724088449053

Epoch: 6| Step: 9
Training loss: 4.056444320373693
Validation loss: 3.579998370848685

Epoch: 6| Step: 10
Training loss: 3.705435245498367
Validation loss: 3.579800433610982

Epoch: 6| Step: 11
Training loss: 4.196068040381581
Validation loss: 3.580633453193686

Epoch: 6| Step: 12
Training loss: 4.392632185152552
Validation loss: 3.581374829144815

Epoch: 6| Step: 13
Training loss: 2.0173658792946765
Validation loss: 3.580836679524443

Epoch: 24| Step: 0
Training loss: 2.7734768716945717
Validation loss: 3.576514647305398

Epoch: 6| Step: 1
Training loss: 3.5165675277355364
Validation loss: 3.574567544649426

Epoch: 6| Step: 2
Training loss: 3.3691360960114487
Validation loss: 3.5744944838561366

Epoch: 6| Step: 3
Training loss: 3.7909907203103903
Validation loss: 3.570009008775214

Epoch: 6| Step: 4
Training loss: 4.065891669380614
Validation loss: 3.562594159387194

Epoch: 6| Step: 5
Training loss: 3.4555545045034015
Validation loss: 3.5630659406945995

Epoch: 6| Step: 6
Training loss: 3.794644426617979
Validation loss: 3.5580213193579064

Epoch: 6| Step: 7
Training loss: 4.097701400639001
Validation loss: 3.561319447393917

Epoch: 6| Step: 8
Training loss: 3.2264145639417645
Validation loss: 3.5672722116595255

Epoch: 6| Step: 9
Training loss: 4.373135414607257
Validation loss: 3.5540873691084838

Epoch: 6| Step: 10
Training loss: 3.2431192185340643
Validation loss: 3.550711136528475

Epoch: 6| Step: 11
Training loss: 4.705887600951915
Validation loss: 3.5520019223606076

Epoch: 6| Step: 12
Training loss: 3.6879716991737137
Validation loss: 3.5495025513859684

Epoch: 6| Step: 13
Training loss: 4.395623996083082
Validation loss: 3.54984565866152

Epoch: 25| Step: 0
Training loss: 3.504270536778529
Validation loss: 3.551163968184975

Epoch: 6| Step: 1
Training loss: 3.9475538477930336
Validation loss: 3.5527402632224345

Epoch: 6| Step: 2
Training loss: 4.31714015607523
Validation loss: 3.545366141298532

Epoch: 6| Step: 3
Training loss: 3.7523533112727576
Validation loss: 3.540934196072419

Epoch: 6| Step: 4
Training loss: 3.2641192163312374
Validation loss: 3.535717164744436

Epoch: 6| Step: 5
Training loss: 3.0005003194047566
Validation loss: 3.534705606111758

Epoch: 6| Step: 6
Training loss: 3.2249323165060257
Validation loss: 3.5368022322279287

Epoch: 6| Step: 7
Training loss: 4.449295485373174
Validation loss: 3.5344387448758887

Epoch: 6| Step: 8
Training loss: 3.8913805124641363
Validation loss: 3.5318908429347076

Epoch: 6| Step: 9
Training loss: 4.2454207939007835
Validation loss: 3.5390539696424526

Epoch: 6| Step: 10
Training loss: 3.8508490778002606
Validation loss: 3.5415474110937377

Epoch: 6| Step: 11
Training loss: 3.3509890903897515
Validation loss: 3.5318151354465703

Epoch: 6| Step: 12
Training loss: 4.013063556395041
Validation loss: 3.5368559176166334

Epoch: 6| Step: 13
Training loss: 2.8533196039255744
Validation loss: 3.5330228269372315

Epoch: 26| Step: 0
Training loss: 3.858565766904441
Validation loss: 3.5336572353715345

Epoch: 6| Step: 1
Training loss: 3.490707732529034
Validation loss: 3.530863858490204

Epoch: 6| Step: 2
Training loss: 4.268831382411346
Validation loss: 3.5252184926762316

Epoch: 6| Step: 3
Training loss: 3.3499309418805416
Validation loss: 3.5211586105068005

Epoch: 6| Step: 4
Training loss: 4.4911356615035904
Validation loss: 3.5166668593941175

Epoch: 6| Step: 5
Training loss: 3.108015366996176
Validation loss: 3.516220836394884

Epoch: 6| Step: 6
Training loss: 4.1575797112233195
Validation loss: 3.5149667402079148

Epoch: 6| Step: 7
Training loss: 4.228460143256108
Validation loss: 3.515475576636664

Epoch: 6| Step: 8
Training loss: 4.042873451473457
Validation loss: 3.5157287917773163

Epoch: 6| Step: 9
Training loss: 2.9555315172879846
Validation loss: 3.512236255419875

Epoch: 6| Step: 10
Training loss: 3.5299672185224007
Validation loss: 3.50824933525251

Epoch: 6| Step: 11
Training loss: 3.2702732133032
Validation loss: 3.5061689578515396

Epoch: 6| Step: 12
Training loss: 3.3766800266414547
Validation loss: 3.506604746954941

Epoch: 6| Step: 13
Training loss: 3.5724180594698005
Validation loss: 3.5009949291084608

Epoch: 27| Step: 0
Training loss: 4.025322392980672
Validation loss: 3.5004982095634802

Epoch: 6| Step: 1
Training loss: 4.2437698476155905
Validation loss: 3.5006139849562703

Epoch: 6| Step: 2
Training loss: 4.009170510361507
Validation loss: 3.4976494436134984

Epoch: 6| Step: 3
Training loss: 3.386355757922352
Validation loss: 3.498210839356397

Epoch: 6| Step: 4
Training loss: 2.860568771893182
Validation loss: 3.49288670399298

Epoch: 6| Step: 5
Training loss: 2.1685834133578807
Validation loss: 3.4933712105160226

Epoch: 6| Step: 6
Training loss: 3.466624115413778
Validation loss: 3.490402914943581

Epoch: 6| Step: 7
Training loss: 3.27144458348002
Validation loss: 3.4943330743034533

Epoch: 6| Step: 8
Training loss: 4.147223515874807
Validation loss: 3.489658546035144

Epoch: 6| Step: 9
Training loss: 3.962446358013786
Validation loss: 3.490234009209922

Epoch: 6| Step: 10
Training loss: 3.6065715785251498
Validation loss: 3.4870398243808056

Epoch: 6| Step: 11
Training loss: 3.8403856393767097
Validation loss: 3.484169175745749

Epoch: 6| Step: 12
Training loss: 4.162963493133949
Validation loss: 3.4826860447804

Epoch: 6| Step: 13
Training loss: 4.4239199597256045
Validation loss: 3.4835905839011114

Epoch: 28| Step: 0
Training loss: 4.038309938428881
Validation loss: 3.4830098100001154

Epoch: 6| Step: 1
Training loss: 3.4943035635744613
Validation loss: 3.480889832707643

Epoch: 6| Step: 2
Training loss: 4.007186632570531
Validation loss: 3.4777407441595165

Epoch: 6| Step: 3
Training loss: 3.870654222651272
Validation loss: 3.4763552574559373

Epoch: 6| Step: 4
Training loss: 3.683569025177162
Validation loss: 3.477816413967853

Epoch: 6| Step: 5
Training loss: 3.572757342968912
Validation loss: 3.4773662409111736

Epoch: 6| Step: 6
Training loss: 3.0893489475220606
Validation loss: 3.4725916707094027

Epoch: 6| Step: 7
Training loss: 3.408563230886321
Validation loss: 3.4736178304855096

Epoch: 6| Step: 8
Training loss: 3.854091595442694
Validation loss: 3.469476985975557

Epoch: 6| Step: 9
Training loss: 3.876683146495565
Validation loss: 3.46985107140109

Epoch: 6| Step: 10
Training loss: 4.193554728434575
Validation loss: 3.4694413140422764

Epoch: 6| Step: 11
Training loss: 3.8564137824347298
Validation loss: 3.467590427928456

Epoch: 6| Step: 12
Training loss: 3.100019787140731
Validation loss: 3.4664985277168254

Epoch: 6| Step: 13
Training loss: 3.1384711780011685
Validation loss: 3.4633657700220417

Epoch: 29| Step: 0
Training loss: 3.750230654934435
Validation loss: 3.4644363129913716

Epoch: 6| Step: 1
Training loss: 3.8247911533361116
Validation loss: 3.467409748012122

Epoch: 6| Step: 2
Training loss: 3.5813289773431203
Validation loss: 3.4652420911683692

Epoch: 6| Step: 3
Training loss: 3.554128212998393
Validation loss: 3.4698080562745393

Epoch: 6| Step: 4
Training loss: 3.027983173399197
Validation loss: 3.4579610232527864

Epoch: 6| Step: 5
Training loss: 3.7001716006926966
Validation loss: 3.456178881900346

Epoch: 6| Step: 6
Training loss: 4.093385170557617
Validation loss: 3.4553452711497563

Epoch: 6| Step: 7
Training loss: 3.5225697736686166
Validation loss: 3.4548571853394154

Epoch: 6| Step: 8
Training loss: 3.1381827960288584
Validation loss: 3.4520442876792763

Epoch: 6| Step: 9
Training loss: 4.541051117132804
Validation loss: 3.451975931060617

Epoch: 6| Step: 10
Training loss: 3.5558201588745035
Validation loss: 3.4504307121198834

Epoch: 6| Step: 11
Training loss: 4.121515825542262
Validation loss: 3.44843885760531

Epoch: 6| Step: 12
Training loss: 2.817930023629492
Validation loss: 3.446715786190111

Epoch: 6| Step: 13
Training loss: 3.9604302858415816
Validation loss: 3.4460158184681338

Epoch: 30| Step: 0
Training loss: 3.5409391366532157
Validation loss: 3.447883899992652

Epoch: 6| Step: 1
Training loss: 4.125971130728673
Validation loss: 3.4454517903252717

Epoch: 6| Step: 2
Training loss: 3.1074979857900877
Validation loss: 3.444273132369202

Epoch: 6| Step: 3
Training loss: 4.3584079558558955
Validation loss: 3.4422085416165586

Epoch: 6| Step: 4
Training loss: 3.3176508748315436
Validation loss: 3.4432587773305943

Epoch: 6| Step: 5
Training loss: 2.271284099484538
Validation loss: 3.4419799444203694

Epoch: 6| Step: 6
Training loss: 4.481417541351357
Validation loss: 3.442669165087505

Epoch: 6| Step: 7
Training loss: 3.408042506064813
Validation loss: 3.4441583637895024

Epoch: 6| Step: 8
Training loss: 2.784841297634218
Validation loss: 3.450719743019398

Epoch: 6| Step: 9
Training loss: 3.9158637799815743
Validation loss: 3.4466525409512405

Epoch: 6| Step: 10
Training loss: 3.974298758401627
Validation loss: 3.4408925860719113

Epoch: 6| Step: 11
Training loss: 3.654084436469368
Validation loss: 3.4327349199719066

Epoch: 6| Step: 12
Training loss: 3.601916512986985
Validation loss: 3.43321590362145

Epoch: 6| Step: 13
Training loss: 4.300385639729375
Validation loss: 3.435279319815191

Epoch: 31| Step: 0
Training loss: 3.78024909273516
Validation loss: 3.4366682521143685

Epoch: 6| Step: 1
Training loss: 3.344823932204978
Validation loss: 3.43736680444911

Epoch: 6| Step: 2
Training loss: 3.8874414126774326
Validation loss: 3.4348647650558704

Epoch: 6| Step: 3
Training loss: 4.190889495535995
Validation loss: 3.4347154871195653

Epoch: 6| Step: 4
Training loss: 3.650776997259052
Validation loss: 3.4287594851935963

Epoch: 6| Step: 5
Training loss: 3.9051502358113974
Validation loss: 3.4277448008650757

Epoch: 6| Step: 6
Training loss: 3.9192987620561515
Validation loss: 3.426736736278674

Epoch: 6| Step: 7
Training loss: 3.3978226028666887
Validation loss: 3.4243757604361997

Epoch: 6| Step: 8
Training loss: 2.565450040215945
Validation loss: 3.421601516089554

Epoch: 6| Step: 9
Training loss: 3.3707737776340543
Validation loss: 3.4215837078296194

Epoch: 6| Step: 10
Training loss: 3.889002572774588
Validation loss: 3.4262361072398497

Epoch: 6| Step: 11
Training loss: 2.857718232666484
Validation loss: 3.431553932101691

Epoch: 6| Step: 12
Training loss: 3.4045285415831223
Validation loss: 3.4406643947003754

Epoch: 6| Step: 13
Training loss: 5.103324270474995
Validation loss: 3.443193446386911

Epoch: 32| Step: 0
Training loss: 4.327092567449912
Validation loss: 3.4203272078049505

Epoch: 6| Step: 1
Training loss: 3.721442265821384
Validation loss: 3.41849762943282

Epoch: 6| Step: 2
Training loss: 3.538585234875308
Validation loss: 3.419273996829269

Epoch: 6| Step: 3
Training loss: 2.6984625500972483
Validation loss: 3.4213977135668725

Epoch: 6| Step: 4
Training loss: 3.5555048746894484
Validation loss: 3.4204749356390205

Epoch: 6| Step: 5
Training loss: 3.350146583652424
Validation loss: 3.420955471291369

Epoch: 6| Step: 6
Training loss: 3.80489253249522
Validation loss: 3.4184805504396456

Epoch: 6| Step: 7
Training loss: 3.000988797312759
Validation loss: 3.415651089939287

Epoch: 6| Step: 8
Training loss: 4.278566285049982
Validation loss: 3.4144281987570557

Epoch: 6| Step: 9
Training loss: 3.031504512209069
Validation loss: 3.4139531347702152

Epoch: 6| Step: 10
Training loss: 3.2204437243930255
Validation loss: 3.4104494668566696

Epoch: 6| Step: 11
Training loss: 4.357580109394438
Validation loss: 3.408981197663853

Epoch: 6| Step: 12
Training loss: 4.056942939054256
Validation loss: 3.406987359087261

Epoch: 6| Step: 13
Training loss: 3.4805712272722182
Validation loss: 3.4051213475131576

Epoch: 33| Step: 0
Training loss: 2.5029740763109336
Validation loss: 3.407553247455212

Epoch: 6| Step: 1
Training loss: 3.9288671407006555
Validation loss: 3.4070688772204423

Epoch: 6| Step: 2
Training loss: 3.4689484960450034
Validation loss: 3.405266896782598

Epoch: 6| Step: 3
Training loss: 3.0768448544609543
Validation loss: 3.4077157867640837

Epoch: 6| Step: 4
Training loss: 4.511428731208922
Validation loss: 3.4086514245675805

Epoch: 6| Step: 5
Training loss: 3.1822959454513398
Validation loss: 3.4078261593621284

Epoch: 6| Step: 6
Training loss: 3.675761791343952
Validation loss: 3.4087392940773

Epoch: 6| Step: 7
Training loss: 3.5110863443968534
Validation loss: 3.39818428858605

Epoch: 6| Step: 8
Training loss: 4.040719671829338
Validation loss: 3.3950761249907235

Epoch: 6| Step: 9
Training loss: 3.5517317671577344
Validation loss: 3.396699053821379

Epoch: 6| Step: 10
Training loss: 4.0782278932182585
Validation loss: 3.3946557513697577

Epoch: 6| Step: 11
Training loss: 4.069144112386909
Validation loss: 3.3947377755631942

Epoch: 6| Step: 12
Training loss: 3.605532099042265
Validation loss: 3.39427421547614

Epoch: 6| Step: 13
Training loss: 2.6304928666616103
Validation loss: 3.391808626226944

Epoch: 34| Step: 0
Training loss: 3.2616411211289864
Validation loss: 3.391748605003292

Epoch: 6| Step: 1
Training loss: 3.087726315995353
Validation loss: 3.3934403536524025

Epoch: 6| Step: 2
Training loss: 4.045369343157506
Validation loss: 3.391077862653548

Epoch: 6| Step: 3
Training loss: 3.8253412829963924
Validation loss: 3.388733864711621

Epoch: 6| Step: 4
Training loss: 2.7064228557682655
Validation loss: 3.385229389068542

Epoch: 6| Step: 5
Training loss: 4.358331370793929
Validation loss: 3.38337059014627

Epoch: 6| Step: 6
Training loss: 3.4782766852330256
Validation loss: 3.381983515267173

Epoch: 6| Step: 7
Training loss: 3.1142919567840526
Validation loss: 3.3823395335218076

Epoch: 6| Step: 8
Training loss: 3.3805325690095454
Validation loss: 3.3810353734509553

Epoch: 6| Step: 9
Training loss: 4.105814388399966
Validation loss: 3.3827115394122225

Epoch: 6| Step: 10
Training loss: 3.3787256093332085
Validation loss: 3.3886019994185306

Epoch: 6| Step: 11
Training loss: 4.317148108618472
Validation loss: 3.3939217379048094

Epoch: 6| Step: 12
Training loss: 3.4186840769323936
Validation loss: 3.3880374812160845

Epoch: 6| Step: 13
Training loss: 3.803429115442254
Validation loss: 3.3834867857144335

Epoch: 35| Step: 0
Training loss: 2.808860458422621
Validation loss: 3.377343749878549

Epoch: 6| Step: 1
Training loss: 3.7238159294733033
Validation loss: 3.3776788019795996

Epoch: 6| Step: 2
Training loss: 3.1156920093917653
Validation loss: 3.378977589325672

Epoch: 6| Step: 3
Training loss: 3.7499699909281046
Validation loss: 3.377126589642777

Epoch: 6| Step: 4
Training loss: 2.847248649991414
Validation loss: 3.3759773188399036

Epoch: 6| Step: 5
Training loss: 3.7481411459369727
Validation loss: 3.375766799971432

Epoch: 6| Step: 6
Training loss: 3.9894616064453805
Validation loss: 3.3759567290202463

Epoch: 6| Step: 7
Training loss: 3.554276193151307
Validation loss: 3.3761535490116965

Epoch: 6| Step: 8
Training loss: 3.1575864474075073
Validation loss: 3.373276785975998

Epoch: 6| Step: 9
Training loss: 3.9063146967298596
Validation loss: 3.3715203006479926

Epoch: 6| Step: 10
Training loss: 3.8867642653977548
Validation loss: 3.3709428496535128

Epoch: 6| Step: 11
Training loss: 4.160016640483146
Validation loss: 3.3720831897113714

Epoch: 6| Step: 12
Training loss: 4.2330815778550015
Validation loss: 3.3699362004690885

Epoch: 6| Step: 13
Training loss: 2.870774356437408
Validation loss: 3.3708226882237353

Epoch: 36| Step: 0
Training loss: 2.755512002076058
Validation loss: 3.3683083766686885

Epoch: 6| Step: 1
Training loss: 4.2723938610806025
Validation loss: 3.3705640054436823

Epoch: 6| Step: 2
Training loss: 4.2190920090679995
Validation loss: 3.3712510100179105

Epoch: 6| Step: 3
Training loss: 4.48105320199083
Validation loss: 3.3716457475245205

Epoch: 6| Step: 4
Training loss: 3.153266932276969
Validation loss: 3.3701056195491295

Epoch: 6| Step: 5
Training loss: 3.779386707588686
Validation loss: 3.3706624191649297

Epoch: 6| Step: 6
Training loss: 3.5340991383902494
Validation loss: 3.3669843646455666

Epoch: 6| Step: 7
Training loss: 3.074025478855587
Validation loss: 3.3645647046466123

Epoch: 6| Step: 8
Training loss: 2.9393778541027102
Validation loss: 3.3637576095593693

Epoch: 6| Step: 9
Training loss: 3.1753759747267067
Validation loss: 3.3626395410086714

Epoch: 6| Step: 10
Training loss: 3.3398418939596453
Validation loss: 3.3614986223637326

Epoch: 6| Step: 11
Training loss: 3.9400115707150105
Validation loss: 3.3617528125262677

Epoch: 6| Step: 12
Training loss: 3.822582233709522
Validation loss: 3.360443379567494

Epoch: 6| Step: 13
Training loss: 3.2075554701542126
Validation loss: 3.359654287951654

Epoch: 37| Step: 0
Training loss: 3.8093414981110523
Validation loss: 3.3588469380029298

Epoch: 6| Step: 1
Training loss: 3.573892814074952
Validation loss: 3.3590244759955574

Epoch: 6| Step: 2
Training loss: 4.836926582515848
Validation loss: 3.3577681807880464

Epoch: 6| Step: 3
Training loss: 3.6594198457102096
Validation loss: 3.3591570001960687

Epoch: 6| Step: 4
Training loss: 3.9627005060050866
Validation loss: 3.3564937765552956

Epoch: 6| Step: 5
Training loss: 3.18020813074912
Validation loss: 3.355509841726357

Epoch: 6| Step: 6
Training loss: 3.789594789850842
Validation loss: 3.3607415264708216

Epoch: 6| Step: 7
Training loss: 2.2792343222591573
Validation loss: 3.3562720484668267

Epoch: 6| Step: 8
Training loss: 3.1045868011101643
Validation loss: 3.3532737958026226

Epoch: 6| Step: 9
Training loss: 3.082439052353608
Validation loss: 3.353657477394844

Epoch: 6| Step: 10
Training loss: 3.848318099207495
Validation loss: 3.3556466134070404

Epoch: 6| Step: 11
Training loss: 3.432287251880143
Validation loss: 3.353639309872137

Epoch: 6| Step: 12
Training loss: 3.5618262741416133
Validation loss: 3.354663570291633

Epoch: 6| Step: 13
Training loss: 3.5564691459296687
Validation loss: 3.354994873712455

Epoch: 38| Step: 0
Training loss: 4.12589716547128
Validation loss: 3.353417836448074

Epoch: 6| Step: 1
Training loss: 3.5483966537805545
Validation loss: 3.352135315947598

Epoch: 6| Step: 2
Training loss: 3.9564437505396284
Validation loss: 3.3519577633544775

Epoch: 6| Step: 3
Training loss: 3.513788582865811
Validation loss: 3.3508532578480055

Epoch: 6| Step: 4
Training loss: 3.7413278121834996
Validation loss: 3.350183277874438

Epoch: 6| Step: 5
Training loss: 3.646826443516453
Validation loss: 3.3522121905894418

Epoch: 6| Step: 6
Training loss: 3.492449381522246
Validation loss: 3.3494544405828544

Epoch: 6| Step: 7
Training loss: 3.7763508987963292
Validation loss: 3.3487072947850365

Epoch: 6| Step: 8
Training loss: 3.8790449134958425
Validation loss: 3.34985794699215

Epoch: 6| Step: 9
Training loss: 3.170521414440961
Validation loss: 3.3514303662335303

Epoch: 6| Step: 10
Training loss: 3.6456448896844202
Validation loss: 3.349129341260688

Epoch: 6| Step: 11
Training loss: 3.6293377409307253
Validation loss: 3.3474620876171697

Epoch: 6| Step: 12
Training loss: 2.2543881329269446
Validation loss: 3.3485461180559857

Epoch: 6| Step: 13
Training loss: 3.3648659476209426
Validation loss: 3.3481004758400594

Epoch: 39| Step: 0
Training loss: 2.7584347117561068
Validation loss: 3.3476465871010017

Epoch: 6| Step: 1
Training loss: 3.884258530605367
Validation loss: 3.3498744452525533

Epoch: 6| Step: 2
Training loss: 4.033385664755392
Validation loss: 3.3485500065266143

Epoch: 6| Step: 3
Training loss: 4.106001597051593
Validation loss: 3.3502346806368077

Epoch: 6| Step: 4
Training loss: 3.499340131408441
Validation loss: 3.348490076569745

Epoch: 6| Step: 5
Training loss: 3.48022514886494
Validation loss: 3.34594481869169

Epoch: 6| Step: 6
Training loss: 3.749058160126713
Validation loss: 3.348185484309629

Epoch: 6| Step: 7
Training loss: 3.066627990091765
Validation loss: 3.3549859823242154

Epoch: 6| Step: 8
Training loss: 3.2697088815434237
Validation loss: 3.3514476576407017

Epoch: 6| Step: 9
Training loss: 3.9634804171601394
Validation loss: 3.342935558975329

Epoch: 6| Step: 10
Training loss: 3.863973372341995
Validation loss: 3.342019957737694

Epoch: 6| Step: 11
Training loss: 3.388645420465902
Validation loss: 3.3420403746267593

Epoch: 6| Step: 12
Training loss: 3.3208510018281117
Validation loss: 3.3429939428062707

Epoch: 6| Step: 13
Training loss: 3.4056912585117316
Validation loss: 3.342512642231531

Epoch: 40| Step: 0
Training loss: 3.6212586135946165
Validation loss: 3.3428852970820273

Epoch: 6| Step: 1
Training loss: 3.2709820626495043
Validation loss: 3.342956033156444

Epoch: 6| Step: 2
Training loss: 3.7935040112956018
Validation loss: 3.3428311293447743

Epoch: 6| Step: 3
Training loss: 3.6620739581620723
Validation loss: 3.3411371531825464

Epoch: 6| Step: 4
Training loss: 4.047989975204419
Validation loss: 3.3412211618132326

Epoch: 6| Step: 5
Training loss: 3.377426405527715
Validation loss: 3.3394889604238167

Epoch: 6| Step: 6
Training loss: 3.769698349801816
Validation loss: 3.3370834779535703

Epoch: 6| Step: 7
Training loss: 3.610757142023245
Validation loss: 3.337459384495484

Epoch: 6| Step: 8
Training loss: 3.4554051944719015
Validation loss: 3.3376460376297885

Epoch: 6| Step: 9
Training loss: 3.5869261598370055
Validation loss: 3.3375165060717547

Epoch: 6| Step: 10
Training loss: 4.3883678566955515
Validation loss: 3.334629754765918

Epoch: 6| Step: 11
Training loss: 2.9584694593747662
Validation loss: 3.3358348940069913

Epoch: 6| Step: 12
Training loss: 3.007551226476918
Validation loss: 3.3341204565033875

Epoch: 6| Step: 13
Training loss: 2.9992840230426503
Validation loss: 3.335032408951123

Epoch: 41| Step: 0
Training loss: 3.800087907677808
Validation loss: 3.3365882061573724

Epoch: 6| Step: 1
Training loss: 3.50711344866705
Validation loss: 3.3360481486892204

Epoch: 6| Step: 2
Training loss: 3.68814753649804
Validation loss: 3.3374991355748316

Epoch: 6| Step: 3
Training loss: 3.5091555600672617
Validation loss: 3.3340404934532306

Epoch: 6| Step: 4
Training loss: 3.92627715209783
Validation loss: 3.3344099603133333

Epoch: 6| Step: 5
Training loss: 3.674061096040588
Validation loss: 3.331718101674666

Epoch: 6| Step: 6
Training loss: 2.437183653036917
Validation loss: 3.333434891435458

Epoch: 6| Step: 7
Training loss: 3.2485254317103243
Validation loss: 3.3348593715469907

Epoch: 6| Step: 8
Training loss: 3.0049021723052003
Validation loss: 3.334525644704963

Epoch: 6| Step: 9
Training loss: 4.059395410781539
Validation loss: 3.3334887704191547

Epoch: 6| Step: 10
Training loss: 4.295228066833956
Validation loss: 3.333183096504602

Epoch: 6| Step: 11
Training loss: 3.6804881267648892
Validation loss: 3.3336672989889893

Epoch: 6| Step: 12
Training loss: 3.5851132311955176
Validation loss: 3.3285904749044355

Epoch: 6| Step: 13
Training loss: 2.9131816933956163
Validation loss: 3.327877875317779

Epoch: 42| Step: 0
Training loss: 3.3784684619749776
Validation loss: 3.3273323606098875

Epoch: 6| Step: 1
Training loss: 3.7198609047183013
Validation loss: 3.3266813914140227

Epoch: 6| Step: 2
Training loss: 3.3071464606821306
Validation loss: 3.3260312605990854

Epoch: 6| Step: 3
Training loss: 3.444676623842459
Validation loss: 3.3263735628710887

Epoch: 6| Step: 4
Training loss: 3.735810454859651
Validation loss: 3.3272135320918355

Epoch: 6| Step: 5
Training loss: 3.5082401278355597
Validation loss: 3.326356858647826

Epoch: 6| Step: 6
Training loss: 4.100443950901222
Validation loss: 3.324654301928499

Epoch: 6| Step: 7
Training loss: 4.0367049340834305
Validation loss: 3.323563801690219

Epoch: 6| Step: 8
Training loss: 3.962192193720601
Validation loss: 3.3228854787631223

Epoch: 6| Step: 9
Training loss: 3.9231618768460823
Validation loss: 3.3216695688796856

Epoch: 6| Step: 10
Training loss: 4.177341037832835
Validation loss: 3.322953943431864

Epoch: 6| Step: 11
Training loss: 2.053507534952321
Validation loss: 3.3220143586770594

Epoch: 6| Step: 12
Training loss: 2.5455457342831513
Validation loss: 3.3205567034506878

Epoch: 6| Step: 13
Training loss: 3.2138522022307128
Validation loss: 3.3206189124580785

Epoch: 43| Step: 0
Training loss: 3.6806509777311196
Validation loss: 3.3209878376338184

Epoch: 6| Step: 1
Training loss: 2.489384812190366
Validation loss: 3.3230988300231448

Epoch: 6| Step: 2
Training loss: 3.5371312141270854
Validation loss: 3.3228306223793433

Epoch: 6| Step: 3
Training loss: 3.4453515290625245
Validation loss: 3.3306886261494477

Epoch: 6| Step: 4
Training loss: 2.986433188247514
Validation loss: 3.32096484575889

Epoch: 6| Step: 5
Training loss: 3.3629567059495886
Validation loss: 3.3167161955041347

Epoch: 6| Step: 6
Training loss: 3.0309581812758597
Validation loss: 3.3185916301183704

Epoch: 6| Step: 7
Training loss: 3.393583492458685
Validation loss: 3.316683906324449

Epoch: 6| Step: 8
Training loss: 3.940613257612238
Validation loss: 3.316708697924961

Epoch: 6| Step: 9
Training loss: 4.216413741134257
Validation loss: 3.3166693423128417

Epoch: 6| Step: 10
Training loss: 3.793628701999933
Validation loss: 3.315033310603882

Epoch: 6| Step: 11
Training loss: 3.4511428598631744
Validation loss: 3.314239713782102

Epoch: 6| Step: 12
Training loss: 4.266486559483794
Validation loss: 3.313395175876237

Epoch: 6| Step: 13
Training loss: 3.9588008136095882
Validation loss: 3.31183526428923

Epoch: 44| Step: 0
Training loss: 3.9121895761405896
Validation loss: 3.311464071475762

Epoch: 6| Step: 1
Training loss: 2.9450204233908894
Validation loss: 3.311265115846915

Epoch: 6| Step: 2
Training loss: 2.9157055679098045
Validation loss: 3.310715502515491

Epoch: 6| Step: 3
Training loss: 3.0938751503648176
Validation loss: 3.308090181518585

Epoch: 6| Step: 4
Training loss: 4.518168963673421
Validation loss: 3.3091672545644295

Epoch: 6| Step: 5
Training loss: 4.754635606796589
Validation loss: 3.3104004508865006

Epoch: 6| Step: 6
Training loss: 2.7840338501187762
Validation loss: 3.3071827126480726

Epoch: 6| Step: 7
Training loss: 4.059900948955779
Validation loss: 3.3075035460782227

Epoch: 6| Step: 8
Training loss: 3.4557965331229683
Validation loss: 3.3085666055894323

Epoch: 6| Step: 9
Training loss: 3.7335762223069557
Validation loss: 3.3064594369250995

Epoch: 6| Step: 10
Training loss: 3.201753648420018
Validation loss: 3.306971683514539

Epoch: 6| Step: 11
Training loss: 2.830338428602199
Validation loss: 3.3071436436692925

Epoch: 6| Step: 12
Training loss: 2.630771105899048
Validation loss: 3.3060843108381834

Epoch: 6| Step: 13
Training loss: 4.355245404867686
Validation loss: 3.305052285129182

Epoch: 45| Step: 0
Training loss: 3.267023106675743
Validation loss: 3.3040587310630323

Epoch: 6| Step: 1
Training loss: 4.098382323661183
Validation loss: 3.305329997062087

Epoch: 6| Step: 2
Training loss: 4.155746544196314
Validation loss: 3.3064782885644157

Epoch: 6| Step: 3
Training loss: 3.2414154236489705
Validation loss: 3.3059475235110347

Epoch: 6| Step: 4
Training loss: 3.331177077649318
Validation loss: 3.302826428470272

Epoch: 6| Step: 5
Training loss: 3.5306732246831665
Validation loss: 3.301926685449153

Epoch: 6| Step: 6
Training loss: 3.267244220462036
Validation loss: 3.3011887068472516

Epoch: 6| Step: 7
Training loss: 3.986398459846188
Validation loss: 3.3011817968217203

Epoch: 6| Step: 8
Training loss: 2.6293166861880843
Validation loss: 3.2998012263784786

Epoch: 6| Step: 9
Training loss: 3.4652627822731596
Validation loss: 3.30032849086111

Epoch: 6| Step: 10
Training loss: 4.20905280179297
Validation loss: 3.297962806490889

Epoch: 6| Step: 11
Training loss: 3.665279617363717
Validation loss: 3.296634430655282

Epoch: 6| Step: 12
Training loss: 3.2370308554530762
Validation loss: 3.2996804903986616

Epoch: 6| Step: 13
Training loss: 2.8010790891312074
Validation loss: 3.2965476635567317

Epoch: 46| Step: 0
Training loss: 3.473983802682982
Validation loss: 3.2954483137349238

Epoch: 6| Step: 1
Training loss: 3.62210480402828
Validation loss: 3.296454705272994

Epoch: 6| Step: 2
Training loss: 3.2243085844531567
Validation loss: 3.2946705907783507

Epoch: 6| Step: 3
Training loss: 3.2732058786827274
Validation loss: 3.2941842275909496

Epoch: 6| Step: 4
Training loss: 3.0592857152985222
Validation loss: 3.294439571283654

Epoch: 6| Step: 5
Training loss: 4.3027713893522535
Validation loss: 3.2927674155686666

Epoch: 6| Step: 6
Training loss: 2.7603632124037754
Validation loss: 3.293151715701844

Epoch: 6| Step: 7
Training loss: 4.180212939738551
Validation loss: 3.2920175154845537

Epoch: 6| Step: 8
Training loss: 3.2370072862544887
Validation loss: 3.291071287438885

Epoch: 6| Step: 9
Training loss: 3.5302739777834993
Validation loss: 3.2908331497319425

Epoch: 6| Step: 10
Training loss: 3.6653618369309573
Validation loss: 3.2903601323875677

Epoch: 6| Step: 11
Training loss: 3.5917400544377296
Validation loss: 3.2907227849959586

Epoch: 6| Step: 12
Training loss: 3.388426177602158
Validation loss: 3.289207908333799

Epoch: 6| Step: 13
Training loss: 4.158028129023772
Validation loss: 3.2909780747564623

Epoch: 47| Step: 0
Training loss: 4.058804988412225
Validation loss: 3.2892400151813614

Epoch: 6| Step: 1
Training loss: 3.2154415867938724
Validation loss: 3.2869309679207914

Epoch: 6| Step: 2
Training loss: 3.2344317592487273
Validation loss: 3.286489630304206

Epoch: 6| Step: 3
Training loss: 2.9126758702433158
Validation loss: 3.2883649700265303

Epoch: 6| Step: 4
Training loss: 3.4629002639283506
Validation loss: 3.2891145820479983

Epoch: 6| Step: 5
Training loss: 3.287337405749261
Validation loss: 3.289579238696301

Epoch: 6| Step: 6
Training loss: 3.1577854765009903
Validation loss: 3.2905262089947347

Epoch: 6| Step: 7
Training loss: 3.7967715151149513
Validation loss: 3.2886632740789885

Epoch: 6| Step: 8
Training loss: 3.7936990901038636
Validation loss: 3.2980273857672393

Epoch: 6| Step: 9
Training loss: 4.066454796405101
Validation loss: 3.2917091719433818

Epoch: 6| Step: 10
Training loss: 3.0748806813978953
Validation loss: 3.284859904796925

Epoch: 6| Step: 11
Training loss: 4.3074386307146675
Validation loss: 3.2845987446776697

Epoch: 6| Step: 12
Training loss: 3.3093582224938416
Validation loss: 3.285843382197131

Epoch: 6| Step: 13
Training loss: 3.396468510736024
Validation loss: 3.284807603881142

Epoch: 48| Step: 0
Training loss: 4.064913458284179
Validation loss: 3.283072980614401

Epoch: 6| Step: 1
Training loss: 3.412562549283309
Validation loss: 3.2812685917622053

Epoch: 6| Step: 2
Training loss: 3.7668927223316535
Validation loss: 3.282080538674661

Epoch: 6| Step: 3
Training loss: 3.256911924010491
Validation loss: 3.28076024148218

Epoch: 6| Step: 4
Training loss: 4.570229867041444
Validation loss: 3.2777425979507067

Epoch: 6| Step: 5
Training loss: 3.155444353976936
Validation loss: 3.2782691115489833

Epoch: 6| Step: 6
Training loss: 3.936255485407283
Validation loss: 3.277720884217874

Epoch: 6| Step: 7
Training loss: 3.088960272911737
Validation loss: 3.2756777153186896

Epoch: 6| Step: 8
Training loss: 3.6427742176608326
Validation loss: 3.2747122274548848

Epoch: 6| Step: 9
Training loss: 3.516507728805738
Validation loss: 3.2742561524485727

Epoch: 6| Step: 10
Training loss: 2.8878358323626596
Validation loss: 3.27293838869016

Epoch: 6| Step: 11
Training loss: 2.9419627277495013
Validation loss: 3.27056524900993

Epoch: 6| Step: 12
Training loss: 3.1523401196540433
Validation loss: 3.2682129405256655

Epoch: 6| Step: 13
Training loss: 3.5698017447850394
Validation loss: 3.2665502783219957

Epoch: 49| Step: 0
Training loss: 4.137268779090797
Validation loss: 3.26662193593768

Epoch: 6| Step: 1
Training loss: 3.7155169369421013
Validation loss: 3.2651614302537326

Epoch: 6| Step: 2
Training loss: 3.1881617438856176
Validation loss: 3.266835407549442

Epoch: 6| Step: 3
Training loss: 3.4932874615644693
Validation loss: 3.2666533450000883

Epoch: 6| Step: 4
Training loss: 3.7026391334329625
Validation loss: 3.268272769004527

Epoch: 6| Step: 5
Training loss: 2.553695252700398
Validation loss: 3.263869363037947

Epoch: 6| Step: 6
Training loss: 4.135133722396364
Validation loss: 3.2694926594888587

Epoch: 6| Step: 7
Training loss: 3.443414351207825
Validation loss: 3.260779368126717

Epoch: 6| Step: 8
Training loss: 3.271617009904593
Validation loss: 3.261411933598869

Epoch: 6| Step: 9
Training loss: 3.364603205918399
Validation loss: 3.2603326465786675

Epoch: 6| Step: 10
Training loss: 3.8948478608295845
Validation loss: 3.260140329289076

Epoch: 6| Step: 11
Training loss: 3.477497240911468
Validation loss: 3.2592256355923293

Epoch: 6| Step: 12
Training loss: 3.32653885416825
Validation loss: 3.259191340538141

Epoch: 6| Step: 13
Training loss: 2.855059760114608
Validation loss: 3.263208877834202

Epoch: 50| Step: 0
Training loss: 3.3275316452711254
Validation loss: 3.2620713318782086

Epoch: 6| Step: 1
Training loss: 3.620400635062619
Validation loss: 3.261373839705617

Epoch: 6| Step: 2
Training loss: 3.5737240308236347
Validation loss: 3.2624761440756624

Epoch: 6| Step: 3
Training loss: 3.5608418939334148
Validation loss: 3.261991124173963

Epoch: 6| Step: 4
Training loss: 3.8523173801476553
Validation loss: 3.2584107347122986

Epoch: 6| Step: 5
Training loss: 3.2001668528926017
Validation loss: 3.2593675645114537

Epoch: 6| Step: 6
Training loss: 3.299141199897384
Validation loss: 3.2567123940417497

Epoch: 6| Step: 7
Training loss: 3.088549626272065
Validation loss: 3.2545770530984526

Epoch: 6| Step: 8
Training loss: 3.535681989998452
Validation loss: 3.253180459795013

Epoch: 6| Step: 9
Training loss: 4.112957571250907
Validation loss: 3.2542991505859655

Epoch: 6| Step: 10
Training loss: 3.152968409783203
Validation loss: 3.2535002501592984

Epoch: 6| Step: 11
Training loss: 3.32153943897855
Validation loss: 3.252954695458905

Epoch: 6| Step: 12
Training loss: 3.3163708796148277
Validation loss: 3.252451706303644

Epoch: 6| Step: 13
Training loss: 4.253089679288265
Validation loss: 3.251211122144581

Epoch: 51| Step: 0
Training loss: 3.3190614026197753
Validation loss: 3.2499904474665473

Epoch: 6| Step: 1
Training loss: 4.150364659845251
Validation loss: 3.250564676014457

Epoch: 6| Step: 2
Training loss: 3.2663469748512064
Validation loss: 3.2467305198175516

Epoch: 6| Step: 3
Training loss: 3.9755169706235467
Validation loss: 3.250029441504516

Epoch: 6| Step: 4
Training loss: 3.512744316754024
Validation loss: 3.2509326700885044

Epoch: 6| Step: 5
Training loss: 4.590529993578981
Validation loss: 3.24634094548836

Epoch: 6| Step: 6
Training loss: 3.1877405412455984
Validation loss: 3.2461398275317004

Epoch: 6| Step: 7
Training loss: 2.8009601785919958
Validation loss: 3.244518165726642

Epoch: 6| Step: 8
Training loss: 3.2667535173457485
Validation loss: 3.242900138980952

Epoch: 6| Step: 9
Training loss: 4.082476285922806
Validation loss: 3.242997389691308

Epoch: 6| Step: 10
Training loss: 3.235134754233857
Validation loss: 3.243574269452253

Epoch: 6| Step: 11
Training loss: 2.955611216786626
Validation loss: 3.2400295674453465

Epoch: 6| Step: 12
Training loss: 2.46873261650822
Validation loss: 3.241063679551249

Epoch: 6| Step: 13
Training loss: 3.5524000248542493
Validation loss: 3.2390315526291333

Epoch: 52| Step: 0
Training loss: 3.5019563929153743
Validation loss: 3.239342548047892

Epoch: 6| Step: 1
Training loss: 3.650514326045787
Validation loss: 3.237816905553908

Epoch: 6| Step: 2
Training loss: 3.3340464464967283
Validation loss: 3.240133264103329

Epoch: 6| Step: 3
Training loss: 3.583410232665086
Validation loss: 3.2379348581295995

Epoch: 6| Step: 4
Training loss: 2.9872103498813867
Validation loss: 3.2377329947249676

Epoch: 6| Step: 5
Training loss: 3.407735798010604
Validation loss: 3.240539454530939

Epoch: 6| Step: 6
Training loss: 2.802344658635856
Validation loss: 3.2377406546000134

Epoch: 6| Step: 7
Training loss: 4.289147436972059
Validation loss: 3.2402743156011904

Epoch: 6| Step: 8
Training loss: 3.539078668216379
Validation loss: 3.2393410158822222

Epoch: 6| Step: 9
Training loss: 3.2095945942457624
Validation loss: 3.2378249437006543

Epoch: 6| Step: 10
Training loss: 3.8493968144322217
Validation loss: 3.2389598117532565

Epoch: 6| Step: 11
Training loss: 3.174765486579346
Validation loss: 3.241682438430191

Epoch: 6| Step: 12
Training loss: 3.5451852411637166
Validation loss: 3.2411595663752255

Epoch: 6| Step: 13
Training loss: 3.92674919076242
Validation loss: 3.233579842541602

Epoch: 53| Step: 0
Training loss: 4.0553112101576705
Validation loss: 3.236306287077281

Epoch: 6| Step: 1
Training loss: 2.9524693644304576
Validation loss: 3.2377668392954666

Epoch: 6| Step: 2
Training loss: 3.7915134329101985
Validation loss: 3.2403412440014097

Epoch: 6| Step: 3
Training loss: 2.2301145897064205
Validation loss: 3.2356685306619837

Epoch: 6| Step: 4
Training loss: 2.9860341518056206
Validation loss: 3.236630988993732

Epoch: 6| Step: 5
Training loss: 3.285642753438459
Validation loss: 3.237526682784404

Epoch: 6| Step: 6
Training loss: 3.2686797096178424
Validation loss: 3.2371975820410053

Epoch: 6| Step: 7
Training loss: 3.5933090602878264
Validation loss: 3.2369275955905903

Epoch: 6| Step: 8
Training loss: 3.5339380346628766
Validation loss: 3.246019089805448

Epoch: 6| Step: 9
Training loss: 3.7863834308979865
Validation loss: 3.2442602030712457

Epoch: 6| Step: 10
Training loss: 3.993036646406579
Validation loss: 3.2378971657757387

Epoch: 6| Step: 11
Training loss: 3.558968114998939
Validation loss: 3.2318812624918847

Epoch: 6| Step: 12
Training loss: 3.8508175019136437
Validation loss: 3.2295891291257024

Epoch: 6| Step: 13
Training loss: 3.5236850152547627
Validation loss: 3.235313030224053

Epoch: 54| Step: 0
Training loss: 3.567487738627673
Validation loss: 3.2317240744374516

Epoch: 6| Step: 1
Training loss: 3.4708482049727976
Validation loss: 3.233743889887777

Epoch: 6| Step: 2
Training loss: 3.8522887870226716
Validation loss: 3.2341953025748422

Epoch: 6| Step: 3
Training loss: 3.712953297077583
Validation loss: 3.2332263183094887

Epoch: 6| Step: 4
Training loss: 3.4056191516419263
Validation loss: 3.234887390306918

Epoch: 6| Step: 5
Training loss: 3.3889313436326014
Validation loss: 3.231475026187104

Epoch: 6| Step: 6
Training loss: 3.55949556248674
Validation loss: 3.2327399345426495

Epoch: 6| Step: 7
Training loss: 3.373881825899401
Validation loss: 3.2266574305265983

Epoch: 6| Step: 8
Training loss: 3.055544369609664
Validation loss: 3.2323791978932985

Epoch: 6| Step: 9
Training loss: 3.334747602528683
Validation loss: 3.2292257660146

Epoch: 6| Step: 10
Training loss: 3.735696088073971
Validation loss: 3.229806889088212

Epoch: 6| Step: 11
Training loss: 3.5419917836279753
Validation loss: 3.231733430289991

Epoch: 6| Step: 12
Training loss: 3.4497222014550553
Validation loss: 3.2301243378489723

Epoch: 6| Step: 13
Training loss: 3.0854644799160678
Validation loss: 3.231541212613589

Epoch: 55| Step: 0
Training loss: 4.09743188583801
Validation loss: 3.2290172694509502

Epoch: 6| Step: 1
Training loss: 3.5671435426534273
Validation loss: 3.231334083272224

Epoch: 6| Step: 2
Training loss: 4.103017320113381
Validation loss: 3.2285954780341988

Epoch: 6| Step: 3
Training loss: 2.7656447415266894
Validation loss: 3.2295592567900226

Epoch: 6| Step: 4
Training loss: 3.263086381737415
Validation loss: 3.2271035824837653

Epoch: 6| Step: 5
Training loss: 3.8658925980727896
Validation loss: 3.2291281727942014

Epoch: 6| Step: 6
Training loss: 2.5118616991908245
Validation loss: 3.231427682810466

Epoch: 6| Step: 7
Training loss: 3.9228772102488056
Validation loss: 3.2264882602844556

Epoch: 6| Step: 8
Training loss: 2.7141980178548053
Validation loss: 3.2243277494333724

Epoch: 6| Step: 9
Training loss: 4.461512540241091
Validation loss: 3.2249655275059705

Epoch: 6| Step: 10
Training loss: 2.3064334786061687
Validation loss: 3.2248639108482626

Epoch: 6| Step: 11
Training loss: 3.6895151612703994
Validation loss: 3.223427185541866

Epoch: 6| Step: 12
Training loss: 3.469492927241699
Validation loss: 3.2226359518188135

Epoch: 6| Step: 13
Training loss: 2.9035696159361155
Validation loss: 3.2258411465081376

Epoch: 56| Step: 0
Training loss: 4.013093023952533
Validation loss: 3.2316863889731846

Epoch: 6| Step: 1
Training loss: 3.2367089737531125
Validation loss: 3.221381361021712

Epoch: 6| Step: 2
Training loss: 4.142824445322976
Validation loss: 3.2218857617704417

Epoch: 6| Step: 3
Training loss: 2.9938101489688433
Validation loss: 3.224235911696002

Epoch: 6| Step: 4
Training loss: 3.6384427975730134
Validation loss: 3.223744893535224

Epoch: 6| Step: 5
Training loss: 3.380328598978619
Validation loss: 3.2230186746352607

Epoch: 6| Step: 6
Training loss: 3.257975988150876
Validation loss: 3.224424780336038

Epoch: 6| Step: 7
Training loss: 4.044478601677085
Validation loss: 3.224775565636143

Epoch: 6| Step: 8
Training loss: 3.6055950502238505
Validation loss: 3.2214548812440382

Epoch: 6| Step: 9
Training loss: 2.887944643869104
Validation loss: 3.22376856923887

Epoch: 6| Step: 10
Training loss: 2.5915368991103875
Validation loss: 3.2222686429075167

Epoch: 6| Step: 11
Training loss: 4.17991817230003
Validation loss: 3.2249283688116437

Epoch: 6| Step: 12
Training loss: 3.1036499071209174
Validation loss: 3.229018196770807

Epoch: 6| Step: 13
Training loss: 2.87275873810071
Validation loss: 3.2285695619851147

Epoch: 57| Step: 0
Training loss: 3.541580079460087
Validation loss: 3.2323819039923207

Epoch: 6| Step: 1
Training loss: 2.795379068126805
Validation loss: 3.2374291600417724

Epoch: 6| Step: 2
Training loss: 3.965344266822106
Validation loss: 3.2321382508256926

Epoch: 6| Step: 3
Training loss: 3.2135820102889903
Validation loss: 3.2314296138143614

Epoch: 6| Step: 4
Training loss: 3.914825791420718
Validation loss: 3.2203471029293467

Epoch: 6| Step: 5
Training loss: 3.4430250675242817
Validation loss: 3.220965035752725

Epoch: 6| Step: 6
Training loss: 2.874523123291989
Validation loss: 3.2226972453175122

Epoch: 6| Step: 7
Training loss: 3.159806768569443
Validation loss: 3.221248622625647

Epoch: 6| Step: 8
Training loss: 4.35762519310787
Validation loss: 3.214911743684252

Epoch: 6| Step: 9
Training loss: 4.013177147885762
Validation loss: 3.2188560714471826

Epoch: 6| Step: 10
Training loss: 2.5284932513155423
Validation loss: 3.2195333604216234

Epoch: 6| Step: 11
Training loss: 3.741995087775835
Validation loss: 3.216978264691861

Epoch: 6| Step: 12
Training loss: 3.762885652465766
Validation loss: 3.215923440966296

Epoch: 6| Step: 13
Training loss: 1.921029936299551
Validation loss: 3.215174016172513

Epoch: 58| Step: 0
Training loss: 3.456648603911432
Validation loss: 3.2177412947664035

Epoch: 6| Step: 1
Training loss: 3.2779493897623344
Validation loss: 3.216203404771883

Epoch: 6| Step: 2
Training loss: 3.635434883895453
Validation loss: 3.2177659691074383

Epoch: 6| Step: 3
Training loss: 3.9849400736707534
Validation loss: 3.2186925325202678

Epoch: 6| Step: 4
Training loss: 2.437997229307758
Validation loss: 3.2166937506269417

Epoch: 6| Step: 5
Training loss: 3.307791332236607
Validation loss: 3.222283672573776

Epoch: 6| Step: 6
Training loss: 3.8100095024891494
Validation loss: 3.2216476473998523

Epoch: 6| Step: 7
Training loss: 2.746269470062482
Validation loss: 3.218838466786921

Epoch: 6| Step: 8
Training loss: 3.305767198584957
Validation loss: 3.216939289204485

Epoch: 6| Step: 9
Training loss: 3.5471936053385758
Validation loss: 3.216883355351401

Epoch: 6| Step: 10
Training loss: 4.162101126223642
Validation loss: 3.2205857265886455

Epoch: 6| Step: 11
Training loss: 3.058052414579008
Validation loss: 3.218038559783126

Epoch: 6| Step: 12
Training loss: 3.523601249053176
Validation loss: 3.222944526693271

Epoch: 6| Step: 13
Training loss: 4.1984256155046715
Validation loss: 3.2190205434152652

Epoch: 59| Step: 0
Training loss: 3.672982556117568
Validation loss: 3.221360136424768

Epoch: 6| Step: 1
Training loss: 4.229349342246943
Validation loss: 3.2312294417462946

Epoch: 6| Step: 2
Training loss: 3.5812221932122226
Validation loss: 3.2305978853693986

Epoch: 6| Step: 3
Training loss: 3.373107238123385
Validation loss: 3.240520247774573

Epoch: 6| Step: 4
Training loss: 3.312547359487876
Validation loss: 3.2210353699175966

Epoch: 6| Step: 5
Training loss: 3.7293342822604107
Validation loss: 3.2164461608505355

Epoch: 6| Step: 6
Training loss: 2.6247265082893207
Validation loss: 3.2120321537794396

Epoch: 6| Step: 7
Training loss: 3.5464470558963486
Validation loss: 3.213877153710353

Epoch: 6| Step: 8
Training loss: 2.9321799293671584
Validation loss: 3.2142600676201423

Epoch: 6| Step: 9
Training loss: 4.420292979062808
Validation loss: 3.2200785880796805

Epoch: 6| Step: 10
Training loss: 3.65429074211972
Validation loss: 3.2175999645899784

Epoch: 6| Step: 11
Training loss: 2.9222496730867245
Validation loss: 3.216447413002275

Epoch: 6| Step: 12
Training loss: 3.2351465456756467
Validation loss: 3.216577204533975

Epoch: 6| Step: 13
Training loss: 2.234612832382969
Validation loss: 3.216599260882446

Epoch: 60| Step: 0
Training loss: 3.3353516825902507
Validation loss: 3.215806106427337

Epoch: 6| Step: 1
Training loss: 2.474158049435983
Validation loss: 3.216127717497396

Epoch: 6| Step: 2
Training loss: 3.7938539393356585
Validation loss: 3.2182978627014083

Epoch: 6| Step: 3
Training loss: 3.3857933108791713
Validation loss: 3.21804304968226

Epoch: 6| Step: 4
Training loss: 3.912830638625621
Validation loss: 3.2185855309337033

Epoch: 6| Step: 5
Training loss: 2.6217622316682068
Validation loss: 3.225695153131407

Epoch: 6| Step: 6
Training loss: 3.384831555005613
Validation loss: 3.229731695232951

Epoch: 6| Step: 7
Training loss: 2.7325380967286153
Validation loss: 3.220473100169583

Epoch: 6| Step: 8
Training loss: 4.03031993457398
Validation loss: 3.2185971536096427

Epoch: 6| Step: 9
Training loss: 3.426144797022743
Validation loss: 3.2240095677026317

Epoch: 6| Step: 10
Training loss: 4.108751837181932
Validation loss: 3.216535984563958

Epoch: 6| Step: 11
Training loss: 3.6601249831908915
Validation loss: 3.2167137962058345

Epoch: 6| Step: 12
Training loss: 3.768790026906081
Validation loss: 3.2148376814862036

Epoch: 6| Step: 13
Training loss: 3.325202052351833
Validation loss: 3.2164518612853197

Epoch: 61| Step: 0
Training loss: 3.1291668386920692
Validation loss: 3.2177893844598477

Epoch: 6| Step: 1
Training loss: 4.225574991499863
Validation loss: 3.221801862523809

Epoch: 6| Step: 2
Training loss: 3.6571980086919376
Validation loss: 3.2205810356576934

Epoch: 6| Step: 3
Training loss: 3.356956853612599
Validation loss: 3.2162949553615126

Epoch: 6| Step: 4
Training loss: 2.525411961252192
Validation loss: 3.2162052492642808

Epoch: 6| Step: 5
Training loss: 3.527254122485689
Validation loss: 3.214800668886125

Epoch: 6| Step: 6
Training loss: 4.1747979486422215
Validation loss: 3.214613042722617

Epoch: 6| Step: 7
Training loss: 3.117485166023405
Validation loss: 3.2126648079316213

Epoch: 6| Step: 8
Training loss: 2.9782114342618407
Validation loss: 3.2117971338399847

Epoch: 6| Step: 9
Training loss: 3.012493345641072
Validation loss: 3.2142178352989927

Epoch: 6| Step: 10
Training loss: 3.455938237565549
Validation loss: 3.2142536693993344

Epoch: 6| Step: 11
Training loss: 4.603302864528168
Validation loss: 3.212658930009297

Epoch: 6| Step: 12
Training loss: 2.834424500627219
Validation loss: 3.210704008045663

Epoch: 6| Step: 13
Training loss: 3.178558674108593
Validation loss: 3.214638307292599

Epoch: 62| Step: 0
Training loss: 3.644695053426377
Validation loss: 3.209977752268037

Epoch: 6| Step: 1
Training loss: 3.5262953846798837
Validation loss: 3.2097763318466446

Epoch: 6| Step: 2
Training loss: 3.741931882661353
Validation loss: 3.2100365944775837

Epoch: 6| Step: 3
Training loss: 2.814417376215103
Validation loss: 3.2109865714243853

Epoch: 6| Step: 4
Training loss: 3.4885549064165535
Validation loss: 3.2079307347233117

Epoch: 6| Step: 5
Training loss: 2.3396820369109976
Validation loss: 3.205637600095838

Epoch: 6| Step: 6
Training loss: 3.500721584595668
Validation loss: 3.2047191751641972

Epoch: 6| Step: 7
Training loss: 3.818391843691878
Validation loss: 3.204729772989818

Epoch: 6| Step: 8
Training loss: 3.6486856837679382
Validation loss: 3.2082333005139136

Epoch: 6| Step: 9
Training loss: 3.461113574369182
Validation loss: 3.2068107842658815

Epoch: 6| Step: 10
Training loss: 4.022469828263117
Validation loss: 3.2044226250247867

Epoch: 6| Step: 11
Training loss: 3.3524275510328803
Validation loss: 3.2065754048212978

Epoch: 6| Step: 12
Training loss: 3.5554764427549443
Validation loss: 3.2047828719842433

Epoch: 6| Step: 13
Training loss: 2.987052794626868
Validation loss: 3.2032891904466427

Epoch: 63| Step: 0
Training loss: 4.103757318263017
Validation loss: 3.205382850766877

Epoch: 6| Step: 1
Training loss: 3.0467626306402376
Validation loss: 3.205441225478296

Epoch: 6| Step: 2
Training loss: 3.7233353242609843
Validation loss: 3.204847564246157

Epoch: 6| Step: 3
Training loss: 2.4677618439329962
Validation loss: 3.2045431315787583

Epoch: 6| Step: 4
Training loss: 3.3205959782480066
Validation loss: 3.205414220868137

Epoch: 6| Step: 5
Training loss: 3.5030830972906477
Validation loss: 3.2041831456982948

Epoch: 6| Step: 6
Training loss: 3.407885237682292
Validation loss: 3.2057706658046285

Epoch: 6| Step: 7
Training loss: 3.317631040398381
Validation loss: 3.204753881952609

Epoch: 6| Step: 8
Training loss: 3.9403685762377054
Validation loss: 3.2091437569273764

Epoch: 6| Step: 9
Training loss: 3.8635445129981947
Validation loss: 3.210300391231918

Epoch: 6| Step: 10
Training loss: 3.746249294134563
Validation loss: 3.2042265967887302

Epoch: 6| Step: 11
Training loss: 3.4871114753690327
Validation loss: 3.202198040702149

Epoch: 6| Step: 12
Training loss: 3.167172859959766
Validation loss: 3.199878208216638

Epoch: 6| Step: 13
Training loss: 2.3623884548113128
Validation loss: 3.1998366313232562

Epoch: 64| Step: 0
Training loss: 3.9482414628678533
Validation loss: 3.200826843820105

Epoch: 6| Step: 1
Training loss: 3.4964464403979205
Validation loss: 3.2003162994561354

Epoch: 6| Step: 2
Training loss: 3.2749544329785625
Validation loss: 3.1983406470187674

Epoch: 6| Step: 3
Training loss: 3.104335208558697
Validation loss: 3.1997837378760354

Epoch: 6| Step: 4
Training loss: 4.024046383311696
Validation loss: 3.198458742501734

Epoch: 6| Step: 5
Training loss: 3.8729736198080413
Validation loss: 3.198406234250069

Epoch: 6| Step: 6
Training loss: 3.2665996648443665
Validation loss: 3.2017749165136546

Epoch: 6| Step: 7
Training loss: 3.3615114027967854
Validation loss: 3.1987338777398286

Epoch: 6| Step: 8
Training loss: 2.9960277007978005
Validation loss: 3.2002421438088207

Epoch: 6| Step: 9
Training loss: 3.121755823375103
Validation loss: 3.1985093503107382

Epoch: 6| Step: 10
Training loss: 3.2284134181114705
Validation loss: 3.199016721076164

Epoch: 6| Step: 11
Training loss: 2.940719139221924
Validation loss: 3.203321398164689

Epoch: 6| Step: 12
Training loss: 3.6264059037071927
Validation loss: 3.2037925650855414

Epoch: 6| Step: 13
Training loss: 4.05033202517524
Validation loss: 3.196579808489887

Epoch: 65| Step: 0
Training loss: 3.7997857384759466
Validation loss: 3.1952636179065936

Epoch: 6| Step: 1
Training loss: 3.9703995287896268
Validation loss: 3.194444362883517

Epoch: 6| Step: 2
Training loss: 4.047268999280758
Validation loss: 3.1920787764233998

Epoch: 6| Step: 3
Training loss: 2.9566135691018314
Validation loss: 3.1928480107356663

Epoch: 6| Step: 4
Training loss: 3.1246731396442504
Validation loss: 3.193101969712098

Epoch: 6| Step: 5
Training loss: 2.9546501621285737
Validation loss: 3.19513304162039

Epoch: 6| Step: 6
Training loss: 4.037855074832017
Validation loss: 3.197125217925066

Epoch: 6| Step: 7
Training loss: 3.4609611975416126
Validation loss: 3.193663135040245

Epoch: 6| Step: 8
Training loss: 3.2265079669177164
Validation loss: 3.193562803787981

Epoch: 6| Step: 9
Training loss: 3.009856087168672
Validation loss: 3.196058525454248

Epoch: 6| Step: 10
Training loss: 3.6646577071030104
Validation loss: 3.194041685229036

Epoch: 6| Step: 11
Training loss: 3.2733471842030566
Validation loss: 3.193118205275393

Epoch: 6| Step: 12
Training loss: 3.085954806122359
Validation loss: 3.1945836856475016

Epoch: 6| Step: 13
Training loss: 3.26124212928603
Validation loss: 3.19270768239438

Epoch: 66| Step: 0
Training loss: 3.4395719352793637
Validation loss: 3.193665546432191

Epoch: 6| Step: 1
Training loss: 3.4220684118784317
Validation loss: 3.191377887134638

Epoch: 6| Step: 2
Training loss: 3.855241670269406
Validation loss: 3.191771537128625

Epoch: 6| Step: 3
Training loss: 3.3354637649390946
Validation loss: 3.1928470375816316

Epoch: 6| Step: 4
Training loss: 3.570755344698017
Validation loss: 3.1915473006625743

Epoch: 6| Step: 5
Training loss: 2.404074143381905
Validation loss: 3.1900895224815433

Epoch: 6| Step: 6
Training loss: 3.2274817388063735
Validation loss: 3.192728130700286

Epoch: 6| Step: 7
Training loss: 3.0678150998217504
Validation loss: 3.1899387537563153

Epoch: 6| Step: 8
Training loss: 3.147300950498737
Validation loss: 3.191769707431551

Epoch: 6| Step: 9
Training loss: 3.832796072973295
Validation loss: 3.1910008912466776

Epoch: 6| Step: 10
Training loss: 3.874667245667483
Validation loss: 3.1960565923307613

Epoch: 6| Step: 11
Training loss: 3.461471481979397
Validation loss: 3.1934889529119

Epoch: 6| Step: 12
Training loss: 3.5232515476325994
Validation loss: 3.1902155471186084

Epoch: 6| Step: 13
Training loss: 3.975323976953416
Validation loss: 3.1898966044878088

Epoch: 67| Step: 0
Training loss: 3.3049340843749047
Validation loss: 3.1898471571872173

Epoch: 6| Step: 1
Training loss: 3.4138581587964882
Validation loss: 3.1913192326877398

Epoch: 6| Step: 2
Training loss: 2.680365029143069
Validation loss: 3.189941626052059

Epoch: 6| Step: 3
Training loss: 3.299734891010511
Validation loss: 3.1899387666149477

Epoch: 6| Step: 4
Training loss: 3.5775727091504113
Validation loss: 3.1898212863781663

Epoch: 6| Step: 5
Training loss: 3.6795284941511213
Validation loss: 3.188910025059853

Epoch: 6| Step: 6
Training loss: 2.9821471841615947
Validation loss: 3.188752581541942

Epoch: 6| Step: 7
Training loss: 4.324935453958614
Validation loss: 3.1922235494053837

Epoch: 6| Step: 8
Training loss: 2.638750844546011
Validation loss: 3.1904314311832036

Epoch: 6| Step: 9
Training loss: 3.8656259177475922
Validation loss: 3.1854817215587863

Epoch: 6| Step: 10
Training loss: 3.8267965697681343
Validation loss: 3.191227545600921

Epoch: 6| Step: 11
Training loss: 3.29135696950112
Validation loss: 3.1883766566083076

Epoch: 6| Step: 12
Training loss: 3.7987530619993986
Validation loss: 3.189663507674499

Epoch: 6| Step: 13
Training loss: 2.717326526035596
Validation loss: 3.188337019505189

Epoch: 68| Step: 0
Training loss: 2.751610804344467
Validation loss: 3.1878375735833555

Epoch: 6| Step: 1
Training loss: 4.269158210058484
Validation loss: 3.187565281083072

Epoch: 6| Step: 2
Training loss: 2.7315413260743915
Validation loss: 3.1886543935778517

Epoch: 6| Step: 3
Training loss: 3.6704559830787047
Validation loss: 3.187664704126124

Epoch: 6| Step: 4
Training loss: 4.343863286798346
Validation loss: 3.1844954190617303

Epoch: 6| Step: 5
Training loss: 3.6916100824180162
Validation loss: 3.185881169627897

Epoch: 6| Step: 6
Training loss: 3.2684073390748973
Validation loss: 3.186351800149216

Epoch: 6| Step: 7
Training loss: 3.416199597944061
Validation loss: 3.185585603638074

Epoch: 6| Step: 8
Training loss: 3.5018012997362478
Validation loss: 3.184136214884731

Epoch: 6| Step: 9
Training loss: 2.764171843579006
Validation loss: 3.1852349371352746

Epoch: 6| Step: 10
Training loss: 2.811620617187731
Validation loss: 3.183757491851701

Epoch: 6| Step: 11
Training loss: 3.6595927550747507
Validation loss: 3.183729967537044

Epoch: 6| Step: 12
Training loss: 3.2042564812727337
Validation loss: 3.1847976643817035

Epoch: 6| Step: 13
Training loss: 3.5539245457407853
Validation loss: 3.183731834063826

Epoch: 69| Step: 0
Training loss: 3.5372997213761312
Validation loss: 3.183567329104343

Epoch: 6| Step: 1
Training loss: 3.1517888636092812
Validation loss: 3.1829212655408474

Epoch: 6| Step: 2
Training loss: 3.4815147532082413
Validation loss: 3.184409183806308

Epoch: 6| Step: 3
Training loss: 3.188222765789253
Validation loss: 3.1841473320875484

Epoch: 6| Step: 4
Training loss: 3.1055610307142127
Validation loss: 3.18143237258236

Epoch: 6| Step: 5
Training loss: 3.3565262892108523
Validation loss: 3.179600789260293

Epoch: 6| Step: 6
Training loss: 3.680345739626047
Validation loss: 3.180808540180191

Epoch: 6| Step: 7
Training loss: 2.948138998069955
Validation loss: 3.1864102177768436

Epoch: 6| Step: 8
Training loss: 3.5468295594384083
Validation loss: 3.1813730077599813

Epoch: 6| Step: 9
Training loss: 3.537022826022156
Validation loss: 3.1791735802180163

Epoch: 6| Step: 10
Training loss: 3.3583909123661693
Validation loss: 3.1814506733564127

Epoch: 6| Step: 11
Training loss: 3.9860929487983543
Validation loss: 3.181398399310693

Epoch: 6| Step: 12
Training loss: 3.6290831096737017
Validation loss: 3.180717869526012

Epoch: 6| Step: 13
Training loss: 3.5146579344828623
Validation loss: 3.1830896407878586

Epoch: 70| Step: 0
Training loss: 2.992411871483227
Validation loss: 3.1836316520467514

Epoch: 6| Step: 1
Training loss: 3.2440321489051063
Validation loss: 3.1831397310552276

Epoch: 6| Step: 2
Training loss: 4.041081232097922
Validation loss: 3.1817355018951607

Epoch: 6| Step: 3
Training loss: 3.5177632928602125
Validation loss: 3.1822767931861455

Epoch: 6| Step: 4
Training loss: 2.582741597812638
Validation loss: 3.1811477820388165

Epoch: 6| Step: 5
Training loss: 3.6001994766495202
Validation loss: 3.1786667150073282

Epoch: 6| Step: 6
Training loss: 3.4636897387677945
Validation loss: 3.179460893808105

Epoch: 6| Step: 7
Training loss: 3.2952625254589862
Validation loss: 3.1789541711808345

Epoch: 6| Step: 8
Training loss: 4.38004709401353
Validation loss: 3.1782485984827247

Epoch: 6| Step: 9
Training loss: 3.1708300142275014
Validation loss: 3.176396574330604

Epoch: 6| Step: 10
Training loss: 3.280009298544008
Validation loss: 3.1780086440092825

Epoch: 6| Step: 11
Training loss: 3.6978655457880785
Validation loss: 3.177317530033881

Epoch: 6| Step: 12
Training loss: 3.4578561262092715
Validation loss: 3.177632889740997

Epoch: 6| Step: 13
Training loss: 2.573666317928577
Validation loss: 3.176659345788085

Epoch: 71| Step: 0
Training loss: 2.7610737048642195
Validation loss: 3.17720497149984

Epoch: 6| Step: 1
Training loss: 3.1806974939235517
Validation loss: 3.179065092051078

Epoch: 6| Step: 2
Training loss: 2.863420636582127
Validation loss: 3.1802431292161413

Epoch: 6| Step: 3
Training loss: 3.553745689966444
Validation loss: 3.1843424919329055

Epoch: 6| Step: 4
Training loss: 3.6406853797719
Validation loss: 3.1815885418205156

Epoch: 6| Step: 5
Training loss: 3.1141330219098564
Validation loss: 3.1816687443089022

Epoch: 6| Step: 6
Training loss: 3.8272605698519477
Validation loss: 3.1835664159246937

Epoch: 6| Step: 7
Training loss: 3.4287931279756623
Validation loss: 3.1845553439355383

Epoch: 6| Step: 8
Training loss: 3.366884151522073
Validation loss: 3.1874565155325336

Epoch: 6| Step: 9
Training loss: 3.6299394300887835
Validation loss: 3.184236746544397

Epoch: 6| Step: 10
Training loss: 3.815082863323983
Validation loss: 3.183659117622915

Epoch: 6| Step: 11
Training loss: 3.575500725311987
Validation loss: 3.178596561993353

Epoch: 6| Step: 12
Training loss: 3.187658268608283
Validation loss: 3.1743732375395486

Epoch: 6| Step: 13
Training loss: 4.128839035714146
Validation loss: 3.173331380106565

Epoch: 72| Step: 0
Training loss: 4.242974701794528
Validation loss: 3.1741403027043806

Epoch: 6| Step: 1
Training loss: 2.1384968446499135
Validation loss: 3.175245055338218

Epoch: 6| Step: 2
Training loss: 3.0168693228526546
Validation loss: 3.1763833525406557

Epoch: 6| Step: 3
Training loss: 3.1811382161644275
Validation loss: 3.1744991762414805

Epoch: 6| Step: 4
Training loss: 2.77564403174373
Validation loss: 3.175222098111271

Epoch: 6| Step: 5
Training loss: 2.8694397606144166
Validation loss: 3.176897888312246

Epoch: 6| Step: 6
Training loss: 3.089549131369178
Validation loss: 3.174855780561869

Epoch: 6| Step: 7
Training loss: 3.9847023025416055
Validation loss: 3.175894135061662

Epoch: 6| Step: 8
Training loss: 3.9990688670725425
Validation loss: 3.174358540704365

Epoch: 6| Step: 9
Training loss: 3.334693694682244
Validation loss: 3.1732288322225024

Epoch: 6| Step: 10
Training loss: 3.618770376619148
Validation loss: 3.170514277848976

Epoch: 6| Step: 11
Training loss: 3.5553472891714324
Validation loss: 3.174940784726713

Epoch: 6| Step: 12
Training loss: 3.809444766700522
Validation loss: 3.1777562653083775

Epoch: 6| Step: 13
Training loss: 3.9939534262366236
Validation loss: 3.1797528681078124

Epoch: 73| Step: 0
Training loss: 3.615375105943676
Validation loss: 3.1881039759219387

Epoch: 6| Step: 1
Training loss: 3.715458543287712
Validation loss: 3.179949227186557

Epoch: 6| Step: 2
Training loss: 3.3353433906342036
Validation loss: 3.178296535580552

Epoch: 6| Step: 3
Training loss: 3.9721211210839886
Validation loss: 3.17593784564495

Epoch: 6| Step: 4
Training loss: 2.848352417797292
Validation loss: 3.1686467363369766

Epoch: 6| Step: 5
Training loss: 3.644290895703487
Validation loss: 3.169798103109692

Epoch: 6| Step: 6
Training loss: 2.979657183904509
Validation loss: 3.170264098855453

Epoch: 6| Step: 7
Training loss: 3.5406393618178766
Validation loss: 3.1726237165610884

Epoch: 6| Step: 8
Training loss: 3.3938580406231407
Validation loss: 3.168043181216649

Epoch: 6| Step: 9
Training loss: 2.9191294127394065
Validation loss: 3.1707237235918626

Epoch: 6| Step: 10
Training loss: 2.9107532682491395
Validation loss: 3.1687618690251123

Epoch: 6| Step: 11
Training loss: 3.3862087477335976
Validation loss: 3.1716948265631983

Epoch: 6| Step: 12
Training loss: 4.069618209814924
Validation loss: 3.1681720014020645

Epoch: 6| Step: 13
Training loss: 3.3839838057236475
Validation loss: 3.1701750714813985

Epoch: 74| Step: 0
Training loss: 2.92965494773582
Validation loss: 3.168502255099921

Epoch: 6| Step: 1
Training loss: 3.203386249588128
Validation loss: 3.1684409432054137

Epoch: 6| Step: 2
Training loss: 3.8035260254716845
Validation loss: 3.168832163716248

Epoch: 6| Step: 3
Training loss: 3.14064306756891
Validation loss: 3.169513797664189

Epoch: 6| Step: 4
Training loss: 3.2489237837418528
Validation loss: 3.1675384894092184

Epoch: 6| Step: 5
Training loss: 3.409585282285835
Validation loss: 3.1693474206600443

Epoch: 6| Step: 6
Training loss: 3.3293295816052306
Validation loss: 3.1685632106192356

Epoch: 6| Step: 7
Training loss: 3.2895510349214128
Validation loss: 3.1701072601409552

Epoch: 6| Step: 8
Training loss: 3.2586084943980587
Validation loss: 3.1681871007780584

Epoch: 6| Step: 9
Training loss: 3.4160163229433964
Validation loss: 3.168738662567733

Epoch: 6| Step: 10
Training loss: 2.7245350817324003
Validation loss: 3.169555064590946

Epoch: 6| Step: 11
Training loss: 3.92017245477738
Validation loss: 3.17226455973955

Epoch: 6| Step: 12
Training loss: 3.896695101209741
Validation loss: 3.173633420413179

Epoch: 6| Step: 13
Training loss: 4.46291455819622
Validation loss: 3.1747519947485525

Epoch: 75| Step: 0
Training loss: 3.189176828969436
Validation loss: 3.170963415199818

Epoch: 6| Step: 1
Training loss: 3.3103820939816444
Validation loss: 3.173713925713766

Epoch: 6| Step: 2
Training loss: 3.4546705558702944
Validation loss: 3.1673295720200323

Epoch: 6| Step: 3
Training loss: 2.741292519437505
Validation loss: 3.168949825035204

Epoch: 6| Step: 4
Training loss: 3.5871863091788603
Validation loss: 3.1674001413133857

Epoch: 6| Step: 5
Training loss: 3.910139177191749
Validation loss: 3.164152512813871

Epoch: 6| Step: 6
Training loss: 3.2005360631163953
Validation loss: 3.165771408557507

Epoch: 6| Step: 7
Training loss: 3.4183635374681836
Validation loss: 3.164981219176625

Epoch: 6| Step: 8
Training loss: 3.3441372941228593
Validation loss: 3.164787817226376

Epoch: 6| Step: 9
Training loss: 3.818420690644202
Validation loss: 3.1635270921964613

Epoch: 6| Step: 10
Training loss: 3.9886811566844926
Validation loss: 3.1629770191141025

Epoch: 6| Step: 11
Training loss: 3.145419735698354
Validation loss: 3.16492310425051

Epoch: 6| Step: 12
Training loss: 3.1882888715335578
Validation loss: 3.163564774370852

Epoch: 6| Step: 13
Training loss: 3.2907056894580147
Validation loss: 3.1649424336205003

Epoch: 76| Step: 0
Training loss: 4.0286667701392505
Validation loss: 3.166906570086198

Epoch: 6| Step: 1
Training loss: 3.6401265994263268
Validation loss: 3.1721968124614546

Epoch: 6| Step: 2
Training loss: 3.3804335477515544
Validation loss: 3.1779758603058745

Epoch: 6| Step: 3
Training loss: 2.8972033729155435
Validation loss: 3.1818185110162576

Epoch: 6| Step: 4
Training loss: 2.796489070926224
Validation loss: 3.173116804077345

Epoch: 6| Step: 5
Training loss: 4.3973320068055095
Validation loss: 3.165140895672955

Epoch: 6| Step: 6
Training loss: 3.1384561366039065
Validation loss: 3.1609077099124083

Epoch: 6| Step: 7
Training loss: 3.367244994343107
Validation loss: 3.1637702218464887

Epoch: 6| Step: 8
Training loss: 3.2126046189665445
Validation loss: 3.1617935907600954

Epoch: 6| Step: 9
Training loss: 2.7906665623764018
Validation loss: 3.1600695290295047

Epoch: 6| Step: 10
Training loss: 3.2455429913616696
Validation loss: 3.159442035167589

Epoch: 6| Step: 11
Training loss: 2.981586851526925
Validation loss: 3.159908672193984

Epoch: 6| Step: 12
Training loss: 3.8835718651943223
Validation loss: 3.1618277479251966

Epoch: 6| Step: 13
Training loss: 3.744857950203146
Validation loss: 3.1614485119136635

Epoch: 77| Step: 0
Training loss: 3.548430114496525
Validation loss: 3.163746106062349

Epoch: 6| Step: 1
Training loss: 2.759881386350441
Validation loss: 3.1627582162368895

Epoch: 6| Step: 2
Training loss: 3.595383778594555
Validation loss: 3.161173004807543

Epoch: 6| Step: 3
Training loss: 3.4860116168478057
Validation loss: 3.1603946997139434

Epoch: 6| Step: 4
Training loss: 3.161371287488769
Validation loss: 3.1574222431016024

Epoch: 6| Step: 5
Training loss: 3.951808303060226
Validation loss: 3.157812592095205

Epoch: 6| Step: 6
Training loss: 3.6379924637442236
Validation loss: 3.1596261901277476

Epoch: 6| Step: 7
Training loss: 2.5816387853559606
Validation loss: 3.1579182871082705

Epoch: 6| Step: 8
Training loss: 2.609131396223891
Validation loss: 3.1588398061209695

Epoch: 6| Step: 9
Training loss: 3.7459067575445952
Validation loss: 3.1590316756807453

Epoch: 6| Step: 10
Training loss: 3.4166984246491525
Validation loss: 3.161733543406612

Epoch: 6| Step: 11
Training loss: 3.694178207543507
Validation loss: 3.16399113837817

Epoch: 6| Step: 12
Training loss: 3.492276252455111
Validation loss: 3.159873361694103

Epoch: 6| Step: 13
Training loss: 3.9591806943646666
Validation loss: 3.1605652094628325

Epoch: 78| Step: 0
Training loss: 3.8940379175613793
Validation loss: 3.1549395725650693

Epoch: 6| Step: 1
Training loss: 3.032003092862366
Validation loss: 3.1545152976709487

Epoch: 6| Step: 2
Training loss: 2.710083224999886
Validation loss: 3.155557890191207

Epoch: 6| Step: 3
Training loss: 3.3439982669679815
Validation loss: 3.1534954117918943

Epoch: 6| Step: 4
Training loss: 3.46824697335358
Validation loss: 3.154802823772207

Epoch: 6| Step: 5
Training loss: 2.7310695178285296
Validation loss: 3.154719201312405

Epoch: 6| Step: 6
Training loss: 3.4998686629585096
Validation loss: 3.1566223230331385

Epoch: 6| Step: 7
Training loss: 3.0882047026585626
Validation loss: 3.157019608355595

Epoch: 6| Step: 8
Training loss: 3.8211624042627363
Validation loss: 3.1530687546232796

Epoch: 6| Step: 9
Training loss: 4.172581302131858
Validation loss: 3.155644185965704

Epoch: 6| Step: 10
Training loss: 3.4242336557469892
Validation loss: 3.1541781273941942

Epoch: 6| Step: 11
Training loss: 2.8441443536663513
Validation loss: 3.1571178804601403

Epoch: 6| Step: 12
Training loss: 3.6608728381123283
Validation loss: 3.1543702666916102

Epoch: 6| Step: 13
Training loss: 3.826620623769019
Validation loss: 3.1550004000884764

Epoch: 79| Step: 0
Training loss: 4.4172621751376
Validation loss: 3.1521077004980085

Epoch: 6| Step: 1
Training loss: 3.4306550279645487
Validation loss: 3.15278854959759

Epoch: 6| Step: 2
Training loss: 3.374801771205841
Validation loss: 3.1540035488200697

Epoch: 6| Step: 3
Training loss: 3.410056830461202
Validation loss: 3.1547501853727624

Epoch: 6| Step: 4
Training loss: 3.7236285866173895
Validation loss: 3.1554348028007646

Epoch: 6| Step: 5
Training loss: 3.2614330783395364
Validation loss: 3.1552844467740604

Epoch: 6| Step: 6
Training loss: 2.7608676661935743
Validation loss: 3.1546211129112174

Epoch: 6| Step: 7
Training loss: 2.8796673911143396
Validation loss: 3.156447190093155

Epoch: 6| Step: 8
Training loss: 3.5522629738108384
Validation loss: 3.1555839395418808

Epoch: 6| Step: 9
Training loss: 3.1565805394293833
Validation loss: 3.1532120307936378

Epoch: 6| Step: 10
Training loss: 2.5581551911235874
Validation loss: 3.154102509049384

Epoch: 6| Step: 11
Training loss: 3.6988353752140104
Validation loss: 3.1504279142086165

Epoch: 6| Step: 12
Training loss: 3.1044050974238417
Validation loss: 3.15395066704877

Epoch: 6| Step: 13
Training loss: 4.318456765141624
Validation loss: 3.1522943870212177

Epoch: 80| Step: 0
Training loss: 2.9126955155003116
Validation loss: 3.1561993497709397

Epoch: 6| Step: 1
Training loss: 3.2638375533014536
Validation loss: 3.1588528124216255

Epoch: 6| Step: 2
Training loss: 3.7840719490711416
Validation loss: 3.1535865871137068

Epoch: 6| Step: 3
Training loss: 3.0217412877604612
Validation loss: 3.1564573782110914

Epoch: 6| Step: 4
Training loss: 3.639368716402704
Validation loss: 3.1562631046945415

Epoch: 6| Step: 5
Training loss: 3.3810531587119614
Validation loss: 3.1592123319244574

Epoch: 6| Step: 6
Training loss: 3.8430420758626345
Validation loss: 3.1569893380310003

Epoch: 6| Step: 7
Training loss: 3.287337550801955
Validation loss: 3.154021893326138

Epoch: 6| Step: 8
Training loss: 3.7839771871221863
Validation loss: 3.151015283075314

Epoch: 6| Step: 9
Training loss: 2.147882008265222
Validation loss: 3.14855657159121

Epoch: 6| Step: 10
Training loss: 3.840381914458687
Validation loss: 3.149064499334304

Epoch: 6| Step: 11
Training loss: 3.36806949118826
Validation loss: 3.1515975137810237

Epoch: 6| Step: 12
Training loss: 3.945731142701981
Validation loss: 3.1528712735475044

Epoch: 6| Step: 13
Training loss: 2.6834435122440237
Validation loss: 3.1562833017699963

Epoch: 81| Step: 0
Training loss: 2.500253283067975
Validation loss: 3.1628544757727712

Epoch: 6| Step: 1
Training loss: 3.369427778750181
Validation loss: 3.1601065352869377

Epoch: 6| Step: 2
Training loss: 4.184327931100208
Validation loss: 3.1582612613025534

Epoch: 6| Step: 3
Training loss: 3.7991891096160244
Validation loss: 3.1539152044958487

Epoch: 6| Step: 4
Training loss: 3.101625225672396
Validation loss: 3.1509666852268245

Epoch: 6| Step: 5
Training loss: 3.081054997028511
Validation loss: 3.149882745066092

Epoch: 6| Step: 6
Training loss: 2.9718252215944796
Validation loss: 3.1491976826143424

Epoch: 6| Step: 7
Training loss: 3.3677434263201316
Validation loss: 3.1473613131186773

Epoch: 6| Step: 8
Training loss: 2.8192720052501854
Validation loss: 3.153154861600027

Epoch: 6| Step: 9
Training loss: 3.9323271423491164
Validation loss: 3.1620716689957455

Epoch: 6| Step: 10
Training loss: 2.9382036056341674
Validation loss: 3.16204616927315

Epoch: 6| Step: 11
Training loss: 3.497814858738344
Validation loss: 3.16626321028321

Epoch: 6| Step: 12
Training loss: 4.299073256939253
Validation loss: 3.156309238731994

Epoch: 6| Step: 13
Training loss: 3.349698631053886
Validation loss: 3.1533612531480344

Epoch: 82| Step: 0
Training loss: 3.4455533105681004
Validation loss: 3.145751207748337

Epoch: 6| Step: 1
Training loss: 3.935128602927995
Validation loss: 3.14491593261308

Epoch: 6| Step: 2
Training loss: 2.8676195364849697
Validation loss: 3.1455306377681036

Epoch: 6| Step: 3
Training loss: 3.118063437931677
Validation loss: 3.1494736308653493

Epoch: 6| Step: 4
Training loss: 3.064732419106147
Validation loss: 3.1505588835229568

Epoch: 6| Step: 5
Training loss: 3.032191808627324
Validation loss: 3.155079141866482

Epoch: 6| Step: 6
Training loss: 3.3198730177896936
Validation loss: 3.158619356355079

Epoch: 6| Step: 7
Training loss: 3.8353161590242926
Validation loss: 3.157662721130591

Epoch: 6| Step: 8
Training loss: 3.6481613283372876
Validation loss: 3.1560308477197307

Epoch: 6| Step: 9
Training loss: 3.6475630371837977
Validation loss: 3.1475516629111255

Epoch: 6| Step: 10
Training loss: 3.6323706573541235
Validation loss: 3.1451669052427293

Epoch: 6| Step: 11
Training loss: 3.367004247931805
Validation loss: 3.144361131250123

Epoch: 6| Step: 12
Training loss: 3.380528619499237
Validation loss: 3.142116036983864

Epoch: 6| Step: 13
Training loss: 3.229754699982354
Validation loss: 3.1412458741247735

Epoch: 83| Step: 0
Training loss: 2.9674454884716552
Validation loss: 3.140258470547201

Epoch: 6| Step: 1
Training loss: 2.700640379939816
Validation loss: 3.1451662841328116

Epoch: 6| Step: 2
Training loss: 3.2795760471549165
Validation loss: 3.149361736158311

Epoch: 6| Step: 3
Training loss: 4.068775201534855
Validation loss: 3.162275672345206

Epoch: 6| Step: 4
Training loss: 4.400484032450139
Validation loss: 3.1605259097955924

Epoch: 6| Step: 5
Training loss: 3.6898640958575206
Validation loss: 3.1466463246330214

Epoch: 6| Step: 6
Training loss: 3.084024265990424
Validation loss: 3.145116109131725

Epoch: 6| Step: 7
Training loss: 3.5420632682590663
Validation loss: 3.1415336893004997

Epoch: 6| Step: 8
Training loss: 2.3073762371560647
Validation loss: 3.1405396188415104

Epoch: 6| Step: 9
Training loss: 3.153572986789399
Validation loss: 3.139586530283781

Epoch: 6| Step: 10
Training loss: 3.7169558260070557
Validation loss: 3.1407289438316783

Epoch: 6| Step: 11
Training loss: 2.955234480589673
Validation loss: 3.138608898923652

Epoch: 6| Step: 12
Training loss: 3.632293729760551
Validation loss: 3.14578752349203

Epoch: 6| Step: 13
Training loss: 3.615637956099842
Validation loss: 3.144321324938509

Epoch: 84| Step: 0
Training loss: 3.215490968986052
Validation loss: 3.142909023956464

Epoch: 6| Step: 1
Training loss: 2.8823493233940805
Validation loss: 3.1440007077049072

Epoch: 6| Step: 2
Training loss: 4.43596525919238
Validation loss: 3.1399027949536484

Epoch: 6| Step: 3
Training loss: 3.436635134009941
Validation loss: 3.1420239715360423

Epoch: 6| Step: 4
Training loss: 2.4803928153362285
Validation loss: 3.1370697215391874

Epoch: 6| Step: 5
Training loss: 3.7135479870386185
Validation loss: 3.1377357429316586

Epoch: 6| Step: 6
Training loss: 3.4212746289460485
Validation loss: 3.1359929517367395

Epoch: 6| Step: 7
Training loss: 3.5220315162249385
Validation loss: 3.137176358923032

Epoch: 6| Step: 8
Training loss: 2.410120538728292
Validation loss: 3.1359128359459656

Epoch: 6| Step: 9
Training loss: 3.455225793109919
Validation loss: 3.136269356390071

Epoch: 6| Step: 10
Training loss: 3.42730922398982
Validation loss: 3.1359728863980494

Epoch: 6| Step: 11
Training loss: 3.640614128915167
Validation loss: 3.135321196257959

Epoch: 6| Step: 12
Training loss: 4.069741236453425
Validation loss: 3.135450216962884

Epoch: 6| Step: 13
Training loss: 2.3166701373982215
Validation loss: 3.133890119613188

Epoch: 85| Step: 0
Training loss: 3.9482822836048377
Validation loss: 3.1347290916078703

Epoch: 6| Step: 1
Training loss: 3.5813954162367225
Validation loss: 3.13487201691965

Epoch: 6| Step: 2
Training loss: 3.3976342666065666
Validation loss: 3.1323068524890965

Epoch: 6| Step: 3
Training loss: 3.51811801255739
Validation loss: 3.1335242341124205

Epoch: 6| Step: 4
Training loss: 3.814820630817719
Validation loss: 3.132746840652176

Epoch: 6| Step: 5
Training loss: 3.4884265557554603
Validation loss: 3.1323457393246326

Epoch: 6| Step: 6
Training loss: 3.2103652629825685
Validation loss: 3.133100538392084

Epoch: 6| Step: 7
Training loss: 3.2041177839329547
Validation loss: 3.1325592117835637

Epoch: 6| Step: 8
Training loss: 2.98166201641416
Validation loss: 3.1319879807246176

Epoch: 6| Step: 9
Training loss: 3.7291701048652244
Validation loss: 3.1337504512681287

Epoch: 6| Step: 10
Training loss: 3.0779821682240582
Validation loss: 3.130987051692596

Epoch: 6| Step: 11
Training loss: 2.9846034736456133
Validation loss: 3.130735501630452

Epoch: 6| Step: 12
Training loss: 3.3392760391036904
Validation loss: 3.131969268148449

Epoch: 6| Step: 13
Training loss: 2.7348016896435556
Validation loss: 3.131009708523234

Epoch: 86| Step: 0
Training loss: 2.9103060075770824
Validation loss: 3.12984172691757

Epoch: 6| Step: 1
Training loss: 2.785744025871624
Validation loss: 3.1305855316341873

Epoch: 6| Step: 2
Training loss: 3.5431042764097676
Validation loss: 3.1329620164440173

Epoch: 6| Step: 3
Training loss: 3.411431667233368
Validation loss: 3.1311686873780173

Epoch: 6| Step: 4
Training loss: 2.533512752436872
Validation loss: 3.1327467058312584

Epoch: 6| Step: 5
Training loss: 3.9433883960670584
Validation loss: 3.1317252397313253

Epoch: 6| Step: 6
Training loss: 3.523059359472419
Validation loss: 3.1385913432217296

Epoch: 6| Step: 7
Training loss: 3.869116962635873
Validation loss: 3.1333857521676673

Epoch: 6| Step: 8
Training loss: 3.344828208993799
Validation loss: 3.1383614886689535

Epoch: 6| Step: 9
Training loss: 3.0457608264341474
Validation loss: 3.1325461257741343

Epoch: 6| Step: 10
Training loss: 3.819635436552036
Validation loss: 3.1358212669299355

Epoch: 6| Step: 11
Training loss: 3.1852051196677915
Validation loss: 3.139329718577408

Epoch: 6| Step: 12
Training loss: 4.034220702443706
Validation loss: 3.1413379509514785

Epoch: 6| Step: 13
Training loss: 2.903159354245822
Validation loss: 3.12960122537716

Epoch: 87| Step: 0
Training loss: 3.544972989473086
Validation loss: 3.1287084417621505

Epoch: 6| Step: 1
Training loss: 2.8661024654729865
Validation loss: 3.1295422527545846

Epoch: 6| Step: 2
Training loss: 3.7866628697425537
Validation loss: 3.1297600570727386

Epoch: 6| Step: 3
Training loss: 2.8802717223731076
Validation loss: 3.129007561491788

Epoch: 6| Step: 4
Training loss: 3.2645236991948736
Validation loss: 3.124872276403226

Epoch: 6| Step: 5
Training loss: 4.166253463601756
Validation loss: 3.129730961890687

Epoch: 6| Step: 6
Training loss: 2.875042293071649
Validation loss: 3.128231541848828

Epoch: 6| Step: 7
Training loss: 3.105043086983091
Validation loss: 3.1279720587196738

Epoch: 6| Step: 8
Training loss: 2.851014970443743
Validation loss: 3.130049669628518

Epoch: 6| Step: 9
Training loss: 4.225733874988647
Validation loss: 3.1316987324254852

Epoch: 6| Step: 10
Training loss: 3.194876121065585
Validation loss: 3.135313273897236

Epoch: 6| Step: 11
Training loss: 2.7866460338844727
Validation loss: 3.1359688430675687

Epoch: 6| Step: 12
Training loss: 3.9998223742147045
Validation loss: 3.1445910902169545

Epoch: 6| Step: 13
Training loss: 3.416446647693068
Validation loss: 3.1370151119104133

Epoch: 88| Step: 0
Training loss: 3.479494517216102
Validation loss: 3.1345099657365525

Epoch: 6| Step: 1
Training loss: 3.2110723388278792
Validation loss: 3.131261628726015

Epoch: 6| Step: 2
Training loss: 3.979746804546226
Validation loss: 3.1278674876932033

Epoch: 6| Step: 3
Training loss: 3.742975012754688
Validation loss: 3.1274133612965995

Epoch: 6| Step: 4
Training loss: 2.6405527680579377
Validation loss: 3.126240999472299

Epoch: 6| Step: 5
Training loss: 2.9394858931936008
Validation loss: 3.125812939967378

Epoch: 6| Step: 6
Training loss: 3.429495352052686
Validation loss: 3.125097951687006

Epoch: 6| Step: 7
Training loss: 3.6985202923473697
Validation loss: 3.1251920677965606

Epoch: 6| Step: 8
Training loss: 3.0049453347005457
Validation loss: 3.124455893124325

Epoch: 6| Step: 9
Training loss: 2.724623463365234
Validation loss: 3.1239601324788877

Epoch: 6| Step: 10
Training loss: 3.9171193990733393
Validation loss: 3.124550455224848

Epoch: 6| Step: 11
Training loss: 2.2494156396517004
Validation loss: 3.12509544144777

Epoch: 6| Step: 12
Training loss: 4.054487572593898
Validation loss: 3.1234207937616882

Epoch: 6| Step: 13
Training loss: 4.027494115085197
Validation loss: 3.126321445117492

Epoch: 89| Step: 0
Training loss: 3.158757488451687
Validation loss: 3.1248492083520927

Epoch: 6| Step: 1
Training loss: 2.5665366779785517
Validation loss: 3.1242050899060954

Epoch: 6| Step: 2
Training loss: 3.2579936976550403
Validation loss: 3.1304526325930824

Epoch: 6| Step: 3
Training loss: 3.526076586657003
Validation loss: 3.1263283931243904

Epoch: 6| Step: 4
Training loss: 4.043558654503138
Validation loss: 3.1239407653602385

Epoch: 6| Step: 5
Training loss: 3.814497877601656
Validation loss: 3.126725120599745

Epoch: 6| Step: 6
Training loss: 3.7833391203534963
Validation loss: 3.1248568824072107

Epoch: 6| Step: 7
Training loss: 3.5560903610574717
Validation loss: 3.122899904818858

Epoch: 6| Step: 8
Training loss: 3.8830351429895527
Validation loss: 3.128718236766305

Epoch: 6| Step: 9
Training loss: 2.5125344762761603
Validation loss: 3.1228045194107477

Epoch: 6| Step: 10
Training loss: 2.7481775313755694
Validation loss: 3.1226860092934468

Epoch: 6| Step: 11
Training loss: 3.4250774291259187
Validation loss: 3.1233946189847934

Epoch: 6| Step: 12
Training loss: 3.502281671399768
Validation loss: 3.122836580305628

Epoch: 6| Step: 13
Training loss: 2.9439765470441333
Validation loss: 3.1256558310499183

Epoch: 90| Step: 0
Training loss: 3.42698990869386
Validation loss: 3.123752431924655

Epoch: 6| Step: 1
Training loss: 3.4600396294060776
Validation loss: 3.123620923008887

Epoch: 6| Step: 2
Training loss: 2.7176808853098744
Validation loss: 3.123819324224279

Epoch: 6| Step: 3
Training loss: 4.3565507169284645
Validation loss: 3.123287033341292

Epoch: 6| Step: 4
Training loss: 3.452050641737122
Validation loss: 3.1206772178621827

Epoch: 6| Step: 5
Training loss: 4.294981827258921
Validation loss: 3.1216670189321674

Epoch: 6| Step: 6
Training loss: 2.840308989519419
Validation loss: 3.122088610614646

Epoch: 6| Step: 7
Training loss: 2.9365555888662254
Validation loss: 3.1256684373889514

Epoch: 6| Step: 8
Training loss: 3.2889894309727996
Validation loss: 3.123271743163302

Epoch: 6| Step: 9
Training loss: 3.688645136553584
Validation loss: 3.1233903188805248

Epoch: 6| Step: 10
Training loss: 2.7572396955983267
Validation loss: 3.128275824985491

Epoch: 6| Step: 11
Training loss: 3.2768694019433515
Validation loss: 3.1227816774437027

Epoch: 6| Step: 12
Training loss: 2.9200954628062856
Validation loss: 3.118976974275483

Epoch: 6| Step: 13
Training loss: 3.4424689705529974
Validation loss: 3.1174705036216324

Epoch: 91| Step: 0
Training loss: 3.598578087482469
Validation loss: 3.115106631211694

Epoch: 6| Step: 1
Training loss: 3.1687251644929417
Validation loss: 3.114916822113389

Epoch: 6| Step: 2
Training loss: 2.8132590223354317
Validation loss: 3.115781393882005

Epoch: 6| Step: 3
Training loss: 3.1708447516724916
Validation loss: 3.1164103435220194

Epoch: 6| Step: 4
Training loss: 3.234013781440921
Validation loss: 3.1160029162254097

Epoch: 6| Step: 5
Training loss: 3.4955381836418753
Validation loss: 3.1168213152545476

Epoch: 6| Step: 6
Training loss: 2.8030479973430595
Validation loss: 3.1179024506145168

Epoch: 6| Step: 7
Training loss: 3.346620130050741
Validation loss: 3.1177390884764895

Epoch: 6| Step: 8
Training loss: 3.9945288434497934
Validation loss: 3.1175833044807995

Epoch: 6| Step: 9
Training loss: 3.5981659667926604
Validation loss: 3.122943798925493

Epoch: 6| Step: 10
Training loss: 3.596005204838772
Validation loss: 3.122296530231095

Epoch: 6| Step: 11
Training loss: 3.244155911312571
Validation loss: 3.1235919282240037

Epoch: 6| Step: 12
Training loss: 4.053669649234144
Validation loss: 3.1214813932597534

Epoch: 6| Step: 13
Training loss: 2.3027002074834737
Validation loss: 3.1227338388091743

Epoch: 92| Step: 0
Training loss: 3.3748188676618436
Validation loss: 3.1447959634089946

Epoch: 6| Step: 1
Training loss: 3.15002537671721
Validation loss: 3.1688074788785223

Epoch: 6| Step: 2
Training loss: 3.4989565247491945
Validation loss: 3.183083505292039

Epoch: 6| Step: 3
Training loss: 3.4365239925226887
Validation loss: 3.15144367845199

Epoch: 6| Step: 4
Training loss: 3.8069379914476595
Validation loss: 3.129821885074748

Epoch: 6| Step: 5
Training loss: 3.254111696789258
Validation loss: 3.115765193884216

Epoch: 6| Step: 6
Training loss: 3.9617099347370988
Validation loss: 3.112541276407924

Epoch: 6| Step: 7
Training loss: 3.3072044220878665
Validation loss: 3.1118229108765076

Epoch: 6| Step: 8
Training loss: 3.3740368634410878
Validation loss: 3.1136223038848896

Epoch: 6| Step: 9
Training loss: 2.3561194993365273
Validation loss: 3.1145431549436253

Epoch: 6| Step: 10
Training loss: 3.1841631608304937
Validation loss: 3.1152635907610327

Epoch: 6| Step: 11
Training loss: 2.7254862150334573
Validation loss: 3.1151187856382236

Epoch: 6| Step: 12
Training loss: 3.9934224646613847
Validation loss: 3.1167949287756986

Epoch: 6| Step: 13
Training loss: 3.7557991963295128
Validation loss: 3.115655408684054

Epoch: 93| Step: 0
Training loss: 3.7637136840081804
Validation loss: 3.1158025840003316

Epoch: 6| Step: 1
Training loss: 2.6371319482374314
Validation loss: 3.1166904417189167

Epoch: 6| Step: 2
Training loss: 3.2804651684161206
Validation loss: 3.114462246202535

Epoch: 6| Step: 3
Training loss: 2.794005813663581
Validation loss: 3.1136946404027475

Epoch: 6| Step: 4
Training loss: 4.167182941241179
Validation loss: 3.1147917616264245

Epoch: 6| Step: 5
Training loss: 4.013479884398413
Validation loss: 3.112409218830996

Epoch: 6| Step: 6
Training loss: 3.089050731337439
Validation loss: 3.1132926926811915

Epoch: 6| Step: 7
Training loss: 3.0153305621519926
Validation loss: 3.111713603664622

Epoch: 6| Step: 8
Training loss: 2.8211649190355264
Validation loss: 3.113666888658816

Epoch: 6| Step: 9
Training loss: 2.633521372282333
Validation loss: 3.111825103934777

Epoch: 6| Step: 10
Training loss: 3.424186587677641
Validation loss: 3.110780905676937

Epoch: 6| Step: 11
Training loss: 3.557601773702198
Validation loss: 3.1117216248311674

Epoch: 6| Step: 12
Training loss: 4.05319839211092
Validation loss: 3.108819130349813

Epoch: 6| Step: 13
Training loss: 3.595091992131045
Validation loss: 3.113174662072208

Epoch: 94| Step: 0
Training loss: 2.4087165971943163
Validation loss: 3.112371814307277

Epoch: 6| Step: 1
Training loss: 3.6045454998512705
Validation loss: 3.110887835208943

Epoch: 6| Step: 2
Training loss: 3.772746463154414
Validation loss: 3.108477143708587

Epoch: 6| Step: 3
Training loss: 3.36342642688993
Validation loss: 3.11131460197708

Epoch: 6| Step: 4
Training loss: 3.5429314692343286
Validation loss: 3.113453441602194

Epoch: 6| Step: 5
Training loss: 3.2271379230200767
Validation loss: 3.1101947045500533

Epoch: 6| Step: 6
Training loss: 3.567331350787111
Validation loss: 3.1100248821302348

Epoch: 6| Step: 7
Training loss: 2.410512344540802
Validation loss: 3.1087453263028437

Epoch: 6| Step: 8
Training loss: 3.340035487688865
Validation loss: 3.108864824680989

Epoch: 6| Step: 9
Training loss: 3.5098150777331294
Validation loss: 3.1096355172237247

Epoch: 6| Step: 10
Training loss: 3.9900245256554543
Validation loss: 3.107576764302466

Epoch: 6| Step: 11
Training loss: 3.2216484574778383
Validation loss: 3.1075132611832035

Epoch: 6| Step: 12
Training loss: 3.189153504182918
Validation loss: 3.1093256507371185

Epoch: 6| Step: 13
Training loss: 3.838370676083992
Validation loss: 3.1080254779679968

Epoch: 95| Step: 0
Training loss: 4.320557958104016
Validation loss: 3.1087416879253262

Epoch: 6| Step: 1
Training loss: 3.619150901816899
Validation loss: 3.1053957793782834

Epoch: 6| Step: 2
Training loss: 2.9762348785721198
Validation loss: 3.105285065359341

Epoch: 6| Step: 3
Training loss: 3.9003439238096713
Validation loss: 3.106341751568177

Epoch: 6| Step: 4
Training loss: 3.19550917936489
Validation loss: 3.1079464526461886

Epoch: 6| Step: 5
Training loss: 2.637952546983497
Validation loss: 3.111057303979527

Epoch: 6| Step: 6
Training loss: 4.057907795512348
Validation loss: 3.1156604106360897

Epoch: 6| Step: 7
Training loss: 2.7451432429393137
Validation loss: 3.1178677275439273

Epoch: 6| Step: 8
Training loss: 3.4933378300625733
Validation loss: 3.1124774133256676

Epoch: 6| Step: 9
Training loss: 2.7252203581020056
Validation loss: 3.1086643260392033

Epoch: 6| Step: 10
Training loss: 3.403817944697832
Validation loss: 3.109259947244984

Epoch: 6| Step: 11
Training loss: 3.0843848076599705
Validation loss: 3.1060243674620973

Epoch: 6| Step: 12
Training loss: 3.1265364875073574
Validation loss: 3.105479348065854

Epoch: 6| Step: 13
Training loss: 3.3767160362206976
Validation loss: 3.105032582376854

Epoch: 96| Step: 0
Training loss: 3.2957313325693725
Validation loss: 3.1033195324669727

Epoch: 6| Step: 1
Training loss: 3.268171713679937
Validation loss: 3.102395313662318

Epoch: 6| Step: 2
Training loss: 3.32365783907947
Validation loss: 3.1033840606526537

Epoch: 6| Step: 3
Training loss: 2.9114615361304685
Validation loss: 3.10476925629335

Epoch: 6| Step: 4
Training loss: 3.6939663844621182
Validation loss: 3.104252753695476

Epoch: 6| Step: 5
Training loss: 2.872089405378989
Validation loss: 3.104717800064508

Epoch: 6| Step: 6
Training loss: 3.9770270115637896
Validation loss: 3.1053959527425037

Epoch: 6| Step: 7
Training loss: 3.150440118711885
Validation loss: 3.104686346418785

Epoch: 6| Step: 8
Training loss: 3.0324229694341382
Validation loss: 3.1063180523775524

Epoch: 6| Step: 9
Training loss: 3.921236145753862
Validation loss: 3.1049168840445067

Epoch: 6| Step: 10
Training loss: 2.8029924546356932
Validation loss: 3.1038348110087504

Epoch: 6| Step: 11
Training loss: 3.319788705237777
Validation loss: 3.104224195743535

Epoch: 6| Step: 12
Training loss: 3.7623094073209895
Validation loss: 3.102672601931069

Epoch: 6| Step: 13
Training loss: 3.712848500550098
Validation loss: 3.10338864373598

Epoch: 97| Step: 0
Training loss: 2.861465107109311
Validation loss: 3.103722761851378

Epoch: 6| Step: 1
Training loss: 2.6119780206091443
Validation loss: 3.1004512597353906

Epoch: 6| Step: 2
Training loss: 3.4241808781932757
Validation loss: 3.0999616775036096

Epoch: 6| Step: 3
Training loss: 3.9429078280506293
Validation loss: 3.1005490923245764

Epoch: 6| Step: 4
Training loss: 3.1134451292932908
Validation loss: 3.0997144800157144

Epoch: 6| Step: 5
Training loss: 3.146583636072047
Validation loss: 3.1031988341529475

Epoch: 6| Step: 6
Training loss: 4.007779662237549
Validation loss: 3.103559434763354

Epoch: 6| Step: 7
Training loss: 3.3990016425168905
Validation loss: 3.0997244584426573

Epoch: 6| Step: 8
Training loss: 3.2406740631833157
Validation loss: 3.100066701109924

Epoch: 6| Step: 9
Training loss: 3.2515589569673753
Validation loss: 3.09953401340066

Epoch: 6| Step: 10
Training loss: 4.211795301949911
Validation loss: 3.0990587074333105

Epoch: 6| Step: 11
Training loss: 3.6012698900758595
Validation loss: 3.098713188095526

Epoch: 6| Step: 12
Training loss: 2.9469190511313506
Validation loss: 3.0982793833406856

Epoch: 6| Step: 13
Training loss: 2.569225788836438
Validation loss: 3.09918420343686

Epoch: 98| Step: 0
Training loss: 3.1180342286722698
Validation loss: 3.0981729238944835

Epoch: 6| Step: 1
Training loss: 3.418958004162747
Validation loss: 3.0990618715942224

Epoch: 6| Step: 2
Training loss: 3.1471111068870443
Validation loss: 3.100151462010571

Epoch: 6| Step: 3
Training loss: 3.5736805328203554
Validation loss: 3.0993370601663313

Epoch: 6| Step: 4
Training loss: 3.0561899066158
Validation loss: 3.09966359656874

Epoch: 6| Step: 5
Training loss: 3.062248686774691
Validation loss: 3.0975900374570644

Epoch: 6| Step: 6
Training loss: 3.642387258320454
Validation loss: 3.096443658432755

Epoch: 6| Step: 7
Training loss: 3.296327663023159
Validation loss: 3.0982216175531807

Epoch: 6| Step: 8
Training loss: 3.6919039274715932
Validation loss: 3.0957017883999733

Epoch: 6| Step: 9
Training loss: 3.9415361819669856
Validation loss: 3.0979806241667958

Epoch: 6| Step: 10
Training loss: 3.335554114294902
Validation loss: 3.0963939614962

Epoch: 6| Step: 11
Training loss: 3.812657962715987
Validation loss: 3.098135984651041

Epoch: 6| Step: 12
Training loss: 2.546939966040188
Validation loss: 3.1045286390526985

Epoch: 6| Step: 13
Training loss: 2.997740053263611
Validation loss: 3.1011304297384177

Epoch: 99| Step: 0
Training loss: 3.685319805579561
Validation loss: 3.1022697888935395

Epoch: 6| Step: 1
Training loss: 3.7937243540869545
Validation loss: 3.0952004117113048

Epoch: 6| Step: 2
Training loss: 3.668062869033414
Validation loss: 3.0939723821874017

Epoch: 6| Step: 3
Training loss: 3.492566525502212
Validation loss: 3.0947641993438424

Epoch: 6| Step: 4
Training loss: 4.28276380520304
Validation loss: 3.096917980834532

Epoch: 6| Step: 5
Training loss: 2.722949763366625
Validation loss: 3.0935120236760487

Epoch: 6| Step: 6
Training loss: 2.9381881881699754
Validation loss: 3.0941218549089355

Epoch: 6| Step: 7
Training loss: 3.3769601851610695
Validation loss: 3.093607672513207

Epoch: 6| Step: 8
Training loss: 3.146354345835139
Validation loss: 3.092920617478342

Epoch: 6| Step: 9
Training loss: 2.7238439435019486
Validation loss: 3.091598465301049

Epoch: 6| Step: 10
Training loss: 3.2934640894221068
Validation loss: 3.0930193911252983

Epoch: 6| Step: 11
Training loss: 2.5640441149994535
Validation loss: 3.0922479928832023

Epoch: 6| Step: 12
Training loss: 3.0905740793505685
Validation loss: 3.0942152760429487

Epoch: 6| Step: 13
Training loss: 4.085310061767803
Validation loss: 3.098566266713441

Epoch: 100| Step: 0
Training loss: 3.6958136511059605
Validation loss: 3.101286208598203

Epoch: 6| Step: 1
Training loss: 3.383806254465706
Validation loss: 3.1014785364684925

Epoch: 6| Step: 2
Training loss: 4.01229114404842
Validation loss: 3.1037824604529693

Epoch: 6| Step: 3
Training loss: 3.502373163294194
Validation loss: 3.1021865461174087

Epoch: 6| Step: 4
Training loss: 3.200350718352441
Validation loss: 3.1015959624459835

Epoch: 6| Step: 5
Training loss: 3.1711955728698222
Validation loss: 3.093706649620741

Epoch: 6| Step: 6
Training loss: 3.515640055306305
Validation loss: 3.090522950847949

Epoch: 6| Step: 7
Training loss: 2.9189721033188403
Validation loss: 3.08874267417632

Epoch: 6| Step: 8
Training loss: 3.2796827660645027
Validation loss: 3.089862456339699

Epoch: 6| Step: 9
Training loss: 3.6147101798689536
Validation loss: 3.0874705313520527

Epoch: 6| Step: 10
Training loss: 3.032287734638593
Validation loss: 3.0888532856147233

Epoch: 6| Step: 11
Training loss: 2.592502155946812
Validation loss: 3.0895408999580884

Epoch: 6| Step: 12
Training loss: 3.4501224772509493
Validation loss: 3.0881050179013405

Epoch: 6| Step: 13
Training loss: 3.432294059293354
Validation loss: 3.088808283745541

Epoch: 101| Step: 0
Training loss: 3.188154415196083
Validation loss: 3.086762455116816

Epoch: 6| Step: 1
Training loss: 3.0526737687921837
Validation loss: 3.0891853816439356

Epoch: 6| Step: 2
Training loss: 2.8272807510326796
Validation loss: 3.0894806838636426

Epoch: 6| Step: 3
Training loss: 3.716538484926064
Validation loss: 3.090006177586551

Epoch: 6| Step: 4
Training loss: 3.9170229864704758
Validation loss: 3.0896184834559546

Epoch: 6| Step: 5
Training loss: 3.4523266175728295
Validation loss: 3.0904764635486557

Epoch: 6| Step: 6
Training loss: 3.344379686620712
Validation loss: 3.0894076260456305

Epoch: 6| Step: 7
Training loss: 3.47715442204626
Validation loss: 3.092582503062243

Epoch: 6| Step: 8
Training loss: 4.423937205470848
Validation loss: 3.089028886313424

Epoch: 6| Step: 9
Training loss: 3.3191803561563713
Validation loss: 3.090800900296189

Epoch: 6| Step: 10
Training loss: 3.0108416476233
Validation loss: 3.0887660517239186

Epoch: 6| Step: 11
Training loss: 2.8702874744800786
Validation loss: 3.090624900925786

Epoch: 6| Step: 12
Training loss: 3.416822771057334
Validation loss: 3.0876743374542506

Epoch: 6| Step: 13
Training loss: 1.4150074704515576
Validation loss: 3.088470941816437

Epoch: 102| Step: 0
Training loss: 2.8379329670361533
Validation loss: 3.0869346991915068

Epoch: 6| Step: 1
Training loss: 2.974756208416367
Validation loss: 3.0873501583899734

Epoch: 6| Step: 2
Training loss: 3.2649477023599487
Validation loss: 3.0848167717711448

Epoch: 6| Step: 3
Training loss: 3.1624008525037595
Validation loss: 3.0860529703406514

Epoch: 6| Step: 4
Training loss: 3.4621505505879613
Validation loss: 3.0853159139183646

Epoch: 6| Step: 5
Training loss: 3.1692454896831443
Validation loss: 3.085391052388596

Epoch: 6| Step: 6
Training loss: 3.2033366807912853
Validation loss: 3.0866908512015416

Epoch: 6| Step: 7
Training loss: 2.8194013904443356
Validation loss: 3.086761773253788

Epoch: 6| Step: 8
Training loss: 3.131881461364256
Validation loss: 3.086067913265011

Epoch: 6| Step: 9
Training loss: 3.767978550033907
Validation loss: 3.0863059070476355

Epoch: 6| Step: 10
Training loss: 3.457389993965612
Validation loss: 3.086986586378225

Epoch: 6| Step: 11
Training loss: 3.723636526150456
Validation loss: 3.085885001177719

Epoch: 6| Step: 12
Training loss: 4.0253029655969685
Validation loss: 3.084805381362566

Epoch: 6| Step: 13
Training loss: 3.895971707149285
Validation loss: 3.0864795180253735

Epoch: 103| Step: 0
Training loss: 2.89272582548295
Validation loss: 3.0857050209852566

Epoch: 6| Step: 1
Training loss: 3.549300654123544
Validation loss: 3.0835211418665516

Epoch: 6| Step: 2
Training loss: 3.1942178581336194
Validation loss: 3.0843110340062303

Epoch: 6| Step: 3
Training loss: 3.6553081375256493
Validation loss: 3.0851135541289216

Epoch: 6| Step: 4
Training loss: 3.7286080877989716
Validation loss: 3.085232859348829

Epoch: 6| Step: 5
Training loss: 3.492356673885741
Validation loss: 3.0825444825122594

Epoch: 6| Step: 6
Training loss: 2.7795778884418834
Validation loss: 3.0851695461249107

Epoch: 6| Step: 7
Training loss: 3.7353996882112197
Validation loss: 3.0835184905296136

Epoch: 6| Step: 8
Training loss: 4.3392000587975375
Validation loss: 3.0830891833191223

Epoch: 6| Step: 9
Training loss: 3.5559349470249235
Validation loss: 3.082182857210011

Epoch: 6| Step: 10
Training loss: 3.0126630240368613
Validation loss: 3.080504802606806

Epoch: 6| Step: 11
Training loss: 2.5776176184560615
Validation loss: 3.083275438301184

Epoch: 6| Step: 12
Training loss: 2.9746645185302385
Validation loss: 3.0833821335788363

Epoch: 6| Step: 13
Training loss: 2.583352724638322
Validation loss: 3.0824833063799453

Epoch: 104| Step: 0
Training loss: 3.6034261718233176
Validation loss: 3.082297470132279

Epoch: 6| Step: 1
Training loss: 2.547336466353619
Validation loss: 3.082820659032669

Epoch: 6| Step: 2
Training loss: 3.32523646840353
Validation loss: 3.086175691574458

Epoch: 6| Step: 3
Training loss: 3.4742377234134487
Validation loss: 3.0809352687475067

Epoch: 6| Step: 4
Training loss: 3.0363387034663916
Validation loss: 3.080927325528023

Epoch: 6| Step: 5
Training loss: 2.846726588914659
Validation loss: 3.0799244747615893

Epoch: 6| Step: 6
Training loss: 3.460767479158316
Validation loss: 3.0781503470920977

Epoch: 6| Step: 7
Training loss: 3.5612489611810605
Validation loss: 3.07902700865762

Epoch: 6| Step: 8
Training loss: 3.782890531419734
Validation loss: 3.080299824694939

Epoch: 6| Step: 9
Training loss: 3.37661167799174
Validation loss: 3.081857961581024

Epoch: 6| Step: 10
Training loss: 2.6599769924000576
Validation loss: 3.080707847920816

Epoch: 6| Step: 11
Training loss: 4.202917611490214
Validation loss: 3.079815936630207

Epoch: 6| Step: 12
Training loss: 3.564431319496659
Validation loss: 3.0795704618991846

Epoch: 6| Step: 13
Training loss: 2.6491449812099237
Validation loss: 3.0785767039693366

Epoch: 105| Step: 0
Training loss: 3.0038094176322265
Validation loss: 3.07877759656067

Epoch: 6| Step: 1
Training loss: 2.7510382686325823
Validation loss: 3.079982963270382

Epoch: 6| Step: 2
Training loss: 3.750509608927853
Validation loss: 3.0780601246852988

Epoch: 6| Step: 3
Training loss: 3.4745344440170878
Validation loss: 3.079462176024143

Epoch: 6| Step: 4
Training loss: 3.3114942067329043
Validation loss: 3.080139328927264

Epoch: 6| Step: 5
Training loss: 2.8765367464304106
Validation loss: 3.079207922846028

Epoch: 6| Step: 6
Training loss: 2.8077900761986307
Validation loss: 3.0789771921333497

Epoch: 6| Step: 7
Training loss: 3.37523085193191
Validation loss: 3.0794159355066726

Epoch: 6| Step: 8
Training loss: 2.89666117812128
Validation loss: 3.078223267331687

Epoch: 6| Step: 9
Training loss: 3.026111140195036
Validation loss: 3.079993317754896

Epoch: 6| Step: 10
Training loss: 4.02997492060655
Validation loss: 3.07809026380076

Epoch: 6| Step: 11
Training loss: 3.643293851433154
Validation loss: 3.0793392038864846

Epoch: 6| Step: 12
Training loss: 4.133705432099055
Validation loss: 3.0804482730888343

Epoch: 6| Step: 13
Training loss: 3.3417409405020813
Validation loss: 3.0824058659912605

Epoch: 106| Step: 0
Training loss: 4.53617917007394
Validation loss: 3.076605658845954

Epoch: 6| Step: 1
Training loss: 3.255384679468145
Validation loss: 3.07755805308373

Epoch: 6| Step: 2
Training loss: 3.8683466243447087
Validation loss: 3.076968316210225

Epoch: 6| Step: 3
Training loss: 2.5648839142763125
Validation loss: 3.077365968844656

Epoch: 6| Step: 4
Training loss: 3.2847413879509255
Validation loss: 3.075037194790819

Epoch: 6| Step: 5
Training loss: 3.1446181385996397
Validation loss: 3.075224430135499

Epoch: 6| Step: 6
Training loss: 2.9361939468977227
Validation loss: 3.0757528779841277

Epoch: 6| Step: 7
Training loss: 2.4991491777300587
Validation loss: 3.075819092194204

Epoch: 6| Step: 8
Training loss: 2.362054982733272
Validation loss: 3.0759877143681833

Epoch: 6| Step: 9
Training loss: 3.7230324329948226
Validation loss: 3.0710304287387853

Epoch: 6| Step: 10
Training loss: 3.524499297597758
Validation loss: 3.077013388762517

Epoch: 6| Step: 11
Training loss: 3.370165152195983
Validation loss: 3.0754314285029563

Epoch: 6| Step: 12
Training loss: 3.8085026030760067
Validation loss: 3.0744678706853827

Epoch: 6| Step: 13
Training loss: 3.026477478125047
Validation loss: 3.0729103339984953

Epoch: 107| Step: 0
Training loss: 3.888079687730447
Validation loss: 3.0783422133288587

Epoch: 6| Step: 1
Training loss: 3.3384050092336413
Validation loss: 3.086322292410091

Epoch: 6| Step: 2
Training loss: 3.4687319918328297
Validation loss: 3.10091482756351

Epoch: 6| Step: 3
Training loss: 3.5716961406204266
Validation loss: 3.097714802610787

Epoch: 6| Step: 4
Training loss: 3.5925982412604824
Validation loss: 3.0804335608965294

Epoch: 6| Step: 5
Training loss: 2.330961611503235
Validation loss: 3.073597428027535

Epoch: 6| Step: 6
Training loss: 2.9965959946131613
Validation loss: 3.074176371757472

Epoch: 6| Step: 7
Training loss: 3.493943150730926
Validation loss: 3.0709570563762

Epoch: 6| Step: 8
Training loss: 4.301471485043869
Validation loss: 3.0723665788250614

Epoch: 6| Step: 9
Training loss: 3.300095707054602
Validation loss: 3.071652597956864

Epoch: 6| Step: 10
Training loss: 2.625316600780465
Validation loss: 3.0718570762993247

Epoch: 6| Step: 11
Training loss: 3.243580420146164
Validation loss: 3.0715264019062207

Epoch: 6| Step: 12
Training loss: 2.8129940870530046
Validation loss: 3.0731243037671376

Epoch: 6| Step: 13
Training loss: 3.4402294073570356
Validation loss: 3.0727282422367095

Epoch: 108| Step: 0
Training loss: 3.158942858443336
Validation loss: 3.072745818819649

Epoch: 6| Step: 1
Training loss: 2.9365283089417527
Validation loss: 3.0748394111580963

Epoch: 6| Step: 2
Training loss: 3.481516944608442
Validation loss: 3.0709153176696016

Epoch: 6| Step: 3
Training loss: 3.170999340335196
Validation loss: 3.0738171339366636

Epoch: 6| Step: 4
Training loss: 3.356617634278445
Validation loss: 3.077394731886641

Epoch: 6| Step: 5
Training loss: 3.527619512684089
Validation loss: 3.0847712938218863

Epoch: 6| Step: 6
Training loss: 3.50644920721599
Validation loss: 3.0740961485399616

Epoch: 6| Step: 7
Training loss: 3.9380368063598175
Validation loss: 3.0710191149187698

Epoch: 6| Step: 8
Training loss: 3.8712806079160744
Validation loss: 3.0710320089805276

Epoch: 6| Step: 9
Training loss: 2.8145303814865006
Validation loss: 3.068457749547216

Epoch: 6| Step: 10
Training loss: 3.494686180072881
Validation loss: 3.071044658398193

Epoch: 6| Step: 11
Training loss: 3.0494799311262564
Validation loss: 3.0689310385563933

Epoch: 6| Step: 12
Training loss: 3.535628853078155
Validation loss: 3.068665632102315

Epoch: 6| Step: 13
Training loss: 2.000036477709947
Validation loss: 3.0703389068722897

Epoch: 109| Step: 0
Training loss: 3.0837660477262823
Validation loss: 3.0689041133415844

Epoch: 6| Step: 1
Training loss: 3.8209512562721364
Validation loss: 3.0708899926720186

Epoch: 6| Step: 2
Training loss: 3.885792009293568
Validation loss: 3.0703535338405303

Epoch: 6| Step: 3
Training loss: 3.925185550264332
Validation loss: 3.0689946867800186

Epoch: 6| Step: 4
Training loss: 2.3002062663591394
Validation loss: 3.0718799831416854

Epoch: 6| Step: 5
Training loss: 2.9554940868222372
Validation loss: 3.070867918280072

Epoch: 6| Step: 6
Training loss: 2.5606857948823603
Validation loss: 3.070288001674071

Epoch: 6| Step: 7
Training loss: 3.6364197900077704
Validation loss: 3.067783120739577

Epoch: 6| Step: 8
Training loss: 3.6839479051648856
Validation loss: 3.0659113993425873

Epoch: 6| Step: 9
Training loss: 3.675641015648227
Validation loss: 3.0675472584448342

Epoch: 6| Step: 10
Training loss: 3.3364750520587223
Validation loss: 3.0675828720275025

Epoch: 6| Step: 11
Training loss: 3.147651668951432
Validation loss: 3.0712116286667293

Epoch: 6| Step: 12
Training loss: 2.989873962807891
Validation loss: 3.07763400278488

Epoch: 6| Step: 13
Training loss: 3.159968385900425
Validation loss: 3.0804456573896815

Epoch: 110| Step: 0
Training loss: 3.629466889172178
Validation loss: 3.0846711050043067

Epoch: 6| Step: 1
Training loss: 2.792240928305235
Validation loss: 3.091221509177972

Epoch: 6| Step: 2
Training loss: 3.4498049971161326
Validation loss: 3.099811767687974

Epoch: 6| Step: 3
Training loss: 2.8582317797653065
Validation loss: 3.113112119697978

Epoch: 6| Step: 4
Training loss: 3.468348711875784
Validation loss: 3.1009545338279496

Epoch: 6| Step: 5
Training loss: 2.9828114832800945
Validation loss: 3.0821550513019904

Epoch: 6| Step: 6
Training loss: 2.909016266862243
Validation loss: 3.0718414082813017

Epoch: 6| Step: 7
Training loss: 3.1832189795707446
Validation loss: 3.064061434604628

Epoch: 6| Step: 8
Training loss: 2.714091552157224
Validation loss: 3.0651737685149243

Epoch: 6| Step: 9
Training loss: 3.8723013309867076
Validation loss: 3.064646909478175

Epoch: 6| Step: 10
Training loss: 3.7966660179113068
Validation loss: 3.0659187744034626

Epoch: 6| Step: 11
Training loss: 3.0783781150888543
Validation loss: 3.0671758142355823

Epoch: 6| Step: 12
Training loss: 3.5039078830472783
Validation loss: 3.067202127754329

Epoch: 6| Step: 13
Training loss: 4.5868578219686595
Validation loss: 3.0660497682487327

Epoch: 111| Step: 0
Training loss: 2.964967586861228
Validation loss: 3.064257911021187

Epoch: 6| Step: 1
Training loss: 3.040751245432069
Validation loss: 3.0639511355312536

Epoch: 6| Step: 2
Training loss: 3.12202159090659
Validation loss: 3.063355323699809

Epoch: 6| Step: 3
Training loss: 3.0790758552288735
Validation loss: 3.062783262284085

Epoch: 6| Step: 4
Training loss: 3.812385932591746
Validation loss: 3.0649108204016526

Epoch: 6| Step: 5
Training loss: 3.037300285398472
Validation loss: 3.0652732489185173

Epoch: 6| Step: 6
Training loss: 3.6385001993350947
Validation loss: 3.0660288262655646

Epoch: 6| Step: 7
Training loss: 3.3472836085626723
Validation loss: 3.065251595745996

Epoch: 6| Step: 8
Training loss: 3.7391250598741554
Validation loss: 3.0640730610956246

Epoch: 6| Step: 9
Training loss: 2.7940733105947717
Validation loss: 3.0655082993601277

Epoch: 6| Step: 10
Training loss: 3.247651058263531
Validation loss: 3.064579620685887

Epoch: 6| Step: 11
Training loss: 3.990981664528972
Validation loss: 3.0639946684419193

Epoch: 6| Step: 12
Training loss: 2.951126310348947
Validation loss: 3.0663315889784326

Epoch: 6| Step: 13
Training loss: 3.812621443018075
Validation loss: 3.06672667932397

Epoch: 112| Step: 0
Training loss: 1.855728998504497
Validation loss: 3.0633407386351865

Epoch: 6| Step: 1
Training loss: 2.931783267318012
Validation loss: 3.0642164341246585

Epoch: 6| Step: 2
Training loss: 3.839611275388923
Validation loss: 3.0648620232696193

Epoch: 6| Step: 3
Training loss: 2.0622091377234173
Validation loss: 3.0648196478114587

Epoch: 6| Step: 4
Training loss: 3.5992527504091907
Validation loss: 3.06525489934922

Epoch: 6| Step: 5
Training loss: 2.8958638324549386
Validation loss: 3.062642015283006

Epoch: 6| Step: 6
Training loss: 4.003897437109203
Validation loss: 3.063700358894442

Epoch: 6| Step: 7
Training loss: 3.571794532009651
Validation loss: 3.0644463236489448

Epoch: 6| Step: 8
Training loss: 3.5964926164271
Validation loss: 3.0656397949335394

Epoch: 6| Step: 9
Training loss: 3.516674647992615
Validation loss: 3.0642235840266907

Epoch: 6| Step: 10
Training loss: 3.722900638784195
Validation loss: 3.0640898883049816

Epoch: 6| Step: 11
Training loss: 3.1167108080452905
Validation loss: 3.064988552265442

Epoch: 6| Step: 12
Training loss: 3.1501660015628294
Validation loss: 3.062003004318451

Epoch: 6| Step: 13
Training loss: 4.287597183594169
Validation loss: 3.0586021853941343

Epoch: 113| Step: 0
Training loss: 3.54861582245403
Validation loss: 3.058103124414967

Epoch: 6| Step: 1
Training loss: 3.5142548328243497
Validation loss: 3.057370742960611

Epoch: 6| Step: 2
Training loss: 2.6605865981861507
Validation loss: 3.056907432748191

Epoch: 6| Step: 3
Training loss: 3.1846788675054416
Validation loss: 3.056577878646959

Epoch: 6| Step: 4
Training loss: 4.083691769392889
Validation loss: 3.056861931232501

Epoch: 6| Step: 5
Training loss: 2.574462971657923
Validation loss: 3.0545846081303734

Epoch: 6| Step: 6
Training loss: 3.6353522498135735
Validation loss: 3.0559378680926126

Epoch: 6| Step: 7
Training loss: 3.0753257144767723
Validation loss: 3.0551566380637953

Epoch: 6| Step: 8
Training loss: 3.617780402018819
Validation loss: 3.0545785602989732

Epoch: 6| Step: 9
Training loss: 2.8267048173105276
Validation loss: 3.057399096258193

Epoch: 6| Step: 10
Training loss: 3.726942254956111
Validation loss: 3.052378948045714

Epoch: 6| Step: 11
Training loss: 3.1914056523484753
Validation loss: 3.0546214303192256

Epoch: 6| Step: 12
Training loss: 3.4462551635216463
Validation loss: 3.0577432290197555

Epoch: 6| Step: 13
Training loss: 2.8638335940324957
Validation loss: 3.0568467012905005

Epoch: 114| Step: 0
Training loss: 3.759893210091737
Validation loss: 3.060255112283964

Epoch: 6| Step: 1
Training loss: 3.5314646967884427
Validation loss: 3.0565457819954647

Epoch: 6| Step: 2
Training loss: 3.1830817624160375
Validation loss: 3.0597660936626663

Epoch: 6| Step: 3
Training loss: 2.747856605303364
Validation loss: 3.060452042477551

Epoch: 6| Step: 4
Training loss: 3.4131327395306865
Validation loss: 3.0591706449954477

Epoch: 6| Step: 5
Training loss: 3.016735919838922
Validation loss: 3.057429470905986

Epoch: 6| Step: 6
Training loss: 3.610747897800361
Validation loss: 3.0568177138718564

Epoch: 6| Step: 7
Training loss: 3.1805370798550685
Validation loss: 3.056741817261455

Epoch: 6| Step: 8
Training loss: 3.202984764937065
Validation loss: 3.064425768920615

Epoch: 6| Step: 9
Training loss: 3.4919081198543704
Validation loss: 3.0572020775825117

Epoch: 6| Step: 10
Training loss: 3.271421845251297
Validation loss: 3.0567054735103714

Epoch: 6| Step: 11
Training loss: 3.3797896977747124
Validation loss: 3.0552121461346395

Epoch: 6| Step: 12
Training loss: 3.463840343628364
Validation loss: 3.0554187533970776

Epoch: 6| Step: 13
Training loss: 2.982419476761069
Validation loss: 3.052895471750801

Epoch: 115| Step: 0
Training loss: 3.6356515599015604
Validation loss: 3.0507015729255738

Epoch: 6| Step: 1
Training loss: 4.092275339343986
Validation loss: 3.051945567141011

Epoch: 6| Step: 2
Training loss: 3.427838707012619
Validation loss: 3.0531902955195047

Epoch: 6| Step: 3
Training loss: 3.0593407353322517
Validation loss: 3.051025427911334

Epoch: 6| Step: 4
Training loss: 3.7623384307946663
Validation loss: 3.051435021571331

Epoch: 6| Step: 5
Training loss: 2.7497435363477147
Validation loss: 3.0528245178740345

Epoch: 6| Step: 6
Training loss: 3.2912878631372657
Validation loss: 3.0523947621583467

Epoch: 6| Step: 7
Training loss: 2.502896157232489
Validation loss: 3.0502133768366053

Epoch: 6| Step: 8
Training loss: 3.534085645897544
Validation loss: 3.0510528621272752

Epoch: 6| Step: 9
Training loss: 3.1295736794002664
Validation loss: 3.0507204797804546

Epoch: 6| Step: 10
Training loss: 3.2226399739172322
Validation loss: 3.049910364862935

Epoch: 6| Step: 11
Training loss: 2.761125773393712
Validation loss: 3.050335661574977

Epoch: 6| Step: 12
Training loss: 3.4820116179051674
Validation loss: 3.04806364531302

Epoch: 6| Step: 13
Training loss: 3.5880034568625376
Validation loss: 3.048751803296958

Epoch: 116| Step: 0
Training loss: 3.540500643398925
Validation loss: 3.047131643117123

Epoch: 6| Step: 1
Training loss: 2.8424800510427812
Validation loss: 3.050732336946429

Epoch: 6| Step: 2
Training loss: 4.000209326035278
Validation loss: 3.050523680229675

Epoch: 6| Step: 3
Training loss: 2.0537170903453363
Validation loss: 3.051272735305994

Epoch: 6| Step: 4
Training loss: 3.0690980795423575
Validation loss: 3.0537051557445776

Epoch: 6| Step: 5
Training loss: 3.216032936904926
Validation loss: 3.0503559649878564

Epoch: 6| Step: 6
Training loss: 3.842410963090406
Validation loss: 3.0493751316807702

Epoch: 6| Step: 7
Training loss: 2.841911308370399
Validation loss: 3.047915526431995

Epoch: 6| Step: 8
Training loss: 3.5790241560950813
Validation loss: 3.04927312408952

Epoch: 6| Step: 9
Training loss: 3.092088966283965
Validation loss: 3.049132955504401

Epoch: 6| Step: 10
Training loss: 3.0400262005831356
Validation loss: 3.050712157887968

Epoch: 6| Step: 11
Training loss: 3.407239297814047
Validation loss: 3.050918329597268

Epoch: 6| Step: 12
Training loss: 3.772436668718857
Validation loss: 3.049769630419905

Epoch: 6| Step: 13
Training loss: 3.982659782274305
Validation loss: 3.0500660700696516

Epoch: 117| Step: 0
Training loss: 2.5750077330834276
Validation loss: 3.048325066999614

Epoch: 6| Step: 1
Training loss: 2.817113694902519
Validation loss: 3.0471834626620335

Epoch: 6| Step: 2
Training loss: 3.255096401070363
Validation loss: 3.0464798529352097

Epoch: 6| Step: 3
Training loss: 2.977205302198353
Validation loss: 3.0476639880110445

Epoch: 6| Step: 4
Training loss: 2.872893349430951
Validation loss: 3.045866238411109

Epoch: 6| Step: 5
Training loss: 2.9857503707592934
Validation loss: 3.047131902246486

Epoch: 6| Step: 6
Training loss: 3.750918085247766
Validation loss: 3.0489419855422772

Epoch: 6| Step: 7
Training loss: 3.4405346046928327
Validation loss: 3.0472551073493563

Epoch: 6| Step: 8
Training loss: 2.7355800915893504
Validation loss: 3.0458810746448397

Epoch: 6| Step: 9
Training loss: 3.6290623494749927
Validation loss: 3.045512645512462

Epoch: 6| Step: 10
Training loss: 4.171684346503848
Validation loss: 3.045570466583694

Epoch: 6| Step: 11
Training loss: 4.212785135008668
Validation loss: 3.0443794558623907

Epoch: 6| Step: 12
Training loss: 3.320422648678468
Validation loss: 3.0448977634351664

Epoch: 6| Step: 13
Training loss: 3.012691513875239
Validation loss: 3.043762483470341

Epoch: 118| Step: 0
Training loss: 3.8067987055907877
Validation loss: 3.0449333203068853

Epoch: 6| Step: 1
Training loss: 3.859609125734702
Validation loss: 3.0418412867402562

Epoch: 6| Step: 2
Training loss: 3.228635699190663
Validation loss: 3.0427175769371377

Epoch: 6| Step: 3
Training loss: 2.889405689311689
Validation loss: 3.0443534132844037

Epoch: 6| Step: 4
Training loss: 3.0275510261702365
Validation loss: 3.052251961001164

Epoch: 6| Step: 5
Training loss: 3.3471927210632013
Validation loss: 3.05159971196652

Epoch: 6| Step: 6
Training loss: 3.1414027223754597
Validation loss: 3.053999898830566

Epoch: 6| Step: 7
Training loss: 3.5880624629253606
Validation loss: 3.0585154650128734

Epoch: 6| Step: 8
Training loss: 2.836659741451119
Validation loss: 3.054217292694984

Epoch: 6| Step: 9
Training loss: 2.9398326945546844
Validation loss: 3.054852639417429

Epoch: 6| Step: 10
Training loss: 3.122373774399943
Validation loss: 3.0450347787055767

Epoch: 6| Step: 11
Training loss: 3.6016554417068227
Validation loss: 3.041301938613486

Epoch: 6| Step: 12
Training loss: 3.761586790057912
Validation loss: 3.045460052553155

Epoch: 6| Step: 13
Training loss: 2.871954424302551
Validation loss: 3.0415934122467942

Epoch: 119| Step: 0
Training loss: 2.9716920429315117
Validation loss: 3.0413529555542405

Epoch: 6| Step: 1
Training loss: 3.280932892508105
Validation loss: 3.0428298825204187

Epoch: 6| Step: 2
Training loss: 3.5782385395809735
Validation loss: 3.0422427286111584

Epoch: 6| Step: 3
Training loss: 3.6031682537093066
Validation loss: 3.041312031982264

Epoch: 6| Step: 4
Training loss: 2.4166670393669456
Validation loss: 3.0408429339484186

Epoch: 6| Step: 5
Training loss: 2.516402604184238
Validation loss: 3.03961166050049

Epoch: 6| Step: 6
Training loss: 3.8385217356412396
Validation loss: 3.0422620866212076

Epoch: 6| Step: 7
Training loss: 3.6579021405394627
Validation loss: 3.040288621152424

Epoch: 6| Step: 8
Training loss: 2.8579471545983077
Validation loss: 3.042194518439929

Epoch: 6| Step: 9
Training loss: 3.1556961026778314
Validation loss: 3.04219240327596

Epoch: 6| Step: 10
Training loss: 3.3117212783721035
Validation loss: 3.0442183396259694

Epoch: 6| Step: 11
Training loss: 4.019271679088423
Validation loss: 3.045013636626155

Epoch: 6| Step: 12
Training loss: 3.2539384892985717
Validation loss: 3.0470490722742154

Epoch: 6| Step: 13
Training loss: 3.6038629628080625
Validation loss: 3.050610567288557

Epoch: 120| Step: 0
Training loss: 3.240564588169422
Validation loss: 3.051479437908482

Epoch: 6| Step: 1
Training loss: 3.380091464819684
Validation loss: 3.054853460157576

Epoch: 6| Step: 2
Training loss: 3.504369732706688
Validation loss: 3.0600911373663107

Epoch: 6| Step: 3
Training loss: 3.310128568705062
Validation loss: 3.055411436896489

Epoch: 6| Step: 4
Training loss: 3.3063796019797387
Validation loss: 3.0428471995975204

Epoch: 6| Step: 5
Training loss: 2.8412989858624504
Validation loss: 3.040716092403907

Epoch: 6| Step: 6
Training loss: 3.3566792872424296
Validation loss: 3.0389465365581954

Epoch: 6| Step: 7
Training loss: 2.6157215168964525
Validation loss: 3.0362450931406597

Epoch: 6| Step: 8
Training loss: 3.922020168581338
Validation loss: 3.0372313348182574

Epoch: 6| Step: 9
Training loss: 3.6339511194463516
Validation loss: 3.0357754663341514

Epoch: 6| Step: 10
Training loss: 3.427520693125957
Validation loss: 3.03714523407687

Epoch: 6| Step: 11
Training loss: 2.9163866362792272
Validation loss: 3.035474057756171

Epoch: 6| Step: 12
Training loss: 3.3184915732937283
Validation loss: 3.0371687960673577

Epoch: 6| Step: 13
Training loss: 3.420525829202608
Validation loss: 3.034993040910031

Epoch: 121| Step: 0
Training loss: 2.84094452020921
Validation loss: 3.0377253778419213

Epoch: 6| Step: 1
Training loss: 2.4864022482875345
Validation loss: 3.0354601765326694

Epoch: 6| Step: 2
Training loss: 3.923316964045374
Validation loss: 3.0343604984804817

Epoch: 6| Step: 3
Training loss: 2.4215857548421034
Validation loss: 3.039223631442753

Epoch: 6| Step: 4
Training loss: 4.34613761872858
Validation loss: 3.0351448793185463

Epoch: 6| Step: 5
Training loss: 3.040532323007104
Validation loss: 3.0353934552369544

Epoch: 6| Step: 6
Training loss: 3.2906225133815834
Validation loss: 3.0361904356153646

Epoch: 6| Step: 7
Training loss: 3.4767811224272664
Validation loss: 3.0344883584364384

Epoch: 6| Step: 8
Training loss: 3.2383104053836798
Validation loss: 3.034431458295387

Epoch: 6| Step: 9
Training loss: 3.328878541270212
Validation loss: 3.032776641291367

Epoch: 6| Step: 10
Training loss: 3.146834729873603
Validation loss: 3.035419265572876

Epoch: 6| Step: 11
Training loss: 3.8658121765263878
Validation loss: 3.0362203309119216

Epoch: 6| Step: 12
Training loss: 3.181343116221877
Validation loss: 3.0358704312830853

Epoch: 6| Step: 13
Training loss: 3.113353082266121
Validation loss: 3.0392317933144968

Epoch: 122| Step: 0
Training loss: 2.9511802769155713
Validation loss: 3.0392993986826897

Epoch: 6| Step: 1
Training loss: 2.631059283595941
Validation loss: 3.0455769161451034

Epoch: 6| Step: 2
Training loss: 3.057711536142158
Validation loss: 3.0414622298945626

Epoch: 6| Step: 3
Training loss: 3.647838077682617
Validation loss: 3.0471348511034333

Epoch: 6| Step: 4
Training loss: 4.01189846390309
Validation loss: 3.0429380886245427

Epoch: 6| Step: 5
Training loss: 3.509883821309035
Validation loss: 3.0400672367553225

Epoch: 6| Step: 6
Training loss: 3.6587754355361994
Validation loss: 3.038492967384913

Epoch: 6| Step: 7
Training loss: 3.6100492301817626
Validation loss: 3.0392630369864224

Epoch: 6| Step: 8
Training loss: 3.062543440530155
Validation loss: 3.033374312226673

Epoch: 6| Step: 9
Training loss: 2.4697420082800914
Validation loss: 3.0333530347856588

Epoch: 6| Step: 10
Training loss: 3.285356839799801
Validation loss: 3.035278407386994

Epoch: 6| Step: 11
Training loss: 3.604175207462371
Validation loss: 3.036413941552863

Epoch: 6| Step: 12
Training loss: 3.3144948458813484
Validation loss: 3.0324388089941157

Epoch: 6| Step: 13
Training loss: 2.8927027477796123
Validation loss: 3.035554381126755

Epoch: 123| Step: 0
Training loss: 3.1480541516485108
Validation loss: 3.0337743630445813

Epoch: 6| Step: 1
Training loss: 4.260991636742973
Validation loss: 3.035097970372773

Epoch: 6| Step: 2
Training loss: 3.796683098609829
Validation loss: 3.032380182933306

Epoch: 6| Step: 3
Training loss: 2.9210171179604494
Validation loss: 3.033170280640303

Epoch: 6| Step: 4
Training loss: 2.9717833431642515
Validation loss: 3.0301874952348133

Epoch: 6| Step: 5
Training loss: 3.2493210596889295
Validation loss: 3.0309320402952133

Epoch: 6| Step: 6
Training loss: 3.3397839278725034
Validation loss: 3.029424034724843

Epoch: 6| Step: 7
Training loss: 3.6216034597354625
Validation loss: 3.0338041317348043

Epoch: 6| Step: 8
Training loss: 3.2822951332654275
Validation loss: 3.029111875403094

Epoch: 6| Step: 9
Training loss: 3.3452949163552947
Validation loss: 3.0281693493015363

Epoch: 6| Step: 10
Training loss: 2.6859622370549996
Validation loss: 3.0304886817882046

Epoch: 6| Step: 11
Training loss: 2.877896881175418
Validation loss: 3.0294254581117595

Epoch: 6| Step: 12
Training loss: 2.551777993964396
Validation loss: 3.031866990391308

Epoch: 6| Step: 13
Training loss: 4.132230490534657
Validation loss: 3.032892059602822

Epoch: 124| Step: 0
Training loss: 2.868251842055639
Validation loss: 3.02678217786401

Epoch: 6| Step: 1
Training loss: 3.6061772965584855
Validation loss: 3.0264202494821295

Epoch: 6| Step: 2
Training loss: 2.829125327555949
Validation loss: 3.024754018332718

Epoch: 6| Step: 3
Training loss: 2.719583668541969
Validation loss: 3.0274787746225416

Epoch: 6| Step: 4
Training loss: 3.48949927992676
Validation loss: 3.0265984814610394

Epoch: 6| Step: 5
Training loss: 2.90269055354614
Validation loss: 3.025791151842343

Epoch: 6| Step: 6
Training loss: 3.072090080857784
Validation loss: 3.026331812328381

Epoch: 6| Step: 7
Training loss: 3.5711751684480886
Validation loss: 3.0267120136184067

Epoch: 6| Step: 8
Training loss: 3.1096240380011926
Validation loss: 3.024187313059733

Epoch: 6| Step: 9
Training loss: 3.966142413546348
Validation loss: 3.0271392890830775

Epoch: 6| Step: 10
Training loss: 3.245103228180554
Validation loss: 3.02653657259395

Epoch: 6| Step: 11
Training loss: 3.5036299818797585
Validation loss: 3.0270615228151025

Epoch: 6| Step: 12
Training loss: 3.5466945787158473
Validation loss: 3.0255000394818583

Epoch: 6| Step: 13
Training loss: 3.6848101099330273
Validation loss: 3.024653681598689

Epoch: 125| Step: 0
Training loss: 3.2716619005004968
Validation loss: 3.027955972119806

Epoch: 6| Step: 1
Training loss: 3.021069133807215
Validation loss: 3.0237025794733334

Epoch: 6| Step: 2
Training loss: 3.5780620985873983
Validation loss: 3.0255862945268954

Epoch: 6| Step: 3
Training loss: 3.968445773742015
Validation loss: 3.02598432246839

Epoch: 6| Step: 4
Training loss: 2.9804405921015897
Validation loss: 3.0280097546922558

Epoch: 6| Step: 5
Training loss: 4.092920350314499
Validation loss: 3.0318661668108784

Epoch: 6| Step: 6
Training loss: 3.641943565915992
Validation loss: 3.0287170585181777

Epoch: 6| Step: 7
Training loss: 3.346511128624674
Validation loss: 3.0240081971769754

Epoch: 6| Step: 8
Training loss: 3.1172248245337477
Validation loss: 3.0211328348805067

Epoch: 6| Step: 9
Training loss: 2.6225425479662965
Validation loss: 3.022364182182352

Epoch: 6| Step: 10
Training loss: 3.059068275171086
Validation loss: 3.0221046451524467

Epoch: 6| Step: 11
Training loss: 3.3377259081560418
Validation loss: 3.020317674075416

Epoch: 6| Step: 12
Training loss: 3.018048039361784
Validation loss: 3.0203158236944625

Epoch: 6| Step: 13
Training loss: 2.3085281698397364
Validation loss: 3.0217893627248

Epoch: 126| Step: 0
Training loss: 3.2991690947878705
Validation loss: 3.021455421650806

Epoch: 6| Step: 1
Training loss: 3.2965553454152325
Validation loss: 3.021257797705582

Epoch: 6| Step: 2
Training loss: 2.6887606835430145
Validation loss: 3.020873882854642

Epoch: 6| Step: 3
Training loss: 3.1747979287551096
Validation loss: 3.0207532425823005

Epoch: 6| Step: 4
Training loss: 3.458553138703007
Validation loss: 3.0248341568378962

Epoch: 6| Step: 5
Training loss: 3.3929057383104615
Validation loss: 3.024321077399265

Epoch: 6| Step: 6
Training loss: 3.8492795047103687
Validation loss: 3.0315217996892794

Epoch: 6| Step: 7
Training loss: 2.8328117189653503
Validation loss: 3.0266395040277763

Epoch: 6| Step: 8
Training loss: 3.2693009563178728
Validation loss: 3.026456585899239

Epoch: 6| Step: 9
Training loss: 3.9133272070460374
Validation loss: 3.021444601830767

Epoch: 6| Step: 10
Training loss: 3.55324516797742
Validation loss: 3.0254473630088548

Epoch: 6| Step: 11
Training loss: 2.9477726302437675
Validation loss: 3.022088305222095

Epoch: 6| Step: 12
Training loss: 2.9613117394184587
Validation loss: 3.022939289229685

Epoch: 6| Step: 13
Training loss: 3.251314044279077
Validation loss: 3.02007708873042

Epoch: 127| Step: 0
Training loss: 3.764015455256807
Validation loss: 3.017859805124172

Epoch: 6| Step: 1
Training loss: 2.862248545434139
Validation loss: 3.0179954706670404

Epoch: 6| Step: 2
Training loss: 3.3813862602151037
Validation loss: 3.0190280078451974

Epoch: 6| Step: 3
Training loss: 3.0848621667770986
Validation loss: 3.0184063376571117

Epoch: 6| Step: 4
Training loss: 3.2263371201834645
Validation loss: 3.0205555811833738

Epoch: 6| Step: 5
Training loss: 3.2580256037914954
Validation loss: 3.0184940303071413

Epoch: 6| Step: 6
Training loss: 3.479081036699823
Validation loss: 3.016959816746174

Epoch: 6| Step: 7
Training loss: 2.951001892647674
Validation loss: 3.0175466296160587

Epoch: 6| Step: 8
Training loss: 3.6697601071568138
Validation loss: 3.0180098909204434

Epoch: 6| Step: 9
Training loss: 3.1219895167153378
Validation loss: 3.017468147996354

Epoch: 6| Step: 10
Training loss: 3.2529471313045497
Validation loss: 3.016861290829736

Epoch: 6| Step: 11
Training loss: 3.814830130498676
Validation loss: 3.016615182068653

Epoch: 6| Step: 12
Training loss: 2.861709059007103
Validation loss: 3.017536354804619

Epoch: 6| Step: 13
Training loss: 3.094584805151084
Validation loss: 3.0172456618651986

Epoch: 128| Step: 0
Training loss: 3.2199689908637357
Validation loss: 3.0161977066106074

Epoch: 6| Step: 1
Training loss: 2.6525710714959474
Validation loss: 3.0177978843396684

Epoch: 6| Step: 2
Training loss: 3.0950228452070454
Validation loss: 3.019243841554002

Epoch: 6| Step: 3
Training loss: 3.247536973045324
Validation loss: 3.019405390437911

Epoch: 6| Step: 4
Training loss: 4.039689566894342
Validation loss: 3.021570103252407

Epoch: 6| Step: 5
Training loss: 3.3140482613106133
Validation loss: 3.0186480234767195

Epoch: 6| Step: 6
Training loss: 3.3487482949338347
Validation loss: 3.0278432393123205

Epoch: 6| Step: 7
Training loss: 3.2843302483236534
Validation loss: 3.029566681510383

Epoch: 6| Step: 8
Training loss: 3.1666969164022567
Validation loss: 3.051431077939291

Epoch: 6| Step: 9
Training loss: 2.9648900688081485
Validation loss: 3.0340502412274453

Epoch: 6| Step: 10
Training loss: 3.6420268360052113
Validation loss: 3.0237954530289706

Epoch: 6| Step: 11
Training loss: 3.5564440736292395
Validation loss: 3.0149343487037683

Epoch: 6| Step: 12
Training loss: 3.254319914572671
Validation loss: 3.014217558555063

Epoch: 6| Step: 13
Training loss: 2.9889417928041833
Validation loss: 3.013366919850419

Epoch: 129| Step: 0
Training loss: 3.360907342652212
Validation loss: 3.0162931774545942

Epoch: 6| Step: 1
Training loss: 3.7491894163815234
Validation loss: 3.0156704674311645

Epoch: 6| Step: 2
Training loss: 3.168000960744847
Validation loss: 3.0181164318286866

Epoch: 6| Step: 3
Training loss: 3.827524940015789
Validation loss: 3.0177928459090366

Epoch: 6| Step: 4
Training loss: 2.899659097299922
Validation loss: 3.0176701387094007

Epoch: 6| Step: 5
Training loss: 2.9168292045717346
Validation loss: 3.017744484702369

Epoch: 6| Step: 6
Training loss: 3.165088477803845
Validation loss: 3.0173761264280734

Epoch: 6| Step: 7
Training loss: 2.99737656645406
Validation loss: 3.016980492623211

Epoch: 6| Step: 8
Training loss: 3.200710372754584
Validation loss: 3.015464544238236

Epoch: 6| Step: 9
Training loss: 3.166385956084347
Validation loss: 3.0176268320931174

Epoch: 6| Step: 10
Training loss: 3.4570454570241265
Validation loss: 3.0161518969394936

Epoch: 6| Step: 11
Training loss: 3.644154683536903
Validation loss: 3.0143535946888615

Epoch: 6| Step: 12
Training loss: 3.2027878002294097
Validation loss: 3.0152868614429575

Epoch: 6| Step: 13
Training loss: 3.1514870236937758
Validation loss: 3.014774493952687

Epoch: 130| Step: 0
Training loss: 3.3390752610929817
Validation loss: 3.014853025284586

Epoch: 6| Step: 1
Training loss: 3.7609297102121237
Validation loss: 3.0125961365301626

Epoch: 6| Step: 2
Training loss: 2.9413736653137876
Validation loss: 3.014134906816477

Epoch: 6| Step: 3
Training loss: 3.8851879690054116
Validation loss: 3.0124726857723245

Epoch: 6| Step: 4
Training loss: 3.1926534543239637
Validation loss: 3.0121612608916055

Epoch: 6| Step: 5
Training loss: 2.807568189110485
Validation loss: 3.0123520877584493

Epoch: 6| Step: 6
Training loss: 3.19978001553656
Validation loss: 3.0101843067696756

Epoch: 6| Step: 7
Training loss: 2.7383838150036466
Validation loss: 3.0110064910634415

Epoch: 6| Step: 8
Training loss: 3.034857736486653
Validation loss: 3.011680359652438

Epoch: 6| Step: 9
Training loss: 2.654028109093312
Validation loss: 3.0110822293087454

Epoch: 6| Step: 10
Training loss: 3.4494938465289673
Validation loss: 3.011570133222705

Epoch: 6| Step: 11
Training loss: 3.9011036656150897
Validation loss: 3.0109190860997948

Epoch: 6| Step: 12
Training loss: 3.343408442370182
Validation loss: 3.010715089309036

Epoch: 6| Step: 13
Training loss: 3.6580268911100124
Validation loss: 3.011629782388971

Epoch: 131| Step: 0
Training loss: 3.3750228881059843
Validation loss: 3.0124672520765112

Epoch: 6| Step: 1
Training loss: 2.633540565046485
Validation loss: 3.0097184073799435

Epoch: 6| Step: 2
Training loss: 3.6108575063483666
Validation loss: 3.0100730111964427

Epoch: 6| Step: 3
Training loss: 3.7083582216492035
Validation loss: 3.010381806913321

Epoch: 6| Step: 4
Training loss: 3.8279169765704952
Validation loss: 3.0096078007356084

Epoch: 6| Step: 5
Training loss: 3.0821726564716907
Validation loss: 3.0135282163596773

Epoch: 6| Step: 6
Training loss: 2.891218959511434
Validation loss: 3.008904869289726

Epoch: 6| Step: 7
Training loss: 2.8843014394652253
Validation loss: 3.0094974839144863

Epoch: 6| Step: 8
Training loss: 4.132158945252242
Validation loss: 3.0103538709028705

Epoch: 6| Step: 9
Training loss: 3.007478294135681
Validation loss: 3.007906168456831

Epoch: 6| Step: 10
Training loss: 3.572538053658271
Validation loss: 3.009840557196825

Epoch: 6| Step: 11
Training loss: 3.318647186928154
Validation loss: 3.0104811631291035

Epoch: 6| Step: 12
Training loss: 2.91433951771648
Validation loss: 3.0084599808437216

Epoch: 6| Step: 13
Training loss: 2.0616681126327605
Validation loss: 3.0094477584596797

Epoch: 132| Step: 0
Training loss: 3.694593944408844
Validation loss: 3.0085896760446107

Epoch: 6| Step: 1
Training loss: 3.1352938673404314
Validation loss: 3.009497425136831

Epoch: 6| Step: 2
Training loss: 3.394546420960057
Validation loss: 3.0111675538789497

Epoch: 6| Step: 3
Training loss: 3.1730822440860833
Validation loss: 3.009649631564658

Epoch: 6| Step: 4
Training loss: 3.1978437848230405
Validation loss: 3.009949134151851

Epoch: 6| Step: 5
Training loss: 3.1305047951116123
Validation loss: 3.009280916242461

Epoch: 6| Step: 6
Training loss: 2.839887741986461
Validation loss: 3.0087427702328053

Epoch: 6| Step: 7
Training loss: 3.4350636951921074
Validation loss: 3.007913364423321

Epoch: 6| Step: 8
Training loss: 3.789816492313336
Validation loss: 3.008958971936329

Epoch: 6| Step: 9
Training loss: 3.199270320192565
Validation loss: 3.007823776268727

Epoch: 6| Step: 10
Training loss: 3.6845017221286045
Validation loss: 3.0081159899086405

Epoch: 6| Step: 11
Training loss: 2.8656284344734737
Validation loss: 3.0113033157490494

Epoch: 6| Step: 12
Training loss: 3.13124863554112
Validation loss: 3.010231977820244

Epoch: 6| Step: 13
Training loss: 3.011055760815261
Validation loss: 3.0124912419611176

Epoch: 133| Step: 0
Training loss: 2.627894576740784
Validation loss: 3.0131826021331407

Epoch: 6| Step: 1
Training loss: 3.4812406803465215
Validation loss: 3.015805428996646

Epoch: 6| Step: 2
Training loss: 3.3574872057707177
Validation loss: 3.0178993511562164

Epoch: 6| Step: 3
Training loss: 3.715259099578649
Validation loss: 3.013235426653118

Epoch: 6| Step: 4
Training loss: 3.913368391977132
Validation loss: 3.011829539585976

Epoch: 6| Step: 5
Training loss: 3.872297021066482
Validation loss: 3.0075018737403614

Epoch: 6| Step: 6
Training loss: 2.413119431266692
Validation loss: 3.0067833177252035

Epoch: 6| Step: 7
Training loss: 2.6087958327006557
Validation loss: 3.006940118800029

Epoch: 6| Step: 8
Training loss: 3.3743932673127106
Validation loss: 3.0050435466326424

Epoch: 6| Step: 9
Training loss: 2.38154963813355
Validation loss: 3.0041008338498063

Epoch: 6| Step: 10
Training loss: 3.3183264683017453
Validation loss: 3.0042458606336706

Epoch: 6| Step: 11
Training loss: 3.5535968826160045
Validation loss: 3.010006336977748

Epoch: 6| Step: 12
Training loss: 3.259458715985803
Validation loss: 3.0067016203663703

Epoch: 6| Step: 13
Training loss: 3.713876431835063
Validation loss: 3.0073631962111746

Epoch: 134| Step: 0
Training loss: 3.709576873299495
Validation loss: 3.009779083001894

Epoch: 6| Step: 1
Training loss: 3.2085785379878167
Validation loss: 3.000313764660273

Epoch: 6| Step: 2
Training loss: 3.355631601203142
Validation loss: 3.009937273896215

Epoch: 6| Step: 3
Training loss: 3.42786847583125
Validation loss: 3.0061960735988564

Epoch: 6| Step: 4
Training loss: 3.6667873767288026
Validation loss: 3.0084181863067156

Epoch: 6| Step: 5
Training loss: 3.3892591687583726
Validation loss: 3.0059746234658773

Epoch: 6| Step: 6
Training loss: 2.8510649782695134
Validation loss: 3.0094812109786466

Epoch: 6| Step: 7
Training loss: 3.598749282587741
Validation loss: 3.0120768343160087

Epoch: 6| Step: 8
Training loss: 3.0617519165641074
Validation loss: 3.0058145335890716

Epoch: 6| Step: 9
Training loss: 3.431280439620502
Validation loss: 3.00571055891692

Epoch: 6| Step: 10
Training loss: 2.7584538132861605
Validation loss: 2.9993420489538285

Epoch: 6| Step: 11
Training loss: 3.278751112035693
Validation loss: 3.003430066862132

Epoch: 6| Step: 12
Training loss: 2.7833264775296445
Validation loss: 3.000391028840426

Epoch: 6| Step: 13
Training loss: 3.0784743057573984
Validation loss: 2.998139736956237

Epoch: 135| Step: 0
Training loss: 3.3315837242052253
Validation loss: 2.9988370199875067

Epoch: 6| Step: 1
Training loss: 3.4267967745897012
Validation loss: 2.9984428627113986

Epoch: 6| Step: 2
Training loss: 3.4558837365444885
Validation loss: 2.9998835725649546

Epoch: 6| Step: 3
Training loss: 3.853482833544908
Validation loss: 2.999452482870694

Epoch: 6| Step: 4
Training loss: 2.908758905820897
Validation loss: 3.0003133408493166

Epoch: 6| Step: 5
Training loss: 2.082448949657515
Validation loss: 2.9982436090680715

Epoch: 6| Step: 6
Training loss: 2.9838436912014927
Validation loss: 3.0011831483379634

Epoch: 6| Step: 7
Training loss: 3.3836558922658826
Validation loss: 3.0012925766225385

Epoch: 6| Step: 8
Training loss: 2.2232963297374955
Validation loss: 2.999662607629193

Epoch: 6| Step: 9
Training loss: 4.167639707753368
Validation loss: 2.9994281827150577

Epoch: 6| Step: 10
Training loss: 3.3682362633606733
Validation loss: 2.998263362309832

Epoch: 6| Step: 11
Training loss: 3.68154620547858
Validation loss: 2.9988398769893596

Epoch: 6| Step: 12
Training loss: 3.38823183044322
Validation loss: 2.994726084686169

Epoch: 6| Step: 13
Training loss: 2.7002839610222122
Validation loss: 2.9980029086716105

Epoch: 136| Step: 0
Training loss: 3.1326246704719996
Validation loss: 2.9960418862253353

Epoch: 6| Step: 1
Training loss: 3.9996976738165593
Validation loss: 2.999958863540328

Epoch: 6| Step: 2
Training loss: 3.7267672244604304
Validation loss: 2.9961746105865954

Epoch: 6| Step: 3
Training loss: 3.2093353358179155
Validation loss: 3.0071581815603494

Epoch: 6| Step: 4
Training loss: 2.4237522848038826
Validation loss: 3.0099846456496735

Epoch: 6| Step: 5
Training loss: 3.279700503748339
Validation loss: 3.001580678174342

Epoch: 6| Step: 6
Training loss: 3.4694204971169795
Validation loss: 3.024357830658072

Epoch: 6| Step: 7
Training loss: 3.8242011688420563
Validation loss: 3.0172695661766182

Epoch: 6| Step: 8
Training loss: 2.8973080472912156
Validation loss: 3.0057265955384436

Epoch: 6| Step: 9
Training loss: 3.7615372246570242
Validation loss: 2.9998009232812093

Epoch: 6| Step: 10
Training loss: 2.3339796760543705
Validation loss: 2.9976296648734015

Epoch: 6| Step: 11
Training loss: 2.704892148672421
Validation loss: 2.9930209844259874

Epoch: 6| Step: 12
Training loss: 3.4073909983339665
Validation loss: 2.993073380200395

Epoch: 6| Step: 13
Training loss: 2.984123818577173
Validation loss: 2.9950291476403867

Epoch: 137| Step: 0
Training loss: 3.2510569394351903
Validation loss: 2.996378052132385

Epoch: 6| Step: 1
Training loss: 3.4123898387077523
Validation loss: 2.99761635501453

Epoch: 6| Step: 2
Training loss: 2.7508316516456985
Validation loss: 2.9961459243320983

Epoch: 6| Step: 3
Training loss: 3.691487887655468
Validation loss: 2.9960565276587308

Epoch: 6| Step: 4
Training loss: 2.956227121405756
Validation loss: 2.9963344822681632

Epoch: 6| Step: 5
Training loss: 3.687802059927176
Validation loss: 2.996315469236311

Epoch: 6| Step: 6
Training loss: 3.47168751647324
Validation loss: 2.9975890911282286

Epoch: 6| Step: 7
Training loss: 2.9713420594637667
Validation loss: 2.9971578886729504

Epoch: 6| Step: 8
Training loss: 3.6985264808126574
Validation loss: 2.9969795191459316

Epoch: 6| Step: 9
Training loss: 2.567142096574778
Validation loss: 2.996554239929911

Epoch: 6| Step: 10
Training loss: 3.052172628057732
Validation loss: 2.997580189837712

Epoch: 6| Step: 11
Training loss: 3.4932329972492946
Validation loss: 2.9972970092957465

Epoch: 6| Step: 12
Training loss: 3.5744273974277925
Validation loss: 2.9966788948336394

Epoch: 6| Step: 13
Training loss: 2.792067503738864
Validation loss: 2.997410920028727

Epoch: 138| Step: 0
Training loss: 3.159292284508136
Validation loss: 2.997769095412934

Epoch: 6| Step: 1
Training loss: 3.02757795843023
Validation loss: 2.996511363049783

Epoch: 6| Step: 2
Training loss: 3.7106717626893277
Validation loss: 2.9953269196968395

Epoch: 6| Step: 3
Training loss: 3.805286023571869
Validation loss: 2.994839281699661

Epoch: 6| Step: 4
Training loss: 2.65834734523353
Validation loss: 2.9986563052421995

Epoch: 6| Step: 5
Training loss: 3.6014586990193553
Validation loss: 2.9977627516600465

Epoch: 6| Step: 6
Training loss: 3.122782416296603
Validation loss: 2.9934693543985653

Epoch: 6| Step: 7
Training loss: 3.0597955089382287
Validation loss: 2.9939666875832134

Epoch: 6| Step: 8
Training loss: 3.333423390761395
Validation loss: 2.991847641390629

Epoch: 6| Step: 9
Training loss: 2.8810924164217453
Validation loss: 2.9901897725313016

Epoch: 6| Step: 10
Training loss: 3.2121962704294305
Validation loss: 2.992509060662109

Epoch: 6| Step: 11
Training loss: 3.2126576069566037
Validation loss: 2.991249929947067

Epoch: 6| Step: 12
Training loss: 3.309290500675165
Validation loss: 2.9917074173008498

Epoch: 6| Step: 13
Training loss: 3.733237504296876
Validation loss: 2.991609030636917

Epoch: 139| Step: 0
Training loss: 2.8568539371185544
Validation loss: 2.997324605133077

Epoch: 6| Step: 1
Training loss: 3.5052310816275596
Validation loss: 2.9976150952657825

Epoch: 6| Step: 2
Training loss: 3.194936566984268
Validation loss: 2.995578696195656

Epoch: 6| Step: 3
Training loss: 2.8893069999890195
Validation loss: 2.99734574147043

Epoch: 6| Step: 4
Training loss: 3.5946294620646864
Validation loss: 2.9977412411238236

Epoch: 6| Step: 5
Training loss: 3.01977585447044
Validation loss: 3.0007095147351093

Epoch: 6| Step: 6
Training loss: 3.292438143045553
Validation loss: 2.993170813413842

Epoch: 6| Step: 7
Training loss: 3.4835198554760805
Validation loss: 2.994460609546075

Epoch: 6| Step: 8
Training loss: 2.624683451866846
Validation loss: 2.9851585098009297

Epoch: 6| Step: 9
Training loss: 3.76400912109632
Validation loss: 2.984237410879528

Epoch: 6| Step: 10
Training loss: 3.222316950651587
Validation loss: 2.9873558619615816

Epoch: 6| Step: 11
Training loss: 3.0674950482888894
Validation loss: 2.9863384728483906

Epoch: 6| Step: 12
Training loss: 3.861515085019228
Validation loss: 2.9854399397013696

Epoch: 6| Step: 13
Training loss: 2.9870574240284298
Validation loss: 2.9832453042115703

Epoch: 140| Step: 0
Training loss: 3.9229593791584616
Validation loss: 2.9844434460040743

Epoch: 6| Step: 1
Training loss: 3.4736415979822834
Validation loss: 2.98488824665227

Epoch: 6| Step: 2
Training loss: 2.745725864821497
Validation loss: 2.989442607123917

Epoch: 6| Step: 3
Training loss: 3.270973315959001
Validation loss: 2.995424760597551

Epoch: 6| Step: 4
Training loss: 3.293038110692635
Validation loss: 2.9897027509387315

Epoch: 6| Step: 5
Training loss: 2.55023495956726
Validation loss: 2.9896137661474875

Epoch: 6| Step: 6
Training loss: 2.9037236543955403
Validation loss: 2.9890340842394836

Epoch: 6| Step: 7
Training loss: 2.994654980180085
Validation loss: 2.9886100985414585

Epoch: 6| Step: 8
Training loss: 3.817478369031377
Validation loss: 2.9885203529188376

Epoch: 6| Step: 9
Training loss: 4.087695821101968
Validation loss: 2.9923511041542565

Epoch: 6| Step: 10
Training loss: 2.9258451365688503
Validation loss: 2.9856471261578568

Epoch: 6| Step: 11
Training loss: 3.5350024785271876
Validation loss: 2.9879308613233744

Epoch: 6| Step: 12
Training loss: 2.6635695194304327
Validation loss: 2.9856642837514444

Epoch: 6| Step: 13
Training loss: 2.926454596457453
Validation loss: 2.9840424166631108

Epoch: 141| Step: 0
Training loss: 3.0646277062483906
Validation loss: 2.983100451870703

Epoch: 6| Step: 1
Training loss: 3.012574703825678
Validation loss: 2.9862123320711174

Epoch: 6| Step: 2
Training loss: 3.8655020691946658
Validation loss: 2.983486430459196

Epoch: 6| Step: 3
Training loss: 3.7745064115885465
Validation loss: 2.981721515877274

Epoch: 6| Step: 4
Training loss: 3.742519164867677
Validation loss: 2.982659129520083

Epoch: 6| Step: 5
Training loss: 2.9198541027356497
Validation loss: 2.9811451167767653

Epoch: 6| Step: 6
Training loss: 3.566274015851858
Validation loss: 2.9824579549396137

Epoch: 6| Step: 7
Training loss: 3.772053909167332
Validation loss: 2.983477500841457

Epoch: 6| Step: 8
Training loss: 2.8673080710024244
Validation loss: 2.980972772326436

Epoch: 6| Step: 9
Training loss: 3.6633753020289395
Validation loss: 2.9823008629585024

Epoch: 6| Step: 10
Training loss: 2.377961470687235
Validation loss: 2.983464345245461

Epoch: 6| Step: 11
Training loss: 2.8751051510364976
Validation loss: 2.9806291991841953

Epoch: 6| Step: 12
Training loss: 2.867215605969618
Validation loss: 2.9805994885848843

Epoch: 6| Step: 13
Training loss: 2.452179744859384
Validation loss: 2.980129855260522

Epoch: 142| Step: 0
Training loss: 2.468201588427437
Validation loss: 2.9793895038885427

Epoch: 6| Step: 1
Training loss: 3.7615151672098057
Validation loss: 2.981254240922884

Epoch: 6| Step: 2
Training loss: 3.9276615327656224
Validation loss: 2.9819374827101286

Epoch: 6| Step: 3
Training loss: 3.7906990213863914
Validation loss: 2.9876259773992833

Epoch: 6| Step: 4
Training loss: 2.64946040651851
Validation loss: 2.9949553231584276

Epoch: 6| Step: 5
Training loss: 3.0064778326864574
Validation loss: 2.9924092071020296

Epoch: 6| Step: 6
Training loss: 2.8934584468681144
Validation loss: 3.003833172831499

Epoch: 6| Step: 7
Training loss: 2.8350396534671183
Validation loss: 3.0069662765261946

Epoch: 6| Step: 8
Training loss: 2.729211607895472
Validation loss: 3.0044541091310033

Epoch: 6| Step: 9
Training loss: 3.0975198607466146
Validation loss: 2.99253070903918

Epoch: 6| Step: 10
Training loss: 4.020630088505252
Validation loss: 2.9806866232402687

Epoch: 6| Step: 11
Training loss: 3.1239167434011663
Validation loss: 2.9829810057238344

Epoch: 6| Step: 12
Training loss: 3.1898059357833954
Validation loss: 2.982239152895426

Epoch: 6| Step: 13
Training loss: 3.9335330174293115
Validation loss: 2.982337055251532

Epoch: 143| Step: 0
Training loss: 2.634233493104096
Validation loss: 2.982637301194086

Epoch: 6| Step: 1
Training loss: 3.421468074762805
Validation loss: 2.98148741807466

Epoch: 6| Step: 2
Training loss: 3.2022370386968473
Validation loss: 2.982414501483617

Epoch: 6| Step: 3
Training loss: 3.4502446516338416
Validation loss: 2.9811397953912606

Epoch: 6| Step: 4
Training loss: 3.88234850684336
Validation loss: 2.9804879587362714

Epoch: 6| Step: 5
Training loss: 3.1879656582446074
Validation loss: 2.984184913227476

Epoch: 6| Step: 6
Training loss: 3.1953996492546954
Validation loss: 2.983116093550099

Epoch: 6| Step: 7
Training loss: 3.144082666470243
Validation loss: 2.9823712055605545

Epoch: 6| Step: 8
Training loss: 2.7538910128124567
Validation loss: 2.9841626201307285

Epoch: 6| Step: 9
Training loss: 3.847393139203522
Validation loss: 2.9825386333797392

Epoch: 6| Step: 10
Training loss: 3.060175577998143
Validation loss: 2.9801950481849713

Epoch: 6| Step: 11
Training loss: 3.135888926952391
Validation loss: 2.9824541573432324

Epoch: 6| Step: 12
Training loss: 3.327556436176177
Validation loss: 2.97995802590931

Epoch: 6| Step: 13
Training loss: 3.194018113440244
Validation loss: 2.980783885963652

Epoch: 144| Step: 0
Training loss: 3.214649440228214
Validation loss: 2.9809183285832264

Epoch: 6| Step: 1
Training loss: 2.507173926316592
Validation loss: 2.9799804407906487

Epoch: 6| Step: 2
Training loss: 3.516070392793648
Validation loss: 2.979855233603339

Epoch: 6| Step: 3
Training loss: 2.8237390387779557
Validation loss: 2.980075122555053

Epoch: 6| Step: 4
Training loss: 3.29111820593095
Validation loss: 2.9767450753525417

Epoch: 6| Step: 5
Training loss: 3.2230801390254893
Validation loss: 2.9764522727697935

Epoch: 6| Step: 6
Training loss: 4.065752341455488
Validation loss: 2.975311523710858

Epoch: 6| Step: 7
Training loss: 3.681428728152801
Validation loss: 2.9741709947971042

Epoch: 6| Step: 8
Training loss: 3.0263556855319504
Validation loss: 2.974695847432389

Epoch: 6| Step: 9
Training loss: 2.8422904827970403
Validation loss: 2.974821984464739

Epoch: 6| Step: 10
Training loss: 3.6664674589200072
Validation loss: 2.9774099555051796

Epoch: 6| Step: 11
Training loss: 3.0412984825500007
Validation loss: 2.974289842313389

Epoch: 6| Step: 12
Training loss: 3.2972909384764617
Validation loss: 2.976804959875401

Epoch: 6| Step: 13
Training loss: 2.9368928322389705
Validation loss: 2.974298170305097

Epoch: 145| Step: 0
Training loss: 3.5613705367165154
Validation loss: 2.983057490756833

Epoch: 6| Step: 1
Training loss: 2.9432749694993743
Validation loss: 2.9776823799649534

Epoch: 6| Step: 2
Training loss: 2.512060352784928
Validation loss: 2.983141268223005

Epoch: 6| Step: 3
Training loss: 3.326270504629878
Validation loss: 2.982160294848282

Epoch: 6| Step: 4
Training loss: 3.963969437736384
Validation loss: 2.9873769452552335

Epoch: 6| Step: 5
Training loss: 3.2347625647646585
Validation loss: 2.9790951781699224

Epoch: 6| Step: 6
Training loss: 3.5987278173941584
Validation loss: 2.9773339066025057

Epoch: 6| Step: 7
Training loss: 3.0431215299318986
Validation loss: 2.9727769026535245

Epoch: 6| Step: 8
Training loss: 3.42395374439761
Validation loss: 2.975195381295842

Epoch: 6| Step: 9
Training loss: 2.913457976525738
Validation loss: 2.9738462081560697

Epoch: 6| Step: 10
Training loss: 3.789263973582049
Validation loss: 2.972387439269718

Epoch: 6| Step: 11
Training loss: 2.497718723865312
Validation loss: 2.973049023008198

Epoch: 6| Step: 12
Training loss: 3.3263082067535352
Validation loss: 2.970757267518117

Epoch: 6| Step: 13
Training loss: 3.035436511754863
Validation loss: 2.9700387192300792

Epoch: 146| Step: 0
Training loss: 2.8793958146750787
Validation loss: 2.971578983037478

Epoch: 6| Step: 1
Training loss: 3.084069258697646
Validation loss: 2.971859446114877

Epoch: 6| Step: 2
Training loss: 3.191410582970207
Validation loss: 2.9704841475405357

Epoch: 6| Step: 3
Training loss: 3.3944716892789675
Validation loss: 2.9741613510819374

Epoch: 6| Step: 4
Training loss: 2.274605572222532
Validation loss: 2.9767186279450493

Epoch: 6| Step: 5
Training loss: 3.087890161735022
Validation loss: 2.977671874614072

Epoch: 6| Step: 6
Training loss: 4.056218852201287
Validation loss: 2.9747042337525835

Epoch: 6| Step: 7
Training loss: 3.1038851172925357
Validation loss: 2.973647309944223

Epoch: 6| Step: 8
Training loss: 2.7393899324755573
Validation loss: 2.971660552957135

Epoch: 6| Step: 9
Training loss: 3.4123437251823714
Validation loss: 2.974213410222807

Epoch: 6| Step: 10
Training loss: 3.584170103327944
Validation loss: 2.9736694594471875

Epoch: 6| Step: 11
Training loss: 3.23545708730339
Validation loss: 2.9777456816250245

Epoch: 6| Step: 12
Training loss: 3.7842231600325524
Validation loss: 2.9734812075535775

Epoch: 6| Step: 13
Training loss: 3.370735865544578
Validation loss: 2.972239404634493

Epoch: 147| Step: 0
Training loss: 3.186236112256798
Validation loss: 2.97545245328512

Epoch: 6| Step: 1
Training loss: 3.132091258447799
Validation loss: 2.969158309033664

Epoch: 6| Step: 2
Training loss: 3.3250600823731893
Validation loss: 2.9697058839424657

Epoch: 6| Step: 3
Training loss: 3.6648791608886664
Validation loss: 2.9670707819604756

Epoch: 6| Step: 4
Training loss: 2.945841855509372
Validation loss: 2.967755786021666

Epoch: 6| Step: 5
Training loss: 3.4416879285351127
Validation loss: 2.969793918315969

Epoch: 6| Step: 6
Training loss: 3.8303714311138246
Validation loss: 2.9711880718317683

Epoch: 6| Step: 7
Training loss: 3.566692629092785
Validation loss: 2.9692683597987117

Epoch: 6| Step: 8
Training loss: 3.0150264481986557
Validation loss: 2.972088069326972

Epoch: 6| Step: 9
Training loss: 2.7273247208118554
Validation loss: 2.9700322704993414

Epoch: 6| Step: 10
Training loss: 3.0765451162456436
Validation loss: 2.972571361168858

Epoch: 6| Step: 11
Training loss: 3.3283376133304965
Validation loss: 2.972683341541428

Epoch: 6| Step: 12
Training loss: 2.7703687426542842
Validation loss: 2.975750783490806

Epoch: 6| Step: 13
Training loss: 3.302267284063037
Validation loss: 2.9729079881235823

Epoch: 148| Step: 0
Training loss: 3.349179574511743
Validation loss: 2.973035398740809

Epoch: 6| Step: 1
Training loss: 2.895146478297487
Validation loss: 2.971968769742849

Epoch: 6| Step: 2
Training loss: 3.2406565533153016
Validation loss: 2.968261612085004

Epoch: 6| Step: 3
Training loss: 3.2408120788311456
Validation loss: 2.975774612776664

Epoch: 6| Step: 4
Training loss: 3.3313349614572303
Validation loss: 2.966509368015173

Epoch: 6| Step: 5
Training loss: 3.5149840724361727
Validation loss: 2.9698821313546437

Epoch: 6| Step: 6
Training loss: 2.1173501040245317
Validation loss: 2.968914256708807

Epoch: 6| Step: 7
Training loss: 3.617868182276155
Validation loss: 2.9712927058092267

Epoch: 6| Step: 8
Training loss: 2.961994073216641
Validation loss: 2.9689957720452607

Epoch: 6| Step: 9
Training loss: 3.377161393546948
Validation loss: 2.967489012529147

Epoch: 6| Step: 10
Training loss: 3.803534550427266
Validation loss: 2.96490619479148

Epoch: 6| Step: 11
Training loss: 3.7755300591815186
Validation loss: 2.9672722100871334

Epoch: 6| Step: 12
Training loss: 2.6805281585540692
Validation loss: 2.9645292336937303

Epoch: 6| Step: 13
Training loss: 3.0786744222839304
Validation loss: 2.964882279018885

Epoch: 149| Step: 0
Training loss: 3.0273976179683224
Validation loss: 2.966569609527459

Epoch: 6| Step: 1
Training loss: 3.3381977509193734
Validation loss: 2.9657218683623667

Epoch: 6| Step: 2
Training loss: 2.975175669636627
Validation loss: 2.967514423441362

Epoch: 6| Step: 3
Training loss: 3.527545572550191
Validation loss: 2.9652442538943475

Epoch: 6| Step: 4
Training loss: 3.47613673656951
Validation loss: 2.9655713026565573

Epoch: 6| Step: 5
Training loss: 2.9357796359089483
Validation loss: 2.9661704920055505

Epoch: 6| Step: 6
Training loss: 3.1340904768473785
Validation loss: 2.966617200226341

Epoch: 6| Step: 7
Training loss: 3.0364327710462313
Validation loss: 2.9638478502850085

Epoch: 6| Step: 8
Training loss: 2.868333135498087
Validation loss: 2.964183209741833

Epoch: 6| Step: 9
Training loss: 3.211254391962347
Validation loss: 2.969123684691731

Epoch: 6| Step: 10
Training loss: 3.5984311341044295
Validation loss: 2.9680036209957126

Epoch: 6| Step: 11
Training loss: 3.1903301465187925
Validation loss: 2.9708847116933867

Epoch: 6| Step: 12
Training loss: 2.886694633166343
Validation loss: 2.9731628539091415

Epoch: 6| Step: 13
Training loss: 4.524202746555835
Validation loss: 2.966464256727094

Epoch: 150| Step: 0
Training loss: 3.426052939625596
Validation loss: 2.966526394323398

Epoch: 6| Step: 1
Training loss: 2.6730226427825343
Validation loss: 2.966601664264362

Epoch: 6| Step: 2
Training loss: 2.961108361299187
Validation loss: 2.9691266462669055

Epoch: 6| Step: 3
Training loss: 3.2056923602563545
Validation loss: 2.964388702386439

Epoch: 6| Step: 4
Training loss: 2.8665870640666093
Validation loss: 2.964753844414607

Epoch: 6| Step: 5
Training loss: 3.75568759662266
Validation loss: 2.96493620358629

Epoch: 6| Step: 6
Training loss: 2.8323258871518076
Validation loss: 2.964118174073521

Epoch: 6| Step: 7
Training loss: 3.041321216632143
Validation loss: 2.96587095352076

Epoch: 6| Step: 8
Training loss: 3.3578300294556107
Validation loss: 2.9643558350022103

Epoch: 6| Step: 9
Training loss: 2.9411882013199184
Validation loss: 2.961592545492419

Epoch: 6| Step: 10
Training loss: 3.485674560150765
Validation loss: 2.963637943081927

Epoch: 6| Step: 11
Training loss: 4.506043931796849
Validation loss: 2.961650942851411

Epoch: 6| Step: 12
Training loss: 2.7025997114533813
Validation loss: 2.961148882550245

Epoch: 6| Step: 13
Training loss: 3.1847648104990984
Validation loss: 2.9622760071713077

Epoch: 151| Step: 0
Training loss: 3.470778688242566
Validation loss: 2.9637384364306736

Epoch: 6| Step: 1
Training loss: 3.34835925560413
Validation loss: 2.9646960261443813

Epoch: 6| Step: 2
Training loss: 3.3815212119831934
Validation loss: 2.9676336031933093

Epoch: 6| Step: 3
Training loss: 3.1426765990728134
Validation loss: 2.959791605422293

Epoch: 6| Step: 4
Training loss: 3.8066729431189676
Validation loss: 2.9615533962928144

Epoch: 6| Step: 5
Training loss: 3.5710133338407952
Validation loss: 2.957536135596927

Epoch: 6| Step: 6
Training loss: 2.8657692044082284
Validation loss: 2.9574459905251205

Epoch: 6| Step: 7
Training loss: 2.787704179752765
Validation loss: 2.956110251733138

Epoch: 6| Step: 8
Training loss: 3.5815573142712873
Validation loss: 2.956990001283104

Epoch: 6| Step: 9
Training loss: 3.0525959786487147
Validation loss: 2.9572316524191558

Epoch: 6| Step: 10
Training loss: 3.0316143013610417
Validation loss: 2.9568045162620566

Epoch: 6| Step: 11
Training loss: 3.463144119890103
Validation loss: 2.9570580633514303

Epoch: 6| Step: 12
Training loss: 2.8846512386343495
Validation loss: 2.9591041235578137

Epoch: 6| Step: 13
Training loss: 2.4178223203528897
Validation loss: 2.96072887491215

Epoch: 152| Step: 0
Training loss: 2.132804227819924
Validation loss: 2.9673893520346053

Epoch: 6| Step: 1
Training loss: 3.1162967795584127
Validation loss: 2.966669768520428

Epoch: 6| Step: 2
Training loss: 2.72966146473077
Validation loss: 2.965243448986033

Epoch: 6| Step: 3
Training loss: 2.993646251178864
Validation loss: 2.955522562192814

Epoch: 6| Step: 4
Training loss: 3.931554513851454
Validation loss: 2.9574140948738887

Epoch: 6| Step: 5
Training loss: 3.574611221194611
Validation loss: 2.9564588837047223

Epoch: 6| Step: 6
Training loss: 2.9995491960690814
Validation loss: 2.956388022548067

Epoch: 6| Step: 7
Training loss: 3.0577324328029807
Validation loss: 2.9555204977636933

Epoch: 6| Step: 8
Training loss: 4.051961051972146
Validation loss: 2.955894959880083

Epoch: 6| Step: 9
Training loss: 2.9791072670588044
Validation loss: 2.9528258146559923

Epoch: 6| Step: 10
Training loss: 3.0925034603016273
Validation loss: 2.9574641430235813

Epoch: 6| Step: 11
Training loss: 3.7439849932606224
Validation loss: 2.956490972624014

Epoch: 6| Step: 12
Training loss: 3.2954675644285567
Validation loss: 2.95478761757499

Epoch: 6| Step: 13
Training loss: 3.0564367256772793
Validation loss: 2.959840614709588

Epoch: 153| Step: 0
Training loss: 3.6171893455550097
Validation loss: 2.9571542766158085

Epoch: 6| Step: 1
Training loss: 3.389273237796613
Validation loss: 2.956798383746728

Epoch: 6| Step: 2
Training loss: 2.471368680428327
Validation loss: 2.9599696747668447

Epoch: 6| Step: 3
Training loss: 3.1829070866069364
Validation loss: 2.9588087798391953

Epoch: 6| Step: 4
Training loss: 3.6446508324600533
Validation loss: 2.9493403188511493

Epoch: 6| Step: 5
Training loss: 2.67227410798998
Validation loss: 2.9538860756433913

Epoch: 6| Step: 6
Training loss: 3.238533037840222
Validation loss: 2.9509954935337186

Epoch: 6| Step: 7
Training loss: 2.8264915849636996
Validation loss: 2.9550045881493756

Epoch: 6| Step: 8
Training loss: 3.4101860333482477
Validation loss: 2.954183053533652

Epoch: 6| Step: 9
Training loss: 3.4740130388260066
Validation loss: 2.9555817794679857

Epoch: 6| Step: 10
Training loss: 3.4183696751466064
Validation loss: 2.954662174898444

Epoch: 6| Step: 11
Training loss: 3.0610010020750713
Validation loss: 2.955995328793909

Epoch: 6| Step: 12
Training loss: 3.6240806729261634
Validation loss: 2.9555073946770074

Epoch: 6| Step: 13
Training loss: 3.021611256022113
Validation loss: 2.9555225231595035

Epoch: 154| Step: 0
Training loss: 3.0306040282024367
Validation loss: 2.9543579092307417

Epoch: 6| Step: 1
Training loss: 3.2402149496479202
Validation loss: 2.9526102659504394

Epoch: 6| Step: 2
Training loss: 2.6844505930016833
Validation loss: 2.954988762096891

Epoch: 6| Step: 3
Training loss: 4.214404998088702
Validation loss: 2.9537346722702287

Epoch: 6| Step: 4
Training loss: 3.6679094693692047
Validation loss: 2.9539527650975295

Epoch: 6| Step: 5
Training loss: 3.0972204298651906
Validation loss: 2.952154144608002

Epoch: 6| Step: 6
Training loss: 3.4981510183059563
Validation loss: 2.9542847839991344

Epoch: 6| Step: 7
Training loss: 3.041361980767676
Validation loss: 2.950272266024234

Epoch: 6| Step: 8
Training loss: 3.34290395710901
Validation loss: 2.9514010392738577

Epoch: 6| Step: 9
Training loss: 3.1391084719871287
Validation loss: 2.9511534388270295

Epoch: 6| Step: 10
Training loss: 3.3428992499330032
Validation loss: 2.9495573372515036

Epoch: 6| Step: 11
Training loss: 2.836227360143706
Validation loss: 2.950932060241264

Epoch: 6| Step: 12
Training loss: 3.1984281017051712
Validation loss: 2.9515453757667647

Epoch: 6| Step: 13
Training loss: 2.1270362970853722
Validation loss: 2.9525378554469115

Epoch: 155| Step: 0
Training loss: 3.0812642311866303
Validation loss: 2.953539805576671

Epoch: 6| Step: 1
Training loss: 3.153500104960725
Validation loss: 2.949655356140239

Epoch: 6| Step: 2
Training loss: 3.1120295096226527
Validation loss: 2.949969436865387

Epoch: 6| Step: 3
Training loss: 3.3421938118110397
Validation loss: 2.9527702875939834

Epoch: 6| Step: 4
Training loss: 3.1382457014163974
Validation loss: 2.94853024279181

Epoch: 6| Step: 5
Training loss: 3.4615384305644237
Validation loss: 2.9488274940415486

Epoch: 6| Step: 6
Training loss: 2.908671365092217
Validation loss: 2.9470105882004156

Epoch: 6| Step: 7
Training loss: 2.824898243649689
Validation loss: 2.9454593516843874

Epoch: 6| Step: 8
Training loss: 3.219739447056795
Validation loss: 2.9465266719546768

Epoch: 6| Step: 9
Training loss: 2.5583776484657594
Validation loss: 2.947655648013359

Epoch: 6| Step: 10
Training loss: 3.0078251826031317
Validation loss: 2.9482237512674097

Epoch: 6| Step: 11
Training loss: 4.172106332830146
Validation loss: 2.9482311702953488

Epoch: 6| Step: 12
Training loss: 3.822058280736019
Validation loss: 2.946666520426857

Epoch: 6| Step: 13
Training loss: 3.1807211805490834
Validation loss: 2.9477423936677893

Epoch: 156| Step: 0
Training loss: 3.3651543163267967
Validation loss: 2.9462186511198856

Epoch: 6| Step: 1
Training loss: 2.8553042592734146
Validation loss: 2.9458160870754413

Epoch: 6| Step: 2
Training loss: 3.3688753858456155
Validation loss: 2.9488561120306023

Epoch: 6| Step: 3
Training loss: 3.44312893620583
Validation loss: 2.948572223688411

Epoch: 6| Step: 4
Training loss: 3.2089008638517207
Validation loss: 2.9499692230816064

Epoch: 6| Step: 5
Training loss: 3.6582690801749216
Validation loss: 2.9505561080935507

Epoch: 6| Step: 6
Training loss: 2.600260182347078
Validation loss: 2.9496530251265876

Epoch: 6| Step: 7
Training loss: 3.103450786472635
Validation loss: 2.9519211584996126

Epoch: 6| Step: 8
Training loss: 2.8105221045425117
Validation loss: 2.9488000842192488

Epoch: 6| Step: 9
Training loss: 3.538049144379834
Validation loss: 2.949540920490091

Epoch: 6| Step: 10
Training loss: 3.009457938218971
Validation loss: 2.9556605321820815

Epoch: 6| Step: 11
Training loss: 3.5495224537475747
Validation loss: 2.9478617301079497

Epoch: 6| Step: 12
Training loss: 2.9622511553974973
Validation loss: 2.950737256943891

Epoch: 6| Step: 13
Training loss: 3.850488230476378
Validation loss: 2.946301089347261

Epoch: 157| Step: 0
Training loss: 3.322892494871103
Validation loss: 2.9445508764958115

Epoch: 6| Step: 1
Training loss: 3.7975460762407973
Validation loss: 2.9510010899357972

Epoch: 6| Step: 2
Training loss: 3.120798414482334
Validation loss: 2.9481494573511777

Epoch: 6| Step: 3
Training loss: 3.2524072095226906
Validation loss: 2.945192472714248

Epoch: 6| Step: 4
Training loss: 2.4890257292077074
Validation loss: 2.9461501228378473

Epoch: 6| Step: 5
Training loss: 2.813008326051977
Validation loss: 2.9476295040574643

Epoch: 6| Step: 6
Training loss: 2.9836252279286724
Validation loss: 2.9478492991461667

Epoch: 6| Step: 7
Training loss: 3.1666836654474535
Validation loss: 2.9469274790910367

Epoch: 6| Step: 8
Training loss: 3.1412070574787174
Validation loss: 2.945103542792493

Epoch: 6| Step: 9
Training loss: 3.6018042493600353
Validation loss: 2.9494017811176003

Epoch: 6| Step: 10
Training loss: 3.706800222483577
Validation loss: 2.946611557660342

Epoch: 6| Step: 11
Training loss: 3.297778254432107
Validation loss: 2.9480138499092576

Epoch: 6| Step: 12
Training loss: 3.1155120247547754
Validation loss: 2.946488436264016

Epoch: 6| Step: 13
Training loss: 3.1864903664867543
Validation loss: 2.9460321615989953

Epoch: 158| Step: 0
Training loss: 3.1403964894227623
Validation loss: 2.9460919681779862

Epoch: 6| Step: 1
Training loss: 3.0412834309262533
Validation loss: 2.942926541462743

Epoch: 6| Step: 2
Training loss: 3.260050272641722
Validation loss: 2.9420320698458924

Epoch: 6| Step: 3
Training loss: 3.2954448472600792
Validation loss: 2.9425013539169864

Epoch: 6| Step: 4
Training loss: 3.122590471213849
Validation loss: 2.9408069350792507

Epoch: 6| Step: 5
Training loss: 4.0271562001674175
Validation loss: 2.943671706388392

Epoch: 6| Step: 6
Training loss: 2.8648111333724984
Validation loss: 2.9414293918282945

Epoch: 6| Step: 7
Training loss: 3.153042664979365
Validation loss: 2.9423595614179128

Epoch: 6| Step: 8
Training loss: 2.631993197412019
Validation loss: 2.942817511000175

Epoch: 6| Step: 9
Training loss: 2.7706379259850498
Validation loss: 2.941455848871717

Epoch: 6| Step: 10
Training loss: 3.536120541395099
Validation loss: 2.9403545209432025

Epoch: 6| Step: 11
Training loss: 3.4674729754461273
Validation loss: 2.9453295913957214

Epoch: 6| Step: 12
Training loss: 2.9319920948645386
Validation loss: 2.9412168814363957

Epoch: 6| Step: 13
Training loss: 4.032313243611474
Validation loss: 2.9462748898651303

Epoch: 159| Step: 0
Training loss: 2.833401978353064
Validation loss: 2.940918955094714

Epoch: 6| Step: 1
Training loss: 3.7359892735868443
Validation loss: 2.942594715959298

Epoch: 6| Step: 2
Training loss: 3.385725427877109
Validation loss: 2.9430612517803185

Epoch: 6| Step: 3
Training loss: 2.9535220247645086
Validation loss: 2.9391991966185325

Epoch: 6| Step: 4
Training loss: 3.341694708220549
Validation loss: 2.938682391495659

Epoch: 6| Step: 5
Training loss: 2.900075280100333
Validation loss: 2.9371524248213468

Epoch: 6| Step: 6
Training loss: 3.038445495889986
Validation loss: 2.9367087456415644

Epoch: 6| Step: 7
Training loss: 3.3009112631569373
Validation loss: 2.939170034530328

Epoch: 6| Step: 8
Training loss: 3.4856138208191885
Validation loss: 2.936926184162524

Epoch: 6| Step: 9
Training loss: 3.176164554676182
Validation loss: 2.939068128928426

Epoch: 6| Step: 10
Training loss: 3.040410466089592
Validation loss: 2.937760367076798

Epoch: 6| Step: 11
Training loss: 4.1779943726804385
Validation loss: 2.939403534198596

Epoch: 6| Step: 12
Training loss: 2.491845373509062
Validation loss: 2.9391651875284226

Epoch: 6| Step: 13
Training loss: 2.7897113291117006
Validation loss: 2.9374757729506324

Epoch: 160| Step: 0
Training loss: 3.684863683697355
Validation loss: 2.9357774519345328

Epoch: 6| Step: 1
Training loss: 2.8660337533074616
Validation loss: 2.937888038435236

Epoch: 6| Step: 2
Training loss: 2.801792446386451
Validation loss: 2.9379358607538753

Epoch: 6| Step: 3
Training loss: 3.053216994899697
Validation loss: 2.9465455242488416

Epoch: 6| Step: 4
Training loss: 3.2477600007671454
Validation loss: 2.9563804384185186

Epoch: 6| Step: 5
Training loss: 2.665128343651533
Validation loss: 2.9882454531318623

Epoch: 6| Step: 6
Training loss: 3.225849506952224
Validation loss: 3.005866482902643

Epoch: 6| Step: 7
Training loss: 3.3236172375053767
Validation loss: 2.979148665624118

Epoch: 6| Step: 8
Training loss: 3.2390375853121776
Validation loss: 2.9687933356808967

Epoch: 6| Step: 9
Training loss: 3.7980303478263906
Validation loss: 2.942337608380199

Epoch: 6| Step: 10
Training loss: 3.8664260268693154
Validation loss: 2.9358903030396544

Epoch: 6| Step: 11
Training loss: 2.968329470112718
Validation loss: 2.9361832669120504

Epoch: 6| Step: 12
Training loss: 3.1913049464682217
Validation loss: 2.93656160302183

Epoch: 6| Step: 13
Training loss: 3.062112433374461
Validation loss: 2.9377172054225267

Epoch: 161| Step: 0
Training loss: 3.7136697127357094
Validation loss: 2.940208675096223

Epoch: 6| Step: 1
Training loss: 3.0563131626209796
Validation loss: 2.9443915452601845

Epoch: 6| Step: 2
Training loss: 3.1941527708013235
Validation loss: 2.9415447731586535

Epoch: 6| Step: 3
Training loss: 3.370905334935944
Validation loss: 2.9461665567532918

Epoch: 6| Step: 4
Training loss: 2.3670383318241703
Validation loss: 2.9405770977562633

Epoch: 6| Step: 5
Training loss: 3.1043117071142774
Validation loss: 2.9400089713947453

Epoch: 6| Step: 6
Training loss: 3.362711398488417
Validation loss: 2.939144295698662

Epoch: 6| Step: 7
Training loss: 2.208691537943661
Validation loss: 2.938131471797065

Epoch: 6| Step: 8
Training loss: 3.1086995526965207
Validation loss: 2.9438425108465345

Epoch: 6| Step: 9
Training loss: 2.832628910535195
Validation loss: 2.9455499567199

Epoch: 6| Step: 10
Training loss: 3.6145207439064286
Validation loss: 2.953511261614095

Epoch: 6| Step: 11
Training loss: 3.3292361987845447
Validation loss: 2.9605239759924205

Epoch: 6| Step: 12
Training loss: 4.071737263385375
Validation loss: 2.9711454302936717

Epoch: 6| Step: 13
Training loss: 3.73241293210925
Validation loss: 2.9631673778101844

Epoch: 162| Step: 0
Training loss: 3.0058431940963115
Validation loss: 2.949738025104388

Epoch: 6| Step: 1
Training loss: 2.623721765199977
Validation loss: 2.9381849545930856

Epoch: 6| Step: 2
Training loss: 3.4504607957139273
Validation loss: 2.9385170363968527

Epoch: 6| Step: 3
Training loss: 3.4007617938490515
Validation loss: 2.939068859884801

Epoch: 6| Step: 4
Training loss: 3.0207977994385478
Validation loss: 2.9368581906349176

Epoch: 6| Step: 5
Training loss: 3.6126055111375726
Validation loss: 2.936682631684212

Epoch: 6| Step: 6
Training loss: 2.986373312229661
Validation loss: 2.937179748700121

Epoch: 6| Step: 7
Training loss: 3.8978811719465276
Validation loss: 2.93446073480572

Epoch: 6| Step: 8
Training loss: 2.7374233148015206
Validation loss: 2.9384080752649115

Epoch: 6| Step: 9
Training loss: 3.2052132103235835
Validation loss: 2.9366823470954455

Epoch: 6| Step: 10
Training loss: 2.704461180916312
Validation loss: 2.9385852977564406

Epoch: 6| Step: 11
Training loss: 3.3630254739051213
Validation loss: 2.93716946507112

Epoch: 6| Step: 12
Training loss: 3.551636176429692
Validation loss: 2.9362635553196106

Epoch: 6| Step: 13
Training loss: 3.4256971777383436
Validation loss: 2.9354512146245875

Epoch: 163| Step: 0
Training loss: 2.5110807898987315
Validation loss: 2.9365460468579703

Epoch: 6| Step: 1
Training loss: 2.528311731258371
Validation loss: 2.936462840628806

Epoch: 6| Step: 2
Training loss: 3.766902216295096
Validation loss: 2.9359385971146486

Epoch: 6| Step: 3
Training loss: 3.3282257208112305
Validation loss: 2.9353198896220505

Epoch: 6| Step: 4
Training loss: 2.968936954434078
Validation loss: 2.9361989900167615

Epoch: 6| Step: 5
Training loss: 3.656004807817566
Validation loss: 2.932296953717634

Epoch: 6| Step: 6
Training loss: 2.7213566002842486
Validation loss: 2.933983754655013

Epoch: 6| Step: 7
Training loss: 3.8928018018556085
Validation loss: 2.9308803968767716

Epoch: 6| Step: 8
Training loss: 3.3504433352778427
Validation loss: 2.931373015296527

Epoch: 6| Step: 9
Training loss: 3.1149577720559702
Validation loss: 2.9322728777707705

Epoch: 6| Step: 10
Training loss: 3.182147749639716
Validation loss: 2.9307733727723115

Epoch: 6| Step: 11
Training loss: 3.16045590407562
Validation loss: 2.9300011505350922

Epoch: 6| Step: 12
Training loss: 3.5167454269291585
Validation loss: 2.9300051543599817

Epoch: 6| Step: 13
Training loss: 3.003623998747928
Validation loss: 2.929002634374072

Epoch: 164| Step: 0
Training loss: 3.2598408118388655
Validation loss: 2.930905959868328

Epoch: 6| Step: 1
Training loss: 2.509205368978338
Validation loss: 2.931002328373862

Epoch: 6| Step: 2
Training loss: 3.050067344297259
Validation loss: 2.928008875197461

Epoch: 6| Step: 3
Training loss: 3.430394128115098
Validation loss: 2.93270755552767

Epoch: 6| Step: 4
Training loss: 3.642947655309328
Validation loss: 2.9286884182162756

Epoch: 6| Step: 5
Training loss: 3.3000766340663135
Validation loss: 2.9264659242849675

Epoch: 6| Step: 6
Training loss: 2.9458146615810272
Validation loss: 2.9319376229687295

Epoch: 6| Step: 7
Training loss: 2.924108131267085
Validation loss: 2.936591491158369

Epoch: 6| Step: 8
Training loss: 3.2730604878729923
Validation loss: 2.932039357582017

Epoch: 6| Step: 9
Training loss: 3.394566367859916
Validation loss: 2.931403098011226

Epoch: 6| Step: 10
Training loss: 3.02611697043624
Validation loss: 2.9296298909966523

Epoch: 6| Step: 11
Training loss: 3.741382233500191
Validation loss: 2.9316673050504845

Epoch: 6| Step: 12
Training loss: 2.82807273184176
Validation loss: 2.928461848445533

Epoch: 6| Step: 13
Training loss: 3.7125659461538207
Validation loss: 2.9308233379009168

Epoch: 165| Step: 0
Training loss: 3.4936473961028036
Validation loss: 2.9296926260735843

Epoch: 6| Step: 1
Training loss: 3.721345012093832
Validation loss: 2.92939908397058

Epoch: 6| Step: 2
Training loss: 2.850525884462929
Validation loss: 2.9294524960349646

Epoch: 6| Step: 3
Training loss: 3.0274681804065295
Validation loss: 2.9283494552042537

Epoch: 6| Step: 4
Training loss: 2.381839641147438
Validation loss: 2.9299328764289787

Epoch: 6| Step: 5
Training loss: 3.902821615628304
Validation loss: 2.928143310927383

Epoch: 6| Step: 6
Training loss: 4.239498853037036
Validation loss: 2.9320886672412425

Epoch: 6| Step: 7
Training loss: 2.7857749219729784
Validation loss: 2.9276288742691667

Epoch: 6| Step: 8
Training loss: 2.798522804787557
Validation loss: 2.930669599753519

Epoch: 6| Step: 9
Training loss: 3.015809681035354
Validation loss: 2.92724711272663

Epoch: 6| Step: 10
Training loss: 3.33758075630697
Validation loss: 2.932682858799876

Epoch: 6| Step: 11
Training loss: 2.8270026240193267
Validation loss: 2.9398242357910322

Epoch: 6| Step: 12
Training loss: 3.0460066120278824
Validation loss: 2.9397225455942806

Epoch: 6| Step: 13
Training loss: 2.9152389483394887
Validation loss: 2.9474293115967862

Epoch: 166| Step: 0
Training loss: 3.3719363966223046
Validation loss: 2.9502946805178896

Epoch: 6| Step: 1
Training loss: 2.8362919189260536
Validation loss: 2.941416532761638

Epoch: 6| Step: 2
Training loss: 3.5617665656834405
Validation loss: 2.9472227469439205

Epoch: 6| Step: 3
Training loss: 3.5941348989279596
Validation loss: 2.945740902182149

Epoch: 6| Step: 4
Training loss: 3.6304327933244687
Validation loss: 2.936476891252266

Epoch: 6| Step: 5
Training loss: 2.4122327271091253
Validation loss: 2.9319057313716153

Epoch: 6| Step: 6
Training loss: 3.3164063937812838
Validation loss: 2.9342152267788952

Epoch: 6| Step: 7
Training loss: 3.1753298730771964
Validation loss: 2.928381672677437

Epoch: 6| Step: 8
Training loss: 2.8033133623165516
Validation loss: 2.9237057864547453

Epoch: 6| Step: 9
Training loss: 3.973877245607768
Validation loss: 2.9340761033184437

Epoch: 6| Step: 10
Training loss: 3.003026865805647
Validation loss: 2.9247591924148013

Epoch: 6| Step: 11
Training loss: 2.7178234406893953
Validation loss: 2.9219280363354723

Epoch: 6| Step: 12
Training loss: 2.7366895198758376
Validation loss: 2.9238363196512513

Epoch: 6| Step: 13
Training loss: 3.6389517806994722
Validation loss: 2.926505130266194

Epoch: 167| Step: 0
Training loss: 3.4345540688146587
Validation loss: 2.9241113172864033

Epoch: 6| Step: 1
Training loss: 3.2572542073521795
Validation loss: 2.9219924879447308

Epoch: 6| Step: 2
Training loss: 3.161224675014867
Validation loss: 2.92124313129936

Epoch: 6| Step: 3
Training loss: 2.9916103991757588
Validation loss: 2.920563367500008

Epoch: 6| Step: 4
Training loss: 3.777173579898804
Validation loss: 2.922477373605608

Epoch: 6| Step: 5
Training loss: 3.1112948677502996
Validation loss: 2.9210927549073937

Epoch: 6| Step: 6
Training loss: 2.8078085023132973
Validation loss: 2.9226529762220848

Epoch: 6| Step: 7
Training loss: 3.442201485694182
Validation loss: 2.9202372591732373

Epoch: 6| Step: 8
Training loss: 3.342260581595649
Validation loss: 2.920674054692043

Epoch: 6| Step: 9
Training loss: 2.903974401019634
Validation loss: 2.9196919960554517

Epoch: 6| Step: 10
Training loss: 2.787587521124179
Validation loss: 2.920195517066237

Epoch: 6| Step: 11
Training loss: 3.6977301465486008
Validation loss: 2.9201348816160744

Epoch: 6| Step: 12
Training loss: 2.784255985751949
Validation loss: 2.9172134666206206

Epoch: 6| Step: 13
Training loss: 3.2092449990215948
Validation loss: 2.9249972747041193

Epoch: 168| Step: 0
Training loss: 3.3378989106282475
Validation loss: 2.9227812653915697

Epoch: 6| Step: 1
Training loss: 2.483394789308665
Validation loss: 2.9276003990507613

Epoch: 6| Step: 2
Training loss: 3.0285276792816016
Validation loss: 2.9201458880604267

Epoch: 6| Step: 3
Training loss: 3.3635394166757937
Validation loss: 2.9232950919004694

Epoch: 6| Step: 4
Training loss: 3.416041588398331
Validation loss: 2.920087531572102

Epoch: 6| Step: 5
Training loss: 2.226309992877723
Validation loss: 2.917924450392833

Epoch: 6| Step: 6
Training loss: 3.38063003581979
Validation loss: 2.9218843021346745

Epoch: 6| Step: 7
Training loss: 3.1879436707731306
Validation loss: 2.9207772313906624

Epoch: 6| Step: 8
Training loss: 3.1275243100472494
Validation loss: 2.923456885664988

Epoch: 6| Step: 9
Training loss: 4.058655548359517
Validation loss: 2.9240412012641097

Epoch: 6| Step: 10
Training loss: 3.1617278351310354
Validation loss: 2.9250988843547487

Epoch: 6| Step: 11
Training loss: 3.4885255187693525
Validation loss: 2.9223767597131203

Epoch: 6| Step: 12
Training loss: 3.173279700213351
Validation loss: 2.9223500562508704

Epoch: 6| Step: 13
Training loss: 3.006791216377399
Validation loss: 2.9224893107213017

Epoch: 169| Step: 0
Training loss: 2.5906565959922503
Validation loss: 2.922555723633905

Epoch: 6| Step: 1
Training loss: 3.302481273335245
Validation loss: 2.922725349976881

Epoch: 6| Step: 2
Training loss: 2.4840325653349495
Validation loss: 2.9194401564431183

Epoch: 6| Step: 3
Training loss: 3.288197310725172
Validation loss: 2.917244331591973

Epoch: 6| Step: 4
Training loss: 3.3372757168392724
Validation loss: 2.9157516016763942

Epoch: 6| Step: 5
Training loss: 3.8062567950408868
Validation loss: 2.9160066065756545

Epoch: 6| Step: 6
Training loss: 3.681736466756486
Validation loss: 2.9148842420733923

Epoch: 6| Step: 7
Training loss: 3.309845058352843
Validation loss: 2.9161494202206946

Epoch: 6| Step: 8
Training loss: 2.93806289798726
Validation loss: 2.9128592762697534

Epoch: 6| Step: 9
Training loss: 3.3052423971740934
Validation loss: 2.9170326237715125

Epoch: 6| Step: 10
Training loss: 2.9477017777013454
Validation loss: 2.916482754957746

Epoch: 6| Step: 11
Training loss: 2.833553268273866
Validation loss: 2.916510285669388

Epoch: 6| Step: 12
Training loss: 3.3282959227034596
Validation loss: 2.9161874409648605

Epoch: 6| Step: 13
Training loss: 3.6390625052413186
Validation loss: 2.9162074300300933

Epoch: 170| Step: 0
Training loss: 3.3599095118917393
Validation loss: 2.9148940871795537

Epoch: 6| Step: 1
Training loss: 3.2957570860892966
Validation loss: 2.9136789855751046

Epoch: 6| Step: 2
Training loss: 2.980121557329493
Validation loss: 2.9150236922546795

Epoch: 6| Step: 3
Training loss: 3.1370483073296036
Validation loss: 2.9185870670628344

Epoch: 6| Step: 4
Training loss: 2.7568357645346206
Validation loss: 2.9240474410568074

Epoch: 6| Step: 5
Training loss: 3.4463424700098018
Validation loss: 2.93018434267111

Epoch: 6| Step: 6
Training loss: 3.411705198407366
Validation loss: 2.9412418725863128

Epoch: 6| Step: 7
Training loss: 3.506459134370561
Validation loss: 2.9522759434032038

Epoch: 6| Step: 8
Training loss: 2.839992849851392
Validation loss: 2.9325896095563992

Epoch: 6| Step: 9
Training loss: 3.3375717555415454
Validation loss: 2.9274875340039084

Epoch: 6| Step: 10
Training loss: 3.0475334825311498
Validation loss: 2.9178659291080216

Epoch: 6| Step: 11
Training loss: 3.676310485944094
Validation loss: 2.919693462401488

Epoch: 6| Step: 12
Training loss: 2.921402673743098
Validation loss: 2.9139694827601517

Epoch: 6| Step: 13
Training loss: 2.973614852675649
Validation loss: 2.9090758350925423

Epoch: 171| Step: 0
Training loss: 2.408134218144341
Validation loss: 2.9091053376324765

Epoch: 6| Step: 1
Training loss: 3.489478919141973
Validation loss: 2.910647314957274

Epoch: 6| Step: 2
Training loss: 3.352713860639354
Validation loss: 2.9140062430918188

Epoch: 6| Step: 3
Training loss: 3.2931717598491828
Validation loss: 2.9129621339523406

Epoch: 6| Step: 4
Training loss: 3.2390253663867283
Validation loss: 2.911262572693161

Epoch: 6| Step: 5
Training loss: 2.8667139810900983
Validation loss: 2.9106773009660243

Epoch: 6| Step: 6
Training loss: 3.550314021661293
Validation loss: 2.9118786803237655

Epoch: 6| Step: 7
Training loss: 3.1591703293910856
Validation loss: 2.9142651780917737

Epoch: 6| Step: 8
Training loss: 3.175540253338592
Validation loss: 2.9113726166964407

Epoch: 6| Step: 9
Training loss: 2.845492656938928
Validation loss: 2.911947197252895

Epoch: 6| Step: 10
Training loss: 3.37237376005787
Validation loss: 2.910624551103

Epoch: 6| Step: 11
Training loss: 3.520455665572529
Validation loss: 2.910742110029094

Epoch: 6| Step: 12
Training loss: 2.940796645827347
Validation loss: 2.90894485105924

Epoch: 6| Step: 13
Training loss: 3.6843355469536685
Validation loss: 2.908646354986126

Epoch: 172| Step: 0
Training loss: 3.625091814654196
Validation loss: 2.9091599039410094

Epoch: 6| Step: 1
Training loss: 3.14135915801093
Validation loss: 2.9107089451404042

Epoch: 6| Step: 2
Training loss: 3.4078723648598963
Validation loss: 2.9076761572005982

Epoch: 6| Step: 3
Training loss: 3.2480533345170284
Validation loss: 2.906999116347893

Epoch: 6| Step: 4
Training loss: 2.451676445203929
Validation loss: 2.9083706337509896

Epoch: 6| Step: 5
Training loss: 3.0056215704035494
Validation loss: 2.912861077857218

Epoch: 6| Step: 6
Training loss: 3.1817632175008264
Validation loss: 2.915117179769461

Epoch: 6| Step: 7
Training loss: 3.012939838891298
Validation loss: 2.91760435603604

Epoch: 6| Step: 8
Training loss: 3.410387798195688
Validation loss: 2.9258144604650336

Epoch: 6| Step: 9
Training loss: 3.1257892374948715
Validation loss: 2.918768218510762

Epoch: 6| Step: 10
Training loss: 3.314418884711913
Validation loss: 2.9122334964959413

Epoch: 6| Step: 11
Training loss: 3.175853019926269
Validation loss: 2.9091625899305416

Epoch: 6| Step: 12
Training loss: 2.8037213119692246
Validation loss: 2.9092938558345716

Epoch: 6| Step: 13
Training loss: 4.126333079086737
Validation loss: 2.907311571904397

Epoch: 173| Step: 0
Training loss: 2.9066765584981513
Validation loss: 2.9074114259448915

Epoch: 6| Step: 1
Training loss: 2.6019156734632976
Validation loss: 2.907176201517923

Epoch: 6| Step: 2
Training loss: 2.597017275588634
Validation loss: 2.9094154777789396

Epoch: 6| Step: 3
Training loss: 3.6390293537495917
Validation loss: 2.909199654217915

Epoch: 6| Step: 4
Training loss: 3.346675840519747
Validation loss: 2.9096615769721006

Epoch: 6| Step: 5
Training loss: 3.531767140558935
Validation loss: 2.9100519188436924

Epoch: 6| Step: 6
Training loss: 2.9779001669459766
Validation loss: 2.910773587038671

Epoch: 6| Step: 7
Training loss: 3.644978159563018
Validation loss: 2.907975528660849

Epoch: 6| Step: 8
Training loss: 3.453078049560627
Validation loss: 2.9104729936394125

Epoch: 6| Step: 9
Training loss: 3.5508169711658932
Validation loss: 2.907093451000891

Epoch: 6| Step: 10
Training loss: 2.9921584962081575
Validation loss: 2.9063235037747863

Epoch: 6| Step: 11
Training loss: 3.4069327973729435
Validation loss: 2.9068341734881606

Epoch: 6| Step: 12
Training loss: 3.3457780908669355
Validation loss: 2.9062778331752703

Epoch: 6| Step: 13
Training loss: 1.9081956908160265
Validation loss: 2.9045076310940967

Epoch: 174| Step: 0
Training loss: 3.0747249821439824
Validation loss: 2.904818450991374

Epoch: 6| Step: 1
Training loss: 2.540699686264095
Validation loss: 2.9052863771228514

Epoch: 6| Step: 2
Training loss: 3.4733482332209005
Validation loss: 2.9044591727574316

Epoch: 6| Step: 3
Training loss: 3.403515899598649
Validation loss: 2.9027900816893855

Epoch: 6| Step: 4
Training loss: 3.036630476210079
Validation loss: 2.902737683960392

Epoch: 6| Step: 5
Training loss: 3.357508224965784
Validation loss: 2.9033299336850824

Epoch: 6| Step: 6
Training loss: 2.781912392592296
Validation loss: 2.9040680244211323

Epoch: 6| Step: 7
Training loss: 2.9074884872667797
Validation loss: 2.9072442172964923

Epoch: 6| Step: 8
Training loss: 3.730767586607121
Validation loss: 2.9061163374144634

Epoch: 6| Step: 9
Training loss: 3.316472388732433
Validation loss: 2.913107976331314

Epoch: 6| Step: 10
Training loss: 3.603505568244774
Validation loss: 2.91188293092941

Epoch: 6| Step: 11
Training loss: 3.551098564917796
Validation loss: 2.9152668548624123

Epoch: 6| Step: 12
Training loss: 2.6602722232314453
Validation loss: 2.917670990852626

Epoch: 6| Step: 13
Training loss: 2.9305851489396355
Validation loss: 2.9121933105003444

Epoch: 175| Step: 0
Training loss: 3.1673133256757104
Validation loss: 2.919538580581041

Epoch: 6| Step: 1
Training loss: 3.3779380160800043
Validation loss: 2.9058615373838577

Epoch: 6| Step: 2
Training loss: 2.7861322990601525
Validation loss: 2.9041698870035826

Epoch: 6| Step: 3
Training loss: 3.7206321248967194
Validation loss: 2.9018265528860683

Epoch: 6| Step: 4
Training loss: 3.3179242329836756
Validation loss: 2.909961230481351

Epoch: 6| Step: 5
Training loss: 3.2168703979909887
Validation loss: 2.900307352061045

Epoch: 6| Step: 6
Training loss: 3.9795528177896617
Validation loss: 2.9016407469758447

Epoch: 6| Step: 7
Training loss: 2.8353876258620447
Validation loss: 2.9045138166431554

Epoch: 6| Step: 8
Training loss: 2.8999868195332885
Validation loss: 2.9042331764621947

Epoch: 6| Step: 9
Training loss: 2.2801042579772735
Validation loss: 2.902629021609053

Epoch: 6| Step: 10
Training loss: 2.545311570796715
Validation loss: 2.9035043280320934

Epoch: 6| Step: 11
Training loss: 3.6727197852174265
Validation loss: 2.9022673929984246

Epoch: 6| Step: 12
Training loss: 3.2108895328400897
Validation loss: 2.901657223584302

Epoch: 6| Step: 13
Training loss: 3.480149927746258
Validation loss: 2.902614262193619

Epoch: 176| Step: 0
Training loss: 2.4226095746811267
Validation loss: 2.9021277627133104

Epoch: 6| Step: 1
Training loss: 2.7041742129776516
Validation loss: 2.90416306779261

Epoch: 6| Step: 2
Training loss: 3.496256733936621
Validation loss: 2.901142153895196

Epoch: 6| Step: 3
Training loss: 3.5113861978854852
Validation loss: 2.900315208334309

Epoch: 6| Step: 4
Training loss: 2.9221762435577165
Validation loss: 2.9030809699610995

Epoch: 6| Step: 5
Training loss: 3.8616214036875083
Validation loss: 2.9011359249269892

Epoch: 6| Step: 6
Training loss: 3.3383745854902016
Validation loss: 2.9007221674222063

Epoch: 6| Step: 7
Training loss: 3.3143377424487848
Validation loss: 2.9013420720175023

Epoch: 6| Step: 8
Training loss: 3.859241313394985
Validation loss: 2.8992638616863644

Epoch: 6| Step: 9
Training loss: 2.6059112401852125
Validation loss: 2.9028705606889624

Epoch: 6| Step: 10
Training loss: 3.3898697112936214
Validation loss: 2.9038842865056322

Epoch: 6| Step: 11
Training loss: 2.379996014118864
Validation loss: 2.8973442527586335

Epoch: 6| Step: 12
Training loss: 3.1636878274500573
Validation loss: 2.9020852495357397

Epoch: 6| Step: 13
Training loss: 3.3043006327835798
Validation loss: 2.9075473073576044

Epoch: 177| Step: 0
Training loss: 2.2125244915140074
Validation loss: 2.914516242208123

Epoch: 6| Step: 1
Training loss: 3.1586747628276353
Validation loss: 2.9094161827013805

Epoch: 6| Step: 2
Training loss: 3.5849504296614594
Validation loss: 2.9184086380703618

Epoch: 6| Step: 3
Training loss: 3.1079490880932537
Validation loss: 2.906003266074838

Epoch: 6| Step: 4
Training loss: 3.0347967732746333
Validation loss: 2.902063265687226

Epoch: 6| Step: 5
Training loss: 3.1775004295510905
Validation loss: 2.901264924314621

Epoch: 6| Step: 6
Training loss: 3.2240130903106055
Validation loss: 2.9030962153421895

Epoch: 6| Step: 7
Training loss: 3.0045514548573227
Validation loss: 2.9008270170711676

Epoch: 6| Step: 8
Training loss: 2.9290116407919125
Validation loss: 2.9029102257606345

Epoch: 6| Step: 9
Training loss: 3.7042217964272153
Validation loss: 2.900520654081586

Epoch: 6| Step: 10
Training loss: 2.9849087702166233
Validation loss: 2.9010691754220357

Epoch: 6| Step: 11
Training loss: 3.410529851384899
Validation loss: 2.9008079330521426

Epoch: 6| Step: 12
Training loss: 3.5671484886171685
Validation loss: 2.8998990864888556

Epoch: 6| Step: 13
Training loss: 3.4866038493909643
Validation loss: 2.900171234859023

Epoch: 178| Step: 0
Training loss: 3.482667650074647
Validation loss: 2.898364049203437

Epoch: 6| Step: 1
Training loss: 3.2102758463762364
Validation loss: 2.896996776456982

Epoch: 6| Step: 2
Training loss: 2.6934110707058405
Validation loss: 2.8974004102438435

Epoch: 6| Step: 3
Training loss: 2.8747233382084327
Validation loss: 2.8974702348445227

Epoch: 6| Step: 4
Training loss: 2.768724934828303
Validation loss: 2.8985407164426746

Epoch: 6| Step: 5
Training loss: 3.475375472167919
Validation loss: 2.8993344734578295

Epoch: 6| Step: 6
Training loss: 3.632406495079482
Validation loss: 2.899865241521185

Epoch: 6| Step: 7
Training loss: 3.623757247996508
Validation loss: 2.8964908839224073

Epoch: 6| Step: 8
Training loss: 2.8987150239335406
Validation loss: 2.893608984466615

Epoch: 6| Step: 9
Training loss: 2.737763316410783
Validation loss: 2.9029983835348268

Epoch: 6| Step: 10
Training loss: 3.0882979624397597
Validation loss: 2.902141255212347

Epoch: 6| Step: 11
Training loss: 3.1511595816920397
Validation loss: 2.918883456597808

Epoch: 6| Step: 12
Training loss: 3.435684140636504
Validation loss: 2.9122588596038224

Epoch: 6| Step: 13
Training loss: 3.4895565354566114
Validation loss: 2.9071237417483022

Epoch: 179| Step: 0
Training loss: 2.87336352669532
Validation loss: 2.9036443574117055

Epoch: 6| Step: 1
Training loss: 2.8264267179773026
Validation loss: 2.897921841236682

Epoch: 6| Step: 2
Training loss: 3.3745619878169584
Validation loss: 2.8952741675473055

Epoch: 6| Step: 3
Training loss: 3.5859170219152485
Validation loss: 2.896425579844728

Epoch: 6| Step: 4
Training loss: 2.691723011793152
Validation loss: 2.896398529140744

Epoch: 6| Step: 5
Training loss: 3.6496653155163696
Validation loss: 2.896286694696269

Epoch: 6| Step: 6
Training loss: 3.0896914284219013
Validation loss: 2.8947046210355363

Epoch: 6| Step: 7
Training loss: 3.3652384841548475
Validation loss: 2.893782841310408

Epoch: 6| Step: 8
Training loss: 3.378407206644316
Validation loss: 2.8961680559604766

Epoch: 6| Step: 9
Training loss: 2.6664186501403266
Validation loss: 2.8931446272240806

Epoch: 6| Step: 10
Training loss: 2.959102011378641
Validation loss: 2.895714186734983

Epoch: 6| Step: 11
Training loss: 3.9689239704118995
Validation loss: 2.8962533527721157

Epoch: 6| Step: 12
Training loss: 2.5286155460533006
Validation loss: 2.896217243428323

Epoch: 6| Step: 13
Training loss: 3.4545856683389076
Validation loss: 2.898160513850108

Epoch: 180| Step: 0
Training loss: 2.966869682337783
Validation loss: 2.8980436202002977

Epoch: 6| Step: 1
Training loss: 3.790559013025069
Validation loss: 2.898010298489764

Epoch: 6| Step: 2
Training loss: 2.843154341805616
Validation loss: 2.896687325417231

Epoch: 6| Step: 3
Training loss: 2.845920782202445
Validation loss: 2.899563869160854

Epoch: 6| Step: 4
Training loss: 2.747892265606741
Validation loss: 2.8962567818705867

Epoch: 6| Step: 5
Training loss: 2.8196872007430502
Validation loss: 2.897026355105978

Epoch: 6| Step: 6
Training loss: 3.9844385478617954
Validation loss: 2.8982718752931955

Epoch: 6| Step: 7
Training loss: 2.63032708734014
Validation loss: 2.8956174937492953

Epoch: 6| Step: 8
Training loss: 3.1924663076512307
Validation loss: 2.8965286467128744

Epoch: 6| Step: 9
Training loss: 3.5929097395743907
Validation loss: 2.8942119786601013

Epoch: 6| Step: 10
Training loss: 3.448624798450577
Validation loss: 2.896665424506341

Epoch: 6| Step: 11
Training loss: 2.958349218907934
Validation loss: 2.893598823741926

Epoch: 6| Step: 12
Training loss: 3.4620635050167055
Validation loss: 2.894745428860868

Epoch: 6| Step: 13
Training loss: 2.796986071549542
Validation loss: 2.891515181567997

Epoch: 181| Step: 0
Training loss: 3.144351399651016
Validation loss: 2.900116045945768

Epoch: 6| Step: 1
Training loss: 3.567607230357296
Validation loss: 2.9004155047684304

Epoch: 6| Step: 2
Training loss: 2.819108616246943
Validation loss: 2.9158846696061667

Epoch: 6| Step: 3
Training loss: 3.3064635353863867
Validation loss: 2.9423619199917965

Epoch: 6| Step: 4
Training loss: 2.980862772683082
Validation loss: 2.9524043711689045

Epoch: 6| Step: 5
Training loss: 3.5045776404391744
Validation loss: 2.9365883544722657

Epoch: 6| Step: 6
Training loss: 3.3839151818578155
Validation loss: 2.9062651564244444

Epoch: 6| Step: 7
Training loss: 3.3400514772297196
Validation loss: 2.8950314111181696

Epoch: 6| Step: 8
Training loss: 2.7341427077670155
Validation loss: 2.8905891715558982

Epoch: 6| Step: 9
Training loss: 3.082029702847362
Validation loss: 2.8900933607968673

Epoch: 6| Step: 10
Training loss: 3.2164425773505663
Validation loss: 2.894820495584012

Epoch: 6| Step: 11
Training loss: 2.730402998889804
Validation loss: 2.898682695180424

Epoch: 6| Step: 12
Training loss: 3.1864170403915826
Validation loss: 2.9030339016378255

Epoch: 6| Step: 13
Training loss: 4.084965023045112
Validation loss: 2.905873673325811

Epoch: 182| Step: 0
Training loss: 3.285217212016118
Validation loss: 2.9012980381070737

Epoch: 6| Step: 1
Training loss: 2.9081424581273
Validation loss: 2.8960767133035015

Epoch: 6| Step: 2
Training loss: 3.600349006689588
Validation loss: 2.8937614242777188

Epoch: 6| Step: 3
Training loss: 3.4926020229022456
Validation loss: 2.894266940906191

Epoch: 6| Step: 4
Training loss: 2.990727718426838
Validation loss: 2.891298171671459

Epoch: 6| Step: 5
Training loss: 3.40214066715055
Validation loss: 2.890701389605989

Epoch: 6| Step: 6
Training loss: 3.471229148420237
Validation loss: 2.8902191364963925

Epoch: 6| Step: 7
Training loss: 2.4682417720664107
Validation loss: 2.8894163496649683

Epoch: 6| Step: 8
Training loss: 2.985414972901557
Validation loss: 2.8917340236175146

Epoch: 6| Step: 9
Training loss: 3.652387486160259
Validation loss: 2.890829053492801

Epoch: 6| Step: 10
Training loss: 3.2040933773421054
Validation loss: 2.8904805447469637

Epoch: 6| Step: 11
Training loss: 3.19124383408055
Validation loss: 2.888806479616714

Epoch: 6| Step: 12
Training loss: 3.151489293274689
Validation loss: 2.892546188529268

Epoch: 6| Step: 13
Training loss: 1.8922225885894255
Validation loss: 2.89222692674811

Epoch: 183| Step: 0
Training loss: 3.4461893016961502
Validation loss: 2.9024230657354337

Epoch: 6| Step: 1
Training loss: 3.0314305831760744
Validation loss: 2.9126507061654543

Epoch: 6| Step: 2
Training loss: 2.6671551515285796
Validation loss: 2.9362301915038866

Epoch: 6| Step: 3
Training loss: 4.23749452663732
Validation loss: 2.918912730900397

Epoch: 6| Step: 4
Training loss: 2.602022330854621
Validation loss: 2.8911905247116767

Epoch: 6| Step: 5
Training loss: 3.14022232434869
Validation loss: 2.8928470335770347

Epoch: 6| Step: 6
Training loss: 2.5249268473991076
Validation loss: 2.8902652089754204

Epoch: 6| Step: 7
Training loss: 3.8140633301380444
Validation loss: 2.892280239061586

Epoch: 6| Step: 8
Training loss: 2.821906571829457
Validation loss: 2.891405602716202

Epoch: 6| Step: 9
Training loss: 2.99762472852449
Validation loss: 2.891343440488524

Epoch: 6| Step: 10
Training loss: 3.2106860728337447
Validation loss: 2.8884906501868555

Epoch: 6| Step: 11
Training loss: 3.401703346150631
Validation loss: 2.889347396934909

Epoch: 6| Step: 12
Training loss: 3.2103835321821057
Validation loss: 2.8906343122363896

Epoch: 6| Step: 13
Training loss: 3.075812385988663
Validation loss: 2.8889995489139904

Epoch: 184| Step: 0
Training loss: 4.1784173194124605
Validation loss: 2.8910109874477548

Epoch: 6| Step: 1
Training loss: 3.2527630138270287
Validation loss: 2.889664352592687

Epoch: 6| Step: 2
Training loss: 3.008669723625273
Validation loss: 2.8900613942072177

Epoch: 6| Step: 3
Training loss: 2.7936566126019358
Validation loss: 2.888534357474454

Epoch: 6| Step: 4
Training loss: 4.0963976502662005
Validation loss: 2.8903433767041555

Epoch: 6| Step: 5
Training loss: 3.2117082919036584
Validation loss: 2.8864669386918242

Epoch: 6| Step: 6
Training loss: 3.0527093828951384
Validation loss: 2.889680838935811

Epoch: 6| Step: 7
Training loss: 3.3709549858733903
Validation loss: 2.888813777908968

Epoch: 6| Step: 8
Training loss: 2.6468875817154114
Validation loss: 2.8867771895914656

Epoch: 6| Step: 9
Training loss: 2.699681376271324
Validation loss: 2.887033839996957

Epoch: 6| Step: 10
Training loss: 3.1032702455209793
Validation loss: 2.8861729227703563

Epoch: 6| Step: 11
Training loss: 2.711847773597915
Validation loss: 2.887524075801282

Epoch: 6| Step: 12
Training loss: 2.9764226445059894
Validation loss: 2.888214585655969

Epoch: 6| Step: 13
Training loss: 2.9280467410708297
Validation loss: 2.8853260483769874

Epoch: 185| Step: 0
Training loss: 3.7757552395632525
Validation loss: 2.885319396984529

Epoch: 6| Step: 1
Training loss: 2.49157611678137
Validation loss: 2.8879710289809806

Epoch: 6| Step: 2
Training loss: 3.1626175206479172
Validation loss: 2.8871822947181824

Epoch: 6| Step: 3
Training loss: 3.293754945349555
Validation loss: 2.8863795523257125

Epoch: 6| Step: 4
Training loss: 3.486269995795154
Validation loss: 2.884727590917001

Epoch: 6| Step: 5
Training loss: 3.9463921306680896
Validation loss: 2.8870911890034203

Epoch: 6| Step: 6
Training loss: 2.261930096754486
Validation loss: 2.8869291793858913

Epoch: 6| Step: 7
Training loss: 3.214078605882258
Validation loss: 2.8815067968269843

Epoch: 6| Step: 8
Training loss: 3.003832117959208
Validation loss: 2.8826937211505093

Epoch: 6| Step: 9
Training loss: 2.283539341824261
Validation loss: 2.8822904747149094

Epoch: 6| Step: 10
Training loss: 3.281618224781453
Validation loss: 2.878068211440497

Epoch: 6| Step: 11
Training loss: 3.218194709951856
Validation loss: 2.8806843519567877

Epoch: 6| Step: 12
Training loss: 3.4258920440678544
Validation loss: 2.8805580584759634

Epoch: 6| Step: 13
Training loss: 3.211639847246707
Validation loss: 2.878835569956593

Epoch: 186| Step: 0
Training loss: 3.3823570314855793
Validation loss: 2.881066364286293

Epoch: 6| Step: 1
Training loss: 3.162756530248401
Validation loss: 2.877405881845573

Epoch: 6| Step: 2
Training loss: 2.749854170660674
Validation loss: 2.8780613829392308

Epoch: 6| Step: 3
Training loss: 3.163714655841134
Validation loss: 2.878211598208419

Epoch: 6| Step: 4
Training loss: 3.2816041301182386
Validation loss: 2.8788717054134865

Epoch: 6| Step: 5
Training loss: 3.920293238240158
Validation loss: 2.877011147222052

Epoch: 6| Step: 6
Training loss: 2.9109906325351718
Validation loss: 2.875245350003114

Epoch: 6| Step: 7
Training loss: 3.062639350056285
Validation loss: 2.875778738367091

Epoch: 6| Step: 8
Training loss: 3.0787275470096116
Validation loss: 2.877024171185046

Epoch: 6| Step: 9
Training loss: 2.009504503315789
Validation loss: 2.8730554161525657

Epoch: 6| Step: 10
Training loss: 3.2526384061177396
Validation loss: 2.880488045525457

Epoch: 6| Step: 11
Training loss: 3.9089542641256214
Validation loss: 2.8745758453552672

Epoch: 6| Step: 12
Training loss: 3.217911842622804
Validation loss: 2.890629572755256

Epoch: 6| Step: 13
Training loss: 2.6413400799130593
Validation loss: 2.882122862708943

Epoch: 187| Step: 0
Training loss: 3.1940464785448084
Validation loss: 2.890762841092957

Epoch: 6| Step: 1
Training loss: 3.3986097971768983
Validation loss: 2.8950488489460158

Epoch: 6| Step: 2
Training loss: 3.1014109077209158
Validation loss: 2.8933269135362494

Epoch: 6| Step: 3
Training loss: 2.973349130813759
Validation loss: 2.889742874579489

Epoch: 6| Step: 4
Training loss: 3.432317676744715
Validation loss: 2.8856221104388244

Epoch: 6| Step: 5
Training loss: 3.5641910487986506
Validation loss: 2.8852954692596975

Epoch: 6| Step: 6
Training loss: 2.960875175846797
Validation loss: 2.8812359418635722

Epoch: 6| Step: 7
Training loss: 2.610285525872756
Validation loss: 2.8812217731128413

Epoch: 6| Step: 8
Training loss: 2.8165681027955896
Validation loss: 2.8760534017902795

Epoch: 6| Step: 9
Training loss: 3.3617109826539218
Validation loss: 2.8769874239611593

Epoch: 6| Step: 10
Training loss: 3.343233728215036
Validation loss: 2.8796932894297473

Epoch: 6| Step: 11
Training loss: 2.9108092938630072
Validation loss: 2.8820488644748297

Epoch: 6| Step: 12
Training loss: 3.1635301683753076
Validation loss: 2.879718250979821

Epoch: 6| Step: 13
Training loss: 3.7175945121690153
Validation loss: 2.8799871372262666

Epoch: 188| Step: 0
Training loss: 3.4173933667483616
Validation loss: 2.877428406894704

Epoch: 6| Step: 1
Training loss: 3.373675333661793
Validation loss: 2.8728964244845043

Epoch: 6| Step: 2
Training loss: 3.438363816358382
Validation loss: 2.8738493781488876

Epoch: 6| Step: 3
Training loss: 2.8390296073355987
Validation loss: 2.8712405431423846

Epoch: 6| Step: 4
Training loss: 2.98158509232602
Validation loss: 2.873771303270779

Epoch: 6| Step: 5
Training loss: 3.620605172422864
Validation loss: 2.8747454811920643

Epoch: 6| Step: 6
Training loss: 3.5472887780910787
Validation loss: 2.8728417003538333

Epoch: 6| Step: 7
Training loss: 2.9217979706591035
Validation loss: 2.8744170234068696

Epoch: 6| Step: 8
Training loss: 3.20667394025246
Validation loss: 2.8749877480009087

Epoch: 6| Step: 9
Training loss: 3.550866389329253
Validation loss: 2.8761829369796468

Epoch: 6| Step: 10
Training loss: 2.436652598655714
Validation loss: 2.8766514804117795

Epoch: 6| Step: 11
Training loss: 2.4779015419883677
Validation loss: 2.873285016588993

Epoch: 6| Step: 12
Training loss: 3.0025017162003644
Validation loss: 2.8786176683061035

Epoch: 6| Step: 13
Training loss: 3.37676051811195
Validation loss: 2.878073470426515

Epoch: 189| Step: 0
Training loss: 2.798516585586633
Validation loss: 2.8786025034621554

Epoch: 6| Step: 1
Training loss: 3.0211400018884826
Validation loss: 2.8828592857701536

Epoch: 6| Step: 2
Training loss: 3.261477816700295
Validation loss: 2.8797171185942037

Epoch: 6| Step: 3
Training loss: 2.8819896485078575
Validation loss: 2.8751851147536542

Epoch: 6| Step: 4
Training loss: 3.470735548701952
Validation loss: 2.875643338508831

Epoch: 6| Step: 5
Training loss: 3.143817853858933
Validation loss: 2.8809801390961858

Epoch: 6| Step: 6
Training loss: 2.9007753059291375
Validation loss: 2.8731274081723384

Epoch: 6| Step: 7
Training loss: 3.6088297378403973
Validation loss: 2.8696396887600493

Epoch: 6| Step: 8
Training loss: 3.036593103226138
Validation loss: 2.8698270734613462

Epoch: 6| Step: 9
Training loss: 3.3667049903073263
Validation loss: 2.872401920539334

Epoch: 6| Step: 10
Training loss: 3.3420963654792932
Validation loss: 2.868265603845867

Epoch: 6| Step: 11
Training loss: 2.790660581970629
Validation loss: 2.8702175370133785

Epoch: 6| Step: 12
Training loss: 3.317468911020258
Validation loss: 2.8689610303666955

Epoch: 6| Step: 13
Training loss: 3.4363073881095345
Validation loss: 2.8700521247557735

Epoch: 190| Step: 0
Training loss: 3.246445105458262
Validation loss: 2.8733331254069623

Epoch: 6| Step: 1
Training loss: 3.2594598863324507
Validation loss: 2.8740314369814666

Epoch: 6| Step: 2
Training loss: 3.477489150775629
Validation loss: 2.871981603480624

Epoch: 6| Step: 3
Training loss: 3.4949668389358477
Validation loss: 2.870709012993259

Epoch: 6| Step: 4
Training loss: 3.3046546014541534
Validation loss: 2.874277370031827

Epoch: 6| Step: 5
Training loss: 3.1784227559939713
Validation loss: 2.8691312715951227

Epoch: 6| Step: 6
Training loss: 3.008746113729087
Validation loss: 2.8735158245101924

Epoch: 6| Step: 7
Training loss: 3.4070450441133278
Validation loss: 2.8719174095760156

Epoch: 6| Step: 8
Training loss: 3.336734435326631
Validation loss: 2.8700762117201495

Epoch: 6| Step: 9
Training loss: 2.7850523256491977
Validation loss: 2.8726660504915316

Epoch: 6| Step: 10
Training loss: 3.4730430361879163
Validation loss: 2.8694507962279436

Epoch: 6| Step: 11
Training loss: 3.015419434177221
Validation loss: 2.871490481910672

Epoch: 6| Step: 12
Training loss: 2.255565435902587
Validation loss: 2.8723380162820416

Epoch: 6| Step: 13
Training loss: 2.801057554525985
Validation loss: 2.871981921259824

Epoch: 191| Step: 0
Training loss: 2.722957468541931
Validation loss: 2.869595248781146

Epoch: 6| Step: 1
Training loss: 2.9658717608519165
Validation loss: 2.871424627111509

Epoch: 6| Step: 2
Training loss: 3.09813341119212
Validation loss: 2.8698745291845

Epoch: 6| Step: 3
Training loss: 3.5438505881698754
Validation loss: 2.8757390315898146

Epoch: 6| Step: 4
Training loss: 3.2914075306804564
Validation loss: 2.8691619077246204

Epoch: 6| Step: 5
Training loss: 3.063099705113563
Validation loss: 2.8692723387540946

Epoch: 6| Step: 6
Training loss: 2.815477956304493
Validation loss: 2.869469811834192

Epoch: 6| Step: 7
Training loss: 3.024042744147744
Validation loss: 2.868832613176628

Epoch: 6| Step: 8
Training loss: 2.916147912532235
Validation loss: 2.8731779689020867

Epoch: 6| Step: 9
Training loss: 3.6225153859656163
Validation loss: 2.867589018872266

Epoch: 6| Step: 10
Training loss: 3.339210637635056
Validation loss: 2.867624583982417

Epoch: 6| Step: 11
Training loss: 1.8327103842461863
Validation loss: 2.8690196270432446

Epoch: 6| Step: 12
Training loss: 4.237413730699667
Validation loss: 2.870289562699352

Epoch: 6| Step: 13
Training loss: 3.4240843725415417
Validation loss: 2.86515656911745

Epoch: 192| Step: 0
Training loss: 3.0579792832944612
Validation loss: 2.870050207865626

Epoch: 6| Step: 1
Training loss: 3.3749416487559194
Validation loss: 2.865864639477881

Epoch: 6| Step: 2
Training loss: 3.097110964872804
Validation loss: 2.86756275644356

Epoch: 6| Step: 3
Training loss: 3.599097477844869
Validation loss: 2.8680771455080687

Epoch: 6| Step: 4
Training loss: 1.8980654756208102
Validation loss: 2.865695283073304

Epoch: 6| Step: 5
Training loss: 3.5657426231301015
Validation loss: 2.8682090770297544

Epoch: 6| Step: 6
Training loss: 3.5095470192685183
Validation loss: 2.8658654069961167

Epoch: 6| Step: 7
Training loss: 3.4162183017704773
Validation loss: 2.8648494748220816

Epoch: 6| Step: 8
Training loss: 2.6425630578896495
Validation loss: 2.8655832487890582

Epoch: 6| Step: 9
Training loss: 2.981243307877873
Validation loss: 2.863203493115162

Epoch: 6| Step: 10
Training loss: 3.601305772481245
Validation loss: 2.864554025867402

Epoch: 6| Step: 11
Training loss: 2.6725450534430855
Validation loss: 2.8626022000358144

Epoch: 6| Step: 12
Training loss: 3.5894583909306106
Validation loss: 2.8644661678990118

Epoch: 6| Step: 13
Training loss: 2.597900470926868
Validation loss: 2.8629527708888274

Epoch: 193| Step: 0
Training loss: 3.5238912421340647
Validation loss: 2.8652011557846846

Epoch: 6| Step: 1
Training loss: 4.059442631464252
Validation loss: 2.8662585729467187

Epoch: 6| Step: 2
Training loss: 2.881148522300812
Validation loss: 2.8655285361913685

Epoch: 6| Step: 3
Training loss: 3.157847991396606
Validation loss: 2.8647964234209535

Epoch: 6| Step: 4
Training loss: 3.1935066025885037
Validation loss: 2.8663706005118876

Epoch: 6| Step: 5
Training loss: 3.5493228212750703
Validation loss: 2.86552699560634

Epoch: 6| Step: 6
Training loss: 3.4362582651582176
Validation loss: 2.866357224049401

Epoch: 6| Step: 7
Training loss: 3.014212005530173
Validation loss: 2.8686839514923914

Epoch: 6| Step: 8
Training loss: 2.9085920187847387
Validation loss: 2.872297422952499

Epoch: 6| Step: 9
Training loss: 2.779472554619809
Validation loss: 2.8699391984482125

Epoch: 6| Step: 10
Training loss: 2.350386518792117
Validation loss: 2.8651215397644823

Epoch: 6| Step: 11
Training loss: 2.5341450653945166
Validation loss: 2.8678743551709944

Epoch: 6| Step: 12
Training loss: 3.1289032020506378
Validation loss: 2.872025321891495

Epoch: 6| Step: 13
Training loss: 3.527031868868796
Validation loss: 2.863924576681953

Epoch: 194| Step: 0
Training loss: 3.2721133956846224
Validation loss: 2.868513593450845

Epoch: 6| Step: 1
Training loss: 2.808043021375171
Validation loss: 2.8692709958516716

Epoch: 6| Step: 2
Training loss: 3.2440336187951333
Validation loss: 2.8670670580523656

Epoch: 6| Step: 3
Training loss: 3.06904960459486
Validation loss: 2.8654235025395165

Epoch: 6| Step: 4
Training loss: 2.4397228571353975
Validation loss: 2.8653250984396093

Epoch: 6| Step: 5
Training loss: 2.7387337956891504
Validation loss: 2.865285043694609

Epoch: 6| Step: 6
Training loss: 3.307387238971382
Validation loss: 2.865636245366056

Epoch: 6| Step: 7
Training loss: 3.9741006661553415
Validation loss: 2.864200052851111

Epoch: 6| Step: 8
Training loss: 3.0885513245472858
Validation loss: 2.8649588050021744

Epoch: 6| Step: 9
Training loss: 3.327200031244379
Validation loss: 2.8705903736593497

Epoch: 6| Step: 10
Training loss: 3.0111987584094284
Validation loss: 2.8672771173289204

Epoch: 6| Step: 11
Training loss: 3.4558408250092034
Validation loss: 2.8646315192293126

Epoch: 6| Step: 12
Training loss: 3.2507276454063905
Validation loss: 2.8656111128418873

Epoch: 6| Step: 13
Training loss: 2.7923065894485046
Validation loss: 2.8663042524302322

Epoch: 195| Step: 0
Training loss: 3.175477335934734
Validation loss: 2.872154896827755

Epoch: 6| Step: 1
Training loss: 3.4521166679938435
Validation loss: 2.8703538332013734

Epoch: 6| Step: 2
Training loss: 3.19616180548877
Validation loss: 2.862687877266588

Epoch: 6| Step: 3
Training loss: 3.3522851693931996
Validation loss: 2.8600652874500057

Epoch: 6| Step: 4
Training loss: 3.267404317936131
Validation loss: 2.857890758287142

Epoch: 6| Step: 5
Training loss: 3.655296527403361
Validation loss: 2.8624725034541

Epoch: 6| Step: 6
Training loss: 3.115674256267332
Validation loss: 2.8614238461633827

Epoch: 6| Step: 7
Training loss: 3.2595710673477916
Validation loss: 2.8623671283791605

Epoch: 6| Step: 8
Training loss: 2.5825563205659745
Validation loss: 2.8626517331972092

Epoch: 6| Step: 9
Training loss: 2.503618197007183
Validation loss: 2.8613611078508505

Epoch: 6| Step: 10
Training loss: 2.499371068044681
Validation loss: 2.8664005175546197

Epoch: 6| Step: 11
Training loss: 3.0078762295399466
Validation loss: 2.877141110650495

Epoch: 6| Step: 12
Training loss: 3.6876626706207873
Validation loss: 2.8718684307880533

Epoch: 6| Step: 13
Training loss: 3.222472177508202
Validation loss: 2.8703645946788456

Epoch: 196| Step: 0
Training loss: 3.3078357319112874
Validation loss: 2.8664647375240913

Epoch: 6| Step: 1
Training loss: 3.3921106133869143
Validation loss: 2.864881385369817

Epoch: 6| Step: 2
Training loss: 3.3695749550206537
Validation loss: 2.861532208855378

Epoch: 6| Step: 3
Training loss: 3.3453525018772545
Validation loss: 2.8603790096694937

Epoch: 6| Step: 4
Training loss: 2.9227006531059616
Validation loss: 2.858659324423785

Epoch: 6| Step: 5
Training loss: 2.7605465744448066
Validation loss: 2.857489970652038

Epoch: 6| Step: 6
Training loss: 3.3814144637466086
Validation loss: 2.855103125260919

Epoch: 6| Step: 7
Training loss: 3.0708128543276145
Validation loss: 2.8536330795352702

Epoch: 6| Step: 8
Training loss: 3.903536410979257
Validation loss: 2.8554340282609734

Epoch: 6| Step: 9
Training loss: 2.7972788599066356
Validation loss: 2.85868984947912

Epoch: 6| Step: 10
Training loss: 2.6707959589572403
Validation loss: 2.856359635603649

Epoch: 6| Step: 11
Training loss: 3.1212327756700544
Validation loss: 2.858227623377631

Epoch: 6| Step: 12
Training loss: 2.6898048630739027
Validation loss: 2.856114400103844

Epoch: 6| Step: 13
Training loss: 3.185631297739385
Validation loss: 2.8578423841305933

Epoch: 197| Step: 0
Training loss: 2.6600365072627676
Validation loss: 2.856408252067218

Epoch: 6| Step: 1
Training loss: 3.167616668214525
Validation loss: 2.8536133043744054

Epoch: 6| Step: 2
Training loss: 3.3387609321532374
Validation loss: 2.8543614577854868

Epoch: 6| Step: 3
Training loss: 3.301645885737835
Validation loss: 2.8547748851460617

Epoch: 6| Step: 4
Training loss: 3.1321923457845324
Validation loss: 2.8528791619048337

Epoch: 6| Step: 5
Training loss: 3.0845709370349366
Validation loss: 2.855274179277318

Epoch: 6| Step: 6
Training loss: 3.972461076741418
Validation loss: 2.855168680402785

Epoch: 6| Step: 7
Training loss: 2.6803083673680814
Validation loss: 2.8537435796631843

Epoch: 6| Step: 8
Training loss: 3.4067649801989655
Validation loss: 2.853602459061722

Epoch: 6| Step: 9
Training loss: 3.2293372980792245
Validation loss: 2.854053360932755

Epoch: 6| Step: 10
Training loss: 3.115342284817947
Validation loss: 2.8504956650055053

Epoch: 6| Step: 11
Training loss: 3.146644100442348
Validation loss: 2.855759607213917

Epoch: 6| Step: 12
Training loss: 3.1186379330363194
Validation loss: 2.8553069223012

Epoch: 6| Step: 13
Training loss: 2.012733336954316
Validation loss: 2.8571677948116854

Epoch: 198| Step: 0
Training loss: 2.7535879830496626
Validation loss: 2.854473799589303

Epoch: 6| Step: 1
Training loss: 3.294363502535933
Validation loss: 2.8528295363463125

Epoch: 6| Step: 2
Training loss: 2.7497022641003754
Validation loss: 2.851960368599167

Epoch: 6| Step: 3
Training loss: 3.2217980924172176
Validation loss: 2.8568146609787473

Epoch: 6| Step: 4
Training loss: 3.046102729152097
Validation loss: 2.8521943349116876

Epoch: 6| Step: 5
Training loss: 3.7195982406406936
Validation loss: 2.8586836750825375

Epoch: 6| Step: 6
Training loss: 2.636980238769924
Validation loss: 2.857644440385512

Epoch: 6| Step: 7
Training loss: 3.7703674337698607
Validation loss: 2.8542470421434687

Epoch: 6| Step: 8
Training loss: 2.6040634643450358
Validation loss: 2.855632349662333

Epoch: 6| Step: 9
Training loss: 3.650535617355226
Validation loss: 2.8509397232614893

Epoch: 6| Step: 10
Training loss: 3.6146673070001074
Validation loss: 2.850364707922681

Epoch: 6| Step: 11
Training loss: 2.117707924030475
Validation loss: 2.8542435535924895

Epoch: 6| Step: 12
Training loss: 3.1340314439122436
Validation loss: 2.8492613381559337

Epoch: 6| Step: 13
Training loss: 3.4708546619897183
Validation loss: 2.8486026188580635

Epoch: 199| Step: 0
Training loss: 2.5366041283870824
Validation loss: 2.852505881477522

Epoch: 6| Step: 1
Training loss: 3.0499665055233725
Validation loss: 2.848048188699876

Epoch: 6| Step: 2
Training loss: 3.255242301255065
Validation loss: 2.8496923958535283

Epoch: 6| Step: 3
Training loss: 3.41430397838261
Validation loss: 2.8451727772278224

Epoch: 6| Step: 4
Training loss: 3.7270492139903197
Validation loss: 2.8464213196176833

Epoch: 6| Step: 5
Training loss: 3.2271352633654264
Validation loss: 2.8456813416076003

Epoch: 6| Step: 6
Training loss: 2.8724662562314767
Validation loss: 2.8522419024482737

Epoch: 6| Step: 7
Training loss: 3.208432745115852
Validation loss: 2.848336828103865

Epoch: 6| Step: 8
Training loss: 2.6867963180148755
Validation loss: 2.847976885958277

Epoch: 6| Step: 9
Training loss: 2.564930577221691
Validation loss: 2.8487426651585372

Epoch: 6| Step: 10
Training loss: 3.9498888120816282
Validation loss: 2.8512882124910934

Epoch: 6| Step: 11
Training loss: 2.9795923706936165
Validation loss: 2.8462874801931872

Epoch: 6| Step: 12
Training loss: 2.7725011830030692
Validation loss: 2.851355729955563

Epoch: 6| Step: 13
Training loss: 3.76109376906794
Validation loss: 2.8488871351096825

Epoch: 200| Step: 0
Training loss: 2.897859664857329
Validation loss: 2.8496713212745024

Epoch: 6| Step: 1
Training loss: 3.0978278825697942
Validation loss: 2.847279512569508

Epoch: 6| Step: 2
Training loss: 3.745219425959444
Validation loss: 2.848628397318566

Epoch: 6| Step: 3
Training loss: 3.2662347105758203
Validation loss: 2.8494136538166077

Epoch: 6| Step: 4
Training loss: 3.115790874079339
Validation loss: 2.847309976848299

Epoch: 6| Step: 5
Training loss: 2.460086929832266
Validation loss: 2.8470198349178926

Epoch: 6| Step: 6
Training loss: 3.3320690300466604
Validation loss: 2.8483074080741146

Epoch: 6| Step: 7
Training loss: 3.3258558964344287
Validation loss: 2.847347324069718

Epoch: 6| Step: 8
Training loss: 2.901159607129542
Validation loss: 2.8497429909399523

Epoch: 6| Step: 9
Training loss: 2.901200368342474
Validation loss: 2.8486965447826678

Epoch: 6| Step: 10
Training loss: 3.447657057716453
Validation loss: 2.8516598884740403

Epoch: 6| Step: 11
Training loss: 2.962662891142895
Validation loss: 2.852302647381439

Epoch: 6| Step: 12
Training loss: 2.885456970888176
Validation loss: 2.8526875095966475

Epoch: 6| Step: 13
Training loss: 3.765829120342962
Validation loss: 2.85626619234367

Epoch: 201| Step: 0
Training loss: 3.2586949751831913
Validation loss: 2.851802240582919

Epoch: 6| Step: 1
Training loss: 2.9172117178125707
Validation loss: 2.849962825924898

Epoch: 6| Step: 2
Training loss: 2.3973986833185137
Validation loss: 2.858593360565375

Epoch: 6| Step: 3
Training loss: 2.7961154524415774
Validation loss: 2.8579889375639937

Epoch: 6| Step: 4
Training loss: 2.6326200601672602
Validation loss: 2.8550101562960704

Epoch: 6| Step: 5
Training loss: 3.1391429535736646
Validation loss: 2.852021279530323

Epoch: 6| Step: 6
Training loss: 2.8974680140312135
Validation loss: 2.8568773133802745

Epoch: 6| Step: 7
Training loss: 3.378223433988091
Validation loss: 2.851913042670821

Epoch: 6| Step: 8
Training loss: 3.4526975893662804
Validation loss: 2.8504544728175687

Epoch: 6| Step: 9
Training loss: 2.7609300148068545
Validation loss: 2.8428130248661803

Epoch: 6| Step: 10
Training loss: 3.433112934285102
Validation loss: 2.8470443868803734

Epoch: 6| Step: 11
Training loss: 3.2538510028229286
Validation loss: 2.848672025958496

Epoch: 6| Step: 12
Training loss: 3.683147771542576
Validation loss: 2.847661728997649

Epoch: 6| Step: 13
Training loss: 4.121617635539929
Validation loss: 2.845125637547717

Epoch: 202| Step: 0
Training loss: 3.0615052145091632
Validation loss: 2.846503692237043

Epoch: 6| Step: 1
Training loss: 3.0321362959591625
Validation loss: 2.8482484644942767

Epoch: 6| Step: 2
Training loss: 3.03126793295678
Validation loss: 2.846048975724771

Epoch: 6| Step: 3
Training loss: 2.847729759157102
Validation loss: 2.8473708170937595

Epoch: 6| Step: 4
Training loss: 3.1915017233940586
Validation loss: 2.844348560955507

Epoch: 6| Step: 5
Training loss: 3.1939849707357943
Validation loss: 2.8461743261684185

Epoch: 6| Step: 6
Training loss: 3.36996225262338
Validation loss: 2.8501086520712926

Epoch: 6| Step: 7
Training loss: 3.123160774678003
Validation loss: 2.8513115363800754

Epoch: 6| Step: 8
Training loss: 2.716661374451645
Validation loss: 2.8452474624131145

Epoch: 6| Step: 9
Training loss: 3.1027297890994374
Validation loss: 2.8496289710291296

Epoch: 6| Step: 10
Training loss: 3.3612298147575013
Validation loss: 2.845605969603075

Epoch: 6| Step: 11
Training loss: 3.402070587439565
Validation loss: 2.8466294621444175

Epoch: 6| Step: 12
Training loss: 3.6694815119230695
Validation loss: 2.845777092696841

Epoch: 6| Step: 13
Training loss: 2.5855831583430606
Validation loss: 2.8456368283753344

Epoch: 203| Step: 0
Training loss: 3.697918156726519
Validation loss: 2.845994945118283

Epoch: 6| Step: 1
Training loss: 3.1084047270102095
Validation loss: 2.8432880293667635

Epoch: 6| Step: 2
Training loss: 2.8130365495690643
Validation loss: 2.840166203973508

Epoch: 6| Step: 3
Training loss: 3.582833203448482
Validation loss: 2.842137224340745

Epoch: 6| Step: 4
Training loss: 3.422144770330671
Validation loss: 2.8427917991878204

Epoch: 6| Step: 5
Training loss: 2.413055110967608
Validation loss: 2.841132594220482

Epoch: 6| Step: 6
Training loss: 2.8850201679761107
Validation loss: 2.8445487268166847

Epoch: 6| Step: 7
Training loss: 3.139258243881402
Validation loss: 2.8464335910014467

Epoch: 6| Step: 8
Training loss: 3.4703818941628035
Validation loss: 2.844916999313052

Epoch: 6| Step: 9
Training loss: 2.7586064479106738
Validation loss: 2.8542589340823246

Epoch: 6| Step: 10
Training loss: 3.5073481127044412
Validation loss: 2.8488587740766085

Epoch: 6| Step: 11
Training loss: 3.3398994307310303
Validation loss: 2.850644625903751

Epoch: 6| Step: 12
Training loss: 2.5465737381136053
Validation loss: 2.8575604708201405

Epoch: 6| Step: 13
Training loss: 2.874485633282035
Validation loss: 2.850844014277663

Epoch: 204| Step: 0
Training loss: 3.426383058065123
Validation loss: 2.8452229255797685

Epoch: 6| Step: 1
Training loss: 3.14065855397382
Validation loss: 2.841477867607337

Epoch: 6| Step: 2
Training loss: 3.5374167280876447
Validation loss: 2.844549132377747

Epoch: 6| Step: 3
Training loss: 2.621605813140058
Validation loss: 2.8411691099482486

Epoch: 6| Step: 4
Training loss: 3.0699605570194666
Validation loss: 2.8460309494225853

Epoch: 6| Step: 5
Training loss: 3.4274973208627726
Validation loss: 2.837856761395326

Epoch: 6| Step: 6
Training loss: 2.724542344885597
Validation loss: 2.8416788103523007

Epoch: 6| Step: 7
Training loss: 3.7457569277180616
Validation loss: 2.8412240019893265

Epoch: 6| Step: 8
Training loss: 3.388886880787183
Validation loss: 2.8375210864102267

Epoch: 6| Step: 9
Training loss: 2.813291650195126
Validation loss: 2.8411216791584466

Epoch: 6| Step: 10
Training loss: 3.0487727588462556
Validation loss: 2.841300194914274

Epoch: 6| Step: 11
Training loss: 2.711533890349369
Validation loss: 2.8435877632345083

Epoch: 6| Step: 12
Training loss: 3.1301513937512246
Validation loss: 2.840029571150472

Epoch: 6| Step: 13
Training loss: 2.805364330518769
Validation loss: 2.8409448531911927

Epoch: 205| Step: 0
Training loss: 3.085037756987122
Validation loss: 2.848490877100085

Epoch: 6| Step: 1
Training loss: 3.6367001312795413
Validation loss: 2.8428800618710466

Epoch: 6| Step: 2
Training loss: 3.8550396866988215
Validation loss: 2.844963926182518

Epoch: 6| Step: 3
Training loss: 2.4168659215756128
Validation loss: 2.8394480893967398

Epoch: 6| Step: 4
Training loss: 2.3283103510660577
Validation loss: 2.8388151532492083

Epoch: 6| Step: 5
Training loss: 3.5643827582951633
Validation loss: 2.8370762706539145

Epoch: 6| Step: 6
Training loss: 3.7711662581075713
Validation loss: 2.8369026012011576

Epoch: 6| Step: 7
Training loss: 2.4196361406923823
Validation loss: 2.837490731161343

Epoch: 6| Step: 8
Training loss: 2.44318938788437
Validation loss: 2.840008136007373

Epoch: 6| Step: 9
Training loss: 2.7919261773796498
Validation loss: 2.836197015453649

Epoch: 6| Step: 10
Training loss: 3.2848958423655428
Validation loss: 2.8399655522948506

Epoch: 6| Step: 11
Training loss: 3.597016815120791
Validation loss: 2.8356283171816514

Epoch: 6| Step: 12
Training loss: 3.1356339152321344
Validation loss: 2.835346706956735

Epoch: 6| Step: 13
Training loss: 3.030182798052259
Validation loss: 2.8372619342197014

Epoch: 206| Step: 0
Training loss: 3.412579736022576
Validation loss: 2.8364419303482635

Epoch: 6| Step: 1
Training loss: 2.3277730995845394
Validation loss: 2.834746344726751

Epoch: 6| Step: 2
Training loss: 2.99697898708203
Validation loss: 2.8411881578367444

Epoch: 6| Step: 3
Training loss: 2.8885505449608213
Validation loss: 2.84141510482154

Epoch: 6| Step: 4
Training loss: 3.611348194914485
Validation loss: 2.8390325601404927

Epoch: 6| Step: 5
Training loss: 3.559077710470779
Validation loss: 2.838245526246103

Epoch: 6| Step: 6
Training loss: 2.976242088233657
Validation loss: 2.8417261605738964

Epoch: 6| Step: 7
Training loss: 3.3821149639890526
Validation loss: 2.835879097546251

Epoch: 6| Step: 8
Training loss: 3.741336223960987
Validation loss: 2.834648802037549

Epoch: 6| Step: 9
Training loss: 2.4542421360641784
Validation loss: 2.835225652943088

Epoch: 6| Step: 10
Training loss: 3.128389885021539
Validation loss: 2.837869295655598

Epoch: 6| Step: 11
Training loss: 3.800256424333236
Validation loss: 2.8396007725424464

Epoch: 6| Step: 12
Training loss: 2.5540220928087956
Validation loss: 2.839004556229367

Epoch: 6| Step: 13
Training loss: 2.16933550667649
Validation loss: 2.8365356515997573

Epoch: 207| Step: 0
Training loss: 3.457345170245618
Validation loss: 2.837358513360604

Epoch: 6| Step: 1
Training loss: 3.513677303358786
Validation loss: 2.835467790159312

Epoch: 6| Step: 2
Training loss: 3.223056023972744
Validation loss: 2.8433099564228943

Epoch: 6| Step: 3
Training loss: 2.9398210162222247
Validation loss: 2.8419795032429565

Epoch: 6| Step: 4
Training loss: 3.4027858932986548
Validation loss: 2.8419657377492933

Epoch: 6| Step: 5
Training loss: 2.8972907664049212
Validation loss: 2.842647092958263

Epoch: 6| Step: 6
Training loss: 2.9907124122911295
Validation loss: 2.8402805143991126

Epoch: 6| Step: 7
Training loss: 3.2648787672543316
Validation loss: 2.8381366267273713

Epoch: 6| Step: 8
Training loss: 2.6181463961661526
Validation loss: 2.8360963471434313

Epoch: 6| Step: 9
Training loss: 3.2225932167130984
Validation loss: 2.834731071797741

Epoch: 6| Step: 10
Training loss: 2.388916801565564
Validation loss: 2.83723066810901

Epoch: 6| Step: 11
Training loss: 3.4869791058898114
Validation loss: 2.8379612236161336

Epoch: 6| Step: 12
Training loss: 3.4011581580096943
Validation loss: 2.837414081763997

Epoch: 6| Step: 13
Training loss: 2.848696253203837
Validation loss: 2.8369574998872276

Epoch: 208| Step: 0
Training loss: 2.470120592764218
Validation loss: 2.8359493059996064

Epoch: 6| Step: 1
Training loss: 3.9635793088444693
Validation loss: 2.8428087593625406

Epoch: 6| Step: 2
Training loss: 2.551832184143917
Validation loss: 2.8432570351001756

Epoch: 6| Step: 3
Training loss: 2.8692675952589584
Validation loss: 2.8499343348179327

Epoch: 6| Step: 4
Training loss: 3.39562507099985
Validation loss: 2.848946470860683

Epoch: 6| Step: 5
Training loss: 3.2150549558507744
Validation loss: 2.8435436977634705

Epoch: 6| Step: 6
Training loss: 2.545034293372755
Validation loss: 2.837558362804303

Epoch: 6| Step: 7
Training loss: 3.6651280527265757
Validation loss: 2.8373681811230447

Epoch: 6| Step: 8
Training loss: 3.4377980883271717
Validation loss: 2.8340645599933967

Epoch: 6| Step: 9
Training loss: 3.377875057152558
Validation loss: 2.837572084629495

Epoch: 6| Step: 10
Training loss: 3.334774627619774
Validation loss: 2.8328174990727693

Epoch: 6| Step: 11
Training loss: 2.7494560917582573
Validation loss: 2.8340087065483983

Epoch: 6| Step: 12
Training loss: 3.016283032662864
Validation loss: 2.8356959995718007

Epoch: 6| Step: 13
Training loss: 2.728892819786278
Validation loss: 2.8359534028326996

Epoch: 209| Step: 0
Training loss: 2.4227123166669693
Validation loss: 2.837604572059998

Epoch: 6| Step: 1
Training loss: 3.190243606114966
Validation loss: 2.845465352680851

Epoch: 6| Step: 2
Training loss: 3.609532868867259
Validation loss: 2.852551435183884

Epoch: 6| Step: 3
Training loss: 2.8259104282846166
Validation loss: 2.849883248370619

Epoch: 6| Step: 4
Training loss: 2.7873148424723917
Validation loss: 2.85482784754035

Epoch: 6| Step: 5
Training loss: 2.8937301865758314
Validation loss: 2.859559141358201

Epoch: 6| Step: 6
Training loss: 2.448931663516159
Validation loss: 2.868108111999627

Epoch: 6| Step: 7
Training loss: 2.9301894101317147
Validation loss: 2.839356633033218

Epoch: 6| Step: 8
Training loss: 3.4930432527770803
Validation loss: 2.830972660451463

Epoch: 6| Step: 9
Training loss: 3.832229220286016
Validation loss: 2.8310475038214036

Epoch: 6| Step: 10
Training loss: 4.08103166963029
Validation loss: 2.8288724332332444

Epoch: 6| Step: 11
Training loss: 2.7335386904665957
Validation loss: 2.833841043715226

Epoch: 6| Step: 12
Training loss: 3.1366992916582013
Validation loss: 2.8325829468337154

Epoch: 6| Step: 13
Training loss: 3.0213996268718293
Validation loss: 2.8346534442904434

Epoch: 210| Step: 0
Training loss: 2.880439256972858
Validation loss: 2.8333573102087337

Epoch: 6| Step: 1
Training loss: 3.147425941038373
Validation loss: 2.834160614000937

Epoch: 6| Step: 2
Training loss: 3.3155814179658076
Validation loss: 2.8305006331851437

Epoch: 6| Step: 3
Training loss: 3.1210170540678286
Validation loss: 2.833345446358641

Epoch: 6| Step: 4
Training loss: 2.8144971750109344
Validation loss: 2.833719272194068

Epoch: 6| Step: 5
Training loss: 2.9349094087049243
Validation loss: 2.8301718667658906

Epoch: 6| Step: 6
Training loss: 3.2340681879596413
Validation loss: 2.8300667664604062

Epoch: 6| Step: 7
Training loss: 3.306273600560779
Validation loss: 2.828984686192333

Epoch: 6| Step: 8
Training loss: 3.1343022559596685
Validation loss: 2.830654130424858

Epoch: 6| Step: 9
Training loss: 3.352842428881094
Validation loss: 2.827755855621296

Epoch: 6| Step: 10
Training loss: 3.3793424291718464
Validation loss: 2.8320470643300344

Epoch: 6| Step: 11
Training loss: 2.612015718538386
Validation loss: 2.834389764397029

Epoch: 6| Step: 12
Training loss: 3.4293068085806975
Validation loss: 2.8320714654779295

Epoch: 6| Step: 13
Training loss: 3.2233699493800594
Validation loss: 2.829215839727127

Epoch: 211| Step: 0
Training loss: 3.202981787480631
Validation loss: 2.8311263168249523

Epoch: 6| Step: 1
Training loss: 2.9986465898042125
Validation loss: 2.8332082430052683

Epoch: 6| Step: 2
Training loss: 3.105071650613611
Validation loss: 2.830846053662802

Epoch: 6| Step: 3
Training loss: 2.841530740867314
Validation loss: 2.832976940138799

Epoch: 6| Step: 4
Training loss: 3.295676063100047
Validation loss: 2.8319027324365855

Epoch: 6| Step: 5
Training loss: 3.2016279490359043
Validation loss: 2.834000099730851

Epoch: 6| Step: 6
Training loss: 2.7588450630378185
Validation loss: 2.832133460429913

Epoch: 6| Step: 7
Training loss: 3.25386932095641
Validation loss: 2.8339437795887594

Epoch: 6| Step: 8
Training loss: 3.1978736071012297
Validation loss: 2.8305429010039496

Epoch: 6| Step: 9
Training loss: 3.710056561761193
Validation loss: 2.8299581501048214

Epoch: 6| Step: 10
Training loss: 2.643553154292823
Validation loss: 2.833780116541501

Epoch: 6| Step: 11
Training loss: 3.5947460618613354
Validation loss: 2.8306644097691507

Epoch: 6| Step: 12
Training loss: 2.8837769918579923
Validation loss: 2.833268688436814

Epoch: 6| Step: 13
Training loss: 2.8803351284122014
Validation loss: 2.832180814545414

Epoch: 212| Step: 0
Training loss: 3.425903039766073
Validation loss: 2.8356301813982063

Epoch: 6| Step: 1
Training loss: 3.172685491431362
Validation loss: 2.833637373847794

Epoch: 6| Step: 2
Training loss: 3.062761879448057
Validation loss: 2.8324308484190013

Epoch: 6| Step: 3
Training loss: 3.402094134383489
Validation loss: 2.8319007797654385

Epoch: 6| Step: 4
Training loss: 3.042437486217908
Validation loss: 2.8312896787307875

Epoch: 6| Step: 5
Training loss: 3.332799073955464
Validation loss: 2.8347366110475516

Epoch: 6| Step: 6
Training loss: 2.5319785494264875
Validation loss: 2.8332966214599877

Epoch: 6| Step: 7
Training loss: 3.529301198461657
Validation loss: 2.8299154894475365

Epoch: 6| Step: 8
Training loss: 3.8474723345956
Validation loss: 2.834965357689884

Epoch: 6| Step: 9
Training loss: 2.686092984246735
Validation loss: 2.832704025995433

Epoch: 6| Step: 10
Training loss: 2.83792221356301
Validation loss: 2.832114714629136

Epoch: 6| Step: 11
Training loss: 3.1573309227745203
Validation loss: 2.8302002415940364

Epoch: 6| Step: 12
Training loss: 2.3148729675900364
Validation loss: 2.830819497449858

Epoch: 6| Step: 13
Training loss: 3.167725352616122
Validation loss: 2.8356503631365126

Epoch: 213| Step: 0
Training loss: 2.9517660899750777
Validation loss: 2.8348274550087864

Epoch: 6| Step: 1
Training loss: 3.7907222927152393
Validation loss: 2.8422253603278658

Epoch: 6| Step: 2
Training loss: 2.841189730567638
Validation loss: 2.845485069145592

Epoch: 6| Step: 3
Training loss: 3.6186855172060093
Validation loss: 2.8416103069358045

Epoch: 6| Step: 4
Training loss: 3.3193717072487963
Validation loss: 2.8432567312419845

Epoch: 6| Step: 5
Training loss: 3.4614433797183644
Validation loss: 2.8358875255452265

Epoch: 6| Step: 6
Training loss: 2.8148673372871196
Validation loss: 2.8270792700510654

Epoch: 6| Step: 7
Training loss: 3.157955502042557
Validation loss: 2.8258774004408176

Epoch: 6| Step: 8
Training loss: 3.527838890834594
Validation loss: 2.827877287870535

Epoch: 6| Step: 9
Training loss: 3.0142093161920336
Validation loss: 2.8269470223574387

Epoch: 6| Step: 10
Training loss: 2.508585302765772
Validation loss: 2.8288676528070855

Epoch: 6| Step: 11
Training loss: 2.414846842235312
Validation loss: 2.8273798943936352

Epoch: 6| Step: 12
Training loss: 3.179906439214557
Validation loss: 2.828107309067977

Epoch: 6| Step: 13
Training loss: 2.8591968918658046
Validation loss: 2.8272245364239317

Epoch: 214| Step: 0
Training loss: 3.278971725802661
Validation loss: 2.8279141211663505

Epoch: 6| Step: 1
Training loss: 3.0146992107301114
Validation loss: 2.8277479332948223

Epoch: 6| Step: 2
Training loss: 3.116038175101744
Validation loss: 2.827656641578952

Epoch: 6| Step: 3
Training loss: 2.680683451375692
Validation loss: 2.827076263047704

Epoch: 6| Step: 4
Training loss: 3.459832628645106
Validation loss: 2.8255452067639215

Epoch: 6| Step: 5
Training loss: 3.239662455648441
Validation loss: 2.8252056752250954

Epoch: 6| Step: 6
Training loss: 3.1640936955927437
Validation loss: 2.821847390212738

Epoch: 6| Step: 7
Training loss: 2.8985023182821354
Validation loss: 2.828590829244945

Epoch: 6| Step: 8
Training loss: 3.145566933238257
Validation loss: 2.8287834915151207

Epoch: 6| Step: 9
Training loss: 3.024501091034753
Validation loss: 2.844881341367419

Epoch: 6| Step: 10
Training loss: 3.1616334232988352
Validation loss: 2.8290205735030676

Epoch: 6| Step: 11
Training loss: 2.917828700778612
Validation loss: 2.8300452984333693

Epoch: 6| Step: 12
Training loss: 3.685381782040299
Validation loss: 2.834012097434655

Epoch: 6| Step: 13
Training loss: 2.834058238775104
Validation loss: 2.8330106050765216

Epoch: 215| Step: 0
Training loss: 2.778208923788625
Validation loss: 2.8300483312697176

Epoch: 6| Step: 1
Training loss: 3.799881486550418
Validation loss: 2.8301388691777984

Epoch: 6| Step: 2
Training loss: 2.9712122293461984
Validation loss: 2.8229481924214586

Epoch: 6| Step: 3
Training loss: 2.739994574214269
Validation loss: 2.819623723790989

Epoch: 6| Step: 4
Training loss: 2.550535415089445
Validation loss: 2.825249060330118

Epoch: 6| Step: 5
Training loss: 3.193419103034701
Validation loss: 2.819704999054394

Epoch: 6| Step: 6
Training loss: 3.0086316863357396
Validation loss: 2.818944481133014

Epoch: 6| Step: 7
Training loss: 3.2103885821864013
Validation loss: 2.8217493870939663

Epoch: 6| Step: 8
Training loss: 2.977101995482168
Validation loss: 2.820744083503883

Epoch: 6| Step: 9
Training loss: 4.028950826602826
Validation loss: 2.8212422797826444

Epoch: 6| Step: 10
Training loss: 2.8399088981952976
Validation loss: 2.8304679383208318

Epoch: 6| Step: 11
Training loss: 3.0689212665818775
Validation loss: 2.8238300822002502

Epoch: 6| Step: 12
Training loss: 3.0575320373004518
Validation loss: 2.8299967055745627

Epoch: 6| Step: 13
Training loss: 3.342725365059316
Validation loss: 2.8308956652247232

Epoch: 216| Step: 0
Training loss: 3.3836790036664994
Validation loss: 2.8349793633524136

Epoch: 6| Step: 1
Training loss: 2.703678669757965
Validation loss: 2.834337903919081

Epoch: 6| Step: 2
Training loss: 3.2191062656008977
Validation loss: 2.8296727371421873

Epoch: 6| Step: 3
Training loss: 2.4133844997538922
Validation loss: 2.8248553359626407

Epoch: 6| Step: 4
Training loss: 3.1667243216101317
Validation loss: 2.821537651051528

Epoch: 6| Step: 5
Training loss: 3.2620241307734887
Validation loss: 2.8240765607128706

Epoch: 6| Step: 6
Training loss: 3.4065607611610895
Validation loss: 2.8180888387248957

Epoch: 6| Step: 7
Training loss: 2.6542228592973136
Validation loss: 2.820842650483207

Epoch: 6| Step: 8
Training loss: 3.3066417786471702
Validation loss: 2.8227332622092907

Epoch: 6| Step: 9
Training loss: 3.6387212793965547
Validation loss: 2.821821046394584

Epoch: 6| Step: 10
Training loss: 3.1635444876405265
Validation loss: 2.8201173509116586

Epoch: 6| Step: 11
Training loss: 3.2001439062185644
Validation loss: 2.819431270314866

Epoch: 6| Step: 12
Training loss: 2.796427174097863
Validation loss: 2.823323783552782

Epoch: 6| Step: 13
Training loss: 3.2796544146493254
Validation loss: 2.8210651501362505

Epoch: 217| Step: 0
Training loss: 2.9736291243306354
Validation loss: 2.8194160153534304

Epoch: 6| Step: 1
Training loss: 3.492738138434417
Validation loss: 2.817891007382635

Epoch: 6| Step: 2
Training loss: 3.0966080844075132
Validation loss: 2.820631076323787

Epoch: 6| Step: 3
Training loss: 2.8288522702018173
Validation loss: 2.824662759724854

Epoch: 6| Step: 4
Training loss: 3.357543730063987
Validation loss: 2.823028170534229

Epoch: 6| Step: 5
Training loss: 3.322238354624262
Validation loss: 2.828089141210454

Epoch: 6| Step: 6
Training loss: 2.625288629558428
Validation loss: 2.8250482357436186

Epoch: 6| Step: 7
Training loss: 2.925665044577722
Validation loss: 2.8293324826809605

Epoch: 6| Step: 8
Training loss: 2.41021303082173
Validation loss: 2.8247407834029685

Epoch: 6| Step: 9
Training loss: 3.463695245459388
Validation loss: 2.817307086531931

Epoch: 6| Step: 10
Training loss: 3.145300123149627
Validation loss: 2.81603721859009

Epoch: 6| Step: 11
Training loss: 3.4768501077049256
Validation loss: 2.816206851236139

Epoch: 6| Step: 12
Training loss: 2.7828206117352208
Validation loss: 2.8194908881711953

Epoch: 6| Step: 13
Training loss: 3.8955189515148465
Validation loss: 2.8201759952319194

Epoch: 218| Step: 0
Training loss: 3.2619776457412946
Validation loss: 2.817120856781073

Epoch: 6| Step: 1
Training loss: 2.94638017887157
Validation loss: 2.818491583583064

Epoch: 6| Step: 2
Training loss: 3.3971002161910406
Validation loss: 2.8156674814390072

Epoch: 6| Step: 3
Training loss: 3.2018704074079825
Validation loss: 2.815526958174154

Epoch: 6| Step: 4
Training loss: 3.316517678625319
Validation loss: 2.8167825232197985

Epoch: 6| Step: 5
Training loss: 2.7770539251908612
Validation loss: 2.8178427917402353

Epoch: 6| Step: 6
Training loss: 2.9343257554607254
Validation loss: 2.817252583868069

Epoch: 6| Step: 7
Training loss: 3.0065729931310337
Validation loss: 2.8150360268256924

Epoch: 6| Step: 8
Training loss: 3.3104827784632054
Validation loss: 2.813133221330638

Epoch: 6| Step: 9
Training loss: 2.425574842139351
Validation loss: 2.812064170111403

Epoch: 6| Step: 10
Training loss: 3.1197904269428793
Validation loss: 2.819364553231916

Epoch: 6| Step: 11
Training loss: 3.5495662477949828
Validation loss: 2.824858851731224

Epoch: 6| Step: 12
Training loss: 3.0038511670522676
Validation loss: 2.8253746657626553

Epoch: 6| Step: 13
Training loss: 3.413665538903749
Validation loss: 2.824938667757591

Epoch: 219| Step: 0
Training loss: 2.1966522581392978
Validation loss: 2.831662933082159

Epoch: 6| Step: 1
Training loss: 3.4422168621346847
Validation loss: 2.828869425417235

Epoch: 6| Step: 2
Training loss: 3.555573807775485
Validation loss: 2.8293826372468254

Epoch: 6| Step: 3
Training loss: 3.062066495147211
Validation loss: 2.8206543592379067

Epoch: 6| Step: 4
Training loss: 2.9876776989556477
Validation loss: 2.8237166365365507

Epoch: 6| Step: 5
Training loss: 3.067528158616682
Validation loss: 2.817188612529385

Epoch: 6| Step: 6
Training loss: 2.898133459878881
Validation loss: 2.8148841624337013

Epoch: 6| Step: 7
Training loss: 3.6287425222920984
Validation loss: 2.815704723927243

Epoch: 6| Step: 8
Training loss: 2.4501389717080078
Validation loss: 2.808797303591448

Epoch: 6| Step: 9
Training loss: 3.2269687350673313
Validation loss: 2.8131416053838785

Epoch: 6| Step: 10
Training loss: 3.453821724731256
Validation loss: 2.820565928223721

Epoch: 6| Step: 11
Training loss: 2.7654301634008878
Validation loss: 2.8222035104795915

Epoch: 6| Step: 12
Training loss: 2.938026218762145
Validation loss: 2.8160082376677504

Epoch: 6| Step: 13
Training loss: 3.9215687180032908
Validation loss: 2.8141091887577896

Epoch: 220| Step: 0
Training loss: 2.5772163408186772
Validation loss: 2.8103204729608056

Epoch: 6| Step: 1
Training loss: 2.0141576112673314
Validation loss: 2.8127810904024733

Epoch: 6| Step: 2
Training loss: 3.555133095783525
Validation loss: 2.8070549991946763

Epoch: 6| Step: 3
Training loss: 3.592937078997863
Validation loss: 2.8117834165028817

Epoch: 6| Step: 4
Training loss: 3.5807245797792593
Validation loss: 2.8154202030060502

Epoch: 6| Step: 5
Training loss: 2.9619737890141162
Validation loss: 2.8096608040605395

Epoch: 6| Step: 6
Training loss: 3.387589603379201
Validation loss: 2.811806020492503

Epoch: 6| Step: 7
Training loss: 2.3222539210044637
Validation loss: 2.812102082974683

Epoch: 6| Step: 8
Training loss: 3.2675369725255274
Validation loss: 2.8136850082442812

Epoch: 6| Step: 9
Training loss: 3.388778535335092
Validation loss: 2.809260461716231

Epoch: 6| Step: 10
Training loss: 3.0519198394487526
Validation loss: 2.810575912236538

Epoch: 6| Step: 11
Training loss: 3.2632066451027244
Validation loss: 2.813428909966532

Epoch: 6| Step: 12
Training loss: 3.2126362337548535
Validation loss: 2.8074938886407903

Epoch: 6| Step: 13
Training loss: 2.9036453224261507
Validation loss: 2.817456883121322

Epoch: 221| Step: 0
Training loss: 3.572576093243726
Validation loss: 2.815291573686386

Epoch: 6| Step: 1
Training loss: 2.994510555618798
Validation loss: 2.816559242893651

Epoch: 6| Step: 2
Training loss: 2.7733038211896734
Validation loss: 2.820269820699079

Epoch: 6| Step: 3
Training loss: 3.605704418675829
Validation loss: 2.830366088925215

Epoch: 6| Step: 4
Training loss: 3.155689000798904
Validation loss: 2.8560705153360484

Epoch: 6| Step: 5
Training loss: 2.818105325331952
Validation loss: 2.8554416793977215

Epoch: 6| Step: 6
Training loss: 2.95185897574032
Validation loss: 2.862801913471034

Epoch: 6| Step: 7
Training loss: 2.5559896247903926
Validation loss: 2.859617616915491

Epoch: 6| Step: 8
Training loss: 2.8249428059687562
Validation loss: 2.8246790691016335

Epoch: 6| Step: 9
Training loss: 3.5191525542397573
Validation loss: 2.8138927188057865

Epoch: 6| Step: 10
Training loss: 3.1682589359234186
Validation loss: 2.810470554364219

Epoch: 6| Step: 11
Training loss: 3.5555909737836218
Validation loss: 2.8094716338313255

Epoch: 6| Step: 12
Training loss: 2.764264305428943
Validation loss: 2.813010935251412

Epoch: 6| Step: 13
Training loss: 3.123083824144308
Validation loss: 2.8181476053102577

Epoch: 222| Step: 0
Training loss: 2.5549045668842956
Validation loss: 2.8213122391217578

Epoch: 6| Step: 1
Training loss: 3.7896392068768683
Validation loss: 2.8312501140542756

Epoch: 6| Step: 2
Training loss: 3.360177303586173
Validation loss: 2.82738655514763

Epoch: 6| Step: 3
Training loss: 2.95113875183058
Validation loss: 2.819434028147031

Epoch: 6| Step: 4
Training loss: 2.623763474370298
Validation loss: 2.8206808039307933

Epoch: 6| Step: 5
Training loss: 3.1162782648046448
Validation loss: 2.8163758164557953

Epoch: 6| Step: 6
Training loss: 3.0432222821411696
Validation loss: 2.8155563738192395

Epoch: 6| Step: 7
Training loss: 3.1636766740070406
Validation loss: 2.8148075768759044

Epoch: 6| Step: 8
Training loss: 3.1314810113722484
Validation loss: 2.8144832714591166

Epoch: 6| Step: 9
Training loss: 2.444422940920642
Validation loss: 2.8152637861986545

Epoch: 6| Step: 10
Training loss: 3.04685559388852
Validation loss: 2.8194275977475014

Epoch: 6| Step: 11
Training loss: 3.213433476651151
Validation loss: 2.811991641316798

Epoch: 6| Step: 12
Training loss: 3.803522891292035
Validation loss: 2.8146552784489027

Epoch: 6| Step: 13
Training loss: 3.283891468405972
Validation loss: 2.820807286224337

Epoch: 223| Step: 0
Training loss: 3.587621090005077
Validation loss: 2.8284469962356704

Epoch: 6| Step: 1
Training loss: 3.54037538811832
Validation loss: 2.825937015207514

Epoch: 6| Step: 2
Training loss: 2.19853760925842
Validation loss: 2.8151707254848075

Epoch: 6| Step: 3
Training loss: 3.1104821769082314
Validation loss: 2.822873419477418

Epoch: 6| Step: 4
Training loss: 3.4951096838683773
Validation loss: 2.8142336817297595

Epoch: 6| Step: 5
Training loss: 3.0562031685765243
Validation loss: 2.8142982239831746

Epoch: 6| Step: 6
Training loss: 3.1383306368834636
Validation loss: 2.809156871497777

Epoch: 6| Step: 7
Training loss: 2.7777486471132167
Validation loss: 2.811137871538743

Epoch: 6| Step: 8
Training loss: 2.8099857536307744
Validation loss: 2.8123151547522736

Epoch: 6| Step: 9
Training loss: 3.191544304503295
Validation loss: 2.8100334171127987

Epoch: 6| Step: 10
Training loss: 2.8196958253372504
Validation loss: 2.813724966599622

Epoch: 6| Step: 11
Training loss: 3.097053690508069
Validation loss: 2.808643036275449

Epoch: 6| Step: 12
Training loss: 3.6608475690762146
Validation loss: 2.810549587733112

Epoch: 6| Step: 13
Training loss: 2.500558981392238
Validation loss: 2.8099079807915355

Epoch: 224| Step: 0
Training loss: 3.488439541393825
Validation loss: 2.8083088518795893

Epoch: 6| Step: 1
Training loss: 3.3136670917628006
Validation loss: 2.8086852697521985

Epoch: 6| Step: 2
Training loss: 3.5780692949914683
Validation loss: 2.8121630267377458

Epoch: 6| Step: 3
Training loss: 3.3722161008251033
Validation loss: 2.8114974154814556

Epoch: 6| Step: 4
Training loss: 2.819921070103518
Validation loss: 2.8086164572463863

Epoch: 6| Step: 5
Training loss: 2.8490919306160625
Validation loss: 2.807760102574639

Epoch: 6| Step: 6
Training loss: 2.157068622380033
Validation loss: 2.80870611699181

Epoch: 6| Step: 7
Training loss: 2.531246044014559
Validation loss: 2.808332493469321

Epoch: 6| Step: 8
Training loss: 2.483970753152027
Validation loss: 2.814415113549319

Epoch: 6| Step: 9
Training loss: 3.220463269002177
Validation loss: 2.8201676057290452

Epoch: 6| Step: 10
Training loss: 2.65591042535898
Validation loss: 2.819009562122816

Epoch: 6| Step: 11
Training loss: 2.9910127808894993
Validation loss: 2.835393383539352

Epoch: 6| Step: 12
Training loss: 3.878651528960222
Validation loss: 2.8260298021257513

Epoch: 6| Step: 13
Training loss: 4.086670789690619
Validation loss: 2.832600681312084

Epoch: 225| Step: 0
Training loss: 2.8331108192881684
Validation loss: 2.8215688066705296

Epoch: 6| Step: 1
Training loss: 3.596856010645397
Validation loss: 2.817827925758852

Epoch: 6| Step: 2
Training loss: 3.0527665520337157
Validation loss: 2.820833955780667

Epoch: 6| Step: 3
Training loss: 3.1522992779739423
Validation loss: 2.819116327777719

Epoch: 6| Step: 4
Training loss: 3.2553577276916434
Validation loss: 2.8116139391436885

Epoch: 6| Step: 5
Training loss: 3.1482955862770856
Validation loss: 2.8107267616632483

Epoch: 6| Step: 6
Training loss: 3.166808342692324
Validation loss: 2.8095687631303403

Epoch: 6| Step: 7
Training loss: 2.8431852010381498
Validation loss: 2.8085625946691524

Epoch: 6| Step: 8
Training loss: 2.9140688816849525
Validation loss: 2.8107325415826003

Epoch: 6| Step: 9
Training loss: 3.0151796951011063
Validation loss: 2.812638150631154

Epoch: 6| Step: 10
Training loss: 2.706933662450056
Validation loss: 2.8079650449974842

Epoch: 6| Step: 11
Training loss: 3.3571991727331865
Validation loss: 2.808527963030331

Epoch: 6| Step: 12
Training loss: 3.426914075635266
Validation loss: 2.810711091883642

Epoch: 6| Step: 13
Training loss: 2.780487298863389
Validation loss: 2.813672886507703

Epoch: 226| Step: 0
Training loss: 3.6702591607581208
Validation loss: 2.807664487607059

Epoch: 6| Step: 1
Training loss: 3.750291177253384
Validation loss: 2.810843038184467

Epoch: 6| Step: 2
Training loss: 2.5023764759106815
Validation loss: 2.8124368621776177

Epoch: 6| Step: 3
Training loss: 2.3103285208267477
Validation loss: 2.8110478288016307

Epoch: 6| Step: 4
Training loss: 2.9384874348108103
Validation loss: 2.810344096715867

Epoch: 6| Step: 5
Training loss: 2.383845371204831
Validation loss: 2.8157928769661686

Epoch: 6| Step: 6
Training loss: 3.6144310353905946
Validation loss: 2.822511769639536

Epoch: 6| Step: 7
Training loss: 2.932737344826542
Validation loss: 2.826185773661146

Epoch: 6| Step: 8
Training loss: 2.973231095864239
Validation loss: 2.820657304921391

Epoch: 6| Step: 9
Training loss: 3.057297940006784
Validation loss: 2.827572990049786

Epoch: 6| Step: 10
Training loss: 3.4656454403879007
Validation loss: 2.825434015757822

Epoch: 6| Step: 11
Training loss: 3.4357037099115235
Validation loss: 2.8118169659296006

Epoch: 6| Step: 12
Training loss: 2.8865410075100457
Validation loss: 2.8084860959671

Epoch: 6| Step: 13
Training loss: 3.1613786782667943
Validation loss: 2.802389099318968

Epoch: 227| Step: 0
Training loss: 3.5463281957794286
Validation loss: 2.805143245885076

Epoch: 6| Step: 1
Training loss: 3.4530425601284014
Validation loss: 2.8037909642069483

Epoch: 6| Step: 2
Training loss: 2.9614033596765594
Validation loss: 2.7988946428160166

Epoch: 6| Step: 3
Training loss: 3.2171606195187437
Validation loss: 2.7997540992221643

Epoch: 6| Step: 4
Training loss: 2.736090421732885
Validation loss: 2.8026867630118644

Epoch: 6| Step: 5
Training loss: 2.193696754439741
Validation loss: 2.803785320845468

Epoch: 6| Step: 6
Training loss: 2.8265211078065517
Validation loss: 2.80354890024273

Epoch: 6| Step: 7
Training loss: 3.1661490636400043
Validation loss: 2.8058787771282994

Epoch: 6| Step: 8
Training loss: 2.8827446823620235
Validation loss: 2.8051981547206224

Epoch: 6| Step: 9
Training loss: 3.2161886153162023
Validation loss: 2.8030028098136435

Epoch: 6| Step: 10
Training loss: 2.6697564900542003
Validation loss: 2.8029429464420836

Epoch: 6| Step: 11
Training loss: 3.2080280274286985
Validation loss: 2.803632126489562

Epoch: 6| Step: 12
Training loss: 3.6349921793899465
Validation loss: 2.802229636885241

Epoch: 6| Step: 13
Training loss: 3.881356225272416
Validation loss: 2.8037407185059258

Epoch: 228| Step: 0
Training loss: 3.348692761338201
Validation loss: 2.8054086959524183

Epoch: 6| Step: 1
Training loss: 3.117026418094828
Validation loss: 2.8031834933716127

Epoch: 6| Step: 2
Training loss: 3.1716272417091456
Validation loss: 2.7994281936816456

Epoch: 6| Step: 3
Training loss: 3.043469526148044
Validation loss: 2.8004214543874344

Epoch: 6| Step: 4
Training loss: 2.6942741716031016
Validation loss: 2.8052088033387736

Epoch: 6| Step: 5
Training loss: 2.9520952962571507
Validation loss: 2.801091042966793

Epoch: 6| Step: 6
Training loss: 2.176238582083753
Validation loss: 2.8063827876787784

Epoch: 6| Step: 7
Training loss: 3.3768359241699395
Validation loss: 2.8064752674272806

Epoch: 6| Step: 8
Training loss: 3.391581738757571
Validation loss: 2.8099918790228493

Epoch: 6| Step: 9
Training loss: 2.428754424966265
Validation loss: 2.8196137233313117

Epoch: 6| Step: 10
Training loss: 3.3053454021537694
Validation loss: 2.8092126391062613

Epoch: 6| Step: 11
Training loss: 3.2639862767473335
Validation loss: 2.8059251536006866

Epoch: 6| Step: 12
Training loss: 3.6946151107592238
Validation loss: 2.800320242442045

Epoch: 6| Step: 13
Training loss: 3.3400469087972864
Validation loss: 2.8000738838441706

Epoch: 229| Step: 0
Training loss: 3.1954020368720575
Validation loss: 2.7986602649283783

Epoch: 6| Step: 1
Training loss: 2.49883653270505
Validation loss: 2.7999185654668475

Epoch: 6| Step: 2
Training loss: 3.035276746874121
Validation loss: 2.7979908386279626

Epoch: 6| Step: 3
Training loss: 3.287936708866774
Validation loss: 2.804769136783933

Epoch: 6| Step: 4
Training loss: 2.798854787823322
Validation loss: 2.7994410163052263

Epoch: 6| Step: 5
Training loss: 3.129773575755608
Validation loss: 2.802855035917853

Epoch: 6| Step: 6
Training loss: 3.5077526877556564
Validation loss: 2.8043832272539464

Epoch: 6| Step: 7
Training loss: 3.0606104412671273
Validation loss: 2.7983870931688433

Epoch: 6| Step: 8
Training loss: 2.701766449977834
Validation loss: 2.800547702826731

Epoch: 6| Step: 9
Training loss: 3.4200311857887464
Validation loss: 2.80035278761085

Epoch: 6| Step: 10
Training loss: 3.363023488870444
Validation loss: 2.8033577967880245

Epoch: 6| Step: 11
Training loss: 3.0778752724285225
Validation loss: 2.802534825857265

Epoch: 6| Step: 12
Training loss: 3.2384143613323473
Validation loss: 2.7969293397166597

Epoch: 6| Step: 13
Training loss: 2.847817498810407
Validation loss: 2.7949620318937356

Epoch: 230| Step: 0
Training loss: 3.1495489615004675
Validation loss: 2.79824093074657

Epoch: 6| Step: 1
Training loss: 3.5909702330938114
Validation loss: 2.797572737438065

Epoch: 6| Step: 2
Training loss: 2.8910172479854586
Validation loss: 2.7985682982479623

Epoch: 6| Step: 3
Training loss: 2.616582088763888
Validation loss: 2.7968235209348227

Epoch: 6| Step: 4
Training loss: 3.544440152143419
Validation loss: 2.794828211251699

Epoch: 6| Step: 5
Training loss: 2.903753705722318
Validation loss: 2.7996368310386366

Epoch: 6| Step: 6
Training loss: 1.9965959428585711
Validation loss: 2.799360075828792

Epoch: 6| Step: 7
Training loss: 3.232120483730472
Validation loss: 2.799380367946197

Epoch: 6| Step: 8
Training loss: 3.567907946866002
Validation loss: 2.7967676447003136

Epoch: 6| Step: 9
Training loss: 2.8411554930208345
Validation loss: 2.7974649259636872

Epoch: 6| Step: 10
Training loss: 3.5892472959846886
Validation loss: 2.7951130581082193

Epoch: 6| Step: 11
Training loss: 3.165032885532772
Validation loss: 2.79424453810291

Epoch: 6| Step: 12
Training loss: 3.0180761623795758
Validation loss: 2.7939800551576544

Epoch: 6| Step: 13
Training loss: 2.8914300570761484
Validation loss: 2.7947386484105508

Epoch: 231| Step: 0
Training loss: 3.1094277535568895
Validation loss: 2.798960714827195

Epoch: 6| Step: 1
Training loss: 3.3840411556076972
Validation loss: 2.8006865629462654

Epoch: 6| Step: 2
Training loss: 3.357909978744815
Validation loss: 2.8299772417455036

Epoch: 6| Step: 3
Training loss: 2.7954355297019844
Validation loss: 2.8589347775277387

Epoch: 6| Step: 4
Training loss: 3.26774754515398
Validation loss: 2.864519062533138

Epoch: 6| Step: 5
Training loss: 3.102635579923798
Validation loss: 2.8262692839267074

Epoch: 6| Step: 6
Training loss: 3.0300907395879615
Validation loss: 2.800161887175316

Epoch: 6| Step: 7
Training loss: 3.0435113582233067
Validation loss: 2.79595362508395

Epoch: 6| Step: 8
Training loss: 3.0515698379608076
Validation loss: 2.789571548627317

Epoch: 6| Step: 9
Training loss: 2.9099201285815597
Validation loss: 2.791942583412527

Epoch: 6| Step: 10
Training loss: 2.776035692925434
Validation loss: 2.7900019258194124

Epoch: 6| Step: 11
Training loss: 2.805905218545164
Validation loss: 2.792103268737501

Epoch: 6| Step: 12
Training loss: 3.726507222467382
Validation loss: 2.7943895756246153

Epoch: 6| Step: 13
Training loss: 3.030829331615017
Validation loss: 2.7930992178028666

Epoch: 232| Step: 0
Training loss: 2.270033762676539
Validation loss: 2.793039721341556

Epoch: 6| Step: 1
Training loss: 3.16947131853656
Validation loss: 2.796201129669105

Epoch: 6| Step: 2
Training loss: 3.377172124324138
Validation loss: 2.7940229103244323

Epoch: 6| Step: 3
Training loss: 2.5224006341393204
Validation loss: 2.794414323950384

Epoch: 6| Step: 4
Training loss: 3.102714420750546
Validation loss: 2.7915953494056702

Epoch: 6| Step: 5
Training loss: 2.8460397409973788
Validation loss: 2.793156592812246

Epoch: 6| Step: 6
Training loss: 3.471106338907441
Validation loss: 2.792655421376236

Epoch: 6| Step: 7
Training loss: 3.763990625286691
Validation loss: 2.7958124465667127

Epoch: 6| Step: 8
Training loss: 2.9994916485191507
Validation loss: 2.7960734719522327

Epoch: 6| Step: 9
Training loss: 3.2083966302614075
Validation loss: 2.798686666454423

Epoch: 6| Step: 10
Training loss: 3.0750898704731893
Validation loss: 2.804033381210516

Epoch: 6| Step: 11
Training loss: 2.3883197116219335
Validation loss: 2.808559012861046

Epoch: 6| Step: 12
Training loss: 3.1590980295184607
Validation loss: 2.8075172266274895

Epoch: 6| Step: 13
Training loss: 4.021166588342389
Validation loss: 2.8143677465371746

Epoch: 233| Step: 0
Training loss: 3.1230728310561466
Validation loss: 2.8169874562963986

Epoch: 6| Step: 1
Training loss: 3.6224816881431736
Validation loss: 2.823899844884917

Epoch: 6| Step: 2
Training loss: 2.6080037242886216
Validation loss: 2.8228083703545686

Epoch: 6| Step: 3
Training loss: 3.7051456909775666
Validation loss: 2.823948515420308

Epoch: 6| Step: 4
Training loss: 2.8204054883172867
Validation loss: 2.802332931535134

Epoch: 6| Step: 5
Training loss: 2.9417022515612996
Validation loss: 2.792007218589422

Epoch: 6| Step: 6
Training loss: 3.3290097488897694
Validation loss: 2.788861323619703

Epoch: 6| Step: 7
Training loss: 2.958026511887907
Validation loss: 2.7872780438396387

Epoch: 6| Step: 8
Training loss: 3.190526684657675
Validation loss: 2.7872251586931407

Epoch: 6| Step: 9
Training loss: 2.6405173736850176
Validation loss: 2.7914008092182763

Epoch: 6| Step: 10
Training loss: 2.6128548814584556
Validation loss: 2.7893417447022006

Epoch: 6| Step: 11
Training loss: 3.13599475757005
Validation loss: 2.793832142619246

Epoch: 6| Step: 12
Training loss: 3.0828794368663557
Validation loss: 2.7924007472406482

Epoch: 6| Step: 13
Training loss: 3.7788597938469133
Validation loss: 2.7899397591814847

Epoch: 234| Step: 0
Training loss: 3.144632847252371
Validation loss: 2.7884299227098186

Epoch: 6| Step: 1
Training loss: 2.8354172242495967
Validation loss: 2.7881372395232784

Epoch: 6| Step: 2
Training loss: 3.7785183205659516
Validation loss: 2.789583651946173

Epoch: 6| Step: 3
Training loss: 3.2207543511882806
Validation loss: 2.7997690208813486

Epoch: 6| Step: 4
Training loss: 2.9806629682583505
Validation loss: 2.8158474479427174

Epoch: 6| Step: 5
Training loss: 2.450999997864641
Validation loss: 2.821067343855913

Epoch: 6| Step: 6
Training loss: 2.8243609085288615
Validation loss: 2.831247264506968

Epoch: 6| Step: 7
Training loss: 2.824431309806616
Validation loss: 2.8292024226112016

Epoch: 6| Step: 8
Training loss: 2.540779917968641
Validation loss: 2.8409218791476207

Epoch: 6| Step: 9
Training loss: 3.12105937456625
Validation loss: 2.828704830746849

Epoch: 6| Step: 10
Training loss: 3.6076439343538436
Validation loss: 2.812223552576058

Epoch: 6| Step: 11
Training loss: 2.9581056605741947
Validation loss: 2.7902896743897814

Epoch: 6| Step: 12
Training loss: 3.7439168545791004
Validation loss: 2.788235042136513

Epoch: 6| Step: 13
Training loss: 3.085350888667474
Validation loss: 2.7907097623892696

Epoch: 235| Step: 0
Training loss: 2.7332996106587357
Validation loss: 2.7875514829834733

Epoch: 6| Step: 1
Training loss: 2.999253498024159
Validation loss: 2.789966611700259

Epoch: 6| Step: 2
Training loss: 3.2480360112378452
Validation loss: 2.7898169765762004

Epoch: 6| Step: 3
Training loss: 2.9944994090014867
Validation loss: 2.7936086935648508

Epoch: 6| Step: 4
Training loss: 2.8895093259751663
Validation loss: 2.792891018244251

Epoch: 6| Step: 5
Training loss: 2.969524563583879
Validation loss: 2.796366486960295

Epoch: 6| Step: 6
Training loss: 3.5253048704078473
Validation loss: 2.7956181035495344

Epoch: 6| Step: 7
Training loss: 3.3785565322091338
Validation loss: 2.801003880662116

Epoch: 6| Step: 8
Training loss: 2.3845094735358727
Validation loss: 2.8008561944318866

Epoch: 6| Step: 9
Training loss: 3.8493758798020057
Validation loss: 2.798286227237312

Epoch: 6| Step: 10
Training loss: 2.7823203952400593
Validation loss: 2.7944615172698706

Epoch: 6| Step: 11
Training loss: 3.1556672417511993
Validation loss: 2.7913446003379985

Epoch: 6| Step: 12
Training loss: 3.356384365581732
Validation loss: 2.7865641899959224

Epoch: 6| Step: 13
Training loss: 2.901431118605221
Validation loss: 2.78549466072511

Epoch: 236| Step: 0
Training loss: 2.768826802654537
Validation loss: 2.788470233773008

Epoch: 6| Step: 1
Training loss: 2.8876687268919077
Validation loss: 2.7889037831204844

Epoch: 6| Step: 2
Training loss: 3.1281626147467647
Validation loss: 2.7895594562841

Epoch: 6| Step: 3
Training loss: 3.2591652382990817
Validation loss: 2.797186506867472

Epoch: 6| Step: 4
Training loss: 3.040492488721952
Validation loss: 2.7967879446274733

Epoch: 6| Step: 5
Training loss: 3.241524428619641
Validation loss: 2.8009118078756954

Epoch: 6| Step: 6
Training loss: 3.026362618230255
Validation loss: 2.8013664329128054

Epoch: 6| Step: 7
Training loss: 3.034938809376584
Validation loss: 2.810061629455243

Epoch: 6| Step: 8
Training loss: 3.3857724672805927
Validation loss: 2.807085726493259

Epoch: 6| Step: 9
Training loss: 3.9014051986962417
Validation loss: 2.806184738602191

Epoch: 6| Step: 10
Training loss: 2.60768813013236
Validation loss: 2.800021547096894

Epoch: 6| Step: 11
Training loss: 3.019794171373834
Validation loss: 2.795403760003629

Epoch: 6| Step: 12
Training loss: 2.353135808790695
Validation loss: 2.79018216586255

Epoch: 6| Step: 13
Training loss: 3.6125409661844445
Validation loss: 2.783716906778571

Epoch: 237| Step: 0
Training loss: 3.1624111057498547
Validation loss: 2.7827637090339024

Epoch: 6| Step: 1
Training loss: 3.353151882664693
Validation loss: 2.783545512432976

Epoch: 6| Step: 2
Training loss: 2.996778347775865
Validation loss: 2.78120212714213

Epoch: 6| Step: 3
Training loss: 2.4497098050207287
Validation loss: 2.7821141368786386

Epoch: 6| Step: 4
Training loss: 3.179739686879786
Validation loss: 2.7819772690996873

Epoch: 6| Step: 5
Training loss: 3.109421926173066
Validation loss: 2.7802914586160257

Epoch: 6| Step: 6
Training loss: 3.1198599695913276
Validation loss: 2.784458681644517

Epoch: 6| Step: 7
Training loss: 3.090570530734469
Validation loss: 2.781735832105868

Epoch: 6| Step: 8
Training loss: 2.7330414926371085
Validation loss: 2.7802578745531457

Epoch: 6| Step: 9
Training loss: 3.6096563848819385
Validation loss: 2.77950879712136

Epoch: 6| Step: 10
Training loss: 3.3326474119809024
Validation loss: 2.7823267777969867

Epoch: 6| Step: 11
Training loss: 2.9953551892823893
Validation loss: 2.7791293757474573

Epoch: 6| Step: 12
Training loss: 2.7352543751979987
Validation loss: 2.7802243103707496

Epoch: 6| Step: 13
Training loss: 3.297145163508584
Validation loss: 2.781021999237206

Epoch: 238| Step: 0
Training loss: 2.7006315517015005
Validation loss: 2.781110270816541

Epoch: 6| Step: 1
Training loss: 3.1283507121813825
Validation loss: 2.7811667621246063

Epoch: 6| Step: 2
Training loss: 2.493752206595838
Validation loss: 2.7787684188404373

Epoch: 6| Step: 3
Training loss: 3.212283258511017
Validation loss: 2.782741038648513

Epoch: 6| Step: 4
Training loss: 3.0417688082611005
Validation loss: 2.780240479320736

Epoch: 6| Step: 5
Training loss: 3.119449874844518
Validation loss: 2.7779694664010077

Epoch: 6| Step: 6
Training loss: 3.111077077618898
Validation loss: 2.7790514543083744

Epoch: 6| Step: 7
Training loss: 3.5474775029464434
Validation loss: 2.7799108622039816

Epoch: 6| Step: 8
Training loss: 3.068308712682484
Validation loss: 2.7814564865021514

Epoch: 6| Step: 9
Training loss: 2.781488472648075
Validation loss: 2.7786866141703075

Epoch: 6| Step: 10
Training loss: 3.8346351541498565
Validation loss: 2.777940566375749

Epoch: 6| Step: 11
Training loss: 3.1146411869115145
Validation loss: 2.7786738027954123

Epoch: 6| Step: 12
Training loss: 2.8065747045581424
Validation loss: 2.7783821587399684

Epoch: 6| Step: 13
Training loss: 2.9157829217367834
Validation loss: 2.7785729602848077

Epoch: 239| Step: 0
Training loss: 2.991028085488117
Validation loss: 2.787371515224379

Epoch: 6| Step: 1
Training loss: 3.375553227046353
Validation loss: 2.792573334991472

Epoch: 6| Step: 2
Training loss: 2.8443760444774986
Validation loss: 2.7891947295930946

Epoch: 6| Step: 3
Training loss: 2.8597593622408715
Validation loss: 2.7905567119448516

Epoch: 6| Step: 4
Training loss: 3.218258718385891
Validation loss: 2.8169603953947706

Epoch: 6| Step: 5
Training loss: 3.3466821096704833
Validation loss: 2.828670230916548

Epoch: 6| Step: 6
Training loss: 4.175279464048518
Validation loss: 2.818430053533298

Epoch: 6| Step: 7
Training loss: 2.2070336265888755
Validation loss: 2.8243984956700796

Epoch: 6| Step: 8
Training loss: 2.977307804544315
Validation loss: 2.8224082397803256

Epoch: 6| Step: 9
Training loss: 3.5976783842882485
Validation loss: 2.8055478637431754

Epoch: 6| Step: 10
Training loss: 3.104952480179818
Validation loss: 2.7919364624961043

Epoch: 6| Step: 11
Training loss: 2.1657289774540534
Validation loss: 2.792466595581636

Epoch: 6| Step: 12
Training loss: 3.115778171826074
Validation loss: 2.791932708768144

Epoch: 6| Step: 13
Training loss: 2.5708816964800505
Validation loss: 2.786374945893168

Epoch: 240| Step: 0
Training loss: 3.223448943701663
Validation loss: 2.7874572745113717

Epoch: 6| Step: 1
Training loss: 2.759880695252309
Validation loss: 2.791558342712899

Epoch: 6| Step: 2
Training loss: 3.9420851395933516
Validation loss: 2.7914374387026233

Epoch: 6| Step: 3
Training loss: 3.6745185588596905
Validation loss: 2.785621539652987

Epoch: 6| Step: 4
Training loss: 3.0193317934710224
Validation loss: 2.7840481202890577

Epoch: 6| Step: 5
Training loss: 3.4167040070765067
Validation loss: 2.7848822479575492

Epoch: 6| Step: 6
Training loss: 2.4338143678841524
Validation loss: 2.783487748663357

Epoch: 6| Step: 7
Training loss: 2.431950634417695
Validation loss: 2.7820104324724833

Epoch: 6| Step: 8
Training loss: 2.8388371211750636
Validation loss: 2.7828994382073717

Epoch: 6| Step: 9
Training loss: 2.9435066333123836
Validation loss: 2.782001837568286

Epoch: 6| Step: 10
Training loss: 3.4729119154164003
Validation loss: 2.7761668530826666

Epoch: 6| Step: 11
Training loss: 2.302462263264022
Validation loss: 2.775602457444153

Epoch: 6| Step: 12
Training loss: 3.4872236026085055
Validation loss: 2.776012309141826

Epoch: 6| Step: 13
Training loss: 2.4042620683470086
Validation loss: 2.7759403677485444

Epoch: 241| Step: 0
Training loss: 3.463890039042187
Validation loss: 2.7747746711736365

Epoch: 6| Step: 1
Training loss: 2.5354142961410018
Validation loss: 2.7756465051972725

Epoch: 6| Step: 2
Training loss: 3.1664824850494595
Validation loss: 2.775011470157177

Epoch: 6| Step: 3
Training loss: 2.679562045794645
Validation loss: 2.777152261207167

Epoch: 6| Step: 4
Training loss: 3.5355859653367405
Validation loss: 2.774297973312239

Epoch: 6| Step: 5
Training loss: 3.478442286082933
Validation loss: 2.775177320516741

Epoch: 6| Step: 6
Training loss: 3.3618078604307686
Validation loss: 2.7750992178998106

Epoch: 6| Step: 7
Training loss: 3.1312763509955026
Validation loss: 2.7737517295995087

Epoch: 6| Step: 8
Training loss: 3.2147621709918197
Validation loss: 2.7730615310461113

Epoch: 6| Step: 9
Training loss: 3.2259195717081792
Validation loss: 2.7758501779434783

Epoch: 6| Step: 10
Training loss: 2.6588890877926556
Validation loss: 2.7728637083271583

Epoch: 6| Step: 11
Training loss: 3.6539048719128253
Validation loss: 2.7797897393385913

Epoch: 6| Step: 12
Training loss: 1.4970088381254738
Validation loss: 2.78470083079868

Epoch: 6| Step: 13
Training loss: 2.75966083087374
Validation loss: 2.7827499491048524

Epoch: 242| Step: 0
Training loss: 2.795264862149319
Validation loss: 2.784515616917837

Epoch: 6| Step: 1
Training loss: 3.138924816979985
Validation loss: 2.779870224133349

Epoch: 6| Step: 2
Training loss: 3.0724096537282044
Validation loss: 2.7764154595155506

Epoch: 6| Step: 3
Training loss: 3.401416674157306
Validation loss: 2.7793148194320505

Epoch: 6| Step: 4
Training loss: 2.685459160499366
Validation loss: 2.77896849836863

Epoch: 6| Step: 5
Training loss: 3.107115264669841
Validation loss: 2.7764014114280537

Epoch: 6| Step: 6
Training loss: 3.5298610420001064
Validation loss: 2.7824001517328343

Epoch: 6| Step: 7
Training loss: 3.1511488378705765
Validation loss: 2.7822494103057984

Epoch: 6| Step: 8
Training loss: 3.1672868288683995
Validation loss: 2.780081097410087

Epoch: 6| Step: 9
Training loss: 2.657820562656559
Validation loss: 2.7761869398109926

Epoch: 6| Step: 10
Training loss: 2.9481994888635428
Validation loss: 2.7748802886479806

Epoch: 6| Step: 11
Training loss: 3.1833145487232772
Validation loss: 2.7733951836326796

Epoch: 6| Step: 12
Training loss: 2.9655490684636834
Validation loss: 2.774436176287559

Epoch: 6| Step: 13
Training loss: 3.3003958031235268
Validation loss: 2.7712051921730714

Epoch: 243| Step: 0
Training loss: 3.4466038228054225
Validation loss: 2.771998954509951

Epoch: 6| Step: 1
Training loss: 2.9838200397685046
Validation loss: 2.7731591054470917

Epoch: 6| Step: 2
Training loss: 3.6225139380187534
Validation loss: 2.7729219097494275

Epoch: 6| Step: 3
Training loss: 2.8748822395422304
Validation loss: 2.769465436737342

Epoch: 6| Step: 4
Training loss: 2.888849816506407
Validation loss: 2.772295172464176

Epoch: 6| Step: 5
Training loss: 2.8206631344753803
Validation loss: 2.7736519374327986

Epoch: 6| Step: 6
Training loss: 3.516934706128741
Validation loss: 2.771107673865029

Epoch: 6| Step: 7
Training loss: 2.891148205394639
Validation loss: 2.7717803464270685

Epoch: 6| Step: 8
Training loss: 2.685464664934873
Validation loss: 2.769501214064345

Epoch: 6| Step: 9
Training loss: 2.184906102831913
Validation loss: 2.773292916951863

Epoch: 6| Step: 10
Training loss: 3.3147084773376205
Validation loss: 2.771695124133073

Epoch: 6| Step: 11
Training loss: 3.004309102639757
Validation loss: 2.7731507206935193

Epoch: 6| Step: 12
Training loss: 3.34778045459495
Validation loss: 2.772019790955919

Epoch: 6| Step: 13
Training loss: 3.3678552801794233
Validation loss: 2.772599312487397

Epoch: 244| Step: 0
Training loss: 3.71722906730023
Validation loss: 2.774304302248371

Epoch: 6| Step: 1
Training loss: 2.7048650884918715
Validation loss: 2.7766819866709973

Epoch: 6| Step: 2
Training loss: 3.086693316262908
Validation loss: 2.7767545532791575

Epoch: 6| Step: 3
Training loss: 3.082197254965695
Validation loss: 2.776243617177659

Epoch: 6| Step: 4
Training loss: 3.049075852763949
Validation loss: 2.776881766928046

Epoch: 6| Step: 5
Training loss: 3.4128379458814964
Validation loss: 2.7784457880838733

Epoch: 6| Step: 6
Training loss: 2.5882877606541173
Validation loss: 2.774247447573187

Epoch: 6| Step: 7
Training loss: 2.9598283527197107
Validation loss: 2.774781704887626

Epoch: 6| Step: 8
Training loss: 2.702445766247093
Validation loss: 2.775624282828361

Epoch: 6| Step: 9
Training loss: 3.674367894417072
Validation loss: 2.774221222839151

Epoch: 6| Step: 10
Training loss: 2.6229763404980417
Validation loss: 2.7714073505012333

Epoch: 6| Step: 11
Training loss: 3.508608993126819
Validation loss: 2.7681774395073973

Epoch: 6| Step: 12
Training loss: 2.848928745448553
Validation loss: 2.768021000056639

Epoch: 6| Step: 13
Training loss: 2.6167484655371194
Validation loss: 2.770201882569194

Epoch: 245| Step: 0
Training loss: 2.8570143330140736
Validation loss: 2.768888964640532

Epoch: 6| Step: 1
Training loss: 2.7238731784286663
Validation loss: 2.7688572903304056

Epoch: 6| Step: 2
Training loss: 3.3772112348945034
Validation loss: 2.76916984186599

Epoch: 6| Step: 3
Training loss: 3.4082630053837084
Validation loss: 2.7707858914657684

Epoch: 6| Step: 4
Training loss: 3.0959418653012842
Validation loss: 2.7666513874251275

Epoch: 6| Step: 5
Training loss: 2.389720072294197
Validation loss: 2.7728327561963506

Epoch: 6| Step: 6
Training loss: 3.5095498725074683
Validation loss: 2.7726372943581414

Epoch: 6| Step: 7
Training loss: 3.133738392830082
Validation loss: 2.7735579778052437

Epoch: 6| Step: 8
Training loss: 2.394744116825595
Validation loss: 2.771940108507316

Epoch: 6| Step: 9
Training loss: 2.9347007887487306
Validation loss: 2.774488000512977

Epoch: 6| Step: 10
Training loss: 2.7911751917079055
Validation loss: 2.7833885975328023

Epoch: 6| Step: 11
Training loss: 2.8686732462669315
Validation loss: 2.7775982393332153

Epoch: 6| Step: 12
Training loss: 3.9915687395054675
Validation loss: 2.7720057224415324

Epoch: 6| Step: 13
Training loss: 3.435305501798353
Validation loss: 2.7654072406001027

Epoch: 246| Step: 0
Training loss: 3.5352835785080594
Validation loss: 2.7642034602853474

Epoch: 6| Step: 1
Training loss: 3.4578984611434334
Validation loss: 2.7673345924365664

Epoch: 6| Step: 2
Training loss: 2.8702783373864325
Validation loss: 2.7665332794899005

Epoch: 6| Step: 3
Training loss: 2.86233350777669
Validation loss: 2.764493493535151

Epoch: 6| Step: 4
Training loss: 3.4499288413407805
Validation loss: 2.7677570604490063

Epoch: 6| Step: 5
Training loss: 3.730966712510751
Validation loss: 2.7645174606760277

Epoch: 6| Step: 6
Training loss: 2.828783496046469
Validation loss: 2.761788182407563

Epoch: 6| Step: 7
Training loss: 2.0993606774948
Validation loss: 2.761054056002231

Epoch: 6| Step: 8
Training loss: 2.761119556307483
Validation loss: 2.76819413354084

Epoch: 6| Step: 9
Training loss: 3.1472756487793396
Validation loss: 2.7652894160558197

Epoch: 6| Step: 10
Training loss: 3.003488419819241
Validation loss: 2.7734982553356025

Epoch: 6| Step: 11
Training loss: 2.8840841987794694
Validation loss: 2.796290587909776

Epoch: 6| Step: 12
Training loss: 2.760537505953749
Validation loss: 2.7845002360384905

Epoch: 6| Step: 13
Training loss: 3.62279811940843
Validation loss: 2.7850321500573574

Epoch: 247| Step: 0
Training loss: 3.2193336328045654
Validation loss: 2.77326210919784

Epoch: 6| Step: 1
Training loss: 2.793520658155494
Validation loss: 2.76566528101877

Epoch: 6| Step: 2
Training loss: 3.080600730473799
Validation loss: 2.764612285797696

Epoch: 6| Step: 3
Training loss: 3.774388921932766
Validation loss: 2.7633741853223843

Epoch: 6| Step: 4
Training loss: 2.173065079045852
Validation loss: 2.7649919997369916

Epoch: 6| Step: 5
Training loss: 2.538252575149665
Validation loss: 2.7611820923521795

Epoch: 6| Step: 6
Training loss: 2.349099627951577
Validation loss: 2.7638528776537634

Epoch: 6| Step: 7
Training loss: 3.5074625839010487
Validation loss: 2.7619617362980313

Epoch: 6| Step: 8
Training loss: 2.973974188892077
Validation loss: 2.763933679974183

Epoch: 6| Step: 9
Training loss: 3.7969922962045266
Validation loss: 2.7630061143531766

Epoch: 6| Step: 10
Training loss: 3.327303646264248
Validation loss: 2.7624194231681636

Epoch: 6| Step: 11
Training loss: 2.725794030791233
Validation loss: 2.7660016525904605

Epoch: 6| Step: 12
Training loss: 3.082194624947407
Validation loss: 2.7595364065439885

Epoch: 6| Step: 13
Training loss: 3.360720626665234
Validation loss: 2.764795203771195

Epoch: 248| Step: 0
Training loss: 2.757816822599746
Validation loss: 2.762932228162346

Epoch: 6| Step: 1
Training loss: 2.564658023873543
Validation loss: 2.7625333453717795

Epoch: 6| Step: 2
Training loss: 3.878237079780562
Validation loss: 2.764324768998444

Epoch: 6| Step: 3
Training loss: 3.097330506792994
Validation loss: 2.7623495379540906

Epoch: 6| Step: 4
Training loss: 3.098241762720216
Validation loss: 2.763034473781514

Epoch: 6| Step: 5
Training loss: 3.442005049086153
Validation loss: 2.773089978082174

Epoch: 6| Step: 6
Training loss: 3.3038262581945705
Validation loss: 2.7672586039706886

Epoch: 6| Step: 7
Training loss: 2.6193953126426037
Validation loss: 2.7628980981265228

Epoch: 6| Step: 8
Training loss: 3.381300520034726
Validation loss: 2.7629825701930852

Epoch: 6| Step: 9
Training loss: 3.1227482121497365
Validation loss: 2.7674994207140506

Epoch: 6| Step: 10
Training loss: 3.464897559607178
Validation loss: 2.7662923295227557

Epoch: 6| Step: 11
Training loss: 2.5681449307457203
Validation loss: 2.7639828146885574

Epoch: 6| Step: 12
Training loss: 2.7609934845943873
Validation loss: 2.7720431140870936

Epoch: 6| Step: 13
Training loss: 2.3034227942148813
Validation loss: 2.7653916950377644

Epoch: 249| Step: 0
Training loss: 3.6009465350774548
Validation loss: 2.7634624881200485

Epoch: 6| Step: 1
Training loss: 2.597349679395453
Validation loss: 2.7608671786977523

Epoch: 6| Step: 2
Training loss: 3.407619655912372
Validation loss: 2.755804861758704

Epoch: 6| Step: 3
Training loss: 2.388606596933566
Validation loss: 2.756393596074829

Epoch: 6| Step: 4
Training loss: 3.0952949134446444
Validation loss: 2.759197972040295

Epoch: 6| Step: 5
Training loss: 2.7059869334433353
Validation loss: 2.759213173417406

Epoch: 6| Step: 6
Training loss: 2.575709465583926
Validation loss: 2.761341165989854

Epoch: 6| Step: 7
Training loss: 3.231373891908685
Validation loss: 2.7591131871251706

Epoch: 6| Step: 8
Training loss: 2.377695361112337
Validation loss: 2.761442406607969

Epoch: 6| Step: 9
Training loss: 3.3774741252413474
Validation loss: 2.760482762838461

Epoch: 6| Step: 10
Training loss: 3.503821330492699
Validation loss: 2.762682638542088

Epoch: 6| Step: 11
Training loss: 3.2229095544389312
Validation loss: 2.760534133006105

Epoch: 6| Step: 12
Training loss: 3.3679936057005144
Validation loss: 2.760647669618975

Epoch: 6| Step: 13
Training loss: 3.266565798804598
Validation loss: 2.7606393908042657

Epoch: 250| Step: 0
Training loss: 2.948999500335413
Validation loss: 2.757192673170926

Epoch: 6| Step: 1
Training loss: 3.372591218725668
Validation loss: 2.761037340153452

Epoch: 6| Step: 2
Training loss: 2.958164335626448
Validation loss: 2.7612174152975197

Epoch: 6| Step: 3
Training loss: 3.212003136591728
Validation loss: 2.7649906442019563

Epoch: 6| Step: 4
Training loss: 3.32309712046547
Validation loss: 2.7613817100304323

Epoch: 6| Step: 5
Training loss: 2.787469061436043
Validation loss: 2.759227405643591

Epoch: 6| Step: 6
Training loss: 2.5207261201952638
Validation loss: 2.7627144820060523

Epoch: 6| Step: 7
Training loss: 2.885611810982489
Validation loss: 2.7616366036695212

Epoch: 6| Step: 8
Training loss: 2.9969056383462203
Validation loss: 2.7562327189291262

Epoch: 6| Step: 9
Training loss: 3.6479078802892175
Validation loss: 2.7609192966209037

Epoch: 6| Step: 10
Training loss: 2.740074278110093
Validation loss: 2.7577238001516498

Epoch: 6| Step: 11
Training loss: 3.93192878042395
Validation loss: 2.7583090340892564

Epoch: 6| Step: 12
Training loss: 2.667885283341621
Validation loss: 2.758320295905747

Epoch: 6| Step: 13
Training loss: 2.28329522409681
Validation loss: 2.761455990486245

Epoch: 251| Step: 0
Training loss: 3.151138245334682
Validation loss: 2.7608306431944714

Epoch: 6| Step: 1
Training loss: 2.6685859111574937
Validation loss: 2.7596087616442118

Epoch: 6| Step: 2
Training loss: 3.3994526366401643
Validation loss: 2.762032907560613

Epoch: 6| Step: 3
Training loss: 2.9513361927389434
Validation loss: 2.7616798391291715

Epoch: 6| Step: 4
Training loss: 3.0863905175790625
Validation loss: 2.760909902504797

Epoch: 6| Step: 5
Training loss: 2.5796560654091083
Validation loss: 2.7620744587082355

Epoch: 6| Step: 6
Training loss: 3.433417097631541
Validation loss: 2.762657795263048

Epoch: 6| Step: 7
Training loss: 3.16360945107185
Validation loss: 2.7607485020108093

Epoch: 6| Step: 8
Training loss: 2.761825019917683
Validation loss: 2.757512186366527

Epoch: 6| Step: 9
Training loss: 2.816169210291898
Validation loss: 2.757001777477704

Epoch: 6| Step: 10
Training loss: 3.418973624606068
Validation loss: 2.7576467710641226

Epoch: 6| Step: 11
Training loss: 3.40643702002352
Validation loss: 2.7565772319319564

Epoch: 6| Step: 12
Training loss: 2.6711529207774642
Validation loss: 2.7603460447193564

Epoch: 6| Step: 13
Training loss: 3.440448536795512
Validation loss: 2.758529338918245

Epoch: 252| Step: 0
Training loss: 3.2622761324372926
Validation loss: 2.7661011331598817

Epoch: 6| Step: 1
Training loss: 2.643530697215211
Validation loss: 2.7712073578302374

Epoch: 6| Step: 2
Training loss: 2.9436574479960433
Validation loss: 2.7776983594992264

Epoch: 6| Step: 3
Training loss: 2.963767598975551
Validation loss: 2.7777408641153603

Epoch: 6| Step: 4
Training loss: 2.370020615693255
Validation loss: 2.779369709083066

Epoch: 6| Step: 5
Training loss: 3.2276896062186333
Validation loss: 2.7867940674958

Epoch: 6| Step: 6
Training loss: 3.0775793531089684
Validation loss: 2.7665265259706513

Epoch: 6| Step: 7
Training loss: 3.3676706485230747
Validation loss: 2.765727996993946

Epoch: 6| Step: 8
Training loss: 3.035359379514257
Validation loss: 2.7609036756469507

Epoch: 6| Step: 9
Training loss: 3.3337964372007454
Validation loss: 2.761755621389642

Epoch: 6| Step: 10
Training loss: 3.362514288776201
Validation loss: 2.763000770890265

Epoch: 6| Step: 11
Training loss: 2.7820447150667547
Validation loss: 2.7592227275436576

Epoch: 6| Step: 12
Training loss: 3.343470766761462
Validation loss: 2.7567072259391905

Epoch: 6| Step: 13
Training loss: 3.058601856829933
Validation loss: 2.7613544959846603

Epoch: 253| Step: 0
Training loss: 3.403804075867124
Validation loss: 2.7516325097761465

Epoch: 6| Step: 1
Training loss: 3.195812232898218
Validation loss: 2.753703457613654

Epoch: 6| Step: 2
Training loss: 2.9199844200554734
Validation loss: 2.754075849249325

Epoch: 6| Step: 3
Training loss: 3.204521507454091
Validation loss: 2.751855439628047

Epoch: 6| Step: 4
Training loss: 2.304105316596236
Validation loss: 2.7518635026523155

Epoch: 6| Step: 5
Training loss: 3.023263694636902
Validation loss: 2.7493853101117036

Epoch: 6| Step: 6
Training loss: 2.2905674696875704
Validation loss: 2.7484166573704467

Epoch: 6| Step: 7
Training loss: 3.2012338405381513
Validation loss: 2.750893001303735

Epoch: 6| Step: 8
Training loss: 3.3318517889281614
Validation loss: 2.7526561219021697

Epoch: 6| Step: 9
Training loss: 2.956863862191855
Validation loss: 2.7537651240542473

Epoch: 6| Step: 10
Training loss: 3.4643339622856937
Validation loss: 2.750807831803922

Epoch: 6| Step: 11
Training loss: 3.085372216322827
Validation loss: 2.751627838329283

Epoch: 6| Step: 12
Training loss: 3.142606044002769
Validation loss: 2.753274369385971

Epoch: 6| Step: 13
Training loss: 3.151750435471552
Validation loss: 2.7512205264287535

Epoch: 254| Step: 0
Training loss: 3.190854271134026
Validation loss: 2.750325378529276

Epoch: 6| Step: 1
Training loss: 2.8638337605355866
Validation loss: 2.7567556246014653

Epoch: 6| Step: 2
Training loss: 2.933728008017174
Validation loss: 2.7553353548540205

Epoch: 6| Step: 3
Training loss: 3.6223551868797395
Validation loss: 2.751710689650631

Epoch: 6| Step: 4
Training loss: 3.1916004808168568
Validation loss: 2.7539628497163173

Epoch: 6| Step: 5
Training loss: 3.6742945714156043
Validation loss: 2.754716657897988

Epoch: 6| Step: 6
Training loss: 3.4397273390299583
Validation loss: 2.7527810239185153

Epoch: 6| Step: 7
Training loss: 1.9685542902476283
Validation loss: 2.7534997620721513

Epoch: 6| Step: 8
Training loss: 3.087476901689993
Validation loss: 2.753428506179371

Epoch: 6| Step: 9
Training loss: 2.794063241623811
Validation loss: 2.7494209571146104

Epoch: 6| Step: 10
Training loss: 2.6937494583306356
Validation loss: 2.749821174191856

Epoch: 6| Step: 11
Training loss: 2.9422813623400024
Validation loss: 2.746424230551279

Epoch: 6| Step: 12
Training loss: 3.33961958997388
Validation loss: 2.747972809560276

Epoch: 6| Step: 13
Training loss: 2.536268463443578
Validation loss: 2.749435719295525

Epoch: 255| Step: 0
Training loss: 2.4404726730658055
Validation loss: 2.750082861210377

Epoch: 6| Step: 1
Training loss: 2.7930419912271818
Validation loss: 2.7518464002557077

Epoch: 6| Step: 2
Training loss: 3.502806219727815
Validation loss: 2.7543205820527294

Epoch: 6| Step: 3
Training loss: 2.2392824074300743
Validation loss: 2.7630822949215745

Epoch: 6| Step: 4
Training loss: 3.4424890553197254
Validation loss: 2.7627359327093624

Epoch: 6| Step: 5
Training loss: 3.588859879882016
Validation loss: 2.766212021486765

Epoch: 6| Step: 6
Training loss: 2.7012879408078754
Validation loss: 2.763006157034033

Epoch: 6| Step: 7
Training loss: 2.9122347993404065
Validation loss: 2.766417887306022

Epoch: 6| Step: 8
Training loss: 3.525429579078416
Validation loss: 2.7540842902142546

Epoch: 6| Step: 9
Training loss: 3.2412163808236154
Validation loss: 2.7497129113328986

Epoch: 6| Step: 10
Training loss: 3.1494593322812343
Validation loss: 2.7481413738262184

Epoch: 6| Step: 11
Training loss: 2.777903912117641
Validation loss: 2.7514864408549125

Epoch: 6| Step: 12
Training loss: 3.0977670810879046
Validation loss: 2.7527995137111283

Epoch: 6| Step: 13
Training loss: 3.2338016020171207
Validation loss: 2.7499152866862833

Epoch: 256| Step: 0
Training loss: 2.7630488579731325
Validation loss: 2.750016821160055

Epoch: 6| Step: 1
Training loss: 3.6701839367666174
Validation loss: 2.7509376888641768

Epoch: 6| Step: 2
Training loss: 3.744811474036339
Validation loss: 2.749089186214781

Epoch: 6| Step: 3
Training loss: 2.760242806963466
Validation loss: 2.7516392719003777

Epoch: 6| Step: 4
Training loss: 3.3685157085752855
Validation loss: 2.7520361668102415

Epoch: 6| Step: 5
Training loss: 3.2019627393071164
Validation loss: 2.7500927164626017

Epoch: 6| Step: 6
Training loss: 3.0221922525465748
Validation loss: 2.7498600533563016

Epoch: 6| Step: 7
Training loss: 2.5504859648248996
Validation loss: 2.7533814884958345

Epoch: 6| Step: 8
Training loss: 2.699258585965767
Validation loss: 2.7566650210243946

Epoch: 6| Step: 9
Training loss: 3.153773478731687
Validation loss: 2.7635055020566437

Epoch: 6| Step: 10
Training loss: 3.381421796626268
Validation loss: 2.761228265093498

Epoch: 6| Step: 11
Training loss: 2.9539966406987124
Validation loss: 2.769209788036955

Epoch: 6| Step: 12
Training loss: 2.540320827016699
Validation loss: 2.7674009983013677

Epoch: 6| Step: 13
Training loss: 2.6086938391554795
Validation loss: 2.7620847825868724

Epoch: 257| Step: 0
Training loss: 3.1933299585323245
Validation loss: 2.755151910252781

Epoch: 6| Step: 1
Training loss: 3.450534867552041
Validation loss: 2.755702867006695

Epoch: 6| Step: 2
Training loss: 2.9221106449513323
Validation loss: 2.747145115238073

Epoch: 6| Step: 3
Training loss: 3.303520122704089
Validation loss: 2.7449617088990355

Epoch: 6| Step: 4
Training loss: 2.7309653685981488
Validation loss: 2.7438115231723037

Epoch: 6| Step: 5
Training loss: 2.6903570203435123
Validation loss: 2.740745839289867

Epoch: 6| Step: 6
Training loss: 3.196634853736435
Validation loss: 2.746844479041784

Epoch: 6| Step: 7
Training loss: 2.962052671243656
Validation loss: 2.742092332268655

Epoch: 6| Step: 8
Training loss: 2.9274802883406488
Validation loss: 2.745072550875893

Epoch: 6| Step: 9
Training loss: 2.6974844764354717
Validation loss: 2.7456688404054503

Epoch: 6| Step: 10
Training loss: 3.33212469759239
Validation loss: 2.746228703845359

Epoch: 6| Step: 11
Training loss: 3.7313308119209587
Validation loss: 2.747309901593595

Epoch: 6| Step: 12
Training loss: 2.430804324059268
Validation loss: 2.7473124892056187

Epoch: 6| Step: 13
Training loss: 3.1187837954354736
Validation loss: 2.744905219646303

Epoch: 258| Step: 0
Training loss: 2.9964015359956337
Validation loss: 2.7457655470434936

Epoch: 6| Step: 1
Training loss: 3.264165086535637
Validation loss: 2.7524329867919453

Epoch: 6| Step: 2
Training loss: 3.2398992713529204
Validation loss: 2.7448808991351923

Epoch: 6| Step: 3
Training loss: 2.319829100529619
Validation loss: 2.743490714323258

Epoch: 6| Step: 4
Training loss: 3.174072857150957
Validation loss: 2.744006460687348

Epoch: 6| Step: 5
Training loss: 3.4504251411652387
Validation loss: 2.746080049053401

Epoch: 6| Step: 6
Training loss: 3.243802837904346
Validation loss: 2.744788268142978

Epoch: 6| Step: 7
Training loss: 2.6857534544126356
Validation loss: 2.745155602843488

Epoch: 6| Step: 8
Training loss: 2.8470664335806566
Validation loss: 2.7505438743180646

Epoch: 6| Step: 9
Training loss: 3.5323846395112577
Validation loss: 2.743820806714576

Epoch: 6| Step: 10
Training loss: 3.251151247794411
Validation loss: 2.751577229858781

Epoch: 6| Step: 11
Training loss: 3.004989924612308
Validation loss: 2.750152807381063

Epoch: 6| Step: 12
Training loss: 2.54081839075279
Validation loss: 2.757363210145446

Epoch: 6| Step: 13
Training loss: 2.9677766509319556
Validation loss: 2.745336417163574

Epoch: 259| Step: 0
Training loss: 2.4837882830621663
Validation loss: 2.7492828366240296

Epoch: 6| Step: 1
Training loss: 3.2930932796367416
Validation loss: 2.744430211528643

Epoch: 6| Step: 2
Training loss: 3.3700993597398643
Validation loss: 2.7496951084283827

Epoch: 6| Step: 3
Training loss: 3.5015696684233295
Validation loss: 2.7516078611429484

Epoch: 6| Step: 4
Training loss: 2.8878787630369804
Validation loss: 2.746196630012908

Epoch: 6| Step: 5
Training loss: 3.0186565755915833
Validation loss: 2.7526847975087567

Epoch: 6| Step: 6
Training loss: 2.482295383499144
Validation loss: 2.744058063625409

Epoch: 6| Step: 7
Training loss: 3.295159350002172
Validation loss: 2.750337801832165

Epoch: 6| Step: 8
Training loss: 3.708717983456082
Validation loss: 2.7431224333183835

Epoch: 6| Step: 9
Training loss: 3.0973936260637385
Validation loss: 2.7401857977345636

Epoch: 6| Step: 10
Training loss: 3.044443578634889
Validation loss: 2.741419349399971

Epoch: 6| Step: 11
Training loss: 2.6689531735842884
Validation loss: 2.7445719781370443

Epoch: 6| Step: 12
Training loss: 2.780328319290604
Validation loss: 2.7444925776699067

Epoch: 6| Step: 13
Training loss: 2.7282065432882048
Validation loss: 2.7435153209478615

Epoch: 260| Step: 0
Training loss: 2.729986363750678
Validation loss: 2.7417430888603316

Epoch: 6| Step: 1
Training loss: 3.5383725872788254
Validation loss: 2.741158789028092

Epoch: 6| Step: 2
Training loss: 3.11426271215121
Validation loss: 2.742463888777

Epoch: 6| Step: 3
Training loss: 2.592362549834169
Validation loss: 2.74086896909793

Epoch: 6| Step: 4
Training loss: 3.1169194844836636
Validation loss: 2.7412346621077357

Epoch: 6| Step: 5
Training loss: 2.838708453863333
Validation loss: 2.743109450237659

Epoch: 6| Step: 6
Training loss: 3.350481192347732
Validation loss: 2.74617055469499

Epoch: 6| Step: 7
Training loss: 2.821015500188013
Validation loss: 2.7424055850134557

Epoch: 6| Step: 8
Training loss: 2.8011195192669414
Validation loss: 2.7438900650971063

Epoch: 6| Step: 9
Training loss: 3.953545951293504
Validation loss: 2.74875218411146

Epoch: 6| Step: 10
Training loss: 3.1455200915139874
Validation loss: 2.746513163245769

Epoch: 6| Step: 11
Training loss: 2.5520166089943475
Validation loss: 2.7413325248795037

Epoch: 6| Step: 12
Training loss: 3.0915084579033723
Validation loss: 2.7387303813795665

Epoch: 6| Step: 13
Training loss: 2.6859227364818405
Validation loss: 2.7386343179528794

Epoch: 261| Step: 0
Training loss: 2.877589345119965
Validation loss: 2.738391956077847

Epoch: 6| Step: 1
Training loss: 2.061831857369253
Validation loss: 2.741759949457514

Epoch: 6| Step: 2
Training loss: 3.5878270973723985
Validation loss: 2.738519155346552

Epoch: 6| Step: 3
Training loss: 3.223076144520018
Validation loss: 2.74131598242228

Epoch: 6| Step: 4
Training loss: 3.1153161112905705
Validation loss: 2.7415328650114787

Epoch: 6| Step: 5
Training loss: 3.4107083881929205
Validation loss: 2.7414495340329403

Epoch: 6| Step: 6
Training loss: 2.7497846345666823
Validation loss: 2.7451662854540255

Epoch: 6| Step: 7
Training loss: 3.23061502441472
Validation loss: 2.7450301810864626

Epoch: 6| Step: 8
Training loss: 3.0195884156336774
Validation loss: 2.74598946387407

Epoch: 6| Step: 9
Training loss: 2.634847697682758
Validation loss: 2.74083488888761

Epoch: 6| Step: 10
Training loss: 3.5912535911512893
Validation loss: 2.746533455644972

Epoch: 6| Step: 11
Training loss: 3.2922169832956176
Validation loss: 2.7455323286248716

Epoch: 6| Step: 12
Training loss: 2.1915370201763014
Validation loss: 2.7463646311996874

Epoch: 6| Step: 13
Training loss: 3.527032274453845
Validation loss: 2.742745607399951

Epoch: 262| Step: 0
Training loss: 3.548827318811824
Validation loss: 2.740825944118445

Epoch: 6| Step: 1
Training loss: 2.7406027363445933
Validation loss: 2.738807377121665

Epoch: 6| Step: 2
Training loss: 3.166135960997719
Validation loss: 2.7364401429920706

Epoch: 6| Step: 3
Training loss: 2.4380295007186668
Validation loss: 2.7389207632423576

Epoch: 6| Step: 4
Training loss: 3.275461813710948
Validation loss: 2.7402759395330882

Epoch: 6| Step: 5
Training loss: 3.642537805574441
Validation loss: 2.7382971236072087

Epoch: 6| Step: 6
Training loss: 2.742638184118418
Validation loss: 2.7351438148785427

Epoch: 6| Step: 7
Training loss: 2.92172942589398
Validation loss: 2.739517321228587

Epoch: 6| Step: 8
Training loss: 2.7469408185796085
Validation loss: 2.7327890661098846

Epoch: 6| Step: 9
Training loss: 3.158710389456889
Validation loss: 2.734640049430552

Epoch: 6| Step: 10
Training loss: 2.7255442994401045
Validation loss: 2.7350337731223453

Epoch: 6| Step: 11
Training loss: 3.5450740056457737
Validation loss: 2.735884980993391

Epoch: 6| Step: 12
Training loss: 2.3652652199810595
Validation loss: 2.735803946227773

Epoch: 6| Step: 13
Training loss: 3.724990993207245
Validation loss: 2.740409186341094

Epoch: 263| Step: 0
Training loss: 2.754543192908603
Validation loss: 2.740103848837193

Epoch: 6| Step: 1
Training loss: 3.4440474144643556
Validation loss: 2.7445297262550676

Epoch: 6| Step: 2
Training loss: 3.4870195830407615
Validation loss: 2.745778916240631

Epoch: 6| Step: 3
Training loss: 2.553222422801314
Validation loss: 2.7441988657428578

Epoch: 6| Step: 4
Training loss: 3.369606795194898
Validation loss: 2.742411845459333

Epoch: 6| Step: 5
Training loss: 3.226861898280013
Validation loss: 2.741275951488472

Epoch: 6| Step: 6
Training loss: 2.9248309355562614
Validation loss: 2.7444253036319557

Epoch: 6| Step: 7
Training loss: 2.7214459612147386
Validation loss: 2.7409844660202687

Epoch: 6| Step: 8
Training loss: 2.965432974223052
Validation loss: 2.737564624857607

Epoch: 6| Step: 9
Training loss: 3.0792548724915876
Validation loss: 2.733790417601751

Epoch: 6| Step: 10
Training loss: 2.9071302824059737
Validation loss: 2.7354009988123633

Epoch: 6| Step: 11
Training loss: 2.857906277026775
Validation loss: 2.7382764003629325

Epoch: 6| Step: 12
Training loss: 2.9263859978204767
Validation loss: 2.736653205859261

Epoch: 6| Step: 13
Training loss: 3.559515656730597
Validation loss: 2.732628530206182

Epoch: 264| Step: 0
Training loss: 2.7163842969154883
Validation loss: 2.736028668009842

Epoch: 6| Step: 1
Training loss: 2.898013348661209
Validation loss: 2.735149836064422

Epoch: 6| Step: 2
Training loss: 3.400059385342047
Validation loss: 2.7341610160576946

Epoch: 6| Step: 3
Training loss: 3.085237447791163
Validation loss: 2.7326716786222773

Epoch: 6| Step: 4
Training loss: 3.188713740221539
Validation loss: 2.732141283799523

Epoch: 6| Step: 5
Training loss: 3.1033539870981977
Validation loss: 2.733606963926431

Epoch: 6| Step: 6
Training loss: 2.625708075800223
Validation loss: 2.733571691222163

Epoch: 6| Step: 7
Training loss: 3.3070438001769893
Validation loss: 2.7368988474612554

Epoch: 6| Step: 8
Training loss: 2.9799369047513116
Validation loss: 2.750642891517599

Epoch: 6| Step: 9
Training loss: 2.805684117140299
Validation loss: 2.744578809965257

Epoch: 6| Step: 10
Training loss: 2.9703535066088738
Validation loss: 2.746352450362351

Epoch: 6| Step: 11
Training loss: 2.884664793324977
Validation loss: 2.755549470538287

Epoch: 6| Step: 12
Training loss: 3.5317539091857504
Validation loss: 2.747700395349923

Epoch: 6| Step: 13
Training loss: 3.0836268792161947
Validation loss: 2.7362964260531957

Epoch: 265| Step: 0
Training loss: 3.1611634336349
Validation loss: 2.7317988829468574

Epoch: 6| Step: 1
Training loss: 2.6116990572785745
Validation loss: 2.732322861776402

Epoch: 6| Step: 2
Training loss: 3.5027962822206447
Validation loss: 2.730523742772651

Epoch: 6| Step: 3
Training loss: 2.967597496789971
Validation loss: 2.7317216206872064

Epoch: 6| Step: 4
Training loss: 3.2705986440898944
Validation loss: 2.7281681928058146

Epoch: 6| Step: 5
Training loss: 2.6421748922939425
Validation loss: 2.728028087555333

Epoch: 6| Step: 6
Training loss: 3.2599231643047064
Validation loss: 2.730441629701512

Epoch: 6| Step: 7
Training loss: 3.4770458099796824
Validation loss: 2.728914582847735

Epoch: 6| Step: 8
Training loss: 3.3969327554995465
Validation loss: 2.7307162251848336

Epoch: 6| Step: 9
Training loss: 3.2838139280697027
Validation loss: 2.730347272248664

Epoch: 6| Step: 10
Training loss: 1.8829484312762208
Validation loss: 2.7295121311901225

Epoch: 6| Step: 11
Training loss: 2.985055097010764
Validation loss: 2.729990320976967

Epoch: 6| Step: 12
Training loss: 3.151950135645038
Validation loss: 2.733066488812042

Epoch: 6| Step: 13
Training loss: 2.30368216619115
Validation loss: 2.7310792126507657

Epoch: 266| Step: 0
Training loss: 2.6940424926283923
Validation loss: 2.735519578402072

Epoch: 6| Step: 1
Training loss: 3.3302393541431505
Validation loss: 2.7320226598617343

Epoch: 6| Step: 2
Training loss: 3.450654816335448
Validation loss: 2.736684230883824

Epoch: 6| Step: 3
Training loss: 3.299947021521502
Validation loss: 2.741546076243812

Epoch: 6| Step: 4
Training loss: 2.798949596380509
Validation loss: 2.7358812815469076

Epoch: 6| Step: 5
Training loss: 2.8605819406200315
Validation loss: 2.734068126891364

Epoch: 6| Step: 6
Training loss: 2.685060769215681
Validation loss: 2.736989031947845

Epoch: 6| Step: 7
Training loss: 2.846771982047989
Validation loss: 2.7405027043658903

Epoch: 6| Step: 8
Training loss: 3.0155089360963196
Validation loss: 2.742292227993463

Epoch: 6| Step: 9
Training loss: 2.9405097963182594
Validation loss: 2.74168097342097

Epoch: 6| Step: 10
Training loss: 2.7267436757051526
Validation loss: 2.7385822870459138

Epoch: 6| Step: 11
Training loss: 3.748438955277307
Validation loss: 2.7403708316900888

Epoch: 6| Step: 12
Training loss: 2.550925187961261
Validation loss: 2.7319711505201623

Epoch: 6| Step: 13
Training loss: 3.7176975075152705
Validation loss: 2.7369718375424523

Epoch: 267| Step: 0
Training loss: 2.4962093225029203
Validation loss: 2.735457024553311

Epoch: 6| Step: 1
Training loss: 3.485524351497607
Validation loss: 2.7347047851265516

Epoch: 6| Step: 2
Training loss: 3.3736210584504756
Validation loss: 2.734788498325821

Epoch: 6| Step: 3
Training loss: 2.74393670352745
Validation loss: 2.7280056558385044

Epoch: 6| Step: 4
Training loss: 2.9728974934961916
Validation loss: 2.730364336546597

Epoch: 6| Step: 5
Training loss: 2.530698928186542
Validation loss: 2.7291016115727746

Epoch: 6| Step: 6
Training loss: 3.295644521469154
Validation loss: 2.7300575347256286

Epoch: 6| Step: 7
Training loss: 2.9188951607330105
Validation loss: 2.7279707025896145

Epoch: 6| Step: 8
Training loss: 2.7188697876246493
Validation loss: 2.729735546162446

Epoch: 6| Step: 9
Training loss: 3.17384390020118
Validation loss: 2.7319107718187428

Epoch: 6| Step: 10
Training loss: 2.7774491645562724
Validation loss: 2.72761713216872

Epoch: 6| Step: 11
Training loss: 3.533558318934406
Validation loss: 2.724657257079226

Epoch: 6| Step: 12
Training loss: 2.7957432337729107
Validation loss: 2.725888636141882

Epoch: 6| Step: 13
Training loss: 3.9856361936232867
Validation loss: 2.723080887716092

Epoch: 268| Step: 0
Training loss: 2.851276205662398
Validation loss: 2.727005641617759

Epoch: 6| Step: 1
Training loss: 3.5006419001918645
Validation loss: 2.740351026900262

Epoch: 6| Step: 2
Training loss: 2.593138289418695
Validation loss: 2.7453210390292346

Epoch: 6| Step: 3
Training loss: 3.230998612739173
Validation loss: 2.7635264266609956

Epoch: 6| Step: 4
Training loss: 3.4589890620556893
Validation loss: 2.777552583309923

Epoch: 6| Step: 5
Training loss: 3.675963896896848
Validation loss: 2.7491929985403463

Epoch: 6| Step: 6
Training loss: 2.43188534160171
Validation loss: 2.7339755083765818

Epoch: 6| Step: 7
Training loss: 2.49434413094609
Validation loss: 2.7358978540536394

Epoch: 6| Step: 8
Training loss: 3.268197100761934
Validation loss: 2.73669664866399

Epoch: 6| Step: 9
Training loss: 3.1707845984050103
Validation loss: 2.725905982278775

Epoch: 6| Step: 10
Training loss: 2.703882717591183
Validation loss: 2.73209700756537

Epoch: 6| Step: 11
Training loss: 3.4854967167780977
Validation loss: 2.7321894307859185

Epoch: 6| Step: 12
Training loss: 2.4841686618937255
Validation loss: 2.737517342199022

Epoch: 6| Step: 13
Training loss: 2.924996243987973
Validation loss: 2.7366641670942973

Epoch: 269| Step: 0
Training loss: 3.063531974215947
Validation loss: 2.7365162330896733

Epoch: 6| Step: 1
Training loss: 3.6128801772760197
Validation loss: 2.74064776567973

Epoch: 6| Step: 2
Training loss: 2.483092738877411
Validation loss: 2.739815156179481

Epoch: 6| Step: 3
Training loss: 2.4290940519791726
Validation loss: 2.738978597379423

Epoch: 6| Step: 4
Training loss: 3.22451177642276
Validation loss: 2.7319191273703027

Epoch: 6| Step: 5
Training loss: 3.5290346201244076
Validation loss: 2.7297018688500936

Epoch: 6| Step: 6
Training loss: 2.942613088141053
Validation loss: 2.7286749043461462

Epoch: 6| Step: 7
Training loss: 2.950448735908675
Validation loss: 2.7308886844999662

Epoch: 6| Step: 8
Training loss: 2.71179097836905
Validation loss: 2.7265742699793085

Epoch: 6| Step: 9
Training loss: 3.0412092692340167
Validation loss: 2.728793284871121

Epoch: 6| Step: 10
Training loss: 2.9116221991995426
Validation loss: 2.7303871113122495

Epoch: 6| Step: 11
Training loss: 2.9043640252093357
Validation loss: 2.730267915383364

Epoch: 6| Step: 12
Training loss: 3.289296194006295
Validation loss: 2.7345058793067443

Epoch: 6| Step: 13
Training loss: 3.6620274730424773
Validation loss: 2.729205477796388

Epoch: 270| Step: 0
Training loss: 2.7710771859692693
Validation loss: 2.7380181981517624

Epoch: 6| Step: 1
Training loss: 3.4001008972455797
Validation loss: 2.740321071532864

Epoch: 6| Step: 2
Training loss: 2.93885496016181
Validation loss: 2.7514618347048443

Epoch: 6| Step: 3
Training loss: 2.951098034059258
Validation loss: 2.760612331025708

Epoch: 6| Step: 4
Training loss: 3.2476827723613306
Validation loss: 2.752849750485687

Epoch: 6| Step: 5
Training loss: 3.185176825532942
Validation loss: 2.7454462523389864

Epoch: 6| Step: 6
Training loss: 2.856731923388068
Validation loss: 2.7435380715770563

Epoch: 6| Step: 7
Training loss: 3.1106316408926125
Validation loss: 2.7350556841583393

Epoch: 6| Step: 8
Training loss: 2.7227495962858406
Validation loss: 2.734997808310779

Epoch: 6| Step: 9
Training loss: 2.838232031683426
Validation loss: 2.7307151047074667

Epoch: 6| Step: 10
Training loss: 2.7912457466691
Validation loss: 2.7233817561782097

Epoch: 6| Step: 11
Training loss: 3.2820985695904703
Validation loss: 2.723100148744475

Epoch: 6| Step: 12
Training loss: 3.446519013297474
Validation loss: 2.7241600380908046

Epoch: 6| Step: 13
Training loss: 2.924212984022835
Validation loss: 2.726901870228159

Epoch: 271| Step: 0
Training loss: 3.1219152866089583
Validation loss: 2.724195798730185

Epoch: 6| Step: 1
Training loss: 2.7436020726535486
Validation loss: 2.7264495665438875

Epoch: 6| Step: 2
Training loss: 3.094915921697701
Validation loss: 2.7250770682885777

Epoch: 6| Step: 3
Training loss: 2.6362061857125036
Validation loss: 2.722883809977584

Epoch: 6| Step: 4
Training loss: 2.985041199468512
Validation loss: 2.7204068964484733

Epoch: 6| Step: 5
Training loss: 3.346387731876087
Validation loss: 2.7206102050921133

Epoch: 6| Step: 6
Training loss: 2.5779418880284632
Validation loss: 2.7202490084172135

Epoch: 6| Step: 7
Training loss: 3.4051465688296596
Validation loss: 2.720632747726381

Epoch: 6| Step: 8
Training loss: 3.096388183270008
Validation loss: 2.7223625712670647

Epoch: 6| Step: 9
Training loss: 3.0712145385433844
Validation loss: 2.723345994263091

Epoch: 6| Step: 10
Training loss: 3.1374626370215237
Validation loss: 2.7234556083653034

Epoch: 6| Step: 11
Training loss: 3.117000564668156
Validation loss: 2.7223177913235674

Epoch: 6| Step: 12
Training loss: 2.751457521687795
Validation loss: 2.7213537100883642

Epoch: 6| Step: 13
Training loss: 3.602728599056481
Validation loss: 2.7217258945860303

Epoch: 272| Step: 0
Training loss: 3.198418709346137
Validation loss: 2.7195943036025603

Epoch: 6| Step: 1
Training loss: 3.183678224531103
Validation loss: 2.7215337385627625

Epoch: 6| Step: 2
Training loss: 2.7987674725197116
Validation loss: 2.7212714945996517

Epoch: 6| Step: 3
Training loss: 3.6219985638030567
Validation loss: 2.7263118432286344

Epoch: 6| Step: 4
Training loss: 2.974683754404946
Validation loss: 2.723683874315874

Epoch: 6| Step: 5
Training loss: 3.2223968586422442
Validation loss: 2.7206244008579534

Epoch: 6| Step: 6
Training loss: 2.974187429036225
Validation loss: 2.7178549306242767

Epoch: 6| Step: 7
Training loss: 3.374689158500958
Validation loss: 2.7289244046335757

Epoch: 6| Step: 8
Training loss: 3.0855369597653706
Validation loss: 2.730497386339223

Epoch: 6| Step: 9
Training loss: 2.9524714639885183
Validation loss: 2.7355521719638936

Epoch: 6| Step: 10
Training loss: 2.8515885861392434
Validation loss: 2.7400632472471074

Epoch: 6| Step: 11
Training loss: 2.8035452809385744
Validation loss: 2.7364772158658512

Epoch: 6| Step: 12
Training loss: 2.764231702629639
Validation loss: 2.72620124655607

Epoch: 6| Step: 13
Training loss: 2.1794906035061232
Validation loss: 2.735657042457443

Epoch: 273| Step: 0
Training loss: 3.15373673794952
Validation loss: 2.739591041634262

Epoch: 6| Step: 1
Training loss: 3.3545318467906684
Validation loss: 2.7441648773346667

Epoch: 6| Step: 2
Training loss: 3.032349849043581
Validation loss: 2.735021339356202

Epoch: 6| Step: 3
Training loss: 3.184677070763054
Validation loss: 2.7403437729041125

Epoch: 6| Step: 4
Training loss: 2.5729870085167734
Validation loss: 2.7350803460491546

Epoch: 6| Step: 5
Training loss: 2.9777751064604865
Validation loss: 2.72328783378659

Epoch: 6| Step: 6
Training loss: 3.4661484318739477
Validation loss: 2.727676220085378

Epoch: 6| Step: 7
Training loss: 3.1953445843342587
Validation loss: 2.726026712810492

Epoch: 6| Step: 8
Training loss: 2.806837867384174
Validation loss: 2.7195624661680133

Epoch: 6| Step: 9
Training loss: 2.914250017529871
Validation loss: 2.720990123834585

Epoch: 6| Step: 10
Training loss: 3.342517518687364
Validation loss: 2.7135436245197897

Epoch: 6| Step: 11
Training loss: 2.947164990101816
Validation loss: 2.7196827270253126

Epoch: 6| Step: 12
Training loss: 3.0236808422643526
Validation loss: 2.7193878824852447

Epoch: 6| Step: 13
Training loss: 1.9206725289757263
Validation loss: 2.719359353528283

Epoch: 274| Step: 0
Training loss: 3.00059662290415
Validation loss: 2.7167163768331912

Epoch: 6| Step: 1
Training loss: 2.9466115985517547
Validation loss: 2.717613485258551

Epoch: 6| Step: 2
Training loss: 3.1411141541294643
Validation loss: 2.7161441026221844

Epoch: 6| Step: 3
Training loss: 3.5811030226234175
Validation loss: 2.7151076912029652

Epoch: 6| Step: 4
Training loss: 3.102347555664925
Validation loss: 2.716313450990729

Epoch: 6| Step: 5
Training loss: 2.9649773970927664
Validation loss: 2.716368560457351

Epoch: 6| Step: 6
Training loss: 3.3689689437689374
Validation loss: 2.7174254498148853

Epoch: 6| Step: 7
Training loss: 3.4494761525380504
Validation loss: 2.7148269753134477

Epoch: 6| Step: 8
Training loss: 2.8272813413277462
Validation loss: 2.713960458239452

Epoch: 6| Step: 9
Training loss: 2.600388728939475
Validation loss: 2.7150217390552656

Epoch: 6| Step: 10
Training loss: 2.6634389197849178
Validation loss: 2.717064702538438

Epoch: 6| Step: 11
Training loss: 2.6704813574029713
Validation loss: 2.7169678046730996

Epoch: 6| Step: 12
Training loss: 2.8695801774113727
Validation loss: 2.719318488401185

Epoch: 6| Step: 13
Training loss: 3.1507317677004925
Validation loss: 2.7165166677433445

Epoch: 275| Step: 0
Training loss: 2.9572499041930174
Validation loss: 2.720955154897077

Epoch: 6| Step: 1
Training loss: 2.8830615920713103
Validation loss: 2.740241719098813

Epoch: 6| Step: 2
Training loss: 3.107088714904613
Validation loss: 2.744360641693889

Epoch: 6| Step: 3
Training loss: 3.1662999660255684
Validation loss: 2.761940389573925

Epoch: 6| Step: 4
Training loss: 2.878407822090365
Validation loss: 2.7279531374591164

Epoch: 6| Step: 5
Training loss: 2.926945657082926
Validation loss: 2.715820542827568

Epoch: 6| Step: 6
Training loss: 3.7649536800701453
Validation loss: 2.7151794976704866

Epoch: 6| Step: 7
Training loss: 3.1141177098365715
Validation loss: 2.716597820146689

Epoch: 6| Step: 8
Training loss: 3.2460001761012753
Validation loss: 2.71805774634144

Epoch: 6| Step: 9
Training loss: 3.08986180585946
Validation loss: 2.7198651376771243

Epoch: 6| Step: 10
Training loss: 2.6680620436882134
Validation loss: 2.719411763543127

Epoch: 6| Step: 11
Training loss: 2.8791483928654404
Validation loss: 2.7209194515392205

Epoch: 6| Step: 12
Training loss: 2.6046687646660005
Validation loss: 2.7192049703084074

Epoch: 6| Step: 13
Training loss: 3.4251279653882523
Validation loss: 2.7170078446355097

Epoch: 276| Step: 0
Training loss: 2.88593121472693
Validation loss: 2.7163364294487287

Epoch: 6| Step: 1
Training loss: 3.464644193009619
Validation loss: 2.7152383331809524

Epoch: 6| Step: 2
Training loss: 3.1321063304112844
Validation loss: 2.7149111791526037

Epoch: 6| Step: 3
Training loss: 2.459845115779005
Validation loss: 2.718163915217451

Epoch: 6| Step: 4
Training loss: 2.711816738581559
Validation loss: 2.715716415783568

Epoch: 6| Step: 5
Training loss: 3.564183958158958
Validation loss: 2.7170210911424046

Epoch: 6| Step: 6
Training loss: 2.7865276197334037
Validation loss: 2.7150368308513295

Epoch: 6| Step: 7
Training loss: 3.1147050270283234
Validation loss: 2.7170312276628983

Epoch: 6| Step: 8
Training loss: 3.235396956273008
Validation loss: 2.718595169141406

Epoch: 6| Step: 9
Training loss: 2.5054825747007117
Validation loss: 2.719413341653966

Epoch: 6| Step: 10
Training loss: 3.1580303949363433
Validation loss: 2.729912110697806

Epoch: 6| Step: 11
Training loss: 3.0741413499329657
Validation loss: 2.728239264622697

Epoch: 6| Step: 12
Training loss: 3.16305578723281
Validation loss: 2.731104608829166

Epoch: 6| Step: 13
Training loss: 3.1105310792484784
Validation loss: 2.723238371505057

Epoch: 277| Step: 0
Training loss: 2.9540113299752373
Validation loss: 2.7223708195784933

Epoch: 6| Step: 1
Training loss: 3.805512575771557
Validation loss: 2.7154658218296186

Epoch: 6| Step: 2
Training loss: 2.091094995421468
Validation loss: 2.71243035563665

Epoch: 6| Step: 3
Training loss: 2.869115363231199
Validation loss: 2.7141209799747705

Epoch: 6| Step: 4
Training loss: 2.9646851669339336
Validation loss: 2.715822409518513

Epoch: 6| Step: 5
Training loss: 2.903303395878651
Validation loss: 2.7175612198012375

Epoch: 6| Step: 6
Training loss: 3.298203331799831
Validation loss: 2.7136312833714182

Epoch: 6| Step: 7
Training loss: 3.2580927812866483
Validation loss: 2.71726577522352

Epoch: 6| Step: 8
Training loss: 3.0284692653225687
Validation loss: 2.7123827378564123

Epoch: 6| Step: 9
Training loss: 3.2747572830763385
Validation loss: 2.7131422155595337

Epoch: 6| Step: 10
Training loss: 3.2762570130972843
Validation loss: 2.715408064700127

Epoch: 6| Step: 11
Training loss: 3.163770874147495
Validation loss: 2.7177636348427354

Epoch: 6| Step: 12
Training loss: 2.7257302661871714
Validation loss: 2.7199508792759595

Epoch: 6| Step: 13
Training loss: 2.209631544269742
Validation loss: 2.7227454308073615

Epoch: 278| Step: 0
Training loss: 3.208560555738936
Validation loss: 2.7298020646537604

Epoch: 6| Step: 1
Training loss: 3.075212524017014
Validation loss: 2.7244754853189623

Epoch: 6| Step: 2
Training loss: 2.7303073819001047
Validation loss: 2.7346751377376113

Epoch: 6| Step: 3
Training loss: 2.939607878505247
Validation loss: 2.7329599035987346

Epoch: 6| Step: 4
Training loss: 3.1429862639915638
Validation loss: 2.7294743879575365

Epoch: 6| Step: 5
Training loss: 3.3769792475222293
Validation loss: 2.732176631269374

Epoch: 6| Step: 6
Training loss: 2.647391773925967
Validation loss: 2.7191556468328497

Epoch: 6| Step: 7
Training loss: 2.879687427141972
Validation loss: 2.7165827167330354

Epoch: 6| Step: 8
Training loss: 3.1636989808537535
Validation loss: 2.70898344095484

Epoch: 6| Step: 9
Training loss: 2.8771813451676898
Validation loss: 2.7118240471429242

Epoch: 6| Step: 10
Training loss: 2.2805887596489653
Validation loss: 2.7138070790831623

Epoch: 6| Step: 11
Training loss: 3.3608754200613213
Validation loss: 2.7155019131572184

Epoch: 6| Step: 12
Training loss: 3.1857860669511195
Validation loss: 2.7162417679384414

Epoch: 6| Step: 13
Training loss: 3.6275195869321863
Validation loss: 2.7153201252065626

Epoch: 279| Step: 0
Training loss: 2.772301153648975
Validation loss: 2.7153467035439216

Epoch: 6| Step: 1
Training loss: 2.6854103303355616
Validation loss: 2.7129691804561564

Epoch: 6| Step: 2
Training loss: 3.158847457656382
Validation loss: 2.713004693617332

Epoch: 6| Step: 3
Training loss: 2.8421492210691928
Validation loss: 2.7154252540345483

Epoch: 6| Step: 4
Training loss: 3.2707421032924624
Validation loss: 2.7123560179998343

Epoch: 6| Step: 5
Training loss: 2.9352656856033605
Validation loss: 2.711872539719134

Epoch: 6| Step: 6
Training loss: 3.125268695723808
Validation loss: 2.714348949504109

Epoch: 6| Step: 7
Training loss: 2.7792392277050304
Validation loss: 2.719522724940173

Epoch: 6| Step: 8
Training loss: 2.494901799350692
Validation loss: 2.7239737081535953

Epoch: 6| Step: 9
Training loss: 3.4205424183140662
Validation loss: 2.7217924317508846

Epoch: 6| Step: 10
Training loss: 2.815978040165241
Validation loss: 2.726037571007768

Epoch: 6| Step: 11
Training loss: 3.2036529850196467
Validation loss: 2.7219540814347125

Epoch: 6| Step: 12
Training loss: 3.730946008001727
Validation loss: 2.718840168876946

Epoch: 6| Step: 13
Training loss: 2.966886718675426
Validation loss: 2.7184290127724

Epoch: 280| Step: 0
Training loss: 3.547685841376257
Validation loss: 2.716863426251538

Epoch: 6| Step: 1
Training loss: 2.577954003414235
Validation loss: 2.7196228291522404

Epoch: 6| Step: 2
Training loss: 3.1699685065693637
Validation loss: 2.7280613626517516

Epoch: 6| Step: 3
Training loss: 2.599559299092735
Validation loss: 2.7302669144407816

Epoch: 6| Step: 4
Training loss: 3.05294523773909
Validation loss: 2.7427753213092996

Epoch: 6| Step: 5
Training loss: 3.5291887867372074
Validation loss: 2.7454795861869012

Epoch: 6| Step: 6
Training loss: 2.910626141804116
Validation loss: 2.72814565605479

Epoch: 6| Step: 7
Training loss: 3.0947076105348224
Validation loss: 2.723895117123549

Epoch: 6| Step: 8
Training loss: 3.5682396411904413
Validation loss: 2.713584771230336

Epoch: 6| Step: 9
Training loss: 2.977446497413261
Validation loss: 2.7118367073283394

Epoch: 6| Step: 10
Training loss: 2.551538235326488
Validation loss: 2.712713977949262

Epoch: 6| Step: 11
Training loss: 3.2044186840647404
Validation loss: 2.707074451283818

Epoch: 6| Step: 12
Training loss: 2.8231541907874846
Validation loss: 2.7088838700830054

Epoch: 6| Step: 13
Training loss: 2.1966810203202924
Validation loss: 2.707595053132081

Epoch: 281| Step: 0
Training loss: 2.88249258525123
Validation loss: 2.706223314474798

Epoch: 6| Step: 1
Training loss: 3.258974010053711
Validation loss: 2.7102452041630447

Epoch: 6| Step: 2
Training loss: 2.8233669151852103
Validation loss: 2.7111279399825703

Epoch: 6| Step: 3
Training loss: 3.5032785591274065
Validation loss: 2.7049629629672256

Epoch: 6| Step: 4
Training loss: 3.135197290664752
Validation loss: 2.709495008169518

Epoch: 6| Step: 5
Training loss: 3.2373507903485694
Validation loss: 2.709525575884376

Epoch: 6| Step: 6
Training loss: 2.9608711496935984
Validation loss: 2.704409345696171

Epoch: 6| Step: 7
Training loss: 2.8078539302361296
Validation loss: 2.7067918642469317

Epoch: 6| Step: 8
Training loss: 2.9991938779514578
Validation loss: 2.7128487920865743

Epoch: 6| Step: 9
Training loss: 3.132591791535798
Validation loss: 2.7145523388221666

Epoch: 6| Step: 10
Training loss: 3.030756959439734
Validation loss: 2.7099642939289494

Epoch: 6| Step: 11
Training loss: 2.481884553804936
Validation loss: 2.7111251589736534

Epoch: 6| Step: 12
Training loss: 2.96226998896941
Validation loss: 2.7125755336212554

Epoch: 6| Step: 13
Training loss: 3.1148443378479507
Validation loss: 2.716015445810473

Epoch: 282| Step: 0
Training loss: 3.4727625278134067
Validation loss: 2.7161267375600215

Epoch: 6| Step: 1
Training loss: 3.294114389838684
Validation loss: 2.7169119213542583

Epoch: 6| Step: 2
Training loss: 3.3610809962357107
Validation loss: 2.7240125637828108

Epoch: 6| Step: 3
Training loss: 2.815670345843057
Validation loss: 2.7312058983231755

Epoch: 6| Step: 4
Training loss: 2.091307282697902
Validation loss: 2.72971001139907

Epoch: 6| Step: 5
Training loss: 2.690614182365195
Validation loss: 2.7524333835721166

Epoch: 6| Step: 6
Training loss: 3.379320840262236
Validation loss: 2.7295514724482928

Epoch: 6| Step: 7
Training loss: 3.341376059081151
Validation loss: 2.72809173455073

Epoch: 6| Step: 8
Training loss: 2.4572992466745927
Validation loss: 2.7136397122122733

Epoch: 6| Step: 9
Training loss: 3.176811098202427
Validation loss: 2.7052917152108047

Epoch: 6| Step: 10
Training loss: 2.850569042483763
Validation loss: 2.7071586017459937

Epoch: 6| Step: 11
Training loss: 3.1273320461095167
Validation loss: 2.703173152625812

Epoch: 6| Step: 12
Training loss: 2.839438723051246
Validation loss: 2.703423190499335

Epoch: 6| Step: 13
Training loss: 3.1989137832552155
Validation loss: 2.7031027703880013

Epoch: 283| Step: 0
Training loss: 3.180870642086379
Validation loss: 2.6985816033213412

Epoch: 6| Step: 1
Training loss: 3.134667967228827
Validation loss: 2.7043905023113224

Epoch: 6| Step: 2
Training loss: 3.084559033748296
Validation loss: 2.7051155537610647

Epoch: 6| Step: 3
Training loss: 3.1373279782741426
Validation loss: 2.7035020694116376

Epoch: 6| Step: 4
Training loss: 3.6961345121256173
Validation loss: 2.7035160326008283

Epoch: 6| Step: 5
Training loss: 3.153756544761807
Validation loss: 2.703232481801372

Epoch: 6| Step: 6
Training loss: 3.2072066933969072
Validation loss: 2.7019447492323057

Epoch: 6| Step: 7
Training loss: 3.4338981484809104
Validation loss: 2.7049001460218585

Epoch: 6| Step: 8
Training loss: 2.400869124716321
Validation loss: 2.7019972920945445

Epoch: 6| Step: 9
Training loss: 2.557346744811791
Validation loss: 2.7028176330135456

Epoch: 6| Step: 10
Training loss: 2.600825758163859
Validation loss: 2.706502364299758

Epoch: 6| Step: 11
Training loss: 3.1613924039515715
Validation loss: 2.7105304568113184

Epoch: 6| Step: 12
Training loss: 2.7639620679137784
Validation loss: 2.7358935427377618

Epoch: 6| Step: 13
Training loss: 2.163313973765846
Validation loss: 2.750495743838022

Epoch: 284| Step: 0
Training loss: 3.288164682241305
Validation loss: 2.767732382205769

Epoch: 6| Step: 1
Training loss: 3.1217536849238985
Validation loss: 2.7622688131944337

Epoch: 6| Step: 2
Training loss: 2.3834225733484553
Validation loss: 2.7266504417101376

Epoch: 6| Step: 3
Training loss: 3.204903755349712
Validation loss: 2.7284831559696787

Epoch: 6| Step: 4
Training loss: 3.1695528597115037
Validation loss: 2.717101575563998

Epoch: 6| Step: 5
Training loss: 2.96642847140742
Validation loss: 2.707364247043944

Epoch: 6| Step: 6
Training loss: 2.418012825066542
Validation loss: 2.7024649760824975

Epoch: 6| Step: 7
Training loss: 3.4161348316643405
Validation loss: 2.703753934349361

Epoch: 6| Step: 8
Training loss: 3.5901133837632995
Validation loss: 2.699398694330301

Epoch: 6| Step: 9
Training loss: 3.1405639642506573
Validation loss: 2.7000617778672944

Epoch: 6| Step: 10
Training loss: 3.108000638473229
Validation loss: 2.699753258785677

Epoch: 6| Step: 11
Training loss: 2.9032285016912165
Validation loss: 2.702336798836082

Epoch: 6| Step: 12
Training loss: 2.5194958588236247
Validation loss: 2.7002704206927723

Epoch: 6| Step: 13
Training loss: 2.8041981559750075
Validation loss: 2.70035084044332

Epoch: 285| Step: 0
Training loss: 3.386389834085621
Validation loss: 2.6995539300921503

Epoch: 6| Step: 1
Training loss: 2.7015919831025674
Validation loss: 2.70070088676939

Epoch: 6| Step: 2
Training loss: 2.5557239541487204
Validation loss: 2.698583043514279

Epoch: 6| Step: 3
Training loss: 2.5261713578008496
Validation loss: 2.700953981063081

Epoch: 6| Step: 4
Training loss: 3.335249032440972
Validation loss: 2.702128460723

Epoch: 6| Step: 5
Training loss: 2.347391783278646
Validation loss: 2.6970889535808187

Epoch: 6| Step: 6
Training loss: 3.353452776329389
Validation loss: 2.6971100436660933

Epoch: 6| Step: 7
Training loss: 3.557811529656145
Validation loss: 2.7034372574594694

Epoch: 6| Step: 8
Training loss: 2.663006794295201
Validation loss: 2.696709315249219

Epoch: 6| Step: 9
Training loss: 3.47971569609984
Validation loss: 2.6978539387387763

Epoch: 6| Step: 10
Training loss: 2.0447339223856225
Validation loss: 2.7025279615661932

Epoch: 6| Step: 11
Training loss: 3.3546522432703525
Validation loss: 2.7056779899345926

Epoch: 6| Step: 12
Training loss: 3.162786984898101
Validation loss: 2.704627582113392

Epoch: 6| Step: 13
Training loss: 3.3921813205713667
Validation loss: 2.7117889307010117

Epoch: 286| Step: 0
Training loss: 3.0892728526495805
Validation loss: 2.7207699396994984

Epoch: 6| Step: 1
Training loss: 2.4697145919539873
Validation loss: 2.7218094762158267

Epoch: 6| Step: 2
Training loss: 3.443197072358996
Validation loss: 2.7316098793907972

Epoch: 6| Step: 3
Training loss: 3.4192876919487922
Validation loss: 2.7265436301292563

Epoch: 6| Step: 4
Training loss: 2.5575843741929067
Validation loss: 2.7214494994176293

Epoch: 6| Step: 5
Training loss: 2.632075537707828
Validation loss: 2.7172114547789428

Epoch: 6| Step: 6
Training loss: 2.538995078732265
Validation loss: 2.709313990499363

Epoch: 6| Step: 7
Training loss: 2.917119853824513
Validation loss: 2.7064388897063476

Epoch: 6| Step: 8
Training loss: 3.1331835595987108
Validation loss: 2.7049946774878513

Epoch: 6| Step: 9
Training loss: 3.0959698968256752
Validation loss: 2.6999644407029506

Epoch: 6| Step: 10
Training loss: 2.7176646554540893
Validation loss: 2.7010260575021605

Epoch: 6| Step: 11
Training loss: 3.6977460078587407
Validation loss: 2.702425154178998

Epoch: 6| Step: 12
Training loss: 3.1267573183931305
Validation loss: 2.6951299552337744

Epoch: 6| Step: 13
Training loss: 3.3099836472398345
Validation loss: 2.703275053397686

Epoch: 287| Step: 0
Training loss: 2.816245573119076
Validation loss: 2.7091133969479073

Epoch: 6| Step: 1
Training loss: 3.0855901208752545
Validation loss: 2.7083676401494396

Epoch: 6| Step: 2
Training loss: 3.273599479509687
Validation loss: 2.7195302220666666

Epoch: 6| Step: 3
Training loss: 2.720754739308736
Validation loss: 2.721681279366753

Epoch: 6| Step: 4
Training loss: 3.2259689413184938
Validation loss: 2.7118555311148267

Epoch: 6| Step: 5
Training loss: 2.9282377597914846
Validation loss: 2.7041397082259193

Epoch: 6| Step: 6
Training loss: 2.3324077564247263
Validation loss: 2.6946990663457884

Epoch: 6| Step: 7
Training loss: 2.836188691419342
Validation loss: 2.6989237823904646

Epoch: 6| Step: 8
Training loss: 3.6037936302399323
Validation loss: 2.69632793201101

Epoch: 6| Step: 9
Training loss: 3.513840557330584
Validation loss: 2.698916588026482

Epoch: 6| Step: 10
Training loss: 3.2355573032040237
Validation loss: 2.692511137975876

Epoch: 6| Step: 11
Training loss: 2.4571473013878866
Validation loss: 2.6944254257934297

Epoch: 6| Step: 12
Training loss: 2.724927001815309
Validation loss: 2.6905929546561462

Epoch: 6| Step: 13
Training loss: 3.377908089561265
Validation loss: 2.6934033704767097

Epoch: 288| Step: 0
Training loss: 2.737491423014264
Validation loss: 2.6946207003731137

Epoch: 6| Step: 1
Training loss: 2.455502469604717
Validation loss: 2.6935618517949744

Epoch: 6| Step: 2
Training loss: 3.553250267484533
Validation loss: 2.6948205575918367

Epoch: 6| Step: 3
Training loss: 3.5749484291891966
Validation loss: 2.6936866044919943

Epoch: 6| Step: 4
Training loss: 3.055326038949799
Validation loss: 2.696706701896908

Epoch: 6| Step: 5
Training loss: 3.145833569120352
Validation loss: 2.695923818987554

Epoch: 6| Step: 6
Training loss: 2.7260983134822023
Validation loss: 2.694269456845191

Epoch: 6| Step: 7
Training loss: 2.6652062609298293
Validation loss: 2.6932495621167374

Epoch: 6| Step: 8
Training loss: 2.4786949243164296
Validation loss: 2.6928443502238477

Epoch: 6| Step: 9
Training loss: 3.5157386591870203
Validation loss: 2.693284786071728

Epoch: 6| Step: 10
Training loss: 2.9968088980058427
Validation loss: 2.690944129319984

Epoch: 6| Step: 11
Training loss: 3.1059563787753794
Validation loss: 2.6884079906732197

Epoch: 6| Step: 12
Training loss: 2.826708106765839
Validation loss: 2.691016508159876

Epoch: 6| Step: 13
Training loss: 3.2357239789525853
Validation loss: 2.6942604478761525

Epoch: 289| Step: 0
Training loss: 2.6913297999449144
Validation loss: 2.692983747991652

Epoch: 6| Step: 1
Training loss: 3.2293790849940747
Validation loss: 2.6941963879852557

Epoch: 6| Step: 2
Training loss: 3.4273954827130577
Validation loss: 2.6937248843797863

Epoch: 6| Step: 3
Training loss: 2.7155024106853127
Validation loss: 2.6957175976596095

Epoch: 6| Step: 4
Training loss: 2.469062109424409
Validation loss: 2.6982478102752805

Epoch: 6| Step: 5
Training loss: 3.2201200365711147
Validation loss: 2.6924001059886797

Epoch: 6| Step: 6
Training loss: 2.970117193921796
Validation loss: 2.692354528713211

Epoch: 6| Step: 7
Training loss: 2.7130015318290077
Validation loss: 2.697028306785218

Epoch: 6| Step: 8
Training loss: 3.193730118721372
Validation loss: 2.6993501400702273

Epoch: 6| Step: 9
Training loss: 2.6206739291266197
Validation loss: 2.6928519406655225

Epoch: 6| Step: 10
Training loss: 3.145285114409779
Validation loss: 2.6933422594784004

Epoch: 6| Step: 11
Training loss: 3.1184175975457658
Validation loss: 2.6899313625452517

Epoch: 6| Step: 12
Training loss: 3.2863627972548413
Validation loss: 2.6926497322938903

Epoch: 6| Step: 13
Training loss: 3.420979561199115
Validation loss: 2.691811675520173

Epoch: 290| Step: 0
Training loss: 3.0698359850085666
Validation loss: 2.6912836177595536

Epoch: 6| Step: 1
Training loss: 3.2994806921437787
Validation loss: 2.694311979761973

Epoch: 6| Step: 2
Training loss: 2.7810514572085143
Validation loss: 2.69513937412104

Epoch: 6| Step: 3
Training loss: 2.9930845663892653
Validation loss: 2.6938850007547863

Epoch: 6| Step: 4
Training loss: 3.3395650468509275
Validation loss: 2.691102608759139

Epoch: 6| Step: 5
Training loss: 3.2516475316248337
Validation loss: 2.6911391011305774

Epoch: 6| Step: 6
Training loss: 2.8656537269808062
Validation loss: 2.690966351719139

Epoch: 6| Step: 7
Training loss: 2.715871229520898
Validation loss: 2.6887220984230082

Epoch: 6| Step: 8
Training loss: 3.473463275794909
Validation loss: 2.6998363479458636

Epoch: 6| Step: 9
Training loss: 3.0412909567474387
Validation loss: 2.7030279030788855

Epoch: 6| Step: 10
Training loss: 2.935317344600611
Validation loss: 2.7200828786166333

Epoch: 6| Step: 11
Training loss: 2.6109385117734893
Validation loss: 2.7264260480248135

Epoch: 6| Step: 12
Training loss: 2.778564957237483
Validation loss: 2.729067927376909

Epoch: 6| Step: 13
Training loss: 2.920527346297026
Validation loss: 2.7599270133066316

Epoch: 291| Step: 0
Training loss: 3.6633516122247998
Validation loss: 2.789542015206095

Epoch: 6| Step: 1
Training loss: 2.630941841401926
Validation loss: 2.8462038574185096

Epoch: 6| Step: 2
Training loss: 2.6368578160664784
Validation loss: 2.803756793899954

Epoch: 6| Step: 3
Training loss: 3.2347933733601844
Validation loss: 2.7731422684295017

Epoch: 6| Step: 4
Training loss: 3.60451282463274
Validation loss: 2.7291038909570884

Epoch: 6| Step: 5
Training loss: 3.1716043892414243
Validation loss: 2.701157919623954

Epoch: 6| Step: 6
Training loss: 2.911468251074389
Validation loss: 2.6895966799207653

Epoch: 6| Step: 7
Training loss: 2.7126062187809246
Validation loss: 2.6851933685650766

Epoch: 6| Step: 8
Training loss: 3.0113800689615333
Validation loss: 2.6897281616281843

Epoch: 6| Step: 9
Training loss: 3.015208951880207
Validation loss: 2.689474661967519

Epoch: 6| Step: 10
Training loss: 3.454717760716985
Validation loss: 2.691504884403749

Epoch: 6| Step: 11
Training loss: 2.832781588369422
Validation loss: 2.6931074889164264

Epoch: 6| Step: 12
Training loss: 2.5546778874114353
Validation loss: 2.691351857226521

Epoch: 6| Step: 13
Training loss: 2.9360042578642944
Validation loss: 2.6889105517528553

Epoch: 292| Step: 0
Training loss: 2.58645523282092
Validation loss: 2.694285827629123

Epoch: 6| Step: 1
Training loss: 3.4575974167831354
Validation loss: 2.6914367859792003

Epoch: 6| Step: 2
Training loss: 3.3541204476972997
Validation loss: 2.691171793996034

Epoch: 6| Step: 3
Training loss: 3.360884074660366
Validation loss: 2.6887106366249354

Epoch: 6| Step: 4
Training loss: 3.4026635563855123
Validation loss: 2.6877483607062422

Epoch: 6| Step: 5
Training loss: 2.8176200885786593
Validation loss: 2.687287896751601

Epoch: 6| Step: 6
Training loss: 3.192584601157325
Validation loss: 2.6859203102104696

Epoch: 6| Step: 7
Training loss: 2.8986625481195794
Validation loss: 2.6893039037940847

Epoch: 6| Step: 8
Training loss: 2.54396349411689
Validation loss: 2.6851215287779113

Epoch: 6| Step: 9
Training loss: 2.930137009786089
Validation loss: 2.687730229392342

Epoch: 6| Step: 10
Training loss: 2.7896818440378808
Validation loss: 2.6833059080089616

Epoch: 6| Step: 11
Training loss: 2.349800539682878
Validation loss: 2.6854467234502275

Epoch: 6| Step: 12
Training loss: 3.1207654109501894
Validation loss: 2.683884326419752

Epoch: 6| Step: 13
Training loss: 3.2491304261295784
Validation loss: 2.682810077375527

Epoch: 293| Step: 0
Training loss: 3.3236750551448893
Validation loss: 2.6872780401286263

Epoch: 6| Step: 1
Training loss: 3.0941408469179947
Validation loss: 2.6832875957220232

Epoch: 6| Step: 2
Training loss: 3.0443641685272795
Validation loss: 2.686337822834872

Epoch: 6| Step: 3
Training loss: 3.562522085020977
Validation loss: 2.6850769841847977

Epoch: 6| Step: 4
Training loss: 2.8815213752098066
Validation loss: 2.6866377066961853

Epoch: 6| Step: 5
Training loss: 2.7262687634185747
Validation loss: 2.6869906233456207

Epoch: 6| Step: 6
Training loss: 3.2440289151447037
Validation loss: 2.6901516626015196

Epoch: 6| Step: 7
Training loss: 2.888749457523917
Validation loss: 2.691956499834706

Epoch: 6| Step: 8
Training loss: 3.015897748402754
Validation loss: 2.689721029402488

Epoch: 6| Step: 9
Training loss: 3.192837603110886
Validation loss: 2.692099389890334

Epoch: 6| Step: 10
Training loss: 2.712457851662565
Validation loss: 2.6881029845770703

Epoch: 6| Step: 11
Training loss: 2.8434117713415707
Validation loss: 2.68638988173977

Epoch: 6| Step: 12
Training loss: 2.3432935143022826
Validation loss: 2.6840253290278078

Epoch: 6| Step: 13
Training loss: 3.0521271651487214
Validation loss: 2.6916050829392457

Epoch: 294| Step: 0
Training loss: 3.0543509295478932
Validation loss: 2.6878627933824264

Epoch: 6| Step: 1
Training loss: 2.6753793679155238
Validation loss: 2.6875356436691167

Epoch: 6| Step: 2
Training loss: 2.8523280958019317
Validation loss: 2.696949740433041

Epoch: 6| Step: 3
Training loss: 3.1107473747366807
Validation loss: 2.6906540799814214

Epoch: 6| Step: 4
Training loss: 2.9103843241164045
Validation loss: 2.6889379936816447

Epoch: 6| Step: 5
Training loss: 3.100027170369842
Validation loss: 2.694638082249286

Epoch: 6| Step: 6
Training loss: 3.0859979164873015
Validation loss: 2.6962328076337787

Epoch: 6| Step: 7
Training loss: 2.6622268751581735
Validation loss: 2.701770302410586

Epoch: 6| Step: 8
Training loss: 3.245169203803697
Validation loss: 2.6944141052869996

Epoch: 6| Step: 9
Training loss: 3.1372863332024736
Validation loss: 2.687388000672872

Epoch: 6| Step: 10
Training loss: 3.281232125369841
Validation loss: 2.683821022798878

Epoch: 6| Step: 11
Training loss: 2.916899008806387
Validation loss: 2.6877974621968157

Epoch: 6| Step: 12
Training loss: 2.9064034042069657
Validation loss: 2.683581119931607

Epoch: 6| Step: 13
Training loss: 3.286919917575672
Validation loss: 2.687265047685829

Epoch: 295| Step: 0
Training loss: 2.7497810796817146
Validation loss: 2.6879280819684195

Epoch: 6| Step: 1
Training loss: 3.283442173685197
Validation loss: 2.687320374125726

Epoch: 6| Step: 2
Training loss: 3.598744115052839
Validation loss: 2.686603742011869

Epoch: 6| Step: 3
Training loss: 3.0574270778390957
Validation loss: 2.6890565895901806

Epoch: 6| Step: 4
Training loss: 2.8029028014506467
Validation loss: 2.683633491195699

Epoch: 6| Step: 5
Training loss: 3.2051766128796984
Validation loss: 2.6870948350636894

Epoch: 6| Step: 6
Training loss: 2.553947691582647
Validation loss: 2.685796010025763

Epoch: 6| Step: 7
Training loss: 2.564839388483146
Validation loss: 2.690507271292348

Epoch: 6| Step: 8
Training loss: 2.8859707039914446
Validation loss: 2.6917124780492325

Epoch: 6| Step: 9
Training loss: 2.738958212504117
Validation loss: 2.698671941640341

Epoch: 6| Step: 10
Training loss: 2.0498426051310736
Validation loss: 2.7197415565511447

Epoch: 6| Step: 11
Training loss: 3.3693302709306154
Validation loss: 2.726307353135491

Epoch: 6| Step: 12
Training loss: 3.609199949040751
Validation loss: 2.746812528130614

Epoch: 6| Step: 13
Training loss: 3.7777485674931803
Validation loss: 2.7185538606257027

Epoch: 296| Step: 0
Training loss: 3.1382803444247354
Validation loss: 2.703289527967047

Epoch: 6| Step: 1
Training loss: 3.7731888019752686
Validation loss: 2.6921130893995286

Epoch: 6| Step: 2
Training loss: 3.3056255479200187
Validation loss: 2.687533840797241

Epoch: 6| Step: 3
Training loss: 3.488561467345845
Validation loss: 2.6898324092960344

Epoch: 6| Step: 4
Training loss: 2.6505144915383383
Validation loss: 2.6867168026498165

Epoch: 6| Step: 5
Training loss: 2.956572120327484
Validation loss: 2.683807084186363

Epoch: 6| Step: 6
Training loss: 3.2940213115213504
Validation loss: 2.6860443984862106

Epoch: 6| Step: 7
Training loss: 2.625249759962861
Validation loss: 2.6841417456363645

Epoch: 6| Step: 8
Training loss: 2.659281537826395
Validation loss: 2.6794650297802027

Epoch: 6| Step: 9
Training loss: 2.8173831509965135
Validation loss: 2.678684880929865

Epoch: 6| Step: 10
Training loss: 3.0098765239546164
Validation loss: 2.6836403969577454

Epoch: 6| Step: 11
Training loss: 3.1090181232168335
Validation loss: 2.6798059207787976

Epoch: 6| Step: 12
Training loss: 2.3297683752952
Validation loss: 2.67887603854026

Epoch: 6| Step: 13
Training loss: 2.349027870880077
Validation loss: 2.680636829471223

Epoch: 297| Step: 0
Training loss: 2.730895264239254
Validation loss: 2.68248111682235

Epoch: 6| Step: 1
Training loss: 2.9851328901042296
Validation loss: 2.676924890945056

Epoch: 6| Step: 2
Training loss: 2.8306736711094076
Validation loss: 2.682592487680281

Epoch: 6| Step: 3
Training loss: 2.9164983065015093
Validation loss: 2.675929002639864

Epoch: 6| Step: 4
Training loss: 3.556092774681723
Validation loss: 2.6768584385373027

Epoch: 6| Step: 5
Training loss: 2.6125554786157585
Validation loss: 2.68080767494836

Epoch: 6| Step: 6
Training loss: 2.7379254641923954
Validation loss: 2.680239779776796

Epoch: 6| Step: 7
Training loss: 2.9772141111323167
Validation loss: 2.676253244238535

Epoch: 6| Step: 8
Training loss: 3.1248438986890714
Validation loss: 2.678436219630736

Epoch: 6| Step: 9
Training loss: 3.0687052861392066
Validation loss: 2.678538798276539

Epoch: 6| Step: 10
Training loss: 3.1642333938224367
Validation loss: 2.6830229273251915

Epoch: 6| Step: 11
Training loss: 3.179140085998314
Validation loss: 2.6794835255796805

Epoch: 6| Step: 12
Training loss: 3.251473899561743
Validation loss: 2.6786571109660313

Epoch: 6| Step: 13
Training loss: 2.7020706149007574
Validation loss: 2.6789386542072964

Epoch: 298| Step: 0
Training loss: 2.860727125982318
Validation loss: 2.684227953099854

Epoch: 6| Step: 1
Training loss: 3.2570416386970025
Validation loss: 2.698818398334131

Epoch: 6| Step: 2
Training loss: 2.923419401437998
Validation loss: 2.6889089805287774

Epoch: 6| Step: 3
Training loss: 3.0414474268942286
Validation loss: 2.716890983095473

Epoch: 6| Step: 4
Training loss: 2.519341513416624
Validation loss: 2.7117744646291158

Epoch: 6| Step: 5
Training loss: 3.364411025856282
Validation loss: 2.7251732704820077

Epoch: 6| Step: 6
Training loss: 2.4941542945433457
Validation loss: 2.7044214500227843

Epoch: 6| Step: 7
Training loss: 3.3338227548516435
Validation loss: 2.7221178311108862

Epoch: 6| Step: 8
Training loss: 3.365152757643461
Validation loss: 2.7292861740097027

Epoch: 6| Step: 9
Training loss: 2.9902889114678954
Validation loss: 2.7153861830024235

Epoch: 6| Step: 10
Training loss: 2.279818778281335
Validation loss: 2.7121848373784063

Epoch: 6| Step: 11
Training loss: 3.252659223267184
Validation loss: 2.7168886410954296

Epoch: 6| Step: 12
Training loss: 2.8604529178227294
Validation loss: 2.700282662247238

Epoch: 6| Step: 13
Training loss: 3.5544123616476044
Validation loss: 2.6943976886603975

Epoch: 299| Step: 0
Training loss: 3.48433668175399
Validation loss: 2.6804912204564335

Epoch: 6| Step: 1
Training loss: 2.808889657297445
Validation loss: 2.687592758787193

Epoch: 6| Step: 2
Training loss: 3.5884997951831203
Validation loss: 2.6751172971266275

Epoch: 6| Step: 3
Training loss: 2.7387157753878286
Validation loss: 2.6772800885741628

Epoch: 6| Step: 4
Training loss: 2.9852804837486193
Validation loss: 2.677299029885623

Epoch: 6| Step: 5
Training loss: 2.7246627528933547
Validation loss: 2.67879965388529

Epoch: 6| Step: 6
Training loss: 3.006891124351464
Validation loss: 2.674647458413485

Epoch: 6| Step: 7
Training loss: 2.2828450309634003
Validation loss: 2.6757802171782257

Epoch: 6| Step: 8
Training loss: 2.665667992588388
Validation loss: 2.670287472308157

Epoch: 6| Step: 9
Training loss: 2.756564281996266
Validation loss: 2.669998437781847

Epoch: 6| Step: 10
Training loss: 3.8546614183301986
Validation loss: 2.67686442610209

Epoch: 6| Step: 11
Training loss: 2.8196010379076633
Validation loss: 2.6730362118017683

Epoch: 6| Step: 12
Training loss: 3.0047420534447307
Validation loss: 2.677755665391737

Epoch: 6| Step: 13
Training loss: 2.8870682562861374
Validation loss: 2.6759117933548753

Epoch: 300| Step: 0
Training loss: 2.968583594226075
Validation loss: 2.677322147851884

Epoch: 6| Step: 1
Training loss: 2.5542962477537845
Validation loss: 2.6766872203129046

Epoch: 6| Step: 2
Training loss: 2.7783319831696884
Validation loss: 2.6748968869104024

Epoch: 6| Step: 3
Training loss: 3.084744534294195
Validation loss: 2.6775027815092924

Epoch: 6| Step: 4
Training loss: 3.4478852576969756
Validation loss: 2.6766379083064087

Epoch: 6| Step: 5
Training loss: 3.3078837347851944
Validation loss: 2.6803856128686703

Epoch: 6| Step: 6
Training loss: 2.9555337760078206
Validation loss: 2.671962275816029

Epoch: 6| Step: 7
Training loss: 2.861052641121969
Validation loss: 2.6786879549790203

Epoch: 6| Step: 8
Training loss: 3.063195908556019
Validation loss: 2.674178449801196

Epoch: 6| Step: 9
Training loss: 2.9252759754373097
Validation loss: 2.67455711091008

Epoch: 6| Step: 10
Training loss: 2.797514261681524
Validation loss: 2.667329971690682

Epoch: 6| Step: 11
Training loss: 3.5049271643195468
Validation loss: 2.676059510047353

Epoch: 6| Step: 12
Training loss: 3.074300801249764
Validation loss: 2.6707978345599144

Epoch: 6| Step: 13
Training loss: 2.339653911754542
Validation loss: 2.6752201391106025

Epoch: 301| Step: 0
Training loss: 3.236920078727514
Validation loss: 2.673753996054392

Epoch: 6| Step: 1
Training loss: 3.2221535770368286
Validation loss: 2.6813180980739784

Epoch: 6| Step: 2
Training loss: 1.8233997540461115
Validation loss: 2.685067990202363

Epoch: 6| Step: 3
Training loss: 2.341543252301499
Validation loss: 2.6810368592089464

Epoch: 6| Step: 4
Training loss: 3.1046837156337026
Validation loss: 2.6932603953999963

Epoch: 6| Step: 5
Training loss: 3.1465492360245313
Validation loss: 2.6965528927639126

Epoch: 6| Step: 6
Training loss: 2.9111365798470255
Validation loss: 2.689596434003108

Epoch: 6| Step: 7
Training loss: 3.591641545631965
Validation loss: 2.6829310444336096

Epoch: 6| Step: 8
Training loss: 2.905790395183339
Validation loss: 2.6831638146841894

Epoch: 6| Step: 9
Training loss: 2.0474272703637606
Validation loss: 2.6760178773553447

Epoch: 6| Step: 10
Training loss: 3.4762898198891925
Validation loss: 2.6718107555327

Epoch: 6| Step: 11
Training loss: 3.1463540427305747
Validation loss: 2.676689103280656

Epoch: 6| Step: 12
Training loss: 3.3115001105046877
Validation loss: 2.673222456605341

Epoch: 6| Step: 13
Training loss: 3.2679801369837325
Validation loss: 2.674024567217451

Epoch: 302| Step: 0
Training loss: 2.7881211687791536
Validation loss: 2.6735863047386865

Epoch: 6| Step: 1
Training loss: 2.814294623968725
Validation loss: 2.679134246130393

Epoch: 6| Step: 2
Training loss: 2.9446502669590746
Validation loss: 2.6750221947680854

Epoch: 6| Step: 3
Training loss: 2.6472820811149287
Validation loss: 2.6843508828414047

Epoch: 6| Step: 4
Training loss: 3.947940849827331
Validation loss: 2.68670348879166

Epoch: 6| Step: 5
Training loss: 2.8325987779947175
Validation loss: 2.688146349866172

Epoch: 6| Step: 6
Training loss: 3.176208842677806
Validation loss: 2.693887480758357

Epoch: 6| Step: 7
Training loss: 3.1726754216843336
Validation loss: 2.6827062926512624

Epoch: 6| Step: 8
Training loss: 2.63117962015946
Validation loss: 2.686936979849938

Epoch: 6| Step: 9
Training loss: 2.6499803038530922
Validation loss: 2.6786103418143923

Epoch: 6| Step: 10
Training loss: 2.687583212340484
Validation loss: 2.676056335263656

Epoch: 6| Step: 11
Training loss: 3.2114333166747726
Validation loss: 2.6794561863098703

Epoch: 6| Step: 12
Training loss: 3.20538295154071
Validation loss: 2.6811357307021355

Epoch: 6| Step: 13
Training loss: 2.994679023725107
Validation loss: 2.678106541857831

Epoch: 303| Step: 0
Training loss: 2.6733846582288288
Validation loss: 2.6776935572516383

Epoch: 6| Step: 1
Training loss: 2.9559238632989375
Validation loss: 2.6799651985376083

Epoch: 6| Step: 2
Training loss: 2.926731907574296
Validation loss: 2.682961970219473

Epoch: 6| Step: 3
Training loss: 3.61346863956654
Validation loss: 2.6851884135002644

Epoch: 6| Step: 4
Training loss: 2.7937762606963217
Validation loss: 2.6749194774328817

Epoch: 6| Step: 5
Training loss: 2.413633833173468
Validation loss: 2.677058082890181

Epoch: 6| Step: 6
Training loss: 2.8069325761786894
Validation loss: 2.6825262607277267

Epoch: 6| Step: 7
Training loss: 3.19278443553307
Validation loss: 2.6846202599391864

Epoch: 6| Step: 8
Training loss: 2.3715554405325485
Validation loss: 2.687926395718666

Epoch: 6| Step: 9
Training loss: 3.4839125527357693
Validation loss: 2.6821459212800796

Epoch: 6| Step: 10
Training loss: 3.6505881266796307
Validation loss: 2.6790258185668634

Epoch: 6| Step: 11
Training loss: 3.0790549485549463
Validation loss: 2.674563934669546

Epoch: 6| Step: 12
Training loss: 2.898030789777102
Validation loss: 2.6691040531201207

Epoch: 6| Step: 13
Training loss: 2.522507534564044
Validation loss: 2.6738240952010726

Epoch: 304| Step: 0
Training loss: 2.2771564491681366
Validation loss: 2.671332490798319

Epoch: 6| Step: 1
Training loss: 2.907149637093208
Validation loss: 2.676008125796584

Epoch: 6| Step: 2
Training loss: 2.651280050795344
Validation loss: 2.6749439768789425

Epoch: 6| Step: 3
Training loss: 3.419292712329246
Validation loss: 2.6785234807377116

Epoch: 6| Step: 4
Training loss: 3.1313598004427887
Validation loss: 2.686936810017876

Epoch: 6| Step: 5
Training loss: 2.976548082211637
Validation loss: 2.682829228093289

Epoch: 6| Step: 6
Training loss: 3.353641745362464
Validation loss: 2.685645673051315

Epoch: 6| Step: 7
Training loss: 2.799390801506304
Validation loss: 2.681576353501392

Epoch: 6| Step: 8
Training loss: 2.9483256421403063
Validation loss: 2.681737455241107

Epoch: 6| Step: 9
Training loss: 2.952835956940147
Validation loss: 2.6810570705938352

Epoch: 6| Step: 10
Training loss: 3.414589009833995
Validation loss: 2.679109873994476

Epoch: 6| Step: 11
Training loss: 2.958974061450673
Validation loss: 2.6782635889352187

Epoch: 6| Step: 12
Training loss: 2.8603850701669153
Validation loss: 2.680992065065809

Epoch: 6| Step: 13
Training loss: 3.220366581254931
Validation loss: 2.678014977546029

Epoch: 305| Step: 0
Training loss: 3.0309982981839085
Validation loss: 2.675603925522298

Epoch: 6| Step: 1
Training loss: 2.6992986863220114
Validation loss: 2.6817137764216388

Epoch: 6| Step: 2
Training loss: 2.9054587322738366
Validation loss: 2.6825363335914907

Epoch: 6| Step: 3
Training loss: 3.1932894917812122
Validation loss: 2.676476551339628

Epoch: 6| Step: 4
Training loss: 2.9541808163438974
Validation loss: 2.688896688147554

Epoch: 6| Step: 5
Training loss: 1.9684228776702666
Validation loss: 2.695016633033279

Epoch: 6| Step: 6
Training loss: 3.185705540001721
Validation loss: 2.6912122949128983

Epoch: 6| Step: 7
Training loss: 3.5582812577188445
Validation loss: 2.7020306258921543

Epoch: 6| Step: 8
Training loss: 3.4474257996605293
Validation loss: 2.705728091585617

Epoch: 6| Step: 9
Training loss: 2.623057418654349
Validation loss: 2.695163336869833

Epoch: 6| Step: 10
Training loss: 3.4209332846854883
Validation loss: 2.6842113051253613

Epoch: 6| Step: 11
Training loss: 2.870230491766593
Validation loss: 2.6889091921864434

Epoch: 6| Step: 12
Training loss: 2.549362933295615
Validation loss: 2.671764216764648

Epoch: 6| Step: 13
Training loss: 3.171510121071519
Validation loss: 2.6677485823342337

Epoch: 306| Step: 0
Training loss: 3.691114949030383
Validation loss: 2.668757169308069

Epoch: 6| Step: 1
Training loss: 2.566373363266744
Validation loss: 2.666709238784148

Epoch: 6| Step: 2
Training loss: 3.098597264559331
Validation loss: 2.668039987960344

Epoch: 6| Step: 3
Training loss: 3.276867655750043
Validation loss: 2.665006638736264

Epoch: 6| Step: 4
Training loss: 2.848001843741174
Validation loss: 2.670193175306613

Epoch: 6| Step: 5
Training loss: 2.7270483769992757
Validation loss: 2.6649938455453768

Epoch: 6| Step: 6
Training loss: 3.2630543789530817
Validation loss: 2.668969727507427

Epoch: 6| Step: 7
Training loss: 2.5558650951155326
Validation loss: 2.6665522543784332

Epoch: 6| Step: 8
Training loss: 2.834339038153891
Validation loss: 2.672956523039105

Epoch: 6| Step: 9
Training loss: 2.890072166571403
Validation loss: 2.683346067151373

Epoch: 6| Step: 10
Training loss: 3.071790810068738
Validation loss: 2.672639584006381

Epoch: 6| Step: 11
Training loss: 3.354191813562243
Validation loss: 2.671700898481621

Epoch: 6| Step: 12
Training loss: 2.7166762938845683
Validation loss: 2.676455817819617

Epoch: 6| Step: 13
Training loss: 2.707582359857701
Validation loss: 2.672267145033628

Epoch: 307| Step: 0
Training loss: 3.2867909468185497
Validation loss: 2.6740265047897194

Epoch: 6| Step: 1
Training loss: 3.043641551002879
Validation loss: 2.6741233950347723

Epoch: 6| Step: 2
Training loss: 3.394248046299016
Validation loss: 2.6763563433482624

Epoch: 6| Step: 3
Training loss: 3.2839254461786385
Validation loss: 2.6691273923800454

Epoch: 6| Step: 4
Training loss: 3.4777325322217965
Validation loss: 2.670608213487642

Epoch: 6| Step: 5
Training loss: 2.4508374476168577
Validation loss: 2.665338591863139

Epoch: 6| Step: 6
Training loss: 2.439410219204596
Validation loss: 2.667492348053293

Epoch: 6| Step: 7
Training loss: 2.53618526881879
Validation loss: 2.669608593612339

Epoch: 6| Step: 8
Training loss: 2.9100644910030558
Validation loss: 2.6666442276666866

Epoch: 6| Step: 9
Training loss: 3.005963121077556
Validation loss: 2.666363187090004

Epoch: 6| Step: 10
Training loss: 3.033112258679999
Validation loss: 2.6676828460053064

Epoch: 6| Step: 11
Training loss: 2.869499417820905
Validation loss: 2.6782097869132206

Epoch: 6| Step: 12
Training loss: 2.7379528071792656
Validation loss: 2.6795571932117026

Epoch: 6| Step: 13
Training loss: 3.363289331300178
Validation loss: 2.6746364145922543

Epoch: 308| Step: 0
Training loss: 2.4783801800067704
Validation loss: 2.6725422562666656

Epoch: 6| Step: 1
Training loss: 3.1283330308944186
Validation loss: 2.6735510863898044

Epoch: 6| Step: 2
Training loss: 2.8051801583543963
Validation loss: 2.667152420788761

Epoch: 6| Step: 3
Training loss: 3.296452933680341
Validation loss: 2.6624779843164417

Epoch: 6| Step: 4
Training loss: 3.4230305710591122
Validation loss: 2.6650478460725924

Epoch: 6| Step: 5
Training loss: 2.6212650248797735
Validation loss: 2.6681601507450603

Epoch: 6| Step: 6
Training loss: 3.0716559113679702
Validation loss: 2.6648051006048012

Epoch: 6| Step: 7
Training loss: 3.4658087555280686
Validation loss: 2.6739722867500864

Epoch: 6| Step: 8
Training loss: 3.002290487102358
Validation loss: 2.676120533371366

Epoch: 6| Step: 9
Training loss: 3.100693280622191
Validation loss: 2.676623198621193

Epoch: 6| Step: 10
Training loss: 2.6206170684745373
Validation loss: 2.6828216637624447

Epoch: 6| Step: 11
Training loss: 2.7882630300314015
Validation loss: 2.6901117384741013

Epoch: 6| Step: 12
Training loss: 3.024454896852605
Validation loss: 2.705761635239583

Epoch: 6| Step: 13
Training loss: 2.837058274088449
Validation loss: 2.7004749766762624

Epoch: 309| Step: 0
Training loss: 3.0959564971726032
Validation loss: 2.6964105362994846

Epoch: 6| Step: 1
Training loss: 3.071324150236773
Validation loss: 2.6756407820997463

Epoch: 6| Step: 2
Training loss: 3.099086897718322
Validation loss: 2.669188330711166

Epoch: 6| Step: 3
Training loss: 3.0229409768730524
Validation loss: 2.673641108317208

Epoch: 6| Step: 4
Training loss: 3.2383701878242195
Validation loss: 2.6612613087225716

Epoch: 6| Step: 5
Training loss: 3.1868669965919953
Validation loss: 2.660910005886072

Epoch: 6| Step: 6
Training loss: 2.664803857652935
Validation loss: 2.664204419846559

Epoch: 6| Step: 7
Training loss: 2.527758604077106
Validation loss: 2.6624440522906303

Epoch: 6| Step: 8
Training loss: 2.825770541406263
Validation loss: 2.6656715855920874

Epoch: 6| Step: 9
Training loss: 3.0421360820702112
Validation loss: 2.6732098130193256

Epoch: 6| Step: 10
Training loss: 2.736384759462537
Validation loss: 2.6675654237541906

Epoch: 6| Step: 11
Training loss: 3.2987448646242354
Validation loss: 2.668237231026617

Epoch: 6| Step: 12
Training loss: 3.145575877048049
Validation loss: 2.668570998576036

Epoch: 6| Step: 13
Training loss: 2.638913384262525
Validation loss: 2.6683007170109465

Epoch: 310| Step: 0
Training loss: 3.2175781190720985
Validation loss: 2.669504724915575

Epoch: 6| Step: 1
Training loss: 3.109698254828591
Validation loss: 2.671508882955588

Epoch: 6| Step: 2
Training loss: 2.5033884926554872
Validation loss: 2.674819820271257

Epoch: 6| Step: 3
Training loss: 3.6059472127172523
Validation loss: 2.6706627071666773

Epoch: 6| Step: 4
Training loss: 3.395487309400278
Validation loss: 2.680149573919923

Epoch: 6| Step: 5
Training loss: 2.4917773444389115
Validation loss: 2.687152572042368

Epoch: 6| Step: 6
Training loss: 2.6629805619221196
Validation loss: 2.702140953815886

Epoch: 6| Step: 7
Training loss: 2.6222410689860216
Validation loss: 2.6989393564985065

Epoch: 6| Step: 8
Training loss: 2.8445991673542683
Validation loss: 2.6903608071646063

Epoch: 6| Step: 9
Training loss: 3.037947972548433
Validation loss: 2.6846071820582877

Epoch: 6| Step: 10
Training loss: 2.6413473913071224
Validation loss: 2.671256830954521

Epoch: 6| Step: 11
Training loss: 3.013391329648877
Validation loss: 2.6643896308931296

Epoch: 6| Step: 12
Training loss: 3.1827389932870163
Validation loss: 2.6631077522006383

Epoch: 6| Step: 13
Training loss: 3.56364047885367
Validation loss: 2.6643514722142387

Epoch: 311| Step: 0
Training loss: 2.6755693560603797
Validation loss: 2.666107825460465

Epoch: 6| Step: 1
Training loss: 2.4867517390626186
Validation loss: 2.6578434854444373

Epoch: 6| Step: 2
Training loss: 3.478955488972299
Validation loss: 2.658224536138974

Epoch: 6| Step: 3
Training loss: 2.601771074245065
Validation loss: 2.6592136418984773

Epoch: 6| Step: 4
Training loss: 3.0966376497560573
Validation loss: 2.6588423286367213

Epoch: 6| Step: 5
Training loss: 2.96562496141086
Validation loss: 2.6607702053700377

Epoch: 6| Step: 6
Training loss: 2.655822001364114
Validation loss: 2.657833145376927

Epoch: 6| Step: 7
Training loss: 1.9601221707279057
Validation loss: 2.658092697839712

Epoch: 6| Step: 8
Training loss: 3.2719618354940643
Validation loss: 2.6640663492171766

Epoch: 6| Step: 9
Training loss: 3.2907336558546354
Validation loss: 2.6588331340639155

Epoch: 6| Step: 10
Training loss: 3.989302516579386
Validation loss: 2.663437629031486

Epoch: 6| Step: 11
Training loss: 2.8015539148968256
Validation loss: 2.6621760568991713

Epoch: 6| Step: 12
Training loss: 3.2239713817490556
Validation loss: 2.663162800771034

Epoch: 6| Step: 13
Training loss: 2.6563662335265206
Validation loss: 2.6753350147088413

Epoch: 312| Step: 0
Training loss: 3.2337042808766028
Validation loss: 2.678243161198503

Epoch: 6| Step: 1
Training loss: 2.974105341407246
Validation loss: 2.696429849979156

Epoch: 6| Step: 2
Training loss: 3.191195869748763
Validation loss: 2.7081334456015624

Epoch: 6| Step: 3
Training loss: 2.970831211797341
Validation loss: 2.71589975358532

Epoch: 6| Step: 4
Training loss: 2.7818416009122298
Validation loss: 2.696454797640629

Epoch: 6| Step: 5
Training loss: 2.9723833838608127
Validation loss: 2.6842126642060324

Epoch: 6| Step: 6
Training loss: 2.535251045511969
Validation loss: 2.68944026221792

Epoch: 6| Step: 7
Training loss: 2.5441990936275283
Validation loss: 2.6813408936013934

Epoch: 6| Step: 8
Training loss: 2.974002889019936
Validation loss: 2.668228868215844

Epoch: 6| Step: 9
Training loss: 2.508348259189677
Validation loss: 2.6650496131726813

Epoch: 6| Step: 10
Training loss: 3.1460935135588595
Validation loss: 2.6681317802518327

Epoch: 6| Step: 11
Training loss: 3.518284584284737
Validation loss: 2.6680394854250804

Epoch: 6| Step: 12
Training loss: 3.350092211920314
Validation loss: 2.671256284877613

Epoch: 6| Step: 13
Training loss: 3.197045339034357
Validation loss: 2.67010038813851

Epoch: 313| Step: 0
Training loss: 3.4688650576093085
Validation loss: 2.6690366798462666

Epoch: 6| Step: 1
Training loss: 2.790390766903274
Validation loss: 2.668839259560687

Epoch: 6| Step: 2
Training loss: 2.6708491625939144
Validation loss: 2.6715447188662957

Epoch: 6| Step: 3
Training loss: 3.1907832869554094
Validation loss: 2.6696298441349686

Epoch: 6| Step: 4
Training loss: 2.620846323083204
Validation loss: 2.67457384773312

Epoch: 6| Step: 5
Training loss: 2.7416932619731593
Validation loss: 2.6790366797022913

Epoch: 6| Step: 6
Training loss: 3.159595340701081
Validation loss: 2.683450499699921

Epoch: 6| Step: 7
Training loss: 3.4412571574897757
Validation loss: 2.6898101584667193

Epoch: 6| Step: 8
Training loss: 2.987218011931112
Validation loss: 2.6956201359649623

Epoch: 6| Step: 9
Training loss: 3.1898292557991788
Validation loss: 2.6901121368225014

Epoch: 6| Step: 10
Training loss: 3.347263379896989
Validation loss: 2.6883560347399764

Epoch: 6| Step: 11
Training loss: 2.043713406576425
Validation loss: 2.6833449359699766

Epoch: 6| Step: 12
Training loss: 2.586312995685482
Validation loss: 2.6733443043742247

Epoch: 6| Step: 13
Training loss: 3.709451671087558
Validation loss: 2.6654400625777552

Epoch: 314| Step: 0
Training loss: 2.7671795802377317
Validation loss: 2.6626689122639067

Epoch: 6| Step: 1
Training loss: 2.44397228430034
Validation loss: 2.6580882641847685

Epoch: 6| Step: 2
Training loss: 2.67841435653093
Validation loss: 2.6565929290402845

Epoch: 6| Step: 3
Training loss: 2.845891125503183
Validation loss: 2.655501395412484

Epoch: 6| Step: 4
Training loss: 3.7684950911571047
Validation loss: 2.6522824956946187

Epoch: 6| Step: 5
Training loss: 2.564606800689879
Validation loss: 2.6585923379400347

Epoch: 6| Step: 6
Training loss: 3.756841395279698
Validation loss: 2.6587925959934644

Epoch: 6| Step: 7
Training loss: 3.2664112075516223
Validation loss: 2.6589273672862674

Epoch: 6| Step: 8
Training loss: 3.1450137319098252
Validation loss: 2.659873562979139

Epoch: 6| Step: 9
Training loss: 2.87179702138209
Validation loss: 2.66075676649816

Epoch: 6| Step: 10
Training loss: 2.796553779781982
Validation loss: 2.660644927747176

Epoch: 6| Step: 11
Training loss: 3.0955105790869553
Validation loss: 2.660791277900916

Epoch: 6| Step: 12
Training loss: 2.575527848149625
Validation loss: 2.659201805147461

Epoch: 6| Step: 13
Training loss: 2.645951356032686
Validation loss: 2.6625313050600337

Epoch: 315| Step: 0
Training loss: 3.136451491280125
Validation loss: 2.67106073898012

Epoch: 6| Step: 1
Training loss: 2.8308220748370543
Validation loss: 2.680242269536677

Epoch: 6| Step: 2
Training loss: 3.1112651351615748
Validation loss: 2.6740416544280996

Epoch: 6| Step: 3
Training loss: 2.8600079612354365
Validation loss: 2.6836778199752884

Epoch: 6| Step: 4
Training loss: 2.526196368222453
Validation loss: 2.705999831258917

Epoch: 6| Step: 5
Training loss: 2.6672390879741155
Validation loss: 2.6964345619103374

Epoch: 6| Step: 6
Training loss: 3.2439401324635773
Validation loss: 2.7072110642485447

Epoch: 6| Step: 7
Training loss: 3.0943772421874765
Validation loss: 2.687720823647575

Epoch: 6| Step: 8
Training loss: 3.2077843993266564
Validation loss: 2.6887277010610378

Epoch: 6| Step: 9
Training loss: 2.2603521616180187
Validation loss: 2.666465857146228

Epoch: 6| Step: 10
Training loss: 3.161973353023313
Validation loss: 2.6633334186004687

Epoch: 6| Step: 11
Training loss: 3.033076728894173
Validation loss: 2.655997889870323

Epoch: 6| Step: 12
Training loss: 3.1413433714718666
Validation loss: 2.654861248336449

Epoch: 6| Step: 13
Training loss: 3.6183971911652026
Validation loss: 2.6539022379025425

Epoch: 316| Step: 0
Training loss: 2.7626763265961265
Validation loss: 2.654223173205829

Epoch: 6| Step: 1
Training loss: 3.7043917135238438
Validation loss: 2.652108705857759

Epoch: 6| Step: 2
Training loss: 2.5834172348015767
Validation loss: 2.6562358993358686

Epoch: 6| Step: 3
Training loss: 2.50118094208346
Validation loss: 2.6522855964783267

Epoch: 6| Step: 4
Training loss: 2.518702454981965
Validation loss: 2.655855413730876

Epoch: 6| Step: 5
Training loss: 2.400713607872952
Validation loss: 2.652918935788853

Epoch: 6| Step: 6
Training loss: 3.416835749714543
Validation loss: 2.656060069060014

Epoch: 6| Step: 7
Training loss: 3.3712592410313476
Validation loss: 2.65172705765762

Epoch: 6| Step: 8
Training loss: 2.6970387998059446
Validation loss: 2.6531349036520115

Epoch: 6| Step: 9
Training loss: 2.4505959856358315
Validation loss: 2.653765076463683

Epoch: 6| Step: 10
Training loss: 3.511593554411136
Validation loss: 2.6518166864548114

Epoch: 6| Step: 11
Training loss: 2.9155657370739743
Validation loss: 2.6498703602358673

Epoch: 6| Step: 12
Training loss: 3.3037460104275596
Validation loss: 2.64931394136424

Epoch: 6| Step: 13
Training loss: 3.508789198397924
Validation loss: 2.650034936329056

Epoch: 317| Step: 0
Training loss: 2.8823559407267814
Validation loss: 2.650534626159212

Epoch: 6| Step: 1
Training loss: 2.6539901994123225
Validation loss: 2.6494064163121807

Epoch: 6| Step: 2
Training loss: 3.4065476033803903
Validation loss: 2.6501031776970425

Epoch: 6| Step: 3
Training loss: 2.3651134104080076
Validation loss: 2.65564951952752

Epoch: 6| Step: 4
Training loss: 3.0196839524676298
Validation loss: 2.6619506092337315

Epoch: 6| Step: 5
Training loss: 3.2867710712349636
Validation loss: 2.669610029269135

Epoch: 6| Step: 6
Training loss: 2.883267994693458
Validation loss: 2.6779771250203246

Epoch: 6| Step: 7
Training loss: 2.5620543860053724
Validation loss: 2.68726606750757

Epoch: 6| Step: 8
Training loss: 3.0382720782336974
Validation loss: 2.669212503383665

Epoch: 6| Step: 9
Training loss: 3.397039717933078
Validation loss: 2.6612127878846357

Epoch: 6| Step: 10
Training loss: 2.829307856756352
Validation loss: 2.6551230610306846

Epoch: 6| Step: 11
Training loss: 3.6941859522157707
Validation loss: 2.6477044985062363

Epoch: 6| Step: 12
Training loss: 2.86410598014297
Validation loss: 2.648927631206461

Epoch: 6| Step: 13
Training loss: 2.1432001815696147
Validation loss: 2.6500380803733132

Epoch: 318| Step: 0
Training loss: 2.4856289751857004
Validation loss: 2.650724232486156

Epoch: 6| Step: 1
Training loss: 2.6363787396515543
Validation loss: 2.6459965166640966

Epoch: 6| Step: 2
Training loss: 2.9392775980607744
Validation loss: 2.6504484873660163

Epoch: 6| Step: 3
Training loss: 2.554016025035892
Validation loss: 2.6518821693439447

Epoch: 6| Step: 4
Training loss: 3.6798791531747637
Validation loss: 2.6458868590245586

Epoch: 6| Step: 5
Training loss: 3.4581572859356786
Validation loss: 2.6457094310933287

Epoch: 6| Step: 6
Training loss: 3.093446967186272
Validation loss: 2.6519812277986032

Epoch: 6| Step: 7
Training loss: 3.1396060638178658
Validation loss: 2.651355160045506

Epoch: 6| Step: 8
Training loss: 2.82327191321691
Validation loss: 2.650811601194016

Epoch: 6| Step: 9
Training loss: 2.7872015891695803
Validation loss: 2.6547731119306004

Epoch: 6| Step: 10
Training loss: 3.326777082253165
Validation loss: 2.6475602659517676

Epoch: 6| Step: 11
Training loss: 2.9494729039909746
Validation loss: 2.6535419323533596

Epoch: 6| Step: 12
Training loss: 2.9517622129404604
Validation loss: 2.6496705569631867

Epoch: 6| Step: 13
Training loss: 2.25947388238705
Validation loss: 2.647439486759549

Epoch: 319| Step: 0
Training loss: 2.5040275556248606
Validation loss: 2.6568626165453977

Epoch: 6| Step: 1
Training loss: 2.652426267528523
Validation loss: 2.651114672022209

Epoch: 6| Step: 2
Training loss: 2.324968694660714
Validation loss: 2.656791213971652

Epoch: 6| Step: 3
Training loss: 3.64652935831922
Validation loss: 2.651884006120698

Epoch: 6| Step: 4
Training loss: 3.3373603020052225
Validation loss: 2.6502197204719398

Epoch: 6| Step: 5
Training loss: 3.1748495952395253
Validation loss: 2.6524358090623044

Epoch: 6| Step: 6
Training loss: 2.693532339272636
Validation loss: 2.6528617660758482

Epoch: 6| Step: 7
Training loss: 3.1575979243880323
Validation loss: 2.651598899939962

Epoch: 6| Step: 8
Training loss: 3.2351886997285897
Validation loss: 2.6490170305183924

Epoch: 6| Step: 9
Training loss: 2.504865299037216
Validation loss: 2.648740153350009

Epoch: 6| Step: 10
Training loss: 2.6898749747168833
Validation loss: 2.6552630352875877

Epoch: 6| Step: 11
Training loss: 3.764119840686376
Validation loss: 2.6552571785942813

Epoch: 6| Step: 12
Training loss: 2.864679138431058
Validation loss: 2.6583198006452298

Epoch: 6| Step: 13
Training loss: 2.457209885354691
Validation loss: 2.6519157918242713

Epoch: 320| Step: 0
Training loss: 3.054911807671201
Validation loss: 2.648029258782254

Epoch: 6| Step: 1
Training loss: 3.178184810289435
Validation loss: 2.649124701512447

Epoch: 6| Step: 2
Training loss: 3.54650998022788
Validation loss: 2.644759979683114

Epoch: 6| Step: 3
Training loss: 3.1259545966308844
Validation loss: 2.648751183192939

Epoch: 6| Step: 4
Training loss: 3.4288767071327144
Validation loss: 2.649979515406693

Epoch: 6| Step: 5
Training loss: 3.043489267199026
Validation loss: 2.6464306495679364

Epoch: 6| Step: 6
Training loss: 2.102917996290177
Validation loss: 2.648268812095442

Epoch: 6| Step: 7
Training loss: 2.5457774412655447
Validation loss: 2.64514880974019

Epoch: 6| Step: 8
Training loss: 2.9329522824598637
Validation loss: 2.646798248985568

Epoch: 6| Step: 9
Training loss: 2.8639486453604084
Validation loss: 2.6527293452336274

Epoch: 6| Step: 10
Training loss: 2.9973208862444456
Validation loss: 2.652171822986661

Epoch: 6| Step: 11
Training loss: 2.9742884321895287
Validation loss: 2.6480639767197003

Epoch: 6| Step: 12
Training loss: 2.594842152287512
Validation loss: 2.64598558094613

Epoch: 6| Step: 13
Training loss: 3.0246532272949476
Validation loss: 2.6538964013899795

Epoch: 321| Step: 0
Training loss: 3.295248923269469
Validation loss: 2.650161748637067

Epoch: 6| Step: 1
Training loss: 3.1316830699166913
Validation loss: 2.6528925940012904

Epoch: 6| Step: 2
Training loss: 3.2727804685373045
Validation loss: 2.6582781466524223

Epoch: 6| Step: 3
Training loss: 3.0834159496339497
Validation loss: 2.656004950495783

Epoch: 6| Step: 4
Training loss: 2.5497240852230663
Validation loss: 2.6451066275307666

Epoch: 6| Step: 5
Training loss: 2.608334545179904
Validation loss: 2.6530065549701276

Epoch: 6| Step: 6
Training loss: 2.5636534537182905
Validation loss: 2.6566132945483014

Epoch: 6| Step: 7
Training loss: 2.679329717568018
Validation loss: 2.6616033416603386

Epoch: 6| Step: 8
Training loss: 2.7031577224073873
Validation loss: 2.6531726419654427

Epoch: 6| Step: 9
Training loss: 3.2214265823962283
Validation loss: 2.6501795865574307

Epoch: 6| Step: 10
Training loss: 3.0048772584345
Validation loss: 2.6628682966914066

Epoch: 6| Step: 11
Training loss: 3.539584965487518
Validation loss: 2.666987121718764

Epoch: 6| Step: 12
Training loss: 3.077647215655687
Validation loss: 2.6655515683767863

Epoch: 6| Step: 13
Training loss: 2.4299820601817568
Validation loss: 2.660726188668674

Epoch: 322| Step: 0
Training loss: 3.1133388384730196
Validation loss: 2.659912196479013

Epoch: 6| Step: 1
Training loss: 2.5550118803281845
Validation loss: 2.6469554490192087

Epoch: 6| Step: 2
Training loss: 2.969785971331122
Validation loss: 2.6477921053109217

Epoch: 6| Step: 3
Training loss: 3.0798855311933115
Validation loss: 2.646197305542447

Epoch: 6| Step: 4
Training loss: 3.526654519370876
Validation loss: 2.64142282569828

Epoch: 6| Step: 5
Training loss: 2.7661621089440445
Validation loss: 2.6461239526684976

Epoch: 6| Step: 6
Training loss: 3.005422460022552
Validation loss: 2.6470423397178573

Epoch: 6| Step: 7
Training loss: 2.6135449925007848
Validation loss: 2.6459533383846154

Epoch: 6| Step: 8
Training loss: 2.8596478107988474
Validation loss: 2.6452686739843605

Epoch: 6| Step: 9
Training loss: 3.2206548591175705
Validation loss: 2.6429923684914858

Epoch: 6| Step: 10
Training loss: 3.387519504167213
Validation loss: 2.6426911503266584

Epoch: 6| Step: 11
Training loss: 2.567093430581647
Validation loss: 2.6413042525278247

Epoch: 6| Step: 12
Training loss: 3.0454602209113353
Validation loss: 2.644166262478254

Epoch: 6| Step: 13
Training loss: 2.5304379514614244
Validation loss: 2.645240650129539

Epoch: 323| Step: 0
Training loss: 2.875559876700916
Validation loss: 2.647139483543351

Epoch: 6| Step: 1
Training loss: 2.8403534779387356
Validation loss: 2.649041285640331

Epoch: 6| Step: 2
Training loss: 3.038255285229116
Validation loss: 2.6567898244595742

Epoch: 6| Step: 3
Training loss: 3.1714260742000926
Validation loss: 2.6487977149581767

Epoch: 6| Step: 4
Training loss: 3.537267638214608
Validation loss: 2.6428115082344963

Epoch: 6| Step: 5
Training loss: 3.0539879351504378
Validation loss: 2.6453061465585797

Epoch: 6| Step: 6
Training loss: 2.239444556852831
Validation loss: 2.6440995074288387

Epoch: 6| Step: 7
Training loss: 2.905133761085676
Validation loss: 2.6423488057511424

Epoch: 6| Step: 8
Training loss: 3.097557268329129
Validation loss: 2.6431946803983815

Epoch: 6| Step: 9
Training loss: 3.179281222844734
Validation loss: 2.6386184704588103

Epoch: 6| Step: 10
Training loss: 3.2093247867507935
Validation loss: 2.6403093425430315

Epoch: 6| Step: 11
Training loss: 3.009258447848045
Validation loss: 2.641922384161971

Epoch: 6| Step: 12
Training loss: 2.8469594094987545
Validation loss: 2.641119552234581

Epoch: 6| Step: 13
Training loss: 1.743090613604912
Validation loss: 2.6446689378349744

Epoch: 324| Step: 0
Training loss: 2.9662852445711696
Validation loss: 2.650736165121992

Epoch: 6| Step: 1
Training loss: 2.9163299002822494
Validation loss: 2.652000065596966

Epoch: 6| Step: 2
Training loss: 3.2040877221298913
Validation loss: 2.6690453321205454

Epoch: 6| Step: 3
Training loss: 2.534711096287758
Validation loss: 2.675402727652585

Epoch: 6| Step: 4
Training loss: 3.4164515326774763
Validation loss: 2.6968042070274776

Epoch: 6| Step: 5
Training loss: 3.1961692650078866
Validation loss: 2.6903798117041133

Epoch: 6| Step: 6
Training loss: 2.5580295552208345
Validation loss: 2.677067428419683

Epoch: 6| Step: 7
Training loss: 3.018143782945281
Validation loss: 2.659254062685266

Epoch: 6| Step: 8
Training loss: 3.9064894946113435
Validation loss: 2.658569259607656

Epoch: 6| Step: 9
Training loss: 2.504523381254113
Validation loss: 2.649063507290741

Epoch: 6| Step: 10
Training loss: 2.4010417107991002
Validation loss: 2.6419222618954237

Epoch: 6| Step: 11
Training loss: 2.754427207207903
Validation loss: 2.6402647215969095

Epoch: 6| Step: 12
Training loss: 3.1865536650037343
Validation loss: 2.6377207301464405

Epoch: 6| Step: 13
Training loss: 2.6718139641466037
Validation loss: 2.640598628774134

Epoch: 325| Step: 0
Training loss: 2.5993909049000403
Validation loss: 2.6423695022495552

Epoch: 6| Step: 1
Training loss: 2.3757280940262513
Validation loss: 2.642204670887173

Epoch: 6| Step: 2
Training loss: 2.7684063045829523
Validation loss: 2.6424354714989473

Epoch: 6| Step: 3
Training loss: 3.1384910811534086
Validation loss: 2.6407331102442098

Epoch: 6| Step: 4
Training loss: 3.403559050539634
Validation loss: 2.6403304235052345

Epoch: 6| Step: 5
Training loss: 2.9318045736135496
Validation loss: 2.64564037870952

Epoch: 6| Step: 6
Training loss: 3.334195327565684
Validation loss: 2.6376879394706174

Epoch: 6| Step: 7
Training loss: 3.0211128544012253
Validation loss: 2.643626096536137

Epoch: 6| Step: 8
Training loss: 2.9135797422883165
Validation loss: 2.6459950798216556

Epoch: 6| Step: 9
Training loss: 3.1199438772289008
Validation loss: 2.647719934307287

Epoch: 6| Step: 10
Training loss: 3.1702831765177577
Validation loss: 2.645734348307492

Epoch: 6| Step: 11
Training loss: 2.983037359235831
Validation loss: 2.6528404348667363

Epoch: 6| Step: 12
Training loss: 2.932704501228912
Validation loss: 2.6487232290913907

Epoch: 6| Step: 13
Training loss: 2.463520063395605
Validation loss: 2.6503323754219488

Epoch: 326| Step: 0
Training loss: 3.2229471341258638
Validation loss: 2.6442299288842945

Epoch: 6| Step: 1
Training loss: 2.6527712313142415
Validation loss: 2.6488507942604858

Epoch: 6| Step: 2
Training loss: 3.0410937113649936
Validation loss: 2.655822066038599

Epoch: 6| Step: 3
Training loss: 2.022933131215449
Validation loss: 2.6523479284213445

Epoch: 6| Step: 4
Training loss: 3.0769527158776864
Validation loss: 2.6622976562542733

Epoch: 6| Step: 5
Training loss: 3.4202884148681596
Validation loss: 2.6713891308709345

Epoch: 6| Step: 6
Training loss: 3.101754516499886
Validation loss: 2.65538930152696

Epoch: 6| Step: 7
Training loss: 2.8087376330875435
Validation loss: 2.6627860892739816

Epoch: 6| Step: 8
Training loss: 3.0232018667263256
Validation loss: 2.644440935116818

Epoch: 6| Step: 9
Training loss: 3.1656631753621154
Validation loss: 2.6490793358206526

Epoch: 6| Step: 10
Training loss: 2.534032916631274
Validation loss: 2.6510029801305364

Epoch: 6| Step: 11
Training loss: 3.1830489552550545
Validation loss: 2.6427520090111853

Epoch: 6| Step: 12
Training loss: 2.9819034907831483
Validation loss: 2.6434667162392205

Epoch: 6| Step: 13
Training loss: 3.111166892989696
Validation loss: 2.6402897766107274

Epoch: 327| Step: 0
Training loss: 2.2947710223026183
Validation loss: 2.6405161435725124

Epoch: 6| Step: 1
Training loss: 3.188410909306847
Validation loss: 2.6413515958590987

Epoch: 6| Step: 2
Training loss: 2.4919805650090967
Validation loss: 2.6439945134735883

Epoch: 6| Step: 3
Training loss: 2.928868375071863
Validation loss: 2.645826807870748

Epoch: 6| Step: 4
Training loss: 2.507874485093582
Validation loss: 2.6409084621552714

Epoch: 6| Step: 5
Training loss: 3.287241524517956
Validation loss: 2.661732149380117

Epoch: 6| Step: 6
Training loss: 3.109915068224112
Validation loss: 2.654082309549593

Epoch: 6| Step: 7
Training loss: 2.855176501054331
Validation loss: 2.663629595022784

Epoch: 6| Step: 8
Training loss: 2.3301016589732524
Validation loss: 2.663358126654582

Epoch: 6| Step: 9
Training loss: 3.5310279978957726
Validation loss: 2.6576679091127855

Epoch: 6| Step: 10
Training loss: 3.1183984837402603
Validation loss: 2.650834589426619

Epoch: 6| Step: 11
Training loss: 3.269166039563956
Validation loss: 2.649907143734997

Epoch: 6| Step: 12
Training loss: 3.3653437618249202
Validation loss: 2.640445940772162

Epoch: 6| Step: 13
Training loss: 2.92157976423486
Validation loss: 2.638887086280102

Epoch: 328| Step: 0
Training loss: 3.232349885905316
Validation loss: 2.6353247050636064

Epoch: 6| Step: 1
Training loss: 2.443076479457563
Validation loss: 2.639936457978945

Epoch: 6| Step: 2
Training loss: 2.477229561004106
Validation loss: 2.6414733473473566

Epoch: 6| Step: 3
Training loss: 2.7221243077356214
Validation loss: 2.6373429459307767

Epoch: 6| Step: 4
Training loss: 2.7221707276471445
Validation loss: 2.6383303226169286

Epoch: 6| Step: 5
Training loss: 2.9653287749678525
Validation loss: 2.636905082702908

Epoch: 6| Step: 6
Training loss: 3.046187416156962
Validation loss: 2.649794496828571

Epoch: 6| Step: 7
Training loss: 3.0970370622683023
Validation loss: 2.6505485056786253

Epoch: 6| Step: 8
Training loss: 2.9928428788728
Validation loss: 2.658708669626636

Epoch: 6| Step: 9
Training loss: 2.7736330635001383
Validation loss: 2.6640239035919016

Epoch: 6| Step: 10
Training loss: 3.0121943275207275
Validation loss: 2.684433075445677

Epoch: 6| Step: 11
Training loss: 3.5530564810689422
Validation loss: 2.6940193849184344

Epoch: 6| Step: 12
Training loss: 3.5411098865349584
Validation loss: 2.6902251986746903

Epoch: 6| Step: 13
Training loss: 2.6941809891393693
Validation loss: 2.668471308955405

Epoch: 329| Step: 0
Training loss: 2.6852796386924163
Validation loss: 2.6609501773886133

Epoch: 6| Step: 1
Training loss: 3.0029077743102905
Validation loss: 2.6505117581625375

Epoch: 6| Step: 2
Training loss: 2.4743378572309145
Validation loss: 2.643665506639928

Epoch: 6| Step: 3
Training loss: 2.6820051219188645
Validation loss: 2.6427769434385575

Epoch: 6| Step: 4
Training loss: 2.8948541170302033
Validation loss: 2.6376336528905298

Epoch: 6| Step: 5
Training loss: 3.4143672431747363
Validation loss: 2.6383454347908866

Epoch: 6| Step: 6
Training loss: 3.704101305035583
Validation loss: 2.6302924773943546

Epoch: 6| Step: 7
Training loss: 3.0334540150987537
Validation loss: 2.6333681259515203

Epoch: 6| Step: 8
Training loss: 3.274914974827009
Validation loss: 2.630919006759815

Epoch: 6| Step: 9
Training loss: 2.8297448340452296
Validation loss: 2.635737527555184

Epoch: 6| Step: 10
Training loss: 2.1660804566844516
Validation loss: 2.638014162210632

Epoch: 6| Step: 11
Training loss: 2.75097084247941
Validation loss: 2.6367456140824586

Epoch: 6| Step: 12
Training loss: 3.0908062734179578
Validation loss: 2.63465561473623

Epoch: 6| Step: 13
Training loss: 3.3917848914783844
Validation loss: 2.634840932579698

Epoch: 330| Step: 0
Training loss: 2.3799003440765323
Validation loss: 2.635448946048463

Epoch: 6| Step: 1
Training loss: 2.966163070311573
Validation loss: 2.638218016119928

Epoch: 6| Step: 2
Training loss: 2.4639796270296133
Validation loss: 2.64212336330877

Epoch: 6| Step: 3
Training loss: 3.0882911687759704
Validation loss: 2.6453494778612505

Epoch: 6| Step: 4
Training loss: 3.218939914470855
Validation loss: 2.6437377737792356

Epoch: 6| Step: 5
Training loss: 3.7205841926529684
Validation loss: 2.6507462959244057

Epoch: 6| Step: 6
Training loss: 2.5639273227204837
Validation loss: 2.6470740799320454

Epoch: 6| Step: 7
Training loss: 2.368586463617557
Validation loss: 2.64985895290355

Epoch: 6| Step: 8
Training loss: 3.0203883051548215
Validation loss: 2.6499490279877302

Epoch: 6| Step: 9
Training loss: 3.041643081643275
Validation loss: 2.655826033380868

Epoch: 6| Step: 10
Training loss: 2.7139884205109426
Validation loss: 2.657794015766626

Epoch: 6| Step: 11
Training loss: 3.506378900399109
Validation loss: 2.6459198290738013

Epoch: 6| Step: 12
Training loss: 2.8922827014061947
Validation loss: 2.63552366894956

Epoch: 6| Step: 13
Training loss: 3.3895553096901563
Validation loss: 2.629513219802588

Epoch: 331| Step: 0
Training loss: 2.429178558721818
Validation loss: 2.633803150961314

Epoch: 6| Step: 1
Training loss: 3.2667414020890235
Validation loss: 2.635118556076909

Epoch: 6| Step: 2
Training loss: 2.5825830005701627
Validation loss: 2.6353682092383797

Epoch: 6| Step: 3
Training loss: 2.4829779001482297
Validation loss: 2.6415154352049592

Epoch: 6| Step: 4
Training loss: 3.199460347686537
Validation loss: 2.6403721989764355

Epoch: 6| Step: 5
Training loss: 3.4264273126725335
Validation loss: 2.637201406161722

Epoch: 6| Step: 6
Training loss: 3.2321766924573674
Validation loss: 2.6383697904483765

Epoch: 6| Step: 7
Training loss: 2.786350074637758
Validation loss: 2.634861691943365

Epoch: 6| Step: 8
Training loss: 3.0255710850895863
Validation loss: 2.638425037424622

Epoch: 6| Step: 9
Training loss: 3.220173641285404
Validation loss: 2.63489091395381

Epoch: 6| Step: 10
Training loss: 3.14822606590768
Validation loss: 2.6358573733481196

Epoch: 6| Step: 11
Training loss: 2.940226973251528
Validation loss: 2.638948517452938

Epoch: 6| Step: 12
Training loss: 2.9451008930637177
Validation loss: 2.6395416911348413

Epoch: 6| Step: 13
Training loss: 2.6068578217150082
Validation loss: 2.6389528394879345

Epoch: 332| Step: 0
Training loss: 2.593692089491413
Validation loss: 2.6375577922928475

Epoch: 6| Step: 1
Training loss: 3.266752933478985
Validation loss: 2.640353726795233

Epoch: 6| Step: 2
Training loss: 2.332122954285959
Validation loss: 2.6406236281940227

Epoch: 6| Step: 3
Training loss: 3.037651617088727
Validation loss: 2.638664190883039

Epoch: 6| Step: 4
Training loss: 2.9070095587364277
Validation loss: 2.638524211482845

Epoch: 6| Step: 5
Training loss: 3.0619375529832644
Validation loss: 2.649927759917552

Epoch: 6| Step: 6
Training loss: 3.1432432581541696
Validation loss: 2.667872625992834

Epoch: 6| Step: 7
Training loss: 2.8115617670624498
Validation loss: 2.660798697712147

Epoch: 6| Step: 8
Training loss: 3.642796601398793
Validation loss: 2.6532721682017333

Epoch: 6| Step: 9
Training loss: 2.4494340671154036
Validation loss: 2.6725030743855327

Epoch: 6| Step: 10
Training loss: 2.8120603429687563
Validation loss: 2.6553760314092556

Epoch: 6| Step: 11
Training loss: 3.483955392247567
Validation loss: 2.647542030806253

Epoch: 6| Step: 12
Training loss: 3.0668697711471657
Validation loss: 2.6382429428691614

Epoch: 6| Step: 13
Training loss: 2.1519418330786966
Validation loss: 2.637073809235938

Epoch: 333| Step: 0
Training loss: 2.8201127338195926
Validation loss: 2.6404382763817518

Epoch: 6| Step: 1
Training loss: 3.117018769174362
Validation loss: 2.631282055460073

Epoch: 6| Step: 2
Training loss: 2.2331960275299365
Validation loss: 2.6365802677785593

Epoch: 6| Step: 3
Training loss: 2.5537415599263404
Validation loss: 2.6379212266699543

Epoch: 6| Step: 4
Training loss: 2.9860507594276453
Validation loss: 2.6309623645422002

Epoch: 6| Step: 5
Training loss: 3.1333229619388865
Validation loss: 2.6384330438551573

Epoch: 6| Step: 6
Training loss: 3.4168555664938887
Validation loss: 2.6358954932424354

Epoch: 6| Step: 7
Training loss: 3.256235157059651
Validation loss: 2.644947472144624

Epoch: 6| Step: 8
Training loss: 3.037304838213777
Validation loss: 2.6379782323174523

Epoch: 6| Step: 9
Training loss: 3.167809497673401
Validation loss: 2.637952901701314

Epoch: 6| Step: 10
Training loss: 3.058097009770454
Validation loss: 2.6336703792604377

Epoch: 6| Step: 11
Training loss: 2.8600324698252275
Validation loss: 2.6284052652079666

Epoch: 6| Step: 12
Training loss: 2.5886361138800926
Validation loss: 2.6304098374748177

Epoch: 6| Step: 13
Training loss: 3.0506899694250778
Validation loss: 2.639353681591505

Epoch: 334| Step: 0
Training loss: 2.7883738460968472
Validation loss: 2.6457544689199075

Epoch: 6| Step: 1
Training loss: 2.913139135608371
Validation loss: 2.6352617856335523

Epoch: 6| Step: 2
Training loss: 2.906365505097174
Validation loss: 2.6393607780005364

Epoch: 6| Step: 3
Training loss: 2.8644419317314203
Validation loss: 2.651850325233172

Epoch: 6| Step: 4
Training loss: 3.134738853078826
Validation loss: 2.6574067021570205

Epoch: 6| Step: 5
Training loss: 2.9259846391255095
Validation loss: 2.6366538910235864

Epoch: 6| Step: 6
Training loss: 2.4342333104788807
Validation loss: 2.6425434465552695

Epoch: 6| Step: 7
Training loss: 3.007281685101168
Validation loss: 2.6412187309159956

Epoch: 6| Step: 8
Training loss: 2.6779041639904393
Validation loss: 2.6315021566619268

Epoch: 6| Step: 9
Training loss: 3.364879693520658
Validation loss: 2.6400788503240413

Epoch: 6| Step: 10
Training loss: 2.8854108642813574
Validation loss: 2.6270279109709107

Epoch: 6| Step: 11
Training loss: 2.874042849227258
Validation loss: 2.6264955808273456

Epoch: 6| Step: 12
Training loss: 3.299168950255367
Validation loss: 2.630714952689596

Epoch: 6| Step: 13
Training loss: 3.336687847861616
Validation loss: 2.625204369382373

Epoch: 335| Step: 0
Training loss: 2.8998730335723053
Validation loss: 2.626865413647177

Epoch: 6| Step: 1
Training loss: 3.1417953815620283
Validation loss: 2.6294232187930273

Epoch: 6| Step: 2
Training loss: 3.0566240889129386
Validation loss: 2.6358899047451887

Epoch: 6| Step: 3
Training loss: 3.218312502266312
Validation loss: 2.6294581882443446

Epoch: 6| Step: 4
Training loss: 2.9598915044128744
Validation loss: 2.6345910328935656

Epoch: 6| Step: 5
Training loss: 2.7569044309371336
Validation loss: 2.640843320683927

Epoch: 6| Step: 6
Training loss: 2.938356964425974
Validation loss: 2.629503981171972

Epoch: 6| Step: 7
Training loss: 3.0684140769312354
Validation loss: 2.6376161704183607

Epoch: 6| Step: 8
Training loss: 2.699264503897221
Validation loss: 2.63664492340828

Epoch: 6| Step: 9
Training loss: 2.539758956465318
Validation loss: 2.6396708877869703

Epoch: 6| Step: 10
Training loss: 3.2466830419901607
Validation loss: 2.633193738128616

Epoch: 6| Step: 11
Training loss: 2.8000706152867005
Validation loss: 2.629157379403369

Epoch: 6| Step: 12
Training loss: 2.7965782476943666
Validation loss: 2.6379948163776974

Epoch: 6| Step: 13
Training loss: 3.318137068820833
Validation loss: 2.62945295752961

Epoch: 336| Step: 0
Training loss: 2.789182687087865
Validation loss: 2.6402387895431545

Epoch: 6| Step: 1
Training loss: 3.323757691017598
Validation loss: 2.626555441474374

Epoch: 6| Step: 2
Training loss: 3.1776488420994995
Validation loss: 2.626988103910991

Epoch: 6| Step: 3
Training loss: 2.9876780181581726
Validation loss: 2.623409550215776

Epoch: 6| Step: 4
Training loss: 3.0046050966481768
Validation loss: 2.628067353518812

Epoch: 6| Step: 5
Training loss: 2.5357190464059514
Validation loss: 2.6229548517667007

Epoch: 6| Step: 6
Training loss: 2.668046941770326
Validation loss: 2.624213732321437

Epoch: 6| Step: 7
Training loss: 2.5094076532160994
Validation loss: 2.6293973211903072

Epoch: 6| Step: 8
Training loss: 2.737752169486552
Validation loss: 2.6240339801613684

Epoch: 6| Step: 9
Training loss: 2.9646716564225977
Validation loss: 2.6295375973082176

Epoch: 6| Step: 10
Training loss: 2.8805776477711666
Validation loss: 2.6306028288128154

Epoch: 6| Step: 11
Training loss: 3.3714852575381187
Validation loss: 2.6423384399772467

Epoch: 6| Step: 12
Training loss: 3.0860028610067896
Validation loss: 2.6424123578061893

Epoch: 6| Step: 13
Training loss: 3.329097695207126
Validation loss: 2.6440469804302973

Epoch: 337| Step: 0
Training loss: 2.8695386346960348
Validation loss: 2.6336950210149985

Epoch: 6| Step: 1
Training loss: 3.454274948380101
Validation loss: 2.6497086977614326

Epoch: 6| Step: 2
Training loss: 2.9363332825757884
Validation loss: 2.6323741675635675

Epoch: 6| Step: 3
Training loss: 2.8606137786838506
Validation loss: 2.634197070776945

Epoch: 6| Step: 4
Training loss: 3.67003049583134
Validation loss: 2.637090873391793

Epoch: 6| Step: 5
Training loss: 2.9760427747133993
Validation loss: 2.6321775485576864

Epoch: 6| Step: 6
Training loss: 2.781231826551404
Validation loss: 2.635055255212868

Epoch: 6| Step: 7
Training loss: 2.1481075519011874
Validation loss: 2.6323012777689065

Epoch: 6| Step: 8
Training loss: 2.6291912768905377
Validation loss: 2.6299352899915336

Epoch: 6| Step: 9
Training loss: 2.9151828442869583
Validation loss: 2.632177781334569

Epoch: 6| Step: 10
Training loss: 3.0743916910039872
Validation loss: 2.6367156114639325

Epoch: 6| Step: 11
Training loss: 2.6770072856942155
Validation loss: 2.6312007348081417

Epoch: 6| Step: 12
Training loss: 2.643993869653194
Validation loss: 2.6358569269236796

Epoch: 6| Step: 13
Training loss: 3.695004730634539
Validation loss: 2.639114402161971

Epoch: 338| Step: 0
Training loss: 2.9539335244046305
Validation loss: 2.6388779747015296

Epoch: 6| Step: 1
Training loss: 2.4350782247899034
Validation loss: 2.646948252873984

Epoch: 6| Step: 2
Training loss: 3.0373442433300566
Validation loss: 2.662072583873177

Epoch: 6| Step: 3
Training loss: 3.5432026542999875
Validation loss: 2.6661259124696715

Epoch: 6| Step: 4
Training loss: 2.8850327292557623
Validation loss: 2.6588149463416078

Epoch: 6| Step: 5
Training loss: 2.868963123125752
Validation loss: 2.6386063168811247

Epoch: 6| Step: 6
Training loss: 2.7394999405578395
Validation loss: 2.6323773755524664

Epoch: 6| Step: 7
Training loss: 2.5756653120648596
Validation loss: 2.626212131719039

Epoch: 6| Step: 8
Training loss: 3.7600433643356523
Validation loss: 2.622660693740197

Epoch: 6| Step: 9
Training loss: 2.4997742550971545
Validation loss: 2.623894702433755

Epoch: 6| Step: 10
Training loss: 2.3917211874176063
Validation loss: 2.624195111228603

Epoch: 6| Step: 11
Training loss: 3.4099660778875425
Validation loss: 2.6193282629781267

Epoch: 6| Step: 12
Training loss: 3.0223848940353166
Validation loss: 2.6255150761841146

Epoch: 6| Step: 13
Training loss: 2.9835125540777194
Validation loss: 2.621564770799074

Epoch: 339| Step: 0
Training loss: 2.843594892694338
Validation loss: 2.6225483056714594

Epoch: 6| Step: 1
Training loss: 2.991654231506969
Validation loss: 2.6259218053566236

Epoch: 6| Step: 2
Training loss: 3.029171260391243
Validation loss: 2.6332888012468705

Epoch: 6| Step: 3
Training loss: 2.6327234813458356
Validation loss: 2.6303520615785545

Epoch: 6| Step: 4
Training loss: 3.0639990427000776
Validation loss: 2.6406038257604036

Epoch: 6| Step: 5
Training loss: 2.784426043692263
Validation loss: 2.6471813960915114

Epoch: 6| Step: 6
Training loss: 2.7873008143673603
Validation loss: 2.650852215859843

Epoch: 6| Step: 7
Training loss: 3.139066091016099
Validation loss: 2.6575517527756554

Epoch: 6| Step: 8
Training loss: 3.0341080238760973
Validation loss: 2.6513352202061435

Epoch: 6| Step: 9
Training loss: 3.4670696140514976
Validation loss: 2.6550757324925573

Epoch: 6| Step: 10
Training loss: 2.7087940900072316
Validation loss: 2.6419245830181133

Epoch: 6| Step: 11
Training loss: 3.0227878079509605
Validation loss: 2.6385469278406406

Epoch: 6| Step: 12
Training loss: 2.8247527360309532
Validation loss: 2.6194694169335206

Epoch: 6| Step: 13
Training loss: 2.9407053564526384
Validation loss: 2.620388213518194

Epoch: 340| Step: 0
Training loss: 3.2964335503102937
Validation loss: 2.6159103791643337

Epoch: 6| Step: 1
Training loss: 2.982960630468462
Validation loss: 2.623926495005621

Epoch: 6| Step: 2
Training loss: 3.018410774584198
Validation loss: 2.6211015374652202

Epoch: 6| Step: 3
Training loss: 3.0113572671865434
Validation loss: 2.623928660091158

Epoch: 6| Step: 4
Training loss: 2.1827499042074487
Validation loss: 2.622318603507208

Epoch: 6| Step: 5
Training loss: 2.8182210590897103
Validation loss: 2.6204767061582284

Epoch: 6| Step: 6
Training loss: 3.2937404683100047
Validation loss: 2.6268150521725593

Epoch: 6| Step: 7
Training loss: 2.4606275575220966
Validation loss: 2.6225520408415117

Epoch: 6| Step: 8
Training loss: 2.8613352908933307
Validation loss: 2.6331806969114613

Epoch: 6| Step: 9
Training loss: 3.1819061861624807
Validation loss: 2.6415849690568862

Epoch: 6| Step: 10
Training loss: 3.8326263743328717
Validation loss: 2.640873342419416

Epoch: 6| Step: 11
Training loss: 2.450217206240616
Validation loss: 2.648533527911629

Epoch: 6| Step: 12
Training loss: 2.9571550915282687
Validation loss: 2.652550425600736

Epoch: 6| Step: 13
Training loss: 2.200184259501198
Validation loss: 2.6563955027078063

Epoch: 341| Step: 0
Training loss: 3.002000936153502
Validation loss: 2.6565040133952538

Epoch: 6| Step: 1
Training loss: 2.785715525839952
Validation loss: 2.653365180560859

Epoch: 6| Step: 2
Training loss: 3.224139987509478
Validation loss: 2.6504593824235525

Epoch: 6| Step: 3
Training loss: 2.8648269457255315
Validation loss: 2.6369810184646125

Epoch: 6| Step: 4
Training loss: 2.8469741485783358
Validation loss: 2.635155247797364

Epoch: 6| Step: 5
Training loss: 3.539813300990828
Validation loss: 2.642301082492934

Epoch: 6| Step: 6
Training loss: 3.1666747812535236
Validation loss: 2.6272625779735526

Epoch: 6| Step: 7
Training loss: 2.745931129469883
Validation loss: 2.6271851430097835

Epoch: 6| Step: 8
Training loss: 3.4511814084917134
Validation loss: 2.6310113769965757

Epoch: 6| Step: 9
Training loss: 2.4441582146112713
Validation loss: 2.6337587010937855

Epoch: 6| Step: 10
Training loss: 2.8212812878484086
Validation loss: 2.6398831343739118

Epoch: 6| Step: 11
Training loss: 2.6637465661616146
Validation loss: 2.6312561410776683

Epoch: 6| Step: 12
Training loss: 2.8965890753581833
Validation loss: 2.635000394855501

Epoch: 6| Step: 13
Training loss: 2.3885846375499753
Validation loss: 2.6317535887336443

Epoch: 342| Step: 0
Training loss: 3.2408862340652007
Validation loss: 2.62898085559214

Epoch: 6| Step: 1
Training loss: 3.468561253266774
Validation loss: 2.640044754701769

Epoch: 6| Step: 2
Training loss: 2.7840937103087535
Validation loss: 2.6240653060067283

Epoch: 6| Step: 3
Training loss: 3.2790937332386134
Validation loss: 2.629920075389512

Epoch: 6| Step: 4
Training loss: 2.929934559895247
Validation loss: 2.624534008895873

Epoch: 6| Step: 5
Training loss: 2.6273353723987385
Validation loss: 2.6197679185415796

Epoch: 6| Step: 6
Training loss: 2.5714773767623234
Validation loss: 2.6271373340951145

Epoch: 6| Step: 7
Training loss: 3.1365711372198035
Validation loss: 2.6300340053537647

Epoch: 6| Step: 8
Training loss: 2.703620821070961
Validation loss: 2.6184513973688444

Epoch: 6| Step: 9
Training loss: 3.0001614845047038
Validation loss: 2.621044235186045

Epoch: 6| Step: 10
Training loss: 2.6164508750848308
Validation loss: 2.6174866315751393

Epoch: 6| Step: 11
Training loss: 2.6237492987789475
Validation loss: 2.6308410396869277

Epoch: 6| Step: 12
Training loss: 3.0671522654425196
Validation loss: 2.630668237505888

Epoch: 6| Step: 13
Training loss: 3.2136622838528326
Validation loss: 2.6342395522511994

Epoch: 343| Step: 0
Training loss: 2.374902823618444
Validation loss: 2.6297699307773774

Epoch: 6| Step: 1
Training loss: 3.045893740979066
Validation loss: 2.6292202313793793

Epoch: 6| Step: 2
Training loss: 3.2243029646970673
Validation loss: 2.6199553907482973

Epoch: 6| Step: 3
Training loss: 2.8907836870505172
Validation loss: 2.6209833282562585

Epoch: 6| Step: 4
Training loss: 3.3569861146459603
Validation loss: 2.617278678920791

Epoch: 6| Step: 5
Training loss: 2.591716474767928
Validation loss: 2.6169302963212244

Epoch: 6| Step: 6
Training loss: 3.120646687024864
Validation loss: 2.618197875150645

Epoch: 6| Step: 7
Training loss: 2.8987946405958405
Validation loss: 2.6199404352282736

Epoch: 6| Step: 8
Training loss: 1.9683971997181247
Validation loss: 2.6157767992285677

Epoch: 6| Step: 9
Training loss: 3.16496328082487
Validation loss: 2.6229115551426307

Epoch: 6| Step: 10
Training loss: 3.410050398154922
Validation loss: 2.6236848578889793

Epoch: 6| Step: 11
Training loss: 3.389655893241224
Validation loss: 2.622825088771719

Epoch: 6| Step: 12
Training loss: 2.9141506969205957
Validation loss: 2.622733825069823

Epoch: 6| Step: 13
Training loss: 2.316214799608362
Validation loss: 2.6179158788487396

Epoch: 344| Step: 0
Training loss: 3.1547567026484424
Validation loss: 2.6195400615225006

Epoch: 6| Step: 1
Training loss: 3.1716726454656565
Validation loss: 2.6178114437339643

Epoch: 6| Step: 2
Training loss: 2.239954457841848
Validation loss: 2.6232873072824394

Epoch: 6| Step: 3
Training loss: 3.5774876722420643
Validation loss: 2.6317528221020408

Epoch: 6| Step: 4
Training loss: 3.433379321731657
Validation loss: 2.6320871321740476

Epoch: 6| Step: 5
Training loss: 3.14815942184657
Validation loss: 2.661933528196978

Epoch: 6| Step: 6
Training loss: 2.49420199397141
Validation loss: 2.655831509461812

Epoch: 6| Step: 7
Training loss: 2.805761785030215
Validation loss: 2.6426557535509274

Epoch: 6| Step: 8
Training loss: 3.025831117817425
Validation loss: 2.641774562685616

Epoch: 6| Step: 9
Training loss: 2.734361485039145
Validation loss: 2.648113280617187

Epoch: 6| Step: 10
Training loss: 3.034111324211747
Validation loss: 2.6340051272548526

Epoch: 6| Step: 11
Training loss: 2.7659022305435492
Validation loss: 2.630183452601016

Epoch: 6| Step: 12
Training loss: 2.672806248474125
Validation loss: 2.6332476440616914

Epoch: 6| Step: 13
Training loss: 2.572085618286337
Validation loss: 2.6523229293202975

Epoch: 345| Step: 0
Training loss: 3.237836524234356
Validation loss: 2.6458484034601226

Epoch: 6| Step: 1
Training loss: 2.6592435237242262
Validation loss: 2.6441501796014717

Epoch: 6| Step: 2
Training loss: 3.0472568370514868
Validation loss: 2.6445656018646395

Epoch: 6| Step: 3
Training loss: 2.4039846879214397
Validation loss: 2.659604878664754

Epoch: 6| Step: 4
Training loss: 3.476956531611703
Validation loss: 2.6511557462002666

Epoch: 6| Step: 5
Training loss: 3.0817700796345058
Validation loss: 2.643174324980149

Epoch: 6| Step: 6
Training loss: 2.83881629291969
Validation loss: 2.6297008517453064

Epoch: 6| Step: 7
Training loss: 3.293288897498994
Validation loss: 2.62425127988157

Epoch: 6| Step: 8
Training loss: 3.6160375361393244
Validation loss: 2.619435257598828

Epoch: 6| Step: 9
Training loss: 3.0188394916293086
Validation loss: 2.617081959261167

Epoch: 6| Step: 10
Training loss: 2.4982908128305708
Validation loss: 2.610189260591468

Epoch: 6| Step: 11
Training loss: 2.3514388042373637
Validation loss: 2.6155598559739057

Epoch: 6| Step: 12
Training loss: 2.4990339319948656
Validation loss: 2.616662753692496

Epoch: 6| Step: 13
Training loss: 2.965605988356145
Validation loss: 2.6163539410644194

Epoch: 346| Step: 0
Training loss: 2.810521341066039
Validation loss: 2.6262448050438256

Epoch: 6| Step: 1
Training loss: 3.268106931956354
Validation loss: 2.628155670507949

Epoch: 6| Step: 2
Training loss: 3.043656904296905
Validation loss: 2.6271366500378726

Epoch: 6| Step: 3
Training loss: 2.5029136844738114
Validation loss: 2.6298371792170046

Epoch: 6| Step: 4
Training loss: 2.846983695441436
Validation loss: 2.635407527849535

Epoch: 6| Step: 5
Training loss: 3.1406708519468505
Validation loss: 2.640628538731874

Epoch: 6| Step: 6
Training loss: 3.23668230843292
Validation loss: 2.6459148615015673

Epoch: 6| Step: 7
Training loss: 2.528188478783362
Validation loss: 2.6565021479664557

Epoch: 6| Step: 8
Training loss: 2.6821389954212433
Validation loss: 2.6607915611663917

Epoch: 6| Step: 9
Training loss: 3.1383263825677066
Validation loss: 2.6780831434825925

Epoch: 6| Step: 10
Training loss: 2.893026478165926
Validation loss: 2.6760228714348973

Epoch: 6| Step: 11
Training loss: 3.119996452084994
Validation loss: 2.680079822921859

Epoch: 6| Step: 12
Training loss: 2.727112373059495
Validation loss: 2.6823643442867615

Epoch: 6| Step: 13
Training loss: 3.4908387312517637
Validation loss: 2.6681253291821507

Epoch: 347| Step: 0
Training loss: 3.1015532755294184
Validation loss: 2.643225093450256

Epoch: 6| Step: 1
Training loss: 3.1518458997845644
Validation loss: 2.636368030480206

Epoch: 6| Step: 2
Training loss: 3.3910533441089914
Validation loss: 2.6222251273352843

Epoch: 6| Step: 3
Training loss: 2.816796814057949
Validation loss: 2.612192489825963

Epoch: 6| Step: 4
Training loss: 2.8999355177451926
Validation loss: 2.608708835565968

Epoch: 6| Step: 5
Training loss: 3.0559483728391905
Validation loss: 2.613141266720382

Epoch: 6| Step: 6
Training loss: 3.0750095460324864
Validation loss: 2.617326243798339

Epoch: 6| Step: 7
Training loss: 2.845976911267513
Validation loss: 2.615154334578719

Epoch: 6| Step: 8
Training loss: 3.094952282268113
Validation loss: 2.61534864377327

Epoch: 6| Step: 9
Training loss: 3.076732339815919
Validation loss: 2.6186142288525978

Epoch: 6| Step: 10
Training loss: 2.559228250583841
Validation loss: 2.6127796436948403

Epoch: 6| Step: 11
Training loss: 2.4253207397714185
Validation loss: 2.618470058328695

Epoch: 6| Step: 12
Training loss: 2.877097484232478
Validation loss: 2.6141780030361983

Epoch: 6| Step: 13
Training loss: 2.9666877410082995
Validation loss: 2.611234471384454

Epoch: 348| Step: 0
Training loss: 2.861608914603664
Validation loss: 2.6173766512130445

Epoch: 6| Step: 1
Training loss: 2.9169949664679597
Validation loss: 2.6394278364726222

Epoch: 6| Step: 2
Training loss: 3.3079932882847443
Validation loss: 2.6772233107568733

Epoch: 6| Step: 3
Training loss: 2.718609685675175
Validation loss: 2.6805830951664302

Epoch: 6| Step: 4
Training loss: 3.171591459482803
Validation loss: 2.696182365041731

Epoch: 6| Step: 5
Training loss: 2.6007773557744387
Validation loss: 2.6955889141155995

Epoch: 6| Step: 6
Training loss: 2.7509494356301425
Validation loss: 2.713037968711893

Epoch: 6| Step: 7
Training loss: 3.503012178426531
Validation loss: 2.723271180775865

Epoch: 6| Step: 8
Training loss: 2.6022217977642725
Validation loss: 2.761947284255267

Epoch: 6| Step: 9
Training loss: 2.9752577277351544
Validation loss: 2.7750506994243884

Epoch: 6| Step: 10
Training loss: 3.146195666602188
Validation loss: 2.7981375088594973

Epoch: 6| Step: 11
Training loss: 2.6875581069697123
Validation loss: 2.7547828291007175

Epoch: 6| Step: 12
Training loss: 3.3772163178234598
Validation loss: 2.7263452916039093

Epoch: 6| Step: 13
Training loss: 2.601118536747588
Validation loss: 2.698406069776338

Epoch: 349| Step: 0
Training loss: 3.1401351622629674
Validation loss: 2.6661483474984755

Epoch: 6| Step: 1
Training loss: 2.6661902737265604
Validation loss: 2.651504361791649

Epoch: 6| Step: 2
Training loss: 3.6076975966469997
Validation loss: 2.637886933085212

Epoch: 6| Step: 3
Training loss: 3.0710755775863072
Validation loss: 2.6208373121397064

Epoch: 6| Step: 4
Training loss: 2.459929147645921
Validation loss: 2.61517594034227

Epoch: 6| Step: 5
Training loss: 2.910477547542419
Validation loss: 2.6157377500649353

Epoch: 6| Step: 6
Training loss: 2.7609571299694338
Validation loss: 2.6236718211943346

Epoch: 6| Step: 7
Training loss: 2.9235836479808
Validation loss: 2.621399389176937

Epoch: 6| Step: 8
Training loss: 3.099686139123085
Validation loss: 2.624291832792264

Epoch: 6| Step: 9
Training loss: 2.1292372699933444
Validation loss: 2.6179931282260296

Epoch: 6| Step: 10
Training loss: 2.916923202858538
Validation loss: 2.616849939417688

Epoch: 6| Step: 11
Training loss: 3.4427131656645518
Validation loss: 2.6139539779817604

Epoch: 6| Step: 12
Training loss: 3.056236089195
Validation loss: 2.61375360021269

Epoch: 6| Step: 13
Training loss: 3.1304328994468884
Validation loss: 2.6069313304696853

Epoch: 350| Step: 0
Training loss: 3.128232580996903
Validation loss: 2.6137970897291085

Epoch: 6| Step: 1
Training loss: 3.4597321557688026
Validation loss: 2.6183718185331184

Epoch: 6| Step: 2
Training loss: 3.439121488128534
Validation loss: 2.6186750851542566

Epoch: 6| Step: 3
Training loss: 2.1575088143638297
Validation loss: 2.6224089245990263

Epoch: 6| Step: 4
Training loss: 3.105673115081769
Validation loss: 2.625361377161037

Epoch: 6| Step: 5
Training loss: 2.824884064582566
Validation loss: 2.6208251162106935

Epoch: 6| Step: 6
Training loss: 2.1696126667772595
Validation loss: 2.6281740704012932

Epoch: 6| Step: 7
Training loss: 3.289164706927781
Validation loss: 2.637768669423641

Epoch: 6| Step: 8
Training loss: 2.490784731616554
Validation loss: 2.636786725418714

Epoch: 6| Step: 9
Training loss: 3.2531083721281937
Validation loss: 2.6382899174711896

Epoch: 6| Step: 10
Training loss: 2.873873448451982
Validation loss: 2.6396754543516496

Epoch: 6| Step: 11
Training loss: 2.7928367743622218
Validation loss: 2.63039417144373

Epoch: 6| Step: 12
Training loss: 2.8027115771067566
Validation loss: 2.630992385996859

Epoch: 6| Step: 13
Training loss: 3.0945048326512206
Validation loss: 2.6359802996168336

Epoch: 351| Step: 0
Training loss: 2.9569006302681653
Validation loss: 2.631077542361708

Epoch: 6| Step: 1
Training loss: 3.282797602856192
Validation loss: 2.6297203239101488

Epoch: 6| Step: 2
Training loss: 2.618521643539875
Validation loss: 2.633416284649014

Epoch: 6| Step: 3
Training loss: 2.455434210422394
Validation loss: 2.631868110466329

Epoch: 6| Step: 4
Training loss: 2.4017652854111398
Validation loss: 2.6390764327043845

Epoch: 6| Step: 5
Training loss: 2.570536502248764
Validation loss: 2.6349425911874764

Epoch: 6| Step: 6
Training loss: 3.2912010797152975
Validation loss: 2.640834962376325

Epoch: 6| Step: 7
Training loss: 3.580916203093373
Validation loss: 2.649239461302443

Epoch: 6| Step: 8
Training loss: 2.4538726639172244
Validation loss: 2.6564776328484805

Epoch: 6| Step: 9
Training loss: 3.3754236873724315
Validation loss: 2.6419831596391066

Epoch: 6| Step: 10
Training loss: 2.911379809108269
Validation loss: 2.632088436353502

Epoch: 6| Step: 11
Training loss: 3.383848388504106
Validation loss: 2.634701886550868

Epoch: 6| Step: 12
Training loss: 3.130354299754612
Validation loss: 2.6272008081723066

Epoch: 6| Step: 13
Training loss: 1.874752028280408
Validation loss: 2.6291369786856746

Epoch: 352| Step: 0
Training loss: 2.820570999937076
Validation loss: 2.6306389179129117

Epoch: 6| Step: 1
Training loss: 2.875357066662021
Validation loss: 2.6261565907220885

Epoch: 6| Step: 2
Training loss: 3.2067439778843063
Validation loss: 2.622980809068658

Epoch: 6| Step: 3
Training loss: 2.568676366934078
Validation loss: 2.6174842549911483

Epoch: 6| Step: 4
Training loss: 3.373119819528285
Validation loss: 2.622116358618089

Epoch: 6| Step: 5
Training loss: 2.663658670822603
Validation loss: 2.623707386145204

Epoch: 6| Step: 6
Training loss: 3.3754684688252095
Validation loss: 2.6118158982954

Epoch: 6| Step: 7
Training loss: 2.9931372985141107
Validation loss: 2.6115482381225044

Epoch: 6| Step: 8
Training loss: 2.8985603902835293
Validation loss: 2.611106535317659

Epoch: 6| Step: 9
Training loss: 2.6709838630363048
Validation loss: 2.6142413220388496

Epoch: 6| Step: 10
Training loss: 2.5510426689655854
Validation loss: 2.6100177215275027

Epoch: 6| Step: 11
Training loss: 2.9460370616977114
Validation loss: 2.6130835917026545

Epoch: 6| Step: 12
Training loss: 3.2762987837494233
Validation loss: 2.6106832848762336

Epoch: 6| Step: 13
Training loss: 2.6747419357598963
Validation loss: 2.61944308033426

Epoch: 353| Step: 0
Training loss: 2.5980956659595003
Validation loss: 2.6242825943410133

Epoch: 6| Step: 1
Training loss: 2.3924659173305645
Validation loss: 2.6349214296608787

Epoch: 6| Step: 2
Training loss: 3.228861066242277
Validation loss: 2.643205748415459

Epoch: 6| Step: 3
Training loss: 3.324908784461281
Validation loss: 2.677070845242081

Epoch: 6| Step: 4
Training loss: 3.1070913238511313
Validation loss: 2.690269062443603

Epoch: 6| Step: 5
Training loss: 2.9563419642267776
Validation loss: 2.716206978546683

Epoch: 6| Step: 6
Training loss: 3.3601385623880553
Validation loss: 2.6982513019387238

Epoch: 6| Step: 7
Training loss: 2.7225798893075863
Validation loss: 2.697474481249679

Epoch: 6| Step: 8
Training loss: 2.0124154967580123
Validation loss: 2.683213691805929

Epoch: 6| Step: 9
Training loss: 3.210747706240695
Validation loss: 2.657535872453404

Epoch: 6| Step: 10
Training loss: 3.114699362610427
Validation loss: 2.671437930387917

Epoch: 6| Step: 11
Training loss: 2.878975648703482
Validation loss: 2.635156349076158

Epoch: 6| Step: 12
Training loss: 3.0078516573648377
Validation loss: 2.6116026840944184

Epoch: 6| Step: 13
Training loss: 3.199328149361957
Validation loss: 2.6048584607789347

Epoch: 354| Step: 0
Training loss: 3.4090084840462507
Validation loss: 2.607805712185941

Epoch: 6| Step: 1
Training loss: 2.3542173487066083
Validation loss: 2.609598207349647

Epoch: 6| Step: 2
Training loss: 3.3898201967341164
Validation loss: 2.608454296663731

Epoch: 6| Step: 3
Training loss: 2.7565830505248554
Validation loss: 2.6060542068913657

Epoch: 6| Step: 4
Training loss: 2.675680562373392
Validation loss: 2.6064967275165305

Epoch: 6| Step: 5
Training loss: 3.117747015202751
Validation loss: 2.6042695367655644

Epoch: 6| Step: 6
Training loss: 2.880003514287712
Validation loss: 2.6096134235288755

Epoch: 6| Step: 7
Training loss: 3.3043698999182642
Validation loss: 2.6149450925413222

Epoch: 6| Step: 8
Training loss: 2.5444427296809935
Validation loss: 2.6210574610067874

Epoch: 6| Step: 9
Training loss: 3.2508118422429484
Validation loss: 2.6164947910527214

Epoch: 6| Step: 10
Training loss: 2.8644101362177166
Validation loss: 2.6139963103286528

Epoch: 6| Step: 11
Training loss: 3.085789003300158
Validation loss: 2.6060220565930914

Epoch: 6| Step: 12
Training loss: 2.825671738961762
Validation loss: 2.6142954550004776

Epoch: 6| Step: 13
Training loss: 2.316203785582969
Validation loss: 2.6093049153256915

Epoch: 355| Step: 0
Training loss: 3.656508998989662
Validation loss: 2.6078093219954654

Epoch: 6| Step: 1
Training loss: 2.4067554686093793
Validation loss: 2.609033263668007

Epoch: 6| Step: 2
Training loss: 3.104934358501878
Validation loss: 2.607547732545661

Epoch: 6| Step: 3
Training loss: 2.609373263969529
Validation loss: 2.6121052495532613

Epoch: 6| Step: 4
Training loss: 2.833320692445568
Validation loss: 2.606224416250793

Epoch: 6| Step: 5
Training loss: 2.8599746158780497
Validation loss: 2.612770579419815

Epoch: 6| Step: 6
Training loss: 3.7005605066880976
Validation loss: 2.605863245103155

Epoch: 6| Step: 7
Training loss: 2.9451656557910746
Validation loss: 2.6104565661263943

Epoch: 6| Step: 8
Training loss: 3.3334385537388767
Validation loss: 2.6065676578016928

Epoch: 6| Step: 9
Training loss: 2.44921875
Validation loss: 2.604017523319718

Epoch: 6| Step: 10
Training loss: 2.5991221486501006
Validation loss: 2.6061164788900903

Epoch: 6| Step: 11
Training loss: 2.82124292131921
Validation loss: 2.608021545829858

Epoch: 6| Step: 12
Training loss: 2.5897215847471187
Validation loss: 2.616681175617567

Epoch: 6| Step: 13
Training loss: 2.743073670747283
Validation loss: 2.628475128321195

Epoch: 356| Step: 0
Training loss: 2.712567018305057
Validation loss: 2.638833398528791

Epoch: 6| Step: 1
Training loss: 2.496094323099993
Validation loss: 2.651089162312633

Epoch: 6| Step: 2
Training loss: 2.7892597887373958
Validation loss: 2.6782593925561176

Epoch: 6| Step: 3
Training loss: 2.396417717912122
Validation loss: 2.678553241896526

Epoch: 6| Step: 4
Training loss: 2.661053790397824
Validation loss: 2.7211323541671297

Epoch: 6| Step: 5
Training loss: 3.1156825206654286
Validation loss: 2.7155550244747864

Epoch: 6| Step: 6
Training loss: 3.411049078157427
Validation loss: 2.70108023837816

Epoch: 6| Step: 7
Training loss: 3.6267080558023257
Validation loss: 2.690513209425643

Epoch: 6| Step: 8
Training loss: 3.184104457215248
Validation loss: 2.6477938587535896

Epoch: 6| Step: 9
Training loss: 3.4449472385125515
Validation loss: 2.629275510702333

Epoch: 6| Step: 10
Training loss: 2.772930775947319
Validation loss: 2.6172593463359557

Epoch: 6| Step: 11
Training loss: 2.9535917690286397
Validation loss: 2.6102245653122647

Epoch: 6| Step: 12
Training loss: 2.8680701287499466
Validation loss: 2.6125125807576834

Epoch: 6| Step: 13
Training loss: 2.705827189271008
Validation loss: 2.610331756303171

Epoch: 357| Step: 0
Training loss: 3.155126390540196
Validation loss: 2.6068521591665226

Epoch: 6| Step: 1
Training loss: 2.5607991039778653
Validation loss: 2.608331674229768

Epoch: 6| Step: 2
Training loss: 3.027747578912636
Validation loss: 2.60636824905709

Epoch: 6| Step: 3
Training loss: 2.6132297938459863
Validation loss: 2.6083393445051017

Epoch: 6| Step: 4
Training loss: 3.489214491448467
Validation loss: 2.6102485906353925

Epoch: 6| Step: 5
Training loss: 3.0141348047517416
Validation loss: 2.607356303967786

Epoch: 6| Step: 6
Training loss: 2.906433755951505
Validation loss: 2.616463364770571

Epoch: 6| Step: 7
Training loss: 2.8985738799303618
Validation loss: 2.6120234270692717

Epoch: 6| Step: 8
Training loss: 3.1540908226526234
Validation loss: 2.6244605721643235

Epoch: 6| Step: 9
Training loss: 3.1301684554231537
Validation loss: 2.6245689350672747

Epoch: 6| Step: 10
Training loss: 2.2386268761631385
Validation loss: 2.61653393277548

Epoch: 6| Step: 11
Training loss: 2.9133777785529986
Validation loss: 2.6251915516575126

Epoch: 6| Step: 12
Training loss: 2.4805211339510462
Validation loss: 2.6196859737961433

Epoch: 6| Step: 13
Training loss: 3.6176615130492857
Validation loss: 2.6170640103588485

Epoch: 358| Step: 0
Training loss: 3.1672463304789114
Validation loss: 2.612079654293766

Epoch: 6| Step: 1
Training loss: 3.332996510336463
Validation loss: 2.6277765248231404

Epoch: 6| Step: 2
Training loss: 3.377842730251801
Validation loss: 2.6213707130880577

Epoch: 6| Step: 3
Training loss: 2.8910477612619876
Validation loss: 2.6159043618436595

Epoch: 6| Step: 4
Training loss: 3.0505075563950887
Validation loss: 2.611254919190603

Epoch: 6| Step: 5
Training loss: 2.611961772907694
Validation loss: 2.6184222699490323

Epoch: 6| Step: 6
Training loss: 2.5411699674794255
Validation loss: 2.62153965221739

Epoch: 6| Step: 7
Training loss: 2.6702960072427153
Validation loss: 2.617047999947736

Epoch: 6| Step: 8
Training loss: 2.822868900434543
Validation loss: 2.6261779556364724

Epoch: 6| Step: 9
Training loss: 3.1061284738020993
Validation loss: 2.624353690599806

Epoch: 6| Step: 10
Training loss: 3.0065603052457788
Validation loss: 2.6196866363123794

Epoch: 6| Step: 11
Training loss: 2.9243362586595505
Validation loss: 2.623064746801456

Epoch: 6| Step: 12
Training loss: 2.5334848969278316
Validation loss: 2.6181824640699567

Epoch: 6| Step: 13
Training loss: 2.9283634703432764
Validation loss: 2.6132510466592738

Epoch: 359| Step: 0
Training loss: 3.025296529312622
Validation loss: 2.6094053602058143

Epoch: 6| Step: 1
Training loss: 2.727992079250661
Validation loss: 2.597880920124227

Epoch: 6| Step: 2
Training loss: 3.0672312410318714
Validation loss: 2.598661946670277

Epoch: 6| Step: 3
Training loss: 2.975380009335139
Validation loss: 2.6004998112415296

Epoch: 6| Step: 4
Training loss: 3.546505677745044
Validation loss: 2.604192236661995

Epoch: 6| Step: 5
Training loss: 2.6802993832089674
Validation loss: 2.6022805183837656

Epoch: 6| Step: 6
Training loss: 3.3440417581351114
Validation loss: 2.607267336513329

Epoch: 6| Step: 7
Training loss: 2.278048633608906
Validation loss: 2.6059501758978003

Epoch: 6| Step: 8
Training loss: 2.8395985913350694
Validation loss: 2.6064561652701483

Epoch: 6| Step: 9
Training loss: 3.108156511801725
Validation loss: 2.603997842218052

Epoch: 6| Step: 10
Training loss: 2.7761805763822145
Validation loss: 2.608758120671645

Epoch: 6| Step: 11
Training loss: 3.0167294392105193
Validation loss: 2.6056423870738947

Epoch: 6| Step: 12
Training loss: 2.3961496780082303
Validation loss: 2.619123967561047

Epoch: 6| Step: 13
Training loss: 3.1054939316982173
Validation loss: 2.628445563836778

Epoch: 360| Step: 0
Training loss: 2.6155867962343087
Validation loss: 2.652076211008898

Epoch: 6| Step: 1
Training loss: 3.2145817998724637
Validation loss: 2.6553009190724812

Epoch: 6| Step: 2
Training loss: 2.7879420148109246
Validation loss: 2.650892479818349

Epoch: 6| Step: 3
Training loss: 2.620430010968202
Validation loss: 2.6381088281194156

Epoch: 6| Step: 4
Training loss: 3.0924434793005444
Validation loss: 2.6391163255369503

Epoch: 6| Step: 5
Training loss: 2.9135463554081826
Validation loss: 2.6282921356757023

Epoch: 6| Step: 6
Training loss: 2.853348013611341
Validation loss: 2.634919286256315

Epoch: 6| Step: 7
Training loss: 3.1575917328642467
Validation loss: 2.6303628888079666

Epoch: 6| Step: 8
Training loss: 3.649513494389018
Validation loss: 2.621072158784455

Epoch: 6| Step: 9
Training loss: 2.5735726594897406
Validation loss: 2.6232956785007135

Epoch: 6| Step: 10
Training loss: 3.5739255023998613
Validation loss: 2.6232277365855974

Epoch: 6| Step: 11
Training loss: 2.7959282833828754
Validation loss: 2.6185206057559713

Epoch: 6| Step: 12
Training loss: 2.7443196845772992
Validation loss: 2.6055957054633323

Epoch: 6| Step: 13
Training loss: 1.4392198143212651
Validation loss: 2.600430500826775

Epoch: 361| Step: 0
Training loss: 2.874197640617559
Validation loss: 2.596331786980009

Epoch: 6| Step: 1
Training loss: 3.2404155255175433
Validation loss: 2.5967244324565635

Epoch: 6| Step: 2
Training loss: 2.724491589915988
Validation loss: 2.5954533338743513

Epoch: 6| Step: 3
Training loss: 3.2317913258671567
Validation loss: 2.594043385468087

Epoch: 6| Step: 4
Training loss: 3.025123303635286
Validation loss: 2.5925924211501368

Epoch: 6| Step: 5
Training loss: 2.983294066556099
Validation loss: 2.596747541134789

Epoch: 6| Step: 6
Training loss: 3.365825758306321
Validation loss: 2.600049590828164

Epoch: 6| Step: 7
Training loss: 2.5614194685283596
Validation loss: 2.596744312823235

Epoch: 6| Step: 8
Training loss: 3.4204851228066753
Validation loss: 2.5950839836046327

Epoch: 6| Step: 9
Training loss: 2.814351976788861
Validation loss: 2.593635942046943

Epoch: 6| Step: 10
Training loss: 3.1110363073287295
Validation loss: 2.5932061111539806

Epoch: 6| Step: 11
Training loss: 2.5899111363546563
Validation loss: 2.602740775942087

Epoch: 6| Step: 12
Training loss: 2.3517286679182496
Validation loss: 2.604530567626315

Epoch: 6| Step: 13
Training loss: 2.3080574871553075
Validation loss: 2.6127004852552926

Epoch: 362| Step: 0
Training loss: 3.200249101956783
Validation loss: 2.614015740600724

Epoch: 6| Step: 1
Training loss: 2.7837494324031367
Validation loss: 2.608488969334438

Epoch: 6| Step: 2
Training loss: 2.77389823417771
Validation loss: 2.608726859643558

Epoch: 6| Step: 3
Training loss: 2.5940172907974333
Validation loss: 2.6177987234866005

Epoch: 6| Step: 4
Training loss: 2.7661216850186774
Validation loss: 2.6169005191184436

Epoch: 6| Step: 5
Training loss: 2.537924361801026
Validation loss: 2.6129527831685637

Epoch: 6| Step: 6
Training loss: 3.0071684705189043
Validation loss: 2.618048005176456

Epoch: 6| Step: 7
Training loss: 3.105757713069395
Validation loss: 2.618172790850855

Epoch: 6| Step: 8
Training loss: 2.970699272679948
Validation loss: 2.6195835596888215

Epoch: 6| Step: 9
Training loss: 3.036955507557332
Validation loss: 2.6103813397690248

Epoch: 6| Step: 10
Training loss: 3.2564262532804578
Validation loss: 2.6042157476578627

Epoch: 6| Step: 11
Training loss: 2.9961217607882276
Validation loss: 2.5997177274884176

Epoch: 6| Step: 12
Training loss: 3.305774699265618
Validation loss: 2.601929160073349

Epoch: 6| Step: 13
Training loss: 2.1229691618423923
Validation loss: 2.596171235776922

Epoch: 363| Step: 0
Training loss: 3.3857086681712563
Validation loss: 2.5941195402020694

Epoch: 6| Step: 1
Training loss: 3.496445349376529
Validation loss: 2.597146407142377

Epoch: 6| Step: 2
Training loss: 2.50222183678494
Validation loss: 2.602044774736489

Epoch: 6| Step: 3
Training loss: 3.1213203128324225
Validation loss: 2.6014372979553992

Epoch: 6| Step: 4
Training loss: 2.5689246422275307
Validation loss: 2.616442992452607

Epoch: 6| Step: 5
Training loss: 2.908174267402158
Validation loss: 2.612754665349738

Epoch: 6| Step: 6
Training loss: 2.5597061185237666
Validation loss: 2.617337684687325

Epoch: 6| Step: 7
Training loss: 3.728478536925938
Validation loss: 2.622712465333371

Epoch: 6| Step: 8
Training loss: 3.2127295920415695
Validation loss: 2.6303276955198522

Epoch: 6| Step: 9
Training loss: 2.554723710203049
Validation loss: 2.624298502978786

Epoch: 6| Step: 10
Training loss: 2.2329483279217315
Validation loss: 2.6197041689558995

Epoch: 6| Step: 11
Training loss: 2.8803940633222345
Validation loss: 2.6178735643465765

Epoch: 6| Step: 12
Training loss: 2.708430205348865
Validation loss: 2.610905939508423

Epoch: 6| Step: 13
Training loss: 2.6908872682567564
Validation loss: 2.603553408042322

Epoch: 364| Step: 0
Training loss: 2.5617208459304
Validation loss: 2.6111749948724334

Epoch: 6| Step: 1
Training loss: 3.361166117264465
Validation loss: 2.605249385740968

Epoch: 6| Step: 2
Training loss: 3.102493261780288
Validation loss: 2.6103969127918925

Epoch: 6| Step: 3
Training loss: 3.0311318600629007
Validation loss: 2.595877106179202

Epoch: 6| Step: 4
Training loss: 3.578218817001519
Validation loss: 2.5970756736257266

Epoch: 6| Step: 5
Training loss: 2.4118272624119204
Validation loss: 2.60324954875487

Epoch: 6| Step: 6
Training loss: 2.3279250910396985
Validation loss: 2.5909180909893608

Epoch: 6| Step: 7
Training loss: 2.6468304735061814
Validation loss: 2.595450877356565

Epoch: 6| Step: 8
Training loss: 2.8418797641476794
Validation loss: 2.5916295314576625

Epoch: 6| Step: 9
Training loss: 3.2314327697418257
Validation loss: 2.5895633318333244

Epoch: 6| Step: 10
Training loss: 2.7032348963277535
Validation loss: 2.594783898618493

Epoch: 6| Step: 11
Training loss: 3.037640628777474
Validation loss: 2.600749786000032

Epoch: 6| Step: 12
Training loss: 3.235453844972414
Validation loss: 2.618142029012816

Epoch: 6| Step: 13
Training loss: 2.481538508863338
Validation loss: 2.612915782614712

Epoch: 365| Step: 0
Training loss: 2.965591999670268
Validation loss: 2.6120538526757264

Epoch: 6| Step: 1
Training loss: 2.9972655231819347
Validation loss: 2.619487239252298

Epoch: 6| Step: 2
Training loss: 2.9420854207389704
Validation loss: 2.620818797155535

Epoch: 6| Step: 3
Training loss: 2.612354975421342
Validation loss: 2.6227822728662744

Epoch: 6| Step: 4
Training loss: 2.753682878241592
Validation loss: 2.6310661431930087

Epoch: 6| Step: 5
Training loss: 2.87850158414653
Validation loss: 2.6102890330578776

Epoch: 6| Step: 6
Training loss: 3.020571432051069
Validation loss: 2.6015752040478084

Epoch: 6| Step: 7
Training loss: 1.9236002675778716
Validation loss: 2.596782457980176

Epoch: 6| Step: 8
Training loss: 2.9118178980972846
Validation loss: 2.5904849292895094

Epoch: 6| Step: 9
Training loss: 3.4988033428807226
Validation loss: 2.5944494190765495

Epoch: 6| Step: 10
Training loss: 2.9539761401577187
Validation loss: 2.5944748355063108

Epoch: 6| Step: 11
Training loss: 3.144912146962038
Validation loss: 2.5925713737568103

Epoch: 6| Step: 12
Training loss: 3.065641232446592
Validation loss: 2.6009026112721005

Epoch: 6| Step: 13
Training loss: 3.1411950652073655
Validation loss: 2.6013205446324275

Epoch: 366| Step: 0
Training loss: 3.730584555221504
Validation loss: 2.6063987082202216

Epoch: 6| Step: 1
Training loss: 2.9019763657536184
Validation loss: 2.609369420529539

Epoch: 6| Step: 2
Training loss: 2.94363509356831
Validation loss: 2.614865095226917

Epoch: 6| Step: 3
Training loss: 2.9733173773070862
Validation loss: 2.6242455610814126

Epoch: 6| Step: 4
Training loss: 2.871490492624163
Validation loss: 2.610548370987878

Epoch: 6| Step: 5
Training loss: 2.965013582092363
Validation loss: 2.614933081874772

Epoch: 6| Step: 6
Training loss: 2.669928572338665
Validation loss: 2.6159725282609623

Epoch: 6| Step: 7
Training loss: 3.008441968173343
Validation loss: 2.6198540899914184

Epoch: 6| Step: 8
Training loss: 3.2943568443358204
Validation loss: 2.6098222089577043

Epoch: 6| Step: 9
Training loss: 2.3507822966644603
Validation loss: 2.606213908765597

Epoch: 6| Step: 10
Training loss: 3.098577412934483
Validation loss: 2.6130473425556686

Epoch: 6| Step: 11
Training loss: 2.2996230521426333
Validation loss: 2.6075801668430345

Epoch: 6| Step: 12
Training loss: 2.580647661992369
Validation loss: 2.6137566662767315

Epoch: 6| Step: 13
Training loss: 3.1118955890919073
Validation loss: 2.6149061044871877

Epoch: 367| Step: 0
Training loss: 3.790523538387324
Validation loss: 2.640335670052518

Epoch: 6| Step: 1
Training loss: 3.395388864710865
Validation loss: 2.6418311892126614

Epoch: 6| Step: 2
Training loss: 2.603298764880534
Validation loss: 2.665136823926016

Epoch: 6| Step: 3
Training loss: 2.715371850333485
Validation loss: 2.664678513754897

Epoch: 6| Step: 4
Training loss: 3.348482579699027
Validation loss: 2.6826266235623772

Epoch: 6| Step: 5
Training loss: 3.318099848683725
Validation loss: 2.68142813284376

Epoch: 6| Step: 6
Training loss: 1.873068195814361
Validation loss: 2.6513813159908914

Epoch: 6| Step: 7
Training loss: 2.403339557965913
Validation loss: 2.646969928901936

Epoch: 6| Step: 8
Training loss: 3.3190045102908576
Validation loss: 2.6333390194431825

Epoch: 6| Step: 9
Training loss: 3.2117672333135117
Validation loss: 2.632391497376969

Epoch: 6| Step: 10
Training loss: 1.6576398380260664
Validation loss: 2.605282568951536

Epoch: 6| Step: 11
Training loss: 2.9072035999051167
Validation loss: 2.602945808132701

Epoch: 6| Step: 12
Training loss: 2.6363400335660434
Validation loss: 2.591025633468341

Epoch: 6| Step: 13
Training loss: 3.2509104113782676
Validation loss: 2.5886039789936093

Epoch: 368| Step: 0
Training loss: 3.15319888252375
Validation loss: 2.5873069149779777

Epoch: 6| Step: 1
Training loss: 2.6468428140279943
Validation loss: 2.5909686722989393

Epoch: 6| Step: 2
Training loss: 3.313822068589457
Validation loss: 2.587488112844165

Epoch: 6| Step: 3
Training loss: 2.608593669570323
Validation loss: 2.5883713288580874

Epoch: 6| Step: 4
Training loss: 2.6567583383070548
Validation loss: 2.5953781013450583

Epoch: 6| Step: 5
Training loss: 2.535663289530196
Validation loss: 2.5901183901764178

Epoch: 6| Step: 6
Training loss: 2.5149713460757424
Validation loss: 2.5885241060091913

Epoch: 6| Step: 7
Training loss: 3.03935777656559
Validation loss: 2.593262072166494

Epoch: 6| Step: 8
Training loss: 3.4058515683152586
Validation loss: 2.5939628680762383

Epoch: 6| Step: 9
Training loss: 3.619795911315332
Validation loss: 2.594551329335207

Epoch: 6| Step: 10
Training loss: 2.8453101604856355
Validation loss: 2.5920106838404413

Epoch: 6| Step: 11
Training loss: 3.1907209690168807
Validation loss: 2.594226855098308

Epoch: 6| Step: 12
Training loss: 2.301702085199923
Validation loss: 2.5996353898706297

Epoch: 6| Step: 13
Training loss: 2.7628984535049206
Validation loss: 2.5998115080368764

Epoch: 369| Step: 0
Training loss: 3.157963504795397
Validation loss: 2.5974202791149716

Epoch: 6| Step: 1
Training loss: 3.5101085191780395
Validation loss: 2.6053129187909376

Epoch: 6| Step: 2
Training loss: 2.291759373494734
Validation loss: 2.6015612130366854

Epoch: 6| Step: 3
Training loss: 2.6851563991694203
Validation loss: 2.6034846023402363

Epoch: 6| Step: 4
Training loss: 2.4408430991124486
Validation loss: 2.60339901510386

Epoch: 6| Step: 5
Training loss: 2.5719836521489374
Validation loss: 2.6122767555630353

Epoch: 6| Step: 6
Training loss: 3.5708919530721084
Validation loss: 2.5991446471655455

Epoch: 6| Step: 7
Training loss: 2.830617743963138
Validation loss: 2.598307648179061

Epoch: 6| Step: 8
Training loss: 2.8379709399121995
Validation loss: 2.613346150489041

Epoch: 6| Step: 9
Training loss: 3.0875891792298513
Validation loss: 2.6120243418055753

Epoch: 6| Step: 10
Training loss: 2.9969164577953924
Validation loss: 2.610655479944256

Epoch: 6| Step: 11
Training loss: 2.493078473150196
Validation loss: 2.607777647024427

Epoch: 6| Step: 12
Training loss: 3.440170915039341
Validation loss: 2.6018501952143787

Epoch: 6| Step: 13
Training loss: 2.364757940312702
Validation loss: 2.6038434549562153

Epoch: 370| Step: 0
Training loss: 2.8508002111463493
Validation loss: 2.5987075857982935

Epoch: 6| Step: 1
Training loss: 2.770170452781449
Validation loss: 2.6186880331627407

Epoch: 6| Step: 2
Training loss: 3.2519582570811605
Validation loss: 2.615433238129953

Epoch: 6| Step: 3
Training loss: 3.3300459068731056
Validation loss: 2.6103388888887644

Epoch: 6| Step: 4
Training loss: 2.7733674376328707
Validation loss: 2.6075749581128003

Epoch: 6| Step: 5
Training loss: 3.204979485313711
Validation loss: 2.606081604471906

Epoch: 6| Step: 6
Training loss: 2.92990949679744
Validation loss: 2.605806648610481

Epoch: 6| Step: 7
Training loss: 2.4689442039108838
Validation loss: 2.600623610310382

Epoch: 6| Step: 8
Training loss: 2.867453414684916
Validation loss: 2.604691712312523

Epoch: 6| Step: 9
Training loss: 2.4975644645733786
Validation loss: 2.6046714309931054

Epoch: 6| Step: 10
Training loss: 3.1694637961822596
Validation loss: 2.6049174398440362

Epoch: 6| Step: 11
Training loss: 2.8874025270598285
Validation loss: 2.59991826456675

Epoch: 6| Step: 12
Training loss: 3.1395644489640944
Validation loss: 2.599982157631006

Epoch: 6| Step: 13
Training loss: 2.2176569005599296
Validation loss: 2.604953001031891

Epoch: 371| Step: 0
Training loss: 3.3776870203652596
Validation loss: 2.6003770148267726

Epoch: 6| Step: 1
Training loss: 2.1654507697672094
Validation loss: 2.596791355935178

Epoch: 6| Step: 2
Training loss: 3.392458090583037
Validation loss: 2.606144151741334

Epoch: 6| Step: 3
Training loss: 3.090348039797472
Validation loss: 2.614858844123462

Epoch: 6| Step: 4
Training loss: 2.686099463745168
Validation loss: 2.6075715642724027

Epoch: 6| Step: 5
Training loss: 2.6692677766115627
Validation loss: 2.604741028153261

Epoch: 6| Step: 6
Training loss: 2.8192194038199654
Validation loss: 2.605916320414782

Epoch: 6| Step: 7
Training loss: 2.8716271560203213
Validation loss: 2.604532874825571

Epoch: 6| Step: 8
Training loss: 2.1162489045754858
Validation loss: 2.6092894025958153

Epoch: 6| Step: 9
Training loss: 2.7312587746625443
Validation loss: 2.61321520598129

Epoch: 6| Step: 10
Training loss: 2.9820477264085037
Validation loss: 2.6112251455019457

Epoch: 6| Step: 11
Training loss: 3.227221848774276
Validation loss: 2.617606720449108

Epoch: 6| Step: 12
Training loss: 3.19194438977667
Validation loss: 2.5963656701827005

Epoch: 6| Step: 13
Training loss: 3.283143142252115
Validation loss: 2.590797527960078

Epoch: 372| Step: 0
Training loss: 3.0745757888085845
Validation loss: 2.596182503770113

Epoch: 6| Step: 1
Training loss: 3.421733417804422
Validation loss: 2.591163270524439

Epoch: 6| Step: 2
Training loss: 2.8609753075460445
Validation loss: 2.5929861415413304

Epoch: 6| Step: 3
Training loss: 3.5698471600809314
Validation loss: 2.5919654678163457

Epoch: 6| Step: 4
Training loss: 3.1112401534369534
Validation loss: 2.5898821145863535

Epoch: 6| Step: 5
Training loss: 2.4616271975001935
Validation loss: 2.589586853878183

Epoch: 6| Step: 6
Training loss: 2.5688618099632654
Validation loss: 2.5925565500003547

Epoch: 6| Step: 7
Training loss: 3.010162307570793
Validation loss: 2.5870886396965997

Epoch: 6| Step: 8
Training loss: 2.6567581588262312
Validation loss: 2.5906545505465925

Epoch: 6| Step: 9
Training loss: 2.787330581237899
Validation loss: 2.593469931046595

Epoch: 6| Step: 10
Training loss: 2.739460254607149
Validation loss: 2.593210256345736

Epoch: 6| Step: 11
Training loss: 2.75599865794599
Validation loss: 2.5869318321209636

Epoch: 6| Step: 12
Training loss: 2.904346786306166
Validation loss: 2.593422922583586

Epoch: 6| Step: 13
Training loss: 2.7408950237670604
Validation loss: 2.6015914476375546

Epoch: 373| Step: 0
Training loss: 2.6671108134262007
Validation loss: 2.609241008849091

Epoch: 6| Step: 1
Training loss: 3.4388203252703082
Validation loss: 2.6104760099786954

Epoch: 6| Step: 2
Training loss: 3.0375630815651062
Validation loss: 2.603467585754632

Epoch: 6| Step: 3
Training loss: 2.394698617882739
Validation loss: 2.608477932390988

Epoch: 6| Step: 4
Training loss: 3.0855491683570886
Validation loss: 2.6075891970537883

Epoch: 6| Step: 5
Training loss: 3.1738936291317277
Validation loss: 2.613357068775034

Epoch: 6| Step: 6
Training loss: 2.8210566587711545
Validation loss: 2.639621218359045

Epoch: 6| Step: 7
Training loss: 2.525147983255894
Validation loss: 2.64501486874978

Epoch: 6| Step: 8
Training loss: 3.608133474076042
Validation loss: 2.6604082407017193

Epoch: 6| Step: 9
Training loss: 3.0808994550336055
Validation loss: 2.644767531708941

Epoch: 6| Step: 10
Training loss: 2.2153113139081144
Validation loss: 2.628560018053685

Epoch: 6| Step: 11
Training loss: 2.7837633927583667
Validation loss: 2.6233276425098584

Epoch: 6| Step: 12
Training loss: 3.1180134302893636
Validation loss: 2.6032798858592345

Epoch: 6| Step: 13
Training loss: 2.2466243216752817
Validation loss: 2.595246794539858

Epoch: 374| Step: 0
Training loss: 2.7587384190595023
Validation loss: 2.5956733650240946

Epoch: 6| Step: 1
Training loss: 2.879563897016267
Validation loss: 2.5948382003822514

Epoch: 6| Step: 2
Training loss: 3.0647515564334302
Validation loss: 2.595987634953688

Epoch: 6| Step: 3
Training loss: 2.4924205324289948
Validation loss: 2.5835393915419305

Epoch: 6| Step: 4
Training loss: 2.9301158541015115
Validation loss: 2.5865261110745448

Epoch: 6| Step: 5
Training loss: 2.4441776262469634
Validation loss: 2.5844508091851117

Epoch: 6| Step: 6
Training loss: 2.9137008483485385
Validation loss: 2.590824607956045

Epoch: 6| Step: 7
Training loss: 3.62964779408841
Validation loss: 2.584575335328483

Epoch: 6| Step: 8
Training loss: 2.650034915046282
Validation loss: 2.6007836702949563

Epoch: 6| Step: 9
Training loss: 3.259275258952985
Validation loss: 2.6023733130776994

Epoch: 6| Step: 10
Training loss: 2.9768522827383674
Validation loss: 2.6060655541343634

Epoch: 6| Step: 11
Training loss: 3.1981129208132195
Validation loss: 2.594821879937751

Epoch: 6| Step: 12
Training loss: 2.4663060319880032
Validation loss: 2.597571925471498

Epoch: 6| Step: 13
Training loss: 2.8067393328697667
Validation loss: 2.607380907309056

Epoch: 375| Step: 0
Training loss: 2.7319729963227526
Validation loss: 2.6247202474632805

Epoch: 6| Step: 1
Training loss: 2.7646273952749203
Validation loss: 2.6310104181931027

Epoch: 6| Step: 2
Training loss: 2.7411559683435827
Validation loss: 2.6471571936563874

Epoch: 6| Step: 3
Training loss: 3.155247595211026
Validation loss: 2.6828222141743017

Epoch: 6| Step: 4
Training loss: 3.2279252321927263
Validation loss: 2.716318780590839

Epoch: 6| Step: 5
Training loss: 2.8248497982098604
Validation loss: 2.72548489722771

Epoch: 6| Step: 6
Training loss: 2.937997004892421
Validation loss: 2.7220628144959895

Epoch: 6| Step: 7
Training loss: 2.8835139054514944
Validation loss: 2.6725444337670803

Epoch: 6| Step: 8
Training loss: 3.407579075209935
Validation loss: 2.6551582732555934

Epoch: 6| Step: 9
Training loss: 2.896585289090431
Validation loss: 2.630217178965026

Epoch: 6| Step: 10
Training loss: 3.302031042284646
Validation loss: 2.6081200762106036

Epoch: 6| Step: 11
Training loss: 2.5584492183951375
Validation loss: 2.5981991096020463

Epoch: 6| Step: 12
Training loss: 2.769739140508294
Validation loss: 2.5860383498901687

Epoch: 6| Step: 13
Training loss: 2.572260156392488
Validation loss: 2.585383638296244

Epoch: 376| Step: 0
Training loss: 3.398303360319641
Validation loss: 2.5828920742390733

Epoch: 6| Step: 1
Training loss: 2.5680538561453
Validation loss: 2.584427468544875

Epoch: 6| Step: 2
Training loss: 3.224717025762142
Validation loss: 2.5856588354958134

Epoch: 6| Step: 3
Training loss: 3.111595702653618
Validation loss: 2.589067264905277

Epoch: 6| Step: 4
Training loss: 2.807664571611019
Validation loss: 2.5889224917030376

Epoch: 6| Step: 5
Training loss: 3.2116526157749474
Validation loss: 2.592751094307104

Epoch: 6| Step: 6
Training loss: 1.9697706816180993
Validation loss: 2.593748894977989

Epoch: 6| Step: 7
Training loss: 3.1528531670951185
Validation loss: 2.6036051391301496

Epoch: 6| Step: 8
Training loss: 2.7768930318943683
Validation loss: 2.6199170516456403

Epoch: 6| Step: 9
Training loss: 2.621530874445576
Validation loss: 2.6046326208515236

Epoch: 6| Step: 10
Training loss: 2.552034265993681
Validation loss: 2.6448229678231727

Epoch: 6| Step: 11
Training loss: 2.993270638141359
Validation loss: 2.64793030227263

Epoch: 6| Step: 12
Training loss: 3.122808527245844
Validation loss: 2.6418203352339784

Epoch: 6| Step: 13
Training loss: 3.260391641506563
Validation loss: 2.6500904354174524

Epoch: 377| Step: 0
Training loss: 2.594671062870882
Validation loss: 2.636484751585991

Epoch: 6| Step: 1
Training loss: 3.2790633408692513
Validation loss: 2.6278960205533064

Epoch: 6| Step: 2
Training loss: 2.6294113512838293
Validation loss: 2.606376775927506

Epoch: 6| Step: 3
Training loss: 2.8701507472944385
Validation loss: 2.6060589779531753

Epoch: 6| Step: 4
Training loss: 2.51111990759255
Validation loss: 2.6000132260250424

Epoch: 6| Step: 5
Training loss: 3.657603477948956
Validation loss: 2.5884649638783874

Epoch: 6| Step: 6
Training loss: 2.9345166904418747
Validation loss: 2.594094152903789

Epoch: 6| Step: 7
Training loss: 2.4070871061278227
Validation loss: 2.5847466179123217

Epoch: 6| Step: 8
Training loss: 3.0875233884844464
Validation loss: 2.5834455134963084

Epoch: 6| Step: 9
Training loss: 3.0766818153722024
Validation loss: 2.59328588886718

Epoch: 6| Step: 10
Training loss: 2.5706943587747983
Validation loss: 2.5880686280538083

Epoch: 6| Step: 11
Training loss: 2.587887861142392
Validation loss: 2.5946979216304897

Epoch: 6| Step: 12
Training loss: 2.8980242082362664
Validation loss: 2.5895112806296714

Epoch: 6| Step: 13
Training loss: 3.6586077008662587
Validation loss: 2.588194856164777

Epoch: 378| Step: 0
Training loss: 3.287892330532259
Validation loss: 2.5939454470692596

Epoch: 6| Step: 1
Training loss: 3.2406527276172596
Validation loss: 2.594680128128547

Epoch: 6| Step: 2
Training loss: 2.8726528372081646
Validation loss: 2.599147890249827

Epoch: 6| Step: 3
Training loss: 2.799132900853953
Validation loss: 2.6145160694014384

Epoch: 6| Step: 4
Training loss: 2.7953644834560363
Validation loss: 2.6290947462982976

Epoch: 6| Step: 5
Training loss: 2.780912057297455
Validation loss: 2.653345677086388

Epoch: 6| Step: 6
Training loss: 3.1266121329924794
Validation loss: 2.6661398569796053

Epoch: 6| Step: 7
Training loss: 3.3577419836309184
Validation loss: 2.675749997862989

Epoch: 6| Step: 8
Training loss: 3.0083760315743566
Validation loss: 2.671702994146205

Epoch: 6| Step: 9
Training loss: 2.5327872800424482
Validation loss: 2.652779855462292

Epoch: 6| Step: 10
Training loss: 2.541297375058697
Validation loss: 2.647385802982739

Epoch: 6| Step: 11
Training loss: 2.7616053103359435
Validation loss: 2.6182855948726944

Epoch: 6| Step: 12
Training loss: 2.8254102459667543
Validation loss: 2.612787438279003

Epoch: 6| Step: 13
Training loss: 2.7341945915652524
Validation loss: 2.5950963518765158

Epoch: 379| Step: 0
Training loss: 2.6887434810628568
Validation loss: 2.598463962640123

Epoch: 6| Step: 1
Training loss: 2.991599401144597
Validation loss: 2.5871894466965855

Epoch: 6| Step: 2
Training loss: 3.244456331530297
Validation loss: 2.5865351503653686

Epoch: 6| Step: 3
Training loss: 2.997424450607082
Validation loss: 2.5855145417230743

Epoch: 6| Step: 4
Training loss: 2.444675350361383
Validation loss: 2.588880550966945

Epoch: 6| Step: 5
Training loss: 2.872923391296026
Validation loss: 2.5839008831887

Epoch: 6| Step: 6
Training loss: 2.8087715867235445
Validation loss: 2.5885568247226853

Epoch: 6| Step: 7
Training loss: 2.8538927564033076
Validation loss: 2.5883342185815033

Epoch: 6| Step: 8
Training loss: 2.9838320253154085
Validation loss: 2.579011087544204

Epoch: 6| Step: 9
Training loss: 2.7360785708829565
Validation loss: 2.5849368199580685

Epoch: 6| Step: 10
Training loss: 2.968295253257373
Validation loss: 2.592962237059928

Epoch: 6| Step: 11
Training loss: 2.449066887486899
Validation loss: 2.588253726635036

Epoch: 6| Step: 12
Training loss: 3.6921742442664343
Validation loss: 2.594001875408495

Epoch: 6| Step: 13
Training loss: 3.137840592944606
Validation loss: 2.6020186765624644

Epoch: 380| Step: 0
Training loss: 2.803057523699907
Validation loss: 2.60710456825166

Epoch: 6| Step: 1
Training loss: 2.770887293087038
Validation loss: 2.6224617549834868

Epoch: 6| Step: 2
Training loss: 2.1323256163945215
Validation loss: 2.6232347212308773

Epoch: 6| Step: 3
Training loss: 3.400851950774815
Validation loss: 2.6508470882877684

Epoch: 6| Step: 4
Training loss: 2.603506925300778
Validation loss: 2.6750213839933896

Epoch: 6| Step: 5
Training loss: 2.5134777121556446
Validation loss: 2.69632195819315

Epoch: 6| Step: 6
Training loss: 2.9429585488317027
Validation loss: 2.7146349674592383

Epoch: 6| Step: 7
Training loss: 3.5496229374465784
Validation loss: 2.768298818560741

Epoch: 6| Step: 8
Training loss: 3.0150357792440987
Validation loss: 2.7467252235485673

Epoch: 6| Step: 9
Training loss: 2.776524333015321
Validation loss: 2.707422207018776

Epoch: 6| Step: 10
Training loss: 3.3308475444516943
Validation loss: 2.6509918537646096

Epoch: 6| Step: 11
Training loss: 3.0283914832615535
Validation loss: 2.6267843729993468

Epoch: 6| Step: 12
Training loss: 3.1015747992514324
Validation loss: 2.606318941382671

Epoch: 6| Step: 13
Training loss: 3.1457042709721774
Validation loss: 2.5970516162692387

Epoch: 381| Step: 0
Training loss: 2.1077601149873635
Validation loss: 2.5934309394377744

Epoch: 6| Step: 1
Training loss: 2.8979537848136943
Validation loss: 2.591592777460965

Epoch: 6| Step: 2
Training loss: 3.1652258723988753
Validation loss: 2.592655594935619

Epoch: 6| Step: 3
Training loss: 2.663391565761287
Validation loss: 2.5840119539988415

Epoch: 6| Step: 4
Training loss: 2.62043710775152
Validation loss: 2.585675830475629

Epoch: 6| Step: 5
Training loss: 3.766301137916963
Validation loss: 2.587818722135242

Epoch: 6| Step: 6
Training loss: 3.8181892844948697
Validation loss: 2.5797634244737

Epoch: 6| Step: 7
Training loss: 2.551000518487738
Validation loss: 2.583795494897771

Epoch: 6| Step: 8
Training loss: 2.961907300931946
Validation loss: 2.574992047584425

Epoch: 6| Step: 9
Training loss: 2.8644990295951853
Validation loss: 2.5768177047942338

Epoch: 6| Step: 10
Training loss: 2.6515280546559725
Validation loss: 2.578206801025689

Epoch: 6| Step: 11
Training loss: 2.9193378387483775
Validation loss: 2.5753328250242964

Epoch: 6| Step: 12
Training loss: 2.700737576935726
Validation loss: 2.5819224779828933

Epoch: 6| Step: 13
Training loss: 2.7369094873639326
Validation loss: 2.577768132434601

Epoch: 382| Step: 0
Training loss: 2.9311048004041322
Validation loss: 2.5817203553922963

Epoch: 6| Step: 1
Training loss: 2.825123833161827
Validation loss: 2.585029819721397

Epoch: 6| Step: 2
Training loss: 2.6138107151184022
Validation loss: 2.5897129099842995

Epoch: 6| Step: 3
Training loss: 2.4879575605667297
Validation loss: 2.5811892876674127

Epoch: 6| Step: 4
Training loss: 3.4199171344020542
Validation loss: 2.594445434458956

Epoch: 6| Step: 5
Training loss: 3.0372825450530425
Validation loss: 2.5945899819954468

Epoch: 6| Step: 6
Training loss: 3.1170147917283018
Validation loss: 2.600200213255962

Epoch: 6| Step: 7
Training loss: 2.7809900740988502
Validation loss: 2.582754071841822

Epoch: 6| Step: 8
Training loss: 2.651038319124058
Validation loss: 2.5879500571306906

Epoch: 6| Step: 9
Training loss: 2.9549693650466593
Validation loss: 2.583608460504222

Epoch: 6| Step: 10
Training loss: 2.5804596473748114
Validation loss: 2.571583416418785

Epoch: 6| Step: 11
Training loss: 3.1558095794689
Validation loss: 2.583157217457739

Epoch: 6| Step: 12
Training loss: 3.340742808906245
Validation loss: 2.5790923738985914

Epoch: 6| Step: 13
Training loss: 2.574333037876954
Validation loss: 2.58838360540047

Epoch: 383| Step: 0
Training loss: 2.4277793530251257
Validation loss: 2.586522504269751

Epoch: 6| Step: 1
Training loss: 3.1695132929458043
Validation loss: 2.5915083426881407

Epoch: 6| Step: 2
Training loss: 3.222532549709242
Validation loss: 2.5886761581361277

Epoch: 6| Step: 3
Training loss: 2.8367279884652303
Validation loss: 2.595830827689846

Epoch: 6| Step: 4
Training loss: 3.011208101316007
Validation loss: 2.5960243474669054

Epoch: 6| Step: 5
Training loss: 2.825238688690088
Validation loss: 2.5945950300482625

Epoch: 6| Step: 6
Training loss: 3.046970463748871
Validation loss: 2.602920638405842

Epoch: 6| Step: 7
Training loss: 3.1046654387997172
Validation loss: 2.6121182046102893

Epoch: 6| Step: 8
Training loss: 3.4282938356647943
Validation loss: 2.616539291214025

Epoch: 6| Step: 9
Training loss: 2.7334350714318947
Validation loss: 2.6311729820320027

Epoch: 6| Step: 10
Training loss: 2.5271905442841347
Validation loss: 2.621261583237195

Epoch: 6| Step: 11
Training loss: 3.3981731443518504
Validation loss: 2.614474483339312

Epoch: 6| Step: 12
Training loss: 1.8153771551369335
Validation loss: 2.618445994868865

Epoch: 6| Step: 13
Training loss: 2.4136179295524753
Validation loss: 2.6135770836078263

Epoch: 384| Step: 0
Training loss: 3.1874338778949043
Validation loss: 2.601880904329111

Epoch: 6| Step: 1
Training loss: 3.0987308365266597
Validation loss: 2.6073679002004804

Epoch: 6| Step: 2
Training loss: 3.6607678532419383
Validation loss: 2.599599262856823

Epoch: 6| Step: 3
Training loss: 3.0068836710140188
Validation loss: 2.5951948632551103

Epoch: 6| Step: 4
Training loss: 2.7376101293141235
Validation loss: 2.590986493268056

Epoch: 6| Step: 5
Training loss: 2.2911503874940236
Validation loss: 2.593761224150387

Epoch: 6| Step: 6
Training loss: 2.421992735923502
Validation loss: 2.59334463684814

Epoch: 6| Step: 7
Training loss: 3.269557793257698
Validation loss: 2.585165563577933

Epoch: 6| Step: 8
Training loss: 2.296520387432382
Validation loss: 2.590264037763871

Epoch: 6| Step: 9
Training loss: 3.2030395496414625
Validation loss: 2.5778864596361797

Epoch: 6| Step: 10
Training loss: 2.750195843051978
Validation loss: 2.6009831267325083

Epoch: 6| Step: 11
Training loss: 2.5349225375888564
Validation loss: 2.5975831972580017

Epoch: 6| Step: 12
Training loss: 2.968432600220322
Validation loss: 2.585119815283156

Epoch: 6| Step: 13
Training loss: 2.872123274173792
Validation loss: 2.593398800698499

Epoch: 385| Step: 0
Training loss: 3.126646447377281
Validation loss: 2.5887663319476775

Epoch: 6| Step: 1
Training loss: 3.382993204342847
Validation loss: 2.5912451966757444

Epoch: 6| Step: 2
Training loss: 2.7165349947920214
Validation loss: 2.595892783990796

Epoch: 6| Step: 3
Training loss: 2.676340843772003
Validation loss: 2.5916238049709657

Epoch: 6| Step: 4
Training loss: 2.702346336802435
Validation loss: 2.598116993234702

Epoch: 6| Step: 5
Training loss: 3.1171657781393853
Validation loss: 2.598227435604434

Epoch: 6| Step: 6
Training loss: 3.2474250863518446
Validation loss: 2.592823105598539

Epoch: 6| Step: 7
Training loss: 3.1371866259671997
Validation loss: 2.5869667674880112

Epoch: 6| Step: 8
Training loss: 3.083849545817732
Validation loss: 2.5835773287955597

Epoch: 6| Step: 9
Training loss: 2.751691038215174
Validation loss: 2.574544246271134

Epoch: 6| Step: 10
Training loss: 2.544336188631052
Validation loss: 2.571177745189948

Epoch: 6| Step: 11
Training loss: 2.530190893819571
Validation loss: 2.570515280245411

Epoch: 6| Step: 12
Training loss: 2.684462760583161
Validation loss: 2.5722511755722404

Epoch: 6| Step: 13
Training loss: 2.682883889209926
Validation loss: 2.5736547217517587

Epoch: 386| Step: 0
Training loss: 2.7028376255638396
Validation loss: 2.5711212466731563

Epoch: 6| Step: 1
Training loss: 3.4181534548307635
Validation loss: 2.583362471673862

Epoch: 6| Step: 2
Training loss: 2.9195831612699936
Validation loss: 2.5845676976861243

Epoch: 6| Step: 3
Training loss: 3.167978533672084
Validation loss: 2.5853276792905686

Epoch: 6| Step: 4
Training loss: 3.076034378127521
Validation loss: 2.5905753657199444

Epoch: 6| Step: 5
Training loss: 2.35821504689404
Validation loss: 2.6111997978618566

Epoch: 6| Step: 6
Training loss: 2.6662118245685655
Validation loss: 2.61562191636669

Epoch: 6| Step: 7
Training loss: 3.1273174085610753
Validation loss: 2.6126967924216116

Epoch: 6| Step: 8
Training loss: 2.8297289941653285
Validation loss: 2.597330756145458

Epoch: 6| Step: 9
Training loss: 2.9121399947564433
Validation loss: 2.5948006648860242

Epoch: 6| Step: 10
Training loss: 2.5943805893203935
Validation loss: 2.5901037137156093

Epoch: 6| Step: 11
Training loss: 2.944062390122464
Validation loss: 2.580504306992087

Epoch: 6| Step: 12
Training loss: 2.783827284042886
Validation loss: 2.5852854283629036

Epoch: 6| Step: 13
Training loss: 3.081084866383499
Validation loss: 2.5805190976561816

Epoch: 387| Step: 0
Training loss: 2.7520079651262654
Validation loss: 2.586748864886313

Epoch: 6| Step: 1
Training loss: 3.0967497491384517
Validation loss: 2.6018633422320816

Epoch: 6| Step: 2
Training loss: 2.411371700524077
Validation loss: 2.616862936622967

Epoch: 6| Step: 3
Training loss: 3.2903239895915926
Validation loss: 2.6351378208747605

Epoch: 6| Step: 4
Training loss: 2.323744884237042
Validation loss: 2.651651025004094

Epoch: 6| Step: 5
Training loss: 2.9028935893520234
Validation loss: 2.636140225900242

Epoch: 6| Step: 6
Training loss: 2.5341746071119595
Validation loss: 2.6350394319482895

Epoch: 6| Step: 7
Training loss: 3.054729646748085
Validation loss: 2.630871548774343

Epoch: 6| Step: 8
Training loss: 3.053652849123722
Validation loss: 2.6129965249140477

Epoch: 6| Step: 9
Training loss: 2.730397672369317
Validation loss: 2.6043850337530077

Epoch: 6| Step: 10
Training loss: 3.24925663589583
Validation loss: 2.608116368536468

Epoch: 6| Step: 11
Training loss: 3.33270750528694
Validation loss: 2.599174996673755

Epoch: 6| Step: 12
Training loss: 2.9808568539294478
Validation loss: 2.5911947810413847

Epoch: 6| Step: 13
Training loss: 2.8635520234561898
Validation loss: 2.58160303707904

Epoch: 388| Step: 0
Training loss: 2.5180163656828523
Validation loss: 2.582623171438772

Epoch: 6| Step: 1
Training loss: 3.030108364672814
Validation loss: 2.5830699642177306

Epoch: 6| Step: 2
Training loss: 3.138253906373986
Validation loss: 2.5834619117624333

Epoch: 6| Step: 3
Training loss: 3.3063759965451274
Validation loss: 2.5887304295678675

Epoch: 6| Step: 4
Training loss: 2.973443427107532
Validation loss: 2.58202870525381

Epoch: 6| Step: 5
Training loss: 2.5466444227069363
Validation loss: 2.579920557445622

Epoch: 6| Step: 6
Training loss: 3.1806837016299583
Validation loss: 2.574484163609113

Epoch: 6| Step: 7
Training loss: 2.7980777136458457
Validation loss: 2.583297648532391

Epoch: 6| Step: 8
Training loss: 2.889658173405785
Validation loss: 2.586494265163403

Epoch: 6| Step: 9
Training loss: 3.0044444858236266
Validation loss: 2.586453020507993

Epoch: 6| Step: 10
Training loss: 3.377794451072879
Validation loss: 2.5890563768715493

Epoch: 6| Step: 11
Training loss: 2.893052190431846
Validation loss: 2.5872706643696097

Epoch: 6| Step: 12
Training loss: 2.464707553685693
Validation loss: 2.5908076328975858

Epoch: 6| Step: 13
Training loss: 1.6013406739480913
Validation loss: 2.585034719337819

Epoch: 389| Step: 0
Training loss: 2.9828349828497234
Validation loss: 2.594937993038929

Epoch: 6| Step: 1
Training loss: 2.6752071015234056
Validation loss: 2.5947628057689456

Epoch: 6| Step: 2
Training loss: 2.9022849322144078
Validation loss: 2.601681021073814

Epoch: 6| Step: 3
Training loss: 3.2798650816174253
Validation loss: 2.604391158897673

Epoch: 6| Step: 4
Training loss: 2.961958173303254
Validation loss: 2.5966518412191593

Epoch: 6| Step: 5
Training loss: 2.9624982359031864
Validation loss: 2.611549100015872

Epoch: 6| Step: 6
Training loss: 2.8659375867842574
Validation loss: 2.6003729609151858

Epoch: 6| Step: 7
Training loss: 2.1823527131081266
Validation loss: 2.604002232108002

Epoch: 6| Step: 8
Training loss: 2.989088241219042
Validation loss: 2.625670806835677

Epoch: 6| Step: 9
Training loss: 3.2452184275040583
Validation loss: 2.6272532923971497

Epoch: 6| Step: 10
Training loss: 2.633216894770498
Validation loss: 2.6466780500967144

Epoch: 6| Step: 11
Training loss: 2.95847413350335
Validation loss: 2.625733095924329

Epoch: 6| Step: 12
Training loss: 2.7182260644245346
Validation loss: 2.625862843109348

Epoch: 6| Step: 13
Training loss: 3.018074898429344
Validation loss: 2.6056539505953054

Epoch: 390| Step: 0
Training loss: 2.4492454223153937
Validation loss: 2.6281124585888755

Epoch: 6| Step: 1
Training loss: 3.032235997871793
Validation loss: 2.6148712384705517

Epoch: 6| Step: 2
Training loss: 2.7876701405693733
Validation loss: 2.622907368923853

Epoch: 6| Step: 3
Training loss: 2.566837826095773
Validation loss: 2.627757154350825

Epoch: 6| Step: 4
Training loss: 3.0573559591279897
Validation loss: 2.635624685512075

Epoch: 6| Step: 5
Training loss: 2.86904256820611
Validation loss: 2.617824044444664

Epoch: 6| Step: 6
Training loss: 3.0642147324020117
Validation loss: 2.622484650556742

Epoch: 6| Step: 7
Training loss: 3.3163238622993023
Validation loss: 2.6323906846717

Epoch: 6| Step: 8
Training loss: 2.722564914654572
Validation loss: 2.62730175052788

Epoch: 6| Step: 9
Training loss: 2.717456641531249
Validation loss: 2.601837854121425

Epoch: 6| Step: 10
Training loss: 2.478353244040505
Validation loss: 2.5844901158149596

Epoch: 6| Step: 11
Training loss: 3.096552648618147
Validation loss: 2.58931084743983

Epoch: 6| Step: 12
Training loss: 3.4125691165841414
Validation loss: 2.5915155750594296

Epoch: 6| Step: 13
Training loss: 2.844078296533259
Validation loss: 2.5839982091816904

Epoch: 391| Step: 0
Training loss: 2.631613891520135
Validation loss: 2.580372969567626

Epoch: 6| Step: 1
Training loss: 3.202131610441073
Validation loss: 2.586183608694841

Epoch: 6| Step: 2
Training loss: 3.0075553486868767
Validation loss: 2.590659299500918

Epoch: 6| Step: 3
Training loss: 2.5767023958868425
Validation loss: 2.588397832052506

Epoch: 6| Step: 4
Training loss: 2.7701679568549253
Validation loss: 2.5956357991352266

Epoch: 6| Step: 5
Training loss: 3.2087264047252235
Validation loss: 2.5938992467867843

Epoch: 6| Step: 6
Training loss: 3.0316342768967006
Validation loss: 2.604835116006357

Epoch: 6| Step: 7
Training loss: 3.3360740044067394
Validation loss: 2.6172471004306157

Epoch: 6| Step: 8
Training loss: 3.1271391604169585
Validation loss: 2.6243388607624296

Epoch: 6| Step: 9
Training loss: 2.838805542792609
Validation loss: 2.646476768782715

Epoch: 6| Step: 10
Training loss: 2.4819654379750604
Validation loss: 2.6369524408509353

Epoch: 6| Step: 11
Training loss: 2.7873523074312274
Validation loss: 2.6716426663676955

Epoch: 6| Step: 12
Training loss: 2.6579779894673083
Validation loss: 2.6579100235882014

Epoch: 6| Step: 13
Training loss: 2.8488241346554393
Validation loss: 2.661518209351502

Epoch: 392| Step: 0
Training loss: 2.626554846085851
Validation loss: 2.6359952808396208

Epoch: 6| Step: 1
Training loss: 3.2204768909323502
Validation loss: 2.6374020957456317

Epoch: 6| Step: 2
Training loss: 2.637122907393345
Validation loss: 2.6408373611453597

Epoch: 6| Step: 3
Training loss: 3.3195271359779754
Validation loss: 2.6478343793186343

Epoch: 6| Step: 4
Training loss: 3.2501308708250862
Validation loss: 2.6537341987785874

Epoch: 6| Step: 5
Training loss: 2.559842476170676
Validation loss: 2.6500311131662135

Epoch: 6| Step: 6
Training loss: 2.9012039842288697
Validation loss: 2.6213296074085553

Epoch: 6| Step: 7
Training loss: 3.013052836616085
Validation loss: 2.608828621950947

Epoch: 6| Step: 8
Training loss: 3.3912592000305715
Validation loss: 2.6072360369617265

Epoch: 6| Step: 9
Training loss: 3.0564331374266263
Validation loss: 2.590530590754318

Epoch: 6| Step: 10
Training loss: 3.2104375965212633
Validation loss: 2.592508340315598

Epoch: 6| Step: 11
Training loss: 2.5711612865256286
Validation loss: 2.5822389069353746

Epoch: 6| Step: 12
Training loss: 2.225065564679019
Validation loss: 2.5761348497145966

Epoch: 6| Step: 13
Training loss: 1.8900193434436878
Validation loss: 2.5861951442329367

Epoch: 393| Step: 0
Training loss: 3.326817931926101
Validation loss: 2.5890613495677886

Epoch: 6| Step: 1
Training loss: 3.061604115763126
Validation loss: 2.589464815109321

Epoch: 6| Step: 2
Training loss: 2.8487966841470844
Validation loss: 2.5994971333312358

Epoch: 6| Step: 3
Training loss: 2.8729429764311707
Validation loss: 2.606290291177962

Epoch: 6| Step: 4
Training loss: 2.277455976544367
Validation loss: 2.606169166392435

Epoch: 6| Step: 5
Training loss: 3.1417401360000037
Validation loss: 2.6246811213575163

Epoch: 6| Step: 6
Training loss: 2.6447467124537027
Validation loss: 2.6073467901809635

Epoch: 6| Step: 7
Training loss: 3.060858461723619
Validation loss: 2.612112276698229

Epoch: 6| Step: 8
Training loss: 2.7390988771293756
Validation loss: 2.626003011251798

Epoch: 6| Step: 9
Training loss: 2.7876843378672436
Validation loss: 2.6087224305335845

Epoch: 6| Step: 10
Training loss: 3.0039845073214093
Validation loss: 2.616420812195206

Epoch: 6| Step: 11
Training loss: 2.3899832468762456
Validation loss: 2.610976216856456

Epoch: 6| Step: 12
Training loss: 2.8258952418657115
Validation loss: 2.6055924782756015

Epoch: 6| Step: 13
Training loss: 3.605546514430872
Validation loss: 2.5997609025395834

Epoch: 394| Step: 0
Training loss: 2.6217468630518317
Validation loss: 2.6151865554316234

Epoch: 6| Step: 1
Training loss: 2.4878997749858724
Validation loss: 2.622640304069504

Epoch: 6| Step: 2
Training loss: 3.1440138112703933
Validation loss: 2.6078336939773825

Epoch: 6| Step: 3
Training loss: 3.1904540491589786
Validation loss: 2.599634281433385

Epoch: 6| Step: 4
Training loss: 2.4816410208205943
Validation loss: 2.5981218528766488

Epoch: 6| Step: 5
Training loss: 2.7889900946100994
Validation loss: 2.6004928296115852

Epoch: 6| Step: 6
Training loss: 2.767582260053368
Validation loss: 2.591108930331888

Epoch: 6| Step: 7
Training loss: 3.4422839081536396
Validation loss: 2.5972117098302947

Epoch: 6| Step: 8
Training loss: 2.910752940610799
Validation loss: 2.5928148278129797

Epoch: 6| Step: 9
Training loss: 3.501280686537835
Validation loss: 2.5888251428796725

Epoch: 6| Step: 10
Training loss: 2.3653198529145687
Validation loss: 2.6026872733940856

Epoch: 6| Step: 11
Training loss: 2.5981654076901597
Validation loss: 2.606552687430196

Epoch: 6| Step: 12
Training loss: 2.569447102130054
Validation loss: 2.6193133635808494

Epoch: 6| Step: 13
Training loss: 3.7090541839056423
Validation loss: 2.632438004249296

Epoch: 395| Step: 0
Training loss: 2.412302702905325
Validation loss: 2.6131300502711747

Epoch: 6| Step: 1
Training loss: 3.2817362107218027
Validation loss: 2.6151503800380613

Epoch: 6| Step: 2
Training loss: 3.0971907161218293
Validation loss: 2.6032811581860824

Epoch: 6| Step: 3
Training loss: 3.051087113798747
Validation loss: 2.5933343727540374

Epoch: 6| Step: 4
Training loss: 2.2643382660731426
Validation loss: 2.5838861803419646

Epoch: 6| Step: 5
Training loss: 2.4728066638196484
Validation loss: 2.586412072553609

Epoch: 6| Step: 6
Training loss: 2.661908932120487
Validation loss: 2.5747975165577377

Epoch: 6| Step: 7
Training loss: 2.9870555084148607
Validation loss: 2.5696881488438885

Epoch: 6| Step: 8
Training loss: 2.752756557859703
Validation loss: 2.573058883471659

Epoch: 6| Step: 9
Training loss: 3.2718105597649227
Validation loss: 2.5675645637528186

Epoch: 6| Step: 10
Training loss: 2.4758494219989626
Validation loss: 2.575711625415196

Epoch: 6| Step: 11
Training loss: 3.273803399150453
Validation loss: 2.5901806870063244

Epoch: 6| Step: 12
Training loss: 3.5064542387909974
Validation loss: 2.5841057112661137

Epoch: 6| Step: 13
Training loss: 2.569799308213984
Validation loss: 2.5971733627021334

Epoch: 396| Step: 0
Training loss: 2.144313446824797
Validation loss: 2.5960904348048954

Epoch: 6| Step: 1
Training loss: 2.5773995043368916
Validation loss: 2.6134936896591454

Epoch: 6| Step: 2
Training loss: 2.4555101401481445
Validation loss: 2.6290904753395883

Epoch: 6| Step: 3
Training loss: 2.8813691286296383
Validation loss: 2.6417570319233783

Epoch: 6| Step: 4
Training loss: 2.7482472816383745
Validation loss: 2.6644259243334893

Epoch: 6| Step: 5
Training loss: 2.7516485821387477
Validation loss: 2.6332169522115683

Epoch: 6| Step: 6
Training loss: 3.361556936984465
Validation loss: 2.627423947190395

Epoch: 6| Step: 7
Training loss: 3.0581341199584915
Validation loss: 2.6392424312785625

Epoch: 6| Step: 8
Training loss: 3.071430963534314
Validation loss: 2.599440313416364

Epoch: 6| Step: 9
Training loss: 3.003696865924676
Validation loss: 2.588165488278407

Epoch: 6| Step: 10
Training loss: 2.7078169305922533
Validation loss: 2.5821691500469397

Epoch: 6| Step: 11
Training loss: 3.3716473351410103
Validation loss: 2.570347229381685

Epoch: 6| Step: 12
Training loss: 3.182496875362855
Validation loss: 2.571279629624912

Epoch: 6| Step: 13
Training loss: 3.0715786019622264
Validation loss: 2.5691737676421256

Epoch: 397| Step: 0
Training loss: 2.5634665178374636
Validation loss: 2.5669032556617126

Epoch: 6| Step: 1
Training loss: 3.000825927211101
Validation loss: 2.5710539671096684

Epoch: 6| Step: 2
Training loss: 2.8990168647920336
Validation loss: 2.5690444963903643

Epoch: 6| Step: 3
Training loss: 3.065610901530878
Validation loss: 2.5746156107522564

Epoch: 6| Step: 4
Training loss: 2.764777791922616
Validation loss: 2.569632742945198

Epoch: 6| Step: 5
Training loss: 2.6812785682845766
Validation loss: 2.5707064046030315

Epoch: 6| Step: 6
Training loss: 2.484232004716805
Validation loss: 2.5732405536188216

Epoch: 6| Step: 7
Training loss: 3.148841396578765
Validation loss: 2.572044587120256

Epoch: 6| Step: 8
Training loss: 2.8250435749845564
Validation loss: 2.583855167071912

Epoch: 6| Step: 9
Training loss: 3.0026517910032684
Validation loss: 2.5811937828927216

Epoch: 6| Step: 10
Training loss: 3.528187191518959
Validation loss: 2.5840580125921937

Epoch: 6| Step: 11
Training loss: 3.2418789268633135
Validation loss: 2.585268638068215

Epoch: 6| Step: 12
Training loss: 2.5871358900915986
Validation loss: 2.5834491980295575

Epoch: 6| Step: 13
Training loss: 2.3689905733924967
Validation loss: 2.5784444373033684

Epoch: 398| Step: 0
Training loss: 3.3250721285461133
Validation loss: 2.584176123213423

Epoch: 6| Step: 1
Training loss: 3.143485365663506
Validation loss: 2.590708123471499

Epoch: 6| Step: 2
Training loss: 2.1204498044157694
Validation loss: 2.6040090172743215

Epoch: 6| Step: 3
Training loss: 2.714616637026847
Validation loss: 2.607830839187793

Epoch: 6| Step: 4
Training loss: 2.966219013886582
Validation loss: 2.6059044894852827

Epoch: 6| Step: 5
Training loss: 2.839964978176757
Validation loss: 2.6134545838206225

Epoch: 6| Step: 6
Training loss: 2.6431321199889046
Validation loss: 2.6211769138858703

Epoch: 6| Step: 7
Training loss: 2.780931004436163
Validation loss: 2.611384026539595

Epoch: 6| Step: 8
Training loss: 3.1077065136665416
Validation loss: 2.606855856837646

Epoch: 6| Step: 9
Training loss: 2.8855781005062218
Validation loss: 2.601017819161067

Epoch: 6| Step: 10
Training loss: 2.853238885451264
Validation loss: 2.5841231261868267

Epoch: 6| Step: 11
Training loss: 2.9751213369549303
Validation loss: 2.585225694003593

Epoch: 6| Step: 12
Training loss: 3.106015945305213
Validation loss: 2.574417510169219

Epoch: 6| Step: 13
Training loss: 2.8119004352247585
Validation loss: 2.577837379896232

Epoch: 399| Step: 0
Training loss: 3.494022169072307
Validation loss: 2.5730624254567434

Epoch: 6| Step: 1
Training loss: 2.7741804820165825
Validation loss: 2.570205528161998

Epoch: 6| Step: 2
Training loss: 2.502362565450112
Validation loss: 2.563762343861295

Epoch: 6| Step: 3
Training loss: 3.1039822073456005
Validation loss: 2.576679706389525

Epoch: 6| Step: 4
Training loss: 2.719507396914478
Validation loss: 2.580493294409389

Epoch: 6| Step: 5
Training loss: 2.7316509519927594
Validation loss: 2.579427466308345

Epoch: 6| Step: 6
Training loss: 2.8990124237647015
Validation loss: 2.5703495652698374

Epoch: 6| Step: 7
Training loss: 2.7244058293704905
Validation loss: 2.5836659818336187

Epoch: 6| Step: 8
Training loss: 2.83396317456319
Validation loss: 2.5784798873511505

Epoch: 6| Step: 9
Training loss: 2.784530248284849
Validation loss: 2.582967275419316

Epoch: 6| Step: 10
Training loss: 3.161340517533322
Validation loss: 2.595025347117336

Epoch: 6| Step: 11
Training loss: 3.2067032343100554
Validation loss: 2.5994757029784474

Epoch: 6| Step: 12
Training loss: 2.855872338366916
Validation loss: 2.6041139232257513

Epoch: 6| Step: 13
Training loss: 2.251330935703515
Validation loss: 2.6014747623310837

Epoch: 400| Step: 0
Training loss: 2.807513500123418
Validation loss: 2.6024158845348158

Epoch: 6| Step: 1
Training loss: 2.513263802650137
Validation loss: 2.5951816982608773

Epoch: 6| Step: 2
Training loss: 3.472822942691461
Validation loss: 2.6045310755253026

Epoch: 6| Step: 3
Training loss: 2.7369834447380237
Validation loss: 2.5905368906669692

Epoch: 6| Step: 4
Training loss: 3.1077612901920904
Validation loss: 2.5801034157168403

Epoch: 6| Step: 5
Training loss: 2.8033299467933452
Validation loss: 2.580317374819843

Epoch: 6| Step: 6
Training loss: 2.4474567603557444
Validation loss: 2.5713946213998304

Epoch: 6| Step: 7
Training loss: 2.93535925594923
Validation loss: 2.607169266541239

Epoch: 6| Step: 8
Training loss: 2.5026759131736163
Validation loss: 2.589645105658931

Epoch: 6| Step: 9
Training loss: 3.0836525485471173
Validation loss: 2.6015217130046104

Epoch: 6| Step: 10
Training loss: 2.744219513434565
Validation loss: 2.5880333945389484

Epoch: 6| Step: 11
Training loss: 2.8108481748678997
Validation loss: 2.596907591248443

Epoch: 6| Step: 12
Training loss: 3.216484087043203
Validation loss: 2.6008047606429394

Epoch: 6| Step: 13
Training loss: 3.14474945259044
Validation loss: 2.5904638281560337

Epoch: 401| Step: 0
Training loss: 2.974770314301856
Validation loss: 2.59802988717479

Epoch: 6| Step: 1
Training loss: 3.3496092326439473
Validation loss: 2.59916395667429

Epoch: 6| Step: 2
Training loss: 2.375245232218663
Validation loss: 2.595927046716048

Epoch: 6| Step: 3
Training loss: 2.9749084843255775
Validation loss: 2.5977970755905613

Epoch: 6| Step: 4
Training loss: 2.7692165007590455
Validation loss: 2.5823176713187315

Epoch: 6| Step: 5
Training loss: 2.5720990589756356
Validation loss: 2.581256385490816

Epoch: 6| Step: 6
Training loss: 2.8639691243452043
Validation loss: 2.5672180966461493

Epoch: 6| Step: 7
Training loss: 3.3708682730757533
Validation loss: 2.5691899756090675

Epoch: 6| Step: 8
Training loss: 2.4335834631541715
Validation loss: 2.562667166927032

Epoch: 6| Step: 9
Training loss: 3.272816601410737
Validation loss: 2.5613852116189086

Epoch: 6| Step: 10
Training loss: 2.896546273782297
Validation loss: 2.5664349039284673

Epoch: 6| Step: 11
Training loss: 2.78656945883419
Validation loss: 2.5699861595288986

Epoch: 6| Step: 12
Training loss: 2.778438561576286
Validation loss: 2.577291091886162

Epoch: 6| Step: 13
Training loss: 2.7196774709438385
Validation loss: 2.5788621054458436

Epoch: 402| Step: 0
Training loss: 2.288700634993282
Validation loss: 2.5769128977367775

Epoch: 6| Step: 1
Training loss: 2.8317106499566873
Validation loss: 2.5948073703747143

Epoch: 6| Step: 2
Training loss: 3.090493385899108
Validation loss: 2.612708131420834

Epoch: 6| Step: 3
Training loss: 2.0187599583430367
Validation loss: 2.640498326780089

Epoch: 6| Step: 4
Training loss: 3.145416400555854
Validation loss: 2.667246604226263

Epoch: 6| Step: 5
Training loss: 2.7279094003472117
Validation loss: 2.6753337172375926

Epoch: 6| Step: 6
Training loss: 2.895543877568397
Validation loss: 2.675676446258488

Epoch: 6| Step: 7
Training loss: 3.207166104379619
Validation loss: 2.6730982938857264

Epoch: 6| Step: 8
Training loss: 3.0162077819930233
Validation loss: 2.644870919885644

Epoch: 6| Step: 9
Training loss: 3.19401900918424
Validation loss: 2.6128028821623266

Epoch: 6| Step: 10
Training loss: 2.8297185465364403
Validation loss: 2.6217044549034654

Epoch: 6| Step: 11
Training loss: 2.582450705664346
Validation loss: 2.603113100287902

Epoch: 6| Step: 12
Training loss: 3.1725995218164673
Validation loss: 2.5903693103468908

Epoch: 6| Step: 13
Training loss: 3.400081403543188
Validation loss: 2.56989210061805

Epoch: 403| Step: 0
Training loss: 2.52985202190693
Validation loss: 2.5655700557003867

Epoch: 6| Step: 1
Training loss: 2.6652943735918533
Validation loss: 2.5567546508111967

Epoch: 6| Step: 2
Training loss: 2.9178494552881897
Validation loss: 2.5626833770311026

Epoch: 6| Step: 3
Training loss: 2.8383062889197985
Validation loss: 2.55711965072396

Epoch: 6| Step: 4
Training loss: 2.770630353409999
Validation loss: 2.560384357725512

Epoch: 6| Step: 5
Training loss: 2.7420045623184857
Validation loss: 2.5561223414388907

Epoch: 6| Step: 6
Training loss: 2.9576101001099624
Validation loss: 2.5619993353517794

Epoch: 6| Step: 7
Training loss: 2.5532864803202044
Validation loss: 2.56705366682839

Epoch: 6| Step: 8
Training loss: 3.3010993397951975
Validation loss: 2.572490762671883

Epoch: 6| Step: 9
Training loss: 2.9682083438844176
Validation loss: 2.5723665255493975

Epoch: 6| Step: 10
Training loss: 3.1179831500426993
Validation loss: 2.583550972624415

Epoch: 6| Step: 11
Training loss: 3.1032196921722672
Validation loss: 2.5806467877916113

Epoch: 6| Step: 12
Training loss: 2.7818068043413238
Validation loss: 2.595028210066814

Epoch: 6| Step: 13
Training loss: 3.235801787503031
Validation loss: 2.6002427197271003

Epoch: 404| Step: 0
Training loss: 3.317218658545299
Validation loss: 2.5969918129660527

Epoch: 6| Step: 1
Training loss: 3.4780061960280313
Validation loss: 2.6102078519562792

Epoch: 6| Step: 2
Training loss: 2.9956117961042588
Validation loss: 2.6169137355125036

Epoch: 6| Step: 3
Training loss: 2.5959136395306697
Validation loss: 2.636044417563499

Epoch: 6| Step: 4
Training loss: 3.1225359548265526
Validation loss: 2.6518219223612167

Epoch: 6| Step: 5
Training loss: 3.019503456372732
Validation loss: 2.6706790642688056

Epoch: 6| Step: 6
Training loss: 2.6696295867750486
Validation loss: 2.652274839411091

Epoch: 6| Step: 7
Training loss: 2.158892353181824
Validation loss: 2.6411575709428274

Epoch: 6| Step: 8
Training loss: 3.0801515056453783
Validation loss: 2.594467722053529

Epoch: 6| Step: 9
Training loss: 2.738637163701007
Validation loss: 2.585419389827529

Epoch: 6| Step: 10
Training loss: 2.4383219775728344
Validation loss: 2.5748317174882622

Epoch: 6| Step: 11
Training loss: 3.1583984918507664
Validation loss: 2.560973022849638

Epoch: 6| Step: 12
Training loss: 2.6726483569883084
Validation loss: 2.556933401707568

Epoch: 6| Step: 13
Training loss: 2.694397701980988
Validation loss: 2.5563996687461894

Epoch: 405| Step: 0
Training loss: 2.899288247996515
Validation loss: 2.5554536311223393

Epoch: 6| Step: 1
Training loss: 2.67090290076181
Validation loss: 2.561994540277381

Epoch: 6| Step: 2
Training loss: 3.2007756246899555
Validation loss: 2.5641167065468626

Epoch: 6| Step: 3
Training loss: 3.2235521955327817
Validation loss: 2.5547891359337704

Epoch: 6| Step: 4
Training loss: 2.986203577152639
Validation loss: 2.5590439858162184

Epoch: 6| Step: 5
Training loss: 3.081920626628845
Validation loss: 2.5594719244000506

Epoch: 6| Step: 6
Training loss: 2.8076681381246487
Validation loss: 2.551331230744616

Epoch: 6| Step: 7
Training loss: 3.2942853402080945
Validation loss: 2.5694824817535538

Epoch: 6| Step: 8
Training loss: 3.0684902228823874
Validation loss: 2.559206929799123

Epoch: 6| Step: 9
Training loss: 2.1594400443012165
Validation loss: 2.5673906929846497

Epoch: 6| Step: 10
Training loss: 2.6420574027618184
Validation loss: 2.5922541411062507

Epoch: 6| Step: 11
Training loss: 2.708784320157946
Validation loss: 2.6022494012014787

Epoch: 6| Step: 12
Training loss: 2.839418570948095
Validation loss: 2.601388935523697

Epoch: 6| Step: 13
Training loss: 2.6465658140144854
Validation loss: 2.6016709081142446

Epoch: 406| Step: 0
Training loss: 2.863044427130608
Validation loss: 2.607961604808518

Epoch: 6| Step: 1
Training loss: 2.6278429530930127
Validation loss: 2.5729330247592594

Epoch: 6| Step: 2
Training loss: 3.3807188960199355
Validation loss: 2.569608124369049

Epoch: 6| Step: 3
Training loss: 2.430076641553859
Validation loss: 2.560440007806964

Epoch: 6| Step: 4
Training loss: 2.4501848034350155
Validation loss: 2.5551428307393476

Epoch: 6| Step: 5
Training loss: 3.040908841002089
Validation loss: 2.5564702842260627

Epoch: 6| Step: 6
Training loss: 3.5346610549667328
Validation loss: 2.557615156727758

Epoch: 6| Step: 7
Training loss: 2.874606229933563
Validation loss: 2.5519996279428416

Epoch: 6| Step: 8
Training loss: 2.1231754548301955
Validation loss: 2.5550200498121876

Epoch: 6| Step: 9
Training loss: 3.286516014757693
Validation loss: 2.5528415667751387

Epoch: 6| Step: 10
Training loss: 2.416564040361735
Validation loss: 2.5545185092550455

Epoch: 6| Step: 11
Training loss: 3.2929264667733125
Validation loss: 2.5659103789809086

Epoch: 6| Step: 12
Training loss: 2.9386782616572895
Validation loss: 2.5702282648377888

Epoch: 6| Step: 13
Training loss: 2.6010867305259193
Validation loss: 2.5786829250574503

Epoch: 407| Step: 0
Training loss: 2.925620549554502
Validation loss: 2.5839417885902276

Epoch: 6| Step: 1
Training loss: 2.6700133145461122
Validation loss: 2.586167701522721

Epoch: 6| Step: 2
Training loss: 2.7930553076075992
Validation loss: 2.59466536186973

Epoch: 6| Step: 3
Training loss: 3.519731759341164
Validation loss: 2.5892702902259677

Epoch: 6| Step: 4
Training loss: 2.6318872110613034
Validation loss: 2.591240580378577

Epoch: 6| Step: 5
Training loss: 2.097089580807272
Validation loss: 2.5936275531852266

Epoch: 6| Step: 6
Training loss: 3.134108277797761
Validation loss: 2.5882112837706446

Epoch: 6| Step: 7
Training loss: 2.740853270329351
Validation loss: 2.579408774344816

Epoch: 6| Step: 8
Training loss: 2.69864199006568
Validation loss: 2.5779589040482365

Epoch: 6| Step: 9
Training loss: 2.838385752091026
Validation loss: 2.578627816815508

Epoch: 6| Step: 10
Training loss: 3.0477376645852163
Validation loss: 2.5785799044659643

Epoch: 6| Step: 11
Training loss: 2.710961773238773
Validation loss: 2.5793194273329485

Epoch: 6| Step: 12
Training loss: 3.292081267567012
Validation loss: 2.5775640598981537

Epoch: 6| Step: 13
Training loss: 3.0133368948124906
Validation loss: 2.583033538025896

Epoch: 408| Step: 0
Training loss: 2.5602186328689975
Validation loss: 2.58934771600292

Epoch: 6| Step: 1
Training loss: 3.228255965908047
Validation loss: 2.5991869006463686

Epoch: 6| Step: 2
Training loss: 1.8502944918095872
Validation loss: 2.5968605541909775

Epoch: 6| Step: 3
Training loss: 2.8492882425396533
Validation loss: 2.5896658531216206

Epoch: 6| Step: 4
Training loss: 3.15032342128414
Validation loss: 2.5804124028914788

Epoch: 6| Step: 5
Training loss: 2.4778588208552335
Validation loss: 2.573414723498439

Epoch: 6| Step: 6
Training loss: 2.6960905417172034
Validation loss: 2.558152592562106

Epoch: 6| Step: 7
Training loss: 2.9668881651524184
Validation loss: 2.5615389242430426

Epoch: 6| Step: 8
Training loss: 3.5271734152186776
Validation loss: 2.556033932641263

Epoch: 6| Step: 9
Training loss: 2.7330001426386876
Validation loss: 2.55055449957749

Epoch: 6| Step: 10
Training loss: 3.0281060028267617
Validation loss: 2.554394125647108

Epoch: 6| Step: 11
Training loss: 2.669841505625593
Validation loss: 2.5583843882933266

Epoch: 6| Step: 12
Training loss: 3.283840646294943
Validation loss: 2.561187872409834

Epoch: 6| Step: 13
Training loss: 3.154138595341918
Validation loss: 2.5673665262215444

Epoch: 409| Step: 0
Training loss: 2.7852223349672096
Validation loss: 2.5682095064734036

Epoch: 6| Step: 1
Training loss: 3.0188211689333304
Validation loss: 2.5701409247823626

Epoch: 6| Step: 2
Training loss: 2.7732547323691543
Validation loss: 2.570967637297771

Epoch: 6| Step: 3
Training loss: 3.122642696104013
Validation loss: 2.582313906742249

Epoch: 6| Step: 4
Training loss: 2.995992845330653
Validation loss: 2.5858941010879257

Epoch: 6| Step: 5
Training loss: 2.1600296507672305
Validation loss: 2.592234111583081

Epoch: 6| Step: 6
Training loss: 2.230984763400765
Validation loss: 2.602189617849569

Epoch: 6| Step: 7
Training loss: 4.201340988068269
Validation loss: 2.6125560585504086

Epoch: 6| Step: 8
Training loss: 2.8021721146332315
Validation loss: 2.6208124467832055

Epoch: 6| Step: 9
Training loss: 3.114134093752167
Validation loss: 2.5954505395481475

Epoch: 6| Step: 10
Training loss: 2.3418544988088623
Validation loss: 2.5998711705533175

Epoch: 6| Step: 11
Training loss: 2.0543928624076684
Validation loss: 2.597839565132781

Epoch: 6| Step: 12
Training loss: 2.9621830637923052
Validation loss: 2.5902938579083044

Epoch: 6| Step: 13
Training loss: 3.2422841253015027
Validation loss: 2.5906228701772007

Epoch: 410| Step: 0
Training loss: 3.2587693087785325
Validation loss: 2.5947034664516244

Epoch: 6| Step: 1
Training loss: 2.8727213910528797
Validation loss: 2.592321418323756

Epoch: 6| Step: 2
Training loss: 3.2074934780800834
Validation loss: 2.58887536402887

Epoch: 6| Step: 3
Training loss: 3.0937399815869195
Validation loss: 2.5697491661805882

Epoch: 6| Step: 4
Training loss: 1.8820304671080446
Validation loss: 2.576871706656816

Epoch: 6| Step: 5
Training loss: 2.6921476054542817
Validation loss: 2.571989529016742

Epoch: 6| Step: 6
Training loss: 2.900795031781158
Validation loss: 2.5661647361650695

Epoch: 6| Step: 7
Training loss: 2.937305038150787
Validation loss: 2.5761789200536467

Epoch: 6| Step: 8
Training loss: 2.5573857141877507
Validation loss: 2.579477191618961

Epoch: 6| Step: 9
Training loss: 3.1373378574983417
Validation loss: 2.576835416694184

Epoch: 6| Step: 10
Training loss: 3.1197309705702754
Validation loss: 2.5709911011296933

Epoch: 6| Step: 11
Training loss: 3.171912883663852
Validation loss: 2.5729108037072654

Epoch: 6| Step: 12
Training loss: 2.700329961747866
Validation loss: 2.5731765863553195

Epoch: 6| Step: 13
Training loss: 1.9698581301730926
Validation loss: 2.589539442285318

Epoch: 411| Step: 0
Training loss: 2.802508429481427
Validation loss: 2.596034420209011

Epoch: 6| Step: 1
Training loss: 2.6701995772161915
Validation loss: 2.6081509542867054

Epoch: 6| Step: 2
Training loss: 2.906748739127941
Validation loss: 2.617103263076058

Epoch: 6| Step: 3
Training loss: 2.4451149565150776
Validation loss: 2.629509677811382

Epoch: 6| Step: 4
Training loss: 3.5882882451828726
Validation loss: 2.627523911140984

Epoch: 6| Step: 5
Training loss: 2.894341136954217
Validation loss: 2.6368984482943287

Epoch: 6| Step: 6
Training loss: 3.0926604230713144
Validation loss: 2.6382207301657603

Epoch: 6| Step: 7
Training loss: 2.9230419419392426
Validation loss: 2.622985842554438

Epoch: 6| Step: 8
Training loss: 2.9517395968036997
Validation loss: 2.620869018550679

Epoch: 6| Step: 9
Training loss: 2.6671304796109574
Validation loss: 2.6282752075245632

Epoch: 6| Step: 10
Training loss: 2.289745242011746
Validation loss: 2.6495344043193154

Epoch: 6| Step: 11
Training loss: 2.7549489313228253
Validation loss: 2.687266673294857

Epoch: 6| Step: 12
Training loss: 2.8993615993380026
Validation loss: 2.6717985524019237

Epoch: 6| Step: 13
Training loss: 3.623824356437353
Validation loss: 2.664951804296158

Epoch: 412| Step: 0
Training loss: 3.353022330810746
Validation loss: 2.6496601695209665

Epoch: 6| Step: 1
Training loss: 2.703980238904355
Validation loss: 2.63342645677008

Epoch: 6| Step: 2
Training loss: 3.9022760547650615
Validation loss: 2.6142573202196617

Epoch: 6| Step: 3
Training loss: 3.165314452594129
Validation loss: 2.5943213479835054

Epoch: 6| Step: 4
Training loss: 3.0004119590196483
Validation loss: 2.568493253082964

Epoch: 6| Step: 5
Training loss: 2.8870581813191394
Validation loss: 2.5717544418358154

Epoch: 6| Step: 6
Training loss: 2.379195673332051
Validation loss: 2.560919483579949

Epoch: 6| Step: 7
Training loss: 2.232898357601263
Validation loss: 2.564315832835487

Epoch: 6| Step: 8
Training loss: 3.1050289586386106
Validation loss: 2.5554515294096434

Epoch: 6| Step: 9
Training loss: 2.8863540026668484
Validation loss: 2.55904804909853

Epoch: 6| Step: 10
Training loss: 2.6135952565575447
Validation loss: 2.557135574679351

Epoch: 6| Step: 11
Training loss: 2.10950633452541
Validation loss: 2.5696609498607863

Epoch: 6| Step: 12
Training loss: 3.0916182754993162
Validation loss: 2.576689232918432

Epoch: 6| Step: 13
Training loss: 2.604468020486865
Validation loss: 2.5777421882742373

Epoch: 413| Step: 0
Training loss: 3.0634471440749578
Validation loss: 2.5973175595349414

Epoch: 6| Step: 1
Training loss: 2.2593733200552406
Validation loss: 2.6243799867110242

Epoch: 6| Step: 2
Training loss: 3.2875729628904247
Validation loss: 2.630176386988954

Epoch: 6| Step: 3
Training loss: 2.716142741585883
Validation loss: 2.6031675207958185

Epoch: 6| Step: 4
Training loss: 2.8904984730015544
Validation loss: 2.599255241157294

Epoch: 6| Step: 5
Training loss: 2.7195239664499113
Validation loss: 2.5927831728505493

Epoch: 6| Step: 6
Training loss: 3.2232749761159494
Validation loss: 2.5881919093869428

Epoch: 6| Step: 7
Training loss: 3.435172246531793
Validation loss: 2.5886359653284656

Epoch: 6| Step: 8
Training loss: 2.597125143955658
Validation loss: 2.5905000855411564

Epoch: 6| Step: 9
Training loss: 2.88288858618258
Validation loss: 2.575557694582505

Epoch: 6| Step: 10
Training loss: 2.7057166932999204
Validation loss: 2.5721311668385445

Epoch: 6| Step: 11
Training loss: 2.6318188158939826
Validation loss: 2.571569735768258

Epoch: 6| Step: 12
Training loss: 2.9263258708518762
Validation loss: 2.5653428716150066

Epoch: 6| Step: 13
Training loss: 2.833633537844023
Validation loss: 2.565116896701072

Epoch: 414| Step: 0
Training loss: 2.6590989934506415
Validation loss: 2.56848265811588

Epoch: 6| Step: 1
Training loss: 2.919586427742398
Validation loss: 2.5852224354376365

Epoch: 6| Step: 2
Training loss: 2.636054965637164
Validation loss: 2.582796936899453

Epoch: 6| Step: 3
Training loss: 2.5346976454659567
Validation loss: 2.5998569110356473

Epoch: 6| Step: 4
Training loss: 3.2457555785229264
Validation loss: 2.594406703064225

Epoch: 6| Step: 5
Training loss: 3.1196643291760413
Validation loss: 2.603676765547848

Epoch: 6| Step: 6
Training loss: 3.048823745792819
Validation loss: 2.625210880026314

Epoch: 6| Step: 7
Training loss: 2.5559222769106085
Validation loss: 2.6473704727228413

Epoch: 6| Step: 8
Training loss: 2.6908193094977535
Validation loss: 2.6532797916546897

Epoch: 6| Step: 9
Training loss: 2.7261320719865307
Validation loss: 2.624649734489192

Epoch: 6| Step: 10
Training loss: 2.847059734225649
Validation loss: 2.5852726859155943

Epoch: 6| Step: 11
Training loss: 3.1955008229765105
Validation loss: 2.582954948320566

Epoch: 6| Step: 12
Training loss: 3.290643524958243
Validation loss: 2.5709087638846624

Epoch: 6| Step: 13
Training loss: 2.476665891781562
Validation loss: 2.5664561257097156

Epoch: 415| Step: 0
Training loss: 3.2334142170126143
Validation loss: 2.5561994744837553

Epoch: 6| Step: 1
Training loss: 2.0451851195323956
Validation loss: 2.568853997861684

Epoch: 6| Step: 2
Training loss: 2.121220762268235
Validation loss: 2.5703710948375447

Epoch: 6| Step: 3
Training loss: 3.056045113465223
Validation loss: 2.578965649567485

Epoch: 6| Step: 4
Training loss: 2.667834522897727
Validation loss: 2.584809222733912

Epoch: 6| Step: 5
Training loss: 2.8057698576087753
Validation loss: 2.5993379951862177

Epoch: 6| Step: 6
Training loss: 2.0824052142018985
Validation loss: 2.615880951002488

Epoch: 6| Step: 7
Training loss: 3.186599304998235
Validation loss: 2.638470938038992

Epoch: 6| Step: 8
Training loss: 3.0296121478731446
Validation loss: 2.6278568792955124

Epoch: 6| Step: 9
Training loss: 3.3768819577521207
Validation loss: 2.613897418872189

Epoch: 6| Step: 10
Training loss: 3.028589083576411
Validation loss: 2.611792371300564

Epoch: 6| Step: 11
Training loss: 3.2324267430571347
Validation loss: 2.61039120390554

Epoch: 6| Step: 12
Training loss: 3.520819052642813
Validation loss: 2.606375423472703

Epoch: 6| Step: 13
Training loss: 1.573145119284917
Validation loss: 2.5817108871482892

Epoch: 416| Step: 0
Training loss: 2.8679352910338003
Validation loss: 2.5673394843804314

Epoch: 6| Step: 1
Training loss: 3.0999176506671864
Validation loss: 2.560085832164117

Epoch: 6| Step: 2
Training loss: 3.353520743844375
Validation loss: 2.553830887292978

Epoch: 6| Step: 3
Training loss: 2.741643433245354
Validation loss: 2.5537072236123834

Epoch: 6| Step: 4
Training loss: 2.8291519576651494
Validation loss: 2.551684399168077

Epoch: 6| Step: 5
Training loss: 2.3546159253699654
Validation loss: 2.5557758087545306

Epoch: 6| Step: 6
Training loss: 2.9168458792714524
Validation loss: 2.5591960870240826

Epoch: 6| Step: 7
Training loss: 2.816353425735546
Validation loss: 2.5498015867634747

Epoch: 6| Step: 8
Training loss: 2.7080852003626283
Validation loss: 2.556527054380258

Epoch: 6| Step: 9
Training loss: 3.1559775961986043
Validation loss: 2.5628270906653174

Epoch: 6| Step: 10
Training loss: 3.3444486939778866
Validation loss: 2.5697294610573627

Epoch: 6| Step: 11
Training loss: 2.355322382540403
Validation loss: 2.576827078595915

Epoch: 6| Step: 12
Training loss: 2.6787366598120186
Validation loss: 2.5929953402291996

Epoch: 6| Step: 13
Training loss: 2.769397640906237
Validation loss: 2.590994519639741

Epoch: 417| Step: 0
Training loss: 3.3043937101604657
Validation loss: 2.609460718383899

Epoch: 6| Step: 1
Training loss: 3.038196901350693
Validation loss: 2.61972726330801

Epoch: 6| Step: 2
Training loss: 2.6827087275631247
Validation loss: 2.5798902686102965

Epoch: 6| Step: 3
Training loss: 3.2782289675798113
Validation loss: 2.577670943174812

Epoch: 6| Step: 4
Training loss: 2.879739917561628
Validation loss: 2.5682787151967608

Epoch: 6| Step: 5
Training loss: 1.9707849067830083
Validation loss: 2.5618925377530473

Epoch: 6| Step: 6
Training loss: 2.9205826946111304
Validation loss: 2.5545212781058697

Epoch: 6| Step: 7
Training loss: 3.3050271439122962
Validation loss: 2.5619657836516754

Epoch: 6| Step: 8
Training loss: 2.6341828082695424
Validation loss: 2.5626042302561083

Epoch: 6| Step: 9
Training loss: 2.2746402665663763
Validation loss: 2.568789788632044

Epoch: 6| Step: 10
Training loss: 2.9656034157292113
Validation loss: 2.5698814695200536

Epoch: 6| Step: 11
Training loss: 2.6129059800095895
Validation loss: 2.5945740996841815

Epoch: 6| Step: 12
Training loss: 2.7761021667720454
Validation loss: 2.612962690578382

Epoch: 6| Step: 13
Training loss: 3.4451093202915586
Validation loss: 2.6319394445242397

Epoch: 418| Step: 0
Training loss: 2.6252559355445357
Validation loss: 2.599241357001156

Epoch: 6| Step: 1
Training loss: 2.6560614126240787
Validation loss: 2.6018579979079344

Epoch: 6| Step: 2
Training loss: 2.6270578583327455
Validation loss: 2.593701130495208

Epoch: 6| Step: 3
Training loss: 2.3736587551874178
Validation loss: 2.6031456883216797

Epoch: 6| Step: 4
Training loss: 3.349705321603252
Validation loss: 2.594866351648103

Epoch: 6| Step: 5
Training loss: 3.1447735616072867
Validation loss: 2.585472268068596

Epoch: 6| Step: 6
Training loss: 2.8268029932520395
Validation loss: 2.578982281093064

Epoch: 6| Step: 7
Training loss: 2.8285493479660904
Validation loss: 2.5701288094729455

Epoch: 6| Step: 8
Training loss: 2.5940637054091304
Validation loss: 2.570986143339865

Epoch: 6| Step: 9
Training loss: 3.4449166483546927
Validation loss: 2.566056067854218

Epoch: 6| Step: 10
Training loss: 2.017604831396939
Validation loss: 2.569084202387184

Epoch: 6| Step: 11
Training loss: 2.713282030293852
Validation loss: 2.565069577512914

Epoch: 6| Step: 12
Training loss: 3.509125393748809
Validation loss: 2.571033741516642

Epoch: 6| Step: 13
Training loss: 3.0620777072526923
Validation loss: 2.570788730379276

Epoch: 419| Step: 0
Training loss: 2.9310592491697527
Validation loss: 2.567636194114124

Epoch: 6| Step: 1
Training loss: 3.0564409379661486
Validation loss: 2.5814841582589763

Epoch: 6| Step: 2
Training loss: 2.6669022535527773
Validation loss: 2.584941778760459

Epoch: 6| Step: 3
Training loss: 2.514226015035521
Validation loss: 2.5901749395008467

Epoch: 6| Step: 4
Training loss: 3.0271282685408654
Validation loss: 2.583861805717017

Epoch: 6| Step: 5
Training loss: 2.5012551018140043
Validation loss: 2.60464683060172

Epoch: 6| Step: 6
Training loss: 3.2408120788311456
Validation loss: 2.612165674530809

Epoch: 6| Step: 7
Training loss: 2.4333678212617684
Validation loss: 2.6133499841565606

Epoch: 6| Step: 8
Training loss: 2.519462359765549
Validation loss: 2.607899854620154

Epoch: 6| Step: 9
Training loss: 2.3298887190215076
Validation loss: 2.6168791391991952

Epoch: 6| Step: 10
Training loss: 3.2288262136504873
Validation loss: 2.6068346915332445

Epoch: 6| Step: 11
Training loss: 3.002942708305104
Validation loss: 2.592533354522747

Epoch: 6| Step: 12
Training loss: 3.092030982036252
Validation loss: 2.582933127127242

Epoch: 6| Step: 13
Training loss: 3.564671038929636
Validation loss: 2.602917003103231

Epoch: 420| Step: 0
Training loss: 2.6727800230766863
Validation loss: 2.6006208323831417

Epoch: 6| Step: 1
Training loss: 2.9683501928051657
Validation loss: 2.6159042378710278

Epoch: 6| Step: 2
Training loss: 3.5208389613240123
Validation loss: 2.5936524103107934

Epoch: 6| Step: 3
Training loss: 2.865052803178755
Validation loss: 2.582435402898877

Epoch: 6| Step: 4
Training loss: 2.990892095008915
Validation loss: 2.5902527173018495

Epoch: 6| Step: 5
Training loss: 2.4684520493351583
Validation loss: 2.598764351693276

Epoch: 6| Step: 6
Training loss: 2.6415298988084213
Validation loss: 2.5935520917474384

Epoch: 6| Step: 7
Training loss: 3.095025618390131
Validation loss: 2.5820403745277574

Epoch: 6| Step: 8
Training loss: 2.9280361556963297
Validation loss: 2.5940248610856815

Epoch: 6| Step: 9
Training loss: 2.8363041916533445
Validation loss: 2.5773890384849785

Epoch: 6| Step: 10
Training loss: 2.3072106983682783
Validation loss: 2.5875505988260517

Epoch: 6| Step: 11
Training loss: 3.5576238891303884
Validation loss: 2.587694302536305

Epoch: 6| Step: 12
Training loss: 2.2116014541789544
Validation loss: 2.5943295557429074

Epoch: 6| Step: 13
Training loss: 2.309250791355653
Validation loss: 2.5957445110659765

Epoch: 421| Step: 0
Training loss: 3.173856370066626
Validation loss: 2.6073513209345363

Epoch: 6| Step: 1
Training loss: 3.112465094558291
Validation loss: 2.5970424299743655

Epoch: 6| Step: 2
Training loss: 2.841181506880809
Validation loss: 2.588930031338325

Epoch: 6| Step: 3
Training loss: 2.936686626399692
Validation loss: 2.59591854773783

Epoch: 6| Step: 4
Training loss: 2.4355700751012606
Validation loss: 2.58900197859485

Epoch: 6| Step: 5
Training loss: 2.9543026791043574
Validation loss: 2.5885050028589642

Epoch: 6| Step: 6
Training loss: 2.637327222905089
Validation loss: 2.598845030072113

Epoch: 6| Step: 7
Training loss: 2.5775528706438506
Validation loss: 2.5865432103730446

Epoch: 6| Step: 8
Training loss: 2.2606386231003244
Validation loss: 2.5718165465250418

Epoch: 6| Step: 9
Training loss: 2.770094196907609
Validation loss: 2.580012264437189

Epoch: 6| Step: 10
Training loss: 2.9645912354382524
Validation loss: 2.5971049318722943

Epoch: 6| Step: 11
Training loss: 3.07407775322908
Validation loss: 2.606638659919575

Epoch: 6| Step: 12
Training loss: 3.1985868731244924
Validation loss: 2.6257249873056785

Epoch: 6| Step: 13
Training loss: 2.9116547893011884
Validation loss: 2.6143261248140384

Epoch: 422| Step: 0
Training loss: 3.554667915038767
Validation loss: 2.6171547028260926

Epoch: 6| Step: 1
Training loss: 2.789964887883458
Validation loss: 2.610049571159542

Epoch: 6| Step: 2
Training loss: 2.7937299211365114
Validation loss: 2.6181061965383514

Epoch: 6| Step: 3
Training loss: 2.620832495595761
Validation loss: 2.6127016534004786

Epoch: 6| Step: 4
Training loss: 2.852384265955656
Validation loss: 2.6080176522316045

Epoch: 6| Step: 5
Training loss: 2.2756429245852354
Validation loss: 2.6196268124758326

Epoch: 6| Step: 6
Training loss: 2.9426095231382745
Validation loss: 2.6180874889208403

Epoch: 6| Step: 7
Training loss: 2.4258396307512857
Validation loss: 2.6085333063197442

Epoch: 6| Step: 8
Training loss: 2.195319233405488
Validation loss: 2.608826862955264

Epoch: 6| Step: 9
Training loss: 3.204845431642945
Validation loss: 2.6244533915084998

Epoch: 6| Step: 10
Training loss: 3.1620668499109352
Validation loss: 2.615777433822892

Epoch: 6| Step: 11
Training loss: 2.4850129082265817
Validation loss: 2.615779457173188

Epoch: 6| Step: 12
Training loss: 3.212085231025489
Validation loss: 2.5960261724136684

Epoch: 6| Step: 13
Training loss: 3.1053330109878488
Validation loss: 2.5815970947079636

Epoch: 423| Step: 0
Training loss: 3.189436978487911
Validation loss: 2.5663827092872626

Epoch: 6| Step: 1
Training loss: 3.026004302975456
Validation loss: 2.5688780039310797

Epoch: 6| Step: 2
Training loss: 3.139815041020934
Validation loss: 2.562699139868456

Epoch: 6| Step: 3
Training loss: 2.522175003604987
Validation loss: 2.5722014959506065

Epoch: 6| Step: 4
Training loss: 2.6287016427620986
Validation loss: 2.559757571974992

Epoch: 6| Step: 5
Training loss: 2.491996733918966
Validation loss: 2.5768372641846846

Epoch: 6| Step: 6
Training loss: 3.0200057551348083
Validation loss: 2.5797538019717545

Epoch: 6| Step: 7
Training loss: 3.017405246362571
Validation loss: 2.5807088274947056

Epoch: 6| Step: 8
Training loss: 3.207657895680307
Validation loss: 2.6028517795340513

Epoch: 6| Step: 9
Training loss: 2.576828509236815
Validation loss: 2.611551496235005

Epoch: 6| Step: 10
Training loss: 3.0494242640677527
Validation loss: 2.613193802777809

Epoch: 6| Step: 11
Training loss: 2.734860622334563
Validation loss: 2.612342383659281

Epoch: 6| Step: 12
Training loss: 2.567403428323942
Validation loss: 2.5996034757615107

Epoch: 6| Step: 13
Training loss: 2.531317910119364
Validation loss: 2.607022944795365

Epoch: 424| Step: 0
Training loss: 2.5328084598534923
Validation loss: 2.60796234796058

Epoch: 6| Step: 1
Training loss: 3.365838083589858
Validation loss: 2.628508243621107

Epoch: 6| Step: 2
Training loss: 3.169169959053966
Validation loss: 2.631511867587923

Epoch: 6| Step: 3
Training loss: 3.1082215589892597
Validation loss: 2.624897143745953

Epoch: 6| Step: 4
Training loss: 2.6879883255988872
Validation loss: 2.6280278012009233

Epoch: 6| Step: 5
Training loss: 3.7046681983216474
Validation loss: 2.6532522843168627

Epoch: 6| Step: 6
Training loss: 2.753343370417788
Validation loss: 2.643892101397217

Epoch: 6| Step: 7
Training loss: 2.4036643267602376
Validation loss: 2.6460929267186613

Epoch: 6| Step: 8
Training loss: 2.070311348392958
Validation loss: 2.6263605518899475

Epoch: 6| Step: 9
Training loss: 2.79236695535318
Validation loss: 2.6197402848922846

Epoch: 6| Step: 10
Training loss: 2.949883190363983
Validation loss: 2.5982031412513034

Epoch: 6| Step: 11
Training loss: 2.586196748121673
Validation loss: 2.588443337203291

Epoch: 6| Step: 12
Training loss: 2.3292853005029066
Validation loss: 2.5915681874552337

Epoch: 6| Step: 13
Training loss: 2.9973616124422136
Validation loss: 2.5760160489519004

Epoch: 425| Step: 0
Training loss: 2.894367990767415
Validation loss: 2.5685493123575758

Epoch: 6| Step: 1
Training loss: 3.10673587307228
Validation loss: 2.5756342784392783

Epoch: 6| Step: 2
Training loss: 2.7731580996477807
Validation loss: 2.573045727769042

Epoch: 6| Step: 3
Training loss: 3.005528283676108
Validation loss: 2.586425299035782

Epoch: 6| Step: 4
Training loss: 2.9681199860906995
Validation loss: 2.59774499495333

Epoch: 6| Step: 5
Training loss: 2.881615035957111
Validation loss: 2.6216220665900245

Epoch: 6| Step: 6
Training loss: 2.179269292492426
Validation loss: 2.6399104051964493

Epoch: 6| Step: 7
Training loss: 3.2278924376329865
Validation loss: 2.664071366663416

Epoch: 6| Step: 8
Training loss: 2.9913593470875752
Validation loss: 2.623802165684514

Epoch: 6| Step: 9
Training loss: 2.7489718335798177
Validation loss: 2.6269861575058533

Epoch: 6| Step: 10
Training loss: 2.932109838418954
Validation loss: 2.6061277983184303

Epoch: 6| Step: 11
Training loss: 2.662879211213299
Validation loss: 2.593980874042016

Epoch: 6| Step: 12
Training loss: 2.6631039324027617
Validation loss: 2.577914930270404

Epoch: 6| Step: 13
Training loss: 2.923686236224014
Validation loss: 2.57184556680988

Epoch: 426| Step: 0
Training loss: 2.8476107035109277
Validation loss: 2.5601984688743653

Epoch: 6| Step: 1
Training loss: 2.937986617668737
Validation loss: 2.5593634316854086

Epoch: 6| Step: 2
Training loss: 2.7599926508930053
Validation loss: 2.564297340639164

Epoch: 6| Step: 3
Training loss: 3.163240151622374
Validation loss: 2.5505524873050303

Epoch: 6| Step: 4
Training loss: 2.88752638239182
Validation loss: 2.5620872791469433

Epoch: 6| Step: 5
Training loss: 2.580270140647731
Validation loss: 2.5548792023244977

Epoch: 6| Step: 6
Training loss: 2.9654390845595526
Validation loss: 2.5618771542171515

Epoch: 6| Step: 7
Training loss: 2.5293352396643973
Validation loss: 2.57935201780797

Epoch: 6| Step: 8
Training loss: 2.6383400686551184
Validation loss: 2.5934903039166786

Epoch: 6| Step: 9
Training loss: 2.655665972962099
Validation loss: 2.5864778355726967

Epoch: 6| Step: 10
Training loss: 2.7825912499010483
Validation loss: 2.5757282192289503

Epoch: 6| Step: 11
Training loss: 2.576452186494679
Validation loss: 2.5667840126432906

Epoch: 6| Step: 12
Training loss: 3.641638356905495
Validation loss: 2.5555497833821064

Epoch: 6| Step: 13
Training loss: 2.710124660735608
Validation loss: 2.5647981554320425

Epoch: 427| Step: 0
Training loss: 3.0094535017222515
Validation loss: 2.562501416629907

Epoch: 6| Step: 1
Training loss: 2.7759042864522447
Validation loss: 2.5677413310971464

Epoch: 6| Step: 2
Training loss: 2.3322119970260564
Validation loss: 2.572064320356163

Epoch: 6| Step: 3
Training loss: 2.9811807684387217
Validation loss: 2.5890979474073275

Epoch: 6| Step: 4
Training loss: 2.7233085562404926
Validation loss: 2.601832252576087

Epoch: 6| Step: 5
Training loss: 2.8518320452656916
Validation loss: 2.622354147706302

Epoch: 6| Step: 6
Training loss: 2.7756929924137443
Validation loss: 2.6434340957609925

Epoch: 6| Step: 7
Training loss: 2.6436778822998326
Validation loss: 2.6425160961891243

Epoch: 6| Step: 8
Training loss: 3.2085082431691485
Validation loss: 2.636162042826164

Epoch: 6| Step: 9
Training loss: 2.6979112563698817
Validation loss: 2.5986401710495937

Epoch: 6| Step: 10
Training loss: 3.1601482528000635
Validation loss: 2.6158654958908034

Epoch: 6| Step: 11
Training loss: 2.8898401793008994
Validation loss: 2.5986756464836405

Epoch: 6| Step: 12
Training loss: 2.9888888271226213
Validation loss: 2.618430935757438

Epoch: 6| Step: 13
Training loss: 2.6267105160682225
Validation loss: 2.6385488526008913

Epoch: 428| Step: 0
Training loss: 3.028327240700717
Validation loss: 2.6571481015241667

Epoch: 6| Step: 1
Training loss: 2.6790214578325235
Validation loss: 2.7075702800773502

Epoch: 6| Step: 2
Training loss: 3.1164237786233038
Validation loss: 2.726726068823505

Epoch: 6| Step: 3
Training loss: 2.1241526316671333
Validation loss: 2.716770315567938

Epoch: 6| Step: 4
Training loss: 2.4796826656417017
Validation loss: 2.671659103831262

Epoch: 6| Step: 5
Training loss: 2.5540337615623243
Validation loss: 2.6592205850471817

Epoch: 6| Step: 6
Training loss: 2.526030822940374
Validation loss: 2.633115610585088

Epoch: 6| Step: 7
Training loss: 2.5585980364348635
Validation loss: 2.627535173470628

Epoch: 6| Step: 8
Training loss: 2.4857743838519517
Validation loss: 2.6168692368203716

Epoch: 6| Step: 9
Training loss: 3.4437662058481835
Validation loss: 2.609807875128084

Epoch: 6| Step: 10
Training loss: 3.57706858936101
Validation loss: 2.593969366209374

Epoch: 6| Step: 11
Training loss: 3.369294323939808
Validation loss: 2.5911980766182316

Epoch: 6| Step: 12
Training loss: 2.719146699573914
Validation loss: 2.5835923459673658

Epoch: 6| Step: 13
Training loss: 2.9547561903805675
Validation loss: 2.5931647448814603

Epoch: 429| Step: 0
Training loss: 2.6094268976407173
Validation loss: 2.5885514628296633

Epoch: 6| Step: 1
Training loss: 2.669304218858799
Validation loss: 2.583423450841868

Epoch: 6| Step: 2
Training loss: 2.7052861212904773
Validation loss: 2.584831961870634

Epoch: 6| Step: 3
Training loss: 3.2765381906287065
Validation loss: 2.585685044264031

Epoch: 6| Step: 4
Training loss: 2.7096098801330513
Validation loss: 2.5812901174835425

Epoch: 6| Step: 5
Training loss: 3.3013690131739315
Validation loss: 2.586909818028949

Epoch: 6| Step: 6
Training loss: 2.7321484901377278
Validation loss: 2.5941204019565984

Epoch: 6| Step: 7
Training loss: 2.8081500852964205
Validation loss: 2.6131438312022257

Epoch: 6| Step: 8
Training loss: 3.1507435723323707
Validation loss: 2.5995620584307098

Epoch: 6| Step: 9
Training loss: 2.686750263052594
Validation loss: 2.5858057802282874

Epoch: 6| Step: 10
Training loss: 2.8517902440090497
Validation loss: 2.572745064166731

Epoch: 6| Step: 11
Training loss: 2.974756208416367
Validation loss: 2.5637289522290923

Epoch: 6| Step: 12
Training loss: 2.8026611318554777
Validation loss: 2.5692020095318013

Epoch: 6| Step: 13
Training loss: 2.3548613566996557
Validation loss: 2.6036539615739005

Epoch: 430| Step: 0
Training loss: 3.0728671484799066
Validation loss: 2.6000892354861684

Epoch: 6| Step: 1
Training loss: 3.0710861357344874
Validation loss: 2.6141682218355666

Epoch: 6| Step: 2
Training loss: 2.80600726600734
Validation loss: 2.6220177274620493

Epoch: 6| Step: 3
Training loss: 2.8304157569045567
Validation loss: 2.643289133617463

Epoch: 6| Step: 4
Training loss: 2.7608788061460725
Validation loss: 2.6461348568122256

Epoch: 6| Step: 5
Training loss: 2.549854244479637
Validation loss: 2.6538039283369175

Epoch: 6| Step: 6
Training loss: 2.7012889116795327
Validation loss: 2.637292815640387

Epoch: 6| Step: 7
Training loss: 3.212491070330488
Validation loss: 2.649349373041982

Epoch: 6| Step: 8
Training loss: 3.2072627440525054
Validation loss: 2.6240893667844714

Epoch: 6| Step: 9
Training loss: 2.5208806645597432
Validation loss: 2.642551833413829

Epoch: 6| Step: 10
Training loss: 2.5657307796997966
Validation loss: 2.609048468403092

Epoch: 6| Step: 11
Training loss: 2.9406383874894515
Validation loss: 2.5759226401606523

Epoch: 6| Step: 12
Training loss: 2.7949108707363295
Validation loss: 2.558675600828165

Epoch: 6| Step: 13
Training loss: 2.629939654132981
Validation loss: 2.5644586432451746

Epoch: 431| Step: 0
Training loss: 2.3602462069538817
Validation loss: 2.5631640614534055

Epoch: 6| Step: 1
Training loss: 2.8733625309899673
Validation loss: 2.5640388648203785

Epoch: 6| Step: 2
Training loss: 3.0520721713090917
Validation loss: 2.5675760990708194

Epoch: 6| Step: 3
Training loss: 2.8492392076657937
Validation loss: 2.568386613718619

Epoch: 6| Step: 4
Training loss: 3.456311718905311
Validation loss: 2.5953657926946563

Epoch: 6| Step: 5
Training loss: 2.5733220531367924
Validation loss: 2.6076512495354134

Epoch: 6| Step: 6
Training loss: 3.024621697092458
Validation loss: 2.6098617051664283

Epoch: 6| Step: 7
Training loss: 3.1789597936861433
Validation loss: 2.6346433037317407

Epoch: 6| Step: 8
Training loss: 2.5550450999241647
Validation loss: 2.6274342556943613

Epoch: 6| Step: 9
Training loss: 2.9107901273269836
Validation loss: 2.644606739952271

Epoch: 6| Step: 10
Training loss: 2.959902781359154
Validation loss: 2.6969226766069476

Epoch: 6| Step: 11
Training loss: 2.0332091053811543
Validation loss: 2.7238571322932295

Epoch: 6| Step: 12
Training loss: 3.0268352647560297
Validation loss: 2.7392555794684754

Epoch: 6| Step: 13
Training loss: 2.7068293772807257
Validation loss: 2.710038085123176

Epoch: 432| Step: 0
Training loss: 3.1508685776431715
Validation loss: 2.6928387428224903

Epoch: 6| Step: 1
Training loss: 2.744532264646304
Validation loss: 2.6510804785116733

Epoch: 6| Step: 2
Training loss: 2.60348284071866
Validation loss: 2.6034531164981747

Epoch: 6| Step: 3
Training loss: 3.1429225431796373
Validation loss: 2.5743775468530625

Epoch: 6| Step: 4
Training loss: 2.988149762221573
Validation loss: 2.5719546334221652

Epoch: 6| Step: 5
Training loss: 2.7749521337281515
Validation loss: 2.5480110663982796

Epoch: 6| Step: 6
Training loss: 2.7959430356587527
Validation loss: 2.551016410796043

Epoch: 6| Step: 7
Training loss: 2.7232454338347125
Validation loss: 2.5596435817834964

Epoch: 6| Step: 8
Training loss: 3.2041222485331176
Validation loss: 2.5499111709790334

Epoch: 6| Step: 9
Training loss: 2.5636995810726706
Validation loss: 2.548627455695102

Epoch: 6| Step: 10
Training loss: 2.123602575940991
Validation loss: 2.547025214971387

Epoch: 6| Step: 11
Training loss: 3.6418156457335624
Validation loss: 2.5550238224955657

Epoch: 6| Step: 12
Training loss: 2.77913499630141
Validation loss: 2.5530856995346682

Epoch: 6| Step: 13
Training loss: 2.690638373116855
Validation loss: 2.573267494592941

Epoch: 433| Step: 0
Training loss: 2.700119729389708
Validation loss: 2.5628764018394623

Epoch: 6| Step: 1
Training loss: 2.3483781006306734
Validation loss: 2.572683662491298

Epoch: 6| Step: 2
Training loss: 2.8660931486657257
Validation loss: 2.5929326680841243

Epoch: 6| Step: 3
Training loss: 3.439280239701282
Validation loss: 2.6048496454945833

Epoch: 6| Step: 4
Training loss: 2.603708842405953
Validation loss: 2.5818782420566273

Epoch: 6| Step: 5
Training loss: 2.721290629008691
Validation loss: 2.5788159043459267

Epoch: 6| Step: 6
Training loss: 2.3227690463066852
Validation loss: 2.578069515880424

Epoch: 6| Step: 7
Training loss: 2.99597024476538
Validation loss: 2.564983809884049

Epoch: 6| Step: 8
Training loss: 2.810631873334675
Validation loss: 2.5620706340073145

Epoch: 6| Step: 9
Training loss: 2.4047325601005842
Validation loss: 2.5613759674694814

Epoch: 6| Step: 10
Training loss: 2.945302138575939
Validation loss: 2.5580181201672514

Epoch: 6| Step: 11
Training loss: 3.2537784620015477
Validation loss: 2.569510070737242

Epoch: 6| Step: 12
Training loss: 3.269075751621003
Validation loss: 2.5653157065084873

Epoch: 6| Step: 13
Training loss: 3.206467684667566
Validation loss: 2.5666739901851163

Epoch: 434| Step: 0
Training loss: 3.130690771787774
Validation loss: 2.581911692871032

Epoch: 6| Step: 1
Training loss: 2.5067562362549194
Validation loss: 2.5827229467088983

Epoch: 6| Step: 2
Training loss: 2.6520305555375643
Validation loss: 2.607546278449343

Epoch: 6| Step: 3
Training loss: 2.369808345079244
Validation loss: 2.6050997382031746

Epoch: 6| Step: 4
Training loss: 2.760065903360562
Validation loss: 2.6261021536262197

Epoch: 6| Step: 5
Training loss: 2.598777219364652
Validation loss: 2.6478670259472765

Epoch: 6| Step: 6
Training loss: 2.896329292986743
Validation loss: 2.6369003742578587

Epoch: 6| Step: 7
Training loss: 3.1348882253089445
Validation loss: 2.6241936360721136

Epoch: 6| Step: 8
Training loss: 2.9703772652682456
Validation loss: 2.5895279067949795

Epoch: 6| Step: 9
Training loss: 3.3862991513064333
Validation loss: 2.5834064261595038

Epoch: 6| Step: 10
Training loss: 3.0739383012167796
Validation loss: 2.5775141504760892

Epoch: 6| Step: 11
Training loss: 2.7074956234150718
Validation loss: 2.564600404092599

Epoch: 6| Step: 12
Training loss: 2.4800256047926696
Validation loss: 2.564382692354555

Epoch: 6| Step: 13
Training loss: 3.129828270780625
Validation loss: 2.5636421137499097

Epoch: 435| Step: 0
Training loss: 2.798495712824965
Validation loss: 2.5571226899528696

Epoch: 6| Step: 1
Training loss: 2.9283001272294196
Validation loss: 2.559411878056063

Epoch: 6| Step: 2
Training loss: 2.5785963147845306
Validation loss: 2.565147534875135

Epoch: 6| Step: 3
Training loss: 2.8742304891650896
Validation loss: 2.5622627014366777

Epoch: 6| Step: 4
Training loss: 2.9386151408832064
Validation loss: 2.5615448420877507

Epoch: 6| Step: 5
Training loss: 2.94543343455095
Validation loss: 2.5679251484803056

Epoch: 6| Step: 6
Training loss: 2.7618061143580777
Validation loss: 2.575618362848793

Epoch: 6| Step: 7
Training loss: 3.072154494771722
Validation loss: 2.5744297083621857

Epoch: 6| Step: 8
Training loss: 2.525412622106683
Validation loss: 2.596646009308235

Epoch: 6| Step: 9
Training loss: 3.1748015334208417
Validation loss: 2.604799185118732

Epoch: 6| Step: 10
Training loss: 2.652614933583531
Validation loss: 2.6325282420566487

Epoch: 6| Step: 11
Training loss: 2.8106995647804536
Validation loss: 2.638647550792283

Epoch: 6| Step: 12
Training loss: 2.815698373327535
Validation loss: 2.683096074979489

Epoch: 6| Step: 13
Training loss: 2.586037809610365
Validation loss: 2.6629976246906972

Epoch: 436| Step: 0
Training loss: 2.4120097398450575
Validation loss: 2.646748183486947

Epoch: 6| Step: 1
Training loss: 3.2804321723092498
Validation loss: 2.6464007887180263

Epoch: 6| Step: 2
Training loss: 2.8681392908893666
Validation loss: 2.605166925767911

Epoch: 6| Step: 3
Training loss: 2.4790293444473592
Validation loss: 2.6022875316680607

Epoch: 6| Step: 4
Training loss: 3.090568679280973
Validation loss: 2.600135930178413

Epoch: 6| Step: 5
Training loss: 3.2808238888127317
Validation loss: 2.5775249241501434

Epoch: 6| Step: 6
Training loss: 2.723031892408305
Validation loss: 2.571413450380561

Epoch: 6| Step: 7
Training loss: 2.891050235297321
Validation loss: 2.568054623823653

Epoch: 6| Step: 8
Training loss: 2.075949081854876
Validation loss: 2.549262206337432

Epoch: 6| Step: 9
Training loss: 2.7998264020510835
Validation loss: 2.5467332732210433

Epoch: 6| Step: 10
Training loss: 2.677510525551845
Validation loss: 2.5527176568228853

Epoch: 6| Step: 11
Training loss: 3.0614668991489946
Validation loss: 2.547088252755692

Epoch: 6| Step: 12
Training loss: 3.25634908397264
Validation loss: 2.561154834588019

Epoch: 6| Step: 13
Training loss: 2.2582657830902932
Validation loss: 2.5807123897752993

Epoch: 437| Step: 0
Training loss: 2.2268708668043318
Validation loss: 2.618050369987692

Epoch: 6| Step: 1
Training loss: 2.5713431196546606
Validation loss: 2.6527479564116803

Epoch: 6| Step: 2
Training loss: 3.179846457367343
Validation loss: 2.689438371019636

Epoch: 6| Step: 3
Training loss: 2.1466500909927495
Validation loss: 2.731985399858601

Epoch: 6| Step: 4
Training loss: 2.938671771151799
Validation loss: 2.7093496972893005

Epoch: 6| Step: 5
Training loss: 3.038095511627071
Validation loss: 2.6529505351522524

Epoch: 6| Step: 6
Training loss: 3.1380688337820444
Validation loss: 2.611087536019946

Epoch: 6| Step: 7
Training loss: 2.9757267937718805
Validation loss: 2.596149140059128

Epoch: 6| Step: 8
Training loss: 2.601268304909822
Validation loss: 2.563971538394627

Epoch: 6| Step: 9
Training loss: 2.58980269133413
Validation loss: 2.5544142471421227

Epoch: 6| Step: 10
Training loss: 3.295158626460213
Validation loss: 2.532432854033789

Epoch: 6| Step: 11
Training loss: 3.2134457928881526
Validation loss: 2.556179424207905

Epoch: 6| Step: 12
Training loss: 2.829608170036102
Validation loss: 2.539080172367611

Epoch: 6| Step: 13
Training loss: 2.997413951157278
Validation loss: 2.5552266893373434

Epoch: 438| Step: 0
Training loss: 2.636353417977647
Validation loss: 2.542012521124949

Epoch: 6| Step: 1
Training loss: 3.109489707172814
Validation loss: 2.5568322741336713

Epoch: 6| Step: 2
Training loss: 2.8379605226250972
Validation loss: 2.5576758897528524

Epoch: 6| Step: 3
Training loss: 3.036373880999315
Validation loss: 2.5721308409179415

Epoch: 6| Step: 4
Training loss: 2.680551817720626
Validation loss: 2.5730354175727794

Epoch: 6| Step: 5
Training loss: 1.7486143075625764
Validation loss: 2.5945611637395607

Epoch: 6| Step: 6
Training loss: 3.013632635032934
Validation loss: 2.603594345863286

Epoch: 6| Step: 7
Training loss: 3.166478870913464
Validation loss: 2.649273421172489

Epoch: 6| Step: 8
Training loss: 3.0589247094547445
Validation loss: 2.657233314026057

Epoch: 6| Step: 9
Training loss: 2.6721840841418496
Validation loss: 2.657216410094359

Epoch: 6| Step: 10
Training loss: 2.8803137724870385
Validation loss: 2.6196661677127118

Epoch: 6| Step: 11
Training loss: 3.0482170083897926
Validation loss: 2.587663358683976

Epoch: 6| Step: 12
Training loss: 3.0379620989406053
Validation loss: 2.561635809840557

Epoch: 6| Step: 13
Training loss: 2.218360436854551
Validation loss: 2.54308371141236

Epoch: 439| Step: 0
Training loss: 3.0204334564380835
Validation loss: 2.540281438421105

Epoch: 6| Step: 1
Training loss: 3.108737439297777
Validation loss: 2.5491436134546266

Epoch: 6| Step: 2
Training loss: 3.2289495251568647
Validation loss: 2.5490424534131604

Epoch: 6| Step: 3
Training loss: 2.310524483295716
Validation loss: 2.5504959912533636

Epoch: 6| Step: 4
Training loss: 2.848472279447744
Validation loss: 2.559113914245319

Epoch: 6| Step: 5
Training loss: 2.5554451941649736
Validation loss: 2.5683714926670986

Epoch: 6| Step: 6
Training loss: 2.395377527637021
Validation loss: 2.5602880445815672

Epoch: 6| Step: 7
Training loss: 2.735200768168125
Validation loss: 2.581295939395755

Epoch: 6| Step: 8
Training loss: 2.9106246673668985
Validation loss: 2.594242975716159

Epoch: 6| Step: 9
Training loss: 3.1991077073124377
Validation loss: 2.6042094237396336

Epoch: 6| Step: 10
Training loss: 2.521852450169523
Validation loss: 2.6061857226847267

Epoch: 6| Step: 11
Training loss: 3.1351102930650807
Validation loss: 2.6041850572162293

Epoch: 6| Step: 12
Training loss: 3.147770586207183
Validation loss: 2.6047554174235032

Epoch: 6| Step: 13
Training loss: 2.132549227719886
Validation loss: 2.6084652088895934

Epoch: 440| Step: 0
Training loss: 3.4390233219173445
Validation loss: 2.5777527780025427

Epoch: 6| Step: 1
Training loss: 2.7081514933258855
Validation loss: 2.576800928966813

Epoch: 6| Step: 2
Training loss: 3.2200816834792887
Validation loss: 2.574280941630042

Epoch: 6| Step: 3
Training loss: 2.4202852014882397
Validation loss: 2.5692909031513187

Epoch: 6| Step: 4
Training loss: 2.791144013705298
Validation loss: 2.5883914496794342

Epoch: 6| Step: 5
Training loss: 2.500263486328614
Validation loss: 2.593104495039417

Epoch: 6| Step: 6
Training loss: 2.676061729711328
Validation loss: 2.5933764935379613

Epoch: 6| Step: 7
Training loss: 2.2948341904791274
Validation loss: 2.6018751265068625

Epoch: 6| Step: 8
Training loss: 2.74427025105317
Validation loss: 2.589703640241008

Epoch: 6| Step: 9
Training loss: 2.984008446995947
Validation loss: 2.573136114578361

Epoch: 6| Step: 10
Training loss: 3.374945604804348
Validation loss: 2.5759156775081853

Epoch: 6| Step: 11
Training loss: 2.0866473986596317
Validation loss: 2.564624698882067

Epoch: 6| Step: 12
Training loss: 2.9025816377105085
Validation loss: 2.56292564604644

Epoch: 6| Step: 13
Training loss: 3.444581799861914
Validation loss: 2.5728120733168964

Epoch: 441| Step: 0
Training loss: 2.9937306700144153
Validation loss: 2.5620332038114064

Epoch: 6| Step: 1
Training loss: 2.346080892542243
Validation loss: 2.5810540836020293

Epoch: 6| Step: 2
Training loss: 3.163384560376916
Validation loss: 2.589600428455999

Epoch: 6| Step: 3
Training loss: 2.621426647893869
Validation loss: 2.5845855300580096

Epoch: 6| Step: 4
Training loss: 2.783528198532421
Validation loss: 2.6234617770630604

Epoch: 6| Step: 5
Training loss: 3.3934023684341117
Validation loss: 2.6674811583190294

Epoch: 6| Step: 6
Training loss: 3.0932066469175106
Validation loss: 2.6622185420971687

Epoch: 6| Step: 7
Training loss: 2.0482733223517466
Validation loss: 2.652018883928019

Epoch: 6| Step: 8
Training loss: 2.8997556254584507
Validation loss: 2.6515181840246145

Epoch: 6| Step: 9
Training loss: 2.511482286965305
Validation loss: 2.6272018073983663

Epoch: 6| Step: 10
Training loss: 2.998183972333587
Validation loss: 2.6287851189147866

Epoch: 6| Step: 11
Training loss: 2.979281887858512
Validation loss: 2.594880408395243

Epoch: 6| Step: 12
Training loss: 2.9043784729731796
Validation loss: 2.597331779694272

Epoch: 6| Step: 13
Training loss: 2.5521743031591817
Validation loss: 2.597317479585189

Epoch: 442| Step: 0
Training loss: 2.6428798100151183
Validation loss: 2.582440690131244

Epoch: 6| Step: 1
Training loss: 2.731187979476301
Validation loss: 2.58359037331888

Epoch: 6| Step: 2
Training loss: 2.859622798667541
Validation loss: 2.5861777392997305

Epoch: 6| Step: 3
Training loss: 2.8833167816157443
Validation loss: 2.577427776446685

Epoch: 6| Step: 4
Training loss: 2.1999683898042024
Validation loss: 2.5812671475182425

Epoch: 6| Step: 5
Training loss: 2.6596126140943084
Validation loss: 2.6026646449465787

Epoch: 6| Step: 6
Training loss: 2.821329794563617
Validation loss: 2.593319170787929

Epoch: 6| Step: 7
Training loss: 3.699732260424817
Validation loss: 2.617705633368057

Epoch: 6| Step: 8
Training loss: 2.3852140737622145
Validation loss: 2.6369112339047427

Epoch: 6| Step: 9
Training loss: 2.1780256820649795
Validation loss: 2.6577251905476684

Epoch: 6| Step: 10
Training loss: 3.065042180180263
Validation loss: 2.664083195250716

Epoch: 6| Step: 11
Training loss: 2.98853670910734
Validation loss: 2.6685700859306456

Epoch: 6| Step: 12
Training loss: 3.4260644915245613
Validation loss: 2.66514522914422

Epoch: 6| Step: 13
Training loss: 2.4013993554677486
Validation loss: 2.6831320207956666

Epoch: 443| Step: 0
Training loss: 3.052525684645409
Validation loss: 2.683558825867314

Epoch: 6| Step: 1
Training loss: 3.025877448576077
Validation loss: 2.6548350021072165

Epoch: 6| Step: 2
Training loss: 2.8459470876036073
Validation loss: 2.6426098635369124

Epoch: 6| Step: 3
Training loss: 2.8784619924140844
Validation loss: 2.635561907477681

Epoch: 6| Step: 4
Training loss: 2.591602125519241
Validation loss: 2.631479317139744

Epoch: 6| Step: 5
Training loss: 3.3491643404250566
Validation loss: 2.628754134080874

Epoch: 6| Step: 6
Training loss: 3.0823544331603943
Validation loss: 2.612894646774705

Epoch: 6| Step: 7
Training loss: 2.8432071712658917
Validation loss: 2.6123675504398016

Epoch: 6| Step: 8
Training loss: 2.953621958743349
Validation loss: 2.601526440150609

Epoch: 6| Step: 9
Training loss: 2.6297251543963287
Validation loss: 2.6081150120690033

Epoch: 6| Step: 10
Training loss: 2.341209153339918
Validation loss: 2.612991361810291

Epoch: 6| Step: 11
Training loss: 2.978786488708531
Validation loss: 2.6159364122469357

Epoch: 6| Step: 12
Training loss: 1.8628549787966824
Validation loss: 2.6418311072136156

Epoch: 6| Step: 13
Training loss: 2.883092851110168
Validation loss: 2.6761755288512616

Epoch: 444| Step: 0
Training loss: 2.4875928085112786
Validation loss: 2.690603137383927

Epoch: 6| Step: 1
Training loss: 2.445215875343621
Validation loss: 2.707228552786087

Epoch: 6| Step: 2
Training loss: 3.4285870222463672
Validation loss: 2.7229639158663903

Epoch: 6| Step: 3
Training loss: 2.860429913146781
Validation loss: 2.703236937198332

Epoch: 6| Step: 4
Training loss: 2.8149742263508437
Validation loss: 2.670502240986438

Epoch: 6| Step: 5
Training loss: 2.544147927092047
Validation loss: 2.6247892612571837

Epoch: 6| Step: 6
Training loss: 2.6542328299794966
Validation loss: 2.5960599712228416

Epoch: 6| Step: 7
Training loss: 2.6551562581892636
Validation loss: 2.595775315128794

Epoch: 6| Step: 8
Training loss: 3.17063090162369
Validation loss: 2.598462164563743

Epoch: 6| Step: 9
Training loss: 3.006042117983028
Validation loss: 2.596666318755532

Epoch: 6| Step: 10
Training loss: 3.0044048079140224
Validation loss: 2.597330511362268

Epoch: 6| Step: 11
Training loss: 2.896923235149092
Validation loss: 2.599470994786152

Epoch: 6| Step: 12
Training loss: 2.6935043683212263
Validation loss: 2.6131337125702574

Epoch: 6| Step: 13
Training loss: 2.808196186901335
Validation loss: 2.599458799206925

Epoch: 445| Step: 0
Training loss: 2.562889999857034
Validation loss: 2.5982860738289633

Epoch: 6| Step: 1
Training loss: 2.5459501307323893
Validation loss: 2.5817782385260695

Epoch: 6| Step: 2
Training loss: 2.272584525740625
Validation loss: 2.5961554944734586

Epoch: 6| Step: 3
Training loss: 2.8390285995886386
Validation loss: 2.6090522513950183

Epoch: 6| Step: 4
Training loss: 3.338223605346777
Validation loss: 2.607590385676914

Epoch: 6| Step: 5
Training loss: 2.856860780415587
Validation loss: 2.620508774011386

Epoch: 6| Step: 6
Training loss: 3.25249883981577
Validation loss: 2.610894514130261

Epoch: 6| Step: 7
Training loss: 2.9831020975982074
Validation loss: 2.600324553055084

Epoch: 6| Step: 8
Training loss: 2.92462094451014
Validation loss: 2.598535578837987

Epoch: 6| Step: 9
Training loss: 2.283368420389316
Validation loss: 2.596998301545941

Epoch: 6| Step: 10
Training loss: 3.385374160891011
Validation loss: 2.5751666435545353

Epoch: 6| Step: 11
Training loss: 2.7413126971115
Validation loss: 2.565757309932339

Epoch: 6| Step: 12
Training loss: 2.808745357575801
Validation loss: 2.553816519273616

Epoch: 6| Step: 13
Training loss: 1.4866242082517218
Validation loss: 2.543019895904192

Epoch: 446| Step: 0
Training loss: 2.7001478084089876
Validation loss: 2.545112719371886

Epoch: 6| Step: 1
Training loss: 3.3542981487274863
Validation loss: 2.536267025085726

Epoch: 6| Step: 2
Training loss: 2.641404979110904
Validation loss: 2.541193504678209

Epoch: 6| Step: 3
Training loss: 2.3780236321599255
Validation loss: 2.5454730492210165

Epoch: 6| Step: 4
Training loss: 3.1503804839905754
Validation loss: 2.5484656349339665

Epoch: 6| Step: 5
Training loss: 3.2213823239641144
Validation loss: 2.553037236546393

Epoch: 6| Step: 6
Training loss: 2.59603211533206
Validation loss: 2.5701472457473233

Epoch: 6| Step: 7
Training loss: 2.6647576015373655
Validation loss: 2.5895907256892463

Epoch: 6| Step: 8
Training loss: 2.3717205092787177
Validation loss: 2.6027461883868357

Epoch: 6| Step: 9
Training loss: 2.6090550026584287
Validation loss: 2.599604007304946

Epoch: 6| Step: 10
Training loss: 2.6820408577306614
Validation loss: 2.620965622237668

Epoch: 6| Step: 11
Training loss: 3.0827985420046407
Validation loss: 2.614913585870045

Epoch: 6| Step: 12
Training loss: 2.9408589090683823
Validation loss: 2.6337181479412166

Epoch: 6| Step: 13
Training loss: 2.8726179786935946
Validation loss: 2.6236343210380095

Epoch: 447| Step: 0
Training loss: 3.0238358582650435
Validation loss: 2.6443190672273382

Epoch: 6| Step: 1
Training loss: 2.5600887211684493
Validation loss: 2.657113335366063

Epoch: 6| Step: 2
Training loss: 3.1088431205346634
Validation loss: 2.6640551845474274

Epoch: 6| Step: 3
Training loss: 3.069799792940542
Validation loss: 2.6425342787037205

Epoch: 6| Step: 4
Training loss: 2.5549361081729036
Validation loss: 2.6516215845333737

Epoch: 6| Step: 5
Training loss: 2.894394844331467
Validation loss: 2.625547542394222

Epoch: 6| Step: 6
Training loss: 2.9876781777594226
Validation loss: 2.608177167042835

Epoch: 6| Step: 7
Training loss: 2.7578689526191336
Validation loss: 2.598149763326437

Epoch: 6| Step: 8
Training loss: 2.7918914211004617
Validation loss: 2.585486129984831

Epoch: 6| Step: 9
Training loss: 2.8089578999956113
Validation loss: 2.588191927216197

Epoch: 6| Step: 10
Training loss: 2.9332348315722077
Validation loss: 2.590919096292612

Epoch: 6| Step: 11
Training loss: 2.266510047363524
Validation loss: 2.5874986181007276

Epoch: 6| Step: 12
Training loss: 2.8315478102999
Validation loss: 2.6062476098841563

Epoch: 6| Step: 13
Training loss: 2.3833579517862553
Validation loss: 2.6144721986410566

Epoch: 448| Step: 0
Training loss: 2.8064806633097428
Validation loss: 2.610194070256734

Epoch: 6| Step: 1
Training loss: 2.5250751861860143
Validation loss: 2.6423182137942307

Epoch: 6| Step: 2
Training loss: 2.758114374081085
Validation loss: 2.6597084862493143

Epoch: 6| Step: 3
Training loss: 2.459465822047905
Validation loss: 2.677851009574529

Epoch: 6| Step: 4
Training loss: 3.181674345902104
Validation loss: 2.6813072624338323

Epoch: 6| Step: 5
Training loss: 3.0810474135710493
Validation loss: 2.652107193062024

Epoch: 6| Step: 6
Training loss: 2.628799776412295
Validation loss: 2.6210363536527908

Epoch: 6| Step: 7
Training loss: 2.8100892649417593
Validation loss: 2.6136607828863574

Epoch: 6| Step: 8
Training loss: 2.8147112313065636
Validation loss: 2.6052888951849478

Epoch: 6| Step: 9
Training loss: 2.4128443536433193
Validation loss: 2.6077292316129337

Epoch: 6| Step: 10
Training loss: 2.883814030379977
Validation loss: 2.624035604886158

Epoch: 6| Step: 11
Training loss: 2.9122639441708538
Validation loss: 2.6264387056531886

Epoch: 6| Step: 12
Training loss: 2.3771877251408444
Validation loss: 2.6256481304168684

Epoch: 6| Step: 13
Training loss: 3.613475105652779
Validation loss: 2.6403212338906306

Epoch: 449| Step: 0
Training loss: 2.5522228799672493
Validation loss: 2.5912397077728304

Epoch: 6| Step: 1
Training loss: 2.4137170044408385
Validation loss: 2.5779827229061465

Epoch: 6| Step: 2
Training loss: 3.2276157387355755
Validation loss: 2.564924523260702

Epoch: 6| Step: 3
Training loss: 2.4394051369191603
Validation loss: 2.541289506468382

Epoch: 6| Step: 4
Training loss: 3.120102974586173
Validation loss: 2.547473606867852

Epoch: 6| Step: 5
Training loss: 3.0409497674708885
Validation loss: 2.5543523024585566

Epoch: 6| Step: 6
Training loss: 2.619165931027542
Validation loss: 2.546137779744296

Epoch: 6| Step: 7
Training loss: 2.426820787192205
Validation loss: 2.5542687774783364

Epoch: 6| Step: 8
Training loss: 3.071064708866442
Validation loss: 2.5697568767964745

Epoch: 6| Step: 9
Training loss: 3.0201778533808645
Validation loss: 2.588000727652656

Epoch: 6| Step: 10
Training loss: 3.1669495774095444
Validation loss: 2.5920590669611463

Epoch: 6| Step: 11
Training loss: 2.4471629395979937
Validation loss: 2.5918728336277788

Epoch: 6| Step: 12
Training loss: 2.7358892988820482
Validation loss: 2.597532714156418

Epoch: 6| Step: 13
Training loss: 2.927692680240131
Validation loss: 2.590310429565362

Epoch: 450| Step: 0
Training loss: 2.3958316526545285
Validation loss: 2.58817523799007

Epoch: 6| Step: 1
Training loss: 2.451482818456167
Validation loss: 2.572242066152009

Epoch: 6| Step: 2
Training loss: 2.545627499098456
Validation loss: 2.5728494612886

Epoch: 6| Step: 3
Training loss: 2.9080944156247726
Validation loss: 2.5742879943482655

Epoch: 6| Step: 4
Training loss: 2.941269910674463
Validation loss: 2.574593984244368

Epoch: 6| Step: 5
Training loss: 3.0691370764604184
Validation loss: 2.5814316352927484

Epoch: 6| Step: 6
Training loss: 3.2075950136331697
Validation loss: 2.5966143684702603

Epoch: 6| Step: 7
Training loss: 2.6404817079568894
Validation loss: 2.580288509429595

Epoch: 6| Step: 8
Training loss: 2.9224495552349685
Validation loss: 2.5999624686612615

Epoch: 6| Step: 9
Training loss: 2.851194760374056
Validation loss: 2.610007856961701

Epoch: 6| Step: 10
Training loss: 2.840131868336577
Validation loss: 2.6101313936421646

Epoch: 6| Step: 11
Training loss: 2.328839800378381
Validation loss: 2.6398840025541435

Epoch: 6| Step: 12
Training loss: 3.571381590397951
Validation loss: 2.666539756064811

Epoch: 6| Step: 13
Training loss: 1.8141681623941872
Validation loss: 2.659378249029029

Epoch: 451| Step: 0
Training loss: 3.144788117905331
Validation loss: 2.6203918020808974

Epoch: 6| Step: 1
Training loss: 3.0633117222845185
Validation loss: 2.648328262880072

Epoch: 6| Step: 2
Training loss: 2.2405319215815642
Validation loss: 2.634420045380374

Epoch: 6| Step: 3
Training loss: 2.416435581427623
Validation loss: 2.6289118689457327

Epoch: 6| Step: 4
Training loss: 3.099352147486771
Validation loss: 2.6167794563507476

Epoch: 6| Step: 5
Training loss: 2.724282784525769
Validation loss: 2.6053592935443617

Epoch: 6| Step: 6
Training loss: 2.8259884683167202
Validation loss: 2.6112902257025796

Epoch: 6| Step: 7
Training loss: 2.6831235515342655
Validation loss: 2.5926223885462623

Epoch: 6| Step: 8
Training loss: 2.5352965611450866
Validation loss: 2.6047212747643074

Epoch: 6| Step: 9
Training loss: 2.652127825974845
Validation loss: 2.619644935628519

Epoch: 6| Step: 10
Training loss: 2.8837728580648685
Validation loss: 2.6408349788793974

Epoch: 6| Step: 11
Training loss: 2.6230632358248136
Validation loss: 2.637309537183837

Epoch: 6| Step: 12
Training loss: 3.0533786320831253
Validation loss: 2.606749267397128

Epoch: 6| Step: 13
Training loss: 2.9781802129280677
Validation loss: 2.586710627268661

Epoch: 452| Step: 0
Training loss: 2.753582787962987
Validation loss: 2.5720922863122766

Epoch: 6| Step: 1
Training loss: 2.905393905065423
Validation loss: 2.558574762550232

Epoch: 6| Step: 2
Training loss: 2.8628900320536808
Validation loss: 2.5547989247128666

Epoch: 6| Step: 3
Training loss: 2.667393903114986
Validation loss: 2.5443400013382482

Epoch: 6| Step: 4
Training loss: 2.627707583632655
Validation loss: 2.5484928599428534

Epoch: 6| Step: 5
Training loss: 3.130080861031267
Validation loss: 2.5479625154413097

Epoch: 6| Step: 6
Training loss: 3.0354955770742773
Validation loss: 2.5689624200839614

Epoch: 6| Step: 7
Training loss: 2.774355454381406
Validation loss: 2.5984294857269834

Epoch: 6| Step: 8
Training loss: 2.829830266762316
Validation loss: 2.6385550203744073

Epoch: 6| Step: 9
Training loss: 3.0338845356525
Validation loss: 2.661929020040839

Epoch: 6| Step: 10
Training loss: 2.597184538497035
Validation loss: 2.702007993528462

Epoch: 6| Step: 11
Training loss: 3.2747217540622167
Validation loss: 2.6584665237385914

Epoch: 6| Step: 12
Training loss: 2.2942570928767623
Validation loss: 2.649813897766088

Epoch: 6| Step: 13
Training loss: 2.3664384418462805
Validation loss: 2.6359735286675097

Epoch: 453| Step: 0
Training loss: 3.1520230533124725
Validation loss: 2.6168583184932017

Epoch: 6| Step: 1
Training loss: 3.0585264001205505
Validation loss: 2.5748644215164926

Epoch: 6| Step: 2
Training loss: 2.0613950601755624
Validation loss: 2.558005096571131

Epoch: 6| Step: 3
Training loss: 3.0924442502719494
Validation loss: 2.5409506426851425

Epoch: 6| Step: 4
Training loss: 2.8075835595812215
Validation loss: 2.534371167810181

Epoch: 6| Step: 5
Training loss: 2.5414517942393924
Validation loss: 2.5432281142606246

Epoch: 6| Step: 6
Training loss: 3.05971930244881
Validation loss: 2.5432135825130477

Epoch: 6| Step: 7
Training loss: 3.4852904070969117
Validation loss: 2.5474006447099904

Epoch: 6| Step: 8
Training loss: 2.431356660126242
Validation loss: 2.571294317815778

Epoch: 6| Step: 9
Training loss: 2.7209779226801696
Validation loss: 2.586773637470677

Epoch: 6| Step: 10
Training loss: 2.7111380115418235
Validation loss: 2.5987577856444477

Epoch: 6| Step: 11
Training loss: 2.6792025558259014
Validation loss: 2.621912979554319

Epoch: 6| Step: 12
Training loss: 2.4363833094725202
Validation loss: 2.6226336638783745

Epoch: 6| Step: 13
Training loss: 2.5970478463978077
Validation loss: 2.659245164534846

Epoch: 454| Step: 0
Training loss: 3.213781132526863
Validation loss: 2.678402939637723

Epoch: 6| Step: 1
Training loss: 3.0699492183797075
Validation loss: 2.6873629993681507

Epoch: 6| Step: 2
Training loss: 2.5562454745898493
Validation loss: 2.6791962280566533

Epoch: 6| Step: 3
Training loss: 2.8119665699649747
Validation loss: 2.678457614514002

Epoch: 6| Step: 4
Training loss: 2.8178461761509856
Validation loss: 2.676181178830624

Epoch: 6| Step: 5
Training loss: 2.7392605977035753
Validation loss: 2.6598465305685464

Epoch: 6| Step: 6
Training loss: 2.2155489328774958
Validation loss: 2.64097442033501

Epoch: 6| Step: 7
Training loss: 2.840093924352768
Validation loss: 2.6169215648058546

Epoch: 6| Step: 8
Training loss: 2.8019285951075377
Validation loss: 2.597843152277808

Epoch: 6| Step: 9
Training loss: 3.146314184226015
Validation loss: 2.5844073862996018

Epoch: 6| Step: 10
Training loss: 2.5034023021775487
Validation loss: 2.5720189420598727

Epoch: 6| Step: 11
Training loss: 2.669532686120937
Validation loss: 2.58595145657686

Epoch: 6| Step: 12
Training loss: 2.84074175671294
Validation loss: 2.571109263611294

Epoch: 6| Step: 13
Training loss: 2.877706000596082
Validation loss: 2.572573121033788

Epoch: 455| Step: 0
Training loss: 2.3258842591528706
Validation loss: 2.5956534241085896

Epoch: 6| Step: 1
Training loss: 2.8473799457645255
Validation loss: 2.5993157222287873

Epoch: 6| Step: 2
Training loss: 2.8343264204444405
Validation loss: 2.590752656890954

Epoch: 6| Step: 3
Training loss: 2.4968810653135423
Validation loss: 2.6218497460906507

Epoch: 6| Step: 4
Training loss: 3.2523399145913308
Validation loss: 2.6013287805689482

Epoch: 6| Step: 5
Training loss: 2.9815382332289575
Validation loss: 2.615334993068326

Epoch: 6| Step: 6
Training loss: 2.3519166191852663
Validation loss: 2.6092690047238056

Epoch: 6| Step: 7
Training loss: 3.211390999281862
Validation loss: 2.603393311551412

Epoch: 6| Step: 8
Training loss: 2.740592035945703
Validation loss: 2.593162042007621

Epoch: 6| Step: 9
Training loss: 2.5265203487770336
Validation loss: 2.571073233324769

Epoch: 6| Step: 10
Training loss: 2.9584277142437116
Validation loss: 2.5884224650521417

Epoch: 6| Step: 11
Training loss: 2.789627231730164
Validation loss: 2.5801952741889926

Epoch: 6| Step: 12
Training loss: 2.7784575255825064
Validation loss: 2.5956274680960756

Epoch: 6| Step: 13
Training loss: 2.6211490539992663
Validation loss: 2.60907636415491

Epoch: 456| Step: 0
Training loss: 2.7485279998713237
Validation loss: 2.6287666657601276

Epoch: 6| Step: 1
Training loss: 3.384297879538852
Validation loss: 2.647637176176273

Epoch: 6| Step: 2
Training loss: 2.7245349067164217
Validation loss: 2.627794420066367

Epoch: 6| Step: 3
Training loss: 2.8791763820751104
Validation loss: 2.6291545594684527

Epoch: 6| Step: 4
Training loss: 2.226194973779093
Validation loss: 2.633838171275258

Epoch: 6| Step: 5
Training loss: 2.8356561862776846
Validation loss: 2.6217706840265724

Epoch: 6| Step: 6
Training loss: 2.9590249842510414
Validation loss: 2.644289986248304

Epoch: 6| Step: 7
Training loss: 2.7145728106427733
Validation loss: 2.63945801417178

Epoch: 6| Step: 8
Training loss: 2.9373865308557594
Validation loss: 2.6268054175746665

Epoch: 6| Step: 9
Training loss: 2.046578305705173
Validation loss: 2.6257295195432953

Epoch: 6| Step: 10
Training loss: 2.9729290910945503
Validation loss: 2.6284678454936197

Epoch: 6| Step: 11
Training loss: 2.6229807035119594
Validation loss: 2.6116563406946796

Epoch: 6| Step: 12
Training loss: 2.437465960925187
Validation loss: 2.6077930375074234

Epoch: 6| Step: 13
Training loss: 3.2750655247779936
Validation loss: 2.590785784334538

Epoch: 457| Step: 0
Training loss: 2.9983356945572086
Validation loss: 2.5911060887763457

Epoch: 6| Step: 1
Training loss: 2.308813197619124
Validation loss: 2.5723627394334434

Epoch: 6| Step: 2
Training loss: 2.819068359531292
Validation loss: 2.552861757747994

Epoch: 6| Step: 3
Training loss: 2.5951587574048824
Validation loss: 2.563086811929052

Epoch: 6| Step: 4
Training loss: 3.299195255066709
Validation loss: 2.5686824190388506

Epoch: 6| Step: 5
Training loss: 2.485298225115294
Validation loss: 2.5729584883353622

Epoch: 6| Step: 6
Training loss: 2.5576967953079417
Validation loss: 2.6047363767209957

Epoch: 6| Step: 7
Training loss: 2.959601188805232
Validation loss: 2.62065277270605

Epoch: 6| Step: 8
Training loss: 3.0128380740081058
Validation loss: 2.627649995157076

Epoch: 6| Step: 9
Training loss: 2.7391137613917134
Validation loss: 2.62195152315658

Epoch: 6| Step: 10
Training loss: 2.7883723925195563
Validation loss: 2.5985403311476145

Epoch: 6| Step: 11
Training loss: 3.2508869428076075
Validation loss: 2.5894785383351775

Epoch: 6| Step: 12
Training loss: 2.385088624567187
Validation loss: 2.5682348841202423

Epoch: 6| Step: 13
Training loss: 2.399104022627856
Validation loss: 2.578746305386731

Epoch: 458| Step: 0
Training loss: 3.1976309947962784
Validation loss: 2.5855616790966525

Epoch: 6| Step: 1
Training loss: 2.813932604971602
Validation loss: 2.6165557583745684

Epoch: 6| Step: 2
Training loss: 3.0985915706954446
Validation loss: 2.638325708054483

Epoch: 6| Step: 3
Training loss: 2.556663845297771
Validation loss: 2.6362266795392184

Epoch: 6| Step: 4
Training loss: 2.959690767579827
Validation loss: 2.6502941778224622

Epoch: 6| Step: 5
Training loss: 2.7140660770724305
Validation loss: 2.6328301906128284

Epoch: 6| Step: 6
Training loss: 2.63187289804752
Validation loss: 2.602961056798176

Epoch: 6| Step: 7
Training loss: 2.6534807916941188
Validation loss: 2.5665642926346495

Epoch: 6| Step: 8
Training loss: 2.7067869222012484
Validation loss: 2.5403189358129232

Epoch: 6| Step: 9
Training loss: 2.758531082379242
Validation loss: 2.5348268322034015

Epoch: 6| Step: 10
Training loss: 3.1695490986333468
Validation loss: 2.524799784460396

Epoch: 6| Step: 11
Training loss: 2.3109202788603076
Validation loss: 2.524576609497996

Epoch: 6| Step: 12
Training loss: 2.829455826542098
Validation loss: 2.528204301037842

Epoch: 6| Step: 13
Training loss: 2.7667609861298312
Validation loss: 2.5335437798834

Epoch: 459| Step: 0
Training loss: 2.681426526640892
Validation loss: 2.5324927089627387

Epoch: 6| Step: 1
Training loss: 2.4790530993524884
Validation loss: 2.529370988792641

Epoch: 6| Step: 2
Training loss: 3.09650044567586
Validation loss: 2.5388171722555217

Epoch: 6| Step: 3
Training loss: 2.7456212295169413
Validation loss: 2.547945892730089

Epoch: 6| Step: 4
Training loss: 3.2740643977576345
Validation loss: 2.560749273261358

Epoch: 6| Step: 5
Training loss: 3.222859250235134
Validation loss: 2.582156893600163

Epoch: 6| Step: 6
Training loss: 2.631954064487221
Validation loss: 2.613693119745902

Epoch: 6| Step: 7
Training loss: 2.3215315471069196
Validation loss: 2.6184803487239843

Epoch: 6| Step: 8
Training loss: 2.8717447178691518
Validation loss: 2.629662933545848

Epoch: 6| Step: 9
Training loss: 2.7063691181282628
Validation loss: 2.622495680362562

Epoch: 6| Step: 10
Training loss: 2.556039061855272
Validation loss: 2.620404936295884

Epoch: 6| Step: 11
Training loss: 3.1189366837092583
Validation loss: 2.591422599315934

Epoch: 6| Step: 12
Training loss: 2.5139078475583836
Validation loss: 2.589652017538474

Epoch: 6| Step: 13
Training loss: 2.881289692437754
Validation loss: 2.571158704100086

Epoch: 460| Step: 0
Training loss: 2.9479316378551395
Validation loss: 2.5633622276329793

Epoch: 6| Step: 1
Training loss: 2.037139219392782
Validation loss: 2.574763307207477

Epoch: 6| Step: 2
Training loss: 2.2800362898632254
Validation loss: 2.5698682905685417

Epoch: 6| Step: 3
Training loss: 3.8999041472173275
Validation loss: 2.5709484420866975

Epoch: 6| Step: 4
Training loss: 2.460127439842024
Validation loss: 2.588244432846323

Epoch: 6| Step: 5
Training loss: 2.5430964424665525
Validation loss: 2.5939549171064016

Epoch: 6| Step: 6
Training loss: 2.685085720349084
Validation loss: 2.624054700944702

Epoch: 6| Step: 7
Training loss: 2.754408337430498
Validation loss: 2.6160961958376157

Epoch: 6| Step: 8
Training loss: 2.917934432842883
Validation loss: 2.6035634920270883

Epoch: 6| Step: 9
Training loss: 3.057833171417897
Validation loss: 2.595982414814022

Epoch: 6| Step: 10
Training loss: 2.9763076152455827
Validation loss: 2.5787277387193672

Epoch: 6| Step: 11
Training loss: 3.167610797344293
Validation loss: 2.5619183812449715

Epoch: 6| Step: 12
Training loss: 2.252727444900852
Validation loss: 2.555662690229919

Epoch: 6| Step: 13
Training loss: 2.440722853570867
Validation loss: 2.5481661778630706

Epoch: 461| Step: 0
Training loss: 3.1056335021647463
Validation loss: 2.5612272217553325

Epoch: 6| Step: 1
Training loss: 3.2744477017452644
Validation loss: 2.5594442938213358

Epoch: 6| Step: 2
Training loss: 2.593996702664176
Validation loss: 2.5753622979355457

Epoch: 6| Step: 3
Training loss: 2.2180105777140837
Validation loss: 2.5928927627301666

Epoch: 6| Step: 4
Training loss: 2.943008614582256
Validation loss: 2.6075761251130984

Epoch: 6| Step: 5
Training loss: 2.1262703632543554
Validation loss: 2.5996782566420387

Epoch: 6| Step: 6
Training loss: 2.7402713525714706
Validation loss: 2.623143774748811

Epoch: 6| Step: 7
Training loss: 3.2594320904860457
Validation loss: 2.629540666416649

Epoch: 6| Step: 8
Training loss: 1.8707288414108945
Validation loss: 2.616197867481937

Epoch: 6| Step: 9
Training loss: 2.8610901404870464
Validation loss: 2.594231440388146

Epoch: 6| Step: 10
Training loss: 2.8051459912609893
Validation loss: 2.5926197553133976

Epoch: 6| Step: 11
Training loss: 3.042045325830024
Validation loss: 2.5722085932405387

Epoch: 6| Step: 12
Training loss: 2.7772858904728253
Validation loss: 2.561171030240766

Epoch: 6| Step: 13
Training loss: 3.0457450140704267
Validation loss: 2.548150636003338

Epoch: 462| Step: 0
Training loss: 2.7958257827618933
Validation loss: 2.537902918611412

Epoch: 6| Step: 1
Training loss: 1.9368595172156164
Validation loss: 2.538592513060345

Epoch: 6| Step: 2
Training loss: 3.080818043853927
Validation loss: 2.54415545229911

Epoch: 6| Step: 3
Training loss: 2.7252686499361767
Validation loss: 2.5652697661141044

Epoch: 6| Step: 4
Training loss: 2.631979519071578
Validation loss: 2.5868816545037636

Epoch: 6| Step: 5
Training loss: 3.0285127216366035
Validation loss: 2.5845577082109954

Epoch: 6| Step: 6
Training loss: 3.153037976821143
Validation loss: 2.5996240993698585

Epoch: 6| Step: 7
Training loss: 2.8017002869660845
Validation loss: 2.6391460842434227

Epoch: 6| Step: 8
Training loss: 2.7474589311968396
Validation loss: 2.6458763152657103

Epoch: 6| Step: 9
Training loss: 3.007467829785114
Validation loss: 2.6324084696636483

Epoch: 6| Step: 10
Training loss: 3.2034704998974752
Validation loss: 2.6552220400941775

Epoch: 6| Step: 11
Training loss: 2.3581325467997694
Validation loss: 2.6071941794188374

Epoch: 6| Step: 12
Training loss: 3.0306501286574705
Validation loss: 2.5882831262060257

Epoch: 6| Step: 13
Training loss: 1.4757647099938749
Validation loss: 2.5711618389051183

Epoch: 463| Step: 0
Training loss: 2.836700757094892
Validation loss: 2.5463498397804245

Epoch: 6| Step: 1
Training loss: 2.4155968786579196
Validation loss: 2.5465295555970835

Epoch: 6| Step: 2
Training loss: 2.377140686609252
Validation loss: 2.5427216465756377

Epoch: 6| Step: 3
Training loss: 2.6847965038338177
Validation loss: 2.546075055738624

Epoch: 6| Step: 4
Training loss: 3.341524613580463
Validation loss: 2.5552290671402615

Epoch: 6| Step: 5
Training loss: 2.3486342336923975
Validation loss: 2.571153592086353

Epoch: 6| Step: 6
Training loss: 3.186348202113558
Validation loss: 2.581246338507771

Epoch: 6| Step: 7
Training loss: 2.782909112760029
Validation loss: 2.586763530649618

Epoch: 6| Step: 8
Training loss: 2.48559204616864
Validation loss: 2.604031930370724

Epoch: 6| Step: 9
Training loss: 3.2443264076093405
Validation loss: 2.609044117464297

Epoch: 6| Step: 10
Training loss: 2.931767978735721
Validation loss: 2.6342231323779304

Epoch: 6| Step: 11
Training loss: 2.8903818389068627
Validation loss: 2.6386271544661994

Epoch: 6| Step: 12
Training loss: 2.628188603523986
Validation loss: 2.6550749272136014

Epoch: 6| Step: 13
Training loss: 1.935013806394859
Validation loss: 2.6385339470887055

Epoch: 464| Step: 0
Training loss: 3.167628560456779
Validation loss: 2.6563551281773843

Epoch: 6| Step: 1
Training loss: 2.4101918618215885
Validation loss: 2.6546492499912873

Epoch: 6| Step: 2
Training loss: 2.245858088859991
Validation loss: 2.6099128505326448

Epoch: 6| Step: 3
Training loss: 2.810698886177558
Validation loss: 2.591369102498396

Epoch: 6| Step: 4
Training loss: 2.229265573274145
Validation loss: 2.5914335100539407

Epoch: 6| Step: 5
Training loss: 3.508097953481445
Validation loss: 2.583957552707664

Epoch: 6| Step: 6
Training loss: 3.307738282493219
Validation loss: 2.575593932873034

Epoch: 6| Step: 7
Training loss: 2.6012805866164492
Validation loss: 2.5904405614879744

Epoch: 6| Step: 8
Training loss: 2.9681765353816862
Validation loss: 2.5865982094426463

Epoch: 6| Step: 9
Training loss: 2.4713887465817588
Validation loss: 2.610132347346874

Epoch: 6| Step: 10
Training loss: 2.573559319138052
Validation loss: 2.6227129491843515

Epoch: 6| Step: 11
Training loss: 2.4965942072147103
Validation loss: 2.653397074123569

Epoch: 6| Step: 12
Training loss: 2.8460427567895255
Validation loss: 2.6493966495378984

Epoch: 6| Step: 13
Training loss: 2.684959008811457
Validation loss: 2.6531681720672604

Epoch: 465| Step: 0
Training loss: 2.886000444503401
Validation loss: 2.65769881537014

Epoch: 6| Step: 1
Training loss: 2.745586929109445
Validation loss: 2.6409873124054197

Epoch: 6| Step: 2
Training loss: 3.023157387702518
Validation loss: 2.6019646359874775

Epoch: 6| Step: 3
Training loss: 2.6225509117864823
Validation loss: 2.5740333283826238

Epoch: 6| Step: 4
Training loss: 2.482190401223735
Validation loss: 2.558931767150227

Epoch: 6| Step: 5
Training loss: 2.370915564891489
Validation loss: 2.5569495910124074

Epoch: 6| Step: 6
Training loss: 2.955598148797514
Validation loss: 2.5583259227544213

Epoch: 6| Step: 7
Training loss: 3.085877854941786
Validation loss: 2.549780061475264

Epoch: 6| Step: 8
Training loss: 3.045603795062888
Validation loss: 2.550040720502511

Epoch: 6| Step: 9
Training loss: 2.7439324459513097
Validation loss: 2.548416260193778

Epoch: 6| Step: 10
Training loss: 2.19363784720717
Validation loss: 2.5813038424567

Epoch: 6| Step: 11
Training loss: 2.62143610666988
Validation loss: 2.5960422621079395

Epoch: 6| Step: 12
Training loss: 2.618625075244352
Validation loss: 2.6299104609399917

Epoch: 6| Step: 13
Training loss: 3.4235185133916897
Validation loss: 2.6503745721553997

Epoch: 466| Step: 0
Training loss: 3.107605397039807
Validation loss: 2.6665722380987926

Epoch: 6| Step: 1
Training loss: 1.9980372095853098
Validation loss: 2.6650601349452514

Epoch: 6| Step: 2
Training loss: 3.001236819580319
Validation loss: 2.6651320686846813

Epoch: 6| Step: 3
Training loss: 2.3354495760538354
Validation loss: 2.6537590976414025

Epoch: 6| Step: 4
Training loss: 2.176527679449632
Validation loss: 2.6069715332733048

Epoch: 6| Step: 5
Training loss: 2.5727827729715957
Validation loss: 2.59838737384342

Epoch: 6| Step: 6
Training loss: 2.727686871526477
Validation loss: 2.5912396840284524

Epoch: 6| Step: 7
Training loss: 2.6343739574063774
Validation loss: 2.5710453928895762

Epoch: 6| Step: 8
Training loss: 3.156705615707344
Validation loss: 2.564460002811003

Epoch: 6| Step: 9
Training loss: 3.3374511715178135
Validation loss: 2.571772414888915

Epoch: 6| Step: 10
Training loss: 2.961253126729697
Validation loss: 2.5514418535167693

Epoch: 6| Step: 11
Training loss: 2.583876973037221
Validation loss: 2.5714847193065333

Epoch: 6| Step: 12
Training loss: 3.0640877480952375
Validation loss: 2.564532883481604

Epoch: 6| Step: 13
Training loss: 2.8300093806350577
Validation loss: 2.573477258316664

Epoch: 467| Step: 0
Training loss: 2.772456637732224
Validation loss: 2.588161462784793

Epoch: 6| Step: 1
Training loss: 3.0910672973494386
Validation loss: 2.604865941494215

Epoch: 6| Step: 2
Training loss: 2.8739671925243084
Validation loss: 2.619727943917727

Epoch: 6| Step: 3
Training loss: 2.725263400865219
Validation loss: 2.6198999950119752

Epoch: 6| Step: 4
Training loss: 3.0070476401703226
Validation loss: 2.6537568767117437

Epoch: 6| Step: 5
Training loss: 3.242048366272923
Validation loss: 2.6780930693657945

Epoch: 6| Step: 6
Training loss: 2.4200079827925745
Validation loss: 2.670312235063853

Epoch: 6| Step: 7
Training loss: 2.720781115682694
Validation loss: 2.6469964841065905

Epoch: 6| Step: 8
Training loss: 2.6390527863942017
Validation loss: 2.6227416008230575

Epoch: 6| Step: 9
Training loss: 2.6093978423986157
Validation loss: 2.5834038787985123

Epoch: 6| Step: 10
Training loss: 2.673056625622697
Validation loss: 2.544201851540867

Epoch: 6| Step: 11
Training loss: 2.66693050350902
Validation loss: 2.5335558950859016

Epoch: 6| Step: 12
Training loss: 2.613104707374054
Validation loss: 2.547348047983983

Epoch: 6| Step: 13
Training loss: 2.8550068159406177
Validation loss: 2.5377715392596043

Epoch: 468| Step: 0
Training loss: 2.8284084957778
Validation loss: 2.5336130936826584

Epoch: 6| Step: 1
Training loss: 2.9570893013621466
Validation loss: 2.5324353241012934

Epoch: 6| Step: 2
Training loss: 2.7617122752587204
Validation loss: 2.5256389363270992

Epoch: 6| Step: 3
Training loss: 2.919113241133853
Validation loss: 2.5438392242757883

Epoch: 6| Step: 4
Training loss: 3.0921262853576357
Validation loss: 2.5452391379055754

Epoch: 6| Step: 5
Training loss: 2.279212564381667
Validation loss: 2.5741010449733137

Epoch: 6| Step: 6
Training loss: 2.460834319358531
Validation loss: 2.589844794325676

Epoch: 6| Step: 7
Training loss: 2.6384038669060477
Validation loss: 2.6035894358794773

Epoch: 6| Step: 8
Training loss: 2.8286279052061336
Validation loss: 2.6525331603209077

Epoch: 6| Step: 9
Training loss: 2.8879183907852966
Validation loss: 2.662967269945791

Epoch: 6| Step: 10
Training loss: 3.218172484503379
Validation loss: 2.662790269601852

Epoch: 6| Step: 11
Training loss: 2.5735566325310826
Validation loss: 2.621241913268259

Epoch: 6| Step: 12
Training loss: 2.766274413678965
Validation loss: 2.5918712965544017

Epoch: 6| Step: 13
Training loss: 2.6544839710262527
Validation loss: 2.603240251384792

Epoch: 469| Step: 0
Training loss: 2.4684735879796693
Validation loss: 2.601786993420971

Epoch: 6| Step: 1
Training loss: 2.750317901963177
Validation loss: 2.6191041268841064

Epoch: 6| Step: 2
Training loss: 2.9711759593502536
Validation loss: 2.625448711072302

Epoch: 6| Step: 3
Training loss: 3.630666053554312
Validation loss: 2.6171550172624514

Epoch: 6| Step: 4
Training loss: 2.4386958587752727
Validation loss: 2.5969568436539263

Epoch: 6| Step: 5
Training loss: 2.9563397061244183
Validation loss: 2.5808509264906476

Epoch: 6| Step: 6
Training loss: 2.42653301587096
Validation loss: 2.610382998525771

Epoch: 6| Step: 7
Training loss: 2.1059862962224396
Validation loss: 2.650422264179477

Epoch: 6| Step: 8
Training loss: 2.727959567338104
Validation loss: 2.68134957596736

Epoch: 6| Step: 9
Training loss: 2.7452386037383123
Validation loss: 2.686575527160842

Epoch: 6| Step: 10
Training loss: 3.34236187508964
Validation loss: 2.671553728628015

Epoch: 6| Step: 11
Training loss: 2.938982325772997
Validation loss: 2.646008807787445

Epoch: 6| Step: 12
Training loss: 2.184685231282515
Validation loss: 2.6311194096941053

Epoch: 6| Step: 13
Training loss: 2.6776309115109216
Validation loss: 2.587182398430096

Epoch: 470| Step: 0
Training loss: 2.4929518529019874
Validation loss: 2.5729337501299168

Epoch: 6| Step: 1
Training loss: 3.0707491886889726
Validation loss: 2.5621739001688035

Epoch: 6| Step: 2
Training loss: 2.2422598052910434
Validation loss: 2.5495454432530336

Epoch: 6| Step: 3
Training loss: 2.9234768153798445
Validation loss: 2.553825386237335

Epoch: 6| Step: 4
Training loss: 2.556693779587334
Validation loss: 2.5439687423945037

Epoch: 6| Step: 5
Training loss: 2.485153268274451
Validation loss: 2.5435930137369427

Epoch: 6| Step: 6
Training loss: 2.8208825547071563
Validation loss: 2.5468978221501657

Epoch: 6| Step: 7
Training loss: 3.236257990904218
Validation loss: 2.553583587073033

Epoch: 6| Step: 8
Training loss: 2.664509934246308
Validation loss: 2.567473208953479

Epoch: 6| Step: 9
Training loss: 3.121974090439335
Validation loss: 2.5630193294626404

Epoch: 6| Step: 10
Training loss: 2.8555188468160186
Validation loss: 2.582903628447701

Epoch: 6| Step: 11
Training loss: 2.3638965656869595
Validation loss: 2.6215676966884462

Epoch: 6| Step: 12
Training loss: 3.0814570483114605
Validation loss: 2.6677268642028533

Epoch: 6| Step: 13
Training loss: 2.6252503048677105
Validation loss: 2.690690830923139

Epoch: 471| Step: 0
Training loss: 2.5919960250176457
Validation loss: 2.697077049225149

Epoch: 6| Step: 1
Training loss: 3.167421418308923
Validation loss: 2.7094143697022823

Epoch: 6| Step: 2
Training loss: 2.811491806737449
Validation loss: 2.695643914695222

Epoch: 6| Step: 3
Training loss: 2.836577204075393
Validation loss: 2.6839624232178823

Epoch: 6| Step: 4
Training loss: 3.182610445346111
Validation loss: 2.6107729087176015

Epoch: 6| Step: 5
Training loss: 2.828913289008434
Validation loss: 2.6038436479300078

Epoch: 6| Step: 6
Training loss: 2.692830853407974
Validation loss: 2.578758776871009

Epoch: 6| Step: 7
Training loss: 2.690873180467291
Validation loss: 2.5525500662871137

Epoch: 6| Step: 8
Training loss: 1.847288002270661
Validation loss: 2.552472587937144

Epoch: 6| Step: 9
Training loss: 2.70702129764021
Validation loss: 2.54314117504884

Epoch: 6| Step: 10
Training loss: 2.858597613277572
Validation loss: 2.546108751393422

Epoch: 6| Step: 11
Training loss: 2.216124579704624
Validation loss: 2.546890321151114

Epoch: 6| Step: 12
Training loss: 3.26983910937656
Validation loss: 2.540450875688195

Epoch: 6| Step: 13
Training loss: 2.8749328273721204
Validation loss: 2.572634322060713

Epoch: 472| Step: 0
Training loss: 2.579556616750207
Validation loss: 2.5701695669980285

Epoch: 6| Step: 1
Training loss: 2.7772865772398605
Validation loss: 2.6196768198988285

Epoch: 6| Step: 2
Training loss: 2.7715174946543364
Validation loss: 2.6229540434679492

Epoch: 6| Step: 3
Training loss: 2.861989977847718
Validation loss: 2.646070038743832

Epoch: 6| Step: 4
Training loss: 2.4070574904178157
Validation loss: 2.653447363918296

Epoch: 6| Step: 5
Training loss: 1.7367829112334574
Validation loss: 2.6567509110716645

Epoch: 6| Step: 6
Training loss: 2.933220525942193
Validation loss: 2.690749653108769

Epoch: 6| Step: 7
Training loss: 3.0565267425869864
Validation loss: 2.6985725982980733

Epoch: 6| Step: 8
Training loss: 3.129523398581725
Validation loss: 2.6778071558844827

Epoch: 6| Step: 9
Training loss: 3.007302297941804
Validation loss: 2.6455439967388927

Epoch: 6| Step: 10
Training loss: 2.811729071180305
Validation loss: 2.6114565960307026

Epoch: 6| Step: 11
Training loss: 3.105105281648213
Validation loss: 2.5916050773223844

Epoch: 6| Step: 12
Training loss: 2.3679587741240193
Validation loss: 2.554243281145034

Epoch: 6| Step: 13
Training loss: 2.9241151433105177
Validation loss: 2.5508226784731303

Epoch: 473| Step: 0
Training loss: 2.860816967194441
Validation loss: 2.5369144654609332

Epoch: 6| Step: 1
Training loss: 2.862648679378567
Validation loss: 2.5448224803298856

Epoch: 6| Step: 2
Training loss: 2.122778572879498
Validation loss: 2.5498227097023345

Epoch: 6| Step: 3
Training loss: 2.7231300412442847
Validation loss: 2.5692485102348583

Epoch: 6| Step: 4
Training loss: 2.3546238233111034
Validation loss: 2.5581427093859186

Epoch: 6| Step: 5
Training loss: 2.9278278603111656
Validation loss: 2.5641382134627904

Epoch: 6| Step: 6
Training loss: 3.58129342736881
Validation loss: 2.5878387858329313

Epoch: 6| Step: 7
Training loss: 2.596152146928454
Validation loss: 2.5615687705377477

Epoch: 6| Step: 8
Training loss: 2.8760040851823976
Validation loss: 2.5756012447699663

Epoch: 6| Step: 9
Training loss: 2.8201017433101327
Validation loss: 2.5528363869504345

Epoch: 6| Step: 10
Training loss: 2.749085100746028
Validation loss: 2.538092146383426

Epoch: 6| Step: 11
Training loss: 2.739730212162689
Validation loss: 2.5734433043722205

Epoch: 6| Step: 12
Training loss: 2.8044585663170722
Validation loss: 2.543536581819302

Epoch: 6| Step: 13
Training loss: 2.429405956576497
Validation loss: 2.6009265265569326

Epoch: 474| Step: 0
Training loss: 2.7652203969740916
Validation loss: 2.6154796000718052

Epoch: 6| Step: 1
Training loss: 3.080327983583923
Validation loss: 2.6316619098946124

Epoch: 6| Step: 2
Training loss: 3.294169685509712
Validation loss: 2.658134163777247

Epoch: 6| Step: 3
Training loss: 2.7534109116524874
Validation loss: 2.597997363251695

Epoch: 6| Step: 4
Training loss: 3.057589896027595
Validation loss: 2.5988447094745983

Epoch: 6| Step: 5
Training loss: 2.599270839415732
Validation loss: 2.5772780085169718

Epoch: 6| Step: 6
Training loss: 2.0853940563011473
Validation loss: 2.5663198237784117

Epoch: 6| Step: 7
Training loss: 2.464902366267665
Validation loss: 2.574715563903135

Epoch: 6| Step: 8
Training loss: 2.5495552049051393
Validation loss: 2.571271563646777

Epoch: 6| Step: 9
Training loss: 2.982718602216737
Validation loss: 2.569409630726311

Epoch: 6| Step: 10
Training loss: 2.5399607786018934
Validation loss: 2.5521860697603658

Epoch: 6| Step: 11
Training loss: 2.739573392862095
Validation loss: 2.5619086026570645

Epoch: 6| Step: 12
Training loss: 2.8495372530390823
Validation loss: 2.5698154424038053

Epoch: 6| Step: 13
Training loss: 2.595873319788336
Validation loss: 2.5921472998647044

Epoch: 475| Step: 0
Training loss: 3.065298086733926
Validation loss: 2.596307065604002

Epoch: 6| Step: 1
Training loss: 2.2494669388755724
Validation loss: 2.617541735593425

Epoch: 6| Step: 2
Training loss: 2.854575877311909
Validation loss: 2.6446560855223575

Epoch: 6| Step: 3
Training loss: 2.853819405993723
Validation loss: 2.644846953171398

Epoch: 6| Step: 4
Training loss: 2.765977567624519
Validation loss: 2.6737708903555713

Epoch: 6| Step: 5
Training loss: 2.5024235422380667
Validation loss: 2.7192539365209347

Epoch: 6| Step: 6
Training loss: 3.053441410595103
Validation loss: 2.6857071629753095

Epoch: 6| Step: 7
Training loss: 2.7799673658966646
Validation loss: 2.6844909575307887

Epoch: 6| Step: 8
Training loss: 2.5711674065646846
Validation loss: 2.660888560475768

Epoch: 6| Step: 9
Training loss: 3.203002629617546
Validation loss: 2.623562112819991

Epoch: 6| Step: 10
Training loss: 2.736923860861644
Validation loss: 2.5928519204311944

Epoch: 6| Step: 11
Training loss: 2.5144148101423878
Validation loss: 2.5935937493658097

Epoch: 6| Step: 12
Training loss: 2.530366154587462
Validation loss: 2.558879448518052

Epoch: 6| Step: 13
Training loss: 2.9650122955221714
Validation loss: 2.554814965987247

Epoch: 476| Step: 0
Training loss: 2.707743233192659
Validation loss: 2.545879078448642

Epoch: 6| Step: 1
Training loss: 2.992747759844243
Validation loss: 2.5408624768403842

Epoch: 6| Step: 2
Training loss: 2.987516497323043
Validation loss: 2.519956928786192

Epoch: 6| Step: 3
Training loss: 3.2321867243583196
Validation loss: 2.5254563863282034

Epoch: 6| Step: 4
Training loss: 2.5586624252770545
Validation loss: 2.5411780614110895

Epoch: 6| Step: 5
Training loss: 2.7090695676492476
Validation loss: 2.536186270546621

Epoch: 6| Step: 6
Training loss: 2.817604519006332
Validation loss: 2.5608334798495043

Epoch: 6| Step: 7
Training loss: 2.8104745989447184
Validation loss: 2.5901949512957962

Epoch: 6| Step: 8
Training loss: 2.5506657198904024
Validation loss: 2.613477563206556

Epoch: 6| Step: 9
Training loss: 2.8115063077478344
Validation loss: 2.6624646619074737

Epoch: 6| Step: 10
Training loss: 2.332891104434874
Validation loss: 2.6676733926410683

Epoch: 6| Step: 11
Training loss: 2.2954699312341678
Validation loss: 2.666698783122238

Epoch: 6| Step: 12
Training loss: 3.4486259046006733
Validation loss: 2.6621265916551478

Epoch: 6| Step: 13
Training loss: 1.684752028242578
Validation loss: 2.6494031718524926

Epoch: 477| Step: 0
Training loss: 2.317042863155472
Validation loss: 2.6495264546572823

Epoch: 6| Step: 1
Training loss: 2.82175440398564
Validation loss: 2.6635656540955175

Epoch: 6| Step: 2
Training loss: 3.074531742822323
Validation loss: 2.6670700935818106

Epoch: 6| Step: 3
Training loss: 2.775288740377884
Validation loss: 2.664549993747587

Epoch: 6| Step: 4
Training loss: 2.699198787631954
Validation loss: 2.6379226329238534

Epoch: 6| Step: 5
Training loss: 2.373837839181724
Validation loss: 2.633372562285514

Epoch: 6| Step: 6
Training loss: 2.7794044457727183
Validation loss: 2.627195424640209

Epoch: 6| Step: 7
Training loss: 2.634033734898483
Validation loss: 2.6021060057455725

Epoch: 6| Step: 8
Training loss: 2.6634539583157104
Validation loss: 2.590094214750698

Epoch: 6| Step: 9
Training loss: 2.7211061112120087
Validation loss: 2.575139347132648

Epoch: 6| Step: 10
Training loss: 3.0835902304637726
Validation loss: 2.5549454257928064

Epoch: 6| Step: 11
Training loss: 3.20086247622978
Validation loss: 2.556401918098466

Epoch: 6| Step: 12
Training loss: 2.7269026317328713
Validation loss: 2.5280961695931485

Epoch: 6| Step: 13
Training loss: 2.361057111334539
Validation loss: 2.5465638885231106

Epoch: 478| Step: 0
Training loss: 2.9103212450605316
Validation loss: 2.5410772501222265

Epoch: 6| Step: 1
Training loss: 2.900961381131168
Validation loss: 2.545310775107715

Epoch: 6| Step: 2
Training loss: 2.9667470499642667
Validation loss: 2.555790908032159

Epoch: 6| Step: 3
Training loss: 2.6804598482095883
Validation loss: 2.568529625976073

Epoch: 6| Step: 4
Training loss: 2.6406126304201316
Validation loss: 2.5720849873646023

Epoch: 6| Step: 5
Training loss: 2.707475457894778
Validation loss: 2.6028947381182155

Epoch: 6| Step: 6
Training loss: 2.3432987032954657
Validation loss: 2.5932997683312053

Epoch: 6| Step: 7
Training loss: 2.5947446639434935
Validation loss: 2.6421099906611705

Epoch: 6| Step: 8
Training loss: 3.0627639033993965
Validation loss: 2.6570852222423142

Epoch: 6| Step: 9
Training loss: 2.55426824553366
Validation loss: 2.6562525363743523

Epoch: 6| Step: 10
Training loss: 2.5293469280460066
Validation loss: 2.679776384954375

Epoch: 6| Step: 11
Training loss: 2.592236456428853
Validation loss: 2.6763812424858013

Epoch: 6| Step: 12
Training loss: 2.8375890037256877
Validation loss: 2.690426228564971

Epoch: 6| Step: 13
Training loss: 3.208119736203948
Validation loss: 2.6558969816844584

Epoch: 479| Step: 0
Training loss: 2.7594290256071603
Validation loss: 2.6542664120587967

Epoch: 6| Step: 1
Training loss: 2.7238152334481787
Validation loss: 2.6201223908654936

Epoch: 6| Step: 2
Training loss: 3.039227870962581
Validation loss: 2.5985292114989873

Epoch: 6| Step: 3
Training loss: 2.707016277409441
Validation loss: 2.610837393362925

Epoch: 6| Step: 4
Training loss: 2.8417015662711744
Validation loss: 2.6197937846101316

Epoch: 6| Step: 5
Training loss: 2.2236741991509743
Validation loss: 2.6300701529457005

Epoch: 6| Step: 6
Training loss: 2.6680768774415005
Validation loss: 2.6382278267070642

Epoch: 6| Step: 7
Training loss: 2.542485110559067
Validation loss: 2.65885156174537

Epoch: 6| Step: 8
Training loss: 3.2325472620129565
Validation loss: 2.6545847962722897

Epoch: 6| Step: 9
Training loss: 2.4440251578426864
Validation loss: 2.6234860290417887

Epoch: 6| Step: 10
Training loss: 2.5474318381222982
Validation loss: 2.6369028291058516

Epoch: 6| Step: 11
Training loss: 2.500851009483964
Validation loss: 2.5791574846321903

Epoch: 6| Step: 12
Training loss: 2.915720777175287
Validation loss: 2.5597032511214515

Epoch: 6| Step: 13
Training loss: 2.9051570683102033
Validation loss: 2.542512411706626

Epoch: 480| Step: 0
Training loss: 2.689580156682446
Validation loss: 2.5253899174430163

Epoch: 6| Step: 1
Training loss: 2.2995051680952847
Validation loss: 2.535835659835115

Epoch: 6| Step: 2
Training loss: 2.1492387976590206
Validation loss: 2.5292928176424803

Epoch: 6| Step: 3
Training loss: 3.3943078919071965
Validation loss: 2.539213806137152

Epoch: 6| Step: 4
Training loss: 2.605300737766007
Validation loss: 2.5408780582350112

Epoch: 6| Step: 5
Training loss: 2.4033326137434066
Validation loss: 2.548440687138679

Epoch: 6| Step: 6
Training loss: 2.5178366469889206
Validation loss: 2.568985939153548

Epoch: 6| Step: 7
Training loss: 2.7571092092464213
Validation loss: 2.584129091519203

Epoch: 6| Step: 8
Training loss: 2.9823102749052897
Validation loss: 2.628122887300769

Epoch: 6| Step: 9
Training loss: 3.1361880108760998
Validation loss: 2.653776134689399

Epoch: 6| Step: 10
Training loss: 2.37549324936852
Validation loss: 2.638100369801235

Epoch: 6| Step: 11
Training loss: 3.324906203015372
Validation loss: 2.642266178226487

Epoch: 6| Step: 12
Training loss: 2.9592784571786384
Validation loss: 2.635329224682823

Epoch: 6| Step: 13
Training loss: 2.483068542529959
Validation loss: 2.6471989015843254

Epoch: 481| Step: 0
Training loss: 2.4274613463980916
Validation loss: 2.6208237809936517

Epoch: 6| Step: 1
Training loss: 3.0351083327037207
Validation loss: 2.629130206688899

Epoch: 6| Step: 2
Training loss: 2.529762867304942
Validation loss: 2.620468078421172

Epoch: 6| Step: 3
Training loss: 3.203656259535385
Validation loss: 2.6317548141748035

Epoch: 6| Step: 4
Training loss: 3.3476147999639965
Validation loss: 2.6443221783186064

Epoch: 6| Step: 5
Training loss: 2.7503655797541064
Validation loss: 2.642937279068826

Epoch: 6| Step: 6
Training loss: 2.6033316430620803
Validation loss: 2.6025111666158254

Epoch: 6| Step: 7
Training loss: 2.770552475158816
Validation loss: 2.60301272776229

Epoch: 6| Step: 8
Training loss: 2.454095539126611
Validation loss: 2.5734982118329337

Epoch: 6| Step: 9
Training loss: 2.237767984549189
Validation loss: 2.563557178391899

Epoch: 6| Step: 10
Training loss: 2.674543687635847
Validation loss: 2.5466696186249362

Epoch: 6| Step: 11
Training loss: 3.386575698031286
Validation loss: 2.549744114874432

Epoch: 6| Step: 12
Training loss: 2.441572552929665
Validation loss: 2.531779545922081

Epoch: 6| Step: 13
Training loss: 2.251004524636519
Validation loss: 2.5491110752492263

Epoch: 482| Step: 0
Training loss: 2.8825484984553627
Validation loss: 2.563935508791981

Epoch: 6| Step: 1
Training loss: 2.406195503707666
Validation loss: 2.588128405757037

Epoch: 6| Step: 2
Training loss: 2.3349728841248645
Validation loss: 2.6217057525136043

Epoch: 6| Step: 3
Training loss: 2.7776944868528073
Validation loss: 2.6498446382815377

Epoch: 6| Step: 4
Training loss: 2.4596668656726446
Validation loss: 2.663419676809849

Epoch: 6| Step: 5
Training loss: 2.093859769306557
Validation loss: 2.6634485210072536

Epoch: 6| Step: 6
Training loss: 3.126856595705179
Validation loss: 2.676548279306041

Epoch: 6| Step: 7
Training loss: 2.579708006400126
Validation loss: 2.637176699959231

Epoch: 6| Step: 8
Training loss: 2.9617269867561373
Validation loss: 2.6190963510987793

Epoch: 6| Step: 9
Training loss: 3.2858369283118734
Validation loss: 2.591431897535032

Epoch: 6| Step: 10
Training loss: 2.5344617271400827
Validation loss: 2.579875611472646

Epoch: 6| Step: 11
Training loss: 3.0582028817637052
Validation loss: 2.551521425917749

Epoch: 6| Step: 12
Training loss: 2.9191823373675767
Validation loss: 2.545808245722883

Epoch: 6| Step: 13
Training loss: 2.6894350404484566
Validation loss: 2.5384886764186585

Epoch: 483| Step: 0
Training loss: 2.7149242800837254
Validation loss: 2.536104577382151

Epoch: 6| Step: 1
Training loss: 2.3125253624427384
Validation loss: 2.550432959292507

Epoch: 6| Step: 2
Training loss: 2.836350087820386
Validation loss: 2.5623254523967747

Epoch: 6| Step: 3
Training loss: 3.101837069179384
Validation loss: 2.5688025310069142

Epoch: 6| Step: 4
Training loss: 2.60860893288507
Validation loss: 2.599522829797444

Epoch: 6| Step: 5
Training loss: 2.6405868978967986
Validation loss: 2.618507021518366

Epoch: 6| Step: 6
Training loss: 2.741119089684096
Validation loss: 2.625655216025474

Epoch: 6| Step: 7
Training loss: 2.648282566996389
Validation loss: 2.6317951306759233

Epoch: 6| Step: 8
Training loss: 2.3265901152724866
Validation loss: 2.636810963733735

Epoch: 6| Step: 9
Training loss: 2.869103729447081
Validation loss: 2.645396238084079

Epoch: 6| Step: 10
Training loss: 2.715025180819307
Validation loss: 2.6424562352307044

Epoch: 6| Step: 11
Training loss: 2.6916349670937074
Validation loss: 2.618013318095223

Epoch: 6| Step: 12
Training loss: 2.8531660196086066
Validation loss: 2.6268340977713702

Epoch: 6| Step: 13
Training loss: 3.3229325313049887
Validation loss: 2.6058432665674913

Epoch: 484| Step: 0
Training loss: 2.334696462371743
Validation loss: 2.5768604944987783

Epoch: 6| Step: 1
Training loss: 2.5066318287694345
Validation loss: 2.573317795213021

Epoch: 6| Step: 2
Training loss: 3.4353370103609717
Validation loss: 2.572663350061218

Epoch: 6| Step: 3
Training loss: 3.119595087870871
Validation loss: 2.570703871583154

Epoch: 6| Step: 4
Training loss: 2.5324331273610494
Validation loss: 2.5679440208701485

Epoch: 6| Step: 5
Training loss: 2.6656863278202176
Validation loss: 2.588194412910174

Epoch: 6| Step: 6
Training loss: 2.5115087726917493
Validation loss: 2.590860148846187

Epoch: 6| Step: 7
Training loss: 3.2784177636692506
Validation loss: 2.5752694134460303

Epoch: 6| Step: 8
Training loss: 2.2927917724105042
Validation loss: 2.614487592369808

Epoch: 6| Step: 9
Training loss: 2.39592250713306
Validation loss: 2.62187130059123

Epoch: 6| Step: 10
Training loss: 2.4916220474926107
Validation loss: 2.6246963077239527

Epoch: 6| Step: 11
Training loss: 2.9122451146789126
Validation loss: 2.6206243134461626

Epoch: 6| Step: 12
Training loss: 2.750583153362798
Validation loss: 2.633575546020625

Epoch: 6| Step: 13
Training loss: 2.599660000211416
Validation loss: 2.6164191415890636

Epoch: 485| Step: 0
Training loss: 2.490233034619737
Validation loss: 2.5922401086875713

Epoch: 6| Step: 1
Training loss: 1.8577038604053897
Validation loss: 2.5939090816867454

Epoch: 6| Step: 2
Training loss: 2.6092311796653798
Validation loss: 2.5839111455654136

Epoch: 6| Step: 3
Training loss: 3.240567678240697
Validation loss: 2.5764910370483416

Epoch: 6| Step: 4
Training loss: 2.8778867741010763
Validation loss: 2.5843189402305855

Epoch: 6| Step: 5
Training loss: 3.014652708178462
Validation loss: 2.569864075803681

Epoch: 6| Step: 6
Training loss: 2.2150868008313545
Validation loss: 2.5988782417874745

Epoch: 6| Step: 7
Training loss: 2.6752841905455775
Validation loss: 2.589601875799582

Epoch: 6| Step: 8
Training loss: 2.6142600924824295
Validation loss: 2.618567721709673

Epoch: 6| Step: 9
Training loss: 2.2742419310803292
Validation loss: 2.622084464903876

Epoch: 6| Step: 10
Training loss: 3.344153691816473
Validation loss: 2.644825692538665

Epoch: 6| Step: 11
Training loss: 3.05556184787295
Validation loss: 2.6424975691432864

Epoch: 6| Step: 12
Training loss: 2.529155099791001
Validation loss: 2.630358594567842

Epoch: 6| Step: 13
Training loss: 2.975192177600019
Validation loss: 2.6506113543279377

Epoch: 486| Step: 0
Training loss: 2.280757276023959
Validation loss: 2.6501461771178696

Epoch: 6| Step: 1
Training loss: 3.0039746657419455
Validation loss: 2.642783662520292

Epoch: 6| Step: 2
Training loss: 2.814121372384415
Validation loss: 2.612136206144227

Epoch: 6| Step: 3
Training loss: 2.5852983958457765
Validation loss: 2.5966232758869423

Epoch: 6| Step: 4
Training loss: 2.8834350244600975
Validation loss: 2.603180038759994

Epoch: 6| Step: 5
Training loss: 2.9264004998041377
Validation loss: 2.6052093738354185

Epoch: 6| Step: 6
Training loss: 2.38208957399284
Validation loss: 2.5960451792369454

Epoch: 6| Step: 7
Training loss: 2.638627419707864
Validation loss: 2.573956048501246

Epoch: 6| Step: 8
Training loss: 2.720286932424677
Validation loss: 2.565610053285807

Epoch: 6| Step: 9
Training loss: 2.1273921516955796
Validation loss: 2.57512445090351

Epoch: 6| Step: 10
Training loss: 2.4949234919007504
Validation loss: 2.586269062842921

Epoch: 6| Step: 11
Training loss: 3.1983511729999377
Validation loss: 2.5858579387371012

Epoch: 6| Step: 12
Training loss: 2.9307691688083186
Validation loss: 2.5882649627344745

Epoch: 6| Step: 13
Training loss: 2.766827510463247
Validation loss: 2.593856184686435

Epoch: 487| Step: 0
Training loss: 2.674856028737827
Validation loss: 2.587882367099829

Epoch: 6| Step: 1
Training loss: 2.634153120984982
Validation loss: 2.5552946565066783

Epoch: 6| Step: 2
Training loss: 2.8505819228517466
Validation loss: 2.5914136057625607

Epoch: 6| Step: 3
Training loss: 2.9457830968851124
Validation loss: 2.5861202113852837

Epoch: 6| Step: 4
Training loss: 2.5747280051268566
Validation loss: 2.587683150150649

Epoch: 6| Step: 5
Training loss: 2.2288241494638825
Validation loss: 2.6138260274132583

Epoch: 6| Step: 6
Training loss: 3.063415390537246
Validation loss: 2.6438954689772527

Epoch: 6| Step: 7
Training loss: 2.6087563518013646
Validation loss: 2.6855006506438537

Epoch: 6| Step: 8
Training loss: 2.260457215773132
Validation loss: 2.684334888875079

Epoch: 6| Step: 9
Training loss: 2.3639499191233497
Validation loss: 2.6642852671781094

Epoch: 6| Step: 10
Training loss: 3.1219553038814625
Validation loss: 2.64301196679514

Epoch: 6| Step: 11
Training loss: 2.9996426687418483
Validation loss: 2.6033622421359737

Epoch: 6| Step: 12
Training loss: 2.689837658886601
Validation loss: 2.5835181036880197

Epoch: 6| Step: 13
Training loss: 2.900227695602594
Validation loss: 2.567112420934482

Epoch: 488| Step: 0
Training loss: 2.812893225413454
Validation loss: 2.56191652099458

Epoch: 6| Step: 1
Training loss: 2.871546121887467
Validation loss: 2.551623510473989

Epoch: 6| Step: 2
Training loss: 2.5880799422202934
Validation loss: 2.5535535470513606

Epoch: 6| Step: 3
Training loss: 2.911483482475143
Validation loss: 2.5405799853157816

Epoch: 6| Step: 4
Training loss: 2.813720184127528
Validation loss: 2.536663058191612

Epoch: 6| Step: 5
Training loss: 2.7675366879782137
Validation loss: 2.5366777275171692

Epoch: 6| Step: 6
Training loss: 2.725924441817858
Validation loss: 2.535638626258042

Epoch: 6| Step: 7
Training loss: 2.1297930349172502
Validation loss: 2.543053724784865

Epoch: 6| Step: 8
Training loss: 2.8446724202601725
Validation loss: 2.5616999191739276

Epoch: 6| Step: 9
Training loss: 2.6544516366018707
Validation loss: 2.581138150700548

Epoch: 6| Step: 10
Training loss: 2.4733406553991197
Validation loss: 2.6187024681685553

Epoch: 6| Step: 11
Training loss: 2.523075042298065
Validation loss: 2.661044604429566

Epoch: 6| Step: 12
Training loss: 2.846841326618052
Validation loss: 2.6894019327833627

Epoch: 6| Step: 13
Training loss: 3.2753491339333145
Validation loss: 2.698937666679835

Epoch: 489| Step: 0
Training loss: 2.4455107099742737
Validation loss: 2.668523795186367

Epoch: 6| Step: 1
Training loss: 2.8712824130190504
Validation loss: 2.653303596204518

Epoch: 6| Step: 2
Training loss: 2.439056975158651
Validation loss: 2.6563402106295952

Epoch: 6| Step: 3
Training loss: 2.1064908124866863
Validation loss: 2.6385796893810998

Epoch: 6| Step: 4
Training loss: 2.706606260464982
Validation loss: 2.637714517657737

Epoch: 6| Step: 5
Training loss: 2.5967513953583725
Validation loss: 2.6486469979322314

Epoch: 6| Step: 6
Training loss: 2.5358865917311495
Validation loss: 2.6429169885984125

Epoch: 6| Step: 7
Training loss: 3.2782496222271305
Validation loss: 2.6511636087828885

Epoch: 6| Step: 8
Training loss: 2.285126619065371
Validation loss: 2.6234550744559417

Epoch: 6| Step: 9
Training loss: 3.0863827927342604
Validation loss: 2.5878782133740077

Epoch: 6| Step: 10
Training loss: 3.0307741086548945
Validation loss: 2.553218297031546

Epoch: 6| Step: 11
Training loss: 2.4061296110876453
Validation loss: 2.536834020553839

Epoch: 6| Step: 12
Training loss: 2.367417730334024
Validation loss: 2.5279858628345404

Epoch: 6| Step: 13
Training loss: 3.7330750313593084
Validation loss: 2.528359809360101

Epoch: 490| Step: 0
Training loss: 2.316349434115616
Validation loss: 2.524345709714604

Epoch: 6| Step: 1
Training loss: 2.770796773186511
Validation loss: 2.5328005760248082

Epoch: 6| Step: 2
Training loss: 2.809633786648303
Validation loss: 2.5388720263147664

Epoch: 6| Step: 3
Training loss: 2.0330877353784054
Validation loss: 2.5497048145410406

Epoch: 6| Step: 4
Training loss: 2.7250716278741516
Validation loss: 2.564761950523419

Epoch: 6| Step: 5
Training loss: 3.2061589456757322
Validation loss: 2.558725031584777

Epoch: 6| Step: 6
Training loss: 2.3252560136186355
Validation loss: 2.5902820090689183

Epoch: 6| Step: 7
Training loss: 3.2712989686267857
Validation loss: 2.6129924861659166

Epoch: 6| Step: 8
Training loss: 2.609977058806755
Validation loss: 2.6103003373385327

Epoch: 6| Step: 9
Training loss: 2.619662262063385
Validation loss: 2.644945240908165

Epoch: 6| Step: 10
Training loss: 3.0511010230739544
Validation loss: 2.6581894088957485

Epoch: 6| Step: 11
Training loss: 2.3104108704292736
Validation loss: 2.6432039274308634

Epoch: 6| Step: 12
Training loss: 2.609331690263239
Validation loss: 2.634706021919733

Epoch: 6| Step: 13
Training loss: 3.3671729138405797
Validation loss: 2.637771387819399

Epoch: 491| Step: 0
Training loss: 2.151008981328611
Validation loss: 2.639760922047215

Epoch: 6| Step: 1
Training loss: 3.30879046903562
Validation loss: 2.6386406885581253

Epoch: 6| Step: 2
Training loss: 1.6488158167036455
Validation loss: 2.6381045756411465

Epoch: 6| Step: 3
Training loss: 2.907714802752414
Validation loss: 2.6357522232287764

Epoch: 6| Step: 4
Training loss: 2.613982558410409
Validation loss: 2.611244479563667

Epoch: 6| Step: 5
Training loss: 2.9878475098822515
Validation loss: 2.593629733679052

Epoch: 6| Step: 6
Training loss: 2.8361328730265645
Validation loss: 2.59568969097905

Epoch: 6| Step: 7
Training loss: 2.686904841326312
Validation loss: 2.6020213593986465

Epoch: 6| Step: 8
Training loss: 3.075024587641473
Validation loss: 2.5769101211101892

Epoch: 6| Step: 9
Training loss: 2.7557836747941526
Validation loss: 2.5983297245546493

Epoch: 6| Step: 10
Training loss: 3.0979006888501956
Validation loss: 2.578823449670866

Epoch: 6| Step: 11
Training loss: 2.5071566190485517
Validation loss: 2.5769144497016074

Epoch: 6| Step: 12
Training loss: 1.9824720855517903
Validation loss: 2.592316610111225

Epoch: 6| Step: 13
Training loss: 2.8064244239481604
Validation loss: 2.5765710865456932

Epoch: 492| Step: 0
Training loss: 2.657304262863884
Validation loss: 2.5674360861822403

Epoch: 6| Step: 1
Training loss: 3.0344292397174217
Validation loss: 2.597876372854067

Epoch: 6| Step: 2
Training loss: 3.194379525745868
Validation loss: 2.5752454450555775

Epoch: 6| Step: 3
Training loss: 3.2180548352393594
Validation loss: 2.581226006059445

Epoch: 6| Step: 4
Training loss: 2.703045970665547
Validation loss: 2.5775246829564007

Epoch: 6| Step: 5
Training loss: 2.695910135990113
Validation loss: 2.5685693598935933

Epoch: 6| Step: 6
Training loss: 2.328516575186436
Validation loss: 2.600799788714281

Epoch: 6| Step: 7
Training loss: 1.984831089260776
Validation loss: 2.622564586516376

Epoch: 6| Step: 8
Training loss: 2.563898216810119
Validation loss: 2.6262390798468878

Epoch: 6| Step: 9
Training loss: 2.5922654281040844
Validation loss: 2.6227114433811587

Epoch: 6| Step: 10
Training loss: 2.7381115478519544
Validation loss: 2.655534531848531

Epoch: 6| Step: 11
Training loss: 2.6311642159366615
Validation loss: 2.673328391280184

Epoch: 6| Step: 12
Training loss: 2.417074651371011
Validation loss: 2.6831456867868835

Epoch: 6| Step: 13
Training loss: 3.002827424579888
Validation loss: 2.6641547892237467

Epoch: 493| Step: 0
Training loss: 2.8065993399560085
Validation loss: 2.6862273411649844

Epoch: 6| Step: 1
Training loss: 2.419666095113295
Validation loss: 2.667868326785543

Epoch: 6| Step: 2
Training loss: 2.912293088709634
Validation loss: 2.6527791441934103

Epoch: 6| Step: 3
Training loss: 1.970184106598836
Validation loss: 2.6402865529902817

Epoch: 6| Step: 4
Training loss: 2.625704897741171
Validation loss: 2.620744303541624

Epoch: 6| Step: 5
Training loss: 2.519922223177584
Validation loss: 2.610254833136759

Epoch: 6| Step: 6
Training loss: 2.397113944307489
Validation loss: 2.6419018452434395

Epoch: 6| Step: 7
Training loss: 2.9743976079310444
Validation loss: 2.622078312161787

Epoch: 6| Step: 8
Training loss: 2.9303983512605094
Validation loss: 2.6176694325567462

Epoch: 6| Step: 9
Training loss: 2.732179206941147
Validation loss: 2.5965796784214943

Epoch: 6| Step: 10
Training loss: 2.8599417703209387
Validation loss: 2.5800977967933925

Epoch: 6| Step: 11
Training loss: 2.995793094992605
Validation loss: 2.571406635035247

Epoch: 6| Step: 12
Training loss: 2.936601866729918
Validation loss: 2.5709473571790604

Epoch: 6| Step: 13
Training loss: 2.4064540033436623
Validation loss: 2.564816600037691

Epoch: 494| Step: 0
Training loss: 2.710018474895945
Validation loss: 2.558015035399958

Epoch: 6| Step: 1
Training loss: 2.9261730222097606
Validation loss: 2.592685103788337

Epoch: 6| Step: 2
Training loss: 2.625844728700767
Validation loss: 2.621659296301543

Epoch: 6| Step: 3
Training loss: 2.375152783749876
Validation loss: 2.6288465560052416

Epoch: 6| Step: 4
Training loss: 2.350727528712251
Validation loss: 2.6397577521661892

Epoch: 6| Step: 5
Training loss: 2.4587595187663775
Validation loss: 2.657520144454757

Epoch: 6| Step: 6
Training loss: 3.364189636691293
Validation loss: 2.673776998932746

Epoch: 6| Step: 7
Training loss: 2.8950685730819363
Validation loss: 2.669619603975867

Epoch: 6| Step: 8
Training loss: 2.451143667355126
Validation loss: 2.66050815343225

Epoch: 6| Step: 9
Training loss: 2.971754782057257
Validation loss: 2.660167276839253

Epoch: 6| Step: 10
Training loss: 2.463783677024351
Validation loss: 2.644243923905771

Epoch: 6| Step: 11
Training loss: 2.479110706456439
Validation loss: 2.604162886750134

Epoch: 6| Step: 12
Training loss: 2.8257941657317756
Validation loss: 2.5738210979547005

Epoch: 6| Step: 13
Training loss: 2.802351805199733
Validation loss: 2.555738971479184

Epoch: 495| Step: 0
Training loss: 2.8876323983360352
Validation loss: 2.534942243257525

Epoch: 6| Step: 1
Training loss: 2.8624484528143963
Validation loss: 2.523700234755865

Epoch: 6| Step: 2
Training loss: 2.9539370757408703
Validation loss: 2.5323695061023197

Epoch: 6| Step: 3
Training loss: 2.7596781960452454
Validation loss: 2.53319612386762

Epoch: 6| Step: 4
Training loss: 3.034426882582163
Validation loss: 2.549658171567883

Epoch: 6| Step: 5
Training loss: 2.2268251498389633
Validation loss: 2.5640949984861665

Epoch: 6| Step: 6
Training loss: 2.488637662121603
Validation loss: 2.5905337842557814

Epoch: 6| Step: 7
Training loss: 2.3465902793257025
Validation loss: 2.611993970818692

Epoch: 6| Step: 8
Training loss: 2.2533088302220556
Validation loss: 2.6478413745745573

Epoch: 6| Step: 9
Training loss: 2.7274720169715834
Validation loss: 2.657252778353904

Epoch: 6| Step: 10
Training loss: 2.9395910084978167
Validation loss: 2.668318046480482

Epoch: 6| Step: 11
Training loss: 3.1257515575750126
Validation loss: 2.6425503801463175

Epoch: 6| Step: 12
Training loss: 2.481999635239912
Validation loss: 2.623880487492659

Epoch: 6| Step: 13
Training loss: 2.5879960179010855
Validation loss: 2.60361908174136

Epoch: 496| Step: 0
Training loss: 2.686650163995813
Validation loss: 2.5686083815755247

Epoch: 6| Step: 1
Training loss: 2.3907084730946213
Validation loss: 2.553534175758465

Epoch: 6| Step: 2
Training loss: 2.792577329297472
Validation loss: 2.5426464841578214

Epoch: 6| Step: 3
Training loss: 3.054280363692741
Validation loss: 2.539752952528415

Epoch: 6| Step: 4
Training loss: 2.8064516092787684
Validation loss: 2.5501274833042715

Epoch: 6| Step: 5
Training loss: 2.5708752975459985
Validation loss: 2.547340494971544

Epoch: 6| Step: 6
Training loss: 2.9714385056067605
Validation loss: 2.5573095341874366

Epoch: 6| Step: 7
Training loss: 2.8210494750781354
Validation loss: 2.5894693068588928

Epoch: 6| Step: 8
Training loss: 2.980090516015005
Validation loss: 2.6245706688607995

Epoch: 6| Step: 9
Training loss: 2.1240728262936104
Validation loss: 2.6504576704013196

Epoch: 6| Step: 10
Training loss: 2.4422769931594406
Validation loss: 2.648888930409429

Epoch: 6| Step: 11
Training loss: 2.987987947717997
Validation loss: 2.6730325711528176

Epoch: 6| Step: 12
Training loss: 2.6510598132718397
Validation loss: 2.639895613223402

Epoch: 6| Step: 13
Training loss: 2.708566821866432
Validation loss: 2.606544727654266

Epoch: 497| Step: 0
Training loss: 2.440549459033212
Validation loss: 2.5642753691732474

Epoch: 6| Step: 1
Training loss: 3.090427656980073
Validation loss: 2.5368298792470707

Epoch: 6| Step: 2
Training loss: 2.5457948605824408
Validation loss: 2.5382307751689863

Epoch: 6| Step: 3
Training loss: 2.6486405826452097
Validation loss: 2.5447805250176794

Epoch: 6| Step: 4
Training loss: 2.6612482056403395
Validation loss: 2.5386024450822027

Epoch: 6| Step: 5
Training loss: 2.1871091220948906
Validation loss: 2.537634320949538

Epoch: 6| Step: 6
Training loss: 2.5531592041115077
Validation loss: 2.5397421296594294

Epoch: 6| Step: 7
Training loss: 1.8728665612137643
Validation loss: 2.5430385382871155

Epoch: 6| Step: 8
Training loss: 2.6600762129743174
Validation loss: 2.5820461887910846

Epoch: 6| Step: 9
Training loss: 3.758170699655813
Validation loss: 2.5894738867127884

Epoch: 6| Step: 10
Training loss: 2.982272540977265
Validation loss: 2.6039433287967335

Epoch: 6| Step: 11
Training loss: 2.738676426298413
Validation loss: 2.6049694400686176

Epoch: 6| Step: 12
Training loss: 2.528326347641503
Validation loss: 2.5877940417806387

Epoch: 6| Step: 13
Training loss: 2.848122389831753
Validation loss: 2.6132603731600943

Epoch: 498| Step: 0
Training loss: 2.7415170746625863
Validation loss: 2.5981773172750766

Epoch: 6| Step: 1
Training loss: 2.338225300097515
Validation loss: 2.6032080998166514

Epoch: 6| Step: 2
Training loss: 2.564467814302465
Validation loss: 2.6226378388039806

Epoch: 6| Step: 3
Training loss: 2.819768710560263
Validation loss: 2.6080126055848742

Epoch: 6| Step: 4
Training loss: 2.579824823598083
Validation loss: 2.5996564136010814

Epoch: 6| Step: 5
Training loss: 2.861969318089477
Validation loss: 2.598869975396865

Epoch: 6| Step: 6
Training loss: 2.4252726686694466
Validation loss: 2.5731631951315586

Epoch: 6| Step: 7
Training loss: 2.485001203202814
Validation loss: 2.588194657071657

Epoch: 6| Step: 8
Training loss: 2.8673130600381147
Validation loss: 2.6053506246012224

Epoch: 6| Step: 9
Training loss: 3.1748189559141844
Validation loss: 2.588446754142819

Epoch: 6| Step: 10
Training loss: 2.421984762350167
Validation loss: 2.5469302467057946

Epoch: 6| Step: 11
Training loss: 2.897445796956566
Validation loss: 2.566842454319603

Epoch: 6| Step: 12
Training loss: 2.6159995044509463
Validation loss: 2.5630646650489974

Epoch: 6| Step: 13
Training loss: 3.0135897552911546
Validation loss: 2.589377924903138

Epoch: 499| Step: 0
Training loss: 1.9303467894576818
Validation loss: 2.6210485740294316

Epoch: 6| Step: 1
Training loss: 3.286135859721841
Validation loss: 2.662925552906657

Epoch: 6| Step: 2
Training loss: 2.015828558527304
Validation loss: 2.686869263711716

Epoch: 6| Step: 3
Training loss: 2.4571014054657865
Validation loss: 2.6767470244839253

Epoch: 6| Step: 4
Training loss: 2.865018517931998
Validation loss: 2.6795175427257165

Epoch: 6| Step: 5
Training loss: 2.7782870164964444
Validation loss: 2.6682195753190836

Epoch: 6| Step: 6
Training loss: 2.409229959953795
Validation loss: 2.67209888502049

Epoch: 6| Step: 7
Training loss: 2.840094931721721
Validation loss: 2.6596566916366333

Epoch: 6| Step: 8
Training loss: 3.3311889585588674
Validation loss: 2.6414371471383378

Epoch: 6| Step: 9
Training loss: 2.3023694811348445
Validation loss: 2.609163391284888

Epoch: 6| Step: 10
Training loss: 3.0932530476027833
Validation loss: 2.5935922320929032

Epoch: 6| Step: 11
Training loss: 2.3055316995308273
Validation loss: 2.5515143444313506

Epoch: 6| Step: 12
Training loss: 2.8715428007676684
Validation loss: 2.5523437403976867

Epoch: 6| Step: 13
Training loss: 2.6671595316640118
Validation loss: 2.5385405467958146

Epoch: 500| Step: 0
Training loss: 2.3757865005028713
Validation loss: 2.522936033940041

Epoch: 6| Step: 1
Training loss: 2.5173470425852096
Validation loss: 2.529495645114106

Epoch: 6| Step: 2
Training loss: 2.4112221016463864
Validation loss: 2.527065213251774

Epoch: 6| Step: 3
Training loss: 2.835614987364713
Validation loss: 2.5457527188832265

Epoch: 6| Step: 4
Training loss: 3.4375246914063498
Validation loss: 2.540938037085879

Epoch: 6| Step: 5
Training loss: 2.185080798158828
Validation loss: 2.5674909523661538

Epoch: 6| Step: 6
Training loss: 2.6524258180935996
Validation loss: 2.5861352108171713

Epoch: 6| Step: 7
Training loss: 2.4309590928069684
Validation loss: 2.612384949674872

Epoch: 6| Step: 8
Training loss: 2.6882027882591824
Validation loss: 2.6136246143294066

Epoch: 6| Step: 9
Training loss: 2.7248432674305816
Validation loss: 2.6084569424133996

Epoch: 6| Step: 10
Training loss: 2.669800605615085
Validation loss: 2.587203371747549

Epoch: 6| Step: 11
Training loss: 2.4911630850950983
Validation loss: 2.5954313910727924

Epoch: 6| Step: 12
Training loss: 2.9275993534888514
Validation loss: 2.5980752364483415

Epoch: 6| Step: 13
Training loss: 3.4325442570933147
Validation loss: 2.6304003281251576

Epoch: 501| Step: 0
Training loss: 2.1584635995955104
Validation loss: 2.598939916320356

Epoch: 6| Step: 1
Training loss: 1.8944053372100123
Validation loss: 2.5929283632671383

Epoch: 6| Step: 2
Training loss: 2.8226525909290308
Validation loss: 2.588692558919956

Epoch: 6| Step: 3
Training loss: 3.5033466143103795
Validation loss: 2.612884072903667

Epoch: 6| Step: 4
Training loss: 3.2340805730555227
Validation loss: 2.608597178047331

Epoch: 6| Step: 5
Training loss: 1.770887650797426
Validation loss: 2.583816396488201

Epoch: 6| Step: 6
Training loss: 2.8129425548352347
Validation loss: 2.5780173260878168

Epoch: 6| Step: 7
Training loss: 3.1465552977342095
Validation loss: 2.597058601227346

Epoch: 6| Step: 8
Training loss: 2.5992940457820444
Validation loss: 2.575270536352236

Epoch: 6| Step: 9
Training loss: 2.8326191469538315
Validation loss: 2.577871254086387

Epoch: 6| Step: 10
Training loss: 2.9371922108530955
Validation loss: 2.5637522533204833

Epoch: 6| Step: 11
Training loss: 2.3130880072211673
Validation loss: 2.53716562249139

Epoch: 6| Step: 12
Training loss: 2.43217787112237
Validation loss: 2.5308936924270853

Epoch: 6| Step: 13
Training loss: 2.9731752842292956
Validation loss: 2.5438398843742656

Epoch: 502| Step: 0
Training loss: 2.8714629266794365
Validation loss: 2.546773738774409

Epoch: 6| Step: 1
Training loss: 2.944558449303519
Validation loss: 2.55578140792575

Epoch: 6| Step: 2
Training loss: 2.5755098893589103
Validation loss: 2.544760262873706

Epoch: 6| Step: 3
Training loss: 2.2825390035048145
Validation loss: 2.5489881365402587

Epoch: 6| Step: 4
Training loss: 2.2278385186839804
Validation loss: 2.5653999390875084

Epoch: 6| Step: 5
Training loss: 2.723134331344646
Validation loss: 2.588831970794999

Epoch: 6| Step: 6
Training loss: 1.8365707928488315
Validation loss: 2.5925129563330844

Epoch: 6| Step: 7
Training loss: 2.6021850574198373
Validation loss: 2.615596582911582

Epoch: 6| Step: 8
Training loss: 3.1491487897002277
Validation loss: 2.613073975151608

Epoch: 6| Step: 9
Training loss: 2.244239001529001
Validation loss: 2.6302732190186435

Epoch: 6| Step: 10
Training loss: 3.2925211284310008
Validation loss: 2.6261725006981584

Epoch: 6| Step: 11
Training loss: 2.85684625925359
Validation loss: 2.6133683509559713

Epoch: 6| Step: 12
Training loss: 2.892870221789631
Validation loss: 2.578958393930201

Epoch: 6| Step: 13
Training loss: 3.125159145117575
Validation loss: 2.546174559589103

Epoch: 503| Step: 0
Training loss: 2.4201679735763606
Validation loss: 2.528954948587378

Epoch: 6| Step: 1
Training loss: 2.7587302952811554
Validation loss: 2.522096258735925

Epoch: 6| Step: 2
Training loss: 2.871298521874936
Validation loss: 2.5211842868152146

Epoch: 6| Step: 3
Training loss: 2.761963225123317
Validation loss: 2.525031469167877

Epoch: 6| Step: 4
Training loss: 2.8506162144568012
Validation loss: 2.5241001957742006

Epoch: 6| Step: 5
Training loss: 2.203697076206351
Validation loss: 2.5250130385309246

Epoch: 6| Step: 6
Training loss: 2.753610668146635
Validation loss: 2.5284048619784296

Epoch: 6| Step: 7
Training loss: 3.066068322094195
Validation loss: 2.531961826840679

Epoch: 6| Step: 8
Training loss: 2.485516939488028
Validation loss: 2.556330326953491

Epoch: 6| Step: 9
Training loss: 2.4829255680292333
Validation loss: 2.5788987406645596

Epoch: 6| Step: 10
Training loss: 2.723502466824309
Validation loss: 2.5920127687671433

Epoch: 6| Step: 11
Training loss: 2.7464661867930857
Validation loss: 2.605280470043823

Epoch: 6| Step: 12
Training loss: 2.75734959680691
Validation loss: 2.6086246383505953

Epoch: 6| Step: 13
Training loss: 2.9317328472232584
Validation loss: 2.6297745301325532

Epoch: 504| Step: 0
Training loss: 2.627866179323655
Validation loss: 2.64594902100236

Epoch: 6| Step: 1
Training loss: 2.871857127734871
Validation loss: 2.654861689633965

Epoch: 6| Step: 2
Training loss: 2.6223605373599628
Validation loss: 2.6520795111643185

Epoch: 6| Step: 3
Training loss: 2.5224506349903333
Validation loss: 2.6446667519235585

Epoch: 6| Step: 4
Training loss: 3.2462134677739436
Validation loss: 2.645037418872078

Epoch: 6| Step: 5
Training loss: 2.7666034584025447
Validation loss: 2.6219840784681185

Epoch: 6| Step: 6
Training loss: 3.0033261615810085
Validation loss: 2.6074057247590674

Epoch: 6| Step: 7
Training loss: 2.068145885021992
Validation loss: 2.5786879217343293

Epoch: 6| Step: 8
Training loss: 2.0137858908904307
Validation loss: 2.5593470873642774

Epoch: 6| Step: 9
Training loss: 2.752998191519745
Validation loss: 2.568520686508497

Epoch: 6| Step: 10
Training loss: 2.9343108051334723
Validation loss: 2.5788599134596994

Epoch: 6| Step: 11
Training loss: 2.520278133907728
Validation loss: 2.5511247500053758

Epoch: 6| Step: 12
Training loss: 2.811594499416726
Validation loss: 2.5531093528100293

Epoch: 6| Step: 13
Training loss: 2.2523990133428
Validation loss: 2.560266727115104

Epoch: 505| Step: 0
Training loss: 3.256559355056777
Validation loss: 2.5642970592112393

Epoch: 6| Step: 1
Training loss: 3.0717706299724954
Validation loss: 2.5446835114759208

Epoch: 6| Step: 2
Training loss: 2.5235558827506632
Validation loss: 2.561605884263409

Epoch: 6| Step: 3
Training loss: 1.8421282990886776
Validation loss: 2.566833678265297

Epoch: 6| Step: 4
Training loss: 2.12842037710993
Validation loss: 2.58926858725067

Epoch: 6| Step: 5
Training loss: 3.1884986958458437
Validation loss: 2.6261556174556064

Epoch: 6| Step: 6
Training loss: 3.322837246670214
Validation loss: 2.6362292060044994

Epoch: 6| Step: 7
Training loss: 2.5478979759331337
Validation loss: 2.6391835971234583

Epoch: 6| Step: 8
Training loss: 2.766391540160738
Validation loss: 2.639036339154086

Epoch: 6| Step: 9
Training loss: 2.1870085027849484
Validation loss: 2.625555440654518

Epoch: 6| Step: 10
Training loss: 2.041670260783036
Validation loss: 2.6320520320694722

Epoch: 6| Step: 11
Training loss: 2.199940429227773
Validation loss: 2.6325073581433753

Epoch: 6| Step: 12
Training loss: 3.1836040847704186
Validation loss: 2.624240116779898

Epoch: 6| Step: 13
Training loss: 2.7860383379750004
Validation loss: 2.6077883079579136

Epoch: 506| Step: 0
Training loss: 1.9567386614060494
Validation loss: 2.5631379294623513

Epoch: 6| Step: 1
Training loss: 2.6067645326602387
Validation loss: 2.5248455737901

Epoch: 6| Step: 2
Training loss: 2.384293293084198
Validation loss: 2.5160221710380513

Epoch: 6| Step: 3
Training loss: 2.78462271910292
Validation loss: 2.5086276110050814

Epoch: 6| Step: 4
Training loss: 2.720632668573538
Validation loss: 2.5039695368407076

Epoch: 6| Step: 5
Training loss: 2.3244521080001785
Validation loss: 2.5005612010077534

Epoch: 6| Step: 6
Training loss: 3.018304612689937
Validation loss: 2.5004567098297783

Epoch: 6| Step: 7
Training loss: 3.4724977884086448
Validation loss: 2.492555638221997

Epoch: 6| Step: 8
Training loss: 2.542127525780389
Validation loss: 2.5069449629484026

Epoch: 6| Step: 9
Training loss: 2.5063873709990276
Validation loss: 2.5255829340753864

Epoch: 6| Step: 10
Training loss: 2.6262530106495916
Validation loss: 2.5196877438186127

Epoch: 6| Step: 11
Training loss: 2.9759825294145896
Validation loss: 2.5275581201620274

Epoch: 6| Step: 12
Training loss: 2.9122356180194005
Validation loss: 2.5454667153271964

Epoch: 6| Step: 13
Training loss: 2.9427372123629034
Validation loss: 2.5814684992017574

Epoch: 507| Step: 0
Training loss: 2.6208106625723144
Validation loss: 2.624306830430827

Epoch: 6| Step: 1
Training loss: 2.7210215582787423
Validation loss: 2.6673127501764022

Epoch: 6| Step: 2
Training loss: 2.2986077241081904
Validation loss: 2.7199147612114167

Epoch: 6| Step: 3
Training loss: 2.875974738698488
Validation loss: 2.7265908280671716

Epoch: 6| Step: 4
Training loss: 2.453841378156965
Validation loss: 2.723525951287875

Epoch: 6| Step: 5
Training loss: 2.2821877002467863
Validation loss: 2.7258074288148944

Epoch: 6| Step: 6
Training loss: 2.8741208266395217
Validation loss: 2.727277879144545

Epoch: 6| Step: 7
Training loss: 2.224744623508852
Validation loss: 2.645262499574286

Epoch: 6| Step: 8
Training loss: 2.8246131294488257
Validation loss: 2.578781554447321

Epoch: 6| Step: 9
Training loss: 2.2002112417241277
Validation loss: 2.552552718760611

Epoch: 6| Step: 10
Training loss: 2.583250003414141
Validation loss: 2.5133218231252044

Epoch: 6| Step: 11
Training loss: 3.460530483173871
Validation loss: 2.509754109985652

Epoch: 6| Step: 12
Training loss: 2.720007769910149
Validation loss: 2.4877225488451566

Epoch: 6| Step: 13
Training loss: 3.237241644842419
Validation loss: 2.4987582281136502

Epoch: 508| Step: 0
Training loss: 2.958046339558029
Validation loss: 2.497230340981546

Epoch: 6| Step: 1
Training loss: 2.525462657730183
Validation loss: 2.4992550775806546

Epoch: 6| Step: 2
Training loss: 1.7834328778134987
Validation loss: 2.500401827605636

Epoch: 6| Step: 3
Training loss: 2.659773072192954
Validation loss: 2.502893221673877

Epoch: 6| Step: 4
Training loss: 3.491242761000064
Validation loss: 2.5117033449524526

Epoch: 6| Step: 5
Training loss: 2.6592390408933393
Validation loss: 2.525890791793268

Epoch: 6| Step: 6
Training loss: 2.081230882894793
Validation loss: 2.511574539216367

Epoch: 6| Step: 7
Training loss: 2.7972587450057653
Validation loss: 2.5174567360561744

Epoch: 6| Step: 8
Training loss: 2.9121802748013206
Validation loss: 2.5330328254161514

Epoch: 6| Step: 9
Training loss: 2.90065234509405
Validation loss: 2.5436820081267255

Epoch: 6| Step: 10
Training loss: 2.6496924743713626
Validation loss: 2.569272505633461

Epoch: 6| Step: 11
Training loss: 2.379498287500902
Validation loss: 2.5752509172786726

Epoch: 6| Step: 12
Training loss: 2.8477900385988555
Validation loss: 2.5841318861829015

Epoch: 6| Step: 13
Training loss: 2.6382201490706114
Validation loss: 2.6147764371825937

Epoch: 509| Step: 0
Training loss: 2.5533447469882824
Validation loss: 2.6336804326179712

Epoch: 6| Step: 1
Training loss: 2.725178451994446
Validation loss: 2.641838003373006

Epoch: 6| Step: 2
Training loss: 2.602689573362391
Validation loss: 2.634294058645319

Epoch: 6| Step: 3
Training loss: 2.8992111119606845
Validation loss: 2.614985292726225

Epoch: 6| Step: 4
Training loss: 2.57523493759806
Validation loss: 2.5682978495079984

Epoch: 6| Step: 5
Training loss: 3.0294857593433995
Validation loss: 2.544722000800555

Epoch: 6| Step: 6
Training loss: 3.0042241874475386
Validation loss: 2.514100729065204

Epoch: 6| Step: 7
Training loss: 2.4850087826917093
Validation loss: 2.511242175553031

Epoch: 6| Step: 8
Training loss: 2.786587854150033
Validation loss: 2.5018539568519698

Epoch: 6| Step: 9
Training loss: 2.8079493689360393
Validation loss: 2.4961508939949324

Epoch: 6| Step: 10
Training loss: 3.1335612707896696
Validation loss: 2.498508262626213

Epoch: 6| Step: 11
Training loss: 2.3779342995976833
Validation loss: 2.51561238367179

Epoch: 6| Step: 12
Training loss: 2.335687834497
Validation loss: 2.5184666619101854

Epoch: 6| Step: 13
Training loss: 2.2590433217589565
Validation loss: 2.52804961266608

Epoch: 510| Step: 0
Training loss: 2.620911002006408
Validation loss: 2.5426177728747703

Epoch: 6| Step: 1
Training loss: 1.9321398268384518
Validation loss: 2.559638393689324

Epoch: 6| Step: 2
Training loss: 3.080219775941812
Validation loss: 2.5929501176468874

Epoch: 6| Step: 3
Training loss: 2.739346067261437
Validation loss: 2.6329036344019143

Epoch: 6| Step: 4
Training loss: 3.1027577592990765
Validation loss: 2.639684481597375

Epoch: 6| Step: 5
Training loss: 2.3842079954044157
Validation loss: 2.6665217420461826

Epoch: 6| Step: 6
Training loss: 1.9623302361993253
Validation loss: 2.663212320890139

Epoch: 6| Step: 7
Training loss: 2.966001503201269
Validation loss: 2.6520557642602216

Epoch: 6| Step: 8
Training loss: 2.551484412676253
Validation loss: 2.6394153359857158

Epoch: 6| Step: 9
Training loss: 2.7832008977513016
Validation loss: 2.6145445314149462

Epoch: 6| Step: 10
Training loss: 2.8311739340831283
Validation loss: 2.5982697987216348

Epoch: 6| Step: 11
Training loss: 2.6747914063596436
Validation loss: 2.594054771414485

Epoch: 6| Step: 12
Training loss: 3.2450329898515067
Validation loss: 2.5611496135201617

Epoch: 6| Step: 13
Training loss: 2.0663657517962624
Validation loss: 2.555364193943994

Epoch: 511| Step: 0
Training loss: 2.762430706277068
Validation loss: 2.5324329284395457

Epoch: 6| Step: 1
Training loss: 2.638997044494061
Validation loss: 2.573415428809287

Epoch: 6| Step: 2
Training loss: 2.534685417384196
Validation loss: 2.565271668904222

Epoch: 6| Step: 3
Training loss: 3.032131420860438
Validation loss: 2.57022931813099

Epoch: 6| Step: 4
Training loss: 2.1809356288024597
Validation loss: 2.592464473895207

Epoch: 6| Step: 5
Training loss: 2.6057105002280156
Validation loss: 2.5861332936386705

Epoch: 6| Step: 6
Training loss: 2.397191422923845
Validation loss: 2.626217852093864

Epoch: 6| Step: 7
Training loss: 2.6081685457998223
Validation loss: 2.6396410738109064

Epoch: 6| Step: 8
Training loss: 2.9070950171784564
Validation loss: 2.6261070512929217

Epoch: 6| Step: 9
Training loss: 2.744776793891429
Validation loss: 2.6454780856242723

Epoch: 6| Step: 10
Training loss: 2.740070710627202
Validation loss: 2.6245410164382803

Epoch: 6| Step: 11
Training loss: 2.2997302519137723
Validation loss: 2.6253876397436398

Epoch: 6| Step: 12
Training loss: 2.836095548066685
Validation loss: 2.633532328607061

Epoch: 6| Step: 13
Training loss: 3.0423349839458864
Validation loss: 2.6442508103792757

Epoch: 512| Step: 0
Training loss: 2.7671866453008986
Validation loss: 2.6079826783955657

Epoch: 6| Step: 1
Training loss: 2.67077935492075
Validation loss: 2.609992226611977

Epoch: 6| Step: 2
Training loss: 2.3216607386432813
Validation loss: 2.5868425992666273

Epoch: 6| Step: 3
Training loss: 2.6200047147868593
Validation loss: 2.5598627621450807

Epoch: 6| Step: 4
Training loss: 2.432518098299264
Validation loss: 2.5373674700482214

Epoch: 6| Step: 5
Training loss: 2.702181171733195
Validation loss: 2.554995850323945

Epoch: 6| Step: 6
Training loss: 2.4624583555466506
Validation loss: 2.543850441895488

Epoch: 6| Step: 7
Training loss: 3.0243027506154823
Validation loss: 2.5280115682126443

Epoch: 6| Step: 8
Training loss: 2.630747905315293
Validation loss: 2.544609376202527

Epoch: 6| Step: 9
Training loss: 2.958226716891847
Validation loss: 2.546011912314224

Epoch: 6| Step: 10
Training loss: 2.7079275169532795
Validation loss: 2.541029971573302

Epoch: 6| Step: 11
Training loss: 2.722378293794587
Validation loss: 2.5328411912962805

Epoch: 6| Step: 12
Training loss: 2.7384804559316342
Validation loss: 2.5547049900216505

Epoch: 6| Step: 13
Training loss: 2.6517674040425985
Validation loss: 2.5618659885121526

Epoch: 513| Step: 0
Training loss: 2.718457962662506
Validation loss: 2.6032849653151815

Epoch: 6| Step: 1
Training loss: 2.6104766895632165
Validation loss: 2.5771980297193258

Epoch: 6| Step: 2
Training loss: 2.820595259506482
Validation loss: 2.5838531301325487

Epoch: 6| Step: 3
Training loss: 2.0983724099728005
Validation loss: 2.580398051738959

Epoch: 6| Step: 4
Training loss: 2.805525715567485
Validation loss: 2.592665278321993

Epoch: 6| Step: 5
Training loss: 3.102358007386261
Validation loss: 2.588884964510308

Epoch: 6| Step: 6
Training loss: 2.8723990243506092
Validation loss: 2.567390097855128

Epoch: 6| Step: 7
Training loss: 2.4393953632635625
Validation loss: 2.5719645313037978

Epoch: 6| Step: 8
Training loss: 2.145780828136052
Validation loss: 2.5828887730271153

Epoch: 6| Step: 9
Training loss: 2.5038892058031927
Validation loss: 2.5768461265493467

Epoch: 6| Step: 10
Training loss: 2.896161195778998
Validation loss: 2.58745668103619

Epoch: 6| Step: 11
Training loss: 2.762854875235938
Validation loss: 2.593075783361257

Epoch: 6| Step: 12
Training loss: 2.7309847495604114
Validation loss: 2.603473527441799

Epoch: 6| Step: 13
Training loss: 2.4133018109948305
Validation loss: 2.606533880170583

Epoch: 514| Step: 0
Training loss: 3.1222986371096657
Validation loss: 2.637280849396961

Epoch: 6| Step: 1
Training loss: 2.556070962246175
Validation loss: 2.633814083726674

Epoch: 6| Step: 2
Training loss: 2.779673268719718
Validation loss: 2.6395772530166104

Epoch: 6| Step: 3
Training loss: 2.149979360614449
Validation loss: 2.6361437920473536

Epoch: 6| Step: 4
Training loss: 2.2762691520878153
Validation loss: 2.599516478683435

Epoch: 6| Step: 5
Training loss: 2.6521147908644753
Validation loss: 2.555767625637015

Epoch: 6| Step: 6
Training loss: 2.8432390361800235
Validation loss: 2.5370468168186022

Epoch: 6| Step: 7
Training loss: 1.629310466277075
Validation loss: 2.5283405046154934

Epoch: 6| Step: 8
Training loss: 3.025326791561491
Validation loss: 2.506545104783057

Epoch: 6| Step: 9
Training loss: 2.416361778582652
Validation loss: 2.5201250693394743

Epoch: 6| Step: 10
Training loss: 2.899900000591009
Validation loss: 2.520898978967539

Epoch: 6| Step: 11
Training loss: 2.5653272709262667
Validation loss: 2.536392845461801

Epoch: 6| Step: 12
Training loss: 2.9228440580007233
Validation loss: 2.5807480440986708

Epoch: 6| Step: 13
Training loss: 3.2154767327561995
Validation loss: 2.6261241867091045

Epoch: 515| Step: 0
Training loss: 2.401117374663642
Validation loss: 2.6289895538816657

Epoch: 6| Step: 1
Training loss: 2.8291627444734946
Validation loss: 2.679521751485734

Epoch: 6| Step: 2
Training loss: 2.3897513993705406
Validation loss: 2.6812769935442953

Epoch: 6| Step: 3
Training loss: 2.4964904947434183
Validation loss: 2.707447712423406

Epoch: 6| Step: 4
Training loss: 2.696582262897561
Validation loss: 2.7845787157501065

Epoch: 6| Step: 5
Training loss: 2.93627741918189
Validation loss: 2.7736507035140923

Epoch: 6| Step: 6
Training loss: 2.5829906441419044
Validation loss: 2.699657620758224

Epoch: 6| Step: 7
Training loss: 2.9165887186442907
Validation loss: 2.6609991876116816

Epoch: 6| Step: 8
Training loss: 2.8343693204273994
Validation loss: 2.6001673437902677

Epoch: 6| Step: 9
Training loss: 2.568716371042323
Validation loss: 2.559420209785817

Epoch: 6| Step: 10
Training loss: 2.518618490794676
Validation loss: 2.5348803031273035

Epoch: 6| Step: 11
Training loss: 2.566485027805387
Validation loss: 2.528565477515689

Epoch: 6| Step: 12
Training loss: 2.9664882677708784
Validation loss: 2.560217327125731

Epoch: 6| Step: 13
Training loss: 2.4753726062236234
Validation loss: 2.5333889515405477

Epoch: 516| Step: 0
Training loss: 2.4832409843665975
Validation loss: 2.5517609942458503

Epoch: 6| Step: 1
Training loss: 2.57519290534823
Validation loss: 2.536301116878654

Epoch: 6| Step: 2
Training loss: 2.7091957675384304
Validation loss: 2.5388513459278346

Epoch: 6| Step: 3
Training loss: 2.546355212008461
Validation loss: 2.5414026524359

Epoch: 6| Step: 4
Training loss: 2.7527792498082824
Validation loss: 2.5588688888849807

Epoch: 6| Step: 5
Training loss: 2.5654127732479144
Validation loss: 2.5639337309958488

Epoch: 6| Step: 6
Training loss: 2.3710859069191743
Validation loss: 2.58914966531952

Epoch: 6| Step: 7
Training loss: 2.558909901895111
Validation loss: 2.603757215900091

Epoch: 6| Step: 8
Training loss: 2.833899740562991
Validation loss: 2.617580325932727

Epoch: 6| Step: 9
Training loss: 3.362710264077087
Validation loss: 2.6294936476335242

Epoch: 6| Step: 10
Training loss: 2.4609859401234604
Validation loss: 2.645754486361258

Epoch: 6| Step: 11
Training loss: 2.4491655991915255
Validation loss: 2.6341759762529704

Epoch: 6| Step: 12
Training loss: 2.7623481087332244
Validation loss: 2.6591104228462727

Epoch: 6| Step: 13
Training loss: 2.9765101150348516
Validation loss: 2.644825797223516

Epoch: 517| Step: 0
Training loss: 1.641804588965937
Validation loss: 2.6132854418288165

Epoch: 6| Step: 1
Training loss: 2.8687420614294776
Validation loss: 2.606867385473814

Epoch: 6| Step: 2
Training loss: 2.7506065566699913
Validation loss: 2.582116620164428

Epoch: 6| Step: 3
Training loss: 2.8572262888034765
Validation loss: 2.597947308572729

Epoch: 6| Step: 4
Training loss: 2.7352396442652074
Validation loss: 2.584340100464977

Epoch: 6| Step: 5
Training loss: 2.1591110046035604
Validation loss: 2.6094563327645512

Epoch: 6| Step: 6
Training loss: 2.5766869435698965
Validation loss: 2.5840508655031624

Epoch: 6| Step: 7
Training loss: 3.0676745859220964
Validation loss: 2.5743461352172634

Epoch: 6| Step: 8
Training loss: 2.173341763524905
Validation loss: 2.5870068365928764

Epoch: 6| Step: 9
Training loss: 2.8487327435227328
Validation loss: 2.5817246342129363

Epoch: 6| Step: 10
Training loss: 2.8920258298066
Validation loss: 2.616811462726812

Epoch: 6| Step: 11
Training loss: 2.570933722004886
Validation loss: 2.596657261419194

Epoch: 6| Step: 12
Training loss: 2.5487078291176424
Validation loss: 2.5992221131639233

Epoch: 6| Step: 13
Training loss: 3.265227079103809
Validation loss: 2.5732589835391098

Epoch: 518| Step: 0
Training loss: 2.5284304515649385
Validation loss: 2.5533450572342486

Epoch: 6| Step: 1
Training loss: 2.5492363029247436
Validation loss: 2.540965292806994

Epoch: 6| Step: 2
Training loss: 2.3541161748371993
Validation loss: 2.5281537137883516

Epoch: 6| Step: 3
Training loss: 2.895788251859824
Validation loss: 2.5284321661127294

Epoch: 6| Step: 4
Training loss: 2.7536903242587942
Validation loss: 2.5186564124873967

Epoch: 6| Step: 5
Training loss: 2.6045275221989117
Validation loss: 2.5430521128398893

Epoch: 6| Step: 6
Training loss: 2.777181156512197
Validation loss: 2.5684005548719435

Epoch: 6| Step: 7
Training loss: 2.7213679895856075
Validation loss: 2.6126781961993575

Epoch: 6| Step: 8
Training loss: 2.887455372651279
Validation loss: 2.632075466605853

Epoch: 6| Step: 9
Training loss: 2.7847299129118808
Validation loss: 2.6472225680983

Epoch: 6| Step: 10
Training loss: 2.4766836046518477
Validation loss: 2.6177010412086745

Epoch: 6| Step: 11
Training loss: 2.913300197188822
Validation loss: 2.6204575625027715

Epoch: 6| Step: 12
Training loss: 2.2778611814017684
Validation loss: 2.5876131962428857

Epoch: 6| Step: 13
Training loss: 2.9518895062492585
Validation loss: 2.584255987235993

Epoch: 519| Step: 0
Training loss: 2.601337503320717
Validation loss: 2.569817660061377

Epoch: 6| Step: 1
Training loss: 2.521178755200398
Validation loss: 2.5517171185550533

Epoch: 6| Step: 2
Training loss: 2.910395465210186
Validation loss: 2.541759321506593

Epoch: 6| Step: 3
Training loss: 2.4976814963192693
Validation loss: 2.525090621334113

Epoch: 6| Step: 4
Training loss: 2.3956507295321066
Validation loss: 2.5064314469595907

Epoch: 6| Step: 5
Training loss: 2.7437682201154185
Validation loss: 2.521179094825628

Epoch: 6| Step: 6
Training loss: 2.1754821900550754
Validation loss: 2.516742947815976

Epoch: 6| Step: 7
Training loss: 2.9630668451942417
Validation loss: 2.5667003079103323

Epoch: 6| Step: 8
Training loss: 3.036978117139532
Validation loss: 2.591644148828848

Epoch: 6| Step: 9
Training loss: 2.004977469757663
Validation loss: 2.614519357153901

Epoch: 6| Step: 10
Training loss: 3.083494817955496
Validation loss: 2.641458775704335

Epoch: 6| Step: 11
Training loss: 2.5784213733827603
Validation loss: 2.626269945978291

Epoch: 6| Step: 12
Training loss: 2.4442419078997677
Validation loss: 2.6313721633872125

Epoch: 6| Step: 13
Training loss: 3.1820894583949126
Validation loss: 2.6285058618848947

Epoch: 520| Step: 0
Training loss: 2.4329640169191347
Validation loss: 2.6216679122954494

Epoch: 6| Step: 1
Training loss: 2.7539541253872675
Validation loss: 2.614494040470797

Epoch: 6| Step: 2
Training loss: 2.7233078558612154
Validation loss: 2.6071089981434996

Epoch: 6| Step: 3
Training loss: 2.439169678663925
Validation loss: 2.5907301953368216

Epoch: 6| Step: 4
Training loss: 2.5241908788249194
Validation loss: 2.597839700329258

Epoch: 6| Step: 5
Training loss: 1.8336512838991017
Validation loss: 2.612329688793536

Epoch: 6| Step: 6
Training loss: 2.801507959297689
Validation loss: 2.6188581311163586

Epoch: 6| Step: 7
Training loss: 2.472306213190386
Validation loss: 2.582349470453484

Epoch: 6| Step: 8
Training loss: 3.0194856114658206
Validation loss: 2.5571660668698373

Epoch: 6| Step: 9
Training loss: 2.8394639129790593
Validation loss: 2.5483454326003128

Epoch: 6| Step: 10
Training loss: 2.7792526102193613
Validation loss: 2.515745814953507

Epoch: 6| Step: 11
Training loss: 3.332932130192971
Validation loss: 2.5151445483740296

Epoch: 6| Step: 12
Training loss: 2.17996235963716
Validation loss: 2.493150831741511

Epoch: 6| Step: 13
Training loss: 3.0605138449478035
Validation loss: 2.5050354728817674

Epoch: 521| Step: 0
Training loss: 2.976852442920029
Validation loss: 2.5031806821520024

Epoch: 6| Step: 1
Training loss: 2.4286905187370462
Validation loss: 2.514172454079233

Epoch: 6| Step: 2
Training loss: 2.0762091962558666
Validation loss: 2.53499946417215

Epoch: 6| Step: 3
Training loss: 2.7794562566848766
Validation loss: 2.5703077962372087

Epoch: 6| Step: 4
Training loss: 2.6585206144206976
Validation loss: 2.5696494518363378

Epoch: 6| Step: 5
Training loss: 2.919677560849172
Validation loss: 2.607268479069646

Epoch: 6| Step: 6
Training loss: 2.065328796664124
Validation loss: 2.607058965002988

Epoch: 6| Step: 7
Training loss: 2.6066058421376006
Validation loss: 2.667277164974016

Epoch: 6| Step: 8
Training loss: 2.8288411450841657
Validation loss: 2.6963327496577585

Epoch: 6| Step: 9
Training loss: 2.40718427083159
Validation loss: 2.691537722365848

Epoch: 6| Step: 10
Training loss: 3.0768259473288784
Validation loss: 2.7115984189614974

Epoch: 6| Step: 11
Training loss: 2.683251416000466
Validation loss: 2.6744666165703848

Epoch: 6| Step: 12
Training loss: 2.9992161362505705
Validation loss: 2.661511081477629

Epoch: 6| Step: 13
Training loss: 2.6605021830182225
Validation loss: 2.6328046166943495

Epoch: 522| Step: 0
Training loss: 2.9583693667800737
Validation loss: 2.6014341020714564

Epoch: 6| Step: 1
Training loss: 2.8040002177370345
Validation loss: 2.548724070670705

Epoch: 6| Step: 2
Training loss: 2.3491139385056536
Validation loss: 2.5054461357986293

Epoch: 6| Step: 3
Training loss: 2.3342724227326754
Validation loss: 2.487957944913271

Epoch: 6| Step: 4
Training loss: 1.979280194155213
Validation loss: 2.4945694505472837

Epoch: 6| Step: 5
Training loss: 3.3081466570890674
Validation loss: 2.482074068541986

Epoch: 6| Step: 6
Training loss: 2.6316904455958396
Validation loss: 2.4927341539155425

Epoch: 6| Step: 7
Training loss: 3.035088694248985
Validation loss: 2.482724789753674

Epoch: 6| Step: 8
Training loss: 2.4288577904687627
Validation loss: 2.521543925551912

Epoch: 6| Step: 9
Training loss: 2.4571480776328967
Validation loss: 2.5195679929266723

Epoch: 6| Step: 10
Training loss: 2.7649176603615344
Validation loss: 2.552890295577023

Epoch: 6| Step: 11
Training loss: 2.8887695956256754
Validation loss: 2.5968091043668093

Epoch: 6| Step: 12
Training loss: 2.2845933008843295
Validation loss: 2.622276415775291

Epoch: 6| Step: 13
Training loss: 2.753165850298392
Validation loss: 2.6465869560532442

Epoch: 523| Step: 0
Training loss: 2.7373665276304884
Validation loss: 2.6467650593532173

Epoch: 6| Step: 1
Training loss: 2.1026823895934323
Validation loss: 2.6395828366207303

Epoch: 6| Step: 2
Training loss: 2.107920279267591
Validation loss: 2.6230012019566806

Epoch: 6| Step: 3
Training loss: 2.657496350663587
Validation loss: 2.615041387642174

Epoch: 6| Step: 4
Training loss: 2.5115603193800706
Validation loss: 2.6176339726304323

Epoch: 6| Step: 5
Training loss: 3.0954135314073823
Validation loss: 2.607221112709231

Epoch: 6| Step: 6
Training loss: 3.0210333045454583
Validation loss: 2.609315293446708

Epoch: 6| Step: 7
Training loss: 2.6803120143943757
Validation loss: 2.587966558604295

Epoch: 6| Step: 8
Training loss: 2.679246337876732
Validation loss: 2.576737554512401

Epoch: 6| Step: 9
Training loss: 2.6565940185371555
Validation loss: 2.5647391563920467

Epoch: 6| Step: 10
Training loss: 2.327938814847028
Validation loss: 2.5570255571568192

Epoch: 6| Step: 11
Training loss: 2.6801671079945972
Validation loss: 2.5184620832249736

Epoch: 6| Step: 12
Training loss: 3.0365371999209736
Validation loss: 2.500646145699613

Epoch: 6| Step: 13
Training loss: 2.2372211389081413
Validation loss: 2.511796506640343

Epoch: 524| Step: 0
Training loss: 3.273086274088936
Validation loss: 2.5376180468082716

Epoch: 6| Step: 1
Training loss: 2.6087722539021097
Validation loss: 2.561997603242259

Epoch: 6| Step: 2
Training loss: 2.8552586677806486
Validation loss: 2.5932385824692217

Epoch: 6| Step: 3
Training loss: 2.1117600132463306
Validation loss: 2.6038721872180384

Epoch: 6| Step: 4
Training loss: 2.585208663339927
Validation loss: 2.614479044885393

Epoch: 6| Step: 5
Training loss: 2.7123595803475298
Validation loss: 2.641361190016006

Epoch: 6| Step: 6
Training loss: 2.375222647420004
Validation loss: 2.6524242262234843

Epoch: 6| Step: 7
Training loss: 3.0953556094376222
Validation loss: 2.6310472919249825

Epoch: 6| Step: 8
Training loss: 2.713042044207291
Validation loss: 2.638119183302911

Epoch: 6| Step: 9
Training loss: 2.6961649113485273
Validation loss: 2.623983717733257

Epoch: 6| Step: 10
Training loss: 2.042040758180122
Validation loss: 2.6115698859902228

Epoch: 6| Step: 11
Training loss: 2.6294798997428854
Validation loss: 2.576993914025996

Epoch: 6| Step: 12
Training loss: 2.1486262568004593
Validation loss: 2.54421316429477

Epoch: 6| Step: 13
Training loss: 2.809767773490985
Validation loss: 2.5244122599178405

Epoch: 525| Step: 0
Training loss: 2.4431106355390724
Validation loss: 2.5034079795740882

Epoch: 6| Step: 1
Training loss: 2.687024806394735
Validation loss: 2.5013094446571094

Epoch: 6| Step: 2
Training loss: 2.435999677548442
Validation loss: 2.500269856808791

Epoch: 6| Step: 3
Training loss: 2.607886340888381
Validation loss: 2.499281260015992

Epoch: 6| Step: 4
Training loss: 2.5219150355681603
Validation loss: 2.5065044132070744

Epoch: 6| Step: 5
Training loss: 3.0686101877718306
Validation loss: 2.5180780171321233

Epoch: 6| Step: 6
Training loss: 2.8007609900003803
Validation loss: 2.532060071969454

Epoch: 6| Step: 7
Training loss: 2.8339789907771045
Validation loss: 2.567214398803678

Epoch: 6| Step: 8
Training loss: 2.0175897056934096
Validation loss: 2.5862863452385465

Epoch: 6| Step: 9
Training loss: 3.025233324368571
Validation loss: 2.616729364165872

Epoch: 6| Step: 10
Training loss: 2.9484836495916302
Validation loss: 2.6214660083824626

Epoch: 6| Step: 11
Training loss: 2.856863784784716
Validation loss: 2.6005376292281084

Epoch: 6| Step: 12
Training loss: 2.5565100651823975
Validation loss: 2.569937580311919

Epoch: 6| Step: 13
Training loss: 2.6475425265807746
Validation loss: 2.5213371701513316

Epoch: 526| Step: 0
Training loss: 2.7110394285536694
Validation loss: 2.5004301962340585

Epoch: 6| Step: 1
Training loss: 2.312186864323586
Validation loss: 2.505406096086722

Epoch: 6| Step: 2
Training loss: 2.575297521791342
Validation loss: 2.5049680957461757

Epoch: 6| Step: 3
Training loss: 3.422675470238561
Validation loss: 2.5071851014352267

Epoch: 6| Step: 4
Training loss: 2.728851319553881
Validation loss: 2.5159881274681095

Epoch: 6| Step: 5
Training loss: 2.541216409126286
Validation loss: 2.5293261763677357

Epoch: 6| Step: 6
Training loss: 2.625824299317266
Validation loss: 2.5557573931924797

Epoch: 6| Step: 7
Training loss: 2.7100049264447805
Validation loss: 2.5435699946245696

Epoch: 6| Step: 8
Training loss: 2.0341489792299257
Validation loss: 2.5587225302874916

Epoch: 6| Step: 9
Training loss: 2.7156913477054414
Validation loss: 2.5674764461119706

Epoch: 6| Step: 10
Training loss: 3.1035816913004233
Validation loss: 2.579008429479403

Epoch: 6| Step: 11
Training loss: 2.6016209684566243
Validation loss: 2.603608138373299

Epoch: 6| Step: 12
Training loss: 2.19579844679315
Validation loss: 2.5900072743927405

Epoch: 6| Step: 13
Training loss: 2.9909600113083434
Validation loss: 2.574955356783171

Epoch: 527| Step: 0
Training loss: 2.27207607129847
Validation loss: 2.580697573397468

Epoch: 6| Step: 1
Training loss: 2.6118213812551936
Validation loss: 2.5629074829164713

Epoch: 6| Step: 2
Training loss: 2.5156224410713404
Validation loss: 2.582888607271623

Epoch: 6| Step: 3
Training loss: 2.4590510813033113
Validation loss: 2.577392659065814

Epoch: 6| Step: 4
Training loss: 2.7268613635117185
Validation loss: 2.571055232450345

Epoch: 6| Step: 5
Training loss: 3.269933167687465
Validation loss: 2.585766565973408

Epoch: 6| Step: 6
Training loss: 2.6632026783864107
Validation loss: 2.586218909043705

Epoch: 6| Step: 7
Training loss: 1.7955044370727613
Validation loss: 2.5900461284900556

Epoch: 6| Step: 8
Training loss: 3.060632252917305
Validation loss: 2.5854650961338344

Epoch: 6| Step: 9
Training loss: 2.2851953747652276
Validation loss: 2.5720675138608637

Epoch: 6| Step: 10
Training loss: 2.6640381574217775
Validation loss: 2.5568087946708173

Epoch: 6| Step: 11
Training loss: 3.1110353876919628
Validation loss: 2.552835147727534

Epoch: 6| Step: 12
Training loss: 2.6491520010690337
Validation loss: 2.5595939519236066

Epoch: 6| Step: 13
Training loss: 2.3371652292026233
Validation loss: 2.5705390902859673

Epoch: 528| Step: 0
Training loss: 3.0309260873671136
Validation loss: 2.603300706838759

Epoch: 6| Step: 1
Training loss: 2.6091017894137387
Validation loss: 2.570509066899556

Epoch: 6| Step: 2
Training loss: 2.2979675600901253
Validation loss: 2.554982077845137

Epoch: 6| Step: 3
Training loss: 2.6367780664624285
Validation loss: 2.5476229784951467

Epoch: 6| Step: 4
Training loss: 2.428002561332194
Validation loss: 2.5550710798998204

Epoch: 6| Step: 5
Training loss: 2.9082801865000003
Validation loss: 2.555926630012807

Epoch: 6| Step: 6
Training loss: 2.833959977658164
Validation loss: 2.549324842875391

Epoch: 6| Step: 7
Training loss: 3.014355327961999
Validation loss: 2.5864641990124464

Epoch: 6| Step: 8
Training loss: 2.6099875639111296
Validation loss: 2.5590230672234937

Epoch: 6| Step: 9
Training loss: 2.6641685487105957
Validation loss: 2.578366498179887

Epoch: 6| Step: 10
Training loss: 2.4227053295627186
Validation loss: 2.5975816507334955

Epoch: 6| Step: 11
Training loss: 2.299775659981355
Validation loss: 2.614622228477184

Epoch: 6| Step: 12
Training loss: 2.1921315888217023
Validation loss: 2.612618647559769

Epoch: 6| Step: 13
Training loss: 2.8424129486845517
Validation loss: 2.62146825275745

Epoch: 529| Step: 0
Training loss: 2.8584302998843394
Validation loss: 2.632540144206269

Epoch: 6| Step: 1
Training loss: 3.0962355676283067
Validation loss: 2.607585263484064

Epoch: 6| Step: 2
Training loss: 2.6302405226346086
Validation loss: 2.6187285234218365

Epoch: 6| Step: 3
Training loss: 2.780956810059974
Validation loss: 2.6035889100729817

Epoch: 6| Step: 4
Training loss: 2.287504740225461
Validation loss: 2.599457457946135

Epoch: 6| Step: 5
Training loss: 2.7976117575568824
Validation loss: 2.5883756660151302

Epoch: 6| Step: 6
Training loss: 3.061962625495955
Validation loss: 2.552681055613764

Epoch: 6| Step: 7
Training loss: 2.4886980171848383
Validation loss: 2.523133708426299

Epoch: 6| Step: 8
Training loss: 2.5565365507130613
Validation loss: 2.521029191598131

Epoch: 6| Step: 9
Training loss: 2.597516370176512
Validation loss: 2.5246806070740444

Epoch: 6| Step: 10
Training loss: 2.561090593492579
Validation loss: 2.5263772913831133

Epoch: 6| Step: 11
Training loss: 2.007549699142003
Validation loss: 2.5333425728392487

Epoch: 6| Step: 12
Training loss: 2.276248413286489
Validation loss: 2.5708351714688287

Epoch: 6| Step: 13
Training loss: 2.68630520188321
Validation loss: 2.6110161197704054

Epoch: 530| Step: 0
Training loss: 2.7019696715916655
Validation loss: 2.644917990012132

Epoch: 6| Step: 1
Training loss: 2.6436520894274422
Validation loss: 2.647879401333845

Epoch: 6| Step: 2
Training loss: 2.382521914914704
Validation loss: 2.663687378652793

Epoch: 6| Step: 3
Training loss: 2.627957902783081
Validation loss: 2.6907246363536776

Epoch: 6| Step: 4
Training loss: 1.6866592856133835
Validation loss: 2.693416506540368

Epoch: 6| Step: 5
Training loss: 3.2943969380765137
Validation loss: 2.6816617983399733

Epoch: 6| Step: 6
Training loss: 3.135833729394108
Validation loss: 2.622312642929154

Epoch: 6| Step: 7
Training loss: 2.6200086277535757
Validation loss: 2.561624864257494

Epoch: 6| Step: 8
Training loss: 2.3990796748514627
Validation loss: 2.534541839715635

Epoch: 6| Step: 9
Training loss: 2.8270290211178724
Validation loss: 2.5042999492004774

Epoch: 6| Step: 10
Training loss: 2.828583906677378
Validation loss: 2.4812535118209804

Epoch: 6| Step: 11
Training loss: 2.164368094891233
Validation loss: 2.4817517636044055

Epoch: 6| Step: 12
Training loss: 2.8128732221711608
Validation loss: 2.478195207601128

Epoch: 6| Step: 13
Training loss: 3.030826342363732
Validation loss: 2.492136076213639

Epoch: 531| Step: 0
Training loss: 2.8986326085148333
Validation loss: 2.5022501929757417

Epoch: 6| Step: 1
Training loss: 2.519226150374062
Validation loss: 2.532971753539561

Epoch: 6| Step: 2
Training loss: 2.664321126158305
Validation loss: 2.5439146557947216

Epoch: 6| Step: 3
Training loss: 2.784370129513575
Validation loss: 2.593889332782456

Epoch: 6| Step: 4
Training loss: 2.350086851747057
Validation loss: 2.6408310127998185

Epoch: 6| Step: 5
Training loss: 2.665386150790295
Validation loss: 2.6915828801006065

Epoch: 6| Step: 6
Training loss: 3.033216330259407
Validation loss: 2.7565911601711273

Epoch: 6| Step: 7
Training loss: 2.763948956406063
Validation loss: 2.756979081228937

Epoch: 6| Step: 8
Training loss: 2.8285616542872973
Validation loss: 2.75852759080939

Epoch: 6| Step: 9
Training loss: 2.5498940763726274
Validation loss: 2.7487514174679957

Epoch: 6| Step: 10
Training loss: 2.9098150885386693
Validation loss: 2.7017999137712647

Epoch: 6| Step: 11
Training loss: 2.416797064409238
Validation loss: 2.640351901416303

Epoch: 6| Step: 12
Training loss: 3.067028201256827
Validation loss: 2.5752869836864964

Epoch: 6| Step: 13
Training loss: 1.5508998566055503
Validation loss: 2.5318697858413435

Epoch: 532| Step: 0
Training loss: 3.1315987154856773
Validation loss: 2.502055557737663

Epoch: 6| Step: 1
Training loss: 2.486204996828476
Validation loss: 2.5023155512501893

Epoch: 6| Step: 2
Training loss: 2.6649596194416145
Validation loss: 2.4857474434409443

Epoch: 6| Step: 3
Training loss: 3.0081758354008254
Validation loss: 2.478772117949582

Epoch: 6| Step: 4
Training loss: 2.436589486673659
Validation loss: 2.491792907655614

Epoch: 6| Step: 5
Training loss: 2.576679911347071
Validation loss: 2.486118814204344

Epoch: 6| Step: 6
Training loss: 2.8156193706697508
Validation loss: 2.492735950608772

Epoch: 6| Step: 7
Training loss: 2.5575940690774552
Validation loss: 2.491164919968775

Epoch: 6| Step: 8
Training loss: 3.017449178070167
Validation loss: 2.5094541156936376

Epoch: 6| Step: 9
Training loss: 2.0195029162664246
Validation loss: 2.5370633906934232

Epoch: 6| Step: 10
Training loss: 2.5961489326887013
Validation loss: 2.569194220417103

Epoch: 6| Step: 11
Training loss: 2.3202797216290074
Validation loss: 2.6047839319586705

Epoch: 6| Step: 12
Training loss: 2.522769709705828
Validation loss: 2.6578434757988707

Epoch: 6| Step: 13
Training loss: 2.695602976308601
Validation loss: 2.6725565452414157

Epoch: 533| Step: 0
Training loss: 2.049902271639481
Validation loss: 2.6686464876793585

Epoch: 6| Step: 1
Training loss: 2.5225608413058347
Validation loss: 2.6382659648236384

Epoch: 6| Step: 2
Training loss: 2.222713101000197
Validation loss: 2.626896214839853

Epoch: 6| Step: 3
Training loss: 2.493947427148107
Validation loss: 2.5995093070341797

Epoch: 6| Step: 4
Training loss: 2.7862582601336663
Validation loss: 2.56281821583362

Epoch: 6| Step: 5
Training loss: 2.3760237244214695
Validation loss: 2.5475163279227124

Epoch: 6| Step: 6
Training loss: 2.9243727834798716
Validation loss: 2.5219705820360487

Epoch: 6| Step: 7
Training loss: 2.712263063551049
Validation loss: 2.505873460429303

Epoch: 6| Step: 8
Training loss: 2.796014919912454
Validation loss: 2.5221612582436492

Epoch: 6| Step: 9
Training loss: 2.311463716651684
Validation loss: 2.5065526569686924

Epoch: 6| Step: 10
Training loss: 2.9105769934943475
Validation loss: 2.5138733174668504

Epoch: 6| Step: 11
Training loss: 2.464406308684643
Validation loss: 2.5065092980720998

Epoch: 6| Step: 12
Training loss: 3.326455140609931
Validation loss: 2.5099625344988286

Epoch: 6| Step: 13
Training loss: 3.317543077570087
Validation loss: 2.5198554648619305

Epoch: 534| Step: 0
Training loss: 2.324140274902859
Validation loss: 2.55009840989116

Epoch: 6| Step: 1
Training loss: 2.738256696517503
Validation loss: 2.5912345671098826

Epoch: 6| Step: 2
Training loss: 2.6568333602294896
Validation loss: 2.6078822947177804

Epoch: 6| Step: 3
Training loss: 2.584096293429686
Validation loss: 2.63628474678545

Epoch: 6| Step: 4
Training loss: 2.8024662328177987
Validation loss: 2.643619682641315

Epoch: 6| Step: 5
Training loss: 2.7934276283875805
Validation loss: 2.655166943720006

Epoch: 6| Step: 6
Training loss: 2.3075079777043435
Validation loss: 2.6619497569180206

Epoch: 6| Step: 7
Training loss: 1.88085348062988
Validation loss: 2.6383778291117754

Epoch: 6| Step: 8
Training loss: 2.7967383495172373
Validation loss: 2.6297050242249282

Epoch: 6| Step: 9
Training loss: 2.4621481203507294
Validation loss: 2.585459386732033

Epoch: 6| Step: 10
Training loss: 2.8443458687403873
Validation loss: 2.5606155069052035

Epoch: 6| Step: 11
Training loss: 2.6856893605667023
Validation loss: 2.5292850890831082

Epoch: 6| Step: 12
Training loss: 3.263745364737753
Validation loss: 2.5091205572182163

Epoch: 6| Step: 13
Training loss: 2.3676237705187844
Validation loss: 2.4957185898172476

Epoch: 535| Step: 0
Training loss: 2.7742705477554916
Validation loss: 2.475682438245026

Epoch: 6| Step: 1
Training loss: 3.2216786514377693
Validation loss: 2.478073665764444

Epoch: 6| Step: 2
Training loss: 2.6337861657612915
Validation loss: 2.491055054653828

Epoch: 6| Step: 3
Training loss: 2.208306678275221
Validation loss: 2.474267137789071

Epoch: 6| Step: 4
Training loss: 2.4907340950806973
Validation loss: 2.489224578001284

Epoch: 6| Step: 5
Training loss: 2.5778194362007394
Validation loss: 2.490395449070342

Epoch: 6| Step: 6
Training loss: 2.445027392649347
Validation loss: 2.516708083797696

Epoch: 6| Step: 7
Training loss: 2.9227062001837907
Validation loss: 2.52815827289322

Epoch: 6| Step: 8
Training loss: 2.813710778605735
Validation loss: 2.537134105821369

Epoch: 6| Step: 9
Training loss: 2.76996896402758
Validation loss: 2.55304735437448

Epoch: 6| Step: 10
Training loss: 2.51742470379597
Validation loss: 2.5612451565764554

Epoch: 6| Step: 11
Training loss: 2.574811158153659
Validation loss: 2.577601297386669

Epoch: 6| Step: 12
Training loss: 2.5240868834158103
Validation loss: 2.5667394828562182

Epoch: 6| Step: 13
Training loss: 2.3736546370005884
Validation loss: 2.5642316356282393

Epoch: 536| Step: 0
Training loss: 2.735803198445568
Validation loss: 2.5748503207119557

Epoch: 6| Step: 1
Training loss: 2.880437932626881
Validation loss: 2.588510904611951

Epoch: 6| Step: 2
Training loss: 2.5559396270881156
Validation loss: 2.5965445574343797

Epoch: 6| Step: 3
Training loss: 3.032756313174954
Validation loss: 2.566677988451164

Epoch: 6| Step: 4
Training loss: 2.7062559132147976
Validation loss: 2.574961271670776

Epoch: 6| Step: 5
Training loss: 2.503179911988638
Validation loss: 2.581998207819507

Epoch: 6| Step: 6
Training loss: 2.3878515773571567
Validation loss: 2.58752590798788

Epoch: 6| Step: 7
Training loss: 2.7808504996390533
Validation loss: 2.5742222834179476

Epoch: 6| Step: 8
Training loss: 2.3142601737542283
Validation loss: 2.554017743486852

Epoch: 6| Step: 9
Training loss: 2.6230412395811578
Validation loss: 2.5506640408922263

Epoch: 6| Step: 10
Training loss: 2.266184034108116
Validation loss: 2.549211380773465

Epoch: 6| Step: 11
Training loss: 2.1185889303823715
Validation loss: 2.5534562172427724

Epoch: 6| Step: 12
Training loss: 2.4538247635072112
Validation loss: 2.562203631006307

Epoch: 6| Step: 13
Training loss: 3.214342970565194
Validation loss: 2.570866579134762

Epoch: 537| Step: 0
Training loss: 2.8481655842725453
Validation loss: 2.5906365204719495

Epoch: 6| Step: 1
Training loss: 2.759832663508135
Validation loss: 2.5915283323156775

Epoch: 6| Step: 2
Training loss: 1.5917716369500394
Validation loss: 2.594534343087939

Epoch: 6| Step: 3
Training loss: 2.3057447174584187
Validation loss: 2.612996905094681

Epoch: 6| Step: 4
Training loss: 2.074986777206022
Validation loss: 2.586054395653216

Epoch: 6| Step: 5
Training loss: 2.470365744010325
Validation loss: 2.610344526686691

Epoch: 6| Step: 6
Training loss: 2.7853389214617432
Validation loss: 2.627203016422358

Epoch: 6| Step: 7
Training loss: 2.523057277130593
Validation loss: 2.6581091679784454

Epoch: 6| Step: 8
Training loss: 2.8613516223971196
Validation loss: 2.64326870133659

Epoch: 6| Step: 9
Training loss: 2.404016324989123
Validation loss: 2.60994798415063

Epoch: 6| Step: 10
Training loss: 3.3383070237914327
Validation loss: 2.6194279075533826

Epoch: 6| Step: 11
Training loss: 2.7217586137697145
Validation loss: 2.603724686719616

Epoch: 6| Step: 12
Training loss: 2.6343006490077765
Validation loss: 2.6022625196030584

Epoch: 6| Step: 13
Training loss: 2.650766884303607
Validation loss: 2.583766452062557

Epoch: 538| Step: 0
Training loss: 2.7054190190211655
Validation loss: 2.545966678870067

Epoch: 6| Step: 1
Training loss: 2.443386404008423
Validation loss: 2.5296189261229833

Epoch: 6| Step: 2
Training loss: 2.2668005688703103
Validation loss: 2.5343955116316415

Epoch: 6| Step: 3
Training loss: 2.785625487788215
Validation loss: 2.535592160300847

Epoch: 6| Step: 4
Training loss: 3.0132087158777923
Validation loss: 2.5566446299323236

Epoch: 6| Step: 5
Training loss: 2.889812953400211
Validation loss: 2.559750199797994

Epoch: 6| Step: 6
Training loss: 2.7655718954559014
Validation loss: 2.5870134047195323

Epoch: 6| Step: 7
Training loss: 3.1733346972208807
Validation loss: 2.6016183906455956

Epoch: 6| Step: 8
Training loss: 2.6733148275798717
Validation loss: 2.6073197667467873

Epoch: 6| Step: 9
Training loss: 2.306283378876421
Validation loss: 2.622202289133708

Epoch: 6| Step: 10
Training loss: 2.548102334702764
Validation loss: 2.6255891766698256

Epoch: 6| Step: 11
Training loss: 2.2007478916617886
Validation loss: 2.5995593543189703

Epoch: 6| Step: 12
Training loss: 1.8000702685309733
Validation loss: 2.5719281641265943

Epoch: 6| Step: 13
Training loss: 2.499714072088987
Validation loss: 2.5696705582788932

Epoch: 539| Step: 0
Training loss: 2.6317650949997016
Validation loss: 2.5457431188808077

Epoch: 6| Step: 1
Training loss: 2.8437567071521177
Validation loss: 2.5219193995929476

Epoch: 6| Step: 2
Training loss: 2.926205287300064
Validation loss: 2.5244381651847685

Epoch: 6| Step: 3
Training loss: 3.080617602218132
Validation loss: 2.5534854000092646

Epoch: 6| Step: 4
Training loss: 2.454022383105135
Validation loss: 2.5590955527579626

Epoch: 6| Step: 5
Training loss: 2.660772535101606
Validation loss: 2.581298920861237

Epoch: 6| Step: 6
Training loss: 2.6287552448679308
Validation loss: 2.59518708399331

Epoch: 6| Step: 7
Training loss: 2.463375954300139
Validation loss: 2.6089701700471246

Epoch: 6| Step: 8
Training loss: 2.1779207021606415
Validation loss: 2.6003430808679937

Epoch: 6| Step: 9
Training loss: 2.705422455944841
Validation loss: 2.6059674300819626

Epoch: 6| Step: 10
Training loss: 2.700875288760933
Validation loss: 2.609067932083712

Epoch: 6| Step: 11
Training loss: 2.599949517126759
Validation loss: 2.562843545834385

Epoch: 6| Step: 12
Training loss: 1.8417878782794914
Validation loss: 2.580118141113337

Epoch: 6| Step: 13
Training loss: 2.459253225256366
Validation loss: 2.540969443012104

Epoch: 540| Step: 0
Training loss: 2.895951266368724
Validation loss: 2.549620102651899

Epoch: 6| Step: 1
Training loss: 3.0466543264438233
Validation loss: 2.527222956925311

Epoch: 6| Step: 2
Training loss: 2.725438102012297
Validation loss: 2.5179695226040133

Epoch: 6| Step: 3
Training loss: 2.600114482413279
Validation loss: 2.5364987407887942

Epoch: 6| Step: 4
Training loss: 2.9702014787966817
Validation loss: 2.545155197013934

Epoch: 6| Step: 5
Training loss: 2.3860963300139324
Validation loss: 2.5640460047013454

Epoch: 6| Step: 6
Training loss: 2.1377986989261
Validation loss: 2.5707334918036384

Epoch: 6| Step: 7
Training loss: 2.1965672718343057
Validation loss: 2.573948296680805

Epoch: 6| Step: 8
Training loss: 2.8284485352641973
Validation loss: 2.59904881456574

Epoch: 6| Step: 9
Training loss: 2.4570377513514443
Validation loss: 2.59080104866252

Epoch: 6| Step: 10
Training loss: 2.389388219510927
Validation loss: 2.575153759448496

Epoch: 6| Step: 11
Training loss: 2.8711463975296283
Validation loss: 2.5496219668464883

Epoch: 6| Step: 12
Training loss: 2.516014779737331
Validation loss: 2.565490020686178

Epoch: 6| Step: 13
Training loss: 2.032334493019324
Validation loss: 2.5777027906817698

Epoch: 541| Step: 0
Training loss: 2.7029872263819312
Validation loss: 2.582415022234225

Epoch: 6| Step: 1
Training loss: 2.7803978632534982
Validation loss: 2.560359783393976

Epoch: 6| Step: 2
Training loss: 2.1102840019119666
Validation loss: 2.5779654126883673

Epoch: 6| Step: 3
Training loss: 2.843656433578333
Validation loss: 2.5712384499989436

Epoch: 6| Step: 4
Training loss: 2.6844751057372007
Validation loss: 2.558493791268501

Epoch: 6| Step: 5
Training loss: 2.7142097885583847
Validation loss: 2.573410756619418

Epoch: 6| Step: 6
Training loss: 2.557054828519938
Validation loss: 2.5339594541538877

Epoch: 6| Step: 7
Training loss: 2.571977348655044
Validation loss: 2.5277072528242917

Epoch: 6| Step: 8
Training loss: 2.1635214890218846
Validation loss: 2.521267661219601

Epoch: 6| Step: 9
Training loss: 2.246361227280184
Validation loss: 2.5280620979691393

Epoch: 6| Step: 10
Training loss: 2.8693960555227833
Validation loss: 2.514176073925473

Epoch: 6| Step: 11
Training loss: 2.6920154695902445
Validation loss: 2.526235401541883

Epoch: 6| Step: 12
Training loss: 2.7808513569974136
Validation loss: 2.528757208567424

Epoch: 6| Step: 13
Training loss: 2.4236575550000232
Validation loss: 2.5535129871405076

Epoch: 542| Step: 0
Training loss: 2.399923951215674
Validation loss: 2.596207003660854

Epoch: 6| Step: 1
Training loss: 2.2229648369167276
Validation loss: 2.631005137946986

Epoch: 6| Step: 2
Training loss: 2.2520748744056442
Validation loss: 2.623747702212509

Epoch: 6| Step: 3
Training loss: 2.7238102441701657
Validation loss: 2.630402551232323

Epoch: 6| Step: 4
Training loss: 2.498049451932555
Validation loss: 2.630387222865357

Epoch: 6| Step: 5
Training loss: 2.0523752175987404
Validation loss: 2.5945969044157353

Epoch: 6| Step: 6
Training loss: 2.626884692126775
Validation loss: 2.5678376651950536

Epoch: 6| Step: 7
Training loss: 2.7612155741889395
Validation loss: 2.5832745912233044

Epoch: 6| Step: 8
Training loss: 2.9580755166195343
Validation loss: 2.5677093260912773

Epoch: 6| Step: 9
Training loss: 3.096923125631202
Validation loss: 2.57335666917792

Epoch: 6| Step: 10
Training loss: 2.4466016010117966
Validation loss: 2.5754472834500044

Epoch: 6| Step: 11
Training loss: 2.970510021306464
Validation loss: 2.5864675372902743

Epoch: 6| Step: 12
Training loss: 2.5686751603039646
Validation loss: 2.600910034368218

Epoch: 6| Step: 13
Training loss: 2.191447592496608
Validation loss: 2.6200041159527276

Epoch: 543| Step: 0
Training loss: 2.802135273240493
Validation loss: 2.5852866748386183

Epoch: 6| Step: 1
Training loss: 3.1330197995823768
Validation loss: 2.585129024111466

Epoch: 6| Step: 2
Training loss: 2.755000942527762
Validation loss: 2.5932175788755356

Epoch: 6| Step: 3
Training loss: 2.5658545518001703
Validation loss: 2.5653999370888796

Epoch: 6| Step: 4
Training loss: 2.452305359188988
Validation loss: 2.5193098439804205

Epoch: 6| Step: 5
Training loss: 2.2902147953628553
Validation loss: 2.4949408028540088

Epoch: 6| Step: 6
Training loss: 2.680481551163964
Validation loss: 2.509935747486212

Epoch: 6| Step: 7
Training loss: 2.237967956879474
Validation loss: 2.494701807164094

Epoch: 6| Step: 8
Training loss: 2.0213187771845944
Validation loss: 2.488200017857148

Epoch: 6| Step: 9
Training loss: 2.933509226062623
Validation loss: 2.4940445609135304

Epoch: 6| Step: 10
Training loss: 2.938781134255103
Validation loss: 2.528090865040895

Epoch: 6| Step: 11
Training loss: 2.5397822372323646
Validation loss: 2.5828289415512016

Epoch: 6| Step: 12
Training loss: 1.8652154572011852
Validation loss: 2.615282216729979

Epoch: 6| Step: 13
Training loss: 3.146227645582428
Validation loss: 2.636201538257588

Epoch: 544| Step: 0
Training loss: 2.455740827827369
Validation loss: 2.680660422647092

Epoch: 6| Step: 1
Training loss: 3.521935254777233
Validation loss: 2.7027011586235856

Epoch: 6| Step: 2
Training loss: 1.8708864228575357
Validation loss: 2.668621135952167

Epoch: 6| Step: 3
Training loss: 2.1225774082765456
Validation loss: 2.624118956900861

Epoch: 6| Step: 4
Training loss: 2.7170856687078184
Validation loss: 2.613785322914441

Epoch: 6| Step: 5
Training loss: 2.0963058813627566
Validation loss: 2.5797066002128837

Epoch: 6| Step: 6
Training loss: 2.091617238143355
Validation loss: 2.5640455617713442

Epoch: 6| Step: 7
Training loss: 3.079399658253054
Validation loss: 2.5406083805817263

Epoch: 6| Step: 8
Training loss: 2.3033971245300835
Validation loss: 2.5290307439674398

Epoch: 6| Step: 9
Training loss: 2.859201561509076
Validation loss: 2.5232360712717505

Epoch: 6| Step: 10
Training loss: 2.7067405907944875
Validation loss: 2.502884702798494

Epoch: 6| Step: 11
Training loss: 2.2643690113701256
Validation loss: 2.5288911435200427

Epoch: 6| Step: 12
Training loss: 3.070035732695047
Validation loss: 2.5217896517657437

Epoch: 6| Step: 13
Training loss: 2.489454630527014
Validation loss: 2.4871901937329457

Epoch: 545| Step: 0
Training loss: 1.9278098790186038
Validation loss: 2.492411176496204

Epoch: 6| Step: 1
Training loss: 3.0602738989623006
Validation loss: 2.485393942355918

Epoch: 6| Step: 2
Training loss: 2.7979205856996434
Validation loss: 2.4734937700352484

Epoch: 6| Step: 3
Training loss: 1.853188617508479
Validation loss: 2.4795634299588936

Epoch: 6| Step: 4
Training loss: 2.122416552733094
Validation loss: 2.4971532415869224

Epoch: 6| Step: 5
Training loss: 2.35877124059157
Validation loss: 2.5044088496093613

Epoch: 6| Step: 6
Training loss: 2.982005351920797
Validation loss: 2.5135182449429094

Epoch: 6| Step: 7
Training loss: 2.764169773502193
Validation loss: 2.524651024329996

Epoch: 6| Step: 8
Training loss: 2.824339467023713
Validation loss: 2.5312357428263272

Epoch: 6| Step: 9
Training loss: 2.7715033005652265
Validation loss: 2.5436821582958276

Epoch: 6| Step: 10
Training loss: 2.856663653514197
Validation loss: 2.5638620741867704

Epoch: 6| Step: 11
Training loss: 2.8317340563351117
Validation loss: 2.595633858356118

Epoch: 6| Step: 12
Training loss: 2.216936256631389
Validation loss: 2.608923134288

Epoch: 6| Step: 13
Training loss: 2.450739678810689
Validation loss: 2.6520127059002214

Epoch: 546| Step: 0
Training loss: 2.1365721266963313
Validation loss: 2.654324878576083

Epoch: 6| Step: 1
Training loss: 2.4790728147891525
Validation loss: 2.6821035419316632

Epoch: 6| Step: 2
Training loss: 2.7659020581451297
Validation loss: 2.6529499282934053

Epoch: 6| Step: 3
Training loss: 2.4115021099513987
Validation loss: 2.6439653513552197

Epoch: 6| Step: 4
Training loss: 2.5605210827445735
Validation loss: 2.599566228003765

Epoch: 6| Step: 5
Training loss: 2.7053850020539367
Validation loss: 2.57652360857471

Epoch: 6| Step: 6
Training loss: 1.7997553420688996
Validation loss: 2.514487300034436

Epoch: 6| Step: 7
Training loss: 2.178481339103968
Validation loss: 2.49670204316065

Epoch: 6| Step: 8
Training loss: 3.010285388939688
Validation loss: 2.4805893807715362

Epoch: 6| Step: 9
Training loss: 2.9496378013545472
Validation loss: 2.473181113848874

Epoch: 6| Step: 10
Training loss: 3.138169272725317
Validation loss: 2.4658499075828315

Epoch: 6| Step: 11
Training loss: 2.8124350646258156
Validation loss: 2.476725810913492

Epoch: 6| Step: 12
Training loss: 2.7212647832522374
Validation loss: 2.463190067476789

Epoch: 6| Step: 13
Training loss: 2.49813133973822
Validation loss: 2.4800618347018837

Epoch: 547| Step: 0
Training loss: 2.295087469092124
Validation loss: 2.484128442800245

Epoch: 6| Step: 1
Training loss: 2.01724615624894
Validation loss: 2.481173623214642

Epoch: 6| Step: 2
Training loss: 2.9681143632329903
Validation loss: 2.5040091229379757

Epoch: 6| Step: 3
Training loss: 2.598039871227028
Validation loss: 2.511780838742871

Epoch: 6| Step: 4
Training loss: 2.810194638933646
Validation loss: 2.5132744967727403

Epoch: 6| Step: 5
Training loss: 2.2411685981158724
Validation loss: 2.5461265097755743

Epoch: 6| Step: 6
Training loss: 2.811297011060805
Validation loss: 2.5607214337117945

Epoch: 6| Step: 7
Training loss: 2.811598145743483
Validation loss: 2.576079245107384

Epoch: 6| Step: 8
Training loss: 2.5620822100704865
Validation loss: 2.5767041191064517

Epoch: 6| Step: 9
Training loss: 3.062931419658423
Validation loss: 2.5880820530963438

Epoch: 6| Step: 10
Training loss: 2.1523034287568463
Validation loss: 2.5991385910301714

Epoch: 6| Step: 11
Training loss: 2.238301168889063
Validation loss: 2.6470907648680693

Epoch: 6| Step: 12
Training loss: 2.7959835400622137
Validation loss: 2.6379521699135458

Epoch: 6| Step: 13
Training loss: 2.5768884641160046
Validation loss: 2.633291385049644

Epoch: 548| Step: 0
Training loss: 2.932834897898291
Validation loss: 2.638961966351348

Epoch: 6| Step: 1
Training loss: 2.1585303149185475
Validation loss: 2.6366009064914464

Epoch: 6| Step: 2
Training loss: 2.650969338820004
Validation loss: 2.6481528001339285

Epoch: 6| Step: 3
Training loss: 2.6537138556140576
Validation loss: 2.630306439360543

Epoch: 6| Step: 4
Training loss: 1.453380685276937
Validation loss: 2.6055469016932618

Epoch: 6| Step: 5
Training loss: 3.273487463959008
Validation loss: 2.5858059804967657

Epoch: 6| Step: 6
Training loss: 2.3053980879520797
Validation loss: 2.5769610818293773

Epoch: 6| Step: 7
Training loss: 2.8054941871486307
Validation loss: 2.573380210848408

Epoch: 6| Step: 8
Training loss: 2.7189416927414665
Validation loss: 2.569664572351367

Epoch: 6| Step: 9
Training loss: 2.7892025183143994
Validation loss: 2.5809171292022888

Epoch: 6| Step: 10
Training loss: 2.2608736926857644
Validation loss: 2.6248854608738834

Epoch: 6| Step: 11
Training loss: 2.6950570248036234
Validation loss: 2.648161908842933

Epoch: 6| Step: 12
Training loss: 2.8250573312799
Validation loss: 2.6297171926195135

Epoch: 6| Step: 13
Training loss: 1.6171695136945134
Validation loss: 2.6006249844862097

Epoch: 549| Step: 0
Training loss: 2.556796168993585
Validation loss: 2.564650993653867

Epoch: 6| Step: 1
Training loss: 2.72158209958029
Validation loss: 2.5565073716892375

Epoch: 6| Step: 2
Training loss: 2.872721225064917
Validation loss: 2.536104148778484

Epoch: 6| Step: 3
Training loss: 2.533547006764595
Validation loss: 2.53275659658412

Epoch: 6| Step: 4
Training loss: 2.264700023331724
Validation loss: 2.5221152641525553

Epoch: 6| Step: 5
Training loss: 3.2604110928976335
Validation loss: 2.5443496298091075

Epoch: 6| Step: 6
Training loss: 2.49296734605712
Validation loss: 2.542679382356478

Epoch: 6| Step: 7
Training loss: 2.4869530694734037
Validation loss: 2.5192703863708967

Epoch: 6| Step: 8
Training loss: 2.1165060938606155
Validation loss: 2.5167367310832995

Epoch: 6| Step: 9
Training loss: 2.450786180281491
Validation loss: 2.5274349983001816

Epoch: 6| Step: 10
Training loss: 2.37244679591313
Validation loss: 2.5367134570510177

Epoch: 6| Step: 11
Training loss: 2.6165549353619246
Validation loss: 2.5577937201975423

Epoch: 6| Step: 12
Training loss: 2.439763705271688
Validation loss: 2.586598700049185

Epoch: 6| Step: 13
Training loss: 2.3621234169806495
Validation loss: 2.5969780983470017

Epoch: 550| Step: 0
Training loss: 2.3420894589559214
Validation loss: 2.598427889388947

Epoch: 6| Step: 1
Training loss: 2.5155553393463084
Validation loss: 2.578972852499446

Epoch: 6| Step: 2
Training loss: 2.8240636674820103
Validation loss: 2.5980065323552073

Epoch: 6| Step: 3
Training loss: 2.1173756646017274
Validation loss: 2.5779120542822302

Epoch: 6| Step: 4
Training loss: 3.0578601488427117
Validation loss: 2.5912862453465713

Epoch: 6| Step: 5
Training loss: 3.18196103406985
Validation loss: 2.577135732411527

Epoch: 6| Step: 6
Training loss: 2.2499848471237263
Validation loss: 2.5394127994582614

Epoch: 6| Step: 7
Training loss: 2.7266286060440743
Validation loss: 2.501428746532654

Epoch: 6| Step: 8
Training loss: 2.4797000685182815
Validation loss: 2.476921600261711

Epoch: 6| Step: 9
Training loss: 2.3749451881910075
Validation loss: 2.468730629964001

Epoch: 6| Step: 10
Training loss: 2.050629528427821
Validation loss: 2.4706686354472143

Epoch: 6| Step: 11
Training loss: 2.335221503001078
Validation loss: 2.480240820167323

Epoch: 6| Step: 12
Training loss: 2.867070582861855
Validation loss: 2.4856024065640856

Epoch: 6| Step: 13
Training loss: 3.1618334041286658
Validation loss: 2.5010945200693913

Testing loss: 2.7090543403443443
