Epoch: 1| Step: 0
Training loss: 5.329362563329774
Validation loss: 5.749086936159753

Epoch: 5| Step: 1
Training loss: 5.412022678392575
Validation loss: 5.738210219912377

Epoch: 5| Step: 2
Training loss: 6.0293538171509375
Validation loss: 5.726939729232387

Epoch: 5| Step: 3
Training loss: 6.171011794362583
Validation loss: 5.715566133354235

Epoch: 5| Step: 4
Training loss: 6.352010225513597
Validation loss: 5.7028304647261665

Epoch: 5| Step: 5
Training loss: 4.965162409558815
Validation loss: 5.690114967690931

Epoch: 5| Step: 6
Training loss: 5.380883124380438
Validation loss: 5.676279260283676

Epoch: 5| Step: 7
Training loss: 4.918874061890908
Validation loss: 5.661911943348144

Epoch: 5| Step: 8
Training loss: 6.34026853744801
Validation loss: 5.64620556819115

Epoch: 5| Step: 9
Training loss: 6.504550807963522
Validation loss: 5.629881163174774

Epoch: 5| Step: 10
Training loss: 5.186595240365102
Validation loss: 5.612284576858985

Epoch: 2| Step: 0
Training loss: 6.322804415951283
Validation loss: 5.594005178109124

Epoch: 5| Step: 1
Training loss: 6.518981800730979
Validation loss: 5.572799216148246

Epoch: 5| Step: 2
Training loss: 5.307828756851576
Validation loss: 5.551909809725085

Epoch: 5| Step: 3
Training loss: 5.6553376025705
Validation loss: 5.527679701928041

Epoch: 5| Step: 4
Training loss: 5.1554045012878875
Validation loss: 5.50379504907001

Epoch: 5| Step: 5
Training loss: 6.009164486915843
Validation loss: 5.4772748965513145

Epoch: 5| Step: 6
Training loss: 4.767534517544321
Validation loss: 5.449762138330794

Epoch: 5| Step: 7
Training loss: 5.681141075709979
Validation loss: 5.420858682918394

Epoch: 5| Step: 8
Training loss: 5.100392322783952
Validation loss: 5.3897722199565195

Epoch: 5| Step: 9
Training loss: 4.455229252012547
Validation loss: 5.358428751956896

Epoch: 5| Step: 10
Training loss: 5.409960052568387
Validation loss: 5.32438678506536

Epoch: 3| Step: 0
Training loss: 5.5247826995234055
Validation loss: 5.289189757075216

Epoch: 5| Step: 1
Training loss: 5.7490558678431745
Validation loss: 5.253543247964493

Epoch: 5| Step: 2
Training loss: 5.052495041683884
Validation loss: 5.217169837990681

Epoch: 5| Step: 3
Training loss: 4.782681518874775
Validation loss: 5.1784640767170504

Epoch: 5| Step: 4
Training loss: 4.992802971523227
Validation loss: 5.139610924844499

Epoch: 5| Step: 5
Training loss: 4.449453667525163
Validation loss: 5.100447622493433

Epoch: 5| Step: 6
Training loss: 3.716709763372562
Validation loss: 5.061754774194651

Epoch: 5| Step: 7
Training loss: 5.5525518032441585
Validation loss: 5.0234891375650825

Epoch: 5| Step: 8
Training loss: 5.0688421765470455
Validation loss: 4.987286985190151

Epoch: 5| Step: 9
Training loss: 6.208073791950191
Validation loss: 4.947941466843045

Epoch: 5| Step: 10
Training loss: 5.237010690779789
Validation loss: 4.911970889433418

Epoch: 4| Step: 0
Training loss: 4.389945958528285
Validation loss: 4.87548091736554

Epoch: 5| Step: 1
Training loss: 4.74683194169185
Validation loss: 4.840497908677526

Epoch: 5| Step: 2
Training loss: 5.564093029492294
Validation loss: 4.807932823330343

Epoch: 5| Step: 3
Training loss: 4.180931291279772
Validation loss: 4.775307576631519

Epoch: 5| Step: 4
Training loss: 4.155883084500349
Validation loss: 4.744934139686107

Epoch: 5| Step: 5
Training loss: 4.934323604961126
Validation loss: 4.717419978072161

Epoch: 5| Step: 6
Training loss: 4.614667123876279
Validation loss: 4.688796402148467

Epoch: 5| Step: 7
Training loss: 4.6476182231671554
Validation loss: 4.664596794422741

Epoch: 5| Step: 8
Training loss: 5.134642299536497
Validation loss: 4.639379959750648

Epoch: 5| Step: 9
Training loss: 5.225016777340177
Validation loss: 4.61617768377114

Epoch: 5| Step: 10
Training loss: 5.1059538326962945
Validation loss: 4.590330709590391

Epoch: 5| Step: 0
Training loss: 4.624772143550506
Validation loss: 4.568088064415597

Epoch: 5| Step: 1
Training loss: 5.244927817139797
Validation loss: 4.543246826462275

Epoch: 5| Step: 2
Training loss: 5.1874976100686325
Validation loss: 4.519713536674587

Epoch: 5| Step: 3
Training loss: 4.2765155983395875
Validation loss: 4.497629662537176

Epoch: 5| Step: 4
Training loss: 4.460436791213188
Validation loss: 4.477178510786854

Epoch: 5| Step: 5
Training loss: 4.438286295254899
Validation loss: 4.456771978933558

Epoch: 5| Step: 6
Training loss: 4.778455129312356
Validation loss: 4.435069755396575

Epoch: 5| Step: 7
Training loss: 4.793573989521553
Validation loss: 4.414463192801694

Epoch: 5| Step: 8
Training loss: 4.001737693994098
Validation loss: 4.392814003260923

Epoch: 5| Step: 9
Training loss: 3.94986466767462
Validation loss: 4.370252960840263

Epoch: 5| Step: 10
Training loss: 4.271610294783227
Validation loss: 4.352784502015355

Epoch: 6| Step: 0
Training loss: 4.944500173952353
Validation loss: 4.333915637405893

Epoch: 5| Step: 1
Training loss: 5.093495742911409
Validation loss: 4.312649672403082

Epoch: 5| Step: 2
Training loss: 4.648019980264551
Validation loss: 4.297540698200054

Epoch: 5| Step: 3
Training loss: 4.536053236149422
Validation loss: 4.277981884338096

Epoch: 5| Step: 4
Training loss: 4.356260000296762
Validation loss: 4.2591769448624515

Epoch: 5| Step: 5
Training loss: 4.230915528548969
Validation loss: 4.239572016715589

Epoch: 5| Step: 6
Training loss: 4.149331666375669
Validation loss: 4.220392371900466

Epoch: 5| Step: 7
Training loss: 3.904037215055472
Validation loss: 4.201431093495785

Epoch: 5| Step: 8
Training loss: 4.361584394060681
Validation loss: 4.18196277747598

Epoch: 5| Step: 9
Training loss: 3.784780950216999
Validation loss: 4.16146623675718

Epoch: 5| Step: 10
Training loss: 3.810953921149341
Validation loss: 4.144648453063516

Epoch: 7| Step: 0
Training loss: 4.770672635810519
Validation loss: 4.12662314322166

Epoch: 5| Step: 1
Training loss: 3.4021483758306297
Validation loss: 4.1076193245816786

Epoch: 5| Step: 2
Training loss: 3.9863969048374934
Validation loss: 4.092781051795551

Epoch: 5| Step: 3
Training loss: 5.224608462324687
Validation loss: 4.07852410910374

Epoch: 5| Step: 4
Training loss: 3.8053227389757773
Validation loss: 4.061515113203004

Epoch: 5| Step: 5
Training loss: 4.618169328376412
Validation loss: 4.0443675424875645

Epoch: 5| Step: 6
Training loss: 4.155750215927052
Validation loss: 4.031850616337446

Epoch: 5| Step: 7
Training loss: 3.693118195952757
Validation loss: 4.019406528348256

Epoch: 5| Step: 8
Training loss: 4.454283446496026
Validation loss: 4.006698078937855

Epoch: 5| Step: 9
Training loss: 3.7147232180515086
Validation loss: 3.9940577484204804

Epoch: 5| Step: 10
Training loss: 3.9749352024003173
Validation loss: 3.9832136031060674

Epoch: 8| Step: 0
Training loss: 3.670723332731769
Validation loss: 3.969256973861904

Epoch: 5| Step: 1
Training loss: 3.933611205894734
Validation loss: 3.956114145067341

Epoch: 5| Step: 2
Training loss: 2.8537305141323417
Validation loss: 3.9431656838130005

Epoch: 5| Step: 3
Training loss: 5.081300089121201
Validation loss: 3.9307908916145013

Epoch: 5| Step: 4
Training loss: 3.6506499090718023
Validation loss: 3.919427949978108

Epoch: 5| Step: 5
Training loss: 3.9323479991524133
Validation loss: 3.906970093342816

Epoch: 5| Step: 6
Training loss: 4.809990959555523
Validation loss: 3.8918192167677357

Epoch: 5| Step: 7
Training loss: 3.893474224972774
Validation loss: 3.881939549352245

Epoch: 5| Step: 8
Training loss: 3.742358114219685
Validation loss: 3.872226787890141

Epoch: 5| Step: 9
Training loss: 4.3384723024291985
Validation loss: 3.861654977116148

Epoch: 5| Step: 10
Training loss: 4.406276188765812
Validation loss: 3.8464767371318054

Epoch: 9| Step: 0
Training loss: 3.3987150232410044
Validation loss: 3.8293970790003806

Epoch: 5| Step: 1
Training loss: 3.0533720730596405
Validation loss: 3.823118167589664

Epoch: 5| Step: 2
Training loss: 4.47231507978268
Validation loss: 3.8122219869918554

Epoch: 5| Step: 3
Training loss: 4.53115423693258
Validation loss: 3.799863294885281

Epoch: 5| Step: 4
Training loss: 4.013454221592463
Validation loss: 3.789597079108077

Epoch: 5| Step: 5
Training loss: 4.477832447619615
Validation loss: 3.780200785226296

Epoch: 5| Step: 6
Training loss: 3.3722573898746893
Validation loss: 3.771664885987698

Epoch: 5| Step: 7
Training loss: 3.5541848298861267
Validation loss: 3.766814704865897

Epoch: 5| Step: 8
Training loss: 4.1298748457374685
Validation loss: 3.7577843577933714

Epoch: 5| Step: 9
Training loss: 3.764442353106021
Validation loss: 3.7485427882762066

Epoch: 5| Step: 10
Training loss: 4.48776744162478
Validation loss: 3.739659125608052

Epoch: 10| Step: 0
Training loss: 3.6934559454918454
Validation loss: 3.7303551513404813

Epoch: 5| Step: 1
Training loss: 4.05831035839891
Validation loss: 3.7205193476762473

Epoch: 5| Step: 2
Training loss: 3.7977321583425008
Validation loss: 3.7152425194982324

Epoch: 5| Step: 3
Training loss: 2.857587245033137
Validation loss: 3.7097496120210582

Epoch: 5| Step: 4
Training loss: 4.333101682095394
Validation loss: 3.7083757685442915

Epoch: 5| Step: 5
Training loss: 4.779819050001458
Validation loss: 3.689421539465884

Epoch: 5| Step: 6
Training loss: 3.420252724617926
Validation loss: 3.6823242806144885

Epoch: 5| Step: 7
Training loss: 3.5890781719445193
Validation loss: 3.676515651776564

Epoch: 5| Step: 8
Training loss: 4.023323724119463
Validation loss: 3.6720335190242452

Epoch: 5| Step: 9
Training loss: 4.041602275112596
Validation loss: 3.663304055803174

Epoch: 5| Step: 10
Training loss: 3.716087093125161
Validation loss: 3.653904417265183

Epoch: 11| Step: 0
Training loss: 3.9884400219376186
Validation loss: 3.646891192886644

Epoch: 5| Step: 1
Training loss: 3.818339893652349
Validation loss: 3.637172844698832

Epoch: 5| Step: 2
Training loss: 3.1270882305095906
Validation loss: 3.627749021977615

Epoch: 5| Step: 3
Training loss: 3.494340544387299
Validation loss: 3.616308903217958

Epoch: 5| Step: 4
Training loss: 3.664532011163205
Validation loss: 3.6072596311360057

Epoch: 5| Step: 5
Training loss: 3.8930428586884274
Validation loss: 3.596954742984858

Epoch: 5| Step: 6
Training loss: 4.15687498972194
Validation loss: 3.594115400530577

Epoch: 5| Step: 7
Training loss: 4.422340395534316
Validation loss: 3.5802823910431205

Epoch: 5| Step: 8
Training loss: 3.5231293334176357
Validation loss: 3.5677793108469182

Epoch: 5| Step: 9
Training loss: 3.260313542271801
Validation loss: 3.562013550789329

Epoch: 5| Step: 10
Training loss: 4.273481462939428
Validation loss: 3.5578930132916375

Epoch: 12| Step: 0
Training loss: 3.2720110933260345
Validation loss: 3.552948733200891

Epoch: 5| Step: 1
Training loss: 3.029235642464231
Validation loss: 3.553611058517119

Epoch: 5| Step: 2
Training loss: 4.430622627816229
Validation loss: 3.5439788398385046

Epoch: 5| Step: 3
Training loss: 3.8782289649374726
Validation loss: 3.525216204813487

Epoch: 5| Step: 4
Training loss: 3.732130453489373
Validation loss: 3.5201185379107525

Epoch: 5| Step: 5
Training loss: 4.0475953392595345
Validation loss: 3.5193746542246567

Epoch: 5| Step: 6
Training loss: 4.282045387950456
Validation loss: 3.50764173348782

Epoch: 5| Step: 7
Training loss: 4.574698666513926
Validation loss: 3.49913152930296

Epoch: 5| Step: 8
Training loss: 3.1781340982462565
Validation loss: 3.4981236621537146

Epoch: 5| Step: 9
Training loss: 3.156203770062887
Validation loss: 3.495011472094478

Epoch: 5| Step: 10
Training loss: 2.772223580342455
Validation loss: 3.4881494820094057

Epoch: 13| Step: 0
Training loss: 4.373605124316468
Validation loss: 3.477157006953237

Epoch: 5| Step: 1
Training loss: 4.06313330775786
Validation loss: 3.468960757930787

Epoch: 5| Step: 2
Training loss: 3.036584623577525
Validation loss: 3.462578412856907

Epoch: 5| Step: 3
Training loss: 3.355628759190569
Validation loss: 3.458059464389204

Epoch: 5| Step: 4
Training loss: 4.248940279617479
Validation loss: 3.4517926394641223

Epoch: 5| Step: 5
Training loss: 3.488621061888515
Validation loss: 3.4465141575407547

Epoch: 5| Step: 6
Training loss: 3.0844919416372125
Validation loss: 3.442579240956864

Epoch: 5| Step: 7
Training loss: 4.29468938554757
Validation loss: 3.4333710328109226

Epoch: 5| Step: 8
Training loss: 3.668149965987437
Validation loss: 3.4351193877745243

Epoch: 5| Step: 9
Training loss: 2.9009439576346376
Validation loss: 3.427028809795769

Epoch: 5| Step: 10
Training loss: 3.4409541028971353
Validation loss: 3.426050362554598

Epoch: 14| Step: 0
Training loss: 3.6998873049095375
Validation loss: 3.4110458058220177

Epoch: 5| Step: 1
Training loss: 3.5528296677537594
Validation loss: 3.401674311508107

Epoch: 5| Step: 2
Training loss: 3.2580052600066436
Validation loss: 3.3995246985977583

Epoch: 5| Step: 3
Training loss: 3.533254678918381
Validation loss: 3.39426719283926

Epoch: 5| Step: 4
Training loss: 3.5120561584031984
Validation loss: 3.3943659419546925

Epoch: 5| Step: 5
Training loss: 4.216542888729476
Validation loss: 3.384574860950085

Epoch: 5| Step: 6
Training loss: 3.222968734849954
Validation loss: 3.377674531872174

Epoch: 5| Step: 7
Training loss: 2.5902832026647826
Validation loss: 3.3726117272336853

Epoch: 5| Step: 8
Training loss: 3.8712299834914234
Validation loss: 3.3739538223409737

Epoch: 5| Step: 9
Training loss: 4.390699501355798
Validation loss: 3.3684712456679873

Epoch: 5| Step: 10
Training loss: 3.605249201908424
Validation loss: 3.3611321652157895

Epoch: 15| Step: 0
Training loss: 3.3320323948561925
Validation loss: 3.357184911245637

Epoch: 5| Step: 1
Training loss: 3.382914270715812
Validation loss: 3.3529086945313473

Epoch: 5| Step: 2
Training loss: 3.749333894697919
Validation loss: 3.3481780985465157

Epoch: 5| Step: 3
Training loss: 3.117414805602621
Validation loss: 3.348181168931045

Epoch: 5| Step: 4
Training loss: 2.5959916137477568
Validation loss: 3.3446176296669297

Epoch: 5| Step: 5
Training loss: 3.673953502894486
Validation loss: 3.3422115613761822

Epoch: 5| Step: 6
Training loss: 3.8558971472354644
Validation loss: 3.335500197962592

Epoch: 5| Step: 7
Training loss: 3.9446139784244716
Validation loss: 3.3336186738068556

Epoch: 5| Step: 8
Training loss: 3.9101527134958407
Validation loss: 3.3294234653837456

Epoch: 5| Step: 9
Training loss: 4.0381505294486395
Validation loss: 3.3317020044269343

Epoch: 5| Step: 10
Training loss: 3.447757882479385
Validation loss: 3.329194653398661

Epoch: 16| Step: 0
Training loss: 3.4119008638708737
Validation loss: 3.324558955599536

Epoch: 5| Step: 1
Training loss: 3.989815143328032
Validation loss: 3.3168797451794667

Epoch: 5| Step: 2
Training loss: 3.51081892627362
Validation loss: 3.3148920821894317

Epoch: 5| Step: 3
Training loss: 3.6918251405432474
Validation loss: 3.3142396797470903

Epoch: 5| Step: 4
Training loss: 3.3426469070688447
Validation loss: 3.3121466251784466

Epoch: 5| Step: 5
Training loss: 3.054670328935914
Validation loss: 3.3074490639644747

Epoch: 5| Step: 6
Training loss: 3.7874710988367855
Validation loss: 3.299837503879223

Epoch: 5| Step: 7
Training loss: 3.572518433082174
Validation loss: 3.3010539921346806

Epoch: 5| Step: 8
Training loss: 3.7178633458313617
Validation loss: 3.296375978136201

Epoch: 5| Step: 9
Training loss: 3.61732380488662
Validation loss: 3.2866830094567283

Epoch: 5| Step: 10
Training loss: 3.1525845536124453
Validation loss: 3.2871638019409604

Epoch: 17| Step: 0
Training loss: 2.8498001296246365
Validation loss: 3.283503764028656

Epoch: 5| Step: 1
Training loss: 3.4300842750806098
Validation loss: 3.2822849092889657

Epoch: 5| Step: 2
Training loss: 3.875238226674144
Validation loss: 3.2823305146952353

Epoch: 5| Step: 3
Training loss: 3.5241944711568096
Validation loss: 3.2726406378899435

Epoch: 5| Step: 4
Training loss: 3.4154950590973283
Validation loss: 3.27085201670103

Epoch: 5| Step: 5
Training loss: 3.7020174454618533
Validation loss: 3.2744533027720912

Epoch: 5| Step: 6
Training loss: 3.575818913707109
Validation loss: 3.2709560811482428

Epoch: 5| Step: 7
Training loss: 3.3459714836460512
Validation loss: 3.2628142687080395

Epoch: 5| Step: 8
Training loss: 3.8064406975140708
Validation loss: 3.2569829010862934

Epoch: 5| Step: 9
Training loss: 3.066339382730328
Validation loss: 3.256155500012463

Epoch: 5| Step: 10
Training loss: 4.0298724519219915
Validation loss: 3.2519407385980967

Epoch: 18| Step: 0
Training loss: 2.6249387824776735
Validation loss: 3.249358422284291

Epoch: 5| Step: 1
Training loss: 3.2424675142635873
Validation loss: 3.2509341794421376

Epoch: 5| Step: 2
Training loss: 3.44824509146543
Validation loss: 3.2518276253573424

Epoch: 5| Step: 3
Training loss: 3.3268025954410345
Validation loss: 3.2472429421175804

Epoch: 5| Step: 4
Training loss: 3.6281903138635494
Validation loss: 3.2426848015218748

Epoch: 5| Step: 5
Training loss: 3.217162398119502
Validation loss: 3.237654565873391

Epoch: 5| Step: 6
Training loss: 3.3882657470066997
Validation loss: 3.2375889138023797

Epoch: 5| Step: 7
Training loss: 3.880455606590762
Validation loss: 3.2378448584558024

Epoch: 5| Step: 8
Training loss: 3.8937032387560078
Validation loss: 3.236231868464343

Epoch: 5| Step: 9
Training loss: 3.4722132534335124
Validation loss: 3.2245734858437873

Epoch: 5| Step: 10
Training loss: 4.14387217898214
Validation loss: 3.2213738452861658

Epoch: 19| Step: 0
Training loss: 2.8084954468736214
Validation loss: 3.220752522832694

Epoch: 5| Step: 1
Training loss: 4.15150467585048
Validation loss: 3.219100487042623

Epoch: 5| Step: 2
Training loss: 3.595549423190015
Validation loss: 3.211782008007806

Epoch: 5| Step: 3
Training loss: 3.653978343070525
Validation loss: 3.20861323898486

Epoch: 5| Step: 4
Training loss: 3.7276498419810555
Validation loss: 3.2187621955389654

Epoch: 5| Step: 5
Training loss: 2.947911256890787
Validation loss: 3.2298626570775073

Epoch: 5| Step: 6
Training loss: 3.452902670214668
Validation loss: 3.2039293145240593

Epoch: 5| Step: 7
Training loss: 3.459890788565273
Validation loss: 3.202005810602846

Epoch: 5| Step: 8
Training loss: 3.6526002844817005
Validation loss: 3.216905827987734

Epoch: 5| Step: 9
Training loss: 3.319004079284644
Validation loss: 3.2114152139035754

Epoch: 5| Step: 10
Training loss: 3.173589233797898
Validation loss: 3.191679048563723

Epoch: 20| Step: 0
Training loss: 2.7167568574065704
Validation loss: 3.2039964388389124

Epoch: 5| Step: 1
Training loss: 3.876989284702279
Validation loss: 3.225121223058247

Epoch: 5| Step: 2
Training loss: 1.9917570958164932
Validation loss: 3.200332975047883

Epoch: 5| Step: 3
Training loss: 3.848670105558659
Validation loss: 3.1948307276996033

Epoch: 5| Step: 4
Training loss: 3.9746360084334933
Validation loss: 3.1846310441886345

Epoch: 5| Step: 5
Training loss: 3.218328948397409
Validation loss: 3.1919482465465228

Epoch: 5| Step: 6
Training loss: 3.2607069444879637
Validation loss: 3.19489696231843

Epoch: 5| Step: 7
Training loss: 3.753249985315461
Validation loss: 3.1915830198053947

Epoch: 5| Step: 8
Training loss: 3.8138869217431264
Validation loss: 3.1751211082402455

Epoch: 5| Step: 9
Training loss: 3.359590745252454
Validation loss: 3.172535183681228

Epoch: 5| Step: 10
Training loss: 3.654867057417747
Validation loss: 3.1739451697943477

Epoch: 21| Step: 0
Training loss: 3.956404942375616
Validation loss: 3.1860371272376025

Epoch: 5| Step: 1
Training loss: 3.6257382660553406
Validation loss: 3.1771772145172474

Epoch: 5| Step: 2
Training loss: 3.4538221389134294
Validation loss: 3.161361191434249

Epoch: 5| Step: 3
Training loss: 2.7837406107928753
Validation loss: 3.1599422428864834

Epoch: 5| Step: 4
Training loss: 3.7940728793305847
Validation loss: 3.161531441470956

Epoch: 5| Step: 5
Training loss: 2.6620594000376125
Validation loss: 3.1659983953649213

Epoch: 5| Step: 6
Training loss: 3.4716156815478083
Validation loss: 3.1727863487457375

Epoch: 5| Step: 7
Training loss: 3.1694275381841126
Validation loss: 3.182261832362418

Epoch: 5| Step: 8
Training loss: 3.265834965868911
Validation loss: 3.1697941838032264

Epoch: 5| Step: 9
Training loss: 3.7106915522938104
Validation loss: 3.1617046224519703

Epoch: 5| Step: 10
Training loss: 3.669922524655677
Validation loss: 3.1549300491136987

Epoch: 22| Step: 0
Training loss: 3.3591828047310237
Validation loss: 3.155720800714356

Epoch: 5| Step: 1
Training loss: 3.7844817167776124
Validation loss: 3.1724085738631307

Epoch: 5| Step: 2
Training loss: 2.907015955904491
Validation loss: 3.154837234586563

Epoch: 5| Step: 3
Training loss: 3.8647184254083027
Validation loss: 3.1539544483536623

Epoch: 5| Step: 4
Training loss: 3.0512501140189707
Validation loss: 3.15111821867336

Epoch: 5| Step: 5
Training loss: 3.342497974472174
Validation loss: 3.149616854066457

Epoch: 5| Step: 6
Training loss: 2.8912034564265165
Validation loss: 3.1471691010739486

Epoch: 5| Step: 7
Training loss: 2.8854021055953574
Validation loss: 3.149355627752991

Epoch: 5| Step: 8
Training loss: 4.328080710724998
Validation loss: 3.149388032121839

Epoch: 5| Step: 9
Training loss: 3.7691351647880573
Validation loss: 3.1495313829397453

Epoch: 5| Step: 10
Training loss: 3.066655356621273
Validation loss: 3.146441267197221

Epoch: 23| Step: 0
Training loss: 3.621661128393773
Validation loss: 3.1440003652338886

Epoch: 5| Step: 1
Training loss: 3.3342289357248993
Validation loss: 3.142507911984325

Epoch: 5| Step: 2
Training loss: 2.913821131141984
Validation loss: 3.1387947172269635

Epoch: 5| Step: 3
Training loss: 3.7748717431518246
Validation loss: 3.1392151152475773

Epoch: 5| Step: 4
Training loss: 3.3782831400257334
Validation loss: 3.1341183029553474

Epoch: 5| Step: 5
Training loss: 3.2440713947403137
Validation loss: 3.1368590650340944

Epoch: 5| Step: 6
Training loss: 3.8077048491928696
Validation loss: 3.1338661019308156

Epoch: 5| Step: 7
Training loss: 3.0467912711352123
Validation loss: 3.1302614002617246

Epoch: 5| Step: 8
Training loss: 3.309286177958835
Validation loss: 3.128555640970998

Epoch: 5| Step: 9
Training loss: 3.3941645978444743
Validation loss: 3.1310301814910133

Epoch: 5| Step: 10
Training loss: 3.584596869495491
Validation loss: 3.129899249858285

Epoch: 24| Step: 0
Training loss: 3.4686416746528708
Validation loss: 3.1316120854264917

Epoch: 5| Step: 1
Training loss: 3.5334738421542724
Validation loss: 3.1262433029619827

Epoch: 5| Step: 2
Training loss: 2.6861786366281
Validation loss: 3.126972583320959

Epoch: 5| Step: 3
Training loss: 2.810658593836971
Validation loss: 3.123774116190371

Epoch: 5| Step: 4
Training loss: 3.3070573538532417
Validation loss: 3.122036271349434

Epoch: 5| Step: 5
Training loss: 3.9610122583320466
Validation loss: 3.1217262183424332

Epoch: 5| Step: 6
Training loss: 2.8035806581104032
Validation loss: 3.119026700161924

Epoch: 5| Step: 7
Training loss: 3.885628552152186
Validation loss: 3.119031127106606

Epoch: 5| Step: 8
Training loss: 4.128664643031587
Validation loss: 3.1210076111020197

Epoch: 5| Step: 9
Training loss: 3.181945448968282
Validation loss: 3.121841028459316

Epoch: 5| Step: 10
Training loss: 3.248058472760037
Validation loss: 3.117830562000842

Epoch: 25| Step: 0
Training loss: 3.3437993411407745
Validation loss: 3.1197067386960002

Epoch: 5| Step: 1
Training loss: 3.33466909983151
Validation loss: 3.116439191242249

Epoch: 5| Step: 2
Training loss: 3.653095939005051
Validation loss: 3.116287636544818

Epoch: 5| Step: 3
Training loss: 2.6143840293354454
Validation loss: 3.1144885174503347

Epoch: 5| Step: 4
Training loss: 3.3874470104844936
Validation loss: 3.1132112425367198

Epoch: 5| Step: 5
Training loss: 3.4649497169710406
Validation loss: 3.1118352255954007

Epoch: 5| Step: 6
Training loss: 3.1945798448993274
Validation loss: 3.109981644851293

Epoch: 5| Step: 7
Training loss: 4.064949353642756
Validation loss: 3.1107171292498625

Epoch: 5| Step: 8
Training loss: 3.0582223717900865
Validation loss: 3.110698096693865

Epoch: 5| Step: 9
Training loss: 3.2464577370951737
Validation loss: 3.1100106544181556

Epoch: 5| Step: 10
Training loss: 3.7687651018691
Validation loss: 3.107466969482184

Epoch: 26| Step: 0
Training loss: 4.162318338548364
Validation loss: 3.1075730371104395

Epoch: 5| Step: 1
Training loss: 3.082204216767978
Validation loss: 3.1068332189555528

Epoch: 5| Step: 2
Training loss: 2.9761731951983883
Validation loss: 3.1050200912366934

Epoch: 5| Step: 3
Training loss: 3.513423518616421
Validation loss: 3.1036519754450533

Epoch: 5| Step: 4
Training loss: 3.424153166170507
Validation loss: 3.1018538683913635

Epoch: 5| Step: 5
Training loss: 3.307323802081
Validation loss: 3.103045324136617

Epoch: 5| Step: 6
Training loss: 2.821282639963268
Validation loss: 3.102381001379795

Epoch: 5| Step: 7
Training loss: 4.0332151842283395
Validation loss: 3.102369133373507

Epoch: 5| Step: 8
Training loss: 3.403610466693328
Validation loss: 3.0999949678505216

Epoch: 5| Step: 9
Training loss: 2.7719176520299103
Validation loss: 3.100115761132034

Epoch: 5| Step: 10
Training loss: 3.4228097692705286
Validation loss: 3.1005884907332217

Epoch: 27| Step: 0
Training loss: 2.3488833351314207
Validation loss: 3.098172749298616

Epoch: 5| Step: 1
Training loss: 3.1964858309525583
Validation loss: 3.0983646597997936

Epoch: 5| Step: 2
Training loss: 2.841374002042396
Validation loss: 3.097651976236772

Epoch: 5| Step: 3
Training loss: 3.091897429073944
Validation loss: 3.096746869878906

Epoch: 5| Step: 4
Training loss: 2.6689174411964043
Validation loss: 3.0966623436261935

Epoch: 5| Step: 5
Training loss: 3.886228720286782
Validation loss: 3.0964332206933576

Epoch: 5| Step: 6
Training loss: 3.7865792543324406
Validation loss: 3.094919274813564

Epoch: 5| Step: 7
Training loss: 3.2628803309183807
Validation loss: 3.093947355294669

Epoch: 5| Step: 8
Training loss: 4.096064488409929
Validation loss: 3.0935249043705917

Epoch: 5| Step: 9
Training loss: 3.8386685657962483
Validation loss: 3.094590179987143

Epoch: 5| Step: 10
Training loss: 3.6980004242916906
Validation loss: 3.0917181023726954

Epoch: 28| Step: 0
Training loss: 3.0432279229127577
Validation loss: 3.092901152146515

Epoch: 5| Step: 1
Training loss: 1.8261547720205127
Validation loss: 3.09213444024321

Epoch: 5| Step: 2
Training loss: 3.7688301343606665
Validation loss: 3.091348668456715

Epoch: 5| Step: 3
Training loss: 3.7707005401890163
Validation loss: 3.0910393507481357

Epoch: 5| Step: 4
Training loss: 2.751362809706933
Validation loss: 3.090364027108252

Epoch: 5| Step: 5
Training loss: 3.5291760861489894
Validation loss: 3.091113307175742

Epoch: 5| Step: 6
Training loss: 3.453228841057444
Validation loss: 3.089558690399696

Epoch: 5| Step: 7
Training loss: 3.7808787266074138
Validation loss: 3.089085316901438

Epoch: 5| Step: 8
Training loss: 3.4238576501507905
Validation loss: 3.088456380730745

Epoch: 5| Step: 9
Training loss: 3.9960123689629983
Validation loss: 3.0895018319879717

Epoch: 5| Step: 10
Training loss: 3.145220227316414
Validation loss: 3.086175935795913

Epoch: 29| Step: 0
Training loss: 3.1239179645273465
Validation loss: 3.0864021995011846

Epoch: 5| Step: 1
Training loss: 3.283771672171879
Validation loss: 3.0861486975084174

Epoch: 5| Step: 2
Training loss: 3.3604955889016344
Validation loss: 3.0850666138684186

Epoch: 5| Step: 3
Training loss: 2.956621955553588
Validation loss: 3.085463760376736

Epoch: 5| Step: 4
Training loss: 3.4518793543467496
Validation loss: 3.083355377792491

Epoch: 5| Step: 5
Training loss: 3.7803936453617633
Validation loss: 3.085513639177019

Epoch: 5| Step: 6
Training loss: 3.0151945607432604
Validation loss: 3.082979411161259

Epoch: 5| Step: 7
Training loss: 3.612436820669006
Validation loss: 3.0833452474490866

Epoch: 5| Step: 8
Training loss: 3.0903400162466954
Validation loss: 3.0821755543365317

Epoch: 5| Step: 9
Training loss: 3.9812813510588603
Validation loss: 3.0822184514005455

Epoch: 5| Step: 10
Training loss: 3.1964361551473393
Validation loss: 3.0812419049669746

Epoch: 30| Step: 0
Training loss: 4.046333424035493
Validation loss: 3.080328890749619

Epoch: 5| Step: 1
Training loss: 3.3500873725087206
Validation loss: 3.080086949347299

Epoch: 5| Step: 2
Training loss: 3.0410915161933687
Validation loss: 3.078921562131957

Epoch: 5| Step: 3
Training loss: 3.86200726276586
Validation loss: 3.0793276533509544

Epoch: 5| Step: 4
Training loss: 2.9257196437731285
Validation loss: 3.079233808014543

Epoch: 5| Step: 5
Training loss: 3.646111148966816
Validation loss: 3.077590423732617

Epoch: 5| Step: 6
Training loss: 2.834030813497882
Validation loss: 3.0760059932446224

Epoch: 5| Step: 7
Training loss: 2.9417644956349447
Validation loss: 3.0753715371717703

Epoch: 5| Step: 8
Training loss: 3.701458519779064
Validation loss: 3.0750348987961695

Epoch: 5| Step: 9
Training loss: 3.3789996713060693
Validation loss: 3.073977401025474

Epoch: 5| Step: 10
Training loss: 2.922241514341285
Validation loss: 3.0745771925430576

Epoch: 31| Step: 0
Training loss: 3.224439314962219
Validation loss: 3.0739100454304187

Epoch: 5| Step: 1
Training loss: 3.224281520800939
Validation loss: 3.0727685513403746

Epoch: 5| Step: 2
Training loss: 3.820362426181947
Validation loss: 3.0744789558482797

Epoch: 5| Step: 3
Training loss: 3.1661940941466433
Validation loss: 3.074841197045394

Epoch: 5| Step: 4
Training loss: 3.113518642435274
Validation loss: 3.0779492569750286

Epoch: 5| Step: 5
Training loss: 3.097226742074479
Validation loss: 3.073186942524052

Epoch: 5| Step: 6
Training loss: 3.0032878978424065
Validation loss: 3.071528672145522

Epoch: 5| Step: 7
Training loss: 3.8516968245228687
Validation loss: 3.071431340806507

Epoch: 5| Step: 8
Training loss: 3.0244772845648273
Validation loss: 3.0737833865938793

Epoch: 5| Step: 9
Training loss: 3.717071795657144
Validation loss: 3.070193782330311

Epoch: 5| Step: 10
Training loss: 3.5571906697730733
Validation loss: 3.069206734418247

Epoch: 32| Step: 0
Training loss: 3.7900744158602993
Validation loss: 3.0705293442458976

Epoch: 5| Step: 1
Training loss: 3.6714611063687728
Validation loss: 3.068575366422291

Epoch: 5| Step: 2
Training loss: 2.7338078373850725
Validation loss: 3.0683016867666444

Epoch: 5| Step: 3
Training loss: 3.1435220745725956
Validation loss: 3.0689274741032313

Epoch: 5| Step: 4
Training loss: 3.163353659266727
Validation loss: 3.0668814521928867

Epoch: 5| Step: 5
Training loss: 3.52234695372829
Validation loss: 3.0645816308886515

Epoch: 5| Step: 6
Training loss: 2.9545371902456945
Validation loss: 3.0671512390339966

Epoch: 5| Step: 7
Training loss: 3.6486856837679382
Validation loss: 3.0639421417149633

Epoch: 5| Step: 8
Training loss: 3.4661422412298646
Validation loss: 3.074572785389995

Epoch: 5| Step: 9
Training loss: 3.2644242264747865
Validation loss: 3.0804638124431643

Epoch: 5| Step: 10
Training loss: 3.3613065622492577
Validation loss: 3.0696302562573647

Epoch: 33| Step: 0
Training loss: 3.5562499249128123
Validation loss: 3.065477057241189

Epoch: 5| Step: 1
Training loss: 3.1627688930623514
Validation loss: 3.0656149941731923

Epoch: 5| Step: 2
Training loss: 3.3395963164466047
Validation loss: 3.0633694869127677

Epoch: 5| Step: 3
Training loss: 3.789643107497347
Validation loss: 3.066157577983426

Epoch: 5| Step: 4
Training loss: 3.267117975809702
Validation loss: 3.06277600941292

Epoch: 5| Step: 5
Training loss: 3.322058364530002
Validation loss: 3.063995945244009

Epoch: 5| Step: 6
Training loss: 3.8515803276717224
Validation loss: 3.064964956555548

Epoch: 5| Step: 7
Training loss: 2.713192488352295
Validation loss: 3.0619520559824767

Epoch: 5| Step: 8
Training loss: 3.380163975186042
Validation loss: 3.062096122745454

Epoch: 5| Step: 9
Training loss: 3.4518642972261877
Validation loss: 3.0634469097574155

Epoch: 5| Step: 10
Training loss: 2.6820474359127817
Validation loss: 3.0641178748819944

Epoch: 34| Step: 0
Training loss: 4.113178074367795
Validation loss: 3.0657104463554443

Epoch: 5| Step: 1
Training loss: 3.925918622246699
Validation loss: 3.0592093905209277

Epoch: 5| Step: 2
Training loss: 2.8776610954257547
Validation loss: 3.060349414783772

Epoch: 5| Step: 3
Training loss: 3.161425134190173
Validation loss: 3.059172748001363

Epoch: 5| Step: 4
Training loss: 3.090234473754897
Validation loss: 3.060201929928143

Epoch: 5| Step: 5
Training loss: 3.160075824407291
Validation loss: 3.0592644420950674

Epoch: 5| Step: 6
Training loss: 3.4832375898086054
Validation loss: 3.0587337071442255

Epoch: 5| Step: 7
Training loss: 3.580683164358856
Validation loss: 3.057897280349336

Epoch: 5| Step: 8
Training loss: 2.9824951003003224
Validation loss: 3.056571069837014

Epoch: 5| Step: 9
Training loss: 3.199548576223491
Validation loss: 3.0587479336637977

Epoch: 5| Step: 10
Training loss: 2.9208954989955127
Validation loss: 3.060062066744355

Epoch: 35| Step: 0
Training loss: 3.0961993761355595
Validation loss: 3.0637788159781483

Epoch: 5| Step: 1
Training loss: 3.6654153046788474
Validation loss: 3.063451676442176

Epoch: 5| Step: 2
Training loss: 3.232636652607775
Validation loss: 3.0611259872230594

Epoch: 5| Step: 3
Training loss: 3.4493285147632413
Validation loss: 3.0595391991153167

Epoch: 5| Step: 4
Training loss: 2.737546030293345
Validation loss: 3.058298903940369

Epoch: 5| Step: 5
Training loss: 3.3686681620719523
Validation loss: 3.0538047066922887

Epoch: 5| Step: 6
Training loss: 3.5230455540037995
Validation loss: 3.058119965192673

Epoch: 5| Step: 7
Training loss: 3.958011306245374
Validation loss: 3.0547079977264624

Epoch: 5| Step: 8
Training loss: 3.087008133601035
Validation loss: 3.053553599664517

Epoch: 5| Step: 9
Training loss: 2.951300163182024
Validation loss: 3.051134209639309

Epoch: 5| Step: 10
Training loss: 3.4720321111556554
Validation loss: 3.0506578041027237

Epoch: 36| Step: 0
Training loss: 2.996386099705494
Validation loss: 3.0502338584033617

Epoch: 5| Step: 1
Training loss: 3.1815487524623025
Validation loss: 3.0523711698810168

Epoch: 5| Step: 2
Training loss: 3.139749889010198
Validation loss: 3.0524073435118635

Epoch: 5| Step: 3
Training loss: 3.912288545494569
Validation loss: 3.050837690590145

Epoch: 5| Step: 4
Training loss: 3.5296892075789916
Validation loss: 3.050319562800479

Epoch: 5| Step: 5
Training loss: 3.349901334533726
Validation loss: 3.0531339622351994

Epoch: 5| Step: 6
Training loss: 2.9379809371402517
Validation loss: 3.049443823652308

Epoch: 5| Step: 7
Training loss: 3.0702464943505396
Validation loss: 3.048916047520797

Epoch: 5| Step: 8
Training loss: 3.6872372291173594
Validation loss: 3.053835181731436

Epoch: 5| Step: 9
Training loss: 3.5059922557077217
Validation loss: 3.057948926683257

Epoch: 5| Step: 10
Training loss: 3.180884283662297
Validation loss: 3.0658215961010256

Epoch: 37| Step: 0
Training loss: 2.895682863859037
Validation loss: 3.070186342387637

Epoch: 5| Step: 1
Training loss: 3.713533990895746
Validation loss: 3.07095185722587

Epoch: 5| Step: 2
Training loss: 3.7631702573823795
Validation loss: 3.0706935381960574

Epoch: 5| Step: 3
Training loss: 2.81723420860258
Validation loss: 3.0503412135523673

Epoch: 5| Step: 4
Training loss: 3.418250267424413
Validation loss: 3.0468799070408688

Epoch: 5| Step: 5
Training loss: 3.4215944776121665
Validation loss: 3.0420004565573073

Epoch: 5| Step: 6
Training loss: 3.731115347063564
Validation loss: 3.0489210202252326

Epoch: 5| Step: 7
Training loss: 3.3080316311524407
Validation loss: 3.0470562304880775

Epoch: 5| Step: 8
Training loss: 3.164182910276373
Validation loss: 3.044027612131093

Epoch: 5| Step: 9
Training loss: 3.362460684280564
Validation loss: 3.0463292072937045

Epoch: 5| Step: 10
Training loss: 2.8592354161947156
Validation loss: 3.0510891219679257

Epoch: 38| Step: 0
Training loss: 3.5119380352054277
Validation loss: 3.0507192789352073

Epoch: 5| Step: 1
Training loss: 3.4671566714703683
Validation loss: 3.050998129571306

Epoch: 5| Step: 2
Training loss: 3.319768596306077
Validation loss: 3.0590219945559878

Epoch: 5| Step: 3
Training loss: 3.6244952409470685
Validation loss: 3.054064021074024

Epoch: 5| Step: 4
Training loss: 3.204415707940665
Validation loss: 3.0430182436187714

Epoch: 5| Step: 5
Training loss: 3.3142568859481436
Validation loss: 3.0445617510390917

Epoch: 5| Step: 6
Training loss: 3.264849557024777
Validation loss: 3.0480564154505223

Epoch: 5| Step: 7
Training loss: 3.3317295666841837
Validation loss: 3.0548376881452324

Epoch: 5| Step: 8
Training loss: 3.3309770998366575
Validation loss: 3.054397514272689

Epoch: 5| Step: 9
Training loss: 2.8432920317726587
Validation loss: 3.0491499290617545

Epoch: 5| Step: 10
Training loss: 3.4365120595151226
Validation loss: 3.0439640692971244

Epoch: 39| Step: 0
Training loss: 3.0542394597294042
Validation loss: 3.038007950191617

Epoch: 5| Step: 1
Training loss: 3.400820823770436
Validation loss: 3.0376184410447267

Epoch: 5| Step: 2
Training loss: 3.4952592077442968
Validation loss: 3.0467344383629555

Epoch: 5| Step: 3
Training loss: 3.344540796620485
Validation loss: 3.0521903440122164

Epoch: 5| Step: 4
Training loss: 3.825130614998886
Validation loss: 3.0489492301214063

Epoch: 5| Step: 5
Training loss: 2.7458531584962227
Validation loss: 3.0474591364420736

Epoch: 5| Step: 6
Training loss: 2.257442351626448
Validation loss: 3.0415520915457077

Epoch: 5| Step: 7
Training loss: 3.889404840908117
Validation loss: 3.0423932260587065

Epoch: 5| Step: 8
Training loss: 3.52867802491466
Validation loss: 3.041707761056794

Epoch: 5| Step: 9
Training loss: 3.4856987735081515
Validation loss: 3.0423067902439183

Epoch: 5| Step: 10
Training loss: 3.195003578530279
Validation loss: 3.0414511862326497

Epoch: 40| Step: 0
Training loss: 3.5298496947019573
Validation loss: 3.040027000027233

Epoch: 5| Step: 1
Training loss: 3.8283315174683605
Validation loss: 3.038668085090601

Epoch: 5| Step: 2
Training loss: 3.4948512762512847
Validation loss: 3.0362963318300578

Epoch: 5| Step: 3
Training loss: 3.3409072342810253
Validation loss: 3.033839096136827

Epoch: 5| Step: 4
Training loss: 3.7298052931787757
Validation loss: 3.0348216476429766

Epoch: 5| Step: 5
Training loss: 3.2376955834891605
Validation loss: 3.033947448831495

Epoch: 5| Step: 6
Training loss: 3.497621136545113
Validation loss: 3.0362529227486896

Epoch: 5| Step: 7
Training loss: 2.817406084040587
Validation loss: 3.035119811638419

Epoch: 5| Step: 8
Training loss: 3.1612014456655757
Validation loss: 3.0376467559052416

Epoch: 5| Step: 9
Training loss: 2.634631154196836
Validation loss: 3.039324669754753

Epoch: 5| Step: 10
Training loss: 2.941313358375092
Validation loss: 3.040250068762304

Epoch: 41| Step: 0
Training loss: 3.3428033932706858
Validation loss: 3.044305285380755

Epoch: 5| Step: 1
Training loss: 3.2518582533552336
Validation loss: 3.0477573165860306

Epoch: 5| Step: 2
Training loss: 3.4575400457593815
Validation loss: 3.0408022825721015

Epoch: 5| Step: 3
Training loss: 3.1710988866327887
Validation loss: 3.031069409448403

Epoch: 5| Step: 4
Training loss: 2.775183501491291
Validation loss: 3.0335894953724156

Epoch: 5| Step: 5
Training loss: 3.1680545442490278
Validation loss: 3.034118981044224

Epoch: 5| Step: 6
Training loss: 3.3840456646482777
Validation loss: 3.0322451609762635

Epoch: 5| Step: 7
Training loss: 4.002727532290189
Validation loss: 3.0345778808548367

Epoch: 5| Step: 8
Training loss: 2.8811692100336113
Validation loss: 3.031055409941279

Epoch: 5| Step: 9
Training loss: 3.5062875130290494
Validation loss: 3.0308680275197593

Epoch: 5| Step: 10
Training loss: 3.390634422464946
Validation loss: 3.0298256808731407

Epoch: 42| Step: 0
Training loss: 2.8922871527668303
Validation loss: 3.0283011853689623

Epoch: 5| Step: 1
Training loss: 3.107861788029457
Validation loss: 3.0324429810676943

Epoch: 5| Step: 2
Training loss: 3.7079068628031444
Validation loss: 3.051892633110656

Epoch: 5| Step: 3
Training loss: 3.097207959365126
Validation loss: 3.0301339137569445

Epoch: 5| Step: 4
Training loss: 3.758579865776684
Validation loss: 3.0287411059085114

Epoch: 5| Step: 5
Training loss: 3.1550085062193425
Validation loss: 3.0278057409312766

Epoch: 5| Step: 6
Training loss: 3.1754237275211317
Validation loss: 3.027661935821087

Epoch: 5| Step: 7
Training loss: 3.554118150660923
Validation loss: 3.0246048978019706

Epoch: 5| Step: 8
Training loss: 3.4022544735255345
Validation loss: 3.024051420037223

Epoch: 5| Step: 9
Training loss: 3.4770976479801177
Validation loss: 3.0235968916587903

Epoch: 5| Step: 10
Training loss: 2.8219553212576844
Validation loss: 3.023619398490828

Epoch: 43| Step: 0
Training loss: 3.4488037136163188
Validation loss: 3.0220632972041277

Epoch: 5| Step: 1
Training loss: 3.5969627283502152
Validation loss: 3.027264969376599

Epoch: 5| Step: 2
Training loss: 3.2497397098479586
Validation loss: 3.0380710589800044

Epoch: 5| Step: 3
Training loss: 2.780758675028514
Validation loss: 3.051210108781489

Epoch: 5| Step: 4
Training loss: 2.755978155246083
Validation loss: 3.066596030397755

Epoch: 5| Step: 5
Training loss: 3.6732094794946044
Validation loss: 3.0501101718197683

Epoch: 5| Step: 6
Training loss: 3.6322156190181705
Validation loss: 3.029004192710432

Epoch: 5| Step: 7
Training loss: 3.1156669101172874
Validation loss: 3.021028750969039

Epoch: 5| Step: 8
Training loss: 4.0065887545998935
Validation loss: 3.019484939032211

Epoch: 5| Step: 9
Training loss: 3.2582170340489593
Validation loss: 3.0181775315031936

Epoch: 5| Step: 10
Training loss: 2.4118480216457674
Validation loss: 3.0172907191336673

Epoch: 44| Step: 0
Training loss: 3.5289703032275592
Validation loss: 3.019968309691878

Epoch: 5| Step: 1
Training loss: 3.1976386000096966
Validation loss: 3.0186007256825738

Epoch: 5| Step: 2
Training loss: 3.726743937619932
Validation loss: 3.0175941843588547

Epoch: 5| Step: 3
Training loss: 3.080353525605852
Validation loss: 3.017392583635133

Epoch: 5| Step: 4
Training loss: 2.806363850686323
Validation loss: 3.0143432196930453

Epoch: 5| Step: 5
Training loss: 3.775441397825304
Validation loss: 3.0144696069755157

Epoch: 5| Step: 6
Training loss: 3.1546570941277854
Validation loss: 3.016903629513032

Epoch: 5| Step: 7
Training loss: 3.297984004502981
Validation loss: 3.018575751618353

Epoch: 5| Step: 8
Training loss: 3.4097438707115497
Validation loss: 3.015210987345645

Epoch: 5| Step: 9
Training loss: 2.9824823099844395
Validation loss: 3.0204373777335594

Epoch: 5| Step: 10
Training loss: 3.202816832069864
Validation loss: 3.019077501633554

Epoch: 45| Step: 0
Training loss: 3.183126703183602
Validation loss: 3.017158425750339

Epoch: 5| Step: 1
Training loss: 3.1007758615552197
Validation loss: 3.0179311953890067

Epoch: 5| Step: 2
Training loss: 3.4342930486340975
Validation loss: 3.015909108346554

Epoch: 5| Step: 3
Training loss: 2.772358515219119
Validation loss: 3.015469225239845

Epoch: 5| Step: 4
Training loss: 3.2513556954034155
Validation loss: 3.014674013858331

Epoch: 5| Step: 5
Training loss: 3.458069174609125
Validation loss: 3.0172474665479094

Epoch: 5| Step: 6
Training loss: 3.115601406180255
Validation loss: 3.017022843229322

Epoch: 5| Step: 7
Training loss: 3.417352343971379
Validation loss: 3.0126910952093136

Epoch: 5| Step: 8
Training loss: 3.7069059618086326
Validation loss: 3.01371940156522

Epoch: 5| Step: 9
Training loss: 3.6076151202808626
Validation loss: 3.01188398293947

Epoch: 5| Step: 10
Training loss: 3.0149785272899594
Validation loss: 3.0108542238054903

Epoch: 46| Step: 0
Training loss: 3.330935155937672
Validation loss: 3.0106226978352253

Epoch: 5| Step: 1
Training loss: 3.158964745875781
Validation loss: 3.009491094180345

Epoch: 5| Step: 2
Training loss: 3.399474237967467
Validation loss: 3.0072920580321805

Epoch: 5| Step: 3
Training loss: 3.4423833665779697
Validation loss: 3.009414314087592

Epoch: 5| Step: 4
Training loss: 2.4974080000267103
Validation loss: 3.007608849958933

Epoch: 5| Step: 5
Training loss: 3.327395936870622
Validation loss: 3.007028295883141

Epoch: 5| Step: 6
Training loss: 3.361283864467459
Validation loss: 3.0077965674040277

Epoch: 5| Step: 7
Training loss: 3.7326141419686962
Validation loss: 3.004224361529978

Epoch: 5| Step: 8
Training loss: 3.454749782351073
Validation loss: 3.0055947996403516

Epoch: 5| Step: 9
Training loss: 2.893233323573512
Validation loss: 3.005500356290273

Epoch: 5| Step: 10
Training loss: 3.392873554620272
Validation loss: 3.0062812554371523

Epoch: 47| Step: 0
Training loss: 3.0628949903221825
Validation loss: 3.0085697204821646

Epoch: 5| Step: 1
Training loss: 3.578822971550051
Validation loss: 3.019301991623165

Epoch: 5| Step: 2
Training loss: 2.618763372346153
Validation loss: 3.0185449834502087

Epoch: 5| Step: 3
Training loss: 3.5648691431027717
Validation loss: 3.0239594902879703

Epoch: 5| Step: 4
Training loss: 3.3509562195206377
Validation loss: 3.008463362148572

Epoch: 5| Step: 5
Training loss: 3.5205967991094087
Validation loss: 3.003368626197188

Epoch: 5| Step: 6
Training loss: 3.5785335657331903
Validation loss: 3.0047014068055926

Epoch: 5| Step: 7
Training loss: 2.891697700033478
Validation loss: 3.000740322251235

Epoch: 5| Step: 8
Training loss: 3.0291079788784483
Validation loss: 3.001788175542854

Epoch: 5| Step: 9
Training loss: 3.4779280477389154
Validation loss: 3.0034439322365314

Epoch: 5| Step: 10
Training loss: 3.287756581319958
Validation loss: 3.0040201780829663

Epoch: 48| Step: 0
Training loss: 3.351293166215885
Validation loss: 3.0064780322195728

Epoch: 5| Step: 1
Training loss: 2.854168764285317
Validation loss: 3.0072655902787377

Epoch: 5| Step: 2
Training loss: 1.8526532143517052
Validation loss: 3.0075759980096644

Epoch: 5| Step: 3
Training loss: 3.639912678855412
Validation loss: 3.0125999063421105

Epoch: 5| Step: 4
Training loss: 3.047217716602791
Validation loss: 3.0038713391590846

Epoch: 5| Step: 5
Training loss: 3.4767165246340657
Validation loss: 2.998747211969603

Epoch: 5| Step: 6
Training loss: 3.4279689089100707
Validation loss: 2.9996383425071307

Epoch: 5| Step: 7
Training loss: 3.9505623815468556
Validation loss: 2.9994372178386515

Epoch: 5| Step: 8
Training loss: 2.689711968979991
Validation loss: 2.999528830796688

Epoch: 5| Step: 9
Training loss: 3.281727056792012
Validation loss: 3.0004597033085223

Epoch: 5| Step: 10
Training loss: 4.066732930336657
Validation loss: 3.0055503773546257

Epoch: 49| Step: 0
Training loss: 3.3547754781670758
Validation loss: 3.0013961756244494

Epoch: 5| Step: 1
Training loss: 3.598063393085795
Validation loss: 2.998651898930772

Epoch: 5| Step: 2
Training loss: 3.0383299898459457
Validation loss: 2.997714672794487

Epoch: 5| Step: 3
Training loss: 3.2099668794628604
Validation loss: 2.9988936329123845

Epoch: 5| Step: 4
Training loss: 3.5344199746910547
Validation loss: 2.997868180388295

Epoch: 5| Step: 5
Training loss: 2.5344526963371603
Validation loss: 2.9938836146447327

Epoch: 5| Step: 6
Training loss: 2.7629290010302268
Validation loss: 2.9934595895823137

Epoch: 5| Step: 7
Training loss: 3.8226726707045
Validation loss: 2.9927982561737063

Epoch: 5| Step: 8
Training loss: 3.2088030846918802
Validation loss: 2.993123352847773

Epoch: 5| Step: 9
Training loss: 3.4126048871923143
Validation loss: 2.9932860879284537

Epoch: 5| Step: 10
Training loss: 3.3686047467851545
Validation loss: 2.990176948255328

Epoch: 50| Step: 0
Training loss: 3.2000881778965837
Validation loss: 2.988380525170368

Epoch: 5| Step: 1
Training loss: 3.3298439995135194
Validation loss: 2.991824904972453

Epoch: 5| Step: 2
Training loss: 3.3152005685282924
Validation loss: 2.993935428466673

Epoch: 5| Step: 3
Training loss: 3.063481543369397
Validation loss: 2.9915635899929782

Epoch: 5| Step: 4
Training loss: 4.012687113074185
Validation loss: 2.9933302280249956

Epoch: 5| Step: 5
Training loss: 3.3277007356392674
Validation loss: 2.9955514017822646

Epoch: 5| Step: 6
Training loss: 2.828663642970991
Validation loss: 2.9962506775440683

Epoch: 5| Step: 7
Training loss: 3.045532713395444
Validation loss: 2.995826703407593

Epoch: 5| Step: 8
Training loss: 3.4430138495191907
Validation loss: 2.993535120916621

Epoch: 5| Step: 9
Training loss: 3.445430554640181
Validation loss: 2.9926744877259166

Epoch: 5| Step: 10
Training loss: 2.696623198776199
Validation loss: 2.9865973737181837

Epoch: 51| Step: 0
Training loss: 3.610639210376374
Validation loss: 2.9871673131354024

Epoch: 5| Step: 1
Training loss: 3.2547837776525217
Validation loss: 2.9883495584930295

Epoch: 5| Step: 2
Training loss: 4.227893330725269
Validation loss: 2.9868864575455056

Epoch: 5| Step: 3
Training loss: 3.437586280433526
Validation loss: 2.983575134861129

Epoch: 5| Step: 4
Training loss: 3.4904230426500735
Validation loss: 2.984187184622667

Epoch: 5| Step: 5
Training loss: 3.1750637618743616
Validation loss: 2.9841788481471254

Epoch: 5| Step: 6
Training loss: 2.9649568116514775
Validation loss: 2.985242861218817

Epoch: 5| Step: 7
Training loss: 2.5339961284978205
Validation loss: 2.983986913772476

Epoch: 5| Step: 8
Training loss: 2.856021102314413
Validation loss: 2.983069598823715

Epoch: 5| Step: 9
Training loss: 2.9476037460330264
Validation loss: 2.983739777463328

Epoch: 5| Step: 10
Training loss: 3.1460439514659777
Validation loss: 2.984062181436161

Epoch: 52| Step: 0
Training loss: 3.1994050545760957
Validation loss: 2.983379252658935

Epoch: 5| Step: 1
Training loss: 2.792289341807468
Validation loss: 2.983924409498062

Epoch: 5| Step: 2
Training loss: 3.0632567735748255
Validation loss: 2.9848391118276223

Epoch: 5| Step: 3
Training loss: 3.355088733119363
Validation loss: 2.988051374240953

Epoch: 5| Step: 4
Training loss: 3.5941222951691327
Validation loss: 2.985251222203646

Epoch: 5| Step: 5
Training loss: 2.870035778447347
Validation loss: 2.9815704580729814

Epoch: 5| Step: 6
Training loss: 3.671812276101568
Validation loss: 2.9806343322595015

Epoch: 5| Step: 7
Training loss: 2.943978166748025
Validation loss: 2.979675785285176

Epoch: 5| Step: 8
Training loss: 3.3859552669015
Validation loss: 2.9803899801564375

Epoch: 5| Step: 9
Training loss: 3.302674025080644
Validation loss: 2.978882934795427

Epoch: 5| Step: 10
Training loss: 3.6194296822808405
Validation loss: 2.9775402179525376

Epoch: 53| Step: 0
Training loss: 3.035245169928971
Validation loss: 2.97844684652544

Epoch: 5| Step: 1
Training loss: 3.5958171704143793
Validation loss: 2.9793544787247255

Epoch: 5| Step: 2
Training loss: 3.319900594854731
Validation loss: 2.978488688072272

Epoch: 5| Step: 3
Training loss: 3.4283500270656515
Validation loss: 2.9792849047329986

Epoch: 5| Step: 4
Training loss: 3.425041927999879
Validation loss: 2.9797615342557173

Epoch: 5| Step: 5
Training loss: 2.718403673585337
Validation loss: 2.9793657052359017

Epoch: 5| Step: 6
Training loss: 3.123747612813745
Validation loss: 2.981110875025668

Epoch: 5| Step: 7
Training loss: 2.7536972507683486
Validation loss: 2.9772145718138745

Epoch: 5| Step: 8
Training loss: 3.375517628852694
Validation loss: 2.984237467577524

Epoch: 5| Step: 9
Training loss: 3.9061207253999366
Validation loss: 2.980577206516192

Epoch: 5| Step: 10
Training loss: 2.917686683677061
Validation loss: 2.9894918009216807

Epoch: 54| Step: 0
Training loss: 3.9706715415077523
Validation loss: 2.9896929532403185

Epoch: 5| Step: 1
Training loss: 3.5164583701928445
Validation loss: 2.9749936933856485

Epoch: 5| Step: 2
Training loss: 3.3969451082885613
Validation loss: 2.9797697282267985

Epoch: 5| Step: 3
Training loss: 3.0121230906630734
Validation loss: 2.9776479089822256

Epoch: 5| Step: 4
Training loss: 2.722091375393863
Validation loss: 2.9825796147159456

Epoch: 5| Step: 5
Training loss: 3.10176650752827
Validation loss: 2.9805254279738387

Epoch: 5| Step: 6
Training loss: 3.2524507525598523
Validation loss: 2.97298582830036

Epoch: 5| Step: 7
Training loss: 3.4635077376843006
Validation loss: 2.9726749270975708

Epoch: 5| Step: 8
Training loss: 2.299200632255324
Validation loss: 2.9756190599228622

Epoch: 5| Step: 9
Training loss: 3.473245817413261
Validation loss: 2.973794426210415

Epoch: 5| Step: 10
Training loss: 3.375497993180463
Validation loss: 2.9733886799580773

Epoch: 55| Step: 0
Training loss: 3.773282823887307
Validation loss: 2.977148864126368

Epoch: 5| Step: 1
Training loss: 3.3802205434773613
Validation loss: 2.9775210797434757

Epoch: 5| Step: 2
Training loss: 3.364097363282031
Validation loss: 2.986498168893439

Epoch: 5| Step: 3
Training loss: 3.2414588201291057
Validation loss: 2.991866255236975

Epoch: 5| Step: 4
Training loss: 3.353746533983894
Validation loss: 2.975443211782326

Epoch: 5| Step: 5
Training loss: 2.78774138290747
Validation loss: 2.970561943354361

Epoch: 5| Step: 6
Training loss: 2.5669764055238438
Validation loss: 2.967555141438936

Epoch: 5| Step: 7
Training loss: 3.762088492058968
Validation loss: 2.9671339881666965

Epoch: 5| Step: 8
Training loss: 3.2148255061469735
Validation loss: 2.9679820908541044

Epoch: 5| Step: 9
Training loss: 2.8996765285168857
Validation loss: 2.9667945609109037

Epoch: 5| Step: 10
Training loss: 3.2789733254527644
Validation loss: 2.964652794870999

Epoch: 56| Step: 0
Training loss: 3.1573446660557978
Validation loss: 2.9693995284966475

Epoch: 5| Step: 1
Training loss: 3.0685826832828
Validation loss: 2.976765966821154

Epoch: 5| Step: 2
Training loss: 3.873718049667569
Validation loss: 2.9706649174273716

Epoch: 5| Step: 3
Training loss: 3.36051417708106
Validation loss: 2.973259808338381

Epoch: 5| Step: 4
Training loss: 3.0468551243842916
Validation loss: 2.973472719496543

Epoch: 5| Step: 5
Training loss: 2.636757631368418
Validation loss: 2.966845529212637

Epoch: 5| Step: 6
Training loss: 3.269467516133215
Validation loss: 2.967018266565809

Epoch: 5| Step: 7
Training loss: 2.3714632503678943
Validation loss: 2.9645446179402577

Epoch: 5| Step: 8
Training loss: 3.5729985056291342
Validation loss: 2.96619917516137

Epoch: 5| Step: 9
Training loss: 3.3346161916889363
Validation loss: 2.9659020831520775

Epoch: 5| Step: 10
Training loss: 3.8191817468795906
Validation loss: 2.964037944786632

Epoch: 57| Step: 0
Training loss: 2.6862324231523727
Validation loss: 2.9620557177831333

Epoch: 5| Step: 1
Training loss: 2.5326082329625956
Validation loss: 2.9659104174084305

Epoch: 5| Step: 2
Training loss: 3.4541912935404437
Validation loss: 2.966051639818429

Epoch: 5| Step: 3
Training loss: 3.583063307649751
Validation loss: 2.964543281010028

Epoch: 5| Step: 4
Training loss: 3.2122440696327272
Validation loss: 2.9648030648047605

Epoch: 5| Step: 5
Training loss: 3.265644420219244
Validation loss: 2.962804285652116

Epoch: 5| Step: 6
Training loss: 3.2047772867838638
Validation loss: 2.963590399695771

Epoch: 5| Step: 7
Training loss: 3.5444771479815578
Validation loss: 2.963746020761347

Epoch: 5| Step: 8
Training loss: 3.4195002149394145
Validation loss: 2.9629137859171593

Epoch: 5| Step: 9
Training loss: 3.112328588216198
Validation loss: 2.963874217925135

Epoch: 5| Step: 10
Training loss: 3.5975510108623667
Validation loss: 2.9624083699042276

Epoch: 58| Step: 0
Training loss: 2.937857098889613
Validation loss: 2.9604702386376758

Epoch: 5| Step: 1
Training loss: 3.386898260408036
Validation loss: 2.959399601526695

Epoch: 5| Step: 2
Training loss: 2.9607877265673728
Validation loss: 2.961484397014098

Epoch: 5| Step: 3
Training loss: 4.13665696513114
Validation loss: 2.958720139608497

Epoch: 5| Step: 4
Training loss: 3.2220382930248905
Validation loss: 2.960375757731377

Epoch: 5| Step: 5
Training loss: 3.095536766034777
Validation loss: 2.968198131481679

Epoch: 5| Step: 6
Training loss: 3.58257779576658
Validation loss: 2.9828050544284137

Epoch: 5| Step: 7
Training loss: 3.4539382460241863
Validation loss: 2.9822573117945397

Epoch: 5| Step: 8
Training loss: 2.7192485834475564
Validation loss: 2.9671538798260984

Epoch: 5| Step: 9
Training loss: 2.8929335165286267
Validation loss: 2.964853491467135

Epoch: 5| Step: 10
Training loss: 3.051815155711254
Validation loss: 2.9575914856361023

Epoch: 59| Step: 0
Training loss: 2.5502688023128646
Validation loss: 2.956340231627656

Epoch: 5| Step: 1
Training loss: 3.4920277398964137
Validation loss: 2.9570197505626816

Epoch: 5| Step: 2
Training loss: 3.9703913621152482
Validation loss: 2.9545039954741332

Epoch: 5| Step: 3
Training loss: 2.6274164975270007
Validation loss: 2.956045045390471

Epoch: 5| Step: 4
Training loss: 3.3830060308832848
Validation loss: 2.9572170744989075

Epoch: 5| Step: 5
Training loss: 3.545722135480463
Validation loss: 2.9569149010970865

Epoch: 5| Step: 6
Training loss: 3.179590922020706
Validation loss: 2.957915253295878

Epoch: 5| Step: 7
Training loss: 3.1530145359254727
Validation loss: 2.9528181953310964

Epoch: 5| Step: 8
Training loss: 3.6223766437006693
Validation loss: 2.9522597050119943

Epoch: 5| Step: 9
Training loss: 2.9015558541611592
Validation loss: 2.9514062440294766

Epoch: 5| Step: 10
Training loss: 2.8828966908967275
Validation loss: 2.952159431401797

Epoch: 60| Step: 0
Training loss: 3.0225514929891593
Validation loss: 2.950665394758998

Epoch: 5| Step: 1
Training loss: 3.3200601638949743
Validation loss: 2.9494659244189187

Epoch: 5| Step: 2
Training loss: 2.6208780714460875
Validation loss: 2.9500969161557005

Epoch: 5| Step: 3
Training loss: 2.7432909535888608
Validation loss: 2.9528117272242267

Epoch: 5| Step: 4
Training loss: 3.328192481847771
Validation loss: 2.9538817448818717

Epoch: 5| Step: 5
Training loss: 3.4049750225478608
Validation loss: 2.9547099625929727

Epoch: 5| Step: 6
Training loss: 2.656532452095563
Validation loss: 2.9550957454985127

Epoch: 5| Step: 7
Training loss: 3.397979775658786
Validation loss: 2.95937965471445

Epoch: 5| Step: 8
Training loss: 3.5563936603404254
Validation loss: 2.9572211793142387

Epoch: 5| Step: 9
Training loss: 3.668853035670831
Validation loss: 2.9499672885983985

Epoch: 5| Step: 10
Training loss: 3.687015436953909
Validation loss: 2.9519572864285433

Epoch: 61| Step: 0
Training loss: 2.9254471265949977
Validation loss: 2.9473157097878446

Epoch: 5| Step: 1
Training loss: 3.0618029988488424
Validation loss: 2.947091162721826

Epoch: 5| Step: 2
Training loss: 3.6428260534760355
Validation loss: 2.946470873921056

Epoch: 5| Step: 3
Training loss: 2.8605637710949527
Validation loss: 2.945399515722693

Epoch: 5| Step: 4
Training loss: 3.031307573853205
Validation loss: 2.9444214949665097

Epoch: 5| Step: 5
Training loss: 3.270208473209614
Validation loss: 2.943777097210629

Epoch: 5| Step: 6
Training loss: 3.8028104879308278
Validation loss: 2.9433345464150826

Epoch: 5| Step: 7
Training loss: 3.5448523312307287
Validation loss: 2.942379578305174

Epoch: 5| Step: 8
Training loss: 2.95422794796791
Validation loss: 2.9453974468094954

Epoch: 5| Step: 9
Training loss: 2.882788350487433
Validation loss: 2.9420636451589286

Epoch: 5| Step: 10
Training loss: 3.4271917973353427
Validation loss: 2.94260993260851

Epoch: 62| Step: 0
Training loss: 2.7372433685827238
Validation loss: 2.94384659163946

Epoch: 5| Step: 1
Training loss: 3.5947516330880034
Validation loss: 2.94435915817317

Epoch: 5| Step: 2
Training loss: 3.1968084811303377
Validation loss: 2.941022913885535

Epoch: 5| Step: 3
Training loss: 3.4150123933313106
Validation loss: 2.9405355746353883

Epoch: 5| Step: 4
Training loss: 3.2910732909450786
Validation loss: 2.940810109109618

Epoch: 5| Step: 5
Training loss: 3.5272623688528735
Validation loss: 2.9400482932480045

Epoch: 5| Step: 6
Training loss: 2.994781724111666
Validation loss: 2.93887292479586

Epoch: 5| Step: 7
Training loss: 3.324371226811155
Validation loss: 2.9397523789203057

Epoch: 5| Step: 8
Training loss: 3.1795070887566226
Validation loss: 2.938332536791845

Epoch: 5| Step: 9
Training loss: 3.0014852979542392
Validation loss: 2.9381117051831898

Epoch: 5| Step: 10
Training loss: 3.1284895677799547
Validation loss: 2.9386528334498143

Epoch: 63| Step: 0
Training loss: 3.75742342832188
Validation loss: 2.938293517417312

Epoch: 5| Step: 1
Training loss: 3.632198421301361
Validation loss: 2.940671576625746

Epoch: 5| Step: 2
Training loss: 3.6790579158022436
Validation loss: 2.9376326587528676

Epoch: 5| Step: 3
Training loss: 2.263980663392218
Validation loss: 2.939349197906913

Epoch: 5| Step: 4
Training loss: 3.1255082289362077
Validation loss: 2.9397168073752535

Epoch: 5| Step: 5
Training loss: 3.373683531404266
Validation loss: 2.940074301450386

Epoch: 5| Step: 6
Training loss: 3.0439404563143007
Validation loss: 2.9426367144518215

Epoch: 5| Step: 7
Training loss: 3.6711871862444325
Validation loss: 2.9479264182684575

Epoch: 5| Step: 8
Training loss: 2.889320862906736
Validation loss: 2.9438309877575257

Epoch: 5| Step: 9
Training loss: 3.0614821630491282
Validation loss: 2.946967901296753

Epoch: 5| Step: 10
Training loss: 2.4770069385380564
Validation loss: 2.9372564898647475

Epoch: 64| Step: 0
Training loss: 2.943590384203547
Validation loss: 2.935619035667552

Epoch: 5| Step: 1
Training loss: 3.394314073083603
Validation loss: 2.9328837553829916

Epoch: 5| Step: 2
Training loss: 3.100402461352926
Validation loss: 2.932267833145046

Epoch: 5| Step: 3
Training loss: 2.6908586495883076
Validation loss: 2.932885353241685

Epoch: 5| Step: 4
Training loss: 3.197789656677639
Validation loss: 2.9334820235533074

Epoch: 5| Step: 5
Training loss: 2.360357219040595
Validation loss: 2.933222073799344

Epoch: 5| Step: 6
Training loss: 3.146607124875209
Validation loss: 2.9364084246029973

Epoch: 5| Step: 7
Training loss: 3.45308108754955
Validation loss: 2.9349869761442067

Epoch: 5| Step: 8
Training loss: 3.280506304066942
Validation loss: 2.9328266497193463

Epoch: 5| Step: 9
Training loss: 4.101715956950689
Validation loss: 2.933139088800408

Epoch: 5| Step: 10
Training loss: 3.543479739585928
Validation loss: 2.9316739334881707

Epoch: 65| Step: 0
Training loss: 3.531461321153776
Validation loss: 2.9330901988591678

Epoch: 5| Step: 1
Training loss: 3.13715364284582
Validation loss: 2.9304756496836575

Epoch: 5| Step: 2
Training loss: 2.9188853589840766
Validation loss: 2.9309645146792707

Epoch: 5| Step: 3
Training loss: 2.555008521019151
Validation loss: 2.9302304271931576

Epoch: 5| Step: 4
Training loss: 3.505665009192585
Validation loss: 2.928778342005267

Epoch: 5| Step: 5
Training loss: 3.4202576041663035
Validation loss: 2.9303748388659896

Epoch: 5| Step: 6
Training loss: 2.8261446262778054
Validation loss: 2.9294048511517228

Epoch: 5| Step: 7
Training loss: 3.1819319617995423
Validation loss: 2.9290953912743762

Epoch: 5| Step: 8
Training loss: 2.955813198603569
Validation loss: 2.9300075885008483

Epoch: 5| Step: 9
Training loss: 3.68469467782263
Validation loss: 2.9291832475851245

Epoch: 5| Step: 10
Training loss: 3.539437179436891
Validation loss: 2.9282020886408344

Epoch: 66| Step: 0
Training loss: 3.4211911428264856
Validation loss: 2.9302979682214425

Epoch: 5| Step: 1
Training loss: 3.8510904080841564
Validation loss: 2.928830740399753

Epoch: 5| Step: 2
Training loss: 3.2645012048949
Validation loss: 2.927828735922839

Epoch: 5| Step: 3
Training loss: 3.1600181822917652
Validation loss: 2.9275181610510046

Epoch: 5| Step: 4
Training loss: 3.585271902374022
Validation loss: 2.9276517852438877

Epoch: 5| Step: 5
Training loss: 2.7216285287396786
Validation loss: 2.926029049758649

Epoch: 5| Step: 6
Training loss: 2.5465959267336458
Validation loss: 2.927109516581241

Epoch: 5| Step: 7
Training loss: 3.281277756346517
Validation loss: 2.924677102428453

Epoch: 5| Step: 8
Training loss: 2.964694817261478
Validation loss: 2.923686104696185

Epoch: 5| Step: 9
Training loss: 2.92951952643462
Validation loss: 2.9242836569970625

Epoch: 5| Step: 10
Training loss: 3.4497180547085904
Validation loss: 2.921979206432099

Epoch: 67| Step: 0
Training loss: 3.5169969382534414
Validation loss: 2.9216888194693333

Epoch: 5| Step: 1
Training loss: 2.707482854871629
Validation loss: 2.922376620231149

Epoch: 5| Step: 2
Training loss: 3.858135317725755
Validation loss: 2.922544374510028

Epoch: 5| Step: 3
Training loss: 3.001230305484339
Validation loss: 2.921448166692158

Epoch: 5| Step: 4
Training loss: 3.8300931892312753
Validation loss: 2.921905973659732

Epoch: 5| Step: 5
Training loss: 2.4938939868020107
Validation loss: 2.928118408040212

Epoch: 5| Step: 6
Training loss: 3.1633284859440938
Validation loss: 2.927706984860077

Epoch: 5| Step: 7
Training loss: 3.1019598948913187
Validation loss: 2.934260391774927

Epoch: 5| Step: 8
Training loss: 2.9582639515938745
Validation loss: 2.9273571023152916

Epoch: 5| Step: 9
Training loss: 3.6408243411258625
Validation loss: 2.922545027142863

Epoch: 5| Step: 10
Training loss: 2.5771027358940386
Validation loss: 2.9254059828760957

Epoch: 68| Step: 0
Training loss: 3.554017794056292
Validation loss: 2.925104409356105

Epoch: 5| Step: 1
Training loss: 2.6903311432724086
Validation loss: 2.9303905738893943

Epoch: 5| Step: 2
Training loss: 3.853614863854573
Validation loss: 2.9247937012169802

Epoch: 5| Step: 3
Training loss: 3.12034229308276
Validation loss: 2.917790542390218

Epoch: 5| Step: 4
Training loss: 2.7136131077085466
Validation loss: 2.917078854548038

Epoch: 5| Step: 5
Training loss: 3.3285976307139955
Validation loss: 2.915920458029622

Epoch: 5| Step: 6
Training loss: 3.1374307206852565
Validation loss: 2.9161444734172175

Epoch: 5| Step: 7
Training loss: 3.079816943834769
Validation loss: 2.916000128906797

Epoch: 5| Step: 8
Training loss: 2.9695110750905527
Validation loss: 2.9164013426968056

Epoch: 5| Step: 9
Training loss: 3.7557732963517467
Validation loss: 2.9171000502932682

Epoch: 5| Step: 10
Training loss: 2.7194632986642753
Validation loss: 2.91477495775462

Epoch: 69| Step: 0
Training loss: 3.298101115817071
Validation loss: 2.9152364279981486

Epoch: 5| Step: 1
Training loss: 3.7059210028177847
Validation loss: 2.9141018746149037

Epoch: 5| Step: 2
Training loss: 2.947443911833323
Validation loss: 2.913077534838144

Epoch: 5| Step: 3
Training loss: 2.596122116590529
Validation loss: 2.912709511784928

Epoch: 5| Step: 4
Training loss: 3.5006421726202666
Validation loss: 2.913872957409108

Epoch: 5| Step: 5
Training loss: 3.0897227575868356
Validation loss: 2.914033927404609

Epoch: 5| Step: 6
Training loss: 2.959542703358154
Validation loss: 2.9137792478483893

Epoch: 5| Step: 7
Training loss: 3.415072712829279
Validation loss: 2.9125443439469434

Epoch: 5| Step: 8
Training loss: 2.2809307972445914
Validation loss: 2.914056179883566

Epoch: 5| Step: 9
Training loss: 3.162080120212881
Validation loss: 2.911998260135124

Epoch: 5| Step: 10
Training loss: 4.04780503120873
Validation loss: 2.9106693722532038

Epoch: 70| Step: 0
Training loss: 2.9537875930776627
Validation loss: 2.909707953057274

Epoch: 5| Step: 1
Training loss: 3.31784217041523
Validation loss: 2.914281675691496

Epoch: 5| Step: 2
Training loss: 4.0125509288562355
Validation loss: 2.9182490426301033

Epoch: 5| Step: 3
Training loss: 2.8784772328107042
Validation loss: 2.9147188711574494

Epoch: 5| Step: 4
Training loss: 3.170460653439005
Validation loss: 2.9125498795607334

Epoch: 5| Step: 5
Training loss: 2.7045116065452084
Validation loss: 2.9112179878726456

Epoch: 5| Step: 6
Training loss: 3.560945138090344
Validation loss: 2.9082688116387994

Epoch: 5| Step: 7
Training loss: 3.554434631072827
Validation loss: 2.9064788304857627

Epoch: 5| Step: 8
Training loss: 3.205118889232693
Validation loss: 2.905154475686338

Epoch: 5| Step: 9
Training loss: 2.6613275803151506
Validation loss: 2.9065009961533175

Epoch: 5| Step: 10
Training loss: 2.8518860515820923
Validation loss: 2.907028914668366

Epoch: 71| Step: 0
Training loss: 2.9066860733200977
Validation loss: 2.9093355419909672

Epoch: 5| Step: 1
Training loss: 3.2894188332250995
Validation loss: 2.9091208246277462

Epoch: 5| Step: 2
Training loss: 3.3913656383895723
Validation loss: 2.9056915318233014

Epoch: 5| Step: 3
Training loss: 2.6717612259047945
Validation loss: 2.904805999982745

Epoch: 5| Step: 4
Training loss: 3.0147994893016286
Validation loss: 2.9077709592054846

Epoch: 5| Step: 5
Training loss: 3.1932726180397686
Validation loss: 2.9089376200189023

Epoch: 5| Step: 6
Training loss: 3.8921589106455783
Validation loss: 2.9065527588999474

Epoch: 5| Step: 7
Training loss: 3.0098988616782023
Validation loss: 2.911221150132758

Epoch: 5| Step: 8
Training loss: 3.911682379850455
Validation loss: 2.9101962298008814

Epoch: 5| Step: 9
Training loss: 2.6181228105140213
Validation loss: 2.907506956956363

Epoch: 5| Step: 10
Training loss: 3.037737010610017
Validation loss: 2.904939527824863

Epoch: 72| Step: 0
Training loss: 3.4857045190258913
Validation loss: 2.903351769312561

Epoch: 5| Step: 1
Training loss: 2.426554730090335
Validation loss: 2.902319578391064

Epoch: 5| Step: 2
Training loss: 2.812961370984696
Validation loss: 2.903180042314055

Epoch: 5| Step: 3
Training loss: 3.6990946151706994
Validation loss: 2.9070318147179606

Epoch: 5| Step: 4
Training loss: 3.531594453739154
Validation loss: 2.9083101114105876

Epoch: 5| Step: 5
Training loss: 2.7254334656217543
Validation loss: 2.9150821008664094

Epoch: 5| Step: 6
Training loss: 3.3265663759738455
Validation loss: 2.912906202551129

Epoch: 5| Step: 7
Training loss: 3.1659086892990915
Validation loss: 2.919683975919849

Epoch: 5| Step: 8
Training loss: 3.0778825538541628
Validation loss: 2.923982022958778

Epoch: 5| Step: 9
Training loss: 3.4539918113660026
Validation loss: 2.9263903061978995

Epoch: 5| Step: 10
Training loss: 3.2769664597248505
Validation loss: 2.9247839227417574

Epoch: 73| Step: 0
Training loss: 3.145758689011633
Validation loss: 2.9043247524909925

Epoch: 5| Step: 1
Training loss: 2.6604482347671206
Validation loss: 2.900680733099393

Epoch: 5| Step: 2
Training loss: 3.054955200016669
Validation loss: 2.8994596776405643

Epoch: 5| Step: 3
Training loss: 3.812439714799369
Validation loss: 2.9017626375608

Epoch: 5| Step: 4
Training loss: 3.4099088843469616
Validation loss: 2.899820439031091

Epoch: 5| Step: 5
Training loss: 3.328910913936389
Validation loss: 2.9023179257222704

Epoch: 5| Step: 6
Training loss: 3.5435253576698473
Validation loss: 2.9032217694554125

Epoch: 5| Step: 7
Training loss: 3.3670144445994885
Validation loss: 2.901302586971572

Epoch: 5| Step: 8
Training loss: 2.5263796445866054
Validation loss: 2.9004339514392035

Epoch: 5| Step: 9
Training loss: 2.7235697851482996
Validation loss: 2.899716601528954

Epoch: 5| Step: 10
Training loss: 3.3453398160429453
Validation loss: 2.9009442492643207

Epoch: 74| Step: 0
Training loss: 3.4181722874665343
Validation loss: 2.899095840897928

Epoch: 5| Step: 1
Training loss: 2.873455627948442
Validation loss: 2.8992406450281907

Epoch: 5| Step: 2
Training loss: 3.1972272960343817
Validation loss: 2.897053846828856

Epoch: 5| Step: 3
Training loss: 3.32604557319473
Validation loss: 2.8963834662447576

Epoch: 5| Step: 4
Training loss: 2.4217279204961577
Validation loss: 2.8961240159682546

Epoch: 5| Step: 5
Training loss: 3.4208460266645986
Validation loss: 2.8947104467114992

Epoch: 5| Step: 6
Training loss: 3.404929648861528
Validation loss: 2.8943408393447587

Epoch: 5| Step: 7
Training loss: 3.198665137825532
Validation loss: 2.8927535424121023

Epoch: 5| Step: 8
Training loss: 3.2331508217913676
Validation loss: 2.894822181757768

Epoch: 5| Step: 9
Training loss: 2.950367603997553
Validation loss: 2.8962412074993686

Epoch: 5| Step: 10
Training loss: 3.4944598082538403
Validation loss: 2.9005582154802005

Epoch: 75| Step: 0
Training loss: 2.9708718196164754
Validation loss: 2.9139762552685102

Epoch: 5| Step: 1
Training loss: 2.7960445087421166
Validation loss: 2.9342470775481497

Epoch: 5| Step: 2
Training loss: 3.2761226739050993
Validation loss: 2.9783060362619245

Epoch: 5| Step: 3
Training loss: 3.1478973758358046
Validation loss: 2.9637718633919805

Epoch: 5| Step: 4
Training loss: 3.1177494622876174
Validation loss: 2.9070927278780823

Epoch: 5| Step: 5
Training loss: 3.5882806706111414
Validation loss: 2.892952023314032

Epoch: 5| Step: 6
Training loss: 3.310536360372314
Validation loss: 2.888741537847695

Epoch: 5| Step: 7
Training loss: 3.3330823485933982
Validation loss: 2.8928159898293786

Epoch: 5| Step: 8
Training loss: 3.191497838773359
Validation loss: 2.8911282399249503

Epoch: 5| Step: 9
Training loss: 2.939185450333169
Validation loss: 2.903838295915217

Epoch: 5| Step: 10
Training loss: 3.508980673344577
Validation loss: 2.911368559069391

Testing loss: 3.1290788522209225
