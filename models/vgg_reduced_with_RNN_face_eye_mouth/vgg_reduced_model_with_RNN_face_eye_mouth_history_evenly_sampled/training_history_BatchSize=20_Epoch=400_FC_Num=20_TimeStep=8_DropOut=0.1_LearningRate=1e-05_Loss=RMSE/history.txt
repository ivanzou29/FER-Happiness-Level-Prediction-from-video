Epoch: 1| Step: 0
Training loss: 5.776765971151092
Validation loss: 5.834607945194192

Epoch: 5| Step: 1
Training loss: 6.365041996172304
Validation loss: 5.825202298567396

Epoch: 5| Step: 2
Training loss: 4.40231992077069
Validation loss: 5.816230704887204

Epoch: 5| Step: 3
Training loss: 5.777600265286571
Validation loss: 5.807687475539829

Epoch: 5| Step: 4
Training loss: 5.43189555766357
Validation loss: 5.798957399599618

Epoch: 5| Step: 5
Training loss: 6.546735739307952
Validation loss: 5.79016311308919

Epoch: 5| Step: 6
Training loss: 6.0477474086027865
Validation loss: 5.781091313510948

Epoch: 5| Step: 7
Training loss: 5.970421042874549
Validation loss: 5.77073696303746

Epoch: 5| Step: 8
Training loss: 6.165524694880688
Validation loss: 5.759846724227778

Epoch: 5| Step: 9
Training loss: 6.033044735801292
Validation loss: 5.748172432123159

Epoch: 5| Step: 10
Training loss: 5.109515546912986
Validation loss: 5.735726587650078

Epoch: 2| Step: 0
Training loss: 6.623949363459667
Validation loss: 5.7221649515644675

Epoch: 5| Step: 1
Training loss: 5.886187999671813
Validation loss: 5.707398352037531

Epoch: 5| Step: 2
Training loss: 4.401221903283605
Validation loss: 5.691418912772996

Epoch: 5| Step: 3
Training loss: 5.883574701100321
Validation loss: 5.675367820665885

Epoch: 5| Step: 4
Training loss: 5.473858872032392
Validation loss: 5.657287056597142

Epoch: 5| Step: 5
Training loss: 6.875446651861801
Validation loss: 5.638302528043277

Epoch: 5| Step: 6
Training loss: 4.562318772152528
Validation loss: 5.616925857029578

Epoch: 5| Step: 7
Training loss: 5.268420646030044
Validation loss: 5.595341802252406

Epoch: 5| Step: 8
Training loss: 5.6711573291225275
Validation loss: 5.572088737580533

Epoch: 5| Step: 9
Training loss: 5.835498553292471
Validation loss: 5.548497475191278

Epoch: 5| Step: 10
Training loss: 5.3865123153201555
Validation loss: 5.522634286855258

Epoch: 3| Step: 0
Training loss: 5.386747961815735
Validation loss: 5.4970214642908175

Epoch: 5| Step: 1
Training loss: 4.937622841381312
Validation loss: 5.468627043248606

Epoch: 5| Step: 2
Training loss: 5.946701789775041
Validation loss: 5.440759425186477

Epoch: 5| Step: 3
Training loss: 5.866237517757535
Validation loss: 5.41025050882161

Epoch: 5| Step: 4
Training loss: 5.645622427779411
Validation loss: 5.379245475066625

Epoch: 5| Step: 5
Training loss: 5.770626390329526
Validation loss: 5.346827096683087

Epoch: 5| Step: 6
Training loss: 5.2584920956946775
Validation loss: 5.313696791246217

Epoch: 5| Step: 7
Training loss: 5.274367322539849
Validation loss: 5.280638457723807

Epoch: 5| Step: 8
Training loss: 3.952024163322865
Validation loss: 5.246209394901848

Epoch: 5| Step: 9
Training loss: 5.429266824137552
Validation loss: 5.2126660871541235

Epoch: 5| Step: 10
Training loss: 5.607018105782629
Validation loss: 5.177422403349944

Epoch: 4| Step: 0
Training loss: 5.128810117565857
Validation loss: 5.141578785065869

Epoch: 5| Step: 1
Training loss: 5.72928503665597
Validation loss: 5.1024475993194915

Epoch: 5| Step: 2
Training loss: 4.5284796302777846
Validation loss: 5.0642485359461675

Epoch: 5| Step: 3
Training loss: 5.558209425399655
Validation loss: 5.024852433678325

Epoch: 5| Step: 4
Training loss: 4.283158148561169
Validation loss: 4.983414575337969

Epoch: 5| Step: 5
Training loss: 5.222531165234975
Validation loss: 4.943140258333185

Epoch: 5| Step: 6
Training loss: 4.863629897768816
Validation loss: 4.9055542017146525

Epoch: 5| Step: 7
Training loss: 4.94066798307866
Validation loss: 4.86830797645403

Epoch: 5| Step: 8
Training loss: 4.856176372347959
Validation loss: 4.833850800363423

Epoch: 5| Step: 9
Training loss: 5.789032847216566
Validation loss: 4.801350239070171

Epoch: 5| Step: 10
Training loss: 3.9007307199467296
Validation loss: 4.770378869598298

Epoch: 5| Step: 0
Training loss: 4.760742688301256
Validation loss: 4.741056317719732

Epoch: 5| Step: 1
Training loss: 4.206716371616416
Validation loss: 4.7119284620006034

Epoch: 5| Step: 2
Training loss: 4.871644258938098
Validation loss: 4.687035451313606

Epoch: 5| Step: 3
Training loss: 4.535277372413573
Validation loss: 4.662441716903027

Epoch: 5| Step: 4
Training loss: 4.964797649274559
Validation loss: 4.636003555507489

Epoch: 5| Step: 5
Training loss: 4.860605752501431
Validation loss: 4.610787706778973

Epoch: 5| Step: 6
Training loss: 5.052940290728265
Validation loss: 4.584299672896134

Epoch: 5| Step: 7
Training loss: 4.640528822393504
Validation loss: 4.5417895082672874

Epoch: 5| Step: 8
Training loss: 4.188556822463423
Validation loss: 4.5152793684158645

Epoch: 5| Step: 9
Training loss: 4.970480563534144
Validation loss: 4.497355684576367

Epoch: 5| Step: 10
Training loss: 4.564208246533522
Validation loss: 4.479955345750164

Epoch: 6| Step: 0
Training loss: 5.131108435142777
Validation loss: 4.465414883884022

Epoch: 5| Step: 1
Training loss: 4.550303421802633
Validation loss: 4.448446092967889

Epoch: 5| Step: 2
Training loss: 4.570136590164323
Validation loss: 4.429481250517296

Epoch: 5| Step: 3
Training loss: 4.667724807302696
Validation loss: 4.411397937783957

Epoch: 5| Step: 4
Training loss: 4.835824302618016
Validation loss: 4.393624862190963

Epoch: 5| Step: 5
Training loss: 4.977846084894295
Validation loss: 4.379341523843474

Epoch: 5| Step: 6
Training loss: 4.022715679714307
Validation loss: 4.360529288337782

Epoch: 5| Step: 7
Training loss: 4.656496387081737
Validation loss: 4.343833912496093

Epoch: 5| Step: 8
Training loss: 3.8922990621399767
Validation loss: 4.324675680577938

Epoch: 5| Step: 9
Training loss: 4.323749851073511
Validation loss: 4.30972877027218

Epoch: 5| Step: 10
Training loss: 3.5199177621858255
Validation loss: 4.291085459636281

Epoch: 7| Step: 0
Training loss: 4.605938577670615
Validation loss: 4.274472369980693

Epoch: 5| Step: 1
Training loss: 4.981475465044256
Validation loss: 4.25775875717314

Epoch: 5| Step: 2
Training loss: 3.7720121926022636
Validation loss: 4.239385419990375

Epoch: 5| Step: 3
Training loss: 4.0534477911231725
Validation loss: 4.217496695961391

Epoch: 5| Step: 4
Training loss: 5.798828782839302
Validation loss: 4.196622041801255

Epoch: 5| Step: 5
Training loss: 3.7239365512593223
Validation loss: 4.179411428705324

Epoch: 5| Step: 6
Training loss: 3.897948821176621
Validation loss: 4.155714045043005

Epoch: 5| Step: 7
Training loss: 4.397796096245299
Validation loss: 4.129698994505124

Epoch: 5| Step: 8
Training loss: 4.093205073539298
Validation loss: 4.105843087886887

Epoch: 5| Step: 9
Training loss: 4.318217813077145
Validation loss: 4.0881818953889155

Epoch: 5| Step: 10
Training loss: 3.067986381291647
Validation loss: 4.0706233160871825

Epoch: 8| Step: 0
Training loss: 4.0591221778377475
Validation loss: 4.056737551566851

Epoch: 5| Step: 1
Training loss: 3.6299012034609435
Validation loss: 4.043818129636482

Epoch: 5| Step: 2
Training loss: 3.3957910515584917
Validation loss: 4.032654742879259

Epoch: 5| Step: 3
Training loss: 4.659714606718361
Validation loss: 4.019878123305223

Epoch: 5| Step: 4
Training loss: 3.863091289605853
Validation loss: 4.006686216310123

Epoch: 5| Step: 5
Training loss: 4.065620280445594
Validation loss: 3.9960921281949955

Epoch: 5| Step: 6
Training loss: 4.581868070410631
Validation loss: 3.992879179557199

Epoch: 5| Step: 7
Training loss: 3.2438961811974205
Validation loss: 3.978894575794237

Epoch: 5| Step: 8
Training loss: 3.4617976719239225
Validation loss: 3.9633991090283884

Epoch: 5| Step: 9
Training loss: 5.34329596481218
Validation loss: 3.9429852454560197

Epoch: 5| Step: 10
Training loss: 4.816987954658208
Validation loss: 3.927875450118

Epoch: 9| Step: 0
Training loss: 4.150168422360707
Validation loss: 3.9147590101158714

Epoch: 5| Step: 1
Training loss: 3.5609547794152117
Validation loss: 3.900549233453551

Epoch: 5| Step: 2
Training loss: 3.921702225363546
Validation loss: 3.8864705937844057

Epoch: 5| Step: 3
Training loss: 3.766593713532138
Validation loss: 3.8724678438293254

Epoch: 5| Step: 4
Training loss: 4.028451820770061
Validation loss: 3.8623045082849865

Epoch: 5| Step: 5
Training loss: 4.343540543370615
Validation loss: 3.8506365803396605

Epoch: 5| Step: 6
Training loss: 4.610014479939193
Validation loss: 3.8391525168318736

Epoch: 5| Step: 7
Training loss: 3.6941567805323086
Validation loss: 3.832685899208575

Epoch: 5| Step: 8
Training loss: 4.31252896948773
Validation loss: 3.816203367754229

Epoch: 5| Step: 9
Training loss: 4.449935038231729
Validation loss: 3.80758571363208

Epoch: 5| Step: 10
Training loss: 2.9769480698335737
Validation loss: 3.7970059347488774

Epoch: 10| Step: 0
Training loss: 3.858846404289683
Validation loss: 3.7895142198334386

Epoch: 5| Step: 1
Training loss: 3.88986308898838
Validation loss: 3.7815331956659324

Epoch: 5| Step: 2
Training loss: 4.500440999780453
Validation loss: 3.7698209730826258

Epoch: 5| Step: 3
Training loss: 4.051557622833788
Validation loss: 3.7626868197005754

Epoch: 5| Step: 4
Training loss: 4.550840555876975
Validation loss: 3.7495861495068574

Epoch: 5| Step: 5
Training loss: 3.9813509366880604
Validation loss: 3.7376260005629742

Epoch: 5| Step: 6
Training loss: 2.486244026433904
Validation loss: 3.7339681948782624

Epoch: 5| Step: 7
Training loss: 4.0378007522859685
Validation loss: 3.7264309544717578

Epoch: 5| Step: 8
Training loss: 3.701337551948203
Validation loss: 3.721403612360487

Epoch: 5| Step: 9
Training loss: 4.1854935579023635
Validation loss: 3.712878341513371

Epoch: 5| Step: 10
Training loss: 3.513276939397928
Validation loss: 3.7024039722714117

Epoch: 11| Step: 0
Training loss: 2.7119994268557415
Validation loss: 3.696906288880074

Epoch: 5| Step: 1
Training loss: 3.514345741645419
Validation loss: 3.6860645462605874

Epoch: 5| Step: 2
Training loss: 4.582491202005202
Validation loss: 3.6750124821950747

Epoch: 5| Step: 3
Training loss: 4.634677968118612
Validation loss: 3.6761594332837295

Epoch: 5| Step: 4
Training loss: 4.095361057708241
Validation loss: 3.6696361438877254

Epoch: 5| Step: 5
Training loss: 3.824357650774838
Validation loss: 3.6620127465410404

Epoch: 5| Step: 6
Training loss: 3.665080825726282
Validation loss: 3.6477507881087803

Epoch: 5| Step: 7
Training loss: 3.6728646750546976
Validation loss: 3.6410300729993232

Epoch: 5| Step: 8
Training loss: 3.289688884321349
Validation loss: 3.638028963452666

Epoch: 5| Step: 9
Training loss: 4.716922835727548
Validation loss: 3.631136835760843

Epoch: 5| Step: 10
Training loss: 2.9456871057572314
Validation loss: 3.6256599320613483

Epoch: 12| Step: 0
Training loss: 3.941961152983172
Validation loss: 3.6228621759245097

Epoch: 5| Step: 1
Training loss: 3.72766007548525
Validation loss: 3.61398388949342

Epoch: 5| Step: 2
Training loss: 3.5543159039117223
Validation loss: 3.605688798064646

Epoch: 5| Step: 3
Training loss: 3.4449562355661096
Validation loss: 3.5999710915884875

Epoch: 5| Step: 4
Training loss: 3.567638238742693
Validation loss: 3.5919733935831353

Epoch: 5| Step: 5
Training loss: 3.635957140310083
Validation loss: 3.589298503473463

Epoch: 5| Step: 6
Training loss: 4.038890606231067
Validation loss: 3.586486495564653

Epoch: 5| Step: 7
Training loss: 3.222661872627671
Validation loss: 3.581475882284235

Epoch: 5| Step: 8
Training loss: 4.62138410931351
Validation loss: 3.5821185379199134

Epoch: 5| Step: 9
Training loss: 3.758884966868876
Validation loss: 3.5712578159008577

Epoch: 5| Step: 10
Training loss: 4.052472224202122
Validation loss: 3.5702183948159245

Epoch: 13| Step: 0
Training loss: 3.8441453435772153
Validation loss: 3.5631434606645565

Epoch: 5| Step: 1
Training loss: 4.016899173913713
Validation loss: 3.5544650865001857

Epoch: 5| Step: 2
Training loss: 3.9332157623909354
Validation loss: 3.5498476186675125

Epoch: 5| Step: 3
Training loss: 3.7172167526319155
Validation loss: 3.54980826595968

Epoch: 5| Step: 4
Training loss: 3.5229076316953756
Validation loss: 3.550518925667089

Epoch: 5| Step: 5
Training loss: 4.038318676220698
Validation loss: 3.55334762280009

Epoch: 5| Step: 6
Training loss: 3.154710148526457
Validation loss: 3.5345723977795522

Epoch: 5| Step: 7
Training loss: 3.777409013501933
Validation loss: 3.527944870975195

Epoch: 5| Step: 8
Training loss: 3.0720938060365897
Validation loss: 3.5255537583284227

Epoch: 5| Step: 9
Training loss: 3.8659880656508605
Validation loss: 3.5256623928605233

Epoch: 5| Step: 10
Training loss: 4.160213559611125
Validation loss: 3.522415771511402

Epoch: 14| Step: 0
Training loss: 3.8208936003601877
Validation loss: 3.5151191272724485

Epoch: 5| Step: 1
Training loss: 4.182527921028222
Validation loss: 3.5079200279231304

Epoch: 5| Step: 2
Training loss: 3.2760247178035997
Validation loss: 3.509792468226341

Epoch: 5| Step: 3
Training loss: 3.2301549240136893
Validation loss: 3.5019421338303496

Epoch: 5| Step: 4
Training loss: 3.8570443347680374
Validation loss: 3.4960201799923447

Epoch: 5| Step: 5
Training loss: 3.8329031882616
Validation loss: 3.4925209567642237

Epoch: 5| Step: 6
Training loss: 4.0291087059946245
Validation loss: 3.4956315402857396

Epoch: 5| Step: 7
Training loss: 3.8365039290695524
Validation loss: 3.485413269951806

Epoch: 5| Step: 8
Training loss: 3.8339294025446384
Validation loss: 3.482946692376082

Epoch: 5| Step: 9
Training loss: 3.3132166537100147
Validation loss: 3.4771396520603193

Epoch: 5| Step: 10
Training loss: 3.3968398273966764
Validation loss: 3.4737815442355044

Epoch: 15| Step: 0
Training loss: 3.9394280693380823
Validation loss: 3.472513432312834

Epoch: 5| Step: 1
Training loss: 3.2351889945102426
Validation loss: 3.4723578553866514

Epoch: 5| Step: 2
Training loss: 3.8455320119689715
Validation loss: 3.4674888327690283

Epoch: 5| Step: 3
Training loss: 4.23293716399166
Validation loss: 3.4658502210898425

Epoch: 5| Step: 4
Training loss: 3.5562338347645834
Validation loss: 3.457925623970147

Epoch: 5| Step: 5
Training loss: 4.175008561359696
Validation loss: 3.4564821547276776

Epoch: 5| Step: 6
Training loss: 3.521240902998294
Validation loss: 3.4553895191113697

Epoch: 5| Step: 7
Training loss: 2.9919478118751295
Validation loss: 3.455255331910224

Epoch: 5| Step: 8
Training loss: 4.220482590548046
Validation loss: 3.466429021379198

Epoch: 5| Step: 9
Training loss: 3.792946623905598
Validation loss: 3.4572276796607477

Epoch: 5| Step: 10
Training loss: 2.3199799681489286
Validation loss: 3.445531841877681

Epoch: 16| Step: 0
Training loss: 3.79937812334407
Validation loss: 3.441799579598317

Epoch: 5| Step: 1
Training loss: 3.7458886815367767
Validation loss: 3.441372482456139

Epoch: 5| Step: 2
Training loss: 3.4850107476877348
Validation loss: 3.4425899763337977

Epoch: 5| Step: 3
Training loss: 3.26917858341044
Validation loss: 3.4408447489916423

Epoch: 5| Step: 4
Training loss: 4.27783936019982
Validation loss: 3.4411756118754946

Epoch: 5| Step: 5
Training loss: 3.913116645359296
Validation loss: 3.4343112172305146

Epoch: 5| Step: 6
Training loss: 4.085703155624366
Validation loss: 3.4320259113972917

Epoch: 5| Step: 7
Training loss: 3.537783899136886
Validation loss: 3.4273055782169157

Epoch: 5| Step: 8
Training loss: 3.7181465236280014
Validation loss: 3.4254144671545252

Epoch: 5| Step: 9
Training loss: 3.3965576585143236
Validation loss: 3.424093792777317

Epoch: 5| Step: 10
Training loss: 2.597183161513774
Validation loss: 3.422316522676956

Epoch: 17| Step: 0
Training loss: 3.9535090444627086
Validation loss: 3.4228408640810364

Epoch: 5| Step: 1
Training loss: 3.8845899723439103
Validation loss: 3.4221714887941213

Epoch: 5| Step: 2
Training loss: 4.0139363222645095
Validation loss: 3.4184437403971177

Epoch: 5| Step: 3
Training loss: 3.5524812328210684
Validation loss: 3.414955176204006

Epoch: 5| Step: 4
Training loss: 3.428682844872097
Validation loss: 3.413882992659968

Epoch: 5| Step: 5
Training loss: 3.3787246214280096
Validation loss: 3.412380107438445

Epoch: 5| Step: 6
Training loss: 3.980629989757456
Validation loss: 3.4107578054625916

Epoch: 5| Step: 7
Training loss: 3.3768986200597038
Validation loss: 3.4103455906246842

Epoch: 5| Step: 8
Training loss: 3.415746906195636
Validation loss: 3.408245113889973

Epoch: 5| Step: 9
Training loss: 2.3418671229168675
Validation loss: 3.4069691960252695

Epoch: 5| Step: 10
Training loss: 4.441669063794108
Validation loss: 3.4058645677042207

Epoch: 18| Step: 0
Training loss: 2.9556560669764815
Validation loss: 3.404829993884626

Epoch: 5| Step: 1
Training loss: 3.742878955519586
Validation loss: 3.40170172885084

Epoch: 5| Step: 2
Training loss: 3.7692739448290293
Validation loss: 3.409612652556446

Epoch: 5| Step: 3
Training loss: 3.938046735316707
Validation loss: 3.410814401510164

Epoch: 5| Step: 4
Training loss: 3.780361354853078
Validation loss: 3.41292908329937

Epoch: 5| Step: 5
Training loss: 3.1077841518177465
Validation loss: 3.3950341650293243

Epoch: 5| Step: 6
Training loss: 3.768019805062438
Validation loss: 3.397557868880301

Epoch: 5| Step: 7
Training loss: 3.8891222399379757
Validation loss: 3.3994720042379183

Epoch: 5| Step: 8
Training loss: 3.0988657876095083
Validation loss: 3.401598940561454

Epoch: 5| Step: 9
Training loss: 3.7950222691220565
Validation loss: 3.3976450504317053

Epoch: 5| Step: 10
Training loss: 3.921383648371121
Validation loss: 3.399235861635851

Epoch: 19| Step: 0
Training loss: 4.031726424578742
Validation loss: 3.3995433199670515

Epoch: 5| Step: 1
Training loss: 3.458135223842381
Validation loss: 3.396039930941965

Epoch: 5| Step: 2
Training loss: 4.094429018039591
Validation loss: 3.3952718442036467

Epoch: 5| Step: 3
Training loss: 2.7194301587531498
Validation loss: 3.392866380987205

Epoch: 5| Step: 4
Training loss: 3.506936964440421
Validation loss: 3.392208652911514

Epoch: 5| Step: 5
Training loss: 3.796501612258623
Validation loss: 3.392568963347744

Epoch: 5| Step: 6
Training loss: 3.6451584254870752
Validation loss: 3.389056447100294

Epoch: 5| Step: 7
Training loss: 2.9897664686371916
Validation loss: 3.3870791305135195

Epoch: 5| Step: 8
Training loss: 4.065031231411822
Validation loss: 3.384323116659223

Epoch: 5| Step: 9
Training loss: 3.8760347522953116
Validation loss: 3.3857864357162577

Epoch: 5| Step: 10
Training loss: 3.302291109465559
Validation loss: 3.3823754176656697

Epoch: 20| Step: 0
Training loss: 3.3334920527499494
Validation loss: 3.380297655365518

Epoch: 5| Step: 1
Training loss: 3.451074189734164
Validation loss: 3.378684824238743

Epoch: 5| Step: 2
Training loss: 3.027686157551329
Validation loss: 3.376818470479014

Epoch: 5| Step: 3
Training loss: 3.5718236350490513
Validation loss: 3.3766665671749356

Epoch: 5| Step: 4
Training loss: 3.4550136734820245
Validation loss: 3.376917301667106

Epoch: 5| Step: 5
Training loss: 3.7757817602048718
Validation loss: 3.374248623051931

Epoch: 5| Step: 6
Training loss: 4.302678520404606
Validation loss: 3.374291926418219

Epoch: 5| Step: 7
Training loss: 3.7995385140727125
Validation loss: 3.3729059619454116

Epoch: 5| Step: 8
Training loss: 3.124638040561096
Validation loss: 3.371294479640329

Epoch: 5| Step: 9
Training loss: 3.3641295387827945
Validation loss: 3.369385608946565

Epoch: 5| Step: 10
Training loss: 4.343163759478842
Validation loss: 3.367886730891153

Epoch: 21| Step: 0
Training loss: 3.7683373018086685
Validation loss: 3.3659283107246614

Epoch: 5| Step: 1
Training loss: 3.7305642320486747
Validation loss: 3.36423099376815

Epoch: 5| Step: 2
Training loss: 3.4685246849770883
Validation loss: 3.366947124093389

Epoch: 5| Step: 3
Training loss: 4.426369691063747
Validation loss: 3.3631288038619056

Epoch: 5| Step: 4
Training loss: 4.006745372978762
Validation loss: 3.3626555008298333

Epoch: 5| Step: 5
Training loss: 3.0745236779959293
Validation loss: 3.3638502100903414

Epoch: 5| Step: 6
Training loss: 3.4203692742136576
Validation loss: 3.365910859881659

Epoch: 5| Step: 7
Training loss: 3.1747431072926586
Validation loss: 3.366818768568087

Epoch: 5| Step: 8
Training loss: 3.5357407903297107
Validation loss: 3.3641080808625796

Epoch: 5| Step: 9
Training loss: 2.829767751161338
Validation loss: 3.361625022050855

Epoch: 5| Step: 10
Training loss: 3.9082286248621503
Validation loss: 3.356813356610752

Epoch: 22| Step: 0
Training loss: 2.9410181283401817
Validation loss: 3.3563115561116925

Epoch: 5| Step: 1
Training loss: 3.9277655753438183
Validation loss: 3.3553258899914966

Epoch: 5| Step: 2
Training loss: 3.5139126146509847
Validation loss: 3.356261247811698

Epoch: 5| Step: 3
Training loss: 3.7321862865536417
Validation loss: 3.358938506935616

Epoch: 5| Step: 4
Training loss: 3.4472201163338183
Validation loss: 3.355881801945305

Epoch: 5| Step: 5
Training loss: 3.678916121376648
Validation loss: 3.354527722992176

Epoch: 5| Step: 6
Training loss: 3.016220745477562
Validation loss: 3.35333050808722

Epoch: 5| Step: 7
Training loss: 3.166123460725227
Validation loss: 3.3507043671341057

Epoch: 5| Step: 8
Training loss: 4.120254561328278
Validation loss: 3.352043804375972

Epoch: 5| Step: 9
Training loss: 3.9807483398955346
Validation loss: 3.349996848817365

Epoch: 5| Step: 10
Training loss: 3.775425989229094
Validation loss: 3.3483318019075274

Epoch: 23| Step: 0
Training loss: 3.9922207048979907
Validation loss: 3.348028717492746

Epoch: 5| Step: 1
Training loss: 3.4779868647726033
Validation loss: 3.346585363968419

Epoch: 5| Step: 2
Training loss: 3.455171694871333
Validation loss: 3.345488937842787

Epoch: 5| Step: 3
Training loss: 3.222327309206607
Validation loss: 3.3462076601874484

Epoch: 5| Step: 4
Training loss: 3.3059878845731325
Validation loss: 3.3451132224164195

Epoch: 5| Step: 5
Training loss: 3.0369487560522335
Validation loss: 3.343742409698363

Epoch: 5| Step: 6
Training loss: 3.7859848265104525
Validation loss: 3.3454762203412063

Epoch: 5| Step: 7
Training loss: 4.096275191405673
Validation loss: 3.3421996107286014

Epoch: 5| Step: 8
Training loss: 3.428283821259034
Validation loss: 3.344382909203387

Epoch: 5| Step: 9
Training loss: 3.6651184252331994
Validation loss: 3.3454909302163354

Epoch: 5| Step: 10
Training loss: 3.8363255694899085
Validation loss: 3.347124474928906

Epoch: 24| Step: 0
Training loss: 4.350089955769997
Validation loss: 3.342943163379057

Epoch: 5| Step: 1
Training loss: 3.5108406573029884
Validation loss: 3.342489997834753

Epoch: 5| Step: 2
Training loss: 3.2806910447463813
Validation loss: 3.340658825081737

Epoch: 5| Step: 3
Training loss: 3.9456679382356543
Validation loss: 3.339235945271753

Epoch: 5| Step: 4
Training loss: 3.302753432640167
Validation loss: 3.3389333619627366

Epoch: 5| Step: 5
Training loss: 3.178842043187215
Validation loss: 3.3379089104970183

Epoch: 5| Step: 6
Training loss: 3.3106412170831065
Validation loss: 3.337567093077135

Epoch: 5| Step: 7
Training loss: 3.199447381463388
Validation loss: 3.3405754868524653

Epoch: 5| Step: 8
Training loss: 3.26030359691661
Validation loss: 3.335980195594558

Epoch: 5| Step: 9
Training loss: 4.191397603817969
Validation loss: 3.3352472245746476

Epoch: 5| Step: 10
Training loss: 3.5433326542716994
Validation loss: 3.3356179089104714

Epoch: 25| Step: 0
Training loss: 3.435338398396732
Validation loss: 3.3346876059513955

Epoch: 5| Step: 1
Training loss: 3.312853524398731
Validation loss: 3.3328462188387116

Epoch: 5| Step: 2
Training loss: 2.8275026089684063
Validation loss: 3.33376093603384

Epoch: 5| Step: 3
Training loss: 3.9054247175078274
Validation loss: 3.3325161352616957

Epoch: 5| Step: 4
Training loss: 4.32417750834274
Validation loss: 3.3314675729023016

Epoch: 5| Step: 5
Training loss: 2.765566550461539
Validation loss: 3.3284831636426113

Epoch: 5| Step: 6
Training loss: 3.090128464728907
Validation loss: 3.3281718644651646

Epoch: 5| Step: 7
Training loss: 4.027667915921369
Validation loss: 3.328234660581472

Epoch: 5| Step: 8
Training loss: 3.6786187760140576
Validation loss: 3.328998970677891

Epoch: 5| Step: 9
Training loss: 3.735103903146118
Validation loss: 3.330939504434253

Epoch: 5| Step: 10
Training loss: 3.8535491586145474
Validation loss: 3.3316744173184634

Epoch: 26| Step: 0
Training loss: 3.77446788043779
Validation loss: 3.329707111123747

Epoch: 5| Step: 1
Training loss: 3.643876355239424
Validation loss: 3.3265403877874

Epoch: 5| Step: 2
Training loss: 3.883931603140814
Validation loss: 3.3251241060791017

Epoch: 5| Step: 3
Training loss: 1.7780262736984958
Validation loss: 3.3261056123555166

Epoch: 5| Step: 4
Training loss: 3.4090665319322566
Validation loss: 3.324572917505611

Epoch: 5| Step: 5
Training loss: 3.402475207796943
Validation loss: 3.3245215683090303

Epoch: 5| Step: 6
Training loss: 3.934104060508712
Validation loss: 3.324344336158934

Epoch: 5| Step: 7
Training loss: 3.3426402023915234
Validation loss: 3.3281863935478224

Epoch: 5| Step: 8
Training loss: 3.4499052062349245
Validation loss: 3.3701945777206364

Epoch: 5| Step: 9
Training loss: 3.9512026489085192
Validation loss: 3.319748314270935

Epoch: 5| Step: 10
Training loss: 4.190985751856671
Validation loss: 3.3205854908085186

Epoch: 27| Step: 0
Training loss: 3.4800412721488483
Validation loss: 3.3307696086839966

Epoch: 5| Step: 1
Training loss: 3.0069287079205256
Validation loss: 3.33051506286371

Epoch: 5| Step: 2
Training loss: 3.975380112809441
Validation loss: 3.3245022344639668

Epoch: 5| Step: 3
Training loss: 3.247298952241615
Validation loss: 3.323109994585757

Epoch: 5| Step: 4
Training loss: 3.8143146136206028
Validation loss: 3.3222033596291007

Epoch: 5| Step: 5
Training loss: 3.4854775638736513
Validation loss: 3.323597187219521

Epoch: 5| Step: 6
Training loss: 3.3302599725825237
Validation loss: 3.3250016727731664

Epoch: 5| Step: 7
Training loss: 4.062347409243659
Validation loss: 3.3253054944884113

Epoch: 5| Step: 8
Training loss: 3.769605123952288
Validation loss: 3.325442453054098

Epoch: 5| Step: 9
Training loss: 3.412353926106816
Validation loss: 3.3268022455877215

Epoch: 5| Step: 10
Training loss: 3.4705660078605325
Validation loss: 3.321591028772907

Epoch: 28| Step: 0
Training loss: 3.689823130061946
Validation loss: 3.3189239744948384

Epoch: 5| Step: 1
Training loss: 3.22716156429841
Validation loss: 3.316544444127889

Epoch: 5| Step: 2
Training loss: 3.598546020620608
Validation loss: 3.3156834971221416

Epoch: 5| Step: 3
Training loss: 3.2725641000413415
Validation loss: 3.3159553722544843

Epoch: 5| Step: 4
Training loss: 3.6636426477703203
Validation loss: 3.314313582858039

Epoch: 5| Step: 5
Training loss: 2.8383828961593536
Validation loss: 3.3137013862380416

Epoch: 5| Step: 6
Training loss: 4.514827882310107
Validation loss: 3.313217433661864

Epoch: 5| Step: 7
Training loss: 3.5895458010620733
Validation loss: 3.3114243082477652

Epoch: 5| Step: 8
Training loss: 3.1501248289533357
Validation loss: 3.3112062329572436

Epoch: 5| Step: 9
Training loss: 3.8210735538115066
Validation loss: 3.3104233085911443

Epoch: 5| Step: 10
Training loss: 3.4587595267211166
Validation loss: 3.308143806055259

Epoch: 29| Step: 0
Training loss: 3.8707520365860884
Validation loss: 3.3139334170096064

Epoch: 5| Step: 1
Training loss: 3.590750329707964
Validation loss: 3.3077987376489784

Epoch: 5| Step: 2
Training loss: 3.2724202835713356
Validation loss: 3.304294230465701

Epoch: 5| Step: 3
Training loss: 3.459711619801208
Validation loss: 3.304570091464179

Epoch: 5| Step: 4
Training loss: 2.4978748826028463
Validation loss: 3.3035284371112015

Epoch: 5| Step: 5
Training loss: 3.2553898061395032
Validation loss: 3.3039919294937916

Epoch: 5| Step: 6
Training loss: 3.8084234737577107
Validation loss: 3.3028850897376114

Epoch: 5| Step: 7
Training loss: 3.676306594781372
Validation loss: 3.3028135094389177

Epoch: 5| Step: 8
Training loss: 3.623255079512871
Validation loss: 3.301412950991423

Epoch: 5| Step: 9
Training loss: 4.2488760864547315
Validation loss: 3.2998141968252894

Epoch: 5| Step: 10
Training loss: 3.4132464588057223
Validation loss: 3.2991014202472657

Epoch: 30| Step: 0
Training loss: 4.170596952088223
Validation loss: 3.2978471493851735

Epoch: 5| Step: 1
Training loss: 3.1319347493279377
Validation loss: 3.298887996627757

Epoch: 5| Step: 2
Training loss: 3.27327930004432
Validation loss: 3.2970624764551495

Epoch: 5| Step: 3
Training loss: 3.2828109661318408
Validation loss: 3.2952660870387986

Epoch: 5| Step: 4
Training loss: 3.1444467853077627
Validation loss: 3.298032326444125

Epoch: 5| Step: 5
Training loss: 3.3227877377617316
Validation loss: 3.2950399525368073

Epoch: 5| Step: 6
Training loss: 3.4393824191518596
Validation loss: 3.2969376846215006

Epoch: 5| Step: 7
Training loss: 4.17089397883015
Validation loss: 3.297079000968908

Epoch: 5| Step: 8
Training loss: 3.5065967517550325
Validation loss: 3.2974703461708272

Epoch: 5| Step: 9
Training loss: 3.7131179346679697
Validation loss: 3.292412578472291

Epoch: 5| Step: 10
Training loss: 3.5981117647718435
Validation loss: 3.2958870283056214

Epoch: 31| Step: 0
Training loss: 3.046531149217394
Validation loss: 3.2934431487718494

Epoch: 5| Step: 1
Training loss: 3.952855036869539
Validation loss: 3.2938924802782323

Epoch: 5| Step: 2
Training loss: 4.0180893991340705
Validation loss: 3.2901864722385095

Epoch: 5| Step: 3
Training loss: 2.9131769465963058
Validation loss: 3.28658128853609

Epoch: 5| Step: 4
Training loss: 3.084582685688395
Validation loss: 3.2866618555585343

Epoch: 5| Step: 5
Training loss: 3.348676670662773
Validation loss: 3.2916286544713005

Epoch: 5| Step: 6
Training loss: 3.4256036379627792
Validation loss: 3.2916378400565054

Epoch: 5| Step: 7
Training loss: 4.106817922118604
Validation loss: 3.290122445007889

Epoch: 5| Step: 8
Training loss: 4.242380380197325
Validation loss: 3.2903340592506836

Epoch: 5| Step: 9
Training loss: 3.3482649793874413
Validation loss: 3.290682414329298

Epoch: 5| Step: 10
Training loss: 2.9288875861093455
Validation loss: 3.2860341343464943

Epoch: 32| Step: 0
Training loss: 2.8505108291856547
Validation loss: 3.2819079995783134

Epoch: 5| Step: 1
Training loss: 3.8601129112134656
Validation loss: 3.282680272022489

Epoch: 5| Step: 2
Training loss: 3.1425717521493803
Validation loss: 3.2822791622911174

Epoch: 5| Step: 3
Training loss: 3.469306282595772
Validation loss: 3.2786583732302557

Epoch: 5| Step: 4
Training loss: 4.007586675457402
Validation loss: 3.2784470594486694

Epoch: 5| Step: 5
Training loss: 4.209100609256421
Validation loss: 3.2819006607282595

Epoch: 5| Step: 6
Training loss: 2.3138936972240582
Validation loss: 3.2775690084263984

Epoch: 5| Step: 7
Training loss: 3.780076782819205
Validation loss: 3.273910339900957

Epoch: 5| Step: 8
Training loss: 3.677794793798056
Validation loss: 3.2735446531873658

Epoch: 5| Step: 9
Training loss: 3.637468926470718
Validation loss: 3.272349408654246

Epoch: 5| Step: 10
Training loss: 3.345134270315317
Validation loss: 3.2760302472702563

Epoch: 33| Step: 0
Training loss: 3.481284100624052
Validation loss: 3.2805774349066654

Epoch: 5| Step: 1
Training loss: 3.375551108116762
Validation loss: 3.29893654312351

Epoch: 5| Step: 2
Training loss: 3.2789033763873814
Validation loss: 3.3093248668437845

Epoch: 5| Step: 3
Training loss: 4.260620758963298
Validation loss: 3.289525337245468

Epoch: 5| Step: 4
Training loss: 3.844458537973236
Validation loss: 3.2647057682159084

Epoch: 5| Step: 5
Training loss: 3.062055283000675
Validation loss: 3.265903050291872

Epoch: 5| Step: 6
Training loss: 3.1666014480567273
Validation loss: 3.269357609500408

Epoch: 5| Step: 7
Training loss: 2.7105840183191945
Validation loss: 3.2686079731918314

Epoch: 5| Step: 8
Training loss: 3.4455033506787616
Validation loss: 3.274085954082063

Epoch: 5| Step: 9
Training loss: 4.051387200790912
Validation loss: 3.2843542584845515

Epoch: 5| Step: 10
Training loss: 3.7851394952141435
Validation loss: 3.2653214838155495

Epoch: 34| Step: 0
Training loss: 3.863389248008595
Validation loss: 3.263654028207576

Epoch: 5| Step: 1
Training loss: 2.9682787069370127
Validation loss: 3.263542819754544

Epoch: 5| Step: 2
Training loss: 3.6313197853092904
Validation loss: 3.269201636798241

Epoch: 5| Step: 3
Training loss: 3.6437249472331015
Validation loss: 3.274247521771358

Epoch: 5| Step: 4
Training loss: 3.2645933721144975
Validation loss: 3.2792098977619104

Epoch: 5| Step: 5
Training loss: 4.097561757877377
Validation loss: 3.283922843445597

Epoch: 5| Step: 6
Training loss: 3.112255046964493
Validation loss: 3.270443617928786

Epoch: 5| Step: 7
Training loss: 3.270877538167692
Validation loss: 3.2648573527266613

Epoch: 5| Step: 8
Training loss: 3.3014474410928956
Validation loss: 3.2582736958396

Epoch: 5| Step: 9
Training loss: 3.2039764017100443
Validation loss: 3.255758324148271

Epoch: 5| Step: 10
Training loss: 4.124769262160545
Validation loss: 3.2547353870349975

Epoch: 35| Step: 0
Training loss: 3.4386392266178434
Validation loss: 3.2563400318777216

Epoch: 5| Step: 1
Training loss: 3.157670107598774
Validation loss: 3.2542621740075335

Epoch: 5| Step: 2
Training loss: 3.304474808001094
Validation loss: 3.2524642231797216

Epoch: 5| Step: 3
Training loss: 3.771301549572457
Validation loss: 3.2506824704488766

Epoch: 5| Step: 4
Training loss: 3.3507961295098343
Validation loss: 3.249049988910464

Epoch: 5| Step: 5
Training loss: 3.685935771661978
Validation loss: 3.2481201484060502

Epoch: 5| Step: 6
Training loss: 4.044384989342212
Validation loss: 3.248533265007863

Epoch: 5| Step: 7
Training loss: 3.443765651992703
Validation loss: 3.247590044697181

Epoch: 5| Step: 8
Training loss: 3.2686413427787038
Validation loss: 3.2460856991588787

Epoch: 5| Step: 9
Training loss: 2.7305998982161745
Validation loss: 3.248048599591275

Epoch: 5| Step: 10
Training loss: 4.16647480840837
Validation loss: 3.2477145935034337

Epoch: 36| Step: 0
Training loss: 3.562532257469433
Validation loss: 3.2479167892425616

Epoch: 5| Step: 1
Training loss: 3.677314009018383
Validation loss: 3.249565914309807

Epoch: 5| Step: 2
Training loss: 3.757739409372342
Validation loss: 3.258206773858747

Epoch: 5| Step: 3
Training loss: 3.521300079888749
Validation loss: 3.247147035977614

Epoch: 5| Step: 4
Training loss: 3.440867906912415
Validation loss: 3.2450945570982395

Epoch: 5| Step: 5
Training loss: 3.4601429873341725
Validation loss: 3.2417595717457948

Epoch: 5| Step: 6
Training loss: 3.4720319738190315
Validation loss: 3.2412658686158253

Epoch: 5| Step: 7
Training loss: 2.6857068489284806
Validation loss: 3.241693166108901

Epoch: 5| Step: 8
Training loss: 3.7235390736135763
Validation loss: 3.241836190788483

Epoch: 5| Step: 9
Training loss: 3.155833150700625
Validation loss: 3.240798415806781

Epoch: 5| Step: 10
Training loss: 3.860480764028122
Validation loss: 3.2400042476699635

Epoch: 37| Step: 0
Training loss: 4.105889412246826
Validation loss: 3.238214912369891

Epoch: 5| Step: 1
Training loss: 3.2217023327769603
Validation loss: 3.238735207580149

Epoch: 5| Step: 2
Training loss: 3.688206233267903
Validation loss: 3.2404606837963774

Epoch: 5| Step: 3
Training loss: 3.747893313889466
Validation loss: 3.2378654175882846

Epoch: 5| Step: 4
Training loss: 3.2240229997122136
Validation loss: 3.2371748345038305

Epoch: 5| Step: 5
Training loss: 3.077056079520832
Validation loss: 3.235783111973621

Epoch: 5| Step: 6
Training loss: 3.3140826493099897
Validation loss: 3.2337622933811874

Epoch: 5| Step: 7
Training loss: 3.442654854055636
Validation loss: 3.2343180859836

Epoch: 5| Step: 8
Training loss: 3.587095784133842
Validation loss: 3.233715834942352

Epoch: 5| Step: 9
Training loss: 3.156862105133843
Validation loss: 3.233401252160943

Epoch: 5| Step: 10
Training loss: 3.6413446460056007
Validation loss: 3.2311518785397597

Epoch: 38| Step: 0
Training loss: 2.815895065920929
Validation loss: 3.2311347931208516

Epoch: 5| Step: 1
Training loss: 3.4305174220990624
Validation loss: 3.230224781099197

Epoch: 5| Step: 2
Training loss: 3.420144257430991
Validation loss: 3.235859936700595

Epoch: 5| Step: 3
Training loss: 2.735235634648463
Validation loss: 3.235793050296937

Epoch: 5| Step: 4
Training loss: 3.0122479915075564
Validation loss: 3.2334189043899295

Epoch: 5| Step: 5
Training loss: 3.2119143594177424
Validation loss: 3.233305121777531

Epoch: 5| Step: 6
Training loss: 4.2709107678844624
Validation loss: 3.233009875015805

Epoch: 5| Step: 7
Training loss: 4.151449313503405
Validation loss: 3.2299381494945103

Epoch: 5| Step: 8
Training loss: 4.168859642222647
Validation loss: 3.229348882058724

Epoch: 5| Step: 9
Training loss: 3.118703067403474
Validation loss: 3.227380229969879

Epoch: 5| Step: 10
Training loss: 3.5198268618051314
Validation loss: 3.2280814235052175

Epoch: 39| Step: 0
Training loss: 3.6315654624176483
Validation loss: 3.226321301290091

Epoch: 5| Step: 1
Training loss: 2.252990748285294
Validation loss: 3.2255744671723905

Epoch: 5| Step: 2
Training loss: 2.7095519820930822
Validation loss: 3.224596301605004

Epoch: 5| Step: 3
Training loss: 3.0104428370481107
Validation loss: 3.223483846479958

Epoch: 5| Step: 4
Training loss: 3.526552029088354
Validation loss: 3.2241889057026376

Epoch: 5| Step: 5
Training loss: 3.6118134687720413
Validation loss: 3.2233923919047323

Epoch: 5| Step: 6
Training loss: 4.19023703330297
Validation loss: 3.225208239308194

Epoch: 5| Step: 7
Training loss: 3.412063676935327
Validation loss: 3.225339725016469

Epoch: 5| Step: 8
Training loss: 3.610804947483928
Validation loss: 3.22361482992968

Epoch: 5| Step: 9
Training loss: 3.9174799514384087
Validation loss: 3.2262537792976214

Epoch: 5| Step: 10
Training loss: 3.9432438932214455
Validation loss: 3.2354784761472866

Epoch: 40| Step: 0
Training loss: 3.4055616050640207
Validation loss: 3.232482061373212

Epoch: 5| Step: 1
Training loss: 3.6700900020529397
Validation loss: 3.221003301918596

Epoch: 5| Step: 2
Training loss: 3.6878711061109613
Validation loss: 3.219962447937326

Epoch: 5| Step: 3
Training loss: 3.288286783617493
Validation loss: 3.220870308362068

Epoch: 5| Step: 4
Training loss: 3.669594563844961
Validation loss: 3.2187065665570898

Epoch: 5| Step: 5
Training loss: 3.5610446299514904
Validation loss: 3.2182013393193483

Epoch: 5| Step: 6
Training loss: 3.7607747732537242
Validation loss: 3.2170740517912595

Epoch: 5| Step: 7
Training loss: 2.794677809022696
Validation loss: 3.217414485706105

Epoch: 5| Step: 8
Training loss: 3.606844985511814
Validation loss: 3.2160203627344393

Epoch: 5| Step: 9
Training loss: 3.6258413719579696
Validation loss: 3.215984218296969

Epoch: 5| Step: 10
Training loss: 2.8253806271317474
Validation loss: 3.215543627180985

Epoch: 41| Step: 0
Training loss: 3.4165638853911373
Validation loss: 3.2157710111001307

Epoch: 5| Step: 1
Training loss: 2.9249528799581688
Validation loss: 3.2141465982053004

Epoch: 5| Step: 2
Training loss: 3.466874724037898
Validation loss: 3.2147040245492966

Epoch: 5| Step: 3
Training loss: 3.5053782693481543
Validation loss: 3.214450046383704

Epoch: 5| Step: 4
Training loss: 3.4927653062957553
Validation loss: 3.212602709365273

Epoch: 5| Step: 5
Training loss: 3.3562323486318597
Validation loss: 3.212697975778046

Epoch: 5| Step: 6
Training loss: 3.6210887460355123
Validation loss: 3.2122285460630944

Epoch: 5| Step: 7
Training loss: 4.033450923077774
Validation loss: 3.2100902685446253

Epoch: 5| Step: 8
Training loss: 2.955852883504336
Validation loss: 3.210433254893949

Epoch: 5| Step: 9
Training loss: 3.630468387492921
Validation loss: 3.2106831807694465

Epoch: 5| Step: 10
Training loss: 3.5749549649476435
Validation loss: 3.2124932648920246

Epoch: 42| Step: 0
Training loss: 3.2090283586456194
Validation loss: 3.2113184908328964

Epoch: 5| Step: 1
Training loss: 4.003734037836122
Validation loss: 3.213600838770364

Epoch: 5| Step: 2
Training loss: 3.618106206310368
Validation loss: 3.2164242572822292

Epoch: 5| Step: 3
Training loss: 3.3746671159257393
Validation loss: 3.217144111634326

Epoch: 5| Step: 4
Training loss: 4.01631912585127
Validation loss: 3.2134254237628035

Epoch: 5| Step: 5
Training loss: 3.653965815233367
Validation loss: 3.2083682929442126

Epoch: 5| Step: 6
Training loss: 3.0917518405200917
Validation loss: 3.2080972443744025

Epoch: 5| Step: 7
Training loss: 3.539309730904722
Validation loss: 3.2082528332084097

Epoch: 5| Step: 8
Training loss: 3.1665026638996214
Validation loss: 3.2051501283424355

Epoch: 5| Step: 9
Training loss: 3.1315172519199486
Validation loss: 3.204572101117087

Epoch: 5| Step: 10
Training loss: 2.985554726587952
Validation loss: 3.2046358232598506

Epoch: 43| Step: 0
Training loss: 3.8239057683626805
Validation loss: 3.2047107339966145

Epoch: 5| Step: 1
Training loss: 3.616976968723045
Validation loss: 3.203626992031851

Epoch: 5| Step: 2
Training loss: 3.2416228388656765
Validation loss: 3.2038517281379812

Epoch: 5| Step: 3
Training loss: 3.8870698549801133
Validation loss: 3.202952422568488

Epoch: 5| Step: 4
Training loss: 3.021016889235137
Validation loss: 3.203525433145326

Epoch: 5| Step: 5
Training loss: 3.378842744616369
Validation loss: 3.2021850695525904

Epoch: 5| Step: 6
Training loss: 2.9962385756840177
Validation loss: 3.2006316270160164

Epoch: 5| Step: 7
Training loss: 3.3962365751594343
Validation loss: 3.1999990445309927

Epoch: 5| Step: 8
Training loss: 3.211546754233303
Validation loss: 3.200507103504306

Epoch: 5| Step: 9
Training loss: 3.57377900300294
Validation loss: 3.2008400567473694

Epoch: 5| Step: 10
Training loss: 3.7272118216653602
Validation loss: 3.1987467434679355

Epoch: 44| Step: 0
Training loss: 3.4593044587397674
Validation loss: 3.1995232710228363

Epoch: 5| Step: 1
Training loss: 3.5125740885132832
Validation loss: 3.1987095310531135

Epoch: 5| Step: 2
Training loss: 3.1329053451212436
Validation loss: 3.1992181730399456

Epoch: 5| Step: 3
Training loss: 3.4677185724591784
Validation loss: 3.199419714883498

Epoch: 5| Step: 4
Training loss: 3.2165596926069187
Validation loss: 3.198056349062443

Epoch: 5| Step: 5
Training loss: 3.8758606723982303
Validation loss: 3.1976092934616624

Epoch: 5| Step: 6
Training loss: 3.6862273525552602
Validation loss: 3.198237892642093

Epoch: 5| Step: 7
Training loss: 3.219931524508242
Validation loss: 3.1974702083657673

Epoch: 5| Step: 8
Training loss: 3.455659652428585
Validation loss: 3.197667159084167

Epoch: 5| Step: 9
Training loss: 3.3822466440888364
Validation loss: 3.196769574093308

Epoch: 5| Step: 10
Training loss: 3.453216551520738
Validation loss: 3.198661640199689

Epoch: 45| Step: 0
Training loss: 3.7597694297870357
Validation loss: 3.1943482439043827

Epoch: 5| Step: 1
Training loss: 3.0188339632413754
Validation loss: 3.194441746631379

Epoch: 5| Step: 2
Training loss: 3.7415401400531447
Validation loss: 3.195387083747095

Epoch: 5| Step: 3
Training loss: 3.2332062752000783
Validation loss: 3.1918569293218697

Epoch: 5| Step: 4
Training loss: 4.040890307762649
Validation loss: 3.1923369949990827

Epoch: 5| Step: 5
Training loss: 3.422988362102244
Validation loss: 3.1938283448922484

Epoch: 5| Step: 6
Training loss: 3.7058665754301163
Validation loss: 3.1912147949634706

Epoch: 5| Step: 7
Training loss: 3.3462733079613667
Validation loss: 3.1895180654975563

Epoch: 5| Step: 8
Training loss: 3.3223007891014564
Validation loss: 3.1914010687431413

Epoch: 5| Step: 9
Training loss: 3.099507840373865
Validation loss: 3.188941468776055

Epoch: 5| Step: 10
Training loss: 2.8915037726731074
Validation loss: 3.1912628795104774

Epoch: 46| Step: 0
Training loss: 3.368494758066224
Validation loss: 3.1881253205988203

Epoch: 5| Step: 1
Training loss: 3.6592053589888787
Validation loss: 3.188566559868808

Epoch: 5| Step: 2
Training loss: 3.0596529124263494
Validation loss: 3.186732119858026

Epoch: 5| Step: 3
Training loss: 2.7558508966803497
Validation loss: 3.190831533872368

Epoch: 5| Step: 4
Training loss: 3.52181746292841
Validation loss: 3.188214944327304

Epoch: 5| Step: 5
Training loss: 3.8986539914368255
Validation loss: 3.18841736099461

Epoch: 5| Step: 6
Training loss: 3.491939800447065
Validation loss: 3.190647476604197

Epoch: 5| Step: 7
Training loss: 3.544500959644034
Validation loss: 3.185634798405217

Epoch: 5| Step: 8
Training loss: 4.090936990122596
Validation loss: 3.18556730006147

Epoch: 5| Step: 9
Training loss: 3.0349669329933056
Validation loss: 3.184051388576333

Epoch: 5| Step: 10
Training loss: 3.1034320414326806
Validation loss: 3.1826230202168295

Epoch: 47| Step: 0
Training loss: 3.3296763068610256
Validation loss: 3.183446413464998

Epoch: 5| Step: 1
Training loss: 3.892916330210054
Validation loss: 3.183211421248153

Epoch: 5| Step: 2
Training loss: 2.9597097785537354
Validation loss: 3.1843531028289904

Epoch: 5| Step: 3
Training loss: 2.777979867789453
Validation loss: 3.1803838817836447

Epoch: 5| Step: 4
Training loss: 2.999592117556002
Validation loss: 3.181634062073204

Epoch: 5| Step: 5
Training loss: 4.031158919377449
Validation loss: 3.1805337831490816

Epoch: 5| Step: 6
Training loss: 3.753160289436507
Validation loss: 3.1805407102579037

Epoch: 5| Step: 7
Training loss: 3.8480908453402836
Validation loss: 3.186594455427884

Epoch: 5| Step: 8
Training loss: 3.449074833979133
Validation loss: 3.186108712809717

Epoch: 5| Step: 9
Training loss: 3.106096389011782
Validation loss: 3.188463866792369

Epoch: 5| Step: 10
Training loss: 3.3193949789265886
Validation loss: 3.188812809093619

Epoch: 48| Step: 0
Training loss: 3.222318726406241
Validation loss: 3.183330370332481

Epoch: 5| Step: 1
Training loss: 3.2093478163595903
Validation loss: 3.1843372009630126

Epoch: 5| Step: 2
Training loss: 3.2765969845362832
Validation loss: 3.1874572844340516

Epoch: 5| Step: 3
Training loss: 3.5469059207593556
Validation loss: 3.186338231864721

Epoch: 5| Step: 4
Training loss: 3.3364741945599334
Validation loss: 3.1750709932061105

Epoch: 5| Step: 5
Training loss: 3.644359850353978
Validation loss: 3.1755814387219

Epoch: 5| Step: 6
Training loss: 3.433177658057781
Validation loss: 3.1759640733205634

Epoch: 5| Step: 7
Training loss: 3.797177024100398
Validation loss: 3.1758194809989684

Epoch: 5| Step: 8
Training loss: 2.505616744939651
Validation loss: 3.1777758207596487

Epoch: 5| Step: 9
Training loss: 3.699081853410051
Validation loss: 3.1782843412515946

Epoch: 5| Step: 10
Training loss: 3.9165466100811295
Validation loss: 3.1776456263015143

Epoch: 49| Step: 0
Training loss: 3.762438426987227
Validation loss: 3.175954561252482

Epoch: 5| Step: 1
Training loss: 4.105429492185637
Validation loss: 3.1743000196028928

Epoch: 5| Step: 2
Training loss: 3.6004720431369335
Validation loss: 3.1728915207152397

Epoch: 5| Step: 3
Training loss: 3.2306317031150233
Validation loss: 3.172037491151385

Epoch: 5| Step: 4
Training loss: 3.115389733342009
Validation loss: 3.1724269129550438

Epoch: 5| Step: 5
Training loss: 3.3598447959113087
Validation loss: 3.172522466199828

Epoch: 5| Step: 6
Training loss: 3.8333761516888627
Validation loss: 3.1730415885930046

Epoch: 5| Step: 7
Training loss: 3.3035754052804704
Validation loss: 3.17262991430347

Epoch: 5| Step: 8
Training loss: 2.988904302132661
Validation loss: 3.1763484899146244

Epoch: 5| Step: 9
Training loss: 3.3461943631539723
Validation loss: 3.173838677350117

Epoch: 5| Step: 10
Training loss: 2.6984695300137895
Validation loss: 3.174507274575761

Epoch: 50| Step: 0
Training loss: 3.3148956273191366
Validation loss: 3.169662352850876

Epoch: 5| Step: 1
Training loss: 3.1569053045165245
Validation loss: 3.1715180944717214

Epoch: 5| Step: 2
Training loss: 2.916233266691689
Validation loss: 3.171830438106584

Epoch: 5| Step: 3
Training loss: 3.7778490393281516
Validation loss: 3.1686838511596576

Epoch: 5| Step: 4
Training loss: 3.9165586632521303
Validation loss: 3.1728891678694997

Epoch: 5| Step: 5
Training loss: 3.123767151833195
Validation loss: 3.1718546645816263

Epoch: 5| Step: 6
Training loss: 3.940829731087273
Validation loss: 3.1702744026834226

Epoch: 5| Step: 7
Training loss: 2.955858691006099
Validation loss: 3.172685307199397

Epoch: 5| Step: 8
Training loss: 3.83519792128098
Validation loss: 3.168856836226515

Epoch: 5| Step: 9
Training loss: 3.454701749788638
Validation loss: 3.1663569205519524

Epoch: 5| Step: 10
Training loss: 2.9163704494646665
Validation loss: 3.165311486678247

Epoch: 51| Step: 0
Training loss: 3.953997609926465
Validation loss: 3.161086139798632

Epoch: 5| Step: 1
Training loss: 3.3987885392512873
Validation loss: 3.161287123521748

Epoch: 5| Step: 2
Training loss: 3.218699334495813
Validation loss: 3.1633418854834336

Epoch: 5| Step: 3
Training loss: 3.7697676668495004
Validation loss: 3.16184767432181

Epoch: 5| Step: 4
Training loss: 3.1070925515899117
Validation loss: 3.1609421645684472

Epoch: 5| Step: 5
Training loss: 3.712683979446378
Validation loss: 3.159501092339844

Epoch: 5| Step: 6
Training loss: 2.810089180097984
Validation loss: 3.1602129112611568

Epoch: 5| Step: 7
Training loss: 3.502249267447343
Validation loss: 3.160762287693647

Epoch: 5| Step: 8
Training loss: 3.5436418896958575
Validation loss: 3.1611367603869005

Epoch: 5| Step: 9
Training loss: 2.7446150508762313
Validation loss: 3.161416755826296

Epoch: 5| Step: 10
Training loss: 3.63913535884187
Validation loss: 3.160735096829383

Epoch: 52| Step: 0
Training loss: 3.9223464743217193
Validation loss: 3.1595227081427546

Epoch: 5| Step: 1
Training loss: 3.45206942757887
Validation loss: 3.1627255484287864

Epoch: 5| Step: 2
Training loss: 3.3568315680518634
Validation loss: 3.1605628052619283

Epoch: 5| Step: 3
Training loss: 3.4355700537076967
Validation loss: 3.158148624288482

Epoch: 5| Step: 4
Training loss: 3.0283297600425025
Validation loss: 3.1571692370147657

Epoch: 5| Step: 5
Training loss: 3.362299865666017
Validation loss: 3.1581813020993708

Epoch: 5| Step: 6
Training loss: 3.711857667578372
Validation loss: 3.1548892108956426

Epoch: 5| Step: 7
Training loss: 2.6750529168144634
Validation loss: 3.156239094812314

Epoch: 5| Step: 8
Training loss: 3.5311961212098875
Validation loss: 3.155601297532103

Epoch: 5| Step: 9
Training loss: 3.420966737649605
Validation loss: 3.154124821835222

Epoch: 5| Step: 10
Training loss: 3.4354570733804186
Validation loss: 3.1573547213644297

Epoch: 53| Step: 0
Training loss: 3.329322277215218
Validation loss: 3.167111827494869

Epoch: 5| Step: 1
Training loss: 3.613350532486113
Validation loss: 3.1973817749483024

Epoch: 5| Step: 2
Training loss: 3.8378509907702196
Validation loss: 3.193985441086568

Epoch: 5| Step: 3
Training loss: 3.8771431441547413
Validation loss: 3.156457256382707

Epoch: 5| Step: 4
Training loss: 3.5091911614247913
Validation loss: 3.152219239107818

Epoch: 5| Step: 5
Training loss: 3.687911964292541
Validation loss: 3.1498460419183822

Epoch: 5| Step: 6
Training loss: 2.9094302916881136
Validation loss: 3.150473449345386

Epoch: 5| Step: 7
Training loss: 2.9804023545295446
Validation loss: 3.152632334489498

Epoch: 5| Step: 8
Training loss: 3.38829825592523
Validation loss: 3.1510537055339927

Epoch: 5| Step: 9
Training loss: 3.1839115662873674
Validation loss: 3.1504480005922564

Epoch: 5| Step: 10
Training loss: 3.013798293838661
Validation loss: 3.1531752688348593

Epoch: 54| Step: 0
Training loss: 3.1476006164709185
Validation loss: 3.1603815732146106

Epoch: 5| Step: 1
Training loss: 4.236442258360528
Validation loss: 3.1503552769876673

Epoch: 5| Step: 2
Training loss: 3.541801285522717
Validation loss: 3.1503719379147572

Epoch: 5| Step: 3
Training loss: 2.5302217066727994
Validation loss: 3.1498317792085193

Epoch: 5| Step: 4
Training loss: 4.4356836174430585
Validation loss: 3.152478769225722

Epoch: 5| Step: 5
Training loss: 3.6546457797927334
Validation loss: 3.1526500892943976

Epoch: 5| Step: 6
Training loss: 2.7085099578387055
Validation loss: 3.1569206802877

Epoch: 5| Step: 7
Training loss: 2.9602605604497714
Validation loss: 3.1596701703852696

Epoch: 5| Step: 8
Training loss: 3.578767144165119
Validation loss: 3.163995526717911

Epoch: 5| Step: 9
Training loss: 2.993304410198578
Validation loss: 3.1609438580129754

Epoch: 5| Step: 10
Training loss: 3.1259901385502604
Validation loss: 3.15721428191905

Epoch: 55| Step: 0
Training loss: 2.7180608117021294
Validation loss: 3.1523876244822167

Epoch: 5| Step: 1
Training loss: 4.171923919276623
Validation loss: 3.1487286977889997

Epoch: 5| Step: 2
Training loss: 3.021956206594529
Validation loss: 3.1444795777901957

Epoch: 5| Step: 3
Training loss: 3.626019827669095
Validation loss: 3.143072475900113

Epoch: 5| Step: 4
Training loss: 3.1379796364429247
Validation loss: 3.1423733886727883

Epoch: 5| Step: 5
Training loss: 3.084234844760807
Validation loss: 3.1407070484891193

Epoch: 5| Step: 6
Training loss: 4.07577973377272
Validation loss: 3.1397734958903736

Epoch: 5| Step: 7
Training loss: 3.166076772524097
Validation loss: 3.140837069845785

Epoch: 5| Step: 8
Training loss: 3.822998226172345
Validation loss: 3.1405068782787215

Epoch: 5| Step: 9
Training loss: 3.2970466749863543
Validation loss: 3.1403895766227805

Epoch: 5| Step: 10
Training loss: 2.827942225835955
Validation loss: 3.1404431055264332

Epoch: 56| Step: 0
Training loss: 3.6014282466334677
Validation loss: 3.1422210655504808

Epoch: 5| Step: 1
Training loss: 3.396854707294061
Validation loss: 3.139587728984214

Epoch: 5| Step: 2
Training loss: 3.6053273678519577
Validation loss: 3.1385551484176126

Epoch: 5| Step: 3
Training loss: 3.326561072310271
Validation loss: 3.138051439266313

Epoch: 5| Step: 4
Training loss: 2.841202317797298
Validation loss: 3.137714777737689

Epoch: 5| Step: 5
Training loss: 3.3073954568431603
Validation loss: 3.1352403470091743

Epoch: 5| Step: 6
Training loss: 3.763001093653171
Validation loss: 3.1331251780759866

Epoch: 5| Step: 7
Training loss: 3.196453012188801
Validation loss: 3.1366739828833383

Epoch: 5| Step: 8
Training loss: 3.779824863191273
Validation loss: 3.13436066054312

Epoch: 5| Step: 9
Training loss: 2.736216333843514
Validation loss: 3.134401526582344

Epoch: 5| Step: 10
Training loss: 3.656432188010605
Validation loss: 3.1346998331830678

Epoch: 57| Step: 0
Training loss: 3.1633015035375167
Validation loss: 3.132799125362358

Epoch: 5| Step: 1
Training loss: 3.5340802488860388
Validation loss: 3.133836714377229

Epoch: 5| Step: 2
Training loss: 3.0978543577788282
Validation loss: 3.136203816825948

Epoch: 5| Step: 3
Training loss: 2.9657630751597397
Validation loss: 3.134889319494869

Epoch: 5| Step: 4
Training loss: 2.8996612350963193
Validation loss: 3.138026651179536

Epoch: 5| Step: 5
Training loss: 3.2661514952938053
Validation loss: 3.140280755161917

Epoch: 5| Step: 6
Training loss: 4.092486703486389
Validation loss: 3.136035984894927

Epoch: 5| Step: 7
Training loss: 3.4110774558026185
Validation loss: 3.1372295781956456

Epoch: 5| Step: 8
Training loss: 3.716922599522331
Validation loss: 3.137894174317954

Epoch: 5| Step: 9
Training loss: 3.160751305610419
Validation loss: 3.1307887026488155

Epoch: 5| Step: 10
Training loss: 3.8178409624502416
Validation loss: 3.128577137893249

Epoch: 58| Step: 0
Training loss: 3.080470242210915
Validation loss: 3.1293345917290933

Epoch: 5| Step: 1
Training loss: 3.5080608458423757
Validation loss: 3.129668398141932

Epoch: 5| Step: 2
Training loss: 4.084006792442061
Validation loss: 3.127709434460238

Epoch: 5| Step: 3
Training loss: 3.3606862902253454
Validation loss: 3.1269797618973745

Epoch: 5| Step: 4
Training loss: 2.735028695578386
Validation loss: 3.1280324189723547

Epoch: 5| Step: 5
Training loss: 3.309584288062481
Validation loss: 3.127883809422502

Epoch: 5| Step: 6
Training loss: 2.966304534783746
Validation loss: 3.1250462838303736

Epoch: 5| Step: 7
Training loss: 3.8601474992706546
Validation loss: 3.1292618892549053

Epoch: 5| Step: 8
Training loss: 3.609380284425244
Validation loss: 3.1259581247613957

Epoch: 5| Step: 9
Training loss: 2.856108420304228
Validation loss: 3.1248283724672405

Epoch: 5| Step: 10
Training loss: 3.630666053554312
Validation loss: 3.125034563427181

Epoch: 59| Step: 0
Training loss: 3.155387382846619
Validation loss: 3.125768538282074

Epoch: 5| Step: 1
Training loss: 3.845622653225797
Validation loss: 3.1258161631616943

Epoch: 5| Step: 2
Training loss: 2.7730336069793693
Validation loss: 3.121749596897511

Epoch: 5| Step: 3
Training loss: 2.9623680181921217
Validation loss: 3.124093834538334

Epoch: 5| Step: 4
Training loss: 3.2298211367660112
Validation loss: 3.123046837239609

Epoch: 5| Step: 5
Training loss: 3.628782469380468
Validation loss: 3.1245970927733726

Epoch: 5| Step: 6
Training loss: 3.862401972147099
Validation loss: 3.121408517728032

Epoch: 5| Step: 7
Training loss: 2.9298627877248826
Validation loss: 3.1211959023552005

Epoch: 5| Step: 8
Training loss: 3.6777372274119315
Validation loss: 3.12204323792541

Epoch: 5| Step: 9
Training loss: 3.5311288728447994
Validation loss: 3.1231259064971226

Epoch: 5| Step: 10
Training loss: 3.355292532116122
Validation loss: 3.1207676683713634

Epoch: 60| Step: 0
Training loss: 3.2163958783060096
Validation loss: 3.1234731984695316

Epoch: 5| Step: 1
Training loss: 2.73733360446731
Validation loss: 3.121263087634924

Epoch: 5| Step: 2
Training loss: 2.805344528554231
Validation loss: 3.1211751537885064

Epoch: 5| Step: 3
Training loss: 3.7599966954155866
Validation loss: 3.1213235176687166

Epoch: 5| Step: 4
Training loss: 3.85478660477744
Validation loss: 3.121298166354522

Epoch: 5| Step: 5
Training loss: 3.694548513783941
Validation loss: 3.1176659873227632

Epoch: 5| Step: 6
Training loss: 3.0468540288741437
Validation loss: 3.1158409453669362

Epoch: 5| Step: 7
Training loss: 3.7677436661726835
Validation loss: 3.1147416059811053

Epoch: 5| Step: 8
Training loss: 2.6071444360239284
Validation loss: 3.114114982468522

Epoch: 5| Step: 9
Training loss: 3.5316369848967804
Validation loss: 3.114914425476551

Epoch: 5| Step: 10
Training loss: 3.840783936429891
Validation loss: 3.1160896196337617

Epoch: 61| Step: 0
Training loss: 3.382204208128326
Validation loss: 3.1141827592852103

Epoch: 5| Step: 1
Training loss: 3.356366322808537
Validation loss: 3.1141540166156956

Epoch: 5| Step: 2
Training loss: 3.23467087428969
Validation loss: 3.1129647480043627

Epoch: 5| Step: 3
Training loss: 3.963183727301531
Validation loss: 3.1110597217166394

Epoch: 5| Step: 4
Training loss: 3.13496397347565
Validation loss: 3.11201796838508

Epoch: 5| Step: 5
Training loss: 3.782138688504433
Validation loss: 3.114376426016962

Epoch: 5| Step: 6
Training loss: 4.277141520975674
Validation loss: 3.1096676611297256

Epoch: 5| Step: 7
Training loss: 3.196296820090647
Validation loss: 3.109446436069199

Epoch: 5| Step: 8
Training loss: 2.5855531896735098
Validation loss: 3.1093623424430494

Epoch: 5| Step: 9
Training loss: 2.8685379382107015
Validation loss: 3.10899916436781

Epoch: 5| Step: 10
Training loss: 2.8631291993116
Validation loss: 3.1115175597941906

Epoch: 62| Step: 0
Training loss: 3.3428715773097317
Validation loss: 3.107878943196187

Epoch: 5| Step: 1
Training loss: 2.387527553539161
Validation loss: 3.1110752202403846

Epoch: 5| Step: 2
Training loss: 2.5591818563129975
Validation loss: 3.111540583321296

Epoch: 5| Step: 3
Training loss: 3.935866607475825
Validation loss: 3.1086783059140877

Epoch: 5| Step: 4
Training loss: 2.8624867668012555
Validation loss: 3.1117968066089383

Epoch: 5| Step: 5
Training loss: 3.6715099396735376
Validation loss: 3.1132833094551513

Epoch: 5| Step: 6
Training loss: 3.3713224649473523
Validation loss: 3.113276694654937

Epoch: 5| Step: 7
Training loss: 3.638692056187325
Validation loss: 3.112500961836635

Epoch: 5| Step: 8
Training loss: 3.5368836961239234
Validation loss: 3.112506356800947

Epoch: 5| Step: 9
Training loss: 4.056599719190727
Validation loss: 3.1123426933087424

Epoch: 5| Step: 10
Training loss: 3.2260933966836696
Validation loss: 3.1084446345054233

Epoch: 63| Step: 0
Training loss: 2.973543333013344
Validation loss: 3.103954999773424

Epoch: 5| Step: 1
Training loss: 3.4112833613983065
Validation loss: 3.1038898631730283

Epoch: 5| Step: 2
Training loss: 3.9502212655590574
Validation loss: 3.1028226205706573

Epoch: 5| Step: 3
Training loss: 3.555171321598374
Validation loss: 3.1038077301692986

Epoch: 5| Step: 4
Training loss: 3.196783869573395
Validation loss: 3.1038009712795778

Epoch: 5| Step: 5
Training loss: 3.998405138595106
Validation loss: 3.102046207346941

Epoch: 5| Step: 6
Training loss: 3.4666955035795364
Validation loss: 3.1018941048036863

Epoch: 5| Step: 7
Training loss: 3.359889359242006
Validation loss: 3.1003254793012025

Epoch: 5| Step: 8
Training loss: 3.438904770003217
Validation loss: 3.10067461316712

Epoch: 5| Step: 9
Training loss: 2.5557566047679385
Validation loss: 3.100750228977218

Epoch: 5| Step: 10
Training loss: 2.745524318906239
Validation loss: 3.101534006546805

Epoch: 64| Step: 0
Training loss: 3.7576249486233455
Validation loss: 3.106779622572642

Epoch: 5| Step: 1
Training loss: 3.7075313315221963
Validation loss: 3.1033407234156862

Epoch: 5| Step: 2
Training loss: 3.4780083896388803
Validation loss: 3.105464724739775

Epoch: 5| Step: 3
Training loss: 2.8457099951122458
Validation loss: 3.1117115785969145

Epoch: 5| Step: 4
Training loss: 3.2562310567879593
Validation loss: 3.1052217762603576

Epoch: 5| Step: 5
Training loss: 2.8924981723736765
Validation loss: 3.103971430724201

Epoch: 5| Step: 6
Training loss: 3.3587264033668087
Validation loss: 3.100687646829494

Epoch: 5| Step: 7
Training loss: 3.9889736788730743
Validation loss: 3.098295275114693

Epoch: 5| Step: 8
Training loss: 2.841941845529064
Validation loss: 3.103998580338268

Epoch: 5| Step: 9
Training loss: 3.701580514215874
Validation loss: 3.101106275725714

Epoch: 5| Step: 10
Training loss: 2.75047419534439
Validation loss: 3.1076044136909804

Epoch: 65| Step: 0
Training loss: 3.1160599048228095
Validation loss: 3.106858925945373

Epoch: 5| Step: 1
Training loss: 2.6011844394676555
Validation loss: 3.1141071782147245

Epoch: 5| Step: 2
Training loss: 3.5833472909581605
Validation loss: 3.101202087134071

Epoch: 5| Step: 3
Training loss: 2.815731904332153
Validation loss: 3.100410022274993

Epoch: 5| Step: 4
Training loss: 2.985287192377256
Validation loss: 3.0960719664607175

Epoch: 5| Step: 5
Training loss: 3.3913553743340454
Validation loss: 3.097815155487523

Epoch: 5| Step: 6
Training loss: 3.262338691319073
Validation loss: 3.0939473436942877

Epoch: 5| Step: 7
Training loss: 3.573738707944543
Validation loss: 3.093619491262309

Epoch: 5| Step: 8
Training loss: 3.371842779618995
Validation loss: 3.092221477963793

Epoch: 5| Step: 9
Training loss: 3.5047240392690924
Validation loss: 3.094067582624416

Epoch: 5| Step: 10
Training loss: 4.4987615364607265
Validation loss: 3.0994252967892844

Epoch: 66| Step: 0
Training loss: 3.138924816979985
Validation loss: 3.0941384408170225

Epoch: 5| Step: 1
Training loss: 3.6970889315775413
Validation loss: 3.0943412625947926

Epoch: 5| Step: 2
Training loss: 3.3505559089936092
Validation loss: 3.091602645437588

Epoch: 5| Step: 3
Training loss: 3.203236201147108
Validation loss: 3.0894222257981476

Epoch: 5| Step: 4
Training loss: 3.5511380426576284
Validation loss: 3.090012425715842

Epoch: 5| Step: 5
Training loss: 3.251984503883894
Validation loss: 3.0884664660869956

Epoch: 5| Step: 6
Training loss: 3.001429535096633
Validation loss: 3.088163705118239

Epoch: 5| Step: 7
Training loss: 3.052734531200012
Validation loss: 3.08777709809531

Epoch: 5| Step: 8
Training loss: 4.147298940391995
Validation loss: 3.0862812034116605

Epoch: 5| Step: 9
Training loss: 3.0570901850910897
Validation loss: 3.087716369367596

Epoch: 5| Step: 10
Training loss: 3.1925087265337493
Validation loss: 3.0882324059489172

Epoch: 67| Step: 0
Training loss: 3.509797551981595
Validation loss: 3.0857249088978573

Epoch: 5| Step: 1
Training loss: 3.1809721280135763
Validation loss: 3.086333837534408

Epoch: 5| Step: 2
Training loss: 3.4571501458191407
Validation loss: 3.0858784298314084

Epoch: 5| Step: 3
Training loss: 3.2613944800449657
Validation loss: 3.08404008076159

Epoch: 5| Step: 4
Training loss: 3.5496135340125026
Validation loss: 3.083575209021764

Epoch: 5| Step: 5
Training loss: 2.914275706164488
Validation loss: 3.086872812787531

Epoch: 5| Step: 6
Training loss: 3.776820843863991
Validation loss: 3.085039251109758

Epoch: 5| Step: 7
Training loss: 3.4960769738162436
Validation loss: 3.0812468446382897

Epoch: 5| Step: 8
Training loss: 2.8716975608694444
Validation loss: 3.080638022281102

Epoch: 5| Step: 9
Training loss: 3.529233373546733
Validation loss: 3.081835431698844

Epoch: 5| Step: 10
Training loss: 3.1362260215332203
Validation loss: 3.081404328391326

Epoch: 68| Step: 0
Training loss: 2.9648151220414642
Validation loss: 3.0860664279475496

Epoch: 5| Step: 1
Training loss: 3.441194941325839
Validation loss: 3.0809162585737955

Epoch: 5| Step: 2
Training loss: 3.6335550841343354
Validation loss: 3.078523168593076

Epoch: 5| Step: 3
Training loss: 2.112631424647345
Validation loss: 3.081152586822027

Epoch: 5| Step: 4
Training loss: 3.440176320769178
Validation loss: 3.0802256202869476

Epoch: 5| Step: 5
Training loss: 3.307842795440948
Validation loss: 3.079797836858362

Epoch: 5| Step: 6
Training loss: 2.852135336833485
Validation loss: 3.081903692143578

Epoch: 5| Step: 7
Training loss: 2.7044420506677382
Validation loss: 3.0886103419362767

Epoch: 5| Step: 8
Training loss: 3.94816791201314
Validation loss: 3.091142540260671

Epoch: 5| Step: 9
Training loss: 3.794338933490221
Validation loss: 3.088616077441369

Epoch: 5| Step: 10
Training loss: 4.169752402513439
Validation loss: 3.0917043808049547

Epoch: 69| Step: 0
Training loss: 2.1492759594362916
Validation loss: 3.0862254940762845

Epoch: 5| Step: 1
Training loss: 2.7908342648224878
Validation loss: 3.076536828376251

Epoch: 5| Step: 2
Training loss: 3.713412389159121
Validation loss: 3.0774184405551064

Epoch: 5| Step: 3
Training loss: 3.6965675722765097
Validation loss: 3.0755306754747904

Epoch: 5| Step: 4
Training loss: 3.828314702530199
Validation loss: 3.075225173745347

Epoch: 5| Step: 5
Training loss: 2.8759109049169136
Validation loss: 3.074924802423442

Epoch: 5| Step: 6
Training loss: 3.9919566108241504
Validation loss: 3.0747937631264772

Epoch: 5| Step: 7
Training loss: 3.3739464139634574
Validation loss: 3.073658530798246

Epoch: 5| Step: 8
Training loss: 3.3870928248662233
Validation loss: 3.07174308200758

Epoch: 5| Step: 9
Training loss: 3.4881303333815166
Validation loss: 3.0724687942702023

Epoch: 5| Step: 10
Training loss: 2.8152870779872403
Validation loss: 3.067950683817313

Epoch: 70| Step: 0
Training loss: 3.536830577257916
Validation loss: 3.069615948216962

Epoch: 5| Step: 1
Training loss: 2.9593894756732486
Validation loss: 3.067947001238215

Epoch: 5| Step: 2
Training loss: 4.101479026308323
Validation loss: 3.06799336364232

Epoch: 5| Step: 3
Training loss: 3.3418363995781437
Validation loss: 3.0682618495446756

Epoch: 5| Step: 4
Training loss: 3.5379890346497342
Validation loss: 3.0683880244560293

Epoch: 5| Step: 5
Training loss: 3.2480589131804876
Validation loss: 3.066041217889908

Epoch: 5| Step: 6
Training loss: 2.9184560100827435
Validation loss: 3.065813508362012

Epoch: 5| Step: 7
Training loss: 3.0393513441724296
Validation loss: 3.065443283314498

Epoch: 5| Step: 8
Training loss: 3.218562592911585
Validation loss: 3.0641129519403085

Epoch: 5| Step: 9
Training loss: 2.673203166097992
Validation loss: 3.0638291515632203

Epoch: 5| Step: 10
Training loss: 3.9070222625293423
Validation loss: 3.0660864728137303

Epoch: 71| Step: 0
Training loss: 2.537502055801536
Validation loss: 3.06384503459651

Epoch: 5| Step: 1
Training loss: 3.840073602884941
Validation loss: 3.0622570049426012

Epoch: 5| Step: 2
Training loss: 2.963574847866382
Validation loss: 3.0614523519817713

Epoch: 5| Step: 3
Training loss: 3.1934643462773815
Validation loss: 3.061724057403204

Epoch: 5| Step: 4
Training loss: 2.7462021004584676
Validation loss: 3.0614524474446414

Epoch: 5| Step: 5
Training loss: 2.9164932381067445
Validation loss: 3.063832399801676

Epoch: 5| Step: 6
Training loss: 3.493856351322177
Validation loss: 3.0596890737008127

Epoch: 5| Step: 7
Training loss: 3.163496254067564
Validation loss: 3.0603000054346716

Epoch: 5| Step: 8
Training loss: 3.780703166166852
Validation loss: 3.062325772956358

Epoch: 5| Step: 9
Training loss: 4.332500573371194
Validation loss: 3.0620833551510906

Epoch: 5| Step: 10
Training loss: 3.1547497498037336
Validation loss: 3.0635755005306278

Epoch: 72| Step: 0
Training loss: 3.1081022024939045
Validation loss: 3.0668716853905678

Epoch: 5| Step: 1
Training loss: 3.729152459200997
Validation loss: 3.073012275244336

Epoch: 5| Step: 2
Training loss: 3.8050627161138317
Validation loss: 3.082456617643637

Epoch: 5| Step: 3
Training loss: 3.5051221152023317
Validation loss: 3.0654238567613006

Epoch: 5| Step: 4
Training loss: 2.3511658394174066
Validation loss: 3.057489924990239

Epoch: 5| Step: 5
Training loss: 3.856061741022015
Validation loss: 3.0593217476749586

Epoch: 5| Step: 6
Training loss: 3.0349919140879273
Validation loss: 3.0573093373057234

Epoch: 5| Step: 7
Training loss: 3.0277348222708835
Validation loss: 3.059926766592886

Epoch: 5| Step: 8
Training loss: 3.43284819301824
Validation loss: 3.063974689683046

Epoch: 5| Step: 9
Training loss: 3.717983647729661
Validation loss: 3.0663874206320174

Epoch: 5| Step: 10
Training loss: 2.536018965394497
Validation loss: 3.06318285597116

Epoch: 73| Step: 0
Training loss: 3.335008406964505
Validation loss: 3.0632972759359225

Epoch: 5| Step: 1
Training loss: 3.3570409428858494
Validation loss: 3.065076675324511

Epoch: 5| Step: 2
Training loss: 2.9483820858970224
Validation loss: 3.0566256975704973

Epoch: 5| Step: 3
Training loss: 3.214302323313596
Validation loss: 3.055239312004835

Epoch: 5| Step: 4
Training loss: 3.497217707336059
Validation loss: 3.058608404638424

Epoch: 5| Step: 5
Training loss: 3.297400265473118
Validation loss: 3.05609901408077

Epoch: 5| Step: 6
Training loss: 2.9427731847228107
Validation loss: 3.056724979793908

Epoch: 5| Step: 7
Training loss: 3.971535253513112
Validation loss: 3.0553701453264153

Epoch: 5| Step: 8
Training loss: 2.6718966834543667
Validation loss: 3.0547819349310794

Epoch: 5| Step: 9
Training loss: 4.1558823960730935
Validation loss: 3.0555201505721006

Epoch: 5| Step: 10
Training loss: 2.7721847928751773
Validation loss: 3.0542878709189725

Epoch: 74| Step: 0
Training loss: 3.7764462309092566
Validation loss: 3.0551455323008185

Epoch: 5| Step: 1
Training loss: 2.65320996619092
Validation loss: 3.0535596176227315

Epoch: 5| Step: 2
Training loss: 3.115182025912038
Validation loss: 3.0543012435396677

Epoch: 5| Step: 3
Training loss: 2.99889512379159
Validation loss: 3.053563636584593

Epoch: 5| Step: 4
Training loss: 2.5583456836447898
Validation loss: 3.0597134449086023

Epoch: 5| Step: 5
Training loss: 3.5118053794758373
Validation loss: 3.0622351747267236

Epoch: 5| Step: 6
Training loss: 3.804888772830081
Validation loss: 3.0557775357762926

Epoch: 5| Step: 7
Training loss: 3.259737978041462
Validation loss: 3.0549036843354362

Epoch: 5| Step: 8
Training loss: 3.240202735162356
Validation loss: 3.060901741290869

Epoch: 5| Step: 9
Training loss: 3.8411330331707627
Validation loss: 3.0513165356365346

Epoch: 5| Step: 10
Training loss: 3.4838560256728734
Validation loss: 3.0483960717819976

Epoch: 75| Step: 0
Training loss: 3.6650412742715814
Validation loss: 3.0488422749759034

Epoch: 5| Step: 1
Training loss: 3.0203987247416357
Validation loss: 3.045982867591077

Epoch: 5| Step: 2
Training loss: 3.091332309736168
Validation loss: 3.045554183526853

Epoch: 5| Step: 3
Training loss: 3.0806028974920046
Validation loss: 3.046290086714252

Epoch: 5| Step: 4
Training loss: 3.529499666671424
Validation loss: 3.0454779355070674

Epoch: 5| Step: 5
Training loss: 3.7778549716268235
Validation loss: 3.0463402164407505

Epoch: 5| Step: 6
Training loss: 3.4514542762571474
Validation loss: 3.043749238054323

Epoch: 5| Step: 7
Training loss: 2.9804951477881607
Validation loss: 3.0425218193942265

Epoch: 5| Step: 8
Training loss: 3.394952499888837
Validation loss: 3.0449329742709463

Epoch: 5| Step: 9
Training loss: 2.900370238775156
Validation loss: 3.0424461029116396

Epoch: 5| Step: 10
Training loss: 3.4668935670934866
Validation loss: 3.04265735847507

Epoch: 76| Step: 0
Training loss: 3.2142957959698197
Validation loss: 3.040124932025515

Epoch: 5| Step: 1
Training loss: 2.992207101304515
Validation loss: 3.0409512191844836

Epoch: 5| Step: 2
Training loss: 2.723782058954313
Validation loss: 3.0400939906717928

Epoch: 5| Step: 3
Training loss: 4.062804225387697
Validation loss: 3.042083199828561

Epoch: 5| Step: 4
Training loss: 3.510776822021441
Validation loss: 3.039795678684847

Epoch: 5| Step: 5
Training loss: 2.6328272606863212
Validation loss: 3.042995870998717

Epoch: 5| Step: 6
Training loss: 3.4662992050359716
Validation loss: 3.042080553669805

Epoch: 5| Step: 7
Training loss: 3.7042569390114997
Validation loss: 3.0432197330076876

Epoch: 5| Step: 8
Training loss: 3.20346052691994
Validation loss: 3.044364914622424

Epoch: 5| Step: 9
Training loss: 3.1496590263259767
Validation loss: 3.0429107362668795

Epoch: 5| Step: 10
Training loss: 3.493031649363428
Validation loss: 3.0445491069507575

Epoch: 77| Step: 0
Training loss: 2.9051166908871147
Validation loss: 3.040132724656831

Epoch: 5| Step: 1
Training loss: 3.725878382812668
Validation loss: 3.0417157510687263

Epoch: 5| Step: 2
Training loss: 3.278477251093486
Validation loss: 3.03865329716341

Epoch: 5| Step: 3
Training loss: 3.7647215206508644
Validation loss: 3.0384968569367046

Epoch: 5| Step: 4
Training loss: 3.2997679831119346
Validation loss: 3.0359613315815874

Epoch: 5| Step: 5
Training loss: 2.966175448722233
Validation loss: 3.0350325199648784

Epoch: 5| Step: 6
Training loss: 3.002713883251758
Validation loss: 3.034181528581223

Epoch: 5| Step: 7
Training loss: 3.3287362983470326
Validation loss: 3.035728163466423

Epoch: 5| Step: 8
Training loss: 3.243840028546158
Validation loss: 3.0355140575537236

Epoch: 5| Step: 9
Training loss: 3.301123606968004
Validation loss: 3.0354094076720495

Epoch: 5| Step: 10
Training loss: 3.490473725704576
Validation loss: 3.032206953572933

Epoch: 78| Step: 0
Training loss: 3.433674018277499
Validation loss: 3.0312909790692655

Epoch: 5| Step: 1
Training loss: 3.954398330853585
Validation loss: 3.029954165394908

Epoch: 5| Step: 2
Training loss: 3.0653483321376167
Validation loss: 3.031220282343515

Epoch: 5| Step: 3
Training loss: 3.1034821303848625
Validation loss: 3.030199515657299

Epoch: 5| Step: 4
Training loss: 3.6108501111775086
Validation loss: 3.033229188935383

Epoch: 5| Step: 5
Training loss: 3.352365535397708
Validation loss: 3.0317265996737874

Epoch: 5| Step: 6
Training loss: 3.2426447166789574
Validation loss: 3.0322506209491347

Epoch: 5| Step: 7
Training loss: 3.4626036480425393
Validation loss: 3.0337716564014245

Epoch: 5| Step: 8
Training loss: 2.5608126039055996
Validation loss: 3.0372746007749387

Epoch: 5| Step: 9
Training loss: 3.1387409993068847
Validation loss: 3.043334393884941

Epoch: 5| Step: 10
Training loss: 3.1532518102365
Validation loss: 3.050098804774447

Epoch: 79| Step: 0
Training loss: 3.557059433572181
Validation loss: 3.049419978193433

Epoch: 5| Step: 1
Training loss: 3.4762459257198683
Validation loss: 3.034558788096996

Epoch: 5| Step: 2
Training loss: 3.799462586598327
Validation loss: 3.039485605114936

Epoch: 5| Step: 3
Training loss: 3.349807244064604
Validation loss: 3.027751961508602

Epoch: 5| Step: 4
Training loss: 3.2881538060080664
Validation loss: 3.023401179870162

Epoch: 5| Step: 5
Training loss: 3.2097382545116644
Validation loss: 3.0248268341614275

Epoch: 5| Step: 6
Training loss: 3.088560587850233
Validation loss: 3.0253214597602662

Epoch: 5| Step: 7
Training loss: 3.2107220134220813
Validation loss: 3.0232514685629783

Epoch: 5| Step: 8
Training loss: 3.259199912762348
Validation loss: 3.023317074802585

Epoch: 5| Step: 9
Training loss: 3.214500510895262
Validation loss: 3.026506873032475

Epoch: 5| Step: 10
Training loss: 2.587265733811654
Validation loss: 3.029212961552492

Epoch: 80| Step: 0
Training loss: 3.3481697035954894
Validation loss: 3.0446834114981387

Epoch: 5| Step: 1
Training loss: 2.8450513943017377
Validation loss: 3.023471247126527

Epoch: 5| Step: 2
Training loss: 3.1319271368172075
Validation loss: 3.022964172969228

Epoch: 5| Step: 3
Training loss: 2.847630462739036
Validation loss: 3.0217066483014587

Epoch: 5| Step: 4
Training loss: 2.808859779375409
Validation loss: 3.02420104257619

Epoch: 5| Step: 5
Training loss: 3.1413250043409944
Validation loss: 3.0201081171684416

Epoch: 5| Step: 6
Training loss: 3.6604001219449187
Validation loss: 3.0183764570255684

Epoch: 5| Step: 7
Training loss: 2.999064299573057
Validation loss: 3.0206366560195095

Epoch: 5| Step: 8
Training loss: 2.8989625851025087
Validation loss: 3.016692943137891

Epoch: 5| Step: 9
Training loss: 3.7378199819912994
Validation loss: 3.0173131905894714

Epoch: 5| Step: 10
Training loss: 4.629702059426461
Validation loss: 3.0164843454936308

Epoch: 81| Step: 0
Training loss: 2.9207877517894754
Validation loss: 3.015564487910038

Epoch: 5| Step: 1
Training loss: 3.0887121932935884
Validation loss: 3.016839934314374

Epoch: 5| Step: 2
Training loss: 3.531820065555983
Validation loss: 3.0147626416255933

Epoch: 5| Step: 3
Training loss: 3.271589171595761
Validation loss: 3.015235166257299

Epoch: 5| Step: 4
Training loss: 2.54939622649951
Validation loss: 3.0158268990956207

Epoch: 5| Step: 5
Training loss: 3.079285688427131
Validation loss: 3.018708723434818

Epoch: 5| Step: 6
Training loss: 3.4904748185925243
Validation loss: 3.0181149606373783

Epoch: 5| Step: 7
Training loss: 2.9853851046938042
Validation loss: 3.0169711098101684

Epoch: 5| Step: 8
Training loss: 3.8185814053893052
Validation loss: 3.017334854722469

Epoch: 5| Step: 9
Training loss: 3.464886412417029
Validation loss: 3.0154256957252707

Epoch: 5| Step: 10
Training loss: 3.8122432184513646
Validation loss: 3.0186169435114674

Epoch: 82| Step: 0
Training loss: 3.3776452329909206
Validation loss: 3.022861995849866

Epoch: 5| Step: 1
Training loss: 3.1171850524739764
Validation loss: 3.0153050848856546

Epoch: 5| Step: 2
Training loss: 2.729120229855018
Validation loss: 3.0173701977333467

Epoch: 5| Step: 3
Training loss: 3.0909407991425057
Validation loss: 3.01442114227613

Epoch: 5| Step: 4
Training loss: 2.9084411892570885
Validation loss: 3.012947891578656

Epoch: 5| Step: 5
Training loss: 3.380134068375163
Validation loss: 3.0098981215191176

Epoch: 5| Step: 6
Training loss: 3.366619301138581
Validation loss: 3.0121027882756963

Epoch: 5| Step: 7
Training loss: 3.7700389777073418
Validation loss: 3.0105690644854968

Epoch: 5| Step: 8
Training loss: 3.706129440739834
Validation loss: 3.0107697963411644

Epoch: 5| Step: 9
Training loss: 3.282164963811297
Validation loss: 3.009287861015956

Epoch: 5| Step: 10
Training loss: 3.2239484566006746
Validation loss: 3.009001711487351

Epoch: 83| Step: 0
Training loss: 3.4230706899812042
Validation loss: 3.0094183366320895

Epoch: 5| Step: 1
Training loss: 3.005165897556802
Validation loss: 3.009155462862572

Epoch: 5| Step: 2
Training loss: 3.2985051902139193
Validation loss: 3.0058895079909336

Epoch: 5| Step: 3
Training loss: 3.33352137670991
Validation loss: 3.005844724599286

Epoch: 5| Step: 4
Training loss: 3.0662544747470406
Validation loss: 3.004396830457703

Epoch: 5| Step: 5
Training loss: 3.5649950091098344
Validation loss: 3.0064580285325024

Epoch: 5| Step: 6
Training loss: 3.1439522346381987
Validation loss: 3.008323388459186

Epoch: 5| Step: 7
Training loss: 3.376287144241599
Validation loss: 3.0036702589497706

Epoch: 5| Step: 8
Training loss: 3.1408668538814304
Validation loss: 3.0050482720198444

Epoch: 5| Step: 9
Training loss: 3.5646388008146683
Validation loss: 3.0083957787897466

Epoch: 5| Step: 10
Training loss: 3.069501075586608
Validation loss: 3.007811893142918

Epoch: 84| Step: 0
Training loss: 2.6588952749115142
Validation loss: 3.006608319400444

Epoch: 5| Step: 1
Training loss: 3.2607265402346193
Validation loss: 3.0089564696038784

Epoch: 5| Step: 2
Training loss: 3.38756088821475
Validation loss: 3.0024105218369566

Epoch: 5| Step: 3
Training loss: 3.2645175644011615
Validation loss: 3.003249712149538

Epoch: 5| Step: 4
Training loss: 3.631427591153716
Validation loss: 3.00167093264911

Epoch: 5| Step: 5
Training loss: 3.0005764407436124
Validation loss: 2.998826205757758

Epoch: 5| Step: 6
Training loss: 3.352842428881094
Validation loss: 3.0003222682093846

Epoch: 5| Step: 7
Training loss: 3.544152109519996
Validation loss: 2.9988699993004735

Epoch: 5| Step: 8
Training loss: 3.246622090774529
Validation loss: 3.003160420232455

Epoch: 5| Step: 9
Training loss: 3.6727701597516695
Validation loss: 3.0005308847116097

Epoch: 5| Step: 10
Training loss: 2.808768276262093
Validation loss: 2.997918439110625

Epoch: 85| Step: 0
Training loss: 3.7930001788894847
Validation loss: 2.9982807452601397

Epoch: 5| Step: 1
Training loss: 3.0882803606436866
Validation loss: 2.994771275319377

Epoch: 5| Step: 2
Training loss: 2.6602650534719507
Validation loss: 2.99944446232827

Epoch: 5| Step: 3
Training loss: 2.86778115927032
Validation loss: 3.0054967507290744

Epoch: 5| Step: 4
Training loss: 3.135867486693914
Validation loss: 3.006848716303032

Epoch: 5| Step: 5
Training loss: 3.4198294321547293
Validation loss: 3.008316891412563

Epoch: 5| Step: 6
Training loss: 3.4320667677477967
Validation loss: 3.0040370997419954

Epoch: 5| Step: 7
Training loss: 3.3615421845426057
Validation loss: 3.004755652540725

Epoch: 5| Step: 8
Training loss: 3.719688745828705
Validation loss: 2.9942387375485335

Epoch: 5| Step: 9
Training loss: 3.1243428874554655
Validation loss: 2.9939683573071507

Epoch: 5| Step: 10
Training loss: 3.2207796678764518
Validation loss: 2.9928402148753075

Epoch: 86| Step: 0
Training loss: 3.072853803261037
Validation loss: 2.991331744212438

Epoch: 5| Step: 1
Training loss: 2.845234074944124
Validation loss: 2.9925821093862734

Epoch: 5| Step: 2
Training loss: 4.158106339144866
Validation loss: 2.990425760941505

Epoch: 5| Step: 3
Training loss: 2.9379684399389228
Validation loss: 2.991072440611308

Epoch: 5| Step: 4
Training loss: 3.1942023328353546
Validation loss: 2.9921318294701496

Epoch: 5| Step: 5
Training loss: 3.3230827712553683
Validation loss: 2.995858290216058

Epoch: 5| Step: 6
Training loss: 3.6899757479565922
Validation loss: 2.9984768706269462

Epoch: 5| Step: 7
Training loss: 2.598200002564548
Validation loss: 2.9942687845691407

Epoch: 5| Step: 8
Training loss: 3.56703660121969
Validation loss: 2.991046305880932

Epoch: 5| Step: 9
Training loss: 3.3631621549035935
Validation loss: 2.990320753954134

Epoch: 5| Step: 10
Training loss: 2.850098952867724
Validation loss: 2.988449347819831

Epoch: 87| Step: 0
Training loss: 3.5077263156694034
Validation loss: 2.9876119090428372

Epoch: 5| Step: 1
Training loss: 2.9425529686528393
Validation loss: 2.9897355274622406

Epoch: 5| Step: 2
Training loss: 3.5706867046957256
Validation loss: 2.9880555293579203

Epoch: 5| Step: 3
Training loss: 3.474504388828116
Validation loss: 2.98889462361343

Epoch: 5| Step: 4
Training loss: 3.353965626885667
Validation loss: 2.988279472434727

Epoch: 5| Step: 5
Training loss: 3.557169087850009
Validation loss: 2.986919304454504

Epoch: 5| Step: 6
Training loss: 2.1149974348625338
Validation loss: 2.9860310567541877

Epoch: 5| Step: 7
Training loss: 3.7336766056781854
Validation loss: 2.985004772863284

Epoch: 5| Step: 8
Training loss: 2.9360286192993295
Validation loss: 2.985773890129297

Epoch: 5| Step: 9
Training loss: 3.0971990298404033
Validation loss: 2.98537408888124

Epoch: 5| Step: 10
Training loss: 3.266023164413541
Validation loss: 2.9847399335955997

Epoch: 88| Step: 0
Training loss: 3.585401972922155
Validation loss: 2.9839441252223486

Epoch: 5| Step: 1
Training loss: 3.1854512231290064
Validation loss: 2.986581740829111

Epoch: 5| Step: 2
Training loss: 3.3355383891082475
Validation loss: 2.9839668469433

Epoch: 5| Step: 3
Training loss: 3.903446992369848
Validation loss: 2.983356766211424

Epoch: 5| Step: 4
Training loss: 3.0492671086012075
Validation loss: 2.983558296067053

Epoch: 5| Step: 5
Training loss: 3.439501231873607
Validation loss: 2.9849690620945033

Epoch: 5| Step: 6
Training loss: 3.342589417590411
Validation loss: 2.9846300057944606

Epoch: 5| Step: 7
Training loss: 2.9595125740404145
Validation loss: 2.983779304014374

Epoch: 5| Step: 8
Training loss: 3.011056235901568
Validation loss: 2.9880307332707323

Epoch: 5| Step: 9
Training loss: 3.033633209608481
Validation loss: 2.9927069014719687

Epoch: 5| Step: 10
Training loss: 2.757173372293228
Validation loss: 2.986521864355938

Epoch: 89| Step: 0
Training loss: 2.6730216616442495
Validation loss: 2.9940552390370496

Epoch: 5| Step: 1
Training loss: 3.4657255166752017
Validation loss: 2.990687875678959

Epoch: 5| Step: 2
Training loss: 3.1516891612906517
Validation loss: 2.9920846077523304

Epoch: 5| Step: 3
Training loss: 3.6305990715762424
Validation loss: 2.9913537464875493

Epoch: 5| Step: 4
Training loss: 3.678136283967398
Validation loss: 2.9895690892475364

Epoch: 5| Step: 5
Training loss: 3.45278583776983
Validation loss: 2.9870514167047917

Epoch: 5| Step: 6
Training loss: 3.64390907005815
Validation loss: 2.9876192070914582

Epoch: 5| Step: 7
Training loss: 2.460109317025381
Validation loss: 2.9859036915322337

Epoch: 5| Step: 8
Training loss: 3.496306923275702
Validation loss: 2.9816506661389583

Epoch: 5| Step: 9
Training loss: 3.061572810357467
Validation loss: 2.98442881717702

Epoch: 5| Step: 10
Training loss: 2.6816496046656373
Validation loss: 2.9812191783319353

Epoch: 90| Step: 0
Training loss: 2.945236245541811
Validation loss: 2.9762236324988964

Epoch: 5| Step: 1
Training loss: 3.6068431346637864
Validation loss: 2.970022757495401

Epoch: 5| Step: 2
Training loss: 2.826087765868974
Validation loss: 2.970803842756446

Epoch: 5| Step: 3
Training loss: 3.5042059014324187
Validation loss: 2.9693175683812894

Epoch: 5| Step: 4
Training loss: 3.4539541224363446
Validation loss: 2.968990562722409

Epoch: 5| Step: 5
Training loss: 3.6534356917593063
Validation loss: 2.966817076108893

Epoch: 5| Step: 6
Training loss: 2.4596105479727832
Validation loss: 2.971682627548687

Epoch: 5| Step: 7
Training loss: 2.4581716344208435
Validation loss: 2.9681892146019746

Epoch: 5| Step: 8
Training loss: 3.5644836257256682
Validation loss: 2.9696451595945494

Epoch: 5| Step: 9
Training loss: 3.756415156892621
Validation loss: 2.97024365917709

Epoch: 5| Step: 10
Training loss: 3.1099724123795243
Validation loss: 2.9738410168125027

Epoch: 91| Step: 0
Training loss: 2.424271708188773
Validation loss: 2.9711438978789686

Epoch: 5| Step: 1
Training loss: 2.963280065663486
Validation loss: 2.978282925321127

Epoch: 5| Step: 2
Training loss: 2.861274463553983
Validation loss: 2.9773772034487616

Epoch: 5| Step: 3
Training loss: 3.314018333388952
Validation loss: 2.980129204055284

Epoch: 5| Step: 4
Training loss: 3.4575523199286438
Validation loss: 2.9779028873530597

Epoch: 5| Step: 5
Training loss: 3.3873930967009347
Validation loss: 2.9826735126115107

Epoch: 5| Step: 6
Training loss: 3.3020085146798253
Validation loss: 2.965120794313411

Epoch: 5| Step: 7
Training loss: 3.4837800617104953
Validation loss: 2.962878045971142

Epoch: 5| Step: 8
Training loss: 2.5975419786602294
Validation loss: 2.9666557122618555

Epoch: 5| Step: 9
Training loss: 3.808537284236871
Validation loss: 2.9720993862530913

Epoch: 5| Step: 10
Training loss: 3.9019893756450035
Validation loss: 2.9757201635260015

Epoch: 92| Step: 0
Training loss: 2.990679408169443
Validation loss: 2.9738987572841062

Epoch: 5| Step: 1
Training loss: 3.6615757423702515
Validation loss: 2.9675279089156277

Epoch: 5| Step: 2
Training loss: 3.4335027862755285
Validation loss: 2.9653384595113494

Epoch: 5| Step: 3
Training loss: 2.8397970707348263
Validation loss: 2.9633522725053454

Epoch: 5| Step: 4
Training loss: 3.3078203074165358
Validation loss: 2.964524249146141

Epoch: 5| Step: 5
Training loss: 3.544445667911054
Validation loss: 2.963319049306022

Epoch: 5| Step: 6
Training loss: 2.814156023554566
Validation loss: 2.962580335351735

Epoch: 5| Step: 7
Training loss: 3.255703543061428
Validation loss: 2.9623612014089282

Epoch: 5| Step: 8
Training loss: 2.8194025743337305
Validation loss: 2.9628733891730796

Epoch: 5| Step: 9
Training loss: 3.7434248182803387
Validation loss: 2.9610683901312105

Epoch: 5| Step: 10
Training loss: 3.0632695379522183
Validation loss: 2.9642139661792224

Epoch: 93| Step: 0
Training loss: 3.2133901468638872
Validation loss: 2.9682205652099145

Epoch: 5| Step: 1
Training loss: 3.7113182113510237
Validation loss: 2.9622777726466807

Epoch: 5| Step: 2
Training loss: 3.4378509342350068
Validation loss: 2.961635617151061

Epoch: 5| Step: 3
Training loss: 3.414444891074473
Validation loss: 2.9603468925827428

Epoch: 5| Step: 4
Training loss: 2.5438421246766754
Validation loss: 2.959111806401909

Epoch: 5| Step: 5
Training loss: 2.4356108949961057
Validation loss: 2.9576712206369398

Epoch: 5| Step: 6
Training loss: 2.7679086513385047
Validation loss: 2.9588903179806043

Epoch: 5| Step: 7
Training loss: 3.645741023756993
Validation loss: 2.9589476674725512

Epoch: 5| Step: 8
Training loss: 3.724114531684677
Validation loss: 2.96015887253406

Epoch: 5| Step: 9
Training loss: 3.212522686236242
Validation loss: 2.9623911883875613

Epoch: 5| Step: 10
Training loss: 3.1931428515087767
Validation loss: 2.9646372365083384

Epoch: 94| Step: 0
Training loss: 2.441451757388375
Validation loss: 2.9611464774713854

Epoch: 5| Step: 1
Training loss: 3.106691976070316
Validation loss: 2.9676684997580725

Epoch: 5| Step: 2
Training loss: 2.9329015572977903
Validation loss: 2.9568251168425053

Epoch: 5| Step: 3
Training loss: 3.3156045724309613
Validation loss: 2.9554827843799476

Epoch: 5| Step: 4
Training loss: 3.218548962879489
Validation loss: 2.9632424717998096

Epoch: 5| Step: 5
Training loss: 3.511113777709571
Validation loss: 3.012379903113774

Epoch: 5| Step: 6
Training loss: 3.958003475432487
Validation loss: 3.007641206319055

Epoch: 5| Step: 7
Training loss: 2.689990818901419
Validation loss: 2.9606286422257955

Epoch: 5| Step: 8
Training loss: 3.4646136391316467
Validation loss: 2.9533314999202216

Epoch: 5| Step: 9
Training loss: 3.5265647391268646
Validation loss: 2.952084684220028

Epoch: 5| Step: 10
Training loss: 3.3674440927827707
Validation loss: 2.953369324974852

Epoch: 95| Step: 0
Training loss: 3.0952226620942627
Validation loss: 2.9792961444136226

Epoch: 5| Step: 1
Training loss: 3.2352006383640552
Validation loss: 2.990721961491169

Epoch: 5| Step: 2
Training loss: 2.121083296439192
Validation loss: 2.970056816342909

Epoch: 5| Step: 3
Training loss: 3.5409807475960937
Validation loss: 2.983129817872414

Epoch: 5| Step: 4
Training loss: 3.4007723099433087
Validation loss: 2.992848922968929

Epoch: 5| Step: 5
Training loss: 2.979588689901062
Validation loss: 3.000560732021959

Epoch: 5| Step: 6
Training loss: 3.511465366884194
Validation loss: 2.9765276732563355

Epoch: 5| Step: 7
Training loss: 3.6660261606218483
Validation loss: 2.9496430509399887

Epoch: 5| Step: 8
Training loss: 3.499489610787656
Validation loss: 2.94803308923554

Epoch: 5| Step: 9
Training loss: 3.5554882447176217
Validation loss: 2.947982939238968

Epoch: 5| Step: 10
Training loss: 2.606415126335599
Validation loss: 2.9552709236806542

Epoch: 96| Step: 0
Training loss: 3.62127955020729
Validation loss: 2.95333430979808

Epoch: 5| Step: 1
Training loss: 3.3183560699751786
Validation loss: 2.9533339782031183

Epoch: 5| Step: 2
Training loss: 3.2027738052994934
Validation loss: 2.9579183040967325

Epoch: 5| Step: 3
Training loss: 2.9159668945819415
Validation loss: 2.956791626086803

Epoch: 5| Step: 4
Training loss: 3.293615384038281
Validation loss: 2.9576644788397277

Epoch: 5| Step: 5
Training loss: 2.745403436360738
Validation loss: 2.957288175856922

Epoch: 5| Step: 6
Training loss: 2.940788862829528
Validation loss: 2.955764930027719

Epoch: 5| Step: 7
Training loss: 3.1041064843268567
Validation loss: 2.9601121038229143

Epoch: 5| Step: 8
Training loss: 3.317952544817458
Validation loss: 2.9594374772303222

Epoch: 5| Step: 9
Training loss: 3.324472491646951
Validation loss: 2.9605680520877518

Epoch: 5| Step: 10
Training loss: 3.766130848698574
Validation loss: 2.962347786743813

Epoch: 97| Step: 0
Training loss: 3.427226997927728
Validation loss: 2.963244390695459

Epoch: 5| Step: 1
Training loss: 3.161033857444839
Validation loss: 2.9611791146924142

Epoch: 5| Step: 2
Training loss: 2.902725708011301
Validation loss: 2.964507380835308

Epoch: 5| Step: 3
Training loss: 3.683867783127795
Validation loss: 2.9668353881595815

Epoch: 5| Step: 4
Training loss: 3.4469106691370377
Validation loss: 2.9589335836278163

Epoch: 5| Step: 5
Training loss: 2.7358499091400823
Validation loss: 2.9518562122247225

Epoch: 5| Step: 6
Training loss: 3.604094105837203
Validation loss: 2.947646171508434

Epoch: 5| Step: 7
Training loss: 3.4068591771784464
Validation loss: 2.9440855702851145

Epoch: 5| Step: 8
Training loss: 3.0775034320480583
Validation loss: 2.9442971422242175

Epoch: 5| Step: 9
Training loss: 2.9321264262192885
Validation loss: 2.9389093474621433

Epoch: 5| Step: 10
Training loss: 2.9476335117687458
Validation loss: 2.9378797189267636

Epoch: 98| Step: 0
Training loss: 2.9969094569798003
Validation loss: 2.9379618326832233

Epoch: 5| Step: 1
Training loss: 3.3183707270167067
Validation loss: 2.938139903150173

Epoch: 5| Step: 2
Training loss: 3.4478580127963228
Validation loss: 2.937123121959154

Epoch: 5| Step: 3
Training loss: 3.156270093192926
Validation loss: 2.9379502455173347

Epoch: 5| Step: 4
Training loss: 3.1657448146247105
Validation loss: 2.9355715685923047

Epoch: 5| Step: 5
Training loss: 3.704795492811268
Validation loss: 2.9336234044610623

Epoch: 5| Step: 6
Training loss: 3.199238722369739
Validation loss: 2.9348424018264403

Epoch: 5| Step: 7
Training loss: 2.8531162157372645
Validation loss: 2.9345939118356057

Epoch: 5| Step: 8
Training loss: 3.339673275528652
Validation loss: 2.9329979668710022

Epoch: 5| Step: 9
Training loss: 3.0475832384991643
Validation loss: 2.9342517906987253

Epoch: 5| Step: 10
Training loss: 3.1341633536022
Validation loss: 2.9338851885972494

Epoch: 99| Step: 0
Training loss: 3.3435002884360534
Validation loss: 2.935189846158719

Epoch: 5| Step: 1
Training loss: 3.3300933032095443
Validation loss: 2.9371822990904017

Epoch: 5| Step: 2
Training loss: 3.031666992450324
Validation loss: 2.9362079568985067

Epoch: 5| Step: 3
Training loss: 3.137447590789164
Validation loss: 2.9368550507419786

Epoch: 5| Step: 4
Training loss: 3.3198039304907536
Validation loss: 2.9352239947636662

Epoch: 5| Step: 5
Training loss: 3.0066660888513432
Validation loss: 2.9346212953533413

Epoch: 5| Step: 6
Training loss: 3.8993131766391524
Validation loss: 2.9356262036060317

Epoch: 5| Step: 7
Training loss: 3.4263612088815196
Validation loss: 2.935958374866428

Epoch: 5| Step: 8
Training loss: 3.1797249906611973
Validation loss: 2.9363654168166406

Epoch: 5| Step: 9
Training loss: 2.7917426559202703
Validation loss: 2.9319108824218536

Epoch: 5| Step: 10
Training loss: 2.5922742575026354
Validation loss: 2.9385727298428943

Epoch: 100| Step: 0
Training loss: 3.1446857675060285
Validation loss: 2.929826879105013

Epoch: 5| Step: 1
Training loss: 4.387389378905614
Validation loss: 2.934783245649231

Epoch: 5| Step: 2
Training loss: 3.2214051193529145
Validation loss: 2.928341522688133

Epoch: 5| Step: 3
Training loss: 3.0072391904915254
Validation loss: 2.9264609318467083

Epoch: 5| Step: 4
Training loss: 2.8861311338984765
Validation loss: 2.923697314353406

Epoch: 5| Step: 5
Training loss: 3.406388586182328
Validation loss: 2.9251835478955397

Epoch: 5| Step: 6
Training loss: 3.142327905038041
Validation loss: 2.9255807349693423

Epoch: 5| Step: 7
Training loss: 2.9693048862087545
Validation loss: 2.9247011918165553

Epoch: 5| Step: 8
Training loss: 2.79506364698739
Validation loss: 2.9256880164962507

Epoch: 5| Step: 9
Training loss: 2.6214260112442576
Validation loss: 2.923682840173568

Epoch: 5| Step: 10
Training loss: 3.442614963359932
Validation loss: 2.9252804721173153

Epoch: 101| Step: 0
Training loss: 3.08604210784922
Validation loss: 2.925736613041074

Epoch: 5| Step: 1
Training loss: 2.957709089870526
Validation loss: 2.924000886464068

Epoch: 5| Step: 2
Training loss: 2.212608541638741
Validation loss: 2.9268307189106606

Epoch: 5| Step: 3
Training loss: 3.733663962119683
Validation loss: 2.929625256605261

Epoch: 5| Step: 4
Training loss: 2.905416061362645
Validation loss: 2.9250324485513817

Epoch: 5| Step: 5
Training loss: 2.725598883657896
Validation loss: 2.9296533901184123

Epoch: 5| Step: 6
Training loss: 3.3979963345117765
Validation loss: 2.934158720190884

Epoch: 5| Step: 7
Training loss: 3.5268451595987536
Validation loss: 2.938451546959033

Epoch: 5| Step: 8
Training loss: 3.8526068890575598
Validation loss: 2.9386698205078314

Epoch: 5| Step: 9
Training loss: 3.588462323039225
Validation loss: 2.9406298525814023

Epoch: 5| Step: 10
Training loss: 2.8375955573977207
Validation loss: 2.930444992308164

Epoch: 102| Step: 0
Training loss: 2.7408087326280355
Validation loss: 2.92858378172022

Epoch: 5| Step: 1
Training loss: 2.360930378547799
Validation loss: 2.925968071704967

Epoch: 5| Step: 2
Training loss: 3.8751600909234245
Validation loss: 2.9254622922253852

Epoch: 5| Step: 3
Training loss: 2.9086925128129715
Validation loss: 2.928318957665762

Epoch: 5| Step: 4
Training loss: 3.64918605142169
Validation loss: 2.9237587746740408

Epoch: 5| Step: 5
Training loss: 4.060762943686131
Validation loss: 2.9235162911953223

Epoch: 5| Step: 6
Training loss: 3.88964439198415
Validation loss: 2.9231960584421715

Epoch: 5| Step: 7
Training loss: 2.6174206985659088
Validation loss: 2.9176950607639043

Epoch: 5| Step: 8
Training loss: 2.6906218029184874
Validation loss: 2.9176948551591657

Epoch: 5| Step: 9
Training loss: 2.944060608499104
Validation loss: 2.9160462538506384

Epoch: 5| Step: 10
Training loss: 2.816389657869815
Validation loss: 2.9151843304893

Epoch: 103| Step: 0
Training loss: 3.551430352266122
Validation loss: 2.9174491339612483

Epoch: 5| Step: 1
Training loss: 2.8555253593375465
Validation loss: 2.9172221658265935

Epoch: 5| Step: 2
Training loss: 3.231983277220945
Validation loss: 2.9168835147695145

Epoch: 5| Step: 3
Training loss: 3.8693158698797543
Validation loss: 2.9160335123089514

Epoch: 5| Step: 4
Training loss: 2.910314691313987
Validation loss: 2.9178269374028836

Epoch: 5| Step: 5
Training loss: 2.929860997466866
Validation loss: 2.9158870654203546

Epoch: 5| Step: 6
Training loss: 3.4646371738993302
Validation loss: 2.9220598526580503

Epoch: 5| Step: 7
Training loss: 3.2515488381857245
Validation loss: 2.919834893723027

Epoch: 5| Step: 8
Training loss: 2.7286046640972654
Validation loss: 2.928025924006823

Epoch: 5| Step: 9
Training loss: 3.1136001174730707
Validation loss: 2.9253911412000364

Epoch: 5| Step: 10
Training loss: 3.056996909147777
Validation loss: 2.920234074194596

Epoch: 104| Step: 0
Training loss: 3.6898230008315873
Validation loss: 2.922188299461948

Epoch: 5| Step: 1
Training loss: 2.8306883265342972
Validation loss: 2.9127112773786257

Epoch: 5| Step: 2
Training loss: 3.0076441333761923
Validation loss: 2.9125032432918703

Epoch: 5| Step: 3
Training loss: 3.3304859079504663
Validation loss: 2.9108732236791344

Epoch: 5| Step: 4
Training loss: 3.383377133792178
Validation loss: 2.9151795183568425

Epoch: 5| Step: 5
Training loss: 2.9147320098439553
Validation loss: 2.9122513084420127

Epoch: 5| Step: 6
Training loss: 2.888663951561141
Validation loss: 2.908744405780768

Epoch: 5| Step: 7
Training loss: 2.799617424441433
Validation loss: 2.9097372447830896

Epoch: 5| Step: 8
Training loss: 4.041317927989924
Validation loss: 2.9121550870738613

Epoch: 5| Step: 9
Training loss: 3.0238163042940056
Validation loss: 2.9081870892166077

Epoch: 5| Step: 10
Training loss: 2.9134851451342545
Validation loss: 2.9091418122211867

Epoch: 105| Step: 0
Training loss: 3.308781966403391
Validation loss: 2.910273180386235

Epoch: 5| Step: 1
Training loss: 3.212863168338228
Validation loss: 2.906800067955236

Epoch: 5| Step: 2
Training loss: 3.0668145752219753
Validation loss: 2.908047316487736

Epoch: 5| Step: 3
Training loss: 2.8621894034912363
Validation loss: 2.910394168589194

Epoch: 5| Step: 4
Training loss: 3.1494640257664743
Validation loss: 2.9083371597459027

Epoch: 5| Step: 5
Training loss: 3.5733269251106456
Validation loss: 2.9110107664884954

Epoch: 5| Step: 6
Training loss: 3.389028990998905
Validation loss: 2.9108757178541165

Epoch: 5| Step: 7
Training loss: 2.7958184489627627
Validation loss: 2.912857571493486

Epoch: 5| Step: 8
Training loss: 3.58166661793416
Validation loss: 2.9104069991217685

Epoch: 5| Step: 9
Training loss: 2.8774620792067704
Validation loss: 2.9101518189244473

Epoch: 5| Step: 10
Training loss: 3.131013805747625
Validation loss: 2.9084517983498652

Epoch: 106| Step: 0
Training loss: 3.105521262822519
Validation loss: 2.9125912920260135

Epoch: 5| Step: 1
Training loss: 2.921813474609171
Validation loss: 2.908412298763064

Epoch: 5| Step: 2
Training loss: 3.7839504718886126
Validation loss: 2.9074168205508

Epoch: 5| Step: 3
Training loss: 3.1200210580359693
Validation loss: 2.9045007557455347

Epoch: 5| Step: 4
Training loss: 3.5197011417618023
Validation loss: 2.904385889252194

Epoch: 5| Step: 5
Training loss: 3.258690878006584
Validation loss: 2.9007492255308756

Epoch: 5| Step: 6
Training loss: 3.2688180015594837
Validation loss: 2.8990392732172565

Epoch: 5| Step: 7
Training loss: 2.9876872750165635
Validation loss: 2.9034661111826066

Epoch: 5| Step: 8
Training loss: 3.107643450420496
Validation loss: 2.901708882786514

Epoch: 5| Step: 9
Training loss: 3.096859380873201
Validation loss: 2.9022160573230114

Epoch: 5| Step: 10
Training loss: 2.6752078144956375
Validation loss: 2.9015885175672658

Epoch: 107| Step: 0
Training loss: 3.1431305413416335
Validation loss: 2.9030265234102695

Epoch: 5| Step: 1
Training loss: 3.386439117186249
Validation loss: 2.9019093281459725

Epoch: 5| Step: 2
Training loss: 2.932052756153641
Validation loss: 2.903936124145295

Epoch: 5| Step: 3
Training loss: 3.270611911414353
Validation loss: 2.901214531422094

Epoch: 5| Step: 4
Training loss: 3.252934671453702
Validation loss: 2.8986007246006977

Epoch: 5| Step: 5
Training loss: 3.2351381442777734
Validation loss: 2.8993382649775583

Epoch: 5| Step: 6
Training loss: 3.3475397327848464
Validation loss: 2.898539967305743

Epoch: 5| Step: 7
Training loss: 3.1788486433305674
Validation loss: 2.8979189776298315

Epoch: 5| Step: 8
Training loss: 3.014908463336385
Validation loss: 2.897605365477179

Epoch: 5| Step: 9
Training loss: 3.4463730475120053
Validation loss: 2.899390838202551

Epoch: 5| Step: 10
Training loss: 2.6627978234434466
Validation loss: 2.902178032863238

Epoch: 108| Step: 0
Training loss: 3.2241575870762382
Validation loss: 2.9052267206051265

Epoch: 5| Step: 1
Training loss: 3.7708913612467274
Validation loss: 2.9027676854389357

Epoch: 5| Step: 2
Training loss: 2.964528183860844
Validation loss: 2.9042770493528023

Epoch: 5| Step: 3
Training loss: 3.3101974257860607
Validation loss: 2.90112447521966

Epoch: 5| Step: 4
Training loss: 3.0691066247261576
Validation loss: 2.899370868482572

Epoch: 5| Step: 5
Training loss: 2.661344064149392
Validation loss: 2.896257259855079

Epoch: 5| Step: 6
Training loss: 3.3128346687973496
Validation loss: 2.8955340056261916

Epoch: 5| Step: 7
Training loss: 3.0126226629712924
Validation loss: 2.893440793899263

Epoch: 5| Step: 8
Training loss: 3.104903950702955
Validation loss: 2.893896382157909

Epoch: 5| Step: 9
Training loss: 3.235948704986108
Validation loss: 2.8937572533641425

Epoch: 5| Step: 10
Training loss: 3.2251308858171717
Validation loss: 2.894879917561222

Epoch: 109| Step: 0
Training loss: 2.7271778538125604
Validation loss: 2.8923067645541094

Epoch: 5| Step: 1
Training loss: 3.9148686658088834
Validation loss: 2.893204196154549

Epoch: 5| Step: 2
Training loss: 2.8326095516772902
Validation loss: 2.891281047274294

Epoch: 5| Step: 3
Training loss: 2.7390998345989774
Validation loss: 2.891780806005153

Epoch: 5| Step: 4
Training loss: 3.295173097269216
Validation loss: 2.897133587897363

Epoch: 5| Step: 5
Training loss: 3.1844572616299094
Validation loss: 2.9044747118888052

Epoch: 5| Step: 6
Training loss: 4.134548349127089
Validation loss: 2.8991731939930956

Epoch: 5| Step: 7
Training loss: 2.599729975103362
Validation loss: 2.8927722426592566

Epoch: 5| Step: 8
Training loss: 3.172490252877391
Validation loss: 2.8925578716072238

Epoch: 5| Step: 9
Training loss: 3.0283009449457263
Validation loss: 2.891186162993661

Epoch: 5| Step: 10
Training loss: 2.92226158481416
Validation loss: 2.8933492083128405

Epoch: 110| Step: 0
Training loss: 3.5020286947629184
Validation loss: 2.896183751551987

Epoch: 5| Step: 1
Training loss: 3.1508066809602413
Validation loss: 2.8935539326422757

Epoch: 5| Step: 2
Training loss: 3.2554412188829414
Validation loss: 2.890665563882438

Epoch: 5| Step: 3
Training loss: 3.7934331167692106
Validation loss: 2.890491865440698

Epoch: 5| Step: 4
Training loss: 2.7290477192901186
Validation loss: 2.8911293616340226

Epoch: 5| Step: 5
Training loss: 2.705194640146372
Validation loss: 2.8896129518241565

Epoch: 5| Step: 6
Training loss: 3.173750149282517
Validation loss: 2.886944262306095

Epoch: 5| Step: 7
Training loss: 2.9069268863749382
Validation loss: 2.8886267728770054

Epoch: 5| Step: 8
Training loss: 3.2854294090693137
Validation loss: 2.888573069192613

Epoch: 5| Step: 9
Training loss: 2.853253257851883
Validation loss: 2.8868790886067677

Epoch: 5| Step: 10
Training loss: 3.479087889611318
Validation loss: 2.893022258340874

Epoch: 111| Step: 0
Training loss: 3.3644227894055736
Validation loss: 2.887011826782992

Epoch: 5| Step: 1
Training loss: 3.1234068815134144
Validation loss: 2.892923587825183

Epoch: 5| Step: 2
Training loss: 3.0578977297140963
Validation loss: 2.8997653981563922

Epoch: 5| Step: 3
Training loss: 3.202124760462556
Validation loss: 2.903480744420109

Epoch: 5| Step: 4
Training loss: 3.237474219024401
Validation loss: 2.8976737673697297

Epoch: 5| Step: 5
Training loss: 2.790997685988098
Validation loss: 2.8916756567183297

Epoch: 5| Step: 6
Training loss: 3.2590319503243386
Validation loss: 2.8897774342589293

Epoch: 5| Step: 7
Training loss: 3.4189602356590196
Validation loss: 2.88604425168378

Epoch: 5| Step: 8
Training loss: 3.1984061861578543
Validation loss: 2.8840086881561238

Epoch: 5| Step: 9
Training loss: 3.0582485661898935
Validation loss: 2.883361920564697

Epoch: 5| Step: 10
Training loss: 3.159792281458212
Validation loss: 2.883684034309361

Epoch: 112| Step: 0
Training loss: 3.019231191632299
Validation loss: 2.8853893015889076

Epoch: 5| Step: 1
Training loss: 2.802817823915575
Validation loss: 2.8814023545162355

Epoch: 5| Step: 2
Training loss: 3.4845628901573042
Validation loss: 2.8834383852280263

Epoch: 5| Step: 3
Training loss: 3.072218131288177
Validation loss: 2.882290980809422

Epoch: 5| Step: 4
Training loss: 3.352642463314036
Validation loss: 2.8794223929755183

Epoch: 5| Step: 5
Training loss: 3.4152433330475565
Validation loss: 2.8833835348718764

Epoch: 5| Step: 6
Training loss: 3.2891963106966258
Validation loss: 2.8812723742029993

Epoch: 5| Step: 7
Training loss: 2.925655754463934
Validation loss: 2.8823752696551415

Epoch: 5| Step: 8
Training loss: 3.2011288261195574
Validation loss: 2.8814539142052302

Epoch: 5| Step: 9
Training loss: 3.0657896162937393
Validation loss: 2.87754426796487

Epoch: 5| Step: 10
Training loss: 3.2309146375038176
Validation loss: 2.8779314779940823

Epoch: 113| Step: 0
Training loss: 3.2404380398621337
Validation loss: 2.875956625416386

Epoch: 5| Step: 1
Training loss: 3.2837481480343826
Validation loss: 2.8787941919704934

Epoch: 5| Step: 2
Training loss: 2.7339618479725414
Validation loss: 2.878494868891258

Epoch: 5| Step: 3
Training loss: 2.7138014734307343
Validation loss: 2.876256326730662

Epoch: 5| Step: 4
Training loss: 3.773827447744091
Validation loss: 2.8797623335512004

Epoch: 5| Step: 5
Training loss: 3.5045936956280035
Validation loss: 2.877158552656778

Epoch: 5| Step: 6
Training loss: 3.3035407635653726
Validation loss: 2.876658034209445

Epoch: 5| Step: 7
Training loss: 2.572698164296382
Validation loss: 2.8754816753051133

Epoch: 5| Step: 8
Training loss: 2.7844377743958333
Validation loss: 2.875809021091108

Epoch: 5| Step: 9
Training loss: 3.0835177048554834
Validation loss: 2.878718761662005

Epoch: 5| Step: 10
Training loss: 3.629516944375893
Validation loss: 2.8809212633385077

Epoch: 114| Step: 0
Training loss: 3.1604533391814322
Validation loss: 2.8805278247881505

Epoch: 5| Step: 1
Training loss: 3.0181036531661536
Validation loss: 2.8770560545172144

Epoch: 5| Step: 2
Training loss: 3.572443019660796
Validation loss: 2.8737289094210103

Epoch: 5| Step: 3
Training loss: 3.3467896807683273
Validation loss: 2.871762036427467

Epoch: 5| Step: 4
Training loss: 3.430255399709877
Validation loss: 2.8723502617330796

Epoch: 5| Step: 5
Training loss: 2.549483104750826
Validation loss: 2.8716816560093132

Epoch: 5| Step: 6
Training loss: 3.056933735696755
Validation loss: 2.8745850811595037

Epoch: 5| Step: 7
Training loss: 3.4168737085150522
Validation loss: 2.8741218943320286

Epoch: 5| Step: 8
Training loss: 2.7685549458498557
Validation loss: 2.8703235795595115

Epoch: 5| Step: 9
Training loss: 3.251729358386154
Validation loss: 2.870831165830542

Epoch: 5| Step: 10
Training loss: 3.0825618775430668
Validation loss: 2.8710232035469456

Epoch: 115| Step: 0
Training loss: 2.9732038316907023
Validation loss: 2.8748660651598463

Epoch: 5| Step: 1
Training loss: 2.8766841102268663
Validation loss: 2.8764701943463318

Epoch: 5| Step: 2
Training loss: 3.1719781266909854
Validation loss: 2.8819792373309094

Epoch: 5| Step: 3
Training loss: 3.089142730705227
Validation loss: 2.876252281064453

Epoch: 5| Step: 4
Training loss: 3.5577979930637214
Validation loss: 2.8728563128918783

Epoch: 5| Step: 5
Training loss: 2.96243594458497
Validation loss: 2.871744804462203

Epoch: 5| Step: 6
Training loss: 3.489735401692817
Validation loss: 2.867140822416084

Epoch: 5| Step: 7
Training loss: 3.1381148750280112
Validation loss: 2.8685580805727793

Epoch: 5| Step: 8
Training loss: 3.076134982417662
Validation loss: 2.8689459386871246

Epoch: 5| Step: 9
Training loss: 2.6895630480894916
Validation loss: 2.868108246076193

Epoch: 5| Step: 10
Training loss: 3.736806038314132
Validation loss: 2.8683990469739213

Epoch: 116| Step: 0
Training loss: 3.3042713381209685
Validation loss: 2.869346062507307

Epoch: 5| Step: 1
Training loss: 3.4819179476251505
Validation loss: 2.871084948530359

Epoch: 5| Step: 2
Training loss: 3.339330444152927
Validation loss: 2.869795132148389

Epoch: 5| Step: 3
Training loss: 3.2643253350245747
Validation loss: 2.8667405374609793

Epoch: 5| Step: 4
Training loss: 3.392305300585484
Validation loss: 2.8683020060859876

Epoch: 5| Step: 5
Training loss: 2.691085464118375
Validation loss: 2.8651298871132136

Epoch: 5| Step: 6
Training loss: 2.5876560551120593
Validation loss: 2.8649355447915625

Epoch: 5| Step: 7
Training loss: 2.7433293674049435
Validation loss: 2.865238608907924

Epoch: 5| Step: 8
Training loss: 3.0065812402277365
Validation loss: 2.8632359896685626

Epoch: 5| Step: 9
Training loss: 3.004541615134934
Validation loss: 2.864912391773005

Epoch: 5| Step: 10
Training loss: 3.796917699251931
Validation loss: 2.865999232018663

Epoch: 117| Step: 0
Training loss: 2.6689546922001757
Validation loss: 2.8660572103364768

Epoch: 5| Step: 1
Training loss: 2.510688724786929
Validation loss: 2.867638129755243

Epoch: 5| Step: 2
Training loss: 3.079630836805512
Validation loss: 2.8745894850116787

Epoch: 5| Step: 3
Training loss: 3.7878495310029203
Validation loss: 2.877536730833844

Epoch: 5| Step: 4
Training loss: 2.6356129227692393
Validation loss: 2.8761330048875253

Epoch: 5| Step: 5
Training loss: 3.5817093532948054
Validation loss: 2.88611302573238

Epoch: 5| Step: 6
Training loss: 3.5426566292454615
Validation loss: 2.8746646205752056

Epoch: 5| Step: 7
Training loss: 2.7505460543789337
Validation loss: 2.866983899189328

Epoch: 5| Step: 8
Training loss: 2.63708258485133
Validation loss: 2.861152916101835

Epoch: 5| Step: 9
Training loss: 3.7494750609147776
Validation loss: 2.8598918477938846

Epoch: 5| Step: 10
Training loss: 3.3775646214264534
Validation loss: 2.8581034904416467

Epoch: 118| Step: 0
Training loss: 2.8269505881223935
Validation loss: 2.859344670541515

Epoch: 5| Step: 1
Training loss: 3.1030715615088105
Validation loss: 2.8618027697663786

Epoch: 5| Step: 2
Training loss: 3.1883041265106753
Validation loss: 2.8580288595496044

Epoch: 5| Step: 3
Training loss: 3.542079018916026
Validation loss: 2.856487471040902

Epoch: 5| Step: 4
Training loss: 3.132447942132232
Validation loss: 2.8593623062803295

Epoch: 5| Step: 5
Training loss: 2.8750502540508522
Validation loss: 2.8588959384327945

Epoch: 5| Step: 6
Training loss: 3.203193477736015
Validation loss: 2.8572087331947484

Epoch: 5| Step: 7
Training loss: 2.964418001226975
Validation loss: 2.8568983401867203

Epoch: 5| Step: 8
Training loss: 2.7943661481819055
Validation loss: 2.857077790396918

Epoch: 5| Step: 9
Training loss: 3.725196316045453
Validation loss: 2.8565218712456524

Epoch: 5| Step: 10
Training loss: 3.1581246125058513
Validation loss: 2.858706726991853

Epoch: 119| Step: 0
Training loss: 2.8504091203405015
Validation loss: 2.857094492590841

Epoch: 5| Step: 1
Training loss: 3.3357771180525897
Validation loss: 2.855652312833556

Epoch: 5| Step: 2
Training loss: 3.858906705916304
Validation loss: 2.858333806693468

Epoch: 5| Step: 3
Training loss: 2.783812810140412
Validation loss: 2.864846390236275

Epoch: 5| Step: 4
Training loss: 3.559381960894683
Validation loss: 2.864576156174664

Epoch: 5| Step: 5
Training loss: 3.045365179554541
Validation loss: 2.8694929155726143

Epoch: 5| Step: 6
Training loss: 3.2730913730341333
Validation loss: 2.8578983014815735

Epoch: 5| Step: 7
Training loss: 3.173540551875683
Validation loss: 2.852108165380254

Epoch: 5| Step: 8
Training loss: 2.6417336929755146
Validation loss: 2.8500268360998064

Epoch: 5| Step: 9
Training loss: 3.0657325344687836
Validation loss: 2.8516904524931217

Epoch: 5| Step: 10
Training loss: 2.829634964116638
Validation loss: 2.8503488054466244

Epoch: 120| Step: 0
Training loss: 3.4276929195320798
Validation loss: 2.854675084810616

Epoch: 5| Step: 1
Training loss: 3.036198303360487
Validation loss: 2.858498195731146

Epoch: 5| Step: 2
Training loss: 2.63119303082117
Validation loss: 2.8587878954953747

Epoch: 5| Step: 3
Training loss: 3.3843077423091006
Validation loss: 2.851697440332292

Epoch: 5| Step: 4
Training loss: 3.0762893702759584
Validation loss: 2.853793999618308

Epoch: 5| Step: 5
Training loss: 2.768518173811244
Validation loss: 2.856378748233588

Epoch: 5| Step: 6
Training loss: 3.393745498232727
Validation loss: 2.8524008518299038

Epoch: 5| Step: 7
Training loss: 3.1510193038441137
Validation loss: 2.85205689674783

Epoch: 5| Step: 8
Training loss: 2.9318592211140766
Validation loss: 2.8456393220716834

Epoch: 5| Step: 9
Training loss: 3.53141959804289
Validation loss: 2.8515347171362184

Epoch: 5| Step: 10
Training loss: 3.106825506982161
Validation loss: 2.846942763107808

Epoch: 121| Step: 0
Training loss: 3.1260269003678984
Validation loss: 2.848979826515396

Epoch: 5| Step: 1
Training loss: 3.885379794493833
Validation loss: 2.848952373907763

Epoch: 5| Step: 2
Training loss: 3.171395852866465
Validation loss: 2.844506758144103

Epoch: 5| Step: 3
Training loss: 2.957873850497026
Validation loss: 2.846412678730468

Epoch: 5| Step: 4
Training loss: 2.6857437782929257
Validation loss: 2.848595838519028

Epoch: 5| Step: 5
Training loss: 2.817147209061318
Validation loss: 2.8476235828556877

Epoch: 5| Step: 6
Training loss: 3.3732378562663987
Validation loss: 2.8519568412948657

Epoch: 5| Step: 7
Training loss: 3.439958560161718
Validation loss: 2.8453580881784846

Epoch: 5| Step: 8
Training loss: 2.955490376017478
Validation loss: 2.84523963969861

Epoch: 5| Step: 9
Training loss: 3.2424716319399844
Validation loss: 2.845910610211021

Epoch: 5| Step: 10
Training loss: 2.612871306101729
Validation loss: 2.8497226418213115

Epoch: 122| Step: 0
Training loss: 2.996356340859867
Validation loss: 2.853150325930013

Epoch: 5| Step: 1
Training loss: 3.0465842083791346
Validation loss: 2.8503965332947843

Epoch: 5| Step: 2
Training loss: 2.7591392200348768
Validation loss: 2.846381623918222

Epoch: 5| Step: 3
Training loss: 3.1093803674086056
Validation loss: 2.8467773267657903

Epoch: 5| Step: 4
Training loss: 3.286191579851562
Validation loss: 2.841948250244217

Epoch: 5| Step: 5
Training loss: 3.1915230887233905
Validation loss: 2.8429262071712524

Epoch: 5| Step: 6
Training loss: 3.085491061209893
Validation loss: 2.8419177600625964

Epoch: 5| Step: 7
Training loss: 3.0226630271190826
Validation loss: 2.839238653819445

Epoch: 5| Step: 8
Training loss: 2.6996951531576507
Validation loss: 2.8386020069570987

Epoch: 5| Step: 9
Training loss: 3.205857762665992
Validation loss: 2.839109637194839

Epoch: 5| Step: 10
Training loss: 4.045129112191817
Validation loss: 2.83839634755436

Epoch: 123| Step: 0
Training loss: 3.161933088189409
Validation loss: 2.8373104071691673

Epoch: 5| Step: 1
Training loss: 2.222161370344933
Validation loss: 2.8372767137365837

Epoch: 5| Step: 2
Training loss: 3.354498868488616
Validation loss: 2.837311993795603

Epoch: 5| Step: 3
Training loss: 3.111834602775626
Validation loss: 2.837002327318115

Epoch: 5| Step: 4
Training loss: 3.2975422694668977
Validation loss: 2.8380869818581616

Epoch: 5| Step: 5
Training loss: 3.1577007623125217
Validation loss: 2.8401500160257327

Epoch: 5| Step: 6
Training loss: 3.1674066649357013
Validation loss: 2.8348676706099907

Epoch: 5| Step: 7
Training loss: 3.3282182707275947
Validation loss: 2.8340017307268193

Epoch: 5| Step: 8
Training loss: 2.9082108312418886
Validation loss: 2.837004285514372

Epoch: 5| Step: 9
Training loss: 3.305511011274096
Validation loss: 2.8356135335935853

Epoch: 5| Step: 10
Training loss: 3.2993536576283344
Validation loss: 2.834231526233644

Epoch: 124| Step: 0
Training loss: 2.869426798717514
Validation loss: 2.8356906665141204

Epoch: 5| Step: 1
Training loss: 2.818744424277329
Validation loss: 2.8458249503677497

Epoch: 5| Step: 2
Training loss: 3.35600686782116
Validation loss: 2.8462518502254794

Epoch: 5| Step: 3
Training loss: 3.1914220877246247
Validation loss: 2.848785570323559

Epoch: 5| Step: 4
Training loss: 3.5811144738242855
Validation loss: 2.84786792286157

Epoch: 5| Step: 5
Training loss: 3.038209927958438
Validation loss: 2.8435289670481048

Epoch: 5| Step: 6
Training loss: 3.28899581007953
Validation loss: 2.8412662095346746

Epoch: 5| Step: 7
Training loss: 2.6408438507220535
Validation loss: 2.8368605302556418

Epoch: 5| Step: 8
Training loss: 3.367538256863311
Validation loss: 2.836235170655846

Epoch: 5| Step: 9
Training loss: 2.944319742389125
Validation loss: 2.837287297077509

Epoch: 5| Step: 10
Training loss: 3.244182809168466
Validation loss: 2.8350906140358663

Epoch: 125| Step: 0
Training loss: 2.564043278131028
Validation loss: 2.834541881605169

Epoch: 5| Step: 1
Training loss: 3.4198714012373297
Validation loss: 2.835823856152407

Epoch: 5| Step: 2
Training loss: 2.933691762208814
Validation loss: 2.83440467014045

Epoch: 5| Step: 3
Training loss: 3.3295583011617262
Validation loss: 2.8322471717951845

Epoch: 5| Step: 4
Training loss: 3.258285963749932
Validation loss: 2.830114050984293

Epoch: 5| Step: 5
Training loss: 3.01679203201492
Validation loss: 2.828691290669304

Epoch: 5| Step: 6
Training loss: 3.092794868146859
Validation loss: 2.8284304439218606

Epoch: 5| Step: 7
Training loss: 3.6573492500699607
Validation loss: 2.828617055634563

Epoch: 5| Step: 8
Training loss: 3.1107036876325873
Validation loss: 2.8302684242598004

Epoch: 5| Step: 9
Training loss: 3.120727059185037
Validation loss: 2.8315008186228083

Epoch: 5| Step: 10
Training loss: 2.7276275216142474
Validation loss: 2.8344790819123573

Epoch: 126| Step: 0
Training loss: 2.9122609969540645
Validation loss: 2.8332282329757406

Epoch: 5| Step: 1
Training loss: 2.9965291608323703
Validation loss: 2.8421297646953425

Epoch: 5| Step: 2
Training loss: 3.6361770636205946
Validation loss: 2.8410882601205754

Epoch: 5| Step: 3
Training loss: 2.864984731583579
Validation loss: 2.841652510547631

Epoch: 5| Step: 4
Training loss: 3.399685755400583
Validation loss: 2.8336885478126974

Epoch: 5| Step: 5
Training loss: 3.2669688111011284
Validation loss: 2.828665227197022

Epoch: 5| Step: 6
Training loss: 3.62572735033534
Validation loss: 2.8286861175087767

Epoch: 5| Step: 7
Training loss: 2.8301674227845974
Validation loss: 2.825039685567974

Epoch: 5| Step: 8
Training loss: 2.7404944255001706
Validation loss: 2.8284363027740524

Epoch: 5| Step: 9
Training loss: 2.7753179488307373
Validation loss: 2.825666927717173

Epoch: 5| Step: 10
Training loss: 3.1660287281402972
Validation loss: 2.8259110669470404

Epoch: 127| Step: 0
Training loss: 3.1629342787430708
Validation loss: 2.824783498613711

Epoch: 5| Step: 1
Training loss: 3.243188910201035
Validation loss: 2.82252131749867

Epoch: 5| Step: 2
Training loss: 2.7284615360433824
Validation loss: 2.8235098257210898

Epoch: 5| Step: 3
Training loss: 3.761621016424118
Validation loss: 2.824427453584432

Epoch: 5| Step: 4
Training loss: 3.05827663136929
Validation loss: 2.818919833576909

Epoch: 5| Step: 5
Training loss: 2.5902647018670746
Validation loss: 2.824404274841557

Epoch: 5| Step: 6
Training loss: 2.6238720604945183
Validation loss: 2.8249406134435957

Epoch: 5| Step: 7
Training loss: 3.2995834434468474
Validation loss: 2.822890269558637

Epoch: 5| Step: 8
Training loss: 3.654718844640997
Validation loss: 2.8231248143523198

Epoch: 5| Step: 9
Training loss: 2.8166922795713116
Validation loss: 2.8255539368709566

Epoch: 5| Step: 10
Training loss: 3.168750294943049
Validation loss: 2.8204393005817856

Epoch: 128| Step: 0
Training loss: 3.083578787304162
Validation loss: 2.8198119338460983

Epoch: 5| Step: 1
Training loss: 3.031598100633098
Validation loss: 2.822064170228801

Epoch: 5| Step: 2
Training loss: 2.7900677747253804
Validation loss: 2.820218214169552

Epoch: 5| Step: 3
Training loss: 3.473071731068264
Validation loss: 2.8195202188173143

Epoch: 5| Step: 4
Training loss: 2.788169482794907
Validation loss: 2.824286010505873

Epoch: 5| Step: 5
Training loss: 3.4835907605216763
Validation loss: 2.818010176003914

Epoch: 5| Step: 6
Training loss: 2.7572926147443937
Validation loss: 2.819095771226973

Epoch: 5| Step: 7
Training loss: 3.4217244990447844
Validation loss: 2.822300575852633

Epoch: 5| Step: 8
Training loss: 3.277165804773249
Validation loss: 2.8193700271964754

Epoch: 5| Step: 9
Training loss: 3.2141937303248493
Validation loss: 2.817396590731134

Epoch: 5| Step: 10
Training loss: 2.8145805292988517
Validation loss: 2.815849510072865

Epoch: 129| Step: 0
Training loss: 3.000547359123949
Validation loss: 2.8188482314859598

Epoch: 5| Step: 1
Training loss: 3.5556084079258077
Validation loss: 2.817982461720614

Epoch: 5| Step: 2
Training loss: 3.2461799766206423
Validation loss: 2.8183521607816564

Epoch: 5| Step: 3
Training loss: 3.014424772031605
Validation loss: 2.817716773223717

Epoch: 5| Step: 4
Training loss: 3.337581184914242
Validation loss: 2.8168404943170517

Epoch: 5| Step: 5
Training loss: 2.963414587817086
Validation loss: 2.8173928327075313

Epoch: 5| Step: 6
Training loss: 2.4281056642683008
Validation loss: 2.817215779527778

Epoch: 5| Step: 7
Training loss: 2.791578851334014
Validation loss: 2.8171325104926965

Epoch: 5| Step: 8
Training loss: 3.1790509910753904
Validation loss: 2.817854317825679

Epoch: 5| Step: 9
Training loss: 3.5972768974976765
Validation loss: 2.8143070445456724

Epoch: 5| Step: 10
Training loss: 2.946929892294708
Validation loss: 2.8165094834772226

Epoch: 130| Step: 0
Training loss: 3.0885550298717988
Validation loss: 2.812603203669979

Epoch: 5| Step: 1
Training loss: 3.3684572450048673
Validation loss: 2.811609858818147

Epoch: 5| Step: 2
Training loss: 3.3799935592499715
Validation loss: 2.8250117081089083

Epoch: 5| Step: 3
Training loss: 3.4852355441778795
Validation loss: 2.8356167214016885

Epoch: 5| Step: 4
Training loss: 3.1928150518025764
Validation loss: 2.858347494257171

Epoch: 5| Step: 5
Training loss: 3.0502252401762244
Validation loss: 2.8433177736268207

Epoch: 5| Step: 6
Training loss: 3.008725510780063
Validation loss: 2.8315033528360707

Epoch: 5| Step: 7
Training loss: 2.9349587994206794
Validation loss: 2.82182217384999

Epoch: 5| Step: 8
Training loss: 2.6143311357386385
Validation loss: 2.817784195300425

Epoch: 5| Step: 9
Training loss: 2.7061799707668532
Validation loss: 2.8084461561824168

Epoch: 5| Step: 10
Training loss: 3.321128260312714
Validation loss: 2.806904563459412

Epoch: 131| Step: 0
Training loss: 3.8867544508018046
Validation loss: 2.8128262894566594

Epoch: 5| Step: 1
Training loss: 2.4002982510577224
Validation loss: 2.809597391657322

Epoch: 5| Step: 2
Training loss: 3.178528520591467
Validation loss: 2.810357258136392

Epoch: 5| Step: 3
Training loss: 2.6589301556455593
Validation loss: 2.8122807862819856

Epoch: 5| Step: 4
Training loss: 2.8131552886518847
Validation loss: 2.810297021418863

Epoch: 5| Step: 5
Training loss: 2.604571094898142
Validation loss: 2.8091077667223496

Epoch: 5| Step: 6
Training loss: 3.301289572314279
Validation loss: 2.809354646259897

Epoch: 5| Step: 7
Training loss: 3.480977407634726
Validation loss: 2.808010214298546

Epoch: 5| Step: 8
Training loss: 3.023286406613031
Validation loss: 2.808354420505315

Epoch: 5| Step: 9
Training loss: 2.957039312757337
Validation loss: 2.807616709034555

Epoch: 5| Step: 10
Training loss: 3.6409655235730614
Validation loss: 2.805175088059336

Epoch: 132| Step: 0
Training loss: 3.1704477190159865
Validation loss: 2.806903372471966

Epoch: 5| Step: 1
Training loss: 2.5423876776776546
Validation loss: 2.8057338593028476

Epoch: 5| Step: 2
Training loss: 3.3956639690329165
Validation loss: 2.8059010138831653

Epoch: 5| Step: 3
Training loss: 2.805535828381501
Validation loss: 2.8041245195432496

Epoch: 5| Step: 4
Training loss: 3.211385950853898
Validation loss: 2.8018602690400365

Epoch: 5| Step: 5
Training loss: 3.2853481313797404
Validation loss: 2.804305873142934

Epoch: 5| Step: 6
Training loss: 2.9261857327423497
Validation loss: 2.807635924288812

Epoch: 5| Step: 7
Training loss: 3.1533839744173724
Validation loss: 2.809458172610788

Epoch: 5| Step: 8
Training loss: 3.16788400708366
Validation loss: 2.807494630112011

Epoch: 5| Step: 9
Training loss: 3.011174371703133
Validation loss: 2.8116116031010527

Epoch: 5| Step: 10
Training loss: 3.462074248101163
Validation loss: 2.8135157420168997

Epoch: 133| Step: 0
Training loss: 3.132925588036419
Validation loss: 2.8084871904373654

Epoch: 5| Step: 1
Training loss: 2.8761219654988217
Validation loss: 2.8026687560078916

Epoch: 5| Step: 2
Training loss: 3.540937251356199
Validation loss: 2.80703754170163

Epoch: 5| Step: 3
Training loss: 2.5488444009897
Validation loss: 2.8068616236586363

Epoch: 5| Step: 4
Training loss: 3.2861259925170687
Validation loss: 2.8010274859764395

Epoch: 5| Step: 5
Training loss: 3.2221543169722353
Validation loss: 2.799154898122759

Epoch: 5| Step: 6
Training loss: 3.011589077187727
Validation loss: 2.7981591410648043

Epoch: 5| Step: 7
Training loss: 2.457392097502537
Validation loss: 2.80238686536333

Epoch: 5| Step: 8
Training loss: 3.1039639263809775
Validation loss: 2.8005682124427813

Epoch: 5| Step: 9
Training loss: 3.180651319488213
Validation loss: 2.800400939119281

Epoch: 5| Step: 10
Training loss: 3.6420407141683175
Validation loss: 2.800853836602495

Epoch: 134| Step: 0
Training loss: 2.9682375817024256
Validation loss: 2.802822672552949

Epoch: 5| Step: 1
Training loss: 2.940591362366557
Validation loss: 2.7998417316993747

Epoch: 5| Step: 2
Training loss: 3.43463820194312
Validation loss: 2.8009337005609782

Epoch: 5| Step: 3
Training loss: 2.8814952290866325
Validation loss: 2.7989062588384908

Epoch: 5| Step: 4
Training loss: 2.844915130368395
Validation loss: 2.8016163344239464

Epoch: 5| Step: 5
Training loss: 3.5968774870094165
Validation loss: 2.802655768866975

Epoch: 5| Step: 6
Training loss: 3.579312456482783
Validation loss: 2.8144513587951527

Epoch: 5| Step: 7
Training loss: 3.2033307265298525
Validation loss: 2.8250588140773116

Epoch: 5| Step: 8
Training loss: 3.436960212634831
Validation loss: 2.8297743700566764

Epoch: 5| Step: 9
Training loss: 2.437756549343262
Validation loss: 2.8337781425471946

Epoch: 5| Step: 10
Training loss: 2.467010464637188
Validation loss: 2.840134332565783

Epoch: 135| Step: 0
Training loss: 2.8566257621955415
Validation loss: 2.851566818038496

Epoch: 5| Step: 1
Training loss: 3.0914408996352334
Validation loss: 2.8659098126749543

Epoch: 5| Step: 2
Training loss: 3.118445121219878
Validation loss: 2.8674514450967683

Epoch: 5| Step: 3
Training loss: 3.4571773174914875
Validation loss: 2.8756843704687056

Epoch: 5| Step: 4
Training loss: 2.7185945137549488
Validation loss: 2.858637636173006

Epoch: 5| Step: 5
Training loss: 3.6183627960772045
Validation loss: 2.833057283951936

Epoch: 5| Step: 6
Training loss: 2.5522069991894125
Validation loss: 2.818703965906046

Epoch: 5| Step: 7
Training loss: 3.5807292406486733
Validation loss: 2.799484334579853

Epoch: 5| Step: 8
Training loss: 3.359198987031381
Validation loss: 2.797973369476789

Epoch: 5| Step: 9
Training loss: 3.411637830986656
Validation loss: 2.8081323780767105

Epoch: 5| Step: 10
Training loss: 2.1574026150787393
Validation loss: 2.8120642521606167

Epoch: 136| Step: 0
Training loss: 3.486771789872179
Validation loss: 2.813286525263246

Epoch: 5| Step: 1
Training loss: 3.084478955898763
Validation loss: 2.814496124777795

Epoch: 5| Step: 2
Training loss: 3.015428605874134
Validation loss: 2.818613622787952

Epoch: 5| Step: 3
Training loss: 2.8921519602400916
Validation loss: 2.81195253355709

Epoch: 5| Step: 4
Training loss: 2.8529963820548505
Validation loss: 2.806271459533639

Epoch: 5| Step: 5
Training loss: 2.7523265014073313
Validation loss: 2.799876803150431

Epoch: 5| Step: 6
Training loss: 3.728611284950177
Validation loss: 2.795463825174018

Epoch: 5| Step: 7
Training loss: 3.5316641235582438
Validation loss: 2.792612023795514

Epoch: 5| Step: 8
Training loss: 2.680495960405462
Validation loss: 2.794406891035417

Epoch: 5| Step: 9
Training loss: 2.8270635140796503
Validation loss: 2.813165419604037

Epoch: 5| Step: 10
Training loss: 3.15139321291934
Validation loss: 2.8507580548304423

Epoch: 137| Step: 0
Training loss: 3.031955597544825
Validation loss: 2.8684011437180055

Epoch: 5| Step: 1
Training loss: 3.0426274354273857
Validation loss: 2.8109952795875572

Epoch: 5| Step: 2
Training loss: 2.8233121099954177
Validation loss: 2.8037328101572756

Epoch: 5| Step: 3
Training loss: 3.081826864410879
Validation loss: 2.8001792282323255

Epoch: 5| Step: 4
Training loss: 2.859372832083792
Validation loss: 2.803482305395627

Epoch: 5| Step: 5
Training loss: 3.5388773686573978
Validation loss: 2.804878890337946

Epoch: 5| Step: 6
Training loss: 2.793071867633139
Validation loss: 2.8028423496477353

Epoch: 5| Step: 7
Training loss: 2.9783383976473994
Validation loss: 2.79318278845214

Epoch: 5| Step: 8
Training loss: 3.2781271469938305
Validation loss: 2.793356813743799

Epoch: 5| Step: 9
Training loss: 3.182839520751236
Validation loss: 2.791035476269868

Epoch: 5| Step: 10
Training loss: 3.4299617996535354
Validation loss: 2.7914433898922786

Epoch: 138| Step: 0
Training loss: 2.7974285238644385
Validation loss: 2.7957382976652037

Epoch: 5| Step: 1
Training loss: 3.116792352627453
Validation loss: 2.7910783412859774

Epoch: 5| Step: 2
Training loss: 3.019481663463319
Validation loss: 2.787083871937185

Epoch: 5| Step: 3
Training loss: 3.022544393789239
Validation loss: 2.788061482412569

Epoch: 5| Step: 4
Training loss: 3.634998082471339
Validation loss: 2.7866783118893967

Epoch: 5| Step: 5
Training loss: 2.9385138851900274
Validation loss: 2.78858164928482

Epoch: 5| Step: 6
Training loss: 2.76674151108707
Validation loss: 2.7878633051689614

Epoch: 5| Step: 7
Training loss: 2.9970806540531094
Validation loss: 2.7814860947141984

Epoch: 5| Step: 8
Training loss: 3.755189229816974
Validation loss: 2.7842732877607257

Epoch: 5| Step: 9
Training loss: 2.910731971680305
Validation loss: 2.7841532846853876

Epoch: 5| Step: 10
Training loss: 2.8408355869841166
Validation loss: 2.7896302763436855

Epoch: 139| Step: 0
Training loss: 3.3540408345820634
Validation loss: 2.783631506556246

Epoch: 5| Step: 1
Training loss: 3.556813034244461
Validation loss: 2.7812060354624033

Epoch: 5| Step: 2
Training loss: 3.0174807832196064
Validation loss: 2.782596387143893

Epoch: 5| Step: 3
Training loss: 3.544061427081334
Validation loss: 2.786582581666569

Epoch: 5| Step: 4
Training loss: 2.7353920053463265
Validation loss: 2.7857955348278423

Epoch: 5| Step: 5
Training loss: 2.9548034742038247
Validation loss: 2.7838004726838212

Epoch: 5| Step: 6
Training loss: 3.1219579004043236
Validation loss: 2.785258857937809

Epoch: 5| Step: 7
Training loss: 3.2121386729289845
Validation loss: 2.785763306411611

Epoch: 5| Step: 8
Training loss: 2.3855191226817225
Validation loss: 2.785678241332324

Epoch: 5| Step: 9
Training loss: 2.6882158257600337
Validation loss: 2.77998523407092

Epoch: 5| Step: 10
Training loss: 3.2356768213447245
Validation loss: 2.7925055934089738

Epoch: 140| Step: 0
Training loss: 3.449535592929107
Validation loss: 2.786195433049042

Epoch: 5| Step: 1
Training loss: 2.63530000169582
Validation loss: 2.7811274532038524

Epoch: 5| Step: 2
Training loss: 2.353023746738665
Validation loss: 2.7882649875185317

Epoch: 5| Step: 3
Training loss: 3.384102590768878
Validation loss: 2.7841887462025166

Epoch: 5| Step: 4
Training loss: 2.990868021020827
Validation loss: 2.782573849907994

Epoch: 5| Step: 5
Training loss: 3.2512917519088123
Validation loss: 2.783623195712093

Epoch: 5| Step: 6
Training loss: 3.5008775428378365
Validation loss: 2.780060678256446

Epoch: 5| Step: 7
Training loss: 3.1141748234865996
Validation loss: 2.7804284499490763

Epoch: 5| Step: 8
Training loss: 2.8670391491338263
Validation loss: 2.7780624859700067

Epoch: 5| Step: 9
Training loss: 2.986233916209401
Validation loss: 2.7776024462285833

Epoch: 5| Step: 10
Training loss: 3.1836607007434847
Validation loss: 2.7823454351975454

Epoch: 141| Step: 0
Training loss: 3.1266897592186584
Validation loss: 2.781226312550976

Epoch: 5| Step: 1
Training loss: 2.9951668589987817
Validation loss: 2.7779637392069634

Epoch: 5| Step: 2
Training loss: 2.22210665110894
Validation loss: 2.7820316012387587

Epoch: 5| Step: 3
Training loss: 3.783563835975722
Validation loss: 2.7858362585487377

Epoch: 5| Step: 4
Training loss: 3.1699378200654116
Validation loss: 2.7952613926181575

Epoch: 5| Step: 5
Training loss: 2.6047320146423947
Validation loss: 2.8082042597851524

Epoch: 5| Step: 6
Training loss: 3.0179526087412967
Validation loss: 2.8454368003237045

Epoch: 5| Step: 7
Training loss: 3.0263255911347557
Validation loss: 2.8547371160345065

Epoch: 5| Step: 8
Training loss: 3.3352118602985588
Validation loss: 2.8536062978687124

Epoch: 5| Step: 9
Training loss: 3.442590031440391
Validation loss: 2.813058620382669

Epoch: 5| Step: 10
Training loss: 3.08924151892199
Validation loss: 2.790715981533946

Epoch: 142| Step: 0
Training loss: 3.3358045636385825
Validation loss: 2.784797246182503

Epoch: 5| Step: 1
Training loss: 3.065353932193517
Validation loss: 2.7858076904418674

Epoch: 5| Step: 2
Training loss: 3.1241108964684043
Validation loss: 2.792437594960937

Epoch: 5| Step: 3
Training loss: 3.213216228277065
Validation loss: 2.794346529749358

Epoch: 5| Step: 4
Training loss: 2.9578938403988295
Validation loss: 2.776157744194746

Epoch: 5| Step: 5
Training loss: 2.6174084925937815
Validation loss: 2.770456721651273

Epoch: 5| Step: 6
Training loss: 3.2233782335196293
Validation loss: 2.771897416905626

Epoch: 5| Step: 7
Training loss: 3.364663578804745
Validation loss: 2.7756681843044255

Epoch: 5| Step: 8
Training loss: 2.976778758445679
Validation loss: 2.7765912586626467

Epoch: 5| Step: 9
Training loss: 3.0093904393830972
Validation loss: 2.787538400579852

Epoch: 5| Step: 10
Training loss: 2.962318923502501
Validation loss: 2.7908160545767537

Epoch: 143| Step: 0
Training loss: 3.0296804552945593
Validation loss: 2.788821611129628

Epoch: 5| Step: 1
Training loss: 2.7343677629647534
Validation loss: 2.788991487198263

Epoch: 5| Step: 2
Training loss: 2.8637669920198676
Validation loss: 2.7876446886189807

Epoch: 5| Step: 3
Training loss: 2.650200181273855
Validation loss: 2.785580514607586

Epoch: 5| Step: 4
Training loss: 3.2602750769798066
Validation loss: 2.7774765190370347

Epoch: 5| Step: 5
Training loss: 3.0414848970072406
Validation loss: 2.778438809780191

Epoch: 5| Step: 6
Training loss: 3.6853821701985643
Validation loss: 2.774140452168733

Epoch: 5| Step: 7
Training loss: 3.0935692011860434
Validation loss: 2.7806619730225792

Epoch: 5| Step: 8
Training loss: 3.599322302926516
Validation loss: 2.783552935669233

Epoch: 5| Step: 9
Training loss: 2.930771446612279
Validation loss: 2.7735479554419626

Epoch: 5| Step: 10
Training loss: 2.9207443252765644
Validation loss: 2.7729185851490414

Epoch: 144| Step: 0
Training loss: 2.752271061245217
Validation loss: 2.7703646348945328

Epoch: 5| Step: 1
Training loss: 2.416563349740562
Validation loss: 2.7699396852879334

Epoch: 5| Step: 2
Training loss: 3.279398659267618
Validation loss: 2.7732470319744187

Epoch: 5| Step: 3
Training loss: 3.3526393343128107
Validation loss: 2.7723483340917254

Epoch: 5| Step: 4
Training loss: 2.8423414829310745
Validation loss: 2.7755784705670656

Epoch: 5| Step: 5
Training loss: 3.092158515104253
Validation loss: 2.7771925716533636

Epoch: 5| Step: 6
Training loss: 3.2789894673328677
Validation loss: 2.7667917736152297

Epoch: 5| Step: 7
Training loss: 2.2768620133638247
Validation loss: 2.7712012022159036

Epoch: 5| Step: 8
Training loss: 3.752336155861694
Validation loss: 2.765014110069971

Epoch: 5| Step: 9
Training loss: 3.663227173155325
Validation loss: 2.773256699525389

Epoch: 5| Step: 10
Training loss: 2.7975070175341967
Validation loss: 2.767597764595864

Epoch: 145| Step: 0
Training loss: 3.4771508565524782
Validation loss: 2.765834893313179

Epoch: 5| Step: 1
Training loss: 3.094538270344773
Validation loss: 2.7663946659492797

Epoch: 5| Step: 2
Training loss: 3.261268740008352
Validation loss: 2.7668016722003634

Epoch: 5| Step: 3
Training loss: 2.795711595032885
Validation loss: 2.7693015623417536

Epoch: 5| Step: 4
Training loss: 2.5026705783020136
Validation loss: 2.7682985694476914

Epoch: 5| Step: 5
Training loss: 3.8517899204299146
Validation loss: 2.773081423016445

Epoch: 5| Step: 6
Training loss: 2.9905628544679406
Validation loss: 2.7734934765211654

Epoch: 5| Step: 7
Training loss: 2.7720467532510114
Validation loss: 2.7775298528541086

Epoch: 5| Step: 8
Training loss: 3.088489568484283
Validation loss: 2.774694009007602

Epoch: 5| Step: 9
Training loss: 2.7093302334757716
Validation loss: 2.7691373986595993

Epoch: 5| Step: 10
Training loss: 3.0579378050722257
Validation loss: 2.7746325905833857

Epoch: 146| Step: 0
Training loss: 2.8921569064195145
Validation loss: 2.7657517550753545

Epoch: 5| Step: 1
Training loss: 2.875821037815206
Validation loss: 2.767309533380333

Epoch: 5| Step: 2
Training loss: 2.8845811499495957
Validation loss: 2.765331950094789

Epoch: 5| Step: 3
Training loss: 2.8135958761797273
Validation loss: 2.7645451183778027

Epoch: 5| Step: 4
Training loss: 3.2636511280945895
Validation loss: 2.77181612624563

Epoch: 5| Step: 5
Training loss: 3.3309586331339234
Validation loss: 2.7642546583643073

Epoch: 5| Step: 6
Training loss: 2.89341609338393
Validation loss: 2.7709758236781408

Epoch: 5| Step: 7
Training loss: 2.8975934138804025
Validation loss: 2.7752526321347144

Epoch: 5| Step: 8
Training loss: 2.708290500791233
Validation loss: 2.767788747350058

Epoch: 5| Step: 9
Training loss: 3.3990593001559364
Validation loss: 2.78019889353182

Epoch: 5| Step: 10
Training loss: 3.772776038281915
Validation loss: 2.774216887911742

Epoch: 147| Step: 0
Training loss: 3.201517734614898
Validation loss: 2.766538269559051

Epoch: 5| Step: 1
Training loss: 2.867932797058254
Validation loss: 2.7644013713517226

Epoch: 5| Step: 2
Training loss: 2.439478438087994
Validation loss: 2.7582532513116127

Epoch: 5| Step: 3
Training loss: 3.3268091887049605
Validation loss: 2.7549514363846703

Epoch: 5| Step: 4
Training loss: 3.1640410999469206
Validation loss: 2.7588454942070704

Epoch: 5| Step: 5
Training loss: 3.4251627695430433
Validation loss: 2.7574326044004027

Epoch: 5| Step: 6
Training loss: 2.920371091855956
Validation loss: 2.7568879289132093

Epoch: 5| Step: 7
Training loss: 3.009369048591029
Validation loss: 2.7568709209197517

Epoch: 5| Step: 8
Training loss: 3.587287465887706
Validation loss: 2.7569468246728928

Epoch: 5| Step: 9
Training loss: 3.114821221868385
Validation loss: 2.7605239584177066

Epoch: 5| Step: 10
Training loss: 2.3248973208488657
Validation loss: 2.755548136408161

Epoch: 148| Step: 0
Training loss: 2.875052078438815
Validation loss: 2.7637319934764277

Epoch: 5| Step: 1
Training loss: 3.7448077813846523
Validation loss: 2.7732025375101594

Epoch: 5| Step: 2
Training loss: 2.693293514649803
Validation loss: 2.7812333105917793

Epoch: 5| Step: 3
Training loss: 2.8729373332703303
Validation loss: 2.7943019859281515

Epoch: 5| Step: 4
Training loss: 2.5567622261474936
Validation loss: 2.7900475435164203

Epoch: 5| Step: 5
Training loss: 3.1751154240330566
Validation loss: 2.791641620627097

Epoch: 5| Step: 6
Training loss: 2.9812146774534645
Validation loss: 2.8074329576652937

Epoch: 5| Step: 7
Training loss: 3.4015896615173613
Validation loss: 2.789600295991604

Epoch: 5| Step: 8
Training loss: 2.7775114843095055
Validation loss: 2.7947590759037273

Epoch: 5| Step: 9
Training loss: 3.2832677540950823
Validation loss: 2.785262399756863

Epoch: 5| Step: 10
Training loss: 3.273202673744509
Validation loss: 2.7819004678526777

Epoch: 149| Step: 0
Training loss: 2.889656688269735
Validation loss: 2.779244123011895

Epoch: 5| Step: 1
Training loss: 2.9775568385108118
Validation loss: 2.7824532078235578

Epoch: 5| Step: 2
Training loss: 2.725574565824092
Validation loss: 2.769191702210731

Epoch: 5| Step: 3
Training loss: 3.734732894027883
Validation loss: 2.75604191766796

Epoch: 5| Step: 4
Training loss: 2.9988507612695066
Validation loss: 2.7516954337838224

Epoch: 5| Step: 5
Training loss: 3.3577465279880525
Validation loss: 2.7523822459605114

Epoch: 5| Step: 6
Training loss: 3.158587506080738
Validation loss: 2.7573418575726025

Epoch: 5| Step: 7
Training loss: 2.9530956125563246
Validation loss: 2.7565143045042677

Epoch: 5| Step: 8
Training loss: 3.253429803851072
Validation loss: 2.7564379377639185

Epoch: 5| Step: 9
Training loss: 2.8881156958550056
Validation loss: 2.754479273869381

Epoch: 5| Step: 10
Training loss: 2.5473239245599966
Validation loss: 2.7530711710145592

Epoch: 150| Step: 0
Training loss: 3.1554231977090845
Validation loss: 2.751364069461311

Epoch: 5| Step: 1
Training loss: 3.674820777519253
Validation loss: 2.75386625965028

Epoch: 5| Step: 2
Training loss: 3.581938864079198
Validation loss: 2.7454553174526013

Epoch: 5| Step: 3
Training loss: 2.281680758841191
Validation loss: 2.7479994349872188

Epoch: 5| Step: 4
Training loss: 2.989150136648996
Validation loss: 2.7477510313737055

Epoch: 5| Step: 5
Training loss: 2.49624026828143
Validation loss: 2.751323659197744

Epoch: 5| Step: 6
Training loss: 2.9274806141068943
Validation loss: 2.7569111048088732

Epoch: 5| Step: 7
Training loss: 3.414101606969957
Validation loss: 2.7548366050609387

Epoch: 5| Step: 8
Training loss: 2.6254325691939835
Validation loss: 2.7575653838343546

Epoch: 5| Step: 9
Training loss: 3.374136779029723
Validation loss: 2.755098257690905

Epoch: 5| Step: 10
Training loss: 2.711552706783521
Validation loss: 2.7580627078772606

Epoch: 151| Step: 0
Training loss: 2.7337525449443567
Validation loss: 2.750579548247837

Epoch: 5| Step: 1
Training loss: 3.2219089450768483
Validation loss: 2.7481043762128556

Epoch: 5| Step: 2
Training loss: 3.244307006758387
Validation loss: 2.745647478119726

Epoch: 5| Step: 3
Training loss: 2.5231380698352406
Validation loss: 2.7456792465113575

Epoch: 5| Step: 4
Training loss: 2.838997863134512
Validation loss: 2.7443462567019856

Epoch: 5| Step: 5
Training loss: 2.6746929990772292
Validation loss: 2.744179220303685

Epoch: 5| Step: 6
Training loss: 3.0237573262283997
Validation loss: 2.7428946672218864

Epoch: 5| Step: 7
Training loss: 3.2772739116516014
Validation loss: 2.740660170178388

Epoch: 5| Step: 8
Training loss: 2.8904075746987616
Validation loss: 2.7408534012775063

Epoch: 5| Step: 9
Training loss: 3.651175866084531
Validation loss: 2.7479445978943904

Epoch: 5| Step: 10
Training loss: 3.3848270470119437
Validation loss: 2.744004107262302

Epoch: 152| Step: 0
Training loss: 2.6532466289916155
Validation loss: 2.740478587071665

Epoch: 5| Step: 1
Training loss: 2.301146602928937
Validation loss: 2.7446072206232794

Epoch: 5| Step: 2
Training loss: 2.844110319345218
Validation loss: 2.7477453951392774

Epoch: 5| Step: 3
Training loss: 3.355126537773599
Validation loss: 2.7413902510916848

Epoch: 5| Step: 4
Training loss: 3.722021891452174
Validation loss: 2.7419731870444135

Epoch: 5| Step: 5
Training loss: 3.1876219183849064
Validation loss: 2.7463548447146717

Epoch: 5| Step: 6
Training loss: 2.8528197142941973
Validation loss: 2.744077454883096

Epoch: 5| Step: 7
Training loss: 3.1063047039656935
Validation loss: 2.739318955302993

Epoch: 5| Step: 8
Training loss: 3.325916972671814
Validation loss: 2.7388540534288994

Epoch: 5| Step: 9
Training loss: 2.64902726080099
Validation loss: 2.7437088433806385

Epoch: 5| Step: 10
Training loss: 3.3487898733307615
Validation loss: 2.749423094241716

Epoch: 153| Step: 0
Training loss: 3.3913332994792387
Validation loss: 2.7556262033317402

Epoch: 5| Step: 1
Training loss: 2.5470075514299158
Validation loss: 2.7512480391905263

Epoch: 5| Step: 2
Training loss: 2.8510960863741146
Validation loss: 2.7553977839918598

Epoch: 5| Step: 3
Training loss: 3.297680941599768
Validation loss: 2.7537583634264124

Epoch: 5| Step: 4
Training loss: 3.250077320059439
Validation loss: 2.759016337861481

Epoch: 5| Step: 5
Training loss: 3.2032452816593135
Validation loss: 2.7497552369376415

Epoch: 5| Step: 6
Training loss: 2.609147478794764
Validation loss: 2.7469302753951164

Epoch: 5| Step: 7
Training loss: 2.417927533662751
Validation loss: 2.7466892886203405

Epoch: 5| Step: 8
Training loss: 3.15776493993672
Validation loss: 2.7403839446835554

Epoch: 5| Step: 9
Training loss: 3.3608345587025314
Validation loss: 2.7361874322397353

Epoch: 5| Step: 10
Training loss: 3.3061694706878972
Validation loss: 2.7364504277388724

Epoch: 154| Step: 0
Training loss: 3.821531261291771
Validation loss: 2.7393030885529286

Epoch: 5| Step: 1
Training loss: 3.1650408703905666
Validation loss: 2.738037916821787

Epoch: 5| Step: 2
Training loss: 2.4164575837112747
Validation loss: 2.738020852596384

Epoch: 5| Step: 3
Training loss: 2.7193018035401244
Validation loss: 2.7434496741350656

Epoch: 5| Step: 4
Training loss: 3.0021567539305636
Validation loss: 2.739557322648435

Epoch: 5| Step: 5
Training loss: 2.621101299792359
Validation loss: 2.7408338310062583

Epoch: 5| Step: 6
Training loss: 2.726518603302173
Validation loss: 2.7403351998047207

Epoch: 5| Step: 7
Training loss: 2.9577387539093025
Validation loss: 2.7372126617795605

Epoch: 5| Step: 8
Training loss: 3.722389427781971
Validation loss: 2.737108556166253

Epoch: 5| Step: 9
Training loss: 3.1551821573573147
Validation loss: 2.73537763785747

Epoch: 5| Step: 10
Training loss: 2.972894285599407
Validation loss: 2.740693232041622

Epoch: 155| Step: 0
Training loss: 2.74486130994625
Validation loss: 2.7389787780243635

Epoch: 5| Step: 1
Training loss: 2.8476383329018815
Validation loss: 2.7411976470286645

Epoch: 5| Step: 2
Training loss: 3.2784755057565556
Validation loss: 2.7428573016151625

Epoch: 5| Step: 3
Training loss: 2.8568397497432176
Validation loss: 2.751313750583933

Epoch: 5| Step: 4
Training loss: 3.424554759691254
Validation loss: 2.7630664987555833

Epoch: 5| Step: 5
Training loss: 3.1532182390474537
Validation loss: 2.7642251456681612

Epoch: 5| Step: 6
Training loss: 3.4879870659124665
Validation loss: 2.7504953015731752

Epoch: 5| Step: 7
Training loss: 2.5231151079612797
Validation loss: 2.7461823956011067

Epoch: 5| Step: 8
Training loss: 2.9595965164566214
Validation loss: 2.7451591300987186

Epoch: 5| Step: 9
Training loss: 3.1015143787100543
Validation loss: 2.7352396920656523

Epoch: 5| Step: 10
Training loss: 2.989873962807891
Validation loss: 2.7359554962846118

Epoch: 156| Step: 0
Training loss: 2.5668937417519473
Validation loss: 2.731565737198742

Epoch: 5| Step: 1
Training loss: 3.4876046715345574
Validation loss: 2.7291825278456185

Epoch: 5| Step: 2
Training loss: 3.248802111018025
Validation loss: 2.7298430226491055

Epoch: 5| Step: 3
Training loss: 3.153714209439298
Validation loss: 2.734724194427865

Epoch: 5| Step: 4
Training loss: 2.8756789359473647
Validation loss: 2.7353141632067337

Epoch: 5| Step: 5
Training loss: 3.452972823021971
Validation loss: 2.730652043669156

Epoch: 5| Step: 6
Training loss: 3.1156721136420247
Validation loss: 2.732056853750943

Epoch: 5| Step: 7
Training loss: 2.8822465873550485
Validation loss: 2.731381653545695

Epoch: 5| Step: 8
Training loss: 2.5450929363196924
Validation loss: 2.728869996850327

Epoch: 5| Step: 9
Training loss: 3.132355692371592
Validation loss: 2.733629292473078

Epoch: 5| Step: 10
Training loss: 2.887687881764619
Validation loss: 2.7414120084559674

Epoch: 157| Step: 0
Training loss: 3.182077620196753
Validation loss: 2.7475756001394327

Epoch: 5| Step: 1
Training loss: 2.8997314526096063
Validation loss: 2.7492061934771725

Epoch: 5| Step: 2
Training loss: 2.730566282263127
Validation loss: 2.7564602906304074

Epoch: 5| Step: 3
Training loss: 2.9666101071684667
Validation loss: 2.75646496690825

Epoch: 5| Step: 4
Training loss: 2.84695857204876
Validation loss: 2.7682765335038857

Epoch: 5| Step: 5
Training loss: 2.99864643078675
Validation loss: 2.770073795759397

Epoch: 5| Step: 6
Training loss: 3.3918768334159726
Validation loss: 2.7499537319568197

Epoch: 5| Step: 7
Training loss: 3.2300121718138954
Validation loss: 2.73674902829402

Epoch: 5| Step: 8
Training loss: 3.049243339109077
Validation loss: 2.7251669732566435

Epoch: 5| Step: 9
Training loss: 2.4875179539324885
Validation loss: 2.7226868968750098

Epoch: 5| Step: 10
Training loss: 3.648405087182039
Validation loss: 2.7216684492710077

Epoch: 158| Step: 0
Training loss: 2.548722609166514
Validation loss: 2.7277110812430556

Epoch: 5| Step: 1
Training loss: 2.8529392211194855
Validation loss: 2.7336860916323804

Epoch: 5| Step: 2
Training loss: 3.305515483182329
Validation loss: 2.7298925521433106

Epoch: 5| Step: 3
Training loss: 2.796034276329237
Validation loss: 2.731209950463082

Epoch: 5| Step: 4
Training loss: 3.0296496069723693
Validation loss: 2.7304861149241666

Epoch: 5| Step: 5
Training loss: 3.0813024551228803
Validation loss: 2.7253575364320204

Epoch: 5| Step: 6
Training loss: 3.527818751326649
Validation loss: 2.7265094507807857

Epoch: 5| Step: 7
Training loss: 3.9153721611305676
Validation loss: 2.7346553235724755

Epoch: 5| Step: 8
Training loss: 2.996022926100243
Validation loss: 2.732737049618536

Epoch: 5| Step: 9
Training loss: 2.594824143406462
Validation loss: 2.730463354128947

Epoch: 5| Step: 10
Training loss: 2.543113036391233
Validation loss: 2.7214883279718793

Epoch: 159| Step: 0
Training loss: 3.3465818018494224
Validation loss: 2.729081295706866

Epoch: 5| Step: 1
Training loss: 2.869437766480243
Validation loss: 2.720242994773269

Epoch: 5| Step: 2
Training loss: 3.2264896412305837
Validation loss: 2.7228447339287367

Epoch: 5| Step: 3
Training loss: 2.766742545163583
Validation loss: 2.7209458583508557

Epoch: 5| Step: 4
Training loss: 2.8669055935258734
Validation loss: 2.7244469823483475

Epoch: 5| Step: 5
Training loss: 3.3154258042595077
Validation loss: 2.7226403680638516

Epoch: 5| Step: 6
Training loss: 3.2840433492273653
Validation loss: 2.7273847446870394

Epoch: 5| Step: 7
Training loss: 3.0115873355124445
Validation loss: 2.7298206715848123

Epoch: 5| Step: 8
Training loss: 2.6320775305103443
Validation loss: 2.728807224806696

Epoch: 5| Step: 9
Training loss: 2.8362947769631797
Validation loss: 2.718919277520055

Epoch: 5| Step: 10
Training loss: 3.1673770074367167
Validation loss: 2.719771031634205

Epoch: 160| Step: 0
Training loss: 2.6433106257973398
Validation loss: 2.7205746979206027

Epoch: 5| Step: 1
Training loss: 3.571392138159067
Validation loss: 2.720337042081404

Epoch: 5| Step: 2
Training loss: 3.570909713112223
Validation loss: 2.717733011687207

Epoch: 5| Step: 3
Training loss: 2.995557993269374
Validation loss: 2.721957522909727

Epoch: 5| Step: 4
Training loss: 2.830232793716089
Validation loss: 2.717671090808677

Epoch: 5| Step: 5
Training loss: 3.062025072290389
Validation loss: 2.722434659100505

Epoch: 5| Step: 6
Training loss: 3.142416675467443
Validation loss: 2.7213577269699485

Epoch: 5| Step: 7
Training loss: 3.027430064293716
Validation loss: 2.717821323047983

Epoch: 5| Step: 8
Training loss: 2.4597679628867226
Validation loss: 2.7147517183595173

Epoch: 5| Step: 9
Training loss: 2.8144176303549866
Validation loss: 2.7202010487422124

Epoch: 5| Step: 10
Training loss: 3.0733593293233175
Validation loss: 2.71619397252291

Epoch: 161| Step: 0
Training loss: 3.308859353962359
Validation loss: 2.718230848918977

Epoch: 5| Step: 1
Training loss: 3.5731469053297924
Validation loss: 2.714899414322826

Epoch: 5| Step: 2
Training loss: 3.026856532114368
Validation loss: 2.7175901317682154

Epoch: 5| Step: 3
Training loss: 2.8844052595243745
Validation loss: 2.71509579786692

Epoch: 5| Step: 4
Training loss: 3.1382838390929386
Validation loss: 2.7139834490626784

Epoch: 5| Step: 5
Training loss: 2.6464500509478475
Validation loss: 2.7181243827308172

Epoch: 5| Step: 6
Training loss: 2.9033789450752128
Validation loss: 2.7155829127401514

Epoch: 5| Step: 7
Training loss: 2.828866597940396
Validation loss: 2.718273794873272

Epoch: 5| Step: 8
Training loss: 3.4707142535081155
Validation loss: 2.7163651109576734

Epoch: 5| Step: 9
Training loss: 2.6688255174301996
Validation loss: 2.72073272346698

Epoch: 5| Step: 10
Training loss: 2.689257291203241
Validation loss: 2.717925641573517

Epoch: 162| Step: 0
Training loss: 3.599445904369372
Validation loss: 2.7209634998086973

Epoch: 5| Step: 1
Training loss: 3.084014679830522
Validation loss: 2.723493169560185

Epoch: 5| Step: 2
Training loss: 2.760014246751808
Validation loss: 2.7163233155088533

Epoch: 5| Step: 3
Training loss: 2.4335443727434534
Validation loss: 2.7227049582950063

Epoch: 5| Step: 4
Training loss: 3.1384830287482397
Validation loss: 2.7180931185072037

Epoch: 5| Step: 5
Training loss: 2.554440174321374
Validation loss: 2.7188516554676654

Epoch: 5| Step: 6
Training loss: 3.3687729079223145
Validation loss: 2.7116179648186964

Epoch: 5| Step: 7
Training loss: 2.997909135170587
Validation loss: 2.7141450235541877

Epoch: 5| Step: 8
Training loss: 3.2808737402854784
Validation loss: 2.7118916468568126

Epoch: 5| Step: 9
Training loss: 3.167516410321462
Validation loss: 2.7157099219888132

Epoch: 5| Step: 10
Training loss: 2.6923107293918793
Validation loss: 2.7208118383285327

Epoch: 163| Step: 0
Training loss: 3.1195182022368315
Validation loss: 2.731523259261722

Epoch: 5| Step: 1
Training loss: 3.0536886079592143
Validation loss: 2.727143733175314

Epoch: 5| Step: 2
Training loss: 2.4407700342905163
Validation loss: 2.7290914888852917

Epoch: 5| Step: 3
Training loss: 2.992110368416765
Validation loss: 2.7397754336233975

Epoch: 5| Step: 4
Training loss: 3.0391125515540196
Validation loss: 2.734964579175333

Epoch: 5| Step: 5
Training loss: 3.5859058520015474
Validation loss: 2.7323730978546465

Epoch: 5| Step: 6
Training loss: 2.96646029865414
Validation loss: 2.7212147406103426

Epoch: 5| Step: 7
Training loss: 3.20047855375137
Validation loss: 2.7194051135964745

Epoch: 5| Step: 8
Training loss: 3.1788856938809142
Validation loss: 2.712793654587932

Epoch: 5| Step: 9
Training loss: 2.9506712715514056
Validation loss: 2.7090081045600454

Epoch: 5| Step: 10
Training loss: 2.6226532755116994
Validation loss: 2.706981844872111

Epoch: 164| Step: 0
Training loss: 2.334903960448181
Validation loss: 2.7091682743635723

Epoch: 5| Step: 1
Training loss: 3.6190764601115157
Validation loss: 2.706334679251711

Epoch: 5| Step: 2
Training loss: 2.2963744156491868
Validation loss: 2.706463123724202

Epoch: 5| Step: 3
Training loss: 3.5302576341710594
Validation loss: 2.7084907151554325

Epoch: 5| Step: 4
Training loss: 2.8721586367539267
Validation loss: 2.7141492456810923

Epoch: 5| Step: 5
Training loss: 3.131793458113454
Validation loss: 2.7144855656343414

Epoch: 5| Step: 6
Training loss: 2.97139870791048
Validation loss: 2.7191770673373683

Epoch: 5| Step: 7
Training loss: 3.351471159430604
Validation loss: 2.7171107578885496

Epoch: 5| Step: 8
Training loss: 3.1480421854607394
Validation loss: 2.714987942494667

Epoch: 5| Step: 9
Training loss: 2.9115815838889203
Validation loss: 2.719406344789979

Epoch: 5| Step: 10
Training loss: 2.8191638414363327
Validation loss: 2.7211555114452364

Epoch: 165| Step: 0
Training loss: 2.7887405508882424
Validation loss: 2.712669372336518

Epoch: 5| Step: 1
Training loss: 3.0856307637804274
Validation loss: 2.709708923843021

Epoch: 5| Step: 2
Training loss: 3.632005171129352
Validation loss: 2.7056903538856405

Epoch: 5| Step: 3
Training loss: 2.996968804284586
Validation loss: 2.704917903502982

Epoch: 5| Step: 4
Training loss: 2.7156553523537066
Validation loss: 2.7045705556396022

Epoch: 5| Step: 5
Training loss: 3.0828325706946114
Validation loss: 2.7043987049539355

Epoch: 5| Step: 6
Training loss: 3.616770644092292
Validation loss: 2.705400454156542

Epoch: 5| Step: 7
Training loss: 2.9740883464197174
Validation loss: 2.7012594645978596

Epoch: 5| Step: 8
Training loss: 2.911888149974416
Validation loss: 2.705490921549043

Epoch: 5| Step: 9
Training loss: 2.217442086720414
Validation loss: 2.7027474843416774

Epoch: 5| Step: 10
Training loss: 3.018877558254219
Validation loss: 2.702266365405202

Epoch: 166| Step: 0
Training loss: 2.829751574392763
Validation loss: 2.707104423201759

Epoch: 5| Step: 1
Training loss: 3.0544104096772307
Validation loss: 2.7096962461474297

Epoch: 5| Step: 2
Training loss: 2.811289039160958
Validation loss: 2.71490803138811

Epoch: 5| Step: 3
Training loss: 2.9821019328942104
Validation loss: 2.714459792971446

Epoch: 5| Step: 4
Training loss: 3.345643835216047
Validation loss: 2.7283579111717073

Epoch: 5| Step: 5
Training loss: 3.07870772214631
Validation loss: 2.7277509005385827

Epoch: 5| Step: 6
Training loss: 2.9404737962691336
Validation loss: 2.7061869260416542

Epoch: 5| Step: 7
Training loss: 3.25187511636916
Validation loss: 2.6986970148682334

Epoch: 5| Step: 8
Training loss: 2.88078290417574
Validation loss: 2.6980550833979686

Epoch: 5| Step: 9
Training loss: 3.2702220337407333
Validation loss: 2.702253069339218

Epoch: 5| Step: 10
Training loss: 2.758620708358699
Validation loss: 2.6980812474546974

Epoch: 167| Step: 0
Training loss: 2.9680456028542688
Validation loss: 2.7016484537542076

Epoch: 5| Step: 1
Training loss: 3.109731835827533
Validation loss: 2.6979046284960573

Epoch: 5| Step: 2
Training loss: 3.5125363493969655
Validation loss: 2.6973106801864724

Epoch: 5| Step: 3
Training loss: 3.172898151012222
Validation loss: 2.6981015582500127

Epoch: 5| Step: 4
Training loss: 2.829361955946745
Validation loss: 2.698495362293195

Epoch: 5| Step: 5
Training loss: 3.051913589774167
Validation loss: 2.703692411104558

Epoch: 5| Step: 6
Training loss: 3.320168023051536
Validation loss: 2.7148959639007644

Epoch: 5| Step: 7
Training loss: 3.112937228581218
Validation loss: 2.71718126412437

Epoch: 5| Step: 8
Training loss: 2.4984957938106387
Validation loss: 2.7168786370902427

Epoch: 5| Step: 9
Training loss: 2.59989724689794
Validation loss: 2.7161198747526454

Epoch: 5| Step: 10
Training loss: 2.899254367602388
Validation loss: 2.7157382183569503

Epoch: 168| Step: 0
Training loss: 3.2289384494655535
Validation loss: 2.7072219354125235

Epoch: 5| Step: 1
Training loss: 3.2934138493856486
Validation loss: 2.7111133285430795

Epoch: 5| Step: 2
Training loss: 2.523593012030397
Validation loss: 2.7030291796692887

Epoch: 5| Step: 3
Training loss: 3.567838984786492
Validation loss: 2.7104233098116373

Epoch: 5| Step: 4
Training loss: 2.8734450074139795
Validation loss: 2.7023076990080046

Epoch: 5| Step: 5
Training loss: 3.1308409463645877
Validation loss: 2.6981817262484573

Epoch: 5| Step: 6
Training loss: 2.9850078131543114
Validation loss: 2.704100197298523

Epoch: 5| Step: 7
Training loss: 3.2390386158218547
Validation loss: 2.699065787839324

Epoch: 5| Step: 8
Training loss: 3.008938189819021
Validation loss: 2.6976194082941367

Epoch: 5| Step: 9
Training loss: 2.608853499329377
Validation loss: 2.6977633630151296

Epoch: 5| Step: 10
Training loss: 2.4245664346615965
Validation loss: 2.6957361555052857

Epoch: 169| Step: 0
Training loss: 3.3897779962545633
Validation loss: 2.6945758575641365

Epoch: 5| Step: 1
Training loss: 2.873212341481347
Validation loss: 2.690455899984579

Epoch: 5| Step: 2
Training loss: 2.4409834594853774
Validation loss: 2.693386981955318

Epoch: 5| Step: 3
Training loss: 3.6231330799633223
Validation loss: 2.695408069639616

Epoch: 5| Step: 4
Training loss: 3.0199294919505224
Validation loss: 2.695265352854221

Epoch: 5| Step: 5
Training loss: 2.833824863059146
Validation loss: 2.6922855176545486

Epoch: 5| Step: 6
Training loss: 2.606769563037564
Validation loss: 2.6905122642037624

Epoch: 5| Step: 7
Training loss: 2.5796635516306803
Validation loss: 2.6904144995976305

Epoch: 5| Step: 8
Training loss: 3.460943837730512
Validation loss: 2.6912176580284073

Epoch: 5| Step: 9
Training loss: 3.219272311895912
Validation loss: 2.6966933803202853

Epoch: 5| Step: 10
Training loss: 2.825635710225335
Validation loss: 2.7021672073386496

Epoch: 170| Step: 0
Training loss: 2.920887009965944
Validation loss: 2.7011595957155015

Epoch: 5| Step: 1
Training loss: 2.617813445436367
Validation loss: 2.7079197746917316

Epoch: 5| Step: 2
Training loss: 2.2782009075480123
Validation loss: 2.705594244447722

Epoch: 5| Step: 3
Training loss: 2.4249679012730434
Validation loss: 2.7206286798326507

Epoch: 5| Step: 4
Training loss: 3.4331396017383877
Validation loss: 2.7179673232483537

Epoch: 5| Step: 5
Training loss: 3.200342970588392
Validation loss: 2.731316200363221

Epoch: 5| Step: 6
Training loss: 3.1473856416005215
Validation loss: 2.743043662867932

Epoch: 5| Step: 7
Training loss: 3.479166560068338
Validation loss: 2.7402408078702973

Epoch: 5| Step: 8
Training loss: 3.3998708924856675
Validation loss: 2.7120633668294554

Epoch: 5| Step: 9
Training loss: 3.0818833386956874
Validation loss: 2.693374098935083

Epoch: 5| Step: 10
Training loss: 2.9639588896439695
Validation loss: 2.6927998648359566

Epoch: 171| Step: 0
Training loss: 3.0200562804074718
Validation loss: 2.7020033520393216

Epoch: 5| Step: 1
Training loss: 3.3265842936936556
Validation loss: 2.7095691697862447

Epoch: 5| Step: 2
Training loss: 3.2310654666824368
Validation loss: 2.7177749260066424

Epoch: 5| Step: 3
Training loss: 3.2116882486085103
Validation loss: 2.7219655153277973

Epoch: 5| Step: 4
Training loss: 3.0512090131545504
Validation loss: 2.720055896987252

Epoch: 5| Step: 5
Training loss: 2.9606137866209896
Validation loss: 2.7159388984067943

Epoch: 5| Step: 6
Training loss: 3.1445806842969874
Validation loss: 2.7083723502428994

Epoch: 5| Step: 7
Training loss: 2.9773102069007242
Validation loss: 2.711001791266605

Epoch: 5| Step: 8
Training loss: 3.0880603297274845
Validation loss: 2.7108941054174225

Epoch: 5| Step: 9
Training loss: 2.4237186428675948
Validation loss: 2.708119125666743

Epoch: 5| Step: 10
Training loss: 3.0164360576462026
Validation loss: 2.7066587440921954

Epoch: 172| Step: 0
Training loss: 3.0098597309468733
Validation loss: 2.7043006119276836

Epoch: 5| Step: 1
Training loss: 2.8787813612454998
Validation loss: 2.70226766607286

Epoch: 5| Step: 2
Training loss: 2.8975731725397664
Validation loss: 2.7036869589501427

Epoch: 5| Step: 3
Training loss: 2.6862253226828186
Validation loss: 2.701548351575167

Epoch: 5| Step: 4
Training loss: 3.040256452033022
Validation loss: 2.7007018170343455

Epoch: 5| Step: 5
Training loss: 3.284384111705739
Validation loss: 2.6985141147903766

Epoch: 5| Step: 6
Training loss: 3.1856818904365927
Validation loss: 2.69857826693475

Epoch: 5| Step: 7
Training loss: 3.2158111192170447
Validation loss: 2.6970285567779433

Epoch: 5| Step: 8
Training loss: 3.0983511877614256
Validation loss: 2.6976021159532038

Epoch: 5| Step: 9
Training loss: 3.083440383564927
Validation loss: 2.696898259899705

Epoch: 5| Step: 10
Training loss: 2.94200114076801
Validation loss: 2.696279911953167

Epoch: 173| Step: 0
Training loss: 3.5990378577596145
Validation loss: 2.7088693449634906

Epoch: 5| Step: 1
Training loss: 2.7820088926347326
Validation loss: 2.7015574187995797

Epoch: 5| Step: 2
Training loss: 3.4080036094001676
Validation loss: 2.706504613935324

Epoch: 5| Step: 3
Training loss: 2.8277081767245438
Validation loss: 2.692510341036729

Epoch: 5| Step: 4
Training loss: 3.1664205924009776
Validation loss: 2.7030843551134045

Epoch: 5| Step: 5
Training loss: 3.072413688918615
Validation loss: 2.69083052984715

Epoch: 5| Step: 6
Training loss: 2.9430261130903244
Validation loss: 2.6873149707970807

Epoch: 5| Step: 7
Training loss: 2.9373866931895685
Validation loss: 2.682111484884574

Epoch: 5| Step: 8
Training loss: 2.9155305738787374
Validation loss: 2.685324441507737

Epoch: 5| Step: 9
Training loss: 2.7495202599733033
Validation loss: 2.686045540938357

Epoch: 5| Step: 10
Training loss: 2.4938515396288095
Validation loss: 2.6887264691681767

Epoch: 174| Step: 0
Training loss: 3.021719195383971
Validation loss: 2.6857088954822324

Epoch: 5| Step: 1
Training loss: 2.2625621218082617
Validation loss: 2.6848750572506375

Epoch: 5| Step: 2
Training loss: 3.479175605686301
Validation loss: 2.6836997729772616

Epoch: 5| Step: 3
Training loss: 2.8739824567563326
Validation loss: 2.6862887824637407

Epoch: 5| Step: 4
Training loss: 2.9972407049254017
Validation loss: 2.6888170194172525

Epoch: 5| Step: 5
Training loss: 2.6517829583077104
Validation loss: 2.693005847892253

Epoch: 5| Step: 6
Training loss: 3.4528228489484807
Validation loss: 2.689554709648398

Epoch: 5| Step: 7
Training loss: 3.150452832567397
Validation loss: 2.698350351185161

Epoch: 5| Step: 8
Training loss: 2.9303218714232746
Validation loss: 2.6911955329646906

Epoch: 5| Step: 9
Training loss: 3.137765977991603
Validation loss: 2.69184270880134

Epoch: 5| Step: 10
Training loss: 2.8848562052045215
Validation loss: 2.694185369108013

Epoch: 175| Step: 0
Training loss: 3.592180523029735
Validation loss: 2.694230500544889

Epoch: 5| Step: 1
Training loss: 3.478507811394579
Validation loss: 2.689230889722003

Epoch: 5| Step: 2
Training loss: 2.794867450389478
Validation loss: 2.6928021611442183

Epoch: 5| Step: 3
Training loss: 3.3764245594239117
Validation loss: 2.6856492631920705

Epoch: 5| Step: 4
Training loss: 3.457053181206918
Validation loss: 2.682211678293234

Epoch: 5| Step: 5
Training loss: 2.0737609932891488
Validation loss: 2.6781858304175588

Epoch: 5| Step: 6
Training loss: 2.4172030763426298
Validation loss: 2.6749405803411985

Epoch: 5| Step: 7
Training loss: 2.4903753023848667
Validation loss: 2.677971029853062

Epoch: 5| Step: 8
Training loss: 2.6935083515440685
Validation loss: 2.6780872147360792

Epoch: 5| Step: 9
Training loss: 3.3257063552778745
Validation loss: 2.6824721141363073

Epoch: 5| Step: 10
Training loss: 2.914190131043794
Validation loss: 2.685845482238058

Epoch: 176| Step: 0
Training loss: 3.0185025573790405
Validation loss: 2.6887933314348165

Epoch: 5| Step: 1
Training loss: 2.601572214286011
Validation loss: 2.6995473499355493

Epoch: 5| Step: 2
Training loss: 3.2968049968501107
Validation loss: 2.69601913018315

Epoch: 5| Step: 3
Training loss: 2.1502189879561087
Validation loss: 2.713663945220077

Epoch: 5| Step: 4
Training loss: 3.199232760481379
Validation loss: 2.716736655884809

Epoch: 5| Step: 5
Training loss: 3.1348188639365406
Validation loss: 2.7301489302230904

Epoch: 5| Step: 6
Training loss: 2.3668421125078813
Validation loss: 2.7047014506618923

Epoch: 5| Step: 7
Training loss: 3.451462980038419
Validation loss: 2.6922208175257802

Epoch: 5| Step: 8
Training loss: 2.9558273948894422
Validation loss: 2.680700021800663

Epoch: 5| Step: 9
Training loss: 3.2038832348562227
Validation loss: 2.680769135061714

Epoch: 5| Step: 10
Training loss: 3.372490409006064
Validation loss: 2.68169784655135

Epoch: 177| Step: 0
Training loss: 3.0118889469885337
Validation loss: 2.676403903813875

Epoch: 5| Step: 1
Training loss: 2.847919300211145
Validation loss: 2.6785772621024853

Epoch: 5| Step: 2
Training loss: 2.8232766422793802
Validation loss: 2.6753430045880835

Epoch: 5| Step: 3
Training loss: 3.2864159018572905
Validation loss: 2.681494338159122

Epoch: 5| Step: 4
Training loss: 2.9562955114881726
Validation loss: 2.6798737159071906

Epoch: 5| Step: 5
Training loss: 3.032228606833047
Validation loss: 2.6793777017432343

Epoch: 5| Step: 6
Training loss: 2.9615271793878457
Validation loss: 2.6832870520935015

Epoch: 5| Step: 7
Training loss: 2.8075608859844023
Validation loss: 2.6841753422445818

Epoch: 5| Step: 8
Training loss: 3.1956236298422187
Validation loss: 2.6896444456632436

Epoch: 5| Step: 9
Training loss: 2.9422329048790026
Validation loss: 2.6879796837514065

Epoch: 5| Step: 10
Training loss: 3.0915443958325763
Validation loss: 2.6886409151165886

Epoch: 178| Step: 0
Training loss: 3.1897721513555597
Validation loss: 2.6846390950315344

Epoch: 5| Step: 1
Training loss: 2.6270967011763275
Validation loss: 2.678758098232948

Epoch: 5| Step: 2
Training loss: 2.832142878996104
Validation loss: 2.6752790791363816

Epoch: 5| Step: 3
Training loss: 2.729130538429515
Validation loss: 2.671085699958921

Epoch: 5| Step: 4
Training loss: 2.546945957061303
Validation loss: 2.6714805672177646

Epoch: 5| Step: 5
Training loss: 3.340010503878038
Validation loss: 2.668955301183154

Epoch: 5| Step: 6
Training loss: 3.3708586539003966
Validation loss: 2.6705685942875608

Epoch: 5| Step: 7
Training loss: 2.8547890163300664
Validation loss: 2.6696804062353343

Epoch: 5| Step: 8
Training loss: 2.9854128965117526
Validation loss: 2.6669811052499535

Epoch: 5| Step: 9
Training loss: 3.425274279673266
Validation loss: 2.6695955603101083

Epoch: 5| Step: 10
Training loss: 2.8997911443809663
Validation loss: 2.667946951023136

Epoch: 179| Step: 0
Training loss: 2.8599369351563135
Validation loss: 2.673580388939982

Epoch: 5| Step: 1
Training loss: 2.605524934680476
Validation loss: 2.6773462767708947

Epoch: 5| Step: 2
Training loss: 3.0805140484955618
Validation loss: 2.6946422217260904

Epoch: 5| Step: 3
Training loss: 2.7080954129301738
Validation loss: 2.6947669500941926

Epoch: 5| Step: 4
Training loss: 3.095871785379884
Validation loss: 2.695774003071927

Epoch: 5| Step: 5
Training loss: 2.950800227881122
Validation loss: 2.682227920521835

Epoch: 5| Step: 6
Training loss: 3.01065919596531
Validation loss: 2.6742466847707664

Epoch: 5| Step: 7
Training loss: 3.186608133643028
Validation loss: 2.670219973359657

Epoch: 5| Step: 8
Training loss: 3.246092134147086
Validation loss: 2.668250757125784

Epoch: 5| Step: 9
Training loss: 2.729401342964974
Validation loss: 2.6643980783990866

Epoch: 5| Step: 10
Training loss: 3.4109414366674486
Validation loss: 2.668625916197742

Epoch: 180| Step: 0
Training loss: 2.4446615992045286
Validation loss: 2.6647696887560586

Epoch: 5| Step: 1
Training loss: 3.599351580822324
Validation loss: 2.665611244895844

Epoch: 5| Step: 2
Training loss: 2.9831949667215274
Validation loss: 2.667908519394774

Epoch: 5| Step: 3
Training loss: 2.8550378810954915
Validation loss: 2.667422418892499

Epoch: 5| Step: 4
Training loss: 2.6190833669344853
Validation loss: 2.6610584329847153

Epoch: 5| Step: 5
Training loss: 3.5268319097601104
Validation loss: 2.6667510225684534

Epoch: 5| Step: 6
Training loss: 3.1968056470819186
Validation loss: 2.668400958705386

Epoch: 5| Step: 7
Training loss: 2.7542024060891523
Validation loss: 2.667208590227293

Epoch: 5| Step: 8
Training loss: 2.9313439327716675
Validation loss: 2.666022229260647

Epoch: 5| Step: 9
Training loss: 2.8763446151377163
Validation loss: 2.668715858341948

Epoch: 5| Step: 10
Training loss: 2.952314154503603
Validation loss: 2.6703284608662794

Epoch: 181| Step: 0
Training loss: 3.2189236195969033
Validation loss: 2.676060156691127

Epoch: 5| Step: 1
Training loss: 2.455810437656108
Validation loss: 2.6718018320347783

Epoch: 5| Step: 2
Training loss: 3.1617726269791055
Validation loss: 2.667905433886114

Epoch: 5| Step: 3
Training loss: 3.3198712942155226
Validation loss: 2.6657622236634273

Epoch: 5| Step: 4
Training loss: 2.858930542802986
Validation loss: 2.667416679239777

Epoch: 5| Step: 5
Training loss: 2.3788727756393833
Validation loss: 2.666876758354426

Epoch: 5| Step: 6
Training loss: 3.190534755166566
Validation loss: 2.664640202391219

Epoch: 5| Step: 7
Training loss: 2.7479415472107855
Validation loss: 2.665087829191037

Epoch: 5| Step: 8
Training loss: 3.131421320144086
Validation loss: 2.66888150468983

Epoch: 5| Step: 9
Training loss: 2.9599926731946837
Validation loss: 2.6628454932158583

Epoch: 5| Step: 10
Training loss: 3.3601159986272733
Validation loss: 2.665489925105222

Epoch: 182| Step: 0
Training loss: 3.3586495969166186
Validation loss: 2.6660812072368287

Epoch: 5| Step: 1
Training loss: 2.800063207457874
Validation loss: 2.664823863142927

Epoch: 5| Step: 2
Training loss: 2.3796903573893813
Validation loss: 2.6661641582533493

Epoch: 5| Step: 3
Training loss: 3.3663524468460992
Validation loss: 2.665672019329626

Epoch: 5| Step: 4
Training loss: 2.2213970029635384
Validation loss: 2.6698319494788287

Epoch: 5| Step: 5
Training loss: 2.8503887112205786
Validation loss: 2.672666282711835

Epoch: 5| Step: 6
Training loss: 2.8898824201906304
Validation loss: 2.6769084475083895

Epoch: 5| Step: 7
Training loss: 3.5537540090392716
Validation loss: 2.6857121781741027

Epoch: 5| Step: 8
Training loss: 3.6579850473489386
Validation loss: 2.6861454477877773

Epoch: 5| Step: 9
Training loss: 3.288702648348271
Validation loss: 2.701815998865674

Epoch: 5| Step: 10
Training loss: 1.8154446589451254
Validation loss: 2.680278192410969

Epoch: 183| Step: 0
Training loss: 3.611881063165442
Validation loss: 2.667105333590041

Epoch: 5| Step: 1
Training loss: 2.8936029714057057
Validation loss: 2.666349323550858

Epoch: 5| Step: 2
Training loss: 3.0645156766441026
Validation loss: 2.6597053748418595

Epoch: 5| Step: 3
Training loss: 3.5226597910931137
Validation loss: 2.6657680140011273

Epoch: 5| Step: 4
Training loss: 2.9101146310992108
Validation loss: 2.6674499607883355

Epoch: 5| Step: 5
Training loss: 2.4467179522046223
Validation loss: 2.6682507792240573

Epoch: 5| Step: 6
Training loss: 2.7635023516635817
Validation loss: 2.6666472194588047

Epoch: 5| Step: 7
Training loss: 2.1974936947607344
Validation loss: 2.6620571821806993

Epoch: 5| Step: 8
Training loss: 3.2524624812244123
Validation loss: 2.6611273848993924

Epoch: 5| Step: 9
Training loss: 3.2798083816939494
Validation loss: 2.662456362810253

Epoch: 5| Step: 10
Training loss: 2.7176147370739248
Validation loss: 2.6631405802880628

Epoch: 184| Step: 0
Training loss: 3.3069551231585335
Validation loss: 2.664780755189725

Epoch: 5| Step: 1
Training loss: 3.387100849354251
Validation loss: 2.6655282569563012

Epoch: 5| Step: 2
Training loss: 3.6668544778985925
Validation loss: 2.6646798265161804

Epoch: 5| Step: 3
Training loss: 2.5899272462207414
Validation loss: 2.6721506658406264

Epoch: 5| Step: 4
Training loss: 2.7029814930125964
Validation loss: 2.6689954918314496

Epoch: 5| Step: 5
Training loss: 2.7209879116138915
Validation loss: 2.6687419834272563

Epoch: 5| Step: 6
Training loss: 2.9437057200217667
Validation loss: 2.666330677510655

Epoch: 5| Step: 7
Training loss: 2.8492604617932322
Validation loss: 2.6661699054101837

Epoch: 5| Step: 8
Training loss: 2.6470734000583795
Validation loss: 2.665454928235297

Epoch: 5| Step: 9
Training loss: 3.1228144823440434
Validation loss: 2.6626184798697095

Epoch: 5| Step: 10
Training loss: 2.7241339155881037
Validation loss: 2.6601215318301294

Epoch: 185| Step: 0
Training loss: 3.600107292059955
Validation loss: 2.6631993236686813

Epoch: 5| Step: 1
Training loss: 2.9941116401279704
Validation loss: 2.659202667020506

Epoch: 5| Step: 2
Training loss: 2.998811645383028
Validation loss: 2.6634587151092974

Epoch: 5| Step: 3
Training loss: 2.912012928850167
Validation loss: 2.6594517337338526

Epoch: 5| Step: 4
Training loss: 3.421673215725728
Validation loss: 2.6653224588004774

Epoch: 5| Step: 5
Training loss: 3.0230718978120286
Validation loss: 2.658020781442618

Epoch: 5| Step: 6
Training loss: 2.856551480398779
Validation loss: 2.664302121449644

Epoch: 5| Step: 7
Training loss: 2.7909319940507795
Validation loss: 2.6643783906027725

Epoch: 5| Step: 8
Training loss: 2.4277702200001103
Validation loss: 2.668941919854809

Epoch: 5| Step: 9
Training loss: 2.830106767992562
Validation loss: 2.6729059087760776

Epoch: 5| Step: 10
Training loss: 2.7743161810930204
Validation loss: 2.6817826766693034

Epoch: 186| Step: 0
Training loss: 3.096990256373321
Validation loss: 2.678593038734499

Epoch: 5| Step: 1
Training loss: 3.1592323640797653
Validation loss: 2.6960437041419407

Epoch: 5| Step: 2
Training loss: 3.2196449591095795
Validation loss: 2.6872030763323114

Epoch: 5| Step: 3
Training loss: 2.9524897139303055
Validation loss: 2.668502478213526

Epoch: 5| Step: 4
Training loss: 2.832875345651309
Validation loss: 2.658936288675884

Epoch: 5| Step: 5
Training loss: 2.5889300867913008
Validation loss: 2.653473303112831

Epoch: 5| Step: 6
Training loss: 3.0044451206659213
Validation loss: 2.648079481097595

Epoch: 5| Step: 7
Training loss: 3.0599181522069454
Validation loss: 2.6533890529431234

Epoch: 5| Step: 8
Training loss: 3.1058050009586067
Validation loss: 2.6515311843606817

Epoch: 5| Step: 9
Training loss: 2.462172715953293
Validation loss: 2.651632123816653

Epoch: 5| Step: 10
Training loss: 3.2494959807211865
Validation loss: 2.6535203597662678

Epoch: 187| Step: 0
Training loss: 2.9097449504861905
Validation loss: 2.64960453660543

Epoch: 5| Step: 1
Training loss: 2.6709239672568716
Validation loss: 2.6491736334211087

Epoch: 5| Step: 2
Training loss: 2.842595127899368
Validation loss: 2.651424439717315

Epoch: 5| Step: 3
Training loss: 3.2668464967963176
Validation loss: 2.6525631483313075

Epoch: 5| Step: 4
Training loss: 3.144519422046854
Validation loss: 2.6498651407900193

Epoch: 5| Step: 5
Training loss: 3.147035499578597
Validation loss: 2.6497031113071

Epoch: 5| Step: 6
Training loss: 2.9613861307758835
Validation loss: 2.6565452570833514

Epoch: 5| Step: 7
Training loss: 2.4895096984784693
Validation loss: 2.650636684871895

Epoch: 5| Step: 8
Training loss: 2.433012915988165
Validation loss: 2.644503297823316

Epoch: 5| Step: 9
Training loss: 3.18806871314766
Validation loss: 2.645727613948427

Epoch: 5| Step: 10
Training loss: 3.604045417524872
Validation loss: 2.650972442106739

Epoch: 188| Step: 0
Training loss: 3.584376974196751
Validation loss: 2.646270230122105

Epoch: 5| Step: 1
Training loss: 3.251603831184787
Validation loss: 2.6418207675502092

Epoch: 5| Step: 2
Training loss: 2.680740727785769
Validation loss: 2.644587942551704

Epoch: 5| Step: 3
Training loss: 3.042151599705514
Validation loss: 2.651295152491373

Epoch: 5| Step: 4
Training loss: 3.1920883962490407
Validation loss: 2.6532657322125464

Epoch: 5| Step: 5
Training loss: 2.8667485787273455
Validation loss: 2.653687580647356

Epoch: 5| Step: 6
Training loss: 3.165876156031241
Validation loss: 2.645147241597119

Epoch: 5| Step: 7
Training loss: 2.9530187517055837
Validation loss: 2.6510492552738443

Epoch: 5| Step: 8
Training loss: 2.52484101276496
Validation loss: 2.6548717737933076

Epoch: 5| Step: 9
Training loss: 2.6381135091416135
Validation loss: 2.648272487755818

Epoch: 5| Step: 10
Training loss: 2.5855348394551516
Validation loss: 2.640154862788584

Epoch: 189| Step: 0
Training loss: 2.5055964771302013
Validation loss: 2.6413418958738353

Epoch: 5| Step: 1
Training loss: 3.307604212773489
Validation loss: 2.640417990009718

Epoch: 5| Step: 2
Training loss: 2.9336519400645225
Validation loss: 2.6430206179377356

Epoch: 5| Step: 3
Training loss: 3.201828708258199
Validation loss: 2.6419187850594192

Epoch: 5| Step: 4
Training loss: 2.646984951073065
Validation loss: 2.6406584765050147

Epoch: 5| Step: 5
Training loss: 2.971911543853098
Validation loss: 2.6411519256341056

Epoch: 5| Step: 6
Training loss: 3.071588537416507
Validation loss: 2.6421427080210385

Epoch: 5| Step: 7
Training loss: 3.2534731866397917
Validation loss: 2.646455730484067

Epoch: 5| Step: 8
Training loss: 2.7703049712877554
Validation loss: 2.644017639514538

Epoch: 5| Step: 9
Training loss: 2.838358872620359
Validation loss: 2.645312347033177

Epoch: 5| Step: 10
Training loss: 3.137553824764748
Validation loss: 2.6468577444230776

Epoch: 190| Step: 0
Training loss: 3.607428748470712
Validation loss: 2.65192361831862

Epoch: 5| Step: 1
Training loss: 3.2016331617861726
Validation loss: 2.651262829458054

Epoch: 5| Step: 2
Training loss: 3.1141766609056702
Validation loss: 2.6508727492591917

Epoch: 5| Step: 3
Training loss: 3.008432458176137
Validation loss: 2.648464375892328

Epoch: 5| Step: 4
Training loss: 3.042482467011561
Validation loss: 2.6529028402620045

Epoch: 5| Step: 5
Training loss: 2.2406236465003104
Validation loss: 2.6533254816701057

Epoch: 5| Step: 6
Training loss: 3.1993594482186976
Validation loss: 2.6493719685206347

Epoch: 5| Step: 7
Training loss: 2.6864446297737707
Validation loss: 2.6468207316110273

Epoch: 5| Step: 8
Training loss: 3.094662002077851
Validation loss: 2.645211832233697

Epoch: 5| Step: 9
Training loss: 2.82317986381616
Validation loss: 2.640413846110207

Epoch: 5| Step: 10
Training loss: 2.356432260602841
Validation loss: 2.637661681754871

Epoch: 191| Step: 0
Training loss: 3.0019124610941383
Validation loss: 2.638452399106285

Epoch: 5| Step: 1
Training loss: 3.141898584954589
Validation loss: 2.637411755787238

Epoch: 5| Step: 2
Training loss: 2.863492242343333
Validation loss: 2.6349701271870813

Epoch: 5| Step: 3
Training loss: 3.1309888292988743
Validation loss: 2.6366767003068756

Epoch: 5| Step: 4
Training loss: 2.66919167502037
Validation loss: 2.638978572401644

Epoch: 5| Step: 5
Training loss: 2.8221069713732567
Validation loss: 2.6373868182660867

Epoch: 5| Step: 6
Training loss: 3.3108588417722675
Validation loss: 2.63931952803494

Epoch: 5| Step: 7
Training loss: 3.143114611990999
Validation loss: 2.637191265127189

Epoch: 5| Step: 8
Training loss: 2.5841575558758194
Validation loss: 2.650977075271293

Epoch: 5| Step: 9
Training loss: 3.2318792619531402
Validation loss: 2.6580122707487432

Epoch: 5| Step: 10
Training loss: 2.61037759307658
Validation loss: 2.666067737441294

Epoch: 192| Step: 0
Training loss: 3.2457582229196293
Validation loss: 2.6639151487472934

Epoch: 5| Step: 1
Training loss: 2.962205922141622
Validation loss: 2.67548129241256

Epoch: 5| Step: 2
Training loss: 2.9877587753012538
Validation loss: 2.674144263597423

Epoch: 5| Step: 3
Training loss: 2.7896252660090135
Validation loss: 2.670813887514797

Epoch: 5| Step: 4
Training loss: 2.7678412054631436
Validation loss: 2.6679069406064535

Epoch: 5| Step: 5
Training loss: 2.698732368160744
Validation loss: 2.6702629714220754

Epoch: 5| Step: 6
Training loss: 3.4123342229239486
Validation loss: 2.669149333950893

Epoch: 5| Step: 7
Training loss: 3.365365723776979
Validation loss: 2.6596404489236556

Epoch: 5| Step: 8
Training loss: 2.1166125428296088
Validation loss: 2.6475388586217683

Epoch: 5| Step: 9
Training loss: 3.229267159815882
Validation loss: 2.638743526443241

Epoch: 5| Step: 10
Training loss: 2.835774734912484
Validation loss: 2.6386153885911834

Epoch: 193| Step: 0
Training loss: 3.2286132502348877
Validation loss: 2.6337229097714303

Epoch: 5| Step: 1
Training loss: 3.0262009561780348
Validation loss: 2.642648295410763

Epoch: 5| Step: 2
Training loss: 3.3077982517056292
Validation loss: 2.637076754859515

Epoch: 5| Step: 3
Training loss: 2.5326237659393915
Validation loss: 2.6408307521479477

Epoch: 5| Step: 4
Training loss: 2.6530696903569777
Validation loss: 2.639741189864396

Epoch: 5| Step: 5
Training loss: 2.7502448233084205
Validation loss: 2.6412105223029445

Epoch: 5| Step: 6
Training loss: 3.225578250350362
Validation loss: 2.6441363392129293

Epoch: 5| Step: 7
Training loss: 3.161676105035406
Validation loss: 2.6428871996008967

Epoch: 5| Step: 8
Training loss: 3.048998127217029
Validation loss: 2.6460464578383593

Epoch: 5| Step: 9
Training loss: 2.914240527403752
Validation loss: 2.6421515468491745

Epoch: 5| Step: 10
Training loss: 2.672448882995999
Validation loss: 2.6421288493543145

Epoch: 194| Step: 0
Training loss: 3.049959939162015
Validation loss: 2.642828596455616

Epoch: 5| Step: 1
Training loss: 3.1697458722511684
Validation loss: 2.638814749447132

Epoch: 5| Step: 2
Training loss: 2.308461968134887
Validation loss: 2.635110503579266

Epoch: 5| Step: 3
Training loss: 2.7102406070498257
Validation loss: 2.6384245671432383

Epoch: 5| Step: 4
Training loss: 3.185095235218198
Validation loss: 2.6312102685460435

Epoch: 5| Step: 5
Training loss: 2.7034763703171665
Validation loss: 2.6319667070687003

Epoch: 5| Step: 6
Training loss: 3.3791207482494614
Validation loss: 2.6370499913666783

Epoch: 5| Step: 7
Training loss: 3.086689917667006
Validation loss: 2.633301968489632

Epoch: 5| Step: 8
Training loss: 2.3843774878012702
Validation loss: 2.6361354519040976

Epoch: 5| Step: 9
Training loss: 3.519337097299881
Validation loss: 2.632075098433952

Epoch: 5| Step: 10
Training loss: 2.8269935156980943
Validation loss: 2.6377924506750685

Epoch: 195| Step: 0
Training loss: 2.96882565050611
Validation loss: 2.6311734877111697

Epoch: 5| Step: 1
Training loss: 3.0178494328378584
Validation loss: 2.633222866687911

Epoch: 5| Step: 2
Training loss: 3.234460212211596
Validation loss: 2.650589675677806

Epoch: 5| Step: 3
Training loss: 2.947314808651907
Validation loss: 2.636783163057927

Epoch: 5| Step: 4
Training loss: 2.979830492306302
Validation loss: 2.646083185014664

Epoch: 5| Step: 5
Training loss: 3.1451965765476335
Validation loss: 2.646712052518272

Epoch: 5| Step: 6
Training loss: 2.620419274772292
Validation loss: 2.644657164911576

Epoch: 5| Step: 7
Training loss: 2.859129514735429
Validation loss: 2.6342255361946014

Epoch: 5| Step: 8
Training loss: 3.2773236716272622
Validation loss: 2.634641026792896

Epoch: 5| Step: 9
Training loss: 2.286598624152226
Validation loss: 2.6363038571957453

Epoch: 5| Step: 10
Training loss: 3.1807037903855258
Validation loss: 2.641645231153834

Epoch: 196| Step: 0
Training loss: 3.0190563544023368
Validation loss: 2.6379098833146144

Epoch: 5| Step: 1
Training loss: 2.7498332753359387
Validation loss: 2.636078557146851

Epoch: 5| Step: 2
Training loss: 3.717950173924951
Validation loss: 2.633528212811344

Epoch: 5| Step: 3
Training loss: 3.040244688927963
Validation loss: 2.6347451431610773

Epoch: 5| Step: 4
Training loss: 2.5703033168825793
Validation loss: 2.632883522689934

Epoch: 5| Step: 5
Training loss: 2.9201433078663386
Validation loss: 2.6311608875993815

Epoch: 5| Step: 6
Training loss: 2.4528157227536678
Validation loss: 2.6318419953482635

Epoch: 5| Step: 7
Training loss: 2.8447039335158153
Validation loss: 2.630634399980743

Epoch: 5| Step: 8
Training loss: 2.962491797584735
Validation loss: 2.6339623198367876

Epoch: 5| Step: 9
Training loss: 2.7953310493037162
Validation loss: 2.632921303954988

Epoch: 5| Step: 10
Training loss: 3.3682250794070865
Validation loss: 2.6315251362711685

Epoch: 197| Step: 0
Training loss: 3.218630297759024
Validation loss: 2.629918631713387

Epoch: 5| Step: 1
Training loss: 2.8628697119089654
Validation loss: 2.6309076848587756

Epoch: 5| Step: 2
Training loss: 2.9821260776488248
Validation loss: 2.633938721052237

Epoch: 5| Step: 3
Training loss: 2.0395112110305824
Validation loss: 2.6294008136083544

Epoch: 5| Step: 4
Training loss: 2.4428642131030673
Validation loss: 2.6338709933325006

Epoch: 5| Step: 5
Training loss: 3.0634463658059095
Validation loss: 2.6343295697212232

Epoch: 5| Step: 6
Training loss: 2.66685639143594
Validation loss: 2.6406012462002177

Epoch: 5| Step: 7
Training loss: 3.2655230784595823
Validation loss: 2.6290274964201448

Epoch: 5| Step: 8
Training loss: 3.3073102494966786
Validation loss: 2.6346584910581066

Epoch: 5| Step: 9
Training loss: 2.772243188877702
Validation loss: 2.6332878481403843

Epoch: 5| Step: 10
Training loss: 3.7179041309195946
Validation loss: 2.6280431145524137

Epoch: 198| Step: 0
Training loss: 2.9401243134251236
Validation loss: 2.627125396733966

Epoch: 5| Step: 1
Training loss: 2.5421246183809356
Validation loss: 2.625823029126692

Epoch: 5| Step: 2
Training loss: 3.17514260640115
Validation loss: 2.6294574677420384

Epoch: 5| Step: 3
Training loss: 2.992657736538538
Validation loss: 2.631008315450117

Epoch: 5| Step: 4
Training loss: 3.0713317577020463
Validation loss: 2.629141562571649

Epoch: 5| Step: 5
Training loss: 3.2514219841206775
Validation loss: 2.634272676834579

Epoch: 5| Step: 6
Training loss: 2.7652599718827826
Validation loss: 2.6462566139534225

Epoch: 5| Step: 7
Training loss: 2.8887408740280383
Validation loss: 2.6394314088619657

Epoch: 5| Step: 8
Training loss: 2.9326724702373412
Validation loss: 2.6431699594126115

Epoch: 5| Step: 9
Training loss: 3.2525854830463605
Validation loss: 2.6344428997923304

Epoch: 5| Step: 10
Training loss: 2.5425585344116315
Validation loss: 2.6328781595407937

Epoch: 199| Step: 0
Training loss: 2.7748107089529586
Validation loss: 2.624675045028196

Epoch: 5| Step: 1
Training loss: 3.0813965427920285
Validation loss: 2.6222878316452425

Epoch: 5| Step: 2
Training loss: 3.289136002324116
Validation loss: 2.6223237115857065

Epoch: 5| Step: 3
Training loss: 3.1542652801726483
Validation loss: 2.6212543605653726

Epoch: 5| Step: 4
Training loss: 2.579447274255014
Validation loss: 2.621216963726776

Epoch: 5| Step: 5
Training loss: 3.0082008804651736
Validation loss: 2.623343971777763

Epoch: 5| Step: 6
Training loss: 2.4163006033929286
Validation loss: 2.617789657983496

Epoch: 5| Step: 7
Training loss: 2.653641171337421
Validation loss: 2.6287625425029177

Epoch: 5| Step: 8
Training loss: 3.3105748178208643
Validation loss: 2.628377598008404

Epoch: 5| Step: 9
Training loss: 2.937159417070204
Validation loss: 2.629432919847268

Epoch: 5| Step: 10
Training loss: 3.156542169626113
Validation loss: 2.6491221554104274

Epoch: 200| Step: 0
Training loss: 2.662986918595974
Validation loss: 2.6503301932142724

Epoch: 5| Step: 1
Training loss: 2.7162515845822988
Validation loss: 2.646325117442199

Epoch: 5| Step: 2
Training loss: 2.9812756167416854
Validation loss: 2.6397972161367287

Epoch: 5| Step: 3
Training loss: 2.895681052469245
Validation loss: 2.642778306366357

Epoch: 5| Step: 4
Training loss: 2.8851216483294393
Validation loss: 2.651616510657446

Epoch: 5| Step: 5
Training loss: 3.043247508844039
Validation loss: 2.627135449765819

Epoch: 5| Step: 6
Training loss: 2.906000270163516
Validation loss: 2.6165380718738356

Epoch: 5| Step: 7
Training loss: 3.239926498898041
Validation loss: 2.6181148487050416

Epoch: 5| Step: 8
Training loss: 3.0215258801993334
Validation loss: 2.6188883407617687

Epoch: 5| Step: 9
Training loss: 2.935536154234416
Validation loss: 2.6195483654444884

Epoch: 5| Step: 10
Training loss: 3.1895005175310076
Validation loss: 2.6193136572044216

Epoch: 201| Step: 0
Training loss: 2.8456580499497215
Validation loss: 2.620677413605086

Epoch: 5| Step: 1
Training loss: 2.9638998466590247
Validation loss: 2.6194660962464638

Epoch: 5| Step: 2
Training loss: 3.2496431594965163
Validation loss: 2.6155948284673736

Epoch: 5| Step: 3
Training loss: 3.1259198170224414
Validation loss: 2.6166554213324615

Epoch: 5| Step: 4
Training loss: 3.10135555778056
Validation loss: 2.622812884491844

Epoch: 5| Step: 5
Training loss: 2.856327621774182
Validation loss: 2.622577143861552

Epoch: 5| Step: 6
Training loss: 2.767593286832146
Validation loss: 2.625657353323255

Epoch: 5| Step: 7
Training loss: 2.9063874899223516
Validation loss: 2.623930282927115

Epoch: 5| Step: 8
Training loss: 2.571589839510442
Validation loss: 2.6305123475823002

Epoch: 5| Step: 9
Training loss: 2.9732171430537218
Validation loss: 2.619158647763711

Epoch: 5| Step: 10
Training loss: 3.080342380022328
Validation loss: 2.6346062321980184

Epoch: 202| Step: 0
Training loss: 3.035199296368652
Validation loss: 2.6364255140948734

Epoch: 5| Step: 1
Training loss: 3.1368654437697665
Validation loss: 2.6277083436395063

Epoch: 5| Step: 2
Training loss: 3.3624908900935204
Validation loss: 2.628415877100348

Epoch: 5| Step: 3
Training loss: 2.958359857001522
Validation loss: 2.6277352627647836

Epoch: 5| Step: 4
Training loss: 2.5368866503350027
Validation loss: 2.622397275611191

Epoch: 5| Step: 5
Training loss: 2.587525493846376
Validation loss: 2.619108887877222

Epoch: 5| Step: 6
Training loss: 2.978009050159524
Validation loss: 2.6189724933512752

Epoch: 5| Step: 7
Training loss: 3.351605323926952
Validation loss: 2.6322013696099464

Epoch: 5| Step: 8
Training loss: 3.0763623762937744
Validation loss: 2.6294387365627276

Epoch: 5| Step: 9
Training loss: 2.931096991671371
Validation loss: 2.623489125750629

Epoch: 5| Step: 10
Training loss: 2.2001333282991014
Validation loss: 2.62414360042215

Epoch: 203| Step: 0
Training loss: 3.238687045782222
Validation loss: 2.618639195849611

Epoch: 5| Step: 1
Training loss: 3.0788712734509454
Validation loss: 2.62376724884797

Epoch: 5| Step: 2
Training loss: 2.6305222327129028
Validation loss: 2.6222452230283637

Epoch: 5| Step: 3
Training loss: 3.3276432745372877
Validation loss: 2.6322146922804346

Epoch: 5| Step: 4
Training loss: 2.689646462532633
Validation loss: 2.631727141275461

Epoch: 5| Step: 5
Training loss: 2.817534116387817
Validation loss: 2.623801397706707

Epoch: 5| Step: 6
Training loss: 3.144168505863151
Validation loss: 2.6358191089552947

Epoch: 5| Step: 7
Training loss: 3.0582616633056623
Validation loss: 2.649208789245365

Epoch: 5| Step: 8
Training loss: 3.1184972626253744
Validation loss: 2.6437168736863548

Epoch: 5| Step: 9
Training loss: 2.5239346135612775
Validation loss: 2.62541695255728

Epoch: 5| Step: 10
Training loss: 2.635819888020838
Validation loss: 2.6191578285053785

Epoch: 204| Step: 0
Training loss: 3.0671463577379474
Validation loss: 2.6219925056677

Epoch: 5| Step: 1
Training loss: 2.8727524306333745
Validation loss: 2.622284538968147

Epoch: 5| Step: 2
Training loss: 3.3420380104592606
Validation loss: 2.6168761208781595

Epoch: 5| Step: 3
Training loss: 2.3653826489896637
Validation loss: 2.616310831123955

Epoch: 5| Step: 4
Training loss: 3.3173084986248758
Validation loss: 2.6169159593006595

Epoch: 5| Step: 5
Training loss: 2.5490159473421676
Validation loss: 2.6236962588367168

Epoch: 5| Step: 6
Training loss: 2.8584686677292175
Validation loss: 2.615618072307311

Epoch: 5| Step: 7
Training loss: 3.3827614725330117
Validation loss: 2.6203382470658245

Epoch: 5| Step: 8
Training loss: 3.2772050903232355
Validation loss: 2.619774496028378

Epoch: 5| Step: 9
Training loss: 2.6275816438514297
Validation loss: 2.622891575979509

Epoch: 5| Step: 10
Training loss: 2.4526961613870983
Validation loss: 2.631985357431951

Epoch: 205| Step: 0
Training loss: 2.8409851383087714
Validation loss: 2.626633363978726

Epoch: 5| Step: 1
Training loss: 3.4622378694210374
Validation loss: 2.6289334903652635

Epoch: 5| Step: 2
Training loss: 3.1480273412658635
Validation loss: 2.6290169425791037

Epoch: 5| Step: 3
Training loss: 2.5221247136970946
Validation loss: 2.6280074151267074

Epoch: 5| Step: 4
Training loss: 2.4991692116285464
Validation loss: 2.6171999616820605

Epoch: 5| Step: 5
Training loss: 3.1485265525169543
Validation loss: 2.608708255758777

Epoch: 5| Step: 6
Training loss: 3.0767416387028867
Validation loss: 2.6129117030243343

Epoch: 5| Step: 7
Training loss: 3.1938507541955814
Validation loss: 2.6138274888048887

Epoch: 5| Step: 8
Training loss: 3.1838428236059717
Validation loss: 2.615074787755488

Epoch: 5| Step: 9
Training loss: 2.4743023014204826
Validation loss: 2.615422147173827

Epoch: 5| Step: 10
Training loss: 2.66588988514149
Validation loss: 2.607883639509872

Epoch: 206| Step: 0
Training loss: 2.4348577214214537
Validation loss: 2.6195732486717156

Epoch: 5| Step: 1
Training loss: 2.760372799698738
Validation loss: 2.6150552977089148

Epoch: 5| Step: 2
Training loss: 3.2479159202028356
Validation loss: 2.623617841632036

Epoch: 5| Step: 3
Training loss: 3.0111363660528263
Validation loss: 2.6347622039115204

Epoch: 5| Step: 4
Training loss: 3.4348275633595713
Validation loss: 2.6263982132222354

Epoch: 5| Step: 5
Training loss: 2.827599155161369
Validation loss: 2.6320302648410396

Epoch: 5| Step: 6
Training loss: 3.024674194697641
Validation loss: 2.630984821713903

Epoch: 5| Step: 7
Training loss: 2.7627501119907554
Validation loss: 2.630648749943397

Epoch: 5| Step: 8
Training loss: 3.1914114794460673
Validation loss: 2.6241837153789507

Epoch: 5| Step: 9
Training loss: 2.488624345489911
Validation loss: 2.6223920738267483

Epoch: 5| Step: 10
Training loss: 2.99260754537816
Validation loss: 2.6116473559585436

Epoch: 207| Step: 0
Training loss: 2.7985848256515626
Validation loss: 2.615673972333062

Epoch: 5| Step: 1
Training loss: 2.9418617493635155
Validation loss: 2.612902663736094

Epoch: 5| Step: 2
Training loss: 3.195830286879167
Validation loss: 2.6209188310967444

Epoch: 5| Step: 3
Training loss: 2.995062579741429
Validation loss: 2.632101762517584

Epoch: 5| Step: 4
Training loss: 2.9803433173147185
Validation loss: 2.646384039370366

Epoch: 5| Step: 5
Training loss: 2.4435757938351914
Validation loss: 2.6582782556295004

Epoch: 5| Step: 6
Training loss: 2.7617506918348185
Validation loss: 2.680638717315476

Epoch: 5| Step: 7
Training loss: 3.2254775765650314
Validation loss: 2.718090973723765

Epoch: 5| Step: 8
Training loss: 3.191172858567338
Validation loss: 2.739506122953574

Epoch: 5| Step: 9
Training loss: 2.8179542213279043
Validation loss: 2.698536564604342

Epoch: 5| Step: 10
Training loss: 3.044928765426777
Validation loss: 2.67338013102484

Epoch: 208| Step: 0
Training loss: 3.0704351890841486
Validation loss: 2.6183775061028407

Epoch: 5| Step: 1
Training loss: 2.8478548375757007
Validation loss: 2.6148315992949622

Epoch: 5| Step: 2
Training loss: 2.608481888202002
Validation loss: 2.6168527696731334

Epoch: 5| Step: 3
Training loss: 3.311472319487133
Validation loss: 2.6209865267122248

Epoch: 5| Step: 4
Training loss: 2.6560886109634128
Validation loss: 2.6247473398351313

Epoch: 5| Step: 5
Training loss: 3.083004873840459
Validation loss: 2.6280510794499277

Epoch: 5| Step: 6
Training loss: 2.715696351899493
Validation loss: 2.636125873738275

Epoch: 5| Step: 7
Training loss: 2.6671395975201433
Validation loss: 2.6339507968899163

Epoch: 5| Step: 8
Training loss: 3.0357431362287812
Validation loss: 2.6275657072835874

Epoch: 5| Step: 9
Training loss: 3.309050869580385
Validation loss: 2.620254105562934

Epoch: 5| Step: 10
Training loss: 3.2886913389152608
Validation loss: 2.6185232863705337

Epoch: 209| Step: 0
Training loss: 2.901803830268399
Validation loss: 2.620202555437996

Epoch: 5| Step: 1
Training loss: 3.184366668300941
Validation loss: 2.631868273137084

Epoch: 5| Step: 2
Training loss: 2.9944119862354523
Validation loss: 2.6314758109184586

Epoch: 5| Step: 3
Training loss: 2.712159862375297
Validation loss: 2.622127985389245

Epoch: 5| Step: 4
Training loss: 2.5631457189779687
Validation loss: 2.627220239342939

Epoch: 5| Step: 5
Training loss: 2.5954579624335126
Validation loss: 2.636523852268345

Epoch: 5| Step: 6
Training loss: 3.143367196470712
Validation loss: 2.6398316470853596

Epoch: 5| Step: 7
Training loss: 2.810771750227802
Validation loss: 2.6382502385533324

Epoch: 5| Step: 8
Training loss: 3.0171748314645352
Validation loss: 2.646878040520843

Epoch: 5| Step: 9
Training loss: 2.8543739150788427
Validation loss: 2.622382150228523

Epoch: 5| Step: 10
Training loss: 3.724820607621253
Validation loss: 2.6168135053610313

Epoch: 210| Step: 0
Training loss: 3.0332946174023245
Validation loss: 2.6240033134143896

Epoch: 5| Step: 1
Training loss: 2.7123732928377886
Validation loss: 2.622734154476807

Epoch: 5| Step: 2
Training loss: 3.0179861046007943
Validation loss: 2.628255047714924

Epoch: 5| Step: 3
Training loss: 3.2251135872643055
Validation loss: 2.6227285242508516

Epoch: 5| Step: 4
Training loss: 2.838133579048811
Validation loss: 2.6158135005790237

Epoch: 5| Step: 5
Training loss: 2.819302364792964
Validation loss: 2.613295099784666

Epoch: 5| Step: 6
Training loss: 3.0119312176798094
Validation loss: 2.6145833395432674

Epoch: 5| Step: 7
Training loss: 3.0974270325718627
Validation loss: 2.611274739493158

Epoch: 5| Step: 8
Training loss: 2.7590040707145103
Validation loss: 2.611356189799796

Epoch: 5| Step: 9
Training loss: 2.8938898567693956
Validation loss: 2.617967881367719

Epoch: 5| Step: 10
Training loss: 2.922819586673573
Validation loss: 2.632196872864727

Epoch: 211| Step: 0
Training loss: 3.2265019076294568
Validation loss: 2.642327347467497

Epoch: 5| Step: 1
Training loss: 3.2957401582365065
Validation loss: 2.636009334168435

Epoch: 5| Step: 2
Training loss: 2.888400484842752
Validation loss: 2.6375896855206773

Epoch: 5| Step: 3
Training loss: 2.853730681224904
Validation loss: 2.6153460706708294

Epoch: 5| Step: 4
Training loss: 3.02567068814472
Validation loss: 2.6107429866570313

Epoch: 5| Step: 5
Training loss: 2.9423505627485054
Validation loss: 2.596274161661567

Epoch: 5| Step: 6
Training loss: 2.627433557078617
Validation loss: 2.600079633977781

Epoch: 5| Step: 7
Training loss: 3.137729809616229
Validation loss: 2.6041786150914565

Epoch: 5| Step: 8
Training loss: 3.094091993753273
Validation loss: 2.610661091035785

Epoch: 5| Step: 9
Training loss: 2.917639615494573
Validation loss: 2.6170201088409883

Epoch: 5| Step: 10
Training loss: 2.3538649936811975
Validation loss: 2.6097305524254035

Epoch: 212| Step: 0
Training loss: 3.0421218183154175
Validation loss: 2.6179101011625416

Epoch: 5| Step: 1
Training loss: 2.772796470813299
Validation loss: 2.6090444751298194

Epoch: 5| Step: 2
Training loss: 3.1821690279257697
Validation loss: 2.6105058594817447

Epoch: 5| Step: 3
Training loss: 3.313710549320096
Validation loss: 2.612326589651049

Epoch: 5| Step: 4
Training loss: 3.0166140500813885
Validation loss: 2.605596170847087

Epoch: 5| Step: 5
Training loss: 2.9304787342996734
Validation loss: 2.59975142061705

Epoch: 5| Step: 6
Training loss: 3.477310203128173
Validation loss: 2.5973393195944663

Epoch: 5| Step: 7
Training loss: 2.5328338753929627
Validation loss: 2.5919441977343327

Epoch: 5| Step: 8
Training loss: 2.8820290263274155
Validation loss: 2.5936081787350598

Epoch: 5| Step: 9
Training loss: 2.583430524248834
Validation loss: 2.5963858870336063

Epoch: 5| Step: 10
Training loss: 2.6815492262965748
Validation loss: 2.6068946383061404

Epoch: 213| Step: 0
Training loss: 3.1941003715495095
Validation loss: 2.6155828854737107

Epoch: 5| Step: 1
Training loss: 2.826667199164766
Validation loss: 2.6314127799730107

Epoch: 5| Step: 2
Training loss: 2.4451204169640786
Validation loss: 2.6491323369006388

Epoch: 5| Step: 3
Training loss: 3.0169785382269576
Validation loss: 2.664843032484765

Epoch: 5| Step: 4
Training loss: 2.8310161165555496
Validation loss: 2.655282441646877

Epoch: 5| Step: 5
Training loss: 2.722456324063232
Validation loss: 2.6378475523004217

Epoch: 5| Step: 6
Training loss: 3.112783739263278
Validation loss: 2.6134086577951177

Epoch: 5| Step: 7
Training loss: 3.1477225653848233
Validation loss: 2.606645722455226

Epoch: 5| Step: 8
Training loss: 2.5729558738367313
Validation loss: 2.599380924064534

Epoch: 5| Step: 9
Training loss: 3.021528878651728
Validation loss: 2.589514245706273

Epoch: 5| Step: 10
Training loss: 3.4699254149410628
Validation loss: 2.5901036325534017

Epoch: 214| Step: 0
Training loss: 2.784637103176412
Validation loss: 2.5906321722562438

Epoch: 5| Step: 1
Training loss: 2.799210154301666
Validation loss: 2.595031936440769

Epoch: 5| Step: 2
Training loss: 2.854470137081271
Validation loss: 2.5939713601199657

Epoch: 5| Step: 3
Training loss: 3.126882062648961
Validation loss: 2.5916296244424863

Epoch: 5| Step: 4
Training loss: 3.035418132152391
Validation loss: 2.591456104998639

Epoch: 5| Step: 5
Training loss: 3.1647185975817633
Validation loss: 2.5956967507128876

Epoch: 5| Step: 6
Training loss: 2.9074807791103274
Validation loss: 2.5917686350018743

Epoch: 5| Step: 7
Training loss: 3.164339481993012
Validation loss: 2.5924598360359594

Epoch: 5| Step: 8
Training loss: 2.3584315959107935
Validation loss: 2.5977809306454764

Epoch: 5| Step: 9
Training loss: 3.2782692585669406
Validation loss: 2.601177659745831

Epoch: 5| Step: 10
Training loss: 2.7392289158458007
Validation loss: 2.6057578881446823

Epoch: 215| Step: 0
Training loss: 3.0288866406018253
Validation loss: 2.626527024698532

Epoch: 5| Step: 1
Training loss: 2.18551109359673
Validation loss: 2.6249107808598087

Epoch: 5| Step: 2
Training loss: 2.9412979572113573
Validation loss: 2.634298348416494

Epoch: 5| Step: 3
Training loss: 3.1484564314431607
Validation loss: 2.6341417711354755

Epoch: 5| Step: 4
Training loss: 2.9811094302899668
Validation loss: 2.610298404516257

Epoch: 5| Step: 5
Training loss: 3.151274734999209
Validation loss: 2.5964949447255834

Epoch: 5| Step: 6
Training loss: 3.150902627867179
Validation loss: 2.5923994674593427

Epoch: 5| Step: 7
Training loss: 2.5347128834545134
Validation loss: 2.5851946432532316

Epoch: 5| Step: 8
Training loss: 2.971931439334114
Validation loss: 2.5860560561351815

Epoch: 5| Step: 9
Training loss: 2.9626991044107682
Validation loss: 2.585699604025214

Epoch: 5| Step: 10
Training loss: 3.1179617395898074
Validation loss: 2.591109238034965

Epoch: 216| Step: 0
Training loss: 2.293416020248213
Validation loss: 2.584986777473803

Epoch: 5| Step: 1
Training loss: 2.844428348330149
Validation loss: 2.586932356358109

Epoch: 5| Step: 2
Training loss: 3.301022781473735
Validation loss: 2.5856735223138734

Epoch: 5| Step: 3
Training loss: 2.4754337662797186
Validation loss: 2.5860479906438374

Epoch: 5| Step: 4
Training loss: 2.9134365360594345
Validation loss: 2.5817233214727096

Epoch: 5| Step: 5
Training loss: 3.231328441619581
Validation loss: 2.592802520836647

Epoch: 5| Step: 6
Training loss: 3.5019675582698944
Validation loss: 2.588494698776017

Epoch: 5| Step: 7
Training loss: 2.974554551058306
Validation loss: 2.6066553863255297

Epoch: 5| Step: 8
Training loss: 3.0686188897057236
Validation loss: 2.6061695293709173

Epoch: 5| Step: 9
Training loss: 2.5611583640078455
Validation loss: 2.615236092435715

Epoch: 5| Step: 10
Training loss: 2.9650808046082733
Validation loss: 2.6176558605512117

Epoch: 217| Step: 0
Training loss: 3.183563793954156
Validation loss: 2.6074091197985383

Epoch: 5| Step: 1
Training loss: 2.803442973768439
Validation loss: 2.5876605341498586

Epoch: 5| Step: 2
Training loss: 2.9175933637283618
Validation loss: 2.590977063832675

Epoch: 5| Step: 3
Training loss: 3.1284718872777657
Validation loss: 2.58530910138253

Epoch: 5| Step: 4
Training loss: 3.464404709447891
Validation loss: 2.587478008813883

Epoch: 5| Step: 5
Training loss: 2.640627708659391
Validation loss: 2.5877617651723512

Epoch: 5| Step: 6
Training loss: 3.0244577347407913
Validation loss: 2.5848092108321876

Epoch: 5| Step: 7
Training loss: 2.392509266387948
Validation loss: 2.5840934719411965

Epoch: 5| Step: 8
Training loss: 3.030784335204905
Validation loss: 2.5849172355709324

Epoch: 5| Step: 9
Training loss: 2.67637879319644
Validation loss: 2.585031597885054

Epoch: 5| Step: 10
Training loss: 2.7723178376463493
Validation loss: 2.5858295506003053

Epoch: 218| Step: 0
Training loss: 2.9357568966475034
Validation loss: 2.5847656164306136

Epoch: 5| Step: 1
Training loss: 2.8096059532410935
Validation loss: 2.5915941356518433

Epoch: 5| Step: 2
Training loss: 2.865486991995243
Validation loss: 2.5954880567564333

Epoch: 5| Step: 3
Training loss: 3.103976676981107
Validation loss: 2.6000141479448025

Epoch: 5| Step: 4
Training loss: 2.3038673105244523
Validation loss: 2.5988802827335666

Epoch: 5| Step: 5
Training loss: 2.768835585672844
Validation loss: 2.6111393534781615

Epoch: 5| Step: 6
Training loss: 3.017019157118726
Validation loss: 2.6105692979944717

Epoch: 5| Step: 7
Training loss: 2.6324412822786334
Validation loss: 2.619912052383356

Epoch: 5| Step: 8
Training loss: 3.2191179676274606
Validation loss: 2.6282060033674437

Epoch: 5| Step: 9
Training loss: 3.3882850272254568
Validation loss: 2.6449970938918224

Epoch: 5| Step: 10
Training loss: 3.0033369579004
Validation loss: 2.6322301468443428

Epoch: 219| Step: 0
Training loss: 2.8253040892740904
Validation loss: 2.617051166968425

Epoch: 5| Step: 1
Training loss: 3.040114664374748
Validation loss: 2.596609181184263

Epoch: 5| Step: 2
Training loss: 2.9957265616442887
Validation loss: 2.58926652585698

Epoch: 5| Step: 3
Training loss: 2.906908022312214
Validation loss: 2.5884365627359336

Epoch: 5| Step: 4
Training loss: 2.791649054476471
Validation loss: 2.589736132703617

Epoch: 5| Step: 5
Training loss: 3.310530454881845
Validation loss: 2.598782691361069

Epoch: 5| Step: 6
Training loss: 3.6422319917649313
Validation loss: 2.5864683738414063

Epoch: 5| Step: 7
Training loss: 2.5244767732781384
Validation loss: 2.5867244052447607

Epoch: 5| Step: 8
Training loss: 2.5125191037794496
Validation loss: 2.5879386324385374

Epoch: 5| Step: 9
Training loss: 2.5962988038634673
Validation loss: 2.587028984629799

Epoch: 5| Step: 10
Training loss: 2.843792254794245
Validation loss: 2.5858122304517726

Epoch: 220| Step: 0
Training loss: 3.0845598066903817
Validation loss: 2.5937049536630172

Epoch: 5| Step: 1
Training loss: 3.1254166897484414
Validation loss: 2.5886232408596324

Epoch: 5| Step: 2
Training loss: 2.9961612300908005
Validation loss: 2.5943315933502356

Epoch: 5| Step: 3
Training loss: 2.7690422368876875
Validation loss: 2.5850688626775877

Epoch: 5| Step: 4
Training loss: 2.9138196583214793
Validation loss: 2.5902655075002405

Epoch: 5| Step: 5
Training loss: 2.8901177038491097
Validation loss: 2.5875539842494417

Epoch: 5| Step: 6
Training loss: 2.503212009779787
Validation loss: 2.586951109905885

Epoch: 5| Step: 7
Training loss: 2.931239009747104
Validation loss: 2.58723007121047

Epoch: 5| Step: 8
Training loss: 2.7968618722959198
Validation loss: 2.590725790874254

Epoch: 5| Step: 9
Training loss: 3.0891001273117737
Validation loss: 2.5873994817752908

Epoch: 5| Step: 10
Training loss: 3.058433479796773
Validation loss: 2.5958089137571023

Epoch: 221| Step: 0
Training loss: 3.538053457146316
Validation loss: 2.6063601175698365

Epoch: 5| Step: 1
Training loss: 2.710126596147268
Validation loss: 2.598067975960312

Epoch: 5| Step: 2
Training loss: 2.877293376911511
Validation loss: 2.5949370317740326

Epoch: 5| Step: 3
Training loss: 2.667213969889843
Validation loss: 2.6163765814355484

Epoch: 5| Step: 4
Training loss: 3.329004449118898
Validation loss: 2.604712727710916

Epoch: 5| Step: 5
Training loss: 2.9011316656446757
Validation loss: 2.616118344549293

Epoch: 5| Step: 6
Training loss: 2.730552835766031
Validation loss: 2.6095734068208936

Epoch: 5| Step: 7
Training loss: 2.7454021337181143
Validation loss: 2.594599249102291

Epoch: 5| Step: 8
Training loss: 3.4267849468592986
Validation loss: 2.5871417652403017

Epoch: 5| Step: 9
Training loss: 2.57364121298408
Validation loss: 2.585625241800045

Epoch: 5| Step: 10
Training loss: 2.3882654051649728
Validation loss: 2.583844994265203

Epoch: 222| Step: 0
Training loss: 3.0932624509790965
Validation loss: 2.5842247661085747

Epoch: 5| Step: 1
Training loss: 2.6902901116528635
Validation loss: 2.583917195224088

Epoch: 5| Step: 2
Training loss: 3.170978588598571
Validation loss: 2.5806600924990537

Epoch: 5| Step: 3
Training loss: 2.712237395482395
Validation loss: 2.581273225719886

Epoch: 5| Step: 4
Training loss: 2.411594549057318
Validation loss: 2.5815416554208617

Epoch: 5| Step: 5
Training loss: 3.4389892126625767
Validation loss: 2.5860022411068506

Epoch: 5| Step: 6
Training loss: 3.0210224136283763
Validation loss: 2.5862828253289636

Epoch: 5| Step: 7
Training loss: 3.0291769273278946
Validation loss: 2.584941227342103

Epoch: 5| Step: 8
Training loss: 2.805538292843258
Validation loss: 2.5842920628821693

Epoch: 5| Step: 9
Training loss: 2.9232334508183566
Validation loss: 2.5970754258571165

Epoch: 5| Step: 10
Training loss: 2.7289070607732118
Validation loss: 2.6017158756499144

Epoch: 223| Step: 0
Training loss: 3.203633635540144
Validation loss: 2.5953217967685145

Epoch: 5| Step: 1
Training loss: 3.302465823831963
Validation loss: 2.598371511783469

Epoch: 5| Step: 2
Training loss: 2.561027569027727
Validation loss: 2.5954592158767307

Epoch: 5| Step: 3
Training loss: 3.063029496487113
Validation loss: 2.5918800545963947

Epoch: 5| Step: 4
Training loss: 2.724319541035875
Validation loss: 2.596384677482851

Epoch: 5| Step: 5
Training loss: 2.909917670589561
Validation loss: 2.5860059973399885

Epoch: 5| Step: 6
Training loss: 2.7561496119480093
Validation loss: 2.5924154842336886

Epoch: 5| Step: 7
Training loss: 2.4573632821037945
Validation loss: 2.602332266893981

Epoch: 5| Step: 8
Training loss: 3.252342846861363
Validation loss: 2.603386036352772

Epoch: 5| Step: 9
Training loss: 2.850182604377463
Validation loss: 2.5970379404644706

Epoch: 5| Step: 10
Training loss: 2.9654226831015382
Validation loss: 2.5940473049827473

Epoch: 224| Step: 0
Training loss: 3.242660304145887
Validation loss: 2.5912265563220616

Epoch: 5| Step: 1
Training loss: 3.2719458046787517
Validation loss: 2.5807855276931857

Epoch: 5| Step: 2
Training loss: 2.776611832592086
Validation loss: 2.5769993208576385

Epoch: 5| Step: 3
Training loss: 3.23654927319436
Validation loss: 2.579056744896404

Epoch: 5| Step: 4
Training loss: 2.679975933422378
Validation loss: 2.5806910189981584

Epoch: 5| Step: 5
Training loss: 2.5973419687700683
Validation loss: 2.580344144540362

Epoch: 5| Step: 6
Training loss: 3.0482265506963415
Validation loss: 2.5857265341621165

Epoch: 5| Step: 7
Training loss: 3.163110962003511
Validation loss: 2.5771758001802305

Epoch: 5| Step: 8
Training loss: 2.5870787531039645
Validation loss: 2.579679708597701

Epoch: 5| Step: 9
Training loss: 2.17038571458749
Validation loss: 2.579088258698684

Epoch: 5| Step: 10
Training loss: 3.2027141028371107
Validation loss: 2.5910590888769085

Epoch: 225| Step: 0
Training loss: 2.700791691458383
Validation loss: 2.596767545717168

Epoch: 5| Step: 1
Training loss: 3.0239058730598702
Validation loss: 2.6267978041483175

Epoch: 5| Step: 2
Training loss: 2.337117079107309
Validation loss: 2.6354589186924438

Epoch: 5| Step: 3
Training loss: 3.4738999361375376
Validation loss: 2.626312446349077

Epoch: 5| Step: 4
Training loss: 2.970739882302593
Validation loss: 2.6282415089133147

Epoch: 5| Step: 5
Training loss: 3.0209840583469045
Validation loss: 2.6017703628262896

Epoch: 5| Step: 6
Training loss: 2.176010914158097
Validation loss: 2.585818046148241

Epoch: 5| Step: 7
Training loss: 3.2150957418990864
Validation loss: 2.582924031062878

Epoch: 5| Step: 8
Training loss: 3.005477514172382
Validation loss: 2.5882254975028602

Epoch: 5| Step: 9
Training loss: 2.6261396204953478
Validation loss: 2.58844519522662

Epoch: 5| Step: 10
Training loss: 3.3555892549665365
Validation loss: 2.589381576243449

Epoch: 226| Step: 0
Training loss: 3.489385312663176
Validation loss: 2.597142181368097

Epoch: 5| Step: 1
Training loss: 2.9372428619170754
Validation loss: 2.5978347434494338

Epoch: 5| Step: 2
Training loss: 2.8478956919867207
Validation loss: 2.6162368068888915

Epoch: 5| Step: 3
Training loss: 3.2408244381546543
Validation loss: 2.6079487185574104

Epoch: 5| Step: 4
Training loss: 2.7308604296481835
Validation loss: 2.6150398543834084

Epoch: 5| Step: 5
Training loss: 2.984310768594619
Validation loss: 2.614879408197508

Epoch: 5| Step: 6
Training loss: 2.902265545085331
Validation loss: 2.6007342991284528

Epoch: 5| Step: 7
Training loss: 2.7619734111171783
Validation loss: 2.5935414647170325

Epoch: 5| Step: 8
Training loss: 2.8344350991401783
Validation loss: 2.577443957375333

Epoch: 5| Step: 9
Training loss: 2.7913705374576256
Validation loss: 2.577510211787849

Epoch: 5| Step: 10
Training loss: 2.3282188038201896
Validation loss: 2.5793121816361633

Epoch: 227| Step: 0
Training loss: 3.038431842551123
Validation loss: 2.571565856762724

Epoch: 5| Step: 1
Training loss: 2.657026558849183
Validation loss: 2.5746329873041467

Epoch: 5| Step: 2
Training loss: 2.9308412441753937
Validation loss: 2.571292394556896

Epoch: 5| Step: 3
Training loss: 3.2767716136850233
Validation loss: 2.5866543173783265

Epoch: 5| Step: 4
Training loss: 2.4155106136189124
Validation loss: 2.5858088020995162

Epoch: 5| Step: 5
Training loss: 3.425414184252643
Validation loss: 2.6064724669626864

Epoch: 5| Step: 6
Training loss: 2.7618110349956386
Validation loss: 2.6217562815592377

Epoch: 5| Step: 7
Training loss: 2.5127097350684022
Validation loss: 2.6348419473949134

Epoch: 5| Step: 8
Training loss: 2.7543302601884805
Validation loss: 2.632376591572541

Epoch: 5| Step: 9
Training loss: 3.298028680791192
Validation loss: 2.601530564201547

Epoch: 5| Step: 10
Training loss: 2.9019292070730756
Validation loss: 2.5967601556990227

Epoch: 228| Step: 0
Training loss: 2.8210410236511634
Validation loss: 2.5874770358604633

Epoch: 5| Step: 1
Training loss: 3.1166653685813555
Validation loss: 2.590369308367528

Epoch: 5| Step: 2
Training loss: 3.0023251106344713
Validation loss: 2.585923738650258

Epoch: 5| Step: 3
Training loss: 2.6606351670583286
Validation loss: 2.57350457535635

Epoch: 5| Step: 4
Training loss: 2.7980477202724536
Validation loss: 2.5715757471685126

Epoch: 5| Step: 5
Training loss: 2.922528035834602
Validation loss: 2.576078899782852

Epoch: 5| Step: 6
Training loss: 2.631259267613996
Validation loss: 2.570918900127556

Epoch: 5| Step: 7
Training loss: 3.0190336106038247
Validation loss: 2.5729384769908403

Epoch: 5| Step: 8
Training loss: 3.0181440989256765
Validation loss: 2.5708329507001757

Epoch: 5| Step: 9
Training loss: 3.136411050832648
Validation loss: 2.5822766994857353

Epoch: 5| Step: 10
Training loss: 2.9269891544997364
Validation loss: 2.593527864308298

Epoch: 229| Step: 0
Training loss: 2.9590193441106125
Validation loss: 2.599502079151484

Epoch: 5| Step: 1
Training loss: 2.616034319171297
Validation loss: 2.6009517121312626

Epoch: 5| Step: 2
Training loss: 3.372410239798902
Validation loss: 2.5938758409388036

Epoch: 5| Step: 3
Training loss: 2.3909801144604614
Validation loss: 2.591376553892906

Epoch: 5| Step: 4
Training loss: 2.8085395903266397
Validation loss: 2.5942618197050176

Epoch: 5| Step: 5
Training loss: 3.39209093319266
Validation loss: 2.5943500266078208

Epoch: 5| Step: 6
Training loss: 2.787476417202259
Validation loss: 2.5886154047107057

Epoch: 5| Step: 7
Training loss: 2.1294748649322957
Validation loss: 2.573963472617811

Epoch: 5| Step: 8
Training loss: 3.31504752606922
Validation loss: 2.580778214590684

Epoch: 5| Step: 9
Training loss: 2.8921511358760323
Validation loss: 2.5909925724157583

Epoch: 5| Step: 10
Training loss: 3.1179521048380403
Validation loss: 2.6085804729372364

Epoch: 230| Step: 0
Training loss: 2.5910205497677645
Validation loss: 2.60512362283059

Epoch: 5| Step: 1
Training loss: 3.186487074330905
Validation loss: 2.6023582614406613

Epoch: 5| Step: 2
Training loss: 2.994145880468724
Validation loss: 2.5946397556241134

Epoch: 5| Step: 3
Training loss: 2.4924697955261377
Validation loss: 2.5828618897293545

Epoch: 5| Step: 4
Training loss: 3.0529736640461502
Validation loss: 2.5814579147852066

Epoch: 5| Step: 5
Training loss: 2.800608779938577
Validation loss: 2.579594458535824

Epoch: 5| Step: 6
Training loss: 3.112032114427097
Validation loss: 2.567761796280184

Epoch: 5| Step: 7
Training loss: 2.955421805960608
Validation loss: 2.5806512342914782

Epoch: 5| Step: 8
Training loss: 3.035702296642062
Validation loss: 2.575699987187772

Epoch: 5| Step: 9
Training loss: 2.6279936477549524
Validation loss: 2.585797020945765

Epoch: 5| Step: 10
Training loss: 2.9671620187574255
Validation loss: 2.583211392459787

Epoch: 231| Step: 0
Training loss: 3.223129404185927
Validation loss: 2.5748550614782637

Epoch: 5| Step: 1
Training loss: 2.5339502131472
Validation loss: 2.5740517556146

Epoch: 5| Step: 2
Training loss: 3.111535476700549
Validation loss: 2.566304975253184

Epoch: 5| Step: 3
Training loss: 2.623290458952506
Validation loss: 2.5675893926293134

Epoch: 5| Step: 4
Training loss: 3.044155687558975
Validation loss: 2.5714040309225257

Epoch: 5| Step: 5
Training loss: 2.7103751091162085
Validation loss: 2.559630540417116

Epoch: 5| Step: 6
Training loss: 2.836735552688377
Validation loss: 2.565067256805398

Epoch: 5| Step: 7
Training loss: 3.1996643724862173
Validation loss: 2.5611560127301183

Epoch: 5| Step: 8
Training loss: 3.0085530744134297
Validation loss: 2.5718041470392454

Epoch: 5| Step: 9
Training loss: 2.8102630196195015
Validation loss: 2.584247345711692

Epoch: 5| Step: 10
Training loss: 2.7566780155906176
Validation loss: 2.5715216281093602

Epoch: 232| Step: 0
Training loss: 2.6486069166522217
Validation loss: 2.5894023624495466

Epoch: 5| Step: 1
Training loss: 3.089025569959367
Validation loss: 2.585380800859821

Epoch: 5| Step: 2
Training loss: 2.951587579559029
Validation loss: 2.5898413257769732

Epoch: 5| Step: 3
Training loss: 3.1027852682055297
Validation loss: 2.586331520786012

Epoch: 5| Step: 4
Training loss: 3.1566201172417303
Validation loss: 2.5883857883309935

Epoch: 5| Step: 5
Training loss: 2.586222653066934
Validation loss: 2.5897190544872233

Epoch: 5| Step: 6
Training loss: 2.7958357601088912
Validation loss: 2.5708787782210782

Epoch: 5| Step: 7
Training loss: 2.84374027460133
Validation loss: 2.5796860071837067

Epoch: 5| Step: 8
Training loss: 2.580253600882468
Validation loss: 2.5816239415247453

Epoch: 5| Step: 9
Training loss: 2.772522853416593
Validation loss: 2.5774923095782545

Epoch: 5| Step: 10
Training loss: 3.306092020165316
Validation loss: 2.577225390878302

Epoch: 233| Step: 0
Training loss: 2.5136041520961605
Validation loss: 2.5815144542132216

Epoch: 5| Step: 1
Training loss: 2.4216216908544865
Validation loss: 2.5926614921845217

Epoch: 5| Step: 2
Training loss: 3.0992309108502276
Validation loss: 2.5951955093032315

Epoch: 5| Step: 3
Training loss: 3.261257043014296
Validation loss: 2.619943440233949

Epoch: 5| Step: 4
Training loss: 2.9335981386763943
Validation loss: 2.6080563235337024

Epoch: 5| Step: 5
Training loss: 2.7548956209822766
Validation loss: 2.6272898949030004

Epoch: 5| Step: 6
Training loss: 2.86343745577066
Validation loss: 2.625049633566717

Epoch: 5| Step: 7
Training loss: 3.4931565546728796
Validation loss: 2.6260850463766925

Epoch: 5| Step: 8
Training loss: 3.0046836531639767
Validation loss: 2.593432698002105

Epoch: 5| Step: 9
Training loss: 2.5791581366854497
Validation loss: 2.576629331111011

Epoch: 5| Step: 10
Training loss: 2.761890540924167
Validation loss: 2.562468248676323

Epoch: 234| Step: 0
Training loss: 3.11728279905038
Validation loss: 2.55587883073898

Epoch: 5| Step: 1
Training loss: 2.573388760353566
Validation loss: 2.5644254336266163

Epoch: 5| Step: 2
Training loss: 3.478492595375759
Validation loss: 2.5647248644763

Epoch: 5| Step: 3
Training loss: 2.4463031943516462
Validation loss: 2.5618132464596166

Epoch: 5| Step: 4
Training loss: 2.545827544893051
Validation loss: 2.5583194443157105

Epoch: 5| Step: 5
Training loss: 2.7384283921437356
Validation loss: 2.5614057766289813

Epoch: 5| Step: 6
Training loss: 2.9527350274196427
Validation loss: 2.560682584179708

Epoch: 5| Step: 7
Training loss: 2.829269599072064
Validation loss: 2.5677874539060705

Epoch: 5| Step: 8
Training loss: 2.905313976870524
Validation loss: 2.566834720467012

Epoch: 5| Step: 9
Training loss: 2.7976896495471233
Validation loss: 2.5725923051189583

Epoch: 5| Step: 10
Training loss: 3.4756423246778136
Validation loss: 2.5946972023441996

Epoch: 235| Step: 0
Training loss: 3.3238614133458384
Validation loss: 2.602158312392699

Epoch: 5| Step: 1
Training loss: 2.3966834398336183
Validation loss: 2.6298334807144936

Epoch: 5| Step: 2
Training loss: 3.1323229628431815
Validation loss: 2.693053728325516

Epoch: 5| Step: 3
Training loss: 2.289174464485247
Validation loss: 2.655461219680596

Epoch: 5| Step: 4
Training loss: 2.950242669420887
Validation loss: 2.652693787643765

Epoch: 5| Step: 5
Training loss: 3.006638334892187
Validation loss: 2.637561368187007

Epoch: 5| Step: 6
Training loss: 2.910132327397479
Validation loss: 2.601427588092954

Epoch: 5| Step: 7
Training loss: 3.3655130776839974
Validation loss: 2.587651203555402

Epoch: 5| Step: 8
Training loss: 2.8378980180994544
Validation loss: 2.5728896047753165

Epoch: 5| Step: 9
Training loss: 2.809481717841955
Validation loss: 2.572626266309001

Epoch: 5| Step: 10
Training loss: 2.808640268760269
Validation loss: 2.565525642741291

Epoch: 236| Step: 0
Training loss: 2.8250795268790077
Validation loss: 2.5716873463120935

Epoch: 5| Step: 1
Training loss: 2.8573848281304834
Validation loss: 2.567251681060418

Epoch: 5| Step: 2
Training loss: 2.5382644103276237
Validation loss: 2.572427142510183

Epoch: 5| Step: 3
Training loss: 2.6569495682357602
Validation loss: 2.5678193051871485

Epoch: 5| Step: 4
Training loss: 3.1055065224707543
Validation loss: 2.5722064543879175

Epoch: 5| Step: 5
Training loss: 2.920909211991161
Validation loss: 2.582467532149015

Epoch: 5| Step: 6
Training loss: 3.125391821139316
Validation loss: 2.5762145540269286

Epoch: 5| Step: 7
Training loss: 2.972786498255296
Validation loss: 2.5842666018572227

Epoch: 5| Step: 8
Training loss: 2.8883209118481514
Validation loss: 2.5939901443132167

Epoch: 5| Step: 9
Training loss: 3.081075890131087
Validation loss: 2.6034475469848033

Epoch: 5| Step: 10
Training loss: 2.862961151424418
Validation loss: 2.612490591848792

Epoch: 237| Step: 0
Training loss: 3.037230108382012
Validation loss: 2.6134047702609715

Epoch: 5| Step: 1
Training loss: 2.5234473260741352
Validation loss: 2.6204369062164443

Epoch: 5| Step: 2
Training loss: 2.6295405581984648
Validation loss: 2.6136225172165126

Epoch: 5| Step: 3
Training loss: 2.7541225050840157
Validation loss: 2.6056476055706392

Epoch: 5| Step: 4
Training loss: 3.2998250625943166
Validation loss: 2.602291648601955

Epoch: 5| Step: 5
Training loss: 2.520679490200147
Validation loss: 2.598798008351972

Epoch: 5| Step: 6
Training loss: 2.8236937819816537
Validation loss: 2.5911606407556613

Epoch: 5| Step: 7
Training loss: 3.45105470761776
Validation loss: 2.584042296708648

Epoch: 5| Step: 8
Training loss: 3.123236654597688
Validation loss: 2.587760167702346

Epoch: 5| Step: 9
Training loss: 2.380960814370251
Validation loss: 2.5971405417934634

Epoch: 5| Step: 10
Training loss: 3.0806793613014056
Validation loss: 2.5830158547318627

Epoch: 238| Step: 0
Training loss: 2.610157740711562
Validation loss: 2.5778179335112665

Epoch: 5| Step: 1
Training loss: 3.0109637510207485
Validation loss: 2.56830519615126

Epoch: 5| Step: 2
Training loss: 2.7252806352769663
Validation loss: 2.5651837463344167

Epoch: 5| Step: 3
Training loss: 3.302728744312542
Validation loss: 2.558381433232846

Epoch: 5| Step: 4
Training loss: 2.733825279563361
Validation loss: 2.56576854063509

Epoch: 5| Step: 5
Training loss: 2.8895119663511557
Validation loss: 2.5607477535469214

Epoch: 5| Step: 6
Training loss: 3.262050442762265
Validation loss: 2.5601030870320476

Epoch: 5| Step: 7
Training loss: 2.6001750006835476
Validation loss: 2.5668187138599547

Epoch: 5| Step: 8
Training loss: 2.9526008261859484
Validation loss: 2.5709224949192975

Epoch: 5| Step: 9
Training loss: 3.1579050691335198
Validation loss: 2.6095214158169653

Epoch: 5| Step: 10
Training loss: 2.3032924762015163
Validation loss: 2.6067013369190266

Epoch: 239| Step: 0
Training loss: 2.712233176050601
Validation loss: 2.6091242723738164

Epoch: 5| Step: 1
Training loss: 2.8863117101390725
Validation loss: 2.630633107749364

Epoch: 5| Step: 2
Training loss: 2.0106773273369223
Validation loss: 2.6953062775837138

Epoch: 5| Step: 3
Training loss: 3.0396156886267542
Validation loss: 2.7460617175355133

Epoch: 5| Step: 4
Training loss: 3.4603366028772986
Validation loss: 2.6788482983108537

Epoch: 5| Step: 5
Training loss: 3.2070493895079264
Validation loss: 2.6080651407580167

Epoch: 5| Step: 6
Training loss: 2.789451764294322
Validation loss: 2.5809128470562936

Epoch: 5| Step: 7
Training loss: 2.524077059831432
Validation loss: 2.579755275708502

Epoch: 5| Step: 8
Training loss: 3.084595670990156
Validation loss: 2.572922063467055

Epoch: 5| Step: 9
Training loss: 3.1985352919126653
Validation loss: 2.573852995089689

Epoch: 5| Step: 10
Training loss: 2.7197235819664995
Validation loss: 2.571010646514694

Epoch: 240| Step: 0
Training loss: 3.4188786456296576
Validation loss: 2.5802601355281722

Epoch: 5| Step: 1
Training loss: 2.826397953336543
Validation loss: 2.5861214376325017

Epoch: 5| Step: 2
Training loss: 3.010098784843953
Validation loss: 2.5767838505807843

Epoch: 5| Step: 3
Training loss: 2.851078859885009
Validation loss: 2.5631713287940845

Epoch: 5| Step: 4
Training loss: 3.0357720377581674
Validation loss: 2.5601177552306216

Epoch: 5| Step: 5
Training loss: 2.347273251081024
Validation loss: 2.558947435882508

Epoch: 5| Step: 6
Training loss: 2.887144065156138
Validation loss: 2.5749710395188776

Epoch: 5| Step: 7
Training loss: 2.990573696864358
Validation loss: 2.578258502246903

Epoch: 5| Step: 8
Training loss: 2.5825030520514356
Validation loss: 2.604112825554914

Epoch: 5| Step: 9
Training loss: 2.850358431847202
Validation loss: 2.626537354291656

Epoch: 5| Step: 10
Training loss: 3.0823417478160318
Validation loss: 2.69013134515046

Epoch: 241| Step: 0
Training loss: 2.794559223311253
Validation loss: 2.7048427480715582

Epoch: 5| Step: 1
Training loss: 3.204330887242534
Validation loss: 2.701741182247638

Epoch: 5| Step: 2
Training loss: 2.3690599143171776
Validation loss: 2.6772220242552924

Epoch: 5| Step: 3
Training loss: 3.318417715331036
Validation loss: 2.6583779099222817

Epoch: 5| Step: 4
Training loss: 2.8025000072142356
Validation loss: 2.6034185471160334

Epoch: 5| Step: 5
Training loss: 3.160307438538077
Validation loss: 2.5720539165202787

Epoch: 5| Step: 6
Training loss: 2.436179757199211
Validation loss: 2.555113794326723

Epoch: 5| Step: 7
Training loss: 2.5601337020947397
Validation loss: 2.5587784930359834

Epoch: 5| Step: 8
Training loss: 3.099525993778468
Validation loss: 2.5584866799817987

Epoch: 5| Step: 9
Training loss: 3.0319573275197786
Validation loss: 2.570881877967429

Epoch: 5| Step: 10
Training loss: 3.069957916518058
Validation loss: 2.5715057030158794

Epoch: 242| Step: 0
Training loss: 3.163148649135206
Validation loss: 2.561209525034543

Epoch: 5| Step: 1
Training loss: 2.800807383480544
Validation loss: 2.5617317991093205

Epoch: 5| Step: 2
Training loss: 2.69088647083668
Validation loss: 2.5555259079199493

Epoch: 5| Step: 3
Training loss: 3.0264048443224314
Validation loss: 2.5573061678718596

Epoch: 5| Step: 4
Training loss: 2.739058663103862
Validation loss: 2.560833462830869

Epoch: 5| Step: 5
Training loss: 3.24606128589174
Validation loss: 2.5650503471595534

Epoch: 5| Step: 6
Training loss: 2.55010771804383
Validation loss: 2.5567047713488273

Epoch: 5| Step: 7
Training loss: 3.118242357790123
Validation loss: 2.5561391787617933

Epoch: 5| Step: 8
Training loss: 2.743287390289066
Validation loss: 2.5534795869757634

Epoch: 5| Step: 9
Training loss: 2.898479944622678
Validation loss: 2.5566248218007193

Epoch: 5| Step: 10
Training loss: 2.865966204149169
Validation loss: 2.5524822690931104

Epoch: 243| Step: 0
Training loss: 2.645120980393057
Validation loss: 2.548928607611267

Epoch: 5| Step: 1
Training loss: 3.3801009166482108
Validation loss: 2.5527001963691593

Epoch: 5| Step: 2
Training loss: 3.288727006994969
Validation loss: 2.556165394337025

Epoch: 5| Step: 3
Training loss: 2.445889438416728
Validation loss: 2.568903891912732

Epoch: 5| Step: 4
Training loss: 3.3646056151857895
Validation loss: 2.575351573448387

Epoch: 5| Step: 5
Training loss: 2.579262037676006
Validation loss: 2.6087496644781605

Epoch: 5| Step: 6
Training loss: 2.9988513972959656
Validation loss: 2.601045519153064

Epoch: 5| Step: 7
Training loss: 2.6402603890866856
Validation loss: 2.6015574073267422

Epoch: 5| Step: 8
Training loss: 2.798669505765631
Validation loss: 2.5987602479147025

Epoch: 5| Step: 9
Training loss: 2.7014568672245822
Validation loss: 2.5729706042699454

Epoch: 5| Step: 10
Training loss: 2.825198434932815
Validation loss: 2.568450168274511

Epoch: 244| Step: 0
Training loss: 3.1965475889852573
Validation loss: 2.5508278091207415

Epoch: 5| Step: 1
Training loss: 2.7426511367144286
Validation loss: 2.5553606093690684

Epoch: 5| Step: 2
Training loss: 3.274950064940906
Validation loss: 2.553367016327901

Epoch: 5| Step: 3
Training loss: 3.42006367161246
Validation loss: 2.5507454391202184

Epoch: 5| Step: 4
Training loss: 1.858580732199774
Validation loss: 2.5570122287302275

Epoch: 5| Step: 5
Training loss: 2.332007122074722
Validation loss: 2.5477746939257155

Epoch: 5| Step: 6
Training loss: 3.1377105095142404
Validation loss: 2.551029951438942

Epoch: 5| Step: 7
Training loss: 2.712233703479934
Validation loss: 2.5459787319365987

Epoch: 5| Step: 8
Training loss: 2.5913712037700734
Validation loss: 2.5459785305491556

Epoch: 5| Step: 9
Training loss: 2.9589779290358833
Validation loss: 2.5500167994918

Epoch: 5| Step: 10
Training loss: 3.1685185455121445
Validation loss: 2.555834872271281

Epoch: 245| Step: 0
Training loss: 3.3132805534421426
Validation loss: 2.563291322952294

Epoch: 5| Step: 1
Training loss: 2.9227234939470947
Validation loss: 2.577096031093287

Epoch: 5| Step: 2
Training loss: 2.6031681638804893
Validation loss: 2.5696123664909822

Epoch: 5| Step: 3
Training loss: 2.856237806298336
Validation loss: 2.5858625606777665

Epoch: 5| Step: 4
Training loss: 3.156854703781689
Validation loss: 2.6037439681701215

Epoch: 5| Step: 5
Training loss: 2.310853629818125
Validation loss: 2.598641218745937

Epoch: 5| Step: 6
Training loss: 3.2735611703313072
Validation loss: 2.6296763499924865

Epoch: 5| Step: 7
Training loss: 2.853339490735312
Validation loss: 2.5859558106803227

Epoch: 5| Step: 8
Training loss: 2.7637640947787374
Validation loss: 2.578336377022515

Epoch: 5| Step: 9
Training loss: 2.2874520010159567
Validation loss: 2.5634593243388024

Epoch: 5| Step: 10
Training loss: 3.224690261279208
Validation loss: 2.557129685729785

Epoch: 246| Step: 0
Training loss: 2.4927643015777114
Validation loss: 2.54796101023568

Epoch: 5| Step: 1
Training loss: 2.897118445643177
Validation loss: 2.544437119664062

Epoch: 5| Step: 2
Training loss: 3.112008977558357
Validation loss: 2.541516141369593

Epoch: 5| Step: 3
Training loss: 3.2156819656412527
Validation loss: 2.543231823794428

Epoch: 5| Step: 4
Training loss: 2.6155390316270095
Validation loss: 2.5586971935561356

Epoch: 5| Step: 5
Training loss: 2.9329999177908666
Validation loss: 2.55324945250307

Epoch: 5| Step: 6
Training loss: 2.902511982001808
Validation loss: 2.5467097741354783

Epoch: 5| Step: 7
Training loss: 2.806140916229233
Validation loss: 2.5633873092341126

Epoch: 5| Step: 8
Training loss: 2.71284404629515
Validation loss: 2.563253382501914

Epoch: 5| Step: 9
Training loss: 2.6417197943157573
Validation loss: 2.5764997821978426

Epoch: 5| Step: 10
Training loss: 3.3049590447870494
Validation loss: 2.587173085929335

Epoch: 247| Step: 0
Training loss: 2.984853975695559
Validation loss: 2.5759971401602155

Epoch: 5| Step: 1
Training loss: 3.0813112759639076
Validation loss: 2.590504437937092

Epoch: 5| Step: 2
Training loss: 2.725473968163199
Validation loss: 2.5714489584760982

Epoch: 5| Step: 3
Training loss: 2.8629441628828802
Validation loss: 2.5578529245417263

Epoch: 5| Step: 4
Training loss: 2.8101038580330315
Validation loss: 2.553851726951043

Epoch: 5| Step: 5
Training loss: 2.859051795578353
Validation loss: 2.546829763766059

Epoch: 5| Step: 6
Training loss: 3.107303715442841
Validation loss: 2.550193824133651

Epoch: 5| Step: 7
Training loss: 2.812849235044743
Validation loss: 2.554170223301124

Epoch: 5| Step: 8
Training loss: 2.636949678834166
Validation loss: 2.569615283694005

Epoch: 5| Step: 9
Training loss: 3.070650892561982
Validation loss: 2.5689397310829745

Epoch: 5| Step: 10
Training loss: 2.5590913943821985
Validation loss: 2.5987768356240704

Epoch: 248| Step: 0
Training loss: 2.613130163093216
Validation loss: 2.5939655038988962

Epoch: 5| Step: 1
Training loss: 2.9319657482837154
Validation loss: 2.612732519522145

Epoch: 5| Step: 2
Training loss: 2.493415171390225
Validation loss: 2.637936431082334

Epoch: 5| Step: 3
Training loss: 2.607371857695595
Validation loss: 2.645594457130348

Epoch: 5| Step: 4
Training loss: 3.1777466795436333
Validation loss: 2.5975388638483174

Epoch: 5| Step: 5
Training loss: 2.786946239121271
Validation loss: 2.5644416975961954

Epoch: 5| Step: 6
Training loss: 2.7223975607355237
Validation loss: 2.5551266861734576

Epoch: 5| Step: 7
Training loss: 2.9814246808265015
Validation loss: 2.545754577853601

Epoch: 5| Step: 8
Training loss: 3.2917872217692503
Validation loss: 2.5470008600067504

Epoch: 5| Step: 9
Training loss: 2.750635507152263
Validation loss: 2.5450314023889984

Epoch: 5| Step: 10
Training loss: 3.312863599866925
Validation loss: 2.5520308676059087

Epoch: 249| Step: 0
Training loss: 3.2014438590412255
Validation loss: 2.55708305688114

Epoch: 5| Step: 1
Training loss: 3.0243852100960704
Validation loss: 2.5558527616784623

Epoch: 5| Step: 2
Training loss: 3.1072797760760977
Validation loss: 2.563401468094122

Epoch: 5| Step: 3
Training loss: 2.8503239698485614
Validation loss: 2.5662726786149896

Epoch: 5| Step: 4
Training loss: 2.5397598013355958
Validation loss: 2.5777472613641965

Epoch: 5| Step: 5
Training loss: 3.075615339041135
Validation loss: 2.5630553039287536

Epoch: 5| Step: 6
Training loss: 3.0161892852174006
Validation loss: 2.562170039957355

Epoch: 5| Step: 7
Training loss: 2.6749190451948164
Validation loss: 2.5563923961946546

Epoch: 5| Step: 8
Training loss: 3.1616584592989856
Validation loss: 2.5590531352048953

Epoch: 5| Step: 9
Training loss: 1.968595105087549
Validation loss: 2.580522293612695

Epoch: 5| Step: 10
Training loss: 2.6945790937760106
Validation loss: 2.5890872704091863

Epoch: 250| Step: 0
Training loss: 3.1554547809424798
Validation loss: 2.5917274089978415

Epoch: 5| Step: 1
Training loss: 2.8679878302812085
Validation loss: 2.600263830237301

Epoch: 5| Step: 2
Training loss: 3.1981293217203186
Validation loss: 2.5942265210833435

Epoch: 5| Step: 3
Training loss: 3.3150155933870677
Validation loss: 2.5726006350192443

Epoch: 5| Step: 4
Training loss: 2.8430183223921577
Validation loss: 2.559946308901239

Epoch: 5| Step: 5
Training loss: 2.3979493678890456
Validation loss: 2.5540936432610026

Epoch: 5| Step: 6
Training loss: 3.072765816471932
Validation loss: 2.541438873374063

Epoch: 5| Step: 7
Training loss: 2.927610917698048
Validation loss: 2.5484328144490362

Epoch: 5| Step: 8
Training loss: 2.7546667902054933
Validation loss: 2.5410759143654746

Epoch: 5| Step: 9
Training loss: 2.706028167583646
Validation loss: 2.5347826386126826

Epoch: 5| Step: 10
Training loss: 2.1977179438952557
Validation loss: 2.536216853885194

Epoch: 251| Step: 0
Training loss: 3.005594441398738
Validation loss: 2.5330939443991585

Epoch: 5| Step: 1
Training loss: 2.9878012277857127
Validation loss: 2.5493738571104214

Epoch: 5| Step: 2
Training loss: 2.7220936526430837
Validation loss: 2.560788683406557

Epoch: 5| Step: 3
Training loss: 2.562683378031476
Validation loss: 2.5685623942758706

Epoch: 5| Step: 4
Training loss: 3.1494261748798094
Validation loss: 2.589201383188803

Epoch: 5| Step: 5
Training loss: 2.7366429106331362
Validation loss: 2.595447996106163

Epoch: 5| Step: 6
Training loss: 2.8313204590238477
Validation loss: 2.587459545424618

Epoch: 5| Step: 7
Training loss: 3.09617904711153
Validation loss: 2.5811127951335098

Epoch: 5| Step: 8
Training loss: 3.1012988230664926
Validation loss: 2.5828167597008234

Epoch: 5| Step: 9
Training loss: 2.6338427421126425
Validation loss: 2.57360151951814

Epoch: 5| Step: 10
Training loss: 2.69739202359295
Validation loss: 2.56529125736686

Epoch: 252| Step: 0
Training loss: 3.145815228205911
Validation loss: 2.5672137606931367

Epoch: 5| Step: 1
Training loss: 2.9052407758143044
Validation loss: 2.543301204183911

Epoch: 5| Step: 2
Training loss: 3.022192725882234
Validation loss: 2.5397477439906195

Epoch: 5| Step: 3
Training loss: 3.113567956528631
Validation loss: 2.5413459852571885

Epoch: 5| Step: 4
Training loss: 2.468946328384363
Validation loss: 2.5491294664161077

Epoch: 5| Step: 5
Training loss: 2.547664683730722
Validation loss: 2.5378588881890742

Epoch: 5| Step: 6
Training loss: 2.820523494531312
Validation loss: 2.5468906503016973

Epoch: 5| Step: 7
Training loss: 2.687488910740884
Validation loss: 2.559422350308786

Epoch: 5| Step: 8
Training loss: 2.6199204480855665
Validation loss: 2.562971691474822

Epoch: 5| Step: 9
Training loss: 3.104891050334656
Validation loss: 2.559893951917725

Epoch: 5| Step: 10
Training loss: 3.101743755281099
Validation loss: 2.5570905159499637

Epoch: 253| Step: 0
Training loss: 2.4581233328225123
Validation loss: 2.557001361609772

Epoch: 5| Step: 1
Training loss: 2.6416897404702935
Validation loss: 2.5345710025648764

Epoch: 5| Step: 2
Training loss: 3.5180604086195406
Validation loss: 2.535073865307178

Epoch: 5| Step: 3
Training loss: 3.331964561447963
Validation loss: 2.533555875860286

Epoch: 5| Step: 4
Training loss: 3.1063355585668773
Validation loss: 2.5406146014638145

Epoch: 5| Step: 5
Training loss: 2.8459232954678386
Validation loss: 2.5419510749992855

Epoch: 5| Step: 6
Training loss: 3.0524491404452396
Validation loss: 2.5415534420067396

Epoch: 5| Step: 7
Training loss: 2.7507697675314167
Validation loss: 2.5449759381793866

Epoch: 5| Step: 8
Training loss: 2.5089579310442325
Validation loss: 2.542043473063651

Epoch: 5| Step: 9
Training loss: 3.0067079571964026
Validation loss: 2.5461956652953375

Epoch: 5| Step: 10
Training loss: 2.3811331412409342
Validation loss: 2.5492740195658614

Epoch: 254| Step: 0
Training loss: 2.713664593294894
Validation loss: 2.5476868447366505

Epoch: 5| Step: 1
Training loss: 2.9788218656603864
Validation loss: 2.5518230882308606

Epoch: 5| Step: 2
Training loss: 2.9096148300887967
Validation loss: 2.5473100965118243

Epoch: 5| Step: 3
Training loss: 3.0407042003953224
Validation loss: 2.5507680819142204

Epoch: 5| Step: 4
Training loss: 2.897002078070404
Validation loss: 2.5507118881381343

Epoch: 5| Step: 5
Training loss: 2.7808467272591297
Validation loss: 2.55252481140755

Epoch: 5| Step: 6
Training loss: 2.4465028833075646
Validation loss: 2.5683785097084804

Epoch: 5| Step: 7
Training loss: 3.0444008196035606
Validation loss: 2.5607621707751753

Epoch: 5| Step: 8
Training loss: 2.9147133598926867
Validation loss: 2.5746718921929634

Epoch: 5| Step: 9
Training loss: 3.270708571725281
Validation loss: 2.5779948510276296

Epoch: 5| Step: 10
Training loss: 2.3734691102947165
Validation loss: 2.5921456531747133

Epoch: 255| Step: 0
Training loss: 3.085833815752226
Validation loss: 2.5812976754393655

Epoch: 5| Step: 1
Training loss: 3.0497312020845806
Validation loss: 2.5667823576719795

Epoch: 5| Step: 2
Training loss: 2.9781115248416286
Validation loss: 2.55824264776357

Epoch: 5| Step: 3
Training loss: 3.139991050999032
Validation loss: 2.5668032399958007

Epoch: 5| Step: 4
Training loss: 2.6494002041311897
Validation loss: 2.5559817833762346

Epoch: 5| Step: 5
Training loss: 2.9614416815448044
Validation loss: 2.546116138400057

Epoch: 5| Step: 6
Training loss: 3.132233145171031
Validation loss: 2.5446572209327867

Epoch: 5| Step: 7
Training loss: 2.515844679060636
Validation loss: 2.545093302972364

Epoch: 5| Step: 8
Training loss: 2.849115026838549
Validation loss: 2.5447659013933537

Epoch: 5| Step: 9
Training loss: 2.1555167900392505
Validation loss: 2.5438773817176816

Epoch: 5| Step: 10
Training loss: 2.761958909012892
Validation loss: 2.563137129305323

Epoch: 256| Step: 0
Training loss: 2.4938702776592034
Validation loss: 2.555806148652804

Epoch: 5| Step: 1
Training loss: 2.491031294820216
Validation loss: 2.5972339268010596

Epoch: 5| Step: 2
Training loss: 2.6859421761623508
Validation loss: 2.6151598291648233

Epoch: 5| Step: 3
Training loss: 3.460847943871644
Validation loss: 2.6565284713327695

Epoch: 5| Step: 4
Training loss: 2.8488053879954447
Validation loss: 2.66996162285884

Epoch: 5| Step: 5
Training loss: 3.1692719701150045
Validation loss: 2.6148389720643617

Epoch: 5| Step: 6
Training loss: 2.8774433534085766
Validation loss: 2.566328406794177

Epoch: 5| Step: 7
Training loss: 2.5119814816903943
Validation loss: 2.542019681523541

Epoch: 5| Step: 8
Training loss: 3.2283008686324584
Validation loss: 2.5402427879572222

Epoch: 5| Step: 9
Training loss: 3.0212757356657884
Validation loss: 2.5420210621670907

Epoch: 5| Step: 10
Training loss: 3.11248286598729
Validation loss: 2.543173360710759

Epoch: 257| Step: 0
Training loss: 3.369928434840245
Validation loss: 2.54169198589601

Epoch: 5| Step: 1
Training loss: 2.427558579528712
Validation loss: 2.5492224017806695

Epoch: 5| Step: 2
Training loss: 3.5234353346722838
Validation loss: 2.5459123759258278

Epoch: 5| Step: 3
Training loss: 2.7432336795022083
Validation loss: 2.547344426968955

Epoch: 5| Step: 4
Training loss: 2.660732660568443
Validation loss: 2.547120901346442

Epoch: 5| Step: 5
Training loss: 2.6752203806000416
Validation loss: 2.5456482548524364

Epoch: 5| Step: 6
Training loss: 2.9046478777681886
Validation loss: 2.5397529111427883

Epoch: 5| Step: 7
Training loss: 3.1499306141311005
Validation loss: 2.543053615910565

Epoch: 5| Step: 8
Training loss: 2.691116649621286
Validation loss: 2.5384599342673857

Epoch: 5| Step: 9
Training loss: 2.7891928591570196
Validation loss: 2.538084204221876

Epoch: 5| Step: 10
Training loss: 2.9165453931028225
Validation loss: 2.545781225631841

Epoch: 258| Step: 0
Training loss: 2.531501851680349
Validation loss: 2.534030980267299

Epoch: 5| Step: 1
Training loss: 2.9441171340238044
Validation loss: 2.5511088985684682

Epoch: 5| Step: 2
Training loss: 2.561188338856064
Validation loss: 2.5672739031629073

Epoch: 5| Step: 3
Training loss: 3.209024495241439
Validation loss: 2.5573329158235008

Epoch: 5| Step: 4
Training loss: 2.987889961105953
Validation loss: 2.57974041905205

Epoch: 5| Step: 5
Training loss: 1.9830628509833765
Validation loss: 2.5797440840331767

Epoch: 5| Step: 6
Training loss: 2.9317180463211328
Validation loss: 2.5892913486110865

Epoch: 5| Step: 7
Training loss: 3.2160459845277662
Validation loss: 2.5915168610760104

Epoch: 5| Step: 8
Training loss: 2.9671282705589586
Validation loss: 2.6025553207599175

Epoch: 5| Step: 9
Training loss: 3.283626458755942
Validation loss: 2.5751608884228774

Epoch: 5| Step: 10
Training loss: 2.8735908703843775
Validation loss: 2.5514966004389854

Epoch: 259| Step: 0
Training loss: 2.5702343960753935
Validation loss: 2.5421156208510496

Epoch: 5| Step: 1
Training loss: 2.785564633426381
Validation loss: 2.5320307678146667

Epoch: 5| Step: 2
Training loss: 3.0370377805066253
Validation loss: 2.5277760887418315

Epoch: 5| Step: 3
Training loss: 2.962998450472913
Validation loss: 2.530460444680981

Epoch: 5| Step: 4
Training loss: 2.790485264952319
Validation loss: 2.530069897231004

Epoch: 5| Step: 5
Training loss: 2.9475739799967213
Validation loss: 2.5357420579299697

Epoch: 5| Step: 6
Training loss: 3.1000067126293724
Validation loss: 2.5432280457148404

Epoch: 5| Step: 7
Training loss: 3.123436345858263
Validation loss: 2.54052376094562

Epoch: 5| Step: 8
Training loss: 3.052572078869211
Validation loss: 2.544573892039256

Epoch: 5| Step: 9
Training loss: 2.7328890005127424
Validation loss: 2.552124371344123

Epoch: 5| Step: 10
Training loss: 2.1968229805877235
Validation loss: 2.5437754236898784

Epoch: 260| Step: 0
Training loss: 2.915504405644254
Validation loss: 2.54401419879761

Epoch: 5| Step: 1
Training loss: 2.6677459579092537
Validation loss: 2.554117566238499

Epoch: 5| Step: 2
Training loss: 2.9376439810022337
Validation loss: 2.550362119351925

Epoch: 5| Step: 3
Training loss: 2.1620129957487815
Validation loss: 2.545377237447516

Epoch: 5| Step: 4
Training loss: 2.9449916027318537
Validation loss: 2.5655212689535416

Epoch: 5| Step: 5
Training loss: 3.2495197528192383
Validation loss: 2.5545783233921275

Epoch: 5| Step: 6
Training loss: 3.1219433903959426
Validation loss: 2.569716519761181

Epoch: 5| Step: 7
Training loss: 3.3241838930770173
Validation loss: 2.5577329087832275

Epoch: 5| Step: 8
Training loss: 2.985960853601112
Validation loss: 2.5556443811875447

Epoch: 5| Step: 9
Training loss: 2.270866802097259
Validation loss: 2.55142936707108

Epoch: 5| Step: 10
Training loss: 2.5361205913379976
Validation loss: 2.5410250814388853

Epoch: 261| Step: 0
Training loss: 2.4666992554788636
Validation loss: 2.543919018358839

Epoch: 5| Step: 1
Training loss: 2.7054285366452633
Validation loss: 2.524963963626202

Epoch: 5| Step: 2
Training loss: 2.594256432051716
Validation loss: 2.532331204617062

Epoch: 5| Step: 3
Training loss: 2.651377978223898
Validation loss: 2.5497374075075734

Epoch: 5| Step: 4
Training loss: 2.961478875825051
Validation loss: 2.530889079499198

Epoch: 5| Step: 5
Training loss: 2.62238026639276
Validation loss: 2.5334469573694913

Epoch: 5| Step: 6
Training loss: 2.652134658145035
Validation loss: 2.5441641292342587

Epoch: 5| Step: 7
Training loss: 2.990449325838871
Validation loss: 2.543799557585703

Epoch: 5| Step: 8
Training loss: 3.0032047003134608
Validation loss: 2.540796245514044

Epoch: 5| Step: 9
Training loss: 3.2913810187549113
Validation loss: 2.5582297255220006

Epoch: 5| Step: 10
Training loss: 3.3901511709440078
Validation loss: 2.5421886207383517

Epoch: 262| Step: 0
Training loss: 2.682248951593415
Validation loss: 2.548329271126723

Epoch: 5| Step: 1
Training loss: 2.748689252417188
Validation loss: 2.547241510698784

Epoch: 5| Step: 2
Training loss: 3.1378986424548234
Validation loss: 2.546209928312128

Epoch: 5| Step: 3
Training loss: 2.6818478609097425
Validation loss: 2.5572173789468597

Epoch: 5| Step: 4
Training loss: 2.6981255488497857
Validation loss: 2.573405057333255

Epoch: 5| Step: 5
Training loss: 2.8432006305288153
Validation loss: 2.586308048433285

Epoch: 5| Step: 6
Training loss: 3.200076257273905
Validation loss: 2.6052961788460776

Epoch: 5| Step: 7
Training loss: 2.988862024853821
Validation loss: 2.6187647800771003

Epoch: 5| Step: 8
Training loss: 3.0173695316253295
Validation loss: 2.6107257002066264

Epoch: 5| Step: 9
Training loss: 2.8562558363973807
Validation loss: 2.615545857436097

Epoch: 5| Step: 10
Training loss: 2.411306938104263
Validation loss: 2.5880555654889252

Epoch: 263| Step: 0
Training loss: 2.9585134603617407
Validation loss: 2.552346702448498

Epoch: 5| Step: 1
Training loss: 3.2340214485396133
Validation loss: 2.549279141262682

Epoch: 5| Step: 2
Training loss: 3.072562832046329
Validation loss: 2.5349301336694774

Epoch: 5| Step: 3
Training loss: 2.4779896760529985
Validation loss: 2.535079178506911

Epoch: 5| Step: 4
Training loss: 3.1335656837456183
Validation loss: 2.535512222464579

Epoch: 5| Step: 5
Training loss: 2.6084496233512033
Validation loss: 2.528047156566878

Epoch: 5| Step: 6
Training loss: 2.7372724603993914
Validation loss: 2.526797564743057

Epoch: 5| Step: 7
Training loss: 2.9159670581081962
Validation loss: 2.5407860617471107

Epoch: 5| Step: 8
Training loss: 2.6470084596966377
Validation loss: 2.5431669434695565

Epoch: 5| Step: 9
Training loss: 2.522753170983349
Validation loss: 2.5672920683543015

Epoch: 5| Step: 10
Training loss: 2.984114710456616
Validation loss: 2.5912575565582117

Epoch: 264| Step: 0
Training loss: 2.8436094815256983
Validation loss: 2.578486798338614

Epoch: 5| Step: 1
Training loss: 2.825212528032581
Validation loss: 2.559118575471592

Epoch: 5| Step: 2
Training loss: 3.0059174351726954
Validation loss: 2.553950290407302

Epoch: 5| Step: 3
Training loss: 2.929266082972162
Validation loss: 2.536327245388647

Epoch: 5| Step: 4
Training loss: 2.4889606883652338
Validation loss: 2.5360676929411174

Epoch: 5| Step: 5
Training loss: 2.9778710239987376
Validation loss: 2.523787504901187

Epoch: 5| Step: 6
Training loss: 2.6995683324975737
Validation loss: 2.522761324002764

Epoch: 5| Step: 7
Training loss: 2.8064066683869426
Validation loss: 2.521013535320165

Epoch: 5| Step: 8
Training loss: 2.9653445337321855
Validation loss: 2.5241638599106966

Epoch: 5| Step: 9
Training loss: 2.8271231378401667
Validation loss: 2.520871853582851

Epoch: 5| Step: 10
Training loss: 2.924954836244037
Validation loss: 2.535379266213207

Epoch: 265| Step: 0
Training loss: 3.061824490531002
Validation loss: 2.539313659614414

Epoch: 5| Step: 1
Training loss: 2.641348925794665
Validation loss: 2.5395289898897255

Epoch: 5| Step: 2
Training loss: 3.0612162799465614
Validation loss: 2.5428896842349102

Epoch: 5| Step: 3
Training loss: 2.840932267527975
Validation loss: 2.566108927505514

Epoch: 5| Step: 4
Training loss: 2.4941176829406873
Validation loss: 2.569200157548689

Epoch: 5| Step: 5
Training loss: 2.9216922152051925
Validation loss: 2.5986150775107597

Epoch: 5| Step: 6
Training loss: 2.698750037033837
Validation loss: 2.6336100855654188

Epoch: 5| Step: 7
Training loss: 2.79822537519706
Validation loss: 2.6056010903320095

Epoch: 5| Step: 8
Training loss: 2.9211490157582896
Validation loss: 2.5925372229222283

Epoch: 5| Step: 9
Training loss: 2.979718315073191
Validation loss: 2.5702048887991795

Epoch: 5| Step: 10
Training loss: 2.786794643368589
Validation loss: 2.582787178796391

Epoch: 266| Step: 0
Training loss: 2.0552155138970787
Validation loss: 2.5591175306283582

Epoch: 5| Step: 1
Training loss: 2.5662150551283656
Validation loss: 2.5438360940965548

Epoch: 5| Step: 2
Training loss: 2.9598840938247823
Validation loss: 2.545809188279022

Epoch: 5| Step: 3
Training loss: 2.4471778458107822
Validation loss: 2.5337938767941375

Epoch: 5| Step: 4
Training loss: 3.4140119396105972
Validation loss: 2.53348206258631

Epoch: 5| Step: 5
Training loss: 3.1546206659470974
Validation loss: 2.5384460437941514

Epoch: 5| Step: 6
Training loss: 2.854890736160927
Validation loss: 2.533774922046576

Epoch: 5| Step: 7
Training loss: 2.8735377698187987
Validation loss: 2.5402014937403914

Epoch: 5| Step: 8
Training loss: 3.336704567977573
Validation loss: 2.5497709029424005

Epoch: 5| Step: 9
Training loss: 2.369511536749827
Validation loss: 2.558408163930403

Epoch: 5| Step: 10
Training loss: 2.822224399569148
Validation loss: 2.5530049156611847

Epoch: 267| Step: 0
Training loss: 2.807099052054133
Validation loss: 2.5870990732462693

Epoch: 5| Step: 1
Training loss: 2.6409651858813112
Validation loss: 2.611638642119045

Epoch: 5| Step: 2
Training loss: 3.072952804783973
Validation loss: 2.5883922341060233

Epoch: 5| Step: 3
Training loss: 2.897298501671529
Validation loss: 2.575187149279747

Epoch: 5| Step: 4
Training loss: 2.723922719534207
Validation loss: 2.574586755121152

Epoch: 5| Step: 5
Training loss: 2.8682194237826133
Validation loss: 2.5796104768023134

Epoch: 5| Step: 6
Training loss: 2.265210133419715
Validation loss: 2.5611761001196665

Epoch: 5| Step: 7
Training loss: 3.0716692617912185
Validation loss: 2.555808709477406

Epoch: 5| Step: 8
Training loss: 2.810949279522984
Validation loss: 2.5468492373888467

Epoch: 5| Step: 9
Training loss: 2.6138376233862433
Validation loss: 2.542991319892708

Epoch: 5| Step: 10
Training loss: 3.3949214592502046
Validation loss: 2.539285100450864

Epoch: 268| Step: 0
Training loss: 2.9517925829086717
Validation loss: 2.552923342944454

Epoch: 5| Step: 1
Training loss: 2.7263178237391177
Validation loss: 2.5712654398674935

Epoch: 5| Step: 2
Training loss: 2.7739771358260055
Validation loss: 2.634446512514145

Epoch: 5| Step: 3
Training loss: 2.69040629243458
Validation loss: 2.70855311944674

Epoch: 5| Step: 4
Training loss: 2.702947357161878
Validation loss: 2.692115781488684

Epoch: 5| Step: 5
Training loss: 2.9903389820860116
Validation loss: 2.7004218886978943

Epoch: 5| Step: 6
Training loss: 2.615811934450949
Validation loss: 2.664742218249947

Epoch: 5| Step: 7
Training loss: 3.1994259200130526
Validation loss: 2.6124838836639133

Epoch: 5| Step: 8
Training loss: 3.353788334772785
Validation loss: 2.5812249016350397

Epoch: 5| Step: 9
Training loss: 2.4199862098300935
Validation loss: 2.5262515577204407

Epoch: 5| Step: 10
Training loss: 2.8446968933506893
Validation loss: 2.514986646500118

Epoch: 269| Step: 0
Training loss: 2.7733457738187726
Validation loss: 2.516085297812094

Epoch: 5| Step: 1
Training loss: 2.4833431380246904
Validation loss: 2.527580338786588

Epoch: 5| Step: 2
Training loss: 2.8446824777201147
Validation loss: 2.541403992055918

Epoch: 5| Step: 3
Training loss: 3.2376306338079517
Validation loss: 2.5453951540227457

Epoch: 5| Step: 4
Training loss: 3.289167606368767
Validation loss: 2.5523154204470533

Epoch: 5| Step: 5
Training loss: 2.4301175537246453
Validation loss: 2.550351861198739

Epoch: 5| Step: 6
Training loss: 2.9498309782066823
Validation loss: 2.556276090723325

Epoch: 5| Step: 7
Training loss: 3.1755995657400997
Validation loss: 2.5680508742767514

Epoch: 5| Step: 8
Training loss: 3.0680373597736383
Validation loss: 2.5596114394678926

Epoch: 5| Step: 9
Training loss: 2.887594583126493
Validation loss: 2.5474135886739284

Epoch: 5| Step: 10
Training loss: 2.963870244283844
Validation loss: 2.539809382716793

Epoch: 270| Step: 0
Training loss: 3.2299762982423
Validation loss: 2.5300416066107325

Epoch: 5| Step: 1
Training loss: 2.4941834496127715
Validation loss: 2.5198307842151193

Epoch: 5| Step: 2
Training loss: 2.8289267736500054
Validation loss: 2.516643472138279

Epoch: 5| Step: 3
Training loss: 3.2105727533860926
Validation loss: 2.5098409202264693

Epoch: 5| Step: 4
Training loss: 3.1263525515349766
Validation loss: 2.5137405047666683

Epoch: 5| Step: 5
Training loss: 2.7934799473447165
Validation loss: 2.511326987631104

Epoch: 5| Step: 6
Training loss: 2.788016670823026
Validation loss: 2.520678128378562

Epoch: 5| Step: 7
Training loss: 3.235840985798897
Validation loss: 2.5344196195328705

Epoch: 5| Step: 8
Training loss: 2.07959460159191
Validation loss: 2.5447970203167065

Epoch: 5| Step: 9
Training loss: 2.819105571641484
Validation loss: 2.565484974321609

Epoch: 5| Step: 10
Training loss: 2.508617046275354
Validation loss: 2.6052675134579304

Epoch: 271| Step: 0
Training loss: 2.2314581338526627
Validation loss: 2.6123333266992947

Epoch: 5| Step: 1
Training loss: 2.8802699012913124
Validation loss: 2.671520715077591

Epoch: 5| Step: 2
Training loss: 3.4675128552034202
Validation loss: 2.6108230582333296

Epoch: 5| Step: 3
Training loss: 3.2984637007763715
Validation loss: 2.594532270068471

Epoch: 5| Step: 4
Training loss: 2.153285102815879
Validation loss: 2.5552619638667355

Epoch: 5| Step: 5
Training loss: 2.8633515269982284
Validation loss: 2.548583168960819

Epoch: 5| Step: 6
Training loss: 2.610042463812195
Validation loss: 2.5266974520297976

Epoch: 5| Step: 7
Training loss: 2.941657350721728
Validation loss: 2.51331709634419

Epoch: 5| Step: 8
Training loss: 2.9559387043132723
Validation loss: 2.509245710250533

Epoch: 5| Step: 9
Training loss: 2.744663088330665
Validation loss: 2.514067404890779

Epoch: 5| Step: 10
Training loss: 3.022546129150759
Validation loss: 2.5206803414653947

Epoch: 272| Step: 0
Training loss: 3.3272473248072516
Validation loss: 2.522375833056777

Epoch: 5| Step: 1
Training loss: 3.167851644625802
Validation loss: 2.522523418367282

Epoch: 5| Step: 2
Training loss: 2.8154128355645938
Validation loss: 2.5149000526178407

Epoch: 5| Step: 3
Training loss: 2.6086104866306647
Validation loss: 2.524036172508714

Epoch: 5| Step: 4
Training loss: 2.472956104387232
Validation loss: 2.5257161563218253

Epoch: 5| Step: 5
Training loss: 3.0870683746723757
Validation loss: 2.528272069380941

Epoch: 5| Step: 6
Training loss: 2.801726156583104
Validation loss: 2.5224473197217874

Epoch: 5| Step: 7
Training loss: 3.024589693600808
Validation loss: 2.517800341062041

Epoch: 5| Step: 8
Training loss: 3.0893952518010037
Validation loss: 2.5197512772947843

Epoch: 5| Step: 9
Training loss: 2.7947498964384234
Validation loss: 2.538279995550753

Epoch: 5| Step: 10
Training loss: 1.834996408360264
Validation loss: 2.5439188540951836

Epoch: 273| Step: 0
Training loss: 2.345649254884651
Validation loss: 2.5601916877604847

Epoch: 5| Step: 1
Training loss: 3.1562648055229787
Validation loss: 2.5806957276771274

Epoch: 5| Step: 2
Training loss: 2.7032186679377257
Validation loss: 2.5657599007918823

Epoch: 5| Step: 3
Training loss: 2.608084536580663
Validation loss: 2.5745167271669835

Epoch: 5| Step: 4
Training loss: 2.974050668506711
Validation loss: 2.5532492275914276

Epoch: 5| Step: 5
Training loss: 3.1786323314973584
Validation loss: 2.5373943382631228

Epoch: 5| Step: 6
Training loss: 2.8187807948424366
Validation loss: 2.5282795363865653

Epoch: 5| Step: 7
Training loss: 2.4632944597300814
Validation loss: 2.5189318070460636

Epoch: 5| Step: 8
Training loss: 2.878080459233511
Validation loss: 2.5150233936414446

Epoch: 5| Step: 9
Training loss: 3.172456133744362
Validation loss: 2.521163976374372

Epoch: 5| Step: 10
Training loss: 2.7551340382780243
Validation loss: 2.513728486814375

Epoch: 274| Step: 0
Training loss: 2.683756327805968
Validation loss: 2.508132415812282

Epoch: 5| Step: 1
Training loss: 2.801281574416874
Validation loss: 2.5223691138951865

Epoch: 5| Step: 2
Training loss: 3.0200741219424345
Validation loss: 2.521179765941217

Epoch: 5| Step: 3
Training loss: 2.7782962844962737
Validation loss: 2.5286204328127537

Epoch: 5| Step: 4
Training loss: 2.9353275788223563
Validation loss: 2.538942643106176

Epoch: 5| Step: 5
Training loss: 2.672858252497793
Validation loss: 2.5362264131244854

Epoch: 5| Step: 6
Training loss: 2.532691827496272
Validation loss: 2.540326843739943

Epoch: 5| Step: 7
Training loss: 2.2893743204984873
Validation loss: 2.553702512855149

Epoch: 5| Step: 8
Training loss: 3.2268273196409583
Validation loss: 2.557515765195172

Epoch: 5| Step: 9
Training loss: 3.1649207940819784
Validation loss: 2.5816092267033532

Epoch: 5| Step: 10
Training loss: 2.765408178763511
Validation loss: 2.581409693469402

Epoch: 275| Step: 0
Training loss: 2.8584778425723454
Validation loss: 2.581945499706931

Epoch: 5| Step: 1
Training loss: 2.9101729629343915
Validation loss: 2.5662551155864706

Epoch: 5| Step: 2
Training loss: 2.882714577435813
Validation loss: 2.565662357571497

Epoch: 5| Step: 3
Training loss: 3.005597614394402
Validation loss: 2.5460271188358714

Epoch: 5| Step: 4
Training loss: 2.7243762501072495
Validation loss: 2.523000290376289

Epoch: 5| Step: 5
Training loss: 2.9178236346948037
Validation loss: 2.521005574946174

Epoch: 5| Step: 6
Training loss: 3.152352977110489
Validation loss: 2.523723574269038

Epoch: 5| Step: 7
Training loss: 2.8971018219903804
Validation loss: 2.508269510536145

Epoch: 5| Step: 8
Training loss: 2.0668403731941614
Validation loss: 2.508090286272846

Epoch: 5| Step: 9
Training loss: 2.8683328030142627
Validation loss: 2.51373702197327

Epoch: 5| Step: 10
Training loss: 2.776806743228542
Validation loss: 2.5128798571768

Epoch: 276| Step: 0
Training loss: 2.693450195905747
Validation loss: 2.5216076562610246

Epoch: 5| Step: 1
Training loss: 2.7444744083589496
Validation loss: 2.5246997803819617

Epoch: 5| Step: 2
Training loss: 3.268156977409699
Validation loss: 2.5298917360288113

Epoch: 5| Step: 3
Training loss: 2.348459014489462
Validation loss: 2.528169718278845

Epoch: 5| Step: 4
Training loss: 2.9078801003233345
Validation loss: 2.540398720379734

Epoch: 5| Step: 5
Training loss: 2.6684019482678263
Validation loss: 2.5507853932796074

Epoch: 5| Step: 6
Training loss: 2.4829153895440177
Validation loss: 2.5518292225005044

Epoch: 5| Step: 7
Training loss: 2.8323561909490174
Validation loss: 2.561915051005553

Epoch: 5| Step: 8
Training loss: 2.335525731566676
Validation loss: 2.573486361372313

Epoch: 5| Step: 9
Training loss: 2.9311306666828174
Validation loss: 2.584749065758485

Epoch: 5| Step: 10
Training loss: 3.721445084732107
Validation loss: 2.6058021515725054

Epoch: 277| Step: 0
Training loss: 2.606769563037564
Validation loss: 2.641271981938602

Epoch: 5| Step: 1
Training loss: 2.814085365215225
Validation loss: 2.646350069546576

Epoch: 5| Step: 2
Training loss: 3.14098056279787
Validation loss: 2.664904338627591

Epoch: 5| Step: 3
Training loss: 2.6650854031904547
Validation loss: 2.6197254220890334

Epoch: 5| Step: 4
Training loss: 3.437463656146651
Validation loss: 2.5849415308205654

Epoch: 5| Step: 5
Training loss: 2.612862546304832
Validation loss: 2.5681996879529794

Epoch: 5| Step: 6
Training loss: 2.752104647426577
Validation loss: 2.562847399029528

Epoch: 5| Step: 7
Training loss: 3.0171346887977473
Validation loss: 2.5655128381243597

Epoch: 5| Step: 8
Training loss: 3.0047798225871
Validation loss: 2.541083109687355

Epoch: 5| Step: 9
Training loss: 2.5892085566558016
Validation loss: 2.5292947029005934

Epoch: 5| Step: 10
Training loss: 2.229106854738581
Validation loss: 2.534790594153046

Epoch: 278| Step: 0
Training loss: 2.040106962616126
Validation loss: 2.5164744928069713

Epoch: 5| Step: 1
Training loss: 3.091644032713373
Validation loss: 2.525874879432917

Epoch: 5| Step: 2
Training loss: 2.935236769163988
Validation loss: 2.523267309413899

Epoch: 5| Step: 3
Training loss: 2.702319251128921
Validation loss: 2.514466744842087

Epoch: 5| Step: 4
Training loss: 3.039666044815033
Validation loss: 2.5250146396553306

Epoch: 5| Step: 5
Training loss: 3.0920729281965738
Validation loss: 2.5083592256907545

Epoch: 5| Step: 6
Training loss: 2.0207780129113195
Validation loss: 2.51286715157088

Epoch: 5| Step: 7
Training loss: 2.9421380944948243
Validation loss: 2.517117755929641

Epoch: 5| Step: 8
Training loss: 3.0107470972328603
Validation loss: 2.5171832587857437

Epoch: 5| Step: 9
Training loss: 3.128448719571924
Validation loss: 2.5078361488903482

Epoch: 5| Step: 10
Training loss: 2.8182795163668644
Validation loss: 2.510887772380978

Epoch: 279| Step: 0
Training loss: 3.5728131307979907
Validation loss: 2.513549065334976

Epoch: 5| Step: 1
Training loss: 2.5452289527777467
Validation loss: 2.5141772710227728

Epoch: 5| Step: 2
Training loss: 3.346760758018286
Validation loss: 2.520976092463211

Epoch: 5| Step: 3
Training loss: 2.952253909534596
Validation loss: 2.5181251351091647

Epoch: 5| Step: 4
Training loss: 2.3150627781901876
Validation loss: 2.5203718737492347

Epoch: 5| Step: 5
Training loss: 2.9711703422758893
Validation loss: 2.517171435501154

Epoch: 5| Step: 6
Training loss: 3.092108859565241
Validation loss: 2.506005176027147

Epoch: 5| Step: 7
Training loss: 2.4601316071018386
Validation loss: 2.50756150788416

Epoch: 5| Step: 8
Training loss: 2.3923105518428707
Validation loss: 2.5032815684316634

Epoch: 5| Step: 9
Training loss: 2.815414105814496
Validation loss: 2.5224401749068885

Epoch: 5| Step: 10
Training loss: 2.2773629084676017
Validation loss: 2.53927398684339

Epoch: 280| Step: 0
Training loss: 2.7880399309360944
Validation loss: 2.5452251192430086

Epoch: 5| Step: 1
Training loss: 2.444849524986988
Validation loss: 2.562807484368489

Epoch: 5| Step: 2
Training loss: 2.6668048961893707
Validation loss: 2.571199592864637

Epoch: 5| Step: 3
Training loss: 2.8689549790496827
Validation loss: 2.6026340711616625

Epoch: 5| Step: 4
Training loss: 2.926144993660735
Validation loss: 2.585475414273987

Epoch: 5| Step: 5
Training loss: 3.361503884631705
Validation loss: 2.5397322838570004

Epoch: 5| Step: 6
Training loss: 2.6369697507845506
Validation loss: 2.51603202505298

Epoch: 5| Step: 7
Training loss: 2.6571246334042833
Validation loss: 2.505811531214339

Epoch: 5| Step: 8
Training loss: 2.971358588725529
Validation loss: 2.502283784149625

Epoch: 5| Step: 9
Training loss: 2.9028314973848333
Validation loss: 2.5021296198249443

Epoch: 5| Step: 10
Training loss: 2.874709736642343
Validation loss: 2.497289342723942

Epoch: 281| Step: 0
Training loss: 2.9542762086804433
Validation loss: 2.5063982632298627

Epoch: 5| Step: 1
Training loss: 2.927743332781076
Validation loss: 2.501427533085638

Epoch: 5| Step: 2
Training loss: 2.7766423151139836
Validation loss: 2.49918352197061

Epoch: 5| Step: 3
Training loss: 3.027814511028673
Validation loss: 2.5037820449377457

Epoch: 5| Step: 4
Training loss: 2.980125557475368
Validation loss: 2.508777668693154

Epoch: 5| Step: 5
Training loss: 3.1280124640253044
Validation loss: 2.509585968210315

Epoch: 5| Step: 6
Training loss: 2.7062504510680916
Validation loss: 2.525317656253845

Epoch: 5| Step: 7
Training loss: 2.2849877450226215
Validation loss: 2.5201688521405057

Epoch: 5| Step: 8
Training loss: 2.589047316677624
Validation loss: 2.530852523217129

Epoch: 5| Step: 9
Training loss: 2.9223534503411295
Validation loss: 2.5408931633085303

Epoch: 5| Step: 10
Training loss: 2.6228898058892773
Validation loss: 2.5479313813495836

Epoch: 282| Step: 0
Training loss: 3.1021794010724117
Validation loss: 2.565936345859379

Epoch: 5| Step: 1
Training loss: 2.6418168126546466
Validation loss: 2.584519284427624

Epoch: 5| Step: 2
Training loss: 3.1782146670015003
Validation loss: 2.604501283538705

Epoch: 5| Step: 3
Training loss: 3.0329160536038593
Validation loss: 2.631880501663146

Epoch: 5| Step: 4
Training loss: 2.5676937038373704
Validation loss: 2.6412841329565633

Epoch: 5| Step: 5
Training loss: 2.7130548744656036
Validation loss: 2.62899280013055

Epoch: 5| Step: 6
Training loss: 3.088377478075263
Validation loss: 2.618812828476218

Epoch: 5| Step: 7
Training loss: 2.296197285220991
Validation loss: 2.569195837912631

Epoch: 5| Step: 8
Training loss: 3.0078862168827762
Validation loss: 2.544019607196931

Epoch: 5| Step: 9
Training loss: 2.448704131603755
Validation loss: 2.5049628118103913

Epoch: 5| Step: 10
Training loss: 2.866295616029805
Validation loss: 2.5019820754558366

Epoch: 283| Step: 0
Training loss: 3.0406933799339133
Validation loss: 2.5062580557668066

Epoch: 5| Step: 1
Training loss: 2.496830552413319
Validation loss: 2.507912495644571

Epoch: 5| Step: 2
Training loss: 2.362856185139936
Validation loss: 2.500221722522758

Epoch: 5| Step: 3
Training loss: 2.876096433463259
Validation loss: 2.5053518334051104

Epoch: 5| Step: 4
Training loss: 2.725594684910721
Validation loss: 2.496368709907202

Epoch: 5| Step: 5
Training loss: 2.732192209120384
Validation loss: 2.4903979515673877

Epoch: 5| Step: 6
Training loss: 3.338686237190502
Validation loss: 2.5104654544226643

Epoch: 5| Step: 7
Training loss: 2.6494553672082057
Validation loss: 2.5135643519786837

Epoch: 5| Step: 8
Training loss: 3.1472632251061348
Validation loss: 2.5368178302089635

Epoch: 5| Step: 9
Training loss: 2.65700484377384
Validation loss: 2.578901775599639

Epoch: 5| Step: 10
Training loss: 2.896618706847922
Validation loss: 2.5984713502791537

Epoch: 284| Step: 0
Training loss: 2.4923096629847734
Validation loss: 2.6122252334964324

Epoch: 5| Step: 1
Training loss: 2.7829313018302817
Validation loss: 2.601677953588623

Epoch: 5| Step: 2
Training loss: 2.7304401096048
Validation loss: 2.573972157631746

Epoch: 5| Step: 3
Training loss: 2.9064915054226033
Validation loss: 2.529831808414755

Epoch: 5| Step: 4
Training loss: 2.276403635486843
Validation loss: 2.52854718010937

Epoch: 5| Step: 5
Training loss: 3.198667970226426
Validation loss: 2.5148915795109925

Epoch: 5| Step: 6
Training loss: 2.7975348008678376
Validation loss: 2.517355051190121

Epoch: 5| Step: 7
Training loss: 2.652733932807401
Validation loss: 2.5215267494512035

Epoch: 5| Step: 8
Training loss: 2.723720348068954
Validation loss: 2.5166469152558744

Epoch: 5| Step: 9
Training loss: 3.253710316120356
Validation loss: 2.5212725032461627

Epoch: 5| Step: 10
Training loss: 3.0024305670060687
Validation loss: 2.5392888096873

Epoch: 285| Step: 0
Training loss: 2.134959275797542
Validation loss: 2.554132389258216

Epoch: 5| Step: 1
Training loss: 2.663546694046028
Validation loss: 2.5733255479365327

Epoch: 5| Step: 2
Training loss: 3.5093864189363004
Validation loss: 2.582595820811224

Epoch: 5| Step: 3
Training loss: 2.8747289778633034
Validation loss: 2.5958072111210257

Epoch: 5| Step: 4
Training loss: 2.566787946816433
Validation loss: 2.6361308753170736

Epoch: 5| Step: 5
Training loss: 2.076916565572416
Validation loss: 2.6432039216114696

Epoch: 5| Step: 6
Training loss: 2.9673055246673186
Validation loss: 2.6343128798671214

Epoch: 5| Step: 7
Training loss: 2.9632182735365773
Validation loss: 2.5956114686727547

Epoch: 5| Step: 8
Training loss: 3.0754263419489365
Validation loss: 2.5799909683473916

Epoch: 5| Step: 9
Training loss: 2.6653289022264133
Validation loss: 2.554908343751872

Epoch: 5| Step: 10
Training loss: 3.4851192483517597
Validation loss: 2.545719531099169

Epoch: 286| Step: 0
Training loss: 3.0623059892508713
Validation loss: 2.5419541177404477

Epoch: 5| Step: 1
Training loss: 2.9789636894028706
Validation loss: 2.544918836814487

Epoch: 5| Step: 2
Training loss: 2.5313473906442754
Validation loss: 2.5554932102129198

Epoch: 5| Step: 3
Training loss: 2.956036298257965
Validation loss: 2.5537998583733126

Epoch: 5| Step: 4
Training loss: 2.6029167430868108
Validation loss: 2.571201542116479

Epoch: 5| Step: 5
Training loss: 3.167371587762222
Validation loss: 2.5717959954836362

Epoch: 5| Step: 6
Training loss: 2.792925043364315
Validation loss: 2.5784198093994704

Epoch: 5| Step: 7
Training loss: 2.5862932680768735
Validation loss: 2.597852961391874

Epoch: 5| Step: 8
Training loss: 2.6989572842791123
Validation loss: 2.603799607198472

Epoch: 5| Step: 9
Training loss: 2.7118594665856137
Validation loss: 2.610256927062445

Epoch: 5| Step: 10
Training loss: 2.6697289844367718
Validation loss: 2.6038901709341253

Epoch: 287| Step: 0
Training loss: 3.118341600361938
Validation loss: 2.5969654932323336

Epoch: 5| Step: 1
Training loss: 3.3375423242978495
Validation loss: 2.5907422439923895

Epoch: 5| Step: 2
Training loss: 2.625748482215673
Validation loss: 2.573224253604731

Epoch: 5| Step: 3
Training loss: 2.7467104570669507
Validation loss: 2.5534775860442442

Epoch: 5| Step: 4
Training loss: 2.1357057949431404
Validation loss: 2.5450634820516265

Epoch: 5| Step: 5
Training loss: 2.4429327259146385
Validation loss: 2.53246499306812

Epoch: 5| Step: 6
Training loss: 3.021096439523143
Validation loss: 2.526590384909986

Epoch: 5| Step: 7
Training loss: 2.7712588927556894
Validation loss: 2.52628265100782

Epoch: 5| Step: 8
Training loss: 2.750651369113639
Validation loss: 2.5230151112832155

Epoch: 5| Step: 9
Training loss: 2.752368080796073
Validation loss: 2.519639073925099

Epoch: 5| Step: 10
Training loss: 2.9267133340902056
Validation loss: 2.542112020620016

Epoch: 288| Step: 0
Training loss: 2.6868181472587995
Validation loss: 2.5478049952766146

Epoch: 5| Step: 1
Training loss: 3.208025203291903
Validation loss: 2.561623354569994

Epoch: 5| Step: 2
Training loss: 3.1310579709315483
Validation loss: 2.5613606929307604

Epoch: 5| Step: 3
Training loss: 2.7538658193231167
Validation loss: 2.5665428040508527

Epoch: 5| Step: 4
Training loss: 2.572688433656972
Validation loss: 2.5554617490340945

Epoch: 5| Step: 5
Training loss: 2.6728190042716973
Validation loss: 2.5447262189251445

Epoch: 5| Step: 6
Training loss: 2.1160728082083264
Validation loss: 2.555110266590809

Epoch: 5| Step: 7
Training loss: 3.2847628726464566
Validation loss: 2.5592905991362715

Epoch: 5| Step: 8
Training loss: 2.3278847384808072
Validation loss: 2.5436180151254217

Epoch: 5| Step: 9
Training loss: 2.907756783978073
Validation loss: 2.5310477820771853

Epoch: 5| Step: 10
Training loss: 2.857793485266413
Validation loss: 2.5305215893228215

Epoch: 289| Step: 0
Training loss: 2.6376977530012313
Validation loss: 2.5241384545752545

Epoch: 5| Step: 1
Training loss: 3.1822256694303817
Validation loss: 2.5258597870582116

Epoch: 5| Step: 2
Training loss: 2.991657419287824
Validation loss: 2.5177513536532756

Epoch: 5| Step: 3
Training loss: 2.980483628782079
Validation loss: 2.5183643082913547

Epoch: 5| Step: 4
Training loss: 2.9732942836346905
Validation loss: 2.512749797664142

Epoch: 5| Step: 5
Training loss: 2.365941893946727
Validation loss: 2.5116821167993106

Epoch: 5| Step: 6
Training loss: 3.0138085779915404
Validation loss: 2.514490106848664

Epoch: 5| Step: 7
Training loss: 2.4331866516251335
Validation loss: 2.5270444428364316

Epoch: 5| Step: 8
Training loss: 2.2878978487499606
Validation loss: 2.5471357358952362

Epoch: 5| Step: 9
Training loss: 2.690431105376214
Validation loss: 2.5549699207564016

Epoch: 5| Step: 10
Training loss: 2.99712058802325
Validation loss: 2.5588327373406163

Epoch: 290| Step: 0
Training loss: 2.7227762160285596
Validation loss: 2.5707040480968244

Epoch: 5| Step: 1
Training loss: 2.959491144980711
Validation loss: 2.5767232475626622

Epoch: 5| Step: 2
Training loss: 2.6575615730222126
Validation loss: 2.5791515246987227

Epoch: 5| Step: 3
Training loss: 2.689915480863563
Validation loss: 2.5755964172879326

Epoch: 5| Step: 4
Training loss: 3.001200118025704
Validation loss: 2.5613724893946617

Epoch: 5| Step: 5
Training loss: 2.4473096595449766
Validation loss: 2.5649042383392686

Epoch: 5| Step: 6
Training loss: 2.77546570452855
Validation loss: 2.574406530302195

Epoch: 5| Step: 7
Training loss: 3.104864020817748
Validation loss: 2.580085545411246

Epoch: 5| Step: 8
Training loss: 2.9627423988034263
Validation loss: 2.6128744330516853

Epoch: 5| Step: 9
Training loss: 2.212382568863704
Validation loss: 2.597912256401717

Epoch: 5| Step: 10
Training loss: 3.0629871525907575
Validation loss: 2.609403616335844

Epoch: 291| Step: 0
Training loss: 2.524329721602445
Validation loss: 2.5829762790275743

Epoch: 5| Step: 1
Training loss: 1.9628776284162401
Validation loss: 2.5569434168906535

Epoch: 5| Step: 2
Training loss: 3.2065451621856553
Validation loss: 2.537815374213076

Epoch: 5| Step: 3
Training loss: 2.763296666640227
Validation loss: 2.5273274684283358

Epoch: 5| Step: 4
Training loss: 3.1092814522477683
Validation loss: 2.5247386566041774

Epoch: 5| Step: 5
Training loss: 3.2433407857978516
Validation loss: 2.53468804404991

Epoch: 5| Step: 6
Training loss: 2.9917256369839973
Validation loss: 2.519732576062717

Epoch: 5| Step: 7
Training loss: 1.9850102406581127
Validation loss: 2.5183941226681856

Epoch: 5| Step: 8
Training loss: 2.813220122652348
Validation loss: 2.522265738593298

Epoch: 5| Step: 9
Training loss: 2.8632236282358536
Validation loss: 2.535970501770311

Epoch: 5| Step: 10
Training loss: 2.7856479975739825
Validation loss: 2.528215665601154

Epoch: 292| Step: 0
Training loss: 3.10846424662311
Validation loss: 2.521392263167069

Epoch: 5| Step: 1
Training loss: 3.003433805500537
Validation loss: 2.5408345313904426

Epoch: 5| Step: 2
Training loss: 2.941021371005643
Validation loss: 2.534596614859861

Epoch: 5| Step: 3
Training loss: 2.92201420253511
Validation loss: 2.5364724644601715

Epoch: 5| Step: 4
Training loss: 2.728520955194552
Validation loss: 2.536180667537132

Epoch: 5| Step: 5
Training loss: 2.51561599635059
Validation loss: 2.5426625133740766

Epoch: 5| Step: 6
Training loss: 2.770450240496064
Validation loss: 2.5362216158201516

Epoch: 5| Step: 7
Training loss: 2.2568904485519754
Validation loss: 2.539529066611309

Epoch: 5| Step: 8
Training loss: 2.783500960626534
Validation loss: 2.538348068049533

Epoch: 5| Step: 9
Training loss: 2.428370275100806
Validation loss: 2.5415523909510935

Epoch: 5| Step: 10
Training loss: 2.9993965813634786
Validation loss: 2.545963615750832

Epoch: 293| Step: 0
Training loss: 2.7870766972615693
Validation loss: 2.545151596046195

Epoch: 5| Step: 1
Training loss: 2.7979165806963224
Validation loss: 2.552070981452656

Epoch: 5| Step: 2
Training loss: 2.7140061657581835
Validation loss: 2.5386557168152883

Epoch: 5| Step: 3
Training loss: 2.6361672962107012
Validation loss: 2.537080511123639

Epoch: 5| Step: 4
Training loss: 2.7681842751270715
Validation loss: 2.5299479474039654

Epoch: 5| Step: 5
Training loss: 2.6795731678586345
Validation loss: 2.5370492935092526

Epoch: 5| Step: 6
Training loss: 2.868277942655356
Validation loss: 2.5367322756428736

Epoch: 5| Step: 7
Training loss: 2.7637012924947157
Validation loss: 2.5405500569270267

Epoch: 5| Step: 8
Training loss: 2.475844799705548
Validation loss: 2.537226091246065

Epoch: 5| Step: 9
Training loss: 2.778458555298596
Validation loss: 2.5507649883790937

Epoch: 5| Step: 10
Training loss: 3.2516275878727017
Validation loss: 2.5427210013102712

Epoch: 294| Step: 0
Training loss: 2.0462456820470964
Validation loss: 2.552661204674016

Epoch: 5| Step: 1
Training loss: 2.7156801101834414
Validation loss: 2.5536190288646203

Epoch: 5| Step: 2
Training loss: 3.036245889358596
Validation loss: 2.575015733596932

Epoch: 5| Step: 3
Training loss: 2.65846124498761
Validation loss: 2.554593881341314

Epoch: 5| Step: 4
Training loss: 2.865847240553649
Validation loss: 2.58018053134809

Epoch: 5| Step: 5
Training loss: 2.561311771956718
Validation loss: 2.5634393698498794

Epoch: 5| Step: 6
Training loss: 2.916409526570705
Validation loss: 2.5497563632388967

Epoch: 5| Step: 7
Training loss: 2.5907526737130504
Validation loss: 2.5261731043268703

Epoch: 5| Step: 8
Training loss: 3.0263500133124346
Validation loss: 2.548449925899086

Epoch: 5| Step: 9
Training loss: 3.0765861886169823
Validation loss: 2.5172708801309738

Epoch: 5| Step: 10
Training loss: 2.836079071126308
Validation loss: 2.5129736363138497

Epoch: 295| Step: 0
Training loss: 2.8954676298855997
Validation loss: 2.506114410496107

Epoch: 5| Step: 1
Training loss: 2.557846682441875
Validation loss: 2.510978524204332

Epoch: 5| Step: 2
Training loss: 3.1662593044139777
Validation loss: 2.5131646544200894

Epoch: 5| Step: 3
Training loss: 3.128087159193729
Validation loss: 2.5133455405378533

Epoch: 5| Step: 4
Training loss: 2.5801685903602105
Validation loss: 2.512192129741907

Epoch: 5| Step: 5
Training loss: 2.9392782469781897
Validation loss: 2.51730455703962

Epoch: 5| Step: 6
Training loss: 2.597347568155064
Validation loss: 2.5206003141559927

Epoch: 5| Step: 7
Training loss: 3.0024534365738207
Validation loss: 2.5238406972521856

Epoch: 5| Step: 8
Training loss: 2.635638251557393
Validation loss: 2.5336314819962964

Epoch: 5| Step: 9
Training loss: 1.9649052088929615
Validation loss: 2.536357715338733

Epoch: 5| Step: 10
Training loss: 2.800889272482103
Validation loss: 2.5478124845268675

Epoch: 296| Step: 0
Training loss: 3.0627772925822603
Validation loss: 2.5708438146981196

Epoch: 5| Step: 1
Training loss: 2.6580038227200196
Validation loss: 2.588238268004195

Epoch: 5| Step: 2
Training loss: 2.447511896527283
Validation loss: 2.6016776343255814

Epoch: 5| Step: 3
Training loss: 2.5843572945778215
Validation loss: 2.592999664708544

Epoch: 5| Step: 4
Training loss: 2.4368494583986817
Validation loss: 2.6010084803020828

Epoch: 5| Step: 5
Training loss: 2.976442990444502
Validation loss: 2.6116375338681386

Epoch: 5| Step: 6
Training loss: 2.7161635449796044
Validation loss: 2.6071002022687644

Epoch: 5| Step: 7
Training loss: 3.1172075390470395
Validation loss: 2.6004355740182477

Epoch: 5| Step: 8
Training loss: 2.9012564140751853
Validation loss: 2.567901657632023

Epoch: 5| Step: 9
Training loss: 3.0383266940927567
Validation loss: 2.5269034543364923

Epoch: 5| Step: 10
Training loss: 2.3560231633367272
Validation loss: 2.524435453720385

Epoch: 297| Step: 0
Training loss: 3.1001689864829913
Validation loss: 2.5092886305678146

Epoch: 5| Step: 1
Training loss: 2.200819175103649
Validation loss: 2.505914456885211

Epoch: 5| Step: 2
Training loss: 2.9375428541588176
Validation loss: 2.498205593075398

Epoch: 5| Step: 3
Training loss: 2.7040580947154127
Validation loss: 2.505327166440349

Epoch: 5| Step: 4
Training loss: 2.4341333075874143
Validation loss: 2.4976407291078

Epoch: 5| Step: 5
Training loss: 2.8372942408770303
Validation loss: 2.4982081267441787

Epoch: 5| Step: 6
Training loss: 2.692611889369443
Validation loss: 2.5036090774756548

Epoch: 5| Step: 7
Training loss: 3.1222816851539443
Validation loss: 2.5064222374267637

Epoch: 5| Step: 8
Training loss: 2.685693710474434
Validation loss: 2.5143092367987383

Epoch: 5| Step: 9
Training loss: 3.05592527946278
Validation loss: 2.516102480491907

Epoch: 5| Step: 10
Training loss: 2.7737815106300965
Validation loss: 2.5338800091285587

Epoch: 298| Step: 0
Training loss: 2.876634713529935
Validation loss: 2.5643731071111264

Epoch: 5| Step: 1
Training loss: 3.1642730266091563
Validation loss: 2.590106580125604

Epoch: 5| Step: 2
Training loss: 2.5182740852796996
Validation loss: 2.590384234701214

Epoch: 5| Step: 3
Training loss: 2.665954991583856
Validation loss: 2.582026410710713

Epoch: 5| Step: 4
Training loss: 3.1381402506075013
Validation loss: 2.61315137355046

Epoch: 5| Step: 5
Training loss: 2.83313505563523
Validation loss: 2.611731880754266

Epoch: 5| Step: 6
Training loss: 2.390446874427551
Validation loss: 2.5955533833888427

Epoch: 5| Step: 7
Training loss: 3.0236060911187637
Validation loss: 2.5890386822337983

Epoch: 5| Step: 8
Training loss: 2.4928785938397136
Validation loss: 2.5689930812520094

Epoch: 5| Step: 9
Training loss: 2.929538733202047
Validation loss: 2.5721541486220767

Epoch: 5| Step: 10
Training loss: 2.106297940124626
Validation loss: 2.5810083101083996

Epoch: 299| Step: 0
Training loss: 2.8072475979565663
Validation loss: 2.573351370255022

Epoch: 5| Step: 1
Training loss: 2.913414768096351
Validation loss: 2.578868851383349

Epoch: 5| Step: 2
Training loss: 2.406558029473807
Validation loss: 2.5739628750240318

Epoch: 5| Step: 3
Training loss: 2.9296414384399854
Validation loss: 2.5610308668870463

Epoch: 5| Step: 4
Training loss: 2.7537693720139207
Validation loss: 2.5736752340446327

Epoch: 5| Step: 5
Training loss: 2.5887236093072046
Validation loss: 2.56602509484952

Epoch: 5| Step: 6
Training loss: 3.2295270329046954
Validation loss: 2.567397222425161

Epoch: 5| Step: 7
Training loss: 2.7232817666048192
Validation loss: 2.5739554190339784

Epoch: 5| Step: 8
Training loss: 2.338347961514161
Validation loss: 2.5767011074511044

Epoch: 5| Step: 9
Training loss: 2.606572913787166
Validation loss: 2.585571566532618

Epoch: 5| Step: 10
Training loss: 3.160638307977517
Validation loss: 2.597437279059941

Epoch: 300| Step: 0
Training loss: 2.722879890440655
Validation loss: 2.5862406782276093

Epoch: 5| Step: 1
Training loss: 2.9981063588357904
Validation loss: 2.5783326334791647

Epoch: 5| Step: 2
Training loss: 2.5809667473431563
Validation loss: 2.561552665471482

Epoch: 5| Step: 3
Training loss: 2.5291978971343174
Validation loss: 2.543793304180379

Epoch: 5| Step: 4
Training loss: 2.830164053108032
Validation loss: 2.542705314253898

Epoch: 5| Step: 5
Training loss: 2.858317528802387
Validation loss: 2.5445211477176506

Epoch: 5| Step: 6
Training loss: 3.085419971190406
Validation loss: 2.5442434496204736

Epoch: 5| Step: 7
Training loss: 2.0129180000230744
Validation loss: 2.534969350563963

Epoch: 5| Step: 8
Training loss: 2.923634045516725
Validation loss: 2.5374398285849025

Epoch: 5| Step: 9
Training loss: 2.375679320507446
Validation loss: 2.5456698050071562

Epoch: 5| Step: 10
Training loss: 3.292820466708831
Validation loss: 2.555146060442944

Epoch: 301| Step: 0
Training loss: 2.42293963258792
Validation loss: 2.562760146547241

Epoch: 5| Step: 1
Training loss: 2.2888931367993157
Validation loss: 2.575934372923955

Epoch: 5| Step: 2
Training loss: 3.547942148065967
Validation loss: 2.5915707030498467

Epoch: 5| Step: 3
Training loss: 2.6383856131731065
Validation loss: 2.5788575385574153

Epoch: 5| Step: 4
Training loss: 3.1655327289234814
Validation loss: 2.594004849188246

Epoch: 5| Step: 5
Training loss: 2.175900796725614
Validation loss: 2.585336453054156

Epoch: 5| Step: 6
Training loss: 2.6091770850864706
Validation loss: 2.594751837893663

Epoch: 5| Step: 7
Training loss: 1.9227552801527672
Validation loss: 2.5968081388584077

Epoch: 5| Step: 8
Training loss: 2.4028675035642433
Validation loss: 2.5954016813202503

Epoch: 5| Step: 9
Training loss: 3.436354567684154
Validation loss: 2.5983463742110455

Epoch: 5| Step: 10
Training loss: 3.151116303539915
Validation loss: 2.5860593210857163

Epoch: 302| Step: 0
Training loss: 2.9925492269726313
Validation loss: 2.5900679268740725

Epoch: 5| Step: 1
Training loss: 3.0842241770190584
Validation loss: 2.588427272574969

Epoch: 5| Step: 2
Training loss: 2.4207928608735503
Validation loss: 2.587210720196519

Epoch: 5| Step: 3
Training loss: 2.6436214262447435
Validation loss: 2.5839917107765378

Epoch: 5| Step: 4
Training loss: 2.737399537494437
Validation loss: 2.5999210905748478

Epoch: 5| Step: 5
Training loss: 2.505407017517372
Validation loss: 2.62795250177915

Epoch: 5| Step: 6
Training loss: 3.0609080010901497
Validation loss: 2.6105225807502075

Epoch: 5| Step: 7
Training loss: 2.9751567574883206
Validation loss: 2.5886728841069395

Epoch: 5| Step: 8
Training loss: 2.5489869517684167
Validation loss: 2.5605229420063322

Epoch: 5| Step: 9
Training loss: 2.624699439144129
Validation loss: 2.5535760545120643

Epoch: 5| Step: 10
Training loss: 2.477544259023423
Validation loss: 2.5395810621124366

Epoch: 303| Step: 0
Training loss: 2.4577828669231874
Validation loss: 2.535059851107982

Epoch: 5| Step: 1
Training loss: 3.337319581373683
Validation loss: 2.535627834358087

Epoch: 5| Step: 2
Training loss: 3.085990345176482
Validation loss: 2.522626424370414

Epoch: 5| Step: 3
Training loss: 2.2185120790817745
Validation loss: 2.5337472586260263

Epoch: 5| Step: 4
Training loss: 3.062962088464546
Validation loss: 2.5430141718562065

Epoch: 5| Step: 5
Training loss: 2.3055674796453567
Validation loss: 2.546518347765649

Epoch: 5| Step: 6
Training loss: 2.594145411489994
Validation loss: 2.539292611800462

Epoch: 5| Step: 7
Training loss: 2.576718495807123
Validation loss: 2.540998980048542

Epoch: 5| Step: 8
Training loss: 2.9702051712222293
Validation loss: 2.546529013982004

Epoch: 5| Step: 9
Training loss: 2.564777571643279
Validation loss: 2.5498849202600655

Epoch: 5| Step: 10
Training loss: 2.7315718751403226
Validation loss: 2.5790482812772724

Epoch: 304| Step: 0
Training loss: 2.6478807432397558
Validation loss: 2.5900833973499817

Epoch: 5| Step: 1
Training loss: 2.7392991550746024
Validation loss: 2.614586486017019

Epoch: 5| Step: 2
Training loss: 2.5617944630017653
Validation loss: 2.627563634956779

Epoch: 5| Step: 3
Training loss: 2.7883566596345104
Validation loss: 2.5942507103753756

Epoch: 5| Step: 4
Training loss: 2.531740305944827
Validation loss: 2.5759992161532854

Epoch: 5| Step: 5
Training loss: 2.71184126770323
Validation loss: 2.556326494020888

Epoch: 5| Step: 6
Training loss: 3.1042207717447297
Validation loss: 2.5235597492030966

Epoch: 5| Step: 7
Training loss: 2.8534718431146717
Validation loss: 2.50036383667998

Epoch: 5| Step: 8
Training loss: 2.8742877243737017
Validation loss: 2.4975346263386298

Epoch: 5| Step: 9
Training loss: 2.5113064678217762
Validation loss: 2.4949223646860594

Epoch: 5| Step: 10
Training loss: 2.688854674532336
Validation loss: 2.4893722976770785

Epoch: 305| Step: 0
Training loss: 2.738068794138589
Validation loss: 2.4997652974245943

Epoch: 5| Step: 1
Training loss: 2.389845577662038
Validation loss: 2.495797357507579

Epoch: 5| Step: 2
Training loss: 2.68859503859454
Validation loss: 2.5253322026618092

Epoch: 5| Step: 3
Training loss: 2.8104221721922324
Validation loss: 2.527093501686369

Epoch: 5| Step: 4
Training loss: 2.6944945932639506
Validation loss: 2.5619535446265838

Epoch: 5| Step: 5
Training loss: 3.0363632021484728
Validation loss: 2.561516518776795

Epoch: 5| Step: 6
Training loss: 2.1444951177725136
Validation loss: 2.6129660440583615

Epoch: 5| Step: 7
Training loss: 2.773620685384067
Validation loss: 2.5981194235501763

Epoch: 5| Step: 8
Training loss: 2.881664347282728
Validation loss: 2.5812493021533367

Epoch: 5| Step: 9
Training loss: 3.3663006032716263
Validation loss: 2.550668494933752

Epoch: 5| Step: 10
Training loss: 2.9379755812033346
Validation loss: 2.5097766312736547

Epoch: 306| Step: 0
Training loss: 2.3493204676455886
Validation loss: 2.5008075809485137

Epoch: 5| Step: 1
Training loss: 2.2612926233258945
Validation loss: 2.5191280997952554

Epoch: 5| Step: 2
Training loss: 2.975101462805808
Validation loss: 2.563077541909689

Epoch: 5| Step: 3
Training loss: 2.6716465545614376
Validation loss: 2.583929880858428

Epoch: 5| Step: 4
Training loss: 3.189771553397862
Validation loss: 2.562709424624897

Epoch: 5| Step: 5
Training loss: 2.645467257268051
Validation loss: 2.5338711259911753

Epoch: 5| Step: 6
Training loss: 3.0195209853379055
Validation loss: 2.5228708694525914

Epoch: 5| Step: 7
Training loss: 2.8133928365275462
Validation loss: 2.541659738607528

Epoch: 5| Step: 8
Training loss: 2.9947242441742477
Validation loss: 2.54616756693866

Epoch: 5| Step: 9
Training loss: 3.0240378560012786
Validation loss: 2.561747426697684

Epoch: 5| Step: 10
Training loss: 2.453596033443731
Validation loss: 2.5751075336285405

Epoch: 307| Step: 0
Training loss: 2.272947383105462
Validation loss: 2.5748410586939996

Epoch: 5| Step: 1
Training loss: 2.7554703836027903
Validation loss: 2.585186685149257

Epoch: 5| Step: 2
Training loss: 3.310300852768498
Validation loss: 2.593420518511014

Epoch: 5| Step: 3
Training loss: 2.620716232651395
Validation loss: 2.5631216302144066

Epoch: 5| Step: 4
Training loss: 2.534190977214737
Validation loss: 2.5423032423055343

Epoch: 5| Step: 5
Training loss: 2.490865996797392
Validation loss: 2.521968662840244

Epoch: 5| Step: 6
Training loss: 2.4418295531465484
Validation loss: 2.515333009544552

Epoch: 5| Step: 7
Training loss: 3.114339115089957
Validation loss: 2.51403584237066

Epoch: 5| Step: 8
Training loss: 2.8599796177064425
Validation loss: 2.5079147895072813

Epoch: 5| Step: 9
Training loss: 2.81225067728994
Validation loss: 2.5196600610560362

Epoch: 5| Step: 10
Training loss: 2.937544964385336
Validation loss: 2.5099048173541805

Epoch: 308| Step: 0
Training loss: 3.571551018386958
Validation loss: 2.51407483250818

Epoch: 5| Step: 1
Training loss: 2.62370122841499
Validation loss: 2.524440023602495

Epoch: 5| Step: 2
Training loss: 2.5019071933600996
Validation loss: 2.5374735641456243

Epoch: 5| Step: 3
Training loss: 2.8370663416531023
Validation loss: 2.5352452189827415

Epoch: 5| Step: 4
Training loss: 2.826198364218034
Validation loss: 2.5368597777536683

Epoch: 5| Step: 5
Training loss: 2.6082005398943027
Validation loss: 2.559384184225159

Epoch: 5| Step: 6
Training loss: 2.656041754245021
Validation loss: 2.573943866489501

Epoch: 5| Step: 7
Training loss: 3.030328669584064
Validation loss: 2.563646799742925

Epoch: 5| Step: 8
Training loss: 2.0230606494058243
Validation loss: 2.53538736548615

Epoch: 5| Step: 9
Training loss: 2.450753784998619
Validation loss: 2.548880245618942

Epoch: 5| Step: 10
Training loss: 2.7451904895051333
Validation loss: 2.544326909743393

Epoch: 309| Step: 0
Training loss: 2.9140507183910627
Validation loss: 2.5317404922632494

Epoch: 5| Step: 1
Training loss: 2.448440452432709
Validation loss: 2.5407141859749465

Epoch: 5| Step: 2
Training loss: 3.0607308707953957
Validation loss: 2.531958548326104

Epoch: 5| Step: 3
Training loss: 2.31810853624707
Validation loss: 2.535348450316012

Epoch: 5| Step: 4
Training loss: 3.0334653329599024
Validation loss: 2.520375995309021

Epoch: 5| Step: 5
Training loss: 2.7357033255164382
Validation loss: 2.5498643528189335

Epoch: 5| Step: 6
Training loss: 2.362104441311306
Validation loss: 2.549643902703741

Epoch: 5| Step: 7
Training loss: 2.87209870273498
Validation loss: 2.555739089844006

Epoch: 5| Step: 8
Training loss: 2.5399902526788587
Validation loss: 2.5547257718731777

Epoch: 5| Step: 9
Training loss: 2.717858003759776
Validation loss: 2.567499809049055

Epoch: 5| Step: 10
Training loss: 3.0219453190035326
Validation loss: 2.5639958401426868

Epoch: 310| Step: 0
Training loss: 2.6680452439162243
Validation loss: 2.545410676449171

Epoch: 5| Step: 1
Training loss: 2.6589870936499067
Validation loss: 2.544076096923187

Epoch: 5| Step: 2
Training loss: 3.163349589341913
Validation loss: 2.5405458702141015

Epoch: 5| Step: 3
Training loss: 2.477064785728818
Validation loss: 2.530791133325775

Epoch: 5| Step: 4
Training loss: 2.568663279607965
Validation loss: 2.523562331575542

Epoch: 5| Step: 5
Training loss: 2.5654912098280667
Validation loss: 2.5278837100722944

Epoch: 5| Step: 6
Training loss: 2.3397327836205526
Validation loss: 2.532890913170087

Epoch: 5| Step: 7
Training loss: 3.1166182454745566
Validation loss: 2.5285988833491846

Epoch: 5| Step: 8
Training loss: 3.502488205513438
Validation loss: 2.5236550057080893

Epoch: 5| Step: 9
Training loss: 2.5431609425380217
Validation loss: 2.5233683008821837

Epoch: 5| Step: 10
Training loss: 1.8512916849763434
Validation loss: 2.5192029187868887

Epoch: 311| Step: 0
Training loss: 2.438985323127859
Validation loss: 2.5307080797641426

Epoch: 5| Step: 1
Training loss: 2.8253695727291435
Validation loss: 2.523053335733827

Epoch: 5| Step: 2
Training loss: 2.6524429864535675
Validation loss: 2.516082187106863

Epoch: 5| Step: 3
Training loss: 2.732388106949357
Validation loss: 2.5273008989421997

Epoch: 5| Step: 4
Training loss: 3.0260260489099626
Validation loss: 2.542128475752018

Epoch: 5| Step: 5
Training loss: 2.3913329827625933
Validation loss: 2.5377342466776662

Epoch: 5| Step: 6
Training loss: 2.6901608092163114
Validation loss: 2.5572589146790485

Epoch: 5| Step: 7
Training loss: 2.6630322206491104
Validation loss: 2.5704653955306482

Epoch: 5| Step: 8
Training loss: 2.6445908419995967
Validation loss: 2.5700942307530825

Epoch: 5| Step: 9
Training loss: 2.9805394635492437
Validation loss: 2.592631678507163

Epoch: 5| Step: 10
Training loss: 2.8012655735902188
Validation loss: 2.59720804580833

Epoch: 312| Step: 0
Training loss: 3.0140291250703704
Validation loss: 2.5838426100543455

Epoch: 5| Step: 1
Training loss: 2.8073936731682325
Validation loss: 2.588014912328528

Epoch: 5| Step: 2
Training loss: 2.5832311753613704
Validation loss: 2.584352146176639

Epoch: 5| Step: 3
Training loss: 2.605909593338722
Validation loss: 2.609888523505837

Epoch: 5| Step: 4
Training loss: 2.7856059734541176
Validation loss: 2.6079426464952844

Epoch: 5| Step: 5
Training loss: 2.7483961456813666
Validation loss: 2.5980437215599106

Epoch: 5| Step: 6
Training loss: 2.761893303303994
Validation loss: 2.587204988883741

Epoch: 5| Step: 7
Training loss: 3.085876155195253
Validation loss: 2.5972279649171295

Epoch: 5| Step: 8
Training loss: 2.491585685749369
Validation loss: 2.585535630201833

Epoch: 5| Step: 9
Training loss: 2.271329656368258
Validation loss: 2.5874092393274393

Epoch: 5| Step: 10
Training loss: 2.513938859989709
Validation loss: 2.5656297031152793

Epoch: 313| Step: 0
Training loss: 2.944391486053533
Validation loss: 2.5451332627605336

Epoch: 5| Step: 1
Training loss: 2.3919785600804966
Validation loss: 2.536355512393479

Epoch: 5| Step: 2
Training loss: 2.8070746758465135
Validation loss: 2.5610277842470865

Epoch: 5| Step: 3
Training loss: 3.133103050400077
Validation loss: 2.5778234977342818

Epoch: 5| Step: 4
Training loss: 2.5593458162350937
Validation loss: 2.5732559618741075

Epoch: 5| Step: 5
Training loss: 2.3896265874626823
Validation loss: 2.577670706470239

Epoch: 5| Step: 6
Training loss: 2.507785309736263
Validation loss: 2.578762903532199

Epoch: 5| Step: 7
Training loss: 2.5833881638973635
Validation loss: 2.5545020616773573

Epoch: 5| Step: 8
Training loss: 3.018280125413529
Validation loss: 2.5580429204386568

Epoch: 5| Step: 9
Training loss: 2.8154564471499715
Validation loss: 2.525359770458645

Epoch: 5| Step: 10
Training loss: 2.480008300336668
Validation loss: 2.5330852244834277

Epoch: 314| Step: 0
Training loss: 2.498317056678783
Validation loss: 2.5252209579201317

Epoch: 5| Step: 1
Training loss: 2.6802232390274785
Validation loss: 2.509574088701946

Epoch: 5| Step: 2
Training loss: 3.1649983846892322
Validation loss: 2.5369919318845238

Epoch: 5| Step: 3
Training loss: 2.9208324836878465
Validation loss: 2.5402735020951743

Epoch: 5| Step: 4
Training loss: 2.633627383397294
Validation loss: 2.565693660694314

Epoch: 5| Step: 5
Training loss: 2.6870454803070465
Validation loss: 2.5603584306624434

Epoch: 5| Step: 6
Training loss: 2.5691482086788917
Validation loss: 2.550450546841858

Epoch: 5| Step: 7
Training loss: 2.837937335622979
Validation loss: 2.566258874750003

Epoch: 5| Step: 8
Training loss: 2.828752479703847
Validation loss: 2.5491060688704383

Epoch: 5| Step: 9
Training loss: 2.2512482253707846
Validation loss: 2.5770599880138145

Epoch: 5| Step: 10
Training loss: 2.6861448197965654
Validation loss: 2.563963235452887

Epoch: 315| Step: 0
Training loss: 2.823305269827718
Validation loss: 2.5334906323868003

Epoch: 5| Step: 1
Training loss: 3.214188983006669
Validation loss: 2.5166118471884285

Epoch: 5| Step: 2
Training loss: 2.670396451484192
Validation loss: 2.5168542953216475

Epoch: 5| Step: 3
Training loss: 2.2408651779179998
Validation loss: 2.51553015994151

Epoch: 5| Step: 4
Training loss: 2.9500351337991577
Validation loss: 2.5208716623932603

Epoch: 5| Step: 5
Training loss: 2.2962743272152037
Validation loss: 2.5279320792555104

Epoch: 5| Step: 6
Training loss: 2.553447270685722
Validation loss: 2.532377243470582

Epoch: 5| Step: 7
Training loss: 2.4740614913046013
Validation loss: 2.5480889012470005

Epoch: 5| Step: 8
Training loss: 2.1363681317250753
Validation loss: 2.5547896206071594

Epoch: 5| Step: 9
Training loss: 3.2313184070540175
Validation loss: 2.585249295180372

Epoch: 5| Step: 10
Training loss: 3.1754145674495633
Validation loss: 2.5862606262957146

Epoch: 316| Step: 0
Training loss: 2.436907378316953
Validation loss: 2.5919913853311383

Epoch: 5| Step: 1
Training loss: 2.13646723018327
Validation loss: 2.593952475970934

Epoch: 5| Step: 2
Training loss: 2.934817611252174
Validation loss: 2.606830396888895

Epoch: 5| Step: 3
Training loss: 3.155491350607275
Validation loss: 2.6117126258834076

Epoch: 5| Step: 4
Training loss: 2.4162453470515857
Validation loss: 2.5837351892997176

Epoch: 5| Step: 5
Training loss: 2.923885204749283
Validation loss: 2.5538605807427377

Epoch: 5| Step: 6
Training loss: 3.31699498211329
Validation loss: 2.5428809868204207

Epoch: 5| Step: 7
Training loss: 2.8938382821180175
Validation loss: 2.51627140737486

Epoch: 5| Step: 8
Training loss: 2.40261625899778
Validation loss: 2.519047017682947

Epoch: 5| Step: 9
Training loss: 2.7210164762570805
Validation loss: 2.520773221218476

Epoch: 5| Step: 10
Training loss: 2.5976709351088667
Validation loss: 2.5166615290984247

Epoch: 317| Step: 0
Training loss: 2.7971707832315076
Validation loss: 2.5167656866862402

Epoch: 5| Step: 1
Training loss: 2.8662370566846533
Validation loss: 2.507456099939387

Epoch: 5| Step: 2
Training loss: 2.3803316803628056
Validation loss: 2.5099878034616876

Epoch: 5| Step: 3
Training loss: 3.1863344342794897
Validation loss: 2.518582848605911

Epoch: 5| Step: 4
Training loss: 2.4553548797993323
Validation loss: 2.526872692329845

Epoch: 5| Step: 5
Training loss: 2.6349522077073533
Validation loss: 2.5640408355134987

Epoch: 5| Step: 6
Training loss: 2.823090936177835
Validation loss: 2.5876714280568134

Epoch: 5| Step: 7
Training loss: 2.772350689347681
Validation loss: 2.608477779072478

Epoch: 5| Step: 8
Training loss: 2.567808467828863
Validation loss: 2.6052872282647708

Epoch: 5| Step: 9
Training loss: 2.657549910269557
Validation loss: 2.592414615979017

Epoch: 5| Step: 10
Training loss: 2.7611768911275276
Validation loss: 2.578415860163444

Epoch: 318| Step: 0
Training loss: 2.519373689204949
Validation loss: 2.553533553304533

Epoch: 5| Step: 1
Training loss: 2.724179075984361
Validation loss: 2.5453913751254733

Epoch: 5| Step: 2
Training loss: 2.614073218524891
Validation loss: 2.5485506839552956

Epoch: 5| Step: 3
Training loss: 3.0032586837054915
Validation loss: 2.556059251641473

Epoch: 5| Step: 4
Training loss: 2.8408631144184473
Validation loss: 2.578208456121187

Epoch: 5| Step: 5
Training loss: 3.0243650290160664
Validation loss: 2.599735765582062

Epoch: 5| Step: 6
Training loss: 2.352065935456293
Validation loss: 2.6034451679245403

Epoch: 5| Step: 7
Training loss: 2.8032790023703695
Validation loss: 2.6046037611486565

Epoch: 5| Step: 8
Training loss: 2.4281385580933814
Validation loss: 2.5866899631401767

Epoch: 5| Step: 9
Training loss: 2.4474856923886237
Validation loss: 2.5756714164252794

Epoch: 5| Step: 10
Training loss: 3.0015335931532796
Validation loss: 2.564068832990041

Epoch: 319| Step: 0
Training loss: 3.1185867113930072
Validation loss: 2.573184664295153

Epoch: 5| Step: 1
Training loss: 3.083250628900089
Validation loss: 2.580633585834051

Epoch: 5| Step: 2
Training loss: 2.460562541189312
Validation loss: 2.619172722914644

Epoch: 5| Step: 3
Training loss: 2.955081513598933
Validation loss: 2.633072435764455

Epoch: 5| Step: 4
Training loss: 2.8360849557588605
Validation loss: 2.6130389090726216

Epoch: 5| Step: 5
Training loss: 2.7687705734556336
Validation loss: 2.5895374424872077

Epoch: 5| Step: 6
Training loss: 2.496584466447693
Validation loss: 2.5607411390744375

Epoch: 5| Step: 7
Training loss: 2.5782095230581237
Validation loss: 2.530775650893104

Epoch: 5| Step: 8
Training loss: 2.5677562861320586
Validation loss: 2.544932362554814

Epoch: 5| Step: 9
Training loss: 2.507116013066091
Validation loss: 2.5147610551956294

Epoch: 5| Step: 10
Training loss: 2.3108182410778957
Validation loss: 2.5192265157032807

Epoch: 320| Step: 0
Training loss: 2.584182927698539
Validation loss: 2.502118530733531

Epoch: 5| Step: 1
Training loss: 2.835555458082133
Validation loss: 2.5095773760287474

Epoch: 5| Step: 2
Training loss: 2.6569274935924154
Validation loss: 2.5166790164980517

Epoch: 5| Step: 3
Training loss: 2.7850969262780474
Validation loss: 2.519014419440857

Epoch: 5| Step: 4
Training loss: 2.808103558415821
Validation loss: 2.5210680125652556

Epoch: 5| Step: 5
Training loss: 2.357570943725704
Validation loss: 2.5388087466574945

Epoch: 5| Step: 6
Training loss: 2.535791161828247
Validation loss: 2.5477899030070525

Epoch: 5| Step: 7
Training loss: 2.8998401466247348
Validation loss: 2.5203502588448337

Epoch: 5| Step: 8
Training loss: 2.2575433168025794
Validation loss: 2.516553587784942

Epoch: 5| Step: 9
Training loss: 3.0741650820244
Validation loss: 2.4923707005736317

Epoch: 5| Step: 10
Training loss: 2.739655284637795
Validation loss: 2.509546027749834

Epoch: 321| Step: 0
Training loss: 2.502530724396864
Validation loss: 2.511474374980431

Epoch: 5| Step: 1
Training loss: 2.3602009521210925
Validation loss: 2.5201677891145

Epoch: 5| Step: 2
Training loss: 2.821143960307856
Validation loss: 2.531504366202127

Epoch: 5| Step: 3
Training loss: 2.738224654762412
Validation loss: 2.5324561677307256

Epoch: 5| Step: 4
Training loss: 2.398734307329731
Validation loss: 2.5314417120413335

Epoch: 5| Step: 5
Training loss: 2.7120642175751417
Validation loss: 2.5406566982216394

Epoch: 5| Step: 6
Training loss: 2.7337312649057415
Validation loss: 2.549164156540538

Epoch: 5| Step: 7
Training loss: 2.9094527450319125
Validation loss: 2.5457888064317054

Epoch: 5| Step: 8
Training loss: 2.4674128520691774
Validation loss: 2.554767007435048

Epoch: 5| Step: 9
Training loss: 2.9580466619580714
Validation loss: 2.575429814840813

Epoch: 5| Step: 10
Training loss: 2.903953547345267
Validation loss: 2.5515907868724965

Epoch: 322| Step: 0
Training loss: 2.510772574325064
Validation loss: 2.5418437356123276

Epoch: 5| Step: 1
Training loss: 2.6578750127564423
Validation loss: 2.535871628697268

Epoch: 5| Step: 2
Training loss: 3.136267528644594
Validation loss: 2.5296400270637203

Epoch: 5| Step: 3
Training loss: 2.259513240821841
Validation loss: 2.5157744777821467

Epoch: 5| Step: 4
Training loss: 2.0507041698684074
Validation loss: 2.5166363444624174

Epoch: 5| Step: 5
Training loss: 2.219315577672716
Validation loss: 2.5038246380939366

Epoch: 5| Step: 6
Training loss: 2.684351029916308
Validation loss: 2.502763816043053

Epoch: 5| Step: 7
Training loss: 3.0657166695766453
Validation loss: 2.501710135559712

Epoch: 5| Step: 8
Training loss: 3.268754399663178
Validation loss: 2.51316960080559

Epoch: 5| Step: 9
Training loss: 2.8898895152795134
Validation loss: 2.5322092503031484

Epoch: 5| Step: 10
Training loss: 2.4648589361965323
Validation loss: 2.540707399272987

Epoch: 323| Step: 0
Training loss: 3.17640745551091
Validation loss: 2.5423115887601804

Epoch: 5| Step: 1
Training loss: 2.8384138072670413
Validation loss: 2.573671690910714

Epoch: 5| Step: 2
Training loss: 2.9055343895411307
Validation loss: 2.5715106468437994

Epoch: 5| Step: 3
Training loss: 2.0492226918015723
Validation loss: 2.5800544427359866

Epoch: 5| Step: 4
Training loss: 2.6781202354077185
Validation loss: 2.604689975129113

Epoch: 5| Step: 5
Training loss: 2.3224740283774525
Validation loss: 2.60120441485583

Epoch: 5| Step: 6
Training loss: 2.6459673049129333
Validation loss: 2.5780290423571475

Epoch: 5| Step: 7
Training loss: 2.048586879378578
Validation loss: 2.5796677374655306

Epoch: 5| Step: 8
Training loss: 2.4511958026098064
Validation loss: 2.572405599256049

Epoch: 5| Step: 9
Training loss: 2.8635395344688903
Validation loss: 2.564587316958719

Epoch: 5| Step: 10
Training loss: 3.1484885389105166
Validation loss: 2.5823186680569443

Epoch: 324| Step: 0
Training loss: 2.863355690273389
Validation loss: 2.580226665289638

Epoch: 5| Step: 1
Training loss: 2.9396193954739416
Validation loss: 2.570425446568957

Epoch: 5| Step: 2
Training loss: 2.849790257549479
Validation loss: 2.565345491873838

Epoch: 5| Step: 3
Training loss: 2.934637744909524
Validation loss: 2.5687393614207337

Epoch: 5| Step: 4
Training loss: 2.2670723337043217
Validation loss: 2.5888810252969603

Epoch: 5| Step: 5
Training loss: 2.7575335915422476
Validation loss: 2.5803617149990834

Epoch: 5| Step: 6
Training loss: 2.5783119827435326
Validation loss: 2.5932102266878174

Epoch: 5| Step: 7
Training loss: 2.734039286031918
Validation loss: 2.595869290446137

Epoch: 5| Step: 8
Training loss: 2.304193062197089
Validation loss: 2.6167629053640917

Epoch: 5| Step: 9
Training loss: 3.142971851063829
Validation loss: 2.5932387703006485

Epoch: 5| Step: 10
Training loss: 1.84743816225786
Validation loss: 2.590464754463971

Epoch: 325| Step: 0
Training loss: 2.7981058321414096
Validation loss: 2.587987576087042

Epoch: 5| Step: 1
Training loss: 2.5131547065350937
Validation loss: 2.587738221089003

Epoch: 5| Step: 2
Training loss: 2.4128709339921195
Validation loss: 2.5776476953005067

Epoch: 5| Step: 3
Training loss: 2.7053178481324203
Validation loss: 2.5825620631879143

Epoch: 5| Step: 4
Training loss: 2.5743485969361966
Validation loss: 2.595918574402109

Epoch: 5| Step: 5
Training loss: 2.9682160549852608
Validation loss: 2.6096252484498144

Epoch: 5| Step: 6
Training loss: 2.6634729353881497
Validation loss: 2.6013169001950933

Epoch: 5| Step: 7
Training loss: 2.7100571843831918
Validation loss: 2.5881803054879966

Epoch: 5| Step: 8
Training loss: 2.7361680609579517
Validation loss: 2.5472363859113645

Epoch: 5| Step: 9
Training loss: 2.790140237599392
Validation loss: 2.5388330226845626

Epoch: 5| Step: 10
Training loss: 2.252957307921555
Validation loss: 2.530276657406843

Epoch: 326| Step: 0
Training loss: 2.5634207583211723
Validation loss: 2.5363679800579537

Epoch: 5| Step: 1
Training loss: 2.514326625342509
Validation loss: 2.5136572651938467

Epoch: 5| Step: 2
Training loss: 2.4865912382874926
Validation loss: 2.527368960819289

Epoch: 5| Step: 3
Training loss: 2.5566243986426445
Validation loss: 2.5457037678579253

Epoch: 5| Step: 4
Training loss: 3.0905382844275215
Validation loss: 2.5614251864760766

Epoch: 5| Step: 5
Training loss: 2.0457222291361403
Validation loss: 2.5553203139064204

Epoch: 5| Step: 6
Training loss: 3.0878388933146907
Validation loss: 2.5510904503223024

Epoch: 5| Step: 7
Training loss: 2.6575991626228332
Validation loss: 2.554073439944286

Epoch: 5| Step: 8
Training loss: 2.8354479995180992
Validation loss: 2.5376136239092077

Epoch: 5| Step: 9
Training loss: 2.1991417771415374
Validation loss: 2.542155928971966

Epoch: 5| Step: 10
Training loss: 3.1246572688033085
Validation loss: 2.541225169740622

Epoch: 327| Step: 0
Training loss: 2.7406055201813584
Validation loss: 2.5435304577873676

Epoch: 5| Step: 1
Training loss: 2.4899865838727346
Validation loss: 2.5675699095649036

Epoch: 5| Step: 2
Training loss: 2.9021418258639944
Validation loss: 2.5806528128169566

Epoch: 5| Step: 3
Training loss: 2.7015448565814304
Validation loss: 2.5779673299744887

Epoch: 5| Step: 4
Training loss: 2.932451658248829
Validation loss: 2.5933261321883334

Epoch: 5| Step: 5
Training loss: 2.1347812606643775
Validation loss: 2.601235243946787

Epoch: 5| Step: 6
Training loss: 2.688913372898637
Validation loss: 2.617065123168903

Epoch: 5| Step: 7
Training loss: 2.2316701028734247
Validation loss: 2.596053222556374

Epoch: 5| Step: 8
Training loss: 2.7145916938409025
Validation loss: 2.5678901132938527

Epoch: 5| Step: 9
Training loss: 2.730760288637178
Validation loss: 2.5223188715619043

Epoch: 5| Step: 10
Training loss: 2.8562982400706107
Validation loss: 2.5202500975353668

Epoch: 328| Step: 0
Training loss: 2.7806582732213037
Validation loss: 2.5069451940594822

Epoch: 5| Step: 1
Training loss: 2.777323319028667
Validation loss: 2.5282928540466347

Epoch: 5| Step: 2
Training loss: 2.596671607617177
Validation loss: 2.5309110890861803

Epoch: 5| Step: 3
Training loss: 2.6040765568719926
Validation loss: 2.532307468622367

Epoch: 5| Step: 4
Training loss: 2.192926488128689
Validation loss: 2.5497520931089923

Epoch: 5| Step: 5
Training loss: 2.512008626534295
Validation loss: 2.555712112553792

Epoch: 5| Step: 6
Training loss: 2.816514181113912
Validation loss: 2.563815579781188

Epoch: 5| Step: 7
Training loss: 3.0638647347315993
Validation loss: 2.5709897719403974

Epoch: 5| Step: 8
Training loss: 2.8794714943424875
Validation loss: 2.568375565148642

Epoch: 5| Step: 9
Training loss: 2.424690529651423
Validation loss: 2.5816845814335756

Epoch: 5| Step: 10
Training loss: 2.620944568919688
Validation loss: 2.56443695007526

Epoch: 329| Step: 0
Training loss: 2.833446911797985
Validation loss: 2.5662647797124802

Epoch: 5| Step: 1
Training loss: 2.91412533444321
Validation loss: 2.5701492297111854

Epoch: 5| Step: 2
Training loss: 2.6844687111321233
Validation loss: 2.5740159059518755

Epoch: 5| Step: 3
Training loss: 2.7757520876511306
Validation loss: 2.5763398723138824

Epoch: 5| Step: 4
Training loss: 2.613274407484736
Validation loss: 2.5707241256998445

Epoch: 5| Step: 5
Training loss: 2.5384995056416346
Validation loss: 2.5572240245890447

Epoch: 5| Step: 6
Training loss: 2.419973402113597
Validation loss: 2.5377568307977727

Epoch: 5| Step: 7
Training loss: 2.5108860468740835
Validation loss: 2.5382464060488497

Epoch: 5| Step: 8
Training loss: 2.9876192843193907
Validation loss: 2.5491705707525694

Epoch: 5| Step: 9
Training loss: 2.020893279559657
Validation loss: 2.5516760090246287

Epoch: 5| Step: 10
Training loss: 2.537127417661018
Validation loss: 2.5620036180901073

Epoch: 330| Step: 0
Training loss: 2.560562517829792
Validation loss: 2.568819356074396

Epoch: 5| Step: 1
Training loss: 2.5215117012038357
Validation loss: 2.5912162155723024

Epoch: 5| Step: 2
Training loss: 3.2075805936991957
Validation loss: 2.580772044827265

Epoch: 5| Step: 3
Training loss: 2.110265473212231
Validation loss: 2.5793775094545746

Epoch: 5| Step: 4
Training loss: 2.489516785395926
Validation loss: 2.5852345543866067

Epoch: 5| Step: 5
Training loss: 2.918390981415985
Validation loss: 2.6008196379293973

Epoch: 5| Step: 6
Training loss: 2.7429067858392897
Validation loss: 2.597817159920093

Epoch: 5| Step: 7
Training loss: 2.8206720096618976
Validation loss: 2.5906440927227528

Epoch: 5| Step: 8
Training loss: 1.8304383077137418
Validation loss: 2.5918654865274955

Epoch: 5| Step: 9
Training loss: 2.9107599848269903
Validation loss: 2.603611342419781

Epoch: 5| Step: 10
Training loss: 2.5091911163034166
Validation loss: 2.5804692692316347

Epoch: 331| Step: 0
Training loss: 2.9440610943964907
Validation loss: 2.5765463153665085

Epoch: 5| Step: 1
Training loss: 2.3294900054422474
Validation loss: 2.5594929785495433

Epoch: 5| Step: 2
Training loss: 2.866277815446337
Validation loss: 2.5387008866367453

Epoch: 5| Step: 3
Training loss: 2.792348085811729
Validation loss: 2.5369319607915344

Epoch: 5| Step: 4
Training loss: 2.6270223728965414
Validation loss: 2.5214975902766796

Epoch: 5| Step: 5
Training loss: 3.008447832656635
Validation loss: 2.519194377214476

Epoch: 5| Step: 6
Training loss: 2.692489605301793
Validation loss: 2.52192890730587

Epoch: 5| Step: 7
Training loss: 2.329908878034471
Validation loss: 2.523118385774207

Epoch: 5| Step: 8
Training loss: 2.617500582515502
Validation loss: 2.530707991631995

Epoch: 5| Step: 9
Training loss: 2.4125075779929253
Validation loss: 2.5532029445710016

Epoch: 5| Step: 10
Training loss: 2.338103957867967
Validation loss: 2.572338259602666

Epoch: 332| Step: 0
Training loss: 2.827812556927474
Validation loss: 2.6138357824321132

Epoch: 5| Step: 1
Training loss: 2.684084118680401
Validation loss: 2.6578881787660684

Epoch: 5| Step: 2
Training loss: 2.5652262444016594
Validation loss: 2.6403621575050558

Epoch: 5| Step: 3
Training loss: 3.0803830921667577
Validation loss: 2.63559470320509

Epoch: 5| Step: 4
Training loss: 2.39456311153354
Validation loss: 2.579287512321098

Epoch: 5| Step: 5
Training loss: 2.698992177284101
Validation loss: 2.5460193061468144

Epoch: 5| Step: 6
Training loss: 2.26831337166252
Validation loss: 2.52648454206293

Epoch: 5| Step: 7
Training loss: 2.430935946776785
Validation loss: 2.5276075291027356

Epoch: 5| Step: 8
Training loss: 2.880412107758621
Validation loss: 2.530889690302385

Epoch: 5| Step: 9
Training loss: 2.6071638229631957
Validation loss: 2.5274880195574654

Epoch: 5| Step: 10
Training loss: 2.499372021958794
Validation loss: 2.5248435288435163

Epoch: 333| Step: 0
Training loss: 3.0712704316803756
Validation loss: 2.5310856309900647

Epoch: 5| Step: 1
Training loss: 2.1094485799883795
Validation loss: 2.5297208395761874

Epoch: 5| Step: 2
Training loss: 1.9422525752513644
Validation loss: 2.528054930487884

Epoch: 5| Step: 3
Training loss: 2.056835140003169
Validation loss: 2.529960673626968

Epoch: 5| Step: 4
Training loss: 2.4866601762695426
Validation loss: 2.539328280311885

Epoch: 5| Step: 5
Training loss: 2.768572255235268
Validation loss: 2.564197760213781

Epoch: 5| Step: 6
Training loss: 3.1548031049370433
Validation loss: 2.5902567870522417

Epoch: 5| Step: 7
Training loss: 2.6615918468771262
Validation loss: 2.6075177420136813

Epoch: 5| Step: 8
Training loss: 2.7850435081658436
Validation loss: 2.5671026870979565

Epoch: 5| Step: 9
Training loss: 3.030337796156309
Validation loss: 2.570115336535443

Epoch: 5| Step: 10
Training loss: 2.466974030066136
Validation loss: 2.5811534109996126

Epoch: 334| Step: 0
Training loss: 2.3389071467097997
Validation loss: 2.5776880415417485

Epoch: 5| Step: 1
Training loss: 2.3255022880495373
Validation loss: 2.5787281125195145

Epoch: 5| Step: 2
Training loss: 2.219841594543291
Validation loss: 2.5841107232514493

Epoch: 5| Step: 3
Training loss: 3.200648993007579
Validation loss: 2.6022416775096597

Epoch: 5| Step: 4
Training loss: 2.401285077801431
Validation loss: 2.628050113713487

Epoch: 5| Step: 5
Training loss: 2.9566888850372526
Validation loss: 2.628245450584582

Epoch: 5| Step: 6
Training loss: 2.18504762785307
Validation loss: 2.6427971835716346

Epoch: 5| Step: 7
Training loss: 2.7186122289367534
Validation loss: 2.63043438697342

Epoch: 5| Step: 8
Training loss: 2.6199767778546823
Validation loss: 2.623699255632292

Epoch: 5| Step: 9
Training loss: 2.7876408904867866
Validation loss: 2.5968359666805556

Epoch: 5| Step: 10
Training loss: 2.814623730245108
Validation loss: 2.591048383351473

Epoch: 335| Step: 0
Training loss: 2.808476685695984
Validation loss: 2.5612299252990254

Epoch: 5| Step: 1
Training loss: 2.273472107299418
Validation loss: 2.5548987711276565

Epoch: 5| Step: 2
Training loss: 2.6622947577945557
Validation loss: 2.541404763749358

Epoch: 5| Step: 3
Training loss: 2.04399861914631
Validation loss: 2.538602443062477

Epoch: 5| Step: 4
Training loss: 2.766867493230866
Validation loss: 2.5503337582974237

Epoch: 5| Step: 5
Training loss: 2.563784393719657
Validation loss: 2.5705809393335395

Epoch: 5| Step: 6
Training loss: 2.4521077956732578
Validation loss: 2.5642966608132185

Epoch: 5| Step: 7
Training loss: 2.6713807836852594
Validation loss: 2.5798788827542474

Epoch: 5| Step: 8
Training loss: 3.060034869126258
Validation loss: 2.5763134888710053

Epoch: 5| Step: 9
Training loss: 2.8110278197234684
Validation loss: 2.551808695846262

Epoch: 5| Step: 10
Training loss: 2.3262861529640784
Validation loss: 2.571975965153684

Epoch: 336| Step: 0
Training loss: 2.1273511333806754
Validation loss: 2.569578589947378

Epoch: 5| Step: 1
Training loss: 2.4991571913087256
Validation loss: 2.556511355270354

Epoch: 5| Step: 2
Training loss: 2.641927725069743
Validation loss: 2.5558833795070193

Epoch: 5| Step: 3
Training loss: 2.447855933768438
Validation loss: 2.5694311322509713

Epoch: 5| Step: 4
Training loss: 3.0678008000287806
Validation loss: 2.557833705079556

Epoch: 5| Step: 5
Training loss: 2.8062301261215112
Validation loss: 2.5625784707128587

Epoch: 5| Step: 6
Training loss: 1.8351990858383362
Validation loss: 2.5546458612446603

Epoch: 5| Step: 7
Training loss: 3.025136544164551
Validation loss: 2.561638135658345

Epoch: 5| Step: 8
Training loss: 2.6030305952925903
Validation loss: 2.5669130471818247

Epoch: 5| Step: 9
Training loss: 2.709206151925839
Validation loss: 2.577790366810836

Epoch: 5| Step: 10
Training loss: 2.481229314069254
Validation loss: 2.57852370733122

Epoch: 337| Step: 0
Training loss: 3.12818929051691
Validation loss: 2.558467512375495

Epoch: 5| Step: 1
Training loss: 2.8910391845897725
Validation loss: 2.561557837678795

Epoch: 5| Step: 2
Training loss: 2.5582167951981964
Validation loss: 2.5326141171832615

Epoch: 5| Step: 3
Training loss: 2.2476554947508074
Validation loss: 2.525999043016989

Epoch: 5| Step: 4
Training loss: 2.591076311619694
Validation loss: 2.5320207391408034

Epoch: 5| Step: 5
Training loss: 2.435078714339998
Validation loss: 2.5506142116832815

Epoch: 5| Step: 6
Training loss: 2.4090609295060914
Validation loss: 2.553899615359057

Epoch: 5| Step: 7
Training loss: 2.3618052515662007
Validation loss: 2.5531733509115933

Epoch: 5| Step: 8
Training loss: 2.9062621413766885
Validation loss: 2.5615517917597344

Epoch: 5| Step: 9
Training loss: 2.497019039577971
Validation loss: 2.5845608555296864

Epoch: 5| Step: 10
Training loss: 2.30280405445494
Validation loss: 2.6126172060982924

Epoch: 338| Step: 0
Training loss: 2.6125651520266406
Validation loss: 2.670338067078562

Epoch: 5| Step: 1
Training loss: 2.8997084306614553
Validation loss: 2.67935880383096

Epoch: 5| Step: 2
Training loss: 2.687472764697799
Validation loss: 2.674139944753991

Epoch: 5| Step: 3
Training loss: 1.9109680697350107
Validation loss: 2.626613195471692

Epoch: 5| Step: 4
Training loss: 2.795146130749237
Validation loss: 2.6087819953895597

Epoch: 5| Step: 5
Training loss: 2.4993746929163745
Validation loss: 2.5871445080948345

Epoch: 5| Step: 6
Training loss: 2.9955452587291562
Validation loss: 2.539218616466321

Epoch: 5| Step: 7
Training loss: 2.8255966434182334
Validation loss: 2.513251790068703

Epoch: 5| Step: 8
Training loss: 1.9927607291299732
Validation loss: 2.5055306468007092

Epoch: 5| Step: 9
Training loss: 2.827644602402777
Validation loss: 2.5002224207964403

Epoch: 5| Step: 10
Training loss: 2.4357652604514697
Validation loss: 2.487069964553992

Epoch: 339| Step: 0
Training loss: 3.3346409299249538
Validation loss: 2.4833286243924557

Epoch: 5| Step: 1
Training loss: 2.595088016141926
Validation loss: 2.495466827161903

Epoch: 5| Step: 2
Training loss: 2.642244102192083
Validation loss: 2.508762589957651

Epoch: 5| Step: 3
Training loss: 2.863874053998878
Validation loss: 2.4924108463224726

Epoch: 5| Step: 4
Training loss: 2.6928621957723573
Validation loss: 2.5175090581021373

Epoch: 5| Step: 5
Training loss: 2.097940038596932
Validation loss: 2.523173234149691

Epoch: 5| Step: 6
Training loss: 2.167829519388985
Validation loss: 2.511969395108821

Epoch: 5| Step: 7
Training loss: 1.8471711310234298
Validation loss: 2.531393667154909

Epoch: 5| Step: 8
Training loss: 3.0308158012961988
Validation loss: 2.5271662862665187

Epoch: 5| Step: 9
Training loss: 2.424338779557512
Validation loss: 2.5537452220644674

Epoch: 5| Step: 10
Training loss: 2.5066352529112996
Validation loss: 2.5523279417308706

Epoch: 340| Step: 0
Training loss: 2.744394311005134
Validation loss: 2.563340304158378

Epoch: 5| Step: 1
Training loss: 2.759324909934973
Validation loss: 2.56265007437965

Epoch: 5| Step: 2
Training loss: 2.489430687559475
Validation loss: 2.5714241539057276

Epoch: 5| Step: 3
Training loss: 1.7615134379653674
Validation loss: 2.5603470871143097

Epoch: 5| Step: 4
Training loss: 2.3043967888021584
Validation loss: 2.557177191942478

Epoch: 5| Step: 5
Training loss: 2.360101853128613
Validation loss: 2.5501933496448173

Epoch: 5| Step: 6
Training loss: 2.49489816798027
Validation loss: 2.5755373072716607

Epoch: 5| Step: 7
Training loss: 2.8908937071581216
Validation loss: 2.566302955351631

Epoch: 5| Step: 8
Training loss: 2.352201558721438
Validation loss: 2.5824662128374523

Epoch: 5| Step: 9
Training loss: 2.7956267400403987
Validation loss: 2.5925726434282272

Epoch: 5| Step: 10
Training loss: 3.0450949139514756
Validation loss: 2.589775892675452

Epoch: 341| Step: 0
Training loss: 2.407826687364412
Validation loss: 2.595314522156964

Epoch: 5| Step: 1
Training loss: 2.786767009619886
Validation loss: 2.5849525809826552

Epoch: 5| Step: 2
Training loss: 2.454182390854552
Validation loss: 2.5990733476059025

Epoch: 5| Step: 3
Training loss: 2.3636857624493905
Validation loss: 2.579849046564768

Epoch: 5| Step: 4
Training loss: 2.7891873884689757
Validation loss: 2.5809206385502272

Epoch: 5| Step: 5
Training loss: 2.5554419287239383
Validation loss: 2.5931181174412905

Epoch: 5| Step: 6
Training loss: 2.8762124863440746
Validation loss: 2.577918466577883

Epoch: 5| Step: 7
Training loss: 1.9486667868298444
Validation loss: 2.5670734304404763

Epoch: 5| Step: 8
Training loss: 2.577624555625191
Validation loss: 2.552048605874514

Epoch: 5| Step: 9
Training loss: 2.753737943660129
Validation loss: 2.53172931110843

Epoch: 5| Step: 10
Training loss: 2.4652554852786626
Validation loss: 2.5335804470901024

Epoch: 342| Step: 0
Training loss: 2.2030637475555395
Validation loss: 2.545391064917239

Epoch: 5| Step: 1
Training loss: 2.7396848729876924
Validation loss: 2.5531164017569914

Epoch: 5| Step: 2
Training loss: 2.8564077521568993
Validation loss: 2.5601359231320466

Epoch: 5| Step: 3
Training loss: 2.598098235424898
Validation loss: 2.548540137857781

Epoch: 5| Step: 4
Training loss: 2.23588777562798
Validation loss: 2.5474707639379717

Epoch: 5| Step: 5
Training loss: 2.2452516254197867
Validation loss: 2.540741969288525

Epoch: 5| Step: 6
Training loss: 2.5323137473541983
Validation loss: 2.546542457679873

Epoch: 5| Step: 7
Training loss: 3.0441600734814385
Validation loss: 2.5492319987371834

Epoch: 5| Step: 8
Training loss: 2.1373672756459516
Validation loss: 2.5477385781568906

Epoch: 5| Step: 9
Training loss: 2.9992077099139083
Validation loss: 2.5398807662949503

Epoch: 5| Step: 10
Training loss: 2.457304388975225
Validation loss: 2.542491933856804

Epoch: 343| Step: 0
Training loss: 2.8492276600812665
Validation loss: 2.5616027397657053

Epoch: 5| Step: 1
Training loss: 2.594962606436264
Validation loss: 2.5651543928348763

Epoch: 5| Step: 2
Training loss: 2.4720179500792296
Validation loss: 2.5780567705828106

Epoch: 5| Step: 3
Training loss: 2.3084554614686046
Validation loss: 2.584846683140781

Epoch: 5| Step: 4
Training loss: 2.2904216389853365
Validation loss: 2.5973895932614695

Epoch: 5| Step: 5
Training loss: 2.717939584898495
Validation loss: 2.578444175813335

Epoch: 5| Step: 6
Training loss: 2.7493060710337254
Validation loss: 2.5811864202935784

Epoch: 5| Step: 7
Training loss: 2.811768330663945
Validation loss: 2.585187376340069

Epoch: 5| Step: 8
Training loss: 2.5140333175150897
Validation loss: 2.576476107838427

Epoch: 5| Step: 9
Training loss: 2.0812394746164853
Validation loss: 2.578733825888962

Epoch: 5| Step: 10
Training loss: 2.455303124167986
Validation loss: 2.573153356657372

Epoch: 344| Step: 0
Training loss: 2.7423073940748166
Validation loss: 2.566758674586029

Epoch: 5| Step: 1
Training loss: 2.204037308337354
Validation loss: 2.566420156959674

Epoch: 5| Step: 2
Training loss: 2.369978565489339
Validation loss: 2.5478758046893404

Epoch: 5| Step: 3
Training loss: 2.778064231937415
Validation loss: 2.5609734292725115

Epoch: 5| Step: 4
Training loss: 2.384586161891129
Validation loss: 2.537787281058069

Epoch: 5| Step: 5
Training loss: 2.6623680117849564
Validation loss: 2.530714579248349

Epoch: 5| Step: 6
Training loss: 2.2188310205415114
Validation loss: 2.5332660634814044

Epoch: 5| Step: 7
Training loss: 2.276400179237274
Validation loss: 2.51027451585341

Epoch: 5| Step: 8
Training loss: 2.5245799971153056
Validation loss: 2.5260102043733954

Epoch: 5| Step: 9
Training loss: 2.366071078976505
Validation loss: 2.517885230560269

Epoch: 5| Step: 10
Training loss: 3.1798439081137713
Validation loss: 2.531261166054584

Epoch: 345| Step: 0
Training loss: 2.1896091647186653
Validation loss: 2.548445361851011

Epoch: 5| Step: 1
Training loss: 2.6595670745016364
Validation loss: 2.550960438558987

Epoch: 5| Step: 2
Training loss: 2.7543134672330325
Validation loss: 2.5532103597506843

Epoch: 5| Step: 3
Training loss: 2.2917737300023333
Validation loss: 2.560476635273593

Epoch: 5| Step: 4
Training loss: 2.3388438436661247
Validation loss: 2.568545628408692

Epoch: 5| Step: 5
Training loss: 2.6519237517245737
Validation loss: 2.5572105789001784

Epoch: 5| Step: 6
Training loss: 2.8017497283616817
Validation loss: 2.549733517407693

Epoch: 5| Step: 7
Training loss: 2.4172693575293973
Validation loss: 2.5362112388134888

Epoch: 5| Step: 8
Training loss: 2.8412076883316475
Validation loss: 2.516713725066152

Epoch: 5| Step: 9
Training loss: 2.6099080894627527
Validation loss: 2.516051774742538

Epoch: 5| Step: 10
Training loss: 2.0583424134253665
Validation loss: 2.500256324261262

Epoch: 346| Step: 0
Training loss: 2.083876716957669
Validation loss: 2.498850591035137

Epoch: 5| Step: 1
Training loss: 2.300428275993564
Validation loss: 2.492852294794123

Epoch: 5| Step: 2
Training loss: 2.5202849451061695
Validation loss: 2.5112787130862815

Epoch: 5| Step: 3
Training loss: 2.46737893577651
Validation loss: 2.5142005133594276

Epoch: 5| Step: 4
Training loss: 2.549463372706015
Validation loss: 2.538337127588932

Epoch: 5| Step: 5
Training loss: 1.7108442725296222
Validation loss: 2.585202169960804

Epoch: 5| Step: 6
Training loss: 3.1318574053579
Validation loss: 2.6241945993200875

Epoch: 5| Step: 7
Training loss: 2.397662009452597
Validation loss: 2.6001742503760474

Epoch: 5| Step: 8
Training loss: 3.06667930213426
Validation loss: 2.564210796347653

Epoch: 5| Step: 9
Training loss: 2.300799695185507
Validation loss: 2.5558722658544064

Epoch: 5| Step: 10
Training loss: 3.078132435746095
Validation loss: 2.5347790653876605

Epoch: 347| Step: 0
Training loss: 2.6551222258341802
Validation loss: 2.518229271863418

Epoch: 5| Step: 1
Training loss: 2.6547416443492553
Validation loss: 2.518261279637242

Epoch: 5| Step: 2
Training loss: 2.5663874841755883
Validation loss: 2.51697970293836

Epoch: 5| Step: 3
Training loss: 2.6777443471732623
Validation loss: 2.522550537171613

Epoch: 5| Step: 4
Training loss: 2.048505410378825
Validation loss: 2.507175216739094

Epoch: 5| Step: 5
Training loss: 2.0691087210084027
Validation loss: 2.515474549731228

Epoch: 5| Step: 6
Training loss: 2.863291408630086
Validation loss: 2.5182080671636657

Epoch: 5| Step: 7
Training loss: 2.498452279701438
Validation loss: 2.5620042374855485

Epoch: 5| Step: 8
Training loss: 2.373421093982602
Validation loss: 2.567851680212248

Epoch: 5| Step: 9
Training loss: 2.590393284281083
Validation loss: 2.5997773181995316

Epoch: 5| Step: 10
Training loss: 2.6406559688399893
Validation loss: 2.583468465085789

Epoch: 348| Step: 0
Training loss: 2.629523602986311
Validation loss: 2.5635914332781837

Epoch: 5| Step: 1
Training loss: 2.8050669463901334
Validation loss: 2.5526572597759705

Epoch: 5| Step: 2
Training loss: 2.407218143843038
Validation loss: 2.5487870010593214

Epoch: 5| Step: 3
Training loss: 2.80602162542731
Validation loss: 2.543705952427687

Epoch: 5| Step: 4
Training loss: 1.957538470478504
Validation loss: 2.5407058705976535

Epoch: 5| Step: 5
Training loss: 2.5905967756880504
Validation loss: 2.528540084974868

Epoch: 5| Step: 6
Training loss: 2.6601464807720303
Validation loss: 2.5131502201811298

Epoch: 5| Step: 7
Training loss: 2.328705068944159
Validation loss: 2.5254344464499168

Epoch: 5| Step: 8
Training loss: 2.5159269353085425
Validation loss: 2.5325094999158195

Epoch: 5| Step: 9
Training loss: 2.1199689661309664
Validation loss: 2.566208397805036

Epoch: 5| Step: 10
Training loss: 2.709982316216348
Validation loss: 2.5671990261873043

Epoch: 349| Step: 0
Training loss: 2.7509024613122968
Validation loss: 2.5707824279443523

Epoch: 5| Step: 1
Training loss: 2.8564855432530156
Validation loss: 2.588544050841043

Epoch: 5| Step: 2
Training loss: 2.3607363783719997
Validation loss: 2.5951870909082198

Epoch: 5| Step: 3
Training loss: 2.1964998665646123
Validation loss: 2.607465857500131

Epoch: 5| Step: 4
Training loss: 2.423322675629923
Validation loss: 2.5824425296408307

Epoch: 5| Step: 5
Training loss: 2.0674772605890928
Validation loss: 2.561876503769638

Epoch: 5| Step: 6
Training loss: 2.812710478642233
Validation loss: 2.5487172197997

Epoch: 5| Step: 7
Training loss: 2.4876023928017217
Validation loss: 2.508015918758758

Epoch: 5| Step: 8
Training loss: 2.7020346145728054
Validation loss: 2.5102588343713

Epoch: 5| Step: 9
Training loss: 1.9398537151988677
Validation loss: 2.511163706517101

Epoch: 5| Step: 10
Training loss: 2.714101566435428
Validation loss: 2.5016614684339986

Epoch: 350| Step: 0
Training loss: 2.8028770277557573
Validation loss: 2.5160855790286236

Epoch: 5| Step: 1
Training loss: 2.8719688690751024
Validation loss: 2.502847177201609

Epoch: 5| Step: 2
Training loss: 2.4220208893181447
Validation loss: 2.5047737095742644

Epoch: 5| Step: 3
Training loss: 2.637652467777263
Validation loss: 2.51786674659509

Epoch: 5| Step: 4
Training loss: 2.046902255976093
Validation loss: 2.5477704768233083

Epoch: 5| Step: 5
Training loss: 2.2206273263091836
Validation loss: 2.5348553541141348

Epoch: 5| Step: 6
Training loss: 2.672273483454404
Validation loss: 2.5656372292648717

Epoch: 5| Step: 7
Training loss: 2.529357579508016
Validation loss: 2.5625355950901407

Epoch: 5| Step: 8
Training loss: 2.0544052800476105
Validation loss: 2.578550487719303

Epoch: 5| Step: 9
Training loss: 2.819147011822473
Validation loss: 2.5554948363804755

Epoch: 5| Step: 10
Training loss: 2.0438722906360094
Validation loss: 2.559006447234092

Epoch: 351| Step: 0
Training loss: 2.5117275777753596
Validation loss: 2.5698110230445033

Epoch: 5| Step: 1
Training loss: 2.9578074314660414
Validation loss: 2.5668548498084847

Epoch: 5| Step: 2
Training loss: 2.123463916965116
Validation loss: 2.572534398661596

Epoch: 5| Step: 3
Training loss: 1.9596617907062068
Validation loss: 2.5834077301056855

Epoch: 5| Step: 4
Training loss: 2.495720920567962
Validation loss: 2.5696252185213155

Epoch: 5| Step: 5
Training loss: 2.547800656472093
Validation loss: 2.571228979050325

Epoch: 5| Step: 6
Training loss: 2.3359647513238486
Validation loss: 2.5503332888607146

Epoch: 5| Step: 7
Training loss: 2.896018774740997
Validation loss: 2.5739370927042873

Epoch: 5| Step: 8
Training loss: 2.463433444097099
Validation loss: 2.563077668937587

Epoch: 5| Step: 9
Training loss: 2.2131629769515007
Validation loss: 2.5426813121343135

Epoch: 5| Step: 10
Training loss: 2.5020059167561755
Validation loss: 2.543727483763369

Epoch: 352| Step: 0
Training loss: 2.2446182313789294
Validation loss: 2.5374661928967144

Epoch: 5| Step: 1
Training loss: 2.8100605027551073
Validation loss: 2.5416776823964713

Epoch: 5| Step: 2
Training loss: 2.3473643599090845
Validation loss: 2.5291358335533722

Epoch: 5| Step: 3
Training loss: 2.808967491187221
Validation loss: 2.5494052938646616

Epoch: 5| Step: 4
Training loss: 2.10947615769451
Validation loss: 2.592677847981884

Epoch: 5| Step: 5
Training loss: 2.404649177231028
Validation loss: 2.5958304336377065

Epoch: 5| Step: 6
Training loss: 2.6313211535621406
Validation loss: 2.59775832804722

Epoch: 5| Step: 7
Training loss: 2.277702499582688
Validation loss: 2.5813803953724093

Epoch: 5| Step: 8
Training loss: 2.1830923088153176
Validation loss: 2.574542046625666

Epoch: 5| Step: 9
Training loss: 2.9561001761861774
Validation loss: 2.5846790949274183

Epoch: 5| Step: 10
Training loss: 2.4409823850803307
Validation loss: 2.5746244897258914

Epoch: 353| Step: 0
Training loss: 2.3815085923966723
Validation loss: 2.5673851261217346

Epoch: 5| Step: 1
Training loss: 2.532218371112137
Validation loss: 2.5444309776485823

Epoch: 5| Step: 2
Training loss: 3.0466330407733446
Validation loss: 2.5238797116448985

Epoch: 5| Step: 3
Training loss: 2.4933443164923528
Validation loss: 2.5140085154670526

Epoch: 5| Step: 4
Training loss: 2.0572552899070016
Validation loss: 2.5097077215017514

Epoch: 5| Step: 5
Training loss: 2.857095779303567
Validation loss: 2.5030612702036947

Epoch: 5| Step: 6
Training loss: 2.3791064849920343
Validation loss: 2.495215435689305

Epoch: 5| Step: 7
Training loss: 1.9618985681980563
Validation loss: 2.5082168720771527

Epoch: 5| Step: 8
Training loss: 2.2459693409838986
Validation loss: 2.5364076780680316

Epoch: 5| Step: 9
Training loss: 2.414415055983754
Validation loss: 2.5380560675787893

Epoch: 5| Step: 10
Training loss: 2.460591803596399
Validation loss: 2.567510629737308

Epoch: 354| Step: 0
Training loss: 2.246540482917666
Validation loss: 2.5857960647099003

Epoch: 5| Step: 1
Training loss: 2.594556384379818
Validation loss: 2.5664631879439668

Epoch: 5| Step: 2
Training loss: 2.8544781554350624
Validation loss: 2.5715532716374043

Epoch: 5| Step: 3
Training loss: 2.461350760501872
Validation loss: 2.559843393529624

Epoch: 5| Step: 4
Training loss: 2.60188268575603
Validation loss: 2.5633952360051424

Epoch: 5| Step: 5
Training loss: 2.6691579109434955
Validation loss: 2.5494162235314377

Epoch: 5| Step: 6
Training loss: 2.43969266034618
Validation loss: 2.546872244981315

Epoch: 5| Step: 7
Training loss: 1.9179230041642297
Validation loss: 2.5175990290099985

Epoch: 5| Step: 8
Training loss: 2.5880365524894513
Validation loss: 2.523488688225166

Epoch: 5| Step: 9
Training loss: 2.1011926261698397
Validation loss: 2.505183422766463

Epoch: 5| Step: 10
Training loss: 2.1905152384513773
Validation loss: 2.5091656022805844

Epoch: 355| Step: 0
Training loss: 2.9752165386990637
Validation loss: 2.5283012903535553

Epoch: 5| Step: 1
Training loss: 2.3262020080305854
Validation loss: 2.517235920562707

Epoch: 5| Step: 2
Training loss: 2.8339517329917174
Validation loss: 2.528082012264975

Epoch: 5| Step: 3
Training loss: 1.7617824906619648
Validation loss: 2.536225898622622

Epoch: 5| Step: 4
Training loss: 2.649267736064725
Validation loss: 2.5448263718925697

Epoch: 5| Step: 5
Training loss: 2.3170749670420823
Validation loss: 2.541627386009153

Epoch: 5| Step: 6
Training loss: 2.55524795404055
Validation loss: 2.5219550119080276

Epoch: 5| Step: 7
Training loss: 2.1072742314983737
Validation loss: 2.5255111991540837

Epoch: 5| Step: 8
Training loss: 2.067275789181888
Validation loss: 2.5316576581960737

Epoch: 5| Step: 9
Training loss: 2.506409630008319
Validation loss: 2.533863427584169

Epoch: 5| Step: 10
Training loss: 2.4724043827834548
Validation loss: 2.5426256867595267

Epoch: 356| Step: 0
Training loss: 2.212854208314099
Validation loss: 2.547768702840897

Epoch: 5| Step: 1
Training loss: 2.505441751266239
Validation loss: 2.562300398421315

Epoch: 5| Step: 2
Training loss: 2.4701607451855567
Validation loss: 2.5544429743687287

Epoch: 5| Step: 3
Training loss: 3.0206449954197683
Validation loss: 2.5391121979827855

Epoch: 5| Step: 4
Training loss: 2.1518742487161275
Validation loss: 2.543673358774617

Epoch: 5| Step: 5
Training loss: 2.348186718614709
Validation loss: 2.5309563697768582

Epoch: 5| Step: 6
Training loss: 2.374655748815925
Validation loss: 2.531951790806142

Epoch: 5| Step: 7
Training loss: 2.072354673437221
Validation loss: 2.52469125994518

Epoch: 5| Step: 8
Training loss: 2.84662474486001
Validation loss: 2.5583337519733096

Epoch: 5| Step: 9
Training loss: 2.509183704880463
Validation loss: 2.553128461235085

Epoch: 5| Step: 10
Training loss: 1.8837933656476253
Validation loss: 2.545472445945754

Epoch: 357| Step: 0
Training loss: 2.6485546164935077
Validation loss: 2.568043848852983

Epoch: 5| Step: 1
Training loss: 2.287290961714858
Validation loss: 2.5807593724783273

Epoch: 5| Step: 2
Training loss: 2.4620732668674465
Validation loss: 2.5688538052533603

Epoch: 5| Step: 3
Training loss: 2.6904812622665526
Validation loss: 2.566646124005529

Epoch: 5| Step: 4
Training loss: 2.633136310530464
Validation loss: 2.52312887149558

Epoch: 5| Step: 5
Training loss: 2.8600649808957646
Validation loss: 2.5196947031244923

Epoch: 5| Step: 6
Training loss: 2.3117461135549418
Validation loss: 2.494791479986523

Epoch: 5| Step: 7
Training loss: 1.8044609819412862
Validation loss: 2.4856489520030083

Epoch: 5| Step: 8
Training loss: 2.3490706006025
Validation loss: 2.4786710284193716

Epoch: 5| Step: 9
Training loss: 2.2493028620382227
Validation loss: 2.483394382577324

Epoch: 5| Step: 10
Training loss: 2.2859682384830973
Validation loss: 2.5178786582504196

Epoch: 358| Step: 0
Training loss: 2.8742882220661694
Validation loss: 2.552963398081928

Epoch: 5| Step: 1
Training loss: 2.238281995630057
Validation loss: 2.5944152870342445

Epoch: 5| Step: 2
Training loss: 2.583436799797387
Validation loss: 2.562522790038628

Epoch: 5| Step: 3
Training loss: 2.3040991080545012
Validation loss: 2.5477106698922554

Epoch: 5| Step: 4
Training loss: 2.320211389053286
Validation loss: 2.5514900885838814

Epoch: 5| Step: 5
Training loss: 2.6367760772124478
Validation loss: 2.5255721753374316

Epoch: 5| Step: 6
Training loss: 2.8608258011501446
Validation loss: 2.4940738025808225

Epoch: 5| Step: 7
Training loss: 2.6232148412807565
Validation loss: 2.4808535284451008

Epoch: 5| Step: 8
Training loss: 2.3431187097399375
Validation loss: 2.4760074031552897

Epoch: 5| Step: 9
Training loss: 1.9188860469140057
Validation loss: 2.482644112581456

Epoch: 5| Step: 10
Training loss: 1.6936655086825447
Validation loss: 2.492671042572975

Epoch: 359| Step: 0
Training loss: 2.544634529807632
Validation loss: 2.5112351101325903

Epoch: 5| Step: 1
Training loss: 2.524302331455089
Validation loss: 2.5320784249879695

Epoch: 5| Step: 2
Training loss: 1.9665330787590418
Validation loss: 2.5723262204195483

Epoch: 5| Step: 3
Training loss: 2.582527424610385
Validation loss: 2.6168102077550697

Epoch: 5| Step: 4
Training loss: 2.3124354585455924
Validation loss: 2.667216166157749

Epoch: 5| Step: 5
Training loss: 2.9148996904496216
Validation loss: 2.680428175276704

Epoch: 5| Step: 6
Training loss: 2.428093292147127
Validation loss: 2.5934380043317673

Epoch: 5| Step: 7
Training loss: 2.5764450610932945
Validation loss: 2.54645572172796

Epoch: 5| Step: 8
Training loss: 2.276251974508235
Validation loss: 2.543003733853183

Epoch: 5| Step: 9
Training loss: 2.7103035045304282
Validation loss: 2.5443265701852376

Epoch: 5| Step: 10
Training loss: 2.1108107590199285
Validation loss: 2.5313724674044185

Epoch: 360| Step: 0
Training loss: 2.133673749029444
Validation loss: 2.519445812560247

Epoch: 5| Step: 1
Training loss: 2.5159307258542243
Validation loss: 2.520430975580264

Epoch: 5| Step: 2
Training loss: 2.521947462135169
Validation loss: 2.506840266415697

Epoch: 5| Step: 3
Training loss: 2.6675919675837942
Validation loss: 2.4934216015218955

Epoch: 5| Step: 4
Training loss: 2.374511266916598
Validation loss: 2.4918149955894453

Epoch: 5| Step: 5
Training loss: 2.4455242613729817
Validation loss: 2.496668102725597

Epoch: 5| Step: 6
Training loss: 2.515391273776879
Validation loss: 2.5110907878577238

Epoch: 5| Step: 7
Training loss: 2.4200596065904416
Validation loss: 2.5312700451850088

Epoch: 5| Step: 8
Training loss: 2.561575653090802
Validation loss: 2.5931805063167954

Epoch: 5| Step: 9
Training loss: 2.4410732194732687
Validation loss: 2.598931040517694

Epoch: 5| Step: 10
Training loss: 2.4886335425956703
Validation loss: 2.588006850960765

Epoch: 361| Step: 0
Training loss: 2.5110990195794374
Validation loss: 2.546694233957535

Epoch: 5| Step: 1
Training loss: 2.2316952087575177
Validation loss: 2.5126682709814014

Epoch: 5| Step: 2
Training loss: 2.5892972297600307
Validation loss: 2.4834629540627975

Epoch: 5| Step: 3
Training loss: 2.386906343320715
Validation loss: 2.4768353792554154

Epoch: 5| Step: 4
Training loss: 2.3300877432612674
Validation loss: 2.4641344615129555

Epoch: 5| Step: 5
Training loss: 2.0262863547507233
Validation loss: 2.4664865005461767

Epoch: 5| Step: 6
Training loss: 2.4078755028246936
Validation loss: 2.4797035939480154

Epoch: 5| Step: 7
Training loss: 2.3666304634799635
Validation loss: 2.4838697286375546

Epoch: 5| Step: 8
Training loss: 2.2499239166959426
Validation loss: 2.5048934687148883

Epoch: 5| Step: 9
Training loss: 2.640691722500927
Validation loss: 2.5270646370307728

Epoch: 5| Step: 10
Training loss: 2.7879072088619825
Validation loss: 2.5502541076239194

Epoch: 362| Step: 0
Training loss: 2.242670731525313
Validation loss: 2.573255043319124

Epoch: 5| Step: 1
Training loss: 2.59035352289918
Validation loss: 2.590403749550316

Epoch: 5| Step: 2
Training loss: 2.199790107944949
Validation loss: 2.613003473626182

Epoch: 5| Step: 3
Training loss: 2.9535615790053478
Validation loss: 2.61727276857384

Epoch: 5| Step: 4
Training loss: 2.2147162937312648
Validation loss: 2.5835984226678224

Epoch: 5| Step: 5
Training loss: 2.4381229876070143
Validation loss: 2.5636873053255353

Epoch: 5| Step: 6
Training loss: 2.364614466883735
Validation loss: 2.566789314137446

Epoch: 5| Step: 7
Training loss: 2.0612080313329355
Validation loss: 2.54394612272447

Epoch: 5| Step: 8
Training loss: 1.9326607350844731
Validation loss: 2.5535762271899736

Epoch: 5| Step: 9
Training loss: 2.5553844562787162
Validation loss: 2.541290082490371

Epoch: 5| Step: 10
Training loss: 2.711306500125368
Validation loss: 2.541972906611653

Epoch: 363| Step: 0
Training loss: 2.2150622601509906
Validation loss: 2.5472794259551397

Epoch: 5| Step: 1
Training loss: 2.0522505664617867
Validation loss: 2.5469685893450467

Epoch: 5| Step: 2
Training loss: 2.910213925602968
Validation loss: 2.5949709672718666

Epoch: 5| Step: 3
Training loss: 2.1315788082521827
Validation loss: 2.5827976972180093

Epoch: 5| Step: 4
Training loss: 2.785132965803793
Validation loss: 2.6072614074049505

Epoch: 5| Step: 5
Training loss: 2.2525893253138856
Validation loss: 2.5839390532495923

Epoch: 5| Step: 6
Training loss: 2.5799663094974883
Validation loss: 2.523680018719139

Epoch: 5| Step: 7
Training loss: 2.2305030619692827
Validation loss: 2.508960946359426

Epoch: 5| Step: 8
Training loss: 2.5465104479917136
Validation loss: 2.504551522022503

Epoch: 5| Step: 9
Training loss: 2.3626455918111975
Validation loss: 2.49363999201349

Epoch: 5| Step: 10
Training loss: 2.118613913337643
Validation loss: 2.4939309193256998

Epoch: 364| Step: 0
Training loss: 1.9876084903880398
Validation loss: 2.5045760277352627

Epoch: 5| Step: 1
Training loss: 2.227424427981103
Validation loss: 2.5133704246082393

Epoch: 5| Step: 2
Training loss: 2.4976879873159543
Validation loss: 2.5201402255582814

Epoch: 5| Step: 3
Training loss: 2.5743978666700933
Validation loss: 2.526470960178074

Epoch: 5| Step: 4
Training loss: 2.4585911782599457
Validation loss: 2.5652697661141044

Epoch: 5| Step: 5
Training loss: 2.1650800275217845
Validation loss: 2.5460349063280807

Epoch: 5| Step: 6
Training loss: 2.20265636464928
Validation loss: 2.5609324563169147

Epoch: 5| Step: 7
Training loss: 2.611988517665891
Validation loss: 2.5535037034485235

Epoch: 5| Step: 8
Training loss: 2.0876776476896146
Validation loss: 2.533001504275558

Epoch: 5| Step: 9
Training loss: 2.800002496582008
Validation loss: 2.5208500670288925

Epoch: 5| Step: 10
Training loss: 2.396414633733328
Validation loss: 2.5292125600904956

Epoch: 365| Step: 0
Training loss: 2.0066953883644993
Validation loss: 2.5363212191774576

Epoch: 5| Step: 1
Training loss: 2.4480625082088694
Validation loss: 2.5483289944744003

Epoch: 5| Step: 2
Training loss: 2.5102683903339917
Validation loss: 2.565907581456197

Epoch: 5| Step: 3
Training loss: 2.965345176945277
Validation loss: 2.5624925406702834

Epoch: 5| Step: 4
Training loss: 1.91275814533207
Validation loss: 2.5568349828258206

Epoch: 5| Step: 5
Training loss: 2.2411956188201976
Validation loss: 2.5443081130657608

Epoch: 5| Step: 6
Training loss: 2.3646166850915455
Validation loss: 2.54072248820776

Epoch: 5| Step: 7
Training loss: 2.001009924532763
Validation loss: 2.5407029736796964

Epoch: 5| Step: 8
Training loss: 2.6579443520432005
Validation loss: 2.5432117821672855

Epoch: 5| Step: 9
Training loss: 2.101385513283903
Validation loss: 2.5447804675952352

Epoch: 5| Step: 10
Training loss: 2.6958537125050563
Validation loss: 2.5179961559369883

Epoch: 366| Step: 0
Training loss: 2.2899594160923145
Validation loss: 2.535998505873955

Epoch: 5| Step: 1
Training loss: 2.494626182424746
Validation loss: 2.560066281980837

Epoch: 5| Step: 2
Training loss: 2.811029600847277
Validation loss: 2.5463584870886957

Epoch: 5| Step: 3
Training loss: 2.319609770019185
Validation loss: 2.531167636039241

Epoch: 5| Step: 4
Training loss: 2.403000755719508
Validation loss: 2.542028492820155

Epoch: 5| Step: 5
Training loss: 2.02945583040376
Validation loss: 2.5672110994009842

Epoch: 5| Step: 6
Training loss: 2.20900768804011
Validation loss: 2.563404848907296

Epoch: 5| Step: 7
Training loss: 2.553933875307056
Validation loss: 2.5659707663051994

Epoch: 5| Step: 8
Training loss: 1.7508642242529255
Validation loss: 2.559706750493597

Epoch: 5| Step: 9
Training loss: 2.5205165149016757
Validation loss: 2.538946524496367

Epoch: 5| Step: 10
Training loss: 2.415723506996581
Validation loss: 2.5103330261678294

Epoch: 367| Step: 0
Training loss: 2.6303840100127234
Validation loss: 2.514075483086473

Epoch: 5| Step: 1
Training loss: 2.7118846107342502
Validation loss: 2.4990041174608213

Epoch: 5| Step: 2
Training loss: 2.308542318787827
Validation loss: 2.511014522424293

Epoch: 5| Step: 3
Training loss: 1.944514589709603
Validation loss: 2.5244493664468415

Epoch: 5| Step: 4
Training loss: 2.384830208418587
Validation loss: 2.511792067871937

Epoch: 5| Step: 5
Training loss: 2.3364499145664537
Validation loss: 2.5212765857119828

Epoch: 5| Step: 6
Training loss: 2.583227852749577
Validation loss: 2.5531556545968783

Epoch: 5| Step: 7
Training loss: 1.9240415812934035
Validation loss: 2.555129674094718

Epoch: 5| Step: 8
Training loss: 2.448679595449236
Validation loss: 2.561529822765358

Epoch: 5| Step: 9
Training loss: 2.0378434201886804
Validation loss: 2.5702572910865045

Epoch: 5| Step: 10
Training loss: 2.4686985251939286
Validation loss: 2.5626716406218852

Epoch: 368| Step: 0
Training loss: 2.571263377999093
Validation loss: 2.570900061541738

Epoch: 5| Step: 1
Training loss: 2.2792707243974366
Validation loss: 2.5335206198829594

Epoch: 5| Step: 2
Training loss: 2.4883114320370745
Validation loss: 2.524636755276703

Epoch: 5| Step: 3
Training loss: 1.9249806316441733
Validation loss: 2.515407042505983

Epoch: 5| Step: 4
Training loss: 2.2217103792522876
Validation loss: 2.5300567044381346

Epoch: 5| Step: 5
Training loss: 2.2591149820259613
Validation loss: 2.531652337815568

Epoch: 5| Step: 6
Training loss: 2.3872985635033026
Validation loss: 2.5229599200847286

Epoch: 5| Step: 7
Training loss: 2.3820394293775093
Validation loss: 2.526114682832814

Epoch: 5| Step: 8
Training loss: 2.4884211382626815
Validation loss: 2.5197098975422003

Epoch: 5| Step: 9
Training loss: 2.329031236654471
Validation loss: 2.545766849440878

Epoch: 5| Step: 10
Training loss: 2.1916687616065085
Validation loss: 2.542477494700614

Epoch: 369| Step: 0
Training loss: 1.7112858387194576
Validation loss: 2.548993426771138

Epoch: 5| Step: 1
Training loss: 2.7394013338348513
Validation loss: 2.5379194384089954

Epoch: 5| Step: 2
Training loss: 2.529045557917254
Validation loss: 2.5208101697803484

Epoch: 5| Step: 3
Training loss: 2.357738103887329
Validation loss: 2.5271449658402334

Epoch: 5| Step: 4
Training loss: 2.7641045652890126
Validation loss: 2.4986431326127163

Epoch: 5| Step: 5
Training loss: 2.030070035506179
Validation loss: 2.5123052575550773

Epoch: 5| Step: 6
Training loss: 2.045771410510593
Validation loss: 2.5041781019008043

Epoch: 5| Step: 7
Training loss: 2.5550934355311616
Validation loss: 2.5125288980685596

Epoch: 5| Step: 8
Training loss: 1.9995407530897193
Validation loss: 2.490241178808503

Epoch: 5| Step: 9
Training loss: 2.247214606541619
Validation loss: 2.515890990054402

Epoch: 5| Step: 10
Training loss: 2.405357690807656
Validation loss: 2.528633797341931

Epoch: 370| Step: 0
Training loss: 2.8177317808142845
Validation loss: 2.528932344659858

Epoch: 5| Step: 1
Training loss: 2.3164715042057744
Validation loss: 2.497080580099256

Epoch: 5| Step: 2
Training loss: 1.8639188751118023
Validation loss: 2.5173485757706366

Epoch: 5| Step: 3
Training loss: 2.717293711029323
Validation loss: 2.5133529447883483

Epoch: 5| Step: 4
Training loss: 2.6374965396514902
Validation loss: 2.519271496585716

Epoch: 5| Step: 5
Training loss: 2.085785478059966
Validation loss: 2.532108844314427

Epoch: 5| Step: 6
Training loss: 2.4133230515080117
Validation loss: 2.5275629085527984

Epoch: 5| Step: 7
Training loss: 2.0783565076786643
Validation loss: 2.5347886614020196

Epoch: 5| Step: 8
Training loss: 2.2262907163483234
Validation loss: 2.532832412817062

Epoch: 5| Step: 9
Training loss: 2.075404401231216
Validation loss: 2.5294894632710205

Epoch: 5| Step: 10
Training loss: 2.1831962755975933
Validation loss: 2.517645842833658

Epoch: 371| Step: 0
Training loss: 2.0175325106018613
Validation loss: 2.5308052319412275

Epoch: 5| Step: 1
Training loss: 2.2945383863432287
Validation loss: 2.5308764126436527

Epoch: 5| Step: 2
Training loss: 2.485842960845006
Validation loss: 2.5371027979250464

Epoch: 5| Step: 3
Training loss: 2.7239194810088962
Validation loss: 2.5440355259832095

Epoch: 5| Step: 4
Training loss: 2.4470791513528614
Validation loss: 2.5440151500801576

Epoch: 5| Step: 5
Training loss: 1.946963547947766
Validation loss: 2.5319431216329065

Epoch: 5| Step: 6
Training loss: 2.271187734217508
Validation loss: 2.5185122406490748

Epoch: 5| Step: 7
Training loss: 2.267977210386175
Validation loss: 2.5096097546396527

Epoch: 5| Step: 8
Training loss: 2.2692221662514953
Validation loss: 2.5254234931889905

Epoch: 5| Step: 9
Training loss: 2.19871772764116
Validation loss: 2.5031374358832186

Epoch: 5| Step: 10
Training loss: 2.5275761823181266
Validation loss: 2.520544668328191

Epoch: 372| Step: 0
Training loss: 2.490261756896027
Validation loss: 2.523048294923267

Epoch: 5| Step: 1
Training loss: 1.7339978882051872
Validation loss: 2.5368902569710827

Epoch: 5| Step: 2
Training loss: 2.5856374699082347
Validation loss: 2.532918062672461

Epoch: 5| Step: 3
Training loss: 2.433764603252124
Validation loss: 2.533521149100643

Epoch: 5| Step: 4
Training loss: 1.8533158511199463
Validation loss: 2.5386441581398365

Epoch: 5| Step: 5
Training loss: 2.3795281460182123
Validation loss: 2.526647051236879

Epoch: 5| Step: 6
Training loss: 2.366799602894172
Validation loss: 2.5308081584222624

Epoch: 5| Step: 7
Training loss: 2.5307191833772325
Validation loss: 2.537006313337477

Epoch: 5| Step: 8
Training loss: 2.1200537617182458
Validation loss: 2.522426402533043

Epoch: 5| Step: 9
Training loss: 2.5514341398003535
Validation loss: 2.5074529468342575

Epoch: 5| Step: 10
Training loss: 2.0972801169628172
Validation loss: 2.506489727870843

Epoch: 373| Step: 0
Training loss: 2.1083731073339473
Validation loss: 2.494393544647234

Epoch: 5| Step: 1
Training loss: 2.2089145423381105
Validation loss: 2.47052050928163

Epoch: 5| Step: 2
Training loss: 2.357836594404775
Validation loss: 2.4909311535897913

Epoch: 5| Step: 3
Training loss: 1.9471193065404564
Validation loss: 2.499091268294641

Epoch: 5| Step: 4
Training loss: 2.8678997101107666
Validation loss: 2.502016489933339

Epoch: 5| Step: 5
Training loss: 2.807635105241739
Validation loss: 2.518084759961011

Epoch: 5| Step: 6
Training loss: 2.4587856027559263
Validation loss: 2.517095844199622

Epoch: 5| Step: 7
Training loss: 2.099525457080237
Validation loss: 2.5376190297859336

Epoch: 5| Step: 8
Training loss: 2.313837643967087
Validation loss: 2.5418729049535327

Epoch: 5| Step: 9
Training loss: 1.8650931259917898
Validation loss: 2.5611532250268234

Epoch: 5| Step: 10
Training loss: 2.104632662800021
Validation loss: 2.55310449284096

Epoch: 374| Step: 0
Training loss: 2.5918719374963066
Validation loss: 2.5514628684276146

Epoch: 5| Step: 1
Training loss: 2.64343888276088
Validation loss: 2.5430816478646734

Epoch: 5| Step: 2
Training loss: 2.1285258942046736
Validation loss: 2.552047391382651

Epoch: 5| Step: 3
Training loss: 2.6583251028222494
Validation loss: 2.537110399603474

Epoch: 5| Step: 4
Training loss: 2.241941963601636
Validation loss: 2.546015003569192

Epoch: 5| Step: 5
Training loss: 2.0106136508819374
Validation loss: 2.5508583093766175

Epoch: 5| Step: 6
Training loss: 2.0654555443121465
Validation loss: 2.533441636698941

Epoch: 5| Step: 7
Training loss: 2.1533836441933865
Validation loss: 2.52504036715874

Epoch: 5| Step: 8
Training loss: 2.1235130942210185
Validation loss: 2.515140674081569

Epoch: 5| Step: 9
Training loss: 2.343540640063325
Validation loss: 2.5059992538792932

Epoch: 5| Step: 10
Training loss: 2.2016061728418665
Validation loss: 2.4967828575105684

Epoch: 375| Step: 0
Training loss: 2.3399489033654834
Validation loss: 2.5187116231752746

Epoch: 5| Step: 1
Training loss: 1.9768405763931718
Validation loss: 2.5353270318536665

Epoch: 5| Step: 2
Training loss: 2.383474589432251
Validation loss: 2.525583805004334

Epoch: 5| Step: 3
Training loss: 2.0692386937391927
Validation loss: 2.531736188709234

Epoch: 5| Step: 4
Training loss: 2.4168759836333495
Validation loss: 2.5238014628467322

Epoch: 5| Step: 5
Training loss: 2.058202485572946
Validation loss: 2.517483789276279

Epoch: 5| Step: 6
Training loss: 2.4166901247486443
Validation loss: 2.506273885539512

Epoch: 5| Step: 7
Training loss: 2.371413283208524
Validation loss: 2.52034754298256

Epoch: 5| Step: 8
Training loss: 2.204139854494026
Validation loss: 2.5030370436097322

Epoch: 5| Step: 9
Training loss: 2.5903748763097774
Validation loss: 2.515040757880512

Epoch: 5| Step: 10
Training loss: 2.4395231995852584
Validation loss: 2.517232120779638

Epoch: 376| Step: 0
Training loss: 2.0961687152095583
Validation loss: 2.518638890977443

Epoch: 5| Step: 1
Training loss: 2.495030040674787
Validation loss: 2.5403409641119605

Epoch: 5| Step: 2
Training loss: 2.305515153625365
Validation loss: 2.546777843779077

Epoch: 5| Step: 3
Training loss: 2.3243143526818844
Validation loss: 2.544390398261346

Epoch: 5| Step: 4
Training loss: 2.329885546775158
Validation loss: 2.536758627096282

Epoch: 5| Step: 5
Training loss: 2.471906840701661
Validation loss: 2.527708242698719

Epoch: 5| Step: 6
Training loss: 2.299573286527277
Validation loss: 2.5054304916291192

Epoch: 5| Step: 7
Training loss: 2.739686352396799
Validation loss: 2.499874087208478

Epoch: 5| Step: 8
Training loss: 1.873002259615112
Validation loss: 2.4872957390313437

Epoch: 5| Step: 9
Training loss: 2.239213093753214
Validation loss: 2.505957174411218

Epoch: 5| Step: 10
Training loss: 1.6868029673667173
Validation loss: 2.5341027512059684

Epoch: 377| Step: 0
Training loss: 1.631751267743747
Validation loss: 2.527682082905448

Epoch: 5| Step: 1
Training loss: 2.3500835038628254
Validation loss: 2.54188783417324

Epoch: 5| Step: 2
Training loss: 2.0129579153422976
Validation loss: 2.5569343922990537

Epoch: 5| Step: 3
Training loss: 2.374745405504935
Validation loss: 2.557478086899951

Epoch: 5| Step: 4
Training loss: 1.8762882893090786
Validation loss: 2.5551108665871927

Epoch: 5| Step: 5
Training loss: 2.67862985274767
Validation loss: 2.5573363813479215

Epoch: 5| Step: 6
Training loss: 2.4117208932484604
Validation loss: 2.537062413563336

Epoch: 5| Step: 7
Training loss: 2.430751457191163
Validation loss: 2.506025519301471

Epoch: 5| Step: 8
Training loss: 2.6783577425053546
Validation loss: 2.4915322873515064

Epoch: 5| Step: 9
Training loss: 2.2899230797521652
Validation loss: 2.5050423050570916

Epoch: 5| Step: 10
Training loss: 2.196848159126851
Validation loss: 2.4857470783480005

Epoch: 378| Step: 0
Training loss: 2.2805747509033787
Validation loss: 2.512035557791365

Epoch: 5| Step: 1
Training loss: 2.4076773633420463
Validation loss: 2.5341186270762153

Epoch: 5| Step: 2
Training loss: 2.229986830189224
Validation loss: 2.5451498796670515

Epoch: 5| Step: 3
Training loss: 1.937315039881542
Validation loss: 2.538388616777689

Epoch: 5| Step: 4
Training loss: 2.0804399489079137
Validation loss: 2.5250634993515755

Epoch: 5| Step: 5
Training loss: 2.640848184216593
Validation loss: 2.5392006790260666

Epoch: 5| Step: 6
Training loss: 2.647531360011831
Validation loss: 2.5199845238497027

Epoch: 5| Step: 7
Training loss: 2.3667702889479942
Validation loss: 2.512838772357039

Epoch: 5| Step: 8
Training loss: 2.175760977905729
Validation loss: 2.501732724138062

Epoch: 5| Step: 9
Training loss: 2.2488661134183916
Validation loss: 2.485152354292183

Epoch: 5| Step: 10
Training loss: 2.1383050752092245
Validation loss: 2.495315165604366

Epoch: 379| Step: 0
Training loss: 2.236064885400782
Validation loss: 2.4990460370270724

Epoch: 5| Step: 1
Training loss: 2.3921266713746276
Validation loss: 2.518068095784556

Epoch: 5| Step: 2
Training loss: 2.282665597313039
Validation loss: 2.533253869981163

Epoch: 5| Step: 3
Training loss: 2.728279338373063
Validation loss: 2.5292265742535545

Epoch: 5| Step: 4
Training loss: 1.9124516150643285
Validation loss: 2.518871004961933

Epoch: 5| Step: 5
Training loss: 2.425747931062692
Validation loss: 2.510560285663761

Epoch: 5| Step: 6
Training loss: 2.16915668555108
Validation loss: 2.502106049171314

Epoch: 5| Step: 7
Training loss: 2.1784644848842167
Validation loss: 2.4947872123718744

Epoch: 5| Step: 8
Training loss: 2.692341103713253
Validation loss: 2.5182514689582916

Epoch: 5| Step: 9
Training loss: 1.9950146529727975
Validation loss: 2.5119011149853216

Epoch: 5| Step: 10
Training loss: 1.9091321700248784
Validation loss: 2.507761678256429

Epoch: 380| Step: 0
Training loss: 2.243304569160115
Validation loss: 2.50991909866124

Epoch: 5| Step: 1
Training loss: 2.466359683428841
Validation loss: 2.527974233062845

Epoch: 5| Step: 2
Training loss: 2.350516153019994
Validation loss: 2.516451554686282

Epoch: 5| Step: 3
Training loss: 2.551392556468598
Validation loss: 2.5464261221414644

Epoch: 5| Step: 4
Training loss: 2.4255622605208647
Validation loss: 2.5330496401150073

Epoch: 5| Step: 5
Training loss: 1.7305170401213947
Validation loss: 2.5581338633997537

Epoch: 5| Step: 6
Training loss: 2.5028542437664147
Validation loss: 2.530467962976291

Epoch: 5| Step: 7
Training loss: 2.1596435159104868
Validation loss: 2.524823762633439

Epoch: 5| Step: 8
Training loss: 2.1844436001681697
Validation loss: 2.510182184164712

Epoch: 5| Step: 9
Training loss: 2.2965124973029334
Validation loss: 2.499235882424518

Epoch: 5| Step: 10
Training loss: 1.7809099240836368
Validation loss: 2.513724282965156

Epoch: 381| Step: 0
Training loss: 2.3080556277838764
Validation loss: 2.53611528486888

Epoch: 5| Step: 1
Training loss: 2.498236511047466
Validation loss: 2.540286349161736

Epoch: 5| Step: 2
Training loss: 1.7832003172468995
Validation loss: 2.57380032038024

Epoch: 5| Step: 3
Training loss: 2.1507708830883234
Validation loss: 2.569356642419004

Epoch: 5| Step: 4
Training loss: 2.457880355567609
Validation loss: 2.581298731167833

Epoch: 5| Step: 5
Training loss: 2.4459280391035922
Validation loss: 2.5934016535812883

Epoch: 5| Step: 6
Training loss: 2.017411024738592
Validation loss: 2.574005804812142

Epoch: 5| Step: 7
Training loss: 1.8794600529100423
Validation loss: 2.58405194986983

Epoch: 5| Step: 8
Training loss: 2.2041120550052096
Validation loss: 2.6027159662150927

Epoch: 5| Step: 9
Training loss: 2.6477123606868784
Validation loss: 2.577362492708381

Epoch: 5| Step: 10
Training loss: 2.2036799820775754
Validation loss: 2.5427555862948656

Epoch: 382| Step: 0
Training loss: 2.4000137567125877
Validation loss: 2.506676334067043

Epoch: 5| Step: 1
Training loss: 2.239574757640891
Validation loss: 2.498157903387609

Epoch: 5| Step: 2
Training loss: 2.2766778145661917
Validation loss: 2.4841819590670164

Epoch: 5| Step: 3
Training loss: 2.293388991050149
Validation loss: 2.4810773029827167

Epoch: 5| Step: 4
Training loss: 2.665067242745615
Validation loss: 2.4994215624236937

Epoch: 5| Step: 5
Training loss: 2.4605669983996132
Validation loss: 2.4922765386152768

Epoch: 5| Step: 6
Training loss: 2.2851577106699392
Validation loss: 2.5224489732912847

Epoch: 5| Step: 7
Training loss: 2.294240985261969
Validation loss: 2.531579717655607

Epoch: 5| Step: 8
Training loss: 2.2150297540943864
Validation loss: 2.5365006651618835

Epoch: 5| Step: 9
Training loss: 1.6582683285316073
Validation loss: 2.5466423237908566

Epoch: 5| Step: 10
Training loss: 2.0083569927589493
Validation loss: 2.5579333197825576

Epoch: 383| Step: 0
Training loss: 2.154271088460527
Validation loss: 2.536537450323929

Epoch: 5| Step: 1
Training loss: 1.3547423777305119
Validation loss: 2.529215713435996

Epoch: 5| Step: 2
Training loss: 2.6187058328987263
Validation loss: 2.517054046999827

Epoch: 5| Step: 3
Training loss: 2.7611815538466904
Validation loss: 2.4850025835442855

Epoch: 5| Step: 4
Training loss: 2.5619364793393924
Validation loss: 2.47822460524795

Epoch: 5| Step: 5
Training loss: 1.8670141546635337
Validation loss: 2.499895210531042

Epoch: 5| Step: 6
Training loss: 2.0332449872986884
Validation loss: 2.497404175849786

Epoch: 5| Step: 7
Training loss: 1.9695978912252359
Validation loss: 2.5076615871445775

Epoch: 5| Step: 8
Training loss: 2.2823903617139267
Validation loss: 2.53472400795767

Epoch: 5| Step: 9
Training loss: 2.2939456243015433
Validation loss: 2.551158505580389

Epoch: 5| Step: 10
Training loss: 2.345285040118381
Validation loss: 2.545840161023387

Epoch: 384| Step: 0
Training loss: 1.6468677006655645
Validation loss: 2.569978026646511

Epoch: 5| Step: 1
Training loss: 2.4053303335866105
Validation loss: 2.5626777209128795

Epoch: 5| Step: 2
Training loss: 2.3760763038430754
Validation loss: 2.539818572123794

Epoch: 5| Step: 3
Training loss: 2.269803423163219
Validation loss: 2.513120944433687

Epoch: 5| Step: 4
Training loss: 2.635761997279901
Validation loss: 2.5151109556850075

Epoch: 5| Step: 5
Training loss: 2.3621704517591575
Validation loss: 2.513959943655952

Epoch: 5| Step: 6
Training loss: 2.2452112736511185
Validation loss: 2.5037627257808635

Epoch: 5| Step: 7
Training loss: 2.246460780134416
Validation loss: 2.5259453302976294

Epoch: 5| Step: 8
Training loss: 1.8006234254998974
Validation loss: 2.5003837680566754

Epoch: 5| Step: 9
Training loss: 1.857309556647757
Validation loss: 2.4966566361471254

Epoch: 5| Step: 10
Training loss: 2.5237097814717506
Validation loss: 2.4960175593953293

Epoch: 385| Step: 0
Training loss: 1.6592566352770193
Validation loss: 2.5090733105029353

Epoch: 5| Step: 1
Training loss: 2.1362250557967135
Validation loss: 2.506042218544946

Epoch: 5| Step: 2
Training loss: 2.8611071400373076
Validation loss: 2.4882324253110704

Epoch: 5| Step: 3
Training loss: 2.056296527185426
Validation loss: 2.4932107927261478

Epoch: 5| Step: 4
Training loss: 3.058624306400686
Validation loss: 2.49796299341881

Epoch: 5| Step: 5
Training loss: 1.7963135878869319
Validation loss: 2.504215835845601

Epoch: 5| Step: 6
Training loss: 2.072897279990577
Validation loss: 2.5063232133771125

Epoch: 5| Step: 7
Training loss: 1.594056193539877
Validation loss: 2.499576425047461

Epoch: 5| Step: 8
Training loss: 2.320188165794926
Validation loss: 2.516421639867962

Epoch: 5| Step: 9
Training loss: 2.365500273748659
Validation loss: 2.504462437166152

Epoch: 5| Step: 10
Training loss: 2.0379643899803255
Validation loss: 2.5282690395793224

Epoch: 386| Step: 0
Training loss: 2.208130797209311
Validation loss: 2.547901132313714

Epoch: 5| Step: 1
Training loss: 2.4496737944196085
Validation loss: 2.522981675210098

Epoch: 5| Step: 2
Training loss: 1.882810663879259
Validation loss: 2.5625115891301338

Epoch: 5| Step: 3
Training loss: 2.074877158515874
Validation loss: 2.561338802369196

Epoch: 5| Step: 4
Training loss: 2.187914999696843
Validation loss: 2.5665150093651445

Epoch: 5| Step: 5
Training loss: 2.5463415418002273
Validation loss: 2.5539000239113934

Epoch: 5| Step: 6
Training loss: 1.9238908941417767
Validation loss: 2.552219493884324

Epoch: 5| Step: 7
Training loss: 2.34712779465242
Validation loss: 2.5762880932833143

Epoch: 5| Step: 8
Training loss: 1.9501776467613436
Validation loss: 2.5334066634853163

Epoch: 5| Step: 9
Training loss: 2.507651635830737
Validation loss: 2.527590093985136

Epoch: 5| Step: 10
Training loss: 1.8886850666267916
Validation loss: 2.533033880006901

Epoch: 387| Step: 0
Training loss: 1.5227178194174424
Validation loss: 2.506838481876586

Epoch: 5| Step: 1
Training loss: 2.362551842983538
Validation loss: 2.5027755363289548

Epoch: 5| Step: 2
Training loss: 2.8290407163050375
Validation loss: 2.4934276913163096

Epoch: 5| Step: 3
Training loss: 2.183835147623522
Validation loss: 2.4857320424538867

Epoch: 5| Step: 4
Training loss: 2.212544965556491
Validation loss: 2.4629853020192263

Epoch: 5| Step: 5
Training loss: 2.371847369167534
Validation loss: 2.469964519558272

Epoch: 5| Step: 6
Training loss: 1.9786360045976585
Validation loss: 2.486373455649777

Epoch: 5| Step: 7
Training loss: 2.179354296958703
Validation loss: 2.5093343004120183

Epoch: 5| Step: 8
Training loss: 2.061940088276772
Validation loss: 2.4890275955263377

Epoch: 5| Step: 9
Training loss: 2.3350108678593426
Validation loss: 2.5264394054790698

Epoch: 5| Step: 10
Training loss: 1.838079169206903
Validation loss: 2.557713969068045

Epoch: 388| Step: 0
Training loss: 1.7701491735927908
Validation loss: 2.557726491988151

Epoch: 5| Step: 1
Training loss: 2.478531593169109
Validation loss: 2.580501301758801

Epoch: 5| Step: 2
Training loss: 2.129772772869537
Validation loss: 2.548925440433751

Epoch: 5| Step: 3
Training loss: 1.696486387486574
Validation loss: 2.551582817401302

Epoch: 5| Step: 4
Training loss: 2.0408766119674846
Validation loss: 2.5477586163740327

Epoch: 5| Step: 5
Training loss: 2.5319911672308533
Validation loss: 2.5516367233757236

Epoch: 5| Step: 6
Training loss: 1.9455321161172718
Validation loss: 2.569648821314116

Epoch: 5| Step: 7
Training loss: 1.8836550271862658
Validation loss: 2.5516662072606158

Epoch: 5| Step: 8
Training loss: 2.6823811241466458
Validation loss: 2.554873846013309

Epoch: 5| Step: 9
Training loss: 2.275046077722761
Validation loss: 2.5278633986945525

Epoch: 5| Step: 10
Training loss: 2.5050184425086273
Validation loss: 2.515005577715818

Epoch: 389| Step: 0
Training loss: 2.6878656537792422
Validation loss: 2.51542105816516

Epoch: 5| Step: 1
Training loss: 1.6752162594467965
Validation loss: 2.5075192828727175

Epoch: 5| Step: 2
Training loss: 2.150351375876484
Validation loss: 2.5287144187193786

Epoch: 5| Step: 3
Training loss: 2.6818423490508074
Validation loss: 2.5274329067610597

Epoch: 5| Step: 4
Training loss: 2.41478750458954
Validation loss: 2.5576239864656163

Epoch: 5| Step: 5
Training loss: 2.3804012918757564
Validation loss: 2.574873748166843

Epoch: 5| Step: 6
Training loss: 1.8651273846523793
Validation loss: 2.606554247319183

Epoch: 5| Step: 7
Training loss: 2.4902879896189183
Validation loss: 2.5698000993133916

Epoch: 5| Step: 8
Training loss: 1.8585507785981548
Validation loss: 2.536965183701173

Epoch: 5| Step: 9
Training loss: 1.810469838697877
Validation loss: 2.5081643888975442

Epoch: 5| Step: 10
Training loss: 1.8059476605981204
Validation loss: 2.489020265170779

Epoch: 390| Step: 0
Training loss: 2.122124690110932
Validation loss: 2.4787726505821603

Epoch: 5| Step: 1
Training loss: 2.037122483179303
Validation loss: 2.4728409452370057

Epoch: 5| Step: 2
Training loss: 2.409553835870401
Validation loss: 2.452546199216973

Epoch: 5| Step: 3
Training loss: 2.0872964040185478
Validation loss: 2.467497273487561

Epoch: 5| Step: 4
Training loss: 2.4048374538253703
Validation loss: 2.470940208838569

Epoch: 5| Step: 5
Training loss: 2.306837004103449
Validation loss: 2.4888779369454554

Epoch: 5| Step: 6
Training loss: 2.107978188780083
Validation loss: 2.5005572677246852

Epoch: 5| Step: 7
Training loss: 2.364847669796677
Validation loss: 2.5320469087831197

Epoch: 5| Step: 8
Training loss: 1.9072879404406258
Validation loss: 2.50171393739886

Epoch: 5| Step: 9
Training loss: 2.0997175889627773
Validation loss: 2.5417565609430057

Epoch: 5| Step: 10
Training loss: 2.0941577343561124
Validation loss: 2.547231363770721

Epoch: 391| Step: 0
Training loss: 2.528965236764279
Validation loss: 2.545136807347077

Epoch: 5| Step: 1
Training loss: 2.10526717712621
Validation loss: 2.5592006829879224

Epoch: 5| Step: 2
Training loss: 1.4023338891322874
Validation loss: 2.5321948416055555

Epoch: 5| Step: 3
Training loss: 2.3056855707647803
Validation loss: 2.5423065205888618

Epoch: 5| Step: 4
Training loss: 2.1603030384264317
Validation loss: 2.5345548958773336

Epoch: 5| Step: 5
Training loss: 2.225153534124611
Validation loss: 2.4903093146980284

Epoch: 5| Step: 6
Training loss: 2.304935454915053
Validation loss: 2.5161581848244707

Epoch: 5| Step: 7
Training loss: 2.3850411420748383
Validation loss: 2.501633117867404

Epoch: 5| Step: 8
Training loss: 1.994465322335054
Validation loss: 2.529708454680428

Epoch: 5| Step: 9
Training loss: 2.5854875340202703
Validation loss: 2.5392190945203645

Epoch: 5| Step: 10
Training loss: 1.3293020081848343
Validation loss: 2.5365590617116007

Epoch: 392| Step: 0
Training loss: 2.0335952131549675
Validation loss: 2.552024694643443

Epoch: 5| Step: 1
Training loss: 1.8447000674298342
Validation loss: 2.5332656667811833

Epoch: 5| Step: 2
Training loss: 2.0742490949404626
Validation loss: 2.541411759417105

Epoch: 5| Step: 3
Training loss: 2.25391703955119
Validation loss: 2.518245049290259

Epoch: 5| Step: 4
Training loss: 2.5088738307983416
Validation loss: 2.518889925303757

Epoch: 5| Step: 5
Training loss: 2.283636229906592
Validation loss: 2.527505785025621

Epoch: 5| Step: 6
Training loss: 1.9245563813352817
Validation loss: 2.521170377424627

Epoch: 5| Step: 7
Training loss: 2.1005185168312086
Validation loss: 2.5029870543943202

Epoch: 5| Step: 8
Training loss: 2.31020571333534
Validation loss: 2.5222192966405124

Epoch: 5| Step: 9
Training loss: 2.2026314689896704
Validation loss: 2.550593242046166

Epoch: 5| Step: 10
Training loss: 2.179426498920479
Validation loss: 2.51155192074825

Epoch: 393| Step: 0
Training loss: 1.9330682830432966
Validation loss: 2.507562748011396

Epoch: 5| Step: 1
Training loss: 2.1455751529173726
Validation loss: 2.4787230232136874

Epoch: 5| Step: 2
Training loss: 2.561141980091596
Validation loss: 2.4963924918536793

Epoch: 5| Step: 3
Training loss: 2.1831339179642346
Validation loss: 2.4691081298078235

Epoch: 5| Step: 4
Training loss: 2.044348752101986
Validation loss: 2.45916928913561

Epoch: 5| Step: 5
Training loss: 2.1616974725148297
Validation loss: 2.442569231151369

Epoch: 5| Step: 6
Training loss: 1.872679418771433
Validation loss: 2.446462411764174

Epoch: 5| Step: 7
Training loss: 2.559264582859327
Validation loss: 2.459176455148999

Epoch: 5| Step: 8
Training loss: 1.9428746524690956
Validation loss: 2.483994216202418

Epoch: 5| Step: 9
Training loss: 2.3314359534504705
Validation loss: 2.51935293373161

Epoch: 5| Step: 10
Training loss: 1.9319110985712031
Validation loss: 2.54966777392252

Epoch: 394| Step: 0
Training loss: 1.6306513305269363
Validation loss: 2.6005980331577483

Epoch: 5| Step: 1
Training loss: 1.8344784397158966
Validation loss: 2.623396746686274

Epoch: 5| Step: 2
Training loss: 2.2285907274675174
Validation loss: 2.626780127563029

Epoch: 5| Step: 3
Training loss: 2.5358618649187536
Validation loss: 2.577115641094219

Epoch: 5| Step: 4
Training loss: 1.7384822429225182
Validation loss: 2.570769707349837

Epoch: 5| Step: 5
Training loss: 2.5475318857280804
Validation loss: 2.5583651297350563

Epoch: 5| Step: 6
Training loss: 2.3136885398149944
Validation loss: 2.5139060456010722

Epoch: 5| Step: 7
Training loss: 2.5800207393019674
Validation loss: 2.5048834757002516

Epoch: 5| Step: 8
Training loss: 2.2520787914511455
Validation loss: 2.485043393540228

Epoch: 5| Step: 9
Training loss: 2.1506732197161313
Validation loss: 2.50033060984673

Epoch: 5| Step: 10
Training loss: 1.6127968123156593
Validation loss: 2.4824880413643142

Epoch: 395| Step: 0
Training loss: 2.215216603592091
Validation loss: 2.4878437439790395

Epoch: 5| Step: 1
Training loss: 2.193355353089311
Validation loss: 2.493283551567323

Epoch: 5| Step: 2
Training loss: 2.359466955148761
Validation loss: 2.5255431126093604

Epoch: 5| Step: 3
Training loss: 2.0218617552333766
Validation loss: 2.5059518107193024

Epoch: 5| Step: 4
Training loss: 2.487335648211068
Validation loss: 2.5344476205424495

Epoch: 5| Step: 5
Training loss: 1.8187077861488128
Validation loss: 2.527789948599527

Epoch: 5| Step: 6
Training loss: 1.9477715939712987
Validation loss: 2.5315113365690105

Epoch: 5| Step: 7
Training loss: 2.0991119505245455
Validation loss: 2.5112702226566457

Epoch: 5| Step: 8
Training loss: 2.0676464260516263
Validation loss: 2.5302217927954698

Epoch: 5| Step: 9
Training loss: 2.4686443451110827
Validation loss: 2.512722617975993

Epoch: 5| Step: 10
Training loss: 1.7669146393740907
Validation loss: 2.496019502653371

Epoch: 396| Step: 0
Training loss: 1.7380851720741164
Validation loss: 2.509362997142481

Epoch: 5| Step: 1
Training loss: 1.9137093354432757
Validation loss: 2.49902977215882

Epoch: 5| Step: 2
Training loss: 2.307683413439508
Validation loss: 2.538565793860417

Epoch: 5| Step: 3
Training loss: 2.475912688772675
Validation loss: 2.560939326565303

Epoch: 5| Step: 4
Training loss: 2.1707981651029886
Validation loss: 2.5669657473699155

Epoch: 5| Step: 5
Training loss: 2.624015078373362
Validation loss: 2.5091097324895193

Epoch: 5| Step: 6
Training loss: 1.690567548695849
Validation loss: 2.480412737170586

Epoch: 5| Step: 7
Training loss: 2.33332837195096
Validation loss: 2.44358113182771

Epoch: 5| Step: 8
Training loss: 1.901670552226629
Validation loss: 2.4519935079653017

Epoch: 5| Step: 9
Training loss: 2.3980253281707307
Validation loss: 2.454206824987816

Epoch: 5| Step: 10
Training loss: 1.6063551486142826
Validation loss: 2.4852599316165316

Epoch: 397| Step: 0
Training loss: 2.06700866802227
Validation loss: 2.4812882561561707

Epoch: 5| Step: 1
Training loss: 1.72580401991419
Validation loss: 2.487822678054974

Epoch: 5| Step: 2
Training loss: 2.3140265091718693
Validation loss: 2.5335890863762374

Epoch: 5| Step: 3
Training loss: 2.181876010200662
Validation loss: 2.562841429175397

Epoch: 5| Step: 4
Training loss: 1.964871112488867
Validation loss: 2.57064932129746

Epoch: 5| Step: 5
Training loss: 1.8787542904254708
Validation loss: 2.5884351801085463

Epoch: 5| Step: 6
Training loss: 2.056273106036474
Validation loss: 2.5943551433106498

Epoch: 5| Step: 7
Training loss: 2.3944036004796154
Validation loss: 2.577366637519974

Epoch: 5| Step: 8
Training loss: 2.4504001329609397
Validation loss: 2.5608760671283317

Epoch: 5| Step: 9
Training loss: 2.246257424403314
Validation loss: 2.5260429173424055

Epoch: 5| Step: 10
Training loss: 2.008325770932386
Validation loss: 2.5562587428295083

Epoch: 398| Step: 0
Training loss: 2.225487914862266
Validation loss: 2.5217966205199622

Epoch: 5| Step: 1
Training loss: 1.7780809822735029
Validation loss: 2.521775906337184

Epoch: 5| Step: 2
Training loss: 2.510332784135058
Validation loss: 2.5231765931700645

Epoch: 5| Step: 3
Training loss: 1.524834720847909
Validation loss: 2.5277386385516083

Epoch: 5| Step: 4
Training loss: 2.0780568506066017
Validation loss: 2.488998693180026

Epoch: 5| Step: 5
Training loss: 1.6541714851571856
Validation loss: 2.491842701682643

Epoch: 5| Step: 6
Training loss: 2.1051190427341706
Validation loss: 2.476926887091294

Epoch: 5| Step: 7
Training loss: 1.7657601633914957
Validation loss: 2.5068566902518254

Epoch: 5| Step: 8
Training loss: 2.668948171078784
Validation loss: 2.51341839582288

Epoch: 5| Step: 9
Training loss: 2.361358314239141
Validation loss: 2.5533659892115947

Epoch: 5| Step: 10
Training loss: 2.3009301543827663
Validation loss: 2.5273921650189406

Epoch: 399| Step: 0
Training loss: 2.037332085553298
Validation loss: 2.5383330670071804

Epoch: 5| Step: 1
Training loss: 2.4354728681368356
Validation loss: 2.5089204431497

Epoch: 5| Step: 2
Training loss: 2.143325772586062
Validation loss: 2.507348797052602

Epoch: 5| Step: 3
Training loss: 2.1770123435193125
Validation loss: 2.4903155387248272

Epoch: 5| Step: 4
Training loss: 2.258647196825791
Validation loss: 2.4903654086154146

Epoch: 5| Step: 5
Training loss: 2.015203150880538
Validation loss: 2.4710298247551634

Epoch: 5| Step: 6
Training loss: 2.2037986645272234
Validation loss: 2.513113451770598

Epoch: 5| Step: 7
Training loss: 1.690223897289211
Validation loss: 2.5126819274744023

Epoch: 5| Step: 8
Training loss: 1.550762877847918
Validation loss: 2.5188240958446855

Epoch: 5| Step: 9
Training loss: 2.149075500085076
Validation loss: 2.513350505947537

Epoch: 5| Step: 10
Training loss: 2.4081531281243045
Validation loss: 2.5322189259122005

Epoch: 400| Step: 0
Training loss: 2.4087905353011796
Validation loss: 2.5230400889783064

Epoch: 5| Step: 1
Training loss: 1.367256816741696
Validation loss: 2.5385258670271296

Epoch: 5| Step: 2
Training loss: 1.5590071739340026
Validation loss: 2.5312726115892095

Epoch: 5| Step: 3
Training loss: 1.9613741810216927
Validation loss: 2.519089812730399

Epoch: 5| Step: 4
Training loss: 2.456167775881776
Validation loss: 2.515721794074608

Epoch: 5| Step: 5
Training loss: 2.496573006673133
Validation loss: 2.526394749076886

Epoch: 5| Step: 6
Training loss: 2.09873903200102
Validation loss: 2.5359821150900106

Epoch: 5| Step: 7
Training loss: 2.118854724917779
Validation loss: 2.5706152178054786

Epoch: 5| Step: 8
Training loss: 1.962723667009429
Validation loss: 2.5717427837067572

Epoch: 5| Step: 9
Training loss: 2.4736705947321838
Validation loss: 2.5616551904233598

Epoch: 5| Step: 10
Training loss: 2.1393139019197873
Validation loss: 2.5182069809130163

Testing loss: 2.682376729363317
