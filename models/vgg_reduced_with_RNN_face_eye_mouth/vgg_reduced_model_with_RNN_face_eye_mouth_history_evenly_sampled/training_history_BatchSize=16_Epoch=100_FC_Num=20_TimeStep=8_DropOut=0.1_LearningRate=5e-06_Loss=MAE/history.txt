Epoch: 1| Step: 0
Training loss: 4.847557067871094
Validation loss: 5.190636173371346

Epoch: 6| Step: 1
Training loss: 5.61607027053833
Validation loss: 5.1847983842254965

Epoch: 6| Step: 2
Training loss: 5.843017578125
Validation loss: 5.178906774008146

Epoch: 6| Step: 3
Training loss: 5.954086780548096
Validation loss: 5.172820327102497

Epoch: 6| Step: 4
Training loss: 4.7026166915893555
Validation loss: 5.166616075782366

Epoch: 6| Step: 5
Training loss: 5.438946723937988
Validation loss: 5.160205205281575

Epoch: 6| Step: 6
Training loss: 5.728084564208984
Validation loss: 5.1541289770475

Epoch: 6| Step: 7
Training loss: 3.813707113265991
Validation loss: 5.147679672446302

Epoch: 6| Step: 8
Training loss: 4.501143455505371
Validation loss: 5.141067366446218

Epoch: 6| Step: 9
Training loss: 3.3176426887512207
Validation loss: 5.134521812521001

Epoch: 6| Step: 10
Training loss: 3.852365016937256
Validation loss: 5.127474292632072

Epoch: 6| Step: 11
Training loss: 4.763459205627441
Validation loss: 5.120635970946281

Epoch: 6| Step: 12
Training loss: 5.920094966888428
Validation loss: 5.11301488261069

Epoch: 6| Step: 13
Training loss: 4.954934120178223
Validation loss: 5.105647322952106

Epoch: 2| Step: 0
Training loss: 4.874550819396973
Validation loss: 5.097885224127

Epoch: 6| Step: 1
Training loss: 5.5310139656066895
Validation loss: 5.089415632268434

Epoch: 6| Step: 2
Training loss: 3.679532051086426
Validation loss: 5.080560730349633

Epoch: 6| Step: 3
Training loss: 5.928804874420166
Validation loss: 5.071789346715455

Epoch: 6| Step: 4
Training loss: 4.265789985656738
Validation loss: 5.0628186400218675

Epoch: 6| Step: 5
Training loss: 4.877547264099121
Validation loss: 5.053016601070281

Epoch: 6| Step: 6
Training loss: 4.434525489807129
Validation loss: 5.042690256590484

Epoch: 6| Step: 7
Training loss: 4.929843902587891
Validation loss: 5.032874138124527

Epoch: 6| Step: 8
Training loss: 5.557415962219238
Validation loss: 5.021906473303354

Epoch: 6| Step: 9
Training loss: 4.349809646606445
Validation loss: 5.010181416747391

Epoch: 6| Step: 10
Training loss: 5.134608268737793
Validation loss: 4.9982014420211955

Epoch: 6| Step: 11
Training loss: 4.53572940826416
Validation loss: 4.9856599274502

Epoch: 6| Step: 12
Training loss: 4.925873279571533
Validation loss: 4.972622958562708

Epoch: 6| Step: 13
Training loss: 4.449957847595215
Validation loss: 4.959371033535208

Epoch: 3| Step: 0
Training loss: 5.939098358154297
Validation loss: 4.945634144608692

Epoch: 6| Step: 1
Training loss: 3.7201344966888428
Validation loss: 4.9314358516405985

Epoch: 6| Step: 2
Training loss: 3.817776918411255
Validation loss: 4.916822402707992

Epoch: 6| Step: 3
Training loss: 5.606629371643066
Validation loss: 4.901620459812944

Epoch: 6| Step: 4
Training loss: 4.041893482208252
Validation loss: 4.885514510575161

Epoch: 6| Step: 5
Training loss: 5.284196853637695
Validation loss: 4.867725772242392

Epoch: 6| Step: 6
Training loss: 5.132538795471191
Validation loss: 4.851401123949277

Epoch: 6| Step: 7
Training loss: 3.952801465988159
Validation loss: 4.832939855514034

Epoch: 6| Step: 8
Training loss: 5.833001613616943
Validation loss: 4.815552721741379

Epoch: 6| Step: 9
Training loss: 4.408788681030273
Validation loss: 4.794782397567585

Epoch: 6| Step: 10
Training loss: 4.64635705947876
Validation loss: 4.77500384341004

Epoch: 6| Step: 11
Training loss: 4.840388298034668
Validation loss: 4.75583287464675

Epoch: 6| Step: 12
Training loss: 3.2901577949523926
Validation loss: 4.73464169297167

Epoch: 6| Step: 13
Training loss: 4.080126762390137
Validation loss: 4.713930545314666

Epoch: 4| Step: 0
Training loss: 4.2623701095581055
Validation loss: 4.693117613433509

Epoch: 6| Step: 1
Training loss: 3.9723241329193115
Validation loss: 4.671569152544904

Epoch: 6| Step: 2
Training loss: 5.320190906524658
Validation loss: 4.650912069505261

Epoch: 6| Step: 3
Training loss: 4.554622173309326
Validation loss: 4.627564096963534

Epoch: 6| Step: 4
Training loss: 4.1239447593688965
Validation loss: 4.604447303279754

Epoch: 6| Step: 5
Training loss: 2.9277143478393555
Validation loss: 4.581516568378736

Epoch: 6| Step: 6
Training loss: 4.283388137817383
Validation loss: 4.557444269939135

Epoch: 6| Step: 7
Training loss: 3.2883658409118652
Validation loss: 4.5342699584140576

Epoch: 6| Step: 8
Training loss: 3.7944834232330322
Validation loss: 4.511131868567518

Epoch: 6| Step: 9
Training loss: 5.491859436035156
Validation loss: 4.487452435237105

Epoch: 6| Step: 10
Training loss: 5.587619304656982
Validation loss: 4.46526728394211

Epoch: 6| Step: 11
Training loss: 4.247062683105469
Validation loss: 4.439588182715959

Epoch: 6| Step: 12
Training loss: 5.088092803955078
Validation loss: 4.416918405922511

Epoch: 6| Step: 13
Training loss: 3.297821521759033
Validation loss: 4.3938395310473695

Epoch: 5| Step: 0
Training loss: 3.9882352352142334
Validation loss: 4.374153439716626

Epoch: 6| Step: 1
Training loss: 3.5704121589660645
Validation loss: 4.353517234966319

Epoch: 6| Step: 2
Training loss: 3.3951544761657715
Validation loss: 4.331555745934927

Epoch: 6| Step: 3
Training loss: 4.179606914520264
Validation loss: 4.3123269234934165

Epoch: 6| Step: 4
Training loss: 5.078060626983643
Validation loss: 4.293328367253785

Epoch: 6| Step: 5
Training loss: 4.451865196228027
Validation loss: 4.273093926009311

Epoch: 6| Step: 6
Training loss: 3.564138412475586
Validation loss: 4.252339373352707

Epoch: 6| Step: 7
Training loss: 4.174192428588867
Validation loss: 4.23526987465479

Epoch: 6| Step: 8
Training loss: 3.107459545135498
Validation loss: 4.21698554613257

Epoch: 6| Step: 9
Training loss: 4.199644088745117
Validation loss: 4.202052167666856

Epoch: 6| Step: 10
Training loss: 3.86334228515625
Validation loss: 4.183575204623643

Epoch: 6| Step: 11
Training loss: 4.640614986419678
Validation loss: 4.166532901025588

Epoch: 6| Step: 12
Training loss: 5.267875671386719
Validation loss: 4.151398710025254

Epoch: 6| Step: 13
Training loss: 2.7530925273895264
Validation loss: 4.13500698151127

Epoch: 6| Step: 0
Training loss: 4.127732753753662
Validation loss: 4.119137907540926

Epoch: 6| Step: 1
Training loss: 3.7826762199401855
Validation loss: 4.104457242514497

Epoch: 6| Step: 2
Training loss: 3.9298582077026367
Validation loss: 4.091291107157225

Epoch: 6| Step: 3
Training loss: 3.5287022590637207
Validation loss: 4.076161605055614

Epoch: 6| Step: 4
Training loss: 3.996671676635742
Validation loss: 4.061649907019831

Epoch: 6| Step: 5
Training loss: 4.0739641189575195
Validation loss: 4.047807406353694

Epoch: 6| Step: 6
Training loss: 2.9561290740966797
Validation loss: 4.034900285864389

Epoch: 6| Step: 7
Training loss: 4.750126361846924
Validation loss: 4.020712673023183

Epoch: 6| Step: 8
Training loss: 4.3292927742004395
Validation loss: 4.008932308484149

Epoch: 6| Step: 9
Training loss: 4.0665082931518555
Validation loss: 3.994701272697859

Epoch: 6| Step: 10
Training loss: 3.4923059940338135
Validation loss: 3.9821379928178686

Epoch: 6| Step: 11
Training loss: 2.960944652557373
Validation loss: 3.968467991839173

Epoch: 6| Step: 12
Training loss: 4.016765594482422
Validation loss: 3.9565276740699686

Epoch: 6| Step: 13
Training loss: 4.510039806365967
Validation loss: 3.9433726290220856

Epoch: 7| Step: 0
Training loss: 2.773484706878662
Validation loss: 3.931230798844368

Epoch: 6| Step: 1
Training loss: 3.1339147090911865
Validation loss: 3.918659035877515

Epoch: 6| Step: 2
Training loss: 3.6561901569366455
Validation loss: 3.9063007190663326

Epoch: 6| Step: 3
Training loss: 3.4993014335632324
Validation loss: 3.895434912814889

Epoch: 6| Step: 4
Training loss: 4.031472206115723
Validation loss: 3.8827980692668627

Epoch: 6| Step: 5
Training loss: 4.652681350708008
Validation loss: 3.871687686571511

Epoch: 6| Step: 6
Training loss: 4.216793537139893
Validation loss: 3.857556507151614

Epoch: 6| Step: 7
Training loss: 2.9436936378479004
Validation loss: 3.8462208881173083

Epoch: 6| Step: 8
Training loss: 4.119136333465576
Validation loss: 3.8334926917988765

Epoch: 6| Step: 9
Training loss: 3.8069002628326416
Validation loss: 3.8205188243619856

Epoch: 6| Step: 10
Training loss: 4.127853870391846
Validation loss: 3.8071674582778767

Epoch: 6| Step: 11
Training loss: 4.5308427810668945
Validation loss: 3.7932874464219615

Epoch: 6| Step: 12
Training loss: 4.164435863494873
Validation loss: 3.7781930687606975

Epoch: 6| Step: 13
Training loss: 1.6632660627365112
Validation loss: 3.7643010795757337

Epoch: 8| Step: 0
Training loss: 3.5598278045654297
Validation loss: 3.7494067222841325

Epoch: 6| Step: 1
Training loss: 3.2724459171295166
Validation loss: 3.7353903221827682

Epoch: 6| Step: 2
Training loss: 3.9812965393066406
Validation loss: 3.720738036658174

Epoch: 6| Step: 3
Training loss: 3.3687615394592285
Validation loss: 3.7059531570762716

Epoch: 6| Step: 4
Training loss: 3.5763139724731445
Validation loss: 3.693281186524258

Epoch: 6| Step: 5
Training loss: 3.411499261856079
Validation loss: 3.6797013795504006

Epoch: 6| Step: 6
Training loss: 3.408099412918091
Validation loss: 3.6680047768418507

Epoch: 6| Step: 7
Training loss: 2.979346752166748
Validation loss: 3.656790510300667

Epoch: 6| Step: 8
Training loss: 3.1320676803588867
Validation loss: 3.646853800742857

Epoch: 6| Step: 9
Training loss: 4.823085784912109
Validation loss: 3.636833055045015

Epoch: 6| Step: 10
Training loss: 4.265071868896484
Validation loss: 3.6291424997391237

Epoch: 6| Step: 11
Training loss: 3.624603748321533
Validation loss: 3.617614471784202

Epoch: 6| Step: 12
Training loss: 3.946357011795044
Validation loss: 3.6078771237404115

Epoch: 6| Step: 13
Training loss: 1.9101706743240356
Validation loss: 3.597740475849439

Epoch: 9| Step: 0
Training loss: 3.7176637649536133
Validation loss: 3.588668318204982

Epoch: 6| Step: 1
Training loss: 3.2006542682647705
Validation loss: 3.5800546292335755

Epoch: 6| Step: 2
Training loss: 3.282750129699707
Validation loss: 3.5711395612327

Epoch: 6| Step: 3
Training loss: 3.233405351638794
Validation loss: 3.565081496392527

Epoch: 6| Step: 4
Training loss: 2.640265464782715
Validation loss: 3.5557847920284478

Epoch: 6| Step: 5
Training loss: 2.5642974376678467
Validation loss: 3.5505378348853

Epoch: 6| Step: 6
Training loss: 3.643662452697754
Validation loss: 3.5398539753370386

Epoch: 6| Step: 7
Training loss: 2.380239486694336
Validation loss: 3.535915128646358

Epoch: 6| Step: 8
Training loss: 4.541708469390869
Validation loss: 3.5295024328334357

Epoch: 6| Step: 9
Training loss: 3.1515650749206543
Validation loss: 3.526020106448922

Epoch: 6| Step: 10
Training loss: 4.437487602233887
Validation loss: 3.519481038534513

Epoch: 6| Step: 11
Training loss: 3.662814140319824
Validation loss: 3.511788906589631

Epoch: 6| Step: 12
Training loss: 3.847980499267578
Validation loss: 3.5056566730622323

Epoch: 6| Step: 13
Training loss: 4.795309066772461
Validation loss: 3.4997921400172736

Epoch: 10| Step: 0
Training loss: 2.886408805847168
Validation loss: 3.4920223195065736

Epoch: 6| Step: 1
Training loss: 3.51749849319458
Validation loss: 3.488251814278223

Epoch: 6| Step: 2
Training loss: 3.85882306098938
Validation loss: 3.481732742760771

Epoch: 6| Step: 3
Training loss: 4.179572105407715
Validation loss: 3.47858093630883

Epoch: 6| Step: 4
Training loss: 3.6061506271362305
Validation loss: 3.472117026646932

Epoch: 6| Step: 5
Training loss: 2.104710817337036
Validation loss: 3.466751916434175

Epoch: 6| Step: 6
Training loss: 4.086129188537598
Validation loss: 3.4603401768592095

Epoch: 6| Step: 7
Training loss: 3.175440788269043
Validation loss: 3.455873591925508

Epoch: 6| Step: 8
Training loss: 3.4401838779449463
Validation loss: 3.4506342795587357

Epoch: 6| Step: 9
Training loss: 3.6125335693359375
Validation loss: 3.447195978574855

Epoch: 6| Step: 10
Training loss: 3.152778387069702
Validation loss: 3.4400891027142926

Epoch: 6| Step: 11
Training loss: 3.283778667449951
Validation loss: 3.436936639970349

Epoch: 6| Step: 12
Training loss: 3.6832690238952637
Validation loss: 3.433187207868022

Epoch: 6| Step: 13
Training loss: 2.7174386978149414
Validation loss: 3.4289055819152505

Epoch: 11| Step: 0
Training loss: 4.124727725982666
Validation loss: 3.424864694636355

Epoch: 6| Step: 1
Training loss: 3.9293718338012695
Validation loss: 3.422395219085037

Epoch: 6| Step: 2
Training loss: 4.654391288757324
Validation loss: 3.4185708492032942

Epoch: 6| Step: 3
Training loss: 3.498016357421875
Validation loss: 3.4123859713154454

Epoch: 6| Step: 4
Training loss: 2.620192766189575
Validation loss: 3.411063906966999

Epoch: 6| Step: 5
Training loss: 2.9116969108581543
Validation loss: 3.4058663486152567

Epoch: 6| Step: 6
Training loss: 2.8168437480926514
Validation loss: 3.4014500443653395

Epoch: 6| Step: 7
Training loss: 2.974959373474121
Validation loss: 3.398411850775442

Epoch: 6| Step: 8
Training loss: 3.1717677116394043
Validation loss: 3.396462014926377

Epoch: 6| Step: 9
Training loss: 2.801273822784424
Validation loss: 3.3949699427491877

Epoch: 6| Step: 10
Training loss: 4.254864692687988
Validation loss: 3.3866080417427966

Epoch: 6| Step: 11
Training loss: 2.95186710357666
Validation loss: 3.385207171081215

Epoch: 6| Step: 12
Training loss: 3.091639995574951
Validation loss: 3.3827148714373187

Epoch: 6| Step: 13
Training loss: 3.0462398529052734
Validation loss: 3.3815327844312115

Epoch: 12| Step: 0
Training loss: 3.620178699493408
Validation loss: 3.3775784200237644

Epoch: 6| Step: 1
Training loss: 4.811123847961426
Validation loss: 3.374373984593217

Epoch: 6| Step: 2
Training loss: 3.0261621475219727
Validation loss: 3.3713728509923464

Epoch: 6| Step: 3
Training loss: 3.175689220428467
Validation loss: 3.368284789464807

Epoch: 6| Step: 4
Training loss: 3.434419870376587
Validation loss: 3.364522011049332

Epoch: 6| Step: 5
Training loss: 2.990086793899536
Validation loss: 3.3618998373708417

Epoch: 6| Step: 6
Training loss: 3.42887544631958
Validation loss: 3.357693592707316

Epoch: 6| Step: 7
Training loss: 2.748415946960449
Validation loss: 3.35619673421306

Epoch: 6| Step: 8
Training loss: 2.4792628288269043
Validation loss: 3.3538988944022887

Epoch: 6| Step: 9
Training loss: 3.247474431991577
Validation loss: 3.348421658239057

Epoch: 6| Step: 10
Training loss: 3.6918513774871826
Validation loss: 3.3490998565509753

Epoch: 6| Step: 11
Training loss: 3.9097723960876465
Validation loss: 3.343614614138039

Epoch: 6| Step: 12
Training loss: 2.784834384918213
Validation loss: 3.341919555458971

Epoch: 6| Step: 13
Training loss: 2.9252195358276367
Validation loss: 3.3378083757174912

Epoch: 13| Step: 0
Training loss: 3.305044651031494
Validation loss: 3.337061292381697

Epoch: 6| Step: 1
Training loss: 3.187760353088379
Validation loss: 3.331951464376142

Epoch: 6| Step: 2
Training loss: 2.590386390686035
Validation loss: 3.329717807872321

Epoch: 6| Step: 3
Training loss: 2.7588307857513428
Validation loss: 3.327003179057952

Epoch: 6| Step: 4
Training loss: 3.79937744140625
Validation loss: 3.3264650837067635

Epoch: 6| Step: 5
Training loss: 2.679471492767334
Validation loss: 3.322121089504611

Epoch: 6| Step: 6
Training loss: 2.7273755073547363
Validation loss: 3.3190976240301646

Epoch: 6| Step: 7
Training loss: 3.024205446243286
Validation loss: 3.3157413005828857

Epoch: 6| Step: 8
Training loss: 2.652639627456665
Validation loss: 3.3143117607280774

Epoch: 6| Step: 9
Training loss: 3.6623287200927734
Validation loss: 3.3103696735956336

Epoch: 6| Step: 10
Training loss: 2.9197192192077637
Validation loss: 3.3083019025864138

Epoch: 6| Step: 11
Training loss: 4.086067199707031
Validation loss: 3.305377839713968

Epoch: 6| Step: 12
Training loss: 4.996747016906738
Validation loss: 3.3031450240842757

Epoch: 6| Step: 13
Training loss: 3.7884984016418457
Validation loss: 3.299954498967817

Epoch: 14| Step: 0
Training loss: 3.8168082237243652
Validation loss: 3.2962566575696393

Epoch: 6| Step: 1
Training loss: 3.0749335289001465
Validation loss: 3.2941717614409742

Epoch: 6| Step: 2
Training loss: 3.9181067943573
Validation loss: 3.2906876584535003

Epoch: 6| Step: 3
Training loss: 3.4214272499084473
Validation loss: 3.287287789006387

Epoch: 6| Step: 4
Training loss: 3.045170307159424
Validation loss: 3.282555293011409

Epoch: 6| Step: 5
Training loss: 2.8507027626037598
Validation loss: 3.281842536823724

Epoch: 6| Step: 6
Training loss: 2.8310303688049316
Validation loss: 3.2775272579603296

Epoch: 6| Step: 7
Training loss: 2.928988218307495
Validation loss: 3.2754795269299577

Epoch: 6| Step: 8
Training loss: 2.6147148609161377
Validation loss: 3.2716733922240553

Epoch: 6| Step: 9
Training loss: 3.4328694343566895
Validation loss: 3.2682311637427217

Epoch: 6| Step: 10
Training loss: 3.6286439895629883
Validation loss: 3.2659411994359826

Epoch: 6| Step: 11
Training loss: 2.6293692588806152
Validation loss: 3.2636234734648015

Epoch: 6| Step: 12
Training loss: 3.5148732662200928
Validation loss: 3.259357588265532

Epoch: 6| Step: 13
Training loss: 4.318897247314453
Validation loss: 3.2549975431093605

Epoch: 15| Step: 0
Training loss: 3.9786760807037354
Validation loss: 3.2555579164976716

Epoch: 6| Step: 1
Training loss: 2.91009521484375
Validation loss: 3.2519866420376684

Epoch: 6| Step: 2
Training loss: 3.4001519680023193
Validation loss: 3.250350083074262

Epoch: 6| Step: 3
Training loss: 2.080648899078369
Validation loss: 3.2452951554329164

Epoch: 6| Step: 4
Training loss: 3.867616891860962
Validation loss: 3.2421495094094226

Epoch: 6| Step: 5
Training loss: 3.551144599914551
Validation loss: 3.238100803026589

Epoch: 6| Step: 6
Training loss: 3.000088930130005
Validation loss: 3.2346699186550674

Epoch: 6| Step: 7
Training loss: 3.288792610168457
Validation loss: 3.231508690823791

Epoch: 6| Step: 8
Training loss: 2.985090494155884
Validation loss: 3.227503735532043

Epoch: 6| Step: 9
Training loss: 3.828648090362549
Validation loss: 3.2248340627198577

Epoch: 6| Step: 10
Training loss: 2.6964523792266846
Validation loss: 3.2192884106789865

Epoch: 6| Step: 11
Training loss: 3.733525037765503
Validation loss: 3.2163982724630706

Epoch: 6| Step: 12
Training loss: 3.355240821838379
Validation loss: 3.212840998044578

Epoch: 6| Step: 13
Training loss: 1.8033959865570068
Validation loss: 3.2090354709215063

Epoch: 16| Step: 0
Training loss: 3.1916871070861816
Validation loss: 3.2086231118889263

Epoch: 6| Step: 1
Training loss: 3.2429580688476562
Validation loss: 3.2038669073453514

Epoch: 6| Step: 2
Training loss: 2.8127031326293945
Validation loss: 3.1995481368034118

Epoch: 6| Step: 3
Training loss: 3.847376823425293
Validation loss: 3.199354592189994

Epoch: 6| Step: 4
Training loss: 1.8933721780776978
Validation loss: 3.1958163579305015

Epoch: 6| Step: 5
Training loss: 3.057533025741577
Validation loss: 3.190124334827546

Epoch: 6| Step: 6
Training loss: 3.3184242248535156
Validation loss: 3.1886932619156374

Epoch: 6| Step: 7
Training loss: 3.2474656105041504
Validation loss: 3.185067499837568

Epoch: 6| Step: 8
Training loss: 2.501756191253662
Validation loss: 3.1862067714814217

Epoch: 6| Step: 9
Training loss: 4.367622375488281
Validation loss: 3.1808487189713346

Epoch: 6| Step: 10
Training loss: 3.472865581512451
Validation loss: 3.180395257088446

Epoch: 6| Step: 11
Training loss: 2.5115413665771484
Validation loss: 3.173628140521306

Epoch: 6| Step: 12
Training loss: 4.061046600341797
Validation loss: 3.1719209353129068

Epoch: 6| Step: 13
Training loss: 3.060529947280884
Validation loss: 3.1694447507140455

Epoch: 17| Step: 0
Training loss: 2.5233163833618164
Validation loss: 3.1656254645316833

Epoch: 6| Step: 1
Training loss: 3.210069179534912
Validation loss: 3.1597511050521687

Epoch: 6| Step: 2
Training loss: 4.265399932861328
Validation loss: 3.1577662191083355

Epoch: 6| Step: 3
Training loss: 1.8265070915222168
Validation loss: 3.1567322054216937

Epoch: 6| Step: 4
Training loss: 3.3458776473999023
Validation loss: 3.152318413539599

Epoch: 6| Step: 5
Training loss: 3.123286485671997
Validation loss: 3.1468884996188584

Epoch: 6| Step: 6
Training loss: 3.5898211002349854
Validation loss: 3.145241904002364

Epoch: 6| Step: 7
Training loss: 3.377673625946045
Validation loss: 3.142177633059922

Epoch: 6| Step: 8
Training loss: 3.591017961502075
Validation loss: 3.1373854606382308

Epoch: 6| Step: 9
Training loss: 2.4193637371063232
Validation loss: 3.1392398982919674

Epoch: 6| Step: 10
Training loss: 3.0248963832855225
Validation loss: 3.137056496835524

Epoch: 6| Step: 11
Training loss: 2.6604981422424316
Validation loss: 3.135335337731146

Epoch: 6| Step: 12
Training loss: 4.2758870124816895
Validation loss: 3.133595440977363

Epoch: 6| Step: 13
Training loss: 2.7883822917938232
Validation loss: 3.1296829305669314

Epoch: 18| Step: 0
Training loss: 3.3899948596954346
Validation loss: 3.1242365298732633

Epoch: 6| Step: 1
Training loss: 3.3651676177978516
Validation loss: 3.1204883872821765

Epoch: 6| Step: 2
Training loss: 4.165360450744629
Validation loss: 3.118102983761859

Epoch: 6| Step: 3
Training loss: 3.502915143966675
Validation loss: 3.116929828479726

Epoch: 6| Step: 4
Training loss: 2.6420514583587646
Validation loss: 3.108403262271676

Epoch: 6| Step: 5
Training loss: 3.3755576610565186
Validation loss: 3.109551014438752

Epoch: 6| Step: 6
Training loss: 3.621631383895874
Validation loss: 3.104645270173268

Epoch: 6| Step: 7
Training loss: 2.9053564071655273
Validation loss: 3.105941649406187

Epoch: 6| Step: 8
Training loss: 3.204455852508545
Validation loss: 3.104116719256165

Epoch: 6| Step: 9
Training loss: 2.4016494750976562
Validation loss: 3.1067646241957143

Epoch: 6| Step: 10
Training loss: 2.47422456741333
Validation loss: 3.111109305453557

Epoch: 6| Step: 11
Training loss: 2.870378255844116
Validation loss: 3.1041288016944804

Epoch: 6| Step: 12
Training loss: 2.669208288192749
Validation loss: 3.104924363474692

Epoch: 6| Step: 13
Training loss: 3.360391139984131
Validation loss: 3.0905081969435497

Epoch: 19| Step: 0
Training loss: 3.1369376182556152
Validation loss: 3.091109691127654

Epoch: 6| Step: 1
Training loss: 3.0308775901794434
Validation loss: 3.0842680828545683

Epoch: 6| Step: 2
Training loss: 3.6183953285217285
Validation loss: 3.084531222620318

Epoch: 6| Step: 3
Training loss: 3.5432543754577637
Validation loss: 3.0785763725157707

Epoch: 6| Step: 4
Training loss: 3.1169819831848145
Validation loss: 3.0812470784751316

Epoch: 6| Step: 5
Training loss: 3.3014230728149414
Validation loss: 3.0738465221979285

Epoch: 6| Step: 6
Training loss: 2.8906054496765137
Validation loss: 3.0720386197490077

Epoch: 6| Step: 7
Training loss: 4.453220367431641
Validation loss: 3.0665946340048187

Epoch: 6| Step: 8
Training loss: 2.6304502487182617
Validation loss: 3.0652038922873874

Epoch: 6| Step: 9
Training loss: 3.7486093044281006
Validation loss: 3.0627803392307733

Epoch: 6| Step: 10
Training loss: 2.5487117767333984
Validation loss: 3.0604481799628145

Epoch: 6| Step: 11
Training loss: 2.6740469932556152
Validation loss: 3.059228274130052

Epoch: 6| Step: 12
Training loss: 2.0086090564727783
Validation loss: 3.0607422295437066

Epoch: 6| Step: 13
Training loss: 2.609368324279785
Validation loss: 3.0552525699779554

Epoch: 20| Step: 0
Training loss: 2.632584571838379
Validation loss: 3.0614360378634546

Epoch: 6| Step: 1
Training loss: 2.9360885620117188
Validation loss: 3.0612849830299296

Epoch: 6| Step: 2
Training loss: 2.9915826320648193
Validation loss: 3.0593795289275465

Epoch: 6| Step: 3
Training loss: 3.426588773727417
Validation loss: 3.0496428961394937

Epoch: 6| Step: 4
Training loss: 3.087576150894165
Validation loss: 3.046742513615598

Epoch: 6| Step: 5
Training loss: 3.878568172454834
Validation loss: 3.0399445103060816

Epoch: 6| Step: 6
Training loss: 2.803913116455078
Validation loss: 3.0338027836174093

Epoch: 6| Step: 7
Training loss: 3.6197454929351807
Validation loss: 3.0315628820850002

Epoch: 6| Step: 8
Training loss: 2.3313074111938477
Validation loss: 3.0316526735982587

Epoch: 6| Step: 9
Training loss: 3.2793054580688477
Validation loss: 3.024929182503813

Epoch: 6| Step: 10
Training loss: 3.083588123321533
Validation loss: 3.0260475040763937

Epoch: 6| Step: 11
Training loss: 3.091639995574951
Validation loss: 3.0211216352319203

Epoch: 6| Step: 12
Training loss: 3.2552318572998047
Validation loss: 3.019472896411855

Epoch: 6| Step: 13
Training loss: 2.4983479976654053
Validation loss: 3.0150561512157483

Epoch: 21| Step: 0
Training loss: 2.9404196739196777
Validation loss: 3.0168083098626908

Epoch: 6| Step: 1
Training loss: 3.170863628387451
Validation loss: 3.0143491401467273

Epoch: 6| Step: 2
Training loss: 2.8684592247009277
Validation loss: 3.016096476585634

Epoch: 6| Step: 3
Training loss: 3.3494529724121094
Validation loss: 3.0119294453692693

Epoch: 6| Step: 4
Training loss: 2.2701456546783447
Validation loss: 3.0036890224743913

Epoch: 6| Step: 5
Training loss: 3.5637948513031006
Validation loss: 3.0065606973504506

Epoch: 6| Step: 6
Training loss: 2.958763360977173
Validation loss: 3.0030815908985753

Epoch: 6| Step: 7
Training loss: 3.9727396965026855
Validation loss: 3.0043432584372898

Epoch: 6| Step: 8
Training loss: 3.403903007507324
Validation loss: 2.994552009849138

Epoch: 6| Step: 9
Training loss: 3.209811210632324
Validation loss: 2.9876058563109367

Epoch: 6| Step: 10
Training loss: 3.2789764404296875
Validation loss: 2.9840891002326884

Epoch: 6| Step: 11
Training loss: 3.164445400238037
Validation loss: 2.9871978605947187

Epoch: 6| Step: 12
Training loss: 2.1904537677764893
Validation loss: 2.9902705377148044

Epoch: 6| Step: 13
Training loss: 2.0413424968719482
Validation loss: 3.0070380651822655

Epoch: 22| Step: 0
Training loss: 2.674725294113159
Validation loss: 3.003269454484345

Epoch: 6| Step: 1
Training loss: 2.439462184906006
Validation loss: 2.994174003601074

Epoch: 6| Step: 2
Training loss: 3.573812484741211
Validation loss: 2.9871998499798518

Epoch: 6| Step: 3
Training loss: 3.0614516735076904
Validation loss: 2.976288631398191

Epoch: 6| Step: 4
Training loss: 3.206367015838623
Validation loss: 2.9825067366323164

Epoch: 6| Step: 5
Training loss: 2.477795362472534
Validation loss: 2.9812632786330355

Epoch: 6| Step: 6
Training loss: 2.365074634552002
Validation loss: 2.992166590946977

Epoch: 6| Step: 7
Training loss: 3.729100227355957
Validation loss: 2.9916152236282185

Epoch: 6| Step: 8
Training loss: 4.202665328979492
Validation loss: 2.9792494132954586

Epoch: 6| Step: 9
Training loss: 2.87394118309021
Validation loss: 2.973068816687471

Epoch: 6| Step: 10
Training loss: 2.932671070098877
Validation loss: 2.969647148604034

Epoch: 6| Step: 11
Training loss: 2.6723275184631348
Validation loss: 2.9650070026356685

Epoch: 6| Step: 12
Training loss: 3.2558343410491943
Validation loss: 2.963937210780318

Epoch: 6| Step: 13
Training loss: 3.2144923210144043
Validation loss: 2.961829108576621

Epoch: 23| Step: 0
Training loss: 3.0653281211853027
Validation loss: 2.955635675819971

Epoch: 6| Step: 1
Training loss: 3.3316283226013184
Validation loss: 2.957722851025161

Epoch: 6| Step: 2
Training loss: 2.9970920085906982
Validation loss: 2.9547435032424105

Epoch: 6| Step: 3
Training loss: 3.0412545204162598
Validation loss: 2.953219857267154

Epoch: 6| Step: 4
Training loss: 1.8209795951843262
Validation loss: 2.9510533578934206

Epoch: 6| Step: 5
Training loss: 2.7302746772766113
Validation loss: 2.9526287612094673

Epoch: 6| Step: 6
Training loss: 3.5332846641540527
Validation loss: 2.94774809704032

Epoch: 6| Step: 7
Training loss: 4.038804054260254
Validation loss: 2.9443302359632266

Epoch: 6| Step: 8
Training loss: 2.0585474967956543
Validation loss: 2.9398655224871892

Epoch: 6| Step: 9
Training loss: 3.2548394203186035
Validation loss: 2.9379586378733316

Epoch: 6| Step: 10
Training loss: 3.1130638122558594
Validation loss: 2.940662948034143

Epoch: 6| Step: 11
Training loss: 3.7421462535858154
Validation loss: 2.9393621362665647

Epoch: 6| Step: 12
Training loss: 3.0679006576538086
Validation loss: 2.9330952167510986

Epoch: 6| Step: 13
Training loss: 2.055152654647827
Validation loss: 2.930728917480797

Epoch: 24| Step: 0
Training loss: 3.240175247192383
Validation loss: 2.9287418216787358

Epoch: 6| Step: 1
Training loss: 3.444831609725952
Validation loss: 2.930350370304559

Epoch: 6| Step: 2
Training loss: 2.5430002212524414
Validation loss: 2.92982135024122

Epoch: 6| Step: 3
Training loss: 2.9155144691467285
Validation loss: 2.935801731642856

Epoch: 6| Step: 4
Training loss: 3.4923605918884277
Validation loss: 2.935213601717385

Epoch: 6| Step: 5
Training loss: 3.3999276161193848
Validation loss: 2.9377696616675264

Epoch: 6| Step: 6
Training loss: 3.209652900695801
Validation loss: 2.9335373909242692

Epoch: 6| Step: 7
Training loss: 3.06571102142334
Validation loss: 2.926264726987449

Epoch: 6| Step: 8
Training loss: 2.917794942855835
Validation loss: 2.922703750671879

Epoch: 6| Step: 9
Training loss: 3.427520990371704
Validation loss: 2.9223731102481967

Epoch: 6| Step: 10
Training loss: 2.1791434288024902
Validation loss: 2.9216094529756935

Epoch: 6| Step: 11
Training loss: 2.8776354789733887
Validation loss: 2.92250076160636

Epoch: 6| Step: 12
Training loss: 2.504714012145996
Validation loss: 2.927240021767155

Epoch: 6| Step: 13
Training loss: 2.800150156021118
Validation loss: 2.916636872035201

Epoch: 25| Step: 0
Training loss: 3.125737190246582
Validation loss: 2.916793010568106

Epoch: 6| Step: 1
Training loss: 3.0713181495666504
Validation loss: 2.9155724894615913

Epoch: 6| Step: 2
Training loss: 3.6147713661193848
Validation loss: 2.9164139532273814

Epoch: 6| Step: 3
Training loss: 2.8649349212646484
Validation loss: 2.9090914444256852

Epoch: 6| Step: 4
Training loss: 2.790256977081299
Validation loss: 2.9116662856071227

Epoch: 6| Step: 5
Training loss: 2.6986207962036133
Validation loss: 2.9090164502461753

Epoch: 6| Step: 6
Training loss: 2.236917734146118
Validation loss: 2.9049916933941584

Epoch: 6| Step: 7
Training loss: 3.337871551513672
Validation loss: 2.908241871864565

Epoch: 6| Step: 8
Training loss: 3.466745138168335
Validation loss: 2.911572740923974

Epoch: 6| Step: 9
Training loss: 2.503307819366455
Validation loss: 2.9167360208367787

Epoch: 6| Step: 10
Training loss: 3.4155564308166504
Validation loss: 2.920879848541752

Epoch: 6| Step: 11
Training loss: 2.538848400115967
Validation loss: 2.9136041723271853

Epoch: 6| Step: 12
Training loss: 2.98382568359375
Validation loss: 2.9075685316516506

Epoch: 6| Step: 13
Training loss: 3.4537174701690674
Validation loss: 2.901959475650582

Epoch: 26| Step: 0
Training loss: 2.955639362335205
Validation loss: 2.9002444410836823

Epoch: 6| Step: 1
Training loss: 3.2041261196136475
Validation loss: 2.8959784533387873

Epoch: 6| Step: 2
Training loss: 3.332841396331787
Validation loss: 2.8986959559943086

Epoch: 6| Step: 3
Training loss: 2.6332740783691406
Validation loss: 2.898452648552515

Epoch: 6| Step: 4
Training loss: 2.3566548824310303
Validation loss: 2.896654116210117

Epoch: 6| Step: 5
Training loss: 2.719078302383423
Validation loss: 2.9133829045039352

Epoch: 6| Step: 6
Training loss: 3.130007743835449
Validation loss: 2.9259375551695466

Epoch: 6| Step: 7
Training loss: 3.1763086318969727
Validation loss: 2.895184924525599

Epoch: 6| Step: 8
Training loss: 2.8607962131500244
Validation loss: 2.896534401883361

Epoch: 6| Step: 9
Training loss: 2.398195743560791
Validation loss: 2.8931999539816253

Epoch: 6| Step: 10
Training loss: 3.7713863849639893
Validation loss: 2.8963416314894155

Epoch: 6| Step: 11
Training loss: 3.650538921356201
Validation loss: 2.904096734139227

Epoch: 6| Step: 12
Training loss: 2.698413848876953
Validation loss: 2.917749351070773

Epoch: 6| Step: 13
Training loss: 2.961463451385498
Validation loss: 2.9315196493620514

Epoch: 27| Step: 0
Training loss: 2.231940746307373
Validation loss: 2.946544965108236

Epoch: 6| Step: 1
Training loss: 3.159613609313965
Validation loss: 2.939338243135842

Epoch: 6| Step: 2
Training loss: 2.3419315814971924
Validation loss: 2.925160079874018

Epoch: 6| Step: 3
Training loss: 3.711378574371338
Validation loss: 2.9130660487759497

Epoch: 6| Step: 4
Training loss: 2.866126537322998
Validation loss: 2.8933683928622993

Epoch: 6| Step: 5
Training loss: 3.270002841949463
Validation loss: 2.8852258830942135

Epoch: 6| Step: 6
Training loss: 3.427466630935669
Validation loss: 2.8830375979023595

Epoch: 6| Step: 7
Training loss: 2.2991533279418945
Validation loss: 2.8820750610802763

Epoch: 6| Step: 8
Training loss: 3.5376343727111816
Validation loss: 2.886505634553971

Epoch: 6| Step: 9
Training loss: 3.2172837257385254
Validation loss: 2.8859877176182245

Epoch: 6| Step: 10
Training loss: 2.4888665676116943
Validation loss: 2.8834675306914956

Epoch: 6| Step: 11
Training loss: 3.3063740730285645
Validation loss: 2.8824071999519103

Epoch: 6| Step: 12
Training loss: 3.186835527420044
Validation loss: 2.881050573882236

Epoch: 6| Step: 13
Training loss: 2.664060354232788
Validation loss: 2.8782344787351546

Epoch: 28| Step: 0
Training loss: 2.38907527923584
Validation loss: 2.8788182299624205

Epoch: 6| Step: 1
Training loss: 3.1885435581207275
Validation loss: 2.8744525371059293

Epoch: 6| Step: 2
Training loss: 2.5739450454711914
Validation loss: 2.8737230249630508

Epoch: 6| Step: 3
Training loss: 3.4783709049224854
Validation loss: 2.8769092790542112

Epoch: 6| Step: 4
Training loss: 3.0775558948516846
Validation loss: 2.875368946342058

Epoch: 6| Step: 5
Training loss: 2.6927971839904785
Validation loss: 2.8732977067270586

Epoch: 6| Step: 6
Training loss: 2.1849334239959717
Validation loss: 2.8735125705760014

Epoch: 6| Step: 7
Training loss: 3.785019874572754
Validation loss: 2.8724464165267123

Epoch: 6| Step: 8
Training loss: 3.241701126098633
Validation loss: 2.8715402746713288

Epoch: 6| Step: 9
Training loss: 2.6211209297180176
Validation loss: 2.8687218286657847

Epoch: 6| Step: 10
Training loss: 3.061284065246582
Validation loss: 2.8675767067940003

Epoch: 6| Step: 11
Training loss: 2.308462619781494
Validation loss: 2.8625668300095426

Epoch: 6| Step: 12
Training loss: 3.3683505058288574
Validation loss: 2.8593857877997944

Epoch: 6| Step: 13
Training loss: 4.096278190612793
Validation loss: 2.860176263316985

Epoch: 29| Step: 0
Training loss: 3.1262078285217285
Validation loss: 2.8574879220736924

Epoch: 6| Step: 1
Training loss: 2.1387717723846436
Validation loss: 2.865765651067098

Epoch: 6| Step: 2
Training loss: 3.006964683532715
Validation loss: 2.8672238396060084

Epoch: 6| Step: 3
Training loss: 2.5190930366516113
Validation loss: 2.85549957008772

Epoch: 6| Step: 4
Training loss: 3.4635539054870605
Validation loss: 2.854738591819681

Epoch: 6| Step: 5
Training loss: 2.5784687995910645
Validation loss: 2.8557766996404177

Epoch: 6| Step: 6
Training loss: 3.776639938354492
Validation loss: 2.8547726651673675

Epoch: 6| Step: 7
Training loss: 3.347722053527832
Validation loss: 2.857480566988709

Epoch: 6| Step: 8
Training loss: 3.5353121757507324
Validation loss: 2.8584282141859814

Epoch: 6| Step: 9
Training loss: 2.3498051166534424
Validation loss: 2.8587908642266386

Epoch: 6| Step: 10
Training loss: 2.755549430847168
Validation loss: 2.862744003213862

Epoch: 6| Step: 11
Training loss: 2.954791307449341
Validation loss: 2.8585839092090564

Epoch: 6| Step: 12
Training loss: 3.270799160003662
Validation loss: 2.857502463043377

Epoch: 6| Step: 13
Training loss: 2.348262310028076
Validation loss: 2.858417098240186

Epoch: 30| Step: 0
Training loss: 2.4880332946777344
Validation loss: 2.855408030171548

Epoch: 6| Step: 1
Training loss: 2.6718268394470215
Validation loss: 2.855797129292642

Epoch: 6| Step: 2
Training loss: 3.7087554931640625
Validation loss: 2.8574704508627615

Epoch: 6| Step: 3
Training loss: 2.668078899383545
Validation loss: 2.857655397025488

Epoch: 6| Step: 4
Training loss: 2.6691854000091553
Validation loss: 2.8538308271797757

Epoch: 6| Step: 5
Training loss: 3.4057908058166504
Validation loss: 2.858440811916064

Epoch: 6| Step: 6
Training loss: 1.5413458347320557
Validation loss: 2.857456535421392

Epoch: 6| Step: 7
Training loss: 3.068047523498535
Validation loss: 2.857232029720019

Epoch: 6| Step: 8
Training loss: 3.2769150733947754
Validation loss: 2.855015198389689

Epoch: 6| Step: 9
Training loss: 2.164283275604248
Validation loss: 2.857747800888554

Epoch: 6| Step: 10
Training loss: 3.1403753757476807
Validation loss: 2.856800768965034

Epoch: 6| Step: 11
Training loss: 4.199521064758301
Validation loss: 2.8520666373673307

Epoch: 6| Step: 12
Training loss: 2.9264109134674072
Validation loss: 2.8467520642024216

Epoch: 6| Step: 13
Training loss: 3.794092893600464
Validation loss: 2.842345960678593

Epoch: 31| Step: 0
Training loss: 3.159607410430908
Validation loss: 2.840197904135591

Epoch: 6| Step: 1
Training loss: 3.5111849308013916
Validation loss: 2.854846090398809

Epoch: 6| Step: 2
Training loss: 2.650564670562744
Validation loss: 2.850745467729466

Epoch: 6| Step: 3
Training loss: 2.2598769664764404
Validation loss: 2.8445639969200216

Epoch: 6| Step: 4
Training loss: 3.8031504154205322
Validation loss: 2.833483693420246

Epoch: 6| Step: 5
Training loss: 3.6615850925445557
Validation loss: 2.8362045672632035

Epoch: 6| Step: 6
Training loss: 2.0753660202026367
Validation loss: 2.835059873519405

Epoch: 6| Step: 7
Training loss: 2.623076915740967
Validation loss: 2.832117308852493

Epoch: 6| Step: 8
Training loss: 2.686964988708496
Validation loss: 2.8339143491560415

Epoch: 6| Step: 9
Training loss: 2.8319144248962402
Validation loss: 2.835129876290598

Epoch: 6| Step: 10
Training loss: 3.036151885986328
Validation loss: 2.8334220711902907

Epoch: 6| Step: 11
Training loss: 2.6637725830078125
Validation loss: 2.8379434898335445

Epoch: 6| Step: 12
Training loss: 3.477128505706787
Validation loss: 2.8382078242558304

Epoch: 6| Step: 13
Training loss: 2.723857879638672
Validation loss: 2.8347163097832793

Epoch: 32| Step: 0
Training loss: 3.0168633460998535
Validation loss: 2.8344481222091185

Epoch: 6| Step: 1
Training loss: 2.4774913787841797
Validation loss: 2.835977787612587

Epoch: 6| Step: 2
Training loss: 3.484527587890625
Validation loss: 2.831381038952899

Epoch: 6| Step: 3
Training loss: 3.4537994861602783
Validation loss: 2.8302809346106743

Epoch: 6| Step: 4
Training loss: 2.608506917953491
Validation loss: 2.829688866933187

Epoch: 6| Step: 5
Training loss: 2.642313003540039
Validation loss: 2.82691635880419

Epoch: 6| Step: 6
Training loss: 2.358994960784912
Validation loss: 2.8275852305914766

Epoch: 6| Step: 7
Training loss: 3.136605978012085
Validation loss: 2.8243251180136077

Epoch: 6| Step: 8
Training loss: 3.1810288429260254
Validation loss: 2.8222208740890666

Epoch: 6| Step: 9
Training loss: 2.604666233062744
Validation loss: 2.8210302475960023

Epoch: 6| Step: 10
Training loss: 3.2965805530548096
Validation loss: 2.822776517560405

Epoch: 6| Step: 11
Training loss: 2.734930992126465
Validation loss: 2.824274565583916

Epoch: 6| Step: 12
Training loss: 3.536656618118286
Validation loss: 2.819338442176901

Epoch: 6| Step: 13
Training loss: 2.322411060333252
Validation loss: 2.8192993440935687

Epoch: 33| Step: 0
Training loss: 3.1952314376831055
Validation loss: 2.820482095082601

Epoch: 6| Step: 1
Training loss: 3.4392426013946533
Validation loss: 2.820901034980692

Epoch: 6| Step: 2
Training loss: 3.497556209564209
Validation loss: 2.82439241614393

Epoch: 6| Step: 3
Training loss: 3.5471837520599365
Validation loss: 2.8282336214537263

Epoch: 6| Step: 4
Training loss: 3.564035177230835
Validation loss: 2.8269435051948792

Epoch: 6| Step: 5
Training loss: 3.2441558837890625
Validation loss: 2.8300842623556814

Epoch: 6| Step: 6
Training loss: 3.255905866622925
Validation loss: 2.821480458782565

Epoch: 6| Step: 7
Training loss: 2.7387948036193848
Validation loss: 2.8139748137484313

Epoch: 6| Step: 8
Training loss: 2.6381986141204834
Validation loss: 2.812585189778318

Epoch: 6| Step: 9
Training loss: 1.2394719123840332
Validation loss: 2.8174552456025155

Epoch: 6| Step: 10
Training loss: 2.7392964363098145
Validation loss: 2.8196222935953448

Epoch: 6| Step: 11
Training loss: 2.8912272453308105
Validation loss: 2.8088702258243354

Epoch: 6| Step: 12
Training loss: 2.526505470275879
Validation loss: 2.8085479172327186

Epoch: 6| Step: 13
Training loss: 2.1127450466156006
Validation loss: 2.8086488528918196

Epoch: 34| Step: 0
Training loss: 2.7228708267211914
Validation loss: 2.806908433155347

Epoch: 6| Step: 1
Training loss: 2.1812257766723633
Validation loss: 2.809150239472748

Epoch: 6| Step: 2
Training loss: 2.812208414077759
Validation loss: 2.81067898965651

Epoch: 6| Step: 3
Training loss: 3.455508232116699
Validation loss: 2.8118414161025838

Epoch: 6| Step: 4
Training loss: 2.551891326904297
Validation loss: 2.812225913488737

Epoch: 6| Step: 5
Training loss: 3.578252077102661
Validation loss: 2.8090081701996508

Epoch: 6| Step: 6
Training loss: 3.800814390182495
Validation loss: 2.8074314953178487

Epoch: 6| Step: 7
Training loss: 2.5177972316741943
Validation loss: 2.804660627918859

Epoch: 6| Step: 8
Training loss: 2.958538293838501
Validation loss: 2.8031175674930697

Epoch: 6| Step: 9
Training loss: 2.831024169921875
Validation loss: 2.8016967670891875

Epoch: 6| Step: 10
Training loss: 1.9974408149719238
Validation loss: 2.798069812918222

Epoch: 6| Step: 11
Training loss: 2.7943341732025146
Validation loss: 2.7982642317330964

Epoch: 6| Step: 12
Training loss: 3.3777010440826416
Validation loss: 2.79819760271298

Epoch: 6| Step: 13
Training loss: 3.5721843242645264
Validation loss: 2.7994348515746412

Epoch: 35| Step: 0
Training loss: 3.027019500732422
Validation loss: 2.7973453562746764

Epoch: 6| Step: 1
Training loss: 2.781513214111328
Validation loss: 2.7948349060550814

Epoch: 6| Step: 2
Training loss: 2.7900543212890625
Validation loss: 2.801748852575979

Epoch: 6| Step: 3
Training loss: 2.503469705581665
Validation loss: 2.8095192101693924

Epoch: 6| Step: 4
Training loss: 3.7368907928466797
Validation loss: 2.828319452142203

Epoch: 6| Step: 5
Training loss: 2.8200602531433105
Validation loss: 2.8191798707490325

Epoch: 6| Step: 6
Training loss: 2.6300508975982666
Validation loss: 2.81639362406987

Epoch: 6| Step: 7
Training loss: 3.377472400665283
Validation loss: 2.825134023543327

Epoch: 6| Step: 8
Training loss: 3.4312477111816406
Validation loss: 2.803571213958084

Epoch: 6| Step: 9
Training loss: 2.409184217453003
Validation loss: 2.7914303502728863

Epoch: 6| Step: 10
Training loss: 2.9185190200805664
Validation loss: 2.795891110615064

Epoch: 6| Step: 11
Training loss: 3.5177700519561768
Validation loss: 2.7978033493923884

Epoch: 6| Step: 12
Training loss: 2.303950071334839
Validation loss: 2.799110997107721

Epoch: 6| Step: 13
Training loss: 2.3655011653900146
Validation loss: 2.800451527359665

Epoch: 36| Step: 0
Training loss: 2.959933042526245
Validation loss: 2.7927720956904913

Epoch: 6| Step: 1
Training loss: 2.616729736328125
Validation loss: 2.792358695819814

Epoch: 6| Step: 2
Training loss: 2.0229504108428955
Validation loss: 2.790614387040497

Epoch: 6| Step: 3
Training loss: 2.4911069869995117
Validation loss: 2.7911254257284184

Epoch: 6| Step: 4
Training loss: 2.783989906311035
Validation loss: 2.7873474346694125

Epoch: 6| Step: 5
Training loss: 3.2585837841033936
Validation loss: 2.785698457430768

Epoch: 6| Step: 6
Training loss: 3.1556248664855957
Validation loss: 2.789810985647222

Epoch: 6| Step: 7
Training loss: 2.3875811100006104
Validation loss: 2.791738171731272

Epoch: 6| Step: 8
Training loss: 3.2214441299438477
Validation loss: 2.798255043645059

Epoch: 6| Step: 9
Training loss: 3.049835205078125
Validation loss: 2.7970698623247046

Epoch: 6| Step: 10
Training loss: 2.8773748874664307
Validation loss: 2.785866383583315

Epoch: 6| Step: 11
Training loss: 3.0336849689483643
Validation loss: 2.783224633944932

Epoch: 6| Step: 12
Training loss: 3.152655601501465
Validation loss: 2.7825689546523558

Epoch: 6| Step: 13
Training loss: 4.307699203491211
Validation loss: 2.780886878249466

Epoch: 37| Step: 0
Training loss: 2.6092615127563477
Validation loss: 2.7812678762661514

Epoch: 6| Step: 1
Training loss: 3.660210132598877
Validation loss: 2.778467688509213

Epoch: 6| Step: 2
Training loss: 3.193478584289551
Validation loss: 2.7774011319683445

Epoch: 6| Step: 3
Training loss: 2.7853636741638184
Validation loss: 2.7760972874138945

Epoch: 6| Step: 4
Training loss: 3.169583797454834
Validation loss: 2.7737511691226753

Epoch: 6| Step: 5
Training loss: 2.4055862426757812
Validation loss: 2.7710019696143364

Epoch: 6| Step: 6
Training loss: 2.5497217178344727
Validation loss: 2.7708004802785893

Epoch: 6| Step: 7
Training loss: 2.644291639328003
Validation loss: 2.7702874188782065

Epoch: 6| Step: 8
Training loss: 3.2770495414733887
Validation loss: 2.7706844011942544

Epoch: 6| Step: 9
Training loss: 3.331327199935913
Validation loss: 2.76779035599001

Epoch: 6| Step: 10
Training loss: 2.4001097679138184
Validation loss: 2.7662514768620974

Epoch: 6| Step: 11
Training loss: 2.6192541122436523
Validation loss: 2.7676960268328266

Epoch: 6| Step: 12
Training loss: 3.3625094890594482
Validation loss: 2.769331229630337

Epoch: 6| Step: 13
Training loss: 2.288905620574951
Validation loss: 2.76352761894144

Epoch: 38| Step: 0
Training loss: 1.6745989322662354
Validation loss: 2.76466247599612

Epoch: 6| Step: 1
Training loss: 2.3086366653442383
Validation loss: 2.766551599707655

Epoch: 6| Step: 2
Training loss: 2.4242804050445557
Validation loss: 2.76618972645011

Epoch: 6| Step: 3
Training loss: 2.651279926300049
Validation loss: 2.7637584158169326

Epoch: 6| Step: 4
Training loss: 3.706934928894043
Validation loss: 2.765101989110311

Epoch: 6| Step: 5
Training loss: 3.0211281776428223
Validation loss: 2.7696633620928695

Epoch: 6| Step: 6
Training loss: 2.8597476482391357
Validation loss: 2.768062953026064

Epoch: 6| Step: 7
Training loss: 3.4503014087677
Validation loss: 2.7656191856630388

Epoch: 6| Step: 8
Training loss: 3.442143440246582
Validation loss: 2.7642686033761628

Epoch: 6| Step: 9
Training loss: 3.796290636062622
Validation loss: 2.7606936680373324

Epoch: 6| Step: 10
Training loss: 2.6921632289886475
Validation loss: 2.7575763117882515

Epoch: 6| Step: 11
Training loss: 3.190242052078247
Validation loss: 2.756206932888236

Epoch: 6| Step: 12
Training loss: 2.738199234008789
Validation loss: 2.7561829807937785

Epoch: 6| Step: 13
Training loss: 1.9510765075683594
Validation loss: 2.7551799435769357

Epoch: 39| Step: 0
Training loss: 3.099762439727783
Validation loss: 2.753533442815145

Epoch: 6| Step: 1
Training loss: 2.9257941246032715
Validation loss: 2.755781025014898

Epoch: 6| Step: 2
Training loss: 2.5895652770996094
Validation loss: 2.7519832811047955

Epoch: 6| Step: 3
Training loss: 2.741230010986328
Validation loss: 2.752999174979425

Epoch: 6| Step: 4
Training loss: 1.7912163734436035
Validation loss: 2.7552226743390484

Epoch: 6| Step: 5
Training loss: 2.2485454082489014
Validation loss: 2.755912870489141

Epoch: 6| Step: 6
Training loss: 2.915764570236206
Validation loss: 2.7671803864099647

Epoch: 6| Step: 7
Training loss: 2.593294620513916
Validation loss: 2.770026960680562

Epoch: 6| Step: 8
Training loss: 3.1544852256774902
Validation loss: 2.760175940810993

Epoch: 6| Step: 9
Training loss: 3.41385555267334
Validation loss: 2.7523054922780683

Epoch: 6| Step: 10
Training loss: 3.1995127201080322
Validation loss: 2.7471047165573284

Epoch: 6| Step: 11
Training loss: 3.255427837371826
Validation loss: 2.753671189790131

Epoch: 6| Step: 12
Training loss: 3.8759400844573975
Validation loss: 2.759802464515932

Epoch: 6| Step: 13
Training loss: 2.164417266845703
Validation loss: 2.767250555817799

Epoch: 40| Step: 0
Training loss: 3.1318817138671875
Validation loss: 2.7770660231190343

Epoch: 6| Step: 1
Training loss: 2.5374820232391357
Validation loss: 2.7921117249355523

Epoch: 6| Step: 2
Training loss: 3.323366165161133
Validation loss: 2.813551551552229

Epoch: 6| Step: 3
Training loss: 3.485931396484375
Validation loss: 2.812264565498598

Epoch: 6| Step: 4
Training loss: 2.9544520378112793
Validation loss: 2.785104810550649

Epoch: 6| Step: 5
Training loss: 1.950448989868164
Validation loss: 2.762941696310556

Epoch: 6| Step: 6
Training loss: 3.2178244590759277
Validation loss: 2.760884113209222

Epoch: 6| Step: 7
Training loss: 2.3802056312561035
Validation loss: 2.7624083360036216

Epoch: 6| Step: 8
Training loss: 2.725511074066162
Validation loss: 2.7671494919766664

Epoch: 6| Step: 9
Training loss: 2.2084057331085205
Validation loss: 2.77802199445745

Epoch: 6| Step: 10
Training loss: 2.0928096771240234
Validation loss: 2.7887774103431293

Epoch: 6| Step: 11
Training loss: 3.7606732845306396
Validation loss: 2.7934131878678516

Epoch: 6| Step: 12
Training loss: 3.9214839935302734
Validation loss: 2.7947665388866136

Epoch: 6| Step: 13
Training loss: 3.0109686851501465
Validation loss: 2.786658702358123

Epoch: 41| Step: 0
Training loss: 3.2336950302124023
Validation loss: 2.7615429996162333

Epoch: 6| Step: 1
Training loss: 3.7996323108673096
Validation loss: 2.7581685768660678

Epoch: 6| Step: 2
Training loss: 3.2996530532836914
Validation loss: 2.7586933259041078

Epoch: 6| Step: 3
Training loss: 3.1729037761688232
Validation loss: 2.7579372416260424

Epoch: 6| Step: 4
Training loss: 2.0748515129089355
Validation loss: 2.75842821726235

Epoch: 6| Step: 5
Training loss: 1.9435954093933105
Validation loss: 2.7618740630406204

Epoch: 6| Step: 6
Training loss: 3.142216682434082
Validation loss: 2.7579533797438427

Epoch: 6| Step: 7
Training loss: 3.307516574859619
Validation loss: 2.761160289087603

Epoch: 6| Step: 8
Training loss: 2.3163633346557617
Validation loss: 2.759894645342263

Epoch: 6| Step: 9
Training loss: 3.5391058921813965
Validation loss: 2.7630402324020222

Epoch: 6| Step: 10
Training loss: 2.708266258239746
Validation loss: 2.7679067606567056

Epoch: 6| Step: 11
Training loss: 2.934765338897705
Validation loss: 2.765156440837409

Epoch: 6| Step: 12
Training loss: 1.810272216796875
Validation loss: 2.754320162598805

Epoch: 6| Step: 13
Training loss: 3.3987319469451904
Validation loss: 2.7514176266167754

Epoch: 42| Step: 0
Training loss: 2.8151426315307617
Validation loss: 2.7462957930821243

Epoch: 6| Step: 1
Training loss: 2.1733903884887695
Validation loss: 2.7396943748638196

Epoch: 6| Step: 2
Training loss: 2.9680683612823486
Validation loss: 2.7369183314743863

Epoch: 6| Step: 3
Training loss: 2.8094496726989746
Validation loss: 2.736134385549894

Epoch: 6| Step: 4
Training loss: 3.1190366744995117
Validation loss: 2.736725027843188

Epoch: 6| Step: 5
Training loss: 3.401808500289917
Validation loss: 2.735122593500281

Epoch: 6| Step: 6
Training loss: 3.453975200653076
Validation loss: 2.736496630535331

Epoch: 6| Step: 7
Training loss: 3.016763687133789
Validation loss: 2.73890927017376

Epoch: 6| Step: 8
Training loss: 2.8618054389953613
Validation loss: 2.734561712511124

Epoch: 6| Step: 9
Training loss: 2.6319751739501953
Validation loss: 2.7325257255185034

Epoch: 6| Step: 10
Training loss: 2.4841971397399902
Validation loss: 2.7320421716218353

Epoch: 6| Step: 11
Training loss: 3.5026144981384277
Validation loss: 2.730067627404326

Epoch: 6| Step: 12
Training loss: 1.9300588369369507
Validation loss: 2.731674958300847

Epoch: 6| Step: 13
Training loss: 3.1537692546844482
Validation loss: 2.734140134626819

Epoch: 43| Step: 0
Training loss: 3.1777422428131104
Validation loss: 2.730817312835365

Epoch: 6| Step: 1
Training loss: 2.1544573307037354
Validation loss: 2.7321463041408087

Epoch: 6| Step: 2
Training loss: 3.00108003616333
Validation loss: 2.7347391959159606

Epoch: 6| Step: 3
Training loss: 2.4305918216705322
Validation loss: 2.7365134018723682

Epoch: 6| Step: 4
Training loss: 2.6674351692199707
Validation loss: 2.7365334085238877

Epoch: 6| Step: 5
Training loss: 2.762599229812622
Validation loss: 2.7356749119297152

Epoch: 6| Step: 6
Training loss: 2.4101240634918213
Validation loss: 2.7361973024183706

Epoch: 6| Step: 7
Training loss: 2.7780895233154297
Validation loss: 2.73006276417804

Epoch: 6| Step: 8
Training loss: 3.138489007949829
Validation loss: 2.734734768508583

Epoch: 6| Step: 9
Training loss: 2.666102886199951
Validation loss: 2.735697261748775

Epoch: 6| Step: 10
Training loss: 2.3031954765319824
Validation loss: 2.7366672767105924

Epoch: 6| Step: 11
Training loss: 4.0455498695373535
Validation loss: 2.7379882233117216

Epoch: 6| Step: 12
Training loss: 3.5696592330932617
Validation loss: 2.7343023976972027

Epoch: 6| Step: 13
Training loss: 3.074740409851074
Validation loss: 2.732699922336045

Epoch: 44| Step: 0
Training loss: 2.4010396003723145
Validation loss: 2.7322182475879626

Epoch: 6| Step: 1
Training loss: 2.9401230812072754
Validation loss: 2.7301644304747223

Epoch: 6| Step: 2
Training loss: 3.3228237628936768
Validation loss: 2.7304711803313224

Epoch: 6| Step: 3
Training loss: 3.3759045600891113
Validation loss: 2.729199537666895

Epoch: 6| Step: 4
Training loss: 3.3908395767211914
Validation loss: 2.7289958205274356

Epoch: 6| Step: 5
Training loss: 2.611605167388916
Validation loss: 2.731283341684649

Epoch: 6| Step: 6
Training loss: 3.1258492469787598
Validation loss: 2.725438530727099

Epoch: 6| Step: 7
Training loss: 2.186563491821289
Validation loss: 2.7242283539105485

Epoch: 6| Step: 8
Training loss: 3.025578022003174
Validation loss: 2.7257681687672934

Epoch: 6| Step: 9
Training loss: 3.0745272636413574
Validation loss: 2.7242142179960847

Epoch: 6| Step: 10
Training loss: 2.0873606204986572
Validation loss: 2.7249059497669177

Epoch: 6| Step: 11
Training loss: 2.780025005340576
Validation loss: 2.7226725342453166

Epoch: 6| Step: 12
Training loss: 2.985733985900879
Validation loss: 2.724020360618509

Epoch: 6| Step: 13
Training loss: 2.5361592769622803
Validation loss: 2.721970699166739

Epoch: 45| Step: 0
Training loss: 3.76106858253479
Validation loss: 2.7214405587924424

Epoch: 6| Step: 1
Training loss: 3.2922682762145996
Validation loss: 2.724954302592944

Epoch: 6| Step: 2
Training loss: 2.911999464035034
Validation loss: 2.721329237825127

Epoch: 6| Step: 3
Training loss: 2.675326347351074
Validation loss: 2.7239284207743983

Epoch: 6| Step: 4
Training loss: 3.1042943000793457
Validation loss: 2.7253603678877636

Epoch: 6| Step: 5
Training loss: 2.2475671768188477
Validation loss: 2.7271692727201726

Epoch: 6| Step: 6
Training loss: 2.0987792015075684
Validation loss: 2.7249874273935952

Epoch: 6| Step: 7
Training loss: 3.369582414627075
Validation loss: 2.7256679842548985

Epoch: 6| Step: 8
Training loss: 2.0114331245422363
Validation loss: 2.7269125523105746

Epoch: 6| Step: 9
Training loss: 2.686598777770996
Validation loss: 2.718974836411015

Epoch: 6| Step: 10
Training loss: 4.0207061767578125
Validation loss: 2.7235662296254146

Epoch: 6| Step: 11
Training loss: 2.6629841327667236
Validation loss: 2.721221770009687

Epoch: 6| Step: 12
Training loss: 2.221557378768921
Validation loss: 2.7215866401631343

Epoch: 6| Step: 13
Training loss: 2.888608694076538
Validation loss: 2.718696394274312

Epoch: 46| Step: 0
Training loss: 3.0834403038024902
Validation loss: 2.7186321468763452

Epoch: 6| Step: 1
Training loss: 3.1433424949645996
Validation loss: 2.716559458804387

Epoch: 6| Step: 2
Training loss: 2.366711139678955
Validation loss: 2.716176845694101

Epoch: 6| Step: 3
Training loss: 2.737537384033203
Validation loss: 2.7157781431751866

Epoch: 6| Step: 4
Training loss: 3.5320959091186523
Validation loss: 2.723706517168271

Epoch: 6| Step: 5
Training loss: 2.796457290649414
Validation loss: 2.72215284070661

Epoch: 6| Step: 6
Training loss: 2.7383978366851807
Validation loss: 2.7200128288679224

Epoch: 6| Step: 7
Training loss: 2.575840473175049
Validation loss: 2.720425251991518

Epoch: 6| Step: 8
Training loss: 2.854220390319824
Validation loss: 2.7196432928885184

Epoch: 6| Step: 9
Training loss: 3.143965721130371
Validation loss: 2.721189773210915

Epoch: 6| Step: 10
Training loss: 2.619081974029541
Validation loss: 2.7174786136996363

Epoch: 6| Step: 11
Training loss: 2.5582995414733887
Validation loss: 2.7121195306060133

Epoch: 6| Step: 12
Training loss: 2.461700201034546
Validation loss: 2.7147902724563435

Epoch: 6| Step: 13
Training loss: 3.619540214538574
Validation loss: 2.7128229397599415

Epoch: 47| Step: 0
Training loss: 2.7294721603393555
Validation loss: 2.7111243919659684

Epoch: 6| Step: 1
Training loss: 3.0926828384399414
Validation loss: 2.71168920557986

Epoch: 6| Step: 2
Training loss: 2.5810043811798096
Validation loss: 2.7093942601193666

Epoch: 6| Step: 3
Training loss: 2.7651422023773193
Validation loss: 2.709564347420969

Epoch: 6| Step: 4
Training loss: 2.571600914001465
Validation loss: 2.708223025004069

Epoch: 6| Step: 5
Training loss: 3.123467445373535
Validation loss: 2.71162441725372

Epoch: 6| Step: 6
Training loss: 2.5529205799102783
Validation loss: 2.711892886828351

Epoch: 6| Step: 7
Training loss: 2.476128101348877
Validation loss: 2.7091399290228404

Epoch: 6| Step: 8
Training loss: 3.293952703475952
Validation loss: 2.709905514153101

Epoch: 6| Step: 9
Training loss: 3.0836949348449707
Validation loss: 2.70972934333227

Epoch: 6| Step: 10
Training loss: 3.340012311935425
Validation loss: 2.709834314161731

Epoch: 6| Step: 11
Training loss: 2.434415340423584
Validation loss: 2.7106664385846866

Epoch: 6| Step: 12
Training loss: 3.112557888031006
Validation loss: 2.708505512565695

Epoch: 6| Step: 13
Training loss: 2.697535276412964
Validation loss: 2.708214421426096

Epoch: 48| Step: 0
Training loss: 2.5236268043518066
Validation loss: 2.7093075449748705

Epoch: 6| Step: 1
Training loss: 3.303445816040039
Validation loss: 2.7103900447968514

Epoch: 6| Step: 2
Training loss: 2.6113924980163574
Validation loss: 2.71562018445743

Epoch: 6| Step: 3
Training loss: 1.6747725009918213
Validation loss: 2.7238865001227266

Epoch: 6| Step: 4
Training loss: 2.32997989654541
Validation loss: 2.719167355568178

Epoch: 6| Step: 5
Training loss: 2.68609619140625
Validation loss: 2.711983001360329

Epoch: 6| Step: 6
Training loss: 2.706834077835083
Validation loss: 2.7036488594547397

Epoch: 6| Step: 7
Training loss: 2.427853584289551
Validation loss: 2.700408581764467

Epoch: 6| Step: 8
Training loss: 2.6364481449127197
Validation loss: 2.7014952218660744

Epoch: 6| Step: 9
Training loss: 4.178823471069336
Validation loss: 2.7013894075988443

Epoch: 6| Step: 10
Training loss: 3.1404635906219482
Validation loss: 2.701229920951269

Epoch: 6| Step: 11
Training loss: 3.3341941833496094
Validation loss: 2.702293480596235

Epoch: 6| Step: 12
Training loss: 3.894648551940918
Validation loss: 2.701843072009343

Epoch: 6| Step: 13
Training loss: 2.0943002700805664
Validation loss: 2.7019635656828522

Epoch: 49| Step: 0
Training loss: 2.655337333679199
Validation loss: 2.7038195722846576

Epoch: 6| Step: 1
Training loss: 2.577298402786255
Validation loss: 2.6998088282923542

Epoch: 6| Step: 2
Training loss: 2.606203079223633
Validation loss: 2.7029130689559446

Epoch: 6| Step: 3
Training loss: 2.5198705196380615
Validation loss: 2.700103072709935

Epoch: 6| Step: 4
Training loss: 2.683229923248291
Validation loss: 2.7018579026704193

Epoch: 6| Step: 5
Training loss: 3.737954616546631
Validation loss: 2.707422823034307

Epoch: 6| Step: 6
Training loss: 1.934264898300171
Validation loss: 2.7054715669283302

Epoch: 6| Step: 7
Training loss: 3.4430489540100098
Validation loss: 2.7038597676061813

Epoch: 6| Step: 8
Training loss: 2.944024085998535
Validation loss: 2.707971134493428

Epoch: 6| Step: 9
Training loss: 2.7247941493988037
Validation loss: 2.7057199273058163

Epoch: 6| Step: 10
Training loss: 3.358692169189453
Validation loss: 2.7069783287663616

Epoch: 6| Step: 11
Training loss: 2.603167772293091
Validation loss: 2.706862611155356

Epoch: 6| Step: 12
Training loss: 2.7832534313201904
Validation loss: 2.7059131181368263

Epoch: 6| Step: 13
Training loss: 3.5764095783233643
Validation loss: 2.7050029334201606

Epoch: 50| Step: 0
Training loss: 3.262333869934082
Validation loss: 2.707216762727307

Epoch: 6| Step: 1
Training loss: 2.4543023109436035
Validation loss: 2.706462547343264

Epoch: 6| Step: 2
Training loss: 2.895982265472412
Validation loss: 2.700672067621703

Epoch: 6| Step: 3
Training loss: 2.650563955307007
Validation loss: 2.702971322562105

Epoch: 6| Step: 4
Training loss: 2.7403974533081055
Validation loss: 2.7045411679052536

Epoch: 6| Step: 5
Training loss: 3.119267463684082
Validation loss: 2.7022279641961537

Epoch: 6| Step: 6
Training loss: 3.16487979888916
Validation loss: 2.6991948594329176

Epoch: 6| Step: 7
Training loss: 2.6776914596557617
Validation loss: 2.700216144643804

Epoch: 6| Step: 8
Training loss: 1.8348495960235596
Validation loss: 2.700806922810052

Epoch: 6| Step: 9
Training loss: 3.146533727645874
Validation loss: 2.698719693768409

Epoch: 6| Step: 10
Training loss: 3.0209176540374756
Validation loss: 2.6969481924528718

Epoch: 6| Step: 11
Training loss: 2.1606807708740234
Validation loss: 2.6969570421403453

Epoch: 6| Step: 12
Training loss: 2.75232195854187
Validation loss: 2.6949095777285996

Epoch: 6| Step: 13
Training loss: 4.567680358886719
Validation loss: 2.6957987047010854

Epoch: 51| Step: 0
Training loss: 3.5595145225524902
Validation loss: 2.695868827963388

Epoch: 6| Step: 1
Training loss: 2.6100239753723145
Validation loss: 2.6919567020990516

Epoch: 6| Step: 2
Training loss: 2.751148223876953
Validation loss: 2.6948237214037167

Epoch: 6| Step: 3
Training loss: 2.87904691696167
Validation loss: 2.694135550529726

Epoch: 6| Step: 4
Training loss: 2.7360663414001465
Validation loss: 2.694425280376147

Epoch: 6| Step: 5
Training loss: 2.704596519470215
Validation loss: 2.6983762095051427

Epoch: 6| Step: 6
Training loss: 3.0079429149627686
Validation loss: 2.7048236708487234

Epoch: 6| Step: 7
Training loss: 3.1028263568878174
Validation loss: 2.706944698928505

Epoch: 6| Step: 8
Training loss: 2.1090140342712402
Validation loss: 2.704905561221543

Epoch: 6| Step: 9
Training loss: 2.8199896812438965
Validation loss: 2.6970336770498626

Epoch: 6| Step: 10
Training loss: 2.7543957233428955
Validation loss: 2.692082861418365

Epoch: 6| Step: 11
Training loss: 3.300276517868042
Validation loss: 2.6890019319390737

Epoch: 6| Step: 12
Training loss: 2.661458969116211
Validation loss: 2.690626726355604

Epoch: 6| Step: 13
Training loss: 2.587106466293335
Validation loss: 2.6906577464072936

Epoch: 52| Step: 0
Training loss: 2.653961658477783
Validation loss: 2.6920948284928516

Epoch: 6| Step: 1
Training loss: 2.0440680980682373
Validation loss: 2.6942327278916554

Epoch: 6| Step: 2
Training loss: 2.5128440856933594
Validation loss: 2.69407134415001

Epoch: 6| Step: 3
Training loss: 3.252906084060669
Validation loss: 2.6965167035338697

Epoch: 6| Step: 4
Training loss: 3.401259183883667
Validation loss: 2.695041274511686

Epoch: 6| Step: 5
Training loss: 2.8110616207122803
Validation loss: 2.6963652718451714

Epoch: 6| Step: 6
Training loss: 3.6179661750793457
Validation loss: 2.6982105342290734

Epoch: 6| Step: 7
Training loss: 2.8377013206481934
Validation loss: 2.694517489402525

Epoch: 6| Step: 8
Training loss: 2.637308120727539
Validation loss: 2.694302353807675

Epoch: 6| Step: 9
Training loss: 2.9256014823913574
Validation loss: 2.694542272116548

Epoch: 6| Step: 10
Training loss: 2.85078763961792
Validation loss: 2.6923882602363505

Epoch: 6| Step: 11
Training loss: 2.4699010848999023
Validation loss: 2.6897021365422074

Epoch: 6| Step: 12
Training loss: 2.461730718612671
Validation loss: 2.6922701430577103

Epoch: 6| Step: 13
Training loss: 3.6067614555358887
Validation loss: 2.690070685519967

Epoch: 53| Step: 0
Training loss: 2.918346881866455
Validation loss: 2.6950039056039627

Epoch: 6| Step: 1
Training loss: 3.7703723907470703
Validation loss: 2.688641853229974

Epoch: 6| Step: 2
Training loss: 2.4020252227783203
Validation loss: 2.6903897613607426

Epoch: 6| Step: 3
Training loss: 3.445742130279541
Validation loss: 2.6930741263974096

Epoch: 6| Step: 4
Training loss: 2.6237826347351074
Validation loss: 2.6930050311550016

Epoch: 6| Step: 5
Training loss: 3.317070960998535
Validation loss: 2.696002229567497

Epoch: 6| Step: 6
Training loss: 2.3010754585266113
Validation loss: 2.692863602792063

Epoch: 6| Step: 7
Training loss: 2.345237970352173
Validation loss: 2.6954001816370154

Epoch: 6| Step: 8
Training loss: 2.159101724624634
Validation loss: 2.692582448323568

Epoch: 6| Step: 9
Training loss: 3.3291921615600586
Validation loss: 2.694144833472467

Epoch: 6| Step: 10
Training loss: 2.8702573776245117
Validation loss: 2.6900250142620457

Epoch: 6| Step: 11
Training loss: 2.570216655731201
Validation loss: 2.6906432733740857

Epoch: 6| Step: 12
Training loss: 2.951937675476074
Validation loss: 2.691813022859635

Epoch: 6| Step: 13
Training loss: 2.4229021072387695
Validation loss: 2.6928319546484176

Epoch: 54| Step: 0
Training loss: 1.9627043008804321
Validation loss: 2.6911191055851598

Epoch: 6| Step: 1
Training loss: 2.6858785152435303
Validation loss: 2.688264303309943

Epoch: 6| Step: 2
Training loss: 2.5611824989318848
Validation loss: 2.685684088737734

Epoch: 6| Step: 3
Training loss: 3.13820219039917
Validation loss: 2.6846084569090154

Epoch: 6| Step: 4
Training loss: 2.8000681400299072
Validation loss: 2.68307154152983

Epoch: 6| Step: 5
Training loss: 2.646686315536499
Validation loss: 2.683013600687827

Epoch: 6| Step: 6
Training loss: 3.352226972579956
Validation loss: 2.6812859119907504

Epoch: 6| Step: 7
Training loss: 3.442953586578369
Validation loss: 2.6826390476636988

Epoch: 6| Step: 8
Training loss: 2.411402702331543
Validation loss: 2.6820781512926986

Epoch: 6| Step: 9
Training loss: 3.3668055534362793
Validation loss: 2.685995337783649

Epoch: 6| Step: 10
Training loss: 2.0887746810913086
Validation loss: 2.6875751146706204

Epoch: 6| Step: 11
Training loss: 3.059046983718872
Validation loss: 2.6870337532412623

Epoch: 6| Step: 12
Training loss: 3.520822286605835
Validation loss: 2.681914734584029

Epoch: 6| Step: 13
Training loss: 2.3616864681243896
Validation loss: 2.684324497817665

Epoch: 55| Step: 0
Training loss: 3.6024270057678223
Validation loss: 2.6806587378184

Epoch: 6| Step: 1
Training loss: 2.7977170944213867
Validation loss: 2.6805905475411365

Epoch: 6| Step: 2
Training loss: 2.9558591842651367
Validation loss: 2.6813013322891726

Epoch: 6| Step: 3
Training loss: 2.240895986557007
Validation loss: 2.681188924338228

Epoch: 6| Step: 4
Training loss: 3.223003387451172
Validation loss: 2.6836167714929067

Epoch: 6| Step: 5
Training loss: 2.6372108459472656
Validation loss: 2.686539162871658

Epoch: 6| Step: 6
Training loss: 2.5753679275512695
Validation loss: 2.6838148101683585

Epoch: 6| Step: 7
Training loss: 3.3110098838806152
Validation loss: 2.6871625402922272

Epoch: 6| Step: 8
Training loss: 2.895641565322876
Validation loss: 2.6816937282521236

Epoch: 6| Step: 9
Training loss: 2.343317985534668
Validation loss: 2.6832594640793337

Epoch: 6| Step: 10
Training loss: 3.0068421363830566
Validation loss: 2.679524649855911

Epoch: 6| Step: 11
Training loss: 2.452549457550049
Validation loss: 2.6783692247124127

Epoch: 6| Step: 12
Training loss: 3.49229097366333
Validation loss: 2.677995281834756

Epoch: 6| Step: 13
Training loss: 1.402958631515503
Validation loss: 2.6791258935005433

Epoch: 56| Step: 0
Training loss: 3.2669599056243896
Validation loss: 2.6781085742417203

Epoch: 6| Step: 1
Training loss: 2.4565017223358154
Validation loss: 2.6797612841411302

Epoch: 6| Step: 2
Training loss: 2.9252359867095947
Validation loss: 2.6801222883244997

Epoch: 6| Step: 3
Training loss: 2.756631374359131
Validation loss: 2.6816707811047955

Epoch: 6| Step: 4
Training loss: 2.469526767730713
Validation loss: 2.693816638761951

Epoch: 6| Step: 5
Training loss: 2.741554021835327
Validation loss: 2.696538304769865

Epoch: 6| Step: 6
Training loss: 2.8397717475891113
Validation loss: 2.7100289406314975

Epoch: 6| Step: 7
Training loss: 3.4003241062164307
Validation loss: 2.711385247527912

Epoch: 6| Step: 8
Training loss: 2.93742299079895
Validation loss: 2.6982708028567735

Epoch: 6| Step: 9
Training loss: 3.369182586669922
Validation loss: 2.6908823264542447

Epoch: 6| Step: 10
Training loss: 2.8293232917785645
Validation loss: 2.680477060297484

Epoch: 6| Step: 11
Training loss: 2.39561128616333
Validation loss: 2.689810506759151

Epoch: 6| Step: 12
Training loss: 2.395225763320923
Validation loss: 2.6910003462145404

Epoch: 6| Step: 13
Training loss: 2.864832878112793
Validation loss: 2.693224791557558

Epoch: 57| Step: 0
Training loss: 2.450489044189453
Validation loss: 2.694265660419259

Epoch: 6| Step: 1
Training loss: 2.832508087158203
Validation loss: 2.6980183098905828

Epoch: 6| Step: 2
Training loss: 2.511431932449341
Validation loss: 2.697578675003462

Epoch: 6| Step: 3
Training loss: 3.2840065956115723
Validation loss: 2.6983078961731284

Epoch: 6| Step: 4
Training loss: 3.0299365520477295
Validation loss: 2.6956683897203013

Epoch: 6| Step: 5
Training loss: 2.334777593612671
Validation loss: 2.6962968123856412

Epoch: 6| Step: 6
Training loss: 2.804565906524658
Validation loss: 2.689942393251645

Epoch: 6| Step: 7
Training loss: 3.293454647064209
Validation loss: 2.6821828144852833

Epoch: 6| Step: 8
Training loss: 2.97874116897583
Validation loss: 2.6791829678320114

Epoch: 6| Step: 9
Training loss: 2.61100697517395
Validation loss: 2.6760962547794467

Epoch: 6| Step: 10
Training loss: 2.7732889652252197
Validation loss: 2.6755860518383723

Epoch: 6| Step: 11
Training loss: 3.2110438346862793
Validation loss: 2.6757424159716536

Epoch: 6| Step: 12
Training loss: 2.91554594039917
Validation loss: 2.675493614647978

Epoch: 6| Step: 13
Training loss: 2.3907601833343506
Validation loss: 2.677586337571503

Epoch: 58| Step: 0
Training loss: 3.4362897872924805
Validation loss: 2.675277284396592

Epoch: 6| Step: 1
Training loss: 4.231575012207031
Validation loss: 2.678428870375438

Epoch: 6| Step: 2
Training loss: 2.5135579109191895
Validation loss: 2.6777583988763953

Epoch: 6| Step: 3
Training loss: 3.111880302429199
Validation loss: 2.6806490985296105

Epoch: 6| Step: 4
Training loss: 1.8851240873336792
Validation loss: 2.684534647131479

Epoch: 6| Step: 5
Training loss: 3.4704089164733887
Validation loss: 2.6838288589190413

Epoch: 6| Step: 6
Training loss: 3.129190683364868
Validation loss: 2.685371470707719

Epoch: 6| Step: 7
Training loss: 2.602935314178467
Validation loss: 2.6798895559003277

Epoch: 6| Step: 8
Training loss: 2.8906607627868652
Validation loss: 2.680392098683183

Epoch: 6| Step: 9
Training loss: 2.9429898262023926
Validation loss: 2.673886481151786

Epoch: 6| Step: 10
Training loss: 3.020124912261963
Validation loss: 2.67875337600708

Epoch: 6| Step: 11
Training loss: 2.3270108699798584
Validation loss: 2.6740559377977924

Epoch: 6| Step: 12
Training loss: 1.4344024658203125
Validation loss: 2.673204796288603

Epoch: 6| Step: 13
Training loss: 2.1856324672698975
Validation loss: 2.67422152591008

Epoch: 59| Step: 0
Training loss: 2.4243175983428955
Validation loss: 2.670762910637804

Epoch: 6| Step: 1
Training loss: 2.411086320877075
Validation loss: 2.6712509483419438

Epoch: 6| Step: 2
Training loss: 2.6713056564331055
Validation loss: 2.6713220304058445

Epoch: 6| Step: 3
Training loss: 2.7979073524475098
Validation loss: 2.673098179601854

Epoch: 6| Step: 4
Training loss: 2.703278064727783
Validation loss: 2.6733582942716536

Epoch: 6| Step: 5
Training loss: 2.735400676727295
Validation loss: 2.6745950739870787

Epoch: 6| Step: 6
Training loss: 2.61545991897583
Validation loss: 2.671536689163536

Epoch: 6| Step: 7
Training loss: 3.1446633338928223
Validation loss: 2.6733948415325535

Epoch: 6| Step: 8
Training loss: 3.5547749996185303
Validation loss: 2.67116879904142

Epoch: 6| Step: 9
Training loss: 2.5687036514282227
Validation loss: 2.6736770906756

Epoch: 6| Step: 10
Training loss: 2.8549513816833496
Validation loss: 2.67254569966306

Epoch: 6| Step: 11
Training loss: 3.646245002746582
Validation loss: 2.6739913391810592

Epoch: 6| Step: 12
Training loss: 2.6916909217834473
Validation loss: 2.6716043692763134

Epoch: 6| Step: 13
Training loss: 2.4629931449890137
Validation loss: 2.6731598710501068

Epoch: 60| Step: 0
Training loss: 2.4837963581085205
Validation loss: 2.670196415275656

Epoch: 6| Step: 1
Training loss: 3.0825858116149902
Validation loss: 2.671711011599469

Epoch: 6| Step: 2
Training loss: 2.7219815254211426
Validation loss: 2.672908821413594

Epoch: 6| Step: 3
Training loss: 3.018981456756592
Validation loss: 2.6726497886001424

Epoch: 6| Step: 4
Training loss: 3.12894344329834
Validation loss: 2.688817257522255

Epoch: 6| Step: 5
Training loss: 2.9411613941192627
Validation loss: 2.7175357444311983

Epoch: 6| Step: 6
Training loss: 3.318930149078369
Validation loss: 2.7399182460641347

Epoch: 6| Step: 7
Training loss: 3.3061635494232178
Validation loss: 2.720624262286771

Epoch: 6| Step: 8
Training loss: 3.0160117149353027
Validation loss: 2.700013178651051

Epoch: 6| Step: 9
Training loss: 2.5699877738952637
Validation loss: 2.6839999973133044

Epoch: 6| Step: 10
Training loss: 2.775634765625
Validation loss: 2.6682211019659556

Epoch: 6| Step: 11
Training loss: 2.548687219619751
Validation loss: 2.6654541723189817

Epoch: 6| Step: 12
Training loss: 2.075284719467163
Validation loss: 2.667134572100896

Epoch: 6| Step: 13
Training loss: 2.3465373516082764
Validation loss: 2.6765747736859065

Epoch: 61| Step: 0
Training loss: 2.713036060333252
Validation loss: 2.6751968758080595

Epoch: 6| Step: 1
Training loss: 2.5038466453552246
Validation loss: 2.677071427786222

Epoch: 6| Step: 2
Training loss: 3.088585376739502
Validation loss: 2.671100772837157

Epoch: 6| Step: 3
Training loss: 3.813716411590576
Validation loss: 2.6690757915537846

Epoch: 6| Step: 4
Training loss: 2.8404600620269775
Validation loss: 2.6672311213708695

Epoch: 6| Step: 5
Training loss: 3.473024845123291
Validation loss: 2.6659631472761913

Epoch: 6| Step: 6
Training loss: 3.6989569664001465
Validation loss: 2.6647679369936705

Epoch: 6| Step: 7
Training loss: 1.45782470703125
Validation loss: 2.6646381039773264

Epoch: 6| Step: 8
Training loss: 3.205519676208496
Validation loss: 2.6625673437631256

Epoch: 6| Step: 9
Training loss: 2.1514785289764404
Validation loss: 2.6636554066852858

Epoch: 6| Step: 10
Training loss: 2.8288588523864746
Validation loss: 2.6631234768898255

Epoch: 6| Step: 11
Training loss: 2.211249351501465
Validation loss: 2.666102388853668

Epoch: 6| Step: 12
Training loss: 2.5375664234161377
Validation loss: 2.6668952152293217

Epoch: 6| Step: 13
Training loss: 2.922912120819092
Validation loss: 2.6656082035392843

Epoch: 62| Step: 0
Training loss: 3.015465497970581
Validation loss: 2.666342350744432

Epoch: 6| Step: 1
Training loss: 3.317814588546753
Validation loss: 2.6624865737012637

Epoch: 6| Step: 2
Training loss: 3.733738422393799
Validation loss: 2.6632920054979223

Epoch: 6| Step: 3
Training loss: 2.356031894683838
Validation loss: 2.6608298183769308

Epoch: 6| Step: 4
Training loss: 2.997748851776123
Validation loss: 2.6616799446844284

Epoch: 6| Step: 5
Training loss: 2.454070568084717
Validation loss: 2.661350727081299

Epoch: 6| Step: 6
Training loss: 3.297440767288208
Validation loss: 2.660940562525103

Epoch: 6| Step: 7
Training loss: 2.7682859897613525
Validation loss: 2.662522715906943

Epoch: 6| Step: 8
Training loss: 2.720639705657959
Validation loss: 2.6611977469536567

Epoch: 6| Step: 9
Training loss: 2.2694149017333984
Validation loss: 2.6610804809037076

Epoch: 6| Step: 10
Training loss: 3.3251047134399414
Validation loss: 2.6605945633303736

Epoch: 6| Step: 11
Training loss: 2.524266004562378
Validation loss: 2.6601552322346675

Epoch: 6| Step: 12
Training loss: 1.8142926692962646
Validation loss: 2.6600465774536133

Epoch: 6| Step: 13
Training loss: 2.730727195739746
Validation loss: 2.6592079362561627

Epoch: 63| Step: 0
Training loss: 3.663980484008789
Validation loss: 2.6572132238777737

Epoch: 6| Step: 1
Training loss: 2.581562042236328
Validation loss: 2.6595075873918432

Epoch: 6| Step: 2
Training loss: 1.7196184396743774
Validation loss: 2.6581957006967194

Epoch: 6| Step: 3
Training loss: 2.081651210784912
Validation loss: 2.656571302362668

Epoch: 6| Step: 4
Training loss: 3.109576940536499
Validation loss: 2.659697881308935

Epoch: 6| Step: 5
Training loss: 3.6714227199554443
Validation loss: 2.6594743164636756

Epoch: 6| Step: 6
Training loss: 2.917602062225342
Validation loss: 2.660272467520929

Epoch: 6| Step: 7
Training loss: 2.992295503616333
Validation loss: 2.6605069842389835

Epoch: 6| Step: 8
Training loss: 3.4270095825195312
Validation loss: 2.65590073216346

Epoch: 6| Step: 9
Training loss: 2.1726396083831787
Validation loss: 2.6565405989205964

Epoch: 6| Step: 10
Training loss: 2.6498658657073975
Validation loss: 2.65648583058388

Epoch: 6| Step: 11
Training loss: 2.836418390274048
Validation loss: 2.6568485767610612

Epoch: 6| Step: 12
Training loss: 2.4064106941223145
Validation loss: 2.6529281882829565

Epoch: 6| Step: 13
Training loss: 3.2034058570861816
Validation loss: 2.655517570434078

Epoch: 64| Step: 0
Training loss: 3.0906057357788086
Validation loss: 2.6560717449393323

Epoch: 6| Step: 1
Training loss: 2.2329466342926025
Validation loss: 2.655736595071772

Epoch: 6| Step: 2
Training loss: 2.7046773433685303
Validation loss: 2.6560133939148276

Epoch: 6| Step: 3
Training loss: 2.6852216720581055
Validation loss: 2.6558016833438667

Epoch: 6| Step: 4
Training loss: 3.936666250228882
Validation loss: 2.6561980580770843

Epoch: 6| Step: 5
Training loss: 2.407273530960083
Validation loss: 2.656148741322179

Epoch: 6| Step: 6
Training loss: 2.898014545440674
Validation loss: 2.654810474764916

Epoch: 6| Step: 7
Training loss: 2.924107074737549
Validation loss: 2.6535922660622546

Epoch: 6| Step: 8
Training loss: 2.164531707763672
Validation loss: 2.65494938306911

Epoch: 6| Step: 9
Training loss: 2.8575892448425293
Validation loss: 2.6544610351644535

Epoch: 6| Step: 10
Training loss: 2.4853110313415527
Validation loss: 2.655409005380446

Epoch: 6| Step: 11
Training loss: 3.7829039096832275
Validation loss: 2.6553081209941576

Epoch: 6| Step: 12
Training loss: 2.341707229614258
Validation loss: 2.659027435446298

Epoch: 6| Step: 13
Training loss: 2.68613338470459
Validation loss: 2.65755198847863

Epoch: 65| Step: 0
Training loss: 2.6496798992156982
Validation loss: 2.656154291604155

Epoch: 6| Step: 1
Training loss: 2.484949827194214
Validation loss: 2.6532623383306686

Epoch: 6| Step: 2
Training loss: 1.9556512832641602
Validation loss: 2.653838034599058

Epoch: 6| Step: 3
Training loss: 3.6092257499694824
Validation loss: 2.6563364357076664

Epoch: 6| Step: 4
Training loss: 2.6023106575012207
Validation loss: 2.6610676447550454

Epoch: 6| Step: 5
Training loss: 3.2430121898651123
Validation loss: 2.655572288779802

Epoch: 6| Step: 6
Training loss: 2.7780990600585938
Validation loss: 2.653198472915157

Epoch: 6| Step: 7
Training loss: 2.1688642501831055
Validation loss: 2.651473932368781

Epoch: 6| Step: 8
Training loss: 2.2926104068756104
Validation loss: 2.6532169080549672

Epoch: 6| Step: 9
Training loss: 2.8505477905273438
Validation loss: 2.652002634540681

Epoch: 6| Step: 10
Training loss: 3.4110326766967773
Validation loss: 2.6512586660282587

Epoch: 6| Step: 11
Training loss: 3.130725383758545
Validation loss: 2.651637323441044

Epoch: 6| Step: 12
Training loss: 3.0306129455566406
Validation loss: 2.653427467551283

Epoch: 6| Step: 13
Training loss: 3.2065072059631348
Validation loss: 2.6555157579401487

Epoch: 66| Step: 0
Training loss: 2.7451329231262207
Validation loss: 2.655102542651597

Epoch: 6| Step: 1
Training loss: 3.813997268676758
Validation loss: 2.649901872040123

Epoch: 6| Step: 2
Training loss: 2.5783042907714844
Validation loss: 2.6508070063847367

Epoch: 6| Step: 3
Training loss: 2.6989712715148926
Validation loss: 2.6534353968917683

Epoch: 6| Step: 4
Training loss: 3.35722017288208
Validation loss: 2.6507786550829486

Epoch: 6| Step: 5
Training loss: 2.126728057861328
Validation loss: 2.651164698344405

Epoch: 6| Step: 6
Training loss: 2.772448778152466
Validation loss: 2.6525518484013055

Epoch: 6| Step: 7
Training loss: 2.2880916595458984
Validation loss: 2.649028370457311

Epoch: 6| Step: 8
Training loss: 2.360399007797241
Validation loss: 2.6488520201816352

Epoch: 6| Step: 9
Training loss: 2.3468565940856934
Validation loss: 2.6503559671422487

Epoch: 6| Step: 10
Training loss: 2.7286300659179688
Validation loss: 2.649509560677313

Epoch: 6| Step: 11
Training loss: 3.0675179958343506
Validation loss: 2.650528436066002

Epoch: 6| Step: 12
Training loss: 3.267176628112793
Validation loss: 2.6532518171495005

Epoch: 6| Step: 13
Training loss: 3.248727321624756
Validation loss: 2.655581884486701

Epoch: 67| Step: 0
Training loss: 2.656494379043579
Validation loss: 2.6529350203852498

Epoch: 6| Step: 1
Training loss: 2.7207584381103516
Validation loss: 2.658896892301498

Epoch: 6| Step: 2
Training loss: 3.166710376739502
Validation loss: 2.6564075228988484

Epoch: 6| Step: 3
Training loss: 2.6814017295837402
Validation loss: 2.6525782372361872

Epoch: 6| Step: 4
Training loss: 3.0934925079345703
Validation loss: 2.649774407827726

Epoch: 6| Step: 5
Training loss: 2.710437297821045
Validation loss: 2.650331799701978

Epoch: 6| Step: 6
Training loss: 2.3320095539093018
Validation loss: 2.6497835830975602

Epoch: 6| Step: 7
Training loss: 2.28104829788208
Validation loss: 2.647209031607515

Epoch: 6| Step: 8
Training loss: 3.3574633598327637
Validation loss: 2.647501876277308

Epoch: 6| Step: 9
Training loss: 2.538513660430908
Validation loss: 2.6452390173430085

Epoch: 6| Step: 10
Training loss: 2.4434287548065186
Validation loss: 2.646255544436875

Epoch: 6| Step: 11
Training loss: 2.4000182151794434
Validation loss: 2.6480259408232985

Epoch: 6| Step: 12
Training loss: 3.2845258712768555
Validation loss: 2.6501014617181595

Epoch: 6| Step: 13
Training loss: 4.090601444244385
Validation loss: 2.6461440209419496

Epoch: 68| Step: 0
Training loss: 3.1564292907714844
Validation loss: 2.6498649376694874

Epoch: 6| Step: 1
Training loss: 2.733945846557617
Validation loss: 2.6484749368442

Epoch: 6| Step: 2
Training loss: 2.4286375045776367
Validation loss: 2.6466511013687297

Epoch: 6| Step: 3
Training loss: 3.144680976867676
Validation loss: 2.648687413943711

Epoch: 6| Step: 4
Training loss: 2.7014145851135254
Validation loss: 2.6463911943538214

Epoch: 6| Step: 5
Training loss: 2.6071057319641113
Validation loss: 2.645496783717986

Epoch: 6| Step: 6
Training loss: 2.350416898727417
Validation loss: 2.646459505122195

Epoch: 6| Step: 7
Training loss: 2.7677195072174072
Validation loss: 2.6435737148407967

Epoch: 6| Step: 8
Training loss: 3.555121421813965
Validation loss: 2.6460301594067643

Epoch: 6| Step: 9
Training loss: 3.0164153575897217
Validation loss: 2.644577810841222

Epoch: 6| Step: 10
Training loss: 3.2210264205932617
Validation loss: 2.6458810093582317

Epoch: 6| Step: 11
Training loss: 1.9984462261199951
Validation loss: 2.644149000926684

Epoch: 6| Step: 12
Training loss: 2.6050376892089844
Validation loss: 2.64520776015456

Epoch: 6| Step: 13
Training loss: 2.9948184490203857
Validation loss: 2.6424801477821926

Epoch: 69| Step: 0
Training loss: 3.8916587829589844
Validation loss: 2.643366370149838

Epoch: 6| Step: 1
Training loss: 2.6996121406555176
Validation loss: 2.6422952144376692

Epoch: 6| Step: 2
Training loss: 2.361591339111328
Validation loss: 2.6435208115526425

Epoch: 6| Step: 3
Training loss: 2.5901026725769043
Validation loss: 2.6458539962768555

Epoch: 6| Step: 4
Training loss: 2.787266254425049
Validation loss: 2.6426163822092037

Epoch: 6| Step: 5
Training loss: 2.555751323699951
Validation loss: 2.642398485573389

Epoch: 6| Step: 6
Training loss: 3.090693235397339
Validation loss: 2.642758410464051

Epoch: 6| Step: 7
Training loss: 2.517622232437134
Validation loss: 2.6417483719446326

Epoch: 6| Step: 8
Training loss: 2.10573673248291
Validation loss: 2.6419520275567168

Epoch: 6| Step: 9
Training loss: 2.5583317279815674
Validation loss: 2.641229086024787

Epoch: 6| Step: 10
Training loss: 2.859956741333008
Validation loss: 2.6458317336215766

Epoch: 6| Step: 11
Training loss: 3.5856215953826904
Validation loss: 2.6441699997071297

Epoch: 6| Step: 12
Training loss: 3.2974765300750732
Validation loss: 2.6478257025441816

Epoch: 6| Step: 13
Training loss: 1.794077754020691
Validation loss: 2.646562058438537

Epoch: 70| Step: 0
Training loss: 2.4951705932617188
Validation loss: 2.647992754495272

Epoch: 6| Step: 1
Training loss: 2.6572213172912598
Validation loss: 2.6486005757444646

Epoch: 6| Step: 2
Training loss: 3.182504177093506
Validation loss: 2.646586351497199

Epoch: 6| Step: 3
Training loss: 2.659221649169922
Validation loss: 2.647225231252691

Epoch: 6| Step: 4
Training loss: 2.6066300868988037
Validation loss: 2.645536161238147

Epoch: 6| Step: 5
Training loss: 3.0473833084106445
Validation loss: 2.6473359241280505

Epoch: 6| Step: 6
Training loss: 1.9966102838516235
Validation loss: 2.6518031679173952

Epoch: 6| Step: 7
Training loss: 2.9403226375579834
Validation loss: 2.643227026026736

Epoch: 6| Step: 8
Training loss: 2.3194522857666016
Validation loss: 2.6395624581203667

Epoch: 6| Step: 9
Training loss: 3.239269733428955
Validation loss: 2.6440540641866703

Epoch: 6| Step: 10
Training loss: 3.045492649078369
Validation loss: 2.6398658778077815

Epoch: 6| Step: 11
Training loss: 2.8790738582611084
Validation loss: 2.637456727284257

Epoch: 6| Step: 12
Training loss: 3.0026063919067383
Validation loss: 2.6423782763942594

Epoch: 6| Step: 13
Training loss: 3.130427837371826
Validation loss: 2.640420139476817

Epoch: 71| Step: 0
Training loss: 3.0799193382263184
Validation loss: 2.637971334559943

Epoch: 6| Step: 1
Training loss: 2.3902180194854736
Validation loss: 2.6405724094760035

Epoch: 6| Step: 2
Training loss: 3.40498685836792
Validation loss: 2.6409696481561147

Epoch: 6| Step: 3
Training loss: 2.349555253982544
Validation loss: 2.6396613736306467

Epoch: 6| Step: 4
Training loss: 3.2450647354125977
Validation loss: 2.638961120318341

Epoch: 6| Step: 5
Training loss: 1.6729599237442017
Validation loss: 2.640581141236008

Epoch: 6| Step: 6
Training loss: 3.2307872772216797
Validation loss: 2.640593215983401

Epoch: 6| Step: 7
Training loss: 2.5621089935302734
Validation loss: 2.6405328396827943

Epoch: 6| Step: 8
Training loss: 3.7205238342285156
Validation loss: 2.64174751312502

Epoch: 6| Step: 9
Training loss: 3.0312275886535645
Validation loss: 2.6410072926552064

Epoch: 6| Step: 10
Training loss: 2.73173189163208
Validation loss: 2.6414389200108026

Epoch: 6| Step: 11
Training loss: 2.748699426651001
Validation loss: 2.6384217508377565

Epoch: 6| Step: 12
Training loss: 2.152876853942871
Validation loss: 2.637967683935678

Epoch: 6| Step: 13
Training loss: 2.6902425289154053
Validation loss: 2.6362270309079077

Epoch: 72| Step: 0
Training loss: 3.157902240753174
Validation loss: 2.638874541046799

Epoch: 6| Step: 1
Training loss: 4.283419609069824
Validation loss: 2.640183589791739

Epoch: 6| Step: 2
Training loss: 2.783573627471924
Validation loss: 2.6347870108901814

Epoch: 6| Step: 3
Training loss: 2.0206246376037598
Validation loss: 2.638543462240568

Epoch: 6| Step: 4
Training loss: 1.8810946941375732
Validation loss: 2.637114465877574

Epoch: 6| Step: 5
Training loss: 2.6065468788146973
Validation loss: 2.6389847288849535

Epoch: 6| Step: 6
Training loss: 3.065847635269165
Validation loss: 2.6377604802449546

Epoch: 6| Step: 7
Training loss: 2.3742642402648926
Validation loss: 2.6380844885303127

Epoch: 6| Step: 8
Training loss: 2.5005459785461426
Validation loss: 2.63733160367576

Epoch: 6| Step: 9
Training loss: 3.0218982696533203
Validation loss: 2.6349325282599336

Epoch: 6| Step: 10
Training loss: 3.3184995651245117
Validation loss: 2.633625222790626

Epoch: 6| Step: 11
Training loss: 2.1153180599212646
Validation loss: 2.6321425822473343

Epoch: 6| Step: 12
Training loss: 2.871819257736206
Validation loss: 2.63335153108002

Epoch: 6| Step: 13
Training loss: 3.186131477355957
Validation loss: 2.6329023248405865

Epoch: 73| Step: 0
Training loss: 2.587512969970703
Validation loss: 2.632687614810082

Epoch: 6| Step: 1
Training loss: 2.0844788551330566
Validation loss: 2.633762372437344

Epoch: 6| Step: 2
Training loss: 2.7506768703460693
Validation loss: 2.6329401359763196

Epoch: 6| Step: 3
Training loss: 3.005992889404297
Validation loss: 2.633341976391372

Epoch: 6| Step: 4
Training loss: 3.0028843879699707
Validation loss: 2.6446274890694568

Epoch: 6| Step: 5
Training loss: 3.1137924194335938
Validation loss: 2.6439523517444568

Epoch: 6| Step: 6
Training loss: 2.685062885284424
Validation loss: 2.647266523812407

Epoch: 6| Step: 7
Training loss: 3.2044544219970703
Validation loss: 2.6364139920921734

Epoch: 6| Step: 8
Training loss: 2.5774381160736084
Validation loss: 2.634097986323859

Epoch: 6| Step: 9
Training loss: 2.675513744354248
Validation loss: 2.6352268854777017

Epoch: 6| Step: 10
Training loss: 2.609497547149658
Validation loss: 2.634638838870551

Epoch: 6| Step: 11
Training loss: 2.5447065830230713
Validation loss: 2.63908245999326

Epoch: 6| Step: 12
Training loss: 3.492748260498047
Validation loss: 2.6417735033137824

Epoch: 6| Step: 13
Training loss: 2.6226987838745117
Validation loss: 2.6447871679900796

Epoch: 74| Step: 0
Training loss: 2.3370635509490967
Validation loss: 2.649074876180259

Epoch: 6| Step: 1
Training loss: 3.0016531944274902
Validation loss: 2.6479806823115193

Epoch: 6| Step: 2
Training loss: 2.869591236114502
Validation loss: 2.6469952624331237

Epoch: 6| Step: 3
Training loss: 2.1831531524658203
Validation loss: 2.6450119941465315

Epoch: 6| Step: 4
Training loss: 2.0512912273406982
Validation loss: 2.652535071936987

Epoch: 6| Step: 5
Training loss: 2.5133867263793945
Validation loss: 2.6528037312210246

Epoch: 6| Step: 6
Training loss: 3.611203193664551
Validation loss: 2.64737029229441

Epoch: 6| Step: 7
Training loss: 2.6016345024108887
Validation loss: 2.6451083229434107

Epoch: 6| Step: 8
Training loss: 3.174166679382324
Validation loss: 2.634035700110979

Epoch: 6| Step: 9
Training loss: 2.880612850189209
Validation loss: 2.629943447728311

Epoch: 6| Step: 10
Training loss: 3.0007786750793457
Validation loss: 2.6274615128835044

Epoch: 6| Step: 11
Training loss: 3.2978098392486572
Validation loss: 2.6285623491451306

Epoch: 6| Step: 12
Training loss: 3.0102648735046387
Validation loss: 2.629716944950883

Epoch: 6| Step: 13
Training loss: 2.404723882675171
Validation loss: 2.6322776271450903

Epoch: 75| Step: 0
Training loss: 3.3870797157287598
Validation loss: 2.629265990308536

Epoch: 6| Step: 1
Training loss: 2.3518526554107666
Validation loss: 2.628826486167087

Epoch: 6| Step: 2
Training loss: 3.002432107925415
Validation loss: 2.626893166572817

Epoch: 6| Step: 3
Training loss: 2.9258856773376465
Validation loss: 2.631539724206412

Epoch: 6| Step: 4
Training loss: 3.415557384490967
Validation loss: 2.631741116123815

Epoch: 6| Step: 5
Training loss: 3.3536019325256348
Validation loss: 2.6413272939702517

Epoch: 6| Step: 6
Training loss: 2.821505546569824
Validation loss: 2.636844427354874

Epoch: 6| Step: 7
Training loss: 1.806488037109375
Validation loss: 2.6354636017994215

Epoch: 6| Step: 8
Training loss: 2.496495485305786
Validation loss: 2.6291597966224916

Epoch: 6| Step: 9
Training loss: 3.004981517791748
Validation loss: 2.628799412840156

Epoch: 6| Step: 10
Training loss: 2.723057270050049
Validation loss: 2.6294513569083264

Epoch: 6| Step: 11
Training loss: 2.410051107406616
Validation loss: 2.6345183387879403

Epoch: 6| Step: 12
Training loss: 3.079190254211426
Validation loss: 2.628483510786487

Epoch: 6| Step: 13
Training loss: 1.7935456037521362
Validation loss: 2.628950144654961

Epoch: 76| Step: 0
Training loss: 2.6237330436706543
Validation loss: 2.6289852434589016

Epoch: 6| Step: 1
Training loss: 2.1213879585266113
Validation loss: 2.630353778921148

Epoch: 6| Step: 2
Training loss: 3.342390537261963
Validation loss: 2.6296990994484193

Epoch: 6| Step: 3
Training loss: 3.06339168548584
Validation loss: 2.6276379067410707

Epoch: 6| Step: 4
Training loss: 2.7390801906585693
Validation loss: 2.6261431837594635

Epoch: 6| Step: 5
Training loss: 3.193824291229248
Validation loss: 2.6262483904438634

Epoch: 6| Step: 6
Training loss: 2.917874813079834
Validation loss: 2.6245472482455674

Epoch: 6| Step: 7
Training loss: 2.422788143157959
Validation loss: 2.6230290576975834

Epoch: 6| Step: 8
Training loss: 2.263814926147461
Validation loss: 2.623513167904269

Epoch: 6| Step: 9
Training loss: 2.697599411010742
Validation loss: 2.624831412428169

Epoch: 6| Step: 10
Training loss: 2.3552322387695312
Validation loss: 2.6242186151525027

Epoch: 6| Step: 11
Training loss: 2.5417120456695557
Validation loss: 2.6226601805738223

Epoch: 6| Step: 12
Training loss: 3.640226364135742
Validation loss: 2.623554757846299

Epoch: 6| Step: 13
Training loss: 3.2038259506225586
Validation loss: 2.624087784879951

Epoch: 77| Step: 0
Training loss: 2.6584601402282715
Validation loss: 2.6208405904872443

Epoch: 6| Step: 1
Training loss: 2.3863017559051514
Validation loss: 2.6230529521101262

Epoch: 6| Step: 2
Training loss: 3.132967710494995
Validation loss: 2.6209801576470815

Epoch: 6| Step: 3
Training loss: 2.8968868255615234
Validation loss: 2.6200316567574777

Epoch: 6| Step: 4
Training loss: 1.9033432006835938
Validation loss: 2.619853001768871

Epoch: 6| Step: 5
Training loss: 3.4160075187683105
Validation loss: 2.616981206401702

Epoch: 6| Step: 6
Training loss: 2.930135488510132
Validation loss: 2.6197727495624172

Epoch: 6| Step: 7
Training loss: 2.360250234603882
Validation loss: 2.628258619257199

Epoch: 6| Step: 8
Training loss: 3.036745309829712
Validation loss: 2.6316256446223103

Epoch: 6| Step: 9
Training loss: 2.529547929763794
Validation loss: 2.6300497311417774

Epoch: 6| Step: 10
Training loss: 3.295813798904419
Validation loss: 2.6280694443692445

Epoch: 6| Step: 11
Training loss: 2.519620418548584
Validation loss: 2.6213882174543155

Epoch: 6| Step: 12
Training loss: 3.2807061672210693
Validation loss: 2.6234966478040143

Epoch: 6| Step: 13
Training loss: 2.407843589782715
Validation loss: 2.6231257428405104

Epoch: 78| Step: 0
Training loss: 2.7338414192199707
Validation loss: 2.6221715122140865

Epoch: 6| Step: 1
Training loss: 2.4286327362060547
Validation loss: 2.6218901231724727

Epoch: 6| Step: 2
Training loss: 3.527334451675415
Validation loss: 2.6188153374579644

Epoch: 6| Step: 3
Training loss: 2.982712984085083
Validation loss: 2.620544525884813

Epoch: 6| Step: 4
Training loss: 2.064479351043701
Validation loss: 2.6210748816049225

Epoch: 6| Step: 5
Training loss: 2.740938425064087
Validation loss: 2.6234775794449674

Epoch: 6| Step: 6
Training loss: 3.2023086547851562
Validation loss: 2.624152619351623

Epoch: 6| Step: 7
Training loss: 3.1487882137298584
Validation loss: 2.6257129997335453

Epoch: 6| Step: 8
Training loss: 3.0006003379821777
Validation loss: 2.62245612759744

Epoch: 6| Step: 9
Training loss: 2.6248440742492676
Validation loss: 2.6239104194025837

Epoch: 6| Step: 10
Training loss: 2.600153684616089
Validation loss: 2.6229048005996214

Epoch: 6| Step: 11
Training loss: 2.5299534797668457
Validation loss: 2.621703081233527

Epoch: 6| Step: 12
Training loss: 3.1596834659576416
Validation loss: 2.618810325540522

Epoch: 6| Step: 13
Training loss: 1.7364773750305176
Validation loss: 2.6168583362333235

Epoch: 79| Step: 0
Training loss: 2.2899835109710693
Validation loss: 2.6166751987190655

Epoch: 6| Step: 1
Training loss: 2.903721809387207
Validation loss: 2.6181198986627723

Epoch: 6| Step: 2
Training loss: 2.6529998779296875
Validation loss: 2.6201177668827835

Epoch: 6| Step: 3
Training loss: 3.019108772277832
Validation loss: 2.6279351326727096

Epoch: 6| Step: 4
Training loss: 2.9189987182617188
Validation loss: 2.632313979569302

Epoch: 6| Step: 5
Training loss: 2.887516975402832
Validation loss: 2.636478095926264

Epoch: 6| Step: 6
Training loss: 3.4230074882507324
Validation loss: 2.6432980234904955

Epoch: 6| Step: 7
Training loss: 3.2212839126586914
Validation loss: 2.6359141411319857

Epoch: 6| Step: 8
Training loss: 2.306283950805664
Validation loss: 2.631261161578599

Epoch: 6| Step: 9
Training loss: 2.6198878288269043
Validation loss: 2.6246192198927685

Epoch: 6| Step: 10
Training loss: 3.0176122188568115
Validation loss: 2.6205929735655427

Epoch: 6| Step: 11
Training loss: 2.104140520095825
Validation loss: 2.6185533538941415

Epoch: 6| Step: 12
Training loss: 2.7409133911132812
Validation loss: 2.617653400667252

Epoch: 6| Step: 13
Training loss: 2.834484577178955
Validation loss: 2.615000699156074

Epoch: 80| Step: 0
Training loss: 2.2298426628112793
Validation loss: 2.6176961955203804

Epoch: 6| Step: 1
Training loss: 1.9637370109558105
Validation loss: 2.618731762773247

Epoch: 6| Step: 2
Training loss: 2.3390960693359375
Validation loss: 2.617549732167234

Epoch: 6| Step: 3
Training loss: 2.377514123916626
Validation loss: 2.619093697558167

Epoch: 6| Step: 4
Training loss: 3.3037991523742676
Validation loss: 2.6164623050279516

Epoch: 6| Step: 5
Training loss: 3.5838019847869873
Validation loss: 2.6166469614992858

Epoch: 6| Step: 6
Training loss: 2.0929155349731445
Validation loss: 2.6196183184141755

Epoch: 6| Step: 7
Training loss: 2.8315274715423584
Validation loss: 2.617159581953479

Epoch: 6| Step: 8
Training loss: 2.816171646118164
Validation loss: 2.621137180636006

Epoch: 6| Step: 9
Training loss: 3.156325340270996
Validation loss: 2.619385293734971

Epoch: 6| Step: 10
Training loss: 3.232854127883911
Validation loss: 2.6176662188704296

Epoch: 6| Step: 11
Training loss: 2.363025665283203
Validation loss: 2.6187726656595864

Epoch: 6| Step: 12
Training loss: 3.5212478637695312
Validation loss: 2.6181182297327186

Epoch: 6| Step: 13
Training loss: 3.2271616458892822
Validation loss: 2.618079229067731

Epoch: 81| Step: 0
Training loss: 3.441274404525757
Validation loss: 2.6162051129084762

Epoch: 6| Step: 1
Training loss: 2.814085006713867
Validation loss: 2.61356363245236

Epoch: 6| Step: 2
Training loss: 3.4326930046081543
Validation loss: 2.6142923831939697

Epoch: 6| Step: 3
Training loss: 2.492471694946289
Validation loss: 2.6144043604532876

Epoch: 6| Step: 4
Training loss: 1.9313724040985107
Validation loss: 2.612274344249438

Epoch: 6| Step: 5
Training loss: 2.04715633392334
Validation loss: 2.613412892946633

Epoch: 6| Step: 6
Training loss: 3.3603434562683105
Validation loss: 2.6127054076040945

Epoch: 6| Step: 7
Training loss: 2.026487112045288
Validation loss: 2.61374298731486

Epoch: 6| Step: 8
Training loss: 3.5912299156188965
Validation loss: 2.610411336345057

Epoch: 6| Step: 9
Training loss: 2.5972933769226074
Validation loss: 2.6136756276571624

Epoch: 6| Step: 10
Training loss: 2.389634609222412
Validation loss: 2.615349251736877

Epoch: 6| Step: 11
Training loss: 3.5097455978393555
Validation loss: 2.6182457554724907

Epoch: 6| Step: 12
Training loss: 2.741858959197998
Validation loss: 2.6172881023858183

Epoch: 6| Step: 13
Training loss: 1.9762636423110962
Validation loss: 2.615319393014395

Epoch: 82| Step: 0
Training loss: 2.322006940841675
Validation loss: 2.6187322524286087

Epoch: 6| Step: 1
Training loss: 3.2908935546875
Validation loss: 2.618246929619902

Epoch: 6| Step: 2
Training loss: 3.272749662399292
Validation loss: 2.6168764560453353

Epoch: 6| Step: 3
Training loss: 3.150373935699463
Validation loss: 2.6198362381227556

Epoch: 6| Step: 4
Training loss: 1.8151851892471313
Validation loss: 2.6183305940320416

Epoch: 6| Step: 5
Training loss: 3.520507335662842
Validation loss: 2.614356125554731

Epoch: 6| Step: 6
Training loss: 2.957679271697998
Validation loss: 2.6139879072866132

Epoch: 6| Step: 7
Training loss: 3.057328462600708
Validation loss: 2.615151782189646

Epoch: 6| Step: 8
Training loss: 2.7313876152038574
Validation loss: 2.6118160806676394

Epoch: 6| Step: 9
Training loss: 2.71407413482666
Validation loss: 2.613476530198128

Epoch: 6| Step: 10
Training loss: 2.008979558944702
Validation loss: 2.6133034793279504

Epoch: 6| Step: 11
Training loss: 2.5386738777160645
Validation loss: 2.60868211202724

Epoch: 6| Step: 12
Training loss: 2.4627256393432617
Validation loss: 2.609358444008776

Epoch: 6| Step: 13
Training loss: 2.9402527809143066
Validation loss: 2.6120859551173385

Epoch: 83| Step: 0
Training loss: 2.1668009757995605
Validation loss: 2.6150676870858796

Epoch: 6| Step: 1
Training loss: 2.760817527770996
Validation loss: 2.6200891169168616

Epoch: 6| Step: 2
Training loss: 2.8563380241394043
Validation loss: 2.627537665828582

Epoch: 6| Step: 3
Training loss: 2.556788444519043
Validation loss: 2.625465882721768

Epoch: 6| Step: 4
Training loss: 2.4674928188323975
Validation loss: 2.621819470518379

Epoch: 6| Step: 5
Training loss: 2.104170799255371
Validation loss: 2.6190337698946715

Epoch: 6| Step: 6
Training loss: 3.2409844398498535
Validation loss: 2.615913880768643

Epoch: 6| Step: 7
Training loss: 2.1423816680908203
Validation loss: 2.6139026252172326

Epoch: 6| Step: 8
Training loss: 3.1638193130493164
Validation loss: 2.6102197272803194

Epoch: 6| Step: 9
Training loss: 3.349609136581421
Validation loss: 2.6093051536108858

Epoch: 6| Step: 10
Training loss: 2.881777763366699
Validation loss: 2.6082319700589744

Epoch: 6| Step: 11
Training loss: 2.7929434776306152
Validation loss: 2.6064324327694472

Epoch: 6| Step: 12
Training loss: 2.9290432929992676
Validation loss: 2.6083477030518236

Epoch: 6| Step: 13
Training loss: 3.9916224479675293
Validation loss: 2.61003807539581

Epoch: 84| Step: 0
Training loss: 2.290501594543457
Validation loss: 2.6095882731099285

Epoch: 6| Step: 1
Training loss: 3.0683834552764893
Validation loss: 2.6098586820786998

Epoch: 6| Step: 2
Training loss: 2.403656482696533
Validation loss: 2.6122461621479323

Epoch: 6| Step: 3
Training loss: 2.977847099304199
Validation loss: 2.6139711667132635

Epoch: 6| Step: 4
Training loss: 3.646472454071045
Validation loss: 2.6130110704770653

Epoch: 6| Step: 5
Training loss: 2.137540817260742
Validation loss: 2.6100462713549213

Epoch: 6| Step: 6
Training loss: 2.694007396697998
Validation loss: 2.616967752415647

Epoch: 6| Step: 7
Training loss: 2.5350089073181152
Validation loss: 2.6110443197270876

Epoch: 6| Step: 8
Training loss: 3.3904263973236084
Validation loss: 2.606590429941813

Epoch: 6| Step: 9
Training loss: 2.5207903385162354
Validation loss: 2.6081499873950915

Epoch: 6| Step: 10
Training loss: 2.559856414794922
Validation loss: 2.6064287872724634

Epoch: 6| Step: 11
Training loss: 1.8590457439422607
Validation loss: 2.6036869325945453

Epoch: 6| Step: 12
Training loss: 3.8551011085510254
Validation loss: 2.6028512113837787

Epoch: 6| Step: 13
Training loss: 2.6803736686706543
Validation loss: 2.602784623381912

Epoch: 85| Step: 0
Training loss: 2.31269907951355
Validation loss: 2.6036325782857914

Epoch: 6| Step: 1
Training loss: 2.819833517074585
Validation loss: 2.6028014024098716

Epoch: 6| Step: 2
Training loss: 3.374858856201172
Validation loss: 2.604555365859821

Epoch: 6| Step: 3
Training loss: 2.609560012817383
Validation loss: 2.6050603235921552

Epoch: 6| Step: 4
Training loss: 3.3542933464050293
Validation loss: 2.6058326716064126

Epoch: 6| Step: 5
Training loss: 2.5944695472717285
Validation loss: 2.606016646149338

Epoch: 6| Step: 6
Training loss: 3.1007893085479736
Validation loss: 2.6012556245250087

Epoch: 6| Step: 7
Training loss: 3.200490951538086
Validation loss: 2.60287445334978

Epoch: 6| Step: 8
Training loss: 1.8711388111114502
Validation loss: 2.6052464464659333

Epoch: 6| Step: 9
Training loss: 2.9906387329101562
Validation loss: 2.605045936440909

Epoch: 6| Step: 10
Training loss: 2.1132473945617676
Validation loss: 2.6056623689589964

Epoch: 6| Step: 11
Training loss: 2.7221240997314453
Validation loss: 2.6028323686251076

Epoch: 6| Step: 12
Training loss: 2.933349609375
Validation loss: 2.6084708295842653

Epoch: 6| Step: 13
Training loss: 2.5632665157318115
Validation loss: 2.6069532466191117

Epoch: 86| Step: 0
Training loss: 3.5981171131134033
Validation loss: 2.6088408500917497

Epoch: 6| Step: 1
Training loss: 2.3211770057678223
Validation loss: 2.6047064283842682

Epoch: 6| Step: 2
Training loss: 3.4214887619018555
Validation loss: 2.604379787239977

Epoch: 6| Step: 3
Training loss: 2.9684267044067383
Validation loss: 2.60372563844086

Epoch: 6| Step: 4
Training loss: 2.790088653564453
Validation loss: 2.6000913855850056

Epoch: 6| Step: 5
Training loss: 3.0512194633483887
Validation loss: 2.60191092183513

Epoch: 6| Step: 6
Training loss: 3.487985610961914
Validation loss: 2.600164254506429

Epoch: 6| Step: 7
Training loss: 2.389819622039795
Validation loss: 2.5988819022332468

Epoch: 6| Step: 8
Training loss: 2.835099935531616
Validation loss: 2.6008951458879697

Epoch: 6| Step: 9
Training loss: 2.5157527923583984
Validation loss: 2.599598479527299

Epoch: 6| Step: 10
Training loss: 1.580216884613037
Validation loss: 2.6038884616667226

Epoch: 6| Step: 11
Training loss: 2.4799389839172363
Validation loss: 2.6046915079957698

Epoch: 6| Step: 12
Training loss: 2.6768269538879395
Validation loss: 2.6051506252699

Epoch: 6| Step: 13
Training loss: 2.228296995162964
Validation loss: 2.6059442976469636

Epoch: 87| Step: 0
Training loss: 3.3150367736816406
Validation loss: 2.6033062832329863

Epoch: 6| Step: 1
Training loss: 2.4063639640808105
Validation loss: 2.6035382183649207

Epoch: 6| Step: 2
Training loss: 3.030482769012451
Validation loss: 2.6010529610418502

Epoch: 6| Step: 3
Training loss: 2.6784863471984863
Validation loss: 2.600168425549743

Epoch: 6| Step: 4
Training loss: 2.307962417602539
Validation loss: 2.602799082315096

Epoch: 6| Step: 5
Training loss: 2.478372573852539
Validation loss: 2.5983807066435456

Epoch: 6| Step: 6
Training loss: 3.3614048957824707
Validation loss: 2.5982286263537664

Epoch: 6| Step: 7
Training loss: 2.756783962249756
Validation loss: 2.599808346840643

Epoch: 6| Step: 8
Training loss: 2.7759766578674316
Validation loss: 2.594684877703267

Epoch: 6| Step: 9
Training loss: 2.5964770317077637
Validation loss: 2.6005623468788723

Epoch: 6| Step: 10
Training loss: 2.0864758491516113
Validation loss: 2.597087393524826

Epoch: 6| Step: 11
Training loss: 2.83127498626709
Validation loss: 2.59584060535636

Epoch: 6| Step: 12
Training loss: 3.270820140838623
Validation loss: 2.5952974955240884

Epoch: 6| Step: 13
Training loss: 2.5909945964813232
Validation loss: 2.5982496764070246

Epoch: 88| Step: 0
Training loss: 2.3989076614379883
Validation loss: 2.5982081941379014

Epoch: 6| Step: 1
Training loss: 3.531200885772705
Validation loss: 2.5983182307212584

Epoch: 6| Step: 2
Training loss: 2.9124083518981934
Validation loss: 2.597964576495591

Epoch: 6| Step: 3
Training loss: 1.8884475231170654
Validation loss: 2.5985904534657798

Epoch: 6| Step: 4
Training loss: 2.550251007080078
Validation loss: 2.6062297257043983

Epoch: 6| Step: 5
Training loss: 3.1380858421325684
Validation loss: 2.612928036720522

Epoch: 6| Step: 6
Training loss: 2.3140435218811035
Validation loss: 2.6081505719051568

Epoch: 6| Step: 7
Training loss: 3.3353610038757324
Validation loss: 2.6056581748429166

Epoch: 6| Step: 8
Training loss: 2.795220375061035
Validation loss: 2.6019367171872045

Epoch: 6| Step: 9
Training loss: 3.2302916049957275
Validation loss: 2.5979158673235165

Epoch: 6| Step: 10
Training loss: 2.7035999298095703
Validation loss: 2.6001666643286265

Epoch: 6| Step: 11
Training loss: 2.120407819747925
Validation loss: 2.6002740193438787

Epoch: 6| Step: 12
Training loss: 2.583284854888916
Validation loss: 2.605403461763936

Epoch: 6| Step: 13
Training loss: 3.141730785369873
Validation loss: 2.6122600314437703

Epoch: 89| Step: 0
Training loss: 1.6141777038574219
Validation loss: 2.618430506798529

Epoch: 6| Step: 1
Training loss: 2.061067581176758
Validation loss: 2.621544007332094

Epoch: 6| Step: 2
Training loss: 2.30647873878479
Validation loss: 2.6148542845120994

Epoch: 6| Step: 3
Training loss: 3.3396480083465576
Validation loss: 2.6097678253727574

Epoch: 6| Step: 4
Training loss: 3.6241726875305176
Validation loss: 2.598813300491661

Epoch: 6| Step: 5
Training loss: 2.243807315826416
Validation loss: 2.5947501146665184

Epoch: 6| Step: 6
Training loss: 3.0681769847869873
Validation loss: 2.592216904445361

Epoch: 6| Step: 7
Training loss: 2.6998791694641113
Validation loss: 2.5947897588053057

Epoch: 6| Step: 8
Training loss: 3.020463705062866
Validation loss: 2.5955321865697063

Epoch: 6| Step: 9
Training loss: 2.995810031890869
Validation loss: 2.613615083438094

Epoch: 6| Step: 10
Training loss: 3.040456771850586
Validation loss: 2.660160428734236

Epoch: 6| Step: 11
Training loss: 3.2527661323547363
Validation loss: 2.6919911369200675

Epoch: 6| Step: 12
Training loss: 2.6806442737579346
Validation loss: 2.6963041059432493

Epoch: 6| Step: 13
Training loss: 2.982043743133545
Validation loss: 2.6818474390173472

Epoch: 90| Step: 0
Training loss: 3.2784390449523926
Validation loss: 2.6489104993881716

Epoch: 6| Step: 1
Training loss: 3.067135810852051
Validation loss: 2.644250426241147

Epoch: 6| Step: 2
Training loss: 2.238039016723633
Validation loss: 2.6201238991111837

Epoch: 6| Step: 3
Training loss: 3.5269908905029297
Validation loss: 2.6040294631834953

Epoch: 6| Step: 4
Training loss: 2.836520195007324
Validation loss: 2.611429750278432

Epoch: 6| Step: 5
Training loss: 3.369129180908203
Validation loss: 2.6196119054671256

Epoch: 6| Step: 6
Training loss: 2.5659570693969727
Validation loss: 2.6338743522603023

Epoch: 6| Step: 7
Training loss: 1.818474531173706
Validation loss: 2.6476963412377144

Epoch: 6| Step: 8
Training loss: 2.5943727493286133
Validation loss: 2.6600282781867572

Epoch: 6| Step: 9
Training loss: 2.7247438430786133
Validation loss: 2.665194370413339

Epoch: 6| Step: 10
Training loss: 3.2661447525024414
Validation loss: 2.670171988907681

Epoch: 6| Step: 11
Training loss: 2.6243720054626465
Validation loss: 2.655315427369969

Epoch: 6| Step: 12
Training loss: 2.6180636882781982
Validation loss: 2.64007729868735

Epoch: 6| Step: 13
Training loss: 2.150646448135376
Validation loss: 2.6228741189484954

Epoch: 91| Step: 0
Training loss: 2.851133108139038
Validation loss: 2.6094376630680536

Epoch: 6| Step: 1
Training loss: 3.4712162017822266
Validation loss: 2.6006998323625132

Epoch: 6| Step: 2
Training loss: 2.3382444381713867
Validation loss: 2.591916640599569

Epoch: 6| Step: 3
Training loss: 2.9924049377441406
Validation loss: 2.5869249566908805

Epoch: 6| Step: 4
Training loss: 2.1117260456085205
Validation loss: 2.586463071966684

Epoch: 6| Step: 5
Training loss: 3.201537847518921
Validation loss: 2.588456394851849

Epoch: 6| Step: 6
Training loss: 3.0380947589874268
Validation loss: 2.5913074016571045

Epoch: 6| Step: 7
Training loss: 3.0848841667175293
Validation loss: 2.5990834748873146

Epoch: 6| Step: 8
Training loss: 2.874142646789551
Validation loss: 2.602202974339967

Epoch: 6| Step: 9
Training loss: 2.9483156204223633
Validation loss: 2.6028921373428835

Epoch: 6| Step: 10
Training loss: 1.9334897994995117
Validation loss: 2.603460350344258

Epoch: 6| Step: 11
Training loss: 2.68962025642395
Validation loss: 2.6008476416269937

Epoch: 6| Step: 12
Training loss: 2.6114823818206787
Validation loss: 2.595739728660994

Epoch: 6| Step: 13
Training loss: 2.29494047164917
Validation loss: 2.595136155364334

Epoch: 92| Step: 0
Training loss: 2.8059370517730713
Validation loss: 2.5932484314005864

Epoch: 6| Step: 1
Training loss: 2.692293405532837
Validation loss: 2.593435687403525

Epoch: 6| Step: 2
Training loss: 2.6154909133911133
Validation loss: 2.5900417809845298

Epoch: 6| Step: 3
Training loss: 2.8203041553497314
Validation loss: 2.591093409445978

Epoch: 6| Step: 4
Training loss: 2.9656565189361572
Validation loss: 2.5853009377756426

Epoch: 6| Step: 5
Training loss: 2.595266342163086
Validation loss: 2.588377239883587

Epoch: 6| Step: 6
Training loss: 2.515674352645874
Validation loss: 2.587980285767586

Epoch: 6| Step: 7
Training loss: 2.6570253372192383
Validation loss: 2.5856358774246706

Epoch: 6| Step: 8
Training loss: 2.124924659729004
Validation loss: 2.5903486077503493

Epoch: 6| Step: 9
Training loss: 3.5283401012420654
Validation loss: 2.5873342483274397

Epoch: 6| Step: 10
Training loss: 3.3977231979370117
Validation loss: 2.5859212183183238

Epoch: 6| Step: 11
Training loss: 2.0467450618743896
Validation loss: 2.585565149143178

Epoch: 6| Step: 12
Training loss: 2.809903144836426
Validation loss: 2.586979589154643

Epoch: 6| Step: 13
Training loss: 3.085618019104004
Validation loss: 2.5884795778541156

Epoch: 93| Step: 0
Training loss: 2.102778434753418
Validation loss: 2.5867892439647386

Epoch: 6| Step: 1
Training loss: 2.2978782653808594
Validation loss: 2.584817132642192

Epoch: 6| Step: 2
Training loss: 2.426168203353882
Validation loss: 2.589097930539039

Epoch: 6| Step: 3
Training loss: 1.9770455360412598
Validation loss: 2.5862830300484934

Epoch: 6| Step: 4
Training loss: 2.8602828979492188
Validation loss: 2.585387317083215

Epoch: 6| Step: 5
Training loss: 2.5472428798675537
Validation loss: 2.5869195140818113

Epoch: 6| Step: 6
Training loss: 2.677001476287842
Validation loss: 2.5865918974722586

Epoch: 6| Step: 7
Training loss: 3.761784553527832
Validation loss: 2.587579455426944

Epoch: 6| Step: 8
Training loss: 2.2113051414489746
Validation loss: 2.5860591934573267

Epoch: 6| Step: 9
Training loss: 3.313246488571167
Validation loss: 2.586410989043533

Epoch: 6| Step: 10
Training loss: 3.874876022338867
Validation loss: 2.5851664338060605

Epoch: 6| Step: 11
Training loss: 3.0226621627807617
Validation loss: 2.5861658537259666

Epoch: 6| Step: 12
Training loss: 2.76216983795166
Validation loss: 2.5892660105100243

Epoch: 6| Step: 13
Training loss: 2.4856975078582764
Validation loss: 2.588503363311932

Epoch: 94| Step: 0
Training loss: 2.3405661582946777
Validation loss: 2.5833086506012948

Epoch: 6| Step: 1
Training loss: 3.0840063095092773
Validation loss: 2.585437533675983

Epoch: 6| Step: 2
Training loss: 2.06398868560791
Validation loss: 2.581336147041731

Epoch: 6| Step: 3
Training loss: 2.4011425971984863
Validation loss: 2.584792367873653

Epoch: 6| Step: 4
Training loss: 2.6282150745391846
Validation loss: 2.5809453020813646

Epoch: 6| Step: 5
Training loss: 3.5941543579101562
Validation loss: 2.580181690954393

Epoch: 6| Step: 6
Training loss: 2.8585503101348877
Validation loss: 2.582907804878809

Epoch: 6| Step: 7
Training loss: 1.5255725383758545
Validation loss: 2.5861908646040064

Epoch: 6| Step: 8
Training loss: 2.2122642993927
Validation loss: 2.5878032561271422

Epoch: 6| Step: 9
Training loss: 3.4582679271698
Validation loss: 2.58947931310182

Epoch: 6| Step: 10
Training loss: 2.790229082107544
Validation loss: 2.5908715391671784

Epoch: 6| Step: 11
Training loss: 2.759753704071045
Validation loss: 2.592167677417878

Epoch: 6| Step: 12
Training loss: 3.906096935272217
Validation loss: 2.59497505875044

Epoch: 6| Step: 13
Training loss: 2.801494598388672
Validation loss: 2.592973311742147

Epoch: 95| Step: 0
Training loss: 3.232295274734497
Validation loss: 2.5791041389588387

Epoch: 6| Step: 1
Training loss: 3.181260108947754
Validation loss: 2.578770376020862

Epoch: 6| Step: 2
Training loss: 1.8059470653533936
Validation loss: 2.579608994145547

Epoch: 6| Step: 3
Training loss: 2.638186454772949
Validation loss: 2.579449371625018

Epoch: 6| Step: 4
Training loss: 2.5198731422424316
Validation loss: 2.579708117310719

Epoch: 6| Step: 5
Training loss: 2.2158169746398926
Validation loss: 2.578568937957928

Epoch: 6| Step: 6
Training loss: 2.429199695587158
Validation loss: 2.5785079950927408

Epoch: 6| Step: 7
Training loss: 2.6393260955810547
Validation loss: 2.5791182979460685

Epoch: 6| Step: 8
Training loss: 3.055508613586426
Validation loss: 2.5769232549974994

Epoch: 6| Step: 9
Training loss: 3.212806463241577
Validation loss: 2.57684991949348

Epoch: 6| Step: 10
Training loss: 2.7018580436706543
Validation loss: 2.5763748897019254

Epoch: 6| Step: 11
Training loss: 3.1970362663269043
Validation loss: 2.5784433887850855

Epoch: 6| Step: 12
Training loss: 3.2334868907928467
Validation loss: 2.579191179685695

Epoch: 6| Step: 13
Training loss: 2.0349819660186768
Validation loss: 2.5783166475193475

Epoch: 96| Step: 0
Training loss: 3.081015110015869
Validation loss: 2.576916428022487

Epoch: 6| Step: 1
Training loss: 2.0717082023620605
Validation loss: 2.577550034369192

Epoch: 6| Step: 2
Training loss: 3.2760963439941406
Validation loss: 2.5776254951312976

Epoch: 6| Step: 3
Training loss: 3.589470624923706
Validation loss: 2.5806231626900296

Epoch: 6| Step: 4
Training loss: 1.9957804679870605
Validation loss: 2.579490759039438

Epoch: 6| Step: 5
Training loss: 2.4358434677124023
Validation loss: 2.5788936666263047

Epoch: 6| Step: 6
Training loss: 2.9095287322998047
Validation loss: 2.577998258734262

Epoch: 6| Step: 7
Training loss: 2.415431022644043
Validation loss: 2.5785702838692615

Epoch: 6| Step: 8
Training loss: 2.9728646278381348
Validation loss: 2.5773324889521443

Epoch: 6| Step: 9
Training loss: 2.701723575592041
Validation loss: 2.57851973143957

Epoch: 6| Step: 10
Training loss: 3.5706987380981445
Validation loss: 2.5772267041667813

Epoch: 6| Step: 11
Training loss: 1.7661305665969849
Validation loss: 2.578126953494164

Epoch: 6| Step: 12
Training loss: 2.7254176139831543
Validation loss: 2.5798005391192693

Epoch: 6| Step: 13
Training loss: 2.9591588973999023
Validation loss: 2.5833713469966764

Epoch: 97| Step: 0
Training loss: 2.907180070877075
Validation loss: 2.582961231149653

Epoch: 6| Step: 1
Training loss: 3.3561224937438965
Validation loss: 2.5779043910323933

Epoch: 6| Step: 2
Training loss: 2.2922730445861816
Validation loss: 2.5809078985644924

Epoch: 6| Step: 3
Training loss: 2.908445358276367
Validation loss: 2.5783459909500612

Epoch: 6| Step: 4
Training loss: 3.018958806991577
Validation loss: 2.578872078208513

Epoch: 6| Step: 5
Training loss: 1.8764311075210571
Validation loss: 2.573874291553292

Epoch: 6| Step: 6
Training loss: 3.3838047981262207
Validation loss: 2.575919646088795

Epoch: 6| Step: 7
Training loss: 3.097947120666504
Validation loss: 2.5763299285724597

Epoch: 6| Step: 8
Training loss: 1.8540140390396118
Validation loss: 2.5735550618940786

Epoch: 6| Step: 9
Training loss: 2.3358154296875
Validation loss: 2.573301020488944

Epoch: 6| Step: 10
Training loss: 3.50929594039917
Validation loss: 2.572043252247636

Epoch: 6| Step: 11
Training loss: 2.2032957077026367
Validation loss: 2.5761955527849096

Epoch: 6| Step: 12
Training loss: 2.5429024696350098
Validation loss: 2.5763118190150105

Epoch: 6| Step: 13
Training loss: 3.3756821155548096
Validation loss: 2.5741701203007854

Epoch: 98| Step: 0
Training loss: 2.696307420730591
Validation loss: 2.5767110727166616

Epoch: 6| Step: 1
Training loss: 2.385005235671997
Validation loss: 2.5786303474057104

Epoch: 6| Step: 2
Training loss: 2.6400418281555176
Validation loss: 2.573797038806382

Epoch: 6| Step: 3
Training loss: 2.286539077758789
Validation loss: 2.572989648388278

Epoch: 6| Step: 4
Training loss: 2.9950454235076904
Validation loss: 2.5749829200006302

Epoch: 6| Step: 5
Training loss: 2.953766345977783
Validation loss: 2.57576726072578

Epoch: 6| Step: 6
Training loss: 2.6083598136901855
Validation loss: 2.5750003937752015

Epoch: 6| Step: 7
Training loss: 2.916091203689575
Validation loss: 2.576549650520407

Epoch: 6| Step: 8
Training loss: 2.542114019393921
Validation loss: 2.5775608811327206

Epoch: 6| Step: 9
Training loss: 2.383979320526123
Validation loss: 2.57732145760649

Epoch: 6| Step: 10
Training loss: 2.7982919216156006
Validation loss: 2.574473750206732

Epoch: 6| Step: 11
Training loss: 3.0350730419158936
Validation loss: 2.576128649455245

Epoch: 6| Step: 12
Training loss: 3.7857964038848877
Validation loss: 2.5772229240786646

Epoch: 6| Step: 13
Training loss: 2.019721508026123
Validation loss: 2.5748758008403163

Epoch: 99| Step: 0
Training loss: 2.6361632347106934
Validation loss: 2.5761652697799025

Epoch: 6| Step: 1
Training loss: 2.163062334060669
Validation loss: 2.5789856705614316

Epoch: 6| Step: 2
Training loss: 2.511777639389038
Validation loss: 2.5752354693669144

Epoch: 6| Step: 3
Training loss: 2.8971385955810547
Validation loss: 2.572217728502007

Epoch: 6| Step: 4
Training loss: 3.1549839973449707
Validation loss: 2.570521398257184

Epoch: 6| Step: 5
Training loss: 3.009006977081299
Validation loss: 2.57155176131956

Epoch: 6| Step: 6
Training loss: 2.7546491622924805
Validation loss: 2.571041791669784

Epoch: 6| Step: 7
Training loss: 3.1406517028808594
Validation loss: 2.5697208963414675

Epoch: 6| Step: 8
Training loss: 2.0016846656799316
Validation loss: 2.571733602913477

Epoch: 6| Step: 9
Training loss: 2.926640272140503
Validation loss: 2.5696751712470927

Epoch: 6| Step: 10
Training loss: 3.1485443115234375
Validation loss: 2.5710315524890857

Epoch: 6| Step: 11
Training loss: 2.2585678100585938
Validation loss: 2.570022713753485

Epoch: 6| Step: 12
Training loss: 3.0883522033691406
Validation loss: 2.571396876406926

Epoch: 6| Step: 13
Training loss: 2.6033201217651367
Validation loss: 2.5688188870747886

Epoch: 100| Step: 0
Training loss: 2.5954787731170654
Validation loss: 2.572354421820692

Epoch: 6| Step: 1
Training loss: 3.299504280090332
Validation loss: 2.57020963135586

Epoch: 6| Step: 2
Training loss: 2.8690454959869385
Validation loss: 2.5659145309079077

Epoch: 6| Step: 3
Training loss: 1.9324102401733398
Validation loss: 2.5653404702422438

Epoch: 6| Step: 4
Training loss: 2.1813907623291016
Validation loss: 2.5651950682363203

Epoch: 6| Step: 5
Training loss: 2.754560708999634
Validation loss: 2.5641409658616587

Epoch: 6| Step: 6
Training loss: 2.659993886947632
Validation loss: 2.564035979650354

Epoch: 6| Step: 7
Training loss: 2.689140558242798
Validation loss: 2.5664152996514433

Epoch: 6| Step: 8
Training loss: 3.249542236328125
Validation loss: 2.561922998838527

Epoch: 6| Step: 9
Training loss: 2.817366123199463
Validation loss: 2.565095768179945

Epoch: 6| Step: 10
Training loss: 2.5381171703338623
Validation loss: 2.563938189578313

Epoch: 6| Step: 11
Training loss: 3.5508413314819336
Validation loss: 2.5636754548677834

Epoch: 6| Step: 12
Training loss: 2.5606637001037598
Validation loss: 2.5622229704292874

Epoch: 6| Step: 13
Training loss: 2.424132823944092
Validation loss: 2.5635928338573826

Testing loss: 2.6712343984180027
