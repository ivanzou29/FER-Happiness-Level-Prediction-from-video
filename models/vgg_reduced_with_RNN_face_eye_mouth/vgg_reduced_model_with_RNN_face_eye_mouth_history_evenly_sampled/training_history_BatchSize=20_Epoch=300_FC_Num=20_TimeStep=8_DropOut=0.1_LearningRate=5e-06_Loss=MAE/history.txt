Epoch: 1| Step: 0
Training loss: 6.569990634918213
Validation loss: 5.2117979090700866

Epoch: 5| Step: 1
Training loss: 4.484498023986816
Validation loss: 5.206858019674978

Epoch: 5| Step: 2
Training loss: 5.28997278213501
Validation loss: 5.201922724323888

Epoch: 5| Step: 3
Training loss: 4.8916730880737305
Validation loss: 5.1971985396518505

Epoch: 5| Step: 4
Training loss: 5.251574993133545
Validation loss: 5.192493536139048

Epoch: 5| Step: 5
Training loss: 4.1046881675720215
Validation loss: 5.188004232222034

Epoch: 5| Step: 6
Training loss: 3.9261059761047363
Validation loss: 5.183535011865759

Epoch: 5| Step: 7
Training loss: 4.9027838706970215
Validation loss: 5.179118325633388

Epoch: 5| Step: 8
Training loss: 4.91603946685791
Validation loss: 5.175058185413319

Epoch: 5| Step: 9
Training loss: 5.429258346557617
Validation loss: 5.170452415302235

Epoch: 5| Step: 10
Training loss: 5.06793737411499
Validation loss: 5.165919298766761

Epoch: 2| Step: 0
Training loss: 5.740298271179199
Validation loss: 5.161192068489649

Epoch: 5| Step: 1
Training loss: 6.158825397491455
Validation loss: 5.156218174965151

Epoch: 5| Step: 2
Training loss: 5.186738967895508
Validation loss: 5.151632006450366

Epoch: 5| Step: 3
Training loss: 4.745444297790527
Validation loss: 5.14649450138051

Epoch: 5| Step: 4
Training loss: 4.73382568359375
Validation loss: 5.1411058313103135

Epoch: 5| Step: 5
Training loss: 4.736469745635986
Validation loss: 5.135942054051225

Epoch: 5| Step: 6
Training loss: 4.815903663635254
Validation loss: 5.130104100832376

Epoch: 5| Step: 7
Training loss: 4.521964073181152
Validation loss: 5.12465851794007

Epoch: 5| Step: 8
Training loss: 4.063237190246582
Validation loss: 5.118242822667604

Epoch: 5| Step: 9
Training loss: 4.566977500915527
Validation loss: 5.111673719139509

Epoch: 5| Step: 10
Training loss: 4.966342926025391
Validation loss: 5.104783775985882

Epoch: 3| Step: 0
Training loss: 4.521778106689453
Validation loss: 5.097856921534384

Epoch: 5| Step: 1
Training loss: 5.133267402648926
Validation loss: 5.090327883279452

Epoch: 5| Step: 2
Training loss: 5.102524280548096
Validation loss: 5.082530693341327

Epoch: 5| Step: 3
Training loss: 5.236533164978027
Validation loss: 5.074182459103164

Epoch: 5| Step: 4
Training loss: 4.708968639373779
Validation loss: 5.065864809097782

Epoch: 5| Step: 5
Training loss: 4.1130547523498535
Validation loss: 5.057251868709441

Epoch: 5| Step: 6
Training loss: 4.859996795654297
Validation loss: 5.0476012640101935

Epoch: 5| Step: 7
Training loss: 4.983532428741455
Validation loss: 5.037843791387415

Epoch: 5| Step: 8
Training loss: 5.539281845092773
Validation loss: 5.026910361423288

Epoch: 5| Step: 9
Training loss: 3.875774383544922
Validation loss: 5.016674149420954

Epoch: 5| Step: 10
Training loss: 5.344583511352539
Validation loss: 5.004829540047594

Epoch: 4| Step: 0
Training loss: 4.890489101409912
Validation loss: 4.993787832157587

Epoch: 5| Step: 1
Training loss: 4.386959552764893
Validation loss: 4.980958020815286

Epoch: 5| Step: 2
Training loss: 5.199820041656494
Validation loss: 4.967986973383093

Epoch: 5| Step: 3
Training loss: 4.9268293380737305
Validation loss: 4.95434437003187

Epoch: 5| Step: 4
Training loss: 5.199526786804199
Validation loss: 4.939854724432832

Epoch: 5| Step: 5
Training loss: 4.437373638153076
Validation loss: 4.924640814463298

Epoch: 5| Step: 6
Training loss: 5.208985328674316
Validation loss: 4.909344980793614

Epoch: 5| Step: 7
Training loss: 4.640682220458984
Validation loss: 4.892994326929892

Epoch: 5| Step: 8
Training loss: 4.551441192626953
Validation loss: 4.875974070641302

Epoch: 5| Step: 9
Training loss: 3.11527681350708
Validation loss: 4.858443583211591

Epoch: 5| Step: 10
Training loss: 5.384860515594482
Validation loss: 4.838767097842309

Epoch: 5| Step: 0
Training loss: 3.733403444290161
Validation loss: 4.820213471689532

Epoch: 5| Step: 1
Training loss: 5.77288818359375
Validation loss: 4.798954743210987

Epoch: 5| Step: 2
Training loss: 4.254932403564453
Validation loss: 4.778331879646547

Epoch: 5| Step: 3
Training loss: 5.313055515289307
Validation loss: 4.757613125667777

Epoch: 5| Step: 4
Training loss: 3.5031611919403076
Validation loss: 4.733170488829254

Epoch: 5| Step: 5
Training loss: 3.995051622390747
Validation loss: 4.710613368659891

Epoch: 5| Step: 6
Training loss: 3.748257875442505
Validation loss: 4.687381349584108

Epoch: 5| Step: 7
Training loss: 4.333202362060547
Validation loss: 4.66370762548139

Epoch: 5| Step: 8
Training loss: 4.817876815795898
Validation loss: 4.639513379784041

Epoch: 5| Step: 9
Training loss: 5.372899055480957
Validation loss: 4.613618809689758

Epoch: 5| Step: 10
Training loss: 4.566974639892578
Validation loss: 4.589092936567081

Epoch: 6| Step: 0
Training loss: 5.2262372970581055
Validation loss: 4.563149436827628

Epoch: 5| Step: 1
Training loss: 4.304251670837402
Validation loss: 4.537998127680953

Epoch: 5| Step: 2
Training loss: 4.650496482849121
Validation loss: 4.51393787835234

Epoch: 5| Step: 3
Training loss: 4.232731342315674
Validation loss: 4.4876378326005835

Epoch: 5| Step: 4
Training loss: 2.789577007293701
Validation loss: 4.464173639974287

Epoch: 5| Step: 5
Training loss: 4.369358062744141
Validation loss: 4.438855171203613

Epoch: 5| Step: 6
Training loss: 3.524418592453003
Validation loss: 4.414543695347284

Epoch: 5| Step: 7
Training loss: 4.752218723297119
Validation loss: 4.390652856519146

Epoch: 5| Step: 8
Training loss: 4.227730751037598
Validation loss: 4.3668484482713925

Epoch: 5| Step: 9
Training loss: 4.104054927825928
Validation loss: 4.34666948421027

Epoch: 5| Step: 10
Training loss: 4.446997165679932
Validation loss: 4.32435287967805

Epoch: 7| Step: 0
Training loss: 4.176152229309082
Validation loss: 4.302455184280231

Epoch: 5| Step: 1
Training loss: 4.3892927169799805
Validation loss: 4.282284182886923

Epoch: 5| Step: 2
Training loss: 4.541825294494629
Validation loss: 4.262377139060728

Epoch: 5| Step: 3
Training loss: 4.377241611480713
Validation loss: 4.244102011444748

Epoch: 5| Step: 4
Training loss: 3.4189937114715576
Validation loss: 4.223603358832738

Epoch: 5| Step: 5
Training loss: 3.4637768268585205
Validation loss: 4.205688889308642

Epoch: 5| Step: 6
Training loss: 4.544093132019043
Validation loss: 4.188336044229487

Epoch: 5| Step: 7
Training loss: 4.019013404846191
Validation loss: 4.172767428941624

Epoch: 5| Step: 8
Training loss: 4.428892612457275
Validation loss: 4.156036161607312

Epoch: 5| Step: 9
Training loss: 2.803689479827881
Validation loss: 4.138326650024743

Epoch: 5| Step: 10
Training loss: 4.1186699867248535
Validation loss: 4.122904710872199

Epoch: 8| Step: 0
Training loss: 4.10882568359375
Validation loss: 4.109859430661765

Epoch: 5| Step: 1
Training loss: 3.4491188526153564
Validation loss: 4.094401041666667

Epoch: 5| Step: 2
Training loss: 4.659652233123779
Validation loss: 4.08105795357817

Epoch: 5| Step: 3
Training loss: 2.721287965774536
Validation loss: 4.067246919037194

Epoch: 5| Step: 4
Training loss: 3.2550289630889893
Validation loss: 4.053962553701093

Epoch: 5| Step: 5
Training loss: 3.333777666091919
Validation loss: 4.041224807821294

Epoch: 5| Step: 6
Training loss: 4.532289981842041
Validation loss: 4.027686270334387

Epoch: 5| Step: 7
Training loss: 3.299375534057617
Validation loss: 4.017824057609804

Epoch: 5| Step: 8
Training loss: 4.342219352722168
Validation loss: 4.007358361315983

Epoch: 5| Step: 9
Training loss: 4.7732343673706055
Validation loss: 3.994173611364057

Epoch: 5| Step: 10
Training loss: 4.258790016174316
Validation loss: 3.9804132471802416

Epoch: 9| Step: 0
Training loss: 3.7667930126190186
Validation loss: 3.9711044167959564

Epoch: 5| Step: 1
Training loss: 4.109013557434082
Validation loss: 3.9576619517418647

Epoch: 5| Step: 2
Training loss: 3.1932923793792725
Validation loss: 3.944228403029903

Epoch: 5| Step: 3
Training loss: 3.483372449874878
Validation loss: 3.9333332815477924

Epoch: 5| Step: 4
Training loss: 3.6864681243896484
Validation loss: 3.9192610402261057

Epoch: 5| Step: 5
Training loss: 5.087335586547852
Validation loss: 3.9082841078440347

Epoch: 5| Step: 6
Training loss: 3.573131561279297
Validation loss: 3.8950229050010763

Epoch: 5| Step: 7
Training loss: 4.154656410217285
Validation loss: 3.88246549073086

Epoch: 5| Step: 8
Training loss: 2.833627462387085
Validation loss: 3.870825357334588

Epoch: 5| Step: 9
Training loss: 4.649552822113037
Validation loss: 3.857424315585885

Epoch: 5| Step: 10
Training loss: 2.806584596633911
Validation loss: 3.8417986798030075

Epoch: 10| Step: 0
Training loss: 3.909748077392578
Validation loss: 3.8284597909578713

Epoch: 5| Step: 1
Training loss: 3.733877658843994
Validation loss: 3.8101754085991972

Epoch: 5| Step: 2
Training loss: 3.8223915100097656
Validation loss: 3.796612580617269

Epoch: 5| Step: 3
Training loss: 4.232272148132324
Validation loss: 3.7814241122174006

Epoch: 5| Step: 4
Training loss: 3.85542631149292
Validation loss: 3.7620467319283435

Epoch: 5| Step: 5
Training loss: 3.5917792320251465
Validation loss: 3.7515199620236634

Epoch: 5| Step: 6
Training loss: 3.8733444213867188
Validation loss: 3.737963722598168

Epoch: 5| Step: 7
Training loss: 2.9904911518096924
Validation loss: 3.7220929899523334

Epoch: 5| Step: 8
Training loss: 2.720452070236206
Validation loss: 3.708374141364969

Epoch: 5| Step: 9
Training loss: 3.852011203765869
Validation loss: 3.694034622561547

Epoch: 5| Step: 10
Training loss: 3.518422842025757
Validation loss: 3.6815871474563435

Epoch: 11| Step: 0
Training loss: 3.9453728199005127
Validation loss: 3.67091417056258

Epoch: 5| Step: 1
Training loss: 3.002638339996338
Validation loss: 3.6601516610832623

Epoch: 5| Step: 2
Training loss: 2.7472922801971436
Validation loss: 3.6434515753099994

Epoch: 5| Step: 3
Training loss: 3.7336037158966064
Validation loss: 3.634169496515746

Epoch: 5| Step: 4
Training loss: 3.0406546592712402
Validation loss: 3.622648746736588

Epoch: 5| Step: 5
Training loss: 3.0189907550811768
Validation loss: 3.612211145380492

Epoch: 5| Step: 6
Training loss: 4.463881015777588
Validation loss: 3.6024330175051125

Epoch: 5| Step: 7
Training loss: 4.225719928741455
Validation loss: 3.593048290539813

Epoch: 5| Step: 8
Training loss: 3.55122709274292
Validation loss: 3.5825866037799465

Epoch: 5| Step: 9
Training loss: 3.481717586517334
Validation loss: 3.5718294625641196

Epoch: 5| Step: 10
Training loss: 3.5798943042755127
Validation loss: 3.562790142592563

Epoch: 12| Step: 0
Training loss: 3.1975533962249756
Validation loss: 3.5534151472071165

Epoch: 5| Step: 1
Training loss: 3.5674991607666016
Validation loss: 3.543651601319672

Epoch: 5| Step: 2
Training loss: 3.336838960647583
Validation loss: 3.5325003952108402

Epoch: 5| Step: 3
Training loss: 3.3274664878845215
Validation loss: 3.521862917048957

Epoch: 5| Step: 4
Training loss: 4.019606113433838
Validation loss: 3.504417578379313

Epoch: 5| Step: 5
Training loss: 3.5758793354034424
Validation loss: 3.491380371073241

Epoch: 5| Step: 6
Training loss: 4.065012454986572
Validation loss: 3.480832294751239

Epoch: 5| Step: 7
Training loss: 3.6801109313964844
Validation loss: 3.4727896028949368

Epoch: 5| Step: 8
Training loss: 3.292492389678955
Validation loss: 3.4677630188644573

Epoch: 5| Step: 9
Training loss: 3.0541181564331055
Validation loss: 3.457005908412318

Epoch: 5| Step: 10
Training loss: 2.4739439487457275
Validation loss: 3.4489926830414803

Epoch: 13| Step: 0
Training loss: 3.259484052658081
Validation loss: 3.4368692290398384

Epoch: 5| Step: 1
Training loss: 3.998878002166748
Validation loss: 3.4302028276587047

Epoch: 5| Step: 2
Training loss: 2.742382526397705
Validation loss: 3.4195121539536344

Epoch: 5| Step: 3
Training loss: 3.0052170753479004
Validation loss: 3.412905349526354

Epoch: 5| Step: 4
Training loss: 2.9764788150787354
Validation loss: 3.4072983239286687

Epoch: 5| Step: 5
Training loss: 3.2122230529785156
Validation loss: 3.404424503285398

Epoch: 5| Step: 6
Training loss: 2.441307544708252
Validation loss: 3.3973255926562893

Epoch: 5| Step: 7
Training loss: 3.552511215209961
Validation loss: 3.396381357664703

Epoch: 5| Step: 8
Training loss: 4.278334617614746
Validation loss: 3.3942754653192337

Epoch: 5| Step: 9
Training loss: 4.029236793518066
Validation loss: 3.3865296609940065

Epoch: 5| Step: 10
Training loss: 3.3863542079925537
Validation loss: 3.3762460754763697

Epoch: 14| Step: 0
Training loss: 3.4286727905273438
Validation loss: 3.3707744741952546

Epoch: 5| Step: 1
Training loss: 3.6533660888671875
Validation loss: 3.3656094176794893

Epoch: 5| Step: 2
Training loss: 2.640958786010742
Validation loss: 3.3613887397191857

Epoch: 5| Step: 3
Training loss: 3.682126998901367
Validation loss: 3.357894479587514

Epoch: 5| Step: 4
Training loss: 2.9820637702941895
Validation loss: 3.3513037414960962

Epoch: 5| Step: 5
Training loss: 3.787649631500244
Validation loss: 3.34963797753857

Epoch: 5| Step: 6
Training loss: 3.639756441116333
Validation loss: 3.3453896276412474

Epoch: 5| Step: 7
Training loss: 2.6198019981384277
Validation loss: 3.3427204855026735

Epoch: 5| Step: 8
Training loss: 3.009615421295166
Validation loss: 3.3386619167943157

Epoch: 5| Step: 9
Training loss: 3.13581919670105
Validation loss: 3.3346190811485372

Epoch: 5| Step: 10
Training loss: 3.9111812114715576
Validation loss: 3.3318910573118474

Epoch: 15| Step: 0
Training loss: 3.6678872108459473
Validation loss: 3.3276124923459944

Epoch: 5| Step: 1
Training loss: 2.705019474029541
Validation loss: 3.32332435987329

Epoch: 5| Step: 2
Training loss: 2.6815383434295654
Validation loss: 3.318758818411058

Epoch: 5| Step: 3
Training loss: 3.019871950149536
Validation loss: 3.3142788846005677

Epoch: 5| Step: 4
Training loss: 4.247264385223389
Validation loss: 3.312426241495276

Epoch: 5| Step: 5
Training loss: 3.328835964202881
Validation loss: 3.3107266579904864

Epoch: 5| Step: 6
Training loss: 3.682178497314453
Validation loss: 3.3102173113053843

Epoch: 5| Step: 7
Training loss: 2.6460514068603516
Validation loss: 3.3008581207644556

Epoch: 5| Step: 8
Training loss: 2.83064341545105
Validation loss: 3.297734593832365

Epoch: 5| Step: 9
Training loss: 4.060765266418457
Validation loss: 3.300454601164787

Epoch: 5| Step: 10
Training loss: 3.147196054458618
Validation loss: 3.2956809074647966

Epoch: 16| Step: 0
Training loss: 2.916825532913208
Validation loss: 3.2974120263130433

Epoch: 5| Step: 1
Training loss: 3.3128154277801514
Validation loss: 3.295151518237206

Epoch: 5| Step: 2
Training loss: 2.7763123512268066
Validation loss: 3.2911287584612445

Epoch: 5| Step: 3
Training loss: 2.6536293029785156
Validation loss: 3.285863276450865

Epoch: 5| Step: 4
Training loss: 3.198380470275879
Validation loss: 3.2795915167818785

Epoch: 5| Step: 5
Training loss: 3.099224805831909
Validation loss: 3.2771422145187215

Epoch: 5| Step: 6
Training loss: 3.4810893535614014
Validation loss: 3.27822643967085

Epoch: 5| Step: 7
Training loss: 3.904533863067627
Validation loss: 3.2762785855159966

Epoch: 5| Step: 8
Training loss: 2.7259626388549805
Validation loss: 3.281656639550322

Epoch: 5| Step: 9
Training loss: 3.644165515899658
Validation loss: 3.2765946285699004

Epoch: 5| Step: 10
Training loss: 4.267096996307373
Validation loss: 3.265721264705863

Epoch: 17| Step: 0
Training loss: 3.395994186401367
Validation loss: 3.2600528758059264

Epoch: 5| Step: 1
Training loss: 2.899407148361206
Validation loss: 3.2587956305473083

Epoch: 5| Step: 2
Training loss: 2.5835132598876953
Validation loss: 3.256546466581283

Epoch: 5| Step: 3
Training loss: 2.923701763153076
Validation loss: 3.2577578688180573

Epoch: 5| Step: 4
Training loss: 3.2826473712921143
Validation loss: 3.254579149266725

Epoch: 5| Step: 5
Training loss: 3.3488082885742188
Validation loss: 3.2524453773293445

Epoch: 5| Step: 6
Training loss: 3.8110198974609375
Validation loss: 3.2506348471487723

Epoch: 5| Step: 7
Training loss: 3.51684832572937
Validation loss: 3.2504894964156614

Epoch: 5| Step: 8
Training loss: 4.283494472503662
Validation loss: 3.2482748134161836

Epoch: 5| Step: 9
Training loss: 2.776740550994873
Validation loss: 3.244459141967117

Epoch: 5| Step: 10
Training loss: 2.665766477584839
Validation loss: 3.2407620824793333

Epoch: 18| Step: 0
Training loss: 3.2026352882385254
Validation loss: 3.241884398204024

Epoch: 5| Step: 1
Training loss: 2.5903139114379883
Validation loss: 3.2391743249790643

Epoch: 5| Step: 2
Training loss: 3.0320029258728027
Validation loss: 3.2378289750827256

Epoch: 5| Step: 3
Training loss: 2.984623908996582
Validation loss: 3.237177497597151

Epoch: 5| Step: 4
Training loss: 4.4246039390563965
Validation loss: 3.232701422065817

Epoch: 5| Step: 5
Training loss: 2.8803303241729736
Validation loss: 3.2311286823723906

Epoch: 5| Step: 6
Training loss: 3.3244099617004395
Validation loss: 3.229421946310228

Epoch: 5| Step: 7
Training loss: 2.1456351280212402
Validation loss: 3.2250269330957884

Epoch: 5| Step: 8
Training loss: 3.445394515991211
Validation loss: 3.22166004232181

Epoch: 5| Step: 9
Training loss: 3.366800308227539
Validation loss: 3.2215176551572737

Epoch: 5| Step: 10
Training loss: 4.144352912902832
Validation loss: 3.221143943007274

Epoch: 19| Step: 0
Training loss: 2.663957118988037
Validation loss: 3.2152364535998275

Epoch: 5| Step: 1
Training loss: 2.736415386199951
Validation loss: 3.218942796030352

Epoch: 5| Step: 2
Training loss: 3.711031436920166
Validation loss: 3.2215502415933917

Epoch: 5| Step: 3
Training loss: 3.609498977661133
Validation loss: 3.218355635161041

Epoch: 5| Step: 4
Training loss: 3.2552669048309326
Validation loss: 3.2090213888434955

Epoch: 5| Step: 5
Training loss: 2.9700751304626465
Validation loss: 3.205197077925487

Epoch: 5| Step: 6
Training loss: 3.178511142730713
Validation loss: 3.205430543550881

Epoch: 5| Step: 7
Training loss: 2.529095411300659
Validation loss: 3.2027899578053463

Epoch: 5| Step: 8
Training loss: 3.005797863006592
Validation loss: 3.2063324733447005

Epoch: 5| Step: 9
Training loss: 4.225842475891113
Validation loss: 3.204908017189272

Epoch: 5| Step: 10
Training loss: 3.377056121826172
Validation loss: 3.2041961992940595

Epoch: 20| Step: 0
Training loss: 2.7387986183166504
Validation loss: 3.1994145326716925

Epoch: 5| Step: 1
Training loss: 2.9168572425842285
Validation loss: 3.197153942559355

Epoch: 5| Step: 2
Training loss: 2.7925777435302734
Validation loss: 3.193546987348987

Epoch: 5| Step: 3
Training loss: 3.570856809616089
Validation loss: 3.1905374014249412

Epoch: 5| Step: 4
Training loss: 3.826521396636963
Validation loss: 3.188316878452096

Epoch: 5| Step: 5
Training loss: 3.806124210357666
Validation loss: 3.188196818033854

Epoch: 5| Step: 6
Training loss: 3.186208724975586
Validation loss: 3.184779579921435

Epoch: 5| Step: 7
Training loss: 3.2177703380584717
Validation loss: 3.1829529834050003

Epoch: 5| Step: 8
Training loss: 2.6265687942504883
Validation loss: 3.1828641122387302

Epoch: 5| Step: 9
Training loss: 3.331815242767334
Validation loss: 3.1865435441335044

Epoch: 5| Step: 10
Training loss: 3.0446972846984863
Validation loss: 3.1795997568356094

Epoch: 21| Step: 0
Training loss: 4.048183441162109
Validation loss: 3.1767407822352585

Epoch: 5| Step: 1
Training loss: 3.0831027030944824
Validation loss: 3.1727127541777906

Epoch: 5| Step: 2
Training loss: 3.144857406616211
Validation loss: 3.1696249951598463

Epoch: 5| Step: 3
Training loss: 2.8951926231384277
Validation loss: 3.1712960991808163

Epoch: 5| Step: 4
Training loss: 2.612302780151367
Validation loss: 3.173492588022704

Epoch: 5| Step: 5
Training loss: 3.0844826698303223
Validation loss: 3.1705885446199806

Epoch: 5| Step: 6
Training loss: 2.8446061611175537
Validation loss: 3.1696731121309343

Epoch: 5| Step: 7
Training loss: 3.314929485321045
Validation loss: 3.167301239505891

Epoch: 5| Step: 8
Training loss: 2.812887668609619
Validation loss: 3.1624182321692027

Epoch: 5| Step: 9
Training loss: 3.340695858001709
Validation loss: 3.160206902411676

Epoch: 5| Step: 10
Training loss: 3.800243616104126
Validation loss: 3.160277276910761

Epoch: 22| Step: 0
Training loss: 2.868457555770874
Validation loss: 3.1546196860651814

Epoch: 5| Step: 1
Training loss: 3.7882320880889893
Validation loss: 3.1567927586135043

Epoch: 5| Step: 2
Training loss: 2.775411605834961
Validation loss: 3.177231873235395

Epoch: 5| Step: 3
Training loss: 2.3097124099731445
Validation loss: 3.220050278530326

Epoch: 5| Step: 4
Training loss: 2.6416358947753906
Validation loss: 3.178096076493622

Epoch: 5| Step: 5
Training loss: 3.0606884956359863
Validation loss: 3.151033027197725

Epoch: 5| Step: 6
Training loss: 2.9789929389953613
Validation loss: 3.154885070298308

Epoch: 5| Step: 7
Training loss: 3.8202903270721436
Validation loss: 3.162903424232237

Epoch: 5| Step: 8
Training loss: 3.8017330169677734
Validation loss: 3.174546536578927

Epoch: 5| Step: 9
Training loss: 3.4703993797302246
Validation loss: 3.1850820536254556

Epoch: 5| Step: 10
Training loss: 3.5506091117858887
Validation loss: 3.186462443362

Epoch: 23| Step: 0
Training loss: 2.132045269012451
Validation loss: 3.186591886704968

Epoch: 5| Step: 1
Training loss: 2.640132427215576
Validation loss: 3.1801576614379883

Epoch: 5| Step: 2
Training loss: 3.2090229988098145
Validation loss: 3.1731522390919347

Epoch: 5| Step: 3
Training loss: 3.1327507495880127
Validation loss: 3.1680354431111324

Epoch: 5| Step: 4
Training loss: 3.701819658279419
Validation loss: 3.1608480176618023

Epoch: 5| Step: 5
Training loss: 3.6774909496307373
Validation loss: 3.15386454520687

Epoch: 5| Step: 6
Training loss: 2.920104742050171
Validation loss: 3.1484725962403

Epoch: 5| Step: 7
Training loss: 3.0723962783813477
Validation loss: 3.1445702686104724

Epoch: 5| Step: 8
Training loss: 3.8042311668395996
Validation loss: 3.1423558035204486

Epoch: 5| Step: 9
Training loss: 3.3503241539001465
Validation loss: 3.1401783189465924

Epoch: 5| Step: 10
Training loss: 3.19795560836792
Validation loss: 3.1404046217600503

Epoch: 24| Step: 0
Training loss: 3.1919140815734863
Validation loss: 3.1385732619993147

Epoch: 5| Step: 1
Training loss: 3.201509952545166
Validation loss: 3.137170260952365

Epoch: 5| Step: 2
Training loss: 2.3974156379699707
Validation loss: 3.1373292271808912

Epoch: 5| Step: 3
Training loss: 3.5697147846221924
Validation loss: 3.135258459275769

Epoch: 5| Step: 4
Training loss: 3.2631759643554688
Validation loss: 3.134655047488469

Epoch: 5| Step: 5
Training loss: 2.460901975631714
Validation loss: 3.134245621260776

Epoch: 5| Step: 6
Training loss: 3.37709379196167
Validation loss: 3.13689402867389

Epoch: 5| Step: 7
Training loss: 2.9960222244262695
Validation loss: 3.1281810063187794

Epoch: 5| Step: 8
Training loss: 3.3288402557373047
Validation loss: 3.1187416148442093

Epoch: 5| Step: 9
Training loss: 3.1189045906066895
Validation loss: 3.1155425784408406

Epoch: 5| Step: 10
Training loss: 3.8090016841888428
Validation loss: 3.111435318505892

Epoch: 25| Step: 0
Training loss: 2.994947671890259
Validation loss: 3.108072985884964

Epoch: 5| Step: 1
Training loss: 3.0985093116760254
Validation loss: 3.1109737837186424

Epoch: 5| Step: 2
Training loss: 2.1725335121154785
Validation loss: 3.108656724294027

Epoch: 5| Step: 3
Training loss: 2.3532965183258057
Validation loss: 3.1091153980583273

Epoch: 5| Step: 4
Training loss: 2.840449810028076
Validation loss: 3.1067822056431926

Epoch: 5| Step: 5
Training loss: 3.391329288482666
Validation loss: 3.1072084801171416

Epoch: 5| Step: 6
Training loss: 3.9122836589813232
Validation loss: 3.1067061065345682

Epoch: 5| Step: 7
Training loss: 2.909414529800415
Validation loss: 3.1025005566176547

Epoch: 5| Step: 8
Training loss: 3.7442173957824707
Validation loss: 3.1069673517698884

Epoch: 5| Step: 9
Training loss: 3.969799757003784
Validation loss: 3.098386387671194

Epoch: 5| Step: 10
Training loss: 3.053130626678467
Validation loss: 3.0982431621961695

Epoch: 26| Step: 0
Training loss: 3.213581085205078
Validation loss: 3.0961927111430834

Epoch: 5| Step: 1
Training loss: 3.076476573944092
Validation loss: 3.0962518030597317

Epoch: 5| Step: 2
Training loss: 2.900285482406616
Validation loss: 3.0962915343623005

Epoch: 5| Step: 3
Training loss: 2.23421049118042
Validation loss: 3.094227644705003

Epoch: 5| Step: 4
Training loss: 3.5441575050354004
Validation loss: 3.098600190172913

Epoch: 5| Step: 5
Training loss: 3.6854140758514404
Validation loss: 3.0978599748303814

Epoch: 5| Step: 6
Training loss: 3.725177049636841
Validation loss: 3.094077753764327

Epoch: 5| Step: 7
Training loss: 3.5292537212371826
Validation loss: 3.0908458335425264

Epoch: 5| Step: 8
Training loss: 1.9975337982177734
Validation loss: 3.0881437409308647

Epoch: 5| Step: 9
Training loss: 3.134068727493286
Validation loss: 3.0884515931529384

Epoch: 5| Step: 10
Training loss: 3.3147196769714355
Validation loss: 3.0899021804973645

Epoch: 27| Step: 0
Training loss: 3.4322903156280518
Validation loss: 3.0886017020030687

Epoch: 5| Step: 1
Training loss: 3.842816114425659
Validation loss: 3.0920868919741724

Epoch: 5| Step: 2
Training loss: 2.7272908687591553
Validation loss: 3.0848355216364705

Epoch: 5| Step: 3
Training loss: 3.094813108444214
Validation loss: 3.0812253259843394

Epoch: 5| Step: 4
Training loss: 3.307617664337158
Validation loss: 3.0802721515778573

Epoch: 5| Step: 5
Training loss: 3.2368857860565186
Validation loss: 3.0833891207172024

Epoch: 5| Step: 6
Training loss: 3.0453360080718994
Validation loss: 3.0863487541034655

Epoch: 5| Step: 7
Training loss: 2.3005661964416504
Validation loss: 3.076236371071108

Epoch: 5| Step: 8
Training loss: 2.939157247543335
Validation loss: 3.0716014190386702

Epoch: 5| Step: 9
Training loss: 3.647050142288208
Validation loss: 3.0708340931964178

Epoch: 5| Step: 10
Training loss: 2.5387051105499268
Validation loss: 3.0700657111342236

Epoch: 28| Step: 0
Training loss: 3.3967337608337402
Validation loss: 3.0685138061482418

Epoch: 5| Step: 1
Training loss: 3.2054543495178223
Validation loss: 3.0700733482196765

Epoch: 5| Step: 2
Training loss: 3.6647934913635254
Validation loss: 3.069764667941678

Epoch: 5| Step: 3
Training loss: 4.00916862487793
Validation loss: 3.0642731010272937

Epoch: 5| Step: 4
Training loss: 3.0053868293762207
Validation loss: 3.0637457370758057

Epoch: 5| Step: 5
Training loss: 2.0073840618133545
Validation loss: 3.060561949206937

Epoch: 5| Step: 6
Training loss: 2.1629021167755127
Validation loss: 3.05784849966726

Epoch: 5| Step: 7
Training loss: 3.4265313148498535
Validation loss: 3.0578117473151094

Epoch: 5| Step: 8
Training loss: 2.755513906478882
Validation loss: 3.0530898007013465

Epoch: 5| Step: 9
Training loss: 3.240300416946411
Validation loss: 3.056751533221173

Epoch: 5| Step: 10
Training loss: 3.253373622894287
Validation loss: 3.053450753611903

Epoch: 29| Step: 0
Training loss: 2.135342597961426
Validation loss: 3.0581034947467107

Epoch: 5| Step: 1
Training loss: 2.689887523651123
Validation loss: 3.061628995403167

Epoch: 5| Step: 2
Training loss: 3.807192325592041
Validation loss: 3.070818885680168

Epoch: 5| Step: 3
Training loss: 3.6591084003448486
Validation loss: 3.051488858397289

Epoch: 5| Step: 4
Training loss: 3.2621002197265625
Validation loss: 3.049685993502217

Epoch: 5| Step: 5
Training loss: 2.720581293106079
Validation loss: 3.0453575862351285

Epoch: 5| Step: 6
Training loss: 3.612286329269409
Validation loss: 3.0449329960730767

Epoch: 5| Step: 7
Training loss: 2.7087483406066895
Validation loss: 3.0434578900696128

Epoch: 5| Step: 8
Training loss: 2.469686985015869
Validation loss: 3.0457655024784867

Epoch: 5| Step: 9
Training loss: 3.4646148681640625
Validation loss: 3.0435013309601815

Epoch: 5| Step: 10
Training loss: 3.5207407474517822
Validation loss: 3.039904773876231

Epoch: 30| Step: 0
Training loss: 2.6049065589904785
Validation loss: 3.0401643296723724

Epoch: 5| Step: 1
Training loss: 2.5921220779418945
Validation loss: 3.0390499355972453

Epoch: 5| Step: 2
Training loss: 3.354370594024658
Validation loss: 3.0413529231984127

Epoch: 5| Step: 3
Training loss: 2.622708320617676
Validation loss: 3.034099704475813

Epoch: 5| Step: 4
Training loss: 3.7330520153045654
Validation loss: 3.038589108374811

Epoch: 5| Step: 5
Training loss: 2.9574944972991943
Validation loss: 3.0353734903438117

Epoch: 5| Step: 6
Training loss: 2.918590784072876
Validation loss: 3.031468491400442

Epoch: 5| Step: 7
Training loss: 3.3875038623809814
Validation loss: 3.03079249781947

Epoch: 5| Step: 8
Training loss: 3.4374213218688965
Validation loss: 3.029338498269358

Epoch: 5| Step: 9
Training loss: 3.127744197845459
Validation loss: 3.0391407089848674

Epoch: 5| Step: 10
Training loss: 3.1816928386688232
Validation loss: 3.044930006868096

Epoch: 31| Step: 0
Training loss: 2.9907801151275635
Validation loss: 3.039588882077125

Epoch: 5| Step: 1
Training loss: 3.4507534503936768
Validation loss: 3.027775215846236

Epoch: 5| Step: 2
Training loss: 2.659960985183716
Validation loss: 3.0281121730804443

Epoch: 5| Step: 3
Training loss: 2.9970781803131104
Validation loss: 3.0275387379430954

Epoch: 5| Step: 4
Training loss: 3.783831834793091
Validation loss: 3.023840242816556

Epoch: 5| Step: 5
Training loss: 3.287017822265625
Validation loss: 3.025446855893699

Epoch: 5| Step: 6
Training loss: 2.6141467094421387
Validation loss: 3.019401278547061

Epoch: 5| Step: 7
Training loss: 3.878775119781494
Validation loss: 3.0225045860454602

Epoch: 5| Step: 8
Training loss: 3.290698289871216
Validation loss: 3.020160003374982

Epoch: 5| Step: 9
Training loss: 2.756715774536133
Validation loss: 3.0214165769597536

Epoch: 5| Step: 10
Training loss: 1.9659647941589355
Validation loss: 3.0184137693015476

Epoch: 32| Step: 0
Training loss: 2.8654093742370605
Validation loss: 3.0150744838099324

Epoch: 5| Step: 1
Training loss: 3.0394937992095947
Validation loss: 3.016906181971232

Epoch: 5| Step: 2
Training loss: 2.1868109703063965
Validation loss: 3.0148115568263556

Epoch: 5| Step: 3
Training loss: 3.21620512008667
Validation loss: 3.0175634558482836

Epoch: 5| Step: 4
Training loss: 3.252429246902466
Validation loss: 3.0214883665884695

Epoch: 5| Step: 5
Training loss: 3.406458616256714
Validation loss: 3.039461315319102

Epoch: 5| Step: 6
Training loss: 3.4671363830566406
Validation loss: 3.011511105363087

Epoch: 5| Step: 7
Training loss: 2.0535316467285156
Validation loss: 3.0172270036512807

Epoch: 5| Step: 8
Training loss: 3.521007537841797
Validation loss: 3.0149177889670096

Epoch: 5| Step: 9
Training loss: 3.0763771533966064
Validation loss: 3.0200251763866794

Epoch: 5| Step: 10
Training loss: 3.8229787349700928
Validation loss: 3.0230529436501126

Epoch: 33| Step: 0
Training loss: 3.2932980060577393
Validation loss: 3.0244804864288657

Epoch: 5| Step: 1
Training loss: 3.427874803543091
Validation loss: 3.019915114166916

Epoch: 5| Step: 2
Training loss: 3.014021396636963
Validation loss: 3.01554540664919

Epoch: 5| Step: 3
Training loss: 2.9050021171569824
Validation loss: 3.0126379587317027

Epoch: 5| Step: 4
Training loss: 2.808978319168091
Validation loss: 3.014478668089836

Epoch: 5| Step: 5
Training loss: 2.3728203773498535
Validation loss: 3.0124352824303413

Epoch: 5| Step: 6
Training loss: 2.966144323348999
Validation loss: 3.017474456499982

Epoch: 5| Step: 7
Training loss: 2.5642342567443848
Validation loss: 3.023835220644551

Epoch: 5| Step: 8
Training loss: 3.5911331176757812
Validation loss: 3.0208443544244252

Epoch: 5| Step: 9
Training loss: 3.6744847297668457
Validation loss: 3.015406075344291

Epoch: 5| Step: 10
Training loss: 3.1691176891326904
Validation loss: 3.005730859694942

Epoch: 34| Step: 0
Training loss: 3.24711275100708
Validation loss: 3.003256392735307

Epoch: 5| Step: 1
Training loss: 2.926076889038086
Validation loss: 3.0009062392737276

Epoch: 5| Step: 2
Training loss: 2.8470757007598877
Validation loss: 3.0017851732110463

Epoch: 5| Step: 3
Training loss: 2.830636501312256
Validation loss: 2.995790220076038

Epoch: 5| Step: 4
Training loss: 2.9789187908172607
Validation loss: 2.9966879916447464

Epoch: 5| Step: 5
Training loss: 3.2165133953094482
Validation loss: 2.9950750591934368

Epoch: 5| Step: 6
Training loss: 2.7316784858703613
Validation loss: 2.9922665370407926

Epoch: 5| Step: 7
Training loss: 3.8643832206726074
Validation loss: 2.9927042145882883

Epoch: 5| Step: 8
Training loss: 3.2143568992614746
Validation loss: 2.993819216246246

Epoch: 5| Step: 9
Training loss: 3.178913116455078
Validation loss: 2.9956393293155137

Epoch: 5| Step: 10
Training loss: 2.54211688041687
Validation loss: 2.9956449718885523

Epoch: 35| Step: 0
Training loss: 3.3191826343536377
Validation loss: 2.988508152705367

Epoch: 5| Step: 1
Training loss: 3.8969688415527344
Validation loss: 2.9885817522643716

Epoch: 5| Step: 2
Training loss: 1.9589201211929321
Validation loss: 2.9840509378781883

Epoch: 5| Step: 3
Training loss: 2.570695400238037
Validation loss: 2.986481999838224

Epoch: 5| Step: 4
Training loss: 3.0789732933044434
Validation loss: 2.982248719020556

Epoch: 5| Step: 5
Training loss: 3.1417784690856934
Validation loss: 2.9809431106813493

Epoch: 5| Step: 6
Training loss: 3.5593082904815674
Validation loss: 2.9840177182228333

Epoch: 5| Step: 7
Training loss: 3.3430588245391846
Validation loss: 2.9811840621373986

Epoch: 5| Step: 8
Training loss: 3.1064891815185547
Validation loss: 2.982627381560623

Epoch: 5| Step: 9
Training loss: 2.461662769317627
Validation loss: 2.977104763830862

Epoch: 5| Step: 10
Training loss: 3.13967227935791
Validation loss: 2.976752755462482

Epoch: 36| Step: 0
Training loss: 2.8621726036071777
Validation loss: 2.97387961418398

Epoch: 5| Step: 1
Training loss: 2.1512320041656494
Validation loss: 2.972571893404889

Epoch: 5| Step: 2
Training loss: 2.8182621002197266
Validation loss: 2.971651807908089

Epoch: 5| Step: 3
Training loss: 3.9064114093780518
Validation loss: 2.9724341489935435

Epoch: 5| Step: 4
Training loss: 2.689734935760498
Validation loss: 2.9721430963085544

Epoch: 5| Step: 5
Training loss: 2.8370680809020996
Validation loss: 2.9684022062568256

Epoch: 5| Step: 6
Training loss: 3.413017749786377
Validation loss: 2.9676248053068757

Epoch: 5| Step: 7
Training loss: 2.5055789947509766
Validation loss: 2.966454800739083

Epoch: 5| Step: 8
Training loss: 3.664153575897217
Validation loss: 2.9660966627059446

Epoch: 5| Step: 9
Training loss: 3.3603806495666504
Validation loss: 2.964747477603215

Epoch: 5| Step: 10
Training loss: 3.2686359882354736
Validation loss: 2.9623634251215125

Epoch: 37| Step: 0
Training loss: 3.2761013507843018
Validation loss: 2.9622768663590953

Epoch: 5| Step: 1
Training loss: 2.9395453929901123
Validation loss: 2.9633499319835375

Epoch: 5| Step: 2
Training loss: 2.5711989402770996
Validation loss: 2.964783876172958

Epoch: 5| Step: 3
Training loss: 3.028496265411377
Validation loss: 2.959990926968154

Epoch: 5| Step: 4
Training loss: 2.421043872833252
Validation loss: 2.9587296029572845

Epoch: 5| Step: 5
Training loss: 3.4879441261291504
Validation loss: 2.9605865632334063

Epoch: 5| Step: 6
Training loss: 2.8203446865081787
Validation loss: 2.958487718336044

Epoch: 5| Step: 7
Training loss: 2.9846673011779785
Validation loss: 2.957665463929535

Epoch: 5| Step: 8
Training loss: 3.3501954078674316
Validation loss: 2.953136190291374

Epoch: 5| Step: 9
Training loss: 3.101811170578003
Validation loss: 2.956847313911684

Epoch: 5| Step: 10
Training loss: 3.4297332763671875
Validation loss: 2.964715644877444

Epoch: 38| Step: 0
Training loss: 3.2261581420898438
Validation loss: 2.9594645910365607

Epoch: 5| Step: 1
Training loss: 2.942894458770752
Validation loss: 2.9499753572607554

Epoch: 5| Step: 2
Training loss: 3.528463363647461
Validation loss: 2.950486013966222

Epoch: 5| Step: 3
Training loss: 3.3033194541931152
Validation loss: 2.948380706130817

Epoch: 5| Step: 4
Training loss: 2.4604899883270264
Validation loss: 2.9499965816415767

Epoch: 5| Step: 5
Training loss: 2.8971974849700928
Validation loss: 2.9486802675390757

Epoch: 5| Step: 6
Training loss: 3.057265520095825
Validation loss: 2.9467763259846675

Epoch: 5| Step: 7
Training loss: 2.604651927947998
Validation loss: 2.9472062587738037

Epoch: 5| Step: 8
Training loss: 3.4882309436798096
Validation loss: 2.9466057772277505

Epoch: 5| Step: 9
Training loss: 2.2963075637817383
Validation loss: 2.947507760858023

Epoch: 5| Step: 10
Training loss: 3.5639240741729736
Validation loss: 2.944013241798647

Epoch: 39| Step: 0
Training loss: 3.472581148147583
Validation loss: 2.94421523873524

Epoch: 5| Step: 1
Training loss: 3.061091661453247
Validation loss: 2.9444352452472975

Epoch: 5| Step: 2
Training loss: 3.3104248046875
Validation loss: 2.9449691490460466

Epoch: 5| Step: 3
Training loss: 3.3979811668395996
Validation loss: 2.9436891053312566

Epoch: 5| Step: 4
Training loss: 2.3035712242126465
Validation loss: 2.9406447154219433

Epoch: 5| Step: 5
Training loss: 2.8765876293182373
Validation loss: 2.9416522005552888

Epoch: 5| Step: 6
Training loss: 2.9897313117980957
Validation loss: 2.9408208554790867

Epoch: 5| Step: 7
Training loss: 3.9332480430603027
Validation loss: 2.9389858835486957

Epoch: 5| Step: 8
Training loss: 2.585264205932617
Validation loss: 2.9410016408530613

Epoch: 5| Step: 9
Training loss: 2.756115436553955
Validation loss: 2.941727033225439

Epoch: 5| Step: 10
Training loss: 2.4386110305786133
Validation loss: 2.9424254868620183

Epoch: 40| Step: 0
Training loss: 3.1511566638946533
Validation loss: 2.9379199704816266

Epoch: 5| Step: 1
Training loss: 3.6900455951690674
Validation loss: 2.933734611798358

Epoch: 5| Step: 2
Training loss: 2.332139015197754
Validation loss: 2.9319314674664567

Epoch: 5| Step: 3
Training loss: 3.0422534942626953
Validation loss: 2.932957859449489

Epoch: 5| Step: 4
Training loss: 3.0945944786071777
Validation loss: 2.9291090555088495

Epoch: 5| Step: 5
Training loss: 3.068157911300659
Validation loss: 2.9308230825649795

Epoch: 5| Step: 6
Training loss: 3.026355743408203
Validation loss: 2.9301644422674693

Epoch: 5| Step: 7
Training loss: 3.24198842048645
Validation loss: 2.9271902166387087

Epoch: 5| Step: 8
Training loss: 2.6163368225097656
Validation loss: 2.92747728542615

Epoch: 5| Step: 9
Training loss: 3.3391449451446533
Validation loss: 2.9281212104264127

Epoch: 5| Step: 10
Training loss: 2.444164991378784
Validation loss: 2.9250040592685824

Epoch: 41| Step: 0
Training loss: 2.332242250442505
Validation loss: 2.927565474664011

Epoch: 5| Step: 1
Training loss: 2.712561845779419
Validation loss: 2.929885297693232

Epoch: 5| Step: 2
Training loss: 2.9546806812286377
Validation loss: 2.935285440055273

Epoch: 5| Step: 3
Training loss: 2.848242998123169
Validation loss: 2.9249277935233167

Epoch: 5| Step: 4
Training loss: 4.123593330383301
Validation loss: 2.923593290390507

Epoch: 5| Step: 5
Training loss: 2.670769214630127
Validation loss: 2.925375871760871

Epoch: 5| Step: 6
Training loss: 3.00173282623291
Validation loss: 2.9290979472539758

Epoch: 5| Step: 7
Training loss: 3.6362717151641846
Validation loss: 2.9255517964722006

Epoch: 5| Step: 8
Training loss: 3.5483875274658203
Validation loss: 2.92650269949308

Epoch: 5| Step: 9
Training loss: 2.6934256553649902
Validation loss: 2.9235811105338474

Epoch: 5| Step: 10
Training loss: 2.4735233783721924
Validation loss: 2.920818431403047

Epoch: 42| Step: 0
Training loss: 3.1517391204833984
Validation loss: 2.9196082417682936

Epoch: 5| Step: 1
Training loss: 2.7704262733459473
Validation loss: 2.9168027088206303

Epoch: 5| Step: 2
Training loss: 2.899000644683838
Validation loss: 2.9170496438139226

Epoch: 5| Step: 3
Training loss: 2.3796675205230713
Validation loss: 2.9203444475768716

Epoch: 5| Step: 4
Training loss: 3.6215243339538574
Validation loss: 2.9187838236490884

Epoch: 5| Step: 5
Training loss: 2.691138505935669
Validation loss: 2.9155081523362028

Epoch: 5| Step: 6
Training loss: 3.024402618408203
Validation loss: 2.916633193210889

Epoch: 5| Step: 7
Training loss: 3.5233070850372314
Validation loss: 2.9168541508336223

Epoch: 5| Step: 8
Training loss: 2.3718769550323486
Validation loss: 2.9160247310515373

Epoch: 5| Step: 9
Training loss: 3.75946044921875
Validation loss: 2.91551015966682

Epoch: 5| Step: 10
Training loss: 2.861438274383545
Validation loss: 2.9113551109067854

Epoch: 43| Step: 0
Training loss: 2.7504029273986816
Validation loss: 2.9124478781095116

Epoch: 5| Step: 1
Training loss: 3.674333095550537
Validation loss: 2.9138739749949467

Epoch: 5| Step: 2
Training loss: 2.873924970626831
Validation loss: 2.9106640943916897

Epoch: 5| Step: 3
Training loss: 2.973811388015747
Validation loss: 2.911273423061576

Epoch: 5| Step: 4
Training loss: 3.4304518699645996
Validation loss: 2.9095463598928144

Epoch: 5| Step: 5
Training loss: 3.0387089252471924
Validation loss: 2.911292729839202

Epoch: 5| Step: 6
Training loss: 2.7630505561828613
Validation loss: 2.90687386707593

Epoch: 5| Step: 7
Training loss: 2.683729410171509
Validation loss: 2.907650791188722

Epoch: 5| Step: 8
Training loss: 2.6682193279266357
Validation loss: 2.9099658612282044

Epoch: 5| Step: 9
Training loss: 3.147984266281128
Validation loss: 2.9089933979895806

Epoch: 5| Step: 10
Training loss: 2.9968628883361816
Validation loss: 2.9083293432830484

Epoch: 44| Step: 0
Training loss: 2.864408254623413
Validation loss: 2.9073145620284544

Epoch: 5| Step: 1
Training loss: 3.057325839996338
Validation loss: 2.9084074445950088

Epoch: 5| Step: 2
Training loss: 3.118781805038452
Validation loss: 2.9097153807199128

Epoch: 5| Step: 3
Training loss: 2.981900453567505
Validation loss: 2.918456574921967

Epoch: 5| Step: 4
Training loss: 2.7609119415283203
Validation loss: 2.918013706002184

Epoch: 5| Step: 5
Training loss: 3.2213497161865234
Validation loss: 2.9105989292103756

Epoch: 5| Step: 6
Training loss: 2.4284751415252686
Validation loss: 2.906998085719283

Epoch: 5| Step: 7
Training loss: 3.918184995651245
Validation loss: 2.9052348752175607

Epoch: 5| Step: 8
Training loss: 2.947725296020508
Validation loss: 2.902740711806923

Epoch: 5| Step: 9
Training loss: 2.2056477069854736
Validation loss: 2.8989019983558246

Epoch: 5| Step: 10
Training loss: 3.486725330352783
Validation loss: 2.9026580318327873

Epoch: 45| Step: 0
Training loss: 2.975482940673828
Validation loss: 2.901479854378649

Epoch: 5| Step: 1
Training loss: 3.2119688987731934
Validation loss: 2.900132894515991

Epoch: 5| Step: 2
Training loss: 1.9114528894424438
Validation loss: 2.898379038738948

Epoch: 5| Step: 3
Training loss: 3.4528183937072754
Validation loss: 2.897866961776569

Epoch: 5| Step: 4
Training loss: 2.8063645362854004
Validation loss: 2.8975902911155456

Epoch: 5| Step: 5
Training loss: 2.765026092529297
Validation loss: 2.8949926745507026

Epoch: 5| Step: 6
Training loss: 2.7666988372802734
Validation loss: 2.892922560373942

Epoch: 5| Step: 7
Training loss: 3.1196227073669434
Validation loss: 2.8943604987154723

Epoch: 5| Step: 8
Training loss: 2.6228504180908203
Validation loss: 2.90664755657155

Epoch: 5| Step: 9
Training loss: 3.8616020679473877
Validation loss: 2.9294393908592964

Epoch: 5| Step: 10
Training loss: 3.435443878173828
Validation loss: 2.9046088059743247

Epoch: 46| Step: 0
Training loss: 2.1706326007843018
Validation loss: 2.896327495574951

Epoch: 5| Step: 1
Training loss: 2.542379856109619
Validation loss: 2.890659345093594

Epoch: 5| Step: 2
Training loss: 3.4569175243377686
Validation loss: 2.893682902859103

Epoch: 5| Step: 3
Training loss: 2.6886932849884033
Validation loss: 2.8967697569119033

Epoch: 5| Step: 4
Training loss: 3.3202145099639893
Validation loss: 2.899290705239901

Epoch: 5| Step: 5
Training loss: 3.456462860107422
Validation loss: 2.9016159606236283

Epoch: 5| Step: 6
Training loss: 3.1505866050720215
Validation loss: 2.897131730151433

Epoch: 5| Step: 7
Training loss: 2.9468259811401367
Validation loss: 2.8992179619368685

Epoch: 5| Step: 8
Training loss: 2.785677433013916
Validation loss: 2.8972330836839575

Epoch: 5| Step: 9
Training loss: 3.0822269916534424
Validation loss: 2.8972894427596882

Epoch: 5| Step: 10
Training loss: 3.349583387374878
Validation loss: 2.8931102137411795

Epoch: 47| Step: 0
Training loss: 3.264822006225586
Validation loss: 2.8918975860841813

Epoch: 5| Step: 1
Training loss: 2.304431200027466
Validation loss: 2.892034358875726

Epoch: 5| Step: 2
Training loss: 1.7752764225006104
Validation loss: 2.890617057841311

Epoch: 5| Step: 3
Training loss: 3.8966994285583496
Validation loss: 2.8913748341221965

Epoch: 5| Step: 4
Training loss: 2.8465919494628906
Validation loss: 2.8879537992579962

Epoch: 5| Step: 5
Training loss: 2.9420275688171387
Validation loss: 2.888132131227883

Epoch: 5| Step: 6
Training loss: 2.852508544921875
Validation loss: 2.8901656827619

Epoch: 5| Step: 7
Training loss: 3.8302180767059326
Validation loss: 2.8911243613048265

Epoch: 5| Step: 8
Training loss: 3.031907558441162
Validation loss: 2.891794381603118

Epoch: 5| Step: 9
Training loss: 2.6045520305633545
Validation loss: 2.8905798850520963

Epoch: 5| Step: 10
Training loss: 3.5598738193511963
Validation loss: 2.8878696016086045

Epoch: 48| Step: 0
Training loss: 3.610375165939331
Validation loss: 2.887324612627747

Epoch: 5| Step: 1
Training loss: 3.7196974754333496
Validation loss: 2.887027745605797

Epoch: 5| Step: 2
Training loss: 3.092845916748047
Validation loss: 2.8829549692010366

Epoch: 5| Step: 3
Training loss: 2.712679624557495
Validation loss: 2.8825119131354877

Epoch: 5| Step: 4
Training loss: 2.9917190074920654
Validation loss: 2.882761465605869

Epoch: 5| Step: 5
Training loss: 1.9991620779037476
Validation loss: 2.8797506081160678

Epoch: 5| Step: 6
Training loss: 3.3709914684295654
Validation loss: 2.8776898948095178

Epoch: 5| Step: 7
Training loss: 2.0358622074127197
Validation loss: 2.8764448806803715

Epoch: 5| Step: 8
Training loss: 3.1994433403015137
Validation loss: 2.8785416823561474

Epoch: 5| Step: 9
Training loss: 3.0651144981384277
Validation loss: 2.87608047967316

Epoch: 5| Step: 10
Training loss: 2.9117183685302734
Validation loss: 2.8779263675853772

Epoch: 49| Step: 0
Training loss: 3.7507622241973877
Validation loss: 2.894506864650275

Epoch: 5| Step: 1
Training loss: 3.0719265937805176
Validation loss: 2.8947774107738207

Epoch: 5| Step: 2
Training loss: 2.6268386840820312
Validation loss: 2.879642750627251

Epoch: 5| Step: 3
Training loss: 2.322161912918091
Validation loss: 2.8735918665444977

Epoch: 5| Step: 4
Training loss: 4.0839924812316895
Validation loss: 2.870367826954011

Epoch: 5| Step: 5
Training loss: 2.821660041809082
Validation loss: 2.873115985624252

Epoch: 5| Step: 6
Training loss: 2.7530479431152344
Validation loss: 2.8703544960227063

Epoch: 5| Step: 7
Training loss: 2.737719774246216
Validation loss: 2.873406030798471

Epoch: 5| Step: 8
Training loss: 2.979250431060791
Validation loss: 2.872114840374198

Epoch: 5| Step: 9
Training loss: 2.9263079166412354
Validation loss: 2.873794822282689

Epoch: 5| Step: 10
Training loss: 2.559901475906372
Validation loss: 2.874935855147659

Epoch: 50| Step: 0
Training loss: 2.5442702770233154
Validation loss: 2.8711709668559413

Epoch: 5| Step: 1
Training loss: 2.824580192565918
Validation loss: 2.8648450066966396

Epoch: 5| Step: 2
Training loss: 2.275805711746216
Validation loss: 2.868395633594964

Epoch: 5| Step: 3
Training loss: 2.7156004905700684
Validation loss: 2.8652862374500563

Epoch: 5| Step: 4
Training loss: 3.5296764373779297
Validation loss: 2.8636144156097085

Epoch: 5| Step: 5
Training loss: 3.5002479553222656
Validation loss: 2.8663625947890745

Epoch: 5| Step: 6
Training loss: 3.62202787399292
Validation loss: 2.8614020347595215

Epoch: 5| Step: 7
Training loss: 2.326308012008667
Validation loss: 2.8638550825016473

Epoch: 5| Step: 8
Training loss: 2.618332624435425
Validation loss: 2.8603576408919467

Epoch: 5| Step: 9
Training loss: 2.815294027328491
Validation loss: 2.8619477043869677

Epoch: 5| Step: 10
Training loss: 3.960287094116211
Validation loss: 2.8591654480144544

Epoch: 51| Step: 0
Training loss: 2.7980542182922363
Validation loss: 2.8601886226284887

Epoch: 5| Step: 1
Training loss: 2.9674160480499268
Validation loss: 2.8599527420536166

Epoch: 5| Step: 2
Training loss: 3.079697847366333
Validation loss: 2.8596377475287325

Epoch: 5| Step: 3
Training loss: 3.804274797439575
Validation loss: 2.861097405033727

Epoch: 5| Step: 4
Training loss: 2.35517954826355
Validation loss: 2.8590879107034333

Epoch: 5| Step: 5
Training loss: 2.8025238513946533
Validation loss: 2.8553556370478805

Epoch: 5| Step: 6
Training loss: 3.3452072143554688
Validation loss: 2.8559530063342025

Epoch: 5| Step: 7
Training loss: 2.6028389930725098
Validation loss: 2.8546433705155567

Epoch: 5| Step: 8
Training loss: 2.8362250328063965
Validation loss: 2.8536852867372575

Epoch: 5| Step: 9
Training loss: 2.989659547805786
Validation loss: 2.85567000860809

Epoch: 5| Step: 10
Training loss: 2.9504079818725586
Validation loss: 2.8543963739948888

Epoch: 52| Step: 0
Training loss: 3.5397448539733887
Validation loss: 2.8507919875524377

Epoch: 5| Step: 1
Training loss: 2.5710346698760986
Validation loss: 2.8579703325866372

Epoch: 5| Step: 2
Training loss: 3.139296293258667
Validation loss: 2.8595685343588553

Epoch: 5| Step: 3
Training loss: 3.0131783485412598
Validation loss: 2.8659871470543647

Epoch: 5| Step: 4
Training loss: 3.286832332611084
Validation loss: 2.8567004203796387

Epoch: 5| Step: 5
Training loss: 4.005502223968506
Validation loss: 2.851459946683658

Epoch: 5| Step: 6
Training loss: 2.8262245655059814
Validation loss: 2.847470839818319

Epoch: 5| Step: 7
Training loss: 3.0170607566833496
Validation loss: 2.8503324447139615

Epoch: 5| Step: 8
Training loss: 2.8141772747039795
Validation loss: 2.8524692161108858

Epoch: 5| Step: 9
Training loss: 1.7522627115249634
Validation loss: 2.854371240062098

Epoch: 5| Step: 10
Training loss: 2.5837574005126953
Validation loss: 2.851793284057289

Epoch: 53| Step: 0
Training loss: 3.068510055541992
Validation loss: 2.858292389941472

Epoch: 5| Step: 1
Training loss: 2.462254762649536
Validation loss: 2.8517949529873428

Epoch: 5| Step: 2
Training loss: 2.636687994003296
Validation loss: 2.8532808493542414

Epoch: 5| Step: 3
Training loss: 3.6217758655548096
Validation loss: 2.847156504149078

Epoch: 5| Step: 4
Training loss: 2.7977309226989746
Validation loss: 2.8455829210178827

Epoch: 5| Step: 5
Training loss: 4.06897497177124
Validation loss: 2.8469628108445035

Epoch: 5| Step: 6
Training loss: 3.5232818126678467
Validation loss: 2.845595144456433

Epoch: 5| Step: 7
Training loss: 2.1175262928009033
Validation loss: 2.8465664566204114

Epoch: 5| Step: 8
Training loss: 2.9023289680480957
Validation loss: 2.8482271420058383

Epoch: 5| Step: 9
Training loss: 2.6815197467803955
Validation loss: 2.841926359361218

Epoch: 5| Step: 10
Training loss: 2.6248764991760254
Validation loss: 2.838060220082601

Epoch: 54| Step: 0
Training loss: 3.5069642066955566
Validation loss: 2.8409019106177875

Epoch: 5| Step: 1
Training loss: 2.972592830657959
Validation loss: 2.8379105957605506

Epoch: 5| Step: 2
Training loss: 2.8792872428894043
Validation loss: 2.841007478775517

Epoch: 5| Step: 3
Training loss: 3.518568754196167
Validation loss: 2.8396427451923327

Epoch: 5| Step: 4
Training loss: 3.785886764526367
Validation loss: 2.838848847214894

Epoch: 5| Step: 5
Training loss: 2.8207199573516846
Validation loss: 2.8373703777149157

Epoch: 5| Step: 6
Training loss: 2.613532304763794
Validation loss: 2.835410479576357

Epoch: 5| Step: 7
Training loss: 2.6926605701446533
Validation loss: 2.8329122681771555

Epoch: 5| Step: 8
Training loss: 3.0249431133270264
Validation loss: 2.831897692013812

Epoch: 5| Step: 9
Training loss: 2.5929932594299316
Validation loss: 2.8328201386236374

Epoch: 5| Step: 10
Training loss: 1.8512773513793945
Validation loss: 2.83183527505526

Epoch: 55| Step: 0
Training loss: 3.675835371017456
Validation loss: 2.8311031864535425

Epoch: 5| Step: 1
Training loss: 3.4426321983337402
Validation loss: 2.8274008535569712

Epoch: 5| Step: 2
Training loss: 3.366142749786377
Validation loss: 2.829547720570718

Epoch: 5| Step: 3
Training loss: 2.8800110816955566
Validation loss: 2.832821975472153

Epoch: 5| Step: 4
Training loss: 1.9198005199432373
Validation loss: 2.8323312882454164

Epoch: 5| Step: 5
Training loss: 3.1178417205810547
Validation loss: 2.8278051063578618

Epoch: 5| Step: 6
Training loss: 2.478513717651367
Validation loss: 2.8278171529052076

Epoch: 5| Step: 7
Training loss: 1.8679940700531006
Validation loss: 2.8269026740904777

Epoch: 5| Step: 8
Training loss: 3.270447254180908
Validation loss: 2.83077863724001

Epoch: 5| Step: 9
Training loss: 3.1896815299987793
Validation loss: 2.8283125610761743

Epoch: 5| Step: 10
Training loss: 3.1518163681030273
Validation loss: 2.8261981420619513

Epoch: 56| Step: 0
Training loss: 3.1421141624450684
Validation loss: 2.825080515235983

Epoch: 5| Step: 1
Training loss: 3.6028892993927
Validation loss: 2.823461009610084

Epoch: 5| Step: 2
Training loss: 2.8040268421173096
Validation loss: 2.8231208580796436

Epoch: 5| Step: 3
Training loss: 2.4271881580352783
Validation loss: 2.823159179379863

Epoch: 5| Step: 4
Training loss: 1.970342993736267
Validation loss: 2.8231516243309103

Epoch: 5| Step: 5
Training loss: 3.1385631561279297
Validation loss: 2.825266953437559

Epoch: 5| Step: 6
Training loss: 2.969446897506714
Validation loss: 2.825956065167663

Epoch: 5| Step: 7
Training loss: 3.5789551734924316
Validation loss: 2.815929515387422

Epoch: 5| Step: 8
Training loss: 2.9775710105895996
Validation loss: 2.814895501700781

Epoch: 5| Step: 9
Training loss: 2.4016337394714355
Validation loss: 2.816335860119071

Epoch: 5| Step: 10
Training loss: 3.3179991245269775
Validation loss: 2.8168909165167038

Epoch: 57| Step: 0
Training loss: 2.8372693061828613
Validation loss: 2.817120728954192

Epoch: 5| Step: 1
Training loss: 3.4947853088378906
Validation loss: 2.813964428440217

Epoch: 5| Step: 2
Training loss: 3.056936502456665
Validation loss: 2.817932064815234

Epoch: 5| Step: 3
Training loss: 2.9481098651885986
Validation loss: 2.8155803347146637

Epoch: 5| Step: 4
Training loss: 2.2265422344207764
Validation loss: 2.813871229848554

Epoch: 5| Step: 5
Training loss: 3.6692752838134766
Validation loss: 2.8135329190120903

Epoch: 5| Step: 6
Training loss: 2.5344817638397217
Validation loss: 2.8123177482235815

Epoch: 5| Step: 7
Training loss: 2.920457363128662
Validation loss: 2.811181024838519

Epoch: 5| Step: 8
Training loss: 2.834517240524292
Validation loss: 2.8109824016530025

Epoch: 5| Step: 9
Training loss: 2.6495635509490967
Validation loss: 2.8084298436359694

Epoch: 5| Step: 10
Training loss: 3.1099226474761963
Validation loss: 2.8087290486981793

Epoch: 58| Step: 0
Training loss: 2.9984025955200195
Validation loss: 2.8068289218410367

Epoch: 5| Step: 1
Training loss: 2.7205405235290527
Validation loss: 2.806745280501663

Epoch: 5| Step: 2
Training loss: 3.0726218223571777
Validation loss: 2.8116662886834916

Epoch: 5| Step: 3
Training loss: 3.044893264770508
Validation loss: 2.8168136714607157

Epoch: 5| Step: 4
Training loss: 2.9292349815368652
Validation loss: 2.819029010752196

Epoch: 5| Step: 5
Training loss: 3.1797616481781006
Validation loss: 2.8111735825897544

Epoch: 5| Step: 6
Training loss: 2.77545428276062
Validation loss: 2.8069221460691063

Epoch: 5| Step: 7
Training loss: 2.454489231109619
Validation loss: 2.8103484389602498

Epoch: 5| Step: 8
Training loss: 3.0604541301727295
Validation loss: 2.806209897482267

Epoch: 5| Step: 9
Training loss: 2.3848280906677246
Validation loss: 2.8051197939021613

Epoch: 5| Step: 10
Training loss: 3.699514389038086
Validation loss: 2.803089036736437

Epoch: 59| Step: 0
Training loss: 2.3961071968078613
Validation loss: 2.8033016163815736

Epoch: 5| Step: 1
Training loss: 2.2122018337249756
Validation loss: 2.800759361636254

Epoch: 5| Step: 2
Training loss: 3.5670440196990967
Validation loss: 2.8007388012383574

Epoch: 5| Step: 3
Training loss: 2.847774028778076
Validation loss: 2.802051131443311

Epoch: 5| Step: 4
Training loss: 2.9185256958007812
Validation loss: 2.8004900383692917

Epoch: 5| Step: 5
Training loss: 2.8381543159484863
Validation loss: 2.7996749544656403

Epoch: 5| Step: 6
Training loss: 3.471764326095581
Validation loss: 2.7981104902041856

Epoch: 5| Step: 7
Training loss: 2.4226157665252686
Validation loss: 2.799920633275022

Epoch: 5| Step: 8
Training loss: 3.571807384490967
Validation loss: 2.7977453483048307

Epoch: 5| Step: 9
Training loss: 2.9788966178894043
Validation loss: 2.794372994412658

Epoch: 5| Step: 10
Training loss: 2.916980028152466
Validation loss: 2.7973443359457035

Epoch: 60| Step: 0
Training loss: 3.1516318321228027
Validation loss: 2.7953709351119174

Epoch: 5| Step: 1
Training loss: 3.164766311645508
Validation loss: 2.7941777372872956

Epoch: 5| Step: 2
Training loss: 2.1969504356384277
Validation loss: 2.7977064835127963

Epoch: 5| Step: 3
Training loss: 2.253173828125
Validation loss: 2.7988933491450485

Epoch: 5| Step: 4
Training loss: 3.1034910678863525
Validation loss: 2.79488068754955

Epoch: 5| Step: 5
Training loss: 3.5296478271484375
Validation loss: 2.7964668940472346

Epoch: 5| Step: 6
Training loss: 2.149780511856079
Validation loss: 2.7955120225106516

Epoch: 5| Step: 7
Training loss: 3.2728123664855957
Validation loss: 2.7940584869794947

Epoch: 5| Step: 8
Training loss: 2.858041524887085
Validation loss: 2.7932527603641635

Epoch: 5| Step: 9
Training loss: 3.326580047607422
Validation loss: 2.793483787967313

Epoch: 5| Step: 10
Training loss: 3.150491952896118
Validation loss: 2.7947191576803885

Epoch: 61| Step: 0
Training loss: 3.4693732261657715
Validation loss: 2.796058903458298

Epoch: 5| Step: 1
Training loss: 3.496281385421753
Validation loss: 2.8001956093695854

Epoch: 5| Step: 2
Training loss: 1.9892343282699585
Validation loss: 2.7949338241290023

Epoch: 5| Step: 3
Training loss: 3.0750949382781982
Validation loss: 2.7885207770973124

Epoch: 5| Step: 4
Training loss: 3.0590970516204834
Validation loss: 2.7900242805480957

Epoch: 5| Step: 5
Training loss: 2.9422245025634766
Validation loss: 2.787722828567669

Epoch: 5| Step: 6
Training loss: 2.7395920753479004
Validation loss: 2.79239579426345

Epoch: 5| Step: 7
Training loss: 4.159125328063965
Validation loss: 2.791277136853946

Epoch: 5| Step: 8
Training loss: 2.8005900382995605
Validation loss: 2.787762129178611

Epoch: 5| Step: 9
Training loss: 2.2632508277893066
Validation loss: 2.7870978975808747

Epoch: 5| Step: 10
Training loss: 1.9315333366394043
Validation loss: 2.7836594863604476

Epoch: 62| Step: 0
Training loss: 2.7219619750976562
Validation loss: 2.7817688295918126

Epoch: 5| Step: 1
Training loss: 2.912781238555908
Validation loss: 2.782316533468103

Epoch: 5| Step: 2
Training loss: 2.4382236003875732
Validation loss: 2.782363712146718

Epoch: 5| Step: 3
Training loss: 3.593324661254883
Validation loss: 2.7814042234933503

Epoch: 5| Step: 4
Training loss: 2.571310043334961
Validation loss: 2.7831608300567954

Epoch: 5| Step: 5
Training loss: 3.6061205863952637
Validation loss: 2.777660687764486

Epoch: 5| Step: 6
Training loss: 2.597860813140869
Validation loss: 2.779680246947914

Epoch: 5| Step: 7
Training loss: 1.803628921508789
Validation loss: 2.778324141297289

Epoch: 5| Step: 8
Training loss: 3.158155918121338
Validation loss: 2.7781724468354256

Epoch: 5| Step: 9
Training loss: 3.0630009174346924
Validation loss: 2.7805420916567565

Epoch: 5| Step: 10
Training loss: 3.635274887084961
Validation loss: 2.7810675149322837

Epoch: 63| Step: 0
Training loss: 2.7615342140197754
Validation loss: 2.775789817174276

Epoch: 5| Step: 1
Training loss: 3.02312970161438
Validation loss: 2.7769496748524327

Epoch: 5| Step: 2
Training loss: 3.1478378772735596
Validation loss: 2.7741317133749686

Epoch: 5| Step: 3
Training loss: 3.0240864753723145
Validation loss: 2.774331259471114

Epoch: 5| Step: 4
Training loss: 2.5276479721069336
Validation loss: 2.7743975167633383

Epoch: 5| Step: 5
Training loss: 3.0894036293029785
Validation loss: 2.774780083728093

Epoch: 5| Step: 6
Training loss: 2.914707660675049
Validation loss: 2.772720559950798

Epoch: 5| Step: 7
Training loss: 2.8172125816345215
Validation loss: 2.7707297878880657

Epoch: 5| Step: 8
Training loss: 3.018207550048828
Validation loss: 2.7722020251776582

Epoch: 5| Step: 9
Training loss: 2.6099231243133545
Validation loss: 2.7716524754801104

Epoch: 5| Step: 10
Training loss: 3.0151753425598145
Validation loss: 2.772175735042941

Epoch: 64| Step: 0
Training loss: 2.653634786605835
Validation loss: 2.7688408615768596

Epoch: 5| Step: 1
Training loss: 3.333718776702881
Validation loss: 2.774220771687005

Epoch: 5| Step: 2
Training loss: 3.215406894683838
Validation loss: 2.772655748551892

Epoch: 5| Step: 3
Training loss: 2.938707113265991
Validation loss: 2.7685043427252

Epoch: 5| Step: 4
Training loss: 3.409414291381836
Validation loss: 2.770443836847941

Epoch: 5| Step: 5
Training loss: 2.634157419204712
Validation loss: 2.7711236451261785

Epoch: 5| Step: 6
Training loss: 2.7576823234558105
Validation loss: 2.765702591147474

Epoch: 5| Step: 7
Training loss: 3.322727918624878
Validation loss: 2.7636427264059744

Epoch: 5| Step: 8
Training loss: 2.851519823074341
Validation loss: 2.760833058305966

Epoch: 5| Step: 9
Training loss: 2.909212589263916
Validation loss: 2.7701478030091975

Epoch: 5| Step: 10
Training loss: 1.6942342519760132
Validation loss: 2.761744624824934

Epoch: 65| Step: 0
Training loss: 2.727870225906372
Validation loss: 2.766216931804534

Epoch: 5| Step: 1
Training loss: 2.759270668029785
Validation loss: 2.7658291555220083

Epoch: 5| Step: 2
Training loss: 2.6468544006347656
Validation loss: 2.76728811828039

Epoch: 5| Step: 3
Training loss: 3.2709879875183105
Validation loss: 2.761688860513831

Epoch: 5| Step: 4
Training loss: 2.294837474822998
Validation loss: 2.7593225227889193

Epoch: 5| Step: 5
Training loss: 3.3013968467712402
Validation loss: 2.7604796142988306

Epoch: 5| Step: 6
Training loss: 3.0781891345977783
Validation loss: 2.755377008068946

Epoch: 5| Step: 7
Training loss: 2.9368515014648438
Validation loss: 2.7577665467416086

Epoch: 5| Step: 8
Training loss: 2.707998752593994
Validation loss: 2.756022032871041

Epoch: 5| Step: 9
Training loss: 2.7851791381835938
Validation loss: 2.7590241509099163

Epoch: 5| Step: 10
Training loss: 3.39925479888916
Validation loss: 2.758050598124022

Epoch: 66| Step: 0
Training loss: 2.64996075630188
Validation loss: 2.7589768337947067

Epoch: 5| Step: 1
Training loss: 3.083848476409912
Validation loss: 2.7608440281242452

Epoch: 5| Step: 2
Training loss: 3.0546841621398926
Validation loss: 2.760477968441543

Epoch: 5| Step: 3
Training loss: 3.16920804977417
Validation loss: 2.7660872192792993

Epoch: 5| Step: 4
Training loss: 2.8988239765167236
Validation loss: 2.7621336624186528

Epoch: 5| Step: 5
Training loss: 2.8911068439483643
Validation loss: 2.7605643733855216

Epoch: 5| Step: 6
Training loss: 2.715641736984253
Validation loss: 2.7635176848339778

Epoch: 5| Step: 7
Training loss: 4.114640712738037
Validation loss: 2.7539312378052743

Epoch: 5| Step: 8
Training loss: 2.3516087532043457
Validation loss: 2.7540416486801638

Epoch: 5| Step: 9
Training loss: 2.807264804840088
Validation loss: 2.7542870583072787

Epoch: 5| Step: 10
Training loss: 1.9217900037765503
Validation loss: 2.7552269299825034

Epoch: 67| Step: 0
Training loss: 3.1932873725891113
Validation loss: 2.7610235111687773

Epoch: 5| Step: 1
Training loss: 2.7231383323669434
Validation loss: 2.7587098152406755

Epoch: 5| Step: 2
Training loss: 2.829359531402588
Validation loss: 2.7541635600469445

Epoch: 5| Step: 3
Training loss: 2.484074831008911
Validation loss: 2.7536046581883586

Epoch: 5| Step: 4
Training loss: 4.1960129737854
Validation loss: 2.7550856298015964

Epoch: 5| Step: 5
Training loss: 2.6563363075256348
Validation loss: 2.7542304685038905

Epoch: 5| Step: 6
Training loss: 3.3197083473205566
Validation loss: 2.7526469845925607

Epoch: 5| Step: 7
Training loss: 2.663557529449463
Validation loss: 2.752368944947438

Epoch: 5| Step: 8
Training loss: 2.7797811031341553
Validation loss: 2.74666230909286

Epoch: 5| Step: 9
Training loss: 1.8157867193222046
Validation loss: 2.74295739717381

Epoch: 5| Step: 10
Training loss: 3.18847393989563
Validation loss: 2.7495095012008504

Epoch: 68| Step: 0
Training loss: 3.385127305984497
Validation loss: 2.7463446047998246

Epoch: 5| Step: 1
Training loss: 2.554678440093994
Validation loss: 2.747315499090379

Epoch: 5| Step: 2
Training loss: 2.5681354999542236
Validation loss: 2.748640562898369

Epoch: 5| Step: 3
Training loss: 2.0264358520507812
Validation loss: 2.7483195104906635

Epoch: 5| Step: 4
Training loss: 2.55656361579895
Validation loss: 2.7486130627252723

Epoch: 5| Step: 5
Training loss: 2.903409481048584
Validation loss: 2.748768909003145

Epoch: 5| Step: 6
Training loss: 3.0124568939208984
Validation loss: 2.745599692867648

Epoch: 5| Step: 7
Training loss: 3.133138418197632
Validation loss: 2.746893931460637

Epoch: 5| Step: 8
Training loss: 3.1057775020599365
Validation loss: 2.74686852834558

Epoch: 5| Step: 9
Training loss: 3.754560947418213
Validation loss: 2.743704431800432

Epoch: 5| Step: 10
Training loss: 2.695923328399658
Validation loss: 2.74437984343498

Epoch: 69| Step: 0
Training loss: 3.0442140102386475
Validation loss: 2.745238232356246

Epoch: 5| Step: 1
Training loss: 2.947533369064331
Validation loss: 2.741236679015621

Epoch: 5| Step: 2
Training loss: 2.8783798217773438
Validation loss: 2.7424949702396186

Epoch: 5| Step: 3
Training loss: 2.9776179790496826
Validation loss: 2.7421285003744145

Epoch: 5| Step: 4
Training loss: 3.5173423290252686
Validation loss: 2.7459429053850073

Epoch: 5| Step: 5
Training loss: 3.032338857650757
Validation loss: 2.741545646421371

Epoch: 5| Step: 6
Training loss: 1.7958488464355469
Validation loss: 2.7424757916440248

Epoch: 5| Step: 7
Training loss: 2.854179859161377
Validation loss: 2.7400533409528833

Epoch: 5| Step: 8
Training loss: 2.918097972869873
Validation loss: 2.740822163961267

Epoch: 5| Step: 9
Training loss: 2.4096693992614746
Validation loss: 2.741077615368751

Epoch: 5| Step: 10
Training loss: 3.392127752304077
Validation loss: 2.743392454680576

Epoch: 70| Step: 0
Training loss: 2.9212255477905273
Validation loss: 2.7432111463239117

Epoch: 5| Step: 1
Training loss: 2.577261447906494
Validation loss: 2.7465098545115483

Epoch: 5| Step: 2
Training loss: 3.5611069202423096
Validation loss: 2.754455269023936

Epoch: 5| Step: 3
Training loss: 2.97857928276062
Validation loss: 2.742579888272029

Epoch: 5| Step: 4
Training loss: 2.664699077606201
Validation loss: 2.7449010085034113

Epoch: 5| Step: 5
Training loss: 2.606640338897705
Validation loss: 2.744669762990808

Epoch: 5| Step: 6
Training loss: 3.213000535964966
Validation loss: 2.743151577570105

Epoch: 5| Step: 7
Training loss: 2.3335204124450684
Validation loss: 2.7451619999383086

Epoch: 5| Step: 8
Training loss: 2.914185047149658
Validation loss: 2.7434867428195093

Epoch: 5| Step: 9
Training loss: 2.7392871379852295
Validation loss: 2.74048517083609

Epoch: 5| Step: 10
Training loss: 3.2695212364196777
Validation loss: 2.743263224119781

Epoch: 71| Step: 0
Training loss: 2.9563252925872803
Validation loss: 2.7398498801774878

Epoch: 5| Step: 1
Training loss: 2.4769864082336426
Validation loss: 2.741524838632153

Epoch: 5| Step: 2
Training loss: 2.989161252975464
Validation loss: 2.7410086483083744

Epoch: 5| Step: 3
Training loss: 3.602043628692627
Validation loss: 2.7362627598547165

Epoch: 5| Step: 4
Training loss: 2.838067054748535
Validation loss: 2.7393351472834104

Epoch: 5| Step: 5
Training loss: 2.961674213409424
Validation loss: 2.736081597625568

Epoch: 5| Step: 6
Training loss: 3.050105094909668
Validation loss: 2.7375559909369356

Epoch: 5| Step: 7
Training loss: 2.6956629753112793
Validation loss: 2.7361131919327604

Epoch: 5| Step: 8
Training loss: 2.880791187286377
Validation loss: 2.735801763432

Epoch: 5| Step: 9
Training loss: 2.8255653381347656
Validation loss: 2.7334613312957106

Epoch: 5| Step: 10
Training loss: 2.326526403427124
Validation loss: 2.7363378206888833

Epoch: 72| Step: 0
Training loss: 2.6857523918151855
Validation loss: 2.7381832932913177

Epoch: 5| Step: 1
Training loss: 2.7590079307556152
Validation loss: 2.736256625062676

Epoch: 5| Step: 2
Training loss: 2.5412044525146484
Validation loss: 2.7391336066748506

Epoch: 5| Step: 3
Training loss: 3.048806667327881
Validation loss: 2.746149755293323

Epoch: 5| Step: 4
Training loss: 2.7369165420532227
Validation loss: 2.7454937632365892

Epoch: 5| Step: 5
Training loss: 2.531035900115967
Validation loss: 2.7405677175009124

Epoch: 5| Step: 6
Training loss: 3.3836307525634766
Validation loss: 2.7410373995381017

Epoch: 5| Step: 7
Training loss: 2.6256203651428223
Validation loss: 2.7436954898218953

Epoch: 5| Step: 8
Training loss: 3.720970630645752
Validation loss: 2.737686340526868

Epoch: 5| Step: 9
Training loss: 3.073914051055908
Validation loss: 2.742313797755908

Epoch: 5| Step: 10
Training loss: 2.5204291343688965
Validation loss: 2.735902793945805

Epoch: 73| Step: 0
Training loss: 2.7730050086975098
Validation loss: 2.7286871146130305

Epoch: 5| Step: 1
Training loss: 2.892151355743408
Validation loss: 2.7309003235191427

Epoch: 5| Step: 2
Training loss: 2.361584186553955
Validation loss: 2.7324557714564826

Epoch: 5| Step: 3
Training loss: 2.9189319610595703
Validation loss: 2.7325226517133814

Epoch: 5| Step: 4
Training loss: 3.23925518989563
Validation loss: 2.7341768690334853

Epoch: 5| Step: 5
Training loss: 3.0583913326263428
Validation loss: 2.7390134514019056

Epoch: 5| Step: 6
Training loss: 2.8415095806121826
Validation loss: 2.7387243599020024

Epoch: 5| Step: 7
Training loss: 2.7571468353271484
Validation loss: 2.736548098184729

Epoch: 5| Step: 8
Training loss: 2.712209701538086
Validation loss: 2.732682727998303

Epoch: 5| Step: 9
Training loss: 3.2734031677246094
Validation loss: 2.734806130009313

Epoch: 5| Step: 10
Training loss: 2.85513973236084
Validation loss: 2.7297877034833355

Epoch: 74| Step: 0
Training loss: 4.109255313873291
Validation loss: 2.732984506955711

Epoch: 5| Step: 1
Training loss: 3.021083354949951
Validation loss: 2.7303060075288177

Epoch: 5| Step: 2
Training loss: 2.8673620223999023
Validation loss: 2.7320410590017996

Epoch: 5| Step: 3
Training loss: 3.120964527130127
Validation loss: 2.733274341911398

Epoch: 5| Step: 4
Training loss: 2.6026673316955566
Validation loss: 2.7354759682891188

Epoch: 5| Step: 5
Training loss: 3.0822596549987793
Validation loss: 2.7439692943326888

Epoch: 5| Step: 6
Training loss: 2.0758254528045654
Validation loss: 2.732884422425301

Epoch: 5| Step: 7
Training loss: 2.8910624980926514
Validation loss: 2.7307584106281237

Epoch: 5| Step: 8
Training loss: 1.4553991556167603
Validation loss: 2.7346814806743334

Epoch: 5| Step: 9
Training loss: 3.156329393386841
Validation loss: 2.734329605615267

Epoch: 5| Step: 10
Training loss: 3.2801687717437744
Validation loss: 2.7314087754936627

Epoch: 75| Step: 0
Training loss: 2.8117456436157227
Validation loss: 2.730431690010973

Epoch: 5| Step: 1
Training loss: 2.0355911254882812
Validation loss: 2.7278815520707

Epoch: 5| Step: 2
Training loss: 2.8939573764801025
Validation loss: 2.727773927873181

Epoch: 5| Step: 3
Training loss: 2.888375759124756
Validation loss: 2.729921212760351

Epoch: 5| Step: 4
Training loss: 2.844778060913086
Validation loss: 2.7302910333038657

Epoch: 5| Step: 5
Training loss: 2.934863567352295
Validation loss: 2.7288380669009302

Epoch: 5| Step: 6
Training loss: 2.443504571914673
Validation loss: 2.7289226337145736

Epoch: 5| Step: 7
Training loss: 4.013460159301758
Validation loss: 2.7283263411573184

Epoch: 5| Step: 8
Training loss: 2.4488039016723633
Validation loss: 2.7291065236573577

Epoch: 5| Step: 9
Training loss: 2.8097293376922607
Validation loss: 2.7273956216791624

Epoch: 5| Step: 10
Training loss: 3.581409454345703
Validation loss: 2.7266628255126295

Epoch: 76| Step: 0
Training loss: 2.8301048278808594
Validation loss: 2.728114830550327

Epoch: 5| Step: 1
Training loss: 3.0158989429473877
Validation loss: 2.72639210249788

Epoch: 5| Step: 2
Training loss: 2.7913882732391357
Validation loss: 2.7214734169744674

Epoch: 5| Step: 3
Training loss: 2.6847431659698486
Validation loss: 2.721461183281355

Epoch: 5| Step: 4
Training loss: 3.1224253177642822
Validation loss: 2.725960990434052

Epoch: 5| Step: 5
Training loss: 2.424503803253174
Validation loss: 2.7242011665016093

Epoch: 5| Step: 6
Training loss: 2.9854824542999268
Validation loss: 2.728428271508986

Epoch: 5| Step: 7
Training loss: 2.793722629547119
Validation loss: 2.727338585802304

Epoch: 5| Step: 8
Training loss: 2.4522242546081543
Validation loss: 2.730411047576576

Epoch: 5| Step: 9
Training loss: 3.5565452575683594
Validation loss: 2.727237004105763

Epoch: 5| Step: 10
Training loss: 2.9094738960266113
Validation loss: 2.7293607240082114

Epoch: 77| Step: 0
Training loss: 2.472637891769409
Validation loss: 2.7297255992889404

Epoch: 5| Step: 1
Training loss: 3.471534013748169
Validation loss: 2.7272104294069353

Epoch: 5| Step: 2
Training loss: 3.503060817718506
Validation loss: 2.727202899994389

Epoch: 5| Step: 3
Training loss: 2.5746750831604004
Validation loss: 2.72273059814207

Epoch: 5| Step: 4
Training loss: 1.8496507406234741
Validation loss: 2.722910463169057

Epoch: 5| Step: 5
Training loss: 2.4161839485168457
Validation loss: 2.725730406340732

Epoch: 5| Step: 6
Training loss: 2.631805896759033
Validation loss: 2.727987702174853

Epoch: 5| Step: 7
Training loss: 2.8781328201293945
Validation loss: 2.7242484861804592

Epoch: 5| Step: 8
Training loss: 3.3891990184783936
Validation loss: 2.7191961631979993

Epoch: 5| Step: 9
Training loss: 3.3082222938537598
Validation loss: 2.7171232110710553

Epoch: 5| Step: 10
Training loss: 3.095060348510742
Validation loss: 2.7178575095310005

Epoch: 78| Step: 0
Training loss: 2.677222490310669
Validation loss: 2.7235757868777037

Epoch: 5| Step: 1
Training loss: 2.753430128097534
Validation loss: 2.726667542611399

Epoch: 5| Step: 2
Training loss: 1.9936597347259521
Validation loss: 2.7236728514394453

Epoch: 5| Step: 3
Training loss: 3.2191009521484375
Validation loss: 2.7248311042785645

Epoch: 5| Step: 4
Training loss: 2.4109859466552734
Validation loss: 2.7296635720037643

Epoch: 5| Step: 5
Training loss: 2.9572558403015137
Validation loss: 2.7254240128301803

Epoch: 5| Step: 6
Training loss: 3.003722667694092
Validation loss: 2.7198799220464562

Epoch: 5| Step: 7
Training loss: 3.7339768409729004
Validation loss: 2.7232441620160173

Epoch: 5| Step: 8
Training loss: 2.825119733810425
Validation loss: 2.722592048747565

Epoch: 5| Step: 9
Training loss: 2.8958868980407715
Validation loss: 2.721329576225691

Epoch: 5| Step: 10
Training loss: 3.1430552005767822
Validation loss: 2.720793593314386

Epoch: 79| Step: 0
Training loss: 2.6285696029663086
Validation loss: 2.718518118704519

Epoch: 5| Step: 1
Training loss: 2.7792248725891113
Validation loss: 2.7186323647857993

Epoch: 5| Step: 2
Training loss: 3.0955052375793457
Validation loss: 2.7172763629626204

Epoch: 5| Step: 3
Training loss: 2.6416635513305664
Validation loss: 2.7204522573819725

Epoch: 5| Step: 4
Training loss: 2.9798197746276855
Validation loss: 2.7229004444614535

Epoch: 5| Step: 5
Training loss: 3.1560676097869873
Validation loss: 2.7256148194753997

Epoch: 5| Step: 6
Training loss: 3.2850983142852783
Validation loss: 2.728102684020996

Epoch: 5| Step: 7
Training loss: 2.170685052871704
Validation loss: 2.7144917493225424

Epoch: 5| Step: 8
Training loss: 4.037528991699219
Validation loss: 2.718394764008061

Epoch: 5| Step: 9
Training loss: 2.261476993560791
Validation loss: 2.719687036288682

Epoch: 5| Step: 10
Training loss: 2.4149062633514404
Validation loss: 2.716900219199478

Epoch: 80| Step: 0
Training loss: 2.962965488433838
Validation loss: 2.718332229122039

Epoch: 5| Step: 1
Training loss: 3.0374062061309814
Validation loss: 2.716894567653697

Epoch: 5| Step: 2
Training loss: 2.4693968296051025
Validation loss: 2.7202654807798323

Epoch: 5| Step: 3
Training loss: 3.2147879600524902
Validation loss: 2.7176711046567528

Epoch: 5| Step: 4
Training loss: 2.4668796062469482
Validation loss: 2.7237419261727283

Epoch: 5| Step: 5
Training loss: 3.261517286300659
Validation loss: 2.7238207478677072

Epoch: 5| Step: 6
Training loss: 2.836427927017212
Validation loss: 2.7153924254960913

Epoch: 5| Step: 7
Training loss: 3.097170352935791
Validation loss: 2.7202438180164625

Epoch: 5| Step: 8
Training loss: 2.797393560409546
Validation loss: 2.7249669439049176

Epoch: 5| Step: 9
Training loss: 2.1615653038024902
Validation loss: 2.7167845567067466

Epoch: 5| Step: 10
Training loss: 3.283531665802002
Validation loss: 2.718383078934044

Epoch: 81| Step: 0
Training loss: 3.316821575164795
Validation loss: 2.719233589787637

Epoch: 5| Step: 1
Training loss: 2.6893224716186523
Validation loss: 2.718617711015927

Epoch: 5| Step: 2
Training loss: 2.82075834274292
Validation loss: 2.720289235473961

Epoch: 5| Step: 3
Training loss: 2.629915237426758
Validation loss: 2.7178880835092194

Epoch: 5| Step: 4
Training loss: 2.527139186859131
Validation loss: 2.715902290036601

Epoch: 5| Step: 5
Training loss: 2.508756637573242
Validation loss: 2.7188656150653796

Epoch: 5| Step: 6
Training loss: 3.283132553100586
Validation loss: 2.7186925180496706

Epoch: 5| Step: 7
Training loss: 2.220500946044922
Validation loss: 2.7152661969584804

Epoch: 5| Step: 8
Training loss: 3.4006755352020264
Validation loss: 2.715336209984236

Epoch: 5| Step: 9
Training loss: 3.2199387550354004
Validation loss: 2.7148899006587204

Epoch: 5| Step: 10
Training loss: 2.89400315284729
Validation loss: 2.714212412475258

Epoch: 82| Step: 0
Training loss: 3.4173359870910645
Validation loss: 2.7131393647963002

Epoch: 5| Step: 1
Training loss: 2.2235560417175293
Validation loss: 2.71161477540129

Epoch: 5| Step: 2
Training loss: 2.65290904045105
Validation loss: 2.7155308159448768

Epoch: 5| Step: 3
Training loss: 3.0768280029296875
Validation loss: 2.714249692937379

Epoch: 5| Step: 4
Training loss: 3.5763869285583496
Validation loss: 2.7179775930220083

Epoch: 5| Step: 5
Training loss: 3.2233994007110596
Validation loss: 2.7169736123854116

Epoch: 5| Step: 6
Training loss: 2.594419479370117
Validation loss: 2.722744280292142

Epoch: 5| Step: 7
Training loss: 2.4386305809020996
Validation loss: 2.712144310756396

Epoch: 5| Step: 8
Training loss: 2.856637477874756
Validation loss: 2.711086021956577

Epoch: 5| Step: 9
Training loss: 2.8900725841522217
Validation loss: 2.713883779382193

Epoch: 5| Step: 10
Training loss: 2.438141107559204
Validation loss: 2.715136961270404

Epoch: 83| Step: 0
Training loss: 2.465003490447998
Validation loss: 2.7162558981167373

Epoch: 5| Step: 1
Training loss: 2.9033684730529785
Validation loss: 2.7133012945934007

Epoch: 5| Step: 2
Training loss: 2.403346538543701
Validation loss: 2.71533416932629

Epoch: 5| Step: 3
Training loss: 3.236997127532959
Validation loss: 2.7117320235057543

Epoch: 5| Step: 4
Training loss: 1.8802299499511719
Validation loss: 2.712366980891074

Epoch: 5| Step: 5
Training loss: 2.60788893699646
Validation loss: 2.710157855864494

Epoch: 5| Step: 6
Training loss: 2.882805824279785
Validation loss: 2.7115996063396497

Epoch: 5| Step: 7
Training loss: 3.074284315109253
Validation loss: 2.710474665446948

Epoch: 5| Step: 8
Training loss: 3.45068359375
Validation loss: 2.7160912047150316

Epoch: 5| Step: 9
Training loss: 3.5771377086639404
Validation loss: 2.717279380367648

Epoch: 5| Step: 10
Training loss: 2.9703893661499023
Validation loss: 2.714548062252742

Epoch: 84| Step: 0
Training loss: 2.792710542678833
Validation loss: 2.7175615192741476

Epoch: 5| Step: 1
Training loss: 2.391589641571045
Validation loss: 2.7109801051437215

Epoch: 5| Step: 2
Training loss: 2.9397168159484863
Validation loss: 2.7108614624187513

Epoch: 5| Step: 3
Training loss: 2.958523988723755
Validation loss: 2.703952891852266

Epoch: 5| Step: 4
Training loss: 2.9719314575195312
Validation loss: 2.710019393633771

Epoch: 5| Step: 5
Training loss: 2.657043933868408
Validation loss: 2.7100100645454983

Epoch: 5| Step: 6
Training loss: 3.1385748386383057
Validation loss: 2.703806415680916

Epoch: 5| Step: 7
Training loss: 2.986349582672119
Validation loss: 2.7022017253342496

Epoch: 5| Step: 8
Training loss: 3.681475877761841
Validation loss: 2.7044092480854323

Epoch: 5| Step: 9
Training loss: 2.650773525238037
Validation loss: 2.7041429012052474

Epoch: 5| Step: 10
Training loss: 2.1468989849090576
Validation loss: 2.7044355689838366

Epoch: 85| Step: 0
Training loss: 2.9940898418426514
Validation loss: 2.7068821948061705

Epoch: 5| Step: 1
Training loss: 2.5477261543273926
Validation loss: 2.705127610955187

Epoch: 5| Step: 2
Training loss: 3.361027479171753
Validation loss: 2.7078381584536646

Epoch: 5| Step: 3
Training loss: 3.0987932682037354
Validation loss: 2.7025973412298385

Epoch: 5| Step: 4
Training loss: 2.1541430950164795
Validation loss: 2.709644138172109

Epoch: 5| Step: 5
Training loss: 3.1899263858795166
Validation loss: 2.7106818409376245

Epoch: 5| Step: 6
Training loss: 2.6835811138153076
Validation loss: 2.708050186916064

Epoch: 5| Step: 7
Training loss: 2.8625407218933105
Validation loss: 2.709773927606562

Epoch: 5| Step: 8
Training loss: 2.884251117706299
Validation loss: 2.7087695214056198

Epoch: 5| Step: 9
Training loss: 2.3664774894714355
Validation loss: 2.704589000312231

Epoch: 5| Step: 10
Training loss: 3.2979719638824463
Validation loss: 2.705474263878279

Epoch: 86| Step: 0
Training loss: 2.856325626373291
Validation loss: 2.7075783514207408

Epoch: 5| Step: 1
Training loss: 3.1066486835479736
Validation loss: 2.707216739654541

Epoch: 5| Step: 2
Training loss: 2.338022470474243
Validation loss: 2.707608205015941

Epoch: 5| Step: 3
Training loss: 3.4580464363098145
Validation loss: 2.7151594802897465

Epoch: 5| Step: 4
Training loss: 3.1061697006225586
Validation loss: 2.713807152163598

Epoch: 5| Step: 5
Training loss: 2.3503897190093994
Validation loss: 2.713635621532317

Epoch: 5| Step: 6
Training loss: 2.7654623985290527
Validation loss: 2.7053514552372757

Epoch: 5| Step: 7
Training loss: 2.7162041664123535
Validation loss: 2.7055256007820048

Epoch: 5| Step: 8
Training loss: 3.0179686546325684
Validation loss: 2.7007090712106354

Epoch: 5| Step: 9
Training loss: 2.7399420738220215
Validation loss: 2.700911778275685

Epoch: 5| Step: 10
Training loss: 2.9311277866363525
Validation loss: 2.698299359249812

Epoch: 87| Step: 0
Training loss: 2.887355089187622
Validation loss: 2.700555747555148

Epoch: 5| Step: 1
Training loss: 3.3033034801483154
Validation loss: 2.704652850345899

Epoch: 5| Step: 2
Training loss: 3.307331085205078
Validation loss: 2.703068594778738

Epoch: 5| Step: 3
Training loss: 2.4121761322021484
Validation loss: 2.705469339124618

Epoch: 5| Step: 4
Training loss: 2.250319004058838
Validation loss: 2.70439395084176

Epoch: 5| Step: 5
Training loss: 3.2595748901367188
Validation loss: 2.700161149424891

Epoch: 5| Step: 6
Training loss: 2.8841733932495117
Validation loss: 2.701848409509146

Epoch: 5| Step: 7
Training loss: 2.0003209114074707
Validation loss: 2.6980879447793447

Epoch: 5| Step: 8
Training loss: 2.754135847091675
Validation loss: 2.6984581126961658

Epoch: 5| Step: 9
Training loss: 3.2615113258361816
Validation loss: 2.6968459211369997

Epoch: 5| Step: 10
Training loss: 3.1149821281433105
Validation loss: 2.697741216228854

Epoch: 88| Step: 0
Training loss: 2.901249885559082
Validation loss: 2.6969723547658613

Epoch: 5| Step: 1
Training loss: 2.299107313156128
Validation loss: 2.7003528738534577

Epoch: 5| Step: 2
Training loss: 3.225072145462036
Validation loss: 2.698786602225355

Epoch: 5| Step: 3
Training loss: 2.6044728755950928
Validation loss: 2.7044593518780125

Epoch: 5| Step: 4
Training loss: 2.050358295440674
Validation loss: 2.7030891346675094

Epoch: 5| Step: 5
Training loss: 2.9432549476623535
Validation loss: 2.7033271405004684

Epoch: 5| Step: 6
Training loss: 3.528043031692505
Validation loss: 2.705663509266351

Epoch: 5| Step: 7
Training loss: 2.898275375366211
Validation loss: 2.7076472056809293

Epoch: 5| Step: 8
Training loss: 2.875424861907959
Validation loss: 2.701848291581677

Epoch: 5| Step: 9
Training loss: 2.750894069671631
Validation loss: 2.6992034963382188

Epoch: 5| Step: 10
Training loss: 3.3172523975372314
Validation loss: 2.6939488534004457

Epoch: 89| Step: 0
Training loss: 3.1725261211395264
Validation loss: 2.6969811659987255

Epoch: 5| Step: 1
Training loss: 2.1146953105926514
Validation loss: 2.6969040388702066

Epoch: 5| Step: 2
Training loss: 2.8682661056518555
Validation loss: 2.699407305768741

Epoch: 5| Step: 3
Training loss: 2.8602941036224365
Validation loss: 2.6987087521501767

Epoch: 5| Step: 4
Training loss: 3.730384111404419
Validation loss: 2.6968741263112714

Epoch: 5| Step: 5
Training loss: 2.8564341068267822
Validation loss: 2.6972506277022825

Epoch: 5| Step: 6
Training loss: 2.5275909900665283
Validation loss: 2.696294573045546

Epoch: 5| Step: 7
Training loss: 3.048231840133667
Validation loss: 2.6950447431174656

Epoch: 5| Step: 8
Training loss: 3.051727771759033
Validation loss: 2.69474720954895

Epoch: 5| Step: 9
Training loss: 2.7453296184539795
Validation loss: 2.694307642598306

Epoch: 5| Step: 10
Training loss: 2.194410562515259
Validation loss: 2.692936130749282

Epoch: 90| Step: 0
Training loss: 2.185356378555298
Validation loss: 2.691258233080628

Epoch: 5| Step: 1
Training loss: 2.506082057952881
Validation loss: 2.6861427753202376

Epoch: 5| Step: 2
Training loss: 2.7578988075256348
Validation loss: 2.6875384289731263

Epoch: 5| Step: 3
Training loss: 3.1486639976501465
Validation loss: 2.684179400884977

Epoch: 5| Step: 4
Training loss: 3.0397496223449707
Validation loss: 2.685430262678413

Epoch: 5| Step: 5
Training loss: 2.8179872035980225
Validation loss: 2.679299541698989

Epoch: 5| Step: 6
Training loss: 2.665391445159912
Validation loss: 2.678718246439452

Epoch: 5| Step: 7
Training loss: 3.2348411083221436
Validation loss: 2.6765026251475015

Epoch: 5| Step: 8
Training loss: 2.933183193206787
Validation loss: 2.681692538722869

Epoch: 5| Step: 9
Training loss: 2.44687819480896
Validation loss: 2.684081126284856

Epoch: 5| Step: 10
Training loss: 3.547994613647461
Validation loss: 2.704468363074846

Epoch: 91| Step: 0
Training loss: 2.138735771179199
Validation loss: 2.6867052329483854

Epoch: 5| Step: 1
Training loss: 2.8713438510894775
Validation loss: 2.6835554415179836

Epoch: 5| Step: 2
Training loss: 2.85978627204895
Validation loss: 2.6776345904155443

Epoch: 5| Step: 3
Training loss: 3.2302486896514893
Validation loss: 2.6783490565515335

Epoch: 5| Step: 4
Training loss: 2.9010653495788574
Validation loss: 2.678341322047736

Epoch: 5| Step: 5
Training loss: 2.635972261428833
Validation loss: 2.6806421202998005

Epoch: 5| Step: 6
Training loss: 2.792504072189331
Validation loss: 2.682751114650439

Epoch: 5| Step: 7
Training loss: 2.867969512939453
Validation loss: 2.6822503612887476

Epoch: 5| Step: 8
Training loss: 1.9737017154693604
Validation loss: 2.680192247513802

Epoch: 5| Step: 9
Training loss: 3.4904980659484863
Validation loss: 2.684326664094002

Epoch: 5| Step: 10
Training loss: 3.5279502868652344
Validation loss: 2.6832924606979534

Epoch: 92| Step: 0
Training loss: 2.6878163814544678
Validation loss: 2.6803444303492063

Epoch: 5| Step: 1
Training loss: 2.9416775703430176
Validation loss: 2.6781477389797086

Epoch: 5| Step: 2
Training loss: 2.5210819244384766
Validation loss: 2.675285539319438

Epoch: 5| Step: 3
Training loss: 2.35097074508667
Validation loss: 2.673988752467658

Epoch: 5| Step: 4
Training loss: 3.320199966430664
Validation loss: 2.673477057487734

Epoch: 5| Step: 5
Training loss: 2.8334949016571045
Validation loss: 2.6717186461212816

Epoch: 5| Step: 6
Training loss: 3.333989381790161
Validation loss: 2.6716251168199765

Epoch: 5| Step: 7
Training loss: 2.7772347927093506
Validation loss: 2.6709594547107653

Epoch: 5| Step: 8
Training loss: 2.8275482654571533
Validation loss: 2.668478527376729

Epoch: 5| Step: 9
Training loss: 3.1095547676086426
Validation loss: 2.671845151532081

Epoch: 5| Step: 10
Training loss: 2.348407030105591
Validation loss: 2.669564057421941

Epoch: 93| Step: 0
Training loss: 3.3309683799743652
Validation loss: 2.667086737130278

Epoch: 5| Step: 1
Training loss: 2.2710227966308594
Validation loss: 2.665503424982871

Epoch: 5| Step: 2
Training loss: 1.9473994970321655
Validation loss: 2.666636718216763

Epoch: 5| Step: 3
Training loss: 2.9808545112609863
Validation loss: 2.6638198693593345

Epoch: 5| Step: 4
Training loss: 2.9471428394317627
Validation loss: 2.6682574851538545

Epoch: 5| Step: 5
Training loss: 2.7086939811706543
Validation loss: 2.665524957000568

Epoch: 5| Step: 6
Training loss: 3.4233384132385254
Validation loss: 2.666053751463531

Epoch: 5| Step: 7
Training loss: 3.1098592281341553
Validation loss: 2.6607482484591904

Epoch: 5| Step: 8
Training loss: 2.825953960418701
Validation loss: 2.659610027907997

Epoch: 5| Step: 9
Training loss: 2.610703229904175
Validation loss: 2.661153160115724

Epoch: 5| Step: 10
Training loss: 2.8886940479278564
Validation loss: 2.6619011394439207

Epoch: 94| Step: 0
Training loss: 3.080303192138672
Validation loss: 2.65883191170231

Epoch: 5| Step: 1
Training loss: 3.5013084411621094
Validation loss: 2.6563603365293114

Epoch: 5| Step: 2
Training loss: 2.785576581954956
Validation loss: 2.656428365297215

Epoch: 5| Step: 3
Training loss: 2.2293787002563477
Validation loss: 2.655231745012345

Epoch: 5| Step: 4
Training loss: 3.540654420852661
Validation loss: 2.655077418973369

Epoch: 5| Step: 5
Training loss: 2.8387179374694824
Validation loss: 2.652234408163255

Epoch: 5| Step: 6
Training loss: 2.636801242828369
Validation loss: 2.6533047947832333

Epoch: 5| Step: 7
Training loss: 3.2764739990234375
Validation loss: 2.648200773423718

Epoch: 5| Step: 8
Training loss: 2.4952495098114014
Validation loss: 2.6515854558637066

Epoch: 5| Step: 9
Training loss: 1.8180274963378906
Validation loss: 2.6522309113574285

Epoch: 5| Step: 10
Training loss: 2.769259214401245
Validation loss: 2.6484347876682075

Epoch: 95| Step: 0
Training loss: 3.65818452835083
Validation loss: 2.648309079549646

Epoch: 5| Step: 1
Training loss: 3.042785167694092
Validation loss: 2.6495603771619898

Epoch: 5| Step: 2
Training loss: 2.919238567352295
Validation loss: 2.6504518396110943

Epoch: 5| Step: 3
Training loss: 2.082024097442627
Validation loss: 2.6469300331607943

Epoch: 5| Step: 4
Training loss: 2.150740623474121
Validation loss: 2.649365850674209

Epoch: 5| Step: 5
Training loss: 2.2105679512023926
Validation loss: 2.645662200066351

Epoch: 5| Step: 6
Training loss: 2.7034995555877686
Validation loss: 2.6468190352121987

Epoch: 5| Step: 7
Training loss: 3.532670259475708
Validation loss: 2.6504505936817457

Epoch: 5| Step: 8
Training loss: 2.9495110511779785
Validation loss: 2.647170925653109

Epoch: 5| Step: 9
Training loss: 2.3146328926086426
Validation loss: 2.647301022724439

Epoch: 5| Step: 10
Training loss: 3.445155143737793
Validation loss: 2.649109968575098

Epoch: 96| Step: 0
Training loss: 2.0881855487823486
Validation loss: 2.6458567368086947

Epoch: 5| Step: 1
Training loss: 2.747828245162964
Validation loss: 2.6449949382453837

Epoch: 5| Step: 2
Training loss: 3.6160736083984375
Validation loss: 2.6503769556681314

Epoch: 5| Step: 3
Training loss: 3.3010635375976562
Validation loss: 2.646129970909447

Epoch: 5| Step: 4
Training loss: 2.9415199756622314
Validation loss: 2.6493761231822353

Epoch: 5| Step: 5
Training loss: 2.754429340362549
Validation loss: 2.6535170514096498

Epoch: 5| Step: 6
Training loss: 3.1132054328918457
Validation loss: 2.654310505877259

Epoch: 5| Step: 7
Training loss: 1.810847520828247
Validation loss: 2.6545742224621516

Epoch: 5| Step: 8
Training loss: 3.1305906772613525
Validation loss: 2.6481054418830463

Epoch: 5| Step: 9
Training loss: 2.25891375541687
Validation loss: 2.649204482314407

Epoch: 5| Step: 10
Training loss: 3.2488794326782227
Validation loss: 2.6504285668814056

Epoch: 97| Step: 0
Training loss: 2.783133029937744
Validation loss: 2.6448337160130984

Epoch: 5| Step: 1
Training loss: 3.5245354175567627
Validation loss: 2.647876290864842

Epoch: 5| Step: 2
Training loss: 2.996095895767212
Validation loss: 2.6488097560021187

Epoch: 5| Step: 3
Training loss: 2.550952196121216
Validation loss: 2.6468663446364866

Epoch: 5| Step: 4
Training loss: 3.1585497856140137
Validation loss: 2.644034972754858

Epoch: 5| Step: 5
Training loss: 2.631530523300171
Validation loss: 2.64543588443469

Epoch: 5| Step: 6
Training loss: 1.6391957998275757
Validation loss: 2.6464331201327744

Epoch: 5| Step: 7
Training loss: 3.061835765838623
Validation loss: 2.645941401040682

Epoch: 5| Step: 8
Training loss: 3.4193851947784424
Validation loss: 2.6496309080431537

Epoch: 5| Step: 9
Training loss: 2.565382480621338
Validation loss: 2.6517278173918366

Epoch: 5| Step: 10
Training loss: 2.5777952671051025
Validation loss: 2.65644653894568

Epoch: 98| Step: 0
Training loss: 2.947460651397705
Validation loss: 2.653530349013626

Epoch: 5| Step: 1
Training loss: 3.31431245803833
Validation loss: 2.6463322331828456

Epoch: 5| Step: 2
Training loss: 2.882091522216797
Validation loss: 2.6397572204630864

Epoch: 5| Step: 3
Training loss: 2.9965405464172363
Validation loss: 2.6391022641171693

Epoch: 5| Step: 4
Training loss: 2.759788990020752
Validation loss: 2.6395304228669856

Epoch: 5| Step: 5
Training loss: 2.519310712814331
Validation loss: 2.638472636540731

Epoch: 5| Step: 6
Training loss: 3.0972204208374023
Validation loss: 2.641869748792341

Epoch: 5| Step: 7
Training loss: 2.308181047439575
Validation loss: 2.6557087282980643

Epoch: 5| Step: 8
Training loss: 2.840027332305908
Validation loss: 2.6805567356847946

Epoch: 5| Step: 9
Training loss: 2.7348477840423584
Validation loss: 2.689323689347954

Epoch: 5| Step: 10
Training loss: 2.4869885444641113
Validation loss: 2.669371474173761

Epoch: 99| Step: 0
Training loss: 2.7250113487243652
Validation loss: 2.6458294340359267

Epoch: 5| Step: 1
Training loss: 2.694675922393799
Validation loss: 2.6425799990213044

Epoch: 5| Step: 2
Training loss: 2.5812582969665527
Validation loss: 2.642512798309326

Epoch: 5| Step: 3
Training loss: 3.150585889816284
Validation loss: 2.6423694625977547

Epoch: 5| Step: 4
Training loss: 2.1527180671691895
Validation loss: 2.6425712595703783

Epoch: 5| Step: 5
Training loss: 3.246135711669922
Validation loss: 2.64404139467465

Epoch: 5| Step: 6
Training loss: 3.200524091720581
Validation loss: 2.6421645200380715

Epoch: 5| Step: 7
Training loss: 3.034045457839966
Validation loss: 2.644191659906859

Epoch: 5| Step: 8
Training loss: 2.4121804237365723
Validation loss: 2.6434920654501965

Epoch: 5| Step: 9
Training loss: 2.310062885284424
Validation loss: 2.6432919989350023

Epoch: 5| Step: 10
Training loss: 3.49518084526062
Validation loss: 2.644083922909152

Epoch: 100| Step: 0
Training loss: 3.0532288551330566
Validation loss: 2.6436689079448743

Epoch: 5| Step: 1
Training loss: 2.4752197265625
Validation loss: 2.647129222910891

Epoch: 5| Step: 2
Training loss: 3.0704450607299805
Validation loss: 2.645362807858375

Epoch: 5| Step: 3
Training loss: 2.910720109939575
Validation loss: 2.6490038543619137

Epoch: 5| Step: 4
Training loss: 2.73576021194458
Validation loss: 2.6473862201936784

Epoch: 5| Step: 5
Training loss: 2.7183241844177246
Validation loss: 2.6403364263555056

Epoch: 5| Step: 6
Training loss: 3.3377633094787598
Validation loss: 2.638435515024329

Epoch: 5| Step: 7
Training loss: 2.789090633392334
Validation loss: 2.641831797938193

Epoch: 5| Step: 8
Training loss: 2.322340250015259
Validation loss: 2.6353859824519

Epoch: 5| Step: 9
Training loss: 3.0732667446136475
Validation loss: 2.637353217729958

Epoch: 5| Step: 10
Training loss: 2.299386501312256
Validation loss: 2.639654380018993

Epoch: 101| Step: 0
Training loss: 2.9628610610961914
Validation loss: 2.6333695714191725

Epoch: 5| Step: 1
Training loss: 2.3209664821624756
Validation loss: 2.6298671871103267

Epoch: 5| Step: 2
Training loss: 2.3514552116394043
Validation loss: 2.6309291829345045

Epoch: 5| Step: 3
Training loss: 2.8925185203552246
Validation loss: 2.6300794988550167

Epoch: 5| Step: 4
Training loss: 2.772312641143799
Validation loss: 2.6339848041534424

Epoch: 5| Step: 5
Training loss: 3.16025972366333
Validation loss: 2.634862497288694

Epoch: 5| Step: 6
Training loss: 3.720027446746826
Validation loss: 2.635244036233553

Epoch: 5| Step: 7
Training loss: 2.7719614505767822
Validation loss: 2.634671259951848

Epoch: 5| Step: 8
Training loss: 2.3971548080444336
Validation loss: 2.6380465671580327

Epoch: 5| Step: 9
Training loss: 2.885607957839966
Validation loss: 2.6343633282569145

Epoch: 5| Step: 10
Training loss: 2.5060465335845947
Validation loss: 2.6336572593258274

Epoch: 102| Step: 0
Training loss: 3.1124298572540283
Validation loss: 2.635655774865099

Epoch: 5| Step: 1
Training loss: 3.2225029468536377
Validation loss: 2.630292961674352

Epoch: 5| Step: 2
Training loss: 2.3297510147094727
Validation loss: 2.6367038449933453

Epoch: 5| Step: 3
Training loss: 3.3513827323913574
Validation loss: 2.6336059749767347

Epoch: 5| Step: 4
Training loss: 2.5353496074676514
Validation loss: 2.630395430390553

Epoch: 5| Step: 5
Training loss: 2.805098295211792
Validation loss: 2.6299025448419715

Epoch: 5| Step: 6
Training loss: 2.459049701690674
Validation loss: 2.628664375633322

Epoch: 5| Step: 7
Training loss: 2.2962307929992676
Validation loss: 2.6271582675236527

Epoch: 5| Step: 8
Training loss: 2.950753927230835
Validation loss: 2.627459059479416

Epoch: 5| Step: 9
Training loss: 3.098503589630127
Validation loss: 2.6265750854246077

Epoch: 5| Step: 10
Training loss: 2.5897581577301025
Validation loss: 2.6267663996706725

Epoch: 103| Step: 0
Training loss: 2.5466179847717285
Validation loss: 2.6264453408538655

Epoch: 5| Step: 1
Training loss: 2.48213529586792
Validation loss: 2.62474307193551

Epoch: 5| Step: 2
Training loss: 3.7154650688171387
Validation loss: 2.626861902975267

Epoch: 5| Step: 3
Training loss: 3.6249725818634033
Validation loss: 2.6252913295581775

Epoch: 5| Step: 4
Training loss: 2.3809595108032227
Validation loss: 2.6223917930356917

Epoch: 5| Step: 5
Training loss: 2.79272723197937
Validation loss: 2.6258055779241745

Epoch: 5| Step: 6
Training loss: 3.0647034645080566
Validation loss: 2.6233810865750877

Epoch: 5| Step: 7
Training loss: 2.67384672164917
Validation loss: 2.624190766324279

Epoch: 5| Step: 8
Training loss: 2.517674684524536
Validation loss: 2.618555212533602

Epoch: 5| Step: 9
Training loss: 2.1938226222991943
Validation loss: 2.6270724470897386

Epoch: 5| Step: 10
Training loss: 2.755786657333374
Validation loss: 2.6312658607318835

Epoch: 104| Step: 0
Training loss: 2.223280191421509
Validation loss: 2.6234674992099887

Epoch: 5| Step: 1
Training loss: 3.2719123363494873
Validation loss: 2.6199154059092202

Epoch: 5| Step: 2
Training loss: 2.281628370285034
Validation loss: 2.617712769457089

Epoch: 5| Step: 3
Training loss: 3.165443181991577
Validation loss: 2.6194323749952417

Epoch: 5| Step: 4
Training loss: 2.613832712173462
Validation loss: 2.6218731057259346

Epoch: 5| Step: 5
Training loss: 2.721053123474121
Validation loss: 2.619747179810719

Epoch: 5| Step: 6
Training loss: 2.660672426223755
Validation loss: 2.6140593662056872

Epoch: 5| Step: 7
Training loss: 3.187268018722534
Validation loss: 2.6204373810880925

Epoch: 5| Step: 8
Training loss: 3.7067627906799316
Validation loss: 2.6175176635865243

Epoch: 5| Step: 9
Training loss: 2.336951494216919
Validation loss: 2.61815655872386

Epoch: 5| Step: 10
Training loss: 2.4959237575531006
Validation loss: 2.6194116838516726

Epoch: 105| Step: 0
Training loss: 3.7199547290802
Validation loss: 2.625487889012983

Epoch: 5| Step: 1
Training loss: 2.7595067024230957
Validation loss: 2.621891406274611

Epoch: 5| Step: 2
Training loss: 1.9616988897323608
Validation loss: 2.623828939212266

Epoch: 5| Step: 3
Training loss: 2.7205944061279297
Validation loss: 2.6215398003978114

Epoch: 5| Step: 4
Training loss: 3.4841811656951904
Validation loss: 2.625302576249646

Epoch: 5| Step: 5
Training loss: 2.9652962684631348
Validation loss: 2.6262970252703597

Epoch: 5| Step: 6
Training loss: 3.1706488132476807
Validation loss: 2.621354926017023

Epoch: 5| Step: 7
Training loss: 1.7712472677230835
Validation loss: 2.6194072897716234

Epoch: 5| Step: 8
Training loss: 3.214458465576172
Validation loss: 2.6193193286977787

Epoch: 5| Step: 9
Training loss: 2.3687729835510254
Validation loss: 2.615216629479521

Epoch: 5| Step: 10
Training loss: 2.4799327850341797
Validation loss: 2.6193913029086207

Epoch: 106| Step: 0
Training loss: 2.0883400440216064
Validation loss: 2.619130032036894

Epoch: 5| Step: 1
Training loss: 2.930570602416992
Validation loss: 2.6163733261887745

Epoch: 5| Step: 2
Training loss: 2.196843385696411
Validation loss: 2.6174449510471796

Epoch: 5| Step: 3
Training loss: 2.2549195289611816
Validation loss: 2.6169764329028387

Epoch: 5| Step: 4
Training loss: 2.9257476329803467
Validation loss: 2.6168521065865793

Epoch: 5| Step: 5
Training loss: 2.8323616981506348
Validation loss: 2.6190209004186813

Epoch: 5| Step: 6
Training loss: 2.5085339546203613
Validation loss: 2.6125111118439706

Epoch: 5| Step: 7
Training loss: 3.2196381092071533
Validation loss: 2.6115712324778237

Epoch: 5| Step: 8
Training loss: 2.7552647590637207
Validation loss: 2.615220067321613

Epoch: 5| Step: 9
Training loss: 3.921478748321533
Validation loss: 2.612223873856247

Epoch: 5| Step: 10
Training loss: 3.099058151245117
Validation loss: 2.6128251411581553

Epoch: 107| Step: 0
Training loss: 2.862719774246216
Validation loss: 2.6157154754925798

Epoch: 5| Step: 1
Training loss: 3.2375617027282715
Validation loss: 2.612287249616397

Epoch: 5| Step: 2
Training loss: 2.564795970916748
Validation loss: 2.6121903311821724

Epoch: 5| Step: 3
Training loss: 3.108987331390381
Validation loss: 2.612085665425947

Epoch: 5| Step: 4
Training loss: 2.630244493484497
Validation loss: 2.61574540856064

Epoch: 5| Step: 5
Training loss: 2.2407448291778564
Validation loss: 2.613643482167234

Epoch: 5| Step: 6
Training loss: 2.789705276489258
Validation loss: 2.6200333487602974

Epoch: 5| Step: 7
Training loss: 3.0601985454559326
Validation loss: 2.621530535400555

Epoch: 5| Step: 8
Training loss: 2.4894790649414062
Validation loss: 2.618802862782632

Epoch: 5| Step: 9
Training loss: 2.820291519165039
Validation loss: 2.613997305593183

Epoch: 5| Step: 10
Training loss: 2.813199043273926
Validation loss: 2.61615240445701

Epoch: 108| Step: 0
Training loss: 3.284297466278076
Validation loss: 2.6143711023433234

Epoch: 5| Step: 1
Training loss: 2.748255729675293
Validation loss: 2.616205184690414

Epoch: 5| Step: 2
Training loss: 2.708284854888916
Validation loss: 2.618539143634099

Epoch: 5| Step: 3
Training loss: 2.32507061958313
Validation loss: 2.612602633814658

Epoch: 5| Step: 4
Training loss: 3.335519790649414
Validation loss: 2.609945753569244

Epoch: 5| Step: 5
Training loss: 2.5647854804992676
Validation loss: 2.6077282274923017

Epoch: 5| Step: 6
Training loss: 2.816723346710205
Validation loss: 2.6068098545074463

Epoch: 5| Step: 7
Training loss: 2.922215700149536
Validation loss: 2.608915626361806

Epoch: 5| Step: 8
Training loss: 2.233292579650879
Validation loss: 2.611455512303178

Epoch: 5| Step: 9
Training loss: 2.9108402729034424
Validation loss: 2.607125174614691

Epoch: 5| Step: 10
Training loss: 2.7702667713165283
Validation loss: 2.6094016618626092

Epoch: 109| Step: 0
Training loss: 2.599165439605713
Validation loss: 2.6142658008042203

Epoch: 5| Step: 1
Training loss: 2.761831283569336
Validation loss: 2.6128187769202778

Epoch: 5| Step: 2
Training loss: 2.7499966621398926
Validation loss: 2.615133382940805

Epoch: 5| Step: 3
Training loss: 3.015623092651367
Validation loss: 2.6030634705738356

Epoch: 5| Step: 4
Training loss: 2.5052225589752197
Validation loss: 2.60455717579011

Epoch: 5| Step: 5
Training loss: 2.8859667778015137
Validation loss: 2.608726703992454

Epoch: 5| Step: 6
Training loss: 2.3734850883483887
Validation loss: 2.6099004873665432

Epoch: 5| Step: 7
Training loss: 2.89363694190979
Validation loss: 2.6052479436320644

Epoch: 5| Step: 8
Training loss: 2.5967941284179688
Validation loss: 2.615741119589857

Epoch: 5| Step: 9
Training loss: 3.096446990966797
Validation loss: 2.6173601099239883

Epoch: 5| Step: 10
Training loss: 3.1734392642974854
Validation loss: 2.6198187592209026

Epoch: 110| Step: 0
Training loss: 3.0674991607666016
Validation loss: 2.628760991557952

Epoch: 5| Step: 1
Training loss: 2.8931777477264404
Validation loss: 2.6300593268486763

Epoch: 5| Step: 2
Training loss: 2.539928913116455
Validation loss: 2.624361374044931

Epoch: 5| Step: 3
Training loss: 2.382655620574951
Validation loss: 2.622349521165253

Epoch: 5| Step: 4
Training loss: 2.222533702850342
Validation loss: 2.6135702594634025

Epoch: 5| Step: 5
Training loss: 2.9334359169006348
Validation loss: 2.6110018760927263

Epoch: 5| Step: 6
Training loss: 2.9289393424987793
Validation loss: 2.611814985993088

Epoch: 5| Step: 7
Training loss: 2.9211959838867188
Validation loss: 2.6051180003791727

Epoch: 5| Step: 8
Training loss: 2.851713180541992
Validation loss: 2.6052348408647763

Epoch: 5| Step: 9
Training loss: 3.0523033142089844
Validation loss: 2.6063375806295745

Epoch: 5| Step: 10
Training loss: 2.88887619972229
Validation loss: 2.604935371747581

Epoch: 111| Step: 0
Training loss: 3.6029434204101562
Validation loss: 2.606545635448989

Epoch: 5| Step: 1
Training loss: 2.877612590789795
Validation loss: 2.604391239022696

Epoch: 5| Step: 2
Training loss: 2.304508924484253
Validation loss: 2.605672174884427

Epoch: 5| Step: 3
Training loss: 2.4778692722320557
Validation loss: 2.6080702453531246

Epoch: 5| Step: 4
Training loss: 2.124634265899658
Validation loss: 2.6066898504892984

Epoch: 5| Step: 5
Training loss: 2.8522250652313232
Validation loss: 2.603490375703381

Epoch: 5| Step: 6
Training loss: 2.8622424602508545
Validation loss: 2.6057895793709704

Epoch: 5| Step: 7
Training loss: 3.6118857860565186
Validation loss: 2.6026928399198797

Epoch: 5| Step: 8
Training loss: 2.0636439323425293
Validation loss: 2.6059568953770462

Epoch: 5| Step: 9
Training loss: 3.020944118499756
Validation loss: 2.602822837009225

Epoch: 5| Step: 10
Training loss: 2.7523562908172607
Validation loss: 2.608294174235354

Epoch: 112| Step: 0
Training loss: 3.029303789138794
Validation loss: 2.604883478533837

Epoch: 5| Step: 1
Training loss: 3.391422986984253
Validation loss: 2.6058239142100015

Epoch: 5| Step: 2
Training loss: 2.8756067752838135
Validation loss: 2.6072273126212497

Epoch: 5| Step: 3
Training loss: 2.2776334285736084
Validation loss: 2.6126985729381604

Epoch: 5| Step: 4
Training loss: 2.4385299682617188
Validation loss: 2.606707303754745

Epoch: 5| Step: 5
Training loss: 2.807107448577881
Validation loss: 2.6040556276998212

Epoch: 5| Step: 6
Training loss: 2.8517463207244873
Validation loss: 2.6051465772813365

Epoch: 5| Step: 7
Training loss: 3.1085803508758545
Validation loss: 2.607685127565938

Epoch: 5| Step: 8
Training loss: 2.6585142612457275
Validation loss: 2.6039191087086997

Epoch: 5| Step: 9
Training loss: 2.3389251232147217
Validation loss: 2.603254202873476

Epoch: 5| Step: 10
Training loss: 2.7771952152252197
Validation loss: 2.605534815019177

Epoch: 113| Step: 0
Training loss: 2.3730545043945312
Validation loss: 2.606856405094106

Epoch: 5| Step: 1
Training loss: 2.5548603534698486
Validation loss: 2.6075128073333413

Epoch: 5| Step: 2
Training loss: 2.702308416366577
Validation loss: 2.6056107628730034

Epoch: 5| Step: 3
Training loss: 2.4657227993011475
Validation loss: 2.602992396200857

Epoch: 5| Step: 4
Training loss: 3.0420749187469482
Validation loss: 2.6040552252082416

Epoch: 5| Step: 5
Training loss: 3.293706178665161
Validation loss: 2.6037510223286127

Epoch: 5| Step: 6
Training loss: 2.899752140045166
Validation loss: 2.600287634839294

Epoch: 5| Step: 7
Training loss: 3.03948974609375
Validation loss: 2.602051250396236

Epoch: 5| Step: 8
Training loss: 3.2909743785858154
Validation loss: 2.5990257916911954

Epoch: 5| Step: 9
Training loss: 2.207970142364502
Validation loss: 2.599274504569269

Epoch: 5| Step: 10
Training loss: 2.615914821624756
Validation loss: 2.6011088458440637

Epoch: 114| Step: 0
Training loss: 2.998582363128662
Validation loss: 2.600747431478193

Epoch: 5| Step: 1
Training loss: 2.28029465675354
Validation loss: 2.596716812861863

Epoch: 5| Step: 2
Training loss: 2.4860010147094727
Validation loss: 2.596818288167318

Epoch: 5| Step: 3
Training loss: 2.8510966300964355
Validation loss: 2.5949398368917485

Epoch: 5| Step: 4
Training loss: 2.626539945602417
Validation loss: 2.596781340978479

Epoch: 5| Step: 5
Training loss: 2.4884190559387207
Validation loss: 2.596635377535256

Epoch: 5| Step: 6
Training loss: 2.4679203033447266
Validation loss: 2.6003614292349866

Epoch: 5| Step: 7
Training loss: 3.314314365386963
Validation loss: 2.601673098020656

Epoch: 5| Step: 8
Training loss: 3.676647663116455
Validation loss: 2.6001129124754216

Epoch: 5| Step: 9
Training loss: 2.7458763122558594
Validation loss: 2.6020944195408977

Epoch: 5| Step: 10
Training loss: 2.4366188049316406
Validation loss: 2.6021679729543705

Epoch: 115| Step: 0
Training loss: 2.4491279125213623
Validation loss: 2.6109919060942945

Epoch: 5| Step: 1
Training loss: 2.7772440910339355
Validation loss: 2.613264085144125

Epoch: 5| Step: 2
Training loss: 3.035322666168213
Validation loss: 2.643290924769576

Epoch: 5| Step: 3
Training loss: 2.6398496627807617
Validation loss: 2.6546720843161307

Epoch: 5| Step: 4
Training loss: 3.0550448894500732
Validation loss: 2.6516843508648615

Epoch: 5| Step: 5
Training loss: 1.9767401218414307
Validation loss: 2.6560887649495113

Epoch: 5| Step: 6
Training loss: 3.4769020080566406
Validation loss: 2.64379406744434

Epoch: 5| Step: 7
Training loss: 2.8292737007141113
Validation loss: 2.630719530966974

Epoch: 5| Step: 8
Training loss: 2.5046308040618896
Validation loss: 2.629808379757789

Epoch: 5| Step: 9
Training loss: 3.038443088531494
Validation loss: 2.619605223337809

Epoch: 5| Step: 10
Training loss: 2.9818787574768066
Validation loss: 2.6076961435297483

Epoch: 116| Step: 0
Training loss: 2.63622784614563
Validation loss: 2.6131519040753766

Epoch: 5| Step: 1
Training loss: 1.8213622570037842
Validation loss: 2.610256125850062

Epoch: 5| Step: 2
Training loss: 2.529958963394165
Validation loss: 2.6333162553848757

Epoch: 5| Step: 3
Training loss: 1.905400037765503
Validation loss: 2.645619697468255

Epoch: 5| Step: 4
Training loss: 2.9289684295654297
Validation loss: 2.6447043803430375

Epoch: 5| Step: 5
Training loss: 3.4595985412597656
Validation loss: 2.645920668878863

Epoch: 5| Step: 6
Training loss: 3.221881151199341
Validation loss: 2.6210733075295725

Epoch: 5| Step: 7
Training loss: 2.7778480052948
Validation loss: 2.591941487404608

Epoch: 5| Step: 8
Training loss: 3.0329489707946777
Validation loss: 2.5927428122489684

Epoch: 5| Step: 9
Training loss: 2.9128289222717285
Validation loss: 2.592341761435232

Epoch: 5| Step: 10
Training loss: 3.4353415966033936
Validation loss: 2.596469435640561

Epoch: 117| Step: 0
Training loss: 3.092413902282715
Validation loss: 2.6000714404608614

Epoch: 5| Step: 1
Training loss: 1.9983142614364624
Validation loss: 2.602854759462418

Epoch: 5| Step: 2
Training loss: 3.430636167526245
Validation loss: 2.6007980710716656

Epoch: 5| Step: 3
Training loss: 3.2448031902313232
Validation loss: 2.5970264070777485

Epoch: 5| Step: 4
Training loss: 2.602250576019287
Validation loss: 2.599108208892166

Epoch: 5| Step: 5
Training loss: 2.8485569953918457
Validation loss: 2.5948831906882663

Epoch: 5| Step: 6
Training loss: 2.3572654724121094
Validation loss: 2.5987310922274025

Epoch: 5| Step: 7
Training loss: 2.3727028369903564
Validation loss: 2.5961726019459386

Epoch: 5| Step: 8
Training loss: 3.293666362762451
Validation loss: 2.6023468432887906

Epoch: 5| Step: 9
Training loss: 3.0533454418182373
Validation loss: 2.5991023689187984

Epoch: 5| Step: 10
Training loss: 2.0252349376678467
Validation loss: 2.603282828484812

Epoch: 118| Step: 0
Training loss: 2.6179282665252686
Validation loss: 2.6070760142418647

Epoch: 5| Step: 1
Training loss: 3.057450532913208
Validation loss: 2.602518391865556

Epoch: 5| Step: 2
Training loss: 2.3626887798309326
Validation loss: 2.599943991630308

Epoch: 5| Step: 3
Training loss: 2.249692678451538
Validation loss: 2.598603520342099

Epoch: 5| Step: 4
Training loss: 3.255387544631958
Validation loss: 2.6000616319717897

Epoch: 5| Step: 5
Training loss: 2.842895984649658
Validation loss: 2.5950505836035616

Epoch: 5| Step: 6
Training loss: 3.275089740753174
Validation loss: 2.596536433824929

Epoch: 5| Step: 7
Training loss: 2.230193614959717
Validation loss: 2.590890306298451

Epoch: 5| Step: 8
Training loss: 3.557032346725464
Validation loss: 2.5904777921656126

Epoch: 5| Step: 9
Training loss: 2.740095615386963
Validation loss: 2.5889289225301435

Epoch: 5| Step: 10
Training loss: 2.157116651535034
Validation loss: 2.591294821872506

Epoch: 119| Step: 0
Training loss: 3.0348517894744873
Validation loss: 2.589726019931096

Epoch: 5| Step: 1
Training loss: 2.8109090328216553
Validation loss: 2.5864658637713362

Epoch: 5| Step: 2
Training loss: 2.574129581451416
Validation loss: 2.5871291134947088

Epoch: 5| Step: 3
Training loss: 3.4673283100128174
Validation loss: 2.5879641989225983

Epoch: 5| Step: 4
Training loss: 2.483218193054199
Validation loss: 2.585196279710339

Epoch: 5| Step: 5
Training loss: 2.781716823577881
Validation loss: 2.588948101125738

Epoch: 5| Step: 6
Training loss: 2.7837419509887695
Validation loss: 2.589474698548676

Epoch: 5| Step: 7
Training loss: 3.3727831840515137
Validation loss: 2.59104420292762

Epoch: 5| Step: 8
Training loss: 2.5328006744384766
Validation loss: 2.5874877463104906

Epoch: 5| Step: 9
Training loss: 2.4122910499572754
Validation loss: 2.5874477278801704

Epoch: 5| Step: 10
Training loss: 2.037269115447998
Validation loss: 2.5867163801705964

Epoch: 120| Step: 0
Training loss: 3.156404733657837
Validation loss: 2.5910848904681463

Epoch: 5| Step: 1
Training loss: 2.64679217338562
Validation loss: 2.5937192311850925

Epoch: 5| Step: 2
Training loss: 2.936258316040039
Validation loss: 2.59219362402475

Epoch: 5| Step: 3
Training loss: 2.7904820442199707
Validation loss: 2.5925419894597863

Epoch: 5| Step: 4
Training loss: 2.251621723175049
Validation loss: 2.585730239909182

Epoch: 5| Step: 5
Training loss: 2.6769890785217285
Validation loss: 2.5904027544042116

Epoch: 5| Step: 6
Training loss: 3.351309299468994
Validation loss: 2.584693606181811

Epoch: 5| Step: 7
Training loss: 2.6536574363708496
Validation loss: 2.587371395480248

Epoch: 5| Step: 8
Training loss: 2.6063451766967773
Validation loss: 2.5908705957474245

Epoch: 5| Step: 9
Training loss: 2.392895221710205
Validation loss: 2.596110874606717

Epoch: 5| Step: 10
Training loss: 2.9270503520965576
Validation loss: 2.595961606630715

Epoch: 121| Step: 0
Training loss: 2.1857848167419434
Validation loss: 2.5986425774071806

Epoch: 5| Step: 1
Training loss: 2.538750410079956
Validation loss: 2.6080799333510862

Epoch: 5| Step: 2
Training loss: 3.314727306365967
Validation loss: 2.6085017829812984

Epoch: 5| Step: 3
Training loss: 3.2529804706573486
Validation loss: 2.5914289028413835

Epoch: 5| Step: 4
Training loss: 2.804783582687378
Validation loss: 2.580814628190892

Epoch: 5| Step: 5
Training loss: 2.4547207355499268
Validation loss: 2.5828127604658886

Epoch: 5| Step: 6
Training loss: 2.8794431686401367
Validation loss: 2.585139215633433

Epoch: 5| Step: 7
Training loss: 2.027005910873413
Validation loss: 2.586184806721185

Epoch: 5| Step: 8
Training loss: 3.036520004272461
Validation loss: 2.591147299735777

Epoch: 5| Step: 9
Training loss: 2.9189140796661377
Validation loss: 2.5912754048583326

Epoch: 5| Step: 10
Training loss: 3.0510315895080566
Validation loss: 2.5884760323391167

Epoch: 122| Step: 0
Training loss: 2.73441481590271
Validation loss: 2.588520203867266

Epoch: 5| Step: 1
Training loss: 2.733598232269287
Validation loss: 2.588450124186854

Epoch: 5| Step: 2
Training loss: 2.5249438285827637
Validation loss: 2.592889908821352

Epoch: 5| Step: 3
Training loss: 3.196788787841797
Validation loss: 2.5893494929036787

Epoch: 5| Step: 4
Training loss: 3.262331008911133
Validation loss: 2.5913005157183577

Epoch: 5| Step: 5
Training loss: 3.2006468772888184
Validation loss: 2.5897588755494807

Epoch: 5| Step: 6
Training loss: 2.735844135284424
Validation loss: 2.5900695580308155

Epoch: 5| Step: 7
Training loss: 2.657931089401245
Validation loss: 2.5931721297643517

Epoch: 5| Step: 8
Training loss: 1.9485435485839844
Validation loss: 2.5932503079855316

Epoch: 5| Step: 9
Training loss: 2.3467557430267334
Validation loss: 2.592670258655343

Epoch: 5| Step: 10
Training loss: 3.1499881744384766
Validation loss: 2.5904412500319944

Epoch: 123| Step: 0
Training loss: 1.526257038116455
Validation loss: 2.5911393755225727

Epoch: 5| Step: 1
Training loss: 2.69222092628479
Validation loss: 2.589150931245537

Epoch: 5| Step: 2
Training loss: 2.60493540763855
Validation loss: 2.58418099598218

Epoch: 5| Step: 3
Training loss: 3.203092098236084
Validation loss: 2.590081055959066

Epoch: 5| Step: 4
Training loss: 2.6371922492980957
Validation loss: 2.595627097673314

Epoch: 5| Step: 5
Training loss: 3.229112148284912
Validation loss: 2.591814426965611

Epoch: 5| Step: 6
Training loss: 2.5938644409179688
Validation loss: 2.5866563807251635

Epoch: 5| Step: 7
Training loss: 2.9780924320220947
Validation loss: 2.585839245909004

Epoch: 5| Step: 8
Training loss: 3.0704410076141357
Validation loss: 2.5812774473621

Epoch: 5| Step: 9
Training loss: 3.196399688720703
Validation loss: 2.5814969334551083

Epoch: 5| Step: 10
Training loss: 2.672454357147217
Validation loss: 2.5781345264886015

Epoch: 124| Step: 0
Training loss: 2.6100058555603027
Validation loss: 2.5790241097891204

Epoch: 5| Step: 1
Training loss: 2.8829448223114014
Validation loss: 2.5764278775902203

Epoch: 5| Step: 2
Training loss: 2.6266849040985107
Validation loss: 2.5789145833702496

Epoch: 5| Step: 3
Training loss: 3.011897325515747
Validation loss: 2.5765644555450766

Epoch: 5| Step: 4
Training loss: 2.986020565032959
Validation loss: 2.579541829324538

Epoch: 5| Step: 5
Training loss: 2.489386796951294
Validation loss: 2.5768293462773806

Epoch: 5| Step: 6
Training loss: 2.4806995391845703
Validation loss: 2.5793489563849663

Epoch: 5| Step: 7
Training loss: 3.3700146675109863
Validation loss: 2.5789213590724493

Epoch: 5| Step: 8
Training loss: 3.1297643184661865
Validation loss: 2.5782780493459394

Epoch: 5| Step: 9
Training loss: 2.2325758934020996
Validation loss: 2.578154653631231

Epoch: 5| Step: 10
Training loss: 2.4161460399627686
Validation loss: 2.5775608734417985

Epoch: 125| Step: 0
Training loss: 3.4210104942321777
Validation loss: 2.5782053573157198

Epoch: 5| Step: 1
Training loss: 3.0916192531585693
Validation loss: 2.5758809530606834

Epoch: 5| Step: 2
Training loss: 2.2339584827423096
Validation loss: 2.579029252452235

Epoch: 5| Step: 3
Training loss: 3.1824452877044678
Validation loss: 2.5793087123542704

Epoch: 5| Step: 4
Training loss: 2.472343921661377
Validation loss: 2.587573274489372

Epoch: 5| Step: 5
Training loss: 3.063528537750244
Validation loss: 2.5869835576703473

Epoch: 5| Step: 6
Training loss: 2.3454079627990723
Validation loss: 2.5829110043023222

Epoch: 5| Step: 7
Training loss: 3.4153358936309814
Validation loss: 2.577112561912947

Epoch: 5| Step: 8
Training loss: 2.5922622680664062
Validation loss: 2.5785665794085433

Epoch: 5| Step: 9
Training loss: 1.8162720203399658
Validation loss: 2.5720502945684616

Epoch: 5| Step: 10
Training loss: 2.686624526977539
Validation loss: 2.575235177111882

Epoch: 126| Step: 0
Training loss: 2.7814249992370605
Validation loss: 2.575904446263467

Epoch: 5| Step: 1
Training loss: 2.753922939300537
Validation loss: 2.573777396191833

Epoch: 5| Step: 2
Training loss: 2.5829033851623535
Validation loss: 2.58037466900323

Epoch: 5| Step: 3
Training loss: 2.4535114765167236
Validation loss: 2.5940809147332304

Epoch: 5| Step: 4
Training loss: 2.7542777061462402
Validation loss: 2.5872215481214624

Epoch: 5| Step: 5
Training loss: 2.7648463249206543
Validation loss: 2.5786716450927076

Epoch: 5| Step: 6
Training loss: 2.5976669788360596
Validation loss: 2.577915096795687

Epoch: 5| Step: 7
Training loss: 2.513465404510498
Validation loss: 2.573379114109983

Epoch: 5| Step: 8
Training loss: 3.700186252593994
Validation loss: 2.5746673819839314

Epoch: 5| Step: 9
Training loss: 2.994805097579956
Validation loss: 2.5772017330251713

Epoch: 5| Step: 10
Training loss: 2.3623790740966797
Validation loss: 2.580693088552003

Epoch: 127| Step: 0
Training loss: 3.2387492656707764
Validation loss: 2.5799462179983816

Epoch: 5| Step: 1
Training loss: 2.201314687728882
Validation loss: 2.5794373250776723

Epoch: 5| Step: 2
Training loss: 2.1383402347564697
Validation loss: 2.5781273970039944

Epoch: 5| Step: 3
Training loss: 2.2025578022003174
Validation loss: 2.576734878683603

Epoch: 5| Step: 4
Training loss: 3.1289050579071045
Validation loss: 2.5741994534769366

Epoch: 5| Step: 5
Training loss: 2.7162766456604004
Validation loss: 2.5786865782994095

Epoch: 5| Step: 6
Training loss: 3.0129928588867188
Validation loss: 2.5711972610924834

Epoch: 5| Step: 7
Training loss: 2.6500961780548096
Validation loss: 2.5768596818370204

Epoch: 5| Step: 8
Training loss: 3.107821226119995
Validation loss: 2.5810507446207027

Epoch: 5| Step: 9
Training loss: 2.4626243114471436
Validation loss: 2.571861582417642

Epoch: 5| Step: 10
Training loss: 3.53123140335083
Validation loss: 2.5777342601488997

Epoch: 128| Step: 0
Training loss: 3.7251136302948
Validation loss: 2.5769034765099965

Epoch: 5| Step: 1
Training loss: 2.403585910797119
Validation loss: 2.5706680385015344

Epoch: 5| Step: 2
Training loss: 2.9724173545837402
Validation loss: 2.5755941816555556

Epoch: 5| Step: 3
Training loss: 2.6944642066955566
Validation loss: 2.574804141957273

Epoch: 5| Step: 4
Training loss: 3.122575283050537
Validation loss: 2.576080408147586

Epoch: 5| Step: 5
Training loss: 2.8439316749572754
Validation loss: 2.578774457336754

Epoch: 5| Step: 6
Training loss: 2.4528603553771973
Validation loss: 2.5949373193966445

Epoch: 5| Step: 7
Training loss: 2.744882345199585
Validation loss: 2.5954887097881687

Epoch: 5| Step: 8
Training loss: 2.287174701690674
Validation loss: 2.599345027759511

Epoch: 5| Step: 9
Training loss: 2.83415150642395
Validation loss: 2.6016830757100093

Epoch: 5| Step: 10
Training loss: 2.1970882415771484
Validation loss: 2.5867435573249735

Epoch: 129| Step: 0
Training loss: 3.2110908031463623
Validation loss: 2.570551731253183

Epoch: 5| Step: 1
Training loss: 2.762579917907715
Validation loss: 2.565555352036671

Epoch: 5| Step: 2
Training loss: 2.1737051010131836
Validation loss: 2.566592836892733

Epoch: 5| Step: 3
Training loss: 2.879995107650757
Validation loss: 2.5684516558083157

Epoch: 5| Step: 4
Training loss: 3.091823101043701
Validation loss: 2.5718210743319605

Epoch: 5| Step: 5
Training loss: 2.42094349861145
Validation loss: 2.5727150030033563

Epoch: 5| Step: 6
Training loss: 2.459251880645752
Validation loss: 2.5723123255596367

Epoch: 5| Step: 7
Training loss: 2.6795713901519775
Validation loss: 2.571986811135405

Epoch: 5| Step: 8
Training loss: 2.9511163234710693
Validation loss: 2.5703229827265583

Epoch: 5| Step: 9
Training loss: 3.0415732860565186
Validation loss: 2.5723950350156395

Epoch: 5| Step: 10
Training loss: 2.561544895172119
Validation loss: 2.5640921695258028

Epoch: 130| Step: 0
Training loss: 2.8631362915039062
Validation loss: 2.5680285166668635

Epoch: 5| Step: 1
Training loss: 2.809185266494751
Validation loss: 2.5694695595772035

Epoch: 5| Step: 2
Training loss: 3.1735520362854004
Validation loss: 2.563763233923143

Epoch: 5| Step: 3
Training loss: 2.3881585597991943
Validation loss: 2.5650092683812624

Epoch: 5| Step: 4
Training loss: 2.235821485519409
Validation loss: 2.568892027742119

Epoch: 5| Step: 5
Training loss: 2.6046037673950195
Validation loss: 2.565801571774226

Epoch: 5| Step: 6
Training loss: 2.4178247451782227
Validation loss: 2.564373557285596

Epoch: 5| Step: 7
Training loss: 2.5249149799346924
Validation loss: 2.56208384677928

Epoch: 5| Step: 8
Training loss: 2.6558725833892822
Validation loss: 2.568754506367509

Epoch: 5| Step: 9
Training loss: 3.642355442047119
Validation loss: 2.565777532515987

Epoch: 5| Step: 10
Training loss: 2.894564390182495
Validation loss: 2.570949762098251

Epoch: 131| Step: 0
Training loss: 3.021117687225342
Validation loss: 2.5685968886139574

Epoch: 5| Step: 1
Training loss: 2.272894859313965
Validation loss: 2.568813157337968

Epoch: 5| Step: 2
Training loss: 3.066636323928833
Validation loss: 2.5664767744720622

Epoch: 5| Step: 3
Training loss: 2.397315502166748
Validation loss: 2.5798170464013213

Epoch: 5| Step: 4
Training loss: 2.6887764930725098
Validation loss: 2.572694545151085

Epoch: 5| Step: 5
Training loss: 3.1737964153289795
Validation loss: 2.5774834796946537

Epoch: 5| Step: 6
Training loss: 2.9523510932922363
Validation loss: 2.5641158268015873

Epoch: 5| Step: 7
Training loss: 3.2763900756835938
Validation loss: 2.5607289011760423

Epoch: 5| Step: 8
Training loss: 2.3913745880126953
Validation loss: 2.562130940857754

Epoch: 5| Step: 9
Training loss: 2.3499510288238525
Validation loss: 2.55975014932694

Epoch: 5| Step: 10
Training loss: 2.5340428352355957
Validation loss: 2.561331661798621

Epoch: 132| Step: 0
Training loss: 3.2241337299346924
Validation loss: 2.5565727782505814

Epoch: 5| Step: 1
Training loss: 3.3263962268829346
Validation loss: 2.557385424131988

Epoch: 5| Step: 2
Training loss: 2.7638046741485596
Validation loss: 2.557642190687118

Epoch: 5| Step: 3
Training loss: 2.44968318939209
Validation loss: 2.5617869541209233

Epoch: 5| Step: 4
Training loss: 2.420473575592041
Validation loss: 2.559343909704557

Epoch: 5| Step: 5
Training loss: 2.9918394088745117
Validation loss: 2.562886978990288

Epoch: 5| Step: 6
Training loss: 2.035188674926758
Validation loss: 2.5638919979013424

Epoch: 5| Step: 7
Training loss: 3.078540325164795
Validation loss: 2.5608298188896588

Epoch: 5| Step: 8
Training loss: 2.331242322921753
Validation loss: 2.5601911775527464

Epoch: 5| Step: 9
Training loss: 2.7370362281799316
Validation loss: 2.5581610125880085

Epoch: 5| Step: 10
Training loss: 2.7378289699554443
Validation loss: 2.5588841861294163

Epoch: 133| Step: 0
Training loss: 3.408299207687378
Validation loss: 2.558456543953188

Epoch: 5| Step: 1
Training loss: 1.9307628870010376
Validation loss: 2.561606850675357

Epoch: 5| Step: 2
Training loss: 3.293914794921875
Validation loss: 2.5592693462166736

Epoch: 5| Step: 3
Training loss: 2.9627444744110107
Validation loss: 2.5590393261242936

Epoch: 5| Step: 4
Training loss: 2.603135585784912
Validation loss: 2.5605188108259633

Epoch: 5| Step: 5
Training loss: 2.5712621212005615
Validation loss: 2.5588402158470562

Epoch: 5| Step: 6
Training loss: 3.051867961883545
Validation loss: 2.5577977652190835

Epoch: 5| Step: 7
Training loss: 2.9045956134796143
Validation loss: 2.5584756635850474

Epoch: 5| Step: 8
Training loss: 2.753432273864746
Validation loss: 2.559601581224831

Epoch: 5| Step: 9
Training loss: 2.5474584102630615
Validation loss: 2.561859069332

Epoch: 5| Step: 10
Training loss: 1.9994778633117676
Validation loss: 2.5593642675748436

Epoch: 134| Step: 0
Training loss: 2.503484010696411
Validation loss: 2.5594767242349605

Epoch: 5| Step: 1
Training loss: 2.0857503414154053
Validation loss: 2.5595865634179886

Epoch: 5| Step: 2
Training loss: 3.183913469314575
Validation loss: 2.5609937278173303

Epoch: 5| Step: 3
Training loss: 2.379467010498047
Validation loss: 2.558147661147579

Epoch: 5| Step: 4
Training loss: 2.071476459503174
Validation loss: 2.562540187630602

Epoch: 5| Step: 5
Training loss: 2.4519236087799072
Validation loss: 2.563133365364485

Epoch: 5| Step: 6
Training loss: 3.3818726539611816
Validation loss: 2.575514316558838

Epoch: 5| Step: 7
Training loss: 3.4216220378875732
Validation loss: 2.572081076201572

Epoch: 5| Step: 8
Training loss: 3.1897788047790527
Validation loss: 2.57397642443257

Epoch: 5| Step: 9
Training loss: 2.839411497116089
Validation loss: 2.569893826720535

Epoch: 5| Step: 10
Training loss: 2.5509095191955566
Validation loss: 2.5675767621686383

Epoch: 135| Step: 0
Training loss: 2.2398550510406494
Validation loss: 2.561733179194953

Epoch: 5| Step: 1
Training loss: 2.068307399749756
Validation loss: 2.5576958566583614

Epoch: 5| Step: 2
Training loss: 2.5030319690704346
Validation loss: 2.5540531809611986

Epoch: 5| Step: 3
Training loss: 3.3288445472717285
Validation loss: 2.548954722701862

Epoch: 5| Step: 4
Training loss: 2.67637300491333
Validation loss: 2.551874424821587

Epoch: 5| Step: 5
Training loss: 2.666059970855713
Validation loss: 2.548413940655288

Epoch: 5| Step: 6
Training loss: 2.800319194793701
Validation loss: 2.5526793618356027

Epoch: 5| Step: 7
Training loss: 3.3769257068634033
Validation loss: 2.552176624216059

Epoch: 5| Step: 8
Training loss: 2.889465570449829
Validation loss: 2.5522351700772523

Epoch: 5| Step: 9
Training loss: 2.797445297241211
Validation loss: 2.5520728326612905

Epoch: 5| Step: 10
Training loss: 2.7692205905914307
Validation loss: 2.5550666060498965

Epoch: 136| Step: 0
Training loss: 2.308469772338867
Validation loss: 2.5483544693198255

Epoch: 5| Step: 1
Training loss: 3.1688904762268066
Validation loss: 2.547296865012056

Epoch: 5| Step: 2
Training loss: 1.984734296798706
Validation loss: 2.550275082229286

Epoch: 5| Step: 3
Training loss: 3.361455202102661
Validation loss: 2.5472217554687173

Epoch: 5| Step: 4
Training loss: 3.082855701446533
Validation loss: 2.54640462834348

Epoch: 5| Step: 5
Training loss: 3.161642074584961
Validation loss: 2.544774880973242

Epoch: 5| Step: 6
Training loss: 2.4280261993408203
Validation loss: 2.547960865882135

Epoch: 5| Step: 7
Training loss: 2.9245376586914062
Validation loss: 2.5497883186545423

Epoch: 5| Step: 8
Training loss: 2.5668039321899414
Validation loss: 2.5465813811107347

Epoch: 5| Step: 9
Training loss: 2.2464559078216553
Validation loss: 2.5460019931998303

Epoch: 5| Step: 10
Training loss: 2.7739510536193848
Validation loss: 2.5523274457582863

Epoch: 137| Step: 0
Training loss: 2.5725502967834473
Validation loss: 2.5532858064097743

Epoch: 5| Step: 1
Training loss: 2.554028272628784
Validation loss: 2.5507300643510717

Epoch: 5| Step: 2
Training loss: 2.8469111919403076
Validation loss: 2.5473353324397916

Epoch: 5| Step: 3
Training loss: 3.271326780319214
Validation loss: 2.542828416311613

Epoch: 5| Step: 4
Training loss: 2.690416097640991
Validation loss: 2.5456133606613323

Epoch: 5| Step: 5
Training loss: 2.764474868774414
Validation loss: 2.5456988708947295

Epoch: 5| Step: 6
Training loss: 2.5585968494415283
Validation loss: 2.546731036196473

Epoch: 5| Step: 7
Training loss: 2.1475918292999268
Validation loss: 2.5416094180076354

Epoch: 5| Step: 8
Training loss: 2.3757643699645996
Validation loss: 2.5415459909746723

Epoch: 5| Step: 9
Training loss: 3.4730255603790283
Validation loss: 2.542431944160051

Epoch: 5| Step: 10
Training loss: 2.7177469730377197
Validation loss: 2.5481531645662043

Epoch: 138| Step: 0
Training loss: 2.4264705181121826
Validation loss: 2.5489502491489535

Epoch: 5| Step: 1
Training loss: 2.9700698852539062
Validation loss: 2.543805271066645

Epoch: 5| Step: 2
Training loss: 2.707930326461792
Validation loss: 2.5431948925859187

Epoch: 5| Step: 3
Training loss: 1.9372336864471436
Validation loss: 2.54500513692056

Epoch: 5| Step: 4
Training loss: 3.1607794761657715
Validation loss: 2.5436650732512116

Epoch: 5| Step: 5
Training loss: 3.108285427093506
Validation loss: 2.5395837906868226

Epoch: 5| Step: 6
Training loss: 3.318955183029175
Validation loss: 2.5392494201660156

Epoch: 5| Step: 7
Training loss: 2.4451165199279785
Validation loss: 2.540551018971269

Epoch: 5| Step: 8
Training loss: 2.7794222831726074
Validation loss: 2.535355479486527

Epoch: 5| Step: 9
Training loss: 2.6523098945617676
Validation loss: 2.527948902499291

Epoch: 5| Step: 10
Training loss: 2.3597092628479004
Validation loss: 2.533781797655167

Epoch: 139| Step: 0
Training loss: 2.762411594390869
Validation loss: 2.5339063341899584

Epoch: 5| Step: 1
Training loss: 3.0778465270996094
Validation loss: 2.5283143315263974

Epoch: 5| Step: 2
Training loss: 2.2845568656921387
Validation loss: 2.5258657342644146

Epoch: 5| Step: 3
Training loss: 3.1234710216522217
Validation loss: 2.5331357832877868

Epoch: 5| Step: 4
Training loss: 2.6167852878570557
Validation loss: 2.5261887427299254

Epoch: 5| Step: 5
Training loss: 1.7282832860946655
Validation loss: 2.5297252362774265

Epoch: 5| Step: 6
Training loss: 3.271759033203125
Validation loss: 2.527424625171128

Epoch: 5| Step: 7
Training loss: 3.08514404296875
Validation loss: 2.534971267946305

Epoch: 5| Step: 8
Training loss: 2.506847858428955
Validation loss: 2.526059858260616

Epoch: 5| Step: 9
Training loss: 2.6841509342193604
Validation loss: 2.525058930920016

Epoch: 5| Step: 10
Training loss: 2.6812243461608887
Validation loss: 2.5190726608358402

Epoch: 140| Step: 0
Training loss: 2.8199915885925293
Validation loss: 2.522415207278344

Epoch: 5| Step: 1
Training loss: 2.8932933807373047
Validation loss: 2.5226353432542536

Epoch: 5| Step: 2
Training loss: 3.12368106842041
Validation loss: 2.5189731095426824

Epoch: 5| Step: 3
Training loss: 2.8546321392059326
Validation loss: 2.5193388744067122

Epoch: 5| Step: 4
Training loss: 2.759115219116211
Validation loss: 2.5199313445757796

Epoch: 5| Step: 5
Training loss: 3.113476514816284
Validation loss: 2.51861499714595

Epoch: 5| Step: 6
Training loss: 2.9817748069763184
Validation loss: 2.5224171094996954

Epoch: 5| Step: 7
Training loss: 2.2034125328063965
Validation loss: 2.5231866708365818

Epoch: 5| Step: 8
Training loss: 1.6755883693695068
Validation loss: 2.526904365067841

Epoch: 5| Step: 9
Training loss: 2.1391923427581787
Validation loss: 2.523579171908799

Epoch: 5| Step: 10
Training loss: 3.3141050338745117
Validation loss: 2.521852949614166

Epoch: 141| Step: 0
Training loss: 2.972285032272339
Validation loss: 2.520325291541315

Epoch: 5| Step: 1
Training loss: 2.9816501140594482
Validation loss: 2.517269088375953

Epoch: 5| Step: 2
Training loss: 2.401740550994873
Validation loss: 2.516746836323892

Epoch: 5| Step: 3
Training loss: 2.238964080810547
Validation loss: 2.514319763388685

Epoch: 5| Step: 4
Training loss: 3.890639543533325
Validation loss: 2.515934826225363

Epoch: 5| Step: 5
Training loss: 2.705836534500122
Validation loss: 2.510302374439855

Epoch: 5| Step: 6
Training loss: 2.65553617477417
Validation loss: 2.5148093418408464

Epoch: 5| Step: 7
Training loss: 2.556633949279785
Validation loss: 2.5127563989290627

Epoch: 5| Step: 8
Training loss: 2.4024643898010254
Validation loss: 2.513596216837565

Epoch: 5| Step: 9
Training loss: 2.7417373657226562
Validation loss: 2.515387673531809

Epoch: 5| Step: 10
Training loss: 2.1521687507629395
Validation loss: 2.517415805529523

Epoch: 142| Step: 0
Training loss: 2.5854671001434326
Validation loss: 2.5135168516507713

Epoch: 5| Step: 1
Training loss: 2.696967601776123
Validation loss: 2.5099819552513862

Epoch: 5| Step: 2
Training loss: 2.8367745876312256
Validation loss: 2.5111312097118748

Epoch: 5| Step: 3
Training loss: 2.068316698074341
Validation loss: 2.5090799434210664

Epoch: 5| Step: 4
Training loss: 2.7473154067993164
Validation loss: 2.510821452704809

Epoch: 5| Step: 5
Training loss: 2.7266573905944824
Validation loss: 2.5078408128471783

Epoch: 5| Step: 6
Training loss: 3.1520214080810547
Validation loss: 2.510600143863309

Epoch: 5| Step: 7
Training loss: 2.886528491973877
Validation loss: 2.509719253868185

Epoch: 5| Step: 8
Training loss: 2.5840904712677
Validation loss: 2.5105706184141097

Epoch: 5| Step: 9
Training loss: 2.802097797393799
Validation loss: 2.5059843396627777

Epoch: 5| Step: 10
Training loss: 2.632145881652832
Validation loss: 2.508273579741037

Epoch: 143| Step: 0
Training loss: 2.955850839614868
Validation loss: 2.511229750930622

Epoch: 5| Step: 1
Training loss: 2.711900234222412
Validation loss: 2.512155532836914

Epoch: 5| Step: 2
Training loss: 3.2227368354797363
Validation loss: 2.509852645217731

Epoch: 5| Step: 3
Training loss: 2.5018365383148193
Validation loss: 2.5075787703196206

Epoch: 5| Step: 4
Training loss: 2.5507349967956543
Validation loss: 2.5090540057869366

Epoch: 5| Step: 5
Training loss: 1.8683456182479858
Validation loss: 2.5175391063895276

Epoch: 5| Step: 6
Training loss: 2.5161430835723877
Validation loss: 2.5160241460287445

Epoch: 5| Step: 7
Training loss: 2.891043186187744
Validation loss: 2.5151734505930254

Epoch: 5| Step: 8
Training loss: 2.4570581912994385
Validation loss: 2.5184700642862627

Epoch: 5| Step: 9
Training loss: 3.0722150802612305
Validation loss: 2.514913774305774

Epoch: 5| Step: 10
Training loss: 3.023052930831909
Validation loss: 2.5045555817183627

Epoch: 144| Step: 0
Training loss: 3.0877957344055176
Validation loss: 2.5067966445799796

Epoch: 5| Step: 1
Training loss: 2.403472423553467
Validation loss: 2.5115319887797036

Epoch: 5| Step: 2
Training loss: 3.0915560722351074
Validation loss: 2.50672491904228

Epoch: 5| Step: 3
Training loss: 2.8340606689453125
Validation loss: 2.506605130369945

Epoch: 5| Step: 4
Training loss: 2.532851457595825
Validation loss: 2.5067231988394134

Epoch: 5| Step: 5
Training loss: 2.5557172298431396
Validation loss: 2.506407273712979

Epoch: 5| Step: 6
Training loss: 3.1323769092559814
Validation loss: 2.506501397778911

Epoch: 5| Step: 7
Training loss: 1.9927723407745361
Validation loss: 2.5068157129390265

Epoch: 5| Step: 8
Training loss: 2.4431583881378174
Validation loss: 2.509816182556973

Epoch: 5| Step: 9
Training loss: 2.775789260864258
Validation loss: 2.5128109070562545

Epoch: 5| Step: 10
Training loss: 2.8565831184387207
Validation loss: 2.5112677979212936

Epoch: 145| Step: 0
Training loss: 2.6964142322540283
Validation loss: 2.5198603663393246

Epoch: 5| Step: 1
Training loss: 2.777855157852173
Validation loss: 2.519023900390953

Epoch: 5| Step: 2
Training loss: 2.315098524093628
Validation loss: 2.5221395954009025

Epoch: 5| Step: 3
Training loss: 2.536717653274536
Validation loss: 2.5174016542332147

Epoch: 5| Step: 4
Training loss: 2.205927848815918
Validation loss: 2.5160199185853362

Epoch: 5| Step: 5
Training loss: 2.9979262351989746
Validation loss: 2.51598536070957

Epoch: 5| Step: 6
Training loss: 2.6552700996398926
Validation loss: 2.510047515233358

Epoch: 5| Step: 7
Training loss: 3.158499240875244
Validation loss: 2.507259645769673

Epoch: 5| Step: 8
Training loss: 2.6082897186279297
Validation loss: 2.50203614593834

Epoch: 5| Step: 9
Training loss: 2.829772710800171
Validation loss: 2.5072934319896083

Epoch: 5| Step: 10
Training loss: 2.917571783065796
Validation loss: 2.5057036030677056

Epoch: 146| Step: 0
Training loss: 2.4787020683288574
Validation loss: 2.5011852172113236

Epoch: 5| Step: 1
Training loss: 2.1216044425964355
Validation loss: 2.502941236701063

Epoch: 5| Step: 2
Training loss: 2.4357457160949707
Validation loss: 2.5063622202924503

Epoch: 5| Step: 3
Training loss: 3.087218761444092
Validation loss: 2.5058699500176216

Epoch: 5| Step: 4
Training loss: 4.10928201675415
Validation loss: 2.5002569947191464

Epoch: 5| Step: 5
Training loss: 2.706979751586914
Validation loss: 2.505803228706442

Epoch: 5| Step: 6
Training loss: 2.1500895023345947
Validation loss: 2.5043158608098186

Epoch: 5| Step: 7
Training loss: 3.0249991416931152
Validation loss: 2.503815702212754

Epoch: 5| Step: 8
Training loss: 2.238328218460083
Validation loss: 2.50815515108006

Epoch: 5| Step: 9
Training loss: 2.3204097747802734
Validation loss: 2.5076648291721138

Epoch: 5| Step: 10
Training loss: 2.986624002456665
Validation loss: 2.5127392558641333

Epoch: 147| Step: 0
Training loss: 2.9510340690612793
Validation loss: 2.511680728645735

Epoch: 5| Step: 1
Training loss: 3.271857500076294
Validation loss: 2.5157781339460805

Epoch: 5| Step: 2
Training loss: 2.917161703109741
Validation loss: 2.511828443055512

Epoch: 5| Step: 3
Training loss: 2.6267051696777344
Validation loss: 2.5082477907980643

Epoch: 5| Step: 4
Training loss: 2.560835123062134
Validation loss: 2.5058810608361357

Epoch: 5| Step: 5
Training loss: 2.164381265640259
Validation loss: 2.5057861907507784

Epoch: 5| Step: 6
Training loss: 2.7816710472106934
Validation loss: 2.5019213871289323

Epoch: 5| Step: 7
Training loss: 1.7332122325897217
Validation loss: 2.4984219304976927

Epoch: 5| Step: 8
Training loss: 2.4700257778167725
Validation loss: 2.4979373203810824

Epoch: 5| Step: 9
Training loss: 2.9242780208587646
Validation loss: 2.498527726819438

Epoch: 5| Step: 10
Training loss: 3.386110782623291
Validation loss: 2.5016628132071546

Epoch: 148| Step: 0
Training loss: 3.0446889400482178
Validation loss: 2.5009101193438292

Epoch: 5| Step: 1
Training loss: 2.8128223419189453
Validation loss: 2.5031000516747914

Epoch: 5| Step: 2
Training loss: 2.4901082515716553
Validation loss: 2.513638619453676

Epoch: 5| Step: 3
Training loss: 2.7012224197387695
Validation loss: 2.5235342799976306

Epoch: 5| Step: 4
Training loss: 1.9541696310043335
Validation loss: 2.5079074751946235

Epoch: 5| Step: 5
Training loss: 2.4199769496917725
Validation loss: 2.509838301648376

Epoch: 5| Step: 6
Training loss: 2.9259085655212402
Validation loss: 2.507627953765213

Epoch: 5| Step: 7
Training loss: 3.2074050903320312
Validation loss: 2.5099949375275643

Epoch: 5| Step: 8
Training loss: 3.3269832134246826
Validation loss: 2.512517662458522

Epoch: 5| Step: 9
Training loss: 2.5892646312713623
Validation loss: 2.513528193196943

Epoch: 5| Step: 10
Training loss: 2.059019088745117
Validation loss: 2.513814669783397

Epoch: 149| Step: 0
Training loss: 2.8878414630889893
Validation loss: 2.523937309941938

Epoch: 5| Step: 1
Training loss: 3.121774196624756
Validation loss: 2.5276663329011653

Epoch: 5| Step: 2
Training loss: 3.1146082878112793
Validation loss: 2.534189393443446

Epoch: 5| Step: 3
Training loss: 2.68935227394104
Validation loss: 2.5484077468995125

Epoch: 5| Step: 4
Training loss: 2.8422317504882812
Validation loss: 2.5438430514386905

Epoch: 5| Step: 5
Training loss: 2.631746768951416
Validation loss: 2.5444565062881797

Epoch: 5| Step: 6
Training loss: 2.1203408241271973
Validation loss: 2.532552206388084

Epoch: 5| Step: 7
Training loss: 2.6152515411376953
Validation loss: 2.524818117900561

Epoch: 5| Step: 8
Training loss: 3.089703321456909
Validation loss: 2.518920398527576

Epoch: 5| Step: 9
Training loss: 2.7056126594543457
Validation loss: 2.505749556326097

Epoch: 5| Step: 10
Training loss: 1.8611394166946411
Validation loss: 2.5063642558231147

Epoch: 150| Step: 0
Training loss: 2.5475449562072754
Validation loss: 2.501132970215172

Epoch: 5| Step: 1
Training loss: 2.590813398361206
Validation loss: 2.502328949589883

Epoch: 5| Step: 2
Training loss: 2.65679931640625
Validation loss: 2.5047309091014247

Epoch: 5| Step: 3
Training loss: 3.227870225906372
Validation loss: 2.4997822494917017

Epoch: 5| Step: 4
Training loss: 3.254065990447998
Validation loss: 2.4976150656259186

Epoch: 5| Step: 5
Training loss: 2.436711072921753
Validation loss: 2.49631622786163

Epoch: 5| Step: 6
Training loss: 2.4513096809387207
Validation loss: 2.4984024827198317

Epoch: 5| Step: 7
Training loss: 2.2041449546813965
Validation loss: 2.5067060711563274

Epoch: 5| Step: 8
Training loss: 2.256838321685791
Validation loss: 2.5087462881559968

Epoch: 5| Step: 9
Training loss: 3.6586754322052
Validation loss: 2.5089644975559686

Epoch: 5| Step: 10
Training loss: 2.40311336517334
Validation loss: 2.507232076378279

Epoch: 151| Step: 0
Training loss: 2.4846205711364746
Validation loss: 2.5011664308527464

Epoch: 5| Step: 1
Training loss: 2.8943963050842285
Validation loss: 2.5005952542827976

Epoch: 5| Step: 2
Training loss: 2.6773788928985596
Validation loss: 2.4982896081862913

Epoch: 5| Step: 3
Training loss: 2.5136563777923584
Validation loss: 2.4974317704477618

Epoch: 5| Step: 4
Training loss: 2.0175745487213135
Validation loss: 2.4995942423420567

Epoch: 5| Step: 5
Training loss: 2.6587677001953125
Validation loss: 2.49608777928096

Epoch: 5| Step: 6
Training loss: 1.9779174327850342
Validation loss: 2.48990870547551

Epoch: 5| Step: 7
Training loss: 2.8087010383605957
Validation loss: 2.4959576873369116

Epoch: 5| Step: 8
Training loss: 2.972407817840576
Validation loss: 2.494142778458134

Epoch: 5| Step: 9
Training loss: 3.3893463611602783
Validation loss: 2.489087361161427

Epoch: 5| Step: 10
Training loss: 3.3199405670166016
Validation loss: 2.5018402427755375

Epoch: 152| Step: 0
Training loss: 3.058021068572998
Validation loss: 2.5104214196564048

Epoch: 5| Step: 1
Training loss: 2.404062271118164
Validation loss: 2.5168000959580943

Epoch: 5| Step: 2
Training loss: 2.875870704650879
Validation loss: 2.5282764434814453

Epoch: 5| Step: 3
Training loss: 2.9288971424102783
Validation loss: 2.5134323335463002

Epoch: 5| Step: 4
Training loss: 2.214323043823242
Validation loss: 2.5026649634043374

Epoch: 5| Step: 5
Training loss: 2.247596263885498
Validation loss: 2.4984988038257887

Epoch: 5| Step: 6
Training loss: 2.367833137512207
Validation loss: 2.493016581381521

Epoch: 5| Step: 7
Training loss: 2.9090914726257324
Validation loss: 2.496379485694311

Epoch: 5| Step: 8
Training loss: 2.506377935409546
Validation loss: 2.496055567136375

Epoch: 5| Step: 9
Training loss: 2.855485200881958
Validation loss: 2.494367686651086

Epoch: 5| Step: 10
Training loss: 3.36053729057312
Validation loss: 2.4953859211296163

Epoch: 153| Step: 0
Training loss: 2.4619956016540527
Validation loss: 2.4978057389618247

Epoch: 5| Step: 1
Training loss: 2.3707213401794434
Validation loss: 2.494489341653803

Epoch: 5| Step: 2
Training loss: 3.1518454551696777
Validation loss: 2.496668073438829

Epoch: 5| Step: 3
Training loss: 2.8782570362091064
Validation loss: 2.4955244987241683

Epoch: 5| Step: 4
Training loss: 2.319678783416748
Validation loss: 2.496751469950522

Epoch: 5| Step: 5
Training loss: 1.9952666759490967
Validation loss: 2.4959896559356363

Epoch: 5| Step: 6
Training loss: 2.6926252841949463
Validation loss: 2.495811011201592

Epoch: 5| Step: 7
Training loss: 2.747093915939331
Validation loss: 2.492807408814789

Epoch: 5| Step: 8
Training loss: 3.3503010272979736
Validation loss: 2.494661554213493

Epoch: 5| Step: 9
Training loss: 2.63689923286438
Validation loss: 2.492908905911189

Epoch: 5| Step: 10
Training loss: 3.1223719120025635
Validation loss: 2.4919512041153444

Epoch: 154| Step: 0
Training loss: 2.640042304992676
Validation loss: 2.4963597738614647

Epoch: 5| Step: 1
Training loss: 2.7505288124084473
Validation loss: 2.4952846547608734

Epoch: 5| Step: 2
Training loss: 2.658557176589966
Validation loss: 2.4955361043253252

Epoch: 5| Step: 3
Training loss: 2.955517292022705
Validation loss: 2.4944739239190215

Epoch: 5| Step: 4
Training loss: 2.726292848587036
Validation loss: 2.4892575048631236

Epoch: 5| Step: 5
Training loss: 2.7699942588806152
Validation loss: 2.487928872467369

Epoch: 5| Step: 6
Training loss: 2.3945202827453613
Validation loss: 2.4912032260689685

Epoch: 5| Step: 7
Training loss: 3.622462749481201
Validation loss: 2.4906523778874385

Epoch: 5| Step: 8
Training loss: 2.2032597064971924
Validation loss: 2.489508795481856

Epoch: 5| Step: 9
Training loss: 2.2336184978485107
Validation loss: 2.489735221350065

Epoch: 5| Step: 10
Training loss: 2.5489017963409424
Validation loss: 2.4886958983636673

Epoch: 155| Step: 0
Training loss: 2.057417631149292
Validation loss: 2.494094266686388

Epoch: 5| Step: 1
Training loss: 2.1998815536499023
Validation loss: 2.487900008437454

Epoch: 5| Step: 2
Training loss: 3.301642894744873
Validation loss: 2.4947663891700005

Epoch: 5| Step: 3
Training loss: 2.937683582305908
Validation loss: 2.4901400894247074

Epoch: 5| Step: 4
Training loss: 2.9167938232421875
Validation loss: 2.4996767736250356

Epoch: 5| Step: 5
Training loss: 2.915355682373047
Validation loss: 2.5015694325970066

Epoch: 5| Step: 6
Training loss: 2.9293675422668457
Validation loss: 2.4937568249241

Epoch: 5| Step: 7
Training loss: 2.5616438388824463
Validation loss: 2.488412203327302

Epoch: 5| Step: 8
Training loss: 2.7445461750030518
Validation loss: 2.489900691534883

Epoch: 5| Step: 9
Training loss: 2.563066244125366
Validation loss: 2.4932141919289865

Epoch: 5| Step: 10
Training loss: 2.3462345600128174
Validation loss: 2.492380137084633

Epoch: 156| Step: 0
Training loss: 2.7952334880828857
Validation loss: 2.4904639746553157

Epoch: 5| Step: 1
Training loss: 2.5249316692352295
Validation loss: 2.4956180049527075

Epoch: 5| Step: 2
Training loss: 2.3238673210144043
Validation loss: 2.496983881919615

Epoch: 5| Step: 3
Training loss: 2.456167697906494
Validation loss: 2.4942936358913297

Epoch: 5| Step: 4
Training loss: 2.9306089878082275
Validation loss: 2.491302135170147

Epoch: 5| Step: 5
Training loss: 2.5400962829589844
Validation loss: 2.4871433601584485

Epoch: 5| Step: 6
Training loss: 2.304845094680786
Validation loss: 2.4884621379196004

Epoch: 5| Step: 7
Training loss: 2.704782009124756
Validation loss: 2.4887301204025105

Epoch: 5| Step: 8
Training loss: 3.0463130474090576
Validation loss: 2.488649388795258

Epoch: 5| Step: 9
Training loss: 2.9530911445617676
Validation loss: 2.4902042342770483

Epoch: 5| Step: 10
Training loss: 3.00386381149292
Validation loss: 2.4848656641539706

Epoch: 157| Step: 0
Training loss: 2.3019070625305176
Validation loss: 2.489448114108014

Epoch: 5| Step: 1
Training loss: 2.9213287830352783
Validation loss: 2.486429455459759

Epoch: 5| Step: 2
Training loss: 2.98701548576355
Validation loss: 2.490582278979722

Epoch: 5| Step: 3
Training loss: 2.010009527206421
Validation loss: 2.488467680510654

Epoch: 5| Step: 4
Training loss: 3.137303352355957
Validation loss: 2.4886521382998397

Epoch: 5| Step: 5
Training loss: 2.9912214279174805
Validation loss: 2.483137043573523

Epoch: 5| Step: 6
Training loss: 2.7001748085021973
Validation loss: 2.4837331541122927

Epoch: 5| Step: 7
Training loss: 2.7211930751800537
Validation loss: 2.4826179883813344

Epoch: 5| Step: 8
Training loss: 2.328927993774414
Validation loss: 2.486630165448753

Epoch: 5| Step: 9
Training loss: 2.7944493293762207
Validation loss: 2.485993363523996

Epoch: 5| Step: 10
Training loss: 2.5806870460510254
Validation loss: 2.4895456247432257

Epoch: 158| Step: 0
Training loss: 2.794069290161133
Validation loss: 2.490170089147424

Epoch: 5| Step: 1
Training loss: 1.6837246417999268
Validation loss: 2.4945953046121905

Epoch: 5| Step: 2
Training loss: 2.9291210174560547
Validation loss: 2.4965043862660727

Epoch: 5| Step: 3
Training loss: 2.356621742248535
Validation loss: 2.4974335009051907

Epoch: 5| Step: 4
Training loss: 2.6617345809936523
Validation loss: 2.499966013816095

Epoch: 5| Step: 5
Training loss: 2.866278648376465
Validation loss: 2.5068048405390915

Epoch: 5| Step: 6
Training loss: 3.0497045516967773
Validation loss: 2.5093363203028196

Epoch: 5| Step: 7
Training loss: 3.1261401176452637
Validation loss: 2.514510626433998

Epoch: 5| Step: 8
Training loss: 2.496523857116699
Validation loss: 2.5027603436541814

Epoch: 5| Step: 9
Training loss: 2.807077646255493
Validation loss: 2.492841879526774

Epoch: 5| Step: 10
Training loss: 2.854748249053955
Validation loss: 2.4868976582763014

Epoch: 159| Step: 0
Training loss: 2.9224014282226562
Validation loss: 2.4863232348554876

Epoch: 5| Step: 1
Training loss: 2.6445205211639404
Validation loss: 2.4876016750130603

Epoch: 5| Step: 2
Training loss: 3.060058832168579
Validation loss: 2.489211687477686

Epoch: 5| Step: 3
Training loss: 2.5146026611328125
Validation loss: 2.4972592810148835

Epoch: 5| Step: 4
Training loss: 2.6754744052886963
Validation loss: 2.5029887486529607

Epoch: 5| Step: 5
Training loss: 2.4232146739959717
Validation loss: 2.5070476301254763

Epoch: 5| Step: 6
Training loss: 2.5498409271240234
Validation loss: 2.5110878636760097

Epoch: 5| Step: 7
Training loss: 2.7075939178466797
Validation loss: 2.5114217368505334

Epoch: 5| Step: 8
Training loss: 2.6762535572052
Validation loss: 2.5011088925023235

Epoch: 5| Step: 9
Training loss: 2.88435959815979
Validation loss: 2.495084044753864

Epoch: 5| Step: 10
Training loss: 2.847586154937744
Validation loss: 2.4899731451465237

Epoch: 160| Step: 0
Training loss: 2.991356611251831
Validation loss: 2.4844541267682145

Epoch: 5| Step: 1
Training loss: 2.344712734222412
Validation loss: 2.4769845316486974

Epoch: 5| Step: 2
Training loss: 2.2309606075286865
Validation loss: 2.4770798708802912

Epoch: 5| Step: 3
Training loss: 2.5829081535339355
Validation loss: 2.479501534533757

Epoch: 5| Step: 4
Training loss: 2.8850975036621094
Validation loss: 2.482970460768669

Epoch: 5| Step: 5
Training loss: 2.454890012741089
Validation loss: 2.4954421750960813

Epoch: 5| Step: 6
Training loss: 2.9239203929901123
Validation loss: 2.5022271961294194

Epoch: 5| Step: 7
Training loss: 2.300488233566284
Validation loss: 2.509183486302694

Epoch: 5| Step: 8
Training loss: 3.141136646270752
Validation loss: 2.5078720123537126

Epoch: 5| Step: 9
Training loss: 2.781860828399658
Validation loss: 2.5089338415412494

Epoch: 5| Step: 10
Training loss: 2.960347890853882
Validation loss: 2.5054580985858874

Epoch: 161| Step: 0
Training loss: 2.398310661315918
Validation loss: 2.5095139344533286

Epoch: 5| Step: 1
Training loss: 2.372708797454834
Validation loss: 2.505955162868705

Epoch: 5| Step: 2
Training loss: 3.4998154640197754
Validation loss: 2.5090347951458347

Epoch: 5| Step: 3
Training loss: 2.7763619422912598
Validation loss: 2.506070952261648

Epoch: 5| Step: 4
Training loss: 2.7285304069519043
Validation loss: 2.496566664788031

Epoch: 5| Step: 5
Training loss: 3.321287155151367
Validation loss: 2.5035796191102717

Epoch: 5| Step: 6
Training loss: 2.123134136199951
Validation loss: 2.5026237528811217

Epoch: 5| Step: 7
Training loss: 2.8503880500793457
Validation loss: 2.5040049681099514

Epoch: 5| Step: 8
Training loss: 1.9086658954620361
Validation loss: 2.494231854715655

Epoch: 5| Step: 9
Training loss: 3.144472360610962
Validation loss: 2.489877849496821

Epoch: 5| Step: 10
Training loss: 2.3763792514801025
Validation loss: 2.4841507250262844

Epoch: 162| Step: 0
Training loss: 2.572467565536499
Validation loss: 2.480443631449053

Epoch: 5| Step: 1
Training loss: 2.713031768798828
Validation loss: 2.4750052780233402

Epoch: 5| Step: 2
Training loss: 2.2408790588378906
Validation loss: 2.4786995303246284

Epoch: 5| Step: 3
Training loss: 2.890786647796631
Validation loss: 2.4792243742173716

Epoch: 5| Step: 4
Training loss: 3.4541289806365967
Validation loss: 2.4818493807187645

Epoch: 5| Step: 5
Training loss: 2.4863409996032715
Validation loss: 2.4819493088670956

Epoch: 5| Step: 6
Training loss: 2.3793997764587402
Validation loss: 2.486207772326726

Epoch: 5| Step: 7
Training loss: 2.836169719696045
Validation loss: 2.4850550825877855

Epoch: 5| Step: 8
Training loss: 3.140259265899658
Validation loss: 2.4859010993793444

Epoch: 5| Step: 9
Training loss: 2.136107921600342
Validation loss: 2.484352106689125

Epoch: 5| Step: 10
Training loss: 2.825723886489868
Validation loss: 2.4823470090025213

Epoch: 163| Step: 0
Training loss: 1.624511957168579
Validation loss: 2.4812693416431384

Epoch: 5| Step: 1
Training loss: 3.295250415802002
Validation loss: 2.477729343598889

Epoch: 5| Step: 2
Training loss: 2.726696252822876
Validation loss: 2.477266380863805

Epoch: 5| Step: 3
Training loss: 2.722019910812378
Validation loss: 2.4780828696425243

Epoch: 5| Step: 4
Training loss: 3.3500773906707764
Validation loss: 2.4727022160765944

Epoch: 5| Step: 5
Training loss: 2.342062473297119
Validation loss: 2.4743666007954586

Epoch: 5| Step: 6
Training loss: 3.3232784271240234
Validation loss: 2.4737972828649704

Epoch: 5| Step: 7
Training loss: 2.357703685760498
Validation loss: 2.4735349814097085

Epoch: 5| Step: 8
Training loss: 2.7773196697235107
Validation loss: 2.481997351492605

Epoch: 5| Step: 9
Training loss: 2.583204507827759
Validation loss: 2.4914633817570184

Epoch: 5| Step: 10
Training loss: 2.373778820037842
Validation loss: 2.4974171294960925

Epoch: 164| Step: 0
Training loss: 2.5851237773895264
Validation loss: 2.4934864659463205

Epoch: 5| Step: 1
Training loss: 2.6898982524871826
Validation loss: 2.4856846255640828

Epoch: 5| Step: 2
Training loss: 3.137119770050049
Validation loss: 2.487834063909387

Epoch: 5| Step: 3
Training loss: 3.331164598464966
Validation loss: 2.4970074340861332

Epoch: 5| Step: 4
Training loss: 2.7939066886901855
Validation loss: 2.4902328586065643

Epoch: 5| Step: 5
Training loss: 3.036895275115967
Validation loss: 2.477359382055139

Epoch: 5| Step: 6
Training loss: 2.513108253479004
Validation loss: 2.4707532057198147

Epoch: 5| Step: 7
Training loss: 2.2787768840789795
Validation loss: 2.4728110554397746

Epoch: 5| Step: 8
Training loss: 2.0522847175598145
Validation loss: 2.4691705473007692

Epoch: 5| Step: 9
Training loss: 2.3301022052764893
Validation loss: 2.4738267519140757

Epoch: 5| Step: 10
Training loss: 2.744593381881714
Validation loss: 2.480036848334856

Epoch: 165| Step: 0
Training loss: 1.9910656213760376
Validation loss: 2.481837321353215

Epoch: 5| Step: 1
Training loss: 2.4094152450561523
Validation loss: 2.4907921693658315

Epoch: 5| Step: 2
Training loss: 2.1962666511535645
Validation loss: 2.508769383994482

Epoch: 5| Step: 3
Training loss: 2.9289512634277344
Validation loss: 2.5107699978736138

Epoch: 5| Step: 4
Training loss: 2.4665615558624268
Validation loss: 2.5158396587576917

Epoch: 5| Step: 5
Training loss: 2.8284189701080322
Validation loss: 2.4962068296247915

Epoch: 5| Step: 6
Training loss: 3.300489902496338
Validation loss: 2.485058258938533

Epoch: 5| Step: 7
Training loss: 3.0426411628723145
Validation loss: 2.4862557200975317

Epoch: 5| Step: 8
Training loss: 2.5692214965820312
Validation loss: 2.485051724218553

Epoch: 5| Step: 9
Training loss: 2.624016761779785
Validation loss: 2.4849008475580523

Epoch: 5| Step: 10
Training loss: 3.1571216583251953
Validation loss: 2.482440020448418

Epoch: 166| Step: 0
Training loss: 2.507413864135742
Validation loss: 2.485255979722546

Epoch: 5| Step: 1
Training loss: 2.69016170501709
Validation loss: 2.4898066469418105

Epoch: 5| Step: 2
Training loss: 2.427792549133301
Validation loss: 2.4967739505152546

Epoch: 5| Step: 3
Training loss: 2.5320279598236084
Validation loss: 2.49983730623799

Epoch: 5| Step: 4
Training loss: 3.2331433296203613
Validation loss: 2.4990071788910897

Epoch: 5| Step: 5
Training loss: 3.7057900428771973
Validation loss: 2.497796573946553

Epoch: 5| Step: 6
Training loss: 3.155914783477783
Validation loss: 2.498501226466189

Epoch: 5| Step: 7
Training loss: 2.194706916809082
Validation loss: 2.4879901511694795

Epoch: 5| Step: 8
Training loss: 2.5570549964904785
Validation loss: 2.4868763313498548

Epoch: 5| Step: 9
Training loss: 2.6634013652801514
Validation loss: 2.4837006292035504

Epoch: 5| Step: 10
Training loss: 1.915521502494812
Validation loss: 2.4801176081421556

Epoch: 167| Step: 0
Training loss: 3.4858005046844482
Validation loss: 2.4812428823081394

Epoch: 5| Step: 1
Training loss: 2.319662094116211
Validation loss: 2.477663045288414

Epoch: 5| Step: 2
Training loss: 1.961993932723999
Validation loss: 2.47559690988192

Epoch: 5| Step: 3
Training loss: 2.911158800125122
Validation loss: 2.484354490874916

Epoch: 5| Step: 4
Training loss: 3.2481601238250732
Validation loss: 2.479876918177451

Epoch: 5| Step: 5
Training loss: 2.7839934825897217
Validation loss: 2.4849496605575725

Epoch: 5| Step: 6
Training loss: 2.8290486335754395
Validation loss: 2.4899716633622364

Epoch: 5| Step: 7
Training loss: 2.680922269821167
Validation loss: 2.4908229202352543

Epoch: 5| Step: 8
Training loss: 2.725567579269409
Validation loss: 2.490553737968527

Epoch: 5| Step: 9
Training loss: 1.9196078777313232
Validation loss: 2.4840670580505044

Epoch: 5| Step: 10
Training loss: 2.641859769821167
Validation loss: 2.4768146417474233

Epoch: 168| Step: 0
Training loss: 2.5786452293395996
Validation loss: 2.476166835395239

Epoch: 5| Step: 1
Training loss: 2.7792093753814697
Validation loss: 2.4742636860057874

Epoch: 5| Step: 2
Training loss: 2.6114258766174316
Validation loss: 2.470795723699754

Epoch: 5| Step: 3
Training loss: 2.7140445709228516
Validation loss: 2.4735939784716536

Epoch: 5| Step: 4
Training loss: 2.526697874069214
Validation loss: 2.4696333049446024

Epoch: 5| Step: 5
Training loss: 2.515082597732544
Validation loss: 2.4699557417182514

Epoch: 5| Step: 6
Training loss: 2.847944736480713
Validation loss: 2.469650927410331

Epoch: 5| Step: 7
Training loss: 3.1885385513305664
Validation loss: 2.468815806091473

Epoch: 5| Step: 8
Training loss: 1.9827972650527954
Validation loss: 2.4681132583207983

Epoch: 5| Step: 9
Training loss: 2.6419765949249268
Validation loss: 2.4682041675813737

Epoch: 5| Step: 10
Training loss: 3.1414637565612793
Validation loss: 2.471637246429279

Epoch: 169| Step: 0
Training loss: 2.9001216888427734
Validation loss: 2.4761064616582726

Epoch: 5| Step: 1
Training loss: 2.004525661468506
Validation loss: 2.4784718662179928

Epoch: 5| Step: 2
Training loss: 3.2333984375
Validation loss: 2.47689212265835

Epoch: 5| Step: 3
Training loss: 2.4902901649475098
Validation loss: 2.472647661803871

Epoch: 5| Step: 4
Training loss: 3.0203089714050293
Validation loss: 2.464705110878073

Epoch: 5| Step: 5
Training loss: 2.716587543487549
Validation loss: 2.46640169876878

Epoch: 5| Step: 6
Training loss: 2.7430574893951416
Validation loss: 2.4664601023479173

Epoch: 5| Step: 7
Training loss: 2.294617176055908
Validation loss: 2.4680627264002317

Epoch: 5| Step: 8
Training loss: 2.6958744525909424
Validation loss: 2.4716861286470966

Epoch: 5| Step: 9
Training loss: 2.7881362438201904
Validation loss: 2.4714983599160307

Epoch: 5| Step: 10
Training loss: 2.5220532417297363
Validation loss: 2.4709272307734333

Epoch: 170| Step: 0
Training loss: 2.9178082942962646
Validation loss: 2.473918871213031

Epoch: 5| Step: 1
Training loss: 2.7585372924804688
Validation loss: 2.477868628758256

Epoch: 5| Step: 2
Training loss: 2.7033185958862305
Validation loss: 2.4757184905390583

Epoch: 5| Step: 3
Training loss: 2.1967532634735107
Validation loss: 2.475501219431559

Epoch: 5| Step: 4
Training loss: 2.1591451168060303
Validation loss: 2.4789459115715435

Epoch: 5| Step: 5
Training loss: 2.629735231399536
Validation loss: 2.477258102868193

Epoch: 5| Step: 6
Training loss: 2.4383749961853027
Validation loss: 2.478451416056643

Epoch: 5| Step: 7
Training loss: 3.583826780319214
Validation loss: 2.472532662012244

Epoch: 5| Step: 8
Training loss: 2.6113197803497314
Validation loss: 2.475868607080111

Epoch: 5| Step: 9
Training loss: 3.0169711112976074
Validation loss: 2.4754372155794533

Epoch: 5| Step: 10
Training loss: 2.371577739715576
Validation loss: 2.4770931659206266

Epoch: 171| Step: 0
Training loss: 2.83782696723938
Validation loss: 2.4757652051987185

Epoch: 5| Step: 1
Training loss: 2.3005881309509277
Validation loss: 2.47759186836981

Epoch: 5| Step: 2
Training loss: 2.140800952911377
Validation loss: 2.4758961021259265

Epoch: 5| Step: 3
Training loss: 2.4838707447052
Validation loss: 2.474820119078441

Epoch: 5| Step: 4
Training loss: 3.307292938232422
Validation loss: 2.479077882664178

Epoch: 5| Step: 5
Training loss: 2.594822883605957
Validation loss: 2.487693404638639

Epoch: 5| Step: 6
Training loss: 2.5468218326568604
Validation loss: 2.484449945470338

Epoch: 5| Step: 7
Training loss: 2.55521821975708
Validation loss: 2.498395155834895

Epoch: 5| Step: 8
Training loss: 3.13026762008667
Validation loss: 2.501269899388795

Epoch: 5| Step: 9
Training loss: 3.0123820304870605
Validation loss: 2.488727682380266

Epoch: 5| Step: 10
Training loss: 2.528259038925171
Validation loss: 2.4752264176645586

Epoch: 172| Step: 0
Training loss: 2.5475475788116455
Validation loss: 2.46812161578927

Epoch: 5| Step: 1
Training loss: 2.5455029010772705
Validation loss: 2.46683729464008

Epoch: 5| Step: 2
Training loss: 2.7003238201141357
Validation loss: 2.466558079565725

Epoch: 5| Step: 3
Training loss: 2.5683889389038086
Validation loss: 2.468069491847869

Epoch: 5| Step: 4
Training loss: 2.148589611053467
Validation loss: 2.4637151636103147

Epoch: 5| Step: 5
Training loss: 3.097261428833008
Validation loss: 2.464444891099007

Epoch: 5| Step: 6
Training loss: 2.4118475914001465
Validation loss: 2.4632404235101517

Epoch: 5| Step: 7
Training loss: 3.523197650909424
Validation loss: 2.463331086661226

Epoch: 5| Step: 8
Training loss: 2.768981456756592
Validation loss: 2.465330634065854

Epoch: 5| Step: 9
Training loss: 2.4236223697662354
Validation loss: 2.467824028384301

Epoch: 5| Step: 10
Training loss: 2.643707036972046
Validation loss: 2.471023667243219

Epoch: 173| Step: 0
Training loss: 3.0018627643585205
Validation loss: 2.477583526283182

Epoch: 5| Step: 1
Training loss: 2.846559762954712
Validation loss: 2.483296304620722

Epoch: 5| Step: 2
Training loss: 2.6656694412231445
Validation loss: 2.4874209229664137

Epoch: 5| Step: 3
Training loss: 3.2204203605651855
Validation loss: 2.4834327492662656

Epoch: 5| Step: 4
Training loss: 2.2301807403564453
Validation loss: 2.481901063713976

Epoch: 5| Step: 5
Training loss: 2.495173931121826
Validation loss: 2.4721414786513134

Epoch: 5| Step: 6
Training loss: 2.514655590057373
Validation loss: 2.4687672430469143

Epoch: 5| Step: 7
Training loss: 2.632183790206909
Validation loss: 2.4629274388795257

Epoch: 5| Step: 8
Training loss: 2.2853424549102783
Validation loss: 2.4608141760672293

Epoch: 5| Step: 9
Training loss: 3.0065770149230957
Validation loss: 2.4612769388383433

Epoch: 5| Step: 10
Training loss: 2.4146969318389893
Validation loss: 2.4619439622407318

Epoch: 174| Step: 0
Training loss: 2.341785430908203
Validation loss: 2.4621988957928074

Epoch: 5| Step: 1
Training loss: 2.2787559032440186
Validation loss: 2.4634949571342877

Epoch: 5| Step: 2
Training loss: 2.9582719802856445
Validation loss: 2.464850192428917

Epoch: 5| Step: 3
Training loss: 2.6946756839752197
Validation loss: 2.4682869001101424

Epoch: 5| Step: 4
Training loss: 2.771665096282959
Validation loss: 2.468020592966387

Epoch: 5| Step: 5
Training loss: 2.59125018119812
Validation loss: 2.4603558560853362

Epoch: 5| Step: 6
Training loss: 1.956748366355896
Validation loss: 2.4642365183881534

Epoch: 5| Step: 7
Training loss: 3.4534430503845215
Validation loss: 2.4637869711845153

Epoch: 5| Step: 8
Training loss: 2.9825661182403564
Validation loss: 2.4642289966665287

Epoch: 5| Step: 9
Training loss: 2.625251054763794
Validation loss: 2.463918075766615

Epoch: 5| Step: 10
Training loss: 2.685739755630493
Validation loss: 2.4604011145971154

Epoch: 175| Step: 0
Training loss: 2.1472175121307373
Validation loss: 2.4615822017833753

Epoch: 5| Step: 1
Training loss: 3.2465755939483643
Validation loss: 2.4599443558723695

Epoch: 5| Step: 2
Training loss: 3.0643832683563232
Validation loss: 2.462065804389215

Epoch: 5| Step: 3
Training loss: 2.1158764362335205
Validation loss: 2.460832388170304

Epoch: 5| Step: 4
Training loss: 2.7534639835357666
Validation loss: 2.462282378186462

Epoch: 5| Step: 5
Training loss: 2.5013890266418457
Validation loss: 2.4611616506371448

Epoch: 5| Step: 6
Training loss: 2.624882698059082
Validation loss: 2.4581441494726364

Epoch: 5| Step: 7
Training loss: 2.339055299758911
Validation loss: 2.4582095735816547

Epoch: 5| Step: 8
Training loss: 3.0675771236419678
Validation loss: 2.458224506788356

Epoch: 5| Step: 9
Training loss: 2.8228955268859863
Validation loss: 2.4586842367725987

Epoch: 5| Step: 10
Training loss: 2.6003940105438232
Validation loss: 2.465800139211839

Epoch: 176| Step: 0
Training loss: 2.7116847038269043
Validation loss: 2.472714267751222

Epoch: 5| Step: 1
Training loss: 2.1273653507232666
Validation loss: 2.4774377474220852

Epoch: 5| Step: 2
Training loss: 2.4940860271453857
Validation loss: 2.4786080262994252

Epoch: 5| Step: 3
Training loss: 2.900489091873169
Validation loss: 2.468367800917677

Epoch: 5| Step: 4
Training loss: 2.367250442504883
Validation loss: 2.4620685474846953

Epoch: 5| Step: 5
Training loss: 3.060793161392212
Validation loss: 2.4604900908726517

Epoch: 5| Step: 6
Training loss: 2.5601370334625244
Validation loss: 2.459489894169633

Epoch: 5| Step: 7
Training loss: 3.1389338970184326
Validation loss: 2.4581816862988215

Epoch: 5| Step: 8
Training loss: 2.515350818634033
Validation loss: 2.4607941591611473

Epoch: 5| Step: 9
Training loss: 2.8501083850860596
Validation loss: 2.459695718621695

Epoch: 5| Step: 10
Training loss: 2.6914026737213135
Validation loss: 2.4612531072349957

Epoch: 177| Step: 0
Training loss: 2.488708257675171
Validation loss: 2.4656546808058217

Epoch: 5| Step: 1
Training loss: 3.285773515701294
Validation loss: 2.4646559069233556

Epoch: 5| Step: 2
Training loss: 2.7294363975524902
Validation loss: 2.466235073663855

Epoch: 5| Step: 3
Training loss: 2.491795063018799
Validation loss: 2.467052416134906

Epoch: 5| Step: 4
Training loss: 2.266977310180664
Validation loss: 2.4671545669596684

Epoch: 5| Step: 5
Training loss: 2.839233875274658
Validation loss: 2.46905025359123

Epoch: 5| Step: 6
Training loss: 2.767050266265869
Validation loss: 2.4726226329803467

Epoch: 5| Step: 7
Training loss: 2.210908889770508
Validation loss: 2.474100027033078

Epoch: 5| Step: 8
Training loss: 2.8149170875549316
Validation loss: 2.474883028255996

Epoch: 5| Step: 9
Training loss: 2.9326400756835938
Validation loss: 2.469005528316703

Epoch: 5| Step: 10
Training loss: 2.5140225887298584
Validation loss: 2.4618320926543205

Epoch: 178| Step: 0
Training loss: 2.8932266235351562
Validation loss: 2.4619267961030364

Epoch: 5| Step: 1
Training loss: 2.2916269302368164
Validation loss: 2.4589702211400515

Epoch: 5| Step: 2
Training loss: 2.965660572052002
Validation loss: 2.4574453740991573

Epoch: 5| Step: 3
Training loss: 2.8054702281951904
Validation loss: 2.4602869556796167

Epoch: 5| Step: 4
Training loss: 2.779076337814331
Validation loss: 2.4595543928043817

Epoch: 5| Step: 5
Training loss: 3.0799648761749268
Validation loss: 2.4590662089727258

Epoch: 5| Step: 6
Training loss: 2.5527091026306152
Validation loss: 2.455774963542979

Epoch: 5| Step: 7
Training loss: 2.865739107131958
Validation loss: 2.4553914095765803

Epoch: 5| Step: 8
Training loss: 1.844662070274353
Validation loss: 2.4563889913661505

Epoch: 5| Step: 9
Training loss: 2.711949586868286
Validation loss: 2.4581347473206057

Epoch: 5| Step: 10
Training loss: 2.53560209274292
Validation loss: 2.458456234265399

Epoch: 179| Step: 0
Training loss: 2.381925106048584
Validation loss: 2.4581881928187546

Epoch: 5| Step: 1
Training loss: 2.6393704414367676
Validation loss: 2.454156198809224

Epoch: 5| Step: 2
Training loss: 3.318260908126831
Validation loss: 2.4556327763424126

Epoch: 5| Step: 3
Training loss: 2.418989658355713
Validation loss: 2.4573419940087105

Epoch: 5| Step: 4
Training loss: 2.539090633392334
Validation loss: 2.459785158916186

Epoch: 5| Step: 5
Training loss: 2.6867752075195312
Validation loss: 2.464876736364057

Epoch: 5| Step: 6
Training loss: 2.3036539554595947
Validation loss: 2.4617191514661236

Epoch: 5| Step: 7
Training loss: 3.0372989177703857
Validation loss: 2.456789767870339

Epoch: 5| Step: 8
Training loss: 2.9862618446350098
Validation loss: 2.4510900307727117

Epoch: 5| Step: 9
Training loss: 2.45479154586792
Validation loss: 2.452340392656224

Epoch: 5| Step: 10
Training loss: 2.459840774536133
Validation loss: 2.4516027460816088

Epoch: 180| Step: 0
Training loss: 2.904024839401245
Validation loss: 2.450967214440787

Epoch: 5| Step: 1
Training loss: 2.6580073833465576
Validation loss: 2.4568386257335706

Epoch: 5| Step: 2
Training loss: 2.287111759185791
Validation loss: 2.451737614088161

Epoch: 5| Step: 3
Training loss: 2.3612186908721924
Validation loss: 2.452848694657767

Epoch: 5| Step: 4
Training loss: 3.151978015899658
Validation loss: 2.45518857817496

Epoch: 5| Step: 5
Training loss: 2.1698384284973145
Validation loss: 2.452673009646836

Epoch: 5| Step: 6
Training loss: 2.5872840881347656
Validation loss: 2.4530564354312037

Epoch: 5| Step: 7
Training loss: 2.6695685386657715
Validation loss: 2.4520913913685787

Epoch: 5| Step: 8
Training loss: 2.5913612842559814
Validation loss: 2.455554469939201

Epoch: 5| Step: 9
Training loss: 3.156162977218628
Validation loss: 2.456536113574941

Epoch: 5| Step: 10
Training loss: 2.7037625312805176
Validation loss: 2.456361730893453

Epoch: 181| Step: 0
Training loss: 3.096024990081787
Validation loss: 2.4563278023914625

Epoch: 5| Step: 1
Training loss: 3.299156665802002
Validation loss: 2.4647195518657727

Epoch: 5| Step: 2
Training loss: 2.5170865058898926
Validation loss: 2.463485389627436

Epoch: 5| Step: 3
Training loss: 2.8768715858459473
Validation loss: 2.473389087184783

Epoch: 5| Step: 4
Training loss: 2.6101160049438477
Validation loss: 2.4709835539581957

Epoch: 5| Step: 5
Training loss: 1.9702552556991577
Validation loss: 2.4726430780144146

Epoch: 5| Step: 6
Training loss: 2.5038204193115234
Validation loss: 2.463266259880476

Epoch: 5| Step: 7
Training loss: 2.4988582134246826
Validation loss: 2.4670350705423663

Epoch: 5| Step: 8
Training loss: 2.607813835144043
Validation loss: 2.466027388008692

Epoch: 5| Step: 9
Training loss: 2.386009693145752
Validation loss: 2.465861802460045

Epoch: 5| Step: 10
Training loss: 2.995922565460205
Validation loss: 2.4681536279698855

Epoch: 182| Step: 0
Training loss: 1.5747789144515991
Validation loss: 2.4603035116708405

Epoch: 5| Step: 1
Training loss: 3.4830710887908936
Validation loss: 2.4566604347639185

Epoch: 5| Step: 2
Training loss: 2.418553590774536
Validation loss: 2.4576744853809314

Epoch: 5| Step: 3
Training loss: 2.637885570526123
Validation loss: 2.4505104531524

Epoch: 5| Step: 4
Training loss: 2.417832851409912
Validation loss: 2.4453951876650573

Epoch: 5| Step: 5
Training loss: 2.689239978790283
Validation loss: 2.448710831262732

Epoch: 5| Step: 6
Training loss: 2.777536153793335
Validation loss: 2.451706737600347

Epoch: 5| Step: 7
Training loss: 2.5817654132843018
Validation loss: 2.441648439694476

Epoch: 5| Step: 8
Training loss: 3.0509777069091797
Validation loss: 2.4458663412319717

Epoch: 5| Step: 9
Training loss: 2.8513741493225098
Validation loss: 2.451256272613361

Epoch: 5| Step: 10
Training loss: 2.8123974800109863
Validation loss: 2.457712214480164

Epoch: 183| Step: 0
Training loss: 3.051367998123169
Validation loss: 2.4565633676385366

Epoch: 5| Step: 1
Training loss: 2.2759299278259277
Validation loss: 2.454733802426246

Epoch: 5| Step: 2
Training loss: 2.704575777053833
Validation loss: 2.452702991424068

Epoch: 5| Step: 3
Training loss: 2.4630837440490723
Validation loss: 2.4595402056171047

Epoch: 5| Step: 4
Training loss: 2.881089687347412
Validation loss: 2.465155391282933

Epoch: 5| Step: 5
Training loss: 2.8258025646209717
Validation loss: 2.4647072720271286

Epoch: 5| Step: 6
Training loss: 3.1055009365081787
Validation loss: 2.4611440576532835

Epoch: 5| Step: 7
Training loss: 2.0483925342559814
Validation loss: 2.456340910286032

Epoch: 5| Step: 8
Training loss: 3.1495249271392822
Validation loss: 2.4543388223135345

Epoch: 5| Step: 9
Training loss: 2.2078661918640137
Validation loss: 2.449544827143351

Epoch: 5| Step: 10
Training loss: 2.467963695526123
Validation loss: 2.444785964104437

Epoch: 184| Step: 0
Training loss: 3.3394885063171387
Validation loss: 2.445117829948343

Epoch: 5| Step: 1
Training loss: 2.889225482940674
Validation loss: 2.4523819492709253

Epoch: 5| Step: 2
Training loss: 2.6833622455596924
Validation loss: 2.460352518225229

Epoch: 5| Step: 3
Training loss: 2.1092238426208496
Validation loss: 2.458568731943766

Epoch: 5| Step: 4
Training loss: 1.8652992248535156
Validation loss: 2.478091219420074

Epoch: 5| Step: 5
Training loss: 1.7669368982315063
Validation loss: 2.480401659524569

Epoch: 5| Step: 6
Training loss: 2.855494260787964
Validation loss: 2.4564372467738327

Epoch: 5| Step: 7
Training loss: 2.825122356414795
Validation loss: 2.452770781773393

Epoch: 5| Step: 8
Training loss: 3.6405341625213623
Validation loss: 2.4475331178275486

Epoch: 5| Step: 9
Training loss: 2.5187058448791504
Validation loss: 2.449106595849478

Epoch: 5| Step: 10
Training loss: 2.819258689880371
Validation loss: 2.454692650866765

Epoch: 185| Step: 0
Training loss: 2.783370018005371
Validation loss: 2.452405875728976

Epoch: 5| Step: 1
Training loss: 2.734945058822632
Validation loss: 2.4511412548762497

Epoch: 5| Step: 2
Training loss: 2.7018942832946777
Validation loss: 2.453381748609645

Epoch: 5| Step: 3
Training loss: 2.3735814094543457
Validation loss: 2.453365602800923

Epoch: 5| Step: 4
Training loss: 2.6467604637145996
Validation loss: 2.453086627426968

Epoch: 5| Step: 5
Training loss: 2.992027759552002
Validation loss: 2.450788467161117

Epoch: 5| Step: 6
Training loss: 3.112217426300049
Validation loss: 2.4489280434064966

Epoch: 5| Step: 7
Training loss: 2.3942246437072754
Validation loss: 2.4494345213777278

Epoch: 5| Step: 8
Training loss: 2.272667646408081
Validation loss: 2.448914545838551

Epoch: 5| Step: 9
Training loss: 2.4622883796691895
Validation loss: 2.4484981593265327

Epoch: 5| Step: 10
Training loss: 2.839695692062378
Validation loss: 2.45887783650429

Epoch: 186| Step: 0
Training loss: 2.400040864944458
Validation loss: 2.458733066435783

Epoch: 5| Step: 1
Training loss: 3.102750301361084
Validation loss: 2.4681248049582205

Epoch: 5| Step: 2
Training loss: 2.8589844703674316
Validation loss: 2.477054390856015

Epoch: 5| Step: 3
Training loss: 3.080731153488159
Validation loss: 2.478765800435056

Epoch: 5| Step: 4
Training loss: 2.873821496963501
Validation loss: 2.4727331489645024

Epoch: 5| Step: 5
Training loss: 2.2724099159240723
Validation loss: 2.464973675307407

Epoch: 5| Step: 6
Training loss: 2.1323561668395996
Validation loss: 2.467201896893081

Epoch: 5| Step: 7
Training loss: 2.917745351791382
Validation loss: 2.468301829471383

Epoch: 5| Step: 8
Training loss: 2.3915891647338867
Validation loss: 2.456471786704115

Epoch: 5| Step: 9
Training loss: 3.1370296478271484
Validation loss: 2.461080135837678

Epoch: 5| Step: 10
Training loss: 2.0266168117523193
Validation loss: 2.4595507806347263

Epoch: 187| Step: 0
Training loss: 2.694732904434204
Validation loss: 2.443883808710242

Epoch: 5| Step: 1
Training loss: 2.9330363273620605
Validation loss: 2.4435839678651545

Epoch: 5| Step: 2
Training loss: 1.9035027027130127
Validation loss: 2.444535465650661

Epoch: 5| Step: 3
Training loss: 3.050133466720581
Validation loss: 2.4408200479322866

Epoch: 5| Step: 4
Training loss: 2.441443920135498
Validation loss: 2.4385754728829987

Epoch: 5| Step: 5
Training loss: 2.9924962520599365
Validation loss: 2.4461713016674085

Epoch: 5| Step: 6
Training loss: 2.2303173542022705
Validation loss: 2.4455103989570373

Epoch: 5| Step: 7
Training loss: 2.9124579429626465
Validation loss: 2.4544636818670456

Epoch: 5| Step: 8
Training loss: 2.448619842529297
Validation loss: 2.455626844077982

Epoch: 5| Step: 9
Training loss: 2.7761199474334717
Validation loss: 2.4484421207058813

Epoch: 5| Step: 10
Training loss: 2.9888973236083984
Validation loss: 2.4540509023974018

Epoch: 188| Step: 0
Training loss: 2.492518901824951
Validation loss: 2.456498590848779

Epoch: 5| Step: 1
Training loss: 2.2420878410339355
Validation loss: 2.4558079165797078

Epoch: 5| Step: 2
Training loss: 3.018928050994873
Validation loss: 2.4668589048488165

Epoch: 5| Step: 3
Training loss: 2.134320020675659
Validation loss: 2.467802224620696

Epoch: 5| Step: 4
Training loss: 2.4534595012664795
Validation loss: 2.4717088002030567

Epoch: 5| Step: 5
Training loss: 2.6768200397491455
Validation loss: 2.4776714104478077

Epoch: 5| Step: 6
Training loss: 2.7852768898010254
Validation loss: 2.4739100471619637

Epoch: 5| Step: 7
Training loss: 3.040503978729248
Validation loss: 2.4639360340692664

Epoch: 5| Step: 8
Training loss: 3.360882520675659
Validation loss: 2.4544415986666115

Epoch: 5| Step: 9
Training loss: 2.188880205154419
Validation loss: 2.4540912874283327

Epoch: 5| Step: 10
Training loss: 2.944883108139038
Validation loss: 2.4410509370988414

Epoch: 189| Step: 0
Training loss: 3.2171871662139893
Validation loss: 2.443602433768652

Epoch: 5| Step: 1
Training loss: 2.4045727252960205
Validation loss: 2.448237262746339

Epoch: 5| Step: 2
Training loss: 3.172441005706787
Validation loss: 2.4437860135109193

Epoch: 5| Step: 3
Training loss: 2.644395351409912
Validation loss: 2.4392885546530447

Epoch: 5| Step: 4
Training loss: 2.5272839069366455
Validation loss: 2.4428233638886483

Epoch: 5| Step: 5
Training loss: 2.7521965503692627
Validation loss: 2.439682842582785

Epoch: 5| Step: 6
Training loss: 3.0621845722198486
Validation loss: 2.44302128207299

Epoch: 5| Step: 7
Training loss: 2.2504494190216064
Validation loss: 2.444553662371892

Epoch: 5| Step: 8
Training loss: 2.524956226348877
Validation loss: 2.4438888770277782

Epoch: 5| Step: 9
Training loss: 2.0410053730010986
Validation loss: 2.4509850317432034

Epoch: 5| Step: 10
Training loss: 2.5796048641204834
Validation loss: 2.4586450412709224

Epoch: 190| Step: 0
Training loss: 2.768963575363159
Validation loss: 2.4663288106200514

Epoch: 5| Step: 1
Training loss: 2.707113742828369
Validation loss: 2.4583756077674126

Epoch: 5| Step: 2
Training loss: 2.3427481651306152
Validation loss: 2.4555437334122194

Epoch: 5| Step: 3
Training loss: 2.8864800930023193
Validation loss: 2.4474148135031424

Epoch: 5| Step: 4
Training loss: 3.3046886920928955
Validation loss: 2.4470282831499652

Epoch: 5| Step: 5
Training loss: 2.8219170570373535
Validation loss: 2.4469454929392827

Epoch: 5| Step: 6
Training loss: 2.309231758117676
Validation loss: 2.454380814747144

Epoch: 5| Step: 7
Training loss: 1.8099561929702759
Validation loss: 2.450902951660977

Epoch: 5| Step: 8
Training loss: 2.521503448486328
Validation loss: 2.4512039025624595

Epoch: 5| Step: 9
Training loss: 2.8103795051574707
Validation loss: 2.44871764029226

Epoch: 5| Step: 10
Training loss: 2.9795985221862793
Validation loss: 2.4515023231506348

Epoch: 191| Step: 0
Training loss: 3.025505542755127
Validation loss: 2.4532163450794835

Epoch: 5| Step: 1
Training loss: 2.585508346557617
Validation loss: 2.454764207204183

Epoch: 5| Step: 2
Training loss: 3.0421276092529297
Validation loss: 2.455915166485694

Epoch: 5| Step: 3
Training loss: 1.983033537864685
Validation loss: 2.4532240949651247

Epoch: 5| Step: 4
Training loss: 1.8204349279403687
Validation loss: 2.4439833356488134

Epoch: 5| Step: 5
Training loss: 2.442924737930298
Validation loss: 2.4474785276638564

Epoch: 5| Step: 6
Training loss: 3.124709367752075
Validation loss: 2.438474847424415

Epoch: 5| Step: 7
Training loss: 2.7857117652893066
Validation loss: 2.440982457130186

Epoch: 5| Step: 8
Training loss: 3.0356881618499756
Validation loss: 2.440370234110022

Epoch: 5| Step: 9
Training loss: 2.811323642730713
Validation loss: 2.448242542564228

Epoch: 5| Step: 10
Training loss: 2.4589152336120605
Validation loss: 2.447984310888475

Epoch: 192| Step: 0
Training loss: 3.127319097518921
Validation loss: 2.440842390060425

Epoch: 5| Step: 1
Training loss: 2.204911708831787
Validation loss: 2.439789338778424

Epoch: 5| Step: 2
Training loss: 3.0774917602539062
Validation loss: 2.4409814342375724

Epoch: 5| Step: 3
Training loss: 2.3492181301116943
Validation loss: 2.4393372099886657

Epoch: 5| Step: 4
Training loss: 2.5203781127929688
Validation loss: 2.440414536383844

Epoch: 5| Step: 5
Training loss: 2.817474842071533
Validation loss: 2.4334115123236053

Epoch: 5| Step: 6
Training loss: 3.071955442428589
Validation loss: 2.4306762705567064

Epoch: 5| Step: 7
Training loss: 2.3470206260681152
Validation loss: 2.434513654760135

Epoch: 5| Step: 8
Training loss: 2.417616605758667
Validation loss: 2.430912338277345

Epoch: 5| Step: 9
Training loss: 1.9853769540786743
Validation loss: 2.4312194316617903

Epoch: 5| Step: 10
Training loss: 3.296339750289917
Validation loss: 2.4303024917520504

Epoch: 193| Step: 0
Training loss: 2.721623420715332
Validation loss: 2.4426911774502007

Epoch: 5| Step: 1
Training loss: 2.428720474243164
Validation loss: 2.436931435779859

Epoch: 5| Step: 2
Training loss: 2.6610589027404785
Validation loss: 2.4408068682557795

Epoch: 5| Step: 3
Training loss: 2.8098015785217285
Validation loss: 2.4504623566904375

Epoch: 5| Step: 4
Training loss: 2.8652379512786865
Validation loss: 2.4498739140008086

Epoch: 5| Step: 5
Training loss: 2.973557233810425
Validation loss: 2.4549661938862135

Epoch: 5| Step: 6
Training loss: 2.6060900688171387
Validation loss: 2.4576081204158005

Epoch: 5| Step: 7
Training loss: 3.0871920585632324
Validation loss: 2.449568909983481

Epoch: 5| Step: 8
Training loss: 2.355146884918213
Validation loss: 2.4471805095672607

Epoch: 5| Step: 9
Training loss: 2.213283061981201
Validation loss: 2.4385798515812045

Epoch: 5| Step: 10
Training loss: 2.3430447578430176
Validation loss: 2.438366602825862

Epoch: 194| Step: 0
Training loss: 2.8669862747192383
Validation loss: 2.4396543220807145

Epoch: 5| Step: 1
Training loss: 2.6981441974639893
Validation loss: 2.44007364139762

Epoch: 5| Step: 2
Training loss: 3.241117000579834
Validation loss: 2.4372010743746193

Epoch: 5| Step: 3
Training loss: 2.171109437942505
Validation loss: 2.4412307585439375

Epoch: 5| Step: 4
Training loss: 3.0166149139404297
Validation loss: 2.445654971625215

Epoch: 5| Step: 5
Training loss: 2.4493308067321777
Validation loss: 2.443574887450023

Epoch: 5| Step: 6
Training loss: 2.6395134925842285
Validation loss: 2.4409776579949165

Epoch: 5| Step: 7
Training loss: 2.5119411945343018
Validation loss: 2.4466354564953874

Epoch: 5| Step: 8
Training loss: 2.6448845863342285
Validation loss: 2.4404232386619813

Epoch: 5| Step: 9
Training loss: 2.5826878547668457
Validation loss: 2.446067048657325

Epoch: 5| Step: 10
Training loss: 2.2792911529541016
Validation loss: 2.4521087587520642

Epoch: 195| Step: 0
Training loss: 2.877962112426758
Validation loss: 2.4458847994445474

Epoch: 5| Step: 1
Training loss: 2.377732276916504
Validation loss: 2.4546466540264826

Epoch: 5| Step: 2
Training loss: 2.760812759399414
Validation loss: 2.4623896178378852

Epoch: 5| Step: 3
Training loss: 2.705362319946289
Validation loss: 2.474611851476854

Epoch: 5| Step: 4
Training loss: 2.2188096046447754
Validation loss: 2.477531211350554

Epoch: 5| Step: 5
Training loss: 2.509145498275757
Validation loss: 2.4726420000035274

Epoch: 5| Step: 6
Training loss: 2.4092535972595215
Validation loss: 2.4686243764815794

Epoch: 5| Step: 7
Training loss: 2.9056975841522217
Validation loss: 2.4580280165518484

Epoch: 5| Step: 8
Training loss: 2.871410369873047
Validation loss: 2.4571264072131087

Epoch: 5| Step: 9
Training loss: 2.803495407104492
Validation loss: 2.4413054732866186

Epoch: 5| Step: 10
Training loss: 2.7772467136383057
Validation loss: 2.4333811421548166

Epoch: 196| Step: 0
Training loss: 2.718527317047119
Validation loss: 2.436550312144782

Epoch: 5| Step: 1
Training loss: 2.265389919281006
Validation loss: 2.4364800017367125

Epoch: 5| Step: 2
Training loss: 2.44486141204834
Validation loss: 2.438044830035138

Epoch: 5| Step: 3
Training loss: 2.8505587577819824
Validation loss: 2.4514358043670654

Epoch: 5| Step: 4
Training loss: 2.604933023452759
Validation loss: 2.4563173350467475

Epoch: 5| Step: 5
Training loss: 3.047119140625
Validation loss: 2.4517889176645586

Epoch: 5| Step: 6
Training loss: 2.190282106399536
Validation loss: 2.4477141441837436

Epoch: 5| Step: 7
Training loss: 3.3750603199005127
Validation loss: 2.4396364329963602

Epoch: 5| Step: 8
Training loss: 2.2373709678649902
Validation loss: 2.4356382277704056

Epoch: 5| Step: 9
Training loss: 2.619054079055786
Validation loss: 2.4304703127953315

Epoch: 5| Step: 10
Training loss: 2.8578808307647705
Validation loss: 2.4335449793005504

Epoch: 197| Step: 0
Training loss: 2.745966672897339
Validation loss: 2.435255468532603

Epoch: 5| Step: 1
Training loss: 2.5541489124298096
Validation loss: 2.4306612117316133

Epoch: 5| Step: 2
Training loss: 2.981316089630127
Validation loss: 2.432264527966899

Epoch: 5| Step: 3
Training loss: 2.6056647300720215
Validation loss: 2.4309283302676294

Epoch: 5| Step: 4
Training loss: 3.2701950073242188
Validation loss: 2.427832406054261

Epoch: 5| Step: 5
Training loss: 3.312267780303955
Validation loss: 2.429836550066548

Epoch: 5| Step: 6
Training loss: 1.9757664203643799
Validation loss: 2.426877106389692

Epoch: 5| Step: 7
Training loss: 2.5428175926208496
Validation loss: 2.4287395938750236

Epoch: 5| Step: 8
Training loss: 2.9227099418640137
Validation loss: 2.4264530469012517

Epoch: 5| Step: 9
Training loss: 2.3777451515197754
Validation loss: 2.434059070002648

Epoch: 5| Step: 10
Training loss: 1.6747325658798218
Validation loss: 2.435077492908765

Epoch: 198| Step: 0
Training loss: 2.465736150741577
Validation loss: 2.431555458294448

Epoch: 5| Step: 1
Training loss: 2.4788498878479004
Validation loss: 2.444183977701331

Epoch: 5| Step: 2
Training loss: 2.5009636878967285
Validation loss: 2.4354622030770905

Epoch: 5| Step: 3
Training loss: 2.408878803253174
Validation loss: 2.4327175335217546

Epoch: 5| Step: 4
Training loss: 2.617462635040283
Validation loss: 2.4304844692189205

Epoch: 5| Step: 5
Training loss: 2.3399198055267334
Validation loss: 2.4258245832176617

Epoch: 5| Step: 6
Training loss: 3.0532965660095215
Validation loss: 2.421664512285622

Epoch: 5| Step: 7
Training loss: 2.872530460357666
Validation loss: 2.4253124267824235

Epoch: 5| Step: 8
Training loss: 2.650242805480957
Validation loss: 2.429422673358712

Epoch: 5| Step: 9
Training loss: 3.11224365234375
Validation loss: 2.4274530231311755

Epoch: 5| Step: 10
Training loss: 2.616696357727051
Validation loss: 2.4324447877945437

Epoch: 199| Step: 0
Training loss: 2.342599630355835
Validation loss: 2.4376149690279396

Epoch: 5| Step: 1
Training loss: 3.1062440872192383
Validation loss: 2.4379576175443587

Epoch: 5| Step: 2
Training loss: 2.9560086727142334
Validation loss: 2.437852580060241

Epoch: 5| Step: 3
Training loss: 2.5398812294006348
Validation loss: 2.4391302575347242

Epoch: 5| Step: 4
Training loss: 2.969813823699951
Validation loss: 2.4464424425555813

Epoch: 5| Step: 5
Training loss: 2.8735225200653076
Validation loss: 2.4340857998017342

Epoch: 5| Step: 6
Training loss: 2.7792296409606934
Validation loss: 2.43069710013687

Epoch: 5| Step: 7
Training loss: 2.7406458854675293
Validation loss: 2.435450150120643

Epoch: 5| Step: 8
Training loss: 2.0392045974731445
Validation loss: 2.429490581635506

Epoch: 5| Step: 9
Training loss: 2.2937519550323486
Validation loss: 2.4303489244112404

Epoch: 5| Step: 10
Training loss: 2.434051752090454
Validation loss: 2.4356336926901214

Epoch: 200| Step: 0
Training loss: 2.6741867065429688
Validation loss: 2.433128577406688

Epoch: 5| Step: 1
Training loss: 2.0840630531311035
Validation loss: 2.428885493227231

Epoch: 5| Step: 2
Training loss: 3.0524020195007324
Validation loss: 2.4246526405375493

Epoch: 5| Step: 3
Training loss: 2.932642698287964
Validation loss: 2.4257194354969966

Epoch: 5| Step: 4
Training loss: 2.7101926803588867
Validation loss: 2.4323486845980407

Epoch: 5| Step: 5
Training loss: 3.3710708618164062
Validation loss: 2.427028453478249

Epoch: 5| Step: 6
Training loss: 2.367551326751709
Validation loss: 2.435987969880463

Epoch: 5| Step: 7
Training loss: 2.421537160873413
Validation loss: 2.4245517920422297

Epoch: 5| Step: 8
Training loss: 2.4196617603302
Validation loss: 2.430311702912854

Epoch: 5| Step: 9
Training loss: 2.458505153656006
Validation loss: 2.4279176291599067

Epoch: 5| Step: 10
Training loss: 2.581310510635376
Validation loss: 2.4261437462222193

Epoch: 201| Step: 0
Training loss: 3.0374755859375
Validation loss: 2.4302781679297007

Epoch: 5| Step: 1
Training loss: 1.9477567672729492
Validation loss: 2.4285523942721787

Epoch: 5| Step: 2
Training loss: 3.234381914138794
Validation loss: 2.4243251944100983

Epoch: 5| Step: 3
Training loss: 2.5239129066467285
Validation loss: 2.427445621900661

Epoch: 5| Step: 4
Training loss: 2.648437738418579
Validation loss: 2.4195771909529165

Epoch: 5| Step: 5
Training loss: 2.407355546951294
Validation loss: 2.421531897719188

Epoch: 5| Step: 6
Training loss: 2.4383699893951416
Validation loss: 2.4218401985783733

Epoch: 5| Step: 7
Training loss: 2.774441719055176
Validation loss: 2.4235409100850425

Epoch: 5| Step: 8
Training loss: 2.938107967376709
Validation loss: 2.427091437001382

Epoch: 5| Step: 9
Training loss: 2.591383695602417
Validation loss: 2.435789854295792

Epoch: 5| Step: 10
Training loss: 2.4550364017486572
Validation loss: 2.4297323483292774

Epoch: 202| Step: 0
Training loss: 2.2475175857543945
Validation loss: 2.4235966410688174

Epoch: 5| Step: 1
Training loss: 2.3646247386932373
Validation loss: 2.4219791966099895

Epoch: 5| Step: 2
Training loss: 2.3331551551818848
Validation loss: 2.418827647803932

Epoch: 5| Step: 3
Training loss: 2.678506851196289
Validation loss: 2.4221126853778796

Epoch: 5| Step: 4
Training loss: 2.5793066024780273
Validation loss: 2.419467246660622

Epoch: 5| Step: 5
Training loss: 2.126161813735962
Validation loss: 2.422567972572901

Epoch: 5| Step: 6
Training loss: 3.1747469902038574
Validation loss: 2.422445184441023

Epoch: 5| Step: 7
Training loss: 2.6281867027282715
Validation loss: 2.4287877005915486

Epoch: 5| Step: 8
Training loss: 3.0576138496398926
Validation loss: 2.4226474018507105

Epoch: 5| Step: 9
Training loss: 2.6062934398651123
Validation loss: 2.425225232237129

Epoch: 5| Step: 10
Training loss: 3.3495113849639893
Validation loss: 2.420718349436278

Epoch: 203| Step: 0
Training loss: 2.861380100250244
Validation loss: 2.428285503900179

Epoch: 5| Step: 1
Training loss: 2.6622180938720703
Validation loss: 2.4317444191184094

Epoch: 5| Step: 2
Training loss: 3.549079179763794
Validation loss: 2.431519813435052

Epoch: 5| Step: 3
Training loss: 2.7583844661712646
Validation loss: 2.4422465396183792

Epoch: 5| Step: 4
Training loss: 2.800783634185791
Validation loss: 2.443221563933998

Epoch: 5| Step: 5
Training loss: 1.4090936183929443
Validation loss: 2.4394840655788297

Epoch: 5| Step: 6
Training loss: 2.3048815727233887
Validation loss: 2.4402058278360674

Epoch: 5| Step: 7
Training loss: 2.425477981567383
Validation loss: 2.4247507459373883

Epoch: 5| Step: 8
Training loss: 2.893660068511963
Validation loss: 2.425509983493436

Epoch: 5| Step: 9
Training loss: 3.0976977348327637
Validation loss: 2.4287439853914323

Epoch: 5| Step: 10
Training loss: 2.178992986679077
Validation loss: 2.4196545859818817

Epoch: 204| Step: 0
Training loss: 2.3137924671173096
Validation loss: 2.4194457659157376

Epoch: 5| Step: 1
Training loss: 3.079313278198242
Validation loss: 2.4203979225568872

Epoch: 5| Step: 2
Training loss: 2.640410900115967
Validation loss: 2.419415840538599

Epoch: 5| Step: 3
Training loss: 2.611175060272217
Validation loss: 2.417822358428791

Epoch: 5| Step: 4
Training loss: 2.6293704509735107
Validation loss: 2.415955297408565

Epoch: 5| Step: 5
Training loss: 2.6562302112579346
Validation loss: 2.424117757428077

Epoch: 5| Step: 6
Training loss: 2.2231392860412598
Validation loss: 2.41967559629871

Epoch: 5| Step: 7
Training loss: 2.7174887657165527
Validation loss: 2.4197039245277323

Epoch: 5| Step: 8
Training loss: 2.4049649238586426
Validation loss: 2.4150387215357956

Epoch: 5| Step: 9
Training loss: 2.523494243621826
Validation loss: 2.4181753076532835

Epoch: 5| Step: 10
Training loss: 3.3528027534484863
Validation loss: 2.4207722692079443

Epoch: 205| Step: 0
Training loss: 2.372979164123535
Validation loss: 2.419767782252322

Epoch: 5| Step: 1
Training loss: 2.6515402793884277
Validation loss: 2.432233659170007

Epoch: 5| Step: 2
Training loss: 3.000100612640381
Validation loss: 2.43114818808853

Epoch: 5| Step: 3
Training loss: 3.0295989513397217
Validation loss: 2.448672133107339

Epoch: 5| Step: 4
Training loss: 2.438650608062744
Validation loss: 2.4451457377403014

Epoch: 5| Step: 5
Training loss: 2.7450509071350098
Validation loss: 2.4606005145657446

Epoch: 5| Step: 6
Training loss: 2.6862716674804688
Validation loss: 2.442530790964762

Epoch: 5| Step: 7
Training loss: 2.820937395095825
Validation loss: 2.443519999904017

Epoch: 5| Step: 8
Training loss: 2.5444867610931396
Validation loss: 2.434550880103983

Epoch: 5| Step: 9
Training loss: 2.0879483222961426
Validation loss: 2.431818180186774

Epoch: 5| Step: 10
Training loss: 2.7364158630371094
Validation loss: 2.4262104906061643

Epoch: 206| Step: 0
Training loss: 2.499246120452881
Validation loss: 2.42875865967043

Epoch: 5| Step: 1
Training loss: 2.920668125152588
Validation loss: 2.418372749000467

Epoch: 5| Step: 2
Training loss: 2.9184443950653076
Validation loss: 2.4198380926603913

Epoch: 5| Step: 3
Training loss: 3.146516799926758
Validation loss: 2.420787472878733

Epoch: 5| Step: 4
Training loss: 2.769852638244629
Validation loss: 2.4173545760493123

Epoch: 5| Step: 5
Training loss: 2.9353127479553223
Validation loss: 2.411165006699101

Epoch: 5| Step: 6
Training loss: 2.265779972076416
Validation loss: 2.415298173504491

Epoch: 5| Step: 7
Training loss: 2.7570409774780273
Validation loss: 2.4114584845881306

Epoch: 5| Step: 8
Training loss: 2.2012622356414795
Validation loss: 2.411612549135762

Epoch: 5| Step: 9
Training loss: 2.246445417404175
Validation loss: 2.415966272354126

Epoch: 5| Step: 10
Training loss: 2.3450098037719727
Validation loss: 2.4163067481851064

Epoch: 207| Step: 0
Training loss: 2.3736376762390137
Validation loss: 2.4143187486997215

Epoch: 5| Step: 1
Training loss: 2.825504779815674
Validation loss: 2.413809235377978

Epoch: 5| Step: 2
Training loss: 2.347881555557251
Validation loss: 2.416717883079283

Epoch: 5| Step: 3
Training loss: 2.832448959350586
Validation loss: 2.4216458592363583

Epoch: 5| Step: 4
Training loss: 3.072287082672119
Validation loss: 2.4194724585420344

Epoch: 5| Step: 5
Training loss: 2.8041181564331055
Validation loss: 2.416696071624756

Epoch: 5| Step: 6
Training loss: 2.5784130096435547
Validation loss: 2.4212653329295497

Epoch: 5| Step: 7
Training loss: 2.3613369464874268
Validation loss: 2.4241496798812703

Epoch: 5| Step: 8
Training loss: 2.6094815731048584
Validation loss: 2.4376157188928254

Epoch: 5| Step: 9
Training loss: 3.0980637073516846
Validation loss: 2.4276623546436267

Epoch: 5| Step: 10
Training loss: 1.9861778020858765
Validation loss: 2.434203383743122

Epoch: 208| Step: 0
Training loss: 2.5963025093078613
Validation loss: 2.429818866073444

Epoch: 5| Step: 1
Training loss: 2.481949806213379
Validation loss: 2.4244390943998932

Epoch: 5| Step: 2
Training loss: 2.824410915374756
Validation loss: 2.4207768773519867

Epoch: 5| Step: 3
Training loss: 2.2305908203125
Validation loss: 2.4146422186205463

Epoch: 5| Step: 4
Training loss: 1.9652843475341797
Validation loss: 2.4142323745194303

Epoch: 5| Step: 5
Training loss: 2.640021800994873
Validation loss: 2.4147001927898777

Epoch: 5| Step: 6
Training loss: 2.86793851852417
Validation loss: 2.410410168350384

Epoch: 5| Step: 7
Training loss: 2.6004207134246826
Validation loss: 2.415805180867513

Epoch: 5| Step: 8
Training loss: 3.0882701873779297
Validation loss: 2.4176131115164807

Epoch: 5| Step: 9
Training loss: 3.0367367267608643
Validation loss: 2.4121690437357914

Epoch: 5| Step: 10
Training loss: 2.6096811294555664
Validation loss: 2.414362374172416

Epoch: 209| Step: 0
Training loss: 2.750696897506714
Validation loss: 2.417387831595636

Epoch: 5| Step: 1
Training loss: 2.824206829071045
Validation loss: 2.407573584587343

Epoch: 5| Step: 2
Training loss: 2.8456194400787354
Validation loss: 2.412769056135608

Epoch: 5| Step: 3
Training loss: 2.0555977821350098
Validation loss: 2.407088651452013

Epoch: 5| Step: 4
Training loss: 2.80322003364563
Validation loss: 2.4052400537716445

Epoch: 5| Step: 5
Training loss: 2.381584644317627
Validation loss: 2.406818566783782

Epoch: 5| Step: 6
Training loss: 2.357448101043701
Validation loss: 2.409327765946747

Epoch: 5| Step: 7
Training loss: 2.1621851921081543
Validation loss: 2.4155189068086687

Epoch: 5| Step: 8
Training loss: 3.160048246383667
Validation loss: 2.422781273882876

Epoch: 5| Step: 9
Training loss: 2.777311086654663
Validation loss: 2.4367396908421672

Epoch: 5| Step: 10
Training loss: 2.8680639266967773
Validation loss: 2.4563330194001556

Epoch: 210| Step: 0
Training loss: 2.7247042655944824
Validation loss: 2.453112325360698

Epoch: 5| Step: 1
Training loss: 2.723663091659546
Validation loss: 2.4421533974268104

Epoch: 5| Step: 2
Training loss: 2.383061647415161
Validation loss: 2.457031911419284

Epoch: 5| Step: 3
Training loss: 2.672848701477051
Validation loss: 2.426352539370137

Epoch: 5| Step: 4
Training loss: 2.6532087326049805
Validation loss: 2.412155182130875

Epoch: 5| Step: 5
Training loss: 2.8995604515075684
Validation loss: 2.406196867266009

Epoch: 5| Step: 6
Training loss: 3.185883045196533
Validation loss: 2.4099502691658596

Epoch: 5| Step: 7
Training loss: 2.9174840450286865
Validation loss: 2.410805666318504

Epoch: 5| Step: 8
Training loss: 2.0745434761047363
Validation loss: 2.416770253130185

Epoch: 5| Step: 9
Training loss: 2.599186420440674
Validation loss: 2.4153979362980014

Epoch: 5| Step: 10
Training loss: 2.11803936958313
Validation loss: 2.420357975908505

Epoch: 211| Step: 0
Training loss: 2.527618885040283
Validation loss: 2.4221810910009567

Epoch: 5| Step: 1
Training loss: 2.59845232963562
Validation loss: 2.4210243994189846

Epoch: 5| Step: 2
Training loss: 2.795727252960205
Validation loss: 2.4181437851280294

Epoch: 5| Step: 3
Training loss: 2.619764804840088
Validation loss: 2.4155128386712845

Epoch: 5| Step: 4
Training loss: 2.3221020698547363
Validation loss: 2.414161028400544

Epoch: 5| Step: 5
Training loss: 2.852586269378662
Validation loss: 2.4267169224318637

Epoch: 5| Step: 6
Training loss: 2.477949857711792
Validation loss: 2.4260608637204735

Epoch: 5| Step: 7
Training loss: 2.685666084289551
Validation loss: 2.4304421191574423

Epoch: 5| Step: 8
Training loss: 3.262434482574463
Validation loss: 2.43888613998249

Epoch: 5| Step: 9
Training loss: 2.1328728199005127
Validation loss: 2.4387144452782086

Epoch: 5| Step: 10
Training loss: 2.7308261394500732
Validation loss: 2.4385652875387542

Epoch: 212| Step: 0
Training loss: 2.259138584136963
Validation loss: 2.432690276894518

Epoch: 5| Step: 1
Training loss: 3.396047592163086
Validation loss: 2.4226448253918718

Epoch: 5| Step: 2
Training loss: 3.5413360595703125
Validation loss: 2.421613823982977

Epoch: 5| Step: 3
Training loss: 2.8112199306488037
Validation loss: 2.4143821090780277

Epoch: 5| Step: 4
Training loss: 2.3368492126464844
Validation loss: 2.4140389657789663

Epoch: 5| Step: 5
Training loss: 2.1339399814605713
Validation loss: 2.4117557489743797

Epoch: 5| Step: 6
Training loss: 2.067047119140625
Validation loss: 2.415736811135405

Epoch: 5| Step: 7
Training loss: 2.86098313331604
Validation loss: 2.4042227268218994

Epoch: 5| Step: 8
Training loss: 2.8278205394744873
Validation loss: 2.4144318539609193

Epoch: 5| Step: 9
Training loss: 2.1859116554260254
Validation loss: 2.4081155561631724

Epoch: 5| Step: 10
Training loss: 2.5372273921966553
Validation loss: 2.406496940120574

Epoch: 213| Step: 0
Training loss: 2.9560341835021973
Validation loss: 2.4052132227087535

Epoch: 5| Step: 1
Training loss: 3.1783039569854736
Validation loss: 2.4078221500560804

Epoch: 5| Step: 2
Training loss: 2.2044243812561035
Validation loss: 2.4054342110951743

Epoch: 5| Step: 3
Training loss: 2.5268020629882812
Validation loss: 2.4023667099655315

Epoch: 5| Step: 4
Training loss: 2.5586063861846924
Validation loss: 2.402682104418355

Epoch: 5| Step: 5
Training loss: 2.781520366668701
Validation loss: 2.401350459744853

Epoch: 5| Step: 6
Training loss: 2.958092451095581
Validation loss: 2.4024224806857366

Epoch: 5| Step: 7
Training loss: 2.984002113342285
Validation loss: 2.408880595237978

Epoch: 5| Step: 8
Training loss: 2.467867612838745
Validation loss: 2.4096079898136917

Epoch: 5| Step: 9
Training loss: 2.0921356678009033
Validation loss: 2.4081064065297446

Epoch: 5| Step: 10
Training loss: 2.1494734287261963
Validation loss: 2.406064159126692

Epoch: 214| Step: 0
Training loss: 2.6613967418670654
Validation loss: 2.4096933539195726

Epoch: 5| Step: 1
Training loss: 2.51108717918396
Validation loss: 2.402525609539401

Epoch: 5| Step: 2
Training loss: 1.97906494140625
Validation loss: 2.404275345545943

Epoch: 5| Step: 3
Training loss: 2.77344012260437
Validation loss: 2.4062722729098414

Epoch: 5| Step: 4
Training loss: 2.6555709838867188
Validation loss: 2.4042059016484085

Epoch: 5| Step: 5
Training loss: 3.2088236808776855
Validation loss: 2.40240139602333

Epoch: 5| Step: 6
Training loss: 2.868156671524048
Validation loss: 2.4091573197354554

Epoch: 5| Step: 7
Training loss: 2.686081886291504
Validation loss: 2.4029645919799805

Epoch: 5| Step: 8
Training loss: 2.6541671752929688
Validation loss: 2.4065484257154566

Epoch: 5| Step: 9
Training loss: 2.8862788677215576
Validation loss: 2.4066095121445192

Epoch: 5| Step: 10
Training loss: 1.9191726446151733
Validation loss: 2.4097248918266705

Epoch: 215| Step: 0
Training loss: 2.7892355918884277
Validation loss: 2.420052084871518

Epoch: 5| Step: 1
Training loss: 2.9995479583740234
Validation loss: 2.42107577477732

Epoch: 5| Step: 2
Training loss: 2.569195508956909
Validation loss: 2.4127976996924287

Epoch: 5| Step: 3
Training loss: 2.5588202476501465
Validation loss: 2.4111487198901433

Epoch: 5| Step: 4
Training loss: 2.3799796104431152
Validation loss: 2.4064285473157

Epoch: 5| Step: 5
Training loss: 2.53851056098938
Validation loss: 2.4051198600440897

Epoch: 5| Step: 6
Training loss: 1.9558429718017578
Validation loss: 2.4021892316879763

Epoch: 5| Step: 7
Training loss: 2.842278003692627
Validation loss: 2.4067189590905302

Epoch: 5| Step: 8
Training loss: 2.9261391162872314
Validation loss: 2.4115440332761375

Epoch: 5| Step: 9
Training loss: 2.5879170894622803
Validation loss: 2.401354717951949

Epoch: 5| Step: 10
Training loss: 2.84515380859375
Validation loss: 2.4041707772080616

Epoch: 216| Step: 0
Training loss: 2.037393808364868
Validation loss: 2.4069966116259174

Epoch: 5| Step: 1
Training loss: 3.258009433746338
Validation loss: 2.4007204014767884

Epoch: 5| Step: 2
Training loss: 2.681382417678833
Validation loss: 2.4020365553517498

Epoch: 5| Step: 3
Training loss: 2.457388162612915
Validation loss: 2.4177923151241836

Epoch: 5| Step: 4
Training loss: 2.7181429862976074
Validation loss: 2.4163176526305494

Epoch: 5| Step: 5
Training loss: 3.2810070514678955
Validation loss: 2.422162558442803

Epoch: 5| Step: 6
Training loss: 2.4942874908447266
Validation loss: 2.4125765267238823

Epoch: 5| Step: 7
Training loss: 2.162257671356201
Validation loss: 2.4040646860676427

Epoch: 5| Step: 8
Training loss: 2.735661268234253
Validation loss: 2.408227523167928

Epoch: 5| Step: 9
Training loss: 2.384819746017456
Validation loss: 2.3973744659013647

Epoch: 5| Step: 10
Training loss: 2.7053446769714355
Validation loss: 2.398826519648234

Epoch: 217| Step: 0
Training loss: 3.0424296855926514
Validation loss: 2.404471702473138

Epoch: 5| Step: 1
Training loss: 2.449573040008545
Validation loss: 2.4054547740567114

Epoch: 5| Step: 2
Training loss: 2.6035103797912598
Validation loss: 2.3983694968685025

Epoch: 5| Step: 3
Training loss: 2.319298505783081
Validation loss: 2.4000511092524373

Epoch: 5| Step: 4
Training loss: 2.468219041824341
Validation loss: 2.4055896010450137

Epoch: 5| Step: 5
Training loss: 3.1433892250061035
Validation loss: 2.405459657792122

Epoch: 5| Step: 6
Training loss: 2.962764263153076
Validation loss: 2.4024771541677494

Epoch: 5| Step: 7
Training loss: 2.376993179321289
Validation loss: 2.4006515215801936

Epoch: 5| Step: 8
Training loss: 2.1766982078552246
Validation loss: 2.403450483916908

Epoch: 5| Step: 9
Training loss: 2.8115944862365723
Validation loss: 2.3982774314060005

Epoch: 5| Step: 10
Training loss: 2.458469867706299
Validation loss: 2.404198761909239

Epoch: 218| Step: 0
Training loss: 2.8206634521484375
Validation loss: 2.3981777468035297

Epoch: 5| Step: 1
Training loss: 2.933833360671997
Validation loss: 2.406906630403252

Epoch: 5| Step: 2
Training loss: 2.51123309135437
Validation loss: 2.406649507502074

Epoch: 5| Step: 3
Training loss: 2.6665070056915283
Validation loss: 2.4142037283989692

Epoch: 5| Step: 4
Training loss: 2.6110901832580566
Validation loss: 2.4061590343393306

Epoch: 5| Step: 5
Training loss: 2.736854076385498
Validation loss: 2.4101183158095165

Epoch: 5| Step: 6
Training loss: 2.5280044078826904
Validation loss: 2.414600195423249

Epoch: 5| Step: 7
Training loss: 2.8932042121887207
Validation loss: 2.407279142769434

Epoch: 5| Step: 8
Training loss: 2.8840789794921875
Validation loss: 2.4037430183861845

Epoch: 5| Step: 9
Training loss: 2.2550244331359863
Validation loss: 2.408060899344824

Epoch: 5| Step: 10
Training loss: 1.9328539371490479
Validation loss: 2.402702869907502

Epoch: 219| Step: 0
Training loss: 2.5666921138763428
Validation loss: 2.4021884446503012

Epoch: 5| Step: 1
Training loss: 2.2511842250823975
Validation loss: 2.404227446484309

Epoch: 5| Step: 2
Training loss: 2.370330333709717
Validation loss: 2.3987178161580074

Epoch: 5| Step: 3
Training loss: 2.337170362472534
Validation loss: 2.399448066629389

Epoch: 5| Step: 4
Training loss: 3.199014186859131
Validation loss: 2.3987069437580724

Epoch: 5| Step: 5
Training loss: 3.0238876342773438
Validation loss: 2.393102128018615

Epoch: 5| Step: 6
Training loss: 2.6009232997894287
Validation loss: 2.407197292133044

Epoch: 5| Step: 7
Training loss: 2.525794267654419
Validation loss: 2.4077736203388502

Epoch: 5| Step: 8
Training loss: 2.7382829189300537
Validation loss: 2.4110310487849738

Epoch: 5| Step: 9
Training loss: 2.615023374557495
Validation loss: 2.409685472006439

Epoch: 5| Step: 10
Training loss: 2.583150625228882
Validation loss: 2.41001191190494

Epoch: 220| Step: 0
Training loss: 2.7838845252990723
Validation loss: 2.4103586109735633

Epoch: 5| Step: 1
Training loss: 3.0213165283203125
Validation loss: 2.394280877164615

Epoch: 5| Step: 2
Training loss: 2.547213077545166
Validation loss: 2.4024863781467563

Epoch: 5| Step: 3
Training loss: 2.625230312347412
Validation loss: 2.3932100931803384

Epoch: 5| Step: 4
Training loss: 2.697613000869751
Validation loss: 2.395245570008473

Epoch: 5| Step: 5
Training loss: 2.3839945793151855
Validation loss: 2.393375386473953

Epoch: 5| Step: 6
Training loss: 2.155308485031128
Validation loss: 2.394221213556105

Epoch: 5| Step: 7
Training loss: 2.978738307952881
Validation loss: 2.3940617653631393

Epoch: 5| Step: 8
Training loss: 2.4646172523498535
Validation loss: 2.3959089120229087

Epoch: 5| Step: 9
Training loss: 2.8421552181243896
Validation loss: 2.4099862088439283

Epoch: 5| Step: 10
Training loss: 2.2822399139404297
Validation loss: 2.3974765962170017

Epoch: 221| Step: 0
Training loss: 3.060669183731079
Validation loss: 2.397274596716768

Epoch: 5| Step: 1
Training loss: 2.820249080657959
Validation loss: 2.39957764328167

Epoch: 5| Step: 2
Training loss: 2.769747257232666
Validation loss: 2.4034646557223414

Epoch: 5| Step: 3
Training loss: 2.588514566421509
Validation loss: 2.3990622963956607

Epoch: 5| Step: 4
Training loss: 2.490908145904541
Validation loss: 2.4027784716698433

Epoch: 5| Step: 5
Training loss: 2.7081680297851562
Validation loss: 2.4027830605865805

Epoch: 5| Step: 6
Training loss: 2.4484825134277344
Validation loss: 2.3948152193459133

Epoch: 5| Step: 7
Training loss: 2.2411484718322754
Validation loss: 2.3947364643055904

Epoch: 5| Step: 8
Training loss: 2.1033685207366943
Validation loss: 2.395531474903066

Epoch: 5| Step: 9
Training loss: 2.7229483127593994
Validation loss: 2.397692588067824

Epoch: 5| Step: 10
Training loss: 2.8555901050567627
Validation loss: 2.3955021186541487

Epoch: 222| Step: 0
Training loss: 2.097536087036133
Validation loss: 2.3994805633380847

Epoch: 5| Step: 1
Training loss: 2.745551347732544
Validation loss: 2.3994317772567912

Epoch: 5| Step: 2
Training loss: 2.549553155899048
Validation loss: 2.392846930411554

Epoch: 5| Step: 3
Training loss: 2.7165794372558594
Validation loss: 2.3941418970784833

Epoch: 5| Step: 4
Training loss: 2.6829867362976074
Validation loss: 2.398074339794856

Epoch: 5| Step: 5
Training loss: 2.4451136589050293
Validation loss: 2.39259002541983

Epoch: 5| Step: 6
Training loss: 3.117438554763794
Validation loss: 2.395568355437248

Epoch: 5| Step: 7
Training loss: 2.5363075733184814
Validation loss: 2.394199830229564

Epoch: 5| Step: 8
Training loss: 2.9443519115448
Validation loss: 2.392358908089258

Epoch: 5| Step: 9
Training loss: 2.170708179473877
Validation loss: 2.405559757704376

Epoch: 5| Step: 10
Training loss: 2.824425458908081
Validation loss: 2.405554474041026

Epoch: 223| Step: 0
Training loss: 2.722916603088379
Validation loss: 2.4134301908554567

Epoch: 5| Step: 1
Training loss: 2.8068058490753174
Validation loss: 2.41216097083143

Epoch: 5| Step: 2
Training loss: 2.376237392425537
Validation loss: 2.406875184787217

Epoch: 5| Step: 3
Training loss: 2.4483346939086914
Validation loss: 2.4043161125593286

Epoch: 5| Step: 4
Training loss: 2.7853474617004395
Validation loss: 2.408919257502402

Epoch: 5| Step: 5
Training loss: 2.9567909240722656
Validation loss: 2.401071604862008

Epoch: 5| Step: 6
Training loss: 1.9594945907592773
Validation loss: 2.406038484265727

Epoch: 5| Step: 7
Training loss: 2.9319040775299072
Validation loss: 2.416616601328696

Epoch: 5| Step: 8
Training loss: 2.4641895294189453
Validation loss: 2.40421433858974

Epoch: 5| Step: 9
Training loss: 2.383356809616089
Validation loss: 2.399173749390469

Epoch: 5| Step: 10
Training loss: 3.068390130996704
Validation loss: 2.3988076435622347

Epoch: 224| Step: 0
Training loss: 2.0630342960357666
Validation loss: 2.389601033221009

Epoch: 5| Step: 1
Training loss: 2.457287311553955
Validation loss: 2.3983724091642644

Epoch: 5| Step: 2
Training loss: 2.062643051147461
Validation loss: 2.3934079190736175

Epoch: 5| Step: 3
Training loss: 2.9197239875793457
Validation loss: 2.392841908239549

Epoch: 5| Step: 4
Training loss: 2.5210278034210205
Validation loss: 2.393865150790061

Epoch: 5| Step: 5
Training loss: 2.87298846244812
Validation loss: 2.3918479655378606

Epoch: 5| Step: 6
Training loss: 2.5089271068573
Validation loss: 2.3949097612852692

Epoch: 5| Step: 7
Training loss: 2.831364393234253
Validation loss: 2.3975907243708128

Epoch: 5| Step: 8
Training loss: 3.1886837482452393
Validation loss: 2.3983110432983725

Epoch: 5| Step: 9
Training loss: 2.642220973968506
Validation loss: 2.401301578808856

Epoch: 5| Step: 10
Training loss: 2.7989683151245117
Validation loss: 2.389753395511258

Epoch: 225| Step: 0
Training loss: 2.254981279373169
Validation loss: 2.3896828543755317

Epoch: 5| Step: 1
Training loss: 2.6101717948913574
Validation loss: 2.385671384872929

Epoch: 5| Step: 2
Training loss: 2.4555511474609375
Validation loss: 2.3868892551750265

Epoch: 5| Step: 3
Training loss: 2.8416030406951904
Validation loss: 2.387437028269614

Epoch: 5| Step: 4
Training loss: 2.444075107574463
Validation loss: 2.3791702857581516

Epoch: 5| Step: 5
Training loss: 3.207780361175537
Validation loss: 2.385293483734131

Epoch: 5| Step: 6
Training loss: 2.5838558673858643
Validation loss: 2.3772622334059847

Epoch: 5| Step: 7
Training loss: 3.162818431854248
Validation loss: 2.379093800821612

Epoch: 5| Step: 8
Training loss: 3.0673346519470215
Validation loss: 2.3772768230848413

Epoch: 5| Step: 9
Training loss: 2.292607307434082
Validation loss: 2.382981600299958

Epoch: 5| Step: 10
Training loss: 1.7150601148605347
Validation loss: 2.379920223707794

Epoch: 226| Step: 0
Training loss: 2.846512794494629
Validation loss: 2.382992195826705

Epoch: 5| Step: 1
Training loss: 2.376669406890869
Validation loss: 2.387498970954649

Epoch: 5| Step: 2
Training loss: 2.541726589202881
Validation loss: 2.4001255137946016

Epoch: 5| Step: 3
Training loss: 2.3290772438049316
Validation loss: 2.3976937006878596

Epoch: 5| Step: 4
Training loss: 2.9188849925994873
Validation loss: 2.41572126009131

Epoch: 5| Step: 5
Training loss: 2.4352543354034424
Validation loss: 2.4084891042401715

Epoch: 5| Step: 6
Training loss: 2.774733304977417
Validation loss: 2.4039706594200543

Epoch: 5| Step: 7
Training loss: 2.596254825592041
Validation loss: 2.4116922655413227

Epoch: 5| Step: 8
Training loss: 3.415295362472534
Validation loss: 2.4109504043415027

Epoch: 5| Step: 9
Training loss: 2.006895065307617
Validation loss: 2.410669990765151

Epoch: 5| Step: 10
Training loss: 2.6015446186065674
Validation loss: 2.4144132624390306

Epoch: 227| Step: 0
Training loss: 1.9914772510528564
Validation loss: 2.409925604379305

Epoch: 5| Step: 1
Training loss: 2.6752066612243652
Validation loss: 2.3883343024920394

Epoch: 5| Step: 2
Training loss: 2.769260883331299
Validation loss: 2.3845075458608647

Epoch: 5| Step: 3
Training loss: 2.648819923400879
Validation loss: 2.3950327724538822

Epoch: 5| Step: 4
Training loss: 2.7288172245025635
Validation loss: 2.401139877175772

Epoch: 5| Step: 5
Training loss: 2.3913652896881104
Validation loss: 2.399493989124093

Epoch: 5| Step: 6
Training loss: 2.468679904937744
Validation loss: 2.4009325965758292

Epoch: 5| Step: 7
Training loss: 2.9258604049682617
Validation loss: 2.3989347719377085

Epoch: 5| Step: 8
Training loss: 2.4342923164367676
Validation loss: 2.3895994335092525

Epoch: 5| Step: 9
Training loss: 2.808192014694214
Validation loss: 2.3849713674155613

Epoch: 5| Step: 10
Training loss: 2.934054374694824
Validation loss: 2.3863177504590762

Epoch: 228| Step: 0
Training loss: 2.8360772132873535
Validation loss: 2.383474757594447

Epoch: 5| Step: 1
Training loss: 2.621443271636963
Validation loss: 2.386017676322691

Epoch: 5| Step: 2
Training loss: 2.409350633621216
Validation loss: 2.380104123905141

Epoch: 5| Step: 3
Training loss: 2.374011516571045
Validation loss: 2.3868929006720103

Epoch: 5| Step: 4
Training loss: 2.2438063621520996
Validation loss: 2.3876716513787546

Epoch: 5| Step: 5
Training loss: 2.7582225799560547
Validation loss: 2.3856275953272337

Epoch: 5| Step: 6
Training loss: 2.924699544906616
Validation loss: 2.3899126411766134

Epoch: 5| Step: 7
Training loss: 3.052199602127075
Validation loss: 2.384103593005929

Epoch: 5| Step: 8
Training loss: 2.267725944519043
Validation loss: 2.3849021106637935

Epoch: 5| Step: 9
Training loss: 2.3453118801116943
Validation loss: 2.383258581161499

Epoch: 5| Step: 10
Training loss: 2.9631824493408203
Validation loss: 2.386242380706213

Epoch: 229| Step: 0
Training loss: 2.1700193881988525
Validation loss: 2.3809757309575237

Epoch: 5| Step: 1
Training loss: 2.4033050537109375
Validation loss: 2.3802278298203663

Epoch: 5| Step: 2
Training loss: 2.546337604522705
Validation loss: 2.3926471535877516

Epoch: 5| Step: 3
Training loss: 3.0594351291656494
Validation loss: 2.391861269550939

Epoch: 5| Step: 4
Training loss: 2.6725127696990967
Validation loss: 2.3919154059502388

Epoch: 5| Step: 5
Training loss: 2.860555648803711
Validation loss: 2.394943719269127

Epoch: 5| Step: 6
Training loss: 2.442030191421509
Validation loss: 2.39124309632086

Epoch: 5| Step: 7
Training loss: 2.3036417961120605
Validation loss: 2.3871602294265584

Epoch: 5| Step: 8
Training loss: 2.8697397708892822
Validation loss: 2.3860386238303235

Epoch: 5| Step: 9
Training loss: 2.9167308807373047
Validation loss: 2.3839667484324467

Epoch: 5| Step: 10
Training loss: 2.4404704570770264
Validation loss: 2.3737012083812425

Epoch: 230| Step: 0
Training loss: 2.5201191902160645
Validation loss: 2.384920063839164

Epoch: 5| Step: 1
Training loss: 2.4460701942443848
Validation loss: 2.386182818361508

Epoch: 5| Step: 2
Training loss: 2.533709764480591
Validation loss: 2.3819537265326387

Epoch: 5| Step: 3
Training loss: 2.558008909225464
Validation loss: 2.3797114279962357

Epoch: 5| Step: 4
Training loss: 2.7757575511932373
Validation loss: 2.381479024887085

Epoch: 5| Step: 5
Training loss: 3.1909091472625732
Validation loss: 2.3813585004498883

Epoch: 5| Step: 6
Training loss: 2.309811592102051
Validation loss: 2.3833235604788667

Epoch: 5| Step: 7
Training loss: 2.494006633758545
Validation loss: 2.381079089257025

Epoch: 5| Step: 8
Training loss: 2.444591999053955
Validation loss: 2.3786557066825127

Epoch: 5| Step: 9
Training loss: 2.5275585651397705
Validation loss: 2.381554936849943

Epoch: 5| Step: 10
Training loss: 2.9679996967315674
Validation loss: 2.3846233173083236

Epoch: 231| Step: 0
Training loss: 2.650442123413086
Validation loss: 2.3754641163733696

Epoch: 5| Step: 1
Training loss: 2.721872329711914
Validation loss: 2.3872041561270274

Epoch: 5| Step: 2
Training loss: 3.005046844482422
Validation loss: 2.390529255713186

Epoch: 5| Step: 3
Training loss: 2.754340410232544
Validation loss: 2.3880852524952223

Epoch: 5| Step: 4
Training loss: 2.852421998977661
Validation loss: 2.397184479621149

Epoch: 5| Step: 5
Training loss: 2.977107286453247
Validation loss: 2.3867371671943256

Epoch: 5| Step: 6
Training loss: 2.4399375915527344
Validation loss: 2.3832435351546093

Epoch: 5| Step: 7
Training loss: 2.3343417644500732
Validation loss: 2.3749366293671312

Epoch: 5| Step: 8
Training loss: 2.1391968727111816
Validation loss: 2.3742437388307307

Epoch: 5| Step: 9
Training loss: 2.161439895629883
Validation loss: 2.368519344637471

Epoch: 5| Step: 10
Training loss: 2.672243595123291
Validation loss: 2.371941856158677

Epoch: 232| Step: 0
Training loss: 2.831522226333618
Validation loss: 2.3724586322743404

Epoch: 5| Step: 1
Training loss: 3.1121227741241455
Validation loss: 2.379217593900619

Epoch: 5| Step: 2
Training loss: 2.435141086578369
Validation loss: 2.387991782157652

Epoch: 5| Step: 3
Training loss: 2.717980146408081
Validation loss: 2.386096026307793

Epoch: 5| Step: 4
Training loss: 2.5206072330474854
Validation loss: 2.392775691965575

Epoch: 5| Step: 5
Training loss: 3.013256788253784
Validation loss: 2.396287679672241

Epoch: 5| Step: 6
Training loss: 2.6559581756591797
Validation loss: 2.3901382620616625

Epoch: 5| Step: 7
Training loss: 2.1355230808258057
Validation loss: 2.395204537658281

Epoch: 5| Step: 8
Training loss: 2.5493597984313965
Validation loss: 2.391497060816775

Epoch: 5| Step: 9
Training loss: 2.3350512981414795
Validation loss: 2.387699257942938

Epoch: 5| Step: 10
Training loss: 2.252769947052002
Validation loss: 2.3820335275383404

Epoch: 233| Step: 0
Training loss: 1.9771541357040405
Validation loss: 2.376034334141721

Epoch: 5| Step: 1
Training loss: 3.4646377563476562
Validation loss: 2.37817443314419

Epoch: 5| Step: 2
Training loss: 3.5612189769744873
Validation loss: 2.3788041478844097

Epoch: 5| Step: 3
Training loss: 2.858818531036377
Validation loss: 2.3778940528951664

Epoch: 5| Step: 4
Training loss: 2.72934889793396
Validation loss: 2.374297111265121

Epoch: 5| Step: 5
Training loss: 2.165701389312744
Validation loss: 2.383672486069382

Epoch: 5| Step: 6
Training loss: 2.075645923614502
Validation loss: 2.377263012752738

Epoch: 5| Step: 7
Training loss: 2.0980992317199707
Validation loss: 2.3747102240080475

Epoch: 5| Step: 8
Training loss: 2.864987850189209
Validation loss: 2.378787886711859

Epoch: 5| Step: 9
Training loss: 2.4954159259796143
Validation loss: 2.378723300913329

Epoch: 5| Step: 10
Training loss: 2.420616865158081
Validation loss: 2.383783999309745

Epoch: 234| Step: 0
Training loss: 2.5067131519317627
Validation loss: 2.3769682427888275

Epoch: 5| Step: 1
Training loss: 3.2222037315368652
Validation loss: 2.381376028060913

Epoch: 5| Step: 2
Training loss: 2.8009860515594482
Validation loss: 2.3811086275244273

Epoch: 5| Step: 3
Training loss: 2.6849753856658936
Validation loss: 2.3768652844172653

Epoch: 5| Step: 4
Training loss: 2.388751983642578
Validation loss: 2.3744556032201296

Epoch: 5| Step: 5
Training loss: 2.0758745670318604
Validation loss: 2.3788218985321703

Epoch: 5| Step: 6
Training loss: 2.5268943309783936
Validation loss: 2.383006534268779

Epoch: 5| Step: 7
Training loss: 3.0462231636047363
Validation loss: 2.380377697688277

Epoch: 5| Step: 8
Training loss: 2.8440825939178467
Validation loss: 2.396695616424725

Epoch: 5| Step: 9
Training loss: 2.237501859664917
Validation loss: 2.384266298304322

Epoch: 5| Step: 10
Training loss: 2.244380235671997
Validation loss: 2.3939598016841437

Epoch: 235| Step: 0
Training loss: 3.458914279937744
Validation loss: 2.3896353808782433

Epoch: 5| Step: 1
Training loss: 1.9806983470916748
Validation loss: 2.401887293784849

Epoch: 5| Step: 2
Training loss: 1.8156019449234009
Validation loss: 2.3961514836998394

Epoch: 5| Step: 3
Training loss: 2.8404319286346436
Validation loss: 2.3986904416033017

Epoch: 5| Step: 4
Training loss: 2.8400325775146484
Validation loss: 2.3943219723240023

Epoch: 5| Step: 5
Training loss: 2.7672770023345947
Validation loss: 2.38128040939249

Epoch: 5| Step: 6
Training loss: 2.0971932411193848
Validation loss: 2.3762108433631157

Epoch: 5| Step: 7
Training loss: 2.637843608856201
Validation loss: 2.378779585643481

Epoch: 5| Step: 8
Training loss: 2.4579436779022217
Validation loss: 2.377289407996721

Epoch: 5| Step: 9
Training loss: 2.608412504196167
Validation loss: 2.3793221904385473

Epoch: 5| Step: 10
Training loss: 3.2745957374572754
Validation loss: 2.3739458848071355

Epoch: 236| Step: 0
Training loss: 2.4522032737731934
Validation loss: 2.3763351440429688

Epoch: 5| Step: 1
Training loss: 2.082235813140869
Validation loss: 2.3682041655304613

Epoch: 5| Step: 2
Training loss: 2.0607497692108154
Validation loss: 2.3730234766519196

Epoch: 5| Step: 3
Training loss: 2.5823464393615723
Validation loss: 2.370685331283077

Epoch: 5| Step: 4
Training loss: 2.7334532737731934
Validation loss: 2.377795773167764

Epoch: 5| Step: 5
Training loss: 2.8525962829589844
Validation loss: 2.3884743054707847

Epoch: 5| Step: 6
Training loss: 2.7901740074157715
Validation loss: 2.3915096482922955

Epoch: 5| Step: 7
Training loss: 2.4667601585388184
Validation loss: 2.3889670243827243

Epoch: 5| Step: 8
Training loss: 2.7515318393707275
Validation loss: 2.390149618989678

Epoch: 5| Step: 9
Training loss: 3.2559685707092285
Validation loss: 2.3890377988097486

Epoch: 5| Step: 10
Training loss: 2.6486754417419434
Validation loss: 2.3778060328575874

Epoch: 237| Step: 0
Training loss: 2.5420501232147217
Validation loss: 2.375905821400304

Epoch: 5| Step: 1
Training loss: 3.026700496673584
Validation loss: 2.378195798525246

Epoch: 5| Step: 2
Training loss: 2.300133466720581
Validation loss: 2.3808926664372927

Epoch: 5| Step: 3
Training loss: 2.410064220428467
Validation loss: 2.395494435423164

Epoch: 5| Step: 4
Training loss: 2.8710999488830566
Validation loss: 2.396104721612828

Epoch: 5| Step: 5
Training loss: 3.0700318813323975
Validation loss: 2.384533230976392

Epoch: 5| Step: 6
Training loss: 2.4363815784454346
Validation loss: 2.381064861051498

Epoch: 5| Step: 7
Training loss: 2.124424457550049
Validation loss: 2.381491950763169

Epoch: 5| Step: 8
Training loss: 2.6040451526641846
Validation loss: 2.3769551605306645

Epoch: 5| Step: 9
Training loss: 2.2866756916046143
Validation loss: 2.3807619951104604

Epoch: 5| Step: 10
Training loss: 3.1336164474487305
Validation loss: 2.37751660039348

Epoch: 238| Step: 0
Training loss: 2.2370643615722656
Validation loss: 2.378755179784631

Epoch: 5| Step: 1
Training loss: 2.522480010986328
Validation loss: 2.374944994526525

Epoch: 5| Step: 2
Training loss: 2.902513265609741
Validation loss: 2.381273546526509

Epoch: 5| Step: 3
Training loss: 3.0342249870300293
Validation loss: 2.3741149633161482

Epoch: 5| Step: 4
Training loss: 2.995488405227661
Validation loss: 2.380357712827703

Epoch: 5| Step: 5
Training loss: 2.398895740509033
Validation loss: 2.38222175259744

Epoch: 5| Step: 6
Training loss: 2.7092652320861816
Validation loss: 2.3845928484393704

Epoch: 5| Step: 7
Training loss: 2.2526135444641113
Validation loss: 2.383693530995359

Epoch: 5| Step: 8
Training loss: 2.344749689102173
Validation loss: 2.3772940404953493

Epoch: 5| Step: 9
Training loss: 2.3105721473693848
Validation loss: 2.3819502143449682

Epoch: 5| Step: 10
Training loss: 3.035714864730835
Validation loss: 2.3714186376140964

Epoch: 239| Step: 0
Training loss: 3.76800799369812
Validation loss: 2.376872903557234

Epoch: 5| Step: 1
Training loss: 2.508049726486206
Validation loss: 2.369030152597735

Epoch: 5| Step: 2
Training loss: 2.221464157104492
Validation loss: 2.3735937815840527

Epoch: 5| Step: 3
Training loss: 2.553337574005127
Validation loss: 2.3648539307296916

Epoch: 5| Step: 4
Training loss: 2.4472928047180176
Validation loss: 2.3641143434791156

Epoch: 5| Step: 5
Training loss: 3.060811996459961
Validation loss: 2.3667306746205976

Epoch: 5| Step: 6
Training loss: 2.537431240081787
Validation loss: 2.36997631801072

Epoch: 5| Step: 7
Training loss: 2.823517084121704
Validation loss: 2.3616796257675334

Epoch: 5| Step: 8
Training loss: 2.1962573528289795
Validation loss: 2.366949286512149

Epoch: 5| Step: 9
Training loss: 1.8545717000961304
Validation loss: 2.366260761855751

Epoch: 5| Step: 10
Training loss: 2.6748123168945312
Validation loss: 2.362819166593654

Epoch: 240| Step: 0
Training loss: 2.149244785308838
Validation loss: 2.36721731001331

Epoch: 5| Step: 1
Training loss: 2.3363118171691895
Validation loss: 2.3639086472090853

Epoch: 5| Step: 2
Training loss: 2.270460844039917
Validation loss: 2.3739611282143542

Epoch: 5| Step: 3
Training loss: 2.9976487159729004
Validation loss: 2.386532393834924

Epoch: 5| Step: 4
Training loss: 2.403721809387207
Validation loss: 2.3856104907169136

Epoch: 5| Step: 5
Training loss: 2.7833149433135986
Validation loss: 2.3869919264188377

Epoch: 5| Step: 6
Training loss: 2.379727363586426
Validation loss: 2.3843652279146257

Epoch: 5| Step: 7
Training loss: 3.0097978115081787
Validation loss: 2.377784288057717

Epoch: 5| Step: 8
Training loss: 2.3251872062683105
Validation loss: 2.3687686151073826

Epoch: 5| Step: 9
Training loss: 2.796874523162842
Validation loss: 2.3676628015374623

Epoch: 5| Step: 10
Training loss: 3.2982606887817383
Validation loss: 2.359003766890495

Epoch: 241| Step: 0
Training loss: 2.283489227294922
Validation loss: 2.35646580624324

Epoch: 5| Step: 1
Training loss: 3.0812582969665527
Validation loss: 2.362762212753296

Epoch: 5| Step: 2
Training loss: 2.6987853050231934
Validation loss: 2.3628302517757622

Epoch: 5| Step: 3
Training loss: 2.5233943462371826
Validation loss: 2.3668090271693405

Epoch: 5| Step: 4
Training loss: 2.1762616634368896
Validation loss: 2.36602759104903

Epoch: 5| Step: 5
Training loss: 2.6617889404296875
Validation loss: 2.368010546571465

Epoch: 5| Step: 6
Training loss: 2.722372055053711
Validation loss: 2.3671067196835756

Epoch: 5| Step: 7
Training loss: 2.4098098278045654
Validation loss: 2.371076491571242

Epoch: 5| Step: 8
Training loss: 2.4352035522460938
Validation loss: 2.3609547127959547

Epoch: 5| Step: 9
Training loss: 2.767443895339966
Validation loss: 2.367522524249169

Epoch: 5| Step: 10
Training loss: 2.8770508766174316
Validation loss: 2.3639664239780878

Epoch: 242| Step: 0
Training loss: 2.5403082370758057
Validation loss: 2.370545769250521

Epoch: 5| Step: 1
Training loss: 3.321448564529419
Validation loss: 2.357912399435556

Epoch: 5| Step: 2
Training loss: 2.8477509021759033
Validation loss: 2.361811573787402

Epoch: 5| Step: 3
Training loss: 2.3572442531585693
Validation loss: 2.3642446789690243

Epoch: 5| Step: 4
Training loss: 2.5702061653137207
Validation loss: 2.361629045137795

Epoch: 5| Step: 5
Training loss: 2.4680700302124023
Validation loss: 2.3605313275450017

Epoch: 5| Step: 6
Training loss: 3.205963134765625
Validation loss: 2.358387621500159

Epoch: 5| Step: 7
Training loss: 2.2420482635498047
Validation loss: 2.367250132304366

Epoch: 5| Step: 8
Training loss: 3.002822160720825
Validation loss: 2.3627049948579524

Epoch: 5| Step: 9
Training loss: 2.1935641765594482
Validation loss: 2.3654579424089

Epoch: 5| Step: 10
Training loss: 1.6438586711883545
Validation loss: 2.3603587535119828

Epoch: 243| Step: 0
Training loss: 2.6875596046447754
Validation loss: 2.368602050248013

Epoch: 5| Step: 1
Training loss: 2.6344010829925537
Validation loss: 2.3739099425654255

Epoch: 5| Step: 2
Training loss: 2.655895233154297
Validation loss: 2.378761053085327

Epoch: 5| Step: 3
Training loss: 2.004333734512329
Validation loss: 2.37447625847273

Epoch: 5| Step: 4
Training loss: 2.2696988582611084
Validation loss: 2.3725008195446384

Epoch: 5| Step: 5
Training loss: 2.810490846633911
Validation loss: 2.3787785550599456

Epoch: 5| Step: 6
Training loss: 2.0143344402313232
Validation loss: 2.3777873516082764

Epoch: 5| Step: 7
Training loss: 2.3086886405944824
Validation loss: 2.385344132300346

Epoch: 5| Step: 8
Training loss: 2.1515755653381348
Validation loss: 2.3737321694691977

Epoch: 5| Step: 9
Training loss: 3.5190136432647705
Validation loss: 2.3671801218422512

Epoch: 5| Step: 10
Training loss: 3.678255558013916
Validation loss: 2.359808152721774

Epoch: 244| Step: 0
Training loss: 2.264197826385498
Validation loss: 2.36027798088648

Epoch: 5| Step: 1
Training loss: 2.62451171875
Validation loss: 2.3638329890466507

Epoch: 5| Step: 2
Training loss: 2.449685573577881
Validation loss: 2.360069651757517

Epoch: 5| Step: 3
Training loss: 2.5331342220306396
Validation loss: 2.358235469428442

Epoch: 5| Step: 4
Training loss: 2.694758892059326
Validation loss: 2.3575554996408443

Epoch: 5| Step: 5
Training loss: 2.6572413444519043
Validation loss: 2.360758417396135

Epoch: 5| Step: 6
Training loss: 3.26536226272583
Validation loss: 2.352977551439757

Epoch: 5| Step: 7
Training loss: 2.6252708435058594
Validation loss: 2.3591431366500033

Epoch: 5| Step: 8
Training loss: 2.4640774726867676
Validation loss: 2.356303527791013

Epoch: 5| Step: 9
Training loss: 2.585329055786133
Validation loss: 2.356541613096832

Epoch: 5| Step: 10
Training loss: 2.4399428367614746
Validation loss: 2.3558299208200104

Epoch: 245| Step: 0
Training loss: 2.1511740684509277
Validation loss: 2.358409325281779

Epoch: 5| Step: 1
Training loss: 2.609924793243408
Validation loss: 2.3559054815641014

Epoch: 5| Step: 2
Training loss: 2.9681458473205566
Validation loss: 2.355080566098613

Epoch: 5| Step: 3
Training loss: 2.5858702659606934
Validation loss: 2.3543686148940877

Epoch: 5| Step: 4
Training loss: 2.227311611175537
Validation loss: 2.3578728116968626

Epoch: 5| Step: 5
Training loss: 3.330589771270752
Validation loss: 2.355757259553479

Epoch: 5| Step: 6
Training loss: 2.1969950199127197
Validation loss: 2.357074394020983

Epoch: 5| Step: 7
Training loss: 2.83491849899292
Validation loss: 2.363423393618676

Epoch: 5| Step: 8
Training loss: 2.226641893386841
Validation loss: 2.3608089698258268

Epoch: 5| Step: 9
Training loss: 2.2975103855133057
Validation loss: 2.3545473749919603

Epoch: 5| Step: 10
Training loss: 3.1301276683807373
Validation loss: 2.362249856354088

Epoch: 246| Step: 0
Training loss: 2.513913631439209
Validation loss: 2.3560310268914826

Epoch: 5| Step: 1
Training loss: 3.0097556114196777
Validation loss: 2.3628207252871607

Epoch: 5| Step: 2
Training loss: 2.6694142818450928
Validation loss: 2.359087718430386

Epoch: 5| Step: 3
Training loss: 1.8706032037734985
Validation loss: 2.3706428697032313

Epoch: 5| Step: 4
Training loss: 3.003006935119629
Validation loss: 2.365930325241499

Epoch: 5| Step: 5
Training loss: 2.672661781311035
Validation loss: 2.362298462980537

Epoch: 5| Step: 6
Training loss: 2.4594879150390625
Validation loss: 2.361402670542399

Epoch: 5| Step: 7
Training loss: 2.5708250999450684
Validation loss: 2.3610634252589238

Epoch: 5| Step: 8
Training loss: 1.7152820825576782
Validation loss: 2.3617845671151274

Epoch: 5| Step: 9
Training loss: 2.9388694763183594
Validation loss: 2.364334960137644

Epoch: 5| Step: 10
Training loss: 3.1129586696624756
Validation loss: 2.367215753883444

Epoch: 247| Step: 0
Training loss: 3.0558502674102783
Validation loss: 2.3609373338760866

Epoch: 5| Step: 1
Training loss: 2.3081536293029785
Validation loss: 2.361967207283102

Epoch: 5| Step: 2
Training loss: 2.87859845161438
Validation loss: 2.3590811978104296

Epoch: 5| Step: 3
Training loss: 2.7956745624542236
Validation loss: 2.3521428569670646

Epoch: 5| Step: 4
Training loss: 2.4625086784362793
Validation loss: 2.3578206108462427

Epoch: 5| Step: 5
Training loss: 2.599984645843506
Validation loss: 2.3582728998635405

Epoch: 5| Step: 6
Training loss: 2.1098930835723877
Validation loss: 2.360150175709878

Epoch: 5| Step: 7
Training loss: 2.7708935737609863
Validation loss: 2.3603369523120183

Epoch: 5| Step: 8
Training loss: 2.603964328765869
Validation loss: 2.357484817504883

Epoch: 5| Step: 9
Training loss: 2.7550320625305176
Validation loss: 2.365079733633226

Epoch: 5| Step: 10
Training loss: 2.077899932861328
Validation loss: 2.368722705430882

Epoch: 248| Step: 0
Training loss: 2.352787494659424
Validation loss: 2.3686085977861957

Epoch: 5| Step: 1
Training loss: 2.799304962158203
Validation loss: 2.371258125510267

Epoch: 5| Step: 2
Training loss: 1.9567209482192993
Validation loss: 2.3693469083437355

Epoch: 5| Step: 3
Training loss: 2.519317150115967
Validation loss: 2.3632989980841197

Epoch: 5| Step: 4
Training loss: 2.4919517040252686
Validation loss: 2.3571653468634493

Epoch: 5| Step: 5
Training loss: 2.878291368484497
Validation loss: 2.3605972105456936

Epoch: 5| Step: 6
Training loss: 2.361229419708252
Validation loss: 2.354583622306906

Epoch: 5| Step: 7
Training loss: 3.0015833377838135
Validation loss: 2.3499651929383636

Epoch: 5| Step: 8
Training loss: 2.5681354999542236
Validation loss: 2.348933409619075

Epoch: 5| Step: 9
Training loss: 2.9455819129943848
Validation loss: 2.348387154199744

Epoch: 5| Step: 10
Training loss: 2.6228723526000977
Validation loss: 2.352354754683792

Epoch: 249| Step: 0
Training loss: 3.166902542114258
Validation loss: 2.344422016092526

Epoch: 5| Step: 1
Training loss: 2.392310380935669
Validation loss: 2.346445829637589

Epoch: 5| Step: 2
Training loss: 2.7118942737579346
Validation loss: 2.344882949706047

Epoch: 5| Step: 3
Training loss: 2.404106616973877
Validation loss: 2.3456798291975454

Epoch: 5| Step: 4
Training loss: 2.3874619007110596
Validation loss: 2.349708036709857

Epoch: 5| Step: 5
Training loss: 2.2975552082061768
Validation loss: 2.3471367154070126

Epoch: 5| Step: 6
Training loss: 2.614847421646118
Validation loss: 2.3499309426994732

Epoch: 5| Step: 7
Training loss: 2.647797107696533
Validation loss: 2.352935057814403

Epoch: 5| Step: 8
Training loss: 2.2607905864715576
Validation loss: 2.352288120536394

Epoch: 5| Step: 9
Training loss: 2.452846050262451
Validation loss: 2.355062876978228

Epoch: 5| Step: 10
Training loss: 3.241077184677124
Validation loss: 2.3511284218039563

Epoch: 250| Step: 0
Training loss: 2.1488990783691406
Validation loss: 2.3518018978898243

Epoch: 5| Step: 1
Training loss: 3.0530130863189697
Validation loss: 2.3499864839738414

Epoch: 5| Step: 2
Training loss: 2.346712589263916
Validation loss: 2.3448928838135092

Epoch: 5| Step: 3
Training loss: 2.29378604888916
Validation loss: 2.3415176483892624

Epoch: 5| Step: 4
Training loss: 2.4360408782958984
Validation loss: 2.3453081935964604

Epoch: 5| Step: 5
Training loss: 2.6441192626953125
Validation loss: 2.3484834496692946

Epoch: 5| Step: 6
Training loss: 2.182664155960083
Validation loss: 2.3468581527791996

Epoch: 5| Step: 7
Training loss: 2.9839706420898438
Validation loss: 2.341835647500971

Epoch: 5| Step: 8
Training loss: 3.3419861793518066
Validation loss: 2.3417705515379548

Epoch: 5| Step: 9
Training loss: 2.8067116737365723
Validation loss: 2.3456096495351484

Epoch: 5| Step: 10
Training loss: 2.1492505073547363
Validation loss: 2.3425709791080926

Epoch: 251| Step: 0
Training loss: 2.3682003021240234
Validation loss: 2.3380947625765236

Epoch: 5| Step: 1
Training loss: 2.98689603805542
Validation loss: 2.3397315573948685

Epoch: 5| Step: 2
Training loss: 2.283118486404419
Validation loss: 2.344892465940086

Epoch: 5| Step: 3
Training loss: 2.590782880783081
Validation loss: 2.343418046992312

Epoch: 5| Step: 4
Training loss: 2.814913511276245
Validation loss: 2.341922772827969

Epoch: 5| Step: 5
Training loss: 3.092848300933838
Validation loss: 2.3446617562283754

Epoch: 5| Step: 6
Training loss: 2.488680601119995
Validation loss: 2.3423106388379167

Epoch: 5| Step: 7
Training loss: 2.7108943462371826
Validation loss: 2.342943227419289

Epoch: 5| Step: 8
Training loss: 2.4335217475891113
Validation loss: 2.347431928880753

Epoch: 5| Step: 9
Training loss: 2.7745201587677
Validation loss: 2.3367555218358196

Epoch: 5| Step: 10
Training loss: 1.8196194171905518
Validation loss: 2.3432289092771468

Epoch: 252| Step: 0
Training loss: 3.0969436168670654
Validation loss: 2.3402570370704896

Epoch: 5| Step: 1
Training loss: 2.927886486053467
Validation loss: 2.3480009494289273

Epoch: 5| Step: 2
Training loss: 2.0286202430725098
Validation loss: 2.351063364295549

Epoch: 5| Step: 3
Training loss: 3.0885119438171387
Validation loss: 2.342088632686164

Epoch: 5| Step: 4
Training loss: 1.999610185623169
Validation loss: 2.34234183578081

Epoch: 5| Step: 5
Training loss: 2.746065616607666
Validation loss: 2.3427256845658824

Epoch: 5| Step: 6
Training loss: 2.176003932952881
Validation loss: 2.341233174006144

Epoch: 5| Step: 7
Training loss: 2.9045815467834473
Validation loss: 2.344790151042323

Epoch: 5| Step: 8
Training loss: 2.8902907371520996
Validation loss: 2.338513958838678

Epoch: 5| Step: 9
Training loss: 2.2715773582458496
Validation loss: 2.3461980153155584

Epoch: 5| Step: 10
Training loss: 2.26926326751709
Validation loss: 2.345619442642376

Epoch: 253| Step: 0
Training loss: 2.3340487480163574
Validation loss: 2.3486220759730183

Epoch: 5| Step: 1
Training loss: 2.6396946907043457
Validation loss: 2.3467391434536187

Epoch: 5| Step: 2
Training loss: 1.773066520690918
Validation loss: 2.3452960214307232

Epoch: 5| Step: 3
Training loss: 2.5461268424987793
Validation loss: 2.3509736766097364

Epoch: 5| Step: 4
Training loss: 2.113429069519043
Validation loss: 2.354466064001924

Epoch: 5| Step: 5
Training loss: 3.0326716899871826
Validation loss: 2.3486696981614634

Epoch: 5| Step: 6
Training loss: 3.4624087810516357
Validation loss: 2.3516333064725323

Epoch: 5| Step: 7
Training loss: 2.9389424324035645
Validation loss: 2.3485097526222147

Epoch: 5| Step: 8
Training loss: 2.6281840801239014
Validation loss: 2.345441907964727

Epoch: 5| Step: 9
Training loss: 2.4840426445007324
Validation loss: 2.3539934953053794

Epoch: 5| Step: 10
Training loss: 2.51126766204834
Validation loss: 2.3552301212023665

Epoch: 254| Step: 0
Training loss: 2.3655447959899902
Validation loss: 2.3584729727878364

Epoch: 5| Step: 1
Training loss: 1.6707916259765625
Validation loss: 2.3589740299409434

Epoch: 5| Step: 2
Training loss: 2.1840243339538574
Validation loss: 2.3550158162270822

Epoch: 5| Step: 3
Training loss: 2.5721068382263184
Validation loss: 2.355770528957408

Epoch: 5| Step: 4
Training loss: 2.1602632999420166
Validation loss: 2.3571975461898313

Epoch: 5| Step: 5
Training loss: 2.7478575706481934
Validation loss: 2.3638585216255596

Epoch: 5| Step: 6
Training loss: 3.2847366333007812
Validation loss: 2.3581555710043958

Epoch: 5| Step: 7
Training loss: 2.5097973346710205
Validation loss: 2.3595386833272953

Epoch: 5| Step: 8
Training loss: 3.4882240295410156
Validation loss: 2.354252064099876

Epoch: 5| Step: 9
Training loss: 3.081761360168457
Validation loss: 2.3532091391983854

Epoch: 5| Step: 10
Training loss: 2.270768404006958
Validation loss: 2.3507137708766486

Epoch: 255| Step: 0
Training loss: 2.741462469100952
Validation loss: 2.351024176484795

Epoch: 5| Step: 1
Training loss: 1.8963444232940674
Validation loss: 2.3496379621567263

Epoch: 5| Step: 2
Training loss: 2.15336275100708
Validation loss: 2.3442926740133636

Epoch: 5| Step: 3
Training loss: 3.1882822513580322
Validation loss: 2.3409180641174316

Epoch: 5| Step: 4
Training loss: 2.909229278564453
Validation loss: 2.343626755540089

Epoch: 5| Step: 5
Training loss: 2.4424684047698975
Validation loss: 2.3493750172276653

Epoch: 5| Step: 6
Training loss: 2.2435715198516846
Validation loss: 2.355324742614582

Epoch: 5| Step: 7
Training loss: 2.6615946292877197
Validation loss: 2.3582479735856414

Epoch: 5| Step: 8
Training loss: 3.598456621170044
Validation loss: 2.3535170708933184

Epoch: 5| Step: 9
Training loss: 2.0371649265289307
Validation loss: 2.351400536875571

Epoch: 5| Step: 10
Training loss: 2.541278123855591
Validation loss: 2.3468100742627214

Epoch: 256| Step: 0
Training loss: 3.031154155731201
Validation loss: 2.346318616661974

Epoch: 5| Step: 1
Training loss: 2.950254440307617
Validation loss: 2.3424761987501577

Epoch: 5| Step: 2
Training loss: 2.491405487060547
Validation loss: 2.351781827147289

Epoch: 5| Step: 3
Training loss: 2.998382568359375
Validation loss: 2.362557324030066

Epoch: 5| Step: 4
Training loss: 2.247620105743408
Validation loss: 2.3629323051821802

Epoch: 5| Step: 5
Training loss: 2.0813989639282227
Validation loss: 2.3534512519836426

Epoch: 5| Step: 6
Training loss: 2.825615406036377
Validation loss: 2.342799127742808

Epoch: 5| Step: 7
Training loss: 2.384828805923462
Validation loss: 2.350707946285125

Epoch: 5| Step: 8
Training loss: 2.641986846923828
Validation loss: 2.3454686493001957

Epoch: 5| Step: 9
Training loss: 2.2902064323425293
Validation loss: 2.356705270787721

Epoch: 5| Step: 10
Training loss: 2.4350717067718506
Validation loss: 2.3644317298807125

Epoch: 257| Step: 0
Training loss: 2.053218364715576
Validation loss: 2.370917122851136

Epoch: 5| Step: 1
Training loss: 2.295447587966919
Validation loss: 2.3861925781414075

Epoch: 5| Step: 2
Training loss: 2.1608054637908936
Validation loss: 2.3732561834396853

Epoch: 5| Step: 3
Training loss: 2.7053894996643066
Validation loss: 2.3681497381579493

Epoch: 5| Step: 4
Training loss: 2.5980823040008545
Validation loss: 2.367432684026739

Epoch: 5| Step: 5
Training loss: 2.78717041015625
Validation loss: 2.359991245372321

Epoch: 5| Step: 6
Training loss: 3.6606011390686035
Validation loss: 2.3590132651790494

Epoch: 5| Step: 7
Training loss: 3.0112252235412598
Validation loss: 2.3436972325847996

Epoch: 5| Step: 8
Training loss: 2.46818208694458
Validation loss: 2.3527696389023975

Epoch: 5| Step: 9
Training loss: 2.292015552520752
Validation loss: 2.3542600165131273

Epoch: 5| Step: 10
Training loss: 2.4044065475463867
Validation loss: 2.3495241339488695

Epoch: 258| Step: 0
Training loss: 2.855699062347412
Validation loss: 2.3587893311695387

Epoch: 5| Step: 1
Training loss: 1.965319037437439
Validation loss: 2.361599386379283

Epoch: 5| Step: 2
Training loss: 2.110788345336914
Validation loss: 2.3653338416930167

Epoch: 5| Step: 3
Training loss: 2.710951328277588
Validation loss: 2.3559525551334506

Epoch: 5| Step: 4
Training loss: 3.649122714996338
Validation loss: 2.353917601288006

Epoch: 5| Step: 5
Training loss: 3.096341371536255
Validation loss: 2.345556841101698

Epoch: 5| Step: 6
Training loss: 2.785893201828003
Validation loss: 2.338374553188201

Epoch: 5| Step: 7
Training loss: 2.5219860076904297
Validation loss: 2.3405880299947595

Epoch: 5| Step: 8
Training loss: 2.824150323867798
Validation loss: 2.338575288813601

Epoch: 5| Step: 9
Training loss: 1.9270083904266357
Validation loss: 2.340570257556054

Epoch: 5| Step: 10
Training loss: 1.8658926486968994
Validation loss: 2.341792313001489

Epoch: 259| Step: 0
Training loss: 2.697364568710327
Validation loss: 2.353977875042987

Epoch: 5| Step: 1
Training loss: 2.6956918239593506
Validation loss: 2.35546273826271

Epoch: 5| Step: 2
Training loss: 2.4256272315979004
Validation loss: 2.355582529498685

Epoch: 5| Step: 3
Training loss: 2.9749341011047363
Validation loss: 2.356590611960298

Epoch: 5| Step: 4
Training loss: 2.7441158294677734
Validation loss: 2.3529840489869476

Epoch: 5| Step: 5
Training loss: 2.3955605030059814
Validation loss: 2.3601831441284506

Epoch: 5| Step: 6
Training loss: 2.8405661582946777
Validation loss: 2.3491635220025175

Epoch: 5| Step: 7
Training loss: 2.665360689163208
Validation loss: 2.3535783316499446

Epoch: 5| Step: 8
Training loss: 2.5926122665405273
Validation loss: 2.347923478772563

Epoch: 5| Step: 9
Training loss: 2.2647531032562256
Validation loss: 2.3380431872542187

Epoch: 5| Step: 10
Training loss: 2.1773903369903564
Validation loss: 2.343865268973894

Epoch: 260| Step: 0
Training loss: 2.5680136680603027
Validation loss: 2.3438167418203046

Epoch: 5| Step: 1
Training loss: 2.39119291305542
Validation loss: 2.335551097828855

Epoch: 5| Step: 2
Training loss: 2.4087350368499756
Validation loss: 2.3435337530669345

Epoch: 5| Step: 3
Training loss: 2.7948830127716064
Validation loss: 2.351464720182521

Epoch: 5| Step: 4
Training loss: 2.2548351287841797
Validation loss: 2.340657008591519

Epoch: 5| Step: 5
Training loss: 2.499037504196167
Validation loss: 2.3468435977094915

Epoch: 5| Step: 6
Training loss: 3.1337547302246094
Validation loss: 2.344888969134259

Epoch: 5| Step: 7
Training loss: 2.5492453575134277
Validation loss: 2.3368732954866145

Epoch: 5| Step: 8
Training loss: 2.438298463821411
Validation loss: 2.338124975081413

Epoch: 5| Step: 9
Training loss: 2.801494836807251
Validation loss: 2.3300177128084245

Epoch: 5| Step: 10
Training loss: 2.552157402038574
Validation loss: 2.346982948241695

Epoch: 261| Step: 0
Training loss: 2.5061795711517334
Validation loss: 2.33797150786205

Epoch: 5| Step: 1
Training loss: 2.779853343963623
Validation loss: 2.343842475645004

Epoch: 5| Step: 2
Training loss: 2.9272549152374268
Validation loss: 2.340534563987486

Epoch: 5| Step: 3
Training loss: 2.602356195449829
Validation loss: 2.334884000080888

Epoch: 5| Step: 4
Training loss: 2.1250014305114746
Validation loss: 2.3389679719043035

Epoch: 5| Step: 5
Training loss: 2.2655906677246094
Validation loss: 2.339212453493508

Epoch: 5| Step: 6
Training loss: 2.5762526988983154
Validation loss: 2.3496618193964802

Epoch: 5| Step: 7
Training loss: 2.8183181285858154
Validation loss: 2.3570469399934173

Epoch: 5| Step: 8
Training loss: 2.7421271800994873
Validation loss: 2.3451948845258324

Epoch: 5| Step: 9
Training loss: 2.469942808151245
Validation loss: 2.337029953156748

Epoch: 5| Step: 10
Training loss: 2.597743034362793
Validation loss: 2.3380068438027495

Epoch: 262| Step: 0
Training loss: 2.428598403930664
Validation loss: 2.344376302534534

Epoch: 5| Step: 1
Training loss: 2.7322351932525635
Validation loss: 2.336440396565263

Epoch: 5| Step: 2
Training loss: 2.7286014556884766
Validation loss: 2.326002008171492

Epoch: 5| Step: 3
Training loss: 2.6054840087890625
Validation loss: 2.3279040372499855

Epoch: 5| Step: 4
Training loss: 2.5687694549560547
Validation loss: 2.331665923518519

Epoch: 5| Step: 5
Training loss: 2.4975593090057373
Validation loss: 2.3254914591389317

Epoch: 5| Step: 6
Training loss: 2.098740816116333
Validation loss: 2.3286781221307735

Epoch: 5| Step: 7
Training loss: 2.813875675201416
Validation loss: 2.3278360879549416

Epoch: 5| Step: 8
Training loss: 2.9250946044921875
Validation loss: 2.3354144109192716

Epoch: 5| Step: 9
Training loss: 2.4925010204315186
Validation loss: 2.3338577926799817

Epoch: 5| Step: 10
Training loss: 2.5048511028289795
Validation loss: 2.331279541856499

Epoch: 263| Step: 0
Training loss: 2.618394136428833
Validation loss: 2.3431398150741414

Epoch: 5| Step: 1
Training loss: 2.4194495677948
Validation loss: 2.341359648653256

Epoch: 5| Step: 2
Training loss: 1.8418095111846924
Validation loss: 2.335190179527447

Epoch: 5| Step: 3
Training loss: 2.7793617248535156
Validation loss: 2.32534424976636

Epoch: 5| Step: 4
Training loss: 2.901522159576416
Validation loss: 2.336755262908115

Epoch: 5| Step: 5
Training loss: 3.2227416038513184
Validation loss: 2.330381090923022

Epoch: 5| Step: 6
Training loss: 2.775719165802002
Validation loss: 2.3343620018292497

Epoch: 5| Step: 7
Training loss: 2.4501290321350098
Validation loss: 2.341417981732276

Epoch: 5| Step: 8
Training loss: 2.9906198978424072
Validation loss: 2.339321521020705

Epoch: 5| Step: 9
Training loss: 2.078044891357422
Validation loss: 2.3552459747560563

Epoch: 5| Step: 10
Training loss: 2.2292134761810303
Validation loss: 2.3520320923097673

Epoch: 264| Step: 0
Training loss: 3.170858860015869
Validation loss: 2.3325025125216414

Epoch: 5| Step: 1
Training loss: 2.0857017040252686
Validation loss: 2.3315594529592865

Epoch: 5| Step: 2
Training loss: 3.1801657676696777
Validation loss: 2.3283900958235546

Epoch: 5| Step: 3
Training loss: 2.5453379154205322
Validation loss: 2.333581793692804

Epoch: 5| Step: 4
Training loss: 2.413217067718506
Validation loss: 2.323496690360449

Epoch: 5| Step: 5
Training loss: 2.434617519378662
Validation loss: 2.336439186526883

Epoch: 5| Step: 6
Training loss: 2.451559543609619
Validation loss: 2.332491062020743

Epoch: 5| Step: 7
Training loss: 2.618072986602783
Validation loss: 2.341151370797106

Epoch: 5| Step: 8
Training loss: 2.268399238586426
Validation loss: 2.338026859427011

Epoch: 5| Step: 9
Training loss: 3.2037880420684814
Validation loss: 2.3379909556399108

Epoch: 5| Step: 10
Training loss: 1.835891842842102
Validation loss: 2.351287385468842

Epoch: 265| Step: 0
Training loss: 2.5215864181518555
Validation loss: 2.346140771783808

Epoch: 5| Step: 1
Training loss: 2.617135524749756
Validation loss: 2.355592471297069

Epoch: 5| Step: 2
Training loss: 2.7085227966308594
Validation loss: 2.3565262363803003

Epoch: 5| Step: 3
Training loss: 3.097348690032959
Validation loss: 2.3695108249623287

Epoch: 5| Step: 4
Training loss: 2.5347931385040283
Validation loss: 2.378405147983182

Epoch: 5| Step: 5
Training loss: 1.8290603160858154
Validation loss: 2.3722104692971833

Epoch: 5| Step: 6
Training loss: 2.594170093536377
Validation loss: 2.3654902570991108

Epoch: 5| Step: 7
Training loss: 2.8449501991271973
Validation loss: 2.3801865936607443

Epoch: 5| Step: 8
Training loss: 2.3889801502227783
Validation loss: 2.358771998395202

Epoch: 5| Step: 9
Training loss: 2.5367929935455322
Validation loss: 2.35724736285466

Epoch: 5| Step: 10
Training loss: 2.6898467540740967
Validation loss: 2.332714088501469

Epoch: 266| Step: 0
Training loss: 2.7654521465301514
Validation loss: 2.3395484391079155

Epoch: 5| Step: 1
Training loss: 2.4748518466949463
Validation loss: 2.3364126477190243

Epoch: 5| Step: 2
Training loss: 2.6688971519470215
Validation loss: 2.327954371770223

Epoch: 5| Step: 3
Training loss: 1.7422358989715576
Validation loss: 2.324910489461755

Epoch: 5| Step: 4
Training loss: 2.5155892372131348
Validation loss: 2.325412501570999

Epoch: 5| Step: 5
Training loss: 1.7230991125106812
Validation loss: 2.3292756183173067

Epoch: 5| Step: 6
Training loss: 2.5972847938537598
Validation loss: 2.3286979531729095

Epoch: 5| Step: 7
Training loss: 2.556001663208008
Validation loss: 2.3317682871254544

Epoch: 5| Step: 8
Training loss: 2.9001805782318115
Validation loss: 2.3303321228232434

Epoch: 5| Step: 9
Training loss: 3.0754928588867188
Validation loss: 2.342678781478636

Epoch: 5| Step: 10
Training loss: 3.416242837905884
Validation loss: 2.333366286370062

Epoch: 267| Step: 0
Training loss: 2.391658067703247
Validation loss: 2.3220664057680356

Epoch: 5| Step: 1
Training loss: 3.167618989944458
Validation loss: 2.3293048976570048

Epoch: 5| Step: 2
Training loss: 2.5736336708068848
Validation loss: 2.3366428395753265

Epoch: 5| Step: 3
Training loss: 1.582885980606079
Validation loss: 2.335286853133991

Epoch: 5| Step: 4
Training loss: 2.425703525543213
Validation loss: 2.341469044326454

Epoch: 5| Step: 5
Training loss: 2.6680970191955566
Validation loss: 2.3458374084964877

Epoch: 5| Step: 6
Training loss: 2.640760660171509
Validation loss: 2.3611221364749375

Epoch: 5| Step: 7
Training loss: 2.516542434692383
Validation loss: 2.3730599713581864

Epoch: 5| Step: 8
Training loss: 2.8307714462280273
Validation loss: 2.3743193816113215

Epoch: 5| Step: 9
Training loss: 2.5216870307922363
Validation loss: 2.3797039203746344

Epoch: 5| Step: 10
Training loss: 3.1484873294830322
Validation loss: 2.3896070052218694

Epoch: 268| Step: 0
Training loss: 2.697841167449951
Validation loss: 2.3943639455303067

Epoch: 5| Step: 1
Training loss: 2.1128859519958496
Validation loss: 2.377227960094329

Epoch: 5| Step: 2
Training loss: 2.7215559482574463
Validation loss: 2.377261220767934

Epoch: 5| Step: 3
Training loss: 3.0371217727661133
Validation loss: 2.3754584520093855

Epoch: 5| Step: 4
Training loss: 3.3886611461639404
Validation loss: 2.366580314533685

Epoch: 5| Step: 5
Training loss: 1.982583999633789
Validation loss: 2.3537672412010933

Epoch: 5| Step: 6
Training loss: 2.8428590297698975
Validation loss: 2.3446973575058805

Epoch: 5| Step: 7
Training loss: 2.0880472660064697
Validation loss: 2.334930528876602

Epoch: 5| Step: 8
Training loss: 2.338970184326172
Validation loss: 2.3299197304633354

Epoch: 5| Step: 9
Training loss: 2.4298155307769775
Validation loss: 2.326862399296094

Epoch: 5| Step: 10
Training loss: 2.7576069831848145
Validation loss: 2.3285199185853362

Epoch: 269| Step: 0
Training loss: 3.0679328441619873
Validation loss: 2.32173046758098

Epoch: 5| Step: 1
Training loss: 2.656052589416504
Validation loss: 2.3234373984798307

Epoch: 5| Step: 2
Training loss: 2.325071334838867
Validation loss: 2.3253924295466435

Epoch: 5| Step: 3
Training loss: 2.6586272716522217
Validation loss: 2.3226607896948375

Epoch: 5| Step: 4
Training loss: 2.703464984893799
Validation loss: 2.326298954666302

Epoch: 5| Step: 5
Training loss: 2.6685805320739746
Validation loss: 2.3246509234110513

Epoch: 5| Step: 6
Training loss: 2.0220224857330322
Validation loss: 2.323145753593855

Epoch: 5| Step: 7
Training loss: 2.151930332183838
Validation loss: 2.329640906344178

Epoch: 5| Step: 8
Training loss: 2.843428134918213
Validation loss: 2.330387887134347

Epoch: 5| Step: 9
Training loss: 2.5073320865631104
Validation loss: 2.339033131958336

Epoch: 5| Step: 10
Training loss: 2.615936517715454
Validation loss: 2.3297891770639727

Epoch: 270| Step: 0
Training loss: 3.1938891410827637
Validation loss: 2.335818741911201

Epoch: 5| Step: 1
Training loss: 2.535891056060791
Validation loss: 2.337334845655708

Epoch: 5| Step: 2
Training loss: 2.175682544708252
Validation loss: 2.3316676629486905

Epoch: 5| Step: 3
Training loss: 2.439941883087158
Validation loss: 2.329613365152831

Epoch: 5| Step: 4
Training loss: 2.4664580821990967
Validation loss: 2.329254432391095

Epoch: 5| Step: 5
Training loss: 2.4887797832489014
Validation loss: 2.325950050866732

Epoch: 5| Step: 6
Training loss: 2.3750436305999756
Validation loss: 2.329180545704339

Epoch: 5| Step: 7
Training loss: 2.9338836669921875
Validation loss: 2.3230518012918453

Epoch: 5| Step: 8
Training loss: 2.665828227996826
Validation loss: 2.3245077184451524

Epoch: 5| Step: 9
Training loss: 1.921558141708374
Validation loss: 2.318859984797816

Epoch: 5| Step: 10
Training loss: 3.058286190032959
Validation loss: 2.323902953055597

Epoch: 271| Step: 0
Training loss: 2.434635639190674
Validation loss: 2.330376681461129

Epoch: 5| Step: 1
Training loss: 2.932609796524048
Validation loss: 2.3256197014162616

Epoch: 5| Step: 2
Training loss: 2.4422061443328857
Validation loss: 2.3332163800475416

Epoch: 5| Step: 3
Training loss: 2.4590258598327637
Validation loss: 2.3269032739823863

Epoch: 5| Step: 4
Training loss: 2.5150959491729736
Validation loss: 2.3362460495323263

Epoch: 5| Step: 5
Training loss: 2.743809223175049
Validation loss: 2.3414958805166264

Epoch: 5| Step: 6
Training loss: 2.9873557090759277
Validation loss: 2.3367519276116484

Epoch: 5| Step: 7
Training loss: 1.8576173782348633
Validation loss: 2.3311446353953373

Epoch: 5| Step: 8
Training loss: 2.6075894832611084
Validation loss: 2.328069120325068

Epoch: 5| Step: 9
Training loss: 2.6495473384857178
Validation loss: 2.322816518045241

Epoch: 5| Step: 10
Training loss: 2.59232234954834
Validation loss: 2.3197618428096978

Epoch: 272| Step: 0
Training loss: 2.3420567512512207
Validation loss: 2.3198136693687847

Epoch: 5| Step: 1
Training loss: 2.4147887229919434
Validation loss: 2.3193424901654645

Epoch: 5| Step: 2
Training loss: 3.2421088218688965
Validation loss: 2.3213839146398727

Epoch: 5| Step: 3
Training loss: 2.182480573654175
Validation loss: 2.3290757671479256

Epoch: 5| Step: 4
Training loss: 3.1167216300964355
Validation loss: 2.335101919789468

Epoch: 5| Step: 5
Training loss: 3.1452412605285645
Validation loss: 2.3366458005802606

Epoch: 5| Step: 6
Training loss: 2.824877977371216
Validation loss: 2.330423291011523

Epoch: 5| Step: 7
Training loss: 2.707949161529541
Validation loss: 2.3343738689217517

Epoch: 5| Step: 8
Training loss: 2.2855842113494873
Validation loss: 2.3392509798849783

Epoch: 5| Step: 9
Training loss: 2.474147081375122
Validation loss: 2.3348216933588826

Epoch: 5| Step: 10
Training loss: 1.2903815507888794
Validation loss: 2.329168686302759

Epoch: 273| Step: 0
Training loss: 2.5719246864318848
Validation loss: 2.325371209011283

Epoch: 5| Step: 1
Training loss: 2.5342512130737305
Validation loss: 2.3260679988450903

Epoch: 5| Step: 2
Training loss: 2.532609462738037
Validation loss: 2.318164802366687

Epoch: 5| Step: 3
Training loss: 2.4931702613830566
Validation loss: 2.3172533025023756

Epoch: 5| Step: 4
Training loss: 2.9167537689208984
Validation loss: 2.318632387345837

Epoch: 5| Step: 5
Training loss: 2.137985944747925
Validation loss: 2.3243741476407616

Epoch: 5| Step: 6
Training loss: 2.023397922515869
Validation loss: 2.324999047863868

Epoch: 5| Step: 7
Training loss: 2.9180665016174316
Validation loss: 2.3301327843819895

Epoch: 5| Step: 8
Training loss: 2.571733236312866
Validation loss: 2.3330466542192685

Epoch: 5| Step: 9
Training loss: 2.7763779163360596
Validation loss: 2.3478130396976264

Epoch: 5| Step: 10
Training loss: 2.8518409729003906
Validation loss: 2.3462911139252367

Epoch: 274| Step: 0
Training loss: 2.7771987915039062
Validation loss: 2.3511394992951424

Epoch: 5| Step: 1
Training loss: 2.204516887664795
Validation loss: 2.341518532845282

Epoch: 5| Step: 2
Training loss: 3.0238795280456543
Validation loss: 2.330498990192208

Epoch: 5| Step: 3
Training loss: 2.574972629547119
Validation loss: 2.327265936841247

Epoch: 5| Step: 4
Training loss: 2.300147294998169
Validation loss: 2.3209242897648967

Epoch: 5| Step: 5
Training loss: 2.016340494155884
Validation loss: 2.311766186068135

Epoch: 5| Step: 6
Training loss: 2.855740547180176
Validation loss: 2.3219296957856868

Epoch: 5| Step: 7
Training loss: 2.3780720233917236
Validation loss: 2.3278851368094005

Epoch: 5| Step: 8
Training loss: 2.9488139152526855
Validation loss: 2.3305994631141744

Epoch: 5| Step: 9
Training loss: 2.2607226371765137
Validation loss: 2.3361605367352887

Epoch: 5| Step: 10
Training loss: 2.915963888168335
Validation loss: 2.340273162370087

Epoch: 275| Step: 0
Training loss: 2.130549669265747
Validation loss: 2.3455399544008317

Epoch: 5| Step: 1
Training loss: 2.5275912284851074
Validation loss: 2.3495986487275813

Epoch: 5| Step: 2
Training loss: 2.9329750537872314
Validation loss: 2.355119461654335

Epoch: 5| Step: 3
Training loss: 2.732451915740967
Validation loss: 2.3481026798166256

Epoch: 5| Step: 4
Training loss: 2.638519763946533
Validation loss: 2.3545039289741108

Epoch: 5| Step: 5
Training loss: 2.378058910369873
Validation loss: 2.3407418932966007

Epoch: 5| Step: 6
Training loss: 2.9050076007843018
Validation loss: 2.3409023823276645

Epoch: 5| Step: 7
Training loss: 2.0020108222961426
Validation loss: 2.3335863697913384

Epoch: 5| Step: 8
Training loss: 2.580629587173462
Validation loss: 2.3305794192898657

Epoch: 5| Step: 9
Training loss: 2.384786605834961
Validation loss: 2.3284745242006037

Epoch: 5| Step: 10
Training loss: 3.046905517578125
Validation loss: 2.3258876954355547

Epoch: 276| Step: 0
Training loss: 2.0731780529022217
Validation loss: 2.3268325533918155

Epoch: 5| Step: 1
Training loss: 3.130241870880127
Validation loss: 2.3224171464161207

Epoch: 5| Step: 2
Training loss: 1.8194282054901123
Validation loss: 2.3279489112156693

Epoch: 5| Step: 3
Training loss: 2.1370599269866943
Validation loss: 2.3264285390095045

Epoch: 5| Step: 4
Training loss: 2.1877732276916504
Validation loss: 2.3246831227374334

Epoch: 5| Step: 5
Training loss: 3.0131287574768066
Validation loss: 2.331007754930886

Epoch: 5| Step: 6
Training loss: 2.4159698486328125
Validation loss: 2.330336783521919

Epoch: 5| Step: 7
Training loss: 3.0803768634796143
Validation loss: 2.3259815067373295

Epoch: 5| Step: 8
Training loss: 2.677448272705078
Validation loss: 2.329884870077974

Epoch: 5| Step: 9
Training loss: 3.1524205207824707
Validation loss: 2.3279361801762737

Epoch: 5| Step: 10
Training loss: 2.420003652572632
Validation loss: 2.321339653384301

Epoch: 277| Step: 0
Training loss: 2.5920989513397217
Validation loss: 2.3370708598885486

Epoch: 5| Step: 1
Training loss: 2.6891651153564453
Validation loss: 2.327798999765868

Epoch: 5| Step: 2
Training loss: 2.4598276615142822
Validation loss: 2.338497213138047

Epoch: 5| Step: 3
Training loss: 3.229111909866333
Validation loss: 2.3255389300725793

Epoch: 5| Step: 4
Training loss: 2.291353702545166
Validation loss: 2.3285520499752415

Epoch: 5| Step: 5
Training loss: 2.7860045433044434
Validation loss: 2.3378408711443663

Epoch: 5| Step: 6
Training loss: 2.4694764614105225
Validation loss: 2.33541545303919

Epoch: 5| Step: 7
Training loss: 3.1535797119140625
Validation loss: 2.328594189818187

Epoch: 5| Step: 8
Training loss: 1.7960174083709717
Validation loss: 2.3208342085602465

Epoch: 5| Step: 9
Training loss: 2.350614070892334
Validation loss: 2.323750624092676

Epoch: 5| Step: 10
Training loss: 2.3082849979400635
Validation loss: 2.326975248193228

Epoch: 278| Step: 0
Training loss: 2.564673900604248
Validation loss: 2.331369229542312

Epoch: 5| Step: 1
Training loss: 2.5331063270568848
Validation loss: 2.334137947328629

Epoch: 5| Step: 2
Training loss: 2.1531050205230713
Validation loss: 2.3268945550405853

Epoch: 5| Step: 3
Training loss: 2.5210163593292236
Validation loss: 2.333346882174092

Epoch: 5| Step: 4
Training loss: 2.4142191410064697
Validation loss: 2.325322840803413

Epoch: 5| Step: 5
Training loss: 2.7324814796447754
Validation loss: 2.3201243569774013

Epoch: 5| Step: 6
Training loss: 1.961124062538147
Validation loss: 2.312742151239867

Epoch: 5| Step: 7
Training loss: 2.9186770915985107
Validation loss: 2.3143349898758756

Epoch: 5| Step: 8
Training loss: 2.5903491973876953
Validation loss: 2.3272321403667493

Epoch: 5| Step: 9
Training loss: 2.570260524749756
Validation loss: 2.3217656150940926

Epoch: 5| Step: 10
Training loss: 3.256124258041382
Validation loss: 2.3421040734937115

Epoch: 279| Step: 0
Training loss: 2.929269790649414
Validation loss: 2.3426105565922235

Epoch: 5| Step: 1
Training loss: 3.187908887863159
Validation loss: 2.3329271706201697

Epoch: 5| Step: 2
Training loss: 2.9791367053985596
Validation loss: 2.3314918266829623

Epoch: 5| Step: 3
Training loss: 1.8179740905761719
Validation loss: 2.32827236319101

Epoch: 5| Step: 4
Training loss: 1.8977572917938232
Validation loss: 2.3286497951835714

Epoch: 5| Step: 5
Training loss: 2.6372103691101074
Validation loss: 2.327063916831888

Epoch: 5| Step: 6
Training loss: 2.4548983573913574
Validation loss: 2.329531331216135

Epoch: 5| Step: 7
Training loss: 3.1367554664611816
Validation loss: 2.326251927242484

Epoch: 5| Step: 8
Training loss: 1.8970344066619873
Validation loss: 2.3219339514291413

Epoch: 5| Step: 9
Training loss: 2.644599199295044
Validation loss: 2.321430003771218

Epoch: 5| Step: 10
Training loss: 2.5184288024902344
Validation loss: 2.311233571780625

Epoch: 280| Step: 0
Training loss: 2.664307117462158
Validation loss: 2.3096312758743123

Epoch: 5| Step: 1
Training loss: 2.5840649604797363
Validation loss: 2.3016680376504057

Epoch: 5| Step: 2
Training loss: 2.2962656021118164
Validation loss: 2.3102536252749863

Epoch: 5| Step: 3
Training loss: 3.068415403366089
Validation loss: 2.314937558225406

Epoch: 5| Step: 4
Training loss: 2.9176926612854004
Validation loss: 2.3138003656941075

Epoch: 5| Step: 5
Training loss: 1.9506393671035767
Validation loss: 2.314634567947798

Epoch: 5| Step: 6
Training loss: 2.4044549465179443
Validation loss: 2.303170463090302

Epoch: 5| Step: 7
Training loss: 2.5614736080169678
Validation loss: 2.312260074000205

Epoch: 5| Step: 8
Training loss: 2.2984237670898438
Validation loss: 2.3196326276307464

Epoch: 5| Step: 9
Training loss: 2.539442539215088
Validation loss: 2.3163529134565786

Epoch: 5| Step: 10
Training loss: 2.939096450805664
Validation loss: 2.333209537690686

Epoch: 281| Step: 0
Training loss: 2.4515578746795654
Validation loss: 2.340151914986231

Epoch: 5| Step: 1
Training loss: 2.6740992069244385
Validation loss: 2.331610679626465

Epoch: 5| Step: 2
Training loss: 2.184239149093628
Validation loss: 2.3558691599035777

Epoch: 5| Step: 3
Training loss: 2.882373809814453
Validation loss: 2.3576123406810146

Epoch: 5| Step: 4
Training loss: 2.267484426498413
Validation loss: 2.3661825554345244

Epoch: 5| Step: 5
Training loss: 2.80502986907959
Validation loss: 2.3567241596919235

Epoch: 5| Step: 6
Training loss: 3.3402321338653564
Validation loss: 2.357030225056474

Epoch: 5| Step: 7
Training loss: 2.0445713996887207
Validation loss: 2.3532036735165502

Epoch: 5| Step: 8
Training loss: 2.854872226715088
Validation loss: 2.347338725161809

Epoch: 5| Step: 9
Training loss: 2.7489407062530518
Validation loss: 2.3356801258620394

Epoch: 5| Step: 10
Training loss: 1.8004822731018066
Validation loss: 2.321707296115096

Epoch: 282| Step: 0
Training loss: 2.6703152656555176
Validation loss: 2.313361842145202

Epoch: 5| Step: 1
Training loss: 2.3010001182556152
Validation loss: 2.310022620744603

Epoch: 5| Step: 2
Training loss: 3.222478151321411
Validation loss: 2.3082265007880425

Epoch: 5| Step: 3
Training loss: 2.7637581825256348
Validation loss: 2.305596110641315

Epoch: 5| Step: 4
Training loss: 2.4568042755126953
Validation loss: 2.3125320249988186

Epoch: 5| Step: 5
Training loss: 2.7542734146118164
Validation loss: 2.3111445416686354

Epoch: 5| Step: 6
Training loss: 2.753387689590454
Validation loss: 2.3073105094253377

Epoch: 5| Step: 7
Training loss: 2.455296277999878
Validation loss: 2.31597323571482

Epoch: 5| Step: 8
Training loss: 2.51662015914917
Validation loss: 2.3096527181645876

Epoch: 5| Step: 9
Training loss: 2.1589910984039307
Validation loss: 2.310698652780184

Epoch: 5| Step: 10
Training loss: 2.0220839977264404
Validation loss: 2.311143518776022

Epoch: 283| Step: 0
Training loss: 2.8211135864257812
Validation loss: 2.310994094417941

Epoch: 5| Step: 1
Training loss: 3.12386155128479
Validation loss: 2.3309609095255532

Epoch: 5| Step: 2
Training loss: 2.6371185779571533
Validation loss: 2.332824389139811

Epoch: 5| Step: 3
Training loss: 2.547694683074951
Validation loss: 2.3333639649934668

Epoch: 5| Step: 4
Training loss: 2.4783244132995605
Validation loss: 2.328465416867246

Epoch: 5| Step: 5
Training loss: 2.2164063453674316
Validation loss: 2.3312529594667497

Epoch: 5| Step: 6
Training loss: 2.575096607208252
Validation loss: 2.3277934392293296

Epoch: 5| Step: 7
Training loss: 2.3786840438842773
Validation loss: 2.327057312893611

Epoch: 5| Step: 8
Training loss: 2.4603171348571777
Validation loss: 2.3305415722631637

Epoch: 5| Step: 9
Training loss: 2.446901798248291
Validation loss: 2.320792705781998

Epoch: 5| Step: 10
Training loss: 2.4424190521240234
Validation loss: 2.314185309153731

Epoch: 284| Step: 0
Training loss: 2.6415696144104004
Validation loss: 2.309923084833289

Epoch: 5| Step: 1
Training loss: 2.695321798324585
Validation loss: 2.313033482079865

Epoch: 5| Step: 2
Training loss: 2.805358409881592
Validation loss: 2.31885628802802

Epoch: 5| Step: 3
Training loss: 2.6167306900024414
Validation loss: 2.3146815428169827

Epoch: 5| Step: 4
Training loss: 2.0793871879577637
Validation loss: 2.312784351328368

Epoch: 5| Step: 5
Training loss: 2.746988534927368
Validation loss: 2.3037462490861134

Epoch: 5| Step: 6
Training loss: 2.341836452484131
Validation loss: 2.305797041103404

Epoch: 5| Step: 7
Training loss: 2.200601100921631
Validation loss: 2.310036664368004

Epoch: 5| Step: 8
Training loss: 2.666195869445801
Validation loss: 2.296820911028052

Epoch: 5| Step: 9
Training loss: 2.259331464767456
Validation loss: 2.3033193862566383

Epoch: 5| Step: 10
Training loss: 3.1951847076416016
Validation loss: 2.3019658621921333

Epoch: 285| Step: 0
Training loss: 2.785428524017334
Validation loss: 2.315458374638711

Epoch: 5| Step: 1
Training loss: 2.4182353019714355
Validation loss: 2.3290576755359607

Epoch: 5| Step: 2
Training loss: 2.514949321746826
Validation loss: 2.3189837560858777

Epoch: 5| Step: 3
Training loss: 2.798089027404785
Validation loss: 2.3092860893536638

Epoch: 5| Step: 4
Training loss: 2.6632416248321533
Validation loss: 2.3134392769105974

Epoch: 5| Step: 5
Training loss: 2.6312155723571777
Validation loss: 2.311452845091461

Epoch: 5| Step: 6
Training loss: 1.9825509786605835
Validation loss: 2.3164957877128356

Epoch: 5| Step: 7
Training loss: 2.8383712768554688
Validation loss: 2.3155771827185028

Epoch: 5| Step: 8
Training loss: 2.394568681716919
Validation loss: 2.2967025413308093

Epoch: 5| Step: 9
Training loss: 2.690925121307373
Validation loss: 2.2897877193266347

Epoch: 5| Step: 10
Training loss: 2.3697926998138428
Validation loss: 2.296890845862768

Epoch: 286| Step: 0
Training loss: 2.18207049369812
Validation loss: 2.299579612670406

Epoch: 5| Step: 1
Training loss: 2.6139979362487793
Validation loss: 2.2982360342497468

Epoch: 5| Step: 2
Training loss: 2.820115089416504
Validation loss: 2.3108509637976207

Epoch: 5| Step: 3
Training loss: 2.888627290725708
Validation loss: 2.310677856527349

Epoch: 5| Step: 4
Training loss: 2.636373519897461
Validation loss: 2.314192810366231

Epoch: 5| Step: 5
Training loss: 3.189173698425293
Validation loss: 2.3280960539335847

Epoch: 5| Step: 6
Training loss: 2.7927086353302
Validation loss: 2.312267288084953

Epoch: 5| Step: 7
Training loss: 2.2972588539123535
Validation loss: 2.322683690696634

Epoch: 5| Step: 8
Training loss: 2.6284127235412598
Validation loss: 2.3220698577101513

Epoch: 5| Step: 9
Training loss: 1.652761459350586
Validation loss: 2.3090936624875633

Epoch: 5| Step: 10
Training loss: 2.4660677909851074
Validation loss: 2.311591799541186

Epoch: 287| Step: 0
Training loss: 2.3154399394989014
Validation loss: 2.3026809948746876

Epoch: 5| Step: 1
Training loss: 2.188215732574463
Validation loss: 2.304719158398208

Epoch: 5| Step: 2
Training loss: 2.1376917362213135
Validation loss: 2.31113653157347

Epoch: 5| Step: 3
Training loss: 2.569333791732788
Validation loss: 2.3091885082183348

Epoch: 5| Step: 4
Training loss: 3.2568182945251465
Validation loss: 2.312696894009908

Epoch: 5| Step: 5
Training loss: 2.679664373397827
Validation loss: 2.3139760391686552

Epoch: 5| Step: 6
Training loss: 2.576735496520996
Validation loss: 2.3163432716041483

Epoch: 5| Step: 7
Training loss: 2.9359819889068604
Validation loss: 2.315995272769723

Epoch: 5| Step: 8
Training loss: 2.4199185371398926
Validation loss: 2.3120510475609892

Epoch: 5| Step: 9
Training loss: 2.8814613819122314
Validation loss: 2.3115238912643923

Epoch: 5| Step: 10
Training loss: 2.153287887573242
Validation loss: 2.3189457949771675

Epoch: 288| Step: 0
Training loss: 2.227890968322754
Validation loss: 2.326897377608925

Epoch: 5| Step: 1
Training loss: 2.462433099746704
Validation loss: 2.3388132869556384

Epoch: 5| Step: 2
Training loss: 2.6324827671051025
Validation loss: 2.3563980594758065

Epoch: 5| Step: 3
Training loss: 2.1345410346984863
Validation loss: 2.3692137118308776

Epoch: 5| Step: 4
Training loss: 3.1873059272766113
Validation loss: 2.3706354684727167

Epoch: 5| Step: 5
Training loss: 3.2205257415771484
Validation loss: 2.39679221312205

Epoch: 5| Step: 6
Training loss: 2.873668670654297
Validation loss: 2.383800470700828

Epoch: 5| Step: 7
Training loss: 2.593517780303955
Validation loss: 2.380621079475649

Epoch: 5| Step: 8
Training loss: 2.0724573135375977
Validation loss: 2.36230250968728

Epoch: 5| Step: 9
Training loss: 2.9289536476135254
Validation loss: 2.36526233150113

Epoch: 5| Step: 10
Training loss: 2.003946304321289
Validation loss: 2.340221490911258

Epoch: 289| Step: 0
Training loss: 2.600310802459717
Validation loss: 2.315556626166067

Epoch: 5| Step: 1
Training loss: 2.6092472076416016
Validation loss: 2.3107924461364746

Epoch: 5| Step: 2
Training loss: 2.7050232887268066
Validation loss: 2.2891178695104455

Epoch: 5| Step: 3
Training loss: 2.2145614624023438
Validation loss: 2.288908113715469

Epoch: 5| Step: 4
Training loss: 1.5930445194244385
Validation loss: 2.2949960641963507

Epoch: 5| Step: 5
Training loss: 2.591092586517334
Validation loss: 2.304704835337977

Epoch: 5| Step: 6
Training loss: 3.079024076461792
Validation loss: 2.311020689625894

Epoch: 5| Step: 7
Training loss: 2.916658878326416
Validation loss: 2.305867947557921

Epoch: 5| Step: 8
Training loss: 3.1485817432403564
Validation loss: 2.313396907621814

Epoch: 5| Step: 9
Training loss: 2.5913593769073486
Validation loss: 2.3033616388997724

Epoch: 5| Step: 10
Training loss: 2.15248966217041
Validation loss: 2.311460946195869

Epoch: 290| Step: 0
Training loss: 2.4088191986083984
Validation loss: 2.31544312097693

Epoch: 5| Step: 1
Training loss: 2.5312187671661377
Validation loss: 2.317317126899637

Epoch: 5| Step: 2
Training loss: 2.148397922515869
Validation loss: 2.321654381290559

Epoch: 5| Step: 3
Training loss: 3.072197437286377
Validation loss: 2.334265383340979

Epoch: 5| Step: 4
Training loss: 2.666008472442627
Validation loss: 2.344118963005722

Epoch: 5| Step: 5
Training loss: 2.304769992828369
Validation loss: 2.3590309209721063

Epoch: 5| Step: 6
Training loss: 2.4408748149871826
Validation loss: 2.3590600644388506

Epoch: 5| Step: 7
Training loss: 3.1552090644836426
Validation loss: 2.355139714415355

Epoch: 5| Step: 8
Training loss: 2.3196558952331543
Validation loss: 2.354510400884895

Epoch: 5| Step: 9
Training loss: 2.555180072784424
Validation loss: 2.3577664821378645

Epoch: 5| Step: 10
Training loss: 2.5830395221710205
Validation loss: 2.3326320391829296

Epoch: 291| Step: 0
Training loss: 1.9017601013183594
Validation loss: 2.330565978122014

Epoch: 5| Step: 1
Training loss: 3.1906378269195557
Validation loss: 2.312142897677678

Epoch: 5| Step: 2
Training loss: 2.360244035720825
Validation loss: 2.3084094755111204

Epoch: 5| Step: 3
Training loss: 2.552001476287842
Validation loss: 2.309831811535743

Epoch: 5| Step: 4
Training loss: 3.001631498336792
Validation loss: 2.2987928082866054

Epoch: 5| Step: 5
Training loss: 2.1981215476989746
Validation loss: 2.3034250300417662

Epoch: 5| Step: 6
Training loss: 2.9609344005584717
Validation loss: 2.3079281289090394

Epoch: 5| Step: 7
Training loss: 2.1681039333343506
Validation loss: 2.3085473968136694

Epoch: 5| Step: 8
Training loss: 2.522871494293213
Validation loss: 2.307620781724171

Epoch: 5| Step: 9
Training loss: 2.599513292312622
Validation loss: 2.3076858853781097

Epoch: 5| Step: 10
Training loss: 2.7049036026000977
Validation loss: 2.3096267459213093

Epoch: 292| Step: 0
Training loss: 2.9475908279418945
Validation loss: 2.2981972002214

Epoch: 5| Step: 1
Training loss: 2.6958000659942627
Validation loss: 2.3017194463360693

Epoch: 5| Step: 2
Training loss: 2.0268936157226562
Validation loss: 2.2956944973238054

Epoch: 5| Step: 3
Training loss: 2.8693830966949463
Validation loss: 2.295466166670604

Epoch: 5| Step: 4
Training loss: 2.501741647720337
Validation loss: 2.295752171547182

Epoch: 5| Step: 5
Training loss: 2.783848285675049
Validation loss: 2.299885478070987

Epoch: 5| Step: 6
Training loss: 1.9067356586456299
Validation loss: 2.3007509041857976

Epoch: 5| Step: 7
Training loss: 3.0181376934051514
Validation loss: 2.3119632249237387

Epoch: 5| Step: 8
Training loss: 2.0521247386932373
Validation loss: 2.3211196417449624

Epoch: 5| Step: 9
Training loss: 3.045074462890625
Validation loss: 2.3295220534006753

Epoch: 5| Step: 10
Training loss: 2.0672879219055176
Validation loss: 2.324495559097618

Epoch: 293| Step: 0
Training loss: 2.8383634090423584
Validation loss: 2.322642810883061

Epoch: 5| Step: 1
Training loss: 2.7947540283203125
Validation loss: 2.3327078024546304

Epoch: 5| Step: 2
Training loss: 2.583199977874756
Validation loss: 2.335527405943922

Epoch: 5| Step: 3
Training loss: 2.0835061073303223
Validation loss: 2.3253163112107145

Epoch: 5| Step: 4
Training loss: 1.9981606006622314
Validation loss: 2.317312163691367

Epoch: 5| Step: 5
Training loss: 2.596768617630005
Validation loss: 2.3090514880354687

Epoch: 5| Step: 6
Training loss: 2.1911025047302246
Validation loss: 2.314821268922539

Epoch: 5| Step: 7
Training loss: 3.0218915939331055
Validation loss: 2.3034669276206725

Epoch: 5| Step: 8
Training loss: 3.2205557823181152
Validation loss: 2.3049287129473943

Epoch: 5| Step: 9
Training loss: 2.6074347496032715
Validation loss: 2.29025940228534

Epoch: 5| Step: 10
Training loss: 1.9916958808898926
Validation loss: 2.289598371392937

Epoch: 294| Step: 0
Training loss: 2.5748422145843506
Validation loss: 2.2877521745620237

Epoch: 5| Step: 1
Training loss: 2.1331522464752197
Validation loss: 2.2871192680892123

Epoch: 5| Step: 2
Training loss: 2.631476402282715
Validation loss: 2.289972430916243

Epoch: 5| Step: 3
Training loss: 2.8132991790771484
Validation loss: 2.292229237095002

Epoch: 5| Step: 4
Training loss: 2.7489633560180664
Validation loss: 2.2912888116734003

Epoch: 5| Step: 5
Training loss: 2.4492027759552
Validation loss: 2.2892351124876287

Epoch: 5| Step: 6
Training loss: 2.267629623413086
Validation loss: 2.3001443647569224

Epoch: 5| Step: 7
Training loss: 2.838508129119873
Validation loss: 2.2961310673785467

Epoch: 5| Step: 8
Training loss: 2.3051540851593018
Validation loss: 2.2903668829189834

Epoch: 5| Step: 9
Training loss: 2.8348069190979004
Validation loss: 2.296878501933108

Epoch: 5| Step: 10
Training loss: 2.3553380966186523
Validation loss: 2.298849046871226

Epoch: 295| Step: 0
Training loss: 2.833970308303833
Validation loss: 2.2913966640349357

Epoch: 5| Step: 1
Training loss: 2.590564489364624
Validation loss: 2.2925673800130046

Epoch: 5| Step: 2
Training loss: 2.6644420623779297
Validation loss: 2.2954038573849584

Epoch: 5| Step: 3
Training loss: 2.8107876777648926
Validation loss: 2.292392543567124

Epoch: 5| Step: 4
Training loss: 2.6286327838897705
Validation loss: 2.2934795630875455

Epoch: 5| Step: 5
Training loss: 1.7239787578582764
Validation loss: 2.291372065903038

Epoch: 5| Step: 6
Training loss: 2.8972277641296387
Validation loss: 2.2989524000434467

Epoch: 5| Step: 7
Training loss: 2.981189012527466
Validation loss: 2.300436791553292

Epoch: 5| Step: 8
Training loss: 1.895647406578064
Validation loss: 2.2958274374726

Epoch: 5| Step: 9
Training loss: 2.7850143909454346
Validation loss: 2.3033689042573333

Epoch: 5| Step: 10
Training loss: 1.9591262340545654
Validation loss: 2.3032894903613674

Epoch: 296| Step: 0
Training loss: 2.638308048248291
Validation loss: 2.3038651968843196

Epoch: 5| Step: 1
Training loss: 2.786686897277832
Validation loss: 2.3075771229241484

Epoch: 5| Step: 2
Training loss: 2.9595084190368652
Validation loss: 2.3152087285954464

Epoch: 5| Step: 3
Training loss: 2.138125419616699
Validation loss: 2.3201217215548278

Epoch: 5| Step: 4
Training loss: 2.7225120067596436
Validation loss: 2.303415554825978

Epoch: 5| Step: 5
Training loss: 1.7502777576446533
Validation loss: 2.287971019744873

Epoch: 5| Step: 6
Training loss: 2.793449640274048
Validation loss: 2.2859783659699144

Epoch: 5| Step: 7
Training loss: 2.5052075386047363
Validation loss: 2.292766963281939

Epoch: 5| Step: 8
Training loss: 2.549271821975708
Validation loss: 2.2995421578807216

Epoch: 5| Step: 9
Training loss: 2.6247353553771973
Validation loss: 2.306982878715761

Epoch: 5| Step: 10
Training loss: 2.4721431732177734
Validation loss: 2.312176287815135

Epoch: 297| Step: 0
Training loss: 2.5841283798217773
Validation loss: 2.298951433550927

Epoch: 5| Step: 1
Training loss: 2.331545829772949
Validation loss: 2.2962869623655915

Epoch: 5| Step: 2
Training loss: 1.8484668731689453
Validation loss: 2.306098186841575

Epoch: 5| Step: 3
Training loss: 2.5685436725616455
Validation loss: 2.308185910665861

Epoch: 5| Step: 4
Training loss: 3.0017590522766113
Validation loss: 2.2979939189008487

Epoch: 5| Step: 5
Training loss: 2.2224040031433105
Validation loss: 2.296251158560476

Epoch: 5| Step: 6
Training loss: 2.637423038482666
Validation loss: 2.296288036531018

Epoch: 5| Step: 7
Training loss: 3.1454825401306152
Validation loss: 2.3011099702568463

Epoch: 5| Step: 8
Training loss: 2.671535015106201
Validation loss: 2.2984839306082776

Epoch: 5| Step: 9
Training loss: 2.574265718460083
Validation loss: 2.291005160218926

Epoch: 5| Step: 10
Training loss: 2.2576351165771484
Validation loss: 2.3007684112876974

Epoch: 298| Step: 0
Training loss: 1.8289499282836914
Validation loss: 2.2974649783103698

Epoch: 5| Step: 1
Training loss: 2.61911940574646
Validation loss: 2.297299079997565

Epoch: 5| Step: 2
Training loss: 2.1904287338256836
Validation loss: 2.2961702705711446

Epoch: 5| Step: 3
Training loss: 3.3070685863494873
Validation loss: 2.294910074562155

Epoch: 5| Step: 4
Training loss: 2.691331148147583
Validation loss: 2.2936173356989378

Epoch: 5| Step: 5
Training loss: 2.384458065032959
Validation loss: 2.2953832072596394

Epoch: 5| Step: 6
Training loss: 2.746586322784424
Validation loss: 2.2876439325271116

Epoch: 5| Step: 7
Training loss: 2.7124476432800293
Validation loss: 2.2933553944351854

Epoch: 5| Step: 8
Training loss: 1.796318769454956
Validation loss: 2.2910431444004016

Epoch: 5| Step: 9
Training loss: 3.233635663986206
Validation loss: 2.305415394485638

Epoch: 5| Step: 10
Training loss: 2.3733253479003906
Validation loss: 2.3016692592251684

Epoch: 299| Step: 0
Training loss: 2.3534278869628906
Validation loss: 2.2992865449638775

Epoch: 5| Step: 1
Training loss: 3.0827531814575195
Validation loss: 2.303375820959768

Epoch: 5| Step: 2
Training loss: 2.334726333618164
Validation loss: 2.314477200149208

Epoch: 5| Step: 3
Training loss: 2.3733794689178467
Validation loss: 2.3059624189971597

Epoch: 5| Step: 4
Training loss: 2.735905170440674
Validation loss: 2.3052455481662544

Epoch: 5| Step: 5
Training loss: 2.4198508262634277
Validation loss: 2.306379013164069

Epoch: 5| Step: 6
Training loss: 2.6384549140930176
Validation loss: 2.293572464296895

Epoch: 5| Step: 7
Training loss: 2.36348032951355
Validation loss: 2.2879225618095806

Epoch: 5| Step: 8
Training loss: 2.425276279449463
Validation loss: 2.2870372982435327

Epoch: 5| Step: 9
Training loss: 2.5217528343200684
Validation loss: 2.2822515144143054

Epoch: 5| Step: 10
Training loss: 2.6738226413726807
Validation loss: 2.290486083235792

Epoch: 300| Step: 0
Training loss: 2.166740894317627
Validation loss: 2.2900157436247794

Epoch: 5| Step: 1
Training loss: 2.1857359409332275
Validation loss: 2.302547472779469

Epoch: 5| Step: 2
Training loss: 3.032646656036377
Validation loss: 2.3007460589049966

Epoch: 5| Step: 3
Training loss: 2.157073974609375
Validation loss: 2.299052681974185

Epoch: 5| Step: 4
Training loss: 2.762514114379883
Validation loss: 2.292902046634305

Epoch: 5| Step: 5
Training loss: 1.8969342708587646
Validation loss: 2.292041331209162

Epoch: 5| Step: 6
Training loss: 2.579348564147949
Validation loss: 2.293872183369052

Epoch: 5| Step: 7
Training loss: 2.3689017295837402
Validation loss: 2.2899962240649807

Epoch: 5| Step: 8
Training loss: 2.1883347034454346
Validation loss: 2.294017791748047

Epoch: 5| Step: 9
Training loss: 3.170319080352783
Validation loss: 2.2944892606427594

Epoch: 5| Step: 10
Training loss: 3.3426365852355957
Validation loss: 2.296288428768035

Testing loss: 2.4790904654396906
