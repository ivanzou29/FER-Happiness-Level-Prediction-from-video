Epoch: 1| Step: 0
Training loss: 6.039684031729226
Validation loss: 5.767363712439713

Epoch: 6| Step: 1
Training loss: 6.733993484063391
Validation loss: 5.759775502531119

Epoch: 6| Step: 2
Training loss: 5.55773962110901
Validation loss: 5.7519459973747304

Epoch: 6| Step: 3
Training loss: 5.226206495080694
Validation loss: 5.7445609935442565

Epoch: 6| Step: 4
Training loss: 4.340501627257004
Validation loss: 5.73668895313955

Epoch: 6| Step: 5
Training loss: 5.933824545996939
Validation loss: 5.729486194399826

Epoch: 6| Step: 6
Training loss: 6.626612916775756
Validation loss: 5.721590888117056

Epoch: 6| Step: 7
Training loss: 4.519247219224325
Validation loss: 5.7141572964209635

Epoch: 6| Step: 8
Training loss: 7.189187291336352
Validation loss: 5.706183859759423

Epoch: 6| Step: 9
Training loss: 4.928971469826764
Validation loss: 5.699179273382021

Epoch: 6| Step: 10
Training loss: 5.583095014050279
Validation loss: 5.69098434085404

Epoch: 6| Step: 11
Training loss: 6.450004506664032
Validation loss: 5.683370824660171

Epoch: 6| Step: 12
Training loss: 4.695156507392086
Validation loss: 5.676141058251353

Epoch: 6| Step: 13
Training loss: 6.026703222608397
Validation loss: 5.666879491893179

Epoch: 2| Step: 0
Training loss: 5.516642274063134
Validation loss: 5.658845264283654

Epoch: 6| Step: 1
Training loss: 6.603605741953862
Validation loss: 5.649638283247859

Epoch: 6| Step: 2
Training loss: 6.851091740615511
Validation loss: 5.640453594285997

Epoch: 6| Step: 3
Training loss: 5.608621105653965
Validation loss: 5.630579710718892

Epoch: 6| Step: 4
Training loss: 3.9443759524229853
Validation loss: 5.620320726250235

Epoch: 6| Step: 5
Training loss: 5.342429014527807
Validation loss: 5.610604310450412

Epoch: 6| Step: 6
Training loss: 6.624012423628062
Validation loss: 5.599081600708621

Epoch: 6| Step: 7
Training loss: 5.172843911494955
Validation loss: 5.589761512475715

Epoch: 6| Step: 8
Training loss: 5.1330547769114485
Validation loss: 5.577054696471884

Epoch: 6| Step: 9
Training loss: 5.826720203936425
Validation loss: 5.565160928111258

Epoch: 6| Step: 10
Training loss: 5.030706340726031
Validation loss: 5.55263729926119

Epoch: 6| Step: 11
Training loss: 4.553947480218441
Validation loss: 5.538854452453667

Epoch: 6| Step: 12
Training loss: 6.151799641118271
Validation loss: 5.527530556767293

Epoch: 6| Step: 13
Training loss: 5.8190493858013035
Validation loss: 5.51273713180259

Epoch: 3| Step: 0
Training loss: 4.279501676337833
Validation loss: 5.499170501818388

Epoch: 6| Step: 1
Training loss: 6.11784973067731
Validation loss: 5.484613737380359

Epoch: 6| Step: 2
Training loss: 6.167684556962155
Validation loss: 5.468962231339931

Epoch: 6| Step: 3
Training loss: 4.973527830443919
Validation loss: 5.452121328094166

Epoch: 6| Step: 4
Training loss: 5.19900193539756
Validation loss: 5.436699758975578

Epoch: 6| Step: 5
Training loss: 4.735732686476169
Validation loss: 5.4190705233831125

Epoch: 6| Step: 6
Training loss: 5.705561203764477
Validation loss: 5.401780782524132

Epoch: 6| Step: 7
Training loss: 6.487584507856682
Validation loss: 5.384039635693433

Epoch: 6| Step: 8
Training loss: 3.676663267584227
Validation loss: 5.366467681866546

Epoch: 6| Step: 9
Training loss: 5.7143878246448425
Validation loss: 5.3491122932594015

Epoch: 6| Step: 10
Training loss: 6.196445972328677
Validation loss: 5.330876031700592

Epoch: 6| Step: 11
Training loss: 4.378024554410749
Validation loss: 5.312502829775941

Epoch: 6| Step: 12
Training loss: 6.134276546984396
Validation loss: 5.294817423076112

Epoch: 6| Step: 13
Training loss: 5.463149161796526
Validation loss: 5.275811640051577

Epoch: 4| Step: 0
Training loss: 4.377526126175783
Validation loss: 5.255829414245729

Epoch: 6| Step: 1
Training loss: 4.66128534035087
Validation loss: 5.2388057796813365

Epoch: 6| Step: 2
Training loss: 5.68696138954639
Validation loss: 5.219678700237037

Epoch: 6| Step: 3
Training loss: 5.491022933409094
Validation loss: 5.2017931677440075

Epoch: 6| Step: 4
Training loss: 4.340440106556421
Validation loss: 5.1823693591847855

Epoch: 6| Step: 5
Training loss: 6.434477457617509
Validation loss: 5.16420131431806

Epoch: 6| Step: 6
Training loss: 4.898788123229453
Validation loss: 5.144045513181317

Epoch: 6| Step: 7
Training loss: 5.85930501260285
Validation loss: 5.12659741589582

Epoch: 6| Step: 8
Training loss: 4.618518721348151
Validation loss: 5.107331353586146

Epoch: 6| Step: 9
Training loss: 4.801279437891806
Validation loss: 5.087083792982836

Epoch: 6| Step: 10
Training loss: 5.4221887854985225
Validation loss: 5.068658263062146

Epoch: 6| Step: 11
Training loss: 5.250480993126219
Validation loss: 5.0480488195293995

Epoch: 6| Step: 12
Training loss: 5.119016550504202
Validation loss: 5.02705329236789

Epoch: 6| Step: 13
Training loss: 5.346013175494295
Validation loss: 5.006262542781409

Epoch: 5| Step: 0
Training loss: 5.48837264992843
Validation loss: 4.98274702710586

Epoch: 6| Step: 1
Training loss: 5.991651448887939
Validation loss: 4.959825093661751

Epoch: 6| Step: 2
Training loss: 5.030239975287897
Validation loss: 4.933898999998419

Epoch: 6| Step: 3
Training loss: 4.787208185689731
Validation loss: 4.9091121971885805

Epoch: 6| Step: 4
Training loss: 6.066769070162766
Validation loss: 4.884183882098241

Epoch: 6| Step: 5
Training loss: 5.2350246652570425
Validation loss: 4.859318067917958

Epoch: 6| Step: 6
Training loss: 4.394727426176807
Validation loss: 4.837740450765103

Epoch: 6| Step: 7
Training loss: 4.5325492311677085
Validation loss: 4.814503058312059

Epoch: 6| Step: 8
Training loss: 3.963720544027727
Validation loss: 4.7946059055695835

Epoch: 6| Step: 9
Training loss: 4.9179470313261495
Validation loss: 4.775077243741313

Epoch: 6| Step: 10
Training loss: 4.933433113291919
Validation loss: 4.757893230774995

Epoch: 6| Step: 11
Training loss: 5.014895947670978
Validation loss: 4.740109360406286

Epoch: 6| Step: 12
Training loss: 3.08697384200461
Validation loss: 4.724239574304474

Epoch: 6| Step: 13
Training loss: 4.409187582184239
Validation loss: 4.70848495467227

Epoch: 6| Step: 0
Training loss: 4.407019798184133
Validation loss: 4.6918826402538025

Epoch: 6| Step: 1
Training loss: 5.19132009281168
Validation loss: 4.677682417210795

Epoch: 6| Step: 2
Training loss: 4.713291876762117
Validation loss: 4.664280234355545

Epoch: 6| Step: 3
Training loss: 4.246983074415884
Validation loss: 4.648044444992596

Epoch: 6| Step: 4
Training loss: 4.752039421354728
Validation loss: 4.637196702776591

Epoch: 6| Step: 5
Training loss: 4.568375240459838
Validation loss: 4.623009261856741

Epoch: 6| Step: 6
Training loss: 4.32701146092582
Validation loss: 4.609260194188886

Epoch: 6| Step: 7
Training loss: 5.312652406189328
Validation loss: 4.59764717676805

Epoch: 6| Step: 8
Training loss: 3.926941536013811
Validation loss: 4.584737332593348

Epoch: 6| Step: 9
Training loss: 5.777678505134342
Validation loss: 4.573645124910403

Epoch: 6| Step: 10
Training loss: 4.662274655375657
Validation loss: 4.560380280031909

Epoch: 6| Step: 11
Training loss: 4.158398065974163
Validation loss: 4.548944773842445

Epoch: 6| Step: 12
Training loss: 4.398477178093124
Validation loss: 4.536645610792078

Epoch: 6| Step: 13
Training loss: 5.222665014951509
Validation loss: 4.52575852671886

Epoch: 7| Step: 0
Training loss: 3.9878106357990704
Validation loss: 4.512538180307478

Epoch: 6| Step: 1
Training loss: 4.934755165960479
Validation loss: 4.4998711165335195

Epoch: 6| Step: 2
Training loss: 5.423310279508022
Validation loss: 4.488675332334201

Epoch: 6| Step: 3
Training loss: 4.9384868939295234
Validation loss: 4.475122730329509

Epoch: 6| Step: 4
Training loss: 4.98579544347977
Validation loss: 4.458178560738646

Epoch: 6| Step: 5
Training loss: 3.2034483211439877
Validation loss: 4.446139494020725

Epoch: 6| Step: 6
Training loss: 5.420962561968732
Validation loss: 4.434249706675318

Epoch: 6| Step: 7
Training loss: 3.9312628134805214
Validation loss: 4.423372167190285

Epoch: 6| Step: 8
Training loss: 4.282837510757872
Validation loss: 4.412153545932543

Epoch: 6| Step: 9
Training loss: 4.799651594233209
Validation loss: 4.402557075254761

Epoch: 6| Step: 10
Training loss: 4.618205673085167
Validation loss: 4.393152962995991

Epoch: 6| Step: 11
Training loss: 4.5365027138268745
Validation loss: 4.382689131745251

Epoch: 6| Step: 12
Training loss: 4.0072618370178805
Validation loss: 4.371885200520312

Epoch: 6| Step: 13
Training loss: 3.603736337244847
Validation loss: 4.361410018187088

Epoch: 8| Step: 0
Training loss: 5.6633320514991095
Validation loss: 4.3507956960365854

Epoch: 6| Step: 1
Training loss: 4.119335099427692
Validation loss: 4.339957735377463

Epoch: 6| Step: 2
Training loss: 5.4710901103755925
Validation loss: 4.330118896023637

Epoch: 6| Step: 3
Training loss: 4.265045909209656
Validation loss: 4.318817352889978

Epoch: 6| Step: 4
Training loss: 3.762541588841733
Validation loss: 4.3082279317070755

Epoch: 6| Step: 5
Training loss: 4.31482932167604
Validation loss: 4.297352575049252

Epoch: 6| Step: 6
Training loss: 4.779901251950039
Validation loss: 4.2865230661225

Epoch: 6| Step: 7
Training loss: 4.243857713548686
Validation loss: 4.277089412805106

Epoch: 6| Step: 8
Training loss: 3.853397574455728
Validation loss: 4.26790351328347

Epoch: 6| Step: 9
Training loss: 4.592475766287769
Validation loss: 4.257239013898033

Epoch: 6| Step: 10
Training loss: 3.694515731111015
Validation loss: 4.24925964778745

Epoch: 6| Step: 11
Training loss: 4.434839230002783
Validation loss: 4.237825334204544

Epoch: 6| Step: 12
Training loss: 3.7351173078098343
Validation loss: 4.230098080884277

Epoch: 6| Step: 13
Training loss: 4.215358020424415
Validation loss: 4.218798713600331

Epoch: 9| Step: 0
Training loss: 3.6877012036275834
Validation loss: 4.211097074559536

Epoch: 6| Step: 1
Training loss: 5.099868189286435
Validation loss: 4.200661447135917

Epoch: 6| Step: 2
Training loss: 3.3391369523497914
Validation loss: 4.192896439522265

Epoch: 6| Step: 3
Training loss: 4.464367191116145
Validation loss: 4.181913113711202

Epoch: 6| Step: 4
Training loss: 3.9507482568420413
Validation loss: 4.174326550397837

Epoch: 6| Step: 5
Training loss: 3.7227182453192995
Validation loss: 4.166523680335725

Epoch: 6| Step: 6
Training loss: 5.045104480943166
Validation loss: 4.156933987497431

Epoch: 6| Step: 7
Training loss: 4.264096387908122
Validation loss: 4.149195423307369

Epoch: 6| Step: 8
Training loss: 5.22048080890052
Validation loss: 4.138613619150935

Epoch: 6| Step: 9
Training loss: 4.788731524681512
Validation loss: 4.1301141671853845

Epoch: 6| Step: 10
Training loss: 2.9522774908217047
Validation loss: 4.1204068716684406

Epoch: 6| Step: 11
Training loss: 4.599106967319915
Validation loss: 4.111848925347277

Epoch: 6| Step: 12
Training loss: 4.285955585771173
Validation loss: 4.101232633124649

Epoch: 6| Step: 13
Training loss: 3.590718458534714
Validation loss: 4.091123235269907

Epoch: 10| Step: 0
Training loss: 4.382644078899683
Validation loss: 4.082099885633877

Epoch: 6| Step: 1
Training loss: 4.215067747030948
Validation loss: 4.072331471487613

Epoch: 6| Step: 2
Training loss: 5.337713390078109
Validation loss: 4.060561235742179

Epoch: 6| Step: 3
Training loss: 3.870133327977004
Validation loss: 4.050100947795251

Epoch: 6| Step: 4
Training loss: 3.2070789775015096
Validation loss: 4.038904889098618

Epoch: 6| Step: 5
Training loss: 3.8560311971011823
Validation loss: 4.029412085525296

Epoch: 6| Step: 6
Training loss: 3.8615963369481343
Validation loss: 4.021084666612601

Epoch: 6| Step: 7
Training loss: 4.0763606789497535
Validation loss: 4.010658973860443

Epoch: 6| Step: 8
Training loss: 4.170733692199731
Validation loss: 4.000129546354452

Epoch: 6| Step: 9
Training loss: 4.686726824255422
Validation loss: 3.988506537561246

Epoch: 6| Step: 10
Training loss: 4.943740377886989
Validation loss: 3.979483491903307

Epoch: 6| Step: 11
Training loss: 3.6295725166674324
Validation loss: 3.9683157796582145

Epoch: 6| Step: 12
Training loss: 3.809610491288698
Validation loss: 3.9593097633123118

Epoch: 6| Step: 13
Training loss: 3.5017703892123837
Validation loss: 3.94776971989274

Epoch: 11| Step: 0
Training loss: 4.207332277995278
Validation loss: 3.9363182730918926

Epoch: 6| Step: 1
Training loss: 3.2455958823505373
Validation loss: 3.927186078680263

Epoch: 6| Step: 2
Training loss: 4.081177018872742
Validation loss: 3.9153047291324943

Epoch: 6| Step: 3
Training loss: 4.296285470922091
Validation loss: 3.9050098404664437

Epoch: 6| Step: 4
Training loss: 3.2212545779887343
Validation loss: 3.8955227777057906

Epoch: 6| Step: 5
Training loss: 4.725461519498982
Validation loss: 3.886369123897281

Epoch: 6| Step: 6
Training loss: 3.8223151514180844
Validation loss: 3.875334429856102

Epoch: 6| Step: 7
Training loss: 3.8575833134730533
Validation loss: 3.86444860847713

Epoch: 6| Step: 8
Training loss: 4.063030267000422
Validation loss: 3.8567842188308568

Epoch: 6| Step: 9
Training loss: 3.5760364017212614
Validation loss: 3.848655910711818

Epoch: 6| Step: 10
Training loss: 3.8324702300167766
Validation loss: 3.8381061472461475

Epoch: 6| Step: 11
Training loss: 3.8795918975616464
Validation loss: 3.8289024529585345

Epoch: 6| Step: 12
Training loss: 4.83266238236278
Validation loss: 3.8195086738105593

Epoch: 6| Step: 13
Training loss: 4.75258826962952
Validation loss: 3.809547923472477

Epoch: 12| Step: 0
Training loss: 2.6686094081751417
Validation loss: 3.797415846019033

Epoch: 6| Step: 1
Training loss: 4.6235202793498775
Validation loss: 3.7943834841607873

Epoch: 6| Step: 2
Training loss: 3.6768740125230406
Validation loss: 3.7840737836919556

Epoch: 6| Step: 3
Training loss: 3.4640559146940677
Validation loss: 3.776968161272139

Epoch: 6| Step: 4
Training loss: 4.494871820270747
Validation loss: 3.768805918384733

Epoch: 6| Step: 5
Training loss: 3.9175671022628857
Validation loss: 3.7627610453697344

Epoch: 6| Step: 6
Training loss: 4.3280260646267905
Validation loss: 3.7567622532859892

Epoch: 6| Step: 7
Training loss: 3.6331269815158347
Validation loss: 3.747816494720827

Epoch: 6| Step: 8
Training loss: 3.9988144071208978
Validation loss: 3.7436234407680353

Epoch: 6| Step: 9
Training loss: 4.480722674596756
Validation loss: 3.736562674272774

Epoch: 6| Step: 10
Training loss: 3.697550896119556
Validation loss: 3.730527591783515

Epoch: 6| Step: 11
Training loss: 3.763037081180681
Validation loss: 3.723937486136568

Epoch: 6| Step: 12
Training loss: 3.490845834274535
Validation loss: 3.7192718782169614

Epoch: 6| Step: 13
Training loss: 4.563093799985468
Validation loss: 3.715019131098902

Epoch: 13| Step: 0
Training loss: 3.2026241748329776
Validation loss: 3.7097185503555155

Epoch: 6| Step: 1
Training loss: 4.076932652410991
Validation loss: 3.7055180947492006

Epoch: 6| Step: 2
Training loss: 3.014437426815011
Validation loss: 3.701818585090746

Epoch: 6| Step: 3
Training loss: 3.9224365561844947
Validation loss: 3.698856960870814

Epoch: 6| Step: 4
Training loss: 3.304435702351329
Validation loss: 3.6944859985766434

Epoch: 6| Step: 5
Training loss: 3.96195293705509
Validation loss: 3.691008617025523

Epoch: 6| Step: 6
Training loss: 4.199502624852445
Validation loss: 3.686812559037954

Epoch: 6| Step: 7
Training loss: 3.9319292655162856
Validation loss: 3.681416583420489

Epoch: 6| Step: 8
Training loss: 4.363861291319082
Validation loss: 3.6799443506274985

Epoch: 6| Step: 9
Training loss: 4.409469834895519
Validation loss: 3.6753056062947493

Epoch: 6| Step: 10
Training loss: 4.255693548857472
Validation loss: 3.6701977294140007

Epoch: 6| Step: 11
Training loss: 3.5638751671846465
Validation loss: 3.6689121095992867

Epoch: 6| Step: 12
Training loss: 3.389097370620801
Validation loss: 3.6597943539593296

Epoch: 6| Step: 13
Training loss: 4.500171022344226
Validation loss: 3.6575824871197082

Epoch: 14| Step: 0
Training loss: 3.769317589273442
Validation loss: 3.6551274281114514

Epoch: 6| Step: 1
Training loss: 3.533784480053197
Validation loss: 3.6512014716763463

Epoch: 6| Step: 2
Training loss: 4.757843769139858
Validation loss: 3.6471781196807385

Epoch: 6| Step: 3
Training loss: 3.3534175123060384
Validation loss: 3.6443699857095497

Epoch: 6| Step: 4
Training loss: 3.9741415812321312
Validation loss: 3.6403443483002835

Epoch: 6| Step: 5
Training loss: 3.142973216501922
Validation loss: 3.636238917431163

Epoch: 6| Step: 6
Training loss: 3.8569031494577195
Validation loss: 3.6336976348118784

Epoch: 6| Step: 7
Training loss: 4.23574570433034
Validation loss: 3.630952515726629

Epoch: 6| Step: 8
Training loss: 3.662348950496809
Validation loss: 3.6269262441412464

Epoch: 6| Step: 9
Training loss: 4.0584121090699865
Validation loss: 3.6233726670527298

Epoch: 6| Step: 10
Training loss: 3.6283835043802077
Validation loss: 3.6204997350683863

Epoch: 6| Step: 11
Training loss: 4.578919846209127
Validation loss: 3.6176295685728954

Epoch: 6| Step: 12
Training loss: 3.2492490047468867
Validation loss: 3.612275498977114

Epoch: 6| Step: 13
Training loss: 2.967771348767363
Validation loss: 3.6092575544932837

Epoch: 15| Step: 0
Training loss: 3.7046199308143755
Validation loss: 3.6085764429458904

Epoch: 6| Step: 1
Training loss: 4.0287363658251785
Validation loss: 3.6048831392343383

Epoch: 6| Step: 2
Training loss: 3.355615259597974
Validation loss: 3.601990452412449

Epoch: 6| Step: 3
Training loss: 4.020866565204653
Validation loss: 3.5979820453917433

Epoch: 6| Step: 4
Training loss: 4.517646944055369
Validation loss: 3.593540113115218

Epoch: 6| Step: 5
Training loss: 4.486435898452451
Validation loss: 3.5925160005483607

Epoch: 6| Step: 6
Training loss: 3.870065562163558
Validation loss: 3.590825628514833

Epoch: 6| Step: 7
Training loss: 3.5642578071486795
Validation loss: 3.589515900391677

Epoch: 6| Step: 8
Training loss: 3.0775709863900023
Validation loss: 3.582647547497367

Epoch: 6| Step: 9
Training loss: 2.8925743334820693
Validation loss: 3.577654916452925

Epoch: 6| Step: 10
Training loss: 4.6269467354984375
Validation loss: 3.5753912016019167

Epoch: 6| Step: 11
Training loss: 2.9082862529569167
Validation loss: 3.571361868714477

Epoch: 6| Step: 12
Training loss: 3.6749838796249064
Validation loss: 3.566853238070489

Epoch: 6| Step: 13
Training loss: 3.6775111020748517
Validation loss: 3.565086968323068

Epoch: 16| Step: 0
Training loss: 3.9118503555274873
Validation loss: 3.562232083182624

Epoch: 6| Step: 1
Training loss: 3.1507011965251728
Validation loss: 3.5583129849857973

Epoch: 6| Step: 2
Training loss: 3.8101949759027467
Validation loss: 3.5532817214981978

Epoch: 6| Step: 3
Training loss: 3.9550950038220085
Validation loss: 3.547658459626524

Epoch: 6| Step: 4
Training loss: 3.5705552968079735
Validation loss: 3.5473016132951356

Epoch: 6| Step: 5
Training loss: 4.103031730899192
Validation loss: 3.540046273919703

Epoch: 6| Step: 6
Training loss: 4.255056178509914
Validation loss: 3.536683964932061

Epoch: 6| Step: 7
Training loss: 3.6464786212796065
Validation loss: 3.5382060222257916

Epoch: 6| Step: 8
Training loss: 3.2740713885056403
Validation loss: 3.532635555529446

Epoch: 6| Step: 9
Training loss: 4.259064600515271
Validation loss: 3.5277134839377364

Epoch: 6| Step: 10
Training loss: 3.1014259750336266
Validation loss: 3.5244796685404087

Epoch: 6| Step: 11
Training loss: 3.2680322271133084
Validation loss: 3.5216039629859135

Epoch: 6| Step: 12
Training loss: 3.57012364662246
Validation loss: 3.518617239240424

Epoch: 6| Step: 13
Training loss: 4.577109787380821
Validation loss: 3.516617555503294

Epoch: 17| Step: 0
Training loss: 3.8089531831595758
Validation loss: 3.5151860693012997

Epoch: 6| Step: 1
Training loss: 4.64969188530766
Validation loss: 3.5139418293783033

Epoch: 6| Step: 2
Training loss: 3.7183108030349357
Validation loss: 3.5122838909342358

Epoch: 6| Step: 3
Training loss: 4.424773974492007
Validation loss: 3.5100957174157132

Epoch: 6| Step: 4
Training loss: 3.1235891590635187
Validation loss: 3.5070906463063256

Epoch: 6| Step: 5
Training loss: 4.236274321422395
Validation loss: 3.503470750876818

Epoch: 6| Step: 6
Training loss: 3.0105627391887713
Validation loss: 3.4965018400809638

Epoch: 6| Step: 7
Training loss: 2.7198872434862174
Validation loss: 3.4946870104881755

Epoch: 6| Step: 8
Training loss: 2.9144522480438635
Validation loss: 3.4954909990630054

Epoch: 6| Step: 9
Training loss: 3.6060625209370993
Validation loss: 3.497281405997837

Epoch: 6| Step: 10
Training loss: 2.9753731181073015
Validation loss: 3.4951333169527397

Epoch: 6| Step: 11
Training loss: 4.034288311181339
Validation loss: 3.483030698066302

Epoch: 6| Step: 12
Training loss: 4.327907735831836
Validation loss: 3.4754478740815116

Epoch: 6| Step: 13
Training loss: 3.682759486817479
Validation loss: 3.4767938698900767

Epoch: 18| Step: 0
Training loss: 3.9616596233309056
Validation loss: 3.4754086002581435

Epoch: 6| Step: 1
Training loss: 4.057480748495803
Validation loss: 3.4705621711500965

Epoch: 6| Step: 2
Training loss: 3.8486538750692363
Validation loss: 3.4678280192739326

Epoch: 6| Step: 3
Training loss: 3.497552833621618
Validation loss: 3.4672031221988555

Epoch: 6| Step: 4
Training loss: 3.7129449494233993
Validation loss: 3.462227343058595

Epoch: 6| Step: 5
Training loss: 3.0427830532937477
Validation loss: 3.459038757499644

Epoch: 6| Step: 6
Training loss: 3.745534272325973
Validation loss: 3.4561842596255112

Epoch: 6| Step: 7
Training loss: 4.634285343715108
Validation loss: 3.4542488025639457

Epoch: 6| Step: 8
Training loss: 3.689957914861923
Validation loss: 3.4518221318888904

Epoch: 6| Step: 9
Training loss: 2.518620952016989
Validation loss: 3.44992983709406

Epoch: 6| Step: 10
Training loss: 3.781200566244532
Validation loss: 3.4441239138610267

Epoch: 6| Step: 11
Training loss: 3.9894951926007716
Validation loss: 3.440997536832621

Epoch: 6| Step: 12
Training loss: 3.012437469973119
Validation loss: 3.4351742018155664

Epoch: 6| Step: 13
Training loss: 3.28469232102473
Validation loss: 3.431174694029644

Epoch: 19| Step: 0
Training loss: 3.9502310431789467
Validation loss: 3.4304806186563948

Epoch: 6| Step: 1
Training loss: 4.186108258257724
Validation loss: 3.427302001256637

Epoch: 6| Step: 2
Training loss: 3.7823875544664403
Validation loss: 3.4232343931970046

Epoch: 6| Step: 3
Training loss: 3.7364434933835207
Validation loss: 3.4229309532509444

Epoch: 6| Step: 4
Training loss: 3.4228179886459693
Validation loss: 3.4190181355796816

Epoch: 6| Step: 5
Training loss: 4.101329048415758
Validation loss: 3.4150784420451887

Epoch: 6| Step: 6
Training loss: 3.6004515152813266
Validation loss: 3.413305726464434

Epoch: 6| Step: 7
Training loss: 3.8769672691413906
Validation loss: 3.411057166539381

Epoch: 6| Step: 8
Training loss: 2.9554142228213274
Validation loss: 3.408181422539084

Epoch: 6| Step: 9
Training loss: 3.642241156079329
Validation loss: 3.406490739268763

Epoch: 6| Step: 10
Training loss: 4.097374396362837
Validation loss: 3.400764059900498

Epoch: 6| Step: 11
Training loss: 2.7436397869245717
Validation loss: 3.3997990557883218

Epoch: 6| Step: 12
Training loss: 3.3132853026973565
Validation loss: 3.400763107043387

Epoch: 6| Step: 13
Training loss: 2.767087043476724
Validation loss: 3.3974934504916687

Epoch: 20| Step: 0
Training loss: 3.5157641574021476
Validation loss: 3.397786948257353

Epoch: 6| Step: 1
Training loss: 3.107377680782526
Validation loss: 3.394783350415818

Epoch: 6| Step: 2
Training loss: 3.345070266327738
Validation loss: 3.3872114569844425

Epoch: 6| Step: 3
Training loss: 3.7584628932187356
Validation loss: 3.38434660528316

Epoch: 6| Step: 4
Training loss: 3.067291248683119
Validation loss: 3.382247256528337

Epoch: 6| Step: 5
Training loss: 3.043190474261228
Validation loss: 3.381488226999873

Epoch: 6| Step: 6
Training loss: 4.15561390074798
Validation loss: 3.3807529144957265

Epoch: 6| Step: 7
Training loss: 3.9917746851142226
Validation loss: 3.3835811746278237

Epoch: 6| Step: 8
Training loss: 3.416803512313849
Validation loss: 3.3736684687590457

Epoch: 6| Step: 9
Training loss: 3.530330301884694
Validation loss: 3.368303873199859

Epoch: 6| Step: 10
Training loss: 4.077064814823584
Validation loss: 3.365442797439497

Epoch: 6| Step: 11
Training loss: 4.149198128317353
Validation loss: 3.3669392982713306

Epoch: 6| Step: 12
Training loss: 3.421337904213726
Validation loss: 3.3638780309826384

Epoch: 6| Step: 13
Training loss: 3.6863054830024153
Validation loss: 3.369227328998692

Epoch: 21| Step: 0
Training loss: 4.1038553858926745
Validation loss: 3.364840582852464

Epoch: 6| Step: 1
Training loss: 2.92965185525191
Validation loss: 3.3609479331044554

Epoch: 6| Step: 2
Training loss: 3.3709808719695475
Validation loss: 3.3542648257245915

Epoch: 6| Step: 3
Training loss: 2.8189257649433976
Validation loss: 3.352390589252894

Epoch: 6| Step: 4
Training loss: 3.8708749780512317
Validation loss: 3.3473537477492785

Epoch: 6| Step: 5
Training loss: 3.142214548382463
Validation loss: 3.3456261406409458

Epoch: 6| Step: 6
Training loss: 3.6534170277144047
Validation loss: 3.341810625267277

Epoch: 6| Step: 7
Training loss: 4.292695499293911
Validation loss: 3.3418105853759337

Epoch: 6| Step: 8
Training loss: 3.2389850288838917
Validation loss: 3.338975031867852

Epoch: 6| Step: 9
Training loss: 3.773372673283403
Validation loss: 3.335488104905333

Epoch: 6| Step: 10
Training loss: 4.231814578099221
Validation loss: 3.3360437284680344

Epoch: 6| Step: 11
Training loss: 3.2517790693378434
Validation loss: 3.330819174436258

Epoch: 6| Step: 12
Training loss: 3.427429011727614
Validation loss: 3.324401137104438

Epoch: 6| Step: 13
Training loss: 3.552715316142529
Validation loss: 3.325460239607134

Epoch: 22| Step: 0
Training loss: 3.8982269903005538
Validation loss: 3.320815948981422

Epoch: 6| Step: 1
Training loss: 3.4915608434793546
Validation loss: 3.3198102998089785

Epoch: 6| Step: 2
Training loss: 3.9870751899037833
Validation loss: 3.3169809017470318

Epoch: 6| Step: 3
Training loss: 3.53716087198501
Validation loss: 3.314214889789122

Epoch: 6| Step: 4
Training loss: 2.9628384811248782
Validation loss: 3.3111657512342028

Epoch: 6| Step: 5
Training loss: 2.0680769456460735
Validation loss: 3.3116736314830795

Epoch: 6| Step: 6
Training loss: 3.5089935829188716
Validation loss: 3.3096566235523968

Epoch: 6| Step: 7
Training loss: 4.001652376296904
Validation loss: 3.3117850056919322

Epoch: 6| Step: 8
Training loss: 3.5005440970254504
Validation loss: 3.3135011026622836

Epoch: 6| Step: 9
Training loss: 3.59456777804875
Validation loss: 3.3101192346142976

Epoch: 6| Step: 10
Training loss: 3.6776044582569782
Validation loss: 3.304928545089505

Epoch: 6| Step: 11
Training loss: 4.338471423157099
Validation loss: 3.2992498626010867

Epoch: 6| Step: 12
Training loss: 3.3835159521819067
Validation loss: 3.292070223607425

Epoch: 6| Step: 13
Training loss: 2.849863711662161
Validation loss: 3.2895559244243335

Epoch: 23| Step: 0
Training loss: 3.4356143287685885
Validation loss: 3.2888181039906326

Epoch: 6| Step: 1
Training loss: 4.494211712755351
Validation loss: 3.287279574445768

Epoch: 6| Step: 2
Training loss: 3.4291291010403153
Validation loss: 3.2834052239216076

Epoch: 6| Step: 3
Training loss: 2.5245065225753796
Validation loss: 3.2831376763011617

Epoch: 6| Step: 4
Training loss: 4.261810721323702
Validation loss: 3.2785080117224266

Epoch: 6| Step: 5
Training loss: 3.795568421908073
Validation loss: 3.2739702827330266

Epoch: 6| Step: 6
Training loss: 3.401284053902589
Validation loss: 3.2739802022336844

Epoch: 6| Step: 7
Training loss: 3.187817576426501
Validation loss: 3.2691069771303103

Epoch: 6| Step: 8
Training loss: 3.2725109163689443
Validation loss: 3.2697382271257367

Epoch: 6| Step: 9
Training loss: 3.409109752487355
Validation loss: 3.268172375735871

Epoch: 6| Step: 10
Training loss: 3.2693754863209947
Validation loss: 3.2656845116397255

Epoch: 6| Step: 11
Training loss: 2.6721704330853995
Validation loss: 3.263349653104311

Epoch: 6| Step: 12
Training loss: 3.782323763637708
Validation loss: 3.2585064965802237

Epoch: 6| Step: 13
Training loss: 4.025523768874
Validation loss: 3.2601958095887245

Epoch: 24| Step: 0
Training loss: 3.683343387319615
Validation loss: 3.25692022043929

Epoch: 6| Step: 1
Training loss: 3.284521452073105
Validation loss: 3.2560574786077927

Epoch: 6| Step: 2
Training loss: 3.104911322317919
Validation loss: 3.2545124986087064

Epoch: 6| Step: 3
Training loss: 3.4055436828168464
Validation loss: 3.2519762437397692

Epoch: 6| Step: 4
Training loss: 2.8685590493473
Validation loss: 3.2490911672333938

Epoch: 6| Step: 5
Training loss: 4.8396547787084145
Validation loss: 3.2474858046154664

Epoch: 6| Step: 6
Training loss: 3.1553591235753924
Validation loss: 3.2408639221753495

Epoch: 6| Step: 7
Training loss: 2.970140793927856
Validation loss: 3.239764023578116

Epoch: 6| Step: 8
Training loss: 3.2396642218955165
Validation loss: 3.2445791248604543

Epoch: 6| Step: 9
Training loss: 4.284115911060798
Validation loss: 3.2491903677007192

Epoch: 6| Step: 10
Training loss: 2.8851517281392267
Validation loss: 3.2504705194180294

Epoch: 6| Step: 11
Training loss: 2.951646868831238
Validation loss: 3.244775695450711

Epoch: 6| Step: 12
Training loss: 4.118354993758341
Validation loss: 3.2386558325272077

Epoch: 6| Step: 13
Training loss: 3.5279468852951665
Validation loss: 3.231073931036613

Epoch: 25| Step: 0
Training loss: 2.558047357122326
Validation loss: 3.2281027405061544

Epoch: 6| Step: 1
Training loss: 3.717245615071535
Validation loss: 3.225773001723009

Epoch: 6| Step: 2
Training loss: 3.435662766974731
Validation loss: 3.2216587974927093

Epoch: 6| Step: 3
Training loss: 3.3006688567218307
Validation loss: 3.222478312790889

Epoch: 6| Step: 4
Training loss: 4.59006689949566
Validation loss: 3.219398574167053

Epoch: 6| Step: 5
Training loss: 3.691752680916703
Validation loss: 3.220039745656966

Epoch: 6| Step: 6
Training loss: 3.2175874555034985
Validation loss: 3.2203275353249077

Epoch: 6| Step: 7
Training loss: 3.4555695455444444
Validation loss: 3.215939916852585

Epoch: 6| Step: 8
Training loss: 3.218815182516576
Validation loss: 3.215889403182391

Epoch: 6| Step: 9
Training loss: 3.4053220272289755
Validation loss: 3.2095519954110228

Epoch: 6| Step: 10
Training loss: 2.5547774646095416
Validation loss: 3.205248481238592

Epoch: 6| Step: 11
Training loss: 3.6907879669876382
Validation loss: 3.201832147978202

Epoch: 6| Step: 12
Training loss: 3.7130573201171546
Validation loss: 3.197154408632744

Epoch: 6| Step: 13
Training loss: 3.6608934179200854
Validation loss: 3.195315474975077

Epoch: 26| Step: 0
Training loss: 3.5110346007830096
Validation loss: 3.1930599055543776

Epoch: 6| Step: 1
Training loss: 3.608074267618988
Validation loss: 3.1970396697511783

Epoch: 6| Step: 2
Training loss: 3.5668549271094445
Validation loss: 3.199771447569535

Epoch: 6| Step: 3
Training loss: 3.159291831713191
Validation loss: 3.1895443679760263

Epoch: 6| Step: 4
Training loss: 3.4583966506002897
Validation loss: 3.189818071600037

Epoch: 6| Step: 5
Training loss: 3.2198105333397287
Validation loss: 3.1866375317114604

Epoch: 6| Step: 6
Training loss: 3.267751339130946
Validation loss: 3.1834258636631834

Epoch: 6| Step: 7
Training loss: 2.9676241697510526
Validation loss: 3.1811884612632557

Epoch: 6| Step: 8
Training loss: 4.375435071838124
Validation loss: 3.1797171620026536

Epoch: 6| Step: 9
Training loss: 3.409441371589867
Validation loss: 3.1733583709433613

Epoch: 6| Step: 10
Training loss: 3.5775757747065384
Validation loss: 3.1717932259322468

Epoch: 6| Step: 11
Training loss: 3.5630469989787046
Validation loss: 3.1726076056064536

Epoch: 6| Step: 12
Training loss: 3.1952089325552193
Validation loss: 3.1680905671066246

Epoch: 6| Step: 13
Training loss: 2.799631816635148
Validation loss: 3.1684493280777306

Epoch: 27| Step: 0
Training loss: 4.117648422817998
Validation loss: 3.169432609766829

Epoch: 6| Step: 1
Training loss: 3.0724098089279335
Validation loss: 3.162466389045673

Epoch: 6| Step: 2
Training loss: 3.875435220211677
Validation loss: 3.1605670864254245

Epoch: 6| Step: 3
Training loss: 3.5326710770116274
Validation loss: 3.1579361704967934

Epoch: 6| Step: 4
Training loss: 2.418553689880831
Validation loss: 3.1628214012497744

Epoch: 6| Step: 5
Training loss: 3.1046086109814826
Validation loss: 3.1615126377865437

Epoch: 6| Step: 6
Training loss: 3.23753077665451
Validation loss: 3.1601659807916587

Epoch: 6| Step: 7
Training loss: 3.399651111205013
Validation loss: 3.160322526817594

Epoch: 6| Step: 8
Training loss: 3.6143769453565575
Validation loss: 3.1578097084358903

Epoch: 6| Step: 9
Training loss: 3.161809123571334
Validation loss: 3.149662098142627

Epoch: 6| Step: 10
Training loss: 3.0509466109354193
Validation loss: 3.147246806754146

Epoch: 6| Step: 11
Training loss: 3.9587154137100593
Validation loss: 3.14592161966748

Epoch: 6| Step: 12
Training loss: 3.36248294868542
Validation loss: 3.147851471155814

Epoch: 6| Step: 13
Training loss: 3.7283028111738243
Validation loss: 3.1500463755433437

Epoch: 28| Step: 0
Training loss: 3.897712227241036
Validation loss: 3.1514231900442886

Epoch: 6| Step: 1
Training loss: 4.019807885736882
Validation loss: 3.147900433897984

Epoch: 6| Step: 2
Training loss: 3.1737674273042105
Validation loss: 3.140142851211595

Epoch: 6| Step: 3
Training loss: 3.1835458201913496
Validation loss: 3.1365205010506516

Epoch: 6| Step: 4
Training loss: 3.9640816693712697
Validation loss: 3.1440920857939063

Epoch: 6| Step: 5
Training loss: 3.585369522225133
Validation loss: 3.1409545082349237

Epoch: 6| Step: 6
Training loss: 3.2316765332149244
Validation loss: 3.1328104951173055

Epoch: 6| Step: 7
Training loss: 3.7274669133540175
Validation loss: 3.1290129640456086

Epoch: 6| Step: 8
Training loss: 2.710693524290305
Validation loss: 3.130822858257846

Epoch: 6| Step: 9
Training loss: 3.2205387811503767
Validation loss: 3.1311591538523644

Epoch: 6| Step: 10
Training loss: 2.5266233003999674
Validation loss: 3.131485072777347

Epoch: 6| Step: 11
Training loss: 3.0949099129182405
Validation loss: 3.131706778535149

Epoch: 6| Step: 12
Training loss: 3.4317555373030375
Validation loss: 3.129796658296552

Epoch: 6| Step: 13
Training loss: 3.7011272981319543
Validation loss: 3.1342061182351104

Epoch: 29| Step: 0
Training loss: 3.164385291694422
Validation loss: 3.12644461599221

Epoch: 6| Step: 1
Training loss: 3.7394002517186777
Validation loss: 3.123265025573784

Epoch: 6| Step: 2
Training loss: 3.292308374620116
Validation loss: 3.122720458768881

Epoch: 6| Step: 3
Training loss: 3.4544508101991336
Validation loss: 3.125302583545321

Epoch: 6| Step: 4
Training loss: 3.3640535644185787
Validation loss: 3.118627578621429

Epoch: 6| Step: 5
Training loss: 3.545263386399221
Validation loss: 3.114196987693414

Epoch: 6| Step: 6
Training loss: 3.2852937032313716
Validation loss: 3.1132355612011633

Epoch: 6| Step: 7
Training loss: 3.2836366239040884
Validation loss: 3.114182751876279

Epoch: 6| Step: 8
Training loss: 3.5916236225803027
Validation loss: 3.1168083934750177

Epoch: 6| Step: 9
Training loss: 2.8937608360268903
Validation loss: 3.1193279580704645

Epoch: 6| Step: 10
Training loss: 3.463935053386127
Validation loss: 3.1255345238104373

Epoch: 6| Step: 11
Training loss: 3.5108837115076854
Validation loss: 3.1135083763897446

Epoch: 6| Step: 12
Training loss: 3.3525867097637274
Validation loss: 3.111314308642517

Epoch: 6| Step: 13
Training loss: 3.471368299809861
Validation loss: 3.1104878490059202

Epoch: 30| Step: 0
Training loss: 3.350436361560418
Validation loss: 3.1065377143988733

Epoch: 6| Step: 1
Training loss: 2.988219655717335
Validation loss: 3.1018275463346683

Epoch: 6| Step: 2
Training loss: 3.795277828656539
Validation loss: 3.1020478883159823

Epoch: 6| Step: 3
Training loss: 3.1371571387691244
Validation loss: 3.099993451991792

Epoch: 6| Step: 4
Training loss: 3.5266994086357957
Validation loss: 3.100667482827752

Epoch: 6| Step: 5
Training loss: 3.692563992554676
Validation loss: 3.100271533092125

Epoch: 6| Step: 6
Training loss: 3.6417572487419654
Validation loss: 3.109513233789498

Epoch: 6| Step: 7
Training loss: 3.1274945792830438
Validation loss: 3.1034326428088916

Epoch: 6| Step: 8
Training loss: 3.023281990408813
Validation loss: 3.0973344879966485

Epoch: 6| Step: 9
Training loss: 3.5961892515798874
Validation loss: 3.0956530310890273

Epoch: 6| Step: 10
Training loss: 2.5752005897094676
Validation loss: 3.0948224455040423

Epoch: 6| Step: 11
Training loss: 3.204318535971145
Validation loss: 3.0930746846892108

Epoch: 6| Step: 12
Training loss: 3.2542608647179416
Validation loss: 3.0926042898264714

Epoch: 6| Step: 13
Training loss: 4.519647726999514
Validation loss: 3.0889878092495353

Epoch: 31| Step: 0
Training loss: 3.373289169153096
Validation loss: 3.0897761370790744

Epoch: 6| Step: 1
Training loss: 3.8880543010043715
Validation loss: 3.0880418814504793

Epoch: 6| Step: 2
Training loss: 2.694582898448765
Validation loss: 3.08719558958852

Epoch: 6| Step: 3
Training loss: 2.887202365612774
Validation loss: 3.082948438394441

Epoch: 6| Step: 4
Training loss: 3.186628334687404
Validation loss: 3.0913198735344114

Epoch: 6| Step: 5
Training loss: 3.1290121643961317
Validation loss: 3.1004852203632796

Epoch: 6| Step: 6
Training loss: 3.4495559130139166
Validation loss: 3.0827788339657283

Epoch: 6| Step: 7
Training loss: 3.033291001775569
Validation loss: 3.07695030633412

Epoch: 6| Step: 8
Training loss: 4.2501373268828955
Validation loss: 3.0764463986541144

Epoch: 6| Step: 9
Training loss: 3.4118547437366673
Validation loss: 3.074573953571755

Epoch: 6| Step: 10
Training loss: 2.8690432330092164
Validation loss: 3.075108246390782

Epoch: 6| Step: 11
Training loss: 2.8776813111242103
Validation loss: 3.077550411028573

Epoch: 6| Step: 12
Training loss: 4.0432050995227335
Validation loss: 3.0775276230304884

Epoch: 6| Step: 13
Training loss: 3.661121220848881
Validation loss: 3.0731075093425724

Epoch: 32| Step: 0
Training loss: 3.617081115344652
Validation loss: 3.073993137384277

Epoch: 6| Step: 1
Training loss: 3.1719621918819456
Validation loss: 3.06828432953563

Epoch: 6| Step: 2
Training loss: 3.5558267297915127
Validation loss: 3.065318488417475

Epoch: 6| Step: 3
Training loss: 3.3131618198492565
Validation loss: 3.0635913296495683

Epoch: 6| Step: 4
Training loss: 3.5605128585353962
Validation loss: 3.0677601649213297

Epoch: 6| Step: 5
Training loss: 3.0662526086111126
Validation loss: 3.0688050689210553

Epoch: 6| Step: 6
Training loss: 3.718419164478861
Validation loss: 3.0667043174886333

Epoch: 6| Step: 7
Training loss: 3.408410183538367
Validation loss: 3.0626716523808803

Epoch: 6| Step: 8
Training loss: 3.741490436530008
Validation loss: 3.0608753945481895

Epoch: 6| Step: 9
Training loss: 3.610889992098095
Validation loss: 3.060673410256937

Epoch: 6| Step: 10
Training loss: 3.254441527523101
Validation loss: 3.057593828362296

Epoch: 6| Step: 11
Training loss: 2.7914896002645273
Validation loss: 3.0567666120164225

Epoch: 6| Step: 12
Training loss: 2.9571834711480536
Validation loss: 3.054098109706244

Epoch: 6| Step: 13
Training loss: 2.454718491366513
Validation loss: 3.055437490942319

Epoch: 33| Step: 0
Training loss: 3.256149782480042
Validation loss: 3.053287021097482

Epoch: 6| Step: 1
Training loss: 2.7384987389668
Validation loss: 3.050997885895046

Epoch: 6| Step: 2
Training loss: 2.5161348383057955
Validation loss: 3.051045593974637

Epoch: 6| Step: 3
Training loss: 3.01856874668151
Validation loss: 3.052567432927879

Epoch: 6| Step: 4
Training loss: 4.180938362402627
Validation loss: 3.0502371782717614

Epoch: 6| Step: 5
Training loss: 3.814683507787691
Validation loss: 3.04913736789852

Epoch: 6| Step: 6
Training loss: 3.2169089375972346
Validation loss: 3.045348728719367

Epoch: 6| Step: 7
Training loss: 4.063105846125755
Validation loss: 3.0441402694081208

Epoch: 6| Step: 8
Training loss: 3.2312424089648806
Validation loss: 3.038872596228774

Epoch: 6| Step: 9
Training loss: 3.2265622044302225
Validation loss: 3.039863620655509

Epoch: 6| Step: 10
Training loss: 3.6600642727070625
Validation loss: 3.040842570585626

Epoch: 6| Step: 11
Training loss: 2.696830079023922
Validation loss: 3.0402500653893703

Epoch: 6| Step: 12
Training loss: 2.4878632630065263
Validation loss: 3.0388649463119686

Epoch: 6| Step: 13
Training loss: 4.271595782940716
Validation loss: 3.0405340683378648

Epoch: 34| Step: 0
Training loss: 3.487743443021694
Validation loss: 3.038539832355839

Epoch: 6| Step: 1
Training loss: 3.2868604378777535
Validation loss: 3.0449185628073856

Epoch: 6| Step: 2
Training loss: 3.462174790737205
Validation loss: 3.0433416122210524

Epoch: 6| Step: 3
Training loss: 1.8872149271139804
Validation loss: 3.0339227531940742

Epoch: 6| Step: 4
Training loss: 3.9318806347119133
Validation loss: 3.033933094189275

Epoch: 6| Step: 5
Training loss: 3.1762792518226544
Validation loss: 3.0360205775269673

Epoch: 6| Step: 6
Training loss: 3.324668557993084
Validation loss: 3.034886958995537

Epoch: 6| Step: 7
Training loss: 3.4369839367595203
Validation loss: 3.0310037121919144

Epoch: 6| Step: 8
Training loss: 3.446164395635827
Validation loss: 3.0328976756327624

Epoch: 6| Step: 9
Training loss: 2.701409826603422
Validation loss: 3.028526583913841

Epoch: 6| Step: 10
Training loss: 4.076897798246681
Validation loss: 3.0289280663744296

Epoch: 6| Step: 11
Training loss: 3.7574637840084057
Validation loss: 3.0415754255386758

Epoch: 6| Step: 12
Training loss: 2.7621400072106397
Validation loss: 3.0410695938951853

Epoch: 6| Step: 13
Training loss: 2.9264058769258834
Validation loss: 3.068666467527413

Epoch: 35| Step: 0
Training loss: 3.04305195725255
Validation loss: 3.0913300474060423

Epoch: 6| Step: 1
Training loss: 3.587795466042113
Validation loss: 3.103756732112099

Epoch: 6| Step: 2
Training loss: 3.4847592539665446
Validation loss: 3.105429722257001

Epoch: 6| Step: 3
Training loss: 3.7055048639000217
Validation loss: 3.0327128576497713

Epoch: 6| Step: 4
Training loss: 3.652007421011765
Validation loss: 3.020059134313142

Epoch: 6| Step: 5
Training loss: 2.7427658818735834
Validation loss: 3.0266057786752505

Epoch: 6| Step: 6
Training loss: 3.787405253317427
Validation loss: 3.0316003517259578

Epoch: 6| Step: 7
Training loss: 3.773318460612647
Validation loss: 3.0396098581315454

Epoch: 6| Step: 8
Training loss: 3.8226181592823005
Validation loss: 3.0451067787104114

Epoch: 6| Step: 9
Training loss: 2.5264373049979305
Validation loss: 3.047378479088308

Epoch: 6| Step: 10
Training loss: 2.709028027766529
Validation loss: 3.041789128401507

Epoch: 6| Step: 11
Training loss: 3.254970271242858
Validation loss: 3.0369123088082493

Epoch: 6| Step: 12
Training loss: 2.7679614526457046
Validation loss: 3.029535034894441

Epoch: 6| Step: 13
Training loss: 3.3785995785235503
Validation loss: 3.0309448460713613

Epoch: 36| Step: 0
Training loss: 2.969528899158008
Validation loss: 3.0249056876062266

Epoch: 6| Step: 1
Training loss: 3.3209967413073334
Validation loss: 3.0317022766180566

Epoch: 6| Step: 2
Training loss: 2.7682546409279336
Validation loss: 3.0345458894349027

Epoch: 6| Step: 3
Training loss: 3.587781112237224
Validation loss: 3.0328248879004485

Epoch: 6| Step: 4
Training loss: 3.4783472858972253
Validation loss: 3.0270578133586614

Epoch: 6| Step: 5
Training loss: 3.017077318626393
Validation loss: 3.0162392998565886

Epoch: 6| Step: 6
Training loss: 2.5861873448389194
Validation loss: 3.01125446465665

Epoch: 6| Step: 7
Training loss: 2.6931893209946236
Validation loss: 3.012079614074598

Epoch: 6| Step: 8
Training loss: 3.3232133467838305
Validation loss: 3.0122237196806516

Epoch: 6| Step: 9
Training loss: 3.4328706954308448
Validation loss: 3.0183889890737037

Epoch: 6| Step: 10
Training loss: 3.789788056740726
Validation loss: 3.0175081163093265

Epoch: 6| Step: 11
Training loss: 3.2449180778425175
Validation loss: 3.006332787367358

Epoch: 6| Step: 12
Training loss: 3.845474600601287
Validation loss: 3.0072588829406564

Epoch: 6| Step: 13
Training loss: 4.294858369101888
Validation loss: 3.003348875803731

Epoch: 37| Step: 0
Training loss: 4.217426459774197
Validation loss: 3.0013131468870626

Epoch: 6| Step: 1
Training loss: 2.980469709923666
Validation loss: 3.000281744548593

Epoch: 6| Step: 2
Training loss: 3.315078595410673
Validation loss: 3.0017860011617716

Epoch: 6| Step: 3
Training loss: 3.374428594749703
Validation loss: 2.99811067445486

Epoch: 6| Step: 4
Training loss: 2.9814336372294328
Validation loss: 3.0002434197664667

Epoch: 6| Step: 5
Training loss: 3.4576816787484552
Validation loss: 2.9996606043453435

Epoch: 6| Step: 6
Training loss: 2.6699118736096508
Validation loss: 3.0148021117859125

Epoch: 6| Step: 7
Training loss: 3.239988900624796
Validation loss: 3.043357607231363

Epoch: 6| Step: 8
Training loss: 3.2214661036260375
Validation loss: 3.052306897847729

Epoch: 6| Step: 9
Training loss: 3.2003632339316677
Validation loss: 3.014173595906518

Epoch: 6| Step: 10
Training loss: 2.3101360507220043
Validation loss: 2.994654671994106

Epoch: 6| Step: 11
Training loss: 3.6973246928885697
Validation loss: 2.9904524068874667

Epoch: 6| Step: 12
Training loss: 3.372745184557537
Validation loss: 2.9854618158030655

Epoch: 6| Step: 13
Training loss: 3.836265410103025
Validation loss: 2.9888482565186076

Epoch: 38| Step: 0
Training loss: 3.288735996449959
Validation loss: 2.9890920372482426

Epoch: 6| Step: 1
Training loss: 3.4720591663645837
Validation loss: 2.9901831006224264

Epoch: 6| Step: 2
Training loss: 3.463220949549415
Validation loss: 2.9908036924813723

Epoch: 6| Step: 3
Training loss: 2.9668912188237533
Validation loss: 2.99208243660125

Epoch: 6| Step: 4
Training loss: 4.014596295232721
Validation loss: 2.9859349317026562

Epoch: 6| Step: 5
Training loss: 3.605397728977852
Validation loss: 2.9821200479260273

Epoch: 6| Step: 6
Training loss: 3.0823536596652814
Validation loss: 2.978953759998543

Epoch: 6| Step: 7
Training loss: 2.9157520131599144
Validation loss: 2.981578979825657

Epoch: 6| Step: 8
Training loss: 2.9617409936969703
Validation loss: 2.992351869215145

Epoch: 6| Step: 9
Training loss: 2.8585554105236755
Validation loss: 2.9859484807993395

Epoch: 6| Step: 10
Training loss: 3.2174846050661827
Validation loss: 2.9862688864403872

Epoch: 6| Step: 11
Training loss: 3.13550465271303
Validation loss: 2.9888233332002794

Epoch: 6| Step: 12
Training loss: 3.213637949749522
Validation loss: 2.980788501879855

Epoch: 6| Step: 13
Training loss: 3.768495723819622
Validation loss: 2.980433162934297

Epoch: 39| Step: 0
Training loss: 2.8943187311280005
Validation loss: 2.975339861117225

Epoch: 6| Step: 1
Training loss: 3.0611628513228983
Validation loss: 2.978438060173507

Epoch: 6| Step: 2
Training loss: 2.9099347126247146
Validation loss: 2.975277809359162

Epoch: 6| Step: 3
Training loss: 3.2234524939627947
Validation loss: 2.977762631633043

Epoch: 6| Step: 4
Training loss: 3.2406608204347127
Validation loss: 2.978015677031143

Epoch: 6| Step: 5
Training loss: 3.0168620522242775
Validation loss: 2.980075600859801

Epoch: 6| Step: 6
Training loss: 4.059349599146496
Validation loss: 2.977692067377453

Epoch: 6| Step: 7
Training loss: 3.13041035555095
Validation loss: 2.981232098756357

Epoch: 6| Step: 8
Training loss: 3.533424855492419
Validation loss: 2.9796257867130915

Epoch: 6| Step: 9
Training loss: 3.5723102080836036
Validation loss: 2.972089244150118

Epoch: 6| Step: 10
Training loss: 3.205401249136955
Validation loss: 2.973360406727614

Epoch: 6| Step: 11
Training loss: 3.2721326316683
Validation loss: 2.97211384287347

Epoch: 6| Step: 12
Training loss: 3.5288218023850795
Validation loss: 2.9677649011566003

Epoch: 6| Step: 13
Training loss: 2.5886220222348073
Validation loss: 2.9712008598597133

Epoch: 40| Step: 0
Training loss: 3.063124301103171
Validation loss: 2.976891880071809

Epoch: 6| Step: 1
Training loss: 3.7296920207411333
Validation loss: 2.980052606014117

Epoch: 6| Step: 2
Training loss: 3.2072492146735985
Validation loss: 2.992367709272841

Epoch: 6| Step: 3
Training loss: 3.773326042851211
Validation loss: 2.9791686607840075

Epoch: 6| Step: 4
Training loss: 3.0202468478136875
Validation loss: 2.9748188708537358

Epoch: 6| Step: 5
Training loss: 2.9082573961839238
Validation loss: 2.967829158953769

Epoch: 6| Step: 6
Training loss: 2.2171339140123165
Validation loss: 2.9698645649197095

Epoch: 6| Step: 7
Training loss: 3.1615448907925665
Validation loss: 2.9626646529264566

Epoch: 6| Step: 8
Training loss: 3.311067667369604
Validation loss: 2.961876316273018

Epoch: 6| Step: 9
Training loss: 3.276451453135825
Validation loss: 2.9633611330003933

Epoch: 6| Step: 10
Training loss: 3.8257850190467955
Validation loss: 2.963937824869381

Epoch: 6| Step: 11
Training loss: 3.583580555630618
Validation loss: 2.9617646422693213

Epoch: 6| Step: 12
Training loss: 3.2833110330924873
Validation loss: 2.962269120941869

Epoch: 6| Step: 13
Training loss: 2.703838188154644
Validation loss: 2.962530541512425

Epoch: 41| Step: 0
Training loss: 3.6342547435331984
Validation loss: 2.96319696471284

Epoch: 6| Step: 1
Training loss: 2.350014516095719
Validation loss: 2.9606467552947593

Epoch: 6| Step: 2
Training loss: 3.5898668622589778
Validation loss: 2.958814894324658

Epoch: 6| Step: 3
Training loss: 3.1578929892752647
Validation loss: 2.959502054434084

Epoch: 6| Step: 4
Training loss: 2.6231586719357742
Validation loss: 2.962477621119703

Epoch: 6| Step: 5
Training loss: 3.7929581898346814
Validation loss: 2.9601664816248703

Epoch: 6| Step: 6
Training loss: 3.2378779069243677
Validation loss: 2.9579632735763504

Epoch: 6| Step: 7
Training loss: 3.107745946724855
Validation loss: 2.95432800905781

Epoch: 6| Step: 8
Training loss: 2.8393688618154678
Validation loss: 2.955734075264186

Epoch: 6| Step: 9
Training loss: 3.431776240561614
Validation loss: 2.9567780162134136

Epoch: 6| Step: 10
Training loss: 3.1770206299311012
Validation loss: 2.955783431976342

Epoch: 6| Step: 11
Training loss: 3.304343491994429
Validation loss: 2.954779786402657

Epoch: 6| Step: 12
Training loss: 4.067149392124224
Validation loss: 2.9598369050234417

Epoch: 6| Step: 13
Training loss: 2.4539499050023386
Validation loss: 2.9597493098667207

Epoch: 42| Step: 0
Training loss: 3.1859240656518493
Validation loss: 2.9518826583202236

Epoch: 6| Step: 1
Training loss: 3.408034390969988
Validation loss: 2.956015470161083

Epoch: 6| Step: 2
Training loss: 2.4294017366116214
Validation loss: 2.9535126590898724

Epoch: 6| Step: 3
Training loss: 3.156187755613034
Validation loss: 2.9551698621803113

Epoch: 6| Step: 4
Training loss: 3.3411180351847225
Validation loss: 2.9542598858283586

Epoch: 6| Step: 5
Training loss: 3.7508233755900915
Validation loss: 2.9545322027238385

Epoch: 6| Step: 6
Training loss: 2.985655025772797
Validation loss: 2.954743687778886

Epoch: 6| Step: 7
Training loss: 3.0728699416579164
Validation loss: 2.9528877443828523

Epoch: 6| Step: 8
Training loss: 3.660885993572399
Validation loss: 2.954171464907093

Epoch: 6| Step: 9
Training loss: 2.354204284457439
Validation loss: 2.9502103917532505

Epoch: 6| Step: 10
Training loss: 2.878592858408848
Validation loss: 2.9518455072684175

Epoch: 6| Step: 11
Training loss: 3.9578717949812137
Validation loss: 2.9509394351037534

Epoch: 6| Step: 12
Training loss: 3.7512347413832874
Validation loss: 2.951023782968145

Epoch: 6| Step: 13
Training loss: 3.1127157236126446
Validation loss: 2.9487189225959933

Epoch: 43| Step: 0
Training loss: 3.0654948635652484
Validation loss: 2.9477531700548707

Epoch: 6| Step: 1
Training loss: 3.2660564520886624
Validation loss: 2.9507493977200503

Epoch: 6| Step: 2
Training loss: 3.5090374751162203
Validation loss: 2.952737681584621

Epoch: 6| Step: 3
Training loss: 3.4826053521842666
Validation loss: 2.9510923457578646

Epoch: 6| Step: 4
Training loss: 2.1646887358580296
Validation loss: 2.9492527161752733

Epoch: 6| Step: 5
Training loss: 4.188638560817114
Validation loss: 2.948344277725085

Epoch: 6| Step: 6
Training loss: 3.3285204155507717
Validation loss: 2.949686066334326

Epoch: 6| Step: 7
Training loss: 3.6005814347680007
Validation loss: 2.951320690997378

Epoch: 6| Step: 8
Training loss: 3.423665035735316
Validation loss: 2.9442013290420874

Epoch: 6| Step: 9
Training loss: 3.4592143089513705
Validation loss: 2.9445174820795037

Epoch: 6| Step: 10
Training loss: 2.6998940270431326
Validation loss: 2.9452523955732426

Epoch: 6| Step: 11
Training loss: 3.0390472803985067
Validation loss: 2.9482267216633966

Epoch: 6| Step: 12
Training loss: 2.8793077124253377
Validation loss: 2.949428749010287

Epoch: 6| Step: 13
Training loss: 2.5831238343803604
Validation loss: 2.9520942420024685

Epoch: 44| Step: 0
Training loss: 3.7072617486295143
Validation loss: 2.949888055386602

Epoch: 6| Step: 1
Training loss: 3.5321914633140006
Validation loss: 2.9472727385182518

Epoch: 6| Step: 2
Training loss: 4.058622182061744
Validation loss: 2.9454213676048226

Epoch: 6| Step: 3
Training loss: 3.144343210604437
Validation loss: 2.9453318614208555

Epoch: 6| Step: 4
Training loss: 3.1986752748276817
Validation loss: 2.943746766471215

Epoch: 6| Step: 5
Training loss: 3.2994626272379626
Validation loss: 2.9449370944583975

Epoch: 6| Step: 6
Training loss: 2.770899339238681
Validation loss: 2.946612612136588

Epoch: 6| Step: 7
Training loss: 2.8556053452494767
Validation loss: 2.94533039739411

Epoch: 6| Step: 8
Training loss: 3.4807413767208
Validation loss: 2.9452670762353352

Epoch: 6| Step: 9
Training loss: 2.964801451289588
Validation loss: 2.9453458627718696

Epoch: 6| Step: 10
Training loss: 3.4259311551883718
Validation loss: 2.94804811780652

Epoch: 6| Step: 11
Training loss: 2.211767249887696
Validation loss: 2.9452231445754347

Epoch: 6| Step: 12
Training loss: 2.7183906931607242
Validation loss: 2.9436460757203373

Epoch: 6| Step: 13
Training loss: 3.90067204284906
Validation loss: 2.9410631749194214

Epoch: 45| Step: 0
Training loss: 2.530120786113141
Validation loss: 2.9430753397170673

Epoch: 6| Step: 1
Training loss: 3.4445739092816554
Validation loss: 2.9437924357649377

Epoch: 6| Step: 2
Training loss: 3.0354735848024115
Validation loss: 2.9450533507443986

Epoch: 6| Step: 3
Training loss: 2.5027523149085833
Validation loss: 2.9462076437513023

Epoch: 6| Step: 4
Training loss: 3.4775323436557533
Validation loss: 2.9428146536210353

Epoch: 6| Step: 5
Training loss: 3.3518066317335795
Validation loss: 2.943864264559998

Epoch: 6| Step: 6
Training loss: 3.3506378819111804
Validation loss: 2.943884140590643

Epoch: 6| Step: 7
Training loss: 3.088999019080513
Validation loss: 2.940436533330364

Epoch: 6| Step: 8
Training loss: 3.131539331039632
Validation loss: 2.939631203677596

Epoch: 6| Step: 9
Training loss: 3.4690650590660885
Validation loss: 2.9377275019693805

Epoch: 6| Step: 10
Training loss: 3.7513917247791784
Validation loss: 2.937917595449547

Epoch: 6| Step: 11
Training loss: 3.1203824833417766
Validation loss: 2.9381372183475087

Epoch: 6| Step: 12
Training loss: 3.4072535725050805
Validation loss: 2.938381994731626

Epoch: 6| Step: 13
Training loss: 3.4761515513789525
Validation loss: 2.9392788348414234

Epoch: 46| Step: 0
Training loss: 3.277534924865915
Validation loss: 2.934703835291707

Epoch: 6| Step: 1
Training loss: 3.2222371886625605
Validation loss: 2.9375486756050955

Epoch: 6| Step: 2
Training loss: 3.5914166380437647
Validation loss: 2.936267453691682

Epoch: 6| Step: 3
Training loss: 3.4587610432207603
Validation loss: 2.9374065327572554

Epoch: 6| Step: 4
Training loss: 3.3079059340769006
Validation loss: 2.936933369860281

Epoch: 6| Step: 5
Training loss: 3.1801157669971554
Validation loss: 2.9388973636400197

Epoch: 6| Step: 6
Training loss: 3.188718076850447
Validation loss: 2.935719336311179

Epoch: 6| Step: 7
Training loss: 3.235284649738187
Validation loss: 2.9337042601510794

Epoch: 6| Step: 8
Training loss: 2.885568350834273
Validation loss: 2.9322155495034563

Epoch: 6| Step: 9
Training loss: 2.76991086437709
Validation loss: 2.9317295995308217

Epoch: 6| Step: 10
Training loss: 3.8733944181483095
Validation loss: 2.9310803945466186

Epoch: 6| Step: 11
Training loss: 2.834848914855279
Validation loss: 2.9325791113893875

Epoch: 6| Step: 12
Training loss: 2.933894928000552
Validation loss: 2.933021430267408

Epoch: 6| Step: 13
Training loss: 3.4939850484160186
Validation loss: 2.929470869251949

Epoch: 47| Step: 0
Training loss: 2.8094888462511243
Validation loss: 2.931151120595501

Epoch: 6| Step: 1
Training loss: 2.8747113953733603
Validation loss: 2.9296074487831265

Epoch: 6| Step: 2
Training loss: 2.659136381997957
Validation loss: 2.9335658867329055

Epoch: 6| Step: 3
Training loss: 3.2937296104885836
Validation loss: 2.9300825611491064

Epoch: 6| Step: 4
Training loss: 2.1617498607209735
Validation loss: 2.940178612721925

Epoch: 6| Step: 5
Training loss: 3.265563672233648
Validation loss: 2.9588091454783303

Epoch: 6| Step: 6
Training loss: 3.112718481032791
Validation loss: 2.9619971535713114

Epoch: 6| Step: 7
Training loss: 3.7717253471211567
Validation loss: 2.9496178372000825

Epoch: 6| Step: 8
Training loss: 3.0188638164159425
Validation loss: 2.94311118076873

Epoch: 6| Step: 9
Training loss: 4.004250652108595
Validation loss: 2.927485596924793

Epoch: 6| Step: 10
Training loss: 3.7877867133769763
Validation loss: 2.926288223630566

Epoch: 6| Step: 11
Training loss: 3.3268192219076025
Validation loss: 2.934738416281064

Epoch: 6| Step: 12
Training loss: 3.456078694463102
Validation loss: 2.939901214875392

Epoch: 6| Step: 13
Training loss: 3.329187357953209
Validation loss: 2.949158260988555

Epoch: 48| Step: 0
Training loss: 2.5138354837307704
Validation loss: 2.9622260974395402

Epoch: 6| Step: 1
Training loss: 3.5038469154326806
Validation loss: 2.970346074652684

Epoch: 6| Step: 2
Training loss: 2.899473267436115
Validation loss: 2.977268829269711

Epoch: 6| Step: 3
Training loss: 2.858137686422034
Validation loss: 2.9673601274575354

Epoch: 6| Step: 4
Training loss: 3.1729438371469745
Validation loss: 2.9583328388034027

Epoch: 6| Step: 5
Training loss: 3.695845132068493
Validation loss: 2.955349405356913

Epoch: 6| Step: 6
Training loss: 2.817929092944634
Validation loss: 2.9406454612443156

Epoch: 6| Step: 7
Training loss: 2.921003078982759
Validation loss: 2.9375815379133137

Epoch: 6| Step: 8
Training loss: 3.262760640106612
Validation loss: 2.9375432032451947

Epoch: 6| Step: 9
Training loss: 3.074974190208233
Validation loss: 2.956615552995793

Epoch: 6| Step: 10
Training loss: 3.5667991797765937
Validation loss: 2.9437501332788294

Epoch: 6| Step: 11
Training loss: 4.142705200490838
Validation loss: 2.934695683652851

Epoch: 6| Step: 12
Training loss: 3.3614687050697905
Validation loss: 2.9297137051849407

Epoch: 6| Step: 13
Training loss: 3.505769606267155
Validation loss: 2.926949248171176

Epoch: 49| Step: 0
Training loss: 2.992594479604671
Validation loss: 2.9275323947162795

Epoch: 6| Step: 1
Training loss: 3.656311034646817
Validation loss: 2.928164895417878

Epoch: 6| Step: 2
Training loss: 2.9663445615746324
Validation loss: 2.9255932991074856

Epoch: 6| Step: 3
Training loss: 3.1660924357392832
Validation loss: 2.9244101073353588

Epoch: 6| Step: 4
Training loss: 3.263921411951954
Validation loss: 2.923885673833236

Epoch: 6| Step: 5
Training loss: 2.7535149911832955
Validation loss: 2.9256352078030314

Epoch: 6| Step: 6
Training loss: 3.2380126547233314
Validation loss: 2.9227200327466223

Epoch: 6| Step: 7
Training loss: 3.014727681326078
Validation loss: 2.922822691649012

Epoch: 6| Step: 8
Training loss: 3.4756638640638817
Validation loss: 2.9217492471837274

Epoch: 6| Step: 9
Training loss: 3.0152113240390435
Validation loss: 2.9226669353475705

Epoch: 6| Step: 10
Training loss: 2.6536191590191085
Validation loss: 2.9263040270596936

Epoch: 6| Step: 11
Training loss: 3.530118777948666
Validation loss: 2.9236969092492084

Epoch: 6| Step: 12
Training loss: 3.206919436997229
Validation loss: 2.9240172449656665

Epoch: 6| Step: 13
Training loss: 4.506218745828248
Validation loss: 2.925872878845422

Epoch: 50| Step: 0
Training loss: 3.4863913137655955
Validation loss: 2.921007624368081

Epoch: 6| Step: 1
Training loss: 3.072276489471413
Validation loss: 2.919686548617379

Epoch: 6| Step: 2
Training loss: 3.0717642654531043
Validation loss: 2.9177733028588744

Epoch: 6| Step: 3
Training loss: 3.022017271051846
Validation loss: 2.9166180854185226

Epoch: 6| Step: 4
Training loss: 3.659931904727356
Validation loss: 2.9198282384089866

Epoch: 6| Step: 5
Training loss: 3.5530221244795275
Validation loss: 2.9212215162883464

Epoch: 6| Step: 6
Training loss: 2.6292307229760405
Validation loss: 2.9194007633784715

Epoch: 6| Step: 7
Training loss: 3.3084853693877996
Validation loss: 2.918174645346388

Epoch: 6| Step: 8
Training loss: 2.7884861112771646
Validation loss: 2.9176621251603003

Epoch: 6| Step: 9
Training loss: 3.5672204048286638
Validation loss: 2.918809563829021

Epoch: 6| Step: 10
Training loss: 2.7193522169999493
Validation loss: 2.914846275570955

Epoch: 6| Step: 11
Training loss: 2.9550529524291367
Validation loss: 2.9132118689189315

Epoch: 6| Step: 12
Training loss: 3.5253282705271616
Validation loss: 2.914010885607904

Epoch: 6| Step: 13
Training loss: 3.917184768389741
Validation loss: 2.9143769436764493

Epoch: 51| Step: 0
Training loss: 3.390691941123465
Validation loss: 2.9123584119806503

Epoch: 6| Step: 1
Training loss: 3.7124470100089004
Validation loss: 2.9115540849381003

Epoch: 6| Step: 2
Training loss: 3.309144533829909
Validation loss: 2.9135100257118025

Epoch: 6| Step: 3
Training loss: 3.2949794725811943
Validation loss: 2.9279665189131405

Epoch: 6| Step: 4
Training loss: 2.7577775731455096
Validation loss: 2.9188449729720487

Epoch: 6| Step: 5
Training loss: 3.1199907972738066
Validation loss: 2.913878308379537

Epoch: 6| Step: 6
Training loss: 3.0968972583513614
Validation loss: 2.917751183286537

Epoch: 6| Step: 7
Training loss: 2.827419129689923
Validation loss: 2.914261519032194

Epoch: 6| Step: 8
Training loss: 3.1977666929452133
Validation loss: 2.9111767469662113

Epoch: 6| Step: 9
Training loss: 3.254210312502191
Validation loss: 2.9094525247464365

Epoch: 6| Step: 10
Training loss: 2.7650479506737575
Validation loss: 2.907834432130999

Epoch: 6| Step: 11
Training loss: 3.4938837834438505
Validation loss: 2.9096930647897956

Epoch: 6| Step: 12
Training loss: 3.898544157170745
Validation loss: 2.9079649372255427

Epoch: 6| Step: 13
Training loss: 2.13040270925071
Validation loss: 2.9081596057709724

Epoch: 52| Step: 0
Training loss: 3.1213864605779427
Validation loss: 2.910084627840257

Epoch: 6| Step: 1
Training loss: 3.4491170001979765
Validation loss: 2.913811055415988

Epoch: 6| Step: 2
Training loss: 3.076361291291331
Validation loss: 2.9170881587943325

Epoch: 6| Step: 3
Training loss: 2.8570255153265696
Validation loss: 2.9190233656322175

Epoch: 6| Step: 4
Training loss: 3.2362020004089938
Validation loss: 2.9253828229580185

Epoch: 6| Step: 5
Training loss: 3.5708218467880783
Validation loss: 2.9229271265414796

Epoch: 6| Step: 6
Training loss: 2.494438087929167
Validation loss: 2.9222815288217836

Epoch: 6| Step: 7
Training loss: 3.5093506836834267
Validation loss: 2.915932669917557

Epoch: 6| Step: 8
Training loss: 3.625237029646222
Validation loss: 2.914329895931719

Epoch: 6| Step: 9
Training loss: 3.147243831957252
Validation loss: 2.9095293029172677

Epoch: 6| Step: 10
Training loss: 3.672455437417769
Validation loss: 2.9084190163397734

Epoch: 6| Step: 11
Training loss: 3.1562321728495615
Validation loss: 2.9098279709622097

Epoch: 6| Step: 12
Training loss: 3.221167684146488
Validation loss: 2.908701144959208

Epoch: 6| Step: 13
Training loss: 2.4501225265693627
Validation loss: 2.912299483954961

Epoch: 53| Step: 0
Training loss: 3.462530109811688
Validation loss: 2.910551248432902

Epoch: 6| Step: 1
Training loss: 3.6248313601499267
Validation loss: 2.9088468493247848

Epoch: 6| Step: 2
Training loss: 2.8589628996174747
Validation loss: 2.9120838380424043

Epoch: 6| Step: 3
Training loss: 3.2266925480753024
Validation loss: 2.9168779900167383

Epoch: 6| Step: 4
Training loss: 3.489473863089753
Validation loss: 2.918685847594923

Epoch: 6| Step: 5
Training loss: 3.2978707929462265
Validation loss: 2.922422905071758

Epoch: 6| Step: 6
Training loss: 3.3087963776315896
Validation loss: 2.9274147157613384

Epoch: 6| Step: 7
Training loss: 3.7622040844509064
Validation loss: 2.92421061694747

Epoch: 6| Step: 8
Training loss: 3.5199000157981506
Validation loss: 2.916010566316197

Epoch: 6| Step: 9
Training loss: 2.5369642772693166
Validation loss: 2.905645657185328

Epoch: 6| Step: 10
Training loss: 3.3227438248951584
Validation loss: 2.904303098071502

Epoch: 6| Step: 11
Training loss: 3.0282847264919774
Validation loss: 2.902236041915785

Epoch: 6| Step: 12
Training loss: 2.580913353643177
Validation loss: 2.904008913159764

Epoch: 6| Step: 13
Training loss: 2.2827947951406387
Validation loss: 2.903857734342855

Epoch: 54| Step: 0
Training loss: 3.2237465603511666
Validation loss: 2.9073354365930215

Epoch: 6| Step: 1
Training loss: 3.0697095439080164
Validation loss: 2.902884157478059

Epoch: 6| Step: 2
Training loss: 2.880621017681737
Validation loss: 2.905951225350393

Epoch: 6| Step: 3
Training loss: 2.206700230983771
Validation loss: 2.9020923766272864

Epoch: 6| Step: 4
Training loss: 3.2585517172707905
Validation loss: 2.9043707865740407

Epoch: 6| Step: 5
Training loss: 3.604347591967332
Validation loss: 2.9067220931833364

Epoch: 6| Step: 6
Training loss: 2.978295970384245
Validation loss: 2.9057296020615007

Epoch: 6| Step: 7
Training loss: 3.6545327873476285
Validation loss: 2.9028708388779982

Epoch: 6| Step: 8
Training loss: 2.5654926038214283
Validation loss: 2.898839641119764

Epoch: 6| Step: 9
Training loss: 3.628668408765999
Validation loss: 2.900268802271362

Epoch: 6| Step: 10
Training loss: 3.093330740215048
Validation loss: 2.9115291973316384

Epoch: 6| Step: 11
Training loss: 3.2651594642382014
Validation loss: 2.9152461945285513

Epoch: 6| Step: 12
Training loss: 3.810493942041691
Validation loss: 2.9019530736203483

Epoch: 6| Step: 13
Training loss: 3.4727452269956536
Validation loss: 2.90194556808237

Epoch: 55| Step: 0
Training loss: 3.239529837179927
Validation loss: 2.8978409372824117

Epoch: 6| Step: 1
Training loss: 2.484697045140097
Validation loss: 2.898011149494997

Epoch: 6| Step: 2
Training loss: 3.4816519869842937
Validation loss: 2.9008310620469415

Epoch: 6| Step: 3
Training loss: 3.4363326431388677
Validation loss: 2.9012217613877915

Epoch: 6| Step: 4
Training loss: 2.8807502958692686
Validation loss: 2.90039725950793

Epoch: 6| Step: 5
Training loss: 3.749554162543419
Validation loss: 2.902953846645991

Epoch: 6| Step: 6
Training loss: 3.4355185606778083
Validation loss: 2.9023579278158893

Epoch: 6| Step: 7
Training loss: 3.01373310731499
Validation loss: 2.9063708822387717

Epoch: 6| Step: 8
Training loss: 2.428935336248329
Validation loss: 2.906944395713796

Epoch: 6| Step: 9
Training loss: 2.3734071308978115
Validation loss: 2.9053269463141906

Epoch: 6| Step: 10
Training loss: 3.528398831251639
Validation loss: 2.9088202631410396

Epoch: 6| Step: 11
Training loss: 2.822113054104836
Validation loss: 2.905593373155088

Epoch: 6| Step: 12
Training loss: 4.365589374896586
Validation loss: 2.9076631131529105

Epoch: 6| Step: 13
Training loss: 2.811832772688472
Validation loss: 2.9014483765989234

Epoch: 56| Step: 0
Training loss: 3.325216105615972
Validation loss: 2.897533687451037

Epoch: 6| Step: 1
Training loss: 2.587271078551904
Validation loss: 2.895767845628527

Epoch: 6| Step: 2
Training loss: 3.371638566744048
Validation loss: 2.896670497503426

Epoch: 6| Step: 3
Training loss: 3.1096169842436043
Validation loss: 2.8948383225709255

Epoch: 6| Step: 4
Training loss: 3.5188772120949703
Validation loss: 2.8949377451969953

Epoch: 6| Step: 5
Training loss: 2.7027959899009955
Validation loss: 2.8942454530509556

Epoch: 6| Step: 6
Training loss: 3.506276089440314
Validation loss: 2.893665459850281

Epoch: 6| Step: 7
Training loss: 3.014966191091179
Validation loss: 2.892506156213803

Epoch: 6| Step: 8
Training loss: 2.9549464507180714
Validation loss: 2.893812436863861

Epoch: 6| Step: 9
Training loss: 3.136111532038017
Validation loss: 2.8959202098643995

Epoch: 6| Step: 10
Training loss: 3.353863262093843
Validation loss: 2.894442860908614

Epoch: 6| Step: 11
Training loss: 4.0111467497825375
Validation loss: 2.8932302665905882

Epoch: 6| Step: 12
Training loss: 3.066833077628712
Validation loss: 2.8933678559779032

Epoch: 6| Step: 13
Training loss: 2.730491277904652
Validation loss: 2.889858537344082

Epoch: 57| Step: 0
Training loss: 3.927117844218318
Validation loss: 2.8934037793743927

Epoch: 6| Step: 1
Training loss: 3.0445663704631687
Validation loss: 2.891041633803354

Epoch: 6| Step: 2
Training loss: 4.415342216318802
Validation loss: 2.894616321375682

Epoch: 6| Step: 3
Training loss: 2.838173229326055
Validation loss: 2.8946529404529997

Epoch: 6| Step: 4
Training loss: 2.8506523456528976
Validation loss: 2.8903968905058326

Epoch: 6| Step: 5
Training loss: 3.008319445408037
Validation loss: 2.8927217035917616

Epoch: 6| Step: 6
Training loss: 2.7660925518447668
Validation loss: 2.8927136042490083

Epoch: 6| Step: 7
Training loss: 3.035143681602034
Validation loss: 2.8912920589303392

Epoch: 6| Step: 8
Training loss: 2.798363060656066
Validation loss: 2.8965201827429965

Epoch: 6| Step: 9
Training loss: 3.4517747819792377
Validation loss: 2.891579840283512

Epoch: 6| Step: 10
Training loss: 3.3645896006113425
Validation loss: 2.8943668198266033

Epoch: 6| Step: 11
Training loss: 3.2964938698261324
Validation loss: 2.8907630131396784

Epoch: 6| Step: 12
Training loss: 2.7401134331048667
Validation loss: 2.892700597750717

Epoch: 6| Step: 13
Training loss: 2.4478862246521085
Validation loss: 2.8941001164147018

Epoch: 58| Step: 0
Training loss: 3.1113373204901777
Validation loss: 2.8922337714425495

Epoch: 6| Step: 1
Training loss: 3.5049564144455614
Validation loss: 2.891724145761352

Epoch: 6| Step: 2
Training loss: 3.476577861623365
Validation loss: 2.8944800623139186

Epoch: 6| Step: 3
Training loss: 3.8898114805459416
Validation loss: 2.895828731022988

Epoch: 6| Step: 4
Training loss: 3.4283344493438235
Validation loss: 2.895249364020961

Epoch: 6| Step: 5
Training loss: 2.8026031995108927
Validation loss: 2.897141166073868

Epoch: 6| Step: 6
Training loss: 2.9355520729328566
Validation loss: 2.892085030864106

Epoch: 6| Step: 7
Training loss: 2.5315850118595127
Validation loss: 2.8943886442431466

Epoch: 6| Step: 8
Training loss: 3.324419994964156
Validation loss: 2.890989261680593

Epoch: 6| Step: 9
Training loss: 3.0782439697821222
Validation loss: 2.8924130892201703

Epoch: 6| Step: 10
Training loss: 2.9436647374466434
Validation loss: 2.892844500816727

Epoch: 6| Step: 11
Training loss: 3.450151777384193
Validation loss: 2.8909893273015235

Epoch: 6| Step: 12
Training loss: 3.047213022115198
Validation loss: 2.8908980799589554

Epoch: 6| Step: 13
Training loss: 2.865703312959189
Validation loss: 2.889867532689442

Epoch: 59| Step: 0
Training loss: 2.8205272138446182
Validation loss: 2.8933436279894402

Epoch: 6| Step: 1
Training loss: 4.169686304089519
Validation loss: 2.8911666535576055

Epoch: 6| Step: 2
Training loss: 2.616973868234122
Validation loss: 2.892980281291582

Epoch: 6| Step: 3
Training loss: 3.9558944952215573
Validation loss: 2.8931435603490048

Epoch: 6| Step: 4
Training loss: 3.246219784049216
Validation loss: 2.897797804746121

Epoch: 6| Step: 5
Training loss: 3.1869576684673784
Validation loss: 2.8920564698403948

Epoch: 6| Step: 6
Training loss: 2.993829421102868
Validation loss: 2.890769249382989

Epoch: 6| Step: 7
Training loss: 2.8379074274709053
Validation loss: 2.89026921373921

Epoch: 6| Step: 8
Training loss: 3.424603493564586
Validation loss: 2.8864410638493356

Epoch: 6| Step: 9
Training loss: 3.1887378159144064
Validation loss: 2.8883524938520786

Epoch: 6| Step: 10
Training loss: 3.229507690798515
Validation loss: 2.8916814556939316

Epoch: 6| Step: 11
Training loss: 1.9951643898524754
Validation loss: 2.889573998522694

Epoch: 6| Step: 12
Training loss: 3.684007963190574
Validation loss: 2.8838883122339207

Epoch: 6| Step: 13
Training loss: 2.126399869396989
Validation loss: 2.8892304129132107

Epoch: 60| Step: 0
Training loss: 3.244612115797884
Validation loss: 2.889132715860048

Epoch: 6| Step: 1
Training loss: 3.19895343355735
Validation loss: 2.8853938577639764

Epoch: 6| Step: 2
Training loss: 3.5519150202783987
Validation loss: 2.8827262363287987

Epoch: 6| Step: 3
Training loss: 3.7921325201788694
Validation loss: 2.8900783031818627

Epoch: 6| Step: 4
Training loss: 3.382800236563005
Validation loss: 2.8837079220646573

Epoch: 6| Step: 5
Training loss: 3.1615025089367985
Validation loss: 2.8831342696593514

Epoch: 6| Step: 6
Training loss: 3.459852750434258
Validation loss: 2.887139609417752

Epoch: 6| Step: 7
Training loss: 2.4430606699095976
Validation loss: 2.8865335880133753

Epoch: 6| Step: 8
Training loss: 3.2201483198326737
Validation loss: 2.8833841367982274

Epoch: 6| Step: 9
Training loss: 2.5812820986767835
Validation loss: 2.8834974309699284

Epoch: 6| Step: 10
Training loss: 2.6031461827033358
Validation loss: 2.8874910979250683

Epoch: 6| Step: 11
Training loss: 3.5941776187080374
Validation loss: 2.8823313551245415

Epoch: 6| Step: 12
Training loss: 2.5986373998808627
Validation loss: 2.8870260132929966

Epoch: 6| Step: 13
Training loss: 3.5919961381394456
Validation loss: 2.8858595474470747

Epoch: 61| Step: 0
Training loss: 3.5036699944737633
Validation loss: 2.891299119083109

Epoch: 6| Step: 1
Training loss: 3.519136158977075
Validation loss: 2.892690209171438

Epoch: 6| Step: 2
Training loss: 3.1258098315910847
Validation loss: 2.8866172671780936

Epoch: 6| Step: 3
Training loss: 3.3376549045461275
Validation loss: 2.886479933312066

Epoch: 6| Step: 4
Training loss: 3.4325074440138437
Validation loss: 2.882919306432385

Epoch: 6| Step: 5
Training loss: 3.0877862342016167
Validation loss: 2.881636247012132

Epoch: 6| Step: 6
Training loss: 2.7367185304616046
Validation loss: 2.8805298005650237

Epoch: 6| Step: 7
Training loss: 3.2741820733599587
Validation loss: 2.88112423960687

Epoch: 6| Step: 8
Training loss: 2.97684411346219
Validation loss: 2.882515508124076

Epoch: 6| Step: 9
Training loss: 3.032132364428545
Validation loss: 2.880018223120349

Epoch: 6| Step: 10
Training loss: 3.421248147759792
Validation loss: 2.8825184501789827

Epoch: 6| Step: 11
Training loss: 3.179014692427962
Validation loss: 2.8810571029881324

Epoch: 6| Step: 12
Training loss: 3.0051371776987335
Validation loss: 2.8819751614480764

Epoch: 6| Step: 13
Training loss: 2.776903163124016
Validation loss: 2.8858884975966714

Epoch: 62| Step: 0
Training loss: 3.6034899537534106
Validation loss: 2.8840937259128867

Epoch: 6| Step: 1
Training loss: 3.280354114118424
Validation loss: 2.8904376456205014

Epoch: 6| Step: 2
Training loss: 3.143529052250631
Validation loss: 2.8884450721697608

Epoch: 6| Step: 3
Training loss: 2.7412262451701195
Validation loss: 2.887041659575845

Epoch: 6| Step: 4
Training loss: 2.540029112881801
Validation loss: 2.888620608333001

Epoch: 6| Step: 5
Training loss: 3.148691171881776
Validation loss: 2.8861150385460164

Epoch: 6| Step: 6
Training loss: 3.710653258028613
Validation loss: 2.8789599283081517

Epoch: 6| Step: 7
Training loss: 3.1975167652970122
Validation loss: 2.879356616309123

Epoch: 6| Step: 8
Training loss: 3.173544909238656
Validation loss: 2.8778323319385755

Epoch: 6| Step: 9
Training loss: 2.8390280957150242
Validation loss: 2.880242714877607

Epoch: 6| Step: 10
Training loss: 2.9256692821636885
Validation loss: 2.8803809335517867

Epoch: 6| Step: 11
Training loss: 3.4591307735640995
Validation loss: 2.8794038668967876

Epoch: 6| Step: 12
Training loss: 3.4847231293297805
Validation loss: 2.8796476790026526

Epoch: 6| Step: 13
Training loss: 3.1100023106508163
Validation loss: 2.8779221647403035

Epoch: 63| Step: 0
Training loss: 3.5964744523815684
Validation loss: 2.8798010892994657

Epoch: 6| Step: 1
Training loss: 2.9454789253792866
Validation loss: 2.8781541319491044

Epoch: 6| Step: 2
Training loss: 3.291691035570809
Validation loss: 2.876482347342016

Epoch: 6| Step: 3
Training loss: 3.14594012620217
Validation loss: 2.8785391946301786

Epoch: 6| Step: 4
Training loss: 3.624190141384445
Validation loss: 2.8780793012625843

Epoch: 6| Step: 5
Training loss: 3.4791235245334997
Validation loss: 2.878413925676699

Epoch: 6| Step: 6
Training loss: 2.863645938895815
Validation loss: 2.8786118830896488

Epoch: 6| Step: 7
Training loss: 3.006603919627027
Validation loss: 2.8781313462511586

Epoch: 6| Step: 8
Training loss: 3.1671823449791545
Validation loss: 2.880718153517614

Epoch: 6| Step: 9
Training loss: 3.2915944119663623
Validation loss: 2.884771278792322

Epoch: 6| Step: 10
Training loss: 3.1159181998292804
Validation loss: 2.878130317456741

Epoch: 6| Step: 11
Training loss: 2.9964896963761247
Validation loss: 2.8853260661471842

Epoch: 6| Step: 12
Training loss: 3.0087039567746974
Validation loss: 2.8840067360965604

Epoch: 6| Step: 13
Training loss: 2.617552683390248
Validation loss: 2.8828053190182628

Epoch: 64| Step: 0
Training loss: 3.1425629515248974
Validation loss: 2.898200551211874

Epoch: 6| Step: 1
Training loss: 3.5046474391571154
Validation loss: 2.902428460780227

Epoch: 6| Step: 2
Training loss: 3.4528985272877764
Validation loss: 2.9122733914418437

Epoch: 6| Step: 3
Training loss: 2.5157816583415005
Validation loss: 2.9139625342804236

Epoch: 6| Step: 4
Training loss: 3.58797727593378
Validation loss: 2.901420986598878

Epoch: 6| Step: 5
Training loss: 3.6545393112558866
Validation loss: 2.881791486328592

Epoch: 6| Step: 6
Training loss: 2.4511957053435727
Validation loss: 2.876672631817699

Epoch: 6| Step: 7
Training loss: 3.029645986995602
Validation loss: 2.8766732289099886

Epoch: 6| Step: 8
Training loss: 2.7098465629017108
Validation loss: 2.871736667382104

Epoch: 6| Step: 9
Training loss: 2.7664957346067185
Validation loss: 2.8759008283027656

Epoch: 6| Step: 10
Training loss: 3.8352746332500325
Validation loss: 2.8794028821835767

Epoch: 6| Step: 11
Training loss: 3.2723392656338643
Validation loss: 2.878284229921136

Epoch: 6| Step: 12
Training loss: 3.4375337078869332
Validation loss: 2.87541202198332

Epoch: 6| Step: 13
Training loss: 2.4679778617842834
Validation loss: 2.876740233462928

Epoch: 65| Step: 0
Training loss: 3.3758851762562365
Validation loss: 2.87866603532433

Epoch: 6| Step: 1
Training loss: 2.9165467010531185
Validation loss: 2.878175689167884

Epoch: 6| Step: 2
Training loss: 3.4359794721689627
Validation loss: 2.8783068710098676

Epoch: 6| Step: 3
Training loss: 2.506118059371614
Validation loss: 2.875422906289779

Epoch: 6| Step: 4
Training loss: 3.5738006180457167
Validation loss: 2.8764568844577387

Epoch: 6| Step: 5
Training loss: 3.5740960105291615
Validation loss: 2.8759504256915083

Epoch: 6| Step: 6
Training loss: 3.691160551098971
Validation loss: 2.8753504617530656

Epoch: 6| Step: 7
Training loss: 2.8789698517397784
Validation loss: 2.87474981791512

Epoch: 6| Step: 8
Training loss: 2.6201539493787047
Validation loss: 2.878842135701802

Epoch: 6| Step: 9
Training loss: 2.7965087650843077
Validation loss: 2.8781005579715897

Epoch: 6| Step: 10
Training loss: 3.2107151817709694
Validation loss: 2.8783632645382986

Epoch: 6| Step: 11
Training loss: 3.462251641906574
Validation loss: 2.879423206738451

Epoch: 6| Step: 12
Training loss: 3.2093574738882915
Validation loss: 2.8763982628186247

Epoch: 6| Step: 13
Training loss: 2.8173081730256055
Validation loss: 2.877632332443434

Epoch: 66| Step: 0
Training loss: 3.2105246322535264
Validation loss: 2.895070492888295

Epoch: 6| Step: 1
Training loss: 3.2288870577607547
Validation loss: 2.8987491034297057

Epoch: 6| Step: 2
Training loss: 3.1803985475510217
Validation loss: 2.8912973940577347

Epoch: 6| Step: 3
Training loss: 3.3947208821276766
Validation loss: 2.8776358460933116

Epoch: 6| Step: 4
Training loss: 3.2762194627185015
Validation loss: 2.871330273252757

Epoch: 6| Step: 5
Training loss: 2.7075045173304413
Validation loss: 2.8718422539131647

Epoch: 6| Step: 6
Training loss: 3.0059609002510146
Validation loss: 2.8693180086775953

Epoch: 6| Step: 7
Training loss: 2.9585440833730563
Validation loss: 2.8692244692108035

Epoch: 6| Step: 8
Training loss: 3.362690411816868
Validation loss: 2.8701426101611127

Epoch: 6| Step: 9
Training loss: 3.292822059631228
Validation loss: 2.870436828343938

Epoch: 6| Step: 10
Training loss: 2.615828522816205
Validation loss: 2.870130223988636

Epoch: 6| Step: 11
Training loss: 3.372126450942708
Validation loss: 2.8693196794601916

Epoch: 6| Step: 12
Training loss: 3.2613307333764574
Validation loss: 2.8708334358253773

Epoch: 6| Step: 13
Training loss: 3.837350495746964
Validation loss: 2.870077557818736

Epoch: 67| Step: 0
Training loss: 3.4220837394416543
Validation loss: 2.8704431471513594

Epoch: 6| Step: 1
Training loss: 3.3943800985838504
Validation loss: 2.86857178637819

Epoch: 6| Step: 2
Training loss: 3.1912389032011825
Validation loss: 2.86962611044694

Epoch: 6| Step: 3
Training loss: 2.6905050111393254
Validation loss: 2.8690232745520743

Epoch: 6| Step: 4
Training loss: 3.675148531448824
Validation loss: 2.870740475300265

Epoch: 6| Step: 5
Training loss: 3.372964315723854
Validation loss: 2.8701932073929455

Epoch: 6| Step: 6
Training loss: 3.073983286428093
Validation loss: 2.8655718699502146

Epoch: 6| Step: 7
Training loss: 3.0547613344757245
Validation loss: 2.8671775322125836

Epoch: 6| Step: 8
Training loss: 3.024524897317294
Validation loss: 2.8711407436944563

Epoch: 6| Step: 9
Training loss: 3.752342001417977
Validation loss: 2.8720172882582906

Epoch: 6| Step: 10
Training loss: 2.7517399052146856
Validation loss: 2.8682662518469617

Epoch: 6| Step: 11
Training loss: 2.363194084136315
Validation loss: 2.8652407509122124

Epoch: 6| Step: 12
Training loss: 3.3294451607024556
Validation loss: 2.8707048103723714

Epoch: 6| Step: 13
Training loss: 2.939886706238868
Validation loss: 2.8687697124990246

Epoch: 68| Step: 0
Training loss: 2.872084590664951
Validation loss: 2.8710410139977443

Epoch: 6| Step: 1
Training loss: 3.5382754227482236
Validation loss: 2.8760291420398314

Epoch: 6| Step: 2
Training loss: 2.594104329001606
Validation loss: 2.868617080489192

Epoch: 6| Step: 3
Training loss: 3.2685211334922477
Validation loss: 2.8691365648325795

Epoch: 6| Step: 4
Training loss: 3.580276042589132
Validation loss: 2.8725209384288135

Epoch: 6| Step: 5
Training loss: 3.118178590094955
Validation loss: 2.872606819595863

Epoch: 6| Step: 6
Training loss: 1.9844195743871036
Validation loss: 2.8675434027678177

Epoch: 6| Step: 7
Training loss: 3.3227639158211653
Validation loss: 2.8732959160905818

Epoch: 6| Step: 8
Training loss: 3.5123805015572738
Validation loss: 2.8682755079679954

Epoch: 6| Step: 9
Training loss: 3.0906186681360506
Validation loss: 2.8705400486748314

Epoch: 6| Step: 10
Training loss: 3.5583320462822354
Validation loss: 2.8662765954646057

Epoch: 6| Step: 11
Training loss: 2.7170796140955265
Validation loss: 2.8692274740363355

Epoch: 6| Step: 12
Training loss: 3.536713011854744
Validation loss: 2.869266327406886

Epoch: 6| Step: 13
Training loss: 3.336052564293758
Validation loss: 2.8680010042732698

Epoch: 69| Step: 0
Training loss: 2.655607527282362
Validation loss: 2.8683504603546

Epoch: 6| Step: 1
Training loss: 3.3356012894100613
Validation loss: 2.867525786947185

Epoch: 6| Step: 2
Training loss: 3.8477375467299773
Validation loss: 2.874145833017782

Epoch: 6| Step: 3
Training loss: 3.290531075233917
Validation loss: 2.866480774181039

Epoch: 6| Step: 4
Training loss: 3.372993579260118
Validation loss: 2.866659919657378

Epoch: 6| Step: 5
Training loss: 2.7946893260719077
Validation loss: 2.8650139195115285

Epoch: 6| Step: 6
Training loss: 3.424806636725992
Validation loss: 2.864455660811654

Epoch: 6| Step: 7
Training loss: 2.7591120005954513
Validation loss: 2.8630140953543797

Epoch: 6| Step: 8
Training loss: 3.058643170148712
Validation loss: 2.865991320141902

Epoch: 6| Step: 9
Training loss: 3.1651690773299834
Validation loss: 2.8626210067971933

Epoch: 6| Step: 10
Training loss: 2.9301570261777923
Validation loss: 2.864153746371823

Epoch: 6| Step: 11
Training loss: 2.8467900720986803
Validation loss: 2.8654326819542755

Epoch: 6| Step: 12
Training loss: 3.293978462764925
Validation loss: 2.8607067725509423

Epoch: 6| Step: 13
Training loss: 3.6324158154556137
Validation loss: 2.8620291560934548

Epoch: 70| Step: 0
Training loss: 2.478030278246415
Validation loss: 2.864765667225765

Epoch: 6| Step: 1
Training loss: 4.02621571443036
Validation loss: 2.86551137767756

Epoch: 6| Step: 2
Training loss: 3.0727998010859268
Validation loss: 2.862253591655101

Epoch: 6| Step: 3
Training loss: 3.7275397021138437
Validation loss: 2.8609095780979157

Epoch: 6| Step: 4
Training loss: 2.8252245113315704
Validation loss: 2.861087923692371

Epoch: 6| Step: 5
Training loss: 3.321879225949805
Validation loss: 2.866150127767235

Epoch: 6| Step: 6
Training loss: 3.7981380669446088
Validation loss: 2.8662149553011718

Epoch: 6| Step: 7
Training loss: 3.1381745908853476
Validation loss: 2.8842741470606543

Epoch: 6| Step: 8
Training loss: 2.5709930724766927
Validation loss: 2.8851672424169377

Epoch: 6| Step: 9
Training loss: 2.979909701931426
Validation loss: 2.906246494481194

Epoch: 6| Step: 10
Training loss: 3.7482191307635255
Validation loss: 2.911273911200671

Epoch: 6| Step: 11
Training loss: 2.907905353291467
Validation loss: 2.913474015855376

Epoch: 6| Step: 12
Training loss: 2.5394345993870777
Validation loss: 2.8928665773196247

Epoch: 6| Step: 13
Training loss: 2.336923754648466
Validation loss: 2.8804411429188

Epoch: 71| Step: 0
Training loss: 3.040081255479365
Validation loss: 2.8725925547360216

Epoch: 6| Step: 1
Training loss: 3.4764895313620494
Validation loss: 2.863389173529503

Epoch: 6| Step: 2
Training loss: 3.36936522688852
Validation loss: 2.8613203346017313

Epoch: 6| Step: 3
Training loss: 2.797536164459931
Validation loss: 2.8609267937820726

Epoch: 6| Step: 4
Training loss: 3.797241193278568
Validation loss: 2.859641442139292

Epoch: 6| Step: 5
Training loss: 3.3354480393264825
Validation loss: 2.8579846570357827

Epoch: 6| Step: 6
Training loss: 2.6344201134996714
Validation loss: 2.858360332398692

Epoch: 6| Step: 7
Training loss: 2.837188360771034
Validation loss: 2.8568668555553938

Epoch: 6| Step: 8
Training loss: 3.000047524393673
Validation loss: 2.859047964979639

Epoch: 6| Step: 9
Training loss: 3.1760690706463097
Validation loss: 2.856880242354055

Epoch: 6| Step: 10
Training loss: 3.5617482245435403
Validation loss: 2.860071149621281

Epoch: 6| Step: 11
Training loss: 2.4262769502836106
Validation loss: 2.8575482068477602

Epoch: 6| Step: 12
Training loss: 2.9876789757655433
Validation loss: 2.857257912135004

Epoch: 6| Step: 13
Training loss: 3.779180669846224
Validation loss: 2.861866452416687

Epoch: 72| Step: 0
Training loss: 2.446744262008822
Validation loss: 2.8587952130304903

Epoch: 6| Step: 1
Training loss: 2.8239190455712326
Validation loss: 2.8630504819858813

Epoch: 6| Step: 2
Training loss: 3.4036536164354074
Validation loss: 2.863634527292219

Epoch: 6| Step: 3
Training loss: 2.300309707687584
Validation loss: 2.866495555980224

Epoch: 6| Step: 4
Training loss: 2.9857655426287772
Validation loss: 2.8672059154586904

Epoch: 6| Step: 5
Training loss: 3.789940549439547
Validation loss: 2.862329738891315

Epoch: 6| Step: 6
Training loss: 3.697425802542577
Validation loss: 2.859933809416137

Epoch: 6| Step: 7
Training loss: 3.509190074365785
Validation loss: 2.8681933262256427

Epoch: 6| Step: 8
Training loss: 3.160754322848313
Validation loss: 2.85929776988527

Epoch: 6| Step: 9
Training loss: 3.165154313458181
Validation loss: 2.856983339600137

Epoch: 6| Step: 10
Training loss: 3.81784033796483
Validation loss: 2.854335120355579

Epoch: 6| Step: 11
Training loss: 2.424197553811823
Validation loss: 2.856310071412448

Epoch: 6| Step: 12
Training loss: 3.3627430200502215
Validation loss: 2.857869252583446

Epoch: 6| Step: 13
Training loss: 2.4919370328072246
Validation loss: 2.8590683544299944

Epoch: 73| Step: 0
Training loss: 2.6896871494041683
Validation loss: 2.859709911657972

Epoch: 6| Step: 1
Training loss: 2.5183636466052652
Validation loss: 2.8588903473531135

Epoch: 6| Step: 2
Training loss: 3.381430821687096
Validation loss: 2.8589172418257727

Epoch: 6| Step: 3
Training loss: 3.069692301536237
Validation loss: 2.8601730096516245

Epoch: 6| Step: 4
Training loss: 3.386502620924112
Validation loss: 2.85681843534519

Epoch: 6| Step: 5
Training loss: 3.201519819787805
Validation loss: 2.856589238085534

Epoch: 6| Step: 6
Training loss: 2.523572321735798
Validation loss: 2.8557652349450704

Epoch: 6| Step: 7
Training loss: 3.3818011104454904
Validation loss: 2.853629221898348

Epoch: 6| Step: 8
Training loss: 2.8703522639461214
Validation loss: 2.8538817845940687

Epoch: 6| Step: 9
Training loss: 3.4000808425716804
Validation loss: 2.853973486925493

Epoch: 6| Step: 10
Training loss: 2.9613288077305966
Validation loss: 2.857358297855397

Epoch: 6| Step: 11
Training loss: 3.39632151708464
Validation loss: 2.851575458591003

Epoch: 6| Step: 12
Training loss: 3.8087868040013686
Validation loss: 2.855756132180895

Epoch: 6| Step: 13
Training loss: 3.6798707304930764
Validation loss: 2.851789681261071

Epoch: 74| Step: 0
Training loss: 2.8300878973476897
Validation loss: 2.8541684229658015

Epoch: 6| Step: 1
Training loss: 2.36618534441122
Validation loss: 2.850316384123528

Epoch: 6| Step: 2
Training loss: 3.4723887560432662
Validation loss: 2.8521499448993692

Epoch: 6| Step: 3
Training loss: 3.8257568508162385
Validation loss: 2.857007477522406

Epoch: 6| Step: 4
Training loss: 3.328877968299834
Validation loss: 2.848606501301368

Epoch: 6| Step: 5
Training loss: 2.7490145044537364
Validation loss: 2.8519308699893315

Epoch: 6| Step: 6
Training loss: 3.4395418518510232
Validation loss: 2.850870243676989

Epoch: 6| Step: 7
Training loss: 2.955337744967335
Validation loss: 2.8493062320390274

Epoch: 6| Step: 8
Training loss: 3.60308633537093
Validation loss: 2.854268375743509

Epoch: 6| Step: 9
Training loss: 3.1291067985432286
Validation loss: 2.848917259596165

Epoch: 6| Step: 10
Training loss: 3.5065773061479337
Validation loss: 2.84754987649351

Epoch: 6| Step: 11
Training loss: 2.901960755822263
Validation loss: 2.8435240588963593

Epoch: 6| Step: 12
Training loss: 2.2996489713074366
Validation loss: 2.8459716992651805

Epoch: 6| Step: 13
Training loss: 3.4446528142708748
Validation loss: 2.8431307120488034

Epoch: 75| Step: 0
Training loss: 3.141898584954589
Validation loss: 2.8453133824801475

Epoch: 6| Step: 1
Training loss: 2.2355358602761366
Validation loss: 2.842977250005738

Epoch: 6| Step: 2
Training loss: 3.2212716012096476
Validation loss: 2.8465167783303134

Epoch: 6| Step: 3
Training loss: 3.8931099795806374
Validation loss: 2.841699267592433

Epoch: 6| Step: 4
Training loss: 3.325351616186904
Validation loss: 2.843196008543143

Epoch: 6| Step: 5
Training loss: 3.0510435101542703
Validation loss: 2.8404701572190936

Epoch: 6| Step: 6
Training loss: 3.2547163853528733
Validation loss: 2.8431799685895944

Epoch: 6| Step: 7
Training loss: 3.0239312609070526
Validation loss: 2.8411552909004207

Epoch: 6| Step: 8
Training loss: 2.809934505636093
Validation loss: 2.8461362618752144

Epoch: 6| Step: 9
Training loss: 3.2028281469723106
Validation loss: 2.8692651685592243

Epoch: 6| Step: 10
Training loss: 2.9062654228211406
Validation loss: 2.8603069755246207

Epoch: 6| Step: 11
Training loss: 3.0293357546566075
Validation loss: 2.8514912676037123

Epoch: 6| Step: 12
Training loss: 3.6391994321160617
Validation loss: 2.8358598797526717

Epoch: 6| Step: 13
Training loss: 2.9558848246228315
Validation loss: 2.831988108203449

Epoch: 76| Step: 0
Training loss: 2.6903215722378504
Validation loss: 2.8375681617915895

Epoch: 6| Step: 1
Training loss: 3.180234819775284
Validation loss: 2.8349149537328713

Epoch: 6| Step: 2
Training loss: 2.9555595898262097
Validation loss: 2.834970255339039

Epoch: 6| Step: 3
Training loss: 3.667652575563703
Validation loss: 2.8382917676695407

Epoch: 6| Step: 4
Training loss: 2.4002111381799347
Validation loss: 2.8381971731426656

Epoch: 6| Step: 5
Training loss: 3.5332637210202456
Validation loss: 2.832552115095042

Epoch: 6| Step: 6
Training loss: 2.773825175094809
Validation loss: 2.83693250051771

Epoch: 6| Step: 7
Training loss: 3.3947096449635272
Validation loss: 2.832055171516161

Epoch: 6| Step: 8
Training loss: 3.924808818267296
Validation loss: 2.8366421281481458

Epoch: 6| Step: 9
Training loss: 3.0313936179834644
Validation loss: 2.829909217845486

Epoch: 6| Step: 10
Training loss: 3.2592070816981855
Validation loss: 2.835694073922363

Epoch: 6| Step: 11
Training loss: 2.8472583634065036
Validation loss: 2.833916714150484

Epoch: 6| Step: 12
Training loss: 3.580481939855424
Validation loss: 2.832740654445023

Epoch: 6| Step: 13
Training loss: 1.5707954688867272
Validation loss: 2.83683221571977

Epoch: 77| Step: 0
Training loss: 2.753227247575912
Validation loss: 2.8377756699431256

Epoch: 6| Step: 1
Training loss: 3.1062492877184167
Validation loss: 2.832214370368727

Epoch: 6| Step: 2
Training loss: 3.017339031537191
Validation loss: 2.8419559647495585

Epoch: 6| Step: 3
Training loss: 3.0561335816472535
Validation loss: 2.839700600710836

Epoch: 6| Step: 4
Training loss: 3.050520843059498
Validation loss: 2.8409148007332705

Epoch: 6| Step: 5
Training loss: 3.3837565102600893
Validation loss: 2.8458148960446006

Epoch: 6| Step: 6
Training loss: 3.5749006777751227
Validation loss: 2.8482568513918975

Epoch: 6| Step: 7
Training loss: 3.2500404942263916
Validation loss: 2.842782644962035

Epoch: 6| Step: 8
Training loss: 3.150095462866308
Validation loss: 2.831996374880857

Epoch: 6| Step: 9
Training loss: 3.235084934917909
Validation loss: 2.831988973616713

Epoch: 6| Step: 10
Training loss: 3.3789070967303854
Validation loss: 2.8295717447555275

Epoch: 6| Step: 11
Training loss: 3.299312323386644
Validation loss: 2.829556126788138

Epoch: 6| Step: 12
Training loss: 2.8315811536187354
Validation loss: 2.828408523875884

Epoch: 6| Step: 13
Training loss: 2.532450638466047
Validation loss: 2.8281876461850333

Epoch: 78| Step: 0
Training loss: 3.594826180576008
Validation loss: 2.831210892912094

Epoch: 6| Step: 1
Training loss: 2.965469957646199
Validation loss: 2.8316024533729998

Epoch: 6| Step: 2
Training loss: 3.2213192657496164
Validation loss: 2.8294531591169636

Epoch: 6| Step: 3
Training loss: 3.3683388991752694
Validation loss: 2.8309580182709815

Epoch: 6| Step: 4
Training loss: 2.190224177413504
Validation loss: 2.829932622817329

Epoch: 6| Step: 5
Training loss: 3.2098410560497443
Validation loss: 2.8284470705586218

Epoch: 6| Step: 6
Training loss: 3.2232097358505447
Validation loss: 2.8298607802808697

Epoch: 6| Step: 7
Training loss: 3.313067117763635
Validation loss: 2.8259335733549737

Epoch: 6| Step: 8
Training loss: 3.586655222887504
Validation loss: 2.8292331712447707

Epoch: 6| Step: 9
Training loss: 3.6189219063362166
Validation loss: 2.8254153307607996

Epoch: 6| Step: 10
Training loss: 2.399876066822701
Validation loss: 2.822801598896858

Epoch: 6| Step: 11
Training loss: 2.3688135385169575
Validation loss: 2.826807259328055

Epoch: 6| Step: 12
Training loss: 3.2954743650791087
Validation loss: 2.827184284644688

Epoch: 6| Step: 13
Training loss: 3.1590506337145134
Validation loss: 2.8333198545836256

Epoch: 79| Step: 0
Training loss: 3.199333067774008
Validation loss: 2.836144283200944

Epoch: 6| Step: 1
Training loss: 3.0336985972497463
Validation loss: 2.83969062852427

Epoch: 6| Step: 2
Training loss: 3.3151300893260998
Validation loss: 2.8511186394477925

Epoch: 6| Step: 3
Training loss: 2.5978948727335736
Validation loss: 2.8441448440143127

Epoch: 6| Step: 4
Training loss: 3.080858904486778
Validation loss: 2.8383811060071693

Epoch: 6| Step: 5
Training loss: 3.086105612509478
Validation loss: 2.8545686621192568

Epoch: 6| Step: 6
Training loss: 3.224174003392247
Validation loss: 2.8464741677001903

Epoch: 6| Step: 7
Training loss: 3.504812338208996
Validation loss: 2.84976791436408

Epoch: 6| Step: 8
Training loss: 3.451525287418938
Validation loss: 2.8402157502185514

Epoch: 6| Step: 9
Training loss: 3.178935793938346
Validation loss: 2.8277951287640244

Epoch: 6| Step: 10
Training loss: 3.42130138867342
Validation loss: 2.826830056969534

Epoch: 6| Step: 11
Training loss: 2.846198233299948
Validation loss: 2.823604502816454

Epoch: 6| Step: 12
Training loss: 2.806564850338448
Validation loss: 2.8213717018330997

Epoch: 6| Step: 13
Training loss: 2.9793590314600027
Validation loss: 2.8206478180099865

Epoch: 80| Step: 0
Training loss: 3.645233642667003
Validation loss: 2.822610790777296

Epoch: 6| Step: 1
Training loss: 1.9611410818010164
Validation loss: 2.822177423426775

Epoch: 6| Step: 2
Training loss: 3.882643022426812
Validation loss: 2.8257161557163473

Epoch: 6| Step: 3
Training loss: 3.2020169458268493
Validation loss: 2.8226056845824443

Epoch: 6| Step: 4
Training loss: 3.0086670293330893
Validation loss: 2.8255937963351627

Epoch: 6| Step: 5
Training loss: 2.872553572325311
Validation loss: 2.821382838230902

Epoch: 6| Step: 6
Training loss: 2.6677235257452097
Validation loss: 2.825801219877163

Epoch: 6| Step: 7
Training loss: 2.5761767800192596
Validation loss: 2.8265303101632844

Epoch: 6| Step: 8
Training loss: 3.8305287813341002
Validation loss: 2.820823237094075

Epoch: 6| Step: 9
Training loss: 3.1839001841594263
Validation loss: 2.8202437675735594

Epoch: 6| Step: 10
Training loss: 2.7294949826685153
Validation loss: 2.8206624564517906

Epoch: 6| Step: 11
Training loss: 3.199878964519321
Validation loss: 2.820076761331904

Epoch: 6| Step: 12
Training loss: 3.4831869383595526
Validation loss: 2.8223424623492015

Epoch: 6| Step: 13
Training loss: 3.106848528973117
Validation loss: 2.821664197603393

Epoch: 81| Step: 0
Training loss: 3.0568777364103603
Validation loss: 2.825296328393216

Epoch: 6| Step: 1
Training loss: 2.964305240744066
Validation loss: 2.8291164399232227

Epoch: 6| Step: 2
Training loss: 3.1329651602747846
Validation loss: 2.8427360626534735

Epoch: 6| Step: 3
Training loss: 3.449248472541459
Validation loss: 2.8448536455497853

Epoch: 6| Step: 4
Training loss: 3.32663575284835
Validation loss: 2.8305301730842145

Epoch: 6| Step: 5
Training loss: 2.9490775977707573
Validation loss: 2.81600224189154

Epoch: 6| Step: 6
Training loss: 3.0342460062755494
Validation loss: 2.8194212437127453

Epoch: 6| Step: 7
Training loss: 3.136246243015075
Validation loss: 2.8157156596718953

Epoch: 6| Step: 8
Training loss: 3.2772683827187796
Validation loss: 2.815996195121005

Epoch: 6| Step: 9
Training loss: 3.365041947578063
Validation loss: 2.814173132623151

Epoch: 6| Step: 10
Training loss: 2.681112638925299
Validation loss: 2.8161768115291888

Epoch: 6| Step: 11
Training loss: 3.313089570174643
Validation loss: 2.816063872327058

Epoch: 6| Step: 12
Training loss: 3.0935240383666245
Validation loss: 2.818079472345992

Epoch: 6| Step: 13
Training loss: 2.949046553075178
Validation loss: 2.815591135711737

Epoch: 82| Step: 0
Training loss: 3.5554567280253657
Validation loss: 2.8237243935880976

Epoch: 6| Step: 1
Training loss: 3.070751828509976
Validation loss: 2.8224783527865127

Epoch: 6| Step: 2
Training loss: 2.880594863386341
Validation loss: 2.8222012567813968

Epoch: 6| Step: 3
Training loss: 1.9610251600877828
Validation loss: 2.8195225519444556

Epoch: 6| Step: 4
Training loss: 3.4043076603117304
Validation loss: 2.8302546199229996

Epoch: 6| Step: 5
Training loss: 3.472128382792289
Validation loss: 2.8198230454928495

Epoch: 6| Step: 6
Training loss: 3.4136089660945172
Validation loss: 2.813939277512984

Epoch: 6| Step: 7
Training loss: 3.343328003681026
Validation loss: 2.816997427856856

Epoch: 6| Step: 8
Training loss: 2.6194065991559348
Validation loss: 2.8172073238799333

Epoch: 6| Step: 9
Training loss: 2.827423092903317
Validation loss: 2.81705780432365

Epoch: 6| Step: 10
Training loss: 3.6391899980851625
Validation loss: 2.8146042839809207

Epoch: 6| Step: 11
Training loss: 3.2547430494295644
Validation loss: 2.8157511024461757

Epoch: 6| Step: 12
Training loss: 2.452338803405731
Validation loss: 2.812050404954439

Epoch: 6| Step: 13
Training loss: 3.6763033521426243
Validation loss: 2.8129252924612884

Epoch: 83| Step: 0
Training loss: 2.2340841037283576
Validation loss: 2.8164424195583417

Epoch: 6| Step: 1
Training loss: 2.755633825511647
Validation loss: 2.8147300593132805

Epoch: 6| Step: 2
Training loss: 3.841227874741794
Validation loss: 2.818815906226107

Epoch: 6| Step: 3
Training loss: 2.5005933057573237
Validation loss: 2.823378231670162

Epoch: 6| Step: 4
Training loss: 3.7663953317682966
Validation loss: 2.835153146093396

Epoch: 6| Step: 5
Training loss: 3.9446960571940872
Validation loss: 2.83592121649892

Epoch: 6| Step: 6
Training loss: 2.017851317116373
Validation loss: 2.8186502915469216

Epoch: 6| Step: 7
Training loss: 3.180669009773171
Validation loss: 2.810364373378266

Epoch: 6| Step: 8
Training loss: 3.258902314858567
Validation loss: 2.8160731161387997

Epoch: 6| Step: 9
Training loss: 2.9110202812345345
Validation loss: 2.816636021109932

Epoch: 6| Step: 10
Training loss: 3.5391619333610262
Validation loss: 2.815521380220782

Epoch: 6| Step: 11
Training loss: 3.409341231894814
Validation loss: 2.8135269131546066

Epoch: 6| Step: 12
Training loss: 2.733205141767603
Validation loss: 2.8150003364428877

Epoch: 6| Step: 13
Training loss: 3.0638731388791247
Validation loss: 2.8160555643411556

Epoch: 84| Step: 0
Training loss: 3.069969721094972
Validation loss: 2.815027291420925

Epoch: 6| Step: 1
Training loss: 2.6996772255289696
Validation loss: 2.812205757965284

Epoch: 6| Step: 2
Training loss: 3.0036492405190724
Validation loss: 2.8137304378689287

Epoch: 6| Step: 3
Training loss: 3.2565915680903896
Validation loss: 2.8108254336630356

Epoch: 6| Step: 4
Training loss: 3.7472273431065393
Validation loss: 2.8177348041585644

Epoch: 6| Step: 5
Training loss: 2.46930697954477
Validation loss: 2.81974634678192

Epoch: 6| Step: 6
Training loss: 3.210041450161566
Validation loss: 2.8217973106736314

Epoch: 6| Step: 7
Training loss: 3.4593946061789143
Validation loss: 2.8174125854786687

Epoch: 6| Step: 8
Training loss: 3.432511194798495
Validation loss: 2.8215639638978565

Epoch: 6| Step: 9
Training loss: 3.092026355586669
Validation loss: 2.81385576574562

Epoch: 6| Step: 10
Training loss: 2.691872167468435
Validation loss: 2.8139150179571186

Epoch: 6| Step: 11
Training loss: 2.654847257139332
Validation loss: 2.814278862920076

Epoch: 6| Step: 12
Training loss: 3.0398378143213383
Validation loss: 2.813211842719717

Epoch: 6| Step: 13
Training loss: 3.9917804189466555
Validation loss: 2.816698363984317

Epoch: 85| Step: 0
Training loss: 2.282584649111372
Validation loss: 2.8084604538398503

Epoch: 6| Step: 1
Training loss: 2.6508431550793063
Validation loss: 2.8291246778390455

Epoch: 6| Step: 2
Training loss: 3.9123758119611356
Validation loss: 2.848046154383909

Epoch: 6| Step: 3
Training loss: 3.12526915344809
Validation loss: 2.8291658842751515

Epoch: 6| Step: 4
Training loss: 3.078738388677734
Validation loss: 2.8265749791707893

Epoch: 6| Step: 5
Training loss: 3.0373092340289745
Validation loss: 2.8170632063271865

Epoch: 6| Step: 6
Training loss: 2.731694067987684
Validation loss: 2.8097453364984433

Epoch: 6| Step: 7
Training loss: 3.5707556117771606
Validation loss: 2.804441460144031

Epoch: 6| Step: 8
Training loss: 2.9069687149469248
Validation loss: 2.810784009429794

Epoch: 6| Step: 9
Training loss: 3.362186408753178
Validation loss: 2.8127897562235344

Epoch: 6| Step: 10
Training loss: 2.5502145789126325
Validation loss: 2.8134695098009823

Epoch: 6| Step: 11
Training loss: 3.518422552290973
Validation loss: 2.8168356861906902

Epoch: 6| Step: 12
Training loss: 3.405675017097568
Validation loss: 2.82192817354169

Epoch: 6| Step: 13
Training loss: 3.4103947891406725
Validation loss: 2.8171016479811053

Epoch: 86| Step: 0
Training loss: 3.016346899405589
Validation loss: 2.813026336131644

Epoch: 6| Step: 1
Training loss: 3.6626388940090333
Validation loss: 2.810328683873359

Epoch: 6| Step: 2
Training loss: 3.0961436250083243
Validation loss: 2.8121952105941705

Epoch: 6| Step: 3
Training loss: 2.6517829583077104
Validation loss: 2.807543145828571

Epoch: 6| Step: 4
Training loss: 3.1917418136581333
Validation loss: 2.8070313258398096

Epoch: 6| Step: 5
Training loss: 3.1195541231963375
Validation loss: 2.809849683279266

Epoch: 6| Step: 6
Training loss: 3.2428239680250384
Validation loss: 2.8073493381906203

Epoch: 6| Step: 7
Training loss: 3.4108347703856285
Validation loss: 2.804000245165427

Epoch: 6| Step: 8
Training loss: 3.176336748964484
Validation loss: 2.808197544403607

Epoch: 6| Step: 9
Training loss: 3.157210251175774
Validation loss: 2.8065517624781524

Epoch: 6| Step: 10
Training loss: 3.593753582496516
Validation loss: 2.8036351901843934

Epoch: 6| Step: 11
Training loss: 2.614987123067453
Validation loss: 2.8092211233807034

Epoch: 6| Step: 12
Training loss: 1.9842639201155277
Validation loss: 2.8077156473794536

Epoch: 6| Step: 13
Training loss: 3.650362932111383
Validation loss: 2.8052714202706803

Epoch: 87| Step: 0
Training loss: 2.911827396119152
Validation loss: 2.804632710965353

Epoch: 6| Step: 1
Training loss: 2.8544637892018785
Validation loss: 2.8044756924965175

Epoch: 6| Step: 2
Training loss: 2.8547749857241307
Validation loss: 2.8081914917824995

Epoch: 6| Step: 3
Training loss: 3.122125906116699
Validation loss: 2.8065587457836223

Epoch: 6| Step: 4
Training loss: 3.6913837734930794
Validation loss: 2.818069711119622

Epoch: 6| Step: 5
Training loss: 3.2977230192689633
Validation loss: 2.8313287004869534

Epoch: 6| Step: 6
Training loss: 2.9820200631319347
Validation loss: 2.836157916956813

Epoch: 6| Step: 7
Training loss: 3.0433490402913828
Validation loss: 2.8378846808762557

Epoch: 6| Step: 8
Training loss: 3.207222304420625
Validation loss: 2.8164943410321115

Epoch: 6| Step: 9
Training loss: 2.5639499190939885
Validation loss: 2.8078714438256998

Epoch: 6| Step: 10
Training loss: 2.56621923592658
Validation loss: 2.8029945673804586

Epoch: 6| Step: 11
Training loss: 3.2039567565285707
Validation loss: 2.8002452067637114

Epoch: 6| Step: 12
Training loss: 3.5737774018834596
Validation loss: 2.8051167972857525

Epoch: 6| Step: 13
Training loss: 3.900048299637064
Validation loss: 2.804974462251679

Epoch: 88| Step: 0
Training loss: 3.465878784683918
Validation loss: 2.80466525545193

Epoch: 6| Step: 1
Training loss: 3.8519169332910232
Validation loss: 2.8021158116700633

Epoch: 6| Step: 2
Training loss: 3.6537085935821985
Validation loss: 2.8054321847022496

Epoch: 6| Step: 3
Training loss: 2.799866254200788
Validation loss: 2.8073808293378977

Epoch: 6| Step: 4
Training loss: 2.7184134088631215
Validation loss: 2.807539098851233

Epoch: 6| Step: 5
Training loss: 2.62362544083495
Validation loss: 2.808691364208611

Epoch: 6| Step: 6
Training loss: 3.4102896438150108
Validation loss: 2.8045567952138226

Epoch: 6| Step: 7
Training loss: 3.5343392961420537
Validation loss: 2.8059957150125654

Epoch: 6| Step: 8
Training loss: 3.074569275005304
Validation loss: 2.8057435812117926

Epoch: 6| Step: 9
Training loss: 3.501362671569646
Validation loss: 2.8048493627135644

Epoch: 6| Step: 10
Training loss: 2.3393747818192816
Validation loss: 2.8037743001652906

Epoch: 6| Step: 11
Training loss: 2.6211814354045715
Validation loss: 2.802306804047908

Epoch: 6| Step: 12
Training loss: 2.2130046118176683
Validation loss: 2.8003856875998663

Epoch: 6| Step: 13
Training loss: 3.5958214138948836
Validation loss: 2.799246376624806

Epoch: 89| Step: 0
Training loss: 2.8702562421124953
Validation loss: 2.802842299341575

Epoch: 6| Step: 1
Training loss: 2.6122187120781915
Validation loss: 2.8038266582966194

Epoch: 6| Step: 2
Training loss: 3.4191846330657074
Validation loss: 2.807154783830556

Epoch: 6| Step: 3
Training loss: 3.365153466135976
Validation loss: 2.811409246299487

Epoch: 6| Step: 4
Training loss: 3.132504417130141
Validation loss: 2.8247868756162697

Epoch: 6| Step: 5
Training loss: 2.957559636628047
Validation loss: 2.812513335457273

Epoch: 6| Step: 6
Training loss: 3.32694879083462
Validation loss: 2.8062843449827723

Epoch: 6| Step: 7
Training loss: 3.1466256127130903
Validation loss: 2.8019618123785777

Epoch: 6| Step: 8
Training loss: 2.9033400210607554
Validation loss: 2.799996181784281

Epoch: 6| Step: 9
Training loss: 2.7242558294364994
Validation loss: 2.802742254151728

Epoch: 6| Step: 10
Training loss: 3.1243934042614234
Validation loss: 2.7958121806490825

Epoch: 6| Step: 11
Training loss: 3.486563914470449
Validation loss: 2.795350297651572

Epoch: 6| Step: 12
Training loss: 2.8961603725561287
Validation loss: 2.7976830857814043

Epoch: 6| Step: 13
Training loss: 3.8459137819637013
Validation loss: 2.799335983899715

Epoch: 90| Step: 0
Training loss: 3.508298980351399
Validation loss: 2.7997855521848405

Epoch: 6| Step: 1
Training loss: 3.536701821366115
Validation loss: 2.7964115901237845

Epoch: 6| Step: 2
Training loss: 3.140538608254795
Validation loss: 2.8000329469465157

Epoch: 6| Step: 3
Training loss: 2.9703632990523117
Validation loss: 2.7993732989650475

Epoch: 6| Step: 4
Training loss: 3.104624123543191
Validation loss: 2.801317584179083

Epoch: 6| Step: 5
Training loss: 3.2033042299322667
Validation loss: 2.7961554207438137

Epoch: 6| Step: 6
Training loss: 3.082470145842812
Validation loss: 2.79717978519805

Epoch: 6| Step: 7
Training loss: 3.548006121048491
Validation loss: 2.7970008549090144

Epoch: 6| Step: 8
Training loss: 3.368862080876969
Validation loss: 2.7960353380813467

Epoch: 6| Step: 9
Training loss: 2.446738902627208
Validation loss: 2.7944612980111216

Epoch: 6| Step: 10
Training loss: 2.7092028078054256
Validation loss: 2.796983645380969

Epoch: 6| Step: 11
Training loss: 2.477727381398523
Validation loss: 2.7942143072427474

Epoch: 6| Step: 12
Training loss: 2.9468324822021392
Validation loss: 2.797498142168099

Epoch: 6| Step: 13
Training loss: 3.5316037701317775
Validation loss: 2.7962341986090764

Epoch: 91| Step: 0
Training loss: 3.204630130605842
Validation loss: 2.797445563866851

Epoch: 6| Step: 1
Training loss: 3.058629606969735
Validation loss: 2.7977297667139243

Epoch: 6| Step: 2
Training loss: 2.728368647336544
Validation loss: 2.805703283496899

Epoch: 6| Step: 3
Training loss: 3.443231970842118
Validation loss: 2.8039231374084603

Epoch: 6| Step: 4
Training loss: 3.1753627599900676
Validation loss: 2.805917552914936

Epoch: 6| Step: 5
Training loss: 3.5813042122297665
Validation loss: 2.806980758205618

Epoch: 6| Step: 6
Training loss: 3.202550026996462
Validation loss: 2.800432246584862

Epoch: 6| Step: 7
Training loss: 3.677696126535375
Validation loss: 2.7966024807179326

Epoch: 6| Step: 8
Training loss: 3.2911761598457048
Validation loss: 2.7951678044486252

Epoch: 6| Step: 9
Training loss: 2.668099574711591
Validation loss: 2.7938493600898697

Epoch: 6| Step: 10
Training loss: 2.874612533333297
Validation loss: 2.791873858689315

Epoch: 6| Step: 11
Training loss: 2.5235763842271166
Validation loss: 2.7970355696951543

Epoch: 6| Step: 12
Training loss: 2.6004691360951013
Validation loss: 2.794804988371896

Epoch: 6| Step: 13
Training loss: 3.5801010339215202
Validation loss: 2.7980208298623963

Epoch: 92| Step: 0
Training loss: 3.1937180250623878
Validation loss: 2.7978113279603187

Epoch: 6| Step: 1
Training loss: 3.1667965979438946
Validation loss: 2.7971129837205164

Epoch: 6| Step: 2
Training loss: 2.7064407387134803
Validation loss: 2.7959095910033147

Epoch: 6| Step: 3
Training loss: 2.6529977073731423
Validation loss: 2.798867372177345

Epoch: 6| Step: 4
Training loss: 3.47279836494743
Validation loss: 2.7968541470688253

Epoch: 6| Step: 5
Training loss: 2.601576429908277
Validation loss: 2.79604353134659

Epoch: 6| Step: 6
Training loss: 3.2224230502746543
Validation loss: 2.7949434440382874

Epoch: 6| Step: 7
Training loss: 2.9981974908726245
Validation loss: 2.7956070937731856

Epoch: 6| Step: 8
Training loss: 2.736506301775046
Validation loss: 2.793992559619286

Epoch: 6| Step: 9
Training loss: 3.4307762277511404
Validation loss: 2.794745792408707

Epoch: 6| Step: 10
Training loss: 3.5580653647325637
Validation loss: 2.790869954685545

Epoch: 6| Step: 11
Training loss: 2.68601203357901
Validation loss: 2.7925521194483047

Epoch: 6| Step: 12
Training loss: 3.9528289804711436
Validation loss: 2.7915477871243866

Epoch: 6| Step: 13
Training loss: 2.6939356728840895
Validation loss: 2.7931926219644807

Epoch: 93| Step: 0
Training loss: 2.8411504580526827
Validation loss: 2.7957148943623222

Epoch: 6| Step: 1
Training loss: 2.988091995130388
Validation loss: 2.7941215262777708

Epoch: 6| Step: 2
Training loss: 3.1391955106817844
Validation loss: 2.797215096236508

Epoch: 6| Step: 3
Training loss: 3.7369993557091115
Validation loss: 2.8016547491984283

Epoch: 6| Step: 4
Training loss: 3.0543470266117714
Validation loss: 2.808053153425224

Epoch: 6| Step: 5
Training loss: 2.760195558917523
Validation loss: 2.8013592362477717

Epoch: 6| Step: 6
Training loss: 3.5117468572898387
Validation loss: 2.796031150668051

Epoch: 6| Step: 7
Training loss: 2.4463552378462023
Validation loss: 2.8033516861640377

Epoch: 6| Step: 8
Training loss: 2.6778654348853146
Validation loss: 2.7921698889159843

Epoch: 6| Step: 9
Training loss: 2.8592097333664492
Validation loss: 2.791188075207411

Epoch: 6| Step: 10
Training loss: 3.5125077054085163
Validation loss: 2.78939363297062

Epoch: 6| Step: 11
Training loss: 3.2040213470509835
Validation loss: 2.793912235737813

Epoch: 6| Step: 12
Training loss: 3.465706254507052
Validation loss: 2.792308939805478

Epoch: 6| Step: 13
Training loss: 3.0119498989198865
Validation loss: 2.7933169210374076

Epoch: 94| Step: 0
Training loss: 3.1313499023581723
Validation loss: 2.7916915597358325

Epoch: 6| Step: 1
Training loss: 2.9898092115892783
Validation loss: 2.793360829873533

Epoch: 6| Step: 2
Training loss: 2.83920931649054
Validation loss: 2.796702248710453

Epoch: 6| Step: 3
Training loss: 3.916791196967187
Validation loss: 2.793385591902365

Epoch: 6| Step: 4
Training loss: 2.9203650505028036
Validation loss: 2.7871526283085717

Epoch: 6| Step: 5
Training loss: 3.1986177320067197
Validation loss: 2.787822595425638

Epoch: 6| Step: 6
Training loss: 3.109950486797896
Validation loss: 2.788688897759734

Epoch: 6| Step: 7
Training loss: 2.5948611717353653
Validation loss: 2.7887107650539873

Epoch: 6| Step: 8
Training loss: 3.889955148904141
Validation loss: 2.7859466963179185

Epoch: 6| Step: 9
Training loss: 3.027321698508397
Validation loss: 2.787873030543954

Epoch: 6| Step: 10
Training loss: 2.727720173341682
Validation loss: 2.7854158409694754

Epoch: 6| Step: 11
Training loss: 2.7409058099684223
Validation loss: 2.788677007972792

Epoch: 6| Step: 12
Training loss: 2.9675190833232556
Validation loss: 2.7846550444972764

Epoch: 6| Step: 13
Training loss: 3.123672203264495
Validation loss: 2.792955312962604

Epoch: 95| Step: 0
Training loss: 2.72772856428611
Validation loss: 2.782956695556419

Epoch: 6| Step: 1
Training loss: 3.1462737189919343
Validation loss: 2.787453389671346

Epoch: 6| Step: 2
Training loss: 3.4276982058276912
Validation loss: 2.7860546912631223

Epoch: 6| Step: 3
Training loss: 2.6245154887327575
Validation loss: 2.785541806370618

Epoch: 6| Step: 4
Training loss: 2.910925273286017
Validation loss: 2.785020781776935

Epoch: 6| Step: 5
Training loss: 3.2738173817461838
Validation loss: 2.783661638684059

Epoch: 6| Step: 6
Training loss: 3.0674473252627696
Validation loss: 2.780741899698052

Epoch: 6| Step: 7
Training loss: 3.1898309001528315
Validation loss: 2.785191628792711

Epoch: 6| Step: 8
Training loss: 3.2399391559492177
Validation loss: 2.784966985708206

Epoch: 6| Step: 9
Training loss: 3.3047729192565654
Validation loss: 2.782617509072468

Epoch: 6| Step: 10
Training loss: 3.032134566086319
Validation loss: 2.781950654626528

Epoch: 6| Step: 11
Training loss: 3.2569924472795053
Validation loss: 2.786618435461377

Epoch: 6| Step: 12
Training loss: 2.838008576243738
Validation loss: 2.7842513082706275

Epoch: 6| Step: 13
Training loss: 3.3991137303143195
Validation loss: 2.7839794787829404

Epoch: 96| Step: 0
Training loss: 3.487087545308408
Validation loss: 2.783983024071344

Epoch: 6| Step: 1
Training loss: 3.3606803309727784
Validation loss: 2.784665679609919

Epoch: 6| Step: 2
Training loss: 3.1644436076903695
Validation loss: 2.7897427841083835

Epoch: 6| Step: 3
Training loss: 2.706275118739879
Validation loss: 2.810606924848699

Epoch: 6| Step: 4
Training loss: 2.3723237870823697
Validation loss: 2.819880126773911

Epoch: 6| Step: 5
Training loss: 3.5884256477960834
Validation loss: 2.847601954598045

Epoch: 6| Step: 6
Training loss: 3.5965062725469057
Validation loss: 2.8312181133012255

Epoch: 6| Step: 7
Training loss: 2.741536467996146
Validation loss: 2.7970719484955735

Epoch: 6| Step: 8
Training loss: 3.196978370285486
Validation loss: 2.783295547801652

Epoch: 6| Step: 9
Training loss: 2.553662949178652
Validation loss: 2.782330749035499

Epoch: 6| Step: 10
Training loss: 3.058242641285762
Validation loss: 2.783145707838348

Epoch: 6| Step: 11
Training loss: 2.6515171746250377
Validation loss: 2.7781821597139316

Epoch: 6| Step: 12
Training loss: 3.3128932503526918
Validation loss: 2.7845535448862466

Epoch: 6| Step: 13
Training loss: 3.751241986915397
Validation loss: 2.782040776593813

Epoch: 97| Step: 0
Training loss: 3.2392650255704285
Validation loss: 2.7826101929763882

Epoch: 6| Step: 1
Training loss: 3.608772524798728
Validation loss: 2.7823099105662576

Epoch: 6| Step: 2
Training loss: 2.529775024935682
Validation loss: 2.7821883558612535

Epoch: 6| Step: 3
Training loss: 3.510443501506684
Validation loss: 2.78191189127506

Epoch: 6| Step: 4
Training loss: 3.1481957733275205
Validation loss: 2.7807538506101985

Epoch: 6| Step: 5
Training loss: 2.5593089261684354
Validation loss: 2.787863981973766

Epoch: 6| Step: 6
Training loss: 2.82822633003251
Validation loss: 2.7913421311513216

Epoch: 6| Step: 7
Training loss: 3.3626170992403397
Validation loss: 2.81078818033723

Epoch: 6| Step: 8
Training loss: 3.405054004929916
Validation loss: 2.8167154803642327

Epoch: 6| Step: 9
Training loss: 2.7968967372965956
Validation loss: 2.789289927158441

Epoch: 6| Step: 10
Training loss: 3.4004554106945837
Validation loss: 2.7969697005994463

Epoch: 6| Step: 11
Training loss: 3.139731512557605
Validation loss: 2.7814163696554983

Epoch: 6| Step: 12
Training loss: 2.4902807134169054
Validation loss: 2.7832179548569727

Epoch: 6| Step: 13
Training loss: 3.2865971184800946
Validation loss: 2.7812376732971895

Epoch: 98| Step: 0
Training loss: 3.2323006137564665
Validation loss: 2.7815625129341357

Epoch: 6| Step: 1
Training loss: 3.2126124855861384
Validation loss: 2.7850408920953633

Epoch: 6| Step: 2
Training loss: 2.675946886268235
Validation loss: 2.786376821901099

Epoch: 6| Step: 3
Training loss: 3.1543107826705783
Validation loss: 2.7897592057382137

Epoch: 6| Step: 4
Training loss: 2.876365171644062
Validation loss: 2.7881999152758623

Epoch: 6| Step: 5
Training loss: 3.325449266412935
Validation loss: 2.7864864700241596

Epoch: 6| Step: 6
Training loss: 3.0431476976226275
Validation loss: 2.786453357163453

Epoch: 6| Step: 7
Training loss: 2.8641577572129515
Validation loss: 2.7887171293080684

Epoch: 6| Step: 8
Training loss: 2.795404484505709
Validation loss: 2.785335961436807

Epoch: 6| Step: 9
Training loss: 2.9674527194877123
Validation loss: 2.7895626103339866

Epoch: 6| Step: 10
Training loss: 2.9388633972902056
Validation loss: 2.784967161529086

Epoch: 6| Step: 11
Training loss: 3.8242832135542923
Validation loss: 2.785411288306788

Epoch: 6| Step: 12
Training loss: 2.9418160405115303
Validation loss: 2.781959759291267

Epoch: 6| Step: 13
Training loss: 3.8101762037006988
Validation loss: 2.775999408774227

Epoch: 99| Step: 0
Training loss: 2.9349097336465597
Validation loss: 2.7810541618395086

Epoch: 6| Step: 1
Training loss: 3.162650539750554
Validation loss: 2.7824641600063917

Epoch: 6| Step: 2
Training loss: 2.8014960447600408
Validation loss: 2.779602232785149

Epoch: 6| Step: 3
Training loss: 3.086483523192766
Validation loss: 2.784406429801302

Epoch: 6| Step: 4
Training loss: 3.2552159342359177
Validation loss: 2.7879488019709147

Epoch: 6| Step: 5
Training loss: 3.104681872596498
Validation loss: 2.8005643457897675

Epoch: 6| Step: 6
Training loss: 2.974563688452092
Validation loss: 2.799731502316625

Epoch: 6| Step: 7
Training loss: 3.150852384740873
Validation loss: 2.8041349061958805

Epoch: 6| Step: 8
Training loss: 3.329715545693712
Validation loss: 2.807500308934979

Epoch: 6| Step: 9
Training loss: 2.8403212448893735
Validation loss: 2.8039938963996747

Epoch: 6| Step: 10
Training loss: 3.1776689500410025
Validation loss: 2.785059989721562

Epoch: 6| Step: 11
Training loss: 3.602461762605899
Validation loss: 2.7810114995281174

Epoch: 6| Step: 12
Training loss: 2.6958014445553657
Validation loss: 2.7775291476873605

Epoch: 6| Step: 13
Training loss: 3.230968801042583
Validation loss: 2.7738470135389406

Epoch: 100| Step: 0
Training loss: 2.4289388699210765
Validation loss: 2.774321061985118

Epoch: 6| Step: 1
Training loss: 2.3553622650318853
Validation loss: 2.7729820273778083

Epoch: 6| Step: 2
Training loss: 2.903241312676042
Validation loss: 2.779270682230465

Epoch: 6| Step: 3
Training loss: 3.212368759858744
Validation loss: 2.7764216931353936

Epoch: 6| Step: 4
Training loss: 2.7598706743099424
Validation loss: 2.775107408311233

Epoch: 6| Step: 5
Training loss: 3.242191912176968
Validation loss: 2.772937906790602

Epoch: 6| Step: 6
Training loss: 3.315971139282973
Validation loss: 2.7792576263395743

Epoch: 6| Step: 7
Training loss: 3.199831129625074
Validation loss: 2.778548025651083

Epoch: 6| Step: 8
Training loss: 3.375898171050737
Validation loss: 2.7781443883779295

Epoch: 6| Step: 9
Training loss: 3.414775852426401
Validation loss: 2.7771845277038447

Epoch: 6| Step: 10
Training loss: 2.8526388566825758
Validation loss: 2.780496530946944

Epoch: 6| Step: 11
Training loss: 2.997374975605282
Validation loss: 2.777536853747256

Epoch: 6| Step: 12
Training loss: 3.8460520232000417
Validation loss: 2.79123903824734

Epoch: 6| Step: 13
Training loss: 3.0474039254444847
Validation loss: 2.7898463738435333

Epoch: 101| Step: 0
Training loss: 2.6522998834277507
Validation loss: 2.793493200150284

Epoch: 6| Step: 1
Training loss: 3.2499640536154364
Validation loss: 2.8079034394894498

Epoch: 6| Step: 2
Training loss: 2.4465694426709574
Validation loss: 2.8034869599354386

Epoch: 6| Step: 3
Training loss: 3.2136513038534202
Validation loss: 2.7934057943468122

Epoch: 6| Step: 4
Training loss: 3.482662036464275
Validation loss: 2.807924864072931

Epoch: 6| Step: 5
Training loss: 2.865667870719822
Validation loss: 2.7960673032326353

Epoch: 6| Step: 6
Training loss: 3.0633609106616424
Validation loss: 2.7896265498392063

Epoch: 6| Step: 7
Training loss: 3.002852355457517
Validation loss: 2.7825310952693365

Epoch: 6| Step: 8
Training loss: 2.814272682181898
Validation loss: 2.782681967460671

Epoch: 6| Step: 9
Training loss: 4.094745078250828
Validation loss: 2.7837186123618474

Epoch: 6| Step: 10
Training loss: 2.8511681689034347
Validation loss: 2.7757233788129145

Epoch: 6| Step: 11
Training loss: 3.0458472450310894
Validation loss: 2.7746518956694994

Epoch: 6| Step: 12
Training loss: 2.9394596137802136
Validation loss: 2.7718118689477538

Epoch: 6| Step: 13
Training loss: 3.3118164508839714
Validation loss: 2.7722508624687623

Epoch: 102| Step: 0
Training loss: 3.4334090425112826
Validation loss: 2.7745798986749595

Epoch: 6| Step: 1
Training loss: 2.6357447202655484
Validation loss: 2.7740971669412535

Epoch: 6| Step: 2
Training loss: 3.1131988476194925
Validation loss: 2.775998189751496

Epoch: 6| Step: 3
Training loss: 2.8573050589160114
Validation loss: 2.773067185623835

Epoch: 6| Step: 4
Training loss: 2.9737056128198547
Validation loss: 2.7750143284877193

Epoch: 6| Step: 5
Training loss: 2.317709133419513
Validation loss: 2.771811857848989

Epoch: 6| Step: 6
Training loss: 3.3068301061518337
Validation loss: 2.774050961648416

Epoch: 6| Step: 7
Training loss: 3.238526853811981
Validation loss: 2.7738361789046877

Epoch: 6| Step: 8
Training loss: 3.4619377533568794
Validation loss: 2.7756205495268182

Epoch: 6| Step: 9
Training loss: 3.45370409498382
Validation loss: 2.7748898701319953

Epoch: 6| Step: 10
Training loss: 2.778099933592712
Validation loss: 2.7722649389865865

Epoch: 6| Step: 11
Training loss: 2.886637643957448
Validation loss: 2.7740535899312464

Epoch: 6| Step: 12
Training loss: 3.3491483943909333
Validation loss: 2.774021128060944

Epoch: 6| Step: 13
Training loss: 3.4974568528083174
Validation loss: 2.7737468310690376

Epoch: 103| Step: 0
Training loss: 3.0223882071721886
Validation loss: 2.7739050945162296

Epoch: 6| Step: 1
Training loss: 3.393222218426109
Validation loss: 2.771108333484131

Epoch: 6| Step: 2
Training loss: 2.5545905325215776
Validation loss: 2.771684882297686

Epoch: 6| Step: 3
Training loss: 3.0050130920632743
Validation loss: 2.7696144525061404

Epoch: 6| Step: 4
Training loss: 3.1935587129584437
Validation loss: 2.7751822192935474

Epoch: 6| Step: 5
Training loss: 2.501993433607528
Validation loss: 2.7725970545293306

Epoch: 6| Step: 6
Training loss: 3.4184708057611535
Validation loss: 2.768303774887098

Epoch: 6| Step: 7
Training loss: 3.0819065470058526
Validation loss: 2.7690040057239287

Epoch: 6| Step: 8
Training loss: 3.563255631468283
Validation loss: 2.769445728925645

Epoch: 6| Step: 9
Training loss: 2.6743968640187257
Validation loss: 2.7690506942601067

Epoch: 6| Step: 10
Training loss: 3.252542821439535
Validation loss: 2.7733248313238774

Epoch: 6| Step: 11
Training loss: 2.116926451633012
Validation loss: 2.7715749029675982

Epoch: 6| Step: 12
Training loss: 3.5008937511998193
Validation loss: 2.7756698043195223

Epoch: 6| Step: 13
Training loss: 3.8761083186931433
Validation loss: 2.7756534877502705

Epoch: 104| Step: 0
Training loss: 2.9238839000817434
Validation loss: 2.772000600715109

Epoch: 6| Step: 1
Training loss: 2.6384402836296186
Validation loss: 2.769487828862352

Epoch: 6| Step: 2
Training loss: 3.4788443288511606
Validation loss: 2.7681929897999438

Epoch: 6| Step: 3
Training loss: 3.445311254384341
Validation loss: 2.7707223036494297

Epoch: 6| Step: 4
Training loss: 3.23040852611639
Validation loss: 2.7703295970016915

Epoch: 6| Step: 5
Training loss: 2.5673738974978346
Validation loss: 2.7686728416148565

Epoch: 6| Step: 6
Training loss: 3.040335342081457
Validation loss: 2.767625251644532

Epoch: 6| Step: 7
Training loss: 2.96429542828805
Validation loss: 2.7734524412328967

Epoch: 6| Step: 8
Training loss: 2.7845626134204777
Validation loss: 2.7740515512563846

Epoch: 6| Step: 9
Training loss: 3.025808267352108
Validation loss: 2.7738051627625877

Epoch: 6| Step: 10
Training loss: 3.27692338796072
Validation loss: 2.776914115039549

Epoch: 6| Step: 11
Training loss: 3.2078261697053327
Validation loss: 2.7777600811493732

Epoch: 6| Step: 12
Training loss: 3.209109786236237
Validation loss: 2.7887573663546754

Epoch: 6| Step: 13
Training loss: 3.312343089867823
Validation loss: 2.783282011562418

Epoch: 105| Step: 0
Training loss: 3.3646236137758305
Validation loss: 2.797174162409272

Epoch: 6| Step: 1
Training loss: 3.7911134812363905
Validation loss: 2.778688038677881

Epoch: 6| Step: 2
Training loss: 3.509938434810803
Validation loss: 2.772739230178561

Epoch: 6| Step: 3
Training loss: 3.1983478930527736
Validation loss: 2.7688004904685686

Epoch: 6| Step: 4
Training loss: 2.942443907793774
Validation loss: 2.767811656911026

Epoch: 6| Step: 5
Training loss: 2.8743909107687764
Validation loss: 2.769495243494685

Epoch: 6| Step: 6
Training loss: 2.850132748373242
Validation loss: 2.7634801216236475

Epoch: 6| Step: 7
Training loss: 2.4075574419214014
Validation loss: 2.7739935509758102

Epoch: 6| Step: 8
Training loss: 2.4156595521259496
Validation loss: 2.771554330497078

Epoch: 6| Step: 9
Training loss: 3.319501135930348
Validation loss: 2.7689192127592386

Epoch: 6| Step: 10
Training loss: 3.0529852219194886
Validation loss: 2.770719537118364

Epoch: 6| Step: 11
Training loss: 2.89089007837577
Validation loss: 2.7737115983648115

Epoch: 6| Step: 12
Training loss: 2.890756305083647
Validation loss: 2.772107466932859

Epoch: 6| Step: 13
Training loss: 3.6718266910053496
Validation loss: 2.7777648710819225

Epoch: 106| Step: 0
Training loss: 3.1238388956219847
Validation loss: 2.769196165354808

Epoch: 6| Step: 1
Training loss: 3.617684579396526
Validation loss: 2.764886856643634

Epoch: 6| Step: 2
Training loss: 3.2745793429151897
Validation loss: 2.7656967369765186

Epoch: 6| Step: 3
Training loss: 2.797765408932055
Validation loss: 2.767073496506736

Epoch: 6| Step: 4
Training loss: 3.368024611358243
Validation loss: 2.7784109748197188

Epoch: 6| Step: 5
Training loss: 3.1993573616377744
Validation loss: 2.7957892474507426

Epoch: 6| Step: 6
Training loss: 2.7369508654107864
Validation loss: 2.7886733523598832

Epoch: 6| Step: 7
Training loss: 3.1470568637516743
Validation loss: 2.79616217054729

Epoch: 6| Step: 8
Training loss: 3.2317601935585247
Validation loss: 2.7780471394967936

Epoch: 6| Step: 9
Training loss: 2.938643537286106
Validation loss: 2.778782275981635

Epoch: 6| Step: 10
Training loss: 2.561529673642571
Validation loss: 2.7738580117168983

Epoch: 6| Step: 11
Training loss: 3.1705581111157564
Validation loss: 2.7726195008808645

Epoch: 6| Step: 12
Training loss: 2.860357730607467
Validation loss: 2.7678710445309935

Epoch: 6| Step: 13
Training loss: 3.306580490583958
Validation loss: 2.7730079633692215

Epoch: 107| Step: 0
Training loss: 2.4965489409753334
Validation loss: 2.7714187894240134

Epoch: 6| Step: 1
Training loss: 2.786066492403143
Validation loss: 2.77237521459135

Epoch: 6| Step: 2
Training loss: 3.2972704031070994
Validation loss: 2.774594528846115

Epoch: 6| Step: 3
Training loss: 3.335745955603074
Validation loss: 2.7707193520660205

Epoch: 6| Step: 4
Training loss: 3.2574871092839155
Validation loss: 2.7691776554338365

Epoch: 6| Step: 5
Training loss: 2.77122826498453
Validation loss: 2.7668943148656564

Epoch: 6| Step: 6
Training loss: 2.9866215902855138
Validation loss: 2.7707611088141304

Epoch: 6| Step: 7
Training loss: 2.71610051986236
Validation loss: 2.771760609754082

Epoch: 6| Step: 8
Training loss: 2.476844266151651
Validation loss: 2.7661465314791553

Epoch: 6| Step: 9
Training loss: 3.0279286859295738
Validation loss: 2.767459443370774

Epoch: 6| Step: 10
Training loss: 3.2066464303608067
Validation loss: 2.777840752109968

Epoch: 6| Step: 11
Training loss: 3.8164106230383723
Validation loss: 2.78216147526356

Epoch: 6| Step: 12
Training loss: 3.503122571660203
Validation loss: 2.7829760469935714

Epoch: 6| Step: 13
Training loss: 3.3814920222453266
Validation loss: 2.7879669711748187

Epoch: 108| Step: 0
Training loss: 3.2997993408232063
Validation loss: 2.7860804236651164

Epoch: 6| Step: 1
Training loss: 2.706504164955575
Validation loss: 2.778584521021487

Epoch: 6| Step: 2
Training loss: 2.8116371526640784
Validation loss: 2.770761469660751

Epoch: 6| Step: 3
Training loss: 2.5165570351003543
Validation loss: 2.7633594011188296

Epoch: 6| Step: 4
Training loss: 3.4749123761223846
Validation loss: 2.757099859798017

Epoch: 6| Step: 5
Training loss: 3.1047801663872754
Validation loss: 2.759757290589895

Epoch: 6| Step: 6
Training loss: 2.509241380376283
Validation loss: 2.7628971127167308

Epoch: 6| Step: 7
Training loss: 2.9997523523476133
Validation loss: 2.7585284941385058

Epoch: 6| Step: 8
Training loss: 2.925563992632496
Validation loss: 2.76093969113045

Epoch: 6| Step: 9
Training loss: 3.567227355761114
Validation loss: 2.7596199289742165

Epoch: 6| Step: 10
Training loss: 3.5468603461546824
Validation loss: 2.762566508306089

Epoch: 6| Step: 11
Training loss: 3.3820152841016218
Validation loss: 2.758940898039454

Epoch: 6| Step: 12
Training loss: 3.1188137621276644
Validation loss: 2.759336927591643

Epoch: 6| Step: 13
Training loss: 3.0002992798615598
Validation loss: 2.7592573490117704

Epoch: 109| Step: 0
Training loss: 2.97261951639385
Validation loss: 2.753586224355647

Epoch: 6| Step: 1
Training loss: 2.6833485320551302
Validation loss: 2.755068196539374

Epoch: 6| Step: 2
Training loss: 2.8055518898347214
Validation loss: 2.7548935988391863

Epoch: 6| Step: 3
Training loss: 3.180502897120024
Validation loss: 2.7579992933416597

Epoch: 6| Step: 4
Training loss: 3.3868120965995945
Validation loss: 2.7641464470052806

Epoch: 6| Step: 5
Training loss: 3.050928793647313
Validation loss: 2.763478664229231

Epoch: 6| Step: 6
Training loss: 2.8573844943727194
Validation loss: 2.7612405697095523

Epoch: 6| Step: 7
Training loss: 3.6366988200984514
Validation loss: 2.768428057981456

Epoch: 6| Step: 8
Training loss: 2.715135824834965
Validation loss: 2.768033983915424

Epoch: 6| Step: 9
Training loss: 2.595753918244804
Validation loss: 2.775032639193741

Epoch: 6| Step: 10
Training loss: 2.7838121249833994
Validation loss: 2.7716661799593103

Epoch: 6| Step: 11
Training loss: 3.9706149788082605
Validation loss: 2.7654101616987594

Epoch: 6| Step: 12
Training loss: 2.8535565654681982
Validation loss: 2.7642622363487948

Epoch: 6| Step: 13
Training loss: 3.5436106713302777
Validation loss: 2.760798373138261

Epoch: 110| Step: 0
Training loss: 2.9669418450221037
Validation loss: 2.755173117893733

Epoch: 6| Step: 1
Training loss: 2.9278565241988797
Validation loss: 2.7577804474791003

Epoch: 6| Step: 2
Training loss: 2.9970138310802845
Validation loss: 2.75338453501429

Epoch: 6| Step: 3
Training loss: 2.1682711553589464
Validation loss: 2.7542242772576273

Epoch: 6| Step: 4
Training loss: 2.5088263152888133
Validation loss: 2.756451076628555

Epoch: 6| Step: 5
Training loss: 3.5664565217568587
Validation loss: 2.7546864343721778

Epoch: 6| Step: 6
Training loss: 2.877864902933446
Validation loss: 2.7544820743953546

Epoch: 6| Step: 7
Training loss: 3.2830651485173394
Validation loss: 2.7578400408867925

Epoch: 6| Step: 8
Training loss: 2.8672410507814186
Validation loss: 2.75724671918671

Epoch: 6| Step: 9
Training loss: 3.99712578506431
Validation loss: 2.750697423178977

Epoch: 6| Step: 10
Training loss: 3.234296714830442
Validation loss: 2.7546868634004062

Epoch: 6| Step: 11
Training loss: 3.514794688190802
Validation loss: 2.7531760772205374

Epoch: 6| Step: 12
Training loss: 3.0809477435381933
Validation loss: 2.7539693035795936

Epoch: 6| Step: 13
Training loss: 2.2926677135824907
Validation loss: 2.7502437126515042

Epoch: 111| Step: 0
Training loss: 3.9878384963671625
Validation loss: 2.759867599653108

Epoch: 6| Step: 1
Training loss: 3.2622243889042966
Validation loss: 2.7612816564985363

Epoch: 6| Step: 2
Training loss: 2.7959373223588333
Validation loss: 2.7657366776946155

Epoch: 6| Step: 3
Training loss: 2.868118342917442
Validation loss: 2.7701846462963857

Epoch: 6| Step: 4
Training loss: 2.891205105694821
Validation loss: 2.7733912938850436

Epoch: 6| Step: 5
Training loss: 2.3724900082859155
Validation loss: 2.7689615799389853

Epoch: 6| Step: 6
Training loss: 3.052816691298609
Validation loss: 2.7622979249787405

Epoch: 6| Step: 7
Training loss: 3.2849971628394568
Validation loss: 2.7653068098497755

Epoch: 6| Step: 8
Training loss: 2.6896844015084778
Validation loss: 2.754973495161158

Epoch: 6| Step: 9
Training loss: 3.2743824616820643
Validation loss: 2.753470880809595

Epoch: 6| Step: 10
Training loss: 3.1806872996253572
Validation loss: 2.7552432325871283

Epoch: 6| Step: 11
Training loss: 2.8348726317305273
Validation loss: 2.7491721177731017

Epoch: 6| Step: 12
Training loss: 3.2980604887828995
Validation loss: 2.753150449783725

Epoch: 6| Step: 13
Training loss: 2.87579351338096
Validation loss: 2.7476148712334085

Epoch: 112| Step: 0
Training loss: 3.110713191546047
Validation loss: 2.7540619459891102

Epoch: 6| Step: 1
Training loss: 2.9487464375007457
Validation loss: 2.7473166827555944

Epoch: 6| Step: 2
Training loss: 3.672365326304526
Validation loss: 2.7542582411243863

Epoch: 6| Step: 3
Training loss: 3.113343433252108
Validation loss: 2.7515212491110144

Epoch: 6| Step: 4
Training loss: 2.677198405087194
Validation loss: 2.7482794024327295

Epoch: 6| Step: 5
Training loss: 3.139472408313772
Validation loss: 2.751309232341095

Epoch: 6| Step: 6
Training loss: 2.7768063139249937
Validation loss: 2.754061636944232

Epoch: 6| Step: 7
Training loss: 3.147755589246692
Validation loss: 2.7600201886021125

Epoch: 6| Step: 8
Training loss: 3.1870787099042595
Validation loss: 2.7593738210525514

Epoch: 6| Step: 9
Training loss: 2.718667390817967
Validation loss: 2.760533770822605

Epoch: 6| Step: 10
Training loss: 2.931677058817575
Validation loss: 2.7613651094294265

Epoch: 6| Step: 11
Training loss: 2.788518430498792
Validation loss: 2.767082752035058

Epoch: 6| Step: 12
Training loss: 3.6828866322387457
Validation loss: 2.77473260156026

Epoch: 6| Step: 13
Training loss: 2.8642628068486973
Validation loss: 2.771848696254052

Epoch: 113| Step: 0
Training loss: 3.2731675648976406
Validation loss: 2.764750033622636

Epoch: 6| Step: 1
Training loss: 3.0342158329839313
Validation loss: 2.776848670632079

Epoch: 6| Step: 2
Training loss: 3.3041561772748036
Validation loss: 2.768217387959738

Epoch: 6| Step: 3
Training loss: 2.553847428534528
Validation loss: 2.773524009029019

Epoch: 6| Step: 4
Training loss: 2.6737254020625913
Validation loss: 2.769071276072957

Epoch: 6| Step: 5
Training loss: 3.608911657937523
Validation loss: 2.752646379206039

Epoch: 6| Step: 6
Training loss: 2.9892348419772445
Validation loss: 2.760202326069478

Epoch: 6| Step: 7
Training loss: 3.295116950175218
Validation loss: 2.7532483564438657

Epoch: 6| Step: 8
Training loss: 3.0557250775407985
Validation loss: 2.7522007236581665

Epoch: 6| Step: 9
Training loss: 3.0771327864267954
Validation loss: 2.753753994424685

Epoch: 6| Step: 10
Training loss: 2.4870568920725393
Validation loss: 2.7459240199876014

Epoch: 6| Step: 11
Training loss: 3.4471095927860684
Validation loss: 2.74618244321108

Epoch: 6| Step: 12
Training loss: 2.7772247675265307
Validation loss: 2.751648668784469

Epoch: 6| Step: 13
Training loss: 3.2208582815871236
Validation loss: 2.74863513327215

Epoch: 114| Step: 0
Training loss: 2.9675883379468364
Validation loss: 2.749537968906202

Epoch: 6| Step: 1
Training loss: 2.815121679166278
Validation loss: 2.7545864419835846

Epoch: 6| Step: 2
Training loss: 3.1762346645496944
Validation loss: 2.7515682995132686

Epoch: 6| Step: 3
Training loss: 2.755210967804792
Validation loss: 2.749860650947974

Epoch: 6| Step: 4
Training loss: 2.7959291361177048
Validation loss: 2.748469799562512

Epoch: 6| Step: 5
Training loss: 3.6795452114706833
Validation loss: 2.7513415251750106

Epoch: 6| Step: 6
Training loss: 3.7403460533261907
Validation loss: 2.7528721138624563

Epoch: 6| Step: 7
Training loss: 2.9682109142535915
Validation loss: 2.7461132090356135

Epoch: 6| Step: 8
Training loss: 3.24632407425956
Validation loss: 2.7473794154088895

Epoch: 6| Step: 9
Training loss: 2.0642750355571122
Validation loss: 2.7474061137706265

Epoch: 6| Step: 10
Training loss: 2.920631021484855
Validation loss: 2.7409915789616144

Epoch: 6| Step: 11
Training loss: 3.767782645757824
Validation loss: 2.744610928857511

Epoch: 6| Step: 12
Training loss: 2.9368127871246155
Validation loss: 2.7434597877638

Epoch: 6| Step: 13
Training loss: 2.2493136736710326
Validation loss: 2.7484806371863493

Epoch: 115| Step: 0
Training loss: 3.1051307734226192
Validation loss: 2.746844044122137

Epoch: 6| Step: 1
Training loss: 2.5279972228022904
Validation loss: 2.744007474369209

Epoch: 6| Step: 2
Training loss: 3.05731759176792
Validation loss: 2.747444294627148

Epoch: 6| Step: 3
Training loss: 2.9270794055048066
Validation loss: 2.7469213010105675

Epoch: 6| Step: 4
Training loss: 3.2031982413501465
Validation loss: 2.748139599519369

Epoch: 6| Step: 5
Training loss: 3.2140100633407886
Validation loss: 2.743397314041045

Epoch: 6| Step: 6
Training loss: 3.2040232817700485
Validation loss: 2.7444930606014704

Epoch: 6| Step: 7
Training loss: 3.218050093617142
Validation loss: 2.747663571872692

Epoch: 6| Step: 8
Training loss: 3.3119869194693883
Validation loss: 2.7411826038694036

Epoch: 6| Step: 9
Training loss: 2.9901005810307075
Validation loss: 2.7484309436388044

Epoch: 6| Step: 10
Training loss: 3.422263206164965
Validation loss: 2.7488070032281398

Epoch: 6| Step: 11
Training loss: 2.418118325877697
Validation loss: 2.7458032484045134

Epoch: 6| Step: 12
Training loss: 2.868218426291479
Validation loss: 2.75021257259459

Epoch: 6| Step: 13
Training loss: 3.4814631179418454
Validation loss: 2.752199628228621

Epoch: 116| Step: 0
Training loss: 3.0154181691133886
Validation loss: 2.7573550999806087

Epoch: 6| Step: 1
Training loss: 3.2800388098956064
Validation loss: 2.7536839572543346

Epoch: 6| Step: 2
Training loss: 3.635495349866894
Validation loss: 2.7467297866656013

Epoch: 6| Step: 3
Training loss: 3.4946468833044144
Validation loss: 2.7491141054843777

Epoch: 6| Step: 4
Training loss: 3.156532954761383
Validation loss: 2.746408110812906

Epoch: 6| Step: 5
Training loss: 2.546461013192903
Validation loss: 2.747473235508431

Epoch: 6| Step: 6
Training loss: 2.325458202536783
Validation loss: 2.7500931592582925

Epoch: 6| Step: 7
Training loss: 2.869840221144282
Validation loss: 2.7477261706506555

Epoch: 6| Step: 8
Training loss: 3.452324822005563
Validation loss: 2.74831835471208

Epoch: 6| Step: 9
Training loss: 2.789844990871285
Validation loss: 2.7518234984542183

Epoch: 6| Step: 10
Training loss: 2.624937874195081
Validation loss: 2.752006660020529

Epoch: 6| Step: 11
Training loss: 2.9689657032554173
Validation loss: 2.7453900055720366

Epoch: 6| Step: 12
Training loss: 3.2061898804023343
Validation loss: 2.7480181631243976

Epoch: 6| Step: 13
Training loss: 3.3106793852536307
Validation loss: 2.748704926017982

Epoch: 117| Step: 0
Training loss: 2.9006995245334215
Validation loss: 2.748560016651186

Epoch: 6| Step: 1
Training loss: 2.8882527282643844
Validation loss: 2.753879443366681

Epoch: 6| Step: 2
Training loss: 3.2850581278078126
Validation loss: 2.76287312316879

Epoch: 6| Step: 3
Training loss: 3.015651406286184
Validation loss: 2.7552871033758164

Epoch: 6| Step: 4
Training loss: 2.93404721185291
Validation loss: 2.753763588903501

Epoch: 6| Step: 5
Training loss: 2.740011106872323
Validation loss: 2.7559221248244965

Epoch: 6| Step: 6
Training loss: 3.6319988693201934
Validation loss: 2.7446047948562615

Epoch: 6| Step: 7
Training loss: 3.4045310626563237
Validation loss: 2.7403710393730027

Epoch: 6| Step: 8
Training loss: 3.012833167682715
Validation loss: 2.743031287839899

Epoch: 6| Step: 9
Training loss: 3.0946977493037826
Validation loss: 2.7463194472934047

Epoch: 6| Step: 10
Training loss: 3.0657798175819115
Validation loss: 2.7415758106347705

Epoch: 6| Step: 11
Training loss: 2.846715366146481
Validation loss: 2.7426647276673517

Epoch: 6| Step: 12
Training loss: 2.761057902777969
Validation loss: 2.743776332132655

Epoch: 6| Step: 13
Training loss: 3.312917719000309
Validation loss: 2.7443958859598894

Epoch: 118| Step: 0
Training loss: 2.9585460174473397
Validation loss: 2.743963785742678

Epoch: 6| Step: 1
Training loss: 2.950632324985364
Validation loss: 2.7472383367786373

Epoch: 6| Step: 2
Training loss: 3.514921126369291
Validation loss: 2.747318524780196

Epoch: 6| Step: 3
Training loss: 3.432032033606287
Validation loss: 2.7457492390370857

Epoch: 6| Step: 4
Training loss: 2.861050141146822
Validation loss: 2.7461345182205052

Epoch: 6| Step: 5
Training loss: 2.7760155958677495
Validation loss: 2.743645497000543

Epoch: 6| Step: 6
Training loss: 2.75448597967707
Validation loss: 2.7444803595664853

Epoch: 6| Step: 7
Training loss: 3.258267377753342
Validation loss: 2.7455285562725393

Epoch: 6| Step: 8
Training loss: 2.8217543194926087
Validation loss: 2.741134987540973

Epoch: 6| Step: 9
Training loss: 3.3240938084720133
Validation loss: 2.7407294579195183

Epoch: 6| Step: 10
Training loss: 2.560263239022187
Validation loss: 2.7407010781539194

Epoch: 6| Step: 11
Training loss: 3.371021893244885
Validation loss: 2.742922259757273

Epoch: 6| Step: 12
Training loss: 3.1633753654439674
Validation loss: 2.747936526170029

Epoch: 6| Step: 13
Training loss: 3.010129199882921
Validation loss: 2.749610272905025

Epoch: 119| Step: 0
Training loss: 3.1047807807136825
Validation loss: 2.766147301642647

Epoch: 6| Step: 1
Training loss: 2.682442986130429
Validation loss: 2.7762592995859587

Epoch: 6| Step: 2
Training loss: 3.3018948634581107
Validation loss: 2.790689642396728

Epoch: 6| Step: 3
Training loss: 3.6397958228727814
Validation loss: 2.800723923176442

Epoch: 6| Step: 4
Training loss: 3.7890078825799414
Validation loss: 2.78620394600784

Epoch: 6| Step: 5
Training loss: 3.4491775527515647
Validation loss: 2.762965544044924

Epoch: 6| Step: 6
Training loss: 1.4012219290597205
Validation loss: 2.7478000272201775

Epoch: 6| Step: 7
Training loss: 3.551823059271472
Validation loss: 2.7411615751058647

Epoch: 6| Step: 8
Training loss: 2.853459477117001
Validation loss: 2.742340254720659

Epoch: 6| Step: 9
Training loss: 2.8765360833591482
Validation loss: 2.7415472236206258

Epoch: 6| Step: 10
Training loss: 2.9322862822696085
Validation loss: 2.740464927277339

Epoch: 6| Step: 11
Training loss: 2.879054320628204
Validation loss: 2.7440633075746272

Epoch: 6| Step: 12
Training loss: 2.967489999113127
Validation loss: 2.746645103162464

Epoch: 6| Step: 13
Training loss: 2.8586554950927585
Validation loss: 2.74812586959199

Epoch: 120| Step: 0
Training loss: 2.748053034902256
Validation loss: 2.7532338735617716

Epoch: 6| Step: 1
Training loss: 3.417500525964949
Validation loss: 2.753699246791524

Epoch: 6| Step: 2
Training loss: 3.2444927798405563
Validation loss: 2.751088815264178

Epoch: 6| Step: 3
Training loss: 2.736278895630274
Validation loss: 2.745106987521956

Epoch: 6| Step: 4
Training loss: 2.8351207219008265
Validation loss: 2.7476449915367467

Epoch: 6| Step: 5
Training loss: 3.237388055110564
Validation loss: 2.7457533644821472

Epoch: 6| Step: 6
Training loss: 2.7506226788324444
Validation loss: 2.746509999895513

Epoch: 6| Step: 7
Training loss: 2.9320293374669024
Validation loss: 2.743520433244754

Epoch: 6| Step: 8
Training loss: 3.347439450662923
Validation loss: 2.7386192972214958

Epoch: 6| Step: 9
Training loss: 3.2653291559136823
Validation loss: 2.7372803369213807

Epoch: 6| Step: 10
Training loss: 3.295002627103971
Validation loss: 2.744536570798653

Epoch: 6| Step: 11
Training loss: 3.0796412107878113
Validation loss: 2.7449060331281845

Epoch: 6| Step: 12
Training loss: 2.995780520621358
Validation loss: 2.756386951642481

Epoch: 6| Step: 13
Training loss: 2.849957910862714
Validation loss: 2.755385682164978

Epoch: 121| Step: 0
Training loss: 2.602441037963992
Validation loss: 2.755282494882324

Epoch: 6| Step: 1
Training loss: 2.8204726070702915
Validation loss: 2.760123761627092

Epoch: 6| Step: 2
Training loss: 3.6068625685207083
Validation loss: 2.783230897296767

Epoch: 6| Step: 3
Training loss: 3.3925926019319066
Validation loss: 2.749723659215474

Epoch: 6| Step: 4
Training loss: 2.5573580254816894
Validation loss: 2.7384365817662246

Epoch: 6| Step: 5
Training loss: 3.045572325190106
Validation loss: 2.738223836486875

Epoch: 6| Step: 6
Training loss: 2.88595467703292
Validation loss: 2.7373407877707416

Epoch: 6| Step: 7
Training loss: 2.584395118644295
Validation loss: 2.7352992685783755

Epoch: 6| Step: 8
Training loss: 3.07675946149102
Validation loss: 2.736848767518745

Epoch: 6| Step: 9
Training loss: 3.6075097751286727
Validation loss: 2.7357123957384704

Epoch: 6| Step: 10
Training loss: 3.3411691277817552
Validation loss: 2.7311312729196477

Epoch: 6| Step: 11
Training loss: 3.3044709118870035
Validation loss: 2.7339474879712027

Epoch: 6| Step: 12
Training loss: 2.54696187064271
Validation loss: 2.7353539074366466

Epoch: 6| Step: 13
Training loss: 3.3144450684934497
Validation loss: 2.7360634077543073

Epoch: 122| Step: 0
Training loss: 3.011930901047623
Validation loss: 2.7404703708098923

Epoch: 6| Step: 1
Training loss: 2.8234213815386275
Validation loss: 2.7418758501665423

Epoch: 6| Step: 2
Training loss: 3.0435990940417015
Validation loss: 2.758452496360124

Epoch: 6| Step: 3
Training loss: 3.8777640544377694
Validation loss: 2.7662084599096954

Epoch: 6| Step: 4
Training loss: 2.6386282329211523
Validation loss: 2.7447813863998207

Epoch: 6| Step: 5
Training loss: 3.0717960879181927
Validation loss: 2.7399055403461867

Epoch: 6| Step: 6
Training loss: 3.198013022562677
Validation loss: 2.7301491987803024

Epoch: 6| Step: 7
Training loss: 3.1593576372312837
Validation loss: 2.7285201950810705

Epoch: 6| Step: 8
Training loss: 3.155101756103855
Validation loss: 2.7308274937612134

Epoch: 6| Step: 9
Training loss: 3.034670600675146
Validation loss: 2.7312005414544513

Epoch: 6| Step: 10
Training loss: 2.9985440217896335
Validation loss: 2.732917155594659

Epoch: 6| Step: 11
Training loss: 3.0295707534558938
Validation loss: 2.731921925216902

Epoch: 6| Step: 12
Training loss: 2.851015137695458
Validation loss: 2.7287816127743185

Epoch: 6| Step: 13
Training loss: 2.725106273993608
Validation loss: 2.729027201052616

Epoch: 123| Step: 0
Training loss: 3.083767439379666
Validation loss: 2.732850404296386

Epoch: 6| Step: 1
Training loss: 3.631703984939923
Validation loss: 2.735777325805064

Epoch: 6| Step: 2
Training loss: 3.8121399005864234
Validation loss: 2.7334480348116394

Epoch: 6| Step: 3
Training loss: 2.400075744387328
Validation loss: 2.7334291740210235

Epoch: 6| Step: 4
Training loss: 3.2754785552076204
Validation loss: 2.734815998289202

Epoch: 6| Step: 5
Training loss: 3.0898810961910224
Validation loss: 2.728935161116011

Epoch: 6| Step: 6
Training loss: 2.678639376550515
Validation loss: 2.735354269205271

Epoch: 6| Step: 7
Training loss: 2.9036502490273786
Validation loss: 2.743086368949691

Epoch: 6| Step: 8
Training loss: 3.052451639878009
Validation loss: 2.7400858992960813

Epoch: 6| Step: 9
Training loss: 3.0920999153150768
Validation loss: 2.7487730158403383

Epoch: 6| Step: 10
Training loss: 2.4417603258867784
Validation loss: 2.7637314675265956

Epoch: 6| Step: 11
Training loss: 3.0327006536080234
Validation loss: 2.751386625675809

Epoch: 6| Step: 12
Training loss: 3.0949146891285064
Validation loss: 2.753561098835747

Epoch: 6| Step: 13
Training loss: 2.7324529377478464
Validation loss: 2.7516185224306176

Epoch: 124| Step: 0
Training loss: 2.7645180421165616
Validation loss: 2.7394366325466306

Epoch: 6| Step: 1
Training loss: 3.8430127933318037
Validation loss: 2.741748074491369

Epoch: 6| Step: 2
Training loss: 2.6665166474900457
Validation loss: 2.7313652263381423

Epoch: 6| Step: 3
Training loss: 3.0434670193387565
Validation loss: 2.727785766380791

Epoch: 6| Step: 4
Training loss: 3.269814318363461
Validation loss: 2.7245869904109234

Epoch: 6| Step: 5
Training loss: 3.3337159096198112
Validation loss: 2.7258842986499316

Epoch: 6| Step: 6
Training loss: 2.682115972499195
Validation loss: 2.7262457784021854

Epoch: 6| Step: 7
Training loss: 3.452466530827544
Validation loss: 2.7297727053952383

Epoch: 6| Step: 8
Training loss: 3.341485228016538
Validation loss: 2.7303264614352676

Epoch: 6| Step: 9
Training loss: 3.4178275640483036
Validation loss: 2.7245421830432957

Epoch: 6| Step: 10
Training loss: 2.895192759261678
Validation loss: 2.726060619847366

Epoch: 6| Step: 11
Training loss: 2.338357851639004
Validation loss: 2.7279462348609624

Epoch: 6| Step: 12
Training loss: 2.7898531095058803
Validation loss: 2.729405481378735

Epoch: 6| Step: 13
Training loss: 2.2406360961128553
Validation loss: 2.7299783666427366

Epoch: 125| Step: 0
Training loss: 2.4314715836072707
Validation loss: 2.7326297226062835

Epoch: 6| Step: 1
Training loss: 2.9099014477902942
Validation loss: 2.7371386506556497

Epoch: 6| Step: 2
Training loss: 3.382952751089065
Validation loss: 2.740304385446674

Epoch: 6| Step: 3
Training loss: 3.1803952490892837
Validation loss: 2.750082332650165

Epoch: 6| Step: 4
Training loss: 3.536613374812524
Validation loss: 2.7604104250750074

Epoch: 6| Step: 5
Training loss: 2.17043723399518
Validation loss: 2.751217522241397

Epoch: 6| Step: 6
Training loss: 2.446262357950549
Validation loss: 2.7341736384491226

Epoch: 6| Step: 7
Training loss: 3.0027885192936186
Validation loss: 2.7339908031095863

Epoch: 6| Step: 8
Training loss: 3.020164748996979
Validation loss: 2.7315583247243005

Epoch: 6| Step: 9
Training loss: 3.6057075925596065
Validation loss: 2.7237193983701884

Epoch: 6| Step: 10
Training loss: 3.1998095217280977
Validation loss: 2.729558461151653

Epoch: 6| Step: 11
Training loss: 3.318802505911159
Validation loss: 2.7333816022335093

Epoch: 6| Step: 12
Training loss: 3.0367548401388027
Validation loss: 2.7307465248402476

Epoch: 6| Step: 13
Training loss: 3.333530388411641
Validation loss: 2.7280447942248385

Testing loss: 2.940563568543787
