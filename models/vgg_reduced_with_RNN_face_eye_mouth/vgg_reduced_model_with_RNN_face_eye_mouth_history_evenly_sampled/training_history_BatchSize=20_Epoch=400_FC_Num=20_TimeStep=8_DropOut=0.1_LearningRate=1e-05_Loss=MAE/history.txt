Epoch: 1| Step: 0
Training loss: 4.650899887084961
Validation loss: 5.183668736488588

Epoch: 5| Step: 1
Training loss: 5.474287033081055
Validation loss: 5.1727833850409395

Epoch: 5| Step: 2
Training loss: 4.252450942993164
Validation loss: 5.162749880103655

Epoch: 5| Step: 3
Training loss: 6.022170543670654
Validation loss: 5.15360656861336

Epoch: 5| Step: 4
Training loss: 4.359913349151611
Validation loss: 5.143496795367169

Epoch: 5| Step: 5
Training loss: 4.4342241287231445
Validation loss: 5.1340971813406995

Epoch: 5| Step: 6
Training loss: 4.4685163497924805
Validation loss: 5.123676520521923

Epoch: 5| Step: 7
Training loss: 5.35257625579834
Validation loss: 5.112427660214004

Epoch: 5| Step: 8
Training loss: 5.580165863037109
Validation loss: 5.100626755786198

Epoch: 5| Step: 9
Training loss: 5.5081000328063965
Validation loss: 5.088005204354563

Epoch: 5| Step: 10
Training loss: 3.953481435775757
Validation loss: 5.074280441448253

Epoch: 2| Step: 0
Training loss: 5.001679420471191
Validation loss: 5.05936179109799

Epoch: 5| Step: 1
Training loss: 5.110018730163574
Validation loss: 5.043957028337704

Epoch: 5| Step: 2
Training loss: 4.297418594360352
Validation loss: 5.027293974353421

Epoch: 5| Step: 3
Training loss: 4.236258506774902
Validation loss: 5.00955109442434

Epoch: 5| Step: 4
Training loss: 4.902117729187012
Validation loss: 4.990246142110517

Epoch: 5| Step: 5
Training loss: 6.112873077392578
Validation loss: 4.969348466524514

Epoch: 5| Step: 6
Training loss: 5.813963890075684
Validation loss: 4.948018986691711

Epoch: 5| Step: 7
Training loss: 4.587942600250244
Validation loss: 4.925348051132694

Epoch: 5| Step: 8
Training loss: 4.355306148529053
Validation loss: 4.9013173221259985

Epoch: 5| Step: 9
Training loss: 3.5765843391418457
Validation loss: 4.876213781295284

Epoch: 5| Step: 10
Training loss: 4.251029968261719
Validation loss: 4.85030298848306

Epoch: 3| Step: 0
Training loss: 3.443073272705078
Validation loss: 4.8239852074653875

Epoch: 5| Step: 1
Training loss: 4.169070720672607
Validation loss: 4.796288951750724

Epoch: 5| Step: 2
Training loss: 4.77486515045166
Validation loss: 4.767722980950468

Epoch: 5| Step: 3
Training loss: 4.469986915588379
Validation loss: 4.7415092786153155

Epoch: 5| Step: 4
Training loss: 4.968406677246094
Validation loss: 4.714104160185783

Epoch: 5| Step: 5
Training loss: 4.497071266174316
Validation loss: 4.6880922061140815

Epoch: 5| Step: 6
Training loss: 5.1179609298706055
Validation loss: 4.662230850547872

Epoch: 5| Step: 7
Training loss: 4.225630283355713
Validation loss: 4.63611049549554

Epoch: 5| Step: 8
Training loss: 5.4143242835998535
Validation loss: 4.61154721372871

Epoch: 5| Step: 9
Training loss: 3.929172992706299
Validation loss: 4.586067768835252

Epoch: 5| Step: 10
Training loss: 4.198594570159912
Validation loss: 4.5602998784793325

Epoch: 4| Step: 0
Training loss: 5.105147838592529
Validation loss: 4.533735726469306

Epoch: 5| Step: 1
Training loss: 4.089729309082031
Validation loss: 4.505562043959094

Epoch: 5| Step: 2
Training loss: 5.09627628326416
Validation loss: 4.475269358645203

Epoch: 5| Step: 3
Training loss: 4.637962818145752
Validation loss: 4.444191609659502

Epoch: 5| Step: 4
Training loss: 3.0940804481506348
Validation loss: 4.410285519015405

Epoch: 5| Step: 5
Training loss: 3.8146815299987793
Validation loss: 4.378649547535886

Epoch: 5| Step: 6
Training loss: 3.121837615966797
Validation loss: 4.343915441984771

Epoch: 5| Step: 7
Training loss: 4.2000932693481445
Validation loss: 4.312824144158312

Epoch: 5| Step: 8
Training loss: 4.922560691833496
Validation loss: 4.279883974341936

Epoch: 5| Step: 9
Training loss: 4.168853759765625
Validation loss: 4.2473618702221945

Epoch: 5| Step: 10
Training loss: 3.6414506435394287
Validation loss: 4.210619567542948

Epoch: 5| Step: 0
Training loss: 4.018782615661621
Validation loss: 4.174447241649832

Epoch: 5| Step: 1
Training loss: 4.042204856872559
Validation loss: 4.137473270457278

Epoch: 5| Step: 2
Training loss: 3.8125534057617188
Validation loss: 4.101537642940398

Epoch: 5| Step: 3
Training loss: 2.799316883087158
Validation loss: 4.067588190878591

Epoch: 5| Step: 4
Training loss: 3.7246875762939453
Validation loss: 4.040763639634656

Epoch: 5| Step: 5
Training loss: 2.9337334632873535
Validation loss: 4.01724338018766

Epoch: 5| Step: 6
Training loss: 4.598326683044434
Validation loss: 3.9963374804424983

Epoch: 5| Step: 7
Training loss: 4.833402633666992
Validation loss: 3.9694473871620755

Epoch: 5| Step: 8
Training loss: 3.2863755226135254
Validation loss: 3.9463889983392533

Epoch: 5| Step: 9
Training loss: 3.7447707653045654
Validation loss: 3.9281857987885833

Epoch: 5| Step: 10
Training loss: 4.809351921081543
Validation loss: 3.9142114526482037

Epoch: 6| Step: 0
Training loss: 5.047369956970215
Validation loss: 3.901055674399099

Epoch: 5| Step: 1
Training loss: 4.263301849365234
Validation loss: 3.885622957701324

Epoch: 5| Step: 2
Training loss: 3.925502061843872
Validation loss: 3.8720083441785587

Epoch: 5| Step: 3
Training loss: 3.3239452838897705
Validation loss: 3.8581471981540805

Epoch: 5| Step: 4
Training loss: 3.5139033794403076
Validation loss: 3.8452486274062947

Epoch: 5| Step: 5
Training loss: 3.87152361869812
Validation loss: 3.8350004893477245

Epoch: 5| Step: 6
Training loss: 3.2192752361297607
Validation loss: 3.8252146320958293

Epoch: 5| Step: 7
Training loss: 3.5828919410705566
Validation loss: 3.813684848047072

Epoch: 5| Step: 8
Training loss: 3.3159286975860596
Validation loss: 3.812654218366069

Epoch: 5| Step: 9
Training loss: 3.5511162281036377
Validation loss: 3.8011846465449177

Epoch: 5| Step: 10
Training loss: 3.2637412548065186
Validation loss: 3.7884313752574306

Epoch: 7| Step: 0
Training loss: 4.197509765625
Validation loss: 3.776649095678842

Epoch: 5| Step: 1
Training loss: 4.886490345001221
Validation loss: 3.7690126716449694

Epoch: 5| Step: 2
Training loss: 3.835343599319458
Validation loss: 3.7597455568211053

Epoch: 5| Step: 3
Training loss: 2.923856735229492
Validation loss: 3.7503924779994513

Epoch: 5| Step: 4
Training loss: 3.323542833328247
Validation loss: 3.741202897922967

Epoch: 5| Step: 5
Training loss: 3.371619701385498
Validation loss: 3.730753134655696

Epoch: 5| Step: 6
Training loss: 3.6113662719726562
Validation loss: 3.721271296983124

Epoch: 5| Step: 7
Training loss: 2.832854747772217
Validation loss: 3.709221304103892

Epoch: 5| Step: 8
Training loss: 3.871342182159424
Validation loss: 3.700333849076302

Epoch: 5| Step: 9
Training loss: 2.6283798217773438
Validation loss: 3.6907428208217827

Epoch: 5| Step: 10
Training loss: 4.590085029602051
Validation loss: 3.6799564156481015

Epoch: 8| Step: 0
Training loss: 3.901947021484375
Validation loss: 3.669924146385603

Epoch: 5| Step: 1
Training loss: 3.99277925491333
Validation loss: 3.659443547648768

Epoch: 5| Step: 2
Training loss: 3.3682103157043457
Validation loss: 3.648827527159004

Epoch: 5| Step: 3
Training loss: 2.9395453929901123
Validation loss: 3.63890931939566

Epoch: 5| Step: 4
Training loss: 4.15843391418457
Validation loss: 3.631280514501756

Epoch: 5| Step: 5
Training loss: 3.853621244430542
Validation loss: 3.624925228857225

Epoch: 5| Step: 6
Training loss: 3.088209867477417
Validation loss: 3.614762088303925

Epoch: 5| Step: 7
Training loss: 3.7096500396728516
Validation loss: 3.605107186942972

Epoch: 5| Step: 8
Training loss: 3.8794918060302734
Validation loss: 3.596348234402236

Epoch: 5| Step: 9
Training loss: 3.405726909637451
Validation loss: 3.587000826353668

Epoch: 5| Step: 10
Training loss: 2.4944732189178467
Validation loss: 3.579090828536659

Epoch: 9| Step: 0
Training loss: 3.7880988121032715
Validation loss: 3.5702011431417158

Epoch: 5| Step: 1
Training loss: 3.1259655952453613
Validation loss: 3.562753244112897

Epoch: 5| Step: 2
Training loss: 4.103741645812988
Validation loss: 3.5567698811972015

Epoch: 5| Step: 3
Training loss: 3.3634238243103027
Validation loss: 3.5467242220396638

Epoch: 5| Step: 4
Training loss: 3.05977725982666
Validation loss: 3.5383714937394664

Epoch: 5| Step: 5
Training loss: 4.3875532150268555
Validation loss: 3.5276158753261773

Epoch: 5| Step: 6
Training loss: 3.743307113647461
Validation loss: 3.512852530325613

Epoch: 5| Step: 7
Training loss: 3.452481508255005
Validation loss: 3.4989614640512774

Epoch: 5| Step: 8
Training loss: 3.231342315673828
Validation loss: 3.4872725009918213

Epoch: 5| Step: 9
Training loss: 2.5662949085235596
Validation loss: 3.4833879445188787

Epoch: 5| Step: 10
Training loss: 3.1633734703063965
Validation loss: 3.4772821241809475

Epoch: 10| Step: 0
Training loss: 3.3235621452331543
Validation loss: 3.4713318937568256

Epoch: 5| Step: 1
Training loss: 3.025331974029541
Validation loss: 3.4627439539919616

Epoch: 5| Step: 2
Training loss: 3.1537718772888184
Validation loss: 3.4531622394438712

Epoch: 5| Step: 3
Training loss: 3.504664897918701
Validation loss: 3.438696938176309

Epoch: 5| Step: 4
Training loss: 2.7164981365203857
Validation loss: 3.4272484958812757

Epoch: 5| Step: 5
Training loss: 2.3697712421417236
Validation loss: 3.4160105284824165

Epoch: 5| Step: 6
Training loss: 3.9338717460632324
Validation loss: 3.407935973136656

Epoch: 5| Step: 7
Training loss: 3.781655788421631
Validation loss: 3.402576210678265

Epoch: 5| Step: 8
Training loss: 3.5848548412323
Validation loss: 3.3959049306890017

Epoch: 5| Step: 9
Training loss: 3.964181900024414
Validation loss: 3.3839447754685597

Epoch: 5| Step: 10
Training loss: 3.7589497566223145
Validation loss: 3.3739276393767326

Epoch: 11| Step: 0
Training loss: 4.011643409729004
Validation loss: 3.3668192868591635

Epoch: 5| Step: 1
Training loss: 2.674947738647461
Validation loss: 3.3604718844095864

Epoch: 5| Step: 2
Training loss: 3.0214648246765137
Validation loss: 3.3567755940139934

Epoch: 5| Step: 3
Training loss: 2.9648303985595703
Validation loss: 3.3489280105918966

Epoch: 5| Step: 4
Training loss: 2.7134318351745605
Validation loss: 3.3428265920249363

Epoch: 5| Step: 5
Training loss: 3.592411518096924
Validation loss: 3.340294579023956

Epoch: 5| Step: 6
Training loss: 4.273218631744385
Validation loss: 3.3361693402772308

Epoch: 5| Step: 7
Training loss: 3.3865718841552734
Validation loss: 3.3318834253536758

Epoch: 5| Step: 8
Training loss: 3.4877047538757324
Validation loss: 3.326272569676881

Epoch: 5| Step: 9
Training loss: 2.46397066116333
Validation loss: 3.3214910927639214

Epoch: 5| Step: 10
Training loss: 3.817462682723999
Validation loss: 3.3137955563042754

Epoch: 12| Step: 0
Training loss: 3.259573459625244
Validation loss: 3.306557983480474

Epoch: 5| Step: 1
Training loss: 3.810502529144287
Validation loss: 3.301151042343468

Epoch: 5| Step: 2
Training loss: 3.2583720684051514
Validation loss: 3.2926878903501775

Epoch: 5| Step: 3
Training loss: 4.130572319030762
Validation loss: 3.2890790021547707

Epoch: 5| Step: 4
Training loss: 2.2779507637023926
Validation loss: 3.281964486645114

Epoch: 5| Step: 5
Training loss: 3.143177032470703
Validation loss: 3.2755212783813477

Epoch: 5| Step: 6
Training loss: 3.346686840057373
Validation loss: 3.2668655149398313

Epoch: 5| Step: 7
Training loss: 2.6613738536834717
Validation loss: 3.2640547649834746

Epoch: 5| Step: 8
Training loss: 2.7026443481445312
Validation loss: 3.255910801631148

Epoch: 5| Step: 9
Training loss: 3.41230845451355
Validation loss: 3.251307725906372

Epoch: 5| Step: 10
Training loss: 3.8677687644958496
Validation loss: 3.240976615618634

Epoch: 13| Step: 0
Training loss: 3.778625011444092
Validation loss: 3.238770472106113

Epoch: 5| Step: 1
Training loss: 2.729921817779541
Validation loss: 3.234978909133583

Epoch: 5| Step: 2
Training loss: 3.8467609882354736
Validation loss: 3.2325456373153196

Epoch: 5| Step: 3
Training loss: 3.57145619392395
Validation loss: 3.231363491345477

Epoch: 5| Step: 4
Training loss: 3.1378228664398193
Validation loss: 3.226630562095232

Epoch: 5| Step: 5
Training loss: 3.823495388031006
Validation loss: 3.22230262653802

Epoch: 5| Step: 6
Training loss: 2.637049913406372
Validation loss: 3.211253550744826

Epoch: 5| Step: 7
Training loss: 3.3745675086975098
Validation loss: 3.2034579425729732

Epoch: 5| Step: 8
Training loss: 3.29313588142395
Validation loss: 3.201595983197612

Epoch: 5| Step: 9
Training loss: 2.609563112258911
Validation loss: 3.19379170479313

Epoch: 5| Step: 10
Training loss: 2.368468999862671
Validation loss: 3.1863306440332884

Epoch: 14| Step: 0
Training loss: 3.2729992866516113
Validation loss: 3.1817923027981996

Epoch: 5| Step: 1
Training loss: 3.321984052658081
Validation loss: 3.1791548703306463

Epoch: 5| Step: 2
Training loss: 3.7170510292053223
Validation loss: 3.175829633589714

Epoch: 5| Step: 3
Training loss: 3.175093650817871
Validation loss: 3.1708584216333207

Epoch: 5| Step: 4
Training loss: 3.418591022491455
Validation loss: 3.1656249671854

Epoch: 5| Step: 5
Training loss: 3.287604808807373
Validation loss: 3.161392173459453

Epoch: 5| Step: 6
Training loss: 3.534022569656372
Validation loss: 3.1586731736378004

Epoch: 5| Step: 7
Training loss: 2.2669765949249268
Validation loss: 3.1550827026367188

Epoch: 5| Step: 8
Training loss: 3.087568998336792
Validation loss: 3.149370854900729

Epoch: 5| Step: 9
Training loss: 2.7426421642303467
Validation loss: 3.1473876583960747

Epoch: 5| Step: 10
Training loss: 3.038330078125
Validation loss: 3.138683360110047

Epoch: 15| Step: 0
Training loss: 3.133812189102173
Validation loss: 3.136591854915824

Epoch: 5| Step: 1
Training loss: 3.8892548084259033
Validation loss: 3.1319043533776396

Epoch: 5| Step: 2
Training loss: 3.124732494354248
Validation loss: 3.126071181348575

Epoch: 5| Step: 3
Training loss: 3.0891482830047607
Validation loss: 3.127283991024058

Epoch: 5| Step: 4
Training loss: 3.3687546253204346
Validation loss: 3.121484033523067

Epoch: 5| Step: 5
Training loss: 2.3585758209228516
Validation loss: 3.1586868070786998

Epoch: 5| Step: 6
Training loss: 3.870455265045166
Validation loss: 3.1335782850942304

Epoch: 5| Step: 7
Training loss: 2.725363254547119
Validation loss: 3.1126832090398318

Epoch: 5| Step: 8
Training loss: 2.821997880935669
Validation loss: 3.1195680633667977

Epoch: 5| Step: 9
Training loss: 2.3289573192596436
Validation loss: 3.1344069357841247

Epoch: 5| Step: 10
Training loss: 4.021188259124756
Validation loss: 3.1525869959144184

Epoch: 16| Step: 0
Training loss: 3.708775281906128
Validation loss: 3.157327434068085

Epoch: 5| Step: 1
Training loss: 3.022369861602783
Validation loss: 3.1429381344908025

Epoch: 5| Step: 2
Training loss: 2.8377468585968018
Validation loss: 3.1382565370170017

Epoch: 5| Step: 3
Training loss: 3.4721121788024902
Validation loss: 3.1279952987547843

Epoch: 5| Step: 4
Training loss: 2.8532872200012207
Validation loss: 3.1242399266971055

Epoch: 5| Step: 5
Training loss: 2.7797954082489014
Validation loss: 3.1159373790987077

Epoch: 5| Step: 6
Training loss: 3.4068474769592285
Validation loss: 3.1132765149557464

Epoch: 5| Step: 7
Training loss: 2.531973361968994
Validation loss: 3.10665798699984

Epoch: 5| Step: 8
Training loss: 3.9757137298583984
Validation loss: 3.1019066046643

Epoch: 5| Step: 9
Training loss: 2.9251999855041504
Validation loss: 3.0996048065923874

Epoch: 5| Step: 10
Training loss: 3.0170183181762695
Validation loss: 3.091253262694164

Epoch: 17| Step: 0
Training loss: 3.1494154930114746
Validation loss: 3.0863841477260796

Epoch: 5| Step: 1
Training loss: 3.721198320388794
Validation loss: 3.0826033930624686

Epoch: 5| Step: 2
Training loss: 3.353623628616333
Validation loss: 3.077716040354903

Epoch: 5| Step: 3
Training loss: 3.814157485961914
Validation loss: 3.0738083931707565

Epoch: 5| Step: 4
Training loss: 3.785456895828247
Validation loss: 3.0672592270758843

Epoch: 5| Step: 5
Training loss: 2.542151689529419
Validation loss: 3.0643005627457813

Epoch: 5| Step: 6
Training loss: 3.1068484783172607
Validation loss: 3.0611651712848293

Epoch: 5| Step: 7
Training loss: 2.819463014602661
Validation loss: 3.0583716900117937

Epoch: 5| Step: 8
Training loss: 2.7150557041168213
Validation loss: 3.0562170346577964

Epoch: 5| Step: 9
Training loss: 3.16078782081604
Validation loss: 3.055659555619763

Epoch: 5| Step: 10
Training loss: 1.829681634902954
Validation loss: 3.051289020046111

Epoch: 18| Step: 0
Training loss: 3.5848548412323
Validation loss: 3.048696433344195

Epoch: 5| Step: 1
Training loss: 3.6699745655059814
Validation loss: 3.046913880173878

Epoch: 5| Step: 2
Training loss: 2.458684206008911
Validation loss: 3.041850007990355

Epoch: 5| Step: 3
Training loss: 3.2632522583007812
Validation loss: 3.0384157293586322

Epoch: 5| Step: 4
Training loss: 3.966794490814209
Validation loss: 3.037489975652387

Epoch: 5| Step: 5
Training loss: 2.4562156200408936
Validation loss: 3.032633322541432

Epoch: 5| Step: 6
Training loss: 2.6135616302490234
Validation loss: 3.031233808045746

Epoch: 5| Step: 7
Training loss: 3.1411325931549072
Validation loss: 3.0285193638135026

Epoch: 5| Step: 8
Training loss: 2.688147783279419
Validation loss: 3.0276152754342682

Epoch: 5| Step: 9
Training loss: 2.694277048110962
Validation loss: 3.023904405614381

Epoch: 5| Step: 10
Training loss: 3.4617278575897217
Validation loss: 3.0223351165812504

Epoch: 19| Step: 0
Training loss: 3.383911609649658
Validation loss: 3.0203655124992452

Epoch: 5| Step: 1
Training loss: 2.8154873847961426
Validation loss: 3.0158349621680474

Epoch: 5| Step: 2
Training loss: 3.2142245769500732
Validation loss: 3.018785971467213

Epoch: 5| Step: 3
Training loss: 2.4367051124572754
Validation loss: 3.0129853294741724

Epoch: 5| Step: 4
Training loss: 2.7796971797943115
Validation loss: 3.0100880643372894

Epoch: 5| Step: 5
Training loss: 3.1581902503967285
Validation loss: 3.010451434760965

Epoch: 5| Step: 6
Training loss: 3.3391852378845215
Validation loss: 3.009243542148221

Epoch: 5| Step: 7
Training loss: 4.326252460479736
Validation loss: 3.007115574293239

Epoch: 5| Step: 8
Training loss: 2.3618860244750977
Validation loss: 3.0055847629424064

Epoch: 5| Step: 9
Training loss: 2.5944907665252686
Validation loss: 2.9984230995178223

Epoch: 5| Step: 10
Training loss: 3.4291679859161377
Validation loss: 2.998808355741603

Epoch: 20| Step: 0
Training loss: 3.024242877960205
Validation loss: 2.9962159356763287

Epoch: 5| Step: 1
Training loss: 3.4178600311279297
Validation loss: 2.9929934163247385

Epoch: 5| Step: 2
Training loss: 2.789780378341675
Validation loss: 2.9910267322294173

Epoch: 5| Step: 3
Training loss: 3.1526458263397217
Validation loss: 2.9922332968763126

Epoch: 5| Step: 4
Training loss: 3.13244366645813
Validation loss: 2.985471446027038

Epoch: 5| Step: 5
Training loss: 2.8680717945098877
Validation loss: 2.98428431377616

Epoch: 5| Step: 6
Training loss: 2.8904013633728027
Validation loss: 2.9856448070977324

Epoch: 5| Step: 7
Training loss: 3.504882335662842
Validation loss: 2.980990045814104

Epoch: 5| Step: 8
Training loss: 3.7891697883605957
Validation loss: 2.9766110604809177

Epoch: 5| Step: 9
Training loss: 2.700808048248291
Validation loss: 2.975025632048166

Epoch: 5| Step: 10
Training loss: 2.2155849933624268
Validation loss: 2.9729032977934806

Epoch: 21| Step: 0
Training loss: 3.481168270111084
Validation loss: 2.9715292812675558

Epoch: 5| Step: 1
Training loss: 3.1585488319396973
Validation loss: 2.9698860542748564

Epoch: 5| Step: 2
Training loss: 3.2721126079559326
Validation loss: 2.9664421260997815

Epoch: 5| Step: 3
Training loss: 2.9197068214416504
Validation loss: 2.966563840066233

Epoch: 5| Step: 4
Training loss: 2.4600977897644043
Validation loss: 2.9658451516141175

Epoch: 5| Step: 5
Training loss: 3.1021339893341064
Validation loss: 2.96458512736905

Epoch: 5| Step: 6
Training loss: 2.6026084423065186
Validation loss: 2.9631617428154073

Epoch: 5| Step: 7
Training loss: 3.1897664070129395
Validation loss: 2.9642932645736204

Epoch: 5| Step: 8
Training loss: 2.565955638885498
Validation loss: 2.963014938498056

Epoch: 5| Step: 9
Training loss: 3.323944091796875
Validation loss: 2.9598477040567706

Epoch: 5| Step: 10
Training loss: 3.450465202331543
Validation loss: 2.957489446927142

Epoch: 22| Step: 0
Training loss: 3.7307987213134766
Validation loss: 2.9546358534084853

Epoch: 5| Step: 1
Training loss: 3.629173994064331
Validation loss: 2.9548363941971973

Epoch: 5| Step: 2
Training loss: 3.7070822715759277
Validation loss: 2.9544063896261235

Epoch: 5| Step: 3
Training loss: 2.5084192752838135
Validation loss: 2.952173666287494

Epoch: 5| Step: 4
Training loss: 2.903212785720825
Validation loss: 2.949779297715874

Epoch: 5| Step: 5
Training loss: 2.8332924842834473
Validation loss: 2.948737952017015

Epoch: 5| Step: 6
Training loss: 2.614022731781006
Validation loss: 2.9460305116509877

Epoch: 5| Step: 7
Training loss: 3.483412265777588
Validation loss: 2.946395176713185

Epoch: 5| Step: 8
Training loss: 2.647982120513916
Validation loss: 2.943802223410658

Epoch: 5| Step: 9
Training loss: 2.072197437286377
Validation loss: 2.943943920955863

Epoch: 5| Step: 10
Training loss: 3.2622406482696533
Validation loss: 2.9413139845735286

Epoch: 23| Step: 0
Training loss: 3.131261110305786
Validation loss: 2.939803636202248

Epoch: 5| Step: 1
Training loss: 2.883533000946045
Validation loss: 2.9399654685810046

Epoch: 5| Step: 2
Training loss: 3.839491605758667
Validation loss: 2.937596085251019

Epoch: 5| Step: 3
Training loss: 3.638867139816284
Validation loss: 2.9378344525573072

Epoch: 5| Step: 4
Training loss: 2.843379497528076
Validation loss: 2.9365918046684674

Epoch: 5| Step: 5
Training loss: 2.5753791332244873
Validation loss: 2.9349982430857997

Epoch: 5| Step: 6
Training loss: 2.4589805603027344
Validation loss: 2.9336909683801795

Epoch: 5| Step: 7
Training loss: 3.010732412338257
Validation loss: 2.932188190439696

Epoch: 5| Step: 8
Training loss: 3.425133228302002
Validation loss: 2.9317336646459435

Epoch: 5| Step: 9
Training loss: 2.237792491912842
Validation loss: 2.9301989232340167

Epoch: 5| Step: 10
Training loss: 3.2421460151672363
Validation loss: 2.929051027503065

Epoch: 24| Step: 0
Training loss: 3.332205295562744
Validation loss: 2.9272740784511773

Epoch: 5| Step: 1
Training loss: 2.695178747177124
Validation loss: 2.9266469427334365

Epoch: 5| Step: 2
Training loss: 2.8684356212615967
Validation loss: 2.928112822194253

Epoch: 5| Step: 3
Training loss: 2.860048294067383
Validation loss: 2.9266394748482654

Epoch: 5| Step: 4
Training loss: 3.278780460357666
Validation loss: 2.9247842296477287

Epoch: 5| Step: 5
Training loss: 2.3535618782043457
Validation loss: 2.9245641308446086

Epoch: 5| Step: 6
Training loss: 2.852459669113159
Validation loss: 2.9221322126286005

Epoch: 5| Step: 7
Training loss: 2.7775070667266846
Validation loss: 2.9215839985878236

Epoch: 5| Step: 8
Training loss: 3.4027886390686035
Validation loss: 2.919136590855096

Epoch: 5| Step: 9
Training loss: 3.278489351272583
Validation loss: 2.91969052181449

Epoch: 5| Step: 10
Training loss: 3.551088333129883
Validation loss: 2.9180378990788616

Epoch: 25| Step: 0
Training loss: 3.4089267253875732
Validation loss: 2.9185608510048158

Epoch: 5| Step: 1
Training loss: 3.3794662952423096
Validation loss: 2.918117533447922

Epoch: 5| Step: 2
Training loss: 3.211937665939331
Validation loss: 2.915489012195218

Epoch: 5| Step: 3
Training loss: 2.500340223312378
Validation loss: 2.916148180602699

Epoch: 5| Step: 4
Training loss: 3.7983672618865967
Validation loss: 2.9130257432178785

Epoch: 5| Step: 5
Training loss: 2.836326837539673
Validation loss: 2.91525197798206

Epoch: 5| Step: 6
Training loss: 2.6362898349761963
Validation loss: 2.9131822534786758

Epoch: 5| Step: 7
Training loss: 3.0832371711730957
Validation loss: 2.913068166343115

Epoch: 5| Step: 8
Training loss: 3.065903425216675
Validation loss: 2.9120271077720066

Epoch: 5| Step: 9
Training loss: 2.476375102996826
Validation loss: 2.910421153550507

Epoch: 5| Step: 10
Training loss: 2.6424388885498047
Validation loss: 2.9087032169424076

Epoch: 26| Step: 0
Training loss: 1.9398858547210693
Validation loss: 2.907630540991342

Epoch: 5| Step: 1
Training loss: 3.8301143646240234
Validation loss: 2.9071141878763833

Epoch: 5| Step: 2
Training loss: 3.0079331398010254
Validation loss: 2.9071933172082387

Epoch: 5| Step: 3
Training loss: 3.177562952041626
Validation loss: 2.904283046722412

Epoch: 5| Step: 4
Training loss: 3.0233020782470703
Validation loss: 2.9024990220223703

Epoch: 5| Step: 5
Training loss: 3.5724635124206543
Validation loss: 2.9022700171316824

Epoch: 5| Step: 6
Training loss: 2.6973302364349365
Validation loss: 2.899284831939205

Epoch: 5| Step: 7
Training loss: 2.709876775741577
Validation loss: 2.899589897483908

Epoch: 5| Step: 8
Training loss: 3.4983139038085938
Validation loss: 2.8961667553071053

Epoch: 5| Step: 9
Training loss: 3.0631871223449707
Validation loss: 2.895278094917215

Epoch: 5| Step: 10
Training loss: 2.3943402767181396
Validation loss: 2.894649818379392

Epoch: 27| Step: 0
Training loss: 2.7001335620880127
Validation loss: 2.8936512290790515

Epoch: 5| Step: 1
Training loss: 3.6699328422546387
Validation loss: 2.8917485411449144

Epoch: 5| Step: 2
Training loss: 2.7949776649475098
Validation loss: 2.8902756603815223

Epoch: 5| Step: 3
Training loss: 3.7755789756774902
Validation loss: 2.891028114544448

Epoch: 5| Step: 4
Training loss: 2.8141608238220215
Validation loss: 2.883874770133726

Epoch: 5| Step: 5
Training loss: 3.0630042552948
Validation loss: 2.8829656672734085

Epoch: 5| Step: 6
Training loss: 2.9821219444274902
Validation loss: 2.879489691026749

Epoch: 5| Step: 7
Training loss: 2.774637222290039
Validation loss: 2.8790828438215357

Epoch: 5| Step: 8
Training loss: 2.7392663955688477
Validation loss: 2.8762476931336107

Epoch: 5| Step: 9
Training loss: 2.5933780670166016
Validation loss: 2.875626064115955

Epoch: 5| Step: 10
Training loss: 2.9558682441711426
Validation loss: 2.8732653202549105

Epoch: 28| Step: 0
Training loss: 2.6749672889709473
Validation loss: 2.874048848305979

Epoch: 5| Step: 1
Training loss: 3.1726956367492676
Validation loss: 2.8724295964805027

Epoch: 5| Step: 2
Training loss: 3.3909614086151123
Validation loss: 2.871035091338619

Epoch: 5| Step: 3
Training loss: 3.691551923751831
Validation loss: 2.866472921063823

Epoch: 5| Step: 4
Training loss: 3.4788622856140137
Validation loss: 2.865900367818853

Epoch: 5| Step: 5
Training loss: 2.9682438373565674
Validation loss: 2.866794659245399

Epoch: 5| Step: 6
Training loss: 2.745687961578369
Validation loss: 2.8691134170819352

Epoch: 5| Step: 7
Training loss: 2.6432178020477295
Validation loss: 2.8828398361000964

Epoch: 5| Step: 8
Training loss: 2.286364793777466
Validation loss: 2.8654452293149886

Epoch: 5| Step: 9
Training loss: 2.6583056449890137
Validation loss: 2.858491313072943

Epoch: 5| Step: 10
Training loss: 3.0732431411743164
Validation loss: 2.8614617829681723

Epoch: 29| Step: 0
Training loss: 1.9866259098052979
Validation loss: 2.867255626186248

Epoch: 5| Step: 1
Training loss: 2.7087745666503906
Validation loss: 2.8705793170518774

Epoch: 5| Step: 2
Training loss: 2.7063651084899902
Validation loss: 2.8705026308695474

Epoch: 5| Step: 3
Training loss: 3.4794952869415283
Validation loss: 2.8728279170169624

Epoch: 5| Step: 4
Training loss: 3.730863094329834
Validation loss: 2.8662586058339765

Epoch: 5| Step: 5
Training loss: 3.2516446113586426
Validation loss: 2.8644146073249077

Epoch: 5| Step: 6
Training loss: 3.1860861778259277
Validation loss: 2.860388207179244

Epoch: 5| Step: 7
Training loss: 2.965728998184204
Validation loss: 2.8576796644477436

Epoch: 5| Step: 8
Training loss: 3.3132622241973877
Validation loss: 2.8587415641353977

Epoch: 5| Step: 9
Training loss: 2.861931562423706
Validation loss: 2.862184568118024

Epoch: 5| Step: 10
Training loss: 2.476907253265381
Validation loss: 2.854154504755492

Epoch: 30| Step: 0
Training loss: 3.0719637870788574
Validation loss: 2.8514050822104178

Epoch: 5| Step: 1
Training loss: 2.316542148590088
Validation loss: 2.8488589230404107

Epoch: 5| Step: 2
Training loss: 3.3497345447540283
Validation loss: 2.848290225510956

Epoch: 5| Step: 3
Training loss: 2.622983455657959
Validation loss: 2.848874527920959

Epoch: 5| Step: 4
Training loss: 2.922809362411499
Validation loss: 2.84751283994285

Epoch: 5| Step: 5
Training loss: 3.087955951690674
Validation loss: 2.84998922194204

Epoch: 5| Step: 6
Training loss: 3.3461966514587402
Validation loss: 2.848583654690814

Epoch: 5| Step: 7
Training loss: 3.5822854042053223
Validation loss: 2.849716668487877

Epoch: 5| Step: 8
Training loss: 2.7391505241394043
Validation loss: 2.8525171510634886

Epoch: 5| Step: 9
Training loss: 3.151556968688965
Validation loss: 2.8608647546460553

Epoch: 5| Step: 10
Training loss: 2.318148374557495
Validation loss: 2.8414692801813923

Epoch: 31| Step: 0
Training loss: 3.129112958908081
Validation loss: 2.8375688111910256

Epoch: 5| Step: 1
Training loss: 2.696794033050537
Validation loss: 2.839159909115043

Epoch: 5| Step: 2
Training loss: 3.7770755290985107
Validation loss: 2.839730303774598

Epoch: 5| Step: 3
Training loss: 3.5629279613494873
Validation loss: 2.84108934351193

Epoch: 5| Step: 4
Training loss: 2.895516872406006
Validation loss: 2.836398655368436

Epoch: 5| Step: 5
Training loss: 2.1839656829833984
Validation loss: 2.8384333118315666

Epoch: 5| Step: 6
Training loss: 3.1166720390319824
Validation loss: 2.83482252910573

Epoch: 5| Step: 7
Training loss: 3.1453590393066406
Validation loss: 2.8328541299348236

Epoch: 5| Step: 8
Training loss: 2.385007381439209
Validation loss: 2.8306812291504233

Epoch: 5| Step: 9
Training loss: 2.42743182182312
Validation loss: 2.833863565998693

Epoch: 5| Step: 10
Training loss: 3.2635278701782227
Validation loss: 2.8308667264958864

Epoch: 32| Step: 0
Training loss: 2.4604716300964355
Validation loss: 2.83086048915822

Epoch: 5| Step: 1
Training loss: 2.8407955169677734
Validation loss: 2.8299498788772093

Epoch: 5| Step: 2
Training loss: 3.398820161819458
Validation loss: 2.830271336340135

Epoch: 5| Step: 3
Training loss: 3.256654739379883
Validation loss: 2.8281234771974626

Epoch: 5| Step: 4
Training loss: 2.91873836517334
Validation loss: 2.829763150984241

Epoch: 5| Step: 5
Training loss: 2.84755277633667
Validation loss: 2.824593154332971

Epoch: 5| Step: 6
Training loss: 2.877911329269409
Validation loss: 2.823072735981275

Epoch: 5| Step: 7
Training loss: 3.236435651779175
Validation loss: 2.8206188832559893

Epoch: 5| Step: 8
Training loss: 2.822732925415039
Validation loss: 2.8162894377144436

Epoch: 5| Step: 9
Training loss: 3.1254265308380127
Validation loss: 2.8152826678368355

Epoch: 5| Step: 10
Training loss: 2.6063709259033203
Validation loss: 2.816166203509095

Epoch: 33| Step: 0
Training loss: 2.709153413772583
Validation loss: 2.8170463218483874

Epoch: 5| Step: 1
Training loss: 3.268225908279419
Validation loss: 2.823037924305085

Epoch: 5| Step: 2
Training loss: 3.046475648880005
Validation loss: 2.8151638456570205

Epoch: 5| Step: 3
Training loss: 2.177783966064453
Validation loss: 2.8150963065444783

Epoch: 5| Step: 4
Training loss: 2.7548372745513916
Validation loss: 2.8120287925966325

Epoch: 5| Step: 5
Training loss: 3.576639175415039
Validation loss: 2.813156089475078

Epoch: 5| Step: 6
Training loss: 3.464085102081299
Validation loss: 2.811617733329855

Epoch: 5| Step: 7
Training loss: 3.534219264984131
Validation loss: 2.8102153911385486

Epoch: 5| Step: 8
Training loss: 2.143158197402954
Validation loss: 2.809830665588379

Epoch: 5| Step: 9
Training loss: 2.7999825477600098
Validation loss: 2.8092173863482732

Epoch: 5| Step: 10
Training loss: 2.912917137145996
Validation loss: 2.8118714132616596

Epoch: 34| Step: 0
Training loss: 2.549954652786255
Validation loss: 2.809138398016653

Epoch: 5| Step: 1
Training loss: 2.550203323364258
Validation loss: 2.80856910315893

Epoch: 5| Step: 2
Training loss: 2.3636908531188965
Validation loss: 2.808527482453213

Epoch: 5| Step: 3
Training loss: 2.890120029449463
Validation loss: 2.8084862873118412

Epoch: 5| Step: 4
Training loss: 3.142885446548462
Validation loss: 2.8064947230841524

Epoch: 5| Step: 5
Training loss: 3.587947130203247
Validation loss: 2.808171215877738

Epoch: 5| Step: 6
Training loss: 2.1985881328582764
Validation loss: 2.8054370572490077

Epoch: 5| Step: 7
Training loss: 2.582326889038086
Validation loss: 2.803980137712212

Epoch: 5| Step: 8
Training loss: 3.38227915763855
Validation loss: 2.8034782076394684

Epoch: 5| Step: 9
Training loss: 4.082953453063965
Validation loss: 2.8015359242757163

Epoch: 5| Step: 10
Training loss: 2.9975078105926514
Validation loss: 2.799613183544528

Epoch: 35| Step: 0
Training loss: 3.242506504058838
Validation loss: 2.8003436262889574

Epoch: 5| Step: 1
Training loss: 2.655017852783203
Validation loss: 2.8006305925307737

Epoch: 5| Step: 2
Training loss: 2.65822172164917
Validation loss: 2.8039136496923303

Epoch: 5| Step: 3
Training loss: 3.02598237991333
Validation loss: 2.8016161662276073

Epoch: 5| Step: 4
Training loss: 2.764007091522217
Validation loss: 2.8003285059364895

Epoch: 5| Step: 5
Training loss: 3.4084174633026123
Validation loss: 2.7982069036012054

Epoch: 5| Step: 6
Training loss: 3.4030559062957764
Validation loss: 2.7966479460398355

Epoch: 5| Step: 7
Training loss: 2.707017183303833
Validation loss: 2.7965906896898822

Epoch: 5| Step: 8
Training loss: 2.6737964153289795
Validation loss: 2.793262199688983

Epoch: 5| Step: 9
Training loss: 2.5995888710021973
Validation loss: 2.792676107857817

Epoch: 5| Step: 10
Training loss: 3.1439366340637207
Validation loss: 2.7955176138108775

Epoch: 36| Step: 0
Training loss: 2.5790886878967285
Validation loss: 2.7946215162995043

Epoch: 5| Step: 1
Training loss: 2.9821650981903076
Validation loss: 2.793479883542625

Epoch: 5| Step: 2
Training loss: 3.0676848888397217
Validation loss: 2.7987377284675516

Epoch: 5| Step: 3
Training loss: 2.943188190460205
Validation loss: 2.795759485613915

Epoch: 5| Step: 4
Training loss: 2.821828842163086
Validation loss: 2.795394097605059

Epoch: 5| Step: 5
Training loss: 2.170504570007324
Validation loss: 2.792163407930764

Epoch: 5| Step: 6
Training loss: 3.3671298027038574
Validation loss: 2.7927390939445904

Epoch: 5| Step: 7
Training loss: 2.5957190990448
Validation loss: 2.79635710870066

Epoch: 5| Step: 8
Training loss: 3.0394740104675293
Validation loss: 2.80140822164474

Epoch: 5| Step: 9
Training loss: 2.737274408340454
Validation loss: 2.823702137957337

Epoch: 5| Step: 10
Training loss: 4.1255693435668945
Validation loss: 2.801345968759188

Epoch: 37| Step: 0
Training loss: 2.4001593589782715
Validation loss: 2.7958975197166525

Epoch: 5| Step: 1
Training loss: 2.95530366897583
Validation loss: 2.7937591075897217

Epoch: 5| Step: 2
Training loss: 3.035259485244751
Validation loss: 2.7954563453633297

Epoch: 5| Step: 3
Training loss: 3.4163620471954346
Validation loss: 2.7948075161185315

Epoch: 5| Step: 4
Training loss: 3.4180915355682373
Validation loss: 2.790888624806558

Epoch: 5| Step: 5
Training loss: 3.211881637573242
Validation loss: 2.7915810872149724

Epoch: 5| Step: 6
Training loss: 1.7542861700057983
Validation loss: 2.787422877486034

Epoch: 5| Step: 7
Training loss: 3.5391693115234375
Validation loss: 2.78622345770559

Epoch: 5| Step: 8
Training loss: 2.787644386291504
Validation loss: 2.7868749095547583

Epoch: 5| Step: 9
Training loss: 2.7332868576049805
Validation loss: 2.7879479777428413

Epoch: 5| Step: 10
Training loss: 2.958643913269043
Validation loss: 2.7899235063983547

Epoch: 38| Step: 0
Training loss: 3.5779900550842285
Validation loss: 2.789238240129204

Epoch: 5| Step: 1
Training loss: 3.7119972705841064
Validation loss: 2.787232627150833

Epoch: 5| Step: 2
Training loss: 2.913973569869995
Validation loss: 2.787616547717843

Epoch: 5| Step: 3
Training loss: 2.691251277923584
Validation loss: 2.7867239854669057

Epoch: 5| Step: 4
Training loss: 1.9821736812591553
Validation loss: 2.7855516172224477

Epoch: 5| Step: 5
Training loss: 2.6490910053253174
Validation loss: 2.7868414796808714

Epoch: 5| Step: 6
Training loss: 2.3720200061798096
Validation loss: 2.781063938653597

Epoch: 5| Step: 7
Training loss: 3.3312156200408936
Validation loss: 2.7831530442801853

Epoch: 5| Step: 8
Training loss: 2.6692962646484375
Validation loss: 2.7838721788057716

Epoch: 5| Step: 9
Training loss: 3.217433452606201
Validation loss: 2.7821332203444613

Epoch: 5| Step: 10
Training loss: 3.039274215698242
Validation loss: 2.7796343911078667

Epoch: 39| Step: 0
Training loss: 3.4803669452667236
Validation loss: 2.781333905394359

Epoch: 5| Step: 1
Training loss: 2.7185065746307373
Validation loss: 2.783310967106973

Epoch: 5| Step: 2
Training loss: 3.58324933052063
Validation loss: 2.7803246667308192

Epoch: 5| Step: 3
Training loss: 2.6261138916015625
Validation loss: 2.7845374743143716

Epoch: 5| Step: 4
Training loss: 3.0952906608581543
Validation loss: 2.789478417365782

Epoch: 5| Step: 5
Training loss: 2.567880392074585
Validation loss: 2.78325835094657

Epoch: 5| Step: 6
Training loss: 2.8503196239471436
Validation loss: 2.780203080946399

Epoch: 5| Step: 7
Training loss: 2.5423812866210938
Validation loss: 2.7745501302903697

Epoch: 5| Step: 8
Training loss: 3.3589141368865967
Validation loss: 2.7754695979497765

Epoch: 5| Step: 9
Training loss: 2.7057507038116455
Validation loss: 2.773304049686719

Epoch: 5| Step: 10
Training loss: 2.5445446968078613
Validation loss: 2.7739801714497228

Epoch: 40| Step: 0
Training loss: 3.6955227851867676
Validation loss: 2.773237851358229

Epoch: 5| Step: 1
Training loss: 2.4002318382263184
Validation loss: 2.7746321821725495

Epoch: 5| Step: 2
Training loss: 3.07073712348938
Validation loss: 2.772263870444349

Epoch: 5| Step: 3
Training loss: 2.160173177719116
Validation loss: 2.771042387972596

Epoch: 5| Step: 4
Training loss: 3.598672866821289
Validation loss: 2.769404475406934

Epoch: 5| Step: 5
Training loss: 2.655463933944702
Validation loss: 2.7720178429798414

Epoch: 5| Step: 6
Training loss: 3.588549852371216
Validation loss: 2.7748438414706977

Epoch: 5| Step: 7
Training loss: 2.6127262115478516
Validation loss: 2.7690561586810696

Epoch: 5| Step: 8
Training loss: 2.905427932739258
Validation loss: 2.769699717080721

Epoch: 5| Step: 9
Training loss: 3.188223361968994
Validation loss: 2.773676303125197

Epoch: 5| Step: 10
Training loss: 2.059913158416748
Validation loss: 2.770454716938798

Epoch: 41| Step: 0
Training loss: 3.0535364151000977
Validation loss: 2.769208144116145

Epoch: 5| Step: 1
Training loss: 3.3912856578826904
Validation loss: 2.7679819932547947

Epoch: 5| Step: 2
Training loss: 2.870211124420166
Validation loss: 2.7648303431849324

Epoch: 5| Step: 3
Training loss: 2.5444610118865967
Validation loss: 2.766748830836306

Epoch: 5| Step: 4
Training loss: 3.3853752613067627
Validation loss: 2.768869912752541

Epoch: 5| Step: 5
Training loss: 2.5862221717834473
Validation loss: 2.769235651980164

Epoch: 5| Step: 6
Training loss: 2.09417462348938
Validation loss: 2.763121215246057

Epoch: 5| Step: 7
Training loss: 2.3833725452423096
Validation loss: 2.7640261521903415

Epoch: 5| Step: 8
Training loss: 3.031637668609619
Validation loss: 2.763364253505584

Epoch: 5| Step: 9
Training loss: 3.386645555496216
Validation loss: 2.7640973726908364

Epoch: 5| Step: 10
Training loss: 3.3452014923095703
Validation loss: 2.7611632782925843

Epoch: 42| Step: 0
Training loss: 2.6124565601348877
Validation loss: 2.763469560171968

Epoch: 5| Step: 1
Training loss: 3.0181639194488525
Validation loss: 2.7647386417594007

Epoch: 5| Step: 2
Training loss: 3.1579997539520264
Validation loss: 2.763996075558406

Epoch: 5| Step: 3
Training loss: 3.5378432273864746
Validation loss: 2.760944084454608

Epoch: 5| Step: 4
Training loss: 2.8481526374816895
Validation loss: 2.7606066503832416

Epoch: 5| Step: 5
Training loss: 2.5673346519470215
Validation loss: 2.758883214765979

Epoch: 5| Step: 6
Training loss: 2.95328688621521
Validation loss: 2.7580318886746644

Epoch: 5| Step: 7
Training loss: 2.6733500957489014
Validation loss: 2.753129892451789

Epoch: 5| Step: 8
Training loss: 3.200784206390381
Validation loss: 2.7568107702398814

Epoch: 5| Step: 9
Training loss: 2.3317086696624756
Validation loss: 2.7558871879372546

Epoch: 5| Step: 10
Training loss: 3.086259365081787
Validation loss: 2.756550032605407

Epoch: 43| Step: 0
Training loss: 2.812549352645874
Validation loss: 2.757710620921145

Epoch: 5| Step: 1
Training loss: 2.775031805038452
Validation loss: 2.7594337027559996

Epoch: 5| Step: 2
Training loss: 3.143920660018921
Validation loss: 2.7554512844290784

Epoch: 5| Step: 3
Training loss: 2.9700264930725098
Validation loss: 2.756037635187949

Epoch: 5| Step: 4
Training loss: 2.3960800170898438
Validation loss: 2.759395912129392

Epoch: 5| Step: 5
Training loss: 3.2946460247039795
Validation loss: 2.757308985597344

Epoch: 5| Step: 6
Training loss: 3.0289225578308105
Validation loss: 2.754300004692488

Epoch: 5| Step: 7
Training loss: 2.572052478790283
Validation loss: 2.753903865814209

Epoch: 5| Step: 8
Training loss: 3.130002737045288
Validation loss: 2.7540042707996983

Epoch: 5| Step: 9
Training loss: 3.034547805786133
Validation loss: 2.7535337478883806

Epoch: 5| Step: 10
Training loss: 2.7160608768463135
Validation loss: 2.7536922039524203

Epoch: 44| Step: 0
Training loss: 2.4121298789978027
Validation loss: 2.7597488075174312

Epoch: 5| Step: 1
Training loss: 2.6857354640960693
Validation loss: 2.7644163844405965

Epoch: 5| Step: 2
Training loss: 2.75270676612854
Validation loss: 2.769919059609854

Epoch: 5| Step: 3
Training loss: 3.1855647563934326
Validation loss: 2.7630334438816195

Epoch: 5| Step: 4
Training loss: 3.4414801597595215
Validation loss: 2.7586996580964778

Epoch: 5| Step: 5
Training loss: 3.0487492084503174
Validation loss: 2.757474394254787

Epoch: 5| Step: 6
Training loss: 1.978849172592163
Validation loss: 2.7556716319053405

Epoch: 5| Step: 7
Training loss: 3.2939651012420654
Validation loss: 2.7518336593463855

Epoch: 5| Step: 8
Training loss: 3.546353816986084
Validation loss: 2.7575934881805093

Epoch: 5| Step: 9
Training loss: 2.6881699562072754
Validation loss: 2.7603297131035918

Epoch: 5| Step: 10
Training loss: 2.864898443222046
Validation loss: 2.761082031393564

Epoch: 45| Step: 0
Training loss: 3.221684694290161
Validation loss: 2.7574953725261073

Epoch: 5| Step: 1
Training loss: 1.9589307308197021
Validation loss: 2.7694542023443405

Epoch: 5| Step: 2
Training loss: 3.5153846740722656
Validation loss: 2.7669707934061685

Epoch: 5| Step: 3
Training loss: 3.015078067779541
Validation loss: 2.7565133802352415

Epoch: 5| Step: 4
Training loss: 3.370744228363037
Validation loss: 2.755110732970699

Epoch: 5| Step: 5
Training loss: 2.9853813648223877
Validation loss: 2.756827610795216

Epoch: 5| Step: 6
Training loss: 2.9775760173797607
Validation loss: 2.767446184671053

Epoch: 5| Step: 7
Training loss: 2.5249123573303223
Validation loss: 2.7643620147499988

Epoch: 5| Step: 8
Training loss: 2.9516940116882324
Validation loss: 2.757329417813209

Epoch: 5| Step: 9
Training loss: 2.2417283058166504
Validation loss: 2.7638363325467674

Epoch: 5| Step: 10
Training loss: 3.2300479412078857
Validation loss: 2.764303235597508

Epoch: 46| Step: 0
Training loss: 2.3921170234680176
Validation loss: 2.7619192959159933

Epoch: 5| Step: 1
Training loss: 3.3583922386169434
Validation loss: 2.765370297175582

Epoch: 5| Step: 2
Training loss: 3.1838996410369873
Validation loss: 2.763552970783685

Epoch: 5| Step: 3
Training loss: 3.4121406078338623
Validation loss: 2.755582335174725

Epoch: 5| Step: 4
Training loss: 2.3708083629608154
Validation loss: 2.7519721651589997

Epoch: 5| Step: 5
Training loss: 2.3934550285339355
Validation loss: 2.7466189528024323

Epoch: 5| Step: 6
Training loss: 3.2192978858947754
Validation loss: 2.749269921292541

Epoch: 5| Step: 7
Training loss: 3.303680419921875
Validation loss: 2.7484535376230874

Epoch: 5| Step: 8
Training loss: 2.880892276763916
Validation loss: 2.7476175087754444

Epoch: 5| Step: 9
Training loss: 2.7237613201141357
Validation loss: 2.7511878705793813

Epoch: 5| Step: 10
Training loss: 2.587085723876953
Validation loss: 2.750144940550609

Epoch: 47| Step: 0
Training loss: 3.033390522003174
Validation loss: 2.750965746500159

Epoch: 5| Step: 1
Training loss: 2.9185783863067627
Validation loss: 2.746734683231641

Epoch: 5| Step: 2
Training loss: 2.9221558570861816
Validation loss: 2.7521348025209162

Epoch: 5| Step: 3
Training loss: 3.4492835998535156
Validation loss: 2.7445237918566634

Epoch: 5| Step: 4
Training loss: 3.202735185623169
Validation loss: 2.73999088041244

Epoch: 5| Step: 5
Training loss: 2.0395455360412598
Validation loss: 2.735637689149508

Epoch: 5| Step: 6
Training loss: 3.068237781524658
Validation loss: 2.7385132415320284

Epoch: 5| Step: 7
Training loss: 2.9616611003875732
Validation loss: 2.7333148910153295

Epoch: 5| Step: 8
Training loss: 2.7346205711364746
Validation loss: 2.736068207730529

Epoch: 5| Step: 9
Training loss: 2.829826831817627
Validation loss: 2.7375578265036307

Epoch: 5| Step: 10
Training loss: 2.5562732219696045
Validation loss: 2.7408585061309156

Epoch: 48| Step: 0
Training loss: 2.695091724395752
Validation loss: 2.7432347036177114

Epoch: 5| Step: 1
Training loss: 2.619013547897339
Validation loss: 2.7381774507543093

Epoch: 5| Step: 2
Training loss: 2.7576987743377686
Validation loss: 2.7343665348586215

Epoch: 5| Step: 3
Training loss: 2.3835878372192383
Validation loss: 2.7404323726572017

Epoch: 5| Step: 4
Training loss: 2.199188232421875
Validation loss: 2.7398968563284924

Epoch: 5| Step: 5
Training loss: 3.315840244293213
Validation loss: 2.7345947040024625

Epoch: 5| Step: 6
Training loss: 3.7457213401794434
Validation loss: 2.73232933526398

Epoch: 5| Step: 7
Training loss: 3.1321260929107666
Validation loss: 2.727967603232271

Epoch: 5| Step: 8
Training loss: 2.6087453365325928
Validation loss: 2.7310165769310406

Epoch: 5| Step: 9
Training loss: 3.225381851196289
Validation loss: 2.7264688835349133

Epoch: 5| Step: 10
Training loss: 2.9761664867401123
Validation loss: 2.7268429084490706

Epoch: 49| Step: 0
Training loss: 2.4963488578796387
Validation loss: 2.7318914269888275

Epoch: 5| Step: 1
Training loss: 2.6588988304138184
Validation loss: 2.731787266269807

Epoch: 5| Step: 2
Training loss: 3.4610931873321533
Validation loss: 2.727212785392679

Epoch: 5| Step: 3
Training loss: 2.5304431915283203
Validation loss: 2.7212831794574694

Epoch: 5| Step: 4
Training loss: 2.731645107269287
Validation loss: 2.726551684000159

Epoch: 5| Step: 5
Training loss: 3.673330307006836
Validation loss: 2.7257462778399066

Epoch: 5| Step: 6
Training loss: 2.4378838539123535
Validation loss: 2.731274535579066

Epoch: 5| Step: 7
Training loss: 3.0946123600006104
Validation loss: 2.7413746490273425

Epoch: 5| Step: 8
Training loss: 3.162440299987793
Validation loss: 2.721016671067925

Epoch: 5| Step: 9
Training loss: 2.313499927520752
Validation loss: 2.721479385129867

Epoch: 5| Step: 10
Training loss: 3.0784473419189453
Validation loss: 2.719772320921703

Epoch: 50| Step: 0
Training loss: 2.881648540496826
Validation loss: 2.7158343843234483

Epoch: 5| Step: 1
Training loss: 2.9271366596221924
Validation loss: 2.717188988962481

Epoch: 5| Step: 2
Training loss: 3.019143581390381
Validation loss: 2.7107719964878534

Epoch: 5| Step: 3
Training loss: 2.7816967964172363
Validation loss: 2.7089207685121925

Epoch: 5| Step: 4
Training loss: 2.9347288608551025
Validation loss: 2.713135888499598

Epoch: 5| Step: 5
Training loss: 3.0691843032836914
Validation loss: 2.715804866565171

Epoch: 5| Step: 6
Training loss: 2.205289840698242
Validation loss: 2.719006743482364

Epoch: 5| Step: 7
Training loss: 2.8962326049804688
Validation loss: 2.7295086204364734

Epoch: 5| Step: 8
Training loss: 3.199751853942871
Validation loss: 2.7371942612432663

Epoch: 5| Step: 9
Training loss: 3.323474168777466
Validation loss: 2.7259385149966002

Epoch: 5| Step: 10
Training loss: 2.230654716491699
Validation loss: 2.714930690744872

Epoch: 51| Step: 0
Training loss: 2.8974645137786865
Validation loss: 2.711545087957895

Epoch: 5| Step: 1
Training loss: 3.240795850753784
Validation loss: 2.7037061081137708

Epoch: 5| Step: 2
Training loss: 2.4214179515838623
Validation loss: 2.712998720907396

Epoch: 5| Step: 3
Training loss: 3.3447623252868652
Validation loss: 2.7176295403511292

Epoch: 5| Step: 4
Training loss: 2.7962164878845215
Validation loss: 2.7237933246038293

Epoch: 5| Step: 5
Training loss: 2.310859203338623
Validation loss: 2.7192858367837887

Epoch: 5| Step: 6
Training loss: 2.9362621307373047
Validation loss: 2.7103809284907516

Epoch: 5| Step: 7
Training loss: 3.4291908740997314
Validation loss: 2.7095673571350756

Epoch: 5| Step: 8
Training loss: 2.6705050468444824
Validation loss: 2.7018068631490073

Epoch: 5| Step: 9
Training loss: 2.440821886062622
Validation loss: 2.701778486210813

Epoch: 5| Step: 10
Training loss: 2.867088794708252
Validation loss: 2.7028398026702223

Epoch: 52| Step: 0
Training loss: 2.4506518840789795
Validation loss: 2.7123106192517024

Epoch: 5| Step: 1
Training loss: 2.828634262084961
Validation loss: 2.715846364216138

Epoch: 5| Step: 2
Training loss: 2.9127166271209717
Validation loss: 2.7098139383459605

Epoch: 5| Step: 3
Training loss: 2.9484498500823975
Validation loss: 2.7050889153634348

Epoch: 5| Step: 4
Training loss: 2.2204318046569824
Validation loss: 2.7107262355025097

Epoch: 5| Step: 5
Training loss: 2.523921251296997
Validation loss: 2.7178322140888502

Epoch: 5| Step: 6
Training loss: 2.5489964485168457
Validation loss: 2.7215909009338706

Epoch: 5| Step: 7
Training loss: 3.127502918243408
Validation loss: 2.733182094430411

Epoch: 5| Step: 8
Training loss: 3.4526209831237793
Validation loss: 2.760962391412386

Epoch: 5| Step: 9
Training loss: 3.740929365158081
Validation loss: 2.7549642080901773

Epoch: 5| Step: 10
Training loss: 2.6872353553771973
Validation loss: 2.710483161352014

Epoch: 53| Step: 0
Training loss: 2.884995698928833
Validation loss: 2.71505319687628

Epoch: 5| Step: 1
Training loss: 3.2549896240234375
Validation loss: 2.737892755898096

Epoch: 5| Step: 2
Training loss: 2.9735305309295654
Validation loss: 2.7430064575646513

Epoch: 5| Step: 3
Training loss: 3.1856977939605713
Validation loss: 2.751654012228853

Epoch: 5| Step: 4
Training loss: 3.207507371902466
Validation loss: 2.7490085094205794

Epoch: 5| Step: 5
Training loss: 2.483426809310913
Validation loss: 2.738336342637257

Epoch: 5| Step: 6
Training loss: 2.5997889041900635
Validation loss: 2.7254696584516958

Epoch: 5| Step: 7
Training loss: 2.7617087364196777
Validation loss: 2.7232400140454693

Epoch: 5| Step: 8
Training loss: 2.9220707416534424
Validation loss: 2.720590071011615

Epoch: 5| Step: 9
Training loss: 2.847435235977173
Validation loss: 2.714035523835049

Epoch: 5| Step: 10
Training loss: 2.4151196479797363
Validation loss: 2.717838361699094

Epoch: 54| Step: 0
Training loss: 2.4712882041931152
Validation loss: 2.728724302784089

Epoch: 5| Step: 1
Training loss: 2.7832484245300293
Validation loss: 2.725399186534266

Epoch: 5| Step: 2
Training loss: 2.992220878601074
Validation loss: 2.7317218575426327

Epoch: 5| Step: 3
Training loss: 2.6626217365264893
Validation loss: 2.7313176560145553

Epoch: 5| Step: 4
Training loss: 2.687781810760498
Validation loss: 2.7250375363134567

Epoch: 5| Step: 5
Training loss: 3.1168506145477295
Validation loss: 2.719151960906162

Epoch: 5| Step: 6
Training loss: 2.353081226348877
Validation loss: 2.709252626665177

Epoch: 5| Step: 7
Training loss: 2.8774819374084473
Validation loss: 2.6995449219980547

Epoch: 5| Step: 8
Training loss: 2.7884984016418457
Validation loss: 2.696351771713585

Epoch: 5| Step: 9
Training loss: 3.1712584495544434
Validation loss: 2.6998022448632026

Epoch: 5| Step: 10
Training loss: 3.4770967960357666
Validation loss: 2.6921389641300326

Epoch: 55| Step: 0
Training loss: 3.073276996612549
Validation loss: 2.6939382553100586

Epoch: 5| Step: 1
Training loss: 2.6450839042663574
Validation loss: 2.691028456534109

Epoch: 5| Step: 2
Training loss: 2.1243419647216797
Validation loss: 2.691587225083382

Epoch: 5| Step: 3
Training loss: 3.0039896965026855
Validation loss: 2.69735062250527

Epoch: 5| Step: 4
Training loss: 2.562695264816284
Validation loss: 2.7038251405121176

Epoch: 5| Step: 5
Training loss: 2.3101372718811035
Validation loss: 2.703800839762534

Epoch: 5| Step: 6
Training loss: 3.0979702472686768
Validation loss: 2.69838273397056

Epoch: 5| Step: 7
Training loss: 3.0594379901885986
Validation loss: 2.6877066909625964

Epoch: 5| Step: 8
Training loss: 3.1618905067443848
Validation loss: 2.688643963106217

Epoch: 5| Step: 9
Training loss: 2.878821849822998
Validation loss: 2.6871689929757068

Epoch: 5| Step: 10
Training loss: 3.289637804031372
Validation loss: 2.683638995693576

Epoch: 56| Step: 0
Training loss: 3.443460464477539
Validation loss: 2.6850062493355042

Epoch: 5| Step: 1
Training loss: 3.1593449115753174
Validation loss: 2.6845244002598587

Epoch: 5| Step: 2
Training loss: 2.83695912361145
Validation loss: 2.686589653773974

Epoch: 5| Step: 3
Training loss: 3.1580824851989746
Validation loss: 2.684556133003645

Epoch: 5| Step: 4
Training loss: 2.78627347946167
Validation loss: 2.6863375786812074

Epoch: 5| Step: 5
Training loss: 2.2914257049560547
Validation loss: 2.682998070152857

Epoch: 5| Step: 6
Training loss: 2.7629213333129883
Validation loss: 2.6848981380462646

Epoch: 5| Step: 7
Training loss: 3.2093398571014404
Validation loss: 2.678714072832497

Epoch: 5| Step: 8
Training loss: 2.7194342613220215
Validation loss: 2.6811898780125443

Epoch: 5| Step: 9
Training loss: 2.475308418273926
Validation loss: 2.682913513593776

Epoch: 5| Step: 10
Training loss: 2.248788595199585
Validation loss: 2.6773586734648673

Epoch: 57| Step: 0
Training loss: 3.084620237350464
Validation loss: 2.681838312456685

Epoch: 5| Step: 1
Training loss: 3.0268940925598145
Validation loss: 2.680016615057504

Epoch: 5| Step: 2
Training loss: 3.226187229156494
Validation loss: 2.687113244046447

Epoch: 5| Step: 3
Training loss: 2.607365846633911
Validation loss: 2.6826678245298323

Epoch: 5| Step: 4
Training loss: 2.164350986480713
Validation loss: 2.6825495432781916

Epoch: 5| Step: 5
Training loss: 3.1622872352600098
Validation loss: 2.684129966202603

Epoch: 5| Step: 6
Training loss: 2.6544930934906006
Validation loss: 2.6770481217292046

Epoch: 5| Step: 7
Training loss: 2.8369858264923096
Validation loss: 2.6761777990607807

Epoch: 5| Step: 8
Training loss: 2.6110939979553223
Validation loss: 2.6752903179455827

Epoch: 5| Step: 9
Training loss: 2.969696521759033
Validation loss: 2.670092175083776

Epoch: 5| Step: 10
Training loss: 2.7162721157073975
Validation loss: 2.6674885160179547

Epoch: 58| Step: 0
Training loss: 2.6902072429656982
Validation loss: 2.6669263173175115

Epoch: 5| Step: 1
Training loss: 1.7900218963623047
Validation loss: 2.6672566731770835

Epoch: 5| Step: 2
Training loss: 2.758176803588867
Validation loss: 2.667702013446439

Epoch: 5| Step: 3
Training loss: 2.9914329051971436
Validation loss: 2.6694158302840365

Epoch: 5| Step: 4
Training loss: 3.0909154415130615
Validation loss: 2.6655417873013403

Epoch: 5| Step: 5
Training loss: 3.036085367202759
Validation loss: 2.663335874516477

Epoch: 5| Step: 6
Training loss: 2.793254852294922
Validation loss: 2.6624752526642173

Epoch: 5| Step: 7
Training loss: 2.7179179191589355
Validation loss: 2.66394591587846

Epoch: 5| Step: 8
Training loss: 3.045717477798462
Validation loss: 2.662589624363889

Epoch: 5| Step: 9
Training loss: 3.1859889030456543
Validation loss: 2.6688530368189656

Epoch: 5| Step: 10
Training loss: 2.7860107421875
Validation loss: 2.6734215905589442

Epoch: 59| Step: 0
Training loss: 3.0831172466278076
Validation loss: 2.687769297630556

Epoch: 5| Step: 1
Training loss: 2.6951162815093994
Validation loss: 2.684672486397528

Epoch: 5| Step: 2
Training loss: 2.7887821197509766
Validation loss: 2.6769539694632254

Epoch: 5| Step: 3
Training loss: 2.438674211502075
Validation loss: 2.6575182714769916

Epoch: 5| Step: 4
Training loss: 3.244821071624756
Validation loss: 2.6557876397204656

Epoch: 5| Step: 5
Training loss: 2.6585309505462646
Validation loss: 2.6487259890443537

Epoch: 5| Step: 6
Training loss: 3.041585922241211
Validation loss: 2.65512187762927

Epoch: 5| Step: 7
Training loss: 2.5993893146514893
Validation loss: 2.6560368871176117

Epoch: 5| Step: 8
Training loss: 2.686415195465088
Validation loss: 2.6604879184435775

Epoch: 5| Step: 9
Training loss: 3.2042784690856934
Validation loss: 2.6561581780833583

Epoch: 5| Step: 10
Training loss: 2.375380516052246
Validation loss: 2.647415607206283

Epoch: 60| Step: 0
Training loss: 3.34136962890625
Validation loss: 2.64821126896848

Epoch: 5| Step: 1
Training loss: 3.4977214336395264
Validation loss: 2.6485609803148495

Epoch: 5| Step: 2
Training loss: 2.542483329772949
Validation loss: 2.6492297085382606

Epoch: 5| Step: 3
Training loss: 2.473294973373413
Validation loss: 2.649624057995376

Epoch: 5| Step: 4
Training loss: 3.370685577392578
Validation loss: 2.6571691651498117

Epoch: 5| Step: 5
Training loss: 2.361236572265625
Validation loss: 2.6714118296100247

Epoch: 5| Step: 6
Training loss: 3.0180819034576416
Validation loss: 2.661265080974948

Epoch: 5| Step: 7
Training loss: 2.055711030960083
Validation loss: 2.651655263798211

Epoch: 5| Step: 8
Training loss: 2.977693557739258
Validation loss: 2.651279572517641

Epoch: 5| Step: 9
Training loss: 2.500175952911377
Validation loss: 2.6436470580357376

Epoch: 5| Step: 10
Training loss: 2.629603147506714
Validation loss: 2.6415172725595455

Epoch: 61| Step: 0
Training loss: 2.635021924972534
Validation loss: 2.646478452990132

Epoch: 5| Step: 1
Training loss: 2.673840284347534
Validation loss: 2.6527970016643567

Epoch: 5| Step: 2
Training loss: 3.096869468688965
Validation loss: 2.657381437158072

Epoch: 5| Step: 3
Training loss: 2.722316265106201
Validation loss: 2.6543092778933945

Epoch: 5| Step: 4
Training loss: 2.552433490753174
Validation loss: 2.649937113126119

Epoch: 5| Step: 5
Training loss: 3.08013916015625
Validation loss: 2.6477035066132903

Epoch: 5| Step: 6
Training loss: 2.88696551322937
Validation loss: 2.66484191853513

Epoch: 5| Step: 7
Training loss: 2.810356616973877
Validation loss: 2.6454144703444613

Epoch: 5| Step: 8
Training loss: 2.807978391647339
Validation loss: 2.64235435506349

Epoch: 5| Step: 9
Training loss: 2.3459274768829346
Validation loss: 2.6448936513675156

Epoch: 5| Step: 10
Training loss: 3.240463972091675
Validation loss: 2.6529076945397163

Epoch: 62| Step: 0
Training loss: 2.259047508239746
Validation loss: 2.66933201718074

Epoch: 5| Step: 1
Training loss: 2.6829867362976074
Validation loss: 2.6673049862666796

Epoch: 5| Step: 2
Training loss: 2.8287127017974854
Validation loss: 2.6784784614398913

Epoch: 5| Step: 3
Training loss: 2.881861686706543
Validation loss: 2.6827981446378972

Epoch: 5| Step: 4
Training loss: 2.608607769012451
Validation loss: 2.6895415449655182

Epoch: 5| Step: 5
Training loss: 3.1162197589874268
Validation loss: 2.6974815296870407

Epoch: 5| Step: 6
Training loss: 2.8828351497650146
Validation loss: 2.669458099590835

Epoch: 5| Step: 7
Training loss: 3.6192092895507812
Validation loss: 2.646661963514102

Epoch: 5| Step: 8
Training loss: 2.203800678253174
Validation loss: 2.6340835530270814

Epoch: 5| Step: 9
Training loss: 3.013558864593506
Validation loss: 2.634299309022965

Epoch: 5| Step: 10
Training loss: 2.675384998321533
Validation loss: 2.6517751806525776

Epoch: 63| Step: 0
Training loss: 2.5114102363586426
Validation loss: 2.6915317709727953

Epoch: 5| Step: 1
Training loss: 3.483722686767578
Validation loss: 2.69358911309191

Epoch: 5| Step: 2
Training loss: 2.7603979110717773
Validation loss: 2.674978099843507

Epoch: 5| Step: 3
Training loss: 2.7701783180236816
Validation loss: 2.6550253873230307

Epoch: 5| Step: 4
Training loss: 3.016660213470459
Validation loss: 2.64466772284559

Epoch: 5| Step: 5
Training loss: 3.0322258472442627
Validation loss: 2.6440130510637836

Epoch: 5| Step: 6
Training loss: 2.5325770378112793
Validation loss: 2.6410207492049023

Epoch: 5| Step: 7
Training loss: 2.9213194847106934
Validation loss: 2.642726239337716

Epoch: 5| Step: 8
Training loss: 2.480229139328003
Validation loss: 2.646132625559325

Epoch: 5| Step: 9
Training loss: 2.9800922870635986
Validation loss: 2.658198025918776

Epoch: 5| Step: 10
Training loss: 2.308650016784668
Validation loss: 2.661152316677955

Epoch: 64| Step: 0
Training loss: 2.940889835357666
Validation loss: 2.6996218747990106

Epoch: 5| Step: 1
Training loss: 2.5757462978363037
Validation loss: 2.7156956785468647

Epoch: 5| Step: 2
Training loss: 3.453174591064453
Validation loss: 2.7099256028411207

Epoch: 5| Step: 3
Training loss: 2.7532894611358643
Validation loss: 2.6740329547594954

Epoch: 5| Step: 4
Training loss: 2.88568115234375
Validation loss: 2.6463985084205546

Epoch: 5| Step: 5
Training loss: 2.3575663566589355
Validation loss: 2.626182386952062

Epoch: 5| Step: 6
Training loss: 2.9960854053497314
Validation loss: 2.6271373943615983

Epoch: 5| Step: 7
Training loss: 2.389194965362549
Validation loss: 2.6380206077329573

Epoch: 5| Step: 8
Training loss: 3.1362104415893555
Validation loss: 2.6577436975253526

Epoch: 5| Step: 9
Training loss: 2.6105151176452637
Validation loss: 2.6566179439585698

Epoch: 5| Step: 10
Training loss: 2.9456000328063965
Validation loss: 2.6547575009766446

Epoch: 65| Step: 0
Training loss: 3.393655776977539
Validation loss: 2.654869535917877

Epoch: 5| Step: 1
Training loss: 1.78597891330719
Validation loss: 2.6423824987103863

Epoch: 5| Step: 2
Training loss: 2.6397461891174316
Validation loss: 2.6304931179169686

Epoch: 5| Step: 3
Training loss: 3.1443140506744385
Validation loss: 2.6218380235856578

Epoch: 5| Step: 4
Training loss: 3.19722056388855
Validation loss: 2.620690479073473

Epoch: 5| Step: 5
Training loss: 2.8590140342712402
Validation loss: 2.6216656751530145

Epoch: 5| Step: 6
Training loss: 3.0549018383026123
Validation loss: 2.6240949784555743

Epoch: 5| Step: 7
Training loss: 2.4365997314453125
Validation loss: 2.625994820748606

Epoch: 5| Step: 8
Training loss: 2.408446788787842
Validation loss: 2.640159615906336

Epoch: 5| Step: 9
Training loss: 2.8162875175476074
Validation loss: 2.644550082504108

Epoch: 5| Step: 10
Training loss: 2.9064464569091797
Validation loss: 2.648061252409412

Epoch: 66| Step: 0
Training loss: 3.3174967765808105
Validation loss: 2.6434624220735286

Epoch: 5| Step: 1
Training loss: 2.9087984561920166
Validation loss: 2.6399000793374996

Epoch: 5| Step: 2
Training loss: 2.773077964782715
Validation loss: 2.6368493982540664

Epoch: 5| Step: 3
Training loss: 3.1727397441864014
Validation loss: 2.6349219378604682

Epoch: 5| Step: 4
Training loss: 2.8223018646240234
Validation loss: 2.6299795104611303

Epoch: 5| Step: 5
Training loss: 2.8704123497009277
Validation loss: 2.6305197515795307

Epoch: 5| Step: 6
Training loss: 2.6580586433410645
Validation loss: 2.6240599309244463

Epoch: 5| Step: 7
Training loss: 2.792738437652588
Validation loss: 2.6232437138916342

Epoch: 5| Step: 8
Training loss: 2.4778268337249756
Validation loss: 2.6237972782504175

Epoch: 5| Step: 9
Training loss: 2.182338237762451
Validation loss: 2.6267726241901355

Epoch: 5| Step: 10
Training loss: 2.581325054168701
Validation loss: 2.622889288010136

Epoch: 67| Step: 0
Training loss: 3.088003158569336
Validation loss: 2.6202910407896964

Epoch: 5| Step: 1
Training loss: 2.7714200019836426
Validation loss: 2.6259882552649385

Epoch: 5| Step: 2
Training loss: 2.473808765411377
Validation loss: 2.6331112871887865

Epoch: 5| Step: 3
Training loss: 3.926903486251831
Validation loss: 2.6351407907342397

Epoch: 5| Step: 4
Training loss: 2.7660441398620605
Validation loss: 2.6280979674349547

Epoch: 5| Step: 5
Training loss: 2.89015531539917
Validation loss: 2.6193320059007212

Epoch: 5| Step: 6
Training loss: 2.9911246299743652
Validation loss: 2.610222157611642

Epoch: 5| Step: 7
Training loss: 2.644775867462158
Validation loss: 2.61090991573949

Epoch: 5| Step: 8
Training loss: 2.3976497650146484
Validation loss: 2.613671492504817

Epoch: 5| Step: 9
Training loss: 2.468224048614502
Validation loss: 2.6138257108708864

Epoch: 5| Step: 10
Training loss: 2.038422107696533
Validation loss: 2.612338194283106

Epoch: 68| Step: 0
Training loss: 3.0210301876068115
Validation loss: 2.614972086362941

Epoch: 5| Step: 1
Training loss: 2.657395124435425
Validation loss: 2.6232271220094416

Epoch: 5| Step: 2
Training loss: 3.253699541091919
Validation loss: 2.6319235140277493

Epoch: 5| Step: 3
Training loss: 1.6943728923797607
Validation loss: 2.647979221036357

Epoch: 5| Step: 4
Training loss: 2.7233967781066895
Validation loss: 2.6514903858143795

Epoch: 5| Step: 5
Training loss: 2.6488518714904785
Validation loss: 2.647005952814574

Epoch: 5| Step: 6
Training loss: 2.9830100536346436
Validation loss: 2.6408208672718336

Epoch: 5| Step: 7
Training loss: 3.1174874305725098
Validation loss: 2.63678345628964

Epoch: 5| Step: 8
Training loss: 2.9371867179870605
Validation loss: 2.631877096750403

Epoch: 5| Step: 9
Training loss: 3.0097947120666504
Validation loss: 2.630208215405864

Epoch: 5| Step: 10
Training loss: 2.478764533996582
Validation loss: 2.621173938115438

Epoch: 69| Step: 0
Training loss: 2.3994193077087402
Validation loss: 2.619035925916446

Epoch: 5| Step: 1
Training loss: 3.019683361053467
Validation loss: 2.6093600757660402

Epoch: 5| Step: 2
Training loss: 2.9109930992126465
Validation loss: 2.6075065469229095

Epoch: 5| Step: 3
Training loss: 3.038989305496216
Validation loss: 2.606552109923414

Epoch: 5| Step: 4
Training loss: 2.424630641937256
Validation loss: 2.606182926444597

Epoch: 5| Step: 5
Training loss: 2.944331645965576
Validation loss: 2.6067058860614734

Epoch: 5| Step: 6
Training loss: 2.279562473297119
Validation loss: 2.6091636509023686

Epoch: 5| Step: 7
Training loss: 3.068368434906006
Validation loss: 2.6137409440932737

Epoch: 5| Step: 8
Training loss: 2.8416876792907715
Validation loss: 2.6231699194959415

Epoch: 5| Step: 9
Training loss: 3.0680108070373535
Validation loss: 2.621256430943807

Epoch: 5| Step: 10
Training loss: 2.41867733001709
Validation loss: 2.6198786010024366

Epoch: 70| Step: 0
Training loss: 2.3070805072784424
Validation loss: 2.6110555997458835

Epoch: 5| Step: 1
Training loss: 2.1476378440856934
Validation loss: 2.611078011092319

Epoch: 5| Step: 2
Training loss: 3.311901807785034
Validation loss: 2.607905513496809

Epoch: 5| Step: 3
Training loss: 2.636531114578247
Validation loss: 2.6052414242939284

Epoch: 5| Step: 4
Training loss: 2.8415799140930176
Validation loss: 2.603433378281132

Epoch: 5| Step: 5
Training loss: 3.046565294265747
Validation loss: 2.6023175254944833

Epoch: 5| Step: 6
Training loss: 3.361138105392456
Validation loss: 2.602342713263727

Epoch: 5| Step: 7
Training loss: 2.1228816509246826
Validation loss: 2.602152539837745

Epoch: 5| Step: 8
Training loss: 2.740744113922119
Validation loss: 2.6012719087703253

Epoch: 5| Step: 9
Training loss: 2.769428253173828
Validation loss: 2.602150478670674

Epoch: 5| Step: 10
Training loss: 3.157679319381714
Validation loss: 2.6033076035079135

Epoch: 71| Step: 0
Training loss: 2.546151638031006
Validation loss: 2.6051041464651785

Epoch: 5| Step: 1
Training loss: 2.489426374435425
Validation loss: 2.6054983292856524

Epoch: 5| Step: 2
Training loss: 2.564537525177002
Validation loss: 2.6046442562533962

Epoch: 5| Step: 3
Training loss: 3.08390474319458
Validation loss: 2.6015568625542427

Epoch: 5| Step: 4
Training loss: 2.8778438568115234
Validation loss: 2.6025865052336004

Epoch: 5| Step: 5
Training loss: 3.148224353790283
Validation loss: 2.5996696103003716

Epoch: 5| Step: 6
Training loss: 2.918581247329712
Validation loss: 2.594119377033685

Epoch: 5| Step: 7
Training loss: 2.3129141330718994
Validation loss: 2.597237535702285

Epoch: 5| Step: 8
Training loss: 2.5598998069763184
Validation loss: 2.5945132522172827

Epoch: 5| Step: 9
Training loss: 3.212287425994873
Validation loss: 2.5965410842690417

Epoch: 5| Step: 10
Training loss: 2.5639045238494873
Validation loss: 2.592640810115363

Epoch: 72| Step: 0
Training loss: 2.7454819679260254
Validation loss: 2.5921695027300107

Epoch: 5| Step: 1
Training loss: 3.2892792224884033
Validation loss: 2.591785507817422

Epoch: 5| Step: 2
Training loss: 2.6350300312042236
Validation loss: 2.59467670225328

Epoch: 5| Step: 3
Training loss: 2.662107467651367
Validation loss: 2.592140943773331

Epoch: 5| Step: 4
Training loss: 2.6036791801452637
Validation loss: 2.589937369028727

Epoch: 5| Step: 5
Training loss: 2.2997777462005615
Validation loss: 2.5900057797790854

Epoch: 5| Step: 6
Training loss: 3.0990824699401855
Validation loss: 2.591043705581337

Epoch: 5| Step: 7
Training loss: 2.707056760787964
Validation loss: 2.5893827138408536

Epoch: 5| Step: 8
Training loss: 2.762718677520752
Validation loss: 2.5932620238232356

Epoch: 5| Step: 9
Training loss: 3.338496685028076
Validation loss: 2.591235994010843

Epoch: 5| Step: 10
Training loss: 2.043976068496704
Validation loss: 2.5890215417390228

Epoch: 73| Step: 0
Training loss: 2.6138885021209717
Validation loss: 2.5956905452154015

Epoch: 5| Step: 1
Training loss: 2.7621779441833496
Validation loss: 2.603101053545552

Epoch: 5| Step: 2
Training loss: 2.311016082763672
Validation loss: 2.6042787515988914

Epoch: 5| Step: 3
Training loss: 3.5699119567871094
Validation loss: 2.615616657400644

Epoch: 5| Step: 4
Training loss: 2.735485315322876
Validation loss: 2.609390717680736

Epoch: 5| Step: 5
Training loss: 2.548926830291748
Validation loss: 2.6083277989459295

Epoch: 5| Step: 6
Training loss: 2.8198719024658203
Validation loss: 2.6059879923379548

Epoch: 5| Step: 7
Training loss: 2.7475531101226807
Validation loss: 2.5904282600648942

Epoch: 5| Step: 8
Training loss: 3.04095721244812
Validation loss: 2.587037694069647

Epoch: 5| Step: 9
Training loss: 2.34727144241333
Validation loss: 2.582856716648225

Epoch: 5| Step: 10
Training loss: 2.7588932514190674
Validation loss: 2.587897459665934

Epoch: 74| Step: 0
Training loss: 3.424121379852295
Validation loss: 2.589688565141411

Epoch: 5| Step: 1
Training loss: 2.801476001739502
Validation loss: 2.597228980833484

Epoch: 5| Step: 2
Training loss: 2.7563846111297607
Validation loss: 2.605012855222148

Epoch: 5| Step: 3
Training loss: 2.5076823234558105
Validation loss: 2.6076174551440823

Epoch: 5| Step: 4
Training loss: 2.570953369140625
Validation loss: 2.616875094752158

Epoch: 5| Step: 5
Training loss: 1.8700969219207764
Validation loss: 2.602399964486399

Epoch: 5| Step: 6
Training loss: 3.80712890625
Validation loss: 2.5966417097276255

Epoch: 5| Step: 7
Training loss: 3.9750137329101562
Validation loss: 2.588516958298222

Epoch: 5| Step: 8
Training loss: 2.552013874053955
Validation loss: 2.581917311555596

Epoch: 5| Step: 9
Training loss: 2.057730197906494
Validation loss: 2.5829567370876187

Epoch: 5| Step: 10
Training loss: 2.043952226638794
Validation loss: 2.579789538537302

Epoch: 75| Step: 0
Training loss: 2.906914710998535
Validation loss: 2.5812915884038454

Epoch: 5| Step: 1
Training loss: 3.2465572357177734
Validation loss: 2.5869470668095413

Epoch: 5| Step: 2
Training loss: 3.2458038330078125
Validation loss: 2.5859295757867957

Epoch: 5| Step: 3
Training loss: 2.6756532192230225
Validation loss: 2.5778968898198937

Epoch: 5| Step: 4
Training loss: 2.753847122192383
Validation loss: 2.5781786980167514

Epoch: 5| Step: 5
Training loss: 2.599574089050293
Validation loss: 2.5758524299949728

Epoch: 5| Step: 6
Training loss: 2.032635450363159
Validation loss: 2.578454836722343

Epoch: 5| Step: 7
Training loss: 2.7593207359313965
Validation loss: 2.580319030310518

Epoch: 5| Step: 8
Training loss: 2.390533208847046
Validation loss: 2.5820771263491724

Epoch: 5| Step: 9
Training loss: 2.6702520847320557
Validation loss: 2.577251083107405

Epoch: 5| Step: 10
Training loss: 3.1265339851379395
Validation loss: 2.5804974468805457

Epoch: 76| Step: 0
Training loss: 2.3752026557922363
Validation loss: 2.5743029348311888

Epoch: 5| Step: 1
Training loss: 2.9645111560821533
Validation loss: 2.579087793186147

Epoch: 5| Step: 2
Training loss: 1.7925821542739868
Validation loss: 2.578871601371355

Epoch: 5| Step: 3
Training loss: 2.574079990386963
Validation loss: 2.5793667583055395

Epoch: 5| Step: 4
Training loss: 2.7409415245056152
Validation loss: 2.5821578976928548

Epoch: 5| Step: 5
Training loss: 3.171901226043701
Validation loss: 2.5793157239114084

Epoch: 5| Step: 6
Training loss: 3.1926376819610596
Validation loss: 2.5865225868840374

Epoch: 5| Step: 7
Training loss: 2.704519748687744
Validation loss: 2.5844304894888275

Epoch: 5| Step: 8
Training loss: 2.6905932426452637
Validation loss: 2.59035994673288

Epoch: 5| Step: 9
Training loss: 2.8616251945495605
Validation loss: 2.596215522417458

Epoch: 5| Step: 10
Training loss: 3.1455814838409424
Validation loss: 2.5916658473271195

Epoch: 77| Step: 0
Training loss: 2.4292285442352295
Validation loss: 2.5882720793447187

Epoch: 5| Step: 1
Training loss: 2.71547269821167
Validation loss: 2.5779610526177192

Epoch: 5| Step: 2
Training loss: 2.2118022441864014
Validation loss: 2.5782470331397107

Epoch: 5| Step: 3
Training loss: 2.727999210357666
Validation loss: 2.583039017133815

Epoch: 5| Step: 4
Training loss: 2.1790201663970947
Validation loss: 2.586936753283265

Epoch: 5| Step: 5
Training loss: 2.5700113773345947
Validation loss: 2.5685742721762708

Epoch: 5| Step: 6
Training loss: 3.562453508377075
Validation loss: 2.5640559427199827

Epoch: 5| Step: 7
Training loss: 3.4826035499572754
Validation loss: 2.5663513060539

Epoch: 5| Step: 8
Training loss: 2.276801109313965
Validation loss: 2.5663745890381517

Epoch: 5| Step: 9
Training loss: 2.9567856788635254
Validation loss: 2.5698602404645694

Epoch: 5| Step: 10
Training loss: 3.101797103881836
Validation loss: 2.5727113857064197

Epoch: 78| Step: 0
Training loss: 3.150024890899658
Validation loss: 2.57615856201418

Epoch: 5| Step: 1
Training loss: 2.7476704120635986
Validation loss: 2.573693278015301

Epoch: 5| Step: 2
Training loss: 2.838332414627075
Validation loss: 2.573033712243521

Epoch: 5| Step: 3
Training loss: 3.1089882850646973
Validation loss: 2.573092440123199

Epoch: 5| Step: 4
Training loss: 1.964657187461853
Validation loss: 2.5729331944578435

Epoch: 5| Step: 5
Training loss: 2.6226508617401123
Validation loss: 2.5682280396902435

Epoch: 5| Step: 6
Training loss: 3.0506880283355713
Validation loss: 2.569998554004136

Epoch: 5| Step: 7
Training loss: 2.8200278282165527
Validation loss: 2.5633363339208786

Epoch: 5| Step: 8
Training loss: 2.4530491828918457
Validation loss: 2.563847000880908

Epoch: 5| Step: 9
Training loss: 2.6156044006347656
Validation loss: 2.559789570428992

Epoch: 5| Step: 10
Training loss: 2.8224740028381348
Validation loss: 2.5600228207085722

Epoch: 79| Step: 0
Training loss: 2.871922731399536
Validation loss: 2.5640808689978813

Epoch: 5| Step: 1
Training loss: 2.093627452850342
Validation loss: 2.565030495325724

Epoch: 5| Step: 2
Training loss: 3.042978286743164
Validation loss: 2.574985296495499

Epoch: 5| Step: 3
Training loss: 2.874136447906494
Validation loss: 2.5802124443874566

Epoch: 5| Step: 4
Training loss: 2.7731289863586426
Validation loss: 2.574396038568148

Epoch: 5| Step: 5
Training loss: 2.3794808387756348
Validation loss: 2.573332166159025

Epoch: 5| Step: 6
Training loss: 2.505521774291992
Validation loss: 2.5689111781376663

Epoch: 5| Step: 7
Training loss: 2.9087564945220947
Validation loss: 2.5629506828964397

Epoch: 5| Step: 8
Training loss: 2.8827102184295654
Validation loss: 2.5649538937435357

Epoch: 5| Step: 9
Training loss: 2.8594720363616943
Validation loss: 2.581632544917445

Epoch: 5| Step: 10
Training loss: 2.9406304359436035
Validation loss: 2.5722679553493375

Epoch: 80| Step: 0
Training loss: 2.5926547050476074
Validation loss: 2.5791832990543817

Epoch: 5| Step: 1
Training loss: 2.8624625205993652
Validation loss: 2.5688856135132494

Epoch: 5| Step: 2
Training loss: 2.7682945728302
Validation loss: 2.5655651861621487

Epoch: 5| Step: 3
Training loss: 2.401620388031006
Validation loss: 2.5610120386205693

Epoch: 5| Step: 4
Training loss: 2.6953094005584717
Validation loss: 2.55869899770265

Epoch: 5| Step: 5
Training loss: 2.834521770477295
Validation loss: 2.5529156218292894

Epoch: 5| Step: 6
Training loss: 2.948032855987549
Validation loss: 2.5567644975518666

Epoch: 5| Step: 7
Training loss: 3.348005771636963
Validation loss: 2.555486827768305

Epoch: 5| Step: 8
Training loss: 2.140658378601074
Validation loss: 2.557950322346021

Epoch: 5| Step: 9
Training loss: 3.348156690597534
Validation loss: 2.5570553323274017

Epoch: 5| Step: 10
Training loss: 2.0214033126831055
Validation loss: 2.5536325490602882

Epoch: 81| Step: 0
Training loss: 2.781642198562622
Validation loss: 2.5614986650405394

Epoch: 5| Step: 1
Training loss: 2.563171863555908
Validation loss: 2.5588215345977456

Epoch: 5| Step: 2
Training loss: 3.0374772548675537
Validation loss: 2.5569965352294264

Epoch: 5| Step: 3
Training loss: 2.5073769092559814
Validation loss: 2.5517744223276773

Epoch: 5| Step: 4
Training loss: 2.683422088623047
Validation loss: 2.5553508932872484

Epoch: 5| Step: 5
Training loss: 2.7172441482543945
Validation loss: 2.549973234053581

Epoch: 5| Step: 6
Training loss: 2.8152670860290527
Validation loss: 2.5541852776722243

Epoch: 5| Step: 7
Training loss: 2.550882339477539
Validation loss: 2.5475774862432994

Epoch: 5| Step: 8
Training loss: 2.6844494342803955
Validation loss: 2.55149144511069

Epoch: 5| Step: 9
Training loss: 2.9212193489074707
Validation loss: 2.5510188379595355

Epoch: 5| Step: 10
Training loss: 2.768651247024536
Validation loss: 2.54580254964931

Epoch: 82| Step: 0
Training loss: 2.4873313903808594
Validation loss: 2.5439788551740747

Epoch: 5| Step: 1
Training loss: 2.9848437309265137
Validation loss: 2.5470193791133102

Epoch: 5| Step: 2
Training loss: 2.6165223121643066
Validation loss: 2.549919755228104

Epoch: 5| Step: 3
Training loss: 2.095383644104004
Validation loss: 2.555580564724502

Epoch: 5| Step: 4
Training loss: 3.269552707672119
Validation loss: 2.5602085410907702

Epoch: 5| Step: 5
Training loss: 2.4061758518218994
Validation loss: 2.5860036470556773

Epoch: 5| Step: 6
Training loss: 3.4624505043029785
Validation loss: 2.578277982691283

Epoch: 5| Step: 7
Training loss: 3.2442798614501953
Validation loss: 2.5757154854395057

Epoch: 5| Step: 8
Training loss: 2.2014949321746826
Validation loss: 2.5626651651115826

Epoch: 5| Step: 9
Training loss: 2.513350009918213
Validation loss: 2.559144109807989

Epoch: 5| Step: 10
Training loss: 2.781156539916992
Validation loss: 2.549187849926692

Epoch: 83| Step: 0
Training loss: 2.420027494430542
Validation loss: 2.546397929550499

Epoch: 5| Step: 1
Training loss: 3.0869314670562744
Validation loss: 2.543990760721186

Epoch: 5| Step: 2
Training loss: 2.7220261096954346
Validation loss: 2.546023823881662

Epoch: 5| Step: 3
Training loss: 2.8908658027648926
Validation loss: 2.5478654420504006

Epoch: 5| Step: 4
Training loss: 2.986949920654297
Validation loss: 2.549363746437975

Epoch: 5| Step: 5
Training loss: 2.8619208335876465
Validation loss: 2.5481124231892247

Epoch: 5| Step: 6
Training loss: 2.489300489425659
Validation loss: 2.54478185279395

Epoch: 5| Step: 7
Training loss: 2.1881468296051025
Validation loss: 2.5430153159685034

Epoch: 5| Step: 8
Training loss: 3.1670918464660645
Validation loss: 2.545148200886224

Epoch: 5| Step: 9
Training loss: 2.167742967605591
Validation loss: 2.544563272947906

Epoch: 5| Step: 10
Training loss: 3.139801263809204
Validation loss: 2.5498204436353458

Epoch: 84| Step: 0
Training loss: 2.9683785438537598
Validation loss: 2.547061650983749

Epoch: 5| Step: 1
Training loss: 2.5858211517333984
Validation loss: 2.546668311601044

Epoch: 5| Step: 2
Training loss: 1.9635813236236572
Validation loss: 2.5586837440408687

Epoch: 5| Step: 3
Training loss: 3.0300583839416504
Validation loss: 2.554197067855507

Epoch: 5| Step: 4
Training loss: 2.7606823444366455
Validation loss: 2.5508825240596646

Epoch: 5| Step: 5
Training loss: 2.305600166320801
Validation loss: 2.5463834193445023

Epoch: 5| Step: 6
Training loss: 2.886350631713867
Validation loss: 2.546357816265475

Epoch: 5| Step: 7
Training loss: 3.146317958831787
Validation loss: 2.5502494073683217

Epoch: 5| Step: 8
Training loss: 2.51519775390625
Validation loss: 2.538662507969846

Epoch: 5| Step: 9
Training loss: 2.8039021492004395
Validation loss: 2.5350186183888423

Epoch: 5| Step: 10
Training loss: 3.0110015869140625
Validation loss: 2.5342627186929025

Epoch: 85| Step: 0
Training loss: 2.0730316638946533
Validation loss: 2.541038992584393

Epoch: 5| Step: 1
Training loss: 1.955481767654419
Validation loss: 2.544754010374828

Epoch: 5| Step: 2
Training loss: 2.9292826652526855
Validation loss: 2.5457336812890987

Epoch: 5| Step: 3
Training loss: 3.0212368965148926
Validation loss: 2.55252270801093

Epoch: 5| Step: 4
Training loss: 2.737577199935913
Validation loss: 2.545201752775459

Epoch: 5| Step: 5
Training loss: 2.8473286628723145
Validation loss: 2.5402697311934603

Epoch: 5| Step: 6
Training loss: 2.4390926361083984
Validation loss: 2.533713984233077

Epoch: 5| Step: 7
Training loss: 2.339393377304077
Validation loss: 2.533701437775807

Epoch: 5| Step: 8
Training loss: 2.914794445037842
Validation loss: 2.5397745524683306

Epoch: 5| Step: 9
Training loss: 3.8940329551696777
Validation loss: 2.5446939212019726

Epoch: 5| Step: 10
Training loss: 2.9293007850646973
Validation loss: 2.5478842207180556

Epoch: 86| Step: 0
Training loss: 2.9434356689453125
Validation loss: 2.5370252414416243

Epoch: 5| Step: 1
Training loss: 2.391197681427002
Validation loss: 2.5323457589713474

Epoch: 5| Step: 2
Training loss: 2.9547624588012695
Validation loss: 2.5354730903461413

Epoch: 5| Step: 3
Training loss: 2.802835464477539
Validation loss: 2.5328556914483347

Epoch: 5| Step: 4
Training loss: 3.1176586151123047
Validation loss: 2.53856340787744

Epoch: 5| Step: 5
Training loss: 3.6535820960998535
Validation loss: 2.538383137795233

Epoch: 5| Step: 6
Training loss: 2.5052969455718994
Validation loss: 2.544878649455245

Epoch: 5| Step: 7
Training loss: 2.0250144004821777
Validation loss: 2.5460323133776264

Epoch: 5| Step: 8
Training loss: 3.26344633102417
Validation loss: 2.559748952106763

Epoch: 5| Step: 9
Training loss: 1.6462571620941162
Validation loss: 2.546863007289107

Epoch: 5| Step: 10
Training loss: 2.6553995609283447
Validation loss: 2.5351241455283215

Epoch: 87| Step: 0
Training loss: 2.38519024848938
Validation loss: 2.529245004859022

Epoch: 5| Step: 1
Training loss: 3.174166202545166
Validation loss: 2.526839207577449

Epoch: 5| Step: 2
Training loss: 3.3709685802459717
Validation loss: 2.5290158846045054

Epoch: 5| Step: 3
Training loss: 3.1363251209259033
Validation loss: 2.5265066264778056

Epoch: 5| Step: 4
Training loss: 2.7177653312683105
Validation loss: 2.52819469154522

Epoch: 5| Step: 5
Training loss: 2.261472702026367
Validation loss: 2.5288997850110455

Epoch: 5| Step: 6
Training loss: 2.0556812286376953
Validation loss: 2.527910893963229

Epoch: 5| Step: 7
Training loss: 2.5052173137664795
Validation loss: 2.527078092739146

Epoch: 5| Step: 8
Training loss: 2.8114676475524902
Validation loss: 2.5293100264764603

Epoch: 5| Step: 9
Training loss: 3.04579758644104
Validation loss: 2.5347672277881252

Epoch: 5| Step: 10
Training loss: 2.3810245990753174
Validation loss: 2.5305709018502185

Epoch: 88| Step: 0
Training loss: 2.5569260120391846
Validation loss: 2.5357531668037496

Epoch: 5| Step: 1
Training loss: 2.3726048469543457
Validation loss: 2.5346672073487313

Epoch: 5| Step: 2
Training loss: 2.0833985805511475
Validation loss: 2.547739933895808

Epoch: 5| Step: 3
Training loss: 2.9756932258605957
Validation loss: 2.5499377122489353

Epoch: 5| Step: 4
Training loss: 2.9064462184906006
Validation loss: 2.5441269259299

Epoch: 5| Step: 5
Training loss: 2.531609058380127
Validation loss: 2.5501193820789294

Epoch: 5| Step: 6
Training loss: 3.362727642059326
Validation loss: 2.553891446000786

Epoch: 5| Step: 7
Training loss: 2.7764892578125
Validation loss: 2.5498839168138403

Epoch: 5| Step: 8
Training loss: 2.8638765811920166
Validation loss: 2.535944607950026

Epoch: 5| Step: 9
Training loss: 2.6161255836486816
Validation loss: 2.5259693514916206

Epoch: 5| Step: 10
Training loss: 2.851644992828369
Validation loss: 2.5257087574210217

Epoch: 89| Step: 0
Training loss: 3.389752149581909
Validation loss: 2.5256055760127243

Epoch: 5| Step: 1
Training loss: 2.6220734119415283
Validation loss: 2.5226282868334042

Epoch: 5| Step: 2
Training loss: 2.6592249870300293
Validation loss: 2.5263749912220943

Epoch: 5| Step: 3
Training loss: 3.28912615776062
Validation loss: 2.5258985206645024

Epoch: 5| Step: 4
Training loss: 2.3041892051696777
Validation loss: 2.5253410467537503

Epoch: 5| Step: 5
Training loss: 2.250535249710083
Validation loss: 2.5239512946016047

Epoch: 5| Step: 6
Training loss: 2.7273383140563965
Validation loss: 2.5235458881624284

Epoch: 5| Step: 7
Training loss: 2.398427724838257
Validation loss: 2.5261102927628385

Epoch: 5| Step: 8
Training loss: 3.288520336151123
Validation loss: 2.528424644982943

Epoch: 5| Step: 9
Training loss: 2.1886239051818848
Validation loss: 2.5232755394392115

Epoch: 5| Step: 10
Training loss: 2.7441725730895996
Validation loss: 2.5219176225764777

Epoch: 90| Step: 0
Training loss: 2.220444679260254
Validation loss: 2.519921500195739

Epoch: 5| Step: 1
Training loss: 2.9456939697265625
Validation loss: 2.523166218111592

Epoch: 5| Step: 2
Training loss: 2.267652750015259
Validation loss: 2.525338290840067

Epoch: 5| Step: 3
Training loss: 2.9745521545410156
Validation loss: 2.5357044781408002

Epoch: 5| Step: 4
Training loss: 2.842470645904541
Validation loss: 2.532601418033723

Epoch: 5| Step: 5
Training loss: 3.204918384552002
Validation loss: 2.536074715275918

Epoch: 5| Step: 6
Training loss: 2.254500389099121
Validation loss: 2.541395254032586

Epoch: 5| Step: 7
Training loss: 2.20329213142395
Validation loss: 2.5349944304394465

Epoch: 5| Step: 8
Training loss: 2.6663455963134766
Validation loss: 2.5303774738824494

Epoch: 5| Step: 9
Training loss: 2.711296319961548
Validation loss: 2.5289223040303876

Epoch: 5| Step: 10
Training loss: 3.610534191131592
Validation loss: 2.5221398774013726

Epoch: 91| Step: 0
Training loss: 2.6633427143096924
Validation loss: 2.5232306834190124

Epoch: 5| Step: 1
Training loss: 3.1358327865600586
Validation loss: 2.520551335427069

Epoch: 5| Step: 2
Training loss: 2.9256412982940674
Validation loss: 2.524735648144958

Epoch: 5| Step: 3
Training loss: 2.3884761333465576
Validation loss: 2.5181791679833525

Epoch: 5| Step: 4
Training loss: 2.1528892517089844
Validation loss: 2.5201729395056285

Epoch: 5| Step: 5
Training loss: 2.7613251209259033
Validation loss: 2.5211422084480204

Epoch: 5| Step: 6
Training loss: 2.9395911693573
Validation loss: 2.521070549564977

Epoch: 5| Step: 7
Training loss: 3.383448839187622
Validation loss: 2.5283155492556992

Epoch: 5| Step: 8
Training loss: 2.5260820388793945
Validation loss: 2.521442731221517

Epoch: 5| Step: 9
Training loss: 2.778618335723877
Validation loss: 2.5226227737242177

Epoch: 5| Step: 10
Training loss: 2.0023326873779297
Validation loss: 2.522412556473927

Epoch: 92| Step: 0
Training loss: 2.841808795928955
Validation loss: 2.5219227780577955

Epoch: 5| Step: 1
Training loss: 2.3719871044158936
Validation loss: 2.5194974099436114

Epoch: 5| Step: 2
Training loss: 2.2042107582092285
Validation loss: 2.521351086196079

Epoch: 5| Step: 3
Training loss: 2.476698398590088
Validation loss: 2.5282444671917985

Epoch: 5| Step: 4
Training loss: 3.132781505584717
Validation loss: 2.5233453653192006

Epoch: 5| Step: 5
Training loss: 2.909318208694458
Validation loss: 2.517942874662338

Epoch: 5| Step: 6
Training loss: 2.911590337753296
Validation loss: 2.5154268331425165

Epoch: 5| Step: 7
Training loss: 2.6014137268066406
Validation loss: 2.5144942473339778

Epoch: 5| Step: 8
Training loss: 2.7904775142669678
Validation loss: 2.5192091054813837

Epoch: 5| Step: 9
Training loss: 2.756702184677124
Validation loss: 2.5117745399475098

Epoch: 5| Step: 10
Training loss: 2.7076358795166016
Validation loss: 2.5092835785240255

Epoch: 93| Step: 0
Training loss: 2.676065683364868
Validation loss: 2.504655968758368

Epoch: 5| Step: 1
Training loss: 2.9784748554229736
Validation loss: 2.5028974471553678

Epoch: 5| Step: 2
Training loss: 2.201547384262085
Validation loss: 2.5039408437667356

Epoch: 5| Step: 3
Training loss: 2.8291192054748535
Validation loss: 2.502659320831299

Epoch: 5| Step: 4
Training loss: 2.4118049144744873
Validation loss: 2.5013174574862242

Epoch: 5| Step: 5
Training loss: 2.547739028930664
Validation loss: 2.505385406555668

Epoch: 5| Step: 6
Training loss: 2.7407283782958984
Validation loss: 2.507466553359903

Epoch: 5| Step: 7
Training loss: 2.8278870582580566
Validation loss: 2.5221510676927466

Epoch: 5| Step: 8
Training loss: 2.779261350631714
Validation loss: 2.5239086740760395

Epoch: 5| Step: 9
Training loss: 2.585806369781494
Validation loss: 2.5301787237967215

Epoch: 5| Step: 10
Training loss: 3.2038304805755615
Validation loss: 2.5311296703994914

Epoch: 94| Step: 0
Training loss: 2.647460460662842
Validation loss: 2.5132301853549097

Epoch: 5| Step: 1
Training loss: 2.357534885406494
Validation loss: 2.5129632437100975

Epoch: 5| Step: 2
Training loss: 3.620452404022217
Validation loss: 2.5040341961768364

Epoch: 5| Step: 3
Training loss: 2.538477659225464
Validation loss: 2.5005117949619087

Epoch: 5| Step: 4
Training loss: 3.047917366027832
Validation loss: 2.4962505243157826

Epoch: 5| Step: 5
Training loss: 2.579052448272705
Validation loss: 2.4998250161447833

Epoch: 5| Step: 6
Training loss: 2.652054786682129
Validation loss: 2.4996287720177763

Epoch: 5| Step: 7
Training loss: 1.8877636194229126
Validation loss: 2.49929609862707

Epoch: 5| Step: 8
Training loss: 3.001088857650757
Validation loss: 2.498650259869073

Epoch: 5| Step: 9
Training loss: 2.334156036376953
Validation loss: 2.5009957026409846

Epoch: 5| Step: 10
Training loss: 3.042262315750122
Validation loss: 2.5044873683683333

Epoch: 95| Step: 0
Training loss: 3.431971788406372
Validation loss: 2.4979435679733113

Epoch: 5| Step: 1
Training loss: 2.9690539836883545
Validation loss: 2.507069021142939

Epoch: 5| Step: 2
Training loss: 3.175264596939087
Validation loss: 2.507315256262338

Epoch: 5| Step: 3
Training loss: 1.8291622400283813
Validation loss: 2.504863090412591

Epoch: 5| Step: 4
Training loss: 1.8857771158218384
Validation loss: 2.5110226856764926

Epoch: 5| Step: 5
Training loss: 1.6845614910125732
Validation loss: 2.523409338407619

Epoch: 5| Step: 6
Training loss: 3.2317569255828857
Validation loss: 2.5248863671415593

Epoch: 5| Step: 7
Training loss: 2.465874671936035
Validation loss: 2.5167400939490205

Epoch: 5| Step: 8
Training loss: 3.459207057952881
Validation loss: 2.5180440000308457

Epoch: 5| Step: 9
Training loss: 2.5111565589904785
Validation loss: 2.507245761091991

Epoch: 5| Step: 10
Training loss: 3.029663324356079
Validation loss: 2.505809248134654

Epoch: 96| Step: 0
Training loss: 3.0486533641815186
Validation loss: 2.4994104626358196

Epoch: 5| Step: 1
Training loss: 1.8385320901870728
Validation loss: 2.4934597553745395

Epoch: 5| Step: 2
Training loss: 2.837714195251465
Validation loss: 2.491299657411473

Epoch: 5| Step: 3
Training loss: 2.6634140014648438
Validation loss: 2.499694760127734

Epoch: 5| Step: 4
Training loss: 2.866917133331299
Validation loss: 2.490782568531652

Epoch: 5| Step: 5
Training loss: 2.7188727855682373
Validation loss: 2.496059997107393

Epoch: 5| Step: 6
Training loss: 2.067645788192749
Validation loss: 2.501232449726392

Epoch: 5| Step: 7
Training loss: 2.7061195373535156
Validation loss: 2.501379471953197

Epoch: 5| Step: 8
Training loss: 2.5781047344207764
Validation loss: 2.4962227011239655

Epoch: 5| Step: 9
Training loss: 3.502452850341797
Validation loss: 2.4983025840533677

Epoch: 5| Step: 10
Training loss: 2.7725419998168945
Validation loss: 2.50711214926935

Epoch: 97| Step: 0
Training loss: 2.202991485595703
Validation loss: 2.512888108530352

Epoch: 5| Step: 1
Training loss: 2.4456984996795654
Validation loss: 2.523147354843796

Epoch: 5| Step: 2
Training loss: 3.1615169048309326
Validation loss: 2.5121336342186056

Epoch: 5| Step: 3
Training loss: 2.6811866760253906
Validation loss: 2.4947852652559996

Epoch: 5| Step: 4
Training loss: 3.681807279586792
Validation loss: 2.485717237636607

Epoch: 5| Step: 5
Training loss: 2.825528383255005
Validation loss: 2.485433716927805

Epoch: 5| Step: 6
Training loss: 2.681633472442627
Validation loss: 2.4863039396142446

Epoch: 5| Step: 7
Training loss: 2.3537955284118652
Validation loss: 2.484045254286899

Epoch: 5| Step: 8
Training loss: 2.2305004596710205
Validation loss: 2.492355695334814

Epoch: 5| Step: 9
Training loss: 2.8516077995300293
Validation loss: 2.4974226925962713

Epoch: 5| Step: 10
Training loss: 2.5005414485931396
Validation loss: 2.5073789345320834

Epoch: 98| Step: 0
Training loss: 2.281489133834839
Validation loss: 2.508732271450822

Epoch: 5| Step: 1
Training loss: 2.598850965499878
Validation loss: 2.5132330694506244

Epoch: 5| Step: 2
Training loss: 2.128751754760742
Validation loss: 2.51265025138855

Epoch: 5| Step: 3
Training loss: 2.4771032333374023
Validation loss: 2.5100438312817643

Epoch: 5| Step: 4
Training loss: 2.9679036140441895
Validation loss: 2.4978176188725296

Epoch: 5| Step: 5
Training loss: 2.737978458404541
Validation loss: 2.485442997306906

Epoch: 5| Step: 6
Training loss: 2.3356688022613525
Validation loss: 2.482968391910676

Epoch: 5| Step: 7
Training loss: 3.456847667694092
Validation loss: 2.482899242831815

Epoch: 5| Step: 8
Training loss: 3.213322401046753
Validation loss: 2.4919399087147047

Epoch: 5| Step: 9
Training loss: 2.4699411392211914
Validation loss: 2.490945504557702

Epoch: 5| Step: 10
Training loss: 2.9429235458374023
Validation loss: 2.49685562041498

Epoch: 99| Step: 0
Training loss: 2.711441993713379
Validation loss: 2.505877617866762

Epoch: 5| Step: 1
Training loss: 2.762207508087158
Validation loss: 2.495935029880975

Epoch: 5| Step: 2
Training loss: 2.0129122734069824
Validation loss: 2.49387296553581

Epoch: 5| Step: 3
Training loss: 1.9047777652740479
Validation loss: 2.485531578781784

Epoch: 5| Step: 4
Training loss: 2.7296879291534424
Validation loss: 2.4880363889919814

Epoch: 5| Step: 5
Training loss: 3.0476253032684326
Validation loss: 2.4881514041654524

Epoch: 5| Step: 6
Training loss: 2.7602059841156006
Validation loss: 2.4984278409711775

Epoch: 5| Step: 7
Training loss: 3.043764114379883
Validation loss: 2.503270379958614

Epoch: 5| Step: 8
Training loss: 2.6002092361450195
Validation loss: 2.5123796745013167

Epoch: 5| Step: 9
Training loss: 2.9439401626586914
Validation loss: 2.5204569139788227

Epoch: 5| Step: 10
Training loss: 3.227287769317627
Validation loss: 2.5203102737344723

Epoch: 100| Step: 0
Training loss: 3.3314170837402344
Validation loss: 2.5101160028929352

Epoch: 5| Step: 1
Training loss: 2.73148775100708
Validation loss: 2.497903388033631

Epoch: 5| Step: 2
Training loss: 3.057344675064087
Validation loss: 2.487124058508104

Epoch: 5| Step: 3
Training loss: 3.2483367919921875
Validation loss: 2.4850981056049304

Epoch: 5| Step: 4
Training loss: 2.5722479820251465
Validation loss: 2.4793503489545596

Epoch: 5| Step: 5
Training loss: 2.018270492553711
Validation loss: 2.480837934760637

Epoch: 5| Step: 6
Training loss: 2.8769278526306152
Validation loss: 2.4865390382787234

Epoch: 5| Step: 7
Training loss: 3.14573073387146
Validation loss: 2.4861329268383723

Epoch: 5| Step: 8
Training loss: 1.8852002620697021
Validation loss: 2.4893780575003674

Epoch: 5| Step: 9
Training loss: 2.109583616256714
Validation loss: 2.4978897751018567

Epoch: 5| Step: 10
Training loss: 2.5942890644073486
Validation loss: 2.503335711776569

Epoch: 101| Step: 0
Training loss: 2.364619493484497
Validation loss: 2.502901120852399

Epoch: 5| Step: 1
Training loss: 2.7774577140808105
Validation loss: 2.4939796950227473

Epoch: 5| Step: 2
Training loss: 3.1723523139953613
Validation loss: 2.4832331006244948

Epoch: 5| Step: 3
Training loss: 3.0225768089294434
Validation loss: 2.480884341783421

Epoch: 5| Step: 4
Training loss: 2.587158679962158
Validation loss: 2.47885545351172

Epoch: 5| Step: 5
Training loss: 3.0281052589416504
Validation loss: 2.4818399977940384

Epoch: 5| Step: 6
Training loss: 2.746279716491699
Validation loss: 2.4794773722207673

Epoch: 5| Step: 7
Training loss: 2.2632765769958496
Validation loss: 2.4753448783710437

Epoch: 5| Step: 8
Training loss: 2.6952152252197266
Validation loss: 2.4772239731204126

Epoch: 5| Step: 9
Training loss: 1.9553191661834717
Validation loss: 2.476439386285761

Epoch: 5| Step: 10
Training loss: 2.8892126083374023
Validation loss: 2.473921578417542

Epoch: 102| Step: 0
Training loss: 3.2462680339813232
Validation loss: 2.4815601636004705

Epoch: 5| Step: 1
Training loss: 2.783173084259033
Validation loss: 2.4832168958520375

Epoch: 5| Step: 2
Training loss: 2.9614033699035645
Validation loss: 2.488747037867064

Epoch: 5| Step: 3
Training loss: 2.5692942142486572
Validation loss: 2.4907513305705082

Epoch: 5| Step: 4
Training loss: 2.1973633766174316
Validation loss: 2.5048092001227924

Epoch: 5| Step: 5
Training loss: 2.674891471862793
Validation loss: 2.534354379100184

Epoch: 5| Step: 6
Training loss: 2.718636989593506
Validation loss: 2.5320073917347896

Epoch: 5| Step: 7
Training loss: 2.5090062618255615
Validation loss: 2.5168914769285466

Epoch: 5| Step: 8
Training loss: 2.7539610862731934
Validation loss: 2.4857826309819377

Epoch: 5| Step: 9
Training loss: 2.2016992568969727
Validation loss: 2.475930369028481

Epoch: 5| Step: 10
Training loss: 3.0434892177581787
Validation loss: 2.4755037497448664

Epoch: 103| Step: 0
Training loss: 2.0421953201293945
Validation loss: 2.4748737786405828

Epoch: 5| Step: 1
Training loss: 3.731656551361084
Validation loss: 2.477939910786126

Epoch: 5| Step: 2
Training loss: 2.6926586627960205
Validation loss: 2.4767966578083653

Epoch: 5| Step: 3
Training loss: 2.658285617828369
Validation loss: 2.473120520191808

Epoch: 5| Step: 4
Training loss: 2.617522716522217
Validation loss: 2.47258589601004

Epoch: 5| Step: 5
Training loss: 3.0489425659179688
Validation loss: 2.473085839261291

Epoch: 5| Step: 6
Training loss: 2.7864584922790527
Validation loss: 2.468986285630093

Epoch: 5| Step: 7
Training loss: 2.5119824409484863
Validation loss: 2.469828856888638

Epoch: 5| Step: 8
Training loss: 2.690899610519409
Validation loss: 2.4716706250303533

Epoch: 5| Step: 9
Training loss: 2.4962048530578613
Validation loss: 2.4785095491716937

Epoch: 5| Step: 10
Training loss: 2.1634106636047363
Validation loss: 2.475010830868957

Epoch: 104| Step: 0
Training loss: 3.018012523651123
Validation loss: 2.4869897493752102

Epoch: 5| Step: 1
Training loss: 2.928522825241089
Validation loss: 2.497029214776972

Epoch: 5| Step: 2
Training loss: 2.929443359375
Validation loss: 2.4955647222457396

Epoch: 5| Step: 3
Training loss: 2.4373631477355957
Validation loss: 2.5049732577416206

Epoch: 5| Step: 4
Training loss: 2.756132125854492
Validation loss: 2.5026807169760428

Epoch: 5| Step: 5
Training loss: 2.6366419792175293
Validation loss: 2.4863880885544645

Epoch: 5| Step: 6
Training loss: 2.529371976852417
Validation loss: 2.4873439419654106

Epoch: 5| Step: 7
Training loss: 2.991931915283203
Validation loss: 2.481249519573745

Epoch: 5| Step: 8
Training loss: 2.4416420459747314
Validation loss: 2.4757328315447737

Epoch: 5| Step: 9
Training loss: 2.779799222946167
Validation loss: 2.474583092556205

Epoch: 5| Step: 10
Training loss: 1.9542734622955322
Validation loss: 2.4673000638202955

Epoch: 105| Step: 0
Training loss: 2.337162733078003
Validation loss: 2.465238801894649

Epoch: 5| Step: 1
Training loss: 2.198026657104492
Validation loss: 2.4627988005197174

Epoch: 5| Step: 2
Training loss: 2.069206476211548
Validation loss: 2.4667524060895367

Epoch: 5| Step: 3
Training loss: 2.9807724952697754
Validation loss: 2.474631422309465

Epoch: 5| Step: 4
Training loss: 3.205371379852295
Validation loss: 2.491065620094217

Epoch: 5| Step: 5
Training loss: 2.640265703201294
Validation loss: 2.506560925514467

Epoch: 5| Step: 6
Training loss: 3.3875935077667236
Validation loss: 2.522260747930055

Epoch: 5| Step: 7
Training loss: 3.0241265296936035
Validation loss: 2.5783093411435365

Epoch: 5| Step: 8
Training loss: 2.9586520195007324
Validation loss: 2.5748664820066063

Epoch: 5| Step: 9
Training loss: 2.354152202606201
Validation loss: 2.520489823433661

Epoch: 5| Step: 10
Training loss: 2.490884304046631
Validation loss: 2.4731159364023516

Epoch: 106| Step: 0
Training loss: 2.1855523586273193
Validation loss: 2.4664833981503724

Epoch: 5| Step: 1
Training loss: 2.816132068634033
Validation loss: 2.463162934908303

Epoch: 5| Step: 2
Training loss: 2.991222858428955
Validation loss: 2.468950440806727

Epoch: 5| Step: 3
Training loss: 2.1151328086853027
Validation loss: 2.4726311775945846

Epoch: 5| Step: 4
Training loss: 2.5849297046661377
Validation loss: 2.480845738482732

Epoch: 5| Step: 5
Training loss: 2.6651108264923096
Validation loss: 2.4871626900088404

Epoch: 5| Step: 6
Training loss: 3.1786134243011475
Validation loss: 2.491318943679974

Epoch: 5| Step: 7
Training loss: 2.4083847999572754
Validation loss: 2.492217130558465

Epoch: 5| Step: 8
Training loss: 2.5708274841308594
Validation loss: 2.478577785594489

Epoch: 5| Step: 9
Training loss: 3.175323009490967
Validation loss: 2.4754192111312703

Epoch: 5| Step: 10
Training loss: 2.7745048999786377
Validation loss: 2.471030912091655

Epoch: 107| Step: 0
Training loss: 2.531297206878662
Validation loss: 2.466580319148238

Epoch: 5| Step: 1
Training loss: 3.370712995529175
Validation loss: 2.461457698575912

Epoch: 5| Step: 2
Training loss: 2.3081798553466797
Validation loss: 2.4594892327503493

Epoch: 5| Step: 3
Training loss: 2.4993138313293457
Validation loss: 2.460387078664636

Epoch: 5| Step: 4
Training loss: 2.673513889312744
Validation loss: 2.4698793734273603

Epoch: 5| Step: 5
Training loss: 2.7403855323791504
Validation loss: 2.470016271837296

Epoch: 5| Step: 6
Training loss: 2.5970897674560547
Validation loss: 2.464700170742568

Epoch: 5| Step: 7
Training loss: 2.619616985321045
Validation loss: 2.4610583397649948

Epoch: 5| Step: 8
Training loss: 2.7188193798065186
Validation loss: 2.4602120063638173

Epoch: 5| Step: 9
Training loss: 2.828918933868408
Validation loss: 2.4583473179929998

Epoch: 5| Step: 10
Training loss: 2.5390214920043945
Validation loss: 2.4571751138215423

Epoch: 108| Step: 0
Training loss: 2.777580499649048
Validation loss: 2.456603098941106

Epoch: 5| Step: 1
Training loss: 3.1618289947509766
Validation loss: 2.459750403640091

Epoch: 5| Step: 2
Training loss: 2.0418450832366943
Validation loss: 2.462211352522655

Epoch: 5| Step: 3
Training loss: 2.53462290763855
Validation loss: 2.463612082184002

Epoch: 5| Step: 4
Training loss: 2.6532485485076904
Validation loss: 2.479082538235572

Epoch: 5| Step: 5
Training loss: 2.9954915046691895
Validation loss: 2.477023006767355

Epoch: 5| Step: 6
Training loss: 2.0115084648132324
Validation loss: 2.4856274076687392

Epoch: 5| Step: 7
Training loss: 2.7672717571258545
Validation loss: 2.4795982658222155

Epoch: 5| Step: 8
Training loss: 2.6758854389190674
Validation loss: 2.4659374221678703

Epoch: 5| Step: 9
Training loss: 2.938781976699829
Validation loss: 2.4565195883474042

Epoch: 5| Step: 10
Training loss: 2.8761837482452393
Validation loss: 2.453898519598028

Epoch: 109| Step: 0
Training loss: 2.193171501159668
Validation loss: 2.4518638221166467

Epoch: 5| Step: 1
Training loss: 2.9725215435028076
Validation loss: 2.459825966947822

Epoch: 5| Step: 2
Training loss: 3.0276806354522705
Validation loss: 2.457607018050327

Epoch: 5| Step: 3
Training loss: 2.3227031230926514
Validation loss: 2.4695525066826933

Epoch: 5| Step: 4
Training loss: 2.974379062652588
Validation loss: 2.4697113190927813

Epoch: 5| Step: 5
Training loss: 3.1643171310424805
Validation loss: 2.4761239482510473

Epoch: 5| Step: 6
Training loss: 3.1902549266815186
Validation loss: 2.472863220399426

Epoch: 5| Step: 7
Training loss: 2.5001652240753174
Validation loss: 2.469358883878236

Epoch: 5| Step: 8
Training loss: 2.407365083694458
Validation loss: 2.4619629767633255

Epoch: 5| Step: 9
Training loss: 2.3334453105926514
Validation loss: 2.4549381989304737

Epoch: 5| Step: 10
Training loss: 2.393662691116333
Validation loss: 2.4518151462719007

Epoch: 110| Step: 0
Training loss: 3.373802900314331
Validation loss: 2.4551391255471016

Epoch: 5| Step: 1
Training loss: 2.6188294887542725
Validation loss: 2.4701080322265625

Epoch: 5| Step: 2
Training loss: 2.102626323699951
Validation loss: 2.479921833161385

Epoch: 5| Step: 3
Training loss: 2.788623809814453
Validation loss: 2.489087107361004

Epoch: 5| Step: 4
Training loss: 2.5884857177734375
Validation loss: 2.5030454615110993

Epoch: 5| Step: 5
Training loss: 3.0044636726379395
Validation loss: 2.5207788290516024

Epoch: 5| Step: 6
Training loss: 2.743255615234375
Validation loss: 2.525839841493996

Epoch: 5| Step: 7
Training loss: 2.616556406021118
Validation loss: 2.511359804420061

Epoch: 5| Step: 8
Training loss: 2.437391519546509
Validation loss: 2.513638342580488

Epoch: 5| Step: 9
Training loss: 2.6329636573791504
Validation loss: 2.4822910319092455

Epoch: 5| Step: 10
Training loss: 2.5759363174438477
Validation loss: 2.471195154292609

Epoch: 111| Step: 0
Training loss: 2.765012264251709
Validation loss: 2.4530016888854322

Epoch: 5| Step: 1
Training loss: 3.32067608833313
Validation loss: 2.446937975063119

Epoch: 5| Step: 2
Training loss: 3.33744478225708
Validation loss: 2.447656185396256

Epoch: 5| Step: 3
Training loss: 2.2696897983551025
Validation loss: 2.449104880773893

Epoch: 5| Step: 4
Training loss: 2.6559643745422363
Validation loss: 2.4504417680924937

Epoch: 5| Step: 5
Training loss: 2.98738169670105
Validation loss: 2.4498698993395736

Epoch: 5| Step: 6
Training loss: 2.836184024810791
Validation loss: 2.4463751956980717

Epoch: 5| Step: 7
Training loss: 2.580625057220459
Validation loss: 2.4409855155534643

Epoch: 5| Step: 8
Training loss: 1.958918809890747
Validation loss: 2.441455169390607

Epoch: 5| Step: 9
Training loss: 2.0048725605010986
Validation loss: 2.4461526588727067

Epoch: 5| Step: 10
Training loss: 2.672287702560425
Validation loss: 2.441956086825299

Epoch: 112| Step: 0
Training loss: 1.8679157495498657
Validation loss: 2.4422065673335904

Epoch: 5| Step: 1
Training loss: 2.233154535293579
Validation loss: 2.439042119569676

Epoch: 5| Step: 2
Training loss: 2.7120091915130615
Validation loss: 2.44060686326796

Epoch: 5| Step: 3
Training loss: 2.689507246017456
Validation loss: 2.4401082531098397

Epoch: 5| Step: 4
Training loss: 2.624886989593506
Validation loss: 2.4432722624912055

Epoch: 5| Step: 5
Training loss: 2.7824859619140625
Validation loss: 2.4542425781167965

Epoch: 5| Step: 6
Training loss: 2.847398519515991
Validation loss: 2.4694831345670964

Epoch: 5| Step: 7
Training loss: 2.6871609687805176
Validation loss: 2.475784663231142

Epoch: 5| Step: 8
Training loss: 2.553760051727295
Validation loss: 2.485984668936781

Epoch: 5| Step: 9
Training loss: 3.354522705078125
Validation loss: 2.484258520987726

Epoch: 5| Step: 10
Training loss: 3.064364194869995
Validation loss: 2.4685049774826213

Epoch: 113| Step: 0
Training loss: 2.8173489570617676
Validation loss: 2.4507988883603002

Epoch: 5| Step: 1
Training loss: 2.8461174964904785
Validation loss: 2.4492286892347437

Epoch: 5| Step: 2
Training loss: 2.7209246158599854
Validation loss: 2.4424613086126183

Epoch: 5| Step: 3
Training loss: 3.0088114738464355
Validation loss: 2.4353450088090796

Epoch: 5| Step: 4
Training loss: 2.2466723918914795
Validation loss: 2.440451204135854

Epoch: 5| Step: 5
Training loss: 1.9462894201278687
Validation loss: 2.4428380689313336

Epoch: 5| Step: 6
Training loss: 2.8600900173187256
Validation loss: 2.4451077215133177

Epoch: 5| Step: 7
Training loss: 2.5566985607147217
Validation loss: 2.4467998114965295

Epoch: 5| Step: 8
Training loss: 2.820431709289551
Validation loss: 2.449215191666798

Epoch: 5| Step: 9
Training loss: 3.3884806632995605
Validation loss: 2.4471794610382407

Epoch: 5| Step: 10
Training loss: 2.0145630836486816
Validation loss: 2.442111074283559

Epoch: 114| Step: 0
Training loss: 2.4967079162597656
Validation loss: 2.4454144662426365

Epoch: 5| Step: 1
Training loss: 2.641746997833252
Validation loss: 2.4442969009440434

Epoch: 5| Step: 2
Training loss: 2.648343563079834
Validation loss: 2.448255970913877

Epoch: 5| Step: 3
Training loss: 2.6618263721466064
Validation loss: 2.454047672210201

Epoch: 5| Step: 4
Training loss: 2.2016615867614746
Validation loss: 2.451956802798856

Epoch: 5| Step: 5
Training loss: 3.124356746673584
Validation loss: 2.454978863398234

Epoch: 5| Step: 6
Training loss: 2.370140552520752
Validation loss: 2.4533633544880855

Epoch: 5| Step: 7
Training loss: 2.5742945671081543
Validation loss: 2.4577616696716635

Epoch: 5| Step: 8
Training loss: 3.096344232559204
Validation loss: 2.4524574305421565

Epoch: 5| Step: 9
Training loss: 2.4135379791259766
Validation loss: 2.451456895438574

Epoch: 5| Step: 10
Training loss: 3.066682815551758
Validation loss: 2.4369113445281982

Epoch: 115| Step: 0
Training loss: 1.9320380687713623
Validation loss: 2.4324315517179427

Epoch: 5| Step: 1
Training loss: 2.2441563606262207
Validation loss: 2.435463325951689

Epoch: 5| Step: 2
Training loss: 2.5205447673797607
Validation loss: 2.4386122765079623

Epoch: 5| Step: 3
Training loss: 2.426851987838745
Validation loss: 2.4353611212904736

Epoch: 5| Step: 4
Training loss: 3.4576332569122314
Validation loss: 2.436958802643643

Epoch: 5| Step: 5
Training loss: 2.889713764190674
Validation loss: 2.431212704668763

Epoch: 5| Step: 6
Training loss: 2.674452543258667
Validation loss: 2.4367891665427917

Epoch: 5| Step: 7
Training loss: 3.149078369140625
Validation loss: 2.431085814711868

Epoch: 5| Step: 8
Training loss: 2.560274839401245
Validation loss: 2.4290047717350784

Epoch: 5| Step: 9
Training loss: 3.009979724884033
Validation loss: 2.4310685306467037

Epoch: 5| Step: 10
Training loss: 2.3003294467926025
Validation loss: 2.442922111480467

Epoch: 116| Step: 0
Training loss: 2.8009254932403564
Validation loss: 2.442478746496221

Epoch: 5| Step: 1
Training loss: 2.24527645111084
Validation loss: 2.454502219794899

Epoch: 5| Step: 2
Training loss: 2.532060384750366
Validation loss: 2.461584855151433

Epoch: 5| Step: 3
Training loss: 3.3072304725646973
Validation loss: 2.465974853884789

Epoch: 5| Step: 4
Training loss: 2.658202648162842
Validation loss: 2.4760575807222756

Epoch: 5| Step: 5
Training loss: 2.6465277671813965
Validation loss: 2.4689345564893497

Epoch: 5| Step: 6
Training loss: 2.8816189765930176
Validation loss: 2.455174543524301

Epoch: 5| Step: 7
Training loss: 2.6479923725128174
Validation loss: 2.4500032368526665

Epoch: 5| Step: 8
Training loss: 2.3133761882781982
Validation loss: 2.443225837522937

Epoch: 5| Step: 9
Training loss: 2.610588312149048
Validation loss: 2.4325988600330968

Epoch: 5| Step: 10
Training loss: 2.5670979022979736
Validation loss: 2.433269267441124

Epoch: 117| Step: 0
Training loss: 2.7290101051330566
Validation loss: 2.433702817527197

Epoch: 5| Step: 1
Training loss: 2.583991289138794
Validation loss: 2.43395838814397

Epoch: 5| Step: 2
Training loss: 2.5211703777313232
Validation loss: 2.4380703664595083

Epoch: 5| Step: 3
Training loss: 2.5631613731384277
Validation loss: 2.436871087679299

Epoch: 5| Step: 4
Training loss: 2.953977584838867
Validation loss: 2.4355782334522535

Epoch: 5| Step: 5
Training loss: 2.9728448390960693
Validation loss: 2.4313237282537643

Epoch: 5| Step: 6
Training loss: 2.6796772480010986
Validation loss: 2.4263193017692974

Epoch: 5| Step: 7
Training loss: 2.9807441234588623
Validation loss: 2.433877939819008

Epoch: 5| Step: 8
Training loss: 2.367276906967163
Validation loss: 2.444740823520127

Epoch: 5| Step: 9
Training loss: 2.916642665863037
Validation loss: 2.452754195018481

Epoch: 5| Step: 10
Training loss: 1.797674536705017
Validation loss: 2.453892110496439

Epoch: 118| Step: 0
Training loss: 2.4161808490753174
Validation loss: 2.468158698851062

Epoch: 5| Step: 1
Training loss: 2.8179118633270264
Validation loss: 2.5007930609487716

Epoch: 5| Step: 2
Training loss: 2.3924052715301514
Validation loss: 2.5093211666230233

Epoch: 5| Step: 3
Training loss: 2.5825629234313965
Validation loss: 2.520052430450275

Epoch: 5| Step: 4
Training loss: 2.671112537384033
Validation loss: 2.5343394151297947

Epoch: 5| Step: 5
Training loss: 2.9238243103027344
Validation loss: 2.5075997793546287

Epoch: 5| Step: 6
Training loss: 2.953906536102295
Validation loss: 2.460417729552074

Epoch: 5| Step: 7
Training loss: 1.638546347618103
Validation loss: 2.427601768124488

Epoch: 5| Step: 8
Training loss: 2.4875917434692383
Validation loss: 2.4201886833354993

Epoch: 5| Step: 9
Training loss: 3.670388698577881
Validation loss: 2.426516191933745

Epoch: 5| Step: 10
Training loss: 2.773756980895996
Validation loss: 2.446770876966497

Epoch: 119| Step: 0
Training loss: 3.087210178375244
Validation loss: 2.457107474727015

Epoch: 5| Step: 1
Training loss: 2.5885190963745117
Validation loss: 2.471100950753817

Epoch: 5| Step: 2
Training loss: 2.6392016410827637
Validation loss: 2.4818118900381108

Epoch: 5| Step: 3
Training loss: 2.7718334197998047
Validation loss: 2.469086954670568

Epoch: 5| Step: 4
Training loss: 3.053015947341919
Validation loss: 2.4635960440481863

Epoch: 5| Step: 5
Training loss: 2.8527607917785645
Validation loss: 2.4569350391305904

Epoch: 5| Step: 6
Training loss: 2.6282944679260254
Validation loss: 2.451022717260545

Epoch: 5| Step: 7
Training loss: 3.0980451107025146
Validation loss: 2.4433936278025308

Epoch: 5| Step: 8
Training loss: 2.6373226642608643
Validation loss: 2.4380664876712266

Epoch: 5| Step: 9
Training loss: 2.2236831188201904
Validation loss: 2.4273034321364535

Epoch: 5| Step: 10
Training loss: 1.8569035530090332
Validation loss: 2.423828422382314

Epoch: 120| Step: 0
Training loss: 3.0113048553466797
Validation loss: 2.4379781856331775

Epoch: 5| Step: 1
Training loss: 1.959577202796936
Validation loss: 2.434143340715798

Epoch: 5| Step: 2
Training loss: 2.087009906768799
Validation loss: 2.4569541664533716

Epoch: 5| Step: 3
Training loss: 2.918159008026123
Validation loss: 2.4618745875614945

Epoch: 5| Step: 4
Training loss: 3.19555401802063
Validation loss: 2.464269071496943

Epoch: 5| Step: 5
Training loss: 2.521395206451416
Validation loss: 2.4643257279549875

Epoch: 5| Step: 6
Training loss: 2.721780776977539
Validation loss: 2.4500209413548952

Epoch: 5| Step: 7
Training loss: 2.840578556060791
Validation loss: 2.434034780789447

Epoch: 5| Step: 8
Training loss: 2.1613402366638184
Validation loss: 2.416306777666974

Epoch: 5| Step: 9
Training loss: 3.4873974323272705
Validation loss: 2.4195508854363554

Epoch: 5| Step: 10
Training loss: 2.3520960807800293
Validation loss: 2.4250366585229033

Epoch: 121| Step: 0
Training loss: 2.4698288440704346
Validation loss: 2.4289191076832433

Epoch: 5| Step: 1
Training loss: 2.4428646564483643
Validation loss: 2.4330341123765513

Epoch: 5| Step: 2
Training loss: 2.5060083866119385
Validation loss: 2.4329477894690728

Epoch: 5| Step: 3
Training loss: 3.271097183227539
Validation loss: 2.4349203237923245

Epoch: 5| Step: 4
Training loss: 2.992565870285034
Validation loss: 2.434988301287415

Epoch: 5| Step: 5
Training loss: 2.5810117721557617
Validation loss: 2.431856547632525

Epoch: 5| Step: 6
Training loss: 3.012773036956787
Validation loss: 2.425147202707106

Epoch: 5| Step: 7
Training loss: 2.36014986038208
Validation loss: 2.423749159741145

Epoch: 5| Step: 8
Training loss: 2.7050137519836426
Validation loss: 2.4257246063601587

Epoch: 5| Step: 9
Training loss: 2.6482932567596436
Validation loss: 2.423974516571209

Epoch: 5| Step: 10
Training loss: 2.3044328689575195
Validation loss: 2.4228001794507428

Epoch: 122| Step: 0
Training loss: 2.490025758743286
Validation loss: 2.420185855639878

Epoch: 5| Step: 1
Training loss: 3.0421595573425293
Validation loss: 2.4186375038598174

Epoch: 5| Step: 2
Training loss: 2.541430950164795
Validation loss: 2.4159881068814184

Epoch: 5| Step: 3
Training loss: 2.842505693435669
Validation loss: 2.4142702305188743

Epoch: 5| Step: 4
Training loss: 2.8124277591705322
Validation loss: 2.4157415051614084

Epoch: 5| Step: 5
Training loss: 3.051346778869629
Validation loss: 2.4162916573145057

Epoch: 5| Step: 6
Training loss: 2.1434638500213623
Validation loss: 2.420097763820361

Epoch: 5| Step: 7
Training loss: 2.671154499053955
Validation loss: 2.420137943760041

Epoch: 5| Step: 8
Training loss: 1.697076439857483
Validation loss: 2.420183366344821

Epoch: 5| Step: 9
Training loss: 2.602752208709717
Validation loss: 2.4229234546743412

Epoch: 5| Step: 10
Training loss: 3.325221538543701
Validation loss: 2.4240661231420373

Epoch: 123| Step: 0
Training loss: 2.179309129714966
Validation loss: 2.4294238090515137

Epoch: 5| Step: 1
Training loss: 2.874950408935547
Validation loss: 2.4283837092820035

Epoch: 5| Step: 2
Training loss: 3.229753017425537
Validation loss: 2.4341533209687922

Epoch: 5| Step: 3
Training loss: 2.7742562294006348
Validation loss: 2.440860907236735

Epoch: 5| Step: 4
Training loss: 2.5331203937530518
Validation loss: 2.446909030278524

Epoch: 5| Step: 5
Training loss: 2.235962390899658
Validation loss: 2.4625365426463466

Epoch: 5| Step: 6
Training loss: 3.0922136306762695
Validation loss: 2.459010249824934

Epoch: 5| Step: 7
Training loss: 2.862175464630127
Validation loss: 2.4694802632895847

Epoch: 5| Step: 8
Training loss: 2.407999277114868
Validation loss: 2.462613110901207

Epoch: 5| Step: 9
Training loss: 2.661362886428833
Validation loss: 2.4664361707625853

Epoch: 5| Step: 10
Training loss: 2.2582950592041016
Validation loss: 2.4824246693682928

Epoch: 124| Step: 0
Training loss: 2.262031078338623
Validation loss: 2.487675923173146

Epoch: 5| Step: 1
Training loss: 2.52398943901062
Validation loss: 2.493737172054988

Epoch: 5| Step: 2
Training loss: 3.007101535797119
Validation loss: 2.5104875205665507

Epoch: 5| Step: 3
Training loss: 2.960724353790283
Validation loss: 2.502427380572083

Epoch: 5| Step: 4
Training loss: 2.535628080368042
Validation loss: 2.4892844999990156

Epoch: 5| Step: 5
Training loss: 2.3658599853515625
Validation loss: 2.4785753270631194

Epoch: 5| Step: 6
Training loss: 2.5833206176757812
Validation loss: 2.4750786699274534

Epoch: 5| Step: 7
Training loss: 3.114028215408325
Validation loss: 2.467296829787634

Epoch: 5| Step: 8
Training loss: 3.1380977630615234
Validation loss: 2.4570130584060506

Epoch: 5| Step: 9
Training loss: 2.9102559089660645
Validation loss: 2.4582104964922835

Epoch: 5| Step: 10
Training loss: 1.9558998346328735
Validation loss: 2.4555816086389686

Epoch: 125| Step: 0
Training loss: 2.6108574867248535
Validation loss: 2.4512944042041735

Epoch: 5| Step: 1
Training loss: 2.929487705230713
Validation loss: 2.449781994665823

Epoch: 5| Step: 2
Training loss: 3.2591030597686768
Validation loss: 2.447940872561547

Epoch: 5| Step: 3
Training loss: 2.413301944732666
Validation loss: 2.444198654543969

Epoch: 5| Step: 4
Training loss: 3.011352062225342
Validation loss: 2.4456037347034743

Epoch: 5| Step: 5
Training loss: 2.8142945766448975
Validation loss: 2.439510678732267

Epoch: 5| Step: 6
Training loss: 2.220855474472046
Validation loss: 2.436883852046023

Epoch: 5| Step: 7
Training loss: 2.6214394569396973
Validation loss: 2.4361462823806272

Epoch: 5| Step: 8
Training loss: 2.083512306213379
Validation loss: 2.442181561582832

Epoch: 5| Step: 9
Training loss: 2.177929401397705
Validation loss: 2.4393959494047266

Epoch: 5| Step: 10
Training loss: 3.131469249725342
Validation loss: 2.432380609614875

Epoch: 126| Step: 0
Training loss: 3.2619259357452393
Validation loss: 2.433397440500157

Epoch: 5| Step: 1
Training loss: 2.705871105194092
Validation loss: 2.4328505992889404

Epoch: 5| Step: 2
Training loss: 2.7529377937316895
Validation loss: 2.428703938761065

Epoch: 5| Step: 3
Training loss: 2.883587598800659
Validation loss: 2.429747214881323

Epoch: 5| Step: 4
Training loss: 2.1965389251708984
Validation loss: 2.416242225195772

Epoch: 5| Step: 5
Training loss: 2.3986620903015137
Validation loss: 2.412265408423639

Epoch: 5| Step: 6
Training loss: 2.475846767425537
Validation loss: 2.414004856540311

Epoch: 5| Step: 7
Training loss: 2.543154001235962
Validation loss: 2.4112074323879775

Epoch: 5| Step: 8
Training loss: 2.6675467491149902
Validation loss: 2.40628118412469

Epoch: 5| Step: 9
Training loss: 3.2905426025390625
Validation loss: 2.4089969511955016

Epoch: 5| Step: 10
Training loss: 1.7405431270599365
Validation loss: 2.400747419685446

Epoch: 127| Step: 0
Training loss: 2.525641679763794
Validation loss: 2.403049974031346

Epoch: 5| Step: 1
Training loss: 2.927224636077881
Validation loss: 2.3993752976899505

Epoch: 5| Step: 2
Training loss: 3.195563554763794
Validation loss: 2.4011375570809967

Epoch: 5| Step: 3
Training loss: 2.6908798217773438
Validation loss: 2.4022289424814205

Epoch: 5| Step: 4
Training loss: 2.6194188594818115
Validation loss: 2.4068756154788438

Epoch: 5| Step: 5
Training loss: 2.7712321281433105
Validation loss: 2.41279709980052

Epoch: 5| Step: 6
Training loss: 2.5214314460754395
Validation loss: 2.420856903958064

Epoch: 5| Step: 7
Training loss: 2.023789644241333
Validation loss: 2.424188539546023

Epoch: 5| Step: 8
Training loss: 2.114260196685791
Validation loss: 2.447126675677556

Epoch: 5| Step: 9
Training loss: 2.969388961791992
Validation loss: 2.439396640305878

Epoch: 5| Step: 10
Training loss: 2.6759469509124756
Validation loss: 2.4298146463209584

Epoch: 128| Step: 0
Training loss: 2.2875614166259766
Validation loss: 2.424126978843443

Epoch: 5| Step: 1
Training loss: 3.395678997039795
Validation loss: 2.400873881514354

Epoch: 5| Step: 2
Training loss: 3.1481411457061768
Validation loss: 2.402327924646357

Epoch: 5| Step: 3
Training loss: 2.5518829822540283
Validation loss: 2.397980205474361

Epoch: 5| Step: 4
Training loss: 2.181688070297241
Validation loss: 2.402714252471924

Epoch: 5| Step: 5
Training loss: 2.158897876739502
Validation loss: 2.402877261561732

Epoch: 5| Step: 6
Training loss: 2.9173812866210938
Validation loss: 2.4057895637327626

Epoch: 5| Step: 7
Training loss: 2.307096481323242
Validation loss: 2.404565022837731

Epoch: 5| Step: 8
Training loss: 2.494837760925293
Validation loss: 2.4140147265567573

Epoch: 5| Step: 9
Training loss: 2.8246400356292725
Validation loss: 2.4171694735045075

Epoch: 5| Step: 10
Training loss: 2.703270196914673
Validation loss: 2.415503586492231

Epoch: 129| Step: 0
Training loss: 1.8945434093475342
Validation loss: 2.4179011903783327

Epoch: 5| Step: 1
Training loss: 3.380948543548584
Validation loss: 2.420205085508285

Epoch: 5| Step: 2
Training loss: 2.0166373252868652
Validation loss: 2.4178580622519217

Epoch: 5| Step: 3
Training loss: 2.7388672828674316
Validation loss: 2.414367639890281

Epoch: 5| Step: 4
Training loss: 2.8380465507507324
Validation loss: 2.4102514174676712

Epoch: 5| Step: 5
Training loss: 2.6982975006103516
Validation loss: 2.411269437882208

Epoch: 5| Step: 6
Training loss: 2.292938232421875
Validation loss: 2.3975970616904636

Epoch: 5| Step: 7
Training loss: 2.8499679565429688
Validation loss: 2.3978952489873415

Epoch: 5| Step: 8
Training loss: 2.0909180641174316
Validation loss: 2.3947784157209497

Epoch: 5| Step: 9
Training loss: 3.2410457134246826
Validation loss: 2.393335942299135

Epoch: 5| Step: 10
Training loss: 2.897174596786499
Validation loss: 2.403134407535676

Epoch: 130| Step: 0
Training loss: 3.3392062187194824
Validation loss: 2.4136653869382796

Epoch: 5| Step: 1
Training loss: 2.2908854484558105
Validation loss: 2.4116583024301836

Epoch: 5| Step: 2
Training loss: 2.183412551879883
Validation loss: 2.425000654753818

Epoch: 5| Step: 3
Training loss: 2.2278969287872314
Validation loss: 2.4350516616657214

Epoch: 5| Step: 4
Training loss: 3.5755207538604736
Validation loss: 2.4451457556857856

Epoch: 5| Step: 5
Training loss: 2.8609156608581543
Validation loss: 2.439207664100073

Epoch: 5| Step: 6
Training loss: 2.7820606231689453
Validation loss: 2.4260953985234743

Epoch: 5| Step: 7
Training loss: 2.293334484100342
Validation loss: 2.409856868046586

Epoch: 5| Step: 8
Training loss: 2.4119949340820312
Validation loss: 2.398555117268716

Epoch: 5| Step: 9
Training loss: 2.6336092948913574
Validation loss: 2.398859335530189

Epoch: 5| Step: 10
Training loss: 2.421321392059326
Validation loss: 2.397379177872853

Epoch: 131| Step: 0
Training loss: 2.914685010910034
Validation loss: 2.3914265478810957

Epoch: 5| Step: 1
Training loss: 2.5591444969177246
Validation loss: 2.3906356724359656

Epoch: 5| Step: 2
Training loss: 2.413722276687622
Validation loss: 2.390763303285004

Epoch: 5| Step: 3
Training loss: 3.0500078201293945
Validation loss: 2.388778181486232

Epoch: 5| Step: 4
Training loss: 2.5943398475646973
Validation loss: 2.3953124400108092

Epoch: 5| Step: 5
Training loss: 2.3894028663635254
Validation loss: 2.3940798749205885

Epoch: 5| Step: 6
Training loss: 3.2133355140686035
Validation loss: 2.3912541815029678

Epoch: 5| Step: 7
Training loss: 2.232985019683838
Validation loss: 2.3945010374951106

Epoch: 5| Step: 8
Training loss: 1.9763762950897217
Validation loss: 2.3906753217020342

Epoch: 5| Step: 9
Training loss: 2.8363406658172607
Validation loss: 2.3934303073472876

Epoch: 5| Step: 10
Training loss: 2.7085788249969482
Validation loss: 2.391102393468221

Epoch: 132| Step: 0
Training loss: 3.4752488136291504
Validation loss: 2.3923619383124897

Epoch: 5| Step: 1
Training loss: 2.538846254348755
Validation loss: 2.395877117751747

Epoch: 5| Step: 2
Training loss: 2.307889938354492
Validation loss: 2.3936949288973244

Epoch: 5| Step: 3
Training loss: 2.9741313457489014
Validation loss: 2.392762391797958

Epoch: 5| Step: 4
Training loss: 2.436702013015747
Validation loss: 2.38824422513285

Epoch: 5| Step: 5
Training loss: 2.824246406555176
Validation loss: 2.3850008569737917

Epoch: 5| Step: 6
Training loss: 3.203352451324463
Validation loss: 2.392611495910152

Epoch: 5| Step: 7
Training loss: 3.1341331005096436
Validation loss: 2.4058190443182506

Epoch: 5| Step: 8
Training loss: 1.7635282278060913
Validation loss: 2.4187392265565935

Epoch: 5| Step: 9
Training loss: 2.0062062740325928
Validation loss: 2.4304110568056823

Epoch: 5| Step: 10
Training loss: 2.149343729019165
Validation loss: 2.4468189208738265

Epoch: 133| Step: 0
Training loss: 2.474334239959717
Validation loss: 2.464078623761413

Epoch: 5| Step: 1
Training loss: 3.1063668727874756
Validation loss: 2.4680047419763382

Epoch: 5| Step: 2
Training loss: 1.9040968418121338
Validation loss: 2.464487386006181

Epoch: 5| Step: 3
Training loss: 3.2908413410186768
Validation loss: 2.456077298810405

Epoch: 5| Step: 4
Training loss: 2.8832952976226807
Validation loss: 2.4448272028276996

Epoch: 5| Step: 5
Training loss: 2.434767484664917
Validation loss: 2.4166572863055813

Epoch: 5| Step: 6
Training loss: 1.7906376123428345
Validation loss: 2.4042383201660646

Epoch: 5| Step: 7
Training loss: 2.3624768257141113
Validation loss: 2.396717876516363

Epoch: 5| Step: 8
Training loss: 3.1904311180114746
Validation loss: 2.391037566687471

Epoch: 5| Step: 9
Training loss: 3.087343692779541
Validation loss: 2.386546734840639

Epoch: 5| Step: 10
Training loss: 2.531165838241577
Validation loss: 2.3856618430024836

Epoch: 134| Step: 0
Training loss: 2.508263111114502
Validation loss: 2.3911283041841243

Epoch: 5| Step: 1
Training loss: 3.3022499084472656
Validation loss: 2.3838814484175814

Epoch: 5| Step: 2
Training loss: 3.084867477416992
Validation loss: 2.3882790124544533

Epoch: 5| Step: 3
Training loss: 2.4617698192596436
Validation loss: 2.392976951855485

Epoch: 5| Step: 4
Training loss: 2.277571439743042
Validation loss: 2.3917764002277004

Epoch: 5| Step: 5
Training loss: 2.9162869453430176
Validation loss: 2.396010560374106

Epoch: 5| Step: 6
Training loss: 2.3366222381591797
Validation loss: 2.4040838697905182

Epoch: 5| Step: 7
Training loss: 2.081045150756836
Validation loss: 2.41327807980199

Epoch: 5| Step: 8
Training loss: 3.2163538932800293
Validation loss: 2.419449838258887

Epoch: 5| Step: 9
Training loss: 2.315427303314209
Validation loss: 2.424515829291395

Epoch: 5| Step: 10
Training loss: 2.399946928024292
Validation loss: 2.4219873182235228

Epoch: 135| Step: 0
Training loss: 2.8628056049346924
Validation loss: 2.4217337895465154

Epoch: 5| Step: 1
Training loss: 2.380298614501953
Validation loss: 2.423721226312781

Epoch: 5| Step: 2
Training loss: 2.6838274002075195
Validation loss: 2.41973985907852

Epoch: 5| Step: 3
Training loss: 2.2532241344451904
Validation loss: 2.4166570530142835

Epoch: 5| Step: 4
Training loss: 2.2611899375915527
Validation loss: 2.4109804937916417

Epoch: 5| Step: 5
Training loss: 2.6140964031219482
Validation loss: 2.4129711991997174

Epoch: 5| Step: 6
Training loss: 3.0095646381378174
Validation loss: 2.405111574357556

Epoch: 5| Step: 7
Training loss: 3.3420796394348145
Validation loss: 2.40060099991419

Epoch: 5| Step: 8
Training loss: 1.9497524499893188
Validation loss: 2.394479126058599

Epoch: 5| Step: 9
Training loss: 2.498539447784424
Validation loss: 2.387602965037028

Epoch: 5| Step: 10
Training loss: 3.0545976161956787
Validation loss: 2.3932581178603636

Epoch: 136| Step: 0
Training loss: 2.1977100372314453
Validation loss: 2.3833489007847284

Epoch: 5| Step: 1
Training loss: 2.66400146484375
Validation loss: 2.389953844008907

Epoch: 5| Step: 2
Training loss: 2.8797779083251953
Validation loss: 2.386695720816171

Epoch: 5| Step: 3
Training loss: 2.882326126098633
Validation loss: 2.3834437042154293

Epoch: 5| Step: 4
Training loss: 2.4659981727600098
Validation loss: 2.3809351203262166

Epoch: 5| Step: 5
Training loss: 2.779470920562744
Validation loss: 2.3840506307540403

Epoch: 5| Step: 6
Training loss: 2.728896141052246
Validation loss: 2.385565327059838

Epoch: 5| Step: 7
Training loss: 1.8936268091201782
Validation loss: 2.3824137308264293

Epoch: 5| Step: 8
Training loss: 2.8149495124816895
Validation loss: 2.386913812288674

Epoch: 5| Step: 9
Training loss: 2.6454575061798096
Validation loss: 2.3866593504464753

Epoch: 5| Step: 10
Training loss: 2.9205873012542725
Validation loss: 2.3895600175344818

Epoch: 137| Step: 0
Training loss: 2.6135220527648926
Validation loss: 2.3882429676671184

Epoch: 5| Step: 1
Training loss: 3.297126293182373
Validation loss: 2.3960296723150436

Epoch: 5| Step: 2
Training loss: 2.6050076484680176
Validation loss: 2.3945859529638804

Epoch: 5| Step: 3
Training loss: 3.2042593955993652
Validation loss: 2.389995333968952

Epoch: 5| Step: 4
Training loss: 2.4247355461120605
Validation loss: 2.397074035418931

Epoch: 5| Step: 5
Training loss: 2.5509188175201416
Validation loss: 2.4024056670486287

Epoch: 5| Step: 6
Training loss: 1.982459306716919
Validation loss: 2.405973131938647

Epoch: 5| Step: 7
Training loss: 2.326139450073242
Validation loss: 2.415836400883172

Epoch: 5| Step: 8
Training loss: 2.377546787261963
Validation loss: 2.4106051896208074

Epoch: 5| Step: 9
Training loss: 2.6179354190826416
Validation loss: 2.414915697548979

Epoch: 5| Step: 10
Training loss: 2.8501951694488525
Validation loss: 2.4154248699065177

Epoch: 138| Step: 0
Training loss: 3.4329826831817627
Validation loss: 2.411869946346488

Epoch: 5| Step: 1
Training loss: 2.6835646629333496
Validation loss: 2.4040838723541587

Epoch: 5| Step: 2
Training loss: 2.707831621170044
Validation loss: 2.4081961442065496

Epoch: 5| Step: 3
Training loss: 2.9852848052978516
Validation loss: 2.4003428413021948

Epoch: 5| Step: 4
Training loss: 2.3257954120635986
Validation loss: 2.405346102611993

Epoch: 5| Step: 5
Training loss: 2.2852132320404053
Validation loss: 2.4022881805255847

Epoch: 5| Step: 6
Training loss: 2.5943822860717773
Validation loss: 2.410006382132089

Epoch: 5| Step: 7
Training loss: 2.947711229324341
Validation loss: 2.394767576648343

Epoch: 5| Step: 8
Training loss: 2.379202365875244
Validation loss: 2.3842760670569634

Epoch: 5| Step: 9
Training loss: 2.1637349128723145
Validation loss: 2.381223314551897

Epoch: 5| Step: 10
Training loss: 2.231005907058716
Validation loss: 2.3886428443334435

Epoch: 139| Step: 0
Training loss: 3.204364776611328
Validation loss: 2.3889961870767737

Epoch: 5| Step: 1
Training loss: 2.503452777862549
Validation loss: 2.3905726402036604

Epoch: 5| Step: 2
Training loss: 2.70586895942688
Validation loss: 2.4148854850440897

Epoch: 5| Step: 3
Training loss: 2.5005135536193848
Validation loss: 2.410196973431495

Epoch: 5| Step: 4
Training loss: 2.3071446418762207
Validation loss: 2.4164089387462986

Epoch: 5| Step: 5
Training loss: 2.919261932373047
Validation loss: 2.4091085003268335

Epoch: 5| Step: 6
Training loss: 2.153317928314209
Validation loss: 2.408196546698129

Epoch: 5| Step: 7
Training loss: 2.9749293327331543
Validation loss: 2.4036218850843367

Epoch: 5| Step: 8
Training loss: 2.9462597370147705
Validation loss: 2.3929923580538843

Epoch: 5| Step: 9
Training loss: 2.2052340507507324
Validation loss: 2.3748515728981263

Epoch: 5| Step: 10
Training loss: 2.2824606895446777
Validation loss: 2.373296571034257

Epoch: 140| Step: 0
Training loss: 2.442408323287964
Validation loss: 2.3727263071203746

Epoch: 5| Step: 1
Training loss: 3.1450397968292236
Validation loss: 2.3722153709780787

Epoch: 5| Step: 2
Training loss: 2.7526772022247314
Validation loss: 2.375662167867025

Epoch: 5| Step: 3
Training loss: 2.4147987365722656
Validation loss: 2.3782226757336686

Epoch: 5| Step: 4
Training loss: 2.3393187522888184
Validation loss: 2.385024634740686

Epoch: 5| Step: 5
Training loss: 2.7881875038146973
Validation loss: 2.3877572423668316

Epoch: 5| Step: 6
Training loss: 2.731191873550415
Validation loss: 2.3881542400647233

Epoch: 5| Step: 7
Training loss: 2.6646900177001953
Validation loss: 2.3842243673980876

Epoch: 5| Step: 8
Training loss: 2.5843729972839355
Validation loss: 2.388863202064268

Epoch: 5| Step: 9
Training loss: 2.2480599880218506
Validation loss: 2.382719583408807

Epoch: 5| Step: 10
Training loss: 2.562016248703003
Validation loss: 2.3784730408781316

Epoch: 141| Step: 0
Training loss: 2.868962049484253
Validation loss: 2.376799216834448

Epoch: 5| Step: 1
Training loss: 2.1183741092681885
Validation loss: 2.3773457850179365

Epoch: 5| Step: 2
Training loss: 3.1077888011932373
Validation loss: 2.3821260313833914

Epoch: 5| Step: 3
Training loss: 2.9859230518341064
Validation loss: 2.382599594772503

Epoch: 5| Step: 4
Training loss: 2.7158498764038086
Validation loss: 2.38874827918186

Epoch: 5| Step: 5
Training loss: 2.8855106830596924
Validation loss: 2.387528224657941

Epoch: 5| Step: 6
Training loss: 2.320169687271118
Validation loss: 2.3917813711268927

Epoch: 5| Step: 7
Training loss: 2.056086778640747
Validation loss: 2.3941660337550665

Epoch: 5| Step: 8
Training loss: 1.8910291194915771
Validation loss: 2.3869078569514777

Epoch: 5| Step: 9
Training loss: 2.8468735218048096
Validation loss: 2.3837242895557034

Epoch: 5| Step: 10
Training loss: 2.925349235534668
Validation loss: 2.385110032173895

Epoch: 142| Step: 0
Training loss: 2.3117494583129883
Validation loss: 2.3797642415569675

Epoch: 5| Step: 1
Training loss: 3.2409253120422363
Validation loss: 2.38194626890203

Epoch: 5| Step: 2
Training loss: 2.397566080093384
Validation loss: 2.383544388637748

Epoch: 5| Step: 3
Training loss: 2.1470589637756348
Validation loss: 2.3815020694527576

Epoch: 5| Step: 4
Training loss: 2.2819979190826416
Validation loss: 2.389532078978836

Epoch: 5| Step: 5
Training loss: 2.2848360538482666
Validation loss: 2.385406688977313

Epoch: 5| Step: 6
Training loss: 3.1114470958709717
Validation loss: 2.385574416447711

Epoch: 5| Step: 7
Training loss: 2.4720523357391357
Validation loss: 2.3825497499076267

Epoch: 5| Step: 8
Training loss: 2.9627184867858887
Validation loss: 2.3782177125253985

Epoch: 5| Step: 9
Training loss: 2.690304756164551
Validation loss: 2.3887336254119873

Epoch: 5| Step: 10
Training loss: 2.7811241149902344
Validation loss: 2.40108758659773

Epoch: 143| Step: 0
Training loss: 3.0773353576660156
Validation loss: 2.4141317670063307

Epoch: 5| Step: 1
Training loss: 2.9827420711517334
Validation loss: 2.431615721794867

Epoch: 5| Step: 2
Training loss: 2.056492328643799
Validation loss: 2.446729688234227

Epoch: 5| Step: 3
Training loss: 2.537785053253174
Validation loss: 2.455750908902896

Epoch: 5| Step: 4
Training loss: 2.9530138969421387
Validation loss: 2.4615465825603855

Epoch: 5| Step: 5
Training loss: 2.4459991455078125
Validation loss: 2.4661818832479496

Epoch: 5| Step: 6
Training loss: 2.767272472381592
Validation loss: 2.4510919586304696

Epoch: 5| Step: 7
Training loss: 2.664231538772583
Validation loss: 2.437617850560014

Epoch: 5| Step: 8
Training loss: 2.5522408485412598
Validation loss: 2.4311355724129626

Epoch: 5| Step: 9
Training loss: 2.324272394180298
Validation loss: 2.4087211393540904

Epoch: 5| Step: 10
Training loss: 2.5710020065307617
Validation loss: 2.395140988852388

Epoch: 144| Step: 0
Training loss: 2.8091037273406982
Validation loss: 2.3858638476299983

Epoch: 5| Step: 1
Training loss: 2.127713680267334
Validation loss: 2.3835022603311846

Epoch: 5| Step: 2
Training loss: 2.8255863189697266
Validation loss: 2.3968120954369985

Epoch: 5| Step: 3
Training loss: 2.567723035812378
Validation loss: 2.414260551493655

Epoch: 5| Step: 4
Training loss: 2.8837363719940186
Validation loss: 2.416847426404235

Epoch: 5| Step: 5
Training loss: 2.3042385578155518
Validation loss: 2.40688387040169

Epoch: 5| Step: 6
Training loss: 3.210765838623047
Validation loss: 2.4002972674626175

Epoch: 5| Step: 7
Training loss: 2.5554568767547607
Validation loss: 2.386092637174873

Epoch: 5| Step: 8
Training loss: 2.4053189754486084
Validation loss: 2.3796985110928937

Epoch: 5| Step: 9
Training loss: 2.54717755317688
Validation loss: 2.3773908615112305

Epoch: 5| Step: 10
Training loss: 2.755235433578491
Validation loss: 2.3724091873374036

Epoch: 145| Step: 0
Training loss: 2.4237067699432373
Validation loss: 2.3765729934938493

Epoch: 5| Step: 1
Training loss: 2.727787494659424
Validation loss: 2.390938630668066

Epoch: 5| Step: 2
Training loss: 2.8745665550231934
Validation loss: 2.4044125926110054

Epoch: 5| Step: 3
Training loss: 2.6581976413726807
Validation loss: 2.3955855267022246

Epoch: 5| Step: 4
Training loss: 2.4256625175476074
Validation loss: 2.4123983024269022

Epoch: 5| Step: 5
Training loss: 3.025172233581543
Validation loss: 2.403878834939772

Epoch: 5| Step: 6
Training loss: 2.822025775909424
Validation loss: 2.4095956202476256

Epoch: 5| Step: 7
Training loss: 2.427799940109253
Validation loss: 2.415361117291194

Epoch: 5| Step: 8
Training loss: 2.206418991088867
Validation loss: 2.394488473092356

Epoch: 5| Step: 9
Training loss: 2.929705858230591
Validation loss: 2.384543611157325

Epoch: 5| Step: 10
Training loss: 2.1673743724823
Validation loss: 2.3757716968495357

Epoch: 146| Step: 0
Training loss: 3.107880115509033
Validation loss: 2.376717872517083

Epoch: 5| Step: 1
Training loss: 2.520847797393799
Validation loss: 2.3732909207702964

Epoch: 5| Step: 2
Training loss: 2.8172295093536377
Validation loss: 2.369588026436426

Epoch: 5| Step: 3
Training loss: 1.8994354009628296
Validation loss: 2.3570523787570257

Epoch: 5| Step: 4
Training loss: 2.495896816253662
Validation loss: 2.3635805909351637

Epoch: 5| Step: 5
Training loss: 2.9619991779327393
Validation loss: 2.362009045898273

Epoch: 5| Step: 6
Training loss: 2.6747078895568848
Validation loss: 2.3663105887751423

Epoch: 5| Step: 7
Training loss: 2.570413112640381
Validation loss: 2.371165103809808

Epoch: 5| Step: 8
Training loss: 2.7190330028533936
Validation loss: 2.372480788538533

Epoch: 5| Step: 9
Training loss: 2.3698112964630127
Validation loss: 2.3665677834582586

Epoch: 5| Step: 10
Training loss: 2.451667547225952
Validation loss: 2.367468862123387

Epoch: 147| Step: 0
Training loss: 2.4885356426239014
Validation loss: 2.370938624105146

Epoch: 5| Step: 1
Training loss: 2.7659525871276855
Validation loss: 2.366418033517817

Epoch: 5| Step: 2
Training loss: 3.3474040031433105
Validation loss: 2.3660195514719975

Epoch: 5| Step: 3
Training loss: 2.2700607776641846
Validation loss: 2.363176877780627

Epoch: 5| Step: 4
Training loss: 2.5456552505493164
Validation loss: 2.3635414979791127

Epoch: 5| Step: 5
Training loss: 2.9100582599639893
Validation loss: 2.3546510716920257

Epoch: 5| Step: 6
Training loss: 2.3822181224823
Validation loss: 2.3599331302027546

Epoch: 5| Step: 7
Training loss: 2.0808823108673096
Validation loss: 2.3687352288153862

Epoch: 5| Step: 8
Training loss: 2.8565011024475098
Validation loss: 2.3785906837832544

Epoch: 5| Step: 9
Training loss: 2.4818673133850098
Validation loss: 2.381466584820901

Epoch: 5| Step: 10
Training loss: 2.3602678775787354
Validation loss: 2.388060942772896

Epoch: 148| Step: 0
Training loss: 2.862056016921997
Validation loss: 2.3952802535026305

Epoch: 5| Step: 1
Training loss: 2.4742555618286133
Validation loss: 2.393238341936501

Epoch: 5| Step: 2
Training loss: 2.786158800125122
Validation loss: 2.386985391698858

Epoch: 5| Step: 3
Training loss: 2.806877851486206
Validation loss: 2.3887301055333947

Epoch: 5| Step: 4
Training loss: 2.2660908699035645
Validation loss: 2.3872537330914567

Epoch: 5| Step: 5
Training loss: 2.360812187194824
Validation loss: 2.3837027037015526

Epoch: 5| Step: 6
Training loss: 2.8132565021514893
Validation loss: 2.3820055556553665

Epoch: 5| Step: 7
Training loss: 2.4866018295288086
Validation loss: 2.3925726003544305

Epoch: 5| Step: 8
Training loss: 2.9535224437713623
Validation loss: 2.3809056153861423

Epoch: 5| Step: 9
Training loss: 2.558753252029419
Validation loss: 2.3634822009712138

Epoch: 5| Step: 10
Training loss: 1.9706634283065796
Validation loss: 2.370488302682036

Epoch: 149| Step: 0
Training loss: 2.7426207065582275
Validation loss: 2.367858232990388

Epoch: 5| Step: 1
Training loss: 1.9525798559188843
Validation loss: 2.3661384428701093

Epoch: 5| Step: 2
Training loss: 2.4863953590393066
Validation loss: 2.3696393735947145

Epoch: 5| Step: 3
Training loss: 2.323481321334839
Validation loss: 2.3842428012560775

Epoch: 5| Step: 4
Training loss: 3.2765300273895264
Validation loss: 2.3898665648634716

Epoch: 5| Step: 5
Training loss: 2.5462229251861572
Validation loss: 2.3919792688021095

Epoch: 5| Step: 6
Training loss: 2.79296875
Validation loss: 2.3819045071960776

Epoch: 5| Step: 7
Training loss: 2.2605502605438232
Validation loss: 2.368632111498105

Epoch: 5| Step: 8
Training loss: 2.283405303955078
Validation loss: 2.358474123862482

Epoch: 5| Step: 9
Training loss: 3.061295509338379
Validation loss: 2.355078499804261

Epoch: 5| Step: 10
Training loss: 2.598371982574463
Validation loss: 2.34239625418058

Epoch: 150| Step: 0
Training loss: 2.2139480113983154
Validation loss: 2.3480921509445354

Epoch: 5| Step: 1
Training loss: 2.387683868408203
Validation loss: 2.342620449681436

Epoch: 5| Step: 2
Training loss: 2.6141977310180664
Validation loss: 2.3449357299394507

Epoch: 5| Step: 3
Training loss: 1.9941209554672241
Validation loss: 2.3441704806461128

Epoch: 5| Step: 4
Training loss: 2.430251359939575
Validation loss: 2.3424758116404214

Epoch: 5| Step: 5
Training loss: 3.082913398742676
Validation loss: 2.3593768048030075

Epoch: 5| Step: 6
Training loss: 2.2531237602233887
Validation loss: 2.3803783924348894

Epoch: 5| Step: 7
Training loss: 2.909156084060669
Validation loss: 2.3883020442019225

Epoch: 5| Step: 8
Training loss: 2.9000496864318848
Validation loss: 2.3917107248819

Epoch: 5| Step: 9
Training loss: 3.3294804096221924
Validation loss: 2.387046898564985

Epoch: 5| Step: 10
Training loss: 2.4946091175079346
Validation loss: 2.381050243172594

Epoch: 151| Step: 0
Training loss: 2.7481529712677
Validation loss: 2.3692549044086086

Epoch: 5| Step: 1
Training loss: 2.3856170177459717
Validation loss: 2.3624638613834175

Epoch: 5| Step: 2
Training loss: 2.331486225128174
Validation loss: 2.3498480268703994

Epoch: 5| Step: 3
Training loss: 2.470918655395508
Validation loss: 2.342792685313891

Epoch: 5| Step: 4
Training loss: 2.5978786945343018
Validation loss: 2.3420609658764255

Epoch: 5| Step: 5
Training loss: 2.595552444458008
Validation loss: 2.3390669515055995

Epoch: 5| Step: 6
Training loss: 2.649681568145752
Validation loss: 2.3272271566493536

Epoch: 5| Step: 7
Training loss: 2.7177305221557617
Validation loss: 2.331327329399765

Epoch: 5| Step: 8
Training loss: 2.683757781982422
Validation loss: 2.3308610147045505

Epoch: 5| Step: 9
Training loss: 2.479435682296753
Validation loss: 2.3348251260736936

Epoch: 5| Step: 10
Training loss: 2.795905351638794
Validation loss: 2.3411533012185046

Epoch: 152| Step: 0
Training loss: 3.0492329597473145
Validation loss: 2.3503957820195023

Epoch: 5| Step: 1
Training loss: 2.549811601638794
Validation loss: 2.3469276633313907

Epoch: 5| Step: 2
Training loss: 2.360686779022217
Validation loss: 2.3393613317961335

Epoch: 5| Step: 3
Training loss: 2.944838762283325
Validation loss: 2.343678766681302

Epoch: 5| Step: 4
Training loss: 1.9509260654449463
Validation loss: 2.3344512293415685

Epoch: 5| Step: 5
Training loss: 2.5213961601257324
Validation loss: 2.329502272349532

Epoch: 5| Step: 6
Training loss: 2.3784544467926025
Validation loss: 2.335947286698126

Epoch: 5| Step: 7
Training loss: 3.040132761001587
Validation loss: 2.34083039786226

Epoch: 5| Step: 8
Training loss: 2.6145834922790527
Validation loss: 2.3321852645566388

Epoch: 5| Step: 9
Training loss: 2.3712430000305176
Validation loss: 2.3376748869496007

Epoch: 5| Step: 10
Training loss: 2.6057848930358887
Validation loss: 2.3280351482411867

Epoch: 153| Step: 0
Training loss: 2.0266411304473877
Validation loss: 2.3291452161727415

Epoch: 5| Step: 1
Training loss: 2.6307215690612793
Validation loss: 2.330485831024826

Epoch: 5| Step: 2
Training loss: 2.463352918624878
Validation loss: 2.3337757561796453

Epoch: 5| Step: 3
Training loss: 2.9462475776672363
Validation loss: 2.329081248211604

Epoch: 5| Step: 4
Training loss: 3.0521984100341797
Validation loss: 2.3450300334602274

Epoch: 5| Step: 5
Training loss: 2.5498311519622803
Validation loss: 2.345433060840894

Epoch: 5| Step: 6
Training loss: 2.5437474250793457
Validation loss: 2.3530203757747525

Epoch: 5| Step: 7
Training loss: 2.3858625888824463
Validation loss: 2.376242491506761

Epoch: 5| Step: 8
Training loss: 2.5763325691223145
Validation loss: 2.4092275006796724

Epoch: 5| Step: 9
Training loss: 2.526345729827881
Validation loss: 2.3834678588374967

Epoch: 5| Step: 10
Training loss: 2.626305341720581
Validation loss: 2.3654161883938696

Epoch: 154| Step: 0
Training loss: 2.922152280807495
Validation loss: 2.3566506908785914

Epoch: 5| Step: 1
Training loss: 2.3203444480895996
Validation loss: 2.359006307458365

Epoch: 5| Step: 2
Training loss: 2.3966567516326904
Validation loss: 2.349389717143069

Epoch: 5| Step: 3
Training loss: 2.3874077796936035
Validation loss: 2.3626356868333716

Epoch: 5| Step: 4
Training loss: 2.8131790161132812
Validation loss: 2.3582675713364796

Epoch: 5| Step: 5
Training loss: 2.53619647026062
Validation loss: 2.3674159331988265

Epoch: 5| Step: 6
Training loss: 2.817558765411377
Validation loss: 2.364345622319047

Epoch: 5| Step: 7
Training loss: 2.0955076217651367
Validation loss: 2.3556526143063783

Epoch: 5| Step: 8
Training loss: 2.5871593952178955
Validation loss: 2.3382527469306864

Epoch: 5| Step: 9
Training loss: 2.969789981842041
Validation loss: 2.329253068534277

Epoch: 5| Step: 10
Training loss: 2.3896849155426025
Validation loss: 2.3260954605635775

Epoch: 155| Step: 0
Training loss: 2.568105697631836
Validation loss: 2.3163319531307427

Epoch: 5| Step: 1
Training loss: 2.138237714767456
Validation loss: 2.320969545713035

Epoch: 5| Step: 2
Training loss: 3.158803939819336
Validation loss: 2.3173521846853276

Epoch: 5| Step: 3
Training loss: 2.218278169631958
Validation loss: 2.3204491881914038

Epoch: 5| Step: 4
Training loss: 2.7841715812683105
Validation loss: 2.3315081929647796

Epoch: 5| Step: 5
Training loss: 2.0800833702087402
Validation loss: 2.3331011469646166

Epoch: 5| Step: 6
Training loss: 2.9608144760131836
Validation loss: 2.34886606021594

Epoch: 5| Step: 7
Training loss: 2.8993773460388184
Validation loss: 2.3523776967038392

Epoch: 5| Step: 8
Training loss: 2.4381792545318604
Validation loss: 2.3484165335214264

Epoch: 5| Step: 9
Training loss: 2.5984978675842285
Validation loss: 2.345851521338186

Epoch: 5| Step: 10
Training loss: 2.315077781677246
Validation loss: 2.3249706158074

Epoch: 156| Step: 0
Training loss: 3.3834609985351562
Validation loss: 2.315367878124278

Epoch: 5| Step: 1
Training loss: 1.7992579936981201
Validation loss: 2.3124091740577453

Epoch: 5| Step: 2
Training loss: 2.5102453231811523
Validation loss: 2.3096053318310807

Epoch: 5| Step: 3
Training loss: 2.722111225128174
Validation loss: 2.313290524226363

Epoch: 5| Step: 4
Training loss: 1.9667507410049438
Validation loss: 2.31829313565326

Epoch: 5| Step: 5
Training loss: 2.786853075027466
Validation loss: 2.3209708300969933

Epoch: 5| Step: 6
Training loss: 2.759795904159546
Validation loss: 2.320503386118079

Epoch: 5| Step: 7
Training loss: 2.739523410797119
Validation loss: 2.345699579485001

Epoch: 5| Step: 8
Training loss: 2.8508617877960205
Validation loss: 2.3639218909766084

Epoch: 5| Step: 9
Training loss: 2.3029685020446777
Validation loss: 2.351035346267044

Epoch: 5| Step: 10
Training loss: 2.5133259296417236
Validation loss: 2.361478523541522

Epoch: 157| Step: 0
Training loss: 2.267084836959839
Validation loss: 2.3378705183664956

Epoch: 5| Step: 1
Training loss: 2.539167881011963
Validation loss: 2.3516040027782483

Epoch: 5| Step: 2
Training loss: 1.972853660583496
Validation loss: 2.3545589498294297

Epoch: 5| Step: 3
Training loss: 2.1978049278259277
Validation loss: 2.3724562403976277

Epoch: 5| Step: 4
Training loss: 2.616403341293335
Validation loss: 2.375444286613054

Epoch: 5| Step: 5
Training loss: 2.379304885864258
Validation loss: 2.38576453603724

Epoch: 5| Step: 6
Training loss: 2.4336495399475098
Validation loss: 2.376819041467482

Epoch: 5| Step: 7
Training loss: 2.641176700592041
Validation loss: 2.384634099980836

Epoch: 5| Step: 8
Training loss: 2.6639320850372314
Validation loss: 2.3848558164411977

Epoch: 5| Step: 9
Training loss: 2.80011248588562
Validation loss: 2.3706066608428955

Epoch: 5| Step: 10
Training loss: 3.878708839416504
Validation loss: 2.3521860645663355

Epoch: 158| Step: 0
Training loss: 2.1172432899475098
Validation loss: 2.3376024794834915

Epoch: 5| Step: 1
Training loss: 2.4940218925476074
Validation loss: 2.3258981320165817

Epoch: 5| Step: 2
Training loss: 3.0010788440704346
Validation loss: 2.3207590246713288

Epoch: 5| Step: 3
Training loss: 2.576286792755127
Validation loss: 2.3130295507369505

Epoch: 5| Step: 4
Training loss: 2.6786410808563232
Validation loss: 2.313955096788304

Epoch: 5| Step: 5
Training loss: 2.658090114593506
Validation loss: 2.320796617897608

Epoch: 5| Step: 6
Training loss: 3.2672035694122314
Validation loss: 2.3153303271980694

Epoch: 5| Step: 7
Training loss: 3.028571128845215
Validation loss: 2.3121136414107455

Epoch: 5| Step: 8
Training loss: 2.161442518234253
Validation loss: 2.323229907661356

Epoch: 5| Step: 9
Training loss: 1.9727901220321655
Validation loss: 2.3239877736696632

Epoch: 5| Step: 10
Training loss: 2.190272092819214
Validation loss: 2.3413679574125554

Epoch: 159| Step: 0
Training loss: 2.731179714202881
Validation loss: 2.3582807599857287

Epoch: 5| Step: 1
Training loss: 3.1236772537231445
Validation loss: 2.3611223902753604

Epoch: 5| Step: 2
Training loss: 2.92466139793396
Validation loss: 2.3709064350333264

Epoch: 5| Step: 3
Training loss: 3.292926073074341
Validation loss: 2.3614499966303506

Epoch: 5| Step: 4
Training loss: 1.5827792882919312
Validation loss: 2.3419258697058565

Epoch: 5| Step: 5
Training loss: 2.5862393379211426
Validation loss: 2.340614249629359

Epoch: 5| Step: 6
Training loss: 2.310033082962036
Validation loss: 2.334996064503988

Epoch: 5| Step: 7
Training loss: 2.146970748901367
Validation loss: 2.322317700232229

Epoch: 5| Step: 8
Training loss: 2.4849424362182617
Validation loss: 2.3258229686367895

Epoch: 5| Step: 9
Training loss: 3.112879753112793
Validation loss: 2.3202201345915436

Epoch: 5| Step: 10
Training loss: 1.769067645072937
Validation loss: 2.306647277647449

Epoch: 160| Step: 0
Training loss: 2.6618435382843018
Validation loss: 2.315210544934837

Epoch: 5| Step: 1
Training loss: 2.3030080795288086
Validation loss: 2.308145874290056

Epoch: 5| Step: 2
Training loss: 2.0129003524780273
Validation loss: 2.3226957692894885

Epoch: 5| Step: 3
Training loss: 2.550572156906128
Validation loss: 2.3359435219918527

Epoch: 5| Step: 4
Training loss: 2.801992893218994
Validation loss: 2.359706304406607

Epoch: 5| Step: 5
Training loss: 2.5443296432495117
Validation loss: 2.3552471565943893

Epoch: 5| Step: 6
Training loss: 2.1876325607299805
Validation loss: 2.35916579410594

Epoch: 5| Step: 7
Training loss: 2.6366126537323
Validation loss: 2.3327153087944112

Epoch: 5| Step: 8
Training loss: 2.7440667152404785
Validation loss: 2.3282209365598616

Epoch: 5| Step: 9
Training loss: 2.838820219039917
Validation loss: 2.3254796663920083

Epoch: 5| Step: 10
Training loss: 2.8801677227020264
Validation loss: 2.3223405602157756

Epoch: 161| Step: 0
Training loss: 3.0343222618103027
Validation loss: 2.3140828609466553

Epoch: 5| Step: 1
Training loss: 2.493776321411133
Validation loss: 2.3156175715948946

Epoch: 5| Step: 2
Training loss: 2.841358184814453
Validation loss: 2.312269961962136

Epoch: 5| Step: 3
Training loss: 2.500150203704834
Validation loss: 2.3136990865071616

Epoch: 5| Step: 4
Training loss: 1.8890511989593506
Validation loss: 2.31218784598894

Epoch: 5| Step: 5
Training loss: 2.4888148307800293
Validation loss: 2.3137343519477436

Epoch: 5| Step: 6
Training loss: 2.520822048187256
Validation loss: 2.314472060049734

Epoch: 5| Step: 7
Training loss: 2.8077778816223145
Validation loss: 2.3260880618967037

Epoch: 5| Step: 8
Training loss: 2.0736441612243652
Validation loss: 2.338677483220254

Epoch: 5| Step: 9
Training loss: 2.7784245014190674
Validation loss: 2.355344105792302

Epoch: 5| Step: 10
Training loss: 2.6599349975585938
Validation loss: 2.3481835088422223

Epoch: 162| Step: 0
Training loss: 1.79389226436615
Validation loss: 2.3555044820231776

Epoch: 5| Step: 1
Training loss: 2.8785901069641113
Validation loss: 2.345282875081544

Epoch: 5| Step: 2
Training loss: 2.138640880584717
Validation loss: 2.354047265104068

Epoch: 5| Step: 3
Training loss: 2.5857841968536377
Validation loss: 2.3472319264565744

Epoch: 5| Step: 4
Training loss: 3.1505961418151855
Validation loss: 2.3517763922291417

Epoch: 5| Step: 5
Training loss: 2.348140001296997
Validation loss: 2.3307960238508

Epoch: 5| Step: 6
Training loss: 2.4357967376708984
Validation loss: 2.3005953834902857

Epoch: 5| Step: 7
Training loss: 3.2699637413024902
Validation loss: 2.2988418353501188

Epoch: 5| Step: 8
Training loss: 2.49511456489563
Validation loss: 2.300148376854517

Epoch: 5| Step: 9
Training loss: 2.736490249633789
Validation loss: 2.3008285594242874

Epoch: 5| Step: 10
Training loss: 2.187605381011963
Validation loss: 2.3017701307932534

Epoch: 163| Step: 0
Training loss: 2.7187986373901367
Validation loss: 2.2961550963822233

Epoch: 5| Step: 1
Training loss: 2.9150702953338623
Validation loss: 2.3004776995669127

Epoch: 5| Step: 2
Training loss: 2.9775891304016113
Validation loss: 2.3066165395962295

Epoch: 5| Step: 3
Training loss: 3.0129411220550537
Validation loss: 2.3171365453350927

Epoch: 5| Step: 4
Training loss: 2.5440802574157715
Validation loss: 2.3130511340274604

Epoch: 5| Step: 5
Training loss: 2.0814380645751953
Validation loss: 2.313773432085591

Epoch: 5| Step: 6
Training loss: 2.3508529663085938
Validation loss: 2.3150160825380715

Epoch: 5| Step: 7
Training loss: 2.730731725692749
Validation loss: 2.328111166595131

Epoch: 5| Step: 8
Training loss: 2.350987434387207
Validation loss: 2.3342955881549465

Epoch: 5| Step: 9
Training loss: 2.1448235511779785
Validation loss: 2.3352532976417133

Epoch: 5| Step: 10
Training loss: 2.0884413719177246
Validation loss: 2.338570464041925

Epoch: 164| Step: 0
Training loss: 2.8826231956481934
Validation loss: 2.3508671406776673

Epoch: 5| Step: 1
Training loss: 2.5737013816833496
Validation loss: 2.3396781926514

Epoch: 5| Step: 2
Training loss: 3.0470728874206543
Validation loss: 2.3302848210898777

Epoch: 5| Step: 3
Training loss: 2.186522960662842
Validation loss: 2.3178562989798923

Epoch: 5| Step: 4
Training loss: 2.244088649749756
Validation loss: 2.3089890967133226

Epoch: 5| Step: 5
Training loss: 1.995194673538208
Validation loss: 2.3116620689310055

Epoch: 5| Step: 6
Training loss: 2.18000864982605
Validation loss: 2.3030012935720463

Epoch: 5| Step: 7
Training loss: 3.563053607940674
Validation loss: 2.3030797512300554

Epoch: 5| Step: 8
Training loss: 3.0935988426208496
Validation loss: 2.3085693851594002

Epoch: 5| Step: 9
Training loss: 2.1389689445495605
Validation loss: 2.310690064584055

Epoch: 5| Step: 10
Training loss: 2.1123225688934326
Validation loss: 2.3073748350143433

Epoch: 165| Step: 0
Training loss: 2.540111780166626
Validation loss: 2.3234037122418805

Epoch: 5| Step: 1
Training loss: 2.638057231903076
Validation loss: 2.335671260792722

Epoch: 5| Step: 2
Training loss: 2.699122905731201
Validation loss: 2.3520722081584315

Epoch: 5| Step: 3
Training loss: 2.4414916038513184
Validation loss: 2.3540814461246615

Epoch: 5| Step: 4
Training loss: 2.4551918506622314
Validation loss: 2.353447668014034

Epoch: 5| Step: 5
Training loss: 1.8637688159942627
Validation loss: 2.3387723251055648

Epoch: 5| Step: 6
Training loss: 2.620493173599243
Validation loss: 2.331661182065164

Epoch: 5| Step: 7
Training loss: 2.9153220653533936
Validation loss: 2.3172623572811

Epoch: 5| Step: 8
Training loss: 2.5092670917510986
Validation loss: 2.312889292675962

Epoch: 5| Step: 9
Training loss: 2.7367701530456543
Validation loss: 2.3091604068715084

Epoch: 5| Step: 10
Training loss: 2.619849443435669
Validation loss: 2.304500749034266

Epoch: 166| Step: 0
Training loss: 2.37630033493042
Validation loss: 2.312657115279987

Epoch: 5| Step: 1
Training loss: 2.570995569229126
Validation loss: 2.3378795628906577

Epoch: 5| Step: 2
Training loss: 2.696075916290283
Validation loss: 2.3503474753390075

Epoch: 5| Step: 3
Training loss: 2.2667620182037354
Validation loss: 2.353569056398125

Epoch: 5| Step: 4
Training loss: 3.1478612422943115
Validation loss: 2.370548076527093

Epoch: 5| Step: 5
Training loss: 2.317786455154419
Validation loss: 2.346219144841676

Epoch: 5| Step: 6
Training loss: 3.1111748218536377
Validation loss: 2.338057905115107

Epoch: 5| Step: 7
Training loss: 2.749243974685669
Validation loss: 2.3230394176257554

Epoch: 5| Step: 8
Training loss: 2.129608631134033
Validation loss: 2.3203889477637505

Epoch: 5| Step: 9
Training loss: 2.149564266204834
Validation loss: 2.3249021525024087

Epoch: 5| Step: 10
Training loss: 2.556025981903076
Validation loss: 2.32630096456056

Epoch: 167| Step: 0
Training loss: 2.5656535625457764
Validation loss: 2.319326287956648

Epoch: 5| Step: 1
Training loss: 2.5403246879577637
Validation loss: 2.320419297423414

Epoch: 5| Step: 2
Training loss: 2.358529567718506
Validation loss: 2.3109109094066005

Epoch: 5| Step: 3
Training loss: 2.4160666465759277
Validation loss: 2.319075999721404

Epoch: 5| Step: 4
Training loss: 2.3976478576660156
Validation loss: 2.31420398271212

Epoch: 5| Step: 5
Training loss: 2.2834792137145996
Validation loss: 2.3236904477560394

Epoch: 5| Step: 6
Training loss: 2.946380376815796
Validation loss: 2.3213624415859098

Epoch: 5| Step: 7
Training loss: 2.7032113075256348
Validation loss: 2.326327295713527

Epoch: 5| Step: 8
Training loss: 2.427955150604248
Validation loss: 2.311264673868815

Epoch: 5| Step: 9
Training loss: 2.8967931270599365
Validation loss: 2.3070687273497223

Epoch: 5| Step: 10
Training loss: 2.400843858718872
Validation loss: 2.3096154402661067

Epoch: 168| Step: 0
Training loss: 2.9905343055725098
Validation loss: 2.307736283989363

Epoch: 5| Step: 1
Training loss: 2.9858875274658203
Validation loss: 2.2955448678744736

Epoch: 5| Step: 2
Training loss: 1.7716376781463623
Validation loss: 2.306841193988759

Epoch: 5| Step: 3
Training loss: 2.48767352104187
Validation loss: 2.3112850445573048

Epoch: 5| Step: 4
Training loss: 3.082305431365967
Validation loss: 2.308647183961766

Epoch: 5| Step: 5
Training loss: 2.866133213043213
Validation loss: 2.3007999543220765

Epoch: 5| Step: 6
Training loss: 1.8927829265594482
Validation loss: 2.2989288119859594

Epoch: 5| Step: 7
Training loss: 2.6153676509857178
Validation loss: 2.3043862030070317

Epoch: 5| Step: 8
Training loss: 2.162534475326538
Validation loss: 2.3037504124385055

Epoch: 5| Step: 9
Training loss: 3.0845227241516113
Validation loss: 2.3119978391995994

Epoch: 5| Step: 10
Training loss: 1.9404497146606445
Validation loss: 2.347213988663048

Epoch: 169| Step: 0
Training loss: 2.304476261138916
Validation loss: 2.346998142939742

Epoch: 5| Step: 1
Training loss: 3.0470616817474365
Validation loss: 2.381157721242597

Epoch: 5| Step: 2
Training loss: 1.9999287128448486
Validation loss: 2.3884840396142777

Epoch: 5| Step: 3
Training loss: 2.5862324237823486
Validation loss: 2.3644554691929973

Epoch: 5| Step: 4
Training loss: 2.156625509262085
Validation loss: 2.345840110573717

Epoch: 5| Step: 5
Training loss: 2.800273895263672
Validation loss: 2.3428093617962253

Epoch: 5| Step: 6
Training loss: 2.8817765712738037
Validation loss: 2.3121248368294007

Epoch: 5| Step: 7
Training loss: 3.09843373298645
Validation loss: 2.3081366913292998

Epoch: 5| Step: 8
Training loss: 1.965014100074768
Validation loss: 2.309531539999029

Epoch: 5| Step: 9
Training loss: 2.902291774749756
Validation loss: 2.3063770083970923

Epoch: 5| Step: 10
Training loss: 2.0713140964508057
Validation loss: 2.295459480695827

Epoch: 170| Step: 0
Training loss: 2.082225799560547
Validation loss: 2.294622057227678

Epoch: 5| Step: 1
Training loss: 3.395399808883667
Validation loss: 2.3062562904050274

Epoch: 5| Step: 2
Training loss: 2.5330498218536377
Validation loss: 2.3029247445444905

Epoch: 5| Step: 3
Training loss: 2.9013984203338623
Validation loss: 2.3132570276978197

Epoch: 5| Step: 4
Training loss: 2.014130115509033
Validation loss: 2.315807483529532

Epoch: 5| Step: 5
Training loss: 2.380505084991455
Validation loss: 2.33128854279877

Epoch: 5| Step: 6
Training loss: 2.650195837020874
Validation loss: 2.3405891387693343

Epoch: 5| Step: 7
Training loss: 3.1315479278564453
Validation loss: 2.3336203611025246

Epoch: 5| Step: 8
Training loss: 1.8666059970855713
Validation loss: 2.344161643776842

Epoch: 5| Step: 9
Training loss: 2.6187901496887207
Validation loss: 2.3515737210550616

Epoch: 5| Step: 10
Training loss: 2.142892599105835
Validation loss: 2.3324951805094236

Epoch: 171| Step: 0
Training loss: 2.5572078227996826
Validation loss: 2.3403834963357575

Epoch: 5| Step: 1
Training loss: 2.9153499603271484
Validation loss: 2.3491215603325957

Epoch: 5| Step: 2
Training loss: 1.9715564250946045
Validation loss: 2.325316229174214

Epoch: 5| Step: 3
Training loss: 2.7805514335632324
Validation loss: 2.3312914089490007

Epoch: 5| Step: 4
Training loss: 2.7475383281707764
Validation loss: 2.3292404400405062

Epoch: 5| Step: 5
Training loss: 2.8866183757781982
Validation loss: 2.32398538051113

Epoch: 5| Step: 6
Training loss: 2.269958734512329
Validation loss: 2.3258194641400407

Epoch: 5| Step: 7
Training loss: 2.664956569671631
Validation loss: 2.336272034593808

Epoch: 5| Step: 8
Training loss: 2.3837802410125732
Validation loss: 2.3129039067094044

Epoch: 5| Step: 9
Training loss: 2.0978965759277344
Validation loss: 2.318697944764168

Epoch: 5| Step: 10
Training loss: 2.395411252975464
Validation loss: 2.31391562954072

Epoch: 172| Step: 0
Training loss: 2.209932804107666
Validation loss: 2.305821696917216

Epoch: 5| Step: 1
Training loss: 2.228713035583496
Validation loss: 2.3027549020705687

Epoch: 5| Step: 2
Training loss: 2.795736312866211
Validation loss: 2.3063091616476736

Epoch: 5| Step: 3
Training loss: 2.715050458908081
Validation loss: 2.3038448364503923

Epoch: 5| Step: 4
Training loss: 1.8766021728515625
Validation loss: 2.3028242562406804

Epoch: 5| Step: 5
Training loss: 2.655879259109497
Validation loss: 2.2993908236103673

Epoch: 5| Step: 6
Training loss: 2.366300344467163
Validation loss: 2.285446113155734

Epoch: 5| Step: 7
Training loss: 3.1446845531463623
Validation loss: 2.280833903179374

Epoch: 5| Step: 8
Training loss: 2.212972640991211
Validation loss: 2.272437854479718

Epoch: 5| Step: 9
Training loss: 2.599165678024292
Validation loss: 2.277537074140323

Epoch: 5| Step: 10
Training loss: 3.0803616046905518
Validation loss: 2.276702002812457

Epoch: 173| Step: 0
Training loss: 2.3270585536956787
Validation loss: 2.280317942301432

Epoch: 5| Step: 1
Training loss: 2.2564759254455566
Validation loss: 2.2898220221201577

Epoch: 5| Step: 2
Training loss: 2.5597739219665527
Validation loss: 2.277879129173935

Epoch: 5| Step: 3
Training loss: 2.8492419719696045
Validation loss: 2.301170136338921

Epoch: 5| Step: 4
Training loss: 2.348475456237793
Validation loss: 2.288045149977489

Epoch: 5| Step: 5
Training loss: 2.6299500465393066
Validation loss: 2.282041508664367

Epoch: 5| Step: 6
Training loss: 2.708040714263916
Validation loss: 2.273462567278134

Epoch: 5| Step: 7
Training loss: 2.9976863861083984
Validation loss: 2.2681304613749185

Epoch: 5| Step: 8
Training loss: 2.837817668914795
Validation loss: 2.2625304755344184

Epoch: 5| Step: 9
Training loss: 2.0578482151031494
Validation loss: 2.2625086230616414

Epoch: 5| Step: 10
Training loss: 2.2012202739715576
Validation loss: 2.2636869517705773

Epoch: 174| Step: 0
Training loss: 2.606780529022217
Validation loss: 2.256910977825042

Epoch: 5| Step: 1
Training loss: 1.72738778591156
Validation loss: 2.2679717220285887

Epoch: 5| Step: 2
Training loss: 2.6077404022216797
Validation loss: 2.277564271803825

Epoch: 5| Step: 3
Training loss: 2.383254289627075
Validation loss: 2.2849718601472917

Epoch: 5| Step: 4
Training loss: 2.2948079109191895
Validation loss: 2.2966481434401644

Epoch: 5| Step: 5
Training loss: 2.512632369995117
Validation loss: 2.308744920197354

Epoch: 5| Step: 6
Training loss: 2.123319387435913
Validation loss: 2.3149492663721882

Epoch: 5| Step: 7
Training loss: 2.680021047592163
Validation loss: 2.3027026063652447

Epoch: 5| Step: 8
Training loss: 2.3804311752319336
Validation loss: 2.3032530956370856

Epoch: 5| Step: 9
Training loss: 3.4757332801818848
Validation loss: 2.297126272673248

Epoch: 5| Step: 10
Training loss: 3.1098413467407227
Validation loss: 2.274388156911378

Epoch: 175| Step: 0
Training loss: 2.9930522441864014
Validation loss: 2.2787562544627855

Epoch: 5| Step: 1
Training loss: 2.3044016361236572
Validation loss: 2.2806327676260345

Epoch: 5| Step: 2
Training loss: 2.4947125911712646
Validation loss: 2.271382548475778

Epoch: 5| Step: 3
Training loss: 2.134341239929199
Validation loss: 2.270112359395591

Epoch: 5| Step: 4
Training loss: 1.7688461542129517
Validation loss: 2.2862357785624843

Epoch: 5| Step: 5
Training loss: 2.3840107917785645
Validation loss: 2.27281327145074

Epoch: 5| Step: 6
Training loss: 3.007585048675537
Validation loss: 2.2847318623655584

Epoch: 5| Step: 7
Training loss: 2.921485185623169
Validation loss: 2.284703980210007

Epoch: 5| Step: 8
Training loss: 2.9256157875061035
Validation loss: 2.289951055280624

Epoch: 5| Step: 9
Training loss: 2.6494393348693848
Validation loss: 2.2951059315794256

Epoch: 5| Step: 10
Training loss: 2.162364959716797
Validation loss: 2.2982505316375406

Epoch: 176| Step: 0
Training loss: 2.282867908477783
Validation loss: 2.3137951538126957

Epoch: 5| Step: 1
Training loss: 2.4122884273529053
Validation loss: 2.3237088854594896

Epoch: 5| Step: 2
Training loss: 2.784330368041992
Validation loss: 2.340946976856519

Epoch: 5| Step: 3
Training loss: 2.214743137359619
Validation loss: 2.3311266924745295

Epoch: 5| Step: 4
Training loss: 2.9455058574676514
Validation loss: 2.313252333671816

Epoch: 5| Step: 5
Training loss: 2.739030122756958
Validation loss: 2.3062637288083314

Epoch: 5| Step: 6
Training loss: 2.1722421646118164
Validation loss: 2.3024189702926146

Epoch: 5| Step: 7
Training loss: 2.6757779121398926
Validation loss: 2.301068377751176

Epoch: 5| Step: 8
Training loss: 2.2263901233673096
Validation loss: 2.291375670381772

Epoch: 5| Step: 9
Training loss: 2.7281970977783203
Validation loss: 2.2956660178399857

Epoch: 5| Step: 10
Training loss: 2.328068971633911
Validation loss: 2.281758548111044

Epoch: 177| Step: 0
Training loss: 2.7340962886810303
Validation loss: 2.270591628166937

Epoch: 5| Step: 1
Training loss: 3.011871337890625
Validation loss: 2.2791158255710395

Epoch: 5| Step: 2
Training loss: 2.003326892852783
Validation loss: 2.2704436766204013

Epoch: 5| Step: 3
Training loss: 2.3814849853515625
Validation loss: 2.282850101429929

Epoch: 5| Step: 4
Training loss: 2.9415502548217773
Validation loss: 2.2869553924888693

Epoch: 5| Step: 5
Training loss: 2.698319911956787
Validation loss: 2.286233909668461

Epoch: 5| Step: 6
Training loss: 1.7084341049194336
Validation loss: 2.291642705599467

Epoch: 5| Step: 7
Training loss: 3.0140717029571533
Validation loss: 2.304634617220971

Epoch: 5| Step: 8
Training loss: 2.563861846923828
Validation loss: 2.3077848649794057

Epoch: 5| Step: 9
Training loss: 2.0304312705993652
Validation loss: 2.307226073357367

Epoch: 5| Step: 10
Training loss: 2.3792386054992676
Validation loss: 2.3069864934490574

Epoch: 178| Step: 0
Training loss: 2.777431011199951
Validation loss: 2.313087929961502

Epoch: 5| Step: 1
Training loss: 2.446021556854248
Validation loss: 2.3058392873374363

Epoch: 5| Step: 2
Training loss: 2.7150356769561768
Validation loss: 2.3047240139335714

Epoch: 5| Step: 3
Training loss: 2.352569818496704
Validation loss: 2.302944452531876

Epoch: 5| Step: 4
Training loss: 2.8003764152526855
Validation loss: 2.3110581956883913

Epoch: 5| Step: 5
Training loss: 2.103306293487549
Validation loss: 2.309091560302242

Epoch: 5| Step: 6
Training loss: 2.67745041847229
Validation loss: 2.308399172239406

Epoch: 5| Step: 7
Training loss: 2.388355255126953
Validation loss: 2.3023090029275544

Epoch: 5| Step: 8
Training loss: 2.050017833709717
Validation loss: 2.3082520731033815

Epoch: 5| Step: 9
Training loss: 2.539660930633545
Validation loss: 2.3021241541831725

Epoch: 5| Step: 10
Training loss: 2.8205783367156982
Validation loss: 2.307275508039741

Epoch: 179| Step: 0
Training loss: 2.3953022956848145
Validation loss: 2.335711811178474

Epoch: 5| Step: 1
Training loss: 2.019625186920166
Validation loss: 2.3096679590081655

Epoch: 5| Step: 2
Training loss: 2.565786600112915
Validation loss: 2.3060152299942507

Epoch: 5| Step: 3
Training loss: 1.9559814929962158
Validation loss: 2.3130365904941352

Epoch: 5| Step: 4
Training loss: 3.0805225372314453
Validation loss: 2.305173550882647

Epoch: 5| Step: 5
Training loss: 3.2708630561828613
Validation loss: 2.2908356805001535

Epoch: 5| Step: 6
Training loss: 2.4309284687042236
Validation loss: 2.296253206909344

Epoch: 5| Step: 7
Training loss: 2.351795196533203
Validation loss: 2.288970808829031

Epoch: 5| Step: 8
Training loss: 2.7783312797546387
Validation loss: 2.2855042872890348

Epoch: 5| Step: 9
Training loss: 2.8150734901428223
Validation loss: 2.284251198973707

Epoch: 5| Step: 10
Training loss: 1.761716604232788
Validation loss: 2.2774014883143927

Epoch: 180| Step: 0
Training loss: 2.971785306930542
Validation loss: 2.2708791058550597

Epoch: 5| Step: 1
Training loss: 2.5882911682128906
Validation loss: 2.2552487722007175

Epoch: 5| Step: 2
Training loss: 2.5564489364624023
Validation loss: 2.252079024109789

Epoch: 5| Step: 3
Training loss: 2.0678274631500244
Validation loss: 2.2468608784419235

Epoch: 5| Step: 4
Training loss: 2.1684088706970215
Validation loss: 2.2440072746687036

Epoch: 5| Step: 5
Training loss: 2.325645923614502
Validation loss: 2.2527957142040296

Epoch: 5| Step: 6
Training loss: 2.7525646686553955
Validation loss: 2.255089734190254

Epoch: 5| Step: 7
Training loss: 2.3433804512023926
Validation loss: 2.2758301278596282

Epoch: 5| Step: 8
Training loss: 1.9961235523223877
Validation loss: 2.2822602564288723

Epoch: 5| Step: 9
Training loss: 2.8593945503234863
Validation loss: 2.2927156033054477

Epoch: 5| Step: 10
Training loss: 3.097903251647949
Validation loss: 2.282366874397442

Epoch: 181| Step: 0
Training loss: 2.1507930755615234
Validation loss: 2.27270173001033

Epoch: 5| Step: 1
Training loss: 2.7516589164733887
Validation loss: 2.264634434894849

Epoch: 5| Step: 2
Training loss: 2.6219077110290527
Validation loss: 2.261169589975829

Epoch: 5| Step: 3
Training loss: 2.2758350372314453
Validation loss: 2.262985758883979

Epoch: 5| Step: 4
Training loss: 2.9761626720428467
Validation loss: 2.283515707139046

Epoch: 5| Step: 5
Training loss: 2.059255838394165
Validation loss: 2.295049741703977

Epoch: 5| Step: 6
Training loss: 2.1924595832824707
Validation loss: 2.3065706760652605

Epoch: 5| Step: 7
Training loss: 1.975206971168518
Validation loss: 2.3064091897779897

Epoch: 5| Step: 8
Training loss: 3.1071953773498535
Validation loss: 2.3001367635624383

Epoch: 5| Step: 9
Training loss: 3.0286779403686523
Validation loss: 2.2994505820735807

Epoch: 5| Step: 10
Training loss: 2.425107479095459
Validation loss: 2.2910168324747393

Epoch: 182| Step: 0
Training loss: 2.901154041290283
Validation loss: 2.2905010561789236

Epoch: 5| Step: 1
Training loss: 2.4594802856445312
Validation loss: 2.2994425681329544

Epoch: 5| Step: 2
Training loss: 2.1215434074401855
Validation loss: 2.2989634134436168

Epoch: 5| Step: 3
Training loss: 2.5351076126098633
Validation loss: 2.316948862485988

Epoch: 5| Step: 4
Training loss: 2.81876277923584
Validation loss: 2.315557982331963

Epoch: 5| Step: 5
Training loss: 2.135303020477295
Validation loss: 2.3117888435240714

Epoch: 5| Step: 6
Training loss: 2.5849099159240723
Validation loss: 2.31781756236989

Epoch: 5| Step: 7
Training loss: 2.4431700706481934
Validation loss: 2.2989170705118487

Epoch: 5| Step: 8
Training loss: 2.873058795928955
Validation loss: 2.2964935892371723

Epoch: 5| Step: 9
Training loss: 2.0858020782470703
Validation loss: 2.2683390648134294

Epoch: 5| Step: 10
Training loss: 2.4721384048461914
Validation loss: 2.255829762387019

Epoch: 183| Step: 0
Training loss: 2.4116127490997314
Validation loss: 2.2579044731714393

Epoch: 5| Step: 1
Training loss: 1.8545761108398438
Validation loss: 2.259662010336435

Epoch: 5| Step: 2
Training loss: 2.362750291824341
Validation loss: 2.263622894082018

Epoch: 5| Step: 3
Training loss: 2.2016563415527344
Validation loss: 2.2556224356415453

Epoch: 5| Step: 4
Training loss: 2.5162153244018555
Validation loss: 2.266765125336186

Epoch: 5| Step: 5
Training loss: 2.8855795860290527
Validation loss: 2.2721389775635092

Epoch: 5| Step: 6
Training loss: 3.019498109817505
Validation loss: 2.2788052123080016

Epoch: 5| Step: 7
Training loss: 2.5168426036834717
Validation loss: 2.280299832743983

Epoch: 5| Step: 8
Training loss: 2.490175724029541
Validation loss: 2.2885497257273686

Epoch: 5| Step: 9
Training loss: 2.912733554840088
Validation loss: 2.2871756656195528

Epoch: 5| Step: 10
Training loss: 2.185994863510132
Validation loss: 2.287246237518967

Epoch: 184| Step: 0
Training loss: 2.2934958934783936
Validation loss: 2.28323709067478

Epoch: 5| Step: 1
Training loss: 2.3900370597839355
Validation loss: 2.2787826650886127

Epoch: 5| Step: 2
Training loss: 3.1494221687316895
Validation loss: 2.271336961817998

Epoch: 5| Step: 3
Training loss: 2.2532639503479004
Validation loss: 2.264291609487226

Epoch: 5| Step: 4
Training loss: 2.4030940532684326
Validation loss: 2.273147198461717

Epoch: 5| Step: 5
Training loss: 2.4414126873016357
Validation loss: 2.2697139017043577

Epoch: 5| Step: 6
Training loss: 2.4855453968048096
Validation loss: 2.267785023617488

Epoch: 5| Step: 7
Training loss: 2.8122963905334473
Validation loss: 2.26696801441972

Epoch: 5| Step: 8
Training loss: 2.4179747104644775
Validation loss: 2.2793286013346847

Epoch: 5| Step: 9
Training loss: 2.1449155807495117
Validation loss: 2.2755186519315167

Epoch: 5| Step: 10
Training loss: 2.5134825706481934
Validation loss: 2.2623383896325224

Epoch: 185| Step: 0
Training loss: 2.7375292778015137
Validation loss: 2.2785002416180027

Epoch: 5| Step: 1
Training loss: 2.4864907264709473
Validation loss: 2.282164608278582

Epoch: 5| Step: 2
Training loss: 3.1043877601623535
Validation loss: 2.274975671563097

Epoch: 5| Step: 3
Training loss: 2.2557554244995117
Validation loss: 2.262181689662318

Epoch: 5| Step: 4
Training loss: 2.402052402496338
Validation loss: 2.252550040521929

Epoch: 5| Step: 5
Training loss: 1.9857890605926514
Validation loss: 2.246813480572034

Epoch: 5| Step: 6
Training loss: 2.107590675354004
Validation loss: 2.2601962320266233

Epoch: 5| Step: 7
Training loss: 2.0473198890686035
Validation loss: 2.2545877323355725

Epoch: 5| Step: 8
Training loss: 3.0123770236968994
Validation loss: 2.2529717914519773

Epoch: 5| Step: 9
Training loss: 2.1534006595611572
Validation loss: 2.2488044064532042

Epoch: 5| Step: 10
Training loss: 3.152109384536743
Validation loss: 2.264995892842611

Epoch: 186| Step: 0
Training loss: 1.9464054107666016
Validation loss: 2.270094612593292

Epoch: 5| Step: 1
Training loss: 2.5347611904144287
Validation loss: 2.282261735649519

Epoch: 5| Step: 2
Training loss: 2.017665147781372
Validation loss: 2.275153918932843

Epoch: 5| Step: 3
Training loss: 3.150738000869751
Validation loss: 2.276131009542814

Epoch: 5| Step: 4
Training loss: 2.2491352558135986
Validation loss: 2.2764104950812554

Epoch: 5| Step: 5
Training loss: 2.4841928482055664
Validation loss: 2.2753936116413405

Epoch: 5| Step: 6
Training loss: 2.1990628242492676
Validation loss: 2.276623505418019

Epoch: 5| Step: 7
Training loss: 2.534836769104004
Validation loss: 2.2960213256138626

Epoch: 5| Step: 8
Training loss: 3.0936410427093506
Validation loss: 2.3067404941845964

Epoch: 5| Step: 9
Training loss: 2.726499080657959
Validation loss: 2.3033223626434163

Epoch: 5| Step: 10
Training loss: 2.1089823246002197
Validation loss: 2.301862585929132

Epoch: 187| Step: 0
Training loss: 1.829581618309021
Validation loss: 2.3025142428695515

Epoch: 5| Step: 1
Training loss: 1.8790754079818726
Validation loss: 2.3018856484402894

Epoch: 5| Step: 2
Training loss: 2.3101677894592285
Validation loss: 2.3037948608398438

Epoch: 5| Step: 3
Training loss: 2.4199655055999756
Validation loss: 2.29652674095605

Epoch: 5| Step: 4
Training loss: 2.360802173614502
Validation loss: 2.291236792841265

Epoch: 5| Step: 5
Training loss: 2.7741198539733887
Validation loss: 2.293444779611403

Epoch: 5| Step: 6
Training loss: 3.109569787979126
Validation loss: 2.289569144607872

Epoch: 5| Step: 7
Training loss: 2.8470165729522705
Validation loss: 2.3031139553234143

Epoch: 5| Step: 8
Training loss: 3.087740898132324
Validation loss: 2.296588869505031

Epoch: 5| Step: 9
Training loss: 1.981134057044983
Validation loss: 2.2774299267799623

Epoch: 5| Step: 10
Training loss: 2.5421319007873535
Validation loss: 2.286609649658203

Epoch: 188| Step: 0
Training loss: 2.093369483947754
Validation loss: 2.2609142782867595

Epoch: 5| Step: 1
Training loss: 2.42991304397583
Validation loss: 2.2716057069839968

Epoch: 5| Step: 2
Training loss: 2.8903205394744873
Validation loss: 2.2582936389471895

Epoch: 5| Step: 3
Training loss: 2.581338405609131
Validation loss: 2.2577485961298787

Epoch: 5| Step: 4
Training loss: 2.4771411418914795
Validation loss: 2.253023703893026

Epoch: 5| Step: 5
Training loss: 2.9517688751220703
Validation loss: 2.252240114314582

Epoch: 5| Step: 6
Training loss: 1.9981024265289307
Validation loss: 2.255116431943832

Epoch: 5| Step: 7
Training loss: 2.4551942348480225
Validation loss: 2.2699976813408638

Epoch: 5| Step: 8
Training loss: 2.024143695831299
Validation loss: 2.2764998046300744

Epoch: 5| Step: 9
Training loss: 2.8918793201446533
Validation loss: 2.2929139983269478

Epoch: 5| Step: 10
Training loss: 2.313392400741577
Validation loss: 2.286036434993949

Epoch: 189| Step: 0
Training loss: 2.5665013790130615
Validation loss: 2.285962984126101

Epoch: 5| Step: 1
Training loss: 2.682495594024658
Validation loss: 2.2868310559180474

Epoch: 5| Step: 2
Training loss: 2.7162041664123535
Validation loss: 2.299077997925461

Epoch: 5| Step: 3
Training loss: 2.1232869625091553
Validation loss: 2.2918471405583043

Epoch: 5| Step: 4
Training loss: 2.70412015914917
Validation loss: 2.2889622437056674

Epoch: 5| Step: 5
Training loss: 2.5234692096710205
Validation loss: 2.278212252483573

Epoch: 5| Step: 6
Training loss: 2.2367355823516846
Validation loss: 2.2675696419131373

Epoch: 5| Step: 7
Training loss: 2.3022429943084717
Validation loss: 2.281096919890373

Epoch: 5| Step: 8
Training loss: 1.9114030599594116
Validation loss: 2.2668512328978507

Epoch: 5| Step: 9
Training loss: 2.2968411445617676
Validation loss: 2.28068337773764

Epoch: 5| Step: 10
Training loss: 3.1835381984710693
Validation loss: 2.28462508673309

Epoch: 190| Step: 0
Training loss: 2.697988510131836
Validation loss: 2.277634346356956

Epoch: 5| Step: 1
Training loss: 2.0302743911743164
Validation loss: 2.2656519694994857

Epoch: 5| Step: 2
Training loss: 2.184288740158081
Validation loss: 2.28264715081902

Epoch: 5| Step: 3
Training loss: 2.320971965789795
Validation loss: 2.27433410767586

Epoch: 5| Step: 4
Training loss: 2.3589205741882324
Validation loss: 2.2684003563337427

Epoch: 5| Step: 5
Training loss: 2.20766019821167
Validation loss: 2.2612605197455293

Epoch: 5| Step: 6
Training loss: 2.4870543479919434
Validation loss: 2.2644080551721717

Epoch: 5| Step: 7
Training loss: 2.9266014099121094
Validation loss: 2.2797779370379705

Epoch: 5| Step: 8
Training loss: 2.7227680683135986
Validation loss: 2.2991957459398495

Epoch: 5| Step: 9
Training loss: 2.213458299636841
Validation loss: 2.288276274998983

Epoch: 5| Step: 10
Training loss: 3.00333833694458
Validation loss: 2.2796475118206394

Epoch: 191| Step: 0
Training loss: 2.3644275665283203
Validation loss: 2.298792395540463

Epoch: 5| Step: 1
Training loss: 2.7467639446258545
Validation loss: 2.3260817604680217

Epoch: 5| Step: 2
Training loss: 2.4684689044952393
Validation loss: 2.3411034230263

Epoch: 5| Step: 3
Training loss: 2.600897789001465
Validation loss: 2.3360090281373713

Epoch: 5| Step: 4
Training loss: 2.5824155807495117
Validation loss: 2.3102830174148723

Epoch: 5| Step: 5
Training loss: 2.41615629196167
Validation loss: 2.305584725513253

Epoch: 5| Step: 6
Training loss: 2.6347336769104004
Validation loss: 2.279529466423937

Epoch: 5| Step: 7
Training loss: 1.832042932510376
Validation loss: 2.255457144911571

Epoch: 5| Step: 8
Training loss: 2.9654040336608887
Validation loss: 2.2254252408140447

Epoch: 5| Step: 9
Training loss: 2.2582342624664307
Validation loss: 2.2192833949160833

Epoch: 5| Step: 10
Training loss: 2.38928484916687
Validation loss: 2.1990587224242506

Epoch: 192| Step: 0
Training loss: 2.644991397857666
Validation loss: 2.197353224600515

Epoch: 5| Step: 1
Training loss: 2.18538498878479
Validation loss: 2.199070933044598

Epoch: 5| Step: 2
Training loss: 2.3575997352600098
Validation loss: 2.1984968211061213

Epoch: 5| Step: 3
Training loss: 2.970332384109497
Validation loss: 2.1952999407245266

Epoch: 5| Step: 4
Training loss: 2.4911887645721436
Validation loss: 2.200431567366405

Epoch: 5| Step: 5
Training loss: 2.801790952682495
Validation loss: 2.1998609586428572

Epoch: 5| Step: 6
Training loss: 2.412590503692627
Validation loss: 2.1979190739252235

Epoch: 5| Step: 7
Training loss: 2.2333905696868896
Validation loss: 2.204998375267111

Epoch: 5| Step: 8
Training loss: 2.311786413192749
Validation loss: 2.216672588420171

Epoch: 5| Step: 9
Training loss: 2.7147488594055176
Validation loss: 2.2112300793329873

Epoch: 5| Step: 10
Training loss: 2.1518349647521973
Validation loss: 2.2428548156574206

Epoch: 193| Step: 0
Training loss: 2.4783852100372314
Validation loss: 2.292159447105982

Epoch: 5| Step: 1
Training loss: 2.32850980758667
Validation loss: 2.3577221234639487

Epoch: 5| Step: 2
Training loss: 2.6739983558654785
Validation loss: 2.388227678114368

Epoch: 5| Step: 3
Training loss: 2.974400043487549
Validation loss: 2.367491396524573

Epoch: 5| Step: 4
Training loss: 1.939765214920044
Validation loss: 2.316022108959895

Epoch: 5| Step: 5
Training loss: 2.845813035964966
Validation loss: 2.2732029294454925

Epoch: 5| Step: 6
Training loss: 2.708007574081421
Validation loss: 2.254835315929946

Epoch: 5| Step: 7
Training loss: 2.4096224308013916
Validation loss: 2.2438530127207437

Epoch: 5| Step: 8
Training loss: 2.474034070968628
Validation loss: 2.25661737175398

Epoch: 5| Step: 9
Training loss: 2.0550925731658936
Validation loss: 2.2524854316506335

Epoch: 5| Step: 10
Training loss: 2.5071005821228027
Validation loss: 2.2662678764712427

Epoch: 194| Step: 0
Training loss: 2.3049700260162354
Validation loss: 2.2706426805065525

Epoch: 5| Step: 1
Training loss: 2.9940879344940186
Validation loss: 2.26413554786354

Epoch: 5| Step: 2
Training loss: 2.248910903930664
Validation loss: 2.2616030554617605

Epoch: 5| Step: 3
Training loss: 2.548344135284424
Validation loss: 2.2491694919524656

Epoch: 5| Step: 4
Training loss: 2.7573459148406982
Validation loss: 2.2480032238908993

Epoch: 5| Step: 5
Training loss: 2.2625489234924316
Validation loss: 2.2529013618346183

Epoch: 5| Step: 6
Training loss: 2.876290798187256
Validation loss: 2.252628372561547

Epoch: 5| Step: 7
Training loss: 2.0320677757263184
Validation loss: 2.245805953138618

Epoch: 5| Step: 8
Training loss: 2.623911142349243
Validation loss: 2.251948789883685

Epoch: 5| Step: 9
Training loss: 2.2256503105163574
Validation loss: 2.2464389980480237

Epoch: 5| Step: 10
Training loss: 2.0595803260803223
Validation loss: 2.246469651499102

Epoch: 195| Step: 0
Training loss: 2.389008045196533
Validation loss: 2.247463200681953

Epoch: 5| Step: 1
Training loss: 2.9049994945526123
Validation loss: 2.2573155997901835

Epoch: 5| Step: 2
Training loss: 2.518627405166626
Validation loss: 2.254383420431486

Epoch: 5| Step: 3
Training loss: 2.1894912719726562
Validation loss: 2.2639805232324908

Epoch: 5| Step: 4
Training loss: 1.8473138809204102
Validation loss: 2.2766302529201714

Epoch: 5| Step: 5
Training loss: 2.397350788116455
Validation loss: 2.2900257930960706

Epoch: 5| Step: 6
Training loss: 1.9780771732330322
Validation loss: 2.2755181840671006

Epoch: 5| Step: 7
Training loss: 2.2057201862335205
Validation loss: 2.2897529422595935

Epoch: 5| Step: 8
Training loss: 2.8015596866607666
Validation loss: 2.289010659340889

Epoch: 5| Step: 9
Training loss: 2.472308397293091
Validation loss: 2.298253869497648

Epoch: 5| Step: 10
Training loss: 3.243962526321411
Validation loss: 2.297571700106385

Epoch: 196| Step: 0
Training loss: 2.2786307334899902
Validation loss: 2.282964380838538

Epoch: 5| Step: 1
Training loss: 2.779998302459717
Validation loss: 2.265293154665219

Epoch: 5| Step: 2
Training loss: 2.809270143508911
Validation loss: 2.2356783215717604

Epoch: 5| Step: 3
Training loss: 3.087549924850464
Validation loss: 2.222235656553699

Epoch: 5| Step: 4
Training loss: 2.432389974594116
Validation loss: 2.2150662534980365

Epoch: 5| Step: 5
Training loss: 2.135467290878296
Validation loss: 2.1973943223235426

Epoch: 5| Step: 6
Training loss: 2.197760820388794
Validation loss: 2.1968010907532065

Epoch: 5| Step: 7
Training loss: 2.01442289352417
Validation loss: 2.19279573809716

Epoch: 5| Step: 8
Training loss: 2.669473648071289
Validation loss: 2.2002265863521124

Epoch: 5| Step: 9
Training loss: 2.389967203140259
Validation loss: 2.197194442954115

Epoch: 5| Step: 10
Training loss: 2.4147777557373047
Validation loss: 2.2028570303352932

Epoch: 197| Step: 0
Training loss: 2.006579637527466
Validation loss: 2.2084145751050723

Epoch: 5| Step: 1
Training loss: 2.4621012210845947
Validation loss: 2.2108251176854616

Epoch: 5| Step: 2
Training loss: 2.211186170578003
Validation loss: 2.2256582526750464

Epoch: 5| Step: 3
Training loss: 3.059983730316162
Validation loss: 2.2479188852412726

Epoch: 5| Step: 4
Training loss: 2.4943325519561768
Validation loss: 2.251609533063827

Epoch: 5| Step: 5
Training loss: 2.1862549781799316
Validation loss: 2.263686490315263

Epoch: 5| Step: 6
Training loss: 2.6516497135162354
Validation loss: 2.261808172349007

Epoch: 5| Step: 7
Training loss: 2.4189016819000244
Validation loss: 2.270159987993138

Epoch: 5| Step: 8
Training loss: 2.6591944694519043
Validation loss: 2.28935666238108

Epoch: 5| Step: 9
Training loss: 2.1034669876098633
Validation loss: 2.3005277725958053

Epoch: 5| Step: 10
Training loss: 2.751401662826538
Validation loss: 2.285948327792588

Epoch: 198| Step: 0
Training loss: 2.4827938079833984
Validation loss: 2.264682739011703

Epoch: 5| Step: 1
Training loss: 2.095160961151123
Validation loss: 2.2583278045859387

Epoch: 5| Step: 2
Training loss: 2.686854600906372
Validation loss: 2.2750027487354894

Epoch: 5| Step: 3
Training loss: 2.7720799446105957
Validation loss: 2.317307400447066

Epoch: 5| Step: 4
Training loss: 2.799409866333008
Validation loss: 2.395831902821859

Epoch: 5| Step: 5
Training loss: 1.8811109066009521
Validation loss: 2.4398049077680035

Epoch: 5| Step: 6
Training loss: 2.9992237091064453
Validation loss: 2.4391333979945027

Epoch: 5| Step: 7
Training loss: 2.177757740020752
Validation loss: 2.394414835078742

Epoch: 5| Step: 8
Training loss: 2.351799726486206
Validation loss: 2.3018740633482575

Epoch: 5| Step: 9
Training loss: 2.878068208694458
Validation loss: 2.257557330592986

Epoch: 5| Step: 10
Training loss: 2.4754719734191895
Validation loss: 2.229239830406763

Epoch: 199| Step: 0
Training loss: 1.8750684261322021
Validation loss: 2.224628527959188

Epoch: 5| Step: 1
Training loss: 2.8626527786254883
Validation loss: 2.227516902390347

Epoch: 5| Step: 2
Training loss: 2.4824767112731934
Validation loss: 2.2527801811054187

Epoch: 5| Step: 3
Training loss: 2.6741766929626465
Validation loss: 2.2835213368938816

Epoch: 5| Step: 4
Training loss: 2.6145637035369873
Validation loss: 2.310033921272524

Epoch: 5| Step: 5
Training loss: 2.142239809036255
Validation loss: 2.330079088928879

Epoch: 5| Step: 6
Training loss: 2.4315285682678223
Validation loss: 2.3145768847516788

Epoch: 5| Step: 7
Training loss: 2.3449127674102783
Validation loss: 2.3112127960369153

Epoch: 5| Step: 8
Training loss: 2.3733229637145996
Validation loss: 2.3051419527299943

Epoch: 5| Step: 9
Training loss: 2.3212294578552246
Validation loss: 2.2695496313033567

Epoch: 5| Step: 10
Training loss: 2.977548599243164
Validation loss: 2.2423210682407504

Epoch: 200| Step: 0
Training loss: 1.9538249969482422
Validation loss: 2.2195880156691357

Epoch: 5| Step: 1
Training loss: 2.5622811317443848
Validation loss: 2.2217935157078568

Epoch: 5| Step: 2
Training loss: 2.435382843017578
Validation loss: 2.231485515512446

Epoch: 5| Step: 3
Training loss: 2.5469162464141846
Validation loss: 2.2255696583819646

Epoch: 5| Step: 4
Training loss: 2.4537527561187744
Validation loss: 2.2232974626684703

Epoch: 5| Step: 5
Training loss: 2.6083056926727295
Validation loss: 2.218187560317337

Epoch: 5| Step: 6
Training loss: 2.4080991744995117
Validation loss: 2.2095508985621954

Epoch: 5| Step: 7
Training loss: 2.277961254119873
Validation loss: 2.216078873603575

Epoch: 5| Step: 8
Training loss: 2.7134757041931152
Validation loss: 2.217720257338657

Epoch: 5| Step: 9
Training loss: 2.4928956031799316
Validation loss: 2.2247329360695294

Epoch: 5| Step: 10
Training loss: 2.594362735748291
Validation loss: 2.2263862420153875

Epoch: 201| Step: 0
Training loss: 2.935605049133301
Validation loss: 2.22245668595837

Epoch: 5| Step: 1
Training loss: 2.0966200828552246
Validation loss: 2.2238727487543577

Epoch: 5| Step: 2
Training loss: 2.259885311126709
Validation loss: 2.2234071813603884

Epoch: 5| Step: 3
Training loss: 2.9155144691467285
Validation loss: 2.216487794794062

Epoch: 5| Step: 4
Training loss: 2.521644115447998
Validation loss: 2.2230583108881468

Epoch: 5| Step: 5
Training loss: 2.541203737258911
Validation loss: 2.234799349179832

Epoch: 5| Step: 6
Training loss: 2.560783863067627
Validation loss: 2.2379154428359

Epoch: 5| Step: 7
Training loss: 2.3441338539123535
Validation loss: 2.2496044712681926

Epoch: 5| Step: 8
Training loss: 1.9956085681915283
Validation loss: 2.290925923214164

Epoch: 5| Step: 9
Training loss: 2.631504774093628
Validation loss: 2.3357028832999607

Epoch: 5| Step: 10
Training loss: 2.1739118099212646
Validation loss: 2.344222061095699

Epoch: 202| Step: 0
Training loss: 1.8590977191925049
Validation loss: 2.3415566823815785

Epoch: 5| Step: 1
Training loss: 2.3758444786071777
Validation loss: 2.3267214810976418

Epoch: 5| Step: 2
Training loss: 2.5493688583374023
Validation loss: 2.312652898091142

Epoch: 5| Step: 3
Training loss: 2.2229645252227783
Validation loss: 2.295199253225839

Epoch: 5| Step: 4
Training loss: 2.9877562522888184
Validation loss: 2.289950088788104

Epoch: 5| Step: 5
Training loss: 1.9578883647918701
Validation loss: 2.259665971161217

Epoch: 5| Step: 6
Training loss: 2.143808126449585
Validation loss: 2.2438626007367204

Epoch: 5| Step: 7
Training loss: 2.7579333782196045
Validation loss: 2.2269085145765737

Epoch: 5| Step: 8
Training loss: 2.742222309112549
Validation loss: 2.222118946813768

Epoch: 5| Step: 9
Training loss: 2.7679290771484375
Validation loss: 2.216190699608095

Epoch: 5| Step: 10
Training loss: 2.4208264350891113
Validation loss: 2.2024109286646687

Epoch: 203| Step: 0
Training loss: 2.3764700889587402
Validation loss: 2.2013321897035003

Epoch: 5| Step: 1
Training loss: 1.9263696670532227
Validation loss: 2.200212171000819

Epoch: 5| Step: 2
Training loss: 2.996185302734375
Validation loss: 2.20543247653592

Epoch: 5| Step: 3
Training loss: 2.2493066787719727
Validation loss: 2.22433711636451

Epoch: 5| Step: 4
Training loss: 2.7995026111602783
Validation loss: 2.2370723434673843

Epoch: 5| Step: 5
Training loss: 2.1652636528015137
Validation loss: 2.2477316600020214

Epoch: 5| Step: 6
Training loss: 2.39949369430542
Validation loss: 2.2737651512187016

Epoch: 5| Step: 7
Training loss: 2.6116421222686768
Validation loss: 2.279612245098237

Epoch: 5| Step: 8
Training loss: 2.6437458992004395
Validation loss: 2.248114119293869

Epoch: 5| Step: 9
Training loss: 2.239192485809326
Validation loss: 2.227804755651823

Epoch: 5| Step: 10
Training loss: 2.5129811763763428
Validation loss: 2.2276987491115445

Epoch: 204| Step: 0
Training loss: 2.5534427165985107
Validation loss: 2.217062747606667

Epoch: 5| Step: 1
Training loss: 2.134042263031006
Validation loss: 2.2224545376275175

Epoch: 5| Step: 2
Training loss: 2.2521510124206543
Validation loss: 2.225368474119453

Epoch: 5| Step: 3
Training loss: 2.4838879108428955
Validation loss: 2.22830186095289

Epoch: 5| Step: 4
Training loss: 2.1739141941070557
Validation loss: 2.2310463587443032

Epoch: 5| Step: 5
Training loss: 2.1220316886901855
Validation loss: 2.2296790576750234

Epoch: 5| Step: 6
Training loss: 2.0496115684509277
Validation loss: 2.236791972191103

Epoch: 5| Step: 7
Training loss: 3.0243160724639893
Validation loss: 2.2284716072902886

Epoch: 5| Step: 8
Training loss: 2.859426975250244
Validation loss: 2.2382217658463346

Epoch: 5| Step: 9
Training loss: 2.545772075653076
Validation loss: 2.2319938239230903

Epoch: 5| Step: 10
Training loss: 2.2573485374450684
Validation loss: 2.2364902150246406

Epoch: 205| Step: 0
Training loss: 1.844458818435669
Validation loss: 2.237425060682399

Epoch: 5| Step: 1
Training loss: 2.0318410396575928
Validation loss: 2.233517631407707

Epoch: 5| Step: 2
Training loss: 3.098106861114502
Validation loss: 2.2238332815067743

Epoch: 5| Step: 3
Training loss: 2.6746439933776855
Validation loss: 2.2209802930073073

Epoch: 5| Step: 4
Training loss: 2.569092035293579
Validation loss: 2.2238873986787695

Epoch: 5| Step: 5
Training loss: 2.0886943340301514
Validation loss: 2.204978453215732

Epoch: 5| Step: 6
Training loss: 1.9386894702911377
Validation loss: 2.218154945681172

Epoch: 5| Step: 7
Training loss: 1.9435417652130127
Validation loss: 2.22262530813935

Epoch: 5| Step: 8
Training loss: 3.16491961479187
Validation loss: 2.221438938571561

Epoch: 5| Step: 9
Training loss: 2.2073638439178467
Validation loss: 2.21983326378689

Epoch: 5| Step: 10
Training loss: 2.9762649536132812
Validation loss: 2.2187181903469946

Epoch: 206| Step: 0
Training loss: 1.6709976196289062
Validation loss: 2.2106664270483036

Epoch: 5| Step: 1
Training loss: 2.6987624168395996
Validation loss: 2.2054404353582733

Epoch: 5| Step: 2
Training loss: 1.7960169315338135
Validation loss: 2.2172916678972143

Epoch: 5| Step: 3
Training loss: 2.663753032684326
Validation loss: 2.2093532931420112

Epoch: 5| Step: 4
Training loss: 2.6745989322662354
Validation loss: 2.2116161674581547

Epoch: 5| Step: 5
Training loss: 2.0924785137176514
Validation loss: 2.2229422625674995

Epoch: 5| Step: 6
Training loss: 2.3184120655059814
Validation loss: 2.2316846591170116

Epoch: 5| Step: 7
Training loss: 2.513711929321289
Validation loss: 2.238545371640113

Epoch: 5| Step: 8
Training loss: 2.8970794677734375
Validation loss: 2.2424414696231967

Epoch: 5| Step: 9
Training loss: 2.3510019779205322
Validation loss: 2.2444274707507064

Epoch: 5| Step: 10
Training loss: 2.7779736518859863
Validation loss: 2.243222173824105

Epoch: 207| Step: 0
Training loss: 2.374005079269409
Validation loss: 2.2269349303296817

Epoch: 5| Step: 1
Training loss: 2.086146354675293
Validation loss: 2.2113285346697737

Epoch: 5| Step: 2
Training loss: 2.651050329208374
Validation loss: 2.2060415975509153

Epoch: 5| Step: 3
Training loss: 1.7166402339935303
Validation loss: 2.207185868294008

Epoch: 5| Step: 4
Training loss: 2.0937323570251465
Validation loss: 2.1997133301150416

Epoch: 5| Step: 5
Training loss: 2.3216392993927
Validation loss: 2.190950808986541

Epoch: 5| Step: 6
Training loss: 1.9716899394989014
Validation loss: 2.189787208393056

Epoch: 5| Step: 7
Training loss: 2.843688488006592
Validation loss: 2.1939774405571724

Epoch: 5| Step: 8
Training loss: 3.1394646167755127
Validation loss: 2.211626504057197

Epoch: 5| Step: 9
Training loss: 2.6006240844726562
Validation loss: 2.210375826845887

Epoch: 5| Step: 10
Training loss: 2.4914143085479736
Validation loss: 2.2177643211939

Epoch: 208| Step: 0
Training loss: 2.2269763946533203
Validation loss: 2.234199554689469

Epoch: 5| Step: 1
Training loss: 2.180708169937134
Validation loss: 2.250590057783229

Epoch: 5| Step: 2
Training loss: 2.023245334625244
Validation loss: 2.2855315234071467

Epoch: 5| Step: 3
Training loss: 2.4808263778686523
Validation loss: 2.3034600083545973

Epoch: 5| Step: 4
Training loss: 2.4487175941467285
Validation loss: 2.2969231836257444

Epoch: 5| Step: 5
Training loss: 2.4650397300720215
Validation loss: 2.30478661803789

Epoch: 5| Step: 6
Training loss: 2.5354018211364746
Validation loss: 2.292834504958122

Epoch: 5| Step: 7
Training loss: 2.159205913543701
Validation loss: 2.275106712054181

Epoch: 5| Step: 8
Training loss: 2.105302095413208
Validation loss: 2.2505514083370084

Epoch: 5| Step: 9
Training loss: 2.502436637878418
Validation loss: 2.238690999246413

Epoch: 5| Step: 10
Training loss: 3.4609901905059814
Validation loss: 2.2113175725424163

Epoch: 209| Step: 0
Training loss: 2.719757556915283
Validation loss: 2.2083810849856307

Epoch: 5| Step: 1
Training loss: 1.9636332988739014
Validation loss: 2.2063217188722346

Epoch: 5| Step: 2
Training loss: 2.4533135890960693
Validation loss: 2.202711089964836

Epoch: 5| Step: 3
Training loss: 2.2453720569610596
Validation loss: 2.2007202845747753

Epoch: 5| Step: 4
Training loss: 2.343865394592285
Validation loss: 2.183107222280195

Epoch: 5| Step: 5
Training loss: 2.975849151611328
Validation loss: 2.196436382109119

Epoch: 5| Step: 6
Training loss: 2.1688644886016846
Validation loss: 2.183454931423228

Epoch: 5| Step: 7
Training loss: 2.1202731132507324
Validation loss: 2.1830023591236403

Epoch: 5| Step: 8
Training loss: 2.1509604454040527
Validation loss: 2.179695911304925

Epoch: 5| Step: 9
Training loss: 2.7168853282928467
Validation loss: 2.190556026274158

Epoch: 5| Step: 10
Training loss: 2.580441474914551
Validation loss: 2.203683358366771

Epoch: 210| Step: 0
Training loss: 2.4770636558532715
Validation loss: 2.188740563649003

Epoch: 5| Step: 1
Training loss: 2.623777151107788
Validation loss: 2.203094915677142

Epoch: 5| Step: 2
Training loss: 2.1530044078826904
Validation loss: 2.2232989444527576

Epoch: 5| Step: 3
Training loss: 2.5715065002441406
Validation loss: 2.251554243026241

Epoch: 5| Step: 4
Training loss: 2.2698373794555664
Validation loss: 2.254458704302388

Epoch: 5| Step: 5
Training loss: 2.6710145473480225
Validation loss: 2.253471930821737

Epoch: 5| Step: 6
Training loss: 2.6181232929229736
Validation loss: 2.2436399024019957

Epoch: 5| Step: 7
Training loss: 2.115586042404175
Validation loss: 2.232449180336409

Epoch: 5| Step: 8
Training loss: 2.1972479820251465
Validation loss: 2.239319480875487

Epoch: 5| Step: 9
Training loss: 1.862207055091858
Validation loss: 2.2265179413621143

Epoch: 5| Step: 10
Training loss: 2.741163492202759
Validation loss: 2.2238333507250716

Epoch: 211| Step: 0
Training loss: 2.28507137298584
Validation loss: 2.2424342119565575

Epoch: 5| Step: 1
Training loss: 2.624406337738037
Validation loss: 2.2401594756751932

Epoch: 5| Step: 2
Training loss: 1.4365673065185547
Validation loss: 2.267582634443878

Epoch: 5| Step: 3
Training loss: 2.2108683586120605
Validation loss: 2.307124863388718

Epoch: 5| Step: 4
Training loss: 2.4459939002990723
Validation loss: 2.3255977886979298

Epoch: 5| Step: 5
Training loss: 2.6341941356658936
Validation loss: 2.2693674846362044

Epoch: 5| Step: 6
Training loss: 2.568873643875122
Validation loss: 2.2314763402426117

Epoch: 5| Step: 7
Training loss: 2.2581329345703125
Validation loss: 2.1975810348346667

Epoch: 5| Step: 8
Training loss: 2.831709623336792
Validation loss: 2.1791542255750267

Epoch: 5| Step: 9
Training loss: 2.2825927734375
Validation loss: 2.1904184638812976

Epoch: 5| Step: 10
Training loss: 3.0628700256347656
Validation loss: 2.185980554549925

Epoch: 212| Step: 0
Training loss: 2.288874387741089
Validation loss: 2.1704933002430904

Epoch: 5| Step: 1
Training loss: 2.450216293334961
Validation loss: 2.1884320166803177

Epoch: 5| Step: 2
Training loss: 2.444105863571167
Validation loss: 2.190310897365693

Epoch: 5| Step: 3
Training loss: 2.5059916973114014
Validation loss: 2.202519223254214

Epoch: 5| Step: 4
Training loss: 2.3768887519836426
Validation loss: 2.195829834989322

Epoch: 5| Step: 5
Training loss: 2.7102274894714355
Validation loss: 2.203887349815779

Epoch: 5| Step: 6
Training loss: 2.4502429962158203
Validation loss: 2.2048051023996003

Epoch: 5| Step: 7
Training loss: 2.537142515182495
Validation loss: 2.1823528043685423

Epoch: 5| Step: 8
Training loss: 2.2658543586730957
Validation loss: 2.1943498170504006

Epoch: 5| Step: 9
Training loss: 2.7380073070526123
Validation loss: 2.1989416050654587

Epoch: 5| Step: 10
Training loss: 1.4053350687026978
Validation loss: 2.2065861020036923

Epoch: 213| Step: 0
Training loss: 1.9376342296600342
Validation loss: 2.2024837642587642

Epoch: 5| Step: 1
Training loss: 2.4560160636901855
Validation loss: 2.213973214549403

Epoch: 5| Step: 2
Training loss: 2.457892894744873
Validation loss: 2.2082115373303814

Epoch: 5| Step: 3
Training loss: 2.5665030479431152
Validation loss: 2.2177567071812128

Epoch: 5| Step: 4
Training loss: 2.689187526702881
Validation loss: 2.213613194804038

Epoch: 5| Step: 5
Training loss: 2.4376275539398193
Validation loss: 2.2015522115974018

Epoch: 5| Step: 6
Training loss: 2.2055535316467285
Validation loss: 2.1961713631947837

Epoch: 5| Step: 7
Training loss: 2.9189908504486084
Validation loss: 2.2011230248276905

Epoch: 5| Step: 8
Training loss: 2.5043535232543945
Validation loss: 2.1924373539545203

Epoch: 5| Step: 9
Training loss: 1.909184217453003
Validation loss: 2.199265057040799

Epoch: 5| Step: 10
Training loss: 1.9015058279037476
Validation loss: 2.2038836145913727

Epoch: 214| Step: 0
Training loss: 2.0188775062561035
Validation loss: 2.2166774811283236

Epoch: 5| Step: 1
Training loss: 2.0861222743988037
Validation loss: 2.238820988644836

Epoch: 5| Step: 2
Training loss: 1.8846851587295532
Validation loss: 2.271056798196608

Epoch: 5| Step: 3
Training loss: 2.551600456237793
Validation loss: 2.297670820707916

Epoch: 5| Step: 4
Training loss: 2.3951311111450195
Validation loss: 2.2902695799386628

Epoch: 5| Step: 5
Training loss: 2.466310501098633
Validation loss: 2.2578764833429807

Epoch: 5| Step: 6
Training loss: 2.339193820953369
Validation loss: 2.2469199601040093

Epoch: 5| Step: 7
Training loss: 2.5542776584625244
Validation loss: 2.236624619012238

Epoch: 5| Step: 8
Training loss: 2.1078085899353027
Validation loss: 2.210991895327004

Epoch: 5| Step: 9
Training loss: 2.9240450859069824
Validation loss: 2.2094287833859845

Epoch: 5| Step: 10
Training loss: 2.692394971847534
Validation loss: 2.2116601133859284

Epoch: 215| Step: 0
Training loss: 2.640669584274292
Validation loss: 2.2221492054641887

Epoch: 5| Step: 1
Training loss: 2.611408233642578
Validation loss: 2.2332564579543246

Epoch: 5| Step: 2
Training loss: 2.50639009475708
Validation loss: 2.235353050693389

Epoch: 5| Step: 3
Training loss: 1.8612744808197021
Validation loss: 2.246217299533147

Epoch: 5| Step: 4
Training loss: 2.8858695030212402
Validation loss: 2.237726362802649

Epoch: 5| Step: 5
Training loss: 2.8527235984802246
Validation loss: 2.214151397828133

Epoch: 5| Step: 6
Training loss: 1.9738963842391968
Validation loss: 2.1907668831527873

Epoch: 5| Step: 7
Training loss: 2.1223466396331787
Validation loss: 2.1731712254144813

Epoch: 5| Step: 8
Training loss: 1.8553440570831299
Validation loss: 2.175686959297426

Epoch: 5| Step: 9
Training loss: 2.9188430309295654
Validation loss: 2.169676738400613

Epoch: 5| Step: 10
Training loss: 2.0565102100372314
Validation loss: 2.194539964839976

Epoch: 216| Step: 0
Training loss: 2.7207224369049072
Validation loss: 2.2014951577750583

Epoch: 5| Step: 1
Training loss: 2.829681873321533
Validation loss: 2.2277652704587547

Epoch: 5| Step: 2
Training loss: 2.4538700580596924
Validation loss: 2.2198787530263266

Epoch: 5| Step: 3
Training loss: 1.8674299716949463
Validation loss: 2.2242631091866443

Epoch: 5| Step: 4
Training loss: 2.6148531436920166
Validation loss: 2.2267250860891035

Epoch: 5| Step: 5
Training loss: 2.099943161010742
Validation loss: 2.2044664634171354

Epoch: 5| Step: 6
Training loss: 2.796804904937744
Validation loss: 2.203874813613071

Epoch: 5| Step: 7
Training loss: 1.551628828048706
Validation loss: 2.193003962116857

Epoch: 5| Step: 8
Training loss: 2.2135136127471924
Validation loss: 2.2070162539841025

Epoch: 5| Step: 9
Training loss: 2.546260356903076
Validation loss: 2.207991712836809

Epoch: 5| Step: 10
Training loss: 2.31986141204834
Validation loss: 2.2020366473864486

Epoch: 217| Step: 0
Training loss: 2.5456178188323975
Validation loss: 2.2079721650769635

Epoch: 5| Step: 1
Training loss: 2.0210680961608887
Validation loss: 2.2088874924567437

Epoch: 5| Step: 2
Training loss: 2.044523000717163
Validation loss: 2.205311116351876

Epoch: 5| Step: 3
Training loss: 2.2383298873901367
Validation loss: 2.2028953234354653

Epoch: 5| Step: 4
Training loss: 2.5841658115386963
Validation loss: 2.2016059044868714

Epoch: 5| Step: 5
Training loss: 2.368459701538086
Validation loss: 2.200670514055478

Epoch: 5| Step: 6
Training loss: 2.4731080532073975
Validation loss: 2.2049281007500103

Epoch: 5| Step: 7
Training loss: 2.7978670597076416
Validation loss: 2.205981562214513

Epoch: 5| Step: 8
Training loss: 1.972801923751831
Validation loss: 2.2043031223358645

Epoch: 5| Step: 9
Training loss: 1.9241327047348022
Validation loss: 2.212752180714761

Epoch: 5| Step: 10
Training loss: 2.9031505584716797
Validation loss: 2.2114823607988257

Epoch: 218| Step: 0
Training loss: 1.8661924600601196
Validation loss: 2.2066789301492835

Epoch: 5| Step: 1
Training loss: 2.021428346633911
Validation loss: 2.209919801322363

Epoch: 5| Step: 2
Training loss: 2.4923877716064453
Validation loss: 2.214766299852761

Epoch: 5| Step: 3
Training loss: 2.189291477203369
Validation loss: 2.206712443341491

Epoch: 5| Step: 4
Training loss: 3.360638380050659
Validation loss: 2.2068159195684616

Epoch: 5| Step: 5
Training loss: 2.301668643951416
Validation loss: 2.201821614337224

Epoch: 5| Step: 6
Training loss: 2.1730151176452637
Validation loss: 2.191488322391305

Epoch: 5| Step: 7
Training loss: 2.5584557056427
Validation loss: 2.2156156750135523

Epoch: 5| Step: 8
Training loss: 2.3348772525787354
Validation loss: 2.221832754791424

Epoch: 5| Step: 9
Training loss: 2.167564868927002
Validation loss: 2.210897922515869

Epoch: 5| Step: 10
Training loss: 2.2267398834228516
Validation loss: 2.223443933712539

Epoch: 219| Step: 0
Training loss: 1.5564062595367432
Validation loss: 2.2075104815985567

Epoch: 5| Step: 1
Training loss: 2.633347988128662
Validation loss: 2.2211440442710795

Epoch: 5| Step: 2
Training loss: 2.548367738723755
Validation loss: 2.2083711777963946

Epoch: 5| Step: 3
Training loss: 1.958900809288025
Validation loss: 2.2163679727943997

Epoch: 5| Step: 4
Training loss: 2.497021198272705
Validation loss: 2.2075202670148624

Epoch: 5| Step: 5
Training loss: 2.2624528408050537
Validation loss: 2.186988999766688

Epoch: 5| Step: 6
Training loss: 2.3894686698913574
Validation loss: 2.1768833975638113

Epoch: 5| Step: 7
Training loss: 2.0861165523529053
Validation loss: 2.1789589287132345

Epoch: 5| Step: 8
Training loss: 2.545650005340576
Validation loss: 2.189909573524229

Epoch: 5| Step: 9
Training loss: 2.5920674800872803
Validation loss: 2.1922718055786623

Epoch: 5| Step: 10
Training loss: 2.698678970336914
Validation loss: 2.196986062552339

Epoch: 220| Step: 0
Training loss: 1.7129347324371338
Validation loss: 2.2018518242784726

Epoch: 5| Step: 1
Training loss: 2.1614646911621094
Validation loss: 2.2055081013710267

Epoch: 5| Step: 2
Training loss: 2.080893039703369
Validation loss: 2.179583413626558

Epoch: 5| Step: 3
Training loss: 2.7476203441619873
Validation loss: 2.190087333802254

Epoch: 5| Step: 4
Training loss: 2.1840322017669678
Validation loss: 2.1766231034391668

Epoch: 5| Step: 5
Training loss: 2.3157684803009033
Validation loss: 2.1849729373890865

Epoch: 5| Step: 6
Training loss: 2.320650577545166
Validation loss: 2.1794660322127806

Epoch: 5| Step: 7
Training loss: 2.2988321781158447
Validation loss: 2.1775754523533646

Epoch: 5| Step: 8
Training loss: 2.4333558082580566
Validation loss: 2.181044202978893

Epoch: 5| Step: 9
Training loss: 2.9595890045166016
Validation loss: 2.1757476329803467

Epoch: 5| Step: 10
Training loss: 2.413034677505493
Validation loss: 2.1889530740758425

Epoch: 221| Step: 0
Training loss: 2.2576348781585693
Validation loss: 2.1841786317927863

Epoch: 5| Step: 1
Training loss: 2.772763967514038
Validation loss: 2.1910777156070997

Epoch: 5| Step: 2
Training loss: 2.683394193649292
Validation loss: 2.2144187419645247

Epoch: 5| Step: 3
Training loss: 2.2280325889587402
Validation loss: 2.2104674539258404

Epoch: 5| Step: 4
Training loss: 2.242111921310425
Validation loss: 2.214349642876656

Epoch: 5| Step: 5
Training loss: 2.4053826332092285
Validation loss: 2.2117648124694824

Epoch: 5| Step: 6
Training loss: 1.5669492483139038
Validation loss: 2.2132367523767615

Epoch: 5| Step: 7
Training loss: 2.358168363571167
Validation loss: 2.2075543326716267

Epoch: 5| Step: 8
Training loss: 2.338759660720825
Validation loss: 2.2208904604757986

Epoch: 5| Step: 9
Training loss: 2.1549015045166016
Validation loss: 2.214947485154675

Epoch: 5| Step: 10
Training loss: 2.365530014038086
Validation loss: 2.2071431811137865

Epoch: 222| Step: 0
Training loss: 2.313333511352539
Validation loss: 2.206707536533315

Epoch: 5| Step: 1
Training loss: 1.9287595748901367
Validation loss: 2.197074588908944

Epoch: 5| Step: 2
Training loss: 1.8877092599868774
Validation loss: 2.1921207494633173

Epoch: 5| Step: 3
Training loss: 2.5928640365600586
Validation loss: 2.190080019735521

Epoch: 5| Step: 4
Training loss: 2.136331558227539
Validation loss: 2.1891105431382374

Epoch: 5| Step: 5
Training loss: 2.2945687770843506
Validation loss: 2.193057962643203

Epoch: 5| Step: 6
Training loss: 2.7422542572021484
Validation loss: 2.1849754138659407

Epoch: 5| Step: 7
Training loss: 2.1389272212982178
Validation loss: 2.1616787090096423

Epoch: 5| Step: 8
Training loss: 2.2232227325439453
Validation loss: 2.1771052511789466

Epoch: 5| Step: 9
Training loss: 2.7771079540252686
Validation loss: 2.172492309283185

Epoch: 5| Step: 10
Training loss: 2.4373624324798584
Validation loss: 2.185570219511627

Epoch: 223| Step: 0
Training loss: 1.7335811853408813
Validation loss: 2.2098926062225015

Epoch: 5| Step: 1
Training loss: 2.341749668121338
Validation loss: 2.231031010227819

Epoch: 5| Step: 2
Training loss: 2.2749667167663574
Validation loss: 2.2429527364751345

Epoch: 5| Step: 3
Training loss: 2.5971903800964355
Validation loss: 2.279433624718779

Epoch: 5| Step: 4
Training loss: 2.288409471511841
Validation loss: 2.264226708360898

Epoch: 5| Step: 5
Training loss: 2.713850736618042
Validation loss: 2.2555999345676874

Epoch: 5| Step: 6
Training loss: 2.5412039756774902
Validation loss: 2.24347020733741

Epoch: 5| Step: 7
Training loss: 2.0467541217803955
Validation loss: 2.2581087235481507

Epoch: 5| Step: 8
Training loss: 2.171666383743286
Validation loss: 2.226618560411597

Epoch: 5| Step: 9
Training loss: 2.335477113723755
Validation loss: 2.217808561940347

Epoch: 5| Step: 10
Training loss: 2.3375043869018555
Validation loss: 2.201913833618164

Epoch: 224| Step: 0
Training loss: 2.029186725616455
Validation loss: 2.1709759055927234

Epoch: 5| Step: 1
Training loss: 2.411098003387451
Validation loss: 2.1620061448825303

Epoch: 5| Step: 2
Training loss: 1.892799973487854
Validation loss: 2.1521327546847764

Epoch: 5| Step: 3
Training loss: 2.6212754249572754
Validation loss: 2.1364563203627065

Epoch: 5| Step: 4
Training loss: 2.603400707244873
Validation loss: 2.1491411808998353

Epoch: 5| Step: 5
Training loss: 2.5645012855529785
Validation loss: 2.1473241775266585

Epoch: 5| Step: 6
Training loss: 2.4540412425994873
Validation loss: 2.1379263016485397

Epoch: 5| Step: 7
Training loss: 1.7812144756317139
Validation loss: 2.1491912154741186

Epoch: 5| Step: 8
Training loss: 1.9927078485488892
Validation loss: 2.1507334529712634

Epoch: 5| Step: 9
Training loss: 2.2042901515960693
Validation loss: 2.1666801642346125

Epoch: 5| Step: 10
Training loss: 3.004971742630005
Validation loss: 2.180872012210149

Epoch: 225| Step: 0
Training loss: 2.11212420463562
Validation loss: 2.223297695959768

Epoch: 5| Step: 1
Training loss: 2.2552690505981445
Validation loss: 2.239229941880831

Epoch: 5| Step: 2
Training loss: 2.3081328868865967
Validation loss: 2.2437835970232562

Epoch: 5| Step: 3
Training loss: 2.1132383346557617
Validation loss: 2.2604361311081917

Epoch: 5| Step: 4
Training loss: 2.6870055198669434
Validation loss: 2.25260337193807

Epoch: 5| Step: 5
Training loss: 2.2400882244110107
Validation loss: 2.220233109689528

Epoch: 5| Step: 6
Training loss: 2.6546196937561035
Validation loss: 2.2089096756391626

Epoch: 5| Step: 7
Training loss: 2.308140754699707
Validation loss: 2.188511786922332

Epoch: 5| Step: 8
Training loss: 2.4799375534057617
Validation loss: 2.1773776751692577

Epoch: 5| Step: 9
Training loss: 2.025385856628418
Validation loss: 2.1716541500501734

Epoch: 5| Step: 10
Training loss: 2.057081699371338
Validation loss: 2.1756814731064664

Epoch: 226| Step: 0
Training loss: 2.108747959136963
Validation loss: 2.1862453286365797

Epoch: 5| Step: 1
Training loss: 2.690420627593994
Validation loss: 2.1812779172774284

Epoch: 5| Step: 2
Training loss: 2.92248797416687
Validation loss: 2.1918190961243003

Epoch: 5| Step: 3
Training loss: 2.035311222076416
Validation loss: 2.1918862686362317

Epoch: 5| Step: 4
Training loss: 1.6827688217163086
Validation loss: 2.19135703579072

Epoch: 5| Step: 5
Training loss: 1.8508237600326538
Validation loss: 2.1888844300341863

Epoch: 5| Step: 6
Training loss: 2.4504904747009277
Validation loss: 2.2157690255872664

Epoch: 5| Step: 7
Training loss: 2.7553718090057373
Validation loss: 2.215603418247674

Epoch: 5| Step: 8
Training loss: 2.401139497756958
Validation loss: 2.2417930505609

Epoch: 5| Step: 9
Training loss: 2.190359354019165
Validation loss: 2.266965327724334

Epoch: 5| Step: 10
Training loss: 1.9523468017578125
Validation loss: 2.266126940327306

Epoch: 227| Step: 0
Training loss: 2.0214836597442627
Validation loss: 2.25901170187099

Epoch: 5| Step: 1
Training loss: 2.2410435676574707
Validation loss: 2.2693068006987214

Epoch: 5| Step: 2
Training loss: 2.0022552013397217
Validation loss: 2.2832649241211596

Epoch: 5| Step: 3
Training loss: 1.878922700881958
Validation loss: 2.264347235361735

Epoch: 5| Step: 4
Training loss: 2.729280710220337
Validation loss: 2.2325745910726567

Epoch: 5| Step: 5
Training loss: 1.9521602392196655
Validation loss: 2.2001733818361835

Epoch: 5| Step: 6
Training loss: 2.1206493377685547
Validation loss: 2.185918361909928

Epoch: 5| Step: 7
Training loss: 2.5526809692382812
Validation loss: 2.1809170630670365

Epoch: 5| Step: 8
Training loss: 2.318138837814331
Validation loss: 2.1836319790091565

Epoch: 5| Step: 9
Training loss: 2.6647448539733887
Validation loss: 2.189668188812912

Epoch: 5| Step: 10
Training loss: 2.7929513454437256
Validation loss: 2.1749713318322295

Epoch: 228| Step: 0
Training loss: 2.446589946746826
Validation loss: 2.180889409075501

Epoch: 5| Step: 1
Training loss: 2.082642078399658
Validation loss: 2.1938613819819626

Epoch: 5| Step: 2
Training loss: 1.820014238357544
Validation loss: 2.1980678907004734

Epoch: 5| Step: 3
Training loss: 1.9141794443130493
Validation loss: 2.2040979708394697

Epoch: 5| Step: 4
Training loss: 2.3083441257476807
Validation loss: 2.2166576308588826

Epoch: 5| Step: 5
Training loss: 2.7094807624816895
Validation loss: 2.1966401402668287

Epoch: 5| Step: 6
Training loss: 2.3145105838775635
Validation loss: 2.2040672353518906

Epoch: 5| Step: 7
Training loss: 2.5415539741516113
Validation loss: 2.1999534099332747

Epoch: 5| Step: 8
Training loss: 2.5830283164978027
Validation loss: 2.201325579356122

Epoch: 5| Step: 9
Training loss: 1.9476184844970703
Validation loss: 2.1864296877256004

Epoch: 5| Step: 10
Training loss: 2.2403719425201416
Validation loss: 2.1804432817684707

Epoch: 229| Step: 0
Training loss: 2.8105475902557373
Validation loss: 2.188612537999307

Epoch: 5| Step: 1
Training loss: 1.860954999923706
Validation loss: 2.1882910600272556

Epoch: 5| Step: 2
Training loss: 2.1245827674865723
Validation loss: 2.2164053147838962

Epoch: 5| Step: 3
Training loss: 2.605721950531006
Validation loss: 2.209468618515999

Epoch: 5| Step: 4
Training loss: 2.062497854232788
Validation loss: 2.210328027766238

Epoch: 5| Step: 5
Training loss: 2.6486775875091553
Validation loss: 2.219428300857544

Epoch: 5| Step: 6
Training loss: 2.1451144218444824
Validation loss: 2.1986095751485517

Epoch: 5| Step: 7
Training loss: 2.015822172164917
Validation loss: 2.184049016685896

Epoch: 5| Step: 8
Training loss: 2.390063762664795
Validation loss: 2.1687324534180346

Epoch: 5| Step: 9
Training loss: 1.9321311712265015
Validation loss: 2.1843694999653804

Epoch: 5| Step: 10
Training loss: 2.572880506515503
Validation loss: 2.189707681696902

Epoch: 230| Step: 0
Training loss: 2.3910069465637207
Validation loss: 2.2150936947073987

Epoch: 5| Step: 1
Training loss: 2.9836814403533936
Validation loss: 2.224130602293117

Epoch: 5| Step: 2
Training loss: 2.2920620441436768
Validation loss: 2.220053457444714

Epoch: 5| Step: 3
Training loss: 1.8318891525268555
Validation loss: 2.203460908705188

Epoch: 5| Step: 4
Training loss: 1.936220407485962
Validation loss: 2.1968734418192217

Epoch: 5| Step: 5
Training loss: 2.44396710395813
Validation loss: 2.187980718510125

Epoch: 5| Step: 6
Training loss: 2.15327525138855
Validation loss: 2.2040145345913467

Epoch: 5| Step: 7
Training loss: 2.92049503326416
Validation loss: 2.2049059637131228

Epoch: 5| Step: 8
Training loss: 2.639125108718872
Validation loss: 2.178652186547556

Epoch: 5| Step: 9
Training loss: 1.7380523681640625
Validation loss: 2.1957774034110447

Epoch: 5| Step: 10
Training loss: 1.5880613327026367
Validation loss: 2.1869101447443806

Epoch: 231| Step: 0
Training loss: 2.0497336387634277
Validation loss: 2.1978017989025322

Epoch: 5| Step: 1
Training loss: 2.4783172607421875
Validation loss: 2.2041276039615756

Epoch: 5| Step: 2
Training loss: 2.163587808609009
Validation loss: 2.202973590102247

Epoch: 5| Step: 3
Training loss: 2.2640693187713623
Validation loss: 2.207455628661699

Epoch: 5| Step: 4
Training loss: 2.5642571449279785
Validation loss: 2.209551134417134

Epoch: 5| Step: 5
Training loss: 1.4565918445587158
Validation loss: 2.212770679945587

Epoch: 5| Step: 6
Training loss: 2.229348659515381
Validation loss: 2.1877220522972847

Epoch: 5| Step: 7
Training loss: 3.0056843757629395
Validation loss: 2.1932872982435327

Epoch: 5| Step: 8
Training loss: 2.055333375930786
Validation loss: 2.1780003706614175

Epoch: 5| Step: 9
Training loss: 2.357417106628418
Validation loss: 2.178880483873429

Epoch: 5| Step: 10
Training loss: 2.083514928817749
Validation loss: 2.174881465973393

Epoch: 232| Step: 0
Training loss: 1.7808881998062134
Validation loss: 2.1670458496257825

Epoch: 5| Step: 1
Training loss: 2.3540945053100586
Validation loss: 2.174257396369852

Epoch: 5| Step: 2
Training loss: 2.7800793647766113
Validation loss: 2.182214516465382

Epoch: 5| Step: 3
Training loss: 2.324866533279419
Validation loss: 2.167517367229667

Epoch: 5| Step: 4
Training loss: 1.726243019104004
Validation loss: 2.171575500119117

Epoch: 5| Step: 5
Training loss: 2.6301586627960205
Validation loss: 2.174481088115323

Epoch: 5| Step: 6
Training loss: 2.631868839263916
Validation loss: 2.18139793667742

Epoch: 5| Step: 7
Training loss: 1.815073013305664
Validation loss: 2.1731954056729554

Epoch: 5| Step: 8
Training loss: 2.2268595695495605
Validation loss: 2.173345183813444

Epoch: 5| Step: 9
Training loss: 2.000239849090576
Validation loss: 2.172929407447897

Epoch: 5| Step: 10
Training loss: 2.3429858684539795
Validation loss: 2.179173384943316

Epoch: 233| Step: 0
Training loss: 2.4014649391174316
Validation loss: 2.1928284911699194

Epoch: 5| Step: 1
Training loss: 1.9170541763305664
Validation loss: 2.181689526445122

Epoch: 5| Step: 2
Training loss: 2.6177122592926025
Validation loss: 2.193207827947473

Epoch: 5| Step: 3
Training loss: 1.9871962070465088
Validation loss: 2.188729522048786

Epoch: 5| Step: 4
Training loss: 1.9046764373779297
Validation loss: 2.2050825165164087

Epoch: 5| Step: 5
Training loss: 2.5375747680664062
Validation loss: 2.205517856023645

Epoch: 5| Step: 6
Training loss: 1.9734541177749634
Validation loss: 2.2118726468855336

Epoch: 5| Step: 7
Training loss: 2.26151704788208
Validation loss: 2.2096739686945432

Epoch: 5| Step: 8
Training loss: 1.6770169734954834
Validation loss: 2.23208793517082

Epoch: 5| Step: 9
Training loss: 2.6338047981262207
Validation loss: 2.2506491702090026

Epoch: 5| Step: 10
Training loss: 2.6153488159179688
Validation loss: 2.24235781802926

Epoch: 234| Step: 0
Training loss: 2.033473491668701
Validation loss: 2.232064357367895

Epoch: 5| Step: 1
Training loss: 2.3581466674804688
Validation loss: 2.206224130045983

Epoch: 5| Step: 2
Training loss: 2.386293888092041
Validation loss: 2.1934215099580827

Epoch: 5| Step: 3
Training loss: 1.7398340702056885
Validation loss: 2.185712347748459

Epoch: 5| Step: 4
Training loss: 2.074857473373413
Validation loss: 2.179976381281371

Epoch: 5| Step: 5
Training loss: 3.1406471729278564
Validation loss: 2.1722428798675537

Epoch: 5| Step: 6
Training loss: 2.2660927772521973
Validation loss: 2.1719321973862185

Epoch: 5| Step: 7
Training loss: 1.622560739517212
Validation loss: 2.159625614843061

Epoch: 5| Step: 8
Training loss: 1.9277406930923462
Validation loss: 2.1593224989470614

Epoch: 5| Step: 9
Training loss: 2.511723041534424
Validation loss: 2.166086930100636

Epoch: 5| Step: 10
Training loss: 2.4055230617523193
Validation loss: 2.1639035773533646

Epoch: 235| Step: 0
Training loss: 1.9129997491836548
Validation loss: 2.1834047520032493

Epoch: 5| Step: 1
Training loss: 2.7827136516571045
Validation loss: 2.1721254394900416

Epoch: 5| Step: 2
Training loss: 2.3467578887939453
Validation loss: 2.1573177511974047

Epoch: 5| Step: 3
Training loss: 1.752606749534607
Validation loss: 2.174835802406393

Epoch: 5| Step: 4
Training loss: 2.865492582321167
Validation loss: 2.1892944843538347

Epoch: 5| Step: 5
Training loss: 2.2055373191833496
Validation loss: 2.209103997035693

Epoch: 5| Step: 6
Training loss: 1.9014819860458374
Validation loss: 2.194042964648175

Epoch: 5| Step: 7
Training loss: 2.330134868621826
Validation loss: 2.1838336862543577

Epoch: 5| Step: 8
Training loss: 2.5306124687194824
Validation loss: 2.1736308618258406

Epoch: 5| Step: 9
Training loss: 2.0216026306152344
Validation loss: 2.1715159800744828

Epoch: 5| Step: 10
Training loss: 1.9203239679336548
Validation loss: 2.189757498361731

Epoch: 236| Step: 0
Training loss: 2.412877082824707
Validation loss: 2.2004662585514847

Epoch: 5| Step: 1
Training loss: 2.036377191543579
Validation loss: 2.2224408811138523

Epoch: 5| Step: 2
Training loss: 2.2873682975769043
Validation loss: 2.2502172377801712

Epoch: 5| Step: 3
Training loss: 2.0988433361053467
Validation loss: 2.2528922019466275

Epoch: 5| Step: 4
Training loss: 2.0892021656036377
Validation loss: 2.2520509894176195

Epoch: 5| Step: 5
Training loss: 2.0641965866088867
Validation loss: 2.224630924963182

Epoch: 5| Step: 6
Training loss: 2.786856174468994
Validation loss: 2.2225613824782835

Epoch: 5| Step: 7
Training loss: 2.555945634841919
Validation loss: 2.2155336103131695

Epoch: 5| Step: 8
Training loss: 1.8556041717529297
Validation loss: 2.197717833262618

Epoch: 5| Step: 9
Training loss: 2.1190381050109863
Validation loss: 2.198582172393799

Epoch: 5| Step: 10
Training loss: 2.316518545150757
Validation loss: 2.210819459730579

Epoch: 237| Step: 0
Training loss: 2.3552792072296143
Validation loss: 2.1912304970525924

Epoch: 5| Step: 1
Training loss: 1.5519757270812988
Validation loss: 2.1720223093545563

Epoch: 5| Step: 2
Training loss: 2.5459651947021484
Validation loss: 2.152674477587464

Epoch: 5| Step: 3
Training loss: 2.230292558670044
Validation loss: 2.1518663257680912

Epoch: 5| Step: 4
Training loss: 2.307849407196045
Validation loss: 2.1639435086199033

Epoch: 5| Step: 5
Training loss: 2.574765920639038
Validation loss: 2.171901769535516

Epoch: 5| Step: 6
Training loss: 2.271597385406494
Validation loss: 2.1978374924711

Epoch: 5| Step: 7
Training loss: 2.1399099826812744
Validation loss: 2.2157265268346316

Epoch: 5| Step: 8
Training loss: 1.6559267044067383
Validation loss: 2.20960114079137

Epoch: 5| Step: 9
Training loss: 2.3818583488464355
Validation loss: 2.193366709575858

Epoch: 5| Step: 10
Training loss: 2.683534622192383
Validation loss: 2.1755302439453783

Epoch: 238| Step: 0
Training loss: 1.8475697040557861
Validation loss: 2.173067513332572

Epoch: 5| Step: 1
Training loss: 2.026841163635254
Validation loss: 2.168182821683986

Epoch: 5| Step: 2
Training loss: 2.1375248432159424
Validation loss: 2.1902624304576586

Epoch: 5| Step: 3
Training loss: 1.9669405221939087
Validation loss: 2.188605487987559

Epoch: 5| Step: 4
Training loss: 2.3903462886810303
Validation loss: 2.1853193313844743

Epoch: 5| Step: 5
Training loss: 2.0970921516418457
Validation loss: 2.1982380215839674

Epoch: 5| Step: 6
Training loss: 2.2614972591400146
Validation loss: 2.182878727553993

Epoch: 5| Step: 7
Training loss: 2.258527994155884
Validation loss: 2.1795545803603305

Epoch: 5| Step: 8
Training loss: 2.299644708633423
Validation loss: 2.1777991338442733

Epoch: 5| Step: 9
Training loss: 2.832598924636841
Validation loss: 2.1753308670495146

Epoch: 5| Step: 10
Training loss: 2.106597900390625
Validation loss: 2.1703986083307574

Epoch: 239| Step: 0
Training loss: 2.364100933074951
Validation loss: 2.1814486390800885

Epoch: 5| Step: 1
Training loss: 2.4204840660095215
Validation loss: 2.178601098316972

Epoch: 5| Step: 2
Training loss: 2.3874940872192383
Validation loss: 2.1611964164241666

Epoch: 5| Step: 3
Training loss: 2.264495849609375
Validation loss: 2.1654452764859764

Epoch: 5| Step: 4
Training loss: 2.631070613861084
Validation loss: 2.159272442581833

Epoch: 5| Step: 5
Training loss: 1.7300913333892822
Validation loss: 2.1659226661087363

Epoch: 5| Step: 6
Training loss: 2.0789713859558105
Validation loss: 2.1636594777466147

Epoch: 5| Step: 7
Training loss: 2.782435894012451
Validation loss: 2.1606280342225106

Epoch: 5| Step: 8
Training loss: 1.2489335536956787
Validation loss: 2.166879082238802

Epoch: 5| Step: 9
Training loss: 2.0123291015625
Validation loss: 2.1847460334018995

Epoch: 5| Step: 10
Training loss: 2.2485299110412598
Validation loss: 2.1913090162379767

Epoch: 240| Step: 0
Training loss: 2.0947425365448
Validation loss: 2.190758384684081

Epoch: 5| Step: 1
Training loss: 1.8529762029647827
Validation loss: 2.193185624255929

Epoch: 5| Step: 2
Training loss: 2.207113742828369
Validation loss: 2.1788171183678413

Epoch: 5| Step: 3
Training loss: 1.7600319385528564
Validation loss: 2.1615933577219644

Epoch: 5| Step: 4
Training loss: 3.1076478958129883
Validation loss: 2.169405238602751

Epoch: 5| Step: 5
Training loss: 2.227339267730713
Validation loss: 2.175256916271743

Epoch: 5| Step: 6
Training loss: 1.7975692749023438
Validation loss: 2.172298682633267

Epoch: 5| Step: 7
Training loss: 2.8468666076660156
Validation loss: 2.159749436122115

Epoch: 5| Step: 8
Training loss: 1.8819230794906616
Validation loss: 2.1427321664748655

Epoch: 5| Step: 9
Training loss: 2.241384983062744
Validation loss: 2.1304327698164087

Epoch: 5| Step: 10
Training loss: 2.0464344024658203
Validation loss: 2.128274402310771

Epoch: 241| Step: 0
Training loss: 1.7563869953155518
Validation loss: 2.127065248386834

Epoch: 5| Step: 1
Training loss: 2.433032751083374
Validation loss: 2.1410362797398723

Epoch: 5| Step: 2
Training loss: 2.8058979511260986
Validation loss: 2.1564270283586238

Epoch: 5| Step: 3
Training loss: 2.829808473587036
Validation loss: 2.156037840791928

Epoch: 5| Step: 4
Training loss: 2.381120204925537
Validation loss: 2.170893870374208

Epoch: 5| Step: 5
Training loss: 1.9342231750488281
Validation loss: 2.1772895679678967

Epoch: 5| Step: 6
Training loss: 2.0344440937042236
Validation loss: 2.1904909226202194

Epoch: 5| Step: 7
Training loss: 2.086885929107666
Validation loss: 2.1912337554398404

Epoch: 5| Step: 8
Training loss: 1.1330959796905518
Validation loss: 2.1834297680085704

Epoch: 5| Step: 9
Training loss: 2.3493897914886475
Validation loss: 2.1794218273573023

Epoch: 5| Step: 10
Training loss: 2.1569526195526123
Validation loss: 2.180342114099892

Epoch: 242| Step: 0
Training loss: 1.350273847579956
Validation loss: 2.1861683066173265

Epoch: 5| Step: 1
Training loss: 2.204113483428955
Validation loss: 2.182722326247923

Epoch: 5| Step: 2
Training loss: 2.030034303665161
Validation loss: 2.1628710044327604

Epoch: 5| Step: 3
Training loss: 2.028221607208252
Validation loss: 2.1704372564951577

Epoch: 5| Step: 4
Training loss: 2.1910390853881836
Validation loss: 2.175244931251772

Epoch: 5| Step: 5
Training loss: 2.6159043312072754
Validation loss: 2.1834887330250075

Epoch: 5| Step: 6
Training loss: 1.4068642854690552
Validation loss: 2.1790817527360815

Epoch: 5| Step: 7
Training loss: 2.9540743827819824
Validation loss: 2.1677227917537896

Epoch: 5| Step: 8
Training loss: 2.8007190227508545
Validation loss: 2.155116496547576

Epoch: 5| Step: 9
Training loss: 2.270350217819214
Validation loss: 2.1417343590849187

Epoch: 5| Step: 10
Training loss: 2.1040897369384766
Validation loss: 2.1302757955366567

Epoch: 243| Step: 0
Training loss: 2.612560749053955
Validation loss: 2.141374718758368

Epoch: 5| Step: 1
Training loss: 2.5282344818115234
Validation loss: 2.131562679044662

Epoch: 5| Step: 2
Training loss: 2.350306749343872
Validation loss: 2.135832163595384

Epoch: 5| Step: 3
Training loss: 1.9959627389907837
Validation loss: 2.141878269051993

Epoch: 5| Step: 4
Training loss: 1.896588683128357
Validation loss: 2.1455805558030323

Epoch: 5| Step: 5
Training loss: 2.3343911170959473
Validation loss: 2.1374576450676046

Epoch: 5| Step: 6
Training loss: 2.0041751861572266
Validation loss: 2.144449867228026

Epoch: 5| Step: 7
Training loss: 2.37052059173584
Validation loss: 2.155547031792261

Epoch: 5| Step: 8
Training loss: 1.8174326419830322
Validation loss: 2.1499552021744432

Epoch: 5| Step: 9
Training loss: 1.9204657077789307
Validation loss: 2.1714093441604287

Epoch: 5| Step: 10
Training loss: 2.0428972244262695
Validation loss: 2.1741504464098202

Epoch: 244| Step: 0
Training loss: 1.8637888431549072
Validation loss: 2.1766822517559095

Epoch: 5| Step: 1
Training loss: 2.7636778354644775
Validation loss: 2.168532416384707

Epoch: 5| Step: 2
Training loss: 2.169550895690918
Validation loss: 2.146249645499773

Epoch: 5| Step: 3
Training loss: 2.80426287651062
Validation loss: 2.1461233656893492

Epoch: 5| Step: 4
Training loss: 1.4374735355377197
Validation loss: 2.1408702711905203

Epoch: 5| Step: 5
Training loss: 1.5967367887496948
Validation loss: 2.1294578813737437

Epoch: 5| Step: 6
Training loss: 2.052462100982666
Validation loss: 2.141425976189234

Epoch: 5| Step: 7
Training loss: 1.9628431797027588
Validation loss: 2.1433189004980107

Epoch: 5| Step: 8
Training loss: 2.3153789043426514
Validation loss: 2.1721134775428363

Epoch: 5| Step: 9
Training loss: 2.3753821849823
Validation loss: 2.1722357029555948

Epoch: 5| Step: 10
Training loss: 2.539855718612671
Validation loss: 2.1887484583803403

Epoch: 245| Step: 0
Training loss: 1.8289114236831665
Validation loss: 2.1896490050900366

Epoch: 5| Step: 1
Training loss: 1.9931875467300415
Validation loss: 2.196030657778504

Epoch: 5| Step: 2
Training loss: 2.48165225982666
Validation loss: 2.1999441769815262

Epoch: 5| Step: 3
Training loss: 2.465317726135254
Validation loss: 2.1835323892613894

Epoch: 5| Step: 4
Training loss: 2.3370556831359863
Validation loss: 2.1706188532613937

Epoch: 5| Step: 5
Training loss: 2.011329174041748
Validation loss: 2.158625307903495

Epoch: 5| Step: 6
Training loss: 2.7198357582092285
Validation loss: 2.1667335623054096

Epoch: 5| Step: 7
Training loss: 2.0308148860931396
Validation loss: 2.15639268454685

Epoch: 5| Step: 8
Training loss: 1.8797528743743896
Validation loss: 2.1744072309104343

Epoch: 5| Step: 9
Training loss: 1.7318270206451416
Validation loss: 2.184868877933871

Epoch: 5| Step: 10
Training loss: 2.265468120574951
Validation loss: 2.1676242172077136

Epoch: 246| Step: 0
Training loss: 2.2149200439453125
Validation loss: 2.1821268861011793

Epoch: 5| Step: 1
Training loss: 2.559147357940674
Validation loss: 2.173264957243396

Epoch: 5| Step: 2
Training loss: 2.362043857574463
Validation loss: 2.1795234205902263

Epoch: 5| Step: 3
Training loss: 2.1008646488189697
Validation loss: 2.14814954932018

Epoch: 5| Step: 4
Training loss: 2.067131519317627
Validation loss: 2.121350574237044

Epoch: 5| Step: 5
Training loss: 1.7496860027313232
Validation loss: 2.140059863367388

Epoch: 5| Step: 6
Training loss: 1.9907302856445312
Validation loss: 2.156086907591871

Epoch: 5| Step: 7
Training loss: 2.505241870880127
Validation loss: 2.1579490220674904

Epoch: 5| Step: 8
Training loss: 2.3899049758911133
Validation loss: 2.1463513169237363

Epoch: 5| Step: 9
Training loss: 1.9194214344024658
Validation loss: 2.1497040076922347

Epoch: 5| Step: 10
Training loss: 2.265385866165161
Validation loss: 2.136960332111646

Epoch: 247| Step: 0
Training loss: 2.0002083778381348
Validation loss: 2.1401864328692035

Epoch: 5| Step: 1
Training loss: 2.00193452835083
Validation loss: 2.1657096237264652

Epoch: 5| Step: 2
Training loss: 2.068601131439209
Validation loss: 2.2050367862947526

Epoch: 5| Step: 3
Training loss: 1.8192278146743774
Validation loss: 2.2203443101657334

Epoch: 5| Step: 4
Training loss: 2.1269867420196533
Validation loss: 2.2450157980765066

Epoch: 5| Step: 5
Training loss: 2.3215460777282715
Validation loss: 2.246241731028403

Epoch: 5| Step: 6
Training loss: 1.7727372646331787
Validation loss: 2.23872180907957

Epoch: 5| Step: 7
Training loss: 2.2159905433654785
Validation loss: 2.209879385527744

Epoch: 5| Step: 8
Training loss: 2.322932720184326
Validation loss: 2.1703489365116244

Epoch: 5| Step: 9
Training loss: 2.3207616806030273
Validation loss: 2.1701362697027062

Epoch: 5| Step: 10
Training loss: 2.777505874633789
Validation loss: 2.1497533757199525

Epoch: 248| Step: 0
Training loss: 1.6946134567260742
Validation loss: 2.1349514607460267

Epoch: 5| Step: 1
Training loss: 2.1219403743743896
Validation loss: 2.113919614463724

Epoch: 5| Step: 2
Training loss: 2.345940589904785
Validation loss: 2.1154701761020127

Epoch: 5| Step: 3
Training loss: 2.204336404800415
Validation loss: 2.1020862594727547

Epoch: 5| Step: 4
Training loss: 2.292728900909424
Validation loss: 2.123294923895149

Epoch: 5| Step: 5
Training loss: 2.4743781089782715
Validation loss: 2.1357914619548346

Epoch: 5| Step: 6
Training loss: 1.853226661682129
Validation loss: 2.150125806049634

Epoch: 5| Step: 7
Training loss: 2.4361274242401123
Validation loss: 2.1783930024793072

Epoch: 5| Step: 8
Training loss: 2.166814088821411
Validation loss: 2.1767073292886057

Epoch: 5| Step: 9
Training loss: 1.933854103088379
Validation loss: 2.190769680084721

Epoch: 5| Step: 10
Training loss: 2.2624690532684326
Validation loss: 2.2065471782479236

Epoch: 249| Step: 0
Training loss: 1.9372285604476929
Validation loss: 2.1896692040146037

Epoch: 5| Step: 1
Training loss: 2.5711874961853027
Validation loss: 2.193040347868396

Epoch: 5| Step: 2
Training loss: 2.0050790309906006
Validation loss: 2.193154869541045

Epoch: 5| Step: 3
Training loss: 2.009207248687744
Validation loss: 2.1767249568816154

Epoch: 5| Step: 4
Training loss: 1.803598165512085
Validation loss: 2.1823093198960826

Epoch: 5| Step: 5
Training loss: 2.8010849952697754
Validation loss: 2.146741335109998

Epoch: 5| Step: 6
Training loss: 1.9162895679473877
Validation loss: 2.1318028152629895

Epoch: 5| Step: 7
Training loss: 2.470195770263672
Validation loss: 2.11801847334831

Epoch: 5| Step: 8
Training loss: 1.9614009857177734
Validation loss: 2.126570055561681

Epoch: 5| Step: 9
Training loss: 2.051119327545166
Validation loss: 2.1199603901114514

Epoch: 5| Step: 10
Training loss: 1.9291677474975586
Validation loss: 2.126668696762413

Epoch: 250| Step: 0
Training loss: 2.0029876232147217
Validation loss: 2.1308659635564333

Epoch: 5| Step: 1
Training loss: 2.3922057151794434
Validation loss: 2.1405385796741774

Epoch: 5| Step: 2
Training loss: 2.0757529735565186
Validation loss: 2.1379269053859096

Epoch: 5| Step: 3
Training loss: 1.7825281620025635
Validation loss: 2.1480009658362276

Epoch: 5| Step: 4
Training loss: 2.002685070037842
Validation loss: 2.1619833618082027

Epoch: 5| Step: 5
Training loss: 2.625131130218506
Validation loss: 2.15546449025472

Epoch: 5| Step: 6
Training loss: 2.1051080226898193
Validation loss: 2.156947489707701

Epoch: 5| Step: 7
Training loss: 2.4328737258911133
Validation loss: 2.150848214344312

Epoch: 5| Step: 8
Training loss: 2.142901659011841
Validation loss: 2.1564701346940893

Epoch: 5| Step: 9
Training loss: 1.9020802974700928
Validation loss: 2.1664142506096953

Epoch: 5| Step: 10
Training loss: 2.0970375537872314
Validation loss: 2.187765516260619

Epoch: 251| Step: 0
Training loss: 2.422121524810791
Validation loss: 2.175751957842099

Epoch: 5| Step: 1
Training loss: 2.124276638031006
Validation loss: 2.175239445060812

Epoch: 5| Step: 2
Training loss: 2.0149121284484863
Validation loss: 2.1471464813396497

Epoch: 5| Step: 3
Training loss: 2.094722270965576
Validation loss: 2.138201170070197

Epoch: 5| Step: 4
Training loss: 2.3914759159088135
Validation loss: 2.120333456224011

Epoch: 5| Step: 5
Training loss: 1.9372364282608032
Validation loss: 2.1351245000798214

Epoch: 5| Step: 6
Training loss: 2.0668816566467285
Validation loss: 2.131920314604236

Epoch: 5| Step: 7
Training loss: 2.0581960678100586
Validation loss: 2.153456787909231

Epoch: 5| Step: 8
Training loss: 2.574901580810547
Validation loss: 2.173763839147424

Epoch: 5| Step: 9
Training loss: 1.7540889978408813
Validation loss: 2.173029940615418

Epoch: 5| Step: 10
Training loss: 2.116816997528076
Validation loss: 2.1602952249588503

Epoch: 252| Step: 0
Training loss: 2.4887421131134033
Validation loss: 2.1524848989261094

Epoch: 5| Step: 1
Training loss: 1.6267318725585938
Validation loss: 2.155492498028663

Epoch: 5| Step: 2
Training loss: 3.086949586868286
Validation loss: 2.169522152152113

Epoch: 5| Step: 3
Training loss: 2.4033756256103516
Validation loss: 2.1846298581810406

Epoch: 5| Step: 4
Training loss: 2.1028859615325928
Validation loss: 2.1878482052074966

Epoch: 5| Step: 5
Training loss: 2.9501214027404785
Validation loss: 2.1954897911317888

Epoch: 5| Step: 6
Training loss: 1.4905786514282227
Validation loss: 2.17207214396487

Epoch: 5| Step: 7
Training loss: 1.7178363800048828
Validation loss: 2.165100569366127

Epoch: 5| Step: 8
Training loss: 1.6868280172348022
Validation loss: 2.145039548156082

Epoch: 5| Step: 9
Training loss: 1.5525137186050415
Validation loss: 2.131836337427939

Epoch: 5| Step: 10
Training loss: 2.3197169303894043
Validation loss: 2.1402010853572557

Epoch: 253| Step: 0
Training loss: 1.5059782266616821
Validation loss: 2.1292565509837162

Epoch: 5| Step: 1
Training loss: 2.500645160675049
Validation loss: 2.1541036123870523

Epoch: 5| Step: 2
Training loss: 2.367969512939453
Validation loss: 2.1689190403107674

Epoch: 5| Step: 3
Training loss: 2.0892155170440674
Validation loss: 2.1821644844547397

Epoch: 5| Step: 4
Training loss: 2.2944374084472656
Validation loss: 2.183133320141864

Epoch: 5| Step: 5
Training loss: 2.3859355449676514
Validation loss: 2.165485817898986

Epoch: 5| Step: 6
Training loss: 2.5148465633392334
Validation loss: 2.1386163491074757

Epoch: 5| Step: 7
Training loss: 1.9267818927764893
Validation loss: 2.1460373247823408

Epoch: 5| Step: 8
Training loss: 1.4869381189346313
Validation loss: 2.1132177024759273

Epoch: 5| Step: 9
Training loss: 2.0722336769104004
Validation loss: 2.125588875944896

Epoch: 5| Step: 10
Training loss: 2.130460023880005
Validation loss: 2.132110611084969

Epoch: 254| Step: 0
Training loss: 2.1480345726013184
Validation loss: 2.1325189887836413

Epoch: 5| Step: 1
Training loss: 2.37563157081604
Validation loss: 2.13489080116313

Epoch: 5| Step: 2
Training loss: 2.6284339427948
Validation loss: 2.1259637263513382

Epoch: 5| Step: 3
Training loss: 1.894075632095337
Validation loss: 2.144235307170499

Epoch: 5| Step: 4
Training loss: 2.1449685096740723
Validation loss: 2.17832923576396

Epoch: 5| Step: 5
Training loss: 1.5592823028564453
Validation loss: 2.163708963701802

Epoch: 5| Step: 6
Training loss: 2.2074100971221924
Validation loss: 2.158654410351989

Epoch: 5| Step: 7
Training loss: 2.0833799839019775
Validation loss: 2.1814198032502206

Epoch: 5| Step: 8
Training loss: 2.244680404663086
Validation loss: 2.1791479959282825

Epoch: 5| Step: 9
Training loss: 1.9430923461914062
Validation loss: 2.1818867268100863

Epoch: 5| Step: 10
Training loss: 2.146463394165039
Validation loss: 2.195013315446915

Epoch: 255| Step: 0
Training loss: 1.2638602256774902
Validation loss: 2.1828304824008735

Epoch: 5| Step: 1
Training loss: 2.7416625022888184
Validation loss: 2.1875635295785885

Epoch: 5| Step: 2
Training loss: 2.2247233390808105
Validation loss: 2.1769182297491256

Epoch: 5| Step: 3
Training loss: 2.672541379928589
Validation loss: 2.1533424264641217

Epoch: 5| Step: 4
Training loss: 2.3834872245788574
Validation loss: 2.1471702257792153

Epoch: 5| Step: 5
Training loss: 2.098787784576416
Validation loss: 2.144066492716471

Epoch: 5| Step: 6
Training loss: 1.837856650352478
Validation loss: 2.1640382171959005

Epoch: 5| Step: 7
Training loss: 1.8114382028579712
Validation loss: 2.1618002640303744

Epoch: 5| Step: 8
Training loss: 2.1305317878723145
Validation loss: 2.1602887389480427

Epoch: 5| Step: 9
Training loss: 2.256321907043457
Validation loss: 2.1327647060476322

Epoch: 5| Step: 10
Training loss: 1.9553487300872803
Validation loss: 2.1300437194044872

Epoch: 256| Step: 0
Training loss: 2.5387935638427734
Validation loss: 2.144209325954478

Epoch: 5| Step: 1
Training loss: 2.169264316558838
Validation loss: 2.165357260293858

Epoch: 5| Step: 2
Training loss: 1.3471814393997192
Validation loss: 2.1826860186874226

Epoch: 5| Step: 3
Training loss: 2.0563693046569824
Validation loss: 2.221014829092128

Epoch: 5| Step: 4
Training loss: 2.1887385845184326
Validation loss: 2.235664518930579

Epoch: 5| Step: 5
Training loss: 2.6540393829345703
Validation loss: 2.211572047202818

Epoch: 5| Step: 6
Training loss: 2.3908374309539795
Validation loss: 2.1699387719554286

Epoch: 5| Step: 7
Training loss: 1.7035715579986572
Validation loss: 2.1238279522106214

Epoch: 5| Step: 8
Training loss: 1.898624062538147
Validation loss: 2.1271738416405133

Epoch: 5| Step: 9
Training loss: 1.9109563827514648
Validation loss: 2.1372566030871485

Epoch: 5| Step: 10
Training loss: 2.6054506301879883
Validation loss: 2.150145912683138

Epoch: 257| Step: 0
Training loss: 2.3615472316741943
Validation loss: 2.1507370625772784

Epoch: 5| Step: 1
Training loss: 1.8261569738388062
Validation loss: 2.159041920015889

Epoch: 5| Step: 2
Training loss: 2.745206356048584
Validation loss: 2.1762240086832354

Epoch: 5| Step: 3
Training loss: 2.302492618560791
Validation loss: 2.1720394421649236

Epoch: 5| Step: 4
Training loss: 2.663817882537842
Validation loss: 2.178864648265223

Epoch: 5| Step: 5
Training loss: 2.139288902282715
Validation loss: 2.1611041740704606

Epoch: 5| Step: 6
Training loss: 1.911900281906128
Validation loss: 2.1305058053744736

Epoch: 5| Step: 7
Training loss: 1.7252765893936157
Validation loss: 2.1321951958440963

Epoch: 5| Step: 8
Training loss: 2.361125946044922
Validation loss: 2.138796147479806

Epoch: 5| Step: 9
Training loss: 1.6267330646514893
Validation loss: 2.1363908398535942

Epoch: 5| Step: 10
Training loss: 1.5120869874954224
Validation loss: 2.1550929392537763

Epoch: 258| Step: 0
Training loss: 1.4827313423156738
Validation loss: 2.15274396763053

Epoch: 5| Step: 1
Training loss: 1.699495553970337
Validation loss: 2.1761685853363364

Epoch: 5| Step: 2
Training loss: 2.9647092819213867
Validation loss: 2.206758442745414

Epoch: 5| Step: 3
Training loss: 2.3079330921173096
Validation loss: 2.196692805136404

Epoch: 5| Step: 4
Training loss: 2.073530673980713
Validation loss: 2.184136131758331

Epoch: 5| Step: 5
Training loss: 2.6740829944610596
Validation loss: 2.182924750030682

Epoch: 5| Step: 6
Training loss: 2.184641122817993
Validation loss: 2.1723601536084245

Epoch: 5| Step: 7
Training loss: 1.5969127416610718
Validation loss: 2.1488378022306707

Epoch: 5| Step: 8
Training loss: 2.390881061553955
Validation loss: 2.1421087275269213

Epoch: 5| Step: 9
Training loss: 1.8403953313827515
Validation loss: 2.134531218518493

Epoch: 5| Step: 10
Training loss: 1.7535473108291626
Validation loss: 2.132346604460029

Epoch: 259| Step: 0
Training loss: 2.068453788757324
Validation loss: 2.182110663383238

Epoch: 5| Step: 1
Training loss: 2.078848123550415
Validation loss: 2.196956073084185

Epoch: 5| Step: 2
Training loss: 2.2488722801208496
Validation loss: 2.1801913707487044

Epoch: 5| Step: 3
Training loss: 2.8094375133514404
Validation loss: 2.1670780335703204

Epoch: 5| Step: 4
Training loss: 1.8286304473876953
Validation loss: 2.13231143131051

Epoch: 5| Step: 5
Training loss: 1.735300064086914
Validation loss: 2.112279849667703

Epoch: 5| Step: 6
Training loss: 2.1374704837799072
Validation loss: 2.1165486510081957

Epoch: 5| Step: 7
Training loss: 1.7317383289337158
Validation loss: 2.120539939531716

Epoch: 5| Step: 8
Training loss: 2.0370495319366455
Validation loss: 2.13228577439503

Epoch: 5| Step: 9
Training loss: 2.225696086883545
Validation loss: 2.1342986001763293

Epoch: 5| Step: 10
Training loss: 2.0445022583007812
Validation loss: 2.1330512364705405

Epoch: 260| Step: 0
Training loss: 1.82279372215271
Validation loss: 2.1575613201305432

Epoch: 5| Step: 1
Training loss: 2.073334217071533
Validation loss: 2.154917559316081

Epoch: 5| Step: 2
Training loss: 1.7922604084014893
Validation loss: 2.171832933220812

Epoch: 5| Step: 3
Training loss: 2.450150489807129
Validation loss: 2.176222207725689

Epoch: 5| Step: 4
Training loss: 2.427356243133545
Validation loss: 2.1705985453821

Epoch: 5| Step: 5
Training loss: 1.7149055004119873
Validation loss: 2.166119553709543

Epoch: 5| Step: 6
Training loss: 2.117922306060791
Validation loss: 2.148727814356486

Epoch: 5| Step: 7
Training loss: 2.2213611602783203
Validation loss: 2.142606964675329

Epoch: 5| Step: 8
Training loss: 1.7754127979278564
Validation loss: 2.141719418187295

Epoch: 5| Step: 9
Training loss: 2.665804147720337
Validation loss: 2.1379168148963683

Epoch: 5| Step: 10
Training loss: 1.5334566831588745
Validation loss: 2.1182180963536745

Epoch: 261| Step: 0
Training loss: 2.278672456741333
Validation loss: 2.1187210864918207

Epoch: 5| Step: 1
Training loss: 2.4440085887908936
Validation loss: 2.1138369819169402

Epoch: 5| Step: 2
Training loss: 2.5778462886810303
Validation loss: 2.10129209744033

Epoch: 5| Step: 3
Training loss: 2.3680944442749023
Validation loss: 2.120300828769643

Epoch: 5| Step: 4
Training loss: 2.037980556488037
Validation loss: 2.1219481345145934

Epoch: 5| Step: 5
Training loss: 2.1549324989318848
Validation loss: 2.1257427507831204

Epoch: 5| Step: 6
Training loss: 1.6875228881835938
Validation loss: 2.166313491841798

Epoch: 5| Step: 7
Training loss: 1.6176483631134033
Validation loss: 2.171334876809069

Epoch: 5| Step: 8
Training loss: 1.9034292697906494
Validation loss: 2.1766964697068736

Epoch: 5| Step: 9
Training loss: 1.848901391029358
Validation loss: 2.186183520542678

Epoch: 5| Step: 10
Training loss: 1.694217324256897
Validation loss: 2.1870943935968543

Epoch: 262| Step: 0
Training loss: 1.8169872760772705
Validation loss: 2.199167010604694

Epoch: 5| Step: 1
Training loss: 2.338715076446533
Validation loss: 2.219762453468897

Epoch: 5| Step: 2
Training loss: 2.2405152320861816
Validation loss: 2.196964826635135

Epoch: 5| Step: 3
Training loss: 1.8115758895874023
Validation loss: 2.1881809516619612

Epoch: 5| Step: 4
Training loss: 1.8739910125732422
Validation loss: 2.177944717868682

Epoch: 5| Step: 5
Training loss: 1.95499587059021
Validation loss: 2.1667608163690053

Epoch: 5| Step: 6
Training loss: 1.8703418970108032
Validation loss: 2.127879840071483

Epoch: 5| Step: 7
Training loss: 1.8791881799697876
Validation loss: 2.1078049803292878

Epoch: 5| Step: 8
Training loss: 2.0187413692474365
Validation loss: 2.101667152938022

Epoch: 5| Step: 9
Training loss: 2.1619341373443604
Validation loss: 2.091012853448109

Epoch: 5| Step: 10
Training loss: 2.748370885848999
Validation loss: 2.093803439089047

Epoch: 263| Step: 0
Training loss: 2.1092021465301514
Validation loss: 2.0884202206006615

Epoch: 5| Step: 1
Training loss: 2.092846393585205
Validation loss: 2.111668427785238

Epoch: 5| Step: 2
Training loss: 1.6867700815200806
Validation loss: 2.1192119211278935

Epoch: 5| Step: 3
Training loss: 2.4483494758605957
Validation loss: 2.1405733990412887

Epoch: 5| Step: 4
Training loss: 2.0099148750305176
Validation loss: 2.185551817699145

Epoch: 5| Step: 5
Training loss: 1.611445426940918
Validation loss: 2.19101438214702

Epoch: 5| Step: 6
Training loss: 1.7175861597061157
Validation loss: 2.175414376361396

Epoch: 5| Step: 7
Training loss: 2.3727567195892334
Validation loss: 2.1943291130886284

Epoch: 5| Step: 8
Training loss: 1.9770914316177368
Validation loss: 2.1700266740655385

Epoch: 5| Step: 9
Training loss: 2.431649684906006
Validation loss: 2.1877828054530646

Epoch: 5| Step: 10
Training loss: 2.0974016189575195
Validation loss: 2.1574264828876784

Epoch: 264| Step: 0
Training loss: 1.8024775981903076
Validation loss: 2.142346187304425

Epoch: 5| Step: 1
Training loss: 2.0195980072021484
Validation loss: 2.118866002687844

Epoch: 5| Step: 2
Training loss: 2.534712076187134
Validation loss: 2.097489489022122

Epoch: 5| Step: 3
Training loss: 1.9239397048950195
Validation loss: 2.089710186886531

Epoch: 5| Step: 4
Training loss: 2.1030590534210205
Validation loss: 2.0775661801779144

Epoch: 5| Step: 5
Training loss: 1.8846051692962646
Validation loss: 2.0846767374264297

Epoch: 5| Step: 6
Training loss: 2.477844715118408
Validation loss: 2.088628956066665

Epoch: 5| Step: 7
Training loss: 2.752943277359009
Validation loss: 2.0853098438632105

Epoch: 5| Step: 8
Training loss: 1.6045347452163696
Validation loss: 2.1017975473916657

Epoch: 5| Step: 9
Training loss: 1.938795804977417
Validation loss: 2.109405673960204

Epoch: 5| Step: 10
Training loss: 1.4443546533584595
Validation loss: 2.117621778160013

Epoch: 265| Step: 0
Training loss: 1.3526175022125244
Validation loss: 2.161591996428787

Epoch: 5| Step: 1
Training loss: 1.5496819019317627
Validation loss: 2.1461490584957983

Epoch: 5| Step: 2
Training loss: 1.9623022079467773
Validation loss: 2.155261895989859

Epoch: 5| Step: 3
Training loss: 2.32200026512146
Validation loss: 2.1626604551910074

Epoch: 5| Step: 4
Training loss: 2.137993335723877
Validation loss: 2.175682521635486

Epoch: 5| Step: 5
Training loss: 2.167602062225342
Validation loss: 2.183757858891641

Epoch: 5| Step: 6
Training loss: 2.0600266456604004
Validation loss: 2.1538951909670265

Epoch: 5| Step: 7
Training loss: 2.697795867919922
Validation loss: 2.157508574506288

Epoch: 5| Step: 8
Training loss: 1.87716543674469
Validation loss: 2.1571402562561857

Epoch: 5| Step: 9
Training loss: 1.8122392892837524
Validation loss: 2.1252676133186585

Epoch: 5| Step: 10
Training loss: 2.414396286010742
Validation loss: 2.1290397823497815

Epoch: 266| Step: 0
Training loss: 1.9485441446304321
Validation loss: 2.1151477547102076

Epoch: 5| Step: 1
Training loss: 2.149327278137207
Validation loss: 2.1131135443205475

Epoch: 5| Step: 2
Training loss: 1.7652699947357178
Validation loss: 2.095974724779847

Epoch: 5| Step: 3
Training loss: 2.080273151397705
Validation loss: 2.1108909447987876

Epoch: 5| Step: 4
Training loss: 1.6427488327026367
Validation loss: 2.109077189558296

Epoch: 5| Step: 5
Training loss: 2.21435546875
Validation loss: 2.1254979128478677

Epoch: 5| Step: 6
Training loss: 2.53877592086792
Validation loss: 2.130769952650993

Epoch: 5| Step: 7
Training loss: 1.9273427724838257
Validation loss: 2.1360245161159064

Epoch: 5| Step: 8
Training loss: 2.0361340045928955
Validation loss: 2.1360265644647742

Epoch: 5| Step: 9
Training loss: 1.6169097423553467
Validation loss: 2.1190540047102076

Epoch: 5| Step: 10
Training loss: 2.3999321460723877
Validation loss: 2.1286372407790153

Epoch: 267| Step: 0
Training loss: 2.0209922790527344
Validation loss: 2.129232680925759

Epoch: 5| Step: 1
Training loss: 1.6073700189590454
Validation loss: 2.1353220785817792

Epoch: 5| Step: 2
Training loss: 2.1635971069335938
Validation loss: 2.1527701142013713

Epoch: 5| Step: 3
Training loss: 1.768126130104065
Validation loss: 2.156472731662053

Epoch: 5| Step: 4
Training loss: 2.4902262687683105
Validation loss: 2.1491759720669

Epoch: 5| Step: 5
Training loss: 2.1900954246520996
Validation loss: 2.1383336859364666

Epoch: 5| Step: 6
Training loss: 2.3182761669158936
Validation loss: 2.1267264914768997

Epoch: 5| Step: 7
Training loss: 1.6488698720932007
Validation loss: 2.1329343652212494

Epoch: 5| Step: 8
Training loss: 2.3675036430358887
Validation loss: 2.1407608370627127

Epoch: 5| Step: 9
Training loss: 2.1143813133239746
Validation loss: 2.1240416778031217

Epoch: 5| Step: 10
Training loss: 1.3961634635925293
Validation loss: 2.1131274674528386

Epoch: 268| Step: 0
Training loss: 2.2151806354522705
Validation loss: 2.1056310207613054

Epoch: 5| Step: 1
Training loss: 2.1807072162628174
Validation loss: 2.0933232922707834

Epoch: 5| Step: 2
Training loss: 1.9190547466278076
Validation loss: 2.0864310392769436

Epoch: 5| Step: 3
Training loss: 1.8604198694229126
Validation loss: 2.099722695607011

Epoch: 5| Step: 4
Training loss: 2.3855397701263428
Validation loss: 2.1068053386544667

Epoch: 5| Step: 5
Training loss: 1.9600645303726196
Validation loss: 2.1271395503833728

Epoch: 5| Step: 6
Training loss: 2.0308921337127686
Validation loss: 2.132186274374685

Epoch: 5| Step: 7
Training loss: 1.6257293224334717
Validation loss: 2.1414549145647275

Epoch: 5| Step: 8
Training loss: 1.7609202861785889
Validation loss: 2.1340825429526706

Epoch: 5| Step: 9
Training loss: 1.9251086711883545
Validation loss: 2.1219097927052486

Epoch: 5| Step: 10
Training loss: 2.3602566719055176
Validation loss: 2.1346603337154595

Epoch: 269| Step: 0
Training loss: 1.4564111232757568
Validation loss: 2.1242044933380617

Epoch: 5| Step: 1
Training loss: 1.7494932413101196
Validation loss: 2.1280844955034155

Epoch: 5| Step: 2
Training loss: 2.2209103107452393
Validation loss: 2.128743927965882

Epoch: 5| Step: 3
Training loss: 2.1793105602264404
Validation loss: 2.1323439869829404

Epoch: 5| Step: 4
Training loss: 2.2860374450683594
Validation loss: 2.1507178660362

Epoch: 5| Step: 5
Training loss: 1.9899730682373047
Validation loss: 2.1482252382463023

Epoch: 5| Step: 6
Training loss: 2.3683090209960938
Validation loss: 2.144769363505866

Epoch: 5| Step: 7
Training loss: 1.6837360858917236
Validation loss: 2.145840876845903

Epoch: 5| Step: 8
Training loss: 1.94167959690094
Validation loss: 2.1338860668161863

Epoch: 5| Step: 9
Training loss: 1.96124267578125
Validation loss: 2.139492657876784

Epoch: 5| Step: 10
Training loss: 2.0797674655914307
Validation loss: 2.120898021164761

Epoch: 270| Step: 0
Training loss: 1.2984883785247803
Validation loss: 2.132749922813908

Epoch: 5| Step: 1
Training loss: 2.063007354736328
Validation loss: 2.1461529757386897

Epoch: 5| Step: 2
Training loss: 2.226865768432617
Validation loss: 2.119363489971366

Epoch: 5| Step: 3
Training loss: 1.9396995306015015
Validation loss: 2.117566277903895

Epoch: 5| Step: 4
Training loss: 1.899867057800293
Validation loss: 2.1178281640493744

Epoch: 5| Step: 5
Training loss: 2.3491034507751465
Validation loss: 2.1286277540268435

Epoch: 5| Step: 6
Training loss: 1.722840666770935
Validation loss: 2.122191216356011

Epoch: 5| Step: 7
Training loss: 2.204767942428589
Validation loss: 2.1254420972639516

Epoch: 5| Step: 8
Training loss: 2.5563952922821045
Validation loss: 2.1445359594078472

Epoch: 5| Step: 9
Training loss: 1.4331700801849365
Validation loss: 2.1416287396543767

Epoch: 5| Step: 10
Training loss: 2.3270535469055176
Validation loss: 2.126384458234233

Epoch: 271| Step: 0
Training loss: 2.190396785736084
Validation loss: 2.1053853957883772

Epoch: 5| Step: 1
Training loss: 2.0590317249298096
Validation loss: 2.112315482990716

Epoch: 5| Step: 2
Training loss: 1.7219293117523193
Validation loss: 2.1144284022751676

Epoch: 5| Step: 3
Training loss: 1.8171932697296143
Validation loss: 2.1257256897546912

Epoch: 5| Step: 4
Training loss: 2.1544625759124756
Validation loss: 2.1390252549161195

Epoch: 5| Step: 5
Training loss: 1.6234108209609985
Validation loss: 2.160020013009348

Epoch: 5| Step: 6
Training loss: 1.891384482383728
Validation loss: 2.167626239920175

Epoch: 5| Step: 7
Training loss: 2.1205294132232666
Validation loss: 2.170308515589724

Epoch: 5| Step: 8
Training loss: 2.2366650104522705
Validation loss: 2.153606358394828

Epoch: 5| Step: 9
Training loss: 1.7876561880111694
Validation loss: 2.1172139131894676

Epoch: 5| Step: 10
Training loss: 2.378086566925049
Validation loss: 2.1085548990516254

Epoch: 272| Step: 0
Training loss: 1.633618950843811
Validation loss: 2.090985071274542

Epoch: 5| Step: 1
Training loss: 2.712411403656006
Validation loss: 2.0961525722216536

Epoch: 5| Step: 2
Training loss: 2.10326886177063
Validation loss: 2.0652349982210385

Epoch: 5| Step: 3
Training loss: 2.1732020378112793
Validation loss: 2.0776420408679592

Epoch: 5| Step: 4
Training loss: 1.6211525201797485
Validation loss: 2.080712982403335

Epoch: 5| Step: 5
Training loss: 2.358234405517578
Validation loss: 2.0822726065112698

Epoch: 5| Step: 6
Training loss: 2.176586627960205
Validation loss: 2.074308605604274

Epoch: 5| Step: 7
Training loss: 1.9889205694198608
Validation loss: 2.0879164613703245

Epoch: 5| Step: 8
Training loss: 1.9649842977523804
Validation loss: 2.123841452342208

Epoch: 5| Step: 9
Training loss: 1.4663797616958618
Validation loss: 2.1594354978171726

Epoch: 5| Step: 10
Training loss: 1.9278836250305176
Validation loss: 2.1928215898493284

Epoch: 273| Step: 0
Training loss: 1.9968585968017578
Validation loss: 2.2149026727163665

Epoch: 5| Step: 1
Training loss: 2.6920313835144043
Validation loss: 2.235717551682585

Epoch: 5| Step: 2
Training loss: 2.5045394897460938
Validation loss: 2.205889512133855

Epoch: 5| Step: 3
Training loss: 1.8818655014038086
Validation loss: 2.200097417318693

Epoch: 5| Step: 4
Training loss: 1.8802337646484375
Validation loss: 2.188109287651636

Epoch: 5| Step: 5
Training loss: 1.9291191101074219
Validation loss: 2.186543439024238

Epoch: 5| Step: 6
Training loss: 2.0074565410614014
Validation loss: 2.202381231451547

Epoch: 5| Step: 7
Training loss: 1.5624076128005981
Validation loss: 2.1867592539838565

Epoch: 5| Step: 8
Training loss: 1.800616979598999
Validation loss: 2.166580638577861

Epoch: 5| Step: 9
Training loss: 1.715932846069336
Validation loss: 2.1525434858055523

Epoch: 5| Step: 10
Training loss: 2.090888500213623
Validation loss: 2.1319580795944377

Epoch: 274| Step: 0
Training loss: 2.1543025970458984
Validation loss: 2.1314131957228466

Epoch: 5| Step: 1
Training loss: 1.9369710683822632
Validation loss: 2.1465642785513275

Epoch: 5| Step: 2
Training loss: 2.118269205093384
Validation loss: 2.132720631937827

Epoch: 5| Step: 3
Training loss: 2.021455764770508
Validation loss: 2.140270261354344

Epoch: 5| Step: 4
Training loss: 2.742128849029541
Validation loss: 2.152575577459028

Epoch: 5| Step: 5
Training loss: 1.6152684688568115
Validation loss: 2.184235841997208

Epoch: 5| Step: 6
Training loss: 1.7044528722763062
Validation loss: 2.1606425880103983

Epoch: 5| Step: 7
Training loss: 2.37870454788208
Validation loss: 2.1626135636401433

Epoch: 5| Step: 8
Training loss: 1.9606975317001343
Validation loss: 2.152803664566368

Epoch: 5| Step: 9
Training loss: 1.5079433917999268
Validation loss: 2.164400586517908

Epoch: 5| Step: 10
Training loss: 1.601067066192627
Validation loss: 2.153185313747775

Epoch: 275| Step: 0
Training loss: 2.3256945610046387
Validation loss: 2.1640542027770833

Epoch: 5| Step: 1
Training loss: 1.942786455154419
Validation loss: 2.157630338463732

Epoch: 5| Step: 2
Training loss: 1.8483102321624756
Validation loss: 2.173997991828508

Epoch: 5| Step: 3
Training loss: 1.6631038188934326
Validation loss: 2.1586956285661265

Epoch: 5| Step: 4
Training loss: 2.2164950370788574
Validation loss: 2.166069310198548

Epoch: 5| Step: 5
Training loss: 2.1006007194519043
Validation loss: 2.1661969333566646

Epoch: 5| Step: 6
Training loss: 1.9094291925430298
Validation loss: 2.1517604602280485

Epoch: 5| Step: 7
Training loss: 1.7865912914276123
Validation loss: 2.1661573712543776

Epoch: 5| Step: 8
Training loss: 2.1562352180480957
Validation loss: 2.135786214182454

Epoch: 5| Step: 9
Training loss: 1.4774526357650757
Validation loss: 2.1367708393322524

Epoch: 5| Step: 10
Training loss: 2.3269169330596924
Validation loss: 2.1181501111676617

Epoch: 276| Step: 0
Training loss: 2.559324264526367
Validation loss: 2.108345946957988

Epoch: 5| Step: 1
Training loss: 1.541299819946289
Validation loss: 2.1110478652420865

Epoch: 5| Step: 2
Training loss: 2.14408540725708
Validation loss: 2.110617371015651

Epoch: 5| Step: 3
Training loss: 1.6855566501617432
Validation loss: 2.1034975308243946

Epoch: 5| Step: 4
Training loss: 2.1140151023864746
Validation loss: 2.1169599448480914

Epoch: 5| Step: 5
Training loss: 2.0287280082702637
Validation loss: 2.1249847642837034

Epoch: 5| Step: 6
Training loss: 2.0094923973083496
Validation loss: 2.115564141222226

Epoch: 5| Step: 7
Training loss: 1.6317239999771118
Validation loss: 2.1374011872917094

Epoch: 5| Step: 8
Training loss: 2.1205830574035645
Validation loss: 2.1208450922402005

Epoch: 5| Step: 9
Training loss: 1.6920883655548096
Validation loss: 2.1473794239823536

Epoch: 5| Step: 10
Training loss: 1.8790812492370605
Validation loss: 2.1456870789168985

Epoch: 277| Step: 0
Training loss: 2.055156707763672
Validation loss: 2.167473634084066

Epoch: 5| Step: 1
Training loss: 2.219097852706909
Validation loss: 2.1485276914411977

Epoch: 5| Step: 2
Training loss: 2.2811875343322754
Validation loss: 2.138173254587317

Epoch: 5| Step: 3
Training loss: 1.8622757196426392
Validation loss: 2.1544048273435203

Epoch: 5| Step: 4
Training loss: 2.218898296356201
Validation loss: 2.1626375182982414

Epoch: 5| Step: 5
Training loss: 1.2639340162277222
Validation loss: 2.1447852068049933

Epoch: 5| Step: 6
Training loss: 2.548053741455078
Validation loss: 2.126591585015738

Epoch: 5| Step: 7
Training loss: 1.689978003501892
Validation loss: 2.133838986837736

Epoch: 5| Step: 8
Training loss: 1.606327772140503
Validation loss: 2.1368219147446337

Epoch: 5| Step: 9
Training loss: 2.0548787117004395
Validation loss: 2.1306998191341275

Epoch: 5| Step: 10
Training loss: 1.6484837532043457
Validation loss: 2.137030045191447

Epoch: 278| Step: 0
Training loss: 2.1085023880004883
Validation loss: 2.139512533782631

Epoch: 5| Step: 1
Training loss: 1.5844123363494873
Validation loss: 2.1231291678643998

Epoch: 5| Step: 2
Training loss: 2.183593273162842
Validation loss: 2.1366433046197377

Epoch: 5| Step: 3
Training loss: 1.3020551204681396
Validation loss: 2.162499232958722

Epoch: 5| Step: 4
Training loss: 1.6767345666885376
Validation loss: 2.1578414106881745

Epoch: 5| Step: 5
Training loss: 1.5535224676132202
Validation loss: 2.164097926949942

Epoch: 5| Step: 6
Training loss: 2.134262800216675
Validation loss: 2.1692643909044165

Epoch: 5| Step: 7
Training loss: 2.113398790359497
Validation loss: 2.141567050769765

Epoch: 5| Step: 8
Training loss: 2.8111133575439453
Validation loss: 2.1277948758935414

Epoch: 5| Step: 9
Training loss: 2.2135281562805176
Validation loss: 2.110666977461948

Epoch: 5| Step: 10
Training loss: 1.7297407388687134
Validation loss: 2.109055772904427

Epoch: 279| Step: 0
Training loss: 2.257530689239502
Validation loss: 2.094711729275283

Epoch: 5| Step: 1
Training loss: 1.8372104167938232
Validation loss: 2.0799535602651615

Epoch: 5| Step: 2
Training loss: 1.8587652444839478
Validation loss: 2.0891455258092573

Epoch: 5| Step: 3
Training loss: 2.04314923286438
Validation loss: 2.1165968602703464

Epoch: 5| Step: 4
Training loss: 1.7866073846817017
Validation loss: 2.1533000110298075

Epoch: 5| Step: 5
Training loss: 1.317448616027832
Validation loss: 2.197382406521869

Epoch: 5| Step: 6
Training loss: 1.5843638181686401
Validation loss: 2.2314156486142065

Epoch: 5| Step: 7
Training loss: 2.3506016731262207
Validation loss: 2.219040181047173

Epoch: 5| Step: 8
Training loss: 2.1101250648498535
Validation loss: 2.206097332380151

Epoch: 5| Step: 9
Training loss: 2.1060853004455566
Validation loss: 2.140515714563349

Epoch: 5| Step: 10
Training loss: 2.2725658416748047
Validation loss: 2.1158011767172042

Epoch: 280| Step: 0
Training loss: 2.356157064437866
Validation loss: 2.106714471693962

Epoch: 5| Step: 1
Training loss: 1.8985611200332642
Validation loss: 2.092413256245275

Epoch: 5| Step: 2
Training loss: 1.6527891159057617
Validation loss: 2.084452893144341

Epoch: 5| Step: 3
Training loss: 2.4578301906585693
Validation loss: 2.0902722599685832

Epoch: 5| Step: 4
Training loss: 1.7619882822036743
Validation loss: 2.097602228964529

Epoch: 5| Step: 5
Training loss: 1.8463895320892334
Validation loss: 2.131584608426658

Epoch: 5| Step: 6
Training loss: 1.8842830657958984
Validation loss: 2.1441413253866215

Epoch: 5| Step: 7
Training loss: 1.7340891361236572
Validation loss: 2.1938604667622554

Epoch: 5| Step: 8
Training loss: 1.5341765880584717
Validation loss: 2.2042387224012807

Epoch: 5| Step: 9
Training loss: 2.113792657852173
Validation loss: 2.183079670834285

Epoch: 5| Step: 10
Training loss: 2.1057350635528564
Validation loss: 2.1651302717065297

Epoch: 281| Step: 0
Training loss: 1.5899635553359985
Validation loss: 2.163966848004249

Epoch: 5| Step: 1
Training loss: 2.86674165725708
Validation loss: 2.155852155018878

Epoch: 5| Step: 2
Training loss: 2.161120653152466
Validation loss: 2.166665179755098

Epoch: 5| Step: 3
Training loss: 1.8632144927978516
Validation loss: 2.1527941355141262

Epoch: 5| Step: 4
Training loss: 2.2115771770477295
Validation loss: 2.1508372381169307

Epoch: 5| Step: 5
Training loss: 1.7878406047821045
Validation loss: 2.1208266173639605

Epoch: 5| Step: 6
Training loss: 1.0864547491073608
Validation loss: 2.1042858657016548

Epoch: 5| Step: 7
Training loss: 1.7382217645645142
Validation loss: 2.1262583386513496

Epoch: 5| Step: 8
Training loss: 1.6393026113510132
Validation loss: 2.139605132482385

Epoch: 5| Step: 9
Training loss: 2.1491706371307373
Validation loss: 2.1511475245157876

Epoch: 5| Step: 10
Training loss: 2.1923422813415527
Validation loss: 2.1528808378404185

Epoch: 282| Step: 0
Training loss: 1.7480666637420654
Validation loss: 2.1527650651111396

Epoch: 5| Step: 1
Training loss: 1.355924367904663
Validation loss: 2.1226755726721978

Epoch: 5| Step: 2
Training loss: 2.146669387817383
Validation loss: 2.1105776884222545

Epoch: 5| Step: 3
Training loss: 2.4818005561828613
Validation loss: 2.096043843095021

Epoch: 5| Step: 4
Training loss: 2.091676712036133
Validation loss: 2.1077691073058755

Epoch: 5| Step: 5
Training loss: 1.6839570999145508
Validation loss: 2.103713027892574

Epoch: 5| Step: 6
Training loss: 2.0635838508605957
Validation loss: 2.1118726986710743

Epoch: 5| Step: 7
Training loss: 2.016767740249634
Validation loss: 2.134513598616405

Epoch: 5| Step: 8
Training loss: 2.0992839336395264
Validation loss: 2.154998251186904

Epoch: 5| Step: 9
Training loss: 1.734347939491272
Validation loss: 2.1495126652461227

Epoch: 5| Step: 10
Training loss: 1.8231920003890991
Validation loss: 2.1314871131732898

Epoch: 283| Step: 0
Training loss: 1.6184005737304688
Validation loss: 2.1268766631362257

Epoch: 5| Step: 1
Training loss: 2.2487573623657227
Validation loss: 2.1449436679963143

Epoch: 5| Step: 2
Training loss: 2.099240779876709
Validation loss: 2.1050579150517783

Epoch: 5| Step: 3
Training loss: 2.4997849464416504
Validation loss: 2.1144956055507866

Epoch: 5| Step: 4
Training loss: 1.870757818222046
Validation loss: 2.104112200839545

Epoch: 5| Step: 5
Training loss: 1.2828768491744995
Validation loss: 2.1106897233634867

Epoch: 5| Step: 6
Training loss: 1.6784031391143799
Validation loss: 2.13966094293902

Epoch: 5| Step: 7
Training loss: 1.8720595836639404
Validation loss: 2.1989581046565885

Epoch: 5| Step: 8
Training loss: 2.205886125564575
Validation loss: 2.23521468716283

Epoch: 5| Step: 9
Training loss: 1.7938324213027954
Validation loss: 2.254104188693467

Epoch: 5| Step: 10
Training loss: 2.0153164863586426
Validation loss: 2.2347110753418296

Epoch: 284| Step: 0
Training loss: 1.4206832647323608
Validation loss: 2.206938671809371

Epoch: 5| Step: 1
Training loss: 1.8629777431488037
Validation loss: 2.191575070863129

Epoch: 5| Step: 2
Training loss: 2.2173011302948
Validation loss: 2.1684873283550306

Epoch: 5| Step: 3
Training loss: 2.972565174102783
Validation loss: 2.156966737521592

Epoch: 5| Step: 4
Training loss: 1.2176973819732666
Validation loss: 2.134018164809032

Epoch: 5| Step: 5
Training loss: 1.894679307937622
Validation loss: 2.126453827786189

Epoch: 5| Step: 6
Training loss: 1.9768216609954834
Validation loss: 2.117207340014878

Epoch: 5| Step: 7
Training loss: 2.1880550384521484
Validation loss: 2.0949672114464546

Epoch: 5| Step: 8
Training loss: 1.868870496749878
Validation loss: 2.106288643293483

Epoch: 5| Step: 9
Training loss: 1.6649118661880493
Validation loss: 2.1120904619975756

Epoch: 5| Step: 10
Training loss: 1.6476964950561523
Validation loss: 2.1164946684273342

Epoch: 285| Step: 0
Training loss: 2.2253663539886475
Validation loss: 2.129428140578731

Epoch: 5| Step: 1
Training loss: 1.5678894519805908
Validation loss: 2.1401861867597027

Epoch: 5| Step: 2
Training loss: 2.0986557006835938
Validation loss: 2.1437177452989804

Epoch: 5| Step: 3
Training loss: 1.563306450843811
Validation loss: 2.155554820132512

Epoch: 5| Step: 4
Training loss: 1.3746683597564697
Validation loss: 2.188692359514134

Epoch: 5| Step: 5
Training loss: 2.185727596282959
Validation loss: 2.1763245854326474

Epoch: 5| Step: 6
Training loss: 2.260532855987549
Validation loss: 2.1402164428464827

Epoch: 5| Step: 7
Training loss: 1.9240925312042236
Validation loss: 2.1241326178273847

Epoch: 5| Step: 8
Training loss: 1.4541469812393188
Validation loss: 2.1285774964158253

Epoch: 5| Step: 9
Training loss: 2.5694704055786133
Validation loss: 2.114626097422774

Epoch: 5| Step: 10
Training loss: 1.7478004693984985
Validation loss: 2.1034378518340406

Epoch: 286| Step: 0
Training loss: 1.2272788286209106
Validation loss: 2.118553738440237

Epoch: 5| Step: 1
Training loss: 2.087660312652588
Validation loss: 2.1411539328995572

Epoch: 5| Step: 2
Training loss: 1.7722320556640625
Validation loss: 2.169390627132949

Epoch: 5| Step: 3
Training loss: 2.138829231262207
Validation loss: 2.191208472815893

Epoch: 5| Step: 4
Training loss: 1.7972110509872437
Validation loss: 2.173264241987659

Epoch: 5| Step: 5
Training loss: 1.9594265222549438
Validation loss: 2.1637547528871925

Epoch: 5| Step: 6
Training loss: 1.7217057943344116
Validation loss: 2.1532141418867212

Epoch: 5| Step: 7
Training loss: 2.362522602081299
Validation loss: 2.1528299675192883

Epoch: 5| Step: 8
Training loss: 1.6785633563995361
Validation loss: 2.1255928060059905

Epoch: 5| Step: 9
Training loss: 1.7088897228240967
Validation loss: 2.1307676556289836

Epoch: 5| Step: 10
Training loss: 2.5050296783447266
Validation loss: 2.1191207542214343

Epoch: 287| Step: 0
Training loss: 2.1005303859710693
Validation loss: 2.106992144738474

Epoch: 5| Step: 1
Training loss: 1.4750579595565796
Validation loss: 2.1256259641339703

Epoch: 5| Step: 2
Training loss: 2.4298834800720215
Validation loss: 2.1513816387422624

Epoch: 5| Step: 3
Training loss: 1.6954644918441772
Validation loss: 2.1601546784882903

Epoch: 5| Step: 4
Training loss: 2.0559327602386475
Validation loss: 2.14043790166096

Epoch: 5| Step: 5
Training loss: 1.6549361944198608
Validation loss: 2.1226199955068608

Epoch: 5| Step: 6
Training loss: 1.503350019454956
Validation loss: 2.1240411163658224

Epoch: 5| Step: 7
Training loss: 1.7219798564910889
Validation loss: 2.1153825675287554

Epoch: 5| Step: 8
Training loss: 1.8930914402008057
Validation loss: 2.1132860555443713

Epoch: 5| Step: 9
Training loss: 2.072835922241211
Validation loss: 2.1149185062736593

Epoch: 5| Step: 10
Training loss: 2.2084097862243652
Validation loss: 2.1180878890457975

Epoch: 288| Step: 0
Training loss: 1.541482925415039
Validation loss: 2.1396512446864957

Epoch: 5| Step: 1
Training loss: 2.4511539936065674
Validation loss: 2.1656743993041334

Epoch: 5| Step: 2
Training loss: 2.3249592781066895
Validation loss: 2.16405983894102

Epoch: 5| Step: 3
Training loss: 1.4798481464385986
Validation loss: 2.1769706510728404

Epoch: 5| Step: 4
Training loss: 1.7683684825897217
Validation loss: 2.1857860395985265

Epoch: 5| Step: 5
Training loss: 1.644514799118042
Validation loss: 2.1513962591848066

Epoch: 5| Step: 6
Training loss: 2.2537178993225098
Validation loss: 2.1411240664861535

Epoch: 5| Step: 7
Training loss: 1.551239252090454
Validation loss: 2.1431278297978062

Epoch: 5| Step: 8
Training loss: 1.7874311208724976
Validation loss: 2.1410060364712953

Epoch: 5| Step: 9
Training loss: 2.3807199001312256
Validation loss: 2.148453140771517

Epoch: 5| Step: 10
Training loss: 1.4786444902420044
Validation loss: 2.1347321207805345

Epoch: 289| Step: 0
Training loss: 2.0789730548858643
Validation loss: 2.1521146220545613

Epoch: 5| Step: 1
Training loss: 1.707334280014038
Validation loss: 2.176196011163855

Epoch: 5| Step: 2
Training loss: 2.2736411094665527
Validation loss: 2.171868093552128

Epoch: 5| Step: 3
Training loss: 1.5138272047042847
Validation loss: 2.159257552957022

Epoch: 5| Step: 4
Training loss: 1.5996674299240112
Validation loss: 2.163330380634595

Epoch: 5| Step: 5
Training loss: 1.332096815109253
Validation loss: 2.1742798718073035

Epoch: 5| Step: 6
Training loss: 1.7827011346817017
Validation loss: 2.160726926660025

Epoch: 5| Step: 7
Training loss: 1.5952551364898682
Validation loss: 2.1507542799877863

Epoch: 5| Step: 8
Training loss: 2.092170000076294
Validation loss: 2.163333523658014

Epoch: 5| Step: 9
Training loss: 2.2493984699249268
Validation loss: 2.1754559304124568

Epoch: 5| Step: 10
Training loss: 2.639998197555542
Validation loss: 2.1607536769682363

Epoch: 290| Step: 0
Training loss: 1.9328323602676392
Validation loss: 2.161178623476336

Epoch: 5| Step: 1
Training loss: 1.9192520380020142
Validation loss: 2.172766448349081

Epoch: 5| Step: 2
Training loss: 2.27952241897583
Validation loss: 2.163070427474155

Epoch: 5| Step: 3
Training loss: 1.4793494939804077
Validation loss: 2.151684284210205

Epoch: 5| Step: 4
Training loss: 1.6827661991119385
Validation loss: 2.172295980556037

Epoch: 5| Step: 5
Training loss: 1.8196579217910767
Validation loss: 2.179409174508946

Epoch: 5| Step: 6
Training loss: 1.142827033996582
Validation loss: 2.2085421239176104

Epoch: 5| Step: 7
Training loss: 1.8524211645126343
Validation loss: 2.199867089589437

Epoch: 5| Step: 8
Training loss: 2.013314723968506
Validation loss: 2.2178292171929472

Epoch: 5| Step: 9
Training loss: 2.3954226970672607
Validation loss: 2.1782108109484435

Epoch: 5| Step: 10
Training loss: 2.0482754707336426
Validation loss: 2.142994607648542

Epoch: 291| Step: 0
Training loss: 1.315887689590454
Validation loss: 2.094614956968574

Epoch: 5| Step: 1
Training loss: 1.7822754383087158
Validation loss: 2.087934381218367

Epoch: 5| Step: 2
Training loss: 2.0072083473205566
Validation loss: 2.0654043971851306

Epoch: 5| Step: 3
Training loss: 2.2489306926727295
Validation loss: 2.077458635453255

Epoch: 5| Step: 4
Training loss: 2.143176317214966
Validation loss: 2.077137044681016

Epoch: 5| Step: 5
Training loss: 1.5931612253189087
Validation loss: 2.0621384753975818

Epoch: 5| Step: 6
Training loss: 1.9486186504364014
Validation loss: 2.0814076162153676

Epoch: 5| Step: 7
Training loss: 1.6754674911499023
Validation loss: 2.1163880184132564

Epoch: 5| Step: 8
Training loss: 2.0573606491088867
Validation loss: 2.135642329851786

Epoch: 5| Step: 9
Training loss: 1.9847400188446045
Validation loss: 2.1774644595320507

Epoch: 5| Step: 10
Training loss: 1.8992217779159546
Validation loss: 2.206741279171359

Epoch: 292| Step: 0
Training loss: 2.114278554916382
Validation loss: 2.208523875923567

Epoch: 5| Step: 1
Training loss: 1.59246027469635
Validation loss: 2.18705004261386

Epoch: 5| Step: 2
Training loss: 2.0550742149353027
Validation loss: 2.1636865497917257

Epoch: 5| Step: 3
Training loss: 1.7473294734954834
Validation loss: 2.167058096137098

Epoch: 5| Step: 4
Training loss: 1.964139699935913
Validation loss: 2.1689441127161824

Epoch: 5| Step: 5
Training loss: 2.1967413425445557
Validation loss: 2.145870727877463

Epoch: 5| Step: 6
Training loss: 1.931852102279663
Validation loss: 2.123816728591919

Epoch: 5| Step: 7
Training loss: 1.7039743661880493
Validation loss: 2.112845705401513

Epoch: 5| Step: 8
Training loss: 1.6175912618637085
Validation loss: 2.113795727811834

Epoch: 5| Step: 9
Training loss: 1.6007044315338135
Validation loss: 2.126564097660844

Epoch: 5| Step: 10
Training loss: 1.966538429260254
Validation loss: 2.135635227285406

Epoch: 293| Step: 0
Training loss: 1.3995893001556396
Validation loss: 2.140636836328814

Epoch: 5| Step: 1
Training loss: 1.7579082250595093
Validation loss: 2.143400273015422

Epoch: 5| Step: 2
Training loss: 1.3550739288330078
Validation loss: 2.1393775850213985

Epoch: 5| Step: 3
Training loss: 2.12536883354187
Validation loss: 2.1628383333965013

Epoch: 5| Step: 4
Training loss: 1.6189028024673462
Validation loss: 2.1521477109642437

Epoch: 5| Step: 5
Training loss: 2.2631664276123047
Validation loss: 2.1689292846187467

Epoch: 5| Step: 6
Training loss: 2.0093610286712646
Validation loss: 2.16563097892269

Epoch: 5| Step: 7
Training loss: 1.8183314800262451
Validation loss: 2.1565454313831944

Epoch: 5| Step: 8
Training loss: 2.0057177543640137
Validation loss: 2.123388756987869

Epoch: 5| Step: 9
Training loss: 2.0165605545043945
Validation loss: 2.1060024358892955

Epoch: 5| Step: 10
Training loss: 2.0937836170196533
Validation loss: 2.0923645445095596

Epoch: 294| Step: 0
Training loss: 1.9477615356445312
Validation loss: 2.112043147446007

Epoch: 5| Step: 1
Training loss: 2.2346267700195312
Validation loss: 2.0928161477529876

Epoch: 5| Step: 2
Training loss: 1.633657455444336
Validation loss: 2.111253109029544

Epoch: 5| Step: 3
Training loss: 1.5264579057693481
Validation loss: 2.1121427295028523

Epoch: 5| Step: 4
Training loss: 2.083281993865967
Validation loss: 2.1389841289930445

Epoch: 5| Step: 5
Training loss: 2.1137912273406982
Validation loss: 2.1552975229037705

Epoch: 5| Step: 6
Training loss: 2.1716082096099854
Validation loss: 2.161967585163732

Epoch: 5| Step: 7
Training loss: 1.178130030632019
Validation loss: 2.1370747166295208

Epoch: 5| Step: 8
Training loss: 2.3391339778900146
Validation loss: 2.1439191525982273

Epoch: 5| Step: 9
Training loss: 1.1704330444335938
Validation loss: 2.152999372892482

Epoch: 5| Step: 10
Training loss: 1.993773341178894
Validation loss: 2.163211199545091

Epoch: 295| Step: 0
Training loss: 2.2829761505126953
Validation loss: 2.1551621037144817

Epoch: 5| Step: 1
Training loss: 1.7468507289886475
Validation loss: 2.167786313641456

Epoch: 5| Step: 2
Training loss: 2.2953879833221436
Validation loss: 2.1398120900636077

Epoch: 5| Step: 3
Training loss: 2.0632832050323486
Validation loss: 2.1550593735069357

Epoch: 5| Step: 4
Training loss: 1.418465256690979
Validation loss: 2.1526737187498357

Epoch: 5| Step: 5
Training loss: 1.406768560409546
Validation loss: 2.1331115256073656

Epoch: 5| Step: 6
Training loss: 1.7516496181488037
Validation loss: 2.1393439590290027

Epoch: 5| Step: 7
Training loss: 1.7326648235321045
Validation loss: 2.144533247076055

Epoch: 5| Step: 8
Training loss: 2.2502150535583496
Validation loss: 2.138508648000738

Epoch: 5| Step: 9
Training loss: 1.612903356552124
Validation loss: 2.153591776406893

Epoch: 5| Step: 10
Training loss: 1.5236079692840576
Validation loss: 2.147848467673025

Epoch: 296| Step: 0
Training loss: 1.9685205221176147
Validation loss: 2.1532754923707698

Epoch: 5| Step: 1
Training loss: 2.172673225402832
Validation loss: 2.177263136832945

Epoch: 5| Step: 2
Training loss: 2.3769774436950684
Validation loss: 2.166514345394668

Epoch: 5| Step: 3
Training loss: 2.001607894897461
Validation loss: 2.1582817441673687

Epoch: 5| Step: 4
Training loss: 1.4011541604995728
Validation loss: 2.1461620920447895

Epoch: 5| Step: 5
Training loss: 1.4662946462631226
Validation loss: 2.157573870433274

Epoch: 5| Step: 6
Training loss: 1.7662118673324585
Validation loss: 2.155282817861085

Epoch: 5| Step: 7
Training loss: 1.3918664455413818
Validation loss: 2.1691734252437467

Epoch: 5| Step: 8
Training loss: 1.716660737991333
Validation loss: 2.191396008255661

Epoch: 5| Step: 9
Training loss: 1.6682446002960205
Validation loss: 2.2012137520697808

Epoch: 5| Step: 10
Training loss: 2.374323606491089
Validation loss: 2.251145762781943

Epoch: 297| Step: 0
Training loss: 2.3643150329589844
Validation loss: 2.1933743799886396

Epoch: 5| Step: 1
Training loss: 1.5869474411010742
Validation loss: 2.158665865980169

Epoch: 5| Step: 2
Training loss: 1.6268017292022705
Validation loss: 2.1641914562512468

Epoch: 5| Step: 3
Training loss: 2.0579922199249268
Validation loss: 2.1594187931347917

Epoch: 5| Step: 4
Training loss: 1.4961435794830322
Validation loss: 2.1549964092111074

Epoch: 5| Step: 5
Training loss: 1.7233470678329468
Validation loss: 2.1655272399225542

Epoch: 5| Step: 6
Training loss: 1.7563083171844482
Validation loss: 2.150042582583684

Epoch: 5| Step: 7
Training loss: 2.147512674331665
Validation loss: 2.142417589823405

Epoch: 5| Step: 8
Training loss: 1.5902725458145142
Validation loss: 2.1660783880500385

Epoch: 5| Step: 9
Training loss: 1.5311548709869385
Validation loss: 2.177448338077914

Epoch: 5| Step: 10
Training loss: 2.2480783462524414
Validation loss: 2.1514397334027033

Epoch: 298| Step: 0
Training loss: 1.2422807216644287
Validation loss: 2.1503296795711724

Epoch: 5| Step: 1
Training loss: 1.9409481287002563
Validation loss: 2.143477478334981

Epoch: 5| Step: 2
Training loss: 1.9324214458465576
Validation loss: 2.1605576187051754

Epoch: 5| Step: 3
Training loss: 1.6535835266113281
Validation loss: 2.1380810942701114

Epoch: 5| Step: 4
Training loss: 1.5130027532577515
Validation loss: 2.1349401640635666

Epoch: 5| Step: 5
Training loss: 1.6298716068267822
Validation loss: 2.146779824328679

Epoch: 5| Step: 6
Training loss: 2.3338379859924316
Validation loss: 2.134819171761954

Epoch: 5| Step: 7
Training loss: 2.3411567211151123
Validation loss: 2.1321058875770977

Epoch: 5| Step: 8
Training loss: 2.061021327972412
Validation loss: 2.1264358284652873

Epoch: 5| Step: 9
Training loss: 1.825641393661499
Validation loss: 2.1193022061419744

Epoch: 5| Step: 10
Training loss: 1.6702698469161987
Validation loss: 2.115160334494806

Epoch: 299| Step: 0
Training loss: 1.7757041454315186
Validation loss: 2.1036310170286443

Epoch: 5| Step: 1
Training loss: 2.2636570930480957
Validation loss: 2.091813600191506

Epoch: 5| Step: 2
Training loss: 1.2417978048324585
Validation loss: 2.1157288089875252

Epoch: 5| Step: 3
Training loss: 1.9567428827285767
Validation loss: 2.1391652296948176

Epoch: 5| Step: 4
Training loss: 1.9503196477890015
Validation loss: 2.1684429055900982

Epoch: 5| Step: 5
Training loss: 2.3050332069396973
Validation loss: 2.211010116402821

Epoch: 5| Step: 6
Training loss: 1.743579626083374
Validation loss: 2.2243916039825766

Epoch: 5| Step: 7
Training loss: 1.223467230796814
Validation loss: 2.223457436407766

Epoch: 5| Step: 8
Training loss: 1.7188161611557007
Validation loss: 2.210549069989112

Epoch: 5| Step: 9
Training loss: 1.7866131067276
Validation loss: 2.2179353057697253

Epoch: 5| Step: 10
Training loss: 2.4744577407836914
Validation loss: 2.194504273835049

Epoch: 300| Step: 0
Training loss: 1.2763477563858032
Validation loss: 2.1517838842125347

Epoch: 5| Step: 1
Training loss: 1.838060975074768
Validation loss: 2.1217153956813197

Epoch: 5| Step: 2
Training loss: 2.2850914001464844
Validation loss: 2.0969799308366674

Epoch: 5| Step: 3
Training loss: 1.8198362588882446
Validation loss: 2.088049424591885

Epoch: 5| Step: 4
Training loss: 1.616769552230835
Validation loss: 2.104736884435018

Epoch: 5| Step: 5
Training loss: 1.5687482357025146
Validation loss: 2.110980138983778

Epoch: 5| Step: 6
Training loss: 1.662777304649353
Validation loss: 2.103561311639765

Epoch: 5| Step: 7
Training loss: 1.8737030029296875
Validation loss: 2.117072702735983

Epoch: 5| Step: 8
Training loss: 1.519623041152954
Validation loss: 2.127829428642027

Epoch: 5| Step: 9
Training loss: 2.3956985473632812
Validation loss: 2.1284866999554377

Epoch: 5| Step: 10
Training loss: 2.259915351867676
Validation loss: 2.121445079003611

Epoch: 301| Step: 0
Training loss: 2.1496009826660156
Validation loss: 2.1390457794230473

Epoch: 5| Step: 1
Training loss: 2.440415620803833
Validation loss: 2.1620308583782566

Epoch: 5| Step: 2
Training loss: 0.8316940069198608
Validation loss: 2.171078324317932

Epoch: 5| Step: 3
Training loss: 1.9362223148345947
Validation loss: 2.1844580224765244

Epoch: 5| Step: 4
Training loss: 1.7953393459320068
Validation loss: 2.156058749844951

Epoch: 5| Step: 5
Training loss: 1.7567462921142578
Validation loss: 2.1352858581850604

Epoch: 5| Step: 6
Training loss: 2.1392290592193604
Validation loss: 2.1028770349359

Epoch: 5| Step: 7
Training loss: 1.4157111644744873
Validation loss: 2.099834547247938

Epoch: 5| Step: 8
Training loss: 1.9517196416854858
Validation loss: 2.0994743941932597

Epoch: 5| Step: 9
Training loss: 1.7714240550994873
Validation loss: 2.088721389411598

Epoch: 5| Step: 10
Training loss: 1.7612797021865845
Validation loss: 2.135867762309249

Epoch: 302| Step: 0
Training loss: 2.302410125732422
Validation loss: 2.1276550831333285

Epoch: 5| Step: 1
Training loss: 2.0463995933532715
Validation loss: 2.155966035781368

Epoch: 5| Step: 2
Training loss: 1.6820571422576904
Validation loss: 2.1724189840337282

Epoch: 5| Step: 3
Training loss: 2.2893426418304443
Validation loss: 2.1957680704773113

Epoch: 5| Step: 4
Training loss: 1.308424711227417
Validation loss: 2.2060796958143993

Epoch: 5| Step: 5
Training loss: 1.9163808822631836
Validation loss: 2.2514031907563568

Epoch: 5| Step: 6
Training loss: 1.9659664630889893
Validation loss: 2.247773455035302

Epoch: 5| Step: 7
Training loss: 1.3172128200531006
Validation loss: 2.2080116784700783

Epoch: 5| Step: 8
Training loss: 2.08693265914917
Validation loss: 2.1676483359388126

Epoch: 5| Step: 9
Training loss: 1.7884912490844727
Validation loss: 2.1349520042378414

Epoch: 5| Step: 10
Training loss: 1.2138868570327759
Validation loss: 2.090613362609699

Epoch: 303| Step: 0
Training loss: 1.633374810218811
Validation loss: 2.071960823510283

Epoch: 5| Step: 1
Training loss: 1.1751102209091187
Validation loss: 2.0531692838156097

Epoch: 5| Step: 2
Training loss: 2.6389923095703125
Validation loss: 2.0440207271165747

Epoch: 5| Step: 3
Training loss: 1.5260117053985596
Validation loss: 2.0546996080747215

Epoch: 5| Step: 4
Training loss: 1.4760440587997437
Validation loss: 2.058415787194365

Epoch: 5| Step: 5
Training loss: 2.1349427700042725
Validation loss: 2.0643977324167886

Epoch: 5| Step: 6
Training loss: 1.7693655490875244
Validation loss: 2.0834846035126717

Epoch: 5| Step: 7
Training loss: 2.3933370113372803
Validation loss: 2.1414961263697636

Epoch: 5| Step: 8
Training loss: 1.7471723556518555
Validation loss: 2.1441711687272593

Epoch: 5| Step: 9
Training loss: 1.6112200021743774
Validation loss: 2.199627471226518

Epoch: 5| Step: 10
Training loss: 2.0518808364868164
Validation loss: 2.1785177159053024

Epoch: 304| Step: 0
Training loss: 1.8401634693145752
Validation loss: 2.1705000605634464

Epoch: 5| Step: 1
Training loss: 1.8029603958129883
Validation loss: 2.1883866966411634

Epoch: 5| Step: 2
Training loss: 1.4342195987701416
Validation loss: 2.1898921894770798

Epoch: 5| Step: 3
Training loss: 1.9998117685317993
Validation loss: 2.1922272584771596

Epoch: 5| Step: 4
Training loss: 1.6686652898788452
Validation loss: 2.190634947951122

Epoch: 5| Step: 5
Training loss: 2.1599061489105225
Validation loss: 2.1766720253934144

Epoch: 5| Step: 6
Training loss: 1.5529537200927734
Validation loss: 2.1333158067477647

Epoch: 5| Step: 7
Training loss: 1.6750284433364868
Validation loss: 2.1304206719962497

Epoch: 5| Step: 8
Training loss: 1.751004934310913
Validation loss: 2.1086306277141778

Epoch: 5| Step: 9
Training loss: 2.0780742168426514
Validation loss: 2.099422570197813

Epoch: 5| Step: 10
Training loss: 2.157808303833008
Validation loss: 2.1235110554643857

Epoch: 305| Step: 0
Training loss: 1.7695306539535522
Validation loss: 2.147984694409114

Epoch: 5| Step: 1
Training loss: 1.7708215713500977
Validation loss: 2.155564046675159

Epoch: 5| Step: 2
Training loss: 1.091989278793335
Validation loss: 2.157668346999794

Epoch: 5| Step: 3
Training loss: 1.5111700296401978
Validation loss: 2.1400200936102096

Epoch: 5| Step: 4
Training loss: 1.6438124179840088
Validation loss: 2.125852049037974

Epoch: 5| Step: 5
Training loss: 2.513378858566284
Validation loss: 2.1192380369350476

Epoch: 5| Step: 6
Training loss: 1.7478673458099365
Validation loss: 2.1383358047854517

Epoch: 5| Step: 7
Training loss: 1.5799314975738525
Validation loss: 2.1389602332986812

Epoch: 5| Step: 8
Training loss: 1.887376070022583
Validation loss: 2.1885617830420054

Epoch: 5| Step: 9
Training loss: 2.2385237216949463
Validation loss: 2.197569421542588

Epoch: 5| Step: 10
Training loss: 1.9757966995239258
Validation loss: 2.2066310515967746

Epoch: 306| Step: 0
Training loss: 1.1316378116607666
Validation loss: 2.215195071312689

Epoch: 5| Step: 1
Training loss: 1.6376606225967407
Validation loss: 2.1952769653771513

Epoch: 5| Step: 2
Training loss: 1.9906680583953857
Validation loss: 2.1899172413733696

Epoch: 5| Step: 3
Training loss: 1.293402910232544
Validation loss: 2.1719810603767313

Epoch: 5| Step: 4
Training loss: 1.7589271068572998
Validation loss: 2.1743659639871247

Epoch: 5| Step: 5
Training loss: 2.1521761417388916
Validation loss: 2.1308533350626626

Epoch: 5| Step: 6
Training loss: 2.0510239601135254
Validation loss: 2.111634587728849

Epoch: 5| Step: 7
Training loss: 2.072289228439331
Validation loss: 2.1135058326105916

Epoch: 5| Step: 8
Training loss: 2.3358168601989746
Validation loss: 2.1230971044109714

Epoch: 5| Step: 9
Training loss: 1.716962218284607
Validation loss: 2.1326472272155104

Epoch: 5| Step: 10
Training loss: 1.8325608968734741
Validation loss: 2.1063915401376705

Epoch: 307| Step: 0
Training loss: 1.5205333232879639
Validation loss: 2.106766475144253

Epoch: 5| Step: 1
Training loss: 1.7421869039535522
Validation loss: 2.0969163551125476

Epoch: 5| Step: 2
Training loss: 2.2682945728302
Validation loss: 2.1099669548772995

Epoch: 5| Step: 3
Training loss: 2.0495212078094482
Validation loss: 2.1076959692021853

Epoch: 5| Step: 4
Training loss: 1.9003273248672485
Validation loss: 2.1446993761165167

Epoch: 5| Step: 5
Training loss: 1.6144460439682007
Validation loss: 2.1639109503838325

Epoch: 5| Step: 6
Training loss: 2.2565064430236816
Validation loss: 2.2128858027919645

Epoch: 5| Step: 7
Training loss: 1.2364507913589478
Validation loss: 2.19680679228998

Epoch: 5| Step: 8
Training loss: 1.796605110168457
Validation loss: 2.1654207450087353

Epoch: 5| Step: 9
Training loss: 1.3803743124008179
Validation loss: 2.2000272248380925

Epoch: 5| Step: 10
Training loss: 1.8397042751312256
Validation loss: 2.176344851011871

Epoch: 308| Step: 0
Training loss: 1.8685433864593506
Validation loss: 2.175122002119659

Epoch: 5| Step: 1
Training loss: 1.368560552597046
Validation loss: 2.161548299174155

Epoch: 5| Step: 2
Training loss: 2.0168142318725586
Validation loss: 2.114126158016984

Epoch: 5| Step: 3
Training loss: 1.895986557006836
Validation loss: 2.1371386794633764

Epoch: 5| Step: 4
Training loss: 1.71750009059906
Validation loss: 2.121282075041084

Epoch: 5| Step: 5
Training loss: 2.2152657508850098
Validation loss: 2.1095783736116145

Epoch: 5| Step: 6
Training loss: 1.6414467096328735
Validation loss: 2.1174224525369625

Epoch: 5| Step: 7
Training loss: 1.6714725494384766
Validation loss: 2.1107031324858307

Epoch: 5| Step: 8
Training loss: 1.4997572898864746
Validation loss: 2.106838822364807

Epoch: 5| Step: 9
Training loss: 2.124051094055176
Validation loss: 2.1236997522333616

Epoch: 5| Step: 10
Training loss: 1.4011739492416382
Validation loss: 2.1480227183270197

Epoch: 309| Step: 0
Training loss: 1.6582491397857666
Validation loss: 2.142639437029439

Epoch: 5| Step: 1
Training loss: 1.8904670476913452
Validation loss: 2.161453221433906

Epoch: 5| Step: 2
Training loss: 1.5966434478759766
Validation loss: 2.1491797380549933

Epoch: 5| Step: 3
Training loss: 1.9134525060653687
Validation loss: 2.162323554356893

Epoch: 5| Step: 4
Training loss: 1.5163944959640503
Validation loss: 2.1438657468365085

Epoch: 5| Step: 5
Training loss: 1.8892905712127686
Validation loss: 2.1501397279001053

Epoch: 5| Step: 6
Training loss: 1.8500925302505493
Validation loss: 2.1515563713606967

Epoch: 5| Step: 7
Training loss: 1.7519142627716064
Validation loss: 2.1572683036968274

Epoch: 5| Step: 8
Training loss: 2.0663037300109863
Validation loss: 2.1682942862151773

Epoch: 5| Step: 9
Training loss: 1.634610891342163
Validation loss: 2.1709021393970778

Epoch: 5| Step: 10
Training loss: 1.5847339630126953
Validation loss: 2.169740638425273

Epoch: 310| Step: 0
Training loss: 2.047799587249756
Validation loss: 2.174260195865426

Epoch: 5| Step: 1
Training loss: 1.2688757181167603
Validation loss: 2.1690083139686176

Epoch: 5| Step: 2
Training loss: 1.4409297704696655
Validation loss: 2.1436054783482708

Epoch: 5| Step: 3
Training loss: 1.8879539966583252
Validation loss: 2.162687397772266

Epoch: 5| Step: 4
Training loss: 1.4262237548828125
Validation loss: 2.161126603362381

Epoch: 5| Step: 5
Training loss: 1.4053629636764526
Validation loss: 2.195957822184409

Epoch: 5| Step: 6
Training loss: 1.6213340759277344
Validation loss: 2.20064180128036

Epoch: 5| Step: 7
Training loss: 2.317995071411133
Validation loss: 2.2090771044454267

Epoch: 5| Step: 8
Training loss: 1.942706823348999
Validation loss: 2.213561019589824

Epoch: 5| Step: 9
Training loss: 1.823603868484497
Validation loss: 2.1851984275284635

Epoch: 5| Step: 10
Training loss: 2.1313703060150146
Validation loss: 2.148721089927099

Epoch: 311| Step: 0
Training loss: 1.4869850873947144
Validation loss: 2.145651509684901

Epoch: 5| Step: 1
Training loss: 2.2531039714813232
Validation loss: 2.098244860608091

Epoch: 5| Step: 2
Training loss: 1.9893890619277954
Validation loss: 2.103353282456757

Epoch: 5| Step: 3
Training loss: 2.2551937103271484
Validation loss: 2.128008920659301

Epoch: 5| Step: 4
Training loss: 1.6106733083724976
Validation loss: 2.1057785787890033

Epoch: 5| Step: 5
Training loss: 1.6102266311645508
Validation loss: 2.0976165122883295

Epoch: 5| Step: 6
Training loss: 1.5394282341003418
Validation loss: 2.08462962027519

Epoch: 5| Step: 7
Training loss: 1.4290368556976318
Validation loss: 2.086459113705543

Epoch: 5| Step: 8
Training loss: 1.791150450706482
Validation loss: 2.0926300966611473

Epoch: 5| Step: 9
Training loss: 1.127890944480896
Validation loss: 2.118217445188953

Epoch: 5| Step: 10
Training loss: 2.316828966140747
Validation loss: 2.1525754403042536

Epoch: 312| Step: 0
Training loss: 1.5296560525894165
Validation loss: 2.2064728813786663

Epoch: 5| Step: 1
Training loss: 1.6909687519073486
Validation loss: 2.2521334463550198

Epoch: 5| Step: 2
Training loss: 1.8071517944335938
Validation loss: 2.2792525393988496

Epoch: 5| Step: 3
Training loss: 2.04945969581604
Validation loss: 2.3180810687362507

Epoch: 5| Step: 4
Training loss: 2.072774887084961
Validation loss: 2.316775547560825

Epoch: 5| Step: 5
Training loss: 2.2070882320404053
Validation loss: 2.2675496224434144

Epoch: 5| Step: 6
Training loss: 1.8943450450897217
Validation loss: 2.234893973155688

Epoch: 5| Step: 7
Training loss: 1.338050127029419
Validation loss: 2.1791635867088073

Epoch: 5| Step: 8
Training loss: 1.2775099277496338
Validation loss: 2.125513228037024

Epoch: 5| Step: 9
Training loss: 1.4567406177520752
Validation loss: 2.097454047972156

Epoch: 5| Step: 10
Training loss: 2.2262141704559326
Validation loss: 2.0585381215618503

Epoch: 313| Step: 0
Training loss: 1.691642165184021
Validation loss: 2.0583592614819928

Epoch: 5| Step: 1
Training loss: 2.030646800994873
Validation loss: 2.056102288666592

Epoch: 5| Step: 2
Training loss: 1.5073082447052002
Validation loss: 2.0665452941771476

Epoch: 5| Step: 3
Training loss: 1.7639080286026
Validation loss: 2.0738864509008264

Epoch: 5| Step: 4
Training loss: 1.7873594760894775
Validation loss: 2.1029277411840295

Epoch: 5| Step: 5
Training loss: 1.519391417503357
Validation loss: 2.1343800175574517

Epoch: 5| Step: 6
Training loss: 1.7447487115859985
Validation loss: 2.181675445648932

Epoch: 5| Step: 7
Training loss: 1.4879169464111328
Validation loss: 2.1828642301661993

Epoch: 5| Step: 8
Training loss: 2.026174545288086
Validation loss: 2.2107313666292416

Epoch: 5| Step: 9
Training loss: 2.250523328781128
Validation loss: 2.225648041694395

Epoch: 5| Step: 10
Training loss: 1.3875439167022705
Validation loss: 2.2368927565954064

Epoch: 314| Step: 0
Training loss: 1.6497989892959595
Validation loss: 2.2199808833419636

Epoch: 5| Step: 1
Training loss: 1.28903067111969
Validation loss: 2.2139024606315036

Epoch: 5| Step: 2
Training loss: 1.7540206909179688
Validation loss: 2.2052270109935472

Epoch: 5| Step: 3
Training loss: 1.7436577081680298
Validation loss: 2.203454009948238

Epoch: 5| Step: 4
Training loss: 1.651885986328125
Validation loss: 2.2233541832175305

Epoch: 5| Step: 5
Training loss: 2.131544828414917
Validation loss: 2.2210029914814937

Epoch: 5| Step: 6
Training loss: 1.4568949937820435
Validation loss: 2.1806412358437814

Epoch: 5| Step: 7
Training loss: 1.817967176437378
Validation loss: 2.173610071982107

Epoch: 5| Step: 8
Training loss: 1.8750731945037842
Validation loss: 2.1372677254420456

Epoch: 5| Step: 9
Training loss: 1.9988431930541992
Validation loss: 2.1369930031479045

Epoch: 5| Step: 10
Training loss: 1.7585902214050293
Validation loss: 2.149033097810643

Epoch: 315| Step: 0
Training loss: 1.4062055349349976
Validation loss: 2.1442851302444295

Epoch: 5| Step: 1
Training loss: 2.221158504486084
Validation loss: 2.1335729475944274

Epoch: 5| Step: 2
Training loss: 1.393108606338501
Validation loss: 2.1330921521750827

Epoch: 5| Step: 3
Training loss: 2.3587405681610107
Validation loss: 2.116880762961603

Epoch: 5| Step: 4
Training loss: 1.5721601247787476
Validation loss: 2.129810215324484

Epoch: 5| Step: 5
Training loss: 2.1020729541778564
Validation loss: 2.141406169501684

Epoch: 5| Step: 6
Training loss: 1.826266884803772
Validation loss: 2.1577292924286215

Epoch: 5| Step: 7
Training loss: 1.2323181629180908
Validation loss: 2.158039318617954

Epoch: 5| Step: 8
Training loss: 1.8408458232879639
Validation loss: 2.1687236806397796

Epoch: 5| Step: 9
Training loss: 1.9197416305541992
Validation loss: 2.1667481814661333

Epoch: 5| Step: 10
Training loss: 1.2354276180267334
Validation loss: 2.1650962419407342

Epoch: 316| Step: 0
Training loss: 2.2125296592712402
Validation loss: 2.1708630284955426

Epoch: 5| Step: 1
Training loss: 2.000532627105713
Validation loss: 2.150245253757764

Epoch: 5| Step: 2
Training loss: 1.8301525115966797
Validation loss: 2.1231799715308735

Epoch: 5| Step: 3
Training loss: 1.705690622329712
Validation loss: 2.1099030471617177

Epoch: 5| Step: 4
Training loss: 1.634141206741333
Validation loss: 2.1090766845210904

Epoch: 5| Step: 5
Training loss: 1.664473295211792
Validation loss: 2.1104984014265

Epoch: 5| Step: 6
Training loss: 1.8946197032928467
Validation loss: 2.125316168672295

Epoch: 5| Step: 7
Training loss: 1.502017617225647
Validation loss: 2.1528997754537933

Epoch: 5| Step: 8
Training loss: 1.5552107095718384
Validation loss: 2.163038540911931

Epoch: 5| Step: 9
Training loss: 1.623710036277771
Validation loss: 2.1794790221798803

Epoch: 5| Step: 10
Training loss: 1.2495157718658447
Validation loss: 2.185059767897411

Epoch: 317| Step: 0
Training loss: 1.7012172937393188
Validation loss: 2.191163565522881

Epoch: 5| Step: 1
Training loss: 1.4510539770126343
Validation loss: 2.180913212478802

Epoch: 5| Step: 2
Training loss: 1.5564868450164795
Validation loss: 2.1690333530467045

Epoch: 5| Step: 3
Training loss: 1.1777197122573853
Validation loss: 2.14836630000863

Epoch: 5| Step: 4
Training loss: 1.6416456699371338
Validation loss: 2.1329086903602845

Epoch: 5| Step: 5
Training loss: 1.7913116216659546
Validation loss: 2.1137996232637795

Epoch: 5| Step: 6
Training loss: 1.727966070175171
Validation loss: 2.080728033537506

Epoch: 5| Step: 7
Training loss: 2.1244094371795654
Validation loss: 2.070139741384855

Epoch: 5| Step: 8
Training loss: 2.006403923034668
Validation loss: 2.0583820573745237

Epoch: 5| Step: 9
Training loss: 2.073359727859497
Validation loss: 2.032757706539605

Epoch: 5| Step: 10
Training loss: 1.6857792139053345
Validation loss: 2.0440884533748833

Epoch: 318| Step: 0
Training loss: 1.4517788887023926
Validation loss: 2.0526882243412796

Epoch: 5| Step: 1
Training loss: 1.8448874950408936
Validation loss: 2.0903373866952877

Epoch: 5| Step: 2
Training loss: 1.5595051050186157
Validation loss: 2.123479425266225

Epoch: 5| Step: 3
Training loss: 1.8478600978851318
Validation loss: 2.162755059939559

Epoch: 5| Step: 4
Training loss: 1.669316053390503
Validation loss: 2.178228889742205

Epoch: 5| Step: 5
Training loss: 1.975284218788147
Validation loss: 2.2101480640390867

Epoch: 5| Step: 6
Training loss: 1.5039739608764648
Validation loss: 2.229811132595103

Epoch: 5| Step: 7
Training loss: 1.9108970165252686
Validation loss: 2.2392503728148756

Epoch: 5| Step: 8
Training loss: 1.4384825229644775
Validation loss: 2.24664322791561

Epoch: 5| Step: 9
Training loss: 2.0191473960876465
Validation loss: 2.2505761449055006

Epoch: 5| Step: 10
Training loss: 1.6837143898010254
Validation loss: 2.2217899112291235

Epoch: 319| Step: 0
Training loss: 1.938197374343872
Validation loss: 2.2181566133294055

Epoch: 5| Step: 1
Training loss: 1.2229154109954834
Validation loss: 2.202642358759398

Epoch: 5| Step: 2
Training loss: 1.7486757040023804
Validation loss: 2.167941104981207

Epoch: 5| Step: 3
Training loss: 1.4653774499893188
Validation loss: 2.1741051212433846

Epoch: 5| Step: 4
Training loss: 1.5123028755187988
Validation loss: 2.137987523950556

Epoch: 5| Step: 5
Training loss: 1.696457862854004
Validation loss: 2.127851470824211

Epoch: 5| Step: 6
Training loss: 1.9770593643188477
Validation loss: 2.137207800342191

Epoch: 5| Step: 7
Training loss: 1.7246185541152954
Validation loss: 2.122368243432814

Epoch: 5| Step: 8
Training loss: 2.1577060222625732
Validation loss: 2.104519692800378

Epoch: 5| Step: 9
Training loss: 1.7081340551376343
Validation loss: 2.108011620019072

Epoch: 5| Step: 10
Training loss: 1.5093241930007935
Validation loss: 2.0882572730382285

Epoch: 320| Step: 0
Training loss: 2.0028889179229736
Validation loss: 2.1210651141341015

Epoch: 5| Step: 1
Training loss: 1.723633050918579
Validation loss: 2.1454685836709957

Epoch: 5| Step: 2
Training loss: 1.490424394607544
Validation loss: 2.1561939203610985

Epoch: 5| Step: 3
Training loss: 2.0659379959106445
Validation loss: 2.1739804257628736

Epoch: 5| Step: 4
Training loss: 1.4544775485992432
Validation loss: 2.1635675097024567

Epoch: 5| Step: 5
Training loss: 1.8913085460662842
Validation loss: 2.1758604049682617

Epoch: 5| Step: 6
Training loss: 1.534717082977295
Validation loss: 2.197045680015318

Epoch: 5| Step: 7
Training loss: 1.5429344177246094
Validation loss: 2.173067380023259

Epoch: 5| Step: 8
Training loss: 2.2179348468780518
Validation loss: 2.1611751279523297

Epoch: 5| Step: 9
Training loss: 1.276813268661499
Validation loss: 2.1656794214761383

Epoch: 5| Step: 10
Training loss: 1.2977287769317627
Validation loss: 2.174751676538939

Epoch: 321| Step: 0
Training loss: 1.972863793373108
Validation loss: 2.151385315002934

Epoch: 5| Step: 1
Training loss: 1.9478931427001953
Validation loss: 2.141594176651329

Epoch: 5| Step: 2
Training loss: 1.680771827697754
Validation loss: 2.1270244967552925

Epoch: 5| Step: 3
Training loss: 1.7539570331573486
Validation loss: 2.121555453987532

Epoch: 5| Step: 4
Training loss: 1.8155405521392822
Validation loss: 2.111395248802759

Epoch: 5| Step: 5
Training loss: 1.7977590560913086
Validation loss: 2.094088759473575

Epoch: 5| Step: 6
Training loss: 1.8203834295272827
Validation loss: 2.096483991992089

Epoch: 5| Step: 7
Training loss: 1.58829927444458
Validation loss: 2.1283586050874446

Epoch: 5| Step: 8
Training loss: 1.388822317123413
Validation loss: 2.1707595061230403

Epoch: 5| Step: 9
Training loss: 1.7493854761123657
Validation loss: 2.1844356700938237

Epoch: 5| Step: 10
Training loss: 0.8514928221702576
Validation loss: 2.202470156454271

Epoch: 322| Step: 0
Training loss: 1.6270358562469482
Validation loss: 2.1788870532025575

Epoch: 5| Step: 1
Training loss: 1.47048020362854
Validation loss: 2.1866406932953866

Epoch: 5| Step: 2
Training loss: 1.5539659261703491
Validation loss: 2.1667609830056467

Epoch: 5| Step: 3
Training loss: 1.4772274494171143
Validation loss: 2.1717092913966023

Epoch: 5| Step: 4
Training loss: 1.8041356801986694
Validation loss: 2.161191983889508

Epoch: 5| Step: 5
Training loss: 1.7650530338287354
Validation loss: 2.124103508969789

Epoch: 5| Step: 6
Training loss: 1.8280837535858154
Validation loss: 2.1109258039023286

Epoch: 5| Step: 7
Training loss: 1.7693029642105103
Validation loss: 2.120071928988221

Epoch: 5| Step: 8
Training loss: 1.6144936084747314
Validation loss: 2.0941410705607426

Epoch: 5| Step: 9
Training loss: 2.094658136367798
Validation loss: 2.1006075566814792

Epoch: 5| Step: 10
Training loss: 1.1938929557800293
Validation loss: 2.127389479708928

Epoch: 323| Step: 0
Training loss: 1.716148018836975
Validation loss: 2.1465802782325336

Epoch: 5| Step: 1
Training loss: 1.3598419427871704
Validation loss: 2.1912315532725346

Epoch: 5| Step: 2
Training loss: 2.091765880584717
Validation loss: 2.1637764387233283

Epoch: 5| Step: 3
Training loss: 1.5590307712554932
Validation loss: 2.161892719166253

Epoch: 5| Step: 4
Training loss: 1.6861121654510498
Validation loss: 2.146092217455628

Epoch: 5| Step: 5
Training loss: 1.6306028366088867
Validation loss: 2.1534823294608825

Epoch: 5| Step: 6
Training loss: 1.935280203819275
Validation loss: 2.1466964906261814

Epoch: 5| Step: 7
Training loss: 1.6614164113998413
Validation loss: 2.1213313969232703

Epoch: 5| Step: 8
Training loss: 1.786123275756836
Validation loss: 2.124983884954965

Epoch: 5| Step: 9
Training loss: 1.551628828048706
Validation loss: 2.0984780967876477

Epoch: 5| Step: 10
Training loss: 1.2163504362106323
Validation loss: 2.133191917532234

Epoch: 324| Step: 0
Training loss: 1.5347508192062378
Validation loss: 2.1378200951442925

Epoch: 5| Step: 1
Training loss: 1.861567735671997
Validation loss: 2.1575865002088648

Epoch: 5| Step: 2
Training loss: 1.806951880455017
Validation loss: 2.1898833756805747

Epoch: 5| Step: 3
Training loss: 1.3094247579574585
Validation loss: 2.212542159582979

Epoch: 5| Step: 4
Training loss: 1.5698171854019165
Validation loss: 2.2008741119856476

Epoch: 5| Step: 5
Training loss: 1.4741753339767456
Validation loss: 2.180883913911799

Epoch: 5| Step: 6
Training loss: 1.9573103189468384
Validation loss: 2.171897901001797

Epoch: 5| Step: 7
Training loss: 1.8052623271942139
Validation loss: 2.1463428825460453

Epoch: 5| Step: 8
Training loss: 1.7384965419769287
Validation loss: 2.1269035288082656

Epoch: 5| Step: 9
Training loss: 1.6669833660125732
Validation loss: 2.123858718461888

Epoch: 5| Step: 10
Training loss: 1.3997044563293457
Validation loss: 2.1353786735124487

Epoch: 325| Step: 0
Training loss: 1.824835181236267
Validation loss: 2.1312487997034544

Epoch: 5| Step: 1
Training loss: 1.764792799949646
Validation loss: 2.1186309322234123

Epoch: 5| Step: 2
Training loss: 1.7382838726043701
Validation loss: 2.0876114829894035

Epoch: 5| Step: 3
Training loss: 1.801351547241211
Validation loss: 2.111334011118899

Epoch: 5| Step: 4
Training loss: 1.554780125617981
Validation loss: 2.12545935825635

Epoch: 5| Step: 5
Training loss: 1.3096868991851807
Validation loss: 2.1316986737712735

Epoch: 5| Step: 6
Training loss: 1.7973957061767578
Validation loss: 2.1443866081135248

Epoch: 5| Step: 7
Training loss: 1.4878201484680176
Validation loss: 2.144687952533845

Epoch: 5| Step: 8
Training loss: 1.639133095741272
Validation loss: 2.1332524194512317

Epoch: 5| Step: 9
Training loss: 1.276227593421936
Validation loss: 2.159085025069534

Epoch: 5| Step: 10
Training loss: 2.099635601043701
Validation loss: 2.1677138728480183

Epoch: 326| Step: 0
Training loss: 1.7143442630767822
Validation loss: 2.1843935622963855

Epoch: 5| Step: 1
Training loss: 1.8105665445327759
Validation loss: 2.209124893270513

Epoch: 5| Step: 2
Training loss: 1.4426469802856445
Validation loss: 2.219108445670015

Epoch: 5| Step: 3
Training loss: 1.6289079189300537
Validation loss: 2.230521627651748

Epoch: 5| Step: 4
Training loss: 1.3390651941299438
Validation loss: 2.218394612753263

Epoch: 5| Step: 5
Training loss: 1.858245849609375
Validation loss: 2.253905188652777

Epoch: 5| Step: 6
Training loss: 2.2246859073638916
Validation loss: 2.2456472919833277

Epoch: 5| Step: 7
Training loss: 1.8325269222259521
Validation loss: 2.189903279786469

Epoch: 5| Step: 8
Training loss: 1.4837349653244019
Validation loss: 2.1858749979285785

Epoch: 5| Step: 9
Training loss: 1.5449597835540771
Validation loss: 2.119840386093304

Epoch: 5| Step: 10
Training loss: 1.3424814939498901
Validation loss: 2.105531132349404

Epoch: 327| Step: 0
Training loss: 2.5261154174804688
Validation loss: 2.0688985675893803

Epoch: 5| Step: 1
Training loss: 1.8299192190170288
Validation loss: 2.0876668422452864

Epoch: 5| Step: 2
Training loss: 1.7326314449310303
Validation loss: 2.062224954687139

Epoch: 5| Step: 3
Training loss: 1.2149229049682617
Validation loss: 2.063525774145639

Epoch: 5| Step: 4
Training loss: 1.6787474155426025
Validation loss: 2.0922530748510875

Epoch: 5| Step: 5
Training loss: 1.1946463584899902
Validation loss: 2.1180492729269047

Epoch: 5| Step: 6
Training loss: 1.5980257987976074
Validation loss: 2.105395177359222

Epoch: 5| Step: 7
Training loss: 1.612288236618042
Validation loss: 2.158689332264726

Epoch: 5| Step: 8
Training loss: 1.3909103870391846
Validation loss: 2.154206222103488

Epoch: 5| Step: 9
Training loss: 1.8444267511367798
Validation loss: 2.19478242499854

Epoch: 5| Step: 10
Training loss: 1.5695711374282837
Validation loss: 2.1947561182001585

Epoch: 328| Step: 0
Training loss: 1.4458051919937134
Validation loss: 2.2234261164101223

Epoch: 5| Step: 1
Training loss: 2.056583881378174
Validation loss: 2.2265748952024724

Epoch: 5| Step: 2
Training loss: 1.4986236095428467
Validation loss: 2.2317895325281287

Epoch: 5| Step: 3
Training loss: 1.4035305976867676
Validation loss: 2.206020660297845

Epoch: 5| Step: 4
Training loss: 2.205368757247925
Validation loss: 2.1735420073232343

Epoch: 5| Step: 5
Training loss: 1.4448058605194092
Validation loss: 2.14037303258014

Epoch: 5| Step: 6
Training loss: 1.3197243213653564
Validation loss: 2.1272508636597665

Epoch: 5| Step: 7
Training loss: 1.4904130697250366
Validation loss: 2.098938076726852

Epoch: 5| Step: 8
Training loss: 1.4284898042678833
Validation loss: 2.0679978298884567

Epoch: 5| Step: 9
Training loss: 1.7002639770507812
Validation loss: 2.1067686260387464

Epoch: 5| Step: 10
Training loss: 2.217653274536133
Validation loss: 2.1097353645550307

Epoch: 329| Step: 0
Training loss: 1.514492154121399
Validation loss: 2.1401093493225756

Epoch: 5| Step: 1
Training loss: 1.548795223236084
Validation loss: 2.1723924477895102

Epoch: 5| Step: 2
Training loss: 2.169625997543335
Validation loss: 2.2194974242999987

Epoch: 5| Step: 3
Training loss: 2.1132876873016357
Validation loss: 2.2547420301745014

Epoch: 5| Step: 4
Training loss: 1.7525924444198608
Validation loss: 2.2516863628100325

Epoch: 5| Step: 5
Training loss: 2.109349012374878
Validation loss: 2.2228534811286518

Epoch: 5| Step: 6
Training loss: 1.282602310180664
Validation loss: 2.225806433667419

Epoch: 5| Step: 7
Training loss: 1.5564110279083252
Validation loss: 2.2027032106153426

Epoch: 5| Step: 8
Training loss: 1.0085079669952393
Validation loss: 2.178892179202008

Epoch: 5| Step: 9
Training loss: 1.4078277349472046
Validation loss: 2.1476953593633508

Epoch: 5| Step: 10
Training loss: 1.2464599609375
Validation loss: 2.156737704430857

Epoch: 330| Step: 0
Training loss: 1.0536282062530518
Validation loss: 2.1261281608253397

Epoch: 5| Step: 1
Training loss: 1.5819361209869385
Validation loss: 2.1224191150357647

Epoch: 5| Step: 2
Training loss: 1.689125418663025
Validation loss: 2.108648278379953

Epoch: 5| Step: 3
Training loss: 1.8809659481048584
Validation loss: 2.095639351875551

Epoch: 5| Step: 4
Training loss: 1.7183891534805298
Validation loss: 2.113225452361568

Epoch: 5| Step: 5
Training loss: 2.2414920330047607
Validation loss: 2.0969413531723844

Epoch: 5| Step: 6
Training loss: 1.571533441543579
Validation loss: 2.1190597511106923

Epoch: 5| Step: 7
Training loss: 1.7112048864364624
Validation loss: 2.1009340786164805

Epoch: 5| Step: 8
Training loss: 1.1519629955291748
Validation loss: 2.1452319673312608

Epoch: 5| Step: 9
Training loss: 1.7493369579315186
Validation loss: 2.174698968087473

Epoch: 5| Step: 10
Training loss: 1.4085334539413452
Validation loss: 2.189505684760309

Epoch: 331| Step: 0
Training loss: 2.085329532623291
Validation loss: 2.223669168769672

Epoch: 5| Step: 1
Training loss: 1.4567264318466187
Validation loss: 2.2566655528160835

Epoch: 5| Step: 2
Training loss: 1.457770824432373
Validation loss: 2.2211930585163895

Epoch: 5| Step: 3
Training loss: 1.8958065509796143
Validation loss: 2.2404146989186606

Epoch: 5| Step: 4
Training loss: 1.1983106136322021
Validation loss: 2.2012659080566896

Epoch: 5| Step: 5
Training loss: 1.41912043094635
Validation loss: 2.196859957069479

Epoch: 5| Step: 6
Training loss: 1.3478420972824097
Validation loss: 2.2055477698644004

Epoch: 5| Step: 7
Training loss: 2.0213334560394287
Validation loss: 2.1998069568346907

Epoch: 5| Step: 8
Training loss: 1.6646778583526611
Validation loss: 2.1711649971623577

Epoch: 5| Step: 9
Training loss: 2.1256954669952393
Validation loss: 2.161731437970233

Epoch: 5| Step: 10
Training loss: 1.045454978942871
Validation loss: 2.1257597502841743

Epoch: 332| Step: 0
Training loss: 1.5105865001678467
Validation loss: 2.092038493002615

Epoch: 5| Step: 1
Training loss: 1.3176991939544678
Validation loss: 2.082251433403261

Epoch: 5| Step: 2
Training loss: 1.0449786186218262
Validation loss: 2.096323961852699

Epoch: 5| Step: 3
Training loss: 1.5047963857650757
Validation loss: 2.085383002476026

Epoch: 5| Step: 4
Training loss: 1.3445196151733398
Validation loss: 2.099732405395918

Epoch: 5| Step: 5
Training loss: 1.9597793817520142
Validation loss: 2.1492546514798234

Epoch: 5| Step: 6
Training loss: 1.7092548608779907
Validation loss: 2.191361745198568

Epoch: 5| Step: 7
Training loss: 1.8782867193222046
Validation loss: 2.1946313278649443

Epoch: 5| Step: 8
Training loss: 1.5413745641708374
Validation loss: 2.196058218197156

Epoch: 5| Step: 9
Training loss: 1.6898720264434814
Validation loss: 2.179197399846969

Epoch: 5| Step: 10
Training loss: 2.4859561920166016
Validation loss: 2.1839115645295832

Epoch: 333| Step: 0
Training loss: 2.333869457244873
Validation loss: 2.15913850004955

Epoch: 5| Step: 1
Training loss: 1.1294283866882324
Validation loss: 2.1489105583519064

Epoch: 5| Step: 2
Training loss: 1.8656299114227295
Validation loss: 2.143106939972088

Epoch: 5| Step: 3
Training loss: 2.0300700664520264
Validation loss: 2.102106599397557

Epoch: 5| Step: 4
Training loss: 1.5408271551132202
Validation loss: 2.0973810598414433

Epoch: 5| Step: 5
Training loss: 1.4461694955825806
Validation loss: 2.0919292665296987

Epoch: 5| Step: 6
Training loss: 1.2553832530975342
Validation loss: 2.0897096151946695

Epoch: 5| Step: 7
Training loss: 1.4844822883605957
Validation loss: 2.089286478616858

Epoch: 5| Step: 8
Training loss: 1.5836637020111084
Validation loss: 2.1032059500294347

Epoch: 5| Step: 9
Training loss: 1.0478025674819946
Validation loss: 2.136783153780045

Epoch: 5| Step: 10
Training loss: 2.0936713218688965
Validation loss: 2.1573506709068053

Epoch: 334| Step: 0
Training loss: 1.512540578842163
Validation loss: 2.183692927001625

Epoch: 5| Step: 1
Training loss: 1.8977266550064087
Validation loss: 2.1763882380659862

Epoch: 5| Step: 2
Training loss: 1.788964867591858
Validation loss: 2.178319425993068

Epoch: 5| Step: 3
Training loss: 0.7711724042892456
Validation loss: 2.1707191621103594

Epoch: 5| Step: 4
Training loss: 1.351966142654419
Validation loss: 2.1687212349266134

Epoch: 5| Step: 5
Training loss: 1.4221022129058838
Validation loss: 2.1950984795888266

Epoch: 5| Step: 6
Training loss: 1.4381544589996338
Validation loss: 2.22237334200131

Epoch: 5| Step: 7
Training loss: 2.2022995948791504
Validation loss: 2.1922113382688133

Epoch: 5| Step: 8
Training loss: 1.6609764099121094
Validation loss: 2.2139974165988225

Epoch: 5| Step: 9
Training loss: 1.6445506811141968
Validation loss: 2.1854088408972627

Epoch: 5| Step: 10
Training loss: 1.901336669921875
Validation loss: 2.155829478335637

Epoch: 335| Step: 0
Training loss: 2.145171642303467
Validation loss: 2.1496803401618876

Epoch: 5| Step: 1
Training loss: 0.8518122434616089
Validation loss: 2.1502994568117204

Epoch: 5| Step: 2
Training loss: 1.3321595191955566
Validation loss: 2.145423553323233

Epoch: 5| Step: 3
Training loss: 1.4273995161056519
Validation loss: 2.0967811769054783

Epoch: 5| Step: 4
Training loss: 1.9611520767211914
Validation loss: 2.0962748283980996

Epoch: 5| Step: 5
Training loss: 1.727469801902771
Validation loss: 2.103318494494243

Epoch: 5| Step: 6
Training loss: 1.865041732788086
Validation loss: 2.138677853409962

Epoch: 5| Step: 7
Training loss: 1.663652777671814
Validation loss: 2.1373661102787143

Epoch: 5| Step: 8
Training loss: 1.5605649948120117
Validation loss: 2.133300155721685

Epoch: 5| Step: 9
Training loss: 1.4094964265823364
Validation loss: 2.1525242790099113

Epoch: 5| Step: 10
Training loss: 1.3087584972381592
Validation loss: 2.1324256645735873

Epoch: 336| Step: 0
Training loss: 1.9175113439559937
Validation loss: 2.1456606926456576

Epoch: 5| Step: 1
Training loss: 1.5617897510528564
Validation loss: 2.1408274814646733

Epoch: 5| Step: 2
Training loss: 1.3304892778396606
Validation loss: 2.1218701613846647

Epoch: 5| Step: 3
Training loss: 1.3549823760986328
Validation loss: 2.1342241558977353

Epoch: 5| Step: 4
Training loss: 1.2046527862548828
Validation loss: 2.126354007310765

Epoch: 5| Step: 5
Training loss: 1.4299708604812622
Validation loss: 2.1625286033076625

Epoch: 5| Step: 6
Training loss: 1.8105674982070923
Validation loss: 2.12979975054341

Epoch: 5| Step: 7
Training loss: 1.2025926113128662
Validation loss: 2.1514832255660847

Epoch: 5| Step: 8
Training loss: 2.1241252422332764
Validation loss: 2.180766313306747

Epoch: 5| Step: 9
Training loss: 1.2313544750213623
Validation loss: 2.180238236663162

Epoch: 5| Step: 10
Training loss: 2.060748338699341
Validation loss: 2.188134226106828

Epoch: 337| Step: 0
Training loss: 1.3709838390350342
Validation loss: 2.1735289737742436

Epoch: 5| Step: 1
Training loss: 1.7962181568145752
Validation loss: 2.18496435944752

Epoch: 5| Step: 2
Training loss: 1.6447179317474365
Validation loss: 2.1652662343876337

Epoch: 5| Step: 3
Training loss: 1.8702621459960938
Validation loss: 2.1706227000041673

Epoch: 5| Step: 4
Training loss: 1.2070449590682983
Validation loss: 2.1733394630493654

Epoch: 5| Step: 5
Training loss: 1.785651445388794
Validation loss: 2.1799113878639798

Epoch: 5| Step: 6
Training loss: 1.4054657220840454
Validation loss: 2.1729559334375526

Epoch: 5| Step: 7
Training loss: 1.645264983177185
Validation loss: 2.156043832020093

Epoch: 5| Step: 8
Training loss: 1.0977751016616821
Validation loss: 2.118367246402207

Epoch: 5| Step: 9
Training loss: 1.7007850408554077
Validation loss: 2.106926107919344

Epoch: 5| Step: 10
Training loss: 1.7136479616165161
Validation loss: 2.0663478566754248

Epoch: 338| Step: 0
Training loss: 2.236070394515991
Validation loss: 2.0769011538515807

Epoch: 5| Step: 1
Training loss: 1.3844149112701416
Validation loss: 2.1070577841933056

Epoch: 5| Step: 2
Training loss: 1.6220070123672485
Validation loss: 2.145398014335222

Epoch: 5| Step: 3
Training loss: 1.3459056615829468
Validation loss: 2.1967021316610356

Epoch: 5| Step: 4
Training loss: 0.7089978456497192
Validation loss: 2.181741904186946

Epoch: 5| Step: 5
Training loss: 1.068983793258667
Validation loss: 2.1267689851022538

Epoch: 5| Step: 6
Training loss: 2.2806544303894043
Validation loss: 2.181787693372337

Epoch: 5| Step: 7
Training loss: 1.8774802684783936
Validation loss: 2.18620970941359

Epoch: 5| Step: 8
Training loss: 2.1675753593444824
Validation loss: 2.1993114973909114

Epoch: 5| Step: 9
Training loss: 1.5483325719833374
Validation loss: 2.170923758578557

Epoch: 5| Step: 10
Training loss: 1.1888947486877441
Validation loss: 2.14372774862474

Epoch: 339| Step: 0
Training loss: 1.0430517196655273
Validation loss: 2.135768436616467

Epoch: 5| Step: 1
Training loss: 1.6705341339111328
Validation loss: 2.1469912631537325

Epoch: 5| Step: 2
Training loss: 1.0816751718521118
Validation loss: 2.1758164013585737

Epoch: 5| Step: 3
Training loss: 1.9688717126846313
Validation loss: 2.153939131767519

Epoch: 5| Step: 4
Training loss: 1.228287935256958
Validation loss: 2.1794332560672554

Epoch: 5| Step: 5
Training loss: 1.2949724197387695
Validation loss: 2.16062137644778

Epoch: 5| Step: 6
Training loss: 2.3189120292663574
Validation loss: 2.1487755352450955

Epoch: 5| Step: 7
Training loss: 1.9581291675567627
Validation loss: 2.16767204448741

Epoch: 5| Step: 8
Training loss: 2.091845989227295
Validation loss: 2.1290593480551117

Epoch: 5| Step: 9
Training loss: 1.359305500984192
Validation loss: 2.1117921708732523

Epoch: 5| Step: 10
Training loss: 1.02253258228302
Validation loss: 2.1015048591039514

Epoch: 340| Step: 0
Training loss: 1.514756441116333
Validation loss: 2.1276379964684926

Epoch: 5| Step: 1
Training loss: 1.4467275142669678
Validation loss: 2.1107684719947075

Epoch: 5| Step: 2
Training loss: 1.3406368494033813
Validation loss: 2.1240581440669235

Epoch: 5| Step: 3
Training loss: 2.1046059131622314
Validation loss: 2.135636750087943

Epoch: 5| Step: 4
Training loss: 1.1353116035461426
Validation loss: 2.1524304395080893

Epoch: 5| Step: 5
Training loss: 1.0888844728469849
Validation loss: 2.1112589220846854

Epoch: 5| Step: 6
Training loss: 1.7235199213027954
Validation loss: 2.131251024943526

Epoch: 5| Step: 7
Training loss: 1.9649055004119873
Validation loss: 2.1310740811850435

Epoch: 5| Step: 8
Training loss: 1.670121431350708
Validation loss: 2.1526447649924987

Epoch: 5| Step: 9
Training loss: 1.5607013702392578
Validation loss: 2.144446284540238

Epoch: 5| Step: 10
Training loss: 1.4516123533248901
Validation loss: 2.185343929516372

Epoch: 341| Step: 0
Training loss: 1.4642516374588013
Validation loss: 2.1841975719698015

Epoch: 5| Step: 1
Training loss: 1.308111548423767
Validation loss: 2.1906951268514

Epoch: 5| Step: 2
Training loss: 1.7157875299453735
Validation loss: 2.1694580387043696

Epoch: 5| Step: 3
Training loss: 1.5348386764526367
Validation loss: 2.112071834584718

Epoch: 5| Step: 4
Training loss: 1.5947297811508179
Validation loss: 2.1242843289529123

Epoch: 5| Step: 5
Training loss: 2.2573556900024414
Validation loss: 2.080109150178971

Epoch: 5| Step: 6
Training loss: 1.4690696001052856
Validation loss: 2.0665228366851807

Epoch: 5| Step: 7
Training loss: 1.261217713356018
Validation loss: 2.0508872309038715

Epoch: 5| Step: 8
Training loss: 1.5446960926055908
Validation loss: 2.0732297000064643

Epoch: 5| Step: 9
Training loss: 1.4979350566864014
Validation loss: 2.10318116090631

Epoch: 5| Step: 10
Training loss: 1.5106346607208252
Validation loss: 2.1236346908794936

Epoch: 342| Step: 0
Training loss: 1.0661976337432861
Validation loss: 2.1396171328842

Epoch: 5| Step: 1
Training loss: 1.5592842102050781
Validation loss: 2.172460033047584

Epoch: 5| Step: 2
Training loss: 1.6011368036270142
Validation loss: 2.200343455037763

Epoch: 5| Step: 3
Training loss: 1.807845115661621
Validation loss: 2.2227652918907905

Epoch: 5| Step: 4
Training loss: 1.985498070716858
Validation loss: 2.2228297853982575

Epoch: 5| Step: 5
Training loss: 1.3785171508789062
Validation loss: 2.2087713108267835

Epoch: 5| Step: 6
Training loss: 1.9052757024765015
Validation loss: 2.177886466826162

Epoch: 5| Step: 7
Training loss: 1.8100906610488892
Validation loss: 2.153812644302204

Epoch: 5| Step: 8
Training loss: 1.0993276834487915
Validation loss: 2.1329328372914302

Epoch: 5| Step: 9
Training loss: 1.463194489479065
Validation loss: 2.118319152503885

Epoch: 5| Step: 10
Training loss: 1.276215672492981
Validation loss: 2.0966888922517017

Epoch: 343| Step: 0
Training loss: 1.3112744092941284
Validation loss: 2.0832613668134137

Epoch: 5| Step: 1
Training loss: 1.649404525756836
Validation loss: 2.0799317552197363

Epoch: 5| Step: 2
Training loss: 1.3704500198364258
Validation loss: 2.0867048668605026

Epoch: 5| Step: 3
Training loss: 1.9740930795669556
Validation loss: 2.106284649141373

Epoch: 5| Step: 4
Training loss: 1.8665882349014282
Validation loss: 2.115136536218787

Epoch: 5| Step: 5
Training loss: 1.6306202411651611
Validation loss: 2.12421739485956

Epoch: 5| Step: 6
Training loss: 1.509137749671936
Validation loss: 2.1802665777103876

Epoch: 5| Step: 7
Training loss: 1.4667003154754639
Validation loss: 2.1921086721522833

Epoch: 5| Step: 8
Training loss: 1.319667935371399
Validation loss: 2.2004700194122973

Epoch: 5| Step: 9
Training loss: 1.1864826679229736
Validation loss: 2.2036701684357016

Epoch: 5| Step: 10
Training loss: 1.6999154090881348
Validation loss: 2.1959893677824285

Epoch: 344| Step: 0
Training loss: 1.6709554195404053
Validation loss: 2.1918939326399114

Epoch: 5| Step: 1
Training loss: 1.4925252199172974
Validation loss: 2.173674967981154

Epoch: 5| Step: 2
Training loss: 1.513828992843628
Validation loss: 2.1402040732804166

Epoch: 5| Step: 3
Training loss: 0.8373549580574036
Validation loss: 2.1069598723483343

Epoch: 5| Step: 4
Training loss: 1.4230730533599854
Validation loss: 2.1119713206445017

Epoch: 5| Step: 5
Training loss: 0.8539503216743469
Validation loss: 2.1055230555995816

Epoch: 5| Step: 6
Training loss: 1.3563542366027832
Validation loss: 2.1142446558962584

Epoch: 5| Step: 7
Training loss: 2.096156597137451
Validation loss: 2.128112518659202

Epoch: 5| Step: 8
Training loss: 2.0287859439849854
Validation loss: 2.112006307930075

Epoch: 5| Step: 9
Training loss: 1.4476125240325928
Validation loss: 2.118177403685867

Epoch: 5| Step: 10
Training loss: 2.0487959384918213
Validation loss: 2.124673653674382

Epoch: 345| Step: 0
Training loss: 1.1429517269134521
Validation loss: 2.144468201104031

Epoch: 5| Step: 1
Training loss: 1.3328148126602173
Validation loss: 2.166204479432875

Epoch: 5| Step: 2
Training loss: 1.58717679977417
Validation loss: 2.1846065598149456

Epoch: 5| Step: 3
Training loss: 1.8248186111450195
Validation loss: 2.1778543174907727

Epoch: 5| Step: 4
Training loss: 1.6172904968261719
Validation loss: 2.1755436261494956

Epoch: 5| Step: 5
Training loss: 1.8418395519256592
Validation loss: 2.178512063077701

Epoch: 5| Step: 6
Training loss: 1.5976296663284302
Validation loss: 2.1629809615432576

Epoch: 5| Step: 7
Training loss: 1.333350419998169
Validation loss: 2.1822358562100317

Epoch: 5| Step: 8
Training loss: 1.351395606994629
Validation loss: 2.176659409717847

Epoch: 5| Step: 9
Training loss: 1.8064368963241577
Validation loss: 2.1578008359478367

Epoch: 5| Step: 10
Training loss: 1.274202585220337
Validation loss: 2.142430008098643

Epoch: 346| Step: 0
Training loss: 1.8658561706542969
Validation loss: 2.170474734357608

Epoch: 5| Step: 1
Training loss: 0.8377664685249329
Validation loss: 2.2057230011109383

Epoch: 5| Step: 2
Training loss: 1.2279771566390991
Validation loss: 2.198220460645614

Epoch: 5| Step: 3
Training loss: 2.191202163696289
Validation loss: 2.202997863933604

Epoch: 5| Step: 4
Training loss: 1.4499741792678833
Validation loss: 2.1775443451378935

Epoch: 5| Step: 5
Training loss: 1.7080962657928467
Validation loss: 2.174958082937425

Epoch: 5| Step: 6
Training loss: 1.1594287157058716
Validation loss: 2.1541476249694824

Epoch: 5| Step: 7
Training loss: 1.5830076932907104
Validation loss: 2.189372399801849

Epoch: 5| Step: 8
Training loss: 1.8920352458953857
Validation loss: 2.1759102216330906

Epoch: 5| Step: 9
Training loss: 1.4901092052459717
Validation loss: 2.1619877276882047

Epoch: 5| Step: 10
Training loss: 1.3917118310928345
Validation loss: 2.1261073696997856

Epoch: 347| Step: 0
Training loss: 1.7651370763778687
Validation loss: 2.1202551498207995

Epoch: 5| Step: 1
Training loss: 1.6550829410552979
Validation loss: 2.127751012002268

Epoch: 5| Step: 2
Training loss: 1.666565179824829
Validation loss: 2.0912139851559877

Epoch: 5| Step: 3
Training loss: 1.4111766815185547
Validation loss: 2.087118030876242

Epoch: 5| Step: 4
Training loss: 1.5854339599609375
Validation loss: 2.051368923597438

Epoch: 5| Step: 5
Training loss: 1.4442119598388672
Validation loss: 2.0420381535765944

Epoch: 5| Step: 6
Training loss: 1.3326303958892822
Validation loss: 2.0791574857568227

Epoch: 5| Step: 7
Training loss: 1.3052698373794556
Validation loss: 2.073632877360108

Epoch: 5| Step: 8
Training loss: 1.8710963726043701
Validation loss: 2.115521566842192

Epoch: 5| Step: 9
Training loss: 1.2074289321899414
Validation loss: 2.1186731246209916

Epoch: 5| Step: 10
Training loss: 1.5382537841796875
Validation loss: 2.1195558771010368

Epoch: 348| Step: 0
Training loss: 1.2855212688446045
Validation loss: 2.1534101527224303

Epoch: 5| Step: 1
Training loss: 1.481934905052185
Validation loss: 2.198194953703111

Epoch: 5| Step: 2
Training loss: 1.8208773136138916
Validation loss: 2.206705665075651

Epoch: 5| Step: 3
Training loss: 2.041710376739502
Validation loss: 2.192612260900518

Epoch: 5| Step: 4
Training loss: 1.6611725091934204
Validation loss: 2.2113109660404984

Epoch: 5| Step: 5
Training loss: 1.3168317079544067
Validation loss: 2.1793485867079867

Epoch: 5| Step: 6
Training loss: 1.3329521417617798
Validation loss: 2.1939397063306583

Epoch: 5| Step: 7
Training loss: 1.5846716165542603
Validation loss: 2.1959689612029702

Epoch: 5| Step: 8
Training loss: 1.5727756023406982
Validation loss: 2.194379929573305

Epoch: 5| Step: 9
Training loss: 1.480419397354126
Validation loss: 2.163056642778458

Epoch: 5| Step: 10
Training loss: 1.3465677499771118
Validation loss: 2.1238027080412833

Epoch: 349| Step: 0
Training loss: 1.1434866189956665
Validation loss: 2.148001565728136

Epoch: 5| Step: 1
Training loss: 1.571058988571167
Validation loss: 2.1412294551890385

Epoch: 5| Step: 2
Training loss: 1.3281551599502563
Validation loss: 2.1605048025808027

Epoch: 5| Step: 3
Training loss: 1.1118810176849365
Validation loss: 2.1726457688116256

Epoch: 5| Step: 4
Training loss: 1.3507083654403687
Validation loss: 2.190537796225599

Epoch: 5| Step: 5
Training loss: 1.817840337753296
Validation loss: 2.203387932110858

Epoch: 5| Step: 6
Training loss: 1.9549436569213867
Validation loss: 2.145241874520497

Epoch: 5| Step: 7
Training loss: 1.6701148748397827
Validation loss: 2.147208108696886

Epoch: 5| Step: 8
Training loss: 1.2134265899658203
Validation loss: 2.1542734638337167

Epoch: 5| Step: 9
Training loss: 2.073782205581665
Validation loss: 2.1729969311785955

Epoch: 5| Step: 10
Training loss: 1.5076720714569092
Validation loss: 2.1358654781054427

Epoch: 350| Step: 0
Training loss: 1.8416696786880493
Validation loss: 2.1323784782040502

Epoch: 5| Step: 1
Training loss: 0.9949830770492554
Validation loss: 2.120967380462154

Epoch: 5| Step: 2
Training loss: 1.7310291528701782
Validation loss: 2.1245355888079573

Epoch: 5| Step: 3
Training loss: 1.3309545516967773
Validation loss: 2.1093896332607476

Epoch: 5| Step: 4
Training loss: 1.6609718799591064
Validation loss: 2.1075468191536526

Epoch: 5| Step: 5
Training loss: 1.2191230058670044
Validation loss: 2.130473206120153

Epoch: 5| Step: 6
Training loss: 1.6490309238433838
Validation loss: 2.1543251070924985

Epoch: 5| Step: 7
Training loss: 1.495146632194519
Validation loss: 2.140509884844544

Epoch: 5| Step: 8
Training loss: 1.598065733909607
Validation loss: 2.13842838041244

Epoch: 5| Step: 9
Training loss: 1.7481849193572998
Validation loss: 2.1888813946836736

Epoch: 5| Step: 10
Training loss: 0.9172749519348145
Validation loss: 2.1556699583607335

Epoch: 351| Step: 0
Training loss: 1.9819228649139404
Validation loss: 2.167490500275807

Epoch: 5| Step: 1
Training loss: 1.3767389059066772
Validation loss: 2.1876634090177474

Epoch: 5| Step: 2
Training loss: 1.2788722515106201
Validation loss: 2.18949084256285

Epoch: 5| Step: 3
Training loss: 1.525119423866272
Validation loss: 2.2098736481000016

Epoch: 5| Step: 4
Training loss: 1.3905550241470337
Validation loss: 2.1958488290027907

Epoch: 5| Step: 5
Training loss: 1.1075589656829834
Validation loss: 2.1832042612055296

Epoch: 5| Step: 6
Training loss: 1.6225897073745728
Validation loss: 2.1719919943040416

Epoch: 5| Step: 7
Training loss: 1.640648603439331
Validation loss: 2.1421312644917476

Epoch: 5| Step: 8
Training loss: 1.2976983785629272
Validation loss: 2.127911731760989

Epoch: 5| Step: 9
Training loss: 1.332167387008667
Validation loss: 2.0952375819606166

Epoch: 5| Step: 10
Training loss: 1.6929157972335815
Validation loss: 2.097543506212132

Epoch: 352| Step: 0
Training loss: 1.2939695119857788
Validation loss: 2.1026752123268704

Epoch: 5| Step: 1
Training loss: 1.3939485549926758
Validation loss: 2.092086266445857

Epoch: 5| Step: 2
Training loss: 1.4085657596588135
Validation loss: 2.122792911785905

Epoch: 5| Step: 3
Training loss: 1.1801862716674805
Validation loss: 2.124735155413228

Epoch: 5| Step: 4
Training loss: 1.8204891681671143
Validation loss: 2.161569272318194

Epoch: 5| Step: 5
Training loss: 1.5037904977798462
Validation loss: 2.1766304713423534

Epoch: 5| Step: 6
Training loss: 1.4315191507339478
Validation loss: 2.174171793845392

Epoch: 5| Step: 7
Training loss: 1.577222228050232
Validation loss: 2.1690320020080893

Epoch: 5| Step: 8
Training loss: 1.179055094718933
Validation loss: 2.1691056118216565

Epoch: 5| Step: 9
Training loss: 1.7050853967666626
Validation loss: 2.1883840125094176

Epoch: 5| Step: 10
Training loss: 1.7577844858169556
Validation loss: 2.181452857550754

Epoch: 353| Step: 0
Training loss: 1.1564338207244873
Validation loss: 2.197849682582322

Epoch: 5| Step: 1
Training loss: 1.8875585794448853
Validation loss: 2.2006970695270005

Epoch: 5| Step: 2
Training loss: 1.228101134300232
Validation loss: 2.19431722035972

Epoch: 5| Step: 3
Training loss: 0.8359822034835815
Validation loss: 2.1712678247882473

Epoch: 5| Step: 4
Training loss: 2.003514528274536
Validation loss: 2.1854804126165246

Epoch: 5| Step: 5
Training loss: 1.216088056564331
Validation loss: 2.1629231053013958

Epoch: 5| Step: 6
Training loss: 1.9403425455093384
Validation loss: 2.1704255278392504

Epoch: 5| Step: 7
Training loss: 1.5229904651641846
Validation loss: 2.1722827521703576

Epoch: 5| Step: 8
Training loss: 1.0363171100616455
Validation loss: 2.1249071731362292

Epoch: 5| Step: 9
Training loss: 1.4500277042388916
Validation loss: 2.112588920900899

Epoch: 5| Step: 10
Training loss: 2.274527072906494
Validation loss: 2.06605419804973

Epoch: 354| Step: 0
Training loss: 0.9605073928833008
Validation loss: 2.0663607838333293

Epoch: 5| Step: 1
Training loss: 1.8912912607192993
Validation loss: 2.074268361573578

Epoch: 5| Step: 2
Training loss: 1.6209399700164795
Validation loss: 2.0608166135767454

Epoch: 5| Step: 3
Training loss: 1.7247825860977173
Validation loss: 2.0565754572550454

Epoch: 5| Step: 4
Training loss: 1.8479630947113037
Validation loss: 2.069007278770529

Epoch: 5| Step: 5
Training loss: 1.5759350061416626
Validation loss: 2.0856914404899842

Epoch: 5| Step: 6
Training loss: 0.9164568185806274
Validation loss: 2.0869815657215733

Epoch: 5| Step: 7
Training loss: 1.3996102809906006
Validation loss: 2.116431320867231

Epoch: 5| Step: 8
Training loss: 1.3526939153671265
Validation loss: 2.110110241879699

Epoch: 5| Step: 9
Training loss: 1.6856889724731445
Validation loss: 2.127773795076596

Epoch: 5| Step: 10
Training loss: 1.229431390762329
Validation loss: 2.1640899771003315

Epoch: 355| Step: 0
Training loss: 1.152707815170288
Validation loss: 2.1657326708557787

Epoch: 5| Step: 1
Training loss: 1.3189634084701538
Validation loss: 2.2013738821911555

Epoch: 5| Step: 2
Training loss: 1.0206191539764404
Validation loss: 2.21358904018197

Epoch: 5| Step: 3
Training loss: 1.761521577835083
Validation loss: 2.1724710925932853

Epoch: 5| Step: 4
Training loss: 1.2191530466079712
Validation loss: 2.1630545508476997

Epoch: 5| Step: 5
Training loss: 1.7136995792388916
Validation loss: 2.1496549370468303

Epoch: 5| Step: 6
Training loss: 1.6340692043304443
Validation loss: 2.1294124100797918

Epoch: 5| Step: 7
Training loss: 1.9200690984725952
Validation loss: 2.1159956891049623

Epoch: 5| Step: 8
Training loss: 0.8292099237442017
Validation loss: 2.1100487119408062

Epoch: 5| Step: 9
Training loss: 2.1515026092529297
Validation loss: 2.154000912943194

Epoch: 5| Step: 10
Training loss: 1.260474443435669
Validation loss: 2.143804227152178

Epoch: 356| Step: 0
Training loss: 1.1552857160568237
Validation loss: 2.163968696389147

Epoch: 5| Step: 1
Training loss: 1.431061029434204
Validation loss: 2.162447614054526

Epoch: 5| Step: 2
Training loss: 1.5745079517364502
Validation loss: 2.1786282241985364

Epoch: 5| Step: 3
Training loss: 1.524301528930664
Validation loss: 2.1682278263953423

Epoch: 5| Step: 4
Training loss: 0.9846011996269226
Validation loss: 2.1650797282495806

Epoch: 5| Step: 5
Training loss: 1.360349416732788
Validation loss: 2.1573417468737532

Epoch: 5| Step: 6
Training loss: 1.576465129852295
Validation loss: 2.1436559282323366

Epoch: 5| Step: 7
Training loss: 1.5183227062225342
Validation loss: 2.1253297123857724

Epoch: 5| Step: 8
Training loss: 1.5026352405548096
Validation loss: 2.099741881893527

Epoch: 5| Step: 9
Training loss: 1.7721636295318604
Validation loss: 2.112208197193761

Epoch: 5| Step: 10
Training loss: 1.5796337127685547
Validation loss: 2.157326234284268

Epoch: 357| Step: 0
Training loss: 1.4859098196029663
Validation loss: 2.160885453224182

Epoch: 5| Step: 1
Training loss: 1.4423801898956299
Validation loss: 2.1467903993463002

Epoch: 5| Step: 2
Training loss: 0.8754194378852844
Validation loss: 2.1600342168602893

Epoch: 5| Step: 3
Training loss: 1.461670160293579
Validation loss: 2.1962192161108858

Epoch: 5| Step: 4
Training loss: 1.3544155359268188
Validation loss: 2.196910745354109

Epoch: 5| Step: 5
Training loss: 0.9928923845291138
Validation loss: 2.18489892636576

Epoch: 5| Step: 6
Training loss: 1.2752459049224854
Validation loss: 2.1820999678745063

Epoch: 5| Step: 7
Training loss: 1.7289493083953857
Validation loss: 2.167205374727967

Epoch: 5| Step: 8
Training loss: 1.2067731618881226
Validation loss: 2.149640942132601

Epoch: 5| Step: 9
Training loss: 2.306408405303955
Validation loss: 2.1381433035737727

Epoch: 5| Step: 10
Training loss: 1.7133721113204956
Validation loss: 2.1426659425099692

Epoch: 358| Step: 0
Training loss: 1.40673828125
Validation loss: 2.1477439377897527

Epoch: 5| Step: 1
Training loss: 0.9939786195755005
Validation loss: 2.1599426782259377

Epoch: 5| Step: 2
Training loss: 1.682518720626831
Validation loss: 2.191845788750597

Epoch: 5| Step: 3
Training loss: 1.202760100364685
Validation loss: 2.188208051907119

Epoch: 5| Step: 4
Training loss: 1.2472288608551025
Validation loss: 2.1831610997517905

Epoch: 5| Step: 5
Training loss: 1.076048493385315
Validation loss: 2.1964360898540867

Epoch: 5| Step: 6
Training loss: 2.0237677097320557
Validation loss: 2.212191102325275

Epoch: 5| Step: 7
Training loss: 1.818992257118225
Validation loss: 2.195550516087522

Epoch: 5| Step: 8
Training loss: 1.1567836999893188
Validation loss: 2.1723943448835805

Epoch: 5| Step: 9
Training loss: 1.4725884199142456
Validation loss: 2.2153319594680623

Epoch: 5| Step: 10
Training loss: 1.8298375606536865
Validation loss: 2.1957005595648162

Epoch: 359| Step: 0
Training loss: 0.9403796195983887
Validation loss: 2.2030061957656697

Epoch: 5| Step: 1
Training loss: 1.3940948247909546
Validation loss: 2.190188430970715

Epoch: 5| Step: 2
Training loss: 1.5280601978302002
Validation loss: 2.2382474099436114

Epoch: 5| Step: 3
Training loss: 1.1074018478393555
Validation loss: 2.241234984449161

Epoch: 5| Step: 4
Training loss: 2.165698528289795
Validation loss: 2.240167684452508

Epoch: 5| Step: 5
Training loss: 1.2886112928390503
Validation loss: 2.256053475923436

Epoch: 5| Step: 6
Training loss: 1.5361993312835693
Validation loss: 2.1975386758004465

Epoch: 5| Step: 7
Training loss: 1.7169997692108154
Validation loss: 2.155629854048452

Epoch: 5| Step: 8
Training loss: 1.5610538721084595
Validation loss: 2.1381855190441175

Epoch: 5| Step: 9
Training loss: 1.7079931497573853
Validation loss: 2.1209787989175446

Epoch: 5| Step: 10
Training loss: 0.7722659111022949
Validation loss: 2.1096158232740176

Epoch: 360| Step: 0
Training loss: 1.3613708019256592
Validation loss: 2.1305147242802445

Epoch: 5| Step: 1
Training loss: 1.6358308792114258
Validation loss: 2.120086121302779

Epoch: 5| Step: 2
Training loss: 1.6393706798553467
Validation loss: 2.1047309085886967

Epoch: 5| Step: 3
Training loss: 1.3783719539642334
Validation loss: 2.1318342096062115

Epoch: 5| Step: 4
Training loss: 1.5262384414672852
Validation loss: 2.1581326812826176

Epoch: 5| Step: 5
Training loss: 1.4346282482147217
Validation loss: 2.176503340403239

Epoch: 5| Step: 6
Training loss: 0.7840844988822937
Validation loss: 2.1658786176353373

Epoch: 5| Step: 7
Training loss: 1.6631752252578735
Validation loss: 2.1635062592003935

Epoch: 5| Step: 8
Training loss: 1.381320595741272
Validation loss: 2.1919206419298725

Epoch: 5| Step: 9
Training loss: 1.6351242065429688
Validation loss: 2.1506271746850785

Epoch: 5| Step: 10
Training loss: 1.5358949899673462
Validation loss: 2.1445406700975154

Epoch: 361| Step: 0
Training loss: 1.7429819107055664
Validation loss: 2.1435845974952943

Epoch: 5| Step: 1
Training loss: 1.0198134183883667
Validation loss: 2.1300241793355634

Epoch: 5| Step: 2
Training loss: 1.2834179401397705
Validation loss: 2.137275872691985

Epoch: 5| Step: 3
Training loss: 1.667072057723999
Validation loss: 2.1300406584175686

Epoch: 5| Step: 4
Training loss: 1.1888477802276611
Validation loss: 2.154714103667967

Epoch: 5| Step: 5
Training loss: 1.1551697254180908
Validation loss: 2.1492059717896166

Epoch: 5| Step: 6
Training loss: 2.5858218669891357
Validation loss: 2.1424899588349047

Epoch: 5| Step: 7
Training loss: 0.9684236645698547
Validation loss: 2.139651434395903

Epoch: 5| Step: 8
Training loss: 0.8604122400283813
Validation loss: 2.139691129807503

Epoch: 5| Step: 9
Training loss: 1.5669399499893188
Validation loss: 2.123366114913776

Epoch: 5| Step: 10
Training loss: 1.4915412664413452
Validation loss: 2.116092058920091

Epoch: 362| Step: 0
Training loss: 1.588727593421936
Validation loss: 2.0986047931896743

Epoch: 5| Step: 1
Training loss: 1.4656503200531006
Validation loss: 2.10972079923076

Epoch: 5| Step: 2
Training loss: 0.9172881245613098
Validation loss: 2.0815421278758715

Epoch: 5| Step: 3
Training loss: 1.8666391372680664
Validation loss: 2.1415566129069172

Epoch: 5| Step: 4
Training loss: 1.3654850721359253
Validation loss: 2.121140323659425

Epoch: 5| Step: 5
Training loss: 1.288184642791748
Validation loss: 2.1376838735354844

Epoch: 5| Step: 6
Training loss: 1.2985364198684692
Validation loss: 2.1281278748666086

Epoch: 5| Step: 7
Training loss: 1.195923924446106
Validation loss: 2.141634161754321

Epoch: 5| Step: 8
Training loss: 1.6534831523895264
Validation loss: 2.142069790952949

Epoch: 5| Step: 9
Training loss: 1.0337036848068237
Validation loss: 2.157020843157204

Epoch: 5| Step: 10
Training loss: 2.009685754776001
Validation loss: 2.1125861008961997

Epoch: 363| Step: 0
Training loss: 1.7286293506622314
Validation loss: 2.131545361652169

Epoch: 5| Step: 1
Training loss: 0.6210692524909973
Validation loss: 2.1115979315132223

Epoch: 5| Step: 2
Training loss: 1.8492443561553955
Validation loss: 2.108451489479311

Epoch: 5| Step: 3
Training loss: 1.3795089721679688
Validation loss: 2.1014649227101314

Epoch: 5| Step: 4
Training loss: 1.2521775960922241
Validation loss: 2.079438095451683

Epoch: 5| Step: 5
Training loss: 1.6516624689102173
Validation loss: 2.104144347611294

Epoch: 5| Step: 6
Training loss: 1.5704587697982788
Validation loss: 2.119928806058822

Epoch: 5| Step: 7
Training loss: 1.504308819770813
Validation loss: 2.160858605497627

Epoch: 5| Step: 8
Training loss: 1.685243010520935
Validation loss: 2.1669528420253465

Epoch: 5| Step: 9
Training loss: 0.7765253782272339
Validation loss: 2.1622664056798464

Epoch: 5| Step: 10
Training loss: 1.441794514656067
Validation loss: 2.1736062137029504

Epoch: 364| Step: 0
Training loss: 1.3872628211975098
Validation loss: 2.165588376342609

Epoch: 5| Step: 1
Training loss: 1.8661508560180664
Validation loss: 2.1228000040977233

Epoch: 5| Step: 2
Training loss: 1.3132753372192383
Validation loss: 2.1309501663331063

Epoch: 5| Step: 3
Training loss: 0.8882814645767212
Validation loss: 2.1034283561091267

Epoch: 5| Step: 4
Training loss: 1.5710909366607666
Validation loss: 2.1187003453572593

Epoch: 5| Step: 5
Training loss: 1.7750184535980225
Validation loss: 2.095282793045044

Epoch: 5| Step: 6
Training loss: 1.3948695659637451
Validation loss: 2.1126224751113565

Epoch: 5| Step: 7
Training loss: 0.9742789268493652
Validation loss: 2.098820609431113

Epoch: 5| Step: 8
Training loss: 1.137784719467163
Validation loss: 2.0957804315833637

Epoch: 5| Step: 9
Training loss: 1.5436794757843018
Validation loss: 2.1023573029425835

Epoch: 5| Step: 10
Training loss: 1.3072227239608765
Validation loss: 2.140070810112902

Epoch: 365| Step: 0
Training loss: 2.009495496749878
Validation loss: 2.144463159704721

Epoch: 5| Step: 1
Training loss: 1.208485722541809
Validation loss: 2.151622349216092

Epoch: 5| Step: 2
Training loss: 1.768080711364746
Validation loss: 2.1340491233333463

Epoch: 5| Step: 3
Training loss: 1.1042934656143188
Validation loss: 2.137568755816388

Epoch: 5| Step: 4
Training loss: 1.1512938737869263
Validation loss: 2.1171821291728685

Epoch: 5| Step: 5
Training loss: 1.3053127527236938
Validation loss: 2.101837049248398

Epoch: 5| Step: 6
Training loss: 1.4401925802230835
Validation loss: 2.086823712113083

Epoch: 5| Step: 7
Training loss: 1.0744287967681885
Validation loss: 2.073442751361478

Epoch: 5| Step: 8
Training loss: 1.5037187337875366
Validation loss: 2.108276938879362

Epoch: 5| Step: 9
Training loss: 1.6005951166152954
Validation loss: 2.108367245684388

Epoch: 5| Step: 10
Training loss: 0.9596327543258667
Validation loss: 2.161882729940517

Epoch: 366| Step: 0
Training loss: 1.2384029626846313
Validation loss: 2.1683719722173547

Epoch: 5| Step: 1
Training loss: 1.3755388259887695
Validation loss: 2.1904388038061

Epoch: 5| Step: 2
Training loss: 0.8954342007637024
Validation loss: 2.1962596447237077

Epoch: 5| Step: 3
Training loss: 1.4467846155166626
Validation loss: 2.207153453621813

Epoch: 5| Step: 4
Training loss: 1.4972240924835205
Validation loss: 2.1831963857014975

Epoch: 5| Step: 5
Training loss: 1.48433518409729
Validation loss: 2.1700760113295687

Epoch: 5| Step: 6
Training loss: 1.8805580139160156
Validation loss: 2.1654862306451284

Epoch: 5| Step: 7
Training loss: 1.2110517024993896
Validation loss: 2.1603648611294326

Epoch: 5| Step: 8
Training loss: 1.2903791666030884
Validation loss: 2.1268518278675694

Epoch: 5| Step: 9
Training loss: 1.6652734279632568
Validation loss: 2.1152173062806487

Epoch: 5| Step: 10
Training loss: 1.4534281492233276
Validation loss: 2.080251779607547

Epoch: 367| Step: 0
Training loss: 1.0033113956451416
Validation loss: 2.083728324982428

Epoch: 5| Step: 1
Training loss: 1.373563289642334
Validation loss: 2.1757228553936048

Epoch: 5| Step: 2
Training loss: 1.555759072303772
Validation loss: 2.187179814102829

Epoch: 5| Step: 3
Training loss: 1.614549994468689
Validation loss: 2.205800599949334

Epoch: 5| Step: 4
Training loss: 1.3974390029907227
Validation loss: 2.210300890348291

Epoch: 5| Step: 5
Training loss: 0.7635628581047058
Validation loss: 2.154617146779132

Epoch: 5| Step: 6
Training loss: 1.5646089315414429
Validation loss: 2.1599909131244948

Epoch: 5| Step: 7
Training loss: 0.9444482922554016
Validation loss: 2.148720714353746

Epoch: 5| Step: 8
Training loss: 1.7668590545654297
Validation loss: 2.153876478954028

Epoch: 5| Step: 9
Training loss: 1.8303558826446533
Validation loss: 2.1395996488550657

Epoch: 5| Step: 10
Training loss: 1.5452719926834106
Validation loss: 2.0928488674984185

Epoch: 368| Step: 0
Training loss: 1.7300844192504883
Validation loss: 2.1041310589800597

Epoch: 5| Step: 1
Training loss: 1.1929370164871216
Validation loss: 2.086475988870026

Epoch: 5| Step: 2
Training loss: 1.4077632427215576
Validation loss: 2.1209500553787395

Epoch: 5| Step: 3
Training loss: 1.7186920642852783
Validation loss: 2.1117950716326312

Epoch: 5| Step: 4
Training loss: 1.2983338832855225
Validation loss: 2.1265296730943906

Epoch: 5| Step: 5
Training loss: 1.271526575088501
Validation loss: 2.2101918125665314

Epoch: 5| Step: 6
Training loss: 1.1542203426361084
Validation loss: 2.2314256557854275

Epoch: 5| Step: 7
Training loss: 1.4102907180786133
Validation loss: 2.258878004166388

Epoch: 5| Step: 8
Training loss: 0.9914861917495728
Validation loss: 2.17041511817645

Epoch: 5| Step: 9
Training loss: 1.6641714572906494
Validation loss: 2.135597700713783

Epoch: 5| Step: 10
Training loss: 1.687351107597351
Validation loss: 2.097671934353408

Epoch: 369| Step: 0
Training loss: 1.731469750404358
Validation loss: 2.1086030096136112

Epoch: 5| Step: 1
Training loss: 1.0465431213378906
Validation loss: 2.1325417898034535

Epoch: 5| Step: 2
Training loss: 1.8760020732879639
Validation loss: 2.1065154062804354

Epoch: 5| Step: 3
Training loss: 1.5404703617095947
Validation loss: 2.110386097303001

Epoch: 5| Step: 4
Training loss: 1.2709300518035889
Validation loss: 2.1094347866632606

Epoch: 5| Step: 5
Training loss: 1.3696365356445312
Validation loss: 2.0959537900904173

Epoch: 5| Step: 6
Training loss: 1.0639281272888184
Validation loss: 2.104630842003771

Epoch: 5| Step: 7
Training loss: 1.3186711072921753
Validation loss: 2.1751690769708283

Epoch: 5| Step: 8
Training loss: 1.4977965354919434
Validation loss: 2.223356416148524

Epoch: 5| Step: 9
Training loss: 1.619196891784668
Validation loss: 2.178152476587603

Epoch: 5| Step: 10
Training loss: 1.2292370796203613
Validation loss: 2.1450164318084717

Epoch: 370| Step: 0
Training loss: 1.5887248516082764
Validation loss: 2.105405251185099

Epoch: 5| Step: 1
Training loss: 0.8883476257324219
Validation loss: 2.0837761766167096

Epoch: 5| Step: 2
Training loss: 2.211430549621582
Validation loss: 2.126441160837809

Epoch: 5| Step: 3
Training loss: 1.2262271642684937
Validation loss: 2.1638440188541206

Epoch: 5| Step: 4
Training loss: 1.4311283826828003
Validation loss: 2.125038418718564

Epoch: 5| Step: 5
Training loss: 1.4821752309799194
Validation loss: 2.1820242661301807

Epoch: 5| Step: 6
Training loss: 0.8463951945304871
Validation loss: 2.191047368511077

Epoch: 5| Step: 7
Training loss: 1.4738777875900269
Validation loss: 2.1972042488795456

Epoch: 5| Step: 8
Training loss: 1.7226378917694092
Validation loss: 2.2255870526836765

Epoch: 5| Step: 9
Training loss: 0.9773851633071899
Validation loss: 2.2064063472132527

Epoch: 5| Step: 10
Training loss: 1.0147868394851685
Validation loss: 2.1846448388150943

Epoch: 371| Step: 0
Training loss: 1.5463125705718994
Validation loss: 2.1736876580022995

Epoch: 5| Step: 1
Training loss: 1.4157696962356567
Validation loss: 2.1517571121133785

Epoch: 5| Step: 2
Training loss: 1.4331905841827393
Validation loss: 2.1431383189334663

Epoch: 5| Step: 3
Training loss: 0.9336572885513306
Validation loss: 2.1087967285545925

Epoch: 5| Step: 4
Training loss: 1.378208875656128
Validation loss: 2.104647858168489

Epoch: 5| Step: 5
Training loss: 1.4108283519744873
Validation loss: 2.097138822719615

Epoch: 5| Step: 6
Training loss: 1.3178411722183228
Validation loss: 2.087332763979512

Epoch: 5| Step: 7
Training loss: 1.0969908237457275
Validation loss: 2.0683823836747037

Epoch: 5| Step: 8
Training loss: 1.7989580631256104
Validation loss: 2.089793271915887

Epoch: 5| Step: 9
Training loss: 1.1310267448425293
Validation loss: 2.0958655572706655

Epoch: 5| Step: 10
Training loss: 1.4860906600952148
Validation loss: 2.1243265623687417

Epoch: 372| Step: 0
Training loss: 1.2513525485992432
Validation loss: 2.1299599780831286

Epoch: 5| Step: 1
Training loss: 1.499647617340088
Validation loss: 2.1493757411997807

Epoch: 5| Step: 2
Training loss: 1.4063084125518799
Validation loss: 2.104733351738222

Epoch: 5| Step: 3
Training loss: 1.0639612674713135
Validation loss: 2.1106808762396536

Epoch: 5| Step: 4
Training loss: 0.9818450212478638
Validation loss: 2.0940284729003906

Epoch: 5| Step: 5
Training loss: 1.5241023302078247
Validation loss: 2.046496829678935

Epoch: 5| Step: 6
Training loss: 1.2402324676513672
Validation loss: 2.0608465094720163

Epoch: 5| Step: 7
Training loss: 1.428128719329834
Validation loss: 2.0529188738074353

Epoch: 5| Step: 8
Training loss: 1.1763904094696045
Validation loss: 2.1004844404036

Epoch: 5| Step: 9
Training loss: 1.3483235836029053
Validation loss: 2.0980858533613143

Epoch: 5| Step: 10
Training loss: 1.9342938661575317
Validation loss: 2.105095465977987

Epoch: 373| Step: 0
Training loss: 1.1030430793762207
Validation loss: 2.1346144112207557

Epoch: 5| Step: 1
Training loss: 1.0053173303604126
Validation loss: 2.143245789312547

Epoch: 5| Step: 2
Training loss: 1.349908471107483
Validation loss: 2.15397882974276

Epoch: 5| Step: 3
Training loss: 1.4839732646942139
Validation loss: 2.1558364514381654

Epoch: 5| Step: 4
Training loss: 2.1375632286071777
Validation loss: 2.149763495691361

Epoch: 5| Step: 5
Training loss: 1.0488255023956299
Validation loss: 2.1529640023426344

Epoch: 5| Step: 6
Training loss: 1.75111985206604
Validation loss: 2.112135830745902

Epoch: 5| Step: 7
Training loss: 0.809741199016571
Validation loss: 2.093352271664527

Epoch: 5| Step: 8
Training loss: 1.513750433921814
Validation loss: 2.061464725002166

Epoch: 5| Step: 9
Training loss: 1.5850389003753662
Validation loss: 2.0666926009680635

Epoch: 5| Step: 10
Training loss: 0.8831273913383484
Validation loss: 2.0380014142682477

Epoch: 374| Step: 0
Training loss: 1.740997314453125
Validation loss: 2.0569535275941253

Epoch: 5| Step: 1
Training loss: 1.0411485433578491
Validation loss: 2.0829123732864216

Epoch: 5| Step: 2
Training loss: 1.318985939025879
Validation loss: 2.1251454660969396

Epoch: 5| Step: 3
Training loss: 1.0580087900161743
Validation loss: 2.1144223431105256

Epoch: 5| Step: 4
Training loss: 1.6132252216339111
Validation loss: 2.112679640452067

Epoch: 5| Step: 5
Training loss: 1.0772212743759155
Validation loss: 2.1184483728101178

Epoch: 5| Step: 6
Training loss: 1.9230947494506836
Validation loss: 2.1644708007894535

Epoch: 5| Step: 7
Training loss: 1.2295795679092407
Validation loss: 2.189768442543604

Epoch: 5| Step: 8
Training loss: 1.3402901887893677
Validation loss: 2.198613287300192

Epoch: 5| Step: 9
Training loss: 1.064945936203003
Validation loss: 2.1709696887641825

Epoch: 5| Step: 10
Training loss: 1.3595705032348633
Validation loss: 2.160248556444722

Epoch: 375| Step: 0
Training loss: 1.251715898513794
Validation loss: 2.1761137952086744

Epoch: 5| Step: 1
Training loss: 1.7193365097045898
Validation loss: 2.1410818869067776

Epoch: 5| Step: 2
Training loss: 1.1241010427474976
Validation loss: 2.1515171707317395

Epoch: 5| Step: 3
Training loss: 1.2792890071868896
Validation loss: 2.152685239750852

Epoch: 5| Step: 4
Training loss: 1.1013940572738647
Validation loss: 2.1252757451867543

Epoch: 5| Step: 5
Training loss: 1.434422254562378
Validation loss: 2.140435544393396

Epoch: 5| Step: 6
Training loss: 1.3112355470657349
Validation loss: 2.1506459097708426

Epoch: 5| Step: 7
Training loss: 1.1510570049285889
Validation loss: 2.146497236785068

Epoch: 5| Step: 8
Training loss: 1.4313169717788696
Validation loss: 2.128917065999841

Epoch: 5| Step: 9
Training loss: 1.2914762496948242
Validation loss: 2.140643569730943

Epoch: 5| Step: 10
Training loss: 1.5052037239074707
Validation loss: 2.142064357316622

Epoch: 376| Step: 0
Training loss: 1.8671404123306274
Validation loss: 2.135550534853371

Epoch: 5| Step: 1
Training loss: 1.2472152709960938
Validation loss: 2.108183117323024

Epoch: 5| Step: 2
Training loss: 1.733912706375122
Validation loss: 2.1264189110007337

Epoch: 5| Step: 3
Training loss: 1.2386534214019775
Validation loss: 2.1240019977733655

Epoch: 5| Step: 4
Training loss: 0.9979496002197266
Validation loss: 2.105667778240737

Epoch: 5| Step: 5
Training loss: 1.6441755294799805
Validation loss: 2.1229557273208455

Epoch: 5| Step: 6
Training loss: 1.061815857887268
Validation loss: 2.0982736554197086

Epoch: 5| Step: 7
Training loss: 1.042671799659729
Validation loss: 2.0902202334455264

Epoch: 5| Step: 8
Training loss: 1.1170541048049927
Validation loss: 2.0936178673980055

Epoch: 5| Step: 9
Training loss: 1.0224963426589966
Validation loss: 2.092246583712998

Epoch: 5| Step: 10
Training loss: 1.4869580268859863
Validation loss: 2.0971938281930904

Epoch: 377| Step: 0
Training loss: 1.1026661396026611
Validation loss: 2.1126094992442797

Epoch: 5| Step: 1
Training loss: 1.0824735164642334
Validation loss: 2.1118448113882415

Epoch: 5| Step: 2
Training loss: 1.5413538217544556
Validation loss: 2.090732962854447

Epoch: 5| Step: 3
Training loss: 1.8068625926971436
Validation loss: 2.086911980823804

Epoch: 5| Step: 4
Training loss: 0.8130432367324829
Validation loss: 2.1093142570987826

Epoch: 5| Step: 5
Training loss: 1.4996665716171265
Validation loss: 2.093952040518484

Epoch: 5| Step: 6
Training loss: 1.0711520910263062
Validation loss: 2.1173172073979534

Epoch: 5| Step: 7
Training loss: 1.5317504405975342
Validation loss: 2.1100983491507908

Epoch: 5| Step: 8
Training loss: 1.509181261062622
Validation loss: 2.1034512494200017

Epoch: 5| Step: 9
Training loss: 0.8193972706794739
Validation loss: 2.0784990582414853

Epoch: 5| Step: 10
Training loss: 1.7131767272949219
Validation loss: 2.0603073156008156

Epoch: 378| Step: 0
Training loss: 1.2236336469650269
Validation loss: 2.0822345979752077

Epoch: 5| Step: 1
Training loss: 0.984164834022522
Validation loss: 2.078234414900503

Epoch: 5| Step: 2
Training loss: 1.2216696739196777
Validation loss: 2.083565309483518

Epoch: 5| Step: 3
Training loss: 1.753943681716919
Validation loss: 2.0911356249163227

Epoch: 5| Step: 4
Training loss: 1.1629774570465088
Validation loss: 2.1232470671335855

Epoch: 5| Step: 5
Training loss: 1.4379273653030396
Validation loss: 2.1340776592172603

Epoch: 5| Step: 6
Training loss: 1.4206300973892212
Validation loss: 2.1032215997736943

Epoch: 5| Step: 7
Training loss: 1.6697584390640259
Validation loss: 2.1342405144886305

Epoch: 5| Step: 8
Training loss: 0.9584223031997681
Validation loss: 2.1535015721474924

Epoch: 5| Step: 9
Training loss: 1.2688831090927124
Validation loss: 2.1651317432362545

Epoch: 5| Step: 10
Training loss: 1.3474892377853394
Validation loss: 2.1773182320338424

Epoch: 379| Step: 0
Training loss: 1.0388296842575073
Validation loss: 2.126789995419082

Epoch: 5| Step: 1
Training loss: 1.3070166110992432
Validation loss: 2.1136424195381904

Epoch: 5| Step: 2
Training loss: 1.7189750671386719
Validation loss: 2.086431231549991

Epoch: 5| Step: 3
Training loss: 1.2347285747528076
Validation loss: 2.0559311874451174

Epoch: 5| Step: 4
Training loss: 1.4226229190826416
Validation loss: 2.0460275911515757

Epoch: 5| Step: 5
Training loss: 1.2327792644500732
Validation loss: 2.024938605164969

Epoch: 5| Step: 6
Training loss: 1.6031148433685303
Validation loss: 2.0207542988561813

Epoch: 5| Step: 7
Training loss: 1.4090677499771118
Validation loss: 2.0475125030804704

Epoch: 5| Step: 8
Training loss: 1.0621010065078735
Validation loss: 2.077389919629661

Epoch: 5| Step: 9
Training loss: 1.189085841178894
Validation loss: 2.13037762846998

Epoch: 5| Step: 10
Training loss: 1.2994685173034668
Validation loss: 2.168039852573026

Epoch: 380| Step: 0
Training loss: 1.37916898727417
Validation loss: 2.1509012535054195

Epoch: 5| Step: 1
Training loss: 1.2676522731781006
Validation loss: 2.1715277830759683

Epoch: 5| Step: 2
Training loss: 2.1018972396850586
Validation loss: 2.1594218323307652

Epoch: 5| Step: 3
Training loss: 0.7340145111083984
Validation loss: 2.1381486923463884

Epoch: 5| Step: 4
Training loss: 1.264106035232544
Validation loss: 2.113323173215312

Epoch: 5| Step: 5
Training loss: 1.5007202625274658
Validation loss: 2.094218293825785

Epoch: 5| Step: 6
Training loss: 1.6307270526885986
Validation loss: 2.093878005140571

Epoch: 5| Step: 7
Training loss: 1.346789836883545
Validation loss: 2.0732974237011326

Epoch: 5| Step: 8
Training loss: 1.1525592803955078
Validation loss: 2.0848937034606934

Epoch: 5| Step: 9
Training loss: 1.0741552114486694
Validation loss: 2.085908025823614

Epoch: 5| Step: 10
Training loss: 0.9206958413124084
Validation loss: 2.0928174347005863

Epoch: 381| Step: 0
Training loss: 0.9583722949028015
Validation loss: 2.0947198149978474

Epoch: 5| Step: 1
Training loss: 2.2137210369110107
Validation loss: 2.0786043879806355

Epoch: 5| Step: 2
Training loss: 2.0602498054504395
Validation loss: 2.0771178417308356

Epoch: 5| Step: 3
Training loss: 1.5431735515594482
Validation loss: 2.0535816274663454

Epoch: 5| Step: 4
Training loss: 1.5673940181732178
Validation loss: 2.0814516236705165

Epoch: 5| Step: 5
Training loss: 0.9411770701408386
Validation loss: 2.080192376208562

Epoch: 5| Step: 6
Training loss: 1.4464327096939087
Validation loss: 2.104604277559506

Epoch: 5| Step: 7
Training loss: 0.8659347295761108
Validation loss: 2.0744133585242817

Epoch: 5| Step: 8
Training loss: 0.7415496110916138
Validation loss: 2.07447749312206

Epoch: 5| Step: 9
Training loss: 1.1323282718658447
Validation loss: 2.077170010535948

Epoch: 5| Step: 10
Training loss: 0.6896138191223145
Validation loss: 2.1039871323493218

Epoch: 382| Step: 0
Training loss: 1.3014118671417236
Validation loss: 2.0999671489961687

Epoch: 5| Step: 1
Training loss: 1.041912317276001
Validation loss: 2.1022678600844515

Epoch: 5| Step: 2
Training loss: 1.201648473739624
Validation loss: 2.082094782142229

Epoch: 5| Step: 3
Training loss: 1.1158709526062012
Validation loss: 2.11437318658316

Epoch: 5| Step: 4
Training loss: 1.1163318157196045
Validation loss: 2.0951659012866277

Epoch: 5| Step: 5
Training loss: 1.6256749629974365
Validation loss: 2.089435149264592

Epoch: 5| Step: 6
Training loss: 1.3764708042144775
Validation loss: 2.084660409599222

Epoch: 5| Step: 7
Training loss: 1.0710657835006714
Validation loss: 2.1003781339173675

Epoch: 5| Step: 8
Training loss: 1.6339027881622314
Validation loss: 2.1057741513816257

Epoch: 5| Step: 9
Training loss: 1.6525179147720337
Validation loss: 2.0934813266159384

Epoch: 5| Step: 10
Training loss: 1.1128917932510376
Validation loss: 2.09318132041603

Epoch: 383| Step: 0
Training loss: 1.3812110424041748
Validation loss: 2.060737015098654

Epoch: 5| Step: 1
Training loss: 1.09381103515625
Validation loss: 2.072371934049873

Epoch: 5| Step: 2
Training loss: 1.1041618585586548
Validation loss: 2.052955513359398

Epoch: 5| Step: 3
Training loss: 1.7530059814453125
Validation loss: 2.0069027100839922

Epoch: 5| Step: 4
Training loss: 1.7005317211151123
Validation loss: 2.0044137918820946

Epoch: 5| Step: 5
Training loss: 1.4020153284072876
Validation loss: 2.0184590278133268

Epoch: 5| Step: 6
Training loss: 1.276725172996521
Validation loss: 2.0231730373956824

Epoch: 5| Step: 7
Training loss: 1.3284056186676025
Validation loss: 2.0387250492649693

Epoch: 5| Step: 8
Training loss: 1.2914749383926392
Validation loss: 2.0464974398254068

Epoch: 5| Step: 9
Training loss: 1.023733139038086
Validation loss: 2.0957296791897027

Epoch: 5| Step: 10
Training loss: 0.7355232238769531
Validation loss: 2.096859655072612

Epoch: 384| Step: 0
Training loss: 1.5868806838989258
Validation loss: 2.118077867774553

Epoch: 5| Step: 1
Training loss: 1.2803646326065063
Validation loss: 2.1404201663950437

Epoch: 5| Step: 2
Training loss: 1.2082996368408203
Validation loss: 2.1231819442523423

Epoch: 5| Step: 3
Training loss: 1.2918927669525146
Validation loss: 2.0890954066348333

Epoch: 5| Step: 4
Training loss: 0.8457560539245605
Validation loss: 2.092159907023112

Epoch: 5| Step: 5
Training loss: 1.1623427867889404
Validation loss: 2.0772556925332673

Epoch: 5| Step: 6
Training loss: 1.6749995946884155
Validation loss: 2.0794085225751324

Epoch: 5| Step: 7
Training loss: 1.102720856666565
Validation loss: 2.048097292582194

Epoch: 5| Step: 8
Training loss: 1.3126839399337769
Validation loss: 2.039687095149871

Epoch: 5| Step: 9
Training loss: 1.6330559253692627
Validation loss: 2.0357840881552747

Epoch: 5| Step: 10
Training loss: 0.8782344460487366
Validation loss: 2.060443421845795

Epoch: 385| Step: 0
Training loss: 1.1012712717056274
Validation loss: 2.079515218734741

Epoch: 5| Step: 1
Training loss: 0.9025405645370483
Validation loss: 2.0346868499632804

Epoch: 5| Step: 2
Training loss: 2.0773708820343018
Validation loss: 2.0907499482554774

Epoch: 5| Step: 3
Training loss: 1.350416898727417
Validation loss: 2.112218728629492

Epoch: 5| Step: 4
Training loss: 1.0535160303115845
Validation loss: 2.1162261373253277

Epoch: 5| Step: 5
Training loss: 1.2913671731948853
Validation loss: 2.115154634239853

Epoch: 5| Step: 6
Training loss: 1.249281883239746
Validation loss: 2.0787598497124127

Epoch: 5| Step: 7
Training loss: 1.044329285621643
Validation loss: 2.0513502910572994

Epoch: 5| Step: 8
Training loss: 1.1796382665634155
Validation loss: 2.037274927221319

Epoch: 5| Step: 9
Training loss: 1.5336506366729736
Validation loss: 2.059126313014697

Epoch: 5| Step: 10
Training loss: 1.0744612216949463
Validation loss: 2.0422545786826842

Epoch: 386| Step: 0
Training loss: 1.4060003757476807
Validation loss: 2.050046278584388

Epoch: 5| Step: 1
Training loss: 1.003674030303955
Validation loss: 2.0611723148694603

Epoch: 5| Step: 2
Training loss: 1.6894077062606812
Validation loss: 2.0899974120560514

Epoch: 5| Step: 3
Training loss: 1.1787384748458862
Validation loss: 2.105987020718154

Epoch: 5| Step: 4
Training loss: 1.5875061750411987
Validation loss: 2.155041410077003

Epoch: 5| Step: 5
Training loss: 0.9916136860847473
Validation loss: 2.2016475380107923

Epoch: 5| Step: 6
Training loss: 1.114667534828186
Validation loss: 2.236981536752434

Epoch: 5| Step: 7
Training loss: 0.7145482301712036
Validation loss: 2.246808244336036

Epoch: 5| Step: 8
Training loss: 1.3894236087799072
Validation loss: 2.2099988281085925

Epoch: 5| Step: 9
Training loss: 1.1202008724212646
Validation loss: 2.128204439276008

Epoch: 5| Step: 10
Training loss: 1.8288899660110474
Validation loss: 2.0785656411160707

Epoch: 387| Step: 0
Training loss: 1.2972357273101807
Validation loss: 2.041149580350486

Epoch: 5| Step: 1
Training loss: 1.1143985986709595
Validation loss: 2.007048858109341

Epoch: 5| Step: 2
Training loss: 1.0757074356079102
Validation loss: 1.9697432184732089

Epoch: 5| Step: 3
Training loss: 1.6021051406860352
Validation loss: 1.9789179345612884

Epoch: 5| Step: 4
Training loss: 0.8687402009963989
Validation loss: 2.008322008194462

Epoch: 5| Step: 5
Training loss: 1.1357777118682861
Validation loss: 2.0327485094788256

Epoch: 5| Step: 6
Training loss: 1.0723756551742554
Validation loss: 2.050399882819063

Epoch: 5| Step: 7
Training loss: 1.3482121229171753
Validation loss: 2.0808452944601736

Epoch: 5| Step: 8
Training loss: 1.6671918630599976
Validation loss: 2.145202121426982

Epoch: 5| Step: 9
Training loss: 1.725106954574585
Validation loss: 2.198365378123458

Epoch: 5| Step: 10
Training loss: 1.3023386001586914
Validation loss: 2.197606953241492

Epoch: 388| Step: 0
Training loss: 1.5497252941131592
Validation loss: 2.2138111783612158

Epoch: 5| Step: 1
Training loss: 1.436935305595398
Validation loss: 2.184654910077331

Epoch: 5| Step: 2
Training loss: 1.1642409563064575
Validation loss: 2.16771601605159

Epoch: 5| Step: 3
Training loss: 0.9450138807296753
Validation loss: 2.123805974119453

Epoch: 5| Step: 4
Training loss: 1.24259614944458
Validation loss: 2.0943079174205823

Epoch: 5| Step: 5
Training loss: 0.810971736907959
Validation loss: 2.0478053554411857

Epoch: 5| Step: 6
Training loss: 1.3473384380340576
Validation loss: 2.0432845751444497

Epoch: 5| Step: 7
Training loss: 1.5833914279937744
Validation loss: 2.0254065234174012

Epoch: 5| Step: 8
Training loss: 1.356357216835022
Validation loss: 2.0243889644581783

Epoch: 5| Step: 9
Training loss: 1.3138797283172607
Validation loss: 2.027426564565269

Epoch: 5| Step: 10
Training loss: 1.1690081357955933
Validation loss: 2.0304525013892882

Epoch: 389| Step: 0
Training loss: 0.7824496626853943
Validation loss: 2.095961114411713

Epoch: 5| Step: 1
Training loss: 1.3568041324615479
Validation loss: 2.1243385960978847

Epoch: 5| Step: 2
Training loss: 1.0776445865631104
Validation loss: 2.14985292701311

Epoch: 5| Step: 3
Training loss: 1.566794991493225
Validation loss: 2.1963220873186664

Epoch: 5| Step: 4
Training loss: 1.18120276927948
Validation loss: 2.174802666069359

Epoch: 5| Step: 5
Training loss: 1.5704656839370728
Validation loss: 2.154812921759903

Epoch: 5| Step: 6
Training loss: 1.0249195098876953
Validation loss: 2.1428946192546556

Epoch: 5| Step: 7
Training loss: 1.743857979774475
Validation loss: 2.1170634505569295

Epoch: 5| Step: 8
Training loss: 1.0175540447235107
Validation loss: 2.1033149816656627

Epoch: 5| Step: 9
Training loss: 1.7263141870498657
Validation loss: 2.0500258156048354

Epoch: 5| Step: 10
Training loss: 0.8441610932350159
Validation loss: 2.0303078646300943

Epoch: 390| Step: 0
Training loss: 1.1489343643188477
Validation loss: 2.040740472014232

Epoch: 5| Step: 1
Training loss: 1.1474922895431519
Validation loss: 2.023554012339602

Epoch: 5| Step: 2
Training loss: 1.2737305164337158
Validation loss: 2.0423255274372716

Epoch: 5| Step: 3
Training loss: 1.9278122186660767
Validation loss: 2.0133284817459765

Epoch: 5| Step: 4
Training loss: 1.1085662841796875
Validation loss: 2.021073604142794

Epoch: 5| Step: 5
Training loss: 1.3398444652557373
Validation loss: 2.0419480057172876

Epoch: 5| Step: 6
Training loss: 1.1281238794326782
Validation loss: 2.0215043662696757

Epoch: 5| Step: 7
Training loss: 1.2804043292999268
Validation loss: 2.0630581173845517

Epoch: 5| Step: 8
Training loss: 0.7861384153366089
Validation loss: 2.092321832974752

Epoch: 5| Step: 9
Training loss: 1.3925269842147827
Validation loss: 2.0918826133974138

Epoch: 5| Step: 10
Training loss: 1.364294409751892
Validation loss: 2.107701440011301

Epoch: 391| Step: 0
Training loss: 1.228942632675171
Validation loss: 2.1140264464962866

Epoch: 5| Step: 1
Training loss: 1.5366383790969849
Validation loss: 2.1308035619797243

Epoch: 5| Step: 2
Training loss: 1.0730804204940796
Validation loss: 2.1235558140662407

Epoch: 5| Step: 3
Training loss: 0.9405290484428406
Validation loss: 2.10242623154835

Epoch: 5| Step: 4
Training loss: 1.4313840866088867
Validation loss: 2.0815626011099866

Epoch: 5| Step: 5
Training loss: 1.3973021507263184
Validation loss: 2.0784328855494016

Epoch: 5| Step: 6
Training loss: 1.3440988063812256
Validation loss: 2.0321758562518704

Epoch: 5| Step: 7
Training loss: 1.3093689680099487
Validation loss: 2.03354202547381

Epoch: 5| Step: 8
Training loss: 1.2375855445861816
Validation loss: 2.0758620026291057

Epoch: 5| Step: 9
Training loss: 0.8935827016830444
Validation loss: 2.0715104046688286

Epoch: 5| Step: 10
Training loss: 1.374948501586914
Validation loss: 2.065609860163863

Epoch: 392| Step: 0
Training loss: 1.1430095434188843
Validation loss: 2.0870749976045344

Epoch: 5| Step: 1
Training loss: 1.324517011642456
Validation loss: 2.1380068409827446

Epoch: 5| Step: 2
Training loss: 1.2501780986785889
Validation loss: 2.1182954901008197

Epoch: 5| Step: 3
Training loss: 1.176284909248352
Validation loss: 2.129930611579649

Epoch: 5| Step: 4
Training loss: 0.8127288818359375
Validation loss: 2.092401075106795

Epoch: 5| Step: 5
Training loss: 1.6022813320159912
Validation loss: 2.089380330936883

Epoch: 5| Step: 6
Training loss: 1.3279427289962769
Validation loss: 2.078933290255967

Epoch: 5| Step: 7
Training loss: 1.1676726341247559
Validation loss: 2.0607703629360405

Epoch: 5| Step: 8
Training loss: 1.0347440242767334
Validation loss: 2.011191430912223

Epoch: 5| Step: 9
Training loss: 1.4225496053695679
Validation loss: 2.028893724564583

Epoch: 5| Step: 10
Training loss: 1.3721643686294556
Validation loss: 2.0384939870526715

Epoch: 393| Step: 0
Training loss: 1.1212499141693115
Validation loss: 2.067033721554664

Epoch: 5| Step: 1
Training loss: 1.1143114566802979
Validation loss: 2.0681889287887083

Epoch: 5| Step: 2
Training loss: 1.1073668003082275
Validation loss: 2.096604116501347

Epoch: 5| Step: 3
Training loss: 1.218454122543335
Validation loss: 2.116859728290189

Epoch: 5| Step: 4
Training loss: 0.9499884843826294
Validation loss: 2.129656122576806

Epoch: 5| Step: 5
Training loss: 1.364877462387085
Validation loss: 2.130389819863022

Epoch: 5| Step: 6
Training loss: 1.2868423461914062
Validation loss: 2.1331902627022035

Epoch: 5| Step: 7
Training loss: 1.791865348815918
Validation loss: 2.1009757390586277

Epoch: 5| Step: 8
Training loss: 1.3249855041503906
Validation loss: 2.1205342738859114

Epoch: 5| Step: 9
Training loss: 0.9835416078567505
Validation loss: 2.0510890765856673

Epoch: 5| Step: 10
Training loss: 1.1348775625228882
Validation loss: 2.021495760128062

Epoch: 394| Step: 0
Training loss: 0.997880756855011
Validation loss: 2.020949238090105

Epoch: 5| Step: 1
Training loss: 1.175935983657837
Validation loss: 2.0054074333560084

Epoch: 5| Step: 2
Training loss: 1.1335734128952026
Validation loss: 2.048027538484143

Epoch: 5| Step: 3
Training loss: 1.1945281028747559
Validation loss: 2.07592858037641

Epoch: 5| Step: 4
Training loss: 1.3470138311386108
Validation loss: 2.1064767068432224

Epoch: 5| Step: 5
Training loss: 1.1248811483383179
Validation loss: 2.1111964025805072

Epoch: 5| Step: 6
Training loss: 1.3387664556503296
Validation loss: 2.1301703581246

Epoch: 5| Step: 7
Training loss: 1.7167848348617554
Validation loss: 2.1182442583063597

Epoch: 5| Step: 8
Training loss: 1.3827215433120728
Validation loss: 2.084300051453293

Epoch: 5| Step: 9
Training loss: 1.3650163412094116
Validation loss: 2.0828785588664394

Epoch: 5| Step: 10
Training loss: 0.9420991539955139
Validation loss: 2.092376897411962

Epoch: 395| Step: 0
Training loss: 0.8258830904960632
Validation loss: 2.045917473813539

Epoch: 5| Step: 1
Training loss: 0.7692723274230957
Validation loss: 2.0256781872882637

Epoch: 5| Step: 2
Training loss: 0.9711853861808777
Validation loss: 2.0555409577585038

Epoch: 5| Step: 3
Training loss: 1.1289374828338623
Validation loss: 2.0562394203678256

Epoch: 5| Step: 4
Training loss: 1.3622102737426758
Validation loss: 2.0603399943279963

Epoch: 5| Step: 5
Training loss: 1.3929743766784668
Validation loss: 2.0585675983018774

Epoch: 5| Step: 6
Training loss: 1.2103619575500488
Validation loss: 2.0611206716106785

Epoch: 5| Step: 7
Training loss: 1.5005390644073486
Validation loss: 2.0333019533464984

Epoch: 5| Step: 8
Training loss: 1.4638216495513916
Validation loss: 2.0113079047972158

Epoch: 5| Step: 9
Training loss: 1.6115763187408447
Validation loss: 2.0211144672927035

Epoch: 5| Step: 10
Training loss: 1.2515257596969604
Validation loss: 2.055740894809846

Epoch: 396| Step: 0
Training loss: 1.660257339477539
Validation loss: 2.0417802603014055

Epoch: 5| Step: 1
Training loss: 0.7625932693481445
Validation loss: 2.0522893295493176

Epoch: 5| Step: 2
Training loss: 1.7481629848480225
Validation loss: 2.076511590711532

Epoch: 5| Step: 3
Training loss: 1.5316873788833618
Validation loss: 2.094524332272109

Epoch: 5| Step: 4
Training loss: 0.7519198656082153
Validation loss: 2.091056005929106

Epoch: 5| Step: 5
Training loss: 1.0329391956329346
Validation loss: 2.127844592576386

Epoch: 5| Step: 6
Training loss: 0.8537005186080933
Validation loss: 2.082789203172089

Epoch: 5| Step: 7
Training loss: 0.7169564366340637
Validation loss: 2.064700174075301

Epoch: 5| Step: 8
Training loss: 1.5020074844360352
Validation loss: 1.992683029943897

Epoch: 5| Step: 9
Training loss: 1.4996798038482666
Validation loss: 2.000916228499464

Epoch: 5| Step: 10
Training loss: 1.19263756275177
Validation loss: 1.9871824133780696

Epoch: 397| Step: 0
Training loss: 1.4721839427947998
Validation loss: 1.964354920130904

Epoch: 5| Step: 1
Training loss: 0.5710010528564453
Validation loss: 1.9793034445854925

Epoch: 5| Step: 2
Training loss: 1.229637622833252
Validation loss: 1.9964296510142665

Epoch: 5| Step: 3
Training loss: 0.9240878820419312
Validation loss: 2.0138129431714296

Epoch: 5| Step: 4
Training loss: 0.9345505833625793
Validation loss: 2.0740480563973867

Epoch: 5| Step: 5
Training loss: 1.8438646793365479
Validation loss: 2.056254412538262

Epoch: 5| Step: 6
Training loss: 1.4122397899627686
Validation loss: 2.107406098355529

Epoch: 5| Step: 7
Training loss: 1.1362228393554688
Validation loss: 2.0769579538735012

Epoch: 5| Step: 8
Training loss: 1.3608694076538086
Validation loss: 2.0950895676048855

Epoch: 5| Step: 9
Training loss: 1.1792583465576172
Validation loss: 2.0868037503252745

Epoch: 5| Step: 10
Training loss: 1.1333564519882202
Validation loss: 2.0949578233944472

Epoch: 398| Step: 0
Training loss: 1.4878344535827637
Validation loss: 2.1004825433095298

Epoch: 5| Step: 1
Training loss: 0.8046806454658508
Validation loss: 2.08844954352225

Epoch: 5| Step: 2
Training loss: 1.5856260061264038
Validation loss: 2.0427484486692693

Epoch: 5| Step: 3
Training loss: 1.1311613321304321
Validation loss: 2.0134835486770957

Epoch: 5| Step: 4
Training loss: 1.361602544784546
Validation loss: 2.024781325811981

Epoch: 5| Step: 5
Training loss: 0.9090534448623657
Validation loss: 2.051094771713339

Epoch: 5| Step: 6
Training loss: 0.7728385329246521
Validation loss: 2.0577461822058565

Epoch: 5| Step: 7
Training loss: 1.1676483154296875
Validation loss: 2.037566702852967

Epoch: 5| Step: 8
Training loss: 1.425872564315796
Validation loss: 2.064530921238725

Epoch: 5| Step: 9
Training loss: 1.7920814752578735
Validation loss: 2.067014371195147

Epoch: 5| Step: 10
Training loss: 0.542391300201416
Validation loss: 2.0965551945470993

Epoch: 399| Step: 0
Training loss: 1.3824187517166138
Validation loss: 2.09091386231043

Epoch: 5| Step: 1
Training loss: 1.0463298559188843
Validation loss: 2.0599201879193707

Epoch: 5| Step: 2
Training loss: 1.4534038305282593
Validation loss: 2.0730132415730465

Epoch: 5| Step: 3
Training loss: 1.0884591341018677
Validation loss: 2.034008461941955

Epoch: 5| Step: 4
Training loss: 0.8143371343612671
Validation loss: 1.9970065880847234

Epoch: 5| Step: 5
Training loss: 0.7141914367675781
Validation loss: 1.9995305563813897

Epoch: 5| Step: 6
Training loss: 1.6822007894515991
Validation loss: 1.9659775533983785

Epoch: 5| Step: 7
Training loss: 1.1211917400360107
Validation loss: 1.962071805871943

Epoch: 5| Step: 8
Training loss: 1.0679346323013306
Validation loss: 1.9847766071237543

Epoch: 5| Step: 9
Training loss: 1.3455374240875244
Validation loss: 2.0078935982078634

Epoch: 5| Step: 10
Training loss: 1.4019134044647217
Validation loss: 2.0304797849347516

Epoch: 400| Step: 0
Training loss: 0.5878230333328247
Validation loss: 2.0205942328258226

Epoch: 5| Step: 1
Training loss: 1.5207165479660034
Validation loss: 2.0922607760275564

Epoch: 5| Step: 2
Training loss: 1.5183390378952026
Validation loss: 2.1130054202131046

Epoch: 5| Step: 3
Training loss: 1.3798491954803467
Validation loss: 2.1459628843492076

Epoch: 5| Step: 4
Training loss: 1.4612153768539429
Validation loss: 2.0939531403203167

Epoch: 5| Step: 5
Training loss: 0.6522639989852905
Validation loss: 2.0889990611742904

Epoch: 5| Step: 6
Training loss: 0.9023272395133972
Validation loss: 2.072326158964506

Epoch: 5| Step: 7
Training loss: 1.207784652709961
Validation loss: 2.0487089003286054

Epoch: 5| Step: 8
Training loss: 1.2371374368667603
Validation loss: 1.985040085290068

Epoch: 5| Step: 9
Training loss: 1.0614501237869263
Validation loss: 1.9910875571671354

Epoch: 5| Step: 10
Training loss: 1.5183298587799072
Validation loss: 2.0157286813182216

Testing loss: 2.0967050658331976
