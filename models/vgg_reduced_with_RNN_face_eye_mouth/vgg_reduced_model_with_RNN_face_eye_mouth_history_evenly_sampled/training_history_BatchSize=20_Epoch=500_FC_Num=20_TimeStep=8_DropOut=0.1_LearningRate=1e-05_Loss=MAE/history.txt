Epoch: 1| Step: 0
Training loss: 4.352926254272461
Validation loss: 5.254786214520855

Epoch: 5| Step: 1
Training loss: 5.059399604797363
Validation loss: 5.247334557194864

Epoch: 5| Step: 2
Training loss: 5.901505947113037
Validation loss: 5.240552404875396

Epoch: 5| Step: 3
Training loss: 4.44888162612915
Validation loss: 5.233653463343138

Epoch: 5| Step: 4
Training loss: 4.205463886260986
Validation loss: 5.226455339821436

Epoch: 5| Step: 5
Training loss: 5.99146032333374
Validation loss: 5.218854283773771

Epoch: 5| Step: 6
Training loss: 4.164492130279541
Validation loss: 5.210727060994794

Epoch: 5| Step: 7
Training loss: 5.98731803894043
Validation loss: 5.201788245990712

Epoch: 5| Step: 8
Training loss: 4.390950679779053
Validation loss: 5.191897310236449

Epoch: 5| Step: 9
Training loss: 5.261415958404541
Validation loss: 5.181625109846874

Epoch: 5| Step: 10
Training loss: 5.427774906158447
Validation loss: 5.17016395958521

Epoch: 2| Step: 0
Training loss: 4.207947731018066
Validation loss: 5.157957615390901

Epoch: 5| Step: 1
Training loss: 5.264618396759033
Validation loss: 5.1448944768598

Epoch: 5| Step: 2
Training loss: 4.403127193450928
Validation loss: 5.130451597193236

Epoch: 5| Step: 3
Training loss: 4.543362617492676
Validation loss: 5.11504062016805

Epoch: 5| Step: 4
Training loss: 4.452633857727051
Validation loss: 5.098330961760654

Epoch: 5| Step: 5
Training loss: 4.786637306213379
Validation loss: 5.079634204987557

Epoch: 5| Step: 6
Training loss: 4.6574506759643555
Validation loss: 5.060010756215742

Epoch: 5| Step: 7
Training loss: 4.7735981941223145
Validation loss: 5.038222538527622

Epoch: 5| Step: 8
Training loss: 5.751891136169434
Validation loss: 5.015292762428202

Epoch: 5| Step: 9
Training loss: 5.877296447753906
Validation loss: 4.989786886399792

Epoch: 5| Step: 10
Training loss: 4.762677192687988
Validation loss: 4.962817838115077

Epoch: 3| Step: 0
Training loss: 4.574570655822754
Validation loss: 4.933398923566265

Epoch: 5| Step: 1
Training loss: 4.209139823913574
Validation loss: 4.901145627421718

Epoch: 5| Step: 2
Training loss: 5.693655967712402
Validation loss: 4.867611726125081

Epoch: 5| Step: 3
Training loss: 4.485870838165283
Validation loss: 4.830727941246443

Epoch: 5| Step: 4
Training loss: 6.180779457092285
Validation loss: 4.792027350394957

Epoch: 5| Step: 5
Training loss: 4.286435604095459
Validation loss: 4.749742010588287

Epoch: 5| Step: 6
Training loss: 4.717304229736328
Validation loss: 4.706515201958277

Epoch: 5| Step: 7
Training loss: 4.777890205383301
Validation loss: 4.661070741632933

Epoch: 5| Step: 8
Training loss: 3.003988742828369
Validation loss: 4.61384609694122

Epoch: 5| Step: 9
Training loss: 3.700413465499878
Validation loss: 4.564557495937552

Epoch: 5| Step: 10
Training loss: 4.138428211212158
Validation loss: 4.514723870062059

Epoch: 4| Step: 0
Training loss: 5.2675371170043945
Validation loss: 4.462638972907938

Epoch: 5| Step: 1
Training loss: 4.103431224822998
Validation loss: 4.412331750316005

Epoch: 5| Step: 2
Training loss: 2.8677544593811035
Validation loss: 4.363285992735175

Epoch: 5| Step: 3
Training loss: 4.0940070152282715
Validation loss: 4.316230009960872

Epoch: 5| Step: 4
Training loss: 4.230385780334473
Validation loss: 4.270807063707742

Epoch: 5| Step: 5
Training loss: 3.627758741378784
Validation loss: 4.226975302542409

Epoch: 5| Step: 6
Training loss: 4.194807529449463
Validation loss: 4.183196031919089

Epoch: 5| Step: 7
Training loss: 3.922072649002075
Validation loss: 4.141530421472365

Epoch: 5| Step: 8
Training loss: 4.206567287445068
Validation loss: 4.098908629468692

Epoch: 5| Step: 9
Training loss: 4.640622138977051
Validation loss: 4.057946805031069

Epoch: 5| Step: 10
Training loss: 3.172459602355957
Validation loss: 4.017997946790469

Epoch: 5| Step: 0
Training loss: 3.6086788177490234
Validation loss: 3.9856160686862085

Epoch: 5| Step: 1
Training loss: 3.7297444343566895
Validation loss: 3.9578030699042865

Epoch: 5| Step: 2
Training loss: 3.2433555126190186
Validation loss: 3.932236917557255

Epoch: 5| Step: 3
Training loss: 3.9941959381103516
Validation loss: 3.9094679022348053

Epoch: 5| Step: 4
Training loss: 3.6278350353240967
Validation loss: 3.8880149010689027

Epoch: 5| Step: 5
Training loss: 3.9267539978027344
Validation loss: 3.8672127723693848

Epoch: 5| Step: 6
Training loss: 3.928621768951416
Validation loss: 3.849266508574127

Epoch: 5| Step: 7
Training loss: 3.751976728439331
Validation loss: 3.830709539433961

Epoch: 5| Step: 8
Training loss: 3.5138962268829346
Validation loss: 3.813229186560518

Epoch: 5| Step: 9
Training loss: 3.7418742179870605
Validation loss: 3.7949475985701366

Epoch: 5| Step: 10
Training loss: 4.155644416809082
Validation loss: 3.7763161351603847

Epoch: 6| Step: 0
Training loss: 3.094743490219116
Validation loss: 3.760078763449064

Epoch: 5| Step: 1
Training loss: 4.089990139007568
Validation loss: 3.7417262933587514

Epoch: 5| Step: 2
Training loss: 3.7435622215270996
Validation loss: 3.72314057811614

Epoch: 5| Step: 3
Training loss: 4.156555652618408
Validation loss: 3.708233320584861

Epoch: 5| Step: 4
Training loss: 3.209177017211914
Validation loss: 3.690381691020022

Epoch: 5| Step: 5
Training loss: 3.5054614543914795
Validation loss: 3.675855549432898

Epoch: 5| Step: 6
Training loss: 3.867143154144287
Validation loss: 3.660153653032036

Epoch: 5| Step: 7
Training loss: 4.159388542175293
Validation loss: 3.6424844957167104

Epoch: 5| Step: 8
Training loss: 3.1136279106140137
Validation loss: 3.629666410466676

Epoch: 5| Step: 9
Training loss: 3.541308641433716
Validation loss: 3.6171369629521526

Epoch: 5| Step: 10
Training loss: 2.843486785888672
Validation loss: 3.6070859022037958

Epoch: 7| Step: 0
Training loss: 3.787165403366089
Validation loss: 3.5970526869579027

Epoch: 5| Step: 1
Training loss: 4.137221813201904
Validation loss: 3.586439824873401

Epoch: 5| Step: 2
Training loss: 3.528280258178711
Validation loss: 3.5756457441596576

Epoch: 5| Step: 3
Training loss: 3.6620960235595703
Validation loss: 3.5673855402136363

Epoch: 5| Step: 4
Training loss: 2.6144754886627197
Validation loss: 3.5571018521503737

Epoch: 5| Step: 5
Training loss: 3.3031439781188965
Validation loss: 3.547921895980835

Epoch: 5| Step: 6
Training loss: 2.8301053047180176
Validation loss: 3.537879425992248

Epoch: 5| Step: 7
Training loss: 3.7210450172424316
Validation loss: 3.530354897181193

Epoch: 5| Step: 8
Training loss: 3.1504249572753906
Validation loss: 3.521695201114942

Epoch: 5| Step: 9
Training loss: 3.2248694896698
Validation loss: 3.511802483630437

Epoch: 5| Step: 10
Training loss: 4.403815746307373
Validation loss: 3.50203953507126

Epoch: 8| Step: 0
Training loss: 2.8097965717315674
Validation loss: 3.4935884501344416

Epoch: 5| Step: 1
Training loss: 3.8757522106170654
Validation loss: 3.4857869994255806

Epoch: 5| Step: 2
Training loss: 3.438002824783325
Validation loss: 3.4773342276132233

Epoch: 5| Step: 3
Training loss: 3.5443756580352783
Validation loss: 3.4689070716980965

Epoch: 5| Step: 4
Training loss: 3.220757246017456
Validation loss: 3.4610936667329524

Epoch: 5| Step: 5
Training loss: 3.359478712081909
Validation loss: 3.455325275339106

Epoch: 5| Step: 6
Training loss: 2.9225375652313232
Validation loss: 3.4470557884503434

Epoch: 5| Step: 7
Training loss: 3.029571533203125
Validation loss: 3.4366912021431872

Epoch: 5| Step: 8
Training loss: 3.396268844604492
Validation loss: 3.4288981140300794

Epoch: 5| Step: 9
Training loss: 3.536846160888672
Validation loss: 3.4232032683587845

Epoch: 5| Step: 10
Training loss: 4.331936359405518
Validation loss: 3.414531771854688

Epoch: 9| Step: 0
Training loss: 3.3600029945373535
Validation loss: 3.40844391751033

Epoch: 5| Step: 1
Training loss: 3.2623817920684814
Validation loss: 3.402648131052653

Epoch: 5| Step: 2
Training loss: 3.46748423576355
Validation loss: 3.396815405097059

Epoch: 5| Step: 3
Training loss: 4.1743574142456055
Validation loss: 3.39164985123501

Epoch: 5| Step: 4
Training loss: 2.6769580841064453
Validation loss: 3.383275757553757

Epoch: 5| Step: 5
Training loss: 2.659097194671631
Validation loss: 3.3735326900277087

Epoch: 5| Step: 6
Training loss: 3.411752700805664
Validation loss: 3.365960923574304

Epoch: 5| Step: 7
Training loss: 3.1989035606384277
Validation loss: 3.363693996142316

Epoch: 5| Step: 8
Training loss: 3.676849365234375
Validation loss: 3.3561500426261657

Epoch: 5| Step: 9
Training loss: 2.6270344257354736
Validation loss: 3.349280321469871

Epoch: 5| Step: 10
Training loss: 4.212467193603516
Validation loss: 3.342360165811354

Epoch: 10| Step: 0
Training loss: 2.955019235610962
Validation loss: 3.336699101232713

Epoch: 5| Step: 1
Training loss: 3.6813430786132812
Validation loss: 3.330588927832983

Epoch: 5| Step: 2
Training loss: 2.925663709640503
Validation loss: 3.323656666663385

Epoch: 5| Step: 3
Training loss: 3.7969353199005127
Validation loss: 3.318742157310568

Epoch: 5| Step: 4
Training loss: 3.000685214996338
Validation loss: 3.309997256084155

Epoch: 5| Step: 5
Training loss: 3.6460704803466797
Validation loss: 3.2997153523147746

Epoch: 5| Step: 6
Training loss: 3.797309160232544
Validation loss: 3.2907744274344495

Epoch: 5| Step: 7
Training loss: 3.668776035308838
Validation loss: 3.2840549279284734

Epoch: 5| Step: 8
Training loss: 2.4319472312927246
Validation loss: 3.2802234003620763

Epoch: 5| Step: 9
Training loss: 2.7683792114257812
Validation loss: 3.273626337769211

Epoch: 5| Step: 10
Training loss: 3.3028109073638916
Validation loss: 3.2712162617714173

Epoch: 11| Step: 0
Training loss: 2.8863463401794434
Validation loss: 3.266515298556256

Epoch: 5| Step: 1
Training loss: 3.232236862182617
Validation loss: 3.2669178414088424

Epoch: 5| Step: 2
Training loss: 2.6698973178863525
Validation loss: 3.260184021406276

Epoch: 5| Step: 3
Training loss: 2.7063040733337402
Validation loss: 3.2525051665562454

Epoch: 5| Step: 4
Training loss: 2.739943742752075
Validation loss: 3.2448153982880297

Epoch: 5| Step: 5
Training loss: 3.25874400138855
Validation loss: 3.2375409962028585

Epoch: 5| Step: 6
Training loss: 3.5581138134002686
Validation loss: 3.2338314851125083

Epoch: 5| Step: 7
Training loss: 3.080944061279297
Validation loss: 3.22895243090968

Epoch: 5| Step: 8
Training loss: 3.361631393432617
Validation loss: 3.221776980225758

Epoch: 5| Step: 9
Training loss: 4.201445579528809
Validation loss: 3.216666883037936

Epoch: 5| Step: 10
Training loss: 3.8337228298187256
Validation loss: 3.2129520036840953

Epoch: 12| Step: 0
Training loss: 3.3105087280273438
Validation loss: 3.2075868011802755

Epoch: 5| Step: 1
Training loss: 2.9699223041534424
Validation loss: 3.199734136622439

Epoch: 5| Step: 2
Training loss: 3.817892074584961
Validation loss: 3.1924634184888614

Epoch: 5| Step: 3
Training loss: 3.4729995727539062
Validation loss: 3.1945242317773963

Epoch: 5| Step: 4
Training loss: 3.7668960094451904
Validation loss: 3.1833472354437715

Epoch: 5| Step: 5
Training loss: 3.352001190185547
Validation loss: 3.1858390838869157

Epoch: 5| Step: 6
Training loss: 2.1523845195770264
Validation loss: 3.186371305937408

Epoch: 5| Step: 7
Training loss: 3.1852364540100098
Validation loss: 3.187280785652899

Epoch: 5| Step: 8
Training loss: 2.7019407749176025
Validation loss: 3.1890239356666483

Epoch: 5| Step: 9
Training loss: 3.6428475379943848
Validation loss: 3.1920460808661675

Epoch: 5| Step: 10
Training loss: 2.654564619064331
Validation loss: 3.178056650264289

Epoch: 13| Step: 0
Training loss: 2.8331522941589355
Validation loss: 3.1670721064331713

Epoch: 5| Step: 1
Training loss: 3.5790295600891113
Validation loss: 3.1537152926127114

Epoch: 5| Step: 2
Training loss: 2.613105297088623
Validation loss: 3.1448565708693637

Epoch: 5| Step: 3
Training loss: 3.826368808746338
Validation loss: 3.1514014172297653

Epoch: 5| Step: 4
Training loss: 3.61383056640625
Validation loss: 3.159309320552375

Epoch: 5| Step: 5
Training loss: 3.10538387298584
Validation loss: 3.132198323485672

Epoch: 5| Step: 6
Training loss: 3.4945578575134277
Validation loss: 3.128177237767045

Epoch: 5| Step: 7
Training loss: 2.765674352645874
Validation loss: 3.134243908748832

Epoch: 5| Step: 8
Training loss: 2.9389004707336426
Validation loss: 3.137967642917428

Epoch: 5| Step: 9
Training loss: 3.299412488937378
Validation loss: 3.1380627642395678

Epoch: 5| Step: 10
Training loss: 2.553346872329712
Validation loss: 3.1221985893864788

Epoch: 14| Step: 0
Training loss: 2.9507253170013428
Validation loss: 3.107453792325912

Epoch: 5| Step: 1
Training loss: 2.542881488800049
Validation loss: 3.0999243105611494

Epoch: 5| Step: 2
Training loss: 3.0652832984924316
Validation loss: 3.102641100524574

Epoch: 5| Step: 3
Training loss: 4.218958377838135
Validation loss: 3.092295597958308

Epoch: 5| Step: 4
Training loss: 2.6410653591156006
Validation loss: 3.0843185224840717

Epoch: 5| Step: 5
Training loss: 2.536247968673706
Validation loss: 3.079334984543503

Epoch: 5| Step: 6
Training loss: 3.685875415802002
Validation loss: 3.079864873681017

Epoch: 5| Step: 7
Training loss: 3.7434470653533936
Validation loss: 3.069349104358304

Epoch: 5| Step: 8
Training loss: 3.3651232719421387
Validation loss: 3.057008768922539

Epoch: 5| Step: 9
Training loss: 3.0874648094177246
Validation loss: 3.0582317639422674

Epoch: 5| Step: 10
Training loss: 2.257429838180542
Validation loss: 3.0616812911084903

Epoch: 15| Step: 0
Training loss: 2.665095567703247
Validation loss: 3.056138902582148

Epoch: 5| Step: 1
Training loss: 3.069154739379883
Validation loss: 3.0422433883913103

Epoch: 5| Step: 2
Training loss: 3.57452130317688
Validation loss: 3.036023839827507

Epoch: 5| Step: 3
Training loss: 2.6828274726867676
Validation loss: 3.0382872371263403

Epoch: 5| Step: 4
Training loss: 3.3734488487243652
Validation loss: 3.038276159635154

Epoch: 5| Step: 5
Training loss: 4.211699485778809
Validation loss: 3.0317726212163127

Epoch: 5| Step: 6
Training loss: 3.2596614360809326
Validation loss: 3.0223332938327583

Epoch: 5| Step: 7
Training loss: 2.6808114051818848
Validation loss: 3.016600008933775

Epoch: 5| Step: 8
Training loss: 2.284405469894409
Validation loss: 3.0076859740800757

Epoch: 5| Step: 9
Training loss: 2.7214980125427246
Validation loss: 3.00204441624303

Epoch: 5| Step: 10
Training loss: 3.396962881088257
Validation loss: 3.000635552149947

Epoch: 16| Step: 0
Training loss: 3.103440999984741
Validation loss: 2.9994720669202906

Epoch: 5| Step: 1
Training loss: 3.786543369293213
Validation loss: 2.9981911208039973

Epoch: 5| Step: 2
Training loss: 3.3349006175994873
Validation loss: 2.9941191980915685

Epoch: 5| Step: 3
Training loss: 3.5282936096191406
Validation loss: 2.990746449398738

Epoch: 5| Step: 4
Training loss: 2.499650239944458
Validation loss: 2.978470097305954

Epoch: 5| Step: 5
Training loss: 2.920131206512451
Validation loss: 3.0196704274864605

Epoch: 5| Step: 6
Training loss: 2.962725877761841
Validation loss: 3.012998983424197

Epoch: 5| Step: 7
Training loss: 2.2092461585998535
Validation loss: 2.9626653502064366

Epoch: 5| Step: 8
Training loss: 2.65739369392395
Validation loss: 2.9769037462049917

Epoch: 5| Step: 9
Training loss: 2.6972298622131348
Validation loss: 2.9902853760668027

Epoch: 5| Step: 10
Training loss: 4.0544281005859375
Validation loss: 3.003341741459344

Epoch: 17| Step: 0
Training loss: 3.6235604286193848
Validation loss: 3.0044695997750885

Epoch: 5| Step: 1
Training loss: 2.8448264598846436
Validation loss: 3.0060701934240197

Epoch: 5| Step: 2
Training loss: 3.7454795837402344
Validation loss: 2.995926387848393

Epoch: 5| Step: 3
Training loss: 3.408942461013794
Validation loss: 2.9881039716864146

Epoch: 5| Step: 4
Training loss: 3.2199008464813232
Validation loss: 2.974020840019308

Epoch: 5| Step: 5
Training loss: 2.244948625564575
Validation loss: 2.9493396871833393

Epoch: 5| Step: 6
Training loss: 2.950875759124756
Validation loss: 2.965467499148461

Epoch: 5| Step: 7
Training loss: 2.852137327194214
Validation loss: 2.9600714406659527

Epoch: 5| Step: 8
Training loss: 2.1537346839904785
Validation loss: 2.9454782803853354

Epoch: 5| Step: 9
Training loss: 2.7632973194122314
Validation loss: 2.9410041891118532

Epoch: 5| Step: 10
Training loss: 3.773419141769409
Validation loss: 2.930073333042924

Epoch: 18| Step: 0
Training loss: 3.5314056873321533
Validation loss: 2.9345795210971626

Epoch: 5| Step: 1
Training loss: 3.023797035217285
Validation loss: 2.933579647412864

Epoch: 5| Step: 2
Training loss: 2.797245740890503
Validation loss: 2.958101749420166

Epoch: 5| Step: 3
Training loss: 2.437788248062134
Validation loss: 2.9596834054557224

Epoch: 5| Step: 4
Training loss: 3.022559642791748
Validation loss: 2.9274853762759956

Epoch: 5| Step: 5
Training loss: 2.201785087585449
Validation loss: 2.923511071871686

Epoch: 5| Step: 6
Training loss: 3.850860595703125
Validation loss: 2.9386740781927623

Epoch: 5| Step: 7
Training loss: 3.4568755626678467
Validation loss: 2.934464951997162

Epoch: 5| Step: 8
Training loss: 3.2784030437469482
Validation loss: 2.9220865823889293

Epoch: 5| Step: 9
Training loss: 3.4332900047302246
Validation loss: 2.9178856803524877

Epoch: 5| Step: 10
Training loss: 1.9854345321655273
Validation loss: 2.91562742828041

Epoch: 19| Step: 0
Training loss: 2.7597591876983643
Validation loss: 2.9101984885431107

Epoch: 5| Step: 1
Training loss: 2.966498851776123
Validation loss: 2.90703986793436

Epoch: 5| Step: 2
Training loss: 2.4430596828460693
Validation loss: 2.9037101935314875

Epoch: 5| Step: 3
Training loss: 3.1056342124938965
Validation loss: 2.8980859069414038

Epoch: 5| Step: 4
Training loss: 2.921846866607666
Validation loss: 2.8920484076264086

Epoch: 5| Step: 5
Training loss: 2.6215713024139404
Validation loss: 2.8928392215441634

Epoch: 5| Step: 6
Training loss: 2.585329532623291
Validation loss: 2.8865158942437943

Epoch: 5| Step: 7
Training loss: 3.740535020828247
Validation loss: 2.879929639959848

Epoch: 5| Step: 8
Training loss: 2.618655204772949
Validation loss: 2.880451399792907

Epoch: 5| Step: 9
Training loss: 3.386345624923706
Validation loss: 2.8732727214854252

Epoch: 5| Step: 10
Training loss: 3.8152241706848145
Validation loss: 2.874102859086888

Epoch: 20| Step: 0
Training loss: 2.2005555629730225
Validation loss: 2.869359859856226

Epoch: 5| Step: 1
Training loss: 3.023466110229492
Validation loss: 2.8629434775280695

Epoch: 5| Step: 2
Training loss: 2.0956714153289795
Validation loss: 2.8592236606023644

Epoch: 5| Step: 3
Training loss: 3.2159085273742676
Validation loss: 2.8596516014427267

Epoch: 5| Step: 4
Training loss: 3.2278778553009033
Validation loss: 2.8519424161603375

Epoch: 5| Step: 5
Training loss: 3.703643321990967
Validation loss: 2.847545764779532

Epoch: 5| Step: 6
Training loss: 3.2994301319122314
Validation loss: 2.8463271228216027

Epoch: 5| Step: 7
Training loss: 2.548574447631836
Validation loss: 2.849115107649116

Epoch: 5| Step: 8
Training loss: 2.5829341411590576
Validation loss: 2.8485084451654905

Epoch: 5| Step: 9
Training loss: 3.234447479248047
Validation loss: 2.8452989593628915

Epoch: 5| Step: 10
Training loss: 3.5468127727508545
Validation loss: 2.8442521454185568

Epoch: 21| Step: 0
Training loss: 3.217409610748291
Validation loss: 2.842937213118358

Epoch: 5| Step: 1
Training loss: 2.4221339225769043
Validation loss: 2.839309323218561

Epoch: 5| Step: 2
Training loss: 2.699143409729004
Validation loss: 2.8336116959971767

Epoch: 5| Step: 3
Training loss: 3.0899319648742676
Validation loss: 2.8304366398883123

Epoch: 5| Step: 4
Training loss: 2.283019542694092
Validation loss: 2.8265159924825034

Epoch: 5| Step: 5
Training loss: 3.770071506500244
Validation loss: 2.8252468416767735

Epoch: 5| Step: 6
Training loss: 2.6858162879943848
Validation loss: 2.8216936844651417

Epoch: 5| Step: 7
Training loss: 2.9746994972229004
Validation loss: 2.820952248829667

Epoch: 5| Step: 8
Training loss: 3.576566696166992
Validation loss: 2.817748115908715

Epoch: 5| Step: 9
Training loss: 3.136842727661133
Validation loss: 2.8176235511738765

Epoch: 5| Step: 10
Training loss: 2.491122007369995
Validation loss: 2.814030490895753

Epoch: 22| Step: 0
Training loss: 2.5469164848327637
Validation loss: 2.8151717057792087

Epoch: 5| Step: 1
Training loss: 3.346376419067383
Validation loss: 2.8137008144009497

Epoch: 5| Step: 2
Training loss: 3.14866042137146
Validation loss: 2.8090518700179232

Epoch: 5| Step: 3
Training loss: 2.84321928024292
Validation loss: 2.8088472350951164

Epoch: 5| Step: 4
Training loss: 3.3997550010681152
Validation loss: 2.8059976434194915

Epoch: 5| Step: 5
Training loss: 2.8583877086639404
Validation loss: 2.804121358420259

Epoch: 5| Step: 6
Training loss: 2.4265244007110596
Validation loss: 2.8027504156994563

Epoch: 5| Step: 7
Training loss: 2.6037538051605225
Validation loss: 2.8020708381488757

Epoch: 5| Step: 8
Training loss: 2.6623988151550293
Validation loss: 2.7995457444139706

Epoch: 5| Step: 9
Training loss: 3.0964720249176025
Validation loss: 2.7996127861802296

Epoch: 5| Step: 10
Training loss: 3.3806991577148438
Validation loss: 2.8033423039220993

Epoch: 23| Step: 0
Training loss: 2.6556591987609863
Validation loss: 2.8024490033426592

Epoch: 5| Step: 1
Training loss: 2.6065452098846436
Validation loss: 2.8079641608781714

Epoch: 5| Step: 2
Training loss: 3.3307533264160156
Validation loss: 2.805055031212427

Epoch: 5| Step: 3
Training loss: 3.0747101306915283
Validation loss: 2.7957887111171598

Epoch: 5| Step: 4
Training loss: 2.9945547580718994
Validation loss: 2.7950291223423456

Epoch: 5| Step: 5
Training loss: 3.1509177684783936
Validation loss: 2.79344964796497

Epoch: 5| Step: 6
Training loss: 3.0918171405792236
Validation loss: 2.7922580344702608

Epoch: 5| Step: 7
Training loss: 2.987044334411621
Validation loss: 2.790854471986012

Epoch: 5| Step: 8
Training loss: 2.8940672874450684
Validation loss: 2.7893068252071256

Epoch: 5| Step: 9
Training loss: 2.5344290733337402
Validation loss: 2.787930724441364

Epoch: 5| Step: 10
Training loss: 2.8383922576904297
Validation loss: 2.7855412742143035

Epoch: 24| Step: 0
Training loss: 2.6559977531433105
Validation loss: 2.790498638665804

Epoch: 5| Step: 1
Training loss: 2.212188959121704
Validation loss: 2.786773450912968

Epoch: 5| Step: 2
Training loss: 2.6089022159576416
Validation loss: 2.786969136166316

Epoch: 5| Step: 3
Training loss: 2.3354251384735107
Validation loss: 2.7917373103480183

Epoch: 5| Step: 4
Training loss: 3.3857619762420654
Validation loss: 2.7873029503771054

Epoch: 5| Step: 5
Training loss: 2.776777744293213
Validation loss: 2.791572881001298

Epoch: 5| Step: 6
Training loss: 3.5019371509552
Validation loss: 2.785435361246909

Epoch: 5| Step: 7
Training loss: 3.0072898864746094
Validation loss: 2.7863550391248477

Epoch: 5| Step: 8
Training loss: 3.261664867401123
Validation loss: 2.784156012278731

Epoch: 5| Step: 9
Training loss: 3.2702298164367676
Validation loss: 2.779318665945402

Epoch: 5| Step: 10
Training loss: 3.0693821907043457
Validation loss: 2.779077535034508

Epoch: 25| Step: 0
Training loss: 2.8720626831054688
Validation loss: 2.7742436996070285

Epoch: 5| Step: 1
Training loss: 2.8362317085266113
Validation loss: 2.772987537486579

Epoch: 5| Step: 2
Training loss: 3.0979371070861816
Validation loss: 2.769057899393061

Epoch: 5| Step: 3
Training loss: 3.4379723072052
Validation loss: 2.7697323342805267

Epoch: 5| Step: 4
Training loss: 2.2817721366882324
Validation loss: 2.768694918642762

Epoch: 5| Step: 5
Training loss: 3.597689151763916
Validation loss: 2.7661528920614593

Epoch: 5| Step: 6
Training loss: 3.1109607219696045
Validation loss: 2.7673309644063315

Epoch: 5| Step: 7
Training loss: 2.0592403411865234
Validation loss: 2.772491157695811

Epoch: 5| Step: 8
Training loss: 2.8518364429473877
Validation loss: 2.7692313476275374

Epoch: 5| Step: 9
Training loss: 2.825650215148926
Validation loss: 2.7660148502678

Epoch: 5| Step: 10
Training loss: 3.052962303161621
Validation loss: 2.765312010242093

Epoch: 26| Step: 0
Training loss: 2.7926433086395264
Validation loss: 2.761880754142679

Epoch: 5| Step: 1
Training loss: 3.2382607460021973
Validation loss: 2.7607498579127814

Epoch: 5| Step: 2
Training loss: 3.3992056846618652
Validation loss: 2.7612206628245692

Epoch: 5| Step: 3
Training loss: 2.7706291675567627
Validation loss: 2.761468602764991

Epoch: 5| Step: 4
Training loss: 1.913031816482544
Validation loss: 2.758291857216948

Epoch: 5| Step: 5
Training loss: 2.9293570518493652
Validation loss: 2.757586202313823

Epoch: 5| Step: 6
Training loss: 2.749541759490967
Validation loss: 2.756337055595972

Epoch: 5| Step: 7
Training loss: 2.8790464401245117
Validation loss: 2.7583160426027034

Epoch: 5| Step: 8
Training loss: 3.364421844482422
Validation loss: 2.760679180904101

Epoch: 5| Step: 9
Training loss: 3.67992901802063
Validation loss: 2.765625630655596

Epoch: 5| Step: 10
Training loss: 2.1129093170166016
Validation loss: 2.7676014233660955

Epoch: 27| Step: 0
Training loss: 2.331357717514038
Validation loss: 2.764859673797443

Epoch: 5| Step: 1
Training loss: 2.8865575790405273
Validation loss: 2.755791546196066

Epoch: 5| Step: 2
Training loss: 3.948305606842041
Validation loss: 2.756328526363578

Epoch: 5| Step: 3
Training loss: 2.567493438720703
Validation loss: 2.75124865962613

Epoch: 5| Step: 4
Training loss: 2.0590338706970215
Validation loss: 2.7518407375581804

Epoch: 5| Step: 5
Training loss: 3.2631163597106934
Validation loss: 2.7508633059840046

Epoch: 5| Step: 6
Training loss: 3.356539487838745
Validation loss: 2.746991052422472

Epoch: 5| Step: 7
Training loss: 1.8239799737930298
Validation loss: 2.7469076469380367

Epoch: 5| Step: 8
Training loss: 2.8809425830841064
Validation loss: 2.7500433537267868

Epoch: 5| Step: 9
Training loss: 2.981421947479248
Validation loss: 2.7456041074568227

Epoch: 5| Step: 10
Training loss: 3.914595603942871
Validation loss: 2.7471029784089778

Epoch: 28| Step: 0
Training loss: 2.103548765182495
Validation loss: 2.7445928640263055

Epoch: 5| Step: 1
Training loss: 2.4653875827789307
Validation loss: 2.7423763634056173

Epoch: 5| Step: 2
Training loss: 3.5879218578338623
Validation loss: 2.7434532129636375

Epoch: 5| Step: 3
Training loss: 2.7845396995544434
Validation loss: 2.740897681123467

Epoch: 5| Step: 4
Training loss: 3.154024124145508
Validation loss: 2.7404533099102717

Epoch: 5| Step: 5
Training loss: 3.2699761390686035
Validation loss: 2.740043245336061

Epoch: 5| Step: 6
Training loss: 2.79243803024292
Validation loss: 2.7423292411270963

Epoch: 5| Step: 7
Training loss: 3.314347743988037
Validation loss: 2.741185744603475

Epoch: 5| Step: 8
Training loss: 2.9582457542419434
Validation loss: 2.7410324696571595

Epoch: 5| Step: 9
Training loss: 2.8683860301971436
Validation loss: 2.739592641912481

Epoch: 5| Step: 10
Training loss: 2.4467272758483887
Validation loss: 2.7388845592416744

Epoch: 29| Step: 0
Training loss: 2.982468843460083
Validation loss: 2.7375935918541363

Epoch: 5| Step: 1
Training loss: 2.6440303325653076
Validation loss: 2.7386707387944704

Epoch: 5| Step: 2
Training loss: 2.9717602729797363
Validation loss: 2.7328457627245175

Epoch: 5| Step: 3
Training loss: 3.0868518352508545
Validation loss: 2.7344097475851736

Epoch: 5| Step: 4
Training loss: 2.9902007579803467
Validation loss: 2.733047116187311

Epoch: 5| Step: 5
Training loss: 2.620418071746826
Validation loss: 2.73316280816191

Epoch: 5| Step: 6
Training loss: 2.2148654460906982
Validation loss: 2.7298498204959336

Epoch: 5| Step: 7
Training loss: 3.1700878143310547
Validation loss: 2.730176397549209

Epoch: 5| Step: 8
Training loss: 2.8400027751922607
Validation loss: 2.7288717557025213

Epoch: 5| Step: 9
Training loss: 3.166395664215088
Validation loss: 2.730875789478261

Epoch: 5| Step: 10
Training loss: 3.073878049850464
Validation loss: 2.7312328020731607

Epoch: 30| Step: 0
Training loss: 2.798555850982666
Validation loss: 2.7293795078031478

Epoch: 5| Step: 1
Training loss: 3.167821168899536
Validation loss: 2.729980863550658

Epoch: 5| Step: 2
Training loss: 2.97005558013916
Validation loss: 2.730711406277072

Epoch: 5| Step: 3
Training loss: 3.3923580646514893
Validation loss: 2.7333407222583728

Epoch: 5| Step: 4
Training loss: 2.6824800968170166
Validation loss: 2.733669650170111

Epoch: 5| Step: 5
Training loss: 2.656837224960327
Validation loss: 2.743437082536759

Epoch: 5| Step: 6
Training loss: 2.991765260696411
Validation loss: 2.739522623759444

Epoch: 5| Step: 7
Training loss: 2.5261764526367188
Validation loss: 2.7359916548575125

Epoch: 5| Step: 8
Training loss: 2.830366373062134
Validation loss: 2.7285387221203057

Epoch: 5| Step: 9
Training loss: 2.737941026687622
Validation loss: 2.7257563016747914

Epoch: 5| Step: 10
Training loss: 2.953434944152832
Validation loss: 2.725599632468275

Epoch: 31| Step: 0
Training loss: 2.2021281719207764
Validation loss: 2.7258347542055192

Epoch: 5| Step: 1
Training loss: 2.757033348083496
Validation loss: 2.7278280950361684

Epoch: 5| Step: 2
Training loss: 3.4032280445098877
Validation loss: 2.7351156537250807

Epoch: 5| Step: 3
Training loss: 3.903618335723877
Validation loss: 2.7261914463453394

Epoch: 5| Step: 4
Training loss: 3.2564759254455566
Validation loss: 2.7248342575565463

Epoch: 5| Step: 5
Training loss: 3.7227377891540527
Validation loss: 2.729624822575559

Epoch: 5| Step: 6
Training loss: 2.648308038711548
Validation loss: 2.7315562104666107

Epoch: 5| Step: 7
Training loss: 2.8412129878997803
Validation loss: 2.738080724593132

Epoch: 5| Step: 8
Training loss: 2.3988213539123535
Validation loss: 2.72876133970035

Epoch: 5| Step: 9
Training loss: 2.094719171524048
Validation loss: 2.7249658902486167

Epoch: 5| Step: 10
Training loss: 2.442716598510742
Validation loss: 2.7210753040928997

Epoch: 32| Step: 0
Training loss: 2.626295804977417
Validation loss: 2.7209948211587887

Epoch: 5| Step: 1
Training loss: 2.98724102973938
Validation loss: 2.723681280689855

Epoch: 5| Step: 2
Training loss: 3.04398775100708
Validation loss: 2.72094298947242

Epoch: 5| Step: 3
Training loss: 3.0693984031677246
Validation loss: 2.7230126280938425

Epoch: 5| Step: 4
Training loss: 3.375175952911377
Validation loss: 2.7283882992241972

Epoch: 5| Step: 5
Training loss: 2.9536221027374268
Validation loss: 2.724550708647697

Epoch: 5| Step: 6
Training loss: 3.138190746307373
Validation loss: 2.722196470024765

Epoch: 5| Step: 7
Training loss: 2.32204008102417
Validation loss: 2.7261120350130144

Epoch: 5| Step: 8
Training loss: 2.635312557220459
Validation loss: 2.720384928487962

Epoch: 5| Step: 9
Training loss: 2.767531156539917
Validation loss: 2.719606594372821

Epoch: 5| Step: 10
Training loss: 2.727020263671875
Validation loss: 2.7211913037043747

Epoch: 33| Step: 0
Training loss: 2.516446590423584
Validation loss: 2.717369359026673

Epoch: 5| Step: 1
Training loss: 3.38678240776062
Validation loss: 2.718760774981591

Epoch: 5| Step: 2
Training loss: 2.729949474334717
Validation loss: 2.7188180800407165

Epoch: 5| Step: 3
Training loss: 2.583383560180664
Validation loss: 2.7188088304253033

Epoch: 5| Step: 4
Training loss: 3.1136021614074707
Validation loss: 2.7161736872888382

Epoch: 5| Step: 5
Training loss: 3.3751797676086426
Validation loss: 2.7162664116069837

Epoch: 5| Step: 6
Training loss: 2.790818929672241
Validation loss: 2.7140952258981685

Epoch: 5| Step: 7
Training loss: 3.0270309448242188
Validation loss: 2.718941516773675

Epoch: 5| Step: 8
Training loss: 2.8733818531036377
Validation loss: 2.7126131391012542

Epoch: 5| Step: 9
Training loss: 2.7936131954193115
Validation loss: 2.7115340745577248

Epoch: 5| Step: 10
Training loss: 2.3340320587158203
Validation loss: 2.7086316667577273

Epoch: 34| Step: 0
Training loss: 2.7886881828308105
Validation loss: 2.7067948413151566

Epoch: 5| Step: 1
Training loss: 2.841784715652466
Validation loss: 2.7094347656414075

Epoch: 5| Step: 2
Training loss: 2.9709489345550537
Validation loss: 2.7086312540115847

Epoch: 5| Step: 3
Training loss: 3.238349437713623
Validation loss: 2.710596287122337

Epoch: 5| Step: 4
Training loss: 2.6824026107788086
Validation loss: 2.707751066453995

Epoch: 5| Step: 5
Training loss: 2.7447509765625
Validation loss: 2.7079024622517247

Epoch: 5| Step: 6
Training loss: 2.8041510581970215
Validation loss: 2.7058700797378377

Epoch: 5| Step: 7
Training loss: 2.622931957244873
Validation loss: 2.7098641754478536

Epoch: 5| Step: 8
Training loss: 3.8242297172546387
Validation loss: 2.7046968449828444

Epoch: 5| Step: 9
Training loss: 2.4158568382263184
Validation loss: 2.7054302833413564

Epoch: 5| Step: 10
Training loss: 2.5978832244873047
Validation loss: 2.7071133582822737

Epoch: 35| Step: 0
Training loss: 3.1972274780273438
Validation loss: 2.7075529072874334

Epoch: 5| Step: 1
Training loss: 3.2814841270446777
Validation loss: 2.7014858953414427

Epoch: 5| Step: 2
Training loss: 3.0329909324645996
Validation loss: 2.7017975981517504

Epoch: 5| Step: 3
Training loss: 3.347907304763794
Validation loss: 2.7068275136332356

Epoch: 5| Step: 4
Training loss: 3.0771942138671875
Validation loss: 2.7061085521533923

Epoch: 5| Step: 5
Training loss: 2.450756788253784
Validation loss: 2.7048719236927647

Epoch: 5| Step: 6
Training loss: 2.1568493843078613
Validation loss: 2.7137666056233067

Epoch: 5| Step: 7
Training loss: 2.7341842651367188
Validation loss: 2.7137931367402435

Epoch: 5| Step: 8
Training loss: 2.6841988563537598
Validation loss: 2.7178271355167514

Epoch: 5| Step: 9
Training loss: 2.9887607097625732
Validation loss: 2.7102325270252843

Epoch: 5| Step: 10
Training loss: 2.5116965770721436
Validation loss: 2.7091298410969396

Epoch: 36| Step: 0
Training loss: 4.057538032531738
Validation loss: 2.7093900583123647

Epoch: 5| Step: 1
Training loss: 2.239542007446289
Validation loss: 2.712153455262543

Epoch: 5| Step: 2
Training loss: 2.7308716773986816
Validation loss: 2.7077747365479827

Epoch: 5| Step: 3
Training loss: 3.108365535736084
Validation loss: 2.706258261075584

Epoch: 5| Step: 4
Training loss: 2.7071194648742676
Validation loss: 2.702761032248056

Epoch: 5| Step: 5
Training loss: 2.2205281257629395
Validation loss: 2.6960229309656287

Epoch: 5| Step: 6
Training loss: 3.206721782684326
Validation loss: 2.694266960185061

Epoch: 5| Step: 7
Training loss: 2.3564980030059814
Validation loss: 2.700267594347718

Epoch: 5| Step: 8
Training loss: 3.443361759185791
Validation loss: 2.698324188109367

Epoch: 5| Step: 9
Training loss: 2.4259984493255615
Validation loss: 2.6980459459366335

Epoch: 5| Step: 10
Training loss: 2.9924049377441406
Validation loss: 2.6977915302399667

Epoch: 37| Step: 0
Training loss: 3.3746981620788574
Validation loss: 2.6963271376907185

Epoch: 5| Step: 1
Training loss: 2.557445526123047
Validation loss: 2.6996011862190823

Epoch: 5| Step: 2
Training loss: 2.9378509521484375
Validation loss: 2.695987142542357

Epoch: 5| Step: 3
Training loss: 2.847491502761841
Validation loss: 2.6996922646799395

Epoch: 5| Step: 4
Training loss: 2.9149022102355957
Validation loss: 2.6986299432734007

Epoch: 5| Step: 5
Training loss: 2.0533287525177
Validation loss: 2.695169905180572

Epoch: 5| Step: 6
Training loss: 3.0587949752807617
Validation loss: 2.698469446551415

Epoch: 5| Step: 7
Training loss: 2.787692070007324
Validation loss: 2.698075440622145

Epoch: 5| Step: 8
Training loss: 2.951122760772705
Validation loss: 2.6957231311387915

Epoch: 5| Step: 9
Training loss: 2.687387466430664
Validation loss: 2.695151303404121

Epoch: 5| Step: 10
Training loss: 3.3139848709106445
Validation loss: 2.691539918222735

Epoch: 38| Step: 0
Training loss: 3.32007098197937
Validation loss: 2.69247628027393

Epoch: 5| Step: 1
Training loss: 3.2619705200195312
Validation loss: 2.691939748743529

Epoch: 5| Step: 2
Training loss: 3.0146660804748535
Validation loss: 2.689926270515688

Epoch: 5| Step: 3
Training loss: 2.213019609451294
Validation loss: 2.693532261797177

Epoch: 5| Step: 4
Training loss: 2.800281286239624
Validation loss: 2.6907776094252065

Epoch: 5| Step: 5
Training loss: 2.899501085281372
Validation loss: 2.690435896637619

Epoch: 5| Step: 6
Training loss: 2.761659860610962
Validation loss: 2.6903152594002346

Epoch: 5| Step: 7
Training loss: 3.209779739379883
Validation loss: 2.695511330840408

Epoch: 5| Step: 8
Training loss: 2.78928804397583
Validation loss: 2.6946131516528387

Epoch: 5| Step: 9
Training loss: 2.75085711479187
Validation loss: 2.6978301284133748

Epoch: 5| Step: 10
Training loss: 2.2600276470184326
Validation loss: 2.6980789476825344

Epoch: 39| Step: 0
Training loss: 2.8135838508605957
Validation loss: 2.705649688679685

Epoch: 5| Step: 1
Training loss: 3.041677474975586
Validation loss: 2.6950967645132415

Epoch: 5| Step: 2
Training loss: 2.4343416690826416
Validation loss: 2.6963690634696715

Epoch: 5| Step: 3
Training loss: 3.2343807220458984
Validation loss: 2.688099386871502

Epoch: 5| Step: 4
Training loss: 2.658325672149658
Validation loss: 2.690898192826138

Epoch: 5| Step: 5
Training loss: 2.897878408432007
Validation loss: 2.6864241938437186

Epoch: 5| Step: 6
Training loss: 2.9503087997436523
Validation loss: 2.68701179822286

Epoch: 5| Step: 7
Training loss: 2.769425868988037
Validation loss: 2.6866140724510275

Epoch: 5| Step: 8
Training loss: 2.7116198539733887
Validation loss: 2.686840670083159

Epoch: 5| Step: 9
Training loss: 3.191375494003296
Validation loss: 2.688598648194344

Epoch: 5| Step: 10
Training loss: 2.615830898284912
Validation loss: 2.685677338671941

Epoch: 40| Step: 0
Training loss: 2.845643997192383
Validation loss: 2.6891713526941117

Epoch: 5| Step: 1
Training loss: 2.919884204864502
Validation loss: 2.68856147796877

Epoch: 5| Step: 2
Training loss: 2.12992525100708
Validation loss: 2.697880486006378

Epoch: 5| Step: 3
Training loss: 3.3118858337402344
Validation loss: 2.6997225361485637

Epoch: 5| Step: 4
Training loss: 2.7537598609924316
Validation loss: 2.6985646499100553

Epoch: 5| Step: 5
Training loss: 3.3699722290039062
Validation loss: 2.7005191156941075

Epoch: 5| Step: 6
Training loss: 2.4680233001708984
Validation loss: 2.6937518376176075

Epoch: 5| Step: 7
Training loss: 2.9188129901885986
Validation loss: 2.6920017760287047

Epoch: 5| Step: 8
Training loss: 2.728545665740967
Validation loss: 2.691997774185673

Epoch: 5| Step: 9
Training loss: 2.695533275604248
Validation loss: 2.6886767956518356

Epoch: 5| Step: 10
Training loss: 3.2387044429779053
Validation loss: 2.6864081992897937

Epoch: 41| Step: 0
Training loss: 3.23158597946167
Validation loss: 2.6846880553871073

Epoch: 5| Step: 1
Training loss: 2.8518803119659424
Validation loss: 2.6847418662040465

Epoch: 5| Step: 2
Training loss: 3.33384370803833
Validation loss: 2.686712195796351

Epoch: 5| Step: 3
Training loss: 3.298398971557617
Validation loss: 2.68253122222039

Epoch: 5| Step: 4
Training loss: 2.3582687377929688
Validation loss: 2.6821975720826017

Epoch: 5| Step: 5
Training loss: 3.3006958961486816
Validation loss: 2.6801820544786352

Epoch: 5| Step: 6
Training loss: 2.3808059692382812
Validation loss: 2.682208753401233

Epoch: 5| Step: 7
Training loss: 2.558088779449463
Validation loss: 2.6795008233798447

Epoch: 5| Step: 8
Training loss: 2.244884967803955
Validation loss: 2.6852369462290118

Epoch: 5| Step: 9
Training loss: 2.9510161876678467
Validation loss: 2.6858460903167725

Epoch: 5| Step: 10
Training loss: 2.7351248264312744
Validation loss: 2.6870450306964178

Epoch: 42| Step: 0
Training loss: 2.5386531352996826
Validation loss: 2.685901775155016

Epoch: 5| Step: 1
Training loss: 3.1919851303100586
Validation loss: 2.6882671412601264

Epoch: 5| Step: 2
Training loss: 2.4986891746520996
Validation loss: 2.685060844626478

Epoch: 5| Step: 3
Training loss: 2.974637508392334
Validation loss: 2.6858515611258884

Epoch: 5| Step: 4
Training loss: 2.237492084503174
Validation loss: 2.6864150698466966

Epoch: 5| Step: 5
Training loss: 3.684417724609375
Validation loss: 2.6856389866080335

Epoch: 5| Step: 6
Training loss: 2.5845513343811035
Validation loss: 2.678931510576638

Epoch: 5| Step: 7
Training loss: 3.127419948577881
Validation loss: 2.67931269573909

Epoch: 5| Step: 8
Training loss: 2.793017864227295
Validation loss: 2.6783946252638295

Epoch: 5| Step: 9
Training loss: 2.7381105422973633
Validation loss: 2.6774925698516188

Epoch: 5| Step: 10
Training loss: 2.8294715881347656
Validation loss: 2.6770050192392

Epoch: 43| Step: 0
Training loss: 2.6015491485595703
Validation loss: 2.6801925987325688

Epoch: 5| Step: 1
Training loss: 3.486372709274292
Validation loss: 2.6805236467751126

Epoch: 5| Step: 2
Training loss: 2.8335959911346436
Validation loss: 2.682257039572603

Epoch: 5| Step: 3
Training loss: 3.4554057121276855
Validation loss: 2.6808497598094325

Epoch: 5| Step: 4
Training loss: 2.2944912910461426
Validation loss: 2.680452367310883

Epoch: 5| Step: 5
Training loss: 2.97493314743042
Validation loss: 2.6849043574384464

Epoch: 5| Step: 6
Training loss: 2.1307244300842285
Validation loss: 2.6858277884862756

Epoch: 5| Step: 7
Training loss: 2.624725103378296
Validation loss: 2.681478620857321

Epoch: 5| Step: 8
Training loss: 2.902501344680786
Validation loss: 2.6823489204529793

Epoch: 5| Step: 9
Training loss: 3.1182844638824463
Validation loss: 2.678505127147962

Epoch: 5| Step: 10
Training loss: 2.720491409301758
Validation loss: 2.6721715286213863

Epoch: 44| Step: 0
Training loss: 2.368009328842163
Validation loss: 2.6718630893256075

Epoch: 5| Step: 1
Training loss: 3.257061004638672
Validation loss: 2.6814841455028904

Epoch: 5| Step: 2
Training loss: 2.9193577766418457
Validation loss: 2.67634803377172

Epoch: 5| Step: 3
Training loss: 3.5911431312561035
Validation loss: 2.6708163138358825

Epoch: 5| Step: 4
Training loss: 2.4693121910095215
Validation loss: 2.6676262681202223

Epoch: 5| Step: 5
Training loss: 2.799654960632324
Validation loss: 2.6664222901867283

Epoch: 5| Step: 6
Training loss: 3.375736951828003
Validation loss: 2.6765471043125277

Epoch: 5| Step: 7
Training loss: 2.554614305496216
Validation loss: 2.679170711066133

Epoch: 5| Step: 8
Training loss: 2.507253646850586
Validation loss: 2.6955887527876

Epoch: 5| Step: 9
Training loss: 2.2277767658233643
Validation loss: 2.7046589825742986

Epoch: 5| Step: 10
Training loss: 3.13193941116333
Validation loss: 2.6986585919575026

Epoch: 45| Step: 0
Training loss: 2.923316478729248
Validation loss: 2.693504495005454

Epoch: 5| Step: 1
Training loss: 2.1969172954559326
Validation loss: 2.673845750029369

Epoch: 5| Step: 2
Training loss: 2.6808502674102783
Validation loss: 2.6693443739286034

Epoch: 5| Step: 3
Training loss: 2.2159171104431152
Validation loss: 2.6700307271813832

Epoch: 5| Step: 4
Training loss: 3.7820992469787598
Validation loss: 2.677974126672232

Epoch: 5| Step: 5
Training loss: 3.0359389781951904
Validation loss: 2.6723888279289327

Epoch: 5| Step: 6
Training loss: 2.8373732566833496
Validation loss: 2.6667551250867945

Epoch: 5| Step: 7
Training loss: 2.4961562156677246
Validation loss: 2.665992142051779

Epoch: 5| Step: 8
Training loss: 2.8678905963897705
Validation loss: 2.6689496271071897

Epoch: 5| Step: 9
Training loss: 3.055511474609375
Validation loss: 2.669622241809804

Epoch: 5| Step: 10
Training loss: 3.091778039932251
Validation loss: 2.6665712197621665

Epoch: 46| Step: 0
Training loss: 2.5948784351348877
Validation loss: 2.669572707145445

Epoch: 5| Step: 1
Training loss: 3.266819715499878
Validation loss: 2.6740726219710482

Epoch: 5| Step: 2
Training loss: 2.4390430450439453
Validation loss: 2.67288742526885

Epoch: 5| Step: 3
Training loss: 2.5949795246124268
Validation loss: 2.6772890783125356

Epoch: 5| Step: 4
Training loss: 2.9907748699188232
Validation loss: 2.6790256833517425

Epoch: 5| Step: 5
Training loss: 2.4209144115448
Validation loss: 2.6664292709801787

Epoch: 5| Step: 6
Training loss: 3.210153579711914
Validation loss: 2.664167901521088

Epoch: 5| Step: 7
Training loss: 2.4482760429382324
Validation loss: 2.6656188477752027

Epoch: 5| Step: 8
Training loss: 3.1537880897521973
Validation loss: 2.661191919798492

Epoch: 5| Step: 9
Training loss: 3.139254331588745
Validation loss: 2.6607074840094453

Epoch: 5| Step: 10
Training loss: 2.7659597396850586
Validation loss: 2.6605566675944994

Epoch: 47| Step: 0
Training loss: 2.9798200130462646
Validation loss: 2.658886055792532

Epoch: 5| Step: 1
Training loss: 2.3889336585998535
Validation loss: 2.658192665346207

Epoch: 5| Step: 2
Training loss: 2.4607608318328857
Validation loss: 2.6592724092545046

Epoch: 5| Step: 3
Training loss: 3.1740312576293945
Validation loss: 2.657336211973621

Epoch: 5| Step: 4
Training loss: 3.2045974731445312
Validation loss: 2.654558015126054

Epoch: 5| Step: 5
Training loss: 2.1255860328674316
Validation loss: 2.6565758566702566

Epoch: 5| Step: 6
Training loss: 2.830698013305664
Validation loss: 2.6552836459170104

Epoch: 5| Step: 7
Training loss: 3.0625839233398438
Validation loss: 2.6530432239655526

Epoch: 5| Step: 8
Training loss: 2.9105019569396973
Validation loss: 2.6534105757231354

Epoch: 5| Step: 9
Training loss: 2.660212993621826
Validation loss: 2.657532743228379

Epoch: 5| Step: 10
Training loss: 3.274956703186035
Validation loss: 2.6567119654788764

Epoch: 48| Step: 0
Training loss: 2.3842196464538574
Validation loss: 2.664180314669045

Epoch: 5| Step: 1
Training loss: 3.052933931350708
Validation loss: 2.6740550584690546

Epoch: 5| Step: 2
Training loss: 2.220510959625244
Validation loss: 2.678059865069646

Epoch: 5| Step: 3
Training loss: 3.395052671432495
Validation loss: 2.6924412404337237

Epoch: 5| Step: 4
Training loss: 2.6264936923980713
Validation loss: 2.6940603256225586

Epoch: 5| Step: 5
Training loss: 2.737389087677002
Validation loss: 2.6876279179767897

Epoch: 5| Step: 6
Training loss: 3.1544747352600098
Validation loss: 2.682451742951588

Epoch: 5| Step: 7
Training loss: 2.6592137813568115
Validation loss: 2.67469609168268

Epoch: 5| Step: 8
Training loss: 2.8171730041503906
Validation loss: 2.6649322279037966

Epoch: 5| Step: 9
Training loss: 2.707770824432373
Validation loss: 2.659329539986067

Epoch: 5| Step: 10
Training loss: 3.3728880882263184
Validation loss: 2.6514906447420836

Epoch: 49| Step: 0
Training loss: 2.3577239513397217
Validation loss: 2.650324954781481

Epoch: 5| Step: 1
Training loss: 2.2014944553375244
Validation loss: 2.651150111229189

Epoch: 5| Step: 2
Training loss: 2.758254051208496
Validation loss: 2.6581176045120403

Epoch: 5| Step: 3
Training loss: 2.6764659881591797
Validation loss: 2.6853087397031885

Epoch: 5| Step: 4
Training loss: 3.5184967517852783
Validation loss: 2.801301363975771

Epoch: 5| Step: 5
Training loss: 2.331329822540283
Validation loss: 2.7860971650769635

Epoch: 5| Step: 6
Training loss: 3.70650053024292
Validation loss: 2.7732989531691357

Epoch: 5| Step: 7
Training loss: 3.1472601890563965
Validation loss: 2.7343049741560415

Epoch: 5| Step: 8
Training loss: 3.225585460662842
Validation loss: 2.7278126285922144

Epoch: 5| Step: 9
Training loss: 2.7607014179229736
Validation loss: 2.7330944051024733

Epoch: 5| Step: 10
Training loss: 2.9729433059692383
Validation loss: 2.742446368740451

Epoch: 50| Step: 0
Training loss: 2.970679759979248
Validation loss: 2.7544918829394924

Epoch: 5| Step: 1
Training loss: 2.7912240028381348
Validation loss: 2.775996915755733

Epoch: 5| Step: 2
Training loss: 3.193819761276245
Validation loss: 2.7872185143091346

Epoch: 5| Step: 3
Training loss: 2.5619282722473145
Validation loss: 2.775053067873883

Epoch: 5| Step: 4
Training loss: 2.884788990020752
Validation loss: 2.7589146937093427

Epoch: 5| Step: 5
Training loss: 3.1884536743164062
Validation loss: 2.746297533794116

Epoch: 5| Step: 6
Training loss: 2.292438507080078
Validation loss: 2.7444230356524066

Epoch: 5| Step: 7
Training loss: 2.8818652629852295
Validation loss: 2.738502005095123

Epoch: 5| Step: 8
Training loss: 2.444831371307373
Validation loss: 2.7355903322978685

Epoch: 5| Step: 9
Training loss: 3.3442111015319824
Validation loss: 2.734329713288174

Epoch: 5| Step: 10
Training loss: 3.1328814029693604
Validation loss: 2.7330288194840953

Epoch: 51| Step: 0
Training loss: 2.8557229042053223
Validation loss: 2.7324593579897316

Epoch: 5| Step: 1
Training loss: 2.6634633541107178
Validation loss: 2.7292579117641655

Epoch: 5| Step: 2
Training loss: 3.6058871746063232
Validation loss: 2.7321110284456642

Epoch: 5| Step: 3
Training loss: 2.8396942615509033
Validation loss: 2.7292652899219143

Epoch: 5| Step: 4
Training loss: 2.203307628631592
Validation loss: 2.7292391946238856

Epoch: 5| Step: 5
Training loss: 2.7566428184509277
Validation loss: 2.7254236975023822

Epoch: 5| Step: 6
Training loss: 3.037489175796509
Validation loss: 2.7232515453010477

Epoch: 5| Step: 7
Training loss: 3.315901279449463
Validation loss: 2.7284390695633425

Epoch: 5| Step: 8
Training loss: 2.72780442237854
Validation loss: 2.728747234549574

Epoch: 5| Step: 9
Training loss: 3.338658094406128
Validation loss: 2.7349428053825133

Epoch: 5| Step: 10
Training loss: 2.024841547012329
Validation loss: 2.733605646318005

Epoch: 52| Step: 0
Training loss: 2.6936707496643066
Validation loss: 2.733131383055

Epoch: 5| Step: 1
Training loss: 2.4356753826141357
Validation loss: 2.7366209055787776

Epoch: 5| Step: 2
Training loss: 3.6835696697235107
Validation loss: 2.7445575280856063

Epoch: 5| Step: 3
Training loss: 2.604686737060547
Validation loss: 2.739641461321103

Epoch: 5| Step: 4
Training loss: 2.465888261795044
Validation loss: 2.7266789200485393

Epoch: 5| Step: 5
Training loss: 3.4602692127227783
Validation loss: 2.724910572010984

Epoch: 5| Step: 6
Training loss: 3.377869129180908
Validation loss: 2.721623359187957

Epoch: 5| Step: 7
Training loss: 2.6053595542907715
Validation loss: 2.7192801737016246

Epoch: 5| Step: 8
Training loss: 2.7042901515960693
Validation loss: 2.7136787752951346

Epoch: 5| Step: 9
Training loss: 2.5514791011810303
Validation loss: 2.7155777228775846

Epoch: 5| Step: 10
Training loss: 2.8479421138763428
Validation loss: 2.7156124807173208

Epoch: 53| Step: 0
Training loss: 2.1176974773406982
Validation loss: 2.7086978061224825

Epoch: 5| Step: 1
Training loss: 2.3410212993621826
Validation loss: 2.7114324108246834

Epoch: 5| Step: 2
Training loss: 3.1602704524993896
Validation loss: 2.714041704772621

Epoch: 5| Step: 3
Training loss: 2.4993672370910645
Validation loss: 2.7102052063070317

Epoch: 5| Step: 4
Training loss: 3.192809581756592
Validation loss: 2.7137161544574204

Epoch: 5| Step: 5
Training loss: 2.84237003326416
Validation loss: 2.7113707629583215

Epoch: 5| Step: 6
Training loss: 3.0242745876312256
Validation loss: 2.7154573676406697

Epoch: 5| Step: 7
Training loss: 2.7086009979248047
Validation loss: 2.710496048773489

Epoch: 5| Step: 8
Training loss: 3.7162795066833496
Validation loss: 2.712993193698186

Epoch: 5| Step: 9
Training loss: 2.8059515953063965
Validation loss: 2.709573571399976

Epoch: 5| Step: 10
Training loss: 2.980424404144287
Validation loss: 2.706673868240849

Epoch: 54| Step: 0
Training loss: 3.4849071502685547
Validation loss: 2.7076942125956216

Epoch: 5| Step: 1
Training loss: 3.006122589111328
Validation loss: 2.7091173228397163

Epoch: 5| Step: 2
Training loss: 3.2084808349609375
Validation loss: 2.710120931748421

Epoch: 5| Step: 3
Training loss: 2.78981351852417
Validation loss: 2.702131122671148

Epoch: 5| Step: 4
Training loss: 2.9092233180999756
Validation loss: 2.708159864589732

Epoch: 5| Step: 5
Training loss: 2.301379680633545
Validation loss: 2.7060440971005346

Epoch: 5| Step: 6
Training loss: 2.9539012908935547
Validation loss: 2.70480441534391

Epoch: 5| Step: 7
Training loss: 3.0178608894348145
Validation loss: 2.703641512060678

Epoch: 5| Step: 8
Training loss: 2.679893970489502
Validation loss: 2.7020932987172115

Epoch: 5| Step: 9
Training loss: 2.2987313270568848
Validation loss: 2.707992064055576

Epoch: 5| Step: 10
Training loss: 2.5627996921539307
Validation loss: 2.708605517623245

Epoch: 55| Step: 0
Training loss: 3.1399147510528564
Validation loss: 2.7105390794815554

Epoch: 5| Step: 1
Training loss: 3.070502758026123
Validation loss: 2.713054833873626

Epoch: 5| Step: 2
Training loss: 3.093583583831787
Validation loss: 2.7172575637858403

Epoch: 5| Step: 3
Training loss: 2.455756187438965
Validation loss: 2.716355585282849

Epoch: 5| Step: 4
Training loss: 2.3071541786193848
Validation loss: 2.7169427692249255

Epoch: 5| Step: 5
Training loss: 2.9328975677490234
Validation loss: 2.7136096595436014

Epoch: 5| Step: 6
Training loss: 3.3113772869110107
Validation loss: 2.711393675496501

Epoch: 5| Step: 7
Training loss: 2.9624297618865967
Validation loss: 2.707832577408001

Epoch: 5| Step: 8
Training loss: 2.515829086303711
Validation loss: 2.7062140792928715

Epoch: 5| Step: 9
Training loss: 2.1991963386535645
Validation loss: 2.7056930398428314

Epoch: 5| Step: 10
Training loss: 3.3505098819732666
Validation loss: 2.7010020440624607

Epoch: 56| Step: 0
Training loss: 3.001246929168701
Validation loss: 2.7029254769766204

Epoch: 5| Step: 1
Training loss: 3.002990245819092
Validation loss: 2.699955963319348

Epoch: 5| Step: 2
Training loss: 1.9684522151947021
Validation loss: 2.699958839724141

Epoch: 5| Step: 3
Training loss: 3.241537570953369
Validation loss: 2.6992931314693984

Epoch: 5| Step: 4
Training loss: 3.1904003620147705
Validation loss: 2.697315413464782

Epoch: 5| Step: 5
Training loss: 2.271491527557373
Validation loss: 2.697535063630791

Epoch: 5| Step: 6
Training loss: 2.726890802383423
Validation loss: 2.6950577561573317

Epoch: 5| Step: 7
Training loss: 2.6462759971618652
Validation loss: 2.694840431213379

Epoch: 5| Step: 8
Training loss: 2.997361660003662
Validation loss: 2.697352350399058

Epoch: 5| Step: 9
Training loss: 2.8693950176239014
Validation loss: 2.694243343927527

Epoch: 5| Step: 10
Training loss: 3.3364956378936768
Validation loss: 2.695028479381274

Epoch: 57| Step: 0
Training loss: 2.6331632137298584
Validation loss: 2.6968028699198077

Epoch: 5| Step: 1
Training loss: 2.985436201095581
Validation loss: 2.697706481461884

Epoch: 5| Step: 2
Training loss: 2.8943490982055664
Validation loss: 2.7014730668837026

Epoch: 5| Step: 3
Training loss: 2.7028307914733887
Validation loss: 2.7096077780569754

Epoch: 5| Step: 4
Training loss: 2.7540252208709717
Validation loss: 2.7106619317044496

Epoch: 5| Step: 5
Training loss: 2.1103646755218506
Validation loss: 2.7205843002565446

Epoch: 5| Step: 6
Training loss: 3.2711219787597656
Validation loss: 2.714964505164854

Epoch: 5| Step: 7
Training loss: 2.673668146133423
Validation loss: 2.7040987322407384

Epoch: 5| Step: 8
Training loss: 3.309105634689331
Validation loss: 2.704336622709869

Epoch: 5| Step: 9
Training loss: 2.865427017211914
Validation loss: 2.6951379314545663

Epoch: 5| Step: 10
Training loss: 3.0107500553131104
Validation loss: 2.6951617348578667

Epoch: 58| Step: 0
Training loss: 3.3252997398376465
Validation loss: 2.694027218767392

Epoch: 5| Step: 1
Training loss: 3.2078793048858643
Validation loss: 2.691834380549769

Epoch: 5| Step: 2
Training loss: 2.905954122543335
Validation loss: 2.68997694600013

Epoch: 5| Step: 3
Training loss: 3.256850481033325
Validation loss: 2.687111331570533

Epoch: 5| Step: 4
Training loss: 2.0510647296905518
Validation loss: 2.6863991752747567

Epoch: 5| Step: 5
Training loss: 2.8505825996398926
Validation loss: 2.6838470992221626

Epoch: 5| Step: 6
Training loss: 2.876713991165161
Validation loss: 2.688361032034761

Epoch: 5| Step: 7
Training loss: 2.632844924926758
Validation loss: 2.6850524435761156

Epoch: 5| Step: 8
Training loss: 2.2628326416015625
Validation loss: 2.6870300231441373

Epoch: 5| Step: 9
Training loss: 2.9731452465057373
Validation loss: 2.6847840252742974

Epoch: 5| Step: 10
Training loss: 2.7664942741394043
Validation loss: 2.686813190419187

Epoch: 59| Step: 0
Training loss: 2.6001899242401123
Validation loss: 2.6837988156144337

Epoch: 5| Step: 1
Training loss: 2.6786720752716064
Validation loss: 2.6862787559468257

Epoch: 5| Step: 2
Training loss: 2.291862964630127
Validation loss: 2.686697931699855

Epoch: 5| Step: 3
Training loss: 3.6070163249969482
Validation loss: 2.6827546986200477

Epoch: 5| Step: 4
Training loss: 2.676424503326416
Validation loss: 2.6826404909933768

Epoch: 5| Step: 5
Training loss: 3.046696424484253
Validation loss: 2.6839973029269966

Epoch: 5| Step: 6
Training loss: 3.0788230895996094
Validation loss: 2.683030657870795

Epoch: 5| Step: 7
Training loss: 2.8794071674346924
Validation loss: 2.6879089416996127

Epoch: 5| Step: 8
Training loss: 2.5491514205932617
Validation loss: 2.6867350403980543

Epoch: 5| Step: 9
Training loss: 3.1806015968322754
Validation loss: 2.688148298571187

Epoch: 5| Step: 10
Training loss: 2.392620325088501
Validation loss: 2.686172277696671

Epoch: 60| Step: 0
Training loss: 2.9865336418151855
Validation loss: 2.6891182289328626

Epoch: 5| Step: 1
Training loss: 2.7463715076446533
Validation loss: 2.6875543081632225

Epoch: 5| Step: 2
Training loss: 3.194558620452881
Validation loss: 2.6986566410269788

Epoch: 5| Step: 3
Training loss: 3.932607650756836
Validation loss: 2.6969823606552614

Epoch: 5| Step: 4
Training loss: 2.594508171081543
Validation loss: 2.6977722875533567

Epoch: 5| Step: 5
Training loss: 2.9494712352752686
Validation loss: 2.6932482873239825

Epoch: 5| Step: 6
Training loss: 3.1713383197784424
Validation loss: 2.6925451627341648

Epoch: 5| Step: 7
Training loss: 2.3374361991882324
Validation loss: 2.6911363447866132

Epoch: 5| Step: 8
Training loss: 2.2968454360961914
Validation loss: 2.685328622018137

Epoch: 5| Step: 9
Training loss: 2.498605251312256
Validation loss: 2.690498285396125

Epoch: 5| Step: 10
Training loss: 2.2223198413848877
Validation loss: 2.6826423778328845

Epoch: 61| Step: 0
Training loss: 2.4588663578033447
Validation loss: 2.684210213281775

Epoch: 5| Step: 1
Training loss: 2.634695529937744
Validation loss: 2.6818362102713635

Epoch: 5| Step: 2
Training loss: 2.942405939102173
Validation loss: 2.681671496360533

Epoch: 5| Step: 3
Training loss: 2.971709728240967
Validation loss: 2.682487569829469

Epoch: 5| Step: 4
Training loss: 2.0736093521118164
Validation loss: 2.6859313211133404

Epoch: 5| Step: 5
Training loss: 2.773707866668701
Validation loss: 2.690109524675595

Epoch: 5| Step: 6
Training loss: 3.257359266281128
Validation loss: 2.6900050255560104

Epoch: 5| Step: 7
Training loss: 2.932832956314087
Validation loss: 2.685458078179308

Epoch: 5| Step: 8
Training loss: 2.3727569580078125
Validation loss: 2.6902792402493056

Epoch: 5| Step: 9
Training loss: 2.682023286819458
Validation loss: 2.685134175003216

Epoch: 5| Step: 10
Training loss: 4.021759510040283
Validation loss: 2.6881823488461074

Epoch: 62| Step: 0
Training loss: 2.589287757873535
Validation loss: 2.6874790037831953

Epoch: 5| Step: 1
Training loss: 3.912052869796753
Validation loss: 2.6894607825945784

Epoch: 5| Step: 2
Training loss: 2.1470823287963867
Validation loss: 2.68718397232794

Epoch: 5| Step: 3
Training loss: 2.7630538940429688
Validation loss: 2.687950103513656

Epoch: 5| Step: 4
Training loss: 2.945566177368164
Validation loss: 2.6845740707971717

Epoch: 5| Step: 5
Training loss: 2.6333446502685547
Validation loss: 2.684716760471303

Epoch: 5| Step: 6
Training loss: 2.7270431518554688
Validation loss: 2.6848059879836215

Epoch: 5| Step: 7
Training loss: 3.2488503456115723
Validation loss: 2.679014931442917

Epoch: 5| Step: 8
Training loss: 2.9096686840057373
Validation loss: 2.678086983260288

Epoch: 5| Step: 9
Training loss: 2.4616446495056152
Validation loss: 2.679689996985979

Epoch: 5| Step: 10
Training loss: 2.600597620010376
Validation loss: 2.6889387612701743

Epoch: 63| Step: 0
Training loss: 3.1656811237335205
Validation loss: 2.6769931290739324

Epoch: 5| Step: 1
Training loss: 2.8410961627960205
Validation loss: 2.6689069706906556

Epoch: 5| Step: 2
Training loss: 2.8937976360321045
Validation loss: 2.6692145639850247

Epoch: 5| Step: 3
Training loss: 2.4642763137817383
Validation loss: 2.670400547724898

Epoch: 5| Step: 4
Training loss: 2.7272984981536865
Validation loss: 2.6709272476934616

Epoch: 5| Step: 5
Training loss: 2.8048393726348877
Validation loss: 2.6684163770368023

Epoch: 5| Step: 6
Training loss: 2.7636804580688477
Validation loss: 2.6748558167488343

Epoch: 5| Step: 7
Training loss: 2.7405238151550293
Validation loss: 2.668546120325724

Epoch: 5| Step: 8
Training loss: 2.73307204246521
Validation loss: 2.663807253683767

Epoch: 5| Step: 9
Training loss: 3.2547848224639893
Validation loss: 2.6692910643034082

Epoch: 5| Step: 10
Training loss: 2.4245569705963135
Validation loss: 2.6652151025751585

Epoch: 64| Step: 0
Training loss: 2.0678977966308594
Validation loss: 2.666145819489674

Epoch: 5| Step: 1
Training loss: 2.703911304473877
Validation loss: 2.6637159291134087

Epoch: 5| Step: 2
Training loss: 2.7097177505493164
Validation loss: 2.662031550561228

Epoch: 5| Step: 3
Training loss: 2.391453504562378
Validation loss: 2.6612839673155095

Epoch: 5| Step: 4
Training loss: 3.0825459957122803
Validation loss: 2.6643424726301626

Epoch: 5| Step: 5
Training loss: 2.7565152645111084
Validation loss: 2.664795091075282

Epoch: 5| Step: 6
Training loss: 3.1052303314208984
Validation loss: 2.663236789805915

Epoch: 5| Step: 7
Training loss: 3.0023162364959717
Validation loss: 2.6683565775553384

Epoch: 5| Step: 8
Training loss: 3.037755250930786
Validation loss: 2.6706245227526595

Epoch: 5| Step: 9
Training loss: 2.9821629524230957
Validation loss: 2.6728583100021526

Epoch: 5| Step: 10
Training loss: 3.070794105529785
Validation loss: 2.671084460391793

Epoch: 65| Step: 0
Training loss: 2.4484646320343018
Validation loss: 2.667792417669809

Epoch: 5| Step: 1
Training loss: 2.6152946949005127
Validation loss: 2.662630699014151

Epoch: 5| Step: 2
Training loss: 2.770301580429077
Validation loss: 2.661215005382415

Epoch: 5| Step: 3
Training loss: 2.8703856468200684
Validation loss: 2.6642050768739436

Epoch: 5| Step: 4
Training loss: 2.776047468185425
Validation loss: 2.6622672542448966

Epoch: 5| Step: 5
Training loss: 3.532064437866211
Validation loss: 2.655313702039821

Epoch: 5| Step: 6
Training loss: 3.261814594268799
Validation loss: 2.656052925253427

Epoch: 5| Step: 7
Training loss: 3.062871217727661
Validation loss: 2.6582527417008595

Epoch: 5| Step: 8
Training loss: 2.0386977195739746
Validation loss: 2.6574043766144784

Epoch: 5| Step: 9
Training loss: 2.109468936920166
Validation loss: 2.6570530424835863

Epoch: 5| Step: 10
Training loss: 3.3888747692108154
Validation loss: 2.660458121248471

Epoch: 66| Step: 0
Training loss: 2.8464818000793457
Validation loss: 2.659916772637316

Epoch: 5| Step: 1
Training loss: 3.5668532848358154
Validation loss: 2.6623592940709924

Epoch: 5| Step: 2
Training loss: 2.599102020263672
Validation loss: 2.6750370866508892

Epoch: 5| Step: 3
Training loss: 3.4153199195861816
Validation loss: 2.6878108055360856

Epoch: 5| Step: 4
Training loss: 2.5619966983795166
Validation loss: 2.689948256297778

Epoch: 5| Step: 5
Training loss: 2.5195472240448
Validation loss: 2.681376039340932

Epoch: 5| Step: 6
Training loss: 2.506124973297119
Validation loss: 2.6733210907187512

Epoch: 5| Step: 7
Training loss: 2.267455577850342
Validation loss: 2.6647857876234156

Epoch: 5| Step: 8
Training loss: 3.1763129234313965
Validation loss: 2.6631571528732136

Epoch: 5| Step: 9
Training loss: 2.5680437088012695
Validation loss: 2.6618887147595807

Epoch: 5| Step: 10
Training loss: 2.772390365600586
Validation loss: 2.6641325873713337

Epoch: 67| Step: 0
Training loss: 3.1497604846954346
Validation loss: 2.6613322406686764

Epoch: 5| Step: 1
Training loss: 1.7230628728866577
Validation loss: 2.6547643779426493

Epoch: 5| Step: 2
Training loss: 2.945873737335205
Validation loss: 2.6556519718580347

Epoch: 5| Step: 3
Training loss: 3.0571460723876953
Validation loss: 2.653884982550016

Epoch: 5| Step: 4
Training loss: 3.1519579887390137
Validation loss: 2.658855394650531

Epoch: 5| Step: 5
Training loss: 2.8413586616516113
Validation loss: 2.6504694364404164

Epoch: 5| Step: 6
Training loss: 2.5690503120422363
Validation loss: 2.6535358582773516

Epoch: 5| Step: 7
Training loss: 2.027143955230713
Validation loss: 2.657252860325639

Epoch: 5| Step: 8
Training loss: 3.228153705596924
Validation loss: 2.661528318159042

Epoch: 5| Step: 9
Training loss: 2.3861804008483887
Validation loss: 2.663302618970153

Epoch: 5| Step: 10
Training loss: 3.9020862579345703
Validation loss: 2.664402259293423

Epoch: 68| Step: 0
Training loss: 2.834979772567749
Validation loss: 2.6666446885754986

Epoch: 5| Step: 1
Training loss: 2.8905153274536133
Validation loss: 2.6783416066118466

Epoch: 5| Step: 2
Training loss: 2.9019081592559814
Validation loss: 2.675365468507172

Epoch: 5| Step: 3
Training loss: 2.273336410522461
Validation loss: 2.6884396114657

Epoch: 5| Step: 4
Training loss: 2.997480630874634
Validation loss: 2.6986765118055445

Epoch: 5| Step: 5
Training loss: 2.834300994873047
Validation loss: 2.680767087526219

Epoch: 5| Step: 6
Training loss: 3.279726028442383
Validation loss: 2.6650423055054038

Epoch: 5| Step: 7
Training loss: 2.2997756004333496
Validation loss: 2.6600737904989593

Epoch: 5| Step: 8
Training loss: 2.5168089866638184
Validation loss: 2.6514768779918714

Epoch: 5| Step: 9
Training loss: 3.178144931793213
Validation loss: 2.6479081748634257

Epoch: 5| Step: 10
Training loss: 2.9126574993133545
Validation loss: 2.6528760130687425

Epoch: 69| Step: 0
Training loss: 2.636127233505249
Validation loss: 2.6504645578322874

Epoch: 5| Step: 1
Training loss: 2.8893637657165527
Validation loss: 2.6571715442083215

Epoch: 5| Step: 2
Training loss: 2.4747233390808105
Validation loss: 2.65735956417617

Epoch: 5| Step: 3
Training loss: 3.1234116554260254
Validation loss: 2.6589176475360827

Epoch: 5| Step: 4
Training loss: 2.616396903991699
Validation loss: 2.6538397342927995

Epoch: 5| Step: 5
Training loss: 2.605559825897217
Validation loss: 2.6530785227334626

Epoch: 5| Step: 6
Training loss: 3.323129653930664
Validation loss: 2.651268764208722

Epoch: 5| Step: 7
Training loss: 3.057574987411499
Validation loss: 2.6511436021456154

Epoch: 5| Step: 8
Training loss: 2.171774387359619
Validation loss: 2.649040778477987

Epoch: 5| Step: 9
Training loss: 2.4727423191070557
Validation loss: 2.649361606567137

Epoch: 5| Step: 10
Training loss: 3.560025930404663
Validation loss: 2.652668071049516

Epoch: 70| Step: 0
Training loss: 3.0961036682128906
Validation loss: 2.6469536494183283

Epoch: 5| Step: 1
Training loss: 2.65075945854187
Validation loss: 2.6535474997694775

Epoch: 5| Step: 2
Training loss: 2.1804230213165283
Validation loss: 2.6520519282228205

Epoch: 5| Step: 3
Training loss: 2.294384002685547
Validation loss: 2.6575840365502144

Epoch: 5| Step: 4
Training loss: 3.007631540298462
Validation loss: 2.654194765193488

Epoch: 5| Step: 5
Training loss: 3.0642714500427246
Validation loss: 2.659073693777925

Epoch: 5| Step: 6
Training loss: 2.4291796684265137
Validation loss: 2.649387167346093

Epoch: 5| Step: 7
Training loss: 3.116985321044922
Validation loss: 2.64436916125718

Epoch: 5| Step: 8
Training loss: 2.7152328491210938
Validation loss: 2.64679285787767

Epoch: 5| Step: 9
Training loss: 3.027254581451416
Validation loss: 2.6511755194715274

Epoch: 5| Step: 10
Training loss: 3.1328461170196533
Validation loss: 2.642554247251121

Epoch: 71| Step: 0
Training loss: 3.519643783569336
Validation loss: 2.643791870404315

Epoch: 5| Step: 1
Training loss: 2.066984176635742
Validation loss: 2.642515169676914

Epoch: 5| Step: 2
Training loss: 3.3826708793640137
Validation loss: 2.6416123144088255

Epoch: 5| Step: 3
Training loss: 1.7800241708755493
Validation loss: 2.6431751687039613

Epoch: 5| Step: 4
Training loss: 2.693664312362671
Validation loss: 2.644106916202012

Epoch: 5| Step: 5
Training loss: 2.997006893157959
Validation loss: 2.642537022149691

Epoch: 5| Step: 6
Training loss: 1.9827686548233032
Validation loss: 2.6423219532094975

Epoch: 5| Step: 7
Training loss: 3.077073574066162
Validation loss: 2.63879733444542

Epoch: 5| Step: 8
Training loss: 2.763624906539917
Validation loss: 2.6400016533431185

Epoch: 5| Step: 9
Training loss: 2.9583206176757812
Validation loss: 2.637443647589735

Epoch: 5| Step: 10
Training loss: 3.515531539916992
Validation loss: 2.6389158900066088

Epoch: 72| Step: 0
Training loss: 2.508244276046753
Validation loss: 2.6452713909969536

Epoch: 5| Step: 1
Training loss: 3.317836284637451
Validation loss: 2.644199578992782

Epoch: 5| Step: 2
Training loss: 2.2765979766845703
Validation loss: 2.648055499599826

Epoch: 5| Step: 3
Training loss: 2.6185238361358643
Validation loss: 2.642297537096085

Epoch: 5| Step: 4
Training loss: 2.358499050140381
Validation loss: 2.6412901314355994

Epoch: 5| Step: 5
Training loss: 3.3968958854675293
Validation loss: 2.634292787121188

Epoch: 5| Step: 6
Training loss: 3.1300952434539795
Validation loss: 2.6327747580825642

Epoch: 5| Step: 7
Training loss: 2.448099136352539
Validation loss: 2.632840828229022

Epoch: 5| Step: 8
Training loss: 2.668509006500244
Validation loss: 2.6315890999250513

Epoch: 5| Step: 9
Training loss: 3.074763059616089
Validation loss: 2.6330716635591243

Epoch: 5| Step: 10
Training loss: 2.853821039199829
Validation loss: 2.6345264398923485

Epoch: 73| Step: 0
Training loss: 3.308863401412964
Validation loss: 2.6357065041859946

Epoch: 5| Step: 1
Training loss: 2.487976551055908
Validation loss: 2.6361464915737027

Epoch: 5| Step: 2
Training loss: 2.5309975147247314
Validation loss: 2.632782554113737

Epoch: 5| Step: 3
Training loss: 3.1978259086608887
Validation loss: 2.634958385139383

Epoch: 5| Step: 4
Training loss: 3.2569973468780518
Validation loss: 2.6314798657612135

Epoch: 5| Step: 5
Training loss: 2.2857260704040527
Validation loss: 2.6326758169358775

Epoch: 5| Step: 6
Training loss: 2.4698634147644043
Validation loss: 2.632962234558598

Epoch: 5| Step: 7
Training loss: 2.784625291824341
Validation loss: 2.6314647236177997

Epoch: 5| Step: 8
Training loss: 2.6805169582366943
Validation loss: 2.627665078768166

Epoch: 5| Step: 9
Training loss: 3.1186022758483887
Validation loss: 2.628968036302956

Epoch: 5| Step: 10
Training loss: 2.366070508956909
Validation loss: 2.630763861440843

Epoch: 74| Step: 0
Training loss: 2.500465154647827
Validation loss: 2.6313771637537147

Epoch: 5| Step: 1
Training loss: 2.516751766204834
Validation loss: 2.637855855367517

Epoch: 5| Step: 2
Training loss: 2.256124973297119
Validation loss: 2.636278703648557

Epoch: 5| Step: 3
Training loss: 2.7150866985321045
Validation loss: 2.6454515149516444

Epoch: 5| Step: 4
Training loss: 2.9830403327941895
Validation loss: 2.6484673330860753

Epoch: 5| Step: 5
Training loss: 2.898484706878662
Validation loss: 2.6482766802592943

Epoch: 5| Step: 6
Training loss: 2.884906768798828
Validation loss: 2.6504728845370713

Epoch: 5| Step: 7
Training loss: 3.0210118293762207
Validation loss: 2.639464229665777

Epoch: 5| Step: 8
Training loss: 3.598829746246338
Validation loss: 2.632495816035937

Epoch: 5| Step: 9
Training loss: 2.7758877277374268
Validation loss: 2.6271279217094503

Epoch: 5| Step: 10
Training loss: 2.3541839122772217
Validation loss: 2.6249244802741596

Epoch: 75| Step: 0
Training loss: 3.054572820663452
Validation loss: 2.628773594415316

Epoch: 5| Step: 1
Training loss: 2.3320133686065674
Validation loss: 2.625387191772461

Epoch: 5| Step: 2
Training loss: 3.005646228790283
Validation loss: 2.6279283005704164

Epoch: 5| Step: 3
Training loss: 2.975548267364502
Validation loss: 2.6304158574791363

Epoch: 5| Step: 4
Training loss: 2.6461172103881836
Validation loss: 2.624456631240024

Epoch: 5| Step: 5
Training loss: 3.050933361053467
Validation loss: 2.619947459108086

Epoch: 5| Step: 6
Training loss: 2.1576385498046875
Validation loss: 2.6199693090172222

Epoch: 5| Step: 7
Training loss: 3.173436403274536
Validation loss: 2.619886536752024

Epoch: 5| Step: 8
Training loss: 3.668689727783203
Validation loss: 2.6183041116242767

Epoch: 5| Step: 9
Training loss: 2.0418450832366943
Validation loss: 2.62337556962044

Epoch: 5| Step: 10
Training loss: 2.383617401123047
Validation loss: 2.6261044676585863

Epoch: 76| Step: 0
Training loss: 2.6330502033233643
Validation loss: 2.6310146598405737

Epoch: 5| Step: 1
Training loss: 2.693682909011841
Validation loss: 2.6346872827058196

Epoch: 5| Step: 2
Training loss: 3.369361400604248
Validation loss: 2.6300607112146195

Epoch: 5| Step: 3
Training loss: 3.321701765060425
Validation loss: 2.6218709638041835

Epoch: 5| Step: 4
Training loss: 2.417858600616455
Validation loss: 2.625149752504082

Epoch: 5| Step: 5
Training loss: 2.08200740814209
Validation loss: 2.625322928992651

Epoch: 5| Step: 6
Training loss: 2.0933849811553955
Validation loss: 2.6181498650581605

Epoch: 5| Step: 7
Training loss: 2.953625202178955
Validation loss: 2.6225343750369166

Epoch: 5| Step: 8
Training loss: 3.4845175743103027
Validation loss: 2.627604471739902

Epoch: 5| Step: 9
Training loss: 2.901479721069336
Validation loss: 2.6215583739742154

Epoch: 5| Step: 10
Training loss: 2.472597122192383
Validation loss: 2.622998606774115

Epoch: 77| Step: 0
Training loss: 2.1842257976531982
Validation loss: 2.6192796281588975

Epoch: 5| Step: 1
Training loss: 1.8734095096588135
Validation loss: 2.6224527025735505

Epoch: 5| Step: 2
Training loss: 2.6212430000305176
Validation loss: 2.6207858644505984

Epoch: 5| Step: 3
Training loss: 3.013334274291992
Validation loss: 2.623307699798256

Epoch: 5| Step: 4
Training loss: 3.1999213695526123
Validation loss: 2.62825152438174

Epoch: 5| Step: 5
Training loss: 3.4463210105895996
Validation loss: 2.638786531263782

Epoch: 5| Step: 6
Training loss: 3.3291678428649902
Validation loss: 2.630963465218903

Epoch: 5| Step: 7
Training loss: 2.473950147628784
Validation loss: 2.6288928626686014

Epoch: 5| Step: 8
Training loss: 1.7857029438018799
Validation loss: 2.6243839289552424

Epoch: 5| Step: 9
Training loss: 3.031527042388916
Validation loss: 2.6194476953116794

Epoch: 5| Step: 10
Training loss: 3.6453797817230225
Validation loss: 2.6153697762438046

Epoch: 78| Step: 0
Training loss: 1.7813609838485718
Validation loss: 2.614149280773696

Epoch: 5| Step: 1
Training loss: 2.514436721801758
Validation loss: 2.6125795713035007

Epoch: 5| Step: 2
Training loss: 3.7716064453125
Validation loss: 2.6108469655436854

Epoch: 5| Step: 3
Training loss: 3.0853371620178223
Validation loss: 2.609900736039685

Epoch: 5| Step: 4
Training loss: 3.429016590118408
Validation loss: 2.6108607374211794

Epoch: 5| Step: 5
Training loss: 2.669771194458008
Validation loss: 2.6103076575904764

Epoch: 5| Step: 6
Training loss: 1.9614760875701904
Validation loss: 2.6099390983581543

Epoch: 5| Step: 7
Training loss: 2.570939779281616
Validation loss: 2.6067205295767835

Epoch: 5| Step: 8
Training loss: 3.01682710647583
Validation loss: 2.6075212801656416

Epoch: 5| Step: 9
Training loss: 2.358166456222534
Validation loss: 2.606813253894929

Epoch: 5| Step: 10
Training loss: 3.4154748916625977
Validation loss: 2.6085574216740106

Epoch: 79| Step: 0
Training loss: 3.142211437225342
Validation loss: 2.614066393144669

Epoch: 5| Step: 1
Training loss: 2.735384464263916
Validation loss: 2.609564809389012

Epoch: 5| Step: 2
Training loss: 2.7535414695739746
Validation loss: 2.6087681631888113

Epoch: 5| Step: 3
Training loss: 2.455094337463379
Validation loss: 2.6105964260716594

Epoch: 5| Step: 4
Training loss: 3.1520702838897705
Validation loss: 2.61346600901696

Epoch: 5| Step: 5
Training loss: 2.563483476638794
Validation loss: 2.61348404166519

Epoch: 5| Step: 6
Training loss: 2.5389797687530518
Validation loss: 2.6248573385259157

Epoch: 5| Step: 7
Training loss: 2.7440757751464844
Validation loss: 2.6260673743422314

Epoch: 5| Step: 8
Training loss: 3.166727066040039
Validation loss: 2.622960323928505

Epoch: 5| Step: 9
Training loss: 2.262150526046753
Validation loss: 2.621809164683024

Epoch: 5| Step: 10
Training loss: 2.9536139965057373
Validation loss: 2.611919895295174

Epoch: 80| Step: 0
Training loss: 2.502734661102295
Validation loss: 2.6128020671106156

Epoch: 5| Step: 1
Training loss: 2.4417896270751953
Validation loss: 2.6077775801381757

Epoch: 5| Step: 2
Training loss: 2.379922389984131
Validation loss: 2.6006760033228065

Epoch: 5| Step: 3
Training loss: 3.1998801231384277
Validation loss: 2.5983930787732525

Epoch: 5| Step: 4
Training loss: 2.454464912414551
Validation loss: 2.5988253624208513

Epoch: 5| Step: 5
Training loss: 3.3704395294189453
Validation loss: 2.602391319890176

Epoch: 5| Step: 6
Training loss: 2.7811808586120605
Validation loss: 2.604497899291336

Epoch: 5| Step: 7
Training loss: 2.497249126434326
Validation loss: 2.6000883451072117

Epoch: 5| Step: 8
Training loss: 3.6599597930908203
Validation loss: 2.6007363770597722

Epoch: 5| Step: 9
Training loss: 2.4812893867492676
Validation loss: 2.596440884374803

Epoch: 5| Step: 10
Training loss: 2.537627696990967
Validation loss: 2.594238934978362

Epoch: 81| Step: 0
Training loss: 2.7756805419921875
Validation loss: 2.594841105963594

Epoch: 5| Step: 1
Training loss: 2.8669352531433105
Validation loss: 2.590239163367979

Epoch: 5| Step: 2
Training loss: 2.41397762298584
Validation loss: 2.5910220094906387

Epoch: 5| Step: 3
Training loss: 2.8075969219207764
Validation loss: 2.583862502087829

Epoch: 5| Step: 4
Training loss: 2.611619234085083
Validation loss: 2.5848674543442263

Epoch: 5| Step: 5
Training loss: 2.8405814170837402
Validation loss: 2.577209682874782

Epoch: 5| Step: 6
Training loss: 2.461984634399414
Validation loss: 2.581119147680139

Epoch: 5| Step: 7
Training loss: 3.2337470054626465
Validation loss: 2.584265391031901

Epoch: 5| Step: 8
Training loss: 2.2383646965026855
Validation loss: 2.5911017335871214

Epoch: 5| Step: 9
Training loss: 2.7033138275146484
Validation loss: 2.571746398043889

Epoch: 5| Step: 10
Training loss: 3.3874545097351074
Validation loss: 2.561587884861936

Epoch: 82| Step: 0
Training loss: 2.906986951828003
Validation loss: 2.565807875766549

Epoch: 5| Step: 1
Training loss: 2.456529140472412
Validation loss: 2.568780176101192

Epoch: 5| Step: 2
Training loss: 3.0953524112701416
Validation loss: 2.5708710044942875

Epoch: 5| Step: 3
Training loss: 2.506509304046631
Validation loss: 2.5697546697431997

Epoch: 5| Step: 4
Training loss: 3.386496067047119
Validation loss: 2.569157100492908

Epoch: 5| Step: 5
Training loss: 2.738950729370117
Validation loss: 2.5691049611696632

Epoch: 5| Step: 6
Training loss: 3.0400614738464355
Validation loss: 2.5694656013160624

Epoch: 5| Step: 7
Training loss: 2.413456439971924
Validation loss: 2.5673245101846676

Epoch: 5| Step: 8
Training loss: 2.543384552001953
Validation loss: 2.5645150343577066

Epoch: 5| Step: 9
Training loss: 2.6716060638427734
Validation loss: 2.5596287199245986

Epoch: 5| Step: 10
Training loss: 2.3389530181884766
Validation loss: 2.5596331255410307

Epoch: 83| Step: 0
Training loss: 2.9675633907318115
Validation loss: 2.561610601281607

Epoch: 5| Step: 1
Training loss: 2.86454701423645
Validation loss: 2.561517471908241

Epoch: 5| Step: 2
Training loss: 2.373044967651367
Validation loss: 2.5615988290438088

Epoch: 5| Step: 3
Training loss: 2.519382953643799
Validation loss: 2.5634160246900333

Epoch: 5| Step: 4
Training loss: 3.2614784240722656
Validation loss: 2.5630772652164584

Epoch: 5| Step: 5
Training loss: 2.2896716594696045
Validation loss: 2.5585401186379055

Epoch: 5| Step: 6
Training loss: 2.291255474090576
Validation loss: 2.563382843489288

Epoch: 5| Step: 7
Training loss: 3.318385362625122
Validation loss: 2.561344820966003

Epoch: 5| Step: 8
Training loss: 2.371457576751709
Validation loss: 2.5597320474604124

Epoch: 5| Step: 9
Training loss: 2.741105318069458
Validation loss: 2.559326571802939

Epoch: 5| Step: 10
Training loss: 3.080838680267334
Validation loss: 2.5633638161484913

Epoch: 84| Step: 0
Training loss: 2.6706039905548096
Validation loss: 2.5645333977155786

Epoch: 5| Step: 1
Training loss: 2.585261821746826
Validation loss: 2.55943908486315

Epoch: 5| Step: 2
Training loss: 2.7663421630859375
Validation loss: 2.5632007686040734

Epoch: 5| Step: 3
Training loss: 2.7611305713653564
Validation loss: 2.565664396491102

Epoch: 5| Step: 4
Training loss: 2.1014633178710938
Validation loss: 2.570374675976333

Epoch: 5| Step: 5
Training loss: 3.833747386932373
Validation loss: 2.563594297696185

Epoch: 5| Step: 6
Training loss: 2.750368595123291
Validation loss: 2.5620343608240925

Epoch: 5| Step: 7
Training loss: 2.4607667922973633
Validation loss: 2.5643064501465007

Epoch: 5| Step: 8
Training loss: 2.4374656677246094
Validation loss: 2.5616908919426704

Epoch: 5| Step: 9
Training loss: 2.769770860671997
Validation loss: 2.55484866070491

Epoch: 5| Step: 10
Training loss: 2.830986976623535
Validation loss: 2.554048340807679

Epoch: 85| Step: 0
Training loss: 3.0567069053649902
Validation loss: 2.5490063672424643

Epoch: 5| Step: 1
Training loss: 2.1227028369903564
Validation loss: 2.5502732030807005

Epoch: 5| Step: 2
Training loss: 3.229597806930542
Validation loss: 2.546787497817829

Epoch: 5| Step: 3
Training loss: 3.4656589031219482
Validation loss: 2.5501247144514516

Epoch: 5| Step: 4
Training loss: 2.7496871948242188
Validation loss: 2.5480207499637397

Epoch: 5| Step: 5
Training loss: 2.7532570362091064
Validation loss: 2.556440145738663

Epoch: 5| Step: 6
Training loss: 1.8930412530899048
Validation loss: 2.5703206549408617

Epoch: 5| Step: 7
Training loss: 2.5350043773651123
Validation loss: 2.5774544721008628

Epoch: 5| Step: 8
Training loss: 3.051476001739502
Validation loss: 2.6083638950060775

Epoch: 5| Step: 9
Training loss: 2.6947474479675293
Validation loss: 2.629143427777034

Epoch: 5| Step: 10
Training loss: 2.4680662155151367
Validation loss: 2.6341818224999214

Epoch: 86| Step: 0
Training loss: 2.2946431636810303
Validation loss: 2.635030161949896

Epoch: 5| Step: 1
Training loss: 2.6221041679382324
Validation loss: 2.6304845425390426

Epoch: 5| Step: 2
Training loss: 3.1149849891662598
Validation loss: 2.6164578827478553

Epoch: 5| Step: 3
Training loss: 3.1825244426727295
Validation loss: 2.608412814396684

Epoch: 5| Step: 4
Training loss: 3.196293592453003
Validation loss: 2.6046996116638184

Epoch: 5| Step: 5
Training loss: 2.9320192337036133
Validation loss: 2.598789107414984

Epoch: 5| Step: 6
Training loss: 2.9953627586364746
Validation loss: 2.587453742181101

Epoch: 5| Step: 7
Training loss: 3.0491340160369873
Validation loss: 2.5677382561468307

Epoch: 5| Step: 8
Training loss: 3.161652088165283
Validation loss: 2.560502206125567

Epoch: 5| Step: 9
Training loss: 1.877078652381897
Validation loss: 2.5805112059398363

Epoch: 5| Step: 10
Training loss: 1.769540548324585
Validation loss: 2.590721575162744

Epoch: 87| Step: 0
Training loss: 2.7063400745391846
Validation loss: 2.5952055838800248

Epoch: 5| Step: 1
Training loss: 2.7795016765594482
Validation loss: 2.5843655857988583

Epoch: 5| Step: 2
Training loss: 2.5800440311431885
Validation loss: 2.549528952567808

Epoch: 5| Step: 3
Training loss: 2.9590606689453125
Validation loss: 2.552260378355621

Epoch: 5| Step: 4
Training loss: 3.353578567504883
Validation loss: 2.5476631708042596

Epoch: 5| Step: 5
Training loss: 2.2199795246124268
Validation loss: 2.5503684115666214

Epoch: 5| Step: 6
Training loss: 2.663755178451538
Validation loss: 2.557896085964736

Epoch: 5| Step: 7
Training loss: 2.5520248413085938
Validation loss: 2.554711106002972

Epoch: 5| Step: 8
Training loss: 2.0327751636505127
Validation loss: 2.561344503074564

Epoch: 5| Step: 9
Training loss: 3.286686658859253
Validation loss: 2.5601329239465858

Epoch: 5| Step: 10
Training loss: 2.90993332862854
Validation loss: 2.551300289810345

Epoch: 88| Step: 0
Training loss: 3.4931483268737793
Validation loss: 2.5450646056923816

Epoch: 5| Step: 1
Training loss: 2.900097370147705
Validation loss: 2.5419200158888295

Epoch: 5| Step: 2
Training loss: 1.8052726984024048
Validation loss: 2.5349548068097842

Epoch: 5| Step: 3
Training loss: 2.7698631286621094
Validation loss: 2.53757559099505

Epoch: 5| Step: 4
Training loss: 2.7249088287353516
Validation loss: 2.537874544820478

Epoch: 5| Step: 5
Training loss: 3.3582770824432373
Validation loss: 2.54155723766614

Epoch: 5| Step: 6
Training loss: 2.4245619773864746
Validation loss: 2.539245295268233

Epoch: 5| Step: 7
Training loss: 3.0442302227020264
Validation loss: 2.5415969074413343

Epoch: 5| Step: 8
Training loss: 2.6892857551574707
Validation loss: 2.5323778813885105

Epoch: 5| Step: 9
Training loss: 2.03627347946167
Validation loss: 2.5349817199091755

Epoch: 5| Step: 10
Training loss: 2.5534305572509766
Validation loss: 2.5340713326649

Epoch: 89| Step: 0
Training loss: 3.2174460887908936
Validation loss: 2.54071258729504

Epoch: 5| Step: 1
Training loss: 2.784177780151367
Validation loss: 2.539588843622515

Epoch: 5| Step: 2
Training loss: 2.4575493335723877
Validation loss: 2.5411225493236254

Epoch: 5| Step: 3
Training loss: 2.386841297149658
Validation loss: 2.5347156140112106

Epoch: 5| Step: 4
Training loss: 3.339700222015381
Validation loss: 2.5354999316635953

Epoch: 5| Step: 5
Training loss: 2.4813780784606934
Validation loss: 2.538237282024917

Epoch: 5| Step: 6
Training loss: 3.0124449729919434
Validation loss: 2.5366938780712824

Epoch: 5| Step: 7
Training loss: 2.2677435874938965
Validation loss: 2.537623811793584

Epoch: 5| Step: 8
Training loss: 1.9317395687103271
Validation loss: 2.5369300791012344

Epoch: 5| Step: 9
Training loss: 2.639777183532715
Validation loss: 2.5361671396481094

Epoch: 5| Step: 10
Training loss: 3.4406681060791016
Validation loss: 2.535012468214958

Epoch: 90| Step: 0
Training loss: 2.0111823081970215
Validation loss: 2.5371642317823184

Epoch: 5| Step: 1
Training loss: 2.4686152935028076
Validation loss: 2.5358877976735434

Epoch: 5| Step: 2
Training loss: 3.129666328430176
Validation loss: 2.5420241791714906

Epoch: 5| Step: 3
Training loss: 2.8024001121520996
Validation loss: 2.549104872570243

Epoch: 5| Step: 4
Training loss: 2.5420241355895996
Validation loss: 2.5464794430681454

Epoch: 5| Step: 5
Training loss: 3.083697557449341
Validation loss: 2.5517334476594002

Epoch: 5| Step: 6
Training loss: 3.213186740875244
Validation loss: 2.5436616636091665

Epoch: 5| Step: 7
Training loss: 2.9369640350341797
Validation loss: 2.535758623512842

Epoch: 5| Step: 8
Training loss: 2.1747121810913086
Validation loss: 2.5271305678993143

Epoch: 5| Step: 9
Training loss: 2.3255748748779297
Validation loss: 2.527525988958215

Epoch: 5| Step: 10
Training loss: 3.185243844985962
Validation loss: 2.5265915752739034

Epoch: 91| Step: 0
Training loss: 2.2450830936431885
Validation loss: 2.5287303309286795

Epoch: 5| Step: 1
Training loss: 2.528738021850586
Validation loss: 2.531782632232994

Epoch: 5| Step: 2
Training loss: 2.905897617340088
Validation loss: 2.533255092559322

Epoch: 5| Step: 3
Training loss: 2.696958065032959
Validation loss: 2.534663164487449

Epoch: 5| Step: 4
Training loss: 2.877246856689453
Validation loss: 2.532363740346765

Epoch: 5| Step: 5
Training loss: 2.8078694343566895
Validation loss: 2.5314635358830935

Epoch: 5| Step: 6
Training loss: 2.753279447555542
Validation loss: 2.527309081887686

Epoch: 5| Step: 7
Training loss: 2.9553604125976562
Validation loss: 2.5259714895679104

Epoch: 5| Step: 8
Training loss: 2.1047377586364746
Validation loss: 2.527907907321889

Epoch: 5| Step: 9
Training loss: 2.3953750133514404
Validation loss: 2.535514021432528

Epoch: 5| Step: 10
Training loss: 3.745305061340332
Validation loss: 2.530107023895428

Epoch: 92| Step: 0
Training loss: 2.7089078426361084
Validation loss: 2.527942870252876

Epoch: 5| Step: 1
Training loss: 2.465467929840088
Validation loss: 2.5254900583656887

Epoch: 5| Step: 2
Training loss: 2.9739127159118652
Validation loss: 2.5247067507877143

Epoch: 5| Step: 3
Training loss: 2.6415257453918457
Validation loss: 2.5192653312478015

Epoch: 5| Step: 4
Training loss: 2.152953624725342
Validation loss: 2.5240545503554808

Epoch: 5| Step: 5
Training loss: 3.0362141132354736
Validation loss: 2.5280035695722027

Epoch: 5| Step: 6
Training loss: 2.6807522773742676
Validation loss: 2.526898809658584

Epoch: 5| Step: 7
Training loss: 2.7225780487060547
Validation loss: 2.5349716371105564

Epoch: 5| Step: 8
Training loss: 3.6258597373962402
Validation loss: 2.5387375354766846

Epoch: 5| Step: 9
Training loss: 2.239386558532715
Validation loss: 2.5394699804244505

Epoch: 5| Step: 10
Training loss: 2.4880833625793457
Validation loss: 2.537773037469515

Epoch: 93| Step: 0
Training loss: 2.2360832691192627
Validation loss: 2.5343937489294235

Epoch: 5| Step: 1
Training loss: 2.7171788215637207
Validation loss: 2.5264193216959634

Epoch: 5| Step: 2
Training loss: 3.0653350353240967
Validation loss: 2.5178657526611

Epoch: 5| Step: 3
Training loss: 2.910496234893799
Validation loss: 2.520052404813869

Epoch: 5| Step: 4
Training loss: 2.7916595935821533
Validation loss: 2.5186461530705935

Epoch: 5| Step: 5
Training loss: 2.678445339202881
Validation loss: 2.5175335894348803

Epoch: 5| Step: 6
Training loss: 2.8623151779174805
Validation loss: 2.519125335959978

Epoch: 5| Step: 7
Training loss: 2.1009294986724854
Validation loss: 2.5185482835256927

Epoch: 5| Step: 8
Training loss: 2.366013526916504
Validation loss: 2.5179256111062984

Epoch: 5| Step: 9
Training loss: 2.916350841522217
Validation loss: 2.520698042326076

Epoch: 5| Step: 10
Training loss: 3.097269058227539
Validation loss: 2.5202033340290027

Epoch: 94| Step: 0
Training loss: 2.378617763519287
Validation loss: 2.5218327865805676

Epoch: 5| Step: 1
Training loss: 2.11710524559021
Validation loss: 2.5171191743625108

Epoch: 5| Step: 2
Training loss: 2.980461597442627
Validation loss: 2.520736822517969

Epoch: 5| Step: 3
Training loss: 2.7687060832977295
Validation loss: 2.5199296859002884

Epoch: 5| Step: 4
Training loss: 2.385815382003784
Validation loss: 2.5221748634051253

Epoch: 5| Step: 5
Training loss: 2.220370292663574
Validation loss: 2.531980212016772

Epoch: 5| Step: 6
Training loss: 3.2247612476348877
Validation loss: 2.534649590010284

Epoch: 5| Step: 7
Training loss: 2.8271336555480957
Validation loss: 2.540239013651366

Epoch: 5| Step: 8
Training loss: 3.1888177394866943
Validation loss: 2.538869716787851

Epoch: 5| Step: 9
Training loss: 3.5526282787323
Validation loss: 2.5417282812057005

Epoch: 5| Step: 10
Training loss: 2.0873565673828125
Validation loss: 2.5253798551456903

Epoch: 95| Step: 0
Training loss: 2.3900723457336426
Validation loss: 2.520839455307171

Epoch: 5| Step: 1
Training loss: 3.689056396484375
Validation loss: 2.5170283907203266

Epoch: 5| Step: 2
Training loss: 2.4223263263702393
Validation loss: 2.51562423347145

Epoch: 5| Step: 3
Training loss: 2.5268688201904297
Validation loss: 2.5176837828851517

Epoch: 5| Step: 4
Training loss: 1.9815394878387451
Validation loss: 2.521280014386741

Epoch: 5| Step: 5
Training loss: 2.67047381401062
Validation loss: 2.5211969473028697

Epoch: 5| Step: 6
Training loss: 2.684724807739258
Validation loss: 2.520903746287028

Epoch: 5| Step: 7
Training loss: 2.579845666885376
Validation loss: 2.5216688084345993

Epoch: 5| Step: 8
Training loss: 2.8136017322540283
Validation loss: 2.5194361440597044

Epoch: 5| Step: 9
Training loss: 2.737652540206909
Validation loss: 2.5212236194200415

Epoch: 5| Step: 10
Training loss: 3.425666093826294
Validation loss: 2.5191261691431843

Epoch: 96| Step: 0
Training loss: 2.553867816925049
Validation loss: 2.5169432599057435

Epoch: 5| Step: 1
Training loss: 2.554877758026123
Validation loss: 2.514478768071821

Epoch: 5| Step: 2
Training loss: 2.3041832447052
Validation loss: 2.514035819679178

Epoch: 5| Step: 3
Training loss: 3.211786985397339
Validation loss: 2.5173568905040784

Epoch: 5| Step: 4
Training loss: 2.8057453632354736
Validation loss: 2.517020369088778

Epoch: 5| Step: 5
Training loss: 3.153703451156616
Validation loss: 2.5221207193149033

Epoch: 5| Step: 6
Training loss: 2.619877576828003
Validation loss: 2.52611179249261

Epoch: 5| Step: 7
Training loss: 3.2099337577819824
Validation loss: 2.531569163004557

Epoch: 5| Step: 8
Training loss: 2.64064884185791
Validation loss: 2.518126949187248

Epoch: 5| Step: 9
Training loss: 2.4782357215881348
Validation loss: 2.518394790669923

Epoch: 5| Step: 10
Training loss: 2.0672521591186523
Validation loss: 2.5119416200986473

Epoch: 97| Step: 0
Training loss: 2.7866597175598145
Validation loss: 2.509732189998832

Epoch: 5| Step: 1
Training loss: 2.7505993843078613
Validation loss: 2.5118600194172194

Epoch: 5| Step: 2
Training loss: 2.478710651397705
Validation loss: 2.5095691693726407

Epoch: 5| Step: 3
Training loss: 3.013129234313965
Validation loss: 2.509279630517447

Epoch: 5| Step: 4
Training loss: 2.6641690731048584
Validation loss: 2.508866789520428

Epoch: 5| Step: 5
Training loss: 2.657763719558716
Validation loss: 2.5085396125752437

Epoch: 5| Step: 6
Training loss: 2.6398606300354004
Validation loss: 2.5085046188805693

Epoch: 5| Step: 7
Training loss: 2.841334104537964
Validation loss: 2.510696909760916

Epoch: 5| Step: 8
Training loss: 2.3470873832702637
Validation loss: 2.5124249560858614

Epoch: 5| Step: 9
Training loss: 2.132617712020874
Validation loss: 2.5089582807274273

Epoch: 5| Step: 10
Training loss: 3.547908067703247
Validation loss: 2.5089888418874433

Epoch: 98| Step: 0
Training loss: 2.522604465484619
Validation loss: 2.50682129398469

Epoch: 5| Step: 1
Training loss: 2.914982318878174
Validation loss: 2.503979247103455

Epoch: 5| Step: 2
Training loss: 2.6005568504333496
Validation loss: 2.507543102387459

Epoch: 5| Step: 3
Training loss: 2.3424274921417236
Validation loss: 2.5177099909833682

Epoch: 5| Step: 4
Training loss: 2.2881596088409424
Validation loss: 2.5284845931555635

Epoch: 5| Step: 5
Training loss: 2.624319076538086
Validation loss: 2.546501644196049

Epoch: 5| Step: 6
Training loss: 3.099560260772705
Validation loss: 2.5445728276365545

Epoch: 5| Step: 7
Training loss: 2.5506515502929688
Validation loss: 2.5464446313919558

Epoch: 5| Step: 8
Training loss: 2.9177603721618652
Validation loss: 2.5338296608258317

Epoch: 5| Step: 9
Training loss: 2.3620283603668213
Validation loss: 2.517556349436442

Epoch: 5| Step: 10
Training loss: 3.599201202392578
Validation loss: 2.518437031776674

Epoch: 99| Step: 0
Training loss: 2.5308589935302734
Validation loss: 2.504325674426171

Epoch: 5| Step: 1
Training loss: 2.8242807388305664
Validation loss: 2.505756888338315

Epoch: 5| Step: 2
Training loss: 3.5781426429748535
Validation loss: 2.5059649200849634

Epoch: 5| Step: 3
Training loss: 2.593384265899658
Validation loss: 2.5055714986657582

Epoch: 5| Step: 4
Training loss: 2.4368338584899902
Validation loss: 2.5063726902008057

Epoch: 5| Step: 5
Training loss: 2.1920738220214844
Validation loss: 2.5045415534768054

Epoch: 5| Step: 6
Training loss: 2.855022668838501
Validation loss: 2.5045374952336794

Epoch: 5| Step: 7
Training loss: 2.3213953971862793
Validation loss: 2.5025673322780158

Epoch: 5| Step: 8
Training loss: 2.1168742179870605
Validation loss: 2.50619008720562

Epoch: 5| Step: 9
Training loss: 3.1896989345550537
Validation loss: 2.5050755162392893

Epoch: 5| Step: 10
Training loss: 3.0542831420898438
Validation loss: 2.5057660610445085

Epoch: 100| Step: 0
Training loss: 2.596836566925049
Validation loss: 2.5086280120316373

Epoch: 5| Step: 1
Training loss: 2.3771886825561523
Validation loss: 2.506424016849969

Epoch: 5| Step: 2
Training loss: 2.9317169189453125
Validation loss: 2.5083376130750104

Epoch: 5| Step: 3
Training loss: 2.2511889934539795
Validation loss: 2.512974998002411

Epoch: 5| Step: 4
Training loss: 2.448071241378784
Validation loss: 2.518684812771377

Epoch: 5| Step: 5
Training loss: 2.3994641304016113
Validation loss: 2.5167347359400924

Epoch: 5| Step: 6
Training loss: 2.8535990715026855
Validation loss: 2.511651392905943

Epoch: 5| Step: 7
Training loss: 3.063122034072876
Validation loss: 2.5026600489052395

Epoch: 5| Step: 8
Training loss: 2.330735445022583
Validation loss: 2.5014315164217384

Epoch: 5| Step: 9
Training loss: 3.955275058746338
Validation loss: 2.5034236754140546

Epoch: 5| Step: 10
Training loss: 2.3895480632781982
Validation loss: 2.5009277072004092

Epoch: 101| Step: 0
Training loss: 3.1017847061157227
Validation loss: 2.5025706188653105

Epoch: 5| Step: 1
Training loss: 2.4139771461486816
Validation loss: 2.5034012179220877

Epoch: 5| Step: 2
Training loss: 2.6337246894836426
Validation loss: 2.5025494278118177

Epoch: 5| Step: 3
Training loss: 2.468203067779541
Validation loss: 2.499062074128018

Epoch: 5| Step: 4
Training loss: 2.555466890335083
Validation loss: 2.502448228097731

Epoch: 5| Step: 5
Training loss: 3.1827213764190674
Validation loss: 2.5000252646784626

Epoch: 5| Step: 6
Training loss: 2.652650833129883
Validation loss: 2.5001775808231805

Epoch: 5| Step: 7
Training loss: 3.041950225830078
Validation loss: 2.4987709752974974

Epoch: 5| Step: 8
Training loss: 2.845942735671997
Validation loss: 2.497400488904727

Epoch: 5| Step: 9
Training loss: 2.188019275665283
Validation loss: 2.4959272876862557

Epoch: 5| Step: 10
Training loss: 2.4740614891052246
Validation loss: 2.5002199757483696

Epoch: 102| Step: 0
Training loss: 2.5287394523620605
Validation loss: 2.507143674358245

Epoch: 5| Step: 1
Training loss: 1.3967652320861816
Validation loss: 2.5117537193400885

Epoch: 5| Step: 2
Training loss: 2.964841604232788
Validation loss: 2.517898900534517

Epoch: 5| Step: 3
Training loss: 3.2838268280029297
Validation loss: 2.5136004852992233

Epoch: 5| Step: 4
Training loss: 2.601139783859253
Validation loss: 2.5157105563789286

Epoch: 5| Step: 5
Training loss: 3.0711121559143066
Validation loss: 2.5067374526813464

Epoch: 5| Step: 6
Training loss: 2.8195786476135254
Validation loss: 2.496956943183817

Epoch: 5| Step: 7
Training loss: 2.592967987060547
Validation loss: 2.4959950959810646

Epoch: 5| Step: 8
Training loss: 2.8822021484375
Validation loss: 2.495480610478309

Epoch: 5| Step: 9
Training loss: 2.6369967460632324
Validation loss: 2.4959960342735372

Epoch: 5| Step: 10
Training loss: 2.7237093448638916
Validation loss: 2.493698598236166

Epoch: 103| Step: 0
Training loss: 2.2487282752990723
Validation loss: 2.496246858309674

Epoch: 5| Step: 1
Training loss: 2.9726779460906982
Validation loss: 2.496310310979043

Epoch: 5| Step: 2
Training loss: 3.039358615875244
Validation loss: 2.492121201689525

Epoch: 5| Step: 3
Training loss: 3.1693031787872314
Validation loss: 2.4955215069555465

Epoch: 5| Step: 4
Training loss: 2.5841763019561768
Validation loss: 2.4984674094825663

Epoch: 5| Step: 5
Training loss: 2.169337749481201
Validation loss: 2.4979947561858804

Epoch: 5| Step: 6
Training loss: 2.081037998199463
Validation loss: 2.501399140204153

Epoch: 5| Step: 7
Training loss: 2.666337728500366
Validation loss: 2.501461198253016

Epoch: 5| Step: 8
Training loss: 2.071798324584961
Validation loss: 2.507637572544877

Epoch: 5| Step: 9
Training loss: 3.439645767211914
Validation loss: 2.495976109658518

Epoch: 5| Step: 10
Training loss: 3.2136588096618652
Validation loss: 2.501528875802153

Epoch: 104| Step: 0
Training loss: 2.908437728881836
Validation loss: 2.492371307906284

Epoch: 5| Step: 1
Training loss: 2.1278140544891357
Validation loss: 2.496092011851649

Epoch: 5| Step: 2
Training loss: 2.9718775749206543
Validation loss: 2.497879615394018

Epoch: 5| Step: 3
Training loss: 2.729081869125366
Validation loss: 2.504442316229625

Epoch: 5| Step: 4
Training loss: 2.6240615844726562
Validation loss: 2.5071630118995585

Epoch: 5| Step: 5
Training loss: 2.377152919769287
Validation loss: 2.500170648738902

Epoch: 5| Step: 6
Training loss: 2.895636558532715
Validation loss: 2.509137486898771

Epoch: 5| Step: 7
Training loss: 2.948694944381714
Validation loss: 2.5025739515981367

Epoch: 5| Step: 8
Training loss: 2.269949436187744
Validation loss: 2.4954817192528838

Epoch: 5| Step: 9
Training loss: 2.603566884994507
Validation loss: 2.4906916156891854

Epoch: 5| Step: 10
Training loss: 3.1421010494232178
Validation loss: 2.4950803531113492

Epoch: 105| Step: 0
Training loss: 3.365868330001831
Validation loss: 2.4919714235490367

Epoch: 5| Step: 1
Training loss: 2.7528038024902344
Validation loss: 2.4898983893855924

Epoch: 5| Step: 2
Training loss: 2.6162948608398438
Validation loss: 2.4877561189795054

Epoch: 5| Step: 3
Training loss: 2.5828394889831543
Validation loss: 2.4844068916895057

Epoch: 5| Step: 4
Training loss: 2.8021368980407715
Validation loss: 2.486047972914993

Epoch: 5| Step: 5
Training loss: 2.799126148223877
Validation loss: 2.4880976574395293

Epoch: 5| Step: 6
Training loss: 2.5105600357055664
Validation loss: 2.481267277912427

Epoch: 5| Step: 7
Training loss: 2.1393043994903564
Validation loss: 2.4920076195911696

Epoch: 5| Step: 8
Training loss: 2.2447738647460938
Validation loss: 2.487997665200182

Epoch: 5| Step: 9
Training loss: 3.005079746246338
Validation loss: 2.4952743643073627

Epoch: 5| Step: 10
Training loss: 2.6294074058532715
Validation loss: 2.5058357049060125

Epoch: 106| Step: 0
Training loss: 2.2863430976867676
Validation loss: 2.503728166703255

Epoch: 5| Step: 1
Training loss: 2.605581760406494
Validation loss: 2.508816788273473

Epoch: 5| Step: 2
Training loss: 2.7530300617218018
Validation loss: 2.510984049048475

Epoch: 5| Step: 3
Training loss: 3.3604347705841064
Validation loss: 2.5133134754755164

Epoch: 5| Step: 4
Training loss: 3.0851950645446777
Validation loss: 2.5102421775940926

Epoch: 5| Step: 5
Training loss: 2.27555513381958
Validation loss: 2.508140135836858

Epoch: 5| Step: 6
Training loss: 3.0041391849517822
Validation loss: 2.4903525793424217

Epoch: 5| Step: 7
Training loss: 2.3814144134521484
Validation loss: 2.4892811262479393

Epoch: 5| Step: 8
Training loss: 2.907038450241089
Validation loss: 2.4836048362075642

Epoch: 5| Step: 9
Training loss: 1.9738115072250366
Validation loss: 2.4839185899303806

Epoch: 5| Step: 10
Training loss: 2.9057488441467285
Validation loss: 2.482957019600817

Epoch: 107| Step: 0
Training loss: 2.5180511474609375
Validation loss: 2.486375957406977

Epoch: 5| Step: 1
Training loss: 2.5288307666778564
Validation loss: 2.4841544807598157

Epoch: 5| Step: 2
Training loss: 3.465334415435791
Validation loss: 2.4997700837350663

Epoch: 5| Step: 3
Training loss: 2.5270211696624756
Validation loss: 2.4888355552509265

Epoch: 5| Step: 4
Training loss: 2.1812782287597656
Validation loss: 2.4835258709487094

Epoch: 5| Step: 5
Training loss: 2.20927095413208
Validation loss: 2.4778468788311048

Epoch: 5| Step: 6
Training loss: 2.814511775970459
Validation loss: 2.478170064187819

Epoch: 5| Step: 7
Training loss: 2.9205684661865234
Validation loss: 2.4767534168817664

Epoch: 5| Step: 8
Training loss: 2.4428296089172363
Validation loss: 2.4763171108820106

Epoch: 5| Step: 9
Training loss: 2.4454634189605713
Validation loss: 2.4763614413558797

Epoch: 5| Step: 10
Training loss: 3.5632948875427246
Validation loss: 2.4809811256265126

Epoch: 108| Step: 0
Training loss: 2.9398131370544434
Validation loss: 2.4778161984617992

Epoch: 5| Step: 1
Training loss: 2.500283718109131
Validation loss: 2.4771109780957623

Epoch: 5| Step: 2
Training loss: 2.534209966659546
Validation loss: 2.484286992780624

Epoch: 5| Step: 3
Training loss: 2.3383095264434814
Validation loss: 2.493252900338942

Epoch: 5| Step: 4
Training loss: 3.2624154090881348
Validation loss: 2.497555968581989

Epoch: 5| Step: 5
Training loss: 3.2188868522644043
Validation loss: 2.5023145778204805

Epoch: 5| Step: 6
Training loss: 2.466142416000366
Validation loss: 2.501488308752737

Epoch: 5| Step: 7
Training loss: 2.5192930698394775
Validation loss: 2.5023579828200804

Epoch: 5| Step: 8
Training loss: 2.7528178691864014
Validation loss: 2.4982483297265987

Epoch: 5| Step: 9
Training loss: 2.438042402267456
Validation loss: 2.4972052420339277

Epoch: 5| Step: 10
Training loss: 2.495990037918091
Validation loss: 2.487118621026316

Epoch: 109| Step: 0
Training loss: 2.8439228534698486
Validation loss: 2.4797248084058046

Epoch: 5| Step: 1
Training loss: 2.9797139167785645
Validation loss: 2.47976710719447

Epoch: 5| Step: 2
Training loss: 2.2152976989746094
Validation loss: 2.4763787510574504

Epoch: 5| Step: 3
Training loss: 2.97595477104187
Validation loss: 2.477529728284446

Epoch: 5| Step: 4
Training loss: 2.470794200897217
Validation loss: 2.474562842358825

Epoch: 5| Step: 5
Training loss: 2.363482713699341
Validation loss: 2.47190107581436

Epoch: 5| Step: 6
Training loss: 3.018449306488037
Validation loss: 2.4779166329291558

Epoch: 5| Step: 7
Training loss: 2.268646717071533
Validation loss: 2.4731091504455893

Epoch: 5| Step: 8
Training loss: 2.685947895050049
Validation loss: 2.4751793312770065

Epoch: 5| Step: 9
Training loss: 3.3694920539855957
Validation loss: 2.4772060058450185

Epoch: 5| Step: 10
Training loss: 2.165189743041992
Validation loss: 2.475673552482359

Epoch: 110| Step: 0
Training loss: 3.402008056640625
Validation loss: 2.4763778794196343

Epoch: 5| Step: 1
Training loss: 2.565636157989502
Validation loss: 2.4792984788135817

Epoch: 5| Step: 2
Training loss: 2.6503891944885254
Validation loss: 2.4733778430569555

Epoch: 5| Step: 3
Training loss: 2.2056870460510254
Validation loss: 2.4784933072264477

Epoch: 5| Step: 4
Training loss: 2.366487741470337
Validation loss: 2.479271488804971

Epoch: 5| Step: 5
Training loss: 2.7111470699310303
Validation loss: 2.4773634056891165

Epoch: 5| Step: 6
Training loss: 2.996826648712158
Validation loss: 2.4936215774987334

Epoch: 5| Step: 7
Training loss: 2.700479030609131
Validation loss: 2.483984713913292

Epoch: 5| Step: 8
Training loss: 2.1907455921173096
Validation loss: 2.4886756122753186

Epoch: 5| Step: 9
Training loss: 2.595783233642578
Validation loss: 2.479913403910975

Epoch: 5| Step: 10
Training loss: 3.031057357788086
Validation loss: 2.4771212582947104

Epoch: 111| Step: 0
Training loss: 3.0798637866973877
Validation loss: 2.4727330515461583

Epoch: 5| Step: 1
Training loss: 2.036463975906372
Validation loss: 2.4679976483826995

Epoch: 5| Step: 2
Training loss: 2.6665353775024414
Validation loss: 2.463094180630099

Epoch: 5| Step: 3
Training loss: 2.8231582641601562
Validation loss: 2.466834742535827

Epoch: 5| Step: 4
Training loss: 2.96290922164917
Validation loss: 2.466503643220471

Epoch: 5| Step: 5
Training loss: 3.3324692249298096
Validation loss: 2.4705994462454193

Epoch: 5| Step: 6
Training loss: 2.2474400997161865
Validation loss: 2.4646813728476085

Epoch: 5| Step: 7
Training loss: 2.760497570037842
Validation loss: 2.4648250431142826

Epoch: 5| Step: 8
Training loss: 2.940134286880493
Validation loss: 2.465665771115211

Epoch: 5| Step: 9
Training loss: 2.882875919342041
Validation loss: 2.4632714051072315

Epoch: 5| Step: 10
Training loss: 1.5390154123306274
Validation loss: 2.471350077659853

Epoch: 112| Step: 0
Training loss: 2.1796813011169434
Validation loss: 2.4591870948832524

Epoch: 5| Step: 1
Training loss: 1.847886085510254
Validation loss: 2.4673941212315715

Epoch: 5| Step: 2
Training loss: 3.3507461547851562
Validation loss: 2.4690811941700597

Epoch: 5| Step: 3
Training loss: 2.531022071838379
Validation loss: 2.4670623784424155

Epoch: 5| Step: 4
Training loss: 2.779423713684082
Validation loss: 2.4820011238898

Epoch: 5| Step: 5
Training loss: 2.825961112976074
Validation loss: 2.4833467134865383

Epoch: 5| Step: 6
Training loss: 2.8290226459503174
Validation loss: 2.4713170246411393

Epoch: 5| Step: 7
Training loss: 3.328488826751709
Validation loss: 2.4655845447253157

Epoch: 5| Step: 8
Training loss: 2.7823963165283203
Validation loss: 2.464849228500038

Epoch: 5| Step: 9
Training loss: 2.4712460041046143
Validation loss: 2.4600561049676712

Epoch: 5| Step: 10
Training loss: 2.366675615310669
Validation loss: 2.4559574050288044

Epoch: 113| Step: 0
Training loss: 2.7048563957214355
Validation loss: 2.4581671863473873

Epoch: 5| Step: 1
Training loss: 2.841278553009033
Validation loss: 2.455537626820226

Epoch: 5| Step: 2
Training loss: 2.6340126991271973
Validation loss: 2.4599539515792683

Epoch: 5| Step: 3
Training loss: 2.1319851875305176
Validation loss: 2.4572180881295154

Epoch: 5| Step: 4
Training loss: 2.0492827892303467
Validation loss: 2.463749295921736

Epoch: 5| Step: 5
Training loss: 3.1658387184143066
Validation loss: 2.4579543631563903

Epoch: 5| Step: 6
Training loss: 2.6238410472869873
Validation loss: 2.4586637635384836

Epoch: 5| Step: 7
Training loss: 2.807966947555542
Validation loss: 2.463279295993108

Epoch: 5| Step: 8
Training loss: 3.4061782360076904
Validation loss: 2.4645165397274877

Epoch: 5| Step: 9
Training loss: 2.744387149810791
Validation loss: 2.4603068956764798

Epoch: 5| Step: 10
Training loss: 2.020994186401367
Validation loss: 2.4672500420642156

Epoch: 114| Step: 0
Training loss: 2.752997875213623
Validation loss: 2.466794231886505

Epoch: 5| Step: 1
Training loss: 2.633704900741577
Validation loss: 2.4714573403840423

Epoch: 5| Step: 2
Training loss: 2.594508171081543
Validation loss: 2.4744907681659987

Epoch: 5| Step: 3
Training loss: 2.6644206047058105
Validation loss: 2.4759478107575448

Epoch: 5| Step: 4
Training loss: 2.5696346759796143
Validation loss: 2.4667734945974042

Epoch: 5| Step: 5
Training loss: 2.1757326126098633
Validation loss: 2.46634554606612

Epoch: 5| Step: 6
Training loss: 2.535613536834717
Validation loss: 2.457722871534286

Epoch: 5| Step: 7
Training loss: 2.85874605178833
Validation loss: 2.4538415452485443

Epoch: 5| Step: 8
Training loss: 3.0355889797210693
Validation loss: 2.4531090785098333

Epoch: 5| Step: 9
Training loss: 2.5737764835357666
Validation loss: 2.453480387246737

Epoch: 5| Step: 10
Training loss: 2.914015531539917
Validation loss: 2.4553592717775734

Epoch: 115| Step: 0
Training loss: 2.371372938156128
Validation loss: 2.4641268214871808

Epoch: 5| Step: 1
Training loss: 2.975769519805908
Validation loss: 2.4575995245287494

Epoch: 5| Step: 2
Training loss: 3.168088674545288
Validation loss: 2.45509853670674

Epoch: 5| Step: 3
Training loss: 2.064310073852539
Validation loss: 2.4531558457241265

Epoch: 5| Step: 4
Training loss: 2.9159698486328125
Validation loss: 2.455037368241177

Epoch: 5| Step: 5
Training loss: 3.325390338897705
Validation loss: 2.455699902708812

Epoch: 5| Step: 6
Training loss: 2.6445541381835938
Validation loss: 2.45507255805436

Epoch: 5| Step: 7
Training loss: 2.2825913429260254
Validation loss: 2.4501604469873572

Epoch: 5| Step: 8
Training loss: 2.686127185821533
Validation loss: 2.4514440746717554

Epoch: 5| Step: 9
Training loss: 2.702566623687744
Validation loss: 2.4569253588235505

Epoch: 5| Step: 10
Training loss: 2.048724889755249
Validation loss: 2.4576933665942122

Epoch: 116| Step: 0
Training loss: 2.731539249420166
Validation loss: 2.4618312492165515

Epoch: 5| Step: 1
Training loss: 3.1322715282440186
Validation loss: 2.47226785331644

Epoch: 5| Step: 2
Training loss: 2.3025479316711426
Validation loss: 2.480101259805823

Epoch: 5| Step: 3
Training loss: 2.5138790607452393
Validation loss: 2.4963807495691444

Epoch: 5| Step: 4
Training loss: 2.2333266735076904
Validation loss: 2.49044535493338

Epoch: 5| Step: 5
Training loss: 2.767787456512451
Validation loss: 2.480104766866212

Epoch: 5| Step: 6
Training loss: 2.6532540321350098
Validation loss: 2.4713043218017905

Epoch: 5| Step: 7
Training loss: 2.8636045455932617
Validation loss: 2.452384069401731

Epoch: 5| Step: 8
Training loss: 3.0446972846984863
Validation loss: 2.4509264423001196

Epoch: 5| Step: 9
Training loss: 2.9819605350494385
Validation loss: 2.4529046448328162

Epoch: 5| Step: 10
Training loss: 1.975940227508545
Validation loss: 2.4556774170167985

Epoch: 117| Step: 0
Training loss: 2.796536684036255
Validation loss: 2.461885077978975

Epoch: 5| Step: 1
Training loss: 2.386599063873291
Validation loss: 2.4543836168063584

Epoch: 5| Step: 2
Training loss: 2.3662755489349365
Validation loss: 2.45261703255356

Epoch: 5| Step: 3
Training loss: 2.957514762878418
Validation loss: 2.4540453418608634

Epoch: 5| Step: 4
Training loss: 2.8676371574401855
Validation loss: 2.4522854423010223

Epoch: 5| Step: 5
Training loss: 2.7897939682006836
Validation loss: 2.450535838321973

Epoch: 5| Step: 6
Training loss: 1.9034297466278076
Validation loss: 2.443059157299739

Epoch: 5| Step: 7
Training loss: 3.2929248809814453
Validation loss: 2.4457575339142994

Epoch: 5| Step: 8
Training loss: 2.0402309894561768
Validation loss: 2.4479020462241223

Epoch: 5| Step: 9
Training loss: 3.0644195079803467
Validation loss: 2.450348946356004

Epoch: 5| Step: 10
Training loss: 2.959810972213745
Validation loss: 2.4619489075035177

Epoch: 118| Step: 0
Training loss: 2.9271087646484375
Validation loss: 2.4701746099738666

Epoch: 5| Step: 1
Training loss: 2.2777678966522217
Validation loss: 2.469067547910957

Epoch: 5| Step: 2
Training loss: 3.0343852043151855
Validation loss: 2.462789458613242

Epoch: 5| Step: 3
Training loss: 2.776888847351074
Validation loss: 2.452922180134763

Epoch: 5| Step: 4
Training loss: 2.9299113750457764
Validation loss: 2.4510640918567614

Epoch: 5| Step: 5
Training loss: 2.996143341064453
Validation loss: 2.4424449602762857

Epoch: 5| Step: 6
Training loss: 2.5936813354492188
Validation loss: 2.4426547788804576

Epoch: 5| Step: 7
Training loss: 2.4825150966644287
Validation loss: 2.439862266663582

Epoch: 5| Step: 8
Training loss: 1.8844547271728516
Validation loss: 2.4417156096427672

Epoch: 5| Step: 9
Training loss: 2.8594729900360107
Validation loss: 2.4434091455192974

Epoch: 5| Step: 10
Training loss: 2.6104483604431152
Validation loss: 2.4439556649936143

Epoch: 119| Step: 0
Training loss: 2.4311211109161377
Validation loss: 2.4415780908317974

Epoch: 5| Step: 1
Training loss: 3.048849105834961
Validation loss: 2.4455929930492113

Epoch: 5| Step: 2
Training loss: 2.8402161598205566
Validation loss: 2.445091244994953

Epoch: 5| Step: 3
Training loss: 2.4658737182617188
Validation loss: 2.4460437913094797

Epoch: 5| Step: 4
Training loss: 3.064525604248047
Validation loss: 2.448693831761678

Epoch: 5| Step: 5
Training loss: 3.0203137397766113
Validation loss: 2.449124720788771

Epoch: 5| Step: 6
Training loss: 2.8040356636047363
Validation loss: 2.4470946609332995

Epoch: 5| Step: 7
Training loss: 2.823741912841797
Validation loss: 2.447078425397155

Epoch: 5| Step: 8
Training loss: 2.203746795654297
Validation loss: 2.4485405196425734

Epoch: 5| Step: 9
Training loss: 1.7785085439682007
Validation loss: 2.453862487628896

Epoch: 5| Step: 10
Training loss: 2.68420672416687
Validation loss: 2.4563445275829685

Epoch: 120| Step: 0
Training loss: 2.423584461212158
Validation loss: 2.455560714967789

Epoch: 5| Step: 1
Training loss: 2.801032066345215
Validation loss: 2.4559953315283662

Epoch: 5| Step: 2
Training loss: 2.6669440269470215
Validation loss: 2.453825489167244

Epoch: 5| Step: 3
Training loss: 2.228419303894043
Validation loss: 2.450898708835725

Epoch: 5| Step: 4
Training loss: 3.4571220874786377
Validation loss: 2.444501910158383

Epoch: 5| Step: 5
Training loss: 3.2795567512512207
Validation loss: 2.4432954172934256

Epoch: 5| Step: 6
Training loss: 2.904247283935547
Validation loss: 2.4431459749898603

Epoch: 5| Step: 7
Training loss: 2.2197890281677246
Validation loss: 2.447644325994676

Epoch: 5| Step: 8
Training loss: 2.619774341583252
Validation loss: 2.442075960097774

Epoch: 5| Step: 9
Training loss: 2.210887908935547
Validation loss: 2.4459354698017077

Epoch: 5| Step: 10
Training loss: 2.3210887908935547
Validation loss: 2.4402529501145884

Epoch: 121| Step: 0
Training loss: 3.039574146270752
Validation loss: 2.4435543680703766

Epoch: 5| Step: 1
Training loss: 2.173891305923462
Validation loss: 2.443608496778755

Epoch: 5| Step: 2
Training loss: 2.998983383178711
Validation loss: 2.4449793061902447

Epoch: 5| Step: 3
Training loss: 2.862854480743408
Validation loss: 2.439830882574922

Epoch: 5| Step: 4
Training loss: 1.9725898504257202
Validation loss: 2.442566489660612

Epoch: 5| Step: 5
Training loss: 2.679990291595459
Validation loss: 2.4462738652383127

Epoch: 5| Step: 6
Training loss: 3.0478262901306152
Validation loss: 2.4521737611421974

Epoch: 5| Step: 7
Training loss: 2.6609489917755127
Validation loss: 2.4580991985977336

Epoch: 5| Step: 8
Training loss: 2.1949210166931152
Validation loss: 2.4526508315916984

Epoch: 5| Step: 9
Training loss: 3.1637067794799805
Validation loss: 2.452732883473878

Epoch: 5| Step: 10
Training loss: 2.26125168800354
Validation loss: 2.4495839585540113

Epoch: 122| Step: 0
Training loss: 2.276648759841919
Validation loss: 2.4518778862491732

Epoch: 5| Step: 1
Training loss: 3.4789810180664062
Validation loss: 2.4537782874158633

Epoch: 5| Step: 2
Training loss: 2.593459367752075
Validation loss: 2.449405772711641

Epoch: 5| Step: 3
Training loss: 2.486271619796753
Validation loss: 2.4480099216584237

Epoch: 5| Step: 4
Training loss: 2.199401378631592
Validation loss: 2.451152975841235

Epoch: 5| Step: 5
Training loss: 3.4052329063415527
Validation loss: 2.4620940685272217

Epoch: 5| Step: 6
Training loss: 2.862337827682495
Validation loss: 2.4499344569380566

Epoch: 5| Step: 7
Training loss: 2.063040256500244
Validation loss: 2.4541594571964715

Epoch: 5| Step: 8
Training loss: 2.692856550216675
Validation loss: 2.450477948752783

Epoch: 5| Step: 9
Training loss: 2.945016860961914
Validation loss: 2.445042566586566

Epoch: 5| Step: 10
Training loss: 2.03525447845459
Validation loss: 2.4393972722432946

Epoch: 123| Step: 0
Training loss: 1.7124474048614502
Validation loss: 2.4380913575490317

Epoch: 5| Step: 1
Training loss: 3.240962266921997
Validation loss: 2.433828589736774

Epoch: 5| Step: 2
Training loss: 3.316706418991089
Validation loss: 2.4319427577398156

Epoch: 5| Step: 3
Training loss: 3.1560611724853516
Validation loss: 2.4314815049530356

Epoch: 5| Step: 4
Training loss: 2.0987675189971924
Validation loss: 2.429775184200656

Epoch: 5| Step: 5
Training loss: 3.11084246635437
Validation loss: 2.4297652142022246

Epoch: 5| Step: 6
Training loss: 2.68102765083313
Validation loss: 2.429459459038191

Epoch: 5| Step: 7
Training loss: 2.1152846813201904
Validation loss: 2.429963973260695

Epoch: 5| Step: 8
Training loss: 3.155978202819824
Validation loss: 2.4306948595149542

Epoch: 5| Step: 9
Training loss: 2.1209471225738525
Validation loss: 2.4278342800755657

Epoch: 5| Step: 10
Training loss: 2.3810219764709473
Validation loss: 2.428608607220393

Epoch: 124| Step: 0
Training loss: 3.353860855102539
Validation loss: 2.431521810511107

Epoch: 5| Step: 1
Training loss: 1.8608837127685547
Validation loss: 2.4454883657475954

Epoch: 5| Step: 2
Training loss: 2.45308256149292
Validation loss: 2.4702666062180714

Epoch: 5| Step: 3
Training loss: 2.245243787765503
Validation loss: 2.478863536670644

Epoch: 5| Step: 4
Training loss: 3.1272943019866943
Validation loss: 2.4891350269317627

Epoch: 5| Step: 5
Training loss: 2.459440231323242
Validation loss: 2.480870754488053

Epoch: 5| Step: 6
Training loss: 2.3029205799102783
Validation loss: 2.4819638190730924

Epoch: 5| Step: 7
Training loss: 2.7198517322540283
Validation loss: 2.480201872446204

Epoch: 5| Step: 8
Training loss: 2.508064031600952
Validation loss: 2.445190057959608

Epoch: 5| Step: 9
Training loss: 3.1946840286254883
Validation loss: 2.430376042601883

Epoch: 5| Step: 10
Training loss: 3.0220589637756348
Validation loss: 2.4251734466962915

Epoch: 125| Step: 0
Training loss: 2.550952911376953
Validation loss: 2.43025472599973

Epoch: 5| Step: 1
Training loss: 3.082029104232788
Validation loss: 2.4328508223256757

Epoch: 5| Step: 2
Training loss: 2.1238253116607666
Validation loss: 2.4416944634529854

Epoch: 5| Step: 3
Training loss: 2.415775775909424
Validation loss: 2.439448546337825

Epoch: 5| Step: 4
Training loss: 2.8141961097717285
Validation loss: 2.4407079501818587

Epoch: 5| Step: 5
Training loss: 2.711928129196167
Validation loss: 2.437134773500504

Epoch: 5| Step: 6
Training loss: 3.0764894485473633
Validation loss: 2.4300279745491604

Epoch: 5| Step: 7
Training loss: 1.9774850606918335
Validation loss: 2.4271612064812773

Epoch: 5| Step: 8
Training loss: 2.573991298675537
Validation loss: 2.422482121375299

Epoch: 5| Step: 9
Training loss: 3.466149091720581
Validation loss: 2.420592000407557

Epoch: 5| Step: 10
Training loss: 2.483207941055298
Validation loss: 2.419537877523771

Epoch: 126| Step: 0
Training loss: 3.1226916313171387
Validation loss: 2.419401379041774

Epoch: 5| Step: 1
Training loss: 2.5792553424835205
Validation loss: 2.422639064891364

Epoch: 5| Step: 2
Training loss: 2.593522787094116
Validation loss: 2.4288237223061184

Epoch: 5| Step: 3
Training loss: 2.7994465827941895
Validation loss: 2.4277290836457284

Epoch: 5| Step: 4
Training loss: 2.085146427154541
Validation loss: 2.432555688324795

Epoch: 5| Step: 5
Training loss: 2.824627161026001
Validation loss: 2.4288446236682195

Epoch: 5| Step: 6
Training loss: 2.717409610748291
Validation loss: 2.431566648585822

Epoch: 5| Step: 7
Training loss: 2.7297987937927246
Validation loss: 2.4315186008330314

Epoch: 5| Step: 8
Training loss: 2.23075532913208
Validation loss: 2.4361605131497948

Epoch: 5| Step: 9
Training loss: 2.9280292987823486
Validation loss: 2.434453051577332

Epoch: 5| Step: 10
Training loss: 2.449185371398926
Validation loss: 2.436423829806748

Epoch: 127| Step: 0
Training loss: 2.7019124031066895
Validation loss: 2.423620018907773

Epoch: 5| Step: 1
Training loss: 3.365898847579956
Validation loss: 2.419721926412275

Epoch: 5| Step: 2
Training loss: 2.802452564239502
Validation loss: 2.4127324883655836

Epoch: 5| Step: 3
Training loss: 2.2975499629974365
Validation loss: 2.414245174777123

Epoch: 5| Step: 4
Training loss: 2.731074094772339
Validation loss: 2.4163249333699546

Epoch: 5| Step: 5
Training loss: 2.949747323989868
Validation loss: 2.4159543821888585

Epoch: 5| Step: 6
Training loss: 1.5668556690216064
Validation loss: 2.4145076069780576

Epoch: 5| Step: 7
Training loss: 2.207263231277466
Validation loss: 2.4132848349950646

Epoch: 5| Step: 8
Training loss: 2.7156620025634766
Validation loss: 2.4147385602356284

Epoch: 5| Step: 9
Training loss: 3.0212974548339844
Validation loss: 2.416210070733101

Epoch: 5| Step: 10
Training loss: 2.735105514526367
Validation loss: 2.4183577260663434

Epoch: 128| Step: 0
Training loss: 2.586968183517456
Validation loss: 2.4215468052894837

Epoch: 5| Step: 1
Training loss: 2.5193490982055664
Validation loss: 2.4168995631638395

Epoch: 5| Step: 2
Training loss: 3.1197142601013184
Validation loss: 2.4147697315421155

Epoch: 5| Step: 3
Training loss: 2.5048255920410156
Validation loss: 2.4193623911949897

Epoch: 5| Step: 4
Training loss: 1.8178943395614624
Validation loss: 2.4159604118716334

Epoch: 5| Step: 5
Training loss: 2.5911309719085693
Validation loss: 2.4159302583304783

Epoch: 5| Step: 6
Training loss: 2.305230140686035
Validation loss: 2.4207819713059293

Epoch: 5| Step: 7
Training loss: 2.7276248931884766
Validation loss: 2.428672803345547

Epoch: 5| Step: 8
Training loss: 2.7911999225616455
Validation loss: 2.433436873138592

Epoch: 5| Step: 9
Training loss: 2.97924542427063
Validation loss: 2.438028848299416

Epoch: 5| Step: 10
Training loss: 3.1577272415161133
Validation loss: 2.453400306804206

Epoch: 129| Step: 0
Training loss: 3.2299914360046387
Validation loss: 2.455776491472798

Epoch: 5| Step: 1
Training loss: 2.570164680480957
Validation loss: 2.4706677159955426

Epoch: 5| Step: 2
Training loss: 2.6029441356658936
Validation loss: 2.470553111004573

Epoch: 5| Step: 3
Training loss: 3.7191250324249268
Validation loss: 2.444977657769316

Epoch: 5| Step: 4
Training loss: 2.5560011863708496
Validation loss: 2.4344684590575514

Epoch: 5| Step: 5
Training loss: 2.4674477577209473
Validation loss: 2.417730362184586

Epoch: 5| Step: 6
Training loss: 2.666239023208618
Validation loss: 2.4171674431011243

Epoch: 5| Step: 7
Training loss: 2.6255640983581543
Validation loss: 2.416604261244497

Epoch: 5| Step: 8
Training loss: 1.9309412240982056
Validation loss: 2.4114815752993346

Epoch: 5| Step: 9
Training loss: 2.7148709297180176
Validation loss: 2.414933362314778

Epoch: 5| Step: 10
Training loss: 1.8196369409561157
Validation loss: 2.4115482568740845

Epoch: 130| Step: 0
Training loss: 2.4979023933410645
Validation loss: 2.424772103627523

Epoch: 5| Step: 1
Training loss: 2.25876784324646
Validation loss: 2.4312746652992825

Epoch: 5| Step: 2
Training loss: 2.7648074626922607
Validation loss: 2.4370811908475813

Epoch: 5| Step: 3
Training loss: 2.980628252029419
Validation loss: 2.430768477019443

Epoch: 5| Step: 4
Training loss: 2.4128758907318115
Validation loss: 2.4278352004225536

Epoch: 5| Step: 5
Training loss: 2.577430486679077
Validation loss: 2.428364440958987

Epoch: 5| Step: 6
Training loss: 2.4793617725372314
Validation loss: 2.4270528926644275

Epoch: 5| Step: 7
Training loss: 3.3001790046691895
Validation loss: 2.4298928553058254

Epoch: 5| Step: 8
Training loss: 2.62282133102417
Validation loss: 2.425496975580851

Epoch: 5| Step: 9
Training loss: 2.5118300914764404
Validation loss: 2.4147242551208823

Epoch: 5| Step: 10
Training loss: 2.626779794692993
Validation loss: 2.415097813452444

Epoch: 131| Step: 0
Training loss: 2.875622510910034
Validation loss: 2.4110977047233173

Epoch: 5| Step: 1
Training loss: 2.651840925216675
Validation loss: 2.412867187171854

Epoch: 5| Step: 2
Training loss: 2.8681740760803223
Validation loss: 2.417419628430438

Epoch: 5| Step: 3
Training loss: 1.8982127904891968
Validation loss: 2.4142501508035967

Epoch: 5| Step: 4
Training loss: 2.847752571105957
Validation loss: 2.420740509545931

Epoch: 5| Step: 5
Training loss: 1.8592395782470703
Validation loss: 2.421109204651207

Epoch: 5| Step: 6
Training loss: 2.6309101581573486
Validation loss: 2.418704525116951

Epoch: 5| Step: 7
Training loss: 2.681349277496338
Validation loss: 2.4255131060077297

Epoch: 5| Step: 8
Training loss: 2.8559234142303467
Validation loss: 2.422203702311362

Epoch: 5| Step: 9
Training loss: 2.8465018272399902
Validation loss: 2.4225229473524195

Epoch: 5| Step: 10
Training loss: 3.021620988845825
Validation loss: 2.425708083696263

Epoch: 132| Step: 0
Training loss: 1.9906047582626343
Validation loss: 2.417796722022436

Epoch: 5| Step: 1
Training loss: 2.365074396133423
Validation loss: 2.420036456918204

Epoch: 5| Step: 2
Training loss: 3.3197078704833984
Validation loss: 2.425661284436462

Epoch: 5| Step: 3
Training loss: 2.762690782546997
Validation loss: 2.4185339379054245

Epoch: 5| Step: 4
Training loss: 2.8023264408111572
Validation loss: 2.410059226456509

Epoch: 5| Step: 5
Training loss: 2.7273080348968506
Validation loss: 2.413921115218952

Epoch: 5| Step: 6
Training loss: 2.7604942321777344
Validation loss: 2.411660517415693

Epoch: 5| Step: 7
Training loss: 2.7915990352630615
Validation loss: 2.4054061110301683

Epoch: 5| Step: 8
Training loss: 2.72361421585083
Validation loss: 2.4141326694078344

Epoch: 5| Step: 9
Training loss: 2.1518445014953613
Validation loss: 2.411390801911713

Epoch: 5| Step: 10
Training loss: 2.4939286708831787
Validation loss: 2.4095591883505545

Epoch: 133| Step: 0
Training loss: 3.235485792160034
Validation loss: 2.414458691432912

Epoch: 5| Step: 1
Training loss: 2.8985393047332764
Validation loss: 2.414302264490435

Epoch: 5| Step: 2
Training loss: 2.9132964611053467
Validation loss: 2.4174027340386504

Epoch: 5| Step: 3
Training loss: 2.134298801422119
Validation loss: 2.41314023540866

Epoch: 5| Step: 4
Training loss: 2.542184352874756
Validation loss: 2.4134345054626465

Epoch: 5| Step: 5
Training loss: 2.5106711387634277
Validation loss: 2.414953144647742

Epoch: 5| Step: 6
Training loss: 2.765805721282959
Validation loss: 2.420275799689754

Epoch: 5| Step: 7
Training loss: 2.3863654136657715
Validation loss: 2.418653198467788

Epoch: 5| Step: 8
Training loss: 2.159848928451538
Validation loss: 2.418456454430857

Epoch: 5| Step: 9
Training loss: 3.2357277870178223
Validation loss: 2.420491531331052

Epoch: 5| Step: 10
Training loss: 2.0229380130767822
Validation loss: 2.4144432595981065

Epoch: 134| Step: 0
Training loss: 2.543950080871582
Validation loss: 2.4117195503686064

Epoch: 5| Step: 1
Training loss: 2.6138663291931152
Validation loss: 2.410014478109216

Epoch: 5| Step: 2
Training loss: 2.5187888145446777
Validation loss: 2.40824055928056

Epoch: 5| Step: 3
Training loss: 2.376575231552124
Validation loss: 2.4049289200895574

Epoch: 5| Step: 4
Training loss: 2.976067304611206
Validation loss: 2.4057696070722354

Epoch: 5| Step: 5
Training loss: 2.3598527908325195
Validation loss: 2.407539795803767

Epoch: 5| Step: 6
Training loss: 3.4020705223083496
Validation loss: 2.4087074802767847

Epoch: 5| Step: 7
Training loss: 2.1241073608398438
Validation loss: 2.4067504508520967

Epoch: 5| Step: 8
Training loss: 2.981414794921875
Validation loss: 2.4074405880384546

Epoch: 5| Step: 9
Training loss: 1.9288047552108765
Validation loss: 2.4191160150753555

Epoch: 5| Step: 10
Training loss: 3.0692007541656494
Validation loss: 2.4151818213924283

Epoch: 135| Step: 0
Training loss: 2.947591781616211
Validation loss: 2.4240084463550198

Epoch: 5| Step: 1
Training loss: 2.0319385528564453
Validation loss: 2.423295890131304

Epoch: 5| Step: 2
Training loss: 2.9006752967834473
Validation loss: 2.415052902313971

Epoch: 5| Step: 3
Training loss: 2.9491004943847656
Validation loss: 2.4133620621055685

Epoch: 5| Step: 4
Training loss: 2.4275527000427246
Validation loss: 2.410439404108191

Epoch: 5| Step: 5
Training loss: 2.2337284088134766
Validation loss: 2.411036863121935

Epoch: 5| Step: 6
Training loss: 2.0066733360290527
Validation loss: 2.41161871212785

Epoch: 5| Step: 7
Training loss: 2.5887210369110107
Validation loss: 2.4117400236027215

Epoch: 5| Step: 8
Training loss: 2.3930225372314453
Validation loss: 2.4062260761055896

Epoch: 5| Step: 9
Training loss: 3.52227520942688
Validation loss: 2.4046437330143426

Epoch: 5| Step: 10
Training loss: 2.817070484161377
Validation loss: 2.4066480257177867

Epoch: 136| Step: 0
Training loss: 2.3381457328796387
Validation loss: 2.4017149120248775

Epoch: 5| Step: 1
Training loss: 2.285464286804199
Validation loss: 2.3993293905770905

Epoch: 5| Step: 2
Training loss: 2.9967684745788574
Validation loss: 2.3968135951667704

Epoch: 5| Step: 3
Training loss: 2.837493896484375
Validation loss: 2.4003969725742134

Epoch: 5| Step: 4
Training loss: 2.6913094520568848
Validation loss: 2.400993416386266

Epoch: 5| Step: 5
Training loss: 2.602631092071533
Validation loss: 2.4004333916530816

Epoch: 5| Step: 6
Training loss: 2.2839908599853516
Validation loss: 2.4048556948220856

Epoch: 5| Step: 7
Training loss: 3.058048963546753
Validation loss: 2.4238345776834795

Epoch: 5| Step: 8
Training loss: 2.641836166381836
Validation loss: 2.4344020094922794

Epoch: 5| Step: 9
Training loss: 2.562786817550659
Validation loss: 2.4520100316693707

Epoch: 5| Step: 10
Training loss: 2.6520519256591797
Validation loss: 2.4605653439798663

Epoch: 137| Step: 0
Training loss: 2.818540334701538
Validation loss: 2.4305868200076524

Epoch: 5| Step: 1
Training loss: 2.278433084487915
Validation loss: 2.4112977943112774

Epoch: 5| Step: 2
Training loss: 2.1734304428100586
Validation loss: 2.3967344401985087

Epoch: 5| Step: 3
Training loss: 2.532914638519287
Validation loss: 2.401524886008232

Epoch: 5| Step: 4
Training loss: 2.511908531188965
Validation loss: 2.4024006371857016

Epoch: 5| Step: 5
Training loss: 2.630753755569458
Validation loss: 2.4077125134006625

Epoch: 5| Step: 6
Training loss: 3.2933127880096436
Validation loss: 2.4054766085840042

Epoch: 5| Step: 7
Training loss: 2.172560691833496
Validation loss: 2.408523451897406

Epoch: 5| Step: 8
Training loss: 3.4947593212127686
Validation loss: 2.4043211526768182

Epoch: 5| Step: 9
Training loss: 2.7005457878112793
Validation loss: 2.4014055780185166

Epoch: 5| Step: 10
Training loss: 2.2800862789154053
Validation loss: 2.4080256774861324

Epoch: 138| Step: 0
Training loss: 2.707232713699341
Validation loss: 2.412417919405045

Epoch: 5| Step: 1
Training loss: 3.2857909202575684
Validation loss: 2.4220052406352055

Epoch: 5| Step: 2
Training loss: 2.5337374210357666
Validation loss: 2.4168816574158205

Epoch: 5| Step: 3
Training loss: 2.8007874488830566
Validation loss: 2.4127794657984087

Epoch: 5| Step: 4
Training loss: 2.3761987686157227
Validation loss: 2.409856363009381

Epoch: 5| Step: 5
Training loss: 2.606055736541748
Validation loss: 2.415109137053131

Epoch: 5| Step: 6
Training loss: 2.6522276401519775
Validation loss: 2.419490509135749

Epoch: 5| Step: 7
Training loss: 2.9428322315216064
Validation loss: 2.431873982952487

Epoch: 5| Step: 8
Training loss: 1.805620551109314
Validation loss: 2.4149479840391423

Epoch: 5| Step: 9
Training loss: 2.680133581161499
Validation loss: 2.3989876290803314

Epoch: 5| Step: 10
Training loss: 2.512075185775757
Validation loss: 2.3927109523486068

Epoch: 139| Step: 0
Training loss: 2.9219346046447754
Validation loss: 2.3917583316885014

Epoch: 5| Step: 1
Training loss: 1.8905531167984009
Validation loss: 2.3959857981692076

Epoch: 5| Step: 2
Training loss: 2.5729751586914062
Validation loss: 2.4043847360918598

Epoch: 5| Step: 3
Training loss: 2.2959506511688232
Validation loss: 2.4141188488211682

Epoch: 5| Step: 4
Training loss: 3.0737345218658447
Validation loss: 2.4139911846448014

Epoch: 5| Step: 5
Training loss: 3.1199584007263184
Validation loss: 2.420591431279336

Epoch: 5| Step: 6
Training loss: 3.3485970497131348
Validation loss: 2.4254495764291413

Epoch: 5| Step: 7
Training loss: 2.223505735397339
Validation loss: 2.4183527423489477

Epoch: 5| Step: 8
Training loss: 2.1270718574523926
Validation loss: 2.4134197645289923

Epoch: 5| Step: 9
Training loss: 2.6946346759796143
Validation loss: 2.413884324412192

Epoch: 5| Step: 10
Training loss: 2.6284868717193604
Validation loss: 2.411193355437248

Epoch: 140| Step: 0
Training loss: 2.6809422969818115
Validation loss: 2.3949440679242535

Epoch: 5| Step: 1
Training loss: 2.551685094833374
Validation loss: 2.390384517690187

Epoch: 5| Step: 2
Training loss: 2.420182466506958
Validation loss: 2.3916185030373196

Epoch: 5| Step: 3
Training loss: 3.3739013671875
Validation loss: 2.3826269231816775

Epoch: 5| Step: 4
Training loss: 2.4746391773223877
Validation loss: 2.383495041119155

Epoch: 5| Step: 5
Training loss: 1.768254041671753
Validation loss: 2.3890251318613687

Epoch: 5| Step: 6
Training loss: 2.667280673980713
Validation loss: 2.3893391009299987

Epoch: 5| Step: 7
Training loss: 2.6013541221618652
Validation loss: 2.3970813071855934

Epoch: 5| Step: 8
Training loss: 2.4700169563293457
Validation loss: 2.401605872697728

Epoch: 5| Step: 9
Training loss: 2.8440279960632324
Validation loss: 2.3956875031994236

Epoch: 5| Step: 10
Training loss: 2.9184341430664062
Validation loss: 2.4054521245341145

Epoch: 141| Step: 0
Training loss: 2.507061243057251
Validation loss: 2.390225002842565

Epoch: 5| Step: 1
Training loss: 2.408104419708252
Validation loss: 2.3884638381260697

Epoch: 5| Step: 2
Training loss: 2.620309352874756
Validation loss: 2.389890706667336

Epoch: 5| Step: 3
Training loss: 2.1309401988983154
Validation loss: 2.3884834909951813

Epoch: 5| Step: 4
Training loss: 2.6882121562957764
Validation loss: 2.3896361038249028

Epoch: 5| Step: 5
Training loss: 3.557283878326416
Validation loss: 2.3916406785288165

Epoch: 5| Step: 6
Training loss: 2.612977981567383
Validation loss: 2.3878436934563423

Epoch: 5| Step: 7
Training loss: 2.582632541656494
Validation loss: 2.3925489584604898

Epoch: 5| Step: 8
Training loss: 2.3773727416992188
Validation loss: 2.3902428047631377

Epoch: 5| Step: 9
Training loss: 2.7850422859191895
Validation loss: 2.3867814976681947

Epoch: 5| Step: 10
Training loss: 2.356210231781006
Validation loss: 2.3957632254528742

Epoch: 142| Step: 0
Training loss: 3.3380844593048096
Validation loss: 2.38668627636407

Epoch: 5| Step: 1
Training loss: 2.3375840187072754
Validation loss: 2.3876241868542087

Epoch: 5| Step: 2
Training loss: 2.962977170944214
Validation loss: 2.388691138195735

Epoch: 5| Step: 3
Training loss: 2.3594791889190674
Validation loss: 2.384289459515643

Epoch: 5| Step: 4
Training loss: 3.076789379119873
Validation loss: 2.3881872546288276

Epoch: 5| Step: 5
Training loss: 2.9524481296539307
Validation loss: 2.394696981676163

Epoch: 5| Step: 6
Training loss: 2.4068257808685303
Validation loss: 2.389221910507448

Epoch: 5| Step: 7
Training loss: 1.8840644359588623
Validation loss: 2.3926560135297876

Epoch: 5| Step: 8
Training loss: 2.774306297302246
Validation loss: 2.399956968522841

Epoch: 5| Step: 9
Training loss: 2.074535369873047
Validation loss: 2.390062644917478

Epoch: 5| Step: 10
Training loss: 2.5238094329833984
Validation loss: 2.3915096047104045

Epoch: 143| Step: 0
Training loss: 2.5924854278564453
Validation loss: 2.396635696452151

Epoch: 5| Step: 1
Training loss: 2.6012275218963623
Validation loss: 2.3930863898287535

Epoch: 5| Step: 2
Training loss: 1.5693105459213257
Validation loss: 2.394552528217275

Epoch: 5| Step: 3
Training loss: 2.634624481201172
Validation loss: 2.3892027331936743

Epoch: 5| Step: 4
Training loss: 3.1807117462158203
Validation loss: 2.389932294045725

Epoch: 5| Step: 5
Training loss: 3.1729626655578613
Validation loss: 2.38682996842169

Epoch: 5| Step: 6
Training loss: 2.632213592529297
Validation loss: 2.3881831207583026

Epoch: 5| Step: 7
Training loss: 2.386167049407959
Validation loss: 2.3885678757903395

Epoch: 5| Step: 8
Training loss: 2.373905897140503
Validation loss: 2.3903076597439346

Epoch: 5| Step: 9
Training loss: 1.9155075550079346
Validation loss: 2.395791333208802

Epoch: 5| Step: 10
Training loss: 3.771841526031494
Validation loss: 2.3992400759009906

Epoch: 144| Step: 0
Training loss: 2.272263765335083
Validation loss: 2.4061203566930627

Epoch: 5| Step: 1
Training loss: 2.568085193634033
Validation loss: 2.4031773715890865

Epoch: 5| Step: 2
Training loss: 2.4941964149475098
Validation loss: 2.4038669152926375

Epoch: 5| Step: 3
Training loss: 2.669746160507202
Validation loss: 2.400237560272217

Epoch: 5| Step: 4
Training loss: 3.0753555297851562
Validation loss: 2.395771257338985

Epoch: 5| Step: 5
Training loss: 2.686591386795044
Validation loss: 2.3896122952943206

Epoch: 5| Step: 6
Training loss: 2.3515586853027344
Validation loss: 2.3886377016703286

Epoch: 5| Step: 7
Training loss: 2.369330883026123
Validation loss: 2.3912943998972573

Epoch: 5| Step: 8
Training loss: 3.334519147872925
Validation loss: 2.395788485004056

Epoch: 5| Step: 9
Training loss: 2.3586764335632324
Validation loss: 2.390360983469153

Epoch: 5| Step: 10
Training loss: 2.414630651473999
Validation loss: 2.3908223362379175

Epoch: 145| Step: 0
Training loss: 3.1481781005859375
Validation loss: 2.3914535314806047

Epoch: 5| Step: 1
Training loss: 2.411818742752075
Validation loss: 2.389968910524922

Epoch: 5| Step: 2
Training loss: 2.183748960494995
Validation loss: 2.402093264364427

Epoch: 5| Step: 3
Training loss: 3.019914150238037
Validation loss: 2.3945489903931976

Epoch: 5| Step: 4
Training loss: 2.675307035446167
Validation loss: 2.384308212546892

Epoch: 5| Step: 5
Training loss: 2.4071216583251953
Validation loss: 2.3819193634935605

Epoch: 5| Step: 6
Training loss: 3.113863706588745
Validation loss: 2.3802618211315525

Epoch: 5| Step: 7
Training loss: 2.724228620529175
Validation loss: 2.373788797727195

Epoch: 5| Step: 8
Training loss: 2.503058671951294
Validation loss: 2.3782985056600263

Epoch: 5| Step: 9
Training loss: 1.8108341693878174
Validation loss: 2.3814047049450617

Epoch: 5| Step: 10
Training loss: 2.6150615215301514
Validation loss: 2.3787977054554927

Epoch: 146| Step: 0
Training loss: 3.0992178916931152
Validation loss: 2.3866825488305863

Epoch: 5| Step: 1
Training loss: 2.819403648376465
Validation loss: 2.384615849423152

Epoch: 5| Step: 2
Training loss: 2.248558759689331
Validation loss: 2.385252442411197

Epoch: 5| Step: 3
Training loss: 2.489332914352417
Validation loss: 2.3913599214246197

Epoch: 5| Step: 4
Training loss: 1.9037376642227173
Validation loss: 2.39475054125632

Epoch: 5| Step: 5
Training loss: 3.144063711166382
Validation loss: 2.3888509760620775

Epoch: 5| Step: 6
Training loss: 2.1731276512145996
Validation loss: 2.3871289581380863

Epoch: 5| Step: 7
Training loss: 2.2830605506896973
Validation loss: 2.373093940878427

Epoch: 5| Step: 8
Training loss: 2.8412532806396484
Validation loss: 2.3814409086781163

Epoch: 5| Step: 9
Training loss: 2.8149075508117676
Validation loss: 2.370294934959822

Epoch: 5| Step: 10
Training loss: 2.7637455463409424
Validation loss: 2.372020206143779

Epoch: 147| Step: 0
Training loss: 2.8458714485168457
Validation loss: 2.3744414596147436

Epoch: 5| Step: 1
Training loss: 2.2706522941589355
Validation loss: 2.3717827514935563

Epoch: 5| Step: 2
Training loss: 2.54392409324646
Validation loss: 2.3769045901554886

Epoch: 5| Step: 3
Training loss: 2.6890602111816406
Validation loss: 2.372756399134154

Epoch: 5| Step: 4
Training loss: 1.9587726593017578
Validation loss: 2.374281688403058

Epoch: 5| Step: 5
Training loss: 2.7535862922668457
Validation loss: 2.376144434816094

Epoch: 5| Step: 6
Training loss: 2.7042675018310547
Validation loss: 2.383295223277102

Epoch: 5| Step: 7
Training loss: 2.9681484699249268
Validation loss: 2.4080258877046647

Epoch: 5| Step: 8
Training loss: 2.9662559032440186
Validation loss: 2.416217562972858

Epoch: 5| Step: 9
Training loss: 2.372767210006714
Validation loss: 2.415984143492996

Epoch: 5| Step: 10
Training loss: 2.4843454360961914
Validation loss: 2.4041542058349936

Epoch: 148| Step: 0
Training loss: 2.8730854988098145
Validation loss: 2.3928717490165465

Epoch: 5| Step: 1
Training loss: 2.4015886783599854
Validation loss: 2.379573860476094

Epoch: 5| Step: 2
Training loss: 2.4963161945343018
Validation loss: 2.3771726726203837

Epoch: 5| Step: 3
Training loss: 2.3590316772460938
Validation loss: 2.374480301334012

Epoch: 5| Step: 4
Training loss: 2.530897855758667
Validation loss: 2.3702543909831713

Epoch: 5| Step: 5
Training loss: 2.3900299072265625
Validation loss: 2.372550049135762

Epoch: 5| Step: 6
Training loss: 2.0107581615448
Validation loss: 2.3681420305723786

Epoch: 5| Step: 7
Training loss: 2.6921088695526123
Validation loss: 2.37683057144124

Epoch: 5| Step: 8
Training loss: 3.0898947715759277
Validation loss: 2.3723868836638746

Epoch: 5| Step: 9
Training loss: 3.1366219520568848
Validation loss: 2.3777380835625435

Epoch: 5| Step: 10
Training loss: 2.5087130069732666
Validation loss: 2.368523492608019

Epoch: 149| Step: 0
Training loss: 2.9452266693115234
Validation loss: 2.3832501749838553

Epoch: 5| Step: 1
Training loss: 2.42191219329834
Validation loss: 2.3816319460509927

Epoch: 5| Step: 2
Training loss: 2.2553515434265137
Validation loss: 2.378354880117601

Epoch: 5| Step: 3
Training loss: 2.7296440601348877
Validation loss: 2.384309563585507

Epoch: 5| Step: 4
Training loss: 2.1625609397888184
Validation loss: 2.3771806506700415

Epoch: 5| Step: 5
Training loss: 2.1823935508728027
Validation loss: 2.3723425762627715

Epoch: 5| Step: 6
Training loss: 3.126067638397217
Validation loss: 2.371214700001542

Epoch: 5| Step: 7
Training loss: 2.717163562774658
Validation loss: 2.3722178115639636

Epoch: 5| Step: 8
Training loss: 2.340721607208252
Validation loss: 2.3831840817646315

Epoch: 5| Step: 9
Training loss: 2.9703783988952637
Validation loss: 2.39655892566968

Epoch: 5| Step: 10
Training loss: 2.706975221633911
Validation loss: 2.425393483972037

Epoch: 150| Step: 0
Training loss: 1.782012939453125
Validation loss: 2.4136032647984003

Epoch: 5| Step: 1
Training loss: 3.311894655227661
Validation loss: 2.4038779415110105

Epoch: 5| Step: 2
Training loss: 2.956686019897461
Validation loss: 2.3825812314146306

Epoch: 5| Step: 3
Training loss: 2.9886608123779297
Validation loss: 2.380582347992928

Epoch: 5| Step: 4
Training loss: 2.303231716156006
Validation loss: 2.3726690276976554

Epoch: 5| Step: 5
Training loss: 2.7350168228149414
Validation loss: 2.3700754193849463

Epoch: 5| Step: 6
Training loss: 2.8038673400878906
Validation loss: 2.3646077084284958

Epoch: 5| Step: 7
Training loss: 2.9620742797851562
Validation loss: 2.3687019194326093

Epoch: 5| Step: 8
Training loss: 2.7479538917541504
Validation loss: 2.3677548182907926

Epoch: 5| Step: 9
Training loss: 2.1074423789978027
Validation loss: 2.3654721629235054

Epoch: 5| Step: 10
Training loss: 1.757741928100586
Validation loss: 2.37023348962107

Epoch: 151| Step: 0
Training loss: 3.3611044883728027
Validation loss: 2.3756293301941245

Epoch: 5| Step: 1
Training loss: 2.1585707664489746
Validation loss: 2.3755577994931127

Epoch: 5| Step: 2
Training loss: 1.8569514751434326
Validation loss: 2.384007583382309

Epoch: 5| Step: 3
Training loss: 2.4936256408691406
Validation loss: 2.3756947901941117

Epoch: 5| Step: 4
Training loss: 2.730642795562744
Validation loss: 2.38567921679507

Epoch: 5| Step: 5
Training loss: 2.3580100536346436
Validation loss: 2.374701735793903

Epoch: 5| Step: 6
Training loss: 3.1472344398498535
Validation loss: 2.370081473422307

Epoch: 5| Step: 7
Training loss: 2.850353240966797
Validation loss: 2.365972170265772

Epoch: 5| Step: 8
Training loss: 2.3613038063049316
Validation loss: 2.3617684405337096

Epoch: 5| Step: 9
Training loss: 2.1821913719177246
Validation loss: 2.3625097838781213

Epoch: 5| Step: 10
Training loss: 3.0772969722747803
Validation loss: 2.3588278037245556

Epoch: 152| Step: 0
Training loss: 2.353726863861084
Validation loss: 2.36945011795208

Epoch: 5| Step: 1
Training loss: 2.4591763019561768
Validation loss: 2.3689409609763854

Epoch: 5| Step: 2
Training loss: 3.043898105621338
Validation loss: 2.359541992987356

Epoch: 5| Step: 3
Training loss: 2.3679022789001465
Validation loss: 2.370278989115069

Epoch: 5| Step: 4
Training loss: 2.687455177307129
Validation loss: 2.395518284971996

Epoch: 5| Step: 5
Training loss: 3.1817150115966797
Validation loss: 2.4198907011298725

Epoch: 5| Step: 6
Training loss: 2.5549609661102295
Validation loss: 2.4251290880223757

Epoch: 5| Step: 7
Training loss: 2.578193187713623
Validation loss: 2.422605482480859

Epoch: 5| Step: 8
Training loss: 2.002114772796631
Validation loss: 2.4146320127671763

Epoch: 5| Step: 9
Training loss: 2.6461241245269775
Validation loss: 2.383539653593494

Epoch: 5| Step: 10
Training loss: 2.7065982818603516
Validation loss: 2.3684517645066783

Epoch: 153| Step: 0
Training loss: 2.2043066024780273
Validation loss: 2.3714790421147502

Epoch: 5| Step: 1
Training loss: 2.48858642578125
Validation loss: 2.3643810723417547

Epoch: 5| Step: 2
Training loss: 2.8051400184631348
Validation loss: 2.3681547898118214

Epoch: 5| Step: 3
Training loss: 2.4748940467834473
Validation loss: 2.3728214386970765

Epoch: 5| Step: 4
Training loss: 2.6435978412628174
Validation loss: 2.3715184683440835

Epoch: 5| Step: 5
Training loss: 3.007638692855835
Validation loss: 2.372693866811773

Epoch: 5| Step: 6
Training loss: 2.3977527618408203
Validation loss: 2.364981766669981

Epoch: 5| Step: 7
Training loss: 2.4555866718292236
Validation loss: 2.3582719756710913

Epoch: 5| Step: 8
Training loss: 2.5461559295654297
Validation loss: 2.3583538480984267

Epoch: 5| Step: 9
Training loss: 2.876087188720703
Validation loss: 2.3573142610570437

Epoch: 5| Step: 10
Training loss: 2.755138635635376
Validation loss: 2.3666717288314656

Epoch: 154| Step: 0
Training loss: 2.9345195293426514
Validation loss: 2.384571774031526

Epoch: 5| Step: 1
Training loss: 2.682264804840088
Validation loss: 2.3867432660953973

Epoch: 5| Step: 2
Training loss: 1.5159013271331787
Validation loss: 2.401690465147777

Epoch: 5| Step: 3
Training loss: 2.421290397644043
Validation loss: 2.3842941637962096

Epoch: 5| Step: 4
Training loss: 2.6763973236083984
Validation loss: 2.3746610277442524

Epoch: 5| Step: 5
Training loss: 2.6714189052581787
Validation loss: 2.363651970381378

Epoch: 5| Step: 6
Training loss: 2.7712416648864746
Validation loss: 2.362805951026178

Epoch: 5| Step: 7
Training loss: 2.81889009475708
Validation loss: 2.363725954486478

Epoch: 5| Step: 8
Training loss: 2.791571617126465
Validation loss: 2.3635290309947026

Epoch: 5| Step: 9
Training loss: 2.4515650272369385
Validation loss: 2.3590106630838044

Epoch: 5| Step: 10
Training loss: 2.930598020553589
Validation loss: 2.3629775611303185

Epoch: 155| Step: 0
Training loss: 2.264153003692627
Validation loss: 2.3642131461892077

Epoch: 5| Step: 1
Training loss: 2.967212200164795
Validation loss: 2.359499685225948

Epoch: 5| Step: 2
Training loss: 2.284799098968506
Validation loss: 2.3609738221732517

Epoch: 5| Step: 3
Training loss: 2.3456215858459473
Validation loss: 2.360632347804244

Epoch: 5| Step: 4
Training loss: 2.791642189025879
Validation loss: 2.378145828041979

Epoch: 5| Step: 5
Training loss: 2.5501699447631836
Validation loss: 2.384051699792185

Epoch: 5| Step: 6
Training loss: 3.0871691703796387
Validation loss: 2.3905905318516556

Epoch: 5| Step: 7
Training loss: 2.7274975776672363
Validation loss: 2.3791508136257047

Epoch: 5| Step: 8
Training loss: 2.555190324783325
Validation loss: 2.3937001741060646

Epoch: 5| Step: 9
Training loss: 2.0691819190979004
Validation loss: 2.3892278619991836

Epoch: 5| Step: 10
Training loss: 2.869710922241211
Validation loss: 2.37465133718265

Epoch: 156| Step: 0
Training loss: 2.5220706462860107
Validation loss: 2.359890369958775

Epoch: 5| Step: 1
Training loss: 3.3529162406921387
Validation loss: 2.3557201534189205

Epoch: 5| Step: 2
Training loss: 2.209677219390869
Validation loss: 2.354239789388513

Epoch: 5| Step: 3
Training loss: 3.0491108894348145
Validation loss: 2.3495845064040153

Epoch: 5| Step: 4
Training loss: 2.8520846366882324
Validation loss: 2.3511813814922045

Epoch: 5| Step: 5
Training loss: 2.248878240585327
Validation loss: 2.3452162896433184

Epoch: 5| Step: 6
Training loss: 2.425903797149658
Validation loss: 2.3469226385957453

Epoch: 5| Step: 7
Training loss: 2.8019042015075684
Validation loss: 2.342546796285978

Epoch: 5| Step: 8
Training loss: 1.9005905389785767
Validation loss: 2.340650995572408

Epoch: 5| Step: 9
Training loss: 1.9209457635879517
Validation loss: 2.3411971830552623

Epoch: 5| Step: 10
Training loss: 3.1840415000915527
Validation loss: 2.344881401267103

Epoch: 157| Step: 0
Training loss: 2.428433895111084
Validation loss: 2.34441779762186

Epoch: 5| Step: 1
Training loss: 2.6445164680480957
Validation loss: 2.3475695681828324

Epoch: 5| Step: 2
Training loss: 2.579071044921875
Validation loss: 2.358707102396155

Epoch: 5| Step: 3
Training loss: 2.781446933746338
Validation loss: 2.363048973903861

Epoch: 5| Step: 4
Training loss: 2.305765151977539
Validation loss: 2.3695813186707033

Epoch: 5| Step: 5
Training loss: 2.0630061626434326
Validation loss: 2.3633779120701615

Epoch: 5| Step: 6
Training loss: 2.7930541038513184
Validation loss: 2.3666463898074244

Epoch: 5| Step: 7
Training loss: 2.5588057041168213
Validation loss: 2.356769161839639

Epoch: 5| Step: 8
Training loss: 2.6021759510040283
Validation loss: 2.3506623365545787

Epoch: 5| Step: 9
Training loss: 2.9359934329986572
Validation loss: 2.348487420748639

Epoch: 5| Step: 10
Training loss: 2.769824504852295
Validation loss: 2.347914008684056

Epoch: 158| Step: 0
Training loss: 1.8747742176055908
Validation loss: 2.3531223932902017

Epoch: 5| Step: 1
Training loss: 2.634726047515869
Validation loss: 2.3621530097018004

Epoch: 5| Step: 2
Training loss: 3.2084546089172363
Validation loss: 2.3733854191277617

Epoch: 5| Step: 3
Training loss: 2.491058826446533
Validation loss: 2.382666890339185

Epoch: 5| Step: 4
Training loss: 2.5643105506896973
Validation loss: 2.3920928919187157

Epoch: 5| Step: 5
Training loss: 3.2860634326934814
Validation loss: 2.3993032568244526

Epoch: 5| Step: 6
Training loss: 2.530142307281494
Validation loss: 2.392239942345568

Epoch: 5| Step: 7
Training loss: 2.669492721557617
Validation loss: 2.377753975570843

Epoch: 5| Step: 8
Training loss: 2.451237916946411
Validation loss: 2.3520270470649964

Epoch: 5| Step: 9
Training loss: 2.5355563163757324
Validation loss: 2.3467317088957755

Epoch: 5| Step: 10
Training loss: 2.101491928100586
Validation loss: 2.3372642455562467

Epoch: 159| Step: 0
Training loss: 3.308865785598755
Validation loss: 2.346371873732536

Epoch: 5| Step: 1
Training loss: 2.7505950927734375
Validation loss: 2.3571356381139448

Epoch: 5| Step: 2
Training loss: 2.8436532020568848
Validation loss: 2.3492191376224643

Epoch: 5| Step: 3
Training loss: 2.2372517585754395
Validation loss: 2.352525177822318

Epoch: 5| Step: 4
Training loss: 2.3198537826538086
Validation loss: 2.351795219605969

Epoch: 5| Step: 5
Training loss: 2.2643916606903076
Validation loss: 2.3599912428086802

Epoch: 5| Step: 6
Training loss: 2.5497498512268066
Validation loss: 2.3655719141806326

Epoch: 5| Step: 7
Training loss: 2.131621837615967
Validation loss: 2.3701689140771025

Epoch: 5| Step: 8
Training loss: 2.740821361541748
Validation loss: 2.3821473711280414

Epoch: 5| Step: 9
Training loss: 2.586935520172119
Validation loss: 2.397012428570819

Epoch: 5| Step: 10
Training loss: 2.8386783599853516
Validation loss: 2.3962892024747786

Epoch: 160| Step: 0
Training loss: 2.9192357063293457
Validation loss: 2.3899625834598335

Epoch: 5| Step: 1
Training loss: 3.134467840194702
Validation loss: 2.391679730466617

Epoch: 5| Step: 2
Training loss: 2.2454612255096436
Validation loss: 2.3837869333964523

Epoch: 5| Step: 3
Training loss: 3.0961127281188965
Validation loss: 2.3667837547999557

Epoch: 5| Step: 4
Training loss: 2.412868022918701
Validation loss: 2.3560895945436213

Epoch: 5| Step: 5
Training loss: 2.7304794788360596
Validation loss: 2.3483360198236283

Epoch: 5| Step: 6
Training loss: 2.102931261062622
Validation loss: 2.344295729873001

Epoch: 5| Step: 7
Training loss: 2.0400278568267822
Validation loss: 2.34123916779795

Epoch: 5| Step: 8
Training loss: 2.554060220718384
Validation loss: 2.3399694529912805

Epoch: 5| Step: 9
Training loss: 2.4753522872924805
Validation loss: 2.3343336287365166

Epoch: 5| Step: 10
Training loss: 2.54225492477417
Validation loss: 2.3306349169823433

Epoch: 161| Step: 0
Training loss: 2.8154804706573486
Validation loss: 2.3388664824988252

Epoch: 5| Step: 1
Training loss: 2.0154764652252197
Validation loss: 2.3400341349263347

Epoch: 5| Step: 2
Training loss: 2.5418102741241455
Validation loss: 2.345334888786398

Epoch: 5| Step: 3
Training loss: 2.5743889808654785
Validation loss: 2.3418481619127336

Epoch: 5| Step: 4
Training loss: 2.344115734100342
Validation loss: 2.3459436124370945

Epoch: 5| Step: 5
Training loss: 2.1807827949523926
Validation loss: 2.346287969619997

Epoch: 5| Step: 6
Training loss: 2.9521279335021973
Validation loss: 2.344261746252737

Epoch: 5| Step: 7
Training loss: 2.3974242210388184
Validation loss: 2.345914967598454

Epoch: 5| Step: 8
Training loss: 2.721001148223877
Validation loss: 2.3412598999597694

Epoch: 5| Step: 9
Training loss: 2.992392063140869
Validation loss: 2.350694989645353

Epoch: 5| Step: 10
Training loss: 2.8541500568389893
Validation loss: 2.340865969657898

Epoch: 162| Step: 0
Training loss: 2.249696969985962
Validation loss: 2.3523818087834183

Epoch: 5| Step: 1
Training loss: 2.774462938308716
Validation loss: 2.3618031753006803

Epoch: 5| Step: 2
Training loss: 2.498516798019409
Validation loss: 2.368141879317581

Epoch: 5| Step: 3
Training loss: 2.208724021911621
Validation loss: 2.4153185198383946

Epoch: 5| Step: 4
Training loss: 2.6902709007263184
Validation loss: 2.423346004178447

Epoch: 5| Step: 5
Training loss: 3.1073412895202637
Validation loss: 2.383875625107878

Epoch: 5| Step: 6
Training loss: 2.673513889312744
Validation loss: 2.3735676683405393

Epoch: 5| Step: 7
Training loss: 2.8458831310272217
Validation loss: 2.3481397577511367

Epoch: 5| Step: 8
Training loss: 2.8633830547332764
Validation loss: 2.33408700009828

Epoch: 5| Step: 9
Training loss: 2.3261733055114746
Validation loss: 2.3259133984965663

Epoch: 5| Step: 10
Training loss: 2.0342960357666016
Validation loss: 2.330978024390436

Epoch: 163| Step: 0
Training loss: 2.8903231620788574
Validation loss: 2.3266375833942043

Epoch: 5| Step: 1
Training loss: 3.051379919052124
Validation loss: 2.327529530371389

Epoch: 5| Step: 2
Training loss: 2.3982956409454346
Validation loss: 2.336935612463182

Epoch: 5| Step: 3
Training loss: 3.6314918994903564
Validation loss: 2.330035312201387

Epoch: 5| Step: 4
Training loss: 1.9180063009262085
Validation loss: 2.3307338017289356

Epoch: 5| Step: 5
Training loss: 2.7825369834899902
Validation loss: 2.334663170640187

Epoch: 5| Step: 6
Training loss: 2.5994415283203125
Validation loss: 2.337296898647021

Epoch: 5| Step: 7
Training loss: 1.5349172353744507
Validation loss: 2.349509136651152

Epoch: 5| Step: 8
Training loss: 2.4329288005828857
Validation loss: 2.3659888211116997

Epoch: 5| Step: 9
Training loss: 2.4066097736358643
Validation loss: 2.3609962847925003

Epoch: 5| Step: 10
Training loss: 2.7108278274536133
Validation loss: 2.3684236362416256

Epoch: 164| Step: 0
Training loss: 2.557628631591797
Validation loss: 2.3459954056688535

Epoch: 5| Step: 1
Training loss: 2.670417547225952
Validation loss: 2.342946119205926

Epoch: 5| Step: 2
Training loss: 2.7244174480438232
Validation loss: 2.3506401841358473

Epoch: 5| Step: 3
Training loss: 2.3697991371154785
Validation loss: 2.3446587644597536

Epoch: 5| Step: 4
Training loss: 2.189990282058716
Validation loss: 2.345399207966302

Epoch: 5| Step: 5
Training loss: 2.8598766326904297
Validation loss: 2.3529978772645355

Epoch: 5| Step: 6
Training loss: 2.014965772628784
Validation loss: 2.345379828124918

Epoch: 5| Step: 7
Training loss: 2.7095260620117188
Validation loss: 2.3318975356317337

Epoch: 5| Step: 8
Training loss: 2.065042734146118
Validation loss: 2.3220229533410843

Epoch: 5| Step: 9
Training loss: 2.492729663848877
Validation loss: 2.3279064855267926

Epoch: 5| Step: 10
Training loss: 3.6914656162261963
Validation loss: 2.3154907124016875

Epoch: 165| Step: 0
Training loss: 3.092068910598755
Validation loss: 2.3176289143100863

Epoch: 5| Step: 1
Training loss: 2.740086793899536
Validation loss: 2.3233853873386177

Epoch: 5| Step: 2
Training loss: 1.9041693210601807
Validation loss: 2.324961934038388

Epoch: 5| Step: 3
Training loss: 2.9250152111053467
Validation loss: 2.328802121582852

Epoch: 5| Step: 4
Training loss: 2.50966215133667
Validation loss: 2.327451585441507

Epoch: 5| Step: 5
Training loss: 2.388366222381592
Validation loss: 2.3239701101856847

Epoch: 5| Step: 6
Training loss: 1.8213688135147095
Validation loss: 2.326500936221051

Epoch: 5| Step: 7
Training loss: 2.5484414100646973
Validation loss: 2.3323416491990447

Epoch: 5| Step: 8
Training loss: 2.569857120513916
Validation loss: 2.3418105597137124

Epoch: 5| Step: 9
Training loss: 2.980191469192505
Validation loss: 2.3595815653442056

Epoch: 5| Step: 10
Training loss: 2.732052803039551
Validation loss: 2.376241937760384

Epoch: 166| Step: 0
Training loss: 2.8390393257141113
Validation loss: 2.400183641782371

Epoch: 5| Step: 1
Training loss: 2.5966289043426514
Validation loss: 2.3855375500135523

Epoch: 5| Step: 2
Training loss: 2.5240185260772705
Validation loss: 2.3873279453605734

Epoch: 5| Step: 3
Training loss: 2.394984006881714
Validation loss: 2.349698184638895

Epoch: 5| Step: 4
Training loss: 2.835172176361084
Validation loss: 2.3302257330186906

Epoch: 5| Step: 5
Training loss: 2.4192020893096924
Validation loss: 2.3260002443867345

Epoch: 5| Step: 6
Training loss: 3.1441829204559326
Validation loss: 2.32007017443257

Epoch: 5| Step: 7
Training loss: 1.8791353702545166
Validation loss: 2.3300455308729604

Epoch: 5| Step: 8
Training loss: 3.464634418487549
Validation loss: 2.3203987101072907

Epoch: 5| Step: 9
Training loss: 2.043841600418091
Validation loss: 2.3245920532493183

Epoch: 5| Step: 10
Training loss: 1.9708709716796875
Validation loss: 2.327815942866828

Epoch: 167| Step: 0
Training loss: 3.0204761028289795
Validation loss: 2.327048804170342

Epoch: 5| Step: 1
Training loss: 1.8534942865371704
Validation loss: 2.328621202899564

Epoch: 5| Step: 2
Training loss: 3.0414726734161377
Validation loss: 2.3221712496972855

Epoch: 5| Step: 3
Training loss: 2.6054818630218506
Validation loss: 2.3235249519348145

Epoch: 5| Step: 4
Training loss: 2.439042329788208
Validation loss: 2.3267940308458064

Epoch: 5| Step: 5
Training loss: 1.9780021905899048
Validation loss: 2.327669605132072

Epoch: 5| Step: 6
Training loss: 2.3891854286193848
Validation loss: 2.334941215412591

Epoch: 5| Step: 7
Training loss: 1.9507157802581787
Validation loss: 2.337289966562743

Epoch: 5| Step: 8
Training loss: 3.10243821144104
Validation loss: 2.3324680815460863

Epoch: 5| Step: 9
Training loss: 3.022249937057495
Validation loss: 2.3382069987635457

Epoch: 5| Step: 10
Training loss: 2.782133102416992
Validation loss: 2.3509390072156022

Epoch: 168| Step: 0
Training loss: 2.6184191703796387
Validation loss: 2.382758596891998

Epoch: 5| Step: 1
Training loss: 2.302885055541992
Validation loss: 2.3941216750811507

Epoch: 5| Step: 2
Training loss: 3.3945109844207764
Validation loss: 2.421093556188768

Epoch: 5| Step: 3
Training loss: 2.3060672283172607
Validation loss: 2.414699805680142

Epoch: 5| Step: 4
Training loss: 3.243903636932373
Validation loss: 2.4255334690052974

Epoch: 5| Step: 5
Training loss: 2.4465479850769043
Validation loss: 2.412905304662643

Epoch: 5| Step: 6
Training loss: 2.3707356452941895
Validation loss: 2.391509489346576

Epoch: 5| Step: 7
Training loss: 2.7470004558563232
Validation loss: 2.3688155425492154

Epoch: 5| Step: 8
Training loss: 2.6579055786132812
Validation loss: 2.3576204776763916

Epoch: 5| Step: 9
Training loss: 1.9794050455093384
Validation loss: 2.3495923370443363

Epoch: 5| Step: 10
Training loss: 2.3296496868133545
Validation loss: 2.3505097153366252

Epoch: 169| Step: 0
Training loss: 2.744314670562744
Validation loss: 2.339910181619788

Epoch: 5| Step: 1
Training loss: 2.8067874908447266
Validation loss: 2.3267593281243437

Epoch: 5| Step: 2
Training loss: 2.8315930366516113
Validation loss: 2.3353422944263746

Epoch: 5| Step: 3
Training loss: 2.2458443641662598
Validation loss: 2.337832156048026

Epoch: 5| Step: 4
Training loss: 2.3823437690734863
Validation loss: 2.3674355117223596

Epoch: 5| Step: 5
Training loss: 2.8951289653778076
Validation loss: 2.381013301111037

Epoch: 5| Step: 6
Training loss: 2.792163372039795
Validation loss: 2.38084404699264

Epoch: 5| Step: 7
Training loss: 2.3095173835754395
Validation loss: 2.355969927644217

Epoch: 5| Step: 8
Training loss: 2.2676703929901123
Validation loss: 2.357758588688348

Epoch: 5| Step: 9
Training loss: 2.589968204498291
Validation loss: 2.3466755215839674

Epoch: 5| Step: 10
Training loss: 2.4793412685394287
Validation loss: 2.3550198308883177

Epoch: 170| Step: 0
Training loss: 2.838840961456299
Validation loss: 2.3750172122832267

Epoch: 5| Step: 1
Training loss: 3.2470717430114746
Validation loss: 2.3701064304638932

Epoch: 5| Step: 2
Training loss: 2.4951560497283936
Validation loss: 2.34971349470077

Epoch: 5| Step: 3
Training loss: 2.2447896003723145
Validation loss: 2.3489312459063787

Epoch: 5| Step: 4
Training loss: 2.693755865097046
Validation loss: 2.337950539845292

Epoch: 5| Step: 5
Training loss: 2.3076205253601074
Validation loss: 2.33973668723978

Epoch: 5| Step: 6
Training loss: 1.8986936807632446
Validation loss: 2.343613060571814

Epoch: 5| Step: 7
Training loss: 2.428619623184204
Validation loss: 2.3430966895113707

Epoch: 5| Step: 8
Training loss: 2.099871873855591
Validation loss: 2.3458018610554356

Epoch: 5| Step: 9
Training loss: 3.3808281421661377
Validation loss: 2.3310453430298836

Epoch: 5| Step: 10
Training loss: 2.588602304458618
Validation loss: 2.3472660190315655

Epoch: 171| Step: 0
Training loss: 2.389535665512085
Validation loss: 2.3559143568879817

Epoch: 5| Step: 1
Training loss: 2.371248245239258
Validation loss: 2.3469336904505247

Epoch: 5| Step: 2
Training loss: 1.9995733499526978
Validation loss: 2.346302637489893

Epoch: 5| Step: 3
Training loss: 2.9829325675964355
Validation loss: 2.351463364016625

Epoch: 5| Step: 4
Training loss: 2.481858015060425
Validation loss: 2.3409705469685216

Epoch: 5| Step: 5
Training loss: 2.8094115257263184
Validation loss: 2.3402202155000422

Epoch: 5| Step: 6
Training loss: 2.897857904434204
Validation loss: 2.3336434877046974

Epoch: 5| Step: 7
Training loss: 2.6761889457702637
Validation loss: 2.322223722293813

Epoch: 5| Step: 8
Training loss: 2.1584718227386475
Validation loss: 2.323261401986563

Epoch: 5| Step: 9
Training loss: 3.189499616622925
Validation loss: 2.3381672777155393

Epoch: 5| Step: 10
Training loss: 2.1556661128997803
Validation loss: 2.3456968985578066

Epoch: 172| Step: 0
Training loss: 2.4466967582702637
Validation loss: 2.3627057536955802

Epoch: 5| Step: 1
Training loss: 2.2062172889709473
Validation loss: 2.386847379387066

Epoch: 5| Step: 2
Training loss: 2.5084052085876465
Validation loss: 2.3942294325879825

Epoch: 5| Step: 3
Training loss: 2.620168685913086
Validation loss: 2.4026098046251523

Epoch: 5| Step: 4
Training loss: 2.9806671142578125
Validation loss: 2.3876019934172272

Epoch: 5| Step: 5
Training loss: 2.5391783714294434
Validation loss: 2.354219986546424

Epoch: 5| Step: 6
Training loss: 2.7641751766204834
Validation loss: 2.3311979232295865

Epoch: 5| Step: 7
Training loss: 2.489013671875
Validation loss: 2.3151900640097995

Epoch: 5| Step: 8
Training loss: 2.5730113983154297
Validation loss: 2.302489821628858

Epoch: 5| Step: 9
Training loss: 2.7209815979003906
Validation loss: 2.300470554700462

Epoch: 5| Step: 10
Training loss: 2.3250906467437744
Validation loss: 2.303501272714266

Epoch: 173| Step: 0
Training loss: 2.877615213394165
Validation loss: 2.3080254511166642

Epoch: 5| Step: 1
Training loss: 2.663281202316284
Validation loss: 2.3124385674794516

Epoch: 5| Step: 2
Training loss: 1.8509018421173096
Validation loss: 2.313326984323481

Epoch: 5| Step: 3
Training loss: 2.2195403575897217
Validation loss: 2.3096220672771497

Epoch: 5| Step: 4
Training loss: 3.0750162601470947
Validation loss: 2.3048212143682663

Epoch: 5| Step: 5
Training loss: 2.8784499168395996
Validation loss: 2.306155494464341

Epoch: 5| Step: 6
Training loss: 2.896348237991333
Validation loss: 2.3254969889117825

Epoch: 5| Step: 7
Training loss: 2.9349067211151123
Validation loss: 2.3548490308946177

Epoch: 5| Step: 8
Training loss: 2.169019937515259
Validation loss: 2.3705792965427523

Epoch: 5| Step: 9
Training loss: 2.2805845737457275
Validation loss: 2.3939520364166587

Epoch: 5| Step: 10
Training loss: 2.56724214553833
Validation loss: 2.3989680710659234

Epoch: 174| Step: 0
Training loss: 3.141197443008423
Validation loss: 2.39073452385523

Epoch: 5| Step: 1
Training loss: 2.339824676513672
Validation loss: 2.373826344807943

Epoch: 5| Step: 2
Training loss: 3.155118465423584
Validation loss: 2.3384619528247463

Epoch: 5| Step: 3
Training loss: 2.4563281536102295
Validation loss: 2.319266532057075

Epoch: 5| Step: 4
Training loss: 1.884965181350708
Validation loss: 2.3148716188246206

Epoch: 5| Step: 5
Training loss: 1.9358704090118408
Validation loss: 2.302162456256087

Epoch: 5| Step: 6
Training loss: 2.761017322540283
Validation loss: 2.3047091243087605

Epoch: 5| Step: 7
Training loss: 2.263845920562744
Validation loss: 2.3011939551240657

Epoch: 5| Step: 8
Training loss: 2.9682364463806152
Validation loss: 2.2951487725780857

Epoch: 5| Step: 9
Training loss: 2.317988634109497
Validation loss: 2.3025155169989473

Epoch: 5| Step: 10
Training loss: 2.873086452484131
Validation loss: 2.2978092675567954

Epoch: 175| Step: 0
Training loss: 2.6457619667053223
Validation loss: 2.301460366095266

Epoch: 5| Step: 1
Training loss: 2.948040008544922
Validation loss: 2.2983870378104587

Epoch: 5| Step: 2
Training loss: 2.3204541206359863
Validation loss: 2.2980289843774613

Epoch: 5| Step: 3
Training loss: 2.217747449874878
Validation loss: 2.3083084398700344

Epoch: 5| Step: 4
Training loss: 2.847367286682129
Validation loss: 2.310458826762374

Epoch: 5| Step: 5
Training loss: 2.9842782020568848
Validation loss: 2.310935745957077

Epoch: 5| Step: 6
Training loss: 3.123215913772583
Validation loss: 2.313490826596496

Epoch: 5| Step: 7
Training loss: 2.1185145378112793
Validation loss: 2.308910733910017

Epoch: 5| Step: 8
Training loss: 2.224766969680786
Validation loss: 2.3180610313210437

Epoch: 5| Step: 9
Training loss: 2.350257396697998
Validation loss: 2.3285576348663657

Epoch: 5| Step: 10
Training loss: 2.036163091659546
Validation loss: 2.335826463596795

Epoch: 176| Step: 0
Training loss: 1.5238218307495117
Validation loss: 2.3422418691778697

Epoch: 5| Step: 1
Training loss: 2.4145097732543945
Validation loss: 2.3601113903907036

Epoch: 5| Step: 2
Training loss: 2.339564561843872
Validation loss: 2.379733101014168

Epoch: 5| Step: 3
Training loss: 2.7278034687042236
Validation loss: 2.3662376455081406

Epoch: 5| Step: 4
Training loss: 2.6263606548309326
Validation loss: 2.3355797542038785

Epoch: 5| Step: 5
Training loss: 2.9999887943267822
Validation loss: 2.3169064342334704

Epoch: 5| Step: 6
Training loss: 2.235752582550049
Validation loss: 2.3131031272231892

Epoch: 5| Step: 7
Training loss: 2.636122226715088
Validation loss: 2.3090763450950704

Epoch: 5| Step: 8
Training loss: 2.7880988121032715
Validation loss: 2.314659644198674

Epoch: 5| Step: 9
Training loss: 2.8848562240600586
Validation loss: 2.3110837449309645

Epoch: 5| Step: 10
Training loss: 2.8084945678710938
Validation loss: 2.3145683298828783

Epoch: 177| Step: 0
Training loss: 2.9410297870635986
Validation loss: 2.307347846287553

Epoch: 5| Step: 1
Training loss: 3.0367977619171143
Validation loss: 2.305754557732613

Epoch: 5| Step: 2
Training loss: 2.046271800994873
Validation loss: 2.301582528698829

Epoch: 5| Step: 3
Training loss: 2.6217193603515625
Validation loss: 2.289321671250046

Epoch: 5| Step: 4
Training loss: 2.218846559524536
Validation loss: 2.2947085929173294

Epoch: 5| Step: 5
Training loss: 2.385836601257324
Validation loss: 2.2938188224710445

Epoch: 5| Step: 6
Training loss: 1.7193759679794312
Validation loss: 2.299816326428485

Epoch: 5| Step: 7
Training loss: 3.156268358230591
Validation loss: 2.301094626867643

Epoch: 5| Step: 8
Training loss: 2.699212074279785
Validation loss: 2.3031220974460727

Epoch: 5| Step: 9
Training loss: 2.7177681922912598
Validation loss: 2.2953900521801365

Epoch: 5| Step: 10
Training loss: 2.3109047412872314
Validation loss: 2.3206535026591313

Epoch: 178| Step: 0
Training loss: 2.4264309406280518
Validation loss: 2.3188341766275387

Epoch: 5| Step: 1
Training loss: 2.430783271789551
Validation loss: 2.305268410713442

Epoch: 5| Step: 2
Training loss: 2.6598401069641113
Validation loss: 2.292758757068265

Epoch: 5| Step: 3
Training loss: 3.3258731365203857
Validation loss: 2.2892842728604554

Epoch: 5| Step: 4
Training loss: 2.7260069847106934
Validation loss: 2.2887692579659085

Epoch: 5| Step: 5
Training loss: 2.406282901763916
Validation loss: 2.2869432997959915

Epoch: 5| Step: 6
Training loss: 2.5885391235351562
Validation loss: 2.2917945743888937

Epoch: 5| Step: 7
Training loss: 2.5890088081359863
Validation loss: 2.2905115978692168

Epoch: 5| Step: 8
Training loss: 2.5417983531951904
Validation loss: 2.2904586843265

Epoch: 5| Step: 9
Training loss: 2.0272011756896973
Validation loss: 2.285499175389608

Epoch: 5| Step: 10
Training loss: 2.1628482341766357
Validation loss: 2.2883140169164187

Epoch: 179| Step: 0
Training loss: 2.031275749206543
Validation loss: 2.279209752236643

Epoch: 5| Step: 1
Training loss: 3.02158260345459
Validation loss: 2.2889903258251887

Epoch: 5| Step: 2
Training loss: 1.5163637399673462
Validation loss: 2.2938211861477105

Epoch: 5| Step: 3
Training loss: 1.8449382781982422
Validation loss: 2.324080809470146

Epoch: 5| Step: 4
Training loss: 3.2533187866210938
Validation loss: 2.350079313401253

Epoch: 5| Step: 5
Training loss: 1.9575388431549072
Validation loss: 2.3691542302408526

Epoch: 5| Step: 6
Training loss: 3.2514915466308594
Validation loss: 2.382093124492194

Epoch: 5| Step: 7
Training loss: 3.2370307445526123
Validation loss: 2.3793535847817697

Epoch: 5| Step: 8
Training loss: 1.8717247247695923
Validation loss: 2.3397865167228122

Epoch: 5| Step: 9
Training loss: 2.7907352447509766
Validation loss: 2.309138041670604

Epoch: 5| Step: 10
Training loss: 3.2967607975006104
Validation loss: 2.2936697236953245

Epoch: 180| Step: 0
Training loss: 2.4988646507263184
Validation loss: 2.2869142537475913

Epoch: 5| Step: 1
Training loss: 2.093632221221924
Validation loss: 2.2827850541760846

Epoch: 5| Step: 2
Training loss: 2.336348533630371
Validation loss: 2.2816094967626754

Epoch: 5| Step: 3
Training loss: 2.875450372695923
Validation loss: 2.282043892850158

Epoch: 5| Step: 4
Training loss: 1.740417718887329
Validation loss: 2.2759809263290895

Epoch: 5| Step: 5
Training loss: 2.6549816131591797
Validation loss: 2.2879622469666185

Epoch: 5| Step: 6
Training loss: 2.547423839569092
Validation loss: 2.2966031720561366

Epoch: 5| Step: 7
Training loss: 2.8155806064605713
Validation loss: 2.297527397832563

Epoch: 5| Step: 8
Training loss: 2.5311801433563232
Validation loss: 2.2956799794268865

Epoch: 5| Step: 9
Training loss: 3.0786871910095215
Validation loss: 2.2815478514599543

Epoch: 5| Step: 10
Training loss: 2.657817840576172
Validation loss: 2.2806079541483233

Epoch: 181| Step: 0
Training loss: 2.253513813018799
Validation loss: 2.284012508648698

Epoch: 5| Step: 1
Training loss: 1.9004755020141602
Validation loss: 2.2835306839276384

Epoch: 5| Step: 2
Training loss: 2.340923309326172
Validation loss: 2.2903883252092587

Epoch: 5| Step: 3
Training loss: 2.443239450454712
Validation loss: 2.2895098501636135

Epoch: 5| Step: 4
Training loss: 2.4941818714141846
Validation loss: 2.2892558420858076

Epoch: 5| Step: 5
Training loss: 2.187187910079956
Validation loss: 2.2975955317097325

Epoch: 5| Step: 6
Training loss: 2.5960490703582764
Validation loss: 2.318989953687114

Epoch: 5| Step: 7
Training loss: 2.9226553440093994
Validation loss: 2.3274885146848616

Epoch: 5| Step: 8
Training loss: 3.0655651092529297
Validation loss: 2.3548218050310687

Epoch: 5| Step: 9
Training loss: 3.5878453254699707
Validation loss: 2.3668501864197435

Epoch: 5| Step: 10
Training loss: 1.9610671997070312
Validation loss: 2.3317973383011354

Epoch: 182| Step: 0
Training loss: 2.3131136894226074
Validation loss: 2.294489417024838

Epoch: 5| Step: 1
Training loss: 2.1633048057556152
Validation loss: 2.2813626412422425

Epoch: 5| Step: 2
Training loss: 2.719813108444214
Validation loss: 2.2836304198029223

Epoch: 5| Step: 3
Training loss: 2.936030864715576
Validation loss: 2.284504102122399

Epoch: 5| Step: 4
Training loss: 2.490233898162842
Validation loss: 2.300689815193094

Epoch: 5| Step: 5
Training loss: 2.7615766525268555
Validation loss: 2.294572591781616

Epoch: 5| Step: 6
Training loss: 2.3555963039398193
Validation loss: 2.2792688313350884

Epoch: 5| Step: 7
Training loss: 2.431819200515747
Validation loss: 2.2780968168730378

Epoch: 5| Step: 8
Training loss: 2.2664847373962402
Validation loss: 2.280146309124526

Epoch: 5| Step: 9
Training loss: 2.6616897583007812
Validation loss: 2.2935574413627706

Epoch: 5| Step: 10
Training loss: 2.8115482330322266
Validation loss: 2.301864077967982

Epoch: 183| Step: 0
Training loss: 2.272256851196289
Validation loss: 2.3060617446899414

Epoch: 5| Step: 1
Training loss: 2.4402339458465576
Validation loss: 2.315069167844711

Epoch: 5| Step: 2
Training loss: 3.218780517578125
Validation loss: 2.3454182711980676

Epoch: 5| Step: 3
Training loss: 1.889655351638794
Validation loss: 2.3447033461704048

Epoch: 5| Step: 4
Training loss: 2.45536732673645
Validation loss: 2.3565288512937483

Epoch: 5| Step: 5
Training loss: 3.222796678543091
Validation loss: 2.330439470147574

Epoch: 5| Step: 6
Training loss: 2.532055139541626
Validation loss: 2.307999846755817

Epoch: 5| Step: 7
Training loss: 1.9770387411117554
Validation loss: 2.303557872772217

Epoch: 5| Step: 8
Training loss: 2.5751357078552246
Validation loss: 2.2911660927598194

Epoch: 5| Step: 9
Training loss: 2.8368210792541504
Validation loss: 2.293278737734723

Epoch: 5| Step: 10
Training loss: 2.273232936859131
Validation loss: 2.2825922504548104

Epoch: 184| Step: 0
Training loss: 2.0672945976257324
Validation loss: 2.2834465862602316

Epoch: 5| Step: 1
Training loss: 2.796375036239624
Validation loss: 2.2800803107600056

Epoch: 5| Step: 2
Training loss: 1.9934842586517334
Validation loss: 2.291831217786317

Epoch: 5| Step: 3
Training loss: 3.4717209339141846
Validation loss: 2.302767256254791

Epoch: 5| Step: 4
Training loss: 2.432591199874878
Validation loss: 2.3132508390693256

Epoch: 5| Step: 5
Training loss: 2.191751003265381
Validation loss: 2.3112908191578363

Epoch: 5| Step: 6
Training loss: 2.7698068618774414
Validation loss: 2.311946169022591

Epoch: 5| Step: 7
Training loss: 1.988917589187622
Validation loss: 2.2919373435358845

Epoch: 5| Step: 8
Training loss: 2.6916935443878174
Validation loss: 2.284324866469188

Epoch: 5| Step: 9
Training loss: 2.4003143310546875
Validation loss: 2.2771633927540114

Epoch: 5| Step: 10
Training loss: 3.221619129180908
Validation loss: 2.2835874865131993

Epoch: 185| Step: 0
Training loss: 2.291212558746338
Validation loss: 2.302258514588879

Epoch: 5| Step: 1
Training loss: 2.712629795074463
Validation loss: 2.3141664228131695

Epoch: 5| Step: 2
Training loss: 2.46317720413208
Validation loss: 2.3336092887386197

Epoch: 5| Step: 3
Training loss: 2.0547447204589844
Validation loss: 2.3617847042699016

Epoch: 5| Step: 4
Training loss: 2.6315553188323975
Validation loss: 2.3663163774756977

Epoch: 5| Step: 5
Training loss: 2.3836395740509033
Validation loss: 2.350176929145731

Epoch: 5| Step: 6
Training loss: 2.927696704864502
Validation loss: 2.3325192825768584

Epoch: 5| Step: 7
Training loss: 2.9763035774230957
Validation loss: 2.305041431098856

Epoch: 5| Step: 8
Training loss: 2.195383071899414
Validation loss: 2.282750542445849

Epoch: 5| Step: 9
Training loss: 2.7303779125213623
Validation loss: 2.2765690126726703

Epoch: 5| Step: 10
Training loss: 2.448685884475708
Validation loss: 2.2686484936744935

Epoch: 186| Step: 0
Training loss: 2.5588812828063965
Validation loss: 2.268970029328459

Epoch: 5| Step: 1
Training loss: 2.2398438453674316
Validation loss: 2.2726207599844983

Epoch: 5| Step: 2
Training loss: 2.7561631202697754
Validation loss: 2.2772225692708004

Epoch: 5| Step: 3
Training loss: 2.715179920196533
Validation loss: 2.288289846912507

Epoch: 5| Step: 4
Training loss: 1.9547569751739502
Validation loss: 2.2841593270660727

Epoch: 5| Step: 5
Training loss: 2.1763951778411865
Validation loss: 2.28094123512186

Epoch: 5| Step: 6
Training loss: 2.1876220703125
Validation loss: 2.2820096400476273

Epoch: 5| Step: 7
Training loss: 3.057875871658325
Validation loss: 2.270368796522899

Epoch: 5| Step: 8
Training loss: 2.9982247352600098
Validation loss: 2.280394196510315

Epoch: 5| Step: 9
Training loss: 2.636111259460449
Validation loss: 2.2971304590984056

Epoch: 5| Step: 10
Training loss: 2.517369508743286
Validation loss: 2.300493327520227

Epoch: 187| Step: 0
Training loss: 2.592623233795166
Validation loss: 2.3022380721184517

Epoch: 5| Step: 1
Training loss: 3.0390772819519043
Validation loss: 2.3097822871259464

Epoch: 5| Step: 2
Training loss: 2.2880802154541016
Validation loss: 2.3243123997924147

Epoch: 5| Step: 3
Training loss: 2.130657911300659
Validation loss: 2.3226565289241012

Epoch: 5| Step: 4
Training loss: 2.5066096782684326
Validation loss: 2.326571169719901

Epoch: 5| Step: 5
Training loss: 1.594680666923523
Validation loss: 2.3357089193918372

Epoch: 5| Step: 6
Training loss: 2.8995094299316406
Validation loss: 2.3295989933834282

Epoch: 5| Step: 7
Training loss: 2.3483500480651855
Validation loss: 2.3064119892735637

Epoch: 5| Step: 8
Training loss: 2.0923964977264404
Validation loss: 2.2968472075718704

Epoch: 5| Step: 9
Training loss: 3.439551591873169
Validation loss: 2.2928050179635324

Epoch: 5| Step: 10
Training loss: 2.675804376602173
Validation loss: 2.284532641851774

Epoch: 188| Step: 0
Training loss: 1.5784085988998413
Validation loss: 2.2775360102294595

Epoch: 5| Step: 1
Training loss: 2.5444674491882324
Validation loss: 2.2796241955090593

Epoch: 5| Step: 2
Training loss: 3.089604139328003
Validation loss: 2.280273791282408

Epoch: 5| Step: 3
Training loss: 2.449148654937744
Validation loss: 2.2901162024467223

Epoch: 5| Step: 4
Training loss: 1.9093633890151978
Validation loss: 2.2718363551683325

Epoch: 5| Step: 5
Training loss: 2.6318259239196777
Validation loss: 2.263873554045154

Epoch: 5| Step: 6
Training loss: 2.553730010986328
Validation loss: 2.270686739234514

Epoch: 5| Step: 7
Training loss: 3.318554639816284
Validation loss: 2.267943787318404

Epoch: 5| Step: 8
Training loss: 1.9827673435211182
Validation loss: 2.27338009495889

Epoch: 5| Step: 9
Training loss: 2.509082317352295
Validation loss: 2.263217128733153

Epoch: 5| Step: 10
Training loss: 2.969965934753418
Validation loss: 2.2578421151766213

Epoch: 189| Step: 0
Training loss: 2.3924553394317627
Validation loss: 2.2768732411887056

Epoch: 5| Step: 1
Training loss: 1.8970330953598022
Validation loss: 2.297579570483136

Epoch: 5| Step: 2
Training loss: 2.56140398979187
Validation loss: 2.3005409509904924

Epoch: 5| Step: 3
Training loss: 2.7750024795532227
Validation loss: 2.287816716778663

Epoch: 5| Step: 4
Training loss: 2.7377095222473145
Validation loss: 2.2804664052942747

Epoch: 5| Step: 5
Training loss: 2.5444650650024414
Validation loss: 2.2740455007040374

Epoch: 5| Step: 6
Training loss: 2.3634161949157715
Validation loss: 2.2711734925546954

Epoch: 5| Step: 7
Training loss: 2.366694688796997
Validation loss: 2.272093576769675

Epoch: 5| Step: 8
Training loss: 2.7429442405700684
Validation loss: 2.27685909886514

Epoch: 5| Step: 9
Training loss: 2.724503993988037
Validation loss: 2.2633633562313613

Epoch: 5| Step: 10
Training loss: 2.4119927883148193
Validation loss: 2.2628222383478636

Epoch: 190| Step: 0
Training loss: 2.3949999809265137
Validation loss: 2.2719451996587936

Epoch: 5| Step: 1
Training loss: 2.9059767723083496
Validation loss: 2.2655235900673816

Epoch: 5| Step: 2
Training loss: 2.8492989540100098
Validation loss: 2.269350900444933

Epoch: 5| Step: 3
Training loss: 2.4649083614349365
Validation loss: 2.2715859707965644

Epoch: 5| Step: 4
Training loss: 2.61492919921875
Validation loss: 2.263695442548362

Epoch: 5| Step: 5
Training loss: 1.4349143505096436
Validation loss: 2.265063690882857

Epoch: 5| Step: 6
Training loss: 3.1606318950653076
Validation loss: 2.2679029126321115

Epoch: 5| Step: 7
Training loss: 1.7535943984985352
Validation loss: 2.252781632126019

Epoch: 5| Step: 8
Training loss: 2.973569393157959
Validation loss: 2.265892956846504

Epoch: 5| Step: 9
Training loss: 2.6962831020355225
Validation loss: 2.26394711771319

Epoch: 5| Step: 10
Training loss: 2.0821101665496826
Validation loss: 2.2783331845396306

Epoch: 191| Step: 0
Training loss: 2.829540252685547
Validation loss: 2.3268049481094524

Epoch: 5| Step: 1
Training loss: 3.0960988998413086
Validation loss: 2.3391506902633177

Epoch: 5| Step: 2
Training loss: 2.4938132762908936
Validation loss: 2.3574472473513697

Epoch: 5| Step: 3
Training loss: 2.975900411605835
Validation loss: 2.3211554609319216

Epoch: 5| Step: 4
Training loss: 2.3736140727996826
Validation loss: 2.273149500611008

Epoch: 5| Step: 5
Training loss: 2.635420322418213
Validation loss: 2.2529898253820275

Epoch: 5| Step: 6
Training loss: 1.9449987411499023
Validation loss: 2.2474361568368892

Epoch: 5| Step: 7
Training loss: 2.208303928375244
Validation loss: 2.258890977469824

Epoch: 5| Step: 8
Training loss: 2.1866159439086914
Validation loss: 2.2523382376599055

Epoch: 5| Step: 9
Training loss: 2.264275074005127
Validation loss: 2.2653711072860228

Epoch: 5| Step: 10
Training loss: 2.649574041366577
Validation loss: 2.257805129533173

Epoch: 192| Step: 0
Training loss: 2.742783308029175
Validation loss: 2.262411855882214

Epoch: 5| Step: 1
Training loss: 2.463146686553955
Validation loss: 2.2579321989449124

Epoch: 5| Step: 2
Training loss: 2.4349539279937744
Validation loss: 2.2506803286972867

Epoch: 5| Step: 3
Training loss: 2.9913179874420166
Validation loss: 2.257966210765223

Epoch: 5| Step: 4
Training loss: 1.5992368459701538
Validation loss: 2.2525191845432406

Epoch: 5| Step: 5
Training loss: 2.0977180004119873
Validation loss: 2.253209472984396

Epoch: 5| Step: 6
Training loss: 2.2522597312927246
Validation loss: 2.2670893335855133

Epoch: 5| Step: 7
Training loss: 2.519056797027588
Validation loss: 2.28127791548288

Epoch: 5| Step: 8
Training loss: 2.5111727714538574
Validation loss: 2.29943169829666

Epoch: 5| Step: 9
Training loss: 3.0486629009246826
Validation loss: 2.309591083116429

Epoch: 5| Step: 10
Training loss: 2.862302780151367
Validation loss: 2.305875419288553

Epoch: 193| Step: 0
Training loss: 2.174678325653076
Validation loss: 2.3024316782592447

Epoch: 5| Step: 1
Training loss: 2.837674617767334
Validation loss: 2.2873090902964273

Epoch: 5| Step: 2
Training loss: 2.9550201892852783
Validation loss: 2.2713841238329486

Epoch: 5| Step: 3
Training loss: 2.9801666736602783
Validation loss: 2.2624382177988687

Epoch: 5| Step: 4
Training loss: 2.4621071815490723
Validation loss: 2.2544049063036518

Epoch: 5| Step: 5
Training loss: 2.5271754264831543
Validation loss: 2.2409609774107575

Epoch: 5| Step: 6
Training loss: 2.3866090774536133
Validation loss: 2.246277411778768

Epoch: 5| Step: 7
Training loss: 2.6330578327178955
Validation loss: 2.2513883344588743

Epoch: 5| Step: 8
Training loss: 2.0574538707733154
Validation loss: 2.2577265283112884

Epoch: 5| Step: 9
Training loss: 2.366535186767578
Validation loss: 2.2566397805367746

Epoch: 5| Step: 10
Training loss: 2.029327392578125
Validation loss: 2.25557214983048

Epoch: 194| Step: 0
Training loss: 2.2840826511383057
Validation loss: 2.251821187234694

Epoch: 5| Step: 1
Training loss: 2.5377471446990967
Validation loss: 2.274461523179085

Epoch: 5| Step: 2
Training loss: 2.6293067932128906
Validation loss: 2.2748879360896286

Epoch: 5| Step: 3
Training loss: 2.2237236499786377
Validation loss: 2.282489707393031

Epoch: 5| Step: 4
Training loss: 2.3148555755615234
Validation loss: 2.2858519143955682

Epoch: 5| Step: 5
Training loss: 2.432645082473755
Validation loss: 2.2814178261705624

Epoch: 5| Step: 6
Training loss: 3.087935209274292
Validation loss: 2.268953706628533

Epoch: 5| Step: 7
Training loss: 2.1974925994873047
Validation loss: 2.268845917076193

Epoch: 5| Step: 8
Training loss: 2.335742950439453
Validation loss: 2.2799553717336347

Epoch: 5| Step: 9
Training loss: 2.547393798828125
Validation loss: 2.2773692992425736

Epoch: 5| Step: 10
Training loss: 2.752639055252075
Validation loss: 2.273342404314267

Epoch: 195| Step: 0
Training loss: 2.6711134910583496
Validation loss: 2.257033291683402

Epoch: 5| Step: 1
Training loss: 2.261955499649048
Validation loss: 2.254477357351652

Epoch: 5| Step: 2
Training loss: 2.462174654006958
Validation loss: 2.264777329660231

Epoch: 5| Step: 3
Training loss: 2.564807415008545
Validation loss: 2.2721453071922384

Epoch: 5| Step: 4
Training loss: 2.1978392601013184
Validation loss: 2.282987274149413

Epoch: 5| Step: 5
Training loss: 2.4148190021514893
Validation loss: 2.2948869992327947

Epoch: 5| Step: 6
Training loss: 3.0136876106262207
Validation loss: 2.296784572703864

Epoch: 5| Step: 7
Training loss: 2.798551321029663
Validation loss: 2.276571258421867

Epoch: 5| Step: 8
Training loss: 2.4849159717559814
Validation loss: 2.265945326897406

Epoch: 5| Step: 9
Training loss: 2.917015790939331
Validation loss: 2.253090778986613

Epoch: 5| Step: 10
Training loss: 1.4567570686340332
Validation loss: 2.258314199345086

Epoch: 196| Step: 0
Training loss: 1.4041897058486938
Validation loss: 2.262260247302312

Epoch: 5| Step: 1
Training loss: 1.6549413204193115
Validation loss: 2.2764101361715667

Epoch: 5| Step: 2
Training loss: 2.4936413764953613
Validation loss: 2.273710253418133

Epoch: 5| Step: 3
Training loss: 2.283916711807251
Validation loss: 2.2673916329619703

Epoch: 5| Step: 4
Training loss: 1.9690576791763306
Validation loss: 2.2644944114069783

Epoch: 5| Step: 5
Training loss: 2.8274219036102295
Validation loss: 2.263382832209269

Epoch: 5| Step: 6
Training loss: 2.9744606018066406
Validation loss: 2.265140992338939

Epoch: 5| Step: 7
Training loss: 2.744481325149536
Validation loss: 2.2583163733123452

Epoch: 5| Step: 8
Training loss: 2.846317768096924
Validation loss: 2.262548141582038

Epoch: 5| Step: 9
Training loss: 2.8512237071990967
Validation loss: 2.2648606710536505

Epoch: 5| Step: 10
Training loss: 3.3526647090911865
Validation loss: 2.258660290830879

Epoch: 197| Step: 0
Training loss: 2.317625045776367
Validation loss: 2.260353393452142

Epoch: 5| Step: 1
Training loss: 2.9506068229675293
Validation loss: 2.2520581214658675

Epoch: 5| Step: 2
Training loss: 2.1389920711517334
Validation loss: 2.251799516780402

Epoch: 5| Step: 3
Training loss: 1.7781808376312256
Validation loss: 2.26225874757254

Epoch: 5| Step: 4
Training loss: 2.562960147857666
Validation loss: 2.2768783569335938

Epoch: 5| Step: 5
Training loss: 2.268132448196411
Validation loss: 2.2744663812780894

Epoch: 5| Step: 6
Training loss: 1.9574010372161865
Validation loss: 2.2924821569073583

Epoch: 5| Step: 7
Training loss: 2.6887454986572266
Validation loss: 2.310356375991657

Epoch: 5| Step: 8
Training loss: 3.02026629447937
Validation loss: 2.302477090589462

Epoch: 5| Step: 9
Training loss: 2.8468618392944336
Validation loss: 2.293377499426565

Epoch: 5| Step: 10
Training loss: 2.762681722640991
Validation loss: 2.2718418541774956

Epoch: 198| Step: 0
Training loss: 1.956486463546753
Validation loss: 2.2561483229360273

Epoch: 5| Step: 1
Training loss: 2.5550365447998047
Validation loss: 2.236418834296606

Epoch: 5| Step: 2
Training loss: 2.4516985416412354
Validation loss: 2.2394370314895466

Epoch: 5| Step: 3
Training loss: 2.658590316772461
Validation loss: 2.232152772206132

Epoch: 5| Step: 4
Training loss: 3.1263842582702637
Validation loss: 2.2377609822057907

Epoch: 5| Step: 5
Training loss: 1.9737708568572998
Validation loss: 2.2398917803200344

Epoch: 5| Step: 6
Training loss: 2.955975294113159
Validation loss: 2.239302183992119

Epoch: 5| Step: 7
Training loss: 2.2162086963653564
Validation loss: 2.2432428457403697

Epoch: 5| Step: 8
Training loss: 2.8257343769073486
Validation loss: 2.2538442252784647

Epoch: 5| Step: 9
Training loss: 1.6632026433944702
Validation loss: 2.282535784987993

Epoch: 5| Step: 10
Training loss: 2.9113106727600098
Validation loss: 2.2914931710048387

Epoch: 199| Step: 0
Training loss: 3.071441173553467
Validation loss: 2.2958208360979633

Epoch: 5| Step: 1
Training loss: 2.6282522678375244
Validation loss: 2.2902055530137915

Epoch: 5| Step: 2
Training loss: 2.6856746673583984
Validation loss: 2.2874945696964057

Epoch: 5| Step: 3
Training loss: 1.9964367151260376
Validation loss: 2.284854427460701

Epoch: 5| Step: 4
Training loss: 2.6396594047546387
Validation loss: 2.266933621898774

Epoch: 5| Step: 5
Training loss: 2.2978620529174805
Validation loss: 2.257208372956963

Epoch: 5| Step: 6
Training loss: 2.744650363922119
Validation loss: 2.260278227508709

Epoch: 5| Step: 7
Training loss: 2.3532919883728027
Validation loss: 2.2568429939208494

Epoch: 5| Step: 8
Training loss: 2.1756224632263184
Validation loss: 2.2527848469313754

Epoch: 5| Step: 9
Training loss: 2.368372917175293
Validation loss: 2.2509850776323708

Epoch: 5| Step: 10
Training loss: 2.185558557510376
Validation loss: 2.2443151679090274

Epoch: 200| Step: 0
Training loss: 2.4668312072753906
Validation loss: 2.2402905136026363

Epoch: 5| Step: 1
Training loss: 2.647502899169922
Validation loss: 2.2453771727059477

Epoch: 5| Step: 2
Training loss: 3.2296721935272217
Validation loss: 2.240044114410236

Epoch: 5| Step: 3
Training loss: 2.3619353771209717
Validation loss: 2.241854331826651

Epoch: 5| Step: 4
Training loss: 1.8951858282089233
Validation loss: 2.248332074893418

Epoch: 5| Step: 5
Training loss: 2.9481332302093506
Validation loss: 2.2457392805366108

Epoch: 5| Step: 6
Training loss: 2.177793502807617
Validation loss: 2.2402404277555403

Epoch: 5| Step: 7
Training loss: 2.024906635284424
Validation loss: 2.2395354368353404

Epoch: 5| Step: 8
Training loss: 2.6876003742218018
Validation loss: 2.2427898171127483

Epoch: 5| Step: 9
Training loss: 2.000105381011963
Validation loss: 2.241487703015727

Epoch: 5| Step: 10
Training loss: 2.6000919342041016
Validation loss: 2.2435247257191646

Epoch: 201| Step: 0
Training loss: 3.111297369003296
Validation loss: 2.236447165089269

Epoch: 5| Step: 1
Training loss: 2.9802846908569336
Validation loss: 2.2445886314556165

Epoch: 5| Step: 2
Training loss: 2.0682168006896973
Validation loss: 2.2388571359777965

Epoch: 5| Step: 3
Training loss: 2.6581838130950928
Validation loss: 2.2396119397173644

Epoch: 5| Step: 4
Training loss: 1.9590213298797607
Validation loss: 2.2360261127512944

Epoch: 5| Step: 5
Training loss: 2.697289228439331
Validation loss: 2.260478916988578

Epoch: 5| Step: 6
Training loss: 1.788268804550171
Validation loss: 2.2810524432889876

Epoch: 5| Step: 7
Training loss: 2.3903679847717285
Validation loss: 2.278342343145801

Epoch: 5| Step: 8
Training loss: 2.566652536392212
Validation loss: 2.2645295922474196

Epoch: 5| Step: 9
Training loss: 2.251072406768799
Validation loss: 2.243846120372895

Epoch: 5| Step: 10
Training loss: 2.5749552249908447
Validation loss: 2.226424965807187

Epoch: 202| Step: 0
Training loss: 2.019893169403076
Validation loss: 2.227917186675533

Epoch: 5| Step: 1
Training loss: 2.5599448680877686
Validation loss: 2.227868349321427

Epoch: 5| Step: 2
Training loss: 2.1105122566223145
Validation loss: 2.2416029848078245

Epoch: 5| Step: 3
Training loss: 2.4566597938537598
Validation loss: 2.2432121999802126

Epoch: 5| Step: 4
Training loss: 2.707521438598633
Validation loss: 2.248673205734581

Epoch: 5| Step: 5
Training loss: 1.8431650400161743
Validation loss: 2.255858129070651

Epoch: 5| Step: 6
Training loss: 2.260913848876953
Validation loss: 2.2472953488749843

Epoch: 5| Step: 7
Training loss: 3.020078182220459
Validation loss: 2.249753587989397

Epoch: 5| Step: 8
Training loss: 3.1918587684631348
Validation loss: 2.257766756960141

Epoch: 5| Step: 9
Training loss: 2.25661039352417
Validation loss: 2.28066147142841

Epoch: 5| Step: 10
Training loss: 2.5744192600250244
Validation loss: 2.299437625433809

Epoch: 203| Step: 0
Training loss: 2.7056407928466797
Validation loss: 2.2952029653774795

Epoch: 5| Step: 1
Training loss: 2.55338716506958
Validation loss: 2.2892466027249574

Epoch: 5| Step: 2
Training loss: 2.3959879875183105
Validation loss: 2.26675739852331

Epoch: 5| Step: 3
Training loss: 1.682882308959961
Validation loss: 2.2515876946910733

Epoch: 5| Step: 4
Training loss: 2.258739948272705
Validation loss: 2.2711074441991825

Epoch: 5| Step: 5
Training loss: 2.915250062942505
Validation loss: 2.2568299501172957

Epoch: 5| Step: 6
Training loss: 2.1121737957000732
Validation loss: 2.250448352547102

Epoch: 5| Step: 7
Training loss: 2.831083059310913
Validation loss: 2.2411697346677064

Epoch: 5| Step: 8
Training loss: 1.8375561237335205
Validation loss: 2.2421547494908816

Epoch: 5| Step: 9
Training loss: 2.8703126907348633
Validation loss: 2.236345911538729

Epoch: 5| Step: 10
Training loss: 2.7051620483398438
Validation loss: 2.232953671486147

Epoch: 204| Step: 0
Training loss: 3.1758227348327637
Validation loss: 2.2383318562661447

Epoch: 5| Step: 1
Training loss: 2.5518136024475098
Validation loss: 2.2339592108162503

Epoch: 5| Step: 2
Training loss: 1.7872416973114014
Validation loss: 2.2342095528879473

Epoch: 5| Step: 3
Training loss: 2.3813700675964355
Validation loss: 2.234338419411772

Epoch: 5| Step: 4
Training loss: 2.1207048892974854
Validation loss: 2.244184222272647

Epoch: 5| Step: 5
Training loss: 1.7914307117462158
Validation loss: 2.266047736649872

Epoch: 5| Step: 6
Training loss: 2.943057060241699
Validation loss: 2.2942951353647376

Epoch: 5| Step: 7
Training loss: 3.1023340225219727
Validation loss: 2.290249707878277

Epoch: 5| Step: 8
Training loss: 2.0181307792663574
Validation loss: 2.2758728611853813

Epoch: 5| Step: 9
Training loss: 1.9460121393203735
Validation loss: 2.2643631965883317

Epoch: 5| Step: 10
Training loss: 3.2404844760894775
Validation loss: 2.2659718169960925

Epoch: 205| Step: 0
Training loss: 2.512763261795044
Validation loss: 2.2458445487483853

Epoch: 5| Step: 1
Training loss: 2.4297451972961426
Validation loss: 2.2406684813960904

Epoch: 5| Step: 2
Training loss: 2.9064323902130127
Validation loss: 2.2380780250795427

Epoch: 5| Step: 3
Training loss: 2.6556711196899414
Validation loss: 2.2502825221707745

Epoch: 5| Step: 4
Training loss: 1.5936877727508545
Validation loss: 2.2483276449224

Epoch: 5| Step: 5
Training loss: 1.8377749919891357
Validation loss: 2.2353411874463482

Epoch: 5| Step: 6
Training loss: 2.7127089500427246
Validation loss: 2.236058532550771

Epoch: 5| Step: 7
Training loss: 3.001169443130493
Validation loss: 2.2441759724770822

Epoch: 5| Step: 8
Training loss: 2.516627788543701
Validation loss: 2.235226179963799

Epoch: 5| Step: 9
Training loss: 2.4048774242401123
Validation loss: 2.234659343637446

Epoch: 5| Step: 10
Training loss: 2.1911964416503906
Validation loss: 2.2353664559702717

Epoch: 206| Step: 0
Training loss: 2.4604952335357666
Validation loss: 2.2322768806129374

Epoch: 5| Step: 1
Training loss: 2.1024563312530518
Validation loss: 2.238446186947566

Epoch: 5| Step: 2
Training loss: 2.691314458847046
Validation loss: 2.2470826564296598

Epoch: 5| Step: 3
Training loss: 2.553312301635742
Validation loss: 2.2227289548484226

Epoch: 5| Step: 4
Training loss: 2.76985239982605
Validation loss: 2.2206691234342513

Epoch: 5| Step: 5
Training loss: 2.4666240215301514
Validation loss: 2.2129991746717885

Epoch: 5| Step: 6
Training loss: 2.8628334999084473
Validation loss: 2.2146933437675558

Epoch: 5| Step: 7
Training loss: 1.8297630548477173
Validation loss: 2.2158843381430513

Epoch: 5| Step: 8
Training loss: 2.2071309089660645
Validation loss: 2.21873890712697

Epoch: 5| Step: 9
Training loss: 2.535740375518799
Validation loss: 2.220390535170032

Epoch: 5| Step: 10
Training loss: 2.2243897914886475
Validation loss: 2.2219637158096477

Epoch: 207| Step: 0
Training loss: 2.4622445106506348
Validation loss: 2.2285897962508665

Epoch: 5| Step: 1
Training loss: 2.7789084911346436
Validation loss: 2.2286453657252814

Epoch: 5| Step: 2
Training loss: 2.266017198562622
Validation loss: 2.2280755530121508

Epoch: 5| Step: 3
Training loss: 2.4038069248199463
Validation loss: 2.243215009730349

Epoch: 5| Step: 4
Training loss: 2.5386321544647217
Validation loss: 2.2463602327531382

Epoch: 5| Step: 5
Training loss: 1.976443886756897
Validation loss: 2.258740953219834

Epoch: 5| Step: 6
Training loss: 2.411404848098755
Validation loss: 2.2766093874490387

Epoch: 5| Step: 7
Training loss: 2.774656295776367
Validation loss: 2.2902391982334915

Epoch: 5| Step: 8
Training loss: 3.1313071250915527
Validation loss: 2.300320394577519

Epoch: 5| Step: 9
Training loss: 1.8593566417694092
Validation loss: 2.2794011433919272

Epoch: 5| Step: 10
Training loss: 2.073438882827759
Validation loss: 2.2585386640282086

Epoch: 208| Step: 0
Training loss: 2.143636465072632
Validation loss: 2.2493410443746917

Epoch: 5| Step: 1
Training loss: 2.3306825160980225
Validation loss: 2.2396627651747836

Epoch: 5| Step: 2
Training loss: 2.370786190032959
Validation loss: 2.246348842497795

Epoch: 5| Step: 3
Training loss: 2.6600303649902344
Validation loss: 2.237833676799651

Epoch: 5| Step: 4
Training loss: 2.5417048931121826
Validation loss: 2.2419333329764743

Epoch: 5| Step: 5
Training loss: 3.382504940032959
Validation loss: 2.229021441551947

Epoch: 5| Step: 6
Training loss: 2.4001870155334473
Validation loss: 2.237862330611034

Epoch: 5| Step: 7
Training loss: 2.320075511932373
Validation loss: 2.230857474829561

Epoch: 5| Step: 8
Training loss: 2.304250478744507
Validation loss: 2.225396148620113

Epoch: 5| Step: 9
Training loss: 2.0087664127349854
Validation loss: 2.234728951607981

Epoch: 5| Step: 10
Training loss: 2.1636154651641846
Validation loss: 2.2465019687529533

Epoch: 209| Step: 0
Training loss: 2.188959836959839
Validation loss: 2.271221899217175

Epoch: 5| Step: 1
Training loss: 2.600468397140503
Validation loss: 2.274149020512899

Epoch: 5| Step: 2
Training loss: 2.59932541847229
Validation loss: 2.278900464375814

Epoch: 5| Step: 3
Training loss: 2.1988301277160645
Validation loss: 2.2638218300316924

Epoch: 5| Step: 4
Training loss: 2.213527202606201
Validation loss: 2.266384183719594

Epoch: 5| Step: 5
Training loss: 2.416048765182495
Validation loss: 2.260455592986076

Epoch: 5| Step: 6
Training loss: 2.5431175231933594
Validation loss: 2.2717421285567747

Epoch: 5| Step: 7
Training loss: 2.433866500854492
Validation loss: 2.266292127229834

Epoch: 5| Step: 8
Training loss: 2.6292824745178223
Validation loss: 2.2483423550923667

Epoch: 5| Step: 9
Training loss: 2.583845615386963
Validation loss: 2.2424335633554766

Epoch: 5| Step: 10
Training loss: 1.9102264642715454
Validation loss: 2.238527783783533

Epoch: 210| Step: 0
Training loss: 2.2189087867736816
Validation loss: 2.2405591857048774

Epoch: 5| Step: 1
Training loss: 3.360576629638672
Validation loss: 2.246641182130383

Epoch: 5| Step: 2
Training loss: 2.4233970642089844
Validation loss: 2.2666431473147486

Epoch: 5| Step: 3
Training loss: 2.288166046142578
Validation loss: 2.2556690990283923

Epoch: 5| Step: 4
Training loss: 2.381700277328491
Validation loss: 2.251151451500513

Epoch: 5| Step: 5
Training loss: 2.437373399734497
Validation loss: 2.246514456246489

Epoch: 5| Step: 6
Training loss: 2.500938892364502
Validation loss: 2.2406839145127164

Epoch: 5| Step: 7
Training loss: 2.2932677268981934
Validation loss: 2.254665759301955

Epoch: 5| Step: 8
Training loss: 2.048313617706299
Validation loss: 2.2776141628142326

Epoch: 5| Step: 9
Training loss: 2.459324598312378
Validation loss: 2.2805946873080347

Epoch: 5| Step: 10
Training loss: 2.0977866649627686
Validation loss: 2.28162282769398

Epoch: 211| Step: 0
Training loss: 2.379973888397217
Validation loss: 2.267193684013941

Epoch: 5| Step: 1
Training loss: 2.4454398155212402
Validation loss: 2.2784446977799937

Epoch: 5| Step: 2
Training loss: 3.0525758266448975
Validation loss: 2.2716442743937173

Epoch: 5| Step: 3
Training loss: 2.0943069458007812
Validation loss: 2.2906895734930552

Epoch: 5| Step: 4
Training loss: 1.8720452785491943
Validation loss: 2.2912237798013995

Epoch: 5| Step: 5
Training loss: 2.5500028133392334
Validation loss: 2.3107059719741985

Epoch: 5| Step: 6
Training loss: 2.901766300201416
Validation loss: 2.276116294245566

Epoch: 5| Step: 7
Training loss: 2.165497064590454
Validation loss: 2.2634854829439552

Epoch: 5| Step: 8
Training loss: 2.2109317779541016
Validation loss: 2.2438017629807994

Epoch: 5| Step: 9
Training loss: 2.861053943634033
Validation loss: 2.235920029301797

Epoch: 5| Step: 10
Training loss: 1.8990646600723267
Validation loss: 2.245730984595514

Epoch: 212| Step: 0
Training loss: 2.3944621086120605
Validation loss: 2.254167144016553

Epoch: 5| Step: 1
Training loss: 2.098543405532837
Validation loss: 2.2610064321948635

Epoch: 5| Step: 2
Training loss: 1.6218669414520264
Validation loss: 2.2599491893604235

Epoch: 5| Step: 3
Training loss: 2.503187894821167
Validation loss: 2.2919698697264477

Epoch: 5| Step: 4
Training loss: 3.023057460784912
Validation loss: 2.296405097489716

Epoch: 5| Step: 5
Training loss: 2.7721333503723145
Validation loss: 2.2871415820173038

Epoch: 5| Step: 6
Training loss: 2.825544595718384
Validation loss: 2.2667043209075928

Epoch: 5| Step: 7
Training loss: 2.1278281211853027
Validation loss: 2.24348355877784

Epoch: 5| Step: 8
Training loss: 2.6731979846954346
Validation loss: 2.2394275665283203

Epoch: 5| Step: 9
Training loss: 2.208045721054077
Validation loss: 2.2660394483996975

Epoch: 5| Step: 10
Training loss: 2.0804524421691895
Validation loss: 2.2610078755245415

Epoch: 213| Step: 0
Training loss: 2.582864761352539
Validation loss: 2.258685834946171

Epoch: 5| Step: 1
Training loss: 2.3536434173583984
Validation loss: 2.2374310826742523

Epoch: 5| Step: 2
Training loss: 2.7061851024627686
Validation loss: 2.2304264230112874

Epoch: 5| Step: 3
Training loss: 1.3720194101333618
Validation loss: 2.2456395651704524

Epoch: 5| Step: 4
Training loss: 2.6026158332824707
Validation loss: 2.240946549241261

Epoch: 5| Step: 5
Training loss: 2.7342939376831055
Validation loss: 2.252428072755055

Epoch: 5| Step: 6
Training loss: 1.6412395238876343
Validation loss: 2.2587653411332

Epoch: 5| Step: 7
Training loss: 2.624281406402588
Validation loss: 2.275387958813739

Epoch: 5| Step: 8
Training loss: 1.8993409872055054
Validation loss: 2.27650632140457

Epoch: 5| Step: 9
Training loss: 2.6126797199249268
Validation loss: 2.2774346259332474

Epoch: 5| Step: 10
Training loss: 3.280698299407959
Validation loss: 2.2526151108485397

Epoch: 214| Step: 0
Training loss: 2.405648708343506
Validation loss: 2.2273562774863294

Epoch: 5| Step: 1
Training loss: 2.6609435081481934
Validation loss: 2.2241394109623407

Epoch: 5| Step: 2
Training loss: 3.014526844024658
Validation loss: 2.1991803210268737

Epoch: 5| Step: 3
Training loss: 1.9458519220352173
Validation loss: 2.210206398399927

Epoch: 5| Step: 4
Training loss: 2.3245835304260254
Validation loss: 2.213668284877654

Epoch: 5| Step: 5
Training loss: 2.906973123550415
Validation loss: 2.220276076306579

Epoch: 5| Step: 6
Training loss: 2.867008686065674
Validation loss: 2.217899594255673

Epoch: 5| Step: 7
Training loss: 2.0627939701080322
Validation loss: 2.2126765122977634

Epoch: 5| Step: 8
Training loss: 1.9453468322753906
Validation loss: 2.224829840403731

Epoch: 5| Step: 9
Training loss: 1.8967901468276978
Validation loss: 2.24753281634341

Epoch: 5| Step: 10
Training loss: 2.1822474002838135
Validation loss: 2.266109743425923

Epoch: 215| Step: 0
Training loss: 2.246103048324585
Validation loss: 2.299986116347774

Epoch: 5| Step: 1
Training loss: 2.7742791175842285
Validation loss: 2.299809983981553

Epoch: 5| Step: 2
Training loss: 2.432954788208008
Validation loss: 2.296354753996736

Epoch: 5| Step: 3
Training loss: 2.571992874145508
Validation loss: 2.2869678517823577

Epoch: 5| Step: 4
Training loss: 2.4832468032836914
Validation loss: 2.2599218506966867

Epoch: 5| Step: 5
Training loss: 1.959296464920044
Validation loss: 2.2517829979619672

Epoch: 5| Step: 6
Training loss: 2.4480433464050293
Validation loss: 2.2421343736751105

Epoch: 5| Step: 7
Training loss: 1.8048206567764282
Validation loss: 2.2650289279158398

Epoch: 5| Step: 8
Training loss: 2.469804286956787
Validation loss: 2.25483956644612

Epoch: 5| Step: 9
Training loss: 2.728468179702759
Validation loss: 2.287410992448048

Epoch: 5| Step: 10
Training loss: 2.1904969215393066
Validation loss: 2.276198720419279

Epoch: 216| Step: 0
Training loss: 2.1181187629699707
Validation loss: 2.276184343522595

Epoch: 5| Step: 1
Training loss: 2.02375864982605
Validation loss: 2.2608545928873043

Epoch: 5| Step: 2
Training loss: 2.0499303340911865
Validation loss: 2.2760972925411758

Epoch: 5| Step: 3
Training loss: 2.5333750247955322
Validation loss: 2.255647781074688

Epoch: 5| Step: 4
Training loss: 2.716082811355591
Validation loss: 2.24756799205657

Epoch: 5| Step: 5
Training loss: 2.336644411087036
Validation loss: 2.24555064529501

Epoch: 5| Step: 6
Training loss: 2.817373752593994
Validation loss: 2.233284781056066

Epoch: 5| Step: 7
Training loss: 2.7889628410339355
Validation loss: 2.234955915840723

Epoch: 5| Step: 8
Training loss: 2.055962324142456
Validation loss: 2.2271122009523454

Epoch: 5| Step: 9
Training loss: 2.413776397705078
Validation loss: 2.245635450527232

Epoch: 5| Step: 10
Training loss: 2.1639323234558105
Validation loss: 2.2305802247857534

Epoch: 217| Step: 0
Training loss: 2.4888713359832764
Validation loss: 2.222813642153176

Epoch: 5| Step: 1
Training loss: 2.012469530105591
Validation loss: 2.212040698656472

Epoch: 5| Step: 2
Training loss: 2.174351215362549
Validation loss: 2.2239988811554445

Epoch: 5| Step: 3
Training loss: 2.067791223526001
Validation loss: 2.2267208304456485

Epoch: 5| Step: 4
Training loss: 2.9096500873565674
Validation loss: 2.2431200191538823

Epoch: 5| Step: 5
Training loss: 1.8882029056549072
Validation loss: 2.234792891369071

Epoch: 5| Step: 6
Training loss: 2.3324344158172607
Validation loss: 2.2406790102681806

Epoch: 5| Step: 7
Training loss: 2.617079973220825
Validation loss: 2.2412436957000406

Epoch: 5| Step: 8
Training loss: 2.807114601135254
Validation loss: 2.2604280979402605

Epoch: 5| Step: 9
Training loss: 1.9192920923233032
Validation loss: 2.2512151502793833

Epoch: 5| Step: 10
Training loss: 2.547118902206421
Validation loss: 2.2583834253331667

Epoch: 218| Step: 0
Training loss: 2.5272488594055176
Validation loss: 2.2609980824173137

Epoch: 5| Step: 1
Training loss: 2.186541795730591
Validation loss: 2.2563349354651665

Epoch: 5| Step: 2
Training loss: 1.9918521642684937
Validation loss: 2.265631342446932

Epoch: 5| Step: 3
Training loss: 2.2186598777770996
Validation loss: 2.255247405780259

Epoch: 5| Step: 4
Training loss: 2.6266438961029053
Validation loss: 2.264703034072794

Epoch: 5| Step: 5
Training loss: 2.784079074859619
Validation loss: 2.261669874191284

Epoch: 5| Step: 6
Training loss: 2.136859178543091
Validation loss: 2.243912842965895

Epoch: 5| Step: 7
Training loss: 2.1435165405273438
Validation loss: 2.24182899280261

Epoch: 5| Step: 8
Training loss: 1.9466111660003662
Validation loss: 2.2479383099463677

Epoch: 5| Step: 9
Training loss: 2.553114652633667
Validation loss: 2.270529857245825

Epoch: 5| Step: 10
Training loss: 2.7905094623565674
Validation loss: 2.24945221665085

Epoch: 219| Step: 0
Training loss: 1.984235167503357
Validation loss: 2.2591857974247267

Epoch: 5| Step: 1
Training loss: 2.4487032890319824
Validation loss: 2.244545236710579

Epoch: 5| Step: 2
Training loss: 1.9481115341186523
Validation loss: 2.238113567393313

Epoch: 5| Step: 3
Training loss: 2.3287763595581055
Validation loss: 2.24284016957847

Epoch: 5| Step: 4
Training loss: 2.2073721885681152
Validation loss: 2.237089700596307

Epoch: 5| Step: 5
Training loss: 3.0182089805603027
Validation loss: 2.2224435883183635

Epoch: 5| Step: 6
Training loss: 2.2087647914886475
Validation loss: 2.2417190510739564

Epoch: 5| Step: 7
Training loss: 1.9621444940567017
Validation loss: 2.238924562290151

Epoch: 5| Step: 8
Training loss: 2.183013916015625
Validation loss: 2.2415359302233626

Epoch: 5| Step: 9
Training loss: 2.3311171531677246
Validation loss: 2.2521064076372372

Epoch: 5| Step: 10
Training loss: 3.1717641353607178
Validation loss: 2.2583837739882933

Epoch: 220| Step: 0
Training loss: 2.6470484733581543
Validation loss: 2.239917711545062

Epoch: 5| Step: 1
Training loss: 3.234508991241455
Validation loss: 2.232839210059053

Epoch: 5| Step: 2
Training loss: 2.220916271209717
Validation loss: 2.2232600899152857

Epoch: 5| Step: 3
Training loss: 2.0597147941589355
Validation loss: 2.2161881590402253

Epoch: 5| Step: 4
Training loss: 1.9376318454742432
Validation loss: 2.230143065093666

Epoch: 5| Step: 5
Training loss: 2.1680660247802734
Validation loss: 2.2178303272493425

Epoch: 5| Step: 6
Training loss: 2.2895939350128174
Validation loss: 2.221722049097861

Epoch: 5| Step: 7
Training loss: 1.9705536365509033
Validation loss: 2.2235092168213217

Epoch: 5| Step: 8
Training loss: 1.8701995611190796
Validation loss: 2.2320854843303723

Epoch: 5| Step: 9
Training loss: 2.59018874168396
Validation loss: 2.2335116055703934

Epoch: 5| Step: 10
Training loss: 2.5805294513702393
Validation loss: 2.219873179671585

Epoch: 221| Step: 0
Training loss: 3.1482224464416504
Validation loss: 2.229643024424071

Epoch: 5| Step: 1
Training loss: 2.133697032928467
Validation loss: 2.223232744842447

Epoch: 5| Step: 2
Training loss: 1.6093114614486694
Validation loss: 2.2259681891369563

Epoch: 5| Step: 3
Training loss: 2.329331159591675
Validation loss: 2.223774992009645

Epoch: 5| Step: 4
Training loss: 2.212035894393921
Validation loss: 2.2431028965980775

Epoch: 5| Step: 5
Training loss: 1.524167776107788
Validation loss: 2.2560510071375037

Epoch: 5| Step: 6
Training loss: 2.9064409732818604
Validation loss: 2.2795809058732885

Epoch: 5| Step: 7
Training loss: 2.6544852256774902
Validation loss: 2.272411587417767

Epoch: 5| Step: 8
Training loss: 2.4563212394714355
Validation loss: 2.2583505440783758

Epoch: 5| Step: 9
Training loss: 2.398789882659912
Validation loss: 2.250042138561126

Epoch: 5| Step: 10
Training loss: 2.159592390060425
Validation loss: 2.2333985118455786

Epoch: 222| Step: 0
Training loss: 2.7112395763397217
Validation loss: 2.2329584783123386

Epoch: 5| Step: 1
Training loss: 2.498213291168213
Validation loss: 2.2264145112806752

Epoch: 5| Step: 2
Training loss: 2.1898810863494873
Validation loss: 2.2241043736857753

Epoch: 5| Step: 3
Training loss: 2.0196609497070312
Validation loss: 2.212040252583001

Epoch: 5| Step: 4
Training loss: 2.8890087604522705
Validation loss: 2.213951433858564

Epoch: 5| Step: 5
Training loss: 1.6831696033477783
Validation loss: 2.2154240095487205

Epoch: 5| Step: 6
Training loss: 1.9213390350341797
Validation loss: 2.220189720071772

Epoch: 5| Step: 7
Training loss: 1.5158377885818481
Validation loss: 2.267948199343938

Epoch: 5| Step: 8
Training loss: 3.299037456512451
Validation loss: 2.286931550630959

Epoch: 5| Step: 9
Training loss: 2.9388949871063232
Validation loss: 2.316842422690443

Epoch: 5| Step: 10
Training loss: 1.8208545446395874
Validation loss: 2.309724079665317

Epoch: 223| Step: 0
Training loss: 2.054004192352295
Validation loss: 2.2843644567715224

Epoch: 5| Step: 1
Training loss: 2.175672769546509
Validation loss: 2.2794285192284534

Epoch: 5| Step: 2
Training loss: 2.6970303058624268
Validation loss: 2.303593724004684

Epoch: 5| Step: 3
Training loss: 2.2485954761505127
Validation loss: 2.2987515413632957

Epoch: 5| Step: 4
Training loss: 2.6748061180114746
Validation loss: 2.285273717295739

Epoch: 5| Step: 5
Training loss: 2.4458839893341064
Validation loss: 2.252057049864082

Epoch: 5| Step: 6
Training loss: 2.129554271697998
Validation loss: 2.232032173423357

Epoch: 5| Step: 7
Training loss: 3.105844497680664
Validation loss: 2.2167466417435677

Epoch: 5| Step: 8
Training loss: 2.5898826122283936
Validation loss: 2.209888078833139

Epoch: 5| Step: 9
Training loss: 1.843557596206665
Validation loss: 2.2076991040219545

Epoch: 5| Step: 10
Training loss: 1.6967248916625977
Validation loss: 2.2178987892725135

Epoch: 224| Step: 0
Training loss: 1.8877556324005127
Validation loss: 2.2187513048930834

Epoch: 5| Step: 1
Training loss: 2.5035996437072754
Validation loss: 2.2287607680084887

Epoch: 5| Step: 2
Training loss: 2.7617430686950684
Validation loss: 2.2168640475119314

Epoch: 5| Step: 3
Training loss: 1.999333143234253
Validation loss: 2.2080406232546737

Epoch: 5| Step: 4
Training loss: 1.9019092321395874
Validation loss: 2.2162707313414542

Epoch: 5| Step: 5
Training loss: 2.122302532196045
Validation loss: 2.215312025880301

Epoch: 5| Step: 6
Training loss: 2.3956456184387207
Validation loss: 2.2280074729714343

Epoch: 5| Step: 7
Training loss: 2.6303153038024902
Validation loss: 2.2323105412144817

Epoch: 5| Step: 8
Training loss: 2.4374587535858154
Validation loss: 2.2301977936939528

Epoch: 5| Step: 9
Training loss: 2.1156814098358154
Validation loss: 2.259127547664027

Epoch: 5| Step: 10
Training loss: 2.7154102325439453
Validation loss: 2.2815841269749466

Epoch: 225| Step: 0
Training loss: 2.356459856033325
Validation loss: 2.2893851495558217

Epoch: 5| Step: 1
Training loss: 1.4676973819732666
Validation loss: 2.302688967797064

Epoch: 5| Step: 2
Training loss: 2.4672293663024902
Validation loss: 2.32142972946167

Epoch: 5| Step: 3
Training loss: 2.438844919204712
Validation loss: 2.314406018103323

Epoch: 5| Step: 4
Training loss: 2.8361940383911133
Validation loss: 2.2887768181421424

Epoch: 5| Step: 5
Training loss: 2.349182605743408
Validation loss: 2.2682422771248767

Epoch: 5| Step: 6
Training loss: 2.685544967651367
Validation loss: 2.251780281784714

Epoch: 5| Step: 7
Training loss: 2.2288548946380615
Validation loss: 2.2365774544336463

Epoch: 5| Step: 8
Training loss: 2.3355507850646973
Validation loss: 2.238603276591147

Epoch: 5| Step: 9
Training loss: 1.9555981159210205
Validation loss: 2.215828279013275

Epoch: 5| Step: 10
Training loss: 2.300018787384033
Validation loss: 2.2054579488692747

Epoch: 226| Step: 0
Training loss: 2.3282971382141113
Validation loss: 2.205525816127818

Epoch: 5| Step: 1
Training loss: 2.769336223602295
Validation loss: 2.2025708280583864

Epoch: 5| Step: 2
Training loss: 2.5683388710021973
Validation loss: 2.207354704538981

Epoch: 5| Step: 3
Training loss: 2.4366753101348877
Validation loss: 2.2067985278303905

Epoch: 5| Step: 4
Training loss: 1.9519484043121338
Validation loss: 2.2132580767395678

Epoch: 5| Step: 5
Training loss: 2.505805492401123
Validation loss: 2.2208298713930192

Epoch: 5| Step: 6
Training loss: 2.174193859100342
Validation loss: 2.241228207465141

Epoch: 5| Step: 7
Training loss: 1.9128906726837158
Validation loss: 2.2598030387714343

Epoch: 5| Step: 8
Training loss: 2.038796901702881
Validation loss: 2.2639040613687165

Epoch: 5| Step: 9
Training loss: 1.8074067831039429
Validation loss: 2.267501231162779

Epoch: 5| Step: 10
Training loss: 2.967064619064331
Validation loss: 2.283479090659849

Epoch: 227| Step: 0
Training loss: 2.005052328109741
Validation loss: 2.283233686160016

Epoch: 5| Step: 1
Training loss: 2.0352139472961426
Validation loss: 2.2725255899531867

Epoch: 5| Step: 2
Training loss: 3.1721625328063965
Validation loss: 2.2681522959022113

Epoch: 5| Step: 3
Training loss: 2.451014995574951
Validation loss: 2.2667189721138246

Epoch: 5| Step: 4
Training loss: 2.625458240509033
Validation loss: 2.2510865298650597

Epoch: 5| Step: 5
Training loss: 2.15559720993042
Validation loss: 2.2458247933336484

Epoch: 5| Step: 6
Training loss: 2.6230924129486084
Validation loss: 2.2279484066911923

Epoch: 5| Step: 7
Training loss: 1.580373764038086
Validation loss: 2.216533767279758

Epoch: 5| Step: 8
Training loss: 2.140256643295288
Validation loss: 2.2266623614936747

Epoch: 5| Step: 9
Training loss: 1.9780051708221436
Validation loss: 2.2333142539506317

Epoch: 5| Step: 10
Training loss: 2.456904649734497
Validation loss: 2.215044916317027

Epoch: 228| Step: 0
Training loss: 1.9290142059326172
Validation loss: 2.211619997537264

Epoch: 5| Step: 1
Training loss: 2.1823251247406006
Validation loss: 2.2200643734265397

Epoch: 5| Step: 2
Training loss: 2.677060604095459
Validation loss: 2.2195197100280435

Epoch: 5| Step: 3
Training loss: 2.2787728309631348
Validation loss: 2.234676778957408

Epoch: 5| Step: 4
Training loss: 2.6287591457366943
Validation loss: 2.2155112630577496

Epoch: 5| Step: 5
Training loss: 2.234649658203125
Validation loss: 2.2160318795070855

Epoch: 5| Step: 6
Training loss: 1.82246994972229
Validation loss: 2.22360094260144

Epoch: 5| Step: 7
Training loss: 2.162328004837036
Validation loss: 2.2207067512696788

Epoch: 5| Step: 8
Training loss: 2.388763427734375
Validation loss: 2.2278168688538256

Epoch: 5| Step: 9
Training loss: 1.9797643423080444
Validation loss: 2.2271967805841917

Epoch: 5| Step: 10
Training loss: 2.7439322471618652
Validation loss: 2.2370606942843367

Epoch: 229| Step: 0
Training loss: 1.985999345779419
Validation loss: 2.256820773565641

Epoch: 5| Step: 1
Training loss: 1.9407179355621338
Validation loss: 2.263659090124151

Epoch: 5| Step: 2
Training loss: 2.3820018768310547
Validation loss: 2.2510342546688613

Epoch: 5| Step: 3
Training loss: 1.5359019041061401
Validation loss: 2.2499235496726087

Epoch: 5| Step: 4
Training loss: 2.9481987953186035
Validation loss: 2.2471571635174494

Epoch: 5| Step: 5
Training loss: 2.1848316192626953
Validation loss: 2.227362157196127

Epoch: 5| Step: 6
Training loss: 2.548544406890869
Validation loss: 2.238940144097933

Epoch: 5| Step: 7
Training loss: 2.5914454460144043
Validation loss: 2.2349734562699513

Epoch: 5| Step: 8
Training loss: 2.181694507598877
Validation loss: 2.223770582547752

Epoch: 5| Step: 9
Training loss: 2.309039354324341
Validation loss: 2.231236101478659

Epoch: 5| Step: 10
Training loss: 2.3286216259002686
Validation loss: 2.2302411499843804

Epoch: 230| Step: 0
Training loss: 1.624050498008728
Validation loss: 2.2526364300840642

Epoch: 5| Step: 1
Training loss: 2.8760766983032227
Validation loss: 2.2534466904978596

Epoch: 5| Step: 2
Training loss: 2.3022267818450928
Validation loss: 2.2602480842221166

Epoch: 5| Step: 3
Training loss: 2.2974331378936768
Validation loss: 2.2688649315987863

Epoch: 5| Step: 4
Training loss: 2.284790277481079
Validation loss: 2.2797543502623037

Epoch: 5| Step: 5
Training loss: 2.517294406890869
Validation loss: 2.2835552589867705

Epoch: 5| Step: 6
Training loss: 1.785936951637268
Validation loss: 2.2511111690152075

Epoch: 5| Step: 7
Training loss: 2.1504645347595215
Validation loss: 2.2618139841223277

Epoch: 5| Step: 8
Training loss: 2.4118971824645996
Validation loss: 2.261959307937212

Epoch: 5| Step: 9
Training loss: 2.4605937004089355
Validation loss: 2.255195199802358

Epoch: 5| Step: 10
Training loss: 2.273087739944458
Validation loss: 2.263009491787162

Epoch: 231| Step: 0
Training loss: 2.5829215049743652
Validation loss: 2.256038655516922

Epoch: 5| Step: 1
Training loss: 1.5874584913253784
Validation loss: 2.2447934368605256

Epoch: 5| Step: 2
Training loss: 3.045659303665161
Validation loss: 2.241856551939441

Epoch: 5| Step: 3
Training loss: 2.0965981483459473
Validation loss: 2.2355516418333976

Epoch: 5| Step: 4
Training loss: 2.2122244834899902
Validation loss: 2.2506184257486814

Epoch: 5| Step: 5
Training loss: 2.586298942565918
Validation loss: 2.251593335982292

Epoch: 5| Step: 6
Training loss: 1.7019011974334717
Validation loss: 2.2411255708304783

Epoch: 5| Step: 7
Training loss: 1.6763086318969727
Validation loss: 2.23376065428539

Epoch: 5| Step: 8
Training loss: 2.459786891937256
Validation loss: 2.2314303485296105

Epoch: 5| Step: 9
Training loss: 2.7274937629699707
Validation loss: 2.225349146832702

Epoch: 5| Step: 10
Training loss: 2.140719413757324
Validation loss: 2.225446431867538

Epoch: 232| Step: 0
Training loss: 2.71960186958313
Validation loss: 2.2476010502025647

Epoch: 5| Step: 1
Training loss: 2.450003147125244
Validation loss: 2.2652867506909113

Epoch: 5| Step: 2
Training loss: 2.1980857849121094
Validation loss: 2.289336389110934

Epoch: 5| Step: 3
Training loss: 2.3325600624084473
Validation loss: 2.330421850245486

Epoch: 5| Step: 4
Training loss: 1.9023182392120361
Validation loss: 2.33416473737327

Epoch: 5| Step: 5
Training loss: 2.303206443786621
Validation loss: 2.3260232786978445

Epoch: 5| Step: 6
Training loss: 2.1394073963165283
Validation loss: 2.3309594520958523

Epoch: 5| Step: 7
Training loss: 2.2565176486968994
Validation loss: 2.3124478042766614

Epoch: 5| Step: 8
Training loss: 2.0707874298095703
Validation loss: 2.2954283683530745

Epoch: 5| Step: 9
Training loss: 2.431105852127075
Validation loss: 2.2842173883991856

Epoch: 5| Step: 10
Training loss: 2.0009663105010986
Validation loss: 2.2582728939671672

Epoch: 233| Step: 0
Training loss: 2.0682244300842285
Validation loss: 2.2480171162595033

Epoch: 5| Step: 1
Training loss: 2.133526086807251
Validation loss: 2.2424336812829457

Epoch: 5| Step: 2
Training loss: 2.029153823852539
Validation loss: 2.244008869253179

Epoch: 5| Step: 3
Training loss: 2.1180715560913086
Validation loss: 2.252422264827195

Epoch: 5| Step: 4
Training loss: 2.121194362640381
Validation loss: 2.245873712724255

Epoch: 5| Step: 5
Training loss: 2.484238386154175
Validation loss: 2.2464582689346804

Epoch: 5| Step: 6
Training loss: 2.1132659912109375
Validation loss: 2.2398859224011822

Epoch: 5| Step: 7
Training loss: 2.6794304847717285
Validation loss: 2.236710407400644

Epoch: 5| Step: 8
Training loss: 2.567772626876831
Validation loss: 2.2457937771274197

Epoch: 5| Step: 9
Training loss: 2.0886893272399902
Validation loss: 2.24537242099803

Epoch: 5| Step: 10
Training loss: 2.231200933456421
Validation loss: 2.2481963070490028

Epoch: 234| Step: 0
Training loss: 2.5115082263946533
Validation loss: 2.2347358067830405

Epoch: 5| Step: 1
Training loss: 2.9465670585632324
Validation loss: 2.2460799396678968

Epoch: 5| Step: 2
Training loss: 1.4806877374649048
Validation loss: 2.234862530103294

Epoch: 5| Step: 3
Training loss: 2.5202860832214355
Validation loss: 2.23915256479735

Epoch: 5| Step: 4
Training loss: 2.5824427604675293
Validation loss: 2.2323692434577533

Epoch: 5| Step: 5
Training loss: 2.5711822509765625
Validation loss: 2.2235654823241697

Epoch: 5| Step: 6
Training loss: 1.6254138946533203
Validation loss: 2.219620017595189

Epoch: 5| Step: 7
Training loss: 2.4050097465515137
Validation loss: 2.222720464070638

Epoch: 5| Step: 8
Training loss: 2.3639445304870605
Validation loss: 2.221304033392219

Epoch: 5| Step: 9
Training loss: 1.7445236444473267
Validation loss: 2.238490322584747

Epoch: 5| Step: 10
Training loss: 1.8656812906265259
Validation loss: 2.255069745484219

Epoch: 235| Step: 0
Training loss: 2.684596300125122
Validation loss: 2.2656840714075233

Epoch: 5| Step: 1
Training loss: 2.3374550342559814
Validation loss: 2.2755731075040755

Epoch: 5| Step: 2
Training loss: 2.3554115295410156
Validation loss: 2.2946085955507014

Epoch: 5| Step: 3
Training loss: 1.9706138372421265
Validation loss: 2.309850421003116

Epoch: 5| Step: 4
Training loss: 1.884191870689392
Validation loss: 2.3012252366670998

Epoch: 5| Step: 5
Training loss: 1.8201110363006592
Validation loss: 2.2919967482166905

Epoch: 5| Step: 6
Training loss: 2.1333630084991455
Validation loss: 2.2661902366145963

Epoch: 5| Step: 7
Training loss: 1.6695148944854736
Validation loss: 2.2412212382080736

Epoch: 5| Step: 8
Training loss: 2.657815456390381
Validation loss: 2.220732437667026

Epoch: 5| Step: 9
Training loss: 2.7732768058776855
Validation loss: 2.2169353218488794

Epoch: 5| Step: 10
Training loss: 2.150527000427246
Validation loss: 2.2211610809449227

Epoch: 236| Step: 0
Training loss: 2.6920270919799805
Validation loss: 2.20438572155532

Epoch: 5| Step: 1
Training loss: 2.2504303455352783
Validation loss: 2.182399598501062

Epoch: 5| Step: 2
Training loss: 2.3939380645751953
Validation loss: 2.17593785255186

Epoch: 5| Step: 3
Training loss: 2.5436549186706543
Validation loss: 2.1982607328763573

Epoch: 5| Step: 4
Training loss: 2.126781940460205
Validation loss: 2.2048997930301133

Epoch: 5| Step: 5
Training loss: 2.758925676345825
Validation loss: 2.2283623872264737

Epoch: 5| Step: 6
Training loss: 2.6462578773498535
Validation loss: 2.2415746360696773

Epoch: 5| Step: 7
Training loss: 1.571863055229187
Validation loss: 2.2323053703513196

Epoch: 5| Step: 8
Training loss: 1.7588361501693726
Validation loss: 2.2371616466071016

Epoch: 5| Step: 9
Training loss: 1.8655107021331787
Validation loss: 2.2151851948871406

Epoch: 5| Step: 10
Training loss: 1.9912676811218262
Validation loss: 2.2200319741361882

Epoch: 237| Step: 0
Training loss: 2.4432435035705566
Validation loss: 2.24118290152601

Epoch: 5| Step: 1
Training loss: 1.911393165588379
Validation loss: 2.2235588258312595

Epoch: 5| Step: 2
Training loss: 2.483029842376709
Validation loss: 2.2256128147084224

Epoch: 5| Step: 3
Training loss: 1.95168936252594
Validation loss: 2.2182038727627007

Epoch: 5| Step: 4
Training loss: 1.9848995208740234
Validation loss: 2.214824661131828

Epoch: 5| Step: 5
Training loss: 2.212648868560791
Validation loss: 2.233942695843276

Epoch: 5| Step: 6
Training loss: 2.294731616973877
Validation loss: 2.2399167245434177

Epoch: 5| Step: 7
Training loss: 2.5965042114257812
Validation loss: 2.271941566980013

Epoch: 5| Step: 8
Training loss: 2.0898232460021973
Validation loss: 2.258300583849671

Epoch: 5| Step: 9
Training loss: 2.9786922931671143
Validation loss: 2.231911895095661

Epoch: 5| Step: 10
Training loss: 1.5760568380355835
Validation loss: 2.228352859456052

Epoch: 238| Step: 0
Training loss: 1.9909934997558594
Validation loss: 2.2305582441309446

Epoch: 5| Step: 1
Training loss: 2.134887218475342
Validation loss: 2.2249353495977258

Epoch: 5| Step: 2
Training loss: 2.755356550216675
Validation loss: 2.2094697336996756

Epoch: 5| Step: 3
Training loss: 2.5832183361053467
Validation loss: 2.2136036708790767

Epoch: 5| Step: 4
Training loss: 2.784228801727295
Validation loss: 2.2337561179232854

Epoch: 5| Step: 5
Training loss: 1.8878810405731201
Validation loss: 2.2251860633973153

Epoch: 5| Step: 6
Training loss: 2.002074718475342
Validation loss: 2.238045146388392

Epoch: 5| Step: 7
Training loss: 2.114901304244995
Validation loss: 2.2368729050441454

Epoch: 5| Step: 8
Training loss: 1.40609610080719
Validation loss: 2.2370923770371305

Epoch: 5| Step: 9
Training loss: 2.7051138877868652
Validation loss: 2.238168852303618

Epoch: 5| Step: 10
Training loss: 1.9397367238998413
Validation loss: 2.2539536273607643

Epoch: 239| Step: 0
Training loss: 2.262575626373291
Validation loss: 2.2554934281174854

Epoch: 5| Step: 1
Training loss: 1.908780813217163
Validation loss: 2.2507932647582023

Epoch: 5| Step: 2
Training loss: 2.5044591426849365
Validation loss: 2.2502535414952103

Epoch: 5| Step: 3
Training loss: 2.848710536956787
Validation loss: 2.223137281274283

Epoch: 5| Step: 4
Training loss: 2.3057847023010254
Validation loss: 2.206793042921251

Epoch: 5| Step: 5
Training loss: 1.7160804271697998
Validation loss: 2.196352906124566

Epoch: 5| Step: 6
Training loss: 2.297736644744873
Validation loss: 2.1943087859820296

Epoch: 5| Step: 7
Training loss: 2.0717697143554688
Validation loss: 2.1834571579451203

Epoch: 5| Step: 8
Training loss: 2.612316608428955
Validation loss: 2.18601292948569

Epoch: 5| Step: 9
Training loss: 1.9851106405258179
Validation loss: 2.2030495341106127

Epoch: 5| Step: 10
Training loss: 1.9351377487182617
Validation loss: 2.2393907680306384

Epoch: 240| Step: 0
Training loss: 2.6295948028564453
Validation loss: 2.222295104816396

Epoch: 5| Step: 1
Training loss: 1.5753988027572632
Validation loss: 2.2242766323909966

Epoch: 5| Step: 2
Training loss: 3.1816928386688232
Validation loss: 2.219238358159219

Epoch: 5| Step: 3
Training loss: 2.0715200901031494
Validation loss: 2.2237899341890888

Epoch: 5| Step: 4
Training loss: 2.2020339965820312
Validation loss: 2.208477812428628

Epoch: 5| Step: 5
Training loss: 2.34121036529541
Validation loss: 2.2033372540627756

Epoch: 5| Step: 6
Training loss: 1.820039987564087
Validation loss: 2.2008758462885374

Epoch: 5| Step: 7
Training loss: 1.9355833530426025
Validation loss: 2.199990487867786

Epoch: 5| Step: 8
Training loss: 2.5778212547302246
Validation loss: 2.203183235660676

Epoch: 5| Step: 9
Training loss: 1.7875480651855469
Validation loss: 2.212038986144527

Epoch: 5| Step: 10
Training loss: 2.229555130004883
Validation loss: 2.229776244009695

Epoch: 241| Step: 0
Training loss: 2.3215763568878174
Validation loss: 2.237268881131244

Epoch: 5| Step: 1
Training loss: 1.697933554649353
Validation loss: 2.249262802062496

Epoch: 5| Step: 2
Training loss: 2.225560188293457
Validation loss: 2.2508995866262786

Epoch: 5| Step: 3
Training loss: 2.4722752571105957
Validation loss: 2.2647576947366037

Epoch: 5| Step: 4
Training loss: 2.630993366241455
Validation loss: 2.2262574524007817

Epoch: 5| Step: 5
Training loss: 1.8049659729003906
Validation loss: 2.2350232242256083

Epoch: 5| Step: 6
Training loss: 2.0154688358306885
Validation loss: 2.2160890179295696

Epoch: 5| Step: 7
Training loss: 1.7799899578094482
Validation loss: 2.215487136635729

Epoch: 5| Step: 8
Training loss: 2.1114113330841064
Validation loss: 2.225655577516043

Epoch: 5| Step: 9
Training loss: 3.0127434730529785
Validation loss: 2.2128830699510473

Epoch: 5| Step: 10
Training loss: 1.930798888206482
Validation loss: 2.208194173792357

Epoch: 242| Step: 0
Training loss: 2.112912178039551
Validation loss: 2.214950810196579

Epoch: 5| Step: 1
Training loss: 2.240093946456909
Validation loss: 2.1997310922991846

Epoch: 5| Step: 2
Training loss: 2.3582940101623535
Validation loss: 2.1951743684789187

Epoch: 5| Step: 3
Training loss: 2.7594637870788574
Validation loss: 2.2060743019145024

Epoch: 5| Step: 4
Training loss: 2.155377149581909
Validation loss: 2.2222628849808888

Epoch: 5| Step: 5
Training loss: 2.222174882888794
Validation loss: 2.2107497812599264

Epoch: 5| Step: 6
Training loss: 2.4987006187438965
Validation loss: 2.238252765388899

Epoch: 5| Step: 7
Training loss: 1.920440435409546
Validation loss: 2.2430534311520156

Epoch: 5| Step: 8
Training loss: 1.805776596069336
Validation loss: 2.2422963521813832

Epoch: 5| Step: 9
Training loss: 1.7255853414535522
Validation loss: 2.242158071969145

Epoch: 5| Step: 10
Training loss: 2.152085781097412
Validation loss: 2.2442127555929203

Epoch: 243| Step: 0
Training loss: 1.7906286716461182
Validation loss: 2.22527329896086

Epoch: 5| Step: 1
Training loss: 1.817787528038025
Validation loss: 2.224903593781174

Epoch: 5| Step: 2
Training loss: 2.128244400024414
Validation loss: 2.2262597981319634

Epoch: 5| Step: 3
Training loss: 2.1309781074523926
Validation loss: 2.2335301471012894

Epoch: 5| Step: 4
Training loss: 2.1926331520080566
Validation loss: 2.235943058485626

Epoch: 5| Step: 5
Training loss: 2.0146374702453613
Validation loss: 2.2206256722891204

Epoch: 5| Step: 6
Training loss: 2.561460256576538
Validation loss: 2.2113209334752892

Epoch: 5| Step: 7
Training loss: 2.088543653488159
Validation loss: 2.2149944382329143

Epoch: 5| Step: 8
Training loss: 2.764038562774658
Validation loss: 2.202545272406711

Epoch: 5| Step: 9
Training loss: 2.186879873275757
Validation loss: 2.217281013406733

Epoch: 5| Step: 10
Training loss: 2.233999013900757
Validation loss: 2.2220193160477506

Epoch: 244| Step: 0
Training loss: 2.662177562713623
Validation loss: 2.2126098038047872

Epoch: 5| Step: 1
Training loss: 1.9511420726776123
Validation loss: 2.2329461702736477

Epoch: 5| Step: 2
Training loss: 1.6551450490951538
Validation loss: 2.2433303761225876

Epoch: 5| Step: 3
Training loss: 1.855065107345581
Validation loss: 2.220325505861672

Epoch: 5| Step: 4
Training loss: 2.114868640899658
Validation loss: 2.1935640253046507

Epoch: 5| Step: 5
Training loss: 2.5713226795196533
Validation loss: 2.195025690140263

Epoch: 5| Step: 6
Training loss: 2.3573575019836426
Validation loss: 2.1850912058225243

Epoch: 5| Step: 7
Training loss: 2.1926472187042236
Validation loss: 2.2070293195786013

Epoch: 5| Step: 8
Training loss: 1.9855153560638428
Validation loss: 2.2050382783336024

Epoch: 5| Step: 9
Training loss: 2.487391471862793
Validation loss: 2.21309567523259

Epoch: 5| Step: 10
Training loss: 1.949939489364624
Validation loss: 2.220853328704834

Epoch: 245| Step: 0
Training loss: 2.1083273887634277
Validation loss: 2.228589524504959

Epoch: 5| Step: 1
Training loss: 2.2337348461151123
Validation loss: 2.249266375777542

Epoch: 5| Step: 2
Training loss: 2.4005391597747803
Validation loss: 2.2693039858213035

Epoch: 5| Step: 3
Training loss: 2.0285844802856445
Validation loss: 2.269509694909537

Epoch: 5| Step: 4
Training loss: 2.9769370555877686
Validation loss: 2.2918649758062055

Epoch: 5| Step: 5
Training loss: 2.2965328693389893
Validation loss: 2.302431533413549

Epoch: 5| Step: 6
Training loss: 1.7134864330291748
Validation loss: 2.3003983830892913

Epoch: 5| Step: 7
Training loss: 2.244495391845703
Validation loss: 2.298961383040233

Epoch: 5| Step: 8
Training loss: 1.9035263061523438
Validation loss: 2.272176875863024

Epoch: 5| Step: 9
Training loss: 1.9279632568359375
Validation loss: 2.2630826734727427

Epoch: 5| Step: 10
Training loss: 1.8124797344207764
Validation loss: 2.2357853740774174

Epoch: 246| Step: 0
Training loss: 2.1286516189575195
Validation loss: 2.2234300028893257

Epoch: 5| Step: 1
Training loss: 2.279388904571533
Validation loss: 2.209069795505975

Epoch: 5| Step: 2
Training loss: 2.328336715698242
Validation loss: 2.205654316051032

Epoch: 5| Step: 3
Training loss: 1.8959274291992188
Validation loss: 2.218513475951328

Epoch: 5| Step: 4
Training loss: 1.8757603168487549
Validation loss: 2.205159887190788

Epoch: 5| Step: 5
Training loss: 1.507079839706421
Validation loss: 2.209688742955526

Epoch: 5| Step: 6
Training loss: 2.2918858528137207
Validation loss: 2.2185582114804174

Epoch: 5| Step: 7
Training loss: 2.1619534492492676
Validation loss: 2.21021665552611

Epoch: 5| Step: 8
Training loss: 2.308107852935791
Validation loss: 2.23073491742534

Epoch: 5| Step: 9
Training loss: 2.4121005535125732
Validation loss: 2.2378109988345893

Epoch: 5| Step: 10
Training loss: 2.4096343517303467
Validation loss: 2.2047014146722774

Epoch: 247| Step: 0
Training loss: 2.4013404846191406
Validation loss: 2.1967162573209373

Epoch: 5| Step: 1
Training loss: 2.3528194427490234
Validation loss: 2.187202968905049

Epoch: 5| Step: 2
Training loss: 2.592298984527588
Validation loss: 2.2145893881397862

Epoch: 5| Step: 3
Training loss: 2.070751905441284
Validation loss: 2.2311257534129645

Epoch: 5| Step: 4
Training loss: 2.5159287452697754
Validation loss: 2.2248355496314263

Epoch: 5| Step: 5
Training loss: 1.7097241878509521
Validation loss: 2.233065010398947

Epoch: 5| Step: 6
Training loss: 1.4548425674438477
Validation loss: 2.233251522946101

Epoch: 5| Step: 7
Training loss: 2.0800657272338867
Validation loss: 2.252478540584605

Epoch: 5| Step: 8
Training loss: 2.8609578609466553
Validation loss: 2.291744032213765

Epoch: 5| Step: 9
Training loss: 1.7762176990509033
Validation loss: 2.3045714875703216

Epoch: 5| Step: 10
Training loss: 1.6104062795639038
Validation loss: 2.287071522846017

Epoch: 248| Step: 0
Training loss: 1.885611891746521
Validation loss: 2.2784838586725216

Epoch: 5| Step: 1
Training loss: 1.9853624105453491
Validation loss: 2.254136800765991

Epoch: 5| Step: 2
Training loss: 2.4331929683685303
Validation loss: 2.2207522738364434

Epoch: 5| Step: 3
Training loss: 2.772602081298828
Validation loss: 2.1869005054555912

Epoch: 5| Step: 4
Training loss: 2.1247246265411377
Validation loss: 2.173525725641558

Epoch: 5| Step: 5
Training loss: 2.3616690635681152
Validation loss: 2.1877884967352754

Epoch: 5| Step: 6
Training loss: 1.845693588256836
Validation loss: 2.204587403164115

Epoch: 5| Step: 7
Training loss: 2.163222551345825
Validation loss: 2.213539518335814

Epoch: 5| Step: 8
Training loss: 1.6768877506256104
Validation loss: 2.2103931237292547

Epoch: 5| Step: 9
Training loss: 1.8814334869384766
Validation loss: 2.219525316710113

Epoch: 5| Step: 10
Training loss: 2.577120065689087
Validation loss: 2.2144205160038446

Epoch: 249| Step: 0
Training loss: 2.074733257293701
Validation loss: 2.243170856147684

Epoch: 5| Step: 1
Training loss: 2.900388240814209
Validation loss: 2.2579620525401127

Epoch: 5| Step: 2
Training loss: 2.026414394378662
Validation loss: 2.245062130753712

Epoch: 5| Step: 3
Training loss: 1.9685996770858765
Validation loss: 2.250252575002691

Epoch: 5| Step: 4
Training loss: 2.2050588130950928
Validation loss: 2.2617142008196924

Epoch: 5| Step: 5
Training loss: 2.212258815765381
Validation loss: 2.2368730075897707

Epoch: 5| Step: 6
Training loss: 1.9457870721817017
Validation loss: 2.223092696999991

Epoch: 5| Step: 7
Training loss: 1.3696887493133545
Validation loss: 2.2154444020281554

Epoch: 5| Step: 8
Training loss: 2.175245523452759
Validation loss: 2.1980816753961707

Epoch: 5| Step: 9
Training loss: 2.136669874191284
Validation loss: 2.1754267523365636

Epoch: 5| Step: 10
Training loss: 2.3552865982055664
Validation loss: 2.193705056303291

Epoch: 250| Step: 0
Training loss: 2.2797536849975586
Validation loss: 2.2139700894714682

Epoch: 5| Step: 1
Training loss: 1.8660320043563843
Validation loss: 2.2370100175180743

Epoch: 5| Step: 2
Training loss: 1.8567514419555664
Validation loss: 2.254398592056767

Epoch: 5| Step: 3
Training loss: 1.5879383087158203
Validation loss: 2.2565582798373316

Epoch: 5| Step: 4
Training loss: 2.0709900856018066
Validation loss: 2.2706245350581344

Epoch: 5| Step: 5
Training loss: 2.298898458480835
Validation loss: 2.2693310373572895

Epoch: 5| Step: 6
Training loss: 1.9533857107162476
Validation loss: 2.246306014317338

Epoch: 5| Step: 7
Training loss: 1.5275100469589233
Validation loss: 2.2319649316931285

Epoch: 5| Step: 8
Training loss: 2.2466139793395996
Validation loss: 2.224545983858006

Epoch: 5| Step: 9
Training loss: 2.6447741985321045
Validation loss: 2.228043830522927

Epoch: 5| Step: 10
Training loss: 2.882430076599121
Validation loss: 2.2095395339432584

Epoch: 251| Step: 0
Training loss: 1.9199132919311523
Validation loss: 2.207399659259345

Epoch: 5| Step: 1
Training loss: 2.0914466381073
Validation loss: 2.195344178907333

Epoch: 5| Step: 2
Training loss: 1.759559988975525
Validation loss: 2.2138208471318728

Epoch: 5| Step: 3
Training loss: 1.9901173114776611
Validation loss: 2.2110031804730816

Epoch: 5| Step: 4
Training loss: 2.5987439155578613
Validation loss: 2.218335978446468

Epoch: 5| Step: 5
Training loss: 1.7867457866668701
Validation loss: 2.2054682188136603

Epoch: 5| Step: 6
Training loss: 3.0677316188812256
Validation loss: 2.2073905519259873

Epoch: 5| Step: 7
Training loss: 1.5341371297836304
Validation loss: 2.2121200561523438

Epoch: 5| Step: 8
Training loss: 2.068575620651245
Validation loss: 2.2175175836009364

Epoch: 5| Step: 9
Training loss: 2.222414016723633
Validation loss: 2.2142178217569985

Epoch: 5| Step: 10
Training loss: 1.927805781364441
Validation loss: 2.2249382849662536

Epoch: 252| Step: 0
Training loss: 2.4878764152526855
Validation loss: 2.2352815289651193

Epoch: 5| Step: 1
Training loss: 2.114419937133789
Validation loss: 2.2652061985385035

Epoch: 5| Step: 2
Training loss: 2.089139938354492
Validation loss: 2.27717258596933

Epoch: 5| Step: 3
Training loss: 2.147078275680542
Validation loss: 2.286502448461389

Epoch: 5| Step: 4
Training loss: 2.0123348236083984
Validation loss: 2.3178170675872476

Epoch: 5| Step: 5
Training loss: 1.2777763605117798
Validation loss: 2.316843883965605

Epoch: 5| Step: 6
Training loss: 2.6919453144073486
Validation loss: 2.3058060241001908

Epoch: 5| Step: 7
Training loss: 2.349363088607788
Validation loss: 2.3018542207697386

Epoch: 5| Step: 8
Training loss: 1.634295105934143
Validation loss: 2.3059638520722747

Epoch: 5| Step: 9
Training loss: 2.0009353160858154
Validation loss: 2.287249388233308

Epoch: 5| Step: 10
Training loss: 1.933381199836731
Validation loss: 2.252587200492941

Epoch: 253| Step: 0
Training loss: 1.7242988348007202
Validation loss: 2.2018996438672467

Epoch: 5| Step: 1
Training loss: 2.5519306659698486
Validation loss: 2.1860412846329393

Epoch: 5| Step: 2
Training loss: 2.683131456375122
Validation loss: 2.1656880429995957

Epoch: 5| Step: 3
Training loss: 2.1236019134521484
Validation loss: 2.1585830180875716

Epoch: 5| Step: 4
Training loss: 1.9403358697891235
Validation loss: 2.1542892122781403

Epoch: 5| Step: 5
Training loss: 1.363023042678833
Validation loss: 2.14468708602331

Epoch: 5| Step: 6
Training loss: 1.8599077463150024
Validation loss: 2.1469227447304675

Epoch: 5| Step: 7
Training loss: 2.0365490913391113
Validation loss: 2.176296390512938

Epoch: 5| Step: 8
Training loss: 2.3666300773620605
Validation loss: 2.2012978164098596

Epoch: 5| Step: 9
Training loss: 2.4025063514709473
Validation loss: 2.2146764237393617

Epoch: 5| Step: 10
Training loss: 1.9079973697662354
Validation loss: 2.215684624128444

Epoch: 254| Step: 0
Training loss: 1.8725754022598267
Validation loss: 2.225769110905227

Epoch: 5| Step: 1
Training loss: 2.037335157394409
Validation loss: 2.269582825322305

Epoch: 5| Step: 2
Training loss: 2.0512096881866455
Validation loss: 2.307645643911054

Epoch: 5| Step: 3
Training loss: 2.2130093574523926
Validation loss: 2.2955563619572628

Epoch: 5| Step: 4
Training loss: 1.920355200767517
Validation loss: 2.305692184355951

Epoch: 5| Step: 5
Training loss: 2.1396098136901855
Validation loss: 2.3089512830139487

Epoch: 5| Step: 6
Training loss: 2.613990306854248
Validation loss: 2.282302248862482

Epoch: 5| Step: 7
Training loss: 1.9394382238388062
Validation loss: 2.233823037916614

Epoch: 5| Step: 8
Training loss: 1.9862674474716187
Validation loss: 2.1911169610997683

Epoch: 5| Step: 9
Training loss: 2.3530447483062744
Validation loss: 2.1704867450139855

Epoch: 5| Step: 10
Training loss: 1.6302233934402466
Validation loss: 2.175833220122963

Epoch: 255| Step: 0
Training loss: 2.1784491539001465
Validation loss: 2.177254148708877

Epoch: 5| Step: 1
Training loss: 2.4272799491882324
Validation loss: 2.195337321168633

Epoch: 5| Step: 2
Training loss: 2.056981325149536
Validation loss: 2.2269594528341807

Epoch: 5| Step: 3
Training loss: 1.2037445306777954
Validation loss: 2.2809517075938563

Epoch: 5| Step: 4
Training loss: 2.2559456825256348
Validation loss: 2.315416141222882

Epoch: 5| Step: 5
Training loss: 2.504188060760498
Validation loss: 2.3217432729659544

Epoch: 5| Step: 6
Training loss: 2.3916423320770264
Validation loss: 2.3138394637774398

Epoch: 5| Step: 7
Training loss: 2.2852189540863037
Validation loss: 2.2979648600342455

Epoch: 5| Step: 8
Training loss: 1.7947982549667358
Validation loss: 2.272617778470439

Epoch: 5| Step: 9
Training loss: 1.9714866876602173
Validation loss: 2.2443951304240892

Epoch: 5| Step: 10
Training loss: 1.5483520030975342
Validation loss: 2.215220534673301

Epoch: 256| Step: 0
Training loss: 2.433882474899292
Validation loss: 2.2182983006200483

Epoch: 5| Step: 1
Training loss: 2.082746744155884
Validation loss: 2.2131510703794417

Epoch: 5| Step: 2
Training loss: 2.2297329902648926
Validation loss: 2.2127728616037676

Epoch: 5| Step: 3
Training loss: 2.478947401046753
Validation loss: 2.212759280717501

Epoch: 5| Step: 4
Training loss: 2.1976780891418457
Validation loss: 2.2158476870547057

Epoch: 5| Step: 5
Training loss: 1.5917398929595947
Validation loss: 2.24216656274693

Epoch: 5| Step: 6
Training loss: 1.5499831438064575
Validation loss: 2.2565737026993946

Epoch: 5| Step: 7
Training loss: 1.8169596195220947
Validation loss: 2.2615637061416463

Epoch: 5| Step: 8
Training loss: 2.2616281509399414
Validation loss: 2.306339584371095

Epoch: 5| Step: 9
Training loss: 2.092846393585205
Validation loss: 2.3126512381338302

Epoch: 5| Step: 10
Training loss: 1.7962160110473633
Validation loss: 2.301665234309371

Epoch: 257| Step: 0
Training loss: 2.3084661960601807
Validation loss: 2.2890598491955827

Epoch: 5| Step: 1
Training loss: 2.529691219329834
Validation loss: 2.244937926210383

Epoch: 5| Step: 2
Training loss: 1.6053359508514404
Validation loss: 2.2251653055990896

Epoch: 5| Step: 3
Training loss: 1.86173415184021
Validation loss: 2.210654094655027

Epoch: 5| Step: 4
Training loss: 2.144003391265869
Validation loss: 2.2146788515070432

Epoch: 5| Step: 5
Training loss: 2.330129384994507
Validation loss: 2.2139798082331175

Epoch: 5| Step: 6
Training loss: 1.873786211013794
Validation loss: 2.2082826911762194

Epoch: 5| Step: 7
Training loss: 2.034869432449341
Validation loss: 2.221799527445147

Epoch: 5| Step: 8
Training loss: 1.7934595346450806
Validation loss: 2.2326817871421896

Epoch: 5| Step: 9
Training loss: 2.351536512374878
Validation loss: 2.249818355806412

Epoch: 5| Step: 10
Training loss: 1.4361759424209595
Validation loss: 2.299706721818575

Epoch: 258| Step: 0
Training loss: 1.9401832818984985
Validation loss: 2.3106496282803115

Epoch: 5| Step: 1
Training loss: 1.6957725286483765
Validation loss: 2.3186186693047963

Epoch: 5| Step: 2
Training loss: 2.8721156120300293
Validation loss: 2.3398097330524075

Epoch: 5| Step: 3
Training loss: 2.546220541000366
Validation loss: 2.2992634491253923

Epoch: 5| Step: 4
Training loss: 1.6056745052337646
Validation loss: 2.29020582988698

Epoch: 5| Step: 5
Training loss: 1.7790123224258423
Validation loss: 2.2782123678474018

Epoch: 5| Step: 6
Training loss: 2.30934739112854
Validation loss: 2.2777208512829197

Epoch: 5| Step: 7
Training loss: 2.1837666034698486
Validation loss: 2.2741955044449016

Epoch: 5| Step: 8
Training loss: 1.9680744409561157
Validation loss: 2.2562227197872695

Epoch: 5| Step: 9
Training loss: 1.8323427438735962
Validation loss: 2.258549230073088

Epoch: 5| Step: 10
Training loss: 1.5969524383544922
Validation loss: 2.2218718221110683

Epoch: 259| Step: 0
Training loss: 2.014406681060791
Validation loss: 2.226379732931814

Epoch: 5| Step: 1
Training loss: 2.160073757171631
Validation loss: 2.2108181138192453

Epoch: 5| Step: 2
Training loss: 1.501403570175171
Validation loss: 2.188966305025162

Epoch: 5| Step: 3
Training loss: 2.038071870803833
Validation loss: 2.2004285948250883

Epoch: 5| Step: 4
Training loss: 2.4752860069274902
Validation loss: 2.20401789552422

Epoch: 5| Step: 5
Training loss: 2.2810816764831543
Validation loss: 2.206612479302191

Epoch: 5| Step: 6
Training loss: 2.172262191772461
Validation loss: 2.221214045760452

Epoch: 5| Step: 7
Training loss: 1.8473873138427734
Validation loss: 2.242731076414867

Epoch: 5| Step: 8
Training loss: 2.5290489196777344
Validation loss: 2.2569700338507213

Epoch: 5| Step: 9
Training loss: 1.6223961114883423
Validation loss: 2.259958026229694

Epoch: 5| Step: 10
Training loss: 1.605124592781067
Validation loss: 2.291356440513365

Epoch: 260| Step: 0
Training loss: 1.5842816829681396
Validation loss: 2.274742211064985

Epoch: 5| Step: 1
Training loss: 2.3515498638153076
Validation loss: 2.2893652787772556

Epoch: 5| Step: 2
Training loss: 2.152945041656494
Validation loss: 2.2663369819682133

Epoch: 5| Step: 3
Training loss: 1.8640247583389282
Validation loss: 2.250789355206233

Epoch: 5| Step: 4
Training loss: 2.184401273727417
Validation loss: 2.256294209470031

Epoch: 5| Step: 5
Training loss: 1.8933967351913452
Validation loss: 2.2272225272270942

Epoch: 5| Step: 6
Training loss: 2.076777696609497
Validation loss: 2.240117867787679

Epoch: 5| Step: 7
Training loss: 1.8200550079345703
Validation loss: 2.2431843280792236

Epoch: 5| Step: 8
Training loss: 1.8805420398712158
Validation loss: 2.24005482017353

Epoch: 5| Step: 9
Training loss: 2.012214183807373
Validation loss: 2.247594923101446

Epoch: 5| Step: 10
Training loss: 2.239844560623169
Validation loss: 2.241666756650453

Epoch: 261| Step: 0
Training loss: 2.400299310684204
Validation loss: 2.2307735963534285

Epoch: 5| Step: 1
Training loss: 1.9745032787322998
Validation loss: 2.2518233022382184

Epoch: 5| Step: 2
Training loss: 2.1595451831817627
Validation loss: 2.2722398337497505

Epoch: 5| Step: 3
Training loss: 2.5599207878112793
Validation loss: 2.286107832385648

Epoch: 5| Step: 4
Training loss: 1.8765302896499634
Validation loss: 2.267296697503777

Epoch: 5| Step: 5
Training loss: 1.9524295330047607
Validation loss: 2.2883327468749015

Epoch: 5| Step: 6
Training loss: 1.604108452796936
Validation loss: 2.2775568705733105

Epoch: 5| Step: 7
Training loss: 1.9591522216796875
Validation loss: 2.2870107286719867

Epoch: 5| Step: 8
Training loss: 2.225955009460449
Validation loss: 2.2625024036694596

Epoch: 5| Step: 9
Training loss: 1.4827369451522827
Validation loss: 2.2650714997322328

Epoch: 5| Step: 10
Training loss: 1.634247899055481
Validation loss: 2.2673537218442528

Epoch: 262| Step: 0
Training loss: 1.7052104473114014
Validation loss: 2.2548711684442337

Epoch: 5| Step: 1
Training loss: 2.290968418121338
Validation loss: 2.271025155180244

Epoch: 5| Step: 2
Training loss: 2.6902644634246826
Validation loss: 2.278762904546594

Epoch: 5| Step: 3
Training loss: 1.7673259973526
Validation loss: 2.2562209278024654

Epoch: 5| Step: 4
Training loss: 2.2600419521331787
Validation loss: 2.2368345209347305

Epoch: 5| Step: 5
Training loss: 1.6332018375396729
Validation loss: 2.2065987740793536

Epoch: 5| Step: 6
Training loss: 1.5061748027801514
Validation loss: 2.173502834894324

Epoch: 5| Step: 7
Training loss: 2.098548650741577
Validation loss: 2.167758677595405

Epoch: 5| Step: 8
Training loss: 1.737404465675354
Validation loss: 2.1702453782481532

Epoch: 5| Step: 9
Training loss: 1.973829984664917
Validation loss: 2.2007721060065815

Epoch: 5| Step: 10
Training loss: 2.2637548446655273
Validation loss: 2.23406344972631

Epoch: 263| Step: 0
Training loss: 2.3302178382873535
Validation loss: 2.2696783901542745

Epoch: 5| Step: 1
Training loss: 1.5707356929779053
Validation loss: 2.292669073227913

Epoch: 5| Step: 2
Training loss: 2.017216205596924
Validation loss: 2.2993608443967757

Epoch: 5| Step: 3
Training loss: 1.9604103565216064
Validation loss: 2.337795167840937

Epoch: 5| Step: 4
Training loss: 1.91278874874115
Validation loss: 2.317804003274569

Epoch: 5| Step: 5
Training loss: 2.3032448291778564
Validation loss: 2.315990081397436

Epoch: 5| Step: 6
Training loss: 1.9277982711791992
Validation loss: 2.3184648713757916

Epoch: 5| Step: 7
Training loss: 1.6003453731536865
Validation loss: 2.300295986155028

Epoch: 5| Step: 8
Training loss: 1.8067760467529297
Validation loss: 2.2818370198690765

Epoch: 5| Step: 9
Training loss: 2.0637829303741455
Validation loss: 2.240907548576273

Epoch: 5| Step: 10
Training loss: 2.432075023651123
Validation loss: 2.2318325427270707

Epoch: 264| Step: 0
Training loss: 2.2268424034118652
Validation loss: 2.2509939465471493

Epoch: 5| Step: 1
Training loss: 2.1671948432922363
Validation loss: 2.2756235086789696

Epoch: 5| Step: 2
Training loss: 1.2253435850143433
Validation loss: 2.250723079968524

Epoch: 5| Step: 3
Training loss: 2.410785675048828
Validation loss: 2.2677203916734263

Epoch: 5| Step: 4
Training loss: 2.2644598484039307
Validation loss: 2.246392698698146

Epoch: 5| Step: 5
Training loss: 2.1290993690490723
Validation loss: 2.238231607662734

Epoch: 5| Step: 6
Training loss: 1.8975547552108765
Validation loss: 2.2110709298041558

Epoch: 5| Step: 7
Training loss: 2.137094736099243
Validation loss: 2.21226139350604

Epoch: 5| Step: 8
Training loss: 1.0665851831436157
Validation loss: 2.2440622006693194

Epoch: 5| Step: 9
Training loss: 2.175525188446045
Validation loss: 2.256825117654698

Epoch: 5| Step: 10
Training loss: 2.1944921016693115
Validation loss: 2.268434411735945

Epoch: 265| Step: 0
Training loss: 1.8509562015533447
Validation loss: 2.266127742746825

Epoch: 5| Step: 1
Training loss: 1.5193804502487183
Validation loss: 2.2969777686621553

Epoch: 5| Step: 2
Training loss: 2.0337631702423096
Validation loss: 2.317645861256507

Epoch: 5| Step: 3
Training loss: 2.359283924102783
Validation loss: 2.3597566081631567

Epoch: 5| Step: 4
Training loss: 1.8252500295639038
Validation loss: 2.370148342142823

Epoch: 5| Step: 5
Training loss: 1.6899127960205078
Validation loss: 2.38678716715946

Epoch: 5| Step: 6
Training loss: 2.046232223510742
Validation loss: 2.3608162736379974

Epoch: 5| Step: 7
Training loss: 2.387561082839966
Validation loss: 2.324788365312802

Epoch: 5| Step: 8
Training loss: 2.153176784515381
Validation loss: 2.2856424341919603

Epoch: 5| Step: 9
Training loss: 1.5299174785614014
Validation loss: 2.252592453392603

Epoch: 5| Step: 10
Training loss: 2.482907295227051
Validation loss: 2.2048061509286203

Epoch: 266| Step: 0
Training loss: 1.655291199684143
Validation loss: 2.166904758381587

Epoch: 5| Step: 1
Training loss: 1.6487715244293213
Validation loss: 2.152546062264391

Epoch: 5| Step: 2
Training loss: 2.0152969360351562
Validation loss: 2.135581925351133

Epoch: 5| Step: 3
Training loss: 2.179765224456787
Validation loss: 2.135691442797261

Epoch: 5| Step: 4
Training loss: 2.09960675239563
Validation loss: 2.148268361245432

Epoch: 5| Step: 5
Training loss: 2.395641803741455
Validation loss: 2.144747903270106

Epoch: 5| Step: 6
Training loss: 2.543351411819458
Validation loss: 2.168835199007424

Epoch: 5| Step: 7
Training loss: 1.9492794275283813
Validation loss: 2.210322077556323

Epoch: 5| Step: 8
Training loss: 1.9496877193450928
Validation loss: 2.235204212127193

Epoch: 5| Step: 9
Training loss: 1.812485694885254
Validation loss: 2.2260026162670505

Epoch: 5| Step: 10
Training loss: 1.3343987464904785
Validation loss: 2.2535363217835784

Epoch: 267| Step: 0
Training loss: 1.4822114706039429
Validation loss: 2.287374360587007

Epoch: 5| Step: 1
Training loss: 1.5250508785247803
Validation loss: 2.3057723147894746

Epoch: 5| Step: 2
Training loss: 2.2956252098083496
Validation loss: 2.3286685302693355

Epoch: 5| Step: 3
Training loss: 2.420466184616089
Validation loss: 2.3351901936274704

Epoch: 5| Step: 4
Training loss: 2.185699224472046
Validation loss: 2.354273457680979

Epoch: 5| Step: 5
Training loss: 2.1855335235595703
Validation loss: 2.3511122170314995

Epoch: 5| Step: 6
Training loss: 2.399376392364502
Validation loss: 2.3403242608552337

Epoch: 5| Step: 7
Training loss: 2.054945707321167
Validation loss: 2.310153326680583

Epoch: 5| Step: 8
Training loss: 1.2814632654190063
Validation loss: 2.3066296654362834

Epoch: 5| Step: 9
Training loss: 2.102923631668091
Validation loss: 2.2631292727685746

Epoch: 5| Step: 10
Training loss: 1.5522032976150513
Validation loss: 2.250563948385177

Epoch: 268| Step: 0
Training loss: 2.500950336456299
Validation loss: 2.2205999769190305

Epoch: 5| Step: 1
Training loss: 1.8352034091949463
Validation loss: 2.219185572798534

Epoch: 5| Step: 2
Training loss: 2.0104429721832275
Validation loss: 2.219639875555551

Epoch: 5| Step: 3
Training loss: 2.207825183868408
Validation loss: 2.2170061757487636

Epoch: 5| Step: 4
Training loss: 1.5452606678009033
Validation loss: 2.2160462000036754

Epoch: 5| Step: 5
Training loss: 1.9115803241729736
Validation loss: 2.2189235148891324

Epoch: 5| Step: 6
Training loss: 2.2132816314697266
Validation loss: 2.2235707877784647

Epoch: 5| Step: 7
Training loss: 2.4229214191436768
Validation loss: 2.228740325538061

Epoch: 5| Step: 8
Training loss: 1.2725673913955688
Validation loss: 2.2510945848239365

Epoch: 5| Step: 9
Training loss: 2.4003653526306152
Validation loss: 2.274169645001811

Epoch: 5| Step: 10
Training loss: 0.8881911039352417
Validation loss: 2.2708380094138523

Epoch: 269| Step: 0
Training loss: 1.1440376043319702
Validation loss: 2.3006312667682605

Epoch: 5| Step: 1
Training loss: 2.14019513130188
Validation loss: 2.3138728244330293

Epoch: 5| Step: 2
Training loss: 2.541023015975952
Validation loss: 2.2811273272319506

Epoch: 5| Step: 3
Training loss: 1.8861148357391357
Validation loss: 2.2910918715179607

Epoch: 5| Step: 4
Training loss: 2.2478649616241455
Validation loss: 2.2874327064842306

Epoch: 5| Step: 5
Training loss: 2.1642754077911377
Validation loss: 2.281822709627049

Epoch: 5| Step: 6
Training loss: 1.8040244579315186
Validation loss: 2.2652482935177383

Epoch: 5| Step: 7
Training loss: 2.1523795127868652
Validation loss: 2.235473494375906

Epoch: 5| Step: 8
Training loss: 2.101865291595459
Validation loss: 2.2337856010724138

Epoch: 5| Step: 9
Training loss: 1.3983409404754639
Validation loss: 2.204897508826307

Epoch: 5| Step: 10
Training loss: 1.869255781173706
Validation loss: 2.20664309429866

Epoch: 270| Step: 0
Training loss: 1.8543484210968018
Validation loss: 2.199929204038394

Epoch: 5| Step: 1
Training loss: 1.8405126333236694
Validation loss: 2.1954676387130574

Epoch: 5| Step: 2
Training loss: 1.7453044652938843
Validation loss: 2.22685593687078

Epoch: 5| Step: 3
Training loss: 2.03226900100708
Validation loss: 2.251031409027756

Epoch: 5| Step: 4
Training loss: 2.132312297821045
Validation loss: 2.2958044954525527

Epoch: 5| Step: 5
Training loss: 1.981036901473999
Validation loss: 2.290572850934921

Epoch: 5| Step: 6
Training loss: 1.9410789012908936
Validation loss: 2.302897104652979

Epoch: 5| Step: 7
Training loss: 1.9754259586334229
Validation loss: 2.329338786422565

Epoch: 5| Step: 8
Training loss: 2.1143956184387207
Validation loss: 2.3254632283282537

Epoch: 5| Step: 9
Training loss: 2.003798723220825
Validation loss: 2.3262167310201995

Epoch: 5| Step: 10
Training loss: 2.0722756385803223
Validation loss: 2.3092374891363163

Epoch: 271| Step: 0
Training loss: 1.4016635417938232
Validation loss: 2.2918157269877772

Epoch: 5| Step: 1
Training loss: 1.7160335779190063
Validation loss: 2.2528958294981267

Epoch: 5| Step: 2
Training loss: 2.0404248237609863
Validation loss: 2.212126894663739

Epoch: 5| Step: 3
Training loss: 2.3210129737854004
Validation loss: 2.2058268875204106

Epoch: 5| Step: 4
Training loss: 1.4915626049041748
Validation loss: 2.1680347881009503

Epoch: 5| Step: 5
Training loss: 1.863136649131775
Validation loss: 2.156667906750915

Epoch: 5| Step: 6
Training loss: 2.506725311279297
Validation loss: 2.1422577340115785

Epoch: 5| Step: 7
Training loss: 1.6213716268539429
Validation loss: 2.145729431542017

Epoch: 5| Step: 8
Training loss: 2.287349224090576
Validation loss: 2.1412438884858163

Epoch: 5| Step: 9
Training loss: 1.8511970043182373
Validation loss: 2.162338528581845

Epoch: 5| Step: 10
Training loss: 2.2247583866119385
Validation loss: 2.1922254716196368

Epoch: 272| Step: 0
Training loss: 1.5265928506851196
Validation loss: 2.215936237765897

Epoch: 5| Step: 1
Training loss: 1.7615392208099365
Validation loss: 2.23549993576542

Epoch: 5| Step: 2
Training loss: 1.3255082368850708
Validation loss: 2.2468421971926125

Epoch: 5| Step: 3
Training loss: 2.532688617706299
Validation loss: 2.275619054353365

Epoch: 5| Step: 4
Training loss: 2.31099009513855
Validation loss: 2.3010485710636264

Epoch: 5| Step: 5
Training loss: 2.0912742614746094
Validation loss: 2.308121089012392

Epoch: 5| Step: 6
Training loss: 1.5685073137283325
Validation loss: 2.3129997791782504

Epoch: 5| Step: 7
Training loss: 1.440035104751587
Validation loss: 2.3083067042853243

Epoch: 5| Step: 8
Training loss: 2.3603615760803223
Validation loss: 2.3078547216230825

Epoch: 5| Step: 9
Training loss: 2.0388686656951904
Validation loss: 2.281967827068862

Epoch: 5| Step: 10
Training loss: 2.210218667984009
Validation loss: 2.2880611893951253

Epoch: 273| Step: 0
Training loss: 2.1113638877868652
Validation loss: 2.2916240794684297

Epoch: 5| Step: 1
Training loss: 1.7327619791030884
Validation loss: 2.2954948051001436

Epoch: 5| Step: 2
Training loss: 1.4471402168273926
Validation loss: 2.290738700538553

Epoch: 5| Step: 3
Training loss: 2.0443568229675293
Validation loss: 2.299575582627327

Epoch: 5| Step: 4
Training loss: 2.3039627075195312
Validation loss: 2.306710731598639

Epoch: 5| Step: 5
Training loss: 2.1639223098754883
Validation loss: 2.2683088035993677

Epoch: 5| Step: 6
Training loss: 1.6420576572418213
Validation loss: 2.2450817015863236

Epoch: 5| Step: 7
Training loss: 1.7526893615722656
Validation loss: 2.2219855144459713

Epoch: 5| Step: 8
Training loss: 2.0649781227111816
Validation loss: 2.2041937792172996

Epoch: 5| Step: 9
Training loss: 2.2205328941345215
Validation loss: 2.216396884251666

Epoch: 5| Step: 10
Training loss: 1.447295904159546
Validation loss: 2.2313327327851327

Epoch: 274| Step: 0
Training loss: 2.2703285217285156
Validation loss: 2.236117619340138

Epoch: 5| Step: 1
Training loss: 1.6638246774673462
Validation loss: 2.2063325553812008

Epoch: 5| Step: 2
Training loss: 2.165469169616699
Validation loss: 2.2164352081155263

Epoch: 5| Step: 3
Training loss: 2.159775972366333
Validation loss: 2.1921311911716255

Epoch: 5| Step: 4
Training loss: 1.9385621547698975
Validation loss: 2.2040552990410918

Epoch: 5| Step: 5
Training loss: 2.587584972381592
Validation loss: 2.208006998544098

Epoch: 5| Step: 6
Training loss: 1.3384459018707275
Validation loss: 2.2204468404093096

Epoch: 5| Step: 7
Training loss: 2.503356456756592
Validation loss: 2.2107929901410173

Epoch: 5| Step: 8
Training loss: 1.2130906581878662
Validation loss: 2.2177843073362946

Epoch: 5| Step: 9
Training loss: 1.6854164600372314
Validation loss: 2.250301630266251

Epoch: 5| Step: 10
Training loss: 1.4270941019058228
Validation loss: 2.2458681880786853

Epoch: 275| Step: 0
Training loss: 1.8298652172088623
Validation loss: 2.3071658765116045

Epoch: 5| Step: 1
Training loss: 1.799708604812622
Validation loss: 2.3282996070000435

Epoch: 5| Step: 2
Training loss: 1.5503777265548706
Validation loss: 2.367539172531456

Epoch: 5| Step: 3
Training loss: 1.756932258605957
Validation loss: 2.381843351548718

Epoch: 5| Step: 4
Training loss: 1.4868284463882446
Validation loss: 2.368605908527169

Epoch: 5| Step: 5
Training loss: 1.8290321826934814
Validation loss: 2.3613524565132717

Epoch: 5| Step: 6
Training loss: 1.6162350177764893
Validation loss: 2.337330920721895

Epoch: 5| Step: 7
Training loss: 2.3270885944366455
Validation loss: 2.347459667472429

Epoch: 5| Step: 8
Training loss: 1.9418646097183228
Validation loss: 2.316116225334906

Epoch: 5| Step: 9
Training loss: 2.390063762664795
Validation loss: 2.2735827328056417

Epoch: 5| Step: 10
Training loss: 2.6577301025390625
Validation loss: 2.245565909211354

Epoch: 276| Step: 0
Training loss: 1.5546098947525024
Validation loss: 2.20123472521382

Epoch: 5| Step: 1
Training loss: 1.8462152481079102
Validation loss: 2.157324787109129

Epoch: 5| Step: 2
Training loss: 1.6134178638458252
Validation loss: 2.1901335870065997

Epoch: 5| Step: 3
Training loss: 1.901953101158142
Validation loss: 2.20925840767481

Epoch: 5| Step: 4
Training loss: 2.0230674743652344
Validation loss: 2.208660953788347

Epoch: 5| Step: 5
Training loss: 1.6406288146972656
Validation loss: 2.2452127856592976

Epoch: 5| Step: 6
Training loss: 1.9478946924209595
Validation loss: 2.2598192704621183

Epoch: 5| Step: 7
Training loss: 2.054064989089966
Validation loss: 2.2840444387928134

Epoch: 5| Step: 8
Training loss: 1.7326409816741943
Validation loss: 2.2633925240526915

Epoch: 5| Step: 9
Training loss: 2.0318732261657715
Validation loss: 2.266851809716994

Epoch: 5| Step: 10
Training loss: 2.8293843269348145
Validation loss: 2.277754117083806

Epoch: 277| Step: 0
Training loss: 1.6335868835449219
Validation loss: 2.300601392663935

Epoch: 5| Step: 1
Training loss: 2.3018815517425537
Validation loss: 2.296203404344538

Epoch: 5| Step: 2
Training loss: 1.8986074924468994
Validation loss: 2.2744590825932

Epoch: 5| Step: 3
Training loss: 2.1199374198913574
Validation loss: 2.2727423175688712

Epoch: 5| Step: 4
Training loss: 1.707964539527893
Validation loss: 2.235097531349428

Epoch: 5| Step: 5
Training loss: 2.4004156589508057
Validation loss: 2.224742445894467

Epoch: 5| Step: 6
Training loss: 2.267087936401367
Validation loss: 2.2300320056176957

Epoch: 5| Step: 7
Training loss: 1.7641775608062744
Validation loss: 2.2392748658375075

Epoch: 5| Step: 8
Training loss: 1.2966084480285645
Validation loss: 2.2713490096471642

Epoch: 5| Step: 9
Training loss: 1.5903621912002563
Validation loss: 2.2475910699495705

Epoch: 5| Step: 10
Training loss: 1.8719172477722168
Validation loss: 2.2425616223325013

Epoch: 278| Step: 0
Training loss: 1.675466537475586
Validation loss: 2.25287611510164

Epoch: 5| Step: 1
Training loss: 2.3517661094665527
Validation loss: 2.226998322753496

Epoch: 5| Step: 2
Training loss: 2.971450090408325
Validation loss: 2.2425690735540083

Epoch: 5| Step: 3
Training loss: 2.0286471843719482
Validation loss: 2.2286508929344917

Epoch: 5| Step: 4
Training loss: 1.217373013496399
Validation loss: 2.2176911318173973

Epoch: 5| Step: 5
Training loss: 1.604440689086914
Validation loss: 2.2218291887673

Epoch: 5| Step: 6
Training loss: 1.6514160633087158
Validation loss: 2.229800192258691

Epoch: 5| Step: 7
Training loss: 1.5372788906097412
Validation loss: 2.2330209696164696

Epoch: 5| Step: 8
Training loss: 2.1049206256866455
Validation loss: 2.245259079881894

Epoch: 5| Step: 9
Training loss: 1.6071674823760986
Validation loss: 2.2550437206863077

Epoch: 5| Step: 10
Training loss: 1.9018267393112183
Validation loss: 2.272420096141036

Epoch: 279| Step: 0
Training loss: 2.085677146911621
Validation loss: 2.2885733650576685

Epoch: 5| Step: 1
Training loss: 1.3143863677978516
Validation loss: 2.2777139704714537

Epoch: 5| Step: 2
Training loss: 1.6945457458496094
Validation loss: 2.2674157414385068

Epoch: 5| Step: 3
Training loss: 2.197676658630371
Validation loss: 2.285707930082916

Epoch: 5| Step: 4
Training loss: 2.303661823272705
Validation loss: 2.2503427715711695

Epoch: 5| Step: 5
Training loss: 1.5261856317520142
Validation loss: 2.262779845986315

Epoch: 5| Step: 6
Training loss: 2.239673614501953
Validation loss: 2.271006871295232

Epoch: 5| Step: 7
Training loss: 1.776045799255371
Validation loss: 2.2516548479757

Epoch: 5| Step: 8
Training loss: 2.2652924060821533
Validation loss: 2.2444862627214

Epoch: 5| Step: 9
Training loss: 1.3711483478546143
Validation loss: 2.2226838399005193

Epoch: 5| Step: 10
Training loss: 1.8600865602493286
Validation loss: 2.2457643965239167

Epoch: 280| Step: 0
Training loss: 1.3283774852752686
Validation loss: 2.2306940299208446

Epoch: 5| Step: 1
Training loss: 1.7584425210952759
Validation loss: 2.248743262342227

Epoch: 5| Step: 2
Training loss: 1.7347362041473389
Validation loss: 2.259002547110281

Epoch: 5| Step: 3
Training loss: 2.0299479961395264
Validation loss: 2.298765569604853

Epoch: 5| Step: 4
Training loss: 2.7047805786132812
Validation loss: 2.3018719150174047

Epoch: 5| Step: 5
Training loss: 1.7613246440887451
Validation loss: 2.298662693269791

Epoch: 5| Step: 6
Training loss: 1.1766459941864014
Validation loss: 2.2914154260389266

Epoch: 5| Step: 7
Training loss: 2.232081174850464
Validation loss: 2.250646955223494

Epoch: 5| Step: 8
Training loss: 2.105473518371582
Validation loss: 2.217364122790675

Epoch: 5| Step: 9
Training loss: 1.9157226085662842
Validation loss: 2.2151401709484797

Epoch: 5| Step: 10
Training loss: 1.7738984823226929
Validation loss: 2.191823664531913

Epoch: 281| Step: 0
Training loss: 2.167616605758667
Validation loss: 2.1963406685859925

Epoch: 5| Step: 1
Training loss: 2.095045804977417
Validation loss: 2.2272119445185505

Epoch: 5| Step: 2
Training loss: 2.0591161251068115
Validation loss: 2.2468854099191646

Epoch: 5| Step: 3
Training loss: 0.9337560534477234
Validation loss: 2.2496518806744645

Epoch: 5| Step: 4
Training loss: 2.547826051712036
Validation loss: 2.268283146683888

Epoch: 5| Step: 5
Training loss: 2.2614877223968506
Validation loss: 2.3035972913106284

Epoch: 5| Step: 6
Training loss: 1.9962135553359985
Validation loss: 2.3115157311962498

Epoch: 5| Step: 7
Training loss: 1.4027416706085205
Validation loss: 2.302353028328188

Epoch: 5| Step: 8
Training loss: 1.6859432458877563
Validation loss: 2.275681100865846

Epoch: 5| Step: 9
Training loss: 1.7028825283050537
Validation loss: 2.2517532635760564

Epoch: 5| Step: 10
Training loss: 1.6643083095550537
Validation loss: 2.2198167488139164

Epoch: 282| Step: 0
Training loss: 2.1137430667877197
Validation loss: 2.1955104335661857

Epoch: 5| Step: 1
Training loss: 1.4540867805480957
Validation loss: 2.1993584863601194

Epoch: 5| Step: 2
Training loss: 2.399996519088745
Validation loss: 2.183302842160707

Epoch: 5| Step: 3
Training loss: 1.4882615804672241
Validation loss: 2.1868028820201917

Epoch: 5| Step: 4
Training loss: 1.2447879314422607
Validation loss: 2.2197888743492866

Epoch: 5| Step: 5
Training loss: 1.897007942199707
Validation loss: 2.221660437122468

Epoch: 5| Step: 6
Training loss: 2.559596300125122
Validation loss: 2.224296836442845

Epoch: 5| Step: 7
Training loss: 1.9106868505477905
Validation loss: 2.233542460267262

Epoch: 5| Step: 8
Training loss: 2.4164035320281982
Validation loss: 2.264364324590211

Epoch: 5| Step: 9
Training loss: 1.5900249481201172
Validation loss: 2.2683794434352587

Epoch: 5| Step: 10
Training loss: 1.2112681865692139
Validation loss: 2.2623083899098058

Epoch: 283| Step: 0
Training loss: 1.8335222005844116
Validation loss: 2.2321808748347785

Epoch: 5| Step: 1
Training loss: 1.7916465997695923
Validation loss: 2.2122576851998605

Epoch: 5| Step: 2
Training loss: 2.4473350048065186
Validation loss: 2.1925796719007593

Epoch: 5| Step: 3
Training loss: 1.3574426174163818
Validation loss: 2.1904916609487226

Epoch: 5| Step: 4
Training loss: 1.0031245946884155
Validation loss: 2.19114097215796

Epoch: 5| Step: 5
Training loss: 1.594800353050232
Validation loss: 2.18340108471532

Epoch: 5| Step: 6
Training loss: 1.7883288860321045
Validation loss: 2.174528214239305

Epoch: 5| Step: 7
Training loss: 2.3350799083709717
Validation loss: 2.2289667975518013

Epoch: 5| Step: 8
Training loss: 2.1425139904022217
Validation loss: 2.2421805525338776

Epoch: 5| Step: 9
Training loss: 2.573146343231201
Validation loss: 2.23442373096302

Epoch: 5| Step: 10
Training loss: 1.2009782791137695
Validation loss: 2.240646851960049

Epoch: 284| Step: 0
Training loss: 1.3511543273925781
Validation loss: 2.241300262430663

Epoch: 5| Step: 1
Training loss: 1.8806947469711304
Validation loss: 2.233390954232985

Epoch: 5| Step: 2
Training loss: 1.9267181158065796
Validation loss: 2.2331308728905133

Epoch: 5| Step: 3
Training loss: 2.3092188835144043
Validation loss: 2.2290257971773864

Epoch: 5| Step: 4
Training loss: 2.128469944000244
Validation loss: 2.237288903164607

Epoch: 5| Step: 5
Training loss: 1.79973566532135
Validation loss: 2.212083496073241

Epoch: 5| Step: 6
Training loss: 2.5295217037200928
Validation loss: 2.2094510934686147

Epoch: 5| Step: 7
Training loss: 1.3269157409667969
Validation loss: 2.2161618137872345

Epoch: 5| Step: 8
Training loss: 1.4886970520019531
Validation loss: 2.2144046624501548

Epoch: 5| Step: 9
Training loss: 1.696091890335083
Validation loss: 2.215235553761964

Epoch: 5| Step: 10
Training loss: 1.7719603776931763
Validation loss: 2.2136769243465957

Epoch: 285| Step: 0
Training loss: 1.7026487588882446
Validation loss: 2.2201601407861196

Epoch: 5| Step: 1
Training loss: 1.8762098550796509
Validation loss: 2.2324102181260304

Epoch: 5| Step: 2
Training loss: 1.2746849060058594
Validation loss: 2.22392241672803

Epoch: 5| Step: 3
Training loss: 1.9300720691680908
Validation loss: 2.247173963054534

Epoch: 5| Step: 4
Training loss: 1.7692334651947021
Validation loss: 2.251540599330779

Epoch: 5| Step: 5
Training loss: 2.1650242805480957
Validation loss: 2.2577152816198205

Epoch: 5| Step: 6
Training loss: 1.7850408554077148
Validation loss: 2.2537980464196976

Epoch: 5| Step: 7
Training loss: 2.8338890075683594
Validation loss: 2.2644432437035347

Epoch: 5| Step: 8
Training loss: 1.692199945449829
Validation loss: 2.2589376664930776

Epoch: 5| Step: 9
Training loss: 1.321961760520935
Validation loss: 2.259457903523599

Epoch: 5| Step: 10
Training loss: 1.595879077911377
Validation loss: 2.245012056442999

Epoch: 286| Step: 0
Training loss: 1.4869120121002197
Validation loss: 2.2428679299610916

Epoch: 5| Step: 1
Training loss: 2.1217880249023438
Validation loss: 2.2371829607153453

Epoch: 5| Step: 2
Training loss: 1.1575748920440674
Validation loss: 2.2448162365985174

Epoch: 5| Step: 3
Training loss: 2.079450845718384
Validation loss: 2.254156731790112

Epoch: 5| Step: 4
Training loss: 1.8447647094726562
Validation loss: 2.276715550371396

Epoch: 5| Step: 5
Training loss: 2.080484390258789
Validation loss: 2.2725784586321924

Epoch: 5| Step: 6
Training loss: 1.8646745681762695
Validation loss: 2.271229731139316

Epoch: 5| Step: 7
Training loss: 1.899240493774414
Validation loss: 2.2391268078998854

Epoch: 5| Step: 8
Training loss: 1.6106150150299072
Validation loss: 2.2041827222352386

Epoch: 5| Step: 9
Training loss: 1.9294869899749756
Validation loss: 2.206394947985167

Epoch: 5| Step: 10
Training loss: 1.964898705482483
Validation loss: 2.2226858613311604

Epoch: 287| Step: 0
Training loss: 1.7470817565917969
Validation loss: 2.2199619790559173

Epoch: 5| Step: 1
Training loss: 1.8044443130493164
Validation loss: 2.2193746220680977

Epoch: 5| Step: 2
Training loss: 1.2267829179763794
Validation loss: 2.2140373914472518

Epoch: 5| Step: 3
Training loss: 1.4714150428771973
Validation loss: 2.239565351957916

Epoch: 5| Step: 4
Training loss: 1.7886075973510742
Validation loss: 2.277781096837854

Epoch: 5| Step: 5
Training loss: 1.9266780614852905
Validation loss: 2.2925496332107054

Epoch: 5| Step: 6
Training loss: 2.1068222522735596
Validation loss: 2.2754117660625006

Epoch: 5| Step: 7
Training loss: 1.652100920677185
Validation loss: 2.239583538424584

Epoch: 5| Step: 8
Training loss: 2.1271214485168457
Validation loss: 2.2467021583228983

Epoch: 5| Step: 9
Training loss: 2.2596683502197266
Validation loss: 2.226292230749643

Epoch: 5| Step: 10
Training loss: 1.9812040328979492
Validation loss: 2.2179903009886384

Epoch: 288| Step: 0
Training loss: 1.5445215702056885
Validation loss: 2.2083572200549546

Epoch: 5| Step: 1
Training loss: 1.377810001373291
Validation loss: 2.2672757871689333

Epoch: 5| Step: 2
Training loss: 2.0930263996124268
Validation loss: 2.273078695420296

Epoch: 5| Step: 3
Training loss: 2.2352607250213623
Validation loss: 2.297281911296229

Epoch: 5| Step: 4
Training loss: 1.8451074361801147
Validation loss: 2.2773773362559657

Epoch: 5| Step: 5
Training loss: 1.7793439626693726
Validation loss: 2.281891622850972

Epoch: 5| Step: 6
Training loss: 2.4536516666412354
Validation loss: 2.306953812158236

Epoch: 5| Step: 7
Training loss: 1.4327349662780762
Validation loss: 2.2744664556236676

Epoch: 5| Step: 8
Training loss: 1.4806485176086426
Validation loss: 2.2841645056201565

Epoch: 5| Step: 9
Training loss: 2.179333448410034
Validation loss: 2.2506137458227014

Epoch: 5| Step: 10
Training loss: 1.9191423654556274
Validation loss: 2.221081692685363

Epoch: 289| Step: 0
Training loss: 1.5858421325683594
Validation loss: 2.2174376954314527

Epoch: 5| Step: 1
Training loss: 1.2692950963974
Validation loss: 2.225028502043857

Epoch: 5| Step: 2
Training loss: 2.006944179534912
Validation loss: 2.2027402667589087

Epoch: 5| Step: 3
Training loss: 1.7820898294448853
Validation loss: 2.2071537586950485

Epoch: 5| Step: 4
Training loss: 2.2181904315948486
Validation loss: 2.194541487642514

Epoch: 5| Step: 5
Training loss: 2.323108196258545
Validation loss: 2.188252966891053

Epoch: 5| Step: 6
Training loss: 1.9956061840057373
Validation loss: 2.1790279316645798

Epoch: 5| Step: 7
Training loss: 1.9952377080917358
Validation loss: 2.179630348759313

Epoch: 5| Step: 8
Training loss: 1.1773383617401123
Validation loss: 2.1931073537436863

Epoch: 5| Step: 9
Training loss: 1.8448326587677002
Validation loss: 2.257498521958628

Epoch: 5| Step: 10
Training loss: 1.6748449802398682
Validation loss: 2.303846836090088

Epoch: 290| Step: 0
Training loss: 1.479345679283142
Validation loss: 2.3246744217411166

Epoch: 5| Step: 1
Training loss: 1.7893898487091064
Validation loss: 2.3547970018079205

Epoch: 5| Step: 2
Training loss: 2.5211853981018066
Validation loss: 2.4061159472311697

Epoch: 5| Step: 3
Training loss: 2.3668577671051025
Validation loss: 2.4088509210976223

Epoch: 5| Step: 4
Training loss: 2.021332263946533
Validation loss: 2.4381977153080765

Epoch: 5| Step: 5
Training loss: 1.408571720123291
Validation loss: 2.3689768775816886

Epoch: 5| Step: 6
Training loss: 1.4370008707046509
Validation loss: 2.367845501950992

Epoch: 5| Step: 7
Training loss: 1.6398807764053345
Validation loss: 2.306672819199101

Epoch: 5| Step: 8
Training loss: 1.52486252784729
Validation loss: 2.2310681714806506

Epoch: 5| Step: 9
Training loss: 1.9226820468902588
Validation loss: 2.1696992176835255

Epoch: 5| Step: 10
Training loss: 1.745355248451233
Validation loss: 2.164663312255695

Epoch: 291| Step: 0
Training loss: 2.1632838249206543
Validation loss: 2.136844914446595

Epoch: 5| Step: 1
Training loss: 1.8411388397216797
Validation loss: 2.1185341855531097

Epoch: 5| Step: 2
Training loss: 1.7554041147232056
Validation loss: 2.1523529252698346

Epoch: 5| Step: 3
Training loss: 1.6953614950180054
Validation loss: 2.1520573746773506

Epoch: 5| Step: 4
Training loss: 1.8073304891586304
Validation loss: 2.172299782435099

Epoch: 5| Step: 5
Training loss: 2.1158299446105957
Validation loss: 2.1961585091006373

Epoch: 5| Step: 6
Training loss: 1.5257608890533447
Validation loss: 2.2428953365613054

Epoch: 5| Step: 7
Training loss: 1.1128528118133545
Validation loss: 2.2863153949860604

Epoch: 5| Step: 8
Training loss: 2.007798671722412
Validation loss: 2.302896943143619

Epoch: 5| Step: 9
Training loss: 1.7346982955932617
Validation loss: 2.315544564236877

Epoch: 5| Step: 10
Training loss: 1.8122377395629883
Validation loss: 2.3403819709695797

Epoch: 292| Step: 0
Training loss: 1.7233527898788452
Validation loss: 2.290376296607397

Epoch: 5| Step: 1
Training loss: 2.125203847885132
Validation loss: 2.2496378344874226

Epoch: 5| Step: 2
Training loss: 1.5199073553085327
Validation loss: 2.2818517454208864

Epoch: 5| Step: 3
Training loss: 1.0953385829925537
Validation loss: 2.2424197658415763

Epoch: 5| Step: 4
Training loss: 2.2513201236724854
Validation loss: 2.2294415568792694

Epoch: 5| Step: 5
Training loss: 1.5976231098175049
Validation loss: 2.2441701004582066

Epoch: 5| Step: 6
Training loss: 1.97492253780365
Validation loss: 2.2608444639431533

Epoch: 5| Step: 7
Training loss: 2.0645368099212646
Validation loss: 2.2456059507144395

Epoch: 5| Step: 8
Training loss: 1.4712066650390625
Validation loss: 2.2230446415562786

Epoch: 5| Step: 9
Training loss: 1.7219111919403076
Validation loss: 2.2587789386831303

Epoch: 5| Step: 10
Training loss: 1.9873296022415161
Validation loss: 2.253759627701134

Epoch: 293| Step: 0
Training loss: 0.7753416895866394
Validation loss: 2.2456390550059657

Epoch: 5| Step: 1
Training loss: 1.4220833778381348
Validation loss: 2.241974151262673

Epoch: 5| Step: 2
Training loss: 1.7104238271713257
Validation loss: 2.257415299774498

Epoch: 5| Step: 3
Training loss: 2.227170467376709
Validation loss: 2.231170978597415

Epoch: 5| Step: 4
Training loss: 2.1167874336242676
Validation loss: 2.2462401518257717

Epoch: 5| Step: 5
Training loss: 2.276766777038574
Validation loss: 2.222455573338334

Epoch: 5| Step: 6
Training loss: 1.3032097816467285
Validation loss: 2.2223945510002876

Epoch: 5| Step: 7
Training loss: 1.9299170970916748
Validation loss: 2.2197799862072034

Epoch: 5| Step: 8
Training loss: 2.186048984527588
Validation loss: 2.1989133101637646

Epoch: 5| Step: 9
Training loss: 1.5398895740509033
Validation loss: 2.1745361051251813

Epoch: 5| Step: 10
Training loss: 1.9633315801620483
Validation loss: 2.1858258555012364

Epoch: 294| Step: 0
Training loss: 1.6550785303115845
Validation loss: 2.190198325341748

Epoch: 5| Step: 1
Training loss: 1.953179121017456
Validation loss: 2.2027687475245488

Epoch: 5| Step: 2
Training loss: 1.5747486352920532
Validation loss: 2.212508665618076

Epoch: 5| Step: 3
Training loss: 2.4012584686279297
Validation loss: 2.214625604691044

Epoch: 5| Step: 4
Training loss: 2.014219284057617
Validation loss: 2.2352952905880508

Epoch: 5| Step: 5
Training loss: 1.551360845565796
Validation loss: 2.2221137528778403

Epoch: 5| Step: 6
Training loss: 1.5151686668395996
Validation loss: 2.211504759327058

Epoch: 5| Step: 7
Training loss: 1.9918575286865234
Validation loss: 2.240283627663889

Epoch: 5| Step: 8
Training loss: 1.3386904001235962
Validation loss: 2.244257688522339

Epoch: 5| Step: 9
Training loss: 1.6174777746200562
Validation loss: 2.2619254204534713

Epoch: 5| Step: 10
Training loss: 1.585379958152771
Validation loss: 2.2781379838143625

Epoch: 295| Step: 0
Training loss: 2.044114351272583
Validation loss: 2.3006333997172694

Epoch: 5| Step: 1
Training loss: 1.9737743139266968
Validation loss: 2.3270674597832466

Epoch: 5| Step: 2
Training loss: 1.8223717212677002
Validation loss: 2.312444399761897

Epoch: 5| Step: 3
Training loss: 1.5359482765197754
Validation loss: 2.323773322566863

Epoch: 5| Step: 4
Training loss: 2.1086549758911133
Validation loss: 2.2885854577505462

Epoch: 5| Step: 5
Training loss: 1.486029863357544
Validation loss: 2.2835536003112793

Epoch: 5| Step: 6
Training loss: 1.9778339862823486
Validation loss: 2.284665015435988

Epoch: 5| Step: 7
Training loss: 2.1071724891662598
Validation loss: 2.2594264873894314

Epoch: 5| Step: 8
Training loss: 1.0968201160430908
Validation loss: 2.241717012979651

Epoch: 5| Step: 9
Training loss: 1.513002634048462
Validation loss: 2.219271893142372

Epoch: 5| Step: 10
Training loss: 1.4029998779296875
Validation loss: 2.2334721972865443

Epoch: 296| Step: 0
Training loss: 1.7330719232559204
Validation loss: 2.2653043629020773

Epoch: 5| Step: 1
Training loss: 1.9232591390609741
Validation loss: 2.273721992328603

Epoch: 5| Step: 2
Training loss: 2.3179948329925537
Validation loss: 2.2651238159466813

Epoch: 5| Step: 3
Training loss: 1.5298845767974854
Validation loss: 2.287886622131512

Epoch: 5| Step: 4
Training loss: 1.9120838642120361
Validation loss: 2.2690193550561064

Epoch: 5| Step: 5
Training loss: 2.0368292331695557
Validation loss: 2.248963899509881

Epoch: 5| Step: 6
Training loss: 1.2610135078430176
Validation loss: 2.2446082253609934

Epoch: 5| Step: 7
Training loss: 1.6094415187835693
Validation loss: 2.233464871683428

Epoch: 5| Step: 8
Training loss: 2.1864824295043945
Validation loss: 2.216334731348099

Epoch: 5| Step: 9
Training loss: 0.902716338634491
Validation loss: 2.2122915662744993

Epoch: 5| Step: 10
Training loss: 1.640795111656189
Validation loss: 2.219466799048967

Epoch: 297| Step: 0
Training loss: 2.1318588256835938
Validation loss: 2.2693986251790035

Epoch: 5| Step: 1
Training loss: 1.3894603252410889
Validation loss: 2.2752079168955484

Epoch: 5| Step: 2
Training loss: 1.7092605829238892
Validation loss: 2.3020526952640985

Epoch: 5| Step: 3
Training loss: 1.4856009483337402
Validation loss: 2.3093702331666024

Epoch: 5| Step: 4
Training loss: 1.344853401184082
Validation loss: 2.302524015467654

Epoch: 5| Step: 5
Training loss: 1.9909980297088623
Validation loss: 2.340609158239057

Epoch: 5| Step: 6
Training loss: 2.3273465633392334
Validation loss: 2.289722934845955

Epoch: 5| Step: 7
Training loss: 1.9148569107055664
Validation loss: 2.2868515009521158

Epoch: 5| Step: 8
Training loss: 1.1131317615509033
Validation loss: 2.261017360994893

Epoch: 5| Step: 9
Training loss: 1.8119316101074219
Validation loss: 2.2249569431427987

Epoch: 5| Step: 10
Training loss: 1.9151153564453125
Validation loss: 2.171520899700862

Epoch: 298| Step: 0
Training loss: 1.6129310131072998
Validation loss: 2.187575488962153

Epoch: 5| Step: 1
Training loss: 1.7598092555999756
Validation loss: 2.1778129326399935

Epoch: 5| Step: 2
Training loss: 1.5447862148284912
Validation loss: 2.1550315900515487

Epoch: 5| Step: 3
Training loss: 1.5368261337280273
Validation loss: 2.174242740036339

Epoch: 5| Step: 4
Training loss: 2.0299105644226074
Validation loss: 2.177668479181105

Epoch: 5| Step: 5
Training loss: 1.616288185119629
Validation loss: 2.1673151113653697

Epoch: 5| Step: 6
Training loss: 1.3915302753448486
Validation loss: 2.1636719934401976

Epoch: 5| Step: 7
Training loss: 1.7098976373672485
Validation loss: 2.195153772190053

Epoch: 5| Step: 8
Training loss: 2.585273027420044
Validation loss: 2.1841676286471787

Epoch: 5| Step: 9
Training loss: 1.747704267501831
Validation loss: 2.2123611139994797

Epoch: 5| Step: 10
Training loss: 1.5260372161865234
Validation loss: 2.2089526038016043

Epoch: 299| Step: 0
Training loss: 1.5073392391204834
Validation loss: 2.2526952220547583

Epoch: 5| Step: 1
Training loss: 1.2785191535949707
Validation loss: 2.3000012367002425

Epoch: 5| Step: 2
Training loss: 1.7567460536956787
Validation loss: 2.2839571558019167

Epoch: 5| Step: 3
Training loss: 1.9415134191513062
Validation loss: 2.32000502591492

Epoch: 5| Step: 4
Training loss: 1.412148118019104
Validation loss: 2.3081192021728842

Epoch: 5| Step: 5
Training loss: 1.8420597314834595
Validation loss: 2.3003481024055072

Epoch: 5| Step: 6
Training loss: 1.3218119144439697
Validation loss: 2.2842237616098053

Epoch: 5| Step: 7
Training loss: 1.724098563194275
Validation loss: 2.2609274541178057

Epoch: 5| Step: 8
Training loss: 2.3334732055664062
Validation loss: 2.2581589632136847

Epoch: 5| Step: 9
Training loss: 1.9825031757354736
Validation loss: 2.2156812093591176

Epoch: 5| Step: 10
Training loss: 1.8626775741577148
Validation loss: 2.1645669193678003

Epoch: 300| Step: 0
Training loss: 1.5599439144134521
Validation loss: 2.1723269211348666

Epoch: 5| Step: 1
Training loss: 1.3980783224105835
Validation loss: 2.1625408049552672

Epoch: 5| Step: 2
Training loss: 1.755621314048767
Validation loss: 2.174381950850128

Epoch: 5| Step: 3
Training loss: 1.491595983505249
Validation loss: 2.1556168576722503

Epoch: 5| Step: 4
Training loss: 1.4343950748443604
Validation loss: 2.194440690420007

Epoch: 5| Step: 5
Training loss: 1.8557014465332031
Validation loss: 2.2076332940850207

Epoch: 5| Step: 6
Training loss: 2.9828763008117676
Validation loss: 2.207545634238951

Epoch: 5| Step: 7
Training loss: 0.9722176790237427
Validation loss: 2.224730553165559

Epoch: 5| Step: 8
Training loss: 2.319314956665039
Validation loss: 2.2018632273520193

Epoch: 5| Step: 9
Training loss: 1.4527477025985718
Validation loss: 2.2157635791327364

Epoch: 5| Step: 10
Training loss: 1.7186309099197388
Validation loss: 2.1998977635496404

Epoch: 301| Step: 0
Training loss: 1.289581537246704
Validation loss: 2.2209053116460002

Epoch: 5| Step: 1
Training loss: 1.7011924982070923
Validation loss: 2.2793160856411023

Epoch: 5| Step: 2
Training loss: 1.9285255670547485
Validation loss: 2.293803741855006

Epoch: 5| Step: 3
Training loss: 1.465834379196167
Validation loss: 2.3276432188608314

Epoch: 5| Step: 4
Training loss: 2.127258539199829
Validation loss: 2.3434117558181926

Epoch: 5| Step: 5
Training loss: 1.5147982835769653
Validation loss: 2.3113321642721854

Epoch: 5| Step: 6
Training loss: 1.655683159828186
Validation loss: 2.3038114642584198

Epoch: 5| Step: 7
Training loss: 1.5590064525604248
Validation loss: 2.218430090976018

Epoch: 5| Step: 8
Training loss: 1.661489725112915
Validation loss: 2.207583899139076

Epoch: 5| Step: 9
Training loss: 1.8866312503814697
Validation loss: 2.1735696459329255

Epoch: 5| Step: 10
Training loss: 2.0807363986968994
Validation loss: 2.1679672515520485

Epoch: 302| Step: 0
Training loss: 2.203909397125244
Validation loss: 2.1568496509264876

Epoch: 5| Step: 1
Training loss: 1.4211816787719727
Validation loss: 2.126760526369977

Epoch: 5| Step: 2
Training loss: 1.5164382457733154
Validation loss: 2.1280843263031333

Epoch: 5| Step: 3
Training loss: 1.6184008121490479
Validation loss: 2.1266010627951673

Epoch: 5| Step: 4
Training loss: 1.9645637273788452
Validation loss: 2.1837630989731

Epoch: 5| Step: 5
Training loss: 1.4696890115737915
Validation loss: 2.1965931384794173

Epoch: 5| Step: 6
Training loss: 1.4004379510879517
Validation loss: 2.2713259996906405

Epoch: 5| Step: 7
Training loss: 1.5564205646514893
Validation loss: 2.297282482988091

Epoch: 5| Step: 8
Training loss: 1.8116525411605835
Validation loss: 2.3314624960704515

Epoch: 5| Step: 9
Training loss: 1.5844659805297852
Validation loss: 2.3410126137477096

Epoch: 5| Step: 10
Training loss: 2.4957501888275146
Validation loss: 2.338783989670456

Epoch: 303| Step: 0
Training loss: 1.5933443307876587
Validation loss: 2.319273269304665

Epoch: 5| Step: 1
Training loss: 1.684896469116211
Validation loss: 2.255564489672261

Epoch: 5| Step: 2
Training loss: 2.059981107711792
Validation loss: 2.246436316479919

Epoch: 5| Step: 3
Training loss: 1.5993292331695557
Validation loss: 2.2420842186097176

Epoch: 5| Step: 4
Training loss: 1.4449918270111084
Validation loss: 2.2406518151683192

Epoch: 5| Step: 5
Training loss: 1.8471629619598389
Validation loss: 2.1968759131687943

Epoch: 5| Step: 6
Training loss: 1.5753804445266724
Validation loss: 2.2105064520271878

Epoch: 5| Step: 7
Training loss: 1.350427269935608
Validation loss: 2.1951310352612565

Epoch: 5| Step: 8
Training loss: 1.6325414180755615
Validation loss: 2.186827862134544

Epoch: 5| Step: 9
Training loss: 2.214733839035034
Validation loss: 2.235361691444151

Epoch: 5| Step: 10
Training loss: 1.6393903493881226
Validation loss: 2.2294802793892483

Epoch: 304| Step: 0
Training loss: 1.930490255355835
Validation loss: 2.2094642116177465

Epoch: 5| Step: 1
Training loss: 1.2742254734039307
Validation loss: 2.2105820255894817

Epoch: 5| Step: 2
Training loss: 1.8607639074325562
Validation loss: 2.215108927860055

Epoch: 5| Step: 3
Training loss: 2.255143404006958
Validation loss: 2.2228127653880785

Epoch: 5| Step: 4
Training loss: 1.6530039310455322
Validation loss: 2.2195055202771257

Epoch: 5| Step: 5
Training loss: 1.5728352069854736
Validation loss: 2.2597503098108436

Epoch: 5| Step: 6
Training loss: 1.663783073425293
Validation loss: 2.265055020650228

Epoch: 5| Step: 7
Training loss: 1.9531806707382202
Validation loss: 2.2829330480226906

Epoch: 5| Step: 8
Training loss: 1.0658458471298218
Validation loss: 2.3085359040127007

Epoch: 5| Step: 9
Training loss: 2.0254464149475098
Validation loss: 2.3105031726180867

Epoch: 5| Step: 10
Training loss: 1.2058618068695068
Validation loss: 2.3236564538812123

Epoch: 305| Step: 0
Training loss: 2.5236449241638184
Validation loss: 2.350970550249982

Epoch: 5| Step: 1
Training loss: 1.342376947402954
Validation loss: 2.321153497183195

Epoch: 5| Step: 2
Training loss: 2.1445229053497314
Validation loss: 2.2878137916646977

Epoch: 5| Step: 3
Training loss: 1.240623950958252
Validation loss: 2.2528271495655017

Epoch: 5| Step: 4
Training loss: 1.3387330770492554
Validation loss: 2.2673397346209456

Epoch: 5| Step: 5
Training loss: 1.4481722116470337
Validation loss: 2.2653084262724845

Epoch: 5| Step: 6
Training loss: 1.5564244985580444
Validation loss: 2.258805913309897

Epoch: 5| Step: 7
Training loss: 1.6021919250488281
Validation loss: 2.2519158560742616

Epoch: 5| Step: 8
Training loss: 1.7499134540557861
Validation loss: 2.229237284711612

Epoch: 5| Step: 9
Training loss: 1.5516523122787476
Validation loss: 2.221815839890511

Epoch: 5| Step: 10
Training loss: 1.9710843563079834
Validation loss: 2.184788544972738

Epoch: 306| Step: 0
Training loss: 1.270412802696228
Validation loss: 2.148193713157408

Epoch: 5| Step: 1
Training loss: 1.5290122032165527
Validation loss: 2.143186992214572

Epoch: 5| Step: 2
Training loss: 1.5279544591903687
Validation loss: 2.153056151123457

Epoch: 5| Step: 3
Training loss: 1.1960198879241943
Validation loss: 2.1280495018087406

Epoch: 5| Step: 4
Training loss: 2.492114543914795
Validation loss: 2.18873962279289

Epoch: 5| Step: 5
Training loss: 1.6345946788787842
Validation loss: 2.188683771318005

Epoch: 5| Step: 6
Training loss: 1.6449867486953735
Validation loss: 2.2349687660894086

Epoch: 5| Step: 7
Training loss: 2.183187961578369
Validation loss: 2.256406036756372

Epoch: 5| Step: 8
Training loss: 1.5177638530731201
Validation loss: 2.305447839921521

Epoch: 5| Step: 9
Training loss: 1.7828547954559326
Validation loss: 2.283795013222643

Epoch: 5| Step: 10
Training loss: 1.6693809032440186
Validation loss: 2.3086807215085594

Epoch: 307| Step: 0
Training loss: 2.4795632362365723
Validation loss: 2.2911150224747194

Epoch: 5| Step: 1
Training loss: 1.2430697679519653
Validation loss: 2.277357337295368

Epoch: 5| Step: 2
Training loss: 1.6401389837265015
Validation loss: 2.2578061972894976

Epoch: 5| Step: 3
Training loss: 2.0685763359069824
Validation loss: 2.252914951693627

Epoch: 5| Step: 4
Training loss: 1.1781179904937744
Validation loss: 2.203805333824568

Epoch: 5| Step: 5
Training loss: 1.110182523727417
Validation loss: 2.190735154254462

Epoch: 5| Step: 6
Training loss: 1.4621310234069824
Validation loss: 2.1801740738653366

Epoch: 5| Step: 7
Training loss: 1.551807165145874
Validation loss: 2.170864798689401

Epoch: 5| Step: 8
Training loss: 1.794529676437378
Validation loss: 2.20530374973051

Epoch: 5| Step: 9
Training loss: 1.6255614757537842
Validation loss: 2.176251465274442

Epoch: 5| Step: 10
Training loss: 2.1872897148132324
Validation loss: 2.2118728853041127

Epoch: 308| Step: 0
Training loss: 1.641333818435669
Validation loss: 2.217368079769996

Epoch: 5| Step: 1
Training loss: 2.0309791564941406
Validation loss: 2.230616613100934

Epoch: 5| Step: 2
Training loss: 1.5810487270355225
Validation loss: 2.238637626812022

Epoch: 5| Step: 3
Training loss: 2.6779253482818604
Validation loss: 2.2139997764300277

Epoch: 5| Step: 4
Training loss: 1.3193073272705078
Validation loss: 2.2376765281923356

Epoch: 5| Step: 5
Training loss: 1.4001911878585815
Validation loss: 2.227456501735154

Epoch: 5| Step: 6
Training loss: 1.1535656452178955
Validation loss: 2.2481383380069526

Epoch: 5| Step: 7
Training loss: 1.8860180377960205
Validation loss: 2.237708583954842

Epoch: 5| Step: 8
Training loss: 1.0743381977081299
Validation loss: 2.2378252142219135

Epoch: 5| Step: 9
Training loss: 2.216141939163208
Validation loss: 2.213286802332888

Epoch: 5| Step: 10
Training loss: 0.9757153987884521
Validation loss: 2.209951727621017

Epoch: 309| Step: 0
Training loss: 1.04311203956604
Validation loss: 2.2299411117389636

Epoch: 5| Step: 1
Training loss: 1.031308889389038
Validation loss: 2.2472027117206204

Epoch: 5| Step: 2
Training loss: 1.4253876209259033
Validation loss: 2.2602294106637277

Epoch: 5| Step: 3
Training loss: 2.1361567974090576
Validation loss: 2.278025045189806

Epoch: 5| Step: 4
Training loss: 1.8156192302703857
Validation loss: 2.284909893107671

Epoch: 5| Step: 5
Training loss: 2.05942964553833
Validation loss: 2.2283702281213578

Epoch: 5| Step: 6
Training loss: 1.2181532382965088
Validation loss: 2.230427775331723

Epoch: 5| Step: 7
Training loss: 2.3430349826812744
Validation loss: 2.213252180366106

Epoch: 5| Step: 8
Training loss: 2.0430476665496826
Validation loss: 2.2066787981217906

Epoch: 5| Step: 9
Training loss: 1.7339195013046265
Validation loss: 2.2006645561546407

Epoch: 5| Step: 10
Training loss: 1.3763930797576904
Validation loss: 2.208583783077937

Epoch: 310| Step: 0
Training loss: 1.5072269439697266
Validation loss: 2.1927742624795563

Epoch: 5| Step: 1
Training loss: 1.4934836626052856
Validation loss: 2.178809908128554

Epoch: 5| Step: 2
Training loss: 1.4687684774398804
Validation loss: 2.1560027932608

Epoch: 5| Step: 3
Training loss: 1.387697696685791
Validation loss: 2.204111509425666

Epoch: 5| Step: 4
Training loss: 1.6010515689849854
Validation loss: 2.200808237957698

Epoch: 5| Step: 5
Training loss: 1.5279171466827393
Validation loss: 2.2280812724944083

Epoch: 5| Step: 6
Training loss: 2.4163804054260254
Validation loss: 2.2539102697885163

Epoch: 5| Step: 7
Training loss: 1.9150187969207764
Validation loss: 2.284661095629456

Epoch: 5| Step: 8
Training loss: 2.1405982971191406
Validation loss: 2.2710290775504163

Epoch: 5| Step: 9
Training loss: 1.3947069644927979
Validation loss: 2.283897622939079

Epoch: 5| Step: 10
Training loss: 1.4700188636779785
Validation loss: 2.248054112157514

Epoch: 311| Step: 0
Training loss: 1.462961196899414
Validation loss: 2.2177543294045234

Epoch: 5| Step: 1
Training loss: 1.8769912719726562
Validation loss: 2.2175590991973877

Epoch: 5| Step: 2
Training loss: 1.4140551090240479
Validation loss: 2.2326877399157454

Epoch: 5| Step: 3
Training loss: 1.9571044445037842
Validation loss: 2.220107686135077

Epoch: 5| Step: 4
Training loss: 1.1674518585205078
Validation loss: 2.1897180029141006

Epoch: 5| Step: 5
Training loss: 1.8052978515625
Validation loss: 2.210760675450807

Epoch: 5| Step: 6
Training loss: 1.361252784729004
Validation loss: 2.1859711216342066

Epoch: 5| Step: 7
Training loss: 1.7958790063858032
Validation loss: 2.2091695723995084

Epoch: 5| Step: 8
Training loss: 1.1650025844573975
Validation loss: 2.1988319479009157

Epoch: 5| Step: 9
Training loss: 2.1336941719055176
Validation loss: 2.2181313524964037

Epoch: 5| Step: 10
Training loss: 1.9648605585098267
Validation loss: 2.222394638164069

Epoch: 312| Step: 0
Training loss: 1.7294105291366577
Validation loss: 2.222506105258901

Epoch: 5| Step: 1
Training loss: 2.11397647857666
Validation loss: 2.240510922606273

Epoch: 5| Step: 2
Training loss: 0.3952379822731018
Validation loss: 2.243646567867648

Epoch: 5| Step: 3
Training loss: 1.4737298488616943
Validation loss: 2.225886990947108

Epoch: 5| Step: 4
Training loss: 1.5960185527801514
Validation loss: 2.23926471125695

Epoch: 5| Step: 5
Training loss: 1.8985214233398438
Validation loss: 2.21166887334598

Epoch: 5| Step: 6
Training loss: 1.065099835395813
Validation loss: 2.204973914289987

Epoch: 5| Step: 7
Training loss: 2.2965786457061768
Validation loss: 2.214586078479726

Epoch: 5| Step: 8
Training loss: 1.335151195526123
Validation loss: 2.2214820256797214

Epoch: 5| Step: 9
Training loss: 2.386678457260132
Validation loss: 2.214430239892775

Epoch: 5| Step: 10
Training loss: 1.4128422737121582
Validation loss: 2.198089571409328

Epoch: 313| Step: 0
Training loss: 1.2720930576324463
Validation loss: 2.18136271866419

Epoch: 5| Step: 1
Training loss: 1.340091347694397
Validation loss: 2.204863705942708

Epoch: 5| Step: 2
Training loss: 1.2536388635635376
Validation loss: 2.2064217021388393

Epoch: 5| Step: 3
Training loss: 1.3857553005218506
Validation loss: 2.2567281902477307

Epoch: 5| Step: 4
Training loss: 1.4747793674468994
Validation loss: 2.2478075899103636

Epoch: 5| Step: 5
Training loss: 2.198909282684326
Validation loss: 2.2571535597565355

Epoch: 5| Step: 6
Training loss: 1.8019272089004517
Validation loss: 2.284973913623441

Epoch: 5| Step: 7
Training loss: 1.256391167640686
Validation loss: 2.2905838386986845

Epoch: 5| Step: 8
Training loss: 2.2477972507476807
Validation loss: 2.2486246247445383

Epoch: 5| Step: 9
Training loss: 1.5275599956512451
Validation loss: 2.2276406980329946

Epoch: 5| Step: 10
Training loss: 2.0682554244995117
Validation loss: 2.2055648014109623

Epoch: 314| Step: 0
Training loss: 1.1782370805740356
Validation loss: 2.177715721950736

Epoch: 5| Step: 1
Training loss: 1.6375253200531006
Validation loss: 2.1425831138446765

Epoch: 5| Step: 2
Training loss: 1.7301950454711914
Validation loss: 2.11824175747492

Epoch: 5| Step: 3
Training loss: 1.6012709140777588
Validation loss: 2.1035743298069125

Epoch: 5| Step: 4
Training loss: 1.3929108381271362
Validation loss: 2.1137839671104186

Epoch: 5| Step: 5
Training loss: 1.400098204612732
Validation loss: 2.1494976384665376

Epoch: 5| Step: 6
Training loss: 1.497233271598816
Validation loss: 2.159179050435302

Epoch: 5| Step: 7
Training loss: 1.6447299718856812
Validation loss: 2.206206860080842

Epoch: 5| Step: 8
Training loss: 2.0293984413146973
Validation loss: 2.2466029979849376

Epoch: 5| Step: 9
Training loss: 1.8324496746063232
Validation loss: 2.271815799897717

Epoch: 5| Step: 10
Training loss: 2.1739749908447266
Validation loss: 2.2545867760976157

Epoch: 315| Step: 0
Training loss: 2.2369046211242676
Validation loss: 2.2513754906192904

Epoch: 5| Step: 1
Training loss: 1.308778166770935
Validation loss: 2.2706049052617883

Epoch: 5| Step: 2
Training loss: 1.4564635753631592
Validation loss: 2.2729518516089326

Epoch: 5| Step: 3
Training loss: 1.4164167642593384
Validation loss: 2.26057090297822

Epoch: 5| Step: 4
Training loss: 1.6768079996109009
Validation loss: 2.270408708562133

Epoch: 5| Step: 5
Training loss: 1.6826051473617554
Validation loss: 2.2516907107445503

Epoch: 5| Step: 6
Training loss: 1.7318938970565796
Validation loss: 2.2715995773192375

Epoch: 5| Step: 7
Training loss: 1.5549719333648682
Validation loss: 2.2576962440244612

Epoch: 5| Step: 8
Training loss: 1.9994844198226929
Validation loss: 2.253059658952939

Epoch: 5| Step: 9
Training loss: 1.4194411039352417
Validation loss: 2.2627477966329104

Epoch: 5| Step: 10
Training loss: 1.6708914041519165
Validation loss: 2.233046849568685

Epoch: 316| Step: 0
Training loss: 2.416771650314331
Validation loss: 2.197640198533253

Epoch: 5| Step: 1
Training loss: 1.8951994180679321
Validation loss: 2.1945977621181036

Epoch: 5| Step: 2
Training loss: 1.2987340688705444
Validation loss: 2.1556302539763914

Epoch: 5| Step: 3
Training loss: 1.8287547826766968
Validation loss: 2.136229202311526

Epoch: 5| Step: 4
Training loss: 1.319312334060669
Validation loss: 2.134584388425273

Epoch: 5| Step: 5
Training loss: 1.5215790271759033
Validation loss: 2.1396342746673094

Epoch: 5| Step: 6
Training loss: 1.6630874872207642
Validation loss: 2.151447114124093

Epoch: 5| Step: 7
Training loss: 1.6289911270141602
Validation loss: 2.180313902516519

Epoch: 5| Step: 8
Training loss: 1.5057408809661865
Validation loss: 2.200267753293437

Epoch: 5| Step: 9
Training loss: 1.2633548974990845
Validation loss: 2.214130352902156

Epoch: 5| Step: 10
Training loss: 1.4078508615493774
Validation loss: 2.271138709078553

Epoch: 317| Step: 0
Training loss: 2.147420883178711
Validation loss: 2.284136797792168

Epoch: 5| Step: 1
Training loss: 1.7255008220672607
Validation loss: 2.2806043932514806

Epoch: 5| Step: 2
Training loss: 1.676473617553711
Validation loss: 2.2959426526100404

Epoch: 5| Step: 3
Training loss: 1.371085524559021
Validation loss: 2.234847605869334

Epoch: 5| Step: 4
Training loss: 1.2093302011489868
Validation loss: 2.2097783703957834

Epoch: 5| Step: 5
Training loss: 1.862097144126892
Validation loss: 2.2278035289497784

Epoch: 5| Step: 6
Training loss: 1.105363130569458
Validation loss: 2.1758714286229943

Epoch: 5| Step: 7
Training loss: 1.9879190921783447
Validation loss: 2.151499843084684

Epoch: 5| Step: 8
Training loss: 1.3066900968551636
Validation loss: 2.1330306606908

Epoch: 5| Step: 9
Training loss: 2.4246840476989746
Validation loss: 2.1318164512675297

Epoch: 5| Step: 10
Training loss: 0.8817457556724548
Validation loss: 2.1265049160167737

Epoch: 318| Step: 0
Training loss: 2.167313814163208
Validation loss: 2.128778257677632

Epoch: 5| Step: 1
Training loss: 1.8455626964569092
Validation loss: 2.1595190494291243

Epoch: 5| Step: 2
Training loss: 0.7841619253158569
Validation loss: 2.158750380239179

Epoch: 5| Step: 3
Training loss: 1.9821351766586304
Validation loss: 2.1446614637169787

Epoch: 5| Step: 4
Training loss: 1.8507091999053955
Validation loss: 2.1377126734743834

Epoch: 5| Step: 5
Training loss: 1.4750694036483765
Validation loss: 2.140580077325144

Epoch: 5| Step: 6
Training loss: 1.2615272998809814
Validation loss: 2.152807217772289

Epoch: 5| Step: 7
Training loss: 2.051363468170166
Validation loss: 2.1769608451474096

Epoch: 5| Step: 8
Training loss: 1.5842905044555664
Validation loss: 2.2194788661054385

Epoch: 5| Step: 9
Training loss: 1.2321383953094482
Validation loss: 2.2018370679629746

Epoch: 5| Step: 10
Training loss: 1.4673231840133667
Validation loss: 2.231506529674735

Epoch: 319| Step: 0
Training loss: 1.1553205251693726
Validation loss: 2.250161842633319

Epoch: 5| Step: 1
Training loss: 1.5430068969726562
Validation loss: 2.2508758601321968

Epoch: 5| Step: 2
Training loss: 1.349302053451538
Validation loss: 2.2732204775656424

Epoch: 5| Step: 3
Training loss: 1.543532371520996
Validation loss: 2.259670788241971

Epoch: 5| Step: 4
Training loss: 1.5247496366500854
Validation loss: 2.2990372937212706

Epoch: 5| Step: 5
Training loss: 1.875603437423706
Validation loss: 2.2796022084451493

Epoch: 5| Step: 6
Training loss: 1.472047209739685
Validation loss: 2.2555599058828046

Epoch: 5| Step: 7
Training loss: 1.7961156368255615
Validation loss: 2.259414406232936

Epoch: 5| Step: 8
Training loss: 2.0173332691192627
Validation loss: 2.2487563497276715

Epoch: 5| Step: 9
Training loss: 2.167067050933838
Validation loss: 2.2144801783305343

Epoch: 5| Step: 10
Training loss: 1.3592188358306885
Validation loss: 2.1603690731909966

Epoch: 320| Step: 0
Training loss: 1.7617206573486328
Validation loss: 2.1402445941843014

Epoch: 5| Step: 1
Training loss: 0.99354487657547
Validation loss: 2.13460438482223

Epoch: 5| Step: 2
Training loss: 1.8614000082015991
Validation loss: 2.127283775678245

Epoch: 5| Step: 3
Training loss: 1.9439678192138672
Validation loss: 2.1453092175145305

Epoch: 5| Step: 4
Training loss: 1.771297812461853
Validation loss: 2.1079817228419806

Epoch: 5| Step: 5
Training loss: 1.939475655555725
Validation loss: 2.160618248806205

Epoch: 5| Step: 6
Training loss: 1.162482738494873
Validation loss: 2.176629865041343

Epoch: 5| Step: 7
Training loss: 1.5803855657577515
Validation loss: 2.179923406211279

Epoch: 5| Step: 8
Training loss: 1.418501377105713
Validation loss: 2.2309534600985947

Epoch: 5| Step: 9
Training loss: 1.8287792205810547
Validation loss: 2.2563134649748444

Epoch: 5| Step: 10
Training loss: 1.3597124814987183
Validation loss: 2.2800862840426865

Epoch: 321| Step: 0
Training loss: 1.8017847537994385
Validation loss: 2.2963862290946384

Epoch: 5| Step: 1
Training loss: 1.6863186359405518
Validation loss: 2.267933044382321

Epoch: 5| Step: 2
Training loss: 1.7684580087661743
Validation loss: 2.25543212890625

Epoch: 5| Step: 3
Training loss: 1.4056422710418701
Validation loss: 2.2522404219514582

Epoch: 5| Step: 4
Training loss: 1.7548866271972656
Validation loss: 2.264104550884616

Epoch: 5| Step: 5
Training loss: 1.3662673234939575
Validation loss: 2.237551171292541

Epoch: 5| Step: 6
Training loss: 1.248255968093872
Validation loss: 2.2224225792833554

Epoch: 5| Step: 7
Training loss: 1.4132882356643677
Validation loss: 2.2275457330929336

Epoch: 5| Step: 8
Training loss: 1.8679401874542236
Validation loss: 2.2266014673376597

Epoch: 5| Step: 9
Training loss: 1.661365270614624
Validation loss: 2.1987945290021997

Epoch: 5| Step: 10
Training loss: 1.410384178161621
Validation loss: 2.2294091806616834

Epoch: 322| Step: 0
Training loss: 1.9665966033935547
Validation loss: 2.237994255558137

Epoch: 5| Step: 1
Training loss: 1.1720995903015137
Validation loss: 2.213746424644224

Epoch: 5| Step: 2
Training loss: 1.5740907192230225
Validation loss: 2.2217212928238737

Epoch: 5| Step: 3
Training loss: 1.718396782875061
Validation loss: 2.1881845945953042

Epoch: 5| Step: 4
Training loss: 1.701042890548706
Validation loss: 2.1778273736276934

Epoch: 5| Step: 5
Training loss: 1.7286516427993774
Validation loss: 2.1629766059178177

Epoch: 5| Step: 6
Training loss: 1.1403888463974
Validation loss: 2.1728808879852295

Epoch: 5| Step: 7
Training loss: 1.3154170513153076
Validation loss: 2.1451634027624644

Epoch: 5| Step: 8
Training loss: 1.8588520288467407
Validation loss: 2.182714339225523

Epoch: 5| Step: 9
Training loss: 1.7980741262435913
Validation loss: 2.1855890814976027

Epoch: 5| Step: 10
Training loss: 1.0707910060882568
Validation loss: 2.22952183856759

Epoch: 323| Step: 0
Training loss: 0.8878768682479858
Validation loss: 2.200712127070273

Epoch: 5| Step: 1
Training loss: 1.0119266510009766
Validation loss: 2.246308816376553

Epoch: 5| Step: 2
Training loss: 2.1432945728302
Validation loss: 2.273508656409479

Epoch: 5| Step: 3
Training loss: 1.6699117422103882
Validation loss: 2.2876507338657173

Epoch: 5| Step: 4
Training loss: 2.2353789806365967
Validation loss: 2.2438306116288707

Epoch: 5| Step: 5
Training loss: 1.6771278381347656
Validation loss: 2.2296631028575282

Epoch: 5| Step: 6
Training loss: 1.7510486841201782
Validation loss: 2.19999982208334

Epoch: 5| Step: 7
Training loss: 1.7791650295257568
Validation loss: 2.165820839584515

Epoch: 5| Step: 8
Training loss: 1.6667468547821045
Validation loss: 2.136581805444533

Epoch: 5| Step: 9
Training loss: 1.221234679222107
Validation loss: 2.124627419697341

Epoch: 5| Step: 10
Training loss: 0.9331780076026917
Validation loss: 2.1321231549785984

Epoch: 324| Step: 0
Training loss: 1.4132827520370483
Validation loss: 2.1400476040378695

Epoch: 5| Step: 1
Training loss: 1.382240891456604
Validation loss: 2.1294047909398235

Epoch: 5| Step: 2
Training loss: 1.5186759233474731
Validation loss: 2.149094280376229

Epoch: 5| Step: 3
Training loss: 1.676281213760376
Validation loss: 2.179325052486953

Epoch: 5| Step: 4
Training loss: 1.90692138671875
Validation loss: 2.1791862518556657

Epoch: 5| Step: 5
Training loss: 1.4493687152862549
Validation loss: 2.190616443593015

Epoch: 5| Step: 6
Training loss: 1.7074801921844482
Validation loss: 2.2300312519073486

Epoch: 5| Step: 7
Training loss: 1.8367564678192139
Validation loss: 2.2357689783137333

Epoch: 5| Step: 8
Training loss: 1.3478353023529053
Validation loss: 2.2293662025082495

Epoch: 5| Step: 9
Training loss: 1.2822439670562744
Validation loss: 2.220893354826076

Epoch: 5| Step: 10
Training loss: 1.4116129875183105
Validation loss: 2.2121669348850044

Epoch: 325| Step: 0
Training loss: 1.7684829235076904
Validation loss: 2.203583276400002

Epoch: 5| Step: 1
Training loss: 1.4749139547348022
Validation loss: 2.18232330711939

Epoch: 5| Step: 2
Training loss: 1.640878677368164
Validation loss: 2.176092714391729

Epoch: 5| Step: 3
Training loss: 1.0937299728393555
Validation loss: 2.155199186776274

Epoch: 5| Step: 4
Training loss: 1.9174362421035767
Validation loss: 2.1407132225651897

Epoch: 5| Step: 5
Training loss: 1.746376633644104
Validation loss: 2.1451115659488145

Epoch: 5| Step: 6
Training loss: 1.167336106300354
Validation loss: 2.175472664576705

Epoch: 5| Step: 7
Training loss: 1.8231756687164307
Validation loss: 2.1559987824450255

Epoch: 5| Step: 8
Training loss: 1.3269466161727905
Validation loss: 2.2003454136592087

Epoch: 5| Step: 9
Training loss: 1.471947431564331
Validation loss: 2.1721391190764723

Epoch: 5| Step: 10
Training loss: 1.3596019744873047
Validation loss: 2.2149162959027033

Epoch: 326| Step: 0
Training loss: 1.5392119884490967
Validation loss: 2.1901664182703984

Epoch: 5| Step: 1
Training loss: 2.013169527053833
Validation loss: 2.189074913660685

Epoch: 5| Step: 2
Training loss: 1.2974318265914917
Validation loss: 2.171726744662049

Epoch: 5| Step: 3
Training loss: 1.707021713256836
Validation loss: 2.182965409371161

Epoch: 5| Step: 4
Training loss: 1.7579002380371094
Validation loss: 2.192734485031456

Epoch: 5| Step: 5
Training loss: 1.5661438703536987
Validation loss: 2.1627305348714194

Epoch: 5| Step: 6
Training loss: 1.4750760793685913
Validation loss: 2.1988006022668656

Epoch: 5| Step: 7
Training loss: 0.9350969195365906
Validation loss: 2.158354590016027

Epoch: 5| Step: 8
Training loss: 1.380206823348999
Validation loss: 2.2008221867263957

Epoch: 5| Step: 9
Training loss: 1.3263494968414307
Validation loss: 2.1830022399143507

Epoch: 5| Step: 10
Training loss: 1.8162113428115845
Validation loss: 2.186009112224784

Epoch: 327| Step: 0
Training loss: 1.237696886062622
Validation loss: 2.195865261939264

Epoch: 5| Step: 1
Training loss: 1.8746929168701172
Validation loss: 2.1750652046613794

Epoch: 5| Step: 2
Training loss: 1.1346923112869263
Validation loss: 2.2541387414419525

Epoch: 5| Step: 3
Training loss: 1.5848535299301147
Validation loss: 2.235806208784862

Epoch: 5| Step: 4
Training loss: 2.0481224060058594
Validation loss: 2.242583849096811

Epoch: 5| Step: 5
Training loss: 1.28374445438385
Validation loss: 2.252742278960443

Epoch: 5| Step: 6
Training loss: 1.7569841146469116
Validation loss: 2.2619679256152083

Epoch: 5| Step: 7
Training loss: 1.114871859550476
Validation loss: 2.25453213209747

Epoch: 5| Step: 8
Training loss: 1.495322823524475
Validation loss: 2.2370327711105347

Epoch: 5| Step: 9
Training loss: 1.6111915111541748
Validation loss: 2.22022311405469

Epoch: 5| Step: 10
Training loss: 1.9509358406066895
Validation loss: 2.230399759866858

Epoch: 328| Step: 0
Training loss: 1.2061198949813843
Validation loss: 2.190914261725641

Epoch: 5| Step: 1
Training loss: 2.2572262287139893
Validation loss: 2.1451786359151206

Epoch: 5| Step: 2
Training loss: 1.2241535186767578
Validation loss: 2.136241880796289

Epoch: 5| Step: 3
Training loss: 1.391594648361206
Validation loss: 2.124019293374913

Epoch: 5| Step: 4
Training loss: 1.4550873041152954
Validation loss: 2.0971738805053053

Epoch: 5| Step: 5
Training loss: 1.2055426836013794
Validation loss: 2.13138041316822

Epoch: 5| Step: 6
Training loss: 1.2429851293563843
Validation loss: 2.1231552298351

Epoch: 5| Step: 7
Training loss: 1.7895961999893188
Validation loss: 2.2132135257926038

Epoch: 5| Step: 8
Training loss: 1.9260390996932983
Validation loss: 2.202324621139034

Epoch: 5| Step: 9
Training loss: 1.5197317600250244
Validation loss: 2.20941952736147

Epoch: 5| Step: 10
Training loss: 1.6375491619110107
Validation loss: 2.247590572603287

Epoch: 329| Step: 0
Training loss: 1.7289543151855469
Validation loss: 2.2540971258635163

Epoch: 5| Step: 1
Training loss: 1.1485785245895386
Validation loss: 2.2761689270696333

Epoch: 5| Step: 2
Training loss: 1.2424981594085693
Validation loss: 2.2723074407987696

Epoch: 5| Step: 3
Training loss: 2.2761318683624268
Validation loss: 2.261499971471807

Epoch: 5| Step: 4
Training loss: 1.96826171875
Validation loss: 2.261422908434304

Epoch: 5| Step: 5
Training loss: 1.022789716720581
Validation loss: 2.231326674902311

Epoch: 5| Step: 6
Training loss: 1.5545904636383057
Validation loss: 2.1934991126419394

Epoch: 5| Step: 7
Training loss: 1.498077392578125
Validation loss: 2.1713511482361825

Epoch: 5| Step: 8
Training loss: 1.2090461254119873
Validation loss: 2.149841011211436

Epoch: 5| Step: 9
Training loss: 1.420731544494629
Validation loss: 2.163315931955973

Epoch: 5| Step: 10
Training loss: 2.048666477203369
Validation loss: 2.1366445172217583

Epoch: 330| Step: 0
Training loss: 2.2000699043273926
Validation loss: 2.1360092086176716

Epoch: 5| Step: 1
Training loss: 0.9398267865180969
Validation loss: 2.125757613489705

Epoch: 5| Step: 2
Training loss: 1.4493191242218018
Validation loss: 2.141577728333012

Epoch: 5| Step: 3
Training loss: 1.5095819234848022
Validation loss: 2.128373228093629

Epoch: 5| Step: 4
Training loss: 1.4633433818817139
Validation loss: 2.1512312581462245

Epoch: 5| Step: 5
Training loss: 1.097570538520813
Validation loss: 2.191140479938958

Epoch: 5| Step: 6
Training loss: 1.5289719104766846
Validation loss: 2.15642148704939

Epoch: 5| Step: 7
Training loss: 1.910235047340393
Validation loss: 2.2048297030951387

Epoch: 5| Step: 8
Training loss: 1.528710126876831
Validation loss: 2.2160689125778856

Epoch: 5| Step: 9
Training loss: 1.4781484603881836
Validation loss: 2.2042252479061

Epoch: 5| Step: 10
Training loss: 1.6918150186538696
Validation loss: 2.2387536110416537

Epoch: 331| Step: 0
Training loss: 1.3636070489883423
Validation loss: 2.2630384634899836

Epoch: 5| Step: 1
Training loss: 1.112264633178711
Validation loss: 2.3023638494553103

Epoch: 5| Step: 2
Training loss: 1.7286351919174194
Validation loss: 2.307522410987526

Epoch: 5| Step: 3
Training loss: 1.895381212234497
Validation loss: 2.2400222260464906

Epoch: 5| Step: 4
Training loss: 1.1924680471420288
Validation loss: 2.23899814134003

Epoch: 5| Step: 5
Training loss: 1.6726429462432861
Validation loss: 2.2264102646099624

Epoch: 5| Step: 6
Training loss: 1.1944044828414917
Validation loss: 2.223352816797072

Epoch: 5| Step: 7
Training loss: 1.4203786849975586
Validation loss: 2.180218952958302

Epoch: 5| Step: 8
Training loss: 1.921529769897461
Validation loss: 2.1589577480029036

Epoch: 5| Step: 9
Training loss: 1.4083168506622314
Validation loss: 2.164273633751818

Epoch: 5| Step: 10
Training loss: 1.89761483669281
Validation loss: 2.1743341620250414

Epoch: 332| Step: 0
Training loss: 1.2227329015731812
Validation loss: 2.1849359799456853

Epoch: 5| Step: 1
Training loss: 1.2589051723480225
Validation loss: 2.2062814415142102

Epoch: 5| Step: 2
Training loss: 1.4133479595184326
Validation loss: 2.2029310170040337

Epoch: 5| Step: 3
Training loss: 1.712904691696167
Validation loss: 2.156143976796058

Epoch: 5| Step: 4
Training loss: 1.394217848777771
Validation loss: 2.1813024692637946

Epoch: 5| Step: 5
Training loss: 1.2801969051361084
Validation loss: 2.199179122524877

Epoch: 5| Step: 6
Training loss: 1.5835522413253784
Validation loss: 2.2268558650888424

Epoch: 5| Step: 7
Training loss: 2.0818581581115723
Validation loss: 2.214026698502161

Epoch: 5| Step: 8
Training loss: 1.899328589439392
Validation loss: 2.2699893546360794

Epoch: 5| Step: 9
Training loss: 1.2484729290008545
Validation loss: 2.267959394762593

Epoch: 5| Step: 10
Training loss: 1.6556874513626099
Validation loss: 2.225768430258638

Epoch: 333| Step: 0
Training loss: 1.778874158859253
Validation loss: 2.210161045033445

Epoch: 5| Step: 1
Training loss: 1.5403183698654175
Validation loss: 2.1686798270030687

Epoch: 5| Step: 2
Training loss: 1.2542526721954346
Validation loss: 2.147563930480711

Epoch: 5| Step: 3
Training loss: 1.4679739475250244
Validation loss: 2.2013647210213447

Epoch: 5| Step: 4
Training loss: 1.1825932264328003
Validation loss: 2.1688335839138237

Epoch: 5| Step: 5
Training loss: 1.5707898139953613
Validation loss: 2.21509563538336

Epoch: 5| Step: 6
Training loss: 1.3494151830673218
Validation loss: 2.2154495049548406

Epoch: 5| Step: 7
Training loss: 1.1003035306930542
Validation loss: 2.25480640831814

Epoch: 5| Step: 8
Training loss: 1.5904171466827393
Validation loss: 2.253948691070721

Epoch: 5| Step: 9
Training loss: 1.5420262813568115
Validation loss: 2.2785744513234785

Epoch: 5| Step: 10
Training loss: 2.188894271850586
Validation loss: 2.269032706496536

Epoch: 334| Step: 0
Training loss: 1.5587579011917114
Validation loss: 2.2311377422783965

Epoch: 5| Step: 1
Training loss: 1.4779117107391357
Validation loss: 2.211542634553807

Epoch: 5| Step: 2
Training loss: 1.6103627681732178
Validation loss: 2.202544555869154

Epoch: 5| Step: 3
Training loss: 1.7752689123153687
Validation loss: 2.1931208564389135

Epoch: 5| Step: 4
Training loss: 1.3905576467514038
Validation loss: 2.1872036482698176

Epoch: 5| Step: 5
Training loss: 1.9028240442276
Validation loss: 2.189685780514953

Epoch: 5| Step: 6
Training loss: 1.1632342338562012
Validation loss: 2.181467838184808

Epoch: 5| Step: 7
Training loss: 1.3631123304367065
Validation loss: 2.1598000013700096

Epoch: 5| Step: 8
Training loss: 1.2712074518203735
Validation loss: 2.184858375980008

Epoch: 5| Step: 9
Training loss: 1.093043565750122
Validation loss: 2.200768663037208

Epoch: 5| Step: 10
Training loss: 1.878958821296692
Validation loss: 2.2041290319094093

Epoch: 335| Step: 0
Training loss: 1.4773160219192505
Validation loss: 2.196489975016604

Epoch: 5| Step: 1
Training loss: 1.5961370468139648
Validation loss: 2.2021431589639313

Epoch: 5| Step: 2
Training loss: 1.0659621953964233
Validation loss: 2.2301612643785376

Epoch: 5| Step: 3
Training loss: 1.2302899360656738
Validation loss: 2.19272421508707

Epoch: 5| Step: 4
Training loss: 1.2393906116485596
Validation loss: 2.137478877139348

Epoch: 5| Step: 5
Training loss: 2.183882236480713
Validation loss: 2.1799840491305114

Epoch: 5| Step: 6
Training loss: 1.7888786792755127
Validation loss: 2.2007643381754556

Epoch: 5| Step: 7
Training loss: 1.347095251083374
Validation loss: 2.1726200708778958

Epoch: 5| Step: 8
Training loss: 1.182742953300476
Validation loss: 2.169240049136582

Epoch: 5| Step: 9
Training loss: 1.6934301853179932
Validation loss: 2.1705417568965624

Epoch: 5| Step: 10
Training loss: 1.605708360671997
Validation loss: 2.173414348274149

Epoch: 336| Step: 0
Training loss: 1.1114438772201538
Validation loss: 2.1699553638376217

Epoch: 5| Step: 1
Training loss: 1.5475056171417236
Validation loss: 2.2190373738606772

Epoch: 5| Step: 2
Training loss: 1.5177730321884155
Validation loss: 2.232618126817929

Epoch: 5| Step: 3
Training loss: 1.6737817525863647
Validation loss: 2.2527403626390683

Epoch: 5| Step: 4
Training loss: 1.661749243736267
Validation loss: 2.267967709930994

Epoch: 5| Step: 5
Training loss: 2.003157615661621
Validation loss: 2.2718027484032417

Epoch: 5| Step: 6
Training loss: 1.3857601881027222
Validation loss: 2.274134523125105

Epoch: 5| Step: 7
Training loss: 1.577765941619873
Validation loss: 2.2441106252772833

Epoch: 5| Step: 8
Training loss: 1.162360429763794
Validation loss: 2.212698357079619

Epoch: 5| Step: 9
Training loss: 1.0868324041366577
Validation loss: 2.2030566969225482

Epoch: 5| Step: 10
Training loss: 1.5660316944122314
Validation loss: 2.174954434876801

Epoch: 337| Step: 0
Training loss: 1.553362250328064
Validation loss: 2.135100433903356

Epoch: 5| Step: 1
Training loss: 1.7745428085327148
Validation loss: 2.133354699739846

Epoch: 5| Step: 2
Training loss: 1.6656453609466553
Validation loss: 2.143923374914354

Epoch: 5| Step: 3
Training loss: 1.6541261672973633
Validation loss: 2.1255934417888684

Epoch: 5| Step: 4
Training loss: 1.7278258800506592
Validation loss: 2.107737957790334

Epoch: 5| Step: 5
Training loss: 2.174994707107544
Validation loss: 2.1498983547251713

Epoch: 5| Step: 6
Training loss: 0.9335217475891113
Validation loss: 2.1353487173716226

Epoch: 5| Step: 7
Training loss: 1.47843599319458
Validation loss: 2.1608156491351385

Epoch: 5| Step: 8
Training loss: 1.2483723163604736
Validation loss: 2.188218980707148

Epoch: 5| Step: 9
Training loss: 1.2395741939544678
Validation loss: 2.2079468081074376

Epoch: 5| Step: 10
Training loss: 0.9791542291641235
Validation loss: 2.2380077351805983

Epoch: 338| Step: 0
Training loss: 1.0332844257354736
Validation loss: 2.264918117113011

Epoch: 5| Step: 1
Training loss: 1.2626287937164307
Validation loss: 2.280342589142502

Epoch: 5| Step: 2
Training loss: 2.0520668029785156
Validation loss: 2.246916642753027

Epoch: 5| Step: 3
Training loss: 1.6444333791732788
Validation loss: 2.2925718817659604

Epoch: 5| Step: 4
Training loss: 1.2215887308120728
Validation loss: 2.2578102465598815

Epoch: 5| Step: 5
Training loss: 1.0938975811004639
Validation loss: 2.2364966933445265

Epoch: 5| Step: 6
Training loss: 1.7346744537353516
Validation loss: 2.1943870949488815

Epoch: 5| Step: 7
Training loss: 1.6018095016479492
Validation loss: 2.185508611381695

Epoch: 5| Step: 8
Training loss: 1.7120249271392822
Validation loss: 2.163955980731595

Epoch: 5| Step: 9
Training loss: 1.4193241596221924
Validation loss: 2.145284584773484

Epoch: 5| Step: 10
Training loss: 1.4909696578979492
Validation loss: 2.1709015164324033

Epoch: 339| Step: 0
Training loss: 1.65009343624115
Validation loss: 2.1901007647155435

Epoch: 5| Step: 1
Training loss: 1.4412022829055786
Validation loss: 2.1969485667444046

Epoch: 5| Step: 2
Training loss: 1.5351431369781494
Validation loss: 2.207330740908141

Epoch: 5| Step: 3
Training loss: 1.0652451515197754
Validation loss: 2.22412077073128

Epoch: 5| Step: 4
Training loss: 1.739434838294983
Validation loss: 2.203230563030448

Epoch: 5| Step: 5
Training loss: 1.8758842945098877
Validation loss: 2.222833543695429

Epoch: 5| Step: 6
Training loss: 1.7327293157577515
Validation loss: 2.1573875668228313

Epoch: 5| Step: 7
Training loss: 1.093309998512268
Validation loss: 2.1845290045584402

Epoch: 5| Step: 8
Training loss: 1.5365161895751953
Validation loss: 2.153754029222714

Epoch: 5| Step: 9
Training loss: 1.4316343069076538
Validation loss: 2.150556984768119

Epoch: 5| Step: 10
Training loss: 0.9189630150794983
Validation loss: 2.162114968863867

Epoch: 340| Step: 0
Training loss: 1.273267149925232
Validation loss: 2.169066075355776

Epoch: 5| Step: 1
Training loss: 1.2506183385849
Validation loss: 2.1375023293238815

Epoch: 5| Step: 2
Training loss: 1.7913391590118408
Validation loss: 2.1896123399016676

Epoch: 5| Step: 3
Training loss: 1.4970074892044067
Validation loss: 2.2066463116676576

Epoch: 5| Step: 4
Training loss: 1.1894868612289429
Validation loss: 2.207359039655296

Epoch: 5| Step: 5
Training loss: 0.6892300844192505
Validation loss: 2.200613178232665

Epoch: 5| Step: 6
Training loss: 1.1938693523406982
Validation loss: 2.195749072618382

Epoch: 5| Step: 7
Training loss: 1.6891553401947021
Validation loss: 2.1795050354414087

Epoch: 5| Step: 8
Training loss: 1.7208207845687866
Validation loss: 2.1202264626820884

Epoch: 5| Step: 9
Training loss: 1.9436317682266235
Validation loss: 2.1214849820701023

Epoch: 5| Step: 10
Training loss: 1.8180471658706665
Validation loss: 2.107104860326295

Epoch: 341| Step: 0
Training loss: 1.6080608367919922
Validation loss: 2.0937001423169206

Epoch: 5| Step: 1
Training loss: 1.1075108051300049
Validation loss: 2.08270441075807

Epoch: 5| Step: 2
Training loss: 1.7092821598052979
Validation loss: 2.105604315316805

Epoch: 5| Step: 3
Training loss: 1.3502963781356812
Validation loss: 2.1274621640482256

Epoch: 5| Step: 4
Training loss: 1.6360241174697876
Validation loss: 2.140085240846039

Epoch: 5| Step: 5
Training loss: 1.3093808889389038
Validation loss: 2.138963932632118

Epoch: 5| Step: 6
Training loss: 1.4343345165252686
Validation loss: 2.1813610471704954

Epoch: 5| Step: 7
Training loss: 1.563157320022583
Validation loss: 2.228835008477652

Epoch: 5| Step: 8
Training loss: 1.3451669216156006
Validation loss: 2.24753168577789

Epoch: 5| Step: 9
Training loss: 1.5330688953399658
Validation loss: 2.2345501684373423

Epoch: 5| Step: 10
Training loss: 1.2694129943847656
Validation loss: 2.257984935596425

Epoch: 342| Step: 0
Training loss: 1.8133068084716797
Validation loss: 2.25951208606843

Epoch: 5| Step: 1
Training loss: 1.2800610065460205
Validation loss: 2.2685358652504544

Epoch: 5| Step: 2
Training loss: 1.162445068359375
Validation loss: 2.206527622797156

Epoch: 5| Step: 3
Training loss: 1.155360460281372
Validation loss: 2.1717378734260477

Epoch: 5| Step: 4
Training loss: 2.080704689025879
Validation loss: 2.1723742997774513

Epoch: 5| Step: 5
Training loss: 1.2896997928619385
Validation loss: 2.173796162810377

Epoch: 5| Step: 6
Training loss: 1.031214714050293
Validation loss: 2.1406471575460126

Epoch: 5| Step: 7
Training loss: 1.1519206762313843
Validation loss: 2.1778236460942093

Epoch: 5| Step: 8
Training loss: 1.3036749362945557
Validation loss: 2.171966742443782

Epoch: 5| Step: 9
Training loss: 1.9211490154266357
Validation loss: 2.225909125420355

Epoch: 5| Step: 10
Training loss: 1.426883339881897
Validation loss: 2.1911344053924724

Epoch: 343| Step: 0
Training loss: 1.390173316001892
Validation loss: 2.233466245794809

Epoch: 5| Step: 1
Training loss: 1.356102705001831
Validation loss: 2.202216033012636

Epoch: 5| Step: 2
Training loss: 1.7077019214630127
Validation loss: 2.2007606337147374

Epoch: 5| Step: 3
Training loss: 1.0859910249710083
Validation loss: 2.2083802146296345

Epoch: 5| Step: 4
Training loss: 1.5599651336669922
Validation loss: 2.2127345454308296

Epoch: 5| Step: 5
Training loss: 1.1801421642303467
Validation loss: 2.201967902080987

Epoch: 5| Step: 6
Training loss: 1.0312364101409912
Validation loss: 2.211560362128801

Epoch: 5| Step: 7
Training loss: 1.5189599990844727
Validation loss: 2.180795943865212

Epoch: 5| Step: 8
Training loss: 2.121964931488037
Validation loss: 2.1829660707904446

Epoch: 5| Step: 9
Training loss: 1.2782024145126343
Validation loss: 2.1574594436153287

Epoch: 5| Step: 10
Training loss: 1.4156837463378906
Validation loss: 2.1772089876154417

Epoch: 344| Step: 0
Training loss: 1.8325507640838623
Validation loss: 2.1784929357549196

Epoch: 5| Step: 1
Training loss: 1.5168542861938477
Validation loss: 2.148248995504072

Epoch: 5| Step: 2
Training loss: 1.971745491027832
Validation loss: 2.154674829975251

Epoch: 5| Step: 3
Training loss: 1.0490986108779907
Validation loss: 2.157100327553288

Epoch: 5| Step: 4
Training loss: 1.1260576248168945
Validation loss: 2.169998162536211

Epoch: 5| Step: 5
Training loss: 1.7378320693969727
Validation loss: 2.1724450248543934

Epoch: 5| Step: 6
Training loss: 0.6932844519615173
Validation loss: 2.198606127051897

Epoch: 5| Step: 7
Training loss: 1.6804420948028564
Validation loss: 2.200895347902852

Epoch: 5| Step: 8
Training loss: 1.477657675743103
Validation loss: 2.198226644146827

Epoch: 5| Step: 9
Training loss: 1.3705799579620361
Validation loss: 2.1884896755218506

Epoch: 5| Step: 10
Training loss: 1.1607452630996704
Validation loss: 2.225293154357582

Epoch: 345| Step: 0
Training loss: 1.4030606746673584
Validation loss: 2.2063576277866157

Epoch: 5| Step: 1
Training loss: 1.5244717597961426
Validation loss: 2.211644334177817

Epoch: 5| Step: 2
Training loss: 1.5948184728622437
Validation loss: 2.1557448858855874

Epoch: 5| Step: 3
Training loss: 0.827014148235321
Validation loss: 2.1484748496804187

Epoch: 5| Step: 4
Training loss: 1.707811951637268
Validation loss: 2.115563145247839

Epoch: 5| Step: 5
Training loss: 1.6776920557022095
Validation loss: 2.1364683746009745

Epoch: 5| Step: 6
Training loss: 1.3802950382232666
Validation loss: 2.1045243304262877

Epoch: 5| Step: 7
Training loss: 1.2996443510055542
Validation loss: 2.1342362908906836

Epoch: 5| Step: 8
Training loss: 1.2022720575332642
Validation loss: 2.0949628096754833

Epoch: 5| Step: 9
Training loss: 1.3432304859161377
Validation loss: 2.133696767591661

Epoch: 5| Step: 10
Training loss: 1.766427755355835
Validation loss: 2.1538842467851538

Epoch: 346| Step: 0
Training loss: 1.3114001750946045
Validation loss: 2.1652138156275593

Epoch: 5| Step: 1
Training loss: 1.6774708032608032
Validation loss: 2.1851675356588056

Epoch: 5| Step: 2
Training loss: 1.6798439025878906
Validation loss: 2.20196242742641

Epoch: 5| Step: 3
Training loss: 1.4003945589065552
Validation loss: 2.197187562142649

Epoch: 5| Step: 4
Training loss: 1.183464765548706
Validation loss: 2.2044885030356784

Epoch: 5| Step: 5
Training loss: 1.4036587476730347
Validation loss: 2.2266880850638113

Epoch: 5| Step: 6
Training loss: 1.110807180404663
Validation loss: 2.206158204745221

Epoch: 5| Step: 7
Training loss: 1.3847728967666626
Validation loss: 2.1930194247153496

Epoch: 5| Step: 8
Training loss: 1.5337564945220947
Validation loss: 2.165567680071759

Epoch: 5| Step: 9
Training loss: 1.5460278987884521
Validation loss: 2.1578377216093

Epoch: 5| Step: 10
Training loss: 1.255890965461731
Validation loss: 2.152975461816275

Epoch: 347| Step: 0
Training loss: 1.2319844961166382
Validation loss: 2.170601183368314

Epoch: 5| Step: 1
Training loss: 1.3512582778930664
Validation loss: 2.1641626511850665

Epoch: 5| Step: 2
Training loss: 1.5569311380386353
Validation loss: 2.1576553237053657

Epoch: 5| Step: 3
Training loss: 1.1604779958724976
Validation loss: 2.1612149566732426

Epoch: 5| Step: 4
Training loss: 1.1485538482666016
Validation loss: 2.166471419795867

Epoch: 5| Step: 5
Training loss: 1.8426494598388672
Validation loss: 2.156335469215147

Epoch: 5| Step: 6
Training loss: 1.3956934213638306
Validation loss: 2.1766195553605274

Epoch: 5| Step: 7
Training loss: 1.1476459503173828
Validation loss: 2.158576096257856

Epoch: 5| Step: 8
Training loss: 1.407923698425293
Validation loss: 2.1833795834613103

Epoch: 5| Step: 9
Training loss: 1.6606905460357666
Validation loss: 2.1935698486143544

Epoch: 5| Step: 10
Training loss: 1.5488076210021973
Validation loss: 2.1821556065672185

Epoch: 348| Step: 0
Training loss: 1.1196314096450806
Validation loss: 2.1577417081402195

Epoch: 5| Step: 1
Training loss: 1.8741023540496826
Validation loss: 2.1606320758019724

Epoch: 5| Step: 2
Training loss: 1.606891393661499
Validation loss: 2.1694189848438388

Epoch: 5| Step: 3
Training loss: 1.2550214529037476
Validation loss: 2.147707329001478

Epoch: 5| Step: 4
Training loss: 1.9079954624176025
Validation loss: 2.1813759239771033

Epoch: 5| Step: 5
Training loss: 1.2315752506256104
Validation loss: 2.200470145030688

Epoch: 5| Step: 6
Training loss: 1.3350802659988403
Validation loss: 2.1974691319209274

Epoch: 5| Step: 7
Training loss: 1.0932958126068115
Validation loss: 2.187153644459222

Epoch: 5| Step: 8
Training loss: 1.4215675592422485
Validation loss: 2.17006653611378

Epoch: 5| Step: 9
Training loss: 1.628146767616272
Validation loss: 2.1951199603337113

Epoch: 5| Step: 10
Training loss: 0.829627513885498
Validation loss: 2.178794587812116

Epoch: 349| Step: 0
Training loss: 1.094641089439392
Validation loss: 2.1412039213283087

Epoch: 5| Step: 1
Training loss: 1.1242345571517944
Validation loss: 2.137411812300323

Epoch: 5| Step: 2
Training loss: 1.7403007745742798
Validation loss: 2.132254636415871

Epoch: 5| Step: 3
Training loss: 1.0662237405776978
Validation loss: 2.1261989249978015

Epoch: 5| Step: 4
Training loss: 1.2022664546966553
Validation loss: 2.155087042880315

Epoch: 5| Step: 5
Training loss: 1.3793432712554932
Validation loss: 2.176979023923156

Epoch: 5| Step: 6
Training loss: 1.718125581741333
Validation loss: 2.201533764921209

Epoch: 5| Step: 7
Training loss: 1.3953005075454712
Validation loss: 2.209591019538141

Epoch: 5| Step: 8
Training loss: 1.3940529823303223
Validation loss: 2.2403021807311685

Epoch: 5| Step: 9
Training loss: 1.8196481466293335
Validation loss: 2.2332938153256654

Epoch: 5| Step: 10
Training loss: 1.4150264263153076
Validation loss: 2.2347143132199525

Epoch: 350| Step: 0
Training loss: 1.4915392398834229
Validation loss: 2.211935045898602

Epoch: 5| Step: 1
Training loss: 1.2801241874694824
Validation loss: 2.200478958827193

Epoch: 5| Step: 2
Training loss: 1.4527714252471924
Validation loss: 2.19653828682438

Epoch: 5| Step: 3
Training loss: 1.451221227645874
Validation loss: 2.1898915434396393

Epoch: 5| Step: 4
Training loss: 1.9378478527069092
Validation loss: 2.1735378926800144

Epoch: 5| Step: 5
Training loss: 1.008703589439392
Validation loss: 2.1884205392611924

Epoch: 5| Step: 6
Training loss: 0.8509082794189453
Validation loss: 2.1836831108216317

Epoch: 5| Step: 7
Training loss: 1.315325379371643
Validation loss: 2.1769311351160847

Epoch: 5| Step: 8
Training loss: 1.5244957208633423
Validation loss: 2.148940823411429

Epoch: 5| Step: 9
Training loss: 1.3308308124542236
Validation loss: 2.182793830030708

Epoch: 5| Step: 10
Training loss: 1.5080114603042603
Validation loss: 2.1475210587183633

Epoch: 351| Step: 0
Training loss: 1.5303676128387451
Validation loss: 2.172915827843451

Epoch: 5| Step: 1
Training loss: 1.0653784275054932
Validation loss: 2.1927414927431332

Epoch: 5| Step: 2
Training loss: 1.3465672731399536
Validation loss: 2.187817906820646

Epoch: 5| Step: 3
Training loss: 1.4066181182861328
Validation loss: 2.1702605755098405

Epoch: 5| Step: 4
Training loss: 1.3853776454925537
Validation loss: 2.1705119981560657

Epoch: 5| Step: 5
Training loss: 1.4306827783584595
Validation loss: 2.188983928772711

Epoch: 5| Step: 6
Training loss: 0.9574335217475891
Validation loss: 2.1554905958073114

Epoch: 5| Step: 7
Training loss: 1.6528924703598022
Validation loss: 2.161082649743685

Epoch: 5| Step: 8
Training loss: 1.5608408451080322
Validation loss: 2.179451770679925

Epoch: 5| Step: 9
Training loss: 1.3336085081100464
Validation loss: 2.209270028657811

Epoch: 5| Step: 10
Training loss: 1.6344621181488037
Validation loss: 2.2050092104942567

Epoch: 352| Step: 0
Training loss: 0.6415323615074158
Validation loss: 2.240688454720282

Epoch: 5| Step: 1
Training loss: 1.501326322555542
Validation loss: 2.288172714171871

Epoch: 5| Step: 2
Training loss: 1.3836467266082764
Validation loss: 2.2391474836616108

Epoch: 5| Step: 3
Training loss: 1.1123318672180176
Validation loss: 2.232971509297689

Epoch: 5| Step: 4
Training loss: 1.7752676010131836
Validation loss: 2.227944343320785

Epoch: 5| Step: 5
Training loss: 0.9945722818374634
Validation loss: 2.1752696985839517

Epoch: 5| Step: 6
Training loss: 1.7450584173202515
Validation loss: 2.1985921385467693

Epoch: 5| Step: 7
Training loss: 1.3873246908187866
Validation loss: 2.196772293377948

Epoch: 5| Step: 8
Training loss: 1.860581636428833
Validation loss: 2.209181506146667

Epoch: 5| Step: 9
Training loss: 1.3543365001678467
Validation loss: 2.1909140591980307

Epoch: 5| Step: 10
Training loss: 1.290236473083496
Validation loss: 2.160836427442489

Epoch: 353| Step: 0
Training loss: 1.2436599731445312
Validation loss: 2.187918701479512

Epoch: 5| Step: 1
Training loss: 1.485442876815796
Validation loss: 2.1869692520428727

Epoch: 5| Step: 2
Training loss: 0.8063421249389648
Validation loss: 2.148932159587901

Epoch: 5| Step: 3
Training loss: 1.049156904220581
Validation loss: 2.1449570066185406

Epoch: 5| Step: 4
Training loss: 1.2813999652862549
Validation loss: 2.1109084134460776

Epoch: 5| Step: 5
Training loss: 1.3066987991333008
Validation loss: 2.114535052289245

Epoch: 5| Step: 6
Training loss: 2.0037331581115723
Validation loss: 2.1435862433525825

Epoch: 5| Step: 7
Training loss: 1.7921350002288818
Validation loss: 2.161538932913093

Epoch: 5| Step: 8
Training loss: 1.1440023183822632
Validation loss: 2.1748960800068353

Epoch: 5| Step: 9
Training loss: 1.4638570547103882
Validation loss: 2.171146405640469

Epoch: 5| Step: 10
Training loss: 1.5542672872543335
Validation loss: 2.1511727776578677

Epoch: 354| Step: 0
Training loss: 1.0340955257415771
Validation loss: 2.2106217338192846

Epoch: 5| Step: 1
Training loss: 1.6049740314483643
Validation loss: 2.2194388938206497

Epoch: 5| Step: 2
Training loss: 1.0874536037445068
Validation loss: 2.2205087805307038

Epoch: 5| Step: 3
Training loss: 1.389642357826233
Validation loss: 2.2373436830377065

Epoch: 5| Step: 4
Training loss: 1.5599595308303833
Validation loss: 2.2242020945395193

Epoch: 5| Step: 5
Training loss: 1.1787731647491455
Validation loss: 2.228727476571196

Epoch: 5| Step: 6
Training loss: 1.7381584644317627
Validation loss: 2.228873442578059

Epoch: 5| Step: 7
Training loss: 1.4970448017120361
Validation loss: 2.2196730413744525

Epoch: 5| Step: 8
Training loss: 1.5656137466430664
Validation loss: 2.1905165628720353

Epoch: 5| Step: 9
Training loss: 1.4847019910812378
Validation loss: 2.178649988225711

Epoch: 5| Step: 10
Training loss: 0.785342812538147
Validation loss: 2.161468013640373

Epoch: 355| Step: 0
Training loss: 1.0861321687698364
Validation loss: 2.1498715326350224

Epoch: 5| Step: 1
Training loss: 0.7673619985580444
Validation loss: 2.1518732206795805

Epoch: 5| Step: 2
Training loss: 1.0011484622955322
Validation loss: 2.127782772946101

Epoch: 5| Step: 3
Training loss: 1.3515901565551758
Validation loss: 2.1439293315333705

Epoch: 5| Step: 4
Training loss: 1.7274783849716187
Validation loss: 2.1502683149871005

Epoch: 5| Step: 5
Training loss: 1.6596081256866455
Validation loss: 2.1588066777875348

Epoch: 5| Step: 6
Training loss: 1.4638968706130981
Validation loss: 2.163850663810648

Epoch: 5| Step: 7
Training loss: 1.5860412120819092
Validation loss: 2.1660993047939834

Epoch: 5| Step: 8
Training loss: 1.2017443180084229
Validation loss: 2.18035513483068

Epoch: 5| Step: 9
Training loss: 1.8742287158966064
Validation loss: 2.2007937328789824

Epoch: 5| Step: 10
Training loss: 1.2297109365463257
Validation loss: 2.167316731586251

Epoch: 356| Step: 0
Training loss: 1.0342814922332764
Validation loss: 2.1629113689545663

Epoch: 5| Step: 1
Training loss: 1.2374204397201538
Validation loss: 2.151021462614818

Epoch: 5| Step: 2
Training loss: 1.7862815856933594
Validation loss: 2.1350923481807915

Epoch: 5| Step: 3
Training loss: 1.4815633296966553
Validation loss: 2.1354285632410357

Epoch: 5| Step: 4
Training loss: 1.5071046352386475
Validation loss: 2.1089813529804187

Epoch: 5| Step: 5
Training loss: 1.5003529787063599
Validation loss: 2.123479120192989

Epoch: 5| Step: 6
Training loss: 1.0062711238861084
Validation loss: 2.1247101919625395

Epoch: 5| Step: 7
Training loss: 1.6052573919296265
Validation loss: 2.147347263110581

Epoch: 5| Step: 8
Training loss: 1.537018895149231
Validation loss: 2.1539583744541293

Epoch: 5| Step: 9
Training loss: 0.9560815691947937
Validation loss: 2.16757208301175

Epoch: 5| Step: 10
Training loss: 1.278061866760254
Validation loss: 2.1770853022093415

Epoch: 357| Step: 0
Training loss: 1.39716637134552
Validation loss: 2.1948514702499553

Epoch: 5| Step: 1
Training loss: 1.4561660289764404
Validation loss: 2.1983840029726744

Epoch: 5| Step: 2
Training loss: 1.2137722969055176
Validation loss: 2.196980268724503

Epoch: 5| Step: 3
Training loss: 1.5462563037872314
Validation loss: 2.2138074982550835

Epoch: 5| Step: 4
Training loss: 1.5310430526733398
Validation loss: 2.180114725584625

Epoch: 5| Step: 5
Training loss: 1.2221568822860718
Validation loss: 2.184166495518018

Epoch: 5| Step: 6
Training loss: 1.4022407531738281
Validation loss: 2.185446321323354

Epoch: 5| Step: 7
Training loss: 1.1741739511489868
Validation loss: 2.1102008832398282

Epoch: 5| Step: 8
Training loss: 1.3826297521591187
Validation loss: 2.140447126921787

Epoch: 5| Step: 9
Training loss: 1.5714821815490723
Validation loss: 2.1032096519265124

Epoch: 5| Step: 10
Training loss: 0.8082672953605652
Validation loss: 2.0952607790629068

Epoch: 358| Step: 0
Training loss: 1.7499336004257202
Validation loss: 2.1283044584335817

Epoch: 5| Step: 1
Training loss: 1.926425576210022
Validation loss: 2.1390674755137455

Epoch: 5| Step: 2
Training loss: 1.332892656326294
Validation loss: 2.146581490834554

Epoch: 5| Step: 3
Training loss: 1.1522891521453857
Validation loss: 2.117846632516512

Epoch: 5| Step: 4
Training loss: 1.349994421005249
Validation loss: 2.174269219880463

Epoch: 5| Step: 5
Training loss: 1.4754530191421509
Validation loss: 2.215711814101024

Epoch: 5| Step: 6
Training loss: 1.3511228561401367
Validation loss: 2.2353070884622555

Epoch: 5| Step: 7
Training loss: 1.425340175628662
Validation loss: 2.2143519783532746

Epoch: 5| Step: 8
Training loss: 0.8690722584724426
Validation loss: 2.194495636929748

Epoch: 5| Step: 9
Training loss: 1.0747431516647339
Validation loss: 2.1909757250098774

Epoch: 5| Step: 10
Training loss: 1.118233561515808
Validation loss: 2.173010528728526

Epoch: 359| Step: 0
Training loss: 1.084631323814392
Validation loss: 2.153311675594699

Epoch: 5| Step: 1
Training loss: 1.7198257446289062
Validation loss: 2.128377119700114

Epoch: 5| Step: 2
Training loss: 1.2424659729003906
Validation loss: 2.163984692224892

Epoch: 5| Step: 3
Training loss: 1.6562597751617432
Validation loss: 2.160137609768939

Epoch: 5| Step: 4
Training loss: 1.0980068445205688
Validation loss: 2.172076286808137

Epoch: 5| Step: 5
Training loss: 1.5763344764709473
Validation loss: 2.17570000310098

Epoch: 5| Step: 6
Training loss: 1.232305884361267
Validation loss: 2.174243615519616

Epoch: 5| Step: 7
Training loss: 1.4090927839279175
Validation loss: 2.1811852839685257

Epoch: 5| Step: 8
Training loss: 1.0400880575180054
Validation loss: 2.201809193498345

Epoch: 5| Step: 9
Training loss: 1.17775559425354
Validation loss: 2.244685237125684

Epoch: 5| Step: 10
Training loss: 1.5069741010665894
Validation loss: 2.2312739767054075

Epoch: 360| Step: 0
Training loss: 1.015791893005371
Validation loss: 2.24960264595606

Epoch: 5| Step: 1
Training loss: 1.0554859638214111
Validation loss: 2.235009539511896

Epoch: 5| Step: 2
Training loss: 1.1791492700576782
Validation loss: 2.235513097496443

Epoch: 5| Step: 3
Training loss: 1.4179813861846924
Validation loss: 2.2306346047309136

Epoch: 5| Step: 4
Training loss: 1.544476866722107
Validation loss: 2.2063490985542216

Epoch: 5| Step: 5
Training loss: 1.2027442455291748
Validation loss: 2.190912608177431

Epoch: 5| Step: 6
Training loss: 1.4992989301681519
Validation loss: 2.126497007185413

Epoch: 5| Step: 7
Training loss: 1.1932504177093506
Validation loss: 2.1495808452688236

Epoch: 5| Step: 8
Training loss: 1.1784251928329468
Validation loss: 2.109754575196133

Epoch: 5| Step: 9
Training loss: 1.5324550867080688
Validation loss: 2.114600552025662

Epoch: 5| Step: 10
Training loss: 1.93023681640625
Validation loss: 2.1129341945853284

Epoch: 361| Step: 0
Training loss: 0.8979549407958984
Validation loss: 2.0811852921721754

Epoch: 5| Step: 1
Training loss: 1.4974318742752075
Validation loss: 2.1223319550996185

Epoch: 5| Step: 2
Training loss: 1.3196138143539429
Validation loss: 2.114417376056794

Epoch: 5| Step: 3
Training loss: 1.3146469593048096
Validation loss: 2.080781118844145

Epoch: 5| Step: 4
Training loss: 0.9826775789260864
Validation loss: 2.1487559810761483

Epoch: 5| Step: 5
Training loss: 1.0726367235183716
Validation loss: 2.181711043080976

Epoch: 5| Step: 6
Training loss: 1.2898589372634888
Validation loss: 2.192351213065527

Epoch: 5| Step: 7
Training loss: 1.8604917526245117
Validation loss: 2.2541193116095757

Epoch: 5| Step: 8
Training loss: 1.4437510967254639
Validation loss: 2.2874672002689813

Epoch: 5| Step: 9
Training loss: 1.5354408025741577
Validation loss: 2.306599724677301

Epoch: 5| Step: 10
Training loss: 1.539833426475525
Validation loss: 2.2482919974993636

Epoch: 362| Step: 0
Training loss: 1.228979468345642
Validation loss: 2.2563272214704946

Epoch: 5| Step: 1
Training loss: 1.318202018737793
Validation loss: 2.2480720063691497

Epoch: 5| Step: 2
Training loss: 1.3946701288223267
Validation loss: 2.186568788302842

Epoch: 5| Step: 3
Training loss: 1.1587315797805786
Validation loss: 2.1880211996775802

Epoch: 5| Step: 4
Training loss: 1.328513264656067
Validation loss: 2.0960439892225367

Epoch: 5| Step: 5
Training loss: 1.5418920516967773
Validation loss: 2.124576553221672

Epoch: 5| Step: 6
Training loss: 1.241446852684021
Validation loss: 2.1069264873381583

Epoch: 5| Step: 7
Training loss: 1.2698132991790771
Validation loss: 2.070140820677562

Epoch: 5| Step: 8
Training loss: 1.8372637033462524
Validation loss: 2.0846612299642255

Epoch: 5| Step: 9
Training loss: 1.3152191638946533
Validation loss: 2.06162703165444

Epoch: 5| Step: 10
Training loss: 1.1560585498809814
Validation loss: 2.1015464387914187

Epoch: 363| Step: 0
Training loss: 1.2478443384170532
Validation loss: 2.1183819232448453

Epoch: 5| Step: 1
Training loss: 1.2858235836029053
Validation loss: 2.1139295357529835

Epoch: 5| Step: 2
Training loss: 1.5297877788543701
Validation loss: 2.1139326659581994

Epoch: 5| Step: 3
Training loss: 1.2068248987197876
Validation loss: 2.209378832130022

Epoch: 5| Step: 4
Training loss: 1.3522727489471436
Validation loss: 2.2241871895328647

Epoch: 5| Step: 5
Training loss: 1.638538122177124
Validation loss: 2.3003222737261044

Epoch: 5| Step: 6
Training loss: 1.2127149105072021
Validation loss: 2.292429890683902

Epoch: 5| Step: 7
Training loss: 1.1330687999725342
Validation loss: 2.3148837499721076

Epoch: 5| Step: 8
Training loss: 1.1837693452835083
Validation loss: 2.307691647160438

Epoch: 5| Step: 9
Training loss: 1.5826846361160278
Validation loss: 2.306642988676666

Epoch: 5| Step: 10
Training loss: 1.3852061033248901
Validation loss: 2.2782569239216466

Epoch: 364| Step: 0
Training loss: 1.1232489347457886
Validation loss: 2.223173749062323

Epoch: 5| Step: 1
Training loss: 1.0712406635284424
Validation loss: 2.188539521668547

Epoch: 5| Step: 2
Training loss: 1.6836563348770142
Validation loss: 2.1311185795773744

Epoch: 5| Step: 3
Training loss: 1.3206346035003662
Validation loss: 2.124136273578931

Epoch: 5| Step: 4
Training loss: 1.6479389667510986
Validation loss: 2.1248031854629517

Epoch: 5| Step: 5
Training loss: 2.0012383460998535
Validation loss: 2.0860990426873647

Epoch: 5| Step: 6
Training loss: 1.282226324081421
Validation loss: 2.098477214895269

Epoch: 5| Step: 7
Training loss: 1.0448726415634155
Validation loss: 2.1188564838901645

Epoch: 5| Step: 8
Training loss: 1.2679481506347656
Validation loss: 2.0987792502167406

Epoch: 5| Step: 9
Training loss: 0.731897234916687
Validation loss: 2.125083590066561

Epoch: 5| Step: 10
Training loss: 1.3179657459259033
Validation loss: 2.093909905802819

Epoch: 365| Step: 0
Training loss: 1.2931381464004517
Validation loss: 2.132469259282594

Epoch: 5| Step: 1
Training loss: 1.5598360300064087
Validation loss: 2.181506076166707

Epoch: 5| Step: 2
Training loss: 1.829867959022522
Validation loss: 2.205809393236714

Epoch: 5| Step: 3
Training loss: 1.2535244226455688
Validation loss: 2.2059076652731946

Epoch: 5| Step: 4
Training loss: 1.2749931812286377
Validation loss: 2.2393533158045944

Epoch: 5| Step: 5
Training loss: 1.4300639629364014
Validation loss: 2.212241300972559

Epoch: 5| Step: 6
Training loss: 1.3387162685394287
Validation loss: 2.2176575173613844

Epoch: 5| Step: 7
Training loss: 1.0860142707824707
Validation loss: 2.21240492533612

Epoch: 5| Step: 8
Training loss: 1.0088077783584595
Validation loss: 2.2332867986412457

Epoch: 5| Step: 9
Training loss: 1.2751057147979736
Validation loss: 2.171608353173861

Epoch: 5| Step: 10
Training loss: 1.1610082387924194
Validation loss: 2.135411834204069

Epoch: 366| Step: 0
Training loss: 1.4728779792785645
Validation loss: 2.1203744129468034

Epoch: 5| Step: 1
Training loss: 1.5327138900756836
Validation loss: 2.1011614773863103

Epoch: 5| Step: 2
Training loss: 0.9185609817504883
Validation loss: 2.0913304692955426

Epoch: 5| Step: 3
Training loss: 1.4402458667755127
Validation loss: 2.1057637712006927

Epoch: 5| Step: 4
Training loss: 1.082716703414917
Validation loss: 2.0899115390675043

Epoch: 5| Step: 5
Training loss: 2.011904001235962
Validation loss: 2.1336850273993706

Epoch: 5| Step: 6
Training loss: 1.0928142070770264
Validation loss: 2.16338925720543

Epoch: 5| Step: 7
Training loss: 0.7593252062797546
Validation loss: 2.1564281089331514

Epoch: 5| Step: 8
Training loss: 1.6648139953613281
Validation loss: 2.178638107033186

Epoch: 5| Step: 9
Training loss: 1.1457394361495972
Validation loss: 2.22214436915613

Epoch: 5| Step: 10
Training loss: 1.165867567062378
Validation loss: 2.261961767750402

Epoch: 367| Step: 0
Training loss: 1.2458412647247314
Validation loss: 2.2237735461163264

Epoch: 5| Step: 1
Training loss: 0.9113196134567261
Validation loss: 2.213752028762653

Epoch: 5| Step: 2
Training loss: 1.162532091140747
Validation loss: 2.174440892793799

Epoch: 5| Step: 3
Training loss: 1.0409820079803467
Validation loss: 2.1530166236303185

Epoch: 5| Step: 4
Training loss: 1.1077474355697632
Validation loss: 2.122811634053466

Epoch: 5| Step: 5
Training loss: 1.7753407955169678
Validation loss: 2.148905841253137

Epoch: 5| Step: 6
Training loss: 1.2562987804412842
Validation loss: 2.1244842980497625

Epoch: 5| Step: 7
Training loss: 1.1009804010391235
Validation loss: 2.1283678726483415

Epoch: 5| Step: 8
Training loss: 1.653372049331665
Validation loss: 2.1170748997760076

Epoch: 5| Step: 9
Training loss: 1.7251323461532593
Validation loss: 2.121956467628479

Epoch: 5| Step: 10
Training loss: 1.3504477739334106
Validation loss: 2.1194425475212837

Epoch: 368| Step: 0
Training loss: 0.7219870090484619
Validation loss: 2.133202765577583

Epoch: 5| Step: 1
Training loss: 1.7511546611785889
Validation loss: 2.115834659145724

Epoch: 5| Step: 2
Training loss: 1.110924482345581
Validation loss: 2.0987540009201213

Epoch: 5| Step: 3
Training loss: 1.7116611003875732
Validation loss: 2.123775610359766

Epoch: 5| Step: 4
Training loss: 1.5585362911224365
Validation loss: 2.13604292561931

Epoch: 5| Step: 5
Training loss: 1.3458251953125
Validation loss: 2.140119038602357

Epoch: 5| Step: 6
Training loss: 0.9457703828811646
Validation loss: 2.170233375282698

Epoch: 5| Step: 7
Training loss: 1.2132270336151123
Validation loss: 2.2023624015110794

Epoch: 5| Step: 8
Training loss: 1.056261658668518
Validation loss: 2.2034654745491604

Epoch: 5| Step: 9
Training loss: 1.4690250158309937
Validation loss: 2.2186308522378244

Epoch: 5| Step: 10
Training loss: 1.1380833387374878
Validation loss: 2.2037971353018158

Epoch: 369| Step: 0
Training loss: 2.100499391555786
Validation loss: 2.2357560793558755

Epoch: 5| Step: 1
Training loss: 1.057281255722046
Validation loss: 2.1935800839495916

Epoch: 5| Step: 2
Training loss: 0.9554608464241028
Validation loss: 2.188759216698267

Epoch: 5| Step: 3
Training loss: 1.3932654857635498
Validation loss: 2.209797111890649

Epoch: 5| Step: 4
Training loss: 1.3874224424362183
Validation loss: 2.1780043468680432

Epoch: 5| Step: 5
Training loss: 1.0948671102523804
Validation loss: 2.1548159865922827

Epoch: 5| Step: 6
Training loss: 1.7700484991073608
Validation loss: 2.1759498273172686

Epoch: 5| Step: 7
Training loss: 1.3161861896514893
Validation loss: 2.1625213571774062

Epoch: 5| Step: 8
Training loss: 0.9786790013313293
Validation loss: 2.1769049116360244

Epoch: 5| Step: 9
Training loss: 1.193894386291504
Validation loss: 2.184050626652215

Epoch: 5| Step: 10
Training loss: 1.021938681602478
Validation loss: 2.1977178845354306

Epoch: 370| Step: 0
Training loss: 1.1354644298553467
Validation loss: 2.1942095807803574

Epoch: 5| Step: 1
Training loss: 1.4196432828903198
Validation loss: 2.2264021801692184

Epoch: 5| Step: 2
Training loss: 1.4165271520614624
Validation loss: 2.2435896076181883

Epoch: 5| Step: 3
Training loss: 1.3924299478530884
Validation loss: 2.247882047007161

Epoch: 5| Step: 4
Training loss: 1.498557448387146
Validation loss: 2.247516958944259

Epoch: 5| Step: 5
Training loss: 1.5077664852142334
Validation loss: 2.2160091400146484

Epoch: 5| Step: 6
Training loss: 0.849096417427063
Validation loss: 2.2439688123682493

Epoch: 5| Step: 7
Training loss: 1.2424814701080322
Validation loss: 2.177897669935739

Epoch: 5| Step: 8
Training loss: 1.2956889867782593
Validation loss: 2.212415829781563

Epoch: 5| Step: 9
Training loss: 1.149652123451233
Validation loss: 2.1574820369802494

Epoch: 5| Step: 10
Training loss: 1.334670066833496
Validation loss: 2.1884891038299887

Epoch: 371| Step: 0
Training loss: 1.3876736164093018
Validation loss: 2.172501294843612

Epoch: 5| Step: 1
Training loss: 1.5899854898452759
Validation loss: 2.153309133745009

Epoch: 5| Step: 2
Training loss: 1.0907907485961914
Validation loss: 2.166058532653316

Epoch: 5| Step: 3
Training loss: 1.241668462753296
Validation loss: 2.1673066026421

Epoch: 5| Step: 4
Training loss: 1.1962454319000244
Validation loss: 2.124056336700275

Epoch: 5| Step: 5
Training loss: 1.270514965057373
Validation loss: 2.0995493217181136

Epoch: 5| Step: 6
Training loss: 1.267592430114746
Validation loss: 2.1065036712154264

Epoch: 5| Step: 7
Training loss: 0.8978105783462524
Validation loss: 2.0903798380205707

Epoch: 5| Step: 8
Training loss: 1.0941588878631592
Validation loss: 2.0918494360421294

Epoch: 5| Step: 9
Training loss: 1.6590324640274048
Validation loss: 2.103953892184842

Epoch: 5| Step: 10
Training loss: 1.3012847900390625
Validation loss: 2.126357105470473

Epoch: 372| Step: 0
Training loss: 0.9853295087814331
Validation loss: 2.148542458011258

Epoch: 5| Step: 1
Training loss: 1.6180328130722046
Validation loss: 2.149013057831795

Epoch: 5| Step: 2
Training loss: 1.0028438568115234
Validation loss: 2.14690976501793

Epoch: 5| Step: 3
Training loss: 1.4639843702316284
Validation loss: 2.1287607633939354

Epoch: 5| Step: 4
Training loss: 1.4359633922576904
Validation loss: 2.151230800536371

Epoch: 5| Step: 5
Training loss: 1.468658447265625
Validation loss: 2.1273724007350143

Epoch: 5| Step: 6
Training loss: 1.0215892791748047
Validation loss: 2.1371451911105903

Epoch: 5| Step: 7
Training loss: 1.302553415298462
Validation loss: 2.1539990978856243

Epoch: 5| Step: 8
Training loss: 1.4199817180633545
Validation loss: 2.19016739373566

Epoch: 5| Step: 9
Training loss: 0.9746450185775757
Validation loss: 2.1648888690497285

Epoch: 5| Step: 10
Training loss: 1.4253164529800415
Validation loss: 2.166378637795807

Epoch: 373| Step: 0
Training loss: 1.2312837839126587
Validation loss: 2.1934017109614548

Epoch: 5| Step: 1
Training loss: 1.0467265844345093
Validation loss: 2.180324464715937

Epoch: 5| Step: 2
Training loss: 1.255774736404419
Validation loss: 2.200205292752994

Epoch: 5| Step: 3
Training loss: 1.1840229034423828
Validation loss: 2.1914743428589194

Epoch: 5| Step: 4
Training loss: 1.0259538888931274
Validation loss: 2.1624691922177552

Epoch: 5| Step: 5
Training loss: 0.9668546915054321
Validation loss: 2.1275472615354802

Epoch: 5| Step: 6
Training loss: 1.9359309673309326
Validation loss: 2.106887966073969

Epoch: 5| Step: 7
Training loss: 1.057873010635376
Validation loss: 2.1282901738279607

Epoch: 5| Step: 8
Training loss: 1.2054684162139893
Validation loss: 2.1133624892080984

Epoch: 5| Step: 9
Training loss: 1.575656533241272
Validation loss: 2.143553836371309

Epoch: 5| Step: 10
Training loss: 1.6678714752197266
Validation loss: 2.1404189627657653

Epoch: 374| Step: 0
Training loss: 1.0794867277145386
Validation loss: 2.160891766189247

Epoch: 5| Step: 1
Training loss: 0.8646525144577026
Validation loss: 2.1808340780196653

Epoch: 5| Step: 2
Training loss: 1.6488651037216187
Validation loss: 2.1991740401073168

Epoch: 5| Step: 3
Training loss: 0.9946342706680298
Validation loss: 2.2008185117475447

Epoch: 5| Step: 4
Training loss: 0.9140012860298157
Validation loss: 2.1910075551720074

Epoch: 5| Step: 5
Training loss: 1.6005252599716187
Validation loss: 2.1791665220773346

Epoch: 5| Step: 6
Training loss: 0.8323570489883423
Validation loss: 2.1162912896884385

Epoch: 5| Step: 7
Training loss: 1.6794601678848267
Validation loss: 2.130963138354722

Epoch: 5| Step: 8
Training loss: 1.5514113903045654
Validation loss: 2.1132981213190223

Epoch: 5| Step: 9
Training loss: 1.658516526222229
Validation loss: 2.1029543530556465

Epoch: 5| Step: 10
Training loss: 0.9204235672950745
Validation loss: 2.1037071430554954

Epoch: 375| Step: 0
Training loss: 0.827970027923584
Validation loss: 2.107183840966994

Epoch: 5| Step: 1
Training loss: 1.5528382062911987
Validation loss: 2.1036952836539156

Epoch: 5| Step: 2
Training loss: 1.349292516708374
Validation loss: 2.1537578798109487

Epoch: 5| Step: 3
Training loss: 0.9093219041824341
Validation loss: 2.1492509636827695

Epoch: 5| Step: 4
Training loss: 1.433810830116272
Validation loss: 2.1772522721239316

Epoch: 5| Step: 5
Training loss: 1.067436933517456
Validation loss: 2.1960983660913285

Epoch: 5| Step: 6
Training loss: 1.5540504455566406
Validation loss: 2.1597028291353615

Epoch: 5| Step: 7
Training loss: 1.2964361906051636
Validation loss: 2.1682561443698023

Epoch: 5| Step: 8
Training loss: 0.9446126818656921
Validation loss: 2.191928421297381

Epoch: 5| Step: 9
Training loss: 1.8339430093765259
Validation loss: 2.1898185719725904

Epoch: 5| Step: 10
Training loss: 0.9732494354248047
Validation loss: 2.184583753667852

Epoch: 376| Step: 0
Training loss: 1.5092610120773315
Validation loss: 2.189175416064519

Epoch: 5| Step: 1
Training loss: 1.5477960109710693
Validation loss: 2.2009668068219255

Epoch: 5| Step: 2
Training loss: 0.9405964016914368
Validation loss: 2.1857537838720504

Epoch: 5| Step: 3
Training loss: 1.3260012865066528
Validation loss: 2.2249396116502824

Epoch: 5| Step: 4
Training loss: 1.111955165863037
Validation loss: 2.205758874134351

Epoch: 5| Step: 5
Training loss: 0.936160683631897
Validation loss: 2.184809789862684

Epoch: 5| Step: 6
Training loss: 1.1573774814605713
Validation loss: 2.19399025876035

Epoch: 5| Step: 7
Training loss: 1.2165062427520752
Validation loss: 2.206822179978894

Epoch: 5| Step: 8
Training loss: 1.1416817903518677
Validation loss: 2.186332710327641

Epoch: 5| Step: 9
Training loss: 1.4208323955535889
Validation loss: 2.210925635471139

Epoch: 5| Step: 10
Training loss: 1.3153831958770752
Validation loss: 2.1516316244679112

Epoch: 377| Step: 0
Training loss: 1.7933940887451172
Validation loss: 2.1479893781805552

Epoch: 5| Step: 1
Training loss: 1.631347894668579
Validation loss: 2.1327371943381523

Epoch: 5| Step: 2
Training loss: 1.274310827255249
Validation loss: 2.1445876398394184

Epoch: 5| Step: 3
Training loss: 1.0947542190551758
Validation loss: 2.1460414368619203

Epoch: 5| Step: 4
Training loss: 0.9826995730400085
Validation loss: 2.135173936044016

Epoch: 5| Step: 5
Training loss: 0.9068034887313843
Validation loss: 2.1313970255595382

Epoch: 5| Step: 6
Training loss: 1.3258869647979736
Validation loss: 2.118022495700467

Epoch: 5| Step: 7
Training loss: 1.495751976966858
Validation loss: 2.1874413464659

Epoch: 5| Step: 8
Training loss: 1.1157058477401733
Validation loss: 2.174121833616687

Epoch: 5| Step: 9
Training loss: 0.6772188544273376
Validation loss: 2.198459025352232

Epoch: 5| Step: 10
Training loss: 1.5686362981796265
Validation loss: 2.189695845368088

Epoch: 378| Step: 0
Training loss: 1.0445176362991333
Validation loss: 2.180671135584513

Epoch: 5| Step: 1
Training loss: 1.2095197439193726
Validation loss: 2.201886905136929

Epoch: 5| Step: 2
Training loss: 1.4699605703353882
Validation loss: 2.2169310264689948

Epoch: 5| Step: 3
Training loss: 1.1538766622543335
Validation loss: 2.2176323648421996

Epoch: 5| Step: 4
Training loss: 0.9643743634223938
Validation loss: 2.1779951536527244

Epoch: 5| Step: 5
Training loss: 1.6909828186035156
Validation loss: 2.1323294075586463

Epoch: 5| Step: 6
Training loss: 0.8225933313369751
Validation loss: 2.158625623231293

Epoch: 5| Step: 7
Training loss: 1.144970417022705
Validation loss: 2.118075619461716

Epoch: 5| Step: 8
Training loss: 1.2959442138671875
Validation loss: 2.1583523955396426

Epoch: 5| Step: 9
Training loss: 1.8083248138427734
Validation loss: 2.0856900830422678

Epoch: 5| Step: 10
Training loss: 0.9563841223716736
Validation loss: 2.1259194958594536

Epoch: 379| Step: 0
Training loss: 1.51566481590271
Validation loss: 2.1263813536654235

Epoch: 5| Step: 1
Training loss: 1.1921346187591553
Validation loss: 2.0990876536215506

Epoch: 5| Step: 2
Training loss: 0.9788830876350403
Validation loss: 2.1284944767593057

Epoch: 5| Step: 3
Training loss: 0.9316571950912476
Validation loss: 2.1539082116978143

Epoch: 5| Step: 4
Training loss: 1.6723883152008057
Validation loss: 2.150892755036713

Epoch: 5| Step: 5
Training loss: 1.054552435874939
Validation loss: 2.1809564252053537

Epoch: 5| Step: 6
Training loss: 1.4302308559417725
Validation loss: 2.1669744445431616

Epoch: 5| Step: 7
Training loss: 0.8547161817550659
Validation loss: 2.209270223494499

Epoch: 5| Step: 8
Training loss: 1.0999658107757568
Validation loss: 2.217653351445352

Epoch: 5| Step: 9
Training loss: 1.396728754043579
Validation loss: 2.1957321397719847

Epoch: 5| Step: 10
Training loss: 1.4366495609283447
Validation loss: 2.140372718534162

Epoch: 380| Step: 0
Training loss: 1.101075530052185
Validation loss: 2.1413762107972176

Epoch: 5| Step: 1
Training loss: 0.9627710580825806
Validation loss: 2.11639081534519

Epoch: 5| Step: 2
Training loss: 1.2967984676361084
Validation loss: 2.114860201394686

Epoch: 5| Step: 3
Training loss: 1.188739538192749
Validation loss: 2.108674241650489

Epoch: 5| Step: 4
Training loss: 1.0681779384613037
Validation loss: 2.1063187609436693

Epoch: 5| Step: 5
Training loss: 1.1508744955062866
Validation loss: 2.130147599404858

Epoch: 5| Step: 6
Training loss: 1.774827241897583
Validation loss: 2.1404866377512612

Epoch: 5| Step: 7
Training loss: 1.4570443630218506
Validation loss: 2.1418523967906995

Epoch: 5| Step: 8
Training loss: 1.6539363861083984
Validation loss: 2.1810120997890348

Epoch: 5| Step: 9
Training loss: 1.1083028316497803
Validation loss: 2.1926660012173396

Epoch: 5| Step: 10
Training loss: 0.863570511341095
Validation loss: 2.1754713109744492

Epoch: 381| Step: 0
Training loss: 1.4838283061981201
Validation loss: 2.171315421340286

Epoch: 5| Step: 1
Training loss: 1.4596809148788452
Validation loss: 2.165413959051973

Epoch: 5| Step: 2
Training loss: 0.9929443597793579
Validation loss: 2.14842374350435

Epoch: 5| Step: 3
Training loss: 1.325621485710144
Validation loss: 2.157275808754788

Epoch: 5| Step: 4
Training loss: 0.9209942817687988
Validation loss: 2.134728208664925

Epoch: 5| Step: 5
Training loss: 1.1703321933746338
Validation loss: 2.1447015372655724

Epoch: 5| Step: 6
Training loss: 1.828203797340393
Validation loss: 2.133583989194644

Epoch: 5| Step: 7
Training loss: 1.2843126058578491
Validation loss: 2.1532977716897124

Epoch: 5| Step: 8
Training loss: 0.9208402633666992
Validation loss: 2.1369716018758793

Epoch: 5| Step: 9
Training loss: 1.0548149347305298
Validation loss: 2.137405958226932

Epoch: 5| Step: 10
Training loss: 0.9044171571731567
Validation loss: 2.1571992289635444

Epoch: 382| Step: 0
Training loss: 1.19572913646698
Validation loss: 2.1714663172280915

Epoch: 5| Step: 1
Training loss: 1.0515978336334229
Validation loss: 2.1902609948189027

Epoch: 5| Step: 2
Training loss: 1.5751897096633911
Validation loss: 2.211496683859056

Epoch: 5| Step: 3
Training loss: 0.8522486686706543
Validation loss: 2.1671726806189424

Epoch: 5| Step: 4
Training loss: 1.1547973155975342
Validation loss: 2.1680286725362143

Epoch: 5| Step: 5
Training loss: 1.601125955581665
Validation loss: 2.1696311914792625

Epoch: 5| Step: 6
Training loss: 1.384084939956665
Validation loss: 2.1583549976348877

Epoch: 5| Step: 7
Training loss: 0.9452477693557739
Validation loss: 2.13690786720604

Epoch: 5| Step: 8
Training loss: 1.4621965885162354
Validation loss: 2.161698965616124

Epoch: 5| Step: 9
Training loss: 1.2694785594940186
Validation loss: 2.149294199482087

Epoch: 5| Step: 10
Training loss: 1.0000576972961426
Validation loss: 2.148333982754779

Epoch: 383| Step: 0
Training loss: 1.545361876487732
Validation loss: 2.1446133736641175

Epoch: 5| Step: 1
Training loss: 0.9586873054504395
Validation loss: 2.138639542364305

Epoch: 5| Step: 2
Training loss: 1.2593661546707153
Validation loss: 2.1472529595898044

Epoch: 5| Step: 3
Training loss: 1.3794234991073608
Validation loss: 2.167957951945643

Epoch: 5| Step: 4
Training loss: 0.7503029704093933
Validation loss: 2.1734295147721485

Epoch: 5| Step: 5
Training loss: 1.5421953201293945
Validation loss: 2.114451813441451

Epoch: 5| Step: 6
Training loss: 1.3382154703140259
Validation loss: 2.1101100496066514

Epoch: 5| Step: 7
Training loss: 1.3497024774551392
Validation loss: 2.1027962353921708

Epoch: 5| Step: 8
Training loss: 1.342948079109192
Validation loss: 2.103063929465509

Epoch: 5| Step: 9
Training loss: 1.044861912727356
Validation loss: 2.1189937027551795

Epoch: 5| Step: 10
Training loss: 0.8828941583633423
Validation loss: 2.1208206761267876

Epoch: 384| Step: 0
Training loss: 1.1393283605575562
Validation loss: 2.151466727256775

Epoch: 5| Step: 1
Training loss: 0.7330769300460815
Validation loss: 2.141388475254018

Epoch: 5| Step: 2
Training loss: 1.0054748058319092
Validation loss: 2.132432524875928

Epoch: 5| Step: 3
Training loss: 1.3018022775650024
Validation loss: 2.1369648569373676

Epoch: 5| Step: 4
Training loss: 0.8854857683181763
Validation loss: 2.120691858312135

Epoch: 5| Step: 5
Training loss: 1.7755978107452393
Validation loss: 2.1255527106664514

Epoch: 5| Step: 6
Training loss: 1.3336747884750366
Validation loss: 2.1627852224534556

Epoch: 5| Step: 7
Training loss: 1.204247236251831
Validation loss: 2.1338380011179114

Epoch: 5| Step: 8
Training loss: 1.074323296546936
Validation loss: 2.159535966893678

Epoch: 5| Step: 9
Training loss: 1.6564109325408936
Validation loss: 2.121816696659211

Epoch: 5| Step: 10
Training loss: 1.1846928596496582
Validation loss: 2.1267303882106656

Epoch: 385| Step: 0
Training loss: 0.8563014268875122
Validation loss: 2.1321909209733367

Epoch: 5| Step: 1
Training loss: 1.1821485757827759
Validation loss: 2.1386545652984292

Epoch: 5| Step: 2
Training loss: 1.1234195232391357
Validation loss: 2.111818693017447

Epoch: 5| Step: 3
Training loss: 1.0367428064346313
Validation loss: 2.0935323853646555

Epoch: 5| Step: 4
Training loss: 1.5985679626464844
Validation loss: 2.12611436459326

Epoch: 5| Step: 5
Training loss: 0.9131708145141602
Validation loss: 2.123349683259123

Epoch: 5| Step: 6
Training loss: 1.129219651222229
Validation loss: 2.1311235017673944

Epoch: 5| Step: 7
Training loss: 1.8565349578857422
Validation loss: 2.135960635318551

Epoch: 5| Step: 8
Training loss: 0.941431999206543
Validation loss: 2.1531573675012075

Epoch: 5| Step: 9
Training loss: 1.4166486263275146
Validation loss: 2.149665327482326

Epoch: 5| Step: 10
Training loss: 1.3176162242889404
Validation loss: 2.1661620140075684

Epoch: 386| Step: 0
Training loss: 0.769808292388916
Validation loss: 2.136780467084659

Epoch: 5| Step: 1
Training loss: 1.2619483470916748
Validation loss: 2.1605631125870572

Epoch: 5| Step: 2
Training loss: 0.9356125593185425
Validation loss: 2.1551316579182944

Epoch: 5| Step: 3
Training loss: 1.162534475326538
Validation loss: 2.159326725108649

Epoch: 5| Step: 4
Training loss: 1.4727423191070557
Validation loss: 2.1557121199946248

Epoch: 5| Step: 5
Training loss: 1.3876302242279053
Validation loss: 2.140115286714287

Epoch: 5| Step: 6
Training loss: 1.0151548385620117
Validation loss: 2.17620434043228

Epoch: 5| Step: 7
Training loss: 1.074805498123169
Validation loss: 2.126159352640952

Epoch: 5| Step: 8
Training loss: 1.5715073347091675
Validation loss: 2.146928225794146

Epoch: 5| Step: 9
Training loss: 1.4635388851165771
Validation loss: 2.188488521883565

Epoch: 5| Step: 10
Training loss: 1.053155541419983
Validation loss: 2.1568219610439834

Epoch: 387| Step: 0
Training loss: 1.4255036115646362
Validation loss: 2.1663810001906527

Epoch: 5| Step: 1
Training loss: 1.0907742977142334
Validation loss: 2.1252997126630557

Epoch: 5| Step: 2
Training loss: 1.2631042003631592
Validation loss: 2.0727190945738103

Epoch: 5| Step: 3
Training loss: 0.6676396131515503
Validation loss: 2.0912821408241027

Epoch: 5| Step: 4
Training loss: 1.356532335281372
Validation loss: 2.0781237104887604

Epoch: 5| Step: 5
Training loss: 1.1450504064559937
Validation loss: 2.0881939216326644

Epoch: 5| Step: 6
Training loss: 1.470198392868042
Validation loss: 2.0574921587462067

Epoch: 5| Step: 7
Training loss: 0.8863146901130676
Validation loss: 2.093316497341279

Epoch: 5| Step: 8
Training loss: 1.1381317377090454
Validation loss: 2.1067977131053968

Epoch: 5| Step: 9
Training loss: 1.7147223949432373
Validation loss: 2.1139717794233754

Epoch: 5| Step: 10
Training loss: 1.0434441566467285
Validation loss: 2.1209958984005834

Epoch: 388| Step: 0
Training loss: 1.63096022605896
Validation loss: 2.16256683616228

Epoch: 5| Step: 1
Training loss: 1.0218591690063477
Validation loss: 2.1987192028312275

Epoch: 5| Step: 2
Training loss: 1.2701607942581177
Validation loss: 2.1716533553215767

Epoch: 5| Step: 3
Training loss: 1.5603244304656982
Validation loss: 2.1695499945712347

Epoch: 5| Step: 4
Training loss: 1.2979488372802734
Validation loss: 2.160730322202047

Epoch: 5| Step: 5
Training loss: 1.1749460697174072
Validation loss: 2.140506403420561

Epoch: 5| Step: 6
Training loss: 0.9599980115890503
Validation loss: 2.119926510318633

Epoch: 5| Step: 7
Training loss: 1.3087444305419922
Validation loss: 2.1008392687766784

Epoch: 5| Step: 8
Training loss: 0.8746480941772461
Validation loss: 2.111822433369134

Epoch: 5| Step: 9
Training loss: 0.7994054555892944
Validation loss: 2.136884358621413

Epoch: 5| Step: 10
Training loss: 1.1518598794937134
Validation loss: 2.1510389838167416

Epoch: 389| Step: 0
Training loss: 1.1783456802368164
Validation loss: 2.1026420541988906

Epoch: 5| Step: 1
Training loss: 0.9748249053955078
Validation loss: 2.1330020863522767

Epoch: 5| Step: 2
Training loss: 0.8972885012626648
Validation loss: 2.147389027380174

Epoch: 5| Step: 3
Training loss: 1.0633745193481445
Validation loss: 2.1389111241986676

Epoch: 5| Step: 4
Training loss: 1.4661279916763306
Validation loss: 2.1495024158108618

Epoch: 5| Step: 5
Training loss: 1.4319649934768677
Validation loss: 2.114627379243092

Epoch: 5| Step: 6
Training loss: 0.9764062762260437
Validation loss: 2.134621566341769

Epoch: 5| Step: 7
Training loss: 1.464654564857483
Validation loss: 2.1239049588480303

Epoch: 5| Step: 8
Training loss: 1.602137804031372
Validation loss: 2.129315996682772

Epoch: 5| Step: 9
Training loss: 1.2125298976898193
Validation loss: 2.150823813612743

Epoch: 5| Step: 10
Training loss: 0.8841601014137268
Validation loss: 2.152578837128096

Epoch: 390| Step: 0
Training loss: 1.2239997386932373
Validation loss: 2.129564424996735

Epoch: 5| Step: 1
Training loss: 0.8669751882553101
Validation loss: 2.162169437254629

Epoch: 5| Step: 2
Training loss: 1.230266809463501
Validation loss: 2.13572980255209

Epoch: 5| Step: 3
Training loss: 0.999233603477478
Validation loss: 2.1001996917109333

Epoch: 5| Step: 4
Training loss: 1.074190616607666
Validation loss: 2.1067590585318943

Epoch: 5| Step: 5
Training loss: 0.9417766332626343
Validation loss: 2.108707235705468

Epoch: 5| Step: 6
Training loss: 1.3121261596679688
Validation loss: 2.0815338011710875

Epoch: 5| Step: 7
Training loss: 0.672748863697052
Validation loss: 2.0906317439130557

Epoch: 5| Step: 8
Training loss: 1.5133798122406006
Validation loss: 2.1357595510380243

Epoch: 5| Step: 9
Training loss: 1.6638004779815674
Validation loss: 2.1894705859563683

Epoch: 5| Step: 10
Training loss: 1.650941014289856
Validation loss: 2.175419035778251

Epoch: 391| Step: 0
Training loss: 0.8245970606803894
Validation loss: 2.1688809805018927

Epoch: 5| Step: 1
Training loss: 0.9015955924987793
Validation loss: 2.159854660751999

Epoch: 5| Step: 2
Training loss: 1.0541000366210938
Validation loss: 2.1281829008492092

Epoch: 5| Step: 3
Training loss: 0.9657365679740906
Validation loss: 2.140736710640692

Epoch: 5| Step: 4
Training loss: 1.3965470790863037
Validation loss: 2.146422682269927

Epoch: 5| Step: 5
Training loss: 1.5738110542297363
Validation loss: 2.125840025563394

Epoch: 5| Step: 6
Training loss: 0.7190790176391602
Validation loss: 2.1169850544262956

Epoch: 5| Step: 7
Training loss: 1.3235843181610107
Validation loss: 2.165348696452315

Epoch: 5| Step: 8
Training loss: 0.9853112101554871
Validation loss: 2.1522552377434185

Epoch: 5| Step: 9
Training loss: 1.4409797191619873
Validation loss: 2.1579741752275856

Epoch: 5| Step: 10
Training loss: 1.9241701364517212
Validation loss: 2.153235213730925

Epoch: 392| Step: 0
Training loss: 1.6119331121444702
Validation loss: 2.1316606549806494

Epoch: 5| Step: 1
Training loss: 1.4857161045074463
Validation loss: 2.120296375725859

Epoch: 5| Step: 2
Training loss: 1.3292790651321411
Validation loss: 2.1387123997493456

Epoch: 5| Step: 3
Training loss: 1.2547786235809326
Validation loss: 2.137357942519649

Epoch: 5| Step: 4
Training loss: 1.2694882154464722
Validation loss: 2.135421822147985

Epoch: 5| Step: 5
Training loss: 1.286902666091919
Validation loss: 2.1525380329419206

Epoch: 5| Step: 6
Training loss: 0.6547080874443054
Validation loss: 2.119458797157452

Epoch: 5| Step: 7
Training loss: 0.7266849875450134
Validation loss: 2.141686736896474

Epoch: 5| Step: 8
Training loss: 0.8043882250785828
Validation loss: 2.1492198051944857

Epoch: 5| Step: 9
Training loss: 1.0467215776443481
Validation loss: 2.1523112174003356

Epoch: 5| Step: 10
Training loss: 1.4212987422943115
Validation loss: 2.1202290417045675

Epoch: 393| Step: 0
Training loss: 0.8338762521743774
Validation loss: 2.127716697672362

Epoch: 5| Step: 1
Training loss: 1.166264295578003
Validation loss: 2.1047298600596767

Epoch: 5| Step: 2
Training loss: 1.1871325969696045
Validation loss: 2.15385684146676

Epoch: 5| Step: 3
Training loss: 1.1379053592681885
Validation loss: 2.145016395917503

Epoch: 5| Step: 4
Training loss: 1.4369224309921265
Validation loss: 2.142573925756639

Epoch: 5| Step: 5
Training loss: 0.983619213104248
Validation loss: 2.1271755849161456

Epoch: 5| Step: 6
Training loss: 1.1554439067840576
Validation loss: 2.135457641334944

Epoch: 5| Step: 7
Training loss: 1.1267682313919067
Validation loss: 2.1058563596458844

Epoch: 5| Step: 8
Training loss: 1.3885619640350342
Validation loss: 2.1174388303551623

Epoch: 5| Step: 9
Training loss: 1.0466607809066772
Validation loss: 2.1523782002028597

Epoch: 5| Step: 10
Training loss: 1.4578280448913574
Validation loss: 2.147772903083473

Epoch: 394| Step: 0
Training loss: 1.0629445314407349
Validation loss: 2.1667927734313475

Epoch: 5| Step: 1
Training loss: 1.0817114114761353
Validation loss: 2.189468123579538

Epoch: 5| Step: 2
Training loss: 1.3642148971557617
Validation loss: 2.18410264548435

Epoch: 5| Step: 3
Training loss: 0.6862372159957886
Validation loss: 2.167373513662687

Epoch: 5| Step: 4
Training loss: 1.5312203168869019
Validation loss: 2.1867910944005495

Epoch: 5| Step: 5
Training loss: 1.2400137186050415
Validation loss: 2.1705152847433604

Epoch: 5| Step: 6
Training loss: 1.568558931350708
Validation loss: 2.131913415847286

Epoch: 5| Step: 7
Training loss: 1.185869574546814
Validation loss: 2.1410834686730498

Epoch: 5| Step: 8
Training loss: 1.0379928350448608
Validation loss: 2.1015053103047032

Epoch: 5| Step: 9
Training loss: 1.0384252071380615
Validation loss: 2.089706547798649

Epoch: 5| Step: 10
Training loss: 1.3211019039154053
Validation loss: 2.080339841945197

Epoch: 395| Step: 0
Training loss: 0.6377938985824585
Validation loss: 2.015622318431895

Epoch: 5| Step: 1
Training loss: 1.0472309589385986
Validation loss: 2.04039099139552

Epoch: 5| Step: 2
Training loss: 0.5573939085006714
Validation loss: 2.0368552528401858

Epoch: 5| Step: 3
Training loss: 1.8764126300811768
Validation loss: 2.054084849613969

Epoch: 5| Step: 4
Training loss: 1.372577428817749
Validation loss: 2.092725234646951

Epoch: 5| Step: 5
Training loss: 1.007694959640503
Validation loss: 2.103530499242967

Epoch: 5| Step: 6
Training loss: 1.2952734231948853
Validation loss: 2.1056899639867965

Epoch: 5| Step: 7
Training loss: 1.4425843954086304
Validation loss: 2.1139128054341962

Epoch: 5| Step: 8
Training loss: 0.8993037343025208
Validation loss: 2.1459406063120854

Epoch: 5| Step: 9
Training loss: 1.526658296585083
Validation loss: 2.1467777567525066

Epoch: 5| Step: 10
Training loss: 1.210068702697754
Validation loss: 2.1423394756932415

Epoch: 396| Step: 0
Training loss: 0.5908044576644897
Validation loss: 2.1786048412323

Epoch: 5| Step: 1
Training loss: 1.776182770729065
Validation loss: 2.198755769319432

Epoch: 5| Step: 2
Training loss: 1.3785231113433838
Validation loss: 2.1923323267249653

Epoch: 5| Step: 3
Training loss: 1.3605624437332153
Validation loss: 2.2106236129678707

Epoch: 5| Step: 4
Training loss: 0.5239804983139038
Validation loss: 2.2138588223406064

Epoch: 5| Step: 5
Training loss: 1.4606900215148926
Validation loss: 2.1962615994996924

Epoch: 5| Step: 6
Training loss: 1.1550376415252686
Validation loss: 2.219983526455459

Epoch: 5| Step: 7
Training loss: 1.6851736307144165
Validation loss: 2.2111356822393273

Epoch: 5| Step: 8
Training loss: 1.0992743968963623
Validation loss: 2.1547799212958223

Epoch: 5| Step: 9
Training loss: 0.7410905957221985
Validation loss: 2.1281776658950315

Epoch: 5| Step: 10
Training loss: 1.384475588798523
Validation loss: 2.125631158069898

Epoch: 397| Step: 0
Training loss: 0.9176599383354187
Validation loss: 2.1010304433043285

Epoch: 5| Step: 1
Training loss: 1.1233896017074585
Validation loss: 2.088192134775141

Epoch: 5| Step: 2
Training loss: 1.7434183359146118
Validation loss: 2.1046002039345364

Epoch: 5| Step: 3
Training loss: 1.234257459640503
Validation loss: 2.1055103322511077

Epoch: 5| Step: 4
Training loss: 0.9629248380661011
Validation loss: 2.0509457408740954

Epoch: 5| Step: 5
Training loss: 1.507891058921814
Validation loss: 2.0899073282877603

Epoch: 5| Step: 6
Training loss: 1.0384317636489868
Validation loss: 2.061319956215479

Epoch: 5| Step: 7
Training loss: 1.4524556398391724
Validation loss: 2.1103308188017977

Epoch: 5| Step: 8
Training loss: 1.1416807174682617
Validation loss: 2.114089301837388

Epoch: 5| Step: 9
Training loss: 1.0813395977020264
Validation loss: 2.1262057981183453

Epoch: 5| Step: 10
Training loss: 0.8735694885253906
Validation loss: 2.1476810568122455

Epoch: 398| Step: 0
Training loss: 0.9816112518310547
Validation loss: 2.1776912084189792

Epoch: 5| Step: 1
Training loss: 1.2281806468963623
Validation loss: 2.1869699852440947

Epoch: 5| Step: 2
Training loss: 1.8748359680175781
Validation loss: 2.166968302060199

Epoch: 5| Step: 3
Training loss: 0.9610778093338013
Validation loss: 2.185739359548015

Epoch: 5| Step: 4
Training loss: 0.8473443984985352
Validation loss: 2.14603522259702

Epoch: 5| Step: 5
Training loss: 1.11849045753479
Validation loss: 2.135262794392083

Epoch: 5| Step: 6
Training loss: 1.4682047367095947
Validation loss: 2.088446985008896

Epoch: 5| Step: 7
Training loss: 0.8509318232536316
Validation loss: 2.1192346516475884

Epoch: 5| Step: 8
Training loss: 1.0058025121688843
Validation loss: 2.056959964895761

Epoch: 5| Step: 9
Training loss: 0.9233915209770203
Validation loss: 2.0613585518252466

Epoch: 5| Step: 10
Training loss: 1.4715681076049805
Validation loss: 2.049888426257718

Epoch: 399| Step: 0
Training loss: 0.8673324584960938
Validation loss: 2.044882474407073

Epoch: 5| Step: 1
Training loss: 1.4431488513946533
Validation loss: 2.045126945741715

Epoch: 5| Step: 2
Training loss: 0.7673091888427734
Validation loss: 2.0388509445292975

Epoch: 5| Step: 3
Training loss: 0.9534794092178345
Validation loss: 2.090264211418808

Epoch: 5| Step: 4
Training loss: 0.5085985660552979
Validation loss: 2.1224941643335486

Epoch: 5| Step: 5
Training loss: 1.4330662488937378
Validation loss: 2.1394757045212613

Epoch: 5| Step: 6
Training loss: 0.8246742486953735
Validation loss: 2.174596022534114

Epoch: 5| Step: 7
Training loss: 1.3259671926498413
Validation loss: 2.1801467505834435

Epoch: 5| Step: 8
Training loss: 1.4496716260910034
Validation loss: 2.2426485541046306

Epoch: 5| Step: 9
Training loss: 1.9509403705596924
Validation loss: 2.2284876197896977

Epoch: 5| Step: 10
Training loss: 1.2369961738586426
Validation loss: 2.252243426538283

Epoch: 400| Step: 0
Training loss: 1.3983385562896729
Validation loss: 2.2336158175622263

Epoch: 5| Step: 1
Training loss: 1.5943256616592407
Validation loss: 2.1949615504152034

Epoch: 5| Step: 2
Training loss: 0.9814054369926453
Validation loss: 2.1599820608733804

Epoch: 5| Step: 3
Training loss: 1.4140090942382812
Validation loss: 2.1467420324202506

Epoch: 5| Step: 4
Training loss: 1.4867545366287231
Validation loss: 2.099695000597226

Epoch: 5| Step: 5
Training loss: 1.256054162979126
Validation loss: 2.0801494685552453

Epoch: 5| Step: 6
Training loss: 0.7316371202468872
Validation loss: 2.1014118220216487

Epoch: 5| Step: 7
Training loss: 0.6353446245193481
Validation loss: 2.050894298861104

Epoch: 5| Step: 8
Training loss: 1.1164109706878662
Validation loss: 2.081869343275665

Epoch: 5| Step: 9
Training loss: 0.8851757049560547
Validation loss: 2.097389876201589

Epoch: 5| Step: 10
Training loss: 1.3958537578582764
Validation loss: 2.1030949290080736

Epoch: 401| Step: 0
Training loss: 1.156684160232544
Validation loss: 2.0801220914368987

Epoch: 5| Step: 1
Training loss: 0.692132830619812
Validation loss: 2.1455864085946033

Epoch: 5| Step: 2
Training loss: 1.171135425567627
Validation loss: 2.1289782524108887

Epoch: 5| Step: 3
Training loss: 1.3228566646575928
Validation loss: 2.1911183736657582

Epoch: 5| Step: 4
Training loss: 1.1792864799499512
Validation loss: 2.1740681561090613

Epoch: 5| Step: 5
Training loss: 1.3179359436035156
Validation loss: 2.1898379479685137

Epoch: 5| Step: 6
Training loss: 1.1332030296325684
Validation loss: 2.2075049800257527

Epoch: 5| Step: 7
Training loss: 1.4203805923461914
Validation loss: 2.182749129110767

Epoch: 5| Step: 8
Training loss: 0.9439522624015808
Validation loss: 2.152019031586186

Epoch: 5| Step: 9
Training loss: 1.1275866031646729
Validation loss: 2.1044970661081295

Epoch: 5| Step: 10
Training loss: 1.1098322868347168
Validation loss: 2.095018894441666

Epoch: 402| Step: 0
Training loss: 1.0402374267578125
Validation loss: 2.0761820962352138

Epoch: 5| Step: 1
Training loss: 0.9414762258529663
Validation loss: 2.080988037970758

Epoch: 5| Step: 2
Training loss: 1.6703994274139404
Validation loss: 2.0587261158932924

Epoch: 5| Step: 3
Training loss: 1.2188935279846191
Validation loss: 2.065976030083113

Epoch: 5| Step: 4
Training loss: 0.6652154326438904
Validation loss: 2.089232090980776

Epoch: 5| Step: 5
Training loss: 1.174760103225708
Validation loss: 2.0602357874634447

Epoch: 5| Step: 6
Training loss: 1.5172979831695557
Validation loss: 2.0853543435373614

Epoch: 5| Step: 7
Training loss: 1.2356915473937988
Validation loss: 2.066344068896386

Epoch: 5| Step: 8
Training loss: 0.9472034573554993
Validation loss: 2.1043306499399166

Epoch: 5| Step: 9
Training loss: 0.6969877481460571
Validation loss: 2.1096844365519862

Epoch: 5| Step: 10
Training loss: 1.3969186544418335
Validation loss: 2.1315798772278653

Epoch: 403| Step: 0
Training loss: 1.1777375936508179
Validation loss: 2.1129366223530104

Epoch: 5| Step: 1
Training loss: 0.814104437828064
Validation loss: 2.1201142034223004

Epoch: 5| Step: 2
Training loss: 1.34945547580719
Validation loss: 2.1146635458033574

Epoch: 5| Step: 3
Training loss: 1.459104299545288
Validation loss: 2.115976038799491

Epoch: 5| Step: 4
Training loss: 0.9567664861679077
Validation loss: 2.1173430014682073

Epoch: 5| Step: 5
Training loss: 0.9626713991165161
Validation loss: 2.1105366881175707

Epoch: 5| Step: 6
Training loss: 1.2556108236312866
Validation loss: 2.1198650880526473

Epoch: 5| Step: 7
Training loss: 0.820831298828125
Validation loss: 2.127692493059302

Epoch: 5| Step: 8
Training loss: 0.9915404319763184
Validation loss: 2.118622044081329

Epoch: 5| Step: 9
Training loss: 1.2097678184509277
Validation loss: 2.156260400690058

Epoch: 5| Step: 10
Training loss: 1.5312551259994507
Validation loss: 2.1409215042668004

Epoch: 404| Step: 0
Training loss: 1.2303320169448853
Validation loss: 2.1557246164609025

Epoch: 5| Step: 1
Training loss: 1.1907802820205688
Validation loss: 2.101656495883901

Epoch: 5| Step: 2
Training loss: 1.0227233171463013
Validation loss: 2.13158167049449

Epoch: 5| Step: 3
Training loss: 0.7548325657844543
Validation loss: 2.0800309514486663

Epoch: 5| Step: 4
Training loss: 0.7427129149436951
Validation loss: 2.090178551212434

Epoch: 5| Step: 5
Training loss: 0.944659411907196
Validation loss: 2.0752480645333566

Epoch: 5| Step: 6
Training loss: 0.7234228253364563
Validation loss: 2.117003215256558

Epoch: 5| Step: 7
Training loss: 1.6279436349868774
Validation loss: 2.084335514294204

Epoch: 5| Step: 8
Training loss: 1.4090263843536377
Validation loss: 2.0716771630830664

Epoch: 5| Step: 9
Training loss: 1.265777349472046
Validation loss: 2.070080772522957

Epoch: 5| Step: 10
Training loss: 1.4647612571716309
Validation loss: 2.084947857805478

Epoch: 405| Step: 0
Training loss: 1.2468467950820923
Validation loss: 2.0904967682335966

Epoch: 5| Step: 1
Training loss: 0.894748866558075
Validation loss: 2.0744826639852216

Epoch: 5| Step: 2
Training loss: 1.2616857290267944
Validation loss: 2.102027168837927

Epoch: 5| Step: 3
Training loss: 0.8630309104919434
Validation loss: 2.0916962033958844

Epoch: 5| Step: 4
Training loss: 0.8767016530036926
Validation loss: 2.1089454363751154

Epoch: 5| Step: 5
Training loss: 1.1829558610916138
Validation loss: 2.0854613216974403

Epoch: 5| Step: 6
Training loss: 1.550241470336914
Validation loss: 2.1911969774512836

Epoch: 5| Step: 7
Training loss: 0.6363548636436462
Validation loss: 2.1632618006839546

Epoch: 5| Step: 8
Training loss: 1.2171818017959595
Validation loss: 2.1302082461695515

Epoch: 5| Step: 9
Training loss: 1.2202599048614502
Validation loss: 2.14387773442012

Epoch: 5| Step: 10
Training loss: 1.401814341545105
Validation loss: 2.1208440770385084

Epoch: 406| Step: 0
Training loss: 1.1853916645050049
Validation loss: 2.1176581972388813

Epoch: 5| Step: 1
Training loss: 1.2402125597000122
Validation loss: 2.102859100987834

Epoch: 5| Step: 2
Training loss: 1.218482494354248
Validation loss: 2.083264955910303

Epoch: 5| Step: 3
Training loss: 1.1642422676086426
Validation loss: 2.07589626824984

Epoch: 5| Step: 4
Training loss: 0.8681706190109253
Validation loss: 2.0406166315078735

Epoch: 5| Step: 5
Training loss: 1.1656354665756226
Validation loss: 2.0767045597876272

Epoch: 5| Step: 6
Training loss: 0.7317580580711365
Validation loss: 2.038491195248019

Epoch: 5| Step: 7
Training loss: 0.7938824892044067
Validation loss: 2.056043096767959

Epoch: 5| Step: 8
Training loss: 0.9006336331367493
Validation loss: 2.082764494803644

Epoch: 5| Step: 9
Training loss: 1.1911393404006958
Validation loss: 2.0455919965620963

Epoch: 5| Step: 10
Training loss: 1.63522207736969
Validation loss: 2.0700961236030824

Epoch: 407| Step: 0
Training loss: 1.151996374130249
Validation loss: 2.0586989105388684

Epoch: 5| Step: 1
Training loss: 0.9236246943473816
Validation loss: 2.0563537100309968

Epoch: 5| Step: 2
Training loss: 1.2590014934539795
Validation loss: 2.1077972355709282

Epoch: 5| Step: 3
Training loss: 1.4315226078033447
Validation loss: 2.1324051516030424

Epoch: 5| Step: 4
Training loss: 0.9422234296798706
Validation loss: 2.1437878249793925

Epoch: 5| Step: 5
Training loss: 1.185546636581421
Validation loss: 2.1534851328019173

Epoch: 5| Step: 6
Training loss: 1.0488488674163818
Validation loss: 2.1327391234777306

Epoch: 5| Step: 7
Training loss: 0.8754819631576538
Validation loss: 2.1332097809801818

Epoch: 5| Step: 8
Training loss: 1.1843481063842773
Validation loss: 2.137873749579153

Epoch: 5| Step: 9
Training loss: 0.7226866483688354
Validation loss: 2.1260393101681947

Epoch: 5| Step: 10
Training loss: 1.1951029300689697
Validation loss: 2.157063784137849

Epoch: 408| Step: 0
Training loss: 0.8221901059150696
Validation loss: 2.128793486984827

Epoch: 5| Step: 1
Training loss: 1.7220325469970703
Validation loss: 2.1452146845479168

Epoch: 5| Step: 2
Training loss: 0.9930289387702942
Validation loss: 2.1456493613540486

Epoch: 5| Step: 3
Training loss: 1.0522124767303467
Validation loss: 2.1157620876066145

Epoch: 5| Step: 4
Training loss: 0.9584617614746094
Validation loss: 2.1329205984710367

Epoch: 5| Step: 5
Training loss: 1.5507009029388428
Validation loss: 2.1499148056071293

Epoch: 5| Step: 6
Training loss: 1.2095286846160889
Validation loss: 2.1096703134557253

Epoch: 5| Step: 7
Training loss: 0.8886318206787109
Validation loss: 2.1075781160785305

Epoch: 5| Step: 8
Training loss: 1.1929346323013306
Validation loss: 2.0925010147915093

Epoch: 5| Step: 9
Training loss: 0.732345700263977
Validation loss: 2.082349274748115

Epoch: 5| Step: 10
Training loss: 0.7673463225364685
Validation loss: 2.0693095294378137

Epoch: 409| Step: 0
Training loss: 0.8027499914169312
Validation loss: 2.076760621481044

Epoch: 5| Step: 1
Training loss: 1.2333358526229858
Validation loss: 2.056641509456019

Epoch: 5| Step: 2
Training loss: 1.207679033279419
Validation loss: 2.0488752600967244

Epoch: 5| Step: 3
Training loss: 1.2803455591201782
Validation loss: 2.049650457597548

Epoch: 5| Step: 4
Training loss: 0.9289337396621704
Validation loss: 2.034970752654537

Epoch: 5| Step: 5
Training loss: 1.000617265701294
Validation loss: 2.0555649226711643

Epoch: 5| Step: 6
Training loss: 1.0473101139068604
Validation loss: 2.0769623684626755

Epoch: 5| Step: 7
Training loss: 0.9794065356254578
Validation loss: 2.0885377878783853

Epoch: 5| Step: 8
Training loss: 1.0414800643920898
Validation loss: 2.081083925821448

Epoch: 5| Step: 9
Training loss: 1.7039715051651
Validation loss: 2.1243794169477237

Epoch: 5| Step: 10
Training loss: 0.6401090621948242
Validation loss: 2.1198362893955682

Epoch: 410| Step: 0
Training loss: 0.8617531061172485
Validation loss: 2.131132770610112

Epoch: 5| Step: 1
Training loss: 0.9980667233467102
Validation loss: 2.1423239015763804

Epoch: 5| Step: 2
Training loss: 1.2221758365631104
Validation loss: 2.1398700462874545

Epoch: 5| Step: 3
Training loss: 0.8782828450202942
Validation loss: 2.110232965920561

Epoch: 5| Step: 4
Training loss: 1.0691758394241333
Validation loss: 2.1179054091053624

Epoch: 5| Step: 5
Training loss: 1.2519047260284424
Validation loss: 2.082401119252687

Epoch: 5| Step: 6
Training loss: 0.7381292581558228
Validation loss: 2.0765990057299213

Epoch: 5| Step: 7
Training loss: 1.1874035596847534
Validation loss: 2.1022842430299327

Epoch: 5| Step: 8
Training loss: 0.8561212420463562
Validation loss: 2.0718451994721607

Epoch: 5| Step: 9
Training loss: 1.3973668813705444
Validation loss: 2.0757329156321864

Epoch: 5| Step: 10
Training loss: 1.472265601158142
Validation loss: 2.0807090574695217

Epoch: 411| Step: 0
Training loss: 0.697838544845581
Validation loss: 2.078322741293138

Epoch: 5| Step: 1
Training loss: 1.0847041606903076
Validation loss: 2.0685091198131604

Epoch: 5| Step: 2
Training loss: 1.0220937728881836
Validation loss: 2.1030682466363393

Epoch: 5| Step: 3
Training loss: 1.1997859477996826
Validation loss: 2.0777290841584564

Epoch: 5| Step: 4
Training loss: 0.8611463308334351
Validation loss: 2.104018126764605

Epoch: 5| Step: 5
Training loss: 1.1056079864501953
Validation loss: 2.090113503958589

Epoch: 5| Step: 6
Training loss: 1.3922736644744873
Validation loss: 2.14016870913967

Epoch: 5| Step: 7
Training loss: 1.3650798797607422
Validation loss: 2.102400702814902

Epoch: 5| Step: 8
Training loss: 0.9577535390853882
Validation loss: 2.088748699875288

Epoch: 5| Step: 9
Training loss: 0.7607951164245605
Validation loss: 2.056023533626269

Epoch: 5| Step: 10
Training loss: 1.2954673767089844
Validation loss: 2.061472805597449

Epoch: 412| Step: 0
Training loss: 0.8259915113449097
Validation loss: 2.0454507015084706

Epoch: 5| Step: 1
Training loss: 0.7356480360031128
Validation loss: 2.0653608076034056

Epoch: 5| Step: 2
Training loss: 0.7793648838996887
Validation loss: 2.109881765098982

Epoch: 5| Step: 3
Training loss: 1.2271509170532227
Validation loss: 2.0750465957067346

Epoch: 5| Step: 4
Training loss: 1.6606695652008057
Validation loss: 2.0709862811591035

Epoch: 5| Step: 5
Training loss: 1.498840093612671
Validation loss: 2.0671332395204933

Epoch: 5| Step: 6
Training loss: 0.9993511438369751
Validation loss: 2.1515538256655455

Epoch: 5| Step: 7
Training loss: 0.9489538073539734
Validation loss: 2.137171040299118

Epoch: 5| Step: 8
Training loss: 1.1487133502960205
Validation loss: 2.094446664215416

Epoch: 5| Step: 9
Training loss: 0.6835969686508179
Validation loss: 2.096293741656888

Epoch: 5| Step: 10
Training loss: 1.0651781558990479
Validation loss: 2.0967876526617233

Epoch: 413| Step: 0
Training loss: 1.2300406694412231
Validation loss: 2.0893178883419243

Epoch: 5| Step: 1
Training loss: 1.0185842514038086
Validation loss: 2.106413713065527

Epoch: 5| Step: 2
Training loss: 0.963305652141571
Validation loss: 2.039726884134354

Epoch: 5| Step: 3
Training loss: 1.192309856414795
Validation loss: 2.073019621192768

Epoch: 5| Step: 4
Training loss: 0.9666786193847656
Validation loss: 2.0766458690807386

Epoch: 5| Step: 5
Training loss: 1.255886197090149
Validation loss: 2.075889987330283

Epoch: 5| Step: 6
Training loss: 1.1118080615997314
Validation loss: 2.094990679012832

Epoch: 5| Step: 7
Training loss: 0.9544108510017395
Validation loss: 2.099178352663594

Epoch: 5| Step: 8
Training loss: 0.8816407322883606
Validation loss: 2.0899718282043294

Epoch: 5| Step: 9
Training loss: 1.1476963758468628
Validation loss: 2.0777681002052883

Epoch: 5| Step: 10
Training loss: 1.1004853248596191
Validation loss: 2.0904163852814706

Epoch: 414| Step: 0
Training loss: 0.6250775456428528
Validation loss: 2.0884636397002847

Epoch: 5| Step: 1
Training loss: 0.7963253259658813
Validation loss: 2.1078421044093307

Epoch: 5| Step: 2
Training loss: 1.3508033752441406
Validation loss: 2.146471684978854

Epoch: 5| Step: 3
Training loss: 1.4883756637573242
Validation loss: 2.1235733698773127

Epoch: 5| Step: 4
Training loss: 1.256250023841858
Validation loss: 2.130541504070323

Epoch: 5| Step: 5
Training loss: 0.8885859251022339
Validation loss: 2.114993927299335

Epoch: 5| Step: 6
Training loss: 1.1979941129684448
Validation loss: 2.097451707368256

Epoch: 5| Step: 7
Training loss: 0.8296686410903931
Validation loss: 2.084306611809679

Epoch: 5| Step: 8
Training loss: 1.0750178098678589
Validation loss: 2.1219409614480953

Epoch: 5| Step: 9
Training loss: 1.0303672552108765
Validation loss: 2.0687661222232285

Epoch: 5| Step: 10
Training loss: 1.261781930923462
Validation loss: 2.097404800435548

Epoch: 415| Step: 0
Training loss: 1.1579469442367554
Validation loss: 2.1248421976643224

Epoch: 5| Step: 1
Training loss: 0.6297887563705444
Validation loss: 2.061177997178929

Epoch: 5| Step: 2
Training loss: 0.9846383333206177
Validation loss: 2.0786478404075868

Epoch: 5| Step: 3
Training loss: 1.270369052886963
Validation loss: 2.0302410702551565

Epoch: 5| Step: 4
Training loss: 0.8480556607246399
Validation loss: 2.037195336434149

Epoch: 5| Step: 5
Training loss: 1.0446345806121826
Validation loss: 2.043475492026216

Epoch: 5| Step: 6
Training loss: 1.188356876373291
Validation loss: 2.0341134635351037

Epoch: 5| Step: 7
Training loss: 1.0935578346252441
Validation loss: 2.0417162397856354

Epoch: 5| Step: 8
Training loss: 1.200742483139038
Validation loss: 2.056362550745728

Epoch: 5| Step: 9
Training loss: 0.9470226168632507
Validation loss: 2.067761185348675

Epoch: 5| Step: 10
Training loss: 1.2089017629623413
Validation loss: 2.118523338789581

Epoch: 416| Step: 0
Training loss: 1.3883987665176392
Validation loss: 2.112031034244004

Epoch: 5| Step: 1
Training loss: 0.9149370193481445
Validation loss: 2.132974374678827

Epoch: 5| Step: 2
Training loss: 1.1887531280517578
Validation loss: 2.1557766545203423

Epoch: 5| Step: 3
Training loss: 0.9078056216239929
Validation loss: 2.118856881254463

Epoch: 5| Step: 4
Training loss: 0.9669133424758911
Validation loss: 2.1240585363039406

Epoch: 5| Step: 5
Training loss: 1.6210830211639404
Validation loss: 2.0760300390182005

Epoch: 5| Step: 6
Training loss: 1.2043421268463135
Validation loss: 2.0799189472711213

Epoch: 5| Step: 7
Training loss: 0.8939905166625977
Validation loss: 2.085883352064317

Epoch: 5| Step: 8
Training loss: 0.550972580909729
Validation loss: 2.065215249215403

Epoch: 5| Step: 9
Training loss: 1.3228154182434082
Validation loss: 2.0801567262218845

Epoch: 5| Step: 10
Training loss: 0.7426751852035522
Validation loss: 2.0922534440153386

Epoch: 417| Step: 0
Training loss: 1.4059274196624756
Validation loss: 2.1092434801081175

Epoch: 5| Step: 1
Training loss: 1.0719231367111206
Validation loss: 2.065656732487422

Epoch: 5| Step: 2
Training loss: 1.2968494892120361
Validation loss: 2.091669349260228

Epoch: 5| Step: 3
Training loss: 0.9376032948493958
Validation loss: 2.073543958766486

Epoch: 5| Step: 4
Training loss: 1.0940054655075073
Validation loss: 2.10734123568381

Epoch: 5| Step: 5
Training loss: 0.6848155856132507
Validation loss: 2.0498074203409176

Epoch: 5| Step: 6
Training loss: 1.0113205909729004
Validation loss: 2.0546128032028035

Epoch: 5| Step: 7
Training loss: 0.6936140060424805
Validation loss: 2.0733145206205306

Epoch: 5| Step: 8
Training loss: 1.608890175819397
Validation loss: 2.07480046056932

Epoch: 5| Step: 9
Training loss: 0.7598360180854797
Validation loss: 2.096603621718704

Epoch: 5| Step: 10
Training loss: 1.0137649774551392
Validation loss: 2.0927478164754887

Epoch: 418| Step: 0
Training loss: 1.232042670249939
Validation loss: 2.0698353372594362

Epoch: 5| Step: 1
Training loss: 1.1912031173706055
Validation loss: 2.0448298236375213

Epoch: 5| Step: 2
Training loss: 0.916171669960022
Validation loss: 2.083577145812332

Epoch: 5| Step: 3
Training loss: 1.0822519063949585
Validation loss: 2.042764481677804

Epoch: 5| Step: 4
Training loss: 1.3401175737380981
Validation loss: 2.074629993848903

Epoch: 5| Step: 5
Training loss: 0.9921250343322754
Validation loss: 2.0538471462906047

Epoch: 5| Step: 6
Training loss: 1.0139126777648926
Validation loss: 2.082825501759847

Epoch: 5| Step: 7
Training loss: 0.9994224309921265
Validation loss: 2.095145199888496

Epoch: 5| Step: 8
Training loss: 1.1875487565994263
Validation loss: 2.082640047996275

Epoch: 5| Step: 9
Training loss: 0.701181173324585
Validation loss: 2.1065254749790316

Epoch: 5| Step: 10
Training loss: 0.8927105069160461
Validation loss: 2.08922323360238

Epoch: 419| Step: 0
Training loss: 1.2072982788085938
Validation loss: 2.04085264923752

Epoch: 5| Step: 1
Training loss: 1.23249089717865
Validation loss: 2.03614285684401

Epoch: 5| Step: 2
Training loss: 0.826117217540741
Validation loss: 2.0534053720453733

Epoch: 5| Step: 3
Training loss: 1.0586397647857666
Validation loss: 2.083866941031589

Epoch: 5| Step: 4
Training loss: 1.3223103284835815
Validation loss: 2.0641416349718646

Epoch: 5| Step: 5
Training loss: 0.6134024858474731
Validation loss: 2.096629806744155

Epoch: 5| Step: 6
Training loss: 1.1821224689483643
Validation loss: 2.0643582113327517

Epoch: 5| Step: 7
Training loss: 0.882733166217804
Validation loss: 2.0813894348759807

Epoch: 5| Step: 8
Training loss: 0.5500380992889404
Validation loss: 2.121405601501465

Epoch: 5| Step: 9
Training loss: 1.3257076740264893
Validation loss: 2.086561784949354

Epoch: 5| Step: 10
Training loss: 1.3908870220184326
Validation loss: 2.078666474229546

Epoch: 420| Step: 0
Training loss: 0.7246500253677368
Validation loss: 2.1022650387979325

Epoch: 5| Step: 1
Training loss: 0.8784276843070984
Validation loss: 2.121923268482249

Epoch: 5| Step: 2
Training loss: 1.2412835359573364
Validation loss: 2.1170679125734555

Epoch: 5| Step: 3
Training loss: 1.4211227893829346
Validation loss: 2.0993026712889313

Epoch: 5| Step: 4
Training loss: 0.9329557418823242
Validation loss: 2.106465901097944

Epoch: 5| Step: 5
Training loss: 1.5544874668121338
Validation loss: 2.0921292074265017

Epoch: 5| Step: 6
Training loss: 0.4911552369594574
Validation loss: 2.0901123887749127

Epoch: 5| Step: 7
Training loss: 0.9279829263687134
Validation loss: 2.06414302702873

Epoch: 5| Step: 8
Training loss: 1.2173570394515991
Validation loss: 2.0811606530220277

Epoch: 5| Step: 9
Training loss: 0.7740488052368164
Validation loss: 2.062879264995616

Epoch: 5| Step: 10
Training loss: 1.3279602527618408
Validation loss: 2.0247629137449366

Epoch: 421| Step: 0
Training loss: 1.3380582332611084
Validation loss: 2.0405820646593646

Epoch: 5| Step: 1
Training loss: 0.9737502932548523
Validation loss: 2.0359593488836802

Epoch: 5| Step: 2
Training loss: 0.7860552072525024
Validation loss: 2.0589968632626277

Epoch: 5| Step: 3
Training loss: 0.8047157526016235
Validation loss: 2.073033521252294

Epoch: 5| Step: 4
Training loss: 1.3645414113998413
Validation loss: 2.053907170090624

Epoch: 5| Step: 5
Training loss: 1.0041160583496094
Validation loss: 2.0715445779984996

Epoch: 5| Step: 6
Training loss: 1.1473468542099
Validation loss: 2.1306654278950026

Epoch: 5| Step: 7
Training loss: 1.0306068658828735
Validation loss: 2.0761319424516413

Epoch: 5| Step: 8
Training loss: 1.0510635375976562
Validation loss: 2.1003514566729145

Epoch: 5| Step: 9
Training loss: 0.6698359251022339
Validation loss: 2.1291034554922454

Epoch: 5| Step: 10
Training loss: 1.1957409381866455
Validation loss: 2.0942505636522846

Epoch: 422| Step: 0
Training loss: 0.7356012463569641
Validation loss: 2.095301183321143

Epoch: 5| Step: 1
Training loss: 1.1015801429748535
Validation loss: 2.1012587867757326

Epoch: 5| Step: 2
Training loss: 1.0257117748260498
Validation loss: 2.0661221909266647

Epoch: 5| Step: 3
Training loss: 1.2073571681976318
Validation loss: 2.0549841337306525

Epoch: 5| Step: 4
Training loss: 0.8468203544616699
Validation loss: 2.0616440003918064

Epoch: 5| Step: 5
Training loss: 1.0371408462524414
Validation loss: 2.025839308256744

Epoch: 5| Step: 6
Training loss: 0.8977192044258118
Validation loss: 2.0858527024586997

Epoch: 5| Step: 7
Training loss: 0.8893651962280273
Validation loss: 2.0502869249672018

Epoch: 5| Step: 8
Training loss: 1.5985064506530762
Validation loss: 2.0448780187996487

Epoch: 5| Step: 9
Training loss: 1.13504159450531
Validation loss: 2.066127436135405

Epoch: 5| Step: 10
Training loss: 0.7694147825241089
Validation loss: 2.082762800237184

Epoch: 423| Step: 0
Training loss: 1.152451515197754
Validation loss: 2.07096714486358

Epoch: 5| Step: 1
Training loss: 0.9097375869750977
Validation loss: 2.0596890193159862

Epoch: 5| Step: 2
Training loss: 1.0714876651763916
Validation loss: 2.0219333376935733

Epoch: 5| Step: 3
Training loss: 0.4097079336643219
Validation loss: 2.0463501561072563

Epoch: 5| Step: 4
Training loss: 1.2225831747055054
Validation loss: 2.039348630494969

Epoch: 5| Step: 5
Training loss: 0.8551660776138306
Validation loss: 2.074510779432071

Epoch: 5| Step: 6
Training loss: 1.2362040281295776
Validation loss: 2.0430230145813315

Epoch: 5| Step: 7
Training loss: 1.2398287057876587
Validation loss: 2.0611829296235116

Epoch: 5| Step: 8
Training loss: 1.1058927774429321
Validation loss: 2.071732051910893

Epoch: 5| Step: 9
Training loss: 1.2025649547576904
Validation loss: 2.0535040260643087

Epoch: 5| Step: 10
Training loss: 0.8617239594459534
Validation loss: 2.107154264244982

Epoch: 424| Step: 0
Training loss: 1.121670126914978
Validation loss: 2.1354133544429654

Epoch: 5| Step: 1
Training loss: 0.9127775430679321
Validation loss: 2.098217571935346

Epoch: 5| Step: 2
Training loss: 1.1350475549697876
Validation loss: 2.1221679026080715

Epoch: 5| Step: 3
Training loss: 0.34269341826438904
Validation loss: 2.0831930291268135

Epoch: 5| Step: 4
Training loss: 0.994866669178009
Validation loss: 2.0704625575773177

Epoch: 5| Step: 5
Training loss: 1.224496603012085
Validation loss: 2.141813398689352

Epoch: 5| Step: 6
Training loss: 1.1341702938079834
Validation loss: 2.0926489573653027

Epoch: 5| Step: 7
Training loss: 1.4006586074829102
Validation loss: 2.04320958352858

Epoch: 5| Step: 8
Training loss: 1.1926164627075195
Validation loss: 2.030472699032035

Epoch: 5| Step: 9
Training loss: 0.9909344911575317
Validation loss: 2.0703409025746007

Epoch: 5| Step: 10
Training loss: 0.775848925113678
Validation loss: 2.050743736246581

Epoch: 425| Step: 0
Training loss: 0.6145697832107544
Validation loss: 2.080578642506753

Epoch: 5| Step: 1
Training loss: 1.3704813718795776
Validation loss: 2.081184576916438

Epoch: 5| Step: 2
Training loss: 1.2729190587997437
Validation loss: 2.117451278112268

Epoch: 5| Step: 3
Training loss: 0.8881838917732239
Validation loss: 2.100689564981768

Epoch: 5| Step: 4
Training loss: 0.8955151438713074
Validation loss: 2.125012683612044

Epoch: 5| Step: 5
Training loss: 1.0781028270721436
Validation loss: 2.0958013047454176

Epoch: 5| Step: 6
Training loss: 1.3331232070922852
Validation loss: 2.1112316244391987

Epoch: 5| Step: 7
Training loss: 1.0567898750305176
Validation loss: 2.0849139869854016

Epoch: 5| Step: 8
Training loss: 1.3274660110473633
Validation loss: 2.051492642330867

Epoch: 5| Step: 9
Training loss: 0.764614462852478
Validation loss: 2.0376559290834653

Epoch: 5| Step: 10
Training loss: 0.7284405827522278
Validation loss: 2.05024710265539

Epoch: 426| Step: 0
Training loss: 0.8367412686347961
Validation loss: 2.0176469766965477

Epoch: 5| Step: 1
Training loss: 1.5590850114822388
Validation loss: 2.113254033109193

Epoch: 5| Step: 2
Training loss: 1.2060515880584717
Validation loss: 2.0603797999761437

Epoch: 5| Step: 3
Training loss: 0.7179430723190308
Validation loss: 2.046021161540862

Epoch: 5| Step: 4
Training loss: 0.8516136407852173
Validation loss: 2.0581022923992527

Epoch: 5| Step: 5
Training loss: 0.8379309773445129
Validation loss: 2.0843461508392007

Epoch: 5| Step: 6
Training loss: 0.7963519096374512
Validation loss: 2.067874144482356

Epoch: 5| Step: 7
Training loss: 1.5159084796905518
Validation loss: 2.0508696981655654

Epoch: 5| Step: 8
Training loss: 0.6764251589775085
Validation loss: 2.0712337852806173

Epoch: 5| Step: 9
Training loss: 1.0506938695907593
Validation loss: 2.049774782631987

Epoch: 5| Step: 10
Training loss: 1.1559581756591797
Validation loss: 2.040344709991127

Epoch: 427| Step: 0
Training loss: 1.2634689807891846
Validation loss: 2.0601597985913678

Epoch: 5| Step: 1
Training loss: 0.9431598782539368
Validation loss: 2.042043609003867

Epoch: 5| Step: 2
Training loss: 1.1883022785186768
Validation loss: 2.03602962083714

Epoch: 5| Step: 3
Training loss: 0.7075341939926147
Validation loss: 2.040000725817937

Epoch: 5| Step: 4
Training loss: 0.8747226595878601
Validation loss: 2.041541980158898

Epoch: 5| Step: 5
Training loss: 1.2324268817901611
Validation loss: 2.0404154459635415

Epoch: 5| Step: 6
Training loss: 1.0440444946289062
Validation loss: 2.0652692830690773

Epoch: 5| Step: 7
Training loss: 1.321352481842041
Validation loss: 2.059189386265252

Epoch: 5| Step: 8
Training loss: 1.0329787731170654
Validation loss: 2.1101212629707913

Epoch: 5| Step: 9
Training loss: 0.6320046186447144
Validation loss: 2.1434643063493954

Epoch: 5| Step: 10
Training loss: 1.127072811126709
Validation loss: 2.1656087803584274

Epoch: 428| Step: 0
Training loss: 1.5330692529678345
Validation loss: 2.1467141156555503

Epoch: 5| Step: 1
Training loss: 1.0794670581817627
Validation loss: 2.145545110907606

Epoch: 5| Step: 2
Training loss: 1.4239658117294312
Validation loss: 2.11985263516826

Epoch: 5| Step: 3
Training loss: 1.2434321641921997
Validation loss: 2.073946716964886

Epoch: 5| Step: 4
Training loss: 0.8028998374938965
Validation loss: 2.0560823563606507

Epoch: 5| Step: 5
Training loss: 1.0617873668670654
Validation loss: 2.022277788449359

Epoch: 5| Step: 6
Training loss: 0.4217904210090637
Validation loss: 2.007612439893907

Epoch: 5| Step: 7
Training loss: 1.0847020149230957
Validation loss: 1.9943691453626078

Epoch: 5| Step: 8
Training loss: 0.8265194892883301
Validation loss: 1.9676922546919955

Epoch: 5| Step: 9
Training loss: 0.8455546498298645
Validation loss: 2.001353976547077

Epoch: 5| Step: 10
Training loss: 0.9796584844589233
Validation loss: 2.004035193433044

Epoch: 429| Step: 0
Training loss: 1.1396745443344116
Validation loss: 2.039640111307944

Epoch: 5| Step: 1
Training loss: 1.347295880317688
Validation loss: 2.08997969729926

Epoch: 5| Step: 2
Training loss: 1.1858028173446655
Validation loss: 2.1335384486823954

Epoch: 5| Step: 3
Training loss: 0.7974571585655212
Validation loss: 2.1413935974080074

Epoch: 5| Step: 4
Training loss: 0.9679329991340637
Validation loss: 2.203048195890201

Epoch: 5| Step: 5
Training loss: 0.8162460327148438
Validation loss: 2.1488689632825952

Epoch: 5| Step: 6
Training loss: 1.1211332082748413
Validation loss: 2.1311496303927515

Epoch: 5| Step: 7
Training loss: 1.4202053546905518
Validation loss: 2.148123195094447

Epoch: 5| Step: 8
Training loss: 0.7067937850952148
Validation loss: 2.1335447578019995

Epoch: 5| Step: 9
Training loss: 0.9876135587692261
Validation loss: 2.162301819811585

Epoch: 5| Step: 10
Training loss: 0.779287576675415
Validation loss: 2.1160450840509064

Epoch: 430| Step: 0
Training loss: 1.0288630723953247
Validation loss: 2.131645799964987

Epoch: 5| Step: 1
Training loss: 0.9338959455490112
Validation loss: 2.1086722625199186

Epoch: 5| Step: 2
Training loss: 0.9321645498275757
Validation loss: 2.0797081352562032

Epoch: 5| Step: 3
Training loss: 0.8114436268806458
Validation loss: 2.077463250006399

Epoch: 5| Step: 4
Training loss: 0.692886471748352
Validation loss: 2.05621692954853

Epoch: 5| Step: 5
Training loss: 0.9821394085884094
Validation loss: 2.086350348687941

Epoch: 5| Step: 6
Training loss: 1.475858449935913
Validation loss: 2.034840242837065

Epoch: 5| Step: 7
Training loss: 0.7894375324249268
Validation loss: 2.096566702729912

Epoch: 5| Step: 8
Training loss: 1.3107008934020996
Validation loss: 2.057245454480571

Epoch: 5| Step: 9
Training loss: 1.3284331560134888
Validation loss: 2.0665473104805074

Epoch: 5| Step: 10
Training loss: 1.2152490615844727
Validation loss: 2.09395416321293

Epoch: 431| Step: 0
Training loss: 1.1501317024230957
Validation loss: 2.077936790322745

Epoch: 5| Step: 1
Training loss: 1.3725351095199585
Validation loss: 2.121338512307854

Epoch: 5| Step: 2
Training loss: 0.8430277705192566
Validation loss: 2.0865705205548193

Epoch: 5| Step: 3
Training loss: 0.8053570985794067
Validation loss: 2.0887492292670795

Epoch: 5| Step: 4
Training loss: 0.8826500177383423
Validation loss: 2.127619139609798

Epoch: 5| Step: 5
Training loss: 0.8007990121841431
Validation loss: 2.1017270831651587

Epoch: 5| Step: 6
Training loss: 0.716471254825592
Validation loss: 2.1671455547373784

Epoch: 5| Step: 7
Training loss: 0.9189640283584595
Validation loss: 2.169093134582684

Epoch: 5| Step: 8
Training loss: 1.2508063316345215
Validation loss: 2.1849740628273255

Epoch: 5| Step: 9
Training loss: 1.1621125936508179
Validation loss: 2.160587397954797

Epoch: 5| Step: 10
Training loss: 1.3075075149536133
Validation loss: 2.17374901745909

Epoch: 432| Step: 0
Training loss: 0.9236005544662476
Validation loss: 2.138703518016364

Epoch: 5| Step: 1
Training loss: 0.5641035437583923
Validation loss: 2.116087449494229

Epoch: 5| Step: 2
Training loss: 0.967459499835968
Validation loss: 2.099289027593469

Epoch: 5| Step: 3
Training loss: 1.0587072372436523
Validation loss: 2.0894049521415465

Epoch: 5| Step: 4
Training loss: 1.3797032833099365
Validation loss: 2.0772444714782057

Epoch: 5| Step: 5
Training loss: 1.2686342000961304
Validation loss: 2.028654013910601

Epoch: 5| Step: 6
Training loss: 0.5771336555480957
Validation loss: 2.0344313011374524

Epoch: 5| Step: 7
Training loss: 1.208296775817871
Validation loss: 2.0879342966182257

Epoch: 5| Step: 8
Training loss: 1.3241649866104126
Validation loss: 2.0344747599735054

Epoch: 5| Step: 9
Training loss: 0.9060371518135071
Validation loss: 2.0565201261992097

Epoch: 5| Step: 10
Training loss: 0.9470610618591309
Validation loss: 2.0320492284272307

Epoch: 433| Step: 0
Training loss: 1.145193338394165
Validation loss: 2.0454244780284103

Epoch: 5| Step: 1
Training loss: 0.778849184513092
Validation loss: 2.0456877575125745

Epoch: 5| Step: 2
Training loss: 1.0485973358154297
Validation loss: 2.0468163592841035

Epoch: 5| Step: 3
Training loss: 1.378647804260254
Validation loss: 2.1004167346544165

Epoch: 5| Step: 4
Training loss: 0.7263596653938293
Validation loss: 2.0836196663559123

Epoch: 5| Step: 5
Training loss: 1.0366926193237305
Validation loss: 2.060445316376225

Epoch: 5| Step: 6
Training loss: 0.9488599896430969
Validation loss: 2.093920184719947

Epoch: 5| Step: 7
Training loss: 0.854827880859375
Validation loss: 2.0990616608691472

Epoch: 5| Step: 8
Training loss: 0.6446046233177185
Validation loss: 2.079382801568636

Epoch: 5| Step: 9
Training loss: 1.1898621320724487
Validation loss: 2.078141174008769

Epoch: 5| Step: 10
Training loss: 1.4039201736450195
Validation loss: 2.1041212748455744

Epoch: 434| Step: 0
Training loss: 0.793175995349884
Validation loss: 2.0540603642822592

Epoch: 5| Step: 1
Training loss: 0.5734926462173462
Validation loss: 2.0530476621402207

Epoch: 5| Step: 2
Training loss: 0.7343836426734924
Validation loss: 2.0219555977852113

Epoch: 5| Step: 3
Training loss: 1.3199384212493896
Validation loss: 2.0207529298720823

Epoch: 5| Step: 4
Training loss: 1.0583685636520386
Validation loss: 2.046285621581539

Epoch: 5| Step: 5
Training loss: 1.147515058517456
Validation loss: 2.0160050904879006

Epoch: 5| Step: 6
Training loss: 1.0073678493499756
Validation loss: 2.0300918189428185

Epoch: 5| Step: 7
Training loss: 1.2734678983688354
Validation loss: 2.016258123100445

Epoch: 5| Step: 8
Training loss: 1.147940993309021
Validation loss: 2.0433167539617068

Epoch: 5| Step: 9
Training loss: 0.8983207941055298
Validation loss: 2.042422854772178

Epoch: 5| Step: 10
Training loss: 1.1413354873657227
Validation loss: 2.04320107095985

Epoch: 435| Step: 0
Training loss: 0.8239030838012695
Validation loss: 2.0499205025293494

Epoch: 5| Step: 1
Training loss: 1.057864785194397
Validation loss: 2.0712766160247145

Epoch: 5| Step: 2
Training loss: 0.7949385046958923
Validation loss: 2.074623223273985

Epoch: 5| Step: 3
Training loss: 1.0409834384918213
Validation loss: 2.113204388208287

Epoch: 5| Step: 4
Training loss: 1.1156666278839111
Validation loss: 2.10320649608489

Epoch: 5| Step: 5
Training loss: 1.352863073348999
Validation loss: 2.0889778470480316

Epoch: 5| Step: 6
Training loss: 1.2547662258148193
Validation loss: 2.0608017886838605

Epoch: 5| Step: 7
Training loss: 0.8854775428771973
Validation loss: 2.0384193364010064

Epoch: 5| Step: 8
Training loss: 0.8711875081062317
Validation loss: 2.0330924731428905

Epoch: 5| Step: 9
Training loss: 0.5682681202888489
Validation loss: 2.0145932294989146

Epoch: 5| Step: 10
Training loss: 1.1268209218978882
Validation loss: 2.0126818200593353

Epoch: 436| Step: 0
Training loss: 1.0230433940887451
Validation loss: 2.013786817109713

Epoch: 5| Step: 1
Training loss: 1.125237226486206
Validation loss: 2.000534283217563

Epoch: 5| Step: 2
Training loss: 0.6657384634017944
Validation loss: 1.9963222037079513

Epoch: 5| Step: 3
Training loss: 1.167595386505127
Validation loss: 1.9950470283467283

Epoch: 5| Step: 4
Training loss: 0.7765315771102905
Validation loss: 2.0119814770196074

Epoch: 5| Step: 5
Training loss: 0.8798986673355103
Validation loss: 2.023074342358497

Epoch: 5| Step: 6
Training loss: 0.8385351300239563
Validation loss: 2.0274525265539847

Epoch: 5| Step: 7
Training loss: 1.2871589660644531
Validation loss: 2.049750339600348

Epoch: 5| Step: 8
Training loss: 1.0089282989501953
Validation loss: 2.0767017897739204

Epoch: 5| Step: 9
Training loss: 1.642289161682129
Validation loss: 2.1046958290120608

Epoch: 5| Step: 10
Training loss: 0.6332987546920776
Validation loss: 2.1040815063702163

Epoch: 437| Step: 0
Training loss: 0.6638599038124084
Validation loss: 2.147707752002183

Epoch: 5| Step: 1
Training loss: 1.0571433305740356
Validation loss: 2.099752185165241

Epoch: 5| Step: 2
Training loss: 0.7685595750808716
Validation loss: 2.0973635899123324

Epoch: 5| Step: 3
Training loss: 0.834825336933136
Validation loss: 2.0928848148674093

Epoch: 5| Step: 4
Training loss: 1.1352826356887817
Validation loss: 2.0821923209774877

Epoch: 5| Step: 5
Training loss: 0.9838077425956726
Validation loss: 2.044013600195608

Epoch: 5| Step: 6
Training loss: 1.0118186473846436
Validation loss: 2.026595283580083

Epoch: 5| Step: 7
Training loss: 0.9793089628219604
Validation loss: 2.0290708413688083

Epoch: 5| Step: 8
Training loss: 1.190246343612671
Validation loss: 2.010308893777991

Epoch: 5| Step: 9
Training loss: 1.166005253791809
Validation loss: 2.0199667843439246

Epoch: 5| Step: 10
Training loss: 0.9875873327255249
Validation loss: 1.981035094107351

Epoch: 438| Step: 0
Training loss: 1.0438926219940186
Validation loss: 2.013119941116661

Epoch: 5| Step: 1
Training loss: 0.4386600852012634
Validation loss: 2.0071595227846535

Epoch: 5| Step: 2
Training loss: 0.956004798412323
Validation loss: 2.013498665184103

Epoch: 5| Step: 3
Training loss: 1.2522892951965332
Validation loss: 2.0445021070459837

Epoch: 5| Step: 4
Training loss: 0.7522483468055725
Validation loss: 2.0515773629629486

Epoch: 5| Step: 5
Training loss: 1.0504478216171265
Validation loss: 2.035442231803812

Epoch: 5| Step: 6
Training loss: 1.1043312549591064
Validation loss: 2.068313924215173

Epoch: 5| Step: 7
Training loss: 0.9349206686019897
Validation loss: 2.073720561560764

Epoch: 5| Step: 8
Training loss: 1.5136423110961914
Validation loss: 2.1212224268144175

Epoch: 5| Step: 9
Training loss: 0.81471186876297
Validation loss: 2.114317851681863

Epoch: 5| Step: 10
Training loss: 0.8767472505569458
Validation loss: 2.1155077436918854

Epoch: 439| Step: 0
Training loss: 1.0139381885528564
Validation loss: 2.0862444216205227

Epoch: 5| Step: 1
Training loss: 0.8826063275337219
Validation loss: 2.0742214623317925

Epoch: 5| Step: 2
Training loss: 0.9455544352531433
Validation loss: 2.049269001971009

Epoch: 5| Step: 3
Training loss: 1.2109113931655884
Validation loss: 2.0203778243833974

Epoch: 5| Step: 4
Training loss: 0.8567631840705872
Validation loss: 2.039110154233953

Epoch: 5| Step: 5
Training loss: 1.0779316425323486
Validation loss: 2.008815529525921

Epoch: 5| Step: 6
Training loss: 0.9321465492248535
Validation loss: 2.0248163861613118

Epoch: 5| Step: 7
Training loss: 1.1196577548980713
Validation loss: 2.0374989817219396

Epoch: 5| Step: 8
Training loss: 0.8364971280097961
Validation loss: 2.0163376856875677

Epoch: 5| Step: 9
Training loss: 1.1540127992630005
Validation loss: 2.025167085791147

Epoch: 5| Step: 10
Training loss: 0.7411113977432251
Validation loss: 2.030671690099983

Epoch: 440| Step: 0
Training loss: 0.784494161605835
Validation loss: 2.05873320820511

Epoch: 5| Step: 1
Training loss: 0.9462183117866516
Validation loss: 2.057108489415979

Epoch: 5| Step: 2
Training loss: 1.5268313884735107
Validation loss: 2.066068201936701

Epoch: 5| Step: 3
Training loss: 0.6334059834480286
Validation loss: 2.0219909529532156

Epoch: 5| Step: 4
Training loss: 1.1978648900985718
Validation loss: 2.0543075069304435

Epoch: 5| Step: 5
Training loss: 0.5164268612861633
Validation loss: 2.0453751138461533

Epoch: 5| Step: 6
Training loss: 1.0900905132293701
Validation loss: 2.0438011487325034

Epoch: 5| Step: 7
Training loss: 0.8419526219367981
Validation loss: 2.0174119754504134

Epoch: 5| Step: 8
Training loss: 0.9330819845199585
Validation loss: 2.0414522976003666

Epoch: 5| Step: 9
Training loss: 1.2125554084777832
Validation loss: 2.051823382736534

Epoch: 5| Step: 10
Training loss: 1.040313720703125
Validation loss: 2.051264698787402

Epoch: 441| Step: 0
Training loss: 1.0729587078094482
Validation loss: 2.068577310090424

Epoch: 5| Step: 1
Training loss: 0.9235675930976868
Validation loss: 2.0691659091621317

Epoch: 5| Step: 2
Training loss: 0.8707696795463562
Validation loss: 2.101326414333877

Epoch: 5| Step: 3
Training loss: 0.6438004970550537
Validation loss: 2.0946832421005412

Epoch: 5| Step: 4
Training loss: 1.4100987911224365
Validation loss: 2.102598036489179

Epoch: 5| Step: 5
Training loss: 1.2342420816421509
Validation loss: 2.120261961413968

Epoch: 5| Step: 6
Training loss: 1.0917418003082275
Validation loss: 2.1031273026620187

Epoch: 5| Step: 7
Training loss: 0.5958783030509949
Validation loss: 2.0915316638126167

Epoch: 5| Step: 8
Training loss: 0.5282502174377441
Validation loss: 2.0569656600234327

Epoch: 5| Step: 9
Training loss: 1.1424846649169922
Validation loss: 2.054834768336306

Epoch: 5| Step: 10
Training loss: 0.7466685771942139
Validation loss: 2.0431647377629436

Epoch: 442| Step: 0
Training loss: 0.8495929837226868
Validation loss: 2.054820265821231

Epoch: 5| Step: 1
Training loss: 1.020222783088684
Validation loss: 2.030389360202256

Epoch: 5| Step: 2
Training loss: 1.042097806930542
Validation loss: 2.0484284047157533

Epoch: 5| Step: 3
Training loss: 0.9355447888374329
Validation loss: 2.038414539829377

Epoch: 5| Step: 4
Training loss: 1.2172486782073975
Validation loss: 2.065073582433885

Epoch: 5| Step: 5
Training loss: 0.9222543835639954
Validation loss: 2.0506707186340005

Epoch: 5| Step: 6
Training loss: 1.273821473121643
Validation loss: 2.057221761313818

Epoch: 5| Step: 7
Training loss: 0.47106704115867615
Validation loss: 2.0772986899140062

Epoch: 5| Step: 8
Training loss: 0.7861693501472473
Validation loss: 2.072430169710549

Epoch: 5| Step: 9
Training loss: 0.9380003213882446
Validation loss: 2.090878539187934

Epoch: 5| Step: 10
Training loss: 1.0842738151550293
Validation loss: 2.0975985937221076

Epoch: 443| Step: 0
Training loss: 0.9557090997695923
Validation loss: 2.0900417348389984

Epoch: 5| Step: 1
Training loss: 0.6780149936676025
Validation loss: 2.052468566484349

Epoch: 5| Step: 2
Training loss: 1.1326247453689575
Validation loss: 2.0828884519556516

Epoch: 5| Step: 3
Training loss: 0.9079607129096985
Validation loss: 2.0808872202391266

Epoch: 5| Step: 4
Training loss: 0.5556553602218628
Validation loss: 2.0493628132727837

Epoch: 5| Step: 5
Training loss: 1.5632002353668213
Validation loss: 2.0257320173325075

Epoch: 5| Step: 6
Training loss: 0.7684035301208496
Validation loss: 2.076603574137534

Epoch: 5| Step: 7
Training loss: 1.1101229190826416
Validation loss: 2.0224715842995593

Epoch: 5| Step: 8
Training loss: 0.7885920405387878
Validation loss: 2.0085177395933416

Epoch: 5| Step: 9
Training loss: 0.9923356771469116
Validation loss: 2.025476204451694

Epoch: 5| Step: 10
Training loss: 1.0933077335357666
Validation loss: 2.007235280929073

Epoch: 444| Step: 0
Training loss: 1.2054122686386108
Validation loss: 2.034427330058108

Epoch: 5| Step: 1
Training loss: 0.6631583571434021
Validation loss: 2.060913133364852

Epoch: 5| Step: 2
Training loss: 0.9610856175422668
Validation loss: 2.057178892115111

Epoch: 5| Step: 3
Training loss: 0.6075299978256226
Validation loss: 2.0544315845735612

Epoch: 5| Step: 4
Training loss: 1.246683120727539
Validation loss: 2.066072065343139

Epoch: 5| Step: 5
Training loss: 0.8515148162841797
Validation loss: 2.0619174562474734

Epoch: 5| Step: 6
Training loss: 1.0097569227218628
Validation loss: 2.0441543030482467

Epoch: 5| Step: 7
Training loss: 1.0134764909744263
Validation loss: 2.055594298147386

Epoch: 5| Step: 8
Training loss: 1.0449674129486084
Validation loss: 2.114862847071822

Epoch: 5| Step: 9
Training loss: 0.8487612009048462
Validation loss: 2.0904909923512447

Epoch: 5| Step: 10
Training loss: 0.8063973784446716
Validation loss: 2.0549762710448234

Epoch: 445| Step: 0
Training loss: 1.1279064416885376
Validation loss: 2.0418285554455173

Epoch: 5| Step: 1
Training loss: 0.6082965135574341
Validation loss: 2.0763784044532367

Epoch: 5| Step: 2
Training loss: 0.772607147693634
Validation loss: 2.0461199975782827

Epoch: 5| Step: 3
Training loss: 1.2462680339813232
Validation loss: 2.075723139188623

Epoch: 5| Step: 4
Training loss: 0.7895711660385132
Validation loss: 2.0640276273091636

Epoch: 5| Step: 5
Training loss: 0.6623526215553284
Validation loss: 2.023632537934088

Epoch: 5| Step: 6
Training loss: 1.1830909252166748
Validation loss: 2.059117332581551

Epoch: 5| Step: 7
Training loss: 1.3445438146591187
Validation loss: 2.0040042836179017

Epoch: 5| Step: 8
Training loss: 1.0165672302246094
Validation loss: 2.0267262176800798

Epoch: 5| Step: 9
Training loss: 0.7795265913009644
Validation loss: 1.983837959586933

Epoch: 5| Step: 10
Training loss: 0.7246208786964417
Validation loss: 2.0614373683929443

Epoch: 446| Step: 0
Training loss: 0.9654130935668945
Validation loss: 2.0439825775802776

Epoch: 5| Step: 1
Training loss: 1.0961377620697021
Validation loss: 2.055189412127259

Epoch: 5| Step: 2
Training loss: 0.843792736530304
Validation loss: 2.1160136371530514

Epoch: 5| Step: 3
Training loss: 0.8698034286499023
Validation loss: 2.116958177217873

Epoch: 5| Step: 4
Training loss: 0.8277042508125305
Validation loss: 2.1232266605541272

Epoch: 5| Step: 5
Training loss: 0.7695053815841675
Validation loss: 2.1253307404056674

Epoch: 5| Step: 6
Training loss: 0.9710172414779663
Validation loss: 2.0761160414705992

Epoch: 5| Step: 7
Training loss: 1.1507346630096436
Validation loss: 2.074589603690691

Epoch: 5| Step: 8
Training loss: 1.0415829420089722
Validation loss: 2.069725357076173

Epoch: 5| Step: 9
Training loss: 0.8601919412612915
Validation loss: 2.0639862104128768

Epoch: 5| Step: 10
Training loss: 0.5246280431747437
Validation loss: 2.046168504222747

Epoch: 447| Step: 0
Training loss: 0.7792457342147827
Validation loss: 2.040004661006312

Epoch: 5| Step: 1
Training loss: 1.0588021278381348
Validation loss: 2.0435132441982145

Epoch: 5| Step: 2
Training loss: 0.8988348245620728
Validation loss: 2.041566414217795

Epoch: 5| Step: 3
Training loss: 1.0448213815689087
Validation loss: 2.046031012330004

Epoch: 5| Step: 4
Training loss: 0.5950474143028259
Validation loss: 2.029974809256933

Epoch: 5| Step: 5
Training loss: 0.8698994517326355
Validation loss: 2.0498607517570577

Epoch: 5| Step: 6
Training loss: 0.7020627856254578
Validation loss: 2.026560693658808

Epoch: 5| Step: 7
Training loss: 0.7965916395187378
Validation loss: 2.0944258256625106

Epoch: 5| Step: 8
Training loss: 1.2963300943374634
Validation loss: 2.0420116737324703

Epoch: 5| Step: 9
Training loss: 1.4707227945327759
Validation loss: 2.0644751210366525

Epoch: 5| Step: 10
Training loss: 0.5274734497070312
Validation loss: 2.0827023201091315

Epoch: 448| Step: 0
Training loss: 0.6994925141334534
Validation loss: 2.081849608370053

Epoch: 5| Step: 1
Training loss: 0.8816760778427124
Validation loss: 2.078518634201378

Epoch: 5| Step: 2
Training loss: 1.032960295677185
Validation loss: 2.076981303512409

Epoch: 5| Step: 3
Training loss: 0.4595564305782318
Validation loss: 2.055603688763034

Epoch: 5| Step: 4
Training loss: 0.8017633557319641
Validation loss: 2.075562354057066

Epoch: 5| Step: 5
Training loss: 0.6302732825279236
Validation loss: 2.113665480767527

Epoch: 5| Step: 6
Training loss: 1.2632358074188232
Validation loss: 2.080586028355424

Epoch: 5| Step: 7
Training loss: 1.3377782106399536
Validation loss: 2.1282877486239196

Epoch: 5| Step: 8
Training loss: 1.0563596487045288
Validation loss: 2.0819692791149182

Epoch: 5| Step: 9
Training loss: 1.1932120323181152
Validation loss: 2.0851001303683043

Epoch: 5| Step: 10
Training loss: 0.8980834484100342
Validation loss: 2.067144193956929

Epoch: 449| Step: 0
Training loss: 1.372165560722351
Validation loss: 2.110948565185711

Epoch: 5| Step: 1
Training loss: 0.6550914645195007
Validation loss: 2.144048306249803

Epoch: 5| Step: 2
Training loss: 0.6964712142944336
Validation loss: 2.1065015485209804

Epoch: 5| Step: 3
Training loss: 0.8042821884155273
Validation loss: 2.0661464993671705

Epoch: 5| Step: 4
Training loss: 0.6393007040023804
Validation loss: 2.040495321314822

Epoch: 5| Step: 5
Training loss: 0.7953606247901917
Validation loss: 2.0414736822087276

Epoch: 5| Step: 6
Training loss: 0.920519232749939
Validation loss: 1.997518035673326

Epoch: 5| Step: 7
Training loss: 1.3595999479293823
Validation loss: 1.9934528489266672

Epoch: 5| Step: 8
Training loss: 0.8764019012451172
Validation loss: 1.9864347237412647

Epoch: 5| Step: 9
Training loss: 0.9808737635612488
Validation loss: 2.0302040423116376

Epoch: 5| Step: 10
Training loss: 0.9681378602981567
Validation loss: 2.0116972705369354

Epoch: 450| Step: 0
Training loss: 0.7874190211296082
Validation loss: 2.0093607453889746

Epoch: 5| Step: 1
Training loss: 0.6299487948417664
Validation loss: 2.019833690376692

Epoch: 5| Step: 2
Training loss: 1.010559320449829
Validation loss: 2.0575347497899044

Epoch: 5| Step: 3
Training loss: 0.8850876688957214
Validation loss: 2.0653126291049424

Epoch: 5| Step: 4
Training loss: 1.0581456422805786
Validation loss: 2.037197454001314

Epoch: 5| Step: 5
Training loss: 0.9373777508735657
Validation loss: 2.0158070543760895

Epoch: 5| Step: 6
Training loss: 1.0143451690673828
Validation loss: 2.0378991993524695

Epoch: 5| Step: 7
Training loss: 0.7810735702514648
Validation loss: 1.993382630809661

Epoch: 5| Step: 8
Training loss: 1.3014247417449951
Validation loss: 1.9957723720099336

Epoch: 5| Step: 9
Training loss: 0.854832649230957
Validation loss: 1.9798445624689902

Epoch: 5| Step: 10
Training loss: 0.6957515478134155
Validation loss: 2.0075140101935274

Epoch: 451| Step: 0
Training loss: 0.6563892364501953
Validation loss: 2.017568870257306

Epoch: 5| Step: 1
Training loss: 0.7645577788352966
Validation loss: 2.0266492507791005

Epoch: 5| Step: 2
Training loss: 0.8907081484794617
Validation loss: 2.010142300718574

Epoch: 5| Step: 3
Training loss: 0.9187712669372559
Validation loss: 2.0179309370697185

Epoch: 5| Step: 4
Training loss: 1.1581199169158936
Validation loss: 2.0308910159654516

Epoch: 5| Step: 5
Training loss: 0.9209332466125488
Validation loss: 2.0404375727458666

Epoch: 5| Step: 6
Training loss: 0.8097690343856812
Validation loss: 2.009413560231527

Epoch: 5| Step: 7
Training loss: 1.1301147937774658
Validation loss: 2.0059696551292174

Epoch: 5| Step: 8
Training loss: 1.1359198093414307
Validation loss: 2.049893413820574

Epoch: 5| Step: 9
Training loss: 0.9823271632194519
Validation loss: 2.05382675509299

Epoch: 5| Step: 10
Training loss: 0.7130998373031616
Validation loss: 2.103843089072935

Epoch: 452| Step: 0
Training loss: 0.978009819984436
Validation loss: 2.113963398882138

Epoch: 5| Step: 1
Training loss: 1.0839638710021973
Validation loss: 2.1237669939635904

Epoch: 5| Step: 2
Training loss: 0.6981488466262817
Validation loss: 2.1190110175840315

Epoch: 5| Step: 3
Training loss: 1.2330713272094727
Validation loss: 2.126565001344168

Epoch: 5| Step: 4
Training loss: 0.9534652829170227
Validation loss: 2.1274161979716313

Epoch: 5| Step: 5
Training loss: 0.8771129846572876
Validation loss: 2.120449153325891

Epoch: 5| Step: 6
Training loss: 0.6259545087814331
Validation loss: 2.1476053102042085

Epoch: 5| Step: 7
Training loss: 0.8422015309333801
Validation loss: 2.0960822079771306

Epoch: 5| Step: 8
Training loss: 1.068704605102539
Validation loss: 2.1198951185390515

Epoch: 5| Step: 9
Training loss: 0.7122930884361267
Validation loss: 2.100992864178073

Epoch: 5| Step: 10
Training loss: 0.9174959659576416
Validation loss: 2.0600405649472306

Epoch: 453| Step: 0
Training loss: 1.1538728475570679
Validation loss: 2.0357750308129097

Epoch: 5| Step: 1
Training loss: 0.739150881767273
Validation loss: 2.03495547591999

Epoch: 5| Step: 2
Training loss: 1.1641528606414795
Validation loss: 2.0157331753802556

Epoch: 5| Step: 3
Training loss: 0.9732322692871094
Validation loss: 2.0167516200773177

Epoch: 5| Step: 4
Training loss: 1.002450942993164
Validation loss: 2.0049072696316625

Epoch: 5| Step: 5
Training loss: 0.5798672437667847
Validation loss: 2.0058220458287064

Epoch: 5| Step: 6
Training loss: 1.0519376993179321
Validation loss: 2.0223408668271956

Epoch: 5| Step: 7
Training loss: 1.0326800346374512
Validation loss: 2.031675395145211

Epoch: 5| Step: 8
Training loss: 0.8901582956314087
Validation loss: 1.998408458566153

Epoch: 5| Step: 9
Training loss: 0.6875479221343994
Validation loss: 2.032736615468097

Epoch: 5| Step: 10
Training loss: 0.691156804561615
Validation loss: 2.04046602659328

Epoch: 454| Step: 0
Training loss: 0.6218849420547485
Validation loss: 2.05046054368378

Epoch: 5| Step: 1
Training loss: 0.8744707107543945
Validation loss: 2.0699161483395483

Epoch: 5| Step: 2
Training loss: 1.2099484205245972
Validation loss: 2.091391514706355

Epoch: 5| Step: 3
Training loss: 0.9572482109069824
Validation loss: 2.0475538674221245

Epoch: 5| Step: 4
Training loss: 1.1674671173095703
Validation loss: 2.051372569094422

Epoch: 5| Step: 5
Training loss: 1.1651077270507812
Validation loss: 2.0361708799997964

Epoch: 5| Step: 6
Training loss: 1.0808969736099243
Validation loss: 2.0687588363565426

Epoch: 5| Step: 7
Training loss: 1.043455719947815
Validation loss: 1.9949087314708258

Epoch: 5| Step: 8
Training loss: 0.7155748605728149
Validation loss: 2.035895597550177

Epoch: 5| Step: 9
Training loss: 0.4253505766391754
Validation loss: 2.0325677241048505

Epoch: 5| Step: 10
Training loss: 0.7310745716094971
Validation loss: 2.0071631567452544

Epoch: 455| Step: 0
Training loss: 0.6625430583953857
Validation loss: 2.0248976625421995

Epoch: 5| Step: 1
Training loss: 1.0459227561950684
Validation loss: 2.055398464202881

Epoch: 5| Step: 2
Training loss: 0.8154667615890503
Validation loss: 2.0659541032647573

Epoch: 5| Step: 3
Training loss: 1.399476408958435
Validation loss: 2.0639263122312483

Epoch: 5| Step: 4
Training loss: 0.7347161173820496
Validation loss: 2.0797196780481646

Epoch: 5| Step: 5
Training loss: 1.0448213815689087
Validation loss: 2.044266757144723

Epoch: 5| Step: 6
Training loss: 1.3711398839950562
Validation loss: 2.0182558939021122

Epoch: 5| Step: 7
Training loss: 0.698517918586731
Validation loss: 2.017725747118714

Epoch: 5| Step: 8
Training loss: 0.6037276387214661
Validation loss: 2.02141861889952

Epoch: 5| Step: 9
Training loss: 0.8237471580505371
Validation loss: 2.0227501059091217

Epoch: 5| Step: 10
Training loss: 0.8365941047668457
Validation loss: 2.0109556823648433

Epoch: 456| Step: 0
Training loss: 0.7199090719223022
Validation loss: 2.0491580681134294

Epoch: 5| Step: 1
Training loss: 1.0556328296661377
Validation loss: 2.069109803886824

Epoch: 5| Step: 2
Training loss: 0.7910481691360474
Validation loss: 2.0788442204075475

Epoch: 5| Step: 3
Training loss: 0.8226423263549805
Validation loss: 2.0570536582700667

Epoch: 5| Step: 4
Training loss: 0.7548927068710327
Validation loss: 2.0525802207249466

Epoch: 5| Step: 5
Training loss: 1.1019575595855713
Validation loss: 2.106655425922845

Epoch: 5| Step: 6
Training loss: 1.0076606273651123
Validation loss: 2.0873358608573995

Epoch: 5| Step: 7
Training loss: 1.1191234588623047
Validation loss: 2.123074275191112

Epoch: 5| Step: 8
Training loss: 0.7494417428970337
Validation loss: 2.116325404054375

Epoch: 5| Step: 9
Training loss: 1.2369321584701538
Validation loss: 2.1092348355118946

Epoch: 5| Step: 10
Training loss: 0.46489760279655457
Validation loss: 2.1055667195268857

Epoch: 457| Step: 0
Training loss: 0.9378687143325806
Validation loss: 2.1175574487255466

Epoch: 5| Step: 1
Training loss: 1.028490662574768
Validation loss: 2.089532212544513

Epoch: 5| Step: 2
Training loss: 0.7767109870910645
Validation loss: 2.070261650187995

Epoch: 5| Step: 3
Training loss: 1.2332160472869873
Validation loss: 2.051396782680224

Epoch: 5| Step: 4
Training loss: 1.055863857269287
Validation loss: 2.016642403858964

Epoch: 5| Step: 5
Training loss: 0.6246401071548462
Validation loss: 2.056457455440234

Epoch: 5| Step: 6
Training loss: 1.1231619119644165
Validation loss: 2.048848198306176

Epoch: 5| Step: 7
Training loss: 0.9121537208557129
Validation loss: 2.016366051089379

Epoch: 5| Step: 8
Training loss: 0.7620376348495483
Validation loss: 2.0662684902068107

Epoch: 5| Step: 9
Training loss: 0.5261512994766235
Validation loss: 2.0463234570718583

Epoch: 5| Step: 10
Training loss: 0.7620841264724731
Validation loss: 2.0538986421400502

Epoch: 458| Step: 0
Training loss: 1.1171592473983765
Validation loss: 2.0884124643059185

Epoch: 5| Step: 1
Training loss: 0.7224103808403015
Validation loss: 2.0978581854092178

Epoch: 5| Step: 2
Training loss: 1.113174557685852
Validation loss: 2.1068471708605365

Epoch: 5| Step: 3
Training loss: 1.310676097869873
Validation loss: 2.1160377712659937

Epoch: 5| Step: 4
Training loss: 1.0113550424575806
Validation loss: 2.0786839646677815

Epoch: 5| Step: 5
Training loss: 0.9445449709892273
Validation loss: 2.081291310248836

Epoch: 5| Step: 6
Training loss: 0.6222198605537415
Validation loss: 2.0499528736196537

Epoch: 5| Step: 7
Training loss: 0.8165152668952942
Validation loss: 2.0024314644516155

Epoch: 5| Step: 8
Training loss: 0.6201372146606445
Validation loss: 2.0317313799294094

Epoch: 5| Step: 9
Training loss: 0.788224458694458
Validation loss: 2.0179970546435286

Epoch: 5| Step: 10
Training loss: 0.9216927289962769
Validation loss: 2.0146606276112218

Epoch: 459| Step: 0
Training loss: 1.2566505670547485
Validation loss: 2.0251634941306165

Epoch: 5| Step: 1
Training loss: 0.9680004119873047
Validation loss: 1.9974490801493328

Epoch: 5| Step: 2
Training loss: 1.2607929706573486
Validation loss: 2.000871641661531

Epoch: 5| Step: 3
Training loss: 0.8084424734115601
Validation loss: 2.0459675506878923

Epoch: 5| Step: 4
Training loss: 0.7320605516433716
Validation loss: 2.0446166582005

Epoch: 5| Step: 5
Training loss: 0.8166303634643555
Validation loss: 2.06260988661038

Epoch: 5| Step: 6
Training loss: 0.25953003764152527
Validation loss: 2.015981588312375

Epoch: 5| Step: 7
Training loss: 1.181302547454834
Validation loss: 2.0613433225180513

Epoch: 5| Step: 8
Training loss: 0.7211886048316956
Validation loss: 2.0232254971740065

Epoch: 5| Step: 9
Training loss: 1.067275881767273
Validation loss: 2.0337335839066455

Epoch: 5| Step: 10
Training loss: 0.5321168899536133
Validation loss: 2.0363782221271145

Epoch: 460| Step: 0
Training loss: 0.8840819597244263
Validation loss: 2.0537841935311594

Epoch: 5| Step: 1
Training loss: 0.5199075937271118
Validation loss: 2.074184952243682

Epoch: 5| Step: 2
Training loss: 1.2014659643173218
Validation loss: 2.052014611100638

Epoch: 5| Step: 3
Training loss: 1.2559340000152588
Validation loss: 2.0939232328886628

Epoch: 5| Step: 4
Training loss: 0.9555343389511108
Validation loss: 2.0534796125145367

Epoch: 5| Step: 5
Training loss: 0.49190908670425415
Validation loss: 2.0983270624632477

Epoch: 5| Step: 6
Training loss: 0.8999549746513367
Validation loss: 2.051406821896953

Epoch: 5| Step: 7
Training loss: 0.9592244029045105
Validation loss: 2.048425859020602

Epoch: 5| Step: 8
Training loss: 0.868928074836731
Validation loss: 2.0578203701203868

Epoch: 5| Step: 9
Training loss: 0.7537263631820679
Validation loss: 2.0517217971945323

Epoch: 5| Step: 10
Training loss: 0.7878251075744629
Validation loss: 2.0301557869039555

Epoch: 461| Step: 0
Training loss: 1.2549649477005005
Validation loss: 2.0636688560567875

Epoch: 5| Step: 1
Training loss: 1.1533913612365723
Validation loss: 2.01632785284391

Epoch: 5| Step: 2
Training loss: 0.7349742650985718
Validation loss: 2.022331671048236

Epoch: 5| Step: 3
Training loss: 0.38177016377449036
Validation loss: 2.0098815938477874

Epoch: 5| Step: 4
Training loss: 0.7136552929878235
Validation loss: 1.9390814970898371

Epoch: 5| Step: 5
Training loss: 0.949002742767334
Validation loss: 1.9920948525910736

Epoch: 5| Step: 6
Training loss: 1.0679435729980469
Validation loss: 1.9442220516102289

Epoch: 5| Step: 7
Training loss: 0.8660375475883484
Validation loss: 1.9517702851244199

Epoch: 5| Step: 8
Training loss: 1.0335099697113037
Validation loss: 2.0014120737711587

Epoch: 5| Step: 9
Training loss: 0.49122732877731323
Validation loss: 1.9781320325789913

Epoch: 5| Step: 10
Training loss: 0.9072227478027344
Validation loss: 2.043620886341218

Epoch: 462| Step: 0
Training loss: 0.7398850321769714
Validation loss: 2.03160426949942

Epoch: 5| Step: 1
Training loss: 1.3418315649032593
Validation loss: 2.039366137596869

Epoch: 5| Step: 2
Training loss: 0.5301989316940308
Validation loss: 2.0575328180866856

Epoch: 5| Step: 3
Training loss: 0.9201709628105164
Validation loss: 2.0712132556464082

Epoch: 5| Step: 4
Training loss: 0.580100417137146
Validation loss: 2.0608047926297752

Epoch: 5| Step: 5
Training loss: 1.076331377029419
Validation loss: 2.0886363701153825

Epoch: 5| Step: 6
Training loss: 0.7857989072799683
Validation loss: 2.1156709706911476

Epoch: 5| Step: 7
Training loss: 1.0508095026016235
Validation loss: 2.0481230776797057

Epoch: 5| Step: 8
Training loss: 1.0463998317718506
Validation loss: 2.057057979286358

Epoch: 5| Step: 9
Training loss: 0.5373789668083191
Validation loss: 2.0471659245029574

Epoch: 5| Step: 10
Training loss: 0.8061245083808899
Validation loss: 2.004100037518368

Epoch: 463| Step: 0
Training loss: 1.3810760974884033
Validation loss: 1.972527680858489

Epoch: 5| Step: 1
Training loss: 0.8516013026237488
Validation loss: 2.00040086366797

Epoch: 5| Step: 2
Training loss: 0.5604861974716187
Validation loss: 2.019095392637355

Epoch: 5| Step: 3
Training loss: 0.9185112118721008
Validation loss: 1.9995779645058416

Epoch: 5| Step: 4
Training loss: 0.9257420301437378
Validation loss: 2.020241229764877

Epoch: 5| Step: 5
Training loss: 0.6904352307319641
Validation loss: 1.9924027586496005

Epoch: 5| Step: 6
Training loss: 1.105807900428772
Validation loss: 1.9824600476090626

Epoch: 5| Step: 7
Training loss: 0.6757417917251587
Validation loss: 2.074694759102278

Epoch: 5| Step: 8
Training loss: 0.7965191602706909
Validation loss: 2.05249479380987

Epoch: 5| Step: 9
Training loss: 0.7955313920974731
Validation loss: 2.0393283777339484

Epoch: 5| Step: 10
Training loss: 0.8066306114196777
Validation loss: 2.0513218090098393

Epoch: 464| Step: 0
Training loss: 1.1033178567886353
Validation loss: 2.042668705345482

Epoch: 5| Step: 1
Training loss: 1.003907322883606
Validation loss: 2.0477509626778225

Epoch: 5| Step: 2
Training loss: 0.9826555252075195
Validation loss: 2.0751594561402515

Epoch: 5| Step: 3
Training loss: 0.8648870587348938
Validation loss: 2.0804139773050943

Epoch: 5| Step: 4
Training loss: 0.4747592806816101
Validation loss: 2.063118443694166

Epoch: 5| Step: 5
Training loss: 1.2117764949798584
Validation loss: 2.0207788354607037

Epoch: 5| Step: 6
Training loss: 0.5684657692909241
Validation loss: 2.0412640289593766

Epoch: 5| Step: 7
Training loss: 0.7926138043403625
Validation loss: 2.0334295303590837

Epoch: 5| Step: 8
Training loss: 0.7505479454994202
Validation loss: 2.047665173007596

Epoch: 5| Step: 9
Training loss: 0.662362813949585
Validation loss: 2.028669370118008

Epoch: 5| Step: 10
Training loss: 0.9585450291633606
Validation loss: 2.037137505828693

Epoch: 465| Step: 0
Training loss: 1.1767171621322632
Validation loss: 2.028358482545422

Epoch: 5| Step: 1
Training loss: 0.8538735508918762
Validation loss: 2.0390739107644684

Epoch: 5| Step: 2
Training loss: 1.0506776571273804
Validation loss: 2.000351636640487

Epoch: 5| Step: 3
Training loss: 1.0277544260025024
Validation loss: 1.9698009080784296

Epoch: 5| Step: 4
Training loss: 0.9956666231155396
Validation loss: 1.990002123258447

Epoch: 5| Step: 5
Training loss: 0.6023529171943665
Validation loss: 1.9926717178795927

Epoch: 5| Step: 6
Training loss: 0.5367532968521118
Validation loss: 1.996809527438174

Epoch: 5| Step: 7
Training loss: 1.1654375791549683
Validation loss: 2.030122612112312

Epoch: 5| Step: 8
Training loss: 0.6745725870132446
Validation loss: 2.024632482118504

Epoch: 5| Step: 9
Training loss: 0.591448962688446
Validation loss: 2.0389193898888043

Epoch: 5| Step: 10
Training loss: 0.5752381682395935
Validation loss: 2.0503421662956156

Epoch: 466| Step: 0
Training loss: 0.9990224838256836
Validation loss: 2.0502181155707246

Epoch: 5| Step: 1
Training loss: 0.7482751607894897
Validation loss: 2.038331495818271

Epoch: 5| Step: 2
Training loss: 0.913748562335968
Validation loss: 2.003592041230971

Epoch: 5| Step: 3
Training loss: 1.0024055242538452
Validation loss: 2.003685120613344

Epoch: 5| Step: 4
Training loss: 0.6269720196723938
Validation loss: 1.9947884621158722

Epoch: 5| Step: 5
Training loss: 0.7155663967132568
Validation loss: 2.014037057917605

Epoch: 5| Step: 6
Training loss: 0.6710067987442017
Validation loss: 2.0021916768884145

Epoch: 5| Step: 7
Training loss: 1.0740476846694946
Validation loss: 2.004916907638632

Epoch: 5| Step: 8
Training loss: 0.5975282788276672
Validation loss: 2.018440128654562

Epoch: 5| Step: 9
Training loss: 1.1148922443389893
Validation loss: 2.020567963200231

Epoch: 5| Step: 10
Training loss: 0.8885273933410645
Validation loss: 2.0130063692728677

Epoch: 467| Step: 0
Training loss: 0.7949696779251099
Validation loss: 1.9849416722533524

Epoch: 5| Step: 1
Training loss: 0.8295562863349915
Validation loss: 1.9804227108596473

Epoch: 5| Step: 2
Training loss: 0.8510609865188599
Validation loss: 2.030006580455329

Epoch: 5| Step: 3
Training loss: 0.8737279176712036
Validation loss: 1.9887416619126514

Epoch: 5| Step: 4
Training loss: 0.8499528169631958
Validation loss: 2.025087018166819

Epoch: 5| Step: 5
Training loss: 0.4065040051937103
Validation loss: 1.9993060160708684

Epoch: 5| Step: 6
Training loss: 0.8128200769424438
Validation loss: 2.047415429545987

Epoch: 5| Step: 7
Training loss: 0.905758261680603
Validation loss: 2.047594396016931

Epoch: 5| Step: 8
Training loss: 0.8503321409225464
Validation loss: 2.030669968615296

Epoch: 5| Step: 9
Training loss: 1.1652929782867432
Validation loss: 2.0419000143645913

Epoch: 5| Step: 10
Training loss: 1.1513937711715698
Validation loss: 2.005013104408018

Epoch: 468| Step: 0
Training loss: 0.8884906768798828
Validation loss: 2.0338140943998932

Epoch: 5| Step: 1
Training loss: 0.6241899132728577
Validation loss: 1.988902356034966

Epoch: 5| Step: 2
Training loss: 0.8153505325317383
Validation loss: 1.9954585670143046

Epoch: 5| Step: 3
Training loss: 0.9255495071411133
Validation loss: 1.994052835690078

Epoch: 5| Step: 4
Training loss: 0.6651760339736938
Validation loss: 2.0030238025931904

Epoch: 5| Step: 5
Training loss: 1.1158287525177002
Validation loss: 2.0059925074218423

Epoch: 5| Step: 6
Training loss: 0.9808434247970581
Validation loss: 2.0412891346921205

Epoch: 5| Step: 7
Training loss: 1.1668379306793213
Validation loss: 2.028640003614528

Epoch: 5| Step: 8
Training loss: 1.0367028713226318
Validation loss: 2.0190312682941394

Epoch: 5| Step: 9
Training loss: 0.588169515132904
Validation loss: 2.029574554453614

Epoch: 5| Step: 10
Training loss: 0.5914121270179749
Validation loss: 1.9965975207667197

Epoch: 469| Step: 0
Training loss: 0.4669691026210785
Validation loss: 1.987455544933196

Epoch: 5| Step: 1
Training loss: 1.284234881401062
Validation loss: 1.9651176250109108

Epoch: 5| Step: 2
Training loss: 0.43299269676208496
Validation loss: 1.9734668488143592

Epoch: 5| Step: 3
Training loss: 0.8041170239448547
Validation loss: 1.9918965742152224

Epoch: 5| Step: 4
Training loss: 1.221900463104248
Validation loss: 2.0165966108281124

Epoch: 5| Step: 5
Training loss: 0.7517945170402527
Validation loss: 2.046710597571506

Epoch: 5| Step: 6
Training loss: 1.1505992412567139
Validation loss: 2.031477712815808

Epoch: 5| Step: 7
Training loss: 0.9370375871658325
Validation loss: 2.0432187382892897

Epoch: 5| Step: 8
Training loss: 0.8520170450210571
Validation loss: 2.0772950444170224

Epoch: 5| Step: 9
Training loss: 1.0838702917099
Validation loss: 2.0896513077520553

Epoch: 5| Step: 10
Training loss: 0.6763038635253906
Validation loss: 2.110504214481641

Epoch: 470| Step: 0
Training loss: 0.5049529671669006
Validation loss: 2.0805610520865327

Epoch: 5| Step: 1
Training loss: 1.108609914779663
Validation loss: 2.0724991700982534

Epoch: 5| Step: 2
Training loss: 0.8858412504196167
Validation loss: 2.0784084130358953

Epoch: 5| Step: 3
Training loss: 0.6065119504928589
Validation loss: 2.0406819466621644

Epoch: 5| Step: 4
Training loss: 0.8758224248886108
Validation loss: 2.091269880212763

Epoch: 5| Step: 5
Training loss: 1.2481647729873657
Validation loss: 2.0763267547853532

Epoch: 5| Step: 6
Training loss: 0.8888971209526062
Validation loss: 2.044672537875432

Epoch: 5| Step: 7
Training loss: 1.026458978652954
Validation loss: 2.0985097205767067

Epoch: 5| Step: 8
Training loss: 0.7374632954597473
Validation loss: 2.0409235864557247

Epoch: 5| Step: 9
Training loss: 0.8209554553031921
Validation loss: 2.08040117192012

Epoch: 5| Step: 10
Training loss: 0.6892157793045044
Validation loss: 2.0813915447522233

Epoch: 471| Step: 0
Training loss: 0.8153308033943176
Validation loss: 2.055235424349385

Epoch: 5| Step: 1
Training loss: 0.9648551940917969
Validation loss: 2.0448290122452604

Epoch: 5| Step: 2
Training loss: 0.8280923962593079
Validation loss: 2.0010419353362052

Epoch: 5| Step: 3
Training loss: 0.9613596796989441
Validation loss: 1.9800934612110097

Epoch: 5| Step: 4
Training loss: 0.8235538601875305
Validation loss: 1.9961196581522624

Epoch: 5| Step: 5
Training loss: 0.5153121948242188
Validation loss: 1.9901213876662716

Epoch: 5| Step: 6
Training loss: 0.7635637521743774
Validation loss: 1.993219021827944

Epoch: 5| Step: 7
Training loss: 0.9365513920783997
Validation loss: 2.022550972559119

Epoch: 5| Step: 8
Training loss: 0.9431620836257935
Validation loss: 2.0111001512055755

Epoch: 5| Step: 9
Training loss: 0.5425001382827759
Validation loss: 1.9877406371537076

Epoch: 5| Step: 10
Training loss: 1.3720136880874634
Validation loss: 2.0224570382025933

Epoch: 472| Step: 0
Training loss: 0.9590727090835571
Validation loss: 1.9950228403973322

Epoch: 5| Step: 1
Training loss: 0.799464225769043
Validation loss: 2.026883339369169

Epoch: 5| Step: 2
Training loss: 1.0598337650299072
Validation loss: 2.0134949389324395

Epoch: 5| Step: 3
Training loss: 0.8282095193862915
Validation loss: 2.0085786645130446

Epoch: 5| Step: 4
Training loss: 0.6859214305877686
Validation loss: 2.0446714880645915

Epoch: 5| Step: 5
Training loss: 0.8130342364311218
Validation loss: 2.0322769508566907

Epoch: 5| Step: 6
Training loss: 0.48591381311416626
Validation loss: 2.080319668657036

Epoch: 5| Step: 7
Training loss: 0.7560571432113647
Validation loss: 2.086834748586019

Epoch: 5| Step: 8
Training loss: 0.7897461652755737
Validation loss: 2.088777413932226

Epoch: 5| Step: 9
Training loss: 0.8668688535690308
Validation loss: 2.0438658857858307

Epoch: 5| Step: 10
Training loss: 1.2024993896484375
Validation loss: 2.074724333260649

Epoch: 473| Step: 0
Training loss: 1.1652733087539673
Validation loss: 2.036691450303601

Epoch: 5| Step: 1
Training loss: 0.8738656044006348
Validation loss: 2.058918863214472

Epoch: 5| Step: 2
Training loss: 0.6351799964904785
Validation loss: 2.0147728740528064

Epoch: 5| Step: 3
Training loss: 0.9292623400688171
Validation loss: 1.9939091282506143

Epoch: 5| Step: 4
Training loss: 0.8227888941764832
Validation loss: 1.9599007021996282

Epoch: 5| Step: 5
Training loss: 1.2199679613113403
Validation loss: 1.956823661763181

Epoch: 5| Step: 6
Training loss: 0.6090846657752991
Validation loss: 1.961516370055496

Epoch: 5| Step: 7
Training loss: 0.7608860731124878
Validation loss: 1.969382574481349

Epoch: 5| Step: 8
Training loss: 0.6549005508422852
Validation loss: 1.970734852616505

Epoch: 5| Step: 9
Training loss: 0.9008907079696655
Validation loss: 1.9561325657752253

Epoch: 5| Step: 10
Training loss: 0.6372181177139282
Validation loss: 2.019959799705013

Epoch: 474| Step: 0
Training loss: 0.7651798129081726
Validation loss: 2.0219083421973774

Epoch: 5| Step: 1
Training loss: 1.0054552555084229
Validation loss: 2.018347906809981

Epoch: 5| Step: 2
Training loss: 0.8615795969963074
Validation loss: 2.06034065446546

Epoch: 5| Step: 3
Training loss: 0.9563051462173462
Validation loss: 2.05754856909475

Epoch: 5| Step: 4
Training loss: 0.8506094217300415
Validation loss: 2.0293949598907144

Epoch: 5| Step: 5
Training loss: 0.963769793510437
Validation loss: 2.0463350152456634

Epoch: 5| Step: 6
Training loss: 0.35475197434425354
Validation loss: 2.005152681822418

Epoch: 5| Step: 7
Training loss: 1.1500523090362549
Validation loss: 2.0405005588326404

Epoch: 5| Step: 8
Training loss: 1.1510103940963745
Validation loss: 2.0065159105485484

Epoch: 5| Step: 9
Training loss: 0.5900484919548035
Validation loss: 1.9593008167000228

Epoch: 5| Step: 10
Training loss: 0.6432667970657349
Validation loss: 2.0096573214377127

Epoch: 475| Step: 0
Training loss: 0.4417344033718109
Validation loss: 1.9676907447076613

Epoch: 5| Step: 1
Training loss: 0.8769968152046204
Validation loss: 1.961812924313289

Epoch: 5| Step: 2
Training loss: 0.855129599571228
Validation loss: 1.9607367118199666

Epoch: 5| Step: 3
Training loss: 0.7265749573707581
Validation loss: 2.0311339516793527

Epoch: 5| Step: 4
Training loss: 1.0360186100006104
Validation loss: 2.0439471865213044

Epoch: 5| Step: 5
Training loss: 0.9816411733627319
Validation loss: 2.0681415360460997

Epoch: 5| Step: 6
Training loss: 1.1888362169265747
Validation loss: 2.0499735955269105

Epoch: 5| Step: 7
Training loss: 0.7511920928955078
Validation loss: 2.0751368332934637

Epoch: 5| Step: 8
Training loss: 0.7982825040817261
Validation loss: 2.069559633090932

Epoch: 5| Step: 9
Training loss: 0.8402857780456543
Validation loss: 2.046965209386682

Epoch: 5| Step: 10
Training loss: 0.6677767634391785
Validation loss: 2.0747554020215104

Epoch: 476| Step: 0
Training loss: 0.8182294964790344
Validation loss: 2.0337285290482225

Epoch: 5| Step: 1
Training loss: 0.7557868361473083
Validation loss: 2.0608243198804956

Epoch: 5| Step: 2
Training loss: 0.8891609311103821
Validation loss: 2.05682312544956

Epoch: 5| Step: 3
Training loss: 1.0551347732543945
Validation loss: 2.000075142870667

Epoch: 5| Step: 4
Training loss: 0.6039420366287231
Validation loss: 2.0450765061122116

Epoch: 5| Step: 5
Training loss: 0.5336722731590271
Validation loss: 2.021868992877263

Epoch: 5| Step: 6
Training loss: 1.4748196601867676
Validation loss: 2.009095440628708

Epoch: 5| Step: 7
Training loss: 0.33596616983413696
Validation loss: 2.0424351999836583

Epoch: 5| Step: 8
Training loss: 0.6641839146614075
Validation loss: 2.032429284946893

Epoch: 5| Step: 9
Training loss: 0.7527684569358826
Validation loss: 2.031572257318804

Epoch: 5| Step: 10
Training loss: 1.0969113111495972
Validation loss: 2.0404725792587444

Epoch: 477| Step: 0
Training loss: 1.2361646890640259
Validation loss: 2.0595710482648624

Epoch: 5| Step: 1
Training loss: 0.7803800702095032
Validation loss: 2.051935047231695

Epoch: 5| Step: 2
Training loss: 0.6211987733840942
Validation loss: 2.0568885072585075

Epoch: 5| Step: 3
Training loss: 0.8433283567428589
Validation loss: 2.0372973565132386

Epoch: 5| Step: 4
Training loss: 0.8864759206771851
Validation loss: 1.9878072841193086

Epoch: 5| Step: 5
Training loss: 0.9150861501693726
Validation loss: 2.004511064098727

Epoch: 5| Step: 6
Training loss: 0.8825240135192871
Validation loss: 2.020678222820323

Epoch: 5| Step: 7
Training loss: 0.4458613991737366
Validation loss: 2.00477825057122

Epoch: 5| Step: 8
Training loss: 0.7544134855270386
Validation loss: 2.0132697833481656

Epoch: 5| Step: 9
Training loss: 0.8706760406494141
Validation loss: 2.0205205127757084

Epoch: 5| Step: 10
Training loss: 0.7411888241767883
Validation loss: 2.060437661345287

Epoch: 478| Step: 0
Training loss: 0.745143711566925
Validation loss: 2.091391800552286

Epoch: 5| Step: 1
Training loss: 1.1909445524215698
Validation loss: 2.0449495507824804

Epoch: 5| Step: 2
Training loss: 0.8301388621330261
Validation loss: 2.061832683060759

Epoch: 5| Step: 3
Training loss: 0.4586712718009949
Validation loss: 2.01575300001329

Epoch: 5| Step: 4
Training loss: 0.38132044672966003
Validation loss: 1.97984782854716

Epoch: 5| Step: 5
Training loss: 0.9439088702201843
Validation loss: 1.9738339852261286

Epoch: 5| Step: 6
Training loss: 1.1759965419769287
Validation loss: 1.965406520392305

Epoch: 5| Step: 7
Training loss: 0.6993898749351501
Validation loss: 2.0015001835361605

Epoch: 5| Step: 8
Training loss: 0.9980173110961914
Validation loss: 1.9912704293445875

Epoch: 5| Step: 9
Training loss: 0.8389216661453247
Validation loss: 1.9936533666426135

Epoch: 5| Step: 10
Training loss: 0.6483364701271057
Validation loss: 1.9759135592368342

Epoch: 479| Step: 0
Training loss: 0.6450486779212952
Validation loss: 2.0115457632208384

Epoch: 5| Step: 1
Training loss: 0.8628300428390503
Validation loss: 2.005929449553131

Epoch: 5| Step: 2
Training loss: 0.720257580280304
Validation loss: 2.0387512394177016

Epoch: 5| Step: 3
Training loss: 0.7327113151550293
Validation loss: 2.01330219545672

Epoch: 5| Step: 4
Training loss: 0.4261259138584137
Validation loss: 1.9771627687638806

Epoch: 5| Step: 5
Training loss: 0.9088456034660339
Validation loss: 1.9672555885007303

Epoch: 5| Step: 6
Training loss: 0.8263208270072937
Validation loss: 1.9851332531180432

Epoch: 5| Step: 7
Training loss: 1.2772489786148071
Validation loss: 1.9708414500759495

Epoch: 5| Step: 8
Training loss: 1.1162530183792114
Validation loss: 1.9817893582005655

Epoch: 5| Step: 9
Training loss: 0.7389627695083618
Validation loss: 1.9828023449067147

Epoch: 5| Step: 10
Training loss: 0.739957869052887
Validation loss: 1.9890551682441466

Epoch: 480| Step: 0
Training loss: 0.5259151458740234
Validation loss: 1.951668567554925

Epoch: 5| Step: 1
Training loss: 0.8790141344070435
Validation loss: 1.9493403268116776

Epoch: 5| Step: 2
Training loss: 1.0736606121063232
Validation loss: 1.9825294453610656

Epoch: 5| Step: 3
Training loss: 0.7890735864639282
Validation loss: 1.982841968536377

Epoch: 5| Step: 4
Training loss: 0.8704782724380493
Validation loss: 2.020632702817199

Epoch: 5| Step: 5
Training loss: 0.5012611150741577
Validation loss: 2.0203336490097867

Epoch: 5| Step: 6
Training loss: 1.1691172122955322
Validation loss: 2.01734411075551

Epoch: 5| Step: 7
Training loss: 0.7657617926597595
Validation loss: 2.001901048485951

Epoch: 5| Step: 8
Training loss: 0.6819384694099426
Validation loss: 2.0544689060539327

Epoch: 5| Step: 9
Training loss: 0.5786612629890442
Validation loss: 1.9960135977755311

Epoch: 5| Step: 10
Training loss: 0.9301039576530457
Validation loss: 2.0331410105510423

Epoch: 481| Step: 0
Training loss: 0.7767049074172974
Validation loss: 2.052788398599112

Epoch: 5| Step: 1
Training loss: 0.6583002805709839
Validation loss: 1.9696725581281929

Epoch: 5| Step: 2
Training loss: 0.6350513696670532
Validation loss: 2.0160088539123535

Epoch: 5| Step: 3
Training loss: 0.8242616653442383
Validation loss: 2.0151309108221405

Epoch: 5| Step: 4
Training loss: 0.4169907569885254
Validation loss: 1.9849436795839699

Epoch: 5| Step: 5
Training loss: 0.6832256317138672
Validation loss: 1.9834131630518104

Epoch: 5| Step: 6
Training loss: 0.9079688787460327
Validation loss: 1.9928346039146505

Epoch: 5| Step: 7
Training loss: 0.7009394764900208
Validation loss: 2.0226621781626055

Epoch: 5| Step: 8
Training loss: 0.8972517251968384
Validation loss: 1.9915754795074463

Epoch: 5| Step: 9
Training loss: 1.0803031921386719
Validation loss: 2.024330387833298

Epoch: 5| Step: 10
Training loss: 1.0892959833145142
Validation loss: 2.0699579818274385

Epoch: 482| Step: 0
Training loss: 0.856116771697998
Validation loss: 2.059090409227597

Epoch: 5| Step: 1
Training loss: 0.7666374444961548
Validation loss: 2.052979979463803

Epoch: 5| Step: 2
Training loss: 0.5872806906700134
Validation loss: 2.0533049721871652

Epoch: 5| Step: 3
Training loss: 0.7675904035568237
Validation loss: 2.044699038228681

Epoch: 5| Step: 4
Training loss: 0.6318210363388062
Validation loss: 2.0276114351005963

Epoch: 5| Step: 5
Training loss: 0.8106404542922974
Validation loss: 1.9964929421742756

Epoch: 5| Step: 6
Training loss: 0.8959676623344421
Validation loss: 2.0263557921173754

Epoch: 5| Step: 7
Training loss: 0.8053045272827148
Validation loss: 2.038795327627531

Epoch: 5| Step: 8
Training loss: 1.075659990310669
Validation loss: 2.0268049240112305

Epoch: 5| Step: 9
Training loss: 0.7001963257789612
Validation loss: 2.035434542163726

Epoch: 5| Step: 10
Training loss: 0.6450926661491394
Validation loss: 2.0353058589402067

Epoch: 483| Step: 0
Training loss: 0.9148353338241577
Validation loss: 2.0519677144224926

Epoch: 5| Step: 1
Training loss: 1.5154638290405273
Validation loss: 2.026651656755837

Epoch: 5| Step: 2
Training loss: 0.48280277848243713
Validation loss: 2.0459578614081106

Epoch: 5| Step: 3
Training loss: 0.9915153384208679
Validation loss: 2.0504361865341023

Epoch: 5| Step: 4
Training loss: 0.799010157585144
Validation loss: 2.027035109458431

Epoch: 5| Step: 5
Training loss: 0.5684851408004761
Validation loss: 2.0037340348766697

Epoch: 5| Step: 6
Training loss: 0.6898967623710632
Validation loss: 2.00468768612031

Epoch: 5| Step: 7
Training loss: 0.7077423334121704
Validation loss: 1.9744806866491995

Epoch: 5| Step: 8
Training loss: 0.4629926085472107
Validation loss: 2.0057629052028862

Epoch: 5| Step: 9
Training loss: 0.6367329359054565
Validation loss: 1.9820719867624261

Epoch: 5| Step: 10
Training loss: 0.8634458780288696
Validation loss: 1.9879125318219584

Epoch: 484| Step: 0
Training loss: 0.5146910548210144
Validation loss: 1.943517017108138

Epoch: 5| Step: 1
Training loss: 1.1735554933547974
Validation loss: 1.9339723305035663

Epoch: 5| Step: 2
Training loss: 0.701023280620575
Validation loss: 1.9720457625645462

Epoch: 5| Step: 3
Training loss: 0.7582627534866333
Validation loss: 1.9720444627987441

Epoch: 5| Step: 4
Training loss: 0.6961414217948914
Validation loss: 1.9970653877463391

Epoch: 5| Step: 5
Training loss: 0.7915025353431702
Validation loss: 1.990915572771462

Epoch: 5| Step: 6
Training loss: 0.6230311393737793
Validation loss: 2.0027228350280435

Epoch: 5| Step: 7
Training loss: 0.546749472618103
Validation loss: 1.9930155995071575

Epoch: 5| Step: 8
Training loss: 0.9257275462150574
Validation loss: 2.04447304689756

Epoch: 5| Step: 9
Training loss: 1.0614550113677979
Validation loss: 2.0254648731600855

Epoch: 5| Step: 10
Training loss: 0.9655324220657349
Validation loss: 2.046773754140382

Epoch: 485| Step: 0
Training loss: 1.156919002532959
Validation loss: 2.0093746557030627

Epoch: 5| Step: 1
Training loss: 1.11516273021698
Validation loss: 2.018063545227051

Epoch: 5| Step: 2
Training loss: 0.704403281211853
Validation loss: 2.0044442979238366

Epoch: 5| Step: 3
Training loss: 0.6049131751060486
Validation loss: 2.01242079529711

Epoch: 5| Step: 4
Training loss: 0.9785673022270203
Validation loss: 1.9917383347788165

Epoch: 5| Step: 5
Training loss: 0.8908035159111023
Validation loss: 2.033952151575396

Epoch: 5| Step: 6
Training loss: 0.33719420433044434
Validation loss: 2.0235232947975077

Epoch: 5| Step: 7
Training loss: 0.4161059856414795
Validation loss: 2.0203843757670414

Epoch: 5| Step: 8
Training loss: 0.973778247833252
Validation loss: 2.027478330878801

Epoch: 5| Step: 9
Training loss: 0.8047714233398438
Validation loss: 1.992548934874996

Epoch: 5| Step: 10
Training loss: 0.7850745916366577
Validation loss: 2.0253781067427767

Epoch: 486| Step: 0
Training loss: 0.7702606916427612
Validation loss: 1.993440201205592

Epoch: 5| Step: 1
Training loss: 0.45331716537475586
Validation loss: 2.0310285655401086

Epoch: 5| Step: 2
Training loss: 1.070212960243225
Validation loss: 2.0120668385618474

Epoch: 5| Step: 3
Training loss: 0.8989542722702026
Validation loss: 2.0582696648054224

Epoch: 5| Step: 4
Training loss: 0.6533195972442627
Validation loss: 2.0482980166712115

Epoch: 5| Step: 5
Training loss: 0.5783122777938843
Validation loss: 2.070364846978136

Epoch: 5| Step: 6
Training loss: 0.9041975140571594
Validation loss: 2.0851460746539536

Epoch: 5| Step: 7
Training loss: 0.8770081400871277
Validation loss: 2.057026570843112

Epoch: 5| Step: 8
Training loss: 1.072981595993042
Validation loss: 2.029365966396947

Epoch: 5| Step: 9
Training loss: 0.4623532295227051
Validation loss: 2.0023757309041996

Epoch: 5| Step: 10
Training loss: 1.033905267715454
Validation loss: 2.02501344168058

Epoch: 487| Step: 0
Training loss: 1.0005159378051758
Validation loss: 2.0105882536980415

Epoch: 5| Step: 1
Training loss: 0.9078914523124695
Validation loss: 1.9541026738382155

Epoch: 5| Step: 2
Training loss: 0.5176452398300171
Validation loss: 1.9532087964396323

Epoch: 5| Step: 3
Training loss: 0.9030317068099976
Validation loss: 1.9747328745421542

Epoch: 5| Step: 4
Training loss: 0.7062994241714478
Validation loss: 1.9657793352680821

Epoch: 5| Step: 5
Training loss: 0.7412242889404297
Validation loss: 1.9232850523405178

Epoch: 5| Step: 6
Training loss: 0.5676887631416321
Validation loss: 1.9574696235759284

Epoch: 5| Step: 7
Training loss: 0.5607260465621948
Validation loss: 1.991011675967965

Epoch: 5| Step: 8
Training loss: 1.2468583583831787
Validation loss: 1.9978742535396288

Epoch: 5| Step: 9
Training loss: 0.5997990369796753
Validation loss: 2.045360356248835

Epoch: 5| Step: 10
Training loss: 0.7160978317260742
Validation loss: 1.9591641669632287

Epoch: 488| Step: 0
Training loss: 0.9258359670639038
Validation loss: 1.9952858494174095

Epoch: 5| Step: 1
Training loss: 0.6275689601898193
Validation loss: 2.015600314704321

Epoch: 5| Step: 2
Training loss: 0.40891820192337036
Validation loss: 1.974600766294746

Epoch: 5| Step: 3
Training loss: 0.9424548149108887
Validation loss: 1.9701934322234123

Epoch: 5| Step: 4
Training loss: 0.7882423400878906
Validation loss: 1.9609118943573327

Epoch: 5| Step: 5
Training loss: 0.7377288341522217
Validation loss: 1.9392801664208854

Epoch: 5| Step: 6
Training loss: 0.9954490661621094
Validation loss: 1.9672981641625846

Epoch: 5| Step: 7
Training loss: 1.0859545469284058
Validation loss: 1.9747727891450286

Epoch: 5| Step: 8
Training loss: 0.5258480906486511
Validation loss: 1.9743911348363405

Epoch: 5| Step: 9
Training loss: 0.6492426991462708
Validation loss: 1.9480607432703818

Epoch: 5| Step: 10
Training loss: 0.6392572522163391
Validation loss: 1.942451721878462

Epoch: 489| Step: 0
Training loss: 0.8960293531417847
Validation loss: 1.9634874328490226

Epoch: 5| Step: 1
Training loss: 1.1713615655899048
Validation loss: 1.9845802091783094

Epoch: 5| Step: 2
Training loss: 0.8303322792053223
Validation loss: 1.9893860842591973

Epoch: 5| Step: 3
Training loss: 0.8235511779785156
Validation loss: 1.9760053849989367

Epoch: 5| Step: 4
Training loss: 0.7243773341178894
Validation loss: 2.019256332869171

Epoch: 5| Step: 5
Training loss: 0.7101517915725708
Validation loss: 2.022845361822395

Epoch: 5| Step: 6
Training loss: 0.8719803094863892
Validation loss: 2.0238664586056947

Epoch: 5| Step: 7
Training loss: 0.5726839303970337
Validation loss: 1.9871708064950921

Epoch: 5| Step: 8
Training loss: 0.8825138211250305
Validation loss: 1.9713661529684579

Epoch: 5| Step: 9
Training loss: 0.7626857757568359
Validation loss: 1.9635898746469969

Epoch: 5| Step: 10
Training loss: 0.41649216413497925
Validation loss: 1.9337359974461217

Epoch: 490| Step: 0
Training loss: 0.643656849861145
Validation loss: 1.9445327687007126

Epoch: 5| Step: 1
Training loss: 0.5984193682670593
Validation loss: 1.9610637605831187

Epoch: 5| Step: 2
Training loss: 0.6466943025588989
Validation loss: 1.9551225785286195

Epoch: 5| Step: 3
Training loss: 0.8188368082046509
Validation loss: 1.9509552486481205

Epoch: 5| Step: 4
Training loss: 1.1172511577606201
Validation loss: 1.9989275214492634

Epoch: 5| Step: 5
Training loss: 0.8845115900039673
Validation loss: 2.0153384516316075

Epoch: 5| Step: 6
Training loss: 0.9307880401611328
Validation loss: 2.0372514365821757

Epoch: 5| Step: 7
Training loss: 1.1222712993621826
Validation loss: 1.9974991544600456

Epoch: 5| Step: 8
Training loss: 0.4580391049385071
Validation loss: 2.041642622281146

Epoch: 5| Step: 9
Training loss: 0.6769983768463135
Validation loss: 2.0475983440235095

Epoch: 5| Step: 10
Training loss: 0.6122942566871643
Validation loss: 2.016684948757131

Epoch: 491| Step: 0
Training loss: 0.7428739666938782
Validation loss: 2.032390009972357

Epoch: 5| Step: 1
Training loss: 0.6614254713058472
Validation loss: 2.026191334570608

Epoch: 5| Step: 2
Training loss: 0.8637788891792297
Validation loss: 2.02901283643579

Epoch: 5| Step: 3
Training loss: 0.7607795000076294
Validation loss: 2.044024085485807

Epoch: 5| Step: 4
Training loss: 0.8591523170471191
Validation loss: 2.011497566776891

Epoch: 5| Step: 5
Training loss: 0.767776370048523
Validation loss: 1.9927793087497834

Epoch: 5| Step: 6
Training loss: 1.1064326763153076
Validation loss: 1.9935672360081826

Epoch: 5| Step: 7
Training loss: 0.2979115843772888
Validation loss: 1.9890694477224862

Epoch: 5| Step: 8
Training loss: 0.8786374926567078
Validation loss: 1.9774013142431937

Epoch: 5| Step: 9
Training loss: 0.54609614610672
Validation loss: 2.0452544689178467

Epoch: 5| Step: 10
Training loss: 0.9306198358535767
Validation loss: 2.0377288608140844

Epoch: 492| Step: 0
Training loss: 0.9063640832901001
Validation loss: 2.0093176031625397

Epoch: 5| Step: 1
Training loss: 0.5632602572441101
Validation loss: 2.0439074270186888

Epoch: 5| Step: 2
Training loss: 0.9663135409355164
Validation loss: 2.0378239718816613

Epoch: 5| Step: 3
Training loss: 0.48457208275794983
Validation loss: 2.0084513746282107

Epoch: 5| Step: 4
Training loss: 0.8995264172554016
Validation loss: 2.0330433512246735

Epoch: 5| Step: 5
Training loss: 0.2743287980556488
Validation loss: 1.991123866009456

Epoch: 5| Step: 6
Training loss: 1.0993099212646484
Validation loss: 1.9844640352392708

Epoch: 5| Step: 7
Training loss: 1.0013607740402222
Validation loss: 1.9840389015854045

Epoch: 5| Step: 8
Training loss: 0.8072916269302368
Validation loss: 1.9876413678610196

Epoch: 5| Step: 9
Training loss: 0.6058540344238281
Validation loss: 2.0015596343624975

Epoch: 5| Step: 10
Training loss: 0.6705576181411743
Validation loss: 1.9950974320852628

Epoch: 493| Step: 0
Training loss: 0.9420955777168274
Validation loss: 2.0217713553418397

Epoch: 5| Step: 1
Training loss: 1.061580777168274
Validation loss: 2.026581529648073

Epoch: 5| Step: 2
Training loss: 0.6314698457717896
Validation loss: 2.0290881151794107

Epoch: 5| Step: 3
Training loss: 0.5120075345039368
Validation loss: 2.0442984360520557

Epoch: 5| Step: 4
Training loss: 0.8948055505752563
Validation loss: 2.014931139125619

Epoch: 5| Step: 5
Training loss: 0.8129287958145142
Validation loss: 2.036457787277878

Epoch: 5| Step: 6
Training loss: 0.6373186707496643
Validation loss: 2.032192501970517

Epoch: 5| Step: 7
Training loss: 0.5622617602348328
Validation loss: 2.0243144317339827

Epoch: 5| Step: 8
Training loss: 0.8789478540420532
Validation loss: 1.9824882348378499

Epoch: 5| Step: 9
Training loss: 0.960303783416748
Validation loss: 1.9633348488038587

Epoch: 5| Step: 10
Training loss: 0.6544760465621948
Validation loss: 2.007033790311506

Epoch: 494| Step: 0
Training loss: 1.165247917175293
Validation loss: 1.9850440576512327

Epoch: 5| Step: 1
Training loss: 0.9945991635322571
Validation loss: 1.9839633280231106

Epoch: 5| Step: 2
Training loss: 0.8856760859489441
Validation loss: 1.9322252247923164

Epoch: 5| Step: 3
Training loss: 0.5358332991600037
Validation loss: 1.8837042418859338

Epoch: 5| Step: 4
Training loss: 0.5317322015762329
Validation loss: 1.9362924175877725

Epoch: 5| Step: 5
Training loss: 1.0772325992584229
Validation loss: 1.9377158803324546

Epoch: 5| Step: 6
Training loss: 0.260529100894928
Validation loss: 1.9675340216646913

Epoch: 5| Step: 7
Training loss: 0.8296627998352051
Validation loss: 1.9642060290100753

Epoch: 5| Step: 8
Training loss: 0.6493729948997498
Validation loss: 2.0446420997701664

Epoch: 5| Step: 9
Training loss: 0.8783998489379883
Validation loss: 2.0637689764781664

Epoch: 5| Step: 10
Training loss: 0.8865477442741394
Validation loss: 2.043056554691766

Epoch: 495| Step: 0
Training loss: 0.8814321756362915
Validation loss: 2.0204298598791963

Epoch: 5| Step: 1
Training loss: 0.46915403008461
Validation loss: 1.9870968057263283

Epoch: 5| Step: 2
Training loss: 0.9656360745429993
Validation loss: 1.987855037053426

Epoch: 5| Step: 3
Training loss: 0.8590156435966492
Validation loss: 1.9802469771395448

Epoch: 5| Step: 4
Training loss: 0.6147283315658569
Validation loss: 1.9501275631689257

Epoch: 5| Step: 5
Training loss: 1.02880859375
Validation loss: 1.9746276101758402

Epoch: 5| Step: 6
Training loss: 0.6057620644569397
Validation loss: 1.982756442921136

Epoch: 5| Step: 7
Training loss: 0.9336951971054077
Validation loss: 1.9697826062479327

Epoch: 5| Step: 8
Training loss: 0.5938496589660645
Validation loss: 2.0019270502110964

Epoch: 5| Step: 9
Training loss: 0.7119902968406677
Validation loss: 2.009704800062282

Epoch: 5| Step: 10
Training loss: 0.9741411805152893
Validation loss: 1.9901378257300264

Epoch: 496| Step: 0
Training loss: 0.5058141350746155
Validation loss: 2.0080901448444655

Epoch: 5| Step: 1
Training loss: 0.7020961046218872
Validation loss: 2.0694720796359483

Epoch: 5| Step: 2
Training loss: 1.1206954717636108
Validation loss: 2.04669984181722

Epoch: 5| Step: 3
Training loss: 0.8624094128608704
Validation loss: 2.0559546332205496

Epoch: 5| Step: 4
Training loss: 0.917552649974823
Validation loss: 2.0278094276305167

Epoch: 5| Step: 5
Training loss: 1.119367241859436
Validation loss: 2.0670048370156238

Epoch: 5| Step: 6
Training loss: 0.7563876509666443
Validation loss: 2.006526331747732

Epoch: 5| Step: 7
Training loss: 0.9510751962661743
Validation loss: 2.015489441092296

Epoch: 5| Step: 8
Training loss: 0.41386860609054565
Validation loss: 1.9769932044449674

Epoch: 5| Step: 9
Training loss: 0.46587425470352173
Validation loss: 1.9963464608756445

Epoch: 5| Step: 10
Training loss: 0.5600401163101196
Validation loss: 2.0111877020969184

Epoch: 497| Step: 0
Training loss: 0.9341959953308105
Validation loss: 2.0143320201545634

Epoch: 5| Step: 1
Training loss: 0.9994381666183472
Validation loss: 1.9960305895856632

Epoch: 5| Step: 2
Training loss: 0.6389135122299194
Validation loss: 1.9998895122158913

Epoch: 5| Step: 3
Training loss: 0.878819465637207
Validation loss: 2.0110727074325725

Epoch: 5| Step: 4
Training loss: 0.8616073727607727
Validation loss: 2.0580932068568405

Epoch: 5| Step: 5
Training loss: 0.7494646906852722
Validation loss: 2.021706606752129

Epoch: 5| Step: 6
Training loss: 0.7336477637290955
Validation loss: 2.04122446813891

Epoch: 5| Step: 7
Training loss: 0.34855377674102783
Validation loss: 2.027840919392083

Epoch: 5| Step: 8
Training loss: 0.788112461566925
Validation loss: 2.024723090151305

Epoch: 5| Step: 9
Training loss: 0.7220731973648071
Validation loss: 1.9864519757609214

Epoch: 5| Step: 10
Training loss: 0.5783894658088684
Validation loss: 1.9971115127686532

Epoch: 498| Step: 0
Training loss: 0.8568344116210938
Validation loss: 1.943803620594804

Epoch: 5| Step: 1
Training loss: 0.6132200956344604
Validation loss: 1.9387834149022256

Epoch: 5| Step: 2
Training loss: 0.7228931188583374
Validation loss: 1.9616167058226883

Epoch: 5| Step: 3
Training loss: 1.1484285593032837
Validation loss: 1.9695060278779717

Epoch: 5| Step: 4
Training loss: 0.5808719396591187
Validation loss: 1.9738827161891486

Epoch: 5| Step: 5
Training loss: 1.1046147346496582
Validation loss: 1.9645539791353288

Epoch: 5| Step: 6
Training loss: 0.8018583059310913
Validation loss: 2.0004716868041665

Epoch: 5| Step: 7
Training loss: 0.6769993901252747
Validation loss: 1.9516493735774871

Epoch: 5| Step: 8
Training loss: 0.2685855031013489
Validation loss: 2.0203423858970724

Epoch: 5| Step: 9
Training loss: 0.7075031995773315
Validation loss: 1.9809001338097356

Epoch: 5| Step: 10
Training loss: 0.6008136868476868
Validation loss: 1.976365573944584

Epoch: 499| Step: 0
Training loss: 0.6223605871200562
Validation loss: 1.9821145303787724

Epoch: 5| Step: 1
Training loss: 0.8412580490112305
Validation loss: 1.9503001077200777

Epoch: 5| Step: 2
Training loss: 0.7022393941879272
Validation loss: 1.966200751643027

Epoch: 5| Step: 3
Training loss: 0.7508653998374939
Validation loss: 1.9745822363002326

Epoch: 5| Step: 4
Training loss: 0.6159687042236328
Validation loss: 2.003827809005655

Epoch: 5| Step: 5
Training loss: 0.42914265394210815
Validation loss: 1.988642789984262

Epoch: 5| Step: 6
Training loss: 0.5924280285835266
Validation loss: 1.997863741331203

Epoch: 5| Step: 7
Training loss: 0.8759425282478333
Validation loss: 1.9756407673640917

Epoch: 5| Step: 8
Training loss: 0.9066709280014038
Validation loss: 2.0202793337965526

Epoch: 5| Step: 9
Training loss: 0.7938728332519531
Validation loss: 1.991396152844993

Epoch: 5| Step: 10
Training loss: 0.8637373447418213
Validation loss: 1.9908384482065837

Epoch: 500| Step: 0
Training loss: 1.2006828784942627
Validation loss: 2.0252008053564254

Epoch: 5| Step: 1
Training loss: 0.5419631600379944
Validation loss: 2.004788775597849

Epoch: 5| Step: 2
Training loss: 0.5055443048477173
Validation loss: 1.9874301148999123

Epoch: 5| Step: 3
Training loss: 0.14688202738761902
Validation loss: 1.97988570890119

Epoch: 5| Step: 4
Training loss: 1.0773290395736694
Validation loss: 1.9494985124116302

Epoch: 5| Step: 5
Training loss: 1.0099422931671143
Validation loss: 1.957203749687441

Epoch: 5| Step: 6
Training loss: 0.8102970123291016
Validation loss: 1.925333571690385

Epoch: 5| Step: 7
Training loss: 0.6778628826141357
Validation loss: 1.9117898402675506

Epoch: 5| Step: 8
Training loss: 0.5967419743537903
Validation loss: 1.9120345090025215

Epoch: 5| Step: 9
Training loss: 0.791975200176239
Validation loss: 1.9428322161397626

Epoch: 5| Step: 10
Training loss: 0.6548337340354919
Validation loss: 1.926704042701311

Testing loss: 2.0220503542158337
