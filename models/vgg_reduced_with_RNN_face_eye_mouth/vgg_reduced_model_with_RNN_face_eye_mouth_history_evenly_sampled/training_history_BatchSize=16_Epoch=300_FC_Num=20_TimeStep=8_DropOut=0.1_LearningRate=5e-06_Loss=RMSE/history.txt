Epoch: 1| Step: 0
Training loss: 5.760871561126739
Validation loss: 5.799637018216728

Epoch: 6| Step: 1
Training loss: 6.029241514059898
Validation loss: 5.796768267540377

Epoch: 6| Step: 2
Training loss: 6.288697339942385
Validation loss: 5.793974579974241

Epoch: 6| Step: 3
Training loss: 6.164250321421615
Validation loss: 5.7909636313884265

Epoch: 6| Step: 4
Training loss: 5.608729928416246
Validation loss: 5.787930566393944

Epoch: 6| Step: 5
Training loss: 5.937216340366456
Validation loss: 5.78515951506287

Epoch: 6| Step: 6
Training loss: 4.940708711266034
Validation loss: 5.782126810575545

Epoch: 6| Step: 7
Training loss: 4.535878100188596
Validation loss: 5.779328481617037

Epoch: 6| Step: 8
Training loss: 6.426858940308481
Validation loss: 5.776584346724747

Epoch: 6| Step: 9
Training loss: 6.262661125866655
Validation loss: 5.773382474226971

Epoch: 6| Step: 10
Training loss: 5.667818326419684
Validation loss: 5.769949893122132

Epoch: 6| Step: 11
Training loss: 5.968136421342092
Validation loss: 5.766797701226361

Epoch: 6| Step: 12
Training loss: 5.688192807434605
Validation loss: 5.763159116224911

Epoch: 6| Step: 13
Training loss: 5.874110053003342
Validation loss: 5.759480301605534

Epoch: 2| Step: 0
Training loss: 5.668525316187086
Validation loss: 5.755216806324119

Epoch: 6| Step: 1
Training loss: 4.953926671372118
Validation loss: 5.750987427805596

Epoch: 6| Step: 2
Training loss: 6.134034325442994
Validation loss: 5.746559840295475

Epoch: 6| Step: 3
Training loss: 5.526643548295123
Validation loss: 5.7413707396436555

Epoch: 6| Step: 4
Training loss: 5.4473050164966
Validation loss: 5.736593385077853

Epoch: 6| Step: 5
Training loss: 5.446112465898123
Validation loss: 5.730836458566941

Epoch: 6| Step: 6
Training loss: 5.5734590735845435
Validation loss: 5.724708688068835

Epoch: 6| Step: 7
Training loss: 6.656540555388163
Validation loss: 5.718851487664416

Epoch: 6| Step: 8
Training loss: 5.439707866846872
Validation loss: 5.712036958896314

Epoch: 6| Step: 9
Training loss: 6.592061337287491
Validation loss: 5.705297427015091

Epoch: 6| Step: 10
Training loss: 5.401959960721324
Validation loss: 5.697915139317797

Epoch: 6| Step: 11
Training loss: 4.466521447701044
Validation loss: 5.690605115578985

Epoch: 6| Step: 12
Training loss: 6.6720416653473364
Validation loss: 5.682358137649372

Epoch: 6| Step: 13
Training loss: 6.382544746525969
Validation loss: 5.673474369645537

Epoch: 3| Step: 0
Training loss: 7.001040245146442
Validation loss: 5.664815894838901

Epoch: 6| Step: 1
Training loss: 5.281362859659948
Validation loss: 5.655187765982204

Epoch: 6| Step: 2
Training loss: 6.1511823060454835
Validation loss: 5.6450389401116885

Epoch: 6| Step: 3
Training loss: 5.243891477438147
Validation loss: 5.635044659346612

Epoch: 6| Step: 4
Training loss: 6.4341564198773735
Validation loss: 5.6240985216357755

Epoch: 6| Step: 5
Training loss: 5.9946023185869315
Validation loss: 5.61258547341638

Epoch: 6| Step: 6
Training loss: 5.104246593031209
Validation loss: 5.600527780686145

Epoch: 6| Step: 7
Training loss: 5.6878112037111865
Validation loss: 5.5893745498613105

Epoch: 6| Step: 8
Training loss: 6.184541862129611
Validation loss: 5.576847488871592

Epoch: 6| Step: 9
Training loss: 4.929992569614096
Validation loss: 5.562475750326346

Epoch: 6| Step: 10
Training loss: 4.928703101000556
Validation loss: 5.549347410864362

Epoch: 6| Step: 11
Training loss: 5.271873683058705
Validation loss: 5.53483791930928

Epoch: 6| Step: 12
Training loss: 5.0855836525453135
Validation loss: 5.520605158797109

Epoch: 6| Step: 13
Training loss: 4.737193864176039
Validation loss: 5.505669070777031

Epoch: 4| Step: 0
Training loss: 5.411134839294197
Validation loss: 5.49159063580732

Epoch: 6| Step: 1
Training loss: 4.820935275561408
Validation loss: 5.475977535638843

Epoch: 6| Step: 2
Training loss: 4.921223527693239
Validation loss: 5.4606194116343065

Epoch: 6| Step: 3
Training loss: 5.7845390242985495
Validation loss: 5.444848561826047

Epoch: 6| Step: 4
Training loss: 5.100997356055897
Validation loss: 5.42801073892649

Epoch: 6| Step: 5
Training loss: 6.2686446754377885
Validation loss: 5.410432298801887

Epoch: 6| Step: 6
Training loss: 5.004001160911956
Validation loss: 5.393075819055614

Epoch: 6| Step: 7
Training loss: 4.370895640338541
Validation loss: 5.376557134385833

Epoch: 6| Step: 8
Training loss: 6.103472499847647
Validation loss: 5.356633190828396

Epoch: 6| Step: 9
Training loss: 5.6837789918266255
Validation loss: 5.338174333477778

Epoch: 6| Step: 10
Training loss: 5.286113237915217
Validation loss: 5.31932326708524

Epoch: 6| Step: 11
Training loss: 5.204661832555479
Validation loss: 5.300330483489401

Epoch: 6| Step: 12
Training loss: 6.446136015098229
Validation loss: 5.281683465020883

Epoch: 6| Step: 13
Training loss: 4.923104268924252
Validation loss: 5.262671093089444

Epoch: 5| Step: 0
Training loss: 5.457117231561359
Validation loss: 5.2427796375597175

Epoch: 6| Step: 1
Training loss: 6.15761152209056
Validation loss: 5.224386210344148

Epoch: 6| Step: 2
Training loss: 5.39832761793471
Validation loss: 5.203883133493974

Epoch: 6| Step: 3
Training loss: 5.027194455885911
Validation loss: 5.183463411835954

Epoch: 6| Step: 4
Training loss: 4.147496003464607
Validation loss: 5.165658385343213

Epoch: 6| Step: 5
Training loss: 5.260392574846853
Validation loss: 5.147453944019778

Epoch: 6| Step: 6
Training loss: 4.57493902280434
Validation loss: 5.1296640718213

Epoch: 6| Step: 7
Training loss: 4.888714206830804
Validation loss: 5.1114873338945515

Epoch: 6| Step: 8
Training loss: 5.107183050403338
Validation loss: 5.09615948936895

Epoch: 6| Step: 9
Training loss: 4.790941775126407
Validation loss: 5.078523983612067

Epoch: 6| Step: 10
Training loss: 5.318714590884906
Validation loss: 5.062800011758495

Epoch: 6| Step: 11
Training loss: 5.74177693047509
Validation loss: 5.046476312259106

Epoch: 6| Step: 12
Training loss: 4.798440783296765
Validation loss: 5.031252111547739

Epoch: 6| Step: 13
Training loss: 5.970705041707249
Validation loss: 5.014120763747975

Epoch: 6| Step: 0
Training loss: 3.2696902146428863
Validation loss: 5.00007937993852

Epoch: 6| Step: 1
Training loss: 4.629460014344445
Validation loss: 4.9841711914495805

Epoch: 6| Step: 2
Training loss: 5.29124867548071
Validation loss: 4.969054357445604

Epoch: 6| Step: 3
Training loss: 5.591803867496938
Validation loss: 4.9534925637117055

Epoch: 6| Step: 4
Training loss: 5.099604325746735
Validation loss: 4.935411020945421

Epoch: 6| Step: 5
Training loss: 4.786639000184871
Validation loss: 4.919306521730664

Epoch: 6| Step: 6
Training loss: 3.819529572125833
Validation loss: 4.899208788584523

Epoch: 6| Step: 7
Training loss: 4.798506965494621
Validation loss: 4.882095770229621

Epoch: 6| Step: 8
Training loss: 6.073878670644722
Validation loss: 4.863759255897757

Epoch: 6| Step: 9
Training loss: 5.466592068667173
Validation loss: 4.845318770769732

Epoch: 6| Step: 10
Training loss: 5.084551597487213
Validation loss: 4.826835142767482

Epoch: 6| Step: 11
Training loss: 5.5658031471524
Validation loss: 4.808382407601762

Epoch: 6| Step: 12
Training loss: 4.631974194285136
Validation loss: 4.790362100875634

Epoch: 6| Step: 13
Training loss: 4.455445444633726
Validation loss: 4.772314614504996

Epoch: 7| Step: 0
Training loss: 3.9761792431039895
Validation loss: 4.755427674288397

Epoch: 6| Step: 1
Training loss: 5.263773335061113
Validation loss: 4.741061898070189

Epoch: 6| Step: 2
Training loss: 5.922349734640342
Validation loss: 4.7248184483478415

Epoch: 6| Step: 3
Training loss: 3.42737976152689
Validation loss: 4.706657912339065

Epoch: 6| Step: 4
Training loss: 5.3411541260931275
Validation loss: 4.688006599423864

Epoch: 6| Step: 5
Training loss: 4.4844536857480355
Validation loss: 4.672945239186493

Epoch: 6| Step: 6
Training loss: 4.082938557958766
Validation loss: 4.656656759944791

Epoch: 6| Step: 7
Training loss: 4.760271711528463
Validation loss: 4.6402862525735005

Epoch: 6| Step: 8
Training loss: 4.182673163332245
Validation loss: 4.6266880784959685

Epoch: 6| Step: 9
Training loss: 4.922655025615821
Validation loss: 4.611666311181477

Epoch: 6| Step: 10
Training loss: 4.578375799710953
Validation loss: 4.5973479887356605

Epoch: 6| Step: 11
Training loss: 4.697947748029228
Validation loss: 4.579412338479091

Epoch: 6| Step: 12
Training loss: 5.8224444894531775
Validation loss: 4.565510294888491

Epoch: 6| Step: 13
Training loss: 3.8066521493219603
Validation loss: 4.548135458484892

Epoch: 8| Step: 0
Training loss: 4.050512615776122
Validation loss: 4.534080585900531

Epoch: 6| Step: 1
Training loss: 4.0222972254027205
Validation loss: 4.5172343045690075

Epoch: 6| Step: 2
Training loss: 4.58754201760656
Validation loss: 4.5024614176668285

Epoch: 6| Step: 3
Training loss: 4.027370745090177
Validation loss: 4.4864159444105125

Epoch: 6| Step: 4
Training loss: 4.0847420630386955
Validation loss: 4.4730747807859075

Epoch: 6| Step: 5
Training loss: 3.607451483703612
Validation loss: 4.460011094194164

Epoch: 6| Step: 6
Training loss: 4.638073357768923
Validation loss: 4.447378317872901

Epoch: 6| Step: 7
Training loss: 5.2296733636041015
Validation loss: 4.43460511997536

Epoch: 6| Step: 8
Training loss: 5.16202106609576
Validation loss: 4.421364976043275

Epoch: 6| Step: 9
Training loss: 5.180790434220962
Validation loss: 4.409585768046382

Epoch: 6| Step: 10
Training loss: 4.613862106875298
Validation loss: 4.398397604725818

Epoch: 6| Step: 11
Training loss: 5.167989787017841
Validation loss: 4.385517252005602

Epoch: 6| Step: 12
Training loss: 4.987706903358355
Validation loss: 4.371844530493816

Epoch: 6| Step: 13
Training loss: 3.1949064187924674
Validation loss: 4.363607176995079

Epoch: 9| Step: 0
Training loss: 4.995549891907214
Validation loss: 4.352322141764837

Epoch: 6| Step: 1
Training loss: 5.911281158436133
Validation loss: 4.342540974923695

Epoch: 6| Step: 2
Training loss: 4.524433349199395
Validation loss: 4.329626505056376

Epoch: 6| Step: 3
Training loss: 4.7962323979185735
Validation loss: 4.319900884429374

Epoch: 6| Step: 4
Training loss: 4.402106535104657
Validation loss: 4.311379780442834

Epoch: 6| Step: 5
Training loss: 4.119226287486466
Validation loss: 4.300649004830205

Epoch: 6| Step: 6
Training loss: 4.074129098141736
Validation loss: 4.291645358628396

Epoch: 6| Step: 7
Training loss: 3.2050101338671175
Validation loss: 4.282205090547451

Epoch: 6| Step: 8
Training loss: 3.865537349166702
Validation loss: 4.2738407442151045

Epoch: 6| Step: 9
Training loss: 4.069803099872095
Validation loss: 4.2654353874969635

Epoch: 6| Step: 10
Training loss: 4.475363579157499
Validation loss: 4.25530016181199

Epoch: 6| Step: 11
Training loss: 3.9629404394817596
Validation loss: 4.248860307116142

Epoch: 6| Step: 12
Training loss: 4.0750215494721145
Validation loss: 4.238231578384804

Epoch: 6| Step: 13
Training loss: 4.974607266207347
Validation loss: 4.229971928990749

Epoch: 10| Step: 0
Training loss: 4.244337011534365
Validation loss: 4.22021665977177

Epoch: 6| Step: 1
Training loss: 3.7269432785020857
Validation loss: 4.210996552472464

Epoch: 6| Step: 2
Training loss: 4.523980142726879
Validation loss: 4.203916971024176

Epoch: 6| Step: 3
Training loss: 3.6741070395603574
Validation loss: 4.196731577613327

Epoch: 6| Step: 4
Training loss: 4.24786435491516
Validation loss: 4.189304186596896

Epoch: 6| Step: 5
Training loss: 4.575944088107431
Validation loss: 4.179315309434318

Epoch: 6| Step: 6
Training loss: 3.940193466045255
Validation loss: 4.172268639874477

Epoch: 6| Step: 7
Training loss: 4.6500423962701
Validation loss: 4.162578295244465

Epoch: 6| Step: 8
Training loss: 5.015038762042626
Validation loss: 4.157902182802421

Epoch: 6| Step: 9
Training loss: 4.018195965725132
Validation loss: 4.1496225570144665

Epoch: 6| Step: 10
Training loss: 4.539381846554454
Validation loss: 4.138777088513415

Epoch: 6| Step: 11
Training loss: 4.869485328001219
Validation loss: 4.131655558274873

Epoch: 6| Step: 12
Training loss: 3.6592918849142144
Validation loss: 4.124833476215835

Epoch: 6| Step: 13
Training loss: 4.152554123610157
Validation loss: 4.118564797901338

Epoch: 11| Step: 0
Training loss: 4.604376510510094
Validation loss: 4.110471891854001

Epoch: 6| Step: 1
Training loss: 2.964378591845349
Validation loss: 4.105601019120093

Epoch: 6| Step: 2
Training loss: 4.055389049601521
Validation loss: 4.096109765496354

Epoch: 6| Step: 3
Training loss: 3.9132221713245463
Validation loss: 4.0918020075448345

Epoch: 6| Step: 4
Training loss: 4.169574917869631
Validation loss: 4.087691915145604

Epoch: 6| Step: 5
Training loss: 3.3839690101412985
Validation loss: 4.078583692139552

Epoch: 6| Step: 6
Training loss: 4.804266884853851
Validation loss: 4.0760116095561685

Epoch: 6| Step: 7
Training loss: 4.421537244857948
Validation loss: 4.0690961159490024

Epoch: 6| Step: 8
Training loss: 4.171268490483698
Validation loss: 4.065615876572467

Epoch: 6| Step: 9
Training loss: 4.385409369504147
Validation loss: 4.0561050932947635

Epoch: 6| Step: 10
Training loss: 3.715252040563944
Validation loss: 4.048482575839256

Epoch: 6| Step: 11
Training loss: 4.9425193286878635
Validation loss: 4.043753490011268

Epoch: 6| Step: 12
Training loss: 4.605985785558038
Validation loss: 4.03653651685414

Epoch: 6| Step: 13
Training loss: 4.4905325586072875
Validation loss: 4.032524798277158

Epoch: 12| Step: 0
Training loss: 3.6707743841685194
Validation loss: 4.027119598718533

Epoch: 6| Step: 1
Training loss: 4.836517841477752
Validation loss: 4.020816124334058

Epoch: 6| Step: 2
Training loss: 3.7168983529811577
Validation loss: 4.017150829063875

Epoch: 6| Step: 3
Training loss: 4.023226538006908
Validation loss: 4.009214378548079

Epoch: 6| Step: 4
Training loss: 3.714148230680592
Validation loss: 4.002724596358905

Epoch: 6| Step: 5
Training loss: 4.046234197953992
Validation loss: 3.995601994723757

Epoch: 6| Step: 6
Training loss: 4.493756519466759
Validation loss: 3.9890960615984246

Epoch: 6| Step: 7
Training loss: 5.008872171487096
Validation loss: 3.9865460632947047

Epoch: 6| Step: 8
Training loss: 3.8960765959869006
Validation loss: 3.98087258804037

Epoch: 6| Step: 9
Training loss: 3.116379253034309
Validation loss: 3.9733585403968608

Epoch: 6| Step: 10
Training loss: 4.455045158936558
Validation loss: 3.970260819599923

Epoch: 6| Step: 11
Training loss: 4.902167304157835
Validation loss: 3.963913084665434

Epoch: 6| Step: 12
Training loss: 3.1338039741387202
Validation loss: 3.9608343714951846

Epoch: 6| Step: 13
Training loss: 4.510332536977313
Validation loss: 3.9556691079315254

Epoch: 13| Step: 0
Training loss: 3.8999868001469955
Validation loss: 3.953884795093576

Epoch: 6| Step: 1
Training loss: 4.098319960845522
Validation loss: 3.9533919124693284

Epoch: 6| Step: 2
Training loss: 3.445846965967324
Validation loss: 3.946762046424985

Epoch: 6| Step: 3
Training loss: 3.826236181025458
Validation loss: 3.939309541181266

Epoch: 6| Step: 4
Training loss: 4.486203767799209
Validation loss: 3.9349801444524624

Epoch: 6| Step: 5
Training loss: 4.065260668065014
Validation loss: 3.9281341817075677

Epoch: 6| Step: 6
Training loss: 4.272551896353191
Validation loss: 3.921128918515675

Epoch: 6| Step: 7
Training loss: 4.183874582077562
Validation loss: 3.9207116662417305

Epoch: 6| Step: 8
Training loss: 3.6165262033870507
Validation loss: 3.9142597860976953

Epoch: 6| Step: 9
Training loss: 4.362850649494539
Validation loss: 3.9148995273242924

Epoch: 6| Step: 10
Training loss: 3.6988969963027913
Validation loss: 3.9112337867601266

Epoch: 6| Step: 11
Training loss: 4.145706455966579
Validation loss: 3.9049050143229675

Epoch: 6| Step: 12
Training loss: 4.417950185775541
Validation loss: 3.9013899564126757

Epoch: 6| Step: 13
Training loss: 4.726883100245212
Validation loss: 3.897139110582416

Epoch: 14| Step: 0
Training loss: 4.285284883694878
Validation loss: 3.892041103451161

Epoch: 6| Step: 1
Training loss: 3.7750828159166003
Validation loss: 3.891987933795419

Epoch: 6| Step: 2
Training loss: 4.056179587953601
Validation loss: 3.8854048846238083

Epoch: 6| Step: 3
Training loss: 3.6002768251161275
Validation loss: 3.8799594166968223

Epoch: 6| Step: 4
Training loss: 4.502410666825511
Validation loss: 3.876453213170209

Epoch: 6| Step: 5
Training loss: 3.4658243023980275
Validation loss: 3.875467500460892

Epoch: 6| Step: 6
Training loss: 4.178320088821396
Validation loss: 3.8749401552340585

Epoch: 6| Step: 7
Training loss: 4.85734648237631
Validation loss: 3.872347699069272

Epoch: 6| Step: 8
Training loss: 3.244632837481159
Validation loss: 3.866434923687781

Epoch: 6| Step: 9
Training loss: 4.601424676615432
Validation loss: 3.870150878003124

Epoch: 6| Step: 10
Training loss: 4.720266136489763
Validation loss: 3.871504114062342

Epoch: 6| Step: 11
Training loss: 3.280472145523963
Validation loss: 3.8645537598357365

Epoch: 6| Step: 12
Training loss: 3.9637369048480617
Validation loss: 3.857832907889432

Epoch: 6| Step: 13
Training loss: 3.0834945086719006
Validation loss: 3.8540905191913843

Epoch: 15| Step: 0
Training loss: 5.188671301546117
Validation loss: 3.8491386833012293

Epoch: 6| Step: 1
Training loss: 4.908739758143998
Validation loss: 3.85067879529061

Epoch: 6| Step: 2
Training loss: 3.8867013288711334
Validation loss: 3.8476266401230226

Epoch: 6| Step: 3
Training loss: 4.112502151998867
Validation loss: 3.841077452882264

Epoch: 6| Step: 4
Training loss: 3.3159950100225033
Validation loss: 3.8372837103099293

Epoch: 6| Step: 5
Training loss: 4.221079995321611
Validation loss: 3.8358623291012433

Epoch: 6| Step: 6
Training loss: 2.1287658085126875
Validation loss: 3.832106901457376

Epoch: 6| Step: 7
Training loss: 4.32700528971501
Validation loss: 3.8419189780718406

Epoch: 6| Step: 8
Training loss: 2.9032779386413323
Validation loss: 3.827137083413808

Epoch: 6| Step: 9
Training loss: 4.553099052653738
Validation loss: 3.824987133759702

Epoch: 6| Step: 10
Training loss: 3.1503219076704276
Validation loss: 3.8210035894705405

Epoch: 6| Step: 11
Training loss: 4.404791840951099
Validation loss: 3.816548531722635

Epoch: 6| Step: 12
Training loss: 3.9138629428450833
Validation loss: 3.8167952776530387

Epoch: 6| Step: 13
Training loss: 3.868265021127901
Validation loss: 3.8137085866806952

Epoch: 16| Step: 0
Training loss: 4.086306728507218
Validation loss: 3.8086138170006567

Epoch: 6| Step: 1
Training loss: 4.119865458615697
Validation loss: 3.8083126245178263

Epoch: 6| Step: 2
Training loss: 3.7618115375043937
Validation loss: 3.807793431235959

Epoch: 6| Step: 3
Training loss: 3.8121297687806273
Validation loss: 3.805843946589851

Epoch: 6| Step: 4
Training loss: 3.5742440978438617
Validation loss: 3.8057001706827474

Epoch: 6| Step: 5
Training loss: 4.626788644053052
Validation loss: 3.803040452957507

Epoch: 6| Step: 6
Training loss: 3.2716193418987687
Validation loss: 3.795655982287535

Epoch: 6| Step: 7
Training loss: 3.991662395902405
Validation loss: 3.791546950985263

Epoch: 6| Step: 8
Training loss: 4.338539566216603
Validation loss: 3.787359037984171

Epoch: 6| Step: 9
Training loss: 3.800997783769635
Validation loss: 3.7853282379437827

Epoch: 6| Step: 10
Training loss: 4.3927987036102
Validation loss: 3.7794050629337472

Epoch: 6| Step: 11
Training loss: 2.1163234847999193
Validation loss: 3.7781932614599305

Epoch: 6| Step: 12
Training loss: 4.334629720781717
Validation loss: 3.7749179864047906

Epoch: 6| Step: 13
Training loss: 5.023688848445542
Validation loss: 3.7706195263281774

Epoch: 17| Step: 0
Training loss: 4.022999919317682
Validation loss: 3.769719269909232

Epoch: 6| Step: 1
Training loss: 3.43659156586525
Validation loss: 3.7639422112777963

Epoch: 6| Step: 2
Training loss: 4.16001090928628
Validation loss: 3.7604599553289226

Epoch: 6| Step: 3
Training loss: 2.297029658709422
Validation loss: 3.758819628634376

Epoch: 6| Step: 4
Training loss: 3.8524935140685104
Validation loss: 3.755709244606606

Epoch: 6| Step: 5
Training loss: 4.553515222881083
Validation loss: 3.755384102150049

Epoch: 6| Step: 6
Training loss: 3.4673978902445652
Validation loss: 3.75390186561174

Epoch: 6| Step: 7
Training loss: 4.383079915039877
Validation loss: 3.7525521812394302

Epoch: 6| Step: 8
Training loss: 3.764499100272458
Validation loss: 3.748933873684604

Epoch: 6| Step: 9
Training loss: 4.253778012587293
Validation loss: 3.745759967874511

Epoch: 6| Step: 10
Training loss: 4.431930700621053
Validation loss: 3.742914722819551

Epoch: 6| Step: 11
Training loss: 4.179232734824786
Validation loss: 3.7415232817664674

Epoch: 6| Step: 12
Training loss: 3.785767308092634
Validation loss: 3.73888076067597

Epoch: 6| Step: 13
Training loss: 3.845104816134159
Validation loss: 3.734568861978037

Epoch: 18| Step: 0
Training loss: 4.414738048070469
Validation loss: 3.7279160621283043

Epoch: 6| Step: 1
Training loss: 3.60899582229419
Validation loss: 3.7235590509511742

Epoch: 6| Step: 2
Training loss: 3.7982298392144496
Validation loss: 3.72298723095844

Epoch: 6| Step: 3
Training loss: 4.436149284141755
Validation loss: 3.7190334246186714

Epoch: 6| Step: 4
Training loss: 3.6984595674824194
Validation loss: 3.717959152982357

Epoch: 6| Step: 5
Training loss: 3.4058452680724165
Validation loss: 3.7166930049068037

Epoch: 6| Step: 6
Training loss: 5.023168102771028
Validation loss: 3.716252168593001

Epoch: 6| Step: 7
Training loss: 4.284585140981827
Validation loss: 3.7112464252029285

Epoch: 6| Step: 8
Training loss: 3.3417139717489186
Validation loss: 3.7095750916765846

Epoch: 6| Step: 9
Training loss: 3.7186747310938975
Validation loss: 3.7087648110055413

Epoch: 6| Step: 10
Training loss: 3.0806629542471695
Validation loss: 3.705571850641747

Epoch: 6| Step: 11
Training loss: 3.976771860663206
Validation loss: 3.7030983162340814

Epoch: 6| Step: 12
Training loss: 3.6886817202426063
Validation loss: 3.706037562649032

Epoch: 6| Step: 13
Training loss: 3.4549075397756215
Validation loss: 3.699255200014902

Epoch: 19| Step: 0
Training loss: 3.9296372639836945
Validation loss: 3.6997080467398225

Epoch: 6| Step: 1
Training loss: 3.6201107332775617
Validation loss: 3.6968105442959605

Epoch: 6| Step: 2
Training loss: 3.7942685572561308
Validation loss: 3.695079843404819

Epoch: 6| Step: 3
Training loss: 3.6945815542938183
Validation loss: 3.6920623878498238

Epoch: 6| Step: 4
Training loss: 4.508561572903828
Validation loss: 3.689905593393169

Epoch: 6| Step: 5
Training loss: 3.7565103602505774
Validation loss: 3.6898498139496994

Epoch: 6| Step: 6
Training loss: 3.823890180958108
Validation loss: 3.68764529073205

Epoch: 6| Step: 7
Training loss: 3.9255814382841523
Validation loss: 3.684037076060828

Epoch: 6| Step: 8
Training loss: 4.3026005000734635
Validation loss: 3.6827642775086553

Epoch: 6| Step: 9
Training loss: 4.00765068813213
Validation loss: 3.6817626382805266

Epoch: 6| Step: 10
Training loss: 4.462993622307106
Validation loss: 3.6808780342892145

Epoch: 6| Step: 11
Training loss: 3.1516956670009524
Validation loss: 3.6777207807033547

Epoch: 6| Step: 12
Training loss: 3.577674270959685
Validation loss: 3.6750598578077396

Epoch: 6| Step: 13
Training loss: 3.039102823730314
Validation loss: 3.672962200392615

Epoch: 20| Step: 0
Training loss: 3.8456619593721078
Validation loss: 3.674122825622253

Epoch: 6| Step: 1
Training loss: 2.889953535293816
Validation loss: 3.66911934366571

Epoch: 6| Step: 2
Training loss: 4.033655912462242
Validation loss: 3.6720483798755588

Epoch: 6| Step: 3
Training loss: 3.3859868122166223
Validation loss: 3.6704612773478886

Epoch: 6| Step: 4
Training loss: 4.160344681031877
Validation loss: 3.6688058063094546

Epoch: 6| Step: 5
Training loss: 3.4978342167352174
Validation loss: 3.6637911796801896

Epoch: 6| Step: 6
Training loss: 4.739886912031
Validation loss: 3.6617808390377964

Epoch: 6| Step: 7
Training loss: 3.6673251918953618
Validation loss: 3.658284550554427

Epoch: 6| Step: 8
Training loss: 4.30866546432838
Validation loss: 3.656904075307131

Epoch: 6| Step: 9
Training loss: 3.5349409680651074
Validation loss: 3.655459158333798

Epoch: 6| Step: 10
Training loss: 3.9707446755235023
Validation loss: 3.6577779520202767

Epoch: 6| Step: 11
Training loss: 3.7794675803259463
Validation loss: 3.6545450228227803

Epoch: 6| Step: 12
Training loss: 3.5000577649390525
Validation loss: 3.652747552920997

Epoch: 6| Step: 13
Training loss: 4.542280989696198
Validation loss: 3.6512327966452838

Epoch: 21| Step: 0
Training loss: 3.5161501343910393
Validation loss: 3.64847434913426

Epoch: 6| Step: 1
Training loss: 3.9436240634065265
Validation loss: 3.6462720058004257

Epoch: 6| Step: 2
Training loss: 3.5198631680509624
Validation loss: 3.645461628097098

Epoch: 6| Step: 3
Training loss: 3.734456592131335
Validation loss: 3.6420152215553903

Epoch: 6| Step: 4
Training loss: 4.274920608943347
Validation loss: 3.640869497178178

Epoch: 6| Step: 5
Training loss: 3.950925433722701
Validation loss: 3.638863002784493

Epoch: 6| Step: 6
Training loss: 3.6645815874059067
Validation loss: 3.6369313217721175

Epoch: 6| Step: 7
Training loss: 3.749751146324619
Validation loss: 3.633814037138062

Epoch: 6| Step: 8
Training loss: 3.4941560458103678
Validation loss: 3.632971576053064

Epoch: 6| Step: 9
Training loss: 4.094527076176083
Validation loss: 3.632447385705385

Epoch: 6| Step: 10
Training loss: 4.339227751132255
Validation loss: 3.629536713116418

Epoch: 6| Step: 11
Training loss: 3.9331270185338405
Validation loss: 3.6286219365578614

Epoch: 6| Step: 12
Training loss: 3.188221868416779
Validation loss: 3.628102811609644

Epoch: 6| Step: 13
Training loss: 4.2429767246835155
Validation loss: 3.62731575326386

Epoch: 22| Step: 0
Training loss: 3.642367359435221
Validation loss: 3.6268715629260164

Epoch: 6| Step: 1
Training loss: 3.375523561911041
Validation loss: 3.6249418441412993

Epoch: 6| Step: 2
Training loss: 3.2157098430862625
Validation loss: 3.62521734070566

Epoch: 6| Step: 3
Training loss: 3.4281041133386903
Validation loss: 3.621284120650767

Epoch: 6| Step: 4
Training loss: 3.812229584656193
Validation loss: 3.6221047601461374

Epoch: 6| Step: 5
Training loss: 3.974335352194027
Validation loss: 3.6185848542344963

Epoch: 6| Step: 6
Training loss: 4.445818344324521
Validation loss: 3.619511053658646

Epoch: 6| Step: 7
Training loss: 3.582412882435761
Validation loss: 3.6156316087466522

Epoch: 6| Step: 8
Training loss: 3.0497394888263867
Validation loss: 3.612435348811635

Epoch: 6| Step: 9
Training loss: 3.496848458606128
Validation loss: 3.6128473759141793

Epoch: 6| Step: 10
Training loss: 4.839878824151562
Validation loss: 3.608724065840663

Epoch: 6| Step: 11
Training loss: 3.997402301331629
Validation loss: 3.610758499544613

Epoch: 6| Step: 12
Training loss: 3.4193737346721433
Validation loss: 3.604954319734578

Epoch: 6| Step: 13
Training loss: 5.111977010899104
Validation loss: 3.6055692245591966

Epoch: 23| Step: 0
Training loss: 4.110100395665679
Validation loss: 3.6062993706781645

Epoch: 6| Step: 1
Training loss: 3.619086605354404
Validation loss: 3.606669567240354

Epoch: 6| Step: 2
Training loss: 2.6915183964411886
Validation loss: 3.6053068320878343

Epoch: 6| Step: 3
Training loss: 4.306060848871006
Validation loss: 3.6025789414918874

Epoch: 6| Step: 4
Training loss: 3.830595254880613
Validation loss: 3.5974771298430492

Epoch: 6| Step: 5
Training loss: 3.864271262730888
Validation loss: 3.595423940876198

Epoch: 6| Step: 6
Training loss: 3.7744206318668576
Validation loss: 3.5937659193259712

Epoch: 6| Step: 7
Training loss: 4.219056068903189
Validation loss: 3.5924702624002616

Epoch: 6| Step: 8
Training loss: 4.288603989181723
Validation loss: 3.592193477590511

Epoch: 6| Step: 9
Training loss: 2.6567420952434255
Validation loss: 3.591201085175402

Epoch: 6| Step: 10
Training loss: 4.349184876288287
Validation loss: 3.5889878946240397

Epoch: 6| Step: 11
Training loss: 3.38633210154124
Validation loss: 3.5877175769539997

Epoch: 6| Step: 12
Training loss: 3.9826979754247183
Validation loss: 3.5842996073342936

Epoch: 6| Step: 13
Training loss: 3.330982682773144
Validation loss: 3.584818166564593

Epoch: 24| Step: 0
Training loss: 3.902761625993339
Validation loss: 3.582556952132215

Epoch: 6| Step: 1
Training loss: 3.634512423592878
Validation loss: 3.5795974578392165

Epoch: 6| Step: 2
Training loss: 2.9319312696845077
Validation loss: 3.5802311032899996

Epoch: 6| Step: 3
Training loss: 3.4852463526516853
Validation loss: 3.5797447360542067

Epoch: 6| Step: 4
Training loss: 4.281612186008554
Validation loss: 3.578479854392517

Epoch: 6| Step: 5
Training loss: 3.6742574551437857
Validation loss: 3.5734501817084543

Epoch: 6| Step: 6
Training loss: 4.275037950492301
Validation loss: 3.5739301075776315

Epoch: 6| Step: 7
Training loss: 3.7671129761218634
Validation loss: 3.5733812175386728

Epoch: 6| Step: 8
Training loss: 3.984386488954024
Validation loss: 3.571038977238382

Epoch: 6| Step: 9
Training loss: 4.218161760928263
Validation loss: 3.5691362510772446

Epoch: 6| Step: 10
Training loss: 3.9682062933040996
Validation loss: 3.571783098300259

Epoch: 6| Step: 11
Training loss: 3.8496112329951755
Validation loss: 3.5705936246081387

Epoch: 6| Step: 12
Training loss: 3.661753888996242
Validation loss: 3.5701358827145095

Epoch: 6| Step: 13
Training loss: 2.030508757105742
Validation loss: 3.5712024847447617

Epoch: 25| Step: 0
Training loss: 4.603262051512229
Validation loss: 3.5711461534479128

Epoch: 6| Step: 1
Training loss: 3.500744740407074
Validation loss: 3.5673151726407104

Epoch: 6| Step: 2
Training loss: 4.119682583849732
Validation loss: 3.5619200367710757

Epoch: 6| Step: 3
Training loss: 4.417905933530547
Validation loss: 3.5591124580741242

Epoch: 6| Step: 4
Training loss: 3.1622161375970026
Validation loss: 3.5576035881957484

Epoch: 6| Step: 5
Training loss: 3.1139648912198736
Validation loss: 3.55375039487631

Epoch: 6| Step: 6
Training loss: 2.94820142972407
Validation loss: 3.5565365307356935

Epoch: 6| Step: 7
Training loss: 3.5268044635074283
Validation loss: 3.556385452687183

Epoch: 6| Step: 8
Training loss: 3.9997520369920276
Validation loss: 3.5496757522162024

Epoch: 6| Step: 9
Training loss: 4.078697661316264
Validation loss: 3.545785020619829

Epoch: 6| Step: 10
Training loss: 3.521314027615132
Validation loss: 3.542128622677938

Epoch: 6| Step: 11
Training loss: 3.447805596874321
Validation loss: 3.5416680747987868

Epoch: 6| Step: 12
Training loss: 3.9476042181829127
Validation loss: 3.542744703494779

Epoch: 6| Step: 13
Training loss: 3.8685516109349356
Validation loss: 3.539620769224808

Epoch: 26| Step: 0
Training loss: 3.7686589472005743
Validation loss: 3.5420920799949474

Epoch: 6| Step: 1
Training loss: 3.851106875941237
Validation loss: 3.541064047652156

Epoch: 6| Step: 2
Training loss: 4.29892573577277
Validation loss: 3.542339758035569

Epoch: 6| Step: 3
Training loss: 3.038259365780822
Validation loss: 3.545441354070707

Epoch: 6| Step: 4
Training loss: 3.7229887582679395
Validation loss: 3.554129345460397

Epoch: 6| Step: 5
Training loss: 3.2741276052282053
Validation loss: 3.544400834149063

Epoch: 6| Step: 6
Training loss: 3.5026214863893737
Validation loss: 3.535577549857972

Epoch: 6| Step: 7
Training loss: 4.264211343562647
Validation loss: 3.5306884031562906

Epoch: 6| Step: 8
Training loss: 3.246069365225047
Validation loss: 3.528181994750666

Epoch: 6| Step: 9
Training loss: 2.8408397832565813
Validation loss: 3.5258788578983387

Epoch: 6| Step: 10
Training loss: 3.6793223076312054
Validation loss: 3.5248585527372973

Epoch: 6| Step: 11
Training loss: 4.081710700631825
Validation loss: 3.5216559837152914

Epoch: 6| Step: 12
Training loss: 4.170026619732462
Validation loss: 3.5208091819960545

Epoch: 6| Step: 13
Training loss: 4.572590578077876
Validation loss: 3.518851836976743

Epoch: 27| Step: 0
Training loss: 3.7768590985054473
Validation loss: 3.5190080043398386

Epoch: 6| Step: 1
Training loss: 4.180516126974111
Validation loss: 3.512291705309999

Epoch: 6| Step: 2
Training loss: 3.7783302825614773
Validation loss: 3.512352870848818

Epoch: 6| Step: 3
Training loss: 4.173781512959192
Validation loss: 3.508812374031399

Epoch: 6| Step: 4
Training loss: 3.8168001781804994
Validation loss: 3.5094494788845427

Epoch: 6| Step: 5
Training loss: 3.981877759849587
Validation loss: 3.508700084761655

Epoch: 6| Step: 6
Training loss: 3.6902602904608965
Validation loss: 3.5049354983263044

Epoch: 6| Step: 7
Training loss: 3.3131783708477305
Validation loss: 3.508727980964807

Epoch: 6| Step: 8
Training loss: 3.3786622416861967
Validation loss: 3.503713656294387

Epoch: 6| Step: 9
Training loss: 3.7835755566150318
Validation loss: 3.4998816530227197

Epoch: 6| Step: 10
Training loss: 3.459385784514863
Validation loss: 3.4974622696841853

Epoch: 6| Step: 11
Training loss: 3.7751723698553343
Validation loss: 3.49554480700441

Epoch: 6| Step: 12
Training loss: 2.8094637270145784
Validation loss: 3.4937497818034484

Epoch: 6| Step: 13
Training loss: 4.04714528952283
Validation loss: 3.4951813542616157

Epoch: 28| Step: 0
Training loss: 4.46163138689968
Validation loss: 3.4914906583229075

Epoch: 6| Step: 1
Training loss: 4.039491021982201
Validation loss: 3.4908827959039592

Epoch: 6| Step: 2
Training loss: 2.5504994258614486
Validation loss: 3.491081035161285

Epoch: 6| Step: 3
Training loss: 3.4282993992109096
Validation loss: 3.489336203706197

Epoch: 6| Step: 4
Training loss: 3.172758233132207
Validation loss: 3.4876987800663395

Epoch: 6| Step: 5
Training loss: 3.913909970050679
Validation loss: 3.488241714980897

Epoch: 6| Step: 6
Training loss: 3.780788551106273
Validation loss: 3.4861106925397256

Epoch: 6| Step: 7
Training loss: 3.7170011110465766
Validation loss: 3.48386065866304

Epoch: 6| Step: 8
Training loss: 4.5860743331641105
Validation loss: 3.4837352699387445

Epoch: 6| Step: 9
Training loss: 3.5899181337505803
Validation loss: 3.4832333902264905

Epoch: 6| Step: 10
Training loss: 3.5080835454337693
Validation loss: 3.4796317275226953

Epoch: 6| Step: 11
Training loss: 3.614574172185159
Validation loss: 3.4809215355128353

Epoch: 6| Step: 12
Training loss: 3.408336175545873
Validation loss: 3.4776269400130557

Epoch: 6| Step: 13
Training loss: 3.483125608051602
Validation loss: 3.476762604309469

Epoch: 29| Step: 0
Training loss: 2.765695861943074
Validation loss: 3.478520755939419

Epoch: 6| Step: 1
Training loss: 2.6802995611134004
Validation loss: 3.483499633423453

Epoch: 6| Step: 2
Training loss: 3.31004919401647
Validation loss: 3.486604305266412

Epoch: 6| Step: 3
Training loss: 3.7608668233128535
Validation loss: 3.4944029382588235

Epoch: 6| Step: 4
Training loss: 3.974548669299923
Validation loss: 3.4815614100001935

Epoch: 6| Step: 5
Training loss: 4.7615352905080846
Validation loss: 3.4762138587319047

Epoch: 6| Step: 6
Training loss: 4.599093903573476
Validation loss: 3.472998743712412

Epoch: 6| Step: 7
Training loss: 3.84933289532273
Validation loss: 3.4757966836406107

Epoch: 6| Step: 8
Training loss: 3.620858161118302
Validation loss: 3.486642755940027

Epoch: 6| Step: 9
Training loss: 3.50887494893842
Validation loss: 3.4832828089629695

Epoch: 6| Step: 10
Training loss: 3.4045442282304896
Validation loss: 3.4764434082457814

Epoch: 6| Step: 11
Training loss: 2.970886585958545
Validation loss: 3.4730976547260726

Epoch: 6| Step: 12
Training loss: 4.392860793622812
Validation loss: 3.4735552020131717

Epoch: 6| Step: 13
Training loss: 3.0893162254130906
Validation loss: 3.470537027812579

Epoch: 30| Step: 0
Training loss: 3.7318637975634177
Validation loss: 3.4698306440849116

Epoch: 6| Step: 1
Training loss: 2.6023863441648425
Validation loss: 3.480360073418818

Epoch: 6| Step: 2
Training loss: 4.590360883434017
Validation loss: 3.5097491946529074

Epoch: 6| Step: 3
Training loss: 4.1595196017401745
Validation loss: 3.472609953421345

Epoch: 6| Step: 4
Training loss: 3.7460934954216545
Validation loss: 3.4688126398454275

Epoch: 6| Step: 5
Training loss: 3.524281876374338
Validation loss: 3.4716435449143637

Epoch: 6| Step: 6
Training loss: 3.500101360488208
Validation loss: 3.477057680557763

Epoch: 6| Step: 7
Training loss: 3.36950094314202
Validation loss: 3.4811628005590283

Epoch: 6| Step: 8
Training loss: 3.0328226630754496
Validation loss: 3.477897937844592

Epoch: 6| Step: 9
Training loss: 4.1561013101927555
Validation loss: 3.4796479213887306

Epoch: 6| Step: 10
Training loss: 2.4250121440780004
Validation loss: 3.4701775892134488

Epoch: 6| Step: 11
Training loss: 4.164696850866716
Validation loss: 3.469830098822871

Epoch: 6| Step: 12
Training loss: 4.405041901024356
Validation loss: 3.464716277546647

Epoch: 6| Step: 13
Training loss: 3.3986952409896194
Validation loss: 3.4628630273116014

Epoch: 31| Step: 0
Training loss: 3.469706085685778
Validation loss: 3.4625557436790393

Epoch: 6| Step: 1
Training loss: 3.485216800289407
Validation loss: 3.4600321252780057

Epoch: 6| Step: 2
Training loss: 3.975010177311374
Validation loss: 3.4588100481856583

Epoch: 6| Step: 3
Training loss: 4.18607317400975
Validation loss: 3.4593745128498856

Epoch: 6| Step: 4
Training loss: 4.483203482372339
Validation loss: 3.461759817669106

Epoch: 6| Step: 5
Training loss: 3.7349154667818585
Validation loss: 3.4678751322527126

Epoch: 6| Step: 6
Training loss: 3.884977355066235
Validation loss: 3.4700673565567595

Epoch: 6| Step: 7
Training loss: 3.1658981461470526
Validation loss: 3.455157594406768

Epoch: 6| Step: 8
Training loss: 2.990242826623017
Validation loss: 3.45469680461112

Epoch: 6| Step: 9
Training loss: 3.089185642224971
Validation loss: 3.4561274986125325

Epoch: 6| Step: 10
Training loss: 3.569636641958847
Validation loss: 3.4595001865015544

Epoch: 6| Step: 11
Training loss: 3.888427849340446
Validation loss: 3.4628439446673926

Epoch: 6| Step: 12
Training loss: 3.6561231020563487
Validation loss: 3.4673336278029994

Epoch: 6| Step: 13
Training loss: 3.6164209859584466
Validation loss: 3.465336225523927

Epoch: 32| Step: 0
Training loss: 3.8903915151372934
Validation loss: 3.46946502886951

Epoch: 6| Step: 1
Training loss: 3.710765184116067
Validation loss: 3.4605118217917377

Epoch: 6| Step: 2
Training loss: 3.7191501690630218
Validation loss: 3.453834594045908

Epoch: 6| Step: 3
Training loss: 3.513748956908808
Validation loss: 3.4557559543548795

Epoch: 6| Step: 4
Training loss: 3.5297456761024395
Validation loss: 3.4531897673952243

Epoch: 6| Step: 5
Training loss: 3.522960825138972
Validation loss: 3.452086635961838

Epoch: 6| Step: 6
Training loss: 4.030936295479363
Validation loss: 3.4547660097380866

Epoch: 6| Step: 7
Training loss: 3.9653149254360294
Validation loss: 3.454439679762978

Epoch: 6| Step: 8
Training loss: 3.1550991868570866
Validation loss: 3.4513883725155736

Epoch: 6| Step: 9
Training loss: 3.813907801121325
Validation loss: 3.452388918277593

Epoch: 6| Step: 10
Training loss: 3.884493120627094
Validation loss: 3.4509762610120176

Epoch: 6| Step: 11
Training loss: 3.9701189698810997
Validation loss: 3.4489450780131694

Epoch: 6| Step: 12
Training loss: 3.6386571977025506
Validation loss: 3.4478127617839425

Epoch: 6| Step: 13
Training loss: 2.172332386183853
Validation loss: 3.4494854246524724

Epoch: 33| Step: 0
Training loss: 2.822841957670861
Validation loss: 3.4477222326958814

Epoch: 6| Step: 1
Training loss: 3.4956910993689116
Validation loss: 3.4478885701661244

Epoch: 6| Step: 2
Training loss: 3.3329163926354126
Validation loss: 3.4450879083658337

Epoch: 6| Step: 3
Training loss: 3.548879048848655
Validation loss: 3.4468787829292884

Epoch: 6| Step: 4
Training loss: 4.007637838086142
Validation loss: 3.4446543086999384

Epoch: 6| Step: 5
Training loss: 4.19939816113827
Validation loss: 3.4438317700945635

Epoch: 6| Step: 6
Training loss: 3.6828474014823067
Validation loss: 3.444812974975197

Epoch: 6| Step: 7
Training loss: 4.0712840262546806
Validation loss: 3.440702847630224

Epoch: 6| Step: 8
Training loss: 3.6538236995732944
Validation loss: 3.4423153751830697

Epoch: 6| Step: 9
Training loss: 3.491985135967697
Validation loss: 3.4404748530589533

Epoch: 6| Step: 10
Training loss: 4.31250110570921
Validation loss: 3.4390987925475254

Epoch: 6| Step: 11
Training loss: 2.4210934270001196
Validation loss: 3.439376070014594

Epoch: 6| Step: 12
Training loss: 3.501503757595174
Validation loss: 3.439260942723329

Epoch: 6| Step: 13
Training loss: 4.678411395748157
Validation loss: 3.4381969144442195

Epoch: 34| Step: 0
Training loss: 4.064361615230056
Validation loss: 3.4364127191250273

Epoch: 6| Step: 1
Training loss: 3.394405244128159
Validation loss: 3.4376132413198133

Epoch: 6| Step: 2
Training loss: 3.8276396774628982
Validation loss: 3.435448827530619

Epoch: 6| Step: 3
Training loss: 3.890242347130726
Validation loss: 3.4375560782026366

Epoch: 6| Step: 4
Training loss: 3.950363219739559
Validation loss: 3.436438065886351

Epoch: 6| Step: 5
Training loss: 3.6382285158719228
Validation loss: 3.4354072069546424

Epoch: 6| Step: 6
Training loss: 3.4669767779025613
Validation loss: 3.4346947776931867

Epoch: 6| Step: 7
Training loss: 3.6207243598251915
Validation loss: 3.4353864330435777

Epoch: 6| Step: 8
Training loss: 3.7582562158853303
Validation loss: 3.4313474408243896

Epoch: 6| Step: 9
Training loss: 2.954240860610387
Validation loss: 3.431576686547385

Epoch: 6| Step: 10
Training loss: 3.470568893146718
Validation loss: 3.4301713743281157

Epoch: 6| Step: 11
Training loss: 3.29215238504462
Validation loss: 3.4316107185732108

Epoch: 6| Step: 12
Training loss: 3.8632713757457227
Validation loss: 3.4295386694781658

Epoch: 6| Step: 13
Training loss: 4.027425208317809
Validation loss: 3.429359425015539

Epoch: 35| Step: 0
Training loss: 4.33086124233296
Validation loss: 3.4293164492063433

Epoch: 6| Step: 1
Training loss: 3.800201340410944
Validation loss: 3.4297876271704677

Epoch: 6| Step: 2
Training loss: 3.687247962743667
Validation loss: 3.4278823003994683

Epoch: 6| Step: 3
Training loss: 3.6296261175042055
Validation loss: 3.4283244470212173

Epoch: 6| Step: 4
Training loss: 2.935765180255995
Validation loss: 3.4284313931899986

Epoch: 6| Step: 5
Training loss: 3.8422929436734052
Validation loss: 3.4281045171671085

Epoch: 6| Step: 6
Training loss: 2.809048208679246
Validation loss: 3.436114359905311

Epoch: 6| Step: 7
Training loss: 4.110943281052924
Validation loss: 3.428530815288535

Epoch: 6| Step: 8
Training loss: 3.91622834424589
Validation loss: 3.4308393815808755

Epoch: 6| Step: 9
Training loss: 3.161341422536286
Validation loss: 3.4282967610143613

Epoch: 6| Step: 10
Training loss: 2.8462015839933184
Validation loss: 3.4257869987239844

Epoch: 6| Step: 11
Training loss: 3.536698855206566
Validation loss: 3.4287708193697988

Epoch: 6| Step: 12
Training loss: 3.4792781210462764
Validation loss: 3.4258705958444535

Epoch: 6| Step: 13
Training loss: 5.110513636087256
Validation loss: 3.4226554579553805

Epoch: 36| Step: 0
Training loss: 3.6587098804772635
Validation loss: 3.423066463017174

Epoch: 6| Step: 1
Training loss: 3.366258391246968
Validation loss: 3.4225012295693182

Epoch: 6| Step: 2
Training loss: 4.151186045102615
Validation loss: 3.4229407077007177

Epoch: 6| Step: 3
Training loss: 3.6034624297394786
Validation loss: 3.4216796741336557

Epoch: 6| Step: 4
Training loss: 3.5470892887669674
Validation loss: 3.421827174259066

Epoch: 6| Step: 5
Training loss: 3.358534312959039
Validation loss: 3.4222296849697558

Epoch: 6| Step: 6
Training loss: 3.2875752835664747
Validation loss: 3.4222450477679853

Epoch: 6| Step: 7
Training loss: 3.403758686571528
Validation loss: 3.4217644609604143

Epoch: 6| Step: 8
Training loss: 4.346427476499715
Validation loss: 3.4213705559641205

Epoch: 6| Step: 9
Training loss: 4.372077837936063
Validation loss: 3.418841389959442

Epoch: 6| Step: 10
Training loss: 2.479624494919185
Validation loss: 3.4184690554057706

Epoch: 6| Step: 11
Training loss: 4.028063557158428
Validation loss: 3.4197165210264524

Epoch: 6| Step: 12
Training loss: 3.390435138783494
Validation loss: 3.4196725244236514

Epoch: 6| Step: 13
Training loss: 3.614446338765514
Validation loss: 3.4181394731628534

Epoch: 37| Step: 0
Training loss: 3.498625894289551
Validation loss: 3.4185778022189184

Epoch: 6| Step: 1
Training loss: 4.433893161696156
Validation loss: 3.4167516554239774

Epoch: 6| Step: 2
Training loss: 3.3046127563392886
Validation loss: 3.417101827582318

Epoch: 6| Step: 3
Training loss: 4.036250834720415
Validation loss: 3.417484369179571

Epoch: 6| Step: 4
Training loss: 3.5784317618059127
Validation loss: 3.421423138594335

Epoch: 6| Step: 5
Training loss: 3.575014186377488
Validation loss: 3.418578103684484

Epoch: 6| Step: 6
Training loss: 3.255628553605699
Validation loss: 3.424260530105572

Epoch: 6| Step: 7
Training loss: 2.6137720396990813
Validation loss: 3.448460027186583

Epoch: 6| Step: 8
Training loss: 3.0460712644339516
Validation loss: 3.4223073687222425

Epoch: 6| Step: 9
Training loss: 3.92753988322229
Validation loss: 3.418713818982347

Epoch: 6| Step: 10
Training loss: 3.757795496404488
Validation loss: 3.414354083942246

Epoch: 6| Step: 11
Training loss: 3.608363947103432
Validation loss: 3.41234937183131

Epoch: 6| Step: 12
Training loss: 3.8317834927632064
Validation loss: 3.4161399339745606

Epoch: 6| Step: 13
Training loss: 4.533154738405057
Validation loss: 3.4197728563625707

Epoch: 38| Step: 0
Training loss: 2.925425936994782
Validation loss: 3.4159072371627923

Epoch: 6| Step: 1
Training loss: 2.6169968265139585
Validation loss: 3.414048370920051

Epoch: 6| Step: 2
Training loss: 4.30454770396019
Validation loss: 3.4137411525979933

Epoch: 6| Step: 3
Training loss: 3.7405822751466267
Validation loss: 3.4098384485302504

Epoch: 6| Step: 4
Training loss: 3.614619948378504
Validation loss: 3.410560862717981

Epoch: 6| Step: 5
Training loss: 3.820148737543229
Validation loss: 3.4110798172136954

Epoch: 6| Step: 6
Training loss: 3.4698367779075463
Validation loss: 3.4113294321428365

Epoch: 6| Step: 7
Training loss: 4.140286874460758
Validation loss: 3.411091104164875

Epoch: 6| Step: 8
Training loss: 3.1276499384639007
Validation loss: 3.414113932931487

Epoch: 6| Step: 9
Training loss: 3.5647028754541377
Validation loss: 3.4161072629976914

Epoch: 6| Step: 10
Training loss: 3.2152378216195383
Validation loss: 3.420405369484195

Epoch: 6| Step: 11
Training loss: 3.823076679647155
Validation loss: 3.4317618482467918

Epoch: 6| Step: 12
Training loss: 4.592873418304958
Validation loss: 3.44537444983644

Epoch: 6| Step: 13
Training loss: 3.3621336499846177
Validation loss: 3.4198434578887262

Epoch: 39| Step: 0
Training loss: 3.2414888295586213
Validation loss: 3.4114649052647827

Epoch: 6| Step: 1
Training loss: 3.2891702158634692
Validation loss: 3.409923647069444

Epoch: 6| Step: 2
Training loss: 3.660492351330677
Validation loss: 3.4112156279172

Epoch: 6| Step: 3
Training loss: 3.1365887720676797
Validation loss: 3.421066067943946

Epoch: 6| Step: 4
Training loss: 3.6091123543170536
Validation loss: 3.426932845165513

Epoch: 6| Step: 5
Training loss: 4.1972878918383305
Validation loss: 3.4476974775025435

Epoch: 6| Step: 6
Training loss: 4.1612053493076315
Validation loss: 3.4323558721385337

Epoch: 6| Step: 7
Training loss: 3.045578587877273
Validation loss: 3.414583080086297

Epoch: 6| Step: 8
Training loss: 4.846484390742122
Validation loss: 3.4131851005605034

Epoch: 6| Step: 9
Training loss: 3.6872703351414393
Validation loss: 3.408411890921714

Epoch: 6| Step: 10
Training loss: 3.9780233581455575
Validation loss: 3.407008337009897

Epoch: 6| Step: 11
Training loss: 3.3009132855433747
Validation loss: 3.408965179484033

Epoch: 6| Step: 12
Training loss: 3.2575096520187943
Validation loss: 3.4054590401768423

Epoch: 6| Step: 13
Training loss: 2.542398649613134
Validation loss: 3.4056200308746716

Epoch: 40| Step: 0
Training loss: 3.1757797485197865
Validation loss: 3.407596818229834

Epoch: 6| Step: 1
Training loss: 4.762595893114729
Validation loss: 3.4075413062843753

Epoch: 6| Step: 2
Training loss: 3.6500643058233244
Validation loss: 3.4110287812096556

Epoch: 6| Step: 3
Training loss: 4.320894998805021
Validation loss: 3.4093001814095074

Epoch: 6| Step: 4
Training loss: 4.126266516254031
Validation loss: 3.4087106668287808

Epoch: 6| Step: 5
Training loss: 2.89142923250627
Validation loss: 3.4046274779981873

Epoch: 6| Step: 6
Training loss: 3.5077683205997823
Validation loss: 3.4039271113756358

Epoch: 6| Step: 7
Training loss: 3.5557827446462507
Validation loss: 3.4036551740579566

Epoch: 6| Step: 8
Training loss: 2.8685932922778483
Validation loss: 3.402139535337009

Epoch: 6| Step: 9
Training loss: 4.017687553580821
Validation loss: 3.404000114157789

Epoch: 6| Step: 10
Training loss: 3.280501507356841
Validation loss: 3.404299656803405

Epoch: 6| Step: 11
Training loss: 3.4924476065832404
Validation loss: 3.403734831792676

Epoch: 6| Step: 12
Training loss: 3.2990072144160343
Validation loss: 3.403776630268228

Epoch: 6| Step: 13
Training loss: 3.0866360030769293
Validation loss: 3.409945437681333

Epoch: 41| Step: 0
Training loss: 3.5488349775921044
Validation loss: 3.405281369458115

Epoch: 6| Step: 1
Training loss: 4.069385972252093
Validation loss: 3.4035483539960065

Epoch: 6| Step: 2
Training loss: 3.7329480625221394
Validation loss: 3.4015143715994185

Epoch: 6| Step: 3
Training loss: 3.524550437667007
Validation loss: 3.3989611995260387

Epoch: 6| Step: 4
Training loss: 3.548078962830034
Validation loss: 3.3993819042282962

Epoch: 6| Step: 5
Training loss: 3.9154580192551314
Validation loss: 3.399092825097464

Epoch: 6| Step: 6
Training loss: 3.649976907944464
Validation loss: 3.3985710082929383

Epoch: 6| Step: 7
Training loss: 3.1615773178074593
Validation loss: 3.394877651791953

Epoch: 6| Step: 8
Training loss: 3.9415885648725295
Validation loss: 3.3993309369450837

Epoch: 6| Step: 9
Training loss: 2.903289107005188
Validation loss: 3.396463136584694

Epoch: 6| Step: 10
Training loss: 4.166376154626563
Validation loss: 3.3969297684241972

Epoch: 6| Step: 11
Training loss: 3.7180275095003488
Validation loss: 3.392696240391112

Epoch: 6| Step: 12
Training loss: 3.6248113648892506
Validation loss: 3.3957925237038857

Epoch: 6| Step: 13
Training loss: 2.3847067385939638
Validation loss: 3.395988770825559

Epoch: 42| Step: 0
Training loss: 4.375600283176557
Validation loss: 3.395047716292961

Epoch: 6| Step: 1
Training loss: 3.4117921311628363
Validation loss: 3.4019878930309657

Epoch: 6| Step: 2
Training loss: 3.157765543955222
Validation loss: 3.408670777503785

Epoch: 6| Step: 3
Training loss: 3.306955844119491
Validation loss: 3.408413687057985

Epoch: 6| Step: 4
Training loss: 2.8263868185583014
Validation loss: 3.404214835628489

Epoch: 6| Step: 5
Training loss: 2.713676893461064
Validation loss: 3.398075720521826

Epoch: 6| Step: 6
Training loss: 4.46516861822536
Validation loss: 3.3957842449538496

Epoch: 6| Step: 7
Training loss: 4.0021976156100205
Validation loss: 3.3914128580875236

Epoch: 6| Step: 8
Training loss: 3.4969725458007224
Validation loss: 3.391449253982731

Epoch: 6| Step: 9
Training loss: 3.175500310692091
Validation loss: 3.3925621019159613

Epoch: 6| Step: 10
Training loss: 3.9572223643538638
Validation loss: 3.3906788578578912

Epoch: 6| Step: 11
Training loss: 3.743678295741614
Validation loss: 3.3912117272123745

Epoch: 6| Step: 12
Training loss: 3.767514589682657
Validation loss: 3.3893099108151024

Epoch: 6| Step: 13
Training loss: 3.8801792357034337
Validation loss: 3.388479835870633

Epoch: 43| Step: 0
Training loss: 3.116273827367979
Validation loss: 3.391792932075777

Epoch: 6| Step: 1
Training loss: 2.8692594520470993
Validation loss: 3.3904185263663726

Epoch: 6| Step: 2
Training loss: 3.525797727966009
Validation loss: 3.389827130268034

Epoch: 6| Step: 3
Training loss: 3.536565105790866
Validation loss: 3.3882070249675453

Epoch: 6| Step: 4
Training loss: 3.579672666108505
Validation loss: 3.3878957531693583

Epoch: 6| Step: 5
Training loss: 3.505984231324758
Validation loss: 3.388249633919691

Epoch: 6| Step: 6
Training loss: 4.512848208193503
Validation loss: 3.3868205365592536

Epoch: 6| Step: 7
Training loss: 3.9918553163763746
Validation loss: 3.3878746727913835

Epoch: 6| Step: 8
Training loss: 3.3819490172041715
Validation loss: 3.3867742898638786

Epoch: 6| Step: 9
Training loss: 3.695739076280452
Validation loss: 3.3862336571825513

Epoch: 6| Step: 10
Training loss: 3.325210943199312
Validation loss: 3.3876917497160584

Epoch: 6| Step: 11
Training loss: 3.553949099131662
Validation loss: 3.3885243479379294

Epoch: 6| Step: 12
Training loss: 3.727868449104411
Validation loss: 3.384429170199256

Epoch: 6| Step: 13
Training loss: 4.287223936040522
Validation loss: 3.3881357172931965

Epoch: 44| Step: 0
Training loss: 3.7341853775977882
Validation loss: 3.3904003410827106

Epoch: 6| Step: 1
Training loss: 3.6265736814340497
Validation loss: 3.384492040534461

Epoch: 6| Step: 2
Training loss: 3.487640766324594
Validation loss: 3.388082781485742

Epoch: 6| Step: 3
Training loss: 2.5469301369906443
Validation loss: 3.3870032417696536

Epoch: 6| Step: 4
Training loss: 4.035523507760728
Validation loss: 3.3875138236972644

Epoch: 6| Step: 5
Training loss: 4.113562477402423
Validation loss: 3.3840396465322904

Epoch: 6| Step: 6
Training loss: 3.330545467573182
Validation loss: 3.3852859560183677

Epoch: 6| Step: 7
Training loss: 3.527861733493042
Validation loss: 3.384589275161445

Epoch: 6| Step: 8
Training loss: 3.694530960892884
Validation loss: 3.3842308005760104

Epoch: 6| Step: 9
Training loss: 3.491947447443619
Validation loss: 3.3825653091197654

Epoch: 6| Step: 10
Training loss: 3.9833011152382394
Validation loss: 3.3853010654196054

Epoch: 6| Step: 11
Training loss: 3.5431786993334327
Validation loss: 3.388237612611029

Epoch: 6| Step: 12
Training loss: 3.262466290179205
Validation loss: 3.387991963928996

Epoch: 6| Step: 13
Training loss: 4.173374320936986
Validation loss: 3.3819549814297205

Epoch: 45| Step: 0
Training loss: 4.138829025302156
Validation loss: 3.3808599330945976

Epoch: 6| Step: 1
Training loss: 3.7128818919216076
Validation loss: 3.3792257982610505

Epoch: 6| Step: 2
Training loss: 3.477627366103669
Validation loss: 3.379364586905716

Epoch: 6| Step: 3
Training loss: 3.454904503392746
Validation loss: 3.3786107675920785

Epoch: 6| Step: 4
Training loss: 3.6504051244946787
Validation loss: 3.376217606131497

Epoch: 6| Step: 5
Training loss: 3.357877885653154
Validation loss: 3.380092309736261

Epoch: 6| Step: 6
Training loss: 4.019777518421563
Validation loss: 3.380072222811375

Epoch: 6| Step: 7
Training loss: 4.606988838806609
Validation loss: 3.380794128860216

Epoch: 6| Step: 8
Training loss: 3.18635852795007
Validation loss: 3.3774640770443938

Epoch: 6| Step: 9
Training loss: 2.9990512619292935
Validation loss: 3.3770102663315273

Epoch: 6| Step: 10
Training loss: 3.6506781222477422
Validation loss: 3.3781391601532853

Epoch: 6| Step: 11
Training loss: 3.408431588196902
Validation loss: 3.378692662311373

Epoch: 6| Step: 12
Training loss: 3.353515482809767
Validation loss: 3.3810000574200174

Epoch: 6| Step: 13
Training loss: 2.797743337511998
Validation loss: 3.3807642807049296

Epoch: 46| Step: 0
Training loss: 3.900103807290468
Validation loss: 3.3782419564956494

Epoch: 6| Step: 1
Training loss: 3.480815489137766
Validation loss: 3.3809605554382127

Epoch: 6| Step: 2
Training loss: 2.3223278399861016
Validation loss: 3.3873097548590954

Epoch: 6| Step: 3
Training loss: 3.54580591701453
Validation loss: 3.3858026756160644

Epoch: 6| Step: 4
Training loss: 3.8928762762916893
Validation loss: 3.3823120805000952

Epoch: 6| Step: 5
Training loss: 3.7603986885859775
Validation loss: 3.3937924310069807

Epoch: 6| Step: 6
Training loss: 4.510869356598008
Validation loss: 3.3872943410859975

Epoch: 6| Step: 7
Training loss: 3.6463129363907223
Validation loss: 3.3903358880224217

Epoch: 6| Step: 8
Training loss: 2.5066413402630663
Validation loss: 3.3792312301715803

Epoch: 6| Step: 9
Training loss: 3.3525443250668716
Validation loss: 3.3786634086802123

Epoch: 6| Step: 10
Training loss: 3.5990451447119023
Validation loss: 3.3762088754211046

Epoch: 6| Step: 11
Training loss: 3.8045077741656046
Validation loss: 3.3727659444826776

Epoch: 6| Step: 12
Training loss: 3.8052209875671075
Validation loss: 3.376511021715015

Epoch: 6| Step: 13
Training loss: 3.9087513963716973
Validation loss: 3.3858505029102606

Epoch: 47| Step: 0
Training loss: 4.290538651944313
Validation loss: 3.3878556437367875

Epoch: 6| Step: 1
Training loss: 3.3809812315561243
Validation loss: 3.373489581216857

Epoch: 6| Step: 2
Training loss: 3.8472545743301922
Validation loss: 3.3706205933802638

Epoch: 6| Step: 3
Training loss: 3.9666579131556077
Validation loss: 3.3735766020370117

Epoch: 6| Step: 4
Training loss: 3.5626565999195314
Validation loss: 3.3736076354140736

Epoch: 6| Step: 5
Training loss: 3.8131388144687577
Validation loss: 3.3787504282699596

Epoch: 6| Step: 6
Training loss: 4.450316068590136
Validation loss: 3.381822970070001

Epoch: 6| Step: 7
Training loss: 2.2162665854584875
Validation loss: 3.374424227842686

Epoch: 6| Step: 8
Training loss: 3.8380646877274196
Validation loss: 3.379190695466686

Epoch: 6| Step: 9
Training loss: 4.462698086314458
Validation loss: 3.378104483193311

Epoch: 6| Step: 10
Training loss: 2.904268963698262
Validation loss: 3.37565381619218

Epoch: 6| Step: 11
Training loss: 3.302439833850296
Validation loss: 3.3777044149208963

Epoch: 6| Step: 12
Training loss: 2.1058811215633084
Validation loss: 3.378830222458149

Epoch: 6| Step: 13
Training loss: 3.189960801412892
Validation loss: 3.3763729358036474

Epoch: 48| Step: 0
Training loss: 3.4107240464178554
Validation loss: 3.3758669795110094

Epoch: 6| Step: 1
Training loss: 3.8774706439856774
Validation loss: 3.373306467829728

Epoch: 6| Step: 2
Training loss: 3.8258585546004666
Validation loss: 3.3732292333631033

Epoch: 6| Step: 3
Training loss: 3.676075582040648
Validation loss: 3.373967671024385

Epoch: 6| Step: 4
Training loss: 3.699237569662397
Validation loss: 3.3737484652101037

Epoch: 6| Step: 5
Training loss: 3.4477635529203137
Validation loss: 3.3711331196854957

Epoch: 6| Step: 6
Training loss: 3.595553269130806
Validation loss: 3.3711074872359

Epoch: 6| Step: 7
Training loss: 3.9582295989782526
Validation loss: 3.3701060584732216

Epoch: 6| Step: 8
Training loss: 2.550780689186864
Validation loss: 3.371093416910879

Epoch: 6| Step: 9
Training loss: 3.536454677813986
Validation loss: 3.3730191274528263

Epoch: 6| Step: 10
Training loss: 3.6350875457757685
Validation loss: 3.3682613217057784

Epoch: 6| Step: 11
Training loss: 4.415364463338922
Validation loss: 3.3705110583543147

Epoch: 6| Step: 12
Training loss: 2.6005782364700094
Validation loss: 3.3684809705996743

Epoch: 6| Step: 13
Training loss: 3.787090992009922
Validation loss: 3.369829608651457

Epoch: 49| Step: 0
Training loss: 4.07328210672569
Validation loss: 3.3676098575622815

Epoch: 6| Step: 1
Training loss: 3.427862633373217
Validation loss: 3.368610433266087

Epoch: 6| Step: 2
Training loss: 3.074367340258265
Validation loss: 3.36703506169209

Epoch: 6| Step: 3
Training loss: 3.952163277747341
Validation loss: 3.3665951496944264

Epoch: 6| Step: 4
Training loss: 3.220506059436875
Validation loss: 3.3656443912095524

Epoch: 6| Step: 5
Training loss: 3.5460908669987177
Validation loss: 3.366179500833003

Epoch: 6| Step: 6
Training loss: 3.3713351944514756
Validation loss: 3.3663423639289407

Epoch: 6| Step: 7
Training loss: 3.443787806142439
Validation loss: 3.365515544192118

Epoch: 6| Step: 8
Training loss: 3.868427732784897
Validation loss: 3.3644967240247547

Epoch: 6| Step: 9
Training loss: 4.107944021807468
Validation loss: 3.367301866456237

Epoch: 6| Step: 10
Training loss: 3.2278648131281855
Validation loss: 3.3694773175519277

Epoch: 6| Step: 11
Training loss: 3.7649313893342122
Validation loss: 3.369109629612859

Epoch: 6| Step: 12
Training loss: 3.443290688126614
Validation loss: 3.3666051039239533

Epoch: 6| Step: 13
Training loss: 3.633018569844229
Validation loss: 3.3672395613691584

Epoch: 50| Step: 0
Training loss: 3.321129265350563
Validation loss: 3.3665604375915454

Epoch: 6| Step: 1
Training loss: 3.5364217779698195
Validation loss: 3.3620624938756327

Epoch: 6| Step: 2
Training loss: 3.97892262507675
Validation loss: 3.3614203783309455

Epoch: 6| Step: 3
Training loss: 3.6187110806548106
Validation loss: 3.3622230798491106

Epoch: 6| Step: 4
Training loss: 3.642429150355082
Validation loss: 3.3620582085092603

Epoch: 6| Step: 5
Training loss: 3.540965261379982
Validation loss: 3.3615252646078972

Epoch: 6| Step: 6
Training loss: 4.169724270786351
Validation loss: 3.3603008317561085

Epoch: 6| Step: 7
Training loss: 2.732021256063943
Validation loss: 3.3631620893482954

Epoch: 6| Step: 8
Training loss: 3.3243119868864937
Validation loss: 3.3611239399116117

Epoch: 6| Step: 9
Training loss: 4.176720252234962
Validation loss: 3.361631137490686

Epoch: 6| Step: 10
Training loss: 3.0760025995092235
Validation loss: 3.363208735431045

Epoch: 6| Step: 11
Training loss: 3.6517071010963167
Validation loss: 3.363903768818412

Epoch: 6| Step: 12
Training loss: 3.7460227219706645
Validation loss: 3.3597252684383356

Epoch: 6| Step: 13
Training loss: 3.3464904678234046
Validation loss: 3.359860141805493

Epoch: 51| Step: 0
Training loss: 3.77345455947716
Validation loss: 3.3588444711773406

Epoch: 6| Step: 1
Training loss: 3.861030131038934
Validation loss: 3.3585120468041447

Epoch: 6| Step: 2
Training loss: 3.9436978199162285
Validation loss: 3.357831392269561

Epoch: 6| Step: 3
Training loss: 3.561782898589836
Validation loss: 3.3579137639931353

Epoch: 6| Step: 4
Training loss: 3.0971916398694397
Validation loss: 3.3581581149606987

Epoch: 6| Step: 5
Training loss: 3.963867788979691
Validation loss: 3.357576305852205

Epoch: 6| Step: 6
Training loss: 2.6848076930164337
Validation loss: 3.357597170255561

Epoch: 6| Step: 7
Training loss: 3.6543849524644143
Validation loss: 3.355064252628723

Epoch: 6| Step: 8
Training loss: 3.2961780842012396
Validation loss: 3.3566901476517037

Epoch: 6| Step: 9
Training loss: 4.262950240265134
Validation loss: 3.3557752526353246

Epoch: 6| Step: 10
Training loss: 3.690970646421364
Validation loss: 3.356496354329723

Epoch: 6| Step: 11
Training loss: 2.698920270699747
Validation loss: 3.3558883548840552

Epoch: 6| Step: 12
Training loss: 4.04426991629933
Validation loss: 3.3544358043783586

Epoch: 6| Step: 13
Training loss: 2.936345949127756
Validation loss: 3.3546665522065418

Epoch: 52| Step: 0
Training loss: 3.993393448985877
Validation loss: 3.356078568637024

Epoch: 6| Step: 1
Training loss: 3.986058975097346
Validation loss: 3.354859224754473

Epoch: 6| Step: 2
Training loss: 3.976914785552722
Validation loss: 3.354185452972634

Epoch: 6| Step: 3
Training loss: 4.149468417764426
Validation loss: 3.3592891864352254

Epoch: 6| Step: 4
Training loss: 3.2054870828080584
Validation loss: 3.3546742966138647

Epoch: 6| Step: 5
Training loss: 4.3565021195648965
Validation loss: 3.3559350684564997

Epoch: 6| Step: 6
Training loss: 3.671321096644303
Validation loss: 3.35472174237249

Epoch: 6| Step: 7
Training loss: 3.908761155735025
Validation loss: 3.352953330168785

Epoch: 6| Step: 8
Training loss: 2.9155444756577755
Validation loss: 3.353517744092436

Epoch: 6| Step: 9
Training loss: 3.159616167200637
Validation loss: 3.352996452869229

Epoch: 6| Step: 10
Training loss: 3.3920550868311627
Validation loss: 3.352129398087226

Epoch: 6| Step: 11
Training loss: 2.538308181220626
Validation loss: 3.3520847484193275

Epoch: 6| Step: 12
Training loss: 2.098794582091097
Validation loss: 3.354971034407862

Epoch: 6| Step: 13
Training loss: 4.385336735496079
Validation loss: 3.3620426591411388

Epoch: 53| Step: 0
Training loss: 4.030690708840363
Validation loss: 3.360664076470301

Epoch: 6| Step: 1
Training loss: 4.552635083778919
Validation loss: 3.3641357815045323

Epoch: 6| Step: 2
Training loss: 2.897699390624026
Validation loss: 3.3552634778921027

Epoch: 6| Step: 3
Training loss: 3.6112483723954667
Validation loss: 3.3514514930241255

Epoch: 6| Step: 4
Training loss: 4.219688932696426
Validation loss: 3.3496897439754267

Epoch: 6| Step: 5
Training loss: 2.522763850285123
Validation loss: 3.3499011294364283

Epoch: 6| Step: 6
Training loss: 4.1566492333514375
Validation loss: 3.352571569156311

Epoch: 6| Step: 7
Training loss: 2.903261678740678
Validation loss: 3.3591612236302093

Epoch: 6| Step: 8
Training loss: 2.6803077447045593
Validation loss: 3.36196365455174

Epoch: 6| Step: 9
Training loss: 4.06381720682997
Validation loss: 3.3780038228275475

Epoch: 6| Step: 10
Training loss: 3.733217706479188
Validation loss: 3.3539963769891137

Epoch: 6| Step: 11
Training loss: 3.132424803833663
Validation loss: 3.3483842046840055

Epoch: 6| Step: 12
Training loss: 3.1547843627267422
Validation loss: 3.3488442432417016

Epoch: 6| Step: 13
Training loss: 3.9613177777188966
Validation loss: 3.35122102412505

Epoch: 54| Step: 0
Training loss: 4.269965454247698
Validation loss: 3.364958271569412

Epoch: 6| Step: 1
Training loss: 3.6262341733243257
Validation loss: 3.3718539181197293

Epoch: 6| Step: 2
Training loss: 3.321025744854418
Validation loss: 3.360528415285375

Epoch: 6| Step: 3
Training loss: 3.6462765814773803
Validation loss: 3.3592212928965615

Epoch: 6| Step: 4
Training loss: 3.4314588695108283
Validation loss: 3.3569886744778574

Epoch: 6| Step: 5
Training loss: 3.6806851794051307
Validation loss: 3.3548350467259596

Epoch: 6| Step: 6
Training loss: 2.8045967958707445
Validation loss: 3.3544186835188676

Epoch: 6| Step: 7
Training loss: 3.856231768547994
Validation loss: 3.3478919370679403

Epoch: 6| Step: 8
Training loss: 4.177046752668039
Validation loss: 3.352465296990836

Epoch: 6| Step: 9
Training loss: 3.5014024377043147
Validation loss: 3.3485288055407905

Epoch: 6| Step: 10
Training loss: 3.5811123433710828
Validation loss: 3.3494984211634726

Epoch: 6| Step: 11
Training loss: 3.1669206684705165
Validation loss: 3.3506934796723917

Epoch: 6| Step: 12
Training loss: 3.6231062316145195
Validation loss: 3.3516342178742446

Epoch: 6| Step: 13
Training loss: 3.0893631475747187
Validation loss: 3.3525963981872438

Epoch: 55| Step: 0
Training loss: 2.4732422337716176
Validation loss: 3.3538737035679977

Epoch: 6| Step: 1
Training loss: 2.9533587973754827
Validation loss: 3.351835099455537

Epoch: 6| Step: 2
Training loss: 3.9403655509030697
Validation loss: 3.3513996943240136

Epoch: 6| Step: 3
Training loss: 3.7723188617920065
Validation loss: 3.347704698855763

Epoch: 6| Step: 4
Training loss: 3.7698983285485
Validation loss: 3.3489348088057986

Epoch: 6| Step: 5
Training loss: 4.153634302328561
Validation loss: 3.3487204333219114

Epoch: 6| Step: 6
Training loss: 3.689713799560673
Validation loss: 3.348594931471164

Epoch: 6| Step: 7
Training loss: 3.3448649891519233
Validation loss: 3.3518093683778605

Epoch: 6| Step: 8
Training loss: 3.185979742394059
Validation loss: 3.3539367354428564

Epoch: 6| Step: 9
Training loss: 3.6003349678180174
Validation loss: 3.355962448495431

Epoch: 6| Step: 10
Training loss: 4.19921875
Validation loss: 3.348120688728443

Epoch: 6| Step: 11
Training loss: 3.743866673149673
Validation loss: 3.3448394420532312

Epoch: 6| Step: 12
Training loss: 3.0095696407131447
Validation loss: 3.340592873584577

Epoch: 6| Step: 13
Training loss: 4.019813342339539
Validation loss: 3.3418348745128394

Epoch: 56| Step: 0
Training loss: 3.4046443689633383
Validation loss: 3.3406067915001896

Epoch: 6| Step: 1
Training loss: 3.364230173825148
Validation loss: 3.3418947351049795

Epoch: 6| Step: 2
Training loss: 3.5225093997913834
Validation loss: 3.339412169057154

Epoch: 6| Step: 3
Training loss: 3.347619358068673
Validation loss: 3.3404081932557106

Epoch: 6| Step: 4
Training loss: 2.601968452925033
Validation loss: 3.3412301435404186

Epoch: 6| Step: 5
Training loss: 3.6133477612121743
Validation loss: 3.3385978216506706

Epoch: 6| Step: 6
Training loss: 3.8831856930108053
Validation loss: 3.33935130433042

Epoch: 6| Step: 7
Training loss: 3.458775381002714
Validation loss: 3.3381592845427344

Epoch: 6| Step: 8
Training loss: 3.033836283924406
Validation loss: 3.3386549590710897

Epoch: 6| Step: 9
Training loss: 4.423130032529902
Validation loss: 3.338575204452949

Epoch: 6| Step: 10
Training loss: 3.50747957752506
Validation loss: 3.3364506155619913

Epoch: 6| Step: 11
Training loss: 3.977187072029729
Validation loss: 3.333656062120778

Epoch: 6| Step: 12
Training loss: 3.99157280118051
Validation loss: 3.336742209060573

Epoch: 6| Step: 13
Training loss: 3.624097382868614
Validation loss: 3.334443208031597

Epoch: 57| Step: 0
Training loss: 4.04836784723949
Validation loss: 3.3325832689504984

Epoch: 6| Step: 1
Training loss: 3.84067095736018
Validation loss: 3.335414777028877

Epoch: 6| Step: 2
Training loss: 4.03253531850258
Validation loss: 3.335108744636107

Epoch: 6| Step: 3
Training loss: 2.773695383037016
Validation loss: 3.3351222380661945

Epoch: 6| Step: 4
Training loss: 3.266514123222478
Validation loss: 3.333599894130239

Epoch: 6| Step: 5
Training loss: 3.663535659751852
Validation loss: 3.3302923287410873

Epoch: 6| Step: 6
Training loss: 3.1689903032726887
Validation loss: 3.3320206369797156

Epoch: 6| Step: 7
Training loss: 2.6840540950571157
Validation loss: 3.3339958937313616

Epoch: 6| Step: 8
Training loss: 3.659983627824696
Validation loss: 3.331914672651073

Epoch: 6| Step: 9
Training loss: 4.297853670507606
Validation loss: 3.3301976796257757

Epoch: 6| Step: 10
Training loss: 3.4122461860362088
Validation loss: 3.331500880765618

Epoch: 6| Step: 11
Training loss: 4.078299215402966
Validation loss: 3.3297480210908432

Epoch: 6| Step: 12
Training loss: 2.6553432936632033
Validation loss: 3.3310476039256636

Epoch: 6| Step: 13
Training loss: 4.061970602901135
Validation loss: 3.329604335462037

Epoch: 58| Step: 0
Training loss: 3.9049408206533904
Validation loss: 3.330771850773224

Epoch: 6| Step: 1
Training loss: 3.687898000154817
Validation loss: 3.331380635686238

Epoch: 6| Step: 2
Training loss: 3.5893347112568916
Validation loss: 3.331509642454399

Epoch: 6| Step: 3
Training loss: 3.6044907323131037
Validation loss: 3.3312618392158004

Epoch: 6| Step: 4
Training loss: 3.6875905171292387
Validation loss: 3.331226762010522

Epoch: 6| Step: 5
Training loss: 3.1541203027204276
Validation loss: 3.3302277215734817

Epoch: 6| Step: 6
Training loss: 4.02939415137969
Validation loss: 3.3309116231610503

Epoch: 6| Step: 7
Training loss: 3.1022871501738503
Validation loss: 3.338577002838303

Epoch: 6| Step: 8
Training loss: 3.25403872216836
Validation loss: 3.3360989654428215

Epoch: 6| Step: 9
Training loss: 2.1336538590603684
Validation loss: 3.3365110253174346

Epoch: 6| Step: 10
Training loss: 4.033757339343193
Validation loss: 3.3429087394335317

Epoch: 6| Step: 11
Training loss: 3.540318011638948
Validation loss: 3.3383789427266652

Epoch: 6| Step: 12
Training loss: 3.1673795667242266
Validation loss: 3.3282058508033674

Epoch: 6| Step: 13
Training loss: 5.032739264859312
Validation loss: 3.329555067310589

Epoch: 59| Step: 0
Training loss: 4.96937355591306
Validation loss: 3.326699064996563

Epoch: 6| Step: 1
Training loss: 3.890313070883852
Validation loss: 3.326805124941041

Epoch: 6| Step: 2
Training loss: 2.297475308191156
Validation loss: 3.32463597745972

Epoch: 6| Step: 3
Training loss: 3.5883201379410834
Validation loss: 3.325000961122228

Epoch: 6| Step: 4
Training loss: 3.718260147785699
Validation loss: 3.3233615437155133

Epoch: 6| Step: 5
Training loss: 3.6742325377159974
Validation loss: 3.324655822537175

Epoch: 6| Step: 6
Training loss: 3.654975342882641
Validation loss: 3.32573111199642

Epoch: 6| Step: 7
Training loss: 3.560411342901837
Validation loss: 3.324650963064209

Epoch: 6| Step: 8
Training loss: 2.92541045218987
Validation loss: 3.325604178289674

Epoch: 6| Step: 9
Training loss: 3.1964376469245055
Validation loss: 3.323696618295297

Epoch: 6| Step: 10
Training loss: 3.7644671800965956
Validation loss: 3.324357294904755

Epoch: 6| Step: 11
Training loss: 2.7246000118846734
Validation loss: 3.3226156876043524

Epoch: 6| Step: 12
Training loss: 3.539249777312426
Validation loss: 3.3225234586575394

Epoch: 6| Step: 13
Training loss: 3.7176681355342622
Validation loss: 3.322712155979187

Epoch: 60| Step: 0
Training loss: 3.048561294677741
Validation loss: 3.3222625576726457

Epoch: 6| Step: 1
Training loss: 3.756066692024262
Validation loss: 3.323635120215794

Epoch: 6| Step: 2
Training loss: 3.18080932922607
Validation loss: 3.324215893470479

Epoch: 6| Step: 3
Training loss: 4.346477283572448
Validation loss: 3.3224494773587443

Epoch: 6| Step: 4
Training loss: 3.59204817572659
Validation loss: 3.320835767479953

Epoch: 6| Step: 5
Training loss: 3.8989388367130355
Validation loss: 3.322973277027371

Epoch: 6| Step: 6
Training loss: 4.087616497094528
Validation loss: 3.3208790679247358

Epoch: 6| Step: 7
Training loss: 3.5047177807081855
Validation loss: 3.320749841174367

Epoch: 6| Step: 8
Training loss: 3.5890804305270163
Validation loss: 3.32132747726213

Epoch: 6| Step: 9
Training loss: 3.6676061611503634
Validation loss: 3.3200380705815102

Epoch: 6| Step: 10
Training loss: 2.939072208500047
Validation loss: 3.320837498273407

Epoch: 6| Step: 11
Training loss: 3.0971175852283936
Validation loss: 3.319157469162274

Epoch: 6| Step: 12
Training loss: 3.3129692465025213
Validation loss: 3.3196424756217295

Epoch: 6| Step: 13
Training loss: 3.42430021836194
Validation loss: 3.320356722976965

Epoch: 61| Step: 0
Training loss: 3.8861126451093146
Validation loss: 3.3201852510355

Epoch: 6| Step: 1
Training loss: 3.5327086010332716
Validation loss: 3.318374775228869

Epoch: 6| Step: 2
Training loss: 3.528260442467071
Validation loss: 3.3176463883716494

Epoch: 6| Step: 3
Training loss: 3.7262098357433167
Validation loss: 3.320025915026693

Epoch: 6| Step: 4
Training loss: 3.034289537006112
Validation loss: 3.3169655785184253

Epoch: 6| Step: 5
Training loss: 3.9712305201892297
Validation loss: 3.31948017418008

Epoch: 6| Step: 6
Training loss: 4.033205016646045
Validation loss: 3.3170209863475977

Epoch: 6| Step: 7
Training loss: 2.8808110430267724
Validation loss: 3.31609015728685

Epoch: 6| Step: 8
Training loss: 3.889069886007073
Validation loss: 3.316539691809871

Epoch: 6| Step: 9
Training loss: 4.206255913060016
Validation loss: 3.3167673440008194

Epoch: 6| Step: 10
Training loss: 2.853889915989734
Validation loss: 3.3167564038818313

Epoch: 6| Step: 11
Training loss: 3.6411843586435406
Validation loss: 3.3166116792677256

Epoch: 6| Step: 12
Training loss: 2.3824448598943504
Validation loss: 3.3147980405168265

Epoch: 6| Step: 13
Training loss: 3.736137197813896
Validation loss: 3.316152593103148

Epoch: 62| Step: 0
Training loss: 3.1706906066399267
Validation loss: 3.3166466358693203

Epoch: 6| Step: 1
Training loss: 3.3739755276536987
Validation loss: 3.316567092524559

Epoch: 6| Step: 2
Training loss: 4.039218331435416
Validation loss: 3.315805554683996

Epoch: 6| Step: 3
Training loss: 2.7351047087157667
Validation loss: 3.3142141796896163

Epoch: 6| Step: 4
Training loss: 3.535153417428078
Validation loss: 3.3148188717839817

Epoch: 6| Step: 5
Training loss: 2.1700610812331895
Validation loss: 3.3154057771206356

Epoch: 6| Step: 6
Training loss: 3.183225121248321
Validation loss: 3.3139877600298546

Epoch: 6| Step: 7
Training loss: 4.093291511777609
Validation loss: 3.3141895365125067

Epoch: 6| Step: 8
Training loss: 3.574254503748769
Validation loss: 3.3142280119055485

Epoch: 6| Step: 9
Training loss: 4.7835368752233
Validation loss: 3.3159954043103843

Epoch: 6| Step: 10
Training loss: 3.068309645125332
Validation loss: 3.314054568975499

Epoch: 6| Step: 11
Training loss: 4.02036679316842
Validation loss: 3.314732600020208

Epoch: 6| Step: 12
Training loss: 3.3360141146793496
Validation loss: 3.3140261758796674

Epoch: 6| Step: 13
Training loss: 4.052263715140096
Validation loss: 3.3115254781784853

Epoch: 63| Step: 0
Training loss: 3.2277489944490716
Validation loss: 3.314259259877071

Epoch: 6| Step: 1
Training loss: 3.532952362490879
Validation loss: 3.3122834614494328

Epoch: 6| Step: 2
Training loss: 3.429786072446295
Validation loss: 3.313263774697618

Epoch: 6| Step: 3
Training loss: 3.4622265759420165
Validation loss: 3.3128241939327783

Epoch: 6| Step: 4
Training loss: 3.5911885296572765
Validation loss: 3.310928959706683

Epoch: 6| Step: 5
Training loss: 2.9599064866321254
Validation loss: 3.31109213634571

Epoch: 6| Step: 6
Training loss: 3.2409459689920443
Validation loss: 3.310307052956523

Epoch: 6| Step: 7
Training loss: 2.869405860144984
Validation loss: 3.309784915544604

Epoch: 6| Step: 8
Training loss: 4.278635382179998
Validation loss: 3.3109538640849676

Epoch: 6| Step: 9
Training loss: 4.135472961093867
Validation loss: 3.309120173632877

Epoch: 6| Step: 10
Training loss: 3.9559299333498363
Validation loss: 3.310568706413727

Epoch: 6| Step: 11
Training loss: 3.3337646841062645
Validation loss: 3.3109249426541134

Epoch: 6| Step: 12
Training loss: 3.1298281184281223
Validation loss: 3.310333106629938

Epoch: 6| Step: 13
Training loss: 4.549583441142171
Validation loss: 3.309605529379151

Epoch: 64| Step: 0
Training loss: 3.789860780921844
Validation loss: 3.3096353670716674

Epoch: 6| Step: 1
Training loss: 3.7345701031016234
Validation loss: 3.3084511649718

Epoch: 6| Step: 2
Training loss: 3.34093064140206
Validation loss: 3.3094408161374806

Epoch: 6| Step: 3
Training loss: 3.685898901982691
Validation loss: 3.307821600156572

Epoch: 6| Step: 4
Training loss: 3.315239834862433
Validation loss: 3.3067360026613724

Epoch: 6| Step: 5
Training loss: 3.6812378033110504
Validation loss: 3.3091046125761077

Epoch: 6| Step: 6
Training loss: 3.883762419956706
Validation loss: 3.3079091968425196

Epoch: 6| Step: 7
Training loss: 3.784591837434595
Validation loss: 3.3087245378103756

Epoch: 6| Step: 8
Training loss: 3.667647635121869
Validation loss: 3.309625875120467

Epoch: 6| Step: 9
Training loss: 3.0581918113734083
Validation loss: 3.3080581088301613

Epoch: 6| Step: 10
Training loss: 2.940813022484655
Validation loss: 3.309708316463424

Epoch: 6| Step: 11
Training loss: 3.2514366495835163
Validation loss: 3.311345268104809

Epoch: 6| Step: 12
Training loss: 3.241134730009496
Validation loss: 3.308564198131671

Epoch: 6| Step: 13
Training loss: 4.3631614730090815
Validation loss: 3.3093649574156925

Epoch: 65| Step: 0
Training loss: 2.6120073209838153
Validation loss: 3.3078697861385247

Epoch: 6| Step: 1
Training loss: 3.075935010722032
Validation loss: 3.308240306642885

Epoch: 6| Step: 2
Training loss: 4.125833831665855
Validation loss: 3.307481950216697

Epoch: 6| Step: 3
Training loss: 3.3051908934804644
Validation loss: 3.3052311109826156

Epoch: 6| Step: 4
Training loss: 2.5931737788263214
Validation loss: 3.3070624097230543

Epoch: 6| Step: 5
Training loss: 4.127332548075372
Validation loss: 3.306151553989569

Epoch: 6| Step: 6
Training loss: 3.224735952997196
Validation loss: 3.304293794437299

Epoch: 6| Step: 7
Training loss: 3.616721862746803
Validation loss: 3.3067337078368357

Epoch: 6| Step: 8
Training loss: 4.123262444033007
Validation loss: 3.3034968664652475

Epoch: 6| Step: 9
Training loss: 3.0881302780974047
Validation loss: 3.306593174708985

Epoch: 6| Step: 10
Training loss: 3.6637176156150155
Validation loss: 3.306351467079611

Epoch: 6| Step: 11
Training loss: 3.7479583268591776
Validation loss: 3.3050915898102113

Epoch: 6| Step: 12
Training loss: 4.407482651164098
Validation loss: 3.3057277918137378

Epoch: 6| Step: 13
Training loss: 2.989565823777303
Validation loss: 3.3050557865163612

Epoch: 66| Step: 0
Training loss: 3.011497083687546
Validation loss: 3.307504823440104

Epoch: 6| Step: 1
Training loss: 2.627622293662439
Validation loss: 3.3036577291140405

Epoch: 6| Step: 2
Training loss: 3.269064811878574
Validation loss: 3.3018223812184813

Epoch: 6| Step: 3
Training loss: 3.6224961677146634
Validation loss: 3.302588318661999

Epoch: 6| Step: 4
Training loss: 3.773721056407358
Validation loss: 3.301113741072879

Epoch: 6| Step: 5
Training loss: 3.9189656321504738
Validation loss: 3.3027103478722104

Epoch: 6| Step: 6
Training loss: 3.8103530341762495
Validation loss: 3.3016092996553428

Epoch: 6| Step: 7
Training loss: 3.32529597865244
Validation loss: 3.3026597594616347

Epoch: 6| Step: 8
Training loss: 3.123451764912398
Validation loss: 3.3031138941174087

Epoch: 6| Step: 9
Training loss: 3.650558475984801
Validation loss: 3.3007778163095227

Epoch: 6| Step: 10
Training loss: 3.697096670152425
Validation loss: 3.302285178361548

Epoch: 6| Step: 11
Training loss: 3.7360150554525164
Validation loss: 3.300055225764136

Epoch: 6| Step: 12
Training loss: 3.8316016777891106
Validation loss: 3.301544122654628

Epoch: 6| Step: 13
Training loss: 4.093517267731483
Validation loss: 3.303231338113521

Epoch: 67| Step: 0
Training loss: 3.9312557784433757
Validation loss: 3.30280477718831

Epoch: 6| Step: 1
Training loss: 2.6579766439785173
Validation loss: 3.3028706775549646

Epoch: 6| Step: 2
Training loss: 3.3361773438186977
Validation loss: 3.3057784899257148

Epoch: 6| Step: 3
Training loss: 2.7382479895559366
Validation loss: 3.309582551384

Epoch: 6| Step: 4
Training loss: 3.205422521820797
Validation loss: 3.323091498051174

Epoch: 6| Step: 5
Training loss: 3.2123818223642484
Validation loss: 3.317009441129579

Epoch: 6| Step: 6
Training loss: 3.0588160564365845
Validation loss: 3.3130291287671954

Epoch: 6| Step: 7
Training loss: 3.5396498977901447
Validation loss: 3.3040357657027255

Epoch: 6| Step: 8
Training loss: 4.295294675654746
Validation loss: 3.3004395659218178

Epoch: 6| Step: 9
Training loss: 4.018511851419627
Validation loss: 3.2966538035124193

Epoch: 6| Step: 10
Training loss: 3.569590422485717
Validation loss: 3.2991901995736375

Epoch: 6| Step: 11
Training loss: 3.537827164581073
Validation loss: 3.2975817631727447

Epoch: 6| Step: 12
Training loss: 4.09353427464166
Validation loss: 3.29549817735851

Epoch: 6| Step: 13
Training loss: 4.061366231140963
Validation loss: 3.296774935723773

Epoch: 68| Step: 0
Training loss: 3.795169902712407
Validation loss: 3.295623963394522

Epoch: 6| Step: 1
Training loss: 3.2869712723514444
Validation loss: 3.2943354393297026

Epoch: 6| Step: 2
Training loss: 4.014162977482359
Validation loss: 3.2984940915956806

Epoch: 6| Step: 3
Training loss: 3.563188452872454
Validation loss: 3.2978810929814637

Epoch: 6| Step: 4
Training loss: 3.6418064803484023
Validation loss: 3.2974279107525035

Epoch: 6| Step: 5
Training loss: 3.745093505466193
Validation loss: 3.2959683774563535

Epoch: 6| Step: 6
Training loss: 2.7535277194416254
Validation loss: 3.2946560547344457

Epoch: 6| Step: 7
Training loss: 2.984785281434752
Validation loss: 3.2944972815701705

Epoch: 6| Step: 8
Training loss: 3.9344143357253483
Validation loss: 3.295082346352355

Epoch: 6| Step: 9
Training loss: 4.174031932319335
Validation loss: 3.295244017318429

Epoch: 6| Step: 10
Training loss: 2.981514403576295
Validation loss: 3.2930313026753035

Epoch: 6| Step: 11
Training loss: 3.332097078592115
Validation loss: 3.293959292093166

Epoch: 6| Step: 12
Training loss: 2.8090065346380744
Validation loss: 3.2924955691738673

Epoch: 6| Step: 13
Training loss: 4.382490666450794
Validation loss: 3.2922627812829237

Epoch: 69| Step: 0
Training loss: 3.1904373098795538
Validation loss: 3.2915997618457857

Epoch: 6| Step: 1
Training loss: 2.836174232543507
Validation loss: 3.2929258844331404

Epoch: 6| Step: 2
Training loss: 4.337957458118655
Validation loss: 3.291284139911076

Epoch: 6| Step: 3
Training loss: 3.316012553468509
Validation loss: 3.2893269298396746

Epoch: 6| Step: 4
Training loss: 3.588828656255743
Validation loss: 3.2919831368489882

Epoch: 6| Step: 5
Training loss: 3.909758434199477
Validation loss: 3.2906624072161788

Epoch: 6| Step: 6
Training loss: 3.0303708404120973
Validation loss: 3.2911481582617315

Epoch: 6| Step: 7
Training loss: 2.554457347896833
Validation loss: 3.2913233535279542

Epoch: 6| Step: 8
Training loss: 3.4446731631591363
Validation loss: 3.2910234148068365

Epoch: 6| Step: 9
Training loss: 3.6440803600541285
Validation loss: 3.292576569208402

Epoch: 6| Step: 10
Training loss: 4.3822610817614125
Validation loss: 3.2928111925529624

Epoch: 6| Step: 11
Training loss: 3.6863852933553884
Validation loss: 3.2927427691538314

Epoch: 6| Step: 12
Training loss: 3.4750519288937682
Validation loss: 3.298662540975401

Epoch: 6| Step: 13
Training loss: 3.484068989680531
Validation loss: 3.298744134097152

Epoch: 70| Step: 0
Training loss: 3.263903734610773
Validation loss: 3.2922444930006094

Epoch: 6| Step: 1
Training loss: 2.6788738116383235
Validation loss: 3.2919194887785186

Epoch: 6| Step: 2
Training loss: 4.358728723236131
Validation loss: 3.293240535538498

Epoch: 6| Step: 3
Training loss: 4.106190655190933
Validation loss: 3.293349339998978

Epoch: 6| Step: 4
Training loss: 3.0944149959524325
Validation loss: 3.2884645308919085

Epoch: 6| Step: 5
Training loss: 3.6072508271068546
Validation loss: 3.289266966796194

Epoch: 6| Step: 6
Training loss: 4.156610458919881
Validation loss: 3.289423029295311

Epoch: 6| Step: 7
Training loss: 3.3118273933877878
Validation loss: 3.286679500976689

Epoch: 6| Step: 8
Training loss: 3.811683817564811
Validation loss: 3.2875493396250803

Epoch: 6| Step: 9
Training loss: 3.2783672930521828
Validation loss: 3.2858378645629385

Epoch: 6| Step: 10
Training loss: 3.243321526072365
Validation loss: 3.287074704817533

Epoch: 6| Step: 11
Training loss: 2.861791538038706
Validation loss: 3.2847314790945634

Epoch: 6| Step: 12
Training loss: 3.5218421047674875
Validation loss: 3.2831533666793655

Epoch: 6| Step: 13
Training loss: 3.655892770384187
Validation loss: 3.2839726728563594

Epoch: 71| Step: 0
Training loss: 3.7369110561991383
Validation loss: 3.2852344828209814

Epoch: 6| Step: 1
Training loss: 3.3991590413535415
Validation loss: 3.2838078261911363

Epoch: 6| Step: 2
Training loss: 3.588834103801592
Validation loss: 3.2815040626747787

Epoch: 6| Step: 3
Training loss: 3.2728885745747642
Validation loss: 3.284655575763856

Epoch: 6| Step: 4
Training loss: 3.582026590824737
Validation loss: 3.283703942623194

Epoch: 6| Step: 5
Training loss: 4.3065157294814895
Validation loss: 3.284377072658162

Epoch: 6| Step: 6
Training loss: 3.2042728507343323
Validation loss: 3.284004866016443

Epoch: 6| Step: 7
Training loss: 3.3134579982625403
Validation loss: 3.2858439049363155

Epoch: 6| Step: 8
Training loss: 3.7131993518082935
Validation loss: 3.284670426892874

Epoch: 6| Step: 9
Training loss: 3.061173599429991
Validation loss: 3.286733190139538

Epoch: 6| Step: 10
Training loss: 2.8859707039914446
Validation loss: 3.2837256651969566

Epoch: 6| Step: 11
Training loss: 3.406600794096208
Validation loss: 3.282925999569648

Epoch: 6| Step: 12
Training loss: 3.668657427112115
Validation loss: 3.2858784976021447

Epoch: 6| Step: 13
Training loss: 4.147299630244054
Validation loss: 3.287067641114919

Epoch: 72| Step: 0
Training loss: 3.3103074788995657
Validation loss: 3.285507049780129

Epoch: 6| Step: 1
Training loss: 3.54089954520506
Validation loss: 3.2819912855886444

Epoch: 6| Step: 2
Training loss: 4.066172656294956
Validation loss: 3.2883876168254895

Epoch: 6| Step: 3
Training loss: 3.081774721481108
Validation loss: 3.284800472086412

Epoch: 6| Step: 4
Training loss: 4.373781306963413
Validation loss: 3.282142235802706

Epoch: 6| Step: 5
Training loss: 3.5605215635671223
Validation loss: 3.2849907182174114

Epoch: 6| Step: 6
Training loss: 3.3748858397214483
Validation loss: 3.2829115684849763

Epoch: 6| Step: 7
Training loss: 2.9926833894732177
Validation loss: 3.282060495528615

Epoch: 6| Step: 8
Training loss: 3.8410904530126726
Validation loss: 3.280810387730217

Epoch: 6| Step: 9
Training loss: 3.4249352831886855
Validation loss: 3.2789525299405473

Epoch: 6| Step: 10
Training loss: 3.453198462347817
Validation loss: 3.2802213635693827

Epoch: 6| Step: 11
Training loss: 2.93711006336024
Validation loss: 3.2803214357551314

Epoch: 6| Step: 12
Training loss: 3.328091473477699
Validation loss: 3.2804253357857456

Epoch: 6| Step: 13
Training loss: 3.7293884950153595
Validation loss: 3.2789985163206943

Epoch: 73| Step: 0
Training loss: 3.5234795882931764
Validation loss: 3.278253613629661

Epoch: 6| Step: 1
Training loss: 3.2851905049863905
Validation loss: 3.2758004519552038

Epoch: 6| Step: 2
Training loss: 3.9710914733387876
Validation loss: 3.2760356757794615

Epoch: 6| Step: 3
Training loss: 3.4793748774253532
Validation loss: 3.2777382993281785

Epoch: 6| Step: 4
Training loss: 3.2203782787018316
Validation loss: 3.276834488853317

Epoch: 6| Step: 5
Training loss: 3.3216865837800316
Validation loss: 3.274897422583726

Epoch: 6| Step: 6
Training loss: 4.447572264488972
Validation loss: 3.2772323177023086

Epoch: 6| Step: 7
Training loss: 3.085309005668869
Validation loss: 3.274983048960724

Epoch: 6| Step: 8
Training loss: 4.261324436816627
Validation loss: 3.2742054861410708

Epoch: 6| Step: 9
Training loss: 3.28503374195624
Validation loss: 3.2738953452120825

Epoch: 6| Step: 10
Training loss: 3.0672320183405586
Validation loss: 3.2751877873123854

Epoch: 6| Step: 11
Training loss: 3.2974199323788316
Validation loss: 3.2743791655086225

Epoch: 6| Step: 12
Training loss: 3.067857532510712
Validation loss: 3.27347526868202

Epoch: 6| Step: 13
Training loss: 3.5360185951848675
Validation loss: 3.274835653157203

Epoch: 74| Step: 0
Training loss: 3.9145717023128888
Validation loss: 3.274895647157572

Epoch: 6| Step: 1
Training loss: 3.529777827633231
Validation loss: 3.2737244021575376

Epoch: 6| Step: 2
Training loss: 3.9741854954792974
Validation loss: 3.273487451428564

Epoch: 6| Step: 3
Training loss: 3.633849949520129
Validation loss: 3.274855225422324

Epoch: 6| Step: 4
Training loss: 3.356361634513012
Validation loss: 3.2726722680604388

Epoch: 6| Step: 5
Training loss: 2.884071798703299
Validation loss: 3.2714634895668184

Epoch: 6| Step: 6
Training loss: 3.1308290666908705
Validation loss: 3.2715630107667812

Epoch: 6| Step: 7
Training loss: 3.6293824112390967
Validation loss: 3.272800308454411

Epoch: 6| Step: 8
Training loss: 4.489519630682355
Validation loss: 3.271325242064837

Epoch: 6| Step: 9
Training loss: 4.105018307904063
Validation loss: 3.272531536601522

Epoch: 6| Step: 10
Training loss: 3.104290202368725
Validation loss: 3.271929331876445

Epoch: 6| Step: 11
Training loss: 2.1465419105545296
Validation loss: 3.276055244787935

Epoch: 6| Step: 12
Training loss: 3.0196983222092437
Validation loss: 3.2779925074829404

Epoch: 6| Step: 13
Training loss: 3.5822248000973667
Validation loss: 3.275559501758924

Epoch: 75| Step: 0
Training loss: 2.9913654044653635
Validation loss: 3.2778311376838265

Epoch: 6| Step: 1
Training loss: 4.031130530191305
Validation loss: 3.275922842401221

Epoch: 6| Step: 2
Training loss: 3.9119866323808252
Validation loss: 3.2747969028272044

Epoch: 6| Step: 3
Training loss: 3.388187217682977
Validation loss: 3.26905917495614

Epoch: 6| Step: 4
Training loss: 3.658603790875475
Validation loss: 3.2694840781819536

Epoch: 6| Step: 5
Training loss: 2.521898963937267
Validation loss: 3.26996735478654

Epoch: 6| Step: 6
Training loss: 3.3218551104031793
Validation loss: 3.2687745087125806

Epoch: 6| Step: 7
Training loss: 3.1881159766914005
Validation loss: 3.267943139480997

Epoch: 6| Step: 8
Training loss: 4.3398110073444185
Validation loss: 3.268586543880141

Epoch: 6| Step: 9
Training loss: 3.972503569153034
Validation loss: 3.2677460537652196

Epoch: 6| Step: 10
Training loss: 3.7199464043478776
Validation loss: 3.2672382069048647

Epoch: 6| Step: 11
Training loss: 3.0426554879772483
Validation loss: 3.2658226949164226

Epoch: 6| Step: 12
Training loss: 2.9333541508138223
Validation loss: 3.2667649105744223

Epoch: 6| Step: 13
Training loss: 3.709165001237973
Validation loss: 3.266300797791491

Epoch: 76| Step: 0
Training loss: 2.7533377419067753
Validation loss: 3.2666261259752303

Epoch: 6| Step: 1
Training loss: 4.103641121355626
Validation loss: 3.26725920251993

Epoch: 6| Step: 2
Training loss: 3.1231320711292088
Validation loss: 3.2642616880015205

Epoch: 6| Step: 3
Training loss: 3.86092997125303
Validation loss: 3.2647955126997044

Epoch: 6| Step: 4
Training loss: 3.7789975858561022
Validation loss: 3.2648273759210515

Epoch: 6| Step: 5
Training loss: 3.1131357424630517
Validation loss: 3.2660045910494993

Epoch: 6| Step: 6
Training loss: 3.6059099218846407
Validation loss: 3.264808079620238

Epoch: 6| Step: 7
Training loss: 3.175311702536329
Validation loss: 3.2676185316249104

Epoch: 6| Step: 8
Training loss: 3.735482279167068
Validation loss: 3.2676577358199017

Epoch: 6| Step: 9
Training loss: 2.595093344771747
Validation loss: 3.265636844636099

Epoch: 6| Step: 10
Training loss: 4.150161988187719
Validation loss: 3.267491771052026

Epoch: 6| Step: 11
Training loss: 3.4495948940660415
Validation loss: 3.2746117294144192

Epoch: 6| Step: 12
Training loss: 3.3693638116745963
Validation loss: 3.265013234588856

Epoch: 6| Step: 13
Training loss: 4.055423853461631
Validation loss: 3.268189509132016

Epoch: 77| Step: 0
Training loss: 3.2415167792676067
Validation loss: 3.270204432790752

Epoch: 6| Step: 1
Training loss: 3.0459778076084794
Validation loss: 3.2701099322883245

Epoch: 6| Step: 2
Training loss: 3.2727580309877067
Validation loss: 3.2746797065134867

Epoch: 6| Step: 3
Training loss: 3.7544308235358153
Validation loss: 3.2718278535421437

Epoch: 6| Step: 4
Training loss: 3.7159223304408746
Validation loss: 3.2776285988574294

Epoch: 6| Step: 5
Training loss: 3.7298803374703784
Validation loss: 3.2649529019577117

Epoch: 6| Step: 6
Training loss: 2.9429044314961916
Validation loss: 3.26292708908076

Epoch: 6| Step: 7
Training loss: 3.962700626336449
Validation loss: 3.263450676283145

Epoch: 6| Step: 8
Training loss: 3.695083965952857
Validation loss: 3.262948165076659

Epoch: 6| Step: 9
Training loss: 3.071507345184282
Validation loss: 3.2621352904072864

Epoch: 6| Step: 10
Training loss: 3.7094235192896194
Validation loss: 3.2625570737713487

Epoch: 6| Step: 11
Training loss: 3.8678780603843292
Validation loss: 3.2608546220027734

Epoch: 6| Step: 12
Training loss: 3.7051181499468973
Validation loss: 3.2600855809442235

Epoch: 6| Step: 13
Training loss: 2.7246783285405556
Validation loss: 3.258567272703405

Epoch: 78| Step: 0
Training loss: 3.7398675723778427
Validation loss: 3.2590943118970133

Epoch: 6| Step: 1
Training loss: 3.7170978370169454
Validation loss: 3.261262039396729

Epoch: 6| Step: 2
Training loss: 3.061365968587867
Validation loss: 3.260408433651324

Epoch: 6| Step: 3
Training loss: 3.439319198574424
Validation loss: 3.2620947482766995

Epoch: 6| Step: 4
Training loss: 3.23122115869397
Validation loss: 3.2617693823385245

Epoch: 6| Step: 5
Training loss: 3.587271249104037
Validation loss: 3.2613315587519085

Epoch: 6| Step: 6
Training loss: 3.275254939981772
Validation loss: 3.2611080473095906

Epoch: 6| Step: 7
Training loss: 2.8290697068990966
Validation loss: 3.2617226971813693

Epoch: 6| Step: 8
Training loss: 3.0148853719249704
Validation loss: 3.2601835740282024

Epoch: 6| Step: 9
Training loss: 4.069658281757012
Validation loss: 3.258775518115353

Epoch: 6| Step: 10
Training loss: 4.36368033719303
Validation loss: 3.257076715936531

Epoch: 6| Step: 11
Training loss: 2.833445060621444
Validation loss: 3.258502378711016

Epoch: 6| Step: 12
Training loss: 3.8824844682312807
Validation loss: 3.25821759584065

Epoch: 6| Step: 13
Training loss: 3.5561956203707688
Validation loss: 3.2556855706955186

Epoch: 79| Step: 0
Training loss: 4.076282070189337
Validation loss: 3.2594860286838534

Epoch: 6| Step: 1
Training loss: 3.36570037785723
Validation loss: 3.256615873290349

Epoch: 6| Step: 2
Training loss: 4.3673796637060445
Validation loss: 3.2567258375882195

Epoch: 6| Step: 3
Training loss: 3.3832879205922586
Validation loss: 3.257771302858313

Epoch: 6| Step: 4
Training loss: 3.472224789088678
Validation loss: 3.260013221711017

Epoch: 6| Step: 5
Training loss: 3.0950114443171453
Validation loss: 3.257561350820098

Epoch: 6| Step: 6
Training loss: 2.8027512181005227
Validation loss: 3.2558372318608755

Epoch: 6| Step: 7
Training loss: 3.58013726168425
Validation loss: 3.257355668276224

Epoch: 6| Step: 8
Training loss: 4.235244267612868
Validation loss: 3.255472220801635

Epoch: 6| Step: 9
Training loss: 2.9823975727562586
Validation loss: 3.2569990409686875

Epoch: 6| Step: 10
Training loss: 3.6171523024492305
Validation loss: 3.2546481913689465

Epoch: 6| Step: 11
Training loss: 2.221120508269612
Validation loss: 3.2563236013715335

Epoch: 6| Step: 12
Training loss: 3.7360810409022784
Validation loss: 3.2551220476425367

Epoch: 6| Step: 13
Training loss: 3.2720294555233607
Validation loss: 3.2557059777959716

Epoch: 80| Step: 0
Training loss: 3.2836633435720017
Validation loss: 3.251948727643524

Epoch: 6| Step: 1
Training loss: 3.773357635347898
Validation loss: 3.254479975112947

Epoch: 6| Step: 2
Training loss: 3.3481661431620737
Validation loss: 3.254455531862946

Epoch: 6| Step: 3
Training loss: 2.6745226496523484
Validation loss: 3.2537315581853234

Epoch: 6| Step: 4
Training loss: 2.8299483854621594
Validation loss: 3.253873860686061

Epoch: 6| Step: 5
Training loss: 3.4848008515692337
Validation loss: 3.2538625483802357

Epoch: 6| Step: 6
Training loss: 3.128058805727578
Validation loss: 3.251103389786344

Epoch: 6| Step: 7
Training loss: 3.8640833254452325
Validation loss: 3.2497606907179146

Epoch: 6| Step: 8
Training loss: 3.919488553139105
Validation loss: 3.2515348788828993

Epoch: 6| Step: 9
Training loss: 4.290873383225045
Validation loss: 3.25114544103088

Epoch: 6| Step: 10
Training loss: 3.406549283099905
Validation loss: 3.252191446835674

Epoch: 6| Step: 11
Training loss: 3.3431331742964625
Validation loss: 3.2518798496650656

Epoch: 6| Step: 12
Training loss: 2.8781609780447566
Validation loss: 3.2511445010975137

Epoch: 6| Step: 13
Training loss: 4.673443279052345
Validation loss: 3.2522919384945546

Epoch: 81| Step: 0
Training loss: 3.6518231842005373
Validation loss: 3.250725935643234

Epoch: 6| Step: 1
Training loss: 3.8554441379739375
Validation loss: 3.2528705840360774

Epoch: 6| Step: 2
Training loss: 3.2128165656832954
Validation loss: 3.2493200568985956

Epoch: 6| Step: 3
Training loss: 3.5898647369999965
Validation loss: 3.2500214982248594

Epoch: 6| Step: 4
Training loss: 3.014713446061704
Validation loss: 3.249439208473192

Epoch: 6| Step: 5
Training loss: 3.6904415747195425
Validation loss: 3.2485500142802697

Epoch: 6| Step: 6
Training loss: 3.151357200944821
Validation loss: 3.2472239565931442

Epoch: 6| Step: 7
Training loss: 2.8505014614174415
Validation loss: 3.249026194438124

Epoch: 6| Step: 8
Training loss: 3.1042210789633007
Validation loss: 3.2499403944142298

Epoch: 6| Step: 9
Training loss: 3.973587332123297
Validation loss: 3.2488529067818925

Epoch: 6| Step: 10
Training loss: 4.024424133806556
Validation loss: 3.2490020099984736

Epoch: 6| Step: 11
Training loss: 3.048547373814792
Validation loss: 3.24847555811557

Epoch: 6| Step: 12
Training loss: 3.168573474669616
Validation loss: 3.24782842936575

Epoch: 6| Step: 13
Training loss: 4.61454209193737
Validation loss: 3.2474982916876347

Epoch: 82| Step: 0
Training loss: 3.357390771425516
Validation loss: 3.2477820789948573

Epoch: 6| Step: 1
Training loss: 3.0734313189042446
Validation loss: 3.247386447870465

Epoch: 6| Step: 2
Training loss: 3.667724991276377
Validation loss: 3.2460099196580643

Epoch: 6| Step: 3
Training loss: 3.527136373074154
Validation loss: 3.2461568150210605

Epoch: 6| Step: 4
Training loss: 3.7795604367481332
Validation loss: 3.2467285473790586

Epoch: 6| Step: 5
Training loss: 3.219651771812952
Validation loss: 3.2463735307819013

Epoch: 6| Step: 6
Training loss: 2.691581554267889
Validation loss: 3.246039998371209

Epoch: 6| Step: 7
Training loss: 3.2752454767611594
Validation loss: 3.245983424728745

Epoch: 6| Step: 8
Training loss: 4.150742632131431
Validation loss: 3.245658473646486

Epoch: 6| Step: 9
Training loss: 3.006759340277615
Validation loss: 3.246182157883883

Epoch: 6| Step: 10
Training loss: 3.689670118147354
Validation loss: 3.2453954007231625

Epoch: 6| Step: 11
Training loss: 3.742900485803872
Validation loss: 3.2442248189407477

Epoch: 6| Step: 12
Training loss: 3.6101299338587887
Validation loss: 3.241968501404528

Epoch: 6| Step: 13
Training loss: 3.913242642544818
Validation loss: 3.2440426246229275

Epoch: 83| Step: 0
Training loss: 3.9438203010399104
Validation loss: 3.24074920724159

Epoch: 6| Step: 1
Training loss: 3.633710852675547
Validation loss: 3.2419602766299622

Epoch: 6| Step: 2
Training loss: 3.466538145054891
Validation loss: 3.243269113366613

Epoch: 6| Step: 3
Training loss: 3.9236900719243333
Validation loss: 3.2442157567229577

Epoch: 6| Step: 4
Training loss: 4.175498046406784
Validation loss: 3.243181746962094

Epoch: 6| Step: 5
Training loss: 3.8144099969960106
Validation loss: 3.241320509322277

Epoch: 6| Step: 6
Training loss: 3.166200419450792
Validation loss: 3.2431533879058545

Epoch: 6| Step: 7
Training loss: 3.6193598574316828
Validation loss: 3.24311515227106

Epoch: 6| Step: 8
Training loss: 2.980208759292275
Validation loss: 3.2419307768702907

Epoch: 6| Step: 9
Training loss: 3.431414401870354
Validation loss: 3.2396412400337185

Epoch: 6| Step: 10
Training loss: 2.939181718938269
Validation loss: 3.240110823598089

Epoch: 6| Step: 11
Training loss: 2.961394020658727
Validation loss: 3.2412550857389073

Epoch: 6| Step: 12
Training loss: 3.107366785583724
Validation loss: 3.2403818897858163

Epoch: 6| Step: 13
Training loss: 3.157127938115108
Validation loss: 3.2405127337073476

Epoch: 84| Step: 0
Training loss: 3.109092354507962
Validation loss: 3.2413230908996553

Epoch: 6| Step: 1
Training loss: 3.2702599446046556
Validation loss: 3.240609813987694

Epoch: 6| Step: 2
Training loss: 3.9216697608772346
Validation loss: 3.240594284692548

Epoch: 6| Step: 3
Training loss: 3.251492231087259
Validation loss: 3.2389368296423604

Epoch: 6| Step: 4
Training loss: 4.130403158909182
Validation loss: 3.2391409591544096

Epoch: 6| Step: 5
Training loss: 3.5573972329839956
Validation loss: 3.2390730799290126

Epoch: 6| Step: 6
Training loss: 3.2520315716420316
Validation loss: 3.240624287888291

Epoch: 6| Step: 7
Training loss: 3.3723409562328435
Validation loss: 3.2389928535945596

Epoch: 6| Step: 8
Training loss: 3.5505585889173776
Validation loss: 3.2388370151350663

Epoch: 6| Step: 9
Training loss: 4.004583117329882
Validation loss: 3.23930901751292

Epoch: 6| Step: 10
Training loss: 3.0268611006385138
Validation loss: 3.237803624198763

Epoch: 6| Step: 11
Training loss: 3.902973968051553
Validation loss: 3.2385019505505666

Epoch: 6| Step: 12
Training loss: 3.0414471133348497
Validation loss: 3.237714392887644

Epoch: 6| Step: 13
Training loss: 2.6620912838137114
Validation loss: 3.2376708028999115

Epoch: 85| Step: 0
Training loss: 3.2440683080064328
Validation loss: 3.237717806360117

Epoch: 6| Step: 1
Training loss: 3.6530604347808335
Validation loss: 3.2385701607600077

Epoch: 6| Step: 2
Training loss: 3.4579693399706075
Validation loss: 3.2390234130006688

Epoch: 6| Step: 3
Training loss: 3.083739296933617
Validation loss: 3.2372759174313357

Epoch: 6| Step: 4
Training loss: 2.8013150226582253
Validation loss: 3.2354142648187616

Epoch: 6| Step: 5
Training loss: 3.534153107845961
Validation loss: 3.2349742088437896

Epoch: 6| Step: 6
Training loss: 4.058205550190584
Validation loss: 3.237185722044353

Epoch: 6| Step: 7
Training loss: 4.395964176104902
Validation loss: 3.234614742192537

Epoch: 6| Step: 8
Training loss: 3.7645192402441587
Validation loss: 3.235632572432024

Epoch: 6| Step: 9
Training loss: 2.73267106507577
Validation loss: 3.2359464360164725

Epoch: 6| Step: 10
Training loss: 2.818525852671523
Validation loss: 3.237658361857722

Epoch: 6| Step: 11
Training loss: 2.7795615911245752
Validation loss: 3.237412603467769

Epoch: 6| Step: 12
Training loss: 4.459420662788506
Validation loss: 3.242073900189885

Epoch: 6| Step: 13
Training loss: 3.0681547003167364
Validation loss: 3.237143649432786

Epoch: 86| Step: 0
Training loss: 4.082869886191373
Validation loss: 3.234287213412314

Epoch: 6| Step: 1
Training loss: 3.460378356268325
Validation loss: 3.233993004399931

Epoch: 6| Step: 2
Training loss: 3.271137166743006
Validation loss: 3.2355606563579107

Epoch: 6| Step: 3
Training loss: 3.7044949472263933
Validation loss: 3.2325789133357574

Epoch: 6| Step: 4
Training loss: 3.672171592908435
Validation loss: 3.231258714708224

Epoch: 6| Step: 5
Training loss: 3.137852142147396
Validation loss: 3.2315857975852684

Epoch: 6| Step: 6
Training loss: 3.5802896273790434
Validation loss: 3.232498858919664

Epoch: 6| Step: 7
Training loss: 3.3763656678877387
Validation loss: 3.231246525077961

Epoch: 6| Step: 8
Training loss: 3.022139869608866
Validation loss: 3.2305156241456867

Epoch: 6| Step: 9
Training loss: 3.0167321263020344
Validation loss: 3.2311688385095985

Epoch: 6| Step: 10
Training loss: 3.0773150157724882
Validation loss: 3.2308683261725544

Epoch: 6| Step: 11
Training loss: 3.352519434475021
Validation loss: 3.2308443906547875

Epoch: 6| Step: 12
Training loss: 3.5714916060198316
Validation loss: 3.2293985755256247

Epoch: 6| Step: 13
Training loss: 4.507533866429274
Validation loss: 3.2305524590794303

Epoch: 87| Step: 0
Training loss: 3.636798206284933
Validation loss: 3.229429778230914

Epoch: 6| Step: 1
Training loss: 2.8239556871995357
Validation loss: 3.229993273909228

Epoch: 6| Step: 2
Training loss: 3.5255252041054415
Validation loss: 3.2295626939643123

Epoch: 6| Step: 3
Training loss: 3.4789896175693418
Validation loss: 3.2295363205037773

Epoch: 6| Step: 4
Training loss: 4.332650032945588
Validation loss: 3.226630380219333

Epoch: 6| Step: 5
Training loss: 3.9530671006135383
Validation loss: 3.229070186596096

Epoch: 6| Step: 6
Training loss: 2.3670190933804767
Validation loss: 3.228394153507058

Epoch: 6| Step: 7
Training loss: 2.082958823556607
Validation loss: 3.2284197565064696

Epoch: 6| Step: 8
Training loss: 3.5788939869888545
Validation loss: 3.227845318100757

Epoch: 6| Step: 9
Training loss: 3.292113567548693
Validation loss: 3.2286092101685484

Epoch: 6| Step: 10
Training loss: 3.4585316306257865
Validation loss: 3.229165644385857

Epoch: 6| Step: 11
Training loss: 4.112863198796746
Validation loss: 3.2263536906850985

Epoch: 6| Step: 12
Training loss: 4.288167224270825
Validation loss: 3.226402052479609

Epoch: 6| Step: 13
Training loss: 2.1432417864947477
Validation loss: 3.228020114701876

Epoch: 88| Step: 0
Training loss: 3.8533595846749304
Validation loss: 3.2269409771321262

Epoch: 6| Step: 1
Training loss: 3.7631166580125472
Validation loss: 3.2264159687567897

Epoch: 6| Step: 2
Training loss: 2.0837129882747485
Validation loss: 3.227243047530516

Epoch: 6| Step: 3
Training loss: 3.468456908894418
Validation loss: 3.225076016923453

Epoch: 6| Step: 4
Training loss: 4.401265889913471
Validation loss: 3.229799569170476

Epoch: 6| Step: 5
Training loss: 3.512303253854042
Validation loss: 3.2273434041082

Epoch: 6| Step: 6
Training loss: 3.1308712545587163
Validation loss: 3.2280515118036264

Epoch: 6| Step: 7
Training loss: 3.9250343029685717
Validation loss: 3.2252605449045846

Epoch: 6| Step: 8
Training loss: 4.104063597545159
Validation loss: 3.2233895128313472

Epoch: 6| Step: 9
Training loss: 3.4504665999079136
Validation loss: 3.2233298963465713

Epoch: 6| Step: 10
Training loss: 2.9438838984981923
Validation loss: 3.2236946826866624

Epoch: 6| Step: 11
Training loss: 3.2069423351902278
Validation loss: 3.2236304616973737

Epoch: 6| Step: 12
Training loss: 3.1272582477714237
Validation loss: 3.2223556526524586

Epoch: 6| Step: 13
Training loss: 2.5171623508137104
Validation loss: 3.2206683083021717

Epoch: 89| Step: 0
Training loss: 3.4515468391557054
Validation loss: 3.2204339249781193

Epoch: 6| Step: 1
Training loss: 3.626858596514864
Validation loss: 3.221176440330177

Epoch: 6| Step: 2
Training loss: 3.090949746746793
Validation loss: 3.221063996133213

Epoch: 6| Step: 3
Training loss: 3.4092706008717264
Validation loss: 3.2214332831020025

Epoch: 6| Step: 4
Training loss: 3.866794635584385
Validation loss: 3.219838819319983

Epoch: 6| Step: 5
Training loss: 2.910110043152464
Validation loss: 3.2185184830768834

Epoch: 6| Step: 6
Training loss: 3.4755037560089366
Validation loss: 3.220047237437261

Epoch: 6| Step: 7
Training loss: 3.4621634970524235
Validation loss: 3.2217203196563102

Epoch: 6| Step: 8
Training loss: 4.352914706242167
Validation loss: 3.2175879335586526

Epoch: 6| Step: 9
Training loss: 2.6463910413661926
Validation loss: 3.2188940337566523

Epoch: 6| Step: 10
Training loss: 2.907978815224575
Validation loss: 3.2169517561840526

Epoch: 6| Step: 11
Training loss: 3.372360327495684
Validation loss: 3.215854542340311

Epoch: 6| Step: 12
Training loss: 3.9985833043432346
Validation loss: 3.216123097384919

Epoch: 6| Step: 13
Training loss: 3.646300512989882
Validation loss: 3.2173369464257915

Epoch: 90| Step: 0
Training loss: 3.020892824486041
Validation loss: 3.2136422224306176

Epoch: 6| Step: 1
Training loss: 3.3635571374396616
Validation loss: 3.2135109473739107

Epoch: 6| Step: 2
Training loss: 2.5998277350358374
Validation loss: 3.212868192103006

Epoch: 6| Step: 3
Training loss: 3.025208577933502
Validation loss: 3.2151743032209223

Epoch: 6| Step: 4
Training loss: 3.4833999432730836
Validation loss: 3.2136126454052296

Epoch: 6| Step: 5
Training loss: 3.7185343190966793
Validation loss: 3.2135510270576106

Epoch: 6| Step: 6
Training loss: 3.2308997313024848
Validation loss: 3.2113824255712218

Epoch: 6| Step: 7
Training loss: 4.1686205796679845
Validation loss: 3.212024158834503

Epoch: 6| Step: 8
Training loss: 3.758620462776619
Validation loss: 3.2148169655193017

Epoch: 6| Step: 9
Training loss: 3.195839239228589
Validation loss: 3.2120292741010568

Epoch: 6| Step: 10
Training loss: 4.24115056243724
Validation loss: 3.215553572250169

Epoch: 6| Step: 11
Training loss: 3.211441483125005
Validation loss: 3.218279286337532

Epoch: 6| Step: 12
Training loss: 3.5150185295039837
Validation loss: 3.2149201548781523

Epoch: 6| Step: 13
Training loss: 3.5230850753971765
Validation loss: 3.2119761671969096

Epoch: 91| Step: 0
Training loss: 3.6046825473389252
Validation loss: 3.2107598491359415

Epoch: 6| Step: 1
Training loss: 3.875669236997261
Validation loss: 3.2118383842962626

Epoch: 6| Step: 2
Training loss: 3.2538804583311562
Validation loss: 3.2142727427913456

Epoch: 6| Step: 3
Training loss: 3.0009239681264144
Validation loss: 3.210689972565134

Epoch: 6| Step: 4
Training loss: 3.9565323329661597
Validation loss: 3.2150631162913665

Epoch: 6| Step: 5
Training loss: 2.7886157279047037
Validation loss: 3.2097430675168575

Epoch: 6| Step: 6
Training loss: 3.7292137071992
Validation loss: 3.2085772739762812

Epoch: 6| Step: 7
Training loss: 4.035852215287088
Validation loss: 3.2090442436109523

Epoch: 6| Step: 8
Training loss: 3.380889839550785
Validation loss: 3.209670464331968

Epoch: 6| Step: 9
Training loss: 3.6069387165021323
Validation loss: 3.21113180765176

Epoch: 6| Step: 10
Training loss: 3.6308772357010946
Validation loss: 3.2091405343445634

Epoch: 6| Step: 11
Training loss: 2.794988752693926
Validation loss: 3.2102651390873276

Epoch: 6| Step: 12
Training loss: 3.376841572496007
Validation loss: 3.214436732284936

Epoch: 6| Step: 13
Training loss: 2.590906813953622
Validation loss: 3.208663920734264

Epoch: 92| Step: 0
Training loss: 3.231012042671035
Validation loss: 3.206057498979342

Epoch: 6| Step: 1
Training loss: 3.069761115108635
Validation loss: 3.2111791373038865

Epoch: 6| Step: 2
Training loss: 3.1784844149318014
Validation loss: 3.211146249959826

Epoch: 6| Step: 3
Training loss: 3.698332441712923
Validation loss: 3.208925248257939

Epoch: 6| Step: 4
Training loss: 3.9106073109825856
Validation loss: 3.208149210442633

Epoch: 6| Step: 5
Training loss: 3.06270567534198
Validation loss: 3.206026027222082

Epoch: 6| Step: 6
Training loss: 3.295445715435001
Validation loss: 3.2080919734034077

Epoch: 6| Step: 7
Training loss: 3.9257780919607943
Validation loss: 3.2064093446342126

Epoch: 6| Step: 8
Training loss: 3.2549676343301956
Validation loss: 3.2091657932677484

Epoch: 6| Step: 9
Training loss: 4.078454716825634
Validation loss: 3.2026692904395113

Epoch: 6| Step: 10
Training loss: 2.287051101580692
Validation loss: 3.204344947376543

Epoch: 6| Step: 11
Training loss: 2.9509876731478077
Validation loss: 3.2059593380288978

Epoch: 6| Step: 12
Training loss: 4.338478017693505
Validation loss: 3.204743388200466

Epoch: 6| Step: 13
Training loss: 3.5654132375596284
Validation loss: 3.205505689317691

Epoch: 93| Step: 0
Training loss: 4.228527803821954
Validation loss: 3.204775309323017

Epoch: 6| Step: 1
Training loss: 3.735950345185205
Validation loss: 3.204621148415629

Epoch: 6| Step: 2
Training loss: 3.6528556261038694
Validation loss: 3.2051055987612345

Epoch: 6| Step: 3
Training loss: 3.6675511651607895
Validation loss: 3.2052162848865624

Epoch: 6| Step: 4
Training loss: 3.0295207016560712
Validation loss: 3.2052492570695863

Epoch: 6| Step: 5
Training loss: 3.074304678853879
Validation loss: 3.2082472029078355

Epoch: 6| Step: 6
Training loss: 3.0103028131798593
Validation loss: 3.2054934105530046

Epoch: 6| Step: 7
Training loss: 3.6834466931144294
Validation loss: 3.203472729448309

Epoch: 6| Step: 8
Training loss: 3.7497642442982175
Validation loss: 3.2023664607289013

Epoch: 6| Step: 9
Training loss: 3.6652999122384613
Validation loss: 3.203957790320041

Epoch: 6| Step: 10
Training loss: 3.0665539748453225
Validation loss: 3.2014678005640187

Epoch: 6| Step: 11
Training loss: 3.3748777861896433
Validation loss: 3.2071077962358094

Epoch: 6| Step: 12
Training loss: 2.6853506675484
Validation loss: 3.2035188086188264

Epoch: 6| Step: 13
Training loss: 3.2337494028604765
Validation loss: 3.204207823634501

Epoch: 94| Step: 0
Training loss: 2.8084173452185337
Validation loss: 3.2065124495775383

Epoch: 6| Step: 1
Training loss: 3.263608903351571
Validation loss: 3.203341253720576

Epoch: 6| Step: 2
Training loss: 3.259943496120813
Validation loss: 3.2058078002535573

Epoch: 6| Step: 3
Training loss: 3.1212657742603938
Validation loss: 3.2028132333205828

Epoch: 6| Step: 4
Training loss: 3.8529099898667045
Validation loss: 3.2028738896353945

Epoch: 6| Step: 5
Training loss: 3.9471066465078253
Validation loss: 3.2045930633091504

Epoch: 6| Step: 6
Training loss: 3.6888882884697893
Validation loss: 3.201176420589704

Epoch: 6| Step: 7
Training loss: 4.197073625421874
Validation loss: 3.203597990740178

Epoch: 6| Step: 8
Training loss: 3.25283249887649
Validation loss: 3.200899435355221

Epoch: 6| Step: 9
Training loss: 2.69734765217416
Validation loss: 3.207441619681151

Epoch: 6| Step: 10
Training loss: 3.232084486027074
Validation loss: 3.2021761717715473

Epoch: 6| Step: 11
Training loss: 4.455198855773154
Validation loss: 3.199381164926001

Epoch: 6| Step: 12
Training loss: 3.366793793144546
Validation loss: 3.211580133987021

Epoch: 6| Step: 13
Training loss: 1.4542641225400907
Validation loss: 3.201957006672206

Epoch: 95| Step: 0
Training loss: 3.794138734813696
Validation loss: 3.2007558941853946

Epoch: 6| Step: 1
Training loss: 3.308665665494619
Validation loss: 3.1993132113818348

Epoch: 6| Step: 2
Training loss: 3.0508286085372665
Validation loss: 3.1978984122907526

Epoch: 6| Step: 3
Training loss: 3.313195353525439
Validation loss: 3.1985151612606804

Epoch: 6| Step: 4
Training loss: 4.1141545454566195
Validation loss: 3.1978509149381824

Epoch: 6| Step: 5
Training loss: 3.8552943598952893
Validation loss: 3.195317601101739

Epoch: 6| Step: 6
Training loss: 2.42483615125076
Validation loss: 3.197748340440021

Epoch: 6| Step: 7
Training loss: 3.0450996117044573
Validation loss: 3.196303089031451

Epoch: 6| Step: 8
Training loss: 3.955984054232437
Validation loss: 3.195304743228871

Epoch: 6| Step: 9
Training loss: 2.489894182492209
Validation loss: 3.197004505537086

Epoch: 6| Step: 10
Training loss: 3.39275254683497
Validation loss: 3.198349739025406

Epoch: 6| Step: 11
Training loss: 3.522856061712282
Validation loss: 3.1972210794212574

Epoch: 6| Step: 12
Training loss: 4.3292682115665535
Validation loss: 3.197822219615274

Epoch: 6| Step: 13
Training loss: 2.6016670641347943
Validation loss: 3.196941899897625

Epoch: 96| Step: 0
Training loss: 3.3003485582244076
Validation loss: 3.1952419999823123

Epoch: 6| Step: 1
Training loss: 2.3378042461655966
Validation loss: 3.1990042563260217

Epoch: 6| Step: 2
Training loss: 2.8287366342671283
Validation loss: 3.198598911506256

Epoch: 6| Step: 3
Training loss: 4.888177131128045
Validation loss: 3.197735012921343

Epoch: 6| Step: 4
Training loss: 3.5319138974660422
Validation loss: 3.1975634033286977

Epoch: 6| Step: 5
Training loss: 3.953770641329707
Validation loss: 3.1971519004426385

Epoch: 6| Step: 6
Training loss: 3.8367444217159368
Validation loss: 3.1953586262438654

Epoch: 6| Step: 7
Training loss: 3.373301608523233
Validation loss: 3.196880351566027

Epoch: 6| Step: 8
Training loss: 2.3339121532039915
Validation loss: 3.193282222226592

Epoch: 6| Step: 9
Training loss: 4.106503255573665
Validation loss: 3.193307192334896

Epoch: 6| Step: 10
Training loss: 3.9527722830848515
Validation loss: 3.191412852274652

Epoch: 6| Step: 11
Training loss: 2.746407850379736
Validation loss: 3.193433912845519

Epoch: 6| Step: 12
Training loss: 2.7847304266102957
Validation loss: 3.1922151956593603

Epoch: 6| Step: 13
Training loss: 2.942061109456658
Validation loss: 3.191571830506407

Epoch: 97| Step: 0
Training loss: 3.780497578564007
Validation loss: 3.1925878227856685

Epoch: 6| Step: 1
Training loss: 3.2137038294570326
Validation loss: 3.1915913976970454

Epoch: 6| Step: 2
Training loss: 2.444694660365968
Validation loss: 3.190668437878578

Epoch: 6| Step: 3
Training loss: 4.093367930047601
Validation loss: 3.193402933224618

Epoch: 6| Step: 4
Training loss: 3.548388725291575
Validation loss: 3.1961856871179744

Epoch: 6| Step: 5
Training loss: 3.283530469162567
Validation loss: 3.2026455796303464

Epoch: 6| Step: 6
Training loss: 3.321008371472971
Validation loss: 3.200748959565761

Epoch: 6| Step: 7
Training loss: 2.9862543549791325
Validation loss: 3.2095137987951534

Epoch: 6| Step: 8
Training loss: 2.9238398672108903
Validation loss: 3.2049826928830107

Epoch: 6| Step: 9
Training loss: 4.020418030368983
Validation loss: 3.191023813688377

Epoch: 6| Step: 10
Training loss: 3.2512232605781644
Validation loss: 3.188505750375325

Epoch: 6| Step: 11
Training loss: 4.390695808898551
Validation loss: 3.188734229414679

Epoch: 6| Step: 12
Training loss: 3.458934195535233
Validation loss: 3.1906395413664166

Epoch: 6| Step: 13
Training loss: 2.436332227279294
Validation loss: 3.191490124140398

Epoch: 98| Step: 0
Training loss: 3.3910226896309315
Validation loss: 3.1946341157032063

Epoch: 6| Step: 1
Training loss: 3.289713960405096
Validation loss: 3.1874781926933426

Epoch: 6| Step: 2
Training loss: 4.216880553679925
Validation loss: 3.1920312165689113

Epoch: 6| Step: 3
Training loss: 3.4913058608161975
Validation loss: 3.1904503537006113

Epoch: 6| Step: 4
Training loss: 3.6975168504518003
Validation loss: 3.186541994640368

Epoch: 6| Step: 5
Training loss: 3.2800784971567016
Validation loss: 3.187857269847994

Epoch: 6| Step: 6
Training loss: 3.5219432428174424
Validation loss: 3.1880633624226165

Epoch: 6| Step: 7
Training loss: 2.750190641557579
Validation loss: 3.1870165865888493

Epoch: 6| Step: 8
Training loss: 3.7504999463287705
Validation loss: 3.1870752285209174

Epoch: 6| Step: 9
Training loss: 3.953460317269494
Validation loss: 3.1877812183692074

Epoch: 6| Step: 10
Training loss: 2.9503656645620158
Validation loss: 3.1866295156923283

Epoch: 6| Step: 11
Training loss: 3.2805879924167205
Validation loss: 3.1862421161647716

Epoch: 6| Step: 12
Training loss: 3.0742337954781926
Validation loss: 3.1858890008427703

Epoch: 6| Step: 13
Training loss: 3.0237207403261492
Validation loss: 3.1849690989335655

Epoch: 99| Step: 0
Training loss: 3.5258948306337006
Validation loss: 3.1860742100618262

Epoch: 6| Step: 1
Training loss: 3.209972078671341
Validation loss: 3.183011249234019

Epoch: 6| Step: 2
Training loss: 3.915791325792696
Validation loss: 3.1900181033906323

Epoch: 6| Step: 3
Training loss: 2.7628625554164055
Validation loss: 3.1897235974684914

Epoch: 6| Step: 4
Training loss: 3.5102351261516858
Validation loss: 3.190514639923541

Epoch: 6| Step: 5
Training loss: 3.420906103911264
Validation loss: 3.1848919143607706

Epoch: 6| Step: 6
Training loss: 2.7067137252619164
Validation loss: 3.1886855407341526

Epoch: 6| Step: 7
Training loss: 3.5959057520310838
Validation loss: 3.19327839195543

Epoch: 6| Step: 8
Training loss: 3.8699376663589695
Validation loss: 3.184165679251922

Epoch: 6| Step: 9
Training loss: 4.223784656771961
Validation loss: 3.1840925653180427

Epoch: 6| Step: 10
Training loss: 3.0261374549784317
Validation loss: 3.1828093884591344

Epoch: 6| Step: 11
Training loss: 3.810778369842258
Validation loss: 3.1820121185713823

Epoch: 6| Step: 12
Training loss: 3.0213180328524913
Validation loss: 3.1826143102050097

Epoch: 6| Step: 13
Training loss: 2.8454418808641107
Validation loss: 3.182114360844392

Epoch: 100| Step: 0
Training loss: 3.3331985128476527
Validation loss: 3.182174841323413

Epoch: 6| Step: 1
Training loss: 3.8455374678642835
Validation loss: 3.1827426614523135

Epoch: 6| Step: 2
Training loss: 3.54682633286752
Validation loss: 3.1817836072274077

Epoch: 6| Step: 3
Training loss: 3.7802711670104263
Validation loss: 3.1810263231157907

Epoch: 6| Step: 4
Training loss: 2.7433821203436892
Validation loss: 3.1833827455312176

Epoch: 6| Step: 5
Training loss: 4.296377368201056
Validation loss: 3.182179112746011

Epoch: 6| Step: 6
Training loss: 3.1281842602462286
Validation loss: 3.182002473117166

Epoch: 6| Step: 7
Training loss: 3.4667441952423577
Validation loss: 3.18175218704421

Epoch: 6| Step: 8
Training loss: 3.4338567674255627
Validation loss: 3.182338530511577

Epoch: 6| Step: 9
Training loss: 3.2907795897830523
Validation loss: 3.178169987498129

Epoch: 6| Step: 10
Training loss: 2.676097455797532
Validation loss: 3.17954564746263

Epoch: 6| Step: 11
Training loss: 2.891813786380039
Validation loss: 3.180094092856319

Epoch: 6| Step: 12
Training loss: 3.3604913320521823
Validation loss: 3.180370724935113

Epoch: 6| Step: 13
Training loss: 4.155944813014047
Validation loss: 3.179560246143049

Epoch: 101| Step: 0
Training loss: 4.055767172832963
Validation loss: 3.185091186635773

Epoch: 6| Step: 1
Training loss: 3.656493741249582
Validation loss: 3.186082618531788

Epoch: 6| Step: 2
Training loss: 2.480919119731617
Validation loss: 3.1817866222466225

Epoch: 6| Step: 3
Training loss: 2.9444433088320414
Validation loss: 3.182588222719123

Epoch: 6| Step: 4
Training loss: 3.483001027538883
Validation loss: 3.1844273346385994

Epoch: 6| Step: 5
Training loss: 3.7719950001866525
Validation loss: 3.1795560099041267

Epoch: 6| Step: 6
Training loss: 3.17009756714286
Validation loss: 3.1794946958817967

Epoch: 6| Step: 7
Training loss: 4.1349067790029945
Validation loss: 3.179535900996017

Epoch: 6| Step: 8
Training loss: 3.102015541485358
Validation loss: 3.178967700014995

Epoch: 6| Step: 9
Training loss: 2.6854293298139136
Validation loss: 3.1837688761002174

Epoch: 6| Step: 10
Training loss: 3.531666148823125
Validation loss: 3.177222219437562

Epoch: 6| Step: 11
Training loss: 3.6013166298175845
Validation loss: 3.179115582804857

Epoch: 6| Step: 12
Training loss: 3.08692904610212
Validation loss: 3.17647436483037

Epoch: 6| Step: 13
Training loss: 4.123119503594089
Validation loss: 3.176764063508732

Epoch: 102| Step: 0
Training loss: 3.1605277202677806
Validation loss: 3.1763012231855217

Epoch: 6| Step: 1
Training loss: 3.119192754779237
Validation loss: 3.1774349852521526

Epoch: 6| Step: 2
Training loss: 3.152827607450532
Validation loss: 3.1761112645839837

Epoch: 6| Step: 3
Training loss: 3.531021785957327
Validation loss: 3.17253204835569

Epoch: 6| Step: 4
Training loss: 3.211793066235336
Validation loss: 3.1760405062414576

Epoch: 6| Step: 5
Training loss: 3.4379061372292345
Validation loss: 3.176869157053912

Epoch: 6| Step: 6
Training loss: 3.825104436508278
Validation loss: 3.1775055963611805

Epoch: 6| Step: 7
Training loss: 3.5613575492196494
Validation loss: 3.17360771147124

Epoch: 6| Step: 8
Training loss: 2.376050014277713
Validation loss: 3.1746897658843154

Epoch: 6| Step: 9
Training loss: 3.513457719554161
Validation loss: 3.176753502314984

Epoch: 6| Step: 10
Training loss: 4.127683055938079
Validation loss: 3.17529416487046

Epoch: 6| Step: 11
Training loss: 3.0740194292416207
Validation loss: 3.1744076090348274

Epoch: 6| Step: 12
Training loss: 3.542310289729106
Validation loss: 3.17486079340957

Epoch: 6| Step: 13
Training loss: 4.3258244428774155
Validation loss: 3.174884602713113

Epoch: 103| Step: 0
Training loss: 3.6936681851332063
Validation loss: 3.173011618568289

Epoch: 6| Step: 1
Training loss: 3.783341262965918
Validation loss: 3.1749391633447535

Epoch: 6| Step: 2
Training loss: 3.5114751440638066
Validation loss: 3.1733798697359705

Epoch: 6| Step: 3
Training loss: 3.361301880844308
Validation loss: 3.1740380814161693

Epoch: 6| Step: 4
Training loss: 4.001698610135128
Validation loss: 3.174035638958938

Epoch: 6| Step: 5
Training loss: 2.6392275029710803
Validation loss: 3.175897627087158

Epoch: 6| Step: 6
Training loss: 3.0718370685583314
Validation loss: 3.1841942979764775

Epoch: 6| Step: 7
Training loss: 3.8627487448189775
Validation loss: 3.19356474484302

Epoch: 6| Step: 8
Training loss: 3.193707573715266
Validation loss: 3.1717833238963276

Epoch: 6| Step: 9
Training loss: 3.880670275062343
Validation loss: 3.1703055242131994

Epoch: 6| Step: 10
Training loss: 2.8881320410260622
Validation loss: 3.16952083297715

Epoch: 6| Step: 11
Training loss: 3.112967557910227
Validation loss: 3.1706589099671825

Epoch: 6| Step: 12
Training loss: 3.0808322832268957
Validation loss: 3.169268005668049

Epoch: 6| Step: 13
Training loss: 3.6461505134304804
Validation loss: 3.172424837751584

Epoch: 104| Step: 0
Training loss: 2.9022098474431846
Validation loss: 3.1726113792198767

Epoch: 6| Step: 1
Training loss: 3.7714272272016762
Validation loss: 3.1732205254192714

Epoch: 6| Step: 2
Training loss: 3.7192492750941133
Validation loss: 3.1753350595663647

Epoch: 6| Step: 3
Training loss: 3.2188114789998665
Validation loss: 3.1716992689070667

Epoch: 6| Step: 4
Training loss: 2.2101751839779737
Validation loss: 3.1701553656330597

Epoch: 6| Step: 5
Training loss: 3.886267493040825
Validation loss: 3.173465590401313

Epoch: 6| Step: 6
Training loss: 3.7282769759762653
Validation loss: 3.1718570982110985

Epoch: 6| Step: 7
Training loss: 3.3085441720754187
Validation loss: 3.1713153162055874

Epoch: 6| Step: 8
Training loss: 2.9787845677760423
Validation loss: 3.169584072443831

Epoch: 6| Step: 9
Training loss: 3.0422611613630393
Validation loss: 3.170087063800603

Epoch: 6| Step: 10
Training loss: 3.438686790204291
Validation loss: 3.168103302378667

Epoch: 6| Step: 11
Training loss: 3.572213833174307
Validation loss: 3.1688648332920235

Epoch: 6| Step: 12
Training loss: 4.134457929475818
Validation loss: 3.168157657737404

Epoch: 6| Step: 13
Training loss: 3.7294163682477057
Validation loss: 3.168203918776444

Epoch: 105| Step: 0
Training loss: 3.99197273647195
Validation loss: 3.167029535414742

Epoch: 6| Step: 1
Training loss: 3.6888240441466325
Validation loss: 3.1682438368897805

Epoch: 6| Step: 2
Training loss: 3.870694999289773
Validation loss: 3.1647844425506637

Epoch: 6| Step: 3
Training loss: 3.569654808986755
Validation loss: 3.167085346809964

Epoch: 6| Step: 4
Training loss: 3.2448346097909924
Validation loss: 3.1660612063984876

Epoch: 6| Step: 5
Training loss: 3.147239286670697
Validation loss: 3.1681388084157907

Epoch: 6| Step: 6
Training loss: 3.8043208954136296
Validation loss: 3.1667998085680353

Epoch: 6| Step: 7
Training loss: 4.066388426053636
Validation loss: 3.16602243488255

Epoch: 6| Step: 8
Training loss: 3.531484950528679
Validation loss: 3.16494351822608

Epoch: 6| Step: 9
Training loss: 3.5683148761849797
Validation loss: 3.1653919072080696

Epoch: 6| Step: 10
Training loss: 1.9773192634407764
Validation loss: 3.1654730238079556

Epoch: 6| Step: 11
Training loss: 2.782540011465293
Validation loss: 3.1643959419661094

Epoch: 6| Step: 12
Training loss: 2.299460480478353
Validation loss: 3.1663673002469466

Epoch: 6| Step: 13
Training loss: 3.6335852672713282
Validation loss: 3.1669683658118206

Epoch: 106| Step: 0
Training loss: 3.7272674725446855
Validation loss: 3.1653101697523907

Epoch: 6| Step: 1
Training loss: 2.4331569616421773
Validation loss: 3.1716031654593273

Epoch: 6| Step: 2
Training loss: 2.776526565619765
Validation loss: 3.166351319388834

Epoch: 6| Step: 3
Training loss: 2.8362586309874116
Validation loss: 3.1628880508623665

Epoch: 6| Step: 4
Training loss: 4.336578596678596
Validation loss: 3.166913795758854

Epoch: 6| Step: 5
Training loss: 3.174250272406087
Validation loss: 3.1635314260745435

Epoch: 6| Step: 6
Training loss: 3.153316078407656
Validation loss: 3.167664754877714

Epoch: 6| Step: 7
Training loss: 3.5104407848280506
Validation loss: 3.1669563788078503

Epoch: 6| Step: 8
Training loss: 3.0839151056976895
Validation loss: 3.163229138429707

Epoch: 6| Step: 9
Training loss: 2.933214348489481
Validation loss: 3.163554836044824

Epoch: 6| Step: 10
Training loss: 4.315912195990101
Validation loss: 3.166761847546036

Epoch: 6| Step: 11
Training loss: 4.054268346741811
Validation loss: 3.167073646799976

Epoch: 6| Step: 12
Training loss: 3.9019417159490075
Validation loss: 3.16495142716845

Epoch: 6| Step: 13
Training loss: 2.2716365641863874
Validation loss: 3.1656224699382496

Epoch: 107| Step: 0
Training loss: 3.5887966351483542
Validation loss: 3.1657645673625203

Epoch: 6| Step: 1
Training loss: 2.858656162311461
Validation loss: 3.1665436025086007

Epoch: 6| Step: 2
Training loss: 3.498204724505938
Validation loss: 3.162110600834856

Epoch: 6| Step: 3
Training loss: 3.965033886489282
Validation loss: 3.164962657119851

Epoch: 6| Step: 4
Training loss: 2.2069922519715495
Validation loss: 3.1633825003122946

Epoch: 6| Step: 5
Training loss: 3.4688698687762716
Validation loss: 3.160867913271021

Epoch: 6| Step: 6
Training loss: 3.869665103586616
Validation loss: 3.1600745750678514

Epoch: 6| Step: 7
Training loss: 3.1586859339325954
Validation loss: 3.1604958616460572

Epoch: 6| Step: 8
Training loss: 3.325196603110983
Validation loss: 3.1611416441464946

Epoch: 6| Step: 9
Training loss: 4.134174201915917
Validation loss: 3.158803804375508

Epoch: 6| Step: 10
Training loss: 2.9943345934602523
Validation loss: 3.157989962930664

Epoch: 6| Step: 11
Training loss: 3.3831404952042012
Validation loss: 3.1586356441700456

Epoch: 6| Step: 12
Training loss: 2.5228471094859866
Validation loss: 3.158461929661368

Epoch: 6| Step: 13
Training loss: 4.587084027382492
Validation loss: 3.1580052603596283

Epoch: 108| Step: 0
Training loss: 3.135787806718147
Validation loss: 3.1573719559460387

Epoch: 6| Step: 1
Training loss: 3.1288631212402884
Validation loss: 3.1576617752911993

Epoch: 6| Step: 2
Training loss: 2.979372315322566
Validation loss: 3.156717968109665

Epoch: 6| Step: 3
Training loss: 2.961485960396897
Validation loss: 3.1552082504355705

Epoch: 6| Step: 4
Training loss: 3.55952463212287
Validation loss: 3.1573873083340263

Epoch: 6| Step: 5
Training loss: 3.2983533970507066
Validation loss: 3.160425858505174

Epoch: 6| Step: 6
Training loss: 3.025306774378685
Validation loss: 3.1598661815818625

Epoch: 6| Step: 7
Training loss: 3.904099627841709
Validation loss: 3.1547096674441066

Epoch: 6| Step: 8
Training loss: 3.7366370847576347
Validation loss: 3.1572245861124535

Epoch: 6| Step: 9
Training loss: 3.4006850954847825
Validation loss: 3.155312263097883

Epoch: 6| Step: 10
Training loss: 3.4921186811591585
Validation loss: 3.1549067051601085

Epoch: 6| Step: 11
Training loss: 4.179476894883876
Validation loss: 3.1531655148435167

Epoch: 6| Step: 12
Training loss: 3.654407526050574
Validation loss: 3.153889877804907

Epoch: 6| Step: 13
Training loss: 2.5632401304658647
Validation loss: 3.153424538646613

Epoch: 109| Step: 0
Training loss: 3.19170550994211
Validation loss: 3.1534635138300393

Epoch: 6| Step: 1
Training loss: 3.220624211387308
Validation loss: 3.153886949916422

Epoch: 6| Step: 2
Training loss: 3.2384956390130046
Validation loss: 3.153661097640362

Epoch: 6| Step: 3
Training loss: 4.07954282704991
Validation loss: 3.155334510455531

Epoch: 6| Step: 4
Training loss: 3.365400154161736
Validation loss: 3.1535597961259447

Epoch: 6| Step: 5
Training loss: 3.426304289016464
Validation loss: 3.155217851048037

Epoch: 6| Step: 6
Training loss: 3.3082746511743157
Validation loss: 3.154080755312977

Epoch: 6| Step: 7
Training loss: 2.822121671285464
Validation loss: 3.1526931496072366

Epoch: 6| Step: 8
Training loss: 3.669866783780218
Validation loss: 3.1535445763112264

Epoch: 6| Step: 9
Training loss: 3.634817443839047
Validation loss: 3.1555961127300844

Epoch: 6| Step: 10
Training loss: 2.9900927668951462
Validation loss: 3.158354658660423

Epoch: 6| Step: 11
Training loss: 4.072775653762297
Validation loss: 3.1675140113966465

Epoch: 6| Step: 12
Training loss: 2.7938818232693774
Validation loss: 3.1570599829535246

Epoch: 6| Step: 13
Training loss: 3.7292700953854143
Validation loss: 3.1629747131978014

Epoch: 110| Step: 0
Training loss: 2.6422038578043687
Validation loss: 3.161628809504664

Epoch: 6| Step: 1
Training loss: 4.024883595554494
Validation loss: 3.162750510937938

Epoch: 6| Step: 2
Training loss: 3.0631526329476917
Validation loss: 3.1634882993471867

Epoch: 6| Step: 3
Training loss: 3.1108986653347364
Validation loss: 3.1635729169030244

Epoch: 6| Step: 4
Training loss: 2.7239178179808894
Validation loss: 3.1547922955124865

Epoch: 6| Step: 5
Training loss: 3.9097629467454484
Validation loss: 3.153034488748849

Epoch: 6| Step: 6
Training loss: 3.1396932405920697
Validation loss: 3.1495088707454424

Epoch: 6| Step: 7
Training loss: 3.889573043104037
Validation loss: 3.151993299867534

Epoch: 6| Step: 8
Training loss: 3.4955443222254496
Validation loss: 3.1531614943723536

Epoch: 6| Step: 9
Training loss: 3.300516296226285
Validation loss: 3.153597262473623

Epoch: 6| Step: 10
Training loss: 4.131309308017344
Validation loss: 3.150734073626683

Epoch: 6| Step: 11
Training loss: 3.8892927838045694
Validation loss: 3.1484938266122504

Epoch: 6| Step: 12
Training loss: 2.969843612817807
Validation loss: 3.1471477392919693

Epoch: 6| Step: 13
Training loss: 2.388405062105701
Validation loss: 3.1475039922415293

Epoch: 111| Step: 0
Training loss: 2.55955801694872
Validation loss: 3.1466366261725

Epoch: 6| Step: 1
Training loss: 2.753409093256333
Validation loss: 3.1463326020825684

Epoch: 6| Step: 2
Training loss: 3.796624571779265
Validation loss: 3.14621919089511

Epoch: 6| Step: 3
Training loss: 3.4676302915488537
Validation loss: 3.1470448620017413

Epoch: 6| Step: 4
Training loss: 3.311684850045443
Validation loss: 3.1473171730767855

Epoch: 6| Step: 5
Training loss: 3.033248242732298
Validation loss: 3.1460255946655096

Epoch: 6| Step: 6
Training loss: 3.829136181621111
Validation loss: 3.145847504427738

Epoch: 6| Step: 7
Training loss: 2.9803924350792528
Validation loss: 3.145506713857623

Epoch: 6| Step: 8
Training loss: 2.893274526071685
Validation loss: 3.1455788403823712

Epoch: 6| Step: 9
Training loss: 3.5300990566803625
Validation loss: 3.14612883285738

Epoch: 6| Step: 10
Training loss: 2.950640890041908
Validation loss: 3.144409116170439

Epoch: 6| Step: 11
Training loss: 4.083512646118028
Validation loss: 3.1443913882104124

Epoch: 6| Step: 12
Training loss: 3.9935282566555785
Validation loss: 3.144359088073385

Epoch: 6| Step: 13
Training loss: 4.312224669582065
Validation loss: 3.145647517888717

Epoch: 112| Step: 0
Training loss: 3.44042248038913
Validation loss: 3.143767970476237

Epoch: 6| Step: 1
Training loss: 3.6591162247215525
Validation loss: 3.1475426058000964

Epoch: 6| Step: 2
Training loss: 3.5738297047488037
Validation loss: 3.146156464488764

Epoch: 6| Step: 3
Training loss: 3.327554143383461
Validation loss: 3.1486144072517734

Epoch: 6| Step: 4
Training loss: 2.85315632630581
Validation loss: 3.1491835537309996

Epoch: 6| Step: 5
Training loss: 2.760019084201015
Validation loss: 3.1459682956933785

Epoch: 6| Step: 6
Training loss: 3.4708314441494115
Validation loss: 3.1483668354490884

Epoch: 6| Step: 7
Training loss: 3.4322558542485493
Validation loss: 3.1537715741523433

Epoch: 6| Step: 8
Training loss: 3.729997695022157
Validation loss: 3.1507250517011887

Epoch: 6| Step: 9
Training loss: 2.997895138159341
Validation loss: 3.1496016900823203

Epoch: 6| Step: 10
Training loss: 3.9732244304692794
Validation loss: 3.152392297342895

Epoch: 6| Step: 11
Training loss: 3.235156126190456
Validation loss: 3.1474128614528216

Epoch: 6| Step: 12
Training loss: 3.6148294297283616
Validation loss: 3.148709002646333

Epoch: 6| Step: 13
Training loss: 3.146072142843917
Validation loss: 3.1492822518873957

Epoch: 113| Step: 0
Training loss: 3.244969215658492
Validation loss: 3.148612052548869

Epoch: 6| Step: 1
Training loss: 3.225894147542269
Validation loss: 3.1447621584745895

Epoch: 6| Step: 2
Training loss: 3.0119820367143206
Validation loss: 3.1446430630486764

Epoch: 6| Step: 3
Training loss: 3.253570649241306
Validation loss: 3.144591157067786

Epoch: 6| Step: 4
Training loss: 3.581442149068789
Validation loss: 3.14319573257091

Epoch: 6| Step: 5
Training loss: 3.1097240156272936
Validation loss: 3.1416290544251817

Epoch: 6| Step: 6
Training loss: 4.111037233622492
Validation loss: 3.146042170143116

Epoch: 6| Step: 7
Training loss: 2.5799401569079694
Validation loss: 3.142456451246621

Epoch: 6| Step: 8
Training loss: 3.5584661835669933
Validation loss: 3.1491529886919127

Epoch: 6| Step: 9
Training loss: 3.3814645244356902
Validation loss: 3.1428801173880765

Epoch: 6| Step: 10
Training loss: 3.8495024768342248
Validation loss: 3.147316389481595

Epoch: 6| Step: 11
Training loss: 3.775611645997454
Validation loss: 3.1471038495961574

Epoch: 6| Step: 12
Training loss: 3.1551321335099782
Validation loss: 3.143398014319143

Epoch: 6| Step: 13
Training loss: 3.39958055938322
Validation loss: 3.1377903988441918

Epoch: 114| Step: 0
Training loss: 3.8132763681847464
Validation loss: 3.140930731482403

Epoch: 6| Step: 1
Training loss: 3.418929273518149
Validation loss: 3.1381861290559376

Epoch: 6| Step: 2
Training loss: 3.5423544421608186
Validation loss: 3.1382395664729215

Epoch: 6| Step: 3
Training loss: 2.782840059926783
Validation loss: 3.1384558384544867

Epoch: 6| Step: 4
Training loss: 3.9185324479210526
Validation loss: 3.137356305170686

Epoch: 6| Step: 5
Training loss: 3.193538705065964
Validation loss: 3.13544119357651

Epoch: 6| Step: 6
Training loss: 3.4062511199109395
Validation loss: 3.1381440624001504

Epoch: 6| Step: 7
Training loss: 4.02843430236448
Validation loss: 3.1386543286350843

Epoch: 6| Step: 8
Training loss: 2.8338356320803855
Validation loss: 3.1359933850060306

Epoch: 6| Step: 9
Training loss: 2.967390532173777
Validation loss: 3.1363962807356773

Epoch: 6| Step: 10
Training loss: 3.3464646772648954
Validation loss: 3.13764134779791

Epoch: 6| Step: 11
Training loss: 3.0491049406885056
Validation loss: 3.136517328089411

Epoch: 6| Step: 12
Training loss: 3.3534942963976664
Validation loss: 3.1363203382888463

Epoch: 6| Step: 13
Training loss: 3.6781655827100836
Validation loss: 3.135351729334631

Epoch: 115| Step: 0
Training loss: 3.6533199209352234
Validation loss: 3.1359113791425046

Epoch: 6| Step: 1
Training loss: 3.6099176700745956
Validation loss: 3.1433375127909833

Epoch: 6| Step: 2
Training loss: 2.847560802477045
Validation loss: 3.144681598419554

Epoch: 6| Step: 3
Training loss: 3.1449536910536646
Validation loss: 3.160548500066508

Epoch: 6| Step: 4
Training loss: 3.567580899749482
Validation loss: 3.179925866963296

Epoch: 6| Step: 5
Training loss: 3.8343207842810987
Validation loss: 3.2083296427541046

Epoch: 6| Step: 6
Training loss: 2.6323056964226144
Validation loss: 3.2347722732208526

Epoch: 6| Step: 7
Training loss: 4.079503553517764
Validation loss: 3.2387511526471364

Epoch: 6| Step: 8
Training loss: 2.854181795474607
Validation loss: 3.226777125771954

Epoch: 6| Step: 9
Training loss: 3.742644152722277
Validation loss: 3.188920790385163

Epoch: 6| Step: 10
Training loss: 3.16650748271049
Validation loss: 3.1418299674788965

Epoch: 6| Step: 11
Training loss: 3.4224540882360985
Validation loss: 3.131854684434157

Epoch: 6| Step: 12
Training loss: 3.1514558546172076
Validation loss: 3.1366355215892034

Epoch: 6| Step: 13
Training loss: 4.069126769169795
Validation loss: 3.153724105615697

Epoch: 116| Step: 0
Training loss: 2.381545934035115
Validation loss: 3.1684861571711367

Epoch: 6| Step: 1
Training loss: 2.7738635098653113
Validation loss: 3.1996181656952003

Epoch: 6| Step: 2
Training loss: 3.397795096880585
Validation loss: 3.214382157780846

Epoch: 6| Step: 3
Training loss: 2.9516311984854338
Validation loss: 3.20617396370399

Epoch: 6| Step: 4
Training loss: 3.6906683290216895
Validation loss: 3.1928564077900896

Epoch: 6| Step: 5
Training loss: 4.0120158916550395
Validation loss: 3.1383044557589743

Epoch: 6| Step: 6
Training loss: 3.2475200875052335
Validation loss: 3.1347336403131814

Epoch: 6| Step: 7
Training loss: 3.37984034686014
Validation loss: 3.1314545519381696

Epoch: 6| Step: 8
Training loss: 3.0279798663841917
Validation loss: 3.133886103044927

Epoch: 6| Step: 9
Training loss: 3.06287926641498
Validation loss: 3.1360437362123808

Epoch: 6| Step: 10
Training loss: 4.350762942702549
Validation loss: 3.1433782458136985

Epoch: 6| Step: 11
Training loss: 3.5515646159563925
Validation loss: 3.152388218145722

Epoch: 6| Step: 12
Training loss: 3.704664465656854
Validation loss: 3.1540063680887966

Epoch: 6| Step: 13
Training loss: 3.9353605240465113
Validation loss: 3.143509645851055

Epoch: 117| Step: 0
Training loss: 4.129693799802469
Validation loss: 3.1457668434053696

Epoch: 6| Step: 1
Training loss: 3.391874021772866
Validation loss: 3.1350690985421723

Epoch: 6| Step: 2
Training loss: 3.173842848523541
Validation loss: 3.1373284293361734

Epoch: 6| Step: 3
Training loss: 3.5603876376470667
Validation loss: 3.1360243619702293

Epoch: 6| Step: 4
Training loss: 3.316314084914492
Validation loss: 3.1389455878798085

Epoch: 6| Step: 5
Training loss: 3.5184192996694033
Validation loss: 3.1328560931974065

Epoch: 6| Step: 6
Training loss: 3.275300945403183
Validation loss: 3.1381858365992916

Epoch: 6| Step: 7
Training loss: 3.703213976342393
Validation loss: 3.1318783148085276

Epoch: 6| Step: 8
Training loss: 3.831694764151367
Validation loss: 3.1335711520717315

Epoch: 6| Step: 9
Training loss: 2.881168713529764
Validation loss: 3.1337884669492073

Epoch: 6| Step: 10
Training loss: 2.690185535796834
Validation loss: 3.1315096531301814

Epoch: 6| Step: 11
Training loss: 2.981386935689954
Validation loss: 3.1333964030800385

Epoch: 6| Step: 12
Training loss: 3.100456290350506
Validation loss: 3.1324237145158045

Epoch: 6| Step: 13
Training loss: 3.814136091535783
Validation loss: 3.132530898795287

Epoch: 118| Step: 0
Training loss: 3.1496031617164
Validation loss: 3.1303716764381506

Epoch: 6| Step: 1
Training loss: 3.732546306713782
Validation loss: 3.1298912015591993

Epoch: 6| Step: 2
Training loss: 3.4620246643562966
Validation loss: 3.130657620325505

Epoch: 6| Step: 3
Training loss: 2.9473762870626246
Validation loss: 3.1332867831863456

Epoch: 6| Step: 4
Training loss: 2.904990138498399
Validation loss: 3.1286417908363813

Epoch: 6| Step: 5
Training loss: 3.5559916692406612
Validation loss: 3.126164624174546

Epoch: 6| Step: 6
Training loss: 3.4287149705811513
Validation loss: 3.1286853544702526

Epoch: 6| Step: 7
Training loss: 3.735394199103071
Validation loss: 3.1295319049275125

Epoch: 6| Step: 8
Training loss: 3.498540846613045
Validation loss: 3.1265397493138862

Epoch: 6| Step: 9
Training loss: 3.6249185750300854
Validation loss: 3.12496365433753

Epoch: 6| Step: 10
Training loss: 3.2172206467509143
Validation loss: 3.1287997183113987

Epoch: 6| Step: 11
Training loss: 3.4867531909989564
Validation loss: 3.1255103303688765

Epoch: 6| Step: 12
Training loss: 3.404666077405068
Validation loss: 3.129018641878743

Epoch: 6| Step: 13
Training loss: 2.860419577652426
Validation loss: 3.1276828455798436

Epoch: 119| Step: 0
Training loss: 3.439225197409453
Validation loss: 3.127260953019845

Epoch: 6| Step: 1
Training loss: 3.977938251052549
Validation loss: 3.1272226718973943

Epoch: 6| Step: 2
Training loss: 3.2598285246140932
Validation loss: 3.1235429907067207

Epoch: 6| Step: 3
Training loss: 3.7739579688856537
Validation loss: 3.1289853694659997

Epoch: 6| Step: 4
Training loss: 2.7286541192985405
Validation loss: 3.1234145098653627

Epoch: 6| Step: 5
Training loss: 2.8755862426135814
Validation loss: 3.123387694820859

Epoch: 6| Step: 6
Training loss: 4.1981639300175955
Validation loss: 3.124562049449082

Epoch: 6| Step: 7
Training loss: 3.0003585601154095
Validation loss: 3.1241296405225265

Epoch: 6| Step: 8
Training loss: 3.4521969199654223
Validation loss: 3.1251519229835374

Epoch: 6| Step: 9
Training loss: 3.5918603324159206
Validation loss: 3.1230240963718607

Epoch: 6| Step: 10
Training loss: 2.647785477848714
Validation loss: 3.124911775061426

Epoch: 6| Step: 11
Training loss: 3.065064271436589
Validation loss: 3.119698088048793

Epoch: 6| Step: 12
Training loss: 3.7013146204333394
Validation loss: 3.125109667750787

Epoch: 6| Step: 13
Training loss: 2.980503946998925
Validation loss: 3.125176660610038

Epoch: 120| Step: 0
Training loss: 3.7146712302211635
Validation loss: 3.1322240584976258

Epoch: 6| Step: 1
Training loss: 3.636554456169068
Validation loss: 3.1233193322418797

Epoch: 6| Step: 2
Training loss: 2.914433269077751
Validation loss: 3.1273477689374927

Epoch: 6| Step: 3
Training loss: 2.836537195277522
Validation loss: 3.121356953064656

Epoch: 6| Step: 4
Training loss: 3.281521885824624
Validation loss: 3.1254401932648856

Epoch: 6| Step: 5
Training loss: 3.432051762641793
Validation loss: 3.1218922221648904

Epoch: 6| Step: 6
Training loss: 4.074587402050451
Validation loss: 3.1186292029745935

Epoch: 6| Step: 7
Training loss: 3.71951696356674
Validation loss: 3.1189300069224926

Epoch: 6| Step: 8
Training loss: 3.714333869286564
Validation loss: 3.120107779606717

Epoch: 6| Step: 9
Training loss: 3.1464892244686404
Validation loss: 3.1180150681177174

Epoch: 6| Step: 10
Training loss: 3.3751641692746834
Validation loss: 3.118428916151793

Epoch: 6| Step: 11
Training loss: 2.6972239033250407
Validation loss: 3.1175944731654313

Epoch: 6| Step: 12
Training loss: 3.3143479572756047
Validation loss: 3.1194301624974576

Epoch: 6| Step: 13
Training loss: 2.985917416779007
Validation loss: 3.119071281657269

Epoch: 121| Step: 0
Training loss: 2.551977931330816
Validation loss: 3.1198754112509115

Epoch: 6| Step: 1
Training loss: 3.2207345122409334
Validation loss: 3.120056610030325

Epoch: 6| Step: 2
Training loss: 3.7116635545895402
Validation loss: 3.1257458180357984

Epoch: 6| Step: 3
Training loss: 4.207823215701868
Validation loss: 3.132481282522351

Epoch: 6| Step: 4
Training loss: 3.642993598540737
Validation loss: 3.1291339299774346

Epoch: 6| Step: 5
Training loss: 3.4503073956196393
Validation loss: 3.1324451087801517

Epoch: 6| Step: 6
Training loss: 3.514586842159622
Validation loss: 3.125513647381503

Epoch: 6| Step: 7
Training loss: 2.640800786233604
Validation loss: 3.139272335771931

Epoch: 6| Step: 8
Training loss: 3.5892494216092676
Validation loss: 3.1319182653539372

Epoch: 6| Step: 9
Training loss: 3.9578910714417646
Validation loss: 3.1304345946548193

Epoch: 6| Step: 10
Training loss: 3.3749860127477085
Validation loss: 3.1263923906513287

Epoch: 6| Step: 11
Training loss: 3.796281430664179
Validation loss: 3.1162559739021005

Epoch: 6| Step: 12
Training loss: 2.2069100405737108
Validation loss: 3.117349203523545

Epoch: 6| Step: 13
Training loss: 2.338031863325862
Validation loss: 3.116786029046357

Epoch: 122| Step: 0
Training loss: 3.3306386705183506
Validation loss: 3.1148159189795517

Epoch: 6| Step: 1
Training loss: 3.6010185708094387
Validation loss: 3.1169322281451546

Epoch: 6| Step: 2
Training loss: 3.2290855315485456
Validation loss: 3.1152421640859433

Epoch: 6| Step: 3
Training loss: 3.9315019972533065
Validation loss: 3.1158209732267275

Epoch: 6| Step: 4
Training loss: 2.881383691693934
Validation loss: 3.114573069425314

Epoch: 6| Step: 5
Training loss: 3.091309480692595
Validation loss: 3.117264487529185

Epoch: 6| Step: 6
Training loss: 3.186404918976592
Validation loss: 3.115767554486424

Epoch: 6| Step: 7
Training loss: 3.463826302135716
Validation loss: 3.1166340536091766

Epoch: 6| Step: 8
Training loss: 3.775497221884945
Validation loss: 3.116193210367066

Epoch: 6| Step: 9
Training loss: 3.3625927086284317
Validation loss: 3.1160063190501703

Epoch: 6| Step: 10
Training loss: 3.149491278123202
Validation loss: 3.1150704400539477

Epoch: 6| Step: 11
Training loss: 3.3283628280267514
Validation loss: 3.1157683015849726

Epoch: 6| Step: 12
Training loss: 3.4726167039368074
Validation loss: 3.1147658698980285

Epoch: 6| Step: 13
Training loss: 3.4684570463726
Validation loss: 3.111967562084346

Epoch: 123| Step: 0
Training loss: 3.2732417155054407
Validation loss: 3.113693459727764

Epoch: 6| Step: 1
Training loss: 4.070035079317499
Validation loss: 3.114240612621704

Epoch: 6| Step: 2
Training loss: 2.569315337182239
Validation loss: 3.1130422171353587

Epoch: 6| Step: 3
Training loss: 3.8341703054046996
Validation loss: 3.1137367689644013

Epoch: 6| Step: 4
Training loss: 3.6955777933972356
Validation loss: 3.112107394145847

Epoch: 6| Step: 5
Training loss: 2.9193907595980644
Validation loss: 3.112494305014347

Epoch: 6| Step: 6
Training loss: 4.094582975250463
Validation loss: 3.1112958631163847

Epoch: 6| Step: 7
Training loss: 2.925070254794472
Validation loss: 3.1113992130125236

Epoch: 6| Step: 8
Training loss: 3.530957775346414
Validation loss: 3.112350790281714

Epoch: 6| Step: 9
Training loss: 3.414398386339416
Validation loss: 3.111140005343264

Epoch: 6| Step: 10
Training loss: 2.812854235911298
Validation loss: 3.1104953013452263

Epoch: 6| Step: 11
Training loss: 3.2946361876924937
Validation loss: 3.112545313931326

Epoch: 6| Step: 12
Training loss: 3.339710398013956
Validation loss: 3.1155515515675125

Epoch: 6| Step: 13
Training loss: 2.7011639311501954
Validation loss: 3.1138324354363442

Epoch: 124| Step: 0
Training loss: 3.2089678809774678
Validation loss: 3.1116127540209186

Epoch: 6| Step: 1
Training loss: 3.9716939745332533
Validation loss: 3.118168572885622

Epoch: 6| Step: 2
Training loss: 3.8731176665161104
Validation loss: 3.112454655361411

Epoch: 6| Step: 3
Training loss: 2.869480473884156
Validation loss: 3.1107539281614383

Epoch: 6| Step: 4
Training loss: 3.816306168523645
Validation loss: 3.1107834488942214

Epoch: 6| Step: 5
Training loss: 2.466484285605756
Validation loss: 3.1078870113793324

Epoch: 6| Step: 6
Training loss: 3.5767687763476643
Validation loss: 3.1078342481672245

Epoch: 6| Step: 7
Training loss: 3.6112591998391435
Validation loss: 3.108933595807764

Epoch: 6| Step: 8
Training loss: 3.632761046342605
Validation loss: 3.108113050574373

Epoch: 6| Step: 9
Training loss: 3.2947693378481024
Validation loss: 3.107544653216811

Epoch: 6| Step: 10
Training loss: 2.8930451030993094
Validation loss: 3.1072539892379893

Epoch: 6| Step: 11
Training loss: 3.21051720608858
Validation loss: 3.107493999457819

Epoch: 6| Step: 12
Training loss: 3.526444667999196
Validation loss: 3.1076247743929306

Epoch: 6| Step: 13
Training loss: 2.3634950147059324
Validation loss: 3.1067152961203908

Epoch: 125| Step: 0
Training loss: 3.6165921275343393
Validation loss: 3.10620168801563

Epoch: 6| Step: 1
Training loss: 2.7437280745271098
Validation loss: 3.1070450423658045

Epoch: 6| Step: 2
Training loss: 2.8242297244881
Validation loss: 3.106783938241225

Epoch: 6| Step: 3
Training loss: 3.745241324743495
Validation loss: 3.105067239268822

Epoch: 6| Step: 4
Training loss: 3.456513550352015
Validation loss: 3.105022137181394

Epoch: 6| Step: 5
Training loss: 3.4287149705811513
Validation loss: 3.106234293321262

Epoch: 6| Step: 6
Training loss: 3.6620472650983036
Validation loss: 3.107525710127568

Epoch: 6| Step: 7
Training loss: 3.5622443391850123
Validation loss: 3.1055358578151444

Epoch: 6| Step: 8
Training loss: 3.1776764529716535
Validation loss: 3.103449088090108

Epoch: 6| Step: 9
Training loss: 3.0799062774072046
Validation loss: 3.104281659889288

Epoch: 6| Step: 10
Training loss: 3.1708074567810822
Validation loss: 3.103510836418912

Epoch: 6| Step: 11
Training loss: 3.2835423772524837
Validation loss: 3.104226732770604

Epoch: 6| Step: 12
Training loss: 3.60158050598807
Validation loss: 3.103713533889361

Epoch: 6| Step: 13
Training loss: 3.769337576995213
Validation loss: 3.105249263338479

Epoch: 126| Step: 0
Training loss: 3.2054667030976893
Validation loss: 3.1039138617224693

Epoch: 6| Step: 1
Training loss: 3.13230347719409
Validation loss: 3.1018561428816334

Epoch: 6| Step: 2
Training loss: 3.192103334307869
Validation loss: 3.1053054107226568

Epoch: 6| Step: 3
Training loss: 3.083958089956858
Validation loss: 3.1075087798810164

Epoch: 6| Step: 4
Training loss: 3.4907431122306805
Validation loss: 3.1051011469346737

Epoch: 6| Step: 5
Training loss: 3.7827435530910827
Validation loss: 3.1032627411343654

Epoch: 6| Step: 6
Training loss: 3.754805220061433
Validation loss: 3.103669995578169

Epoch: 6| Step: 7
Training loss: 3.6238862003707157
Validation loss: 3.106363273472154

Epoch: 6| Step: 8
Training loss: 3.3799987790709327
Validation loss: 3.103154495525867

Epoch: 6| Step: 9
Training loss: 3.257502479347345
Validation loss: 3.1066017672531294

Epoch: 6| Step: 10
Training loss: 3.14756653052591
Validation loss: 3.102773915667817

Epoch: 6| Step: 11
Training loss: 3.1855458271859867
Validation loss: 3.104428366936945

Epoch: 6| Step: 12
Training loss: 3.5171535305584163
Validation loss: 3.1026097875376157

Epoch: 6| Step: 13
Training loss: 3.134762278522357
Validation loss: 3.1007137371400173

Epoch: 127| Step: 0
Training loss: 3.864516073431643
Validation loss: 3.102171370108137

Epoch: 6| Step: 1
Training loss: 3.3752869378078985
Validation loss: 3.0998158548728156

Epoch: 6| Step: 2
Training loss: 2.5321024648414316
Validation loss: 3.1015110724000534

Epoch: 6| Step: 3
Training loss: 3.695479988028476
Validation loss: 3.103284633834566

Epoch: 6| Step: 4
Training loss: 3.793297860416041
Validation loss: 3.0997189386769284

Epoch: 6| Step: 5
Training loss: 2.866780181973388
Validation loss: 3.0985162339838483

Epoch: 6| Step: 6
Training loss: 2.658074145302623
Validation loss: 3.097701200296603

Epoch: 6| Step: 7
Training loss: 3.5896379912043983
Validation loss: 3.100724434136948

Epoch: 6| Step: 8
Training loss: 3.7898356170032295
Validation loss: 3.0983694124813317

Epoch: 6| Step: 9
Training loss: 3.7637775368698265
Validation loss: 3.100957996155717

Epoch: 6| Step: 10
Training loss: 2.922670796594463
Validation loss: 3.098302050979594

Epoch: 6| Step: 11
Training loss: 3.7496113893694454
Validation loss: 3.0987969088716736

Epoch: 6| Step: 12
Training loss: 2.866868003901546
Validation loss: 3.099280303391222

Epoch: 6| Step: 13
Training loss: 2.9120299586232683
Validation loss: 3.0972669260288876

Epoch: 128| Step: 0
Training loss: 3.304849390704402
Validation loss: 3.1001993282618736

Epoch: 6| Step: 1
Training loss: 3.583132109795501
Validation loss: 3.102663522879512

Epoch: 6| Step: 2
Training loss: 2.8880795380267403
Validation loss: 3.1029163250405305

Epoch: 6| Step: 3
Training loss: 3.55779464241408
Validation loss: 3.101056844478845

Epoch: 6| Step: 4
Training loss: 3.808301020401001
Validation loss: 3.1014793630549944

Epoch: 6| Step: 5
Training loss: 3.1538195930994326
Validation loss: 3.1006137252956405

Epoch: 6| Step: 6
Training loss: 2.903166088392463
Validation loss: 3.0993091947511493

Epoch: 6| Step: 7
Training loss: 3.779026354982245
Validation loss: 3.098649827645628

Epoch: 6| Step: 8
Training loss: 2.5569255020275232
Validation loss: 3.097615683771194

Epoch: 6| Step: 9
Training loss: 3.0879188840322205
Validation loss: 3.097758178002273

Epoch: 6| Step: 10
Training loss: 3.5022692816886543
Validation loss: 3.099653274710446

Epoch: 6| Step: 11
Training loss: 3.943449581450285
Validation loss: 3.0979934316659095

Epoch: 6| Step: 12
Training loss: 3.1295916584059746
Validation loss: 3.102230354816772

Epoch: 6| Step: 13
Training loss: 3.583262657237389
Validation loss: 3.099694017730325

Epoch: 129| Step: 0
Training loss: 3.2387094249119777
Validation loss: 3.0982139222071203

Epoch: 6| Step: 1
Training loss: 3.091901284609839
Validation loss: 3.0925219200964253

Epoch: 6| Step: 2
Training loss: 3.129278991823355
Validation loss: 3.0992299198811577

Epoch: 6| Step: 3
Training loss: 2.9453094239560365
Validation loss: 3.0945519238414865

Epoch: 6| Step: 4
Training loss: 4.159956347896724
Validation loss: 3.0954005467635612

Epoch: 6| Step: 5
Training loss: 3.550902109638666
Validation loss: 3.0942943877525595

Epoch: 6| Step: 6
Training loss: 3.2135291859257147
Validation loss: 3.094001344655159

Epoch: 6| Step: 7
Training loss: 2.7400137172828964
Validation loss: 3.0921446495724876

Epoch: 6| Step: 8
Training loss: 3.539016150703668
Validation loss: 3.093596193482985

Epoch: 6| Step: 9
Training loss: 3.616858053344028
Validation loss: 3.093079060921394

Epoch: 6| Step: 10
Training loss: 3.15944547640623
Validation loss: 3.0941148818080326

Epoch: 6| Step: 11
Training loss: 3.813756266751012
Validation loss: 3.093146702759095

Epoch: 6| Step: 12
Training loss: 3.3459059280241297
Validation loss: 3.092849665073589

Epoch: 6| Step: 13
Training loss: 3.04464859436543
Validation loss: 3.092968509431424

Epoch: 130| Step: 0
Training loss: 3.8904535340055597
Validation loss: 3.092174635655103

Epoch: 6| Step: 1
Training loss: 3.0432732053947014
Validation loss: 3.09331561938199

Epoch: 6| Step: 2
Training loss: 3.9719068332359884
Validation loss: 3.092666141118024

Epoch: 6| Step: 3
Training loss: 3.5755035259201167
Validation loss: 3.092533376586912

Epoch: 6| Step: 4
Training loss: 3.31369025960434
Validation loss: 3.092853148078924

Epoch: 6| Step: 5
Training loss: 2.9964002629025486
Validation loss: 3.0902751908002086

Epoch: 6| Step: 6
Training loss: 2.6544862164577645
Validation loss: 3.092814390512958

Epoch: 6| Step: 7
Training loss: 3.132580527376439
Validation loss: 3.0910856529271804

Epoch: 6| Step: 8
Training loss: 3.7653224712742874
Validation loss: 3.088858889534453

Epoch: 6| Step: 9
Training loss: 3.783757788981249
Validation loss: 3.0923385541022363

Epoch: 6| Step: 10
Training loss: 2.445856685841045
Validation loss: 3.093186948005797

Epoch: 6| Step: 11
Training loss: 3.613887195813187
Validation loss: 3.0900577867059043

Epoch: 6| Step: 12
Training loss: 2.7679102017990735
Validation loss: 3.0941604403317395

Epoch: 6| Step: 13
Training loss: 3.696691662973615
Validation loss: 3.0943293471829234

Epoch: 131| Step: 0
Training loss: 2.942949313308941
Validation loss: 3.0933529311157963

Epoch: 6| Step: 1
Training loss: 3.230310364684028
Validation loss: 3.0916489599107977

Epoch: 6| Step: 2
Training loss: 2.8647164238732223
Validation loss: 3.0953841365738524

Epoch: 6| Step: 3
Training loss: 2.5529947534814306
Validation loss: 3.0982702368042028

Epoch: 6| Step: 4
Training loss: 3.8676311199940825
Validation loss: 3.0917384163669537

Epoch: 6| Step: 5
Training loss: 3.4430236825873592
Validation loss: 3.08959928275886

Epoch: 6| Step: 6
Training loss: 3.137062595471323
Validation loss: 3.0879060173129713

Epoch: 6| Step: 7
Training loss: 4.3757667959444815
Validation loss: 3.0901973367468147

Epoch: 6| Step: 8
Training loss: 3.3839033451570737
Validation loss: 3.0876996758984467

Epoch: 6| Step: 9
Training loss: 3.910419527654697
Validation loss: 3.091034085850874

Epoch: 6| Step: 10
Training loss: 3.545497139316965
Validation loss: 3.0906288509518474

Epoch: 6| Step: 11
Training loss: 3.123291158754418
Validation loss: 3.088253393275579

Epoch: 6| Step: 12
Training loss: 3.3540243430576413
Validation loss: 3.0906848375906275

Epoch: 6| Step: 13
Training loss: 2.123105719486942
Validation loss: 3.089912562819232

Epoch: 132| Step: 0
Training loss: 3.342928491373619
Validation loss: 3.0893029429527563

Epoch: 6| Step: 1
Training loss: 3.4224012832393087
Validation loss: 3.089710339798619

Epoch: 6| Step: 2
Training loss: 3.0424379564038597
Validation loss: 3.0883128314132455

Epoch: 6| Step: 3
Training loss: 2.7491495377938873
Validation loss: 3.089883406044586

Epoch: 6| Step: 4
Training loss: 3.52912528333905
Validation loss: 3.09176756186688

Epoch: 6| Step: 5
Training loss: 3.6247463795302934
Validation loss: 3.0894275150173702

Epoch: 6| Step: 6
Training loss: 2.4601315101888996
Validation loss: 3.089229822840834

Epoch: 6| Step: 7
Training loss: 3.29887264531089
Validation loss: 3.0880393676545848

Epoch: 6| Step: 8
Training loss: 3.862265550726176
Validation loss: 3.0877189880404816

Epoch: 6| Step: 9
Training loss: 3.5357324288743555
Validation loss: 3.089388701198383

Epoch: 6| Step: 10
Training loss: 3.407336140622952
Validation loss: 3.0870153220652514

Epoch: 6| Step: 11
Training loss: 3.535356547545654
Validation loss: 3.0870637191939427

Epoch: 6| Step: 12
Training loss: 3.7485958013464935
Validation loss: 3.0874818056455693

Epoch: 6| Step: 13
Training loss: 2.778803831909797
Validation loss: 3.087978605895498

Epoch: 133| Step: 0
Training loss: 2.966637592673262
Validation loss: 3.0876573498364

Epoch: 6| Step: 1
Training loss: 3.544280191148022
Validation loss: 3.08798637489974

Epoch: 6| Step: 2
Training loss: 3.73796426192457
Validation loss: 3.08675726265547

Epoch: 6| Step: 3
Training loss: 3.7016708158503855
Validation loss: 3.087145937265204

Epoch: 6| Step: 4
Training loss: 3.881883598370934
Validation loss: 3.088748060838458

Epoch: 6| Step: 5
Training loss: 3.0653276429534877
Validation loss: 3.0949966158082933

Epoch: 6| Step: 6
Training loss: 3.069196270038551
Validation loss: 3.0898018748017346

Epoch: 6| Step: 7
Training loss: 3.1394607131864403
Validation loss: 3.0875574531140146

Epoch: 6| Step: 8
Training loss: 3.4028891685747737
Validation loss: 3.091000538922486

Epoch: 6| Step: 9
Training loss: 3.8287412809097687
Validation loss: 3.093724593440119

Epoch: 6| Step: 10
Training loss: 3.204866261660064
Validation loss: 3.087242369597491

Epoch: 6| Step: 11
Training loss: 1.7764772419866197
Validation loss: 3.0828683619514883

Epoch: 6| Step: 12
Training loss: 3.3601385623880553
Validation loss: 3.082286924603972

Epoch: 6| Step: 13
Training loss: 3.825175367336947
Validation loss: 3.0810918723020455

Epoch: 134| Step: 0
Training loss: 2.989014539318898
Validation loss: 3.083806711346459

Epoch: 6| Step: 1
Training loss: 3.233808827257728
Validation loss: 3.083415760068191

Epoch: 6| Step: 2
Training loss: 3.0329971783955343
Validation loss: 3.082407795537424

Epoch: 6| Step: 3
Training loss: 3.1204462059994134
Validation loss: 3.0824789899561753

Epoch: 6| Step: 4
Training loss: 3.352270376148781
Validation loss: 3.0813840015961635

Epoch: 6| Step: 5
Training loss: 3.608053254379429
Validation loss: 3.083141654081015

Epoch: 6| Step: 6
Training loss: 3.740589668789062
Validation loss: 3.08561287010076

Epoch: 6| Step: 7
Training loss: 3.7243799500001193
Validation loss: 3.0852798951293505

Epoch: 6| Step: 8
Training loss: 3.4249142601252056
Validation loss: 3.0844160926487647

Epoch: 6| Step: 9
Training loss: 2.5948399471251187
Validation loss: 3.0837549344286983

Epoch: 6| Step: 10
Training loss: 3.4346812395454043
Validation loss: 3.0838005828243715

Epoch: 6| Step: 11
Training loss: 3.3853383842611877
Validation loss: 3.0883928214768166

Epoch: 6| Step: 12
Training loss: 3.420949593046361
Validation loss: 3.0800490765549755

Epoch: 6| Step: 13
Training loss: 3.776134845855544
Validation loss: 3.0829188931100937

Epoch: 135| Step: 0
Training loss: 4.03936258820851
Validation loss: 3.0798271149175873

Epoch: 6| Step: 1
Training loss: 3.60787774279365
Validation loss: 3.080350511175577

Epoch: 6| Step: 2
Training loss: 2.585634150388597
Validation loss: 3.079067694066241

Epoch: 6| Step: 3
Training loss: 3.904937035203176
Validation loss: 3.0815354875736434

Epoch: 6| Step: 4
Training loss: 3.5119199769411713
Validation loss: 3.077790122948149

Epoch: 6| Step: 5
Training loss: 2.6747755402129054
Validation loss: 3.076805513631039

Epoch: 6| Step: 6
Training loss: 3.480593558149071
Validation loss: 3.0783093125916574

Epoch: 6| Step: 7
Training loss: 3.3226310264406744
Validation loss: 3.0768903820783184

Epoch: 6| Step: 8
Training loss: 3.076643069071044
Validation loss: 3.0787081551504003

Epoch: 6| Step: 9
Training loss: 3.322738084608272
Validation loss: 3.075711566102831

Epoch: 6| Step: 10
Training loss: 3.198748618062635
Validation loss: 3.0797077626076264

Epoch: 6| Step: 11
Training loss: 3.7525936058614118
Validation loss: 3.0759903046879375

Epoch: 6| Step: 12
Training loss: 2.93273880814659
Validation loss: 3.0751677635350387

Epoch: 6| Step: 13
Training loss: 2.7010211143981833
Validation loss: 3.0776865149063326

Epoch: 136| Step: 0
Training loss: 3.9003676412379904
Validation loss: 3.072980779052363

Epoch: 6| Step: 1
Training loss: 3.054247265871574
Validation loss: 3.0725761668479157

Epoch: 6| Step: 2
Training loss: 3.5835144233780607
Validation loss: 3.074679510844816

Epoch: 6| Step: 3
Training loss: 3.506151107508643
Validation loss: 3.074546630009355

Epoch: 6| Step: 4
Training loss: 3.4693333590617708
Validation loss: 3.0744400383618555

Epoch: 6| Step: 5
Training loss: 3.6862855624827744
Validation loss: 3.073787016308812

Epoch: 6| Step: 6
Training loss: 3.3573707456839808
Validation loss: 3.0741252532362084

Epoch: 6| Step: 7
Training loss: 2.7180171285711308
Validation loss: 3.0729690677992165

Epoch: 6| Step: 8
Training loss: 3.0419907767352266
Validation loss: 3.0720162088947567

Epoch: 6| Step: 9
Training loss: 2.2204785128547866
Validation loss: 3.0752533440882246

Epoch: 6| Step: 10
Training loss: 3.8121490316969724
Validation loss: 3.07494452495075

Epoch: 6| Step: 11
Training loss: 3.510585580869019
Validation loss: 3.0719198093282603

Epoch: 6| Step: 12
Training loss: 3.2230230319211857
Validation loss: 3.0747887822390614

Epoch: 6| Step: 13
Training loss: 3.235006519529209
Validation loss: 3.074366312923064

Epoch: 137| Step: 0
Training loss: 3.613776095760235
Validation loss: 3.0734250362322086

Epoch: 6| Step: 1
Training loss: 3.259232831215237
Validation loss: 3.0734173371888205

Epoch: 6| Step: 2
Training loss: 2.866829249480811
Validation loss: 3.0739857233167385

Epoch: 6| Step: 3
Training loss: 3.5581004767123106
Validation loss: 3.077535113533049

Epoch: 6| Step: 4
Training loss: 3.932113353736861
Validation loss: 3.0738968598639

Epoch: 6| Step: 5
Training loss: 3.216527671643938
Validation loss: 3.074914836062705

Epoch: 6| Step: 6
Training loss: 3.113887407172247
Validation loss: 3.075825606684617

Epoch: 6| Step: 7
Training loss: 3.3619011895286715
Validation loss: 3.0743512630901133

Epoch: 6| Step: 8
Training loss: 4.052572474175788
Validation loss: 3.0743220704735927

Epoch: 6| Step: 9
Training loss: 3.322220556995169
Validation loss: 3.072743563662994

Epoch: 6| Step: 10
Training loss: 2.59449279444222
Validation loss: 3.0695823943812903

Epoch: 6| Step: 11
Training loss: 2.899144500299729
Validation loss: 3.0791562401095485

Epoch: 6| Step: 12
Training loss: 3.291980454823723
Validation loss: 3.0842931401508156

Epoch: 6| Step: 13
Training loss: 3.351062941945637
Validation loss: 3.074241816033917

Epoch: 138| Step: 0
Training loss: 3.3044736535973978
Validation loss: 3.0799823989333284

Epoch: 6| Step: 1
Training loss: 2.9749376562943115
Validation loss: 3.08422394594243

Epoch: 6| Step: 2
Training loss: 3.32544008942126
Validation loss: 3.0890158814711905

Epoch: 6| Step: 3
Training loss: 2.99320723485382
Validation loss: 3.0760686949995084

Epoch: 6| Step: 4
Training loss: 3.5315967490845455
Validation loss: 3.0719635222340043

Epoch: 6| Step: 5
Training loss: 3.297141837218831
Validation loss: 3.0714149728264877

Epoch: 6| Step: 6
Training loss: 3.039853186826781
Validation loss: 3.069872156607582

Epoch: 6| Step: 7
Training loss: 2.954289766732077
Validation loss: 3.0696446544282234

Epoch: 6| Step: 8
Training loss: 3.4384367620087195
Validation loss: 3.069544321825563

Epoch: 6| Step: 9
Training loss: 3.241613277463091
Validation loss: 3.067618359840153

Epoch: 6| Step: 10
Training loss: 3.732955854496687
Validation loss: 3.069466340347547

Epoch: 6| Step: 11
Training loss: 3.8971069756347485
Validation loss: 3.069654778206066

Epoch: 6| Step: 12
Training loss: 3.51451561272182
Validation loss: 3.069407279766901

Epoch: 6| Step: 13
Training loss: 3.2957164301597466
Validation loss: 3.068411141840458

Epoch: 139| Step: 0
Training loss: 3.0304665093685323
Validation loss: 3.069327623482256

Epoch: 6| Step: 1
Training loss: 3.209082148636014
Validation loss: 3.0695614364106416

Epoch: 6| Step: 2
Training loss: 3.3696396256372934
Validation loss: 3.067256637192808

Epoch: 6| Step: 3
Training loss: 3.4128276066847003
Validation loss: 3.067651915101514

Epoch: 6| Step: 4
Training loss: 4.052057548905084
Validation loss: 3.0677705706888396

Epoch: 6| Step: 5
Training loss: 3.5396086753460416
Validation loss: 3.068604473354814

Epoch: 6| Step: 6
Training loss: 2.65952153412918
Validation loss: 3.066744289468015

Epoch: 6| Step: 7
Training loss: 3.466239776981437
Validation loss: 3.066987044353051

Epoch: 6| Step: 8
Training loss: 3.175779147927502
Validation loss: 3.0673637952258566

Epoch: 6| Step: 9
Training loss: 2.9903539712162748
Validation loss: 3.0670587939912735

Epoch: 6| Step: 10
Training loss: 3.2733094547693056
Validation loss: 3.066700968633012

Epoch: 6| Step: 11
Training loss: 3.769965112256589
Validation loss: 3.0667105052546764

Epoch: 6| Step: 12
Training loss: 3.4347208058975234
Validation loss: 3.066208464801098

Epoch: 6| Step: 13
Training loss: 2.8630520883739066
Validation loss: 3.065851391441811

Epoch: 140| Step: 0
Training loss: 3.7055951985823863
Validation loss: 3.0663420681506572

Epoch: 6| Step: 1
Training loss: 3.9880052969848596
Validation loss: 3.066882084141709

Epoch: 6| Step: 2
Training loss: 2.883578893829416
Validation loss: 3.0688871404442413

Epoch: 6| Step: 3
Training loss: 3.4139448970555804
Validation loss: 3.065763039786532

Epoch: 6| Step: 4
Training loss: 3.045375043951926
Validation loss: 3.065773389616631

Epoch: 6| Step: 5
Training loss: 3.0425180436839776
Validation loss: 3.0687904061689673

Epoch: 6| Step: 6
Training loss: 3.1456096813875623
Validation loss: 3.066651877300274

Epoch: 6| Step: 7
Training loss: 3.2710902281223575
Validation loss: 3.0656039656019005

Epoch: 6| Step: 8
Training loss: 3.1630119180807554
Validation loss: 3.066457457069462

Epoch: 6| Step: 9
Training loss: 3.7370600923111903
Validation loss: 3.064475394508773

Epoch: 6| Step: 10
Training loss: 3.0211055939853817
Validation loss: 3.0656702635432374

Epoch: 6| Step: 11
Training loss: 2.5913254769829925
Validation loss: 3.0637077376042545

Epoch: 6| Step: 12
Training loss: 3.7052593277382107
Validation loss: 3.064063564792592

Epoch: 6| Step: 13
Training loss: 3.845973294495194
Validation loss: 3.063786581080128

Epoch: 141| Step: 0
Training loss: 3.6026176843209887
Validation loss: 3.062988538619402

Epoch: 6| Step: 1
Training loss: 2.9042738892415896
Validation loss: 3.063664256681332

Epoch: 6| Step: 2
Training loss: 3.397898383513347
Validation loss: 3.0630579380126406

Epoch: 6| Step: 3
Training loss: 2.8785907049659403
Validation loss: 3.0634378801499054

Epoch: 6| Step: 4
Training loss: 3.4171039642603027
Validation loss: 3.061441107439732

Epoch: 6| Step: 5
Training loss: 3.943583073536773
Validation loss: 3.062530823804221

Epoch: 6| Step: 6
Training loss: 3.25022814023293
Validation loss: 3.0626017034810946

Epoch: 6| Step: 7
Training loss: 3.743515002178194
Validation loss: 3.060279587049156

Epoch: 6| Step: 8
Training loss: 2.4217103963720525
Validation loss: 3.060485233189471

Epoch: 6| Step: 9
Training loss: 3.3389348806752936
Validation loss: 3.0614252035605762

Epoch: 6| Step: 10
Training loss: 3.368301242812035
Validation loss: 3.0619753014961644

Epoch: 6| Step: 11
Training loss: 3.0271311039228075
Validation loss: 3.061914246899753

Epoch: 6| Step: 12
Training loss: 2.957371801724094
Validation loss: 3.0619878099944673

Epoch: 6| Step: 13
Training loss: 4.403729089648855
Validation loss: 3.0611434587412307

Epoch: 142| Step: 0
Training loss: 3.390935646276694
Validation loss: 3.061918490167425

Epoch: 6| Step: 1
Training loss: 3.347957637578107
Validation loss: 3.0595800473079886

Epoch: 6| Step: 2
Training loss: 3.314619142221833
Validation loss: 3.060480291839599

Epoch: 6| Step: 3
Training loss: 3.328713235225913
Validation loss: 3.0599982193168143

Epoch: 6| Step: 4
Training loss: 3.871910340130158
Validation loss: 3.059302434762786

Epoch: 6| Step: 5
Training loss: 3.219238096098603
Validation loss: 3.0593620088431686

Epoch: 6| Step: 6
Training loss: 3.2825413660492107
Validation loss: 3.0582914283548073

Epoch: 6| Step: 7
Training loss: 2.7452577102395836
Validation loss: 3.0606274483367435

Epoch: 6| Step: 8
Training loss: 2.9240159947157465
Validation loss: 3.061456754994204

Epoch: 6| Step: 9
Training loss: 3.2399493109894113
Validation loss: 3.060994548161613

Epoch: 6| Step: 10
Training loss: 3.3460280599654526
Validation loss: 3.0599685663791987

Epoch: 6| Step: 11
Training loss: 3.76105852364221
Validation loss: 3.059400554187714

Epoch: 6| Step: 12
Training loss: 3.138635109363853
Validation loss: 3.060488690203024

Epoch: 6| Step: 13
Training loss: 3.6179456801925896
Validation loss: 3.0618011333489794

Epoch: 143| Step: 0
Training loss: 3.66347331371144
Validation loss: 3.072593548226851

Epoch: 6| Step: 1
Training loss: 3.0049429544375426
Validation loss: 3.0735409966740006

Epoch: 6| Step: 2
Training loss: 3.658956976517469
Validation loss: 3.0709072116227554

Epoch: 6| Step: 3
Training loss: 3.744566732485627
Validation loss: 3.075253555831657

Epoch: 6| Step: 4
Training loss: 3.4608654419434988
Validation loss: 3.0654586118811626

Epoch: 6| Step: 5
Training loss: 3.395940876449461
Validation loss: 3.0583585160099283

Epoch: 6| Step: 6
Training loss: 3.335620445175449
Validation loss: 3.055208933203856

Epoch: 6| Step: 7
Training loss: 3.585099664683381
Validation loss: 3.0592917345508193

Epoch: 6| Step: 8
Training loss: 2.4556137386849266
Validation loss: 3.0581837051330774

Epoch: 6| Step: 9
Training loss: 2.550438383230474
Validation loss: 3.058257480349157

Epoch: 6| Step: 10
Training loss: 3.0964232945833294
Validation loss: 3.0576752642840423

Epoch: 6| Step: 11
Training loss: 3.1959741182580306
Validation loss: 3.05864886881164

Epoch: 6| Step: 12
Training loss: 3.637000379300668
Validation loss: 3.058954183943887

Epoch: 6| Step: 13
Training loss: 3.499116513597743
Validation loss: 3.055354884454538

Epoch: 144| Step: 0
Training loss: 3.43029932634497
Validation loss: 3.0573349022519847

Epoch: 6| Step: 1
Training loss: 3.3245807813657007
Validation loss: 3.056297575968295

Epoch: 6| Step: 2
Training loss: 3.1791270368979974
Validation loss: 3.055659433005575

Epoch: 6| Step: 3
Training loss: 2.914514256045739
Validation loss: 3.054873627805285

Epoch: 6| Step: 4
Training loss: 2.8596894971982083
Validation loss: 3.0548667027441923

Epoch: 6| Step: 5
Training loss: 3.2040653988263186
Validation loss: 3.0542314672263955

Epoch: 6| Step: 6
Training loss: 3.6104940686052363
Validation loss: 3.0535083940758008

Epoch: 6| Step: 7
Training loss: 3.6950262817769595
Validation loss: 3.0521351732415796

Epoch: 6| Step: 8
Training loss: 2.908067196653383
Validation loss: 3.0547443837055823

Epoch: 6| Step: 9
Training loss: 3.3342689790468
Validation loss: 3.05452083756871

Epoch: 6| Step: 10
Training loss: 3.420583263430456
Validation loss: 3.0530000714216805

Epoch: 6| Step: 11
Training loss: 3.610214994374023
Validation loss: 3.05422527768071

Epoch: 6| Step: 12
Training loss: 3.059055493263281
Validation loss: 3.052163677648304

Epoch: 6| Step: 13
Training loss: 4.072095601216801
Validation loss: 3.0531779193312967

Epoch: 145| Step: 0
Training loss: 3.56890667840312
Validation loss: 3.053057932064841

Epoch: 6| Step: 1
Training loss: 3.092703594145458
Validation loss: 3.0537098914622955

Epoch: 6| Step: 2
Training loss: 3.6210588537878277
Validation loss: 3.0538741662019437

Epoch: 6| Step: 3
Training loss: 4.086202171608235
Validation loss: 3.0527920744047097

Epoch: 6| Step: 4
Training loss: 2.876083667360481
Validation loss: 3.055777603731138

Epoch: 6| Step: 5
Training loss: 3.996481062837671
Validation loss: 3.05571290500069

Epoch: 6| Step: 6
Training loss: 3.4255436431015527
Validation loss: 3.054231566272455

Epoch: 6| Step: 7
Training loss: 2.9186473297424267
Validation loss: 3.0533817638187593

Epoch: 6| Step: 8
Training loss: 2.3482542371278115
Validation loss: 3.05515159579228

Epoch: 6| Step: 9
Training loss: 3.3894457194586036
Validation loss: 3.060662881103473

Epoch: 6| Step: 10
Training loss: 3.5935708706205935
Validation loss: 3.066897346167758

Epoch: 6| Step: 11
Training loss: 2.6764752678315493
Validation loss: 3.0679124606538597

Epoch: 6| Step: 12
Training loss: 2.7771129914684445
Validation loss: 3.051400397416945

Epoch: 6| Step: 13
Training loss: 3.969116914864351
Validation loss: 3.0505299445172795

Epoch: 146| Step: 0
Training loss: 2.7452269660769177
Validation loss: 3.0491132947133606

Epoch: 6| Step: 1
Training loss: 3.2213467983612847
Validation loss: 3.0503283782662742

Epoch: 6| Step: 2
Training loss: 3.6834743961807765
Validation loss: 3.04981005215178

Epoch: 6| Step: 3
Training loss: 3.7585374921903063
Validation loss: 3.047141517781203

Epoch: 6| Step: 4
Training loss: 3.179426702728028
Validation loss: 3.04933809144786

Epoch: 6| Step: 5
Training loss: 3.227464009622825
Validation loss: 3.049566719302657

Epoch: 6| Step: 6
Training loss: 3.4439304200696697
Validation loss: 3.0495995846241293

Epoch: 6| Step: 7
Training loss: 3.8588599969517188
Validation loss: 3.050247517747613

Epoch: 6| Step: 8
Training loss: 3.2526395789184326
Validation loss: 3.0498308768638718

Epoch: 6| Step: 9
Training loss: 2.7094069675904784
Validation loss: 3.056894697155555

Epoch: 6| Step: 10
Training loss: 3.8539410224365067
Validation loss: 3.0532279002841376

Epoch: 6| Step: 11
Training loss: 2.4930529392220437
Validation loss: 3.0589208257637828

Epoch: 6| Step: 12
Training loss: 3.068161227738362
Validation loss: 3.0611408843324406

Epoch: 6| Step: 13
Training loss: 3.7797646876161486
Validation loss: 3.066286500706569

Epoch: 147| Step: 0
Training loss: 3.985819595848133
Validation loss: 3.068530069671429

Epoch: 6| Step: 1
Training loss: 3.307059084105786
Validation loss: 3.061702898271453

Epoch: 6| Step: 2
Training loss: 3.577452750543751
Validation loss: 3.0546675661144373

Epoch: 6| Step: 3
Training loss: 3.2567448684793683
Validation loss: 3.05254079337361

Epoch: 6| Step: 4
Training loss: 2.7169362299135753
Validation loss: 3.0513858661105817

Epoch: 6| Step: 5
Training loss: 3.518797667808926
Validation loss: 3.04430507653741

Epoch: 6| Step: 6
Training loss: 3.562957198938102
Validation loss: 3.046142986617695

Epoch: 6| Step: 7
Training loss: 2.2143384030661295
Validation loss: 3.044548820656194

Epoch: 6| Step: 8
Training loss: 3.140890233620997
Validation loss: 3.0432638901674376

Epoch: 6| Step: 9
Training loss: 3.320206512554715
Validation loss: 3.0452846856185203

Epoch: 6| Step: 10
Training loss: 2.7810884064439207
Validation loss: 3.0458952904951064

Epoch: 6| Step: 11
Training loss: 4.212265116767988
Validation loss: 3.0455214639491395

Epoch: 6| Step: 12
Training loss: 2.998514602409302
Validation loss: 3.046266177856528

Epoch: 6| Step: 13
Training loss: 3.3031687752557706
Validation loss: 3.044052584559073

Epoch: 148| Step: 0
Training loss: 3.9172458761496483
Validation loss: 3.0444148217409217

Epoch: 6| Step: 1
Training loss: 3.366423836691124
Validation loss: 3.04303292945768

Epoch: 6| Step: 2
Training loss: 3.8591250442921528
Validation loss: 3.0431075151042286

Epoch: 6| Step: 3
Training loss: 3.3239988440317654
Validation loss: 3.043850201943478

Epoch: 6| Step: 4
Training loss: 3.3690409858454737
Validation loss: 3.0430532563210746

Epoch: 6| Step: 5
Training loss: 3.4706272853278426
Validation loss: 3.0427471073165897

Epoch: 6| Step: 6
Training loss: 2.7442032667727907
Validation loss: 3.040511408470465

Epoch: 6| Step: 7
Training loss: 2.4524570211675125
Validation loss: 3.042936307603131

Epoch: 6| Step: 8
Training loss: 3.339394558151919
Validation loss: 3.0418898033818627

Epoch: 6| Step: 9
Training loss: 3.2869276063361106
Validation loss: 3.0413602966026736

Epoch: 6| Step: 10
Training loss: 3.2461821799966093
Validation loss: 3.04166247886901

Epoch: 6| Step: 11
Training loss: 3.131003906569211
Validation loss: 3.0422371921908913

Epoch: 6| Step: 12
Training loss: 3.1362824284993014
Validation loss: 3.0424344005154706

Epoch: 6| Step: 13
Training loss: 3.546426753149443
Validation loss: 3.040632343176924

Epoch: 149| Step: 0
Training loss: 3.841809783277755
Validation loss: 3.042534036283095

Epoch: 6| Step: 1
Training loss: 2.77654210793172
Validation loss: 3.039940031420301

Epoch: 6| Step: 2
Training loss: 3.960933286525434
Validation loss: 3.0406504661477474

Epoch: 6| Step: 3
Training loss: 3.3526279561019194
Validation loss: 3.0392890371450076

Epoch: 6| Step: 4
Training loss: 3.365419423688356
Validation loss: 3.042103602140918

Epoch: 6| Step: 5
Training loss: 2.9614209105097
Validation loss: 3.043350895200197

Epoch: 6| Step: 6
Training loss: 3.050086886309648
Validation loss: 3.043125447265191

Epoch: 6| Step: 7
Training loss: 3.5731459711782914
Validation loss: 3.0447589721475823

Epoch: 6| Step: 8
Training loss: 3.3188815275806713
Validation loss: 3.0416777662972887

Epoch: 6| Step: 9
Training loss: 3.1831867730187287
Validation loss: 3.047394955981509

Epoch: 6| Step: 10
Training loss: 3.511553903684442
Validation loss: 3.043245578055898

Epoch: 6| Step: 11
Training loss: 2.736922815518901
Validation loss: 3.0413696168174162

Epoch: 6| Step: 12
Training loss: 3.439937213058569
Validation loss: 3.039665091777979

Epoch: 6| Step: 13
Training loss: 2.6914827864661794
Validation loss: 3.040092732502594

Epoch: 150| Step: 0
Training loss: 3.108818272729438
Validation loss: 3.0401840816537105

Epoch: 6| Step: 1
Training loss: 3.211831666765811
Validation loss: 3.0391242211897636

Epoch: 6| Step: 2
Training loss: 3.938929706954432
Validation loss: 3.0385799099131794

Epoch: 6| Step: 3
Training loss: 3.152758943237272
Validation loss: 3.0393371736280597

Epoch: 6| Step: 4
Training loss: 3.6272583865379593
Validation loss: 3.0384216586154844

Epoch: 6| Step: 5
Training loss: 2.692630660943164
Validation loss: 3.037323790479124

Epoch: 6| Step: 6
Training loss: 2.8350761513683573
Validation loss: 3.0372056441251205

Epoch: 6| Step: 7
Training loss: 3.1275438254721584
Validation loss: 3.0377077783850797

Epoch: 6| Step: 8
Training loss: 4.045144436477255
Validation loss: 3.037278522273081

Epoch: 6| Step: 9
Training loss: 3.0723824936548665
Validation loss: 3.0362129563270557

Epoch: 6| Step: 10
Training loss: 3.0548451570768393
Validation loss: 3.0360710929821684

Epoch: 6| Step: 11
Training loss: 3.2768503392826975
Validation loss: 3.0367111590203835

Epoch: 6| Step: 12
Training loss: 3.6955768901932706
Validation loss: 3.036357678648425

Epoch: 6| Step: 13
Training loss: 3.0192204521485135
Validation loss: 3.037723013137097

Epoch: 151| Step: 0
Training loss: 4.014213105996188
Validation loss: 3.036126476288579

Epoch: 6| Step: 1
Training loss: 3.6082101238497133
Validation loss: 3.033886421697949

Epoch: 6| Step: 2
Training loss: 3.2609246846391837
Validation loss: 3.0358135773133528

Epoch: 6| Step: 3
Training loss: 2.975159802672863
Validation loss: 3.036847680900625

Epoch: 6| Step: 4
Training loss: 2.3886588993796183
Validation loss: 3.035941419982651

Epoch: 6| Step: 5
Training loss: 3.4032928509473117
Validation loss: 3.0365020698708935

Epoch: 6| Step: 6
Training loss: 3.084521468529492
Validation loss: 3.0363089883328604

Epoch: 6| Step: 7
Training loss: 3.681742683432904
Validation loss: 3.034430429267424

Epoch: 6| Step: 8
Training loss: 3.441714945185905
Validation loss: 3.0354047253268575

Epoch: 6| Step: 9
Training loss: 2.8713136342245833
Validation loss: 3.0365311026364554

Epoch: 6| Step: 10
Training loss: 3.072365887091744
Validation loss: 3.0341013141964694

Epoch: 6| Step: 11
Training loss: 3.486573487951982
Validation loss: 3.034641501112016

Epoch: 6| Step: 12
Training loss: 3.894183021825079
Validation loss: 3.035240220428838

Epoch: 6| Step: 13
Training loss: 2.0044830860272156
Validation loss: 3.0329559840154703

Epoch: 152| Step: 0
Training loss: 3.7127362519689666
Validation loss: 3.0336878278561494

Epoch: 6| Step: 1
Training loss: 3.6885788196127915
Validation loss: 3.0352631164447

Epoch: 6| Step: 2
Training loss: 3.2274473145526157
Validation loss: 3.0340098807642546

Epoch: 6| Step: 3
Training loss: 3.232120631261218
Validation loss: 3.03328017050511

Epoch: 6| Step: 4
Training loss: 3.106009957999474
Validation loss: 3.0334213737517937

Epoch: 6| Step: 5
Training loss: 3.6768995604731463
Validation loss: 3.033301661016264

Epoch: 6| Step: 6
Training loss: 2.726522275961353
Validation loss: 3.0342030680501475

Epoch: 6| Step: 7
Training loss: 3.1967814829880985
Validation loss: 3.033416227740361

Epoch: 6| Step: 8
Training loss: 2.6798971110848595
Validation loss: 3.032374669086619

Epoch: 6| Step: 9
Training loss: 3.905871075371264
Validation loss: 3.031956023697105

Epoch: 6| Step: 10
Training loss: 3.7852285592777193
Validation loss: 3.0328552052048963

Epoch: 6| Step: 11
Training loss: 3.250520517774747
Validation loss: 3.0313329250815038

Epoch: 6| Step: 12
Training loss: 2.428914330420883
Validation loss: 3.030430001081326

Epoch: 6| Step: 13
Training loss: 3.206072981262535
Validation loss: 3.030593511739256

Epoch: 153| Step: 0
Training loss: 3.273163194475408
Validation loss: 3.0323156207567004

Epoch: 6| Step: 1
Training loss: 3.408994776208422
Validation loss: 3.0311828984744484

Epoch: 6| Step: 2
Training loss: 3.060000742743907
Validation loss: 3.030346256061539

Epoch: 6| Step: 3
Training loss: 3.129963404529882
Validation loss: 3.0311840859154136

Epoch: 6| Step: 4
Training loss: 3.3995728448805043
Validation loss: 3.0286709379502406

Epoch: 6| Step: 5
Training loss: 2.861982980204371
Validation loss: 3.0306275902936934

Epoch: 6| Step: 6
Training loss: 3.3349640830878284
Validation loss: 3.029937725650291

Epoch: 6| Step: 7
Training loss: 2.878927947626427
Validation loss: 3.0301328731169552

Epoch: 6| Step: 8
Training loss: 3.360365043065448
Validation loss: 3.0293174175893713

Epoch: 6| Step: 9
Training loss: 3.3106429454626043
Validation loss: 3.0304345472990035

Epoch: 6| Step: 10
Training loss: 3.5397851471437436
Validation loss: 3.0317784533688616

Epoch: 6| Step: 11
Training loss: 3.377502926162367
Validation loss: 3.028748361563728

Epoch: 6| Step: 12
Training loss: 3.3298765059932802
Validation loss: 3.0308221790609067

Epoch: 6| Step: 13
Training loss: 4.176290511363252
Validation loss: 3.0303178374543043

Epoch: 154| Step: 0
Training loss: 4.125795229928029
Validation loss: 3.0317399584989317

Epoch: 6| Step: 1
Training loss: 3.3890880845802673
Validation loss: 3.030042816639885

Epoch: 6| Step: 2
Training loss: 3.8365847163944884
Validation loss: 3.0268200599007082

Epoch: 6| Step: 3
Training loss: 2.1750160392082143
Validation loss: 3.0276882032566497

Epoch: 6| Step: 4
Training loss: 2.54385393384948
Validation loss: 3.027524285889247

Epoch: 6| Step: 5
Training loss: 2.970936502071497
Validation loss: 3.0280080427813805

Epoch: 6| Step: 6
Training loss: 4.121892509972759
Validation loss: 3.028158075988089

Epoch: 6| Step: 7
Training loss: 3.396390592257578
Validation loss: 3.028904810998612

Epoch: 6| Step: 8
Training loss: 2.5980459279500416
Validation loss: 3.026498515054734

Epoch: 6| Step: 9
Training loss: 2.8047008460957272
Validation loss: 3.0268510336145398

Epoch: 6| Step: 10
Training loss: 3.217199452078333
Validation loss: 3.0266215648229737

Epoch: 6| Step: 11
Training loss: 3.451300643996971
Validation loss: 3.0259922019238488

Epoch: 6| Step: 12
Training loss: 3.6168402552513754
Validation loss: 3.026450539460238

Epoch: 6| Step: 13
Training loss: 3.131323405793065
Validation loss: 3.025510500778224

Epoch: 155| Step: 0
Training loss: 3.2570028419564214
Validation loss: 3.023717342169268

Epoch: 6| Step: 1
Training loss: 2.8701120371997852
Validation loss: 3.025910761820455

Epoch: 6| Step: 2
Training loss: 3.062547488720216
Validation loss: 3.0278170494243954

Epoch: 6| Step: 3
Training loss: 3.434930430544861
Validation loss: 3.026705024970921

Epoch: 6| Step: 4
Training loss: 3.5858630336766995
Validation loss: 3.0264099844669152

Epoch: 6| Step: 5
Training loss: 3.0040008569708565
Validation loss: 3.0261587323238257

Epoch: 6| Step: 6
Training loss: 3.196519693596505
Validation loss: 3.0249642822494636

Epoch: 6| Step: 7
Training loss: 3.367729833699266
Validation loss: 3.0235242073099107

Epoch: 6| Step: 8
Training loss: 3.5107999115125827
Validation loss: 3.0227754612170963

Epoch: 6| Step: 9
Training loss: 3.536791748749626
Validation loss: 3.0238866433998792

Epoch: 6| Step: 10
Training loss: 4.231688150233908
Validation loss: 3.0248173231308733

Epoch: 6| Step: 11
Training loss: 2.8239746832482755
Validation loss: 3.0231925286617427

Epoch: 6| Step: 12
Training loss: 3.095476381680373
Validation loss: 3.0232747928639974

Epoch: 6| Step: 13
Training loss: 2.4682850460229284
Validation loss: 3.023098923400894

Epoch: 156| Step: 0
Training loss: 3.4060796292595588
Validation loss: 3.0213794343348446

Epoch: 6| Step: 1
Training loss: 3.5416679980705603
Validation loss: 3.025747889441292

Epoch: 6| Step: 2
Training loss: 2.6493813062387166
Validation loss: 3.0224841949571597

Epoch: 6| Step: 3
Training loss: 3.0419229025015055
Validation loss: 3.0219393280122335

Epoch: 6| Step: 4
Training loss: 4.143038755109922
Validation loss: 3.0211580644381844

Epoch: 6| Step: 5
Training loss: 3.5948244561853886
Validation loss: 3.022127189394757

Epoch: 6| Step: 6
Training loss: 2.6676200314859786
Validation loss: 3.0226058738341934

Epoch: 6| Step: 7
Training loss: 3.618515001747415
Validation loss: 3.020743645739385

Epoch: 6| Step: 8
Training loss: 2.971245289222279
Validation loss: 3.0204175437348457

Epoch: 6| Step: 9
Training loss: 3.53258090974731
Validation loss: 3.020009848460374

Epoch: 6| Step: 10
Training loss: 3.125647515923513
Validation loss: 3.020851538026557

Epoch: 6| Step: 11
Training loss: 2.9980840922974967
Validation loss: 3.019149258798079

Epoch: 6| Step: 12
Training loss: 3.4213197858645774
Validation loss: 3.017368364236689

Epoch: 6| Step: 13
Training loss: 2.837126847656767
Validation loss: 3.0195586808434687

Epoch: 157| Step: 0
Training loss: 3.1522240976459437
Validation loss: 3.018253098296474

Epoch: 6| Step: 1
Training loss: 3.5061842913938914
Validation loss: 3.0187392487492977

Epoch: 6| Step: 2
Training loss: 2.851991553231206
Validation loss: 3.0209468889516184

Epoch: 6| Step: 3
Training loss: 3.885873121733762
Validation loss: 3.0193941659126105

Epoch: 6| Step: 4
Training loss: 2.761930249868588
Validation loss: 3.016212492439496

Epoch: 6| Step: 5
Training loss: 3.1301724161551228
Validation loss: 3.019824198426447

Epoch: 6| Step: 6
Training loss: 3.0920596658691633
Validation loss: 3.015787737323009

Epoch: 6| Step: 7
Training loss: 3.614573380660867
Validation loss: 3.018732949064393

Epoch: 6| Step: 8
Training loss: 3.9347307670031593
Validation loss: 3.015903681692118

Epoch: 6| Step: 9
Training loss: 2.6942784191599745
Validation loss: 3.0181410750259103

Epoch: 6| Step: 10
Training loss: 3.0076458773349146
Validation loss: 3.0178000497324105

Epoch: 6| Step: 11
Training loss: 3.712799183513648
Validation loss: 3.021088099671885

Epoch: 6| Step: 12
Training loss: 3.341007855193453
Validation loss: 3.0159752058118876

Epoch: 6| Step: 13
Training loss: 2.779569482469099
Validation loss: 3.016085003506313

Epoch: 158| Step: 0
Training loss: 3.7051351378965496
Validation loss: 3.0136923964962645

Epoch: 6| Step: 1
Training loss: 3.185519931101564
Validation loss: 3.0182158222218645

Epoch: 6| Step: 2
Training loss: 3.4220270271148063
Validation loss: 3.0152463875598787

Epoch: 6| Step: 3
Training loss: 3.2163356874262092
Validation loss: 3.0167830701130014

Epoch: 6| Step: 4
Training loss: 3.1541596090488935
Validation loss: 3.0173012148401264

Epoch: 6| Step: 5
Training loss: 3.388087012748792
Validation loss: 3.018075417430478

Epoch: 6| Step: 6
Training loss: 3.577126975988377
Validation loss: 3.0156320593813617

Epoch: 6| Step: 7
Training loss: 3.105470285475249
Validation loss: 3.017015493096538

Epoch: 6| Step: 8
Training loss: 3.055984260848094
Validation loss: 3.014590319274672

Epoch: 6| Step: 9
Training loss: 3.1515897584189307
Validation loss: 3.0166077884504694

Epoch: 6| Step: 10
Training loss: 3.4248099782536836
Validation loss: 3.0154282658042977

Epoch: 6| Step: 11
Training loss: 3.252855513639477
Validation loss: 3.0164571025637006

Epoch: 6| Step: 12
Training loss: 3.012082089129995
Validation loss: 3.013699774299003

Epoch: 6| Step: 13
Training loss: 3.315366548321836
Validation loss: 3.0157362224410162

Epoch: 159| Step: 0
Training loss: 2.3716650185095642
Validation loss: 3.0162357623791136

Epoch: 6| Step: 1
Training loss: 3.229051272063475
Validation loss: 3.0146209305120273

Epoch: 6| Step: 2
Training loss: 3.4216033967107182
Validation loss: 3.020182407391359

Epoch: 6| Step: 3
Training loss: 3.6215673834412048
Validation loss: 3.014569005349533

Epoch: 6| Step: 4
Training loss: 2.8502414935677423
Validation loss: 3.0328527504832183

Epoch: 6| Step: 5
Training loss: 3.510493488018308
Validation loss: 3.026101651838924

Epoch: 6| Step: 6
Training loss: 4.273562023294311
Validation loss: 3.0247672342044414

Epoch: 6| Step: 7
Training loss: 3.5719991827576183
Validation loss: 3.0138678953476945

Epoch: 6| Step: 8
Training loss: 3.3554507023033997
Validation loss: 3.0129240499798624

Epoch: 6| Step: 9
Training loss: 3.4011689532744858
Validation loss: 3.0134786714131554

Epoch: 6| Step: 10
Training loss: 2.950431766271146
Validation loss: 3.012916531583599

Epoch: 6| Step: 11
Training loss: 2.6499071572792334
Validation loss: 3.014464940580133

Epoch: 6| Step: 12
Training loss: 3.347931146184868
Validation loss: 3.0133183582943657

Epoch: 6| Step: 13
Training loss: 2.9971439754001383
Validation loss: 3.012997852815355

Epoch: 160| Step: 0
Training loss: 3.095299997164852
Validation loss: 3.0123125769850647

Epoch: 6| Step: 1
Training loss: 3.4920758052432697
Validation loss: 3.013378236588342

Epoch: 6| Step: 2
Training loss: 2.947123246643785
Validation loss: 3.015401847361857

Epoch: 6| Step: 3
Training loss: 3.4139862401201166
Validation loss: 3.01632382070594

Epoch: 6| Step: 4
Training loss: 3.2124483215687687
Validation loss: 3.017421047509519

Epoch: 6| Step: 5
Training loss: 3.5565650089778953
Validation loss: 3.0151594303001934

Epoch: 6| Step: 6
Training loss: 3.097962257308032
Validation loss: 3.0130463455133607

Epoch: 6| Step: 7
Training loss: 3.279573720818485
Validation loss: 3.015016052560348

Epoch: 6| Step: 8
Training loss: 3.3081416121757083
Validation loss: 3.0119328025425647

Epoch: 6| Step: 9
Training loss: 3.9054958988901216
Validation loss: 3.0120424726792407

Epoch: 6| Step: 10
Training loss: 2.7635736993935915
Validation loss: 3.0102555912113806

Epoch: 6| Step: 11
Training loss: 3.360482250755329
Validation loss: 3.0110570541055877

Epoch: 6| Step: 12
Training loss: 3.2591125675225157
Validation loss: 3.0117490124851556

Epoch: 6| Step: 13
Training loss: 3.2552291177721875
Validation loss: 3.0101814613866233

Epoch: 161| Step: 0
Training loss: 2.71540310812443
Validation loss: 3.009243316047223

Epoch: 6| Step: 1
Training loss: 3.0856574981752143
Validation loss: 3.0088643887977

Epoch: 6| Step: 2
Training loss: 3.4986359799345763
Validation loss: 3.0078423977876025

Epoch: 6| Step: 3
Training loss: 3.293725412121372
Validation loss: 3.00810295655444

Epoch: 6| Step: 4
Training loss: 2.759961811713691
Validation loss: 3.008776310683153

Epoch: 6| Step: 5
Training loss: 3.099360455407526
Validation loss: 3.0078900914651183

Epoch: 6| Step: 6
Training loss: 3.237212627131823
Validation loss: 3.0101279121556463

Epoch: 6| Step: 7
Training loss: 3.7148355349541133
Validation loss: 3.008143936475028

Epoch: 6| Step: 8
Training loss: 3.1402080505839334
Validation loss: 3.005338622101604

Epoch: 6| Step: 9
Training loss: 3.2904478947435805
Validation loss: 3.0064921495802377

Epoch: 6| Step: 10
Training loss: 2.860455751719286
Validation loss: 3.005263020613278

Epoch: 6| Step: 11
Training loss: 4.085865144107191
Validation loss: 3.0082647636951907

Epoch: 6| Step: 12
Training loss: 3.2555312990826306
Validation loss: 3.0139245627729

Epoch: 6| Step: 13
Training loss: 3.8146215070602305
Validation loss: 3.0108407067490606

Epoch: 162| Step: 0
Training loss: 3.115373815208038
Validation loss: 3.016571024052351

Epoch: 6| Step: 1
Training loss: 3.177431548166873
Validation loss: 3.029446483878879

Epoch: 6| Step: 2
Training loss: 2.9734581806788696
Validation loss: 3.0277379263411883

Epoch: 6| Step: 3
Training loss: 2.987373802679952
Validation loss: 3.048928629775839

Epoch: 6| Step: 4
Training loss: 3.5525419026855847
Validation loss: 3.026762752189086

Epoch: 6| Step: 5
Training loss: 3.5393016473335344
Validation loss: 3.016716846730157

Epoch: 6| Step: 6
Training loss: 3.1924398702456838
Validation loss: 3.011191995979557

Epoch: 6| Step: 7
Training loss: 2.429326168557805
Validation loss: 3.0046952193218748

Epoch: 6| Step: 8
Training loss: 3.74098495242986
Validation loss: 3.0063073191238363

Epoch: 6| Step: 9
Training loss: 3.7529506518979243
Validation loss: 3.0040350093417394

Epoch: 6| Step: 10
Training loss: 3.342957447279838
Validation loss: 3.004105283371681

Epoch: 6| Step: 11
Training loss: 3.4188540985047595
Validation loss: 3.0059373017355373

Epoch: 6| Step: 12
Training loss: 3.4698741569016427
Validation loss: 3.0049099615799664

Epoch: 6| Step: 13
Training loss: 2.7934063761985417
Validation loss: 3.0043677704590905

Epoch: 163| Step: 0
Training loss: 3.4368901492053943
Validation loss: 3.0055962786659904

Epoch: 6| Step: 1
Training loss: 2.9192916138879488
Validation loss: 3.00400018533809

Epoch: 6| Step: 2
Training loss: 3.727989323490228
Validation loss: 3.003645250363441

Epoch: 6| Step: 3
Training loss: 3.374221853337381
Validation loss: 3.0041323473142585

Epoch: 6| Step: 4
Training loss: 3.277707176382058
Validation loss: 3.003282031819484

Epoch: 6| Step: 5
Training loss: 3.2711290035530154
Validation loss: 3.0033335469232303

Epoch: 6| Step: 6
Training loss: 3.417214760586566
Validation loss: 3.0036087839361763

Epoch: 6| Step: 7
Training loss: 2.802215251629911
Validation loss: 3.0031226204795725

Epoch: 6| Step: 8
Training loss: 3.1747009016314176
Validation loss: 3.00367191645153

Epoch: 6| Step: 9
Training loss: 3.044830418767642
Validation loss: 3.003441021571641

Epoch: 6| Step: 10
Training loss: 2.910802413582545
Validation loss: 3.0051256746642814

Epoch: 6| Step: 11
Training loss: 3.495408861642138
Validation loss: 3.003346216003592

Epoch: 6| Step: 12
Training loss: 3.097465057052797
Validation loss: 3.0026460577832683

Epoch: 6| Step: 13
Training loss: 4.163355210803917
Validation loss: 3.002075858062473

Epoch: 164| Step: 0
Training loss: 3.3666341729689093
Validation loss: 3.002280677541337

Epoch: 6| Step: 1
Training loss: 3.1398129148694287
Validation loss: 3.0003377474778756

Epoch: 6| Step: 2
Training loss: 2.92006900888705
Validation loss: 3.0009692465331117

Epoch: 6| Step: 3
Training loss: 2.3684574157868044
Validation loss: 3.0003151232474097

Epoch: 6| Step: 4
Training loss: 3.7271560420191774
Validation loss: 3.00069464738969

Epoch: 6| Step: 5
Training loss: 3.4644966510718533
Validation loss: 3.0019537330414554

Epoch: 6| Step: 6
Training loss: 4.4505479282412255
Validation loss: 3.000741528573496

Epoch: 6| Step: 7
Training loss: 2.354529856345293
Validation loss: 3.0003620940968356

Epoch: 6| Step: 8
Training loss: 3.555950904430037
Validation loss: 2.9996908602842773

Epoch: 6| Step: 9
Training loss: 2.7543161506503124
Validation loss: 2.998923814523302

Epoch: 6| Step: 10
Training loss: 3.3251346532187434
Validation loss: 3.0002536076849533

Epoch: 6| Step: 11
Training loss: 2.44041288384571
Validation loss: 2.9989533307610374

Epoch: 6| Step: 12
Training loss: 3.782144740150649
Validation loss: 2.998127718823491

Epoch: 6| Step: 13
Training loss: 3.6359240916504487
Validation loss: 3.000630368895748

Epoch: 165| Step: 0
Training loss: 3.977218363997254
Validation loss: 2.998916914137598

Epoch: 6| Step: 1
Training loss: 3.464352406237635
Validation loss: 2.9981579816808344

Epoch: 6| Step: 2
Training loss: 3.125216667293533
Validation loss: 2.9982498338072476

Epoch: 6| Step: 3
Training loss: 3.3338686672126374
Validation loss: 2.995483628951398

Epoch: 6| Step: 4
Training loss: 3.3119124845192913
Validation loss: 2.9963292494612417

Epoch: 6| Step: 5
Training loss: 3.3976148990966406
Validation loss: 2.9963483967330187

Epoch: 6| Step: 6
Training loss: 3.0957092862714712
Validation loss: 2.995739772929113

Epoch: 6| Step: 7
Training loss: 3.093251043600857
Validation loss: 2.9957193560867497

Epoch: 6| Step: 8
Training loss: 3.7447790040433007
Validation loss: 2.9962198820473414

Epoch: 6| Step: 9
Training loss: 2.7875268806564146
Validation loss: 2.9952754141027214

Epoch: 6| Step: 10
Training loss: 2.7311790753895475
Validation loss: 2.994317736405378

Epoch: 6| Step: 11
Training loss: 2.969484419078323
Validation loss: 2.9969833359745617

Epoch: 6| Step: 12
Training loss: 3.4545149961525103
Validation loss: 2.998179744891791

Epoch: 6| Step: 13
Training loss: 2.9561242107058177
Validation loss: 2.9993485560392723

Epoch: 166| Step: 0
Training loss: 2.2851822289188353
Validation loss: 3.0020451547721123

Epoch: 6| Step: 1
Training loss: 3.361666017934812
Validation loss: 3.002694461525931

Epoch: 6| Step: 2
Training loss: 3.6071117621002853
Validation loss: 2.9955445449771143

Epoch: 6| Step: 3
Training loss: 2.5251630900372795
Validation loss: 2.994383430352739

Epoch: 6| Step: 4
Training loss: 4.227472175673514
Validation loss: 2.996488585874672

Epoch: 6| Step: 5
Training loss: 3.1489417947748546
Validation loss: 2.996650707886731

Epoch: 6| Step: 6
Training loss: 2.6448818408266965
Validation loss: 3.0000870924445806

Epoch: 6| Step: 7
Training loss: 3.0617953677080156
Validation loss: 3.0096968025632593

Epoch: 6| Step: 8
Training loss: 3.7687306873339126
Validation loss: 3.0199273560986297

Epoch: 6| Step: 9
Training loss: 3.020564170333829
Validation loss: 3.0195659339416725

Epoch: 6| Step: 10
Training loss: 3.4499309145879558
Validation loss: 3.002880455165092

Epoch: 6| Step: 11
Training loss: 3.2682382449243104
Validation loss: 3.004735954777513

Epoch: 6| Step: 12
Training loss: 3.8597183383700804
Validation loss: 2.9981330545212437

Epoch: 6| Step: 13
Training loss: 3.089534469152915
Validation loss: 2.995788593760562

Epoch: 167| Step: 0
Training loss: 3.5893668604112015
Validation loss: 2.9971750659073924

Epoch: 6| Step: 1
Training loss: 3.6007461781199748
Validation loss: 2.996140518355034

Epoch: 6| Step: 2
Training loss: 3.500737112627293
Validation loss: 2.9991903545603944

Epoch: 6| Step: 3
Training loss: 2.7444952576120762
Validation loss: 3.004217731883295

Epoch: 6| Step: 4
Training loss: 3.271967081925654
Validation loss: 3.017278739046865

Epoch: 6| Step: 5
Training loss: 3.349276530019003
Validation loss: 3.018636271285707

Epoch: 6| Step: 6
Training loss: 2.616200092858496
Validation loss: 3.0296497017449613

Epoch: 6| Step: 7
Training loss: 4.000892062850982
Validation loss: 3.0267314667229637

Epoch: 6| Step: 8
Training loss: 3.6480962360889158
Validation loss: 3.02077233942822

Epoch: 6| Step: 9
Training loss: 3.234251747915812
Validation loss: 3.0047094952234494

Epoch: 6| Step: 10
Training loss: 3.068495506408892
Validation loss: 2.9987012348863153

Epoch: 6| Step: 11
Training loss: 2.851146092777148
Validation loss: 2.994221242087956

Epoch: 6| Step: 12
Training loss: 3.1192528328870095
Validation loss: 2.995395812115518

Epoch: 6| Step: 13
Training loss: 2.8262167546756176
Validation loss: 2.9911926684003585

Epoch: 168| Step: 0
Training loss: 2.4636587447129097
Validation loss: 2.991888983629144

Epoch: 6| Step: 1
Training loss: 3.5866828758790517
Validation loss: 2.9909686323063687

Epoch: 6| Step: 2
Training loss: 2.9609250996916296
Validation loss: 2.9897421729305975

Epoch: 6| Step: 3
Training loss: 3.0730123903699424
Validation loss: 2.9923465052174913

Epoch: 6| Step: 4
Training loss: 3.486519739350876
Validation loss: 2.9902795494963965

Epoch: 6| Step: 5
Training loss: 4.2002601361322425
Validation loss: 2.991355721053774

Epoch: 6| Step: 6
Training loss: 2.943540652336986
Validation loss: 2.9909555645161916

Epoch: 6| Step: 7
Training loss: 3.373005878351757
Validation loss: 2.990878764595531

Epoch: 6| Step: 8
Training loss: 3.777663366293138
Validation loss: 2.9895266481467733

Epoch: 6| Step: 9
Training loss: 3.146950041435907
Validation loss: 2.9885297692973793

Epoch: 6| Step: 10
Training loss: 3.2491313066798138
Validation loss: 2.9904752068913276

Epoch: 6| Step: 11
Training loss: 3.0417393366524146
Validation loss: 2.988919325904577

Epoch: 6| Step: 12
Training loss: 3.154674476721354
Validation loss: 2.9871696723756407

Epoch: 6| Step: 13
Training loss: 2.621440017499989
Validation loss: 2.988447835430274

Epoch: 169| Step: 0
Training loss: 3.161920872913708
Validation loss: 2.9872333196658234

Epoch: 6| Step: 1
Training loss: 3.448133079598167
Validation loss: 2.9881851664481993

Epoch: 6| Step: 2
Training loss: 3.090323660482521
Validation loss: 2.98672552478668

Epoch: 6| Step: 3
Training loss: 3.5275151579684625
Validation loss: 2.9870739555851644

Epoch: 6| Step: 4
Training loss: 3.081735729752346
Validation loss: 2.990607509664116

Epoch: 6| Step: 5
Training loss: 3.4496095464043526
Validation loss: 2.9888873672766114

Epoch: 6| Step: 6
Training loss: 3.068457589134704
Validation loss: 2.9935155231694868

Epoch: 6| Step: 7
Training loss: 3.7998071972974237
Validation loss: 2.9883433028369506

Epoch: 6| Step: 8
Training loss: 3.1065461598983366
Validation loss: 2.9900767184451706

Epoch: 6| Step: 9
Training loss: 3.4626175567832287
Validation loss: 2.9942767932898535

Epoch: 6| Step: 10
Training loss: 2.880274040111909
Validation loss: 2.994959685261282

Epoch: 6| Step: 11
Training loss: 2.6479359379709133
Validation loss: 2.9977633366062775

Epoch: 6| Step: 12
Training loss: 3.806916572821032
Validation loss: 3.000578168304958

Epoch: 6| Step: 13
Training loss: 2.6548076528354114
Validation loss: 2.9916505741241055

Epoch: 170| Step: 0
Training loss: 3.536666496940798
Validation loss: 2.9885715262938506

Epoch: 6| Step: 1
Training loss: 3.727609291444462
Validation loss: 2.987939747602144

Epoch: 6| Step: 2
Training loss: 3.5275692281546833
Validation loss: 2.9863400403889133

Epoch: 6| Step: 3
Training loss: 3.187630445017726
Validation loss: 2.984024009172196

Epoch: 6| Step: 4
Training loss: 2.7157132958564953
Validation loss: 2.9865583102267186

Epoch: 6| Step: 5
Training loss: 3.0959886870460918
Validation loss: 2.983770145008853

Epoch: 6| Step: 6
Training loss: 3.092950274438062
Validation loss: 2.9826716474721002

Epoch: 6| Step: 7
Training loss: 2.9991154956259214
Validation loss: 2.9839690575056994

Epoch: 6| Step: 8
Training loss: 3.6587472847999165
Validation loss: 2.982763538152023

Epoch: 6| Step: 9
Training loss: 3.4758515391806246
Validation loss: 2.982665350684072

Epoch: 6| Step: 10
Training loss: 3.552121084838604
Validation loss: 2.982643737283502

Epoch: 6| Step: 11
Training loss: 2.5734636186155595
Validation loss: 2.9810132712353314

Epoch: 6| Step: 12
Training loss: 3.656938536930943
Validation loss: 2.9826653438079656

Epoch: 6| Step: 13
Training loss: 1.770185202376028
Validation loss: 2.980383565005211

Epoch: 171| Step: 0
Training loss: 3.170796177997694
Validation loss: 2.9832157932563743

Epoch: 6| Step: 1
Training loss: 3.3849504511712967
Validation loss: 2.9812969313537656

Epoch: 6| Step: 2
Training loss: 4.09294341782698
Validation loss: 2.9819391608892123

Epoch: 6| Step: 3
Training loss: 3.289369111256055
Validation loss: 2.9859313647624433

Epoch: 6| Step: 4
Training loss: 2.6674607604554064
Validation loss: 2.98776059350455

Epoch: 6| Step: 5
Training loss: 3.278846950690106
Validation loss: 2.9935992177736988

Epoch: 6| Step: 6
Training loss: 4.343529126157138
Validation loss: 3.004854310053186

Epoch: 6| Step: 7
Training loss: 2.7548428288816806
Validation loss: 2.9878129416684915

Epoch: 6| Step: 8
Training loss: 3.6861731518185614
Validation loss: 2.9855744349808786

Epoch: 6| Step: 9
Training loss: 2.573000537159134
Validation loss: 2.9814206033154096

Epoch: 6| Step: 10
Training loss: 2.9626244241202015
Validation loss: 2.979957582857759

Epoch: 6| Step: 11
Training loss: 3.1055091327464774
Validation loss: 2.9789721540691416

Epoch: 6| Step: 12
Training loss: 3.042964675763479
Validation loss: 2.9792434856878036

Epoch: 6| Step: 13
Training loss: 2.28633637562848
Validation loss: 2.9799635515738974

Epoch: 172| Step: 0
Training loss: 2.344415087111813
Validation loss: 2.9806616970439572

Epoch: 6| Step: 1
Training loss: 3.3131285736807357
Validation loss: 2.9796744121252443

Epoch: 6| Step: 2
Training loss: 3.7730486493729005
Validation loss: 2.980155062041387

Epoch: 6| Step: 3
Training loss: 3.544484143514812
Validation loss: 2.979948636643511

Epoch: 6| Step: 4
Training loss: 3.239469634551865
Validation loss: 2.978007415391187

Epoch: 6| Step: 5
Training loss: 2.8257202546843088
Validation loss: 2.978435632904787

Epoch: 6| Step: 6
Training loss: 3.1592575700407624
Validation loss: 2.97903165648307

Epoch: 6| Step: 7
Training loss: 3.664802655453356
Validation loss: 2.9763335348574183

Epoch: 6| Step: 8
Training loss: 3.785487803139094
Validation loss: 2.978025926356933

Epoch: 6| Step: 9
Training loss: 2.7059409407763284
Validation loss: 2.9762164710296926

Epoch: 6| Step: 10
Training loss: 2.411246623446729
Validation loss: 2.978025594067905

Epoch: 6| Step: 11
Training loss: 3.5983907175605023
Validation loss: 2.980577487773945

Epoch: 6| Step: 12
Training loss: 3.354442435038615
Validation loss: 2.978190668280758

Epoch: 6| Step: 13
Training loss: 3.5287015377964
Validation loss: 2.976629019015963

Epoch: 173| Step: 0
Training loss: 4.262379064550335
Validation loss: 2.9769089537834286

Epoch: 6| Step: 1
Training loss: 3.6860716041403223
Validation loss: 2.978792662019473

Epoch: 6| Step: 2
Training loss: 2.7141590160542752
Validation loss: 2.9795311095991446

Epoch: 6| Step: 3
Training loss: 3.4234888460321073
Validation loss: 2.9832336359855036

Epoch: 6| Step: 4
Training loss: 3.5803911121198855
Validation loss: 2.988454869793806

Epoch: 6| Step: 5
Training loss: 2.96593976777255
Validation loss: 2.9796844294672815

Epoch: 6| Step: 6
Training loss: 2.8282726944773504
Validation loss: 2.9800437848242054

Epoch: 6| Step: 7
Training loss: 3.1043110926950432
Validation loss: 2.9808614138304828

Epoch: 6| Step: 8
Training loss: 3.3399071402975484
Validation loss: 2.977439247617018

Epoch: 6| Step: 9
Training loss: 2.642822976057208
Validation loss: 2.979821498392145

Epoch: 6| Step: 10
Training loss: 3.0777959502502683
Validation loss: 2.9807735970976936

Epoch: 6| Step: 11
Training loss: 3.0979540995576915
Validation loss: 2.9792533865905932

Epoch: 6| Step: 12
Training loss: 3.4644378802851956
Validation loss: 2.977326272501754

Epoch: 6| Step: 13
Training loss: 2.7567256698690197
Validation loss: 2.9770384769066713

Epoch: 174| Step: 0
Training loss: 2.218461353707354
Validation loss: 2.9732627106108778

Epoch: 6| Step: 1
Training loss: 3.103674489031075
Validation loss: 2.9733179213650818

Epoch: 6| Step: 2
Training loss: 3.2738773897080806
Validation loss: 2.971485396285773

Epoch: 6| Step: 3
Training loss: 3.5759823976548604
Validation loss: 2.9749783614500473

Epoch: 6| Step: 4
Training loss: 2.8379648911695052
Validation loss: 2.9752946717526196

Epoch: 6| Step: 5
Training loss: 2.787722995203404
Validation loss: 2.9744595280835457

Epoch: 6| Step: 6
Training loss: 3.8653088871355092
Validation loss: 2.9708446908451327

Epoch: 6| Step: 7
Training loss: 3.812463478788959
Validation loss: 2.973108291293959

Epoch: 6| Step: 8
Training loss: 3.48743567732146
Validation loss: 2.9738925755383225

Epoch: 6| Step: 9
Training loss: 3.387344953641559
Validation loss: 2.9775295123490415

Epoch: 6| Step: 10
Training loss: 3.0343346385844745
Validation loss: 2.9735421294515825

Epoch: 6| Step: 11
Training loss: 3.308634391814286
Validation loss: 2.974157245511549

Epoch: 6| Step: 12
Training loss: 2.83685893072505
Validation loss: 2.981929886186848

Epoch: 6| Step: 13
Training loss: 3.7449698726323324
Validation loss: 2.9760256960324365

Epoch: 175| Step: 0
Training loss: 2.814701829096423
Validation loss: 2.9835276445263648

Epoch: 6| Step: 1
Training loss: 2.612594080786974
Validation loss: 2.982479660800596

Epoch: 6| Step: 2
Training loss: 3.956723471418297
Validation loss: 2.9770260317158574

Epoch: 6| Step: 3
Training loss: 3.63516572598096
Validation loss: 2.9748552963652295

Epoch: 6| Step: 4
Training loss: 2.7546720697984517
Validation loss: 2.970257613009016

Epoch: 6| Step: 5
Training loss: 3.2945979783933272
Validation loss: 2.967056218685067

Epoch: 6| Step: 6
Training loss: 3.4805865712030024
Validation loss: 2.9720930213500223

Epoch: 6| Step: 7
Training loss: 3.0760280224301257
Validation loss: 2.9699698074602674

Epoch: 6| Step: 8
Training loss: 2.716272036045674
Validation loss: 2.97211065914527

Epoch: 6| Step: 9
Training loss: 3.3975034635973884
Validation loss: 2.9720502349429796

Epoch: 6| Step: 10
Training loss: 3.4994547282949298
Validation loss: 2.9720483562361513

Epoch: 6| Step: 11
Training loss: 3.402322447192207
Validation loss: 2.9717747122316287

Epoch: 6| Step: 12
Training loss: 3.3723046171403515
Validation loss: 2.9694262042645247

Epoch: 6| Step: 13
Training loss: 3.132264048830213
Validation loss: 2.9694087370077815

Epoch: 176| Step: 0
Training loss: 2.972034123570091
Validation loss: 2.968854251881235

Epoch: 6| Step: 1
Training loss: 3.4964742613283795
Validation loss: 2.9692312855424308

Epoch: 6| Step: 2
Training loss: 2.6213064093243545
Validation loss: 2.9711255209208045

Epoch: 6| Step: 3
Training loss: 3.1310162424636654
Validation loss: 2.967825914481471

Epoch: 6| Step: 4
Training loss: 3.1209273693821356
Validation loss: 2.9677475528331723

Epoch: 6| Step: 5
Training loss: 3.1690587662664593
Validation loss: 2.967712419640877

Epoch: 6| Step: 6
Training loss: 3.511997368848506
Validation loss: 2.9686669364496083

Epoch: 6| Step: 7
Training loss: 2.3897671625211636
Validation loss: 2.9680535579539438

Epoch: 6| Step: 8
Training loss: 3.1481878972089343
Validation loss: 2.968256892047136

Epoch: 6| Step: 9
Training loss: 3.2789174826599803
Validation loss: 2.9685880728031084

Epoch: 6| Step: 10
Training loss: 2.6558989348945996
Validation loss: 2.969362259031088

Epoch: 6| Step: 11
Training loss: 4.277792098006242
Validation loss: 2.9681947699490046

Epoch: 6| Step: 12
Training loss: 3.851951347360722
Validation loss: 2.969747976404273

Epoch: 6| Step: 13
Training loss: 3.452289186708163
Validation loss: 2.968531705800077

Epoch: 177| Step: 0
Training loss: 3.457462814031786
Validation loss: 2.971783695129788

Epoch: 6| Step: 1
Training loss: 3.7625821430960045
Validation loss: 2.9719131121021447

Epoch: 6| Step: 2
Training loss: 3.1046639029264145
Validation loss: 2.97389300656271

Epoch: 6| Step: 3
Training loss: 3.619894312585597
Validation loss: 2.973013413525515

Epoch: 6| Step: 4
Training loss: 2.9021081430908695
Validation loss: 2.9709776279141176

Epoch: 6| Step: 5
Training loss: 2.7005731963203816
Validation loss: 2.971388580671419

Epoch: 6| Step: 6
Training loss: 2.1811578638243057
Validation loss: 2.966129270989178

Epoch: 6| Step: 7
Training loss: 3.9027674906011707
Validation loss: 2.9697070597080097

Epoch: 6| Step: 8
Training loss: 2.9516601158627997
Validation loss: 2.9651558544623944

Epoch: 6| Step: 9
Training loss: 3.2218115607009072
Validation loss: 2.9660787700769866

Epoch: 6| Step: 10
Training loss: 3.514812189025339
Validation loss: 2.9688760140254895

Epoch: 6| Step: 11
Training loss: 2.9357208383146953
Validation loss: 2.96538152171643

Epoch: 6| Step: 12
Training loss: 3.685153667294582
Validation loss: 2.9650930889718694

Epoch: 6| Step: 13
Training loss: 2.932360434304556
Validation loss: 2.9640158193155397

Epoch: 178| Step: 0
Training loss: 3.0388186633984193
Validation loss: 2.96493956449014

Epoch: 6| Step: 1
Training loss: 2.559597045805404
Validation loss: 2.9648032654132304

Epoch: 6| Step: 2
Training loss: 3.661185300078879
Validation loss: 2.965019189214672

Epoch: 6| Step: 3
Training loss: 3.7636868249411175
Validation loss: 2.96419867102775

Epoch: 6| Step: 4
Training loss: 3.43931781214523
Validation loss: 2.962117702064153

Epoch: 6| Step: 5
Training loss: 2.4714228972567525
Validation loss: 2.9612845178714746

Epoch: 6| Step: 6
Training loss: 3.3210669524287897
Validation loss: 2.9622570542076443

Epoch: 6| Step: 7
Training loss: 3.159611186963232
Validation loss: 2.9607305919548517

Epoch: 6| Step: 8
Training loss: 2.9901822295522686
Validation loss: 2.961225274387843

Epoch: 6| Step: 9
Training loss: 3.619724249269144
Validation loss: 2.961499651647542

Epoch: 6| Step: 10
Training loss: 3.2483152277523275
Validation loss: 2.9663980741148714

Epoch: 6| Step: 11
Training loss: 2.7595817790851904
Validation loss: 2.9630900808708414

Epoch: 6| Step: 12
Training loss: 3.8879566770737988
Validation loss: 2.960963853729656

Epoch: 6| Step: 13
Training loss: 3.012109792929714
Validation loss: 2.9632552776795347

Epoch: 179| Step: 0
Training loss: 3.8676507229276775
Validation loss: 2.960965569770283

Epoch: 6| Step: 1
Training loss: 3.1734062219578107
Validation loss: 2.960610993177066

Epoch: 6| Step: 2
Training loss: 3.3020002834012647
Validation loss: 2.960674765476941

Epoch: 6| Step: 3
Training loss: 3.299782578212777
Validation loss: 2.9610809223036503

Epoch: 6| Step: 4
Training loss: 3.954181876654091
Validation loss: 2.9627192746196513

Epoch: 6| Step: 5
Training loss: 3.344861710317038
Validation loss: 2.964661952406224

Epoch: 6| Step: 6
Training loss: 2.6790387227391452
Validation loss: 2.9641126854669335

Epoch: 6| Step: 7
Training loss: 3.09163693793331
Validation loss: 2.964338763363486

Epoch: 6| Step: 8
Training loss: 3.1441395391215203
Validation loss: 2.9675298094900335

Epoch: 6| Step: 9
Training loss: 2.232115770448098
Validation loss: 2.9664999050719456

Epoch: 6| Step: 10
Training loss: 2.997568734775259
Validation loss: 2.967335475503404

Epoch: 6| Step: 11
Training loss: 3.470454441621741
Validation loss: 2.96718350646566

Epoch: 6| Step: 12
Training loss: 3.103289759815223
Validation loss: 2.963304882854468

Epoch: 6| Step: 13
Training loss: 3.419166503306258
Validation loss: 2.9654379192048927

Epoch: 180| Step: 0
Training loss: 3.9309232979343625
Validation loss: 2.961441130976611

Epoch: 6| Step: 1
Training loss: 3.6987054261219066
Validation loss: 2.9583992070431098

Epoch: 6| Step: 2
Training loss: 3.3527047582760687
Validation loss: 2.9551080739725157

Epoch: 6| Step: 3
Training loss: 2.809391592823288
Validation loss: 2.957139042913044

Epoch: 6| Step: 4
Training loss: 1.770352272065029
Validation loss: 2.9608405161164155

Epoch: 6| Step: 5
Training loss: 2.7824435298429933
Validation loss: 2.9639223769268885

Epoch: 6| Step: 6
Training loss: 3.051413418067343
Validation loss: 2.9625117667107155

Epoch: 6| Step: 7
Training loss: 3.2240448890287134
Validation loss: 2.963385932210364

Epoch: 6| Step: 8
Training loss: 2.434156912949856
Validation loss: 2.9650244902483864

Epoch: 6| Step: 9
Training loss: 3.5230379745078277
Validation loss: 2.963917119764379

Epoch: 6| Step: 10
Training loss: 2.790726194864367
Validation loss: 2.9643153645078475

Epoch: 6| Step: 11
Training loss: 3.2779978302907136
Validation loss: 2.956199877319961

Epoch: 6| Step: 12
Training loss: 4.094794918975405
Validation loss: 2.957542351963745

Epoch: 6| Step: 13
Training loss: 4.175161146149149
Validation loss: 2.9610735519208524

Epoch: 181| Step: 0
Training loss: 3.4944585801569628
Validation loss: 2.9569199851716257

Epoch: 6| Step: 1
Training loss: 3.7177399618025984
Validation loss: 2.9554583664464755

Epoch: 6| Step: 2
Training loss: 2.443142839407131
Validation loss: 2.958262632623701

Epoch: 6| Step: 3
Training loss: 3.178694436401103
Validation loss: 2.954620130424054

Epoch: 6| Step: 4
Training loss: 3.089412075517132
Validation loss: 2.955434749819151

Epoch: 6| Step: 5
Training loss: 3.631961452103118
Validation loss: 2.9559762323545677

Epoch: 6| Step: 6
Training loss: 2.9623438733644782
Validation loss: 2.9535714566330418

Epoch: 6| Step: 7
Training loss: 3.4544599205361077
Validation loss: 2.9526656779402978

Epoch: 6| Step: 8
Training loss: 3.0888207209297405
Validation loss: 2.95018935568276

Epoch: 6| Step: 9
Training loss: 2.588884040607866
Validation loss: 2.951904735778047

Epoch: 6| Step: 10
Training loss: 2.783590467838105
Validation loss: 2.9518706759260263

Epoch: 6| Step: 11
Training loss: 3.802924842551225
Validation loss: 2.9517359976605766

Epoch: 6| Step: 12
Training loss: 3.9680489949770132
Validation loss: 2.9533549762504

Epoch: 6| Step: 13
Training loss: 1.920315365521471
Validation loss: 2.9528734089456155

Epoch: 182| Step: 0
Training loss: 2.9352135383349878
Validation loss: 2.954993682913431

Epoch: 6| Step: 1
Training loss: 2.772967661430019
Validation loss: 2.951445699808932

Epoch: 6| Step: 2
Training loss: 3.8629067512335302
Validation loss: 2.952359817179343

Epoch: 6| Step: 3
Training loss: 3.3592195696692015
Validation loss: 2.9496622361832108

Epoch: 6| Step: 4
Training loss: 2.798916290236233
Validation loss: 2.951882025200808

Epoch: 6| Step: 5
Training loss: 2.9307361404519465
Validation loss: 2.9512946246779324

Epoch: 6| Step: 6
Training loss: 3.6463308521679267
Validation loss: 2.9535361452639717

Epoch: 6| Step: 7
Training loss: 2.3162518557578657
Validation loss: 2.9553250748028326

Epoch: 6| Step: 8
Training loss: 3.5761713416506975
Validation loss: 2.950105056087841

Epoch: 6| Step: 9
Training loss: 3.154846181369321
Validation loss: 2.955464502609731

Epoch: 6| Step: 10
Training loss: 3.156908023339018
Validation loss: 2.95969660046589

Epoch: 6| Step: 11
Training loss: 3.2549951753126445
Validation loss: 2.9613476350486443

Epoch: 6| Step: 12
Training loss: 3.3338507886425597
Validation loss: 2.9568272661961443

Epoch: 6| Step: 13
Training loss: 4.138283812623097
Validation loss: 2.951528699065921

Epoch: 183| Step: 0
Training loss: 3.025951986029013
Validation loss: 2.950565133000579

Epoch: 6| Step: 1
Training loss: 3.130663812708596
Validation loss: 2.949331430141876

Epoch: 6| Step: 2
Training loss: 2.6383491956949277
Validation loss: 2.9504036875193203

Epoch: 6| Step: 3
Training loss: 2.846667459504183
Validation loss: 2.952121954707165

Epoch: 6| Step: 4
Training loss: 2.8034290263671178
Validation loss: 2.952030559632005

Epoch: 6| Step: 5
Training loss: 3.1205660071852663
Validation loss: 2.9514105332554292

Epoch: 6| Step: 6
Training loss: 3.776407214481108
Validation loss: 2.9524093036736145

Epoch: 6| Step: 7
Training loss: 3.489998833511289
Validation loss: 2.951825365239872

Epoch: 6| Step: 8
Training loss: 3.6298138455665736
Validation loss: 2.9520161375306166

Epoch: 6| Step: 9
Training loss: 2.7726381681255194
Validation loss: 2.954093475235809

Epoch: 6| Step: 10
Training loss: 3.652450543642567
Validation loss: 2.952381238953431

Epoch: 6| Step: 11
Training loss: 3.298897651585633
Validation loss: 2.9516508545854476

Epoch: 6| Step: 12
Training loss: 3.1301684554231537
Validation loss: 2.9518080352731313

Epoch: 6| Step: 13
Training loss: 4.029095687688104
Validation loss: 2.951443757607404

Epoch: 184| Step: 0
Training loss: 3.0639153149009792
Validation loss: 2.9507816199700407

Epoch: 6| Step: 1
Training loss: 3.1341175585950425
Validation loss: 2.950517190418106

Epoch: 6| Step: 2
Training loss: 3.418986455631122
Validation loss: 2.9504332399311988

Epoch: 6| Step: 3
Training loss: 3.7706354134958193
Validation loss: 2.9492254589482325

Epoch: 6| Step: 4
Training loss: 2.7505135490168366
Validation loss: 2.949135722242746

Epoch: 6| Step: 5
Training loss: 2.7152678892492697
Validation loss: 2.9492313333943883

Epoch: 6| Step: 6
Training loss: 3.4517126172474772
Validation loss: 2.9491813367722335

Epoch: 6| Step: 7
Training loss: 3.460095305260301
Validation loss: 2.9502361678606697

Epoch: 6| Step: 8
Training loss: 3.445124268525874
Validation loss: 2.946952948990347

Epoch: 6| Step: 9
Training loss: 3.2843388142575027
Validation loss: 2.947366721808965

Epoch: 6| Step: 10
Training loss: 2.9056875033188545
Validation loss: 2.95033663457011

Epoch: 6| Step: 11
Training loss: 3.4795178142913286
Validation loss: 2.9451800861951005

Epoch: 6| Step: 12
Training loss: 3.210990366999392
Validation loss: 2.946075167497147

Epoch: 6| Step: 13
Training loss: 2.7036500983050566
Validation loss: 2.9458918252647157

Epoch: 185| Step: 0
Training loss: 3.339252191991673
Validation loss: 2.9458612030080635

Epoch: 6| Step: 1
Training loss: 2.7976504481600863
Validation loss: 2.9463412617240823

Epoch: 6| Step: 2
Training loss: 2.312867315864591
Validation loss: 2.9460446654930794

Epoch: 6| Step: 3
Training loss: 2.953795987552963
Validation loss: 2.949570404191229

Epoch: 6| Step: 4
Training loss: 3.2683184891408548
Validation loss: 2.95332765011412

Epoch: 6| Step: 5
Training loss: 3.5875886593805615
Validation loss: 2.9563018783176065

Epoch: 6| Step: 6
Training loss: 3.9869065563617307
Validation loss: 2.947757136722497

Epoch: 6| Step: 7
Training loss: 2.6541506381027453
Validation loss: 2.951488284601433

Epoch: 6| Step: 8
Training loss: 3.0594833463940923
Validation loss: 2.9499095072770354

Epoch: 6| Step: 9
Training loss: 3.0856187100469015
Validation loss: 2.9451187499611455

Epoch: 6| Step: 10
Training loss: 3.111607196023655
Validation loss: 2.9432578208794213

Epoch: 6| Step: 11
Training loss: 3.3838268283426425
Validation loss: 2.9432966472745856

Epoch: 6| Step: 12
Training loss: 3.930012077138267
Validation loss: 2.9445799156436157

Epoch: 6| Step: 13
Training loss: 3.3322929825123824
Validation loss: 2.942776338337971

Epoch: 186| Step: 0
Training loss: 3.167834484862858
Validation loss: 2.9427449666860337

Epoch: 6| Step: 1
Training loss: 3.481716904071561
Validation loss: 2.943457818896104

Epoch: 6| Step: 2
Training loss: 3.4458609423440416
Validation loss: 2.9437304879978763

Epoch: 6| Step: 3
Training loss: 2.981690642543185
Validation loss: 2.9444615911194885

Epoch: 6| Step: 4
Training loss: 3.3858469684716543
Validation loss: 2.944256702507161

Epoch: 6| Step: 5
Training loss: 3.3995390411258217
Validation loss: 2.9450353820269823

Epoch: 6| Step: 6
Training loss: 3.1672570196952115
Validation loss: 2.9421958907666808

Epoch: 6| Step: 7
Training loss: 3.235937063824059
Validation loss: 2.9426784100410024

Epoch: 6| Step: 8
Training loss: 3.0069582035571183
Validation loss: 2.9430860939947547

Epoch: 6| Step: 9
Training loss: 2.9845213529641277
Validation loss: 2.9442189562964307

Epoch: 6| Step: 10
Training loss: 2.7154799340310443
Validation loss: 2.945192133239013

Epoch: 6| Step: 11
Training loss: 3.6887040839444807
Validation loss: 2.9497864531375346

Epoch: 6| Step: 12
Training loss: 3.3177956051129986
Validation loss: 2.94736515876511

Epoch: 6| Step: 13
Training loss: 2.944762970431808
Validation loss: 2.9512937490790945

Epoch: 187| Step: 0
Training loss: 3.5223037688893375
Validation loss: 2.947456307974046

Epoch: 6| Step: 1
Training loss: 2.795825441655383
Validation loss: 2.943759907972135

Epoch: 6| Step: 2
Training loss: 2.7283530053711385
Validation loss: 2.9381874107507078

Epoch: 6| Step: 3
Training loss: 3.126285136138642
Validation loss: 2.946125051498915

Epoch: 6| Step: 4
Training loss: 2.9016611931880867
Validation loss: 2.9445642912699452

Epoch: 6| Step: 5
Training loss: 3.391109168295292
Validation loss: 2.9410446623041064

Epoch: 6| Step: 6
Training loss: 3.977612070246679
Validation loss: 2.9404052395949147

Epoch: 6| Step: 7
Training loss: 3.2519301038505715
Validation loss: 2.9399459559272954

Epoch: 6| Step: 8
Training loss: 3.093506312165172
Validation loss: 2.941135833062583

Epoch: 6| Step: 9
Training loss: 3.5836307195233066
Validation loss: 2.9424228580197624

Epoch: 6| Step: 10
Training loss: 3.4422685320126285
Validation loss: 2.9396517362342833

Epoch: 6| Step: 11
Training loss: 3.1829601195554846
Validation loss: 2.939804719499151

Epoch: 6| Step: 12
Training loss: 3.0325456190333813
Validation loss: 2.9404471403254013

Epoch: 6| Step: 13
Training loss: 2.558022378502995
Validation loss: 2.9398231160930712

Epoch: 188| Step: 0
Training loss: 3.394792237252001
Validation loss: 2.939961604845027

Epoch: 6| Step: 1
Training loss: 3.174895253293369
Validation loss: 2.9385322780874787

Epoch: 6| Step: 2
Training loss: 3.30647723565427
Validation loss: 2.9411537733052744

Epoch: 6| Step: 3
Training loss: 2.9813894946973627
Validation loss: 2.941090144308677

Epoch: 6| Step: 4
Training loss: 3.5193578273033794
Validation loss: 2.9387235848763087

Epoch: 6| Step: 5
Training loss: 3.4151539749128856
Validation loss: 2.9419410680304274

Epoch: 6| Step: 6
Training loss: 3.4507648117851906
Validation loss: 2.9420780367528176

Epoch: 6| Step: 7
Training loss: 3.0279529376989864
Validation loss: 2.9387033415685853

Epoch: 6| Step: 8
Training loss: 3.4000296535320778
Validation loss: 2.9395455224845968

Epoch: 6| Step: 9
Training loss: 2.922366830159186
Validation loss: 2.9403493986350777

Epoch: 6| Step: 10
Training loss: 3.4263273910805925
Validation loss: 2.9415457937185616

Epoch: 6| Step: 11
Training loss: 3.034734080446898
Validation loss: 2.94108296353682

Epoch: 6| Step: 12
Training loss: 3.183451156699258
Validation loss: 2.942822300588619

Epoch: 6| Step: 13
Training loss: 2.368583242540414
Validation loss: 2.9478242605218976

Epoch: 189| Step: 0
Training loss: 3.673602667648397
Validation loss: 2.9421225843718704

Epoch: 6| Step: 1
Training loss: 3.7471964210682107
Validation loss: 2.9399270386411573

Epoch: 6| Step: 2
Training loss: 3.4395537743471865
Validation loss: 2.9361486038393667

Epoch: 6| Step: 3
Training loss: 3.5840873516370997
Validation loss: 2.936491015142899

Epoch: 6| Step: 4
Training loss: 3.1937643091885293
Validation loss: 2.939226640152293

Epoch: 6| Step: 5
Training loss: 2.2009461362453466
Validation loss: 2.936835427426211

Epoch: 6| Step: 6
Training loss: 2.8309111807151677
Validation loss: 2.9354001081957377

Epoch: 6| Step: 7
Training loss: 2.5472005624334395
Validation loss: 2.9373458214424173

Epoch: 6| Step: 8
Training loss: 3.702519749621586
Validation loss: 2.939858782274951

Epoch: 6| Step: 9
Training loss: 3.303664894696524
Validation loss: 2.935142975682513

Epoch: 6| Step: 10
Training loss: 3.005075135521472
Validation loss: 2.933973495648883

Epoch: 6| Step: 11
Training loss: 2.6319077745587816
Validation loss: 2.93517657894559

Epoch: 6| Step: 12
Training loss: 3.748950938671239
Validation loss: 2.935142632424676

Epoch: 6| Step: 13
Training loss: 2.7347739664295725
Validation loss: 2.9347955843280444

Epoch: 190| Step: 0
Training loss: 3.483658926560056
Validation loss: 2.9349888523700196

Epoch: 6| Step: 1
Training loss: 3.3282424834384368
Validation loss: 2.937115879990843

Epoch: 6| Step: 2
Training loss: 3.598358383998512
Validation loss: 2.9390675855084734

Epoch: 6| Step: 3
Training loss: 2.7277667602382167
Validation loss: 2.942627019663523

Epoch: 6| Step: 4
Training loss: 3.547133784999388
Validation loss: 2.9453190019838846

Epoch: 6| Step: 5
Training loss: 3.0671776062567284
Validation loss: 2.942657423799601

Epoch: 6| Step: 6
Training loss: 3.4222314378963863
Validation loss: 2.9364222912734954

Epoch: 6| Step: 7
Training loss: 2.220624105344335
Validation loss: 2.936303245132808

Epoch: 6| Step: 8
Training loss: 3.4595746183478964
Validation loss: 2.9364385150988164

Epoch: 6| Step: 9
Training loss: 2.8543707410339163
Validation loss: 2.9349344526898737

Epoch: 6| Step: 10
Training loss: 3.500714365399616
Validation loss: 2.9348941224314116

Epoch: 6| Step: 11
Training loss: 2.853586978007197
Validation loss: 2.934667255164761

Epoch: 6| Step: 12
Training loss: 3.331666163917899
Validation loss: 2.933003132610285

Epoch: 6| Step: 13
Training loss: 3.630097061414883
Validation loss: 2.933960761184935

Epoch: 191| Step: 0
Training loss: 3.3136632064567446
Validation loss: 2.9339695819959197

Epoch: 6| Step: 1
Training loss: 2.97609564857184
Validation loss: 2.9358770005705948

Epoch: 6| Step: 2
Training loss: 3.8817193624398243
Validation loss: 2.9378480236000764

Epoch: 6| Step: 3
Training loss: 3.5144754522499904
Validation loss: 2.9414237057466504

Epoch: 6| Step: 4
Training loss: 3.177944145945768
Validation loss: 2.948986416956746

Epoch: 6| Step: 5
Training loss: 3.1397665947828597
Validation loss: 2.9529102866129624

Epoch: 6| Step: 6
Training loss: 3.377712431353637
Validation loss: 2.943485923842671

Epoch: 6| Step: 7
Training loss: 2.7679435364912366
Validation loss: 2.9433184154745033

Epoch: 6| Step: 8
Training loss: 2.8390689091880392
Validation loss: 2.9498199843176387

Epoch: 6| Step: 9
Training loss: 3.3758676614540692
Validation loss: 2.9426571014558993

Epoch: 6| Step: 10
Training loss: 3.545915515872188
Validation loss: 2.9429166585956597

Epoch: 6| Step: 11
Training loss: 2.7007644136371374
Validation loss: 2.938248016553115

Epoch: 6| Step: 12
Training loss: 3.3341022240448566
Validation loss: 2.94088022981083

Epoch: 6| Step: 13
Training loss: 2.592739781737779
Validation loss: 2.9379401478308744

Epoch: 192| Step: 0
Training loss: 3.22594943006579
Validation loss: 2.9295424996319213

Epoch: 6| Step: 1
Training loss: 2.7364352938395244
Validation loss: 2.9314122702130763

Epoch: 6| Step: 2
Training loss: 2.84870529213372
Validation loss: 2.9295557678576927

Epoch: 6| Step: 3
Training loss: 2.510282162008476
Validation loss: 2.9291137921129375

Epoch: 6| Step: 4
Training loss: 3.4000734096904703
Validation loss: 2.9292274679421597

Epoch: 6| Step: 5
Training loss: 3.05725629657169
Validation loss: 2.9359853335175705

Epoch: 6| Step: 6
Training loss: 3.3800305210518715
Validation loss: 2.927030806730125

Epoch: 6| Step: 7
Training loss: 3.348584824176779
Validation loss: 2.926070910158547

Epoch: 6| Step: 8
Training loss: 3.324744141565266
Validation loss: 2.923875705563844

Epoch: 6| Step: 9
Training loss: 3.3794112869947455
Validation loss: 2.9247283769462284

Epoch: 6| Step: 10
Training loss: 3.47795505708302
Validation loss: 2.9247077606590075

Epoch: 6| Step: 11
Training loss: 3.1298762614498523
Validation loss: 2.9252194872229844

Epoch: 6| Step: 12
Training loss: 3.5474756211242244
Validation loss: 2.9269223972348786

Epoch: 6| Step: 13
Training loss: 3.5802336896779625
Validation loss: 2.9260915343640885

Epoch: 193| Step: 0
Training loss: 2.6298143652030777
Validation loss: 2.926296569961357

Epoch: 6| Step: 1
Training loss: 2.6506881827946542
Validation loss: 2.926885648470429

Epoch: 6| Step: 2
Training loss: 3.3487844624727092
Validation loss: 2.929122736923262

Epoch: 6| Step: 3
Training loss: 3.1588770442845986
Validation loss: 2.93084952593248

Epoch: 6| Step: 4
Training loss: 3.000741866890417
Validation loss: 2.926452108551948

Epoch: 6| Step: 5
Training loss: 2.3151592738684106
Validation loss: 2.931129574275786

Epoch: 6| Step: 6
Training loss: 2.8979371659527158
Validation loss: 2.9274976300885465

Epoch: 6| Step: 7
Training loss: 3.3477300326430086
Validation loss: 2.936996570422242

Epoch: 6| Step: 8
Training loss: 4.036423313440156
Validation loss: 2.927466534316559

Epoch: 6| Step: 9
Training loss: 2.6313649168313784
Validation loss: 2.93367491760387

Epoch: 6| Step: 10
Training loss: 3.44369849635552
Validation loss: 2.93215997181219

Epoch: 6| Step: 11
Training loss: 3.503946395524966
Validation loss: 2.930005320602593

Epoch: 6| Step: 12
Training loss: 3.836063546092933
Validation loss: 2.9266576357057055

Epoch: 6| Step: 13
Training loss: 3.967150508532369
Validation loss: 2.920484948220648

Epoch: 194| Step: 0
Training loss: 3.3844455362931702
Validation loss: 2.92587909983653

Epoch: 6| Step: 1
Training loss: 3.0699357051515994
Validation loss: 2.9232993399376417

Epoch: 6| Step: 2
Training loss: 3.2776582951149944
Validation loss: 2.9244402805225675

Epoch: 6| Step: 3
Training loss: 3.560197320248759
Validation loss: 2.9234482786730394

Epoch: 6| Step: 4
Training loss: 3.1800287986746896
Validation loss: 2.921556487991226

Epoch: 6| Step: 5
Training loss: 3.3171650408264366
Validation loss: 2.9242388963592325

Epoch: 6| Step: 6
Training loss: 3.3944289847224995
Validation loss: 2.920791471574348

Epoch: 6| Step: 7
Training loss: 3.1694230247113295
Validation loss: 2.9221629655121992

Epoch: 6| Step: 8
Training loss: 3.5602285271063945
Validation loss: 2.9196928064970944

Epoch: 6| Step: 9
Training loss: 2.7121786744666077
Validation loss: 2.9212155705964897

Epoch: 6| Step: 10
Training loss: 2.829168137862245
Validation loss: 2.923379607737351

Epoch: 6| Step: 11
Training loss: 2.92055118375264
Validation loss: 2.924639936255983

Epoch: 6| Step: 12
Training loss: 3.1270394346106913
Validation loss: 2.9244140048525513

Epoch: 6| Step: 13
Training loss: 3.3674361630557836
Validation loss: 2.927521571042086

Epoch: 195| Step: 0
Training loss: 3.697625950234377
Validation loss: 2.922725906083875

Epoch: 6| Step: 1
Training loss: 3.3593247520769696
Validation loss: 2.921234743325038

Epoch: 6| Step: 2
Training loss: 2.950072471892259
Validation loss: 2.9195880925882176

Epoch: 6| Step: 3
Training loss: 3.3129329758302912
Validation loss: 2.9211084012653425

Epoch: 6| Step: 4
Training loss: 2.7458711319571116
Validation loss: 2.9229190740598145

Epoch: 6| Step: 5
Training loss: 2.7353301205759926
Validation loss: 2.9249864451547705

Epoch: 6| Step: 6
Training loss: 2.407081559400503
Validation loss: 2.91992391191895

Epoch: 6| Step: 7
Training loss: 3.67204745273222
Validation loss: 2.920576286781212

Epoch: 6| Step: 8
Training loss: 3.416458232073307
Validation loss: 2.9291458777735238

Epoch: 6| Step: 9
Training loss: 3.5172789349527296
Validation loss: 2.932777709114723

Epoch: 6| Step: 10
Training loss: 3.38046768361254
Validation loss: 2.922546690303299

Epoch: 6| Step: 11
Training loss: 3.2957683712761874
Validation loss: 2.921901344565289

Epoch: 6| Step: 12
Training loss: 3.261647992308861
Validation loss: 2.917470667081125

Epoch: 6| Step: 13
Training loss: 2.4813309740359024
Validation loss: 2.920519703277265

Epoch: 196| Step: 0
Training loss: 3.120661050262428
Validation loss: 2.9198799378593647

Epoch: 6| Step: 1
Training loss: 3.6024603065988274
Validation loss: 2.9174211560456693

Epoch: 6| Step: 2
Training loss: 3.284259977785646
Validation loss: 2.9205376305906623

Epoch: 6| Step: 3
Training loss: 2.4641713042780515
Validation loss: 2.9199975543644747

Epoch: 6| Step: 4
Training loss: 2.4797850620280424
Validation loss: 2.920417372490418

Epoch: 6| Step: 5
Training loss: 3.1512260109859547
Validation loss: 2.9261313875572372

Epoch: 6| Step: 6
Training loss: 2.498793692423879
Validation loss: 2.9259622618268293

Epoch: 6| Step: 7
Training loss: 3.0047826790575485
Validation loss: 2.9232678456465817

Epoch: 6| Step: 8
Training loss: 3.4904390263343115
Validation loss: 2.9277351249853614

Epoch: 6| Step: 9
Training loss: 2.7634621476572505
Validation loss: 2.931823006416063

Epoch: 6| Step: 10
Training loss: 3.679526420679835
Validation loss: 2.929099005983997

Epoch: 6| Step: 11
Training loss: 3.435005947813079
Validation loss: 2.933363904215715

Epoch: 6| Step: 12
Training loss: 4.085395033002756
Validation loss: 2.922176839247938

Epoch: 6| Step: 13
Training loss: 3.3976972804220225
Validation loss: 2.922640887148015

Epoch: 197| Step: 0
Training loss: 4.023145231723805
Validation loss: 2.916303602964042

Epoch: 6| Step: 1
Training loss: 2.3574010410352173
Validation loss: 2.916360493307209

Epoch: 6| Step: 2
Training loss: 2.8697574749598425
Validation loss: 2.917256904391288

Epoch: 6| Step: 3
Training loss: 3.6703908964694403
Validation loss: 2.9153407134352807

Epoch: 6| Step: 4
Training loss: 2.9967442966316846
Validation loss: 2.913905627912959

Epoch: 6| Step: 5
Training loss: 3.2666817009508513
Validation loss: 2.9130439969929602

Epoch: 6| Step: 6
Training loss: 3.4893229980529474
Validation loss: 2.917394208627863

Epoch: 6| Step: 7
Training loss: 2.901260358602102
Validation loss: 2.9137356420933

Epoch: 6| Step: 8
Training loss: 3.788783238138353
Validation loss: 2.9149693852230456

Epoch: 6| Step: 9
Training loss: 2.6140518762859437
Validation loss: 2.9151111503931824

Epoch: 6| Step: 10
Training loss: 2.5695321890022322
Validation loss: 2.9169534135019917

Epoch: 6| Step: 11
Training loss: 3.339088113532142
Validation loss: 2.9166602162467075

Epoch: 6| Step: 12
Training loss: 3.2939906226037983
Validation loss: 2.912906588033684

Epoch: 6| Step: 13
Training loss: 3.1718801113143855
Validation loss: 2.9154200800762364

Epoch: 198| Step: 0
Training loss: 2.8372481919196404
Validation loss: 2.913564102134748

Epoch: 6| Step: 1
Training loss: 2.5188398018628995
Validation loss: 2.9128022286508446

Epoch: 6| Step: 2
Training loss: 3.7605145865219476
Validation loss: 2.910927027632188

Epoch: 6| Step: 3
Training loss: 3.682699408431447
Validation loss: 2.9101523598155423

Epoch: 6| Step: 4
Training loss: 2.9920928382341856
Validation loss: 2.9111463724607134

Epoch: 6| Step: 5
Training loss: 3.3612326520342317
Validation loss: 2.91484081204079

Epoch: 6| Step: 6
Training loss: 3.8692165407746693
Validation loss: 2.9120539501507574

Epoch: 6| Step: 7
Training loss: 2.9273442777659153
Validation loss: 2.9094397375865353

Epoch: 6| Step: 8
Training loss: 3.2348899247133907
Validation loss: 2.9111166475493815

Epoch: 6| Step: 9
Training loss: 2.618812170633586
Validation loss: 2.9144041142739248

Epoch: 6| Step: 10
Training loss: 3.0786931631810237
Validation loss: 2.911065244241592

Epoch: 6| Step: 11
Training loss: 2.8912214334002724
Validation loss: 2.9192271939798706

Epoch: 6| Step: 12
Training loss: 3.785168595584227
Validation loss: 2.9260609957690913

Epoch: 6| Step: 13
Training loss: 2.53559276896004
Validation loss: 2.918025297749882

Epoch: 199| Step: 0
Training loss: 3.6170895524080073
Validation loss: 2.924930426400598

Epoch: 6| Step: 1
Training loss: 3.3492346729196374
Validation loss: 2.918849519083171

Epoch: 6| Step: 2
Training loss: 2.9337566142582623
Validation loss: 2.912240218462887

Epoch: 6| Step: 3
Training loss: 2.7159851748436887
Validation loss: 2.9123410918792065

Epoch: 6| Step: 4
Training loss: 3.4461942828866152
Validation loss: 2.9163017208704334

Epoch: 6| Step: 5
Training loss: 2.5156227253968755
Validation loss: 2.9132029755761284

Epoch: 6| Step: 6
Training loss: 2.8477607362518187
Validation loss: 2.9141949843968606

Epoch: 6| Step: 7
Training loss: 2.9619328982153315
Validation loss: 2.9111158118235734

Epoch: 6| Step: 8
Training loss: 3.6532739770434373
Validation loss: 2.9165553679670064

Epoch: 6| Step: 9
Training loss: 3.431424962987145
Validation loss: 2.910566617633965

Epoch: 6| Step: 10
Training loss: 2.541263881932521
Validation loss: 2.9126045811401164

Epoch: 6| Step: 11
Training loss: 3.5933689081227493
Validation loss: 2.915804276370313

Epoch: 6| Step: 12
Training loss: 3.3707726459360647
Validation loss: 2.9086446680125304

Epoch: 6| Step: 13
Training loss: 3.5900193463072525
Validation loss: 2.912369962765599

Epoch: 200| Step: 0
Training loss: 3.402800046540831
Validation loss: 2.906307353092119

Epoch: 6| Step: 1
Training loss: 3.3644121596941496
Validation loss: 2.9065356688103776

Epoch: 6| Step: 2
Training loss: 3.327276560491712
Validation loss: 2.9036988665402665

Epoch: 6| Step: 3
Training loss: 3.391533655156265
Validation loss: 2.9067128148479244

Epoch: 6| Step: 4
Training loss: 2.6221105021943245
Validation loss: 2.907597686599664

Epoch: 6| Step: 5
Training loss: 2.4149382647724877
Validation loss: 2.904378310559812

Epoch: 6| Step: 6
Training loss: 3.3532576820025595
Validation loss: 2.9060348852780384

Epoch: 6| Step: 7
Training loss: 3.440910173702058
Validation loss: 2.905674126103051

Epoch: 6| Step: 8
Training loss: 3.3950856483678606
Validation loss: 2.9059847506582535

Epoch: 6| Step: 9
Training loss: 2.777953862861039
Validation loss: 2.9123779467061657

Epoch: 6| Step: 10
Training loss: 3.2741360522170937
Validation loss: 2.9148838278288722

Epoch: 6| Step: 11
Training loss: 3.8369324553357833
Validation loss: 2.913637651920654

Epoch: 6| Step: 12
Training loss: 2.7968968225405635
Validation loss: 2.9140634589251544

Epoch: 6| Step: 13
Training loss: 2.9913885180310675
Validation loss: 2.9094734570790104

Epoch: 201| Step: 0
Training loss: 2.911073025688066
Validation loss: 2.9043749581340212

Epoch: 6| Step: 1
Training loss: 3.818149820416619
Validation loss: 2.905062756377937

Epoch: 6| Step: 2
Training loss: 3.989665270462788
Validation loss: 2.907754777328779

Epoch: 6| Step: 3
Training loss: 2.3145630371778747
Validation loss: 2.9078602726576563

Epoch: 6| Step: 4
Training loss: 3.402472825344748
Validation loss: 2.9104779333466406

Epoch: 6| Step: 5
Training loss: 3.310870939614557
Validation loss: 2.9110635146370383

Epoch: 6| Step: 6
Training loss: 3.0712311513320043
Validation loss: 2.910714215612981

Epoch: 6| Step: 7
Training loss: 3.2730080407052906
Validation loss: 2.912860750455964

Epoch: 6| Step: 8
Training loss: 3.440786559203592
Validation loss: 2.912866948190664

Epoch: 6| Step: 9
Training loss: 2.940018568434434
Validation loss: 2.914281642263586

Epoch: 6| Step: 10
Training loss: 2.2581479572445784
Validation loss: 2.91321258172279

Epoch: 6| Step: 11
Training loss: 3.6823837218407767
Validation loss: 2.917829205102117

Epoch: 6| Step: 12
Training loss: 2.9559338648602633
Validation loss: 2.9139520745789484

Epoch: 6| Step: 13
Training loss: 2.96423767891339
Validation loss: 2.9125296981531816

Epoch: 202| Step: 0
Training loss: 3.7001583271690097
Validation loss: 2.9110148519150076

Epoch: 6| Step: 1
Training loss: 2.870933476340706
Validation loss: 2.911312656932191

Epoch: 6| Step: 2
Training loss: 3.3876221187862647
Validation loss: 2.90884299616755

Epoch: 6| Step: 3
Training loss: 2.3814166874253546
Validation loss: 2.908734222570551

Epoch: 6| Step: 4
Training loss: 2.7308462861535494
Validation loss: 2.909273781376059

Epoch: 6| Step: 5
Training loss: 3.298886521648607
Validation loss: 2.9076991266436956

Epoch: 6| Step: 6
Training loss: 3.2582767439381035
Validation loss: 2.9062145758939963

Epoch: 6| Step: 7
Training loss: 3.1911193644004547
Validation loss: 2.9073227221278493

Epoch: 6| Step: 8
Training loss: 2.867632839115842
Validation loss: 2.9054852186296665

Epoch: 6| Step: 9
Training loss: 3.1744616254781377
Validation loss: 2.904627127780872

Epoch: 6| Step: 10
Training loss: 2.968905474958454
Validation loss: 2.9052503041626667

Epoch: 6| Step: 11
Training loss: 3.8066145698826115
Validation loss: 2.903675429303111

Epoch: 6| Step: 12
Training loss: 3.6397643811607105
Validation loss: 2.902667598344406

Epoch: 6| Step: 13
Training loss: 3.3149121696608974
Validation loss: 2.9050436066418346

Epoch: 203| Step: 0
Training loss: 3.554107417469555
Validation loss: 2.9038633156495184

Epoch: 6| Step: 1
Training loss: 3.7495520006239813
Validation loss: 2.902989534849804

Epoch: 6| Step: 2
Training loss: 3.2203741327761453
Validation loss: 2.9065859950260804

Epoch: 6| Step: 3
Training loss: 3.4179765624910714
Validation loss: 2.904139258248499

Epoch: 6| Step: 4
Training loss: 2.784974936298887
Validation loss: 2.90089660365503

Epoch: 6| Step: 5
Training loss: 3.1394798506448454
Validation loss: 2.899889519340519

Epoch: 6| Step: 6
Training loss: 2.6764309950466383
Validation loss: 2.906381042856965

Epoch: 6| Step: 7
Training loss: 3.306252976760534
Validation loss: 2.899993054505752

Epoch: 6| Step: 8
Training loss: 2.769115249963086
Validation loss: 2.9044600165772088

Epoch: 6| Step: 9
Training loss: 2.8466187145056723
Validation loss: 2.905881323107319

Epoch: 6| Step: 10
Training loss: 2.7446754233098836
Validation loss: 2.901992703528457

Epoch: 6| Step: 11
Training loss: 3.5619763441205246
Validation loss: 2.9121794068090243

Epoch: 6| Step: 12
Training loss: 3.4241051221824876
Validation loss: 2.923304726271522

Epoch: 6| Step: 13
Training loss: 3.2879723851327443
Validation loss: 2.9119298694232003

Epoch: 204| Step: 0
Training loss: 3.1868203130362662
Validation loss: 2.9120699197428084

Epoch: 6| Step: 1
Training loss: 2.640535251514311
Validation loss: 2.9078732157570073

Epoch: 6| Step: 2
Training loss: 3.334134259958308
Validation loss: 2.9007605962951866

Epoch: 6| Step: 3
Training loss: 2.994596383182372
Validation loss: 2.89851249144731

Epoch: 6| Step: 4
Training loss: 3.053450624248193
Validation loss: 2.8969443783667654

Epoch: 6| Step: 5
Training loss: 2.913306089516826
Validation loss: 2.89937216561224

Epoch: 6| Step: 6
Training loss: 3.70845375865607
Validation loss: 2.895220673942371

Epoch: 6| Step: 7
Training loss: 2.8570523860776498
Validation loss: 2.8998888103341836

Epoch: 6| Step: 8
Training loss: 2.887686890998457
Validation loss: 2.9011867990081766

Epoch: 6| Step: 9
Training loss: 3.2294480396041254
Validation loss: 2.8987190975041996

Epoch: 6| Step: 10
Training loss: 3.6810357282418185
Validation loss: 2.899057818843711

Epoch: 6| Step: 11
Training loss: 4.25419633925374
Validation loss: 2.8982952138165414

Epoch: 6| Step: 12
Training loss: 2.803565350735075
Validation loss: 2.8961367937604807

Epoch: 6| Step: 13
Training loss: 2.4374014027534594
Validation loss: 2.8980784064259457

Epoch: 205| Step: 0
Training loss: 2.6468151603699233
Validation loss: 2.897504444002293

Epoch: 6| Step: 1
Training loss: 3.4883418061915505
Validation loss: 2.897490013279685

Epoch: 6| Step: 2
Training loss: 3.076134672394087
Validation loss: 2.893466917136153

Epoch: 6| Step: 3
Training loss: 3.135743099890867
Validation loss: 2.8999991091259023

Epoch: 6| Step: 4
Training loss: 3.434555457166836
Validation loss: 2.8969157475528773

Epoch: 6| Step: 5
Training loss: 2.557883780015791
Validation loss: 2.9039445514925055

Epoch: 6| Step: 6
Training loss: 3.4103706004100367
Validation loss: 2.8966212672847043

Epoch: 6| Step: 7
Training loss: 3.0729447358137167
Validation loss: 2.8973977381249805

Epoch: 6| Step: 8
Training loss: 3.094788348182141
Validation loss: 2.892934906934306

Epoch: 6| Step: 9
Training loss: 2.3126293867875902
Validation loss: 2.892789226182603

Epoch: 6| Step: 10
Training loss: 3.696698757430207
Validation loss: 2.8946343790040774

Epoch: 6| Step: 11
Training loss: 3.609923746249407
Validation loss: 2.8915639357336196

Epoch: 6| Step: 12
Training loss: 3.850819854635691
Validation loss: 2.8964463832769054

Epoch: 6| Step: 13
Training loss: 2.49134348386242
Validation loss: 2.8954840964668427

Epoch: 206| Step: 0
Training loss: 3.30718279481647
Validation loss: 2.8913299224276976

Epoch: 6| Step: 1
Training loss: 3.932144155535515
Validation loss: 2.896230584659113

Epoch: 6| Step: 2
Training loss: 2.2980127954882104
Validation loss: 2.895780694931238

Epoch: 6| Step: 3
Training loss: 3.159411971029664
Validation loss: 2.8926870931221282

Epoch: 6| Step: 4
Training loss: 3.525112253119711
Validation loss: 2.8907163579506183

Epoch: 6| Step: 5
Training loss: 2.9636321274684025
Validation loss: 2.892795807226784

Epoch: 6| Step: 6
Training loss: 3.74023845463224
Validation loss: 2.8922227341210096

Epoch: 6| Step: 7
Training loss: 2.946427597111793
Validation loss: 2.8958266187265247

Epoch: 6| Step: 8
Training loss: 3.6017543385815087
Validation loss: 2.8938653868743662

Epoch: 6| Step: 9
Training loss: 3.1420002673347502
Validation loss: 2.892146230461812

Epoch: 6| Step: 10
Training loss: 2.108426028941742
Validation loss: 2.893461716252754

Epoch: 6| Step: 11
Training loss: 3.4602525433672313
Validation loss: 2.896522861866954

Epoch: 6| Step: 12
Training loss: 2.757868779718542
Validation loss: 2.9007270866150328

Epoch: 6| Step: 13
Training loss: 3.0433559342791967
Validation loss: 2.8981645422023283

Epoch: 207| Step: 0
Training loss: 2.8529500851280982
Validation loss: 2.901438256139332

Epoch: 6| Step: 1
Training loss: 2.090332430452105
Validation loss: 2.9049633740525134

Epoch: 6| Step: 2
Training loss: 3.0354581901173003
Validation loss: 2.9146060719798896

Epoch: 6| Step: 3
Training loss: 2.731817215391492
Validation loss: 2.902478927105204

Epoch: 6| Step: 4
Training loss: 3.3104152236912925
Validation loss: 2.900686830474383

Epoch: 6| Step: 5
Training loss: 3.723232228731501
Validation loss: 2.894575124692079

Epoch: 6| Step: 6
Training loss: 2.8940185422270375
Validation loss: 2.8898138502888058

Epoch: 6| Step: 7
Training loss: 2.7388836991074172
Validation loss: 2.893826785818858

Epoch: 6| Step: 8
Training loss: 3.5862836151302724
Validation loss: 2.889048688055101

Epoch: 6| Step: 9
Training loss: 3.576249743144597
Validation loss: 2.8883316409988895

Epoch: 6| Step: 10
Training loss: 3.460078216727064
Validation loss: 2.8877919067689843

Epoch: 6| Step: 11
Training loss: 3.165309481322297
Validation loss: 2.8896952696209897

Epoch: 6| Step: 12
Training loss: 3.6445184280153606
Validation loss: 2.8914011783709817

Epoch: 6| Step: 13
Training loss: 3.43293681277743
Validation loss: 2.889749781048114

Epoch: 208| Step: 0
Training loss: 3.4699240407407683
Validation loss: 2.8885435939113924

Epoch: 6| Step: 1
Training loss: 2.5801301499001137
Validation loss: 2.893494992884955

Epoch: 6| Step: 2
Training loss: 2.9905068879436443
Validation loss: 2.8918177916588106

Epoch: 6| Step: 3
Training loss: 3.3157340043510524
Validation loss: 2.8893689575942734

Epoch: 6| Step: 4
Training loss: 2.865907471690512
Validation loss: 2.890961226332017

Epoch: 6| Step: 5
Training loss: 3.2904739794442097
Validation loss: 2.889882521321052

Epoch: 6| Step: 6
Training loss: 2.6392216310919556
Validation loss: 2.8915071630736784

Epoch: 6| Step: 7
Training loss: 3.752591826899313
Validation loss: 2.890906640200697

Epoch: 6| Step: 8
Training loss: 4.0172956383126035
Validation loss: 2.89004693341608

Epoch: 6| Step: 9
Training loss: 3.1546856619917873
Validation loss: 2.8909138117003974

Epoch: 6| Step: 10
Training loss: 2.218656726004877
Validation loss: 2.8879712029694122

Epoch: 6| Step: 11
Training loss: 3.1570025764868066
Validation loss: 2.8873983895785424

Epoch: 6| Step: 12
Training loss: 3.194897314579611
Validation loss: 2.8888405535382518

Epoch: 6| Step: 13
Training loss: 3.6731779343492383
Validation loss: 2.8873023974604237

Epoch: 209| Step: 0
Training loss: 3.3806621950190547
Validation loss: 2.8871881897366003

Epoch: 6| Step: 1
Training loss: 2.733853448446311
Validation loss: 2.8877345929848866

Epoch: 6| Step: 2
Training loss: 3.343168261539251
Validation loss: 2.8883949135973954

Epoch: 6| Step: 3
Training loss: 3.19272589043441
Validation loss: 2.891403307200058

Epoch: 6| Step: 4
Training loss: 2.484568270477111
Validation loss: 2.896804018920179

Epoch: 6| Step: 5
Training loss: 3.509638729359493
Validation loss: 2.901056252336825

Epoch: 6| Step: 6
Training loss: 3.51618919084017
Validation loss: 2.9054624610958135

Epoch: 6| Step: 7
Training loss: 3.232984160875623
Validation loss: 2.91050270750789

Epoch: 6| Step: 8
Training loss: 3.5514432418006407
Validation loss: 2.914289522442849

Epoch: 6| Step: 9
Training loss: 2.4358535487871427
Validation loss: 2.931444808210237

Epoch: 6| Step: 10
Training loss: 3.0473986053497653
Validation loss: 2.9301972694028136

Epoch: 6| Step: 11
Training loss: 3.469978733492278
Validation loss: 2.925529764569376

Epoch: 6| Step: 12
Training loss: 2.7424970924828
Validation loss: 2.904182143888163

Epoch: 6| Step: 13
Training loss: 3.8151257337496554
Validation loss: 2.892596790043867

Epoch: 210| Step: 0
Training loss: 3.829479491718194
Validation loss: 2.885909592850947

Epoch: 6| Step: 1
Training loss: 2.872146683254425
Validation loss: 2.889027083299116

Epoch: 6| Step: 2
Training loss: 3.6056893426897343
Validation loss: 2.886910894181018

Epoch: 6| Step: 3
Training loss: 3.3888424173583966
Validation loss: 2.885777521778586

Epoch: 6| Step: 4
Training loss: 2.849655056875528
Validation loss: 2.8854198574997567

Epoch: 6| Step: 5
Training loss: 3.2993733128902676
Validation loss: 2.886849585373193

Epoch: 6| Step: 6
Training loss: 2.772926734850628
Validation loss: 2.890056008010068

Epoch: 6| Step: 7
Training loss: 3.021262162562468
Validation loss: 2.8866847576040637

Epoch: 6| Step: 8
Training loss: 3.051620465659297
Validation loss: 2.890251185605991

Epoch: 6| Step: 9
Training loss: 3.3383745854902016
Validation loss: 2.891207244421995

Epoch: 6| Step: 10
Training loss: 3.842391355488838
Validation loss: 2.8922071858920537

Epoch: 6| Step: 11
Training loss: 2.5259411559148663
Validation loss: 2.8912845931048263

Epoch: 6| Step: 12
Training loss: 2.903018590580477
Validation loss: 2.892710876398735

Epoch: 6| Step: 13
Training loss: 2.7766620641748845
Validation loss: 2.8900087861015074

Epoch: 211| Step: 0
Training loss: 3.763563169405097
Validation loss: 2.8887282348016767

Epoch: 6| Step: 1
Training loss: 2.3410404055700265
Validation loss: 2.88781274931567

Epoch: 6| Step: 2
Training loss: 3.5323776200161023
Validation loss: 2.888373531169784

Epoch: 6| Step: 3
Training loss: 3.3400784594063406
Validation loss: 2.8853409717499576

Epoch: 6| Step: 4
Training loss: 3.4161342733290048
Validation loss: 2.884635849557479

Epoch: 6| Step: 5
Training loss: 3.0537460710622812
Validation loss: 2.8844825808558126

Epoch: 6| Step: 6
Training loss: 3.05413985160377
Validation loss: 2.8848493492264073

Epoch: 6| Step: 7
Training loss: 3.7415607859378905
Validation loss: 2.8842017044104793

Epoch: 6| Step: 8
Training loss: 2.631692529285112
Validation loss: 2.882925588988166

Epoch: 6| Step: 9
Training loss: 3.234522571974993
Validation loss: 2.8844194259691243

Epoch: 6| Step: 10
Training loss: 3.228993827542206
Validation loss: 2.8830357142319984

Epoch: 6| Step: 11
Training loss: 2.7440910144814907
Validation loss: 2.881251966597534

Epoch: 6| Step: 12
Training loss: 3.1117887856361865
Validation loss: 2.8820921135111788

Epoch: 6| Step: 13
Training loss: 2.9163483763909324
Validation loss: 2.8818527782015937

Epoch: 212| Step: 0
Training loss: 2.9466279428909385
Validation loss: 2.8832627149511447

Epoch: 6| Step: 1
Training loss: 2.9352653607011296
Validation loss: 2.880111161907262

Epoch: 6| Step: 2
Training loss: 2.7104253367569515
Validation loss: 2.8826344650700135

Epoch: 6| Step: 3
Training loss: 3.2010458548448404
Validation loss: 2.879353029969434

Epoch: 6| Step: 4
Training loss: 3.4119879313945316
Validation loss: 2.883805476642975

Epoch: 6| Step: 5
Training loss: 2.7608240558695987
Validation loss: 2.891897016670384

Epoch: 6| Step: 6
Training loss: 2.57900190756684
Validation loss: 2.8931827438249935

Epoch: 6| Step: 7
Training loss: 2.884235475416133
Validation loss: 2.8990123822018887

Epoch: 6| Step: 8
Training loss: 3.194982534966768
Validation loss: 2.892895233585859

Epoch: 6| Step: 9
Training loss: 2.9358249514833057
Validation loss: 2.8790678250912545

Epoch: 6| Step: 10
Training loss: 3.7326575763244456
Validation loss: 2.8806046468008737

Epoch: 6| Step: 11
Training loss: 3.7959812195517317
Validation loss: 2.882310056683139

Epoch: 6| Step: 12
Training loss: 3.5125637713850657
Validation loss: 2.8797698648572263

Epoch: 6| Step: 13
Training loss: 3.750702982814743
Validation loss: 2.8812487118309082

Epoch: 213| Step: 0
Training loss: 3.5067400747914634
Validation loss: 2.8816012578511025

Epoch: 6| Step: 1
Training loss: 3.0587653919451596
Validation loss: 2.881245533580671

Epoch: 6| Step: 2
Training loss: 3.660710930905815
Validation loss: 2.88128110629348

Epoch: 6| Step: 3
Training loss: 2.862978139865148
Validation loss: 2.878357452090688

Epoch: 6| Step: 4
Training loss: 3.3652513783667946
Validation loss: 2.8814267620952667

Epoch: 6| Step: 5
Training loss: 3.213314466724436
Validation loss: 2.8777336822363586

Epoch: 6| Step: 6
Training loss: 3.5950628121821677
Validation loss: 2.87892130104265

Epoch: 6| Step: 7
Training loss: 2.5843417957760577
Validation loss: 2.8798672501700024

Epoch: 6| Step: 8
Training loss: 3.219790392385572
Validation loss: 2.8765261604437944

Epoch: 6| Step: 9
Training loss: 2.984249252146675
Validation loss: 2.8756723317776856

Epoch: 6| Step: 10
Training loss: 3.151198470993039
Validation loss: 2.8763887779329687

Epoch: 6| Step: 11
Training loss: 3.3638386724118727
Validation loss: 2.876864949726612

Epoch: 6| Step: 12
Training loss: 2.6933170616804047
Validation loss: 2.874883020704276

Epoch: 6| Step: 13
Training loss: 2.8165155355172997
Validation loss: 2.875692345717157

Epoch: 214| Step: 0
Training loss: 2.9434980474964196
Validation loss: 2.878568290539809

Epoch: 6| Step: 1
Training loss: 3.32708752718864
Validation loss: 2.876011877701257

Epoch: 6| Step: 2
Training loss: 2.430984984715176
Validation loss: 2.8762017930959147

Epoch: 6| Step: 3
Training loss: 3.7455069009668676
Validation loss: 2.878284637854208

Epoch: 6| Step: 4
Training loss: 3.5178947751008187
Validation loss: 2.8748292207933646

Epoch: 6| Step: 5
Training loss: 3.279101149515654
Validation loss: 2.877332897408102

Epoch: 6| Step: 6
Training loss: 2.921308982818439
Validation loss: 2.8799638399437106

Epoch: 6| Step: 7
Training loss: 3.615453052965595
Validation loss: 2.878328811854102

Epoch: 6| Step: 8
Training loss: 3.081491865527081
Validation loss: 2.873736088996646

Epoch: 6| Step: 9
Training loss: 3.3956104665691305
Validation loss: 2.8784381849219565

Epoch: 6| Step: 10
Training loss: 3.161994767070689
Validation loss: 2.8756460183613903

Epoch: 6| Step: 11
Training loss: 3.03456155064063
Validation loss: 2.8746070339120995

Epoch: 6| Step: 12
Training loss: 2.587070919708912
Validation loss: 2.8711729441548504

Epoch: 6| Step: 13
Training loss: 2.9820988947986575
Validation loss: 2.8724221670036054

Epoch: 215| Step: 0
Training loss: 3.0742413957433072
Validation loss: 2.872017816693521

Epoch: 6| Step: 1
Training loss: 3.328573993609368
Validation loss: 2.874185834742882

Epoch: 6| Step: 2
Training loss: 3.507892021518243
Validation loss: 2.8730281132859217

Epoch: 6| Step: 3
Training loss: 3.6382855278319277
Validation loss: 2.873118623639996

Epoch: 6| Step: 4
Training loss: 3.2848653585168424
Validation loss: 2.872348709633975

Epoch: 6| Step: 5
Training loss: 3.3627291236157393
Validation loss: 2.8718809219401598

Epoch: 6| Step: 6
Training loss: 2.3296615343290688
Validation loss: 2.871777105273647

Epoch: 6| Step: 7
Training loss: 3.5353402274295527
Validation loss: 2.8743674932083936

Epoch: 6| Step: 8
Training loss: 2.5925820720045385
Validation loss: 2.874598695800976

Epoch: 6| Step: 9
Training loss: 2.8451675403250913
Validation loss: 2.8732943404120803

Epoch: 6| Step: 10
Training loss: 3.4155756130993247
Validation loss: 2.8737818173340317

Epoch: 6| Step: 11
Training loss: 2.78854989435471
Validation loss: 2.8725098467821333

Epoch: 6| Step: 12
Training loss: 3.429701403196478
Validation loss: 2.872738173635804

Epoch: 6| Step: 13
Training loss: 2.7939659632559963
Validation loss: 2.8709382179763603

Epoch: 216| Step: 0
Training loss: 2.8493990281236794
Validation loss: 2.8715066878057613

Epoch: 6| Step: 1
Training loss: 3.055184482429774
Validation loss: 2.8672836603660934

Epoch: 6| Step: 2
Training loss: 2.6380935362688556
Validation loss: 2.8692624327119227

Epoch: 6| Step: 3
Training loss: 3.0221843636080044
Validation loss: 2.8734448334381635

Epoch: 6| Step: 4
Training loss: 3.584622409998803
Validation loss: 2.8829098750143793

Epoch: 6| Step: 5
Training loss: 3.2543653368087555
Validation loss: 2.878530426613213

Epoch: 6| Step: 6
Training loss: 2.8331688851896626
Validation loss: 2.8806415614704

Epoch: 6| Step: 7
Training loss: 3.191240397407856
Validation loss: 2.8793507016953734

Epoch: 6| Step: 8
Training loss: 3.378392104352956
Validation loss: 2.871000983635815

Epoch: 6| Step: 9
Training loss: 2.7506106305586733
Validation loss: 2.8743391039768165

Epoch: 6| Step: 10
Training loss: 3.5534416279086534
Validation loss: 2.8694541492520473

Epoch: 6| Step: 11
Training loss: 3.9650158473656623
Validation loss: 2.871646560734636

Epoch: 6| Step: 12
Training loss: 2.9210869853575723
Validation loss: 2.871567203766418

Epoch: 6| Step: 13
Training loss: 3.038928502127031
Validation loss: 2.8705389725053676

Epoch: 217| Step: 0
Training loss: 3.8419924804042007
Validation loss: 2.8708283787887954

Epoch: 6| Step: 1
Training loss: 3.1263902242115282
Validation loss: 2.870623963644296

Epoch: 6| Step: 2
Training loss: 3.547697938070551
Validation loss: 2.869922139553465

Epoch: 6| Step: 3
Training loss: 3.0987260661983984
Validation loss: 2.87117842738502

Epoch: 6| Step: 4
Training loss: 3.248964878445452
Validation loss: 2.871766746343097

Epoch: 6| Step: 5
Training loss: 2.2420537290643217
Validation loss: 2.870435639602783

Epoch: 6| Step: 6
Training loss: 3.0278789219503497
Validation loss: 2.871731579798312

Epoch: 6| Step: 7
Training loss: 3.1889349007766845
Validation loss: 2.8709341371340917

Epoch: 6| Step: 8
Training loss: 3.601818282504761
Validation loss: 2.872788706412922

Epoch: 6| Step: 9
Training loss: 2.727970666878694
Validation loss: 2.870459554550879

Epoch: 6| Step: 10
Training loss: 3.0567011525556693
Validation loss: 2.8758133945426483

Epoch: 6| Step: 11
Training loss: 2.921952843266627
Validation loss: 2.8753297018405477

Epoch: 6| Step: 12
Training loss: 3.6539547228416978
Validation loss: 2.872722358869602

Epoch: 6| Step: 13
Training loss: 2.284403776517247
Validation loss: 2.876872568818502

Epoch: 218| Step: 0
Training loss: 2.948760829515934
Validation loss: 2.8793084238285007

Epoch: 6| Step: 1
Training loss: 3.7814986722530994
Validation loss: 2.885680289727538

Epoch: 6| Step: 2
Training loss: 3.240943614927097
Validation loss: 2.87038977936153

Epoch: 6| Step: 3
Training loss: 3.5365826337240716
Validation loss: 2.8711999682261387

Epoch: 6| Step: 4
Training loss: 2.68546750592943
Validation loss: 2.8683882557782923

Epoch: 6| Step: 5
Training loss: 3.3653688409456564
Validation loss: 2.8765051362986185

Epoch: 6| Step: 6
Training loss: 3.554155448248906
Validation loss: 2.8706777182336496

Epoch: 6| Step: 7
Training loss: 2.466278577465952
Validation loss: 2.8696367460085197

Epoch: 6| Step: 8
Training loss: 2.949963042464142
Validation loss: 2.8716836601908025

Epoch: 6| Step: 9
Training loss: 2.8808135258533736
Validation loss: 2.870377018244874

Epoch: 6| Step: 10
Training loss: 3.1159414607022766
Validation loss: 2.8703999842842345

Epoch: 6| Step: 11
Training loss: 3.520943513910641
Validation loss: 2.8739662005961866

Epoch: 6| Step: 12
Training loss: 2.598337001084273
Validation loss: 2.873433194878262

Epoch: 6| Step: 13
Training loss: 3.4403996115719884
Validation loss: 2.871643196879312

Epoch: 219| Step: 0
Training loss: 2.66021235514669
Validation loss: 2.8702191822631327

Epoch: 6| Step: 1
Training loss: 3.099406763965192
Validation loss: 2.8666080429033336

Epoch: 6| Step: 2
Training loss: 2.3031603910089817
Validation loss: 2.8612576773460163

Epoch: 6| Step: 3
Training loss: 3.18612042660078
Validation loss: 2.8631971269923113

Epoch: 6| Step: 4
Training loss: 3.0099413187383797
Validation loss: 2.865431114477346

Epoch: 6| Step: 5
Training loss: 2.9439169413211137
Validation loss: 2.8631417867913544

Epoch: 6| Step: 6
Training loss: 2.96654388373672
Validation loss: 2.863132155019422

Epoch: 6| Step: 7
Training loss: 4.018528938442719
Validation loss: 2.864612507750805

Epoch: 6| Step: 8
Training loss: 3.341898753287071
Validation loss: 2.8635457512160434

Epoch: 6| Step: 9
Training loss: 3.5047621346161653
Validation loss: 2.862085819295944

Epoch: 6| Step: 10
Training loss: 3.323525272388651
Validation loss: 2.860581747041799

Epoch: 6| Step: 11
Training loss: 3.8490249290778937
Validation loss: 2.8589948704878076

Epoch: 6| Step: 12
Training loss: 2.744956854253609
Validation loss: 2.8628781652213076

Epoch: 6| Step: 13
Training loss: 2.748619600111249
Validation loss: 2.8583080960319616

Epoch: 220| Step: 0
Training loss: 2.88597698256949
Validation loss: 2.858564708850649

Epoch: 6| Step: 1
Training loss: 3.0660874510832907
Validation loss: 2.8588338916316607

Epoch: 6| Step: 2
Training loss: 3.027595913137126
Validation loss: 2.8586978658616995

Epoch: 6| Step: 3
Training loss: 3.503235139229861
Validation loss: 2.8625145750189236

Epoch: 6| Step: 4
Training loss: 3.8335786547459834
Validation loss: 2.858816847177641

Epoch: 6| Step: 5
Training loss: 2.562129854590643
Validation loss: 2.859816625309627

Epoch: 6| Step: 6
Training loss: 3.8715603236420852
Validation loss: 2.8594774846149438

Epoch: 6| Step: 7
Training loss: 2.7022015532252457
Validation loss: 2.857083751119106

Epoch: 6| Step: 8
Training loss: 2.482655632004081
Validation loss: 2.8581335514246424

Epoch: 6| Step: 9
Training loss: 3.995564266264174
Validation loss: 2.8626300662387227

Epoch: 6| Step: 10
Training loss: 2.9488038434347685
Validation loss: 2.8573440071134253

Epoch: 6| Step: 11
Training loss: 3.2957489838800065
Validation loss: 2.8574224563768618

Epoch: 6| Step: 12
Training loss: 2.8794960028674783
Validation loss: 2.857379076186785

Epoch: 6| Step: 13
Training loss: 2.211349502834806
Validation loss: 2.8621864136692143

Epoch: 221| Step: 0
Training loss: 2.6342426343722374
Validation loss: 2.8624767020406265

Epoch: 6| Step: 1
Training loss: 3.5955890759683116
Validation loss: 2.8633168686167245

Epoch: 6| Step: 2
Training loss: 2.6984911764755877
Validation loss: 2.8672620695385085

Epoch: 6| Step: 3
Training loss: 3.0855558135196204
Validation loss: 2.8640893251028525

Epoch: 6| Step: 4
Training loss: 3.1001556049794416
Validation loss: 2.865313290006826

Epoch: 6| Step: 5
Training loss: 3.5266419448659083
Validation loss: 2.864168059526283

Epoch: 6| Step: 6
Training loss: 2.7967530975201886
Validation loss: 2.861727084645462

Epoch: 6| Step: 7
Training loss: 3.5192922496195767
Validation loss: 2.8645224884522085

Epoch: 6| Step: 8
Training loss: 3.1613356908464696
Validation loss: 2.8630285691156354

Epoch: 6| Step: 9
Training loss: 3.8983486983404316
Validation loss: 2.8584645959907706

Epoch: 6| Step: 10
Training loss: 2.720247754986803
Validation loss: 2.8662238495409005

Epoch: 6| Step: 11
Training loss: 2.4560816738701305
Validation loss: 2.8585923686834676

Epoch: 6| Step: 12
Training loss: 3.1850281649172145
Validation loss: 2.8601746848799863

Epoch: 6| Step: 13
Training loss: 3.6368102688034765
Validation loss: 2.8567353819782664

Epoch: 222| Step: 0
Training loss: 3.6376146960446323
Validation loss: 2.8584536722232876

Epoch: 6| Step: 1
Training loss: 2.902741149557681
Validation loss: 2.8611834002177203

Epoch: 6| Step: 2
Training loss: 3.387637461445724
Validation loss: 2.856770366091678

Epoch: 6| Step: 3
Training loss: 2.8680402023072795
Validation loss: 2.8558866077476535

Epoch: 6| Step: 4
Training loss: 3.5098805607745858
Validation loss: 2.8578436615360476

Epoch: 6| Step: 5
Training loss: 3.095387651512289
Validation loss: 2.857601631448746

Epoch: 6| Step: 6
Training loss: 2.7556543307734462
Validation loss: 2.8563388767821816

Epoch: 6| Step: 7
Training loss: 3.1647671138663216
Validation loss: 2.8567483242835725

Epoch: 6| Step: 8
Training loss: 3.1896062137938386
Validation loss: 2.8567105866476905

Epoch: 6| Step: 9
Training loss: 3.2629009365858255
Validation loss: 2.8630489257406584

Epoch: 6| Step: 10
Training loss: 3.9016591675393117
Validation loss: 2.8604741818369908

Epoch: 6| Step: 11
Training loss: 3.1143296222416277
Validation loss: 2.8563504943452

Epoch: 6| Step: 12
Training loss: 1.8847768832646268
Validation loss: 2.8531458350744616

Epoch: 6| Step: 13
Training loss: 2.9401184748438562
Validation loss: 2.8573466054354637

Epoch: 223| Step: 0
Training loss: 2.74328095895577
Validation loss: 2.85245960265336

Epoch: 6| Step: 1
Training loss: 2.4401138180623616
Validation loss: 2.8514037538293713

Epoch: 6| Step: 2
Training loss: 3.8652134027822904
Validation loss: 2.8556642877965386

Epoch: 6| Step: 3
Training loss: 3.4046321841644276
Validation loss: 2.8525240969360195

Epoch: 6| Step: 4
Training loss: 2.3941773593379225
Validation loss: 2.8511655892280614

Epoch: 6| Step: 5
Training loss: 3.5259010516048246
Validation loss: 2.8529965815392258

Epoch: 6| Step: 6
Training loss: 2.585909010623608
Validation loss: 2.854155497704636

Epoch: 6| Step: 7
Training loss: 3.5482232980314063
Validation loss: 2.851911417423655

Epoch: 6| Step: 8
Training loss: 3.1772606138369803
Validation loss: 2.852824780787883

Epoch: 6| Step: 9
Training loss: 3.053129223105127
Validation loss: 2.8514584281698516

Epoch: 6| Step: 10
Training loss: 3.4611659265228605
Validation loss: 2.851318523349656

Epoch: 6| Step: 11
Training loss: 3.7146297678003677
Validation loss: 2.8516977576748967

Epoch: 6| Step: 12
Training loss: 2.6596780534822346
Validation loss: 2.853146455060943

Epoch: 6| Step: 13
Training loss: 2.9744769622326106
Validation loss: 2.851781335317945

Epoch: 224| Step: 0
Training loss: 2.495888762795241
Validation loss: 2.854088241389511

Epoch: 6| Step: 1
Training loss: 2.3711713749906806
Validation loss: 2.8523294035393816

Epoch: 6| Step: 2
Training loss: 3.4066416663977597
Validation loss: 2.850509457658534

Epoch: 6| Step: 3
Training loss: 2.9644011115561457
Validation loss: 2.852529539621988

Epoch: 6| Step: 4
Training loss: 3.4700191341169426
Validation loss: 2.851813169152595

Epoch: 6| Step: 5
Training loss: 3.194348028819595
Validation loss: 2.8510139939093384

Epoch: 6| Step: 6
Training loss: 2.9928424008952894
Validation loss: 2.854135018366269

Epoch: 6| Step: 7
Training loss: 2.8009659667666194
Validation loss: 2.8492566522216425

Epoch: 6| Step: 8
Training loss: 3.4976849392687166
Validation loss: 2.8494347204046404

Epoch: 6| Step: 9
Training loss: 3.375148346077877
Validation loss: 2.851451527853336

Epoch: 6| Step: 10
Training loss: 3.011908736711863
Validation loss: 2.8486634773931594

Epoch: 6| Step: 11
Training loss: 2.953959513630223
Validation loss: 2.8494373169419287

Epoch: 6| Step: 12
Training loss: 3.550452625271786
Validation loss: 2.8496568921240435

Epoch: 6| Step: 13
Training loss: 4.052874856375463
Validation loss: 2.8491701410041554

Epoch: 225| Step: 0
Training loss: 3.2343935758637765
Validation loss: 2.847881157519239

Epoch: 6| Step: 1
Training loss: 3.15906723742102
Validation loss: 2.8523785263974326

Epoch: 6| Step: 2
Training loss: 3.723615908940783
Validation loss: 2.851832850720448

Epoch: 6| Step: 3
Training loss: 2.295906225894648
Validation loss: 2.850707467867335

Epoch: 6| Step: 4
Training loss: 3.0843752226206225
Validation loss: 2.857229021819644

Epoch: 6| Step: 5
Training loss: 3.550612039594426
Validation loss: 2.8497185449917906

Epoch: 6| Step: 6
Training loss: 3.350239810615839
Validation loss: 2.8469131026466923

Epoch: 6| Step: 7
Training loss: 2.5150723057509734
Validation loss: 2.8475483405863993

Epoch: 6| Step: 8
Training loss: 2.9477983502659346
Validation loss: 2.8545651568977233

Epoch: 6| Step: 9
Training loss: 3.60544044756294
Validation loss: 2.847953857920302

Epoch: 6| Step: 10
Training loss: 3.1455046290441047
Validation loss: 2.8474929816556678

Epoch: 6| Step: 11
Training loss: 2.693667056052456
Validation loss: 2.8484014463364598

Epoch: 6| Step: 12
Training loss: 3.1439167441102005
Validation loss: 2.8538110695797947

Epoch: 6| Step: 13
Training loss: 3.4295579194982784
Validation loss: 2.8490778791526976

Epoch: 226| Step: 0
Training loss: 3.4893989779990955
Validation loss: 2.847505256523881

Epoch: 6| Step: 1
Training loss: 2.897966454574376
Validation loss: 2.8457731649539006

Epoch: 6| Step: 2
Training loss: 3.2249685419012137
Validation loss: 2.8468843090653992

Epoch: 6| Step: 3
Training loss: 3.0247503382534977
Validation loss: 2.8480982198133984

Epoch: 6| Step: 4
Training loss: 3.084622878111828
Validation loss: 2.8472725643093053

Epoch: 6| Step: 5
Training loss: 3.0109178242537906
Validation loss: 2.848060825730098

Epoch: 6| Step: 6
Training loss: 3.1729627726547363
Validation loss: 2.8523277632500452

Epoch: 6| Step: 7
Training loss: 3.3154216333665056
Validation loss: 2.8514055699707814

Epoch: 6| Step: 8
Training loss: 3.601611486668616
Validation loss: 2.8555847003472468

Epoch: 6| Step: 9
Training loss: 3.3276977264789958
Validation loss: 2.8520370782984923

Epoch: 6| Step: 10
Training loss: 2.826050814426201
Validation loss: 2.8534299796298033

Epoch: 6| Step: 11
Training loss: 3.023569976506585
Validation loss: 2.8456221048916914

Epoch: 6| Step: 12
Training loss: 2.741527597519793
Validation loss: 2.845807439733451

Epoch: 6| Step: 13
Training loss: 3.311176395483828
Validation loss: 2.8472775668422683

Epoch: 227| Step: 0
Training loss: 3.121487894582548
Validation loss: 2.8455829773344052

Epoch: 6| Step: 1
Training loss: 2.838359208615313
Validation loss: 2.844664373365406

Epoch: 6| Step: 2
Training loss: 3.5529864254838985
Validation loss: 2.8451791998992224

Epoch: 6| Step: 3
Training loss: 3.4746607004184202
Validation loss: 2.8498773553477466

Epoch: 6| Step: 4
Training loss: 3.0321405420065033
Validation loss: 2.8422891036953946

Epoch: 6| Step: 5
Training loss: 3.7897684285218918
Validation loss: 2.844020404691073

Epoch: 6| Step: 6
Training loss: 2.4878417963958324
Validation loss: 2.8438644719694985

Epoch: 6| Step: 7
Training loss: 3.473148066533506
Validation loss: 2.842645556205834

Epoch: 6| Step: 8
Training loss: 2.525281769544635
Validation loss: 2.843695578628541

Epoch: 6| Step: 9
Training loss: 3.307754860629424
Validation loss: 2.8449930699055694

Epoch: 6| Step: 10
Training loss: 2.5505065302687626
Validation loss: 2.8423979893326776

Epoch: 6| Step: 11
Training loss: 3.246353157410918
Validation loss: 2.8389973032688736

Epoch: 6| Step: 12
Training loss: 3.6358419932832713
Validation loss: 2.8434577745771747

Epoch: 6| Step: 13
Training loss: 2.003908034652897
Validation loss: 2.8415057948149256

Epoch: 228| Step: 0
Training loss: 2.633229208549514
Validation loss: 2.8420665941538443

Epoch: 6| Step: 1
Training loss: 3.1220188417031083
Validation loss: 2.8412527293187684

Epoch: 6| Step: 2
Training loss: 3.8069981132644934
Validation loss: 2.840199056179412

Epoch: 6| Step: 3
Training loss: 3.206244312898526
Validation loss: 2.839420972595135

Epoch: 6| Step: 4
Training loss: 3.220255379353003
Validation loss: 2.8383034871019652

Epoch: 6| Step: 5
Training loss: 2.9812655402524246
Validation loss: 2.8425642920228364

Epoch: 6| Step: 6
Training loss: 2.5583956343264664
Validation loss: 2.8432907334032627

Epoch: 6| Step: 7
Training loss: 3.117531511259164
Validation loss: 2.8422381847016234

Epoch: 6| Step: 8
Training loss: 3.097477988348854
Validation loss: 2.845315003387081

Epoch: 6| Step: 9
Training loss: 3.4506943377171955
Validation loss: 2.8438801186321787

Epoch: 6| Step: 10
Training loss: 3.3319337926746218
Validation loss: 2.8423886376684293

Epoch: 6| Step: 11
Training loss: 3.1707584313774784
Validation loss: 2.849009950471708

Epoch: 6| Step: 12
Training loss: 3.0593287338795285
Validation loss: 2.8467428286195524

Epoch: 6| Step: 13
Training loss: 2.9683961356228985
Validation loss: 2.8454254310162552

Epoch: 229| Step: 0
Training loss: 3.4060570898462625
Validation loss: 2.851703180362336

Epoch: 6| Step: 1
Training loss: 3.024883703092786
Validation loss: 2.8537807097354797

Epoch: 6| Step: 2
Training loss: 3.3351838379480907
Validation loss: 2.849376303088419

Epoch: 6| Step: 3
Training loss: 2.966567994380578
Validation loss: 2.844623001206503

Epoch: 6| Step: 4
Training loss: 3.2871186590035264
Validation loss: 2.8405345347355526

Epoch: 6| Step: 5
Training loss: 3.7110097135243487
Validation loss: 2.8429620582664508

Epoch: 6| Step: 6
Training loss: 2.504020890633211
Validation loss: 2.8395788231639916

Epoch: 6| Step: 7
Training loss: 3.128104079688177
Validation loss: 2.840199658231623

Epoch: 6| Step: 8
Training loss: 3.3141836530022952
Validation loss: 2.8411824922085964

Epoch: 6| Step: 9
Training loss: 2.960483324954556
Validation loss: 2.837836620642779

Epoch: 6| Step: 10
Training loss: 2.9014002214860426
Validation loss: 2.837824939031144

Epoch: 6| Step: 11
Training loss: 2.3700568305819143
Validation loss: 2.8348009740758546

Epoch: 6| Step: 12
Training loss: 3.315338358232147
Validation loss: 2.83643145231222

Epoch: 6| Step: 13
Training loss: 3.664503254032655
Validation loss: 2.8373307965162655

Epoch: 230| Step: 0
Training loss: 2.8532216718994308
Validation loss: 2.8354219845919197

Epoch: 6| Step: 1
Training loss: 3.0334133018879577
Validation loss: 2.8360991999540506

Epoch: 6| Step: 2
Training loss: 3.060241489231219
Validation loss: 2.8393580108505074

Epoch: 6| Step: 3
Training loss: 2.737995214392616
Validation loss: 2.8401354735122077

Epoch: 6| Step: 4
Training loss: 3.1415604294303643
Validation loss: 2.838728955989735

Epoch: 6| Step: 5
Training loss: 3.228534825355036
Validation loss: 2.8389141899900805

Epoch: 6| Step: 6
Training loss: 3.645178047509734
Validation loss: 2.834228459883427

Epoch: 6| Step: 7
Training loss: 3.6993345022973654
Validation loss: 2.83900420495967

Epoch: 6| Step: 8
Training loss: 2.7693781844051704
Validation loss: 2.833999042251544

Epoch: 6| Step: 9
Training loss: 2.6328896531026587
Validation loss: 2.840532258577951

Epoch: 6| Step: 10
Training loss: 3.875414180155332
Validation loss: 2.8340533106031507

Epoch: 6| Step: 11
Training loss: 2.81487275806634
Validation loss: 2.8347549642005165

Epoch: 6| Step: 12
Training loss: 3.2596268027191964
Validation loss: 2.8351168589682287

Epoch: 6| Step: 13
Training loss: 2.7725731590807183
Validation loss: 2.835568591084885

Epoch: 231| Step: 0
Training loss: 3.290819292409629
Validation loss: 2.834979551444518

Epoch: 6| Step: 1
Training loss: 2.794743498222281
Validation loss: 2.8388750512534835

Epoch: 6| Step: 2
Training loss: 2.902470417775522
Validation loss: 2.835967877297992

Epoch: 6| Step: 3
Training loss: 2.730026886077508
Validation loss: 2.8435489556880715

Epoch: 6| Step: 4
Training loss: 2.979178813207091
Validation loss: 2.8435609239215527

Epoch: 6| Step: 5
Training loss: 2.718363241112623
Validation loss: 2.837849996033569

Epoch: 6| Step: 6
Training loss: 3.6444308971396175
Validation loss: 2.8361895880913854

Epoch: 6| Step: 7
Training loss: 3.379662013564039
Validation loss: 2.8378168139996918

Epoch: 6| Step: 8
Training loss: 3.641028124056569
Validation loss: 2.838072010543951

Epoch: 6| Step: 9
Training loss: 2.8817153124640615
Validation loss: 2.8364514403548875

Epoch: 6| Step: 10
Training loss: 3.2995730383972064
Validation loss: 2.8391138486599052

Epoch: 6| Step: 11
Training loss: 3.0083311748408836
Validation loss: 2.8367326598498637

Epoch: 6| Step: 12
Training loss: 3.157730208678503
Validation loss: 2.83042757144402

Epoch: 6| Step: 13
Training loss: 3.406426801380241
Validation loss: 2.832857741397626

Epoch: 232| Step: 0
Training loss: 2.3533592077171037
Validation loss: 2.8368259792904973

Epoch: 6| Step: 1
Training loss: 3.0467612220843585
Validation loss: 2.8350165221522157

Epoch: 6| Step: 2
Training loss: 3.211249788788417
Validation loss: 2.8349034490835696

Epoch: 6| Step: 3
Training loss: 3.1010812534978665
Validation loss: 2.835229576309473

Epoch: 6| Step: 4
Training loss: 3.668015029826514
Validation loss: 2.8331248368333233

Epoch: 6| Step: 5
Training loss: 3.1366346830169096
Validation loss: 2.835780943820544

Epoch: 6| Step: 6
Training loss: 3.316630828766037
Validation loss: 2.8335381029124775

Epoch: 6| Step: 7
Training loss: 2.9163021041460166
Validation loss: 2.830562616350778

Epoch: 6| Step: 8
Training loss: 2.522117812936006
Validation loss: 2.8327343854777935

Epoch: 6| Step: 9
Training loss: 3.3674491904545447
Validation loss: 2.835140003932308

Epoch: 6| Step: 10
Training loss: 2.796742697202492
Validation loss: 2.833225521145267

Epoch: 6| Step: 11
Training loss: 3.209084674663122
Validation loss: 2.833263831278443

Epoch: 6| Step: 12
Training loss: 3.8861580449044513
Validation loss: 2.8322115326536506

Epoch: 6| Step: 13
Training loss: 2.9022846036200787
Validation loss: 2.8357365201762597

Epoch: 233| Step: 0
Training loss: 3.89679030362299
Validation loss: 2.8333599775775857

Epoch: 6| Step: 1
Training loss: 2.916476397893145
Validation loss: 2.83982909307503

Epoch: 6| Step: 2
Training loss: 3.1476692417205205
Validation loss: 2.8474658514343005

Epoch: 6| Step: 3
Training loss: 3.2542450397609266
Validation loss: 2.8531401716265004

Epoch: 6| Step: 4
Training loss: 3.029060753007466
Validation loss: 2.8558118946841535

Epoch: 6| Step: 5
Training loss: 3.7491254422499756
Validation loss: 2.85949942021513

Epoch: 6| Step: 6
Training loss: 3.4071434319179494
Validation loss: 2.859396087337411

Epoch: 6| Step: 7
Training loss: 2.791747438391522
Validation loss: 2.8531007724789053

Epoch: 6| Step: 8
Training loss: 3.1361090992809504
Validation loss: 2.8360517358988764

Epoch: 6| Step: 9
Training loss: 3.1812944030660684
Validation loss: 2.831908985139448

Epoch: 6| Step: 10
Training loss: 3.0694662777070003
Validation loss: 2.8309008913998284

Epoch: 6| Step: 11
Training loss: 2.2732625677704648
Validation loss: 2.8302620474616664

Epoch: 6| Step: 12
Training loss: 2.9503000462417384
Validation loss: 2.829128387657126

Epoch: 6| Step: 13
Training loss: 2.418671193182066
Validation loss: 2.832049334634161

Epoch: 234| Step: 0
Training loss: 3.308078766324427
Validation loss: 2.8330918197980224

Epoch: 6| Step: 1
Training loss: 2.5289361055748962
Validation loss: 2.83782039140133

Epoch: 6| Step: 2
Training loss: 3.492875204281995
Validation loss: 2.8405800908972867

Epoch: 6| Step: 3
Training loss: 3.3074786436237718
Validation loss: 2.8399349433337484

Epoch: 6| Step: 4
Training loss: 3.0734128562199112
Validation loss: 2.833502101818135

Epoch: 6| Step: 5
Training loss: 3.000185960728134
Validation loss: 2.829942843181301

Epoch: 6| Step: 6
Training loss: 3.1272019829924065
Validation loss: 2.8264722475612434

Epoch: 6| Step: 7
Training loss: 3.4487778585981066
Validation loss: 2.828600159004805

Epoch: 6| Step: 8
Training loss: 3.1748417852434985
Validation loss: 2.8288040882305587

Epoch: 6| Step: 9
Training loss: 3.0039637129785044
Validation loss: 2.8324010196993674

Epoch: 6| Step: 10
Training loss: 2.9795661249429783
Validation loss: 2.8458681526540897

Epoch: 6| Step: 11
Training loss: 3.445131742618709
Validation loss: 2.8472895058972987

Epoch: 6| Step: 12
Training loss: 2.8333119410286933
Validation loss: 2.8493463692492598

Epoch: 6| Step: 13
Training loss: 3.083378215841162
Validation loss: 2.8394354907790986

Epoch: 235| Step: 0
Training loss: 2.1355162310455715
Validation loss: 2.8399300831333325

Epoch: 6| Step: 1
Training loss: 3.5093639995236092
Validation loss: 2.835977274993961

Epoch: 6| Step: 2
Training loss: 3.328437897923293
Validation loss: 2.826869700739647

Epoch: 6| Step: 3
Training loss: 3.561687042101884
Validation loss: 2.8269441657520558

Epoch: 6| Step: 4
Training loss: 2.520505542303317
Validation loss: 2.8294498076169408

Epoch: 6| Step: 5
Training loss: 3.897200577387962
Validation loss: 2.833420069619765

Epoch: 6| Step: 6
Training loss: 3.1780406239279615
Validation loss: 2.8381962391677895

Epoch: 6| Step: 7
Training loss: 3.1017806507329353
Validation loss: 2.8373699538437616

Epoch: 6| Step: 8
Training loss: 2.324802562575165
Validation loss: 2.8455890963717394

Epoch: 6| Step: 9
Training loss: 3.4440276156923257
Validation loss: 2.850952509334852

Epoch: 6| Step: 10
Training loss: 3.3497151438749206
Validation loss: 2.8504819685184293

Epoch: 6| Step: 11
Training loss: 3.4324993867588813
Validation loss: 2.8403948003679176

Epoch: 6| Step: 12
Training loss: 3.1262230577798875
Validation loss: 2.8444207054229866

Epoch: 6| Step: 13
Training loss: 2.1175237297160674
Validation loss: 2.835779674557393

Epoch: 236| Step: 0
Training loss: 3.567175891805535
Validation loss: 2.8340234663949038

Epoch: 6| Step: 1
Training loss: 2.778763077087794
Validation loss: 2.832220802512374

Epoch: 6| Step: 2
Training loss: 2.553951332345529
Validation loss: 2.829558888342422

Epoch: 6| Step: 3
Training loss: 3.508828608573765
Validation loss: 2.8281257868251095

Epoch: 6| Step: 4
Training loss: 2.8469093295559817
Validation loss: 2.8301747563463957

Epoch: 6| Step: 5
Training loss: 3.699188328973383
Validation loss: 2.83261899400165

Epoch: 6| Step: 6
Training loss: 2.8464490217974054
Validation loss: 2.846415960721572

Epoch: 6| Step: 7
Training loss: 3.0692077668215894
Validation loss: 2.854535272980565

Epoch: 6| Step: 8
Training loss: 3.7738312383539583
Validation loss: 2.8607632468726325

Epoch: 6| Step: 9
Training loss: 3.1709226484581556
Validation loss: 2.846480383891627

Epoch: 6| Step: 10
Training loss: 3.21563481068945
Validation loss: 2.8348578803747237

Epoch: 6| Step: 11
Training loss: 2.729581282087951
Validation loss: 2.8347518658594857

Epoch: 6| Step: 12
Training loss: 2.8685989439843667
Validation loss: 2.8288153476203486

Epoch: 6| Step: 13
Training loss: 2.8976929728880028
Validation loss: 2.8289591555580094

Epoch: 237| Step: 0
Training loss: 3.116091274927485
Validation loss: 2.8252864614363697

Epoch: 6| Step: 1
Training loss: 2.8696039395741586
Validation loss: 2.8289456901013637

Epoch: 6| Step: 2
Training loss: 2.955676717194792
Validation loss: 2.8307252455154583

Epoch: 6| Step: 3
Training loss: 3.3340232770870397
Validation loss: 2.834039422483626

Epoch: 6| Step: 4
Training loss: 3.488347410661774
Validation loss: 2.835566596637193

Epoch: 6| Step: 5
Training loss: 4.108589590461861
Validation loss: 2.8403183096708067

Epoch: 6| Step: 6
Training loss: 2.392093681025576
Validation loss: 2.830402201462204

Epoch: 6| Step: 7
Training loss: 3.1231070316477996
Validation loss: 2.8266037991490807

Epoch: 6| Step: 8
Training loss: 3.623090964817646
Validation loss: 2.8253060519487594

Epoch: 6| Step: 9
Training loss: 3.1611875683105257
Validation loss: 2.8219094435276224

Epoch: 6| Step: 10
Training loss: 2.8588509835111817
Validation loss: 2.8212456973716473

Epoch: 6| Step: 11
Training loss: 2.8605504355902664
Validation loss: 2.8248345942909925

Epoch: 6| Step: 12
Training loss: 2.765437232933417
Validation loss: 2.824087470393605

Epoch: 6| Step: 13
Training loss: 2.5979884802817654
Validation loss: 2.821103499090897

Epoch: 238| Step: 0
Training loss: 2.184898573487617
Validation loss: 2.819445923256373

Epoch: 6| Step: 1
Training loss: 3.4473631415474215
Validation loss: 2.8215470304827344

Epoch: 6| Step: 2
Training loss: 3.6158835118359374
Validation loss: 2.825034905008478

Epoch: 6| Step: 3
Training loss: 3.3276226398844684
Validation loss: 2.8547894437847203

Epoch: 6| Step: 4
Training loss: 3.3434960099486406
Validation loss: 2.8675632383169503

Epoch: 6| Step: 5
Training loss: 3.1060988452753873
Validation loss: 2.8972358199342576

Epoch: 6| Step: 6
Training loss: 2.9682920403868494
Validation loss: 2.893189961962393

Epoch: 6| Step: 7
Training loss: 2.7573074007948457
Validation loss: 2.896043865571219

Epoch: 6| Step: 8
Training loss: 3.2801444961540054
Validation loss: 2.8697082055970835

Epoch: 6| Step: 9
Training loss: 2.708151053138918
Validation loss: 2.8604259804292584

Epoch: 6| Step: 10
Training loss: 3.4146288090009547
Validation loss: 2.8463874440193324

Epoch: 6| Step: 11
Training loss: 2.8378738224296107
Validation loss: 2.832962696533611

Epoch: 6| Step: 12
Training loss: 3.5714747834621834
Validation loss: 2.8387523641038355

Epoch: 6| Step: 13
Training loss: 2.9025312032016264
Validation loss: 2.8203762741361698

Epoch: 239| Step: 0
Training loss: 3.476799088903765
Validation loss: 2.8188794704875018

Epoch: 6| Step: 1
Training loss: 3.068304050463994
Validation loss: 2.818608458417516

Epoch: 6| Step: 2
Training loss: 2.900189880205701
Validation loss: 2.823166472498589

Epoch: 6| Step: 3
Training loss: 2.5560990379918196
Validation loss: 2.824143385249998

Epoch: 6| Step: 4
Training loss: 2.469844141069788
Validation loss: 2.8243673204349458

Epoch: 6| Step: 5
Training loss: 3.5779141692970287
Validation loss: 2.8237650505759766

Epoch: 6| Step: 6
Training loss: 3.2928206115199896
Validation loss: 2.8256148091560527

Epoch: 6| Step: 7
Training loss: 3.2552544593086163
Validation loss: 2.8255257703385372

Epoch: 6| Step: 8
Training loss: 3.079192465406096
Validation loss: 2.826223027214797

Epoch: 6| Step: 9
Training loss: 2.9885826607081247
Validation loss: 2.822408376936149

Epoch: 6| Step: 10
Training loss: 3.1391195608205917
Validation loss: 2.825536013901209

Epoch: 6| Step: 11
Training loss: 3.276757789216636
Validation loss: 2.825950711815863

Epoch: 6| Step: 12
Training loss: 2.9885014471567857
Validation loss: 2.826756120406124

Epoch: 6| Step: 13
Training loss: 3.8574600720023384
Validation loss: 2.8232229713137302

Epoch: 240| Step: 0
Training loss: 3.182664681823819
Validation loss: 2.824192136916194

Epoch: 6| Step: 1
Training loss: 4.1254491850456185
Validation loss: 2.8241732394592507

Epoch: 6| Step: 2
Training loss: 2.792635128129399
Validation loss: 2.8220906316887335

Epoch: 6| Step: 3
Training loss: 2.6595685984769943
Validation loss: 2.8216371443028736

Epoch: 6| Step: 4
Training loss: 3.3149205127236865
Validation loss: 2.8213396494611223

Epoch: 6| Step: 5
Training loss: 2.268981341712736
Validation loss: 2.8217225154091645

Epoch: 6| Step: 6
Training loss: 3.5966998391541085
Validation loss: 2.8214366532361512

Epoch: 6| Step: 7
Training loss: 3.507298217320176
Validation loss: 2.8201326593494844

Epoch: 6| Step: 8
Training loss: 3.3195369038990448
Validation loss: 2.82119169425606

Epoch: 6| Step: 9
Training loss: 3.1478923770582603
Validation loss: 2.821446097515589

Epoch: 6| Step: 10
Training loss: 2.3924477802505084
Validation loss: 2.819113883370247

Epoch: 6| Step: 11
Training loss: 2.8478421123115787
Validation loss: 2.816490376093746

Epoch: 6| Step: 12
Training loss: 2.826670319971687
Validation loss: 2.8157470408623544

Epoch: 6| Step: 13
Training loss: 3.4564067729140606
Validation loss: 2.8215853519906324

Epoch: 241| Step: 0
Training loss: 3.121678685458608
Validation loss: 2.8222904440831047

Epoch: 6| Step: 1
Training loss: 2.932259287861495
Validation loss: 2.8259189132297253

Epoch: 6| Step: 2
Training loss: 3.2901887754876205
Validation loss: 2.8321944311736944

Epoch: 6| Step: 3
Training loss: 2.328863142114299
Validation loss: 2.8360599663249366

Epoch: 6| Step: 4
Training loss: 3.3846472858712855
Validation loss: 2.8269720542588517

Epoch: 6| Step: 5
Training loss: 3.3091773877386066
Validation loss: 2.8241719195917927

Epoch: 6| Step: 6
Training loss: 3.1978099362003243
Validation loss: 2.8258071544905

Epoch: 6| Step: 7
Training loss: 2.6325416312408176
Validation loss: 2.8255197838708117

Epoch: 6| Step: 8
Training loss: 3.2462484274688896
Validation loss: 2.833337323863376

Epoch: 6| Step: 9
Training loss: 3.162972721760122
Validation loss: 2.83755671759023

Epoch: 6| Step: 10
Training loss: 3.099156443356868
Validation loss: 2.8418838785921476

Epoch: 6| Step: 11
Training loss: 3.768339452950864
Validation loss: 2.8409147592228847

Epoch: 6| Step: 12
Training loss: 2.836459025199508
Validation loss: 2.8362519856456125

Epoch: 6| Step: 13
Training loss: 3.196503881128999
Validation loss: 2.8395239977290094

Epoch: 242| Step: 0
Training loss: 3.361337487730278
Validation loss: 2.8276028261817734

Epoch: 6| Step: 1
Training loss: 3.4160173000639116
Validation loss: 2.833631370137709

Epoch: 6| Step: 2
Training loss: 2.972573959675309
Validation loss: 2.8284579180631098

Epoch: 6| Step: 3
Training loss: 2.906221779306868
Validation loss: 2.83645059980246

Epoch: 6| Step: 4
Training loss: 3.1411042867822605
Validation loss: 2.824747442211905

Epoch: 6| Step: 5
Training loss: 2.773109180198117
Validation loss: 2.821854262077681

Epoch: 6| Step: 6
Training loss: 3.558846189420269
Validation loss: 2.8244637677609123

Epoch: 6| Step: 7
Training loss: 3.284582280696739
Validation loss: 2.821728399091687

Epoch: 6| Step: 8
Training loss: 3.4017847874300093
Validation loss: 2.821416167200592

Epoch: 6| Step: 9
Training loss: 2.4469266688712294
Validation loss: 2.817103320611588

Epoch: 6| Step: 10
Training loss: 3.019581151552405
Validation loss: 2.8122930489332867

Epoch: 6| Step: 11
Training loss: 3.1369948022207743
Validation loss: 2.8097827578460226

Epoch: 6| Step: 12
Training loss: 2.9555573311261014
Validation loss: 2.809464887716595

Epoch: 6| Step: 13
Training loss: 3.1697861882736063
Validation loss: 2.809525831198914

Epoch: 243| Step: 0
Training loss: 3.0988976395163808
Validation loss: 2.8111021681428823

Epoch: 6| Step: 1
Training loss: 3.6023765190187755
Validation loss: 2.8085690864565036

Epoch: 6| Step: 2
Training loss: 3.8475238912830863
Validation loss: 2.810140316710332

Epoch: 6| Step: 3
Training loss: 2.965015029483162
Validation loss: 2.813399544975656

Epoch: 6| Step: 4
Training loss: 2.7710627315087595
Validation loss: 2.8112095724371073

Epoch: 6| Step: 5
Training loss: 3.2425645723876517
Validation loss: 2.8074642405891974

Epoch: 6| Step: 6
Training loss: 2.6345128757511853
Validation loss: 2.8115886747669245

Epoch: 6| Step: 7
Training loss: 2.5158240198108506
Validation loss: 2.810469461578503

Epoch: 6| Step: 8
Training loss: 2.555921903787218
Validation loss: 2.8080622200178627

Epoch: 6| Step: 9
Training loss: 2.0859177263444213
Validation loss: 2.8099194016595765

Epoch: 6| Step: 10
Training loss: 3.5781985612662215
Validation loss: 2.809855341832215

Epoch: 6| Step: 11
Training loss: 3.585158984544201
Validation loss: 2.807755661469467

Epoch: 6| Step: 12
Training loss: 3.5346234167679387
Validation loss: 2.806579225174418

Epoch: 6| Step: 13
Training loss: 3.1978943334207606
Validation loss: 2.8075302743750052

Epoch: 244| Step: 0
Training loss: 3.4346459765176367
Validation loss: 2.812861044986493

Epoch: 6| Step: 1
Training loss: 3.640691011673535
Validation loss: 2.812297253154386

Epoch: 6| Step: 2
Training loss: 3.405359974344945
Validation loss: 2.808128223309202

Epoch: 6| Step: 3
Training loss: 2.656830488615948
Validation loss: 2.8145950936388213

Epoch: 6| Step: 4
Training loss: 3.1506815218495228
Validation loss: 2.8131268713049886

Epoch: 6| Step: 5
Training loss: 2.948083196638412
Validation loss: 2.8120046710379882

Epoch: 6| Step: 6
Training loss: 3.822322386961964
Validation loss: 2.821476844359506

Epoch: 6| Step: 7
Training loss: 2.6246918997016344
Validation loss: 2.8087613764884978

Epoch: 6| Step: 8
Training loss: 2.8874864189852425
Validation loss: 2.8209259190564184

Epoch: 6| Step: 9
Training loss: 2.8414186416032723
Validation loss: 2.823958935374059

Epoch: 6| Step: 10
Training loss: 3.070297279999649
Validation loss: 2.824075431434142

Epoch: 6| Step: 11
Training loss: 3.3213776439506772
Validation loss: 2.829332854179396

Epoch: 6| Step: 12
Training loss: 2.5807805112368962
Validation loss: 2.824364729895933

Epoch: 6| Step: 13
Training loss: 2.7438724047353253
Validation loss: 2.829068641233607

Epoch: 245| Step: 0
Training loss: 3.643101713374764
Validation loss: 2.8167241231591107

Epoch: 6| Step: 1
Training loss: 3.304046063589281
Validation loss: 2.807270214724772

Epoch: 6| Step: 2
Training loss: 3.465548300689815
Validation loss: 2.805736367448934

Epoch: 6| Step: 3
Training loss: 2.101530620801133
Validation loss: 2.8045032641916317

Epoch: 6| Step: 4
Training loss: 3.602378107427041
Validation loss: 2.808258734483609

Epoch: 6| Step: 5
Training loss: 2.4238837002907956
Validation loss: 2.806214836852767

Epoch: 6| Step: 6
Training loss: 2.7904423738293893
Validation loss: 2.8051933485725686

Epoch: 6| Step: 7
Training loss: 3.577365711392174
Validation loss: 2.8080722260110007

Epoch: 6| Step: 8
Training loss: 2.9344271556700114
Validation loss: 2.8081782243548767

Epoch: 6| Step: 9
Training loss: 2.8850294236611567
Validation loss: 2.809869875921958

Epoch: 6| Step: 10
Training loss: 3.242690155406422
Validation loss: 2.8069935983867107

Epoch: 6| Step: 11
Training loss: 3.295719757888128
Validation loss: 2.8104162101082677

Epoch: 6| Step: 12
Training loss: 3.13027752605687
Validation loss: 2.810617023940774

Epoch: 6| Step: 13
Training loss: 2.6307698371224126
Validation loss: 2.809884867943796

Epoch: 246| Step: 0
Training loss: 2.9042476195806453
Validation loss: 2.8083213518769004

Epoch: 6| Step: 1
Training loss: 3.31148974289847
Validation loss: 2.809445734246978

Epoch: 6| Step: 2
Training loss: 3.0833152736100553
Validation loss: 2.8069779744385728

Epoch: 6| Step: 3
Training loss: 3.541878159136059
Validation loss: 2.8065623000008326

Epoch: 6| Step: 4
Training loss: 2.9405822815665412
Validation loss: 2.805505721018754

Epoch: 6| Step: 5
Training loss: 2.8127547254711707
Validation loss: 2.8060950001214215

Epoch: 6| Step: 6
Training loss: 2.8212273717402927
Validation loss: 2.8020717710424257

Epoch: 6| Step: 7
Training loss: 3.4436804956528904
Validation loss: 2.804694027264259

Epoch: 6| Step: 8
Training loss: 3.4432962274413903
Validation loss: 2.802746386718622

Epoch: 6| Step: 9
Training loss: 3.251310817761262
Validation loss: 2.8054824229543254

Epoch: 6| Step: 10
Training loss: 2.8505228734138353
Validation loss: 2.8048629164307934

Epoch: 6| Step: 11
Training loss: 3.0235802274228805
Validation loss: 2.8037718734702493

Epoch: 6| Step: 12
Training loss: 3.052903534930527
Validation loss: 2.802968243015754

Epoch: 6| Step: 13
Training loss: 2.9565114782721182
Validation loss: 2.8036815566778137

Epoch: 247| Step: 0
Training loss: 3.0767422586276854
Validation loss: 2.8036329531068525

Epoch: 6| Step: 1
Training loss: 2.4374421919790223
Validation loss: 2.803484931690946

Epoch: 6| Step: 2
Training loss: 2.5954042238198607
Validation loss: 2.8093870831201118

Epoch: 6| Step: 3
Training loss: 3.5939358870488056
Validation loss: 2.8070772311982806

Epoch: 6| Step: 4
Training loss: 3.273319214934793
Validation loss: 2.8063441252017687

Epoch: 6| Step: 5
Training loss: 3.2220621197121093
Validation loss: 2.802006373500044

Epoch: 6| Step: 6
Training loss: 2.6798774496213467
Validation loss: 2.80390697245141

Epoch: 6| Step: 7
Training loss: 2.7093280334977754
Validation loss: 2.801980807485003

Epoch: 6| Step: 8
Training loss: 3.3999138091887136
Validation loss: 2.803036598780411

Epoch: 6| Step: 9
Training loss: 3.50700386089355
Validation loss: 2.807204444226272

Epoch: 6| Step: 10
Training loss: 3.0303711551175634
Validation loss: 2.801124087126289

Epoch: 6| Step: 11
Training loss: 3.4218285962446506
Validation loss: 2.8089469844879154

Epoch: 6| Step: 12
Training loss: 2.9535533453090745
Validation loss: 2.8131904857393852

Epoch: 6| Step: 13
Training loss: 3.5199169493761313
Validation loss: 2.820587523843134

Epoch: 248| Step: 0
Training loss: 3.5536418340955773
Validation loss: 2.8272552793657892

Epoch: 6| Step: 1
Training loss: 3.1581117785471653
Validation loss: 2.829208754678702

Epoch: 6| Step: 2
Training loss: 2.937363641698831
Validation loss: 2.8278637492700227

Epoch: 6| Step: 3
Training loss: 2.3966718008157053
Validation loss: 2.8364203126342793

Epoch: 6| Step: 4
Training loss: 2.822605289492276
Validation loss: 2.8255471710857214

Epoch: 6| Step: 5
Training loss: 2.7619876541811994
Validation loss: 2.8317170660432325

Epoch: 6| Step: 6
Training loss: 2.5075350694115155
Validation loss: 2.8195208880231144

Epoch: 6| Step: 7
Training loss: 3.5526130408087804
Validation loss: 2.8208770818600652

Epoch: 6| Step: 8
Training loss: 3.2747636899067154
Validation loss: 2.8074811046234296

Epoch: 6| Step: 9
Training loss: 3.4140636173482153
Validation loss: 2.804135387083892

Epoch: 6| Step: 10
Training loss: 3.8209740937629397
Validation loss: 2.7997911120429766

Epoch: 6| Step: 11
Training loss: 2.70308407438311
Validation loss: 2.796678087135229

Epoch: 6| Step: 12
Training loss: 3.250622469639394
Validation loss: 2.798002121226426

Epoch: 6| Step: 13
Training loss: 2.9682385455816322
Validation loss: 2.7974549938332522

Epoch: 249| Step: 0
Training loss: 2.8945875895959294
Validation loss: 2.7989899134769316

Epoch: 6| Step: 1
Training loss: 3.008412962587882
Validation loss: 2.799814038100265

Epoch: 6| Step: 2
Training loss: 3.59827357327509
Validation loss: 2.798881585953518

Epoch: 6| Step: 3
Training loss: 2.478907681142236
Validation loss: 2.7951600892142285

Epoch: 6| Step: 4
Training loss: 2.977095909083193
Validation loss: 2.7981791917736683

Epoch: 6| Step: 5
Training loss: 3.346955946113514
Validation loss: 2.8000334404414877

Epoch: 6| Step: 6
Training loss: 2.78983465026038
Validation loss: 2.7973658046910392

Epoch: 6| Step: 7
Training loss: 4.03244544941283
Validation loss: 2.7969958394460734

Epoch: 6| Step: 8
Training loss: 2.573368748370099
Validation loss: 2.7972947433175994

Epoch: 6| Step: 9
Training loss: 3.2211611707146424
Validation loss: 2.805055514904532

Epoch: 6| Step: 10
Training loss: 2.8226492967475076
Validation loss: 2.8036444800035456

Epoch: 6| Step: 11
Training loss: 3.292252902850959
Validation loss: 2.8128383802081234

Epoch: 6| Step: 12
Training loss: 3.166446343503875
Validation loss: 2.8074899310804944

Epoch: 6| Step: 13
Training loss: 2.8437706244422944
Validation loss: 2.803058069708434

Epoch: 250| Step: 0
Training loss: 3.297596350846361
Validation loss: 2.8112600922748427

Epoch: 6| Step: 1
Training loss: 2.5373739878367143
Validation loss: 2.810409842085095

Epoch: 6| Step: 2
Training loss: 3.2717234054467452
Validation loss: 2.808905719652343

Epoch: 6| Step: 3
Training loss: 3.3925668807384186
Validation loss: 2.7973772346086534

Epoch: 6| Step: 4
Training loss: 2.665026180002759
Validation loss: 2.7991821696236636

Epoch: 6| Step: 5
Training loss: 3.779896896005709
Validation loss: 2.797098099218197

Epoch: 6| Step: 6
Training loss: 2.3378238270075586
Validation loss: 2.7976799454681096

Epoch: 6| Step: 7
Training loss: 2.3787419805827548
Validation loss: 2.7994809151501165

Epoch: 6| Step: 8
Training loss: 2.305402328066967
Validation loss: 2.7943124760656355

Epoch: 6| Step: 9
Training loss: 3.461334274660207
Validation loss: 2.7960509333212813

Epoch: 6| Step: 10
Training loss: 3.8222386783669458
Validation loss: 2.8000715271871512

Epoch: 6| Step: 11
Training loss: 3.201750371958429
Validation loss: 2.7967289492174543

Epoch: 6| Step: 12
Training loss: 3.0640356145337715
Validation loss: 2.7983898396762408

Epoch: 6| Step: 13
Training loss: 3.5788103138660867
Validation loss: 2.8002115305970845

Epoch: 251| Step: 0
Training loss: 3.0856072744100294
Validation loss: 2.7980411683414355

Epoch: 6| Step: 1
Training loss: 3.4559223702683615
Validation loss: 2.7953279127679225

Epoch: 6| Step: 2
Training loss: 3.4180613826733213
Validation loss: 2.799724726322697

Epoch: 6| Step: 3
Training loss: 3.005676303615254
Validation loss: 2.7955882791149915

Epoch: 6| Step: 4
Training loss: 3.191132663313408
Validation loss: 2.795242741636167

Epoch: 6| Step: 5
Training loss: 3.217272076599703
Validation loss: 2.7954992596811006

Epoch: 6| Step: 6
Training loss: 2.863216633607523
Validation loss: 2.7942740236568486

Epoch: 6| Step: 7
Training loss: 3.056948710262456
Validation loss: 2.7916588327821055

Epoch: 6| Step: 8
Training loss: 3.457719051237749
Validation loss: 2.7911485721723714

Epoch: 6| Step: 9
Training loss: 3.238403465256326
Validation loss: 2.7903961194711635

Epoch: 6| Step: 10
Training loss: 2.4018484706043863
Validation loss: 2.7905659171463406

Epoch: 6| Step: 11
Training loss: 2.4340881531235703
Validation loss: 2.790706898087252

Epoch: 6| Step: 12
Training loss: 3.6650259219472
Validation loss: 2.798624043263575

Epoch: 6| Step: 13
Training loss: 2.423051708216
Validation loss: 2.793208779174286

Epoch: 252| Step: 0
Training loss: 3.0236248579303187
Validation loss: 2.7919881198180274

Epoch: 6| Step: 1
Training loss: 2.8533958080915234
Validation loss: 2.792194988366179

Epoch: 6| Step: 2
Training loss: 2.881938357263798
Validation loss: 2.7896055260115467

Epoch: 6| Step: 3
Training loss: 3.772836451710758
Validation loss: 2.7896056142353096

Epoch: 6| Step: 4
Training loss: 2.565667404586384
Validation loss: 2.7893819635479717

Epoch: 6| Step: 5
Training loss: 3.0101651589335785
Validation loss: 2.788969786643113

Epoch: 6| Step: 6
Training loss: 2.9303506736388405
Validation loss: 2.7917295848923396

Epoch: 6| Step: 7
Training loss: 2.544011290531176
Validation loss: 2.790643550145716

Epoch: 6| Step: 8
Training loss: 3.38505863741823
Validation loss: 2.788095834963507

Epoch: 6| Step: 9
Training loss: 3.437961339337074
Validation loss: 2.7886167281287517

Epoch: 6| Step: 10
Training loss: 2.6503867568885275
Validation loss: 2.788673828559699

Epoch: 6| Step: 11
Training loss: 2.641033615008152
Validation loss: 2.7890089933050026

Epoch: 6| Step: 12
Training loss: 3.3892645149997835
Validation loss: 2.794050689766664

Epoch: 6| Step: 13
Training loss: 4.447416159754659
Validation loss: 2.7903424536794987

Epoch: 253| Step: 0
Training loss: 2.583426186728425
Validation loss: 2.7946173150684657

Epoch: 6| Step: 1
Training loss: 2.8190337687428904
Validation loss: 2.8031504945236634

Epoch: 6| Step: 2
Training loss: 2.7614284940182108
Validation loss: 2.8040965573970498

Epoch: 6| Step: 3
Training loss: 2.739268082924151
Validation loss: 2.8080310405303

Epoch: 6| Step: 4
Training loss: 3.167690278971606
Validation loss: 2.787760661588333

Epoch: 6| Step: 5
Training loss: 3.7517458348597135
Validation loss: 2.795138769485864

Epoch: 6| Step: 6
Training loss: 3.550761106326938
Validation loss: 2.790774115627585

Epoch: 6| Step: 7
Training loss: 2.5761193999642784
Validation loss: 2.7941050275243775

Epoch: 6| Step: 8
Training loss: 3.5299166972675766
Validation loss: 2.7962584873308862

Epoch: 6| Step: 9
Training loss: 2.8506446510847003
Validation loss: 2.7957972497920593

Epoch: 6| Step: 10
Training loss: 3.5202359627616593
Validation loss: 2.7985858241447183

Epoch: 6| Step: 11
Training loss: 3.0672545602067944
Validation loss: 2.801990067564133

Epoch: 6| Step: 12
Training loss: 3.0892764027563078
Validation loss: 2.797796901661511

Epoch: 6| Step: 13
Training loss: 3.376454499091619
Validation loss: 2.7971757635533723

Epoch: 254| Step: 0
Training loss: 3.2905035418549486
Validation loss: 2.7959535709862005

Epoch: 6| Step: 1
Training loss: 2.0915955803736006
Validation loss: 2.796579878514232

Epoch: 6| Step: 2
Training loss: 3.5450512738951883
Validation loss: 2.794583272023311

Epoch: 6| Step: 3
Training loss: 2.859612293507154
Validation loss: 2.7939295825517676

Epoch: 6| Step: 4
Training loss: 3.0856704789538854
Validation loss: 2.7940098306955354

Epoch: 6| Step: 5
Training loss: 3.714916914451037
Validation loss: 2.794946362702084

Epoch: 6| Step: 6
Training loss: 3.2347784850324763
Validation loss: 2.794015557112327

Epoch: 6| Step: 7
Training loss: 3.4207004987517755
Validation loss: 2.7938338658851336

Epoch: 6| Step: 8
Training loss: 2.289339432873577
Validation loss: 2.7899041970915723

Epoch: 6| Step: 9
Training loss: 3.5118425833283196
Validation loss: 2.793851178316843

Epoch: 6| Step: 10
Training loss: 3.056975227542592
Validation loss: 2.7951434590145974

Epoch: 6| Step: 11
Training loss: 3.41816879994922
Validation loss: 2.793779680684864

Epoch: 6| Step: 12
Training loss: 2.614557841101966
Validation loss: 2.792608096553829

Epoch: 6| Step: 13
Training loss: 2.855380076480984
Validation loss: 2.7901406933347825

Epoch: 255| Step: 0
Training loss: 3.0130357447952822
Validation loss: 2.7936142859051207

Epoch: 6| Step: 1
Training loss: 3.195699281297346
Validation loss: 2.7922018257856704

Epoch: 6| Step: 2
Training loss: 3.05263690463396
Validation loss: 2.7898765344139855

Epoch: 6| Step: 3
Training loss: 3.4779080305262284
Validation loss: 2.791606914068743

Epoch: 6| Step: 4
Training loss: 2.768643127858789
Validation loss: 2.7898466476811463

Epoch: 6| Step: 5
Training loss: 2.9101849240932154
Validation loss: 2.791728715263679

Epoch: 6| Step: 6
Training loss: 3.2779879385893276
Validation loss: 2.794416510152048

Epoch: 6| Step: 7
Training loss: 3.0090979269313096
Validation loss: 2.793540599913222

Epoch: 6| Step: 8
Training loss: 3.816745333020503
Validation loss: 2.789439939795061

Epoch: 6| Step: 9
Training loss: 2.9746042453173103
Validation loss: 2.8000765783411996

Epoch: 6| Step: 10
Training loss: 2.6980420430826233
Validation loss: 2.796870580108188

Epoch: 6| Step: 11
Training loss: 3.3884139344823327
Validation loss: 2.794964989062006

Epoch: 6| Step: 12
Training loss: 2.6339035716498347
Validation loss: 2.7966876975234842

Epoch: 6| Step: 13
Training loss: 2.8814760330477016
Validation loss: 2.7935815521101652

Epoch: 256| Step: 0
Training loss: 2.7793168625478146
Validation loss: 2.811442385295171

Epoch: 6| Step: 1
Training loss: 4.109362932194733
Validation loss: 2.8263881700448032

Epoch: 6| Step: 2
Training loss: 2.858602450707584
Validation loss: 2.8685313390495137

Epoch: 6| Step: 3
Training loss: 4.041566172395856
Validation loss: 2.885772558446368

Epoch: 6| Step: 4
Training loss: 3.3949700566854806
Validation loss: 2.8698458400228843

Epoch: 6| Step: 5
Training loss: 2.7259721964078025
Validation loss: 2.815475601614611

Epoch: 6| Step: 6
Training loss: 2.8812943262757638
Validation loss: 2.8037212936818103

Epoch: 6| Step: 7
Training loss: 3.1568448856347073
Validation loss: 2.7929468729023026

Epoch: 6| Step: 8
Training loss: 2.9867517084832214
Validation loss: 2.7961653529061947

Epoch: 6| Step: 9
Training loss: 3.129662202151017
Validation loss: 2.790611648725144

Epoch: 6| Step: 10
Training loss: 2.164030770299879
Validation loss: 2.7951894477136214

Epoch: 6| Step: 11
Training loss: 2.6456468671638023
Validation loss: 2.786132529095938

Epoch: 6| Step: 12
Training loss: 2.9795941310710568
Validation loss: 2.7872961806255727

Epoch: 6| Step: 13
Training loss: 3.1244854312678556
Validation loss: 2.785178580406954

Epoch: 257| Step: 0
Training loss: 2.4673847334664116
Validation loss: 2.7857829530810916

Epoch: 6| Step: 1
Training loss: 2.7992975409680683
Validation loss: 2.7855848024005487

Epoch: 6| Step: 2
Training loss: 3.6077767668978726
Validation loss: 2.784159710001052

Epoch: 6| Step: 3
Training loss: 2.955486019849424
Validation loss: 2.7858878007681533

Epoch: 6| Step: 4
Training loss: 2.6875855188292164
Validation loss: 2.786428812303973

Epoch: 6| Step: 5
Training loss: 1.9752735865905573
Validation loss: 2.785296056937861

Epoch: 6| Step: 6
Training loss: 3.9292963944368555
Validation loss: 2.784826320844809

Epoch: 6| Step: 7
Training loss: 3.324686916210354
Validation loss: 2.7917426283714493

Epoch: 6| Step: 8
Training loss: 3.7206997928954895
Validation loss: 2.7885084940834353

Epoch: 6| Step: 9
Training loss: 2.7926638136638395
Validation loss: 2.788169494748028

Epoch: 6| Step: 10
Training loss: 3.2182625707047308
Validation loss: 2.7857222530847996

Epoch: 6| Step: 11
Training loss: 3.467172074767118
Validation loss: 2.782508647335394

Epoch: 6| Step: 12
Training loss: 3.1591786309407044
Validation loss: 2.780821600054468

Epoch: 6| Step: 13
Training loss: 2.267684842012684
Validation loss: 2.785345684591492

Epoch: 258| Step: 0
Training loss: 2.3014021911523144
Validation loss: 2.7834275208422676

Epoch: 6| Step: 1
Training loss: 3.294352791511772
Validation loss: 2.7792400901725713

Epoch: 6| Step: 2
Training loss: 3.0335770945714393
Validation loss: 2.7839026084533116

Epoch: 6| Step: 3
Training loss: 3.1707263990325583
Validation loss: 2.7822547315435195

Epoch: 6| Step: 4
Training loss: 2.0682321136486914
Validation loss: 2.782507245053308

Epoch: 6| Step: 5
Training loss: 3.0715953680226824
Validation loss: 2.7866837507046993

Epoch: 6| Step: 6
Training loss: 3.378454912504412
Validation loss: 2.7934492374131072

Epoch: 6| Step: 7
Training loss: 2.8283231044113006
Validation loss: 2.780591237095605

Epoch: 6| Step: 8
Training loss: 2.969015330453971
Validation loss: 2.7783817924241268

Epoch: 6| Step: 9
Training loss: 3.7481171013483454
Validation loss: 2.7799845129277956

Epoch: 6| Step: 10
Training loss: 3.11083582008304
Validation loss: 2.7803734668654623

Epoch: 6| Step: 11
Training loss: 3.5477500877915293
Validation loss: 2.7863497259307266

Epoch: 6| Step: 12
Training loss: 3.0201694855278367
Validation loss: 2.793145757817718

Epoch: 6| Step: 13
Training loss: 3.6192676338682674
Validation loss: 2.7939961490904497

Epoch: 259| Step: 0
Training loss: 3.233103626651788
Validation loss: 2.7854893723670737

Epoch: 6| Step: 1
Training loss: 2.9540857437592996
Validation loss: 2.7855650991136742

Epoch: 6| Step: 2
Training loss: 3.4254052750766513
Validation loss: 2.7878802767354887

Epoch: 6| Step: 3
Training loss: 3.1729086709041794
Validation loss: 2.7849965225398026

Epoch: 6| Step: 4
Training loss: 3.1443071178857376
Validation loss: 2.7765653764558165

Epoch: 6| Step: 5
Training loss: 3.0274680229029185
Validation loss: 2.7741613658656172

Epoch: 6| Step: 6
Training loss: 3.2673355806015163
Validation loss: 2.778520762913701

Epoch: 6| Step: 7
Training loss: 2.9829918017682355
Validation loss: 2.7793811041671326

Epoch: 6| Step: 8
Training loss: 2.451388576700865
Validation loss: 2.7808615954952076

Epoch: 6| Step: 9
Training loss: 3.770991130639376
Validation loss: 2.78152788891015

Epoch: 6| Step: 10
Training loss: 2.8204282277210724
Validation loss: 2.781732779773456

Epoch: 6| Step: 11
Training loss: 2.770835321946733
Validation loss: 2.780841596002954

Epoch: 6| Step: 12
Training loss: 2.4928916008277984
Validation loss: 2.7805231427426236

Epoch: 6| Step: 13
Training loss: 3.902628325967895
Validation loss: 2.77966621325893

Epoch: 260| Step: 0
Training loss: 3.507969910078285
Validation loss: 2.779569580234564

Epoch: 6| Step: 1
Training loss: 2.045534932839942
Validation loss: 2.7815840003127743

Epoch: 6| Step: 2
Training loss: 2.8865471196546952
Validation loss: 2.7811644465971646

Epoch: 6| Step: 3
Training loss: 2.780795456679115
Validation loss: 2.778814948854257

Epoch: 6| Step: 4
Training loss: 3.357380119450208
Validation loss: 2.777667110521961

Epoch: 6| Step: 5
Training loss: 3.723867021343722
Validation loss: 2.778452085427368

Epoch: 6| Step: 6
Training loss: 3.0951658149635763
Validation loss: 2.777158230084987

Epoch: 6| Step: 7
Training loss: 2.9052581735418355
Validation loss: 2.7789628276620078

Epoch: 6| Step: 8
Training loss: 3.2246040515174106
Validation loss: 2.7770991075351446

Epoch: 6| Step: 9
Training loss: 3.3284287291717365
Validation loss: 2.7786077835136953

Epoch: 6| Step: 10
Training loss: 2.6191002076719303
Validation loss: 2.789874325357616

Epoch: 6| Step: 11
Training loss: 3.147410184928616
Validation loss: 2.783875642189445

Epoch: 6| Step: 12
Training loss: 3.072044757487168
Validation loss: 2.7925544099268667

Epoch: 6| Step: 13
Training loss: 3.4431751913836117
Validation loss: 2.7900288282770633

Epoch: 261| Step: 0
Training loss: 3.902693693643693
Validation loss: 2.780442838202299

Epoch: 6| Step: 1
Training loss: 3.371180881333419
Validation loss: 2.7713847648265575

Epoch: 6| Step: 2
Training loss: 2.836937762110559
Validation loss: 2.7782762637693295

Epoch: 6| Step: 3
Training loss: 3.0350139098500684
Validation loss: 2.7765945899451445

Epoch: 6| Step: 4
Training loss: 3.2022630974058526
Validation loss: 2.782039360253444

Epoch: 6| Step: 5
Training loss: 2.691184246502013
Validation loss: 2.790515442503626

Epoch: 6| Step: 6
Training loss: 2.6142604572794337
Validation loss: 2.7862421178247354

Epoch: 6| Step: 7
Training loss: 3.5701727975437394
Validation loss: 2.786198219178066

Epoch: 6| Step: 8
Training loss: 2.8642979335218497
Validation loss: 2.7840212797481536

Epoch: 6| Step: 9
Training loss: 2.8106203367853277
Validation loss: 2.7853385772301493

Epoch: 6| Step: 10
Training loss: 2.705713168633277
Validation loss: 2.7805881134364223

Epoch: 6| Step: 11
Training loss: 3.0883992480184834
Validation loss: 2.7809835713995583

Epoch: 6| Step: 12
Training loss: 3.1184070467396126
Validation loss: 2.780262580883033

Epoch: 6| Step: 13
Training loss: 3.4932835030338376
Validation loss: 2.7794448042616002

Epoch: 262| Step: 0
Training loss: 2.642808902697885
Validation loss: 2.779659404952861

Epoch: 6| Step: 1
Training loss: 2.4300895922435797
Validation loss: 2.7771975896481713

Epoch: 6| Step: 2
Training loss: 3.0144110098943484
Validation loss: 2.776741900099236

Epoch: 6| Step: 3
Training loss: 3.1014702540595818
Validation loss: 2.7759067153443193

Epoch: 6| Step: 4
Training loss: 2.818678702321818
Validation loss: 2.7771241179507933

Epoch: 6| Step: 5
Training loss: 3.211669244479808
Validation loss: 2.7771200838791286

Epoch: 6| Step: 6
Training loss: 3.0230786803086063
Validation loss: 2.780710529115989

Epoch: 6| Step: 7
Training loss: 3.2848814714435446
Validation loss: 2.781259042435506

Epoch: 6| Step: 8
Training loss: 3.4123793584157944
Validation loss: 2.7952694670900535

Epoch: 6| Step: 9
Training loss: 3.498275195603863
Validation loss: 2.7981010477109245

Epoch: 6| Step: 10
Training loss: 3.7992285196287354
Validation loss: 2.8003439587985044

Epoch: 6| Step: 11
Training loss: 2.8257016078703696
Validation loss: 2.798627741298841

Epoch: 6| Step: 12
Training loss: 2.8633322093222753
Validation loss: 2.7976152525805396

Epoch: 6| Step: 13
Training loss: 3.081074342498718
Validation loss: 2.7974668064479666

Epoch: 263| Step: 0
Training loss: 2.9778742265343605
Validation loss: 2.786341715777785

Epoch: 6| Step: 1
Training loss: 3.016517309492322
Validation loss: 2.7805924006300944

Epoch: 6| Step: 2
Training loss: 3.208314144192733
Validation loss: 2.7796749970743093

Epoch: 6| Step: 3
Training loss: 3.2314860392379154
Validation loss: 2.7788361013706564

Epoch: 6| Step: 4
Training loss: 3.562935384279551
Validation loss: 2.775450918228527

Epoch: 6| Step: 5
Training loss: 3.2322483903596306
Validation loss: 2.7789987567019323

Epoch: 6| Step: 6
Training loss: 3.4762951694531887
Validation loss: 2.774223352874545

Epoch: 6| Step: 7
Training loss: 2.97432081660139
Validation loss: 2.7735868033362197

Epoch: 6| Step: 8
Training loss: 2.556991424856476
Validation loss: 2.773205380140947

Epoch: 6| Step: 9
Training loss: 2.8845651152705565
Validation loss: 2.772569412424353

Epoch: 6| Step: 10
Training loss: 3.632713004769908
Validation loss: 2.770873501936995

Epoch: 6| Step: 11
Training loss: 2.7151738466978035
Validation loss: 2.771663486516207

Epoch: 6| Step: 12
Training loss: 3.069789075035932
Validation loss: 2.774579727739701

Epoch: 6| Step: 13
Training loss: 1.8524590747961358
Validation loss: 2.771613743368239

Epoch: 264| Step: 0
Training loss: 3.1549284028213243
Validation loss: 2.7722308669769036

Epoch: 6| Step: 1
Training loss: 3.329224454133938
Validation loss: 2.7749886098737133

Epoch: 6| Step: 2
Training loss: 2.888641831845968
Validation loss: 2.774694191946992

Epoch: 6| Step: 3
Training loss: 3.358269514009134
Validation loss: 2.771267570007597

Epoch: 6| Step: 4
Training loss: 2.814273529358309
Validation loss: 2.774313590945544

Epoch: 6| Step: 5
Training loss: 3.1371972656098004
Validation loss: 2.778664720577977

Epoch: 6| Step: 6
Training loss: 3.0108669872569287
Validation loss: 2.7896300089177593

Epoch: 6| Step: 7
Training loss: 3.436638741538562
Validation loss: 2.7923974182892093

Epoch: 6| Step: 8
Training loss: 3.2111581694056164
Validation loss: 2.8220993506804386

Epoch: 6| Step: 9
Training loss: 2.713276055064941
Validation loss: 2.8272801353484462

Epoch: 6| Step: 10
Training loss: 2.700206526169075
Validation loss: 2.85757841452278

Epoch: 6| Step: 11
Training loss: 3.4061461266594577
Validation loss: 2.865912338824916

Epoch: 6| Step: 12
Training loss: 3.270716444384978
Validation loss: 2.8251407052109183

Epoch: 6| Step: 13
Training loss: 2.442742993421367
Validation loss: 2.789400208889812

Epoch: 265| Step: 0
Training loss: 3.53171583495779
Validation loss: 2.772586873353231

Epoch: 6| Step: 1
Training loss: 2.725574478349478
Validation loss: 2.7717807108406287

Epoch: 6| Step: 2
Training loss: 2.7603891239351657
Validation loss: 2.768450395527757

Epoch: 6| Step: 3
Training loss: 2.5914148136764497
Validation loss: 2.7712781954413184

Epoch: 6| Step: 4
Training loss: 3.348597355318623
Validation loss: 2.768803936677329

Epoch: 6| Step: 5
Training loss: 3.08842703921237
Validation loss: 2.7722812052192434

Epoch: 6| Step: 6
Training loss: 3.2781816941296227
Validation loss: 2.77235562918308

Epoch: 6| Step: 7
Training loss: 2.8977976295783225
Validation loss: 2.7737602659613687

Epoch: 6| Step: 8
Training loss: 3.1499725461702006
Validation loss: 2.7747818610279285

Epoch: 6| Step: 9
Training loss: 3.3882312675098416
Validation loss: 2.7793461015374885

Epoch: 6| Step: 10
Training loss: 3.4836188210002046
Validation loss: 2.77252619328605

Epoch: 6| Step: 11
Training loss: 2.59058481146145
Validation loss: 2.771111072798245

Epoch: 6| Step: 12
Training loss: 2.905483021589546
Validation loss: 2.7701295579866465

Epoch: 6| Step: 13
Training loss: 3.632667062780963
Validation loss: 2.770006946796233

Epoch: 266| Step: 0
Training loss: 3.3192024798946904
Validation loss: 2.7695692757974433

Epoch: 6| Step: 1
Training loss: 2.1953780955224556
Validation loss: 2.768398250846403

Epoch: 6| Step: 2
Training loss: 3.1287279399683934
Validation loss: 2.7637608528489026

Epoch: 6| Step: 3
Training loss: 3.45223669994134
Validation loss: 2.766726978379491

Epoch: 6| Step: 4
Training loss: 3.6175246936348087
Validation loss: 2.761852732429022

Epoch: 6| Step: 5
Training loss: 3.0740896971006415
Validation loss: 2.761030467341076

Epoch: 6| Step: 6
Training loss: 2.566829280738694
Validation loss: 2.7689167684790896

Epoch: 6| Step: 7
Training loss: 2.3441556452349563
Validation loss: 2.7654584210280877

Epoch: 6| Step: 8
Training loss: 2.4868048535252223
Validation loss: 2.766145023589243

Epoch: 6| Step: 9
Training loss: 3.3123079640126933
Validation loss: 2.7652253857040425

Epoch: 6| Step: 10
Training loss: 3.085717611084009
Validation loss: 2.7691052531810634

Epoch: 6| Step: 11
Training loss: 3.2638213364845354
Validation loss: 2.766585943030568

Epoch: 6| Step: 12
Training loss: 3.4495433339279105
Validation loss: 2.76892452211715

Epoch: 6| Step: 13
Training loss: 3.640139436880692
Validation loss: 2.777991441145549

Epoch: 267| Step: 0
Training loss: 3.1255791699627573
Validation loss: 2.791346214928663

Epoch: 6| Step: 1
Training loss: 2.8286626315310244
Validation loss: 2.7941458585958117

Epoch: 6| Step: 2
Training loss: 3.2139287599028186
Validation loss: 2.8003197105473965

Epoch: 6| Step: 3
Training loss: 3.4208642869138233
Validation loss: 2.7827575476600512

Epoch: 6| Step: 4
Training loss: 2.6597712794185107
Validation loss: 2.762702940231092

Epoch: 6| Step: 5
Training loss: 2.99629698142409
Validation loss: 2.758604784419267

Epoch: 6| Step: 6
Training loss: 3.1154376403121646
Validation loss: 2.7646748031114923

Epoch: 6| Step: 7
Training loss: 3.1403351455465676
Validation loss: 2.7660475567350518

Epoch: 6| Step: 8
Training loss: 2.9312541384149227
Validation loss: 2.764584457214613

Epoch: 6| Step: 9
Training loss: 3.388187076947788
Validation loss: 2.763584757009043

Epoch: 6| Step: 10
Training loss: 3.32260218041953
Validation loss: 2.761339704681314

Epoch: 6| Step: 11
Training loss: 3.2026444237429232
Validation loss: 2.7599649132027175

Epoch: 6| Step: 12
Training loss: 2.7678945248799844
Validation loss: 2.7599484090425426

Epoch: 6| Step: 13
Training loss: 2.8063960489784625
Validation loss: 2.7600952134629964

Epoch: 268| Step: 0
Training loss: 3.2617805886260043
Validation loss: 2.7598580700529602

Epoch: 6| Step: 1
Training loss: 2.8934777282100272
Validation loss: 2.759300433146518

Epoch: 6| Step: 2
Training loss: 1.939288083340734
Validation loss: 2.7612127693509665

Epoch: 6| Step: 3
Training loss: 3.4952240101812726
Validation loss: 2.757475726342899

Epoch: 6| Step: 4
Training loss: 3.5654314261071494
Validation loss: 2.7647554395400284

Epoch: 6| Step: 5
Training loss: 2.877448987732355
Validation loss: 2.761593085323873

Epoch: 6| Step: 6
Training loss: 2.6925684131938046
Validation loss: 2.766419825035935

Epoch: 6| Step: 7
Training loss: 2.5209918852406523
Validation loss: 2.7689561720490086

Epoch: 6| Step: 8
Training loss: 3.084709753791549
Validation loss: 2.7662725194044033

Epoch: 6| Step: 9
Training loss: 3.4918474889531472
Validation loss: 2.76908491881147

Epoch: 6| Step: 10
Training loss: 2.978483286197394
Validation loss: 2.779229828175119

Epoch: 6| Step: 11
Training loss: 3.0940747331447356
Validation loss: 2.772362536800374

Epoch: 6| Step: 12
Training loss: 3.4539777298360113
Validation loss: 2.7683075847328285

Epoch: 6| Step: 13
Training loss: 3.3615437449000947
Validation loss: 2.7693520052071627

Epoch: 269| Step: 0
Training loss: 3.463458449814831
Validation loss: 2.784541859783162

Epoch: 6| Step: 1
Training loss: 2.6411955628966295
Validation loss: 2.7691731580061267

Epoch: 6| Step: 2
Training loss: 2.9128192775726456
Validation loss: 2.765841278690699

Epoch: 6| Step: 3
Training loss: 3.1997296457526225
Validation loss: 2.7643723498818296

Epoch: 6| Step: 4
Training loss: 2.711568885295402
Validation loss: 2.7590188392303086

Epoch: 6| Step: 5
Training loss: 3.7186224138187485
Validation loss: 2.76167699855936

Epoch: 6| Step: 6
Training loss: 3.203718177021175
Validation loss: 2.760267584674229

Epoch: 6| Step: 7
Training loss: 3.363223404337046
Validation loss: 2.7575872134554578

Epoch: 6| Step: 8
Training loss: 2.4667180064589207
Validation loss: 2.763257556254163

Epoch: 6| Step: 9
Training loss: 2.867113159213779
Validation loss: 2.756370202839923

Epoch: 6| Step: 10
Training loss: 3.1387615084237757
Validation loss: 2.760678036823114

Epoch: 6| Step: 11
Training loss: 3.017573068361459
Validation loss: 2.7569958886336643

Epoch: 6| Step: 12
Training loss: 3.036396023790944
Validation loss: 2.757995228507855

Epoch: 6| Step: 13
Training loss: 3.0663695509348496
Validation loss: 2.7623613419908817

Epoch: 270| Step: 0
Training loss: 3.473776122904726
Validation loss: 2.7606289630840934

Epoch: 6| Step: 1
Training loss: 3.4540656694311234
Validation loss: 2.75721611521528

Epoch: 6| Step: 2
Training loss: 2.698977071760099
Validation loss: 2.764869957197313

Epoch: 6| Step: 3
Training loss: 3.150363834501324
Validation loss: 2.770363083031469

Epoch: 6| Step: 4
Training loss: 2.87115237636785
Validation loss: 2.7595023394875935

Epoch: 6| Step: 5
Training loss: 3.153677921567673
Validation loss: 2.771498409160753

Epoch: 6| Step: 6
Training loss: 2.536987395727764
Validation loss: 2.778741339093137

Epoch: 6| Step: 7
Training loss: 2.6482200870904196
Validation loss: 2.780208662315356

Epoch: 6| Step: 8
Training loss: 3.048259713890074
Validation loss: 2.7696760460762384

Epoch: 6| Step: 9
Training loss: 2.8640765117462763
Validation loss: 2.7758670290132614

Epoch: 6| Step: 10
Training loss: 3.2866312133651405
Validation loss: 2.7741543278064444

Epoch: 6| Step: 11
Training loss: 3.465140999791711
Validation loss: 2.764763321218831

Epoch: 6| Step: 12
Training loss: 2.892620985291848
Validation loss: 2.7609175128834154

Epoch: 6| Step: 13
Training loss: 3.4032936916103758
Validation loss: 2.7585479946372082

Epoch: 271| Step: 0
Training loss: 2.891017742797917
Validation loss: 2.7540196660935443

Epoch: 6| Step: 1
Training loss: 3.4799357647283866
Validation loss: 2.7546851761371616

Epoch: 6| Step: 2
Training loss: 2.7075226573048905
Validation loss: 2.7519928515726684

Epoch: 6| Step: 3
Training loss: 3.537038329499434
Validation loss: 2.7519131081309576

Epoch: 6| Step: 4
Training loss: 2.4274792218718635
Validation loss: 2.758353975126649

Epoch: 6| Step: 5
Training loss: 3.1289638556846042
Validation loss: 2.7556225508552927

Epoch: 6| Step: 6
Training loss: 3.354871419156732
Validation loss: 2.7530102582122167

Epoch: 6| Step: 7
Training loss: 2.882524015884072
Validation loss: 2.754674754727707

Epoch: 6| Step: 8
Training loss: 3.1833221881398397
Validation loss: 2.7553897982993445

Epoch: 6| Step: 9
Training loss: 3.545458540213942
Validation loss: 2.7540104020367804

Epoch: 6| Step: 10
Training loss: 2.873147450546701
Validation loss: 2.7519073322986567

Epoch: 6| Step: 11
Training loss: 3.1395626264031464
Validation loss: 2.7509823934048048

Epoch: 6| Step: 12
Training loss: 2.6947889621181846
Validation loss: 2.7555237572527047

Epoch: 6| Step: 13
Training loss: 2.8908813362904913
Validation loss: 2.75096969530539

Epoch: 272| Step: 0
Training loss: 2.166293209853442
Validation loss: 2.754724196045578

Epoch: 6| Step: 1
Training loss: 3.088330849737276
Validation loss: 2.7520563039063792

Epoch: 6| Step: 2
Training loss: 3.082217212090167
Validation loss: 2.7564601734443452

Epoch: 6| Step: 3
Training loss: 3.383917436462786
Validation loss: 2.751942590771227

Epoch: 6| Step: 4
Training loss: 2.7110646682506507
Validation loss: 2.753981422801094

Epoch: 6| Step: 5
Training loss: 2.4440366689050794
Validation loss: 2.757474765956843

Epoch: 6| Step: 6
Training loss: 2.5851718656564575
Validation loss: 2.759219173668993

Epoch: 6| Step: 7
Training loss: 3.8260776572434874
Validation loss: 2.7623304058225506

Epoch: 6| Step: 8
Training loss: 3.89361567625296
Validation loss: 2.764126768975184

Epoch: 6| Step: 9
Training loss: 2.9683162974733173
Validation loss: 2.7663885265006085

Epoch: 6| Step: 10
Training loss: 3.5853364062520123
Validation loss: 2.7554563534032877

Epoch: 6| Step: 11
Training loss: 3.164012315140206
Validation loss: 2.752814654499487

Epoch: 6| Step: 12
Training loss: 2.8397084116005713
Validation loss: 2.752432386033126

Epoch: 6| Step: 13
Training loss: 2.2739040250026155
Validation loss: 2.7515624549428144

Epoch: 273| Step: 0
Training loss: 3.0127689099093877
Validation loss: 2.754847859669091

Epoch: 6| Step: 1
Training loss: 3.442354831446563
Validation loss: 2.7526432620202894

Epoch: 6| Step: 2
Training loss: 2.6867988913902505
Validation loss: 2.7485832534401924

Epoch: 6| Step: 3
Training loss: 2.801973437644203
Validation loss: 2.7507608522720046

Epoch: 6| Step: 4
Training loss: 3.295001035235739
Validation loss: 2.749001731051738

Epoch: 6| Step: 5
Training loss: 2.685249273283203
Validation loss: 2.7528562348965115

Epoch: 6| Step: 6
Training loss: 3.4817500469278704
Validation loss: 2.7496727499800437

Epoch: 6| Step: 7
Training loss: 3.154355226337214
Validation loss: 2.748641445750546

Epoch: 6| Step: 8
Training loss: 3.3893129121698933
Validation loss: 2.752872506854294

Epoch: 6| Step: 9
Training loss: 3.337307436527735
Validation loss: 2.752285100230568

Epoch: 6| Step: 10
Training loss: 2.8979105097588507
Validation loss: 2.757209922785999

Epoch: 6| Step: 11
Training loss: 2.917850435812549
Validation loss: 2.758528719041388

Epoch: 6| Step: 12
Training loss: 2.9707130768036794
Validation loss: 2.7585146588585987

Epoch: 6| Step: 13
Training loss: 2.2582834142068697
Validation loss: 2.761339881078193

Epoch: 274| Step: 0
Training loss: 2.5573335062762146
Validation loss: 2.7602829166885274

Epoch: 6| Step: 1
Training loss: 2.856275201932546
Validation loss: 2.7552447920358327

Epoch: 6| Step: 2
Training loss: 3.2888835939874497
Validation loss: 2.7690250859792553

Epoch: 6| Step: 3
Training loss: 3.56485817475988
Validation loss: 2.7534264783034526

Epoch: 6| Step: 4
Training loss: 3.635069312231078
Validation loss: 2.745153498815374

Epoch: 6| Step: 5
Training loss: 3.0261278430182093
Validation loss: 2.7492727416188507

Epoch: 6| Step: 6
Training loss: 3.3730853265758527
Validation loss: 2.7501689937271006

Epoch: 6| Step: 7
Training loss: 3.1186376272379603
Validation loss: 2.7519372588971387

Epoch: 6| Step: 8
Training loss: 3.199555282685081
Validation loss: 2.7460036638095615

Epoch: 6| Step: 9
Training loss: 2.0117544226585364
Validation loss: 2.7523595661074736

Epoch: 6| Step: 10
Training loss: 2.6658980235337406
Validation loss: 2.745926316683825

Epoch: 6| Step: 11
Training loss: 2.7237595630913787
Validation loss: 2.74862152800383

Epoch: 6| Step: 12
Training loss: 3.165741802143206
Validation loss: 2.7440100781751853

Epoch: 6| Step: 13
Training loss: 3.539531617725144
Validation loss: 2.746700560745132

Epoch: 275| Step: 0
Training loss: 3.212299587069201
Validation loss: 2.7474461365661917

Epoch: 6| Step: 1
Training loss: 3.066896047168169
Validation loss: 2.7480902962792224

Epoch: 6| Step: 2
Training loss: 3.601738848888923
Validation loss: 2.7483038029409137

Epoch: 6| Step: 3
Training loss: 2.7205870987688128
Validation loss: 2.745115315981506

Epoch: 6| Step: 4
Training loss: 3.0126438723829674
Validation loss: 2.7501748459197555

Epoch: 6| Step: 5
Training loss: 2.4779980467018143
Validation loss: 2.7496216458708984

Epoch: 6| Step: 6
Training loss: 3.0166639998900147
Validation loss: 2.7498859389321026

Epoch: 6| Step: 7
Training loss: 3.346194790657945
Validation loss: 2.7485656316280354

Epoch: 6| Step: 8
Training loss: 2.596559404827444
Validation loss: 2.7497499507011867

Epoch: 6| Step: 9
Training loss: 3.0881142194506093
Validation loss: 2.7510258065580775

Epoch: 6| Step: 10
Training loss: 2.811190151800493
Validation loss: 2.752110127553525

Epoch: 6| Step: 11
Training loss: 3.0373122168999496
Validation loss: 2.7471444386667194

Epoch: 6| Step: 12
Training loss: 3.122414702081923
Validation loss: 2.747385541349091

Epoch: 6| Step: 13
Training loss: 3.9225454783188916
Validation loss: 2.7493721104398285

Epoch: 276| Step: 0
Training loss: 3.1135624431905145
Validation loss: 2.7479137755719942

Epoch: 6| Step: 1
Training loss: 3.0310483255841314
Validation loss: 2.749355055952197

Epoch: 6| Step: 2
Training loss: 2.893315563176633
Validation loss: 2.7423107567210803

Epoch: 6| Step: 3
Training loss: 2.8616762333574686
Validation loss: 2.740912845482025

Epoch: 6| Step: 4
Training loss: 3.707577889177959
Validation loss: 2.7464915909728953

Epoch: 6| Step: 5
Training loss: 3.3093490008808906
Validation loss: 2.750837453967245

Epoch: 6| Step: 6
Training loss: 3.1902672218639325
Validation loss: 2.743510248822284

Epoch: 6| Step: 7
Training loss: 3.0536486329888843
Validation loss: 2.7451987644811395

Epoch: 6| Step: 8
Training loss: 3.2312351779856043
Validation loss: 2.7470630818464215

Epoch: 6| Step: 9
Training loss: 2.7013554596868734
Validation loss: 2.745765029789918

Epoch: 6| Step: 10
Training loss: 2.8916845081083093
Validation loss: 2.7481558620902264

Epoch: 6| Step: 11
Training loss: 3.0387285926783485
Validation loss: 2.743754012348105

Epoch: 6| Step: 12
Training loss: 2.653505051422055
Validation loss: 2.7411391872682787

Epoch: 6| Step: 13
Training loss: 3.1789608436709726
Validation loss: 2.7427165811142675

Epoch: 277| Step: 0
Training loss: 3.273937687862857
Validation loss: 2.743959025563103

Epoch: 6| Step: 1
Training loss: 2.6945974977245957
Validation loss: 2.7478551750751237

Epoch: 6| Step: 2
Training loss: 3.176534603238455
Validation loss: 2.7480094245868085

Epoch: 6| Step: 3
Training loss: 3.4163763031431027
Validation loss: 2.7514328453980417

Epoch: 6| Step: 4
Training loss: 3.570451929888229
Validation loss: 2.7454949270164386

Epoch: 6| Step: 5
Training loss: 3.386502620924112
Validation loss: 2.753620417672056

Epoch: 6| Step: 6
Training loss: 2.440861658010327
Validation loss: 2.7525735095256203

Epoch: 6| Step: 7
Training loss: 2.9457288695665875
Validation loss: 2.7562689061302734

Epoch: 6| Step: 8
Training loss: 3.0696118358539963
Validation loss: 2.7619012766899482

Epoch: 6| Step: 9
Training loss: 2.913180711299842
Validation loss: 2.774152145043394

Epoch: 6| Step: 10
Training loss: 3.0704985506408082
Validation loss: 2.7791234452343354

Epoch: 6| Step: 11
Training loss: 3.4042181551964243
Validation loss: 2.7764926387025164

Epoch: 6| Step: 12
Training loss: 2.2942965820345567
Validation loss: 2.768948842077527

Epoch: 6| Step: 13
Training loss: 2.764196080613026
Validation loss: 2.780299750835096

Epoch: 278| Step: 0
Training loss: 3.557669057789926
Validation loss: 2.7628353234804512

Epoch: 6| Step: 1
Training loss: 3.2852177926013093
Validation loss: 2.769318060749846

Epoch: 6| Step: 2
Training loss: 2.6842006569002823
Validation loss: 2.773722236618315

Epoch: 6| Step: 3
Training loss: 2.576733485297645
Validation loss: 2.774070490728439

Epoch: 6| Step: 4
Training loss: 3.5449401686855797
Validation loss: 2.7738099641458116

Epoch: 6| Step: 5
Training loss: 2.6384981156068297
Validation loss: 2.787572997770895

Epoch: 6| Step: 6
Training loss: 3.2226236977522604
Validation loss: 2.7727317835390863

Epoch: 6| Step: 7
Training loss: 2.7816689850752008
Validation loss: 2.7842642017104513

Epoch: 6| Step: 8
Training loss: 3.0295210164498494
Validation loss: 2.7588197614620817

Epoch: 6| Step: 9
Training loss: 3.3302893250016905
Validation loss: 2.749759381078867

Epoch: 6| Step: 10
Training loss: 2.9778012078661895
Validation loss: 2.74039992304837

Epoch: 6| Step: 11
Training loss: 3.3268121986689305
Validation loss: 2.7440999149751684

Epoch: 6| Step: 12
Training loss: 2.8205170702513223
Validation loss: 2.7377571586397016

Epoch: 6| Step: 13
Training loss: 2.800611333866909
Validation loss: 2.734830199995938

Epoch: 279| Step: 0
Training loss: 3.1506922672645272
Validation loss: 2.7435782040605408

Epoch: 6| Step: 1
Training loss: 2.604628946599283
Validation loss: 2.7409856762971936

Epoch: 6| Step: 2
Training loss: 3.0551741814788245
Validation loss: 2.7428575165870908

Epoch: 6| Step: 3
Training loss: 3.016167310268161
Validation loss: 2.7429652453124813

Epoch: 6| Step: 4
Training loss: 3.598898740386382
Validation loss: 2.7426923477533722

Epoch: 6| Step: 5
Training loss: 2.9491872217375183
Validation loss: 2.7447303079712686

Epoch: 6| Step: 6
Training loss: 2.890842738843235
Validation loss: 2.7442489031033293

Epoch: 6| Step: 7
Training loss: 2.8180436494802517
Validation loss: 2.7456466527192767

Epoch: 6| Step: 8
Training loss: 2.904028587032462
Validation loss: 2.7448800744382003

Epoch: 6| Step: 9
Training loss: 2.921140690702091
Validation loss: 2.74479253466563

Epoch: 6| Step: 10
Training loss: 3.1160060393210025
Validation loss: 2.7440950560024038

Epoch: 6| Step: 11
Training loss: 3.2745895361478548
Validation loss: 2.7421325822067444

Epoch: 6| Step: 12
Training loss: 3.37774659471451
Validation loss: 2.737411463634596

Epoch: 6| Step: 13
Training loss: 3.407857393146598
Validation loss: 2.7388322551513946

Epoch: 280| Step: 0
Training loss: 3.33813375677929
Validation loss: 2.7397013317199126

Epoch: 6| Step: 1
Training loss: 2.512863159503982
Validation loss: 2.7375602243927126

Epoch: 6| Step: 2
Training loss: 2.9295900048881793
Validation loss: 2.740429324680091

Epoch: 6| Step: 3
Training loss: 3.49444930118883
Validation loss: 2.7445976445755855

Epoch: 6| Step: 4
Training loss: 2.830486681442045
Validation loss: 2.738689477198561

Epoch: 6| Step: 5
Training loss: 3.6454692259125157
Validation loss: 2.7470336765569496

Epoch: 6| Step: 6
Training loss: 2.8981578105873322
Validation loss: 2.7467743291591025

Epoch: 6| Step: 7
Training loss: 2.7915318774426203
Validation loss: 2.758443712809835

Epoch: 6| Step: 8
Training loss: 2.7137573703154465
Validation loss: 2.7511262591687227

Epoch: 6| Step: 9
Training loss: 2.7468607931453217
Validation loss: 2.776740645395509

Epoch: 6| Step: 10
Training loss: 3.187683848146623
Validation loss: 2.7883419582433935

Epoch: 6| Step: 11
Training loss: 3.295515168687709
Validation loss: 2.7929340048591573

Epoch: 6| Step: 12
Training loss: 2.6969968094175685
Validation loss: 2.7820513571956687

Epoch: 6| Step: 13
Training loss: 3.8745184568407858
Validation loss: 2.777082032232902

Epoch: 281| Step: 0
Training loss: 3.3737047323700127
Validation loss: 2.745973476955471

Epoch: 6| Step: 1
Training loss: 3.7218367644298977
Validation loss: 2.7415893769954645

Epoch: 6| Step: 2
Training loss: 3.3069047996953356
Validation loss: 2.737264504246263

Epoch: 6| Step: 3
Training loss: 1.6487500947456246
Validation loss: 2.7371027528399

Epoch: 6| Step: 4
Training loss: 3.3311089405304113
Validation loss: 2.737319247169411

Epoch: 6| Step: 5
Training loss: 2.864262973326837
Validation loss: 2.737781190349125

Epoch: 6| Step: 6
Training loss: 2.241493888729222
Validation loss: 2.7381235219179576

Epoch: 6| Step: 7
Training loss: 3.4411914771411127
Validation loss: 2.7374433524237576

Epoch: 6| Step: 8
Training loss: 2.2392205469396966
Validation loss: 2.739800768843233

Epoch: 6| Step: 9
Training loss: 3.4039569100634703
Validation loss: 2.738484019869265

Epoch: 6| Step: 10
Training loss: 3.5390715272632525
Validation loss: 2.7349653178132534

Epoch: 6| Step: 11
Training loss: 2.848730902279307
Validation loss: 2.7356353583373783

Epoch: 6| Step: 12
Training loss: 2.9796637451633234
Validation loss: 2.7353700707622233

Epoch: 6| Step: 13
Training loss: 3.1804139903036583
Validation loss: 2.737511337458329

Epoch: 282| Step: 0
Training loss: 3.190372892726039
Validation loss: 2.7338950584164023

Epoch: 6| Step: 1
Training loss: 3.2042776127438226
Validation loss: 2.7323946624366933

Epoch: 6| Step: 2
Training loss: 2.976052708661499
Validation loss: 2.7345305452185737

Epoch: 6| Step: 3
Training loss: 2.937088308501056
Validation loss: 2.7366553791868498

Epoch: 6| Step: 4
Training loss: 2.559031115707597
Validation loss: 2.7347063548810038

Epoch: 6| Step: 5
Training loss: 2.5082862858040618
Validation loss: 2.736522623175048

Epoch: 6| Step: 6
Training loss: 3.4372713879946346
Validation loss: 2.7336420017227283

Epoch: 6| Step: 7
Training loss: 3.4002540381276973
Validation loss: 2.7356103706408677

Epoch: 6| Step: 8
Training loss: 2.8821418623096156
Validation loss: 2.736669008347106

Epoch: 6| Step: 9
Training loss: 3.1062870506978277
Validation loss: 2.7369608850329974

Epoch: 6| Step: 10
Training loss: 3.356441050513733
Validation loss: 2.7382826833563385

Epoch: 6| Step: 11
Training loss: 3.464505184452132
Validation loss: 2.7353798834269143

Epoch: 6| Step: 12
Training loss: 2.7065480339034553
Validation loss: 2.738075189027253

Epoch: 6| Step: 13
Training loss: 2.6280366499448538
Validation loss: 2.738947217394059

Epoch: 283| Step: 0
Training loss: 3.3934848520242387
Validation loss: 2.738628570281525

Epoch: 6| Step: 1
Training loss: 3.0157378971135596
Validation loss: 2.749266602166575

Epoch: 6| Step: 2
Training loss: 3.7302286919651926
Validation loss: 2.745650492136454

Epoch: 6| Step: 3
Training loss: 3.403004070897208
Validation loss: 2.742905158624069

Epoch: 6| Step: 4
Training loss: 2.5475552826368304
Validation loss: 2.737110236468585

Epoch: 6| Step: 5
Training loss: 2.6208667003001485
Validation loss: 2.736642724213307

Epoch: 6| Step: 6
Training loss: 2.484084394240655
Validation loss: 2.73704727406735

Epoch: 6| Step: 7
Training loss: 2.973597534170865
Validation loss: 2.7396428943043816

Epoch: 6| Step: 8
Training loss: 3.1565089355612983
Validation loss: 2.742608582762237

Epoch: 6| Step: 9
Training loss: 3.0511954169292466
Validation loss: 2.7358298982667497

Epoch: 6| Step: 10
Training loss: 3.1845060761403188
Validation loss: 2.7368978339566152

Epoch: 6| Step: 11
Training loss: 3.199619365942465
Validation loss: 2.7403050103815385

Epoch: 6| Step: 12
Training loss: 2.540062903879363
Validation loss: 2.7331265422947757

Epoch: 6| Step: 13
Training loss: 3.238905235701485
Validation loss: 2.734864004448305

Epoch: 284| Step: 0
Training loss: 3.0984259824014533
Validation loss: 2.7402758422368168

Epoch: 6| Step: 1
Training loss: 3.4976501751085003
Validation loss: 2.7407712394338257

Epoch: 6| Step: 2
Training loss: 3.073349709898152
Validation loss: 2.74435787007361

Epoch: 6| Step: 3
Training loss: 2.871960733522487
Validation loss: 2.7484267200749035

Epoch: 6| Step: 4
Training loss: 2.886368540580149
Validation loss: 2.750400832824389

Epoch: 6| Step: 5
Training loss: 3.2982088256384756
Validation loss: 2.759891661770268

Epoch: 6| Step: 6
Training loss: 2.9895905462481496
Validation loss: 2.7424070638896705

Epoch: 6| Step: 7
Training loss: 2.882280833108273
Validation loss: 2.7342723418154224

Epoch: 6| Step: 8
Training loss: 2.603829252636583
Validation loss: 2.7377506693677796

Epoch: 6| Step: 9
Training loss: 2.975447318163113
Validation loss: 2.7392575860149075

Epoch: 6| Step: 10
Training loss: 3.295813656316984
Validation loss: 2.736570243408784

Epoch: 6| Step: 11
Training loss: 2.6884514654715352
Validation loss: 2.731476751451302

Epoch: 6| Step: 12
Training loss: 3.08268469783873
Validation loss: 2.7338868739438893

Epoch: 6| Step: 13
Training loss: 3.5031638150953013
Validation loss: 2.7284080623989877

Epoch: 285| Step: 0
Training loss: 3.5058357089208183
Validation loss: 2.7334881222348453

Epoch: 6| Step: 1
Training loss: 3.0124301886482767
Validation loss: 2.7311655371046135

Epoch: 6| Step: 2
Training loss: 2.8944747445669714
Validation loss: 2.7328095392171394

Epoch: 6| Step: 3
Training loss: 3.227036115786486
Validation loss: 2.730447979077178

Epoch: 6| Step: 4
Training loss: 2.2477213659523594
Validation loss: 2.740500517251027

Epoch: 6| Step: 5
Training loss: 3.0240367522251765
Validation loss: 2.7378421001989115

Epoch: 6| Step: 6
Training loss: 2.5225154739374074
Validation loss: 2.741551101507574

Epoch: 6| Step: 7
Training loss: 3.3224171867986065
Validation loss: 2.7368150512789144

Epoch: 6| Step: 8
Training loss: 3.6358021237589213
Validation loss: 2.736512379920001

Epoch: 6| Step: 9
Training loss: 2.761492988391037
Validation loss: 2.7370212886119853

Epoch: 6| Step: 10
Training loss: 3.4037319290180155
Validation loss: 2.747953651034605

Epoch: 6| Step: 11
Training loss: 2.9072921689145947
Validation loss: 2.731980193721043

Epoch: 6| Step: 12
Training loss: 3.0352809885282928
Validation loss: 2.7400696870684422

Epoch: 6| Step: 13
Training loss: 2.7198277233767274
Validation loss: 2.741665576653205

Epoch: 286| Step: 0
Training loss: 2.813847536881739
Validation loss: 2.7364775062861586

Epoch: 6| Step: 1
Training loss: 3.208582699155017
Validation loss: 2.7402363190831043

Epoch: 6| Step: 2
Training loss: 2.9585416657784243
Validation loss: 2.7352907499616785

Epoch: 6| Step: 3
Training loss: 3.451511886591685
Validation loss: 2.7366098757170088

Epoch: 6| Step: 4
Training loss: 2.9206587764224454
Validation loss: 2.738801416395303

Epoch: 6| Step: 5
Training loss: 2.877923391365695
Validation loss: 2.7353162270042404

Epoch: 6| Step: 6
Training loss: 2.9366093360711423
Validation loss: 2.7320006625677147

Epoch: 6| Step: 7
Training loss: 2.7342485671104604
Validation loss: 2.7311651757198137

Epoch: 6| Step: 8
Training loss: 1.8844444198853314
Validation loss: 2.7327079151476594

Epoch: 6| Step: 9
Training loss: 3.386324216044145
Validation loss: 2.7355709000362785

Epoch: 6| Step: 10
Training loss: 2.8327514574530093
Validation loss: 2.7398419460291614

Epoch: 6| Step: 11
Training loss: 2.9643745704504187
Validation loss: 2.735570852241621

Epoch: 6| Step: 12
Training loss: 3.830772014130202
Validation loss: 2.735829087708506

Epoch: 6| Step: 13
Training loss: 3.741187230739298
Validation loss: 2.7343572397431695

Epoch: 287| Step: 0
Training loss: 3.247787896507887
Validation loss: 2.7277134647028936

Epoch: 6| Step: 1
Training loss: 2.0334311878650997
Validation loss: 2.7330842030523295

Epoch: 6| Step: 2
Training loss: 3.0960291934448225
Validation loss: 2.727982969263134

Epoch: 6| Step: 3
Training loss: 2.6729655577741505
Validation loss: 2.7348578663962146

Epoch: 6| Step: 4
Training loss: 3.4442934358644397
Validation loss: 2.7342638387512914

Epoch: 6| Step: 5
Training loss: 3.1306711236682645
Validation loss: 2.7335385666708096

Epoch: 6| Step: 6
Training loss: 2.5937990850377135
Validation loss: 2.7319801571241507

Epoch: 6| Step: 7
Training loss: 3.13542496351663
Validation loss: 2.7341697247826606

Epoch: 6| Step: 8
Training loss: 3.0059655005327435
Validation loss: 2.7328013074029074

Epoch: 6| Step: 9
Training loss: 3.538828187305795
Validation loss: 2.7313649982600023

Epoch: 6| Step: 10
Training loss: 3.564661273888249
Validation loss: 2.7377417276315286

Epoch: 6| Step: 11
Training loss: 3.0594657346773864
Validation loss: 2.7347265586512486

Epoch: 6| Step: 12
Training loss: 2.451439734181672
Validation loss: 2.7364435287747084

Epoch: 6| Step: 13
Training loss: 3.3819123583626465
Validation loss: 2.751749870987311

Epoch: 288| Step: 0
Training loss: 3.1493789363351223
Validation loss: 2.741877650031625

Epoch: 6| Step: 1
Training loss: 2.8782583928545398
Validation loss: 2.7379728924244966

Epoch: 6| Step: 2
Training loss: 3.2379614070409066
Validation loss: 2.7298170869454137

Epoch: 6| Step: 3
Training loss: 2.7356181779148447
Validation loss: 2.7240592686713403

Epoch: 6| Step: 4
Training loss: 2.632209505027465
Validation loss: 2.72913043040292

Epoch: 6| Step: 5
Training loss: 2.7148416423103328
Validation loss: 2.724723406054385

Epoch: 6| Step: 6
Training loss: 3.3208415249508505
Validation loss: 2.723281321332452

Epoch: 6| Step: 7
Training loss: 3.5377825512952352
Validation loss: 2.7247419493455776

Epoch: 6| Step: 8
Training loss: 3.0549072810960647
Validation loss: 2.7257222998567596

Epoch: 6| Step: 9
Training loss: 2.806612931807095
Validation loss: 2.72843282383993

Epoch: 6| Step: 10
Training loss: 2.8988783673300644
Validation loss: 2.7239344519798845

Epoch: 6| Step: 11
Training loss: 3.061340423905848
Validation loss: 2.721747884497879

Epoch: 6| Step: 12
Training loss: 3.0952336000402876
Validation loss: 2.7250202101061216

Epoch: 6| Step: 13
Training loss: 3.6034235252458076
Validation loss: 2.7236704239608303

Epoch: 289| Step: 0
Training loss: 2.81253738378475
Validation loss: 2.7241780417492705

Epoch: 6| Step: 1
Training loss: 3.5052578805914183
Validation loss: 2.7262759279184947

Epoch: 6| Step: 2
Training loss: 3.2530383066430844
Validation loss: 2.724342119789058

Epoch: 6| Step: 3
Training loss: 2.2578832489861487
Validation loss: 2.7230293391526184

Epoch: 6| Step: 4
Training loss: 3.4185098623011023
Validation loss: 2.7269068171846063

Epoch: 6| Step: 5
Training loss: 2.7980159371708133
Validation loss: 2.7292341508735762

Epoch: 6| Step: 6
Training loss: 2.580295920293911
Validation loss: 2.7280072101829367

Epoch: 6| Step: 7
Training loss: 3.2163491785834166
Validation loss: 2.7343916753913815

Epoch: 6| Step: 8
Training loss: 3.07128021287477
Validation loss: 2.735000760013329

Epoch: 6| Step: 9
Training loss: 3.191784839749828
Validation loss: 2.7315552463547315

Epoch: 6| Step: 10
Training loss: 2.823575232755759
Validation loss: 2.7260092348401823

Epoch: 6| Step: 11
Training loss: 3.736392828724575
Validation loss: 2.730609940203591

Epoch: 6| Step: 12
Training loss: 2.7130767560675397
Validation loss: 2.730536775367893

Epoch: 6| Step: 13
Training loss: 2.7213108673788193
Validation loss: 2.730585298963286

Epoch: 290| Step: 0
Training loss: 3.147804366977667
Validation loss: 2.7316744030040163

Epoch: 6| Step: 1
Training loss: 3.1778839770120775
Validation loss: 2.7320794614569985

Epoch: 6| Step: 2
Training loss: 3.196440779654288
Validation loss: 2.736288664748923

Epoch: 6| Step: 3
Training loss: 3.3899330101033387
Validation loss: 2.7428993647580167

Epoch: 6| Step: 4
Training loss: 3.2149846543202423
Validation loss: 2.7434193713383928

Epoch: 6| Step: 5
Training loss: 2.86052809848064
Validation loss: 2.758269302754652

Epoch: 6| Step: 6
Training loss: 2.8245716850542153
Validation loss: 2.738712996182707

Epoch: 6| Step: 7
Training loss: 2.475662019602582
Validation loss: 2.740597382876361

Epoch: 6| Step: 8
Training loss: 3.3292518105120634
Validation loss: 2.7362237271408474

Epoch: 6| Step: 9
Training loss: 2.961800723701124
Validation loss: 2.738192572373502

Epoch: 6| Step: 10
Training loss: 2.684389665450335
Validation loss: 2.7357838085128257

Epoch: 6| Step: 11
Training loss: 3.3123043650310886
Validation loss: 2.730596824399256

Epoch: 6| Step: 12
Training loss: 2.7800337457323945
Validation loss: 2.7271274374287238

Epoch: 6| Step: 13
Training loss: 3.1200426071876812
Validation loss: 2.731407931053097

Epoch: 291| Step: 0
Training loss: 3.155042360628979
Validation loss: 2.7218938539757453

Epoch: 6| Step: 1
Training loss: 2.7686364970827273
Validation loss: 2.7265366017295496

Epoch: 6| Step: 2
Training loss: 2.5648885620181026
Validation loss: 2.727856825606238

Epoch: 6| Step: 3
Training loss: 3.3663365822304936
Validation loss: 2.7260698208964786

Epoch: 6| Step: 4
Training loss: 3.359720185753942
Validation loss: 2.7261222156900033

Epoch: 6| Step: 5
Training loss: 2.8829206741010376
Validation loss: 2.7243944791166386

Epoch: 6| Step: 6
Training loss: 3.0641945024114245
Validation loss: 2.7235649121395316

Epoch: 6| Step: 7
Training loss: 2.94156235968333
Validation loss: 2.7265194476569232

Epoch: 6| Step: 8
Training loss: 3.6771009551032177
Validation loss: 2.7245101663069273

Epoch: 6| Step: 9
Training loss: 3.2541600525642678
Validation loss: 2.7217610843879028

Epoch: 6| Step: 10
Training loss: 2.408807955461868
Validation loss: 2.715540903222967

Epoch: 6| Step: 11
Training loss: 2.7111643935354444
Validation loss: 2.7173966077955227

Epoch: 6| Step: 12
Training loss: 3.075745258115871
Validation loss: 2.719327835762784

Epoch: 6| Step: 13
Training loss: 3.169586408331208
Validation loss: 2.7157767538073943

Epoch: 292| Step: 0
Training loss: 2.8353375097059104
Validation loss: 2.7216399385678742

Epoch: 6| Step: 1
Training loss: 2.7810295103305003
Validation loss: 2.714836135113479

Epoch: 6| Step: 2
Training loss: 3.2804829018694805
Validation loss: 2.713126259977547

Epoch: 6| Step: 3
Training loss: 3.197485746660594
Validation loss: 2.7190620941956394

Epoch: 6| Step: 4
Training loss: 3.6865657334080293
Validation loss: 2.717326664721602

Epoch: 6| Step: 5
Training loss: 2.6055335361369982
Validation loss: 2.712039183799077

Epoch: 6| Step: 6
Training loss: 3.4553636569852038
Validation loss: 2.7151728505769217

Epoch: 6| Step: 7
Training loss: 2.806287558799151
Validation loss: 2.714475028612356

Epoch: 6| Step: 8
Training loss: 3.433618608369558
Validation loss: 2.722094854366884

Epoch: 6| Step: 9
Training loss: 2.7730911253501658
Validation loss: 2.721092575570578

Epoch: 6| Step: 10
Training loss: 3.0723959961213367
Validation loss: 2.7224496391783157

Epoch: 6| Step: 11
Training loss: 2.902287889561696
Validation loss: 2.7258616132288687

Epoch: 6| Step: 12
Training loss: 2.9815946879547104
Validation loss: 2.7341423683414376

Epoch: 6| Step: 13
Training loss: 1.9885670994177487
Validation loss: 2.737405690450852

Epoch: 293| Step: 0
Training loss: 3.0443364449841592
Validation loss: 2.747158090444596

Epoch: 6| Step: 1
Training loss: 2.6659368370626795
Validation loss: 2.7363119017508817

Epoch: 6| Step: 2
Training loss: 2.650399080851931
Validation loss: 2.7376621590324084

Epoch: 6| Step: 3
Training loss: 3.5091430587415307
Validation loss: 2.744911957249013

Epoch: 6| Step: 4
Training loss: 3.2180895081394896
Validation loss: 2.7473808766778154

Epoch: 6| Step: 5
Training loss: 3.4270017357168707
Validation loss: 2.7373550756517533

Epoch: 6| Step: 6
Training loss: 2.5841724099549856
Validation loss: 2.7142893768968652

Epoch: 6| Step: 7
Training loss: 2.535629345873916
Validation loss: 2.7144562532132257

Epoch: 6| Step: 8
Training loss: 3.447279872270488
Validation loss: 2.7108484168264595

Epoch: 6| Step: 9
Training loss: 2.6737667770537077
Validation loss: 2.715274334060951

Epoch: 6| Step: 10
Training loss: 3.301144840597873
Validation loss: 2.714776802668749

Epoch: 6| Step: 11
Training loss: 3.3098378550295955
Validation loss: 2.7206641495505384

Epoch: 6| Step: 12
Training loss: 2.7384310040630333
Validation loss: 2.7207005375216133

Epoch: 6| Step: 13
Training loss: 3.357878595680624
Validation loss: 2.722737583796913

Epoch: 294| Step: 0
Training loss: 2.4921992669380812
Validation loss: 2.7205558892313917

Epoch: 6| Step: 1
Training loss: 3.036702394355556
Validation loss: 2.7212189414051564

Epoch: 6| Step: 2
Training loss: 3.3038074954020558
Validation loss: 2.73050142356945

Epoch: 6| Step: 3
Training loss: 2.1824152023079595
Validation loss: 2.7277684528738995

Epoch: 6| Step: 4
Training loss: 3.1626318440452783
Validation loss: 2.726256626323443

Epoch: 6| Step: 5
Training loss: 3.0951799883296367
Validation loss: 2.729352177453132

Epoch: 6| Step: 6
Training loss: 3.4197523248233583
Validation loss: 2.727140468393503

Epoch: 6| Step: 7
Training loss: 2.8095643723325283
Validation loss: 2.729405621329522

Epoch: 6| Step: 8
Training loss: 3.0318080742313835
Validation loss: 2.720845219579673

Epoch: 6| Step: 9
Training loss: 3.3729216216068423
Validation loss: 2.721419075997767

Epoch: 6| Step: 10
Training loss: 2.6441605053082595
Validation loss: 2.7166455858088217

Epoch: 6| Step: 11
Training loss: 3.537907628813201
Validation loss: 2.7184180902339223

Epoch: 6| Step: 12
Training loss: 3.034229190988589
Validation loss: 2.714557301673327

Epoch: 6| Step: 13
Training loss: 3.618245639473412
Validation loss: 2.7173630181365613

Epoch: 295| Step: 0
Training loss: 3.1959032477962945
Validation loss: 2.7186412343979995

Epoch: 6| Step: 1
Training loss: 3.4386192580356143
Validation loss: 2.7146885122004707

Epoch: 6| Step: 2
Training loss: 3.1185026143332037
Validation loss: 2.7132946652518823

Epoch: 6| Step: 3
Training loss: 2.5848541295345235
Validation loss: 2.716126898016045

Epoch: 6| Step: 4
Training loss: 3.188662597463304
Validation loss: 2.7231703822303963

Epoch: 6| Step: 5
Training loss: 2.92730730134351
Validation loss: 2.7280498744304134

Epoch: 6| Step: 6
Training loss: 3.3958093061162695
Validation loss: 2.7412121074624083

Epoch: 6| Step: 7
Training loss: 2.20244528383147
Validation loss: 2.7348547242481516

Epoch: 6| Step: 8
Training loss: 3.6510186224122676
Validation loss: 2.7275538077647448

Epoch: 6| Step: 9
Training loss: 2.976829216489093
Validation loss: 2.7293615590195244

Epoch: 6| Step: 10
Training loss: 2.9892233566496738
Validation loss: 2.7248908951408586

Epoch: 6| Step: 11
Training loss: 2.9248028941459445
Validation loss: 2.718380099602027

Epoch: 6| Step: 12
Training loss: 2.550743488306821
Validation loss: 2.720265291650914

Epoch: 6| Step: 13
Training loss: 3.2190945635317956
Validation loss: 2.7215409353093176

Epoch: 296| Step: 0
Training loss: 3.4398354659542822
Validation loss: 2.7203895962922005

Epoch: 6| Step: 1
Training loss: 3.5331167502570966
Validation loss: 2.7312616722109264

Epoch: 6| Step: 2
Training loss: 2.9236356764904303
Validation loss: 2.7190105014987394

Epoch: 6| Step: 3
Training loss: 2.835696711971355
Validation loss: 2.7241727886947324

Epoch: 6| Step: 4
Training loss: 2.835022329414068
Validation loss: 2.7267685904659618

Epoch: 6| Step: 5
Training loss: 3.0338777773133483
Validation loss: 2.7274416541506694

Epoch: 6| Step: 6
Training loss: 3.3466536134361435
Validation loss: 2.7250146294018887

Epoch: 6| Step: 7
Training loss: 2.6747863256375046
Validation loss: 2.7219798754383286

Epoch: 6| Step: 8
Training loss: 3.1192240933767725
Validation loss: 2.7163161917674414

Epoch: 6| Step: 9
Training loss: 2.9574380693054008
Validation loss: 2.717958177773642

Epoch: 6| Step: 10
Training loss: 2.8711518781318075
Validation loss: 2.7157613715995588

Epoch: 6| Step: 11
Training loss: 3.2004223842807336
Validation loss: 2.7121473194907324

Epoch: 6| Step: 12
Training loss: 2.7809981328525195
Validation loss: 2.7114357306799635

Epoch: 6| Step: 13
Training loss: 2.5725565566953508
Validation loss: 2.7148116377728972

Epoch: 297| Step: 0
Training loss: 3.1848932714860063
Validation loss: 2.7138046909670623

Epoch: 6| Step: 1
Training loss: 3.4141055176423154
Validation loss: 2.717804423361445

Epoch: 6| Step: 2
Training loss: 2.9494594854665643
Validation loss: 2.7145505170615856

Epoch: 6| Step: 3
Training loss: 2.7369284777873157
Validation loss: 2.715046934177903

Epoch: 6| Step: 4
Training loss: 3.1090193501947287
Validation loss: 2.7121041777446373

Epoch: 6| Step: 5
Training loss: 3.77147931770764
Validation loss: 2.7099617605255215

Epoch: 6| Step: 6
Training loss: 3.0603123850721636
Validation loss: 2.710726322730473

Epoch: 6| Step: 7
Training loss: 2.3232553232341973
Validation loss: 2.7113255583023164

Epoch: 6| Step: 8
Training loss: 3.193336230086232
Validation loss: 2.709789905481504

Epoch: 6| Step: 9
Training loss: 2.44587676634125
Validation loss: 2.7143555098346583

Epoch: 6| Step: 10
Training loss: 3.1049853446479445
Validation loss: 2.7063339934252055

Epoch: 6| Step: 11
Training loss: 3.2752911911431304
Validation loss: 2.7119565639868197

Epoch: 6| Step: 12
Training loss: 2.919900645303258
Validation loss: 2.70987438976819

Epoch: 6| Step: 13
Training loss: 2.344099501935783
Validation loss: 2.7073604518106724

Epoch: 298| Step: 0
Training loss: 3.6786055543456806
Validation loss: 2.710334684567524

Epoch: 6| Step: 1
Training loss: 2.4934431876837095
Validation loss: 2.7052297180448295

Epoch: 6| Step: 2
Training loss: 3.731791476476327
Validation loss: 2.708550981306476

Epoch: 6| Step: 3
Training loss: 2.1411511964822822
Validation loss: 2.7086419402204087

Epoch: 6| Step: 4
Training loss: 3.287537572377679
Validation loss: 2.7155581526081796

Epoch: 6| Step: 5
Training loss: 2.9690116365486725
Validation loss: 2.7120797795572

Epoch: 6| Step: 6
Training loss: 2.536032221183296
Validation loss: 2.710615303894043

Epoch: 6| Step: 7
Training loss: 2.8094650848168903
Validation loss: 2.717099613040957

Epoch: 6| Step: 8
Training loss: 2.7638723563546996
Validation loss: 2.7257231585662223

Epoch: 6| Step: 9
Training loss: 3.250134391940405
Validation loss: 2.734906946055394

Epoch: 6| Step: 10
Training loss: 3.4102977535432686
Validation loss: 2.7319839303550246

Epoch: 6| Step: 11
Training loss: 3.3408881088286826
Validation loss: 2.7319727514044327

Epoch: 6| Step: 12
Training loss: 2.4577104027089898
Validation loss: 2.7291935416292303

Epoch: 6| Step: 13
Training loss: 3.0194164417149443
Validation loss: 2.718806014322578

Epoch: 299| Step: 0
Training loss: 3.075229580380284
Validation loss: 2.7310259517187108

Epoch: 6| Step: 1
Training loss: 2.8730397383175297
Validation loss: 2.739181362422792

Epoch: 6| Step: 2
Training loss: 3.057764869127946
Validation loss: 2.740769917752892

Epoch: 6| Step: 3
Training loss: 3.8164827149773264
Validation loss: 2.7206403331964752

Epoch: 6| Step: 4
Training loss: 2.297449572054371
Validation loss: 2.7102603972829913

Epoch: 6| Step: 5
Training loss: 2.633047665017879
Validation loss: 2.706464069058681

Epoch: 6| Step: 6
Training loss: 3.157493723955962
Validation loss: 2.703055538375916

Epoch: 6| Step: 7
Training loss: 3.4259088855659465
Validation loss: 2.712681771521104

Epoch: 6| Step: 8
Training loss: 3.3217784562530293
Validation loss: 2.710519281124242

Epoch: 6| Step: 9
Training loss: 2.325516846337626
Validation loss: 2.709967237895902

Epoch: 6| Step: 10
Training loss: 2.5810056372148273
Validation loss: 2.7091800877382597

Epoch: 6| Step: 11
Training loss: 2.952754890621942
Validation loss: 2.71054235220893

Epoch: 6| Step: 12
Training loss: 3.330999574677833
Validation loss: 2.7024582777944084

Epoch: 6| Step: 13
Training loss: 3.4772818174827016
Validation loss: 2.7029518357918514

Epoch: 300| Step: 0
Training loss: 2.5294836969493053
Validation loss: 2.707391701724188

Epoch: 6| Step: 1
Training loss: 2.8984353613010136
Validation loss: 2.7084572715577475

Epoch: 6| Step: 2
Training loss: 2.506369487549207
Validation loss: 2.7127958177347917

Epoch: 6| Step: 3
Training loss: 3.154558238252677
Validation loss: 2.7153651999342965

Epoch: 6| Step: 4
Training loss: 3.672553336611179
Validation loss: 2.72441788908102

Epoch: 6| Step: 5
Training loss: 2.7103388672281405
Validation loss: 2.7383545159236173

Epoch: 6| Step: 6
Training loss: 2.4015861991551866
Validation loss: 2.7292462465478513

Epoch: 6| Step: 7
Training loss: 3.297581890671344
Validation loss: 2.7220186135471627

Epoch: 6| Step: 8
Training loss: 2.6442382289541166
Validation loss: 2.721508747618366

Epoch: 6| Step: 9
Training loss: 3.8394416295833356
Validation loss: 2.714420197093902

Epoch: 6| Step: 10
Training loss: 3.0643989747844773
Validation loss: 2.7235072326364715

Epoch: 6| Step: 11
Training loss: 2.8014756197204687
Validation loss: 2.716679195662289

Epoch: 6| Step: 12
Training loss: 3.5199571832306913
Validation loss: 2.712086276372344

Epoch: 6| Step: 13
Training loss: 3.023513990119726
Validation loss: 2.7076285480928806

Testing loss: 2.9408707562302463
