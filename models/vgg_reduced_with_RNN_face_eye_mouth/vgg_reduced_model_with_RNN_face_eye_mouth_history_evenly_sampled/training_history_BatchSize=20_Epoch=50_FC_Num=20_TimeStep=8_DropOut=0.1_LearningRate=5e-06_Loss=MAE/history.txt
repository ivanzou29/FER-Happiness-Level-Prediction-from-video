Epoch: 1| Step: 0
Training loss: 5.441397190093994
Validation loss: 5.208088444125268

Epoch: 5| Step: 1
Training loss: 4.776215553283691
Validation loss: 5.203585358076198

Epoch: 5| Step: 2
Training loss: 5.5719709396362305
Validation loss: 5.199296207838161

Epoch: 5| Step: 3
Training loss: 4.903629302978516
Validation loss: 5.195242261373869

Epoch: 5| Step: 4
Training loss: 5.337560176849365
Validation loss: 5.190875930170859

Epoch: 5| Step: 5
Training loss: 4.057304382324219
Validation loss: 5.186441329217726

Epoch: 5| Step: 6
Training loss: 4.299930572509766
Validation loss: 5.1819698528576925

Epoch: 5| Step: 7
Training loss: 4.332468032836914
Validation loss: 5.1773769676044425

Epoch: 5| Step: 8
Training loss: 5.524825096130371
Validation loss: 5.1726017664837585

Epoch: 5| Step: 9
Training loss: 5.620564937591553
Validation loss: 5.167953060519311

Epoch: 5| Step: 10
Training loss: 4.925323486328125
Validation loss: 5.162875872786327

Epoch: 2| Step: 0
Training loss: 4.9342756271362305
Validation loss: 5.157407545274304

Epoch: 5| Step: 1
Training loss: 5.708291053771973
Validation loss: 5.151785137832806

Epoch: 5| Step: 2
Training loss: 5.3229241371154785
Validation loss: 5.146129572263328

Epoch: 5| Step: 3
Training loss: 5.0359601974487305
Validation loss: 5.14019267277051

Epoch: 5| Step: 4
Training loss: 4.772049903869629
Validation loss: 5.133347680491786

Epoch: 5| Step: 5
Training loss: 4.40139102935791
Validation loss: 5.1268747750148975

Epoch: 5| Step: 6
Training loss: 5.255537986755371
Validation loss: 5.1196655355474

Epoch: 5| Step: 7
Training loss: 4.962715148925781
Validation loss: 5.112332528637301

Epoch: 5| Step: 8
Training loss: 3.28840708732605
Validation loss: 5.104043632425288

Epoch: 5| Step: 9
Training loss: 4.809891223907471
Validation loss: 5.096009418528567

Epoch: 5| Step: 10
Training loss: 5.7564897537231445
Validation loss: 5.087173969514908

Epoch: 3| Step: 0
Training loss: 4.938508987426758
Validation loss: 5.078060975638769

Epoch: 5| Step: 1
Training loss: 4.710216522216797
Validation loss: 5.068219369457614

Epoch: 5| Step: 2
Training loss: 5.276708126068115
Validation loss: 5.057318364420245

Epoch: 5| Step: 3
Training loss: 5.345568656921387
Validation loss: 5.046776884345598

Epoch: 5| Step: 4
Training loss: 4.842484474182129
Validation loss: 5.03460709253947

Epoch: 5| Step: 5
Training loss: 4.706871509552002
Validation loss: 5.022919362591159

Epoch: 5| Step: 6
Training loss: 4.342507362365723
Validation loss: 5.009404792580553

Epoch: 5| Step: 7
Training loss: 5.831699848175049
Validation loss: 4.996189040522421

Epoch: 5| Step: 8
Training loss: 4.602675437927246
Validation loss: 4.981298462037118

Epoch: 5| Step: 9
Training loss: 3.996807098388672
Validation loss: 4.965714608469317

Epoch: 5| Step: 10
Training loss: 4.268148899078369
Validation loss: 4.95161295449862

Epoch: 4| Step: 0
Training loss: 4.7225823402404785
Validation loss: 4.934881238527195

Epoch: 5| Step: 1
Training loss: 3.5053794384002686
Validation loss: 4.918505878858669

Epoch: 5| Step: 2
Training loss: 4.237802505493164
Validation loss: 4.8996393142207975

Epoch: 5| Step: 3
Training loss: 3.9348273277282715
Validation loss: 4.881743164472683

Epoch: 5| Step: 4
Training loss: 4.964361667633057
Validation loss: 4.86237040386405

Epoch: 5| Step: 5
Training loss: 3.8264687061309814
Validation loss: 4.842575555206627

Epoch: 5| Step: 6
Training loss: 5.191256046295166
Validation loss: 4.82131491937945

Epoch: 5| Step: 7
Training loss: 3.7322776317596436
Validation loss: 4.800211947451356

Epoch: 5| Step: 8
Training loss: 6.482621192932129
Validation loss: 4.778585682633103

Epoch: 5| Step: 9
Training loss: 5.344269275665283
Validation loss: 4.756062920375537

Epoch: 5| Step: 10
Training loss: 5.007782459259033
Validation loss: 4.730939567729991

Epoch: 5| Step: 0
Training loss: 4.453866004943848
Validation loss: 4.707407659099948

Epoch: 5| Step: 1
Training loss: 4.458906650543213
Validation loss: 4.683405896668793

Epoch: 5| Step: 2
Training loss: 5.191527366638184
Validation loss: 4.657312321406539

Epoch: 5| Step: 3
Training loss: 4.588381767272949
Validation loss: 4.63156488890289

Epoch: 5| Step: 4
Training loss: 5.686121940612793
Validation loss: 4.606535875669089

Epoch: 5| Step: 5
Training loss: 3.7932510375976562
Validation loss: 4.579533130891861

Epoch: 5| Step: 6
Training loss: 3.544832706451416
Validation loss: 4.55310861525997

Epoch: 5| Step: 7
Training loss: 3.4087231159210205
Validation loss: 4.526754353636054

Epoch: 5| Step: 8
Training loss: 4.035407066345215
Validation loss: 4.498876751110118

Epoch: 5| Step: 9
Training loss: 4.3513007164001465
Validation loss: 4.4723650870784635

Epoch: 5| Step: 10
Training loss: 4.488117218017578
Validation loss: 4.446583786318379

Epoch: 6| Step: 0
Training loss: 3.25520396232605
Validation loss: 4.420916731639575

Epoch: 5| Step: 1
Training loss: 4.055042266845703
Validation loss: 4.394764454134049

Epoch: 5| Step: 2
Training loss: 4.0213494300842285
Validation loss: 4.369349571966356

Epoch: 5| Step: 3
Training loss: 4.291563987731934
Validation loss: 4.345876950089649

Epoch: 5| Step: 4
Training loss: 4.156360626220703
Validation loss: 4.321592174550538

Epoch: 5| Step: 5
Training loss: 5.059142112731934
Validation loss: 4.297075515152306

Epoch: 5| Step: 6
Training loss: 3.7179126739501953
Validation loss: 4.27182751060814

Epoch: 5| Step: 7
Training loss: 4.238772392272949
Validation loss: 4.24698063635057

Epoch: 5| Step: 8
Training loss: 3.979325771331787
Validation loss: 4.223339721720706

Epoch: 5| Step: 9
Training loss: 3.9711356163024902
Validation loss: 4.199780038608018

Epoch: 5| Step: 10
Training loss: 4.313604831695557
Validation loss: 4.175945399909891

Epoch: 7| Step: 0
Training loss: 4.83740234375
Validation loss: 4.1509417462092575

Epoch: 5| Step: 1
Training loss: 3.2910563945770264
Validation loss: 4.126027332839145

Epoch: 5| Step: 2
Training loss: 4.828498363494873
Validation loss: 4.099924282361102

Epoch: 5| Step: 3
Training loss: 3.3469691276550293
Validation loss: 4.077643684161607

Epoch: 5| Step: 4
Training loss: 4.693672180175781
Validation loss: 4.052107877628778

Epoch: 5| Step: 5
Training loss: 3.8094775676727295
Validation loss: 4.0293860332940215

Epoch: 5| Step: 6
Training loss: 4.467707633972168
Validation loss: 4.006480857890139

Epoch: 5| Step: 7
Training loss: 3.1919703483581543
Validation loss: 3.984727108350364

Epoch: 5| Step: 8
Training loss: 3.079418420791626
Validation loss: 3.963315381798693

Epoch: 5| Step: 9
Training loss: 3.7366127967834473
Validation loss: 3.9442938835390153

Epoch: 5| Step: 10
Training loss: 3.2815887928009033
Validation loss: 3.9246941074248283

Epoch: 8| Step: 0
Training loss: 4.999122619628906
Validation loss: 3.9072398472857732

Epoch: 5| Step: 1
Training loss: 3.855968475341797
Validation loss: 3.8909188188532347

Epoch: 5| Step: 2
Training loss: 3.8689510822296143
Validation loss: 3.8727394944878033

Epoch: 5| Step: 3
Training loss: 3.52693247795105
Validation loss: 3.8547008575931674

Epoch: 5| Step: 4
Training loss: 3.3916115760803223
Validation loss: 3.840412409074845

Epoch: 5| Step: 5
Training loss: 3.2614734172821045
Validation loss: 3.823784177021314

Epoch: 5| Step: 6
Training loss: 3.688006639480591
Validation loss: 3.810840452871015

Epoch: 5| Step: 7
Training loss: 3.493473768234253
Validation loss: 3.7980230956949215

Epoch: 5| Step: 8
Training loss: 3.8759188652038574
Validation loss: 3.784457698945076

Epoch: 5| Step: 9
Training loss: 3.4493870735168457
Validation loss: 3.772197646479453

Epoch: 5| Step: 10
Training loss: 3.217015027999878
Validation loss: 3.7564588772353305

Epoch: 9| Step: 0
Training loss: 3.6944313049316406
Validation loss: 3.7392089572004092

Epoch: 5| Step: 1
Training loss: 3.436589479446411
Validation loss: 3.72220435706518

Epoch: 5| Step: 2
Training loss: 3.4997341632843018
Validation loss: 3.7066899525221957

Epoch: 5| Step: 3
Training loss: 3.0514025688171387
Validation loss: 3.6920682230303363

Epoch: 5| Step: 4
Training loss: 2.7019009590148926
Validation loss: 3.680750882753762

Epoch: 5| Step: 5
Training loss: 4.028804779052734
Validation loss: 3.675948360914825

Epoch: 5| Step: 6
Training loss: 3.1881158351898193
Validation loss: 3.664066283933578

Epoch: 5| Step: 7
Training loss: 3.915923595428467
Validation loss: 3.653145169699064

Epoch: 5| Step: 8
Training loss: 4.557187080383301
Validation loss: 3.641611253061602

Epoch: 5| Step: 9
Training loss: 3.5328376293182373
Validation loss: 3.627403402841219

Epoch: 5| Step: 10
Training loss: 3.7113394737243652
Validation loss: 3.6181959131712556

Epoch: 10| Step: 0
Training loss: 2.8928887844085693
Validation loss: 3.602613223496304

Epoch: 5| Step: 1
Training loss: 3.6542747020721436
Validation loss: 3.5887437840943694

Epoch: 5| Step: 2
Training loss: 4.124721050262451
Validation loss: 3.580269931465067

Epoch: 5| Step: 3
Training loss: 4.246004581451416
Validation loss: 3.5692416365428636

Epoch: 5| Step: 4
Training loss: 3.3008618354797363
Validation loss: 3.558804870933615

Epoch: 5| Step: 5
Training loss: 3.2520699501037598
Validation loss: 3.549365520477295

Epoch: 5| Step: 6
Training loss: 3.2096474170684814
Validation loss: 3.541761147078647

Epoch: 5| Step: 7
Training loss: 2.887256145477295
Validation loss: 3.534209712859123

Epoch: 5| Step: 8
Training loss: 3.404268741607666
Validation loss: 3.5256106725303074

Epoch: 5| Step: 9
Training loss: 4.503042697906494
Validation loss: 3.52010392373608

Epoch: 5| Step: 10
Training loss: 2.624439239501953
Validation loss: 3.508691298064365

Epoch: 11| Step: 0
Training loss: 3.4968342781066895
Validation loss: 3.5009125407024095

Epoch: 5| Step: 1
Training loss: 3.3377113342285156
Validation loss: 3.495645305161835

Epoch: 5| Step: 2
Training loss: 2.0172743797302246
Validation loss: 3.485817465730893

Epoch: 5| Step: 3
Training loss: 4.373299598693848
Validation loss: 3.478181157060849

Epoch: 5| Step: 4
Training loss: 3.353055238723755
Validation loss: 3.474576080999067

Epoch: 5| Step: 5
Training loss: 3.9606380462646484
Validation loss: 3.4684345645289265

Epoch: 5| Step: 6
Training loss: 3.2544732093811035
Validation loss: 3.4615375559817076

Epoch: 5| Step: 7
Training loss: 3.057961940765381
Validation loss: 3.4569399895206576

Epoch: 5| Step: 8
Training loss: 3.9484920501708984
Validation loss: 3.450298429817282

Epoch: 5| Step: 9
Training loss: 3.2148849964141846
Validation loss: 3.4459732194100656

Epoch: 5| Step: 10
Training loss: 3.449017286300659
Validation loss: 3.4393807124066096

Epoch: 12| Step: 0
Training loss: 3.4551663398742676
Validation loss: 3.438265654348558

Epoch: 5| Step: 1
Training loss: 3.447030544281006
Validation loss: 3.432127119392477

Epoch: 5| Step: 2
Training loss: 3.9334418773651123
Validation loss: 3.4297121417137886

Epoch: 5| Step: 3
Training loss: 2.7119088172912598
Validation loss: 3.422521993678103

Epoch: 5| Step: 4
Training loss: 4.331723690032959
Validation loss: 3.4186990235441472

Epoch: 5| Step: 5
Training loss: 3.4416613578796387
Validation loss: 3.4110210428955736

Epoch: 5| Step: 6
Training loss: 2.70637845993042
Validation loss: 3.4094120430689987

Epoch: 5| Step: 7
Training loss: 3.2058002948760986
Validation loss: 3.404254139110606

Epoch: 5| Step: 8
Training loss: 3.755645751953125
Validation loss: 3.404725326004849

Epoch: 5| Step: 9
Training loss: 3.1607253551483154
Validation loss: 3.3980443503267024

Epoch: 5| Step: 10
Training loss: 2.7680766582489014
Validation loss: 3.3945040113182476

Epoch: 13| Step: 0
Training loss: 3.3990566730499268
Validation loss: 3.390952548673076

Epoch: 5| Step: 1
Training loss: 3.2222371101379395
Validation loss: 3.393799222925658

Epoch: 5| Step: 2
Training loss: 2.4037716388702393
Validation loss: 3.3876807048756588

Epoch: 5| Step: 3
Training loss: 3.2973618507385254
Validation loss: 3.384275908111244

Epoch: 5| Step: 4
Training loss: 4.12274694442749
Validation loss: 3.376226314934351

Epoch: 5| Step: 5
Training loss: 3.5347180366516113
Validation loss: 3.371975765433363

Epoch: 5| Step: 6
Training loss: 3.1603705883026123
Validation loss: 3.3730946356250393

Epoch: 5| Step: 7
Training loss: 3.4495749473571777
Validation loss: 3.3647228005111858

Epoch: 5| Step: 8
Training loss: 3.704329252243042
Validation loss: 3.3621286269157165

Epoch: 5| Step: 9
Training loss: 3.1776881217956543
Validation loss: 3.357301399271975

Epoch: 5| Step: 10
Training loss: 3.1343753337860107
Validation loss: 3.353493575126894

Epoch: 14| Step: 0
Training loss: 3.3341002464294434
Validation loss: 3.352149717269405

Epoch: 5| Step: 1
Training loss: 4.006964683532715
Validation loss: 3.3485517655649493

Epoch: 5| Step: 2
Training loss: 3.318098545074463
Validation loss: 3.3463730658254316

Epoch: 5| Step: 3
Training loss: 3.5110976696014404
Validation loss: 3.343136454141268

Epoch: 5| Step: 4
Training loss: 3.156466007232666
Validation loss: 3.3417390033762944

Epoch: 5| Step: 5
Training loss: 3.5751922130584717
Validation loss: 3.3381390520321426

Epoch: 5| Step: 6
Training loss: 3.71235990524292
Validation loss: 3.3336206225938696

Epoch: 5| Step: 7
Training loss: 2.4100868701934814
Validation loss: 3.3292979014817106

Epoch: 5| Step: 8
Training loss: 2.8906540870666504
Validation loss: 3.329567014530141

Epoch: 5| Step: 9
Training loss: 2.5222463607788086
Validation loss: 3.3226646556649158

Epoch: 5| Step: 10
Training loss: 3.953808069229126
Validation loss: 3.321027135336271

Epoch: 15| Step: 0
Training loss: 3.5090041160583496
Validation loss: 3.3160053735138266

Epoch: 5| Step: 1
Training loss: 2.829869031906128
Validation loss: 3.3126876456763155

Epoch: 5| Step: 2
Training loss: 3.5022149085998535
Validation loss: 3.307650640446653

Epoch: 5| Step: 3
Training loss: 3.109875202178955
Validation loss: 3.306043783823649

Epoch: 5| Step: 4
Training loss: 3.765911817550659
Validation loss: 3.30330398262188

Epoch: 5| Step: 5
Training loss: 3.1058411598205566
Validation loss: 3.2955079796493694

Epoch: 5| Step: 6
Training loss: 2.8983511924743652
Validation loss: 3.2916382205101753

Epoch: 5| Step: 7
Training loss: 3.7723097801208496
Validation loss: 3.288605748966176

Epoch: 5| Step: 8
Training loss: 3.3877482414245605
Validation loss: 3.2849606288376676

Epoch: 5| Step: 9
Training loss: 3.4330475330352783
Validation loss: 3.2785327460176203

Epoch: 5| Step: 10
Training loss: 2.519334554672241
Validation loss: 3.27285074931319

Epoch: 16| Step: 0
Training loss: 3.7004897594451904
Validation loss: 3.267290271738524

Epoch: 5| Step: 1
Training loss: 3.2415897846221924
Validation loss: 3.265858281043268

Epoch: 5| Step: 2
Training loss: 3.468618869781494
Validation loss: 3.257931734925957

Epoch: 5| Step: 3
Training loss: 3.506169080734253
Validation loss: 3.2563291903465026

Epoch: 5| Step: 4
Training loss: 2.6918952465057373
Validation loss: 3.2476730859407814

Epoch: 5| Step: 5
Training loss: 3.735926866531372
Validation loss: 3.24596591149607

Epoch: 5| Step: 6
Training loss: 3.9257938861846924
Validation loss: 3.2423332788610972

Epoch: 5| Step: 7
Training loss: 3.2578816413879395
Validation loss: 3.2388479145624305

Epoch: 5| Step: 8
Training loss: 2.2816834449768066
Validation loss: 3.2325704918112805

Epoch: 5| Step: 9
Training loss: 2.669534683227539
Validation loss: 3.2282524647251254

Epoch: 5| Step: 10
Training loss: 3.0369105339050293
Validation loss: 3.225267348750945

Epoch: 17| Step: 0
Training loss: 3.5191383361816406
Validation loss: 3.2231896949070755

Epoch: 5| Step: 1
Training loss: 3.724058151245117
Validation loss: 3.216316125726187

Epoch: 5| Step: 2
Training loss: 3.8085765838623047
Validation loss: 3.2128911890009397

Epoch: 5| Step: 3
Training loss: 3.5339951515197754
Validation loss: 3.2096815416889806

Epoch: 5| Step: 4
Training loss: 2.6496806144714355
Validation loss: 3.2045669888937347

Epoch: 5| Step: 5
Training loss: 3.0713484287261963
Validation loss: 3.1999414326042257

Epoch: 5| Step: 6
Training loss: 2.5326671600341797
Validation loss: 3.1974553318433863

Epoch: 5| Step: 7
Training loss: 3.4936230182647705
Validation loss: 3.195482361701227

Epoch: 5| Step: 8
Training loss: 2.8679099082946777
Validation loss: 3.191410582552674

Epoch: 5| Step: 9
Training loss: 3.1132683753967285
Validation loss: 3.184687227331182

Epoch: 5| Step: 10
Training loss: 2.858769178390503
Validation loss: 3.180197884959559

Epoch: 18| Step: 0
Training loss: 2.5931036472320557
Validation loss: 3.176719001544419

Epoch: 5| Step: 1
Training loss: 3.1660094261169434
Validation loss: 3.171092179513747

Epoch: 5| Step: 2
Training loss: 3.067060947418213
Validation loss: 3.170706569507558

Epoch: 5| Step: 3
Training loss: 3.3750102519989014
Validation loss: 3.1650892201290337

Epoch: 5| Step: 4
Training loss: 3.120129346847534
Validation loss: 3.160984734053253

Epoch: 5| Step: 5
Training loss: 2.6846303939819336
Validation loss: 3.1602076048492105

Epoch: 5| Step: 6
Training loss: 3.209721803665161
Validation loss: 3.155656894048055

Epoch: 5| Step: 7
Training loss: 3.1254849433898926
Validation loss: 3.1541820520995767

Epoch: 5| Step: 8
Training loss: 3.4005744457244873
Validation loss: 3.1523307984875095

Epoch: 5| Step: 9
Training loss: 3.3495726585388184
Validation loss: 3.145916161998626

Epoch: 5| Step: 10
Training loss: 3.851128101348877
Validation loss: 3.140162803793466

Epoch: 19| Step: 0
Training loss: 3.5485775470733643
Validation loss: 3.138325345131659

Epoch: 5| Step: 1
Training loss: 3.2838852405548096
Validation loss: 3.135125062798941

Epoch: 5| Step: 2
Training loss: 2.5739169120788574
Validation loss: 3.1331715071073143

Epoch: 5| Step: 3
Training loss: 2.01477313041687
Validation loss: 3.1289392773823073

Epoch: 5| Step: 4
Training loss: 3.1557443141937256
Validation loss: 3.1247546903548704

Epoch: 5| Step: 5
Training loss: 3.943209171295166
Validation loss: 3.1208770198206746

Epoch: 5| Step: 6
Training loss: 3.022874355316162
Validation loss: 3.116976373939104

Epoch: 5| Step: 7
Training loss: 3.5503830909729004
Validation loss: 3.1159297702133015

Epoch: 5| Step: 8
Training loss: 3.4355900287628174
Validation loss: 3.111780415299118

Epoch: 5| Step: 9
Training loss: 2.2890753746032715
Validation loss: 3.108875838659143

Epoch: 5| Step: 10
Training loss: 3.88053035736084
Validation loss: 3.1060544649759927

Epoch: 20| Step: 0
Training loss: 3.3804943561553955
Validation loss: 3.104198876247611

Epoch: 5| Step: 1
Training loss: 3.3717856407165527
Validation loss: 3.100855509440104

Epoch: 5| Step: 2
Training loss: 2.4877655506134033
Validation loss: 3.0979831218719482

Epoch: 5| Step: 3
Training loss: 3.1970880031585693
Validation loss: 3.096390716491207

Epoch: 5| Step: 4
Training loss: 3.320626735687256
Validation loss: 3.092118683681693

Epoch: 5| Step: 5
Training loss: 3.1652979850769043
Validation loss: 3.0917354937522643

Epoch: 5| Step: 6
Training loss: 2.4737772941589355
Validation loss: 3.0898800819150862

Epoch: 5| Step: 7
Training loss: 3.3239192962646484
Validation loss: 3.0847349679598244

Epoch: 5| Step: 8
Training loss: 2.990078926086426
Validation loss: 3.080601451217487

Epoch: 5| Step: 9
Training loss: 3.253868818283081
Validation loss: 3.077030333139563

Epoch: 5| Step: 10
Training loss: 3.385590076446533
Validation loss: 3.0771708283373105

Epoch: 21| Step: 0
Training loss: 3.010211706161499
Validation loss: 3.075682311929682

Epoch: 5| Step: 1
Training loss: 3.176440477371216
Validation loss: 3.070291490964992

Epoch: 5| Step: 2
Training loss: 3.1373562812805176
Validation loss: 3.069459794670023

Epoch: 5| Step: 3
Training loss: 3.4383552074432373
Validation loss: 3.0646504971288864

Epoch: 5| Step: 4
Training loss: 2.3143556118011475
Validation loss: 3.0638714246852423

Epoch: 5| Step: 5
Training loss: 3.220149278640747
Validation loss: 3.0585237805561354

Epoch: 5| Step: 6
Training loss: 3.23992657661438
Validation loss: 3.057288623625232

Epoch: 5| Step: 7
Training loss: 3.7515709400177
Validation loss: 3.0544098192645657

Epoch: 5| Step: 8
Training loss: 3.4133453369140625
Validation loss: 3.0514954546446442

Epoch: 5| Step: 9
Training loss: 3.067897319793701
Validation loss: 3.0491702120791198

Epoch: 5| Step: 10
Training loss: 2.244673728942871
Validation loss: 3.0472763507596907

Epoch: 22| Step: 0
Training loss: 2.6296753883361816
Validation loss: 3.0447099849741948

Epoch: 5| Step: 1
Training loss: 3.0326361656188965
Validation loss: 3.0428184924587125

Epoch: 5| Step: 2
Training loss: 2.1466927528381348
Validation loss: 3.0432027309171614

Epoch: 5| Step: 3
Training loss: 3.8300137519836426
Validation loss: 3.0398833059495494

Epoch: 5| Step: 4
Training loss: 2.936185836791992
Validation loss: 3.0373237440663

Epoch: 5| Step: 5
Training loss: 2.501574993133545
Validation loss: 3.035662635680168

Epoch: 5| Step: 6
Training loss: 2.8491907119750977
Validation loss: 3.0354528888579337

Epoch: 5| Step: 7
Training loss: 4.185433864593506
Validation loss: 3.0309172779001217

Epoch: 5| Step: 8
Training loss: 3.5337471961975098
Validation loss: 3.0279617207024687

Epoch: 5| Step: 9
Training loss: 3.3850159645080566
Validation loss: 3.0244025030443744

Epoch: 5| Step: 10
Training loss: 2.8739752769470215
Validation loss: 3.0208601054324897

Epoch: 23| Step: 0
Training loss: 3.7417564392089844
Validation loss: 3.019845506196381

Epoch: 5| Step: 1
Training loss: 3.4924702644348145
Validation loss: 3.017587697634133

Epoch: 5| Step: 2
Training loss: 2.0915615558624268
Validation loss: 3.0168314082648164

Epoch: 5| Step: 3
Training loss: 3.653613328933716
Validation loss: 3.0126565194899038

Epoch: 5| Step: 4
Training loss: 2.029198408126831
Validation loss: 3.01253766141912

Epoch: 5| Step: 5
Training loss: 3.0959255695343018
Validation loss: 3.0085792131321405

Epoch: 5| Step: 6
Training loss: 2.6243929862976074
Validation loss: 3.0074860536923973

Epoch: 5| Step: 7
Training loss: 3.1657891273498535
Validation loss: 3.003257679682906

Epoch: 5| Step: 8
Training loss: 3.2980129718780518
Validation loss: 3.0036292204292874

Epoch: 5| Step: 9
Training loss: 2.7087931632995605
Validation loss: 3.0026942863259265

Epoch: 5| Step: 10
Training loss: 4.024899959564209
Validation loss: 2.9988900307686097

Epoch: 24| Step: 0
Training loss: 2.9316742420196533
Validation loss: 2.9928253004627843

Epoch: 5| Step: 1
Training loss: 2.8240299224853516
Validation loss: 2.9902598011878228

Epoch: 5| Step: 2
Training loss: 2.8072540760040283
Validation loss: 2.989095736575383

Epoch: 5| Step: 3
Training loss: 3.2248191833496094
Validation loss: 2.9877904128002863

Epoch: 5| Step: 4
Training loss: 2.957766056060791
Validation loss: 2.9887275336891093

Epoch: 5| Step: 5
Training loss: 3.068830728530884
Validation loss: 2.990701929215462

Epoch: 5| Step: 6
Training loss: 3.68619966506958
Validation loss: 2.990055109864922

Epoch: 5| Step: 7
Training loss: 3.3368735313415527
Validation loss: 2.980228034398889

Epoch: 5| Step: 8
Training loss: 2.837963104248047
Validation loss: 2.978359512103501

Epoch: 5| Step: 9
Training loss: 2.6592557430267334
Validation loss: 2.975935838555777

Epoch: 5| Step: 10
Training loss: 3.303617238998413
Validation loss: 2.973649106999879

Epoch: 25| Step: 0
Training loss: 3.3349437713623047
Validation loss: 2.974000915404289

Epoch: 5| Step: 1
Training loss: 2.5586776733398438
Validation loss: 2.972548402765746

Epoch: 5| Step: 2
Training loss: 2.843735933303833
Validation loss: 2.975044260742844

Epoch: 5| Step: 3
Training loss: 2.753352165222168
Validation loss: 2.9707323094849944

Epoch: 5| Step: 4
Training loss: 3.287297010421753
Validation loss: 2.9687444753544305

Epoch: 5| Step: 5
Training loss: 2.9974589347839355
Validation loss: 2.9653364714755805

Epoch: 5| Step: 6
Training loss: 3.7505295276641846
Validation loss: 2.966207750381962

Epoch: 5| Step: 7
Training loss: 3.29296875
Validation loss: 2.9636732916678152

Epoch: 5| Step: 8
Training loss: 2.9096899032592773
Validation loss: 2.962959676660517

Epoch: 5| Step: 9
Training loss: 3.368776321411133
Validation loss: 2.958388554152622

Epoch: 5| Step: 10
Training loss: 2.2818362712860107
Validation loss: 2.9553595486507622

Epoch: 26| Step: 0
Training loss: 3.4323935508728027
Validation loss: 2.9538182853370585

Epoch: 5| Step: 1
Training loss: 3.00669264793396
Validation loss: 2.9519800191284506

Epoch: 5| Step: 2
Training loss: 2.8909976482391357
Validation loss: 2.9498345057169595

Epoch: 5| Step: 3
Training loss: 2.8109195232391357
Validation loss: 2.948371564188311

Epoch: 5| Step: 4
Training loss: 3.3719048500061035
Validation loss: 2.9444814446151897

Epoch: 5| Step: 5
Training loss: 2.8679802417755127
Validation loss: 2.941459794198313

Epoch: 5| Step: 6
Training loss: 2.7031657695770264
Validation loss: 2.94102051437542

Epoch: 5| Step: 7
Training loss: 3.276149034500122
Validation loss: 2.9388551199308006

Epoch: 5| Step: 8
Training loss: 3.4225783348083496
Validation loss: 2.9375351064948627

Epoch: 5| Step: 9
Training loss: 2.514523983001709
Validation loss: 2.936074503006474

Epoch: 5| Step: 10
Training loss: 2.9940595626831055
Validation loss: 2.933173461626935

Epoch: 27| Step: 0
Training loss: 3.60954213142395
Validation loss: 2.933890852876889

Epoch: 5| Step: 1
Training loss: 3.70405650138855
Validation loss: 2.9303730482696206

Epoch: 5| Step: 2
Training loss: 2.8428449630737305
Validation loss: 2.9284389147194485

Epoch: 5| Step: 3
Training loss: 3.1404218673706055
Validation loss: 2.924305946596207

Epoch: 5| Step: 4
Training loss: 2.1307778358459473
Validation loss: 2.9204548661426832

Epoch: 5| Step: 5
Training loss: 2.38681697845459
Validation loss: 2.921563338207942

Epoch: 5| Step: 6
Training loss: 3.1486706733703613
Validation loss: 2.9222782452901206

Epoch: 5| Step: 7
Training loss: 2.799166202545166
Validation loss: 2.9208809560345066

Epoch: 5| Step: 8
Training loss: 3.6083602905273438
Validation loss: 2.920718252017934

Epoch: 5| Step: 9
Training loss: 2.9598495960235596
Validation loss: 2.9163118152208227

Epoch: 5| Step: 10
Training loss: 2.78861665725708
Validation loss: 2.914040668036348

Epoch: 28| Step: 0
Training loss: 3.333723545074463
Validation loss: 2.910995337270921

Epoch: 5| Step: 1
Training loss: 3.155489444732666
Validation loss: 2.9109227221499205

Epoch: 5| Step: 2
Training loss: 2.281235456466675
Validation loss: 2.9068593132880425

Epoch: 5| Step: 3
Training loss: 2.808176040649414
Validation loss: 2.9070092913925007

Epoch: 5| Step: 4
Training loss: 2.557116746902466
Validation loss: 2.9056972444698377

Epoch: 5| Step: 5
Training loss: 4.015336036682129
Validation loss: 2.9035207943249772

Epoch: 5| Step: 6
Training loss: 2.647388458251953
Validation loss: 2.9003188199894403

Epoch: 5| Step: 7
Training loss: 3.320638656616211
Validation loss: 2.8991332413047872

Epoch: 5| Step: 8
Training loss: 3.0317904949188232
Validation loss: 2.8987682993694017

Epoch: 5| Step: 9
Training loss: 2.7724575996398926
Validation loss: 2.896084790588707

Epoch: 5| Step: 10
Training loss: 3.102140426635742
Validation loss: 2.896836834569131

Epoch: 29| Step: 0
Training loss: 3.134586811065674
Validation loss: 2.8932260390250915

Epoch: 5| Step: 1
Training loss: 3.0909104347229004
Validation loss: 2.8921582032275457

Epoch: 5| Step: 2
Training loss: 3.214251756668091
Validation loss: 2.889362668478361

Epoch: 5| Step: 3
Training loss: 3.2050883769989014
Validation loss: 2.8885794531914497

Epoch: 5| Step: 4
Training loss: 3.6042582988739014
Validation loss: 2.8855079886733845

Epoch: 5| Step: 5
Training loss: 2.8882834911346436
Validation loss: 2.8855620840544343

Epoch: 5| Step: 6
Training loss: 2.3340694904327393
Validation loss: 2.8810669376004125

Epoch: 5| Step: 7
Training loss: 3.4368178844451904
Validation loss: 2.8805785384229434

Epoch: 5| Step: 8
Training loss: 2.352747678756714
Validation loss: 2.877323829999534

Epoch: 5| Step: 9
Training loss: 2.46274471282959
Validation loss: 2.875423180159702

Epoch: 5| Step: 10
Training loss: 3.1521458625793457
Validation loss: 2.874950280753515

Epoch: 30| Step: 0
Training loss: 2.3640799522399902
Validation loss: 2.870413698175902

Epoch: 5| Step: 1
Training loss: 3.467005968093872
Validation loss: 2.8701228326366794

Epoch: 5| Step: 2
Training loss: 3.625209331512451
Validation loss: 2.8656929872369252

Epoch: 5| Step: 3
Training loss: 2.7352659702301025
Validation loss: 2.864477977957777

Epoch: 5| Step: 4
Training loss: 2.256345748901367
Validation loss: 2.8660776179323912

Epoch: 5| Step: 5
Training loss: 2.6743216514587402
Validation loss: 2.864326195050311

Epoch: 5| Step: 6
Training loss: 3.793067455291748
Validation loss: 2.861126192154423

Epoch: 5| Step: 7
Training loss: 2.8849990367889404
Validation loss: 2.8590889643597346

Epoch: 5| Step: 8
Training loss: 2.502657413482666
Validation loss: 2.8590314977912494

Epoch: 5| Step: 9
Training loss: 3.290844440460205
Validation loss: 2.859346164170132

Epoch: 5| Step: 10
Training loss: 3.136542558670044
Validation loss: 2.859440690727644

Epoch: 31| Step: 0
Training loss: 3.0904479026794434
Validation loss: 2.854812155487717

Epoch: 5| Step: 1
Training loss: 2.5378406047821045
Validation loss: 2.851725842363091

Epoch: 5| Step: 2
Training loss: 2.7895569801330566
Validation loss: 2.8549284524815057

Epoch: 5| Step: 3
Training loss: 3.530672073364258
Validation loss: 2.854138235892019

Epoch: 5| Step: 4
Training loss: 1.956424355506897
Validation loss: 2.8522669935739167

Epoch: 5| Step: 5
Training loss: 2.817040205001831
Validation loss: 2.846977541523595

Epoch: 5| Step: 6
Training loss: 3.192702054977417
Validation loss: 2.845390263424125

Epoch: 5| Step: 7
Training loss: 2.9961202144622803
Validation loss: 2.8446549574534097

Epoch: 5| Step: 8
Training loss: 3.251142978668213
Validation loss: 2.84389494311425

Epoch: 5| Step: 9
Training loss: 3.4269778728485107
Validation loss: 2.841581042094897

Epoch: 5| Step: 10
Training loss: 3.020681381225586
Validation loss: 2.8383525186969387

Epoch: 32| Step: 0
Training loss: 2.651071786880493
Validation loss: 2.838505709043113

Epoch: 5| Step: 1
Training loss: 3.0061354637145996
Validation loss: 2.83673495118336

Epoch: 5| Step: 2
Training loss: 3.086369514465332
Validation loss: 2.834275486648724

Epoch: 5| Step: 3
Training loss: 2.6672987937927246
Validation loss: 2.834949142189436

Epoch: 5| Step: 4
Training loss: 3.2108654975891113
Validation loss: 2.8374063122657036

Epoch: 5| Step: 5
Training loss: 2.807404041290283
Validation loss: 2.8371651429002003

Epoch: 5| Step: 6
Training loss: 3.276873826980591
Validation loss: 2.832205154562509

Epoch: 5| Step: 7
Training loss: 2.682047128677368
Validation loss: 2.8275845050811768

Epoch: 5| Step: 8
Training loss: 2.793567180633545
Validation loss: 2.825723958271806

Epoch: 5| Step: 9
Training loss: 3.3779914379119873
Validation loss: 2.8306861513404438

Epoch: 5| Step: 10
Training loss: 2.886169910430908
Validation loss: 2.830018404991396

Epoch: 33| Step: 0
Training loss: 3.2248730659484863
Validation loss: 2.8236820338874735

Epoch: 5| Step: 1
Training loss: 3.7006306648254395
Validation loss: 2.8194637862584924

Epoch: 5| Step: 2
Training loss: 2.5249183177948
Validation loss: 2.8176855784590527

Epoch: 5| Step: 3
Training loss: 2.8480513095855713
Validation loss: 2.8156255855355212

Epoch: 5| Step: 4
Training loss: 3.048283100128174
Validation loss: 2.8143783794936312

Epoch: 5| Step: 5
Training loss: 2.266408920288086
Validation loss: 2.8163046221579275

Epoch: 5| Step: 6
Training loss: 3.619399309158325
Validation loss: 2.8164727508380847

Epoch: 5| Step: 7
Training loss: 2.201498508453369
Validation loss: 2.8134858095517723

Epoch: 5| Step: 8
Training loss: 3.437514543533325
Validation loss: 2.8136201968757053

Epoch: 5| Step: 9
Training loss: 2.681307315826416
Validation loss: 2.8089947854318926

Epoch: 5| Step: 10
Training loss: 2.78857159614563
Validation loss: 2.8087779911615516

Epoch: 34| Step: 0
Training loss: 2.5370030403137207
Validation loss: 2.805262868122388

Epoch: 5| Step: 1
Training loss: 3.0508761405944824
Validation loss: 2.8062172500036096

Epoch: 5| Step: 2
Training loss: 2.948286533355713
Validation loss: 2.8056175119133404

Epoch: 5| Step: 3
Training loss: 2.979381561279297
Validation loss: 2.8037695756522556

Epoch: 5| Step: 4
Training loss: 3.6532325744628906
Validation loss: 2.8037741927690405

Epoch: 5| Step: 5
Training loss: 3.3365771770477295
Validation loss: 2.8023349341525825

Epoch: 5| Step: 6
Training loss: 2.8861262798309326
Validation loss: 2.801060832956786

Epoch: 5| Step: 7
Training loss: 3.3665554523468018
Validation loss: 2.801509521340811

Epoch: 5| Step: 8
Training loss: 2.240204095840454
Validation loss: 2.7972253804565756

Epoch: 5| Step: 9
Training loss: 2.2223353385925293
Validation loss: 2.793852949655184

Epoch: 5| Step: 10
Training loss: 3.0248148441314697
Validation loss: 2.797493088629938

Epoch: 35| Step: 0
Training loss: 2.748072385787964
Validation loss: 2.794796297627111

Epoch: 5| Step: 1
Training loss: 3.414274215698242
Validation loss: 2.813350469835343

Epoch: 5| Step: 2
Training loss: 2.784848928451538
Validation loss: 2.790825036264235

Epoch: 5| Step: 3
Training loss: 2.6465139389038086
Validation loss: 2.791216596480339

Epoch: 5| Step: 4
Training loss: 3.108396053314209
Validation loss: 2.78920506405574

Epoch: 5| Step: 5
Training loss: 3.1532950401306152
Validation loss: 2.789001428952781

Epoch: 5| Step: 6
Training loss: 3.1725285053253174
Validation loss: 2.7852006343103226

Epoch: 5| Step: 7
Training loss: 3.150731086730957
Validation loss: 2.784618400758313

Epoch: 5| Step: 8
Training loss: 2.805817127227783
Validation loss: 2.785307417633713

Epoch: 5| Step: 9
Training loss: 2.3001015186309814
Validation loss: 2.7820988316689768

Epoch: 5| Step: 10
Training loss: 2.8649823665618896
Validation loss: 2.779845094168058

Epoch: 36| Step: 0
Training loss: 2.991702079772949
Validation loss: 2.7803258716419177

Epoch: 5| Step: 1
Training loss: 3.078810214996338
Validation loss: 2.782855615820936

Epoch: 5| Step: 2
Training loss: 2.4237987995147705
Validation loss: 2.777738155857209

Epoch: 5| Step: 3
Training loss: 3.070758819580078
Validation loss: 2.7762678310435307

Epoch: 5| Step: 4
Training loss: 2.5964744091033936
Validation loss: 2.777120595337242

Epoch: 5| Step: 5
Training loss: 2.86205792427063
Validation loss: 2.7754848541751986

Epoch: 5| Step: 6
Training loss: 3.406986713409424
Validation loss: 2.7763777189357306

Epoch: 5| Step: 7
Training loss: 2.663853645324707
Validation loss: 2.772575168199437

Epoch: 5| Step: 8
Training loss: 2.5653131008148193
Validation loss: 2.769570360901535

Epoch: 5| Step: 9
Training loss: 3.151052474975586
Validation loss: 2.7784439312514437

Epoch: 5| Step: 10
Training loss: 3.319103956222534
Validation loss: 2.7828712027559996

Epoch: 37| Step: 0
Training loss: 2.4781880378723145
Validation loss: 2.777346821241481

Epoch: 5| Step: 1
Training loss: 2.7083029747009277
Validation loss: 2.764082754811933

Epoch: 5| Step: 2
Training loss: 3.623873233795166
Validation loss: 2.766041196802611

Epoch: 5| Step: 3
Training loss: 2.3454859256744385
Validation loss: 2.7636609077453613

Epoch: 5| Step: 4
Training loss: 3.400353193283081
Validation loss: 2.764312836431688

Epoch: 5| Step: 5
Training loss: 2.9863486289978027
Validation loss: 2.764058636080834

Epoch: 5| Step: 6
Training loss: 2.623131513595581
Validation loss: 2.761656843205934

Epoch: 5| Step: 7
Training loss: 2.919776201248169
Validation loss: 2.760275856141121

Epoch: 5| Step: 8
Training loss: 2.7135090827941895
Validation loss: 2.7602126521448933

Epoch: 5| Step: 9
Training loss: 2.495706558227539
Validation loss: 2.762230694934886

Epoch: 5| Step: 10
Training loss: 3.84213924407959
Validation loss: 2.761989665287797

Epoch: 38| Step: 0
Training loss: 2.5804593563079834
Validation loss: 2.7574531698739655

Epoch: 5| Step: 1
Training loss: 2.156266689300537
Validation loss: 2.7576609837111605

Epoch: 5| Step: 2
Training loss: 2.9884257316589355
Validation loss: 2.7536713077176

Epoch: 5| Step: 3
Training loss: 2.820404052734375
Validation loss: 2.753850265215802

Epoch: 5| Step: 4
Training loss: 3.506317138671875
Validation loss: 2.752786354352069

Epoch: 5| Step: 5
Training loss: 2.667630672454834
Validation loss: 2.7518322416531142

Epoch: 5| Step: 6
Training loss: 3.0289390087127686
Validation loss: 2.7504539976837816

Epoch: 5| Step: 7
Training loss: 2.881089925765991
Validation loss: 2.7483984321676274

Epoch: 5| Step: 8
Training loss: 2.2387218475341797
Validation loss: 2.7489380759577595

Epoch: 5| Step: 9
Training loss: 3.9941933155059814
Validation loss: 2.7494044829440374

Epoch: 5| Step: 10
Training loss: 3.0665440559387207
Validation loss: 2.748959287520378

Epoch: 39| Step: 0
Training loss: 2.4809789657592773
Validation loss: 2.7472690510493454

Epoch: 5| Step: 1
Training loss: 3.1229240894317627
Validation loss: 2.746979193020892

Epoch: 5| Step: 2
Training loss: 3.056913375854492
Validation loss: 2.7483408707444386

Epoch: 5| Step: 3
Training loss: 2.1606032848358154
Validation loss: 2.7476957459603586

Epoch: 5| Step: 4
Training loss: 3.4405581951141357
Validation loss: 2.7461604097838044

Epoch: 5| Step: 5
Training loss: 3.7105495929718018
Validation loss: 2.7414770818525747

Epoch: 5| Step: 6
Training loss: 3.2494144439697266
Validation loss: 2.7408159984055387

Epoch: 5| Step: 7
Training loss: 2.556696891784668
Validation loss: 2.7402602728976997

Epoch: 5| Step: 8
Training loss: 3.160266160964966
Validation loss: 2.7391606761563208

Epoch: 5| Step: 9
Training loss: 2.440812110900879
Validation loss: 2.7376420062075377

Epoch: 5| Step: 10
Training loss: 2.399576187133789
Validation loss: 2.7378983446346816

Epoch: 40| Step: 0
Training loss: 2.5780558586120605
Validation loss: 2.7385399469765286

Epoch: 5| Step: 1
Training loss: 2.6923131942749023
Validation loss: 2.738247717580488

Epoch: 5| Step: 2
Training loss: 3.0683982372283936
Validation loss: 2.7406184058035574

Epoch: 5| Step: 3
Training loss: 3.0159435272216797
Validation loss: 2.7400655592641523

Epoch: 5| Step: 4
Training loss: 2.426443099975586
Validation loss: 2.738509911362843

Epoch: 5| Step: 5
Training loss: 2.8696258068084717
Validation loss: 2.7405882522624028

Epoch: 5| Step: 6
Training loss: 2.7470898628234863
Validation loss: 2.732690939339258

Epoch: 5| Step: 7
Training loss: 2.829754590988159
Validation loss: 2.7327953487314205

Epoch: 5| Step: 8
Training loss: 2.984154462814331
Validation loss: 2.7314449305175454

Epoch: 5| Step: 9
Training loss: 3.751120090484619
Validation loss: 2.735715212360505

Epoch: 5| Step: 10
Training loss: 2.833695888519287
Validation loss: 2.736333444554319

Epoch: 41| Step: 0
Training loss: 2.436405897140503
Validation loss: 2.7337387479761595

Epoch: 5| Step: 1
Training loss: 2.040811061859131
Validation loss: 2.7349207401275635

Epoch: 5| Step: 2
Training loss: 2.9195823669433594
Validation loss: 2.7376066741122993

Epoch: 5| Step: 3
Training loss: 2.989264726638794
Validation loss: 2.742353682876915

Epoch: 5| Step: 4
Training loss: 3.5499229431152344
Validation loss: 2.7405186955646803

Epoch: 5| Step: 5
Training loss: 3.0354270935058594
Validation loss: 2.7397296249225573

Epoch: 5| Step: 6
Training loss: 2.4928789138793945
Validation loss: 2.733700054948048

Epoch: 5| Step: 7
Training loss: 3.1081490516662598
Validation loss: 2.7323677693643877

Epoch: 5| Step: 8
Training loss: 3.300696849822998
Validation loss: 2.7302021390648297

Epoch: 5| Step: 9
Training loss: 2.4735591411590576
Validation loss: 2.7278498680360856

Epoch: 5| Step: 10
Training loss: 3.5055196285247803
Validation loss: 2.7278115057176158

Epoch: 42| Step: 0
Training loss: 2.7433669567108154
Validation loss: 2.725978805172828

Epoch: 5| Step: 1
Training loss: 2.452529191970825
Validation loss: 2.7269597348346504

Epoch: 5| Step: 2
Training loss: 2.9152324199676514
Validation loss: 2.725051772209906

Epoch: 5| Step: 3
Training loss: 2.8435862064361572
Validation loss: 2.72743236121311

Epoch: 5| Step: 4
Training loss: 3.4312522411346436
Validation loss: 2.7243227856133574

Epoch: 5| Step: 5
Training loss: 2.3631093502044678
Validation loss: 2.724449837079612

Epoch: 5| Step: 6
Training loss: 2.6844985485076904
Validation loss: 2.7239125082569737

Epoch: 5| Step: 7
Training loss: 2.9539272785186768
Validation loss: 2.720430912510041

Epoch: 5| Step: 8
Training loss: 3.0754802227020264
Validation loss: 2.722564302464967

Epoch: 5| Step: 9
Training loss: 3.487145185470581
Validation loss: 2.721557460805421

Epoch: 5| Step: 10
Training loss: 2.706854820251465
Validation loss: 2.7199040100138676

Epoch: 43| Step: 0
Training loss: 2.8447887897491455
Validation loss: 2.7189719241152526

Epoch: 5| Step: 1
Training loss: 2.6798062324523926
Validation loss: 2.716918024965512

Epoch: 5| Step: 2
Training loss: 2.912764072418213
Validation loss: 2.7189413450097524

Epoch: 5| Step: 3
Training loss: 2.198700189590454
Validation loss: 2.7193501957001223

Epoch: 5| Step: 4
Training loss: 2.7534193992614746
Validation loss: 2.7184585422597904

Epoch: 5| Step: 5
Training loss: 3.201951265335083
Validation loss: 2.7191624564509236

Epoch: 5| Step: 6
Training loss: 3.232130527496338
Validation loss: 2.716044795128607

Epoch: 5| Step: 7
Training loss: 3.3234715461730957
Validation loss: 2.7178633828316965

Epoch: 5| Step: 8
Training loss: 3.165760040283203
Validation loss: 2.7161019796966226

Epoch: 5| Step: 9
Training loss: 2.5073845386505127
Validation loss: 2.7151250762324177

Epoch: 5| Step: 10
Training loss: 2.8168656826019287
Validation loss: 2.7144415327297744

Epoch: 44| Step: 0
Training loss: 2.867910146713257
Validation loss: 2.7160396806655394

Epoch: 5| Step: 1
Training loss: 3.2248966693878174
Validation loss: 2.713610610654277

Epoch: 5| Step: 2
Training loss: 2.5753798484802246
Validation loss: 2.716145182168612

Epoch: 5| Step: 3
Training loss: 2.5724918842315674
Validation loss: 2.717333306548416

Epoch: 5| Step: 4
Training loss: 2.4083361625671387
Validation loss: 2.721073781290362

Epoch: 5| Step: 5
Training loss: 2.8895058631896973
Validation loss: 2.719955177717311

Epoch: 5| Step: 6
Training loss: 3.1820998191833496
Validation loss: 2.7179119279307704

Epoch: 5| Step: 7
Training loss: 2.7177672386169434
Validation loss: 2.7240822956126225

Epoch: 5| Step: 8
Training loss: 2.888000011444092
Validation loss: 2.7127370603622927

Epoch: 5| Step: 9
Training loss: 3.254240036010742
Validation loss: 2.7133678261951735

Epoch: 5| Step: 10
Training loss: 3.075981855392456
Validation loss: 2.7134965542824037

Epoch: 45| Step: 0
Training loss: 3.2452940940856934
Validation loss: 2.714371181303455

Epoch: 5| Step: 1
Training loss: 3.7980637550354004
Validation loss: 2.7156982242420153

Epoch: 5| Step: 2
Training loss: 2.293642520904541
Validation loss: 2.713753713074551

Epoch: 5| Step: 3
Training loss: 3.6341500282287598
Validation loss: 2.71357887534685

Epoch: 5| Step: 4
Training loss: 2.5817179679870605
Validation loss: 2.710396617971441

Epoch: 5| Step: 5
Training loss: 2.6979787349700928
Validation loss: 2.707217167782527

Epoch: 5| Step: 6
Training loss: 1.9854400157928467
Validation loss: 2.7099556846003376

Epoch: 5| Step: 7
Training loss: 2.2437078952789307
Validation loss: 2.7125461998806206

Epoch: 5| Step: 8
Training loss: 3.0549023151397705
Validation loss: 2.717766110615064

Epoch: 5| Step: 9
Training loss: 2.729576349258423
Validation loss: 2.720194250024775

Epoch: 5| Step: 10
Training loss: 3.3731586933135986
Validation loss: 2.717805608626335

Epoch: 46| Step: 0
Training loss: 2.644120931625366
Validation loss: 2.712654559843002

Epoch: 5| Step: 1
Training loss: 3.3543922901153564
Validation loss: 2.712566016822733

Epoch: 5| Step: 2
Training loss: 2.9810855388641357
Validation loss: 2.7087871720713954

Epoch: 5| Step: 3
Training loss: 1.9756619930267334
Validation loss: 2.709611459444928

Epoch: 5| Step: 4
Training loss: 3.364691972732544
Validation loss: 2.707165279696065

Epoch: 5| Step: 5
Training loss: 2.873140811920166
Validation loss: 2.7055473917274067

Epoch: 5| Step: 6
Training loss: 3.0132415294647217
Validation loss: 2.7064185962882092

Epoch: 5| Step: 7
Training loss: 3.1120662689208984
Validation loss: 2.7060693425516926

Epoch: 5| Step: 8
Training loss: 2.948892593383789
Validation loss: 2.707366058903356

Epoch: 5| Step: 9
Training loss: 2.486867904663086
Validation loss: 2.70635897626159

Epoch: 5| Step: 10
Training loss: 2.7806427478790283
Validation loss: 2.7075533149062947

Epoch: 47| Step: 0
Training loss: 2.852933406829834
Validation loss: 2.7041007985350904

Epoch: 5| Step: 1
Training loss: 3.5404770374298096
Validation loss: 2.7038859321225073

Epoch: 5| Step: 2
Training loss: 2.2639660835266113
Validation loss: 2.7086231400889735

Epoch: 5| Step: 3
Training loss: 2.388637065887451
Validation loss: 2.707975951574182

Epoch: 5| Step: 4
Training loss: 2.7416319847106934
Validation loss: 2.70469751152941

Epoch: 5| Step: 5
Training loss: 2.52014422416687
Validation loss: 2.70299837153445

Epoch: 5| Step: 6
Training loss: 3.044950485229492
Validation loss: 2.7005030006490727

Epoch: 5| Step: 7
Training loss: 3.328587055206299
Validation loss: 2.7005897491208968

Epoch: 5| Step: 8
Training loss: 2.917092800140381
Validation loss: 2.699018463011711

Epoch: 5| Step: 9
Training loss: 3.4472286701202393
Validation loss: 2.699810392113142

Epoch: 5| Step: 10
Training loss: 2.3823442459106445
Validation loss: 2.701151976021387

Epoch: 48| Step: 0
Training loss: 2.366548776626587
Validation loss: 2.701510703691872

Epoch: 5| Step: 1
Training loss: 2.6560282707214355
Validation loss: 2.698867702996859

Epoch: 5| Step: 2
Training loss: 2.42321515083313
Validation loss: 2.6991036322809037

Epoch: 5| Step: 3
Training loss: 2.6428887844085693
Validation loss: 2.701798213425503

Epoch: 5| Step: 4
Training loss: 2.328770637512207
Validation loss: 2.711531833935809

Epoch: 5| Step: 5
Training loss: 3.2608742713928223
Validation loss: 2.7214774598357496

Epoch: 5| Step: 6
Training loss: 2.5820412635803223
Validation loss: 2.719812523934149

Epoch: 5| Step: 7
Training loss: 3.2357773780822754
Validation loss: 2.708720161068824

Epoch: 5| Step: 8
Training loss: 4.120009899139404
Validation loss: 2.697620758446314

Epoch: 5| Step: 9
Training loss: 3.0410332679748535
Validation loss: 2.698741489841092

Epoch: 5| Step: 10
Training loss: 2.9031143188476562
Validation loss: 2.6999016192651566

Epoch: 49| Step: 0
Training loss: 3.158864974975586
Validation loss: 2.7016770890963975

Epoch: 5| Step: 1
Training loss: 2.8830103874206543
Validation loss: 2.7093538725247948

Epoch: 5| Step: 2
Training loss: 2.382566452026367
Validation loss: 2.706397195016184

Epoch: 5| Step: 3
Training loss: 2.775442600250244
Validation loss: 2.7027415947247575

Epoch: 5| Step: 4
Training loss: 3.460479259490967
Validation loss: 2.6989775575617307

Epoch: 5| Step: 5
Training loss: 2.4679970741271973
Validation loss: 2.697118513045772

Epoch: 5| Step: 6
Training loss: 2.6738555431365967
Validation loss: 2.697342477818971

Epoch: 5| Step: 7
Training loss: 3.799746036529541
Validation loss: 2.700788510743008

Epoch: 5| Step: 8
Training loss: 2.4087328910827637
Validation loss: 2.700774413283153

Epoch: 5| Step: 9
Training loss: 2.4620940685272217
Validation loss: 2.7064779625144055

Epoch: 5| Step: 10
Training loss: 3.073096513748169
Validation loss: 2.7268737336640716

Epoch: 50| Step: 0
Training loss: 2.5525782108306885
Validation loss: 2.7285116975025465

Epoch: 5| Step: 1
Training loss: 3.7405147552490234
Validation loss: 2.7601167463487193

Epoch: 5| Step: 2
Training loss: 2.291229724884033
Validation loss: 2.7290074415104364

Epoch: 5| Step: 3
Training loss: 2.9922142028808594
Validation loss: 2.7275350350205616

Epoch: 5| Step: 4
Training loss: 2.8697052001953125
Validation loss: 2.737272770174088

Epoch: 5| Step: 5
Training loss: 2.763451337814331
Validation loss: 2.72465504113064

Epoch: 5| Step: 6
Training loss: 3.0452418327331543
Validation loss: 2.7005499691091557

Epoch: 5| Step: 7
Training loss: 2.444457769393921
Validation loss: 2.6945487837637625

Epoch: 5| Step: 8
Training loss: 3.6558127403259277
Validation loss: 2.6945965546433643

Epoch: 5| Step: 9
Training loss: 2.520761013031006
Validation loss: 2.697379796735702

Epoch: 5| Step: 10
Training loss: 2.7217519283294678
Validation loss: 2.6960022757130284

Testing loss: 2.7902911901474
