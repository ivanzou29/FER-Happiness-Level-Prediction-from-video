Epoch: 1| Step: 0
Training loss: 7.133586060274713
Validation loss: 5.810215107825396

Epoch: 6| Step: 1
Training loss: 6.509402004264677
Validation loss: 5.8062474651863845

Epoch: 6| Step: 2
Training loss: 5.901136657363304
Validation loss: 5.802252112214616

Epoch: 6| Step: 3
Training loss: 7.137792781029169
Validation loss: 5.798081935097832

Epoch: 6| Step: 4
Training loss: 5.761194361730284
Validation loss: 5.794130572153466

Epoch: 6| Step: 5
Training loss: 6.484219101100318
Validation loss: 5.790015648026152

Epoch: 6| Step: 6
Training loss: 5.571781601393135
Validation loss: 5.7856623765602935

Epoch: 6| Step: 7
Training loss: 6.095589541055676
Validation loss: 5.781315941006349

Epoch: 6| Step: 8
Training loss: 5.227653172938427
Validation loss: 5.776857198374003

Epoch: 6| Step: 9
Training loss: 3.923545937386017
Validation loss: 5.772063590367565

Epoch: 6| Step: 10
Training loss: 5.619650607125588
Validation loss: 5.7669392305757246

Epoch: 6| Step: 11
Training loss: 5.683467567327818
Validation loss: 5.761837616381398

Epoch: 6| Step: 12
Training loss: 4.587622052058048
Validation loss: 5.756771606942007

Epoch: 6| Step: 13
Training loss: 4.0666820421605685
Validation loss: 5.75100886414547

Epoch: 2| Step: 0
Training loss: 6.526623415051944
Validation loss: 5.745604148692134

Epoch: 6| Step: 1
Training loss: 6.273767674024654
Validation loss: 5.739853867553674

Epoch: 6| Step: 2
Training loss: 5.8646343583574385
Validation loss: 5.733191597715952

Epoch: 6| Step: 3
Training loss: 6.242148694047869
Validation loss: 5.7271710822441975

Epoch: 6| Step: 4
Training loss: 4.213877484959898
Validation loss: 5.720249676250954

Epoch: 6| Step: 5
Training loss: 5.331468355418524
Validation loss: 5.713305591103274

Epoch: 6| Step: 6
Training loss: 5.4596602401939345
Validation loss: 5.705883172447947

Epoch: 6| Step: 7
Training loss: 5.9447208867110355
Validation loss: 5.698061190651082

Epoch: 6| Step: 8
Training loss: 5.043606765774238
Validation loss: 5.689537944420331

Epoch: 6| Step: 9
Training loss: 6.337819902821906
Validation loss: 5.681345468674247

Epoch: 6| Step: 10
Training loss: 5.495693601615887
Validation loss: 5.672137340785168

Epoch: 6| Step: 11
Training loss: 5.910814892765058
Validation loss: 5.662476814155727

Epoch: 6| Step: 12
Training loss: 6.0716402032976875
Validation loss: 5.653169342236976

Epoch: 6| Step: 13
Training loss: 4.624638929964581
Validation loss: 5.641972733687408

Epoch: 3| Step: 0
Training loss: 4.789322166186301
Validation loss: 5.631531392478727

Epoch: 6| Step: 1
Training loss: 5.061497153335912
Validation loss: 5.619805292464276

Epoch: 6| Step: 2
Training loss: 4.5182804101095675
Validation loss: 5.608213493352674

Epoch: 6| Step: 3
Training loss: 5.729634250864678
Validation loss: 5.595533755576362

Epoch: 6| Step: 4
Training loss: 7.009378145636415
Validation loss: 5.5840205450886184

Epoch: 6| Step: 5
Training loss: 5.356280175639274
Validation loss: 5.570043511353567

Epoch: 6| Step: 6
Training loss: 5.418842797986218
Validation loss: 5.555703587080937

Epoch: 6| Step: 7
Training loss: 5.039895537368596
Validation loss: 5.539800719142093

Epoch: 6| Step: 8
Training loss: 6.962533684311752
Validation loss: 5.525574825394174

Epoch: 6| Step: 9
Training loss: 6.0029747264507325
Validation loss: 5.507972104178924

Epoch: 6| Step: 10
Training loss: 4.659257775001938
Validation loss: 5.490608884328414

Epoch: 6| Step: 11
Training loss: 5.732685723804345
Validation loss: 5.473378814927573

Epoch: 6| Step: 12
Training loss: 5.071687626506524
Validation loss: 5.455558348883754

Epoch: 6| Step: 13
Training loss: 6.466387183583103
Validation loss: 5.436038203500219

Epoch: 4| Step: 0
Training loss: 5.557801566168171
Validation loss: 5.41793355522155

Epoch: 6| Step: 1
Training loss: 5.978006106289616
Validation loss: 5.397336572354375

Epoch: 6| Step: 2
Training loss: 5.389713464597979
Validation loss: 5.377118768356857

Epoch: 6| Step: 3
Training loss: 4.504623580939592
Validation loss: 5.35637122050916

Epoch: 6| Step: 4
Training loss: 5.361081933099717
Validation loss: 5.334313796017444

Epoch: 6| Step: 5
Training loss: 4.736440075996514
Validation loss: 5.312093981018734

Epoch: 6| Step: 6
Training loss: 4.811974434826705
Validation loss: 5.29085454440956

Epoch: 6| Step: 7
Training loss: 5.961919101272441
Validation loss: 5.268981580428253

Epoch: 6| Step: 8
Training loss: 4.0070305074392465
Validation loss: 5.245869646172566

Epoch: 6| Step: 9
Training loss: 6.259246699922306
Validation loss: 5.22223964847673

Epoch: 6| Step: 10
Training loss: 4.915731416533767
Validation loss: 5.200888717833912

Epoch: 6| Step: 11
Training loss: 5.293105863364735
Validation loss: 5.175153016102065

Epoch: 6| Step: 12
Training loss: 5.967004970286994
Validation loss: 5.150727155168648

Epoch: 6| Step: 13
Training loss: 5.3217846686357175
Validation loss: 5.126933657717137

Epoch: 5| Step: 0
Training loss: 4.894767006617605
Validation loss: 5.1020586688072775

Epoch: 6| Step: 1
Training loss: 4.928599774138957
Validation loss: 5.0780024476010155

Epoch: 6| Step: 2
Training loss: 5.5991675711872
Validation loss: 5.052775312030875

Epoch: 6| Step: 3
Training loss: 5.0468277589458905
Validation loss: 5.027171775096633

Epoch: 6| Step: 4
Training loss: 3.911683842659618
Validation loss: 5.001510055740702

Epoch: 6| Step: 5
Training loss: 4.982597584244933
Validation loss: 4.9788572394002415

Epoch: 6| Step: 6
Training loss: 6.093853915380002
Validation loss: 4.952873045783417

Epoch: 6| Step: 7
Training loss: 4.33141215847916
Validation loss: 4.928947505909242

Epoch: 6| Step: 8
Training loss: 5.828967322466881
Validation loss: 4.9045646118286355

Epoch: 6| Step: 9
Training loss: 5.278604601068717
Validation loss: 4.878531523877763

Epoch: 6| Step: 10
Training loss: 2.4087708384904656
Validation loss: 4.855377149146441

Epoch: 6| Step: 11
Training loss: 4.848710602504127
Validation loss: 4.829428060781879

Epoch: 6| Step: 12
Training loss: 5.807795107335404
Validation loss: 4.8081880580603675

Epoch: 6| Step: 13
Training loss: 5.05870271661113
Validation loss: 4.783719623842361

Epoch: 6| Step: 0
Training loss: 4.414940238712339
Validation loss: 4.763219233198985

Epoch: 6| Step: 1
Training loss: 5.2890455507714025
Validation loss: 4.739415581768169

Epoch: 6| Step: 2
Training loss: 3.3999958543191204
Validation loss: 4.714628542210245

Epoch: 6| Step: 3
Training loss: 4.351606769439316
Validation loss: 4.695723646208624

Epoch: 6| Step: 4
Training loss: 5.062003782466107
Validation loss: 4.6730183161218335

Epoch: 6| Step: 5
Training loss: 4.56021269854346
Validation loss: 4.65352810987949

Epoch: 6| Step: 6
Training loss: 4.537389765469687
Validation loss: 4.633774325021249

Epoch: 6| Step: 7
Training loss: 4.940672036609984
Validation loss: 4.614905296291404

Epoch: 6| Step: 8
Training loss: 4.500287788513459
Validation loss: 4.592744582330651

Epoch: 6| Step: 9
Training loss: 4.640258774611749
Validation loss: 4.5758227681188925

Epoch: 6| Step: 10
Training loss: 5.0462952271958414
Validation loss: 4.556865292434486

Epoch: 6| Step: 11
Training loss: 5.122727797559677
Validation loss: 4.537603128336396

Epoch: 6| Step: 12
Training loss: 4.757781631544979
Validation loss: 4.520002363690567

Epoch: 6| Step: 13
Training loss: 5.294264968991413
Validation loss: 4.502755750107073

Epoch: 7| Step: 0
Training loss: 4.277717859638469
Validation loss: 4.486679840297716

Epoch: 6| Step: 1
Training loss: 4.237032236033785
Validation loss: 4.471825913675044

Epoch: 6| Step: 2
Training loss: 4.4292687381288385
Validation loss: 4.4554615763762495

Epoch: 6| Step: 3
Training loss: 5.235987901573105
Validation loss: 4.438965189979933

Epoch: 6| Step: 4
Training loss: 4.8493963986787625
Validation loss: 4.424628532960482

Epoch: 6| Step: 5
Training loss: 4.77949980572699
Validation loss: 4.409451106982502

Epoch: 6| Step: 6
Training loss: 3.7094643971726704
Validation loss: 4.395955712981177

Epoch: 6| Step: 7
Training loss: 4.4383514017350185
Validation loss: 4.381540400429549

Epoch: 6| Step: 8
Training loss: 4.392131723370721
Validation loss: 4.369655106515722

Epoch: 6| Step: 9
Training loss: 4.837445888167356
Validation loss: 4.356258846844876

Epoch: 6| Step: 10
Training loss: 4.239834239886492
Validation loss: 4.344671086073436

Epoch: 6| Step: 11
Training loss: 4.572187198974984
Validation loss: 4.332551622205041

Epoch: 6| Step: 12
Training loss: 4.7250479801708885
Validation loss: 4.322834700948815

Epoch: 6| Step: 13
Training loss: 3.828751368757471
Validation loss: 4.3096962342531

Epoch: 8| Step: 0
Training loss: 4.154034475801502
Validation loss: 4.301140785231022

Epoch: 6| Step: 1
Training loss: 4.9292309242804615
Validation loss: 4.291402280369449

Epoch: 6| Step: 2
Training loss: 4.055952694287839
Validation loss: 4.2805669060099

Epoch: 6| Step: 3
Training loss: 4.774636475471237
Validation loss: 4.27332076481491

Epoch: 6| Step: 4
Training loss: 5.194912497817971
Validation loss: 4.264705184514303

Epoch: 6| Step: 5
Training loss: 3.8391835449413
Validation loss: 4.256365343346719

Epoch: 6| Step: 6
Training loss: 2.7898869511387514
Validation loss: 4.248648576415794

Epoch: 6| Step: 7
Training loss: 4.954803086264602
Validation loss: 4.2411974664921255

Epoch: 6| Step: 8
Training loss: 3.6050238205629337
Validation loss: 4.233797709450904

Epoch: 6| Step: 9
Training loss: 4.278320201045707
Validation loss: 4.227559036530877

Epoch: 6| Step: 10
Training loss: 5.0607786666570025
Validation loss: 4.2203254641405055

Epoch: 6| Step: 11
Training loss: 4.580621136520449
Validation loss: 4.213400587483894

Epoch: 6| Step: 12
Training loss: 4.318535603171447
Validation loss: 4.206454414486526

Epoch: 6| Step: 13
Training loss: 3.7543510625999157
Validation loss: 4.201136001212012

Epoch: 9| Step: 0
Training loss: 4.098362777209124
Validation loss: 4.193494741981745

Epoch: 6| Step: 1
Training loss: 4.274671414780989
Validation loss: 4.185868091119037

Epoch: 6| Step: 2
Training loss: 5.19040166752197
Validation loss: 4.180931369766113

Epoch: 6| Step: 3
Training loss: 4.521973262581281
Validation loss: 4.1734846327531745

Epoch: 6| Step: 4
Training loss: 5.040628541778436
Validation loss: 4.166387993302169

Epoch: 6| Step: 5
Training loss: 4.399240532267154
Validation loss: 4.160131664551072

Epoch: 6| Step: 6
Training loss: 4.32522033835755
Validation loss: 4.1536565253243936

Epoch: 6| Step: 7
Training loss: 3.4429490336629844
Validation loss: 4.146891964544816

Epoch: 6| Step: 8
Training loss: 4.785099050997424
Validation loss: 4.137569764738781

Epoch: 6| Step: 9
Training loss: 3.3579277292168683
Validation loss: 4.131135182203636

Epoch: 6| Step: 10
Training loss: 3.2675051592645286
Validation loss: 4.124722300827799

Epoch: 6| Step: 11
Training loss: 2.5264312653438803
Validation loss: 4.11668134695598

Epoch: 6| Step: 12
Training loss: 5.439781499569769
Validation loss: 4.109620974873599

Epoch: 6| Step: 13
Training loss: 4.374137793457955
Validation loss: 4.1031708826018995

Epoch: 10| Step: 0
Training loss: 4.190829419548699
Validation loss: 4.095329189864744

Epoch: 6| Step: 1
Training loss: 4.093856693653776
Validation loss: 4.08808359600649

Epoch: 6| Step: 2
Training loss: 4.637750936541294
Validation loss: 4.079351085980615

Epoch: 6| Step: 3
Training loss: 3.5259751614600745
Validation loss: 4.0720081212421535

Epoch: 6| Step: 4
Training loss: 3.8892405547735804
Validation loss: 4.065590443229043

Epoch: 6| Step: 5
Training loss: 3.38251760135647
Validation loss: 4.0579655307630045

Epoch: 6| Step: 6
Training loss: 4.443722512633649
Validation loss: 4.051232675267513

Epoch: 6| Step: 7
Training loss: 4.143485294132275
Validation loss: 4.044162625688975

Epoch: 6| Step: 8
Training loss: 4.127304127214338
Validation loss: 4.036468991501386

Epoch: 6| Step: 9
Training loss: 5.45910980681031
Validation loss: 4.0299582103656295

Epoch: 6| Step: 10
Training loss: 4.810745117464141
Validation loss: 4.020423853432444

Epoch: 6| Step: 11
Training loss: 3.34752776746223
Validation loss: 4.012006970057688

Epoch: 6| Step: 12
Training loss: 4.001614721539128
Validation loss: 4.005858619832144

Epoch: 6| Step: 13
Training loss: 4.119781429826225
Validation loss: 3.995231192986484

Epoch: 11| Step: 0
Training loss: 3.8445738863116636
Validation loss: 3.9894921736753988

Epoch: 6| Step: 1
Training loss: 4.074768087890742
Validation loss: 3.981584578543363

Epoch: 6| Step: 2
Training loss: 5.1419316170476765
Validation loss: 3.976610153734364

Epoch: 6| Step: 3
Training loss: 3.917189881027709
Validation loss: 3.9694854827399593

Epoch: 6| Step: 4
Training loss: 5.364352125598859
Validation loss: 3.963718655440387

Epoch: 6| Step: 5
Training loss: 3.6088444043170265
Validation loss: 3.9563857480948936

Epoch: 6| Step: 6
Training loss: 3.841924962913031
Validation loss: 3.9507134081614996

Epoch: 6| Step: 7
Training loss: 3.554684280561729
Validation loss: 3.9456402788973417

Epoch: 6| Step: 8
Training loss: 3.2950144937338313
Validation loss: 3.938695316954183

Epoch: 6| Step: 9
Training loss: 3.7565706544626862
Validation loss: 3.9350229399696324

Epoch: 6| Step: 10
Training loss: 3.6459211211761535
Validation loss: 3.9272962673325327

Epoch: 6| Step: 11
Training loss: 3.6762378502275004
Validation loss: 3.9246291572254655

Epoch: 6| Step: 12
Training loss: 4.885942746639332
Validation loss: 3.916890034342274

Epoch: 6| Step: 13
Training loss: 4.350504063307882
Validation loss: 3.9121416698067684

Epoch: 12| Step: 0
Training loss: 3.125400975251578
Validation loss: 3.907339738999045

Epoch: 6| Step: 1
Training loss: 3.776326149933799
Validation loss: 3.900685629094287

Epoch: 6| Step: 2
Training loss: 4.888644563946884
Validation loss: 3.896326216931434

Epoch: 6| Step: 3
Training loss: 4.06362453448886
Validation loss: 3.892997785472153

Epoch: 6| Step: 4
Training loss: 3.8942464496698976
Validation loss: 3.887711374723138

Epoch: 6| Step: 5
Training loss: 3.902187462656475
Validation loss: 3.8842010897083523

Epoch: 6| Step: 6
Training loss: 4.511547108477503
Validation loss: 3.8806187055573838

Epoch: 6| Step: 7
Training loss: 4.085418843306539
Validation loss: 3.872853628424194

Epoch: 6| Step: 8
Training loss: 3.958463178144651
Validation loss: 3.8710235221451756

Epoch: 6| Step: 9
Training loss: 4.875048514882794
Validation loss: 3.8698295357665518

Epoch: 6| Step: 10
Training loss: 3.420321177074706
Validation loss: 3.865413054741391

Epoch: 6| Step: 11
Training loss: 3.8265838634911757
Validation loss: 3.862525377177915

Epoch: 6| Step: 12
Training loss: 4.026161945449577
Validation loss: 3.8581600813601837

Epoch: 6| Step: 13
Training loss: 3.705980962087828
Validation loss: 3.8552452398553716

Epoch: 13| Step: 0
Training loss: 3.676771170501963
Validation loss: 3.848746225281088

Epoch: 6| Step: 1
Training loss: 3.630126485170984
Validation loss: 3.8450461369187034

Epoch: 6| Step: 2
Training loss: 4.127642392082791
Validation loss: 3.8381183946509587

Epoch: 6| Step: 3
Training loss: 2.936920758215833
Validation loss: 3.832040818069831

Epoch: 6| Step: 4
Training loss: 4.422061336621615
Validation loss: 3.8277205206031977

Epoch: 6| Step: 5
Training loss: 3.9143249058277965
Validation loss: 3.823794555365859

Epoch: 6| Step: 6
Training loss: 4.062010750287254
Validation loss: 3.819141793638591

Epoch: 6| Step: 7
Training loss: 4.035129070652052
Validation loss: 3.8167816439978983

Epoch: 6| Step: 8
Training loss: 4.371440638464079
Validation loss: 3.809296267673505

Epoch: 6| Step: 9
Training loss: 4.137132085479045
Validation loss: 3.8059841039759736

Epoch: 6| Step: 10
Training loss: 4.505826568814794
Validation loss: 3.803239260932251

Epoch: 6| Step: 11
Training loss: 3.4382883728411224
Validation loss: 3.7994393040280183

Epoch: 6| Step: 12
Training loss: 3.9692143446446564
Validation loss: 3.7947247539454048

Epoch: 6| Step: 13
Training loss: 4.55747960456976
Validation loss: 3.7913240203318357

Epoch: 14| Step: 0
Training loss: 4.404070375966402
Validation loss: 3.788528804999755

Epoch: 6| Step: 1
Training loss: 4.742834408421615
Validation loss: 3.783369982799718

Epoch: 6| Step: 2
Training loss: 3.598073862629151
Validation loss: 3.7807459341442646

Epoch: 6| Step: 3
Training loss: 3.0068513201437472
Validation loss: 3.7800819018544853

Epoch: 6| Step: 4
Training loss: 2.97699788431202
Validation loss: 3.7764495749230216

Epoch: 6| Step: 5
Training loss: 4.252569207419393
Validation loss: 3.7733236105577044

Epoch: 6| Step: 6
Training loss: 4.167525520818655
Validation loss: 3.7672502709353073

Epoch: 6| Step: 7
Training loss: 4.076223814504976
Validation loss: 3.763915445110238

Epoch: 6| Step: 8
Training loss: 3.1065108560065147
Validation loss: 3.7598184143715825

Epoch: 6| Step: 9
Training loss: 4.237356339891738
Validation loss: 3.761069170647513

Epoch: 6| Step: 10
Training loss: 4.26483102193157
Validation loss: 3.7577687260235666

Epoch: 6| Step: 11
Training loss: 3.298543643372985
Validation loss: 3.7522583604514375

Epoch: 6| Step: 12
Training loss: 4.6776646491410885
Validation loss: 3.747899285394801

Epoch: 6| Step: 13
Training loss: 3.7049121005072916
Validation loss: 3.7450766960325614

Epoch: 15| Step: 0
Training loss: 2.8566040620950823
Validation loss: 3.741562841475735

Epoch: 6| Step: 1
Training loss: 4.284551753454187
Validation loss: 3.7387209630978453

Epoch: 6| Step: 2
Training loss: 4.171024078570354
Validation loss: 3.735576861693706

Epoch: 6| Step: 3
Training loss: 3.880278407067903
Validation loss: 3.7316985580759034

Epoch: 6| Step: 4
Training loss: 4.249226668066947
Validation loss: 3.73055975150741

Epoch: 6| Step: 5
Training loss: 4.194269203303511
Validation loss: 3.725687470596321

Epoch: 6| Step: 6
Training loss: 3.7149197383132484
Validation loss: 3.7246735747406325

Epoch: 6| Step: 7
Training loss: 4.415183892054688
Validation loss: 3.7208964894376977

Epoch: 6| Step: 8
Training loss: 3.1565019865762425
Validation loss: 3.7160263904084925

Epoch: 6| Step: 9
Training loss: 5.1087970931773965
Validation loss: 3.7179126894702783

Epoch: 6| Step: 10
Training loss: 3.2655889335721433
Validation loss: 3.715055496476366

Epoch: 6| Step: 11
Training loss: 3.919364216685802
Validation loss: 3.7101405294722696

Epoch: 6| Step: 12
Training loss: 3.7323996454891404
Validation loss: 3.711170267729029

Epoch: 6| Step: 13
Training loss: 2.372289013821903
Validation loss: 3.707923294539592

Epoch: 16| Step: 0
Training loss: 3.2385156636356234
Validation loss: 3.708079647518329

Epoch: 6| Step: 1
Training loss: 4.179853147272482
Validation loss: 3.7054421945288296

Epoch: 6| Step: 2
Training loss: 4.774691602723997
Validation loss: 3.7005611426517295

Epoch: 6| Step: 3
Training loss: 4.62887617012906
Validation loss: 3.6943703761018494

Epoch: 6| Step: 4
Training loss: 3.0910089854045335
Validation loss: 3.692818382790892

Epoch: 6| Step: 5
Training loss: 4.51337141673607
Validation loss: 3.691820506741795

Epoch: 6| Step: 6
Training loss: 2.7539850318407737
Validation loss: 3.689544154252996

Epoch: 6| Step: 7
Training loss: 3.9698350279231733
Validation loss: 3.687120741050518

Epoch: 6| Step: 8
Training loss: 3.957168621905979
Validation loss: 3.68619734869933

Epoch: 6| Step: 9
Training loss: 3.382616138705883
Validation loss: 3.6811215711087613

Epoch: 6| Step: 10
Training loss: 4.466897220260075
Validation loss: 3.674122282768174

Epoch: 6| Step: 11
Training loss: 2.9195635623588196
Validation loss: 3.6727375414680137

Epoch: 6| Step: 12
Training loss: 4.126153264522429
Validation loss: 3.6769175433569568

Epoch: 6| Step: 13
Training loss: 3.2419220229695744
Validation loss: 3.6773907226393434

Epoch: 17| Step: 0
Training loss: 3.7044525985867036
Validation loss: 3.6681912646805235

Epoch: 6| Step: 1
Training loss: 2.6990106394764055
Validation loss: 3.6647445114295873

Epoch: 6| Step: 2
Training loss: 3.643262178145577
Validation loss: 3.665726182157288

Epoch: 6| Step: 3
Training loss: 2.8893560150070674
Validation loss: 3.662204617657093

Epoch: 6| Step: 4
Training loss: 4.14787929536598
Validation loss: 3.666928376136532

Epoch: 6| Step: 5
Training loss: 3.4069815033952766
Validation loss: 3.6565303451356668

Epoch: 6| Step: 6
Training loss: 3.6290037472606493
Validation loss: 3.6529648708981446

Epoch: 6| Step: 7
Training loss: 4.529852500349957
Validation loss: 3.6515290273818173

Epoch: 6| Step: 8
Training loss: 3.3855683904051976
Validation loss: 3.653501321805985

Epoch: 6| Step: 9
Training loss: 4.989909671738006
Validation loss: 3.6524025055605107

Epoch: 6| Step: 10
Training loss: 3.2113326449096187
Validation loss: 3.6504875428375883

Epoch: 6| Step: 11
Training loss: 4.156360366617936
Validation loss: 3.648252612096283

Epoch: 6| Step: 12
Training loss: 4.944054996616675
Validation loss: 3.643795235292785

Epoch: 6| Step: 13
Training loss: 3.5994269603721922
Validation loss: 3.642362018700066

Epoch: 18| Step: 0
Training loss: 3.896614581157828
Validation loss: 3.6406396433098167

Epoch: 6| Step: 1
Training loss: 3.7859132873793695
Validation loss: 3.638208998706227

Epoch: 6| Step: 2
Training loss: 3.2940878996988503
Validation loss: 3.6351691505932062

Epoch: 6| Step: 3
Training loss: 3.399808479973613
Validation loss: 3.6323112587463453

Epoch: 6| Step: 4
Training loss: 3.655431672161151
Validation loss: 3.6286532812366894

Epoch: 6| Step: 5
Training loss: 3.8776335842160154
Validation loss: 3.6267119945251687

Epoch: 6| Step: 6
Training loss: 3.4998514961345313
Validation loss: 3.62621272094761

Epoch: 6| Step: 7
Training loss: 3.6146830051249395
Validation loss: 3.622688042756786

Epoch: 6| Step: 8
Training loss: 5.0758421476332805
Validation loss: 3.620792804601977

Epoch: 6| Step: 9
Training loss: 3.9327186739993545
Validation loss: 3.6170784688356767

Epoch: 6| Step: 10
Training loss: 3.91278286724875
Validation loss: 3.615102612140247

Epoch: 6| Step: 11
Training loss: 2.716658039508375
Validation loss: 3.6132310436677395

Epoch: 6| Step: 12
Training loss: 4.296420430500837
Validation loss: 3.6126454294502275

Epoch: 6| Step: 13
Training loss: 4.214124163840182
Validation loss: 3.60916134292877

Epoch: 19| Step: 0
Training loss: 2.709864423253187
Validation loss: 3.607868310708445

Epoch: 6| Step: 1
Training loss: 3.9482353034892372
Validation loss: 3.6045596638569544

Epoch: 6| Step: 2
Training loss: 3.4253018434155345
Validation loss: 3.6032898733996515

Epoch: 6| Step: 3
Training loss: 3.575468984933199
Validation loss: 3.6005412331815996

Epoch: 6| Step: 4
Training loss: 3.734446121879286
Validation loss: 3.598769030851685

Epoch: 6| Step: 5
Training loss: 3.317309936046373
Validation loss: 3.597283228776589

Epoch: 6| Step: 6
Training loss: 3.164914164893351
Validation loss: 3.596305316064192

Epoch: 6| Step: 7
Training loss: 5.087629701802797
Validation loss: 3.598892252385013

Epoch: 6| Step: 8
Training loss: 4.068265608917057
Validation loss: 3.5948633867051414

Epoch: 6| Step: 9
Training loss: 3.6526098144232293
Validation loss: 3.5905970256300472

Epoch: 6| Step: 10
Training loss: 4.489454416546843
Validation loss: 3.5887812595434223

Epoch: 6| Step: 11
Training loss: 3.7043070133999323
Validation loss: 3.5894082327750167

Epoch: 6| Step: 12
Training loss: 4.058378975759739
Validation loss: 3.5891646599249287

Epoch: 6| Step: 13
Training loss: 3.5095025899627257
Validation loss: 3.584712077809232

Epoch: 20| Step: 0
Training loss: 3.465357865958458
Validation loss: 3.5832103518315517

Epoch: 6| Step: 1
Training loss: 3.5884195352191175
Validation loss: 3.579817063790697

Epoch: 6| Step: 2
Training loss: 3.9303412377137237
Validation loss: 3.575727564595718

Epoch: 6| Step: 3
Training loss: 4.025112951364251
Validation loss: 3.573760707731164

Epoch: 6| Step: 4
Training loss: 3.335774116177922
Validation loss: 3.571561676187775

Epoch: 6| Step: 5
Training loss: 4.622335749132678
Validation loss: 3.5700803733177913

Epoch: 6| Step: 6
Training loss: 3.614768486154555
Validation loss: 3.567632955723887

Epoch: 6| Step: 7
Training loss: 3.3987797005784244
Validation loss: 3.566847105774248

Epoch: 6| Step: 8
Training loss: 3.5521016199679734
Validation loss: 3.56329898765377

Epoch: 6| Step: 9
Training loss: 4.899879352874874
Validation loss: 3.562208070507495

Epoch: 6| Step: 10
Training loss: 3.827805112591349
Validation loss: 3.559144796666522

Epoch: 6| Step: 11
Training loss: 3.5167947815131777
Validation loss: 3.5595225017116348

Epoch: 6| Step: 12
Training loss: 3.1879439699234196
Validation loss: 3.557353123125416

Epoch: 6| Step: 13
Training loss: 3.1078105422100575
Validation loss: 3.5552827560482476

Epoch: 21| Step: 0
Training loss: 4.393600161779836
Validation loss: 3.553665692560342

Epoch: 6| Step: 1
Training loss: 4.167554811553149
Validation loss: 3.5528005620994185

Epoch: 6| Step: 2
Training loss: 3.0725749369981585
Validation loss: 3.5497925387649674

Epoch: 6| Step: 3
Training loss: 3.7894518465394453
Validation loss: 3.54643140704722

Epoch: 6| Step: 4
Training loss: 3.938241676838534
Validation loss: 3.5467469744904494

Epoch: 6| Step: 5
Training loss: 3.919736484311836
Validation loss: 3.54535148555531

Epoch: 6| Step: 6
Training loss: 3.570371531326131
Validation loss: 3.5414659755723097

Epoch: 6| Step: 7
Training loss: 3.632230453624509
Validation loss: 3.5406610242234664

Epoch: 6| Step: 8
Training loss: 3.869914501734169
Validation loss: 3.5394914238530264

Epoch: 6| Step: 9
Training loss: 3.9083158599744885
Validation loss: 3.537731640186413

Epoch: 6| Step: 10
Training loss: 3.5236759485729894
Validation loss: 3.5358262294648726

Epoch: 6| Step: 11
Training loss: 2.9902184284764215
Validation loss: 3.5355902861835147

Epoch: 6| Step: 12
Training loss: 3.487033531139332
Validation loss: 3.5289224294713892

Epoch: 6| Step: 13
Training loss: 4.1059226267009805
Validation loss: 3.529589016360398

Epoch: 22| Step: 0
Training loss: 4.445040461524489
Validation loss: 3.527796707757101

Epoch: 6| Step: 1
Training loss: 3.7886343487966525
Validation loss: 3.5239423852075835

Epoch: 6| Step: 2
Training loss: 3.5194914177303427
Validation loss: 3.525005943452166

Epoch: 6| Step: 3
Training loss: 3.614075873350608
Validation loss: 3.520780134930789

Epoch: 6| Step: 4
Training loss: 4.231793169011568
Validation loss: 3.5197609913204864

Epoch: 6| Step: 5
Training loss: 4.210775566880024
Validation loss: 3.5192208750252507

Epoch: 6| Step: 6
Training loss: 3.7985750638718647
Validation loss: 3.5140031660913618

Epoch: 6| Step: 7
Training loss: 4.023633755832434
Validation loss: 3.511513281520798

Epoch: 6| Step: 8
Training loss: 3.221045110993583
Validation loss: 3.509031227170911

Epoch: 6| Step: 9
Training loss: 2.6093088472855146
Validation loss: 3.5067174132917525

Epoch: 6| Step: 10
Training loss: 3.7602046720112243
Validation loss: 3.504056112573879

Epoch: 6| Step: 11
Training loss: 4.214279405713844
Validation loss: 3.499361857530458

Epoch: 6| Step: 12
Training loss: 2.0704952519207374
Validation loss: 3.495957310463218

Epoch: 6| Step: 13
Training loss: 3.9763804695720384
Validation loss: 3.4871402323945313

Epoch: 23| Step: 0
Training loss: 3.3754537771837874
Validation loss: 3.4510918725604354

Epoch: 6| Step: 1
Training loss: 3.564861920051491
Validation loss: 3.4468141290040237

Epoch: 6| Step: 2
Training loss: 3.6425207875011405
Validation loss: 3.47025179278381

Epoch: 6| Step: 3
Training loss: 4.591923564686784
Validation loss: 3.4558410727798576

Epoch: 6| Step: 4
Training loss: 3.632116501288287
Validation loss: 3.457776416325813

Epoch: 6| Step: 5
Training loss: 2.729959290309217
Validation loss: 3.4549480439181566

Epoch: 6| Step: 6
Training loss: 4.503910908361641
Validation loss: 3.459217477914423

Epoch: 6| Step: 7
Training loss: 4.0228102704358095
Validation loss: 3.4390686363992953

Epoch: 6| Step: 8
Training loss: 3.03862973149767
Validation loss: 3.4377813677145466

Epoch: 6| Step: 9
Training loss: 3.4858545831234293
Validation loss: 3.432044433361667

Epoch: 6| Step: 10
Training loss: 4.209571631015487
Validation loss: 3.434780332955198

Epoch: 6| Step: 11
Training loss: 2.602203381845993
Validation loss: 3.434635926891489

Epoch: 6| Step: 12
Training loss: 3.718362611740568
Validation loss: 3.438270594342427

Epoch: 6| Step: 13
Training loss: 3.5934239778663177
Validation loss: 3.441999098047124

Epoch: 24| Step: 0
Training loss: 3.252415273092072
Validation loss: 3.437195774312442

Epoch: 6| Step: 1
Training loss: 2.432038669103083
Validation loss: 3.4298155059461246

Epoch: 6| Step: 2
Training loss: 3.090146827542582
Validation loss: 3.425044122598396

Epoch: 6| Step: 3
Training loss: 3.4423087037678846
Validation loss: 3.416256006284035

Epoch: 6| Step: 4
Training loss: 3.6145595289576993
Validation loss: 3.4168779041250907

Epoch: 6| Step: 5
Training loss: 3.4648443004861456
Validation loss: 3.4091978493129225

Epoch: 6| Step: 6
Training loss: 4.0395103811307
Validation loss: 3.4059925266152784

Epoch: 6| Step: 7
Training loss: 4.622546808347248
Validation loss: 3.404542799025691

Epoch: 6| Step: 8
Training loss: 3.8635505605543665
Validation loss: 3.4006488677932607

Epoch: 6| Step: 9
Training loss: 4.015839211060597
Validation loss: 3.3964056235754603

Epoch: 6| Step: 10
Training loss: 4.167756637424256
Validation loss: 3.392168835560327

Epoch: 6| Step: 11
Training loss: 3.2337163724503752
Validation loss: 3.394607223445426

Epoch: 6| Step: 12
Training loss: 3.258505182702001
Validation loss: 3.395370496146743

Epoch: 6| Step: 13
Training loss: 3.9398972010877595
Validation loss: 3.3935239332341065

Epoch: 25| Step: 0
Training loss: 3.7075260583806795
Validation loss: 3.3918425145826823

Epoch: 6| Step: 1
Training loss: 3.361012614114432
Validation loss: 3.3885532259202136

Epoch: 6| Step: 2
Training loss: 3.6220372687812628
Validation loss: 3.390034902822921

Epoch: 6| Step: 3
Training loss: 3.320728949067332
Validation loss: 3.3883587332147274

Epoch: 6| Step: 4
Training loss: 3.552802153911251
Validation loss: 3.3884274622873614

Epoch: 6| Step: 5
Training loss: 3.4642940459340825
Validation loss: 3.3801671955070187

Epoch: 6| Step: 6
Training loss: 3.6906378375160407
Validation loss: 3.3789513995532605

Epoch: 6| Step: 7
Training loss: 3.2577059428766595
Validation loss: 3.379840964286726

Epoch: 6| Step: 8
Training loss: 4.099529350993624
Validation loss: 3.3779029879407036

Epoch: 6| Step: 9
Training loss: 3.795704853606687
Validation loss: 3.377318147106326

Epoch: 6| Step: 10
Training loss: 3.902450911355523
Validation loss: 3.3765132569677605

Epoch: 6| Step: 11
Training loss: 4.121079865201728
Validation loss: 3.3694929649968928

Epoch: 6| Step: 12
Training loss: 3.030871180823443
Validation loss: 3.3717652820063497

Epoch: 6| Step: 13
Training loss: 3.25665848232817
Validation loss: 3.368095556259203

Epoch: 26| Step: 0
Training loss: 3.0701536181159677
Validation loss: 3.3711501039467775

Epoch: 6| Step: 1
Training loss: 2.6881908149884164
Validation loss: 3.366800298955645

Epoch: 6| Step: 2
Training loss: 3.799078156938772
Validation loss: 3.3677423179633164

Epoch: 6| Step: 3
Training loss: 3.9485519555624906
Validation loss: 3.3641660286685195

Epoch: 6| Step: 4
Training loss: 2.509774934625243
Validation loss: 3.362991627531406

Epoch: 6| Step: 5
Training loss: 4.0719368122646715
Validation loss: 3.3607444221340503

Epoch: 6| Step: 6
Training loss: 3.8131085519853265
Validation loss: 3.3639801946720342

Epoch: 6| Step: 7
Training loss: 4.039156944011879
Validation loss: 3.362054437077325

Epoch: 6| Step: 8
Training loss: 3.4364716812403384
Validation loss: 3.3615505323704813

Epoch: 6| Step: 9
Training loss: 2.8409262250903753
Validation loss: 3.3558546748734117

Epoch: 6| Step: 10
Training loss: 3.7862787776947795
Validation loss: 3.356317732409321

Epoch: 6| Step: 11
Training loss: 4.121939708788888
Validation loss: 3.3567880761012767

Epoch: 6| Step: 12
Training loss: 3.732193696828906
Validation loss: 3.3550367781503905

Epoch: 6| Step: 13
Training loss: 4.071378894015247
Validation loss: 3.35968401079804

Epoch: 27| Step: 0
Training loss: 2.8573287562791863
Validation loss: 3.3517710918679495

Epoch: 6| Step: 1
Training loss: 3.883467866480024
Validation loss: 3.354282953173511

Epoch: 6| Step: 2
Training loss: 4.390620438651434
Validation loss: 3.3555232240861015

Epoch: 6| Step: 3
Training loss: 3.5667482444013943
Validation loss: 3.355115942794012

Epoch: 6| Step: 4
Training loss: 2.6207533500203843
Validation loss: 3.3579918805491764

Epoch: 6| Step: 5
Training loss: 3.673634209146619
Validation loss: 3.3545463564683415

Epoch: 6| Step: 6
Training loss: 3.414038756263974
Validation loss: 3.3562146701611915

Epoch: 6| Step: 7
Training loss: 3.146694562298031
Validation loss: 3.350537888393966

Epoch: 6| Step: 8
Training loss: 3.777007947037234
Validation loss: 3.3495702758408994

Epoch: 6| Step: 9
Training loss: 2.983653036139336
Validation loss: 3.3483150747728896

Epoch: 6| Step: 10
Training loss: 3.791038013924743
Validation loss: 3.345039584383348

Epoch: 6| Step: 11
Training loss: 3.253714566120268
Validation loss: 3.3474298009234604

Epoch: 6| Step: 12
Training loss: 4.637343559813964
Validation loss: 3.3462366582017573

Epoch: 6| Step: 13
Training loss: 3.5973202427323554
Validation loss: 3.3450122038403434

Epoch: 28| Step: 0
Training loss: 3.4076192361144755
Validation loss: 3.343350780423829

Epoch: 6| Step: 1
Training loss: 3.4178441662562693
Validation loss: 3.339152281320172

Epoch: 6| Step: 2
Training loss: 3.5849895346261342
Validation loss: 3.338867526875315

Epoch: 6| Step: 3
Training loss: 3.6191910865259067
Validation loss: 3.33683840425413

Epoch: 6| Step: 4
Training loss: 3.642144013173465
Validation loss: 3.33468330078146

Epoch: 6| Step: 5
Training loss: 3.097916542845063
Validation loss: 3.333641758360213

Epoch: 6| Step: 6
Training loss: 4.002507854122769
Validation loss: 3.3356083771483043

Epoch: 6| Step: 7
Training loss: 3.4562844024656796
Validation loss: 3.3336070199610206

Epoch: 6| Step: 8
Training loss: 3.812353162595582
Validation loss: 3.3327059883519925

Epoch: 6| Step: 9
Training loss: 3.30242221830198
Validation loss: 3.334033925254697

Epoch: 6| Step: 10
Training loss: 4.068005631149431
Validation loss: 3.3307340798733054

Epoch: 6| Step: 11
Training loss: 4.108343306729873
Validation loss: 3.33079232506507

Epoch: 6| Step: 12
Training loss: 3.3689705006866815
Validation loss: 3.3299174069503312

Epoch: 6| Step: 13
Training loss: 2.096253222449959
Validation loss: 3.3290756110459716

Epoch: 29| Step: 0
Training loss: 3.8122172016256637
Validation loss: 3.3317003593023027

Epoch: 6| Step: 1
Training loss: 3.7659676423630084
Validation loss: 3.327445343313983

Epoch: 6| Step: 2
Training loss: 3.6668865975976286
Validation loss: 3.3329705545966872

Epoch: 6| Step: 3
Training loss: 2.4159416119549513
Validation loss: 3.328410610338088

Epoch: 6| Step: 4
Training loss: 3.855456876881414
Validation loss: 3.329848732843798

Epoch: 6| Step: 5
Training loss: 3.304900755438187
Validation loss: 3.331143223212286

Epoch: 6| Step: 6
Training loss: 3.8712108913832073
Validation loss: 3.3304726820843076

Epoch: 6| Step: 7
Training loss: 2.8406116648949578
Validation loss: 3.326894449927846

Epoch: 6| Step: 8
Training loss: 3.678316350868015
Validation loss: 3.323345232425407

Epoch: 6| Step: 9
Training loss: 3.3324612589342073
Validation loss: 3.320987247863029

Epoch: 6| Step: 10
Training loss: 3.70290068256844
Validation loss: 3.320666373864994

Epoch: 6| Step: 11
Training loss: 2.524226204174279
Validation loss: 3.322918121206931

Epoch: 6| Step: 12
Training loss: 4.80020016411822
Validation loss: 3.3252523394492974

Epoch: 6| Step: 13
Training loss: 3.664621143821907
Validation loss: 3.31811353335609

Epoch: 30| Step: 0
Training loss: 3.3994711520719707
Validation loss: 3.318185231710668

Epoch: 6| Step: 1
Training loss: 4.181350519771029
Validation loss: 3.3161433277647547

Epoch: 6| Step: 2
Training loss: 3.3560098515980905
Validation loss: 3.3179791310799254

Epoch: 6| Step: 3
Training loss: 3.1048654030146623
Validation loss: 3.3144478460412667

Epoch: 6| Step: 4
Training loss: 4.150613045510802
Validation loss: 3.315013675498468

Epoch: 6| Step: 5
Training loss: 3.1177009790607606
Validation loss: 3.3143787083088716

Epoch: 6| Step: 6
Training loss: 3.5123251114608727
Validation loss: 3.314740767198387

Epoch: 6| Step: 7
Training loss: 3.7386214242021643
Validation loss: 3.310301971064573

Epoch: 6| Step: 8
Training loss: 3.250946347298758
Validation loss: 3.313431031421747

Epoch: 6| Step: 9
Training loss: 3.3166032245133783
Validation loss: 3.311457508044489

Epoch: 6| Step: 10
Training loss: 3.460525522619389
Validation loss: 3.3082634210477195

Epoch: 6| Step: 11
Training loss: 4.213097748950517
Validation loss: 3.308555252477491

Epoch: 6| Step: 12
Training loss: 3.0540261882066355
Validation loss: 3.310683176492801

Epoch: 6| Step: 13
Training loss: 3.5390255822957193
Validation loss: 3.314504262012076

Epoch: 31| Step: 0
Training loss: 3.8298438125516343
Validation loss: 3.3095835010575376

Epoch: 6| Step: 1
Training loss: 3.42308768466059
Validation loss: 3.308918540486461

Epoch: 6| Step: 2
Training loss: 3.2977958947866792
Validation loss: 3.3069131846666724

Epoch: 6| Step: 3
Training loss: 4.093692458818529
Validation loss: 3.3070985486569384

Epoch: 6| Step: 4
Training loss: 3.6004880680267406
Validation loss: 3.303929980837668

Epoch: 6| Step: 5
Training loss: 4.3895790238880545
Validation loss: 3.3034753794423652

Epoch: 6| Step: 6
Training loss: 4.083647164461979
Validation loss: 3.304458641657774

Epoch: 6| Step: 7
Training loss: 3.4406715327554123
Validation loss: 3.303956061520201

Epoch: 6| Step: 8
Training loss: 3.0244555274946543
Validation loss: 3.3007297994127067

Epoch: 6| Step: 9
Training loss: 3.0366452368417347
Validation loss: 3.3012690167776015

Epoch: 6| Step: 10
Training loss: 3.079801461149744
Validation loss: 3.2999303466714918

Epoch: 6| Step: 11
Training loss: 3.2614824951862382
Validation loss: 3.300930744496123

Epoch: 6| Step: 12
Training loss: 3.1366833296470715
Validation loss: 3.3000282426224046

Epoch: 6| Step: 13
Training loss: 3.5439006416825056
Validation loss: 3.2993764644346566

Epoch: 32| Step: 0
Training loss: 4.160343764113214
Validation loss: 3.2994965565459498

Epoch: 6| Step: 1
Training loss: 3.315166623630197
Validation loss: 3.30058922813147

Epoch: 6| Step: 2
Training loss: 3.144227045165131
Validation loss: 3.297778903547831

Epoch: 6| Step: 3
Training loss: 2.7840803510646173
Validation loss: 3.2978821416398505

Epoch: 6| Step: 4
Training loss: 2.449895591846662
Validation loss: 3.2983806597107312

Epoch: 6| Step: 5
Training loss: 3.792399213403468
Validation loss: 3.2935842328760754

Epoch: 6| Step: 6
Training loss: 3.9450760874403117
Validation loss: 3.2974340737258503

Epoch: 6| Step: 7
Training loss: 3.918614707935452
Validation loss: 3.2920478965047453

Epoch: 6| Step: 8
Training loss: 3.6666040126187016
Validation loss: 3.2950158770819473

Epoch: 6| Step: 9
Training loss: 3.575382697689371
Validation loss: 3.2894885345257627

Epoch: 6| Step: 10
Training loss: 3.920420099441323
Validation loss: 3.289257972557149

Epoch: 6| Step: 11
Training loss: 3.543127558975251
Validation loss: 3.289121815167534

Epoch: 6| Step: 12
Training loss: 3.08039686915842
Validation loss: 3.288702523623553

Epoch: 6| Step: 13
Training loss: 3.908286822488956
Validation loss: 3.2913538118356893

Epoch: 33| Step: 0
Training loss: 3.8850010435674927
Validation loss: 3.2911882895332303

Epoch: 6| Step: 1
Training loss: 3.7798073278500515
Validation loss: 3.2897224640047384

Epoch: 6| Step: 2
Training loss: 3.7506917951166776
Validation loss: 3.2881093027377273

Epoch: 6| Step: 3
Training loss: 4.366985937390703
Validation loss: 3.284201733216955

Epoch: 6| Step: 4
Training loss: 2.8395132845893456
Validation loss: 3.2855468945381663

Epoch: 6| Step: 5
Training loss: 3.5671073166018283
Validation loss: 3.284376822880193

Epoch: 6| Step: 6
Training loss: 2.9224826772419537
Validation loss: 3.285274982861253

Epoch: 6| Step: 7
Training loss: 3.1105277066979715
Validation loss: 3.2892041983414098

Epoch: 6| Step: 8
Training loss: 3.8524312554228386
Validation loss: 3.2950830761352243

Epoch: 6| Step: 9
Training loss: 3.5834880765873836
Validation loss: 3.283625065144469

Epoch: 6| Step: 10
Training loss: 3.418869719422814
Validation loss: 3.2814078281804773

Epoch: 6| Step: 11
Training loss: 3.5880321626359293
Validation loss: 3.280759738249827

Epoch: 6| Step: 12
Training loss: 3.0912841834473954
Validation loss: 3.2832836921511777

Epoch: 6| Step: 13
Training loss: 3.0695917967749597
Validation loss: 3.291827251795065

Epoch: 34| Step: 0
Training loss: 2.704472376897635
Validation loss: 3.293390693033844

Epoch: 6| Step: 1
Training loss: 3.9481175488149103
Validation loss: 3.294034005872078

Epoch: 6| Step: 2
Training loss: 3.8868292864699687
Validation loss: 3.2951994090827617

Epoch: 6| Step: 3
Training loss: 3.819596986132779
Validation loss: 3.299584728536574

Epoch: 6| Step: 4
Training loss: 3.5212260070568373
Validation loss: 3.3012325150475075

Epoch: 6| Step: 5
Training loss: 3.4100259273136286
Validation loss: 3.290327715462545

Epoch: 6| Step: 6
Training loss: 3.251923652034234
Validation loss: 3.282208674442394

Epoch: 6| Step: 7
Training loss: 4.256072250441311
Validation loss: 3.276546953760723

Epoch: 6| Step: 8
Training loss: 3.2993656531329973
Validation loss: 3.274701188329911

Epoch: 6| Step: 9
Training loss: 3.1791085880785706
Validation loss: 3.2750351592149802

Epoch: 6| Step: 10
Training loss: 3.7032620046517986
Validation loss: 3.276672054303826

Epoch: 6| Step: 11
Training loss: 2.9552665897436525
Validation loss: 3.272790297645825

Epoch: 6| Step: 12
Training loss: 3.909922102130241
Validation loss: 3.276272581495213

Epoch: 6| Step: 13
Training loss: 2.7190737476736606
Validation loss: 3.2752719690136165

Epoch: 35| Step: 0
Training loss: 2.837332222301342
Validation loss: 3.2788579688204664

Epoch: 6| Step: 1
Training loss: 3.6037405714003654
Validation loss: 3.2806768101298043

Epoch: 6| Step: 2
Training loss: 3.703378274360502
Validation loss: 3.270382822640933

Epoch: 6| Step: 3
Training loss: 3.000608859266091
Validation loss: 3.2701125115209924

Epoch: 6| Step: 4
Training loss: 3.7047026931148683
Validation loss: 3.2709448624054422

Epoch: 6| Step: 5
Training loss: 3.778988248461066
Validation loss: 3.269381348529324

Epoch: 6| Step: 6
Training loss: 3.6453443072092693
Validation loss: 3.2707159882038996

Epoch: 6| Step: 7
Training loss: 3.39838670714557
Validation loss: 3.2712986128375645

Epoch: 6| Step: 8
Training loss: 3.4763311073363643
Validation loss: 3.2695509747691984

Epoch: 6| Step: 9
Training loss: 3.781277743151065
Validation loss: 3.2677509986460134

Epoch: 6| Step: 10
Training loss: 3.4711325770989867
Validation loss: 3.2680542154537764

Epoch: 6| Step: 11
Training loss: 3.1007498726346894
Validation loss: 3.263547873909488

Epoch: 6| Step: 12
Training loss: 3.230116394827484
Validation loss: 3.2658090533185247

Epoch: 6| Step: 13
Training loss: 4.663653127318042
Validation loss: 3.266994590468713

Epoch: 36| Step: 0
Training loss: 3.2355217858649383
Validation loss: 3.259642741542025

Epoch: 6| Step: 1
Training loss: 3.461570664606524
Validation loss: 3.255288750949294

Epoch: 6| Step: 2
Training loss: 3.276243477545238
Validation loss: 3.255240223718117

Epoch: 6| Step: 3
Training loss: 3.831261669346523
Validation loss: 3.257884463118433

Epoch: 6| Step: 4
Training loss: 3.9675882396247957
Validation loss: 3.2553919276813255

Epoch: 6| Step: 5
Training loss: 3.042498766507829
Validation loss: 3.2536786324087936

Epoch: 6| Step: 6
Training loss: 3.538044157737035
Validation loss: 3.255531225060236

Epoch: 6| Step: 7
Training loss: 3.047947934334279
Validation loss: 3.253576536774592

Epoch: 6| Step: 8
Training loss: 4.427871789470013
Validation loss: 3.250919712802857

Epoch: 6| Step: 9
Training loss: 3.581135511981609
Validation loss: 3.25181469134707

Epoch: 6| Step: 10
Training loss: 3.366915592269689
Validation loss: 3.249588721845532

Epoch: 6| Step: 11
Training loss: 3.622162333060325
Validation loss: 3.2448931359352122

Epoch: 6| Step: 12
Training loss: 2.9460933874469415
Validation loss: 3.247677177264226

Epoch: 6| Step: 13
Training loss: 3.1802058816636487
Validation loss: 3.2481282541888636

Epoch: 37| Step: 0
Training loss: 2.9863557483700354
Validation loss: 3.2507206612390487

Epoch: 6| Step: 1
Training loss: 3.8500360710138692
Validation loss: 3.253519942892642

Epoch: 6| Step: 2
Training loss: 3.923725800915069
Validation loss: 3.2447628929279144

Epoch: 6| Step: 3
Training loss: 3.014433630385567
Validation loss: 3.2471257066253814

Epoch: 6| Step: 4
Training loss: 3.413873942250812
Validation loss: 3.2444947141307

Epoch: 6| Step: 5
Training loss: 3.567915698334242
Validation loss: 3.248928827497666

Epoch: 6| Step: 6
Training loss: 3.408865947814742
Validation loss: 3.252567674734976

Epoch: 6| Step: 7
Training loss: 3.3907633810327056
Validation loss: 3.2432810127724228

Epoch: 6| Step: 8
Training loss: 2.5360568523231755
Validation loss: 3.2415056484474665

Epoch: 6| Step: 9
Training loss: 3.2739024412502307
Validation loss: 3.2406086779704597

Epoch: 6| Step: 10
Training loss: 4.283228730187373
Validation loss: 3.2419528030665914

Epoch: 6| Step: 11
Training loss: 3.83715030431253
Validation loss: 3.2398087850042505

Epoch: 6| Step: 12
Training loss: 3.6241936937910406
Validation loss: 3.236019001852475

Epoch: 6| Step: 13
Training loss: 3.349046451878627
Validation loss: 3.2366652886424174

Epoch: 38| Step: 0
Training loss: 3.1601803923676077
Validation loss: 3.2391352432472478

Epoch: 6| Step: 1
Training loss: 3.676867139186364
Validation loss: 3.2416858358618055

Epoch: 6| Step: 2
Training loss: 3.8166341410976488
Validation loss: 3.2519205822139012

Epoch: 6| Step: 3
Training loss: 2.8213646952208644
Validation loss: 3.2416808978804186

Epoch: 6| Step: 4
Training loss: 3.1411168866201327
Validation loss: 3.243624211295394

Epoch: 6| Step: 5
Training loss: 3.78343830943286
Validation loss: 3.2355460092617534

Epoch: 6| Step: 6
Training loss: 3.8926276143053222
Validation loss: 3.2375770687005336

Epoch: 6| Step: 7
Training loss: 4.111973858137934
Validation loss: 3.234151651681186

Epoch: 6| Step: 8
Training loss: 2.853624909675774
Validation loss: 3.2332146958901853

Epoch: 6| Step: 9
Training loss: 3.5772397474610824
Validation loss: 3.2362448219761677

Epoch: 6| Step: 10
Training loss: 2.982707251664719
Validation loss: 3.2407863791345335

Epoch: 6| Step: 11
Training loss: 3.9761526200075337
Validation loss: 3.2457219752249733

Epoch: 6| Step: 12
Training loss: 3.031620592882535
Validation loss: 3.238932932260365

Epoch: 6| Step: 13
Training loss: 3.6801587752629668
Validation loss: 3.236036233394987

Epoch: 39| Step: 0
Training loss: 3.33833116332917
Validation loss: 3.227059786409772

Epoch: 6| Step: 1
Training loss: 2.3358872832447233
Validation loss: 3.2263574316305346

Epoch: 6| Step: 2
Training loss: 3.3020918371690744
Validation loss: 3.2271724093591394

Epoch: 6| Step: 3
Training loss: 2.699161159050051
Validation loss: 3.2269458264463196

Epoch: 6| Step: 4
Training loss: 3.279310543356714
Validation loss: 3.232497331441002

Epoch: 6| Step: 5
Training loss: 3.7009216707150876
Validation loss: 3.227178761313032

Epoch: 6| Step: 6
Training loss: 3.6045002571621265
Validation loss: 3.2283826558345017

Epoch: 6| Step: 7
Training loss: 3.8506385669986254
Validation loss: 3.22523507659504

Epoch: 6| Step: 8
Training loss: 4.134957519460646
Validation loss: 3.2240747202191717

Epoch: 6| Step: 9
Training loss: 3.4928627812047233
Validation loss: 3.223533549241816

Epoch: 6| Step: 10
Training loss: 2.8522717573640217
Validation loss: 3.2246862480981164

Epoch: 6| Step: 11
Training loss: 4.087206787418532
Validation loss: 3.2267573747018403

Epoch: 6| Step: 12
Training loss: 3.915195080414282
Validation loss: 3.228473253589151

Epoch: 6| Step: 13
Training loss: 3.5955771403954304
Validation loss: 3.2279788677189045

Epoch: 40| Step: 0
Training loss: 3.176632324892396
Validation loss: 3.2267245936967526

Epoch: 6| Step: 1
Training loss: 3.1597012827718536
Validation loss: 3.22530558471351

Epoch: 6| Step: 2
Training loss: 2.725735864236833
Validation loss: 3.221375327106654

Epoch: 6| Step: 3
Training loss: 4.123699098696679
Validation loss: 3.220662764977917

Epoch: 6| Step: 4
Training loss: 3.769773864844605
Validation loss: 3.2192774841307954

Epoch: 6| Step: 5
Training loss: 3.978627566156534
Validation loss: 3.2160691318114907

Epoch: 6| Step: 6
Training loss: 2.750823157830088
Validation loss: 3.21725527286237

Epoch: 6| Step: 7
Training loss: 3.223994306734421
Validation loss: 3.216147851895592

Epoch: 6| Step: 8
Training loss: 3.8616882063707134
Validation loss: 3.220692525608019

Epoch: 6| Step: 9
Training loss: 3.9366432347732174
Validation loss: 3.2164996960793513

Epoch: 6| Step: 10
Training loss: 2.452940235347624
Validation loss: 3.2141087832165303

Epoch: 6| Step: 11
Training loss: 3.025108486783825
Validation loss: 3.216432182308717

Epoch: 6| Step: 12
Training loss: 4.149340859887652
Validation loss: 3.214859103846956

Epoch: 6| Step: 13
Training loss: 3.7079228091800793
Validation loss: 3.214310753648784

Epoch: 41| Step: 0
Training loss: 3.715036028229072
Validation loss: 3.217183840062371

Epoch: 6| Step: 1
Training loss: 3.7219575784716277
Validation loss: 3.220903069355779

Epoch: 6| Step: 2
Training loss: 3.000464721289216
Validation loss: 3.211249159703434

Epoch: 6| Step: 3
Training loss: 3.372523352766236
Validation loss: 3.2112921224119257

Epoch: 6| Step: 4
Training loss: 3.1711788822991425
Validation loss: 3.214188081717311

Epoch: 6| Step: 5
Training loss: 3.1388060203423533
Validation loss: 3.229926854953148

Epoch: 6| Step: 6
Training loss: 2.89690825639748
Validation loss: 3.2446440650289974

Epoch: 6| Step: 7
Training loss: 3.704336233874262
Validation loss: 3.236931266499888

Epoch: 6| Step: 8
Training loss: 3.200512970101754
Validation loss: 3.225771982870222

Epoch: 6| Step: 9
Training loss: 4.764832877944023
Validation loss: 3.220080258385703

Epoch: 6| Step: 10
Training loss: 3.5957826919496414
Validation loss: 3.2161317748370757

Epoch: 6| Step: 11
Training loss: 3.2270752727948846
Validation loss: 3.2111675324864595

Epoch: 6| Step: 12
Training loss: 3.329852305164081
Validation loss: 3.213200043202294

Epoch: 6| Step: 13
Training loss: 3.352329122013136
Validation loss: 3.2143731119202186

Epoch: 42| Step: 0
Training loss: 2.9083126500950898
Validation loss: 3.2197166406713724

Epoch: 6| Step: 1
Training loss: 3.306801266494385
Validation loss: 3.2222231286311285

Epoch: 6| Step: 2
Training loss: 3.3149520147886853
Validation loss: 3.2206892715972346

Epoch: 6| Step: 3
Training loss: 2.813719845190352
Validation loss: 3.217781571925345

Epoch: 6| Step: 4
Training loss: 3.463703092479782
Validation loss: 3.2128530553546213

Epoch: 6| Step: 5
Training loss: 4.16787150447415
Validation loss: 3.210296840800127

Epoch: 6| Step: 6
Training loss: 2.98894211187171
Validation loss: 3.2088368013740314

Epoch: 6| Step: 7
Training loss: 3.871543819620438
Validation loss: 3.208664668574304

Epoch: 6| Step: 8
Training loss: 2.9305685524152603
Validation loss: 3.207354025502697

Epoch: 6| Step: 9
Training loss: 2.9968200360330517
Validation loss: 3.206546606086711

Epoch: 6| Step: 10
Training loss: 4.332923625259737
Validation loss: 3.206180808229791

Epoch: 6| Step: 11
Training loss: 3.713471457025891
Validation loss: 3.207989592104073

Epoch: 6| Step: 12
Training loss: 3.7067784825161625
Validation loss: 3.205355484955518

Epoch: 6| Step: 13
Training loss: 3.5544306064882365
Validation loss: 3.2017051657343374

Epoch: 43| Step: 0
Training loss: 2.947471252508291
Validation loss: 3.200909635761628

Epoch: 6| Step: 1
Training loss: 4.391002923848502
Validation loss: 3.2011082200491865

Epoch: 6| Step: 2
Training loss: 3.4521604545848126
Validation loss: 3.199467477404202

Epoch: 6| Step: 3
Training loss: 4.421652636648945
Validation loss: 3.2020235070080796

Epoch: 6| Step: 4
Training loss: 2.870429677134082
Validation loss: 3.2020222219943886

Epoch: 6| Step: 5
Training loss: 2.912116907162459
Validation loss: 3.1983716445394115

Epoch: 6| Step: 6
Training loss: 4.0198429976592465
Validation loss: 3.1984511825208184

Epoch: 6| Step: 7
Training loss: 2.727447103936747
Validation loss: 3.1993652768557412

Epoch: 6| Step: 8
Training loss: 2.9360661355139492
Validation loss: 3.1994051323009023

Epoch: 6| Step: 9
Training loss: 3.574487694799555
Validation loss: 3.1989232014085136

Epoch: 6| Step: 10
Training loss: 3.5218838059485353
Validation loss: 3.1969316098483818

Epoch: 6| Step: 11
Training loss: 3.73766077008422
Validation loss: 3.1965720604079744

Epoch: 6| Step: 12
Training loss: 3.3619465766034335
Validation loss: 3.194882075035338

Epoch: 6| Step: 13
Training loss: 2.368827025436942
Validation loss: 3.196534132951234

Epoch: 44| Step: 0
Training loss: 4.273958777622042
Validation loss: 3.1945238606153787

Epoch: 6| Step: 1
Training loss: 4.135110198354944
Validation loss: 3.198908017908413

Epoch: 6| Step: 2
Training loss: 3.07873730451264
Validation loss: 3.1970733501173645

Epoch: 6| Step: 3
Training loss: 3.8805172927366933
Validation loss: 3.193924473096096

Epoch: 6| Step: 4
Training loss: 2.6230325137474506
Validation loss: 3.1918029566709136

Epoch: 6| Step: 5
Training loss: 3.097727828864439
Validation loss: 3.192622727298298

Epoch: 6| Step: 6
Training loss: 2.47422598478502
Validation loss: 3.1929511248418208

Epoch: 6| Step: 7
Training loss: 3.368900438675867
Validation loss: 3.1966674156059347

Epoch: 6| Step: 8
Training loss: 3.728496313669542
Validation loss: 3.195390642722339

Epoch: 6| Step: 9
Training loss: 3.2755737617443343
Validation loss: 3.191921740596864

Epoch: 6| Step: 10
Training loss: 3.8784813777884204
Validation loss: 3.1968926465718823

Epoch: 6| Step: 11
Training loss: 3.374270042317515
Validation loss: 3.1990813183808857

Epoch: 6| Step: 12
Training loss: 2.9918885243502427
Validation loss: 3.200048932603777

Epoch: 6| Step: 13
Training loss: 3.7086830117167584
Validation loss: 3.210891504938588

Epoch: 45| Step: 0
Training loss: 2.9330777909490893
Validation loss: 3.1938798865364575

Epoch: 6| Step: 1
Training loss: 4.346119844837286
Validation loss: 3.1956239683853065

Epoch: 6| Step: 2
Training loss: 3.665810239360261
Validation loss: 3.195964990615763

Epoch: 6| Step: 3
Training loss: 3.009191578378369
Validation loss: 3.1952371153894963

Epoch: 6| Step: 4
Training loss: 3.44143784126391
Validation loss: 3.1950975194284656

Epoch: 6| Step: 5
Training loss: 3.8610522374727285
Validation loss: 3.1987116581296484

Epoch: 6| Step: 6
Training loss: 3.2024645612961
Validation loss: 3.1970831858528075

Epoch: 6| Step: 7
Training loss: 2.9936422690995252
Validation loss: 3.1937585120702447

Epoch: 6| Step: 8
Training loss: 3.548025339597338
Validation loss: 3.1931539758913745

Epoch: 6| Step: 9
Training loss: 2.9253850243324173
Validation loss: 3.1894084341353333

Epoch: 6| Step: 10
Training loss: 3.3435636094096455
Validation loss: 3.1880944839921463

Epoch: 6| Step: 11
Training loss: 3.4151429446060213
Validation loss: 3.18765637703646

Epoch: 6| Step: 12
Training loss: 3.916819927923458
Validation loss: 3.1872466403065003

Epoch: 6| Step: 13
Training loss: 3.3214056392176867
Validation loss: 3.190013170616624

Epoch: 46| Step: 0
Training loss: 3.0611567762891525
Validation loss: 3.1873925754140044

Epoch: 6| Step: 1
Training loss: 2.684834955353456
Validation loss: 3.1905712859363424

Epoch: 6| Step: 2
Training loss: 3.338103187716896
Validation loss: 3.192447203551978

Epoch: 6| Step: 3
Training loss: 4.1361133107171755
Validation loss: 3.1857905677027847

Epoch: 6| Step: 4
Training loss: 3.873826125985796
Validation loss: 3.187027907714184

Epoch: 6| Step: 5
Training loss: 4.019837303854833
Validation loss: 3.184057385331769

Epoch: 6| Step: 6
Training loss: 3.6804467974894557
Validation loss: 3.183361547837169

Epoch: 6| Step: 7
Training loss: 3.5339936257236335
Validation loss: 3.1832310019780574

Epoch: 6| Step: 8
Training loss: 3.0721964018941765
Validation loss: 3.182822378967439

Epoch: 6| Step: 9
Training loss: 3.149626173816512
Validation loss: 3.1819936606978363

Epoch: 6| Step: 10
Training loss: 3.5873125884651924
Validation loss: 3.1827344696939504

Epoch: 6| Step: 11
Training loss: 3.3009895574987542
Validation loss: 3.180209473750654

Epoch: 6| Step: 12
Training loss: 3.6206855091140135
Validation loss: 3.1805244532108063

Epoch: 6| Step: 13
Training loss: 2.1028153893038066
Validation loss: 3.180115802467621

Epoch: 47| Step: 0
Training loss: 3.3331887849619752
Validation loss: 3.180073698746314

Epoch: 6| Step: 1
Training loss: 2.49929265505958
Validation loss: 3.1811608051206437

Epoch: 6| Step: 2
Training loss: 3.9669649209696956
Validation loss: 3.1796739468156296

Epoch: 6| Step: 3
Training loss: 3.859616785545193
Validation loss: 3.178280826036822

Epoch: 6| Step: 4
Training loss: 3.6476860497802206
Validation loss: 3.1809095388796758

Epoch: 6| Step: 5
Training loss: 3.206442998539169
Validation loss: 3.178435878964147

Epoch: 6| Step: 6
Training loss: 3.395148007252394
Validation loss: 3.1764391271039543

Epoch: 6| Step: 7
Training loss: 3.0058869775170267
Validation loss: 3.1774942445359584

Epoch: 6| Step: 8
Training loss: 3.7828529680333585
Validation loss: 3.1783095542132225

Epoch: 6| Step: 9
Training loss: 3.452537521169467
Validation loss: 3.176051330524798

Epoch: 6| Step: 10
Training loss: 3.9446605181426646
Validation loss: 3.1763464503644974

Epoch: 6| Step: 11
Training loss: 2.760312425096671
Validation loss: 3.1775265902730974

Epoch: 6| Step: 12
Training loss: 2.9188409239760804
Validation loss: 3.176277353474273

Epoch: 6| Step: 13
Training loss: 4.198203229313019
Validation loss: 3.1788242637006165

Epoch: 48| Step: 0
Training loss: 3.5889919461733633
Validation loss: 3.1769353731595493

Epoch: 6| Step: 1
Training loss: 2.8504245107277306
Validation loss: 3.176897822141238

Epoch: 6| Step: 2
Training loss: 3.7819992458074454
Validation loss: 3.180821077040236

Epoch: 6| Step: 3
Training loss: 3.6533097402363066
Validation loss: 3.177351514665593

Epoch: 6| Step: 4
Training loss: 3.0750897154087227
Validation loss: 3.1755268762085875

Epoch: 6| Step: 5
Training loss: 4.0470234611704035
Validation loss: 3.172796062617758

Epoch: 6| Step: 6
Training loss: 2.9666110715764544
Validation loss: 3.1739305808266436

Epoch: 6| Step: 7
Training loss: 3.5508577949154643
Validation loss: 3.1749893450556197

Epoch: 6| Step: 8
Training loss: 3.1395097716753986
Validation loss: 3.170509332519297

Epoch: 6| Step: 9
Training loss: 3.4214700258896795
Validation loss: 3.171131608848872

Epoch: 6| Step: 10
Training loss: 3.7853444527998734
Validation loss: 3.170960491757445

Epoch: 6| Step: 11
Training loss: 3.1002828038334047
Validation loss: 3.1725279449533073

Epoch: 6| Step: 12
Training loss: 3.5174664231292665
Validation loss: 3.171012375991217

Epoch: 6| Step: 13
Training loss: 3.2210266061872437
Validation loss: 3.172053157261103

Epoch: 49| Step: 0
Training loss: 2.5032205818205475
Validation loss: 3.171898880209997

Epoch: 6| Step: 1
Training loss: 3.664964251792771
Validation loss: 3.1708492081433564

Epoch: 6| Step: 2
Training loss: 2.8730068761555394
Validation loss: 3.1715279577275695

Epoch: 6| Step: 3
Training loss: 3.3145820264416095
Validation loss: 3.169862854268449

Epoch: 6| Step: 4
Training loss: 2.9516013115127904
Validation loss: 3.1711293209887295

Epoch: 6| Step: 5
Training loss: 3.0442632974749455
Validation loss: 3.1699061821823267

Epoch: 6| Step: 6
Training loss: 4.091820181914529
Validation loss: 3.1692555622390786

Epoch: 6| Step: 7
Training loss: 3.524869572816999
Validation loss: 3.1689262203114996

Epoch: 6| Step: 8
Training loss: 3.595188549546061
Validation loss: 3.167273125490021

Epoch: 6| Step: 9
Training loss: 2.9656120983361682
Validation loss: 3.1686435631831213

Epoch: 6| Step: 10
Training loss: 3.7519129642241547
Validation loss: 3.167252931313016

Epoch: 6| Step: 11
Training loss: 3.816622646916391
Validation loss: 3.1663861868324505

Epoch: 6| Step: 12
Training loss: 4.058879941335273
Validation loss: 3.1678123285288997

Epoch: 6| Step: 13
Training loss: 3.362347090977533
Validation loss: 3.1745212519872448

Epoch: 50| Step: 0
Training loss: 2.9725067461994383
Validation loss: 3.1670870304940206

Epoch: 6| Step: 1
Training loss: 3.5232338180370686
Validation loss: 3.165735320439411

Epoch: 6| Step: 2
Training loss: 3.478693825271271
Validation loss: 3.1648789126697507

Epoch: 6| Step: 3
Training loss: 3.7239858488475748
Validation loss: 3.1653016129606484

Epoch: 6| Step: 4
Training loss: 3.606603970667269
Validation loss: 3.163302477676582

Epoch: 6| Step: 5
Training loss: 3.3282837449303475
Validation loss: 3.163822035195547

Epoch: 6| Step: 6
Training loss: 3.7818661022318016
Validation loss: 3.163026630354308

Epoch: 6| Step: 7
Training loss: 3.3213994659226773
Validation loss: 3.162500530837721

Epoch: 6| Step: 8
Training loss: 3.589334578408549
Validation loss: 3.1624701431449345

Epoch: 6| Step: 9
Training loss: 3.4031635264728375
Validation loss: 3.1641824387363253

Epoch: 6| Step: 10
Training loss: 2.611570793523032
Validation loss: 3.162335773448264

Epoch: 6| Step: 11
Training loss: 3.3913003978366025
Validation loss: 3.1610575908502065

Epoch: 6| Step: 12
Training loss: 4.08106625480683
Validation loss: 3.161563667526196

Epoch: 6| Step: 13
Training loss: 2.178855600517224
Validation loss: 3.1611773727301156

Epoch: 51| Step: 0
Training loss: 3.755213356102888
Validation loss: 3.1623742367116856

Epoch: 6| Step: 1
Training loss: 2.908594313956264
Validation loss: 3.1592938976910334

Epoch: 6| Step: 2
Training loss: 4.559262106571731
Validation loss: 3.1595400866866665

Epoch: 6| Step: 3
Training loss: 2.9971449299830732
Validation loss: 3.1615484748900813

Epoch: 6| Step: 4
Training loss: 3.09903535293055
Validation loss: 3.1622093438388696

Epoch: 6| Step: 5
Training loss: 3.367748806717402
Validation loss: 3.1610458831278114

Epoch: 6| Step: 6
Training loss: 3.703107487761862
Validation loss: 3.1617119232584616

Epoch: 6| Step: 7
Training loss: 4.101739672512683
Validation loss: 3.159885472924423

Epoch: 6| Step: 8
Training loss: 2.683230002014993
Validation loss: 3.163489519785414

Epoch: 6| Step: 9
Training loss: 2.6010380580043444
Validation loss: 3.1603078863203127

Epoch: 6| Step: 10
Training loss: 3.3720048400373557
Validation loss: 3.157933417651671

Epoch: 6| Step: 11
Training loss: 3.19599440930084
Validation loss: 3.157468614336602

Epoch: 6| Step: 12
Training loss: 2.905088787461944
Validation loss: 3.1567112680946807

Epoch: 6| Step: 13
Training loss: 4.347202602961059
Validation loss: 3.15841220775948

Epoch: 52| Step: 0
Training loss: 3.7567752667638055
Validation loss: 3.1567838873776553

Epoch: 6| Step: 1
Training loss: 2.946814682667849
Validation loss: 3.155910937115688

Epoch: 6| Step: 2
Training loss: 4.308060724622072
Validation loss: 3.1568597598312422

Epoch: 6| Step: 3
Training loss: 3.036388642878343
Validation loss: 3.1574420787584057

Epoch: 6| Step: 4
Training loss: 3.584104913248886
Validation loss: 3.1564297896473197

Epoch: 6| Step: 5
Training loss: 2.908090972274998
Validation loss: 3.1576313580819324

Epoch: 6| Step: 6
Training loss: 2.7413574005671064
Validation loss: 3.1614342018059665

Epoch: 6| Step: 7
Training loss: 3.908810928108969
Validation loss: 3.1599321909438993

Epoch: 6| Step: 8
Training loss: 3.563035489710977
Validation loss: 3.1597403825570587

Epoch: 6| Step: 9
Training loss: 3.1851953889090296
Validation loss: 3.1590214755768917

Epoch: 6| Step: 10
Training loss: 3.549116325537909
Validation loss: 3.1572977473545367

Epoch: 6| Step: 11
Training loss: 3.329382860200575
Validation loss: 3.1560804982919763

Epoch: 6| Step: 12
Training loss: 3.5688150216240313
Validation loss: 3.154434887547454

Epoch: 6| Step: 13
Training loss: 2.7436541251634856
Validation loss: 3.154322580410381

Epoch: 53| Step: 0
Training loss: 4.023522829799038
Validation loss: 3.152836340393059

Epoch: 6| Step: 1
Training loss: 3.5949500692452196
Validation loss: 3.1521949219062373

Epoch: 6| Step: 2
Training loss: 3.242257505833067
Validation loss: 3.1514838479046934

Epoch: 6| Step: 3
Training loss: 3.301169829660797
Validation loss: 3.149119027008529

Epoch: 6| Step: 4
Training loss: 3.7160718233704464
Validation loss: 3.1531489751858355

Epoch: 6| Step: 5
Training loss: 3.7244632974353324
Validation loss: 3.153655127628346

Epoch: 6| Step: 6
Training loss: 3.4879904836209867
Validation loss: 3.1518659641176305

Epoch: 6| Step: 7
Training loss: 3.0515163967011447
Validation loss: 3.1516695204388743

Epoch: 6| Step: 8
Training loss: 3.348828318649388
Validation loss: 3.149849509104699

Epoch: 6| Step: 9
Training loss: 3.396111334594384
Validation loss: 3.1496898550527352

Epoch: 6| Step: 10
Training loss: 3.280066576491371
Validation loss: 3.1496014182206395

Epoch: 6| Step: 11
Training loss: 3.1133480280244155
Validation loss: 3.1478469853842297

Epoch: 6| Step: 12
Training loss: 3.0272412092008927
Validation loss: 3.1488303029019376

Epoch: 6| Step: 13
Training loss: 3.1549595375912336
Validation loss: 3.147483067678127

Epoch: 54| Step: 0
Training loss: 3.4683026549415223
Validation loss: 3.1480066058573795

Epoch: 6| Step: 1
Training loss: 2.6955701621916828
Validation loss: 3.1477215131242806

Epoch: 6| Step: 2
Training loss: 3.5203746669950498
Validation loss: 3.1476427652473333

Epoch: 6| Step: 3
Training loss: 3.6326457980065183
Validation loss: 3.14552495550946

Epoch: 6| Step: 4
Training loss: 3.3616543865846396
Validation loss: 3.144998286513976

Epoch: 6| Step: 5
Training loss: 4.2207110332960385
Validation loss: 3.145946787224163

Epoch: 6| Step: 6
Training loss: 2.945042119655991
Validation loss: 3.145475239383591

Epoch: 6| Step: 7
Training loss: 3.01318561144044
Validation loss: 3.143602695331756

Epoch: 6| Step: 8
Training loss: 3.92732328428935
Validation loss: 3.1463579830876296

Epoch: 6| Step: 9
Training loss: 4.1722229087435085
Validation loss: 3.1437639355404134

Epoch: 6| Step: 10
Training loss: 2.8393643274931666
Validation loss: 3.145119472306641

Epoch: 6| Step: 11
Training loss: 3.171067459211737
Validation loss: 3.1452470632573335

Epoch: 6| Step: 12
Training loss: 3.268768695610075
Validation loss: 3.141740067456519

Epoch: 6| Step: 13
Training loss: 2.641838562323573
Validation loss: 3.142098110060712

Epoch: 55| Step: 0
Training loss: 4.095708713336674
Validation loss: 3.143611993767382

Epoch: 6| Step: 1
Training loss: 3.2580984891145492
Validation loss: 3.1421289558582455

Epoch: 6| Step: 2
Training loss: 2.7683567844280246
Validation loss: 3.1425856488954564

Epoch: 6| Step: 3
Training loss: 3.4463802421789795
Validation loss: 3.1402745711298357

Epoch: 6| Step: 4
Training loss: 3.178586577108421
Validation loss: 3.141029961564466

Epoch: 6| Step: 5
Training loss: 2.969666028495592
Validation loss: 3.1409793434080084

Epoch: 6| Step: 6
Training loss: 3.5796299064328996
Validation loss: 3.141781185118553

Epoch: 6| Step: 7
Training loss: 4.035728628178899
Validation loss: 3.141380025434879

Epoch: 6| Step: 8
Training loss: 2.070513675919971
Validation loss: 3.1422928432501096

Epoch: 6| Step: 9
Training loss: 3.7510880481268103
Validation loss: 3.14047831857719

Epoch: 6| Step: 10
Training loss: 3.2272448984233306
Validation loss: 3.139799312038093

Epoch: 6| Step: 11
Training loss: 4.07695276944403
Validation loss: 3.143966435955883

Epoch: 6| Step: 12
Training loss: 3.0219036617714723
Validation loss: 3.1408645847869825

Epoch: 6| Step: 13
Training loss: 3.5906350609594413
Validation loss: 3.14098399079896

Epoch: 56| Step: 0
Training loss: 3.8630494452226922
Validation loss: 3.1404971339199514

Epoch: 6| Step: 1
Training loss: 3.4056513548986556
Validation loss: 3.14079188964257

Epoch: 6| Step: 2
Training loss: 3.5832991191797885
Validation loss: 3.1384549832147606

Epoch: 6| Step: 3
Training loss: 3.549914968842316
Validation loss: 3.138724328914414

Epoch: 6| Step: 4
Training loss: 2.883601879190062
Validation loss: 3.1378211448276625

Epoch: 6| Step: 5
Training loss: 3.485077517726891
Validation loss: 3.1386944298005552

Epoch: 6| Step: 6
Training loss: 2.3330219151807956
Validation loss: 3.1382420041136827

Epoch: 6| Step: 7
Training loss: 3.4255976524437632
Validation loss: 3.1376344934756983

Epoch: 6| Step: 8
Training loss: 3.9443713585853843
Validation loss: 3.1371993085477987

Epoch: 6| Step: 9
Training loss: 3.3188164425968
Validation loss: 3.135336800527212

Epoch: 6| Step: 10
Training loss: 2.6013262300627353
Validation loss: 3.1365038450117178

Epoch: 6| Step: 11
Training loss: 4.362082020320337
Validation loss: 3.1357424425770435

Epoch: 6| Step: 12
Training loss: 3.196412435796857
Validation loss: 3.1377314175441846

Epoch: 6| Step: 13
Training loss: 2.7944816706532873
Validation loss: 3.138994429008227

Epoch: 57| Step: 0
Training loss: 2.8389459631205654
Validation loss: 3.1368587307732767

Epoch: 6| Step: 1
Training loss: 4.196486438479782
Validation loss: 3.1408992201314825

Epoch: 6| Step: 2
Training loss: 3.5203509630454657
Validation loss: 3.1423191167841167

Epoch: 6| Step: 3
Training loss: 3.217965484121082
Validation loss: 3.166649022293372

Epoch: 6| Step: 4
Training loss: 3.4709103017441847
Validation loss: 3.1698724024089056

Epoch: 6| Step: 5
Training loss: 2.4626987512615774
Validation loss: 3.1744971976863874

Epoch: 6| Step: 6
Training loss: 2.7298056652780844
Validation loss: 3.1610150297140143

Epoch: 6| Step: 7
Training loss: 4.045818411854899
Validation loss: 3.1409780750461644

Epoch: 6| Step: 8
Training loss: 2.9649553642322592
Validation loss: 3.1385600411770866

Epoch: 6| Step: 9
Training loss: 3.419302195249991
Validation loss: 3.136437347481726

Epoch: 6| Step: 10
Training loss: 4.014927191163221
Validation loss: 3.1385871905442424

Epoch: 6| Step: 11
Training loss: 3.8223362342577514
Validation loss: 3.145757939256201

Epoch: 6| Step: 12
Training loss: 3.199962860130314
Validation loss: 3.143592158919961

Epoch: 6| Step: 13
Training loss: 3.000304842401663
Validation loss: 3.1413139298215804

Epoch: 58| Step: 0
Training loss: 2.830506728673234
Validation loss: 3.135587678943704

Epoch: 6| Step: 1
Training loss: 3.472658446990306
Validation loss: 3.1341697729967346

Epoch: 6| Step: 2
Training loss: 3.4326737248633443
Validation loss: 3.1343952696078405

Epoch: 6| Step: 3
Training loss: 3.8460468159968935
Validation loss: 3.1349755757991016

Epoch: 6| Step: 4
Training loss: 3.3644328521681106
Validation loss: 3.1359608316007535

Epoch: 6| Step: 5
Training loss: 3.1194139526845626
Validation loss: 3.1385371537791777

Epoch: 6| Step: 6
Training loss: 2.4047523891327254
Validation loss: 3.137236035443019

Epoch: 6| Step: 7
Training loss: 3.784090598749705
Validation loss: 3.1400918840218828

Epoch: 6| Step: 8
Training loss: 3.598481355997
Validation loss: 3.1355028882959233

Epoch: 6| Step: 9
Training loss: 3.331071722187827
Validation loss: 3.136526801191896

Epoch: 6| Step: 10
Training loss: 3.6171685170938175
Validation loss: 3.1306079489776577

Epoch: 6| Step: 11
Training loss: 3.26930314411125
Validation loss: 3.1285322608313035

Epoch: 6| Step: 12
Training loss: 3.0117215998892157
Validation loss: 3.1293784185179216

Epoch: 6| Step: 13
Training loss: 4.514420820666737
Validation loss: 3.129401481035642

Epoch: 59| Step: 0
Training loss: 3.3355075103441907
Validation loss: 3.1270852529321975

Epoch: 6| Step: 1
Training loss: 3.082362786895245
Validation loss: 3.1283668404502145

Epoch: 6| Step: 2
Training loss: 3.5956100294337605
Validation loss: 3.1277725652402597

Epoch: 6| Step: 3
Training loss: 3.529437654998663
Validation loss: 3.128982837765837

Epoch: 6| Step: 4
Training loss: 3.423943160235924
Validation loss: 3.1260649328860644

Epoch: 6| Step: 5
Training loss: 3.1303701417118543
Validation loss: 3.1258707355197317

Epoch: 6| Step: 6
Training loss: 3.5646949832329735
Validation loss: 3.1275226558864317

Epoch: 6| Step: 7
Training loss: 3.666375900068157
Validation loss: 3.1266159785181395

Epoch: 6| Step: 8
Training loss: 3.5146530503234525
Validation loss: 3.125526829273

Epoch: 6| Step: 9
Training loss: 2.4933228014487256
Validation loss: 3.12643118295364

Epoch: 6| Step: 10
Training loss: 3.3036721114792877
Validation loss: 3.122907506498103

Epoch: 6| Step: 11
Training loss: 2.7705235606873093
Validation loss: 3.1230618313622966

Epoch: 6| Step: 12
Training loss: 3.9626244558530903
Validation loss: 3.1237700833321216

Epoch: 6| Step: 13
Training loss: 4.018608439608611
Validation loss: 3.1255821030430324

Epoch: 60| Step: 0
Training loss: 3.740702993652229
Validation loss: 3.1217476120101284

Epoch: 6| Step: 1
Training loss: 3.7287014434855035
Validation loss: 3.1214361628636094

Epoch: 6| Step: 2
Training loss: 3.673079402706125
Validation loss: 3.120587118808622

Epoch: 6| Step: 3
Training loss: 3.77060253357292
Validation loss: 3.1212356996930426

Epoch: 6| Step: 4
Training loss: 3.224039416713521
Validation loss: 3.12112593031981

Epoch: 6| Step: 5
Training loss: 2.316939139866267
Validation loss: 3.120247430910797

Epoch: 6| Step: 6
Training loss: 3.587893947543712
Validation loss: 3.118585069754608

Epoch: 6| Step: 7
Training loss: 3.4660774451582816
Validation loss: 3.118495016713915

Epoch: 6| Step: 8
Training loss: 3.5970560540335446
Validation loss: 3.118715188907358

Epoch: 6| Step: 9
Training loss: 3.0909523693155547
Validation loss: 3.1187677811881374

Epoch: 6| Step: 10
Training loss: 2.913845514395486
Validation loss: 3.1226842162880857

Epoch: 6| Step: 11
Training loss: 3.6567647196704978
Validation loss: 3.1186265066794037

Epoch: 6| Step: 12
Training loss: 2.566219421739676
Validation loss: 3.1207606184429095

Epoch: 6| Step: 13
Training loss: 3.7682507489510586
Validation loss: 3.1230069784300727

Epoch: 61| Step: 0
Training loss: 4.02408927897313
Validation loss: 3.1202950743305946

Epoch: 6| Step: 1
Training loss: 3.7007576501797264
Validation loss: 3.1142882112868198

Epoch: 6| Step: 2
Training loss: 2.924075190744994
Validation loss: 3.1151466454228163

Epoch: 6| Step: 3
Training loss: 2.9734485587928217
Validation loss: 3.115159946071618

Epoch: 6| Step: 4
Training loss: 2.8088415299200946
Validation loss: 3.1150595882209147

Epoch: 6| Step: 5
Training loss: 4.081967936485669
Validation loss: 3.1148833068892094

Epoch: 6| Step: 6
Training loss: 2.9239698438120003
Validation loss: 3.1146075518407947

Epoch: 6| Step: 7
Training loss: 3.2516363866019566
Validation loss: 3.113731049268366

Epoch: 6| Step: 8
Training loss: 3.5648506841648535
Validation loss: 3.113979226001916

Epoch: 6| Step: 9
Training loss: 3.3961363269145672
Validation loss: 3.113602127315226

Epoch: 6| Step: 10
Training loss: 2.9516394375435993
Validation loss: 3.1130049560992736

Epoch: 6| Step: 11
Training loss: 3.833706644097277
Validation loss: 3.1119717321600118

Epoch: 6| Step: 12
Training loss: 3.5133347574866907
Validation loss: 3.110187084163241

Epoch: 6| Step: 13
Training loss: 2.653439549647595
Validation loss: 3.111660585672402

Epoch: 62| Step: 0
Training loss: 3.055353194577629
Validation loss: 3.1110263379902077

Epoch: 6| Step: 1
Training loss: 4.038086291754821
Validation loss: 3.112732454230066

Epoch: 6| Step: 2
Training loss: 4.0921229266723
Validation loss: 3.1109178960906676

Epoch: 6| Step: 3
Training loss: 2.801504214734174
Validation loss: 3.1113526363591872

Epoch: 6| Step: 4
Training loss: 3.0065338191127586
Validation loss: 3.1119628936030437

Epoch: 6| Step: 5
Training loss: 3.3881019310868687
Validation loss: 3.1104663680036326

Epoch: 6| Step: 6
Training loss: 3.1712447418782777
Validation loss: 3.11094169373933

Epoch: 6| Step: 7
Training loss: 3.7519625296765264
Validation loss: 3.1114156549122

Epoch: 6| Step: 8
Training loss: 3.1889510498309273
Validation loss: 3.109146923568325

Epoch: 6| Step: 9
Training loss: 3.2953211299951453
Validation loss: 3.1085048081805584

Epoch: 6| Step: 10
Training loss: 3.2467027223792577
Validation loss: 3.1092116045572844

Epoch: 6| Step: 11
Training loss: 3.467868314845431
Validation loss: 3.1096567047035797

Epoch: 6| Step: 12
Training loss: 2.952217406622825
Validation loss: 3.1075425759339406

Epoch: 6| Step: 13
Training loss: 3.600607788913555
Validation loss: 3.1107537847642135

Epoch: 63| Step: 0
Training loss: 3.3543063938267466
Validation loss: 3.111430719093098

Epoch: 6| Step: 1
Training loss: 2.9148643556314857
Validation loss: 3.107129515541064

Epoch: 6| Step: 2
Training loss: 3.6793456354098577
Validation loss: 3.110135608764954

Epoch: 6| Step: 3
Training loss: 2.870852920915712
Validation loss: 3.112902710368527

Epoch: 6| Step: 4
Training loss: 3.9960469740053144
Validation loss: 3.1106496667445893

Epoch: 6| Step: 5
Training loss: 3.489763412763534
Validation loss: 3.1155600549177973

Epoch: 6| Step: 6
Training loss: 3.2711667581359545
Validation loss: 3.112925782946296

Epoch: 6| Step: 7
Training loss: 3.8737040167581522
Validation loss: 3.1126430909027563

Epoch: 6| Step: 8
Training loss: 2.7015089375010763
Validation loss: 3.1101443362908174

Epoch: 6| Step: 9
Training loss: 3.2758727563313306
Validation loss: 3.1108609665770057

Epoch: 6| Step: 10
Training loss: 3.3357440972826664
Validation loss: 3.1106073216506327

Epoch: 6| Step: 11
Training loss: 3.245308350664626
Validation loss: 3.1100839882622844

Epoch: 6| Step: 12
Training loss: 3.40850223660602
Validation loss: 3.1040262814215684

Epoch: 6| Step: 13
Training loss: 3.6155950942323467
Validation loss: 3.1049949271625144

Epoch: 64| Step: 0
Training loss: 3.574870265927547
Validation loss: 3.1051752291365893

Epoch: 6| Step: 1
Training loss: 3.7357733115665086
Validation loss: 3.106539361578409

Epoch: 6| Step: 2
Training loss: 3.3169022583474876
Validation loss: 3.110783177760657

Epoch: 6| Step: 3
Training loss: 3.277013459686399
Validation loss: 3.113368750527952

Epoch: 6| Step: 4
Training loss: 3.027628829823226
Validation loss: 3.111180952260444

Epoch: 6| Step: 5
Training loss: 2.791360287911163
Validation loss: 3.105013231780297

Epoch: 6| Step: 6
Training loss: 3.1409089069243445
Validation loss: 3.102855793469621

Epoch: 6| Step: 7
Training loss: 3.46875632345637
Validation loss: 3.104619160787018

Epoch: 6| Step: 8
Training loss: 3.604716676115264
Validation loss: 3.102590089661538

Epoch: 6| Step: 9
Training loss: 3.4608752242915712
Validation loss: 3.101905796109341

Epoch: 6| Step: 10
Training loss: 3.3919547150036147
Validation loss: 3.102417120760304

Epoch: 6| Step: 11
Training loss: 3.3277948779935342
Validation loss: 3.104234124162518

Epoch: 6| Step: 12
Training loss: 3.018697013942821
Validation loss: 3.1018032572454617

Epoch: 6| Step: 13
Training loss: 4.222971746496074
Validation loss: 3.107883875175674

Epoch: 65| Step: 0
Training loss: 2.5814639577793295
Validation loss: 3.1061062132291934

Epoch: 6| Step: 1
Training loss: 3.4795032878980248
Validation loss: 3.1140571095098517

Epoch: 6| Step: 2
Training loss: 3.271044892355526
Validation loss: 3.110394369340692

Epoch: 6| Step: 3
Training loss: 3.6252829342624544
Validation loss: 3.107470845300113

Epoch: 6| Step: 4
Training loss: 3.2995646565278003
Validation loss: 3.1023090191831866

Epoch: 6| Step: 5
Training loss: 2.8996362392245376
Validation loss: 3.100822220903066

Epoch: 6| Step: 6
Training loss: 3.7061268675036243
Validation loss: 3.1004293999476604

Epoch: 6| Step: 7
Training loss: 2.795600472847324
Validation loss: 3.1019430086484876

Epoch: 6| Step: 8
Training loss: 4.238596933447836
Validation loss: 3.101184935538819

Epoch: 6| Step: 9
Training loss: 3.208609895222041
Validation loss: 3.1024228241298744

Epoch: 6| Step: 10
Training loss: 3.586809172889549
Validation loss: 3.103244680635033

Epoch: 6| Step: 11
Training loss: 3.139717540306796
Validation loss: 3.1011239865925

Epoch: 6| Step: 12
Training loss: 3.176108255477558
Validation loss: 3.099865730995421

Epoch: 6| Step: 13
Training loss: 4.082049239269572
Validation loss: 3.0992420447547233

Epoch: 66| Step: 0
Training loss: 3.8232217332626544
Validation loss: 3.098055411203137

Epoch: 6| Step: 1
Training loss: 4.026386965032981
Validation loss: 3.0968416489283914

Epoch: 6| Step: 2
Training loss: 2.6206689254387427
Validation loss: 3.0982515580596997

Epoch: 6| Step: 3
Training loss: 3.026081358517431
Validation loss: 3.098109503573823

Epoch: 6| Step: 4
Training loss: 3.561984643970526
Validation loss: 3.097357163378347

Epoch: 6| Step: 5
Training loss: 3.7913426410991655
Validation loss: 3.0975566724333063

Epoch: 6| Step: 6
Training loss: 4.061839827669788
Validation loss: 3.0961357241183403

Epoch: 6| Step: 7
Training loss: 2.207890004217021
Validation loss: 3.097369716046006

Epoch: 6| Step: 8
Training loss: 2.9711284546150547
Validation loss: 3.0973009099838618

Epoch: 6| Step: 9
Training loss: 3.8798513500014287
Validation loss: 3.0956222174240113

Epoch: 6| Step: 10
Training loss: 2.9905874092505913
Validation loss: 3.0957259829242654

Epoch: 6| Step: 11
Training loss: 3.275315212776015
Validation loss: 3.0946297785224024

Epoch: 6| Step: 12
Training loss: 3.1667728071661583
Validation loss: 3.09419942628248

Epoch: 6| Step: 13
Training loss: 2.85671740157107
Validation loss: 3.0936399348901324

Epoch: 67| Step: 0
Training loss: 3.263090619525506
Validation loss: 3.094465220090183

Epoch: 6| Step: 1
Training loss: 3.0414941468804133
Validation loss: 3.096138675155273

Epoch: 6| Step: 2
Training loss: 3.0595152965948147
Validation loss: 3.0945241727417527

Epoch: 6| Step: 3
Training loss: 3.041579118975422
Validation loss: 3.097854554736587

Epoch: 6| Step: 4
Training loss: 3.404932729809981
Validation loss: 3.1036903449206372

Epoch: 6| Step: 5
Training loss: 3.3721840024818097
Validation loss: 3.1093670816125383

Epoch: 6| Step: 6
Training loss: 3.233115720471955
Validation loss: 3.104677687774983

Epoch: 6| Step: 7
Training loss: 3.5661543457381306
Validation loss: 3.0968126732882104

Epoch: 6| Step: 8
Training loss: 3.6724598520264444
Validation loss: 3.09935253128607

Epoch: 6| Step: 9
Training loss: 3.4646240990481316
Validation loss: 3.0940484211370425

Epoch: 6| Step: 10
Training loss: 3.0862771149159163
Validation loss: 3.098217750023582

Epoch: 6| Step: 11
Training loss: 3.635914911413906
Validation loss: 3.0915269791989965

Epoch: 6| Step: 12
Training loss: 3.7260511515326638
Validation loss: 3.0926806392783717

Epoch: 6| Step: 13
Training loss: 3.388122478878939
Validation loss: 3.094343981708218

Epoch: 68| Step: 0
Training loss: 3.425102906177815
Validation loss: 3.096632364573342

Epoch: 6| Step: 1
Training loss: 2.971107911791617
Validation loss: 3.10291897715295

Epoch: 6| Step: 2
Training loss: 3.041527069929554
Validation loss: 3.1078316843888034

Epoch: 6| Step: 3
Training loss: 3.704079291761747
Validation loss: 3.1112941451209144

Epoch: 6| Step: 4
Training loss: 2.9409231166550702
Validation loss: 3.0987236553845485

Epoch: 6| Step: 5
Training loss: 4.064460164127734
Validation loss: 3.0951859386060963

Epoch: 6| Step: 6
Training loss: 4.189039943567465
Validation loss: 3.093135462374848

Epoch: 6| Step: 7
Training loss: 2.910299126106794
Validation loss: 3.0929525969191003

Epoch: 6| Step: 8
Training loss: 3.2804561562965278
Validation loss: 3.0911477071100166

Epoch: 6| Step: 9
Training loss: 3.3513135128412768
Validation loss: 3.0916891516840312

Epoch: 6| Step: 10
Training loss: 3.0866441907400812
Validation loss: 3.093067016321978

Epoch: 6| Step: 11
Training loss: 3.4222088655263443
Validation loss: 3.0924785375800763

Epoch: 6| Step: 12
Training loss: 2.5609062635135493
Validation loss: 3.0915219440048287

Epoch: 6| Step: 13
Training loss: 4.0058024759031925
Validation loss: 3.092153817544667

Epoch: 69| Step: 0
Training loss: 2.7194209531506095
Validation loss: 3.0965826690095373

Epoch: 6| Step: 1
Training loss: 3.797369779522616
Validation loss: 3.094504468133468

Epoch: 6| Step: 2
Training loss: 3.632442069907702
Validation loss: 3.090552517172982

Epoch: 6| Step: 3
Training loss: 2.785622406586657
Validation loss: 3.0898525365011715

Epoch: 6| Step: 4
Training loss: 3.3651230008231416
Validation loss: 3.094070880317185

Epoch: 6| Step: 5
Training loss: 3.74768783495589
Validation loss: 3.0905783911044318

Epoch: 6| Step: 6
Training loss: 3.4645000919535267
Validation loss: 3.093193699422436

Epoch: 6| Step: 7
Training loss: 2.9324890576196667
Validation loss: 3.0910108921631454

Epoch: 6| Step: 8
Training loss: 3.0201208567910034
Validation loss: 3.090064594737771

Epoch: 6| Step: 9
Training loss: 3.8153098336291005
Validation loss: 3.092403008834937

Epoch: 6| Step: 10
Training loss: 3.7619088858684724
Validation loss: 3.092269345924868

Epoch: 6| Step: 11
Training loss: 2.6858838566987226
Validation loss: 3.090305846239183

Epoch: 6| Step: 12
Training loss: 3.4814175084356074
Validation loss: 3.088414647757531

Epoch: 6| Step: 13
Training loss: 3.4763184879693294
Validation loss: 3.0877047372522526

Epoch: 70| Step: 0
Training loss: 2.5451069879433605
Validation loss: 3.0862715328894135

Epoch: 6| Step: 1
Training loss: 3.5412949011662906
Validation loss: 3.086790649730458

Epoch: 6| Step: 2
Training loss: 4.075063908549736
Validation loss: 3.0856268937627607

Epoch: 6| Step: 3
Training loss: 3.389267610188325
Validation loss: 3.084344977021514

Epoch: 6| Step: 4
Training loss: 3.650329099476493
Validation loss: 3.0839732865962484

Epoch: 6| Step: 5
Training loss: 3.7331791323650907
Validation loss: 3.083564430086055

Epoch: 6| Step: 6
Training loss: 3.244250567259573
Validation loss: 3.0829571231407544

Epoch: 6| Step: 7
Training loss: 3.053591792676898
Validation loss: 3.083170290901297

Epoch: 6| Step: 8
Training loss: 3.1936708444240796
Validation loss: 3.0829140409373967

Epoch: 6| Step: 9
Training loss: 3.7655021679104217
Validation loss: 3.0831959756744056

Epoch: 6| Step: 10
Training loss: 3.120452012795607
Validation loss: 3.0832590392412453

Epoch: 6| Step: 11
Training loss: 3.132455248927851
Validation loss: 3.0804134207750287

Epoch: 6| Step: 12
Training loss: 2.8386903123111167
Validation loss: 3.0817162636509035

Epoch: 6| Step: 13
Training loss: 3.286540534698798
Validation loss: 3.081177471358689

Epoch: 71| Step: 0
Training loss: 3.336495774879107
Validation loss: 3.0815831388415234

Epoch: 6| Step: 1
Training loss: 3.1796792519952146
Validation loss: 3.0817350492727544

Epoch: 6| Step: 2
Training loss: 2.732009474831456
Validation loss: 3.0818829310929794

Epoch: 6| Step: 3
Training loss: 3.701581029495359
Validation loss: 3.080784116069147

Epoch: 6| Step: 4
Training loss: 2.9353803738438993
Validation loss: 3.080104414855078

Epoch: 6| Step: 5
Training loss: 3.1668264114510083
Validation loss: 3.080402788069345

Epoch: 6| Step: 6
Training loss: 2.724030989096733
Validation loss: 3.0798585985303126

Epoch: 6| Step: 7
Training loss: 3.773750876609496
Validation loss: 3.079049585732915

Epoch: 6| Step: 8
Training loss: 3.4271017767845677
Validation loss: 3.0782958493880175

Epoch: 6| Step: 9
Training loss: 2.8893655868664094
Validation loss: 3.079815928306201

Epoch: 6| Step: 10
Training loss: 3.3378047675378992
Validation loss: 3.0785835307287934

Epoch: 6| Step: 11
Training loss: 4.239277496678845
Validation loss: 3.0799314749959845

Epoch: 6| Step: 12
Training loss: 3.821695837904112
Validation loss: 3.078153480276015

Epoch: 6| Step: 13
Training loss: 3.1744243730797606
Validation loss: 3.07780723332847

Epoch: 72| Step: 0
Training loss: 3.1730509865863428
Validation loss: 3.083368599403686

Epoch: 6| Step: 1
Training loss: 2.915438493362798
Validation loss: 3.0780698626493677

Epoch: 6| Step: 2
Training loss: 3.342728645989712
Validation loss: 3.0792966613366923

Epoch: 6| Step: 3
Training loss: 2.4694070062515845
Validation loss: 3.080244298063833

Epoch: 6| Step: 4
Training loss: 3.9926130512166598
Validation loss: 3.077212239001884

Epoch: 6| Step: 5
Training loss: 2.1855014936083785
Validation loss: 3.077757397893896

Epoch: 6| Step: 6
Training loss: 3.146353436521359
Validation loss: 3.0775821553383125

Epoch: 6| Step: 7
Training loss: 2.8462305673263386
Validation loss: 3.07668662654552

Epoch: 6| Step: 8
Training loss: 3.9648101955553665
Validation loss: 3.0753191197337446

Epoch: 6| Step: 9
Training loss: 3.5183717297353723
Validation loss: 3.075662205161981

Epoch: 6| Step: 10
Training loss: 3.5708988968577073
Validation loss: 3.0754041550721603

Epoch: 6| Step: 11
Training loss: 3.4769838227846632
Validation loss: 3.0756894638017775

Epoch: 6| Step: 12
Training loss: 4.472242577758546
Validation loss: 3.0743225441220057

Epoch: 6| Step: 13
Training loss: 2.80231913504466
Validation loss: 3.0743018319424316

Epoch: 73| Step: 0
Training loss: 3.1901167058373887
Validation loss: 3.0755609885835664

Epoch: 6| Step: 1
Training loss: 3.0998388925342506
Validation loss: 3.0740638078121503

Epoch: 6| Step: 2
Training loss: 3.4430162039183516
Validation loss: 3.07542505488772

Epoch: 6| Step: 3
Training loss: 3.01700698731359
Validation loss: 3.0745281440045567

Epoch: 6| Step: 4
Training loss: 3.7616581580173283
Validation loss: 3.0759130383789137

Epoch: 6| Step: 5
Training loss: 3.4174371796466216
Validation loss: 3.071951595131737

Epoch: 6| Step: 6
Training loss: 2.9856917587077096
Validation loss: 3.0722468932927036

Epoch: 6| Step: 7
Training loss: 3.5935135473333286
Validation loss: 3.0737633021493784

Epoch: 6| Step: 8
Training loss: 3.4162586402714012
Validation loss: 3.075325894537817

Epoch: 6| Step: 9
Training loss: 3.8266553899441575
Validation loss: 3.0765824988755464

Epoch: 6| Step: 10
Training loss: 2.875557057689659
Validation loss: 3.07946973591308

Epoch: 6| Step: 11
Training loss: 2.7673553398664588
Validation loss: 3.0805254764090053

Epoch: 6| Step: 12
Training loss: 3.4354895521351234
Validation loss: 3.079613302015486

Epoch: 6| Step: 13
Training loss: 4.135507321585196
Validation loss: 3.0768254449035037

Epoch: 74| Step: 0
Training loss: 2.314696840741477
Validation loss: 3.076877490903763

Epoch: 6| Step: 1
Training loss: 3.8418524795798077
Validation loss: 3.0737057520369886

Epoch: 6| Step: 2
Training loss: 2.8962282053358317
Validation loss: 3.072689305913753

Epoch: 6| Step: 3
Training loss: 3.77042497703459
Validation loss: 3.073850996003139

Epoch: 6| Step: 4
Training loss: 2.597671210453865
Validation loss: 3.0745459279267653

Epoch: 6| Step: 5
Training loss: 3.2899423903781106
Validation loss: 3.0738133583027274

Epoch: 6| Step: 6
Training loss: 3.3302336267762254
Validation loss: 3.0774877294662963

Epoch: 6| Step: 7
Training loss: 3.1807625567629034
Validation loss: 3.0717546193336664

Epoch: 6| Step: 8
Training loss: 3.4397471625538647
Validation loss: 3.070407191205588

Epoch: 6| Step: 9
Training loss: 3.4124335761120617
Validation loss: 3.0714580569018652

Epoch: 6| Step: 10
Training loss: 4.186938120025522
Validation loss: 3.07006647749951

Epoch: 6| Step: 11
Training loss: 3.9237311480829726
Validation loss: 3.0696634078609835

Epoch: 6| Step: 12
Training loss: 3.2310930638229785
Validation loss: 3.0703831683087865

Epoch: 6| Step: 13
Training loss: 2.4191348417814473
Validation loss: 3.0700473282104532

Epoch: 75| Step: 0
Training loss: 3.1924646646550063
Validation loss: 3.069664386660919

Epoch: 6| Step: 1
Training loss: 3.7414421342684947
Validation loss: 3.06944926281677

Epoch: 6| Step: 2
Training loss: 2.8754030028134956
Validation loss: 3.068554371497327

Epoch: 6| Step: 3
Training loss: 2.7624471046596497
Validation loss: 3.0691099091443346

Epoch: 6| Step: 4
Training loss: 3.188145740398943
Validation loss: 3.0673963536901394

Epoch: 6| Step: 5
Training loss: 3.3569694955466547
Validation loss: 3.069027912910507

Epoch: 6| Step: 6
Training loss: 3.174958332419129
Validation loss: 3.0673268969982344

Epoch: 6| Step: 7
Training loss: 3.851540462902854
Validation loss: 3.067274071282735

Epoch: 6| Step: 8
Training loss: 3.6088816648274213
Validation loss: 3.067722472549252

Epoch: 6| Step: 9
Training loss: 2.751660452577108
Validation loss: 3.0668403284284858

Epoch: 6| Step: 10
Training loss: 3.055266888787091
Validation loss: 3.0664304516126393

Epoch: 6| Step: 11
Training loss: 3.6320101600538477
Validation loss: 3.0664642422555177

Epoch: 6| Step: 12
Training loss: 4.046160189268546
Validation loss: 3.0680056754699074

Epoch: 6| Step: 13
Training loss: 3.042080437373603
Validation loss: 3.0677866973859995

Epoch: 76| Step: 0
Training loss: 3.3837899080085525
Validation loss: 3.069836101088397

Epoch: 6| Step: 1
Training loss: 3.543153802145995
Validation loss: 3.0713245291914912

Epoch: 6| Step: 2
Training loss: 3.934418214010714
Validation loss: 3.068789920806616

Epoch: 6| Step: 3
Training loss: 3.8527750888171197
Validation loss: 3.070449648605764

Epoch: 6| Step: 4
Training loss: 3.94807576015795
Validation loss: 3.0670286434326757

Epoch: 6| Step: 5
Training loss: 3.3730094125651973
Validation loss: 3.064741006576207

Epoch: 6| Step: 6
Training loss: 2.7515480712650953
Validation loss: 3.06495835122981

Epoch: 6| Step: 7
Training loss: 2.6846881617173497
Validation loss: 3.063919767924038

Epoch: 6| Step: 8
Training loss: 2.972115145345958
Validation loss: 3.0626574424134634

Epoch: 6| Step: 9
Training loss: 3.0354252012434353
Validation loss: 3.065298359381736

Epoch: 6| Step: 10
Training loss: 3.929691504292505
Validation loss: 3.065438975512666

Epoch: 6| Step: 11
Training loss: 2.6751820582531955
Validation loss: 3.062452416785932

Epoch: 6| Step: 12
Training loss: 3.0521484125031995
Validation loss: 3.0637436702780017

Epoch: 6| Step: 13
Training loss: 2.9977214425369643
Validation loss: 3.0648906702865135

Epoch: 77| Step: 0
Training loss: 4.012255015277217
Validation loss: 3.0688844305192706

Epoch: 6| Step: 1
Training loss: 3.252110602887467
Validation loss: 3.0656494820358047

Epoch: 6| Step: 2
Training loss: 3.647324582248798
Validation loss: 3.0696436639297695

Epoch: 6| Step: 3
Training loss: 3.05680348507828
Validation loss: 3.0638502935007246

Epoch: 6| Step: 4
Training loss: 2.7527746594673643
Validation loss: 3.0616454421597488

Epoch: 6| Step: 5
Training loss: 3.1192069718405526
Validation loss: 3.061109674687882

Epoch: 6| Step: 6
Training loss: 3.1611522712851046
Validation loss: 3.061946680788148

Epoch: 6| Step: 7
Training loss: 3.8079052111985594
Validation loss: 3.060744230342714

Epoch: 6| Step: 8
Training loss: 2.876788868200047
Validation loss: 3.0610018462921764

Epoch: 6| Step: 9
Training loss: 3.914114275987701
Validation loss: 3.060072656190209

Epoch: 6| Step: 10
Training loss: 3.213568210749789
Validation loss: 3.059811770668376

Epoch: 6| Step: 11
Training loss: 3.4854299547694962
Validation loss: 3.058269806223019

Epoch: 6| Step: 12
Training loss: 2.8777174339039147
Validation loss: 3.0609406382735136

Epoch: 6| Step: 13
Training loss: 3.0537949450788857
Validation loss: 3.0601153269292416

Epoch: 78| Step: 0
Training loss: 3.432848331922474
Validation loss: 3.0591777840640466

Epoch: 6| Step: 1
Training loss: 2.5723311546975225
Validation loss: 3.0588407589481412

Epoch: 6| Step: 2
Training loss: 3.15890300783209
Validation loss: 3.061789340818155

Epoch: 6| Step: 3
Training loss: 3.169746473986616
Validation loss: 3.061616919687313

Epoch: 6| Step: 4
Training loss: 3.9907828470794984
Validation loss: 3.0614851625623603

Epoch: 6| Step: 5
Training loss: 3.5273583497413803
Validation loss: 3.058582515064929

Epoch: 6| Step: 6
Training loss: 3.4107531257877346
Validation loss: 3.059821998195846

Epoch: 6| Step: 7
Training loss: 3.1406571875293996
Validation loss: 3.0627921113495677

Epoch: 6| Step: 8
Training loss: 3.3979668653106407
Validation loss: 3.0577281015617115

Epoch: 6| Step: 9
Training loss: 3.2546608589096584
Validation loss: 3.0582840617249207

Epoch: 6| Step: 10
Training loss: 2.907145372512174
Validation loss: 3.0558088451819208

Epoch: 6| Step: 11
Training loss: 3.391342860580489
Validation loss: 3.0564233858854557

Epoch: 6| Step: 12
Training loss: 3.8124949971150577
Validation loss: 3.056097589695371

Epoch: 6| Step: 13
Training loss: 3.132151850345549
Validation loss: 3.0552898705074583

Epoch: 79| Step: 0
Training loss: 2.4778791231071926
Validation loss: 3.056160921355951

Epoch: 6| Step: 1
Training loss: 3.99298649087785
Validation loss: 3.0547586279648695

Epoch: 6| Step: 2
Training loss: 3.3698323565251704
Validation loss: 3.055603018553949

Epoch: 6| Step: 3
Training loss: 3.6941739479668407
Validation loss: 3.0541158749287938

Epoch: 6| Step: 4
Training loss: 3.664667335806745
Validation loss: 3.0541978199191475

Epoch: 6| Step: 5
Training loss: 3.4760466117850384
Validation loss: 3.0540571781192827

Epoch: 6| Step: 6
Training loss: 3.178876393783364
Validation loss: 3.052775767723612

Epoch: 6| Step: 7
Training loss: 2.7360956500327123
Validation loss: 3.054626697549592

Epoch: 6| Step: 8
Training loss: 3.628893241407322
Validation loss: 3.0528660076260454

Epoch: 6| Step: 9
Training loss: 3.001998235876085
Validation loss: 3.053113109671983

Epoch: 6| Step: 10
Training loss: 2.9736890966040344
Validation loss: 3.051780367860196

Epoch: 6| Step: 11
Training loss: 3.528639376964035
Validation loss: 3.0531411649599094

Epoch: 6| Step: 12
Training loss: 3.4350105287704245
Validation loss: 3.053640822797799

Epoch: 6| Step: 13
Training loss: 2.83520414259933
Validation loss: 3.0529173653922967

Epoch: 80| Step: 0
Training loss: 2.72835894758085
Validation loss: 3.0514921456944255

Epoch: 6| Step: 1
Training loss: 3.0175468369130356
Validation loss: 3.054068424665103

Epoch: 6| Step: 2
Training loss: 3.0361893514557137
Validation loss: 3.0528902804692684

Epoch: 6| Step: 3
Training loss: 2.4960052999904803
Validation loss: 3.0508062747063787

Epoch: 6| Step: 4
Training loss: 2.497395875763056
Validation loss: 3.0524714068252856

Epoch: 6| Step: 5
Training loss: 3.3110362723623874
Validation loss: 3.0526558641673285

Epoch: 6| Step: 6
Training loss: 3.7744381922336716
Validation loss: 3.0531134052396305

Epoch: 6| Step: 7
Training loss: 3.7183104183141245
Validation loss: 3.052481753010805

Epoch: 6| Step: 8
Training loss: 3.151035344561495
Validation loss: 3.050364618984466

Epoch: 6| Step: 9
Training loss: 3.6978108708824475
Validation loss: 3.0515309055429025

Epoch: 6| Step: 10
Training loss: 3.427128908420522
Validation loss: 3.0523735097996165

Epoch: 6| Step: 11
Training loss: 3.690665745005557
Validation loss: 3.053822849711293

Epoch: 6| Step: 12
Training loss: 3.9485705529496484
Validation loss: 3.050561679230884

Epoch: 6| Step: 13
Training loss: 3.7529417579252287
Validation loss: 3.0494709559999005

Epoch: 81| Step: 0
Training loss: 3.539400400363287
Validation loss: 3.047317837027741

Epoch: 6| Step: 1
Training loss: 2.8845718928261803
Validation loss: 3.0484123682521007

Epoch: 6| Step: 2
Training loss: 2.72747997161197
Validation loss: 3.04847852372636

Epoch: 6| Step: 3
Training loss: 3.06303432240873
Validation loss: 3.050839766148027

Epoch: 6| Step: 4
Training loss: 3.524142920004476
Validation loss: 3.050300416452234

Epoch: 6| Step: 5
Training loss: 3.472643068028974
Validation loss: 3.049623992749166

Epoch: 6| Step: 6
Training loss: 3.801985202028071
Validation loss: 3.048599281138274

Epoch: 6| Step: 7
Training loss: 3.473247464876424
Validation loss: 3.05071725371577

Epoch: 6| Step: 8
Training loss: 3.6348537821791767
Validation loss: 3.0500559888596412

Epoch: 6| Step: 9
Training loss: 3.635761204581946
Validation loss: 3.048651629896483

Epoch: 6| Step: 10
Training loss: 3.0750385437077186
Validation loss: 3.048490570417605

Epoch: 6| Step: 11
Training loss: 3.481007406935336
Validation loss: 3.05294739415734

Epoch: 6| Step: 12
Training loss: 2.6184301358529263
Validation loss: 3.051467450904415

Epoch: 6| Step: 13
Training loss: 3.260707090725315
Validation loss: 3.0503129602192693

Epoch: 82| Step: 0
Training loss: 2.961686414553684
Validation loss: 3.0562886208627003

Epoch: 6| Step: 1
Training loss: 3.3276378292941104
Validation loss: 3.05508563013164

Epoch: 6| Step: 2
Training loss: 3.3735171698685558
Validation loss: 3.0534861151077086

Epoch: 6| Step: 3
Training loss: 3.275421633769809
Validation loss: 3.051037630076063

Epoch: 6| Step: 4
Training loss: 3.0515885890581838
Validation loss: 3.045316756163469

Epoch: 6| Step: 5
Training loss: 3.331277849320738
Validation loss: 3.0457544479657823

Epoch: 6| Step: 6
Training loss: 3.113840854564297
Validation loss: 3.046084657977253

Epoch: 6| Step: 7
Training loss: 3.490598995757337
Validation loss: 3.0452757570567446

Epoch: 6| Step: 8
Training loss: 3.26359560755815
Validation loss: 3.0464351196640203

Epoch: 6| Step: 9
Training loss: 3.0191484334466887
Validation loss: 3.0482511893218764

Epoch: 6| Step: 10
Training loss: 3.3104280433595337
Validation loss: 3.047621822621434

Epoch: 6| Step: 11
Training loss: 3.1104443115586586
Validation loss: 3.046234071861867

Epoch: 6| Step: 12
Training loss: 4.070917183446199
Validation loss: 3.0455262889936043

Epoch: 6| Step: 13
Training loss: 3.892577022508311
Validation loss: 3.0447885458764725

Epoch: 83| Step: 0
Training loss: 3.4354469410564987
Validation loss: 3.045175136770537

Epoch: 6| Step: 1
Training loss: 3.3870876159778547
Validation loss: 3.0446367775000733

Epoch: 6| Step: 2
Training loss: 2.8211830887742364
Validation loss: 3.0443010394579955

Epoch: 6| Step: 3
Training loss: 2.679354544103907
Validation loss: 3.043371525719699

Epoch: 6| Step: 4
Training loss: 2.95326595878245
Validation loss: 3.0435322664644096

Epoch: 6| Step: 5
Training loss: 3.1028767066726197
Validation loss: 3.0439681034546333

Epoch: 6| Step: 6
Training loss: 3.4975908707435877
Validation loss: 3.043001011762164

Epoch: 6| Step: 7
Training loss: 3.460873846497741
Validation loss: 3.0419209321051675

Epoch: 6| Step: 8
Training loss: 3.2721489530203165
Validation loss: 3.04347163789741

Epoch: 6| Step: 9
Training loss: 2.9366502547337725
Validation loss: 3.043163451033425

Epoch: 6| Step: 10
Training loss: 3.250371911703658
Validation loss: 3.041260878639555

Epoch: 6| Step: 11
Training loss: 3.652509814072309
Validation loss: 3.043523208939679

Epoch: 6| Step: 12
Training loss: 4.433391119405884
Validation loss: 3.0411793471117265

Epoch: 6| Step: 13
Training loss: 3.0561365461451624
Validation loss: 3.0417338911835103

Epoch: 84| Step: 0
Training loss: 2.9842858426022874
Validation loss: 3.0444735444609337

Epoch: 6| Step: 1
Training loss: 4.190154188136915
Validation loss: 3.0427671445719704

Epoch: 6| Step: 2
Training loss: 3.0077287934780936
Validation loss: 3.0391575815580856

Epoch: 6| Step: 3
Training loss: 2.322117780722767
Validation loss: 3.0404239309447862

Epoch: 6| Step: 4
Training loss: 3.738209308183145
Validation loss: 3.03904872121096

Epoch: 6| Step: 5
Training loss: 3.780961459161421
Validation loss: 3.0392365102522905

Epoch: 6| Step: 6
Training loss: 2.641243585668124
Validation loss: 3.0401013440363185

Epoch: 6| Step: 7
Training loss: 2.8074354560749666
Validation loss: 3.0382927795216204

Epoch: 6| Step: 8
Training loss: 3.476227270530072
Validation loss: 3.0385368793760925

Epoch: 6| Step: 9
Training loss: 3.8473011763114617
Validation loss: 3.0383124580179404

Epoch: 6| Step: 10
Training loss: 3.042864071731303
Validation loss: 3.0390832937564545

Epoch: 6| Step: 11
Training loss: 3.1870475896771904
Validation loss: 3.0385416817634074

Epoch: 6| Step: 12
Training loss: 3.194322651923228
Validation loss: 3.039739318132114

Epoch: 6| Step: 13
Training loss: 3.8711701201788116
Validation loss: 3.0403415059390384

Epoch: 85| Step: 0
Training loss: 3.5692102245731148
Validation loss: 3.04370774447412

Epoch: 6| Step: 1
Training loss: 3.120927522169141
Validation loss: 3.0373686461222222

Epoch: 6| Step: 2
Training loss: 2.912282609807923
Validation loss: 3.0384501448623347

Epoch: 6| Step: 3
Training loss: 3.682543510806678
Validation loss: 3.0389401884978726

Epoch: 6| Step: 4
Training loss: 3.2769002512050402
Validation loss: 3.0351612148407163

Epoch: 6| Step: 5
Training loss: 2.581267320330056
Validation loss: 3.0373834774412063

Epoch: 6| Step: 6
Training loss: 3.3141403455282936
Validation loss: 3.0363214590315186

Epoch: 6| Step: 7
Training loss: 3.1990442100300913
Validation loss: 3.0373838977677665

Epoch: 6| Step: 8
Training loss: 3.1520424170568804
Validation loss: 3.0353515501351396

Epoch: 6| Step: 9
Training loss: 3.408489366113841
Validation loss: 3.036606229580936

Epoch: 6| Step: 10
Training loss: 3.224623866658079
Validation loss: 3.03504308270849

Epoch: 6| Step: 11
Training loss: 3.428523880765097
Validation loss: 3.0359807684863456

Epoch: 6| Step: 12
Training loss: 3.9615227682587686
Validation loss: 3.0369418931040606

Epoch: 6| Step: 13
Training loss: 3.289911953289995
Validation loss: 3.0351131709237267

Epoch: 86| Step: 0
Training loss: 3.1932354357638233
Validation loss: 3.0355480031700504

Epoch: 6| Step: 1
Training loss: 3.2161871327002083
Validation loss: 3.0343561947088418

Epoch: 6| Step: 2
Training loss: 3.2990128514553234
Validation loss: 3.0340580993132185

Epoch: 6| Step: 3
Training loss: 3.6540159263242877
Validation loss: 3.0331083503901217

Epoch: 6| Step: 4
Training loss: 2.850433544177185
Validation loss: 3.03263578124748

Epoch: 6| Step: 5
Training loss: 2.3360053725572754
Validation loss: 3.033731758696987

Epoch: 6| Step: 6
Training loss: 3.5447765982628296
Validation loss: 3.0322861790144593

Epoch: 6| Step: 7
Training loss: 3.3635992416001734
Validation loss: 3.032049840847136

Epoch: 6| Step: 8
Training loss: 3.573005311865372
Validation loss: 3.03341059238723

Epoch: 6| Step: 9
Training loss: 3.334403978702712
Validation loss: 3.0343086213195445

Epoch: 6| Step: 10
Training loss: 3.4775190430482454
Validation loss: 3.0325195678212706

Epoch: 6| Step: 11
Training loss: 3.5273964710034313
Validation loss: 3.0382821614171553

Epoch: 6| Step: 12
Training loss: 3.5274751454970747
Validation loss: 3.0344384942013725

Epoch: 6| Step: 13
Training loss: 3.0455646533807754
Validation loss: 3.036733751849229

Epoch: 87| Step: 0
Training loss: 2.7155527190849003
Validation loss: 3.0332170571217345

Epoch: 6| Step: 1
Training loss: 3.515993090539247
Validation loss: 3.0334563290436325

Epoch: 6| Step: 2
Training loss: 2.806933000874607
Validation loss: 3.030354565357465

Epoch: 6| Step: 3
Training loss: 3.4773571006434625
Validation loss: 3.0302728046847

Epoch: 6| Step: 4
Training loss: 3.9909917007241473
Validation loss: 3.0314927049958142

Epoch: 6| Step: 5
Training loss: 2.1930515144584177
Validation loss: 3.029886222898129

Epoch: 6| Step: 6
Training loss: 3.836592049313615
Validation loss: 3.029651008252537

Epoch: 6| Step: 7
Training loss: 3.4648781552160193
Validation loss: 3.0324500444132205

Epoch: 6| Step: 8
Training loss: 3.061455061786293
Validation loss: 3.033432001264608

Epoch: 6| Step: 9
Training loss: 3.4192893654097625
Validation loss: 3.033204102042412

Epoch: 6| Step: 10
Training loss: 3.106522521684717
Validation loss: 3.032255030009554

Epoch: 6| Step: 11
Training loss: 3.831380650842512
Validation loss: 3.034971024723839

Epoch: 6| Step: 12
Training loss: 3.2447561361083053
Validation loss: 3.035101555128368

Epoch: 6| Step: 13
Training loss: 3.1268471408588816
Validation loss: 3.0358454759955795

Epoch: 88| Step: 0
Training loss: 3.601259032598606
Validation loss: 3.0328110080764836

Epoch: 6| Step: 1
Training loss: 2.9625049961225014
Validation loss: 3.030982821561523

Epoch: 6| Step: 2
Training loss: 3.7291431248665887
Validation loss: 3.0310100159762716

Epoch: 6| Step: 3
Training loss: 2.6151877891260122
Validation loss: 3.029773573758138

Epoch: 6| Step: 4
Training loss: 3.122171877013541
Validation loss: 3.0304746034625496

Epoch: 6| Step: 5
Training loss: 3.254650603262416
Validation loss: 3.0289490854376906

Epoch: 6| Step: 6
Training loss: 3.121679449209698
Validation loss: 3.0268796253657912

Epoch: 6| Step: 7
Training loss: 2.920602449950061
Validation loss: 3.029640986038815

Epoch: 6| Step: 8
Training loss: 3.399785618474629
Validation loss: 3.028054000733468

Epoch: 6| Step: 9
Training loss: 3.123359707449909
Validation loss: 3.0281838616413035

Epoch: 6| Step: 10
Training loss: 3.7742292312037504
Validation loss: 3.0275977243516463

Epoch: 6| Step: 11
Training loss: 3.78010201170181
Validation loss: 3.027877889002141

Epoch: 6| Step: 12
Training loss: 2.4974332984975467
Validation loss: 3.0259015524225883

Epoch: 6| Step: 13
Training loss: 4.438938176456101
Validation loss: 3.0258716348181705

Epoch: 89| Step: 0
Training loss: 3.238414066844288
Validation loss: 3.026629294813018

Epoch: 6| Step: 1
Training loss: 3.2672745768301126
Validation loss: 3.027049478074888

Epoch: 6| Step: 2
Training loss: 3.5534727599062172
Validation loss: 3.026550547262534

Epoch: 6| Step: 3
Training loss: 2.998510944844547
Validation loss: 3.026081023033474

Epoch: 6| Step: 4
Training loss: 3.6650930553660146
Validation loss: 3.027458074755014

Epoch: 6| Step: 5
Training loss: 4.1642640371022495
Validation loss: 3.023629712829714

Epoch: 6| Step: 6
Training loss: 2.57931657477711
Validation loss: 3.026572055488053

Epoch: 6| Step: 7
Training loss: 3.076254649183968
Validation loss: 3.0240994870997895

Epoch: 6| Step: 8
Training loss: 2.7024300624609467
Validation loss: 3.023697926479111

Epoch: 6| Step: 9
Training loss: 4.016018503108467
Validation loss: 3.0235871410485395

Epoch: 6| Step: 10
Training loss: 2.3187651435789394
Validation loss: 3.023871550888199

Epoch: 6| Step: 11
Training loss: 3.268512817880544
Validation loss: 3.023260228976496

Epoch: 6| Step: 12
Training loss: 3.279617048563672
Validation loss: 3.0231381956818626

Epoch: 6| Step: 13
Training loss: 3.7462667319859992
Validation loss: 3.023791575935985

Epoch: 90| Step: 0
Training loss: 3.2125737460091655
Validation loss: 3.0245262975813

Epoch: 6| Step: 1
Training loss: 2.830772720090763
Validation loss: 3.0235847161092817

Epoch: 6| Step: 2
Training loss: 3.084299623443756
Validation loss: 3.023308420548623

Epoch: 6| Step: 3
Training loss: 2.2643033085844753
Validation loss: 3.02585019447714

Epoch: 6| Step: 4
Training loss: 3.3341800250149936
Validation loss: 3.0214121921991333

Epoch: 6| Step: 5
Training loss: 3.1490126621625327
Validation loss: 3.023676145148191

Epoch: 6| Step: 6
Training loss: 3.168083743866992
Validation loss: 3.0215413314455226

Epoch: 6| Step: 7
Training loss: 3.6201299641921145
Validation loss: 3.023146102483497

Epoch: 6| Step: 8
Training loss: 3.6245498377714793
Validation loss: 3.020754685331075

Epoch: 6| Step: 9
Training loss: 4.0226191901453685
Validation loss: 3.0218397699449175

Epoch: 6| Step: 10
Training loss: 3.125735234553746
Validation loss: 3.0238121279482155

Epoch: 6| Step: 11
Training loss: 3.391729781354789
Validation loss: 3.0237879090984423

Epoch: 6| Step: 12
Training loss: 3.093349392317599
Validation loss: 3.0212017659257078

Epoch: 6| Step: 13
Training loss: 4.282155853000875
Validation loss: 3.0216812273402556

Epoch: 91| Step: 0
Training loss: 3.0822962657863644
Validation loss: 3.022128639970514

Epoch: 6| Step: 1
Training loss: 3.9032354090325114
Validation loss: 3.020677269853015

Epoch: 6| Step: 2
Training loss: 3.2365174500012506
Validation loss: 3.0223261781331163

Epoch: 6| Step: 3
Training loss: 4.000809587565626
Validation loss: 3.024364296635631

Epoch: 6| Step: 4
Training loss: 3.284186801908366
Validation loss: 3.026222383868264

Epoch: 6| Step: 5
Training loss: 2.467039457280093
Validation loss: 3.0278200890615703

Epoch: 6| Step: 6
Training loss: 3.2053902408395354
Validation loss: 3.0258035142303004

Epoch: 6| Step: 7
Training loss: 2.722888471422878
Validation loss: 3.020190297315002

Epoch: 6| Step: 8
Training loss: 3.6140043617648647
Validation loss: 3.019944317233789

Epoch: 6| Step: 9
Training loss: 3.0776620894386015
Validation loss: 3.0202809132442905

Epoch: 6| Step: 10
Training loss: 3.453308652939355
Validation loss: 3.0185649027919457

Epoch: 6| Step: 11
Training loss: 3.5800311079751563
Validation loss: 3.018373016330121

Epoch: 6| Step: 12
Training loss: 2.835598675792943
Validation loss: 3.0189950822996945

Epoch: 6| Step: 13
Training loss: 3.4259182109879545
Validation loss: 3.021938006293777

Epoch: 92| Step: 0
Training loss: 3.540059940671192
Validation loss: 3.0252745645875603

Epoch: 6| Step: 1
Training loss: 2.944978001873453
Validation loss: 3.0323161398567584

Epoch: 6| Step: 2
Training loss: 3.5384979134543104
Validation loss: 3.0279789790943488

Epoch: 6| Step: 3
Training loss: 3.4345465717032053
Validation loss: 3.025259997615974

Epoch: 6| Step: 4
Training loss: 3.2227231290408858
Validation loss: 3.0175161534072164

Epoch: 6| Step: 5
Training loss: 3.272111646953226
Validation loss: 3.018219980829679

Epoch: 6| Step: 6
Training loss: 3.3039447499844345
Validation loss: 3.0173325403092184

Epoch: 6| Step: 7
Training loss: 3.5794471396944387
Validation loss: 3.0174742871989833

Epoch: 6| Step: 8
Training loss: 3.3358507346097173
Validation loss: 3.018746355199315

Epoch: 6| Step: 9
Training loss: 3.3845744488981593
Validation loss: 3.0168810870253653

Epoch: 6| Step: 10
Training loss: 2.910389566989379
Validation loss: 3.0172765027587274

Epoch: 6| Step: 11
Training loss: 2.942534657082204
Validation loss: 3.0183287073644656

Epoch: 6| Step: 12
Training loss: 3.3198330880916416
Validation loss: 3.0171742145949816

Epoch: 6| Step: 13
Training loss: 3.3720017290031734
Validation loss: 3.0182010759358398

Epoch: 93| Step: 0
Training loss: 3.3075449608754965
Validation loss: 3.016765674803532

Epoch: 6| Step: 1
Training loss: 3.1563140560486302
Validation loss: 3.015582933259483

Epoch: 6| Step: 2
Training loss: 4.22433847519094
Validation loss: 3.017587356401933

Epoch: 6| Step: 3
Training loss: 3.0925373822036732
Validation loss: 3.0176173374490114

Epoch: 6| Step: 4
Training loss: 2.8610948070403133
Validation loss: 3.016034855407883

Epoch: 6| Step: 5
Training loss: 3.683378988014693
Validation loss: 3.0155772161228636

Epoch: 6| Step: 6
Training loss: 3.0663177671847754
Validation loss: 3.0157850221876648

Epoch: 6| Step: 7
Training loss: 3.4095359141892736
Validation loss: 3.016092870999022

Epoch: 6| Step: 8
Training loss: 1.9793540330504487
Validation loss: 3.0176105545711485

Epoch: 6| Step: 9
Training loss: 3.09133138423768
Validation loss: 3.0162395837385514

Epoch: 6| Step: 10
Training loss: 3.213849828320256
Validation loss: 3.017881691295862

Epoch: 6| Step: 11
Training loss: 4.017484123231842
Validation loss: 3.0135747575308285

Epoch: 6| Step: 12
Training loss: 3.5059121470610406
Validation loss: 3.0128878770982603

Epoch: 6| Step: 13
Training loss: 2.6081185428147284
Validation loss: 3.0132310067784704

Epoch: 94| Step: 0
Training loss: 2.7630411783105133
Validation loss: 3.0125271626053243

Epoch: 6| Step: 1
Training loss: 3.4201542956698554
Validation loss: 3.0121754214059138

Epoch: 6| Step: 2
Training loss: 3.048820304982764
Validation loss: 3.0106687925958266

Epoch: 6| Step: 3
Training loss: 3.2775651859228723
Validation loss: 3.01192240814285

Epoch: 6| Step: 4
Training loss: 3.4022544735255345
Validation loss: 3.0101385188558116

Epoch: 6| Step: 5
Training loss: 4.108883904531493
Validation loss: 3.010359815970584

Epoch: 6| Step: 6
Training loss: 3.344365143566261
Validation loss: 3.01134410398649

Epoch: 6| Step: 7
Training loss: 3.5138568416000213
Validation loss: 3.012932143551611

Epoch: 6| Step: 8
Training loss: 3.306009231194487
Validation loss: 3.0136178246367966

Epoch: 6| Step: 9
Training loss: 2.6724570906274843
Validation loss: 3.011011027442575

Epoch: 6| Step: 10
Training loss: 3.0090766925261154
Validation loss: 3.014675863450242

Epoch: 6| Step: 11
Training loss: 3.1291278279650254
Validation loss: 3.0148336137324003

Epoch: 6| Step: 12
Training loss: 3.5702088589306253
Validation loss: 3.012903364985236

Epoch: 6| Step: 13
Training loss: 3.2073180503705756
Validation loss: 3.0173304909814664

Epoch: 95| Step: 0
Training loss: 3.497280426658753
Validation loss: 3.0127702577744184

Epoch: 6| Step: 1
Training loss: 2.6825602177867327
Validation loss: 3.0121874983876964

Epoch: 6| Step: 2
Training loss: 3.8636009153484077
Validation loss: 3.0118668708667475

Epoch: 6| Step: 3
Training loss: 2.904567764876013
Validation loss: 3.0090343612871346

Epoch: 6| Step: 4
Training loss: 3.248865369661468
Validation loss: 3.0102677108123035

Epoch: 6| Step: 5
Training loss: 3.590634264157979
Validation loss: 3.0069724482533804

Epoch: 6| Step: 6
Training loss: 3.352920506081971
Validation loss: 3.0086152647121205

Epoch: 6| Step: 7
Training loss: 3.4252539547515326
Validation loss: 3.0067108169509

Epoch: 6| Step: 8
Training loss: 3.8348765100443636
Validation loss: 3.006350150947362

Epoch: 6| Step: 9
Training loss: 2.4237595639918057
Validation loss: 3.006910389378309

Epoch: 6| Step: 10
Training loss: 2.779583463817973
Validation loss: 3.005168381718642

Epoch: 6| Step: 11
Training loss: 2.936953879379043
Validation loss: 3.005961053764423

Epoch: 6| Step: 12
Training loss: 3.549601443846372
Validation loss: 3.0045902639372617

Epoch: 6| Step: 13
Training loss: 3.6983708635522965
Validation loss: 3.0057964078349877

Epoch: 96| Step: 0
Training loss: 3.7650116860257743
Validation loss: 3.0047184351181917

Epoch: 6| Step: 1
Training loss: 2.602244428092334
Validation loss: 3.0057912179403248

Epoch: 6| Step: 2
Training loss: 2.902947631279485
Validation loss: 3.004459652032842

Epoch: 6| Step: 3
Training loss: 2.959704784157162
Validation loss: 3.0034672976887813

Epoch: 6| Step: 4
Training loss: 3.4812445155978877
Validation loss: 3.0049950075438225

Epoch: 6| Step: 5
Training loss: 2.8106971896696025
Validation loss: 3.004260415151107

Epoch: 6| Step: 6
Training loss: 3.0449514724046614
Validation loss: 3.006346247092568

Epoch: 6| Step: 7
Training loss: 3.3923751603435055
Validation loss: 3.0054993719477583

Epoch: 6| Step: 8
Training loss: 3.683199945396469
Validation loss: 3.006644908041949

Epoch: 6| Step: 9
Training loss: 3.395642764745226
Validation loss: 3.0073519190679296

Epoch: 6| Step: 10
Training loss: 3.800696816050528
Validation loss: 3.0071205403301327

Epoch: 6| Step: 11
Training loss: 3.1101217475439604
Validation loss: 3.0037441227245734

Epoch: 6| Step: 12
Training loss: 2.7627917933952864
Validation loss: 3.006189686228143

Epoch: 6| Step: 13
Training loss: 4.333611601673615
Validation loss: 3.002791901862325

Epoch: 97| Step: 0
Training loss: 3.7957088736191933
Validation loss: 3.0025892603200677

Epoch: 6| Step: 1
Training loss: 2.941648111113758
Validation loss: 3.002744015365071

Epoch: 6| Step: 2
Training loss: 3.31414365475724
Validation loss: 3.0027252623371377

Epoch: 6| Step: 3
Training loss: 3.290679171877964
Validation loss: 3.0054618455681874

Epoch: 6| Step: 4
Training loss: 2.8532995498594302
Validation loss: 3.0034574373432874

Epoch: 6| Step: 5
Training loss: 3.5834641247913996
Validation loss: 3.0035221299059542

Epoch: 6| Step: 6
Training loss: 3.1387937150628065
Validation loss: 3.0031907074959907

Epoch: 6| Step: 7
Training loss: 3.2139763849764105
Validation loss: 3.003010336700578

Epoch: 6| Step: 8
Training loss: 2.9340985672716964
Validation loss: 3.0049647794164414

Epoch: 6| Step: 9
Training loss: 3.6272412967775978
Validation loss: 3.0025469247082333

Epoch: 6| Step: 10
Training loss: 3.929597098977264
Validation loss: 3.0051119927865293

Epoch: 6| Step: 11
Training loss: 3.4288259479874155
Validation loss: 3.005271544280168

Epoch: 6| Step: 12
Training loss: 2.434230568044971
Validation loss: 3.007528763913449

Epoch: 6| Step: 13
Training loss: 3.0309617996854303
Validation loss: 3.0086737718756904

Epoch: 98| Step: 0
Training loss: 3.651119969608052
Validation loss: 3.010774981911328

Epoch: 6| Step: 1
Training loss: 2.983068050190178
Validation loss: 3.0047970825209935

Epoch: 6| Step: 2
Training loss: 3.0212100791582213
Validation loss: 3.001860972844085

Epoch: 6| Step: 3
Training loss: 3.3741274518156827
Validation loss: 2.9997176897191458

Epoch: 6| Step: 4
Training loss: 2.960580124840087
Validation loss: 2.9977967997876265

Epoch: 6| Step: 5
Training loss: 3.408594147295058
Validation loss: 2.9956936863611086

Epoch: 6| Step: 6
Training loss: 2.771262850251987
Validation loss: 2.997699559691187

Epoch: 6| Step: 7
Training loss: 3.448768733251283
Validation loss: 2.9986894660759287

Epoch: 6| Step: 8
Training loss: 3.2345728422092486
Validation loss: 2.997336168897132

Epoch: 6| Step: 9
Training loss: 3.5691279276341943
Validation loss: 2.9952339662546232

Epoch: 6| Step: 10
Training loss: 3.1615429300786775
Validation loss: 2.9965745638204635

Epoch: 6| Step: 11
Training loss: 3.537778507767202
Validation loss: 2.9962900168077136

Epoch: 6| Step: 12
Training loss: 3.585968748800051
Validation loss: 2.9976123730777804

Epoch: 6| Step: 13
Training loss: 2.888547408470466
Validation loss: 2.9965987870213304

Epoch: 99| Step: 0
Training loss: 2.592005407227657
Validation loss: 2.9947126360822978

Epoch: 6| Step: 1
Training loss: 3.826916686894317
Validation loss: 2.993516511452588

Epoch: 6| Step: 2
Training loss: 2.6824714279430744
Validation loss: 2.9948125968868706

Epoch: 6| Step: 3
Training loss: 2.8152423628281813
Validation loss: 2.9954398680610983

Epoch: 6| Step: 4
Training loss: 3.557724814157425
Validation loss: 2.9968332784262817

Epoch: 6| Step: 5
Training loss: 3.492150359841653
Validation loss: 2.998757269042018

Epoch: 6| Step: 6
Training loss: 3.2583935262936525
Validation loss: 2.9992955313863185

Epoch: 6| Step: 7
Training loss: 3.101397377826716
Validation loss: 3.00226803128942

Epoch: 6| Step: 8
Training loss: 3.7284787927070226
Validation loss: 3.0041104616715413

Epoch: 6| Step: 9
Training loss: 2.933102176690449
Validation loss: 2.997836178623659

Epoch: 6| Step: 10
Training loss: 3.600269408211911
Validation loss: 2.9957086050546042

Epoch: 6| Step: 11
Training loss: 3.252279802473062
Validation loss: 2.9958624824259257

Epoch: 6| Step: 12
Training loss: 3.772117620849066
Validation loss: 2.9931435390117342

Epoch: 6| Step: 13
Training loss: 2.621489493544539
Validation loss: 2.993021619978214

Epoch: 100| Step: 0
Training loss: 3.646327321328289
Validation loss: 2.9931643913954193

Epoch: 6| Step: 1
Training loss: 2.864906505503857
Validation loss: 2.9929868117318392

Epoch: 6| Step: 2
Training loss: 3.4816337716347476
Validation loss: 2.996137580059515

Epoch: 6| Step: 3
Training loss: 3.083938607956793
Validation loss: 2.9931429497366433

Epoch: 6| Step: 4
Training loss: 3.322820026263974
Validation loss: 2.996030504003789

Epoch: 6| Step: 5
Training loss: 2.980771430608728
Validation loss: 2.9951048251329224

Epoch: 6| Step: 6
Training loss: 2.8416534072999187
Validation loss: 2.995661349861446

Epoch: 6| Step: 7
Training loss: 3.2887677493281577
Validation loss: 2.994204041058326

Epoch: 6| Step: 8
Training loss: 3.4456028545629094
Validation loss: 2.9937821627938046

Epoch: 6| Step: 9
Training loss: 3.12101002605946
Validation loss: 2.992483272160491

Epoch: 6| Step: 10
Training loss: 2.8194133984422924
Validation loss: 2.9904900530329104

Epoch: 6| Step: 11
Training loss: 3.5797692398203225
Validation loss: 2.9919401876434004

Epoch: 6| Step: 12
Training loss: 3.5137040379034494
Validation loss: 2.991671116423682

Epoch: 6| Step: 13
Training loss: 3.976370876169454
Validation loss: 2.992039422809016

Testing loss: 3.1920961574092193
