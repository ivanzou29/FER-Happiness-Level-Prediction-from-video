Epoch: 1| Step: 0
Training loss: 5.642765389329391
Validation loss: 5.800419817629271

Epoch: 5| Step: 1
Training loss: 5.901980517033032
Validation loss: 5.7938229588216705

Epoch: 5| Step: 2
Training loss: 5.2708359468275185
Validation loss: 5.787856079478872

Epoch: 5| Step: 3
Training loss: 5.39069010377353
Validation loss: 5.7822120121078076

Epoch: 5| Step: 4
Training loss: 5.5600693782073005
Validation loss: 5.776413368081619

Epoch: 5| Step: 5
Training loss: 6.685289819864651
Validation loss: 5.770436405178108

Epoch: 5| Step: 6
Training loss: 5.119311269094022
Validation loss: 5.764024385764855

Epoch: 5| Step: 7
Training loss: 5.714351108721794
Validation loss: 5.757325288097874

Epoch: 5| Step: 8
Training loss: 5.866118515300119
Validation loss: 5.749672764922634

Epoch: 5| Step: 9
Training loss: 6.903210553683433
Validation loss: 5.7416256651298525

Epoch: 5| Step: 10
Training loss: 5.4692670305257804
Validation loss: 5.732431205742896

Epoch: 2| Step: 0
Training loss: 4.460615316805138
Validation loss: 5.722529423412965

Epoch: 5| Step: 1
Training loss: 6.512022783656648
Validation loss: 5.712327985645798

Epoch: 5| Step: 2
Training loss: 5.106020511620365
Validation loss: 5.7007800163112075

Epoch: 5| Step: 3
Training loss: 6.2896214207189605
Validation loss: 5.688342097326535

Epoch: 5| Step: 4
Training loss: 4.974170918606903
Validation loss: 5.674271245093328

Epoch: 5| Step: 5
Training loss: 5.08980533939603
Validation loss: 5.660192110877154

Epoch: 5| Step: 6
Training loss: 5.602636513636296
Validation loss: 5.6445802232505695

Epoch: 5| Step: 7
Training loss: 6.41322772858423
Validation loss: 5.627706589804789

Epoch: 5| Step: 8
Training loss: 5.270649943220913
Validation loss: 5.60913705893864

Epoch: 5| Step: 9
Training loss: 6.342816364005049
Validation loss: 5.589016522382029

Epoch: 5| Step: 10
Training loss: 6.119771789085625
Validation loss: 5.567498754294574

Epoch: 3| Step: 0
Training loss: 6.244358110264699
Validation loss: 5.5452552418978796

Epoch: 5| Step: 1
Training loss: 4.942478615420769
Validation loss: 5.519776943908211

Epoch: 5| Step: 2
Training loss: 5.237416582194349
Validation loss: 5.495577166543707

Epoch: 5| Step: 3
Training loss: 5.7551306349628835
Validation loss: 5.468535570197863

Epoch: 5| Step: 4
Training loss: 5.893582762593652
Validation loss: 5.4399273048782

Epoch: 5| Step: 5
Training loss: 5.03448211915882
Validation loss: 5.413183240706069

Epoch: 5| Step: 6
Training loss: 5.423664072678783
Validation loss: 5.381027482225611

Epoch: 5| Step: 7
Training loss: 5.574774411687969
Validation loss: 5.348994943054731

Epoch: 5| Step: 8
Training loss: 4.943890263126589
Validation loss: 5.316894512686502

Epoch: 5| Step: 9
Training loss: 4.616918565692526
Validation loss: 5.283674281373832

Epoch: 5| Step: 10
Training loss: 6.156589556784107
Validation loss: 5.249137035959746

Epoch: 4| Step: 0
Training loss: 4.332972046878817
Validation loss: 5.213677946771886

Epoch: 5| Step: 1
Training loss: 4.843117161910719
Validation loss: 5.176916513631324

Epoch: 5| Step: 2
Training loss: 5.897704709240904
Validation loss: 5.140771740009901

Epoch: 5| Step: 3
Training loss: 5.658471782865093
Validation loss: 5.102561988078418

Epoch: 5| Step: 4
Training loss: 5.948987268764809
Validation loss: 5.0644376088462915

Epoch: 5| Step: 5
Training loss: 4.70263831576555
Validation loss: 5.027581788154183

Epoch: 5| Step: 6
Training loss: 5.00134983915573
Validation loss: 4.988582748732375

Epoch: 5| Step: 7
Training loss: 4.63864905422018
Validation loss: 4.949567974118647

Epoch: 5| Step: 8
Training loss: 4.510616494818649
Validation loss: 4.90898489481123

Epoch: 5| Step: 9
Training loss: 5.262778579695924
Validation loss: 4.873892438225289

Epoch: 5| Step: 10
Training loss: 4.915711240017996
Validation loss: 4.838602960701816

Epoch: 5| Step: 0
Training loss: 5.139255886318901
Validation loss: 4.805168103674461

Epoch: 5| Step: 1
Training loss: 5.050512744820638
Validation loss: 4.776460482837867

Epoch: 5| Step: 2
Training loss: 5.433422796218854
Validation loss: 4.74987463146105

Epoch: 5| Step: 3
Training loss: 4.837428736593048
Validation loss: 4.722808978459043

Epoch: 5| Step: 4
Training loss: 4.023319931534699
Validation loss: 4.699403703958135

Epoch: 5| Step: 5
Training loss: 4.503589893621714
Validation loss: 4.675077632294355

Epoch: 5| Step: 6
Training loss: 5.190126420614713
Validation loss: 4.652565744427935

Epoch: 5| Step: 7
Training loss: 4.1379683122928865
Validation loss: 4.629541621111144

Epoch: 5| Step: 8
Training loss: 4.717319296897015
Validation loss: 4.605855722250146

Epoch: 5| Step: 9
Training loss: 4.136232284457236
Validation loss: 4.581917853871543

Epoch: 5| Step: 10
Training loss: 5.1264166385975924
Validation loss: 4.560192073395786

Epoch: 6| Step: 0
Training loss: 4.119266802906832
Validation loss: 4.536739865578134

Epoch: 5| Step: 1
Training loss: 4.595364864171645
Validation loss: 4.513989246768345

Epoch: 5| Step: 2
Training loss: 4.094727377660603
Validation loss: 4.494168908500811

Epoch: 5| Step: 3
Training loss: 4.641681589391384
Validation loss: 4.475058184032523

Epoch: 5| Step: 4
Training loss: 5.188114727319369
Validation loss: 4.457530390500612

Epoch: 5| Step: 5
Training loss: 5.565919146724643
Validation loss: 4.44167045595101

Epoch: 5| Step: 6
Training loss: 4.099812452167091
Validation loss: 4.42541275884864

Epoch: 5| Step: 7
Training loss: 4.253116138457429
Validation loss: 4.4102900431808925

Epoch: 5| Step: 8
Training loss: 3.7818613109930324
Validation loss: 4.395981544352577

Epoch: 5| Step: 9
Training loss: 5.123072377998379
Validation loss: 4.385156557649289

Epoch: 5| Step: 10
Training loss: 4.263536549830805
Validation loss: 4.3735815159965625

Epoch: 7| Step: 0
Training loss: 4.5475155094127615
Validation loss: 4.362303341711849

Epoch: 5| Step: 1
Training loss: 4.333331010279888
Validation loss: 4.35119374960112

Epoch: 5| Step: 2
Training loss: 4.951691332772441
Validation loss: 4.337797964207989

Epoch: 5| Step: 3
Training loss: 4.508997293728244
Validation loss: 4.3276941548412475

Epoch: 5| Step: 4
Training loss: 4.615374265561359
Validation loss: 4.315197595970905

Epoch: 5| Step: 5
Training loss: 4.563545838770396
Validation loss: 4.305482328446957

Epoch: 5| Step: 6
Training loss: 4.35309764144198
Validation loss: 4.294263238010316

Epoch: 5| Step: 7
Training loss: 3.8884327545296475
Validation loss: 4.282705199965516

Epoch: 5| Step: 8
Training loss: 4.098571500576379
Validation loss: 4.2718908173761365

Epoch: 5| Step: 9
Training loss: 4.1696099122182115
Validation loss: 4.259840094383369

Epoch: 5| Step: 10
Training loss: 4.624172652192515
Validation loss: 4.247921912750771

Epoch: 8| Step: 0
Training loss: 4.524973132649109
Validation loss: 4.231187917035443

Epoch: 5| Step: 1
Training loss: 4.768943156758891
Validation loss: 4.215848840810252

Epoch: 5| Step: 2
Training loss: 3.360401369372601
Validation loss: 4.198095626190053

Epoch: 5| Step: 3
Training loss: 3.6908287928790093
Validation loss: 4.186862357037162

Epoch: 5| Step: 4
Training loss: 4.530448474368321
Validation loss: 4.176505036218839

Epoch: 5| Step: 5
Training loss: 4.656935263778679
Validation loss: 4.1685564066815

Epoch: 5| Step: 6
Training loss: 4.199144712283355
Validation loss: 4.162894385119779

Epoch: 5| Step: 7
Training loss: 4.64278846941453
Validation loss: 4.153914812176357

Epoch: 5| Step: 8
Training loss: 3.321995494878517
Validation loss: 4.146413560395476

Epoch: 5| Step: 9
Training loss: 4.501310793384809
Validation loss: 4.13897093760637

Epoch: 5| Step: 10
Training loss: 4.9228541777728125
Validation loss: 4.131533641850803

Epoch: 9| Step: 0
Training loss: 5.202546875140781
Validation loss: 4.12269777380999

Epoch: 5| Step: 1
Training loss: 3.7126098719306917
Validation loss: 4.116783774695819

Epoch: 5| Step: 2
Training loss: 3.9946883220145053
Validation loss: 4.110026124833718

Epoch: 5| Step: 3
Training loss: 4.475837475714326
Validation loss: 4.104817491824625

Epoch: 5| Step: 4
Training loss: 4.09853799386242
Validation loss: 4.098556912729542

Epoch: 5| Step: 5
Training loss: 4.6657576811027734
Validation loss: 4.0945707461409375

Epoch: 5| Step: 6
Training loss: 4.1226138524977864
Validation loss: 4.087374077702162

Epoch: 5| Step: 7
Training loss: 3.1126575108394365
Validation loss: 4.079844007081666

Epoch: 5| Step: 8
Training loss: 3.552704310276858
Validation loss: 4.074904616202303

Epoch: 5| Step: 9
Training loss: 5.018017729927447
Validation loss: 4.069705075952725

Epoch: 5| Step: 10
Training loss: 4.227781899030105
Validation loss: 4.065169660801579

Epoch: 10| Step: 0
Training loss: 4.23374861134635
Validation loss: 4.058333033891674

Epoch: 5| Step: 1
Training loss: 4.533159787465186
Validation loss: 4.053835494148368

Epoch: 5| Step: 2
Training loss: 4.089089572745448
Validation loss: 4.047444460486634

Epoch: 5| Step: 3
Training loss: 3.7475041030749354
Validation loss: 4.047398006857681

Epoch: 5| Step: 4
Training loss: 4.766485417972669
Validation loss: 4.035784330380258

Epoch: 5| Step: 5
Training loss: 4.6681824447686795
Validation loss: 4.029612417256024

Epoch: 5| Step: 6
Training loss: 3.6298367033239733
Validation loss: 4.026197680723814

Epoch: 5| Step: 7
Training loss: 3.264849557024777
Validation loss: 4.021730544221356

Epoch: 5| Step: 8
Training loss: 4.24825161144563
Validation loss: 4.018895574871411

Epoch: 5| Step: 9
Training loss: 4.339134563524849
Validation loss: 4.014659258720423

Epoch: 5| Step: 10
Training loss: 4.265862873976414
Validation loss: 4.006552390127594

Epoch: 11| Step: 0
Training loss: 4.038307340703344
Validation loss: 4.002286461331995

Epoch: 5| Step: 1
Training loss: 3.3971761533147484
Validation loss: 3.9940499022710547

Epoch: 5| Step: 2
Training loss: 3.5043471451290635
Validation loss: 3.990405545646471

Epoch: 5| Step: 3
Training loss: 4.402367579100327
Validation loss: 3.9850040049478817

Epoch: 5| Step: 4
Training loss: 4.617375248998448
Validation loss: 3.98071245293597

Epoch: 5| Step: 5
Training loss: 3.7547630578676383
Validation loss: 3.9765730199987566

Epoch: 5| Step: 6
Training loss: 4.769475663194712
Validation loss: 3.972055991089993

Epoch: 5| Step: 7
Training loss: 4.434951910297932
Validation loss: 3.968668301140065

Epoch: 5| Step: 8
Training loss: 4.473744409114801
Validation loss: 3.9618459240186077

Epoch: 5| Step: 9
Training loss: 3.946846903431393
Validation loss: 3.9567458310774932

Epoch: 5| Step: 10
Training loss: 3.801386409621351
Validation loss: 3.9547257443434254

Epoch: 12| Step: 0
Training loss: 4.299092778157964
Validation loss: 3.950450539378418

Epoch: 5| Step: 1
Training loss: 3.662208592405953
Validation loss: 3.9470640066878584

Epoch: 5| Step: 2
Training loss: 3.2549544497348397
Validation loss: 3.9428268082986238

Epoch: 5| Step: 3
Training loss: 4.497553266174852
Validation loss: 3.937852239861985

Epoch: 5| Step: 4
Training loss: 4.501042139391296
Validation loss: 3.9347371273467604

Epoch: 5| Step: 5
Training loss: 3.795323435554439
Validation loss: 3.931808269636684

Epoch: 5| Step: 6
Training loss: 3.717907337275486
Validation loss: 3.927724801153329

Epoch: 5| Step: 7
Training loss: 4.325663062629414
Validation loss: 3.923207114513113

Epoch: 5| Step: 8
Training loss: 4.026209082171995
Validation loss: 3.917061103608075

Epoch: 5| Step: 9
Training loss: 4.093893732940127
Validation loss: 3.9140233528377477

Epoch: 5| Step: 10
Training loss: 4.693583495416097
Validation loss: 3.9102000344626746

Epoch: 13| Step: 0
Training loss: 4.238823500018212
Validation loss: 3.9063984215544534

Epoch: 5| Step: 1
Training loss: 3.5322439769666794
Validation loss: 3.9014110469440895

Epoch: 5| Step: 2
Training loss: 4.512278864717751
Validation loss: 3.8994909154591926

Epoch: 5| Step: 3
Training loss: 4.538042331368665
Validation loss: 3.89635390393931

Epoch: 5| Step: 4
Training loss: 4.096624631818668
Validation loss: 3.893284071800153

Epoch: 5| Step: 5
Training loss: 4.44808235425661
Validation loss: 3.8899078782291743

Epoch: 5| Step: 6
Training loss: 2.92346653967196
Validation loss: 3.8837967419504507

Epoch: 5| Step: 7
Training loss: 4.083010965714221
Validation loss: 3.882456301975237

Epoch: 5| Step: 8
Training loss: 3.499536074818009
Validation loss: 3.8805944763340023

Epoch: 5| Step: 9
Training loss: 4.4788703761318445
Validation loss: 3.878263633363972

Epoch: 5| Step: 10
Training loss: 3.9113817609597072
Validation loss: 3.8738097361798967

Epoch: 14| Step: 0
Training loss: 4.523925333285528
Validation loss: 3.8719833757583824

Epoch: 5| Step: 1
Training loss: 4.681874472674472
Validation loss: 3.868999295352664

Epoch: 5| Step: 2
Training loss: 4.319848033916565
Validation loss: 3.864549477097252

Epoch: 5| Step: 3
Training loss: 3.1339681496331515
Validation loss: 3.858012246722922

Epoch: 5| Step: 4
Training loss: 3.356959126323355
Validation loss: 3.854388536199388

Epoch: 5| Step: 5
Training loss: 4.402231101597803
Validation loss: 3.8523102488560803

Epoch: 5| Step: 6
Training loss: 4.018686278032302
Validation loss: 3.8499262820674622

Epoch: 5| Step: 7
Training loss: 3.8642273333631825
Validation loss: 3.8483784259120526

Epoch: 5| Step: 8
Training loss: 3.886011291220493
Validation loss: 3.8435352411175674

Epoch: 5| Step: 9
Training loss: 3.6176464868925455
Validation loss: 3.8411392321424733

Epoch: 5| Step: 10
Training loss: 4.197864970732146
Validation loss: 3.838208070165938

Epoch: 15| Step: 0
Training loss: 4.124314222262299
Validation loss: 3.836022291722277

Epoch: 5| Step: 1
Training loss: 3.945949268886942
Validation loss: 3.832013221663108

Epoch: 5| Step: 2
Training loss: 3.4164211060894267
Validation loss: 3.8286115185267815

Epoch: 5| Step: 3
Training loss: 4.006603036164713
Validation loss: 3.8252599177613975

Epoch: 5| Step: 4
Training loss: 4.038103059780809
Validation loss: 3.8222461689275757

Epoch: 5| Step: 5
Training loss: 3.9138151840683464
Validation loss: 3.821609963571503

Epoch: 5| Step: 6
Training loss: 4.673931983083955
Validation loss: 3.8186417762374587

Epoch: 5| Step: 7
Training loss: 2.9632253539498166
Validation loss: 3.8168201476305064

Epoch: 5| Step: 8
Training loss: 4.718163460157731
Validation loss: 3.812933569182663

Epoch: 5| Step: 9
Training loss: 4.188638105454659
Validation loss: 3.810415691037706

Epoch: 5| Step: 10
Training loss: 3.5442707735389107
Validation loss: 3.8083386720568004

Epoch: 16| Step: 0
Training loss: 3.587142575631774
Validation loss: 3.8035092397189803

Epoch: 5| Step: 1
Training loss: 4.789542592613616
Validation loss: 3.802234859147046

Epoch: 5| Step: 2
Training loss: 4.092349446206685
Validation loss: 3.798615329264643

Epoch: 5| Step: 3
Training loss: 3.3039954071751922
Validation loss: 3.795255626859814

Epoch: 5| Step: 4
Training loss: 4.326994049272706
Validation loss: 3.7927679598860924

Epoch: 5| Step: 5
Training loss: 4.112286250812091
Validation loss: 3.7898119546499127

Epoch: 5| Step: 6
Training loss: 3.597875996359611
Validation loss: 3.7874557188749924

Epoch: 5| Step: 7
Training loss: 4.585332515394429
Validation loss: 3.786255239364585

Epoch: 5| Step: 8
Training loss: 2.728585004095118
Validation loss: 3.7834006213854603

Epoch: 5| Step: 9
Training loss: 4.355011975067177
Validation loss: 3.7846595540458674

Epoch: 5| Step: 10
Training loss: 3.667281243808744
Validation loss: 3.779134750100287

Epoch: 17| Step: 0
Training loss: 4.639183359958351
Validation loss: 3.774302491550143

Epoch: 5| Step: 1
Training loss: 2.5944436306331573
Validation loss: 3.774431150165541

Epoch: 5| Step: 2
Training loss: 3.786169335811714
Validation loss: 3.771677955440638

Epoch: 5| Step: 3
Training loss: 3.9283619762914492
Validation loss: 3.770183972118341

Epoch: 5| Step: 4
Training loss: 4.628890592009382
Validation loss: 3.767473436635615

Epoch: 5| Step: 5
Training loss: 3.877731468035893
Validation loss: 3.764508434107865

Epoch: 5| Step: 6
Training loss: 4.181322237995893
Validation loss: 3.759846097470912

Epoch: 5| Step: 7
Training loss: 3.8610645873806364
Validation loss: 3.7581725018988394

Epoch: 5| Step: 8
Training loss: 4.101017913995037
Validation loss: 3.7557374542393944

Epoch: 5| Step: 9
Training loss: 4.115318496633687
Validation loss: 3.753856826311238

Epoch: 5| Step: 10
Training loss: 3.1098445365294123
Validation loss: 3.7522429427408546

Epoch: 18| Step: 0
Training loss: 3.2598677265503415
Validation loss: 3.7500783536101743

Epoch: 5| Step: 1
Training loss: 4.142683330892395
Validation loss: 3.745494180985373

Epoch: 5| Step: 2
Training loss: 3.4225145552265084
Validation loss: 3.7441208259496856

Epoch: 5| Step: 3
Training loss: 3.387638024477777
Validation loss: 3.741956384909492

Epoch: 5| Step: 4
Training loss: 3.6948671616974718
Validation loss: 3.7387325349516525

Epoch: 5| Step: 5
Training loss: 4.130510291101158
Validation loss: 3.7353529570987978

Epoch: 5| Step: 6
Training loss: 3.644689951034568
Validation loss: 3.736140330883592

Epoch: 5| Step: 7
Training loss: 3.9351195148315763
Validation loss: 3.7321020345084417

Epoch: 5| Step: 8
Training loss: 3.8346150093852494
Validation loss: 3.732227152788399

Epoch: 5| Step: 9
Training loss: 5.136590644196296
Validation loss: 3.7276216116687295

Epoch: 5| Step: 10
Training loss: 4.2027633114302665
Validation loss: 3.725216002339549

Epoch: 19| Step: 0
Training loss: 4.871219049110198
Validation loss: 3.723625160743575

Epoch: 5| Step: 1
Training loss: 4.301809356068899
Validation loss: 3.720448789203488

Epoch: 5| Step: 2
Training loss: 3.7292172874268483
Validation loss: 3.720421930630492

Epoch: 5| Step: 3
Training loss: 3.58946370467718
Validation loss: 3.717579459623371

Epoch: 5| Step: 4
Training loss: 3.308741182287419
Validation loss: 3.7137616670862865

Epoch: 5| Step: 5
Training loss: 3.429050534129352
Validation loss: 3.713147859078302

Epoch: 5| Step: 6
Training loss: 2.4937031600492174
Validation loss: 3.7134539424934503

Epoch: 5| Step: 7
Training loss: 4.191707035019461
Validation loss: 3.7122180349783385

Epoch: 5| Step: 8
Training loss: 3.502075397422705
Validation loss: 3.7067411548178093

Epoch: 5| Step: 9
Training loss: 4.320290867232233
Validation loss: 3.707360258301357

Epoch: 5| Step: 10
Training loss: 4.685251739480461
Validation loss: 3.70545481676867

Epoch: 20| Step: 0
Training loss: 3.8864282240664516
Validation loss: 3.704485182597866

Epoch: 5| Step: 1
Training loss: 3.979217662118353
Validation loss: 3.70091775832481

Epoch: 5| Step: 2
Training loss: 3.8525963685931175
Validation loss: 3.698660700310016

Epoch: 5| Step: 3
Training loss: 3.063545048744352
Validation loss: 3.6965286781273603

Epoch: 5| Step: 4
Training loss: 4.58001232628642
Validation loss: 3.6948863962349

Epoch: 5| Step: 5
Training loss: 3.565594316462523
Validation loss: 3.694275279868584

Epoch: 5| Step: 6
Training loss: 4.163420722559409
Validation loss: 3.6909279884112616

Epoch: 5| Step: 7
Training loss: 3.910735339899988
Validation loss: 3.6892980130829534

Epoch: 5| Step: 8
Training loss: 3.8989263621731722
Validation loss: 3.686414970220777

Epoch: 5| Step: 9
Training loss: 2.9459543515337776
Validation loss: 3.68597281485063

Epoch: 5| Step: 10
Training loss: 4.62734101305212
Validation loss: 3.683895456583142

Epoch: 21| Step: 0
Training loss: 2.8155712736467646
Validation loss: 3.6838432146372493

Epoch: 5| Step: 1
Training loss: 3.743877626513988
Validation loss: 3.6864758225557632

Epoch: 5| Step: 2
Training loss: 3.728657067854737
Validation loss: 3.6822677458129904

Epoch: 5| Step: 3
Training loss: 4.16338773774843
Validation loss: 3.6791417422768653

Epoch: 5| Step: 4
Training loss: 3.4360817497751266
Validation loss: 3.678468140123761

Epoch: 5| Step: 5
Training loss: 3.911520492256219
Validation loss: 3.678419565065347

Epoch: 5| Step: 6
Training loss: 4.284040669224138
Validation loss: 3.6772881920571336

Epoch: 5| Step: 7
Training loss: 3.8411591024223495
Validation loss: 3.6746809725437473

Epoch: 5| Step: 8
Training loss: 4.066215342090475
Validation loss: 3.6720602721436757

Epoch: 5| Step: 9
Training loss: 3.8278692666094827
Validation loss: 3.6709229403830608

Epoch: 5| Step: 10
Training loss: 4.574536893158173
Validation loss: 3.6691236421107796

Epoch: 22| Step: 0
Training loss: 2.788100987809641
Validation loss: 3.668596547558828

Epoch: 5| Step: 1
Training loss: 4.416947385875762
Validation loss: 3.6696529733386227

Epoch: 5| Step: 2
Training loss: 3.1041157012100924
Validation loss: 3.66590650757541

Epoch: 5| Step: 3
Training loss: 4.504332258419474
Validation loss: 3.6635657358402165

Epoch: 5| Step: 4
Training loss: 3.414812437746084
Validation loss: 3.662369863607488

Epoch: 5| Step: 5
Training loss: 3.830463427003682
Validation loss: 3.6618311750288504

Epoch: 5| Step: 6
Training loss: 4.321344345515022
Validation loss: 3.660432256257948

Epoch: 5| Step: 7
Training loss: 4.537046106088676
Validation loss: 3.657607717033283

Epoch: 5| Step: 8
Training loss: 3.2045295427174527
Validation loss: 3.6567632936979595

Epoch: 5| Step: 9
Training loss: 4.154371941537938
Validation loss: 3.6551852930723023

Epoch: 5| Step: 10
Training loss: 3.5893665947168913
Validation loss: 3.6538082131128973

Epoch: 23| Step: 0
Training loss: 4.3644917310814915
Validation loss: 3.652719726302923

Epoch: 5| Step: 1
Training loss: 3.6974779038868433
Validation loss: 3.650924389802479

Epoch: 5| Step: 2
Training loss: 3.581763271012985
Validation loss: 3.649074379314419

Epoch: 5| Step: 3
Training loss: 3.312255562454495
Validation loss: 3.6486654728389865

Epoch: 5| Step: 4
Training loss: 4.19896915137562
Validation loss: 3.647839078446271

Epoch: 5| Step: 5
Training loss: 3.7163108712403514
Validation loss: 3.6463158372873923

Epoch: 5| Step: 6
Training loss: 3.1583453484325967
Validation loss: 3.646246295282635

Epoch: 5| Step: 7
Training loss: 3.749074821785789
Validation loss: 3.6460543535921364

Epoch: 5| Step: 8
Training loss: 4.085413240894604
Validation loss: 3.6446161195962783

Epoch: 5| Step: 9
Training loss: 3.9036087261707126
Validation loss: 3.641522358862536

Epoch: 5| Step: 10
Training loss: 4.368789842939628
Validation loss: 3.6415768327561007

Epoch: 24| Step: 0
Training loss: 3.444953051995998
Validation loss: 3.6402464772889296

Epoch: 5| Step: 1
Training loss: 4.124515158163077
Validation loss: 3.6402528324280787

Epoch: 5| Step: 2
Training loss: 3.807254371860486
Validation loss: 3.638899941829313

Epoch: 5| Step: 3
Training loss: 3.8367687808538027
Validation loss: 3.6377702090056254

Epoch: 5| Step: 4
Training loss: 4.102089344883678
Validation loss: 3.6381150558197692

Epoch: 5| Step: 5
Training loss: 3.8384963938278864
Validation loss: 3.6363443129642277

Epoch: 5| Step: 6
Training loss: 4.519951143929086
Validation loss: 3.636612534884339

Epoch: 5| Step: 7
Training loss: 4.063658798447551
Validation loss: 3.6350083370248263

Epoch: 5| Step: 8
Training loss: 2.866541152986068
Validation loss: 3.6334800696981597

Epoch: 5| Step: 9
Training loss: 4.001116835128003
Validation loss: 3.632610164480697

Epoch: 5| Step: 10
Training loss: 3.176001359319516
Validation loss: 3.631282619486327

Epoch: 25| Step: 0
Training loss: 3.3371676961791827
Validation loss: 3.6306501194968486

Epoch: 5| Step: 1
Training loss: 4.054136852587346
Validation loss: 3.6302253224996113

Epoch: 5| Step: 2
Training loss: 4.322060643509848
Validation loss: 3.6283432476656206

Epoch: 5| Step: 3
Training loss: 4.0599540362081745
Validation loss: 3.6270865297114643

Epoch: 5| Step: 4
Training loss: 3.888092810272659
Validation loss: 3.6267740945841864

Epoch: 5| Step: 5
Training loss: 4.070519381663601
Validation loss: 3.6256945647960683

Epoch: 5| Step: 6
Training loss: 3.7738127906834458
Validation loss: 3.6252534004783152

Epoch: 5| Step: 7
Training loss: 4.145123265990867
Validation loss: 3.6242456694446057

Epoch: 5| Step: 8
Training loss: 2.9232032735057722
Validation loss: 3.6235755580007343

Epoch: 5| Step: 9
Training loss: 3.5021246864347844
Validation loss: 3.6231184571760506

Epoch: 5| Step: 10
Training loss: 3.7607372425555
Validation loss: 3.622279171894728

Epoch: 26| Step: 0
Training loss: 4.33249044779381
Validation loss: 3.621373885936463

Epoch: 5| Step: 1
Training loss: 4.04902409227872
Validation loss: 3.6206933061955913

Epoch: 5| Step: 2
Training loss: 4.214578105768019
Validation loss: 3.619681383378297

Epoch: 5| Step: 3
Training loss: 3.44985613868528
Validation loss: 3.619635798681721

Epoch: 5| Step: 4
Training loss: 4.318295330399123
Validation loss: 3.6179770082442166

Epoch: 5| Step: 5
Training loss: 3.6649652926478686
Validation loss: 3.6188499932062967

Epoch: 5| Step: 6
Training loss: 3.735887293077395
Validation loss: 3.6172610861694867

Epoch: 5| Step: 7
Training loss: 3.5700439084983193
Validation loss: 3.6162449801612255

Epoch: 5| Step: 8
Training loss: 3.545551473230732
Validation loss: 3.615128457634174

Epoch: 5| Step: 9
Training loss: 3.4898167014968546
Validation loss: 3.6143315037117296

Epoch: 5| Step: 10
Training loss: 3.3810249521665545
Validation loss: 3.6143268578022614

Epoch: 27| Step: 0
Training loss: 3.7276875778885663
Validation loss: 3.614061700532403

Epoch: 5| Step: 1
Training loss: 2.8726699343249837
Validation loss: 3.613071610772212

Epoch: 5| Step: 2
Training loss: 4.482607396759874
Validation loss: 3.6129958474904336

Epoch: 5| Step: 3
Training loss: 3.962965948104394
Validation loss: 3.6119969484927315

Epoch: 5| Step: 4
Training loss: 3.320247730296574
Validation loss: 3.6119737975600414

Epoch: 5| Step: 5
Training loss: 3.2312607076972912
Validation loss: 3.614324877437204

Epoch: 5| Step: 6
Training loss: 4.526187778773194
Validation loss: 3.6105350043246265

Epoch: 5| Step: 7
Training loss: 3.485579620279336
Validation loss: 3.609205429766786

Epoch: 5| Step: 8
Training loss: 4.446926795941979
Validation loss: 3.6085068400355476

Epoch: 5| Step: 9
Training loss: 3.6756328427134277
Validation loss: 3.6079291235630597

Epoch: 5| Step: 10
Training loss: 3.7911829098363166
Validation loss: 3.60743084632641

Epoch: 28| Step: 0
Training loss: 3.981390938891655
Validation loss: 3.607087583379892

Epoch: 5| Step: 1
Training loss: 3.2134309540425674
Validation loss: 3.606300388656012

Epoch: 5| Step: 2
Training loss: 4.252776641369372
Validation loss: 3.605542711856895

Epoch: 5| Step: 3
Training loss: 3.693442260522225
Validation loss: 3.605204582435806

Epoch: 5| Step: 4
Training loss: 3.573138097605939
Validation loss: 3.6046998365047735

Epoch: 5| Step: 5
Training loss: 4.1774624900572075
Validation loss: 3.6040015784177037

Epoch: 5| Step: 6
Training loss: 3.719562986607477
Validation loss: 3.603530498075657

Epoch: 5| Step: 7
Training loss: 3.868902762359727
Validation loss: 3.6028058419925992

Epoch: 5| Step: 8
Training loss: 4.0743968774729264
Validation loss: 3.602509185701196

Epoch: 5| Step: 9
Training loss: 3.35851670767141
Validation loss: 3.601451488134043

Epoch: 5| Step: 10
Training loss: 3.806917574864731
Validation loss: 3.6010681244395535

Epoch: 29| Step: 0
Training loss: 3.9655290885130654
Validation loss: 3.600486179733648

Epoch: 5| Step: 1
Training loss: 3.6605264808250313
Validation loss: 3.6003900193058738

Epoch: 5| Step: 2
Training loss: 4.112856706263286
Validation loss: 3.5996014311160334

Epoch: 5| Step: 3
Training loss: 4.242869510238113
Validation loss: 3.5985767909073543

Epoch: 5| Step: 4
Training loss: 3.2748324169350695
Validation loss: 3.598178497963651

Epoch: 5| Step: 5
Training loss: 4.391056569022813
Validation loss: 3.597619939268129

Epoch: 5| Step: 6
Training loss: 3.8373839221011736
Validation loss: 3.5971044121832456

Epoch: 5| Step: 7
Training loss: 3.144420095813
Validation loss: 3.596576907460691

Epoch: 5| Step: 8
Training loss: 3.666140619747449
Validation loss: 3.5956493649787893

Epoch: 5| Step: 9
Training loss: 4.087987673537451
Validation loss: 3.595190654544126

Epoch: 5| Step: 10
Training loss: 3.0369734068237877
Validation loss: 3.5949331539340843

Epoch: 30| Step: 0
Training loss: 3.652784090475825
Validation loss: 3.5941056470124764

Epoch: 5| Step: 1
Training loss: 3.5395434728529356
Validation loss: 3.5934809843996436

Epoch: 5| Step: 2
Training loss: 4.366407184802078
Validation loss: 3.593112709640085

Epoch: 5| Step: 3
Training loss: 4.967146704771135
Validation loss: 3.5927710670702613

Epoch: 5| Step: 4
Training loss: 3.710458439472768
Validation loss: 3.59171885427354

Epoch: 5| Step: 5
Training loss: 4.1912501609158275
Validation loss: 3.591487775645976

Epoch: 5| Step: 6
Training loss: 3.2441955965955147
Validation loss: 3.59126962433822

Epoch: 5| Step: 7
Training loss: 3.0124194249184453
Validation loss: 3.59168083613152

Epoch: 5| Step: 8
Training loss: 3.5952226358163726
Validation loss: 3.614406051654855

Epoch: 5| Step: 9
Training loss: 3.7399754367368536
Validation loss: 3.5897980363643502

Epoch: 5| Step: 10
Training loss: 3.2385769146538586
Validation loss: 3.599036282123416

Epoch: 31| Step: 0
Training loss: 4.136743878656563
Validation loss: 3.599814448479871

Epoch: 5| Step: 1
Training loss: 3.618096453695256
Validation loss: 3.598606455289213

Epoch: 5| Step: 2
Training loss: 3.484622689924649
Validation loss: 3.599272303598823

Epoch: 5| Step: 3
Training loss: 4.2944517758728935
Validation loss: 3.6010822259484745

Epoch: 5| Step: 4
Training loss: 3.741940038219986
Validation loss: 3.5979395759918584

Epoch: 5| Step: 5
Training loss: 3.5809786548974367
Validation loss: 3.593947050551688

Epoch: 5| Step: 6
Training loss: 3.4727862819703863
Validation loss: 3.592851449596396

Epoch: 5| Step: 7
Training loss: 4.400238914939156
Validation loss: 3.5934410586612913

Epoch: 5| Step: 8
Training loss: 3.236844506791301
Validation loss: 3.592608603993278

Epoch: 5| Step: 9
Training loss: 4.1039550778345255
Validation loss: 3.5924814675653822

Epoch: 5| Step: 10
Training loss: 3.4666660681748485
Validation loss: 3.5885366111191224

Epoch: 32| Step: 0
Training loss: 3.4733291506116677
Validation loss: 3.5866997071602458

Epoch: 5| Step: 1
Training loss: 4.183137357663046
Validation loss: 3.5877110615870462

Epoch: 5| Step: 2
Training loss: 3.964482694074501
Validation loss: 3.5873377294472784

Epoch: 5| Step: 3
Training loss: 3.3272232481683366
Validation loss: 3.5840907177624146

Epoch: 5| Step: 4
Training loss: 3.2597910775481753
Validation loss: 3.5834924705942264

Epoch: 5| Step: 5
Training loss: 3.6913390784232396
Validation loss: 3.581870492783864

Epoch: 5| Step: 6
Training loss: 4.5600054466482725
Validation loss: 3.581685952194248

Epoch: 5| Step: 7
Training loss: 3.6469428127230703
Validation loss: 3.580791529614865

Epoch: 5| Step: 8
Training loss: 3.007039711500014
Validation loss: 3.5804213796955464

Epoch: 5| Step: 9
Training loss: 3.4754829016319637
Validation loss: 3.5802200860583264

Epoch: 5| Step: 10
Training loss: 4.82738797880137
Validation loss: 3.5796953885581577

Epoch: 33| Step: 0
Training loss: 3.5855964049631504
Validation loss: 3.5786799507268063

Epoch: 5| Step: 1
Training loss: 4.0805268796417105
Validation loss: 3.577508207176616

Epoch: 5| Step: 2
Training loss: 3.599736410663609
Validation loss: 3.5769360054348582

Epoch: 5| Step: 3
Training loss: 3.3187703220011042
Validation loss: 3.5760580375301942

Epoch: 5| Step: 4
Training loss: 4.16207981680905
Validation loss: 3.575414411587437

Epoch: 5| Step: 5
Training loss: 3.5387035465728607
Validation loss: 3.574620284907354

Epoch: 5| Step: 6
Training loss: 3.59312831642952
Validation loss: 3.5743497994274636

Epoch: 5| Step: 7
Training loss: 4.241432080530113
Validation loss: 3.573111344262722

Epoch: 5| Step: 8
Training loss: 3.3055085589347546
Validation loss: 3.572554628662692

Epoch: 5| Step: 9
Training loss: 3.5050049827202874
Validation loss: 3.571603059564098

Epoch: 5| Step: 10
Training loss: 4.5468563328520375
Validation loss: 3.5700216833025844

Epoch: 34| Step: 0
Training loss: 3.8463257633814325
Validation loss: 3.570443701418524

Epoch: 5| Step: 1
Training loss: 4.068204425382788
Validation loss: 3.5681373237078597

Epoch: 5| Step: 2
Training loss: 3.696781439093046
Validation loss: 3.5675430684726894

Epoch: 5| Step: 3
Training loss: 3.2365015382873565
Validation loss: 3.5664858818430147

Epoch: 5| Step: 4
Training loss: 4.231184880306344
Validation loss: 3.5639251336815474

Epoch: 5| Step: 5
Training loss: 2.885632962452803
Validation loss: 3.5619674634323397

Epoch: 5| Step: 6
Training loss: 3.342779856616317
Validation loss: 3.558932165900327

Epoch: 5| Step: 7
Training loss: 3.7861850785098277
Validation loss: 3.5574583306629055

Epoch: 5| Step: 8
Training loss: 3.855890222023557
Validation loss: 3.5551842941970806

Epoch: 5| Step: 9
Training loss: 4.017537296219373
Validation loss: 3.55285750320409

Epoch: 5| Step: 10
Training loss: 4.309185800140421
Validation loss: 3.5516156232786806

Epoch: 35| Step: 0
Training loss: 4.18299213147683
Validation loss: 3.5508462085962096

Epoch: 5| Step: 1
Training loss: 3.1209073542197703
Validation loss: 3.5508466591118224

Epoch: 5| Step: 2
Training loss: 3.980616693115192
Validation loss: 3.550332815406807

Epoch: 5| Step: 3
Training loss: 3.661110540868174
Validation loss: 3.55012055301677

Epoch: 5| Step: 4
Training loss: 3.620417625405753
Validation loss: 3.5498113359935557

Epoch: 5| Step: 5
Training loss: 3.6819395394238423
Validation loss: 3.5477757981716413

Epoch: 5| Step: 6
Training loss: 3.5688909125358617
Validation loss: 3.547564895289415

Epoch: 5| Step: 7
Training loss: 3.044441385878661
Validation loss: 3.547207754793565

Epoch: 5| Step: 8
Training loss: 3.226964893141824
Validation loss: 3.5464505473845844

Epoch: 5| Step: 9
Training loss: 3.9925307632054134
Validation loss: 3.5451565673758445

Epoch: 5| Step: 10
Training loss: 5.0411124857509515
Validation loss: 3.5444352092098197

Epoch: 36| Step: 0
Training loss: 3.892484289589638
Validation loss: 3.54378674562187

Epoch: 5| Step: 1
Training loss: 2.937084736792358
Validation loss: 3.5430928166832456

Epoch: 5| Step: 2
Training loss: 4.182058414147955
Validation loss: 3.5423697442717184

Epoch: 5| Step: 3
Training loss: 3.7468529529575116
Validation loss: 3.5416685916284956

Epoch: 5| Step: 4
Training loss: 4.196214859457093
Validation loss: 3.540171416289705

Epoch: 5| Step: 5
Training loss: 3.5876806339950282
Validation loss: 3.5402820701261293

Epoch: 5| Step: 6
Training loss: 4.01036802320168
Validation loss: 3.539019610405791

Epoch: 5| Step: 7
Training loss: 4.208619111181012
Validation loss: 3.538063130418954

Epoch: 5| Step: 8
Training loss: 2.8782680016197153
Validation loss: 3.5369823180652293

Epoch: 5| Step: 9
Training loss: 3.741278870557536
Validation loss: 3.5364499056737415

Epoch: 5| Step: 10
Training loss: 3.542988399631977
Validation loss: 3.535680670358609

Epoch: 37| Step: 0
Training loss: 3.5815868705237905
Validation loss: 3.5345367590467296

Epoch: 5| Step: 1
Training loss: 3.472521544376603
Validation loss: 3.533339918420297

Epoch: 5| Step: 2
Training loss: 3.6713562943965643
Validation loss: 3.5342713749640464

Epoch: 5| Step: 3
Training loss: 4.355400652844898
Validation loss: 3.531873052183797

Epoch: 5| Step: 4
Training loss: 3.674883450067775
Validation loss: 3.530697159938027

Epoch: 5| Step: 5
Training loss: 3.286881473503694
Validation loss: 3.530292549252336

Epoch: 5| Step: 6
Training loss: 3.7232870426106506
Validation loss: 3.529855387238704

Epoch: 5| Step: 7
Training loss: 3.8846488923590945
Validation loss: 3.528272070984236

Epoch: 5| Step: 8
Training loss: 3.706768062723266
Validation loss: 3.5277180026457704

Epoch: 5| Step: 9
Training loss: 4.219938887745721
Validation loss: 3.532910704881554

Epoch: 5| Step: 10
Training loss: 3.3895395536747013
Validation loss: 3.5260793523612963

Epoch: 38| Step: 0
Training loss: 3.902005139877868
Validation loss: 3.5263641937457884

Epoch: 5| Step: 1
Training loss: 4.017830921874695
Validation loss: 3.5262742650698238

Epoch: 5| Step: 2
Training loss: 3.71358792069758
Validation loss: 3.5266124166290758

Epoch: 5| Step: 3
Training loss: 4.147039087954378
Validation loss: 3.526415447804832

Epoch: 5| Step: 4
Training loss: 3.2838797067873697
Validation loss: 3.525138572227186

Epoch: 5| Step: 5
Training loss: 3.146708352033723
Validation loss: 3.5249437203587624

Epoch: 5| Step: 6
Training loss: 3.544117801155085
Validation loss: 3.5246681934598243

Epoch: 5| Step: 7
Training loss: 3.6287201832680664
Validation loss: 3.5236667632773835

Epoch: 5| Step: 8
Training loss: 4.296754259667261
Validation loss: 3.523143985550898

Epoch: 5| Step: 9
Training loss: 3.622302531565798
Validation loss: 3.5221871262739723

Epoch: 5| Step: 10
Training loss: 3.62236492802892
Validation loss: 3.521374500613446

Epoch: 39| Step: 0
Training loss: 1.9794252795526668
Validation loss: 3.5210464077151937

Epoch: 5| Step: 1
Training loss: 3.7783983054434107
Validation loss: 3.52016165196915

Epoch: 5| Step: 2
Training loss: 3.4808757642467802
Validation loss: 3.52048702227309

Epoch: 5| Step: 3
Training loss: 4.191926808307957
Validation loss: 3.519491033128658

Epoch: 5| Step: 4
Training loss: 3.9283133013255935
Validation loss: 3.519413510265095

Epoch: 5| Step: 5
Training loss: 3.704412823891529
Validation loss: 3.518942226348977

Epoch: 5| Step: 6
Training loss: 3.9119745651229567
Validation loss: 3.5178722452149773

Epoch: 5| Step: 7
Training loss: 4.330264887999825
Validation loss: 3.5170367025568523

Epoch: 5| Step: 8
Training loss: 3.50111153527303
Validation loss: 3.5161997554301245

Epoch: 5| Step: 9
Training loss: 3.5514557284925954
Validation loss: 3.516369569020211

Epoch: 5| Step: 10
Training loss: 4.2124494057172415
Validation loss: 3.5153417942185534

Epoch: 40| Step: 0
Training loss: 4.004911030556221
Validation loss: 3.514617301512763

Epoch: 5| Step: 1
Training loss: 3.254347314513533
Validation loss: 3.513712539332205

Epoch: 5| Step: 2
Training loss: 2.8007523922251556
Validation loss: 3.513095878476303

Epoch: 5| Step: 3
Training loss: 4.0828427908905525
Validation loss: 3.5128454233619473

Epoch: 5| Step: 4
Training loss: 3.781943391639531
Validation loss: 3.5122950760114575

Epoch: 5| Step: 5
Training loss: 4.5017480633883435
Validation loss: 3.5119869303111955

Epoch: 5| Step: 6
Training loss: 3.477420178175346
Validation loss: 3.5110266740840963

Epoch: 5| Step: 7
Training loss: 3.2624113341227674
Validation loss: 3.5105940927706185

Epoch: 5| Step: 8
Training loss: 3.5180739625721245
Validation loss: 3.5100879332085606

Epoch: 5| Step: 9
Training loss: 4.144593377685852
Validation loss: 3.509808043777348

Epoch: 5| Step: 10
Training loss: 3.8483439958792816
Validation loss: 3.5090373070822896

Epoch: 41| Step: 0
Training loss: 3.8755423873809867
Validation loss: 3.508459361562729

Epoch: 5| Step: 1
Training loss: 3.676283118012232
Validation loss: 3.5079281969638805

Epoch: 5| Step: 2
Training loss: 4.7308941121464345
Validation loss: 3.5077643623322325

Epoch: 5| Step: 3
Training loss: 3.2613472549950235
Validation loss: 3.506987012628295

Epoch: 5| Step: 4
Training loss: 2.985764105297079
Validation loss: 3.506297521068267

Epoch: 5| Step: 5
Training loss: 3.9525305259534367
Validation loss: 3.5054166647468583

Epoch: 5| Step: 6
Training loss: 3.3815856541354803
Validation loss: 3.505534903112368

Epoch: 5| Step: 7
Training loss: 4.376001297945321
Validation loss: 3.5050263314245984

Epoch: 5| Step: 8
Training loss: 3.841165433499605
Validation loss: 3.5044509519733005

Epoch: 5| Step: 9
Training loss: 3.5343046226881167
Validation loss: 3.503988802805944

Epoch: 5| Step: 10
Training loss: 2.7161165835060417
Validation loss: 3.503222353330787

Epoch: 42| Step: 0
Training loss: 3.612383756780279
Validation loss: 3.502629505301711

Epoch: 5| Step: 1
Training loss: 3.8362294880358094
Validation loss: 3.5023059939309737

Epoch: 5| Step: 2
Training loss: 3.6387149892188746
Validation loss: 3.501853436010346

Epoch: 5| Step: 3
Training loss: 3.76754926845481
Validation loss: 3.501782785081212

Epoch: 5| Step: 4
Training loss: 2.8890326985812536
Validation loss: 3.5006523930640356

Epoch: 5| Step: 5
Training loss: 3.0404601817924584
Validation loss: 3.499998262583687

Epoch: 5| Step: 6
Training loss: 4.572689227427323
Validation loss: 3.5000716098075393

Epoch: 5| Step: 7
Training loss: 3.891623740330469
Validation loss: 3.4987980013531583

Epoch: 5| Step: 8
Training loss: 4.165703369685483
Validation loss: 3.4985238755203154

Epoch: 5| Step: 9
Training loss: 3.2834430450337444
Validation loss: 3.498014513901488

Epoch: 5| Step: 10
Training loss: 3.884116247494126
Validation loss: 3.4977719097241806

Epoch: 43| Step: 0
Training loss: 3.3090142677532137
Validation loss: 3.4967455287273523

Epoch: 5| Step: 1
Training loss: 3.1006451458421633
Validation loss: 3.4972257576982075

Epoch: 5| Step: 2
Training loss: 3.7520471707044685
Validation loss: 3.496147643257269

Epoch: 5| Step: 3
Training loss: 3.8729794064030183
Validation loss: 3.495562448952453

Epoch: 5| Step: 4
Training loss: 3.994684740978889
Validation loss: 3.4957740221809113

Epoch: 5| Step: 5
Training loss: 3.6378294071341712
Validation loss: 3.4948632976127554

Epoch: 5| Step: 6
Training loss: 4.052787556126975
Validation loss: 3.4937252015840663

Epoch: 5| Step: 7
Training loss: 4.177981361767587
Validation loss: 3.4935143613873576

Epoch: 5| Step: 8
Training loss: 2.9736087591391707
Validation loss: 3.493051280467269

Epoch: 5| Step: 9
Training loss: 3.8998737021316634
Validation loss: 3.4925523572704678

Epoch: 5| Step: 10
Training loss: 3.8567466280029734
Validation loss: 3.492943965648625

Epoch: 44| Step: 0
Training loss: 3.000355699433005
Validation loss: 3.494247377756029

Epoch: 5| Step: 1
Training loss: 4.318973713227122
Validation loss: 3.4996812077556503

Epoch: 5| Step: 2
Training loss: 4.226146853840341
Validation loss: 3.4906080528777164

Epoch: 5| Step: 3
Training loss: 3.7180831695989114
Validation loss: 3.4908726996089863

Epoch: 5| Step: 4
Training loss: 3.8609373814371692
Validation loss: 3.4911402621215926

Epoch: 5| Step: 5
Training loss: 3.7530834236986657
Validation loss: 3.4919869566590434

Epoch: 5| Step: 6
Training loss: 3.383443090854027
Validation loss: 3.4939284671250435

Epoch: 5| Step: 7
Training loss: 2.914767673453574
Validation loss: 3.503079748461965

Epoch: 5| Step: 8
Training loss: 4.1078193533902985
Validation loss: 3.4932787533782608

Epoch: 5| Step: 9
Training loss: 3.5388994663572175
Validation loss: 3.490818893825019

Epoch: 5| Step: 10
Training loss: 3.6998090746308385
Validation loss: 3.490089353122808

Epoch: 45| Step: 0
Training loss: 3.631528040734992
Validation loss: 3.4901733154378087

Epoch: 5| Step: 1
Training loss: 3.86644662252866
Validation loss: 3.496346353899058

Epoch: 5| Step: 2
Training loss: 3.6533132643276036
Validation loss: 3.4877342696757387

Epoch: 5| Step: 3
Training loss: 3.4766692070176037
Validation loss: 3.487317096561098

Epoch: 5| Step: 4
Training loss: 3.6360655955072567
Validation loss: 3.4870579012126557

Epoch: 5| Step: 5
Training loss: 3.9553561341334547
Validation loss: 3.486217533815282

Epoch: 5| Step: 6
Training loss: 4.1026835335562595
Validation loss: 3.485773492447505

Epoch: 5| Step: 7
Training loss: 3.660699207660313
Validation loss: 3.485285608299375

Epoch: 5| Step: 8
Training loss: 3.2040933773421054
Validation loss: 3.4846882270309174

Epoch: 5| Step: 9
Training loss: 4.127835772862652
Validation loss: 3.484244780992939

Epoch: 5| Step: 10
Training loss: 3.229333606629658
Validation loss: 3.4843547005054942

Epoch: 46| Step: 0
Training loss: 4.341876826749247
Validation loss: 3.484219630440671

Epoch: 5| Step: 1
Training loss: 3.666117077878302
Validation loss: 3.4830503906895514

Epoch: 5| Step: 2
Training loss: 3.5859187505892596
Validation loss: 3.4823827446117748

Epoch: 5| Step: 3
Training loss: 3.950297554494214
Validation loss: 3.4820488131955263

Epoch: 5| Step: 4
Training loss: 3.838012010047652
Validation loss: 3.481192864540341

Epoch: 5| Step: 5
Training loss: 3.4760492181662586
Validation loss: 3.480134639348999

Epoch: 5| Step: 6
Training loss: 3.2020799374153897
Validation loss: 3.479791349483867

Epoch: 5| Step: 7
Training loss: 3.800452662159719
Validation loss: 3.4793295617986466

Epoch: 5| Step: 8
Training loss: 3.152802803810342
Validation loss: 3.4786438151488603

Epoch: 5| Step: 9
Training loss: 3.7627496782261787
Validation loss: 3.47803506814074

Epoch: 5| Step: 10
Training loss: 3.772194983587362
Validation loss: 3.477705897103282

Epoch: 47| Step: 0
Training loss: 4.1890057945184065
Validation loss: 3.477247020384714

Epoch: 5| Step: 1
Training loss: 2.8402255508690804
Validation loss: 3.4767495691588794

Epoch: 5| Step: 2
Training loss: 3.786033190227587
Validation loss: 3.4762694156591243

Epoch: 5| Step: 3
Training loss: 3.807084286212889
Validation loss: 3.475711705777289

Epoch: 5| Step: 4
Training loss: 3.1533761112572427
Validation loss: 3.4752631367488296

Epoch: 5| Step: 5
Training loss: 3.8662199409073623
Validation loss: 3.474334909410822

Epoch: 5| Step: 6
Training loss: 3.3220847751702496
Validation loss: 3.473617552985518

Epoch: 5| Step: 7
Training loss: 4.414114136520429
Validation loss: 3.4733260978568414

Epoch: 5| Step: 8
Training loss: 3.577130975037571
Validation loss: 3.472785647110948

Epoch: 5| Step: 9
Training loss: 3.730742407542765
Validation loss: 3.47192987508838

Epoch: 5| Step: 10
Training loss: 3.669433691211326
Validation loss: 3.470972186166648

Epoch: 48| Step: 0
Training loss: 3.199789999985366
Validation loss: 3.470371249190768

Epoch: 5| Step: 1
Training loss: 3.262172498378908
Validation loss: 3.4691807358337035

Epoch: 5| Step: 2
Training loss: 3.462739428012665
Validation loss: 3.4674528919627408

Epoch: 5| Step: 3
Training loss: 3.597567578940858
Validation loss: 3.467218452828631

Epoch: 5| Step: 4
Training loss: 3.793448200821956
Validation loss: 3.4679815211024647

Epoch: 5| Step: 5
Training loss: 3.3615678594237455
Validation loss: 3.465282220021283

Epoch: 5| Step: 6
Training loss: 3.984344362627307
Validation loss: 3.4644205600950864

Epoch: 5| Step: 7
Training loss: 3.6117135270873306
Validation loss: 3.463686215664817

Epoch: 5| Step: 8
Training loss: 3.651984049174142
Validation loss: 3.462855039206342

Epoch: 5| Step: 9
Training loss: 4.40484510168894
Validation loss: 3.4627410064394284

Epoch: 5| Step: 10
Training loss: 4.09238393573548
Validation loss: 3.4617598635838216

Epoch: 49| Step: 0
Training loss: 3.9913133235200653
Validation loss: 3.4613881491934926

Epoch: 5| Step: 1
Training loss: 3.56014267410526
Validation loss: 3.461329512271105

Epoch: 5| Step: 2
Training loss: 3.841607714108972
Validation loss: 3.460361740319345

Epoch: 5| Step: 3
Training loss: 3.6796732454773
Validation loss: 3.4597621125429807

Epoch: 5| Step: 4
Training loss: 3.853574772654915
Validation loss: 3.459283374790894

Epoch: 5| Step: 5
Training loss: 3.1938446329508126
Validation loss: 3.4587487303510627

Epoch: 5| Step: 6
Training loss: 3.7614003142737613
Validation loss: 3.4584866341629934

Epoch: 5| Step: 7
Training loss: 4.273418977407871
Validation loss: 3.4582806368352794

Epoch: 5| Step: 8
Training loss: 3.3468495201473063
Validation loss: 3.4576301339152478

Epoch: 5| Step: 9
Training loss: 2.675283655831687
Validation loss: 3.4568974706294657

Epoch: 5| Step: 10
Training loss: 4.090321510194852
Validation loss: 3.456591458923215

Epoch: 50| Step: 0
Training loss: 3.7231384797594265
Validation loss: 3.4561294791293213

Epoch: 5| Step: 1
Training loss: 3.6635602594633596
Validation loss: 3.455335416016781

Epoch: 5| Step: 2
Training loss: 3.7154622651084512
Validation loss: 3.455429033822746

Epoch: 5| Step: 3
Training loss: 3.6330082010039577
Validation loss: 3.4545052655525876

Epoch: 5| Step: 4
Training loss: 3.511687655199862
Validation loss: 3.4535524208346953

Epoch: 5| Step: 5
Training loss: 3.7400662137866356
Validation loss: 3.453373626235253

Epoch: 5| Step: 6
Training loss: 4.000505177068632
Validation loss: 3.453122518858981

Epoch: 5| Step: 7
Training loss: 3.191240397407856
Validation loss: 3.452294306130228

Epoch: 5| Step: 8
Training loss: 3.2107735473653287
Validation loss: 3.452136207982779

Epoch: 5| Step: 9
Training loss: 4.32392453620266
Validation loss: 3.4517463007187583

Epoch: 5| Step: 10
Training loss: 3.5633082225927044
Validation loss: 3.451072964026582

Epoch: 51| Step: 0
Training loss: 3.2462695793704195
Validation loss: 3.450327708187001

Epoch: 5| Step: 1
Training loss: 4.185972476028523
Validation loss: 3.4501404599474306

Epoch: 5| Step: 2
Training loss: 4.292845678257487
Validation loss: 3.4498680389120375

Epoch: 5| Step: 3
Training loss: 4.1856168241792675
Validation loss: 3.4492962109110934

Epoch: 5| Step: 4
Training loss: 3.325996112043594
Validation loss: 3.4488370582903687

Epoch: 5| Step: 5
Training loss: 3.4685237226484693
Validation loss: 3.447915788801648

Epoch: 5| Step: 6
Training loss: 3.7011672369693893
Validation loss: 3.447851743211725

Epoch: 5| Step: 7
Training loss: 3.5354516343272175
Validation loss: 3.447379262411245

Epoch: 5| Step: 8
Training loss: 3.1640174391563716
Validation loss: 3.4471398020450175

Epoch: 5| Step: 9
Training loss: 2.885728307390477
Validation loss: 3.4461760928772565

Epoch: 5| Step: 10
Training loss: 4.143690363712311
Validation loss: 3.4460352531900376

Epoch: 52| Step: 0
Training loss: 3.411036217274968
Validation loss: 3.4450589967715404

Epoch: 5| Step: 1
Training loss: 4.042635195328632
Validation loss: 3.4448745870022455

Epoch: 5| Step: 2
Training loss: 3.153724944521288
Validation loss: 3.4443284482827496

Epoch: 5| Step: 3
Training loss: 3.586395167979028
Validation loss: 3.4435616037856205

Epoch: 5| Step: 4
Training loss: 4.297637982685909
Validation loss: 3.44361882801636

Epoch: 5| Step: 5
Training loss: 3.3806605024372467
Validation loss: 3.4429672273188214

Epoch: 5| Step: 6
Training loss: 3.6930248445883196
Validation loss: 3.442614580595268

Epoch: 5| Step: 7
Training loss: 3.1875553500287754
Validation loss: 3.4421495630745254

Epoch: 5| Step: 8
Training loss: 4.2897323891283605
Validation loss: 3.441973981420864

Epoch: 5| Step: 9
Training loss: 3.3226436554656376
Validation loss: 3.4412305372980976

Epoch: 5| Step: 10
Training loss: 3.749974314283777
Validation loss: 3.440210937657434

Epoch: 53| Step: 0
Training loss: 3.1244378156427373
Validation loss: 3.4407263373247345

Epoch: 5| Step: 1
Training loss: 4.417177758545148
Validation loss: 3.4390652177813377

Epoch: 5| Step: 2
Training loss: 3.93343276420824
Validation loss: 3.439279297515132

Epoch: 5| Step: 3
Training loss: 4.003524896091934
Validation loss: 3.439384685100805

Epoch: 5| Step: 4
Training loss: 3.3453768756486184
Validation loss: 3.437813469548552

Epoch: 5| Step: 5
Training loss: 3.2889997245252616
Validation loss: 3.438176776269828

Epoch: 5| Step: 6
Training loss: 3.3696336822188475
Validation loss: 3.4374230220524695

Epoch: 5| Step: 7
Training loss: 3.4554507333353506
Validation loss: 3.4367534479337896

Epoch: 5| Step: 8
Training loss: 3.3811541362154256
Validation loss: 3.43752114148691

Epoch: 5| Step: 9
Training loss: 3.8851655089718498
Validation loss: 3.435761605241787

Epoch: 5| Step: 10
Training loss: 3.899508709407334
Validation loss: 3.4352377807685768

Epoch: 54| Step: 0
Training loss: 3.4075135853329352
Validation loss: 3.4354132962732544

Epoch: 5| Step: 1
Training loss: 3.2877084296116723
Validation loss: 3.4343438046094374

Epoch: 5| Step: 2
Training loss: 2.9405083368653804
Validation loss: 3.434532598548578

Epoch: 5| Step: 3
Training loss: 4.189388930889303
Validation loss: 3.43382667125639

Epoch: 5| Step: 4
Training loss: 3.3422531627965637
Validation loss: 3.4329219593369698

Epoch: 5| Step: 5
Training loss: 3.8084542742890566
Validation loss: 3.432646226291138

Epoch: 5| Step: 6
Training loss: 3.871263856354927
Validation loss: 3.4319716461572343

Epoch: 5| Step: 7
Training loss: 3.462304803186874
Validation loss: 3.431980285806196

Epoch: 5| Step: 8
Training loss: 2.91521670313006
Validation loss: 3.4314278363583717

Epoch: 5| Step: 9
Training loss: 4.360893176573504
Validation loss: 3.430921095154611

Epoch: 5| Step: 10
Training loss: 4.396444462002301
Validation loss: 3.430748265617456

Epoch: 55| Step: 0
Training loss: 3.888535271567887
Validation loss: 3.429963590484372

Epoch: 5| Step: 1
Training loss: 3.3089004248366822
Validation loss: 3.4304873967729845

Epoch: 5| Step: 2
Training loss: 3.7451870868232495
Validation loss: 3.429189121388776

Epoch: 5| Step: 3
Training loss: 3.607373495970262
Validation loss: 3.4289393367067307

Epoch: 5| Step: 4
Training loss: 4.053445908923945
Validation loss: 3.428288088153237

Epoch: 5| Step: 5
Training loss: 3.514726854675349
Validation loss: 3.4282204004967145

Epoch: 5| Step: 6
Training loss: 3.4721709557033456
Validation loss: 3.4274441537557077

Epoch: 5| Step: 7
Training loss: 3.758122738663529
Validation loss: 3.426778767396312

Epoch: 5| Step: 8
Training loss: 3.742500690263928
Validation loss: 3.4268839169965983

Epoch: 5| Step: 9
Training loss: 3.067139828156497
Validation loss: 3.4263318878692384

Epoch: 5| Step: 10
Training loss: 3.969540614879292
Validation loss: 3.425859306700492

Epoch: 56| Step: 0
Training loss: 3.6758608996916404
Validation loss: 3.4254310116350752

Epoch: 5| Step: 1
Training loss: 3.143009627965587
Validation loss: 3.4249222304309273

Epoch: 5| Step: 2
Training loss: 3.963117311930723
Validation loss: 3.4245852547504025

Epoch: 5| Step: 3
Training loss: 3.6603125800392715
Validation loss: 3.4234538945603177

Epoch: 5| Step: 4
Training loss: 3.1426925306436018
Validation loss: 3.4234044134374404

Epoch: 5| Step: 5
Training loss: 3.3966156384120034
Validation loss: 3.423291191863114

Epoch: 5| Step: 6
Training loss: 4.383593593360138
Validation loss: 3.422195162619762

Epoch: 5| Step: 7
Training loss: 3.2187491111383784
Validation loss: 3.421939630666457

Epoch: 5| Step: 8
Training loss: 3.259062090562873
Validation loss: 3.421815907737006

Epoch: 5| Step: 9
Training loss: 4.429712689040485
Validation loss: 3.421878494228696

Epoch: 5| Step: 10
Training loss: 3.5671311108764447
Validation loss: 3.4212544675951895

Epoch: 57| Step: 0
Training loss: 3.380361184228668
Validation loss: 3.4203200175482964

Epoch: 5| Step: 1
Training loss: 3.656909720086989
Validation loss: 3.420305346919374

Epoch: 5| Step: 2
Training loss: 2.9542516749050343
Validation loss: 3.4188961335489974

Epoch: 5| Step: 3
Training loss: 3.941727563711556
Validation loss: 3.418572503319839

Epoch: 5| Step: 4
Training loss: 3.5399465235749688
Validation loss: 3.418592575500182

Epoch: 5| Step: 5
Training loss: 4.328308542264072
Validation loss: 3.41754263166803

Epoch: 5| Step: 6
Training loss: 3.9255140223103866
Validation loss: 3.4171930973529605

Epoch: 5| Step: 7
Training loss: 3.3938659086157283
Validation loss: 3.4171654381944725

Epoch: 5| Step: 8
Training loss: 4.056832688715841
Validation loss: 3.4163005556671497

Epoch: 5| Step: 9
Training loss: 3.809944046490727
Validation loss: 3.4159239425161316

Epoch: 5| Step: 10
Training loss: 2.6537749483981505
Validation loss: 3.4157034393836843

Epoch: 58| Step: 0
Training loss: 3.3816058184954274
Validation loss: 3.414761771343198

Epoch: 5| Step: 1
Training loss: 3.5906669328729377
Validation loss: 3.4142317200233325

Epoch: 5| Step: 2
Training loss: 3.199126786061837
Validation loss: 3.4143389063872207

Epoch: 5| Step: 3
Training loss: 3.3595115456443043
Validation loss: 3.4136973989033743

Epoch: 5| Step: 4
Training loss: 3.798261475652612
Validation loss: 3.4141295282314092

Epoch: 5| Step: 5
Training loss: 3.6523259942750226
Validation loss: 3.4141195924214265

Epoch: 5| Step: 6
Training loss: 2.5181258192555753
Validation loss: 3.412870627873575

Epoch: 5| Step: 7
Training loss: 3.858859255535024
Validation loss: 3.412305962413936

Epoch: 5| Step: 8
Training loss: 4.351845203030845
Validation loss: 3.4116776946380445

Epoch: 5| Step: 9
Training loss: 3.939226649918264
Validation loss: 3.411067136822876

Epoch: 5| Step: 10
Training loss: 4.141454764662899
Validation loss: 3.41136735151205

Epoch: 59| Step: 0
Training loss: 3.56052276887753
Validation loss: 3.4100580077613882

Epoch: 5| Step: 1
Training loss: 4.0339729516517835
Validation loss: 3.4100464241924544

Epoch: 5| Step: 2
Training loss: 3.12354504093373
Validation loss: 3.409849909504945

Epoch: 5| Step: 3
Training loss: 3.8185347026563248
Validation loss: 3.4095728219052535

Epoch: 5| Step: 4
Training loss: 3.6157170843664868
Validation loss: 3.4091383718727237

Epoch: 5| Step: 5
Training loss: 3.361148525761908
Validation loss: 3.408968319955642

Epoch: 5| Step: 6
Training loss: 4.195052438983369
Validation loss: 3.408192359537562

Epoch: 5| Step: 7
Training loss: 3.4394947159964047
Validation loss: 3.4075324903149924

Epoch: 5| Step: 8
Training loss: 4.042811411869032
Validation loss: 3.406456280178715

Epoch: 5| Step: 9
Training loss: 3.3647996264085185
Validation loss: 3.4074165128275418

Epoch: 5| Step: 10
Training loss: 3.221298986202352
Validation loss: 3.406888489698427

Epoch: 60| Step: 0
Training loss: 3.6125417581540478
Validation loss: 3.4063974111329736

Epoch: 5| Step: 1
Training loss: 3.527929855099163
Validation loss: 3.405387556241112

Epoch: 5| Step: 2
Training loss: 3.729109111888734
Validation loss: 3.4046713256617402

Epoch: 5| Step: 3
Training loss: 3.0705721602192124
Validation loss: 3.4042487616410115

Epoch: 5| Step: 4
Training loss: 3.8124812391476155
Validation loss: 3.4047087273507795

Epoch: 5| Step: 5
Training loss: 3.1911854101414123
Validation loss: 3.4039897398327645

Epoch: 5| Step: 6
Training loss: 3.795495555824328
Validation loss: 3.4028007697965954

Epoch: 5| Step: 7
Training loss: 3.759998724511113
Validation loss: 3.4026466209299038

Epoch: 5| Step: 8
Training loss: 3.46978551855872
Validation loss: 3.4027558334733468

Epoch: 5| Step: 9
Training loss: 3.7629354535440895
Validation loss: 3.402110249719107

Epoch: 5| Step: 10
Training loss: 4.19510449794248
Validation loss: 3.4018524494474875

Epoch: 61| Step: 0
Training loss: 3.759696123545924
Validation loss: 3.401310061917256

Epoch: 5| Step: 1
Training loss: 3.85552613622439
Validation loss: 3.4008354736703814

Epoch: 5| Step: 2
Training loss: 3.166229184365024
Validation loss: 3.400020714032594

Epoch: 5| Step: 3
Training loss: 3.371207755803265
Validation loss: 3.3993333713738463

Epoch: 5| Step: 4
Training loss: 4.265938436429692
Validation loss: 3.399223254715333

Epoch: 5| Step: 5
Training loss: 3.501715512147601
Validation loss: 3.398905280289131

Epoch: 5| Step: 6
Training loss: 3.729818589040668
Validation loss: 3.3977314888121266

Epoch: 5| Step: 7
Training loss: 3.2655880574596283
Validation loss: 3.397876677102989

Epoch: 5| Step: 8
Training loss: 3.7469629069015085
Validation loss: 3.3975261337029856

Epoch: 5| Step: 9
Training loss: 3.444730748477215
Validation loss: 3.396983138416114

Epoch: 5| Step: 10
Training loss: 3.692173727674139
Validation loss: 3.396518489936133

Epoch: 62| Step: 0
Training loss: 2.8403195660746974
Validation loss: 3.3960675062504064

Epoch: 5| Step: 1
Training loss: 3.2477297556406732
Validation loss: 3.3950815330519664

Epoch: 5| Step: 2
Training loss: 4.177733918449016
Validation loss: 3.3949030488896366

Epoch: 5| Step: 3
Training loss: 3.929482911625751
Validation loss: 3.3951552666751548

Epoch: 5| Step: 4
Training loss: 3.844095602237997
Validation loss: 3.3937217422813983

Epoch: 5| Step: 5
Training loss: 3.816394505243571
Validation loss: 3.3944254305167108

Epoch: 5| Step: 6
Training loss: 3.639016250309901
Validation loss: 3.3927836496315016

Epoch: 5| Step: 7
Training loss: 3.5316349596151744
Validation loss: 3.3928151495931043

Epoch: 5| Step: 8
Training loss: 2.427237695415842
Validation loss: 3.393115780129294

Epoch: 5| Step: 9
Training loss: 3.842688188976591
Validation loss: 3.3914799711249586

Epoch: 5| Step: 10
Training loss: 4.25316075990374
Validation loss: 3.3915914714994013

Epoch: 63| Step: 0
Training loss: 3.604511766321115
Validation loss: 3.39155803416854

Epoch: 5| Step: 1
Training loss: 2.914913758822808
Validation loss: 3.3911481483670514

Epoch: 5| Step: 2
Training loss: 3.243639811443218
Validation loss: 3.3907740974941225

Epoch: 5| Step: 3
Training loss: 3.732386614335014
Validation loss: 3.3910149284428504

Epoch: 5| Step: 4
Training loss: 3.5245432672787436
Validation loss: 3.393086702980446

Epoch: 5| Step: 5
Training loss: 3.3250711247000364
Validation loss: 3.3899483755787707

Epoch: 5| Step: 6
Training loss: 4.340969595471568
Validation loss: 3.392280440254856

Epoch: 5| Step: 7
Training loss: 3.656962920236927
Validation loss: 3.394213742377448

Epoch: 5| Step: 8
Training loss: 3.612445664574679
Validation loss: 3.3927243529258893

Epoch: 5| Step: 9
Training loss: 4.135730081335587
Validation loss: 3.389792477582275

Epoch: 5| Step: 10
Training loss: 3.507059606963074
Validation loss: 3.388719406094832

Epoch: 64| Step: 0
Training loss: 4.054041581349474
Validation loss: 3.386607208801499

Epoch: 5| Step: 1
Training loss: 3.3368171764907544
Validation loss: 3.3868458790202522

Epoch: 5| Step: 2
Training loss: 3.2873466891087912
Validation loss: 3.3863201294477006

Epoch: 5| Step: 3
Training loss: 3.8462596856740072
Validation loss: 3.386948915214429

Epoch: 5| Step: 4
Training loss: 3.9803025919457062
Validation loss: 3.3867573097742785

Epoch: 5| Step: 5
Training loss: 3.1152005471811464
Validation loss: 3.3862575701417255

Epoch: 5| Step: 6
Training loss: 3.671694227598012
Validation loss: 3.384645433191765

Epoch: 5| Step: 7
Training loss: 3.0032383606600295
Validation loss: 3.38434670981808

Epoch: 5| Step: 8
Training loss: 4.04595111920354
Validation loss: 3.3828184293581165

Epoch: 5| Step: 9
Training loss: 3.2627686780886425
Validation loss: 3.3830210095171265

Epoch: 5| Step: 10
Training loss: 4.020989660409623
Validation loss: 3.382770606181801

Epoch: 65| Step: 0
Training loss: 4.224970773449092
Validation loss: 3.3823321723137743

Epoch: 5| Step: 1
Training loss: 2.5907477962900853
Validation loss: 3.381810146623122

Epoch: 5| Step: 2
Training loss: 3.2918240151441402
Validation loss: 3.381073676551182

Epoch: 5| Step: 3
Training loss: 3.3810513252936607
Validation loss: 3.3811119215924568

Epoch: 5| Step: 4
Training loss: 2.89148101503834
Validation loss: 3.3806314721006845

Epoch: 5| Step: 5
Training loss: 3.890515184193155
Validation loss: 3.379815680044807

Epoch: 5| Step: 6
Training loss: 3.6750497931396335
Validation loss: 3.380887743680985

Epoch: 5| Step: 7
Training loss: 4.366826296696215
Validation loss: 3.3786563308325537

Epoch: 5| Step: 8
Training loss: 3.7249967536656103
Validation loss: 3.3798666397273207

Epoch: 5| Step: 9
Training loss: 3.528850449075925
Validation loss: 3.38049702476738

Epoch: 5| Step: 10
Training loss: 3.802859264609431
Validation loss: 3.3788388341024804

Epoch: 66| Step: 0
Training loss: 3.957399733352209
Validation loss: 3.3785499761913877

Epoch: 5| Step: 1
Training loss: 2.7640033860082354
Validation loss: 3.380126115327507

Epoch: 5| Step: 2
Training loss: 4.346259181419156
Validation loss: 3.380122496024781

Epoch: 5| Step: 3
Training loss: 3.898274450772095
Validation loss: 3.378874022494742

Epoch: 5| Step: 4
Training loss: 4.1849181913084434
Validation loss: 3.378277090016773

Epoch: 5| Step: 5
Training loss: 3.3835733099958407
Validation loss: 3.3779361308810794

Epoch: 5| Step: 6
Training loss: 3.6900204595396606
Validation loss: 3.3764835835632905

Epoch: 5| Step: 7
Training loss: 3.353524440782676
Validation loss: 3.376199704278325

Epoch: 5| Step: 8
Training loss: 3.4149291730157256
Validation loss: 3.3763514676165878

Epoch: 5| Step: 9
Training loss: 3.04293208167493
Validation loss: 3.376046653834214

Epoch: 5| Step: 10
Training loss: 3.2559930857460784
Validation loss: 3.3748270094520443

Epoch: 67| Step: 0
Training loss: 3.541460382774489
Validation loss: 3.374299498144218

Epoch: 5| Step: 1
Training loss: 3.6125960076585897
Validation loss: 3.374375691585101

Epoch: 5| Step: 2
Training loss: 3.633086294705959
Validation loss: 3.37358095180323

Epoch: 5| Step: 3
Training loss: 3.7407849576398
Validation loss: 3.3733882716914114

Epoch: 5| Step: 4
Training loss: 3.8719937137757654
Validation loss: 3.372129307940382

Epoch: 5| Step: 5
Training loss: 3.4671231140512275
Validation loss: 3.3721745862408157

Epoch: 5| Step: 6
Training loss: 3.361467995800643
Validation loss: 3.3716757904546166

Epoch: 5| Step: 7
Training loss: 2.738489771588614
Validation loss: 3.370761231584567

Epoch: 5| Step: 8
Training loss: 3.458660263480105
Validation loss: 3.371420743988991

Epoch: 5| Step: 9
Training loss: 4.311080477847127
Validation loss: 3.371067403917743

Epoch: 5| Step: 10
Training loss: 3.725744257571519
Validation loss: 3.3721487974959143

Epoch: 68| Step: 0
Training loss: 3.2405790084768284
Validation loss: 3.3712226119547486

Epoch: 5| Step: 1
Training loss: 3.3126805094353386
Validation loss: 3.3753713253877

Epoch: 5| Step: 2
Training loss: 3.421605487121078
Validation loss: 3.372144009504294

Epoch: 5| Step: 3
Training loss: 3.6805439658952173
Validation loss: 3.369738571515307

Epoch: 5| Step: 4
Training loss: 3.565468204136656
Validation loss: 3.368619663122625

Epoch: 5| Step: 5
Training loss: 3.8465853522403886
Validation loss: 3.3684175137346486

Epoch: 5| Step: 6
Training loss: 3.4895472434535737
Validation loss: 3.368178937404363

Epoch: 5| Step: 7
Training loss: 3.160697598293979
Validation loss: 3.36635677091567

Epoch: 5| Step: 8
Training loss: 3.2395918049757766
Validation loss: 3.3660206161971336

Epoch: 5| Step: 9
Training loss: 4.403765904800925
Validation loss: 3.3663898082078783

Epoch: 5| Step: 10
Training loss: 4.0908640232878986
Validation loss: 3.3650571813977033

Epoch: 69| Step: 0
Training loss: 4.060675813023207
Validation loss: 3.364569962119158

Epoch: 5| Step: 1
Training loss: 3.6907290528799943
Validation loss: 3.3638027033176017

Epoch: 5| Step: 2
Training loss: 3.149591050017229
Validation loss: 3.3648678081434116

Epoch: 5| Step: 3
Training loss: 2.920650776496901
Validation loss: 3.3633273593422643

Epoch: 5| Step: 4
Training loss: 3.802084155496308
Validation loss: 3.363009256655861

Epoch: 5| Step: 5
Training loss: 3.522059811986995
Validation loss: 3.36327053130912

Epoch: 5| Step: 6
Training loss: 3.6902172615992646
Validation loss: 3.3625805163057447

Epoch: 5| Step: 7
Training loss: 4.036186094230029
Validation loss: 3.3626407593066614

Epoch: 5| Step: 8
Training loss: 3.439576510155555
Validation loss: 3.3613303062835778

Epoch: 5| Step: 9
Training loss: 3.609211839563347
Validation loss: 3.361519377005848

Epoch: 5| Step: 10
Training loss: 3.4466959625809293
Validation loss: 3.3633336020284723

Epoch: 70| Step: 0
Training loss: 3.182081965869548
Validation loss: 3.3607353033800234

Epoch: 5| Step: 1
Training loss: 3.613250369378176
Validation loss: 3.3608881052275303

Epoch: 5| Step: 2
Training loss: 3.2080434858176368
Validation loss: 3.3631272930256646

Epoch: 5| Step: 3
Training loss: 4.2287591947748195
Validation loss: 3.3679152141719033

Epoch: 5| Step: 4
Training loss: 4.042678837356096
Validation loss: 3.3636102549652844

Epoch: 5| Step: 5
Training loss: 3.717539357821666
Validation loss: 3.360766293617236

Epoch: 5| Step: 6
Training loss: 2.6859649887586774
Validation loss: 3.360261049821308

Epoch: 5| Step: 7
Training loss: 3.7042398183069576
Validation loss: 3.359621228683101

Epoch: 5| Step: 8
Training loss: 4.416793005713791
Validation loss: 3.357508282995928

Epoch: 5| Step: 9
Training loss: 2.8912047758412354
Validation loss: 3.3575646297926927

Epoch: 5| Step: 10
Training loss: 3.3542223781595037
Validation loss: 3.3573707762274125

Epoch: 71| Step: 0
Training loss: 2.98704433397789
Validation loss: 3.356628371158942

Epoch: 5| Step: 1
Training loss: 3.1274561575691338
Validation loss: 3.35554922617326

Epoch: 5| Step: 2
Training loss: 3.4392410030947476
Validation loss: 3.356910708698264

Epoch: 5| Step: 3
Training loss: 3.5234039372708574
Validation loss: 3.3558161190661187

Epoch: 5| Step: 4
Training loss: 3.2425948656920887
Validation loss: 3.355872453023129

Epoch: 5| Step: 5
Training loss: 4.159822463135258
Validation loss: 3.3558360838027714

Epoch: 5| Step: 6
Training loss: 3.421472813211856
Validation loss: 3.355030978497353

Epoch: 5| Step: 7
Training loss: 3.803126710187642
Validation loss: 3.355490735328056

Epoch: 5| Step: 8
Training loss: 3.7872663822453063
Validation loss: 3.3547389977102267

Epoch: 5| Step: 9
Training loss: 4.2113994847458
Validation loss: 3.3615795947909577

Epoch: 5| Step: 10
Training loss: 3.5446038726167317
Validation loss: 3.3560061894813344

Epoch: 72| Step: 0
Training loss: 4.120225397259081
Validation loss: 3.3535126573509824

Epoch: 5| Step: 1
Training loss: 3.6827685502820144
Validation loss: 3.3519952713929126

Epoch: 5| Step: 2
Training loss: 3.380184289095355
Validation loss: 3.3511528936871495

Epoch: 5| Step: 3
Training loss: 3.055902029873753
Validation loss: 3.350435229114261

Epoch: 5| Step: 4
Training loss: 3.5008366810880176
Validation loss: 3.35248097183852

Epoch: 5| Step: 5
Training loss: 3.333448996126659
Validation loss: 3.351233548469387

Epoch: 5| Step: 6
Training loss: 3.97206253821552
Validation loss: 3.3504232618895857

Epoch: 5| Step: 7
Training loss: 2.978758955224487
Validation loss: 3.3483783169445425

Epoch: 5| Step: 8
Training loss: 3.926756112440567
Validation loss: 3.351402723509803

Epoch: 5| Step: 9
Training loss: 3.70185463277098
Validation loss: 3.348072627214142

Epoch: 5| Step: 10
Training loss: 3.608642503797632
Validation loss: 3.3505619183890776

Epoch: 73| Step: 0
Training loss: 3.7861551043562867
Validation loss: 3.348302000491652

Epoch: 5| Step: 1
Training loss: 3.196859941046216
Validation loss: 3.350237840961931

Epoch: 5| Step: 2
Training loss: 3.5843407892857777
Validation loss: 3.347696233796278

Epoch: 5| Step: 3
Training loss: 3.033355296408261
Validation loss: 3.3477829847087293

Epoch: 5| Step: 4
Training loss: 4.38753609927724
Validation loss: 3.3473807277385936

Epoch: 5| Step: 5
Training loss: 3.6907724633662764
Validation loss: 3.347732024448574

Epoch: 5| Step: 6
Training loss: 3.1818438442235717
Validation loss: 3.346219521439948

Epoch: 5| Step: 7
Training loss: 3.9783707200461604
Validation loss: 3.3458945514338465

Epoch: 5| Step: 8
Training loss: 3.394783950021235
Validation loss: 3.344788299750058

Epoch: 5| Step: 9
Training loss: 3.4112038243216856
Validation loss: 3.344097505425168

Epoch: 5| Step: 10
Training loss: 3.5012832741346225
Validation loss: 3.34421408584481

Epoch: 74| Step: 0
Training loss: 4.001780590473085
Validation loss: 3.3433119163243936

Epoch: 5| Step: 1
Training loss: 3.161567514326405
Validation loss: 3.3488260878837024

Epoch: 5| Step: 2
Training loss: 3.3406942790371
Validation loss: 3.3548476301736057

Epoch: 5| Step: 3
Training loss: 3.673932217507935
Validation loss: 3.343601210079035

Epoch: 5| Step: 4
Training loss: 3.774548732235291
Validation loss: 3.342707469436977

Epoch: 5| Step: 5
Training loss: 3.592144682215452
Validation loss: 3.3416365855469032

Epoch: 5| Step: 6
Training loss: 4.243932319511325
Validation loss: 3.341514024574483

Epoch: 5| Step: 7
Training loss: 3.2961856067025423
Validation loss: 3.340433108090785

Epoch: 5| Step: 8
Training loss: 3.3539245391709582
Validation loss: 3.3401663813819797

Epoch: 5| Step: 9
Training loss: 3.596368383130429
Validation loss: 3.3408233957856472

Epoch: 5| Step: 10
Training loss: 3.0452529110664024
Validation loss: 3.34029888474184

Epoch: 75| Step: 0
Training loss: 3.3355009342741826
Validation loss: 3.3396145588279875

Epoch: 5| Step: 1
Training loss: 3.4166458098232417
Validation loss: 3.338790430974161

Epoch: 5| Step: 2
Training loss: 3.152117450442911
Validation loss: 3.338275092430216

Epoch: 5| Step: 3
Training loss: 4.2439725432662785
Validation loss: 3.337989888361479

Epoch: 5| Step: 4
Training loss: 3.2038632914396294
Validation loss: 3.3373398826025564

Epoch: 5| Step: 5
Training loss: 3.2110068506329927
Validation loss: 3.3363002821816212

Epoch: 5| Step: 6
Training loss: 3.7404850091448965
Validation loss: 3.3360186217772374

Epoch: 5| Step: 7
Training loss: 4.118477259217584
Validation loss: 3.337988000569522

Epoch: 5| Step: 8
Training loss: 3.481087814744466
Validation loss: 3.3352795016052283

Epoch: 5| Step: 9
Training loss: 3.926308121128057
Validation loss: 3.336192667945346

Epoch: 5| Step: 10
Training loss: 3.1500447527416022
Validation loss: 3.3354579281783345

Epoch: 76| Step: 0
Training loss: 3.484756790935025
Validation loss: 3.3356668477242266

Epoch: 5| Step: 1
Training loss: 3.8389300387566667
Validation loss: 3.334930074913477

Epoch: 5| Step: 2
Training loss: 3.9566182620508434
Validation loss: 3.3332554582502536

Epoch: 5| Step: 3
Training loss: 3.7729049527965732
Validation loss: 3.332675814126255

Epoch: 5| Step: 4
Training loss: 3.0526178475640546
Validation loss: 3.3340319706325934

Epoch: 5| Step: 5
Training loss: 4.276399858397408
Validation loss: 3.3318016229810983

Epoch: 5| Step: 6
Training loss: 3.370171094677162
Validation loss: 3.3330648826870712

Epoch: 5| Step: 7
Training loss: 3.3401861004178803
Validation loss: 3.331827887139188

Epoch: 5| Step: 8
Training loss: 2.7029634107681093
Validation loss: 3.3315304792675833

Epoch: 5| Step: 9
Training loss: 3.253280597816967
Validation loss: 3.330665658136249

Epoch: 5| Step: 10
Training loss: 3.921659182503418
Validation loss: 3.3333098846554208

Epoch: 77| Step: 0
Training loss: 3.600125967576951
Validation loss: 3.3309151527802823

Epoch: 5| Step: 1
Training loss: 2.8013911095364903
Validation loss: 3.3297024846125356

Epoch: 5| Step: 2
Training loss: 3.693839491326485
Validation loss: 3.3298222536701103

Epoch: 5| Step: 3
Training loss: 3.5308862009262776
Validation loss: 3.329205532623065

Epoch: 5| Step: 4
Training loss: 3.3512230192106442
Validation loss: 3.327252340751763

Epoch: 5| Step: 5
Training loss: 3.853327410626287
Validation loss: 3.327322421412354

Epoch: 5| Step: 6
Training loss: 4.240000011516067
Validation loss: 3.328148501641202

Epoch: 5| Step: 7
Training loss: 3.5430620174896506
Validation loss: 3.327055408011973

Epoch: 5| Step: 8
Training loss: 3.822375655113415
Validation loss: 3.327310841054059

Epoch: 5| Step: 9
Training loss: 3.1210433325675964
Validation loss: 3.3269188433408803

Epoch: 5| Step: 10
Training loss: 3.386732829591552
Validation loss: 3.326988582733757

Epoch: 78| Step: 0
Training loss: 3.3986824736598584
Validation loss: 3.324804035363974

Epoch: 5| Step: 1
Training loss: 3.8441565073803723
Validation loss: 3.3261553393292727

Epoch: 5| Step: 2
Training loss: 3.619363151086915
Validation loss: 3.3250256521595687

Epoch: 5| Step: 3
Training loss: 3.9492666843421924
Validation loss: 3.32522864155855

Epoch: 5| Step: 4
Training loss: 3.954004966288927
Validation loss: 3.3234758809503933

Epoch: 5| Step: 5
Training loss: 3.519621209657746
Validation loss: 3.3309168660219366

Epoch: 5| Step: 6
Training loss: 3.7599497722760957
Validation loss: 3.33234033304057

Epoch: 5| Step: 7
Training loss: 3.40298277222305
Validation loss: 3.3285103982589677

Epoch: 5| Step: 8
Training loss: 3.6410532687176724
Validation loss: 3.330050566010759

Epoch: 5| Step: 9
Training loss: 2.6971309995650374
Validation loss: 3.3222195816107285

Epoch: 5| Step: 10
Training loss: 3.060282157156214
Validation loss: 3.321373549999381

Epoch: 79| Step: 0
Training loss: 3.548020366975801
Validation loss: 3.3215772349373096

Epoch: 5| Step: 1
Training loss: 4.067538614025307
Validation loss: 3.3206903088994815

Epoch: 5| Step: 2
Training loss: 3.789146689826606
Validation loss: 3.3199786467766788

Epoch: 5| Step: 3
Training loss: 2.829215498115658
Validation loss: 3.319582221487011

Epoch: 5| Step: 4
Training loss: 3.3025316642034497
Validation loss: 3.3198632570352626

Epoch: 5| Step: 5
Training loss: 3.1920404446078385
Validation loss: 3.319785755317632

Epoch: 5| Step: 6
Training loss: 3.1124159161956784
Validation loss: 3.319841879029493

Epoch: 5| Step: 7
Training loss: 3.685234149548643
Validation loss: 3.320160826681819

Epoch: 5| Step: 8
Training loss: 3.346271882981349
Validation loss: 3.322909233482786

Epoch: 5| Step: 9
Training loss: 4.445868968493085
Validation loss: 3.3185242388722656

Epoch: 5| Step: 10
Training loss: 3.4783633250716655
Validation loss: 3.3173919128638776

Epoch: 80| Step: 0
Training loss: 2.8926936814886424
Validation loss: 3.3162921042463354

Epoch: 5| Step: 1
Training loss: 3.752063183657129
Validation loss: 3.3167379569384625

Epoch: 5| Step: 2
Training loss: 3.4124060481625893
Validation loss: 3.316975986202744

Epoch: 5| Step: 3
Training loss: 3.876993712397749
Validation loss: 3.3172608732526934

Epoch: 5| Step: 4
Training loss: 2.9642959108686133
Validation loss: 3.316731189065752

Epoch: 5| Step: 5
Training loss: 3.2321973463371547
Validation loss: 3.3168463666224386

Epoch: 5| Step: 6
Training loss: 3.7714365833164343
Validation loss: 3.3161695961107007

Epoch: 5| Step: 7
Training loss: 3.5457798279529245
Validation loss: 3.3152795716592838

Epoch: 5| Step: 8
Training loss: 3.403347073289695
Validation loss: 3.315003478189883

Epoch: 5| Step: 9
Training loss: 3.9386963010933065
Validation loss: 3.3146410612816917

Epoch: 5| Step: 10
Training loss: 4.1436908240142065
Validation loss: 3.31433017528849

Epoch: 81| Step: 0
Training loss: 3.758963743627134
Validation loss: 3.313693637364008

Epoch: 5| Step: 1
Training loss: 3.066946732821242
Validation loss: 3.3132429568658126

Epoch: 5| Step: 2
Training loss: 3.029195187384987
Validation loss: 3.31145162742198

Epoch: 5| Step: 3
Training loss: 3.9634156910964675
Validation loss: 3.3112557431520777

Epoch: 5| Step: 4
Training loss: 3.5849016143620682
Validation loss: 3.3110942423276715

Epoch: 5| Step: 5
Training loss: 3.708193887096099
Validation loss: 3.310981188689424

Epoch: 5| Step: 6
Training loss: 3.588815768126543
Validation loss: 3.3105246531492427

Epoch: 5| Step: 7
Training loss: 4.389287018457042
Validation loss: 3.310308868247946

Epoch: 5| Step: 8
Training loss: 3.3330976561836194
Validation loss: 3.3098597337199918

Epoch: 5| Step: 9
Training loss: 2.6434165149058244
Validation loss: 3.3101733289136384

Epoch: 5| Step: 10
Training loss: 3.6172258609855046
Validation loss: 3.3099478829212927

Epoch: 82| Step: 0
Training loss: 3.4778097251451183
Validation loss: 3.3092148182374617

Epoch: 5| Step: 1
Training loss: 4.019540977651616
Validation loss: 3.3085021328474524

Epoch: 5| Step: 2
Training loss: 3.8194220817758966
Validation loss: 3.3079253091224636

Epoch: 5| Step: 3
Training loss: 3.6969923270045038
Validation loss: 3.307670715071944

Epoch: 5| Step: 4
Training loss: 3.6016014245964634
Validation loss: 3.3090699497221037

Epoch: 5| Step: 5
Training loss: 3.93610696522427
Validation loss: 3.30653904664944

Epoch: 5| Step: 6
Training loss: 2.930150028592986
Validation loss: 3.3053845466790714

Epoch: 5| Step: 7
Training loss: 3.583589204627731
Validation loss: 3.3056373919262674

Epoch: 5| Step: 8
Training loss: 2.9834590125294764
Validation loss: 3.3051098675066855

Epoch: 5| Step: 9
Training loss: 4.058706067231963
Validation loss: 3.305266779745802

Epoch: 5| Step: 10
Training loss: 2.25095304861634
Validation loss: 3.3043336264029537

Epoch: 83| Step: 0
Training loss: 3.543501001184838
Validation loss: 3.3038962615589313

Epoch: 5| Step: 1
Training loss: 3.1665747947081493
Validation loss: 3.3029348597180492

Epoch: 5| Step: 2
Training loss: 3.9039677170606892
Validation loss: 3.304308712472417

Epoch: 5| Step: 3
Training loss: 4.082617379046963
Validation loss: 3.3030393585577955

Epoch: 5| Step: 4
Training loss: 3.1174528922014546
Validation loss: 3.3031164351609457

Epoch: 5| Step: 5
Training loss: 3.9408058941771102
Validation loss: 3.3029206402436926

Epoch: 5| Step: 6
Training loss: 3.7259981699768585
Validation loss: 3.3023652046701595

Epoch: 5| Step: 7
Training loss: 3.3669317374043715
Validation loss: 3.3016671237735182

Epoch: 5| Step: 8
Training loss: 3.58887741814018
Validation loss: 3.300991012899145

Epoch: 5| Step: 9
Training loss: 3.5760149335357374
Validation loss: 3.3021344952462717

Epoch: 5| Step: 10
Training loss: 2.4529272109070126
Validation loss: 3.300381431337492

Epoch: 84| Step: 0
Training loss: 3.1971437760742223
Validation loss: 3.299702280274401

Epoch: 5| Step: 1
Training loss: 3.396499256454604
Validation loss: 3.2998516636110033

Epoch: 5| Step: 2
Training loss: 3.3028396237757747
Validation loss: 3.300430830497289

Epoch: 5| Step: 3
Training loss: 3.880359143221578
Validation loss: 3.299224625882901

Epoch: 5| Step: 4
Training loss: 3.3289200813598776
Validation loss: 3.2973132417393294

Epoch: 5| Step: 5
Training loss: 4.257154389363046
Validation loss: 3.298138973612366

Epoch: 5| Step: 6
Training loss: 3.9299748279648687
Validation loss: 3.297537687233474

Epoch: 5| Step: 7
Training loss: 3.1908224405292223
Validation loss: 3.296154771493556

Epoch: 5| Step: 8
Training loss: 3.11865796276355
Validation loss: 3.2959733741107726

Epoch: 5| Step: 9
Training loss: 3.8378839157861204
Validation loss: 3.297383361605501

Epoch: 5| Step: 10
Training loss: 3.1372519832017822
Validation loss: 3.2959780067431277

Epoch: 85| Step: 0
Training loss: 3.2310068773192326
Validation loss: 3.2989574970841753

Epoch: 5| Step: 1
Training loss: 3.19740730395851
Validation loss: 3.2996638825724514

Epoch: 5| Step: 2
Training loss: 4.193636596783726
Validation loss: 3.295117236483634

Epoch: 5| Step: 3
Training loss: 2.9685135596635313
Validation loss: 3.295978330311565

Epoch: 5| Step: 4
Training loss: 3.650969645632858
Validation loss: 3.2958370896694964

Epoch: 5| Step: 5
Training loss: 4.1626642967997745
Validation loss: 3.2949741880987555

Epoch: 5| Step: 6
Training loss: 3.6697681632341856
Validation loss: 3.2953067765312882

Epoch: 5| Step: 7
Training loss: 3.635610114400424
Validation loss: 3.2933883266366997

Epoch: 5| Step: 8
Training loss: 2.488624249686547
Validation loss: 3.2933295148940527

Epoch: 5| Step: 9
Training loss: 3.603212719103451
Validation loss: 3.2925243643966424

Epoch: 5| Step: 10
Training loss: 3.6837408010149817
Validation loss: 3.2915048747697866

Epoch: 86| Step: 0
Training loss: 3.2685198205023327
Validation loss: 3.2902948229352997

Epoch: 5| Step: 1
Training loss: 3.404471957004533
Validation loss: 3.2907250878696925

Epoch: 5| Step: 2
Training loss: 2.9729449699638897
Validation loss: 3.2915089163020332

Epoch: 5| Step: 3
Training loss: 3.204145166716023
Validation loss: 3.290015767070882

Epoch: 5| Step: 4
Training loss: 2.998384994675291
Validation loss: 3.289377196446366

Epoch: 5| Step: 5
Training loss: 3.4973068775141556
Validation loss: 3.2909311776366086

Epoch: 5| Step: 6
Training loss: 3.7101534687802142
Validation loss: 3.290908693236771

Epoch: 5| Step: 7
Training loss: 3.441730462345861
Validation loss: 3.289937646387612

Epoch: 5| Step: 8
Training loss: 4.0188144233725
Validation loss: 3.290362275013046

Epoch: 5| Step: 9
Training loss: 3.972805084171184
Validation loss: 3.28897699386159

Epoch: 5| Step: 10
Training loss: 4.1833147228379195
Validation loss: 3.288757724762323

Epoch: 87| Step: 0
Training loss: 3.4643546084939913
Validation loss: 3.287605180839256

Epoch: 5| Step: 1
Training loss: 3.4302351043024113
Validation loss: 3.2870456403566144

Epoch: 5| Step: 2
Training loss: 2.987004105658658
Validation loss: 3.28698961025144

Epoch: 5| Step: 3
Training loss: 3.689247622403405
Validation loss: 3.2868604643966104

Epoch: 5| Step: 4
Training loss: 3.3977855539354196
Validation loss: 3.2866946331226203

Epoch: 5| Step: 5
Training loss: 3.6786054247212454
Validation loss: 3.2861930090404905

Epoch: 5| Step: 6
Training loss: 3.5764194738238664
Validation loss: 3.286286535310579

Epoch: 5| Step: 7
Training loss: 3.7802992957572723
Validation loss: 3.2853916740295297

Epoch: 5| Step: 8
Training loss: 3.3000033754273694
Validation loss: 3.2840699625430614

Epoch: 5| Step: 9
Training loss: 3.998218139498597
Validation loss: 3.284477664507572

Epoch: 5| Step: 10
Training loss: 3.3120665356591648
Validation loss: 3.283734421639474

Epoch: 88| Step: 0
Training loss: 3.6158548952965925
Validation loss: 3.2826467015219483

Epoch: 5| Step: 1
Training loss: 3.167641807458875
Validation loss: 3.282855917630256

Epoch: 5| Step: 2
Training loss: 4.075237318746181
Validation loss: 3.2820937705208366

Epoch: 5| Step: 3
Training loss: 2.813527068055878
Validation loss: 3.2822327555787028

Epoch: 5| Step: 4
Training loss: 3.1338436874426616
Validation loss: 3.2816014208611066

Epoch: 5| Step: 5
Training loss: 3.696098260225662
Validation loss: 3.2813057359062583

Epoch: 5| Step: 6
Training loss: 3.3234696042797336
Validation loss: 3.2819156641479923

Epoch: 5| Step: 7
Training loss: 2.8108103445066592
Validation loss: 3.2812639336746727

Epoch: 5| Step: 8
Training loss: 3.2769626764168973
Validation loss: 3.278616643587047

Epoch: 5| Step: 9
Training loss: 4.021182715434379
Validation loss: 3.2795114860161863

Epoch: 5| Step: 10
Training loss: 4.5171542102770665
Validation loss: 3.279653964401549

Epoch: 89| Step: 0
Training loss: 3.5949435698387124
Validation loss: 3.2784663927680837

Epoch: 5| Step: 1
Training loss: 3.820612671337832
Validation loss: 3.2782439932777634

Epoch: 5| Step: 2
Training loss: 3.699849414338608
Validation loss: 3.278512679981172

Epoch: 5| Step: 3
Training loss: 2.974364102145833
Validation loss: 3.2790910297254805

Epoch: 5| Step: 4
Training loss: 3.6893209067180077
Validation loss: 3.2777656880897283

Epoch: 5| Step: 5
Training loss: 3.1292540015280164
Validation loss: 3.277390534915984

Epoch: 5| Step: 6
Training loss: 3.630347943825399
Validation loss: 3.278476173551351

Epoch: 5| Step: 7
Training loss: 3.185503165894185
Validation loss: 3.2770300399241195

Epoch: 5| Step: 8
Training loss: 3.536682001980088
Validation loss: 3.2747993499828203

Epoch: 5| Step: 9
Training loss: 3.5637073813211178
Validation loss: 3.27485252780406

Epoch: 5| Step: 10
Training loss: 3.7655790334088257
Validation loss: 3.275249019405924

Epoch: 90| Step: 0
Training loss: 3.6042208511307385
Validation loss: 3.2758078295147994

Epoch: 5| Step: 1
Training loss: 3.1905372958781033
Validation loss: 3.2729924920263676

Epoch: 5| Step: 2
Training loss: 3.672894794805053
Validation loss: 3.2747339681828675

Epoch: 5| Step: 3
Training loss: 3.825997520473891
Validation loss: 3.2730192132130136

Epoch: 5| Step: 4
Training loss: 4.080621065104862
Validation loss: 3.273466895171154

Epoch: 5| Step: 5
Training loss: 3.609223597930502
Validation loss: 3.270877792111633

Epoch: 5| Step: 6
Training loss: 3.8510595770947256
Validation loss: 3.274943700746581

Epoch: 5| Step: 7
Training loss: 3.064570758377993
Validation loss: 3.2724357245090316

Epoch: 5| Step: 8
Training loss: 2.076321500480635
Validation loss: 3.272778043371784

Epoch: 5| Step: 9
Training loss: 3.1714865160034034
Validation loss: 3.2897119825669106

Epoch: 5| Step: 10
Training loss: 4.1303738356050275
Validation loss: 3.2754210217059625

Epoch: 91| Step: 0
Training loss: 4.165068943144575
Validation loss: 3.2755473689826116

Epoch: 5| Step: 1
Training loss: 4.006376429331854
Validation loss: 3.275754058330523

Epoch: 5| Step: 2
Training loss: 3.149139704619569
Validation loss: 3.2747823873835222

Epoch: 5| Step: 3
Training loss: 3.196749562238474
Validation loss: 3.2795447274615515

Epoch: 5| Step: 4
Training loss: 3.604743264589182
Validation loss: 3.2773867708708724

Epoch: 5| Step: 5
Training loss: 3.55758113251185
Validation loss: 3.277744540776069

Epoch: 5| Step: 6
Training loss: 3.0784797270421596
Validation loss: 3.2735823853922645

Epoch: 5| Step: 7
Training loss: 2.758572654675872
Validation loss: 3.27340542611652

Epoch: 5| Step: 8
Training loss: 3.5349153383900105
Validation loss: 3.2694906490311837

Epoch: 5| Step: 9
Training loss: 3.589521092638893
Validation loss: 3.2676132578127772

Epoch: 5| Step: 10
Training loss: 3.7985175704519554
Validation loss: 3.2660192820852534

Epoch: 92| Step: 0
Training loss: 3.8532569980210054
Validation loss: 3.2656072863481915

Epoch: 5| Step: 1
Training loss: 3.5156296115421144
Validation loss: 3.2652874930321274

Epoch: 5| Step: 2
Training loss: 3.313673711162626
Validation loss: 3.265719135723605

Epoch: 5| Step: 3
Training loss: 3.765594608928192
Validation loss: 3.26517977915151

Epoch: 5| Step: 4
Training loss: 3.483363256979973
Validation loss: 3.26493841341733

Epoch: 5| Step: 5
Training loss: 4.0166080919060105
Validation loss: 3.2639130508469902

Epoch: 5| Step: 6
Training loss: 2.9161850304526182
Validation loss: 3.2627987822375633

Epoch: 5| Step: 7
Training loss: 3.2764123040857887
Validation loss: 3.2628038029734867

Epoch: 5| Step: 8
Training loss: 3.4346584713326687
Validation loss: 3.2630819176765993

Epoch: 5| Step: 9
Training loss: 3.2966581878964503
Validation loss: 3.262939230285254

Epoch: 5| Step: 10
Training loss: 3.5365645664684666
Validation loss: 3.2636862906124877

Epoch: 93| Step: 0
Training loss: 3.4157855750867476
Validation loss: 3.261389386394262

Epoch: 5| Step: 1
Training loss: 3.6171529615825415
Validation loss: 3.261419888439325

Epoch: 5| Step: 2
Training loss: 3.2827229418151824
Validation loss: 3.262105940872289

Epoch: 5| Step: 3
Training loss: 3.7176795508732265
Validation loss: 3.2621380661275023

Epoch: 5| Step: 4
Training loss: 3.4468312624718265
Validation loss: 3.2603697414507913

Epoch: 5| Step: 5
Training loss: 3.7649064387516606
Validation loss: 3.2585915765414253

Epoch: 5| Step: 6
Training loss: 3.6193959557294346
Validation loss: 3.26019471185008

Epoch: 5| Step: 7
Training loss: 3.773167318145032
Validation loss: 3.2618008742820286

Epoch: 5| Step: 8
Training loss: 3.296972336620364
Validation loss: 3.261030729364537

Epoch: 5| Step: 9
Training loss: 3.575679426387456
Validation loss: 3.272185710237129

Epoch: 5| Step: 10
Training loss: 2.7810943217051634
Validation loss: 3.2608031790406247

Epoch: 94| Step: 0
Training loss: 2.876764502366364
Validation loss: 3.256601219342922

Epoch: 5| Step: 1
Training loss: 3.2931711806662736
Validation loss: 3.2569109164731067

Epoch: 5| Step: 2
Training loss: 3.919458868473462
Validation loss: 3.257838710654784

Epoch: 5| Step: 3
Training loss: 2.5178699782951655
Validation loss: 3.255579413283033

Epoch: 5| Step: 4
Training loss: 3.7496368232339976
Validation loss: 3.254976433482041

Epoch: 5| Step: 5
Training loss: 3.2549025898082764
Validation loss: 3.2559641831852777

Epoch: 5| Step: 6
Training loss: 3.362241861297653
Validation loss: 3.2546596316995013

Epoch: 5| Step: 7
Training loss: 3.4441666200497676
Validation loss: 3.2565951058366855

Epoch: 5| Step: 8
Training loss: 4.272662606847529
Validation loss: 3.253814199214369

Epoch: 5| Step: 9
Training loss: 3.3662552749020187
Validation loss: 3.254376790737674

Epoch: 5| Step: 10
Training loss: 4.114373593678554
Validation loss: 3.2532958238471092

Epoch: 95| Step: 0
Training loss: 3.844817346765991
Validation loss: 3.254083067436859

Epoch: 5| Step: 1
Training loss: 3.3892625453328766
Validation loss: 3.254218053336527

Epoch: 5| Step: 2
Training loss: 3.996543105768365
Validation loss: 3.2523834120236077

Epoch: 5| Step: 3
Training loss: 3.5563008765686033
Validation loss: 3.2531944128247665

Epoch: 5| Step: 4
Training loss: 3.9953025414943597
Validation loss: 3.2506466988062113

Epoch: 5| Step: 5
Training loss: 3.628912162981256
Validation loss: 3.251640776496682

Epoch: 5| Step: 6
Training loss: 3.1031855797208614
Validation loss: 3.250727482947384

Epoch: 5| Step: 7
Training loss: 2.6821856629001903
Validation loss: 3.250631258470729

Epoch: 5| Step: 8
Training loss: 3.4458018537111306
Validation loss: 3.249738326948591

Epoch: 5| Step: 9
Training loss: 3.465497390695453
Validation loss: 3.24917347339482

Epoch: 5| Step: 10
Training loss: 3.0320952505283154
Validation loss: 3.2488785426696216

Epoch: 96| Step: 0
Training loss: 3.2896037981501225
Validation loss: 3.24732413145629

Epoch: 5| Step: 1
Training loss: 3.396558641232699
Validation loss: 3.24778637306247

Epoch: 5| Step: 2
Training loss: 2.834243142153258
Validation loss: 3.2480529272458063

Epoch: 5| Step: 3
Training loss: 3.165176007286876
Validation loss: 3.2479547639203568

Epoch: 5| Step: 4
Training loss: 3.1568613498946223
Validation loss: 3.251569738000227

Epoch: 5| Step: 5
Training loss: 3.4338998148216877
Validation loss: 3.2539315498401677

Epoch: 5| Step: 6
Training loss: 3.5682671696317905
Validation loss: 3.248804194250206

Epoch: 5| Step: 7
Training loss: 4.192036463134827
Validation loss: 3.2484278887646028

Epoch: 5| Step: 8
Training loss: 3.577064990154166
Validation loss: 3.2463499441256087

Epoch: 5| Step: 9
Training loss: 3.8717042997723223
Validation loss: 3.2472802228339672

Epoch: 5| Step: 10
Training loss: 3.7674616849554585
Validation loss: 3.2481092643679053

Epoch: 97| Step: 0
Training loss: 4.215792148859193
Validation loss: 3.2462297709730117

Epoch: 5| Step: 1
Training loss: 3.328721830196562
Validation loss: 3.245505861309363

Epoch: 5| Step: 2
Training loss: 3.2174343642481085
Validation loss: 3.2455473223572113

Epoch: 5| Step: 3
Training loss: 3.9654655983634757
Validation loss: 3.2443080166295903

Epoch: 5| Step: 4
Training loss: 3.382206463873845
Validation loss: 3.2449506671537565

Epoch: 5| Step: 5
Training loss: 3.5440678852545937
Validation loss: 3.243287249390553

Epoch: 5| Step: 6
Training loss: 2.3643019812711272
Validation loss: 3.243628175753892

Epoch: 5| Step: 7
Training loss: 3.157170076628947
Validation loss: 3.2423625180739775

Epoch: 5| Step: 8
Training loss: 3.982204309706573
Validation loss: 3.243326765083136

Epoch: 5| Step: 9
Training loss: 3.1762983175698825
Validation loss: 3.2422866752747552

Epoch: 5| Step: 10
Training loss: 3.6956927565568405
Validation loss: 3.2432139782508838

Epoch: 98| Step: 0
Training loss: 3.1043243026817775
Validation loss: 3.2443966604450956

Epoch: 5| Step: 1
Training loss: 2.9557960984414207
Validation loss: 3.241612328438963

Epoch: 5| Step: 2
Training loss: 3.530218463221687
Validation loss: 3.244995978788206

Epoch: 5| Step: 3
Training loss: 3.6254728600787347
Validation loss: 3.2459456789335293

Epoch: 5| Step: 4
Training loss: 3.8491540152741073
Validation loss: 3.2447300599620656

Epoch: 5| Step: 5
Training loss: 4.055823606112742
Validation loss: 3.2417423516460717

Epoch: 5| Step: 6
Training loss: 3.4547166565174123
Validation loss: 3.23928320458934

Epoch: 5| Step: 7
Training loss: 3.5001249291058376
Validation loss: 3.2389631360566655

Epoch: 5| Step: 8
Training loss: 3.5218560503472705
Validation loss: 3.2387800600048733

Epoch: 5| Step: 9
Training loss: 2.808690436851711
Validation loss: 3.2387465869707657

Epoch: 5| Step: 10
Training loss: 3.732007668915583
Validation loss: 3.2390205984763827

Epoch: 99| Step: 0
Training loss: 3.933400517768145
Validation loss: 3.2378248613556746

Epoch: 5| Step: 1
Training loss: 2.7450939110984
Validation loss: 3.238875981191425

Epoch: 5| Step: 2
Training loss: 3.4470102707300647
Validation loss: 3.2389358877490912

Epoch: 5| Step: 3
Training loss: 3.4216431142891715
Validation loss: 3.2437286260544274

Epoch: 5| Step: 4
Training loss: 3.5970344461717074
Validation loss: 3.2454588576842873

Epoch: 5| Step: 5
Training loss: 2.9803282778373186
Validation loss: 3.2437263261712515

Epoch: 5| Step: 6
Training loss: 3.368993146681616
Validation loss: 3.237090862681673

Epoch: 5| Step: 7
Training loss: 4.145982723643573
Validation loss: 3.2349494589194325

Epoch: 5| Step: 8
Training loss: 3.8678352815256556
Validation loss: 3.233823390262206

Epoch: 5| Step: 9
Training loss: 3.0099267439941833
Validation loss: 3.233791227894247

Epoch: 5| Step: 10
Training loss: 3.467486589621731
Validation loss: 3.2342059401515906

Epoch: 100| Step: 0
Training loss: 3.776695724492238
Validation loss: 3.2336187871179196

Epoch: 5| Step: 1
Training loss: 2.6755602668785503
Validation loss: 3.2332396818992053

Epoch: 5| Step: 2
Training loss: 3.2309032733763576
Validation loss: 3.230329138516818

Epoch: 5| Step: 3
Training loss: 3.894123021561551
Validation loss: 3.2325691982921905

Epoch: 5| Step: 4
Training loss: 3.3219174085405916
Validation loss: 3.2291135044597694

Epoch: 5| Step: 5
Training loss: 3.228940221578716
Validation loss: 3.2317402555870682

Epoch: 5| Step: 6
Training loss: 3.9889801339634765
Validation loss: 3.23076291731438

Epoch: 5| Step: 7
Training loss: 2.866306928492689
Validation loss: 3.231388775295496

Epoch: 5| Step: 8
Training loss: 3.260868094070766
Validation loss: 3.2312816276612213

Epoch: 5| Step: 9
Training loss: 3.6503887962308155
Validation loss: 3.230479222086131

Epoch: 5| Step: 10
Training loss: 4.123466206544993
Validation loss: 3.230533602426477

Epoch: 101| Step: 0
Training loss: 3.6355976544263813
Validation loss: 3.2299583446392433

Epoch: 5| Step: 1
Training loss: 3.066969432259325
Validation loss: 3.2295533246790002

Epoch: 5| Step: 2
Training loss: 3.7347280423224745
Validation loss: 3.2275313593503028

Epoch: 5| Step: 3
Training loss: 3.33326431838751
Validation loss: 3.2283667095851776

Epoch: 5| Step: 4
Training loss: 2.662081879930691
Validation loss: 3.2279793648841526

Epoch: 5| Step: 5
Training loss: 3.2552247232660303
Validation loss: 3.227323574685119

Epoch: 5| Step: 6
Training loss: 4.162600835088596
Validation loss: 3.22460256720551

Epoch: 5| Step: 7
Training loss: 3.251690204977705
Validation loss: 3.226146965717932

Epoch: 5| Step: 8
Training loss: 3.4995338947013463
Validation loss: 3.226002022444548

Epoch: 5| Step: 9
Training loss: 3.7772367002669758
Validation loss: 3.225164586012413

Epoch: 5| Step: 10
Training loss: 3.5829894470093504
Validation loss: 3.224181019620382

Epoch: 102| Step: 0
Training loss: 2.533537408071115
Validation loss: 3.223734914092932

Epoch: 5| Step: 1
Training loss: 3.50364604141116
Validation loss: 3.2249506510426103

Epoch: 5| Step: 2
Training loss: 3.2120735033776975
Validation loss: 3.222649061804667

Epoch: 5| Step: 3
Training loss: 3.7093619445211092
Validation loss: 3.222375091787396

Epoch: 5| Step: 4
Training loss: 3.4153874181153023
Validation loss: 3.2222731149784734

Epoch: 5| Step: 5
Training loss: 3.1493615245133357
Validation loss: 3.2216373137152505

Epoch: 5| Step: 6
Training loss: 4.187116235257115
Validation loss: 3.221408218252762

Epoch: 5| Step: 7
Training loss: 2.9541813005767343
Validation loss: 3.221598591944032

Epoch: 5| Step: 8
Training loss: 3.868217932083555
Validation loss: 3.220904673967319

Epoch: 5| Step: 9
Training loss: 3.7453913025091428
Validation loss: 3.2207090694319622

Epoch: 5| Step: 10
Training loss: 3.5508639721524773
Validation loss: 3.2197718373722846

Epoch: 103| Step: 0
Training loss: 2.790480223997956
Validation loss: 3.2194085758104105

Epoch: 5| Step: 1
Training loss: 3.512389733155084
Validation loss: 3.2190955399004237

Epoch: 5| Step: 2
Training loss: 3.5758770540424685
Validation loss: 3.219484959947826

Epoch: 5| Step: 3
Training loss: 2.651269169746674
Validation loss: 3.2184724147439776

Epoch: 5| Step: 4
Training loss: 2.8226195644736665
Validation loss: 3.218380534186081

Epoch: 5| Step: 5
Training loss: 3.858102071160339
Validation loss: 3.217382117076616

Epoch: 5| Step: 6
Training loss: 3.31186857143339
Validation loss: 3.217551613912787

Epoch: 5| Step: 7
Training loss: 3.1277761716445163
Validation loss: 3.2171248608287604

Epoch: 5| Step: 8
Training loss: 3.610279977143975
Validation loss: 3.216807726313706

Epoch: 5| Step: 9
Training loss: 4.92662492465109
Validation loss: 3.2164702234393094

Epoch: 5| Step: 10
Training loss: 3.291665684824608
Validation loss: 3.2154528269739635

Epoch: 104| Step: 0
Training loss: 3.785148187555913
Validation loss: 3.2153262805920777

Epoch: 5| Step: 1
Training loss: 3.42683851919423
Validation loss: 3.215503492606572

Epoch: 5| Step: 2
Training loss: 3.4010469788085826
Validation loss: 3.214022307175756

Epoch: 5| Step: 3
Training loss: 3.4564912018588783
Validation loss: 3.2140476402002096

Epoch: 5| Step: 4
Training loss: 3.956182089368886
Validation loss: 3.2138537816459727

Epoch: 5| Step: 5
Training loss: 3.264869858162016
Validation loss: 3.2137410668808597

Epoch: 5| Step: 6
Training loss: 3.4392369823571314
Validation loss: 3.2139693608289366

Epoch: 5| Step: 7
Training loss: 3.229833095241938
Validation loss: 3.2126246405847456

Epoch: 5| Step: 8
Training loss: 3.242712212811551
Validation loss: 3.2131767763163603

Epoch: 5| Step: 9
Training loss: 3.833320548547627
Validation loss: 3.213321955036961

Epoch: 5| Step: 10
Training loss: 2.772884861863781
Validation loss: 3.211953528374123

Epoch: 105| Step: 0
Training loss: 3.6126089429432837
Validation loss: 3.2120668900956066

Epoch: 5| Step: 1
Training loss: 3.856436533566546
Validation loss: 3.2098069984929904

Epoch: 5| Step: 2
Training loss: 3.07421843978318
Validation loss: 3.2106407273292343

Epoch: 5| Step: 3
Training loss: 3.9293537946189234
Validation loss: 3.2108700529130108

Epoch: 5| Step: 4
Training loss: 3.0478398287081885
Validation loss: 3.21019215160718

Epoch: 5| Step: 5
Training loss: 2.9575104621192674
Validation loss: 3.208711206892344

Epoch: 5| Step: 6
Training loss: 3.7169146456479503
Validation loss: 3.209875453479826

Epoch: 5| Step: 7
Training loss: 3.127676618606632
Validation loss: 3.208131452733707

Epoch: 5| Step: 8
Training loss: 3.7115143980034504
Validation loss: 3.2082939710201406

Epoch: 5| Step: 9
Training loss: 3.3008999955526748
Validation loss: 3.2073916723493907

Epoch: 5| Step: 10
Training loss: 3.49915099064537
Validation loss: 3.2063698616899887

Epoch: 106| Step: 0
Training loss: 3.2516753940149057
Validation loss: 3.2060969633811016

Epoch: 5| Step: 1
Training loss: 3.39829452038487
Validation loss: 3.208697554188329

Epoch: 5| Step: 2
Training loss: 3.778118633962211
Validation loss: 3.2136221433328482

Epoch: 5| Step: 3
Training loss: 3.9189457991994465
Validation loss: 3.2102576164927648

Epoch: 5| Step: 4
Training loss: 2.814591117827415
Validation loss: 3.2118781959118654

Epoch: 5| Step: 5
Training loss: 3.4785215194626504
Validation loss: 3.20854324774918

Epoch: 5| Step: 6
Training loss: 3.4920719818876256
Validation loss: 3.2113674973612

Epoch: 5| Step: 7
Training loss: 3.4364632170057483
Validation loss: 3.206836179855169

Epoch: 5| Step: 8
Training loss: 3.9468708246711883
Validation loss: 3.2018812564641093

Epoch: 5| Step: 9
Training loss: 2.986776134948492
Validation loss: 3.202314178264853

Epoch: 5| Step: 10
Training loss: 3.2603297765364196
Validation loss: 3.2034548625877877

Epoch: 107| Step: 0
Training loss: 2.6904079761771427
Validation loss: 3.201860131596496

Epoch: 5| Step: 1
Training loss: 3.5626405387061193
Validation loss: 3.20280344079595

Epoch: 5| Step: 2
Training loss: 2.9235968590693813
Validation loss: 3.201837813579723

Epoch: 5| Step: 3
Training loss: 3.3740822285941614
Validation loss: 3.2027042603807816

Epoch: 5| Step: 4
Training loss: 4.4619614049045095
Validation loss: 3.202154531662819

Epoch: 5| Step: 5
Training loss: 2.994405457292578
Validation loss: 3.202935479672889

Epoch: 5| Step: 6
Training loss: 3.8075255162566934
Validation loss: 3.202591204441119

Epoch: 5| Step: 7
Training loss: 3.0636155568464147
Validation loss: 3.201885445551073

Epoch: 5| Step: 8
Training loss: 4.011915103672093
Validation loss: 3.2018654592653806

Epoch: 5| Step: 9
Training loss: 2.8481481726387874
Validation loss: 3.201444310679074

Epoch: 5| Step: 10
Training loss: 3.7987116386382094
Validation loss: 3.200933087923241

Epoch: 108| Step: 0
Training loss: 3.1459605883865804
Validation loss: 3.200177483417913

Epoch: 5| Step: 1
Training loss: 3.4175312219964153
Validation loss: 3.200529496482845

Epoch: 5| Step: 2
Training loss: 3.821197095310701
Validation loss: 3.1992422418018465

Epoch: 5| Step: 3
Training loss: 3.461573419638934
Validation loss: 3.199191910028636

Epoch: 5| Step: 4
Training loss: 2.6623549372596216
Validation loss: 3.1979429476329697

Epoch: 5| Step: 5
Training loss: 3.692258060409072
Validation loss: 3.1969574263260068

Epoch: 5| Step: 6
Training loss: 3.5947829379153813
Validation loss: 3.1963348265586773

Epoch: 5| Step: 7
Training loss: 3.228937711084782
Validation loss: 3.196446483684861

Epoch: 5| Step: 8
Training loss: 3.215401694919685
Validation loss: 3.1962362827926807

Epoch: 5| Step: 9
Training loss: 3.79944012181503
Validation loss: 3.1942252515648915

Epoch: 5| Step: 10
Training loss: 3.703545011370203
Validation loss: 3.194535127850378

Epoch: 109| Step: 0
Training loss: 2.607621294603677
Validation loss: 3.195457516381738

Epoch: 5| Step: 1
Training loss: 3.4962856474481954
Validation loss: 3.2027238067842454

Epoch: 5| Step: 2
Training loss: 2.8514031352621316
Validation loss: 3.204410400512538

Epoch: 5| Step: 3
Training loss: 3.6795330298654876
Validation loss: 3.202577586484774

Epoch: 5| Step: 4
Training loss: 3.6102478821415867
Validation loss: 3.2041202994718763

Epoch: 5| Step: 5
Training loss: 3.746271950597291
Validation loss: 3.1968716828046735

Epoch: 5| Step: 6
Training loss: 3.615963294079244
Validation loss: 3.192318061982003

Epoch: 5| Step: 7
Training loss: 3.8207382245777466
Validation loss: 3.1947147787046037

Epoch: 5| Step: 8
Training loss: 3.178752789903047
Validation loss: 3.191722068272585

Epoch: 5| Step: 9
Training loss: 3.5549218404469896
Validation loss: 3.191534292651993

Epoch: 5| Step: 10
Training loss: 3.5162797784341064
Validation loss: 3.1912278275732375

Epoch: 110| Step: 0
Training loss: 2.6721933632515196
Validation loss: 3.1909799000200616

Epoch: 5| Step: 1
Training loss: 3.4119348246620564
Validation loss: 3.1920846593140384

Epoch: 5| Step: 2
Training loss: 4.232164094307141
Validation loss: 3.1900246273703474

Epoch: 5| Step: 3
Training loss: 3.1691510008843458
Validation loss: 3.190714904438344

Epoch: 5| Step: 4
Training loss: 3.2345433582956242
Validation loss: 3.192371107232617

Epoch: 5| Step: 5
Training loss: 4.029979653508245
Validation loss: 3.1929837475618275

Epoch: 5| Step: 6
Training loss: 3.4138212838931414
Validation loss: 3.193376155158286

Epoch: 5| Step: 7
Training loss: 3.9105191514912296
Validation loss: 3.191928002067043

Epoch: 5| Step: 8
Training loss: 3.580754409238677
Validation loss: 3.1912693431057506

Epoch: 5| Step: 9
Training loss: 2.9011076686252193
Validation loss: 3.1901826935830933

Epoch: 5| Step: 10
Training loss: 2.776115220880519
Validation loss: 3.1894317924243705

Epoch: 111| Step: 0
Training loss: 4.070994490235324
Validation loss: 3.1889950718275144

Epoch: 5| Step: 1
Training loss: 2.864536650306165
Validation loss: 3.1888946379213765

Epoch: 5| Step: 2
Training loss: 3.2559509081408375
Validation loss: 3.187664995260215

Epoch: 5| Step: 3
Training loss: 3.1652314463958127
Validation loss: 3.1884757279135525

Epoch: 5| Step: 4
Training loss: 3.492350393161563
Validation loss: 3.1874374159914827

Epoch: 5| Step: 5
Training loss: 3.8990718959882553
Validation loss: 3.189865235285071

Epoch: 5| Step: 6
Training loss: 2.8725904235684467
Validation loss: 3.1888438011499614

Epoch: 5| Step: 7
Training loss: 3.576814769749019
Validation loss: 3.1866519337859005

Epoch: 5| Step: 8
Training loss: 3.6576753104195343
Validation loss: 3.187812978011637

Epoch: 5| Step: 9
Training loss: 3.6692726815703884
Validation loss: 3.1871526562265955

Epoch: 5| Step: 10
Training loss: 2.928716473194168
Validation loss: 3.186908695227908

Epoch: 112| Step: 0
Training loss: 3.598306437667636
Validation loss: 3.1839155583964565

Epoch: 5| Step: 1
Training loss: 3.356075351937632
Validation loss: 3.184095679598462

Epoch: 5| Step: 2
Training loss: 3.642499842071006
Validation loss: 3.1848780178802376

Epoch: 5| Step: 3
Training loss: 2.360056999617355
Validation loss: 3.183623026125573

Epoch: 5| Step: 4
Training loss: 3.2987603315543583
Validation loss: 3.1817335117252217

Epoch: 5| Step: 5
Training loss: 3.704927544959998
Validation loss: 3.1821464976870586

Epoch: 5| Step: 6
Training loss: 3.884946424784994
Validation loss: 3.1808495549931055

Epoch: 5| Step: 7
Training loss: 3.681834248680054
Validation loss: 3.1802022702255863

Epoch: 5| Step: 8
Training loss: 3.1143914783462128
Validation loss: 3.179302141329735

Epoch: 5| Step: 9
Training loss: 3.6422767657678277
Validation loss: 3.179030527372754

Epoch: 5| Step: 10
Training loss: 3.142586773848027
Validation loss: 3.1807312893036492

Epoch: 113| Step: 0
Training loss: 3.5929074833990837
Validation loss: 3.1787302902925734

Epoch: 5| Step: 1
Training loss: 3.3269958013216248
Validation loss: 3.1781253622189576

Epoch: 5| Step: 2
Training loss: 3.567725782514165
Validation loss: 3.1777154759930264

Epoch: 5| Step: 3
Training loss: 4.057249696618142
Validation loss: 3.176766387660662

Epoch: 5| Step: 4
Training loss: 3.3485566289361723
Validation loss: 3.1790749351175918

Epoch: 5| Step: 5
Training loss: 3.3299375084864287
Validation loss: 3.176524780547279

Epoch: 5| Step: 6
Training loss: 3.044957266571901
Validation loss: 3.1779476373320437

Epoch: 5| Step: 7
Training loss: 3.3130047971332064
Validation loss: 3.177805432840562

Epoch: 5| Step: 8
Training loss: 3.1319164792711
Validation loss: 3.177024619401999

Epoch: 5| Step: 9
Training loss: 2.8233649729547565
Validation loss: 3.1775746665430593

Epoch: 5| Step: 10
Training loss: 4.058932102113845
Validation loss: 3.1765880169696117

Epoch: 114| Step: 0
Training loss: 3.2220778067516047
Validation loss: 3.175502994218162

Epoch: 5| Step: 1
Training loss: 3.260250944530724
Validation loss: 3.1745505148733733

Epoch: 5| Step: 2
Training loss: 3.6454033007638165
Validation loss: 3.175754531618597

Epoch: 5| Step: 3
Training loss: 3.9510458804985658
Validation loss: 3.175718132325907

Epoch: 5| Step: 4
Training loss: 3.773307087226233
Validation loss: 3.1736189140232933

Epoch: 5| Step: 5
Training loss: 3.7533882093285738
Validation loss: 3.172538879805859

Epoch: 5| Step: 6
Training loss: 3.4728829446096294
Validation loss: 3.179184116438261

Epoch: 5| Step: 7
Training loss: 3.5110358230818943
Validation loss: 3.172841451264287

Epoch: 5| Step: 8
Training loss: 3.201828708258199
Validation loss: 3.170447222532331

Epoch: 5| Step: 9
Training loss: 2.8642414975669
Validation loss: 3.171212969094764

Epoch: 5| Step: 10
Training loss: 2.6532354864293057
Validation loss: 3.1696211309970304

Epoch: 115| Step: 0
Training loss: 3.1956391482354296
Validation loss: 3.1690807666564353

Epoch: 5| Step: 1
Training loss: 3.127396846933246
Validation loss: 3.168817696832513

Epoch: 5| Step: 2
Training loss: 2.868318339930582
Validation loss: 3.169057361912215

Epoch: 5| Step: 3
Training loss: 3.7165223189122187
Validation loss: 3.168356937097999

Epoch: 5| Step: 4
Training loss: 3.690950880271062
Validation loss: 3.170101217587971

Epoch: 5| Step: 5
Training loss: 3.756149717188735
Validation loss: 3.1691705689880747

Epoch: 5| Step: 6
Training loss: 3.3007139300642394
Validation loss: 3.1685360721350935

Epoch: 5| Step: 7
Training loss: 3.9334525241142098
Validation loss: 3.1698072527222885

Epoch: 5| Step: 8
Training loss: 2.6951330152818533
Validation loss: 3.169259590605362

Epoch: 5| Step: 9
Training loss: 3.6438030729796256
Validation loss: 3.170125151594055

Epoch: 5| Step: 10
Training loss: 3.4655536668348397
Validation loss: 3.1700381776759565

Epoch: 116| Step: 0
Training loss: 3.150711790530404
Validation loss: 3.168934722821517

Epoch: 5| Step: 1
Training loss: 4.29399339632931
Validation loss: 3.170536355466065

Epoch: 5| Step: 2
Training loss: 3.3600917317720436
Validation loss: 3.1691924844736694

Epoch: 5| Step: 3
Training loss: 3.5994558399923697
Validation loss: 3.167306877136007

Epoch: 5| Step: 4
Training loss: 2.744041403066055
Validation loss: 3.165687193130693

Epoch: 5| Step: 5
Training loss: 3.215263478352823
Validation loss: 3.166416534514565

Epoch: 5| Step: 6
Training loss: 3.303565012804083
Validation loss: 3.1657561802381244

Epoch: 5| Step: 7
Training loss: 3.0447627644445547
Validation loss: 3.163052614954117

Epoch: 5| Step: 8
Training loss: 4.168405297253131
Validation loss: 3.1637234332815365

Epoch: 5| Step: 9
Training loss: 3.1586027535407633
Validation loss: 3.162461364657956

Epoch: 5| Step: 10
Training loss: 3.1962590762514123
Validation loss: 3.1629066137468564

Epoch: 117| Step: 0
Training loss: 3.2332682167129367
Validation loss: 3.163995131313841

Epoch: 5| Step: 1
Training loss: 3.4360834150569586
Validation loss: 3.161847567295601

Epoch: 5| Step: 2
Training loss: 3.2406371304938855
Validation loss: 3.1628672053799876

Epoch: 5| Step: 3
Training loss: 3.8512332922583288
Validation loss: 3.1697941660102433

Epoch: 5| Step: 4
Training loss: 3.6879472622938154
Validation loss: 3.171900986470483

Epoch: 5| Step: 5
Training loss: 4.138973036101963
Validation loss: 3.167162163983873

Epoch: 5| Step: 6
Training loss: 2.90770217546831
Validation loss: 3.163291255608791

Epoch: 5| Step: 7
Training loss: 3.714503837301049
Validation loss: 3.1607138624218063

Epoch: 5| Step: 8
Training loss: 3.325892456288739
Validation loss: 3.161251342655336

Epoch: 5| Step: 9
Training loss: 2.6005006748250663
Validation loss: 3.160084636292608

Epoch: 5| Step: 10
Training loss: 3.1061280132572144
Validation loss: 3.160874140552246

Epoch: 118| Step: 0
Training loss: 3.267757613775492
Validation loss: 3.160491053136914

Epoch: 5| Step: 1
Training loss: 3.044198450033446
Validation loss: 3.1622085947410175

Epoch: 5| Step: 2
Training loss: 4.2687578818386696
Validation loss: 3.160845970887983

Epoch: 5| Step: 3
Training loss: 3.873703278182564
Validation loss: 3.160747735208524

Epoch: 5| Step: 4
Training loss: 3.4570508363675376
Validation loss: 3.161973625442818

Epoch: 5| Step: 5
Training loss: 3.784830085236177
Validation loss: 3.1602478212829976

Epoch: 5| Step: 6
Training loss: 2.615965965224582
Validation loss: 3.1593642667188004

Epoch: 5| Step: 7
Training loss: 3.7239192649374746
Validation loss: 3.161751558462146

Epoch: 5| Step: 8
Training loss: 3.0502150788063354
Validation loss: 3.158542797305081

Epoch: 5| Step: 9
Training loss: 2.9068378141161717
Validation loss: 3.1593187120404727

Epoch: 5| Step: 10
Training loss: 3.1231401631138156
Validation loss: 3.155853529243555

Epoch: 119| Step: 0
Training loss: 3.3925147349881644
Validation loss: 3.156029286480707

Epoch: 5| Step: 1
Training loss: 3.847164095467415
Validation loss: 3.1554394581496856

Epoch: 5| Step: 2
Training loss: 3.4890857550550303
Validation loss: 3.1588640380837147

Epoch: 5| Step: 3
Training loss: 2.635592478641275
Validation loss: 3.162486428150577

Epoch: 5| Step: 4
Training loss: 3.3350554468215403
Validation loss: 3.1620370499023673

Epoch: 5| Step: 5
Training loss: 3.530851628611234
Validation loss: 3.1709866732869276

Epoch: 5| Step: 6
Training loss: 3.6698883526110007
Validation loss: 3.1749949810416997

Epoch: 5| Step: 7
Training loss: 3.5796918478530992
Validation loss: 3.1766818600665196

Epoch: 5| Step: 8
Training loss: 3.516946230679358
Validation loss: 3.1699521427353385

Epoch: 5| Step: 9
Training loss: 2.9411676115014784
Validation loss: 3.1675594951550545

Epoch: 5| Step: 10
Training loss: 3.4471018463219236
Validation loss: 3.1621507936859152

Epoch: 120| Step: 0
Training loss: 3.588450363761995
Validation loss: 3.1588660832405284

Epoch: 5| Step: 1
Training loss: 4.022587421574451
Validation loss: 3.155525209585811

Epoch: 5| Step: 2
Training loss: 3.137161394670497
Validation loss: 3.1524563699730397

Epoch: 5| Step: 3
Training loss: 3.1229028913123273
Validation loss: 3.152517969161367

Epoch: 5| Step: 4
Training loss: 3.4312607061500495
Validation loss: 3.1542055682219288

Epoch: 5| Step: 5
Training loss: 3.2006524195778754
Validation loss: 3.1534342154177835

Epoch: 5| Step: 6
Training loss: 3.8843412709325404
Validation loss: 3.1523370179169774

Epoch: 5| Step: 7
Training loss: 3.6075782432186867
Validation loss: 3.151911488239462

Epoch: 5| Step: 8
Training loss: 2.300461751777852
Validation loss: 3.1498889387207876

Epoch: 5| Step: 9
Training loss: 3.388877734876388
Validation loss: 3.1521715902289276

Epoch: 5| Step: 10
Training loss: 3.470300963484384
Validation loss: 3.1513519993980883

Epoch: 121| Step: 0
Training loss: 3.38017018222684
Validation loss: 3.1489483712912776

Epoch: 5| Step: 1
Training loss: 3.6391630061394484
Validation loss: 3.148462992688382

Epoch: 5| Step: 2
Training loss: 3.3073509070830402
Validation loss: 3.147428965348805

Epoch: 5| Step: 3
Training loss: 2.9724751441115265
Validation loss: 3.146775421135443

Epoch: 5| Step: 4
Training loss: 3.891377571580796
Validation loss: 3.146208337311779

Epoch: 5| Step: 5
Training loss: 3.3834808605583464
Validation loss: 3.145340147735878

Epoch: 5| Step: 6
Training loss: 3.128019476300653
Validation loss: 3.145043381835983

Epoch: 5| Step: 7
Training loss: 2.8113999652681
Validation loss: 3.144809425608556

Epoch: 5| Step: 8
Training loss: 3.330962641419185
Validation loss: 3.145116004796624

Epoch: 5| Step: 9
Training loss: 3.860340198487574
Validation loss: 3.1456873359423034

Epoch: 5| Step: 10
Training loss: 3.5805915426914114
Validation loss: 3.14494654861312

Epoch: 122| Step: 0
Training loss: 3.507659432994597
Validation loss: 3.149256001441261

Epoch: 5| Step: 1
Training loss: 3.306038654689886
Validation loss: 3.1421470278335133

Epoch: 5| Step: 2
Training loss: 3.730234827826197
Validation loss: 3.1429957812185365

Epoch: 5| Step: 3
Training loss: 3.9051358274314194
Validation loss: 3.140354486662748

Epoch: 5| Step: 4
Training loss: 3.3868220928401014
Validation loss: 3.1415987896293633

Epoch: 5| Step: 5
Training loss: 2.8316616474875755
Validation loss: 3.1407086891758347

Epoch: 5| Step: 6
Training loss: 2.951468835882326
Validation loss: 3.1398197219784474

Epoch: 5| Step: 7
Training loss: 3.981599446864719
Validation loss: 3.1396211127707336

Epoch: 5| Step: 8
Training loss: 3.362437285224858
Validation loss: 3.13970766857037

Epoch: 5| Step: 9
Training loss: 3.6161493578928496
Validation loss: 3.1405222429086606

Epoch: 5| Step: 10
Training loss: 2.2920462785212914
Validation loss: 3.138738241878161

Epoch: 123| Step: 0
Training loss: 3.811940886976825
Validation loss: 3.1385188551763186

Epoch: 5| Step: 1
Training loss: 3.6526834421744447
Validation loss: 3.137688356164731

Epoch: 5| Step: 2
Training loss: 2.536330693118935
Validation loss: 3.1367047479829573

Epoch: 5| Step: 3
Training loss: 3.1738514121741837
Validation loss: 3.137101664429809

Epoch: 5| Step: 4
Training loss: 3.339214064818054
Validation loss: 3.136517519349917

Epoch: 5| Step: 5
Training loss: 3.5434303529746196
Validation loss: 3.1381741546495183

Epoch: 5| Step: 6
Training loss: 3.27938121076039
Validation loss: 3.1369659996976442

Epoch: 5| Step: 7
Training loss: 3.3522308323480243
Validation loss: 3.1349459533172412

Epoch: 5| Step: 8
Training loss: 4.102330424763519
Validation loss: 3.1391525249193752

Epoch: 5| Step: 9
Training loss: 2.8358520831230805
Validation loss: 3.142902284715373

Epoch: 5| Step: 10
Training loss: 3.436121577544442
Validation loss: 3.143756449530161

Epoch: 124| Step: 0
Training loss: 3.1020713407969125
Validation loss: 3.1559682318440765

Epoch: 5| Step: 1
Training loss: 3.475078960591922
Validation loss: 3.164852779437505

Epoch: 5| Step: 2
Training loss: 3.326110086634332
Validation loss: 3.153026745051949

Epoch: 5| Step: 3
Training loss: 3.4591169886528155
Validation loss: 3.1560649535326815

Epoch: 5| Step: 4
Training loss: 2.9818639926711237
Validation loss: 3.159658290380482

Epoch: 5| Step: 5
Training loss: 3.8091690020295697
Validation loss: 3.155263965431103

Epoch: 5| Step: 6
Training loss: 3.3169436609074006
Validation loss: 3.1427468719469336

Epoch: 5| Step: 7
Training loss: 3.7276975554544935
Validation loss: 3.135288686569131

Epoch: 5| Step: 8
Training loss: 3.5111014191645302
Validation loss: 3.1359629031391347

Epoch: 5| Step: 9
Training loss: 3.138215768333682
Validation loss: 3.1336924999866413

Epoch: 5| Step: 10
Training loss: 3.418284304630069
Validation loss: 3.139045863198652

Epoch: 125| Step: 0
Training loss: 3.993304012511486
Validation loss: 3.1334679656688906

Epoch: 5| Step: 1
Training loss: 3.191878060958826
Validation loss: 3.131182504552442

Epoch: 5| Step: 2
Training loss: 3.0615516284088833
Validation loss: 3.138245282345407

Epoch: 5| Step: 3
Training loss: 3.047401734818372
Validation loss: 3.134846183092644

Epoch: 5| Step: 4
Training loss: 3.671711500058337
Validation loss: 3.135532852182559

Epoch: 5| Step: 5
Training loss: 3.077167807529879
Validation loss: 3.13679045745898

Epoch: 5| Step: 6
Training loss: 3.329699220104168
Validation loss: 3.14259758936133

Epoch: 5| Step: 7
Training loss: 3.4195629652651647
Validation loss: 3.155744387231906

Epoch: 5| Step: 8
Training loss: 3.5113982838343536
Validation loss: 3.1330003706365397

Epoch: 5| Step: 9
Training loss: 3.987553544118488
Validation loss: 3.1347842121157825

Epoch: 5| Step: 10
Training loss: 2.7009721242178717
Validation loss: 3.1347581453067694

Epoch: 126| Step: 0
Training loss: 3.1753740225531653
Validation loss: 3.137191666318515

Epoch: 5| Step: 1
Training loss: 3.5985894830753056
Validation loss: 3.1348648057132587

Epoch: 5| Step: 2
Training loss: 3.4437644058175465
Validation loss: 3.1303305595995297

Epoch: 5| Step: 3
Training loss: 3.7727376158489996
Validation loss: 3.129249266260736

Epoch: 5| Step: 4
Training loss: 3.3894348868556077
Validation loss: 3.1273595208390437

Epoch: 5| Step: 5
Training loss: 3.3899145832384674
Validation loss: 3.126358708164666

Epoch: 5| Step: 6
Training loss: 3.3487787668232096
Validation loss: 3.1261069127827694

Epoch: 5| Step: 7
Training loss: 3.0364120418799767
Validation loss: 3.125082950926743

Epoch: 5| Step: 8
Training loss: 3.156572382108671
Validation loss: 3.1244782715757053

Epoch: 5| Step: 9
Training loss: 3.580115152137355
Validation loss: 3.1254906619865253

Epoch: 5| Step: 10
Training loss: 3.286231483009728
Validation loss: 3.130493249921718

Epoch: 127| Step: 0
Training loss: 3.833720201513941
Validation loss: 3.1429297383452353

Epoch: 5| Step: 1
Training loss: 3.8311708127872515
Validation loss: 3.1235409897232573

Epoch: 5| Step: 2
Training loss: 2.9552333511155933
Validation loss: 3.12076751968392

Epoch: 5| Step: 3
Training loss: 3.448811871041733
Validation loss: 3.122087361675659

Epoch: 5| Step: 4
Training loss: 3.1939407799282185
Validation loss: 3.122182917613609

Epoch: 5| Step: 5
Training loss: 3.2017710731821407
Validation loss: 3.1219907394164834

Epoch: 5| Step: 6
Training loss: 3.189059754762491
Validation loss: 3.1269174382525837

Epoch: 5| Step: 7
Training loss: 2.998337921031632
Validation loss: 3.129135067139549

Epoch: 5| Step: 8
Training loss: 3.3201114369269717
Validation loss: 3.128081493602312

Epoch: 5| Step: 9
Training loss: 3.5071486628697732
Validation loss: 3.1274934046374523

Epoch: 5| Step: 10
Training loss: 3.6611149691566385
Validation loss: 3.1287563660311934

Epoch: 128| Step: 0
Training loss: 3.626222996103282
Validation loss: 3.1291480592692995

Epoch: 5| Step: 1
Training loss: 2.618234544521738
Validation loss: 3.151401289281094

Epoch: 5| Step: 2
Training loss: 3.708431771218425
Validation loss: 3.1431801591610036

Epoch: 5| Step: 3
Training loss: 3.2062051989304936
Validation loss: 3.1353838230045823

Epoch: 5| Step: 4
Training loss: 3.8393907095407487
Validation loss: 3.135256749737811

Epoch: 5| Step: 5
Training loss: 3.2916226605399173
Validation loss: 3.1268062138020127

Epoch: 5| Step: 6
Training loss: 3.696600981720126
Validation loss: 3.1228984912000075

Epoch: 5| Step: 7
Training loss: 3.609245000702731
Validation loss: 3.1188433767226185

Epoch: 5| Step: 8
Training loss: 2.4787459991622853
Validation loss: 3.1186721280088676

Epoch: 5| Step: 9
Training loss: 3.679077875456277
Validation loss: 3.115950396576512

Epoch: 5| Step: 10
Training loss: 3.051356848659115
Validation loss: 3.1151859727801816

Epoch: 129| Step: 0
Training loss: 3.0562910081105374
Validation loss: 3.1189679772065397

Epoch: 5| Step: 1
Training loss: 3.256174091764958
Validation loss: 3.114042915039094

Epoch: 5| Step: 2
Training loss: 3.46088307770593
Validation loss: 3.115257245972269

Epoch: 5| Step: 3
Training loss: 3.9341336346703244
Validation loss: 3.118423990162702

Epoch: 5| Step: 4
Training loss: 3.085434652959071
Validation loss: 3.114376376627159

Epoch: 5| Step: 5
Training loss: 3.300314027121102
Validation loss: 3.116593064821045

Epoch: 5| Step: 6
Training loss: 3.333344570776753
Validation loss: 3.1163078664752977

Epoch: 5| Step: 7
Training loss: 3.8869952692935894
Validation loss: 3.1157501917998704

Epoch: 5| Step: 8
Training loss: 2.9306373785647915
Validation loss: 3.11378195724001

Epoch: 5| Step: 9
Training loss: 3.593945572548697
Validation loss: 3.1168004059624828

Epoch: 5| Step: 10
Training loss: 3.087670875176084
Validation loss: 3.1150634019211334

Epoch: 130| Step: 0
Training loss: 3.592856918157274
Validation loss: 3.1114273755318145

Epoch: 5| Step: 1
Training loss: 3.3804410238167044
Validation loss: 3.111625638880333

Epoch: 5| Step: 2
Training loss: 3.3543820203434374
Validation loss: 3.112748713661927

Epoch: 5| Step: 3
Training loss: 3.3197917215670265
Validation loss: 3.1122447553339625

Epoch: 5| Step: 4
Training loss: 3.4437695289791947
Validation loss: 3.1119415414109186

Epoch: 5| Step: 5
Training loss: 3.685262356739407
Validation loss: 3.111407344574769

Epoch: 5| Step: 6
Training loss: 3.8289815139144934
Validation loss: 3.1104948892499555

Epoch: 5| Step: 7
Training loss: 3.1470624699290974
Validation loss: 3.113241448970608

Epoch: 5| Step: 8
Training loss: 2.844152904096811
Validation loss: 3.113188684277567

Epoch: 5| Step: 9
Training loss: 3.0112293206910614
Validation loss: 3.1118413433925416

Epoch: 5| Step: 10
Training loss: 3.3425518991097487
Validation loss: 3.111098622799003

Epoch: 131| Step: 0
Training loss: 3.3711197764783263
Validation loss: 3.11274713400856

Epoch: 5| Step: 1
Training loss: 3.2434975057245095
Validation loss: 3.11207923613279

Epoch: 5| Step: 2
Training loss: 3.5680708578027525
Validation loss: 3.1096659793331862

Epoch: 5| Step: 3
Training loss: 3.4742890543222504
Validation loss: 3.108780091890322

Epoch: 5| Step: 4
Training loss: 3.05497767638496
Validation loss: 3.1087094585757242

Epoch: 5| Step: 5
Training loss: 3.336858760653469
Validation loss: 3.110104927047363

Epoch: 5| Step: 6
Training loss: 3.7062391876011525
Validation loss: 3.1078367599751133

Epoch: 5| Step: 7
Training loss: 3.6071255102104685
Validation loss: 3.1076767995423955

Epoch: 5| Step: 8
Training loss: 2.995507691520096
Validation loss: 3.1082248779561397

Epoch: 5| Step: 9
Training loss: 3.4242149957022257
Validation loss: 3.1084735033677164

Epoch: 5| Step: 10
Training loss: 3.186902607306127
Validation loss: 3.1077551000195864

Epoch: 132| Step: 0
Training loss: 3.3410943439388383
Validation loss: 3.1064094363721293

Epoch: 5| Step: 1
Training loss: 3.9370785442227216
Validation loss: 3.1074188587778426

Epoch: 5| Step: 2
Training loss: 3.2594802210383684
Validation loss: 3.105422280876438

Epoch: 5| Step: 3
Training loss: 3.9349485335322814
Validation loss: 3.104559339545871

Epoch: 5| Step: 4
Training loss: 2.8205354977520827
Validation loss: 3.1035292266116246

Epoch: 5| Step: 5
Training loss: 3.1763982982762085
Validation loss: 3.1033561431847296

Epoch: 5| Step: 6
Training loss: 2.992454098609968
Validation loss: 3.103064149172099

Epoch: 5| Step: 7
Training loss: 2.8540265868030574
Validation loss: 3.105259474130773

Epoch: 5| Step: 8
Training loss: 3.2714763584323423
Validation loss: 3.103856721148707

Epoch: 5| Step: 9
Training loss: 3.6271507197033905
Validation loss: 3.1038419233344903

Epoch: 5| Step: 10
Training loss: 3.621971312090684
Validation loss: 3.1046705649778

Epoch: 133| Step: 0
Training loss: 3.876087036250018
Validation loss: 3.1041288443061075

Epoch: 5| Step: 1
Training loss: 3.745963021743022
Validation loss: 3.10281231748353

Epoch: 5| Step: 2
Training loss: 3.2158983060690876
Validation loss: 3.105396390280731

Epoch: 5| Step: 3
Training loss: 1.93853074005289
Validation loss: 3.1031874252990037

Epoch: 5| Step: 4
Training loss: 3.4723433019931904
Validation loss: 3.1015801140338346

Epoch: 5| Step: 5
Training loss: 3.5248818830896855
Validation loss: 3.1040795536925843

Epoch: 5| Step: 6
Training loss: 3.512812324295196
Validation loss: 3.102911896586079

Epoch: 5| Step: 7
Training loss: 3.2642689494888697
Validation loss: 3.1013878089949403

Epoch: 5| Step: 8
Training loss: 3.665917681288532
Validation loss: 3.0998187296276827

Epoch: 5| Step: 9
Training loss: 3.132834417784925
Validation loss: 3.0993139294410006

Epoch: 5| Step: 10
Training loss: 3.2106232500953356
Validation loss: 3.0998096223686424

Epoch: 134| Step: 0
Training loss: 3.0840088044274667
Validation loss: 3.0991696984765897

Epoch: 5| Step: 1
Training loss: 3.585914362415142
Validation loss: 3.0987326169178435

Epoch: 5| Step: 2
Training loss: 3.127049651315046
Validation loss: 3.100026462480358

Epoch: 5| Step: 3
Training loss: 2.8016675241148676
Validation loss: 3.098770957956352

Epoch: 5| Step: 4
Training loss: 4.281517744393527
Validation loss: 3.102909528682281

Epoch: 5| Step: 5
Training loss: 3.319787412524403
Validation loss: 3.099300147205249

Epoch: 5| Step: 6
Training loss: 2.85854406738477
Validation loss: 3.098036404298943

Epoch: 5| Step: 7
Training loss: 3.6556500325721184
Validation loss: 3.09483915522494

Epoch: 5| Step: 8
Training loss: 3.333728353618179
Validation loss: 3.0948980295160737

Epoch: 5| Step: 9
Training loss: 2.887297163275304
Validation loss: 3.094897628597486

Epoch: 5| Step: 10
Training loss: 3.7682889640543453
Validation loss: 3.0949905939323865

Epoch: 135| Step: 0
Training loss: 3.4877005133189787
Validation loss: 3.093528983287451

Epoch: 5| Step: 1
Training loss: 2.7741614028301664
Validation loss: 3.093514665619184

Epoch: 5| Step: 2
Training loss: 3.1196333007017296
Validation loss: 3.094393735593988

Epoch: 5| Step: 3
Training loss: 4.088219787497217
Validation loss: 3.0930927747331283

Epoch: 5| Step: 4
Training loss: 3.0158326072583077
Validation loss: 3.0929197007438654

Epoch: 5| Step: 5
Training loss: 3.4033687900062453
Validation loss: 3.0943582019200044

Epoch: 5| Step: 6
Training loss: 3.546207180255464
Validation loss: 3.0926907183196075

Epoch: 5| Step: 7
Training loss: 3.641038077172353
Validation loss: 3.0933586661150505

Epoch: 5| Step: 8
Training loss: 2.439413639967677
Validation loss: 3.0921877747870283

Epoch: 5| Step: 9
Training loss: 3.8711919223566325
Validation loss: 3.0930417765509857

Epoch: 5| Step: 10
Training loss: 3.152787528300694
Validation loss: 3.0932026985257033

Epoch: 136| Step: 0
Training loss: 3.7014153634453164
Validation loss: 3.0918394246508774

Epoch: 5| Step: 1
Training loss: 2.936171860448873
Validation loss: 3.092142460795946

Epoch: 5| Step: 2
Training loss: 3.2918092399012755
Validation loss: 3.0928784316623763

Epoch: 5| Step: 3
Training loss: 3.404064072020516
Validation loss: 3.0924881969822904

Epoch: 5| Step: 4
Training loss: 2.728365763628994
Validation loss: 3.091771667977622

Epoch: 5| Step: 5
Training loss: 3.6140257362247334
Validation loss: 3.0893153125880803

Epoch: 5| Step: 6
Training loss: 3.6554465429973035
Validation loss: 3.087341452786483

Epoch: 5| Step: 7
Training loss: 3.2923635557921456
Validation loss: 3.0872396276212792

Epoch: 5| Step: 8
Training loss: 3.1161489644907037
Validation loss: 3.0888144612601085

Epoch: 5| Step: 9
Training loss: 3.343070843611495
Validation loss: 3.087924175826475

Epoch: 5| Step: 10
Training loss: 3.7018828421282137
Validation loss: 3.0894787993949393

Epoch: 137| Step: 0
Training loss: 3.8478694024080755
Validation loss: 3.0913784093276777

Epoch: 5| Step: 1
Training loss: 3.0899897370893292
Validation loss: 3.090310347510141

Epoch: 5| Step: 2
Training loss: 3.3136827768409316
Validation loss: 3.0901395235793436

Epoch: 5| Step: 3
Training loss: 3.2522427083433008
Validation loss: 3.086931431247017

Epoch: 5| Step: 4
Training loss: 2.9607632467483613
Validation loss: 3.0852393390051773

Epoch: 5| Step: 5
Training loss: 2.7211435239512625
Validation loss: 3.08635679059846

Epoch: 5| Step: 6
Training loss: 3.180849355114775
Validation loss: 3.085180579541059

Epoch: 5| Step: 7
Training loss: 3.1396905068623937
Validation loss: 3.0838888051007185

Epoch: 5| Step: 8
Training loss: 3.3158133867623674
Validation loss: 3.084647438782432

Epoch: 5| Step: 9
Training loss: 3.678903678460558
Validation loss: 3.0842230099987877

Epoch: 5| Step: 10
Training loss: 4.196623925760751
Validation loss: 3.08395886304956

Epoch: 138| Step: 0
Training loss: 3.176316782712043
Validation loss: 3.0836490069304126

Epoch: 5| Step: 1
Training loss: 3.2077618044467364
Validation loss: 3.082619056902481

Epoch: 5| Step: 2
Training loss: 3.598487849013737
Validation loss: 3.0834707003931934

Epoch: 5| Step: 3
Training loss: 3.3156360679966657
Validation loss: 3.083154454207136

Epoch: 5| Step: 4
Training loss: 2.756178590710181
Validation loss: 3.0821698184911974

Epoch: 5| Step: 5
Training loss: 3.609652289766306
Validation loss: 3.081984692010858

Epoch: 5| Step: 6
Training loss: 3.9804758178528394
Validation loss: 3.081028229353939

Epoch: 5| Step: 7
Training loss: 3.3492974583725235
Validation loss: 3.0820198093701414

Epoch: 5| Step: 8
Training loss: 2.9455109789929765
Validation loss: 3.081057188689172

Epoch: 5| Step: 9
Training loss: 3.2668139469914435
Validation loss: 3.080206665658726

Epoch: 5| Step: 10
Training loss: 3.4511968830888633
Validation loss: 3.0800117559758644

Epoch: 139| Step: 0
Training loss: 3.1158707593527137
Validation loss: 3.0791226720089098

Epoch: 5| Step: 1
Training loss: 2.875366519287456
Validation loss: 3.0788787939907416

Epoch: 5| Step: 2
Training loss: 3.7581934111290893
Validation loss: 3.079285994803285

Epoch: 5| Step: 3
Training loss: 2.903184812522975
Validation loss: 3.083374175045392

Epoch: 5| Step: 4
Training loss: 3.4752818974383355
Validation loss: 3.084981435182505

Epoch: 5| Step: 5
Training loss: 2.859225243153968
Validation loss: 3.0916225244344755

Epoch: 5| Step: 6
Training loss: 3.5347673571056784
Validation loss: 3.0950006762192444

Epoch: 5| Step: 7
Training loss: 3.5862768340943396
Validation loss: 3.0945326286602572

Epoch: 5| Step: 8
Training loss: 3.9658977441806744
Validation loss: 3.0919871498795715

Epoch: 5| Step: 9
Training loss: 3.469793489231046
Validation loss: 3.0811003459475623

Epoch: 5| Step: 10
Training loss: 3.0274796781480005
Validation loss: 3.077062030685477

Epoch: 140| Step: 0
Training loss: 3.970024685146351
Validation loss: 3.077274099752325

Epoch: 5| Step: 1
Training loss: 3.086343241225955
Validation loss: 3.077000523098168

Epoch: 5| Step: 2
Training loss: 3.550133372205785
Validation loss: 3.0766352347596198

Epoch: 5| Step: 3
Training loss: 3.3439435100712096
Validation loss: 3.076570601345809

Epoch: 5| Step: 4
Training loss: 2.973142406195352
Validation loss: 3.076360611289604

Epoch: 5| Step: 5
Training loss: 2.9595439923060813
Validation loss: 3.0744719999007253

Epoch: 5| Step: 6
Training loss: 2.847807117542047
Validation loss: 3.0762283880977637

Epoch: 5| Step: 7
Training loss: 3.924294990347266
Validation loss: 3.075523529353025

Epoch: 5| Step: 8
Training loss: 3.3283688451419446
Validation loss: 3.074511348910058

Epoch: 5| Step: 9
Training loss: 2.880031329620344
Validation loss: 3.074833151373142

Epoch: 5| Step: 10
Training loss: 3.690913931497081
Validation loss: 3.075397257901794

Epoch: 141| Step: 0
Training loss: 3.2945170716344037
Validation loss: 3.073905550167732

Epoch: 5| Step: 1
Training loss: 3.141700067182383
Validation loss: 3.074709645577711

Epoch: 5| Step: 2
Training loss: 3.7850550902778135
Validation loss: 3.0759093970040023

Epoch: 5| Step: 3
Training loss: 3.00733400972844
Validation loss: 3.0812652878383178

Epoch: 5| Step: 4
Training loss: 3.027962701343519
Validation loss: 3.083140736101888

Epoch: 5| Step: 5
Training loss: 3.2413595222420484
Validation loss: 3.0863550362936505

Epoch: 5| Step: 6
Training loss: 3.617806235468873
Validation loss: 3.0885546795926553

Epoch: 5| Step: 7
Training loss: 3.297320439769167
Validation loss: 3.1088242117456817

Epoch: 5| Step: 8
Training loss: 3.9565543878741947
Validation loss: 3.112191443253435

Epoch: 5| Step: 9
Training loss: 3.2986045025318713
Validation loss: 3.0781705586541315

Epoch: 5| Step: 10
Training loss: 2.9063684582923144
Validation loss: 3.0688820664335723

Epoch: 142| Step: 0
Training loss: 3.175871637801194
Validation loss: 3.0708599807434167

Epoch: 5| Step: 1
Training loss: 3.442572440477407
Validation loss: 3.0732029089963877

Epoch: 5| Step: 2
Training loss: 3.3169448109711324
Validation loss: 3.0726535162330526

Epoch: 5| Step: 3
Training loss: 3.536287343868674
Validation loss: 3.0799928483079593

Epoch: 5| Step: 4
Training loss: 2.6335745141688487
Validation loss: 3.1044461951076148

Epoch: 5| Step: 5
Training loss: 3.7927924919622167
Validation loss: 3.0820738196833393

Epoch: 5| Step: 6
Training loss: 3.13792705897014
Validation loss: 3.07610489665093

Epoch: 5| Step: 7
Training loss: 3.6122272005662577
Validation loss: 3.0711895432307457

Epoch: 5| Step: 8
Training loss: 3.493077243731703
Validation loss: 3.069481790808148

Epoch: 5| Step: 9
Training loss: 3.5178901665280686
Validation loss: 3.067660563761881

Epoch: 5| Step: 10
Training loss: 2.9012787663234696
Validation loss: 3.064630883372342

Epoch: 143| Step: 0
Training loss: 3.6241914570909977
Validation loss: 3.0637898599052646

Epoch: 5| Step: 1
Training loss: 3.111258544910141
Validation loss: 3.0648129677262403

Epoch: 5| Step: 2
Training loss: 3.6411970614125053
Validation loss: 3.0696619722315033

Epoch: 5| Step: 3
Training loss: 2.5565955826162607
Validation loss: 3.0731759803332364

Epoch: 5| Step: 4
Training loss: 3.596935552092331
Validation loss: 3.082689085494197

Epoch: 5| Step: 5
Training loss: 2.937215913062281
Validation loss: 3.0819930916657707

Epoch: 5| Step: 6
Training loss: 3.170522016029218
Validation loss: 3.0961133329097743

Epoch: 5| Step: 7
Training loss: 3.9719337248944138
Validation loss: 3.0888247745196957

Epoch: 5| Step: 8
Training loss: 3.6037698134010943
Validation loss: 3.0821368637901374

Epoch: 5| Step: 9
Training loss: 2.7931717378705465
Validation loss: 3.0638764489890464

Epoch: 5| Step: 10
Training loss: 3.449859041292145
Validation loss: 3.0614080920599958

Epoch: 144| Step: 0
Training loss: 3.2563564056173693
Validation loss: 3.060656769897673

Epoch: 5| Step: 1
Training loss: 3.68976730212563
Validation loss: 3.0603632618574528

Epoch: 5| Step: 2
Training loss: 3.2690594149254903
Validation loss: 3.0598286255014466

Epoch: 5| Step: 3
Training loss: 2.8215146870775865
Validation loss: 3.0615448189372945

Epoch: 5| Step: 4
Training loss: 3.0926305113308086
Validation loss: 3.06004425394035

Epoch: 5| Step: 5
Training loss: 4.038209806708062
Validation loss: 3.061344646195885

Epoch: 5| Step: 6
Training loss: 3.5655289204897946
Validation loss: 3.062158570166272

Epoch: 5| Step: 7
Training loss: 2.7116710538854045
Validation loss: 3.0614736016082604

Epoch: 5| Step: 8
Training loss: 3.0836666201980925
Validation loss: 3.0585558692280417

Epoch: 5| Step: 9
Training loss: 3.5447209072682724
Validation loss: 3.0607102944656877

Epoch: 5| Step: 10
Training loss: 3.308484504634596
Validation loss: 3.06019752175932

Epoch: 145| Step: 0
Training loss: 3.8972079186068647
Validation loss: 3.0622631129548914

Epoch: 5| Step: 1
Training loss: 3.320162134692668
Validation loss: 3.064902884166223

Epoch: 5| Step: 2
Training loss: 3.3525173009871208
Validation loss: 3.0571908945552937

Epoch: 5| Step: 3
Training loss: 3.3281106724676928
Validation loss: 3.0621996044358317

Epoch: 5| Step: 4
Training loss: 3.2090665466598094
Validation loss: 3.0625023221343435

Epoch: 5| Step: 5
Training loss: 3.4587380199273148
Validation loss: 3.061608372020892

Epoch: 5| Step: 6
Training loss: 2.5665402079884103
Validation loss: 3.062416850692589

Epoch: 5| Step: 7
Training loss: 3.4658073796955096
Validation loss: 3.067594384885865

Epoch: 5| Step: 8
Training loss: 3.2154092581011393
Validation loss: 3.084776433944965

Epoch: 5| Step: 9
Training loss: 3.508632096883938
Validation loss: 3.075946160607235

Epoch: 5| Step: 10
Training loss: 3.133407726486886
Validation loss: 3.056354996729988

Epoch: 146| Step: 0
Training loss: 3.1638323664861097
Validation loss: 3.0540123526931002

Epoch: 5| Step: 1
Training loss: 2.934639532253516
Validation loss: 3.052598879396344

Epoch: 5| Step: 2
Training loss: 3.2904931080932505
Validation loss: 3.055347158336391

Epoch: 5| Step: 3
Training loss: 3.5576607478718714
Validation loss: 3.057754248214514

Epoch: 5| Step: 4
Training loss: 3.33609530144922
Validation loss: 3.0583717576698697

Epoch: 5| Step: 5
Training loss: 3.3632531779642925
Validation loss: 3.063686239050234

Epoch: 5| Step: 6
Training loss: 3.0947025258414915
Validation loss: 3.071941585743593

Epoch: 5| Step: 7
Training loss: 3.6539731231435955
Validation loss: 3.0591029818207756

Epoch: 5| Step: 8
Training loss: 3.999334279929247
Validation loss: 3.0542924135205176

Epoch: 5| Step: 9
Training loss: 3.27574247723484
Validation loss: 3.049809545275809

Epoch: 5| Step: 10
Training loss: 2.6310695232918615
Validation loss: 3.050198185138794

Epoch: 147| Step: 0
Training loss: 2.414754428896193
Validation loss: 3.0499771854966853

Epoch: 5| Step: 1
Training loss: 4.101969380860085
Validation loss: 3.048643942290589

Epoch: 5| Step: 2
Training loss: 2.7107477039220833
Validation loss: 3.049411108818853

Epoch: 5| Step: 3
Training loss: 3.5530864086085177
Validation loss: 3.0503153916449945

Epoch: 5| Step: 4
Training loss: 3.4412530005428428
Validation loss: 3.049649107652652

Epoch: 5| Step: 5
Training loss: 3.2419454093539954
Validation loss: 3.053709033476046

Epoch: 5| Step: 6
Training loss: 2.8590658051962325
Validation loss: 3.055419731725989

Epoch: 5| Step: 7
Training loss: 3.2370731322730544
Validation loss: 3.052748427930384

Epoch: 5| Step: 8
Training loss: 3.3452434591467863
Validation loss: 3.052420806678516

Epoch: 5| Step: 9
Training loss: 3.735387816409034
Validation loss: 3.0560681035940904

Epoch: 5| Step: 10
Training loss: 3.5764041410612695
Validation loss: 3.0507492394207207

Epoch: 148| Step: 0
Training loss: 3.394667083867066
Validation loss: 3.0489935784093203

Epoch: 5| Step: 1
Training loss: 3.4050933553974945
Validation loss: 3.0489373592943707

Epoch: 5| Step: 2
Training loss: 3.327633960300122
Validation loss: 3.0466848124214154

Epoch: 5| Step: 3
Training loss: 3.9245914611073442
Validation loss: 3.044336168774817

Epoch: 5| Step: 4
Training loss: 3.2767512407638844
Validation loss: 3.0462468755879564

Epoch: 5| Step: 5
Training loss: 3.052511625650498
Validation loss: 3.0437385800260617

Epoch: 5| Step: 6
Training loss: 3.456770409695188
Validation loss: 3.0438399098004845

Epoch: 5| Step: 7
Training loss: 3.6298778206516658
Validation loss: 3.044230410754881

Epoch: 5| Step: 8
Training loss: 2.7341155010793137
Validation loss: 3.0444289012848795

Epoch: 5| Step: 9
Training loss: 2.9700460716809958
Validation loss: 3.044648897490915

Epoch: 5| Step: 10
Training loss: 3.095679866089675
Validation loss: 3.0471159741629896

Epoch: 149| Step: 0
Training loss: 2.3783909532410226
Validation loss: 3.0436098132042027

Epoch: 5| Step: 1
Training loss: 2.893481024153051
Validation loss: 3.0431875198973297

Epoch: 5| Step: 2
Training loss: 3.957564563718573
Validation loss: 3.0416260611374324

Epoch: 5| Step: 3
Training loss: 3.3650141736393837
Validation loss: 3.040845149533137

Epoch: 5| Step: 4
Training loss: 3.484927420168221
Validation loss: 3.0440785943394344

Epoch: 5| Step: 5
Training loss: 3.145398966798863
Validation loss: 3.0449980005529524

Epoch: 5| Step: 6
Training loss: 2.84828980649395
Validation loss: 3.045719961246456

Epoch: 5| Step: 7
Training loss: 3.5397373255027174
Validation loss: 3.0494612612196486

Epoch: 5| Step: 8
Training loss: 3.742084923853485
Validation loss: 3.048373652850285

Epoch: 5| Step: 9
Training loss: 3.486989772211669
Validation loss: 3.0444456922348277

Epoch: 5| Step: 10
Training loss: 3.298680683316935
Validation loss: 3.0371249925992454

Epoch: 150| Step: 0
Training loss: 2.908452665691731
Validation loss: 3.039565913566345

Epoch: 5| Step: 1
Training loss: 3.7435324527663107
Validation loss: 3.041112321366156

Epoch: 5| Step: 2
Training loss: 3.2740683300552242
Validation loss: 3.052388044802971

Epoch: 5| Step: 3
Training loss: 2.9099989470909287
Validation loss: 3.0668244224551424

Epoch: 5| Step: 4
Training loss: 3.497165622174051
Validation loss: 3.0422789063836655

Epoch: 5| Step: 5
Training loss: 3.499493698557012
Validation loss: 3.0415015272037302

Epoch: 5| Step: 6
Training loss: 3.438047469498764
Validation loss: 3.0392138187789697

Epoch: 5| Step: 7
Training loss: 3.406763860456948
Validation loss: 3.039315301937929

Epoch: 5| Step: 8
Training loss: 3.095253935273829
Validation loss: 3.041940292163035

Epoch: 5| Step: 9
Training loss: 3.2171853716242502
Validation loss: 3.037105573146585

Epoch: 5| Step: 10
Training loss: 3.4416319549016987
Validation loss: 3.03796065001798

Epoch: 151| Step: 0
Training loss: 3.5605837034830787
Validation loss: 3.038727158463355

Epoch: 5| Step: 1
Training loss: 3.56344136967926
Validation loss: 3.0414599658712773

Epoch: 5| Step: 2
Training loss: 2.807578973924726
Validation loss: 3.047497961885581

Epoch: 5| Step: 3
Training loss: 3.1305410469604293
Validation loss: 3.0435381425117924

Epoch: 5| Step: 4
Training loss: 3.4438232524855787
Validation loss: 3.0472041160297914

Epoch: 5| Step: 5
Training loss: 3.201331255088978
Validation loss: 3.044188021798597

Epoch: 5| Step: 6
Training loss: 3.4402396642012536
Validation loss: 3.0434943591160057

Epoch: 5| Step: 7
Training loss: 2.8529935407488547
Validation loss: 3.039277494667592

Epoch: 5| Step: 8
Training loss: 3.222602390648417
Validation loss: 3.038780276273058

Epoch: 5| Step: 9
Training loss: 3.7044326469321502
Validation loss: 3.0391803839537577

Epoch: 5| Step: 10
Training loss: 3.3763214632540515
Validation loss: 3.0358608062272916

Epoch: 152| Step: 0
Training loss: 2.9503933013980643
Validation loss: 3.0359758201854463

Epoch: 5| Step: 1
Training loss: 4.2085438792119
Validation loss: 3.0357990524674445

Epoch: 5| Step: 2
Training loss: 3.244667961166852
Validation loss: 3.035044173190363

Epoch: 5| Step: 3
Training loss: 3.6499908865200865
Validation loss: 3.0348461112662766

Epoch: 5| Step: 4
Training loss: 2.6820198785555793
Validation loss: 3.0328999223799378

Epoch: 5| Step: 5
Training loss: 2.6815249535492987
Validation loss: 3.033955809103362

Epoch: 5| Step: 6
Training loss: 3.3517332233615993
Validation loss: 3.0324678147202255

Epoch: 5| Step: 7
Training loss: 3.6527702531305963
Validation loss: 3.0335897505880407

Epoch: 5| Step: 8
Training loss: 3.6368530117536455
Validation loss: 3.032800538150189

Epoch: 5| Step: 9
Training loss: 2.822863157171061
Validation loss: 3.0332915029601804

Epoch: 5| Step: 10
Training loss: 3.103179894275837
Validation loss: 3.030766551643659

Epoch: 153| Step: 0
Training loss: 2.828728542946059
Validation loss: 3.0312661594560195

Epoch: 5| Step: 1
Training loss: 3.4157931133755435
Validation loss: 3.0318386266260102

Epoch: 5| Step: 2
Training loss: 2.9784659960004674
Validation loss: 3.0311176054204556

Epoch: 5| Step: 3
Training loss: 2.9354508740228082
Validation loss: 3.0306357364038323

Epoch: 5| Step: 4
Training loss: 3.5208898836970346
Validation loss: 3.0294269077316356

Epoch: 5| Step: 5
Training loss: 3.2091647635505187
Validation loss: 3.028448356362714

Epoch: 5| Step: 6
Training loss: 3.651075304051464
Validation loss: 3.030623775233545

Epoch: 5| Step: 7
Training loss: 2.9944482932678413
Validation loss: 3.030178430816558

Epoch: 5| Step: 8
Training loss: 3.4657952723454413
Validation loss: 3.028805867010502

Epoch: 5| Step: 9
Training loss: 3.330242933742477
Validation loss: 3.028421916056745

Epoch: 5| Step: 10
Training loss: 3.9081378494751804
Validation loss: 3.0314088388007305

Epoch: 154| Step: 0
Training loss: 3.198781860479107
Validation loss: 3.032037192776601

Epoch: 5| Step: 1
Training loss: 3.5005233918263756
Validation loss: 3.034012070497502

Epoch: 5| Step: 2
Training loss: 2.7118351134641627
Validation loss: 3.0346125938842436

Epoch: 5| Step: 3
Training loss: 3.2825904651270714
Validation loss: 3.042550820838334

Epoch: 5| Step: 4
Training loss: 4.523020459915093
Validation loss: 3.0293454512203986

Epoch: 5| Step: 5
Training loss: 3.179538132816952
Validation loss: 3.0303722041355465

Epoch: 5| Step: 6
Training loss: 2.991895855666976
Validation loss: 3.0312075386249138

Epoch: 5| Step: 7
Training loss: 3.2341371900327043
Validation loss: 3.035840009821196

Epoch: 5| Step: 8
Training loss: 3.1593458647851396
Validation loss: 3.0298917277354716

Epoch: 5| Step: 9
Training loss: 3.422112443602658
Validation loss: 3.0254261009972763

Epoch: 5| Step: 10
Training loss: 2.603198204522431
Validation loss: 3.0233554454277543

Epoch: 155| Step: 0
Training loss: 3.027124330505985
Validation loss: 3.026343253395363

Epoch: 5| Step: 1
Training loss: 3.896460022049524
Validation loss: 3.0268201988045895

Epoch: 5| Step: 2
Training loss: 2.8804884228863554
Validation loss: 3.0268586393618087

Epoch: 5| Step: 3
Training loss: 2.8343072414184958
Validation loss: 3.0251921361280876

Epoch: 5| Step: 4
Training loss: 3.571448347854355
Validation loss: 3.0248644109997325

Epoch: 5| Step: 5
Training loss: 3.458143083479258
Validation loss: 3.025319451434737

Epoch: 5| Step: 6
Training loss: 3.2679653998496154
Validation loss: 3.0241221215895275

Epoch: 5| Step: 7
Training loss: 3.5135250347130964
Validation loss: 3.0245782814999513

Epoch: 5| Step: 8
Training loss: 3.512989192034967
Validation loss: 3.0238891342250898

Epoch: 5| Step: 9
Training loss: 2.6718641135903036
Validation loss: 3.022027564561016

Epoch: 5| Step: 10
Training loss: 3.464200584815131
Validation loss: 3.02333891383715

Epoch: 156| Step: 0
Training loss: 3.155911266921587
Validation loss: 3.0223942295058963

Epoch: 5| Step: 1
Training loss: 3.342754893316953
Validation loss: 3.022368835533454

Epoch: 5| Step: 2
Training loss: 3.3531604149931087
Validation loss: 3.0217223158146855

Epoch: 5| Step: 3
Training loss: 3.1241783587817884
Validation loss: 3.0209405310722652

Epoch: 5| Step: 4
Training loss: 3.8390880318376044
Validation loss: 3.020356847562478

Epoch: 5| Step: 5
Training loss: 3.909332158062053
Validation loss: 3.019204887980638

Epoch: 5| Step: 6
Training loss: 2.2188413359419084
Validation loss: 3.0178470763445815

Epoch: 5| Step: 7
Training loss: 3.4664618015889053
Validation loss: 3.0188361329862334

Epoch: 5| Step: 8
Training loss: 3.274670644025634
Validation loss: 3.017767149866914

Epoch: 5| Step: 9
Training loss: 2.984230717072205
Validation loss: 3.0170037702349877

Epoch: 5| Step: 10
Training loss: 3.2683667806197474
Validation loss: 3.0172070614487527

Epoch: 157| Step: 0
Training loss: 3.1445000119760507
Validation loss: 3.0170522265870527

Epoch: 5| Step: 1
Training loss: 2.631879239265762
Validation loss: 3.015632518444607

Epoch: 5| Step: 2
Training loss: 3.2395142346502297
Validation loss: 3.014470619855352

Epoch: 5| Step: 3
Training loss: 3.3432260263197167
Validation loss: 3.0144226339802915

Epoch: 5| Step: 4
Training loss: 3.628536472431095
Validation loss: 3.0138511671106234

Epoch: 5| Step: 5
Training loss: 3.008783515645244
Validation loss: 3.0131048806473726

Epoch: 5| Step: 6
Training loss: 3.2766020780182235
Validation loss: 3.0129645125159734

Epoch: 5| Step: 7
Training loss: 3.047609837268354
Validation loss: 3.0137350485041523

Epoch: 5| Step: 8
Training loss: 3.140078672650507
Validation loss: 3.012916808971572

Epoch: 5| Step: 9
Training loss: 3.8864844170094424
Validation loss: 3.017499088566867

Epoch: 5| Step: 10
Training loss: 3.687570862170026
Validation loss: 3.0278260396293555

Epoch: 158| Step: 0
Training loss: 4.269213162899393
Validation loss: 3.0228901775469894

Epoch: 5| Step: 1
Training loss: 3.248270161306248
Validation loss: 3.010130247438432

Epoch: 5| Step: 2
Training loss: 3.754986054944432
Validation loss: 3.0099666812824064

Epoch: 5| Step: 3
Training loss: 3.4989629298947755
Validation loss: 3.011238328067939

Epoch: 5| Step: 4
Training loss: 3.505658888330838
Validation loss: 3.0100052570142712

Epoch: 5| Step: 5
Training loss: 2.7226034457587955
Validation loss: 3.0103713518040505

Epoch: 5| Step: 6
Training loss: 2.2973163206710736
Validation loss: 3.0088123370251636

Epoch: 5| Step: 7
Training loss: 3.1442507032266387
Validation loss: 3.010511362265699

Epoch: 5| Step: 8
Training loss: 2.8416262231299845
Validation loss: 3.009311283322025

Epoch: 5| Step: 9
Training loss: 2.844546196114349
Validation loss: 3.0103104454081353

Epoch: 5| Step: 10
Training loss: 3.640419360725937
Validation loss: 3.0101564515376777

Epoch: 159| Step: 0
Training loss: 2.9680954060913614
Validation loss: 3.0096439295631723

Epoch: 5| Step: 1
Training loss: 3.720203019621664
Validation loss: 3.0095480211991283

Epoch: 5| Step: 2
Training loss: 2.7900425660909485
Validation loss: 3.009007264755792

Epoch: 5| Step: 3
Training loss: 3.293044626757791
Validation loss: 3.0079696428842677

Epoch: 5| Step: 4
Training loss: 3.6932466631978653
Validation loss: 3.0074132928467328

Epoch: 5| Step: 5
Training loss: 3.313858905097727
Validation loss: 3.006294740975808

Epoch: 5| Step: 6
Training loss: 3.2255702675217317
Validation loss: 3.0070316958488443

Epoch: 5| Step: 7
Training loss: 3.11383028825045
Validation loss: 3.0063938809376536

Epoch: 5| Step: 8
Training loss: 3.11006241297268
Validation loss: 3.0058670543315706

Epoch: 5| Step: 9
Training loss: 3.640231786621169
Validation loss: 3.004627005991372

Epoch: 5| Step: 10
Training loss: 3.111487509649537
Validation loss: 3.0038561733933276

Epoch: 160| Step: 0
Training loss: 2.9371048681846323
Validation loss: 3.002261779871346

Epoch: 5| Step: 1
Training loss: 3.505542725950833
Validation loss: 3.003325480407753

Epoch: 5| Step: 2
Training loss: 3.3240971077920167
Validation loss: 3.0036345635483133

Epoch: 5| Step: 3
Training loss: 2.7897517530687206
Validation loss: 3.0032234972972707

Epoch: 5| Step: 4
Training loss: 3.471819370212091
Validation loss: 3.0018665239501736

Epoch: 5| Step: 5
Training loss: 3.5598490706606913
Validation loss: 3.0012584835885403

Epoch: 5| Step: 6
Training loss: 3.0076078270967725
Validation loss: 3.0016074949877924

Epoch: 5| Step: 7
Training loss: 3.0746179731052754
Validation loss: 3.0019376062373464

Epoch: 5| Step: 8
Training loss: 3.495093994404746
Validation loss: 3.0008794715721763

Epoch: 5| Step: 9
Training loss: 3.289322432805207
Validation loss: 3.001144033807503

Epoch: 5| Step: 10
Training loss: 3.5685051615248633
Validation loss: 3.005980524318136

Epoch: 161| Step: 0
Training loss: 3.88117108103548
Validation loss: 3.00144993530398

Epoch: 5| Step: 1
Training loss: 4.005019376519773
Validation loss: 3.0001364663235597

Epoch: 5| Step: 2
Training loss: 2.2615604114615073
Validation loss: 3.0002555721215183

Epoch: 5| Step: 3
Training loss: 3.383642363567883
Validation loss: 3.0012297929663525

Epoch: 5| Step: 4
Training loss: 3.003590025211627
Validation loss: 2.999039354301904

Epoch: 5| Step: 5
Training loss: 2.9505809341239764
Validation loss: 2.9980749393683572

Epoch: 5| Step: 6
Training loss: 2.848423732738946
Validation loss: 2.999433450286875

Epoch: 5| Step: 7
Training loss: 3.3455454916711
Validation loss: 2.9990828489685333

Epoch: 5| Step: 8
Training loss: 3.5633199986159845
Validation loss: 2.997229315281751

Epoch: 5| Step: 9
Training loss: 2.912718434799341
Validation loss: 2.9951079536049376

Epoch: 5| Step: 10
Training loss: 3.5157895198050184
Validation loss: 2.995196639933541

Epoch: 162| Step: 0
Training loss: 2.0204228511922024
Validation loss: 2.9960657748879926

Epoch: 5| Step: 1
Training loss: 2.8528987732159874
Validation loss: 2.994116789475549

Epoch: 5| Step: 2
Training loss: 3.168575581522447
Validation loss: 2.9959543835368874

Epoch: 5| Step: 3
Training loss: 3.7004794557617324
Validation loss: 2.993447218656837

Epoch: 5| Step: 4
Training loss: 3.7619215612513526
Validation loss: 2.9939553762493536

Epoch: 5| Step: 5
Training loss: 3.06778463496516
Validation loss: 2.9929942825451517

Epoch: 5| Step: 6
Training loss: 3.7511781749058706
Validation loss: 2.994837271765349

Epoch: 5| Step: 7
Training loss: 3.2690387022120215
Validation loss: 2.9946861444673583

Epoch: 5| Step: 8
Training loss: 3.6467642040795907
Validation loss: 2.9938557421881304

Epoch: 5| Step: 9
Training loss: 3.381077416152809
Validation loss: 2.993581437683223

Epoch: 5| Step: 10
Training loss: 2.9200345531143697
Validation loss: 2.9939974711490613

Epoch: 163| Step: 0
Training loss: 3.0767909223346233
Validation loss: 2.993777389652835

Epoch: 5| Step: 1
Training loss: 2.238171107060401
Validation loss: 2.9944856700108646

Epoch: 5| Step: 2
Training loss: 3.054014946541875
Validation loss: 2.9914448040014747

Epoch: 5| Step: 3
Training loss: 2.905431324491331
Validation loss: 2.9984110397902457

Epoch: 5| Step: 4
Training loss: 4.043752282921738
Validation loss: 2.9928288821520788

Epoch: 5| Step: 5
Training loss: 3.3618013358072703
Validation loss: 2.998677934033209

Epoch: 5| Step: 6
Training loss: 3.5845922136549646
Validation loss: 3.0058359786747455

Epoch: 5| Step: 7
Training loss: 2.633122547582231
Validation loss: 3.015037109090032

Epoch: 5| Step: 8
Training loss: 3.757328882642086
Validation loss: 3.0083861587172778

Epoch: 5| Step: 9
Training loss: 3.1150089002944394
Validation loss: 2.997055235495196

Epoch: 5| Step: 10
Training loss: 3.8568398492868323
Validation loss: 2.9891178683013107

Epoch: 164| Step: 0
Training loss: 4.073843978074078
Validation loss: 2.9899906685447903

Epoch: 5| Step: 1
Training loss: 3.1298442677521288
Validation loss: 2.990008094445477

Epoch: 5| Step: 2
Training loss: 3.742654090415374
Validation loss: 2.99335636508218

Epoch: 5| Step: 3
Training loss: 2.881607258590461
Validation loss: 2.995866193711946

Epoch: 5| Step: 4
Training loss: 3.6266757117420423
Validation loss: 3.0082461874010473

Epoch: 5| Step: 5
Training loss: 2.697357551836829
Validation loss: 3.006391066929113

Epoch: 5| Step: 6
Training loss: 3.474049137573952
Validation loss: 2.9964267171181342

Epoch: 5| Step: 7
Training loss: 2.9384848384417355
Validation loss: 2.9978013595768274

Epoch: 5| Step: 8
Training loss: 3.3036397801696147
Validation loss: 2.9945517498003937

Epoch: 5| Step: 9
Training loss: 3.152704041039333
Validation loss: 2.9928127575745553

Epoch: 5| Step: 10
Training loss: 2.6235041216263
Validation loss: 2.9932952563574533

Epoch: 165| Step: 0
Training loss: 3.2758938625129033
Validation loss: 2.9917709809079707

Epoch: 5| Step: 1
Training loss: 3.7585034914821347
Validation loss: 2.9914269768260136

Epoch: 5| Step: 2
Training loss: 3.0380504658809975
Validation loss: 2.9901569306834768

Epoch: 5| Step: 3
Training loss: 2.6059018165495678
Validation loss: 2.9890291182567643

Epoch: 5| Step: 4
Training loss: 3.1663940881231554
Validation loss: 2.990275703535142

Epoch: 5| Step: 5
Training loss: 3.5975640002423646
Validation loss: 2.9892129484622596

Epoch: 5| Step: 6
Training loss: 3.0454195116323555
Validation loss: 2.98755458892268

Epoch: 5| Step: 7
Training loss: 2.9328235168737873
Validation loss: 2.98554677346923

Epoch: 5| Step: 8
Training loss: 3.8309954410885316
Validation loss: 2.984016615559218

Epoch: 5| Step: 9
Training loss: 3.21266710611174
Validation loss: 2.9895408875754126

Epoch: 5| Step: 10
Training loss: 3.286384561539949
Validation loss: 2.9917025620133497

Epoch: 166| Step: 0
Training loss: 3.549287891155317
Validation loss: 2.998540902887315

Epoch: 5| Step: 1
Training loss: 3.442681032073496
Validation loss: 3.0069188060657575

Epoch: 5| Step: 2
Training loss: 3.311538700753678
Validation loss: 3.0077718164393095

Epoch: 5| Step: 3
Training loss: 2.9017783598754243
Validation loss: 3.001037397781432

Epoch: 5| Step: 4
Training loss: 2.9717575098152866
Validation loss: 2.99407131068628

Epoch: 5| Step: 5
Training loss: 3.202623877053935
Validation loss: 2.9861114059973386

Epoch: 5| Step: 6
Training loss: 3.8477014839108232
Validation loss: 2.986280960883116

Epoch: 5| Step: 7
Training loss: 2.7147695407742036
Validation loss: 2.9849665645577006

Epoch: 5| Step: 8
Training loss: 2.923777567720043
Validation loss: 2.9871644286634487

Epoch: 5| Step: 9
Training loss: 3.7237650930067416
Validation loss: 2.9926763102240916

Epoch: 5| Step: 10
Training loss: 3.0766263305180104
Validation loss: 2.9800611037184996

Epoch: 167| Step: 0
Training loss: 3.8010257591332155
Validation loss: 2.9792873984278585

Epoch: 5| Step: 1
Training loss: 3.725473176742117
Validation loss: 2.9819610871750486

Epoch: 5| Step: 2
Training loss: 2.7932424131116442
Validation loss: 2.9832974368550604

Epoch: 5| Step: 3
Training loss: 3.117908518684246
Validation loss: 2.990294856990438

Epoch: 5| Step: 4
Training loss: 3.0531378129828854
Validation loss: 2.990273713681201

Epoch: 5| Step: 5
Training loss: 3.7402060724288173
Validation loss: 2.9937295190980318

Epoch: 5| Step: 6
Training loss: 3.1477998225005
Validation loss: 2.9926961858759626

Epoch: 5| Step: 7
Training loss: 3.4735087151890993
Validation loss: 2.993567879458301

Epoch: 5| Step: 8
Training loss: 3.0968539917634588
Validation loss: 2.988916356494124

Epoch: 5| Step: 9
Training loss: 2.866961311752556
Validation loss: 2.9874798305889723

Epoch: 5| Step: 10
Training loss: 2.863495739323021
Validation loss: 2.985792774524399

Epoch: 168| Step: 0
Training loss: 2.415562629634758
Validation loss: 2.9823210286778927

Epoch: 5| Step: 1
Training loss: 2.636277632371797
Validation loss: 2.9822919908240086

Epoch: 5| Step: 2
Training loss: 3.714646968984672
Validation loss: 2.985829991733635

Epoch: 5| Step: 3
Training loss: 3.300201328956388
Validation loss: 2.981041458123672

Epoch: 5| Step: 4
Training loss: 3.421185567720894
Validation loss: 2.9806436264749023

Epoch: 5| Step: 5
Training loss: 3.2082481538108403
Validation loss: 2.981048733558655

Epoch: 5| Step: 6
Training loss: 3.4305952604383956
Validation loss: 2.9768126676541407

Epoch: 5| Step: 7
Training loss: 3.4901865575382782
Validation loss: 2.974983054450867

Epoch: 5| Step: 8
Training loss: 4.074421220175811
Validation loss: 2.9743206752457327

Epoch: 5| Step: 9
Training loss: 2.8626736650717475
Validation loss: 2.973752631547693

Epoch: 5| Step: 10
Training loss: 2.920620082701697
Validation loss: 2.97308732842241

Epoch: 169| Step: 0
Training loss: 3.065877958821295
Validation loss: 2.9741108167446857

Epoch: 5| Step: 1
Training loss: 2.919423752975658
Validation loss: 2.974253694318402

Epoch: 5| Step: 2
Training loss: 4.369018389271327
Validation loss: 2.973971644192657

Epoch: 5| Step: 3
Training loss: 3.6801885761789155
Validation loss: 2.9711569268301234

Epoch: 5| Step: 4
Training loss: 2.901051784385876
Validation loss: 2.971061521659854

Epoch: 5| Step: 5
Training loss: 3.2642014608573087
Validation loss: 2.9715855077817137

Epoch: 5| Step: 6
Training loss: 3.5395683954352903
Validation loss: 2.9702001478651696

Epoch: 5| Step: 7
Training loss: 2.8098378615929356
Validation loss: 2.971778837484112

Epoch: 5| Step: 8
Training loss: 3.085408843908668
Validation loss: 2.970084129257324

Epoch: 5| Step: 9
Training loss: 3.2240755042423657
Validation loss: 2.969906409982077

Epoch: 5| Step: 10
Training loss: 2.4550024732588915
Validation loss: 2.9709661910867027

Epoch: 170| Step: 0
Training loss: 3.6548061291252782
Validation loss: 2.9715553124944214

Epoch: 5| Step: 1
Training loss: 3.1817975365600604
Validation loss: 2.970839599534652

Epoch: 5| Step: 2
Training loss: 2.4696011584969666
Validation loss: 2.969794425900201

Epoch: 5| Step: 3
Training loss: 3.225781214523038
Validation loss: 2.969285444537713

Epoch: 5| Step: 4
Training loss: 3.4894869814803577
Validation loss: 2.970804237985278

Epoch: 5| Step: 5
Training loss: 3.392723313180337
Validation loss: 2.9703164407184244

Epoch: 5| Step: 6
Training loss: 3.1054400364729946
Validation loss: 2.9684096758191454

Epoch: 5| Step: 7
Training loss: 3.1219562203015423
Validation loss: 2.969899702864922

Epoch: 5| Step: 8
Training loss: 2.9457181858577655
Validation loss: 2.973596139237128

Epoch: 5| Step: 9
Training loss: 3.436951888341744
Validation loss: 2.9732290851184238

Epoch: 5| Step: 10
Training loss: 3.6063047619765696
Validation loss: 2.972954022623353

Epoch: 171| Step: 0
Training loss: 3.6315325050963385
Validation loss: 2.9743628316870145

Epoch: 5| Step: 1
Training loss: 3.3007133522047702
Validation loss: 2.9759558684820586

Epoch: 5| Step: 2
Training loss: 2.8563620113387826
Validation loss: 2.978037308525035

Epoch: 5| Step: 3
Training loss: 3.3557964338142137
Validation loss: 2.980147297529126

Epoch: 5| Step: 4
Training loss: 2.9275591227150626
Validation loss: 2.9704923601985915

Epoch: 5| Step: 5
Training loss: 2.883024709277428
Validation loss: 2.9750195468899148

Epoch: 5| Step: 6
Training loss: 2.9718768868906666
Validation loss: 2.972226777193187

Epoch: 5| Step: 7
Training loss: 3.4012794275212954
Validation loss: 2.9738699630493155

Epoch: 5| Step: 8
Training loss: 3.330255963451532
Validation loss: 2.969141512811588

Epoch: 5| Step: 9
Training loss: 3.571966610298575
Validation loss: 2.9638020843482478

Epoch: 5| Step: 10
Training loss: 3.40281167737895
Validation loss: 2.9657864712375765

Epoch: 172| Step: 0
Training loss: 3.353968043794387
Validation loss: 2.96500304050079

Epoch: 5| Step: 1
Training loss: 3.612396824825219
Validation loss: 2.9676615111482723

Epoch: 5| Step: 2
Training loss: 3.402930786083591
Validation loss: 2.9680038507556694

Epoch: 5| Step: 3
Training loss: 2.8963546466649785
Validation loss: 2.967892610306053

Epoch: 5| Step: 4
Training loss: 2.887393278981886
Validation loss: 2.9687728803235447

Epoch: 5| Step: 5
Training loss: 3.4391246770968773
Validation loss: 2.9698706057133317

Epoch: 5| Step: 6
Training loss: 3.6991296775591587
Validation loss: 2.9696940502938745

Epoch: 5| Step: 7
Training loss: 2.8943515160649307
Validation loss: 2.969591521684995

Epoch: 5| Step: 8
Training loss: 3.2975510902871843
Validation loss: 2.9695244599858537

Epoch: 5| Step: 9
Training loss: 2.9670916292231446
Validation loss: 2.9687338396289915

Epoch: 5| Step: 10
Training loss: 3.2184554770819784
Validation loss: 2.9691705255856142

Epoch: 173| Step: 0
Training loss: 3.438949140788815
Validation loss: 2.967526981089317

Epoch: 5| Step: 1
Training loss: 3.0045970028298408
Validation loss: 2.967376798987868

Epoch: 5| Step: 2
Training loss: 3.312419386548571
Validation loss: 2.9675548546275072

Epoch: 5| Step: 3
Training loss: 3.239877783507117
Validation loss: 2.967872618646484

Epoch: 5| Step: 4
Training loss: 3.0551779272831885
Validation loss: 2.9654881777343536

Epoch: 5| Step: 5
Training loss: 2.5957418859384935
Validation loss: 2.964519899334578

Epoch: 5| Step: 6
Training loss: 3.1060354423490435
Validation loss: 2.964548109867728

Epoch: 5| Step: 7
Training loss: 3.302590572896904
Validation loss: 2.9623320380000275

Epoch: 5| Step: 8
Training loss: 3.6103939583239053
Validation loss: 2.9617878647914577

Epoch: 5| Step: 9
Training loss: 3.600767763708065
Validation loss: 2.960965166301688

Epoch: 5| Step: 10
Training loss: 3.421508769464355
Validation loss: 2.960982527522922

Epoch: 174| Step: 0
Training loss: 2.6426113264728763
Validation loss: 2.962113277749513

Epoch: 5| Step: 1
Training loss: 3.4237036151954143
Validation loss: 2.961043262424565

Epoch: 5| Step: 2
Training loss: 3.1131806207760713
Validation loss: 2.9610178868867267

Epoch: 5| Step: 3
Training loss: 3.3313130614304076
Validation loss: 2.960175315281905

Epoch: 5| Step: 4
Training loss: 3.7488951008982716
Validation loss: 2.956218295029341

Epoch: 5| Step: 5
Training loss: 2.923227415380762
Validation loss: 2.9575947144647627

Epoch: 5| Step: 6
Training loss: 3.3506553862847728
Validation loss: 2.959337356736335

Epoch: 5| Step: 7
Training loss: 2.96903877861521
Validation loss: 2.956885960547205

Epoch: 5| Step: 8
Training loss: 3.185480712353226
Validation loss: 2.9662062380877257

Epoch: 5| Step: 9
Training loss: 3.270546594835747
Validation loss: 2.9720458823449087

Epoch: 5| Step: 10
Training loss: 3.6592520102690664
Validation loss: 2.9757364651513454

Epoch: 175| Step: 0
Training loss: 3.2864587041226927
Validation loss: 2.9645110777587678

Epoch: 5| Step: 1
Training loss: 2.8742417703978393
Validation loss: 2.9575037945026184

Epoch: 5| Step: 2
Training loss: 3.754992023363035
Validation loss: 2.9560812842262543

Epoch: 5| Step: 3
Training loss: 3.4165130828825774
Validation loss: 2.9541002347287737

Epoch: 5| Step: 4
Training loss: 3.641367169481275
Validation loss: 2.953221508071899

Epoch: 5| Step: 5
Training loss: 2.9505945091554846
Validation loss: 2.95551534882831

Epoch: 5| Step: 6
Training loss: 3.2347783376229486
Validation loss: 2.9570240368479235

Epoch: 5| Step: 7
Training loss: 3.12394666085517
Validation loss: 2.9547421494606727

Epoch: 5| Step: 8
Training loss: 3.21031921819732
Validation loss: 2.954226236691432

Epoch: 5| Step: 9
Training loss: 2.8691741962169717
Validation loss: 2.9538911484411443

Epoch: 5| Step: 10
Training loss: 3.1733901440586676
Validation loss: 2.9547072069497595

Epoch: 176| Step: 0
Training loss: 3.421309332927192
Validation loss: 2.953203528287337

Epoch: 5| Step: 1
Training loss: 3.4621433886932054
Validation loss: 2.9515735418056632

Epoch: 5| Step: 2
Training loss: 3.0118568082007933
Validation loss: 2.95279751123056

Epoch: 5| Step: 3
Training loss: 3.5775061992642203
Validation loss: 2.9485045274150523

Epoch: 5| Step: 4
Training loss: 2.906904249484979
Validation loss: 2.950807247736787

Epoch: 5| Step: 5
Training loss: 3.374247997004382
Validation loss: 2.949998266248435

Epoch: 5| Step: 6
Training loss: 3.355192765953113
Validation loss: 2.9466822215246795

Epoch: 5| Step: 7
Training loss: 3.0069450415614836
Validation loss: 2.9514243528940596

Epoch: 5| Step: 8
Training loss: 3.099102591781958
Validation loss: 2.95626469174679

Epoch: 5| Step: 9
Training loss: 3.239256782060056
Validation loss: 2.9564463857022023

Epoch: 5| Step: 10
Training loss: 3.0463550613061994
Validation loss: 2.965653772593936

Epoch: 177| Step: 0
Training loss: 3.484124555268651
Validation loss: 2.957355596514686

Epoch: 5| Step: 1
Training loss: 3.317890747101928
Validation loss: 2.955265925252349

Epoch: 5| Step: 2
Training loss: 3.7019728787756443
Validation loss: 2.950384353299082

Epoch: 5| Step: 3
Training loss: 3.7150121544373427
Validation loss: 2.9481332240577727

Epoch: 5| Step: 4
Training loss: 3.2577773716631273
Validation loss: 2.9446132283841684

Epoch: 5| Step: 5
Training loss: 2.9858241532319747
Validation loss: 2.9473945598551956

Epoch: 5| Step: 6
Training loss: 2.9634834556471765
Validation loss: 2.9418168195862218

Epoch: 5| Step: 7
Training loss: 3.2011827488470748
Validation loss: 2.943455300943171

Epoch: 5| Step: 8
Training loss: 2.740239508386808
Validation loss: 2.9435208279854517

Epoch: 5| Step: 9
Training loss: 3.0554931826920413
Validation loss: 2.9419701651806283

Epoch: 5| Step: 10
Training loss: 2.9418886556606263
Validation loss: 2.9433721437058926

Epoch: 178| Step: 0
Training loss: 3.13598228920587
Validation loss: 2.94513166859379

Epoch: 5| Step: 1
Training loss: 3.890917786148519
Validation loss: 2.942975772368317

Epoch: 5| Step: 2
Training loss: 3.353524156402951
Validation loss: 2.9465790192264065

Epoch: 5| Step: 3
Training loss: 2.499859710571832
Validation loss: 2.9457813267457476

Epoch: 5| Step: 4
Training loss: 3.5352773740472183
Validation loss: 2.943382405663892

Epoch: 5| Step: 5
Training loss: 3.5371901251739946
Validation loss: 2.9441659479576403

Epoch: 5| Step: 6
Training loss: 2.41689581168334
Validation loss: 2.942067796386381

Epoch: 5| Step: 7
Training loss: 3.121886266128633
Validation loss: 2.940408663412414

Epoch: 5| Step: 8
Training loss: 3.2608445509351975
Validation loss: 2.940048236569805

Epoch: 5| Step: 9
Training loss: 3.2289920554584626
Validation loss: 2.940948835560182

Epoch: 5| Step: 10
Training loss: 3.246219637159233
Validation loss: 2.937919656541072

Epoch: 179| Step: 0
Training loss: 3.0447229855065108
Validation loss: 2.940244507496307

Epoch: 5| Step: 1
Training loss: 3.1889265271608065
Validation loss: 2.9447649331452577

Epoch: 5| Step: 2
Training loss: 2.4986682205595696
Validation loss: 2.9438866294392145

Epoch: 5| Step: 3
Training loss: 3.183067980453524
Validation loss: 2.9478345487253708

Epoch: 5| Step: 4
Training loss: 3.247484847834407
Validation loss: 2.9421552635827704

Epoch: 5| Step: 5
Training loss: 3.573074841496748
Validation loss: 2.9392381760590665

Epoch: 5| Step: 6
Training loss: 3.207273597249275
Validation loss: 2.9422945818331625

Epoch: 5| Step: 7
Training loss: 3.373736533568828
Validation loss: 2.9366084892674

Epoch: 5| Step: 8
Training loss: 3.485249362600449
Validation loss: 2.9368390256258676

Epoch: 5| Step: 9
Training loss: 3.2339570148562564
Validation loss: 2.9415370670919643

Epoch: 5| Step: 10
Training loss: 3.345632860789835
Validation loss: 2.9375576449122685

Epoch: 180| Step: 0
Training loss: 3.3051217878239574
Validation loss: 2.9429753333314115

Epoch: 5| Step: 1
Training loss: 3.1678739220741137
Validation loss: 2.9376370082331986

Epoch: 5| Step: 2
Training loss: 3.587952158010386
Validation loss: 2.94060290948391

Epoch: 5| Step: 3
Training loss: 3.3007850060074784
Validation loss: 2.9376705384610937

Epoch: 5| Step: 4
Training loss: 3.6965802137231187
Validation loss: 2.9395496877335807

Epoch: 5| Step: 5
Training loss: 3.148678299472548
Validation loss: 2.937094814725631

Epoch: 5| Step: 6
Training loss: 2.878618533950177
Validation loss: 2.937580139840368

Epoch: 5| Step: 7
Training loss: 3.388687635049807
Validation loss: 2.9388679316260835

Epoch: 5| Step: 8
Training loss: 2.4581999553985505
Validation loss: 2.9377794693533796

Epoch: 5| Step: 9
Training loss: 2.873799778398071
Validation loss: 2.9369701316917736

Epoch: 5| Step: 10
Training loss: 3.496447395041359
Validation loss: 2.940301297328766

Epoch: 181| Step: 0
Training loss: 2.8881946141088357
Validation loss: 2.9372000121095083

Epoch: 5| Step: 1
Training loss: 2.570897369164292
Validation loss: 2.934767141957468

Epoch: 5| Step: 2
Training loss: 3.7220202259905983
Validation loss: 2.939621134439851

Epoch: 5| Step: 3
Training loss: 2.83379491150363
Validation loss: 2.939271974103839

Epoch: 5| Step: 4
Training loss: 3.635669921681415
Validation loss: 2.9406375122048223

Epoch: 5| Step: 5
Training loss: 3.114615619879077
Validation loss: 2.931850120263342

Epoch: 5| Step: 6
Training loss: 3.4919153572564805
Validation loss: 2.9344381548100134

Epoch: 5| Step: 7
Training loss: 3.240198025950804
Validation loss: 2.933150486080907

Epoch: 5| Step: 8
Training loss: 3.533462776356153
Validation loss: 2.929907393321443

Epoch: 5| Step: 9
Training loss: 3.343572594045236
Validation loss: 2.931815436564273

Epoch: 5| Step: 10
Training loss: 2.8023461900439353
Validation loss: 2.933381608829586

Epoch: 182| Step: 0
Training loss: 2.7661504731198927
Validation loss: 2.928750408416395

Epoch: 5| Step: 1
Training loss: 3.2473905798352822
Validation loss: 2.9322517654734126

Epoch: 5| Step: 2
Training loss: 3.0749833393420922
Validation loss: 2.9317101395342187

Epoch: 5| Step: 3
Training loss: 3.348021871215043
Validation loss: 2.9295541331791193

Epoch: 5| Step: 4
Training loss: 3.7029760145646256
Validation loss: 2.930606876842705

Epoch: 5| Step: 5
Training loss: 3.035282873706022
Validation loss: 2.9307578768577036

Epoch: 5| Step: 6
Training loss: 3.040979873946883
Validation loss: 2.93061755877995

Epoch: 5| Step: 7
Training loss: 3.584871686397516
Validation loss: 2.9296191013240924

Epoch: 5| Step: 8
Training loss: 3.3332334185566737
Validation loss: 2.9314725211058943

Epoch: 5| Step: 9
Training loss: 3.3223304988889435
Validation loss: 2.9316551027395965

Epoch: 5| Step: 10
Training loss: 2.790344029343605
Validation loss: 2.9352583752944694

Epoch: 183| Step: 0
Training loss: 2.562522608959664
Validation loss: 2.943300882121866

Epoch: 5| Step: 1
Training loss: 3.2685646077493615
Validation loss: 2.961740117724118

Epoch: 5| Step: 2
Training loss: 3.678199937133224
Validation loss: 2.970904202439985

Epoch: 5| Step: 3
Training loss: 3.1333724208855718
Validation loss: 2.97160435897536

Epoch: 5| Step: 4
Training loss: 2.705750441750578
Validation loss: 2.964934667962373

Epoch: 5| Step: 5
Training loss: 3.5222241666075123
Validation loss: 2.94520565302759

Epoch: 5| Step: 6
Training loss: 3.0660053355549413
Validation loss: 2.9285382245384466

Epoch: 5| Step: 7
Training loss: 3.415501620759553
Validation loss: 2.923070641356614

Epoch: 5| Step: 8
Training loss: 3.140077457808969
Validation loss: 2.928687087677108

Epoch: 5| Step: 9
Training loss: 3.7633057095978266
Validation loss: 2.933806377407671

Epoch: 5| Step: 10
Training loss: 3.0180954375550204
Validation loss: 2.937964082223348

Epoch: 184| Step: 0
Training loss: 3.2977334301558074
Validation loss: 2.938339982539115

Epoch: 5| Step: 1
Training loss: 3.595176347378526
Validation loss: 2.944918850814649

Epoch: 5| Step: 2
Training loss: 3.324163093504408
Validation loss: 2.94951253686916

Epoch: 5| Step: 3
Training loss: 3.2001459922866395
Validation loss: 2.9487863044451528

Epoch: 5| Step: 4
Training loss: 2.622618548656631
Validation loss: 2.955087189016296

Epoch: 5| Step: 5
Training loss: 3.2865138384227204
Validation loss: 2.9353209001189695

Epoch: 5| Step: 6
Training loss: 3.688692578935595
Validation loss: 2.9338960919033954

Epoch: 5| Step: 7
Training loss: 3.1053695566901798
Validation loss: 2.9322044642129956

Epoch: 5| Step: 8
Training loss: 2.674233717212032
Validation loss: 2.9308992334774513

Epoch: 5| Step: 9
Training loss: 3.6332322401162465
Validation loss: 2.930667925457113

Epoch: 5| Step: 10
Training loss: 2.8689353666899904
Validation loss: 2.9303393914487676

Epoch: 185| Step: 0
Training loss: 3.0113721516981173
Validation loss: 2.9291917370772547

Epoch: 5| Step: 1
Training loss: 3.2519094286666377
Validation loss: 2.9313768056061438

Epoch: 5| Step: 2
Training loss: 3.471751658448786
Validation loss: 2.927979447556212

Epoch: 5| Step: 3
Training loss: 3.320039625735675
Validation loss: 2.92603752211782

Epoch: 5| Step: 4
Training loss: 2.9933598465230284
Validation loss: 2.9277869689543503

Epoch: 5| Step: 5
Training loss: 3.0548173725588734
Validation loss: 2.922807733355648

Epoch: 5| Step: 6
Training loss: 3.3307856996623477
Validation loss: 2.9294862538336846

Epoch: 5| Step: 7
Training loss: 3.1056287424391633
Validation loss: 2.922177920964922

Epoch: 5| Step: 8
Training loss: 3.454149603408493
Validation loss: 2.9250544788807815

Epoch: 5| Step: 9
Training loss: 3.1991516776966327
Validation loss: 2.9211637297939013

Epoch: 5| Step: 10
Training loss: 3.1133596680839113
Validation loss: 2.9207932498369855

Epoch: 186| Step: 0
Training loss: 3.310605353004904
Validation loss: 2.9177599863253048

Epoch: 5| Step: 1
Training loss: 3.4418385263411544
Validation loss: 2.9173852946421355

Epoch: 5| Step: 2
Training loss: 3.098035830010415
Validation loss: 2.918003627274726

Epoch: 5| Step: 3
Training loss: 2.827461291249736
Validation loss: 2.9181938644090937

Epoch: 5| Step: 4
Training loss: 2.892716099901846
Validation loss: 2.9184022500632603

Epoch: 5| Step: 5
Training loss: 3.2163757159692734
Validation loss: 2.9170692813466754

Epoch: 5| Step: 6
Training loss: 3.924763136598916
Validation loss: 2.92130713641957

Epoch: 5| Step: 7
Training loss: 2.704628057945072
Validation loss: 2.9168838329302686

Epoch: 5| Step: 8
Training loss: 2.699069646976253
Validation loss: 2.9182688910730192

Epoch: 5| Step: 9
Training loss: 3.745603145419124
Validation loss: 2.922194301076417

Epoch: 5| Step: 10
Training loss: 3.169200051153824
Validation loss: 2.9214473084736423

Epoch: 187| Step: 0
Training loss: 3.1064924364254227
Validation loss: 2.9229699338667556

Epoch: 5| Step: 1
Training loss: 3.4009113997572804
Validation loss: 2.9179464948512486

Epoch: 5| Step: 2
Training loss: 3.348380047282572
Validation loss: 2.9136567504524225

Epoch: 5| Step: 3
Training loss: 3.9133766776505428
Validation loss: 2.914502850979029

Epoch: 5| Step: 4
Training loss: 2.512107712216154
Validation loss: 2.9172565186047943

Epoch: 5| Step: 5
Training loss: 3.5504056188397084
Validation loss: 2.913670670850424

Epoch: 5| Step: 6
Training loss: 2.408806866705516
Validation loss: 2.9129123614649264

Epoch: 5| Step: 7
Training loss: 3.3613556456783025
Validation loss: 2.913273452768902

Epoch: 5| Step: 8
Training loss: 3.466819157058675
Validation loss: 2.912903202298179

Epoch: 5| Step: 9
Training loss: 2.645991092894679
Validation loss: 2.913203896063888

Epoch: 5| Step: 10
Training loss: 3.239516736947788
Validation loss: 2.9134719066727324

Epoch: 188| Step: 0
Training loss: 3.2696486512393452
Validation loss: 2.9105130695029753

Epoch: 5| Step: 1
Training loss: 3.1256584999563866
Validation loss: 2.9108698531928106

Epoch: 5| Step: 2
Training loss: 3.58582965630489
Validation loss: 2.911504710149456

Epoch: 5| Step: 3
Training loss: 3.5227489940611285
Validation loss: 2.9102390129707136

Epoch: 5| Step: 4
Training loss: 3.077509939640954
Validation loss: 2.9111678544512847

Epoch: 5| Step: 5
Training loss: 3.1507847368564885
Validation loss: 2.9080211487954406

Epoch: 5| Step: 6
Training loss: 3.239072475243172
Validation loss: 2.911752037073935

Epoch: 5| Step: 7
Training loss: 2.999580830854144
Validation loss: 2.908376380046389

Epoch: 5| Step: 8
Training loss: 3.2409203684439283
Validation loss: 2.9105266358742994

Epoch: 5| Step: 9
Training loss: 3.1272977392474712
Validation loss: 2.9110446509605654

Epoch: 5| Step: 10
Training loss: 2.74515991829069
Validation loss: 2.9105700404388553

Epoch: 189| Step: 0
Training loss: 2.641472584507242
Validation loss: 2.914389364351378

Epoch: 5| Step: 1
Training loss: 3.318844315792511
Validation loss: 2.9135562965448436

Epoch: 5| Step: 2
Training loss: 2.874493761688539
Validation loss: 2.924476694028521

Epoch: 5| Step: 3
Training loss: 3.6126643793530944
Validation loss: 2.927510419813569

Epoch: 5| Step: 4
Training loss: 3.4804577896853237
Validation loss: 2.928318540068947

Epoch: 5| Step: 5
Training loss: 2.9667018852572244
Validation loss: 2.9230107575448754

Epoch: 5| Step: 6
Training loss: 3.4005862403796314
Validation loss: 2.9285973046487253

Epoch: 5| Step: 7
Training loss: 2.8315494943153166
Validation loss: 2.910218301086623

Epoch: 5| Step: 8
Training loss: 3.7861705952299722
Validation loss: 2.906556029432058

Epoch: 5| Step: 9
Training loss: 3.208213671810102
Validation loss: 2.9075888104715157

Epoch: 5| Step: 10
Training loss: 2.859029780325843
Validation loss: 2.908355156864542

Epoch: 190| Step: 0
Training loss: 3.275056352203336
Validation loss: 2.9101429391344436

Epoch: 5| Step: 1
Training loss: 3.1093469359698505
Validation loss: 2.9112878315446555

Epoch: 5| Step: 2
Training loss: 3.2092010183451363
Validation loss: 2.910969609833861

Epoch: 5| Step: 3
Training loss: 3.0691154806188092
Validation loss: 2.912245273132368

Epoch: 5| Step: 4
Training loss: 3.3243217407481396
Validation loss: 2.9120703475928575

Epoch: 5| Step: 5
Training loss: 3.579178834005568
Validation loss: 2.9125513090131183

Epoch: 5| Step: 6
Training loss: 2.4709754281144147
Validation loss: 2.9129239505374924

Epoch: 5| Step: 7
Training loss: 3.025415054725043
Validation loss: 2.912909353297454

Epoch: 5| Step: 8
Training loss: 2.910201636862935
Validation loss: 2.910479615734314

Epoch: 5| Step: 9
Training loss: 3.767072976965238
Validation loss: 2.9109743954598306

Epoch: 5| Step: 10
Training loss: 3.39764170482379
Validation loss: 2.9181998452480555

Epoch: 191| Step: 0
Training loss: 2.542024264168055
Validation loss: 2.918026239558824

Epoch: 5| Step: 1
Training loss: 3.826664237199958
Validation loss: 2.9072638031400255

Epoch: 5| Step: 2
Training loss: 2.9219858077146506
Validation loss: 2.908426929151012

Epoch: 5| Step: 3
Training loss: 3.3194148028197246
Validation loss: 2.90662008631287

Epoch: 5| Step: 4
Training loss: 3.036933368844993
Validation loss: 2.9083775797240543

Epoch: 5| Step: 5
Training loss: 3.3517605382924787
Validation loss: 2.9068964992111463

Epoch: 5| Step: 6
Training loss: 3.1050460047853554
Validation loss: 2.9042090620673173

Epoch: 5| Step: 7
Training loss: 2.8853136909554293
Validation loss: 2.904999707822259

Epoch: 5| Step: 8
Training loss: 3.245608076539591
Validation loss: 2.905186342385221

Epoch: 5| Step: 9
Training loss: 2.6536522223508303
Validation loss: 2.905884953460197

Epoch: 5| Step: 10
Training loss: 4.158400130006172
Validation loss: 2.914882668647502

Epoch: 192| Step: 0
Training loss: 3.2193244495544437
Validation loss: 2.9228085087258493

Epoch: 5| Step: 1
Training loss: 3.275079501985216
Validation loss: 2.922246448191787

Epoch: 5| Step: 2
Training loss: 3.4287643406728363
Validation loss: 2.904115360233056

Epoch: 5| Step: 3
Training loss: 2.7432920834146586
Validation loss: 2.9013439028466803

Epoch: 5| Step: 4
Training loss: 2.9142696521754505
Validation loss: 2.8988763014735848

Epoch: 5| Step: 5
Training loss: 2.3852932383048078
Validation loss: 2.8986893371351115

Epoch: 5| Step: 6
Training loss: 2.7927766747218805
Validation loss: 2.897184335817095

Epoch: 5| Step: 7
Training loss: 3.859982585571221
Validation loss: 2.8970718830696516

Epoch: 5| Step: 8
Training loss: 3.1063898987611003
Validation loss: 2.8984354249843807

Epoch: 5| Step: 9
Training loss: 3.615021091890338
Validation loss: 2.8973148959088784

Epoch: 5| Step: 10
Training loss: 3.6195205843113953
Validation loss: 2.9004784377503796

Epoch: 193| Step: 0
Training loss: 3.3949546067092284
Validation loss: 2.900515879049243

Epoch: 5| Step: 1
Training loss: 3.2858514401734062
Validation loss: 2.9018175981463203

Epoch: 5| Step: 2
Training loss: 3.299466673785462
Validation loss: 2.904650783284143

Epoch: 5| Step: 3
Training loss: 2.8727481149898497
Validation loss: 2.8980019706561357

Epoch: 5| Step: 4
Training loss: 3.541973474714492
Validation loss: 2.8960433388643083

Epoch: 5| Step: 5
Training loss: 3.178839343124621
Validation loss: 2.8957863396117176

Epoch: 5| Step: 6
Training loss: 2.620693670856494
Validation loss: 2.8944893780902348

Epoch: 5| Step: 7
Training loss: 3.5276620917654795
Validation loss: 2.893596696971084

Epoch: 5| Step: 8
Training loss: 2.8214242704058625
Validation loss: 2.8939403293715658

Epoch: 5| Step: 9
Training loss: 3.447049557233608
Validation loss: 2.895102993033181

Epoch: 5| Step: 10
Training loss: 2.9399037367443244
Validation loss: 2.892869970110877

Epoch: 194| Step: 0
Training loss: 3.481101923589281
Validation loss: 2.8940744984981355

Epoch: 5| Step: 1
Training loss: 2.537984766013356
Validation loss: 2.893718013880332

Epoch: 5| Step: 2
Training loss: 3.2785165209287768
Validation loss: 2.8918685388937577

Epoch: 5| Step: 3
Training loss: 3.2690413277745134
Validation loss: 2.894258545612433

Epoch: 5| Step: 4
Training loss: 3.351371564072482
Validation loss: 2.8902852034683604

Epoch: 5| Step: 5
Training loss: 3.03099719694254
Validation loss: 2.8912626831896704

Epoch: 5| Step: 6
Training loss: 3.3221229553985707
Validation loss: 2.8908871803126925

Epoch: 5| Step: 7
Training loss: 2.786971817952686
Validation loss: 2.8908746089993205

Epoch: 5| Step: 8
Training loss: 3.230847337672912
Validation loss: 2.891605000661261

Epoch: 5| Step: 9
Training loss: 3.1970404171028033
Validation loss: 2.8943876965141904

Epoch: 5| Step: 10
Training loss: 3.5368290942324427
Validation loss: 2.89141029925321

Epoch: 195| Step: 0
Training loss: 3.5697464442034703
Validation loss: 2.8921293140761692

Epoch: 5| Step: 1
Training loss: 2.9187290166390576
Validation loss: 2.8917463039567126

Epoch: 5| Step: 2
Training loss: 3.1889809552709867
Validation loss: 2.890742726632261

Epoch: 5| Step: 3
Training loss: 2.947256888344407
Validation loss: 2.8907376733852272

Epoch: 5| Step: 4
Training loss: 2.824730369056033
Validation loss: 2.8898019334465985

Epoch: 5| Step: 5
Training loss: 3.793933875264292
Validation loss: 2.888678050084346

Epoch: 5| Step: 6
Training loss: 2.962991852310416
Validation loss: 2.88833900439695

Epoch: 5| Step: 7
Training loss: 2.870814054190942
Validation loss: 2.8895057788533562

Epoch: 5| Step: 8
Training loss: 2.961991175481928
Validation loss: 2.8860898667270947

Epoch: 5| Step: 9
Training loss: 3.787949609036607
Validation loss: 2.8871553856131875

Epoch: 5| Step: 10
Training loss: 2.989636800644531
Validation loss: 2.8846887849357037

Epoch: 196| Step: 0
Training loss: 4.091906649407562
Validation loss: 2.885795203857851

Epoch: 5| Step: 1
Training loss: 2.9479047867139063
Validation loss: 2.882831070869577

Epoch: 5| Step: 2
Training loss: 2.797003886913317
Validation loss: 2.8828767963349917

Epoch: 5| Step: 3
Training loss: 3.1421485355945173
Validation loss: 2.883739415905114

Epoch: 5| Step: 4
Training loss: 3.201215370166682
Validation loss: 2.882316996971797

Epoch: 5| Step: 5
Training loss: 2.8065810758024594
Validation loss: 2.88500588807352

Epoch: 5| Step: 6
Training loss: 2.9794377734911595
Validation loss: 2.882383340235959

Epoch: 5| Step: 7
Training loss: 3.357396026387553
Validation loss: 2.8853617253812245

Epoch: 5| Step: 8
Training loss: 3.3800739718135815
Validation loss: 2.882296578084285

Epoch: 5| Step: 9
Training loss: 3.1999037012869254
Validation loss: 2.882804001094966

Epoch: 5| Step: 10
Training loss: 2.8603502288533935
Validation loss: 2.881428241686329

Epoch: 197| Step: 0
Training loss: 3.781546967249665
Validation loss: 2.8834382287479134

Epoch: 5| Step: 1
Training loss: 2.7981183575621
Validation loss: 2.884065670645972

Epoch: 5| Step: 2
Training loss: 3.385840067674075
Validation loss: 2.883071538731749

Epoch: 5| Step: 3
Training loss: 2.6915196365810825
Validation loss: 2.8873090132082257

Epoch: 5| Step: 4
Training loss: 3.486408136555603
Validation loss: 2.8891722838175116

Epoch: 5| Step: 5
Training loss: 3.326064640630477
Validation loss: 2.8876484745773987

Epoch: 5| Step: 6
Training loss: 2.9555145768341924
Validation loss: 2.883636292877307

Epoch: 5| Step: 7
Training loss: 2.991378156799561
Validation loss: 2.8832909362974433

Epoch: 5| Step: 8
Training loss: 3.375051851227492
Validation loss: 2.878946416215153

Epoch: 5| Step: 9
Training loss: 2.9644701173189536
Validation loss: 2.88009693421575

Epoch: 5| Step: 10
Training loss: 3.0838345472530695
Validation loss: 2.879141235690391

Epoch: 198| Step: 0
Training loss: 3.0524914743115383
Validation loss: 2.879622288621116

Epoch: 5| Step: 1
Training loss: 3.153269351796714
Validation loss: 2.8800054103106607

Epoch: 5| Step: 2
Training loss: 3.3505331383828105
Validation loss: 2.877620384754513

Epoch: 5| Step: 3
Training loss: 3.5929827327170023
Validation loss: 2.8764242805853355

Epoch: 5| Step: 4
Training loss: 3.017062462260946
Validation loss: 2.876405446426676

Epoch: 5| Step: 5
Training loss: 2.8933406136533963
Validation loss: 2.878903390631388

Epoch: 5| Step: 6
Training loss: 2.6665035038940594
Validation loss: 2.883957879953242

Epoch: 5| Step: 7
Training loss: 3.311853741636797
Validation loss: 2.883938708306615

Epoch: 5| Step: 8
Training loss: 3.5494155187724
Validation loss: 2.883479300929781

Epoch: 5| Step: 9
Training loss: 3.122178596955046
Validation loss: 2.8830514292983245

Epoch: 5| Step: 10
Training loss: 3.150914734524818
Validation loss: 2.882204081567169

Epoch: 199| Step: 0
Training loss: 2.9841989195642302
Validation loss: 2.8789723236876332

Epoch: 5| Step: 1
Training loss: 2.8036371245943736
Validation loss: 2.8802271625029645

Epoch: 5| Step: 2
Training loss: 3.0125525442265855
Validation loss: 2.8803371310227197

Epoch: 5| Step: 3
Training loss: 3.2403281154030052
Validation loss: 2.87649477657006

Epoch: 5| Step: 4
Training loss: 3.3972011378013387
Validation loss: 2.878134211731162

Epoch: 5| Step: 5
Training loss: 3.188446502777523
Validation loss: 2.8738043101278934

Epoch: 5| Step: 6
Training loss: 3.4561436779921064
Validation loss: 2.8748443226087406

Epoch: 5| Step: 7
Training loss: 3.871330862164605
Validation loss: 2.8734060437057374

Epoch: 5| Step: 8
Training loss: 3.100980228374573
Validation loss: 2.871775476985074

Epoch: 5| Step: 9
Training loss: 2.938090488253057
Validation loss: 2.8723383090310426

Epoch: 5| Step: 10
Training loss: 2.6770248307739095
Validation loss: 2.8731700767934845

Epoch: 200| Step: 0
Training loss: 3.118718356963879
Validation loss: 2.8730519183163064

Epoch: 5| Step: 1
Training loss: 3.6418762676288527
Validation loss: 2.8734046732927516

Epoch: 5| Step: 2
Training loss: 3.2625488686829556
Validation loss: 2.873237924128339

Epoch: 5| Step: 3
Training loss: 3.1229196872064606
Validation loss: 2.871321951965036

Epoch: 5| Step: 4
Training loss: 2.7758639185089007
Validation loss: 2.8719185182572904

Epoch: 5| Step: 5
Training loss: 3.1768067453194146
Validation loss: 2.8704331665551797

Epoch: 5| Step: 6
Training loss: 3.241762432131916
Validation loss: 2.8703497970787035

Epoch: 5| Step: 7
Training loss: 3.6079592880185087
Validation loss: 2.871560347307144

Epoch: 5| Step: 8
Training loss: 2.602152622869204
Validation loss: 2.870886373881984

Epoch: 5| Step: 9
Training loss: 3.020623210746224
Validation loss: 2.8714283662032094

Epoch: 5| Step: 10
Training loss: 3.1846797658762553
Validation loss: 2.8713690758489734

Epoch: 201| Step: 0
Training loss: 3.9529300686869844
Validation loss: 2.876522181999284

Epoch: 5| Step: 1
Training loss: 3.432333236388576
Validation loss: 2.874528689316345

Epoch: 5| Step: 2
Training loss: 3.0350390476687483
Validation loss: 2.8757138286763366

Epoch: 5| Step: 3
Training loss: 2.7362978904300825
Validation loss: 2.8770008962452907

Epoch: 5| Step: 4
Training loss: 2.692459586857632
Validation loss: 2.880683428197333

Epoch: 5| Step: 5
Training loss: 3.3904897073922253
Validation loss: 2.876735675167366

Epoch: 5| Step: 6
Training loss: 2.4057983370874854
Validation loss: 2.8862660621847698

Epoch: 5| Step: 7
Training loss: 2.8084060542560927
Validation loss: 2.8789354918009957

Epoch: 5| Step: 8
Training loss: 3.761130535526976
Validation loss: 2.8843449107034433

Epoch: 5| Step: 9
Training loss: 3.4386281329753654
Validation loss: 2.8782870569495778

Epoch: 5| Step: 10
Training loss: 2.7913409844964727
Validation loss: 2.8736017758629506

Epoch: 202| Step: 0
Training loss: 2.631315898296595
Validation loss: 2.8821169742305006

Epoch: 5| Step: 1
Training loss: 2.91123141710731
Validation loss: 2.8741751286029085

Epoch: 5| Step: 2
Training loss: 3.2567494073493752
Validation loss: 2.870178801916749

Epoch: 5| Step: 3
Training loss: 3.4907996643681702
Validation loss: 2.8663841700983355

Epoch: 5| Step: 4
Training loss: 3.4649560473628305
Validation loss: 2.86810171922169

Epoch: 5| Step: 5
Training loss: 3.7605284078098418
Validation loss: 2.8666158269803543

Epoch: 5| Step: 6
Training loss: 2.870947926250014
Validation loss: 2.867646670925728

Epoch: 5| Step: 7
Training loss: 3.5581579684806166
Validation loss: 2.8646504885202835

Epoch: 5| Step: 8
Training loss: 2.7991527467612283
Validation loss: 2.8657225690276844

Epoch: 5| Step: 9
Training loss: 3.1842422292955512
Validation loss: 2.8651567641761235

Epoch: 5| Step: 10
Training loss: 2.604267901678116
Validation loss: 2.8674376436370093

Epoch: 203| Step: 0
Training loss: 2.9425578301126265
Validation loss: 2.866601533202288

Epoch: 5| Step: 1
Training loss: 3.2635094027482396
Validation loss: 2.8685069799341387

Epoch: 5| Step: 2
Training loss: 3.058442054777105
Validation loss: 2.864917021675814

Epoch: 5| Step: 3
Training loss: 3.1974302702720436
Validation loss: 2.8645023248727512

Epoch: 5| Step: 4
Training loss: 3.026133042934907
Validation loss: 2.863914259170301

Epoch: 5| Step: 5
Training loss: 3.9434542972803386
Validation loss: 2.8654562834724246

Epoch: 5| Step: 6
Training loss: 2.738423516554382
Validation loss: 2.8665622859828335

Epoch: 5| Step: 7
Training loss: 2.7049126860228907
Validation loss: 2.869028745806624

Epoch: 5| Step: 8
Training loss: 3.6030150026998466
Validation loss: 2.865619683314151

Epoch: 5| Step: 9
Training loss: 3.014889800428538
Validation loss: 2.8695090845051987

Epoch: 5| Step: 10
Training loss: 3.146184299587781
Validation loss: 2.8704732780704365

Epoch: 204| Step: 0
Training loss: 3.3434559345173924
Validation loss: 2.8657392270999082

Epoch: 5| Step: 1
Training loss: 2.964751431883699
Validation loss: 2.8667998645207424

Epoch: 5| Step: 2
Training loss: 3.443269084713841
Validation loss: 2.865839851569809

Epoch: 5| Step: 3
Training loss: 3.365575701140871
Validation loss: 2.8627693913934973

Epoch: 5| Step: 4
Training loss: 3.124624306029928
Validation loss: 2.863875582940778

Epoch: 5| Step: 5
Training loss: 3.0660510592454897
Validation loss: 2.864035229791725

Epoch: 5| Step: 6
Training loss: 2.8343000071907913
Validation loss: 2.8612123124286826

Epoch: 5| Step: 7
Training loss: 3.062664261130137
Validation loss: 2.8651072814809826

Epoch: 5| Step: 8
Training loss: 3.0503970403673413
Validation loss: 2.86571297634595

Epoch: 5| Step: 9
Training loss: 3.5329252337252037
Validation loss: 2.865735201475087

Epoch: 5| Step: 10
Training loss: 2.9149641426720785
Validation loss: 2.8627042915026166

Epoch: 205| Step: 0
Training loss: 2.889137668983068
Validation loss: 2.8615542406911936

Epoch: 5| Step: 1
Training loss: 3.1234030648681
Validation loss: 2.86014336090514

Epoch: 5| Step: 2
Training loss: 2.6524491886086405
Validation loss: 2.857974084857118

Epoch: 5| Step: 3
Training loss: 3.8632642168955904
Validation loss: 2.8593076163074507

Epoch: 5| Step: 4
Training loss: 3.2798182679050067
Validation loss: 2.857387721593339

Epoch: 5| Step: 5
Training loss: 3.3463840270534635
Validation loss: 2.8583203809603686

Epoch: 5| Step: 6
Training loss: 3.295235899843912
Validation loss: 2.85548099417393

Epoch: 5| Step: 7
Training loss: 3.274017501103832
Validation loss: 2.857212381425292

Epoch: 5| Step: 8
Training loss: 2.8366365438162617
Validation loss: 2.85633655757204

Epoch: 5| Step: 9
Training loss: 2.7863610271445602
Validation loss: 2.8579043896654848

Epoch: 5| Step: 10
Training loss: 3.299175165147299
Validation loss: 2.857594510020588

Epoch: 206| Step: 0
Training loss: 3.4331708523966014
Validation loss: 2.856460919866492

Epoch: 5| Step: 1
Training loss: 3.300969334045914
Validation loss: 2.8590204288136283

Epoch: 5| Step: 2
Training loss: 3.2095338301093217
Validation loss: 2.864618893101529

Epoch: 5| Step: 3
Training loss: 2.6572055668616508
Validation loss: 2.8703038943805432

Epoch: 5| Step: 4
Training loss: 2.7598941716346745
Validation loss: 2.8782432911384763

Epoch: 5| Step: 5
Training loss: 3.3603341086349245
Validation loss: 2.882873228602716

Epoch: 5| Step: 6
Training loss: 2.7867065224086502
Validation loss: 2.8640794100851106

Epoch: 5| Step: 7
Training loss: 3.8791714027340363
Validation loss: 2.8581462793042056

Epoch: 5| Step: 8
Training loss: 2.9786555423079184
Validation loss: 2.8577949062248473

Epoch: 5| Step: 9
Training loss: 3.265019410851161
Validation loss: 2.8551882607239154

Epoch: 5| Step: 10
Training loss: 2.9047531046648456
Validation loss: 2.853696437825311

Epoch: 207| Step: 0
Training loss: 3.2677997849111162
Validation loss: 2.857623878396087

Epoch: 5| Step: 1
Training loss: 2.6975863830197837
Validation loss: 2.8560840997503343

Epoch: 5| Step: 2
Training loss: 3.0466879762812757
Validation loss: 2.854709382925835

Epoch: 5| Step: 3
Training loss: 3.299916243212733
Validation loss: 2.857581901693952

Epoch: 5| Step: 4
Training loss: 3.0094668111927896
Validation loss: 2.856731289821273

Epoch: 5| Step: 5
Training loss: 2.7662005499114346
Validation loss: 2.8554407977493548

Epoch: 5| Step: 6
Training loss: 3.244472057262766
Validation loss: 2.861036021174494

Epoch: 5| Step: 7
Training loss: 3.603971589970359
Validation loss: 2.8622296108303007

Epoch: 5| Step: 8
Training loss: 3.6569841740020377
Validation loss: 2.8652042811470477

Epoch: 5| Step: 9
Training loss: 3.357000176896496
Validation loss: 2.866264209579628

Epoch: 5| Step: 10
Training loss: 2.469412895728672
Validation loss: 2.8572302546369808

Epoch: 208| Step: 0
Training loss: 3.131202036476935
Validation loss: 2.856666965009567

Epoch: 5| Step: 1
Training loss: 3.398091756838038
Validation loss: 2.851862110328339

Epoch: 5| Step: 2
Training loss: 3.3334820396313707
Validation loss: 2.8511083358389855

Epoch: 5| Step: 3
Training loss: 3.1030334520617493
Validation loss: 2.850989454550997

Epoch: 5| Step: 4
Training loss: 3.0519726486880323
Validation loss: 2.8513166082509596

Epoch: 5| Step: 5
Training loss: 3.2887087380268594
Validation loss: 2.852123060319568

Epoch: 5| Step: 6
Training loss: 2.7785235982582335
Validation loss: 2.8528050862933303

Epoch: 5| Step: 7
Training loss: 3.6392078179007745
Validation loss: 2.850259385307645

Epoch: 5| Step: 8
Training loss: 2.9912954250637505
Validation loss: 2.8490131007944726

Epoch: 5| Step: 9
Training loss: 2.474851769526395
Validation loss: 2.851804617417792

Epoch: 5| Step: 10
Training loss: 3.4202161974918264
Validation loss: 2.850785535013416

Epoch: 209| Step: 0
Training loss: 2.9267719867962576
Validation loss: 2.853070592874224

Epoch: 5| Step: 1
Training loss: 3.3484877062374356
Validation loss: 2.855158592538758

Epoch: 5| Step: 2
Training loss: 2.376881907892132
Validation loss: 2.852281791623078

Epoch: 5| Step: 3
Training loss: 3.699776596335645
Validation loss: 2.8472756994470823

Epoch: 5| Step: 4
Training loss: 3.305340930015428
Validation loss: 2.8496597763406455

Epoch: 5| Step: 5
Training loss: 3.483049491256896
Validation loss: 2.8536918463145757

Epoch: 5| Step: 6
Training loss: 3.5854934716665947
Validation loss: 2.8523419514969004

Epoch: 5| Step: 7
Training loss: 3.0468440127631005
Validation loss: 2.859681848461807

Epoch: 5| Step: 8
Training loss: 2.431180538175662
Validation loss: 2.852129093417503

Epoch: 5| Step: 9
Training loss: 3.1650761240502123
Validation loss: 2.8468723169819348

Epoch: 5| Step: 10
Training loss: 2.9903037413880345
Validation loss: 2.8480797078097426

Epoch: 210| Step: 0
Training loss: 3.370544176623387
Validation loss: 2.8472765998306424

Epoch: 5| Step: 1
Training loss: 3.6353619561364208
Validation loss: 2.846266952349522

Epoch: 5| Step: 2
Training loss: 3.183885656910709
Validation loss: 2.8467587116151285

Epoch: 5| Step: 3
Training loss: 3.611086088892654
Validation loss: 2.8434113241443453

Epoch: 5| Step: 4
Training loss: 3.100092388129974
Validation loss: 2.8441649247723584

Epoch: 5| Step: 5
Training loss: 3.1210714442061187
Validation loss: 2.84197230478211

Epoch: 5| Step: 6
Training loss: 3.0186066587547176
Validation loss: 2.843831405186681

Epoch: 5| Step: 7
Training loss: 3.2450096257188976
Validation loss: 2.842689192797615

Epoch: 5| Step: 8
Training loss: 2.577825817897364
Validation loss: 2.8448492299100274

Epoch: 5| Step: 9
Training loss: 2.449038655597107
Validation loss: 2.845569241885546

Epoch: 5| Step: 10
Training loss: 3.1405627495968416
Validation loss: 2.843831967706525

Epoch: 211| Step: 0
Training loss: 2.579260835998082
Validation loss: 2.8441276150832238

Epoch: 5| Step: 1
Training loss: 3.028118915374595
Validation loss: 2.8464662294724965

Epoch: 5| Step: 2
Training loss: 3.3583416436205353
Validation loss: 2.844649024812564

Epoch: 5| Step: 3
Training loss: 3.368214036986099
Validation loss: 2.8467335240985867

Epoch: 5| Step: 4
Training loss: 2.773640799794631
Validation loss: 2.8438111165360063

Epoch: 5| Step: 5
Training loss: 2.910734756625085
Validation loss: 2.845022380032997

Epoch: 5| Step: 6
Training loss: 3.686530551524593
Validation loss: 2.8410610037689947

Epoch: 5| Step: 7
Training loss: 3.345504728136896
Validation loss: 2.83995032729368

Epoch: 5| Step: 8
Training loss: 2.860170681001903
Validation loss: 2.840404347683334

Epoch: 5| Step: 9
Training loss: 3.1291154846258853
Validation loss: 2.839441077732103

Epoch: 5| Step: 10
Training loss: 3.455747273255637
Validation loss: 2.8394269279487308

Epoch: 212| Step: 0
Training loss: 3.254908889221975
Validation loss: 2.841311714265064

Epoch: 5| Step: 1
Training loss: 2.960931380373788
Validation loss: 2.8364281488260836

Epoch: 5| Step: 2
Training loss: 3.5976045586168395
Validation loss: 2.838301250703799

Epoch: 5| Step: 3
Training loss: 2.9857618694463963
Validation loss: 2.8371669746423995

Epoch: 5| Step: 4
Training loss: 3.2295785620725552
Validation loss: 2.8398960235831416

Epoch: 5| Step: 5
Training loss: 2.7738264643894217
Validation loss: 2.8444913997281374

Epoch: 5| Step: 6
Training loss: 2.8838456119582476
Validation loss: 2.8507376302228202

Epoch: 5| Step: 7
Training loss: 3.0635800695276805
Validation loss: 2.8473172113350618

Epoch: 5| Step: 8
Training loss: 3.232332035902225
Validation loss: 2.842454499571475

Epoch: 5| Step: 9
Training loss: 3.7380965455284065
Validation loss: 2.840515372355759

Epoch: 5| Step: 10
Training loss: 2.6396669534647024
Validation loss: 2.836505070700099

Epoch: 213| Step: 0
Training loss: 3.5453670842157967
Validation loss: 2.8343488374172323

Epoch: 5| Step: 1
Training loss: 3.7287213931647183
Validation loss: 2.8361381302274027

Epoch: 5| Step: 2
Training loss: 3.350695375608184
Validation loss: 2.8365235624408585

Epoch: 5| Step: 3
Training loss: 2.8121206239628203
Validation loss: 2.838461130668105

Epoch: 5| Step: 4
Training loss: 2.5807248964604765
Validation loss: 2.8362300501223094

Epoch: 5| Step: 5
Training loss: 3.217965039581953
Validation loss: 2.8357731311533008

Epoch: 5| Step: 6
Training loss: 3.2040904009158684
Validation loss: 2.8385519529714913

Epoch: 5| Step: 7
Training loss: 3.5534180103492488
Validation loss: 2.8352960367143276

Epoch: 5| Step: 8
Training loss: 2.78752859126597
Validation loss: 2.833558186458591

Epoch: 5| Step: 9
Training loss: 2.688831620442839
Validation loss: 2.8372820600770643

Epoch: 5| Step: 10
Training loss: 2.8970590279898882
Validation loss: 2.8428100038441793

Epoch: 214| Step: 0
Training loss: 2.986615363628405
Validation loss: 2.8630439471829403

Epoch: 5| Step: 1
Training loss: 3.1659639649644804
Validation loss: 2.872288888471362

Epoch: 5| Step: 2
Training loss: 3.2196911667280212
Validation loss: 2.8764597382370836

Epoch: 5| Step: 3
Training loss: 3.298777533008292
Validation loss: 2.875615644769797

Epoch: 5| Step: 4
Training loss: 3.4141911323110867
Validation loss: 2.8507505853691257

Epoch: 5| Step: 5
Training loss: 3.0747060619762845
Validation loss: 2.8357290500215675

Epoch: 5| Step: 6
Training loss: 2.7939728752518023
Validation loss: 2.8317999813599584

Epoch: 5| Step: 7
Training loss: 2.8076507300985463
Validation loss: 2.831537510622528

Epoch: 5| Step: 8
Training loss: 3.256804166121267
Validation loss: 2.8311967427431943

Epoch: 5| Step: 9
Training loss: 3.8466666716030744
Validation loss: 2.8306807325666528

Epoch: 5| Step: 10
Training loss: 2.5235920672717826
Validation loss: 2.832343810601743

Epoch: 215| Step: 0
Training loss: 3.3699200864649828
Validation loss: 2.831567286872919

Epoch: 5| Step: 1
Training loss: 3.119723022588848
Validation loss: 2.832013129040909

Epoch: 5| Step: 2
Training loss: 3.733018189707559
Validation loss: 2.835785318886719

Epoch: 5| Step: 3
Training loss: 2.55645961135245
Validation loss: 2.8326714524955467

Epoch: 5| Step: 4
Training loss: 3.305481294568934
Validation loss: 2.8327490881614947

Epoch: 5| Step: 5
Training loss: 2.9070584393044543
Validation loss: 2.8298324083904696

Epoch: 5| Step: 6
Training loss: 3.4861594792455906
Validation loss: 2.8286896484546884

Epoch: 5| Step: 7
Training loss: 3.1331493168086415
Validation loss: 2.827310125090045

Epoch: 5| Step: 8
Training loss: 2.9853073181727114
Validation loss: 2.826213003844743

Epoch: 5| Step: 9
Training loss: 3.0050497470489184
Validation loss: 2.8254932719591848

Epoch: 5| Step: 10
Training loss: 2.782160234982902
Validation loss: 2.827785193466098

Epoch: 216| Step: 0
Training loss: 3.9290300126379742
Validation loss: 2.8288118476441952

Epoch: 5| Step: 1
Training loss: 3.464355296698815
Validation loss: 2.833822867384217

Epoch: 5| Step: 2
Training loss: 2.910208027014228
Validation loss: 2.8337371298356326

Epoch: 5| Step: 3
Training loss: 2.7646521457443782
Validation loss: 2.8429629735424107

Epoch: 5| Step: 4
Training loss: 3.207459433961373
Validation loss: 2.851434338575326

Epoch: 5| Step: 5
Training loss: 3.677159828204459
Validation loss: 2.8531451674656796

Epoch: 5| Step: 6
Training loss: 2.5740811162110786
Validation loss: 2.8514179511693443

Epoch: 5| Step: 7
Training loss: 2.8172395401991595
Validation loss: 2.841987049880452

Epoch: 5| Step: 8
Training loss: 3.2319146717818388
Validation loss: 2.840474980393838

Epoch: 5| Step: 9
Training loss: 2.9068494609202156
Validation loss: 2.8273265134961645

Epoch: 5| Step: 10
Training loss: 2.691469233292208
Validation loss: 2.824707097956948

Epoch: 217| Step: 0
Training loss: 3.8502437663005864
Validation loss: 2.8257088514096527

Epoch: 5| Step: 1
Training loss: 3.5858924214640053
Validation loss: 2.819720561574472

Epoch: 5| Step: 2
Training loss: 2.481337699973753
Validation loss: 2.824568356805972

Epoch: 5| Step: 3
Training loss: 3.2951337365200724
Validation loss: 2.824249995862171

Epoch: 5| Step: 4
Training loss: 2.6641245188723603
Validation loss: 2.8225452451346515

Epoch: 5| Step: 5
Training loss: 2.7090798645131877
Validation loss: 2.8232758350340625

Epoch: 5| Step: 6
Training loss: 2.8227693207258375
Validation loss: 2.823313648190943

Epoch: 5| Step: 7
Training loss: 3.398906666609178
Validation loss: 2.8202897714801134

Epoch: 5| Step: 8
Training loss: 3.5363020415267488
Validation loss: 2.8266825102222572

Epoch: 5| Step: 9
Training loss: 2.198983052769991
Validation loss: 2.825386669243233

Epoch: 5| Step: 10
Training loss: 3.5407849429738225
Validation loss: 2.82704259817532

Epoch: 218| Step: 0
Training loss: 3.238367537394571
Validation loss: 2.838335018683374

Epoch: 5| Step: 1
Training loss: 2.984288878471462
Validation loss: 2.852022171224621

Epoch: 5| Step: 2
Training loss: 2.923984357778976
Validation loss: 2.8476366097864125

Epoch: 5| Step: 3
Training loss: 3.156780689305726
Validation loss: 2.8575015835351265

Epoch: 5| Step: 4
Training loss: 3.5516697408829025
Validation loss: 2.8519429747398

Epoch: 5| Step: 5
Training loss: 3.309210817696859
Validation loss: 2.8428982100524642

Epoch: 5| Step: 6
Training loss: 3.950278603108304
Validation loss: 2.8369906386565957

Epoch: 5| Step: 7
Training loss: 2.6648261354569374
Validation loss: 2.8311228378161513

Epoch: 5| Step: 8
Training loss: 3.172924751243052
Validation loss: 2.8219098441660773

Epoch: 5| Step: 9
Training loss: 2.4092492571722035
Validation loss: 2.819103703772589

Epoch: 5| Step: 10
Training loss: 2.7610950332197373
Validation loss: 2.8189937956058855

Epoch: 219| Step: 0
Training loss: 3.4001642860663677
Validation loss: 2.818204749635984

Epoch: 5| Step: 1
Training loss: 3.4538453330358747
Validation loss: 2.818392946205383

Epoch: 5| Step: 2
Training loss: 2.691752772730429
Validation loss: 2.8192267567670672

Epoch: 5| Step: 3
Training loss: 2.6580053475916725
Validation loss: 2.819773940083949

Epoch: 5| Step: 4
Training loss: 3.3071738555029824
Validation loss: 2.817868886169798

Epoch: 5| Step: 5
Training loss: 3.3550330202208833
Validation loss: 2.8186842549272466

Epoch: 5| Step: 6
Training loss: 3.016058381717149
Validation loss: 2.8213826910301076

Epoch: 5| Step: 7
Training loss: 2.847864214049722
Validation loss: 2.8181032184575643

Epoch: 5| Step: 8
Training loss: 3.107100838813989
Validation loss: 2.8168794077115966

Epoch: 5| Step: 9
Training loss: 3.130980148413321
Validation loss: 2.8156678620243287

Epoch: 5| Step: 10
Training loss: 3.4160915604052926
Validation loss: 2.8178384293015646

Epoch: 220| Step: 0
Training loss: 2.87355818046479
Validation loss: 2.8152071249175146

Epoch: 5| Step: 1
Training loss: 3.584834176329129
Validation loss: 2.81453345290174

Epoch: 5| Step: 2
Training loss: 2.8993852818860386
Validation loss: 2.81593097074424

Epoch: 5| Step: 3
Training loss: 3.237816789953937
Validation loss: 2.8171632607352226

Epoch: 5| Step: 4
Training loss: 2.891518284694506
Validation loss: 2.8168637985512466

Epoch: 5| Step: 5
Training loss: 3.3883732644908826
Validation loss: 2.8197605571388946

Epoch: 5| Step: 6
Training loss: 2.941145562402222
Validation loss: 2.81973093623708

Epoch: 5| Step: 7
Training loss: 2.8633048979028572
Validation loss: 2.825072144699632

Epoch: 5| Step: 8
Training loss: 3.193603655603186
Validation loss: 2.8221979548059832

Epoch: 5| Step: 9
Training loss: 2.848968078113095
Validation loss: 2.8234365413123053

Epoch: 5| Step: 10
Training loss: 3.637939117249351
Validation loss: 2.822034982303007

Epoch: 221| Step: 0
Training loss: 2.610398417350951
Validation loss: 2.8208177759466735

Epoch: 5| Step: 1
Training loss: 3.1810313391342437
Validation loss: 2.8194049839381066

Epoch: 5| Step: 2
Training loss: 2.9356860789620245
Validation loss: 2.816016420161057

Epoch: 5| Step: 3
Training loss: 3.584938192646112
Validation loss: 2.8145287200789957

Epoch: 5| Step: 4
Training loss: 3.28568687190591
Validation loss: 2.8131509544850846

Epoch: 5| Step: 5
Training loss: 3.412506936314279
Validation loss: 2.8107179508433235

Epoch: 5| Step: 6
Training loss: 2.9738167341007378
Validation loss: 2.811388347977931

Epoch: 5| Step: 7
Training loss: 3.247843100004385
Validation loss: 2.811636940215509

Epoch: 5| Step: 8
Training loss: 3.305078505883591
Validation loss: 2.8089788620322484

Epoch: 5| Step: 9
Training loss: 2.7472831136471467
Validation loss: 2.80998090184366

Epoch: 5| Step: 10
Training loss: 2.981062883626861
Validation loss: 2.8109533088223713

Epoch: 222| Step: 0
Training loss: 2.910190822728782
Validation loss: 2.81194268815488

Epoch: 5| Step: 1
Training loss: 3.4711496112114046
Validation loss: 2.8105216457269266

Epoch: 5| Step: 2
Training loss: 3.5668411574655705
Validation loss: 2.809017301152942

Epoch: 5| Step: 3
Training loss: 3.4652963577074796
Validation loss: 2.8111028010499397

Epoch: 5| Step: 4
Training loss: 2.6024106221237604
Validation loss: 2.8106600267674664

Epoch: 5| Step: 5
Training loss: 3.0747812767085025
Validation loss: 2.8100141233713245

Epoch: 5| Step: 6
Training loss: 2.5555934407932033
Validation loss: 2.808125342995445

Epoch: 5| Step: 7
Training loss: 3.000561184847133
Validation loss: 2.808165663011045

Epoch: 5| Step: 8
Training loss: 3.5665752458591142
Validation loss: 2.812814051004014

Epoch: 5| Step: 9
Training loss: 2.666907617491535
Validation loss: 2.81021655052778

Epoch: 5| Step: 10
Training loss: 3.2471943996496746
Validation loss: 2.817247303255093

Epoch: 223| Step: 0
Training loss: 3.704844916388834
Validation loss: 2.8108904208144927

Epoch: 5| Step: 1
Training loss: 2.7491374830639796
Validation loss: 2.8132445449399093

Epoch: 5| Step: 2
Training loss: 2.5354047985525296
Validation loss: 2.8186517859006055

Epoch: 5| Step: 3
Training loss: 3.050870808594632
Validation loss: 2.8139827998783455

Epoch: 5| Step: 4
Training loss: 3.5079174408370153
Validation loss: 2.813600370936512

Epoch: 5| Step: 5
Training loss: 3.146078357038408
Validation loss: 2.8145193773760933

Epoch: 5| Step: 6
Training loss: 3.0867798247169
Validation loss: 2.8085105174315528

Epoch: 5| Step: 7
Training loss: 3.744809436711721
Validation loss: 2.8085605153223927

Epoch: 5| Step: 8
Training loss: 2.7960428886125723
Validation loss: 2.80709404093466

Epoch: 5| Step: 9
Training loss: 3.2058806684420627
Validation loss: 2.804361224373627

Epoch: 5| Step: 10
Training loss: 2.3386996979760424
Validation loss: 2.8057161989670383

Epoch: 224| Step: 0
Training loss: 3.3116608042505904
Validation loss: 2.80660929818561

Epoch: 5| Step: 1
Training loss: 3.2025680429941414
Validation loss: 2.809231697431956

Epoch: 5| Step: 2
Training loss: 2.8953716175283732
Validation loss: 2.803050833486285

Epoch: 5| Step: 3
Training loss: 3.02031536704064
Validation loss: 2.804301315951411

Epoch: 5| Step: 4
Training loss: 3.000164504309302
Validation loss: 2.80497529441414

Epoch: 5| Step: 5
Training loss: 3.066560816665727
Validation loss: 2.80466896288886

Epoch: 5| Step: 6
Training loss: 3.2656385795639458
Validation loss: 2.8032025103794815

Epoch: 5| Step: 7
Training loss: 2.6130724996034065
Validation loss: 2.80527921918761

Epoch: 5| Step: 8
Training loss: 3.192395807416577
Validation loss: 2.809432517455547

Epoch: 5| Step: 9
Training loss: 3.2659573180568575
Validation loss: 2.8092400036968286

Epoch: 5| Step: 10
Training loss: 3.4316135290353853
Validation loss: 2.814450035279396

Epoch: 225| Step: 0
Training loss: 2.0163324578316373
Validation loss: 2.812121472699198

Epoch: 5| Step: 1
Training loss: 2.2809815967424494
Validation loss: 2.8135730050184202

Epoch: 5| Step: 2
Training loss: 3.007736403258167
Validation loss: 2.8206302828635548

Epoch: 5| Step: 3
Training loss: 3.298834340534035
Validation loss: 2.832281900812422

Epoch: 5| Step: 4
Training loss: 3.2686025378369274
Validation loss: 2.822909551580564

Epoch: 5| Step: 5
Training loss: 3.3868798170321206
Validation loss: 2.823750961146592

Epoch: 5| Step: 6
Training loss: 3.7129314647116107
Validation loss: 2.8083327262509936

Epoch: 5| Step: 7
Training loss: 3.1095127094387527
Validation loss: 2.8037206408210458

Epoch: 5| Step: 8
Training loss: 3.3887792388881626
Validation loss: 2.8117174379262795

Epoch: 5| Step: 9
Training loss: 3.2008456424104685
Validation loss: 2.8016286190468094

Epoch: 5| Step: 10
Training loss: 3.2125586062774154
Validation loss: 2.798814834253916

Epoch: 226| Step: 0
Training loss: 3.074690863724466
Validation loss: 2.8007038064729994

Epoch: 5| Step: 1
Training loss: 3.458096339060288
Validation loss: 2.801260041368251

Epoch: 5| Step: 2
Training loss: 2.6818532838566713
Validation loss: 2.8004032689509177

Epoch: 5| Step: 3
Training loss: 3.3233723263252894
Validation loss: 2.7967865155892873

Epoch: 5| Step: 4
Training loss: 2.5860513621729617
Validation loss: 2.8001016984729663

Epoch: 5| Step: 5
Training loss: 3.0548364159074217
Validation loss: 2.7995494018504887

Epoch: 5| Step: 6
Training loss: 3.6292009675382766
Validation loss: 2.8003546734796427

Epoch: 5| Step: 7
Training loss: 3.2591058373063997
Validation loss: 2.8003715867364383

Epoch: 5| Step: 8
Training loss: 2.846807324539931
Validation loss: 2.797630335930928

Epoch: 5| Step: 9
Training loss: 2.970918525947385
Validation loss: 2.797954124514103

Epoch: 5| Step: 10
Training loss: 3.241537962044406
Validation loss: 2.7957595339619044

Epoch: 227| Step: 0
Training loss: 3.1297287830176312
Validation loss: 2.7968928655678345

Epoch: 5| Step: 1
Training loss: 3.5385333543525803
Validation loss: 2.797592352490318

Epoch: 5| Step: 2
Training loss: 3.319744465427251
Validation loss: 2.795585237322079

Epoch: 5| Step: 3
Training loss: 2.845980262221455
Validation loss: 2.7971046304449154

Epoch: 5| Step: 4
Training loss: 2.7204337332418977
Validation loss: 2.795245111535745

Epoch: 5| Step: 5
Training loss: 2.445925699685366
Validation loss: 2.796049331533052

Epoch: 5| Step: 6
Training loss: 3.009077009458638
Validation loss: 2.794969975148815

Epoch: 5| Step: 7
Training loss: 3.8293202305421716
Validation loss: 2.7940478692611808

Epoch: 5| Step: 8
Training loss: 2.9429384574819717
Validation loss: 2.7992106836596156

Epoch: 5| Step: 9
Training loss: 3.2224656667130733
Validation loss: 2.800336095785726

Epoch: 5| Step: 10
Training loss: 2.970687073633493
Validation loss: 2.804116894777723

Epoch: 228| Step: 0
Training loss: 2.6061797537359084
Validation loss: 2.799597982912443

Epoch: 5| Step: 1
Training loss: 3.447096866442924
Validation loss: 2.8016729164462544

Epoch: 5| Step: 2
Training loss: 2.952375367301428
Validation loss: 2.801226662024453

Epoch: 5| Step: 3
Training loss: 3.137542730397596
Validation loss: 2.8017541359813567

Epoch: 5| Step: 4
Training loss: 3.2066842006381093
Validation loss: 2.7950492101755997

Epoch: 5| Step: 5
Training loss: 3.23864802916645
Validation loss: 2.7951829431954547

Epoch: 5| Step: 6
Training loss: 3.0478341964720737
Validation loss: 2.791494666947401

Epoch: 5| Step: 7
Training loss: 3.545518388818027
Validation loss: 2.792370840242944

Epoch: 5| Step: 8
Training loss: 3.0748433080929067
Validation loss: 2.7918492384380875

Epoch: 5| Step: 9
Training loss: 2.9239915331967112
Validation loss: 2.7938952530980297

Epoch: 5| Step: 10
Training loss: 2.877566643149486
Validation loss: 2.7902590593533354

Epoch: 229| Step: 0
Training loss: 2.4611808535432043
Validation loss: 2.790193266874133

Epoch: 5| Step: 1
Training loss: 3.0661280414697316
Validation loss: 2.7917900082690292

Epoch: 5| Step: 2
Training loss: 3.3088703062453577
Validation loss: 2.7916386902432326

Epoch: 5| Step: 3
Training loss: 3.1933142795936695
Validation loss: 2.789704515913975

Epoch: 5| Step: 4
Training loss: 3.0728885627797657
Validation loss: 2.7908106927096616

Epoch: 5| Step: 5
Training loss: 3.426810828663341
Validation loss: 2.794005010807027

Epoch: 5| Step: 6
Training loss: 2.9558706286127787
Validation loss: 2.7939732009859495

Epoch: 5| Step: 7
Training loss: 2.9548576963598947
Validation loss: 2.7948059340955007

Epoch: 5| Step: 8
Training loss: 3.2557704755503467
Validation loss: 2.7944195899137227

Epoch: 5| Step: 9
Training loss: 3.1454691560318713
Validation loss: 2.800685338192319

Epoch: 5| Step: 10
Training loss: 3.2317746531514913
Validation loss: 2.804688223932032

Epoch: 230| Step: 0
Training loss: 2.979769523463831
Validation loss: 2.7965676899690624

Epoch: 5| Step: 1
Training loss: 2.9199747852647686
Validation loss: 2.7961255837033883

Epoch: 5| Step: 2
Training loss: 2.8135383384672665
Validation loss: 2.804469187577267

Epoch: 5| Step: 3
Training loss: 3.5250819528129913
Validation loss: 2.7966578606617434

Epoch: 5| Step: 4
Training loss: 3.287204389734556
Validation loss: 2.798079152102949

Epoch: 5| Step: 5
Training loss: 2.8297138282397825
Validation loss: 2.7962811796871208

Epoch: 5| Step: 6
Training loss: 3.2673192352050955
Validation loss: 2.7933684225088724

Epoch: 5| Step: 7
Training loss: 3.212234272338452
Validation loss: 2.7953284401097127

Epoch: 5| Step: 8
Training loss: 2.7020306439190303
Validation loss: 2.788674516199443

Epoch: 5| Step: 9
Training loss: 3.0311037008630604
Validation loss: 2.788861505629767

Epoch: 5| Step: 10
Training loss: 3.4959094803480824
Validation loss: 2.789332305688884

Epoch: 231| Step: 0
Training loss: 2.7888778497174327
Validation loss: 2.7860457527289433

Epoch: 5| Step: 1
Training loss: 3.079328427606168
Validation loss: 2.786489578791049

Epoch: 5| Step: 2
Training loss: 3.0840986350251454
Validation loss: 2.78757034912688

Epoch: 5| Step: 3
Training loss: 2.9275060237623833
Validation loss: 2.78623498698703

Epoch: 5| Step: 4
Training loss: 2.9171625169972497
Validation loss: 2.785064181663822

Epoch: 5| Step: 5
Training loss: 3.0059106139537133
Validation loss: 2.7862199137162227

Epoch: 5| Step: 6
Training loss: 3.276212185463525
Validation loss: 2.7882307179633083

Epoch: 5| Step: 7
Training loss: 3.6877516321221697
Validation loss: 2.7861738395345097

Epoch: 5| Step: 8
Training loss: 3.468803199153917
Validation loss: 2.785374434152476

Epoch: 5| Step: 9
Training loss: 2.96176546543463
Validation loss: 2.7847427958503306

Epoch: 5| Step: 10
Training loss: 2.7190669960166307
Validation loss: 2.7839207046102104

Epoch: 232| Step: 0
Training loss: 2.842895882582854
Validation loss: 2.7843017675666752

Epoch: 5| Step: 1
Training loss: 2.9289605217822894
Validation loss: 2.7834117185600418

Epoch: 5| Step: 2
Training loss: 2.447261533254261
Validation loss: 2.7893645673140037

Epoch: 5| Step: 3
Training loss: 3.3358330096065893
Validation loss: 2.787980103061269

Epoch: 5| Step: 4
Training loss: 3.0340129412360604
Validation loss: 2.789022793132015

Epoch: 5| Step: 5
Training loss: 2.9996998954713163
Validation loss: 2.797156971361316

Epoch: 5| Step: 6
Training loss: 3.5428764221879807
Validation loss: 2.795933330102209

Epoch: 5| Step: 7
Training loss: 3.176540007279411
Validation loss: 2.792464962359584

Epoch: 5| Step: 8
Training loss: 3.0318801067673378
Validation loss: 2.797756966888725

Epoch: 5| Step: 9
Training loss: 3.1241432541398764
Validation loss: 2.799474618406767

Epoch: 5| Step: 10
Training loss: 3.5436095948300075
Validation loss: 2.7973713446144455

Epoch: 233| Step: 0
Training loss: 3.4841809411171996
Validation loss: 2.781109762902082

Epoch: 5| Step: 1
Training loss: 2.9940703919416882
Validation loss: 2.7843118451366804

Epoch: 5| Step: 2
Training loss: 3.2152581393962913
Validation loss: 2.783027417419261

Epoch: 5| Step: 3
Training loss: 3.0779057923314164
Validation loss: 2.783344941252869

Epoch: 5| Step: 4
Training loss: 3.219357035162244
Validation loss: 2.783944169305749

Epoch: 5| Step: 5
Training loss: 2.7022359631876394
Validation loss: 2.7883200282944074

Epoch: 5| Step: 6
Training loss: 3.116102751716145
Validation loss: 2.788213342130176

Epoch: 5| Step: 7
Training loss: 3.649334096912903
Validation loss: 2.794520611921225

Epoch: 5| Step: 8
Training loss: 2.726003070267021
Validation loss: 2.7907290132152007

Epoch: 5| Step: 9
Training loss: 2.674369316977614
Validation loss: 2.785975586908024

Epoch: 5| Step: 10
Training loss: 3.1804670648235374
Validation loss: 2.782157909224814

Epoch: 234| Step: 0
Training loss: 2.748371682563619
Validation loss: 2.7820475753861444

Epoch: 5| Step: 1
Training loss: 2.8419542616426035
Validation loss: 2.7796305667682017

Epoch: 5| Step: 2
Training loss: 2.9578495077728895
Validation loss: 2.777528142547537

Epoch: 5| Step: 3
Training loss: 2.979816730419374
Validation loss: 2.7853908962626845

Epoch: 5| Step: 4
Training loss: 2.8264094254864274
Validation loss: 2.787624675255009

Epoch: 5| Step: 5
Training loss: 3.603287885545728
Validation loss: 2.7881254802494655

Epoch: 5| Step: 6
Training loss: 3.5211524743497873
Validation loss: 2.7882096670604755

Epoch: 5| Step: 7
Training loss: 2.9530399047862956
Validation loss: 2.7840114690920164

Epoch: 5| Step: 8
Training loss: 3.277174680438685
Validation loss: 2.8001403006548475

Epoch: 5| Step: 9
Training loss: 2.838502338848592
Validation loss: 2.796850771170883

Epoch: 5| Step: 10
Training loss: 3.4503503759734286
Validation loss: 2.7832982502519825

Epoch: 235| Step: 0
Training loss: 3.388700862177893
Validation loss: 2.7833265991109823

Epoch: 5| Step: 1
Training loss: 3.10749169444465
Validation loss: 2.7764395961319543

Epoch: 5| Step: 2
Training loss: 3.238330725647378
Validation loss: 2.777320948605347

Epoch: 5| Step: 3
Training loss: 3.3489856550764316
Validation loss: 2.7813492144643486

Epoch: 5| Step: 4
Training loss: 2.783330846164833
Validation loss: 2.7796636843560756

Epoch: 5| Step: 5
Training loss: 2.9021891453922026
Validation loss: 2.7800854490136073

Epoch: 5| Step: 6
Training loss: 3.06646487429032
Validation loss: 2.780884923752278

Epoch: 5| Step: 7
Training loss: 3.1094654779353443
Validation loss: 2.7820809793494505

Epoch: 5| Step: 8
Training loss: 3.174898557469156
Validation loss: 2.778703603036238

Epoch: 5| Step: 9
Training loss: 2.785298861454481
Validation loss: 2.780198749683137

Epoch: 5| Step: 10
Training loss: 3.1892816388853693
Validation loss: 2.780432908886393

Epoch: 236| Step: 0
Training loss: 3.1763619693144896
Validation loss: 2.7758455232399433

Epoch: 5| Step: 1
Training loss: 3.1482009230867116
Validation loss: 2.7756577751768865

Epoch: 5| Step: 2
Training loss: 3.1666023515561372
Validation loss: 2.784894505136454

Epoch: 5| Step: 3
Training loss: 2.7857700436639665
Validation loss: 2.798758827400771

Epoch: 5| Step: 4
Training loss: 3.0676113214789007
Validation loss: 2.8056394664045397

Epoch: 5| Step: 5
Training loss: 3.020415459154326
Validation loss: 2.8114479640464656

Epoch: 5| Step: 6
Training loss: 3.307469705109894
Validation loss: 2.809059323660268

Epoch: 5| Step: 7
Training loss: 3.24338533266365
Validation loss: 2.7918960674168347

Epoch: 5| Step: 8
Training loss: 3.1695391693655686
Validation loss: 2.7801791502304782

Epoch: 5| Step: 9
Training loss: 2.483102628586466
Validation loss: 2.7717296961757287

Epoch: 5| Step: 10
Training loss: 3.414592501007552
Validation loss: 2.7717515280070684

Epoch: 237| Step: 0
Training loss: 2.9705769589209554
Validation loss: 2.770450643023992

Epoch: 5| Step: 1
Training loss: 3.6636054235830353
Validation loss: 2.771766313693836

Epoch: 5| Step: 2
Training loss: 2.396105101278337
Validation loss: 2.7733510548281384

Epoch: 5| Step: 3
Training loss: 3.3013836011967737
Validation loss: 2.773195886204947

Epoch: 5| Step: 4
Training loss: 2.609905348921368
Validation loss: 2.7703570606470773

Epoch: 5| Step: 5
Training loss: 3.7742855785456895
Validation loss: 2.7703718112088445

Epoch: 5| Step: 6
Training loss: 2.4000320352959412
Validation loss: 2.7691104598814453

Epoch: 5| Step: 7
Training loss: 3.597826296156057
Validation loss: 2.768441474236006

Epoch: 5| Step: 8
Training loss: 2.7425097849418347
Validation loss: 2.7720392548109642

Epoch: 5| Step: 9
Training loss: 2.852199535543009
Validation loss: 2.77213723326014

Epoch: 5| Step: 10
Training loss: 3.344148986399575
Validation loss: 2.772150846113446

Epoch: 238| Step: 0
Training loss: 2.8459804297690483
Validation loss: 2.768970169027928

Epoch: 5| Step: 1
Training loss: 3.4429945987833
Validation loss: 2.768534098142763

Epoch: 5| Step: 2
Training loss: 3.4098456766776595
Validation loss: 2.772659594294858

Epoch: 5| Step: 3
Training loss: 2.625282090788222
Validation loss: 2.770878962522659

Epoch: 5| Step: 4
Training loss: 3.0610600414350757
Validation loss: 2.7689678210808535

Epoch: 5| Step: 5
Training loss: 3.372325543980735
Validation loss: 2.774215516554059

Epoch: 5| Step: 6
Training loss: 3.153681550373625
Validation loss: 2.776138516069008

Epoch: 5| Step: 7
Training loss: 3.230306674346439
Validation loss: 2.780468677861356

Epoch: 5| Step: 8
Training loss: 2.890753500891676
Validation loss: 2.7832050851247576

Epoch: 5| Step: 9
Training loss: 3.0250761731858358
Validation loss: 2.7768667352078267

Epoch: 5| Step: 10
Training loss: 2.7689199701153013
Validation loss: 2.7741169692380607

Epoch: 239| Step: 0
Training loss: 3.394846314447572
Validation loss: 2.769176907406021

Epoch: 5| Step: 1
Training loss: 3.205405563189146
Validation loss: 2.766055654388829

Epoch: 5| Step: 2
Training loss: 2.945261502014139
Validation loss: 2.7659199133738253

Epoch: 5| Step: 3
Training loss: 3.347425205799653
Validation loss: 2.7664193329583098

Epoch: 5| Step: 4
Training loss: 3.1495427541536407
Validation loss: 2.76561755367125

Epoch: 5| Step: 5
Training loss: 2.641313812885945
Validation loss: 2.767568633065372

Epoch: 5| Step: 6
Training loss: 3.229967735767136
Validation loss: 2.765370838316229

Epoch: 5| Step: 7
Training loss: 3.120687637357519
Validation loss: 2.767723373383398

Epoch: 5| Step: 8
Training loss: 3.05500374252165
Validation loss: 2.7672052139352

Epoch: 5| Step: 9
Training loss: 3.1492749181956117
Validation loss: 2.7683458968204766

Epoch: 5| Step: 10
Training loss: 2.4895586361052437
Validation loss: 2.7685205054717197

Epoch: 240| Step: 0
Training loss: 3.27519466607834
Validation loss: 2.7708134292330513

Epoch: 5| Step: 1
Training loss: 3.0977256738260026
Validation loss: 2.7703655871106156

Epoch: 5| Step: 2
Training loss: 2.9091959143240804
Validation loss: 2.7765035469939883

Epoch: 5| Step: 3
Training loss: 3.364890038335989
Validation loss: 2.7767972745309994

Epoch: 5| Step: 4
Training loss: 3.1573055504057645
Validation loss: 2.7721579650912243

Epoch: 5| Step: 5
Training loss: 3.175762481446308
Validation loss: 2.7666986169562753

Epoch: 5| Step: 6
Training loss: 3.2712015969205126
Validation loss: 2.766652245477165

Epoch: 5| Step: 7
Training loss: 3.1538028105715092
Validation loss: 2.7643936500049016

Epoch: 5| Step: 8
Training loss: 2.6751804540499613
Validation loss: 2.7638756584446784

Epoch: 5| Step: 9
Training loss: 2.8675137783740534
Validation loss: 2.7613329997347567

Epoch: 5| Step: 10
Training loss: 2.904281277540918
Validation loss: 2.7626247837561566

Epoch: 241| Step: 0
Training loss: 2.9845481942136542
Validation loss: 2.762764828004477

Epoch: 5| Step: 1
Training loss: 3.3971225343018645
Validation loss: 2.76416513622772

Epoch: 5| Step: 2
Training loss: 2.360987131441585
Validation loss: 2.76356910750169

Epoch: 5| Step: 3
Training loss: 3.179398507146994
Validation loss: 2.761091322055006

Epoch: 5| Step: 4
Training loss: 3.116512215879096
Validation loss: 2.764428031440367

Epoch: 5| Step: 5
Training loss: 3.1896223594492246
Validation loss: 2.7648412095423756

Epoch: 5| Step: 6
Training loss: 3.3833726238606423
Validation loss: 2.762385938289795

Epoch: 5| Step: 7
Training loss: 2.9151326277906917
Validation loss: 2.766364134452273

Epoch: 5| Step: 8
Training loss: 2.772803607549373
Validation loss: 2.776715263143624

Epoch: 5| Step: 9
Training loss: 3.2949498056110933
Validation loss: 2.770380998344638

Epoch: 5| Step: 10
Training loss: 3.1639473599806487
Validation loss: 2.7734761849085205

Epoch: 242| Step: 0
Training loss: 2.6949145037053577
Validation loss: 2.7750281526408136

Epoch: 5| Step: 1
Training loss: 2.487672357003297
Validation loss: 2.7752883856623356

Epoch: 5| Step: 2
Training loss: 3.0996550644966714
Validation loss: 2.7722812514562665

Epoch: 5| Step: 3
Training loss: 2.9118090550835576
Validation loss: 2.790421489364061

Epoch: 5| Step: 4
Training loss: 2.524898141751604
Validation loss: 2.7724606027656296

Epoch: 5| Step: 5
Training loss: 3.009235471539066
Validation loss: 2.77001526424967

Epoch: 5| Step: 6
Training loss: 3.654505908722771
Validation loss: 2.7674215293905293

Epoch: 5| Step: 7
Training loss: 2.9548647968066537
Validation loss: 2.767305642489882

Epoch: 5| Step: 8
Training loss: 3.1692405245775386
Validation loss: 2.7626260717820927

Epoch: 5| Step: 9
Training loss: 3.4679772143379894
Validation loss: 2.7608740435595616

Epoch: 5| Step: 10
Training loss: 3.722677128704239
Validation loss: 2.760028112597363

Epoch: 243| Step: 0
Training loss: 3.3179718024749763
Validation loss: 2.759741255232957

Epoch: 5| Step: 1
Training loss: 2.3577334522827087
Validation loss: 2.7584475520732736

Epoch: 5| Step: 2
Training loss: 3.240813697316668
Validation loss: 2.760519914946369

Epoch: 5| Step: 3
Training loss: 2.8584199571597693
Validation loss: 2.7590587623308878

Epoch: 5| Step: 4
Training loss: 2.5224150957349685
Validation loss: 2.7580060491509752

Epoch: 5| Step: 5
Training loss: 4.149029188471336
Validation loss: 2.760035264701078

Epoch: 5| Step: 6
Training loss: 2.7264041362778086
Validation loss: 2.758230537477131

Epoch: 5| Step: 7
Training loss: 3.019129796748437
Validation loss: 2.7580526738229505

Epoch: 5| Step: 8
Training loss: 2.940289086382328
Validation loss: 2.7577974573000685

Epoch: 5| Step: 9
Training loss: 2.892762914263318
Validation loss: 2.7587612996985396

Epoch: 5| Step: 10
Training loss: 3.515218753654936
Validation loss: 2.7612671767571855

Epoch: 244| Step: 0
Training loss: 2.6505314923761305
Validation loss: 2.7626476841738175

Epoch: 5| Step: 1
Training loss: 3.7427477327660608
Validation loss: 2.766787247291685

Epoch: 5| Step: 2
Training loss: 2.7351229271470094
Validation loss: 2.768462611557599

Epoch: 5| Step: 3
Training loss: 3.7884923761640237
Validation loss: 2.7707212442256526

Epoch: 5| Step: 4
Training loss: 2.8056793584250643
Validation loss: 2.7646326734648827

Epoch: 5| Step: 5
Training loss: 3.4295099512254223
Validation loss: 2.7665593306096863

Epoch: 5| Step: 6
Training loss: 3.2809215562925185
Validation loss: 2.764746419162881

Epoch: 5| Step: 7
Training loss: 2.7712767014445236
Validation loss: 2.7607498744863954

Epoch: 5| Step: 8
Training loss: 2.98488800273226
Validation loss: 2.761485089023029

Epoch: 5| Step: 9
Training loss: 2.618547592898944
Validation loss: 2.7577456466462538

Epoch: 5| Step: 10
Training loss: 2.6632913944569285
Validation loss: 2.7580562784647262

Epoch: 245| Step: 0
Training loss: 2.8388715546492036
Validation loss: 2.7610597170652214

Epoch: 5| Step: 1
Training loss: 3.085272531450464
Validation loss: 2.7674275970703444

Epoch: 5| Step: 2
Training loss: 3.1866468896079234
Validation loss: 2.761330159736561

Epoch: 5| Step: 3
Training loss: 2.9770058929928345
Validation loss: 2.7655494521575084

Epoch: 5| Step: 4
Training loss: 3.489111448047972
Validation loss: 2.7700980385332516

Epoch: 5| Step: 5
Training loss: 2.69747846621314
Validation loss: 2.779946885043074

Epoch: 5| Step: 6
Training loss: 2.750942242198056
Validation loss: 2.788661490545575

Epoch: 5| Step: 7
Training loss: 2.757118461961211
Validation loss: 2.770849120688554

Epoch: 5| Step: 8
Training loss: 3.5632312760281004
Validation loss: 2.758687041473768

Epoch: 5| Step: 9
Training loss: 3.1153539174261975
Validation loss: 2.7503169595844343

Epoch: 5| Step: 10
Training loss: 3.2606594170012912
Validation loss: 2.7511177047603073

Epoch: 246| Step: 0
Training loss: 3.461248586205951
Validation loss: 2.75552094196922

Epoch: 5| Step: 1
Training loss: 2.6195808967962066
Validation loss: 2.751939912492095

Epoch: 5| Step: 2
Training loss: 3.211393968941662
Validation loss: 2.75196852103632

Epoch: 5| Step: 3
Training loss: 2.7114886072740023
Validation loss: 2.754302705614471

Epoch: 5| Step: 4
Training loss: 3.4713836844186847
Validation loss: 2.7521111280038757

Epoch: 5| Step: 5
Training loss: 2.765230226089247
Validation loss: 2.7506210832104516

Epoch: 5| Step: 6
Training loss: 3.5807952911744847
Validation loss: 2.750159095867982

Epoch: 5| Step: 7
Training loss: 3.034907700267919
Validation loss: 2.748792226479042

Epoch: 5| Step: 8
Training loss: 2.6724711862836075
Validation loss: 2.7497998152629144

Epoch: 5| Step: 9
Training loss: 3.1102353539908125
Validation loss: 2.750516980855569

Epoch: 5| Step: 10
Training loss: 3.007435168093105
Validation loss: 2.7514310070596384

Epoch: 247| Step: 0
Training loss: 2.683510769334325
Validation loss: 2.752515984320848

Epoch: 5| Step: 1
Training loss: 2.9839009013250126
Validation loss: 2.7590561439224515

Epoch: 5| Step: 2
Training loss: 3.4327811016162637
Validation loss: 2.766632504653201

Epoch: 5| Step: 3
Training loss: 3.1209307306945244
Validation loss: 2.7687158736796147

Epoch: 5| Step: 4
Training loss: 3.115697059831096
Validation loss: 2.7802635011245047

Epoch: 5| Step: 5
Training loss: 3.103223533641051
Validation loss: 2.798017988620629

Epoch: 5| Step: 6
Training loss: 3.140597822536716
Validation loss: 2.800124708964116

Epoch: 5| Step: 7
Training loss: 2.9808614929535624
Validation loss: 2.796347848849714

Epoch: 5| Step: 8
Training loss: 3.0493237167771654
Validation loss: 2.7670041531778162

Epoch: 5| Step: 9
Training loss: 3.09693236389307
Validation loss: 2.751620933629337

Epoch: 5| Step: 10
Training loss: 3.08870787063452
Validation loss: 2.7468562433121155

Epoch: 248| Step: 0
Training loss: 3.2982890635547903
Validation loss: 2.7457995006995244

Epoch: 5| Step: 1
Training loss: 2.782727738320603
Validation loss: 2.7455583035577127

Epoch: 5| Step: 2
Training loss: 3.4026030169047656
Validation loss: 2.756407622433804

Epoch: 5| Step: 3
Training loss: 3.0246292643710317
Validation loss: 2.7622526443857236

Epoch: 5| Step: 4
Training loss: 2.979093501830946
Validation loss: 2.749439557151205

Epoch: 5| Step: 5
Training loss: 2.9897728482210755
Validation loss: 2.748177969815586

Epoch: 5| Step: 6
Training loss: 2.7299012125048407
Validation loss: 2.7448598912329922

Epoch: 5| Step: 7
Training loss: 3.1006974327886536
Validation loss: 2.74597213630565

Epoch: 5| Step: 8
Training loss: 2.752204964717592
Validation loss: 2.7477517432495375

Epoch: 5| Step: 9
Training loss: 3.7032634210268025
Validation loss: 2.755424141357983

Epoch: 5| Step: 10
Training loss: 2.881966815744203
Validation loss: 2.768960263381227

Epoch: 249| Step: 0
Training loss: 2.981369662332493
Validation loss: 2.787162931960056

Epoch: 5| Step: 1
Training loss: 2.9804497114500874
Validation loss: 2.815266272195128

Epoch: 5| Step: 2
Training loss: 3.0746024642399465
Validation loss: 2.8495727825499517

Epoch: 5| Step: 3
Training loss: 3.2633214975934064
Validation loss: 2.859439713066156

Epoch: 5| Step: 4
Training loss: 3.1219421684974216
Validation loss: 2.873209560318391

Epoch: 5| Step: 5
Training loss: 3.619708177806668
Validation loss: 2.8440258014533106

Epoch: 5| Step: 6
Training loss: 3.374088446823062
Validation loss: 2.846839920003772

Epoch: 5| Step: 7
Training loss: 2.6706999933420557
Validation loss: 2.8345161468780677

Epoch: 5| Step: 8
Training loss: 3.039770676345587
Validation loss: 2.8203721992156083

Epoch: 5| Step: 9
Training loss: 2.68773845235753
Validation loss: 2.815817970696935

Epoch: 5| Step: 10
Training loss: 3.5161970563225835
Validation loss: 2.794231090686015

Epoch: 250| Step: 0
Training loss: 3.407453971658271
Validation loss: 2.756546567051596

Epoch: 5| Step: 1
Training loss: 3.1086521554480453
Validation loss: 2.7502987951943765

Epoch: 5| Step: 2
Training loss: 3.4789782414075274
Validation loss: 2.749715691540417

Epoch: 5| Step: 3
Training loss: 3.312330421569574
Validation loss: 2.7491473445027994

Epoch: 5| Step: 4
Training loss: 3.380077639709459
Validation loss: 2.754075682626576

Epoch: 5| Step: 5
Training loss: 2.653574415050103
Validation loss: 2.758902640263019

Epoch: 5| Step: 6
Training loss: 3.1324060799537863
Validation loss: 2.76532653881495

Epoch: 5| Step: 7
Training loss: 2.4490682503974814
Validation loss: 2.7620189051276385

Epoch: 5| Step: 8
Training loss: 2.8667705347036443
Validation loss: 2.767575796250827

Epoch: 5| Step: 9
Training loss: 2.7543100047552604
Validation loss: 2.757409051234566

Epoch: 5| Step: 10
Training loss: 3.0302160013590744
Validation loss: 2.754239986377605

Epoch: 251| Step: 0
Training loss: 3.036147575551113
Validation loss: 2.751530382722992

Epoch: 5| Step: 1
Training loss: 2.804579793833081
Validation loss: 2.743387463705363

Epoch: 5| Step: 2
Training loss: 3.451468920701922
Validation loss: 2.746949571715842

Epoch: 5| Step: 3
Training loss: 3.276070130208887
Validation loss: 2.744158056153651

Epoch: 5| Step: 4
Training loss: 2.71709102132484
Validation loss: 2.748834920658866

Epoch: 5| Step: 5
Training loss: 3.589736023657374
Validation loss: 2.766338280740621

Epoch: 5| Step: 6
Training loss: 3.423612806531698
Validation loss: 2.7511333514799756

Epoch: 5| Step: 7
Training loss: 3.26248251373165
Validation loss: 2.751835670911673

Epoch: 5| Step: 8
Training loss: 2.945813204756353
Validation loss: 2.7564465612262734

Epoch: 5| Step: 9
Training loss: 2.0825814098185282
Validation loss: 2.7482203153287643

Epoch: 5| Step: 10
Training loss: 2.7461958495866803
Validation loss: 2.7458603092420666

Epoch: 252| Step: 0
Training loss: 2.9306687809754584
Validation loss: 2.7450609965624437

Epoch: 5| Step: 1
Training loss: 2.8981528746494494
Validation loss: 2.7405326287488965

Epoch: 5| Step: 2
Training loss: 3.0458165604477005
Validation loss: 2.738694428137022

Epoch: 5| Step: 3
Training loss: 3.0862068155325795
Validation loss: 2.738257896765303

Epoch: 5| Step: 4
Training loss: 3.338542841029841
Validation loss: 2.739004667222711

Epoch: 5| Step: 5
Training loss: 2.56835965348739
Validation loss: 2.7387203892926966

Epoch: 5| Step: 6
Training loss: 3.302882357575116
Validation loss: 2.739205237507698

Epoch: 5| Step: 7
Training loss: 2.6796362513320955
Validation loss: 2.743757334912934

Epoch: 5| Step: 8
Training loss: 3.254211338207127
Validation loss: 2.740090725147255

Epoch: 5| Step: 9
Training loss: 2.925469294012494
Validation loss: 2.7377892171028297

Epoch: 5| Step: 10
Training loss: 3.622703614129933
Validation loss: 2.738317723114927

Epoch: 253| Step: 0
Training loss: 3.1914491312048
Validation loss: 2.741141877035688

Epoch: 5| Step: 1
Training loss: 2.522655448547217
Validation loss: 2.7457603791717187

Epoch: 5| Step: 2
Training loss: 3.0538750468075264
Validation loss: 2.7406934883408294

Epoch: 5| Step: 3
Training loss: 3.164883730712815
Validation loss: 2.751993577256164

Epoch: 5| Step: 4
Training loss: 3.1997359047629996
Validation loss: 2.7469104572345455

Epoch: 5| Step: 5
Training loss: 2.9071270019377393
Validation loss: 2.755601161535996

Epoch: 5| Step: 6
Training loss: 2.6886568462811398
Validation loss: 2.7487979286497763

Epoch: 5| Step: 7
Training loss: 3.477764204836337
Validation loss: 2.7423580698480188

Epoch: 5| Step: 8
Training loss: 3.2485155970519135
Validation loss: 2.738228416579756

Epoch: 5| Step: 9
Training loss: 3.0621205308888344
Validation loss: 2.73951143316791

Epoch: 5| Step: 10
Training loss: 3.0138001924541418
Validation loss: 2.739377671024794

Epoch: 254| Step: 0
Training loss: 2.824255725412778
Validation loss: 2.7404794289962213

Epoch: 5| Step: 1
Training loss: 2.811581779635204
Validation loss: 2.7460619462601352

Epoch: 5| Step: 2
Training loss: 3.32701959296128
Validation loss: 2.748043396230381

Epoch: 5| Step: 3
Training loss: 3.281816996677697
Validation loss: 2.7419180218637003

Epoch: 5| Step: 4
Training loss: 3.221156433665028
Validation loss: 2.7423576893718793

Epoch: 5| Step: 5
Training loss: 2.7396071593743714
Validation loss: 2.7482576770483513

Epoch: 5| Step: 6
Training loss: 2.829024198275566
Validation loss: 2.749689602976865

Epoch: 5| Step: 7
Training loss: 3.428586744092612
Validation loss: 2.750342798914688

Epoch: 5| Step: 8
Training loss: 3.188899910878603
Validation loss: 2.7424172430608955

Epoch: 5| Step: 9
Training loss: 2.9035510585126016
Validation loss: 2.7385586143504117

Epoch: 5| Step: 10
Training loss: 2.9425928323860018
Validation loss: 2.7332224705476036

Epoch: 255| Step: 0
Training loss: 2.7592073106628527
Validation loss: 2.7346587275017655

Epoch: 5| Step: 1
Training loss: 2.982080506259512
Validation loss: 2.7345477418494166

Epoch: 5| Step: 2
Training loss: 2.9644810551478593
Validation loss: 2.733222378627978

Epoch: 5| Step: 3
Training loss: 2.9414039804315615
Validation loss: 2.7325327771846464

Epoch: 5| Step: 4
Training loss: 2.788852715817029
Validation loss: 2.733975330214146

Epoch: 5| Step: 5
Training loss: 2.6367987726572104
Validation loss: 2.7313545807941226

Epoch: 5| Step: 6
Training loss: 3.7745934526418936
Validation loss: 2.732918487639726

Epoch: 5| Step: 7
Training loss: 2.6186644984014253
Validation loss: 2.7307299942979477

Epoch: 5| Step: 8
Training loss: 3.3943425906380793
Validation loss: 2.735251745249155

Epoch: 5| Step: 9
Training loss: 3.7595497604427472
Validation loss: 2.7340972253017877

Epoch: 5| Step: 10
Training loss: 2.6252134327177625
Validation loss: 2.7330937190741706

Epoch: 256| Step: 0
Training loss: 2.8356946941081933
Validation loss: 2.7370222692880493

Epoch: 5| Step: 1
Training loss: 2.670071891359725
Validation loss: 2.7368329548282153

Epoch: 5| Step: 2
Training loss: 3.436340968932033
Validation loss: 2.7343250847873617

Epoch: 5| Step: 3
Training loss: 2.6486281604837103
Validation loss: 2.742356219817352

Epoch: 5| Step: 4
Training loss: 3.70517400397326
Validation loss: 2.740081820986766

Epoch: 5| Step: 5
Training loss: 3.1715289147899366
Validation loss: 2.7428676034248864

Epoch: 5| Step: 6
Training loss: 2.688293339935761
Validation loss: 2.7418038396340707

Epoch: 5| Step: 7
Training loss: 3.134402054948508
Validation loss: 2.737835834921919

Epoch: 5| Step: 8
Training loss: 2.8544383975431407
Validation loss: 2.735304841420757

Epoch: 5| Step: 9
Training loss: 2.8692346898935397
Validation loss: 2.7346750064936134

Epoch: 5| Step: 10
Training loss: 3.4010445953559048
Validation loss: 2.7385624346849777

Epoch: 257| Step: 0
Training loss: 3.629478844677285
Validation loss: 2.736284424316743

Epoch: 5| Step: 1
Training loss: 3.1420620339799816
Validation loss: 2.7412372620010195

Epoch: 5| Step: 2
Training loss: 2.3859915117047255
Validation loss: 2.737621115747605

Epoch: 5| Step: 3
Training loss: 3.0792266888031476
Validation loss: 2.738760162721216

Epoch: 5| Step: 4
Training loss: 3.2933847474577878
Validation loss: 2.7489733965861864

Epoch: 5| Step: 5
Training loss: 2.784404209039414
Validation loss: 2.7396892915620468

Epoch: 5| Step: 6
Training loss: 3.12817831537045
Validation loss: 2.739975192422753

Epoch: 5| Step: 7
Training loss: 2.4997823620477404
Validation loss: 2.7338613376320167

Epoch: 5| Step: 8
Training loss: 2.9757405745735106
Validation loss: 2.7323178889717883

Epoch: 5| Step: 9
Training loss: 3.12704477169922
Validation loss: 2.7408410509682195

Epoch: 5| Step: 10
Training loss: 3.3139551673209438
Validation loss: 2.7342481526897453

Epoch: 258| Step: 0
Training loss: 2.7910424478788953
Validation loss: 2.7260916930122434

Epoch: 5| Step: 1
Training loss: 3.0824508091326708
Validation loss: 2.727802787494129

Epoch: 5| Step: 2
Training loss: 2.9031729867703855
Validation loss: 2.726646428864884

Epoch: 5| Step: 3
Training loss: 2.7791202405934192
Validation loss: 2.7257247207959967

Epoch: 5| Step: 4
Training loss: 3.545836578140537
Validation loss: 2.72632808084825

Epoch: 5| Step: 5
Training loss: 2.903886059230823
Validation loss: 2.7262466736206226

Epoch: 5| Step: 6
Training loss: 3.05468906100104
Validation loss: 2.7252724719684003

Epoch: 5| Step: 7
Training loss: 2.7639787159885554
Validation loss: 2.726761416918545

Epoch: 5| Step: 8
Training loss: 3.130152460108445
Validation loss: 2.72739408790285

Epoch: 5| Step: 9
Training loss: 2.903282865865976
Validation loss: 2.726198948288338

Epoch: 5| Step: 10
Training loss: 3.632277451357836
Validation loss: 2.725037063161435

Epoch: 259| Step: 0
Training loss: 3.386048352900642
Validation loss: 2.726134086311614

Epoch: 5| Step: 1
Training loss: 2.681100989693834
Validation loss: 2.7249505323315573

Epoch: 5| Step: 2
Training loss: 2.82730790447819
Validation loss: 2.731778460449287

Epoch: 5| Step: 3
Training loss: 3.0807764087880223
Validation loss: 2.734333482652721

Epoch: 5| Step: 4
Training loss: 3.1363991922566994
Validation loss: 2.746740698355307

Epoch: 5| Step: 5
Training loss: 2.812376061993614
Validation loss: 2.733749487801105

Epoch: 5| Step: 6
Training loss: 3.084087039139822
Validation loss: 2.7314102418322754

Epoch: 5| Step: 7
Training loss: 3.712534863857368
Validation loss: 2.731436092015886

Epoch: 5| Step: 8
Training loss: 2.9182030763718774
Validation loss: 2.731659079346974

Epoch: 5| Step: 9
Training loss: 2.9791693698541786
Validation loss: 2.7262068173082756

Epoch: 5| Step: 10
Training loss: 2.69814737479887
Validation loss: 2.7249933620348323

Epoch: 260| Step: 0
Training loss: 3.0507968799615623
Validation loss: 2.725903585012363

Epoch: 5| Step: 1
Training loss: 3.0175381457201937
Validation loss: 2.7248211510227476

Epoch: 5| Step: 2
Training loss: 3.003455873615162
Validation loss: 2.7250851108249545

Epoch: 5| Step: 3
Training loss: 3.309591780092296
Validation loss: 2.724284401220383

Epoch: 5| Step: 4
Training loss: 3.059801274996182
Validation loss: 2.7295381796803673

Epoch: 5| Step: 5
Training loss: 3.2475820496658008
Validation loss: 2.7250507231476546

Epoch: 5| Step: 6
Training loss: 3.088689036120831
Validation loss: 2.722752492532492

Epoch: 5| Step: 7
Training loss: 2.9087957901704917
Validation loss: 2.7227923057252825

Epoch: 5| Step: 8
Training loss: 3.1894444537351507
Validation loss: 2.72508570067901

Epoch: 5| Step: 9
Training loss: 2.650711388739642
Validation loss: 2.7223940030477016

Epoch: 5| Step: 10
Training loss: 2.854070193105855
Validation loss: 2.7218930072442364

Epoch: 261| Step: 0
Training loss: 3.256737547707963
Validation loss: 2.725246742993873

Epoch: 5| Step: 1
Training loss: 3.444049214347078
Validation loss: 2.7249499923107923

Epoch: 5| Step: 2
Training loss: 3.224467116694712
Validation loss: 2.7278969336382533

Epoch: 5| Step: 3
Training loss: 2.8141244223822866
Validation loss: 2.7264448500683995

Epoch: 5| Step: 4
Training loss: 3.0300915264242927
Validation loss: 2.7212595839249722

Epoch: 5| Step: 5
Training loss: 2.8266294118237556
Validation loss: 2.7275295176995007

Epoch: 5| Step: 6
Training loss: 3.1318586233879793
Validation loss: 2.720014448543733

Epoch: 5| Step: 7
Training loss: 2.6655618246447443
Validation loss: 2.7249121840055963

Epoch: 5| Step: 8
Training loss: 3.4107315958934783
Validation loss: 2.7260360211828454

Epoch: 5| Step: 9
Training loss: 3.019815172514282
Validation loss: 2.7248567543338473

Epoch: 5| Step: 10
Training loss: 2.3311588054748165
Validation loss: 2.7222464801538195

Epoch: 262| Step: 0
Training loss: 2.388571661455687
Validation loss: 2.7253602718761325

Epoch: 5| Step: 1
Training loss: 2.7511968609098965
Validation loss: 2.7261681415338277

Epoch: 5| Step: 2
Training loss: 3.519164478019186
Validation loss: 2.721674333546053

Epoch: 5| Step: 3
Training loss: 2.9404819044267607
Validation loss: 2.7193154065459253

Epoch: 5| Step: 4
Training loss: 2.8222282011197386
Validation loss: 2.7194528982961557

Epoch: 5| Step: 5
Training loss: 3.752840111026019
Validation loss: 2.7231488566309743

Epoch: 5| Step: 6
Training loss: 2.8107916836028313
Validation loss: 2.721086344272632

Epoch: 5| Step: 7
Training loss: 2.516172550864725
Validation loss: 2.7231173460097455

Epoch: 5| Step: 8
Training loss: 2.791279656833071
Validation loss: 2.7182408866157077

Epoch: 5| Step: 9
Training loss: 3.2830998610415127
Validation loss: 2.7210570040323767

Epoch: 5| Step: 10
Training loss: 3.5834033131234886
Validation loss: 2.7250034698407037

Epoch: 263| Step: 0
Training loss: 3.02911978523115
Validation loss: 2.720707618688408

Epoch: 5| Step: 1
Training loss: 3.173260466062254
Validation loss: 2.7242178204630068

Epoch: 5| Step: 2
Training loss: 3.1451921799107567
Validation loss: 2.719915993116769

Epoch: 5| Step: 3
Training loss: 2.9909808960575215
Validation loss: 2.7222877307535613

Epoch: 5| Step: 4
Training loss: 2.9128985087311174
Validation loss: 2.720822871862917

Epoch: 5| Step: 5
Training loss: 2.4417035951740313
Validation loss: 2.721945260162795

Epoch: 5| Step: 6
Training loss: 3.0285407474793975
Validation loss: 2.7163787692519334

Epoch: 5| Step: 7
Training loss: 3.185625609752768
Validation loss: 2.7257003589387687

Epoch: 5| Step: 8
Training loss: 3.511930160184312
Validation loss: 2.722544032112485

Epoch: 5| Step: 9
Training loss: 2.9797855259054313
Validation loss: 2.7233539035325656

Epoch: 5| Step: 10
Training loss: 2.876665545124824
Validation loss: 2.7181067511412618

Epoch: 264| Step: 0
Training loss: 3.0724794928143373
Validation loss: 2.7175896468858967

Epoch: 5| Step: 1
Training loss: 3.1086513884963356
Validation loss: 2.720876790434125

Epoch: 5| Step: 2
Training loss: 2.1974779628304
Validation loss: 2.7186597168608633

Epoch: 5| Step: 3
Training loss: 3.35540963277376
Validation loss: 2.7236100829117458

Epoch: 5| Step: 4
Training loss: 2.7571743234861943
Validation loss: 2.7179926316045973

Epoch: 5| Step: 5
Training loss: 3.0296198600784936
Validation loss: 2.7173483609751647

Epoch: 5| Step: 6
Training loss: 2.6979201818809044
Validation loss: 2.722063044295348

Epoch: 5| Step: 7
Training loss: 3.175308849301458
Validation loss: 2.7257978897071906

Epoch: 5| Step: 8
Training loss: 3.0201949047832026
Validation loss: 2.725730007540446

Epoch: 5| Step: 9
Training loss: 3.2478539644118096
Validation loss: 2.72447490568343

Epoch: 5| Step: 10
Training loss: 3.5960121001314764
Validation loss: 2.725378585547302

Epoch: 265| Step: 0
Training loss: 3.155924412014354
Validation loss: 2.724359892638655

Epoch: 5| Step: 1
Training loss: 3.15781703610781
Validation loss: 2.720936280057891

Epoch: 5| Step: 2
Training loss: 3.3081489633326115
Validation loss: 2.718911235602997

Epoch: 5| Step: 3
Training loss: 3.3612142096926734
Validation loss: 2.7164297352615483

Epoch: 5| Step: 4
Training loss: 2.9998915970608357
Validation loss: 2.714121300179408

Epoch: 5| Step: 5
Training loss: 2.0447890740441474
Validation loss: 2.7118565123833593

Epoch: 5| Step: 6
Training loss: 2.782515163054713
Validation loss: 2.7152506668170657

Epoch: 5| Step: 7
Training loss: 3.0806086246042095
Validation loss: 2.710388812729228

Epoch: 5| Step: 8
Training loss: 3.162453023086664
Validation loss: 2.7141653369304857

Epoch: 5| Step: 9
Training loss: 2.418020220133228
Validation loss: 2.7132786363956805

Epoch: 5| Step: 10
Training loss: 3.639984729441376
Validation loss: 2.713037217489606

Epoch: 266| Step: 0
Training loss: 2.276587647015743
Validation loss: 2.715328860369974

Epoch: 5| Step: 1
Training loss: 3.338516274929441
Validation loss: 2.713317353227566

Epoch: 5| Step: 2
Training loss: 2.8586548278739
Validation loss: 2.715064014379724

Epoch: 5| Step: 3
Training loss: 3.8207091455165476
Validation loss: 2.7077052944537416

Epoch: 5| Step: 4
Training loss: 3.23049797589183
Validation loss: 2.7098379283222926

Epoch: 5| Step: 5
Training loss: 3.0398553828926413
Validation loss: 2.711761910035475

Epoch: 5| Step: 6
Training loss: 2.547235194286104
Validation loss: 2.707250031676801

Epoch: 5| Step: 7
Training loss: 2.4690480112728093
Validation loss: 2.7044233563379043

Epoch: 5| Step: 8
Training loss: 3.474281231211337
Validation loss: 2.705926344909303

Epoch: 5| Step: 9
Training loss: 2.780687425272368
Validation loss: 2.7111659301131827

Epoch: 5| Step: 10
Training loss: 3.174378107395743
Validation loss: 2.7070052567343708

Epoch: 267| Step: 0
Training loss: 3.101077870670283
Validation loss: 2.711021497455368

Epoch: 5| Step: 1
Training loss: 2.6844135570310548
Validation loss: 2.712285487467017

Epoch: 5| Step: 2
Training loss: 3.332585600592777
Validation loss: 2.7138133771624977

Epoch: 5| Step: 3
Training loss: 3.262822166701108
Validation loss: 2.7114211431182906

Epoch: 5| Step: 4
Training loss: 2.9861534371937197
Validation loss: 2.719042267139981

Epoch: 5| Step: 5
Training loss: 2.856672166472593
Validation loss: 2.7263959923183676

Epoch: 5| Step: 6
Training loss: 3.1840798972183655
Validation loss: 2.720539251536998

Epoch: 5| Step: 7
Training loss: 2.882123001470525
Validation loss: 2.715061159031446

Epoch: 5| Step: 8
Training loss: 2.792361320118861
Validation loss: 2.712583340091865

Epoch: 5| Step: 9
Training loss: 3.415150903185439
Validation loss: 2.7090547880182103

Epoch: 5| Step: 10
Training loss: 2.6514867822359722
Validation loss: 2.7094354802286125

Epoch: 268| Step: 0
Training loss: 2.429400068251393
Validation loss: 2.713866401555379

Epoch: 5| Step: 1
Training loss: 2.733278239865718
Validation loss: 2.7105063177991626

Epoch: 5| Step: 2
Training loss: 2.9993027830561294
Validation loss: 2.7135013264530046

Epoch: 5| Step: 3
Training loss: 3.1976476964176768
Validation loss: 2.710405278160467

Epoch: 5| Step: 4
Training loss: 2.791584402741679
Validation loss: 2.7088245530095993

Epoch: 5| Step: 5
Training loss: 3.0078480111540085
Validation loss: 2.719212731348794

Epoch: 5| Step: 6
Training loss: 2.830464107078979
Validation loss: 2.715066076573835

Epoch: 5| Step: 7
Training loss: 3.6852820240107245
Validation loss: 2.7128382581571757

Epoch: 5| Step: 8
Training loss: 3.4912039718024914
Validation loss: 2.717383190472845

Epoch: 5| Step: 9
Training loss: 3.157299660362429
Validation loss: 2.7169231198123756

Epoch: 5| Step: 10
Training loss: 2.736089376071721
Validation loss: 2.7253034525259996

Epoch: 269| Step: 0
Training loss: 3.2629985559935535
Validation loss: 2.7253436983162387

Epoch: 5| Step: 1
Training loss: 3.204742767437714
Validation loss: 2.7301570564145945

Epoch: 5| Step: 2
Training loss: 2.9930953996508585
Validation loss: 2.724352710396325

Epoch: 5| Step: 3
Training loss: 3.496298194746746
Validation loss: 2.72553285140174

Epoch: 5| Step: 4
Training loss: 2.6434301340659156
Validation loss: 2.715176100478962

Epoch: 5| Step: 5
Training loss: 3.01209760328923
Validation loss: 2.71110250135132

Epoch: 5| Step: 6
Training loss: 2.6938009695377767
Validation loss: 2.708347030554528

Epoch: 5| Step: 7
Training loss: 2.815549426488203
Validation loss: 2.707316233352686

Epoch: 5| Step: 8
Training loss: 3.0785830394157983
Validation loss: 2.7037512235064254

Epoch: 5| Step: 9
Training loss: 2.989869656735895
Validation loss: 2.7043376883758867

Epoch: 5| Step: 10
Training loss: 2.976240486088158
Validation loss: 2.703830046389587

Epoch: 270| Step: 0
Training loss: 3.196042749207329
Validation loss: 2.7030131662880685

Epoch: 5| Step: 1
Training loss: 3.1899727598360608
Validation loss: 2.703526178033429

Epoch: 5| Step: 2
Training loss: 2.86662781785176
Validation loss: 2.6999751710832527

Epoch: 5| Step: 3
Training loss: 2.7623471593218114
Validation loss: 2.7026832993107983

Epoch: 5| Step: 4
Training loss: 3.9078441571307443
Validation loss: 2.6989423124913

Epoch: 5| Step: 5
Training loss: 3.176685312489256
Validation loss: 2.7036879128409086

Epoch: 5| Step: 6
Training loss: 2.3712876066243163
Validation loss: 2.7003266996744646

Epoch: 5| Step: 7
Training loss: 2.6832336450702288
Validation loss: 2.712210383065621

Epoch: 5| Step: 8
Training loss: 2.7405083452058348
Validation loss: 2.7257938342243224

Epoch: 5| Step: 9
Training loss: 3.0053278978034044
Validation loss: 2.735100801068133

Epoch: 5| Step: 10
Training loss: 3.1779989121893144
Validation loss: 2.7438827111426827

Epoch: 271| Step: 0
Training loss: 2.7531738173002847
Validation loss: 2.7298161478198257

Epoch: 5| Step: 1
Training loss: 3.719448761244657
Validation loss: 2.701802675912916

Epoch: 5| Step: 2
Training loss: 3.062363913490273
Validation loss: 2.695371093874027

Epoch: 5| Step: 3
Training loss: 2.578862032876718
Validation loss: 2.707774333832697

Epoch: 5| Step: 4
Training loss: 3.42163670376385
Validation loss: 2.7032463031812783

Epoch: 5| Step: 5
Training loss: 2.919537593598858
Validation loss: 2.7045656152222897

Epoch: 5| Step: 6
Training loss: 2.86990286074542
Validation loss: 2.7145281845763005

Epoch: 5| Step: 7
Training loss: 2.712598132630484
Validation loss: 2.713625794502224

Epoch: 5| Step: 8
Training loss: 2.9888476663966674
Validation loss: 2.718906242040465

Epoch: 5| Step: 9
Training loss: 3.3698541477234163
Validation loss: 2.727199143625546

Epoch: 5| Step: 10
Training loss: 2.9109767090086147
Validation loss: 2.7494060251513863

Epoch: 272| Step: 0
Training loss: 2.88399111423896
Validation loss: 2.7080035628106933

Epoch: 5| Step: 1
Training loss: 3.2446858902656905
Validation loss: 2.708478231474365

Epoch: 5| Step: 2
Training loss: 3.302843810557574
Validation loss: 2.7013513437835526

Epoch: 5| Step: 3
Training loss: 3.3309520480833794
Validation loss: 2.702530683122227

Epoch: 5| Step: 4
Training loss: 2.9134763071809737
Validation loss: 2.70147567698044

Epoch: 5| Step: 5
Training loss: 2.7663644782647903
Validation loss: 2.7195814363240065

Epoch: 5| Step: 6
Training loss: 3.229711293878925
Validation loss: 2.7409422070051077

Epoch: 5| Step: 7
Training loss: 2.4379407044132275
Validation loss: 2.7386610154473447

Epoch: 5| Step: 8
Training loss: 2.8840964334690384
Validation loss: 2.732751549193074

Epoch: 5| Step: 9
Training loss: 3.2866219279846844
Validation loss: 2.735803190011933

Epoch: 5| Step: 10
Training loss: 3.0362008161711183
Validation loss: 2.754267269788814

Epoch: 273| Step: 0
Training loss: 3.1530777503292846
Validation loss: 2.7716948744003385

Epoch: 5| Step: 1
Training loss: 2.712520785625646
Validation loss: 2.763165419771315

Epoch: 5| Step: 2
Training loss: 3.836323705060266
Validation loss: 2.7507988467707087

Epoch: 5| Step: 3
Training loss: 2.8442788104006165
Validation loss: 2.7237528126962003

Epoch: 5| Step: 4
Training loss: 2.727454534163933
Validation loss: 2.7054570476230837

Epoch: 5| Step: 5
Training loss: 2.8367135323382198
Validation loss: 2.701810811452166

Epoch: 5| Step: 6
Training loss: 2.98833901343273
Validation loss: 2.6957475698388143

Epoch: 5| Step: 7
Training loss: 3.215079130916407
Validation loss: 2.695683288988631

Epoch: 5| Step: 8
Training loss: 2.776085591401121
Validation loss: 2.6930806406449794

Epoch: 5| Step: 9
Training loss: 3.2119553338029494
Validation loss: 2.6965526674455598

Epoch: 5| Step: 10
Training loss: 2.783776410940652
Validation loss: 2.699400554807705

Epoch: 274| Step: 0
Training loss: 3.5129286535039927
Validation loss: 2.6961110814541187

Epoch: 5| Step: 1
Training loss: 2.98592604031602
Validation loss: 2.6936665839949074

Epoch: 5| Step: 2
Training loss: 2.963830827618819
Validation loss: 2.692198076031529

Epoch: 5| Step: 3
Training loss: 2.538578116356524
Validation loss: 2.6932025961267914

Epoch: 5| Step: 4
Training loss: 2.5681813225473307
Validation loss: 2.6930297715560987

Epoch: 5| Step: 5
Training loss: 3.0823754721530223
Validation loss: 2.6946102497871873

Epoch: 5| Step: 6
Training loss: 2.8920438016684744
Validation loss: 2.697295984393444

Epoch: 5| Step: 7
Training loss: 2.9421196182693805
Validation loss: 2.6972309738903237

Epoch: 5| Step: 8
Training loss: 3.009305826027895
Validation loss: 2.699930145168236

Epoch: 5| Step: 9
Training loss: 3.382782052764249
Validation loss: 2.7046880841036107

Epoch: 5| Step: 10
Training loss: 3.2551757973634423
Validation loss: 2.70353619541359

Epoch: 275| Step: 0
Training loss: 3.31710250968423
Validation loss: 2.7073020056827573

Epoch: 5| Step: 1
Training loss: 3.0402782528673913
Validation loss: 2.707620865573193

Epoch: 5| Step: 2
Training loss: 2.5469156273719906
Validation loss: 2.71361072131121

Epoch: 5| Step: 3
Training loss: 3.426550749390263
Validation loss: 2.7084118348159656

Epoch: 5| Step: 4
Training loss: 2.7701898176522084
Validation loss: 2.7182550428834356

Epoch: 5| Step: 5
Training loss: 2.683791862626805
Validation loss: 2.7200631890657094

Epoch: 5| Step: 6
Training loss: 2.98014619814275
Validation loss: 2.7135429698027775

Epoch: 5| Step: 7
Training loss: 3.4970469960040202
Validation loss: 2.7059355035739983

Epoch: 5| Step: 8
Training loss: 2.6697577403028045
Validation loss: 2.6991946570426446

Epoch: 5| Step: 9
Training loss: 3.111218390053239
Validation loss: 2.6917515098401985

Epoch: 5| Step: 10
Training loss: 2.997619161011026
Validation loss: 2.6922522041289434

Epoch: 276| Step: 0
Training loss: 3.0668061791350394
Validation loss: 2.6943727152914407

Epoch: 5| Step: 1
Training loss: 2.398091741733418
Validation loss: 2.692039672509803

Epoch: 5| Step: 2
Training loss: 2.843178995675903
Validation loss: 2.690712196965026

Epoch: 5| Step: 3
Training loss: 2.9228548253197624
Validation loss: 2.6906919494884707

Epoch: 5| Step: 4
Training loss: 2.4330042925764253
Validation loss: 2.6916944162969014

Epoch: 5| Step: 5
Training loss: 3.1025810202840405
Validation loss: 2.6885687469411472

Epoch: 5| Step: 6
Training loss: 3.0773721926542428
Validation loss: 2.687435028214195

Epoch: 5| Step: 7
Training loss: 3.600713203566874
Validation loss: 2.6841706622783117

Epoch: 5| Step: 8
Training loss: 3.094068876844962
Validation loss: 2.6848167995901893

Epoch: 5| Step: 9
Training loss: 2.9687408447124457
Validation loss: 2.6880483466165814

Epoch: 5| Step: 10
Training loss: 3.5794107717302186
Validation loss: 2.6873108076317944

Epoch: 277| Step: 0
Training loss: 2.9248570203477535
Validation loss: 2.692687550884619

Epoch: 5| Step: 1
Training loss: 2.9776644531751937
Validation loss: 2.6983475323051977

Epoch: 5| Step: 2
Training loss: 3.1635643837751313
Validation loss: 2.7013604372927253

Epoch: 5| Step: 3
Training loss: 3.3234707520852083
Validation loss: 2.703146805498359

Epoch: 5| Step: 4
Training loss: 2.8676735780390183
Validation loss: 2.708685815243041

Epoch: 5| Step: 5
Training loss: 3.3246975295084704
Validation loss: 2.70907945570544

Epoch: 5| Step: 6
Training loss: 2.3331292153950627
Validation loss: 2.706838118061147

Epoch: 5| Step: 7
Training loss: 3.1431335754945064
Validation loss: 2.7030316209333587

Epoch: 5| Step: 8
Training loss: 2.739723946524836
Validation loss: 2.6966842653693113

Epoch: 5| Step: 9
Training loss: 3.0366730306023397
Validation loss: 2.6895065124185313

Epoch: 5| Step: 10
Training loss: 3.259351188594635
Validation loss: 2.687664899753665

Epoch: 278| Step: 0
Training loss: 2.985087204878199
Validation loss: 2.6834802692681463

Epoch: 5| Step: 1
Training loss: 2.723775756630124
Validation loss: 2.685898436444725

Epoch: 5| Step: 2
Training loss: 3.2295841726486487
Validation loss: 2.6861375692551763

Epoch: 5| Step: 3
Training loss: 2.8613797856897816
Validation loss: 2.6852778228494527

Epoch: 5| Step: 4
Training loss: 3.208343869146577
Validation loss: 2.6824899560544413

Epoch: 5| Step: 5
Training loss: 2.8889660172885128
Validation loss: 2.6852013749375674

Epoch: 5| Step: 6
Training loss: 2.813301904587163
Validation loss: 2.6847388116758135

Epoch: 5| Step: 7
Training loss: 3.136336553906503
Validation loss: 2.6821932729914923

Epoch: 5| Step: 8
Training loss: 3.3456650713411653
Validation loss: 2.6830401330405937

Epoch: 5| Step: 9
Training loss: 3.016075614507494
Validation loss: 2.6813329904344467

Epoch: 5| Step: 10
Training loss: 2.82699874455276
Validation loss: 2.6847092818979106

Epoch: 279| Step: 0
Training loss: 2.9349467767571973
Validation loss: 2.681969322542833

Epoch: 5| Step: 1
Training loss: 2.983503124441918
Validation loss: 2.6830036461294404

Epoch: 5| Step: 2
Training loss: 3.2331117383654324
Validation loss: 2.6816818272020804

Epoch: 5| Step: 3
Training loss: 3.253653893181666
Validation loss: 2.6848279972819804

Epoch: 5| Step: 4
Training loss: 3.274128915969289
Validation loss: 2.6827235816243604

Epoch: 5| Step: 5
Training loss: 2.8736232280603775
Validation loss: 2.6810842936168537

Epoch: 5| Step: 6
Training loss: 2.4262407884221466
Validation loss: 2.6791195750306147

Epoch: 5| Step: 7
Training loss: 3.061071880325347
Validation loss: 2.6777372701509017

Epoch: 5| Step: 8
Training loss: 3.0120903211428054
Validation loss: 2.682628022627338

Epoch: 5| Step: 9
Training loss: 3.005122103630242
Validation loss: 2.6818829229882315

Epoch: 5| Step: 10
Training loss: 2.9423557486620426
Validation loss: 2.678039748303043

Epoch: 280| Step: 0
Training loss: 2.7452682187586017
Validation loss: 2.6821864046030806

Epoch: 5| Step: 1
Training loss: 2.6801264545156864
Validation loss: 2.6791278636568636

Epoch: 5| Step: 2
Training loss: 2.911127407167491
Validation loss: 2.683524300606429

Epoch: 5| Step: 3
Training loss: 2.869338390371884
Validation loss: 2.6790916952222354

Epoch: 5| Step: 4
Training loss: 2.912210730075134
Validation loss: 2.6825762882747353

Epoch: 5| Step: 5
Training loss: 2.821129339812892
Validation loss: 2.683138008692576

Epoch: 5| Step: 6
Training loss: 3.384163461204751
Validation loss: 2.6879565477647214

Epoch: 5| Step: 7
Training loss: 3.0839379894785854
Validation loss: 2.687819492191981

Epoch: 5| Step: 8
Training loss: 3.457080629502563
Validation loss: 2.6864304910123806

Epoch: 5| Step: 9
Training loss: 3.0063412721859493
Validation loss: 2.6814137400844578

Epoch: 5| Step: 10
Training loss: 3.165976616479691
Validation loss: 2.6764797007210213

Epoch: 281| Step: 0
Training loss: 3.096213698776887
Validation loss: 2.677448658758721

Epoch: 5| Step: 1
Training loss: 2.7507245236425004
Validation loss: 2.6754012931877766

Epoch: 5| Step: 2
Training loss: 3.094439651223775
Validation loss: 2.679833132595545

Epoch: 5| Step: 3
Training loss: 3.0270890454848587
Validation loss: 2.676942208638136

Epoch: 5| Step: 4
Training loss: 3.081436157793256
Validation loss: 2.6760972555802676

Epoch: 5| Step: 5
Training loss: 3.0988490152177808
Validation loss: 2.67653195615683

Epoch: 5| Step: 6
Training loss: 3.4954607001490694
Validation loss: 2.674954405104588

Epoch: 5| Step: 7
Training loss: 2.8019387209043534
Validation loss: 2.6795978639376856

Epoch: 5| Step: 8
Training loss: 3.275960673598042
Validation loss: 2.6779196085667096

Epoch: 5| Step: 9
Training loss: 2.7646114410221054
Validation loss: 2.6837812996638832

Epoch: 5| Step: 10
Training loss: 2.32424418972422
Validation loss: 2.6935248202282227

Epoch: 282| Step: 0
Training loss: 3.1788856938809142
Validation loss: 2.6952762515124515

Epoch: 5| Step: 1
Training loss: 3.17666444779032
Validation loss: 2.689407162242999

Epoch: 5| Step: 2
Training loss: 3.01135710884028
Validation loss: 2.679868316696684

Epoch: 5| Step: 3
Training loss: 3.333582598585095
Validation loss: 2.682897747574896

Epoch: 5| Step: 4
Training loss: 2.6276348151293183
Validation loss: 2.6787179124178104

Epoch: 5| Step: 5
Training loss: 2.779142974645772
Validation loss: 2.673957198078317

Epoch: 5| Step: 6
Training loss: 3.119161415866839
Validation loss: 2.6725137394807335

Epoch: 5| Step: 7
Training loss: 3.044165242596229
Validation loss: 2.674057068584147

Epoch: 5| Step: 8
Training loss: 2.7538937832164625
Validation loss: 2.6794101496576817

Epoch: 5| Step: 9
Training loss: 2.7811112101354145
Validation loss: 2.675053976750872

Epoch: 5| Step: 10
Training loss: 3.1935224298967912
Validation loss: 2.671102564107985

Epoch: 283| Step: 0
Training loss: 3.266029150380139
Validation loss: 2.674060709755691

Epoch: 5| Step: 1
Training loss: 2.683382917226434
Validation loss: 2.675669543895168

Epoch: 5| Step: 2
Training loss: 3.632957143877826
Validation loss: 2.6746867794911195

Epoch: 5| Step: 3
Training loss: 2.7136348969496376
Validation loss: 2.6719769324851343

Epoch: 5| Step: 4
Training loss: 2.4367882105010508
Validation loss: 2.6773692229327186

Epoch: 5| Step: 5
Training loss: 3.5163256137825964
Validation loss: 2.673478815813073

Epoch: 5| Step: 6
Training loss: 3.041173206869699
Validation loss: 2.677390706773523

Epoch: 5| Step: 7
Training loss: 2.8948697652825035
Validation loss: 2.670977042608122

Epoch: 5| Step: 8
Training loss: 2.69728896057067
Validation loss: 2.6742275703735783

Epoch: 5| Step: 9
Training loss: 3.2597360763901926
Validation loss: 2.676765134419735

Epoch: 5| Step: 10
Training loss: 2.539015455543741
Validation loss: 2.672355367841272

Epoch: 284| Step: 0
Training loss: 3.013660166353632
Validation loss: 2.673041122258252

Epoch: 5| Step: 1
Training loss: 2.9829331355131616
Validation loss: 2.6708243884986165

Epoch: 5| Step: 2
Training loss: 2.634185704572074
Validation loss: 2.6718291416825166

Epoch: 5| Step: 3
Training loss: 3.011584802164781
Validation loss: 2.675487927924995

Epoch: 5| Step: 4
Training loss: 3.228774967842874
Validation loss: 2.674881635731962

Epoch: 5| Step: 5
Training loss: 2.9844973873587772
Validation loss: 2.6728725397832513

Epoch: 5| Step: 6
Training loss: 3.0531451534047296
Validation loss: 2.6806766393683144

Epoch: 5| Step: 7
Training loss: 2.9892056500165425
Validation loss: 2.673055086319577

Epoch: 5| Step: 8
Training loss: 2.9149891706890396
Validation loss: 2.678603918852208

Epoch: 5| Step: 9
Training loss: 3.141970977076105
Validation loss: 2.6793796545805018

Epoch: 5| Step: 10
Training loss: 3.026324330629914
Validation loss: 2.680773211799086

Epoch: 285| Step: 0
Training loss: 3.5076073669401473
Validation loss: 2.679345211335922

Epoch: 5| Step: 1
Training loss: 3.0288688509769544
Validation loss: 2.686034554479916

Epoch: 5| Step: 2
Training loss: 3.0561822614593503
Validation loss: 2.6911853248527877

Epoch: 5| Step: 3
Training loss: 2.4642113601334787
Validation loss: 2.6933479395991897

Epoch: 5| Step: 4
Training loss: 3.4571265600826937
Validation loss: 2.7016930173842533

Epoch: 5| Step: 5
Training loss: 2.5897676160389813
Validation loss: 2.6966307453073193

Epoch: 5| Step: 6
Training loss: 2.622437634303815
Validation loss: 2.689545667729355

Epoch: 5| Step: 7
Training loss: 2.8901375024417124
Validation loss: 2.685701482444771

Epoch: 5| Step: 8
Training loss: 3.259849149572156
Validation loss: 2.6788168216499373

Epoch: 5| Step: 9
Training loss: 3.27700720276447
Validation loss: 2.6770638957195185

Epoch: 5| Step: 10
Training loss: 2.6127248493882473
Validation loss: 2.6742159572968025

Epoch: 286| Step: 0
Training loss: 3.4052426309726385
Validation loss: 2.670008465732477

Epoch: 5| Step: 1
Training loss: 2.788952224218294
Validation loss: 2.668037480087436

Epoch: 5| Step: 2
Training loss: 3.2142449119036853
Validation loss: 2.675285084609962

Epoch: 5| Step: 3
Training loss: 3.1012591542758856
Validation loss: 2.6696152984590658

Epoch: 5| Step: 4
Training loss: 3.1024840400770968
Validation loss: 2.67073552621896

Epoch: 5| Step: 5
Training loss: 2.974384622480134
Validation loss: 2.669407024535793

Epoch: 5| Step: 6
Training loss: 2.7999964509669018
Validation loss: 2.6699432430523538

Epoch: 5| Step: 7
Training loss: 2.451348019536296
Validation loss: 2.6701679400354363

Epoch: 5| Step: 8
Training loss: 3.117041562901977
Validation loss: 2.66923795610295

Epoch: 5| Step: 9
Training loss: 2.5635162757340493
Validation loss: 2.6712335213368523

Epoch: 5| Step: 10
Training loss: 3.397358479699692
Validation loss: 2.6678084340907455

Epoch: 287| Step: 0
Training loss: 3.050858617526906
Validation loss: 2.672803457326001

Epoch: 5| Step: 1
Training loss: 2.391242253021278
Validation loss: 2.6703721743252538

Epoch: 5| Step: 2
Training loss: 2.705736431348274
Validation loss: 2.6705023321849595

Epoch: 5| Step: 3
Training loss: 3.1317505213737893
Validation loss: 2.6683619763784394

Epoch: 5| Step: 4
Training loss: 3.30387633989587
Validation loss: 2.6687207344803863

Epoch: 5| Step: 5
Training loss: 3.1371775062448215
Validation loss: 2.6719657068423985

Epoch: 5| Step: 6
Training loss: 3.1606641061908314
Validation loss: 2.664988775003594

Epoch: 5| Step: 7
Training loss: 3.3774355824480837
Validation loss: 2.6625237369822443

Epoch: 5| Step: 8
Training loss: 2.9465468676050555
Validation loss: 2.663183220002135

Epoch: 5| Step: 9
Training loss: 2.6210825617135
Validation loss: 2.664464358086019

Epoch: 5| Step: 10
Training loss: 3.044481168496062
Validation loss: 2.6662417731516745

Epoch: 288| Step: 0
Training loss: 2.8294802627212134
Validation loss: 2.665931991412654

Epoch: 5| Step: 1
Training loss: 3.198021223282902
Validation loss: 2.6669539334042827

Epoch: 5| Step: 2
Training loss: 2.8254262788248385
Validation loss: 2.6693868939699086

Epoch: 5| Step: 3
Training loss: 2.731825855574983
Validation loss: 2.667292437527468

Epoch: 5| Step: 4
Training loss: 3.0107982530053876
Validation loss: 2.665464103813285

Epoch: 5| Step: 5
Training loss: 2.8677407544279405
Validation loss: 2.668763961307827

Epoch: 5| Step: 6
Training loss: 2.899816796665547
Validation loss: 2.669880905165293

Epoch: 5| Step: 7
Training loss: 2.888042058886769
Validation loss: 2.6719255762231398

Epoch: 5| Step: 8
Training loss: 3.027837346353281
Validation loss: 2.666559531254205

Epoch: 5| Step: 9
Training loss: 3.6719244771018302
Validation loss: 2.6700607671640157

Epoch: 5| Step: 10
Training loss: 2.8723482258858364
Validation loss: 2.6629633546388902

Epoch: 289| Step: 0
Training loss: 2.3606449776577527
Validation loss: 2.6655808386455186

Epoch: 5| Step: 1
Training loss: 3.1649007558102698
Validation loss: 2.66498575345248

Epoch: 5| Step: 2
Training loss: 2.7068033934418456
Validation loss: 2.6621225653291134

Epoch: 5| Step: 3
Training loss: 3.2849946951859605
Validation loss: 2.662055973577913

Epoch: 5| Step: 4
Training loss: 2.9304199930648838
Validation loss: 2.6604157781797415

Epoch: 5| Step: 5
Training loss: 3.1495592565853063
Validation loss: 2.6653350282277595

Epoch: 5| Step: 6
Training loss: 2.2856602300484954
Validation loss: 2.661355779631506

Epoch: 5| Step: 7
Training loss: 3.7558753716995534
Validation loss: 2.663860584402234

Epoch: 5| Step: 8
Training loss: 3.1494264776887078
Validation loss: 2.662347547784513

Epoch: 5| Step: 9
Training loss: 3.0132152040783393
Validation loss: 2.6667333108767655

Epoch: 5| Step: 10
Training loss: 2.7972480056350557
Validation loss: 2.6660102400345393

Epoch: 290| Step: 0
Training loss: 3.5162441132377875
Validation loss: 2.663717919602367

Epoch: 5| Step: 1
Training loss: 2.8570129978096563
Validation loss: 2.662458871125808

Epoch: 5| Step: 2
Training loss: 2.7065684706002475
Validation loss: 2.6617739197958077

Epoch: 5| Step: 3
Training loss: 3.06215136353603
Validation loss: 2.6680067810337342

Epoch: 5| Step: 4
Training loss: 2.86538048952167
Validation loss: 2.663049822182471

Epoch: 5| Step: 5
Training loss: 2.569625994709259
Validation loss: 2.6682845000150484

Epoch: 5| Step: 6
Training loss: 3.2192563149450333
Validation loss: 2.668640484558142

Epoch: 5| Step: 7
Training loss: 3.3105327594647447
Validation loss: 2.672480497011742

Epoch: 5| Step: 8
Training loss: 3.102364309142404
Validation loss: 2.6730643096571662

Epoch: 5| Step: 9
Training loss: 2.7870079187801498
Validation loss: 2.675554964362471

Epoch: 5| Step: 10
Training loss: 2.7258482601449416
Validation loss: 2.678976255824038

Epoch: 291| Step: 0
Training loss: 3.216672504663523
Validation loss: 2.6690773956215397

Epoch: 5| Step: 1
Training loss: 3.1519138274636944
Validation loss: 2.668937882678256

Epoch: 5| Step: 2
Training loss: 3.4048017870421488
Validation loss: 2.6595986989801923

Epoch: 5| Step: 3
Training loss: 2.6900175855551023
Validation loss: 2.6613166565398565

Epoch: 5| Step: 4
Training loss: 3.521824503471454
Validation loss: 2.661605389410208

Epoch: 5| Step: 5
Training loss: 2.4619288793993337
Validation loss: 2.65865002951961

Epoch: 5| Step: 6
Training loss: 2.6784214777072806
Validation loss: 2.6595535177336433

Epoch: 5| Step: 7
Training loss: 2.7751697557093964
Validation loss: 2.657683012131203

Epoch: 5| Step: 8
Training loss: 2.7284215147681556
Validation loss: 2.658517902294666

Epoch: 5| Step: 9
Training loss: 2.5184513113720235
Validation loss: 2.656368237058972

Epoch: 5| Step: 10
Training loss: 3.585575924930323
Validation loss: 2.657243458648918

Epoch: 292| Step: 0
Training loss: 2.786155403759619
Validation loss: 2.6532422828954414

Epoch: 5| Step: 1
Training loss: 3.0941487065033804
Validation loss: 2.6569099402701615

Epoch: 5| Step: 2
Training loss: 2.9819482653381697
Validation loss: 2.6542094539202528

Epoch: 5| Step: 3
Training loss: 2.5677268522160905
Validation loss: 2.661045668018914

Epoch: 5| Step: 4
Training loss: 2.619104213020572
Validation loss: 2.6619491761874987

Epoch: 5| Step: 5
Training loss: 3.0027076899649274
Validation loss: 2.660371815359946

Epoch: 5| Step: 6
Training loss: 2.8104744292804305
Validation loss: 2.6605008609686305

Epoch: 5| Step: 7
Training loss: 2.8431996242602375
Validation loss: 2.6615815310037716

Epoch: 5| Step: 8
Training loss: 3.8168952495861705
Validation loss: 2.6575970944224294

Epoch: 5| Step: 9
Training loss: 2.680023706103567
Validation loss: 2.6540573731497985

Epoch: 5| Step: 10
Training loss: 3.5066540000841475
Validation loss: 2.6554975048179066

Epoch: 293| Step: 0
Training loss: 3.465234710758706
Validation loss: 2.6541999235919183

Epoch: 5| Step: 1
Training loss: 2.7782109834047066
Validation loss: 2.6524100762249114

Epoch: 5| Step: 2
Training loss: 2.794111196906141
Validation loss: 2.6564997672026056

Epoch: 5| Step: 3
Training loss: 2.915109563898285
Validation loss: 2.6573181263195482

Epoch: 5| Step: 4
Training loss: 2.9327176712305514
Validation loss: 2.6558047824503923

Epoch: 5| Step: 5
Training loss: 2.98781926192927
Validation loss: 2.655234512509459

Epoch: 5| Step: 6
Training loss: 3.623959753802486
Validation loss: 2.655046434278558

Epoch: 5| Step: 7
Training loss: 2.62033520337837
Validation loss: 2.656594362080806

Epoch: 5| Step: 8
Training loss: 2.9024702534888616
Validation loss: 2.6560994751641998

Epoch: 5| Step: 9
Training loss: 2.6675226109412478
Validation loss: 2.6552717469260205

Epoch: 5| Step: 10
Training loss: 2.9899640699288232
Validation loss: 2.6534350019401436

Epoch: 294| Step: 0
Training loss: 3.1039202974252667
Validation loss: 2.655977570800923

Epoch: 5| Step: 1
Training loss: 3.2069760874233495
Validation loss: 2.6529682934427505

Epoch: 5| Step: 2
Training loss: 3.015918302355343
Validation loss: 2.6521279555039854

Epoch: 5| Step: 3
Training loss: 3.1092814522477683
Validation loss: 2.654936584581404

Epoch: 5| Step: 4
Training loss: 2.717525513361647
Validation loss: 2.6520428206289672

Epoch: 5| Step: 5
Training loss: 2.988690995192727
Validation loss: 2.6576564532564304

Epoch: 5| Step: 6
Training loss: 2.8298393659529806
Validation loss: 2.6537256356951913

Epoch: 5| Step: 7
Training loss: 2.7837999634183714
Validation loss: 2.6496654358121963

Epoch: 5| Step: 8
Training loss: 3.24014784299013
Validation loss: 2.6498514763385206

Epoch: 5| Step: 9
Training loss: 2.7315557278194693
Validation loss: 2.6525060820972026

Epoch: 5| Step: 10
Training loss: 3.0600834868766693
Validation loss: 2.6495628065562324

Epoch: 295| Step: 0
Training loss: 2.5254414163129986
Validation loss: 2.6523163349272147

Epoch: 5| Step: 1
Training loss: 3.0711696680390053
Validation loss: 2.6509756672388387

Epoch: 5| Step: 2
Training loss: 2.801908258312625
Validation loss: 2.6582605916404924

Epoch: 5| Step: 3
Training loss: 2.748018244287155
Validation loss: 2.648934727130012

Epoch: 5| Step: 4
Training loss: 3.3238743246124502
Validation loss: 2.6544857031474596

Epoch: 5| Step: 5
Training loss: 2.8459333485072182
Validation loss: 2.6537999396171683

Epoch: 5| Step: 6
Training loss: 2.860701289860934
Validation loss: 2.647553632099378

Epoch: 5| Step: 7
Training loss: 3.3109625361289448
Validation loss: 2.648337364209456

Epoch: 5| Step: 8
Training loss: 3.2417081547479074
Validation loss: 2.656725386968555

Epoch: 5| Step: 9
Training loss: 2.9303163387618825
Validation loss: 2.6496507544149717

Epoch: 5| Step: 10
Training loss: 3.054097384455878
Validation loss: 2.6593006666232637

Epoch: 296| Step: 0
Training loss: 2.889090960926182
Validation loss: 2.6566342910074536

Epoch: 5| Step: 1
Training loss: 3.245314521770555
Validation loss: 2.6572920471410586

Epoch: 5| Step: 2
Training loss: 3.1492119302867425
Validation loss: 2.6530138448421967

Epoch: 5| Step: 3
Training loss: 2.965191445048048
Validation loss: 2.651613150949579

Epoch: 5| Step: 4
Training loss: 3.347503266906284
Validation loss: 2.662470319799044

Epoch: 5| Step: 5
Training loss: 2.920594939671666
Validation loss: 2.658056871535804

Epoch: 5| Step: 6
Training loss: 2.533519528054924
Validation loss: 2.6637516669780856

Epoch: 5| Step: 7
Training loss: 3.0719404491076596
Validation loss: 2.6601450843390584

Epoch: 5| Step: 8
Training loss: 2.663673171068115
Validation loss: 2.6486461026192694

Epoch: 5| Step: 9
Training loss: 2.8900249786353456
Validation loss: 2.657619932802708

Epoch: 5| Step: 10
Training loss: 3.0347595348338783
Validation loss: 2.6503441898785893

Epoch: 297| Step: 0
Training loss: 2.387052272337747
Validation loss: 2.6547800995255635

Epoch: 5| Step: 1
Training loss: 2.745330834802445
Validation loss: 2.6566798982421846

Epoch: 5| Step: 2
Training loss: 3.864232639465013
Validation loss: 2.650705850821906

Epoch: 5| Step: 3
Training loss: 3.525091692225698
Validation loss: 2.650266424752933

Epoch: 5| Step: 4
Training loss: 3.022361859745235
Validation loss: 2.6550065331308854

Epoch: 5| Step: 5
Training loss: 2.9406025511708713
Validation loss: 2.6506759868739898

Epoch: 5| Step: 6
Training loss: 3.0701680622633662
Validation loss: 2.6444367984908106

Epoch: 5| Step: 7
Training loss: 3.076041973943767
Validation loss: 2.646537256592283

Epoch: 5| Step: 8
Training loss: 2.5289152704407396
Validation loss: 2.649022309701414

Epoch: 5| Step: 9
Training loss: 2.3490988160026327
Validation loss: 2.6520221822214296

Epoch: 5| Step: 10
Training loss: 2.887925325585346
Validation loss: 2.6479631887894204

Epoch: 298| Step: 0
Training loss: 3.012151427303797
Validation loss: 2.663667319873407

Epoch: 5| Step: 1
Training loss: 3.0893588258264715
Validation loss: 2.6615406071260717

Epoch: 5| Step: 2
Training loss: 2.61129379535213
Validation loss: 2.6682457369698316

Epoch: 5| Step: 3
Training loss: 3.123181386106164
Validation loss: 2.667157761155888

Epoch: 5| Step: 4
Training loss: 3.148715705033639
Validation loss: 2.6725312785679525

Epoch: 5| Step: 5
Training loss: 3.065930527638416
Validation loss: 2.6687175365568723

Epoch: 5| Step: 6
Training loss: 2.784035648512335
Validation loss: 2.6709376928317448

Epoch: 5| Step: 7
Training loss: 2.666432688302857
Validation loss: 2.6658147863126973

Epoch: 5| Step: 8
Training loss: 3.1174109816212106
Validation loss: 2.664895016821608

Epoch: 5| Step: 9
Training loss: 2.744417072096148
Validation loss: 2.6621157366431247

Epoch: 5| Step: 10
Training loss: 3.3738496020703317
Validation loss: 2.6659193440226514

Epoch: 299| Step: 0
Training loss: 3.400402404309006
Validation loss: 2.6589581171739916

Epoch: 5| Step: 1
Training loss: 2.3930916620434526
Validation loss: 2.6521799503098045

Epoch: 5| Step: 2
Training loss: 2.57182782154219
Validation loss: 2.6514161737461537

Epoch: 5| Step: 3
Training loss: 3.125925461108009
Validation loss: 2.6441697256940446

Epoch: 5| Step: 4
Training loss: 2.80106385320235
Validation loss: 2.6500924533683334

Epoch: 5| Step: 5
Training loss: 3.2204339520439693
Validation loss: 2.6486864436690762

Epoch: 5| Step: 6
Training loss: 3.1547944895800066
Validation loss: 2.649978193911956

Epoch: 5| Step: 7
Training loss: 2.714590552069863
Validation loss: 2.6496300257767835

Epoch: 5| Step: 8
Training loss: 3.3095583539821574
Validation loss: 2.654166360955119

Epoch: 5| Step: 9
Training loss: 2.8902902770201147
Validation loss: 2.6512108302034934

Epoch: 5| Step: 10
Training loss: 3.0104298486827976
Validation loss: 2.6520429047289413

Epoch: 300| Step: 0
Training loss: 2.789729020006409
Validation loss: 2.6473095061963914

Epoch: 5| Step: 1
Training loss: 3.462987426162175
Validation loss: 2.6414272805324246

Epoch: 5| Step: 2
Training loss: 2.6007460954191846
Validation loss: 2.6550190688386373

Epoch: 5| Step: 3
Training loss: 2.9285841021114023
Validation loss: 2.655656477786641

Epoch: 5| Step: 4
Training loss: 2.720335311837823
Validation loss: 2.646770875269227

Epoch: 5| Step: 5
Training loss: 2.7074875220013874
Validation loss: 2.650201969882115

Epoch: 5| Step: 6
Training loss: 2.6446353773524787
Validation loss: 2.639394870802815

Epoch: 5| Step: 7
Training loss: 3.5481528782383482
Validation loss: 2.653880220021641

Epoch: 5| Step: 8
Training loss: 3.0778557519258576
Validation loss: 2.6516199805785994

Epoch: 5| Step: 9
Training loss: 3.092088349435988
Validation loss: 2.647690959427884

Epoch: 5| Step: 10
Training loss: 2.9847951862861795
Validation loss: 2.6491124490393454

Epoch: 301| Step: 0
Training loss: 3.154102312352843
Validation loss: 2.647528314663792

Epoch: 5| Step: 1
Training loss: 3.163206535694971
Validation loss: 2.6484736083977696

Epoch: 5| Step: 2
Training loss: 2.8643460447115987
Validation loss: 2.6527782676702194

Epoch: 5| Step: 3
Training loss: 3.162808996492045
Validation loss: 2.652283550232128

Epoch: 5| Step: 4
Training loss: 2.4617610461670103
Validation loss: 2.652367223692264

Epoch: 5| Step: 5
Training loss: 2.9701139830221255
Validation loss: 2.65346711494527

Epoch: 5| Step: 6
Training loss: 3.232813361395034
Validation loss: 2.6563696702207094

Epoch: 5| Step: 7
Training loss: 2.6815316219083516
Validation loss: 2.6461210529628283

Epoch: 5| Step: 8
Training loss: 2.6604748505692504
Validation loss: 2.6494684695885815

Epoch: 5| Step: 9
Training loss: 3.2503788067062214
Validation loss: 2.649042033720001

Epoch: 5| Step: 10
Training loss: 3.012211265814518
Validation loss: 2.648912994110439

Epoch: 302| Step: 0
Training loss: 3.050717791533511
Validation loss: 2.6534800806131242

Epoch: 5| Step: 1
Training loss: 2.7195634173184215
Validation loss: 2.6578552202148593

Epoch: 5| Step: 2
Training loss: 2.9438683488061317
Validation loss: 2.6512995733327123

Epoch: 5| Step: 3
Training loss: 3.3798723724918216
Validation loss: 2.6476508414047437

Epoch: 5| Step: 4
Training loss: 2.8349898675539036
Validation loss: 2.6472181782170803

Epoch: 5| Step: 5
Training loss: 3.126516508253138
Validation loss: 2.658817061804861

Epoch: 5| Step: 6
Training loss: 3.3218378849055457
Validation loss: 2.660671858583523

Epoch: 5| Step: 7
Training loss: 2.867975693135494
Validation loss: 2.6516102533794035

Epoch: 5| Step: 8
Training loss: 2.899091209868991
Validation loss: 2.6487944929813465

Epoch: 5| Step: 9
Training loss: 2.664282557552459
Validation loss: 2.644080754901099

Epoch: 5| Step: 10
Training loss: 2.7992617689782833
Validation loss: 2.6469345384972858

Epoch: 303| Step: 0
Training loss: 3.218470292761862
Validation loss: 2.6483962055529435

Epoch: 5| Step: 1
Training loss: 3.227926266250002
Validation loss: 2.6451645279486105

Epoch: 5| Step: 2
Training loss: 2.9630050486207167
Validation loss: 2.6485174463878813

Epoch: 5| Step: 3
Training loss: 2.662370340118349
Validation loss: 2.6495052693107364

Epoch: 5| Step: 4
Training loss: 2.924151507824184
Validation loss: 2.646299419154075

Epoch: 5| Step: 5
Training loss: 2.8010292954252667
Validation loss: 2.6573156893666106

Epoch: 5| Step: 6
Training loss: 2.7929696036384186
Validation loss: 2.656297308580751

Epoch: 5| Step: 7
Training loss: 3.525125779958265
Validation loss: 2.666479160525639

Epoch: 5| Step: 8
Training loss: 2.5687014275852245
Validation loss: 2.6610196937737762

Epoch: 5| Step: 9
Training loss: 2.997108019221502
Validation loss: 2.6566822855994596

Epoch: 5| Step: 10
Training loss: 2.8426441096376482
Validation loss: 2.6581815844544137

Epoch: 304| Step: 0
Training loss: 2.2907365009393463
Validation loss: 2.6480758826184765

Epoch: 5| Step: 1
Training loss: 2.672806872885213
Validation loss: 2.652763959137132

Epoch: 5| Step: 2
Training loss: 3.3878682967419698
Validation loss: 2.65601009031044

Epoch: 5| Step: 3
Training loss: 3.2442626195266633
Validation loss: 2.6556589635643015

Epoch: 5| Step: 4
Training loss: 3.05386505372412
Validation loss: 2.645942131681997

Epoch: 5| Step: 5
Training loss: 3.2529742496384806
Validation loss: 2.6464229405120068

Epoch: 5| Step: 6
Training loss: 3.344031491418791
Validation loss: 2.647492830533129

Epoch: 5| Step: 7
Training loss: 2.6727945630397034
Validation loss: 2.6408649570256104

Epoch: 5| Step: 8
Training loss: 2.6522166428145275
Validation loss: 2.6475020102637825

Epoch: 5| Step: 9
Training loss: 3.1695503021788425
Validation loss: 2.6375368393412746

Epoch: 5| Step: 10
Training loss: 2.6477570236267054
Validation loss: 2.641926979827446

Epoch: 305| Step: 0
Training loss: 2.877600116065211
Validation loss: 2.6373134332240755

Epoch: 5| Step: 1
Training loss: 3.0303895653304336
Validation loss: 2.644148350056543

Epoch: 5| Step: 2
Training loss: 2.6322464603295566
Validation loss: 2.6456635000537503

Epoch: 5| Step: 3
Training loss: 3.1300682167687617
Validation loss: 2.637023761324692

Epoch: 5| Step: 4
Training loss: 3.042492810932778
Validation loss: 2.6436071883993417

Epoch: 5| Step: 5
Training loss: 2.512362906288478
Validation loss: 2.6395252576249146

Epoch: 5| Step: 6
Training loss: 3.375905233418073
Validation loss: 2.6307958527679753

Epoch: 5| Step: 7
Training loss: 3.1484637010870853
Validation loss: 2.6296936961223185

Epoch: 5| Step: 8
Training loss: 2.636209622431585
Validation loss: 2.6333584277119213

Epoch: 5| Step: 9
Training loss: 3.315248608595137
Validation loss: 2.6303207238616064

Epoch: 5| Step: 10
Training loss: 2.831321301099293
Validation loss: 2.6345486728840095

Epoch: 306| Step: 0
Training loss: 3.0562889798726838
Validation loss: 2.6355203441722783

Epoch: 5| Step: 1
Training loss: 3.113379884925919
Validation loss: 2.6307372930849175

Epoch: 5| Step: 2
Training loss: 2.812812194451251
Validation loss: 2.6327012693012293

Epoch: 5| Step: 3
Training loss: 2.668323320143253
Validation loss: 2.6258335757903635

Epoch: 5| Step: 4
Training loss: 3.7654388508353023
Validation loss: 2.635201709299106

Epoch: 5| Step: 5
Training loss: 2.656089867645627
Validation loss: 2.6343234738007637

Epoch: 5| Step: 6
Training loss: 3.244646798824349
Validation loss: 2.635025272264148

Epoch: 5| Step: 7
Training loss: 2.976119201169999
Validation loss: 2.6398365134530306

Epoch: 5| Step: 8
Training loss: 3.1786822855371524
Validation loss: 2.626796583226336

Epoch: 5| Step: 9
Training loss: 1.9359398374628052
Validation loss: 2.6358148177686753

Epoch: 5| Step: 10
Training loss: 2.8575470297907297
Validation loss: 2.6334460873242587

Epoch: 307| Step: 0
Training loss: 2.7051425526792783
Validation loss: 2.638166853938706

Epoch: 5| Step: 1
Training loss: 2.636631038761037
Validation loss: 2.6347514570332917

Epoch: 5| Step: 2
Training loss: 3.494090131604839
Validation loss: 2.6379963032528964

Epoch: 5| Step: 3
Training loss: 3.0403900777114106
Validation loss: 2.631668981259783

Epoch: 5| Step: 4
Training loss: 2.8826768631285744
Validation loss: 2.6330054700413483

Epoch: 5| Step: 5
Training loss: 2.9473924653786274
Validation loss: 2.627398364557973

Epoch: 5| Step: 6
Training loss: 3.410637785482323
Validation loss: 2.630643600532866

Epoch: 5| Step: 7
Training loss: 2.792423990115052
Validation loss: 2.6319342913076307

Epoch: 5| Step: 8
Training loss: 2.322188726616583
Validation loss: 2.6363088253740643

Epoch: 5| Step: 9
Training loss: 3.3257575412628326
Validation loss: 2.6342705815615535

Epoch: 5| Step: 10
Training loss: 2.8271003679527396
Validation loss: 2.6295874084563478

Epoch: 308| Step: 0
Training loss: 2.9418406779951614
Validation loss: 2.630121155842127

Epoch: 5| Step: 1
Training loss: 2.8641734066897673
Validation loss: 2.631017227249219

Epoch: 5| Step: 2
Training loss: 2.800876418961471
Validation loss: 2.6284259193443433

Epoch: 5| Step: 3
Training loss: 2.9620169330244277
Validation loss: 2.6282999583857505

Epoch: 5| Step: 4
Training loss: 3.3323410623571506
Validation loss: 2.6258054865702065

Epoch: 5| Step: 5
Training loss: 2.976991317177675
Validation loss: 2.631129061623038

Epoch: 5| Step: 6
Training loss: 3.2032110435280226
Validation loss: 2.625194951527167

Epoch: 5| Step: 7
Training loss: 2.8037009881778796
Validation loss: 2.631394157214725

Epoch: 5| Step: 8
Training loss: 2.538522140517579
Validation loss: 2.6343039811635

Epoch: 5| Step: 9
Training loss: 3.162818343834915
Validation loss: 2.6268318121116154

Epoch: 5| Step: 10
Training loss: 2.9333650421104904
Validation loss: 2.635675806582134

Epoch: 309| Step: 0
Training loss: 3.2896135099708763
Validation loss: 2.6325606918915243

Epoch: 5| Step: 1
Training loss: 3.126410051753695
Validation loss: 2.6372739748579037

Epoch: 5| Step: 2
Training loss: 2.6912140133972553
Validation loss: 2.6371914809356536

Epoch: 5| Step: 3
Training loss: 2.534036962352484
Validation loss: 2.6406975814029487

Epoch: 5| Step: 4
Training loss: 2.9321817182093395
Validation loss: 2.642464148922924

Epoch: 5| Step: 5
Training loss: 3.2023409744552196
Validation loss: 2.6389504681497624

Epoch: 5| Step: 6
Training loss: 2.9818027455761373
Validation loss: 2.641429400215576

Epoch: 5| Step: 7
Training loss: 3.2419365843230894
Validation loss: 2.639218723802716

Epoch: 5| Step: 8
Training loss: 3.088402335941265
Validation loss: 2.629258542080458

Epoch: 5| Step: 9
Training loss: 2.6502296888028147
Validation loss: 2.6289731187709733

Epoch: 5| Step: 10
Training loss: 2.758947641321765
Validation loss: 2.6321879796689225

Epoch: 310| Step: 0
Training loss: 3.0496614674785043
Validation loss: 2.6317331779433766

Epoch: 5| Step: 1
Training loss: 2.6703549349891302
Validation loss: 2.6279238654932953

Epoch: 5| Step: 2
Training loss: 2.954315914227375
Validation loss: 2.6320788405385467

Epoch: 5| Step: 3
Training loss: 3.0796291336110486
Validation loss: 2.6414193812037223

Epoch: 5| Step: 4
Training loss: 3.035149023177529
Validation loss: 2.646149233161924

Epoch: 5| Step: 5
Training loss: 2.8679273103044194
Validation loss: 2.653519734681301

Epoch: 5| Step: 6
Training loss: 2.8518292027996552
Validation loss: 2.654610902047099

Epoch: 5| Step: 7
Training loss: 3.120883519202485
Validation loss: 2.648270122826643

Epoch: 5| Step: 8
Training loss: 2.848705961682941
Validation loss: 2.636049877359065

Epoch: 5| Step: 9
Training loss: 2.8241665783887098
Validation loss: 2.629027112219338

Epoch: 5| Step: 10
Training loss: 3.3122201477451503
Validation loss: 2.625364085944489

Epoch: 311| Step: 0
Training loss: 3.0118718485628713
Validation loss: 2.6232498768796675

Epoch: 5| Step: 1
Training loss: 2.8558638230243365
Validation loss: 2.6257174927913263

Epoch: 5| Step: 2
Training loss: 2.539526700355089
Validation loss: 2.6260336565988425

Epoch: 5| Step: 3
Training loss: 3.1540620982189598
Validation loss: 2.6241032347506774

Epoch: 5| Step: 4
Training loss: 2.7546217834284925
Validation loss: 2.6224377623666943

Epoch: 5| Step: 5
Training loss: 2.846109941108214
Validation loss: 2.6233839733883095

Epoch: 5| Step: 6
Training loss: 2.960430977608016
Validation loss: 2.6189222776800145

Epoch: 5| Step: 7
Training loss: 3.241627693105426
Validation loss: 2.624808347925926

Epoch: 5| Step: 8
Training loss: 3.1351195708961273
Validation loss: 2.6312907753711987

Epoch: 5| Step: 9
Training loss: 2.820469141279585
Validation loss: 2.632170870092494

Epoch: 5| Step: 10
Training loss: 3.2648072017277108
Validation loss: 2.630174977568137

Epoch: 312| Step: 0
Training loss: 2.6388680295510185
Validation loss: 2.6430096398376124

Epoch: 5| Step: 1
Training loss: 2.8960362278690304
Validation loss: 2.644365104993593

Epoch: 5| Step: 2
Training loss: 2.5152663455026705
Validation loss: 2.6453261861144313

Epoch: 5| Step: 3
Training loss: 2.8801478861880474
Validation loss: 2.646624703461945

Epoch: 5| Step: 4
Training loss: 2.9711254052986775
Validation loss: 2.6437591682515014

Epoch: 5| Step: 5
Training loss: 3.2590585790931175
Validation loss: 2.6389364955719055

Epoch: 5| Step: 6
Training loss: 3.0268697650619187
Validation loss: 2.638673724858675

Epoch: 5| Step: 7
Training loss: 2.820034953908527
Validation loss: 2.641541289701735

Epoch: 5| Step: 8
Training loss: 3.581383965934146
Validation loss: 2.6294289097575283

Epoch: 5| Step: 9
Training loss: 2.899841297674198
Validation loss: 2.6173379334762736

Epoch: 5| Step: 10
Training loss: 3.08170292680478
Validation loss: 2.6262501436689067

Epoch: 313| Step: 0
Training loss: 2.6742910426066953
Validation loss: 2.626182044880401

Epoch: 5| Step: 1
Training loss: 2.9686248752928552
Validation loss: 2.628517634975173

Epoch: 5| Step: 2
Training loss: 3.392100632731241
Validation loss: 2.6294648073016265

Epoch: 5| Step: 3
Training loss: 2.7527547390312996
Validation loss: 2.6260807373315362

Epoch: 5| Step: 4
Training loss: 2.753034391438493
Validation loss: 2.623136819180928

Epoch: 5| Step: 5
Training loss: 3.173625444249555
Validation loss: 2.626401045877647

Epoch: 5| Step: 6
Training loss: 2.983603972052648
Validation loss: 2.623834230511497

Epoch: 5| Step: 7
Training loss: 3.039666044815033
Validation loss: 2.6333699240452204

Epoch: 5| Step: 8
Training loss: 3.05693233182746
Validation loss: 2.634639859131187

Epoch: 5| Step: 9
Training loss: 2.978539798826082
Validation loss: 2.638378500051932

Epoch: 5| Step: 10
Training loss: 2.7405221778432987
Validation loss: 2.6400477844057844

Epoch: 314| Step: 0
Training loss: 2.9657523028401678
Validation loss: 2.640413571338758

Epoch: 5| Step: 1
Training loss: 2.786044499454719
Validation loss: 2.6406262261784126

Epoch: 5| Step: 2
Training loss: 3.397500095213046
Validation loss: 2.6388954847591966

Epoch: 5| Step: 3
Training loss: 2.8105403430854863
Validation loss: 2.638171848732865

Epoch: 5| Step: 4
Training loss: 2.5236069944165367
Validation loss: 2.622652197330215

Epoch: 5| Step: 5
Training loss: 3.148847302443617
Validation loss: 2.617273244614874

Epoch: 5| Step: 6
Training loss: 2.4214616976600856
Validation loss: 2.6128849500548452

Epoch: 5| Step: 7
Training loss: 3.5567528394313856
Validation loss: 2.6133461151737563

Epoch: 5| Step: 8
Training loss: 2.835108444050486
Validation loss: 2.6128321301153594

Epoch: 5| Step: 9
Training loss: 3.251797985695069
Validation loss: 2.614448353332124

Epoch: 5| Step: 10
Training loss: 2.664626075892941
Validation loss: 2.6186764028661966

Epoch: 315| Step: 0
Training loss: 2.7204334703221424
Validation loss: 2.612661544657547

Epoch: 5| Step: 1
Training loss: 3.167933528530314
Validation loss: 2.611973655901884

Epoch: 5| Step: 2
Training loss: 2.7854950472736855
Validation loss: 2.613644191552367

Epoch: 5| Step: 3
Training loss: 3.1685794942454164
Validation loss: 2.612655260807116

Epoch: 5| Step: 4
Training loss: 3.0381269019960038
Validation loss: 2.619951948363853

Epoch: 5| Step: 5
Training loss: 2.9404703908362633
Validation loss: 2.619088186695106

Epoch: 5| Step: 6
Training loss: 2.6365497450176965
Validation loss: 2.6227968358653393

Epoch: 5| Step: 7
Training loss: 2.938725317393388
Validation loss: 2.633553655101147

Epoch: 5| Step: 8
Training loss: 2.8755096315565205
Validation loss: 2.630361667591504

Epoch: 5| Step: 9
Training loss: 2.742315305682191
Validation loss: 2.637530422302539

Epoch: 5| Step: 10
Training loss: 3.523996786655169
Validation loss: 2.6437707609324725

Epoch: 316| Step: 0
Training loss: 3.0796851836979178
Validation loss: 2.6382570736232616

Epoch: 5| Step: 1
Training loss: 3.092940715943141
Validation loss: 2.6249649076757904

Epoch: 5| Step: 2
Training loss: 3.3621906634565035
Validation loss: 2.6318807373885162

Epoch: 5| Step: 3
Training loss: 3.3029135413500157
Validation loss: 2.6383230106354265

Epoch: 5| Step: 4
Training loss: 3.1556066480568745
Validation loss: 2.6230009185195917

Epoch: 5| Step: 5
Training loss: 2.30711645375277
Validation loss: 2.6226723268956453

Epoch: 5| Step: 6
Training loss: 2.554468921328216
Validation loss: 2.6178604987122465

Epoch: 5| Step: 7
Training loss: 2.507988469019761
Validation loss: 2.6254683436652684

Epoch: 5| Step: 8
Training loss: 3.2254043976123685
Validation loss: 2.6175060369172773

Epoch: 5| Step: 9
Training loss: 3.1792363777033787
Validation loss: 2.6155458348925293

Epoch: 5| Step: 10
Training loss: 2.3896350680944973
Validation loss: 2.6156844280947236

Epoch: 317| Step: 0
Training loss: 2.9544634334143187
Validation loss: 2.6163417418738506

Epoch: 5| Step: 1
Training loss: 3.418645301345422
Validation loss: 2.616765410453855

Epoch: 5| Step: 2
Training loss: 2.8751623688334127
Validation loss: 2.617629480241577

Epoch: 5| Step: 3
Training loss: 3.1679976493749664
Validation loss: 2.615334139284255

Epoch: 5| Step: 4
Training loss: 2.8294327383720717
Validation loss: 2.624155964592861

Epoch: 5| Step: 5
Training loss: 2.9797623223370735
Validation loss: 2.6200668117734467

Epoch: 5| Step: 6
Training loss: 2.758367985011221
Validation loss: 2.6271754390224378

Epoch: 5| Step: 7
Training loss: 2.716188298177206
Validation loss: 2.6150314469331755

Epoch: 5| Step: 8
Training loss: 2.8947803220266937
Validation loss: 2.6280929237862445

Epoch: 5| Step: 9
Training loss: 2.95999637835513
Validation loss: 2.6261460038672033

Epoch: 5| Step: 10
Training loss: 2.7959645243837676
Validation loss: 2.6272171089757417

Epoch: 318| Step: 0
Training loss: 3.0335821245330776
Validation loss: 2.6279530183210515

Epoch: 5| Step: 1
Training loss: 2.894322355611648
Validation loss: 2.623898732705812

Epoch: 5| Step: 2
Training loss: 3.7377836241004188
Validation loss: 2.6391758455284813

Epoch: 5| Step: 3
Training loss: 3.2712763751507805
Validation loss: 2.620865031549763

Epoch: 5| Step: 4
Training loss: 2.9261440159158063
Validation loss: 2.6161221751343766

Epoch: 5| Step: 5
Training loss: 2.3366374622466286
Validation loss: 2.6181693255600056

Epoch: 5| Step: 6
Training loss: 2.9204506079610453
Validation loss: 2.6170047868262944

Epoch: 5| Step: 7
Training loss: 2.8777187595018843
Validation loss: 2.6132389016551194

Epoch: 5| Step: 8
Training loss: 2.1879580426909304
Validation loss: 2.618069425490131

Epoch: 5| Step: 9
Training loss: 2.8180712303434685
Validation loss: 2.613645088065805

Epoch: 5| Step: 10
Training loss: 3.2040488794815434
Validation loss: 2.6124706517285556

Epoch: 319| Step: 0
Training loss: 2.4431362034932844
Validation loss: 2.6088743681970366

Epoch: 5| Step: 1
Training loss: 3.1263055744440282
Validation loss: 2.6094108148270663

Epoch: 5| Step: 2
Training loss: 3.031313079492265
Validation loss: 2.612609071491392

Epoch: 5| Step: 3
Training loss: 2.8986041491533077
Validation loss: 2.610248294027813

Epoch: 5| Step: 4
Training loss: 3.4012328829714886
Validation loss: 2.6148576431177153

Epoch: 5| Step: 5
Training loss: 2.8143841684062054
Validation loss: 2.6119510529420458

Epoch: 5| Step: 6
Training loss: 2.8530455194873934
Validation loss: 2.6101180466506104

Epoch: 5| Step: 7
Training loss: 3.0860842899225607
Validation loss: 2.6191238334632416

Epoch: 5| Step: 8
Training loss: 2.771938724924988
Validation loss: 2.6171255746885476

Epoch: 5| Step: 9
Training loss: 2.8417483820497416
Validation loss: 2.620418730819515

Epoch: 5| Step: 10
Training loss: 3.1153401419643214
Validation loss: 2.6128942268426267

Epoch: 320| Step: 0
Training loss: 3.235082281796727
Validation loss: 2.620903547524721

Epoch: 5| Step: 1
Training loss: 2.623610810126745
Validation loss: 2.6181952686193233

Epoch: 5| Step: 2
Training loss: 3.0028479092015132
Validation loss: 2.629086777736856

Epoch: 5| Step: 3
Training loss: 3.041665656381378
Validation loss: 2.6336236181839126

Epoch: 5| Step: 4
Training loss: 2.567818959750179
Validation loss: 2.6268527001570976

Epoch: 5| Step: 5
Training loss: 2.9120830122779724
Validation loss: 2.6349305539482226

Epoch: 5| Step: 6
Training loss: 3.1596199401025364
Validation loss: 2.634125769146584

Epoch: 5| Step: 7
Training loss: 2.8974813441942318
Validation loss: 2.615505513940663

Epoch: 5| Step: 8
Training loss: 2.6417755690147975
Validation loss: 2.608488608644326

Epoch: 5| Step: 9
Training loss: 2.9162422598005606
Validation loss: 2.607271050311162

Epoch: 5| Step: 10
Training loss: 3.4173247161093765
Validation loss: 2.6091863897954797

Epoch: 321| Step: 0
Training loss: 3.096868465351251
Validation loss: 2.6067428670141117

Epoch: 5| Step: 1
Training loss: 3.1528905231260205
Validation loss: 2.6083146745232644

Epoch: 5| Step: 2
Training loss: 2.999034249308906
Validation loss: 2.6089515492273208

Epoch: 5| Step: 3
Training loss: 2.830972660451463
Validation loss: 2.605708651564297

Epoch: 5| Step: 4
Training loss: 2.835528215451244
Validation loss: 2.605486451128969

Epoch: 5| Step: 5
Training loss: 3.2782590767757953
Validation loss: 2.603523561542354

Epoch: 5| Step: 6
Training loss: 2.3955930064090514
Validation loss: 2.606026455861784

Epoch: 5| Step: 7
Training loss: 2.941159018857454
Validation loss: 2.616181613650435

Epoch: 5| Step: 8
Training loss: 3.281350706462397
Validation loss: 2.6212332010053365

Epoch: 5| Step: 9
Training loss: 2.8623498335850246
Validation loss: 2.6221584589782894

Epoch: 5| Step: 10
Training loss: 2.5859382375848647
Validation loss: 2.6390319434269927

Epoch: 322| Step: 0
Training loss: 3.0733884977187893
Validation loss: 2.6400910223700707

Epoch: 5| Step: 1
Training loss: 2.3709665481157542
Validation loss: 2.6535085681463686

Epoch: 5| Step: 2
Training loss: 3.401939534506095
Validation loss: 2.6634852055393154

Epoch: 5| Step: 3
Training loss: 3.0436982638056866
Validation loss: 2.6399568102011246

Epoch: 5| Step: 4
Training loss: 2.772621572046013
Validation loss: 2.6275536011253298

Epoch: 5| Step: 5
Training loss: 3.2079874488033284
Validation loss: 2.621550723159738

Epoch: 5| Step: 6
Training loss: 3.145856457218967
Validation loss: 2.612364171657817

Epoch: 5| Step: 7
Training loss: 2.2765484790461876
Validation loss: 2.607802134812585

Epoch: 5| Step: 8
Training loss: 2.9643158574631716
Validation loss: 2.609549689651906

Epoch: 5| Step: 9
Training loss: 2.8148917307114036
Validation loss: 2.602110146611853

Epoch: 5| Step: 10
Training loss: 3.2051797370680513
Validation loss: 2.603371541039866

Epoch: 323| Step: 0
Training loss: 2.929233526024819
Validation loss: 2.60822758270718

Epoch: 5| Step: 1
Training loss: 3.168309053518289
Validation loss: 2.6053403143268676

Epoch: 5| Step: 2
Training loss: 2.6769932139228363
Validation loss: 2.6020555808349766

Epoch: 5| Step: 3
Training loss: 2.7482674082507725
Validation loss: 2.6040974551612144

Epoch: 5| Step: 4
Training loss: 2.5868251233708452
Validation loss: 2.6015206014293195

Epoch: 5| Step: 5
Training loss: 3.069624263124113
Validation loss: 2.602176548340013

Epoch: 5| Step: 6
Training loss: 3.151388673617488
Validation loss: 2.599954010483343

Epoch: 5| Step: 7
Training loss: 3.3775643390708323
Validation loss: 2.605864280057471

Epoch: 5| Step: 8
Training loss: 3.1771690648920052
Validation loss: 2.612892448998593

Epoch: 5| Step: 9
Training loss: 2.731407866291183
Validation loss: 2.6160141199084674

Epoch: 5| Step: 10
Training loss: 2.6765390478599858
Validation loss: 2.61767147452147

Epoch: 324| Step: 0
Training loss: 3.2510939004245083
Validation loss: 2.650627902870324

Epoch: 5| Step: 1
Training loss: 3.0051217862806188
Validation loss: 2.669824543249515

Epoch: 5| Step: 2
Training loss: 2.982917789381398
Validation loss: 2.7277548835639682

Epoch: 5| Step: 3
Training loss: 2.820112564735156
Validation loss: 2.7291617739052034

Epoch: 5| Step: 4
Training loss: 3.7085279492233707
Validation loss: 2.706132788673901

Epoch: 5| Step: 5
Training loss: 3.1740431117090697
Validation loss: 2.6462733757328976

Epoch: 5| Step: 6
Training loss: 2.9457427907047924
Validation loss: 2.63637662757653

Epoch: 5| Step: 7
Training loss: 3.061333414657051
Validation loss: 2.624988276567273

Epoch: 5| Step: 8
Training loss: 2.0672384219770925
Validation loss: 2.6264750667072976

Epoch: 5| Step: 9
Training loss: 2.3333895767336155
Validation loss: 2.6185014664015474

Epoch: 5| Step: 10
Training loss: 3.053355675439287
Validation loss: 2.6191042942629172

Epoch: 325| Step: 0
Training loss: 3.040887044688554
Validation loss: 2.637286854883186

Epoch: 5| Step: 1
Training loss: 3.1029440159567994
Validation loss: 2.624532773245599

Epoch: 5| Step: 2
Training loss: 3.1280682569115177
Validation loss: 2.62238324122983

Epoch: 5| Step: 3
Training loss: 3.497012634568684
Validation loss: 2.6206730937119476

Epoch: 5| Step: 4
Training loss: 3.0325199888219996
Validation loss: 2.618317341974764

Epoch: 5| Step: 5
Training loss: 2.4509765547180056
Validation loss: 2.613514702944592

Epoch: 5| Step: 6
Training loss: 2.8772178056814828
Validation loss: 2.6091302289366625

Epoch: 5| Step: 7
Training loss: 2.449968871094046
Validation loss: 2.6148894524266164

Epoch: 5| Step: 8
Training loss: 2.543133567707501
Validation loss: 2.6120946911342613

Epoch: 5| Step: 9
Training loss: 2.9079738959566725
Validation loss: 2.6120472317013435

Epoch: 5| Step: 10
Training loss: 3.3646761917826975
Validation loss: 2.616720005942024

Epoch: 326| Step: 0
Training loss: 3.182495826544651
Validation loss: 2.6167453353788956

Epoch: 5| Step: 1
Training loss: 2.7953440136143284
Validation loss: 2.6223560892397986

Epoch: 5| Step: 2
Training loss: 2.228925127390048
Validation loss: 2.6174443581263827

Epoch: 5| Step: 3
Training loss: 2.692836431313065
Validation loss: 2.6146057903203093

Epoch: 5| Step: 4
Training loss: 2.960685940727929
Validation loss: 2.619440441766281

Epoch: 5| Step: 5
Training loss: 2.7868764308148117
Validation loss: 2.6107250344344344

Epoch: 5| Step: 6
Training loss: 3.565814701420039
Validation loss: 2.607335457363138

Epoch: 5| Step: 7
Training loss: 3.276434862145712
Validation loss: 2.603150864552055

Epoch: 5| Step: 8
Training loss: 2.6164380267250493
Validation loss: 2.5993576390799746

Epoch: 5| Step: 9
Training loss: 2.664782921715565
Validation loss: 2.603738152144302

Epoch: 5| Step: 10
Training loss: 3.431245141642593
Validation loss: 2.593344826648978

Epoch: 327| Step: 0
Training loss: 2.7015399144267187
Validation loss: 2.5954683366580897

Epoch: 5| Step: 1
Training loss: 2.5640204036216225
Validation loss: 2.5970275734970603

Epoch: 5| Step: 2
Training loss: 2.4634647048208733
Validation loss: 2.5992117697028156

Epoch: 5| Step: 3
Training loss: 2.607379172900565
Validation loss: 2.598964831142123

Epoch: 5| Step: 4
Training loss: 3.0682300756493377
Validation loss: 2.6015429353297046

Epoch: 5| Step: 5
Training loss: 3.1912643046194837
Validation loss: 2.5986148969737277

Epoch: 5| Step: 6
Training loss: 2.781422641839356
Validation loss: 2.601392760204373

Epoch: 5| Step: 7
Training loss: 3.495002994126769
Validation loss: 2.6003858856939432

Epoch: 5| Step: 8
Training loss: 2.9208217089136457
Validation loss: 2.59507280271515

Epoch: 5| Step: 9
Training loss: 3.0251940767437273
Validation loss: 2.6051496672659895

Epoch: 5| Step: 10
Training loss: 3.413021810690495
Validation loss: 2.596328194784616

Epoch: 328| Step: 0
Training loss: 2.6772647504279954
Validation loss: 2.5973174568834074

Epoch: 5| Step: 1
Training loss: 3.397362269289801
Validation loss: 2.5924682247207227

Epoch: 5| Step: 2
Training loss: 3.0115436349665625
Validation loss: 2.5961666593441994

Epoch: 5| Step: 3
Training loss: 3.0384873971330904
Validation loss: 2.601040317542065

Epoch: 5| Step: 4
Training loss: 2.024579289378589
Validation loss: 2.5995988762790847

Epoch: 5| Step: 5
Training loss: 3.034157214221167
Validation loss: 2.605420708392122

Epoch: 5| Step: 6
Training loss: 3.2271939230173716
Validation loss: 2.606425516946602

Epoch: 5| Step: 7
Training loss: 2.540260947632717
Validation loss: 2.5969498367043022

Epoch: 5| Step: 8
Training loss: 2.9248252294771118
Validation loss: 2.604397180178918

Epoch: 5| Step: 9
Training loss: 2.7302305365955792
Validation loss: 2.5991321018753206

Epoch: 5| Step: 10
Training loss: 3.5182096347600798
Validation loss: 2.5992442271425187

Epoch: 329| Step: 0
Training loss: 3.4437383745000716
Validation loss: 2.597351074056817

Epoch: 5| Step: 1
Training loss: 2.7159453208599174
Validation loss: 2.5993935648059603

Epoch: 5| Step: 2
Training loss: 3.045102586944264
Validation loss: 2.605257470509703

Epoch: 5| Step: 3
Training loss: 2.4688768957819422
Validation loss: 2.5999505963415954

Epoch: 5| Step: 4
Training loss: 2.8326171268983136
Validation loss: 2.6007642781821767

Epoch: 5| Step: 5
Training loss: 2.5537378255037635
Validation loss: 2.6085290282310534

Epoch: 5| Step: 6
Training loss: 3.4881154327452757
Validation loss: 2.609947834847506

Epoch: 5| Step: 7
Training loss: 3.2983473251788764
Validation loss: 2.6089675474183287

Epoch: 5| Step: 8
Training loss: 2.8581223375686333
Validation loss: 2.5991609098905175

Epoch: 5| Step: 9
Training loss: 2.9257664189898636
Validation loss: 2.600967621537327

Epoch: 5| Step: 10
Training loss: 2.381510194194791
Validation loss: 2.596517779978937

Epoch: 330| Step: 0
Training loss: 2.972593048667005
Validation loss: 2.601450794929202

Epoch: 5| Step: 1
Training loss: 3.221063023544859
Validation loss: 2.5951550904844156

Epoch: 5| Step: 2
Training loss: 2.929867507490773
Validation loss: 2.5992034649202322

Epoch: 5| Step: 3
Training loss: 2.692090748860011
Validation loss: 2.598528902701394

Epoch: 5| Step: 4
Training loss: 2.7034300703652803
Validation loss: 2.5966732208313723

Epoch: 5| Step: 5
Training loss: 3.070290601812414
Validation loss: 2.5944668327470453

Epoch: 5| Step: 6
Training loss: 2.9233582347764786
Validation loss: 2.5956917680124176

Epoch: 5| Step: 7
Training loss: 3.528431941044839
Validation loss: 2.5955772146217835

Epoch: 5| Step: 8
Training loss: 1.9191931644564437
Validation loss: 2.5979454681999616

Epoch: 5| Step: 9
Training loss: 3.306314991995461
Validation loss: 2.598555856745457

Epoch: 5| Step: 10
Training loss: 2.735672735434407
Validation loss: 2.5949886165191156

Epoch: 331| Step: 0
Training loss: 3.243204053972794
Validation loss: 2.6075714620245356

Epoch: 5| Step: 1
Training loss: 2.8650017080251984
Validation loss: 2.6098485051221836

Epoch: 5| Step: 2
Training loss: 2.697971525088656
Validation loss: 2.6114929899677737

Epoch: 5| Step: 3
Training loss: 3.2322716992116263
Validation loss: 2.607706233031345

Epoch: 5| Step: 4
Training loss: 2.612329055815081
Validation loss: 2.60129451212122

Epoch: 5| Step: 5
Training loss: 3.053344431305863
Validation loss: 2.5977735972940663

Epoch: 5| Step: 6
Training loss: 2.895969049214578
Validation loss: 2.599631111438318

Epoch: 5| Step: 7
Training loss: 2.745120661572864
Validation loss: 2.60560080696993

Epoch: 5| Step: 8
Training loss: 2.619196516403557
Validation loss: 2.612683851027042

Epoch: 5| Step: 9
Training loss: 3.2565262631540843
Validation loss: 2.613652819255359

Epoch: 5| Step: 10
Training loss: 2.899803970551622
Validation loss: 2.610670224500072

Epoch: 332| Step: 0
Training loss: 3.1075019754171804
Validation loss: 2.6134092061498344

Epoch: 5| Step: 1
Training loss: 2.666425266863084
Validation loss: 2.6106934218434614

Epoch: 5| Step: 2
Training loss: 2.9376965720777166
Validation loss: 2.615034023286236

Epoch: 5| Step: 3
Training loss: 2.557398765999104
Validation loss: 2.6221385855337624

Epoch: 5| Step: 4
Training loss: 3.1398965930312417
Validation loss: 2.597905503665698

Epoch: 5| Step: 5
Training loss: 3.187905528881271
Validation loss: 2.603959264228161

Epoch: 5| Step: 6
Training loss: 2.706459942927007
Validation loss: 2.605417713203454

Epoch: 5| Step: 7
Training loss: 2.9995067508835835
Validation loss: 2.601027853838558

Epoch: 5| Step: 8
Training loss: 3.5308821495006186
Validation loss: 2.594520572002405

Epoch: 5| Step: 9
Training loss: 2.2716062321207464
Validation loss: 2.6047540385372336

Epoch: 5| Step: 10
Training loss: 2.9817979481004238
Validation loss: 2.599125701475528

Epoch: 333| Step: 0
Training loss: 2.923975877717133
Validation loss: 2.5989842889605845

Epoch: 5| Step: 1
Training loss: 3.1716834701063563
Validation loss: 2.5938129004768418

Epoch: 5| Step: 2
Training loss: 2.915667953256588
Validation loss: 2.5991384016524206

Epoch: 5| Step: 3
Training loss: 2.8890282422062157
Validation loss: 2.5995235694448056

Epoch: 5| Step: 4
Training loss: 2.7442407121427306
Validation loss: 2.597236670842375

Epoch: 5| Step: 5
Training loss: 2.836706808533114
Validation loss: 2.597983356919824

Epoch: 5| Step: 6
Training loss: 3.3402676140482326
Validation loss: 2.5961088081744186

Epoch: 5| Step: 7
Training loss: 2.4069508114120506
Validation loss: 2.607457363687083

Epoch: 5| Step: 8
Training loss: 2.736900079215465
Validation loss: 2.6046362006095705

Epoch: 5| Step: 9
Training loss: 3.026081043365836
Validation loss: 2.5970722818589542

Epoch: 5| Step: 10
Training loss: 3.2281193337109184
Validation loss: 2.6005367390399163

Epoch: 334| Step: 0
Training loss: 2.914782887612967
Validation loss: 2.5995333781351193

Epoch: 5| Step: 1
Training loss: 2.961238634402491
Validation loss: 2.5972374032442795

Epoch: 5| Step: 2
Training loss: 3.2333543429396716
Validation loss: 2.6024563186470924

Epoch: 5| Step: 3
Training loss: 2.906599782588339
Validation loss: 2.600678657609306

Epoch: 5| Step: 4
Training loss: 3.0092183580363145
Validation loss: 2.598323363617755

Epoch: 5| Step: 5
Training loss: 2.1694634311228875
Validation loss: 2.5983535934689006

Epoch: 5| Step: 6
Training loss: 2.7099752779744444
Validation loss: 2.600861959810219

Epoch: 5| Step: 7
Training loss: 3.0797260593611258
Validation loss: 2.6014671398126357

Epoch: 5| Step: 8
Training loss: 2.9113203549431734
Validation loss: 2.603754469869294

Epoch: 5| Step: 9
Training loss: 3.3943045203516853
Validation loss: 2.5907821230989736

Epoch: 5| Step: 10
Training loss: 2.7565872020715236
Validation loss: 2.5942801753913933

Epoch: 335| Step: 0
Training loss: 2.9015634137194812
Validation loss: 2.5957174004229073

Epoch: 5| Step: 1
Training loss: 3.1613975322141084
Validation loss: 2.5876478668046006

Epoch: 5| Step: 2
Training loss: 2.677140963833316
Validation loss: 2.598139303109914

Epoch: 5| Step: 3
Training loss: 2.6332951225051615
Validation loss: 2.5882136401850278

Epoch: 5| Step: 4
Training loss: 3.2570505692020433
Validation loss: 2.5917331431689092

Epoch: 5| Step: 5
Training loss: 3.3825291609652495
Validation loss: 2.596010017442623

Epoch: 5| Step: 6
Training loss: 2.7773844398061014
Validation loss: 2.599279261351449

Epoch: 5| Step: 7
Training loss: 2.84376643249459
Validation loss: 2.6030756092643696

Epoch: 5| Step: 8
Training loss: 2.722082704312084
Validation loss: 2.6086003474657824

Epoch: 5| Step: 9
Training loss: 2.8255807802840542
Validation loss: 2.6254668760593223

Epoch: 5| Step: 10
Training loss: 2.974477282851757
Validation loss: 2.654368253884494

Epoch: 336| Step: 0
Training loss: 2.9703795126991586
Validation loss: 2.630053625163295

Epoch: 5| Step: 1
Training loss: 3.3084242596050117
Validation loss: 2.604734262609806

Epoch: 5| Step: 2
Training loss: 2.9767122806700836
Validation loss: 2.6060209233276814

Epoch: 5| Step: 3
Training loss: 3.043564470029761
Validation loss: 2.594098783888089

Epoch: 5| Step: 4
Training loss: 2.496613402144362
Validation loss: 2.5915646282259663

Epoch: 5| Step: 5
Training loss: 3.3795482929570206
Validation loss: 2.584555982292405

Epoch: 5| Step: 6
Training loss: 2.234753129881167
Validation loss: 2.587542457741487

Epoch: 5| Step: 7
Training loss: 2.524894931231263
Validation loss: 2.5860343766004608

Epoch: 5| Step: 8
Training loss: 2.6711215914546926
Validation loss: 2.585531518812215

Epoch: 5| Step: 9
Training loss: 3.066720195662442
Validation loss: 2.587420564303748

Epoch: 5| Step: 10
Training loss: 3.3237416230921433
Validation loss: 2.580282334521031

Epoch: 337| Step: 0
Training loss: 2.9261487416799334
Validation loss: 2.589422859396172

Epoch: 5| Step: 1
Training loss: 3.1345804985737047
Validation loss: 2.584112641930515

Epoch: 5| Step: 2
Training loss: 3.2696980897545465
Validation loss: 2.5839448999498673

Epoch: 5| Step: 3
Training loss: 2.8110700574984007
Validation loss: 2.587197892105754

Epoch: 5| Step: 4
Training loss: 2.7047927210112155
Validation loss: 2.5891355329025556

Epoch: 5| Step: 5
Training loss: 3.2103196637951803
Validation loss: 2.582441718589005

Epoch: 5| Step: 6
Training loss: 2.2306160418885557
Validation loss: 2.5985572394139824

Epoch: 5| Step: 7
Training loss: 2.796962971076354
Validation loss: 2.6017301052718045

Epoch: 5| Step: 8
Training loss: 2.8774647306373735
Validation loss: 2.599013612523332

Epoch: 5| Step: 9
Training loss: 3.1816906816772854
Validation loss: 2.6065279454596157

Epoch: 5| Step: 10
Training loss: 2.834514334386196
Validation loss: 2.6080375251512593

Epoch: 338| Step: 0
Training loss: 2.864652672130742
Validation loss: 2.6025166110600813

Epoch: 5| Step: 1
Training loss: 2.9289123323448116
Validation loss: 2.6018832843270245

Epoch: 5| Step: 2
Training loss: 2.4957743217951482
Validation loss: 2.607565422511183

Epoch: 5| Step: 3
Training loss: 2.3911076476124413
Validation loss: 2.593916060282219

Epoch: 5| Step: 4
Training loss: 3.39540094224434
Validation loss: 2.5842376565752914

Epoch: 5| Step: 5
Training loss: 2.901276958427436
Validation loss: 2.5830315609806798

Epoch: 5| Step: 6
Training loss: 3.260359466018471
Validation loss: 2.582670036993326

Epoch: 5| Step: 7
Training loss: 3.067058362685991
Validation loss: 2.5853081563698153

Epoch: 5| Step: 8
Training loss: 2.889176619294083
Validation loss: 2.5829558584634436

Epoch: 5| Step: 9
Training loss: 2.6788365205649174
Validation loss: 2.5823599221581426

Epoch: 5| Step: 10
Training loss: 3.200631711118873
Validation loss: 2.5807151558539805

Epoch: 339| Step: 0
Training loss: 3.2766730948844662
Validation loss: 2.5828824068175162

Epoch: 5| Step: 1
Training loss: 2.8393478695217524
Validation loss: 2.585063409254304

Epoch: 5| Step: 2
Training loss: 2.6226285485835037
Validation loss: 2.584535750274578

Epoch: 5| Step: 3
Training loss: 2.7585189822167697
Validation loss: 2.5933768592954864

Epoch: 5| Step: 4
Training loss: 2.696617805531835
Validation loss: 2.6120136643003806

Epoch: 5| Step: 5
Training loss: 2.8139929305843867
Validation loss: 2.6120264882939046

Epoch: 5| Step: 6
Training loss: 3.0581662401778416
Validation loss: 2.636529369412343

Epoch: 5| Step: 7
Training loss: 3.095056431368335
Validation loss: 2.6374791350028053

Epoch: 5| Step: 8
Training loss: 3.055323385800804
Validation loss: 2.5966294662372227

Epoch: 5| Step: 9
Training loss: 2.8465798519157195
Validation loss: 2.595739136366455

Epoch: 5| Step: 10
Training loss: 3.3425904161753976
Validation loss: 2.586621810980649

Epoch: 340| Step: 0
Training loss: 2.8153315383787376
Validation loss: 2.5932691503720084

Epoch: 5| Step: 1
Training loss: 3.0304540788689245
Validation loss: 2.601345903782966

Epoch: 5| Step: 2
Training loss: 3.5125173439330752
Validation loss: 2.632759638751303

Epoch: 5| Step: 3
Training loss: 2.7957702671296443
Validation loss: 2.599696008045469

Epoch: 5| Step: 4
Training loss: 2.6353607975964697
Validation loss: 2.5927958284549883

Epoch: 5| Step: 5
Training loss: 2.538903052385345
Validation loss: 2.583354513880039

Epoch: 5| Step: 6
Training loss: 2.9120270111696662
Validation loss: 2.5806502428696962

Epoch: 5| Step: 7
Training loss: 3.573168390746903
Validation loss: 2.5789287707575728

Epoch: 5| Step: 8
Training loss: 2.7318496813939412
Validation loss: 2.579974628507205

Epoch: 5| Step: 9
Training loss: 2.187597436097289
Validation loss: 2.581766271166485

Epoch: 5| Step: 10
Training loss: 3.250036973009343
Validation loss: 2.5853466289167195

Epoch: 341| Step: 0
Training loss: 2.8855587663788924
Validation loss: 2.590778503418294

Epoch: 5| Step: 1
Training loss: 1.9516412210583822
Validation loss: 2.6008842402255627

Epoch: 5| Step: 2
Training loss: 2.9825927845287152
Validation loss: 2.6097349199018534

Epoch: 5| Step: 3
Training loss: 2.3500767066286525
Validation loss: 2.62744353672836

Epoch: 5| Step: 4
Training loss: 3.0421089652043625
Validation loss: 2.655269722290889

Epoch: 5| Step: 5
Training loss: 2.675602148146016
Validation loss: 2.652300734011582

Epoch: 5| Step: 6
Training loss: 3.608998332660868
Validation loss: 2.654433157127621

Epoch: 5| Step: 7
Training loss: 3.2555679163374465
Validation loss: 2.6282354456925194

Epoch: 5| Step: 8
Training loss: 3.149636014465895
Validation loss: 2.6029022087185556

Epoch: 5| Step: 9
Training loss: 2.797172743650024
Validation loss: 2.579991842770366

Epoch: 5| Step: 10
Training loss: 3.361773818777546
Validation loss: 2.580750058654563

Epoch: 342| Step: 0
Training loss: 2.645845568370815
Validation loss: 2.5795437714660605

Epoch: 5| Step: 1
Training loss: 2.8253164097307746
Validation loss: 2.588627181950782

Epoch: 5| Step: 2
Training loss: 3.0972355175635777
Validation loss: 2.5914663725750002

Epoch: 5| Step: 3
Training loss: 2.9320293374669024
Validation loss: 2.596062613803878

Epoch: 5| Step: 4
Training loss: 3.0709948376059732
Validation loss: 2.5963556105744976

Epoch: 5| Step: 5
Training loss: 3.234673822576916
Validation loss: 2.604503513003359

Epoch: 5| Step: 6
Training loss: 3.0251256680197622
Validation loss: 2.6097621825737773

Epoch: 5| Step: 7
Training loss: 3.0630587632498307
Validation loss: 2.598673418924751

Epoch: 5| Step: 8
Training loss: 2.8139933542147353
Validation loss: 2.5910472603571013

Epoch: 5| Step: 9
Training loss: 2.7425808963997977
Validation loss: 2.5896029291325697

Epoch: 5| Step: 10
Training loss: 3.155099489121521
Validation loss: 2.5859206980770444

Epoch: 343| Step: 0
Training loss: 2.6825795040809752
Validation loss: 2.5789801359295113

Epoch: 5| Step: 1
Training loss: 3.238430558134356
Validation loss: 2.576879765054378

Epoch: 5| Step: 2
Training loss: 2.995116550680565
Validation loss: 2.579498720536479

Epoch: 5| Step: 3
Training loss: 2.6162397348172473
Validation loss: 2.5764886360822032

Epoch: 5| Step: 4
Training loss: 2.8519500887062663
Validation loss: 2.594882227230801

Epoch: 5| Step: 5
Training loss: 3.0151409491999672
Validation loss: 2.590362151970568

Epoch: 5| Step: 6
Training loss: 2.679703337063715
Validation loss: 2.59988518051982

Epoch: 5| Step: 7
Training loss: 2.491517936664945
Validation loss: 2.612879862770143

Epoch: 5| Step: 8
Training loss: 3.359058595882741
Validation loss: 2.6209428650059574

Epoch: 5| Step: 9
Training loss: 3.348156458764029
Validation loss: 2.607990387051117

Epoch: 5| Step: 10
Training loss: 2.8016722045456413
Validation loss: 2.6152270837278255

Epoch: 344| Step: 0
Training loss: 3.065039535441721
Validation loss: 2.608128712357972

Epoch: 5| Step: 1
Training loss: 2.3289811780995344
Validation loss: 2.5923918879745367

Epoch: 5| Step: 2
Training loss: 3.5787603488869753
Validation loss: 2.588189836240056

Epoch: 5| Step: 3
Training loss: 2.78379396826113
Validation loss: 2.589843747030353

Epoch: 5| Step: 4
Training loss: 2.9741654644043867
Validation loss: 2.5838842565339113

Epoch: 5| Step: 5
Training loss: 2.708437951830541
Validation loss: 2.574649391912152

Epoch: 5| Step: 6
Training loss: 3.4495564659397218
Validation loss: 2.5934932011808383

Epoch: 5| Step: 7
Training loss: 2.7403379109427184
Validation loss: 2.57783783537388

Epoch: 5| Step: 8
Training loss: 2.041311025460656
Validation loss: 2.5827542157687584

Epoch: 5| Step: 9
Training loss: 2.8163913509488023
Validation loss: 2.5779988207972098

Epoch: 5| Step: 10
Training loss: 3.3527890964145985
Validation loss: 2.5849335312750763

Epoch: 345| Step: 0
Training loss: 2.862496595089149
Validation loss: 2.5818610314343315

Epoch: 5| Step: 1
Training loss: 2.6455233134466507
Validation loss: 2.582093467916568

Epoch: 5| Step: 2
Training loss: 2.8664133965441367
Validation loss: 2.579837297818348

Epoch: 5| Step: 3
Training loss: 2.7329527725678284
Validation loss: 2.5785625773786665

Epoch: 5| Step: 4
Training loss: 2.410721031058426
Validation loss: 2.5746800978710827

Epoch: 5| Step: 5
Training loss: 3.189723417435488
Validation loss: 2.5776298189100872

Epoch: 5| Step: 6
Training loss: 3.2886314562692447
Validation loss: 2.579928877596553

Epoch: 5| Step: 7
Training loss: 2.7116034401632776
Validation loss: 2.5806862209050547

Epoch: 5| Step: 8
Training loss: 3.1148709745918035
Validation loss: 2.576704072344734

Epoch: 5| Step: 9
Training loss: 3.1850572089262856
Validation loss: 2.5787162095429967

Epoch: 5| Step: 10
Training loss: 2.9904906239709406
Validation loss: 2.5819064144846386

Epoch: 346| Step: 0
Training loss: 3.061275159390522
Validation loss: 2.5827597256829042

Epoch: 5| Step: 1
Training loss: 2.7889713731939962
Validation loss: 2.588303698377537

Epoch: 5| Step: 2
Training loss: 2.9496520273617923
Validation loss: 2.5974030352693847

Epoch: 5| Step: 3
Training loss: 2.4730000671189263
Validation loss: 2.6076417407571824

Epoch: 5| Step: 4
Training loss: 2.226187476983514
Validation loss: 2.616360232688985

Epoch: 5| Step: 5
Training loss: 2.6678007416445366
Validation loss: 2.631268511773217

Epoch: 5| Step: 6
Training loss: 3.380696610665361
Validation loss: 2.601233982445807

Epoch: 5| Step: 7
Training loss: 3.0234922261176798
Validation loss: 2.5916495686208982

Epoch: 5| Step: 8
Training loss: 3.2666386395504183
Validation loss: 2.5839145422061853

Epoch: 5| Step: 9
Training loss: 3.2876514298406545
Validation loss: 2.5763310798530923

Epoch: 5| Step: 10
Training loss: 2.6737562550261575
Validation loss: 2.562637135347505

Epoch: 347| Step: 0
Training loss: 3.0940770448389636
Validation loss: 2.562836322578347

Epoch: 5| Step: 1
Training loss: 2.3087352315598686
Validation loss: 2.564888609994748

Epoch: 5| Step: 2
Training loss: 2.3615091536855566
Validation loss: 2.564617757537132

Epoch: 5| Step: 3
Training loss: 2.9993972172741956
Validation loss: 2.56899442544521

Epoch: 5| Step: 4
Training loss: 3.0216224604334667
Validation loss: 2.573105160044108

Epoch: 5| Step: 5
Training loss: 3.1793988071013
Validation loss: 2.5688574268862028

Epoch: 5| Step: 6
Training loss: 3.1931495714240885
Validation loss: 2.571977122390823

Epoch: 5| Step: 7
Training loss: 3.277679098838594
Validation loss: 2.566409764206522

Epoch: 5| Step: 8
Training loss: 3.037230265379384
Validation loss: 2.5718763540903304

Epoch: 5| Step: 9
Training loss: 2.681783318109296
Validation loss: 2.563170341613178

Epoch: 5| Step: 10
Training loss: 2.783002151461012
Validation loss: 2.567137675609191

Epoch: 348| Step: 0
Training loss: 3.011211268396404
Validation loss: 2.577096615028408

Epoch: 5| Step: 1
Training loss: 2.8189931726552313
Validation loss: 2.567682335784846

Epoch: 5| Step: 2
Training loss: 3.2199630673582837
Validation loss: 2.574823915534325

Epoch: 5| Step: 3
Training loss: 2.667755431196783
Validation loss: 2.587729056220114

Epoch: 5| Step: 4
Training loss: 2.9111449335121695
Validation loss: 2.5917321995094054

Epoch: 5| Step: 5
Training loss: 3.1673837820167936
Validation loss: 2.6036429435201063

Epoch: 5| Step: 6
Training loss: 3.099355993749148
Validation loss: 2.5941892840744325

Epoch: 5| Step: 7
Training loss: 3.0189563751758395
Validation loss: 2.5817736192033376

Epoch: 5| Step: 8
Training loss: 2.223479911094108
Validation loss: 2.585237940859614

Epoch: 5| Step: 9
Training loss: 2.9790038662335063
Validation loss: 2.5844017881413266

Epoch: 5| Step: 10
Training loss: 2.8297367456069966
Validation loss: 2.5779159406444645

Epoch: 349| Step: 0
Training loss: 2.5759852922386957
Validation loss: 2.5876824794406605

Epoch: 5| Step: 1
Training loss: 3.0223386675086834
Validation loss: 2.5872134055064024

Epoch: 5| Step: 2
Training loss: 2.2886591741519067
Validation loss: 2.602039870203241

Epoch: 5| Step: 3
Training loss: 3.135118202037536
Validation loss: 2.5839687449841566

Epoch: 5| Step: 4
Training loss: 3.179174583361873
Validation loss: 2.5913132964915926

Epoch: 5| Step: 5
Training loss: 2.6970066219668625
Validation loss: 2.5865762817131577

Epoch: 5| Step: 6
Training loss: 3.6847958752269907
Validation loss: 2.606671347959171

Epoch: 5| Step: 7
Training loss: 3.028937490015337
Validation loss: 2.5940432639096707

Epoch: 5| Step: 8
Training loss: 2.896197252711101
Validation loss: 2.5886867348264437

Epoch: 5| Step: 9
Training loss: 2.727747968246239
Validation loss: 2.584127796865666

Epoch: 5| Step: 10
Training loss: 2.501256722246294
Validation loss: 2.5808968875319374

Epoch: 350| Step: 0
Training loss: 2.9487760299950287
Validation loss: 2.5762217855482015

Epoch: 5| Step: 1
Training loss: 2.973242161839815
Validation loss: 2.5821818005849417

Epoch: 5| Step: 2
Training loss: 2.842904939954839
Validation loss: 2.5794800400217412

Epoch: 5| Step: 3
Training loss: 3.0489975016512694
Validation loss: 2.5740107727213544

Epoch: 5| Step: 4
Training loss: 2.4385054055350146
Validation loss: 2.5720975051019836

Epoch: 5| Step: 5
Training loss: 3.2254077978833133
Validation loss: 2.566361954902173

Epoch: 5| Step: 6
Training loss: 2.891619536998761
Validation loss: 2.573863849826454

Epoch: 5| Step: 7
Training loss: 3.2404882183287507
Validation loss: 2.5685688688376254

Epoch: 5| Step: 8
Training loss: 2.830587926930545
Validation loss: 2.574699629689425

Epoch: 5| Step: 9
Training loss: 2.6867775944163874
Validation loss: 2.57217544481178

Epoch: 5| Step: 10
Training loss: 2.751124152252082
Validation loss: 2.5774283056008636

Epoch: 351| Step: 0
Training loss: 2.708217784666394
Validation loss: 2.579229301940392

Epoch: 5| Step: 1
Training loss: 2.9289839650057394
Validation loss: 2.588570078870503

Epoch: 5| Step: 2
Training loss: 2.8650687806293265
Validation loss: 2.585721590745147

Epoch: 5| Step: 3
Training loss: 2.9146174907159774
Validation loss: 2.5871287911422236

Epoch: 5| Step: 4
Training loss: 3.121283190042423
Validation loss: 2.584190353187804

Epoch: 5| Step: 5
Training loss: 3.7560670728778303
Validation loss: 2.589464105259711

Epoch: 5| Step: 6
Training loss: 2.6459075636976293
Validation loss: 2.5836086391130575

Epoch: 5| Step: 7
Training loss: 2.3312112718080553
Validation loss: 2.581860274811714

Epoch: 5| Step: 8
Training loss: 2.758709899306688
Validation loss: 2.5799435960398043

Epoch: 5| Step: 9
Training loss: 3.0719329983735943
Validation loss: 2.584719420677891

Epoch: 5| Step: 10
Training loss: 2.605297077248154
Validation loss: 2.5887089328613375

Epoch: 352| Step: 0
Training loss: 3.3504449008042494
Validation loss: 2.5828484911520486

Epoch: 5| Step: 1
Training loss: 2.4565271002860314
Validation loss: 2.584929940099877

Epoch: 5| Step: 2
Training loss: 3.185501219926899
Validation loss: 2.587665914731134

Epoch: 5| Step: 3
Training loss: 2.7487135392321362
Validation loss: 2.599283113793567

Epoch: 5| Step: 4
Training loss: 2.656571133218919
Validation loss: 2.5991330615887094

Epoch: 5| Step: 5
Training loss: 2.92875896743919
Validation loss: 2.6101922817340917

Epoch: 5| Step: 6
Training loss: 3.0837858400709144
Validation loss: 2.61345571876729

Epoch: 5| Step: 7
Training loss: 3.1319023199037446
Validation loss: 2.6192147223043416

Epoch: 5| Step: 8
Training loss: 2.7307916322080668
Validation loss: 2.597753373479297

Epoch: 5| Step: 9
Training loss: 3.2524699582259937
Validation loss: 2.5840894609380163

Epoch: 5| Step: 10
Training loss: 2.1271629545259154
Validation loss: 2.5756494494190303

Epoch: 353| Step: 0
Training loss: 2.396252758520028
Validation loss: 2.571384735282314

Epoch: 5| Step: 1
Training loss: 3.426437193340159
Validation loss: 2.560519231491217

Epoch: 5| Step: 2
Training loss: 2.464012235468669
Validation loss: 2.562616217074006

Epoch: 5| Step: 3
Training loss: 2.7276894937313974
Validation loss: 2.5639066529486194

Epoch: 5| Step: 4
Training loss: 2.6301809680887436
Validation loss: 2.559908008422347

Epoch: 5| Step: 5
Training loss: 2.8507361481920572
Validation loss: 2.5588697705258414

Epoch: 5| Step: 6
Training loss: 3.114431898503327
Validation loss: 2.5508131317225184

Epoch: 5| Step: 7
Training loss: 3.3676097631655266
Validation loss: 2.557647952600096

Epoch: 5| Step: 8
Training loss: 2.7956622174158876
Validation loss: 2.5763905189307854

Epoch: 5| Step: 9
Training loss: 2.5799955113689794
Validation loss: 2.5910652450287124

Epoch: 5| Step: 10
Training loss: 3.597903960705653
Validation loss: 2.6211463809603495

Epoch: 354| Step: 0
Training loss: 2.9321087000370585
Validation loss: 2.598717384250704

Epoch: 5| Step: 1
Training loss: 3.0900730670080025
Validation loss: 2.5994325803916745

Epoch: 5| Step: 2
Training loss: 3.284770711621998
Validation loss: 2.596947855939474

Epoch: 5| Step: 3
Training loss: 3.422703612173375
Validation loss: 2.585228083880458

Epoch: 5| Step: 4
Training loss: 2.85331843410892
Validation loss: 2.5962489030631404

Epoch: 5| Step: 5
Training loss: 2.758786988384176
Validation loss: 2.593773221661798

Epoch: 5| Step: 6
Training loss: 2.7966420167178407
Validation loss: 2.583575763964323

Epoch: 5| Step: 7
Training loss: 2.6037756867957036
Validation loss: 2.570562296735114

Epoch: 5| Step: 8
Training loss: 2.5871492525921247
Validation loss: 2.5791373186109774

Epoch: 5| Step: 9
Training loss: 2.6876918812939095
Validation loss: 2.578987191701708

Epoch: 5| Step: 10
Training loss: 2.71250276697255
Validation loss: 2.580850074212042

Epoch: 355| Step: 0
Training loss: 2.91652217688746
Validation loss: 2.5798627170974795

Epoch: 5| Step: 1
Training loss: 3.150975721105308
Validation loss: 2.5830664766469718

Epoch: 5| Step: 2
Training loss: 2.676794865326366
Validation loss: 2.593016615530262

Epoch: 5| Step: 3
Training loss: 2.721679512300407
Validation loss: 2.604761011698354

Epoch: 5| Step: 4
Training loss: 2.9811116696300055
Validation loss: 2.595271089896442

Epoch: 5| Step: 5
Training loss: 2.5540455236119284
Validation loss: 2.5875119747649458

Epoch: 5| Step: 6
Training loss: 2.9132867757305467
Validation loss: 2.5851518417528716

Epoch: 5| Step: 7
Training loss: 3.2979400505414485
Validation loss: 2.58226227927112

Epoch: 5| Step: 8
Training loss: 3.0501477002511153
Validation loss: 2.566631803753905

Epoch: 5| Step: 9
Training loss: 2.6771660778354764
Validation loss: 2.56428151464432

Epoch: 5| Step: 10
Training loss: 2.8609733075120407
Validation loss: 2.560635730689757

Epoch: 356| Step: 0
Training loss: 2.9021789586144937
Validation loss: 2.567659180186164

Epoch: 5| Step: 1
Training loss: 3.1907962883862537
Validation loss: 2.5590743300443335

Epoch: 5| Step: 2
Training loss: 2.5632543616496335
Validation loss: 2.5554362294910473

Epoch: 5| Step: 3
Training loss: 2.9838638267331867
Validation loss: 2.5624809144372556

Epoch: 5| Step: 4
Training loss: 3.1341939339486613
Validation loss: 2.557121256307487

Epoch: 5| Step: 5
Training loss: 3.1559295491621646
Validation loss: 2.5582172992645895

Epoch: 5| Step: 6
Training loss: 2.7700543467840055
Validation loss: 2.5551107050497186

Epoch: 5| Step: 7
Training loss: 2.7745369464712457
Validation loss: 2.5719605851136627

Epoch: 5| Step: 8
Training loss: 2.78213658292767
Validation loss: 2.555364336403907

Epoch: 5| Step: 9
Training loss: 2.9981295794781446
Validation loss: 2.577112550337986

Epoch: 5| Step: 10
Training loss: 2.422740461699742
Validation loss: 2.5847919145929

Epoch: 357| Step: 0
Training loss: 3.024297862889263
Validation loss: 2.617099166503454

Epoch: 5| Step: 1
Training loss: 2.7589601716847727
Validation loss: 2.6047847409748233

Epoch: 5| Step: 2
Training loss: 3.3998550440237207
Validation loss: 2.616340998162321

Epoch: 5| Step: 3
Training loss: 2.612602658969788
Validation loss: 2.6211752932574326

Epoch: 5| Step: 4
Training loss: 3.3759926643020695
Validation loss: 2.6059804441806396

Epoch: 5| Step: 5
Training loss: 3.0746311555792976
Validation loss: 2.59699909521868

Epoch: 5| Step: 6
Training loss: 2.3656975113956524
Validation loss: 2.5857428951590613

Epoch: 5| Step: 7
Training loss: 2.4241678520856285
Validation loss: 2.580312133907148

Epoch: 5| Step: 8
Training loss: 2.139496108830518
Validation loss: 2.579914659890165

Epoch: 5| Step: 9
Training loss: 3.041727265751535
Validation loss: 2.570250000891845

Epoch: 5| Step: 10
Training loss: 3.445342394640712
Validation loss: 2.574804619635533

Epoch: 358| Step: 0
Training loss: 2.3754206836958436
Validation loss: 2.5661270300123746

Epoch: 5| Step: 1
Training loss: 2.143010946839499
Validation loss: 2.571016176112121

Epoch: 5| Step: 2
Training loss: 2.903900837784168
Validation loss: 2.569359683636367

Epoch: 5| Step: 3
Training loss: 2.7903093388022904
Validation loss: 2.551799143742758

Epoch: 5| Step: 4
Training loss: 3.2023936855706565
Validation loss: 2.5663762771590073

Epoch: 5| Step: 5
Training loss: 3.114235151512881
Validation loss: 2.5702501315549764

Epoch: 5| Step: 6
Training loss: 2.8703997752917827
Validation loss: 2.5694391032345134

Epoch: 5| Step: 7
Training loss: 3.0654514648597266
Validation loss: 2.5720840075916795

Epoch: 5| Step: 8
Training loss: 3.4895641876758288
Validation loss: 2.5777250246270795

Epoch: 5| Step: 9
Training loss: 2.4363335973137796
Validation loss: 2.5831883978964796

Epoch: 5| Step: 10
Training loss: 3.1333855083531486
Validation loss: 2.59387444342055

Epoch: 359| Step: 0
Training loss: 2.6749806341022855
Validation loss: 2.5960659743019607

Epoch: 5| Step: 1
Training loss: 3.168163966174248
Validation loss: 2.6173974981591512

Epoch: 5| Step: 2
Training loss: 2.6610912410743746
Validation loss: 2.640024661946912

Epoch: 5| Step: 3
Training loss: 2.7394105593274864
Validation loss: 2.6375870184517622

Epoch: 5| Step: 4
Training loss: 2.795843946623425
Validation loss: 2.617962920491057

Epoch: 5| Step: 5
Training loss: 3.410069834869445
Validation loss: 2.582935262556336

Epoch: 5| Step: 6
Training loss: 2.851251287330427
Validation loss: 2.5687623196571843

Epoch: 5| Step: 7
Training loss: 2.8800126205273777
Validation loss: 2.5605064518993563

Epoch: 5| Step: 8
Training loss: 2.973049223060267
Validation loss: 2.5625682914751993

Epoch: 5| Step: 9
Training loss: 3.0287436909281236
Validation loss: 2.559453180852831

Epoch: 5| Step: 10
Training loss: 2.6199662218027644
Validation loss: 2.55479749377733

Epoch: 360| Step: 0
Training loss: 3.2313769907687537
Validation loss: 2.556594381314724

Epoch: 5| Step: 1
Training loss: 2.9261407567636857
Validation loss: 2.55585702763411

Epoch: 5| Step: 2
Training loss: 2.686180500535569
Validation loss: 2.5612954090400906

Epoch: 5| Step: 3
Training loss: 3.2280764964799804
Validation loss: 2.554019306352756

Epoch: 5| Step: 4
Training loss: 2.5372892320414895
Validation loss: 2.5529942795131664

Epoch: 5| Step: 5
Training loss: 2.8705732016413457
Validation loss: 2.5485661227839373

Epoch: 5| Step: 6
Training loss: 3.14393221438961
Validation loss: 2.551767399418747

Epoch: 5| Step: 7
Training loss: 2.7639143658799785
Validation loss: 2.55318306053738

Epoch: 5| Step: 8
Training loss: 3.0047982309045755
Validation loss: 2.5540720005723205

Epoch: 5| Step: 9
Training loss: 3.038360436158727
Validation loss: 2.5598559330724173

Epoch: 5| Step: 10
Training loss: 2.3868231368142645
Validation loss: 2.5593906790003054

Epoch: 361| Step: 0
Training loss: 2.9862166708886284
Validation loss: 2.5606421682272673

Epoch: 5| Step: 1
Training loss: 2.9903737439965896
Validation loss: 2.5701416225131224

Epoch: 5| Step: 2
Training loss: 2.7059806777816857
Validation loss: 2.5739399253259454

Epoch: 5| Step: 3
Training loss: 3.000972431253258
Validation loss: 2.578550046286589

Epoch: 5| Step: 4
Training loss: 2.8503540822975335
Validation loss: 2.594252451584606

Epoch: 5| Step: 5
Training loss: 2.861327291755425
Validation loss: 2.5897370741206864

Epoch: 5| Step: 6
Training loss: 2.572971626549316
Validation loss: 2.598430251337461

Epoch: 5| Step: 7
Training loss: 2.410858694928349
Validation loss: 2.586308618393698

Epoch: 5| Step: 8
Training loss: 3.453231878913708
Validation loss: 2.5829295892488484

Epoch: 5| Step: 9
Training loss: 2.760742014779354
Validation loss: 2.5709839964902574

Epoch: 5| Step: 10
Training loss: 3.1448349705322096
Validation loss: 2.5767680883418196

Epoch: 362| Step: 0
Training loss: 2.4216674715772823
Validation loss: 2.567450341038402

Epoch: 5| Step: 1
Training loss: 2.544352024830158
Validation loss: 2.571664505901432

Epoch: 5| Step: 2
Training loss: 2.700050590182465
Validation loss: 2.57457190647823

Epoch: 5| Step: 3
Training loss: 2.907499803459443
Validation loss: 2.5768009787114514

Epoch: 5| Step: 4
Training loss: 3.101753901574104
Validation loss: 2.585756513711433

Epoch: 5| Step: 5
Training loss: 2.6397953874595257
Validation loss: 2.5766419013928097

Epoch: 5| Step: 6
Training loss: 3.2947060921951374
Validation loss: 2.5694016047746553

Epoch: 5| Step: 7
Training loss: 2.873321540820122
Validation loss: 2.5751102445016536

Epoch: 5| Step: 8
Training loss: 2.8255952089895495
Validation loss: 2.559828873982281

Epoch: 5| Step: 9
Training loss: 3.476091057176259
Validation loss: 2.567342376206442

Epoch: 5| Step: 10
Training loss: 2.7665506311771964
Validation loss: 2.5653372813208204

Epoch: 363| Step: 0
Training loss: 2.5376658192842827
Validation loss: 2.5579614131716535

Epoch: 5| Step: 1
Training loss: 2.568344800784457
Validation loss: 2.5708628247143195

Epoch: 5| Step: 2
Training loss: 3.4332222417493856
Validation loss: 2.572725517509566

Epoch: 5| Step: 3
Training loss: 2.5777064128110037
Validation loss: 2.582107253651145

Epoch: 5| Step: 4
Training loss: 2.752173951645049
Validation loss: 2.5764106497342065

Epoch: 5| Step: 5
Training loss: 2.7693388405317934
Validation loss: 2.5767006308789577

Epoch: 5| Step: 6
Training loss: 2.938125056867471
Validation loss: 2.572865604250815

Epoch: 5| Step: 7
Training loss: 2.8614847706694926
Validation loss: 2.576383908796777

Epoch: 5| Step: 8
Training loss: 2.6487387876826882
Validation loss: 2.564111937428058

Epoch: 5| Step: 9
Training loss: 3.172021721514185
Validation loss: 2.5596346368215164

Epoch: 5| Step: 10
Training loss: 3.2905245541912977
Validation loss: 2.5658053658045152

Epoch: 364| Step: 0
Training loss: 2.919713000733605
Validation loss: 2.563022179151687

Epoch: 5| Step: 1
Training loss: 2.838502842815535
Validation loss: 2.562436809606044

Epoch: 5| Step: 2
Training loss: 2.4530540504643414
Validation loss: 2.5539667194550724

Epoch: 5| Step: 3
Training loss: 2.898039345757843
Validation loss: 2.5554975670555615

Epoch: 5| Step: 4
Training loss: 3.4587497383892374
Validation loss: 2.5588826113901795

Epoch: 5| Step: 5
Training loss: 3.0355436453423494
Validation loss: 2.5593897043844196

Epoch: 5| Step: 6
Training loss: 2.197766978393
Validation loss: 2.5700254599512458

Epoch: 5| Step: 7
Training loss: 3.1961410679341506
Validation loss: 2.575116284471992

Epoch: 5| Step: 8
Training loss: 2.954168387673921
Validation loss: 2.5845145311347015

Epoch: 5| Step: 9
Training loss: 2.5881552046353886
Validation loss: 2.5765957152057353

Epoch: 5| Step: 10
Training loss: 2.947055129111262
Validation loss: 2.5853505338512015

Epoch: 365| Step: 0
Training loss: 2.83144339938802
Validation loss: 2.57986670187967

Epoch: 5| Step: 1
Training loss: 2.709597033562288
Validation loss: 2.576076451659481

Epoch: 5| Step: 2
Training loss: 2.7982301465886588
Validation loss: 2.5659174277305414

Epoch: 5| Step: 3
Training loss: 3.004113556017197
Validation loss: 2.577083938533171

Epoch: 5| Step: 4
Training loss: 3.481854677676821
Validation loss: 2.5817963622378377

Epoch: 5| Step: 5
Training loss: 2.818468838559885
Validation loss: 2.57038339451705

Epoch: 5| Step: 6
Training loss: 2.931464630272731
Validation loss: 2.558064225870584

Epoch: 5| Step: 7
Training loss: 2.157228109791772
Validation loss: 2.5742865314236933

Epoch: 5| Step: 8
Training loss: 3.0634262863961026
Validation loss: 2.554507064505989

Epoch: 5| Step: 9
Training loss: 2.5517628578810627
Validation loss: 2.5547872183120677

Epoch: 5| Step: 10
Training loss: 3.0429958592041
Validation loss: 2.552718464263042

Epoch: 366| Step: 0
Training loss: 2.9688699798432325
Validation loss: 2.55793187306138

Epoch: 5| Step: 1
Training loss: 2.4756468996746883
Validation loss: 2.551918941290259

Epoch: 5| Step: 2
Training loss: 1.8773581616582318
Validation loss: 2.553355643727738

Epoch: 5| Step: 3
Training loss: 3.489878460754386
Validation loss: 2.5680217921418818

Epoch: 5| Step: 4
Training loss: 2.9450945786216045
Validation loss: 2.566411153705271

Epoch: 5| Step: 5
Training loss: 3.1383253189878664
Validation loss: 2.5832993911699225

Epoch: 5| Step: 6
Training loss: 2.935722300147612
Validation loss: 2.587602321905569

Epoch: 5| Step: 7
Training loss: 2.9525893598530564
Validation loss: 2.5933860921845775

Epoch: 5| Step: 8
Training loss: 2.1939267166125243
Validation loss: 2.577881701074484

Epoch: 5| Step: 9
Training loss: 3.021297673459673
Validation loss: 2.5840510004289574

Epoch: 5| Step: 10
Training loss: 3.3671305711363577
Validation loss: 2.5699715187260117

Epoch: 367| Step: 0
Training loss: 3.0483945529714385
Validation loss: 2.5631750924803116

Epoch: 5| Step: 1
Training loss: 2.9458238881205676
Validation loss: 2.561085787707782

Epoch: 5| Step: 2
Training loss: 2.6479986046559785
Validation loss: 2.5567029845139686

Epoch: 5| Step: 3
Training loss: 3.0626421525622085
Validation loss: 2.5489732735476767

Epoch: 5| Step: 4
Training loss: 2.78278548470117
Validation loss: 2.555430278439019

Epoch: 5| Step: 5
Training loss: 2.564850450286805
Validation loss: 2.5561872690274394

Epoch: 5| Step: 6
Training loss: 2.241433152961095
Validation loss: 2.5549419158857014

Epoch: 5| Step: 7
Training loss: 3.2146369802696215
Validation loss: 2.554614965658422

Epoch: 5| Step: 8
Training loss: 3.22241402380391
Validation loss: 2.569419051509286

Epoch: 5| Step: 9
Training loss: 2.871036285032912
Validation loss: 2.5768966696998277

Epoch: 5| Step: 10
Training loss: 2.7982782008647415
Validation loss: 2.573799021527254

Epoch: 368| Step: 0
Training loss: 2.674325544234776
Validation loss: 2.574418851530137

Epoch: 5| Step: 1
Training loss: 2.547430153470415
Validation loss: 2.570108988559957

Epoch: 5| Step: 2
Training loss: 2.6422465384918414
Validation loss: 2.5697651141309055

Epoch: 5| Step: 3
Training loss: 2.769596158277204
Validation loss: 2.5701924935076064

Epoch: 5| Step: 4
Training loss: 2.998253154802917
Validation loss: 2.5759750077408405

Epoch: 5| Step: 5
Training loss: 3.178556423855998
Validation loss: 2.565880238488899

Epoch: 5| Step: 6
Training loss: 2.564951584565399
Validation loss: 2.5606706553879444

Epoch: 5| Step: 7
Training loss: 2.864819122782834
Validation loss: 2.5528749491776828

Epoch: 5| Step: 8
Training loss: 3.3633114484434765
Validation loss: 2.5568983818461777

Epoch: 5| Step: 9
Training loss: 3.0375732852587887
Validation loss: 2.559880862754893

Epoch: 5| Step: 10
Training loss: 2.8133245319150437
Validation loss: 2.5731309397402424

Epoch: 369| Step: 0
Training loss: 2.6539964877854936
Validation loss: 2.5850020492677928

Epoch: 5| Step: 1
Training loss: 2.971461934646435
Validation loss: 2.583827861235411

Epoch: 5| Step: 2
Training loss: 2.765649310506235
Validation loss: 2.595784422948075

Epoch: 5| Step: 3
Training loss: 2.7799966109550183
Validation loss: 2.5787966412996415

Epoch: 5| Step: 4
Training loss: 2.896474003532089
Validation loss: 2.5790179016806087

Epoch: 5| Step: 5
Training loss: 3.2838731725366106
Validation loss: 2.561929612765706

Epoch: 5| Step: 6
Training loss: 2.846060013760903
Validation loss: 2.5592812051792073

Epoch: 5| Step: 7
Training loss: 2.923858458948358
Validation loss: 2.5579246354342815

Epoch: 5| Step: 8
Training loss: 2.9520478075286265
Validation loss: 2.548576823684174

Epoch: 5| Step: 9
Training loss: 2.6593034136199876
Validation loss: 2.5506882377573348

Epoch: 5| Step: 10
Training loss: 2.8196778151252704
Validation loss: 2.5635400937787964

Epoch: 370| Step: 0
Training loss: 2.991973630268762
Validation loss: 2.5546242864567046

Epoch: 5| Step: 1
Training loss: 2.9012110516301766
Validation loss: 2.5575508608029103

Epoch: 5| Step: 2
Training loss: 2.6290595136068005
Validation loss: 2.5529170395855303

Epoch: 5| Step: 3
Training loss: 2.8539490628418545
Validation loss: 2.5580404750980836

Epoch: 5| Step: 4
Training loss: 3.2372398772735784
Validation loss: 2.558178449784842

Epoch: 5| Step: 5
Training loss: 2.9424510381963227
Validation loss: 2.5565567927256327

Epoch: 5| Step: 6
Training loss: 2.924916851459484
Validation loss: 2.559934276533795

Epoch: 5| Step: 7
Training loss: 2.753280936597738
Validation loss: 2.5588971483289957

Epoch: 5| Step: 8
Training loss: 2.6710439359935307
Validation loss: 2.5586523096139784

Epoch: 5| Step: 9
Training loss: 2.719575427802532
Validation loss: 2.555516587400636

Epoch: 5| Step: 10
Training loss: 2.94646789392431
Validation loss: 2.5628466477969734

Epoch: 371| Step: 0
Training loss: 3.2677116480769883
Validation loss: 2.5629701510724137

Epoch: 5| Step: 1
Training loss: 2.2414100708102893
Validation loss: 2.5781056651673464

Epoch: 5| Step: 2
Training loss: 2.896596977118419
Validation loss: 2.591157495517038

Epoch: 5| Step: 3
Training loss: 2.539873199151354
Validation loss: 2.6055734279475646

Epoch: 5| Step: 4
Training loss: 2.7138180778043552
Validation loss: 2.579906885232008

Epoch: 5| Step: 5
Training loss: 2.276783790908129
Validation loss: 2.5726616639947624

Epoch: 5| Step: 6
Training loss: 3.27780784621878
Validation loss: 2.5609618081555867

Epoch: 5| Step: 7
Training loss: 2.766847071070456
Validation loss: 2.5516702541599563

Epoch: 5| Step: 8
Training loss: 3.108329712266492
Validation loss: 2.5559703852992492

Epoch: 5| Step: 9
Training loss: 2.8437701214088964
Validation loss: 2.5553312965271022

Epoch: 5| Step: 10
Training loss: 3.5672996713894958
Validation loss: 2.549839649953677

Epoch: 372| Step: 0
Training loss: 2.8039347453993146
Validation loss: 2.5482908292440505

Epoch: 5| Step: 1
Training loss: 2.6044509935929576
Validation loss: 2.5455016678712146

Epoch: 5| Step: 2
Training loss: 2.6327958375307303
Validation loss: 2.550789925502195

Epoch: 5| Step: 3
Training loss: 2.5542676854861264
Validation loss: 2.548663196752566

Epoch: 5| Step: 4
Training loss: 3.086691153520494
Validation loss: 2.548137085090356

Epoch: 5| Step: 5
Training loss: 2.8554665791181044
Validation loss: 2.551791952516297

Epoch: 5| Step: 6
Training loss: 3.034574592853952
Validation loss: 2.543679790863782

Epoch: 5| Step: 7
Training loss: 3.3620201874625564
Validation loss: 2.54958009755215

Epoch: 5| Step: 8
Training loss: 3.2060384758670994
Validation loss: 2.5545639535553644

Epoch: 5| Step: 9
Training loss: 2.701801394947541
Validation loss: 2.563152879350295

Epoch: 5| Step: 10
Training loss: 2.548415671698889
Validation loss: 2.5721329519258855

Epoch: 373| Step: 0
Training loss: 2.7041364772935537
Validation loss: 2.5957328866099814

Epoch: 5| Step: 1
Training loss: 3.2050474770967647
Validation loss: 2.60489149839232

Epoch: 5| Step: 2
Training loss: 3.1698938957291083
Validation loss: 2.6010542359554507

Epoch: 5| Step: 3
Training loss: 3.0503467050078017
Validation loss: 2.6125878880319098

Epoch: 5| Step: 4
Training loss: 3.1729659285617102
Validation loss: 2.607507412779318

Epoch: 5| Step: 5
Training loss: 2.537447841465266
Validation loss: 2.6010637973985573

Epoch: 5| Step: 6
Training loss: 2.569037495138641
Validation loss: 2.615490319297655

Epoch: 5| Step: 7
Training loss: 2.0812775068785103
Validation loss: 2.603324612895464

Epoch: 5| Step: 8
Training loss: 3.411323199131549
Validation loss: 2.600662736577877

Epoch: 5| Step: 9
Training loss: 3.021776477426616
Validation loss: 2.5696072823289606

Epoch: 5| Step: 10
Training loss: 2.3767343512907
Validation loss: 2.5614615741633786

Epoch: 374| Step: 0
Training loss: 3.107820515265085
Validation loss: 2.5530433126704715

Epoch: 5| Step: 1
Training loss: 2.892784837629873
Validation loss: 2.5510018018149045

Epoch: 5| Step: 2
Training loss: 3.1676041737853273
Validation loss: 2.546538992566993

Epoch: 5| Step: 3
Training loss: 2.7976204502059683
Validation loss: 2.5442086178373247

Epoch: 5| Step: 4
Training loss: 3.010163891661563
Validation loss: 2.5407747720760794

Epoch: 5| Step: 5
Training loss: 2.63640189068344
Validation loss: 2.5377419808219415

Epoch: 5| Step: 6
Training loss: 2.862619195980116
Validation loss: 2.5403377852185884

Epoch: 5| Step: 7
Training loss: 3.1342701553045975
Validation loss: 2.538228138029274

Epoch: 5| Step: 8
Training loss: 2.4621436660027283
Validation loss: 2.534468947308608

Epoch: 5| Step: 9
Training loss: 2.8098902992474515
Validation loss: 2.5473883216168107

Epoch: 5| Step: 10
Training loss: 2.7083504505105616
Validation loss: 2.5478394307537138

Epoch: 375| Step: 0
Training loss: 2.527299977886016
Validation loss: 2.552301996108147

Epoch: 5| Step: 1
Training loss: 2.892767694560416
Validation loss: 2.5582835385368496

Epoch: 5| Step: 2
Training loss: 2.702859942720784
Validation loss: 2.5591868780420572

Epoch: 5| Step: 3
Training loss: 3.0776543426856366
Validation loss: 2.5705618130410106

Epoch: 5| Step: 4
Training loss: 3.3921855376530914
Validation loss: 2.588094510300706

Epoch: 5| Step: 5
Training loss: 2.630336876677273
Validation loss: 2.5844869912246065

Epoch: 5| Step: 6
Training loss: 3.044649064209919
Validation loss: 2.6021290725430157

Epoch: 5| Step: 7
Training loss: 2.678286884271446
Validation loss: 2.5958119486735116

Epoch: 5| Step: 8
Training loss: 2.5496210377658604
Validation loss: 2.5708306162484367

Epoch: 5| Step: 9
Training loss: 3.162760148637974
Validation loss: 2.570907879392118

Epoch: 5| Step: 10
Training loss: 2.7671754445826298
Validation loss: 2.569053120197861

Epoch: 376| Step: 0
Training loss: 3.265272787712204
Validation loss: 2.558155028776206

Epoch: 5| Step: 1
Training loss: 2.786377027995076
Validation loss: 2.548599032083316

Epoch: 5| Step: 2
Training loss: 2.3601345835312806
Validation loss: 2.5492497775995124

Epoch: 5| Step: 3
Training loss: 2.876390369741747
Validation loss: 2.5632882395303036

Epoch: 5| Step: 4
Training loss: 2.832623355398201
Validation loss: 2.5767445835931677

Epoch: 5| Step: 5
Training loss: 3.247128612023623
Validation loss: 2.5776750735666516

Epoch: 5| Step: 6
Training loss: 2.7921373530379876
Validation loss: 2.5679314070130235

Epoch: 5| Step: 7
Training loss: 2.487977876239797
Validation loss: 2.5672960277118704

Epoch: 5| Step: 8
Training loss: 3.3071024843109775
Validation loss: 2.56917203837384

Epoch: 5| Step: 9
Training loss: 2.716700252567181
Validation loss: 2.5581851620775087

Epoch: 5| Step: 10
Training loss: 2.5370569377880767
Validation loss: 2.5489698459349786

Epoch: 377| Step: 0
Training loss: 2.7430405553308352
Validation loss: 2.55085040193789

Epoch: 5| Step: 1
Training loss: 2.8274117935143015
Validation loss: 2.5427753451872417

Epoch: 5| Step: 2
Training loss: 2.979798327796836
Validation loss: 2.5361284496833347

Epoch: 5| Step: 3
Training loss: 3.233062625315041
Validation loss: 2.5404904261421204

Epoch: 5| Step: 4
Training loss: 2.13432710965272
Validation loss: 2.550558943256454

Epoch: 5| Step: 5
Training loss: 3.0354002237147313
Validation loss: 2.554311136981303

Epoch: 5| Step: 6
Training loss: 2.9127331685391984
Validation loss: 2.5600023951105864

Epoch: 5| Step: 7
Training loss: 2.8407973166931937
Validation loss: 2.5608585021264823

Epoch: 5| Step: 8
Training loss: 3.3295353869488062
Validation loss: 2.568451263220098

Epoch: 5| Step: 9
Training loss: 2.5986439139477735
Validation loss: 2.5833322360949085

Epoch: 5| Step: 10
Training loss: 2.6295598706866117
Validation loss: 2.5774801711350595

Epoch: 378| Step: 0
Training loss: 3.0608749749348823
Validation loss: 2.5558629546225085

Epoch: 5| Step: 1
Training loss: 2.8464414833871374
Validation loss: 2.5466771575205045

Epoch: 5| Step: 2
Training loss: 2.9596915731320466
Validation loss: 2.548351040049365

Epoch: 5| Step: 3
Training loss: 2.5956593115835336
Validation loss: 2.5524701593563104

Epoch: 5| Step: 4
Training loss: 2.93612151571656
Validation loss: 2.5425560288055533

Epoch: 5| Step: 5
Training loss: 2.953523639233688
Validation loss: 2.5437721221043317

Epoch: 5| Step: 6
Training loss: 2.720614090206847
Validation loss: 2.530996006302876

Epoch: 5| Step: 7
Training loss: 3.1458532741158836
Validation loss: 2.537265575771936

Epoch: 5| Step: 8
Training loss: 3.100928715058446
Validation loss: 2.552825745079072

Epoch: 5| Step: 9
Training loss: 2.6254393800222062
Validation loss: 2.5490365090572227

Epoch: 5| Step: 10
Training loss: 2.3526596602157825
Validation loss: 2.5516038833964756

Epoch: 379| Step: 0
Training loss: 3.29145388981849
Validation loss: 2.577403830117101

Epoch: 5| Step: 1
Training loss: 2.7935070026037505
Validation loss: 2.578551814999643

Epoch: 5| Step: 2
Training loss: 2.8470970829287823
Validation loss: 2.584117879103609

Epoch: 5| Step: 3
Training loss: 2.598266805156389
Validation loss: 2.576981119636424

Epoch: 5| Step: 4
Training loss: 2.6457496890165464
Validation loss: 2.5703967892518973

Epoch: 5| Step: 5
Training loss: 2.5048993740315075
Validation loss: 2.548614473636765

Epoch: 5| Step: 6
Training loss: 2.74316206348383
Validation loss: 2.5502221646286047

Epoch: 5| Step: 7
Training loss: 2.5637909033463595
Validation loss: 2.543052881008917

Epoch: 5| Step: 8
Training loss: 3.058716285560293
Validation loss: 2.543618375943468

Epoch: 5| Step: 9
Training loss: 3.021132425870067
Validation loss: 2.5482872830085013

Epoch: 5| Step: 10
Training loss: 3.35729490243107
Validation loss: 2.547524241685

Epoch: 380| Step: 0
Training loss: 2.6378354116926417
Validation loss: 2.5381279560014556

Epoch: 5| Step: 1
Training loss: 2.5461583913841874
Validation loss: 2.544777329507056

Epoch: 5| Step: 2
Training loss: 2.499185715624275
Validation loss: 2.552895423073477

Epoch: 5| Step: 3
Training loss: 3.1452993651341803
Validation loss: 2.5537492556304824

Epoch: 5| Step: 4
Training loss: 2.9015154266236562
Validation loss: 2.5767492994837418

Epoch: 5| Step: 5
Training loss: 3.015724457202617
Validation loss: 2.5814883331970564

Epoch: 5| Step: 6
Training loss: 3.225325599025091
Validation loss: 2.5886055556405907

Epoch: 5| Step: 7
Training loss: 2.49663145097344
Validation loss: 2.5763114897524755

Epoch: 5| Step: 8
Training loss: 3.2250999849182547
Validation loss: 2.547967784660164

Epoch: 5| Step: 9
Training loss: 2.7701534976501234
Validation loss: 2.544460888600336

Epoch: 5| Step: 10
Training loss: 2.9667362812175404
Validation loss: 2.532092070953686

Epoch: 381| Step: 0
Training loss: 2.59818944980023
Validation loss: 2.531123383116514

Epoch: 5| Step: 1
Training loss: 3.220496879529929
Validation loss: 2.5331909089323577

Epoch: 5| Step: 2
Training loss: 2.936804344105034
Validation loss: 2.5341530998207733

Epoch: 5| Step: 3
Training loss: 3.0336226782940976
Validation loss: 2.5349947687098187

Epoch: 5| Step: 4
Training loss: 3.2829506962560147
Validation loss: 2.5309142053693217

Epoch: 5| Step: 5
Training loss: 2.552765009140977
Validation loss: 2.5361018076307613

Epoch: 5| Step: 6
Training loss: 2.680467764471502
Validation loss: 2.5316178968406198

Epoch: 5| Step: 7
Training loss: 2.636352513627652
Validation loss: 2.5366345732823636

Epoch: 5| Step: 8
Training loss: 2.997705217706642
Validation loss: 2.550326533787579

Epoch: 5| Step: 9
Training loss: 2.741571340865166
Validation loss: 2.559185236189176

Epoch: 5| Step: 10
Training loss: 2.9086449712095286
Validation loss: 2.566246705149898

Epoch: 382| Step: 0
Training loss: 2.552343850884554
Validation loss: 2.5536226419862396

Epoch: 5| Step: 1
Training loss: 2.8417451939029146
Validation loss: 2.5626926724851553

Epoch: 5| Step: 2
Training loss: 3.0769770461631243
Validation loss: 2.5704800105817354

Epoch: 5| Step: 3
Training loss: 3.0600585547934616
Validation loss: 2.5931823401851615

Epoch: 5| Step: 4
Training loss: 2.624400024876175
Validation loss: 2.5953706624268964

Epoch: 5| Step: 5
Training loss: 3.325811020456006
Validation loss: 2.5751053225176563

Epoch: 5| Step: 6
Training loss: 3.0639990427000776
Validation loss: 2.5586306002800887

Epoch: 5| Step: 7
Training loss: 2.8033603939363587
Validation loss: 2.5484636532027056

Epoch: 5| Step: 8
Training loss: 3.002864741421671
Validation loss: 2.537672816167177

Epoch: 5| Step: 9
Training loss: 2.4024412057849447
Validation loss: 2.534174867100205

Epoch: 5| Step: 10
Training loss: 2.527570145385435
Validation loss: 2.546647309846228

Epoch: 383| Step: 0
Training loss: 2.7066074936917706
Validation loss: 2.5410450353880925

Epoch: 5| Step: 1
Training loss: 3.5803580832811406
Validation loss: 2.5434593631077114

Epoch: 5| Step: 2
Training loss: 2.6145212741087676
Validation loss: 2.5460335540409305

Epoch: 5| Step: 3
Training loss: 2.5020912960115305
Validation loss: 2.539485503521337

Epoch: 5| Step: 4
Training loss: 2.582859016271893
Validation loss: 2.5436136318875833

Epoch: 5| Step: 5
Training loss: 2.9189212985692525
Validation loss: 2.548070126284272

Epoch: 5| Step: 6
Training loss: 2.6067995621771427
Validation loss: 2.547654160128731

Epoch: 5| Step: 7
Training loss: 3.12008646918564
Validation loss: 2.5535037586668623

Epoch: 5| Step: 8
Training loss: 2.2952449490012015
Validation loss: 2.5524550103030252

Epoch: 5| Step: 9
Training loss: 3.200598338931777
Validation loss: 2.5766004860921394

Epoch: 5| Step: 10
Training loss: 3.0807253315445715
Validation loss: 2.5740645655605285

Epoch: 384| Step: 0
Training loss: 2.5854958332819757
Validation loss: 2.565136239489641

Epoch: 5| Step: 1
Training loss: 2.4612702644253996
Validation loss: 2.586381759627767

Epoch: 5| Step: 2
Training loss: 3.277433955664131
Validation loss: 2.5906507293093637

Epoch: 5| Step: 3
Training loss: 2.75752935495946
Validation loss: 2.57774421512455

Epoch: 5| Step: 4
Training loss: 2.807507640525904
Validation loss: 2.5835963825492105

Epoch: 5| Step: 5
Training loss: 2.773982980303269
Validation loss: 2.579533487241977

Epoch: 5| Step: 6
Training loss: 3.312800699656859
Validation loss: 2.570508446561473

Epoch: 5| Step: 7
Training loss: 3.096918506489934
Validation loss: 2.5607861055374803

Epoch: 5| Step: 8
Training loss: 3.2705423667086966
Validation loss: 2.560394580690105

Epoch: 5| Step: 9
Training loss: 2.142564771779264
Validation loss: 2.545561000994464

Epoch: 5| Step: 10
Training loss: 2.6693438760331394
Validation loss: 2.5259733897247805

Epoch: 385| Step: 0
Training loss: 2.9763156257837755
Validation loss: 2.530857863512167

Epoch: 5| Step: 1
Training loss: 2.6908794712503172
Validation loss: 2.530131504231166

Epoch: 5| Step: 2
Training loss: 2.854607782362664
Validation loss: 2.5326446707767425

Epoch: 5| Step: 3
Training loss: 3.0082902801335343
Validation loss: 2.529428627635985

Epoch: 5| Step: 4
Training loss: 3.0839517505893927
Validation loss: 2.524887044015318

Epoch: 5| Step: 5
Training loss: 2.8068782145707507
Validation loss: 2.5230068656022206

Epoch: 5| Step: 6
Training loss: 2.846458737941191
Validation loss: 2.534127242271379

Epoch: 5| Step: 7
Training loss: 2.511969807419072
Validation loss: 2.5348499747069875

Epoch: 5| Step: 8
Training loss: 3.0650513589610284
Validation loss: 2.537849445206504

Epoch: 5| Step: 9
Training loss: 3.2363515518068064
Validation loss: 2.549416372357196

Epoch: 5| Step: 10
Training loss: 1.9519156412125387
Validation loss: 2.561361734857173

Epoch: 386| Step: 0
Training loss: 2.365970714307232
Validation loss: 2.5703373781340444

Epoch: 5| Step: 1
Training loss: 2.8544210241728085
Validation loss: 2.594318885452987

Epoch: 5| Step: 2
Training loss: 2.9525333195291275
Validation loss: 2.6053165635424773

Epoch: 5| Step: 3
Training loss: 2.526228267948046
Validation loss: 2.610413509051706

Epoch: 5| Step: 4
Training loss: 3.4082318061561816
Validation loss: 2.5832668782822057

Epoch: 5| Step: 5
Training loss: 2.3486271277218105
Validation loss: 2.571600819440929

Epoch: 5| Step: 6
Training loss: 2.832150623831101
Validation loss: 2.557232203046098

Epoch: 5| Step: 7
Training loss: 3.4668301604916176
Validation loss: 2.538425440226474

Epoch: 5| Step: 8
Training loss: 3.1105799808199173
Validation loss: 2.526788313777158

Epoch: 5| Step: 9
Training loss: 2.5960427687050536
Validation loss: 2.5223924423490094

Epoch: 5| Step: 10
Training loss: 2.6403088803649717
Validation loss: 2.5232318507502436

Epoch: 387| Step: 0
Training loss: 3.175571786652
Validation loss: 2.529230456363682

Epoch: 5| Step: 1
Training loss: 2.8834141876115087
Validation loss: 2.5298932104381646

Epoch: 5| Step: 2
Training loss: 3.369186480666202
Validation loss: 2.5232387657367723

Epoch: 5| Step: 3
Training loss: 2.758317074530896
Validation loss: 2.5221890924463835

Epoch: 5| Step: 4
Training loss: 2.658459810060431
Validation loss: 2.530418563284463

Epoch: 5| Step: 5
Training loss: 2.9170080439286976
Validation loss: 2.534769671614977

Epoch: 5| Step: 6
Training loss: 2.271100603059836
Validation loss: 2.5248802360934843

Epoch: 5| Step: 7
Training loss: 2.6754634919104037
Validation loss: 2.5366304922888605

Epoch: 5| Step: 8
Training loss: 2.969042793692743
Validation loss: 2.5470253770216593

Epoch: 5| Step: 9
Training loss: 2.8019511441008786
Validation loss: 2.558310182073913

Epoch: 5| Step: 10
Training loss: 2.735960930985921
Validation loss: 2.574163051717641

Epoch: 388| Step: 0
Training loss: 2.9391768518943233
Validation loss: 2.590240048777207

Epoch: 5| Step: 1
Training loss: 2.6867572733964415
Validation loss: 2.6132220005812594

Epoch: 5| Step: 2
Training loss: 2.962985575995869
Validation loss: 2.6227076453907516

Epoch: 5| Step: 3
Training loss: 2.2870195144734815
Validation loss: 2.6077827565509866

Epoch: 5| Step: 4
Training loss: 2.831730520132073
Validation loss: 2.581613884055679

Epoch: 5| Step: 5
Training loss: 2.9457716040144013
Validation loss: 2.557765038622808

Epoch: 5| Step: 6
Training loss: 2.945637247410984
Validation loss: 2.5514518038449236

Epoch: 5| Step: 7
Training loss: 3.113508381330102
Validation loss: 2.5380078115400013

Epoch: 5| Step: 8
Training loss: 2.964127968088769
Validation loss: 2.542507285453527

Epoch: 5| Step: 9
Training loss: 2.887003841956515
Validation loss: 2.5410070442576367

Epoch: 5| Step: 10
Training loss: 3.034090893504812
Validation loss: 2.5391375574924364

Epoch: 389| Step: 0
Training loss: 2.3600008305047075
Validation loss: 2.5426993818011625

Epoch: 5| Step: 1
Training loss: 2.5914102135099797
Validation loss: 2.544021919896317

Epoch: 5| Step: 2
Training loss: 2.9560124243344825
Validation loss: 2.5577935327700683

Epoch: 5| Step: 3
Training loss: 2.352901850399788
Validation loss: 2.560413991193998

Epoch: 5| Step: 4
Training loss: 2.87536784596924
Validation loss: 2.5637968709896204

Epoch: 5| Step: 5
Training loss: 3.0127584639349565
Validation loss: 2.569186092012685

Epoch: 5| Step: 6
Training loss: 2.9357707026486715
Validation loss: 2.5677430453545167

Epoch: 5| Step: 7
Training loss: 2.781201137156359
Validation loss: 2.5708031900212664

Epoch: 5| Step: 8
Training loss: 3.146627734261309
Validation loss: 2.564778523221092

Epoch: 5| Step: 9
Training loss: 3.188257463997894
Validation loss: 2.5673216630313265

Epoch: 5| Step: 10
Training loss: 3.343596410343394
Validation loss: 2.5718853362194247

Epoch: 390| Step: 0
Training loss: 2.6850875850152227
Validation loss: 2.5713227507722545

Epoch: 5| Step: 1
Training loss: 3.1141523150149997
Validation loss: 2.5855241626160934

Epoch: 5| Step: 2
Training loss: 2.6857125304022156
Validation loss: 2.5801109284616808

Epoch: 5| Step: 3
Training loss: 2.9809272383467165
Validation loss: 2.5830265905711625

Epoch: 5| Step: 4
Training loss: 2.698306778401491
Validation loss: 2.5782084511494388

Epoch: 5| Step: 5
Training loss: 2.837905579203975
Validation loss: 2.58824652774033

Epoch: 5| Step: 6
Training loss: 2.808276586968601
Validation loss: 2.5952625630868904

Epoch: 5| Step: 7
Training loss: 2.9475228593633886
Validation loss: 2.5838874007042474

Epoch: 5| Step: 8
Training loss: 3.2386484708666177
Validation loss: 2.57946305888314

Epoch: 5| Step: 9
Training loss: 2.7536128327453575
Validation loss: 2.5861940587823313

Epoch: 5| Step: 10
Training loss: 2.7185679407657943
Validation loss: 2.5924697367181895

Epoch: 391| Step: 0
Training loss: 3.1582885806117926
Validation loss: 2.578535149876629

Epoch: 5| Step: 1
Training loss: 2.661701397829455
Validation loss: 2.5813846380108885

Epoch: 5| Step: 2
Training loss: 2.4863640841800185
Validation loss: 2.564203673921806

Epoch: 5| Step: 3
Training loss: 2.4166036027594333
Validation loss: 2.5691296774233634

Epoch: 5| Step: 4
Training loss: 3.396806557956354
Validation loss: 2.5682592024245605

Epoch: 5| Step: 5
Training loss: 3.2380036717111884
Validation loss: 2.5599402171154515

Epoch: 5| Step: 6
Training loss: 2.7736909992257233
Validation loss: 2.556845632575407

Epoch: 5| Step: 7
Training loss: 2.9436039914734056
Validation loss: 2.5669437288340013

Epoch: 5| Step: 8
Training loss: 2.8750703222547718
Validation loss: 2.5720539274842973

Epoch: 5| Step: 9
Training loss: 2.5123833093067827
Validation loss: 2.5579416162391544

Epoch: 5| Step: 10
Training loss: 2.8726131648654847
Validation loss: 2.565514568859836

Epoch: 392| Step: 0
Training loss: 3.0908615037243385
Validation loss: 2.5636118205883984

Epoch: 5| Step: 1
Training loss: 3.243324172453637
Validation loss: 2.5569182901267142

Epoch: 5| Step: 2
Training loss: 2.262598476058243
Validation loss: 2.559036095656891

Epoch: 5| Step: 3
Training loss: 3.0369906779458
Validation loss: 2.5816208204166475

Epoch: 5| Step: 4
Training loss: 3.0819577593919534
Validation loss: 2.5822701580296834

Epoch: 5| Step: 5
Training loss: 2.8782618718939115
Validation loss: 2.5727901048151995

Epoch: 5| Step: 6
Training loss: 2.749854777576447
Validation loss: 2.570177961605385

Epoch: 5| Step: 7
Training loss: 2.5030895216352755
Validation loss: 2.564349721686042

Epoch: 5| Step: 8
Training loss: 2.9174603245251207
Validation loss: 2.574827126525121

Epoch: 5| Step: 9
Training loss: 2.819333907927049
Validation loss: 2.5571170355706117

Epoch: 5| Step: 10
Training loss: 2.6699616122968726
Validation loss: 2.5522979461927138

Epoch: 393| Step: 0
Training loss: 2.803852265083534
Validation loss: 2.548207343010583

Epoch: 5| Step: 1
Training loss: 2.7148864303636993
Validation loss: 2.5654524974804427

Epoch: 5| Step: 2
Training loss: 1.5800900452945754
Validation loss: 2.5648290702871486

Epoch: 5| Step: 3
Training loss: 2.663754353083361
Validation loss: 2.563519719898809

Epoch: 5| Step: 4
Training loss: 2.9454287397279586
Validation loss: 2.587018145493407

Epoch: 5| Step: 5
Training loss: 2.5755774656008765
Validation loss: 2.578899379860158

Epoch: 5| Step: 6
Training loss: 2.987889322746154
Validation loss: 2.583866103811432

Epoch: 5| Step: 7
Training loss: 3.046117756962496
Validation loss: 2.583622725357661

Epoch: 5| Step: 8
Training loss: 3.204324786018039
Validation loss: 2.5744707996005345

Epoch: 5| Step: 9
Training loss: 3.7202389084588026
Validation loss: 2.554393964064308

Epoch: 5| Step: 10
Training loss: 2.5071917089345885
Validation loss: 2.5452545404166385

Epoch: 394| Step: 0
Training loss: 3.483378041055018
Validation loss: 2.5377463580381354

Epoch: 5| Step: 1
Training loss: 2.692063560001897
Validation loss: 2.5307278253399845

Epoch: 5| Step: 2
Training loss: 2.680115512664401
Validation loss: 2.530118370527993

Epoch: 5| Step: 3
Training loss: 2.526101327303005
Validation loss: 2.5328836824304033

Epoch: 5| Step: 4
Training loss: 3.3421109184062363
Validation loss: 2.528856171241224

Epoch: 5| Step: 5
Training loss: 3.0635777348212465
Validation loss: 2.5322867270319014

Epoch: 5| Step: 6
Training loss: 2.642129413094819
Validation loss: 2.5292563761379157

Epoch: 5| Step: 7
Training loss: 2.698145695885978
Validation loss: 2.529376717363313

Epoch: 5| Step: 8
Training loss: 2.6598496225342982
Validation loss: 2.5374729781644496

Epoch: 5| Step: 9
Training loss: 2.7322496274001433
Validation loss: 2.533737293407046

Epoch: 5| Step: 10
Training loss: 2.506925146628016
Validation loss: 2.548937986416493

Epoch: 395| Step: 0
Training loss: 2.991902708838112
Validation loss: 2.5380004681053996

Epoch: 5| Step: 1
Training loss: 2.4045409040773467
Validation loss: 2.544837655678141

Epoch: 5| Step: 2
Training loss: 3.028755813574161
Validation loss: 2.5452093902076625

Epoch: 5| Step: 3
Training loss: 3.285203568234579
Validation loss: 2.5488266726077824

Epoch: 5| Step: 4
Training loss: 2.5938274877532557
Validation loss: 2.564471284180533

Epoch: 5| Step: 5
Training loss: 2.802644968766713
Validation loss: 2.5623841388320074

Epoch: 5| Step: 6
Training loss: 2.676443199086618
Validation loss: 2.5814049692097494

Epoch: 5| Step: 7
Training loss: 2.7142200659220066
Validation loss: 2.5793916853965495

Epoch: 5| Step: 8
Training loss: 2.912035034786368
Validation loss: 2.573345406836733

Epoch: 5| Step: 9
Training loss: 2.8702299933705224
Validation loss: 2.5660392586365597

Epoch: 5| Step: 10
Training loss: 2.835717899447867
Validation loss: 2.5612505285904645

Epoch: 396| Step: 0
Training loss: 2.81335859968341
Validation loss: 2.5456350108680663

Epoch: 5| Step: 1
Training loss: 2.949256906830979
Validation loss: 2.545992727317947

Epoch: 5| Step: 2
Training loss: 2.9524142908742492
Validation loss: 2.5338619666142908

Epoch: 5| Step: 3
Training loss: 2.7867122546334975
Validation loss: 2.5391864392343053

Epoch: 5| Step: 4
Training loss: 2.6677099412354424
Validation loss: 2.536621937138774

Epoch: 5| Step: 5
Training loss: 2.457445555478715
Validation loss: 2.539906373495068

Epoch: 5| Step: 6
Training loss: 2.607432116084757
Validation loss: 2.5343057167097

Epoch: 5| Step: 7
Training loss: 2.8243412397527528
Validation loss: 2.5534930919675367

Epoch: 5| Step: 8
Training loss: 3.553329040519979
Validation loss: 2.556386372155675

Epoch: 5| Step: 9
Training loss: 3.0220993195426544
Validation loss: 2.554790238741204

Epoch: 5| Step: 10
Training loss: 2.088746997002407
Validation loss: 2.565975656355896

Epoch: 397| Step: 0
Training loss: 3.072021164235087
Validation loss: 2.5533468193101383

Epoch: 5| Step: 1
Training loss: 2.7840674199403277
Validation loss: 2.5540899665663632

Epoch: 5| Step: 2
Training loss: 2.71419292305683
Validation loss: 2.5498305368785688

Epoch: 5| Step: 3
Training loss: 2.909457334015158
Validation loss: 2.5512786095421327

Epoch: 5| Step: 4
Training loss: 2.5392517958282883
Validation loss: 2.561015293486129

Epoch: 5| Step: 5
Training loss: 2.595089210490941
Validation loss: 2.558124214655823

Epoch: 5| Step: 6
Training loss: 3.0721728098066734
Validation loss: 2.5621188040546268

Epoch: 5| Step: 7
Training loss: 2.7014417754822704
Validation loss: 2.587311164742701

Epoch: 5| Step: 8
Training loss: 3.1966032298625175
Validation loss: 2.583305993532549

Epoch: 5| Step: 9
Training loss: 2.9958871623488035
Validation loss: 2.5652564115658083

Epoch: 5| Step: 10
Training loss: 2.308853160658007
Validation loss: 2.5340321528097154

Epoch: 398| Step: 0
Training loss: 2.510518168274447
Validation loss: 2.525760397407849

Epoch: 5| Step: 1
Training loss: 2.5403086260028007
Validation loss: 2.537159288067234

Epoch: 5| Step: 2
Training loss: 3.2557864395512524
Validation loss: 2.517948580434918

Epoch: 5| Step: 3
Training loss: 2.7764744424246475
Validation loss: 2.5217580252737277

Epoch: 5| Step: 4
Training loss: 2.9663759074795455
Validation loss: 2.5255460462029693

Epoch: 5| Step: 5
Training loss: 2.4851792671123465
Validation loss: 2.5190321988721704

Epoch: 5| Step: 6
Training loss: 3.624023963806887
Validation loss: 2.520048365206147

Epoch: 5| Step: 7
Training loss: 2.6753774964830184
Validation loss: 2.527407513999141

Epoch: 5| Step: 8
Training loss: 2.722434868151693
Validation loss: 2.536722666768669

Epoch: 5| Step: 9
Training loss: 2.786240290491806
Validation loss: 2.546670501469115

Epoch: 5| Step: 10
Training loss: 2.487611881212886
Validation loss: 2.5438429339262285

Epoch: 399| Step: 0
Training loss: 2.5794391403930623
Validation loss: 2.5521529375085303

Epoch: 5| Step: 1
Training loss: 2.8241160942615635
Validation loss: 2.5586120188997934

Epoch: 5| Step: 2
Training loss: 2.2934087431877637
Validation loss: 2.563470788123937

Epoch: 5| Step: 3
Training loss: 2.707781711057738
Validation loss: 2.5586099698797935

Epoch: 5| Step: 4
Training loss: 2.755473411995232
Validation loss: 2.5494608085244788

Epoch: 5| Step: 5
Training loss: 2.966490357406944
Validation loss: 2.548139733102775

Epoch: 5| Step: 6
Training loss: 3.2015762678811917
Validation loss: 2.56892343770992

Epoch: 5| Step: 7
Training loss: 2.8695283320095597
Validation loss: 2.5707136127262546

Epoch: 5| Step: 8
Training loss: 2.4301471827324432
Validation loss: 2.5563135871647606

Epoch: 5| Step: 9
Training loss: 2.908752348554226
Validation loss: 2.555352466054924

Epoch: 5| Step: 10
Training loss: 3.4182102314249576
Validation loss: 2.55746604392243

Epoch: 400| Step: 0
Training loss: 2.6360884301572445
Validation loss: 2.535287056037275

Epoch: 5| Step: 1
Training loss: 2.7836522218535533
Validation loss: 2.5350224680700877

Epoch: 5| Step: 2
Training loss: 2.6577048412767637
Validation loss: 2.5308422649973816

Epoch: 5| Step: 3
Training loss: 3.3139189074395663
Validation loss: 2.5287547693762185

Epoch: 5| Step: 4
Training loss: 2.5578238457280724
Validation loss: 2.5261847677610803

Epoch: 5| Step: 5
Training loss: 3.0116937341900436
Validation loss: 2.5278869832231763

Epoch: 5| Step: 6
Training loss: 2.976688412383625
Validation loss: 2.535753255764897

Epoch: 5| Step: 7
Training loss: 2.6367086226657364
Validation loss: 2.539178723624613

Epoch: 5| Step: 8
Training loss: 2.689531578631728
Validation loss: 2.5473619331903947

Epoch: 5| Step: 9
Training loss: 3.2006798320081824
Validation loss: 2.563523762086274

Epoch: 5| Step: 10
Training loss: 2.460110867645932
Validation loss: 2.5679931189827854

Epoch: 401| Step: 0
Training loss: 2.888819114950995
Validation loss: 2.573877061108831

Epoch: 5| Step: 1
Training loss: 2.4136458842947426
Validation loss: 2.5669198504885773

Epoch: 5| Step: 2
Training loss: 2.8418507364418932
Validation loss: 2.5454385615877624

Epoch: 5| Step: 3
Training loss: 2.9138730066781995
Validation loss: 2.535188283218137

Epoch: 5| Step: 4
Training loss: 3.077472443321678
Validation loss: 2.5492943383516082

Epoch: 5| Step: 5
Training loss: 2.7070391766320636
Validation loss: 2.5455553672573115

Epoch: 5| Step: 6
Training loss: 3.0967937870713245
Validation loss: 2.5602706938324786

Epoch: 5| Step: 7
Training loss: 2.533332627279618
Validation loss: 2.5625194765916968

Epoch: 5| Step: 8
Training loss: 3.146323429019197
Validation loss: 2.567142096574778

Epoch: 5| Step: 9
Training loss: 2.7309641463706926
Validation loss: 2.5690121523638347

Epoch: 5| Step: 10
Training loss: 2.5982692826920113
Validation loss: 2.577759396560642

Epoch: 402| Step: 0
Training loss: 2.2959785009367826
Validation loss: 2.567219162159046

Epoch: 5| Step: 1
Training loss: 2.552320871522089
Validation loss: 2.577085104419195

Epoch: 5| Step: 2
Training loss: 3.170920693542929
Validation loss: 2.572092078995736

Epoch: 5| Step: 3
Training loss: 2.721574215304742
Validation loss: 2.580846829988109

Epoch: 5| Step: 4
Training loss: 2.847940229324465
Validation loss: 2.585772052614163

Epoch: 5| Step: 5
Training loss: 2.675762003808521
Validation loss: 2.57590867602264

Epoch: 5| Step: 6
Training loss: 2.794881867043099
Validation loss: 2.571761822465832

Epoch: 5| Step: 7
Training loss: 2.78482109289622
Validation loss: 2.5678484015956182

Epoch: 5| Step: 8
Training loss: 3.499463448950709
Validation loss: 2.560205197900509

Epoch: 5| Step: 9
Training loss: 2.8433020941153755
Validation loss: 2.561946041678034

Epoch: 5| Step: 10
Training loss: 2.9565055107685962
Validation loss: 2.553725159546519

Epoch: 403| Step: 0
Training loss: 2.4092797365664165
Validation loss: 2.5650650410374767

Epoch: 5| Step: 1
Training loss: 2.781972898338926
Validation loss: 2.542137645682837

Epoch: 5| Step: 2
Training loss: 3.3294431556469877
Validation loss: 2.5418503679944005

Epoch: 5| Step: 3
Training loss: 3.1610496964957417
Validation loss: 2.5355617564760706

Epoch: 5| Step: 4
Training loss: 2.878945504364758
Validation loss: 2.538111286052294

Epoch: 5| Step: 5
Training loss: 2.88563395392417
Validation loss: 2.5358632458820476

Epoch: 5| Step: 6
Training loss: 2.7224219945236023
Validation loss: 2.537986932695713

Epoch: 5| Step: 7
Training loss: 2.68009460737717
Validation loss: 2.545720968144417

Epoch: 5| Step: 8
Training loss: 2.977902889074836
Validation loss: 2.5481475151446222

Epoch: 5| Step: 9
Training loss: 2.4809818728306356
Validation loss: 2.553865522590673

Epoch: 5| Step: 10
Training loss: 2.511041481699365
Validation loss: 2.556190051114393

Epoch: 404| Step: 0
Training loss: 2.7585557146888444
Validation loss: 2.561208411978786

Epoch: 5| Step: 1
Training loss: 2.779816075696982
Validation loss: 2.566278787335999

Epoch: 5| Step: 2
Training loss: 3.0216814801680094
Validation loss: 2.578061194700825

Epoch: 5| Step: 3
Training loss: 3.0309350548170038
Validation loss: 2.57411532466818

Epoch: 5| Step: 4
Training loss: 2.7110045147178936
Validation loss: 2.5658827133256805

Epoch: 5| Step: 5
Training loss: 2.5143977423579793
Validation loss: 2.5510374297140666

Epoch: 5| Step: 6
Training loss: 3.0082103911944773
Validation loss: 2.5358242915102576

Epoch: 5| Step: 7
Training loss: 3.19461372774657
Validation loss: 2.523048830401908

Epoch: 5| Step: 8
Training loss: 2.65539537032697
Validation loss: 2.5164495742311654

Epoch: 5| Step: 9
Training loss: 2.4533370588454004
Validation loss: 2.523631338455846

Epoch: 5| Step: 10
Training loss: 2.7839227756554217
Validation loss: 2.5202731938446523

Epoch: 405| Step: 0
Training loss: 2.9878850138139397
Validation loss: 2.527001772356512

Epoch: 5| Step: 1
Training loss: 2.710589647649669
Validation loss: 2.540767554691952

Epoch: 5| Step: 2
Training loss: 2.2190969491403116
Validation loss: 2.547888105301112

Epoch: 5| Step: 3
Training loss: 2.6320004441860947
Validation loss: 2.5725110395922868

Epoch: 5| Step: 4
Training loss: 3.2556007250479313
Validation loss: 2.5717619859479424

Epoch: 5| Step: 5
Training loss: 2.8989532094168378
Validation loss: 2.567611384660818

Epoch: 5| Step: 6
Training loss: 2.601798381937283
Validation loss: 2.5571319234119123

Epoch: 5| Step: 7
Training loss: 3.0858358245710438
Validation loss: 2.536543657944287

Epoch: 5| Step: 8
Training loss: 3.3262025537156825
Validation loss: 2.542936998777778

Epoch: 5| Step: 9
Training loss: 2.6342441729984096
Validation loss: 2.548224039470044

Epoch: 5| Step: 10
Training loss: 2.2136785008641136
Validation loss: 2.548184452103555

Epoch: 406| Step: 0
Training loss: 2.957493694230981
Validation loss: 2.5432915626718806

Epoch: 5| Step: 1
Training loss: 2.7937089272707887
Validation loss: 2.5560613247714445

Epoch: 5| Step: 2
Training loss: 2.8871366330019903
Validation loss: 2.554955041388401

Epoch: 5| Step: 3
Training loss: 2.790096743010476
Validation loss: 2.5791291996754255

Epoch: 5| Step: 4
Training loss: 2.5969706383456557
Validation loss: 2.569604183539247

Epoch: 5| Step: 5
Training loss: 3.027331149167324
Validation loss: 2.570746208588412

Epoch: 5| Step: 6
Training loss: 3.1938741939756112
Validation loss: 2.5397708467016336

Epoch: 5| Step: 7
Training loss: 2.964199071461616
Validation loss: 2.530105696774166

Epoch: 5| Step: 8
Training loss: 1.9762943975587604
Validation loss: 2.513129907037142

Epoch: 5| Step: 9
Training loss: 3.011933592420146
Validation loss: 2.5103661119302

Epoch: 5| Step: 10
Training loss: 2.6551670335142
Validation loss: 2.5120923473131045

Epoch: 407| Step: 0
Training loss: 2.6645970856940746
Validation loss: 2.510042881565223

Epoch: 5| Step: 1
Training loss: 2.5171707806307233
Validation loss: 2.512512192961587

Epoch: 5| Step: 2
Training loss: 2.831938475042885
Validation loss: 2.5144547864367603

Epoch: 5| Step: 3
Training loss: 2.4118671990649263
Validation loss: 2.5301038090805843

Epoch: 5| Step: 4
Training loss: 3.0771995741149296
Validation loss: 2.5570186653643505

Epoch: 5| Step: 5
Training loss: 3.118896627706088
Validation loss: 2.5722554850941592

Epoch: 5| Step: 6
Training loss: 3.0549684673373934
Validation loss: 2.581854492896914

Epoch: 5| Step: 7
Training loss: 2.8301456883002323
Validation loss: 2.5810410024221566

Epoch: 5| Step: 8
Training loss: 3.086138832188294
Validation loss: 2.5342646575541306

Epoch: 5| Step: 9
Training loss: 2.7406308355671642
Validation loss: 2.524087212493037

Epoch: 5| Step: 10
Training loss: 2.7484812444054243
Validation loss: 2.528980083536385

Epoch: 408| Step: 0
Training loss: 3.0128833384396687
Validation loss: 2.529506552363972

Epoch: 5| Step: 1
Training loss: 2.902050306392872
Validation loss: 2.532898858457948

Epoch: 5| Step: 2
Training loss: 2.822269004106974
Validation loss: 2.528216900667281

Epoch: 5| Step: 3
Training loss: 2.832287838591757
Validation loss: 2.5290401996038336

Epoch: 5| Step: 4
Training loss: 3.045562304863852
Validation loss: 2.534804509714656

Epoch: 5| Step: 5
Training loss: 3.091156768565237
Validation loss: 2.5378240223166015

Epoch: 5| Step: 6
Training loss: 3.0738807502107353
Validation loss: 2.549049772077508

Epoch: 5| Step: 7
Training loss: 2.747074999162817
Validation loss: 2.5391136256419657

Epoch: 5| Step: 8
Training loss: 2.5546667815601958
Validation loss: 2.5421084375278773

Epoch: 5| Step: 9
Training loss: 2.457591176480855
Validation loss: 2.534678068369706

Epoch: 5| Step: 10
Training loss: 2.323631609957819
Validation loss: 2.543925535485616

Epoch: 409| Step: 0
Training loss: 2.981138381627904
Validation loss: 2.555984704100206

Epoch: 5| Step: 1
Training loss: 2.6637254429029387
Validation loss: 2.5700582490792447

Epoch: 5| Step: 2
Training loss: 3.257155830194934
Validation loss: 2.578117155309869

Epoch: 5| Step: 3
Training loss: 2.4628383500846054
Validation loss: 2.5670876423708644

Epoch: 5| Step: 4
Training loss: 2.5724257851619385
Validation loss: 2.561581692948722

Epoch: 5| Step: 5
Training loss: 2.589613407990513
Validation loss: 2.5586657888063233

Epoch: 5| Step: 6
Training loss: 2.6571680614196045
Validation loss: 2.536262763579389

Epoch: 5| Step: 7
Training loss: 2.375169747962137
Validation loss: 2.52083400691393

Epoch: 5| Step: 8
Training loss: 2.842373860830747
Validation loss: 2.5147573077421774

Epoch: 5| Step: 9
Training loss: 3.2048476634369694
Validation loss: 2.512186497709086

Epoch: 5| Step: 10
Training loss: 3.0784275274180066
Validation loss: 2.5008175641094286

Epoch: 410| Step: 0
Training loss: 2.6480344392490394
Validation loss: 2.506155418354545

Epoch: 5| Step: 1
Training loss: 2.7302675623304875
Validation loss: 2.5117993001311767

Epoch: 5| Step: 2
Training loss: 3.2074832202832235
Validation loss: 2.506947824224781

Epoch: 5| Step: 3
Training loss: 2.7690114123934793
Validation loss: 2.5211324030451814

Epoch: 5| Step: 4
Training loss: 2.7798135884310264
Validation loss: 2.521032711094881

Epoch: 5| Step: 5
Training loss: 2.5907544222209338
Validation loss: 2.5333525193717903

Epoch: 5| Step: 6
Training loss: 3.098226064296051
Validation loss: 2.5268685002025864

Epoch: 5| Step: 7
Training loss: 3.135237138409549
Validation loss: 2.5317542261209396

Epoch: 5| Step: 8
Training loss: 2.5082693664235056
Validation loss: 2.5426503296463903

Epoch: 5| Step: 9
Training loss: 2.691794579205595
Validation loss: 2.5465819799687717

Epoch: 5| Step: 10
Training loss: 2.6194521998154348
Validation loss: 2.531015078086292

Epoch: 411| Step: 0
Training loss: 2.9672012304678366
Validation loss: 2.534796049539672

Epoch: 5| Step: 1
Training loss: 2.845177260845075
Validation loss: 2.5301776449169693

Epoch: 5| Step: 2
Training loss: 2.823033000805856
Validation loss: 2.5364655906053075

Epoch: 5| Step: 3
Training loss: 2.788094146769876
Validation loss: 2.527122743387846

Epoch: 5| Step: 4
Training loss: 2.4288816434215654
Validation loss: 2.5360419964365284

Epoch: 5| Step: 5
Training loss: 2.7628131947830963
Validation loss: 2.55692438610426

Epoch: 5| Step: 6
Training loss: 2.682552752087219
Validation loss: 2.54792014497166

Epoch: 5| Step: 7
Training loss: 3.1314341112173363
Validation loss: 2.552716329165754

Epoch: 5| Step: 8
Training loss: 2.261654024400378
Validation loss: 2.548527454115928

Epoch: 5| Step: 9
Training loss: 2.9457641579052156
Validation loss: 2.542564699099536

Epoch: 5| Step: 10
Training loss: 3.0087055416332924
Validation loss: 2.5579761197088007

Epoch: 412| Step: 0
Training loss: 2.970354630333531
Validation loss: 2.53905167721697

Epoch: 5| Step: 1
Training loss: 2.501966180104747
Validation loss: 2.553974232795707

Epoch: 5| Step: 2
Training loss: 2.699011699502752
Validation loss: 2.5606388803796496

Epoch: 5| Step: 3
Training loss: 2.7851767947173536
Validation loss: 2.5548343386068373

Epoch: 5| Step: 4
Training loss: 2.9605074849561595
Validation loss: 2.540388417957477

Epoch: 5| Step: 5
Training loss: 3.1094341943368304
Validation loss: 2.541818154485705

Epoch: 5| Step: 6
Training loss: 2.881798211693935
Validation loss: 2.5149463504253893

Epoch: 5| Step: 7
Training loss: 2.567482454115541
Validation loss: 2.5178711715998787

Epoch: 5| Step: 8
Training loss: 2.8572319629943324
Validation loss: 2.5139110353982055

Epoch: 5| Step: 9
Training loss: 2.492500596424211
Validation loss: 2.507771382253368

Epoch: 5| Step: 10
Training loss: 2.880488919507463
Validation loss: 2.5080925615742964

Epoch: 413| Step: 0
Training loss: 2.7706041934460295
Validation loss: 2.509149434682848

Epoch: 5| Step: 1
Training loss: 2.5630520481833328
Validation loss: 2.5176576832373816

Epoch: 5| Step: 2
Training loss: 2.873298141311184
Validation loss: 2.527839778957276

Epoch: 5| Step: 3
Training loss: 2.5896189320194836
Validation loss: 2.532666466203981

Epoch: 5| Step: 4
Training loss: 2.68749485458946
Validation loss: 2.5443786036692675

Epoch: 5| Step: 5
Training loss: 3.4100169779335294
Validation loss: 2.5474828229705855

Epoch: 5| Step: 6
Training loss: 2.715495474550132
Validation loss: 2.5455890919471718

Epoch: 5| Step: 7
Training loss: 2.668968538363998
Validation loss: 2.555276793290416

Epoch: 5| Step: 8
Training loss: 3.1518805445967057
Validation loss: 2.5348313788004293

Epoch: 5| Step: 9
Training loss: 2.889469555019953
Validation loss: 2.52695598151719

Epoch: 5| Step: 10
Training loss: 2.1522211223361625
Validation loss: 2.5124419531588202

Epoch: 414| Step: 0
Training loss: 2.7005829075907823
Validation loss: 2.5088228174986478

Epoch: 5| Step: 1
Training loss: 3.0991418265933444
Validation loss: 2.5100328600264215

Epoch: 5| Step: 2
Training loss: 2.577448993255869
Validation loss: 2.5145881262178427

Epoch: 5| Step: 3
Training loss: 2.7388922299495158
Validation loss: 2.512882938179639

Epoch: 5| Step: 4
Training loss: 2.7425164788862966
Validation loss: 2.5220302715493883

Epoch: 5| Step: 5
Training loss: 2.9951999728736713
Validation loss: 2.5231920693973366

Epoch: 5| Step: 6
Training loss: 3.156030175136104
Validation loss: 2.526665335008283

Epoch: 5| Step: 7
Training loss: 2.567204878058098
Validation loss: 2.5183893758863207

Epoch: 5| Step: 8
Training loss: 2.8313708146951746
Validation loss: 2.545404722101095

Epoch: 5| Step: 9
Training loss: 2.83502703887586
Validation loss: 2.552117887208197

Epoch: 5| Step: 10
Training loss: 2.4525428615794915
Validation loss: 2.5597564122180834

Epoch: 415| Step: 0
Training loss: 2.864899514984257
Validation loss: 2.5645147847168013

Epoch: 5| Step: 1
Training loss: 2.7086504432679974
Validation loss: 2.564850588221708

Epoch: 5| Step: 2
Training loss: 2.7440893636782406
Validation loss: 2.542611788795984

Epoch: 5| Step: 3
Training loss: 2.7817220394443125
Validation loss: 2.5487445758985423

Epoch: 5| Step: 4
Training loss: 2.6485806316757268
Validation loss: 2.5358619559046454

Epoch: 5| Step: 5
Training loss: 2.5607859763936798
Validation loss: 2.526164736010519

Epoch: 5| Step: 6
Training loss: 2.556712057049752
Validation loss: 2.5213190083939523

Epoch: 5| Step: 7
Training loss: 2.598245057797877
Validation loss: 2.526871874601792

Epoch: 5| Step: 8
Training loss: 3.1458644907505215
Validation loss: 2.5236634839306498

Epoch: 5| Step: 9
Training loss: 2.8738424209792917
Validation loss: 2.5308054953145294

Epoch: 5| Step: 10
Training loss: 3.219703755227077
Validation loss: 2.544943357769265

Epoch: 416| Step: 0
Training loss: 3.1946310421905593
Validation loss: 2.542791394763371

Epoch: 5| Step: 1
Training loss: 2.9258682788082795
Validation loss: 2.5548226704994645

Epoch: 5| Step: 2
Training loss: 2.8042653225628658
Validation loss: 2.552653417310862

Epoch: 5| Step: 3
Training loss: 2.749366860764638
Validation loss: 2.546723043736576

Epoch: 5| Step: 4
Training loss: 2.866944346914614
Validation loss: 2.549917782377562

Epoch: 5| Step: 5
Training loss: 2.4033085072152662
Validation loss: 2.5587909125604877

Epoch: 5| Step: 6
Training loss: 2.5960562690373368
Validation loss: 2.554005629487072

Epoch: 5| Step: 7
Training loss: 2.8701746708687237
Validation loss: 2.561432990208035

Epoch: 5| Step: 8
Training loss: 2.48960201836335
Validation loss: 2.5562314310409073

Epoch: 5| Step: 9
Training loss: 3.136156841793491
Validation loss: 2.5455285227414417

Epoch: 5| Step: 10
Training loss: 2.4352727642461938
Validation loss: 2.544686519718941

Epoch: 417| Step: 0
Training loss: 2.54906757735373
Validation loss: 2.5248159117487536

Epoch: 5| Step: 1
Training loss: 3.0203976196356472
Validation loss: 2.541407274525477

Epoch: 5| Step: 2
Training loss: 2.9711886378504975
Validation loss: 2.5546894899488293

Epoch: 5| Step: 3
Training loss: 2.925615822937183
Validation loss: 2.5619628207142466

Epoch: 5| Step: 4
Training loss: 2.2859460232120132
Validation loss: 2.561306048751253

Epoch: 5| Step: 5
Training loss: 3.0875857816200516
Validation loss: 2.5646513345195054

Epoch: 5| Step: 6
Training loss: 2.7313450183533106
Validation loss: 2.557830094899556

Epoch: 5| Step: 7
Training loss: 3.3097988127448423
Validation loss: 2.548122551155563

Epoch: 5| Step: 8
Training loss: 2.513930798691147
Validation loss: 2.5359230542157047

Epoch: 5| Step: 9
Training loss: 2.343157782438498
Validation loss: 2.5231935619460115

Epoch: 5| Step: 10
Training loss: 2.7935798029933094
Validation loss: 2.522591226010477

Epoch: 418| Step: 0
Training loss: 3.1557588100641283
Validation loss: 2.5068926689170428

Epoch: 5| Step: 1
Training loss: 2.7222273063179685
Validation loss: 2.5072238044462956

Epoch: 5| Step: 2
Training loss: 2.8971192685938076
Validation loss: 2.5155549291524144

Epoch: 5| Step: 3
Training loss: 3.1443611051600855
Validation loss: 2.530020090531083

Epoch: 5| Step: 4
Training loss: 3.1248214670681276
Validation loss: 2.536376726085481

Epoch: 5| Step: 5
Training loss: 2.4225277913077083
Validation loss: 2.5563883748217817

Epoch: 5| Step: 6
Training loss: 2.968370433434872
Validation loss: 2.55533960444147

Epoch: 5| Step: 7
Training loss: 2.2311903659747974
Validation loss: 2.568302099783252

Epoch: 5| Step: 8
Training loss: 2.672272145163393
Validation loss: 2.593368607002343

Epoch: 5| Step: 9
Training loss: 3.069668068850031
Validation loss: 2.5841810804993655

Epoch: 5| Step: 10
Training loss: 1.9648139602496018
Validation loss: 2.5622734171738957

Epoch: 419| Step: 0
Training loss: 2.7996324127599195
Validation loss: 2.5520077216822057

Epoch: 5| Step: 1
Training loss: 2.7608389957215236
Validation loss: 2.5353513675083126

Epoch: 5| Step: 2
Training loss: 2.693536853544534
Validation loss: 2.531475871855647

Epoch: 5| Step: 3
Training loss: 2.6272400880089934
Validation loss: 2.5259027904464584

Epoch: 5| Step: 4
Training loss: 2.908663824007317
Validation loss: 2.5199088551747972

Epoch: 5| Step: 5
Training loss: 2.9935906608721305
Validation loss: 2.5267323943254385

Epoch: 5| Step: 6
Training loss: 2.4145872662972736
Validation loss: 2.5221029867561877

Epoch: 5| Step: 7
Training loss: 2.8373451627589894
Validation loss: 2.5174351847189764

Epoch: 5| Step: 8
Training loss: 3.095570962774281
Validation loss: 2.5575269629235438

Epoch: 5| Step: 9
Training loss: 2.7745089328420645
Validation loss: 2.5500141353323977

Epoch: 5| Step: 10
Training loss: 2.7938856633848026
Validation loss: 2.559917239345831

Epoch: 420| Step: 0
Training loss: 3.204282077121292
Validation loss: 2.5297300200272526

Epoch: 5| Step: 1
Training loss: 2.4587970447160727
Validation loss: 2.535207318913546

Epoch: 5| Step: 2
Training loss: 2.7349369016687786
Validation loss: 2.535549897561077

Epoch: 5| Step: 3
Training loss: 2.6174717079826944
Validation loss: 2.537114243378499

Epoch: 5| Step: 4
Training loss: 2.5483825527982438
Validation loss: 2.518768914085365

Epoch: 5| Step: 5
Training loss: 2.801863584918515
Validation loss: 2.5228622788207464

Epoch: 5| Step: 6
Training loss: 2.8756252106581712
Validation loss: 2.5091694418653963

Epoch: 5| Step: 7
Training loss: 2.780905712977816
Validation loss: 2.5188113871447793

Epoch: 5| Step: 8
Training loss: 2.995762056891981
Validation loss: 2.5434864340704983

Epoch: 5| Step: 9
Training loss: 2.7168871756930866
Validation loss: 2.5200135652294526

Epoch: 5| Step: 10
Training loss: 2.7086045838506023
Validation loss: 2.5201370140629207

Epoch: 421| Step: 0
Training loss: 2.7811402717118567
Validation loss: 2.546251144216014

Epoch: 5| Step: 1
Training loss: 2.6236417980518727
Validation loss: 2.544801773247933

Epoch: 5| Step: 2
Training loss: 2.5905317080349493
Validation loss: 2.5444416314566696

Epoch: 5| Step: 3
Training loss: 2.4546912957543956
Validation loss: 2.551028162639117

Epoch: 5| Step: 4
Training loss: 2.5061967344640723
Validation loss: 2.542213015754736

Epoch: 5| Step: 5
Training loss: 2.6804945372739466
Validation loss: 2.5377946230891864

Epoch: 5| Step: 6
Training loss: 2.914760311735036
Validation loss: 2.5191518765206813

Epoch: 5| Step: 7
Training loss: 2.935884396660018
Validation loss: 2.5206821741764567

Epoch: 5| Step: 8
Training loss: 3.0383445852813815
Validation loss: 2.5195914999379845

Epoch: 5| Step: 9
Training loss: 3.143022220165272
Validation loss: 2.5234334393169577

Epoch: 5| Step: 10
Training loss: 2.785693872467816
Validation loss: 2.517765791042535

Epoch: 422| Step: 0
Training loss: 2.8650251752935643
Validation loss: 2.53691796797252

Epoch: 5| Step: 1
Training loss: 2.6024008193525168
Validation loss: 2.5463731126415183

Epoch: 5| Step: 2
Training loss: 2.8964876675217295
Validation loss: 2.5533919902877393

Epoch: 5| Step: 3
Training loss: 2.8744197757532235
Validation loss: 2.564170774936136

Epoch: 5| Step: 4
Training loss: 2.0532567369533306
Validation loss: 2.5862135522162943

Epoch: 5| Step: 5
Training loss: 3.0930742238583404
Validation loss: 2.6067826380393804

Epoch: 5| Step: 6
Training loss: 2.966243609434784
Validation loss: 2.603834796719412

Epoch: 5| Step: 7
Training loss: 2.535625114638373
Validation loss: 2.5783875481797147

Epoch: 5| Step: 8
Training loss: 2.970411458140413
Validation loss: 2.573405012504001

Epoch: 5| Step: 9
Training loss: 2.7922702155859027
Validation loss: 2.5581727245801202

Epoch: 5| Step: 10
Training loss: 2.7069950514185543
Validation loss: 2.5486442650790258

Epoch: 423| Step: 0
Training loss: 2.976891526987866
Validation loss: 2.546586199039309

Epoch: 5| Step: 1
Training loss: 2.944743377178066
Validation loss: 2.5359163022053983

Epoch: 5| Step: 2
Training loss: 2.603252331755281
Validation loss: 2.5408756316885452

Epoch: 5| Step: 3
Training loss: 2.459377799705065
Validation loss: 2.5419102976804027

Epoch: 5| Step: 4
Training loss: 2.923400317576962
Validation loss: 2.53957518898687

Epoch: 5| Step: 5
Training loss: 2.464816859562609
Validation loss: 2.54141451026777

Epoch: 5| Step: 6
Training loss: 2.8454152356306768
Validation loss: 2.528848368356806

Epoch: 5| Step: 7
Training loss: 2.6264131466113847
Validation loss: 2.5218424562458

Epoch: 5| Step: 8
Training loss: 2.8232580637741083
Validation loss: 2.5223383555382264

Epoch: 5| Step: 9
Training loss: 2.8177384652849415
Validation loss: 2.5230881862467482

Epoch: 5| Step: 10
Training loss: 2.920423177598562
Validation loss: 2.532411807746145

Epoch: 424| Step: 0
Training loss: 3.270559862371348
Validation loss: 2.549066892460351

Epoch: 5| Step: 1
Training loss: 2.573345956754935
Validation loss: 2.5725919224551075

Epoch: 5| Step: 2
Training loss: 3.566547303267247
Validation loss: 2.5540793891390554

Epoch: 5| Step: 3
Training loss: 3.206652378465486
Validation loss: 2.5511524068791207

Epoch: 5| Step: 4
Training loss: 2.3009953293999557
Validation loss: 2.545523879935831

Epoch: 5| Step: 5
Training loss: 2.250656138222974
Validation loss: 2.5347480975636034

Epoch: 5| Step: 6
Training loss: 2.456702181517551
Validation loss: 2.5272890469116667

Epoch: 5| Step: 7
Training loss: 2.854883554091458
Validation loss: 2.528694869563419

Epoch: 5| Step: 8
Training loss: 2.3792904698572666
Validation loss: 2.524858071890898

Epoch: 5| Step: 9
Training loss: 2.3241627405935206
Validation loss: 2.529006881708981

Epoch: 5| Step: 10
Training loss: 2.792424587778545
Validation loss: 2.534348466525718

Epoch: 425| Step: 0
Training loss: 2.7541533230810833
Validation loss: 2.5449036810902057

Epoch: 5| Step: 1
Training loss: 2.259604089711831
Validation loss: 2.5432979302067156

Epoch: 5| Step: 2
Training loss: 2.5350521401304413
Validation loss: 2.5585210513517542

Epoch: 5| Step: 3
Training loss: 2.561928103758121
Validation loss: 2.542913086554172

Epoch: 5| Step: 4
Training loss: 2.777837052242672
Validation loss: 2.550748797008306

Epoch: 5| Step: 5
Training loss: 3.2110638744424738
Validation loss: 2.5528045746829204

Epoch: 5| Step: 6
Training loss: 2.2995230014261945
Validation loss: 2.55014085374606

Epoch: 5| Step: 7
Training loss: 3.190152579219171
Validation loss: 2.5446766144659403

Epoch: 5| Step: 8
Training loss: 2.7475348607664123
Validation loss: 2.544444159386994

Epoch: 5| Step: 9
Training loss: 3.008887319375021
Validation loss: 2.531358257507147

Epoch: 5| Step: 10
Training loss: 2.8561591737024923
Validation loss: 2.5477587290722075

Epoch: 426| Step: 0
Training loss: 2.705962439361656
Validation loss: 2.5450381664799933

Epoch: 5| Step: 1
Training loss: 2.8749618527742635
Validation loss: 2.536446860494392

Epoch: 5| Step: 2
Training loss: 2.588698005688292
Validation loss: 2.542215104209772

Epoch: 5| Step: 3
Training loss: 2.753283967398397
Validation loss: 2.5358721867418703

Epoch: 5| Step: 4
Training loss: 2.5162201171555947
Validation loss: 2.551923302728284

Epoch: 5| Step: 5
Training loss: 2.8160814158797036
Validation loss: 2.5756157241757256

Epoch: 5| Step: 6
Training loss: 2.2262264600448467
Validation loss: 2.574065641186736

Epoch: 5| Step: 7
Training loss: 2.898710911443243
Validation loss: 2.5531943626157823

Epoch: 5| Step: 8
Training loss: 2.987636521543958
Validation loss: 2.5554707858486823

Epoch: 5| Step: 9
Training loss: 3.1480252206608816
Validation loss: 2.5443067014200924

Epoch: 5| Step: 10
Training loss: 2.7037759338912863
Validation loss: 2.5349723025770343

Epoch: 427| Step: 0
Training loss: 3.066291486208308
Validation loss: 2.517635199863903

Epoch: 5| Step: 1
Training loss: 2.504357355339814
Validation loss: 2.52402246572246

Epoch: 5| Step: 2
Training loss: 2.5640983248944575
Validation loss: 2.50976388237814

Epoch: 5| Step: 3
Training loss: 2.831144459759404
Validation loss: 2.5161121436599565

Epoch: 5| Step: 4
Training loss: 2.5873183513772116
Validation loss: 2.5135793794706918

Epoch: 5| Step: 5
Training loss: 3.096909884074466
Validation loss: 2.5275160699726653

Epoch: 5| Step: 6
Training loss: 2.6855687143998352
Validation loss: 2.551436424678534

Epoch: 5| Step: 7
Training loss: 2.7320197725041293
Validation loss: 2.540536788383606

Epoch: 5| Step: 8
Training loss: 2.793741271412845
Validation loss: 2.5582002832109585

Epoch: 5| Step: 9
Training loss: 2.592546114681567
Validation loss: 2.571626350040497

Epoch: 5| Step: 10
Training loss: 2.9290505492490486
Validation loss: 2.5843745312312922

Epoch: 428| Step: 0
Training loss: 2.4928159489392
Validation loss: 2.5709480671554332

Epoch: 5| Step: 1
Training loss: 2.9715421696841084
Validation loss: 2.5437524586347426

Epoch: 5| Step: 2
Training loss: 2.4093365380449345
Validation loss: 2.5404378064351776

Epoch: 5| Step: 3
Training loss: 3.2549642649386845
Validation loss: 2.523072399478223

Epoch: 5| Step: 4
Training loss: 3.067897788621822
Validation loss: 2.5133494267775736

Epoch: 5| Step: 5
Training loss: 3.057273453111784
Validation loss: 2.5119241916151296

Epoch: 5| Step: 6
Training loss: 2.6011476844708805
Validation loss: 2.5198674749577488

Epoch: 5| Step: 7
Training loss: 2.573387000046448
Validation loss: 2.5147749460067463

Epoch: 5| Step: 8
Training loss: 2.86799763971761
Validation loss: 2.539296910624684

Epoch: 5| Step: 9
Training loss: 2.7273999870837935
Validation loss: 2.5424630322708412

Epoch: 5| Step: 10
Training loss: 2.1153263484159446
Validation loss: 2.552091167974511

Epoch: 429| Step: 0
Training loss: 2.6238119070628936
Validation loss: 2.5810127818104465

Epoch: 5| Step: 1
Training loss: 2.364945057720707
Validation loss: 2.5920063112254366

Epoch: 5| Step: 2
Training loss: 3.118078730628518
Validation loss: 2.63542851815815

Epoch: 5| Step: 3
Training loss: 2.5676042846479916
Validation loss: 2.66909526848851

Epoch: 5| Step: 4
Training loss: 3.3172015527184087
Validation loss: 2.6632549248021333

Epoch: 5| Step: 5
Training loss: 2.661508717716322
Validation loss: 2.589338256837889

Epoch: 5| Step: 6
Training loss: 2.9970566297748924
Validation loss: 2.538534582392607

Epoch: 5| Step: 7
Training loss: 2.4619660665186287
Validation loss: 2.5209749077466834

Epoch: 5| Step: 8
Training loss: 2.724912652531861
Validation loss: 2.5118614869031517

Epoch: 5| Step: 9
Training loss: 2.877429764699957
Validation loss: 2.5201928764086627

Epoch: 5| Step: 10
Training loss: 2.9168978644881394
Validation loss: 2.53506918515171

Epoch: 430| Step: 0
Training loss: 2.6536931915599515
Validation loss: 2.565751185481687

Epoch: 5| Step: 1
Training loss: 2.2412407235221132
Validation loss: 2.5417669667492513

Epoch: 5| Step: 2
Training loss: 3.270415811961819
Validation loss: 2.5382822639901317

Epoch: 5| Step: 3
Training loss: 3.2943606076679726
Validation loss: 2.5268032778418426

Epoch: 5| Step: 4
Training loss: 2.9514071195949403
Validation loss: 2.5150326644373604

Epoch: 5| Step: 5
Training loss: 3.121303966637732
Validation loss: 2.50568448012194

Epoch: 5| Step: 6
Training loss: 2.6935821728745513
Validation loss: 2.506415993049682

Epoch: 5| Step: 7
Training loss: 2.3681958760749704
Validation loss: 2.5264010699012736

Epoch: 5| Step: 8
Training loss: 2.8314689972581517
Validation loss: 2.538349173960074

Epoch: 5| Step: 9
Training loss: 2.4288153846409277
Validation loss: 2.5609526585785836

Epoch: 5| Step: 10
Training loss: 2.9310483493051347
Validation loss: 2.5813434318841404

Epoch: 431| Step: 0
Training loss: 2.9536321295403107
Validation loss: 2.5972976894782924

Epoch: 5| Step: 1
Training loss: 2.56927014581648
Validation loss: 2.617589750617493

Epoch: 5| Step: 2
Training loss: 2.77447464583735
Validation loss: 2.6205661652830714

Epoch: 5| Step: 3
Training loss: 2.830861490637577
Validation loss: 2.6317614264818006

Epoch: 5| Step: 4
Training loss: 2.8324396930681797
Validation loss: 2.5830275562684886

Epoch: 5| Step: 5
Training loss: 2.7460537252317425
Validation loss: 2.551243004605787

Epoch: 5| Step: 6
Training loss: 2.5404978289806066
Validation loss: 2.5118860162167747

Epoch: 5| Step: 7
Training loss: 2.9377227049471686
Validation loss: 2.498012673691154

Epoch: 5| Step: 8
Training loss: 2.49245276877937
Validation loss: 2.4967143166000385

Epoch: 5| Step: 9
Training loss: 3.1793506640730276
Validation loss: 2.495935307454573

Epoch: 5| Step: 10
Training loss: 2.7109663464333416
Validation loss: 2.5019264827842043

Epoch: 432| Step: 0
Training loss: 2.549256878449918
Validation loss: 2.507222007910142

Epoch: 5| Step: 1
Training loss: 2.507805464785206
Validation loss: 2.5105248241862514

Epoch: 5| Step: 2
Training loss: 2.5509173370091602
Validation loss: 2.516013541738189

Epoch: 5| Step: 3
Training loss: 3.23354723376862
Validation loss: 2.5168542336969995

Epoch: 5| Step: 4
Training loss: 1.9946713988168108
Validation loss: 2.5381147808519673

Epoch: 5| Step: 5
Training loss: 2.898274131756701
Validation loss: 2.5524053842955077

Epoch: 5| Step: 6
Training loss: 2.755696465579345
Validation loss: 2.5552495582919432

Epoch: 5| Step: 7
Training loss: 3.305458357706055
Validation loss: 2.559982882344406

Epoch: 5| Step: 8
Training loss: 2.55227509900476
Validation loss: 2.5508484220593335

Epoch: 5| Step: 9
Training loss: 3.115918658927138
Validation loss: 2.5329456966885324

Epoch: 5| Step: 10
Training loss: 2.988148645188962
Validation loss: 2.528916734268354

Epoch: 433| Step: 0
Training loss: 2.869052041635834
Validation loss: 2.5286507416627853

Epoch: 5| Step: 1
Training loss: 2.538491522338488
Validation loss: 2.520555757721969

Epoch: 5| Step: 2
Training loss: 3.1577499904419652
Validation loss: 2.517634788481467

Epoch: 5| Step: 3
Training loss: 2.595306480993265
Validation loss: 2.529847599617636

Epoch: 5| Step: 4
Training loss: 2.48570772328317
Validation loss: 2.5169484061124616

Epoch: 5| Step: 5
Training loss: 2.223837272213809
Validation loss: 2.527018026606355

Epoch: 5| Step: 6
Training loss: 2.6492641362965657
Validation loss: 2.5235747100629444

Epoch: 5| Step: 7
Training loss: 3.2966866823623135
Validation loss: 2.5408513338094174

Epoch: 5| Step: 8
Training loss: 2.5095058915334536
Validation loss: 2.5405392334173875

Epoch: 5| Step: 9
Training loss: 3.010121912974496
Validation loss: 2.5542102107077933

Epoch: 5| Step: 10
Training loss: 2.7598888156444343
Validation loss: 2.5388793636943454

Epoch: 434| Step: 0
Training loss: 2.6731931769841495
Validation loss: 2.532634258869346

Epoch: 5| Step: 1
Training loss: 2.6598151124072404
Validation loss: 2.5148726627280253

Epoch: 5| Step: 2
Training loss: 2.639363997895139
Validation loss: 2.5137495538878376

Epoch: 5| Step: 3
Training loss: 2.656502745328433
Validation loss: 2.514412729183955

Epoch: 5| Step: 4
Training loss: 2.8589999260383694
Validation loss: 2.5079680537587676

Epoch: 5| Step: 5
Training loss: 3.074339111763875
Validation loss: 2.5083039246018233

Epoch: 5| Step: 6
Training loss: 2.532591946769466
Validation loss: 2.5085542527650433

Epoch: 5| Step: 7
Training loss: 1.9827646645020618
Validation loss: 2.520552654568083

Epoch: 5| Step: 8
Training loss: 3.171231810653301
Validation loss: 2.513575498686091

Epoch: 5| Step: 9
Training loss: 2.8750623613311364
Validation loss: 2.5205863120397267

Epoch: 5| Step: 10
Training loss: 3.057732588747674
Validation loss: 2.5338375144670744

Epoch: 435| Step: 0
Training loss: 2.0721811750140287
Validation loss: 2.5122868672338785

Epoch: 5| Step: 1
Training loss: 2.943481037787064
Validation loss: 2.524093209003878

Epoch: 5| Step: 2
Training loss: 2.800393901093512
Validation loss: 2.509512531741847

Epoch: 5| Step: 3
Training loss: 2.7292790474697743
Validation loss: 2.5177322486007947

Epoch: 5| Step: 4
Training loss: 2.750312614011811
Validation loss: 2.5106009778757667

Epoch: 5| Step: 5
Training loss: 2.426481628052864
Validation loss: 2.521883256131747

Epoch: 5| Step: 6
Training loss: 2.429984414949399
Validation loss: 2.5237735042149887

Epoch: 5| Step: 7
Training loss: 2.5501595129348975
Validation loss: 2.538660600405492

Epoch: 5| Step: 8
Training loss: 3.0136407045840223
Validation loss: 2.550542398780259

Epoch: 5| Step: 9
Training loss: 3.338047477023403
Validation loss: 2.565712105856628

Epoch: 5| Step: 10
Training loss: 2.887098646137554
Validation loss: 2.589370807348886

Epoch: 436| Step: 0
Training loss: 2.4507707123169613
Validation loss: 2.5709792490844583

Epoch: 5| Step: 1
Training loss: 2.775695483372114
Validation loss: 2.600158087654819

Epoch: 5| Step: 2
Training loss: 2.40074638045933
Validation loss: 2.590549311821213

Epoch: 5| Step: 3
Training loss: 2.865021680180671
Validation loss: 2.5904143770822197

Epoch: 5| Step: 4
Training loss: 3.300788473087511
Validation loss: 2.587289807845599

Epoch: 5| Step: 5
Training loss: 2.604397989807384
Validation loss: 2.5489812672697107

Epoch: 5| Step: 6
Training loss: 2.567594906130978
Validation loss: 2.5341694558996686

Epoch: 5| Step: 7
Training loss: 2.4700725248245377
Validation loss: 2.540270551196554

Epoch: 5| Step: 8
Training loss: 2.964902130879014
Validation loss: 2.526186339727692

Epoch: 5| Step: 9
Training loss: 2.6311103910618447
Validation loss: 2.5272567933639802

Epoch: 5| Step: 10
Training loss: 3.0808293424922186
Validation loss: 2.5331342675467026

Epoch: 437| Step: 0
Training loss: 2.633320835743796
Validation loss: 2.5147681570939318

Epoch: 5| Step: 1
Training loss: 3.097279702543206
Validation loss: 2.527721725642335

Epoch: 5| Step: 2
Training loss: 2.8786836328446745
Validation loss: 2.5135491142915494

Epoch: 5| Step: 3
Training loss: 2.6955547721447934
Validation loss: 2.5125138602121657

Epoch: 5| Step: 4
Training loss: 2.4809510250277866
Validation loss: 2.5161771062068863

Epoch: 5| Step: 5
Training loss: 2.8756437824765935
Validation loss: 2.5200252063064847

Epoch: 5| Step: 6
Training loss: 2.399427278052993
Validation loss: 2.533895397724515

Epoch: 5| Step: 7
Training loss: 1.994147619222094
Validation loss: 2.5340723426629346

Epoch: 5| Step: 8
Training loss: 3.1586321914979263
Validation loss: 2.5752065866610327

Epoch: 5| Step: 9
Training loss: 2.91744512432827
Validation loss: 2.5548748504479413

Epoch: 5| Step: 10
Training loss: 2.7829881016171587
Validation loss: 2.57308447432879

Epoch: 438| Step: 0
Training loss: 3.0101282494176047
Validation loss: 2.5515502480076466

Epoch: 5| Step: 1
Training loss: 2.5245666811941034
Validation loss: 2.5246999740740734

Epoch: 5| Step: 2
Training loss: 3.4167221499024163
Validation loss: 2.528142939625513

Epoch: 5| Step: 3
Training loss: 2.3170187849486004
Validation loss: 2.5122440348763386

Epoch: 5| Step: 4
Training loss: 2.1051945835163437
Validation loss: 2.518036343137203

Epoch: 5| Step: 5
Training loss: 2.7275311954438104
Validation loss: 2.513378438744223

Epoch: 5| Step: 6
Training loss: 2.949227804207956
Validation loss: 2.521856807186632

Epoch: 5| Step: 7
Training loss: 3.1649879891648274
Validation loss: 2.5422517350892835

Epoch: 5| Step: 8
Training loss: 2.412402227130179
Validation loss: 2.5399726795005892

Epoch: 5| Step: 9
Training loss: 2.4725328266984774
Validation loss: 2.542994816050773

Epoch: 5| Step: 10
Training loss: 2.769791648685895
Validation loss: 2.5576276791293284

Epoch: 439| Step: 0
Training loss: 3.025480147158399
Validation loss: 2.5542565959174675

Epoch: 5| Step: 1
Training loss: 2.847169936612358
Validation loss: 2.5434583712998946

Epoch: 5| Step: 2
Training loss: 2.6969601225431368
Validation loss: 2.5463446729267254

Epoch: 5| Step: 3
Training loss: 2.402611098881436
Validation loss: 2.5562228527343023

Epoch: 5| Step: 4
Training loss: 2.8084642913650875
Validation loss: 2.5523541040450106

Epoch: 5| Step: 5
Training loss: 3.3698071691204623
Validation loss: 2.56127483413554

Epoch: 5| Step: 6
Training loss: 2.3884265240281417
Validation loss: 2.5366522312350517

Epoch: 5| Step: 7
Training loss: 2.318642063147801
Validation loss: 2.5230193138774806

Epoch: 5| Step: 8
Training loss: 2.8107337491893087
Validation loss: 2.5426449768134423

Epoch: 5| Step: 9
Training loss: 2.520806514712928
Validation loss: 2.544494830308812

Epoch: 5| Step: 10
Training loss: 2.625788888009337
Validation loss: 2.557689255315265

Epoch: 440| Step: 0
Training loss: 2.6087806618702247
Validation loss: 2.5576159721441507

Epoch: 5| Step: 1
Training loss: 2.713629186076754
Validation loss: 2.5587123337060245

Epoch: 5| Step: 2
Training loss: 2.4876506012226534
Validation loss: 2.570761299716325

Epoch: 5| Step: 3
Training loss: 2.942324633043713
Validation loss: 2.550188044813438

Epoch: 5| Step: 4
Training loss: 2.7203716834749696
Validation loss: 2.549821389586621

Epoch: 5| Step: 5
Training loss: 2.9846966155748436
Validation loss: 2.546164364107041

Epoch: 5| Step: 6
Training loss: 2.664910324191083
Validation loss: 2.5679441406690486

Epoch: 5| Step: 7
Training loss: 2.5170806085396777
Validation loss: 2.5834036674279703

Epoch: 5| Step: 8
Training loss: 2.8293504957684674
Validation loss: 2.5596491083942543

Epoch: 5| Step: 9
Training loss: 2.816839811732889
Validation loss: 2.5597053593585346

Epoch: 5| Step: 10
Training loss: 2.7428189064238784
Validation loss: 2.518364414161113

Epoch: 441| Step: 0
Training loss: 3.0063755318491028
Validation loss: 2.520221516634035

Epoch: 5| Step: 1
Training loss: 2.8185389640622773
Validation loss: 2.5042136542762266

Epoch: 5| Step: 2
Training loss: 2.3719624620075876
Validation loss: 2.496423484654032

Epoch: 5| Step: 3
Training loss: 2.8528237257933093
Validation loss: 2.4980827301453234

Epoch: 5| Step: 4
Training loss: 2.7716144426403075
Validation loss: 2.501708874085661

Epoch: 5| Step: 5
Training loss: 2.720795223870778
Validation loss: 2.502340822644999

Epoch: 5| Step: 6
Training loss: 3.183338365667337
Validation loss: 2.504830691370557

Epoch: 5| Step: 7
Training loss: 2.196764591313147
Validation loss: 2.5069668836372156

Epoch: 5| Step: 8
Training loss: 2.781434470927628
Validation loss: 2.5170354398014876

Epoch: 5| Step: 9
Training loss: 3.008105137448546
Validation loss: 2.530291001038991

Epoch: 5| Step: 10
Training loss: 2.429131447311543
Validation loss: 2.5589615867491284

Epoch: 442| Step: 0
Training loss: 3.2047284834615803
Validation loss: 2.560246167474915

Epoch: 5| Step: 1
Training loss: 2.529652032255993
Validation loss: 2.544338491974402

Epoch: 5| Step: 2
Training loss: 2.568569531563544
Validation loss: 2.570397574183189

Epoch: 5| Step: 3
Training loss: 2.846028515520747
Validation loss: 2.5646565084744855

Epoch: 5| Step: 4
Training loss: 2.7426359239276112
Validation loss: 2.5446937683006263

Epoch: 5| Step: 5
Training loss: 2.8164635598202166
Validation loss: 2.5321090802159136

Epoch: 5| Step: 6
Training loss: 2.9404603366781106
Validation loss: 2.527260736320392

Epoch: 5| Step: 7
Training loss: 1.9689224409847335
Validation loss: 2.5348403091407765

Epoch: 5| Step: 8
Training loss: 2.632266749294402
Validation loss: 2.5340019447470774

Epoch: 5| Step: 9
Training loss: 2.564523502729313
Validation loss: 2.5440842692778527

Epoch: 5| Step: 10
Training loss: 2.95394530836755
Validation loss: 2.532584955082418

Epoch: 443| Step: 0
Training loss: 3.103622405878177
Validation loss: 2.5434200594031657

Epoch: 5| Step: 1
Training loss: 2.9703172261272237
Validation loss: 2.536258263517961

Epoch: 5| Step: 2
Training loss: 2.463452800629177
Validation loss: 2.553804606595415

Epoch: 5| Step: 3
Training loss: 2.7365370567875353
Validation loss: 2.5511015606885157

Epoch: 5| Step: 4
Training loss: 2.738472272057298
Validation loss: 2.5590047471603747

Epoch: 5| Step: 5
Training loss: 2.236598688941209
Validation loss: 2.5610413880759553

Epoch: 5| Step: 6
Training loss: 2.6351936959694444
Validation loss: 2.5621084228711175

Epoch: 5| Step: 7
Training loss: 2.5706530869997164
Validation loss: 2.5520726223574983

Epoch: 5| Step: 8
Training loss: 2.830234815473404
Validation loss: 2.5410692325445354

Epoch: 5| Step: 9
Training loss: 2.739233006655731
Validation loss: 2.538290388339642

Epoch: 5| Step: 10
Training loss: 2.84893811838811
Validation loss: 2.5258622584788046

Epoch: 444| Step: 0
Training loss: 2.839977738736442
Validation loss: 2.5228448505398684

Epoch: 5| Step: 1
Training loss: 2.803483369813664
Validation loss: 2.5363339215082776

Epoch: 5| Step: 2
Training loss: 2.44295946686106
Validation loss: 2.5262144259075177

Epoch: 5| Step: 3
Training loss: 2.336962012736752
Validation loss: 2.5120769608850244

Epoch: 5| Step: 4
Training loss: 2.323097894780879
Validation loss: 2.5226766372049076

Epoch: 5| Step: 5
Training loss: 2.85180161401152
Validation loss: 2.5168529151328856

Epoch: 5| Step: 6
Training loss: 2.9135366993274063
Validation loss: 2.5240892418016543

Epoch: 5| Step: 7
Training loss: 2.860271709313406
Validation loss: 2.532079678419257

Epoch: 5| Step: 8
Training loss: 2.6783447460349987
Validation loss: 2.531206100976487

Epoch: 5| Step: 9
Training loss: 2.8668779834958826
Validation loss: 2.543692401017088

Epoch: 5| Step: 10
Training loss: 2.837838032623049
Validation loss: 2.555159397600673

Epoch: 445| Step: 0
Training loss: 2.6788455096300967
Validation loss: 2.5913797512983194

Epoch: 5| Step: 1
Training loss: 2.800981969304802
Validation loss: 2.573254893879562

Epoch: 5| Step: 2
Training loss: 2.7725169198678246
Validation loss: 2.552405607272704

Epoch: 5| Step: 3
Training loss: 2.534978875066554
Validation loss: 2.55961933486469

Epoch: 5| Step: 4
Training loss: 2.827852014675934
Validation loss: 2.5497264178847012

Epoch: 5| Step: 5
Training loss: 3.2720501493047793
Validation loss: 2.5279835699443027

Epoch: 5| Step: 6
Training loss: 2.4948020303042395
Validation loss: 2.522144195107506

Epoch: 5| Step: 7
Training loss: 2.7215213900693898
Validation loss: 2.511842015556556

Epoch: 5| Step: 8
Training loss: 2.1745994549828747
Validation loss: 2.51506170693382

Epoch: 5| Step: 9
Training loss: 2.5935648656749226
Validation loss: 2.522023212972144

Epoch: 5| Step: 10
Training loss: 2.930939673811284
Validation loss: 2.537924560797179

Epoch: 446| Step: 0
Training loss: 2.2590254854923626
Validation loss: 2.5359045935561966

Epoch: 5| Step: 1
Training loss: 3.002089726275578
Validation loss: 2.5234462817

Epoch: 5| Step: 2
Training loss: 2.7109220212994702
Validation loss: 2.5389819939079263

Epoch: 5| Step: 3
Training loss: 2.758098987255268
Validation loss: 2.5490053176815723

Epoch: 5| Step: 4
Training loss: 3.26791287091017
Validation loss: 2.536083662651767

Epoch: 5| Step: 5
Training loss: 2.96241727303031
Validation loss: 2.55348152264711

Epoch: 5| Step: 6
Training loss: 2.6929672874223165
Validation loss: 2.559083815922841

Epoch: 5| Step: 7
Training loss: 2.32621820181094
Validation loss: 2.5538618184642337

Epoch: 5| Step: 8
Training loss: 2.4668826030172357
Validation loss: 2.5725694358713405

Epoch: 5| Step: 9
Training loss: 2.2274999953761245
Validation loss: 2.5625286966073135

Epoch: 5| Step: 10
Training loss: 2.8454497570803037
Validation loss: 2.5671757074481842

Epoch: 447| Step: 0
Training loss: 2.6920149381996814
Validation loss: 2.5441202887945487

Epoch: 5| Step: 1
Training loss: 2.5348656345248783
Validation loss: 2.532067376946421

Epoch: 5| Step: 2
Training loss: 2.6860813566144652
Validation loss: 2.5236282441630924

Epoch: 5| Step: 3
Training loss: 2.564744478106167
Validation loss: 2.5308897156258974

Epoch: 5| Step: 4
Training loss: 2.72996522902259
Validation loss: 2.5221689273168

Epoch: 5| Step: 5
Training loss: 2.9386759899819985
Validation loss: 2.5212714030637073

Epoch: 5| Step: 6
Training loss: 2.9260289656482383
Validation loss: 2.5331600912085914

Epoch: 5| Step: 7
Training loss: 2.667003630170436
Validation loss: 2.536482751455927

Epoch: 5| Step: 8
Training loss: 2.8759783863003556
Validation loss: 2.5330059827963027

Epoch: 5| Step: 9
Training loss: 2.416863060786843
Validation loss: 2.520847092376262

Epoch: 5| Step: 10
Training loss: 2.6521809546240536
Validation loss: 2.5249686208842537

Epoch: 448| Step: 0
Training loss: 2.5209490431614348
Validation loss: 2.5114257858027274

Epoch: 5| Step: 1
Training loss: 2.6484017608841834
Validation loss: 2.5257434377567125

Epoch: 5| Step: 2
Training loss: 2.874398044096496
Validation loss: 2.538313387662468

Epoch: 5| Step: 3
Training loss: 2.68605517206742
Validation loss: 2.545168137288679

Epoch: 5| Step: 4
Training loss: 2.652356154759744
Validation loss: 2.5282815826099494

Epoch: 5| Step: 5
Training loss: 2.6266520614831164
Validation loss: 2.516297125447109

Epoch: 5| Step: 6
Training loss: 2.818284000015334
Validation loss: 2.5090170922764448

Epoch: 5| Step: 7
Training loss: 3.031133433194841
Validation loss: 2.516009336612275

Epoch: 5| Step: 8
Training loss: 3.1234183314213744
Validation loss: 2.513056067125641

Epoch: 5| Step: 9
Training loss: 2.5653923272998127
Validation loss: 2.5248462997762

Epoch: 5| Step: 10
Training loss: 2.0572807858980133
Validation loss: 2.5394678178221577

Epoch: 449| Step: 0
Training loss: 2.5795608683512494
Validation loss: 2.558190323054967

Epoch: 5| Step: 1
Training loss: 2.724375024923739
Validation loss: 2.589960862313521

Epoch: 5| Step: 2
Training loss: 2.6300015711326403
Validation loss: 2.6038074394949846

Epoch: 5| Step: 3
Training loss: 2.5641112495544247
Validation loss: 2.626352387617305

Epoch: 5| Step: 4
Training loss: 3.0957912300159633
Validation loss: 2.612188601463296

Epoch: 5| Step: 5
Training loss: 2.645068250759889
Validation loss: 2.6143312377221317

Epoch: 5| Step: 6
Training loss: 2.4945887175791217
Validation loss: 2.579388487045277

Epoch: 5| Step: 7
Training loss: 3.0266047800209726
Validation loss: 2.552695596735914

Epoch: 5| Step: 8
Training loss: 2.9099725652496056
Validation loss: 2.5231324256575287

Epoch: 5| Step: 9
Training loss: 2.400914407420692
Validation loss: 2.5121186255672305

Epoch: 5| Step: 10
Training loss: 2.6040997204122807
Validation loss: 2.501868099671116

Epoch: 450| Step: 0
Training loss: 2.7584860522201247
Validation loss: 2.5040798398724915

Epoch: 5| Step: 1
Training loss: 2.5539530126958776
Validation loss: 2.495830376086939

Epoch: 5| Step: 2
Training loss: 2.7363282992616824
Validation loss: 2.500136296853573

Epoch: 5| Step: 3
Training loss: 3.2221368544513247
Validation loss: 2.5077919861908375

Epoch: 5| Step: 4
Training loss: 2.678662785379963
Validation loss: 2.4933228281819892

Epoch: 5| Step: 5
Training loss: 2.6919970479895174
Validation loss: 2.5233773744024237

Epoch: 5| Step: 6
Training loss: 2.3453989967290045
Validation loss: 2.530337430606919

Epoch: 5| Step: 7
Training loss: 2.910049743751539
Validation loss: 2.5640055527785566

Epoch: 5| Step: 8
Training loss: 2.4197023552319488
Validation loss: 2.5567855145259033

Epoch: 5| Step: 9
Training loss: 2.900030228029758
Validation loss: 2.5675188882571947

Epoch: 5| Step: 10
Training loss: 2.6017382679807906
Validation loss: 2.5582048979999397

Epoch: 451| Step: 0
Training loss: 2.8105925131479625
Validation loss: 2.547657552279425

Epoch: 5| Step: 1
Training loss: 3.412699901049611
Validation loss: 2.5530756210199312

Epoch: 5| Step: 2
Training loss: 2.00868319027031
Validation loss: 2.552786910960602

Epoch: 5| Step: 3
Training loss: 2.4620773339974487
Validation loss: 2.5419654455402916

Epoch: 5| Step: 4
Training loss: 2.4691022790587525
Validation loss: 2.547890184073481

Epoch: 5| Step: 5
Training loss: 3.1667848531519067
Validation loss: 2.543440529780426

Epoch: 5| Step: 6
Training loss: 2.4748982032880025
Validation loss: 2.5431354396811043

Epoch: 5| Step: 7
Training loss: 3.1244249959273755
Validation loss: 2.524345630500425

Epoch: 5| Step: 8
Training loss: 2.5815449543832205
Validation loss: 2.5194197460651613

Epoch: 5| Step: 9
Training loss: 2.554060552818707
Validation loss: 2.505403585557407

Epoch: 5| Step: 10
Training loss: 2.218238019302329
Validation loss: 2.5016286897596567

Epoch: 452| Step: 0
Training loss: 3.1010461949238612
Validation loss: 2.501071389643242

Epoch: 5| Step: 1
Training loss: 3.0219972319473527
Validation loss: 2.5038727604544864

Epoch: 5| Step: 2
Training loss: 2.644932230494054
Validation loss: 2.514283136423875

Epoch: 5| Step: 3
Training loss: 2.2390855339446754
Validation loss: 2.5254820616213243

Epoch: 5| Step: 4
Training loss: 2.6957155672633903
Validation loss: 2.542508781788112

Epoch: 5| Step: 5
Training loss: 2.8938227930656044
Validation loss: 2.556972696212341

Epoch: 5| Step: 6
Training loss: 3.0172630170224806
Validation loss: 2.5927155882370756

Epoch: 5| Step: 7
Training loss: 2.5743021973208786
Validation loss: 2.576579052355489

Epoch: 5| Step: 8
Training loss: 2.248767727267254
Validation loss: 2.580791373590836

Epoch: 5| Step: 9
Training loss: 2.6810243347099414
Validation loss: 2.544988744383528

Epoch: 5| Step: 10
Training loss: 2.509667966849999
Validation loss: 2.5569310224817134

Epoch: 453| Step: 0
Training loss: 3.08947443050997
Validation loss: 2.546815313971949

Epoch: 5| Step: 1
Training loss: 2.6852386186722743
Validation loss: 2.525195496215054

Epoch: 5| Step: 2
Training loss: 2.375601240649962
Validation loss: 2.5222463516315434

Epoch: 5| Step: 3
Training loss: 2.9014753272088765
Validation loss: 2.506012185606072

Epoch: 5| Step: 4
Training loss: 3.0954494239989843
Validation loss: 2.5120508005773368

Epoch: 5| Step: 5
Training loss: 2.805616134728124
Validation loss: 2.5063077250449455

Epoch: 5| Step: 6
Training loss: 2.8898763151002065
Validation loss: 2.517875776814046

Epoch: 5| Step: 7
Training loss: 2.629192999835368
Validation loss: 2.5290336441186816

Epoch: 5| Step: 8
Training loss: 2.077207549222072
Validation loss: 2.5429555596054785

Epoch: 5| Step: 9
Training loss: 2.4994615928719415
Validation loss: 2.55202101798173

Epoch: 5| Step: 10
Training loss: 2.467086038079562
Validation loss: 2.5563574822439055

Epoch: 454| Step: 0
Training loss: 2.7775181797369988
Validation loss: 2.5767629247773183

Epoch: 5| Step: 1
Training loss: 2.856004072490962
Validation loss: 2.5866292502819244

Epoch: 5| Step: 2
Training loss: 2.484345345949938
Validation loss: 2.5727888562708703

Epoch: 5| Step: 3
Training loss: 2.880007487923107
Validation loss: 2.5688839537690034

Epoch: 5| Step: 4
Training loss: 2.2619803743463875
Validation loss: 2.55057044743392

Epoch: 5| Step: 5
Training loss: 2.84454703427456
Validation loss: 2.5428427499033504

Epoch: 5| Step: 6
Training loss: 2.389462157028612
Validation loss: 2.5205224344704984

Epoch: 5| Step: 7
Training loss: 2.7424411058665834
Validation loss: 2.5129707757774997

Epoch: 5| Step: 8
Training loss: 2.801106496571142
Validation loss: 2.5135129647021404

Epoch: 5| Step: 9
Training loss: 2.6593026963837065
Validation loss: 2.511445989215329

Epoch: 5| Step: 10
Training loss: 3.021428823422747
Validation loss: 2.497159626161351

Epoch: 455| Step: 0
Training loss: 2.571204033766682
Validation loss: 2.517169390430876

Epoch: 5| Step: 1
Training loss: 2.7537642638485975
Validation loss: 2.5213039639906523

Epoch: 5| Step: 2
Training loss: 3.0434522917924953
Validation loss: 2.529841218495926

Epoch: 5| Step: 3
Training loss: 2.540462166798604
Validation loss: 2.5434474291343303

Epoch: 5| Step: 4
Training loss: 2.8170614763403217
Validation loss: 2.555152531877754

Epoch: 5| Step: 5
Training loss: 3.0255750251461433
Validation loss: 2.563920426482402

Epoch: 5| Step: 6
Training loss: 2.89922410516802
Validation loss: 2.5702396710026956

Epoch: 5| Step: 7
Training loss: 2.0509284266384937
Validation loss: 2.5304977786074394

Epoch: 5| Step: 8
Training loss: 2.5264373993674103
Validation loss: 2.5301525471956228

Epoch: 5| Step: 9
Training loss: 2.9457805069463308
Validation loss: 2.52077850252334

Epoch: 5| Step: 10
Training loss: 2.134852513170576
Validation loss: 2.5183777985058553

Epoch: 456| Step: 0
Training loss: 3.023403433674359
Validation loss: 2.5156856329052846

Epoch: 5| Step: 1
Training loss: 2.433151082394659
Validation loss: 2.521678201944414

Epoch: 5| Step: 2
Training loss: 3.218502590707611
Validation loss: 2.5365014595717774

Epoch: 5| Step: 3
Training loss: 3.3540345791857935
Validation loss: 2.5642446655913083

Epoch: 5| Step: 4
Training loss: 2.9283646101811045
Validation loss: 2.561915531328813

Epoch: 5| Step: 5
Training loss: 2.3643804342684915
Validation loss: 2.5854826198928973

Epoch: 5| Step: 6
Training loss: 2.330150772586581
Validation loss: 2.640723938049301

Epoch: 5| Step: 7
Training loss: 2.707975236742851
Validation loss: 2.668206336344196

Epoch: 5| Step: 8
Training loss: 2.948344888127185
Validation loss: 2.6342894000315495

Epoch: 5| Step: 9
Training loss: 1.7003961101630172
Validation loss: 2.6032385629646426

Epoch: 5| Step: 10
Training loss: 2.565187672967884
Validation loss: 2.5417890369632294

Epoch: 457| Step: 0
Training loss: 1.9224373219644155
Validation loss: 2.543424674802724

Epoch: 5| Step: 1
Training loss: 2.5403277721830526
Validation loss: 2.529014746953201

Epoch: 5| Step: 2
Training loss: 2.969633432751347
Validation loss: 2.5251315281320434

Epoch: 5| Step: 3
Training loss: 3.2433253486223985
Validation loss: 2.5296738027961507

Epoch: 5| Step: 4
Training loss: 2.50425348834838
Validation loss: 2.511549972155497

Epoch: 5| Step: 5
Training loss: 2.549427181307461
Validation loss: 2.513082346523849

Epoch: 5| Step: 6
Training loss: 2.412542068035603
Validation loss: 2.4929072825498113

Epoch: 5| Step: 7
Training loss: 3.1868587671686806
Validation loss: 2.4954144569686503

Epoch: 5| Step: 8
Training loss: 3.2921932298260086
Validation loss: 2.480270010618733

Epoch: 5| Step: 9
Training loss: 2.290085079161865
Validation loss: 2.4826460575300775

Epoch: 5| Step: 10
Training loss: 2.5367718972106625
Validation loss: 2.5016664549851595

Epoch: 458| Step: 0
Training loss: 2.2897217097537585
Validation loss: 2.5125615661698846

Epoch: 5| Step: 1
Training loss: 2.9219042118672607
Validation loss: 2.526767334108681

Epoch: 5| Step: 2
Training loss: 2.7598684282316617
Validation loss: 2.5414343592768907

Epoch: 5| Step: 3
Training loss: 2.764483544954592
Validation loss: 2.552282597236138

Epoch: 5| Step: 4
Training loss: 2.5369397489184355
Validation loss: 2.556848598434787

Epoch: 5| Step: 5
Training loss: 2.8965533525481133
Validation loss: 2.542489147872368

Epoch: 5| Step: 6
Training loss: 2.6780846253315094
Validation loss: 2.5378057027679177

Epoch: 5| Step: 7
Training loss: 2.9487643870818947
Validation loss: 2.554318997575211

Epoch: 5| Step: 8
Training loss: 2.4428427414561225
Validation loss: 2.546869957015048

Epoch: 5| Step: 9
Training loss: 2.7483029764726234
Validation loss: 2.540039360241068

Epoch: 5| Step: 10
Training loss: 2.7195105530242487
Validation loss: 2.536505552901256

Epoch: 459| Step: 0
Training loss: 2.5918457210626507
Validation loss: 2.5132939243803856

Epoch: 5| Step: 1
Training loss: 2.635170986700937
Validation loss: 2.5120050974558312

Epoch: 5| Step: 2
Training loss: 2.7291568338542205
Validation loss: 2.513862670762928

Epoch: 5| Step: 3
Training loss: 3.1053770807519765
Validation loss: 2.524157949897263

Epoch: 5| Step: 4
Training loss: 2.787078835868733
Validation loss: 2.5267445634937316

Epoch: 5| Step: 5
Training loss: 2.60747289714827
Validation loss: 2.5080427293425034

Epoch: 5| Step: 6
Training loss: 2.3827358546202864
Validation loss: 2.5325614694725664

Epoch: 5| Step: 7
Training loss: 2.874543858706957
Validation loss: 2.527385239587794

Epoch: 5| Step: 8
Training loss: 2.6556649854113736
Validation loss: 2.5434529203817395

Epoch: 5| Step: 9
Training loss: 2.487241902212338
Validation loss: 2.5457105845427446

Epoch: 5| Step: 10
Training loss: 2.522581067327957
Validation loss: 2.535357558820746

Epoch: 460| Step: 0
Training loss: 2.8480323155959293
Validation loss: 2.5451109445442563

Epoch: 5| Step: 1
Training loss: 2.3685628087302533
Validation loss: 2.559682291845332

Epoch: 5| Step: 2
Training loss: 3.2849479545755393
Validation loss: 2.5328277568604722

Epoch: 5| Step: 3
Training loss: 2.6425736138981266
Validation loss: 2.5383955682406034

Epoch: 5| Step: 4
Training loss: 1.981934977152911
Validation loss: 2.5317093120894554

Epoch: 5| Step: 5
Training loss: 2.6005342301468612
Validation loss: 2.524891864886076

Epoch: 5| Step: 6
Training loss: 3.0892040106429617
Validation loss: 2.532026304781269

Epoch: 5| Step: 7
Training loss: 2.8732543289522376
Validation loss: 2.533399972568098

Epoch: 5| Step: 8
Training loss: 2.5912632798969284
Validation loss: 2.511827690068589

Epoch: 5| Step: 9
Training loss: 2.1854308014865027
Validation loss: 2.5199372097027855

Epoch: 5| Step: 10
Training loss: 2.613778059967054
Validation loss: 2.518884728584973

Epoch: 461| Step: 0
Training loss: 2.8095497764391117
Validation loss: 2.524933751651603

Epoch: 5| Step: 1
Training loss: 2.5887953533508132
Validation loss: 2.511823158478013

Epoch: 5| Step: 2
Training loss: 2.6135634197263866
Validation loss: 2.5303532328385314

Epoch: 5| Step: 3
Training loss: 2.938699193439833
Validation loss: 2.525067785850342

Epoch: 5| Step: 4
Training loss: 2.9853900561285864
Validation loss: 2.5295255117319932

Epoch: 5| Step: 5
Training loss: 2.7376754460658668
Validation loss: 2.538532061705969

Epoch: 5| Step: 6
Training loss: 2.5997216295729686
Validation loss: 2.5399792632746303

Epoch: 5| Step: 7
Training loss: 2.6655982281144333
Validation loss: 2.5295196841763645

Epoch: 5| Step: 8
Training loss: 2.279079815908494
Validation loss: 2.526582298023926

Epoch: 5| Step: 9
Training loss: 2.8270527192615513
Validation loss: 2.5258724141143882

Epoch: 5| Step: 10
Training loss: 2.1420125432150314
Validation loss: 2.5266618223428234

Epoch: 462| Step: 0
Training loss: 2.2583452803892814
Validation loss: 2.5344566958701127

Epoch: 5| Step: 1
Training loss: 2.1149444522281766
Validation loss: 2.5427389648319614

Epoch: 5| Step: 2
Training loss: 2.383484192277437
Validation loss: 2.5419119063152644

Epoch: 5| Step: 3
Training loss: 3.1418166295964487
Validation loss: 2.531247213795844

Epoch: 5| Step: 4
Training loss: 2.999143319201149
Validation loss: 2.5699687555481607

Epoch: 5| Step: 5
Training loss: 3.1611693164790666
Validation loss: 2.5723723875900073

Epoch: 5| Step: 6
Training loss: 2.5403630608430747
Validation loss: 2.586496543848998

Epoch: 5| Step: 7
Training loss: 2.5552329318177525
Validation loss: 2.5742175140992853

Epoch: 5| Step: 8
Training loss: 2.854045800390228
Validation loss: 2.539913409626125

Epoch: 5| Step: 9
Training loss: 2.905152636669232
Validation loss: 2.5275049456950085

Epoch: 5| Step: 10
Training loss: 2.206901722035641
Validation loss: 2.4995693676772843

Epoch: 463| Step: 0
Training loss: 2.5006173325325505
Validation loss: 2.4961221141835037

Epoch: 5| Step: 1
Training loss: 2.2944042384966403
Validation loss: 2.4814421759336414

Epoch: 5| Step: 2
Training loss: 2.4486227329396915
Validation loss: 2.4929924674698176

Epoch: 5| Step: 3
Training loss: 2.9437013464144632
Validation loss: 2.48797564539823

Epoch: 5| Step: 4
Training loss: 2.6105138611921443
Validation loss: 2.480444066063165

Epoch: 5| Step: 5
Training loss: 2.689183351149537
Validation loss: 2.4907868590757696

Epoch: 5| Step: 6
Training loss: 3.2339661565553843
Validation loss: 2.4880263112841305

Epoch: 5| Step: 7
Training loss: 2.716955535446209
Validation loss: 2.4887321281190053

Epoch: 5| Step: 8
Training loss: 2.583516811705224
Validation loss: 2.498227161502924

Epoch: 5| Step: 9
Training loss: 2.9603481863764807
Validation loss: 2.5153037474817075

Epoch: 5| Step: 10
Training loss: 2.6692609882948526
Validation loss: 2.526844775796651

Epoch: 464| Step: 0
Training loss: 1.750777889114007
Validation loss: 2.56187800079936

Epoch: 5| Step: 1
Training loss: 2.685983895549655
Validation loss: 2.5801585182757965

Epoch: 5| Step: 2
Training loss: 3.1218496082941987
Validation loss: 2.5576357430303283

Epoch: 5| Step: 3
Training loss: 2.9044820679018954
Validation loss: 2.569930994479916

Epoch: 5| Step: 4
Training loss: 2.198959633450204
Validation loss: 2.554527489192362

Epoch: 5| Step: 5
Training loss: 2.809114071076297
Validation loss: 2.561414395127688

Epoch: 5| Step: 6
Training loss: 2.5160545787925854
Validation loss: 2.5366337940738584

Epoch: 5| Step: 7
Training loss: 2.609907632706055
Validation loss: 2.5272484793559755

Epoch: 5| Step: 8
Training loss: 3.4943427277440873
Validation loss: 2.518125613095404

Epoch: 5| Step: 9
Training loss: 2.4021592480281075
Validation loss: 2.5028405828157014

Epoch: 5| Step: 10
Training loss: 2.5310621780601408
Validation loss: 2.49880909395732

Epoch: 465| Step: 0
Training loss: 2.3178005814499816
Validation loss: 2.4942038214703017

Epoch: 5| Step: 1
Training loss: 3.0834849208650508
Validation loss: 2.4954828666428424

Epoch: 5| Step: 2
Training loss: 2.5699862473116175
Validation loss: 2.4956753611360725

Epoch: 5| Step: 3
Training loss: 2.825714770340041
Validation loss: 2.507691160735921

Epoch: 5| Step: 4
Training loss: 2.656071914986137
Validation loss: 2.52129139336504

Epoch: 5| Step: 5
Training loss: 2.7147261559794993
Validation loss: 2.5593660300191776

Epoch: 5| Step: 6
Training loss: 2.384780221405473
Validation loss: 2.577407001091406

Epoch: 5| Step: 7
Training loss: 2.8905025971761775
Validation loss: 2.601907286664109

Epoch: 5| Step: 8
Training loss: 2.585681545348359
Validation loss: 2.604216648401504

Epoch: 5| Step: 9
Training loss: 2.684165838084132
Validation loss: 2.5640611192668374

Epoch: 5| Step: 10
Training loss: 2.609650191911841
Validation loss: 2.5468357661189893

Epoch: 466| Step: 0
Training loss: 2.4720859442402987
Validation loss: 2.5234906204876904

Epoch: 5| Step: 1
Training loss: 2.4646303595352927
Validation loss: 2.5162923828599624

Epoch: 5| Step: 2
Training loss: 2.690423307047788
Validation loss: 2.5046752897455518

Epoch: 5| Step: 3
Training loss: 2.7359809736962233
Validation loss: 2.494940073303586

Epoch: 5| Step: 4
Training loss: 2.9526271501338464
Validation loss: 2.4998536497779167

Epoch: 5| Step: 5
Training loss: 2.7541121169174048
Validation loss: 2.4915564416329943

Epoch: 5| Step: 6
Training loss: 2.7012139770139423
Validation loss: 2.4976836333001162

Epoch: 5| Step: 7
Training loss: 3.0223438739446253
Validation loss: 2.494339669342812

Epoch: 5| Step: 8
Training loss: 2.4919339711731956
Validation loss: 2.5068227339030207

Epoch: 5| Step: 9
Training loss: 2.5231268251576413
Validation loss: 2.514214182432731

Epoch: 5| Step: 10
Training loss: 2.4196619566956405
Validation loss: 2.5231909756400377

Epoch: 467| Step: 0
Training loss: 2.558414272390686
Validation loss: 2.5227633238918235

Epoch: 5| Step: 1
Training loss: 2.412117875427836
Validation loss: 2.5497858306604373

Epoch: 5| Step: 2
Training loss: 2.508141516852825
Validation loss: 2.5689682439876793

Epoch: 5| Step: 3
Training loss: 2.7957531261356685
Validation loss: 2.5788743169118775

Epoch: 5| Step: 4
Training loss: 2.617355386843525
Validation loss: 2.606858384232179

Epoch: 5| Step: 5
Training loss: 2.557336769301911
Validation loss: 2.597823935583108

Epoch: 5| Step: 6
Training loss: 2.799728898139277
Validation loss: 2.572646491339933

Epoch: 5| Step: 7
Training loss: 2.813866177519861
Validation loss: 2.542749893914793

Epoch: 5| Step: 8
Training loss: 2.739807226124134
Validation loss: 2.529829386473489

Epoch: 5| Step: 9
Training loss: 2.8408522041867497
Validation loss: 2.537478425763532

Epoch: 5| Step: 10
Training loss: 2.8818402395342337
Validation loss: 2.514681924226024

Epoch: 468| Step: 0
Training loss: 2.7394762683055633
Validation loss: 2.502971120358927

Epoch: 5| Step: 1
Training loss: 2.9926504070882403
Validation loss: 2.5006621048014215

Epoch: 5| Step: 2
Training loss: 2.7686479502314043
Validation loss: 2.4937725644999427

Epoch: 5| Step: 3
Training loss: 2.3263021411822438
Validation loss: 2.4859296346310944

Epoch: 5| Step: 4
Training loss: 3.016041148828341
Validation loss: 2.4904336872802624

Epoch: 5| Step: 5
Training loss: 2.80959840083609
Validation loss: 2.4837764721482727

Epoch: 5| Step: 6
Training loss: 2.151888873708975
Validation loss: 2.4934669646323715

Epoch: 5| Step: 7
Training loss: 2.6597398160303296
Validation loss: 2.51456768297688

Epoch: 5| Step: 8
Training loss: 2.0194424696394777
Validation loss: 2.531815909594223

Epoch: 5| Step: 9
Training loss: 2.674193330154164
Validation loss: 2.534089036146415

Epoch: 5| Step: 10
Training loss: 2.9805954572509763
Validation loss: 2.5556934397367197

Epoch: 469| Step: 0
Training loss: 3.0765940930481723
Validation loss: 2.622679783192327

Epoch: 5| Step: 1
Training loss: 2.215538602147889
Validation loss: 2.6325536044189666

Epoch: 5| Step: 2
Training loss: 2.649304183441869
Validation loss: 2.6307750895808515

Epoch: 5| Step: 3
Training loss: 2.8471568733304
Validation loss: 2.593800491491921

Epoch: 5| Step: 4
Training loss: 2.8092175296360904
Validation loss: 2.548944082369943

Epoch: 5| Step: 5
Training loss: 2.6486162783616733
Validation loss: 2.535254964912156

Epoch: 5| Step: 6
Training loss: 2.6969483649572994
Validation loss: 2.5146203454966654

Epoch: 5| Step: 7
Training loss: 2.4632081228738665
Validation loss: 2.5072211725255045

Epoch: 5| Step: 8
Training loss: 2.657130734903837
Validation loss: 2.5061813169551526

Epoch: 5| Step: 9
Training loss: 2.7795183598831015
Validation loss: 2.5101296021563684

Epoch: 5| Step: 10
Training loss: 2.1785618873405124
Validation loss: 2.503854594883988

Epoch: 470| Step: 0
Training loss: 2.8213779624276785
Validation loss: 2.5060841206347835

Epoch: 5| Step: 1
Training loss: 2.9922160254331382
Validation loss: 2.5113841086052755

Epoch: 5| Step: 2
Training loss: 2.610571763854543
Validation loss: 2.511120409882808

Epoch: 5| Step: 3
Training loss: 2.7332091543630797
Validation loss: 2.515743016673546

Epoch: 5| Step: 4
Training loss: 2.4946664182777356
Validation loss: 2.5173165579193517

Epoch: 5| Step: 5
Training loss: 2.555726846077545
Validation loss: 2.543283313177683

Epoch: 5| Step: 6
Training loss: 2.6270929802745955
Validation loss: 2.551313830135969

Epoch: 5| Step: 7
Training loss: 2.304283391147085
Validation loss: 2.540968656052619

Epoch: 5| Step: 8
Training loss: 2.3146277253168424
Validation loss: 2.5539433672289245

Epoch: 5| Step: 9
Training loss: 2.8882839311211184
Validation loss: 2.5839820454847815

Epoch: 5| Step: 10
Training loss: 2.6878980297490562
Validation loss: 2.5687365250602925

Epoch: 471| Step: 0
Training loss: 2.2800027233241362
Validation loss: 2.586046740569734

Epoch: 5| Step: 1
Training loss: 2.5078522390859432
Validation loss: 2.5624611324120843

Epoch: 5| Step: 2
Training loss: 3.272268008991387
Validation loss: 2.543716401658853

Epoch: 5| Step: 3
Training loss: 1.973112570983581
Validation loss: 2.532210905091057

Epoch: 5| Step: 4
Training loss: 2.866446833350532
Validation loss: 2.521778024933379

Epoch: 5| Step: 5
Training loss: 2.757180981827768
Validation loss: 2.5262781960857597

Epoch: 5| Step: 6
Training loss: 2.88687418311455
Validation loss: 2.549660076959454

Epoch: 5| Step: 7
Training loss: 2.700956764951352
Validation loss: 2.5614272762811945

Epoch: 5| Step: 8
Training loss: 2.161332594802953
Validation loss: 2.5677758341752397

Epoch: 5| Step: 9
Training loss: 2.993946962507292
Validation loss: 2.5548555674415736

Epoch: 5| Step: 10
Training loss: 2.4112210139801116
Validation loss: 2.572292699767981

Epoch: 472| Step: 0
Training loss: 2.9019298643421823
Validation loss: 2.583666652594025

Epoch: 5| Step: 1
Training loss: 2.4253987918420745
Validation loss: 2.5917944892019005

Epoch: 5| Step: 2
Training loss: 2.6842646086512807
Validation loss: 2.5937525806891064

Epoch: 5| Step: 3
Training loss: 2.6871131796019
Validation loss: 2.5849922786622797

Epoch: 5| Step: 4
Training loss: 2.886048689570954
Validation loss: 2.589417469595084

Epoch: 5| Step: 5
Training loss: 2.6279720556727253
Validation loss: 2.5708203330679975

Epoch: 5| Step: 6
Training loss: 2.638948890494673
Validation loss: 2.557593242126888

Epoch: 5| Step: 7
Training loss: 2.4735318000249893
Validation loss: 2.5160748387764476

Epoch: 5| Step: 8
Training loss: 2.1786248135781947
Validation loss: 2.519813486558482

Epoch: 5| Step: 9
Training loss: 2.5940083754205014
Validation loss: 2.5195623946786845

Epoch: 5| Step: 10
Training loss: 2.7724576696770984
Validation loss: 2.511485959685718

Epoch: 473| Step: 0
Training loss: 2.6708120272813662
Validation loss: 2.5120639909826474

Epoch: 5| Step: 1
Training loss: 2.483932167748759
Validation loss: 2.508685076510157

Epoch: 5| Step: 2
Training loss: 2.0144939945876574
Validation loss: 2.502286224555887

Epoch: 5| Step: 3
Training loss: 2.5152090925358084
Validation loss: 2.504112127811486

Epoch: 5| Step: 4
Training loss: 2.8579680102769016
Validation loss: 2.5096143596908407

Epoch: 5| Step: 5
Training loss: 2.527635513280027
Validation loss: 2.5254131306904357

Epoch: 5| Step: 6
Training loss: 2.158371034192276
Validation loss: 2.5260560245357477

Epoch: 5| Step: 7
Training loss: 2.696453527445149
Validation loss: 2.530263662251103

Epoch: 5| Step: 8
Training loss: 2.9073246435420277
Validation loss: 2.546183566436908

Epoch: 5| Step: 9
Training loss: 3.0203556253084702
Validation loss: 2.543163477789675

Epoch: 5| Step: 10
Training loss: 2.811019422981744
Validation loss: 2.546529244520779

Epoch: 474| Step: 0
Training loss: 2.3014420756878895
Validation loss: 2.557423688558605

Epoch: 5| Step: 1
Training loss: 2.36151894681051
Validation loss: 2.574220431063033

Epoch: 5| Step: 2
Training loss: 2.740142059402539
Validation loss: 2.5720886682375665

Epoch: 5| Step: 3
Training loss: 2.451159911107506
Validation loss: 2.553372734235659

Epoch: 5| Step: 4
Training loss: 3.0265688587411423
Validation loss: 2.5452124834445637

Epoch: 5| Step: 5
Training loss: 2.580411509734506
Validation loss: 2.5161987640919063

Epoch: 5| Step: 6
Training loss: 2.6666109754786986
Validation loss: 2.503520007212186

Epoch: 5| Step: 7
Training loss: 2.9206284092418544
Validation loss: 2.501668353889102

Epoch: 5| Step: 8
Training loss: 2.458761652039853
Validation loss: 2.5017523161803745

Epoch: 5| Step: 9
Training loss: 2.695503736705309
Validation loss: 2.5145515144291712

Epoch: 5| Step: 10
Training loss: 2.4535269438323533
Validation loss: 2.513114595308506

Epoch: 475| Step: 0
Training loss: 2.6186757880645715
Validation loss: 2.528738620573429

Epoch: 5| Step: 1
Training loss: 2.829009365677121
Validation loss: 2.5500118431477405

Epoch: 5| Step: 2
Training loss: 2.4476110605791983
Validation loss: 2.551158924620623

Epoch: 5| Step: 3
Training loss: 2.4412548781198264
Validation loss: 2.573551678687445

Epoch: 5| Step: 4
Training loss: 2.928769387389816
Validation loss: 2.5923738027368466

Epoch: 5| Step: 5
Training loss: 2.211531165120518
Validation loss: 2.570649256474677

Epoch: 5| Step: 6
Training loss: 2.4813498066159414
Validation loss: 2.5864177382222695

Epoch: 5| Step: 7
Training loss: 2.721910503169045
Validation loss: 2.5920155124015283

Epoch: 5| Step: 8
Training loss: 3.104451945122945
Validation loss: 2.5733873118609827

Epoch: 5| Step: 9
Training loss: 2.645574411854342
Validation loss: 2.5526588887544666

Epoch: 5| Step: 10
Training loss: 2.2272360335107066
Validation loss: 2.5345131134955725

Epoch: 476| Step: 0
Training loss: 2.469102375619586
Validation loss: 2.52774489009245

Epoch: 5| Step: 1
Training loss: 2.490370898524804
Validation loss: 2.5031004200231997

Epoch: 5| Step: 2
Training loss: 2.878184006673224
Validation loss: 2.502626023280277

Epoch: 5| Step: 3
Training loss: 2.6915706589842086
Validation loss: 2.491294719187513

Epoch: 5| Step: 4
Training loss: 2.7157705357999036
Validation loss: 2.4959373627333235

Epoch: 5| Step: 5
Training loss: 2.585705887947205
Validation loss: 2.516482177173272

Epoch: 5| Step: 6
Training loss: 2.6674461020375633
Validation loss: 2.5458018280744246

Epoch: 5| Step: 7
Training loss: 2.770322613985433
Validation loss: 2.5619987419718155

Epoch: 5| Step: 8
Training loss: 2.6975122293472604
Validation loss: 2.5646655078925638

Epoch: 5| Step: 9
Training loss: 2.375517337068576
Validation loss: 2.5595841829848123

Epoch: 5| Step: 10
Training loss: 2.6116004636350745
Validation loss: 2.565968972934593

Epoch: 477| Step: 0
Training loss: 2.7020492618229355
Validation loss: 2.543129184642754

Epoch: 5| Step: 1
Training loss: 2.9278728103736995
Validation loss: 2.5387926527181577

Epoch: 5| Step: 2
Training loss: 3.05526033381731
Validation loss: 2.5195215154919084

Epoch: 5| Step: 3
Training loss: 2.5417170806220795
Validation loss: 2.5017905283681254

Epoch: 5| Step: 4
Training loss: 2.2759278805105305
Validation loss: 2.505705779549039

Epoch: 5| Step: 5
Training loss: 2.533740196265519
Validation loss: 2.5057854026892192

Epoch: 5| Step: 6
Training loss: 2.712171817738158
Validation loss: 2.5116338174383066

Epoch: 5| Step: 7
Training loss: 2.7852429647977432
Validation loss: 2.5314122548949682

Epoch: 5| Step: 8
Training loss: 2.3951322663165464
Validation loss: 2.5367136531103176

Epoch: 5| Step: 9
Training loss: 2.2793938388155786
Validation loss: 2.539940129789617

Epoch: 5| Step: 10
Training loss: 2.518503189299978
Validation loss: 2.5470256830047537

Epoch: 478| Step: 0
Training loss: 2.677930784360872
Validation loss: 2.5632020822394304

Epoch: 5| Step: 1
Training loss: 2.286629174409836
Validation loss: 2.60151913903699

Epoch: 5| Step: 2
Training loss: 2.156582350618116
Validation loss: 2.5979729680686012

Epoch: 5| Step: 3
Training loss: 2.879288833021092
Validation loss: 2.595379995890189

Epoch: 5| Step: 4
Training loss: 2.9152276621882716
Validation loss: 2.585531250106673

Epoch: 5| Step: 5
Training loss: 2.867110165584699
Validation loss: 2.5544342380101104

Epoch: 5| Step: 6
Training loss: 2.6938746058416103
Validation loss: 2.529952090856002

Epoch: 5| Step: 7
Training loss: 2.0928908905663652
Validation loss: 2.523373625521631

Epoch: 5| Step: 8
Training loss: 2.7748608872194676
Validation loss: 2.5052188431932496

Epoch: 5| Step: 9
Training loss: 2.8587268866107944
Validation loss: 2.5118188799958037

Epoch: 5| Step: 10
Training loss: 2.3079776361330673
Validation loss: 2.501404019871308

Epoch: 479| Step: 0
Training loss: 2.438627520232248
Validation loss: 2.5051555541429034

Epoch: 5| Step: 1
Training loss: 2.428609234651847
Validation loss: 2.5037318893617306

Epoch: 5| Step: 2
Training loss: 2.5067844838834703
Validation loss: 2.502833666783731

Epoch: 5| Step: 3
Training loss: 2.459069987557254
Validation loss: 2.5118804569812427

Epoch: 5| Step: 4
Training loss: 2.91500994541572
Validation loss: 2.514055136629522

Epoch: 5| Step: 5
Training loss: 2.8370187763053973
Validation loss: 2.524198156809506

Epoch: 5| Step: 6
Training loss: 2.5663103756349885
Validation loss: 2.5567433404062965

Epoch: 5| Step: 7
Training loss: 2.338048077143658
Validation loss: 2.6009638967678153

Epoch: 5| Step: 8
Training loss: 2.6948817696761687
Validation loss: 2.6412804863952575

Epoch: 5| Step: 9
Training loss: 2.7084641840698502
Validation loss: 2.6166448215095017

Epoch: 5| Step: 10
Training loss: 2.867004056046181
Validation loss: 2.5883929561348324

Epoch: 480| Step: 0
Training loss: 2.860365732456793
Validation loss: 2.5616032091387777

Epoch: 5| Step: 1
Training loss: 2.5005286611444943
Validation loss: 2.546865072054235

Epoch: 5| Step: 2
Training loss: 2.7426553962796163
Validation loss: 2.5156673885650043

Epoch: 5| Step: 3
Training loss: 1.556924408779868
Validation loss: 2.4993044582964177

Epoch: 5| Step: 4
Training loss: 2.872109826317781
Validation loss: 2.4916710496068863

Epoch: 5| Step: 5
Training loss: 2.724725404955455
Validation loss: 2.4910299497230177

Epoch: 5| Step: 6
Training loss: 2.360694566771705
Validation loss: 2.4849288714116065

Epoch: 5| Step: 7
Training loss: 2.663837143659855
Validation loss: 2.4965006907910077

Epoch: 5| Step: 8
Training loss: 2.4602574937859614
Validation loss: 2.5002969145067775

Epoch: 5| Step: 9
Training loss: 2.756263362653177
Validation loss: 2.500348234021471

Epoch: 5| Step: 10
Training loss: 2.746167112756932
Validation loss: 2.5109544730342015

Epoch: 481| Step: 0
Training loss: 3.0159725324963524
Validation loss: 2.533156886605284

Epoch: 5| Step: 1
Training loss: 2.452388774437848
Validation loss: 2.5452992506829397

Epoch: 5| Step: 2
Training loss: 2.6895304262220607
Validation loss: 2.555485934078541

Epoch: 5| Step: 3
Training loss: 2.8882713839811545
Validation loss: 2.5649598483263043

Epoch: 5| Step: 4
Training loss: 2.743900383584098
Validation loss: 2.5839859991113694

Epoch: 5| Step: 5
Training loss: 2.4386262492540807
Validation loss: 2.5752046703060167

Epoch: 5| Step: 6
Training loss: 2.1334015308844183
Validation loss: 2.5477744906677784

Epoch: 5| Step: 7
Training loss: 2.5141743333409035
Validation loss: 2.527337051146631

Epoch: 5| Step: 8
Training loss: 2.0294813232013604
Validation loss: 2.538422821467817

Epoch: 5| Step: 9
Training loss: 2.5651231690814758
Validation loss: 2.5144608477210157

Epoch: 5| Step: 10
Training loss: 2.770744025911236
Validation loss: 2.507516203458578

Epoch: 482| Step: 0
Training loss: 2.7096658411965238
Validation loss: 2.511519045571092

Epoch: 5| Step: 1
Training loss: 2.5707164319465936
Validation loss: 2.5058738635120386

Epoch: 5| Step: 2
Training loss: 2.4842511032207995
Validation loss: 2.5212137089044075

Epoch: 5| Step: 3
Training loss: 2.53727043879876
Validation loss: 2.524454943702224

Epoch: 5| Step: 4
Training loss: 2.733537643829317
Validation loss: 2.523666774237245

Epoch: 5| Step: 5
Training loss: 2.750863113203605
Validation loss: 2.540301398211593

Epoch: 5| Step: 6
Training loss: 2.3528693233766647
Validation loss: 2.529497819574707

Epoch: 5| Step: 7
Training loss: 2.568037237699529
Validation loss: 2.5528396968977933

Epoch: 5| Step: 8
Training loss: 2.6766968879878004
Validation loss: 2.547719980731094

Epoch: 5| Step: 9
Training loss: 2.341863865089058
Validation loss: 2.534141522631356

Epoch: 5| Step: 10
Training loss: 2.6531220812382723
Validation loss: 2.5153065875286025

Epoch: 483| Step: 0
Training loss: 2.524100863066124
Validation loss: 2.523359639810426

Epoch: 5| Step: 1
Training loss: 2.6267139652111724
Validation loss: 2.5172819065471566

Epoch: 5| Step: 2
Training loss: 2.6780604102092207
Validation loss: 2.5297730832858143

Epoch: 5| Step: 3
Training loss: 2.5029337834962098
Validation loss: 2.5353728150884063

Epoch: 5| Step: 4
Training loss: 2.32006505809197
Validation loss: 2.5378817378795713

Epoch: 5| Step: 5
Training loss: 2.951614881851391
Validation loss: 2.5520867259589206

Epoch: 5| Step: 6
Training loss: 2.4764098111325072
Validation loss: 2.53996308288508

Epoch: 5| Step: 7
Training loss: 2.1074744811045947
Validation loss: 2.554727844580019

Epoch: 5| Step: 8
Training loss: 2.6725019645148427
Validation loss: 2.539399700633587

Epoch: 5| Step: 9
Training loss: 2.5571629840822903
Validation loss: 2.5348319704490923

Epoch: 5| Step: 10
Training loss: 2.6055387518999957
Validation loss: 2.5291999182878975

Epoch: 484| Step: 0
Training loss: 2.7752281748122494
Validation loss: 2.529552975047347

Epoch: 5| Step: 1
Training loss: 2.470089126708645
Validation loss: 2.5214830583487755

Epoch: 5| Step: 2
Training loss: 2.566716144960098
Validation loss: 2.5293381232495133

Epoch: 5| Step: 3
Training loss: 2.50329353822383
Validation loss: 2.5438964587123563

Epoch: 5| Step: 4
Training loss: 2.4402917377977507
Validation loss: 2.5302728204689258

Epoch: 5| Step: 5
Training loss: 2.552289204500666
Validation loss: 2.562653164571802

Epoch: 5| Step: 6
Training loss: 2.4206914163072084
Validation loss: 2.5458252207429735

Epoch: 5| Step: 7
Training loss: 2.776878350131572
Validation loss: 2.5414466002793294

Epoch: 5| Step: 8
Training loss: 2.5132317383703304
Validation loss: 2.538070766225907

Epoch: 5| Step: 9
Training loss: 2.492910824266801
Validation loss: 2.5421142392503877

Epoch: 5| Step: 10
Training loss: 2.4133676065817844
Validation loss: 2.5217872002439075

Epoch: 485| Step: 0
Training loss: 2.143429888522533
Validation loss: 2.5286054815295436

Epoch: 5| Step: 1
Training loss: 3.143200932934031
Validation loss: 2.527047780479402

Epoch: 5| Step: 2
Training loss: 2.9639300922587353
Validation loss: 2.5153952628507046

Epoch: 5| Step: 3
Training loss: 2.5735204093839763
Validation loss: 2.5175600888703022

Epoch: 5| Step: 4
Training loss: 2.6863470043846363
Validation loss: 2.520647758243904

Epoch: 5| Step: 5
Training loss: 2.346665971694468
Validation loss: 2.5340972558837973

Epoch: 5| Step: 6
Training loss: 1.8520390022158713
Validation loss: 2.537620899766026

Epoch: 5| Step: 7
Training loss: 2.7458049682016528
Validation loss: 2.526357220568781

Epoch: 5| Step: 8
Training loss: 2.613871189921887
Validation loss: 2.517113310249168

Epoch: 5| Step: 9
Training loss: 2.3704437923594806
Validation loss: 2.5302847638942527

Epoch: 5| Step: 10
Training loss: 2.1671461039510835
Validation loss: 2.5201193807747324

Epoch: 486| Step: 0
Training loss: 2.9818919772174755
Validation loss: 2.5282678207625198

Epoch: 5| Step: 1
Training loss: 2.609256307677821
Validation loss: 2.5241517087699266

Epoch: 5| Step: 2
Training loss: 2.4846997318727184
Validation loss: 2.5304675172081583

Epoch: 5| Step: 3
Training loss: 2.3790277158799147
Validation loss: 2.5314063901607318

Epoch: 5| Step: 4
Training loss: 2.667385858669638
Validation loss: 2.5224790829049883

Epoch: 5| Step: 5
Training loss: 2.764842553096705
Validation loss: 2.5348544105190083

Epoch: 5| Step: 6
Training loss: 2.231481853160883
Validation loss: 2.523132165547504

Epoch: 5| Step: 7
Training loss: 2.346015750529693
Validation loss: 2.526219082889883

Epoch: 5| Step: 8
Training loss: 2.944208641526838
Validation loss: 2.530536174706332

Epoch: 5| Step: 9
Training loss: 2.1850374802576304
Validation loss: 2.5290005633426063

Epoch: 5| Step: 10
Training loss: 2.0601615364663637
Validation loss: 2.541862722978729

Epoch: 487| Step: 0
Training loss: 2.766764260681081
Validation loss: 2.5339581874884436

Epoch: 5| Step: 1
Training loss: 2.5435122892016513
Validation loss: 2.5437006441453742

Epoch: 5| Step: 2
Training loss: 3.1238101983041955
Validation loss: 2.558950699855713

Epoch: 5| Step: 3
Training loss: 2.308738845938695
Validation loss: 2.565852365687128

Epoch: 5| Step: 4
Training loss: 2.1951063609151107
Validation loss: 2.550995740927363

Epoch: 5| Step: 5
Training loss: 2.5870338720368387
Validation loss: 2.5533573144298325

Epoch: 5| Step: 6
Training loss: 2.5232151748459737
Validation loss: 2.5395533700752

Epoch: 5| Step: 7
Training loss: 2.241042426263063
Validation loss: 2.5395688514875663

Epoch: 5| Step: 8
Training loss: 2.4107574257194813
Validation loss: 2.519208665391122

Epoch: 5| Step: 9
Training loss: 2.5666779674760147
Validation loss: 2.5125482396112084

Epoch: 5| Step: 10
Training loss: 2.451482623946471
Validation loss: 2.495657187259784

Epoch: 488| Step: 0
Training loss: 2.6109544005837195
Validation loss: 2.507096886276284

Epoch: 5| Step: 1
Training loss: 2.6547278137918067
Validation loss: 2.5201050077326825

Epoch: 5| Step: 2
Training loss: 2.296164370265574
Validation loss: 2.506378759669495

Epoch: 5| Step: 3
Training loss: 2.13798326528225
Validation loss: 2.529052278600785

Epoch: 5| Step: 4
Training loss: 2.3179395467463353
Validation loss: 2.527508589047138

Epoch: 5| Step: 5
Training loss: 2.7122770402397087
Validation loss: 2.548968183420469

Epoch: 5| Step: 6
Training loss: 3.1072601333810184
Validation loss: 2.5821564090994924

Epoch: 5| Step: 7
Training loss: 2.4970565634398567
Validation loss: 2.5646670962570877

Epoch: 5| Step: 8
Training loss: 2.737051302572946
Validation loss: 2.5795479386124454

Epoch: 5| Step: 9
Training loss: 2.547680124909692
Validation loss: 2.561218205251331

Epoch: 5| Step: 10
Training loss: 1.9306794370001459
Validation loss: 2.533092698554169

Epoch: 489| Step: 0
Training loss: 2.504073829220596
Validation loss: 2.5408105459037507

Epoch: 5| Step: 1
Training loss: 2.4451053031914736
Validation loss: 2.533362476996749

Epoch: 5| Step: 2
Training loss: 2.90110060097206
Validation loss: 2.5436522281083582

Epoch: 5| Step: 3
Training loss: 2.992453620570359
Validation loss: 2.534801158012128

Epoch: 5| Step: 4
Training loss: 1.6585149572903792
Validation loss: 2.537438127195877

Epoch: 5| Step: 5
Training loss: 2.616180864013882
Validation loss: 2.543923255954382

Epoch: 5| Step: 6
Training loss: 2.1056036118609747
Validation loss: 2.5342100502439937

Epoch: 5| Step: 7
Training loss: 2.5511772467609672
Validation loss: 2.549972395131215

Epoch: 5| Step: 8
Training loss: 2.963193813797032
Validation loss: 2.541564729227593

Epoch: 5| Step: 9
Training loss: 2.604575946435099
Validation loss: 2.5509553845560577

Epoch: 5| Step: 10
Training loss: 2.0664950894330425
Validation loss: 2.5796980393482887

Epoch: 490| Step: 0
Training loss: 2.9139193174965214
Validation loss: 2.582650316300311

Epoch: 5| Step: 1
Training loss: 2.4062868586107626
Validation loss: 2.606532556320086

Epoch: 5| Step: 2
Training loss: 2.879103178951958
Validation loss: 2.616060335341143

Epoch: 5| Step: 3
Training loss: 2.4140105504245493
Validation loss: 2.5714016561129895

Epoch: 5| Step: 4
Training loss: 2.698949687261264
Validation loss: 2.5322309036919712

Epoch: 5| Step: 5
Training loss: 2.232395602494683
Validation loss: 2.5016081488120436

Epoch: 5| Step: 6
Training loss: 2.6860046662370336
Validation loss: 2.4842139586782155

Epoch: 5| Step: 7
Training loss: 2.5386114570834586
Validation loss: 2.48141900799115

Epoch: 5| Step: 8
Training loss: 2.644819190438141
Validation loss: 2.4646294733081935

Epoch: 5| Step: 9
Training loss: 2.2389349656876174
Validation loss: 2.493015352014234

Epoch: 5| Step: 10
Training loss: 2.172551660307603
Validation loss: 2.4914345998010314

Epoch: 491| Step: 0
Training loss: 2.5649790983482457
Validation loss: 2.5236652860317985

Epoch: 5| Step: 1
Training loss: 2.5726002075133545
Validation loss: 2.538499079462139

Epoch: 5| Step: 2
Training loss: 2.884626278000828
Validation loss: 2.543170932322142

Epoch: 5| Step: 3
Training loss: 2.129752846468866
Validation loss: 2.559163418178403

Epoch: 5| Step: 4
Training loss: 2.249733591202362
Validation loss: 2.581925809224965

Epoch: 5| Step: 5
Training loss: 2.614186676049338
Validation loss: 2.580961884205579

Epoch: 5| Step: 6
Training loss: 1.7543576345749619
Validation loss: 2.587623040173555

Epoch: 5| Step: 7
Training loss: 2.8177491265597565
Validation loss: 2.5827114532341504

Epoch: 5| Step: 8
Training loss: 2.964481537698205
Validation loss: 2.5713130089457596

Epoch: 5| Step: 9
Training loss: 2.3749477983058354
Validation loss: 2.542733511363375

Epoch: 5| Step: 10
Training loss: 2.478423180746199
Validation loss: 2.530072535781323

Epoch: 492| Step: 0
Training loss: 2.4528239849092404
Validation loss: 2.509191654739274

Epoch: 5| Step: 1
Training loss: 2.4400968168155437
Validation loss: 2.5103477605071194

Epoch: 5| Step: 2
Training loss: 3.020874040702061
Validation loss: 2.5140971978249267

Epoch: 5| Step: 3
Training loss: 2.385264451502406
Validation loss: 2.494689645084926

Epoch: 5| Step: 4
Training loss: 2.501743566952132
Validation loss: 2.517879854605542

Epoch: 5| Step: 5
Training loss: 2.12741803989707
Validation loss: 2.5117111949755677

Epoch: 5| Step: 6
Training loss: 2.207370104137919
Validation loss: 2.5344887384356145

Epoch: 5| Step: 7
Training loss: 2.8171235968545707
Validation loss: 2.537452126239352

Epoch: 5| Step: 8
Training loss: 2.169662556230843
Validation loss: 2.559446811441111

Epoch: 5| Step: 9
Training loss: 2.825821080347658
Validation loss: 2.6005943068730932

Epoch: 5| Step: 10
Training loss: 2.550029369259918
Validation loss: 2.6329466459785458

Epoch: 493| Step: 0
Training loss: 1.8855434887912739
Validation loss: 2.598044594840665

Epoch: 5| Step: 1
Training loss: 2.2559953921047797
Validation loss: 2.5862865226712035

Epoch: 5| Step: 2
Training loss: 2.6667495555711023
Validation loss: 2.5607451365925433

Epoch: 5| Step: 3
Training loss: 2.540936245217164
Validation loss: 2.5377262104565474

Epoch: 5| Step: 4
Training loss: 2.7842425416550403
Validation loss: 2.5387503968061993

Epoch: 5| Step: 5
Training loss: 2.237291366823887
Validation loss: 2.5208188752061718

Epoch: 5| Step: 6
Training loss: 2.500686741919783
Validation loss: 2.5246371086530357

Epoch: 5| Step: 7
Training loss: 2.420675460561322
Validation loss: 2.5114092764969334

Epoch: 5| Step: 8
Training loss: 2.671202993376529
Validation loss: 2.528551144372764

Epoch: 5| Step: 9
Training loss: 2.993814290099016
Validation loss: 2.5246694535479857

Epoch: 5| Step: 10
Training loss: 2.495232040837499
Validation loss: 2.508335087060511

Epoch: 494| Step: 0
Training loss: 2.563723946396655
Validation loss: 2.5222497698216855

Epoch: 5| Step: 1
Training loss: 2.453850899952313
Validation loss: 2.5281040133333477

Epoch: 5| Step: 2
Training loss: 2.747759947068719
Validation loss: 2.5471251376410193

Epoch: 5| Step: 3
Training loss: 2.6846030834497165
Validation loss: 2.533579690215189

Epoch: 5| Step: 4
Training loss: 1.8885159669766192
Validation loss: 2.530285556202965

Epoch: 5| Step: 5
Training loss: 2.7549906442140655
Validation loss: 2.528619093517171

Epoch: 5| Step: 6
Training loss: 2.4800413709696842
Validation loss: 2.5395579278951765

Epoch: 5| Step: 7
Training loss: 2.1951331883300513
Validation loss: 2.5317061010930066

Epoch: 5| Step: 8
Training loss: 3.0509091007341373
Validation loss: 2.509064010535409

Epoch: 5| Step: 9
Training loss: 1.7061808757264219
Validation loss: 2.5069092222838756

Epoch: 5| Step: 10
Training loss: 2.5560522138190542
Validation loss: 2.504914564038475

Epoch: 495| Step: 0
Training loss: 1.9677848266574873
Validation loss: 2.503677480320092

Epoch: 5| Step: 1
Training loss: 2.4184277026506287
Validation loss: 2.506325159896304

Epoch: 5| Step: 2
Training loss: 2.252537673821431
Validation loss: 2.5128973025403627

Epoch: 5| Step: 3
Training loss: 2.8503770010038254
Validation loss: 2.520178358319639

Epoch: 5| Step: 4
Training loss: 2.611327394586659
Validation loss: 2.5597114466955784

Epoch: 5| Step: 5
Training loss: 3.1392137383750467
Validation loss: 2.568321604244121

Epoch: 5| Step: 6
Training loss: 1.9215753833477207
Validation loss: 2.5523765136060637

Epoch: 5| Step: 7
Training loss: 2.8772670266422162
Validation loss: 2.5418292393191804

Epoch: 5| Step: 8
Training loss: 1.8861003359806907
Validation loss: 2.52816883303026

Epoch: 5| Step: 9
Training loss: 2.9959495539575425
Validation loss: 2.5052330294387355

Epoch: 5| Step: 10
Training loss: 1.8647998563333568
Validation loss: 2.4839372611058685

Epoch: 496| Step: 0
Training loss: 2.459582049368238
Validation loss: 2.488934209899471

Epoch: 5| Step: 1
Training loss: 2.614099850476121
Validation loss: 2.493239020048338

Epoch: 5| Step: 2
Training loss: 2.8203733654270238
Validation loss: 2.4918515998720245

Epoch: 5| Step: 3
Training loss: 2.3230158922930224
Validation loss: 2.4911269898810033

Epoch: 5| Step: 4
Training loss: 2.802053335565764
Validation loss: 2.5030703794406897

Epoch: 5| Step: 5
Training loss: 2.1253131186977003
Validation loss: 2.500397835117511

Epoch: 5| Step: 6
Training loss: 2.8464094868013516
Validation loss: 2.5225078729940638

Epoch: 5| Step: 7
Training loss: 2.462619654657836
Validation loss: 2.5384485928440834

Epoch: 5| Step: 8
Training loss: 2.4553616768931352
Validation loss: 2.548409479919637

Epoch: 5| Step: 9
Training loss: 1.9752173388684602
Validation loss: 2.546206849375974

Epoch: 5| Step: 10
Training loss: 2.0483447905743306
Validation loss: 2.553312667954328

Epoch: 497| Step: 0
Training loss: 2.421657921691493
Validation loss: 2.560559748503215

Epoch: 5| Step: 1
Training loss: 2.0017837676078556
Validation loss: 2.577503331999028

Epoch: 5| Step: 2
Training loss: 2.6984910881230353
Validation loss: 2.5861111815485365

Epoch: 5| Step: 3
Training loss: 2.173447732469398
Validation loss: 2.5836809662422313

Epoch: 5| Step: 4
Training loss: 2.3903119249975306
Validation loss: 2.561185103759433

Epoch: 5| Step: 5
Training loss: 2.647411226363795
Validation loss: 2.5430767601633377

Epoch: 5| Step: 6
Training loss: 2.9638480423084292
Validation loss: 2.527589458042273

Epoch: 5| Step: 7
Training loss: 2.2101614840443173
Validation loss: 2.5118729412263305

Epoch: 5| Step: 8
Training loss: 2.666535960411508
Validation loss: 2.5120206608790983

Epoch: 5| Step: 9
Training loss: 2.271736583664643
Validation loss: 2.4956057517606616

Epoch: 5| Step: 10
Training loss: 2.6239710107981438
Validation loss: 2.490681496713289

Epoch: 498| Step: 0
Training loss: 2.1696138755661276
Validation loss: 2.473743730357284

Epoch: 5| Step: 1
Training loss: 2.550207193222354
Validation loss: 2.470540693356247

Epoch: 5| Step: 2
Training loss: 2.2791326442413102
Validation loss: 2.473257889781803

Epoch: 5| Step: 3
Training loss: 2.214883148004419
Validation loss: 2.510897309613968

Epoch: 5| Step: 4
Training loss: 2.119605003842568
Validation loss: 2.5253239777438234

Epoch: 5| Step: 5
Training loss: 3.012354208556427
Validation loss: 2.5554712182265544

Epoch: 5| Step: 6
Training loss: 2.6215667070497592
Validation loss: 2.5767160273979917

Epoch: 5| Step: 7
Training loss: 2.4346347498868175
Validation loss: 2.5929678923711523

Epoch: 5| Step: 8
Training loss: 2.641628819464275
Validation loss: 2.5718187066351517

Epoch: 5| Step: 9
Training loss: 2.6024742018184104
Validation loss: 2.6033223065948983

Epoch: 5| Step: 10
Training loss: 2.7552774248792655
Validation loss: 2.5997379350360195

Epoch: 499| Step: 0
Training loss: 2.09170044748858
Validation loss: 2.5705677101136324

Epoch: 5| Step: 1
Training loss: 2.520266781869418
Validation loss: 2.5136795842519675

Epoch: 5| Step: 2
Training loss: 2.6924848236251324
Validation loss: 2.493974578109984

Epoch: 5| Step: 3
Training loss: 2.4212688056558163
Validation loss: 2.499442149034638

Epoch: 5| Step: 4
Training loss: 2.521766794523374
Validation loss: 2.4817214325787855

Epoch: 5| Step: 5
Training loss: 2.5275946703347993
Validation loss: 2.4803050467690246

Epoch: 5| Step: 6
Training loss: 2.084287297864443
Validation loss: 2.5044575083871763

Epoch: 5| Step: 7
Training loss: 2.923659488602914
Validation loss: 2.5091477151325456

Epoch: 5| Step: 8
Training loss: 2.7773489864852623
Validation loss: 2.5422512490339932

Epoch: 5| Step: 9
Training loss: 2.336672970123423
Validation loss: 2.550818715656364

Epoch: 5| Step: 10
Training loss: 2.2367688140436033
Validation loss: 2.55383857268956

Epoch: 500| Step: 0
Training loss: 2.8683105265102067
Validation loss: 2.577310709355198

Epoch: 5| Step: 1
Training loss: 2.9830731653185367
Validation loss: 2.562079306303655

Epoch: 5| Step: 2
Training loss: 2.529543265930889
Validation loss: 2.5667849415042108

Epoch: 5| Step: 3
Training loss: 2.3000820891616724
Validation loss: 2.526246674497065

Epoch: 5| Step: 4
Training loss: 1.9075193087699212
Validation loss: 2.5172336545442793

Epoch: 5| Step: 5
Training loss: 2.2653308545922872
Validation loss: 2.5133688313659928

Epoch: 5| Step: 6
Training loss: 2.530063680819893
Validation loss: 2.4972037643855307

Epoch: 5| Step: 7
Training loss: 2.8423124599406875
Validation loss: 2.4943090854079064

Epoch: 5| Step: 8
Training loss: 2.1855990188009984
Validation loss: 2.4974020420943273

Epoch: 5| Step: 9
Training loss: 2.3004075477095536
Validation loss: 2.4826663856887294

Epoch: 5| Step: 10
Training loss: 2.166460051833166
Validation loss: 2.4930508753954785

Epoch: 501| Step: 0
Training loss: 2.740821954833649
Validation loss: 2.496968202977915

Epoch: 5| Step: 1
Training loss: 2.4032788449414206
Validation loss: 2.4934183741201763

Epoch: 5| Step: 2
Training loss: 2.4074813862652444
Validation loss: 2.5008724679630925

Epoch: 5| Step: 3
Training loss: 1.9242434910102495
Validation loss: 2.528029332029788

Epoch: 5| Step: 4
Training loss: 2.9589750283474494
Validation loss: 2.5559680232310025

Epoch: 5| Step: 5
Training loss: 2.7875080638820178
Validation loss: 2.549226574243725

Epoch: 5| Step: 6
Training loss: 2.441374413854927
Validation loss: 2.536083288631336

Epoch: 5| Step: 7
Training loss: 2.5347343293572924
Validation loss: 2.5333586356249285

Epoch: 5| Step: 8
Training loss: 2.084726274850549
Validation loss: 2.546129321986324

Epoch: 5| Step: 9
Training loss: 2.420877558905531
Validation loss: 2.540523658017494

Epoch: 5| Step: 10
Training loss: 2.002793983091745
Validation loss: 2.528535764314117

Epoch: 502| Step: 0
Training loss: 2.30373784559317
Validation loss: 2.53472732234016

Epoch: 5| Step: 1
Training loss: 2.692124048194871
Validation loss: 2.531829080056929

Epoch: 5| Step: 2
Training loss: 2.3535702267719594
Validation loss: 2.5479660953318763

Epoch: 5| Step: 3
Training loss: 3.371384131875311
Validation loss: 2.546344284304803

Epoch: 5| Step: 4
Training loss: 2.202899894306579
Validation loss: 2.5299322500532244

Epoch: 5| Step: 5
Training loss: 2.220822722771677
Validation loss: 2.5147356914734824

Epoch: 5| Step: 6
Training loss: 2.5900766489477327
Validation loss: 2.505013582368286

Epoch: 5| Step: 7
Training loss: 2.09644235618963
Validation loss: 2.5056122348572076

Epoch: 5| Step: 8
Training loss: 2.299868443085227
Validation loss: 2.502721629934604

Epoch: 5| Step: 9
Training loss: 2.301204208589787
Validation loss: 2.495528897007584

Epoch: 5| Step: 10
Training loss: 2.4056141000700446
Validation loss: 2.498554471193994

Epoch: 503| Step: 0
Training loss: 2.6796051991449996
Validation loss: 2.5322439176054417

Epoch: 5| Step: 1
Training loss: 1.5820407443291495
Validation loss: 2.549340541490987

Epoch: 5| Step: 2
Training loss: 2.9556812344108154
Validation loss: 2.564121769601648

Epoch: 5| Step: 3
Training loss: 2.6770702515120446
Validation loss: 2.5777593716975704

Epoch: 5| Step: 4
Training loss: 1.9410209043065971
Validation loss: 2.588076330647047

Epoch: 5| Step: 5
Training loss: 2.569826862870932
Validation loss: 2.555416199310313

Epoch: 5| Step: 6
Training loss: 2.1136229515582383
Validation loss: 2.5505031197938672

Epoch: 5| Step: 7
Training loss: 2.0071863764130633
Validation loss: 2.534287777372847

Epoch: 5| Step: 8
Training loss: 2.7090216911182567
Validation loss: 2.5251470187741747

Epoch: 5| Step: 9
Training loss: 2.3345724857243293
Validation loss: 2.5254788213899713

Epoch: 5| Step: 10
Training loss: 2.9656539031249274
Validation loss: 2.500884464662157

Epoch: 504| Step: 0
Training loss: 2.631259539444183
Validation loss: 2.5097720765719242

Epoch: 5| Step: 1
Training loss: 2.0374197353163255
Validation loss: 2.485746854548062

Epoch: 5| Step: 2
Training loss: 2.3034686470125387
Validation loss: 2.478827127430991

Epoch: 5| Step: 3
Training loss: 2.663642022295228
Validation loss: 2.480467250346482

Epoch: 5| Step: 4
Training loss: 2.69139872025321
Validation loss: 2.4880071541755515

Epoch: 5| Step: 5
Training loss: 2.335954851066935
Validation loss: 2.4760165756845374

Epoch: 5| Step: 6
Training loss: 2.17760715540678
Validation loss: 2.4663607852383156

Epoch: 5| Step: 7
Training loss: 2.6740562057465618
Validation loss: 2.493689772803093

Epoch: 5| Step: 8
Training loss: 2.2902168774249505
Validation loss: 2.4995176793460945

Epoch: 5| Step: 9
Training loss: 2.792828579032876
Validation loss: 2.5130001563096593

Epoch: 5| Step: 10
Training loss: 2.1169703748789765
Validation loss: 2.5474244639882135

Epoch: 505| Step: 0
Training loss: 3.1559775961986043
Validation loss: 2.6713958158941367

Epoch: 5| Step: 1
Training loss: 2.0039536022518156
Validation loss: 2.7343205684746494

Epoch: 5| Step: 2
Training loss: 2.3930496187210855
Validation loss: 2.757396307887128

Epoch: 5| Step: 3
Training loss: 2.438198380802253
Validation loss: 2.6453851196321825

Epoch: 5| Step: 4
Training loss: 2.839156916491225
Validation loss: 2.5515075392330115

Epoch: 5| Step: 5
Training loss: 1.9491520260569115
Validation loss: 2.5275106333589292

Epoch: 5| Step: 6
Training loss: 2.52920468431166
Validation loss: 2.4796843611688204

Epoch: 5| Step: 7
Training loss: 2.456440331459379
Validation loss: 2.4845837725734743

Epoch: 5| Step: 8
Training loss: 2.7935947383603845
Validation loss: 2.483861405643606

Epoch: 5| Step: 9
Training loss: 2.692329237401083
Validation loss: 2.4965544419320858

Epoch: 5| Step: 10
Training loss: 2.3065701311597913
Validation loss: 2.5137835191619806

Epoch: 506| Step: 0
Training loss: 2.1252950575687306
Validation loss: 2.500065267387701

Epoch: 5| Step: 1
Training loss: 2.555414405555125
Validation loss: 2.5149493595800885

Epoch: 5| Step: 2
Training loss: 2.1283316580522595
Validation loss: 2.4975062217406205

Epoch: 5| Step: 3
Training loss: 2.333998471780128
Validation loss: 2.529575993004186

Epoch: 5| Step: 4
Training loss: 2.3419190439358935
Validation loss: 2.5372755261230995

Epoch: 5| Step: 5
Training loss: 2.7646079914418236
Validation loss: 2.563158147347167

Epoch: 5| Step: 6
Training loss: 2.183846720064075
Validation loss: 2.5824065105539398

Epoch: 5| Step: 7
Training loss: 2.8828134924413944
Validation loss: 2.5979884131807887

Epoch: 5| Step: 8
Training loss: 2.7742665086103604
Validation loss: 2.5748913833341165

Epoch: 5| Step: 9
Training loss: 2.1405840124953706
Validation loss: 2.53641916910893

Epoch: 5| Step: 10
Training loss: 2.8481372903136353
Validation loss: 2.4982110380485523

Epoch: 507| Step: 0
Training loss: 2.876970693789703
Validation loss: 2.4803437619818873

Epoch: 5| Step: 1
Training loss: 2.877658112769698
Validation loss: 2.4779939632853893

Epoch: 5| Step: 2
Training loss: 1.989892393011127
Validation loss: 2.4668019029294905

Epoch: 5| Step: 3
Training loss: 2.1704590936728407
Validation loss: 2.477615016334821

Epoch: 5| Step: 4
Training loss: 2.4326454139520566
Validation loss: 2.45941328358287

Epoch: 5| Step: 5
Training loss: 2.2557450170553883
Validation loss: 2.464914456908537

Epoch: 5| Step: 6
Training loss: 2.8710188460148363
Validation loss: 2.4718511638324654

Epoch: 5| Step: 7
Training loss: 2.238270811153123
Validation loss: 2.4577912876163555

Epoch: 5| Step: 8
Training loss: 2.4730621535052646
Validation loss: 2.467009145931458

Epoch: 5| Step: 9
Training loss: 2.237851086568706
Validation loss: 2.490358353966286

Epoch: 5| Step: 10
Training loss: 2.369918506846904
Validation loss: 2.500691316244852

Epoch: 508| Step: 0
Training loss: 2.335109704358744
Validation loss: 2.5186908047378007

Epoch: 5| Step: 1
Training loss: 1.9775273678280747
Validation loss: 2.545741898863222

Epoch: 5| Step: 2
Training loss: 2.791665964458624
Validation loss: 2.5469532223633657

Epoch: 5| Step: 3
Training loss: 2.350948621142216
Validation loss: 2.5429148498098413

Epoch: 5| Step: 4
Training loss: 2.5463916343283093
Validation loss: 2.537150109237285

Epoch: 5| Step: 5
Training loss: 2.596996527627262
Validation loss: 2.5384939471242998

Epoch: 5| Step: 6
Training loss: 2.1668023898334927
Validation loss: 2.510822393219139

Epoch: 5| Step: 7
Training loss: 2.0835438685530616
Validation loss: 2.511421706718903

Epoch: 5| Step: 8
Training loss: 2.6389918045142187
Validation loss: 2.513969066429594

Epoch: 5| Step: 9
Training loss: 2.5819260753269777
Validation loss: 2.518247506805454

Epoch: 5| Step: 10
Training loss: 2.396816836848793
Validation loss: 2.532634365154831

Epoch: 509| Step: 0
Training loss: 2.484878872811052
Validation loss: 2.5312794002930645

Epoch: 5| Step: 1
Training loss: 2.2608410016539247
Validation loss: 2.544415146978651

Epoch: 5| Step: 2
Training loss: 2.8251053511968944
Validation loss: 2.5269568722632485

Epoch: 5| Step: 3
Training loss: 2.50636016527477
Validation loss: 2.51151495234817

Epoch: 5| Step: 4
Training loss: 2.4636570027768765
Validation loss: 2.536844621379064

Epoch: 5| Step: 5
Training loss: 2.2063453891438414
Validation loss: 2.5317821897787374

Epoch: 5| Step: 6
Training loss: 2.485461591222373
Validation loss: 2.539208584377973

Epoch: 5| Step: 7
Training loss: 2.060619768778785
Validation loss: 2.553388799530088

Epoch: 5| Step: 8
Training loss: 2.332738414489934
Validation loss: 2.5592446427446407

Epoch: 5| Step: 9
Training loss: 2.423570298000321
Validation loss: 2.5635262771997014

Epoch: 5| Step: 10
Training loss: 2.4200877824735882
Validation loss: 2.5590058371311617

Epoch: 510| Step: 0
Training loss: 2.603862307246698
Validation loss: 2.5287176869932084

Epoch: 5| Step: 1
Training loss: 2.4806357019664054
Validation loss: 2.498946547310641

Epoch: 5| Step: 2
Training loss: 2.6134109806994625
Validation loss: 2.4860583408395627

Epoch: 5| Step: 3
Training loss: 2.439350306204879
Validation loss: 2.487328805534406

Epoch: 5| Step: 4
Training loss: 2.144976793710515
Validation loss: 2.4853942399386337

Epoch: 5| Step: 5
Training loss: 2.497367235536428
Validation loss: 2.496541469430566

Epoch: 5| Step: 6
Training loss: 2.138819469079491
Validation loss: 2.5212213381531767

Epoch: 5| Step: 7
Training loss: 2.3133410393570983
Validation loss: 2.529950926555785

Epoch: 5| Step: 8
Training loss: 1.8189924307944092
Validation loss: 2.5335371662313304

Epoch: 5| Step: 9
Training loss: 2.991940799433447
Validation loss: 2.543169736775878

Epoch: 5| Step: 10
Training loss: 2.458176871886517
Validation loss: 2.5324806514368894

Epoch: 511| Step: 0
Training loss: 1.883470665586053
Validation loss: 2.546367645813611

Epoch: 5| Step: 1
Training loss: 2.4498622115956734
Validation loss: 2.5408516839216917

Epoch: 5| Step: 2
Training loss: 2.3915042631544763
Validation loss: 2.548170973807509

Epoch: 5| Step: 3
Training loss: 2.6392730321750912
Validation loss: 2.522515667035014

Epoch: 5| Step: 4
Training loss: 2.0606939326596616
Validation loss: 2.5390706672884176

Epoch: 5| Step: 5
Training loss: 1.9091675740904075
Validation loss: 2.533042726609325

Epoch: 5| Step: 6
Training loss: 2.888686071106936
Validation loss: 2.51347180353446

Epoch: 5| Step: 7
Training loss: 2.544688028876357
Validation loss: 2.517354016509129

Epoch: 5| Step: 8
Training loss: 2.6939503641688933
Validation loss: 2.5109308085897477

Epoch: 5| Step: 9
Training loss: 2.2425173207850584
Validation loss: 2.5303445237411055

Epoch: 5| Step: 10
Training loss: 2.472489048516037
Validation loss: 2.5384923514720894

Epoch: 512| Step: 0
Training loss: 2.4227002122341457
Validation loss: 2.536439471606237

Epoch: 5| Step: 1
Training loss: 2.2974921195441946
Validation loss: 2.5637232634187583

Epoch: 5| Step: 2
Training loss: 1.9483675579375068
Validation loss: 2.5430340184606046

Epoch: 5| Step: 3
Training loss: 2.39681514580707
Validation loss: 2.5460618693541037

Epoch: 5| Step: 4
Training loss: 2.570683229372609
Validation loss: 2.5354879742976157

Epoch: 5| Step: 5
Training loss: 2.5314705834997397
Validation loss: 2.502484430462986

Epoch: 5| Step: 6
Training loss: 2.4282517683599476
Validation loss: 2.49535897790377

Epoch: 5| Step: 7
Training loss: 2.103856192870497
Validation loss: 2.4730650705692305

Epoch: 5| Step: 8
Training loss: 1.9922406357803497
Validation loss: 2.4793429950960117

Epoch: 5| Step: 9
Training loss: 2.9362296746250007
Validation loss: 2.4612712091496114

Epoch: 5| Step: 10
Training loss: 2.6557049360340073
Validation loss: 2.449946110802217

Epoch: 513| Step: 0
Training loss: 2.2794485425787
Validation loss: 2.45328982617031

Epoch: 5| Step: 1
Training loss: 2.232783143989742
Validation loss: 2.4443206426758395

Epoch: 5| Step: 2
Training loss: 2.318776968004869
Validation loss: 2.449206130738807

Epoch: 5| Step: 3
Training loss: 1.91147603815872
Validation loss: 2.472119087669498

Epoch: 5| Step: 4
Training loss: 2.3708036392935723
Validation loss: 2.476581559308922

Epoch: 5| Step: 5
Training loss: 2.867809425694045
Validation loss: 2.4903706802874965

Epoch: 5| Step: 6
Training loss: 2.5442118382455208
Validation loss: 2.4927636896601046

Epoch: 5| Step: 7
Training loss: 2.408340437811522
Validation loss: 2.4983110742344175

Epoch: 5| Step: 8
Training loss: 1.9624273711936662
Validation loss: 2.528864329928455

Epoch: 5| Step: 9
Training loss: 3.0814066013366737
Validation loss: 2.5685720257669353

Epoch: 5| Step: 10
Training loss: 2.2919668058884346
Validation loss: 2.573600273359717

Epoch: 514| Step: 0
Training loss: 2.281467166126821
Validation loss: 2.5510950468201266

Epoch: 5| Step: 1
Training loss: 2.2223951457877593
Validation loss: 2.5448159534113652

Epoch: 5| Step: 2
Training loss: 2.5202054799789475
Validation loss: 2.5084184470341406

Epoch: 5| Step: 3
Training loss: 2.700436263689945
Validation loss: 2.4692806142519808

Epoch: 5| Step: 4
Training loss: 2.4213147899839096
Validation loss: 2.4689737272829624

Epoch: 5| Step: 5
Training loss: 2.5852511783070025
Validation loss: 2.464924423712242

Epoch: 5| Step: 6
Training loss: 2.307833732037255
Validation loss: 2.470718958966592

Epoch: 5| Step: 7
Training loss: 2.278092380703542
Validation loss: 2.4752422123507496

Epoch: 5| Step: 8
Training loss: 2.0754282957449552
Validation loss: 2.4956707961074707

Epoch: 5| Step: 9
Training loss: 2.54616194964659
Validation loss: 2.5125967683106643

Epoch: 5| Step: 10
Training loss: 2.317394129568342
Validation loss: 2.5484075906946377

Epoch: 515| Step: 0
Training loss: 2.2600544816598562
Validation loss: 2.561216261413827

Epoch: 5| Step: 1
Training loss: 2.470215953699222
Validation loss: 2.582427243703241

Epoch: 5| Step: 2
Training loss: 2.319236531586854
Validation loss: 2.5821180458889312

Epoch: 5| Step: 3
Training loss: 2.9950490470525666
Validation loss: 2.5928399112412275

Epoch: 5| Step: 4
Training loss: 2.3742963852887686
Validation loss: 2.6077757374008192

Epoch: 5| Step: 5
Training loss: 2.1572242415602614
Validation loss: 2.5911626234709697

Epoch: 5| Step: 6
Training loss: 2.515094487897132
Validation loss: 2.5919414263301848

Epoch: 5| Step: 7
Training loss: 2.741517770389929
Validation loss: 2.575963294071727

Epoch: 5| Step: 8
Training loss: 1.8757968480908633
Validation loss: 2.523732853737832

Epoch: 5| Step: 9
Training loss: 2.28090393367831
Validation loss: 2.4733479265012965

Epoch: 5| Step: 10
Training loss: 2.2126486259583933
Validation loss: 2.457249720833905

Epoch: 516| Step: 0
Training loss: 2.632050446383414
Validation loss: 2.4619517028104667

Epoch: 5| Step: 1
Training loss: 2.1089442060460226
Validation loss: 2.4679484833538194

Epoch: 5| Step: 2
Training loss: 2.3996228199848697
Validation loss: 2.4625197275547013

Epoch: 5| Step: 3
Training loss: 2.297393325138964
Validation loss: 2.474363819477678

Epoch: 5| Step: 4
Training loss: 2.348723361040371
Validation loss: 2.4890537361998195

Epoch: 5| Step: 5
Training loss: 2.4468057478925296
Validation loss: 2.5022734323746887

Epoch: 5| Step: 6
Training loss: 2.4404781439016854
Validation loss: 2.5111502091955833

Epoch: 5| Step: 7
Training loss: 2.2628200662900233
Validation loss: 2.5414551523019204

Epoch: 5| Step: 8
Training loss: 2.499791994978374
Validation loss: 2.5300114623635377

Epoch: 5| Step: 9
Training loss: 2.556312627421574
Validation loss: 2.546549320441816

Epoch: 5| Step: 10
Training loss: 2.294595118858873
Validation loss: 2.572861489055573

Epoch: 517| Step: 0
Training loss: 2.5008679790526975
Validation loss: 2.555172613287786

Epoch: 5| Step: 1
Training loss: 2.3501810978038193
Validation loss: 2.5457807483065458

Epoch: 5| Step: 2
Training loss: 2.3419164988147325
Validation loss: 2.529758675913492

Epoch: 5| Step: 3
Training loss: 2.4580459318967596
Validation loss: 2.4932152964511736

Epoch: 5| Step: 4
Training loss: 2.5114645347270774
Validation loss: 2.4800059723922736

Epoch: 5| Step: 5
Training loss: 2.596547468075114
Validation loss: 2.4502332866368914

Epoch: 5| Step: 6
Training loss: 1.9144592496769697
Validation loss: 2.4587115029410134

Epoch: 5| Step: 7
Training loss: 2.5241034133993843
Validation loss: 2.467072706953665

Epoch: 5| Step: 8
Training loss: 2.3036187231504197
Validation loss: 2.484399151634686

Epoch: 5| Step: 9
Training loss: 2.314821469897841
Validation loss: 2.5017573814551226

Epoch: 5| Step: 10
Training loss: 2.4161185487057844
Validation loss: 2.5021119969272876

Epoch: 518| Step: 0
Training loss: 2.2178106334259704
Validation loss: 2.4948036754797904

Epoch: 5| Step: 1
Training loss: 2.576462273068142
Validation loss: 2.49144706691224

Epoch: 5| Step: 2
Training loss: 2.2405766140064083
Validation loss: 2.489528686470135

Epoch: 5| Step: 3
Training loss: 2.8080709551788123
Validation loss: 2.4883449641136823

Epoch: 5| Step: 4
Training loss: 1.8091313858610085
Validation loss: 2.5039595022568815

Epoch: 5| Step: 5
Training loss: 2.734845279034327
Validation loss: 2.5085462354806247

Epoch: 5| Step: 6
Training loss: 2.241608335546751
Validation loss: 2.50721381356215

Epoch: 5| Step: 7
Training loss: 2.4069739899824736
Validation loss: 2.5031513143852324

Epoch: 5| Step: 8
Training loss: 2.2930533866273892
Validation loss: 2.5230676137420516

Epoch: 5| Step: 9
Training loss: 2.3963536457696017
Validation loss: 2.506074306272921

Epoch: 5| Step: 10
Training loss: 1.9635659645526702
Validation loss: 2.5045779510463744

Epoch: 519| Step: 0
Training loss: 2.504672833243279
Validation loss: 2.495705008965144

Epoch: 5| Step: 1
Training loss: 2.1443284569417065
Validation loss: 2.4966099714453036

Epoch: 5| Step: 2
Training loss: 2.44675858611661
Validation loss: 2.483890954003685

Epoch: 5| Step: 3
Training loss: 2.3080073869015116
Validation loss: 2.493103996533907

Epoch: 5| Step: 4
Training loss: 2.342936463624869
Validation loss: 2.512641669940099

Epoch: 5| Step: 5
Training loss: 2.2715904886744185
Validation loss: 2.532140484278537

Epoch: 5| Step: 6
Training loss: 2.545611577175388
Validation loss: 2.5762755212751984

Epoch: 5| Step: 7
Training loss: 2.3260490839888757
Validation loss: 2.5874671418347472

Epoch: 5| Step: 8
Training loss: 2.6747205427847276
Validation loss: 2.5787913605137196

Epoch: 5| Step: 9
Training loss: 2.257380671932928
Validation loss: 2.560644221628129

Epoch: 5| Step: 10
Training loss: 2.254985478221207
Validation loss: 2.5417343916024113

Epoch: 520| Step: 0
Training loss: 1.7862698276665974
Validation loss: 2.5168537901013472

Epoch: 5| Step: 1
Training loss: 2.533243312825738
Validation loss: 2.4798173530500027

Epoch: 5| Step: 2
Training loss: 2.263477860201112
Validation loss: 2.457737437656831

Epoch: 5| Step: 3
Training loss: 2.5437854211389035
Validation loss: 2.4782783617573885

Epoch: 5| Step: 4
Training loss: 2.6957806609096777
Validation loss: 2.4649256176874847

Epoch: 5| Step: 5
Training loss: 2.248071267718987
Validation loss: 2.472277882708208

Epoch: 5| Step: 6
Training loss: 1.9996626688671428
Validation loss: 2.476133907341713

Epoch: 5| Step: 7
Training loss: 2.5922529197379904
Validation loss: 2.499043699119065

Epoch: 5| Step: 8
Training loss: 2.145913600963537
Validation loss: 2.520524944688956

Epoch: 5| Step: 9
Training loss: 2.360482972558585
Validation loss: 2.5492369118460183

Epoch: 5| Step: 10
Training loss: 2.7828385177843957
Validation loss: 2.565124866099542

Epoch: 521| Step: 0
Training loss: 2.1505543770317823
Validation loss: 2.589116814980246

Epoch: 5| Step: 1
Training loss: 2.2977498782218775
Validation loss: 2.5410237628060215

Epoch: 5| Step: 2
Training loss: 2.3136681364262066
Validation loss: 2.5195207330258955

Epoch: 5| Step: 3
Training loss: 2.138456596792071
Validation loss: 2.482759040579086

Epoch: 5| Step: 4
Training loss: 1.796543123861026
Validation loss: 2.4728000639676244

Epoch: 5| Step: 5
Training loss: 2.969020309188624
Validation loss: 2.470313832758087

Epoch: 5| Step: 6
Training loss: 2.328174360123239
Validation loss: 2.478226039018273

Epoch: 5| Step: 7
Training loss: 2.2566841236192463
Validation loss: 2.4757061206769886

Epoch: 5| Step: 8
Training loss: 2.43890887894062
Validation loss: 2.49453306393864

Epoch: 5| Step: 9
Training loss: 2.6472948698376335
Validation loss: 2.518555531340216

Epoch: 5| Step: 10
Training loss: 2.4347199456372968
Validation loss: 2.520205610184995

Epoch: 522| Step: 0
Training loss: 2.5049003258403357
Validation loss: 2.5251990256409753

Epoch: 5| Step: 1
Training loss: 1.677624309157927
Validation loss: 2.5365851825112604

Epoch: 5| Step: 2
Training loss: 1.9787095060560784
Validation loss: 2.5502151981555983

Epoch: 5| Step: 3
Training loss: 2.3055383178597637
Validation loss: 2.537313661028187

Epoch: 5| Step: 4
Training loss: 2.5927039185595344
Validation loss: 2.533484425381051

Epoch: 5| Step: 5
Training loss: 2.2781681511956204
Validation loss: 2.4977200335422434

Epoch: 5| Step: 6
Training loss: 2.3520273148449213
Validation loss: 2.4983474017145584

Epoch: 5| Step: 7
Training loss: 2.7196602010249933
Validation loss: 2.4792276709118806

Epoch: 5| Step: 8
Training loss: 2.3781161695359008
Validation loss: 2.470172232012329

Epoch: 5| Step: 9
Training loss: 2.2438893521954775
Validation loss: 2.4662065375173987

Epoch: 5| Step: 10
Training loss: 2.5849482093212326
Validation loss: 2.470911808742869

Epoch: 523| Step: 0
Training loss: 2.901411232731144
Validation loss: 2.476538940661302

Epoch: 5| Step: 1
Training loss: 2.409646745489744
Validation loss: 2.486105225252589

Epoch: 5| Step: 2
Training loss: 2.2054470081453568
Validation loss: 2.4994398145742007

Epoch: 5| Step: 3
Training loss: 2.3614283840959716
Validation loss: 2.521331187421384

Epoch: 5| Step: 4
Training loss: 2.286528033770579
Validation loss: 2.5206004707856033

Epoch: 5| Step: 5
Training loss: 1.9377707015403156
Validation loss: 2.546647135691824

Epoch: 5| Step: 6
Training loss: 1.8842509619533356
Validation loss: 2.545540165974405

Epoch: 5| Step: 7
Training loss: 2.441475975566833
Validation loss: 2.544635016415156

Epoch: 5| Step: 8
Training loss: 2.101195576341389
Validation loss: 2.5128361136703363

Epoch: 5| Step: 9
Training loss: 2.4105661498074795
Validation loss: 2.512292291892616

Epoch: 5| Step: 10
Training loss: 2.508293604826579
Validation loss: 2.4812953417587127

Epoch: 524| Step: 0
Training loss: 1.9064259057102149
Validation loss: 2.506089244669811

Epoch: 5| Step: 1
Training loss: 2.4905435048630404
Validation loss: 2.482501917581388

Epoch: 5| Step: 2
Training loss: 2.346716262589504
Validation loss: 2.4879602365654105

Epoch: 5| Step: 3
Training loss: 2.673979170484881
Validation loss: 2.5000424904442613

Epoch: 5| Step: 4
Training loss: 2.2156821519289416
Validation loss: 2.50254162316948

Epoch: 5| Step: 5
Training loss: 2.4584093459279712
Validation loss: 2.500763269010679

Epoch: 5| Step: 6
Training loss: 2.4140583519761085
Validation loss: 2.505544272620675

Epoch: 5| Step: 7
Training loss: 2.2983827378253805
Validation loss: 2.473901761006712

Epoch: 5| Step: 8
Training loss: 2.2045126799030372
Validation loss: 2.4650277129122253

Epoch: 5| Step: 9
Training loss: 2.2977150140048908
Validation loss: 2.462116945992894

Epoch: 5| Step: 10
Training loss: 2.2233362213680303
Validation loss: 2.4934807776954786

Epoch: 525| Step: 0
Training loss: 2.752520533181087
Validation loss: 2.5014107077211998

Epoch: 5| Step: 1
Training loss: 2.1029586975641936
Validation loss: 2.496172673257668

Epoch: 5| Step: 2
Training loss: 2.4856751117062363
Validation loss: 2.504528742887139

Epoch: 5| Step: 3
Training loss: 2.2273250947008454
Validation loss: 2.535166104473245

Epoch: 5| Step: 4
Training loss: 2.4296995696231063
Validation loss: 2.5359004952129225

Epoch: 5| Step: 5
Training loss: 2.453568242357152
Validation loss: 2.540483541967344

Epoch: 5| Step: 6
Training loss: 2.28522865637158
Validation loss: 2.5467159619940247

Epoch: 5| Step: 7
Training loss: 2.3647179138155496
Validation loss: 2.5448558540894957

Epoch: 5| Step: 8
Training loss: 2.346477295033122
Validation loss: 2.537568111446147

Epoch: 5| Step: 9
Training loss: 2.0849476726744314
Validation loss: 2.491966985389309

Epoch: 5| Step: 10
Training loss: 1.7145840180937588
Validation loss: 2.477661220341811

Epoch: 526| Step: 0
Training loss: 2.3821325113574727
Validation loss: 2.44152857136444

Epoch: 5| Step: 1
Training loss: 2.4646222336946035
Validation loss: 2.442214175583873

Epoch: 5| Step: 2
Training loss: 1.8368069801573426
Validation loss: 2.4692245407387463

Epoch: 5| Step: 3
Training loss: 1.945270951528249
Validation loss: 2.4753071186002367

Epoch: 5| Step: 4
Training loss: 2.348347642998001
Validation loss: 2.4833423730647564

Epoch: 5| Step: 5
Training loss: 2.1971565728146563
Validation loss: 2.50496240755763

Epoch: 5| Step: 6
Training loss: 2.764406269749611
Validation loss: 2.503583963265072

Epoch: 5| Step: 7
Training loss: 2.085011708983698
Validation loss: 2.5125571501800157

Epoch: 5| Step: 8
Training loss: 2.4434687576997454
Validation loss: 2.5209305318305733

Epoch: 5| Step: 9
Training loss: 2.2936671686418175
Validation loss: 2.5176103742391054

Epoch: 5| Step: 10
Training loss: 2.519505416382821
Validation loss: 2.5257084980194975

Epoch: 527| Step: 0
Training loss: 2.3321705941082427
Validation loss: 2.520478344537114

Epoch: 5| Step: 1
Training loss: 2.395943105643061
Validation loss: 2.5012830651418687

Epoch: 5| Step: 2
Training loss: 2.2748966319316843
Validation loss: 2.4711131339222163

Epoch: 5| Step: 3
Training loss: 2.3176725120490835
Validation loss: 2.455571626304127

Epoch: 5| Step: 4
Training loss: 2.185656397361923
Validation loss: 2.442972991485394

Epoch: 5| Step: 5
Training loss: 1.8152942822435816
Validation loss: 2.42286460365625

Epoch: 5| Step: 6
Training loss: 2.241912080550106
Validation loss: 2.433255237798868

Epoch: 5| Step: 7
Training loss: 2.589066378694713
Validation loss: 2.438392139336033

Epoch: 5| Step: 8
Training loss: 2.251024436855323
Validation loss: 2.45413446097275

Epoch: 5| Step: 9
Training loss: 2.2432514284929246
Validation loss: 2.481252174854862

Epoch: 5| Step: 10
Training loss: 2.7328933625338268
Validation loss: 2.4865935013006277

Epoch: 528| Step: 0
Training loss: 2.1910122603922617
Validation loss: 2.5278997710357025

Epoch: 5| Step: 1
Training loss: 2.6964331909255606
Validation loss: 2.57911807386927

Epoch: 5| Step: 2
Training loss: 2.251776311968635
Validation loss: 2.5629918796631412

Epoch: 5| Step: 3
Training loss: 2.477033022879499
Validation loss: 2.551042871963126

Epoch: 5| Step: 4
Training loss: 1.9795130242566994
Validation loss: 2.529494905259922

Epoch: 5| Step: 5
Training loss: 1.9734657364106591
Validation loss: 2.5226243186818498

Epoch: 5| Step: 6
Training loss: 2.2575078316486157
Validation loss: 2.4862932397162596

Epoch: 5| Step: 7
Training loss: 2.3684306389910232
Validation loss: 2.481798792385878

Epoch: 5| Step: 8
Training loss: 2.143355695312189
Validation loss: 2.4790783658998103

Epoch: 5| Step: 9
Training loss: 2.299508485934763
Validation loss: 2.4679531443282063

Epoch: 5| Step: 10
Training loss: 2.793716949335664
Validation loss: 2.47530148083772

Epoch: 529| Step: 0
Training loss: 2.410292363457958
Validation loss: 2.503210639479511

Epoch: 5| Step: 1
Training loss: 2.4060015859812696
Validation loss: 2.513936164734888

Epoch: 5| Step: 2
Training loss: 2.12960843046513
Validation loss: 2.544237703134595

Epoch: 5| Step: 3
Training loss: 2.5348068490264377
Validation loss: 2.5644217807422582

Epoch: 5| Step: 4
Training loss: 2.3655740508182754
Validation loss: 2.5856812439397032

Epoch: 5| Step: 5
Training loss: 1.9711078269839868
Validation loss: 2.5937362474832315

Epoch: 5| Step: 6
Training loss: 2.564658395725945
Validation loss: 2.555572650448604

Epoch: 5| Step: 7
Training loss: 2.1256305656595784
Validation loss: 2.5381520345113975

Epoch: 5| Step: 8
Training loss: 2.024820451664965
Validation loss: 2.482878366991349

Epoch: 5| Step: 9
Training loss: 2.4940739012585342
Validation loss: 2.453005753652065

Epoch: 5| Step: 10
Training loss: 2.1315538654004302
Validation loss: 2.4346133099082667

Epoch: 530| Step: 0
Training loss: 2.3749089474540934
Validation loss: 2.450771012011663

Epoch: 5| Step: 1
Training loss: 2.5555635869088875
Validation loss: 2.435927930326089

Epoch: 5| Step: 2
Training loss: 1.9501102832028352
Validation loss: 2.460297015251213

Epoch: 5| Step: 3
Training loss: 2.4490705868138587
Validation loss: 2.4804135412755084

Epoch: 5| Step: 4
Training loss: 2.0640498031699286
Validation loss: 2.4892363486465716

Epoch: 5| Step: 5
Training loss: 2.1665201382118155
Validation loss: 2.478417573345609

Epoch: 5| Step: 6
Training loss: 2.550123705387792
Validation loss: 2.518920405176843

Epoch: 5| Step: 7
Training loss: 2.000813676302482
Validation loss: 2.573206449101205

Epoch: 5| Step: 8
Training loss: 2.343798624170093
Validation loss: 2.600261181080775

Epoch: 5| Step: 9
Training loss: 2.0705548990244784
Validation loss: 2.5869750045273525

Epoch: 5| Step: 10
Training loss: 2.7941991696703328
Validation loss: 2.573141944478342

Epoch: 531| Step: 0
Training loss: 2.547563705471378
Validation loss: 2.574644805602528

Epoch: 5| Step: 1
Training loss: 2.161374402235907
Validation loss: 2.532984623470486

Epoch: 5| Step: 2
Training loss: 2.022720858064013
Validation loss: 2.496886827355974

Epoch: 5| Step: 3
Training loss: 2.4290827645610187
Validation loss: 2.4889640502975547

Epoch: 5| Step: 4
Training loss: 2.3772959403183282
Validation loss: 2.4780072356573655

Epoch: 5| Step: 5
Training loss: 2.616419801993027
Validation loss: 2.4790423113797315

Epoch: 5| Step: 6
Training loss: 2.054189643447644
Validation loss: 2.4783236482755133

Epoch: 5| Step: 7
Training loss: 1.8321971045536265
Validation loss: 2.4920796538719143

Epoch: 5| Step: 8
Training loss: 2.496283056874084
Validation loss: 2.4941424782404717

Epoch: 5| Step: 9
Training loss: 2.07109843756837
Validation loss: 2.4920008653739223

Epoch: 5| Step: 10
Training loss: 2.575799436450052
Validation loss: 2.4894923518190106

Epoch: 532| Step: 0
Training loss: 2.127866382541315
Validation loss: 2.5037116277968336

Epoch: 5| Step: 1
Training loss: 2.331416216695331
Validation loss: 2.51699491374579

Epoch: 5| Step: 2
Training loss: 2.469633692710697
Validation loss: 2.517066187081166

Epoch: 5| Step: 3
Training loss: 2.0922927339966337
Validation loss: 2.5274088153919996

Epoch: 5| Step: 4
Training loss: 1.799892909785006
Validation loss: 2.5400629815941023

Epoch: 5| Step: 5
Training loss: 2.4671929193283777
Validation loss: 2.539216948072149

Epoch: 5| Step: 6
Training loss: 1.8740752800891656
Validation loss: 2.5418541350102717

Epoch: 5| Step: 7
Training loss: 2.2694466816416305
Validation loss: 2.51327691324645

Epoch: 5| Step: 8
Training loss: 2.580291023104955
Validation loss: 2.5121499784814363

Epoch: 5| Step: 9
Training loss: 2.2524697206686923
Validation loss: 2.4989876399643047

Epoch: 5| Step: 10
Training loss: 2.569986618393077
Validation loss: 2.4865355633918065

Epoch: 533| Step: 0
Training loss: 2.287149613024027
Validation loss: 2.4669445077032286

Epoch: 5| Step: 1
Training loss: 2.834955723330978
Validation loss: 2.4671760070076303

Epoch: 5| Step: 2
Training loss: 2.630189851500789
Validation loss: 2.4552387154972504

Epoch: 5| Step: 3
Training loss: 2.2133518152537697
Validation loss: 2.4467670222235105

Epoch: 5| Step: 4
Training loss: 2.3024157691153113
Validation loss: 2.4617200694152537

Epoch: 5| Step: 5
Training loss: 2.104325757448959
Validation loss: 2.448870407930099

Epoch: 5| Step: 6
Training loss: 2.1104327905107376
Validation loss: 2.4743550718327376

Epoch: 5| Step: 7
Training loss: 2.2356627694710194
Validation loss: 2.4979533175145687

Epoch: 5| Step: 8
Training loss: 1.7586873907835288
Validation loss: 2.5300022312556383

Epoch: 5| Step: 9
Training loss: 2.1484994220479856
Validation loss: 2.5461965895847425

Epoch: 5| Step: 10
Training loss: 2.190401387467652
Validation loss: 2.556012400662257

Epoch: 534| Step: 0
Training loss: 2.0575036305874095
Validation loss: 2.539981392929605

Epoch: 5| Step: 1
Training loss: 2.340864719801974
Validation loss: 2.5224941731479786

Epoch: 5| Step: 2
Training loss: 1.9426781155142627
Validation loss: 2.5132343425755264

Epoch: 5| Step: 3
Training loss: 2.0475828388303507
Validation loss: 2.5129716439363436

Epoch: 5| Step: 4
Training loss: 2.3449351048386267
Validation loss: 2.507243317793056

Epoch: 5| Step: 5
Training loss: 1.7407386126328634
Validation loss: 2.4978319283255286

Epoch: 5| Step: 6
Training loss: 2.315040224191369
Validation loss: 2.492457059933713

Epoch: 5| Step: 7
Training loss: 2.594754128099718
Validation loss: 2.4739310024200383

Epoch: 5| Step: 8
Training loss: 2.3727996069413293
Validation loss: 2.4920883861070076

Epoch: 5| Step: 9
Training loss: 2.5715863164321995
Validation loss: 2.4853391194819308

Epoch: 5| Step: 10
Training loss: 2.4639954958787844
Validation loss: 2.490345475808722

Epoch: 535| Step: 0
Training loss: 2.292074155703017
Validation loss: 2.508907726688861

Epoch: 5| Step: 1
Training loss: 2.4518847397789
Validation loss: 2.5332110693086243

Epoch: 5| Step: 2
Training loss: 1.4866941304656567
Validation loss: 2.5415484550363585

Epoch: 5| Step: 3
Training loss: 2.236281002164551
Validation loss: 2.5560568746108436

Epoch: 5| Step: 4
Training loss: 2.377427717487933
Validation loss: 2.5306626578716265

Epoch: 5| Step: 5
Training loss: 2.6649615876541026
Validation loss: 2.507551081794323

Epoch: 5| Step: 6
Training loss: 2.009683531334763
Validation loss: 2.4676835776199484

Epoch: 5| Step: 7
Training loss: 2.4093755264380605
Validation loss: 2.4551549271926363

Epoch: 5| Step: 8
Training loss: 2.061822606600793
Validation loss: 2.4555629343858554

Epoch: 5| Step: 9
Training loss: 2.3009155441494573
Validation loss: 2.4419252997470062

Epoch: 5| Step: 10
Training loss: 2.46916793955387
Validation loss: 2.437469596873015

Epoch: 536| Step: 0
Training loss: 2.625940971658217
Validation loss: 2.4478465467964527

Epoch: 5| Step: 1
Training loss: 2.0040625795655536
Validation loss: 2.4439266109018907

Epoch: 5| Step: 2
Training loss: 2.5386545645855434
Validation loss: 2.461024775913159

Epoch: 5| Step: 3
Training loss: 2.346026014835807
Validation loss: 2.4577613368121094

Epoch: 5| Step: 4
Training loss: 2.129104017118574
Validation loss: 2.4696249687958844

Epoch: 5| Step: 5
Training loss: 2.023026118933456
Validation loss: 2.5020479489440666

Epoch: 5| Step: 6
Training loss: 2.4119941220567735
Validation loss: 2.5221927678717555

Epoch: 5| Step: 7
Training loss: 2.467985493553968
Validation loss: 2.5307153319150957

Epoch: 5| Step: 8
Training loss: 2.0917469520915937
Validation loss: 2.5455030989967034

Epoch: 5| Step: 9
Training loss: 2.3252788786629246
Validation loss: 2.490894403013613

Epoch: 5| Step: 10
Training loss: 1.7446324593705071
Validation loss: 2.476137385046542

Epoch: 537| Step: 0
Training loss: 2.179384162605701
Validation loss: 2.46749364334496

Epoch: 5| Step: 1
Training loss: 2.368347488063935
Validation loss: 2.462481145941186

Epoch: 5| Step: 2
Training loss: 2.353258908781661
Validation loss: 2.466623858305148

Epoch: 5| Step: 3
Training loss: 1.9742049077480506
Validation loss: 2.468465154914953

Epoch: 5| Step: 4
Training loss: 2.4169693022906458
Validation loss: 2.469894910063642

Epoch: 5| Step: 5
Training loss: 2.1784893283963473
Validation loss: 2.4954142915668047

Epoch: 5| Step: 6
Training loss: 2.6510461433737578
Validation loss: 2.530943866844479

Epoch: 5| Step: 7
Training loss: 2.4890174914335885
Validation loss: 2.5631351399138294

Epoch: 5| Step: 8
Training loss: 2.1279736077098943
Validation loss: 2.5795647730997504

Epoch: 5| Step: 9
Training loss: 1.6879937191435044
Validation loss: 2.591101300075414

Epoch: 5| Step: 10
Training loss: 2.1535616715641046
Validation loss: 2.587167209860851

Epoch: 538| Step: 0
Training loss: 2.018112303929281
Validation loss: 2.6047571575159125

Epoch: 5| Step: 1
Training loss: 2.152090621990061
Validation loss: 2.5932938151969727

Epoch: 5| Step: 2
Training loss: 2.1169943633439208
Validation loss: 2.582852280755968

Epoch: 5| Step: 3
Training loss: 2.066681985900871
Validation loss: 2.538862949099195

Epoch: 5| Step: 4
Training loss: 2.607456712811507
Validation loss: 2.5177033295702325

Epoch: 5| Step: 5
Training loss: 1.7109242617299636
Validation loss: 2.5070022778436094

Epoch: 5| Step: 6
Training loss: 2.248243069808054
Validation loss: 2.4734602729374466

Epoch: 5| Step: 7
Training loss: 2.4927390513670797
Validation loss: 2.476267500913563

Epoch: 5| Step: 8
Training loss: 2.2652326573001766
Validation loss: 2.455552495273568

Epoch: 5| Step: 9
Training loss: 2.0134656117839276
Validation loss: 2.452407123655638

Epoch: 5| Step: 10
Training loss: 2.87449940179383
Validation loss: 2.4701183613630984

Epoch: 539| Step: 0
Training loss: 2.5891509129053456
Validation loss: 2.4840507148633186

Epoch: 5| Step: 1
Training loss: 1.9184130991048667
Validation loss: 2.4775624167620207

Epoch: 5| Step: 2
Training loss: 1.7229928100931857
Validation loss: 2.4880704446123536

Epoch: 5| Step: 3
Training loss: 2.394468322225746
Validation loss: 2.5015174054871974

Epoch: 5| Step: 4
Training loss: 2.338433300699177
Validation loss: 2.5332682028279554

Epoch: 5| Step: 5
Training loss: 2.1311106616698052
Validation loss: 2.54623515873468

Epoch: 5| Step: 6
Training loss: 1.7929944138362772
Validation loss: 2.536642446205712

Epoch: 5| Step: 7
Training loss: 2.7040116283798734
Validation loss: 2.552450426298089

Epoch: 5| Step: 8
Training loss: 2.442089259929025
Validation loss: 2.5311806913746917

Epoch: 5| Step: 9
Training loss: 2.1595948302002026
Validation loss: 2.5285965737792195

Epoch: 5| Step: 10
Training loss: 2.182841217354548
Validation loss: 2.5087464320252786

Epoch: 540| Step: 0
Training loss: 2.410400971735503
Validation loss: 2.4872418888130268

Epoch: 5| Step: 1
Training loss: 1.9650467451131375
Validation loss: 2.4703906500653274

Epoch: 5| Step: 2
Training loss: 2.1276011535050445
Validation loss: 2.4647713550405594

Epoch: 5| Step: 3
Training loss: 2.15129149481715
Validation loss: 2.4654386719095402

Epoch: 5| Step: 4
Training loss: 2.319232727966766
Validation loss: 2.480663801616035

Epoch: 5| Step: 5
Training loss: 1.9749947463339934
Validation loss: 2.5166883494450807

Epoch: 5| Step: 6
Training loss: 2.2852066425733746
Validation loss: 2.526832830315678

Epoch: 5| Step: 7
Training loss: 2.0397554002239877
Validation loss: 2.519343561811601

Epoch: 5| Step: 8
Training loss: 2.5065287218622707
Validation loss: 2.5320674387070508

Epoch: 5| Step: 9
Training loss: 2.356262174620404
Validation loss: 2.541366704356704

Epoch: 5| Step: 10
Training loss: 2.337175634389484
Validation loss: 2.5319964119745593

Epoch: 541| Step: 0
Training loss: 1.3318566798038087
Validation loss: 2.522652763621629

Epoch: 5| Step: 1
Training loss: 2.451519483258176
Validation loss: 2.517606702306797

Epoch: 5| Step: 2
Training loss: 2.3548289579896706
Validation loss: 2.50851767759292

Epoch: 5| Step: 3
Training loss: 2.0550084316702546
Validation loss: 2.5118087252054777

Epoch: 5| Step: 4
Training loss: 2.2929302777729696
Validation loss: 2.497969252768803

Epoch: 5| Step: 5
Training loss: 1.7578744834991913
Validation loss: 2.502159660944087

Epoch: 5| Step: 6
Training loss: 1.9532113018042492
Validation loss: 2.510422229484107

Epoch: 5| Step: 7
Training loss: 2.675044538893642
Validation loss: 2.5264924466152743

Epoch: 5| Step: 8
Training loss: 2.6568677296131833
Validation loss: 2.526061368881706

Epoch: 5| Step: 9
Training loss: 2.49081086311232
Validation loss: 2.5462956567636903

Epoch: 5| Step: 10
Training loss: 2.081912268124954
Validation loss: 2.5474666328784554

Epoch: 542| Step: 0
Training loss: 1.6764281120371642
Validation loss: 2.524609510624876

Epoch: 5| Step: 1
Training loss: 2.4737876967092167
Validation loss: 2.5007234121478614

Epoch: 5| Step: 2
Training loss: 2.455158532767387
Validation loss: 2.4839814547001247

Epoch: 5| Step: 3
Training loss: 1.9237416824051947
Validation loss: 2.4997838542160458

Epoch: 5| Step: 4
Training loss: 2.2447791456919206
Validation loss: 2.4806588121170843

Epoch: 5| Step: 5
Training loss: 2.3448790818782896
Validation loss: 2.4458861336212383

Epoch: 5| Step: 6
Training loss: 2.2466687867846047
Validation loss: 2.4529641572041503

Epoch: 5| Step: 7
Training loss: 2.3812943421888493
Validation loss: 2.4622331814412024

Epoch: 5| Step: 8
Training loss: 2.2417044833750257
Validation loss: 2.465959686788247

Epoch: 5| Step: 9
Training loss: 2.08781594266866
Validation loss: 2.477157365538946

Epoch: 5| Step: 10
Training loss: 2.120936041882476
Validation loss: 2.4893176375989703

Epoch: 543| Step: 0
Training loss: 1.9701596012430356
Validation loss: 2.5135291674687235

Epoch: 5| Step: 1
Training loss: 2.0422444855868536
Validation loss: 2.5294884401413404

Epoch: 5| Step: 2
Training loss: 2.10820800147377
Validation loss: 2.554158875355263

Epoch: 5| Step: 3
Training loss: 2.2375844033800725
Validation loss: 2.550189378813196

Epoch: 5| Step: 4
Training loss: 2.520793462600875
Validation loss: 2.5618425701941647

Epoch: 5| Step: 5
Training loss: 2.083779122023811
Validation loss: 2.5475656094105257

Epoch: 5| Step: 6
Training loss: 2.0917956212429134
Validation loss: 2.510497447832165

Epoch: 5| Step: 7
Training loss: 2.015480686906226
Validation loss: 2.4635970758893238

Epoch: 5| Step: 8
Training loss: 2.0879587959886416
Validation loss: 2.4363471018981953

Epoch: 5| Step: 9
Training loss: 2.7739021019578787
Validation loss: 2.417824091069562

Epoch: 5| Step: 10
Training loss: 2.3949016141493327
Validation loss: 2.4076978761928154

Epoch: 544| Step: 0
Training loss: 2.16327264466508
Validation loss: 2.4080459610908025

Epoch: 5| Step: 1
Training loss: 2.2524737428749995
Validation loss: 2.42724955753288

Epoch: 5| Step: 2
Training loss: 2.296371923873907
Validation loss: 2.4572479211463607

Epoch: 5| Step: 3
Training loss: 2.246563512356432
Validation loss: 2.4875146323004693

Epoch: 5| Step: 4
Training loss: 1.6792694281220455
Validation loss: 2.5243797319746464

Epoch: 5| Step: 5
Training loss: 2.273229740258527
Validation loss: 2.5429018587505396

Epoch: 5| Step: 6
Training loss: 2.6656674559455564
Validation loss: 2.5721606769340997

Epoch: 5| Step: 7
Training loss: 2.2735729898146326
Validation loss: 2.5808588850507066

Epoch: 5| Step: 8
Training loss: 2.079690787916787
Validation loss: 2.6055559802751587

Epoch: 5| Step: 9
Training loss: 2.4464063056672427
Validation loss: 2.5870210628883967

Epoch: 5| Step: 10
Training loss: 2.15488180345304
Validation loss: 2.5421430651337125

Epoch: 545| Step: 0
Training loss: 2.405923994695076
Validation loss: 2.5206867874765386

Epoch: 5| Step: 1
Training loss: 1.8969198055097523
Validation loss: 2.492251829158742

Epoch: 5| Step: 2
Training loss: 2.1361568625711946
Validation loss: 2.4582468882845094

Epoch: 5| Step: 3
Training loss: 1.6767481435364786
Validation loss: 2.4702372102462444

Epoch: 5| Step: 4
Training loss: 2.1517541427421736
Validation loss: 2.4540734376279945

Epoch: 5| Step: 5
Training loss: 2.597008095095198
Validation loss: 2.4779492490731725

Epoch: 5| Step: 6
Training loss: 2.5632486877884517
Validation loss: 2.473919520610671

Epoch: 5| Step: 7
Training loss: 2.1820184966089213
Validation loss: 2.4961084307672916

Epoch: 5| Step: 8
Training loss: 1.934753933029229
Validation loss: 2.491665794061545

Epoch: 5| Step: 9
Training loss: 2.495533195199921
Validation loss: 2.4996258599259025

Epoch: 5| Step: 10
Training loss: 2.078762100193685
Validation loss: 2.510524147158901

Epoch: 546| Step: 0
Training loss: 2.2545177879621603
Validation loss: 2.5273034237299514

Epoch: 5| Step: 1
Training loss: 2.1373658255242924
Validation loss: 2.530316335482005

Epoch: 5| Step: 2
Training loss: 1.7418136537697189
Validation loss: 2.547616870323944

Epoch: 5| Step: 3
Training loss: 2.4486522353997064
Validation loss: 2.5461266467110786

Epoch: 5| Step: 4
Training loss: 2.196131977520752
Validation loss: 2.5316514872017364

Epoch: 5| Step: 5
Training loss: 2.575018843794825
Validation loss: 2.5001295897008826

Epoch: 5| Step: 6
Training loss: 1.9513455639151671
Validation loss: 2.488323738620274

Epoch: 5| Step: 7
Training loss: 2.2827166715400438
Validation loss: 2.4601162135278365

Epoch: 5| Step: 8
Training loss: 1.9334710592782738
Validation loss: 2.468434864188997

Epoch: 5| Step: 9
Training loss: 2.353734227075466
Validation loss: 2.442761007895

Epoch: 5| Step: 10
Training loss: 2.1158828375384924
Validation loss: 2.4566003278187525

Epoch: 547| Step: 0
Training loss: 2.064666534913235
Validation loss: 2.4660232457515754

Epoch: 5| Step: 1
Training loss: 1.7969924888347721
Validation loss: 2.463958079794685

Epoch: 5| Step: 2
Training loss: 2.5342547631581644
Validation loss: 2.4835861314683294

Epoch: 5| Step: 3
Training loss: 2.432914724878929
Validation loss: 2.477453886388773

Epoch: 5| Step: 4
Training loss: 2.2937764137680556
Validation loss: 2.4881824055157744

Epoch: 5| Step: 5
Training loss: 2.25540328266094
Validation loss: 2.522763800491167

Epoch: 5| Step: 6
Training loss: 1.7998790011533343
Validation loss: 2.5333097426293514

Epoch: 5| Step: 7
Training loss: 2.71270272336809
Validation loss: 2.5362126266622513

Epoch: 5| Step: 8
Training loss: 1.9068460626947774
Validation loss: 2.5335180304587066

Epoch: 5| Step: 9
Training loss: 2.1828784624098594
Validation loss: 2.498281810331861

Epoch: 5| Step: 10
Training loss: 1.934637600972008
Validation loss: 2.482332038307533

Epoch: 548| Step: 0
Training loss: 1.7649359920015306
Validation loss: 2.4902336399528484

Epoch: 5| Step: 1
Training loss: 2.5447909013328283
Validation loss: 2.4927524766290294

Epoch: 5| Step: 2
Training loss: 2.2721816326931794
Validation loss: 2.4936085163725368

Epoch: 5| Step: 3
Training loss: 1.776765498739833
Validation loss: 2.500454548561889

Epoch: 5| Step: 4
Training loss: 1.9843080163899207
Validation loss: 2.507535760536777

Epoch: 5| Step: 5
Training loss: 1.92722159912069
Validation loss: 2.5081471017517405

Epoch: 5| Step: 6
Training loss: 1.9831727959337013
Validation loss: 2.518855347482833

Epoch: 5| Step: 7
Training loss: 1.908439816775992
Validation loss: 2.5029737321670122

Epoch: 5| Step: 8
Training loss: 2.469540336710436
Validation loss: 2.504160132034564

Epoch: 5| Step: 9
Training loss: 2.7658211159002875
Validation loss: 2.5091814704149056

Epoch: 5| Step: 10
Training loss: 2.313189120327732
Validation loss: 2.5237332387309284

Epoch: 549| Step: 0
Training loss: 2.3233706682107047
Validation loss: 2.5283856904044306

Epoch: 5| Step: 1
Training loss: 2.2841181035279803
Validation loss: 2.536621673358732

Epoch: 5| Step: 2
Training loss: 2.735088059229893
Validation loss: 2.5252820446610924

Epoch: 5| Step: 3
Training loss: 1.7770513608440694
Validation loss: 2.5118832707908147

Epoch: 5| Step: 4
Training loss: 1.8681690397460486
Validation loss: 2.4865717113368864

Epoch: 5| Step: 5
Training loss: 2.3445960997193294
Validation loss: 2.5031016070545977

Epoch: 5| Step: 6
Training loss: 2.515765357988757
Validation loss: 2.4762918631016766

Epoch: 5| Step: 7
Training loss: 2.0359965107256475
Validation loss: 2.467548268426612

Epoch: 5| Step: 8
Training loss: 2.184271255234311
Validation loss: 2.480553665496949

Epoch: 5| Step: 9
Training loss: 1.8312339755974845
Validation loss: 2.5158787337425053

Epoch: 5| Step: 10
Training loss: 1.7809717061335073
Validation loss: 2.484625722882638

Epoch: 550| Step: 0
Training loss: 2.5391243795043805
Validation loss: 2.5012229696855774

Epoch: 5| Step: 1
Training loss: 1.642726533152362
Validation loss: 2.523680651583806

Epoch: 5| Step: 2
Training loss: 2.461476100535177
Validation loss: 2.4962150388534323

Epoch: 5| Step: 3
Training loss: 1.852333198173005
Validation loss: 2.5065918504420295

Epoch: 5| Step: 4
Training loss: 1.7847580747388312
Validation loss: 2.5102992700301296

Epoch: 5| Step: 5
Training loss: 1.9546486366610505
Validation loss: 2.496316456196633

Epoch: 5| Step: 6
Training loss: 1.9314670156871376
Validation loss: 2.4906972134507472

Epoch: 5| Step: 7
Training loss: 2.1677648499976314
Validation loss: 2.504711466068467

Epoch: 5| Step: 8
Training loss: 2.6068620287897852
Validation loss: 2.501192036356661

Epoch: 5| Step: 9
Training loss: 2.3106048654097426
Validation loss: 2.517838805554618

Epoch: 5| Step: 10
Training loss: 2.433824849674944
Validation loss: 2.5184872109224714

Testing loss: 2.8036185009851398
