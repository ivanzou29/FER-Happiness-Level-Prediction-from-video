Epoch: 1| Step: 0
Training loss: 6.0280987507123545
Validation loss: 5.765527686548314

Epoch: 5| Step: 1
Training loss: 5.683481662339762
Validation loss: 5.754902859607594

Epoch: 5| Step: 2
Training loss: 5.500513572990289
Validation loss: 5.7442583270088425

Epoch: 5| Step: 3
Training loss: 7.576128069285576
Validation loss: 5.734047359657932

Epoch: 5| Step: 4
Training loss: 5.990098412522053
Validation loss: 5.724404835737734

Epoch: 5| Step: 5
Training loss: 4.615482951608305
Validation loss: 5.714548151667

Epoch: 5| Step: 6
Training loss: 4.184047357382366
Validation loss: 5.7048939019164635

Epoch: 5| Step: 7
Training loss: 5.216717535548875
Validation loss: 5.695407224924915

Epoch: 5| Step: 8
Training loss: 6.197349646353686
Validation loss: 5.684786935919917

Epoch: 5| Step: 9
Training loss: 5.280157393797223
Validation loss: 5.673800765351697

Epoch: 5| Step: 10
Training loss: 6.3907787052687715
Validation loss: 5.661660816625108

Epoch: 2| Step: 0
Training loss: 5.1995483569099274
Validation loss: 5.648556775046549

Epoch: 5| Step: 1
Training loss: 6.100831597347956
Validation loss: 5.63493484160806

Epoch: 5| Step: 2
Training loss: 6.133782143688384
Validation loss: 5.619552756701605

Epoch: 5| Step: 3
Training loss: 5.436745076006817
Validation loss: 5.602849943869265

Epoch: 5| Step: 4
Training loss: 4.861617671670413
Validation loss: 5.584763059947509

Epoch: 5| Step: 5
Training loss: 5.246000310388077
Validation loss: 5.5661020316910905

Epoch: 5| Step: 6
Training loss: 6.1671164408751435
Validation loss: 5.545296960818041

Epoch: 5| Step: 7
Training loss: 6.385737931185498
Validation loss: 5.523371721883701

Epoch: 5| Step: 8
Training loss: 4.994441184859768
Validation loss: 5.4993512730305305

Epoch: 5| Step: 9
Training loss: 5.4906359633899156
Validation loss: 5.4731778334740735

Epoch: 5| Step: 10
Training loss: 5.285894033697009
Validation loss: 5.445278380241728

Epoch: 3| Step: 0
Training loss: 5.022623758571412
Validation loss: 5.415687384796777

Epoch: 5| Step: 1
Training loss: 5.042006089736064
Validation loss: 5.384358498135078

Epoch: 5| Step: 2
Training loss: 4.882355056697352
Validation loss: 5.350690681588736

Epoch: 5| Step: 3
Training loss: 5.937379855897941
Validation loss: 5.315004754058601

Epoch: 5| Step: 4
Training loss: 4.456260460711556
Validation loss: 5.2778668922682845

Epoch: 5| Step: 5
Training loss: 4.355706972184775
Validation loss: 5.23900525888923

Epoch: 5| Step: 6
Training loss: 5.699197665849451
Validation loss: 5.200496801225233

Epoch: 5| Step: 7
Training loss: 5.791565306437498
Validation loss: 5.160227333734272

Epoch: 5| Step: 8
Training loss: 5.233370647580863
Validation loss: 5.1165276284884325

Epoch: 5| Step: 9
Training loss: 6.230862423887255
Validation loss: 5.075862542199912

Epoch: 5| Step: 10
Training loss: 5.006564980264545
Validation loss: 5.034858151209713

Epoch: 4| Step: 0
Training loss: 4.769553844451498
Validation loss: 4.9940606742882085

Epoch: 5| Step: 1
Training loss: 4.178847297998604
Validation loss: 4.952182779403305

Epoch: 5| Step: 2
Training loss: 4.731134394615324
Validation loss: 4.912732006603016

Epoch: 5| Step: 3
Training loss: 5.3521737076833364
Validation loss: 4.872256512229956

Epoch: 5| Step: 4
Training loss: 5.122183793577261
Validation loss: 4.833894895717955

Epoch: 5| Step: 5
Training loss: 4.82678836233529
Validation loss: 4.793821113545504

Epoch: 5| Step: 6
Training loss: 5.881922113685699
Validation loss: 4.753642921314419

Epoch: 5| Step: 7
Training loss: 4.463664969748312
Validation loss: 4.709762357832814

Epoch: 5| Step: 8
Training loss: 4.726546963752876
Validation loss: 4.6664419398423025

Epoch: 5| Step: 9
Training loss: 4.817416763418018
Validation loss: 4.624052172882308

Epoch: 5| Step: 10
Training loss: 4.389854064809803
Validation loss: 4.589116963287612

Epoch: 5| Step: 0
Training loss: 4.730362504290456
Validation loss: 4.556516753193992

Epoch: 5| Step: 1
Training loss: 4.467478324440501
Validation loss: 4.528452694441882

Epoch: 5| Step: 2
Training loss: 5.391594929441446
Validation loss: 4.498344910037024

Epoch: 5| Step: 3
Training loss: 2.5596273183751124
Validation loss: 4.468283127114531

Epoch: 5| Step: 4
Training loss: 3.933949640988307
Validation loss: 4.440435870814234

Epoch: 5| Step: 5
Training loss: 4.235239764095416
Validation loss: 4.413419960786988

Epoch: 5| Step: 6
Training loss: 5.452376087430076
Validation loss: 4.384932343970629

Epoch: 5| Step: 7
Training loss: 5.223096488024874
Validation loss: 4.357850068166604

Epoch: 5| Step: 8
Training loss: 4.924089593538618
Validation loss: 4.3273285341411585

Epoch: 5| Step: 9
Training loss: 3.695713787589655
Validation loss: 4.297805370986061

Epoch: 5| Step: 10
Training loss: 4.277842258336208
Validation loss: 4.266998491791801

Epoch: 6| Step: 0
Training loss: 4.112342604202127
Validation loss: 4.242009534773938

Epoch: 5| Step: 1
Training loss: 4.9940873472544345
Validation loss: 4.218890922984973

Epoch: 5| Step: 2
Training loss: 4.65796071827345
Validation loss: 4.197564949445325

Epoch: 5| Step: 3
Training loss: 4.8724683399062405
Validation loss: 4.177503373465213

Epoch: 5| Step: 4
Training loss: 4.706650942559133
Validation loss: 4.153497248635141

Epoch: 5| Step: 5
Training loss: 3.50517272175369
Validation loss: 4.132862750074995

Epoch: 5| Step: 6
Training loss: 4.888783458574739
Validation loss: 4.1139197420233335

Epoch: 5| Step: 7
Training loss: 4.665533246047091
Validation loss: 4.0981600548371295

Epoch: 5| Step: 8
Training loss: 4.511921878882401
Validation loss: 4.082581131650931

Epoch: 5| Step: 9
Training loss: 2.4412640583592586
Validation loss: 4.064080571228841

Epoch: 5| Step: 10
Training loss: 2.4860276777118484
Validation loss: 4.0483013627392435

Epoch: 7| Step: 0
Training loss: 4.106864365323152
Validation loss: 4.030256851899914

Epoch: 5| Step: 1
Training loss: 4.040908008173111
Validation loss: 4.017525659583572

Epoch: 5| Step: 2
Training loss: 4.507622303247617
Validation loss: 3.9995053431537526

Epoch: 5| Step: 3
Training loss: 3.4728884367242645
Validation loss: 3.9858218714548834

Epoch: 5| Step: 4
Training loss: 3.6015353584508074
Validation loss: 3.972444083263496

Epoch: 5| Step: 5
Training loss: 4.644710296696057
Validation loss: 3.9583809340787863

Epoch: 5| Step: 6
Training loss: 3.0222891270331522
Validation loss: 3.9404167470594866

Epoch: 5| Step: 7
Training loss: 3.6293866154751058
Validation loss: 3.9219609994565396

Epoch: 5| Step: 8
Training loss: 4.837505622485932
Validation loss: 3.909841383693003

Epoch: 5| Step: 9
Training loss: 4.538000300965987
Validation loss: 3.89511264577109

Epoch: 5| Step: 10
Training loss: 4.453895475424391
Validation loss: 3.8821550880143194

Epoch: 8| Step: 0
Training loss: 3.4761002479732888
Validation loss: 3.86728026808212

Epoch: 5| Step: 1
Training loss: 3.4575881768027568
Validation loss: 3.854288182536648

Epoch: 5| Step: 2
Training loss: 3.7118611360834737
Validation loss: 3.843627901069692

Epoch: 5| Step: 3
Training loss: 4.058424093392184
Validation loss: 3.8300912829459746

Epoch: 5| Step: 4
Training loss: 4.660033871114205
Validation loss: 3.819678327025249

Epoch: 5| Step: 5
Training loss: 5.101900472150978
Validation loss: 3.8093805917760424

Epoch: 5| Step: 6
Training loss: 3.9487577295665437
Validation loss: 3.7989466943628374

Epoch: 5| Step: 7
Training loss: 3.974445011573869
Validation loss: 3.7881637510389905

Epoch: 5| Step: 8
Training loss: 4.549190809795274
Validation loss: 3.779634547418304

Epoch: 5| Step: 9
Training loss: 3.3541056625473544
Validation loss: 3.771352597692497

Epoch: 5| Step: 10
Training loss: 2.823037476904673
Validation loss: 3.7624141221757053

Epoch: 9| Step: 0
Training loss: 3.895945637490123
Validation loss: 3.752675366158718

Epoch: 5| Step: 1
Training loss: 3.820995433589999
Validation loss: 3.746137721990457

Epoch: 5| Step: 2
Training loss: 4.297970164057439
Validation loss: 3.7391518279810847

Epoch: 5| Step: 3
Training loss: 3.9155403438589684
Validation loss: 3.73240156320522

Epoch: 5| Step: 4
Training loss: 3.937819452799567
Validation loss: 3.723864713708669

Epoch: 5| Step: 5
Training loss: 3.9453844120534707
Validation loss: 3.7159543116297513

Epoch: 5| Step: 6
Training loss: 3.6682362809284417
Validation loss: 3.7088299997431906

Epoch: 5| Step: 7
Training loss: 3.7500617975865107
Validation loss: 3.7039885975762687

Epoch: 5| Step: 8
Training loss: 4.630097750132415
Validation loss: 3.697057763540434

Epoch: 5| Step: 9
Training loss: 3.664133294891764
Validation loss: 3.689318464903809

Epoch: 5| Step: 10
Training loss: 3.0931576248393893
Validation loss: 3.680852132281649

Epoch: 10| Step: 0
Training loss: 3.985701037383438
Validation loss: 3.6727148390274533

Epoch: 5| Step: 1
Training loss: 4.286050374613055
Validation loss: 3.6653535543471207

Epoch: 5| Step: 2
Training loss: 3.559139875595329
Validation loss: 3.6588938560022095

Epoch: 5| Step: 3
Training loss: 3.879586120829528
Validation loss: 3.652686858784993

Epoch: 5| Step: 4
Training loss: 3.921277004412837
Validation loss: 3.6462371508778926

Epoch: 5| Step: 5
Training loss: 3.7846196820817397
Validation loss: 3.6381976511082215

Epoch: 5| Step: 6
Training loss: 3.203460378069294
Validation loss: 3.632419191845246

Epoch: 5| Step: 7
Training loss: 4.33455029540871
Validation loss: 3.624871053301127

Epoch: 5| Step: 8
Training loss: 3.61796294565874
Validation loss: 3.621773726442644

Epoch: 5| Step: 9
Training loss: 3.875140033775821
Validation loss: 3.614932533317325

Epoch: 5| Step: 10
Training loss: 3.5360885823835604
Validation loss: 3.609861467103275

Epoch: 11| Step: 0
Training loss: 3.1286250641736046
Validation loss: 3.6034807008476606

Epoch: 5| Step: 1
Training loss: 3.7770868507925757
Validation loss: 3.596531832546607

Epoch: 5| Step: 2
Training loss: 4.065059149242582
Validation loss: 3.590838703621779

Epoch: 5| Step: 3
Training loss: 3.5896467584433474
Validation loss: 3.585049395488729

Epoch: 5| Step: 4
Training loss: 4.479396275985688
Validation loss: 3.579539597087187

Epoch: 5| Step: 5
Training loss: 3.9085703557633638
Validation loss: 3.5736883994586877

Epoch: 5| Step: 6
Training loss: 3.7680820663974988
Validation loss: 3.5679246396621185

Epoch: 5| Step: 7
Training loss: 4.566241885474864
Validation loss: 3.563841560865041

Epoch: 5| Step: 8
Training loss: 3.6190747472754947
Validation loss: 3.5554233810274436

Epoch: 5| Step: 9
Training loss: 2.7427079883251175
Validation loss: 3.552163689221398

Epoch: 5| Step: 10
Training loss: 3.4899588008077473
Validation loss: 3.5494837510776147

Epoch: 12| Step: 0
Training loss: 3.478228017921384
Validation loss: 3.544861226591468

Epoch: 5| Step: 1
Training loss: 3.1572531437366966
Validation loss: 3.5411028264184408

Epoch: 5| Step: 2
Training loss: 3.5295414124780375
Validation loss: 3.537188011751175

Epoch: 5| Step: 3
Training loss: 3.9908392434200213
Validation loss: 3.533857916766511

Epoch: 5| Step: 4
Training loss: 3.447611139288917
Validation loss: 3.5365763851490803

Epoch: 5| Step: 5
Training loss: 4.06779487052169
Validation loss: 3.5444116242189723

Epoch: 5| Step: 6
Training loss: 3.560361789364529
Validation loss: 3.522628274703628

Epoch: 5| Step: 7
Training loss: 3.7809137872705403
Validation loss: 3.5189898279108656

Epoch: 5| Step: 8
Training loss: 3.6601847807302508
Validation loss: 3.517965160752801

Epoch: 5| Step: 9
Training loss: 4.627765756453804
Validation loss: 3.5166145928154937

Epoch: 5| Step: 10
Training loss: 3.573486920253952
Validation loss: 3.517301942401705

Epoch: 13| Step: 0
Training loss: 3.5275907208235107
Validation loss: 3.511987214998988

Epoch: 5| Step: 1
Training loss: 3.2193814741516484
Validation loss: 3.508871636323323

Epoch: 5| Step: 2
Training loss: 3.580314532693341
Validation loss: 3.5049759436511145

Epoch: 5| Step: 3
Training loss: 4.036677765162924
Validation loss: 3.501989941579922

Epoch: 5| Step: 4
Training loss: 4.403245050054016
Validation loss: 3.498186554308365

Epoch: 5| Step: 5
Training loss: 3.739871014905445
Validation loss: 3.49331580521727

Epoch: 5| Step: 6
Training loss: 3.392037796097834
Validation loss: 3.490374264123953

Epoch: 5| Step: 7
Training loss: 3.4065124690573585
Validation loss: 3.4885937103714504

Epoch: 5| Step: 8
Training loss: 3.6429517129969673
Validation loss: 3.4809394791461004

Epoch: 5| Step: 9
Training loss: 3.574428731451445
Validation loss: 3.4778052669056727

Epoch: 5| Step: 10
Training loss: 4.162450310121253
Validation loss: 3.476304135522274

Epoch: 14| Step: 0
Training loss: 3.4862440083077124
Validation loss: 3.474504421293232

Epoch: 5| Step: 1
Training loss: 3.839104178562997
Validation loss: 3.4716277050919944

Epoch: 5| Step: 2
Training loss: 4.064088950828235
Validation loss: 3.4674190638504454

Epoch: 5| Step: 3
Training loss: 3.226808404673068
Validation loss: 3.4615769922905995

Epoch: 5| Step: 4
Training loss: 4.003396499563195
Validation loss: 3.4590571081392905

Epoch: 5| Step: 5
Training loss: 3.5106037818249822
Validation loss: 3.4552064872469486

Epoch: 5| Step: 6
Training loss: 3.6786247387116995
Validation loss: 3.4509376684904725

Epoch: 5| Step: 7
Training loss: 3.329965002202509
Validation loss: 3.4495623103006063

Epoch: 5| Step: 8
Training loss: 3.605344958262164
Validation loss: 3.448221648528759

Epoch: 5| Step: 9
Training loss: 4.117454795195512
Validation loss: 3.4447167600726805

Epoch: 5| Step: 10
Training loss: 3.4235504089985445
Validation loss: 3.4401048234554215

Epoch: 15| Step: 0
Training loss: 2.8490674952783004
Validation loss: 3.4374575152712965

Epoch: 5| Step: 1
Training loss: 3.8103221238498985
Validation loss: 3.439077805375293

Epoch: 5| Step: 2
Training loss: 3.4120722016971925
Validation loss: 3.4373941638274235

Epoch: 5| Step: 3
Training loss: 3.6258059953906714
Validation loss: 3.4475065311510207

Epoch: 5| Step: 4
Training loss: 3.8347874799628063
Validation loss: 3.449483098451052

Epoch: 5| Step: 5
Training loss: 3.605763267316533
Validation loss: 3.444977115486215

Epoch: 5| Step: 6
Training loss: 2.9286843985855757
Validation loss: 3.4349549284617322

Epoch: 5| Step: 7
Training loss: 3.9881173304723334
Validation loss: 3.426359187215204

Epoch: 5| Step: 8
Training loss: 4.605088131669084
Validation loss: 3.4265243987604417

Epoch: 5| Step: 9
Training loss: 4.034786358817987
Validation loss: 3.4230268772906305

Epoch: 5| Step: 10
Training loss: 3.056726424015472
Validation loss: 3.420996479338157

Epoch: 16| Step: 0
Training loss: 3.2750883833046447
Validation loss: 3.418273938407884

Epoch: 5| Step: 1
Training loss: 3.8884948046388237
Validation loss: 3.4180056926646984

Epoch: 5| Step: 2
Training loss: 4.072752706182011
Validation loss: 3.410060744268552

Epoch: 5| Step: 3
Training loss: 3.1590023315266516
Validation loss: 3.4041293481083152

Epoch: 5| Step: 4
Training loss: 3.706919854342491
Validation loss: 3.398560642288152

Epoch: 5| Step: 5
Training loss: 3.0886746785865293
Validation loss: 3.393444551038264

Epoch: 5| Step: 6
Training loss: 3.111702665976509
Validation loss: 3.384196186792992

Epoch: 5| Step: 7
Training loss: 4.458834872452646
Validation loss: 3.3767811318799974

Epoch: 5| Step: 8
Training loss: 3.956988109417476
Validation loss: 3.362353280587041

Epoch: 5| Step: 9
Training loss: 2.8675388879641748
Validation loss: 3.355481810109035

Epoch: 5| Step: 10
Training loss: 3.903336682164824
Validation loss: 3.351648913725983

Epoch: 17| Step: 0
Training loss: 3.937010356188915
Validation loss: 3.356764950630119

Epoch: 5| Step: 1
Training loss: 3.2028239783286914
Validation loss: 3.3319693994827966

Epoch: 5| Step: 2
Training loss: 3.3715551244061217
Validation loss: 3.3462714279069576

Epoch: 5| Step: 3
Training loss: 3.7543713840183344
Validation loss: 3.3417709914489473

Epoch: 5| Step: 4
Training loss: 4.035043749944335
Validation loss: 3.330797859051899

Epoch: 5| Step: 5
Training loss: 3.5768696944273892
Validation loss: 3.3378061101098115

Epoch: 5| Step: 6
Training loss: 2.811491806737449
Validation loss: 3.3335077152989214

Epoch: 5| Step: 7
Training loss: 3.522480430792333
Validation loss: 3.330711857240824

Epoch: 5| Step: 8
Training loss: 3.6931277504544515
Validation loss: 3.3290458397815987

Epoch: 5| Step: 9
Training loss: 3.7087164405921826
Validation loss: 3.324834148407304

Epoch: 5| Step: 10
Training loss: 3.504076491082763
Validation loss: 3.3222653117083296

Epoch: 18| Step: 0
Training loss: 3.4519622364034017
Validation loss: 3.3193481789934527

Epoch: 5| Step: 1
Training loss: 2.5144591858396543
Validation loss: 3.3129393800254703

Epoch: 5| Step: 2
Training loss: 4.49054678767191
Validation loss: 3.3112018461578594

Epoch: 5| Step: 3
Training loss: 4.144269843311327
Validation loss: 3.3077467382056107

Epoch: 5| Step: 4
Training loss: 3.352518581080024
Validation loss: 3.303208935886641

Epoch: 5| Step: 5
Training loss: 4.089425168482505
Validation loss: 3.298922477380257

Epoch: 5| Step: 6
Training loss: 3.130044451510652
Validation loss: 3.2924344873050524

Epoch: 5| Step: 7
Training loss: 3.067572926942304
Validation loss: 3.2894102010251958

Epoch: 5| Step: 8
Training loss: 3.6376647702157423
Validation loss: 3.290790812577838

Epoch: 5| Step: 9
Training loss: 3.1894952849517573
Validation loss: 3.2875191236819616

Epoch: 5| Step: 10
Training loss: 3.4810871298476314
Validation loss: 3.282205949281755

Epoch: 19| Step: 0
Training loss: 3.8778868965625772
Validation loss: 3.2834822320560013

Epoch: 5| Step: 1
Training loss: 3.979331980095717
Validation loss: 3.2928370716802116

Epoch: 5| Step: 2
Training loss: 4.06293802100756
Validation loss: 3.27658887250446

Epoch: 5| Step: 3
Training loss: 3.63627423479981
Validation loss: 3.2753988480114793

Epoch: 5| Step: 4
Training loss: 2.608328969381011
Validation loss: 3.2696992258577997

Epoch: 5| Step: 5
Training loss: 2.888286737710756
Validation loss: 3.267942499344105

Epoch: 5| Step: 6
Training loss: 3.461517629805262
Validation loss: 3.272568101511736

Epoch: 5| Step: 7
Training loss: 3.1423754013233043
Validation loss: 3.2678226063966984

Epoch: 5| Step: 8
Training loss: 3.302870663583624
Validation loss: 3.2646522209436575

Epoch: 5| Step: 9
Training loss: 4.010623176839425
Validation loss: 3.263634687264505

Epoch: 5| Step: 10
Training loss: 3.421378182353861
Validation loss: 3.2611104418473964

Epoch: 20| Step: 0
Training loss: 2.8292967334301187
Validation loss: 3.2601585554666483

Epoch: 5| Step: 1
Training loss: 3.8954750073042104
Validation loss: 3.260683703672845

Epoch: 5| Step: 2
Training loss: 3.108203456370945
Validation loss: 3.2588352327184973

Epoch: 5| Step: 3
Training loss: 3.4985248999435323
Validation loss: 3.2545829403865603

Epoch: 5| Step: 4
Training loss: 3.378150881968959
Validation loss: 3.2536160110233143

Epoch: 5| Step: 5
Training loss: 3.8220358240034615
Validation loss: 3.252844100064954

Epoch: 5| Step: 6
Training loss: 3.0716506332776583
Validation loss: 3.250058759689806

Epoch: 5| Step: 7
Training loss: 3.7086660400185294
Validation loss: 3.2489806912459085

Epoch: 5| Step: 8
Training loss: 4.135337361200702
Validation loss: 3.250609417266165

Epoch: 5| Step: 9
Training loss: 3.7041278237765347
Validation loss: 3.2452717914400226

Epoch: 5| Step: 10
Training loss: 3.079355990964961
Validation loss: 3.2451923266331564

Epoch: 21| Step: 0
Training loss: 3.615731459149058
Validation loss: 3.243056141873474

Epoch: 5| Step: 1
Training loss: 3.3702551372175678
Validation loss: 3.243162446768368

Epoch: 5| Step: 2
Training loss: 3.4764461883633317
Validation loss: 3.242010647412544

Epoch: 5| Step: 3
Training loss: 3.5219904937355904
Validation loss: 3.239067420888261

Epoch: 5| Step: 4
Training loss: 3.0884461841115702
Validation loss: 3.237924026947353

Epoch: 5| Step: 5
Training loss: 3.0241663643220225
Validation loss: 3.2393636659021237

Epoch: 5| Step: 6
Training loss: 3.7648907337316544
Validation loss: 3.236592044226305

Epoch: 5| Step: 7
Training loss: 3.737891421027452
Validation loss: 3.234913632174966

Epoch: 5| Step: 8
Training loss: 4.189385743922007
Validation loss: 3.2342290177071193

Epoch: 5| Step: 9
Training loss: 3.4891356375545817
Validation loss: 3.2358069166788614

Epoch: 5| Step: 10
Training loss: 2.80520395608403
Validation loss: 3.234913342915659

Epoch: 22| Step: 0
Training loss: 3.7618938021071937
Validation loss: 3.2322571799770925

Epoch: 5| Step: 1
Training loss: 4.294755558611868
Validation loss: 3.231965728200873

Epoch: 5| Step: 2
Training loss: 3.363648008049907
Validation loss: 3.242095200309215

Epoch: 5| Step: 3
Training loss: 2.9504033217074217
Validation loss: 3.2644980369587615

Epoch: 5| Step: 4
Training loss: 2.4704599373894114
Validation loss: 3.2357336195563526

Epoch: 5| Step: 5
Training loss: 4.048144520648762
Validation loss: 3.237602465261562

Epoch: 5| Step: 6
Training loss: 3.812185555920456
Validation loss: 3.233507891912662

Epoch: 5| Step: 7
Training loss: 3.2216438691552374
Validation loss: 3.2322882710147143

Epoch: 5| Step: 8
Training loss: 3.254735284638566
Validation loss: 3.229902057621263

Epoch: 5| Step: 9
Training loss: 3.1262611895959256
Validation loss: 3.232051273617966

Epoch: 5| Step: 10
Training loss: 3.7166003256951146
Validation loss: 3.232781729813957

Epoch: 23| Step: 0
Training loss: 3.7030477395025785
Validation loss: 3.234148178164633

Epoch: 5| Step: 1
Training loss: 3.093959454468658
Validation loss: 3.231186771105433

Epoch: 5| Step: 2
Training loss: 3.5771934929253737
Validation loss: 3.2293717339403027

Epoch: 5| Step: 3
Training loss: 2.687702082643533
Validation loss: 3.2272441946075614

Epoch: 5| Step: 4
Training loss: 3.8612479788644327
Validation loss: 3.2251794360527177

Epoch: 5| Step: 5
Training loss: 2.6067539231053245
Validation loss: 3.2234487663475657

Epoch: 5| Step: 6
Training loss: 4.522891418489644
Validation loss: 3.2226328668277406

Epoch: 5| Step: 7
Training loss: 3.4580193955432947
Validation loss: 3.224100303449622

Epoch: 5| Step: 8
Training loss: 3.5337291555798553
Validation loss: 3.219641347319897

Epoch: 5| Step: 9
Training loss: 2.977366101179306
Validation loss: 3.2193929275249022

Epoch: 5| Step: 10
Training loss: 3.8696737292849592
Validation loss: 3.2183382762780637

Epoch: 24| Step: 0
Training loss: 4.2527528710732625
Validation loss: 3.216532680121046

Epoch: 5| Step: 1
Training loss: 3.2262762279841093
Validation loss: 3.217760733095831

Epoch: 5| Step: 2
Training loss: 3.016720429533267
Validation loss: 3.2169802442145237

Epoch: 5| Step: 3
Training loss: 3.279350239431416
Validation loss: 3.214859307990267

Epoch: 5| Step: 4
Training loss: 4.003146364630001
Validation loss: 3.2134311502987143

Epoch: 5| Step: 5
Training loss: 2.964473816883247
Validation loss: 3.2116201914686044

Epoch: 5| Step: 6
Training loss: 3.4828605610888705
Validation loss: 3.2103667506828786

Epoch: 5| Step: 7
Training loss: 3.334971661082686
Validation loss: 3.2096662422744506

Epoch: 5| Step: 8
Training loss: 3.421359646106052
Validation loss: 3.2093430435007217

Epoch: 5| Step: 9
Training loss: 3.868596477266459
Validation loss: 3.208313461794053

Epoch: 5| Step: 10
Training loss: 2.983099859752334
Validation loss: 3.2076310591883375

Epoch: 25| Step: 0
Training loss: 3.4384251129972903
Validation loss: 3.2046793290101556

Epoch: 5| Step: 1
Training loss: 3.4741154320162053
Validation loss: 3.2049366747547623

Epoch: 5| Step: 2
Training loss: 3.8639006855761195
Validation loss: 3.2033842536621804

Epoch: 5| Step: 3
Training loss: 3.6381813328845647
Validation loss: 3.2011583214803334

Epoch: 5| Step: 4
Training loss: 2.47415101488901
Validation loss: 3.2045417355751162

Epoch: 5| Step: 5
Training loss: 3.5603382177101244
Validation loss: 3.2108974611477508

Epoch: 5| Step: 6
Training loss: 3.524507144534884
Validation loss: 3.204931611360478

Epoch: 5| Step: 7
Training loss: 2.5882999197266123
Validation loss: 3.1992407417165034

Epoch: 5| Step: 8
Training loss: 3.9191998480602703
Validation loss: 3.1992081723824706

Epoch: 5| Step: 9
Training loss: 2.9484453210287267
Validation loss: 3.1979893293372985

Epoch: 5| Step: 10
Training loss: 4.321720383664931
Validation loss: 3.1961924712199026

Epoch: 26| Step: 0
Training loss: 3.428468387622134
Validation loss: 3.195742569373985

Epoch: 5| Step: 1
Training loss: 3.104297114624613
Validation loss: 3.1951575070276084

Epoch: 5| Step: 2
Training loss: 3.0979005349275175
Validation loss: 3.195275429716882

Epoch: 5| Step: 3
Training loss: 3.512769429472454
Validation loss: 3.1938693875584687

Epoch: 5| Step: 4
Training loss: 3.947348615027815
Validation loss: 3.1931290631938216

Epoch: 5| Step: 5
Training loss: 3.2234097426417136
Validation loss: 3.1908741994473715

Epoch: 5| Step: 6
Training loss: 3.859114418035788
Validation loss: 3.191439254007095

Epoch: 5| Step: 7
Training loss: 3.3464139505035835
Validation loss: 3.1905286484512443

Epoch: 5| Step: 8
Training loss: 3.4822563264685127
Validation loss: 3.18911752952925

Epoch: 5| Step: 9
Training loss: 3.541333007055099
Validation loss: 3.1877648382091395

Epoch: 5| Step: 10
Training loss: 3.324156208099976
Validation loss: 3.1867891468450757

Epoch: 27| Step: 0
Training loss: 3.879684692824259
Validation loss: 3.188048731915175

Epoch: 5| Step: 1
Training loss: 3.3125964456589023
Validation loss: 3.189082834247347

Epoch: 5| Step: 2
Training loss: 2.947812099871269
Validation loss: 3.1857399855834405

Epoch: 5| Step: 3
Training loss: 3.698548656061575
Validation loss: 3.182170729409106

Epoch: 5| Step: 4
Training loss: 3.0236839962804964
Validation loss: 3.183637862180164

Epoch: 5| Step: 5
Training loss: 3.529476564410874
Validation loss: 3.1855618501721414

Epoch: 5| Step: 6
Training loss: 3.67310212104011
Validation loss: 3.188845031982608

Epoch: 5| Step: 7
Training loss: 3.6455048040688767
Validation loss: 3.183879592195535

Epoch: 5| Step: 8
Training loss: 3.5498660747357174
Validation loss: 3.1820382043350968

Epoch: 5| Step: 9
Training loss: 3.5208585990285135
Validation loss: 3.1893354516424446

Epoch: 5| Step: 10
Training loss: 2.912015712569887
Validation loss: 3.189931859914511

Epoch: 28| Step: 0
Training loss: 2.730709911169167
Validation loss: 3.1846600708895236

Epoch: 5| Step: 1
Training loss: 3.4322651624259213
Validation loss: 3.192190518170811

Epoch: 5| Step: 2
Training loss: 3.5671305761753875
Validation loss: 3.1880763443886093

Epoch: 5| Step: 3
Training loss: 3.844243459893073
Validation loss: 3.1860963246925764

Epoch: 5| Step: 4
Training loss: 3.2465822882787725
Validation loss: 3.1818995601335205

Epoch: 5| Step: 5
Training loss: 3.5021207378930788
Validation loss: 3.1771856449194615

Epoch: 5| Step: 6
Training loss: 3.4321140056161283
Validation loss: 3.178963751691662

Epoch: 5| Step: 7
Training loss: 3.4852564770144663
Validation loss: 3.1769310559528368

Epoch: 5| Step: 8
Training loss: 3.378911189257589
Validation loss: 3.180162550585298

Epoch: 5| Step: 9
Training loss: 3.62027274395184
Validation loss: 3.177502767686991

Epoch: 5| Step: 10
Training loss: 3.549027919656242
Validation loss: 3.18005447505367

Epoch: 29| Step: 0
Training loss: 3.050080632879306
Validation loss: 3.176346786119575

Epoch: 5| Step: 1
Training loss: 3.0852893776472965
Validation loss: 3.172924773866323

Epoch: 5| Step: 2
Training loss: 4.129066312605261
Validation loss: 3.1745340963245736

Epoch: 5| Step: 3
Training loss: 4.053621420242934
Validation loss: 3.170987218194181

Epoch: 5| Step: 4
Training loss: 2.967419456667952
Validation loss: 3.1705062582604326

Epoch: 5| Step: 5
Training loss: 2.125865872068172
Validation loss: 3.168519582775051

Epoch: 5| Step: 6
Training loss: 4.451561797313695
Validation loss: 3.1704651573486125

Epoch: 5| Step: 7
Training loss: 3.167867901157586
Validation loss: 3.1725274964716306

Epoch: 5| Step: 8
Training loss: 3.389586118115901
Validation loss: 3.176519215875543

Epoch: 5| Step: 9
Training loss: 3.0199124390495773
Validation loss: 3.1776679770790204

Epoch: 5| Step: 10
Training loss: 3.78755293201687
Validation loss: 3.17820335804052

Epoch: 30| Step: 0
Training loss: 3.9492793620935958
Validation loss: 3.1736729115789846

Epoch: 5| Step: 1
Training loss: 2.7726244957148958
Validation loss: 3.169493280473544

Epoch: 5| Step: 2
Training loss: 3.200730037861449
Validation loss: 3.1694749575701517

Epoch: 5| Step: 3
Training loss: 3.5182524632553926
Validation loss: 3.170367517299546

Epoch: 5| Step: 4
Training loss: 3.4269001611303866
Validation loss: 3.1697386724453245

Epoch: 5| Step: 5
Training loss: 3.2688750379873883
Validation loss: 3.1687916996392405

Epoch: 5| Step: 6
Training loss: 3.053006931860583
Validation loss: 3.163992741062777

Epoch: 5| Step: 7
Training loss: 3.192322616966509
Validation loss: 3.162325566977478

Epoch: 5| Step: 8
Training loss: 3.6331545432894545
Validation loss: 3.161634138476872

Epoch: 5| Step: 9
Training loss: 3.8378739761884435
Validation loss: 3.163208923298302

Epoch: 5| Step: 10
Training loss: 3.750833037355981
Validation loss: 3.160593808281901

Epoch: 31| Step: 0
Training loss: 3.3117198385249007
Validation loss: 3.160421426272658

Epoch: 5| Step: 1
Training loss: 3.3975778479004637
Validation loss: 3.1622949181826314

Epoch: 5| Step: 2
Training loss: 3.35499009791816
Validation loss: 3.1589157152195066

Epoch: 5| Step: 3
Training loss: 2.7403886334264955
Validation loss: 3.1580082136543517

Epoch: 5| Step: 4
Training loss: 3.8104919398349817
Validation loss: 3.1578503392125814

Epoch: 5| Step: 5
Training loss: 3.30946369286433
Validation loss: 3.164230906528086

Epoch: 5| Step: 6
Training loss: 3.6701217036635376
Validation loss: 3.1689874589078735

Epoch: 5| Step: 7
Training loss: 3.5251798867934285
Validation loss: 3.1816615432819795

Epoch: 5| Step: 8
Training loss: 3.6360099913120956
Validation loss: 3.1625555831640058

Epoch: 5| Step: 9
Training loss: 3.0740699974434755
Validation loss: 3.155779606642058

Epoch: 5| Step: 10
Training loss: 3.7457447068391456
Validation loss: 3.1556839282505664

Epoch: 32| Step: 0
Training loss: 3.7171491495072697
Validation loss: 3.150856693743601

Epoch: 5| Step: 1
Training loss: 3.671813964336468
Validation loss: 3.1525138706098828

Epoch: 5| Step: 2
Training loss: 3.176542559184444
Validation loss: 3.1527615420379544

Epoch: 5| Step: 3
Training loss: 3.2078630342140317
Validation loss: 3.1556281946729103

Epoch: 5| Step: 4
Training loss: 4.066614502952671
Validation loss: 3.1526058858736787

Epoch: 5| Step: 5
Training loss: 3.4273339888131744
Validation loss: 3.158079294030427

Epoch: 5| Step: 6
Training loss: 2.862910851724495
Validation loss: 3.1561877539885166

Epoch: 5| Step: 7
Training loss: 3.277788352590051
Validation loss: 3.1570413369694674

Epoch: 5| Step: 8
Training loss: 3.1957928359455283
Validation loss: 3.154620652944504

Epoch: 5| Step: 9
Training loss: 3.823641771503909
Validation loss: 3.150557449765965

Epoch: 5| Step: 10
Training loss: 2.9614194613622797
Validation loss: 3.152119599200487

Epoch: 33| Step: 0
Training loss: 3.479027994708273
Validation loss: 3.14876748358865

Epoch: 5| Step: 1
Training loss: 3.596641372530441
Validation loss: 3.147587784398027

Epoch: 5| Step: 2
Training loss: 4.076810310642373
Validation loss: 3.1466641865380374

Epoch: 5| Step: 3
Training loss: 2.776456581203522
Validation loss: 3.1473487724898987

Epoch: 5| Step: 4
Training loss: 3.1393888707341517
Validation loss: 3.1474271220918095

Epoch: 5| Step: 5
Training loss: 3.6414886890860583
Validation loss: 3.1456397934963185

Epoch: 5| Step: 6
Training loss: 3.5492616933399064
Validation loss: 3.1490177829061485

Epoch: 5| Step: 7
Training loss: 3.370353608638955
Validation loss: 3.15482375504434

Epoch: 5| Step: 8
Training loss: 3.121726648664475
Validation loss: 3.1497699956331138

Epoch: 5| Step: 9
Training loss: 3.0291726771264
Validation loss: 3.1471149485441856

Epoch: 5| Step: 10
Training loss: 3.6110835799773495
Validation loss: 3.1458669224829507

Epoch: 34| Step: 0
Training loss: 3.148567897472226
Validation loss: 3.1429417093154597

Epoch: 5| Step: 1
Training loss: 3.388305714637439
Validation loss: 3.142669533032306

Epoch: 5| Step: 2
Training loss: 4.0256881788982
Validation loss: 3.1435012425721114

Epoch: 5| Step: 3
Training loss: 3.8268028000022394
Validation loss: 3.1437319005104585

Epoch: 5| Step: 4
Training loss: 3.020395093677584
Validation loss: 3.141182194725015

Epoch: 5| Step: 5
Training loss: 3.2776187240315293
Validation loss: 3.1415391143794307

Epoch: 5| Step: 6
Training loss: 3.2567969918960777
Validation loss: 3.1429876538934947

Epoch: 5| Step: 7
Training loss: 3.7410443497154757
Validation loss: 3.142319663399216

Epoch: 5| Step: 8
Training loss: 2.968322401874454
Validation loss: 3.141716279513171

Epoch: 5| Step: 9
Training loss: 3.673802425896957
Validation loss: 3.1392070287669327

Epoch: 5| Step: 10
Training loss: 2.9078722292235017
Validation loss: 3.139358772162934

Epoch: 35| Step: 0
Training loss: 3.6016811260290313
Validation loss: 3.140474599413271

Epoch: 5| Step: 1
Training loss: 3.351788137527799
Validation loss: 3.138583701114694

Epoch: 5| Step: 2
Training loss: 3.2882018061797944
Validation loss: 3.140393491809901

Epoch: 5| Step: 3
Training loss: 3.774968123143494
Validation loss: 3.1406486427487765

Epoch: 5| Step: 4
Training loss: 3.420583263430456
Validation loss: 3.1398911340883497

Epoch: 5| Step: 5
Training loss: 3.821415342198533
Validation loss: 3.1365009205101315

Epoch: 5| Step: 6
Training loss: 2.571658538571474
Validation loss: 3.1392111724579603

Epoch: 5| Step: 7
Training loss: 3.670475599774509
Validation loss: 3.1383692342427496

Epoch: 5| Step: 8
Training loss: 3.0750172994483687
Validation loss: 3.138869036567768

Epoch: 5| Step: 9
Training loss: 3.311664115957255
Validation loss: 3.1396098526006395

Epoch: 5| Step: 10
Training loss: 3.4233935744628936
Validation loss: 3.1380253734546417

Epoch: 36| Step: 0
Training loss: 3.9347369475215754
Validation loss: 3.1349398119162992

Epoch: 5| Step: 1
Training loss: 2.814488195641574
Validation loss: 3.1359000762212736

Epoch: 5| Step: 2
Training loss: 3.2642011686956973
Validation loss: 3.1321399347191217

Epoch: 5| Step: 3
Training loss: 3.724587610958306
Validation loss: 3.132937108715455

Epoch: 5| Step: 4
Training loss: 2.8250656862977492
Validation loss: 3.1336204320259977

Epoch: 5| Step: 5
Training loss: 3.8720942031104086
Validation loss: 3.131552265713

Epoch: 5| Step: 6
Training loss: 2.8775343298169185
Validation loss: 3.1307802816027928

Epoch: 5| Step: 7
Training loss: 3.243390184265553
Validation loss: 3.133373914869068

Epoch: 5| Step: 8
Training loss: 3.2551378573100056
Validation loss: 3.1307995130638426

Epoch: 5| Step: 9
Training loss: 3.7708053728335065
Validation loss: 3.1319143010999553

Epoch: 5| Step: 10
Training loss: 3.5946651454529905
Validation loss: 3.1353945570705064

Epoch: 37| Step: 0
Training loss: 3.351017549756255
Validation loss: 3.1398214455945705

Epoch: 5| Step: 1
Training loss: 4.0799217504589675
Validation loss: 3.148793076190411

Epoch: 5| Step: 2
Training loss: 3.6254044668868257
Validation loss: 3.128224182572611

Epoch: 5| Step: 3
Training loss: 3.502697994672439
Validation loss: 3.1315653493263556

Epoch: 5| Step: 4
Training loss: 3.326506458417826
Validation loss: 3.130360215929165

Epoch: 5| Step: 5
Training loss: 3.5354520389463553
Validation loss: 3.147016165308692

Epoch: 5| Step: 6
Training loss: 3.596558377459705
Validation loss: 3.1575275224906654

Epoch: 5| Step: 7
Training loss: 3.6608086231583625
Validation loss: 3.167516444314311

Epoch: 5| Step: 8
Training loss: 3.002566352511283
Validation loss: 3.1324809379735195

Epoch: 5| Step: 9
Training loss: 2.7241185993922303
Validation loss: 3.1306110665111206

Epoch: 5| Step: 10
Training loss: 2.7393167363593407
Validation loss: 3.1275725737795055

Epoch: 38| Step: 0
Training loss: 3.428405939377111
Validation loss: 3.1278143107542893

Epoch: 5| Step: 1
Training loss: 2.6039161459903277
Validation loss: 3.1283412815185137

Epoch: 5| Step: 2
Training loss: 3.6527963612852883
Validation loss: 3.1291593931338695

Epoch: 5| Step: 3
Training loss: 3.818812413181657
Validation loss: 3.1322168739339142

Epoch: 5| Step: 4
Training loss: 3.9109200599516263
Validation loss: 3.1309722142495584

Epoch: 5| Step: 5
Training loss: 3.075934235612648
Validation loss: 3.1253628312997277

Epoch: 5| Step: 6
Training loss: 3.5334819390577703
Validation loss: 3.1273006248092647

Epoch: 5| Step: 7
Training loss: 3.7479321182438547
Validation loss: 3.1262807981887173

Epoch: 5| Step: 8
Training loss: 2.9627362829052903
Validation loss: 3.122212945286453

Epoch: 5| Step: 9
Training loss: 3.2078426695982936
Validation loss: 3.1265001187080337

Epoch: 5| Step: 10
Training loss: 3.0954229282205077
Validation loss: 3.12221956496591

Epoch: 39| Step: 0
Training loss: 3.6993259950135258
Validation loss: 3.1196208211822456

Epoch: 5| Step: 1
Training loss: 3.342330488701428
Validation loss: 3.1212951315093234

Epoch: 5| Step: 2
Training loss: 3.529585724638692
Validation loss: 3.123589942045126

Epoch: 5| Step: 3
Training loss: 3.1133114228168526
Validation loss: 3.12202604645046

Epoch: 5| Step: 4
Training loss: 3.2594073666129493
Validation loss: 3.1353945570705064

Epoch: 5| Step: 5
Training loss: 3.6453297875849184
Validation loss: 3.124387104269682

Epoch: 5| Step: 6
Training loss: 3.421073645554223
Validation loss: 3.1174652373108596

Epoch: 5| Step: 7
Training loss: 2.865020348707971
Validation loss: 3.1180268223064065

Epoch: 5| Step: 8
Training loss: 3.398375622416203
Validation loss: 3.117830548844819

Epoch: 5| Step: 9
Training loss: 3.3737746946117255
Validation loss: 3.1199883585203376

Epoch: 5| Step: 10
Training loss: 3.573225773525774
Validation loss: 3.1182034126404736

Epoch: 40| Step: 0
Training loss: 3.6904520406094004
Validation loss: 3.1212826676689374

Epoch: 5| Step: 1
Training loss: 3.6190638114571736
Validation loss: 3.119610288415804

Epoch: 5| Step: 2
Training loss: 3.6985335717497363
Validation loss: 3.1171652304030975

Epoch: 5| Step: 3
Training loss: 3.1216375953744966
Validation loss: 3.116201639570473

Epoch: 5| Step: 4
Training loss: 2.676517045703457
Validation loss: 3.1135467512019184

Epoch: 5| Step: 5
Training loss: 3.4923046527643784
Validation loss: 3.1148528974493574

Epoch: 5| Step: 6
Training loss: 2.9314405562353145
Validation loss: 3.11275362721884

Epoch: 5| Step: 7
Training loss: 3.2849004874986023
Validation loss: 3.1123364924793897

Epoch: 5| Step: 8
Training loss: 3.7681455921465243
Validation loss: 3.112188784215372

Epoch: 5| Step: 9
Training loss: 3.659165613713928
Validation loss: 3.1137348802391047

Epoch: 5| Step: 10
Training loss: 3.06917964623557
Validation loss: 3.113249280098447

Epoch: 41| Step: 0
Training loss: 3.9178256220741203
Validation loss: 3.112931275999823

Epoch: 5| Step: 1
Training loss: 3.608747551616265
Validation loss: 3.1106812793137806

Epoch: 5| Step: 2
Training loss: 2.864441765263681
Validation loss: 3.1125664190071745

Epoch: 5| Step: 3
Training loss: 3.4297912164877165
Validation loss: 3.115803051343089

Epoch: 5| Step: 4
Training loss: 2.7525562196788416
Validation loss: 3.1190818433672836

Epoch: 5| Step: 5
Training loss: 4.028689021951894
Validation loss: 3.1197369471562877

Epoch: 5| Step: 6
Training loss: 2.7670899729933134
Validation loss: 3.116674545856769

Epoch: 5| Step: 7
Training loss: 3.7239566545104754
Validation loss: 3.1095499142131566

Epoch: 5| Step: 8
Training loss: 3.83121860609525
Validation loss: 3.1082711270279253

Epoch: 5| Step: 9
Training loss: 2.24723073294712
Validation loss: 3.1072613032997185

Epoch: 5| Step: 10
Training loss: 3.54743731238348
Validation loss: 3.1075596808898176

Epoch: 42| Step: 0
Training loss: 2.926160148665347
Validation loss: 3.109919346567878

Epoch: 5| Step: 1
Training loss: 3.4029163531331323
Validation loss: 3.1238221432418647

Epoch: 5| Step: 2
Training loss: 4.117059173610901
Validation loss: 3.125567476984504

Epoch: 5| Step: 3
Training loss: 3.096977015103612
Validation loss: 3.1218476210068236

Epoch: 5| Step: 4
Training loss: 3.6086374825674605
Validation loss: 3.1162757408796335

Epoch: 5| Step: 5
Training loss: 3.803725103271119
Validation loss: 3.1047895777884404

Epoch: 5| Step: 6
Training loss: 3.468299492801211
Validation loss: 3.103855639149723

Epoch: 5| Step: 7
Training loss: 2.539306065541259
Validation loss: 3.1063664566017475

Epoch: 5| Step: 8
Training loss: 2.998662173474605
Validation loss: 3.1104889748526183

Epoch: 5| Step: 9
Training loss: 3.5010018958288454
Validation loss: 3.138803795496498

Epoch: 5| Step: 10
Training loss: 3.575683693766641
Validation loss: 3.1475766317326155

Epoch: 43| Step: 0
Training loss: 3.7820315223320238
Validation loss: 3.136210519780212

Epoch: 5| Step: 1
Training loss: 2.9787256585782225
Validation loss: 3.1149269732326266

Epoch: 5| Step: 2
Training loss: 3.251102993936836
Validation loss: 3.106155995774427

Epoch: 5| Step: 3
Training loss: 3.5818510020591514
Validation loss: 3.103402511073957

Epoch: 5| Step: 4
Training loss: 2.892021872684396
Validation loss: 3.101113138863934

Epoch: 5| Step: 5
Training loss: 3.6544672866632686
Validation loss: 3.0999761299659205

Epoch: 5| Step: 6
Training loss: 3.575373228637824
Validation loss: 3.0988783349934437

Epoch: 5| Step: 7
Training loss: 3.383580638196859
Validation loss: 3.099633046084305

Epoch: 5| Step: 8
Training loss: 3.2976764590672816
Validation loss: 3.101041922525742

Epoch: 5| Step: 9
Training loss: 3.6547080154789056
Validation loss: 3.1243706477582833

Epoch: 5| Step: 10
Training loss: 2.892795057488329
Validation loss: 3.0965133859676865

Epoch: 44| Step: 0
Training loss: 2.8962721640801115
Validation loss: 3.0960145337635248

Epoch: 5| Step: 1
Training loss: 3.243024823635161
Validation loss: 3.0928232415179266

Epoch: 5| Step: 2
Training loss: 2.93679184189684
Validation loss: 3.091195089120887

Epoch: 5| Step: 3
Training loss: 2.88846453785997
Validation loss: 3.0926989827939164

Epoch: 5| Step: 4
Training loss: 3.1213890575739955
Validation loss: 3.093406707090065

Epoch: 5| Step: 5
Training loss: 3.1434371276849182
Validation loss: 3.092748566689234

Epoch: 5| Step: 6
Training loss: 3.3500657374066987
Validation loss: 3.092622744045699

Epoch: 5| Step: 7
Training loss: 4.071493669338428
Validation loss: 3.09218866355012

Epoch: 5| Step: 8
Training loss: 3.3531086518670383
Validation loss: 3.0912390088064425

Epoch: 5| Step: 9
Training loss: 3.9369318718745614
Validation loss: 3.091011695008525

Epoch: 5| Step: 10
Training loss: 3.90723315264378
Validation loss: 3.094492342923038

Epoch: 45| Step: 0
Training loss: 3.542400747778451
Validation loss: 3.09655872209772

Epoch: 5| Step: 1
Training loss: 3.7143651932816866
Validation loss: 3.0981038270182166

Epoch: 5| Step: 2
Training loss: 3.649888201529876
Validation loss: 3.0965903179080523

Epoch: 5| Step: 3
Training loss: 2.7884488325563135
Validation loss: 3.0929254663858363

Epoch: 5| Step: 4
Training loss: 3.1949380594616206
Validation loss: 3.0903428865433074

Epoch: 5| Step: 5
Training loss: 3.7525979261944267
Validation loss: 3.0903579431133688

Epoch: 5| Step: 6
Training loss: 3.3994022797662793
Validation loss: 3.089535554507811

Epoch: 5| Step: 7
Training loss: 3.0224721387615543
Validation loss: 3.0896627541331445

Epoch: 5| Step: 8
Training loss: 2.542005505931783
Validation loss: 3.086474757833146

Epoch: 5| Step: 9
Training loss: 3.6733710954344034
Validation loss: 3.087332137663917

Epoch: 5| Step: 10
Training loss: 3.432470908378574
Validation loss: 3.0870684685126646

Epoch: 46| Step: 0
Training loss: 3.475720524359251
Validation loss: 3.08708945129567

Epoch: 5| Step: 1
Training loss: 3.079820814493864
Validation loss: 3.0841798133138885

Epoch: 5| Step: 2
Training loss: 3.2769316822295824
Validation loss: 3.0864638793833907

Epoch: 5| Step: 3
Training loss: 3.394204496014729
Validation loss: 3.0847241031857524

Epoch: 5| Step: 4
Training loss: 3.663057038842285
Validation loss: 3.0871342714442727

Epoch: 5| Step: 5
Training loss: 3.6652258874412147
Validation loss: 3.0855142091493213

Epoch: 5| Step: 6
Training loss: 3.402639032420091
Validation loss: 3.082507252857757

Epoch: 5| Step: 7
Training loss: 3.1845249428978377
Validation loss: 3.08102432859289

Epoch: 5| Step: 8
Training loss: 3.4773684821088158
Validation loss: 3.0808571487155954

Epoch: 5| Step: 9
Training loss: 3.062969249664392
Validation loss: 3.0804610777488515

Epoch: 5| Step: 10
Training loss: 3.101401067803715
Validation loss: 3.082190581768173

Epoch: 47| Step: 0
Training loss: 3.277252232361593
Validation loss: 3.079366139427153

Epoch: 5| Step: 1
Training loss: 3.6662332249702128
Validation loss: 3.07902565732499

Epoch: 5| Step: 2
Training loss: 3.3991706846499765
Validation loss: 3.0777811620752487

Epoch: 5| Step: 3
Training loss: 3.16365285976737
Validation loss: 3.079237468769743

Epoch: 5| Step: 4
Training loss: 3.3943782723638796
Validation loss: 3.0802871666769676

Epoch: 5| Step: 5
Training loss: 3.3002410627229217
Validation loss: 3.0776067272151173

Epoch: 5| Step: 6
Training loss: 2.8691745286032946
Validation loss: 3.0768328212996456

Epoch: 5| Step: 7
Training loss: 3.159785943326162
Validation loss: 3.077056925998264

Epoch: 5| Step: 8
Training loss: 3.4524115606495185
Validation loss: 3.0756569856254354

Epoch: 5| Step: 9
Training loss: 3.151223589897326
Validation loss: 3.075679695796045

Epoch: 5| Step: 10
Training loss: 3.991408180569361
Validation loss: 3.0766317325609833

Epoch: 48| Step: 0
Training loss: 4.372653877076361
Validation loss: 3.0772026532818217

Epoch: 5| Step: 1
Training loss: 3.211439552875006
Validation loss: 3.081705976515327

Epoch: 5| Step: 2
Training loss: 3.0991893692874113
Validation loss: 3.088330373256643

Epoch: 5| Step: 3
Training loss: 3.459225336574537
Validation loss: 3.0767032997775856

Epoch: 5| Step: 4
Training loss: 3.095386573178631
Validation loss: 3.0807694287806613

Epoch: 5| Step: 5
Training loss: 3.162669989197622
Validation loss: 3.0816368606485307

Epoch: 5| Step: 6
Training loss: 2.6460805662292435
Validation loss: 3.0885784312507365

Epoch: 5| Step: 7
Training loss: 3.790156696069665
Validation loss: 3.084822437041875

Epoch: 5| Step: 8
Training loss: 3.653288595617134
Validation loss: 3.0889703118063805

Epoch: 5| Step: 9
Training loss: 2.7573106001052694
Validation loss: 3.0752535158171517

Epoch: 5| Step: 10
Training loss: 3.193896439212847
Validation loss: 3.071469778924343

Epoch: 49| Step: 0
Training loss: 3.698234193449242
Validation loss: 3.0714666781516007

Epoch: 5| Step: 1
Training loss: 3.694908458726898
Validation loss: 3.0711864129591855

Epoch: 5| Step: 2
Training loss: 3.254488120196402
Validation loss: 3.0698660937983044

Epoch: 5| Step: 3
Training loss: 2.487724397592154
Validation loss: 3.072130707093398

Epoch: 5| Step: 4
Training loss: 4.328448892861649
Validation loss: 3.071783298882152

Epoch: 5| Step: 5
Training loss: 3.1480573325262156
Validation loss: 3.0716963563953046

Epoch: 5| Step: 6
Training loss: 3.733624754044803
Validation loss: 3.0698883657950753

Epoch: 5| Step: 7
Training loss: 3.430896172407058
Validation loss: 3.0710808082483787

Epoch: 5| Step: 8
Training loss: 2.2072116474254937
Validation loss: 3.0696324594157276

Epoch: 5| Step: 9
Training loss: 3.2008088460546866
Validation loss: 3.067915082860647

Epoch: 5| Step: 10
Training loss: 2.9997680892316265
Validation loss: 3.0683101781884097

Epoch: 50| Step: 0
Training loss: 3.154514250927036
Validation loss: 3.0673374036942325

Epoch: 5| Step: 1
Training loss: 4.096851600795473
Validation loss: 3.0663989546995825

Epoch: 5| Step: 2
Training loss: 2.5563211146677927
Validation loss: 3.066208856093391

Epoch: 5| Step: 3
Training loss: 3.6085180280842146
Validation loss: 3.065828876051334

Epoch: 5| Step: 4
Training loss: 3.9663639856039925
Validation loss: 3.065861169856338

Epoch: 5| Step: 5
Training loss: 2.524748753804312
Validation loss: 3.0665822683154915

Epoch: 5| Step: 6
Training loss: 3.5948020390320665
Validation loss: 3.065991324992031

Epoch: 5| Step: 7
Training loss: 2.873586556000048
Validation loss: 3.063651924059815

Epoch: 5| Step: 8
Training loss: 3.4336051376553196
Validation loss: 3.0666540023449476

Epoch: 5| Step: 9
Training loss: 3.2966957947537368
Validation loss: 3.0651798355871915

Epoch: 5| Step: 10
Training loss: 3.1437391337819323
Validation loss: 3.066364257056781

Epoch: 51| Step: 0
Training loss: 3.2362827442880455
Validation loss: 3.070969822139575

Epoch: 5| Step: 1
Training loss: 3.026444391359554
Validation loss: 3.073240949574956

Epoch: 5| Step: 2
Training loss: 3.5980832719395925
Validation loss: 3.0678995167130774

Epoch: 5| Step: 3
Training loss: 3.072809577412119
Validation loss: 3.063818452099111

Epoch: 5| Step: 4
Training loss: 3.20475943199607
Validation loss: 3.063439152162954

Epoch: 5| Step: 5
Training loss: 3.86361695963021
Validation loss: 3.0601544182125724

Epoch: 5| Step: 6
Training loss: 3.2422826546183425
Validation loss: 3.0610100656715433

Epoch: 5| Step: 7
Training loss: 2.805182028183318
Validation loss: 3.0612340750438527

Epoch: 5| Step: 8
Training loss: 3.600997913651311
Validation loss: 3.0632133983969085

Epoch: 5| Step: 9
Training loss: 3.9470107247762862
Validation loss: 3.064062115662528

Epoch: 5| Step: 10
Training loss: 2.8089247974013216
Validation loss: 3.0627390148990816

Epoch: 52| Step: 0
Training loss: 3.1838360840475137
Validation loss: 3.061685393103211

Epoch: 5| Step: 1
Training loss: 3.915350970325035
Validation loss: 3.0614125353315007

Epoch: 5| Step: 2
Training loss: 3.000134306126538
Validation loss: 3.0602506505775127

Epoch: 5| Step: 3
Training loss: 3.6463248366613095
Validation loss: 3.0594441392795724

Epoch: 5| Step: 4
Training loss: 3.729958704088304
Validation loss: 3.057474979068212

Epoch: 5| Step: 5
Training loss: 2.9829874857615413
Validation loss: 3.058054114700869

Epoch: 5| Step: 6
Training loss: 3.561512994397906
Validation loss: 3.057367562484704

Epoch: 5| Step: 7
Training loss: 2.562576199770959
Validation loss: 3.0550450289741757

Epoch: 5| Step: 8
Training loss: 2.3408778584981706
Validation loss: 3.05776123045478

Epoch: 5| Step: 9
Training loss: 3.4074254238954635
Validation loss: 3.057086033236667

Epoch: 5| Step: 10
Training loss: 3.9401797909064973
Validation loss: 3.0607037796321475

Epoch: 53| Step: 0
Training loss: 3.068698138325136
Validation loss: 3.0583516315311705

Epoch: 5| Step: 1
Training loss: 3.288551272713655
Validation loss: 3.059397423585446

Epoch: 5| Step: 2
Training loss: 2.9726878501626093
Validation loss: 3.0551630027764007

Epoch: 5| Step: 3
Training loss: 3.095768741911055
Validation loss: 3.055792187141519

Epoch: 5| Step: 4
Training loss: 3.2691727490692255
Validation loss: 3.0534538969606326

Epoch: 5| Step: 5
Training loss: 3.379933460190082
Validation loss: 3.0520682268203876

Epoch: 5| Step: 6
Training loss: 3.3429506005857377
Validation loss: 3.052829339773498

Epoch: 5| Step: 7
Training loss: 3.699759841548075
Validation loss: 3.0530553978611605

Epoch: 5| Step: 8
Training loss: 4.086901344999628
Validation loss: 3.0523419770200046

Epoch: 5| Step: 9
Training loss: 3.5479343529598455
Validation loss: 3.0521005267914325

Epoch: 5| Step: 10
Training loss: 2.3696026960770995
Validation loss: 3.0517189144026378

Epoch: 54| Step: 0
Training loss: 3.2817049710150163
Validation loss: 3.051762827616847

Epoch: 5| Step: 1
Training loss: 3.285405025973568
Validation loss: 3.0516691788204113

Epoch: 5| Step: 2
Training loss: 3.733207999123767
Validation loss: 3.0529040547286144

Epoch: 5| Step: 3
Training loss: 3.510344748887562
Validation loss: 3.052122688200721

Epoch: 5| Step: 4
Training loss: 2.9596820676018867
Validation loss: 3.05069568714622

Epoch: 5| Step: 5
Training loss: 3.3801399933304124
Validation loss: 3.0495059164733367

Epoch: 5| Step: 6
Training loss: 3.7668022120120597
Validation loss: 3.0515652358593526

Epoch: 5| Step: 7
Training loss: 3.2454260404484643
Validation loss: 3.0454716944993994

Epoch: 5| Step: 8
Training loss: 2.834656817674199
Validation loss: 3.0453013657787293

Epoch: 5| Step: 9
Training loss: 2.6059701600082676
Validation loss: 3.0477507210713997

Epoch: 5| Step: 10
Training loss: 3.7452189166838723
Validation loss: 3.045927188803626

Epoch: 55| Step: 0
Training loss: 3.0179556107438708
Validation loss: 3.0490385953314076

Epoch: 5| Step: 1
Training loss: 2.758447849474237
Validation loss: 3.0459342587547478

Epoch: 5| Step: 2
Training loss: 3.492427399521739
Validation loss: 3.0460445024195555

Epoch: 5| Step: 3
Training loss: 3.1372284243555604
Validation loss: 3.0438221123964655

Epoch: 5| Step: 4
Training loss: 3.222689985618878
Validation loss: 3.0455731029761477

Epoch: 5| Step: 5
Training loss: 3.633119500426916
Validation loss: 3.0453699593885664

Epoch: 5| Step: 6
Training loss: 3.1437028824477595
Validation loss: 3.0449859072093095

Epoch: 5| Step: 7
Training loss: 3.150215196070766
Validation loss: 3.0422195076004566

Epoch: 5| Step: 8
Training loss: 3.787235787117903
Validation loss: 3.042135000029477

Epoch: 5| Step: 9
Training loss: 3.4526138963081263
Validation loss: 3.04094513159339

Epoch: 5| Step: 10
Training loss: 3.59067782237854
Validation loss: 3.042900226951529

Epoch: 56| Step: 0
Training loss: 3.083371720633524
Validation loss: 3.042252554257632

Epoch: 5| Step: 1
Training loss: 3.736384150578058
Validation loss: 3.0435215520827543

Epoch: 5| Step: 2
Training loss: 3.8311983189045247
Validation loss: 3.039196628616192

Epoch: 5| Step: 3
Training loss: 3.6244218299446596
Validation loss: 3.0408370417329538

Epoch: 5| Step: 4
Training loss: 2.638428536354353
Validation loss: 3.039360015163426

Epoch: 5| Step: 5
Training loss: 3.2473220062225376
Validation loss: 3.0383437330813328

Epoch: 5| Step: 6
Training loss: 3.3617416207299957
Validation loss: 3.0402749221242114

Epoch: 5| Step: 7
Training loss: 2.818414614870335
Validation loss: 3.0374417798932694

Epoch: 5| Step: 8
Training loss: 3.286719133011179
Validation loss: 3.039141481776005

Epoch: 5| Step: 9
Training loss: 3.4757734796356163
Validation loss: 3.036525869869916

Epoch: 5| Step: 10
Training loss: 3.0698760598478807
Validation loss: 3.039087988992279

Epoch: 57| Step: 0
Training loss: 2.9956757852000906
Validation loss: 3.0387326650015845

Epoch: 5| Step: 1
Training loss: 2.5135467664148097
Validation loss: 3.0363785398979646

Epoch: 5| Step: 2
Training loss: 3.2397437020172974
Validation loss: 3.039771600675087

Epoch: 5| Step: 3
Training loss: 3.4666740460195005
Validation loss: 3.042904407429082

Epoch: 5| Step: 4
Training loss: 3.673388749435592
Validation loss: 3.0428279817979655

Epoch: 5| Step: 5
Training loss: 3.3883207727422415
Validation loss: 3.0450614788744

Epoch: 5| Step: 6
Training loss: 3.63242999288331
Validation loss: 3.036078038116015

Epoch: 5| Step: 7
Training loss: 3.394900531238639
Validation loss: 3.0341815666026224

Epoch: 5| Step: 8
Training loss: 3.102013081988475
Validation loss: 3.034191308514379

Epoch: 5| Step: 9
Training loss: 3.7244959445398185
Validation loss: 3.0341998911718635

Epoch: 5| Step: 10
Training loss: 2.9700786628966487
Validation loss: 3.0331292221549004

Epoch: 58| Step: 0
Training loss: 3.8610072834743514
Validation loss: 3.033579645892069

Epoch: 5| Step: 1
Training loss: 3.5157107194410875
Validation loss: 3.0324498262993855

Epoch: 5| Step: 2
Training loss: 2.868889659399193
Validation loss: 3.0318833638679075

Epoch: 5| Step: 3
Training loss: 2.8576581626500652
Validation loss: 3.0307410045091365

Epoch: 5| Step: 4
Training loss: 3.3800219154776032
Validation loss: 3.030587899898652

Epoch: 5| Step: 5
Training loss: 3.169990618718944
Validation loss: 3.031305124644044

Epoch: 5| Step: 6
Training loss: 3.432111504804104
Validation loss: 3.031246962110754

Epoch: 5| Step: 7
Training loss: 3.5099452274754843
Validation loss: 3.029555774728291

Epoch: 5| Step: 8
Training loss: 3.08053742191201
Validation loss: 3.0306593523862957

Epoch: 5| Step: 9
Training loss: 3.1105810538865324
Validation loss: 3.028948652091318

Epoch: 5| Step: 10
Training loss: 3.4708755441749646
Validation loss: 3.0302962712150063

Epoch: 59| Step: 0
Training loss: 3.2538819237723637
Validation loss: 3.029862162597116

Epoch: 5| Step: 1
Training loss: 3.2319226389398303
Validation loss: 3.0280991096777794

Epoch: 5| Step: 2
Training loss: 3.4601920468168372
Validation loss: 3.0275416049879533

Epoch: 5| Step: 3
Training loss: 3.5407157219680183
Validation loss: 3.0275021840587897

Epoch: 5| Step: 4
Training loss: 3.653901348392118
Validation loss: 3.027323086469921

Epoch: 5| Step: 5
Training loss: 3.058853157901105
Validation loss: 3.0261357860610345

Epoch: 5| Step: 6
Training loss: 3.510807381609558
Validation loss: 3.025514113840264

Epoch: 5| Step: 7
Training loss: 3.377645515339779
Validation loss: 3.0266235392503162

Epoch: 5| Step: 8
Training loss: 2.895336703154538
Validation loss: 3.024674321834008

Epoch: 5| Step: 9
Training loss: 2.9845242288238376
Validation loss: 3.0262169790963123

Epoch: 5| Step: 10
Training loss: 3.2593817647715633
Validation loss: 3.024814522871659

Epoch: 60| Step: 0
Training loss: 3.5330337475380382
Validation loss: 3.024889503494193

Epoch: 5| Step: 1
Training loss: 3.9568885709716337
Validation loss: 3.0251983867703416

Epoch: 5| Step: 2
Training loss: 3.4568174479260736
Validation loss: 3.0240833978589228

Epoch: 5| Step: 3
Training loss: 3.2081236006976908
Validation loss: 3.0243292693170254

Epoch: 5| Step: 4
Training loss: 3.260153535375098
Validation loss: 3.0230205257152964

Epoch: 5| Step: 5
Training loss: 2.6929063754913325
Validation loss: 3.0248942563571894

Epoch: 5| Step: 6
Training loss: 3.2824707666796433
Validation loss: 3.0253155229088757

Epoch: 5| Step: 7
Training loss: 3.3729701119033737
Validation loss: 3.0263873518404805

Epoch: 5| Step: 8
Training loss: 3.4840027477722195
Validation loss: 3.02563809246705

Epoch: 5| Step: 9
Training loss: 3.112634531813476
Validation loss: 3.0218257056209974

Epoch: 5| Step: 10
Training loss: 2.5892492564223217
Validation loss: 3.0216407983831215

Epoch: 61| Step: 0
Training loss: 3.0702562788069843
Validation loss: 3.018729317695161

Epoch: 5| Step: 1
Training loss: 3.2158412197069386
Validation loss: 3.0227572963812306

Epoch: 5| Step: 2
Training loss: 3.0942964938134123
Validation loss: 3.020318767327483

Epoch: 5| Step: 3
Training loss: 2.6396769791279735
Validation loss: 3.019700368232117

Epoch: 5| Step: 4
Training loss: 4.128359264856507
Validation loss: 3.020656914628449

Epoch: 5| Step: 5
Training loss: 3.0566719809194423
Validation loss: 3.0191692582160354

Epoch: 5| Step: 6
Training loss: 3.507545783898973
Validation loss: 3.0170667703085603

Epoch: 5| Step: 7
Training loss: 3.5596079548335458
Validation loss: 3.0195275805358874

Epoch: 5| Step: 8
Training loss: 3.3454776471927308
Validation loss: 3.0193306132558546

Epoch: 5| Step: 9
Training loss: 3.2846259778909728
Validation loss: 3.019251862144106

Epoch: 5| Step: 10
Training loss: 3.048476047946709
Validation loss: 3.0196322510556954

Epoch: 62| Step: 0
Training loss: 3.302057179889939
Validation loss: 3.017241845178621

Epoch: 5| Step: 1
Training loss: 3.036715898446211
Validation loss: 3.0150743326341822

Epoch: 5| Step: 2
Training loss: 4.021918326665422
Validation loss: 3.0169397236551103

Epoch: 5| Step: 3
Training loss: 3.935612665199165
Validation loss: 3.01476824380753

Epoch: 5| Step: 4
Training loss: 3.467648030416871
Validation loss: 3.01666196370533

Epoch: 5| Step: 5
Training loss: 2.9944451084580526
Validation loss: 3.0172289710479503

Epoch: 5| Step: 6
Training loss: 2.8435420704374423
Validation loss: 3.0160452356345937

Epoch: 5| Step: 7
Training loss: 2.650336920714882
Validation loss: 3.0186455334224354

Epoch: 5| Step: 8
Training loss: 3.227929811586719
Validation loss: 3.0186917077989137

Epoch: 5| Step: 9
Training loss: 3.2525003058794772
Validation loss: 3.0147873921704655

Epoch: 5| Step: 10
Training loss: 3.194796420254367
Validation loss: 3.014895193194259

Epoch: 63| Step: 0
Training loss: 3.8996973849535896
Validation loss: 3.0109222960565445

Epoch: 5| Step: 1
Training loss: 2.7685459897074574
Validation loss: 3.0115370699552173

Epoch: 5| Step: 2
Training loss: 3.8953282373923726
Validation loss: 3.009475740362959

Epoch: 5| Step: 3
Training loss: 3.5640868283536453
Validation loss: 3.0082311681132183

Epoch: 5| Step: 4
Training loss: 3.0618300970319727
Validation loss: 3.0066497485790316

Epoch: 5| Step: 5
Training loss: 3.5893289987737247
Validation loss: 3.0068949081366134

Epoch: 5| Step: 6
Training loss: 2.880800946176549
Validation loss: 3.006020670103785

Epoch: 5| Step: 7
Training loss: 3.324098829175066
Validation loss: 3.002867840465919

Epoch: 5| Step: 8
Training loss: 2.34522729727786
Validation loss: 3.002809526674064

Epoch: 5| Step: 9
Training loss: 3.3170642716693406
Validation loss: 3.0024423945835412

Epoch: 5| Step: 10
Training loss: 3.1484025143934757
Validation loss: 3.003003464486228

Epoch: 64| Step: 0
Training loss: 2.4447280136510035
Validation loss: 3.000033672376229

Epoch: 5| Step: 1
Training loss: 3.809417979723186
Validation loss: 2.998072375790706

Epoch: 5| Step: 2
Training loss: 3.5041298343085003
Validation loss: 2.997196312783624

Epoch: 5| Step: 3
Training loss: 3.1855726211789124
Validation loss: 2.996673587344534

Epoch: 5| Step: 4
Training loss: 3.1998963994898744
Validation loss: 2.996066384124266

Epoch: 5| Step: 5
Training loss: 3.1860484389689594
Validation loss: 2.9968166347474123

Epoch: 5| Step: 6
Training loss: 3.3617516915180996
Validation loss: 2.9975309842446745

Epoch: 5| Step: 7
Training loss: 2.899764998549704
Validation loss: 2.9948134571939464

Epoch: 5| Step: 8
Training loss: 3.4319257449495693
Validation loss: 2.9934077109996293

Epoch: 5| Step: 9
Training loss: 3.133282024558652
Validation loss: 2.9938642914816715

Epoch: 5| Step: 10
Training loss: 3.7565976913424746
Validation loss: 2.993289785279613

Epoch: 65| Step: 0
Training loss: 3.291987117830196
Validation loss: 2.991037777674385

Epoch: 5| Step: 1
Training loss: 2.9030635962752442
Validation loss: 2.989052267041899

Epoch: 5| Step: 2
Training loss: 3.3284305915764407
Validation loss: 2.9947412727185734

Epoch: 5| Step: 3
Training loss: 3.961525536701978
Validation loss: 2.9915192807156634

Epoch: 5| Step: 4
Training loss: 2.7824948557405995
Validation loss: 2.991141808133956

Epoch: 5| Step: 5
Training loss: 3.665453811381557
Validation loss: 2.988904413636156

Epoch: 5| Step: 6
Training loss: 3.756670042598892
Validation loss: 2.9863323297298447

Epoch: 5| Step: 7
Training loss: 3.195244748765985
Validation loss: 2.983605891600749

Epoch: 5| Step: 8
Training loss: 2.7419099585776454
Validation loss: 2.986400607258318

Epoch: 5| Step: 9
Training loss: 3.059171931353093
Validation loss: 2.9840581101063695

Epoch: 5| Step: 10
Training loss: 2.951079937091671
Validation loss: 2.986792256065809

Epoch: 66| Step: 0
Training loss: 3.847157774261861
Validation loss: 2.9838444369643486

Epoch: 5| Step: 1
Training loss: 3.260954661157377
Validation loss: 2.9854036137092335

Epoch: 5| Step: 2
Training loss: 3.429000890038064
Validation loss: 2.9901315137126514

Epoch: 5| Step: 3
Training loss: 2.4697899861184567
Validation loss: 2.983595015290844

Epoch: 5| Step: 4
Training loss: 3.353558708362955
Validation loss: 2.981157531012808

Epoch: 5| Step: 5
Training loss: 3.5386703981362135
Validation loss: 2.981359324754586

Epoch: 5| Step: 6
Training loss: 2.686649365318129
Validation loss: 2.981432615705573

Epoch: 5| Step: 7
Training loss: 3.287789793984882
Validation loss: 2.9825482895471245

Epoch: 5| Step: 8
Training loss: 3.10903591434892
Validation loss: 2.9812499378792783

Epoch: 5| Step: 9
Training loss: 3.3195121967489793
Validation loss: 2.9809958271537167

Epoch: 5| Step: 10
Training loss: 3.3532005166458485
Validation loss: 2.9787779219597303

Epoch: 67| Step: 0
Training loss: 2.6577225137824514
Validation loss: 2.9804262636065104

Epoch: 5| Step: 1
Training loss: 3.066278889920799
Validation loss: 2.980076025828343

Epoch: 5| Step: 2
Training loss: 3.7338815786077637
Validation loss: 2.9846169317251445

Epoch: 5| Step: 3
Training loss: 3.1665180238336985
Validation loss: 2.9898296344924766

Epoch: 5| Step: 4
Training loss: 3.9006809667145754
Validation loss: 3.0023960454461363

Epoch: 5| Step: 5
Training loss: 3.448727945421082
Validation loss: 2.9866336014995873

Epoch: 5| Step: 6
Training loss: 3.1822965448137137
Validation loss: 2.9787717770192557

Epoch: 5| Step: 7
Training loss: 3.0687972739127005
Validation loss: 2.9757358819058526

Epoch: 5| Step: 8
Training loss: 3.431987156574964
Validation loss: 2.9748887449125743

Epoch: 5| Step: 9
Training loss: 3.1434703482589588
Validation loss: 2.976326651005386

Epoch: 5| Step: 10
Training loss: 2.8030283491298102
Validation loss: 2.9788333704375707

Epoch: 68| Step: 0
Training loss: 3.191222317460124
Validation loss: 2.9768871521882203

Epoch: 5| Step: 1
Training loss: 3.192392820084115
Validation loss: 2.9737923494655014

Epoch: 5| Step: 2
Training loss: 3.0780421211974542
Validation loss: 2.9733630347215785

Epoch: 5| Step: 3
Training loss: 3.5017389337295777
Validation loss: 2.9746931361578492

Epoch: 5| Step: 4
Training loss: 3.297468231487742
Validation loss: 2.974057105938241

Epoch: 5| Step: 5
Training loss: 2.5325868631964057
Validation loss: 2.98160337042438

Epoch: 5| Step: 6
Training loss: 3.73207755823694
Validation loss: 2.9915777306030225

Epoch: 5| Step: 7
Training loss: 3.769656986649723
Validation loss: 2.995153206950916

Epoch: 5| Step: 8
Training loss: 3.181324380480993
Validation loss: 2.9745592214576746

Epoch: 5| Step: 9
Training loss: 3.215938043509984
Validation loss: 2.9728172501953614

Epoch: 5| Step: 10
Training loss: 2.9982315255127667
Validation loss: 2.9722438406142895

Epoch: 69| Step: 0
Training loss: 3.2241970748302204
Validation loss: 2.9734504331662555

Epoch: 5| Step: 1
Training loss: 3.2501223614473167
Validation loss: 2.9759077827512628

Epoch: 5| Step: 2
Training loss: 3.6321586430642356
Validation loss: 2.980278486337756

Epoch: 5| Step: 3
Training loss: 2.7076950690532153
Validation loss: 2.985681259213675

Epoch: 5| Step: 4
Training loss: 2.7926550202128735
Validation loss: 2.9938337480249957

Epoch: 5| Step: 5
Training loss: 3.95007834055027
Validation loss: 3.0012498972729427

Epoch: 5| Step: 6
Training loss: 3.8357691834730927
Validation loss: 2.978350405253655

Epoch: 5| Step: 7
Training loss: 2.726918981469791
Validation loss: 2.9711913661282865

Epoch: 5| Step: 8
Training loss: 2.9975720753407735
Validation loss: 2.969785147799215

Epoch: 5| Step: 9
Training loss: 3.451179059662867
Validation loss: 2.9723360260730662

Epoch: 5| Step: 10
Training loss: 3.0161459675383018
Validation loss: 2.973310167451472

Epoch: 70| Step: 0
Training loss: 3.351066499301268
Validation loss: 2.978376919942619

Epoch: 5| Step: 1
Training loss: 3.092825857524659
Validation loss: 2.977336808347826

Epoch: 5| Step: 2
Training loss: 3.485444182845767
Validation loss: 2.970012862074522

Epoch: 5| Step: 3
Training loss: 3.249919010033534
Validation loss: 2.97022212110557

Epoch: 5| Step: 4
Training loss: 3.2900368884954974
Validation loss: 2.9690969492187564

Epoch: 5| Step: 5
Training loss: 3.180195835729125
Validation loss: 2.967112301807558

Epoch: 5| Step: 6
Training loss: 2.89165729957258
Validation loss: 2.968298281298291

Epoch: 5| Step: 7
Training loss: 3.5310062560634026
Validation loss: 2.9659859985881165

Epoch: 5| Step: 8
Training loss: 3.083368627672697
Validation loss: 2.9665477103423115

Epoch: 5| Step: 9
Training loss: 3.29522157401635
Validation loss: 2.967965674080963

Epoch: 5| Step: 10
Training loss: 3.3306577116594145
Validation loss: 2.9640428177132736

Epoch: 71| Step: 0
Training loss: 3.6676484151920747
Validation loss: 2.966656773439978

Epoch: 5| Step: 1
Training loss: 3.0921105558856294
Validation loss: 2.968389763642864

Epoch: 5| Step: 2
Training loss: 3.464827235374961
Validation loss: 2.9646828736794353

Epoch: 5| Step: 3
Training loss: 2.877027543006033
Validation loss: 2.9636181692573524

Epoch: 5| Step: 4
Training loss: 3.338811203921559
Validation loss: 2.963582503549631

Epoch: 5| Step: 5
Training loss: 3.405359274217483
Validation loss: 2.9631837813695223

Epoch: 5| Step: 6
Training loss: 3.2143121143044064
Validation loss: 2.9628485683678525

Epoch: 5| Step: 7
Training loss: 3.246322164750608
Validation loss: 2.9636178898502505

Epoch: 5| Step: 8
Training loss: 2.9651316225321986
Validation loss: 2.9640307547401994

Epoch: 5| Step: 9
Training loss: 3.202241654826469
Validation loss: 2.96454261167992

Epoch: 5| Step: 10
Training loss: 3.159745801527939
Validation loss: 2.967066657074418

Epoch: 72| Step: 0
Training loss: 3.2987562841403975
Validation loss: 2.962308310011554

Epoch: 5| Step: 1
Training loss: 3.924555132492863
Validation loss: 2.9648836771876956

Epoch: 5| Step: 2
Training loss: 3.295054724185317
Validation loss: 2.966403265520555

Epoch: 5| Step: 3
Training loss: 2.934267578758775
Validation loss: 2.964511283575658

Epoch: 5| Step: 4
Training loss: 3.277101200844828
Validation loss: 2.965191830650014

Epoch: 5| Step: 5
Training loss: 3.389255088726359
Validation loss: 2.973291479686449

Epoch: 5| Step: 6
Training loss: 3.133740066616047
Validation loss: 2.964520826372488

Epoch: 5| Step: 7
Training loss: 3.3353040750447707
Validation loss: 2.9677481134612527

Epoch: 5| Step: 8
Training loss: 3.3696717482174527
Validation loss: 2.96373828765027

Epoch: 5| Step: 9
Training loss: 2.6262463834974614
Validation loss: 2.9572423404787984

Epoch: 5| Step: 10
Training loss: 2.8713571440618253
Validation loss: 2.966894108316316

Epoch: 73| Step: 0
Training loss: 3.209442310314567
Validation loss: 2.9548193047191673

Epoch: 5| Step: 1
Training loss: 2.870147590696829
Validation loss: 2.9525189042250055

Epoch: 5| Step: 2
Training loss: 3.201817687677884
Validation loss: 2.9511462434501334

Epoch: 5| Step: 3
Training loss: 3.304681728348979
Validation loss: 2.95038428378568

Epoch: 5| Step: 4
Training loss: 2.477595934968791
Validation loss: 2.9500078403500107

Epoch: 5| Step: 5
Training loss: 2.7288318360691775
Validation loss: 2.95051208314649

Epoch: 5| Step: 6
Training loss: 3.420445531189751
Validation loss: 2.952271316773352

Epoch: 5| Step: 7
Training loss: 3.564511584494927
Validation loss: 2.9503379753312133

Epoch: 5| Step: 8
Training loss: 3.712819603928518
Validation loss: 2.9490736911225715

Epoch: 5| Step: 9
Training loss: 3.4007922203260343
Validation loss: 2.950039386781803

Epoch: 5| Step: 10
Training loss: 3.5697385631329714
Validation loss: 2.947588768250612

Epoch: 74| Step: 0
Training loss: 3.190241065169534
Validation loss: 2.949367927049579

Epoch: 5| Step: 1
Training loss: 3.689893043022428
Validation loss: 2.9466354216182715

Epoch: 5| Step: 2
Training loss: 3.7694854575424515
Validation loss: 2.948071133581408

Epoch: 5| Step: 3
Training loss: 2.665305823551331
Validation loss: 2.9493433141993255

Epoch: 5| Step: 4
Training loss: 3.6466154004479523
Validation loss: 2.955064490751608

Epoch: 5| Step: 5
Training loss: 2.72953621107163
Validation loss: 2.9520139933583853

Epoch: 5| Step: 6
Training loss: 2.90076840184924
Validation loss: 2.9492110179138855

Epoch: 5| Step: 7
Training loss: 3.0311644237276
Validation loss: 2.950941988370851

Epoch: 5| Step: 8
Training loss: 3.1464628553927363
Validation loss: 2.9526309114228932

Epoch: 5| Step: 9
Training loss: 2.285851736278581
Validation loss: 2.9529948012973373

Epoch: 5| Step: 10
Training loss: 4.252104967215847
Validation loss: 2.9551078197866385

Epoch: 75| Step: 0
Training loss: 3.0395924711623876
Validation loss: 2.947213354292577

Epoch: 5| Step: 1
Training loss: 3.623441163686699
Validation loss: 2.943969432527776

Epoch: 5| Step: 2
Training loss: 2.6537942642063683
Validation loss: 2.941545554048248

Epoch: 5| Step: 3
Training loss: 2.872169262045053
Validation loss: 2.9437811031997074

Epoch: 5| Step: 4
Training loss: 3.2526735899545907
Validation loss: 2.9433519001425097

Epoch: 5| Step: 5
Training loss: 3.798495853278701
Validation loss: 2.9435218522149507

Epoch: 5| Step: 6
Training loss: 3.213118877245522
Validation loss: 2.9434431753714216

Epoch: 5| Step: 7
Training loss: 3.4490518842794553
Validation loss: 2.942064502591779

Epoch: 5| Step: 8
Training loss: 3.029735226031469
Validation loss: 2.943882945803247

Epoch: 5| Step: 9
Training loss: 3.2525155529028607
Validation loss: 2.9428590376401265

Epoch: 5| Step: 10
Training loss: 3.222034741205494
Validation loss: 2.939832959653688

Epoch: 76| Step: 0
Training loss: 3.557763012125971
Validation loss: 2.940210402378592

Epoch: 5| Step: 1
Training loss: 2.7867771905065513
Validation loss: 2.937677731064884

Epoch: 5| Step: 2
Training loss: 3.259173431454489
Validation loss: 2.9396729680587024

Epoch: 5| Step: 3
Training loss: 3.2846789654031214
Validation loss: 2.9382682141377865

Epoch: 5| Step: 4
Training loss: 3.665220813630592
Validation loss: 2.937170650369865

Epoch: 5| Step: 5
Training loss: 3.207362502875769
Validation loss: 2.9388715133801058

Epoch: 5| Step: 6
Training loss: 3.078210819810152
Validation loss: 2.9364504976061125

Epoch: 5| Step: 7
Training loss: 3.2611276422183066
Validation loss: 2.9452717208313235

Epoch: 5| Step: 8
Training loss: 3.4547199691150716
Validation loss: 2.9406321872604475

Epoch: 5| Step: 9
Training loss: 2.754332424221684
Validation loss: 2.935813807343438

Epoch: 5| Step: 10
Training loss: 3.041621290591322
Validation loss: 2.9355831974592186

Epoch: 77| Step: 0
Training loss: 3.0795588373087286
Validation loss: 2.9380058458707454

Epoch: 5| Step: 1
Training loss: 3.056866193254444
Validation loss: 2.937641862119977

Epoch: 5| Step: 2
Training loss: 3.3855400806331097
Validation loss: 2.9373992103211197

Epoch: 5| Step: 3
Training loss: 3.0119435663091134
Validation loss: 2.9371148640015736

Epoch: 5| Step: 4
Training loss: 3.1010445034914085
Validation loss: 2.937364076337881

Epoch: 5| Step: 5
Training loss: 3.4219579120502432
Validation loss: 2.9369405031667584

Epoch: 5| Step: 6
Training loss: 3.708849381676467
Validation loss: 2.937135751064257

Epoch: 5| Step: 7
Training loss: 3.2556909472969826
Validation loss: 2.936814202148579

Epoch: 5| Step: 8
Training loss: 3.47936144681401
Validation loss: 2.9381053390731786

Epoch: 5| Step: 9
Training loss: 2.9704233372620927
Validation loss: 2.9361025318786664

Epoch: 5| Step: 10
Training loss: 2.904139090525228
Validation loss: 2.9362437735117295

Epoch: 78| Step: 0
Training loss: 2.8839487870599014
Validation loss: 2.935003110948224

Epoch: 5| Step: 1
Training loss: 3.503688095259032
Validation loss: 2.9349164613279317

Epoch: 5| Step: 2
Training loss: 3.3567413652348335
Validation loss: 2.9346111774764374

Epoch: 5| Step: 3
Training loss: 3.2287983017696757
Validation loss: 2.933959214591272

Epoch: 5| Step: 4
Training loss: 3.3358929025853827
Validation loss: 2.9312829909416354

Epoch: 5| Step: 5
Training loss: 2.281614300628723
Validation loss: 2.9313668190830104

Epoch: 5| Step: 6
Training loss: 3.230688380532758
Validation loss: 2.932161220775378

Epoch: 5| Step: 7
Training loss: 3.45610780613142
Validation loss: 2.9318842255735245

Epoch: 5| Step: 8
Training loss: 3.144119520065597
Validation loss: 2.9380753406882234

Epoch: 5| Step: 9
Training loss: 3.2904577489881217
Validation loss: 2.93687603741884

Epoch: 5| Step: 10
Training loss: 3.6034379490696673
Validation loss: 2.9424082093443764

Epoch: 79| Step: 0
Training loss: 2.8317972020744633
Validation loss: 2.9398861751785095

Epoch: 5| Step: 1
Training loss: 3.5639042010977304
Validation loss: 2.9366813693669576

Epoch: 5| Step: 2
Training loss: 3.2310595635201675
Validation loss: 2.9312942729982154

Epoch: 5| Step: 3
Training loss: 2.9343839310092723
Validation loss: 2.9283597444186786

Epoch: 5| Step: 4
Training loss: 3.2401504919634965
Validation loss: 2.92943944349859

Epoch: 5| Step: 5
Training loss: 3.582008087183153
Validation loss: 2.928226369654388

Epoch: 5| Step: 6
Training loss: 2.632319644788852
Validation loss: 2.928048199730685

Epoch: 5| Step: 7
Training loss: 3.1298392401413238
Validation loss: 2.9276549034833885

Epoch: 5| Step: 8
Training loss: 3.6763187870774687
Validation loss: 2.9256276447237846

Epoch: 5| Step: 9
Training loss: 3.1262817805831973
Validation loss: 2.9265044522362595

Epoch: 5| Step: 10
Training loss: 3.305648916370397
Validation loss: 2.926139292772398

Epoch: 80| Step: 0
Training loss: 2.2330934277066095
Validation loss: 2.927360466954902

Epoch: 5| Step: 1
Training loss: 3.247314811048609
Validation loss: 2.9278700951419214

Epoch: 5| Step: 2
Training loss: 3.4036446503002598
Validation loss: 2.9284956229162686

Epoch: 5| Step: 3
Training loss: 3.324859593230557
Validation loss: 2.9280231493794

Epoch: 5| Step: 4
Training loss: 3.001715646358635
Validation loss: 2.9252116487573017

Epoch: 5| Step: 5
Training loss: 3.500789689486103
Validation loss: 2.92944268497869

Epoch: 5| Step: 6
Training loss: 3.3358648859558917
Validation loss: 2.9248421022595914

Epoch: 5| Step: 7
Training loss: 3.480207885145387
Validation loss: 2.9249246512735487

Epoch: 5| Step: 8
Training loss: 2.8535647534913524
Validation loss: 2.930462168666313

Epoch: 5| Step: 9
Training loss: 2.874033226336116
Validation loss: 2.927921500242536

Epoch: 5| Step: 10
Training loss: 3.9076828426798675
Validation loss: 2.9259265541728583

Epoch: 81| Step: 0
Training loss: 3.200522058340303
Validation loss: 2.9266518438397733

Epoch: 5| Step: 1
Training loss: 3.5293515934209374
Validation loss: 2.9268883462217135

Epoch: 5| Step: 2
Training loss: 3.023353910646015
Validation loss: 2.9250736430990574

Epoch: 5| Step: 3
Training loss: 3.040842510727714
Validation loss: 2.9272292869338754

Epoch: 5| Step: 4
Training loss: 3.6727112162845934
Validation loss: 2.9230114258605617

Epoch: 5| Step: 5
Training loss: 3.9554109861860263
Validation loss: 2.922886697263827

Epoch: 5| Step: 6
Training loss: 2.901064604982998
Validation loss: 2.920245056562184

Epoch: 5| Step: 7
Training loss: 2.9130792262850114
Validation loss: 2.9196677309948034

Epoch: 5| Step: 8
Training loss: 2.9031854695078176
Validation loss: 2.918537036507689

Epoch: 5| Step: 9
Training loss: 3.1390015310895625
Validation loss: 2.9183430865442634

Epoch: 5| Step: 10
Training loss: 2.7464917085842924
Validation loss: 2.9188421518500713

Epoch: 82| Step: 0
Training loss: 2.5768546008834567
Validation loss: 2.9194704938337654

Epoch: 5| Step: 1
Training loss: 2.7043924171798466
Validation loss: 2.9172880615352517

Epoch: 5| Step: 2
Training loss: 3.355223747785694
Validation loss: 2.9173595402409163

Epoch: 5| Step: 3
Training loss: 3.4226640462187943
Validation loss: 2.923054816938094

Epoch: 5| Step: 4
Training loss: 2.8942370142919294
Validation loss: 2.921621825268812

Epoch: 5| Step: 5
Training loss: 4.071377722821802
Validation loss: 2.9310209394038598

Epoch: 5| Step: 6
Training loss: 3.7737849926534457
Validation loss: 2.9199440896315525

Epoch: 5| Step: 7
Training loss: 3.3037307111716108
Validation loss: 2.9153068665849244

Epoch: 5| Step: 8
Training loss: 3.0594880220540634
Validation loss: 2.917347050487135

Epoch: 5| Step: 9
Training loss: 3.1898231268371875
Validation loss: 2.917402403776436

Epoch: 5| Step: 10
Training loss: 2.5348927224237277
Validation loss: 2.917365793445898

Epoch: 83| Step: 0
Training loss: 3.049889740748852
Validation loss: 2.91888638834492

Epoch: 5| Step: 1
Training loss: 3.2090790282468413
Validation loss: 2.917266158857931

Epoch: 5| Step: 2
Training loss: 3.776128279470921
Validation loss: 2.917457901004996

Epoch: 5| Step: 3
Training loss: 2.5416441014856788
Validation loss: 2.9158165749082747

Epoch: 5| Step: 4
Training loss: 3.2028829343556287
Validation loss: 2.9158493185895114

Epoch: 5| Step: 5
Training loss: 3.099181060908029
Validation loss: 2.9175419585436746

Epoch: 5| Step: 6
Training loss: 3.2571692986717715
Validation loss: 2.917961616000567

Epoch: 5| Step: 7
Training loss: 3.9091857864366615
Validation loss: 2.9164968824997075

Epoch: 5| Step: 8
Training loss: 2.8585792643306966
Validation loss: 2.9164881925575954

Epoch: 5| Step: 9
Training loss: 2.7422335802863507
Validation loss: 2.9145550750171987

Epoch: 5| Step: 10
Training loss: 3.492809129385522
Validation loss: 2.9161601735772336

Epoch: 84| Step: 0
Training loss: 3.377852753035781
Validation loss: 2.917369829550428

Epoch: 5| Step: 1
Training loss: 2.6330312756840675
Validation loss: 2.9154961910915644

Epoch: 5| Step: 2
Training loss: 2.9915598716552947
Validation loss: 2.9157916243315323

Epoch: 5| Step: 3
Training loss: 3.3697597653482165
Validation loss: 2.9157144351551048

Epoch: 5| Step: 4
Training loss: 2.9250761234126523
Validation loss: 2.9169238760845246

Epoch: 5| Step: 5
Training loss: 3.2932178045645237
Validation loss: 2.9186050756392268

Epoch: 5| Step: 6
Training loss: 3.2451915382319134
Validation loss: 2.921528074682164

Epoch: 5| Step: 7
Training loss: 3.3478159204282356
Validation loss: 2.9229829179386186

Epoch: 5| Step: 8
Training loss: 2.532660762282268
Validation loss: 2.917275893987339

Epoch: 5| Step: 9
Training loss: 3.608564013242788
Validation loss: 2.9137224355646807

Epoch: 5| Step: 10
Training loss: 3.808511742907171
Validation loss: 2.9098739171035595

Epoch: 85| Step: 0
Training loss: 3.082621741447089
Validation loss: 2.909488797609335

Epoch: 5| Step: 1
Training loss: 3.4007995114229437
Validation loss: 2.9091791120602952

Epoch: 5| Step: 2
Training loss: 3.271141394101245
Validation loss: 2.9085474428275915

Epoch: 5| Step: 3
Training loss: 3.006390123809298
Validation loss: 2.9083790932035476

Epoch: 5| Step: 4
Training loss: 3.7658738176758844
Validation loss: 2.908984665083342

Epoch: 5| Step: 5
Training loss: 3.495685370265142
Validation loss: 2.9086103642410848

Epoch: 5| Step: 6
Training loss: 2.517271557380612
Validation loss: 2.9065119033990596

Epoch: 5| Step: 7
Training loss: 3.253789453139045
Validation loss: 2.907964284846878

Epoch: 5| Step: 8
Training loss: 3.0506468290248634
Validation loss: 2.908890428777099

Epoch: 5| Step: 9
Training loss: 3.268435204484416
Validation loss: 2.9063841909742756

Epoch: 5| Step: 10
Training loss: 2.948847503537796
Validation loss: 2.90594203277433

Epoch: 86| Step: 0
Training loss: 3.2860588076733794
Validation loss: 2.906619639138536

Epoch: 5| Step: 1
Training loss: 3.562733692736021
Validation loss: 2.905340045411175

Epoch: 5| Step: 2
Training loss: 2.89207842604164
Validation loss: 2.903525016291156

Epoch: 5| Step: 3
Training loss: 2.7759723952896938
Validation loss: 2.9043320329720896

Epoch: 5| Step: 4
Training loss: 3.3830096956001916
Validation loss: 2.902960039038262

Epoch: 5| Step: 5
Training loss: 2.976765142636635
Validation loss: 2.9016386901541926

Epoch: 5| Step: 6
Training loss: 3.695794943029888
Validation loss: 2.9021470394594515

Epoch: 5| Step: 7
Training loss: 3.1947310461945824
Validation loss: 2.9018330321566546

Epoch: 5| Step: 8
Training loss: 3.085503888147674
Validation loss: 2.8990660923549894

Epoch: 5| Step: 9
Training loss: 2.788616411881481
Validation loss: 2.9009887109596

Epoch: 5| Step: 10
Training loss: 3.4004994418257772
Validation loss: 2.9002486953986355

Epoch: 87| Step: 0
Training loss: 3.1210531105575403
Validation loss: 2.9033702194023645

Epoch: 5| Step: 1
Training loss: 2.905695380336787
Validation loss: 2.8991957197007627

Epoch: 5| Step: 2
Training loss: 3.3040163337082102
Validation loss: 2.8997691590538075

Epoch: 5| Step: 3
Training loss: 2.8823241773912627
Validation loss: 2.902065574856028

Epoch: 5| Step: 4
Training loss: 2.6811644818377354
Validation loss: 2.899239137389138

Epoch: 5| Step: 5
Training loss: 2.860136170513459
Validation loss: 2.9006025876390953

Epoch: 5| Step: 6
Training loss: 3.626264022910491
Validation loss: 2.912702013720808

Epoch: 5| Step: 7
Training loss: 3.2079437481711963
Validation loss: 2.913718535184053

Epoch: 5| Step: 8
Training loss: 3.4418636022447955
Validation loss: 2.902788047761238

Epoch: 5| Step: 9
Training loss: 3.442241658231884
Validation loss: 2.9018986845332586

Epoch: 5| Step: 10
Training loss: 3.551663565047324
Validation loss: 2.8995780048682986

Epoch: 88| Step: 0
Training loss: 3.1395340728101577
Validation loss: 2.8996420054814815

Epoch: 5| Step: 1
Training loss: 3.7946391488706275
Validation loss: 2.896167084028656

Epoch: 5| Step: 2
Training loss: 3.4575648698768817
Validation loss: 2.894024833463855

Epoch: 5| Step: 3
Training loss: 2.2401524256888914
Validation loss: 2.8922607139596366

Epoch: 5| Step: 4
Training loss: 2.9792471565808563
Validation loss: 2.8921459060340515

Epoch: 5| Step: 5
Training loss: 3.1360199982530976
Validation loss: 2.8949541156100973

Epoch: 5| Step: 6
Training loss: 3.07889280086388
Validation loss: 2.8932337843358753

Epoch: 5| Step: 7
Training loss: 3.3812104058900156
Validation loss: 2.893419224596591

Epoch: 5| Step: 8
Training loss: 3.386022863645472
Validation loss: 2.892743234670043

Epoch: 5| Step: 9
Training loss: 2.6607398290679005
Validation loss: 2.8902394701418443

Epoch: 5| Step: 10
Training loss: 3.5886641630499074
Validation loss: 2.8926865471927794

Epoch: 89| Step: 0
Training loss: 3.945642438632781
Validation loss: 2.8937766248502763

Epoch: 5| Step: 1
Training loss: 3.122909762370846
Validation loss: 2.8932151907440797

Epoch: 5| Step: 2
Training loss: 3.2043612443819547
Validation loss: 2.9072775063621212

Epoch: 5| Step: 3
Training loss: 2.7291498450617433
Validation loss: 2.9216980590204544

Epoch: 5| Step: 4
Training loss: 3.036126216219917
Validation loss: 2.9256699586346597

Epoch: 5| Step: 5
Training loss: 3.127005429518438
Validation loss: 2.924787432338096

Epoch: 5| Step: 6
Training loss: 3.235514417073554
Validation loss: 2.894315740836999

Epoch: 5| Step: 7
Training loss: 3.7614952646895277
Validation loss: 2.8911067606640395

Epoch: 5| Step: 8
Training loss: 2.5631360450921514
Validation loss: 2.8893728748737555

Epoch: 5| Step: 9
Training loss: 3.08703562838968
Validation loss: 2.889019545954766

Epoch: 5| Step: 10
Training loss: 3.0882576634427688
Validation loss: 2.887909198509949

Epoch: 90| Step: 0
Training loss: 3.7319386726892856
Validation loss: 2.8871890306126256

Epoch: 5| Step: 1
Training loss: 2.7727582072765173
Validation loss: 2.8884930030449327

Epoch: 5| Step: 2
Training loss: 2.7298441815186254
Validation loss: 2.8880944382952864

Epoch: 5| Step: 3
Training loss: 3.4233113936402497
Validation loss: 2.8849783161985125

Epoch: 5| Step: 4
Training loss: 2.908330029446566
Validation loss: 2.888013101031452

Epoch: 5| Step: 5
Training loss: 3.5252218190194804
Validation loss: 2.8871618241088823

Epoch: 5| Step: 6
Training loss: 3.041092143385423
Validation loss: 2.888010580010138

Epoch: 5| Step: 7
Training loss: 2.554906433243573
Validation loss: 2.8845714804497917

Epoch: 5| Step: 8
Training loss: 3.499948909931593
Validation loss: 2.8855300163755264

Epoch: 5| Step: 9
Training loss: 3.456352555200329
Validation loss: 2.8840397964825946

Epoch: 5| Step: 10
Training loss: 3.104177760844706
Validation loss: 2.886339130717895

Epoch: 91| Step: 0
Training loss: 3.727402438467499
Validation loss: 2.884956358390088

Epoch: 5| Step: 1
Training loss: 2.8918169193276513
Validation loss: 2.883696578294853

Epoch: 5| Step: 2
Training loss: 3.1168481933713843
Validation loss: 2.884592968380612

Epoch: 5| Step: 3
Training loss: 2.5481705442152034
Validation loss: 2.8856984450288743

Epoch: 5| Step: 4
Training loss: 2.964790192976005
Validation loss: 2.8829801839548597

Epoch: 5| Step: 5
Training loss: 3.292967157148562
Validation loss: 2.883016641381251

Epoch: 5| Step: 6
Training loss: 3.0758136262127134
Validation loss: 2.8825207910137527

Epoch: 5| Step: 7
Training loss: 3.324750308649984
Validation loss: 2.885652585704463

Epoch: 5| Step: 8
Training loss: 3.5402369287374933
Validation loss: 2.884809625110803

Epoch: 5| Step: 9
Training loss: 3.429851693152916
Validation loss: 2.8868090273702633

Epoch: 5| Step: 10
Training loss: 2.902648499047206
Validation loss: 2.888618062991961

Epoch: 92| Step: 0
Training loss: 3.0980829279361037
Validation loss: 2.88415746836356

Epoch: 5| Step: 1
Training loss: 3.393561010560656
Validation loss: 2.882593628090522

Epoch: 5| Step: 2
Training loss: 3.3364711933124362
Validation loss: 2.8862434471144556

Epoch: 5| Step: 3
Training loss: 3.0969428338898726
Validation loss: 2.880287611841463

Epoch: 5| Step: 4
Training loss: 3.0785999222177445
Validation loss: 2.8820663950852943

Epoch: 5| Step: 5
Training loss: 2.7409947945101054
Validation loss: 2.8839831334940267

Epoch: 5| Step: 6
Training loss: 3.559179800038068
Validation loss: 2.8849599537593966

Epoch: 5| Step: 7
Training loss: 3.2476159668406934
Validation loss: 2.8816791704075815

Epoch: 5| Step: 8
Training loss: 3.114087085464132
Validation loss: 2.8876990420649955

Epoch: 5| Step: 9
Training loss: 3.3833538793932814
Validation loss: 2.8923624313108487

Epoch: 5| Step: 10
Training loss: 2.8078466278532512
Validation loss: 2.8901368407167487

Epoch: 93| Step: 0
Training loss: 3.3942345598190933
Validation loss: 2.888857821078456

Epoch: 5| Step: 1
Training loss: 3.1189981426834
Validation loss: 2.8788769277569632

Epoch: 5| Step: 2
Training loss: 3.1909116550841325
Validation loss: 2.877510438921176

Epoch: 5| Step: 3
Training loss: 3.501067543709729
Validation loss: 2.8777759716570794

Epoch: 5| Step: 4
Training loss: 3.2881442348930574
Validation loss: 2.8734278952807473

Epoch: 5| Step: 5
Training loss: 2.8670592734120968
Validation loss: 2.871142119652525

Epoch: 5| Step: 6
Training loss: 2.93922535973886
Validation loss: 2.874824306332528

Epoch: 5| Step: 7
Training loss: 3.6484555360401356
Validation loss: 2.8777856942786135

Epoch: 5| Step: 8
Training loss: 2.8561508261660626
Validation loss: 2.8784350293969228

Epoch: 5| Step: 9
Training loss: 2.9803954749143022
Validation loss: 2.876248752354691

Epoch: 5| Step: 10
Training loss: 3.0102245617106824
Validation loss: 2.875041136552115

Epoch: 94| Step: 0
Training loss: 3.4806517821542102
Validation loss: 2.8747487094339905

Epoch: 5| Step: 1
Training loss: 3.028699135851128
Validation loss: 2.87310973468313

Epoch: 5| Step: 2
Training loss: 3.039309611730037
Validation loss: 2.8712453056997544

Epoch: 5| Step: 3
Training loss: 3.7046661389208473
Validation loss: 2.8696725278399122

Epoch: 5| Step: 4
Training loss: 2.8004532413130927
Validation loss: 2.8704463802318974

Epoch: 5| Step: 5
Training loss: 3.128158651470077
Validation loss: 2.8694171621328355

Epoch: 5| Step: 6
Training loss: 3.3344852046755578
Validation loss: 2.868806340685351

Epoch: 5| Step: 7
Training loss: 3.3440948023339696
Validation loss: 2.868252428387725

Epoch: 5| Step: 8
Training loss: 3.289532335661974
Validation loss: 2.8691971307829247

Epoch: 5| Step: 9
Training loss: 2.956141792881658
Validation loss: 2.8724578525555478

Epoch: 5| Step: 10
Training loss: 2.47083445565604
Validation loss: 2.8720442178008283

Epoch: 95| Step: 0
Training loss: 3.4085491015744864
Validation loss: 2.884160313634568

Epoch: 5| Step: 1
Training loss: 2.8685622076929578
Validation loss: 2.8818645802446836

Epoch: 5| Step: 2
Training loss: 3.4008872837858948
Validation loss: 2.8902807046751593

Epoch: 5| Step: 3
Training loss: 3.383110050920334
Validation loss: 2.8829817810165848

Epoch: 5| Step: 4
Training loss: 2.6089795206946906
Validation loss: 2.8665012788985855

Epoch: 5| Step: 5
Training loss: 3.0180278159061107
Validation loss: 2.863060136418069

Epoch: 5| Step: 6
Training loss: 3.2867806463486295
Validation loss: 2.864726104907374

Epoch: 5| Step: 7
Training loss: 2.9532168742425666
Validation loss: 2.8616485406220553

Epoch: 5| Step: 8
Training loss: 3.114692167253921
Validation loss: 2.86430031788827

Epoch: 5| Step: 9
Training loss: 3.583564721258735
Validation loss: 2.8596780187070623

Epoch: 5| Step: 10
Training loss: 3.154805674424938
Validation loss: 2.8624748808328286

Epoch: 96| Step: 0
Training loss: 3.43904412007739
Validation loss: 2.8621511741984547

Epoch: 5| Step: 1
Training loss: 2.674731774118026
Validation loss: 2.8620032690233392

Epoch: 5| Step: 2
Training loss: 3.5474854334719685
Validation loss: 2.862023749387706

Epoch: 5| Step: 3
Training loss: 3.3777883808348808
Validation loss: 2.8646238358096316

Epoch: 5| Step: 4
Training loss: 2.98571587443228
Validation loss: 2.8653051570300483

Epoch: 5| Step: 5
Training loss: 2.880733412235607
Validation loss: 2.8623260376225086

Epoch: 5| Step: 6
Training loss: 3.0465128365488363
Validation loss: 2.8610457469199786

Epoch: 5| Step: 7
Training loss: 3.3636895440323875
Validation loss: 2.86064051535759

Epoch: 5| Step: 8
Training loss: 3.2574449510233867
Validation loss: 2.8604411421548157

Epoch: 5| Step: 9
Training loss: 2.9961704607397706
Validation loss: 2.8576550909354816

Epoch: 5| Step: 10
Training loss: 3.0953895000834004
Validation loss: 2.8589151605440923

Epoch: 97| Step: 0
Training loss: 3.457776281388631
Validation loss: 2.8566346234712143

Epoch: 5| Step: 1
Training loss: 2.985088642535827
Validation loss: 2.8577080021931627

Epoch: 5| Step: 2
Training loss: 3.057879485116378
Validation loss: 2.856708030822879

Epoch: 5| Step: 3
Training loss: 3.0819263512923274
Validation loss: 2.862203342218833

Epoch: 5| Step: 4
Training loss: 3.08528767757656
Validation loss: 2.861236518609447

Epoch: 5| Step: 5
Training loss: 3.1670984843786303
Validation loss: 2.863839838786944

Epoch: 5| Step: 6
Training loss: 3.0007672918104813
Validation loss: 2.868368958616885

Epoch: 5| Step: 7
Training loss: 2.542860740793784
Validation loss: 2.865838184125785

Epoch: 5| Step: 8
Training loss: 3.223913550900396
Validation loss: 2.865318715557376

Epoch: 5| Step: 9
Training loss: 3.4591948726799555
Validation loss: 2.868606374120491

Epoch: 5| Step: 10
Training loss: 3.635827173412443
Validation loss: 2.862594119359393

Epoch: 98| Step: 0
Training loss: 3.1432176203648656
Validation loss: 2.8561880649660405

Epoch: 5| Step: 1
Training loss: 3.1117713167164234
Validation loss: 2.8532498507477055

Epoch: 5| Step: 2
Training loss: 3.137144067035951
Validation loss: 2.851400022644132

Epoch: 5| Step: 3
Training loss: 2.8093085937798734
Validation loss: 2.84900545578924

Epoch: 5| Step: 4
Training loss: 3.3567292906580533
Validation loss: 2.8507243602645955

Epoch: 5| Step: 5
Training loss: 3.18094364632244
Validation loss: 2.8512709961539744

Epoch: 5| Step: 6
Training loss: 2.866276650918332
Validation loss: 2.850440064719783

Epoch: 5| Step: 7
Training loss: 3.3539967622235207
Validation loss: 2.8540729453125593

Epoch: 5| Step: 8
Training loss: 3.417296948487659
Validation loss: 2.861143145919661

Epoch: 5| Step: 9
Training loss: 3.229471221016005
Validation loss: 2.8560195700653215

Epoch: 5| Step: 10
Training loss: 3.0046369956022634
Validation loss: 2.870773034776928

Epoch: 99| Step: 0
Training loss: 3.3374368840225257
Validation loss: 2.885818848494701

Epoch: 5| Step: 1
Training loss: 2.706043674277255
Validation loss: 2.887144322661733

Epoch: 5| Step: 2
Training loss: 3.2142926806419814
Validation loss: 2.881716314179547

Epoch: 5| Step: 3
Training loss: 3.1696706544206004
Validation loss: 2.8530978953350155

Epoch: 5| Step: 4
Training loss: 2.602643404187668
Validation loss: 2.851309557439884

Epoch: 5| Step: 5
Training loss: 2.947013707704122
Validation loss: 2.853017530016733

Epoch: 5| Step: 6
Training loss: 3.2719637300397757
Validation loss: 2.8545388060796704

Epoch: 5| Step: 7
Training loss: 3.594676553450363
Validation loss: 2.8609254290405395

Epoch: 5| Step: 8
Training loss: 3.177908734940685
Validation loss: 2.869406523077042

Epoch: 5| Step: 9
Training loss: 3.648542316899724
Validation loss: 2.860740497405331

Epoch: 5| Step: 10
Training loss: 3.036320172280689
Validation loss: 2.8533893158662758

Epoch: 100| Step: 0
Training loss: 2.3343857934745658
Validation loss: 2.8513165812777292

Epoch: 5| Step: 1
Training loss: 3.614266783881732
Validation loss: 2.852471254889529

Epoch: 5| Step: 2
Training loss: 3.3801831605480404
Validation loss: 2.8495271398407054

Epoch: 5| Step: 3
Training loss: 4.166415753756974
Validation loss: 2.8469603423997487

Epoch: 5| Step: 4
Training loss: 2.801426258593366
Validation loss: 2.847203485957647

Epoch: 5| Step: 5
Training loss: 2.363392724805037
Validation loss: 2.844961495873408

Epoch: 5| Step: 6
Training loss: 2.8385162819010192
Validation loss: 2.842324300793737

Epoch: 5| Step: 7
Training loss: 3.0879859016867472
Validation loss: 2.8438699690899276

Epoch: 5| Step: 8
Training loss: 3.531217051664595
Validation loss: 2.841732864383488

Epoch: 5| Step: 9
Training loss: 3.3248600234777124
Validation loss: 2.846037988089244

Epoch: 5| Step: 10
Training loss: 2.6211875296130893
Validation loss: 2.844450997532304

Epoch: 101| Step: 0
Training loss: 3.7396875365180677
Validation loss: 2.852396888269505

Epoch: 5| Step: 1
Training loss: 3.1076391540943984
Validation loss: 2.8452156290026536

Epoch: 5| Step: 2
Training loss: 3.123737232659952
Validation loss: 2.846632842049572

Epoch: 5| Step: 3
Training loss: 3.244680893641546
Validation loss: 2.849032877291224

Epoch: 5| Step: 4
Training loss: 2.55446332128732
Validation loss: 2.848083653974848

Epoch: 5| Step: 5
Training loss: 3.2754037273329173
Validation loss: 2.857652260541346

Epoch: 5| Step: 6
Training loss: 2.8572940445817174
Validation loss: 2.873485630032479

Epoch: 5| Step: 7
Training loss: 2.7544136175188525
Validation loss: 2.870047831849034

Epoch: 5| Step: 8
Training loss: 3.122759664472773
Validation loss: 2.850916675093125

Epoch: 5| Step: 9
Training loss: 3.585149940323904
Validation loss: 2.844606907114611

Epoch: 5| Step: 10
Training loss: 3.012528326764026
Validation loss: 2.8419563201647584

Epoch: 102| Step: 0
Training loss: 3.0692094757991755
Validation loss: 2.8414689184644293

Epoch: 5| Step: 1
Training loss: 3.0558708220936373
Validation loss: 2.840154441679368

Epoch: 5| Step: 2
Training loss: 3.465598934753198
Validation loss: 2.8403327113475965

Epoch: 5| Step: 3
Training loss: 3.2841539883862927
Validation loss: 2.839298480588505

Epoch: 5| Step: 4
Training loss: 3.736444003855178
Validation loss: 2.8385535407102576

Epoch: 5| Step: 5
Training loss: 3.085413480280936
Validation loss: 2.8398632888380195

Epoch: 5| Step: 6
Training loss: 2.9637983285864338
Validation loss: 2.8381629482726427

Epoch: 5| Step: 7
Training loss: 3.0500781315035796
Validation loss: 2.840487885775658

Epoch: 5| Step: 8
Training loss: 3.0643393773204974
Validation loss: 2.8385035563169687

Epoch: 5| Step: 9
Training loss: 2.854651045710042
Validation loss: 2.83850601654079

Epoch: 5| Step: 10
Training loss: 2.8720218326195672
Validation loss: 2.839497909095784

Epoch: 103| Step: 0
Training loss: 3.198775152395982
Validation loss: 2.8516579106745916

Epoch: 5| Step: 1
Training loss: 2.918506986315915
Validation loss: 2.8371197344730903

Epoch: 5| Step: 2
Training loss: 3.3521979736551417
Validation loss: 2.836582905111436

Epoch: 5| Step: 3
Training loss: 2.995159058080743
Validation loss: 2.838076291296435

Epoch: 5| Step: 4
Training loss: 3.1454306506854484
Validation loss: 2.833686705841026

Epoch: 5| Step: 5
Training loss: 2.8665340001065904
Validation loss: 2.8340154516806932

Epoch: 5| Step: 6
Training loss: 3.173101930141833
Validation loss: 2.8353668988502605

Epoch: 5| Step: 7
Training loss: 3.3601713434309204
Validation loss: 2.8352340304404384

Epoch: 5| Step: 8
Training loss: 2.9210995547820264
Validation loss: 2.8353537395965476

Epoch: 5| Step: 9
Training loss: 3.4948815657777983
Validation loss: 2.8372099654043614

Epoch: 5| Step: 10
Training loss: 3.0622827881057315
Validation loss: 2.8389892989841914

Epoch: 104| Step: 0
Training loss: 3.035625328235165
Validation loss: 2.836884561060933

Epoch: 5| Step: 1
Training loss: 3.778898406400145
Validation loss: 2.837172875090308

Epoch: 5| Step: 2
Training loss: 2.4792348601207963
Validation loss: 2.83274570164589

Epoch: 5| Step: 3
Training loss: 3.2625213914659548
Validation loss: 2.8389745049044888

Epoch: 5| Step: 4
Training loss: 2.0963551270539984
Validation loss: 2.8308080621903104

Epoch: 5| Step: 5
Training loss: 3.6030221492648726
Validation loss: 2.833437111224954

Epoch: 5| Step: 6
Training loss: 3.028567985830895
Validation loss: 2.8307362038349546

Epoch: 5| Step: 7
Training loss: 3.3049065267067017
Validation loss: 2.832124478139099

Epoch: 5| Step: 8
Training loss: 3.6766501685769843
Validation loss: 2.8269404204206245

Epoch: 5| Step: 9
Training loss: 3.1169558943368467
Validation loss: 2.8282238336730954

Epoch: 5| Step: 10
Training loss: 2.6176020507447713
Validation loss: 2.8310082445554934

Epoch: 105| Step: 0
Training loss: 3.137236175995459
Validation loss: 2.8268971447057787

Epoch: 5| Step: 1
Training loss: 2.5303974364155253
Validation loss: 2.82953419824813

Epoch: 5| Step: 2
Training loss: 3.4217380165307767
Validation loss: 2.8276002893793453

Epoch: 5| Step: 3
Training loss: 3.4874025884990707
Validation loss: 2.827275801072731

Epoch: 5| Step: 4
Training loss: 3.3973465494810076
Validation loss: 2.828131113299009

Epoch: 5| Step: 5
Training loss: 3.0232526540313205
Validation loss: 2.828053317319872

Epoch: 5| Step: 6
Training loss: 3.3655819350863805
Validation loss: 2.82679117807423

Epoch: 5| Step: 7
Training loss: 3.015539612821251
Validation loss: 2.8244499668222915

Epoch: 5| Step: 8
Training loss: 2.6729610979565273
Validation loss: 2.8270824983140814

Epoch: 5| Step: 9
Training loss: 3.5149597894965092
Validation loss: 2.8275396103453287

Epoch: 5| Step: 10
Training loss: 2.5906308274151795
Validation loss: 2.829936931282302

Epoch: 106| Step: 0
Training loss: 3.862278143674591
Validation loss: 2.828403734508127

Epoch: 5| Step: 1
Training loss: 3.2941735938073595
Validation loss: 2.8320801881402713

Epoch: 5| Step: 2
Training loss: 3.2953075280475326
Validation loss: 2.8270828211401806

Epoch: 5| Step: 3
Training loss: 3.343270383288484
Validation loss: 2.8279684165402585

Epoch: 5| Step: 4
Training loss: 3.0959760575662463
Validation loss: 2.825178159474922

Epoch: 5| Step: 5
Training loss: 2.420469897812117
Validation loss: 2.8309718508728015

Epoch: 5| Step: 6
Training loss: 2.853983815222804
Validation loss: 2.8267716159925755

Epoch: 5| Step: 7
Training loss: 3.0214034145484154
Validation loss: 2.8235570103145835

Epoch: 5| Step: 8
Training loss: 3.0467566833998734
Validation loss: 2.823730954017917

Epoch: 5| Step: 9
Training loss: 2.9102607861887444
Validation loss: 2.8242766192933635

Epoch: 5| Step: 10
Training loss: 3.104759125634459
Validation loss: 2.8228582621286034

Epoch: 107| Step: 0
Training loss: 3.3162838898676634
Validation loss: 2.8223934232788634

Epoch: 5| Step: 1
Training loss: 3.0184417377666897
Validation loss: 2.8233135664686513

Epoch: 5| Step: 2
Training loss: 2.808390688286913
Validation loss: 2.8258503979083467

Epoch: 5| Step: 3
Training loss: 3.131700275505398
Validation loss: 2.8235328878707646

Epoch: 5| Step: 4
Training loss: 3.5527860481484748
Validation loss: 2.825766198464409

Epoch: 5| Step: 5
Training loss: 3.2197027185290144
Validation loss: 2.8222784973775235

Epoch: 5| Step: 6
Training loss: 3.0581682671706587
Validation loss: 2.8230615563601305

Epoch: 5| Step: 7
Training loss: 2.9959622867792763
Validation loss: 2.8290131662660247

Epoch: 5| Step: 8
Training loss: 2.917951428056852
Validation loss: 2.8275623785089326

Epoch: 5| Step: 9
Training loss: 3.150354904284471
Validation loss: 2.8234341914437575

Epoch: 5| Step: 10
Training loss: 3.231385697073996
Validation loss: 2.826933143762515

Epoch: 108| Step: 0
Training loss: 3.7411748674765373
Validation loss: 2.8341720710109946

Epoch: 5| Step: 1
Training loss: 3.411212770588071
Validation loss: 2.8337369959421888

Epoch: 5| Step: 2
Training loss: 2.9914119502222722
Validation loss: 2.8285382071554226

Epoch: 5| Step: 3
Training loss: 3.1067817647293454
Validation loss: 2.8191357247306206

Epoch: 5| Step: 4
Training loss: 3.058512992328652
Validation loss: 2.819867553463189

Epoch: 5| Step: 5
Training loss: 3.2373136724517093
Validation loss: 2.820217350598441

Epoch: 5| Step: 6
Training loss: 3.1965001517620553
Validation loss: 2.8201549391595964

Epoch: 5| Step: 7
Training loss: 3.1708027948888127
Validation loss: 2.8221812023308983

Epoch: 5| Step: 8
Training loss: 2.2099680578072434
Validation loss: 2.824309752542753

Epoch: 5| Step: 9
Training loss: 2.9153136975423632
Validation loss: 2.8241988224354566

Epoch: 5| Step: 10
Training loss: 3.1386506056762227
Validation loss: 2.8182806852635314

Epoch: 109| Step: 0
Training loss: 3.069457267477447
Validation loss: 2.8264295161490702

Epoch: 5| Step: 1
Training loss: 3.2523299448534475
Validation loss: 2.826246142512679

Epoch: 5| Step: 2
Training loss: 3.3123576295595067
Validation loss: 2.833731875417903

Epoch: 5| Step: 3
Training loss: 3.05263690463396
Validation loss: 2.851032857329669

Epoch: 5| Step: 4
Training loss: 2.990762794692386
Validation loss: 2.861408669934268

Epoch: 5| Step: 5
Training loss: 2.9787536726083337
Validation loss: 2.8714093849948688

Epoch: 5| Step: 6
Training loss: 2.980406834270468
Validation loss: 2.871485449243833

Epoch: 5| Step: 7
Training loss: 3.467781275292114
Validation loss: 2.8667344912937773

Epoch: 5| Step: 8
Training loss: 2.8812622202450653
Validation loss: 2.8511097358515487

Epoch: 5| Step: 9
Training loss: 3.422534060479399
Validation loss: 2.8241295927311283

Epoch: 5| Step: 10
Training loss: 2.9190500239979684
Validation loss: 2.813083352101103

Epoch: 110| Step: 0
Training loss: 2.7585362681469108
Validation loss: 2.8110261763097166

Epoch: 5| Step: 1
Training loss: 2.956129695065467
Validation loss: 2.8133769966170865

Epoch: 5| Step: 2
Training loss: 3.3008514577407655
Validation loss: 2.813667954520411

Epoch: 5| Step: 3
Training loss: 2.8630664115129076
Validation loss: 2.8156635007684008

Epoch: 5| Step: 4
Training loss: 3.265792915371222
Validation loss: 2.8179495060772344

Epoch: 5| Step: 5
Training loss: 2.963829701420687
Validation loss: 2.815697524758862

Epoch: 5| Step: 6
Training loss: 3.077564788805733
Validation loss: 2.816346766195982

Epoch: 5| Step: 7
Training loss: 3.3803486297755865
Validation loss: 2.8167456026102986

Epoch: 5| Step: 8
Training loss: 3.511670274580261
Validation loss: 2.8148277321307833

Epoch: 5| Step: 9
Training loss: 3.27678267321774
Validation loss: 2.8148132910373818

Epoch: 5| Step: 10
Training loss: 3.0047407838854796
Validation loss: 2.8125016580483346

Epoch: 111| Step: 0
Training loss: 2.9544660157414886
Validation loss: 2.813029118469971

Epoch: 5| Step: 1
Training loss: 2.347486137536082
Validation loss: 2.8133009085832485

Epoch: 5| Step: 2
Training loss: 3.480902476745406
Validation loss: 2.811953036812208

Epoch: 5| Step: 3
Training loss: 3.2301259902616595
Validation loss: 2.809745845623355

Epoch: 5| Step: 4
Training loss: 2.5308018982406404
Validation loss: 2.810361492619688

Epoch: 5| Step: 5
Training loss: 3.3613051436423853
Validation loss: 2.8074655482220723

Epoch: 5| Step: 6
Training loss: 3.0024832938028863
Validation loss: 2.808407007266561

Epoch: 5| Step: 7
Training loss: 3.37486733069863
Validation loss: 2.808625350419074

Epoch: 5| Step: 8
Training loss: 3.085586102916388
Validation loss: 2.807273531518873

Epoch: 5| Step: 9
Training loss: 3.301330881799867
Validation loss: 2.8092342489964883

Epoch: 5| Step: 10
Training loss: 3.55154984719892
Validation loss: 2.814358704812668

Epoch: 112| Step: 0
Training loss: 3.869859053930781
Validation loss: 2.82794038918683

Epoch: 5| Step: 1
Training loss: 3.110744155707844
Validation loss: 2.8261370654569324

Epoch: 5| Step: 2
Training loss: 3.526245892619351
Validation loss: 2.816917232104369

Epoch: 5| Step: 3
Training loss: 2.694082493629865
Validation loss: 2.811419823975244

Epoch: 5| Step: 4
Training loss: 2.7575309977168234
Validation loss: 2.809581428152918

Epoch: 5| Step: 5
Training loss: 2.6433887352094336
Validation loss: 2.8101305279066318

Epoch: 5| Step: 6
Training loss: 2.8981306628249444
Validation loss: 2.8074063571349757

Epoch: 5| Step: 7
Training loss: 3.087982967764573
Validation loss: 2.805593652655064

Epoch: 5| Step: 8
Training loss: 3.406098388657517
Validation loss: 2.8063309065921804

Epoch: 5| Step: 9
Training loss: 2.775087107760396
Validation loss: 2.8062382951027303

Epoch: 5| Step: 10
Training loss: 3.3252605594277775
Validation loss: 2.8046832468955376

Epoch: 113| Step: 0
Training loss: 3.6126839138852858
Validation loss: 2.8081261719418307

Epoch: 5| Step: 1
Training loss: 3.0783880285978014
Validation loss: 2.804556911304306

Epoch: 5| Step: 2
Training loss: 3.376828722540501
Validation loss: 2.804793738683538

Epoch: 5| Step: 3
Training loss: 3.216069114274525
Validation loss: 2.804281547619035

Epoch: 5| Step: 4
Training loss: 3.1094587305191492
Validation loss: 2.803029655173674

Epoch: 5| Step: 5
Training loss: 2.95181019088544
Validation loss: 2.805237270738599

Epoch: 5| Step: 6
Training loss: 2.5372412150297907
Validation loss: 2.810930634133912

Epoch: 5| Step: 7
Training loss: 2.755513992132837
Validation loss: 2.815384397296485

Epoch: 5| Step: 8
Training loss: 3.0624965745556416
Validation loss: 2.818219013249529

Epoch: 5| Step: 9
Training loss: 3.170072146536354
Validation loss: 2.8148297449160466

Epoch: 5| Step: 10
Training loss: 3.3035462485278013
Validation loss: 2.812362299274771

Epoch: 114| Step: 0
Training loss: 3.1065371037208673
Validation loss: 2.8074313641974364

Epoch: 5| Step: 1
Training loss: 2.9074246893565077
Validation loss: 2.806314491495444

Epoch: 5| Step: 2
Training loss: 2.996325149453096
Validation loss: 2.803270494624618

Epoch: 5| Step: 3
Training loss: 3.1714904251351026
Validation loss: 2.804907276085586

Epoch: 5| Step: 4
Training loss: 2.9870526349922035
Validation loss: 2.79864190224627

Epoch: 5| Step: 5
Training loss: 2.7421087270002475
Validation loss: 2.802339004128404

Epoch: 5| Step: 6
Training loss: 3.3330156810722382
Validation loss: 2.801302842818716

Epoch: 5| Step: 7
Training loss: 3.236991818874652
Validation loss: 2.800974173067067

Epoch: 5| Step: 8
Training loss: 3.5713587590614995
Validation loss: 2.801533656824589

Epoch: 5| Step: 9
Training loss: 3.0746170425755617
Validation loss: 2.8033726882918053

Epoch: 5| Step: 10
Training loss: 2.991284266465689
Validation loss: 2.8048580749763015

Epoch: 115| Step: 0
Training loss: 2.423354945692038
Validation loss: 2.8047239294538966

Epoch: 5| Step: 1
Training loss: 3.063661004917443
Validation loss: 2.804548914761194

Epoch: 5| Step: 2
Training loss: 3.001267483305621
Validation loss: 2.808453567458866

Epoch: 5| Step: 3
Training loss: 3.2525178985924215
Validation loss: 2.808658541429613

Epoch: 5| Step: 4
Training loss: 3.726753917712249
Validation loss: 2.7954742210789636

Epoch: 5| Step: 5
Training loss: 3.115823777265672
Validation loss: 2.792613242910089

Epoch: 5| Step: 6
Training loss: 2.63397716264955
Validation loss: 2.7944742122303534

Epoch: 5| Step: 7
Training loss: 2.9071703038203727
Validation loss: 2.7954802021916536

Epoch: 5| Step: 8
Training loss: 2.1274514363323633
Validation loss: 2.7947068010738563

Epoch: 5| Step: 9
Training loss: 3.49151755100271
Validation loss: 2.7952866963429472

Epoch: 5| Step: 10
Training loss: 4.099502598433794
Validation loss: 2.7954915242690435

Epoch: 116| Step: 0
Training loss: 3.0966134739452134
Validation loss: 2.7950244977395027

Epoch: 5| Step: 1
Training loss: 3.222432224694419
Validation loss: 2.7929188933921885

Epoch: 5| Step: 2
Training loss: 3.2052331453407894
Validation loss: 2.7938280216420366

Epoch: 5| Step: 3
Training loss: 2.858025904843045
Validation loss: 2.7903603344289105

Epoch: 5| Step: 4
Training loss: 3.688335130165054
Validation loss: 2.7918173544677014

Epoch: 5| Step: 5
Training loss: 2.8057209969097068
Validation loss: 2.7914703556022187

Epoch: 5| Step: 6
Training loss: 2.7705787216648248
Validation loss: 2.790624348337977

Epoch: 5| Step: 7
Training loss: 2.798252384574322
Validation loss: 2.79203946675203

Epoch: 5| Step: 8
Training loss: 3.631418136932416
Validation loss: 2.790213306835438

Epoch: 5| Step: 9
Training loss: 2.7629169201283883
Validation loss: 2.7893659146804644

Epoch: 5| Step: 10
Training loss: 3.1761163626236653
Validation loss: 2.786895346602717

Epoch: 117| Step: 0
Training loss: 2.810061096667543
Validation loss: 2.7905482967839883

Epoch: 5| Step: 1
Training loss: 3.610474786365832
Validation loss: 2.7895395687778546

Epoch: 5| Step: 2
Training loss: 2.8194230386289947
Validation loss: 2.7895340996887805

Epoch: 5| Step: 3
Training loss: 3.228222731581529
Validation loss: 2.78955657977279

Epoch: 5| Step: 4
Training loss: 3.449419061151607
Validation loss: 2.78775277411896

Epoch: 5| Step: 5
Training loss: 3.5621956143093114
Validation loss: 2.787002317782962

Epoch: 5| Step: 6
Training loss: 2.880804091100905
Validation loss: 2.7866144620534437

Epoch: 5| Step: 7
Training loss: 3.0037652864356916
Validation loss: 2.789544298047041

Epoch: 5| Step: 8
Training loss: 2.470397689093611
Validation loss: 2.785736768601682

Epoch: 5| Step: 9
Training loss: 2.8446422476669917
Validation loss: 2.7889724348773104

Epoch: 5| Step: 10
Training loss: 3.2331335661483545
Validation loss: 2.7908581361949705

Epoch: 118| Step: 0
Training loss: 3.1640429084077093
Validation loss: 2.792807504038202

Epoch: 5| Step: 1
Training loss: 3.143012813948588
Validation loss: 2.8063975480303016

Epoch: 5| Step: 2
Training loss: 3.2472838275664944
Validation loss: 2.809313885664886

Epoch: 5| Step: 3
Training loss: 2.876552991628602
Validation loss: 2.805978662978611

Epoch: 5| Step: 4
Training loss: 3.2054378440161004
Validation loss: 2.804527317216504

Epoch: 5| Step: 5
Training loss: 3.19431668085949
Validation loss: 2.7955246905571247

Epoch: 5| Step: 6
Training loss: 2.6494244112346266
Validation loss: 2.7875391446000948

Epoch: 5| Step: 7
Training loss: 3.0094458962840873
Validation loss: 2.785069664133022

Epoch: 5| Step: 8
Training loss: 3.1205305562930783
Validation loss: 2.785014143508166

Epoch: 5| Step: 9
Training loss: 3.191848332054847
Validation loss: 2.7837242687757953

Epoch: 5| Step: 10
Training loss: 3.220697350898781
Validation loss: 2.7858202637946796

Epoch: 119| Step: 0
Training loss: 2.9679201271229396
Validation loss: 2.7851384343305203

Epoch: 5| Step: 1
Training loss: 3.133722720063579
Validation loss: 2.7813951768508747

Epoch: 5| Step: 2
Training loss: 3.3144944142887125
Validation loss: 2.7834883473246

Epoch: 5| Step: 3
Training loss: 3.149490975320534
Validation loss: 2.781259763248162

Epoch: 5| Step: 4
Training loss: 2.989555456228685
Validation loss: 2.7866755703986335

Epoch: 5| Step: 5
Training loss: 2.9858845193535264
Validation loss: 2.7877082720781043

Epoch: 5| Step: 6
Training loss: 3.410659875200363
Validation loss: 2.787635256734442

Epoch: 5| Step: 7
Training loss: 2.988208006914902
Validation loss: 2.7881889810261162

Epoch: 5| Step: 8
Training loss: 2.560998802545246
Validation loss: 2.7920938849687786

Epoch: 5| Step: 9
Training loss: 3.4637079108168285
Validation loss: 2.789490242739157

Epoch: 5| Step: 10
Training loss: 2.9617285967527063
Validation loss: 2.7858783123229975

Epoch: 120| Step: 0
Training loss: 3.371728229598652
Validation loss: 2.7849223470971785

Epoch: 5| Step: 1
Training loss: 2.6965117067280615
Validation loss: 2.7812867465788473

Epoch: 5| Step: 2
Training loss: 2.9684849670965034
Validation loss: 2.77762303574218

Epoch: 5| Step: 3
Training loss: 3.398229833813182
Validation loss: 2.7810038639377797

Epoch: 5| Step: 4
Training loss: 2.6052974433001705
Validation loss: 2.7811934449364752

Epoch: 5| Step: 5
Training loss: 3.58646217779566
Validation loss: 2.78053514714874

Epoch: 5| Step: 6
Training loss: 3.1655901199934733
Validation loss: 2.7780387519627667

Epoch: 5| Step: 7
Training loss: 2.9114310730196475
Validation loss: 2.7817428703366516

Epoch: 5| Step: 8
Training loss: 3.0462710050876938
Validation loss: 2.7776439739802004

Epoch: 5| Step: 9
Training loss: 2.709000040791491
Validation loss: 2.7797349354515557

Epoch: 5| Step: 10
Training loss: 3.4273502667175766
Validation loss: 2.7744160325303455

Epoch: 121| Step: 0
Training loss: 3.4779280477389154
Validation loss: 2.7772481881789393

Epoch: 5| Step: 1
Training loss: 2.7102845034873644
Validation loss: 2.777561173522271

Epoch: 5| Step: 2
Training loss: 3.3794100170885795
Validation loss: 2.7814672407603083

Epoch: 5| Step: 3
Training loss: 3.2538924749295757
Validation loss: 2.7789138258909634

Epoch: 5| Step: 4
Training loss: 2.491780693311426
Validation loss: 2.7837645816738332

Epoch: 5| Step: 5
Training loss: 3.345707970753204
Validation loss: 2.777608008956489

Epoch: 5| Step: 6
Training loss: 3.2667840242389685
Validation loss: 2.7750175822139913

Epoch: 5| Step: 7
Training loss: 3.213237449223187
Validation loss: 2.774638770923504

Epoch: 5| Step: 8
Training loss: 2.5258372325693017
Validation loss: 2.7774977122056006

Epoch: 5| Step: 9
Training loss: 2.8057611052330653
Validation loss: 2.7726044053688628

Epoch: 5| Step: 10
Training loss: 3.3130910094265693
Validation loss: 2.772801582748545

Epoch: 122| Step: 0
Training loss: 2.7221310518096513
Validation loss: 2.773009559052509

Epoch: 5| Step: 1
Training loss: 2.8294799256719023
Validation loss: 2.7739844220130347

Epoch: 5| Step: 2
Training loss: 3.208531130023379
Validation loss: 2.774189909743975

Epoch: 5| Step: 3
Training loss: 3.856461633844292
Validation loss: 2.7749819887170397

Epoch: 5| Step: 4
Training loss: 3.0325632298506147
Validation loss: 2.7742095321038374

Epoch: 5| Step: 5
Training loss: 2.8084549531344454
Validation loss: 2.775137256086941

Epoch: 5| Step: 6
Training loss: 2.943245321695363
Validation loss: 2.7747269323599197

Epoch: 5| Step: 7
Training loss: 3.0130374856333173
Validation loss: 2.777439666666057

Epoch: 5| Step: 8
Training loss: 3.0278352990553445
Validation loss: 2.774148967003858

Epoch: 5| Step: 9
Training loss: 3.4146491971664488
Validation loss: 2.779668479308876

Epoch: 5| Step: 10
Training loss: 2.8986066167390696
Validation loss: 2.779164030575605

Epoch: 123| Step: 0
Training loss: 3.370111527903825
Validation loss: 2.785875618817063

Epoch: 5| Step: 1
Training loss: 2.792484097345846
Validation loss: 2.7924354026196467

Epoch: 5| Step: 2
Training loss: 3.3722572484746975
Validation loss: 2.7957585142859016

Epoch: 5| Step: 3
Training loss: 2.271464852063028
Validation loss: 2.793337949053495

Epoch: 5| Step: 4
Training loss: 3.1961179431642086
Validation loss: 2.7899189306818704

Epoch: 5| Step: 5
Training loss: 2.9365385389431284
Validation loss: 2.7825125639552697

Epoch: 5| Step: 6
Training loss: 3.055825570246359
Validation loss: 2.780298560437993

Epoch: 5| Step: 7
Training loss: 3.5299561417316263
Validation loss: 2.775519515724299

Epoch: 5| Step: 8
Training loss: 3.0213652219253886
Validation loss: 2.765277161903757

Epoch: 5| Step: 9
Training loss: 3.263970060669338
Validation loss: 2.7693446642490085

Epoch: 5| Step: 10
Training loss: 2.930302832515196
Validation loss: 2.770611814208059

Epoch: 124| Step: 0
Training loss: 2.6439514876977825
Validation loss: 2.7694845945583344

Epoch: 5| Step: 1
Training loss: 2.735683455074733
Validation loss: 2.767970444021955

Epoch: 5| Step: 2
Training loss: 3.4687585229167532
Validation loss: 2.7684211201744024

Epoch: 5| Step: 3
Training loss: 3.0811133425973867
Validation loss: 2.767941048744738

Epoch: 5| Step: 4
Training loss: 2.6655213956387427
Validation loss: 2.7680646164673854

Epoch: 5| Step: 5
Training loss: 2.9876784969618964
Validation loss: 2.7657513629866344

Epoch: 5| Step: 6
Training loss: 3.4214683534952837
Validation loss: 2.764944126324382

Epoch: 5| Step: 7
Training loss: 3.399031523605204
Validation loss: 2.768989802453809

Epoch: 5| Step: 8
Training loss: 3.4336349953527434
Validation loss: 2.7676167667587244

Epoch: 5| Step: 9
Training loss: 2.7685502094320045
Validation loss: 2.7651734138401847

Epoch: 5| Step: 10
Training loss: 3.1191141775941214
Validation loss: 2.7772425333445643

Epoch: 125| Step: 0
Training loss: 3.1182015282649744
Validation loss: 2.7744246056573707

Epoch: 5| Step: 1
Training loss: 3.1055547354448207
Validation loss: 2.770838730466257

Epoch: 5| Step: 2
Training loss: 3.3974154634604026
Validation loss: 2.7769519751178278

Epoch: 5| Step: 3
Training loss: 3.292040421396493
Validation loss: 2.7689843168482655

Epoch: 5| Step: 4
Training loss: 3.050471135006495
Validation loss: 2.767065604731508

Epoch: 5| Step: 5
Training loss: 3.2379463860147615
Validation loss: 2.763702170014896

Epoch: 5| Step: 6
Training loss: 3.0237374563536523
Validation loss: 2.7668178204480176

Epoch: 5| Step: 7
Training loss: 2.7249007530687623
Validation loss: 2.761670827272133

Epoch: 5| Step: 8
Training loss: 2.97054790465005
Validation loss: 2.768692490112301

Epoch: 5| Step: 9
Training loss: 2.9904094622360757
Validation loss: 2.7733976470750696

Epoch: 5| Step: 10
Training loss: 2.8559548189986517
Validation loss: 2.778042041828125

Epoch: 126| Step: 0
Training loss: 3.264798730602359
Validation loss: 2.77845191842108

Epoch: 5| Step: 1
Training loss: 3.2468346072815315
Validation loss: 2.7782748648875

Epoch: 5| Step: 2
Training loss: 3.871448735379166
Validation loss: 2.774987693426013

Epoch: 5| Step: 3
Training loss: 2.0737616831040513
Validation loss: 2.7637467348726346

Epoch: 5| Step: 4
Training loss: 3.5085447095197075
Validation loss: 2.7606625101331512

Epoch: 5| Step: 5
Training loss: 3.063076976998228
Validation loss: 2.7627606569750656

Epoch: 5| Step: 6
Training loss: 2.8855281950584954
Validation loss: 2.769388736551531

Epoch: 5| Step: 7
Training loss: 2.967214247355501
Validation loss: 2.781404255682699

Epoch: 5| Step: 8
Training loss: 2.8700349477308267
Validation loss: 2.7881118635571225

Epoch: 5| Step: 9
Training loss: 2.751358823586838
Validation loss: 2.791869300488212

Epoch: 5| Step: 10
Training loss: 3.2985763137498934
Validation loss: 2.8023219792441627

Epoch: 127| Step: 0
Training loss: 2.523222734033929
Validation loss: 2.772599481695482

Epoch: 5| Step: 1
Training loss: 3.521066074842357
Validation loss: 2.7662350182468867

Epoch: 5| Step: 2
Training loss: 2.5486010921695956
Validation loss: 2.762411524593291

Epoch: 5| Step: 3
Training loss: 3.5602541084895334
Validation loss: 2.760821492992974

Epoch: 5| Step: 4
Training loss: 2.767812951785539
Validation loss: 2.760584300533731

Epoch: 5| Step: 5
Training loss: 3.0523541604834303
Validation loss: 2.7609316583264474

Epoch: 5| Step: 6
Training loss: 3.2755670653505744
Validation loss: 2.7603216484992052

Epoch: 5| Step: 7
Training loss: 3.4344578546416984
Validation loss: 2.7585356278259465

Epoch: 5| Step: 8
Training loss: 3.2072474305754173
Validation loss: 2.7593536416633793

Epoch: 5| Step: 9
Training loss: 2.8814510449088915
Validation loss: 2.7609129119310603

Epoch: 5| Step: 10
Training loss: 2.9567293645439126
Validation loss: 2.7627787663420644

Epoch: 128| Step: 0
Training loss: 3.0725651599253845
Validation loss: 2.7612323195972768

Epoch: 5| Step: 1
Training loss: 2.9453656017262153
Validation loss: 2.762284726684579

Epoch: 5| Step: 2
Training loss: 2.778671097692714
Validation loss: 2.760259426388146

Epoch: 5| Step: 3
Training loss: 3.375517628852694
Validation loss: 2.7528348492275176

Epoch: 5| Step: 4
Training loss: 3.229759867336762
Validation loss: 2.7573892781716323

Epoch: 5| Step: 5
Training loss: 2.9836977844399843
Validation loss: 2.757297913483405

Epoch: 5| Step: 6
Training loss: 2.539453282728133
Validation loss: 2.7568914309287975

Epoch: 5| Step: 7
Training loss: 2.8753836002686404
Validation loss: 2.759200657211097

Epoch: 5| Step: 8
Training loss: 3.4546811839183555
Validation loss: 2.757708824365839

Epoch: 5| Step: 9
Training loss: 2.841142905583725
Validation loss: 2.7587853649599947

Epoch: 5| Step: 10
Training loss: 3.658684466172268
Validation loss: 2.7585945906335367

Epoch: 129| Step: 0
Training loss: 3.657073881784596
Validation loss: 2.757599861559818

Epoch: 5| Step: 1
Training loss: 2.3734948257444533
Validation loss: 2.7590150314250033

Epoch: 5| Step: 2
Training loss: 3.130580497024801
Validation loss: 2.759835584933639

Epoch: 5| Step: 3
Training loss: 2.8247125597531246
Validation loss: 2.761431282854712

Epoch: 5| Step: 4
Training loss: 3.6522917881497547
Validation loss: 2.7587604968071004

Epoch: 5| Step: 5
Training loss: 3.0017556775197365
Validation loss: 2.7596445394882094

Epoch: 5| Step: 6
Training loss: 3.044869883095248
Validation loss: 2.7607309578497277

Epoch: 5| Step: 7
Training loss: 3.0720990833654986
Validation loss: 2.76296146842414

Epoch: 5| Step: 8
Training loss: 2.8081011811092504
Validation loss: 2.755528466752223

Epoch: 5| Step: 9
Training loss: 2.981266979752976
Validation loss: 2.756815602834537

Epoch: 5| Step: 10
Training loss: 3.1523594814508336
Validation loss: 2.754318940172892

Epoch: 130| Step: 0
Training loss: 2.812598756539814
Validation loss: 2.7573902125548995

Epoch: 5| Step: 1
Training loss: 2.8379509454080565
Validation loss: 2.7565589706868687

Epoch: 5| Step: 2
Training loss: 2.964174619815407
Validation loss: 2.7547389167785212

Epoch: 5| Step: 3
Training loss: 3.230153743049292
Validation loss: 2.756478448829558

Epoch: 5| Step: 4
Training loss: 3.6632874407220695
Validation loss: 2.7565716718697097

Epoch: 5| Step: 5
Training loss: 2.456191848959536
Validation loss: 2.756775672357375

Epoch: 5| Step: 6
Training loss: 3.6514717897142654
Validation loss: 2.753876354573372

Epoch: 5| Step: 7
Training loss: 2.3937897522018474
Validation loss: 2.75714061497843

Epoch: 5| Step: 8
Training loss: 2.9170667283119043
Validation loss: 2.755226834130368

Epoch: 5| Step: 9
Training loss: 3.582898815926972
Validation loss: 2.7542969673704683

Epoch: 5| Step: 10
Training loss: 2.9577086062152547
Validation loss: 2.7598433775539846

Epoch: 131| Step: 0
Training loss: 3.4866952056397547
Validation loss: 2.761588400091522

Epoch: 5| Step: 1
Training loss: 3.01473922765781
Validation loss: 2.7634413979012176

Epoch: 5| Step: 2
Training loss: 3.0661894703429518
Validation loss: 2.7694983370844786

Epoch: 5| Step: 3
Training loss: 2.8344726141930443
Validation loss: 2.7596590621153188

Epoch: 5| Step: 4
Training loss: 2.5457836223271184
Validation loss: 2.7495799923171917

Epoch: 5| Step: 5
Training loss: 3.37419203517802
Validation loss: 2.749967895573981

Epoch: 5| Step: 6
Training loss: 3.2383185040547837
Validation loss: 2.7470440606944577

Epoch: 5| Step: 7
Training loss: 2.754047016847806
Validation loss: 2.7459659969426746

Epoch: 5| Step: 8
Training loss: 3.2675962202502546
Validation loss: 2.745095310078842

Epoch: 5| Step: 9
Training loss: 2.941026883528723
Validation loss: 2.745051025184462

Epoch: 5| Step: 10
Training loss: 3.098806391391783
Validation loss: 2.74621214140493

Epoch: 132| Step: 0
Training loss: 3.500652388670042
Validation loss: 2.7507309413003473

Epoch: 5| Step: 1
Training loss: 2.9427018877257027
Validation loss: 2.747280508277495

Epoch: 5| Step: 2
Training loss: 2.7835469565579083
Validation loss: 2.7588255395491466

Epoch: 5| Step: 3
Training loss: 3.292937182436918
Validation loss: 2.7674869429093762

Epoch: 5| Step: 4
Training loss: 2.596051401578688
Validation loss: 2.7718369335446273

Epoch: 5| Step: 5
Training loss: 3.4421442736501557
Validation loss: 2.7577526317615644

Epoch: 5| Step: 6
Training loss: 3.2754479837143733
Validation loss: 2.7427362052500457

Epoch: 5| Step: 7
Training loss: 3.088877839206658
Validation loss: 2.743651727987084

Epoch: 5| Step: 8
Training loss: 2.6514612451663595
Validation loss: 2.7447774150059887

Epoch: 5| Step: 9
Training loss: 2.9590449663763323
Validation loss: 2.742502853546571

Epoch: 5| Step: 10
Training loss: 2.932063164398819
Validation loss: 2.7414797183335664

Epoch: 133| Step: 0
Training loss: 2.9139009896281576
Validation loss: 2.7396202657296858

Epoch: 5| Step: 1
Training loss: 3.256990836833635
Validation loss: 2.7386795172574323

Epoch: 5| Step: 2
Training loss: 2.936434938234521
Validation loss: 2.7390785792566232

Epoch: 5| Step: 3
Training loss: 2.246604370457152
Validation loss: 2.741002491047586

Epoch: 5| Step: 4
Training loss: 2.560279442317558
Validation loss: 2.740496566782075

Epoch: 5| Step: 5
Training loss: 3.1268735228585918
Validation loss: 2.7464044983505973

Epoch: 5| Step: 6
Training loss: 3.411628186993932
Validation loss: 2.7446702113535966

Epoch: 5| Step: 7
Training loss: 2.875755874119738
Validation loss: 2.744675743686085

Epoch: 5| Step: 8
Training loss: 3.8031150498021025
Validation loss: 2.7477696436472505

Epoch: 5| Step: 9
Training loss: 3.401150867681621
Validation loss: 2.7468684909792946

Epoch: 5| Step: 10
Training loss: 2.8046133727582303
Validation loss: 2.753258296271604

Epoch: 134| Step: 0
Training loss: 3.2292727709330094
Validation loss: 2.750896342271956

Epoch: 5| Step: 1
Training loss: 2.899406003956888
Validation loss: 2.7386659870312613

Epoch: 5| Step: 2
Training loss: 2.549325150593723
Validation loss: 2.739389857608065

Epoch: 5| Step: 3
Training loss: 3.0125625160663483
Validation loss: 2.736888114784005

Epoch: 5| Step: 4
Training loss: 2.717788877179464
Validation loss: 2.7408431938500177

Epoch: 5| Step: 5
Training loss: 2.8298942974825607
Validation loss: 2.7384974845279393

Epoch: 5| Step: 6
Training loss: 3.2481528681781144
Validation loss: 2.7406432831715706

Epoch: 5| Step: 7
Training loss: 3.239807873433654
Validation loss: 2.741143168609434

Epoch: 5| Step: 8
Training loss: 3.5692537770554247
Validation loss: 2.7409638697187435

Epoch: 5| Step: 9
Training loss: 3.0814308964552337
Validation loss: 2.7405375651321773

Epoch: 5| Step: 10
Training loss: 3.264557440354216
Validation loss: 2.7418941647904713

Epoch: 135| Step: 0
Training loss: 2.7270321154659984
Validation loss: 2.7393915018848856

Epoch: 5| Step: 1
Training loss: 3.0778941731147214
Validation loss: 2.742585859008499

Epoch: 5| Step: 2
Training loss: 2.778605886575604
Validation loss: 2.755868478420171

Epoch: 5| Step: 3
Training loss: 3.4343160969591904
Validation loss: 2.7573473393775227

Epoch: 5| Step: 4
Training loss: 3.103988659425056
Validation loss: 2.760764768309852

Epoch: 5| Step: 5
Training loss: 2.83704600462323
Validation loss: 2.757079978980913

Epoch: 5| Step: 6
Training loss: 3.1636377873711488
Validation loss: 2.74807188021792

Epoch: 5| Step: 7
Training loss: 3.2461356149996625
Validation loss: 2.749006882571812

Epoch: 5| Step: 8
Training loss: 2.754979134288496
Validation loss: 2.7397199921289346

Epoch: 5| Step: 9
Training loss: 3.1667856060244945
Validation loss: 2.7457162543940394

Epoch: 5| Step: 10
Training loss: 3.306271004565028
Validation loss: 2.764461644597409

Epoch: 136| Step: 0
Training loss: 2.983539084757543
Validation loss: 2.756382241749604

Epoch: 5| Step: 1
Training loss: 2.993528379388297
Validation loss: 2.737525129050721

Epoch: 5| Step: 2
Training loss: 2.725497324646732
Validation loss: 2.734264165035418

Epoch: 5| Step: 3
Training loss: 3.0071556265786077
Validation loss: 2.7319662756059517

Epoch: 5| Step: 4
Training loss: 2.959932584510362
Validation loss: 2.73125696216797

Epoch: 5| Step: 5
Training loss: 2.8620078050998807
Validation loss: 2.7319856532212063

Epoch: 5| Step: 6
Training loss: 3.1064824591067293
Validation loss: 2.7307446040429353

Epoch: 5| Step: 7
Training loss: 2.98238574132908
Validation loss: 2.7310913480265353

Epoch: 5| Step: 8
Training loss: 3.2876433076554368
Validation loss: 2.7331259147805516

Epoch: 5| Step: 9
Training loss: 3.311334656914491
Validation loss: 2.733900487836414

Epoch: 5| Step: 10
Training loss: 3.389009292909472
Validation loss: 2.733256121364499

Epoch: 137| Step: 0
Training loss: 2.8840570838770727
Validation loss: 2.7309638459767642

Epoch: 5| Step: 1
Training loss: 2.739087213381897
Validation loss: 2.7319064678176175

Epoch: 5| Step: 2
Training loss: 3.161207177598796
Validation loss: 2.730850253398982

Epoch: 5| Step: 3
Training loss: 2.429505859650562
Validation loss: 2.727609146912114

Epoch: 5| Step: 4
Training loss: 2.9997779446118975
Validation loss: 2.728666895878443

Epoch: 5| Step: 5
Training loss: 3.4560327499568655
Validation loss: 2.7278520796106456

Epoch: 5| Step: 6
Training loss: 3.340754227596532
Validation loss: 2.728175860690164

Epoch: 5| Step: 7
Training loss: 3.461649044422396
Validation loss: 2.7281410919242224

Epoch: 5| Step: 8
Training loss: 2.4684836328437902
Validation loss: 2.7289567509862516

Epoch: 5| Step: 9
Training loss: 3.171268649469315
Validation loss: 2.7267595243399136

Epoch: 5| Step: 10
Training loss: 3.2935072344325094
Validation loss: 2.730331958044331

Epoch: 138| Step: 0
Training loss: 2.646533382848817
Validation loss: 2.7364023163763522

Epoch: 5| Step: 1
Training loss: 3.1509519622056192
Validation loss: 2.7435972772732815

Epoch: 5| Step: 2
Training loss: 3.7993525204414715
Validation loss: 2.7548945024293103

Epoch: 5| Step: 3
Training loss: 2.6789044273105493
Validation loss: 2.742557750838725

Epoch: 5| Step: 4
Training loss: 2.940592659621413
Validation loss: 2.7355291834171314

Epoch: 5| Step: 5
Training loss: 2.958543599854288
Validation loss: 2.734836708383827

Epoch: 5| Step: 6
Training loss: 3.6097994468119157
Validation loss: 2.729200422285987

Epoch: 5| Step: 7
Training loss: 2.6755036815717075
Validation loss: 2.728824977030245

Epoch: 5| Step: 8
Training loss: 2.7441221189044582
Validation loss: 2.7275849710668556

Epoch: 5| Step: 9
Training loss: 3.147465482466467
Validation loss: 2.727143490643428

Epoch: 5| Step: 10
Training loss: 3.052590198980629
Validation loss: 2.7228538742888926

Epoch: 139| Step: 0
Training loss: 3.355465339419105
Validation loss: 2.7256000048276423

Epoch: 5| Step: 1
Training loss: 2.952597596237526
Validation loss: 2.720059264521842

Epoch: 5| Step: 2
Training loss: 2.7431587607582713
Validation loss: 2.722576712273706

Epoch: 5| Step: 3
Training loss: 2.9562668007500266
Validation loss: 2.7230814205759364

Epoch: 5| Step: 4
Training loss: 3.0095130769895797
Validation loss: 2.7210097463795275

Epoch: 5| Step: 5
Training loss: 2.868714136635
Validation loss: 2.726162486067997

Epoch: 5| Step: 6
Training loss: 3.1564599902105215
Validation loss: 2.7243448835420656

Epoch: 5| Step: 7
Training loss: 3.36219846373195
Validation loss: 2.725708307463026

Epoch: 5| Step: 8
Training loss: 2.587661951866246
Validation loss: 2.725913490063395

Epoch: 5| Step: 9
Training loss: 3.7140156076541904
Validation loss: 2.7232412060413274

Epoch: 5| Step: 10
Training loss: 2.5588560479517803
Validation loss: 2.7246347533877513

Epoch: 140| Step: 0
Training loss: 3.319178632222517
Validation loss: 2.723004324275409

Epoch: 5| Step: 1
Training loss: 2.476068200683502
Validation loss: 2.726334047218236

Epoch: 5| Step: 2
Training loss: 2.779476500421265
Validation loss: 2.721938895191418

Epoch: 5| Step: 3
Training loss: 3.206956311928975
Validation loss: 2.725791884543143

Epoch: 5| Step: 4
Training loss: 3.6272176338995537
Validation loss: 2.723597379560807

Epoch: 5| Step: 5
Training loss: 3.255066224111585
Validation loss: 2.7220063614354695

Epoch: 5| Step: 6
Training loss: 3.018274280034305
Validation loss: 2.720279079264778

Epoch: 5| Step: 7
Training loss: 2.6111896167163007
Validation loss: 2.7220888156052436

Epoch: 5| Step: 8
Training loss: 2.7742133116608376
Validation loss: 2.7214597221228205

Epoch: 5| Step: 9
Training loss: 3.0056183974331754
Validation loss: 2.722633418098699

Epoch: 5| Step: 10
Training loss: 3.2662237613177365
Validation loss: 2.719862725660733

Epoch: 141| Step: 0
Training loss: 2.62894860243443
Validation loss: 2.720543331814693

Epoch: 5| Step: 1
Training loss: 3.2529532879191163
Validation loss: 2.7181914239808593

Epoch: 5| Step: 2
Training loss: 2.876349920056644
Validation loss: 2.718088793097883

Epoch: 5| Step: 3
Training loss: 3.81699019369895
Validation loss: 2.7154138379192703

Epoch: 5| Step: 4
Training loss: 2.7016673485270477
Validation loss: 2.7201386392999285

Epoch: 5| Step: 5
Training loss: 2.8159438347525607
Validation loss: 2.7256031350709358

Epoch: 5| Step: 6
Training loss: 3.1898776891333718
Validation loss: 2.7300218968830015

Epoch: 5| Step: 7
Training loss: 3.297638863393664
Validation loss: 2.7418420012630063

Epoch: 5| Step: 8
Training loss: 3.1021921590072803
Validation loss: 2.7272411841258544

Epoch: 5| Step: 9
Training loss: 2.583737269989825
Validation loss: 2.713869658689777

Epoch: 5| Step: 10
Training loss: 3.0069705726089393
Validation loss: 2.7177346907627093

Epoch: 142| Step: 0
Training loss: 2.979319499614993
Validation loss: 2.71418393393593

Epoch: 5| Step: 1
Training loss: 2.799961624563726
Validation loss: 2.713518023360839

Epoch: 5| Step: 2
Training loss: 3.3848139456212607
Validation loss: 2.7162100931875455

Epoch: 5| Step: 3
Training loss: 3.1869875926125455
Validation loss: 2.7175788190827115

Epoch: 5| Step: 4
Training loss: 2.6591683008214253
Validation loss: 2.713382805970417

Epoch: 5| Step: 5
Training loss: 2.8354569125116256
Validation loss: 2.71486051702851

Epoch: 5| Step: 6
Training loss: 2.6623496537003457
Validation loss: 2.716992109901761

Epoch: 5| Step: 7
Training loss: 3.1536484373645233
Validation loss: 2.7133181827936803

Epoch: 5| Step: 8
Training loss: 3.0976407025441324
Validation loss: 2.713937721324331

Epoch: 5| Step: 9
Training loss: 3.4944045434670725
Validation loss: 2.7150402017784874

Epoch: 5| Step: 10
Training loss: 3.1357859819621634
Validation loss: 2.731446577686149

Epoch: 143| Step: 0
Training loss: 2.7430573303817822
Validation loss: 2.7379004945876853

Epoch: 5| Step: 1
Training loss: 3.1988958957400015
Validation loss: 2.739458703017791

Epoch: 5| Step: 2
Training loss: 3.207695802701824
Validation loss: 2.7183785444682846

Epoch: 5| Step: 3
Training loss: 3.1233697835233127
Validation loss: 2.710002672146969

Epoch: 5| Step: 4
Training loss: 3.373355747520355
Validation loss: 2.71458125828128

Epoch: 5| Step: 5
Training loss: 3.1629315651006826
Validation loss: 2.7143776784588693

Epoch: 5| Step: 6
Training loss: 2.783447511885597
Validation loss: 2.7169298569818263

Epoch: 5| Step: 7
Training loss: 2.8742671530096358
Validation loss: 2.718582131164725

Epoch: 5| Step: 8
Training loss: 3.4320099425094033
Validation loss: 2.7196470305290332

Epoch: 5| Step: 9
Training loss: 2.7333858771817527
Validation loss: 2.7205317185555855

Epoch: 5| Step: 10
Training loss: 2.8540264197278193
Validation loss: 2.718275846144299

Epoch: 144| Step: 0
Training loss: 3.197211188783305
Validation loss: 2.7192047544093727

Epoch: 5| Step: 1
Training loss: 2.9394670758597514
Validation loss: 2.7177291932015284

Epoch: 5| Step: 2
Training loss: 2.8190758019926268
Validation loss: 2.71532898688424

Epoch: 5| Step: 3
Training loss: 3.1466101556757486
Validation loss: 2.7133938054665876

Epoch: 5| Step: 4
Training loss: 3.0416325780621825
Validation loss: 2.7104039464013643

Epoch: 5| Step: 5
Training loss: 2.9904234942848644
Validation loss: 2.7093682033951607

Epoch: 5| Step: 6
Training loss: 3.326810048694944
Validation loss: 2.7070456713391

Epoch: 5| Step: 7
Training loss: 2.704523683872711
Validation loss: 2.706801212246574

Epoch: 5| Step: 8
Training loss: 3.240447163277495
Validation loss: 2.7154280684035914

Epoch: 5| Step: 9
Training loss: 3.141895397841724
Validation loss: 2.721883905570278

Epoch: 5| Step: 10
Training loss: 2.836269558889132
Validation loss: 2.729750041018761

Epoch: 145| Step: 0
Training loss: 2.87766474089007
Validation loss: 2.7280460882403643

Epoch: 5| Step: 1
Training loss: 3.4706274227200513
Validation loss: 2.7268210855919346

Epoch: 5| Step: 2
Training loss: 3.2806686612997624
Validation loss: 2.713314943894019

Epoch: 5| Step: 3
Training loss: 3.0253329385438037
Validation loss: 2.705681402841738

Epoch: 5| Step: 4
Training loss: 3.064646533043829
Validation loss: 2.708665453201926

Epoch: 5| Step: 5
Training loss: 2.9237687608786445
Validation loss: 2.707819331563196

Epoch: 5| Step: 6
Training loss: 2.741615257438234
Validation loss: 2.7077554674728694

Epoch: 5| Step: 7
Training loss: 2.517421862574384
Validation loss: 2.7079983739963294

Epoch: 5| Step: 8
Training loss: 3.13810241508752
Validation loss: 2.7091558392264767

Epoch: 5| Step: 9
Training loss: 3.2153555739575648
Validation loss: 2.7105369223451916

Epoch: 5| Step: 10
Training loss: 2.9754929911435246
Validation loss: 2.7091735432637414

Epoch: 146| Step: 0
Training loss: 3.06536264337125
Validation loss: 2.7135275683189213

Epoch: 5| Step: 1
Training loss: 2.7151270437286033
Validation loss: 2.71432283836246

Epoch: 5| Step: 2
Training loss: 3.285135493626833
Validation loss: 2.712990411678697

Epoch: 5| Step: 3
Training loss: 2.8046537519459407
Validation loss: 2.7108382221959357

Epoch: 5| Step: 4
Training loss: 2.805409118137566
Validation loss: 2.7115259451838227

Epoch: 5| Step: 5
Training loss: 2.9511812463658287
Validation loss: 2.7091575718785577

Epoch: 5| Step: 6
Training loss: 3.8690251463632177
Validation loss: 2.7081185453703065

Epoch: 5| Step: 7
Training loss: 2.841248638322255
Validation loss: 2.7049897568000594

Epoch: 5| Step: 8
Training loss: 2.8994571506565934
Validation loss: 2.7075604745662285

Epoch: 5| Step: 9
Training loss: 3.0555924345931302
Validation loss: 2.707981178226643

Epoch: 5| Step: 10
Training loss: 2.902601679845311
Validation loss: 2.7082140142946693

Epoch: 147| Step: 0
Training loss: 3.059519348791552
Validation loss: 2.712796441446541

Epoch: 5| Step: 1
Training loss: 2.7474821007851027
Validation loss: 2.7105330804806678

Epoch: 5| Step: 2
Training loss: 2.968320474170188
Validation loss: 2.7194405087733133

Epoch: 5| Step: 3
Training loss: 3.01054072316948
Validation loss: 2.7353926351523308

Epoch: 5| Step: 4
Training loss: 3.290032685416052
Validation loss: 2.7319598082376206

Epoch: 5| Step: 5
Training loss: 2.7392683440361276
Validation loss: 2.7447636738642727

Epoch: 5| Step: 6
Training loss: 3.216017961727106
Validation loss: 2.728621311803855

Epoch: 5| Step: 7
Training loss: 2.865244859547535
Validation loss: 2.7287279509257742

Epoch: 5| Step: 8
Training loss: 3.1278713005302285
Validation loss: 2.716565863604279

Epoch: 5| Step: 9
Training loss: 2.597808236860074
Validation loss: 2.7127414503096046

Epoch: 5| Step: 10
Training loss: 3.6880883216294658
Validation loss: 2.7043309359517633

Epoch: 148| Step: 0
Training loss: 2.26652456380416
Validation loss: 2.69846035170956

Epoch: 5| Step: 1
Training loss: 2.9970691987921523
Validation loss: 2.707376172450395

Epoch: 5| Step: 2
Training loss: 3.2045125793600584
Validation loss: 2.7024912046392373

Epoch: 5| Step: 3
Training loss: 2.935534367436345
Validation loss: 2.703260318902557

Epoch: 5| Step: 4
Training loss: 3.1760848347170034
Validation loss: 2.7036553058949067

Epoch: 5| Step: 5
Training loss: 3.006087008873734
Validation loss: 2.707281283811829

Epoch: 5| Step: 6
Training loss: 3.4020934335839397
Validation loss: 2.705193573066066

Epoch: 5| Step: 7
Training loss: 2.899789993311595
Validation loss: 2.706080677580606

Epoch: 5| Step: 8
Training loss: 2.6148013952339353
Validation loss: 2.702243189508685

Epoch: 5| Step: 9
Training loss: 3.5619750054332293
Validation loss: 2.7024332536932105

Epoch: 5| Step: 10
Training loss: 3.1515607085858814
Validation loss: 2.7022277805439843

Epoch: 149| Step: 0
Training loss: 3.025166019896596
Validation loss: 2.69769835142115

Epoch: 5| Step: 1
Training loss: 3.2800422989048448
Validation loss: 2.6979844488695215

Epoch: 5| Step: 2
Training loss: 2.6473740324575807
Validation loss: 2.695785797162075

Epoch: 5| Step: 3
Training loss: 2.6823939232948253
Validation loss: 2.698733200310266

Epoch: 5| Step: 4
Training loss: 2.792761991090432
Validation loss: 2.702403221430213

Epoch: 5| Step: 5
Training loss: 3.2936822699689494
Validation loss: 2.707663877555873

Epoch: 5| Step: 6
Training loss: 3.5964515151711085
Validation loss: 2.7132728803649107

Epoch: 5| Step: 7
Training loss: 3.343166977866127
Validation loss: 2.700038327636677

Epoch: 5| Step: 8
Training loss: 2.6682451364720756
Validation loss: 2.698968567682384

Epoch: 5| Step: 9
Training loss: 2.8606016102510328
Validation loss: 2.698130592274018

Epoch: 5| Step: 10
Training loss: 2.90233109934785
Validation loss: 2.699840850727584

Epoch: 150| Step: 0
Training loss: 3.188810340971384
Validation loss: 2.7030147748385844

Epoch: 5| Step: 1
Training loss: 3.099495225233476
Validation loss: 2.701019624251777

Epoch: 5| Step: 2
Training loss: 3.4831009661059054
Validation loss: 2.702728086806602

Epoch: 5| Step: 3
Training loss: 2.6167378053491257
Validation loss: 2.700560029566618

Epoch: 5| Step: 4
Training loss: 3.003160242673752
Validation loss: 2.6995739506114163

Epoch: 5| Step: 5
Training loss: 3.007847218498896
Validation loss: 2.6986817290995586

Epoch: 5| Step: 6
Training loss: 2.8583589009586343
Validation loss: 2.6961985273879714

Epoch: 5| Step: 7
Training loss: 2.8516046390293983
Validation loss: 2.700252712398981

Epoch: 5| Step: 8
Training loss: 3.9081326029837937
Validation loss: 2.7086402791700395

Epoch: 5| Step: 9
Training loss: 2.0666482996380813
Validation loss: 2.7081953431623536

Epoch: 5| Step: 10
Training loss: 2.8660984725592975
Validation loss: 2.7152113921629546

Epoch: 151| Step: 0
Training loss: 3.1624525707442683
Validation loss: 2.725008792793393

Epoch: 5| Step: 1
Training loss: 3.5051646954945648
Validation loss: 2.7223674473697055

Epoch: 5| Step: 2
Training loss: 2.840209433664214
Validation loss: 2.7137650959225708

Epoch: 5| Step: 3
Training loss: 2.8627286328291275
Validation loss: 2.698223453065495

Epoch: 5| Step: 4
Training loss: 2.8665952148699905
Validation loss: 2.6959300190580473

Epoch: 5| Step: 5
Training loss: 2.926932135282323
Validation loss: 2.692442003341639

Epoch: 5| Step: 6
Training loss: 3.296112840248625
Validation loss: 2.6958449361097245

Epoch: 5| Step: 7
Training loss: 3.015292134468726
Validation loss: 2.693759162795314

Epoch: 5| Step: 8
Training loss: 3.5009295727756586
Validation loss: 2.6992299639270323

Epoch: 5| Step: 9
Training loss: 2.598397468997164
Validation loss: 2.700480819793187

Epoch: 5| Step: 10
Training loss: 2.463662905999559
Validation loss: 2.7027897192657107

Epoch: 152| Step: 0
Training loss: 2.981589730217076
Validation loss: 2.6991785639252743

Epoch: 5| Step: 1
Training loss: 3.1168183607696425
Validation loss: 2.7001730587688746

Epoch: 5| Step: 2
Training loss: 2.6333876527744935
Validation loss: 2.697650763446496

Epoch: 5| Step: 3
Training loss: 3.251471699771736
Validation loss: 2.6958787273097298

Epoch: 5| Step: 4
Training loss: 2.7807690493894817
Validation loss: 2.6935145467049995

Epoch: 5| Step: 5
Training loss: 3.3575651749614286
Validation loss: 2.7030546847948838

Epoch: 5| Step: 6
Training loss: 3.132195695007924
Validation loss: 2.706798986535302

Epoch: 5| Step: 7
Training loss: 2.8716369530248818
Validation loss: 2.71934192226558

Epoch: 5| Step: 8
Training loss: 3.1754548115014476
Validation loss: 2.7002558131626504

Epoch: 5| Step: 9
Training loss: 3.2534177855437627
Validation loss: 2.699528734719557

Epoch: 5| Step: 10
Training loss: 2.601169040928729
Validation loss: 2.6920254002892094

Epoch: 153| Step: 0
Training loss: 3.0383905682916077
Validation loss: 2.6964483915139117

Epoch: 5| Step: 1
Training loss: 2.299885651606951
Validation loss: 2.692996860399097

Epoch: 5| Step: 2
Training loss: 2.9431382306916025
Validation loss: 2.692101780119745

Epoch: 5| Step: 3
Training loss: 2.91452898070723
Validation loss: 2.6905411047557637

Epoch: 5| Step: 4
Training loss: 3.3663280832985216
Validation loss: 2.6895035022076916

Epoch: 5| Step: 5
Training loss: 3.1013046657137116
Validation loss: 2.6855740315098116

Epoch: 5| Step: 6
Training loss: 2.787885829071029
Validation loss: 2.686110389810529

Epoch: 5| Step: 7
Training loss: 3.3231423200723085
Validation loss: 2.689396455471135

Epoch: 5| Step: 8
Training loss: 2.7747145600475718
Validation loss: 2.6870156605539908

Epoch: 5| Step: 9
Training loss: 3.0967839324833926
Validation loss: 2.6894186229790744

Epoch: 5| Step: 10
Training loss: 3.475075392968677
Validation loss: 2.689800595109326

Epoch: 154| Step: 0
Training loss: 3.252890841716795
Validation loss: 2.6838130371443145

Epoch: 5| Step: 1
Training loss: 2.701053067874838
Validation loss: 2.6871642875804826

Epoch: 5| Step: 2
Training loss: 3.0801888145436385
Validation loss: 2.6888899665471477

Epoch: 5| Step: 3
Training loss: 3.812765893888147
Validation loss: 2.691173509648421

Epoch: 5| Step: 4
Training loss: 3.1990995093773558
Validation loss: 2.689925482216768

Epoch: 5| Step: 5
Training loss: 3.1113497343588086
Validation loss: 2.687200775239434

Epoch: 5| Step: 6
Training loss: 3.0749731047159683
Validation loss: 2.686985072423152

Epoch: 5| Step: 7
Training loss: 2.927692843111442
Validation loss: 2.687823380829347

Epoch: 5| Step: 8
Training loss: 2.5804674084458084
Validation loss: 2.6884014671518917

Epoch: 5| Step: 9
Training loss: 3.0051777979700485
Validation loss: 2.6863067603151936

Epoch: 5| Step: 10
Training loss: 2.0092092917356386
Validation loss: 2.6897025825559715

Epoch: 155| Step: 0
Training loss: 2.795832775436171
Validation loss: 2.6953535588367914

Epoch: 5| Step: 1
Training loss: 2.754859618610268
Validation loss: 2.690979820732074

Epoch: 5| Step: 2
Training loss: 3.5837514027225876
Validation loss: 2.6977140010253793

Epoch: 5| Step: 3
Training loss: 2.9982828948221036
Validation loss: 2.6991080537788754

Epoch: 5| Step: 4
Training loss: 2.726424161795441
Validation loss: 2.7077181026602193

Epoch: 5| Step: 5
Training loss: 3.448740112688714
Validation loss: 2.6972358431504087

Epoch: 5| Step: 6
Training loss: 2.6517010501412237
Validation loss: 2.6986178834092316

Epoch: 5| Step: 7
Training loss: 2.727454009677972
Validation loss: 2.6797000240503355

Epoch: 5| Step: 8
Training loss: 3.030677033377138
Validation loss: 2.6800233052990876

Epoch: 5| Step: 9
Training loss: 3.1082766332559935
Validation loss: 2.6757663018300333

Epoch: 5| Step: 10
Training loss: 3.230403655017903
Validation loss: 2.6760624357499365

Epoch: 156| Step: 0
Training loss: 2.993804733636128
Validation loss: 2.679483368191552

Epoch: 5| Step: 1
Training loss: 3.5923244136621575
Validation loss: 2.674649382115575

Epoch: 5| Step: 2
Training loss: 2.859434533671991
Validation loss: 2.6788570270351175

Epoch: 5| Step: 3
Training loss: 2.9773773119397897
Validation loss: 2.6747324373767185

Epoch: 5| Step: 4
Training loss: 3.384919459682188
Validation loss: 2.6772069132017995

Epoch: 5| Step: 5
Training loss: 3.52199970014442
Validation loss: 2.6759475195267903

Epoch: 5| Step: 6
Training loss: 2.891458587049124
Validation loss: 2.6768939021174956

Epoch: 5| Step: 7
Training loss: 2.8702191947677416
Validation loss: 2.674829582871213

Epoch: 5| Step: 8
Training loss: 2.688050235931675
Validation loss: 2.6750830462536013

Epoch: 5| Step: 9
Training loss: 2.278037435054893
Validation loss: 2.681435817746311

Epoch: 5| Step: 10
Training loss: 2.782616697402261
Validation loss: 2.6802354841464546

Epoch: 157| Step: 0
Training loss: 3.0276801728392493
Validation loss: 2.6823708385264675

Epoch: 5| Step: 1
Training loss: 3.4408273025894682
Validation loss: 2.6867825789920685

Epoch: 5| Step: 2
Training loss: 2.9298868747263684
Validation loss: 2.678270799532036

Epoch: 5| Step: 3
Training loss: 2.756286544730536
Validation loss: 2.6720429287161864

Epoch: 5| Step: 4
Training loss: 2.799253762803679
Validation loss: 2.6725259201607146

Epoch: 5| Step: 5
Training loss: 2.877406232882024
Validation loss: 2.6758692012638137

Epoch: 5| Step: 6
Training loss: 3.1975990825270957
Validation loss: 2.6774265798169044

Epoch: 5| Step: 7
Training loss: 2.6733668217103372
Validation loss: 2.681543371564453

Epoch: 5| Step: 8
Training loss: 2.987294471725749
Validation loss: 2.683334193544499

Epoch: 5| Step: 9
Training loss: 3.5518364843844092
Validation loss: 2.6799370008458587

Epoch: 5| Step: 10
Training loss: 2.8222407884395917
Validation loss: 2.6822148520038565

Epoch: 158| Step: 0
Training loss: 2.8296440639353304
Validation loss: 2.686205948039973

Epoch: 5| Step: 1
Training loss: 2.7297564056206736
Validation loss: 2.688529183587464

Epoch: 5| Step: 2
Training loss: 3.0892950793375564
Validation loss: 2.6940511254954114

Epoch: 5| Step: 3
Training loss: 2.579765583892163
Validation loss: 2.6855964930808516

Epoch: 5| Step: 4
Training loss: 3.328619691860209
Validation loss: 2.6824654557608554

Epoch: 5| Step: 5
Training loss: 2.9824887051492373
Validation loss: 2.6846912069296267

Epoch: 5| Step: 6
Training loss: 2.9934877603311563
Validation loss: 2.6889446379365727

Epoch: 5| Step: 7
Training loss: 3.191200950117106
Validation loss: 2.6843645426274443

Epoch: 5| Step: 8
Training loss: 3.1311269587481303
Validation loss: 2.6743886968495745

Epoch: 5| Step: 9
Training loss: 2.8873376247444873
Validation loss: 2.678040948735053

Epoch: 5| Step: 10
Training loss: 3.319292697248883
Validation loss: 2.676691296562888

Epoch: 159| Step: 0
Training loss: 3.141814201256931
Validation loss: 2.6779307096897966

Epoch: 5| Step: 1
Training loss: 3.1319770745501656
Validation loss: 2.6726816808200224

Epoch: 5| Step: 2
Training loss: 3.02312868103472
Validation loss: 2.6716456669560102

Epoch: 5| Step: 3
Training loss: 2.6166814058540697
Validation loss: 2.6713867835274954

Epoch: 5| Step: 4
Training loss: 2.7163184681955834
Validation loss: 2.672145464010792

Epoch: 5| Step: 5
Training loss: 3.2883546479802868
Validation loss: 2.671858704910717

Epoch: 5| Step: 6
Training loss: 3.069172654889663
Validation loss: 2.6729069158531136

Epoch: 5| Step: 7
Training loss: 3.4351335182504927
Validation loss: 2.6735059107959467

Epoch: 5| Step: 8
Training loss: 2.246420450085427
Validation loss: 2.669843157206977

Epoch: 5| Step: 9
Training loss: 2.8247848935222715
Validation loss: 2.6672685434876677

Epoch: 5| Step: 10
Training loss: 3.409823162158469
Validation loss: 2.671870883779444

Epoch: 160| Step: 0
Training loss: 2.8228972787414146
Validation loss: 2.6732107077774927

Epoch: 5| Step: 1
Training loss: 2.3461548737888083
Validation loss: 2.6680426188221866

Epoch: 5| Step: 2
Training loss: 2.789593985216479
Validation loss: 2.6688502860659202

Epoch: 5| Step: 3
Training loss: 2.8780665421736167
Validation loss: 2.6733542631956033

Epoch: 5| Step: 4
Training loss: 3.2002377779357505
Validation loss: 2.668243010228535

Epoch: 5| Step: 5
Training loss: 3.194543424169377
Validation loss: 2.6711894543942107

Epoch: 5| Step: 6
Training loss: 3.391915493272345
Validation loss: 2.6697858880259733

Epoch: 5| Step: 7
Training loss: 3.340198948582746
Validation loss: 2.670507651453339

Epoch: 5| Step: 8
Training loss: 2.675158173350018
Validation loss: 2.671443241075848

Epoch: 5| Step: 9
Training loss: 2.9064596777310308
Validation loss: 2.6706774055249856

Epoch: 5| Step: 10
Training loss: 3.3892906833229235
Validation loss: 2.671472838323233

Epoch: 161| Step: 0
Training loss: 3.2402917674053735
Validation loss: 2.672174096015397

Epoch: 5| Step: 1
Training loss: 3.3635730151647856
Validation loss: 2.6721919059575825

Epoch: 5| Step: 2
Training loss: 3.278287294805059
Validation loss: 2.67711035863764

Epoch: 5| Step: 3
Training loss: 2.5668170199592795
Validation loss: 2.671366646767618

Epoch: 5| Step: 4
Training loss: 3.2764648422946596
Validation loss: 2.665513693706992

Epoch: 5| Step: 5
Training loss: 2.64169362131641
Validation loss: 2.671982917556405

Epoch: 5| Step: 6
Training loss: 3.1351487730703735
Validation loss: 2.6692378370084926

Epoch: 5| Step: 7
Training loss: 3.0731650731606543
Validation loss: 2.670395660425548

Epoch: 5| Step: 8
Training loss: 3.2273580757216545
Validation loss: 2.6690020224424638

Epoch: 5| Step: 9
Training loss: 2.462681325055448
Validation loss: 2.6670221244365293

Epoch: 5| Step: 10
Training loss: 2.432512707574159
Validation loss: 2.669636912880389

Epoch: 162| Step: 0
Training loss: 3.283206755881767
Validation loss: 2.668679180388604

Epoch: 5| Step: 1
Training loss: 2.7985166707812597
Validation loss: 2.6779407500588337

Epoch: 5| Step: 2
Training loss: 3.2146012317870376
Validation loss: 2.677514976834219

Epoch: 5| Step: 3
Training loss: 3.2007510436375974
Validation loss: 2.664537023255907

Epoch: 5| Step: 4
Training loss: 2.635499573460217
Validation loss: 2.663244893562117

Epoch: 5| Step: 5
Training loss: 2.6674730949153296
Validation loss: 2.662268740847736

Epoch: 5| Step: 6
Training loss: 2.7044856004379234
Validation loss: 2.663754723613615

Epoch: 5| Step: 7
Training loss: 3.26656638270481
Validation loss: 2.6656672251314024

Epoch: 5| Step: 8
Training loss: 3.118504907919462
Validation loss: 2.6692699990420032

Epoch: 5| Step: 9
Training loss: 3.212787772622341
Validation loss: 2.6624136276828647

Epoch: 5| Step: 10
Training loss: 2.8128952596335153
Validation loss: 2.6664091807565704

Epoch: 163| Step: 0
Training loss: 2.5647132433648245
Validation loss: 2.666225755167835

Epoch: 5| Step: 1
Training loss: 3.4132419883406566
Validation loss: 2.66353148086441

Epoch: 5| Step: 2
Training loss: 2.5254064855940457
Validation loss: 2.6636941243897763

Epoch: 5| Step: 3
Training loss: 2.6842520848866833
Validation loss: 2.6645819016003873

Epoch: 5| Step: 4
Training loss: 2.510870949148683
Validation loss: 2.6623107021727677

Epoch: 5| Step: 5
Training loss: 3.0438082397654203
Validation loss: 2.6657486445461123

Epoch: 5| Step: 6
Training loss: 3.0915874282539844
Validation loss: 2.666555701018462

Epoch: 5| Step: 7
Training loss: 3.350106303108375
Validation loss: 2.6771529865233203

Epoch: 5| Step: 8
Training loss: 2.9531311358029844
Validation loss: 2.6766492197101055

Epoch: 5| Step: 9
Training loss: 3.6044478701810267
Validation loss: 2.676768356249621

Epoch: 5| Step: 10
Training loss: 3.018776625363787
Validation loss: 2.6686449583209066

Epoch: 164| Step: 0
Training loss: 3.247547985306779
Validation loss: 2.660696145242823

Epoch: 5| Step: 1
Training loss: 3.181927466063925
Validation loss: 2.663099018063009

Epoch: 5| Step: 2
Training loss: 2.3577115087197607
Validation loss: 2.6622495317847643

Epoch: 5| Step: 3
Training loss: 2.740712347780921
Validation loss: 2.6648364185675377

Epoch: 5| Step: 4
Training loss: 3.4701292028201394
Validation loss: 2.6640908493541455

Epoch: 5| Step: 5
Training loss: 3.122123157005073
Validation loss: 2.660607725166734

Epoch: 5| Step: 6
Training loss: 3.2449949312097024
Validation loss: 2.6642320989312664

Epoch: 5| Step: 7
Training loss: 2.9215082764620117
Validation loss: 2.662722341830539

Epoch: 5| Step: 8
Training loss: 3.1253347599017607
Validation loss: 2.6613555994974485

Epoch: 5| Step: 9
Training loss: 2.560718009810733
Validation loss: 2.661444456124769

Epoch: 5| Step: 10
Training loss: 2.7491995773665883
Validation loss: 2.662927864386408

Epoch: 165| Step: 0
Training loss: 3.163817747092333
Validation loss: 2.664729099573958

Epoch: 5| Step: 1
Training loss: 3.113229021234973
Validation loss: 2.6594423802838483

Epoch: 5| Step: 2
Training loss: 2.855598665927116
Validation loss: 2.661070826021987

Epoch: 5| Step: 3
Training loss: 2.9349748837177807
Validation loss: 2.670753272802301

Epoch: 5| Step: 4
Training loss: 3.3486041904671358
Validation loss: 2.7133789379012967

Epoch: 5| Step: 5
Training loss: 3.024186862076782
Validation loss: 2.699517080438799

Epoch: 5| Step: 6
Training loss: 2.6235083928847303
Validation loss: 2.671152698115314

Epoch: 5| Step: 7
Training loss: 3.48897109093447
Validation loss: 2.656113585239238

Epoch: 5| Step: 8
Training loss: 3.079399193710694
Validation loss: 2.659153356635627

Epoch: 5| Step: 9
Training loss: 2.4324685031776703
Validation loss: 2.6619429277887265

Epoch: 5| Step: 10
Training loss: 2.745428533821281
Validation loss: 2.6618450895111567

Epoch: 166| Step: 0
Training loss: 2.6465732911435285
Validation loss: 2.6627415802172516

Epoch: 5| Step: 1
Training loss: 2.77694652093501
Validation loss: 2.664620512054394

Epoch: 5| Step: 2
Training loss: 3.2234162515299576
Validation loss: 2.6632835888550255

Epoch: 5| Step: 3
Training loss: 2.9571060715434903
Validation loss: 2.6641773120588756

Epoch: 5| Step: 4
Training loss: 2.5293620097489176
Validation loss: 2.662943424703713

Epoch: 5| Step: 5
Training loss: 3.0363394886836272
Validation loss: 2.6591844962867053

Epoch: 5| Step: 6
Training loss: 3.212643655021576
Validation loss: 2.657220073377766

Epoch: 5| Step: 7
Training loss: 2.8443334630667154
Validation loss: 2.656814701440502

Epoch: 5| Step: 8
Training loss: 3.1996534934790235
Validation loss: 2.6537569916707406

Epoch: 5| Step: 9
Training loss: 3.444868201847581
Validation loss: 2.653690648875135

Epoch: 5| Step: 10
Training loss: 2.993346784033287
Validation loss: 2.654481057274229

Epoch: 167| Step: 0
Training loss: 2.5091570045726894
Validation loss: 2.651609821209006

Epoch: 5| Step: 1
Training loss: 3.233606809344099
Validation loss: 2.6521596276054415

Epoch: 5| Step: 2
Training loss: 3.0436086508263123
Validation loss: 2.6525390587886957

Epoch: 5| Step: 3
Training loss: 2.969583173587417
Validation loss: 2.6506750612970693

Epoch: 5| Step: 4
Training loss: 3.383615306009609
Validation loss: 2.655163169464534

Epoch: 5| Step: 5
Training loss: 3.2182249363154614
Validation loss: 2.653687998954438

Epoch: 5| Step: 6
Training loss: 2.9987607621655337
Validation loss: 2.6499468899661944

Epoch: 5| Step: 7
Training loss: 2.8341953611804733
Validation loss: 2.6532509934389683

Epoch: 5| Step: 8
Training loss: 2.746524174737851
Validation loss: 2.6532498281699106

Epoch: 5| Step: 9
Training loss: 3.2227632262074146
Validation loss: 2.6543841425336323

Epoch: 5| Step: 10
Training loss: 2.4969093291747937
Validation loss: 2.653164875198492

Epoch: 168| Step: 0
Training loss: 2.818251091561554
Validation loss: 2.6563534643494595

Epoch: 5| Step: 1
Training loss: 3.018179804497305
Validation loss: 2.655030858577938

Epoch: 5| Step: 2
Training loss: 3.4077948470535153
Validation loss: 2.6544447263713846

Epoch: 5| Step: 3
Training loss: 3.0240028503343983
Validation loss: 2.6566593971816377

Epoch: 5| Step: 4
Training loss: 2.664184030574294
Validation loss: 2.655110313875793

Epoch: 5| Step: 5
Training loss: 2.8211949201690922
Validation loss: 2.6531931458117515

Epoch: 5| Step: 6
Training loss: 2.256846713044916
Validation loss: 2.6517146576892388

Epoch: 5| Step: 7
Training loss: 3.2016927354722045
Validation loss: 2.652370198725804

Epoch: 5| Step: 8
Training loss: 3.0749724844345026
Validation loss: 2.652330399885193

Epoch: 5| Step: 9
Training loss: 3.1464942254753474
Validation loss: 2.659875537364676

Epoch: 5| Step: 10
Training loss: 3.351033202304808
Validation loss: 2.659591725009148

Epoch: 169| Step: 0
Training loss: 2.630495857663311
Validation loss: 2.6601683966747673

Epoch: 5| Step: 1
Training loss: 3.2742978515390537
Validation loss: 2.6632176643450265

Epoch: 5| Step: 2
Training loss: 3.14369499507282
Validation loss: 2.662215090323518

Epoch: 5| Step: 3
Training loss: 3.206253979775262
Validation loss: 2.652587009568696

Epoch: 5| Step: 4
Training loss: 2.9308091928201736
Validation loss: 2.6551124911891923

Epoch: 5| Step: 5
Training loss: 2.786273919298502
Validation loss: 2.65887937754483

Epoch: 5| Step: 6
Training loss: 2.5903855529490674
Validation loss: 2.672226929720337

Epoch: 5| Step: 7
Training loss: 3.3188596890528705
Validation loss: 2.686533451481011

Epoch: 5| Step: 8
Training loss: 2.546920401513704
Validation loss: 2.6686451677431586

Epoch: 5| Step: 9
Training loss: 3.302540904852301
Validation loss: 2.66302604217911

Epoch: 5| Step: 10
Training loss: 3.2492397592924256
Validation loss: 2.659086955655318

Epoch: 170| Step: 0
Training loss: 3.7439697099259193
Validation loss: 2.656500133919511

Epoch: 5| Step: 1
Training loss: 2.9760885987783228
Validation loss: 2.6554382174368123

Epoch: 5| Step: 2
Training loss: 3.3064866094890615
Validation loss: 2.654418624757072

Epoch: 5| Step: 3
Training loss: 2.1859930024589094
Validation loss: 2.650911317616897

Epoch: 5| Step: 4
Training loss: 3.3524012371993575
Validation loss: 2.6499918122415633

Epoch: 5| Step: 5
Training loss: 2.9262646019924485
Validation loss: 2.6557895442267694

Epoch: 5| Step: 6
Training loss: 2.3650688535575175
Validation loss: 2.6700514326357037

Epoch: 5| Step: 7
Training loss: 3.28489351979655
Validation loss: 2.7014399866359433

Epoch: 5| Step: 8
Training loss: 2.918840107149749
Validation loss: 2.707220000765193

Epoch: 5| Step: 9
Training loss: 2.61687091791542
Validation loss: 2.6974989155502365

Epoch: 5| Step: 10
Training loss: 2.9911007812621415
Validation loss: 2.6721958969647615

Epoch: 171| Step: 0
Training loss: 3.526879906388148
Validation loss: 2.6646592643381886

Epoch: 5| Step: 1
Training loss: 2.8141659359135094
Validation loss: 2.657955809552252

Epoch: 5| Step: 2
Training loss: 2.6722145980158705
Validation loss: 2.6476191807260063

Epoch: 5| Step: 3
Training loss: 2.9054733387110008
Validation loss: 2.6522067447810604

Epoch: 5| Step: 4
Training loss: 2.817063592184186
Validation loss: 2.6516861885887573

Epoch: 5| Step: 5
Training loss: 2.9022394215455667
Validation loss: 2.6531628634494764

Epoch: 5| Step: 6
Training loss: 3.1056726544693585
Validation loss: 2.655694946745352

Epoch: 5| Step: 7
Training loss: 2.7881599055698185
Validation loss: 2.6575542300279147

Epoch: 5| Step: 8
Training loss: 3.3221523797112313
Validation loss: 2.653805424709043

Epoch: 5| Step: 9
Training loss: 3.0760401137456044
Validation loss: 2.652606679053837

Epoch: 5| Step: 10
Training loss: 2.7472329523819634
Validation loss: 2.6534839567751476

Epoch: 172| Step: 0
Training loss: 3.2162089270865004
Validation loss: 2.652180040205128

Epoch: 5| Step: 1
Training loss: 2.8970070159690207
Validation loss: 2.652437110002156

Epoch: 5| Step: 2
Training loss: 3.068039535665606
Validation loss: 2.6492489843155638

Epoch: 5| Step: 3
Training loss: 2.8568243939163955
Validation loss: 2.644598112416642

Epoch: 5| Step: 4
Training loss: 2.6981372129417065
Validation loss: 2.639906489682238

Epoch: 5| Step: 5
Training loss: 2.6372499284114137
Validation loss: 2.645787676074197

Epoch: 5| Step: 6
Training loss: 3.306879132992273
Validation loss: 2.650592316122501

Epoch: 5| Step: 7
Training loss: 2.928625295721817
Validation loss: 2.6548483319022744

Epoch: 5| Step: 8
Training loss: 2.996430339582127
Validation loss: 2.6694901103731774

Epoch: 5| Step: 9
Training loss: 2.8103340285706846
Validation loss: 2.6758032553324607

Epoch: 5| Step: 10
Training loss: 3.4482883740888703
Validation loss: 2.6449176488289403

Epoch: 173| Step: 0
Training loss: 2.3479388633385114
Validation loss: 2.6471379417594343

Epoch: 5| Step: 1
Training loss: 2.7761001914739687
Validation loss: 2.6405588806654774

Epoch: 5| Step: 2
Training loss: 2.8918749606905627
Validation loss: 2.6427643617871723

Epoch: 5| Step: 3
Training loss: 2.61671375143205
Validation loss: 2.645523952049594

Epoch: 5| Step: 4
Training loss: 3.273571512397025
Validation loss: 2.645556444041427

Epoch: 5| Step: 5
Training loss: 3.074029667042897
Validation loss: 2.645174411628087

Epoch: 5| Step: 6
Training loss: 3.094239937876805
Validation loss: 2.6445754354351276

Epoch: 5| Step: 7
Training loss: 3.4969320474970647
Validation loss: 2.645006426700613

Epoch: 5| Step: 8
Training loss: 2.996701493476355
Validation loss: 2.6423890130041263

Epoch: 5| Step: 9
Training loss: 3.2982449690856246
Validation loss: 2.642892776212137

Epoch: 5| Step: 10
Training loss: 2.7796674362067493
Validation loss: 2.6429444356953375

Epoch: 174| Step: 0
Training loss: 3.0310654731507953
Validation loss: 2.642571291405256

Epoch: 5| Step: 1
Training loss: 2.576722844618908
Validation loss: 2.6408021229994367

Epoch: 5| Step: 2
Training loss: 2.6377795536806934
Validation loss: 2.653265262629178

Epoch: 5| Step: 3
Training loss: 3.043747455823019
Validation loss: 2.6677502630795966

Epoch: 5| Step: 4
Training loss: 3.4555723053613807
Validation loss: 2.667235261597719

Epoch: 5| Step: 5
Training loss: 3.0786663683096354
Validation loss: 2.6686389811339275

Epoch: 5| Step: 6
Training loss: 2.144868528876432
Validation loss: 2.646967971040079

Epoch: 5| Step: 7
Training loss: 2.959637922875277
Validation loss: 2.6554837264678968

Epoch: 5| Step: 8
Training loss: 4.103095416669105
Validation loss: 2.652560963126455

Epoch: 5| Step: 9
Training loss: 2.856159674553902
Validation loss: 2.6495005997066587

Epoch: 5| Step: 10
Training loss: 2.3947366498811378
Validation loss: 2.6367665830441367

Epoch: 175| Step: 0
Training loss: 3.2079556395586235
Validation loss: 2.6361538515320513

Epoch: 5| Step: 1
Training loss: 3.135433480015958
Validation loss: 2.6363822899174996

Epoch: 5| Step: 2
Training loss: 3.055782346304435
Validation loss: 2.6352938739717935

Epoch: 5| Step: 3
Training loss: 3.440890495458029
Validation loss: 2.630703772188461

Epoch: 5| Step: 4
Training loss: 2.776052096826213
Validation loss: 2.6343565593758136

Epoch: 5| Step: 5
Training loss: 3.0519990529650096
Validation loss: 2.6350170774362356

Epoch: 5| Step: 6
Training loss: 2.5692243968686044
Validation loss: 2.6370857190620463

Epoch: 5| Step: 7
Training loss: 2.621719672202163
Validation loss: 2.6316739435757803

Epoch: 5| Step: 8
Training loss: 3.10519649823704
Validation loss: 2.6341047996007707

Epoch: 5| Step: 9
Training loss: 2.739768240796135
Validation loss: 2.632956886123812

Epoch: 5| Step: 10
Training loss: 2.915468587492543
Validation loss: 2.632330040276408

Epoch: 176| Step: 0
Training loss: 2.8224436139538684
Validation loss: 2.631424614099915

Epoch: 5| Step: 1
Training loss: 3.380696610665361
Validation loss: 2.63267748247237

Epoch: 5| Step: 2
Training loss: 2.5393144218473043
Validation loss: 2.6339790858826437

Epoch: 5| Step: 3
Training loss: 2.884587266246982
Validation loss: 2.632699718574999

Epoch: 5| Step: 4
Training loss: 3.5770657899782217
Validation loss: 2.630028106125658

Epoch: 5| Step: 5
Training loss: 2.6839819659268223
Validation loss: 2.6326585473115847

Epoch: 5| Step: 6
Training loss: 2.777395427668394
Validation loss: 2.634824254721591

Epoch: 5| Step: 7
Training loss: 2.899867442817531
Validation loss: 2.628843205229664

Epoch: 5| Step: 8
Training loss: 3.023227102760916
Validation loss: 2.6290491890476924

Epoch: 5| Step: 9
Training loss: 2.974245626510017
Validation loss: 2.629770099427042

Epoch: 5| Step: 10
Training loss: 3.0151765321890642
Validation loss: 2.633901065340246

Epoch: 177| Step: 0
Training loss: 2.5914031292376447
Validation loss: 2.6351089965910486

Epoch: 5| Step: 1
Training loss: 3.2314239160008618
Validation loss: 2.6315963885404523

Epoch: 5| Step: 2
Training loss: 3.379556899737303
Validation loss: 2.634573234416052

Epoch: 5| Step: 3
Training loss: 2.795318170225087
Validation loss: 2.6303659744968373

Epoch: 5| Step: 4
Training loss: 2.795624266841186
Validation loss: 2.632676558357887

Epoch: 5| Step: 5
Training loss: 3.3117559785003503
Validation loss: 2.631853018083189

Epoch: 5| Step: 6
Training loss: 3.175897912842195
Validation loss: 2.633768963389474

Epoch: 5| Step: 7
Training loss: 2.699759974230493
Validation loss: 2.63903909315838

Epoch: 5| Step: 8
Training loss: 2.622300258335598
Validation loss: 2.6364020598812616

Epoch: 5| Step: 9
Training loss: 2.6190238317837844
Validation loss: 2.6441359349076707

Epoch: 5| Step: 10
Training loss: 3.3044180974428037
Validation loss: 2.6451563015357276

Epoch: 178| Step: 0
Training loss: 3.022904381090609
Validation loss: 2.6591980452953403

Epoch: 5| Step: 1
Training loss: 2.653973669903217
Validation loss: 2.662411494856386

Epoch: 5| Step: 2
Training loss: 2.934834346223055
Validation loss: 2.655924023888685

Epoch: 5| Step: 3
Training loss: 2.8331143537683614
Validation loss: 2.6642522617101134

Epoch: 5| Step: 4
Training loss: 2.975573598237051
Validation loss: 2.6394684407925926

Epoch: 5| Step: 5
Training loss: 3.095902127870253
Validation loss: 2.634543488280329

Epoch: 5| Step: 6
Training loss: 3.239561925165188
Validation loss: 2.629913509142484

Epoch: 5| Step: 7
Training loss: 3.106948749385969
Validation loss: 2.6291953653480498

Epoch: 5| Step: 8
Training loss: 3.0468341531216327
Validation loss: 2.6292278426664053

Epoch: 5| Step: 9
Training loss: 2.7645673723102644
Validation loss: 2.633979044030926

Epoch: 5| Step: 10
Training loss: 3.0531815428949702
Validation loss: 2.6279986609088737

Epoch: 179| Step: 0
Training loss: 2.9028970388668145
Validation loss: 2.6251692182666915

Epoch: 5| Step: 1
Training loss: 2.8163744201131315
Validation loss: 2.629238677450513

Epoch: 5| Step: 2
Training loss: 3.0671603496513895
Validation loss: 2.631957440523628

Epoch: 5| Step: 3
Training loss: 2.7773774006839758
Validation loss: 2.6311388518737546

Epoch: 5| Step: 4
Training loss: 2.9821527805603796
Validation loss: 2.6331735634016336

Epoch: 5| Step: 5
Training loss: 3.244669871649313
Validation loss: 2.628696760657287

Epoch: 5| Step: 6
Training loss: 2.952277975366725
Validation loss: 2.630629248593052

Epoch: 5| Step: 7
Training loss: 2.9829689428469175
Validation loss: 2.626432997472489

Epoch: 5| Step: 8
Training loss: 3.517276359123661
Validation loss: 2.626595775316386

Epoch: 5| Step: 9
Training loss: 2.84146227357902
Validation loss: 2.629825010402773

Epoch: 5| Step: 10
Training loss: 2.433995392844386
Validation loss: 2.6353757842864765

Epoch: 180| Step: 0
Training loss: 2.767562704642335
Validation loss: 2.636431215712663

Epoch: 5| Step: 1
Training loss: 3.4394485499596916
Validation loss: 2.640071411122528

Epoch: 5| Step: 2
Training loss: 2.7365455949450013
Validation loss: 2.64629073029202

Epoch: 5| Step: 3
Training loss: 3.27596707807494
Validation loss: 2.6479988418509404

Epoch: 5| Step: 4
Training loss: 2.93969936416712
Validation loss: 2.6447086736090673

Epoch: 5| Step: 5
Training loss: 2.9385176174329577
Validation loss: 2.6403787129988956

Epoch: 5| Step: 6
Training loss: 3.039161190205493
Validation loss: 2.630811804849519

Epoch: 5| Step: 7
Training loss: 3.117486848535765
Validation loss: 2.6284397234658026

Epoch: 5| Step: 8
Training loss: 2.8286865688465643
Validation loss: 2.628199832766784

Epoch: 5| Step: 9
Training loss: 3.052425395731858
Validation loss: 2.630460132074669

Epoch: 5| Step: 10
Training loss: 2.318114398717102
Validation loss: 2.6371759708724234

Epoch: 181| Step: 0
Training loss: 3.0955544806091577
Validation loss: 2.632534449255449

Epoch: 5| Step: 1
Training loss: 2.598330761523031
Validation loss: 2.6345558367283872

Epoch: 5| Step: 2
Training loss: 3.199667651083871
Validation loss: 2.630505516753104

Epoch: 5| Step: 3
Training loss: 3.6129499953732247
Validation loss: 2.630848650182622

Epoch: 5| Step: 4
Training loss: 3.008477154901619
Validation loss: 2.628633674777415

Epoch: 5| Step: 5
Training loss: 2.9956116369256995
Validation loss: 2.624428506686758

Epoch: 5| Step: 6
Training loss: 3.055649237689749
Validation loss: 2.6213067887887664

Epoch: 5| Step: 7
Training loss: 2.403861805204644
Validation loss: 2.62432956972551

Epoch: 5| Step: 8
Training loss: 2.4457038346883455
Validation loss: 2.6259826533903774

Epoch: 5| Step: 9
Training loss: 3.2822004122545003
Validation loss: 2.6222079771941225

Epoch: 5| Step: 10
Training loss: 2.6747386376873803
Validation loss: 2.6251465980624533

Epoch: 182| Step: 0
Training loss: 3.2302519092410984
Validation loss: 2.6244225147576317

Epoch: 5| Step: 1
Training loss: 2.607094687746585
Validation loss: 2.6277948922501677

Epoch: 5| Step: 2
Training loss: 3.0741118784532806
Validation loss: 2.636268643055138

Epoch: 5| Step: 3
Training loss: 3.0443920484459803
Validation loss: 2.631043462607638

Epoch: 5| Step: 4
Training loss: 3.0843245141749
Validation loss: 2.630175240738056

Epoch: 5| Step: 5
Training loss: 2.2561780035731607
Validation loss: 2.62838501666209

Epoch: 5| Step: 6
Training loss: 3.2572706032561856
Validation loss: 2.6309199753408756

Epoch: 5| Step: 7
Training loss: 3.2066529732753475
Validation loss: 2.6247811350721904

Epoch: 5| Step: 8
Training loss: 2.554092944659316
Validation loss: 2.6206642377131035

Epoch: 5| Step: 9
Training loss: 3.35653935895301
Validation loss: 2.6204357899466415

Epoch: 5| Step: 10
Training loss: 2.6716780562067814
Validation loss: 2.6187264950078917

Epoch: 183| Step: 0
Training loss: 3.144287099896755
Validation loss: 2.6232050253654475

Epoch: 5| Step: 1
Training loss: 3.221214610073031
Validation loss: 2.6237279932330835

Epoch: 5| Step: 2
Training loss: 3.220282921060633
Validation loss: 2.6225244125787306

Epoch: 5| Step: 3
Training loss: 3.048179621032067
Validation loss: 2.620639991903142

Epoch: 5| Step: 4
Training loss: 3.137034171125349
Validation loss: 2.6222906648302415

Epoch: 5| Step: 5
Training loss: 3.134184957658995
Validation loss: 2.624045073797389

Epoch: 5| Step: 6
Training loss: 2.6870911752999747
Validation loss: 2.622675961207557

Epoch: 5| Step: 7
Training loss: 2.8498998523985315
Validation loss: 2.6232367950229154

Epoch: 5| Step: 8
Training loss: 2.5279743993766646
Validation loss: 2.623880420076781

Epoch: 5| Step: 9
Training loss: 2.972582782333765
Validation loss: 2.622010927300649

Epoch: 5| Step: 10
Training loss: 2.4369336962033175
Validation loss: 2.6208344587982304

Epoch: 184| Step: 0
Training loss: 2.935273645696781
Validation loss: 2.618491630859149

Epoch: 5| Step: 1
Training loss: 2.9111111911097445
Validation loss: 2.6178358694910506

Epoch: 5| Step: 2
Training loss: 2.5558849643019204
Validation loss: 2.621873287460607

Epoch: 5| Step: 3
Training loss: 3.2318823603286395
Validation loss: 2.6172662225110837

Epoch: 5| Step: 4
Training loss: 2.495884559712768
Validation loss: 2.619180223431845

Epoch: 5| Step: 5
Training loss: 3.2374228155295426
Validation loss: 2.6150678175880206

Epoch: 5| Step: 6
Training loss: 2.413830100912862
Validation loss: 2.620749994766442

Epoch: 5| Step: 7
Training loss: 3.337405737070788
Validation loss: 2.6175189916880766

Epoch: 5| Step: 8
Training loss: 3.2905533915930927
Validation loss: 2.6160834486310396

Epoch: 5| Step: 9
Training loss: 3.254561524281271
Validation loss: 2.6205497194102185

Epoch: 5| Step: 10
Training loss: 2.6335350426145294
Validation loss: 2.623015669913324

Epoch: 185| Step: 0
Training loss: 2.7207450124086208
Validation loss: 2.6198341794954776

Epoch: 5| Step: 1
Training loss: 2.773889467189362
Validation loss: 2.621550071871605

Epoch: 5| Step: 2
Training loss: 3.074436204289034
Validation loss: 2.6301645102069147

Epoch: 5| Step: 3
Training loss: 2.990386978929724
Validation loss: 2.623028717687973

Epoch: 5| Step: 4
Training loss: 2.651629749315242
Validation loss: 2.6186742393120674

Epoch: 5| Step: 5
Training loss: 2.730095702788955
Validation loss: 2.6190866851703074

Epoch: 5| Step: 6
Training loss: 3.2418046472467528
Validation loss: 2.624714663008731

Epoch: 5| Step: 7
Training loss: 2.7033166541805227
Validation loss: 2.628160110763314

Epoch: 5| Step: 8
Training loss: 2.9432793437402585
Validation loss: 2.622351572679296

Epoch: 5| Step: 9
Training loss: 3.7057035458238223
Validation loss: 2.6230526648280463

Epoch: 5| Step: 10
Training loss: 2.777894900289945
Validation loss: 2.6223492107692343

Epoch: 186| Step: 0
Training loss: 3.5400237068632476
Validation loss: 2.619739026430647

Epoch: 5| Step: 1
Training loss: 2.50871940210193
Validation loss: 2.6187952291710244

Epoch: 5| Step: 2
Training loss: 2.796740480736344
Validation loss: 2.622168242637203

Epoch: 5| Step: 3
Training loss: 3.2195581699311338
Validation loss: 2.6187555975069423

Epoch: 5| Step: 4
Training loss: 2.70641730586469
Validation loss: 2.6181383433647354

Epoch: 5| Step: 5
Training loss: 2.5097983985275034
Validation loss: 2.6155941208085385

Epoch: 5| Step: 6
Training loss: 3.210816615444223
Validation loss: 2.615512440794491

Epoch: 5| Step: 7
Training loss: 3.080081221265089
Validation loss: 2.6170102226692795

Epoch: 5| Step: 8
Training loss: 2.62290244084733
Validation loss: 2.6150861889879633

Epoch: 5| Step: 9
Training loss: 3.1650252019713476
Validation loss: 2.6173804089451362

Epoch: 5| Step: 10
Training loss: 3.040964193527829
Validation loss: 2.6224827902561074

Epoch: 187| Step: 0
Training loss: 3.088833688415014
Validation loss: 2.6156719121471235

Epoch: 5| Step: 1
Training loss: 2.967140323531047
Validation loss: 2.6124174730780814

Epoch: 5| Step: 2
Training loss: 2.7830669168972966
Validation loss: 2.6127847635539765

Epoch: 5| Step: 3
Training loss: 3.293869601255223
Validation loss: 2.6103996243366705

Epoch: 5| Step: 4
Training loss: 3.133757717395435
Validation loss: 2.6170444694939263

Epoch: 5| Step: 5
Training loss: 2.428654098305794
Validation loss: 2.614696159195059

Epoch: 5| Step: 6
Training loss: 3.0288723144519345
Validation loss: 2.6144151040696877

Epoch: 5| Step: 7
Training loss: 2.6502383250906045
Validation loss: 2.615897047938347

Epoch: 5| Step: 8
Training loss: 3.010813773779989
Validation loss: 2.611718646972166

Epoch: 5| Step: 9
Training loss: 2.527837926081474
Validation loss: 2.609574520860396

Epoch: 5| Step: 10
Training loss: 3.4738980144581038
Validation loss: 2.6114581461186375

Epoch: 188| Step: 0
Training loss: 2.7992962634048757
Validation loss: 2.6131449800186393

Epoch: 5| Step: 1
Training loss: 2.6629482411344267
Validation loss: 2.610824521305852

Epoch: 5| Step: 2
Training loss: 2.9019489250815114
Validation loss: 2.6152424024338488

Epoch: 5| Step: 3
Training loss: 2.98710451580903
Validation loss: 2.6106187934782756

Epoch: 5| Step: 4
Training loss: 2.7426252314612367
Validation loss: 2.6080350421504335

Epoch: 5| Step: 5
Training loss: 3.4224265015584097
Validation loss: 2.6136265319405187

Epoch: 5| Step: 6
Training loss: 2.946071698923873
Validation loss: 2.6097521166465336

Epoch: 5| Step: 7
Training loss: 2.7391425722194205
Validation loss: 2.6123118691647087

Epoch: 5| Step: 8
Training loss: 3.157780946388
Validation loss: 2.61060577991595

Epoch: 5| Step: 9
Training loss: 2.8980044635240763
Validation loss: 2.6091856705731153

Epoch: 5| Step: 10
Training loss: 3.1578173381120935
Validation loss: 2.608694082872407

Epoch: 189| Step: 0
Training loss: 2.976968572356507
Validation loss: 2.6082937549821397

Epoch: 5| Step: 1
Training loss: 3.097708587396762
Validation loss: 2.6088589816364824

Epoch: 5| Step: 2
Training loss: 3.2890187167698963
Validation loss: 2.6105226622596227

Epoch: 5| Step: 3
Training loss: 2.686604372758501
Validation loss: 2.606687351784975

Epoch: 5| Step: 4
Training loss: 3.149776353919737
Validation loss: 2.6131972677993134

Epoch: 5| Step: 5
Training loss: 2.9501743006534107
Validation loss: 2.6116488941538454

Epoch: 5| Step: 6
Training loss: 2.5934460933003756
Validation loss: 2.610318808093855

Epoch: 5| Step: 7
Training loss: 3.0452075014367477
Validation loss: 2.6162373281936446

Epoch: 5| Step: 8
Training loss: 2.63525947031618
Validation loss: 2.610953552240344

Epoch: 5| Step: 9
Training loss: 2.958872535530815
Validation loss: 2.616828134886032

Epoch: 5| Step: 10
Training loss: 2.9722345080572343
Validation loss: 2.6103199699389856

Epoch: 190| Step: 0
Training loss: 3.388718310650862
Validation loss: 2.609004477208504

Epoch: 5| Step: 1
Training loss: 2.9138563149660586
Validation loss: 2.606842492091969

Epoch: 5| Step: 2
Training loss: 3.07758802968239
Validation loss: 2.605668428291832

Epoch: 5| Step: 3
Training loss: 3.4659459232925833
Validation loss: 2.605156671842249

Epoch: 5| Step: 4
Training loss: 2.5433924918171087
Validation loss: 2.6124908666131654

Epoch: 5| Step: 5
Training loss: 2.4434455350203907
Validation loss: 2.611703418518359

Epoch: 5| Step: 6
Training loss: 3.1011290739839095
Validation loss: 2.612802734984708

Epoch: 5| Step: 7
Training loss: 2.5830263652748173
Validation loss: 2.610233904591159

Epoch: 5| Step: 8
Training loss: 2.9114310730196475
Validation loss: 2.6098999606549973

Epoch: 5| Step: 9
Training loss: 2.698152676622197
Validation loss: 2.6060870129294016

Epoch: 5| Step: 10
Training loss: 3.177171015962605
Validation loss: 2.606541142649012

Epoch: 191| Step: 0
Training loss: 2.2052169499313776
Validation loss: 2.6078428373440796

Epoch: 5| Step: 1
Training loss: 2.567650062462118
Validation loss: 2.6073039875432027

Epoch: 5| Step: 2
Training loss: 2.849538089731229
Validation loss: 2.6088227799188126

Epoch: 5| Step: 3
Training loss: 3.013720449574106
Validation loss: 2.6181832023625673

Epoch: 5| Step: 4
Training loss: 3.259565362098524
Validation loss: 2.6194656656236073

Epoch: 5| Step: 5
Training loss: 3.172321607595775
Validation loss: 2.616539577310636

Epoch: 5| Step: 6
Training loss: 2.7693568337511225
Validation loss: 2.624143279984587

Epoch: 5| Step: 7
Training loss: 3.6263274031553587
Validation loss: 2.615415080891878

Epoch: 5| Step: 8
Training loss: 2.9268492110666187
Validation loss: 2.6115601917139095

Epoch: 5| Step: 9
Training loss: 2.9732184260735144
Validation loss: 2.6058331348359522

Epoch: 5| Step: 10
Training loss: 2.769899072151107
Validation loss: 2.6018963676258786

Epoch: 192| Step: 0
Training loss: 3.0920593574422677
Validation loss: 2.6049388411749956

Epoch: 5| Step: 1
Training loss: 3.3989364082423474
Validation loss: 2.6118117610383123

Epoch: 5| Step: 2
Training loss: 3.232703030163084
Validation loss: 2.6094996247138087

Epoch: 5| Step: 3
Training loss: 3.0201473816536137
Validation loss: 2.606937342933684

Epoch: 5| Step: 4
Training loss: 2.549340394672021
Validation loss: 2.607932167559287

Epoch: 5| Step: 5
Training loss: 3.330400575480983
Validation loss: 2.6050988180831567

Epoch: 5| Step: 6
Training loss: 2.135910522915662
Validation loss: 2.6053118550814416

Epoch: 5| Step: 7
Training loss: 2.810668348877685
Validation loss: 2.6022181742926564

Epoch: 5| Step: 8
Training loss: 2.949719923269398
Validation loss: 2.6050719711013564

Epoch: 5| Step: 9
Training loss: 2.97807213655289
Validation loss: 2.600357680805929

Epoch: 5| Step: 10
Training loss: 2.695068171387376
Validation loss: 2.600066070726832

Epoch: 193| Step: 0
Training loss: 3.0122544817774415
Validation loss: 2.603898377083242

Epoch: 5| Step: 1
Training loss: 2.1775135424397583
Validation loss: 2.5987328787026387

Epoch: 5| Step: 2
Training loss: 2.712378303153475
Validation loss: 2.6008421799168415

Epoch: 5| Step: 3
Training loss: 2.7510376619779033
Validation loss: 2.6014489353546835

Epoch: 5| Step: 4
Training loss: 3.294633003601155
Validation loss: 2.6038292811889843

Epoch: 5| Step: 5
Training loss: 3.026406577470344
Validation loss: 2.604678636657094

Epoch: 5| Step: 6
Training loss: 3.0423835710802645
Validation loss: 2.6124622261969708

Epoch: 5| Step: 7
Training loss: 2.913090848135318
Validation loss: 2.6169356314165797

Epoch: 5| Step: 8
Training loss: 3.0160496862351036
Validation loss: 2.6156415717518264

Epoch: 5| Step: 9
Training loss: 3.102826761625388
Validation loss: 2.604861993970384

Epoch: 5| Step: 10
Training loss: 3.1902939762037685
Validation loss: 2.6047055250939404

Epoch: 194| Step: 0
Training loss: 2.563117720419893
Validation loss: 2.6016644706032817

Epoch: 5| Step: 1
Training loss: 2.8620466248068634
Validation loss: 2.6007816495712013

Epoch: 5| Step: 2
Training loss: 3.1001848288780405
Validation loss: 2.601866274511463

Epoch: 5| Step: 3
Training loss: 3.2655141711251
Validation loss: 2.601175032216965

Epoch: 5| Step: 4
Training loss: 3.280442492713147
Validation loss: 2.599331177115236

Epoch: 5| Step: 5
Training loss: 2.8139260809163207
Validation loss: 2.600735482998602

Epoch: 5| Step: 6
Training loss: 3.0329157391624606
Validation loss: 2.606782377425092

Epoch: 5| Step: 7
Training loss: 2.7273811051480332
Validation loss: 2.602612222392275

Epoch: 5| Step: 8
Training loss: 3.099521686200556
Validation loss: 2.6051391643025696

Epoch: 5| Step: 9
Training loss: 2.573425263292951
Validation loss: 2.6037872477768076

Epoch: 5| Step: 10
Training loss: 2.9498434251516055
Validation loss: 2.5964488559613614

Epoch: 195| Step: 0
Training loss: 3.4535235006732106
Validation loss: 2.601640136411734

Epoch: 5| Step: 1
Training loss: 2.7644769042015027
Validation loss: 2.5992193115468116

Epoch: 5| Step: 2
Training loss: 3.0224839710350118
Validation loss: 2.5957418375444705

Epoch: 5| Step: 3
Training loss: 3.0829658976700163
Validation loss: 2.597202306451035

Epoch: 5| Step: 4
Training loss: 3.612926502855969
Validation loss: 2.596265820821623

Epoch: 5| Step: 5
Training loss: 2.2056247246586147
Validation loss: 2.594711291624512

Epoch: 5| Step: 6
Training loss: 2.801955568787708
Validation loss: 2.594792350925418

Epoch: 5| Step: 7
Training loss: 2.993095718275606
Validation loss: 2.5979548289242547

Epoch: 5| Step: 8
Training loss: 2.2466804600564827
Validation loss: 2.6003645622392377

Epoch: 5| Step: 9
Training loss: 3.451214153762678
Validation loss: 2.595056792956868

Epoch: 5| Step: 10
Training loss: 2.129469826671958
Validation loss: 2.601408827546637

Epoch: 196| Step: 0
Training loss: 3.5089374598976746
Validation loss: 2.600041521417645

Epoch: 5| Step: 1
Training loss: 3.2841860759490347
Validation loss: 2.5991457124126534

Epoch: 5| Step: 2
Training loss: 3.37793660445772
Validation loss: 2.601298345810438

Epoch: 5| Step: 3
Training loss: 3.0121040938831607
Validation loss: 2.6029858937356862

Epoch: 5| Step: 4
Training loss: 2.337430240997742
Validation loss: 2.60522467862669

Epoch: 5| Step: 5
Training loss: 2.7690553242786637
Validation loss: 2.604433610257727

Epoch: 5| Step: 6
Training loss: 2.4130896919866585
Validation loss: 2.6021652649242606

Epoch: 5| Step: 7
Training loss: 2.951904367546754
Validation loss: 2.6007566338668067

Epoch: 5| Step: 8
Training loss: 2.481572519860277
Validation loss: 2.5985694910187185

Epoch: 5| Step: 9
Training loss: 2.719934665792846
Validation loss: 2.60037625767645

Epoch: 5| Step: 10
Training loss: 3.19648404084686
Validation loss: 2.6071780808656886

Epoch: 197| Step: 0
Training loss: 2.4634290888564205
Validation loss: 2.603652742599376

Epoch: 5| Step: 1
Training loss: 2.6268205233435973
Validation loss: 2.6038069639457864

Epoch: 5| Step: 2
Training loss: 2.361990987852574
Validation loss: 2.605323756598184

Epoch: 5| Step: 3
Training loss: 2.87479963848366
Validation loss: 2.6064942145247008

Epoch: 5| Step: 4
Training loss: 3.385423599627316
Validation loss: 2.6114714744808545

Epoch: 5| Step: 5
Training loss: 2.9598143367275505
Validation loss: 2.6158660329501155

Epoch: 5| Step: 6
Training loss: 3.0124773586577844
Validation loss: 2.608465556806338

Epoch: 5| Step: 7
Training loss: 3.0306203915841623
Validation loss: 2.609615757670542

Epoch: 5| Step: 8
Training loss: 2.9334830556574873
Validation loss: 2.6020733209463973

Epoch: 5| Step: 9
Training loss: 3.513017017691397
Validation loss: 2.604774318229243

Epoch: 5| Step: 10
Training loss: 2.8905920078353704
Validation loss: 2.6019534856502147

Epoch: 198| Step: 0
Training loss: 3.8312494722898034
Validation loss: 2.5977154932476267

Epoch: 5| Step: 1
Training loss: 2.6563337425046205
Validation loss: 2.599690024689181

Epoch: 5| Step: 2
Training loss: 2.8452838491959143
Validation loss: 2.5979148931513936

Epoch: 5| Step: 3
Training loss: 2.3812476851484607
Validation loss: 2.595805190473745

Epoch: 5| Step: 4
Training loss: 3.089257108648842
Validation loss: 2.598719314341706

Epoch: 5| Step: 5
Training loss: 3.2068068766193427
Validation loss: 2.5975512796479685

Epoch: 5| Step: 6
Training loss: 3.1564553071279176
Validation loss: 2.593501637924464

Epoch: 5| Step: 7
Training loss: 2.603606924300569
Validation loss: 2.5921859339776243

Epoch: 5| Step: 8
Training loss: 2.751373381562693
Validation loss: 2.5947648874962774

Epoch: 5| Step: 9
Training loss: 2.844227845004995
Validation loss: 2.590307424822226

Epoch: 5| Step: 10
Training loss: 2.6361540917377613
Validation loss: 2.5922249912897306

Epoch: 199| Step: 0
Training loss: 3.3991381394321682
Validation loss: 2.593665864768176

Epoch: 5| Step: 1
Training loss: 2.593913429350965
Validation loss: 2.5916591608040154

Epoch: 5| Step: 2
Training loss: 3.0441383004470306
Validation loss: 2.5927915891631437

Epoch: 5| Step: 3
Training loss: 3.480576433256316
Validation loss: 2.594732483694557

Epoch: 5| Step: 4
Training loss: 3.624700073462437
Validation loss: 2.587240484867661

Epoch: 5| Step: 5
Training loss: 2.2680137932036724
Validation loss: 2.585998298493647

Epoch: 5| Step: 6
Training loss: 2.846324384183925
Validation loss: 2.590173130226636

Epoch: 5| Step: 7
Training loss: 2.853239888179238
Validation loss: 2.5856975353246128

Epoch: 5| Step: 8
Training loss: 2.8415743711217925
Validation loss: 2.586832233063912

Epoch: 5| Step: 9
Training loss: 2.5431877545863824
Validation loss: 2.587350357569092

Epoch: 5| Step: 10
Training loss: 2.383481891599302
Validation loss: 2.58924230287302

Epoch: 200| Step: 0
Training loss: 3.4959641757587385
Validation loss: 2.5877792084899562

Epoch: 5| Step: 1
Training loss: 2.6957222005193797
Validation loss: 2.5886548907371036

Epoch: 5| Step: 2
Training loss: 3.1452799598765413
Validation loss: 2.5908877481612627

Epoch: 5| Step: 3
Training loss: 2.5000568383431383
Validation loss: 2.5874614953074206

Epoch: 5| Step: 4
Training loss: 3.089134549664384
Validation loss: 2.5893051326566505

Epoch: 5| Step: 5
Training loss: 3.498720889009567
Validation loss: 2.5876846055015617

Epoch: 5| Step: 6
Training loss: 2.786443426264642
Validation loss: 2.5890902973619396

Epoch: 5| Step: 7
Training loss: 2.920847666256756
Validation loss: 2.592208604943604

Epoch: 5| Step: 8
Training loss: 2.770069495062679
Validation loss: 2.5866342335908765

Epoch: 5| Step: 9
Training loss: 2.581749235556275
Validation loss: 2.5893771368149117

Epoch: 5| Step: 10
Training loss: 2.4792720761583245
Validation loss: 2.5885746157488185

Epoch: 201| Step: 0
Training loss: 2.762091669482568
Validation loss: 2.59299752323202

Epoch: 5| Step: 1
Training loss: 3.063949553310951
Validation loss: 2.596058249001167

Epoch: 5| Step: 2
Training loss: 3.2242827039161672
Validation loss: 2.5975857040666686

Epoch: 5| Step: 3
Training loss: 3.074263731107551
Validation loss: 2.5991877429669987

Epoch: 5| Step: 4
Training loss: 2.085543934701582
Validation loss: 2.593418088734744

Epoch: 5| Step: 5
Training loss: 2.6755374546783526
Validation loss: 2.5955528105199734

Epoch: 5| Step: 6
Training loss: 2.913458631193982
Validation loss: 2.6001892653584116

Epoch: 5| Step: 7
Training loss: 3.179111887875273
Validation loss: 2.601765053783634

Epoch: 5| Step: 8
Training loss: 2.8211552848010144
Validation loss: 2.5939127899018315

Epoch: 5| Step: 9
Training loss: 2.7778795372019944
Validation loss: 2.6019060649006933

Epoch: 5| Step: 10
Training loss: 3.517940318318654
Validation loss: 2.5944155795231105

Epoch: 202| Step: 0
Training loss: 2.5701312433121233
Validation loss: 2.589332879731707

Epoch: 5| Step: 1
Training loss: 2.900535626110281
Validation loss: 2.5860376529787676

Epoch: 5| Step: 2
Training loss: 2.8905484576014615
Validation loss: 2.5861052921627796

Epoch: 5| Step: 3
Training loss: 3.07357312103465
Validation loss: 2.5841512394188997

Epoch: 5| Step: 4
Training loss: 2.932268882288026
Validation loss: 2.5891303573670057

Epoch: 5| Step: 5
Training loss: 2.842550506814094
Validation loss: 2.5835515630389336

Epoch: 5| Step: 6
Training loss: 2.6460800256139505
Validation loss: 2.585868287034666

Epoch: 5| Step: 7
Training loss: 3.00203349813112
Validation loss: 2.5828405605590636

Epoch: 5| Step: 8
Training loss: 3.262931625636538
Validation loss: 2.583174034378084

Epoch: 5| Step: 9
Training loss: 2.9218234297337364
Validation loss: 2.578530529715175

Epoch: 5| Step: 10
Training loss: 3.157518188714128
Validation loss: 2.5814527397464557

Epoch: 203| Step: 0
Training loss: 2.687141838160452
Validation loss: 2.58288464402486

Epoch: 5| Step: 1
Training loss: 2.9721015081719417
Validation loss: 2.5795968297782204

Epoch: 5| Step: 2
Training loss: 3.1116075025129413
Validation loss: 2.58164669481506

Epoch: 5| Step: 3
Training loss: 2.941571761663501
Validation loss: 2.5775037348207674

Epoch: 5| Step: 4
Training loss: 2.444493750835943
Validation loss: 2.5774889477404845

Epoch: 5| Step: 5
Training loss: 2.4643415855408173
Validation loss: 2.579854509022997

Epoch: 5| Step: 6
Training loss: 3.5581262074087707
Validation loss: 2.5783461052383068

Epoch: 5| Step: 7
Training loss: 2.7053347689626515
Validation loss: 2.580311635150542

Epoch: 5| Step: 8
Training loss: 3.1202502967009713
Validation loss: 2.5828719056142906

Epoch: 5| Step: 9
Training loss: 2.892237363083553
Validation loss: 2.5800408556915535

Epoch: 5| Step: 10
Training loss: 3.182440838020402
Validation loss: 2.578986008782667

Epoch: 204| Step: 0
Training loss: 1.828251043685851
Validation loss: 2.5828102990188166

Epoch: 5| Step: 1
Training loss: 2.7576618963945996
Validation loss: 2.5868550327088964

Epoch: 5| Step: 2
Training loss: 2.7549749803185866
Validation loss: 2.58394186696955

Epoch: 5| Step: 3
Training loss: 3.297894794699233
Validation loss: 2.58159230723629

Epoch: 5| Step: 4
Training loss: 2.589677854261989
Validation loss: 2.586726592548703

Epoch: 5| Step: 5
Training loss: 3.3549733268029973
Validation loss: 2.5864941462236906

Epoch: 5| Step: 6
Training loss: 2.8027101309654827
Validation loss: 2.585017407747981

Epoch: 5| Step: 7
Training loss: 3.397355672593182
Validation loss: 2.5841444477471947

Epoch: 5| Step: 8
Training loss: 2.5831026056270994
Validation loss: 2.5866715862978826

Epoch: 5| Step: 9
Training loss: 3.0346388602913095
Validation loss: 2.583112378417978

Epoch: 5| Step: 10
Training loss: 3.4512920779682337
Validation loss: 2.5867840356219096

Epoch: 205| Step: 0
Training loss: 2.578977409243143
Validation loss: 2.593633099306222

Epoch: 5| Step: 1
Training loss: 3.309077816336127
Validation loss: 2.589621604932497

Epoch: 5| Step: 2
Training loss: 3.269792735446068
Validation loss: 2.589507839354541

Epoch: 5| Step: 3
Training loss: 2.6889443175940513
Validation loss: 2.5897279786909775

Epoch: 5| Step: 4
Training loss: 2.619936464427471
Validation loss: 2.593356056507138

Epoch: 5| Step: 5
Training loss: 2.721197320290653
Validation loss: 2.587948998171924

Epoch: 5| Step: 6
Training loss: 3.0291393049666837
Validation loss: 2.590498096380961

Epoch: 5| Step: 7
Training loss: 3.135357591108404
Validation loss: 2.5934121002853816

Epoch: 5| Step: 8
Training loss: 3.029356217433343
Validation loss: 2.5992134572866266

Epoch: 5| Step: 9
Training loss: 2.673100240760859
Validation loss: 2.608049196009852

Epoch: 5| Step: 10
Training loss: 2.997126474659109
Validation loss: 2.5981644091375604

Epoch: 206| Step: 0
Training loss: 2.9710458009849483
Validation loss: 2.6080810834427806

Epoch: 5| Step: 1
Training loss: 2.764404544831996
Validation loss: 2.616732099519788

Epoch: 5| Step: 2
Training loss: 3.1932829214854093
Validation loss: 2.606598006447481

Epoch: 5| Step: 3
Training loss: 2.8570567254298993
Validation loss: 2.600081199722172

Epoch: 5| Step: 4
Training loss: 2.93927110887874
Validation loss: 2.6021925034575992

Epoch: 5| Step: 5
Training loss: 2.9031981164370597
Validation loss: 2.59484351964533

Epoch: 5| Step: 6
Training loss: 2.511377575426479
Validation loss: 2.6027586088953827

Epoch: 5| Step: 7
Training loss: 2.871604905072242
Validation loss: 2.598959095664388

Epoch: 5| Step: 8
Training loss: 3.5195976361143333
Validation loss: 2.5953882220325695

Epoch: 5| Step: 9
Training loss: 2.8533002183305727
Validation loss: 2.590307282304678

Epoch: 5| Step: 10
Training loss: 2.4790673329517685
Validation loss: 2.5781530593135673

Epoch: 207| Step: 0
Training loss: 2.9765235718111427
Validation loss: 2.5744667377566777

Epoch: 5| Step: 1
Training loss: 2.3725494993812375
Validation loss: 2.578540391418399

Epoch: 5| Step: 2
Training loss: 3.5856581103289087
Validation loss: 2.5803105939213

Epoch: 5| Step: 3
Training loss: 2.9408833924296713
Validation loss: 2.5776638857888017

Epoch: 5| Step: 4
Training loss: 2.751669117098325
Validation loss: 2.5744667626515483

Epoch: 5| Step: 5
Training loss: 2.9683492289622135
Validation loss: 2.571611894030065

Epoch: 5| Step: 6
Training loss: 2.673969540921124
Validation loss: 2.5716492256810484

Epoch: 5| Step: 7
Training loss: 3.3099361070073097
Validation loss: 2.5775055519936108

Epoch: 5| Step: 8
Training loss: 2.2266374541934284
Validation loss: 2.580734978254946

Epoch: 5| Step: 9
Training loss: 3.0746587610476723
Validation loss: 2.592609171925043

Epoch: 5| Step: 10
Training loss: 3.041029266738429
Validation loss: 2.60953947947298

Epoch: 208| Step: 0
Training loss: 2.8909242217386053
Validation loss: 2.6084663175055

Epoch: 5| Step: 1
Training loss: 3.2728026145393114
Validation loss: 2.580402169817543

Epoch: 5| Step: 2
Training loss: 2.9647308448734337
Validation loss: 2.5755996342831513

Epoch: 5| Step: 3
Training loss: 3.334418851211914
Validation loss: 2.5760921554348473

Epoch: 5| Step: 4
Training loss: 3.0266118696968793
Validation loss: 2.568124424692673

Epoch: 5| Step: 5
Training loss: 2.471525346450441
Validation loss: 2.573464372725959

Epoch: 5| Step: 6
Training loss: 2.6391883869760915
Validation loss: 2.5738599742783266

Epoch: 5| Step: 7
Training loss: 2.7910304032422344
Validation loss: 2.5720892742405175

Epoch: 5| Step: 8
Training loss: 2.8534312356510987
Validation loss: 2.5667994796319706

Epoch: 5| Step: 9
Training loss: 2.6756559690676096
Validation loss: 2.5735553275782244

Epoch: 5| Step: 10
Training loss: 3.167633979691605
Validation loss: 2.5773474392377147

Epoch: 209| Step: 0
Training loss: 2.8920891430255145
Validation loss: 2.5741186650177865

Epoch: 5| Step: 1
Training loss: 2.772228740496756
Validation loss: 2.5780833151770173

Epoch: 5| Step: 2
Training loss: 3.334909606806651
Validation loss: 2.5900070695000217

Epoch: 5| Step: 3
Training loss: 3.236479143890832
Validation loss: 2.590636488805407

Epoch: 5| Step: 4
Training loss: 2.925809119057439
Validation loss: 2.5966133880799247

Epoch: 5| Step: 5
Training loss: 2.677150047648527
Validation loss: 2.6106893142308536

Epoch: 5| Step: 6
Training loss: 3.072416792907632
Validation loss: 2.6155726861041497

Epoch: 5| Step: 7
Training loss: 2.288106777407229
Validation loss: 2.6089301277504404

Epoch: 5| Step: 8
Training loss: 3.018272542216677
Validation loss: 2.604977584754081

Epoch: 5| Step: 9
Training loss: 2.8310514873106265
Validation loss: 2.5838952209308195

Epoch: 5| Step: 10
Training loss: 2.894355964243843
Validation loss: 2.576142785028598

Epoch: 210| Step: 0
Training loss: 2.6593714605323555
Validation loss: 2.57207720299365

Epoch: 5| Step: 1
Training loss: 3.1621556693935906
Validation loss: 2.5761551218357988

Epoch: 5| Step: 2
Training loss: 3.174151726291381
Validation loss: 2.577204967023143

Epoch: 5| Step: 3
Training loss: 2.3896641015590516
Validation loss: 2.5800784111651573

Epoch: 5| Step: 4
Training loss: 3.262358715754414
Validation loss: 2.584379894846498

Epoch: 5| Step: 5
Training loss: 2.2582979835286725
Validation loss: 2.577921553384495

Epoch: 5| Step: 6
Training loss: 3.0499483698242744
Validation loss: 2.578905926884026

Epoch: 5| Step: 7
Training loss: 3.265171001214989
Validation loss: 2.581496181545966

Epoch: 5| Step: 8
Training loss: 2.922155356599061
Validation loss: 2.5860150681892824

Epoch: 5| Step: 9
Training loss: 2.879960466219511
Validation loss: 2.5885593472052726

Epoch: 5| Step: 10
Training loss: 3.083665383132449
Validation loss: 2.5925631703196452

Epoch: 211| Step: 0
Training loss: 3.1421432241604927
Validation loss: 2.594190903773394

Epoch: 5| Step: 1
Training loss: 3.0892805702676953
Validation loss: 2.588520997677711

Epoch: 5| Step: 2
Training loss: 3.429026894175519
Validation loss: 2.582164859056153

Epoch: 5| Step: 3
Training loss: 3.180183240781306
Validation loss: 2.5862784103187315

Epoch: 5| Step: 4
Training loss: 2.1925110233599585
Validation loss: 2.583439800623565

Epoch: 5| Step: 5
Training loss: 3.1467095643152896
Validation loss: 2.578913708536086

Epoch: 5| Step: 6
Training loss: 2.806029102492639
Validation loss: 2.5802709667886896

Epoch: 5| Step: 7
Training loss: 2.93309664927351
Validation loss: 2.578930786734608

Epoch: 5| Step: 8
Training loss: 2.6310004725352507
Validation loss: 2.5856087937978045

Epoch: 5| Step: 9
Training loss: 2.4106585259018787
Validation loss: 2.5810146878934375

Epoch: 5| Step: 10
Training loss: 2.786733985647481
Validation loss: 2.5931757975696015

Epoch: 212| Step: 0
Training loss: 3.127013663969328
Validation loss: 2.5947609443653987

Epoch: 5| Step: 1
Training loss: 2.737665605108313
Validation loss: 2.5794828377345995

Epoch: 5| Step: 2
Training loss: 3.3556139806863854
Validation loss: 2.575462269389622

Epoch: 5| Step: 3
Training loss: 2.435005280725914
Validation loss: 2.5779279577008576

Epoch: 5| Step: 4
Training loss: 2.541338935943277
Validation loss: 2.5724061982081903

Epoch: 5| Step: 5
Training loss: 3.20407953693664
Validation loss: 2.5729326820016247

Epoch: 5| Step: 6
Training loss: 2.718754472400012
Validation loss: 2.5772460562888093

Epoch: 5| Step: 7
Training loss: 3.3816096257387063
Validation loss: 2.604757606809946

Epoch: 5| Step: 8
Training loss: 2.5953481874992166
Validation loss: 2.589768082287236

Epoch: 5| Step: 9
Training loss: 2.6529257224361613
Validation loss: 2.5960429276955503

Epoch: 5| Step: 10
Training loss: 3.119358157871205
Validation loss: 2.5921398244771425

Epoch: 213| Step: 0
Training loss: 2.7390303736628954
Validation loss: 2.580953687573057

Epoch: 5| Step: 1
Training loss: 3.006714300834188
Validation loss: 2.565509124833452

Epoch: 5| Step: 2
Training loss: 3.168113394750041
Validation loss: 2.569643345142304

Epoch: 5| Step: 3
Training loss: 2.5602155597651106
Validation loss: 2.569623740970097

Epoch: 5| Step: 4
Training loss: 3.071920890892196
Validation loss: 2.5650858883695538

Epoch: 5| Step: 5
Training loss: 3.117981314866784
Validation loss: 2.5678988223429835

Epoch: 5| Step: 6
Training loss: 2.7765687271589305
Validation loss: 2.567822115604698

Epoch: 5| Step: 7
Training loss: 2.940385091564426
Validation loss: 2.5733013751424636

Epoch: 5| Step: 8
Training loss: 2.676539760477416
Validation loss: 2.5755931126970766

Epoch: 5| Step: 9
Training loss: 2.021928025365468
Validation loss: 2.5834011289954173

Epoch: 5| Step: 10
Training loss: 3.6830722929223882
Validation loss: 2.5915354904384684

Epoch: 214| Step: 0
Training loss: 2.7338480414386566
Validation loss: 2.5816732998133856

Epoch: 5| Step: 1
Training loss: 2.534318547496172
Validation loss: 2.5769446531387374

Epoch: 5| Step: 2
Training loss: 2.9784519076176488
Validation loss: 2.5714901307432116

Epoch: 5| Step: 3
Training loss: 2.65324105771631
Validation loss: 2.5758654475237455

Epoch: 5| Step: 4
Training loss: 2.7664678980958857
Validation loss: 2.5734638148635978

Epoch: 5| Step: 5
Training loss: 3.2770307752917844
Validation loss: 2.5726327176886206

Epoch: 5| Step: 6
Training loss: 3.428156691398637
Validation loss: 2.573651363866124

Epoch: 5| Step: 7
Training loss: 2.444351836338376
Validation loss: 2.574766757236777

Epoch: 5| Step: 8
Training loss: 2.8043671746481666
Validation loss: 2.5692012411984524

Epoch: 5| Step: 9
Training loss: 3.20648820672602
Validation loss: 2.577459227113533

Epoch: 5| Step: 10
Training loss: 2.9655587159799763
Validation loss: 2.581193628946779

Epoch: 215| Step: 0
Training loss: 2.493366787561929
Validation loss: 2.5938565454345643

Epoch: 5| Step: 1
Training loss: 2.987464942886049
Validation loss: 2.6139453821665763

Epoch: 5| Step: 2
Training loss: 3.109713281987102
Validation loss: 2.598510806901029

Epoch: 5| Step: 3
Training loss: 3.0002690830353327
Validation loss: 2.60089728961573

Epoch: 5| Step: 4
Training loss: 2.906606508764052
Validation loss: 2.6058561017428103

Epoch: 5| Step: 5
Training loss: 2.838755822925315
Validation loss: 2.609130221076141

Epoch: 5| Step: 6
Training loss: 2.3657924456778985
Validation loss: 2.5978653993741996

Epoch: 5| Step: 7
Training loss: 3.125205834285613
Validation loss: 2.5734330146965094

Epoch: 5| Step: 8
Training loss: 2.769548639369332
Validation loss: 2.5688189229493004

Epoch: 5| Step: 9
Training loss: 2.9309544786440798
Validation loss: 2.5671940411018683

Epoch: 5| Step: 10
Training loss: 3.3137075274554104
Validation loss: 2.5632085023296547

Epoch: 216| Step: 0
Training loss: 3.222052204279827
Validation loss: 2.563761576897592

Epoch: 5| Step: 1
Training loss: 2.2075883820446633
Validation loss: 2.566629087921207

Epoch: 5| Step: 2
Training loss: 3.2637938699801823
Validation loss: 2.5666153369139657

Epoch: 5| Step: 3
Training loss: 2.890363361786746
Validation loss: 2.575809202114985

Epoch: 5| Step: 4
Training loss: 3.086922867305934
Validation loss: 2.5678456790627324

Epoch: 5| Step: 5
Training loss: 2.799486613892105
Validation loss: 2.57642697337089

Epoch: 5| Step: 6
Training loss: 2.823153684080622
Validation loss: 2.5736888616671916

Epoch: 5| Step: 7
Training loss: 2.3017481794386354
Validation loss: 2.595590473415935

Epoch: 5| Step: 8
Training loss: 3.1304856027864
Validation loss: 2.6162126239175776

Epoch: 5| Step: 9
Training loss: 3.2617072008122627
Validation loss: 2.5999287284725

Epoch: 5| Step: 10
Training loss: 2.6820389020517843
Validation loss: 2.5653545358435204

Epoch: 217| Step: 0
Training loss: 2.7716942694920657
Validation loss: 2.5642694226386573

Epoch: 5| Step: 1
Training loss: 2.8675177693169807
Validation loss: 2.568178802010434

Epoch: 5| Step: 2
Training loss: 2.896015810991827
Validation loss: 2.5747738355075276

Epoch: 5| Step: 3
Training loss: 2.220913544065785
Validation loss: 2.5759346734826316

Epoch: 5| Step: 4
Training loss: 2.7964102929068964
Validation loss: 2.57524240879798

Epoch: 5| Step: 5
Training loss: 2.827849822593241
Validation loss: 2.5723849846534987

Epoch: 5| Step: 6
Training loss: 3.368160664774308
Validation loss: 2.5732820748005905

Epoch: 5| Step: 7
Training loss: 2.8888701189686636
Validation loss: 2.570009367978286

Epoch: 5| Step: 8
Training loss: 3.050536474355301
Validation loss: 2.564460335704585

Epoch: 5| Step: 9
Training loss: 3.398679106444017
Validation loss: 2.5677790045593927

Epoch: 5| Step: 10
Training loss: 2.779416026110073
Validation loss: 2.5995767455938816

Epoch: 218| Step: 0
Training loss: 3.20833376269317
Validation loss: 2.623111830977684

Epoch: 5| Step: 1
Training loss: 2.873333987289791
Validation loss: 2.6389065256340776

Epoch: 5| Step: 2
Training loss: 2.2076544767873876
Validation loss: 2.6299112632014956

Epoch: 5| Step: 3
Training loss: 2.732952598090912
Validation loss: 2.611750946038374

Epoch: 5| Step: 4
Training loss: 2.760858080617074
Validation loss: 2.5999035507373454

Epoch: 5| Step: 5
Training loss: 2.736943722297899
Validation loss: 2.5791663032409686

Epoch: 5| Step: 6
Training loss: 3.1800956745270272
Validation loss: 2.5662688415515613

Epoch: 5| Step: 7
Training loss: 3.400364682330317
Validation loss: 2.56477536462111

Epoch: 5| Step: 8
Training loss: 3.1011409136688166
Validation loss: 2.5652383418908324

Epoch: 5| Step: 9
Training loss: 2.8746088839982935
Validation loss: 2.5618583151889105

Epoch: 5| Step: 10
Training loss: 2.6699698275743624
Validation loss: 2.5656203463578886

Epoch: 219| Step: 0
Training loss: 2.9693246385675147
Validation loss: 2.569632874637385

Epoch: 5| Step: 1
Training loss: 3.004371636779439
Validation loss: 2.557923717387201

Epoch: 5| Step: 2
Training loss: 2.5196771623810283
Validation loss: 2.5606737509723128

Epoch: 5| Step: 3
Training loss: 3.329410501716547
Validation loss: 2.565034387885669

Epoch: 5| Step: 4
Training loss: 2.8456141471697727
Validation loss: 2.574328045693434

Epoch: 5| Step: 5
Training loss: 2.4752163763541417
Validation loss: 2.5748149615782188

Epoch: 5| Step: 6
Training loss: 2.940694330190699
Validation loss: 2.5853306055344234

Epoch: 5| Step: 7
Training loss: 3.4588838774838164
Validation loss: 2.5978800704721388

Epoch: 5| Step: 8
Training loss: 2.4931931335212676
Validation loss: 2.591933987439517

Epoch: 5| Step: 9
Training loss: 2.606998297757733
Validation loss: 2.5740573867400296

Epoch: 5| Step: 10
Training loss: 2.968475810991542
Validation loss: 2.558947684337337

Epoch: 220| Step: 0
Training loss: 2.9802420393686506
Validation loss: 2.563298194879428

Epoch: 5| Step: 1
Training loss: 2.159338025274751
Validation loss: 2.566242235689433

Epoch: 5| Step: 2
Training loss: 3.214386435853129
Validation loss: 2.5671467132650725

Epoch: 5| Step: 3
Training loss: 2.7990309434811
Validation loss: 2.5692529445311543

Epoch: 5| Step: 4
Training loss: 3.3651915828133894
Validation loss: 2.5594369092230864

Epoch: 5| Step: 5
Training loss: 2.4391730020186873
Validation loss: 2.5649085042330864

Epoch: 5| Step: 6
Training loss: 2.896935580215827
Validation loss: 2.5661762228298346

Epoch: 5| Step: 7
Training loss: 3.3904368264855855
Validation loss: 2.571138073517806

Epoch: 5| Step: 8
Training loss: 2.646042542684322
Validation loss: 2.5843696903779767

Epoch: 5| Step: 9
Training loss: 3.205053279392197
Validation loss: 2.60731601270514

Epoch: 5| Step: 10
Training loss: 2.2943924962901336
Validation loss: 2.625263090568579

Epoch: 221| Step: 0
Training loss: 2.9632589856816676
Validation loss: 2.6285701387461846

Epoch: 5| Step: 1
Training loss: 3.477436632995492
Validation loss: 2.5938702409778145

Epoch: 5| Step: 2
Training loss: 2.607801316901857
Validation loss: 2.5782455540447913

Epoch: 5| Step: 3
Training loss: 3.0438433309733175
Validation loss: 2.5656327077822687

Epoch: 5| Step: 4
Training loss: 3.020848311463855
Validation loss: 2.5663094306189413

Epoch: 5| Step: 5
Training loss: 2.263913474960325
Validation loss: 2.5697067888052905

Epoch: 5| Step: 6
Training loss: 2.4886383327414583
Validation loss: 2.575395793067874

Epoch: 5| Step: 7
Training loss: 3.309728506657421
Validation loss: 2.56020294387899

Epoch: 5| Step: 8
Training loss: 2.3769985624059453
Validation loss: 2.562762036195549

Epoch: 5| Step: 9
Training loss: 2.7513546641510174
Validation loss: 2.5610552781212923

Epoch: 5| Step: 10
Training loss: 3.1426369973898165
Validation loss: 2.564855581860014

Epoch: 222| Step: 0
Training loss: 2.44501549620291
Validation loss: 2.5759699361366906

Epoch: 5| Step: 1
Training loss: 2.3056359360048524
Validation loss: 2.598363227007933

Epoch: 5| Step: 2
Training loss: 3.573297967759482
Validation loss: 2.6238267291309274

Epoch: 5| Step: 3
Training loss: 2.991580911609781
Validation loss: 2.6512527818535596

Epoch: 5| Step: 4
Training loss: 2.7398939838922143
Validation loss: 2.6289242789523626

Epoch: 5| Step: 5
Training loss: 2.8469987693706247
Validation loss: 2.6171115473019215

Epoch: 5| Step: 6
Training loss: 3.360396686706617
Validation loss: 2.6197317633533017

Epoch: 5| Step: 7
Training loss: 2.6766148514758092
Validation loss: 2.6019428426840996

Epoch: 5| Step: 8
Training loss: 2.8429614640132317
Validation loss: 2.5984176216955794

Epoch: 5| Step: 9
Training loss: 2.585069493405561
Validation loss: 2.579572979114687

Epoch: 5| Step: 10
Training loss: 3.1829190715313467
Validation loss: 2.5630050689669033

Epoch: 223| Step: 0
Training loss: 2.7156873970194138
Validation loss: 2.565608499478988

Epoch: 5| Step: 1
Training loss: 2.6443464251213844
Validation loss: 2.5569483738353136

Epoch: 5| Step: 2
Training loss: 2.7536524878928295
Validation loss: 2.5576250399378107

Epoch: 5| Step: 3
Training loss: 3.005617286892753
Validation loss: 2.5597343997720814

Epoch: 5| Step: 4
Training loss: 3.161173389210923
Validation loss: 2.5503322605226106

Epoch: 5| Step: 5
Training loss: 2.9098229543830483
Validation loss: 2.554347134730138

Epoch: 5| Step: 6
Training loss: 2.9513072721877274
Validation loss: 2.561041635326628

Epoch: 5| Step: 7
Training loss: 3.000616169276688
Validation loss: 2.5909789071762037

Epoch: 5| Step: 8
Training loss: 2.6885752633818707
Validation loss: 2.6651455350328694

Epoch: 5| Step: 9
Training loss: 3.051396228579078
Validation loss: 2.6773299364635808

Epoch: 5| Step: 10
Training loss: 2.757156769599516
Validation loss: 2.634040843693517

Epoch: 224| Step: 0
Training loss: 2.4000539892799786
Validation loss: 2.6225796433975512

Epoch: 5| Step: 1
Training loss: 2.4244833405674218
Validation loss: 2.6157050738868084

Epoch: 5| Step: 2
Training loss: 2.521494208685317
Validation loss: 2.6146893439139722

Epoch: 5| Step: 3
Training loss: 3.2677952613897534
Validation loss: 2.5751800313287734

Epoch: 5| Step: 4
Training loss: 2.772841182591775
Validation loss: 2.579258566823106

Epoch: 5| Step: 5
Training loss: 3.155899179431641
Validation loss: 2.5602560895934032

Epoch: 5| Step: 6
Training loss: 3.322026355700868
Validation loss: 2.5645747975512205

Epoch: 5| Step: 7
Training loss: 2.291724418143643
Validation loss: 2.5548657884464756

Epoch: 5| Step: 8
Training loss: 3.0662782678805685
Validation loss: 2.554617755478873

Epoch: 5| Step: 9
Training loss: 3.0055071827052697
Validation loss: 2.550289455958144

Epoch: 5| Step: 10
Training loss: 3.1505123145669947
Validation loss: 2.5627138392246454

Epoch: 225| Step: 0
Training loss: 2.661560494589109
Validation loss: 2.5501043673540567

Epoch: 5| Step: 1
Training loss: 2.9585054016218697
Validation loss: 2.578961916878159

Epoch: 5| Step: 2
Training loss: 2.0581457240465584
Validation loss: 2.583342779091335

Epoch: 5| Step: 3
Training loss: 3.4835536655909647
Validation loss: 2.60051272750326

Epoch: 5| Step: 4
Training loss: 3.1789861931994507
Validation loss: 2.607033938730776

Epoch: 5| Step: 5
Training loss: 2.4881168233300635
Validation loss: 2.571662198123446

Epoch: 5| Step: 6
Training loss: 2.7543534585358396
Validation loss: 2.559355089754074

Epoch: 5| Step: 7
Training loss: 2.9067803996113883
Validation loss: 2.561277498592993

Epoch: 5| Step: 8
Training loss: 2.875476631792606
Validation loss: 2.558243951508396

Epoch: 5| Step: 9
Training loss: 2.8284465122300593
Validation loss: 2.5620562921841095

Epoch: 5| Step: 10
Training loss: 3.325165054698971
Validation loss: 2.558664689673176

Epoch: 226| Step: 0
Training loss: 2.6638163791299863
Validation loss: 2.5451087657955935

Epoch: 5| Step: 1
Training loss: 2.8684376997489953
Validation loss: 2.55610798128518

Epoch: 5| Step: 2
Training loss: 3.2865990045893603
Validation loss: 2.5674868095848256

Epoch: 5| Step: 3
Training loss: 2.6440919767647637
Validation loss: 2.5902276622652765

Epoch: 5| Step: 4
Training loss: 2.82555546658762
Validation loss: 2.626249315885001

Epoch: 5| Step: 5
Training loss: 2.635629838808325
Validation loss: 2.7124974053014483

Epoch: 5| Step: 6
Training loss: 3.239960790561738
Validation loss: 2.7225737706421125

Epoch: 5| Step: 7
Training loss: 2.6533313648497727
Validation loss: 2.7111587862012945

Epoch: 5| Step: 8
Training loss: 2.999176230182612
Validation loss: 2.6756716508233387

Epoch: 5| Step: 9
Training loss: 2.87739347259042
Validation loss: 2.599565835504032

Epoch: 5| Step: 10
Training loss: 2.631376786246837
Validation loss: 2.5697756678964785

Epoch: 227| Step: 0
Training loss: 2.991561465596421
Validation loss: 2.5472576126493522

Epoch: 5| Step: 1
Training loss: 2.711309841651094
Validation loss: 2.5541915299219307

Epoch: 5| Step: 2
Training loss: 3.327138835242601
Validation loss: 2.5653107977111733

Epoch: 5| Step: 3
Training loss: 2.997406315170684
Validation loss: 2.571393391120637

Epoch: 5| Step: 4
Training loss: 2.8602608731142105
Validation loss: 2.5600755819304144

Epoch: 5| Step: 5
Training loss: 2.5293283585757713
Validation loss: 2.556131324768229

Epoch: 5| Step: 6
Training loss: 2.8502413262706296
Validation loss: 2.553488325596594

Epoch: 5| Step: 7
Training loss: 2.777362292264053
Validation loss: 2.5519986233811203

Epoch: 5| Step: 8
Training loss: 2.6995631217720018
Validation loss: 2.556848827040438

Epoch: 5| Step: 9
Training loss: 2.6380339782527935
Validation loss: 2.561115073726078

Epoch: 5| Step: 10
Training loss: 3.382194339223991
Validation loss: 2.577857410891772

Epoch: 228| Step: 0
Training loss: 3.164019096924531
Validation loss: 2.592419673212278

Epoch: 5| Step: 1
Training loss: 1.6479580439578507
Validation loss: 2.6429780942779395

Epoch: 5| Step: 2
Training loss: 2.8428643492849
Validation loss: 2.6637472514039424

Epoch: 5| Step: 3
Training loss: 2.784133445117559
Validation loss: 2.685677167996464

Epoch: 5| Step: 4
Training loss: 3.000382716880283
Validation loss: 2.727593885946483

Epoch: 5| Step: 5
Training loss: 2.7319283138493438
Validation loss: 2.6692288559264847

Epoch: 5| Step: 6
Training loss: 2.543066441875912
Validation loss: 2.6023610453942267

Epoch: 5| Step: 7
Training loss: 3.1366360512136944
Validation loss: 2.5854519698452862

Epoch: 5| Step: 8
Training loss: 3.374591237498645
Validation loss: 2.5538684106009746

Epoch: 5| Step: 9
Training loss: 3.35926002483117
Validation loss: 2.539093362701116

Epoch: 5| Step: 10
Training loss: 2.690708906081601
Validation loss: 2.5511041714567684

Epoch: 229| Step: 0
Training loss: 3.010793184980026
Validation loss: 2.5494418355120927

Epoch: 5| Step: 1
Training loss: 3.0349999268483088
Validation loss: 2.5490959353986686

Epoch: 5| Step: 2
Training loss: 2.6700342987657844
Validation loss: 2.5498565890870695

Epoch: 5| Step: 3
Training loss: 3.0313486299494468
Validation loss: 2.54909051363279

Epoch: 5| Step: 4
Training loss: 3.439924876035957
Validation loss: 2.548452370382571

Epoch: 5| Step: 5
Training loss: 3.0933003725016817
Validation loss: 2.546217633690965

Epoch: 5| Step: 6
Training loss: 2.6268575544592587
Validation loss: 2.5419554469845322

Epoch: 5| Step: 7
Training loss: 2.5950304111176123
Validation loss: 2.5454889196397628

Epoch: 5| Step: 8
Training loss: 2.4812219152134296
Validation loss: 2.5374091094464712

Epoch: 5| Step: 9
Training loss: 2.730694806478591
Validation loss: 2.5535805381102743

Epoch: 5| Step: 10
Training loss: 3.058432076615884
Validation loss: 2.5643171994751848

Epoch: 230| Step: 0
Training loss: 3.272527090125157
Validation loss: 2.589572301123107

Epoch: 5| Step: 1
Training loss: 2.496534425045449
Validation loss: 2.610670314842748

Epoch: 5| Step: 2
Training loss: 2.735786988950999
Validation loss: 2.6588563296653844

Epoch: 5| Step: 3
Training loss: 3.267684506122826
Validation loss: 2.6667220275910792

Epoch: 5| Step: 4
Training loss: 2.694671289217591
Validation loss: 2.6189025147658884

Epoch: 5| Step: 5
Training loss: 2.483665316961455
Validation loss: 2.5668779237752117

Epoch: 5| Step: 6
Training loss: 3.1072662717365693
Validation loss: 2.553403366240051

Epoch: 5| Step: 7
Training loss: 3.1402010655264725
Validation loss: 2.540765387353809

Epoch: 5| Step: 8
Training loss: 2.2339530493055277
Validation loss: 2.548213082556619

Epoch: 5| Step: 9
Training loss: 3.2781168193005943
Validation loss: 2.5469749627853244

Epoch: 5| Step: 10
Training loss: 2.676706418668193
Validation loss: 2.5470910820215473

Epoch: 231| Step: 0
Training loss: 2.325265446758323
Validation loss: 2.544363987810678

Epoch: 5| Step: 1
Training loss: 2.867528245515738
Validation loss: 2.5451045629106215

Epoch: 5| Step: 2
Training loss: 2.8812033030931508
Validation loss: 2.5419208712842574

Epoch: 5| Step: 3
Training loss: 3.189486015790299
Validation loss: 2.5372215292372178

Epoch: 5| Step: 4
Training loss: 2.638816710929468
Validation loss: 2.5450772145257825

Epoch: 5| Step: 5
Training loss: 3.087480608303934
Validation loss: 2.5577640162794997

Epoch: 5| Step: 6
Training loss: 2.97407551994973
Validation loss: 2.585268942499877

Epoch: 5| Step: 7
Training loss: 3.173006804787462
Validation loss: 2.5975405327800063

Epoch: 5| Step: 8
Training loss: 2.79513845397651
Validation loss: 2.6170866347914

Epoch: 5| Step: 9
Training loss: 2.712903807507119
Validation loss: 2.593037981119428

Epoch: 5| Step: 10
Training loss: 2.7265116951917396
Validation loss: 2.5797253963513005

Epoch: 232| Step: 0
Training loss: 2.176541372006325
Validation loss: 2.564903752078897

Epoch: 5| Step: 1
Training loss: 2.5396638598256542
Validation loss: 2.563043103114025

Epoch: 5| Step: 2
Training loss: 3.0910851917997775
Validation loss: 2.5679060722906266

Epoch: 5| Step: 3
Training loss: 2.7112995532560715
Validation loss: 2.5744136792704526

Epoch: 5| Step: 4
Training loss: 3.5251451232472135
Validation loss: 2.5721128524286914

Epoch: 5| Step: 5
Training loss: 2.796333729458551
Validation loss: 2.5663862215281585

Epoch: 5| Step: 6
Training loss: 3.088943909841908
Validation loss: 2.5741375771509665

Epoch: 5| Step: 7
Training loss: 2.6964541463802965
Validation loss: 2.5776905199601177

Epoch: 5| Step: 8
Training loss: 2.881280590234253
Validation loss: 2.604020805621936

Epoch: 5| Step: 9
Training loss: 2.6728025912062487
Validation loss: 2.6215720640025366

Epoch: 5| Step: 10
Training loss: 2.8420280860624465
Validation loss: 2.581608977450359

Epoch: 233| Step: 0
Training loss: 3.2674993219353015
Validation loss: 2.559206922786996

Epoch: 5| Step: 1
Training loss: 3.1312964521605866
Validation loss: 2.5463199006775716

Epoch: 5| Step: 2
Training loss: 2.407195264755972
Validation loss: 2.5413201464200363

Epoch: 5| Step: 3
Training loss: 3.1191904616987625
Validation loss: 2.5368674387724135

Epoch: 5| Step: 4
Training loss: 3.1240368694029783
Validation loss: 2.5403477366553373

Epoch: 5| Step: 5
Training loss: 2.2838320816230735
Validation loss: 2.54924472523335

Epoch: 5| Step: 6
Training loss: 2.903871773224429
Validation loss: 2.5496463028064813

Epoch: 5| Step: 7
Training loss: 2.354823389416501
Validation loss: 2.558061314536221

Epoch: 5| Step: 8
Training loss: 2.5832392049888933
Validation loss: 2.5657165612527115

Epoch: 5| Step: 9
Training loss: 2.6349200860198194
Validation loss: 2.5749605558317095

Epoch: 5| Step: 10
Training loss: 3.250563205923042
Validation loss: 2.577026746799127

Epoch: 234| Step: 0
Training loss: 2.692928509346547
Validation loss: 2.5694754218314926

Epoch: 5| Step: 1
Training loss: 3.004500192724416
Validation loss: 2.5772511020058695

Epoch: 5| Step: 2
Training loss: 2.7482115391875377
Validation loss: 2.5760588091796603

Epoch: 5| Step: 3
Training loss: 3.2408956504814483
Validation loss: 2.5618055669740993

Epoch: 5| Step: 4
Training loss: 2.9498838369483735
Validation loss: 2.5731216222157194

Epoch: 5| Step: 5
Training loss: 2.7864096283741104
Validation loss: 2.5439222391336456

Epoch: 5| Step: 6
Training loss: 2.560467448919497
Validation loss: 2.5483868674743766

Epoch: 5| Step: 7
Training loss: 2.6203613167516364
Validation loss: 2.548604745599763

Epoch: 5| Step: 8
Training loss: 2.785830551208452
Validation loss: 2.5602655450591736

Epoch: 5| Step: 9
Training loss: 2.7273130067105
Validation loss: 2.5949376423205344

Epoch: 5| Step: 10
Training loss: 3.030718255349802
Validation loss: 2.6205027917072874

Epoch: 235| Step: 0
Training loss: 2.8069000442804413
Validation loss: 2.629904160790417

Epoch: 5| Step: 1
Training loss: 2.629811010786443
Validation loss: 2.6391682784733286

Epoch: 5| Step: 2
Training loss: 2.9844588822165257
Validation loss: 2.6073926577978748

Epoch: 5| Step: 3
Training loss: 2.871336883837959
Validation loss: 2.5609609732830667

Epoch: 5| Step: 4
Training loss: 3.011485683264626
Validation loss: 2.5440492730754576

Epoch: 5| Step: 5
Training loss: 2.8330093273328423
Validation loss: 2.5393972666171805

Epoch: 5| Step: 6
Training loss: 3.2937229510070702
Validation loss: 2.5410036775316422

Epoch: 5| Step: 7
Training loss: 2.6907809434951155
Validation loss: 2.54168553768141

Epoch: 5| Step: 8
Training loss: 2.6553103411776724
Validation loss: 2.53465332673325

Epoch: 5| Step: 9
Training loss: 2.719637057408496
Validation loss: 2.538449043270232

Epoch: 5| Step: 10
Training loss: 2.7602228540482034
Validation loss: 2.5409223491113133

Epoch: 236| Step: 0
Training loss: 2.6480092290331387
Validation loss: 2.5426912160860193

Epoch: 5| Step: 1
Training loss: 3.1954265098471573
Validation loss: 2.564352277977714

Epoch: 5| Step: 2
Training loss: 2.592195251710786
Validation loss: 2.5844430719796603

Epoch: 5| Step: 3
Training loss: 2.7627439848575728
Validation loss: 2.6187921836901995

Epoch: 5| Step: 4
Training loss: 3.029311671365379
Validation loss: 2.611332088274202

Epoch: 5| Step: 5
Training loss: 3.0708325748796357
Validation loss: 2.635512845412567

Epoch: 5| Step: 6
Training loss: 3.1875414378146747
Validation loss: 2.629234235116425

Epoch: 5| Step: 7
Training loss: 2.9984780265609823
Validation loss: 2.6109962705034127

Epoch: 5| Step: 8
Training loss: 2.1974338043276425
Validation loss: 2.5663666863753205

Epoch: 5| Step: 9
Training loss: 3.000634603137378
Validation loss: 2.5511447405226373

Epoch: 5| Step: 10
Training loss: 2.2388804434256007
Validation loss: 2.546305105675351

Epoch: 237| Step: 0
Training loss: 2.445589872478895
Validation loss: 2.546096009222293

Epoch: 5| Step: 1
Training loss: 2.786272550194705
Validation loss: 2.550279005511984

Epoch: 5| Step: 2
Training loss: 2.7277637884899635
Validation loss: 2.5486670281336026

Epoch: 5| Step: 3
Training loss: 2.530866994256068
Validation loss: 2.5460898953740436

Epoch: 5| Step: 4
Training loss: 2.880557286862726
Validation loss: 2.5757241344852915

Epoch: 5| Step: 5
Training loss: 3.1716785088172883
Validation loss: 2.6098833488510063

Epoch: 5| Step: 6
Training loss: 2.8103890020103712
Validation loss: 2.6282988357014876

Epoch: 5| Step: 7
Training loss: 3.0998938080842264
Validation loss: 2.619455008664048

Epoch: 5| Step: 8
Training loss: 2.7084537088101275
Validation loss: 2.600464168453947

Epoch: 5| Step: 9
Training loss: 2.9061530312388926
Validation loss: 2.586954055124139

Epoch: 5| Step: 10
Training loss: 3.096791939338476
Validation loss: 2.5696662783421327

Epoch: 238| Step: 0
Training loss: 2.897502244449829
Validation loss: 2.5299738192951624

Epoch: 5| Step: 1
Training loss: 3.3429068099397274
Validation loss: 2.5334939433233283

Epoch: 5| Step: 2
Training loss: 2.4244549207502795
Validation loss: 2.535086429277311

Epoch: 5| Step: 3
Training loss: 2.7320349571370866
Validation loss: 2.533279901398713

Epoch: 5| Step: 4
Training loss: 3.112544145998738
Validation loss: 2.5388050609544557

Epoch: 5| Step: 5
Training loss: 2.5694757740298733
Validation loss: 2.5377373429647436

Epoch: 5| Step: 6
Training loss: 2.6402652653448895
Validation loss: 2.560711583476469

Epoch: 5| Step: 7
Training loss: 2.8049665646931747
Validation loss: 2.5757438464986335

Epoch: 5| Step: 8
Training loss: 2.6754761459265293
Validation loss: 2.578027886842203

Epoch: 5| Step: 9
Training loss: 3.152432389649852
Validation loss: 2.5731981261434753

Epoch: 5| Step: 10
Training loss: 2.6641091261556222
Validation loss: 2.557445852210678

Epoch: 239| Step: 0
Training loss: 3.025217719952201
Validation loss: 2.553130996630185

Epoch: 5| Step: 1
Training loss: 2.937462664427793
Validation loss: 2.535364351754018

Epoch: 5| Step: 2
Training loss: 2.270017063059935
Validation loss: 2.543286782726279

Epoch: 5| Step: 3
Training loss: 2.5275372249831527
Validation loss: 2.5430279970532883

Epoch: 5| Step: 4
Training loss: 3.087216037556949
Validation loss: 2.5419384471306987

Epoch: 5| Step: 5
Training loss: 2.582537949053369
Validation loss: 2.56289426310177

Epoch: 5| Step: 6
Training loss: 3.27103512540388
Validation loss: 2.5803004985461473

Epoch: 5| Step: 7
Training loss: 2.9746850367921702
Validation loss: 2.57668630084065

Epoch: 5| Step: 8
Training loss: 2.7589695910236336
Validation loss: 2.572845463645374

Epoch: 5| Step: 9
Training loss: 2.9955911028205855
Validation loss: 2.5804011296183376

Epoch: 5| Step: 10
Training loss: 2.304388822178349
Validation loss: 2.5676355551099634

Epoch: 240| Step: 0
Training loss: 2.247486618053072
Validation loss: 2.5646127294486383

Epoch: 5| Step: 1
Training loss: 3.0412572471949364
Validation loss: 2.560727340430935

Epoch: 5| Step: 2
Training loss: 3.1104357266379736
Validation loss: 2.5664221887559777

Epoch: 5| Step: 3
Training loss: 2.0389247570064684
Validation loss: 2.5602494307937365

Epoch: 5| Step: 4
Training loss: 2.8816613687702266
Validation loss: 2.562286166941786

Epoch: 5| Step: 5
Training loss: 3.07596880530127
Validation loss: 2.545529738329278

Epoch: 5| Step: 6
Training loss: 2.669550637567466
Validation loss: 2.549829247934822

Epoch: 5| Step: 7
Training loss: 2.9787181347652543
Validation loss: 2.5476089367235364

Epoch: 5| Step: 8
Training loss: 3.025174216305809
Validation loss: 2.5613765760069787

Epoch: 5| Step: 9
Training loss: 2.752883093400033
Validation loss: 2.554462195256109

Epoch: 5| Step: 10
Training loss: 2.9340286846773953
Validation loss: 2.5386514310431103

Epoch: 241| Step: 0
Training loss: 3.06720574519774
Validation loss: 2.54214160387986

Epoch: 5| Step: 1
Training loss: 2.724377475290209
Validation loss: 2.575195804283418

Epoch: 5| Step: 2
Training loss: 2.907911420530357
Validation loss: 2.6131603717553338

Epoch: 5| Step: 3
Training loss: 3.0652207725381566
Validation loss: 2.658629438545425

Epoch: 5| Step: 4
Training loss: 2.879549159154146
Validation loss: 2.6410383384104237

Epoch: 5| Step: 5
Training loss: 2.574582341960472
Validation loss: 2.6033451902843687

Epoch: 5| Step: 6
Training loss: 2.341991324222174
Validation loss: 2.5444533270175884

Epoch: 5| Step: 7
Training loss: 2.6333309761069006
Validation loss: 2.53240004644967

Epoch: 5| Step: 8
Training loss: 3.1755313939227654
Validation loss: 2.534805486703756

Epoch: 5| Step: 9
Training loss: 2.6449502587644047
Validation loss: 2.53495672634595

Epoch: 5| Step: 10
Training loss: 3.1523885239230456
Validation loss: 2.543182848440155

Epoch: 242| Step: 0
Training loss: 3.0586370901104014
Validation loss: 2.551643567412897

Epoch: 5| Step: 1
Training loss: 3.1279586519108538
Validation loss: 2.536717878487729

Epoch: 5| Step: 2
Training loss: 2.3236307891095564
Validation loss: 2.5366161511526317

Epoch: 5| Step: 3
Training loss: 2.9937907174353797
Validation loss: 2.538650860986393

Epoch: 5| Step: 4
Training loss: 3.2162747541320815
Validation loss: 2.542330500028914

Epoch: 5| Step: 5
Training loss: 2.238707709836862
Validation loss: 2.5561658747377654

Epoch: 5| Step: 6
Training loss: 2.4698925995739525
Validation loss: 2.562616831319382

Epoch: 5| Step: 7
Training loss: 3.0794114266361143
Validation loss: 2.6013385824524753

Epoch: 5| Step: 8
Training loss: 3.2493668452984354
Validation loss: 2.627316364585441

Epoch: 5| Step: 9
Training loss: 2.4758353624963636
Validation loss: 2.6776721916877895

Epoch: 5| Step: 10
Training loss: 2.4928436850435536
Validation loss: 2.6702272949649477

Epoch: 243| Step: 0
Training loss: 2.8638710569839336
Validation loss: 2.647362275437346

Epoch: 5| Step: 1
Training loss: 2.9849440746084404
Validation loss: 2.577839722920132

Epoch: 5| Step: 2
Training loss: 2.2111170395921285
Validation loss: 2.5518979190845625

Epoch: 5| Step: 3
Training loss: 2.599416219756412
Validation loss: 2.533234149154872

Epoch: 5| Step: 4
Training loss: 2.8744798272633174
Validation loss: 2.5265665249703013

Epoch: 5| Step: 5
Training loss: 2.5921674749464327
Validation loss: 2.5245979648152943

Epoch: 5| Step: 6
Training loss: 3.055564344759544
Validation loss: 2.525405607497966

Epoch: 5| Step: 7
Training loss: 3.0330566056450174
Validation loss: 2.522953087656343

Epoch: 5| Step: 8
Training loss: 3.223252489824398
Validation loss: 2.5275962647525496

Epoch: 5| Step: 9
Training loss: 2.54363920453197
Validation loss: 2.5313181258391793

Epoch: 5| Step: 10
Training loss: 2.9136069097614
Validation loss: 2.5464284185605917

Epoch: 244| Step: 0
Training loss: 2.2891110359748765
Validation loss: 2.547995977864667

Epoch: 5| Step: 1
Training loss: 2.4402073228025682
Validation loss: 2.5835803612115424

Epoch: 5| Step: 2
Training loss: 2.6950084570077895
Validation loss: 2.571239591615302

Epoch: 5| Step: 3
Training loss: 3.0556851292118954
Validation loss: 2.563286614306386

Epoch: 5| Step: 4
Training loss: 2.9829708610848105
Validation loss: 2.5456038165865267

Epoch: 5| Step: 5
Training loss: 3.1632368352687372
Validation loss: 2.519214478128517

Epoch: 5| Step: 6
Training loss: 2.201615702606913
Validation loss: 2.525663678468711

Epoch: 5| Step: 7
Training loss: 3.0291511111972893
Validation loss: 2.5268637490489816

Epoch: 5| Step: 8
Training loss: 2.7940183574644144
Validation loss: 2.5207623880508994

Epoch: 5| Step: 9
Training loss: 3.348584396977935
Validation loss: 2.5257201229986475

Epoch: 5| Step: 10
Training loss: 2.821388271933847
Validation loss: 2.5235846783329356

Epoch: 245| Step: 0
Training loss: 2.9518670526252553
Validation loss: 2.528713043229781

Epoch: 5| Step: 1
Training loss: 3.460685772492235
Validation loss: 2.54539981619931

Epoch: 5| Step: 2
Training loss: 2.3172871296223265
Validation loss: 2.560412156884647

Epoch: 5| Step: 3
Training loss: 2.710355756712003
Validation loss: 2.594183466392031

Epoch: 5| Step: 4
Training loss: 2.8940121163283967
Validation loss: 2.6204036938068573

Epoch: 5| Step: 5
Training loss: 2.776678378510552
Validation loss: 2.616300554242679

Epoch: 5| Step: 6
Training loss: 2.455860629293013
Validation loss: 2.598638976359556

Epoch: 5| Step: 7
Training loss: 2.6762639633591276
Validation loss: 2.5885453135744365

Epoch: 5| Step: 8
Training loss: 2.9505796412605756
Validation loss: 2.58817422666844

Epoch: 5| Step: 9
Training loss: 2.673968649293096
Validation loss: 2.5983276979758556

Epoch: 5| Step: 10
Training loss: 3.006302570985733
Validation loss: 2.5872837001805506

Epoch: 246| Step: 0
Training loss: 2.8401602420462986
Validation loss: 2.5412458323228484

Epoch: 5| Step: 1
Training loss: 2.9453102334416013
Validation loss: 2.52326901731002

Epoch: 5| Step: 2
Training loss: 2.586836275491499
Validation loss: 2.525508300033359

Epoch: 5| Step: 3
Training loss: 2.555450232265814
Validation loss: 2.517883723665026

Epoch: 5| Step: 4
Training loss: 2.973979319661523
Validation loss: 2.515000133425922

Epoch: 5| Step: 5
Training loss: 3.0084321411757124
Validation loss: 2.5196249280912073

Epoch: 5| Step: 6
Training loss: 2.9132717174354634
Validation loss: 2.5241860698185667

Epoch: 5| Step: 7
Training loss: 2.9196212154467935
Validation loss: 2.5303633623443402

Epoch: 5| Step: 8
Training loss: 2.4387629244963915
Validation loss: 2.5306899579065107

Epoch: 5| Step: 9
Training loss: 2.6960848821131056
Validation loss: 2.5329179776535966

Epoch: 5| Step: 10
Training loss: 2.904308860359012
Validation loss: 2.5513196119301673

Epoch: 247| Step: 0
Training loss: 2.4903416030835666
Validation loss: 2.5670735812385486

Epoch: 5| Step: 1
Training loss: 2.4936221785520063
Validation loss: 2.6005205135076173

Epoch: 5| Step: 2
Training loss: 3.1537642557772236
Validation loss: 2.5864632127923706

Epoch: 5| Step: 3
Training loss: 2.4704735449474864
Validation loss: 2.565766080675756

Epoch: 5| Step: 4
Training loss: 2.9739688977768157
Validation loss: 2.554441926609433

Epoch: 5| Step: 5
Training loss: 2.6009395185666935
Validation loss: 2.5377320262384733

Epoch: 5| Step: 6
Training loss: 3.0205190210045028
Validation loss: 2.5330376115543296

Epoch: 5| Step: 7
Training loss: 3.0139425852065242
Validation loss: 2.5333131064248127

Epoch: 5| Step: 8
Training loss: 3.332025668820428
Validation loss: 2.523607455618596

Epoch: 5| Step: 9
Training loss: 2.25228437384476
Validation loss: 2.5247343289302124

Epoch: 5| Step: 10
Training loss: 2.9534177281855416
Validation loss: 2.5170931665841345

Epoch: 248| Step: 0
Training loss: 2.7179089703281067
Validation loss: 2.5188102899585343

Epoch: 5| Step: 1
Training loss: 2.3459735749391433
Validation loss: 2.519394751811074

Epoch: 5| Step: 2
Training loss: 3.1278673368844205
Validation loss: 2.524073082954903

Epoch: 5| Step: 3
Training loss: 2.6661577235768563
Validation loss: 2.539941860791911

Epoch: 5| Step: 4
Training loss: 2.6892507306571636
Validation loss: 2.5580540958157596

Epoch: 5| Step: 5
Training loss: 2.6851287849271377
Validation loss: 2.5964917753408407

Epoch: 5| Step: 6
Training loss: 3.1546861154478605
Validation loss: 2.5635863991766246

Epoch: 5| Step: 7
Training loss: 2.9730423264298897
Validation loss: 2.557549685009614

Epoch: 5| Step: 8
Training loss: 2.8551063568560737
Validation loss: 2.5282738519733696

Epoch: 5| Step: 9
Training loss: 3.044608187468094
Validation loss: 2.522099551087107

Epoch: 5| Step: 10
Training loss: 2.482657360609883
Validation loss: 2.5376140588245897

Epoch: 249| Step: 0
Training loss: 3.0805275153200697
Validation loss: 2.5304343341091684

Epoch: 5| Step: 1
Training loss: 2.923315825139867
Validation loss: 2.5361320422349527

Epoch: 5| Step: 2
Training loss: 2.873096001449468
Validation loss: 2.530736482468254

Epoch: 5| Step: 3
Training loss: 2.386089935129821
Validation loss: 2.5313576944164238

Epoch: 5| Step: 4
Training loss: 2.78745306685414
Validation loss: 2.5304198712337693

Epoch: 5| Step: 5
Training loss: 2.5545327609267314
Validation loss: 2.5299964980215046

Epoch: 5| Step: 6
Training loss: 2.4139776616173054
Validation loss: 2.5474451834644225

Epoch: 5| Step: 7
Training loss: 2.979986029214561
Validation loss: 2.5760186911956855

Epoch: 5| Step: 8
Training loss: 2.8907863262625355
Validation loss: 2.6262508230762567

Epoch: 5| Step: 9
Training loss: 2.954919501949332
Validation loss: 2.5974445541417355

Epoch: 5| Step: 10
Training loss: 2.998082978966241
Validation loss: 2.5900980897624724

Epoch: 250| Step: 0
Training loss: 2.8950843848808714
Validation loss: 2.555757300908704

Epoch: 5| Step: 1
Training loss: 2.4373698077522894
Validation loss: 2.542610056586556

Epoch: 5| Step: 2
Training loss: 2.9094066909063816
Validation loss: 2.523988040488221

Epoch: 5| Step: 3
Training loss: 2.4114685937211413
Validation loss: 2.525109748887886

Epoch: 5| Step: 4
Training loss: 2.4483873821063664
Validation loss: 2.5248160447631696

Epoch: 5| Step: 5
Training loss: 3.4737853198265127
Validation loss: 2.520339250938513

Epoch: 5| Step: 6
Training loss: 2.298013417987477
Validation loss: 2.532808080288545

Epoch: 5| Step: 7
Training loss: 3.020714294894404
Validation loss: 2.549153713549325

Epoch: 5| Step: 8
Training loss: 2.5871738578435792
Validation loss: 2.5644925561999043

Epoch: 5| Step: 9
Training loss: 2.9908141328484614
Validation loss: 2.5819393992579966

Epoch: 5| Step: 10
Training loss: 3.154537378360283
Validation loss: 2.5866044822614587

Testing loss: 2.718303970250051
