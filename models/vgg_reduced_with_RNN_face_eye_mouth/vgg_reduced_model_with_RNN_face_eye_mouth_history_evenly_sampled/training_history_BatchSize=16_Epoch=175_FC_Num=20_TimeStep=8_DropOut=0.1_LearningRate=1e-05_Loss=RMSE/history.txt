Epoch: 1| Step: 0
Training loss: 5.855890891220807
Validation loss: 5.772637990398124

Epoch: 6| Step: 1
Training loss: 5.8276746642368
Validation loss: 5.7642999346892

Epoch: 6| Step: 2
Training loss: 5.7285319398634025
Validation loss: 5.7555993322934125

Epoch: 6| Step: 3
Training loss: 4.972424378124518
Validation loss: 5.746447171336146

Epoch: 6| Step: 4
Training loss: 5.783928328073998
Validation loss: 5.73745455024046

Epoch: 6| Step: 5
Training loss: 5.7507317118926675
Validation loss: 5.7280950223790175

Epoch: 6| Step: 6
Training loss: 4.598248206237035
Validation loss: 5.7177555271455

Epoch: 6| Step: 7
Training loss: 6.893880546488879
Validation loss: 5.707460564717542

Epoch: 6| Step: 8
Training loss: 5.137566766977948
Validation loss: 5.696541081155033

Epoch: 6| Step: 9
Training loss: 6.30915003352336
Validation loss: 5.6846930640488855

Epoch: 6| Step: 10
Training loss: 6.055457045349771
Validation loss: 5.672054445112995

Epoch: 6| Step: 11
Training loss: 6.3710150137876935
Validation loss: 5.6583679690136055

Epoch: 6| Step: 12
Training loss: 4.672227724979006
Validation loss: 5.643538378637203

Epoch: 6| Step: 13
Training loss: 6.168610068978706
Validation loss: 5.628371214967159

Epoch: 2| Step: 0
Training loss: 4.8289059498109035
Validation loss: 5.611506534904839

Epoch: 6| Step: 1
Training loss: 5.8601887455771475
Validation loss: 5.593946528504161

Epoch: 6| Step: 2
Training loss: 6.235321508468095
Validation loss: 5.575392490445217

Epoch: 6| Step: 3
Training loss: 4.54190179525324
Validation loss: 5.554853481244357

Epoch: 6| Step: 4
Training loss: 6.501526286586541
Validation loss: 5.533049315630649

Epoch: 6| Step: 5
Training loss: 5.810617449676443
Validation loss: 5.5105869519602075

Epoch: 6| Step: 6
Training loss: 4.707562656400914
Validation loss: 5.486338763976026

Epoch: 6| Step: 7
Training loss: 5.889653861945147
Validation loss: 5.460472442388039

Epoch: 6| Step: 8
Training loss: 5.504893466843734
Validation loss: 5.432771942324113

Epoch: 6| Step: 9
Training loss: 6.448711816652864
Validation loss: 5.404641526654037

Epoch: 6| Step: 10
Training loss: 4.522772072979258
Validation loss: 5.375390750449492

Epoch: 6| Step: 11
Training loss: 5.11762488439681
Validation loss: 5.345009322021187

Epoch: 6| Step: 12
Training loss: 5.430752480988765
Validation loss: 5.312355621518595

Epoch: 6| Step: 13
Training loss: 5.017100084577444
Validation loss: 5.281276496266873

Epoch: 3| Step: 0
Training loss: 6.285727959159742
Validation loss: 5.249174726072138

Epoch: 6| Step: 1
Training loss: 5.801042318409724
Validation loss: 5.215215086949883

Epoch: 6| Step: 2
Training loss: 4.8348900272206174
Validation loss: 5.183735669348176

Epoch: 6| Step: 3
Training loss: 4.635246679496697
Validation loss: 5.149992503929238

Epoch: 6| Step: 4
Training loss: 4.566385783075391
Validation loss: 5.1175299547336905

Epoch: 6| Step: 5
Training loss: 5.3986233404607855
Validation loss: 5.086465060839365

Epoch: 6| Step: 6
Training loss: 5.133172938495634
Validation loss: 5.055313738247638

Epoch: 6| Step: 7
Training loss: 4.495752661366893
Validation loss: 5.024365772442698

Epoch: 6| Step: 8
Training loss: 5.39426465104265
Validation loss: 4.995940391858102

Epoch: 6| Step: 9
Training loss: 5.1642576980057004
Validation loss: 4.967212538457415

Epoch: 6| Step: 10
Training loss: 5.232383235206339
Validation loss: 4.939688601836385

Epoch: 6| Step: 11
Training loss: 4.552192017445693
Validation loss: 4.912508455304856

Epoch: 6| Step: 12
Training loss: 4.51596712182564
Validation loss: 4.887454574730966

Epoch: 6| Step: 13
Training loss: 5.40345630236765
Validation loss: 4.859567517651703

Epoch: 4| Step: 0
Training loss: 5.255534751390318
Validation loss: 4.8323902883388135

Epoch: 6| Step: 1
Training loss: 3.5121372130577027
Validation loss: 4.80661856543111

Epoch: 6| Step: 2
Training loss: 5.401608630163521
Validation loss: 4.781012798175765

Epoch: 6| Step: 3
Training loss: 4.0569457599191265
Validation loss: 4.753794246545313

Epoch: 6| Step: 4
Training loss: 4.767805757444682
Validation loss: 4.731295228532982

Epoch: 6| Step: 5
Training loss: 4.870347370393695
Validation loss: 4.703634063171009

Epoch: 6| Step: 6
Training loss: 4.2262156797254935
Validation loss: 4.678310528272797

Epoch: 6| Step: 7
Training loss: 4.451175945793992
Validation loss: 4.653520584544181

Epoch: 6| Step: 8
Training loss: 4.633010937202532
Validation loss: 4.6298320176290195

Epoch: 6| Step: 9
Training loss: 4.751334153583988
Validation loss: 4.6018362224506175

Epoch: 6| Step: 10
Training loss: 4.7961138888748875
Validation loss: 4.573100058482309

Epoch: 6| Step: 11
Training loss: 4.185373705878763
Validation loss: 4.543027886998344

Epoch: 6| Step: 12
Training loss: 5.858904929060842
Validation loss: 4.520632272899993

Epoch: 6| Step: 13
Training loss: 5.716785864889466
Validation loss: 4.502635024811157

Epoch: 5| Step: 0
Training loss: 3.542925008989568
Validation loss: 4.479866832011594

Epoch: 6| Step: 1
Training loss: 3.8608682191654404
Validation loss: 4.4597519388793

Epoch: 6| Step: 2
Training loss: 4.447510294996143
Validation loss: 4.439758435515945

Epoch: 6| Step: 3
Training loss: 4.0277462895942
Validation loss: 4.423928271997767

Epoch: 6| Step: 4
Training loss: 4.582714709523899
Validation loss: 4.401804267047205

Epoch: 6| Step: 5
Training loss: 3.665469031824795
Validation loss: 4.387786219613192

Epoch: 6| Step: 6
Training loss: 4.304036556811878
Validation loss: 4.368960398863506

Epoch: 6| Step: 7
Training loss: 5.4558464189431435
Validation loss: 4.349501933927558

Epoch: 6| Step: 8
Training loss: 5.034648245198552
Validation loss: 4.325647645185805

Epoch: 6| Step: 9
Training loss: 4.457894324438538
Validation loss: 4.307080994956103

Epoch: 6| Step: 10
Training loss: 4.113240907476665
Validation loss: 4.291418378803889

Epoch: 6| Step: 11
Training loss: 4.65310193857354
Validation loss: 4.266844305223181

Epoch: 6| Step: 12
Training loss: 5.187456613382193
Validation loss: 4.251824347525289

Epoch: 6| Step: 13
Training loss: 5.013313117155613
Validation loss: 4.232797801262444

Epoch: 6| Step: 0
Training loss: 3.7917127641383885
Validation loss: 4.21783183507955

Epoch: 6| Step: 1
Training loss: 4.369740185379415
Validation loss: 4.210109031882138

Epoch: 6| Step: 2
Training loss: 4.3542082326751546
Validation loss: 4.197931289901837

Epoch: 6| Step: 3
Training loss: 5.010739047120678
Validation loss: 4.1869088179407905

Epoch: 6| Step: 4
Training loss: 4.919686160738916
Validation loss: 4.175967509988561

Epoch: 6| Step: 5
Training loss: 3.8017810161361636
Validation loss: 4.159226983401974

Epoch: 6| Step: 6
Training loss: 3.268185720370253
Validation loss: 4.145308861424506

Epoch: 6| Step: 7
Training loss: 3.9171856204965327
Validation loss: 4.137802202607552

Epoch: 6| Step: 8
Training loss: 5.438417379228836
Validation loss: 4.131856645934876

Epoch: 6| Step: 9
Training loss: 3.4297258726853928
Validation loss: 4.118857567643086

Epoch: 6| Step: 10
Training loss: 4.2464948673520455
Validation loss: 4.11555366876316

Epoch: 6| Step: 11
Training loss: 4.249009409631234
Validation loss: 4.108853913533777

Epoch: 6| Step: 12
Training loss: 4.286513830716384
Validation loss: 4.09787315721204

Epoch: 6| Step: 13
Training loss: 4.5333583793696235
Validation loss: 4.089986913175546

Epoch: 7| Step: 0
Training loss: 3.919484173448476
Validation loss: 4.078877138085149

Epoch: 6| Step: 1
Training loss: 5.001221316902956
Validation loss: 4.069598966172092

Epoch: 6| Step: 2
Training loss: 4.189001696613812
Validation loss: 4.0582671068319085

Epoch: 6| Step: 3
Training loss: 4.215582216355359
Validation loss: 4.044151259642295

Epoch: 6| Step: 4
Training loss: 3.541793611532769
Validation loss: 4.034896581270638

Epoch: 6| Step: 5
Training loss: 5.014548498121705
Validation loss: 4.0251291747407025

Epoch: 6| Step: 6
Training loss: 3.852374318206013
Validation loss: 4.013542098902975

Epoch: 6| Step: 7
Training loss: 4.020639576303633
Validation loss: 4.003147407211518

Epoch: 6| Step: 8
Training loss: 4.334185932109027
Validation loss: 3.9942165269360865

Epoch: 6| Step: 9
Training loss: 3.8062767140620806
Validation loss: 3.9857365166596654

Epoch: 6| Step: 10
Training loss: 3.2961805434824005
Validation loss: 3.9780060919802334

Epoch: 6| Step: 11
Training loss: 3.7447322722258014
Validation loss: 3.968966597580579

Epoch: 6| Step: 12
Training loss: 4.562512750477153
Validation loss: 3.9616130309356135

Epoch: 6| Step: 13
Training loss: 4.632190167214561
Validation loss: 3.9555042633913406

Epoch: 8| Step: 0
Training loss: 2.798117675907995
Validation loss: 3.9454734117200942

Epoch: 6| Step: 1
Training loss: 4.000859645022545
Validation loss: 3.93649079306504

Epoch: 6| Step: 2
Training loss: 4.0000119209111915
Validation loss: 3.9317570226788736

Epoch: 6| Step: 3
Training loss: 5.270830156930964
Validation loss: 3.920167696552889

Epoch: 6| Step: 4
Training loss: 4.06786121792591
Validation loss: 3.9152859383765777

Epoch: 6| Step: 5
Training loss: 3.382386636688122
Validation loss: 3.905901616793999

Epoch: 6| Step: 6
Training loss: 4.273918612942763
Validation loss: 3.8969848354185306

Epoch: 6| Step: 7
Training loss: 4.0350134972933915
Validation loss: 3.886724628261211

Epoch: 6| Step: 8
Training loss: 3.7771975657629646
Validation loss: 3.8800446101310313

Epoch: 6| Step: 9
Training loss: 4.265570895232648
Validation loss: 3.8755970116898784

Epoch: 6| Step: 10
Training loss: 4.137212534711391
Validation loss: 3.8686782762674885

Epoch: 6| Step: 11
Training loss: 4.999629960672324
Validation loss: 3.8585761515011106

Epoch: 6| Step: 12
Training loss: 3.444866263973125
Validation loss: 3.8498392401549726

Epoch: 6| Step: 13
Training loss: 3.3956620030780376
Validation loss: 3.8433817705341418

Epoch: 9| Step: 0
Training loss: 3.6658885448056124
Validation loss: 3.8373675837492844

Epoch: 6| Step: 1
Training loss: 3.8200814580970106
Validation loss: 3.8345564678258977

Epoch: 6| Step: 2
Training loss: 4.814360023820907
Validation loss: 3.8291279238898124

Epoch: 6| Step: 3
Training loss: 3.48802780478008
Validation loss: 3.8153716054676403

Epoch: 6| Step: 4
Training loss: 4.181263393044227
Validation loss: 3.8063878246445815

Epoch: 6| Step: 5
Training loss: 3.9868582373513517
Validation loss: 3.8010843638780814

Epoch: 6| Step: 6
Training loss: 3.4413566455881597
Validation loss: 3.791591600722796

Epoch: 6| Step: 7
Training loss: 3.4422887564721485
Validation loss: 3.7972451414509063

Epoch: 6| Step: 8
Training loss: 4.354792110417118
Validation loss: 3.7989249243064185

Epoch: 6| Step: 9
Training loss: 3.438098924652728
Validation loss: 3.771092202635269

Epoch: 6| Step: 10
Training loss: 4.099795006070044
Validation loss: 3.7707925791020487

Epoch: 6| Step: 11
Training loss: 4.891195538181295
Validation loss: 3.794217271510018

Epoch: 6| Step: 12
Training loss: 4.006246457864561
Validation loss: 3.7637199846086036

Epoch: 6| Step: 13
Training loss: 3.2949639879032957
Validation loss: 3.7633701007244107

Epoch: 10| Step: 0
Training loss: 3.978183378523929
Validation loss: 3.752698307636001

Epoch: 6| Step: 1
Training loss: 3.543872116649047
Validation loss: 3.745028722058101

Epoch: 6| Step: 2
Training loss: 3.8455022524037337
Validation loss: 3.745217202669882

Epoch: 6| Step: 3
Training loss: 3.055293732802326
Validation loss: 3.7477793171909717

Epoch: 6| Step: 4
Training loss: 4.007973353558134
Validation loss: 3.746352935998066

Epoch: 6| Step: 5
Training loss: 4.0934552967486395
Validation loss: 3.7442086240396617

Epoch: 6| Step: 6
Training loss: 3.800931043505703
Validation loss: 3.7437832920442333

Epoch: 6| Step: 7
Training loss: 4.380709165531164
Validation loss: 3.740469322213987

Epoch: 6| Step: 8
Training loss: 4.471440072438758
Validation loss: 3.7320357382817253

Epoch: 6| Step: 9
Training loss: 3.9618552083455207
Validation loss: 3.7260201927377983

Epoch: 6| Step: 10
Training loss: 4.1438001442661445
Validation loss: 3.7158910250913153

Epoch: 6| Step: 11
Training loss: 3.40040576981837
Validation loss: 3.7104002978567867

Epoch: 6| Step: 12
Training loss: 3.603054970344434
Validation loss: 3.7042843667163154

Epoch: 6| Step: 13
Training loss: 4.525573120915616
Validation loss: 3.6980600100784367

Epoch: 11| Step: 0
Training loss: 3.605604704404495
Validation loss: 3.6913818066880384

Epoch: 6| Step: 1
Training loss: 4.045006751584147
Validation loss: 3.6859047075384326

Epoch: 6| Step: 2
Training loss: 4.170554648637338
Validation loss: 3.6806351402647217

Epoch: 6| Step: 3
Training loss: 4.259696221781017
Validation loss: 3.6758516992375125

Epoch: 6| Step: 4
Training loss: 3.59714579818105
Validation loss: 3.6693794562032247

Epoch: 6| Step: 5
Training loss: 4.138925340280023
Validation loss: 3.6632376160214726

Epoch: 6| Step: 6
Training loss: 2.984987365849274
Validation loss: 3.655314488921633

Epoch: 6| Step: 7
Training loss: 4.260431390688697
Validation loss: 3.647753767981169

Epoch: 6| Step: 8
Training loss: 4.227138289684546
Validation loss: 3.641652415359315

Epoch: 6| Step: 9
Training loss: 3.994603569977178
Validation loss: 3.636015829284893

Epoch: 6| Step: 10
Training loss: 3.673612921910039
Validation loss: 3.63064922273624

Epoch: 6| Step: 11
Training loss: 3.6341440037195154
Validation loss: 3.627443592534774

Epoch: 6| Step: 12
Training loss: 3.6530113548438585
Validation loss: 3.62260888063674

Epoch: 6| Step: 13
Training loss: 2.8829850142635602
Validation loss: 3.6168241142689994

Epoch: 12| Step: 0
Training loss: 3.55328998971046
Validation loss: 3.615988788860237

Epoch: 6| Step: 1
Training loss: 4.346025268958722
Validation loss: 3.6149976851675

Epoch: 6| Step: 2
Training loss: 3.4769746343232146
Validation loss: 3.608613710485639

Epoch: 6| Step: 3
Training loss: 2.9376564795838562
Validation loss: 3.602614946064038

Epoch: 6| Step: 4
Training loss: 3.414918840150444
Validation loss: 3.5988454654851454

Epoch: 6| Step: 5
Training loss: 4.098722044723495
Validation loss: 3.5949204959236445

Epoch: 6| Step: 6
Training loss: 2.6664348342574953
Validation loss: 3.588329537105799

Epoch: 6| Step: 7
Training loss: 4.521555243775063
Validation loss: 3.58444319495653

Epoch: 6| Step: 8
Training loss: 4.675311709533261
Validation loss: 3.5810127833594514

Epoch: 6| Step: 9
Training loss: 4.691317821879455
Validation loss: 3.5760894429141765

Epoch: 6| Step: 10
Training loss: 3.629462685029155
Validation loss: 3.5710931982035397

Epoch: 6| Step: 11
Training loss: 3.2864637823205785
Validation loss: 3.5687332054941088

Epoch: 6| Step: 12
Training loss: 3.26366369313756
Validation loss: 3.56436777365269

Epoch: 6| Step: 13
Training loss: 3.78226249317267
Validation loss: 3.562590126749849

Epoch: 13| Step: 0
Training loss: 4.382342906688914
Validation loss: 3.558249781615821

Epoch: 6| Step: 1
Training loss: 3.904090956066124
Validation loss: 3.5557839789601338

Epoch: 6| Step: 2
Training loss: 3.195124464401595
Validation loss: 3.5513698915245278

Epoch: 6| Step: 3
Training loss: 2.385787357585079
Validation loss: 3.5494356065224024

Epoch: 6| Step: 4
Training loss: 3.0753821530946754
Validation loss: 3.546597247505654

Epoch: 6| Step: 5
Training loss: 4.413882523640057
Validation loss: 3.5436948341187287

Epoch: 6| Step: 6
Training loss: 3.444758156535672
Validation loss: 3.541295070565313

Epoch: 6| Step: 7
Training loss: 3.9076325678287933
Validation loss: 3.5376231661239945

Epoch: 6| Step: 8
Training loss: 3.9613181388389807
Validation loss: 3.5368904573349345

Epoch: 6| Step: 9
Training loss: 3.6888801448851165
Validation loss: 3.5340459457524975

Epoch: 6| Step: 10
Training loss: 3.4244859741297993
Validation loss: 3.5288397697980955

Epoch: 6| Step: 11
Training loss: 3.781785406874306
Validation loss: 3.528954998225423

Epoch: 6| Step: 12
Training loss: 4.369373299990282
Validation loss: 3.5270577520792274

Epoch: 6| Step: 13
Training loss: 4.107841872918829
Validation loss: 3.524016403852671

Epoch: 14| Step: 0
Training loss: 3.2933133670134715
Validation loss: 3.5223546810030673

Epoch: 6| Step: 1
Training loss: 2.42091645991552
Validation loss: 3.5192863811935653

Epoch: 6| Step: 2
Training loss: 4.571693668172165
Validation loss: 3.519829702340998

Epoch: 6| Step: 3
Training loss: 3.585283207261252
Validation loss: 3.51638854199862

Epoch: 6| Step: 4
Training loss: 4.088593941453568
Validation loss: 3.514416956289531

Epoch: 6| Step: 5
Training loss: 4.139487516961028
Validation loss: 3.512579165323316

Epoch: 6| Step: 6
Training loss: 3.3428172298931784
Validation loss: 3.5111452032361004

Epoch: 6| Step: 7
Training loss: 3.4789356147354336
Validation loss: 3.5127892261375413

Epoch: 6| Step: 8
Training loss: 3.0789939312281924
Validation loss: 3.509066492263653

Epoch: 6| Step: 9
Training loss: 3.76187998583581
Validation loss: 3.503505638751822

Epoch: 6| Step: 10
Training loss: 2.9415946180761763
Validation loss: 3.505144648051185

Epoch: 6| Step: 11
Training loss: 4.307215230587222
Validation loss: 3.5045836651669138

Epoch: 6| Step: 12
Training loss: 4.410222852962531
Validation loss: 3.503173956465325

Epoch: 6| Step: 13
Training loss: 4.214791482313197
Validation loss: 3.4999392397245996

Epoch: 15| Step: 0
Training loss: 5.0415941133349165
Validation loss: 3.4987546753282515

Epoch: 6| Step: 1
Training loss: 4.041598263715551
Validation loss: 3.494228328576134

Epoch: 6| Step: 2
Training loss: 3.4121260050306677
Validation loss: 3.4981271710934756

Epoch: 6| Step: 3
Training loss: 3.9632802201143202
Validation loss: 3.49282993609599

Epoch: 6| Step: 4
Training loss: 3.064852064336798
Validation loss: 3.4910664100141373

Epoch: 6| Step: 5
Training loss: 3.316630684994483
Validation loss: 3.4913359608154857

Epoch: 6| Step: 6
Training loss: 2.4494237494575613
Validation loss: 3.489879342265994

Epoch: 6| Step: 7
Training loss: 3.5609443346454266
Validation loss: 3.487453790326849

Epoch: 6| Step: 8
Training loss: 3.198608191128067
Validation loss: 3.484747550872948

Epoch: 6| Step: 9
Training loss: 4.101161624755026
Validation loss: 3.486137859102035

Epoch: 6| Step: 10
Training loss: 3.4125048403303873
Validation loss: 3.4828613015785224

Epoch: 6| Step: 11
Training loss: 3.7661623749413446
Validation loss: 3.4814286866416904

Epoch: 6| Step: 12
Training loss: 4.062212889869519
Validation loss: 3.481725027089968

Epoch: 6| Step: 13
Training loss: 3.8839800976872882
Validation loss: 3.477596442699812

Epoch: 16| Step: 0
Training loss: 4.496820174062606
Validation loss: 3.4804134103701925

Epoch: 6| Step: 1
Training loss: 3.2396835033634583
Validation loss: 3.4765637948860024

Epoch: 6| Step: 2
Training loss: 3.9738998042138234
Validation loss: 3.4754944987227754

Epoch: 6| Step: 3
Training loss: 3.5626294296578145
Validation loss: 3.47382968492744

Epoch: 6| Step: 4
Training loss: 4.308999230126918
Validation loss: 3.4736722444104724

Epoch: 6| Step: 5
Training loss: 4.014310985460429
Validation loss: 3.471949210532691

Epoch: 6| Step: 6
Training loss: 3.7978333570613407
Validation loss: 3.470741886268229

Epoch: 6| Step: 7
Training loss: 3.6699553970827967
Validation loss: 3.46947429928791

Epoch: 6| Step: 8
Training loss: 3.3264461097405893
Validation loss: 3.468070638731148

Epoch: 6| Step: 9
Training loss: 3.0066297707616374
Validation loss: 3.468403238769935

Epoch: 6| Step: 10
Training loss: 3.370534273578549
Validation loss: 3.468674658633645

Epoch: 6| Step: 11
Training loss: 3.837923425432355
Validation loss: 3.4681319706372373

Epoch: 6| Step: 12
Training loss: 3.3827682386502476
Validation loss: 3.465558484078438

Epoch: 6| Step: 13
Training loss: 3.0110761894587768
Validation loss: 3.4651240234429497

Epoch: 17| Step: 0
Training loss: 3.7620353842759036
Validation loss: 3.463612510936738

Epoch: 6| Step: 1
Training loss: 4.02401154506233
Validation loss: 3.460372362741442

Epoch: 6| Step: 2
Training loss: 3.3484012660541724
Validation loss: 3.4608539565752645

Epoch: 6| Step: 3
Training loss: 3.93588090335729
Validation loss: 3.459601756158026

Epoch: 6| Step: 4
Training loss: 2.9627956709611634
Validation loss: 3.4584260600221666

Epoch: 6| Step: 5
Training loss: 3.105148126137287
Validation loss: 3.4593256774368886

Epoch: 6| Step: 6
Training loss: 3.502771098000872
Validation loss: 3.455922886568659

Epoch: 6| Step: 7
Training loss: 3.6290506553867217
Validation loss: 3.4584017046443587

Epoch: 6| Step: 8
Training loss: 3.506213395034734
Validation loss: 3.458150425647956

Epoch: 6| Step: 9
Training loss: 2.5584990738685693
Validation loss: 3.457068227592545

Epoch: 6| Step: 10
Training loss: 4.6687417639234585
Validation loss: 3.458098503785495

Epoch: 6| Step: 11
Training loss: 4.375313883829508
Validation loss: 3.454736475658749

Epoch: 6| Step: 12
Training loss: 3.9072584147586333
Validation loss: 3.452189324528119

Epoch: 6| Step: 13
Training loss: 3.6582237198265717
Validation loss: 3.4535619819015784

Epoch: 18| Step: 0
Training loss: 3.2607184972185235
Validation loss: 3.453999753169215

Epoch: 6| Step: 1
Training loss: 4.391489832947454
Validation loss: 3.4515398008379417

Epoch: 6| Step: 2
Training loss: 4.129018733315852
Validation loss: 3.4507218707681178

Epoch: 6| Step: 3
Training loss: 3.4541853575590005
Validation loss: 3.449513682300497

Epoch: 6| Step: 4
Training loss: 3.4738243035231426
Validation loss: 3.449765773203653

Epoch: 6| Step: 5
Training loss: 4.134868031325136
Validation loss: 3.4485307506067167

Epoch: 6| Step: 6
Training loss: 3.8456927096418125
Validation loss: 3.446996252902106

Epoch: 6| Step: 7
Training loss: 2.8956965315818466
Validation loss: 3.4462151716714495

Epoch: 6| Step: 8
Training loss: 2.6563261133396545
Validation loss: 3.446279105593062

Epoch: 6| Step: 9
Training loss: 4.484487498929143
Validation loss: 3.4454952628020195

Epoch: 6| Step: 10
Training loss: 3.787506224372206
Validation loss: 3.444115865917448

Epoch: 6| Step: 11
Training loss: 2.4946472083671205
Validation loss: 3.4436194027403655

Epoch: 6| Step: 12
Training loss: 3.760765644199439
Validation loss: 3.443517493443483

Epoch: 6| Step: 13
Training loss: 4.09690095033436
Validation loss: 3.442495467228365

Epoch: 19| Step: 0
Training loss: 3.8881391680578443
Validation loss: 3.4423701893285483

Epoch: 6| Step: 1
Training loss: 2.9419865536048593
Validation loss: 3.440457594047953

Epoch: 6| Step: 2
Training loss: 4.719806881202833
Validation loss: 3.4417187797901208

Epoch: 6| Step: 3
Training loss: 2.081173832963084
Validation loss: 3.439626140239538

Epoch: 6| Step: 4
Training loss: 4.154174515931351
Validation loss: 3.439447354395858

Epoch: 6| Step: 5
Training loss: 3.8181628086393027
Validation loss: 3.438073806377831

Epoch: 6| Step: 6
Training loss: 3.4421311133602246
Validation loss: 3.437741578563724

Epoch: 6| Step: 7
Training loss: 3.2681258997110723
Validation loss: 3.4375576174802416

Epoch: 6| Step: 8
Training loss: 3.6567265126684205
Validation loss: 3.436006687403001

Epoch: 6| Step: 9
Training loss: 4.196155768806014
Validation loss: 3.4356332552241655

Epoch: 6| Step: 10
Training loss: 3.3966230788599066
Validation loss: 3.4366494298269354

Epoch: 6| Step: 11
Training loss: 2.607871347612501
Validation loss: 3.434709109949169

Epoch: 6| Step: 12
Training loss: 4.385972568438356
Validation loss: 3.4341072574803477

Epoch: 6| Step: 13
Training loss: 3.8909154576725107
Validation loss: 3.4341405208986524

Epoch: 20| Step: 0
Training loss: 3.2650214554693653
Validation loss: 3.432618754385129

Epoch: 6| Step: 1
Training loss: 3.7563524482961275
Validation loss: 3.4320696032333773

Epoch: 6| Step: 2
Training loss: 3.2658380320298552
Validation loss: 3.4323487855052224

Epoch: 6| Step: 3
Training loss: 3.7492257908482545
Validation loss: 3.4312257636125976

Epoch: 6| Step: 4
Training loss: 3.4847977043995506
Validation loss: 3.430787040412496

Epoch: 6| Step: 5
Training loss: 4.24999102423225
Validation loss: 3.4305589465619595

Epoch: 6| Step: 6
Training loss: 4.160733894755678
Validation loss: 3.429349346441218

Epoch: 6| Step: 7
Training loss: 3.5871189140983097
Validation loss: 3.429410620306858

Epoch: 6| Step: 8
Training loss: 3.2764917659810324
Validation loss: 3.428672679070438

Epoch: 6| Step: 9
Training loss: 4.238194393551256
Validation loss: 3.427759554083091

Epoch: 6| Step: 10
Training loss: 3.9525337832585685
Validation loss: 3.427689960758651

Epoch: 6| Step: 11
Training loss: 3.199388958288895
Validation loss: 3.426917881915792

Epoch: 6| Step: 12
Training loss: 3.6263049177595894
Validation loss: 3.427100671167718

Epoch: 6| Step: 13
Training loss: 2.525386093383405
Validation loss: 3.4251788721456626

Epoch: 21| Step: 0
Training loss: 3.7059161133924703
Validation loss: 3.425171315593035

Epoch: 6| Step: 1
Training loss: 2.978181974140222
Validation loss: 3.424257271892812

Epoch: 6| Step: 2
Training loss: 2.6563844534560483
Validation loss: 3.423847425096956

Epoch: 6| Step: 3
Training loss: 3.6504640362635694
Validation loss: 3.4236590573102976

Epoch: 6| Step: 4
Training loss: 3.0853502704723668
Validation loss: 3.4228123293077513

Epoch: 6| Step: 5
Training loss: 4.195820072661997
Validation loss: 3.421295712589463

Epoch: 6| Step: 6
Training loss: 3.393834436535935
Validation loss: 3.4228740826974557

Epoch: 6| Step: 7
Training loss: 4.023070798292181
Validation loss: 3.420788171172376

Epoch: 6| Step: 8
Training loss: 3.4945980346220056
Validation loss: 3.4200170243976573

Epoch: 6| Step: 9
Training loss: 4.333153403043405
Validation loss: 3.4167579700707025

Epoch: 6| Step: 10
Training loss: 3.8973919339763516
Validation loss: 3.415673687632931

Epoch: 6| Step: 11
Training loss: 3.3900562283964337
Validation loss: 3.4148097140556604

Epoch: 6| Step: 12
Training loss: 3.761436950966504
Validation loss: 3.416339659530169

Epoch: 6| Step: 13
Training loss: 4.3626327100969675
Validation loss: 3.412849291619094

Epoch: 22| Step: 0
Training loss: 3.737385832915128
Validation loss: 3.4116007096558865

Epoch: 6| Step: 1
Training loss: 3.445214787003688
Validation loss: 3.41169499103467

Epoch: 6| Step: 2
Training loss: 4.257004743477077
Validation loss: 3.4108644267998534

Epoch: 6| Step: 3
Training loss: 3.632186343466837
Validation loss: 3.410739334765124

Epoch: 6| Step: 4
Training loss: 2.8663413646857716
Validation loss: 3.4104827475350077

Epoch: 6| Step: 5
Training loss: 3.1401606733677547
Validation loss: 3.4124121770233486

Epoch: 6| Step: 6
Training loss: 3.5123674686719997
Validation loss: 3.4101135900012274

Epoch: 6| Step: 7
Training loss: 2.830750484906837
Validation loss: 3.4089935082983196

Epoch: 6| Step: 8
Training loss: 3.8604865693490016
Validation loss: 3.4082915160438496

Epoch: 6| Step: 9
Training loss: 3.303320780196783
Validation loss: 3.408151569018234

Epoch: 6| Step: 10
Training loss: 5.173177411066354
Validation loss: 3.4078256184725184

Epoch: 6| Step: 11
Training loss: 2.9437922189199814
Validation loss: 3.406403930112193

Epoch: 6| Step: 12
Training loss: 4.029201726488061
Validation loss: 3.4053494438104566

Epoch: 6| Step: 13
Training loss: 3.3692054454815166
Validation loss: 3.4056693413162904

Epoch: 23| Step: 0
Training loss: 3.5197560093588134
Validation loss: 3.404488073132881

Epoch: 6| Step: 1
Training loss: 1.9118058584280528
Validation loss: 3.4030014326773297

Epoch: 6| Step: 2
Training loss: 3.1095465991338767
Validation loss: 3.4028497444016836

Epoch: 6| Step: 3
Training loss: 2.9555776593649354
Validation loss: 3.402456850364449

Epoch: 6| Step: 4
Training loss: 4.29398162527999
Validation loss: 3.4020176273196556

Epoch: 6| Step: 5
Training loss: 4.492393847162929
Validation loss: 3.4009554234773223

Epoch: 6| Step: 6
Training loss: 3.339518213301532
Validation loss: 3.4019708999544083

Epoch: 6| Step: 7
Training loss: 4.115102743208024
Validation loss: 3.400285027070306

Epoch: 6| Step: 8
Training loss: 4.554919490500508
Validation loss: 3.400441615603681

Epoch: 6| Step: 9
Training loss: 3.8379604498260154
Validation loss: 3.398849374463295

Epoch: 6| Step: 10
Training loss: 2.977347363099684
Validation loss: 3.398814763981869

Epoch: 6| Step: 11
Training loss: 3.9982193321225874
Validation loss: 3.3968398334343837

Epoch: 6| Step: 12
Training loss: 3.312563337764158
Validation loss: 3.3969030566993172

Epoch: 6| Step: 13
Training loss: 3.330440235306694
Validation loss: 3.396311846206774

Epoch: 24| Step: 0
Training loss: 4.431954370642486
Validation loss: 3.3980307888594172

Epoch: 6| Step: 1
Training loss: 4.30704983174955
Validation loss: 3.395731078077379

Epoch: 6| Step: 2
Training loss: 4.115801177892039
Validation loss: 3.395753358379467

Epoch: 6| Step: 3
Training loss: 3.755917902275721
Validation loss: 3.395424758929899

Epoch: 6| Step: 4
Training loss: 3.8800084141512214
Validation loss: 3.3955075165362656

Epoch: 6| Step: 5
Training loss: 4.101704331625119
Validation loss: 3.3936629605440594

Epoch: 6| Step: 6
Training loss: 2.1814056515834586
Validation loss: 3.3929474359624674

Epoch: 6| Step: 7
Training loss: 3.8888727248325177
Validation loss: 3.392164048619573

Epoch: 6| Step: 8
Training loss: 3.745624278129102
Validation loss: 3.3920862534614624

Epoch: 6| Step: 9
Training loss: 3.8115250638527787
Validation loss: 3.3907021255306886

Epoch: 6| Step: 10
Training loss: 2.7239834630523037
Validation loss: 3.390455430472142

Epoch: 6| Step: 11
Training loss: 2.4290258359135755
Validation loss: 3.3895913912342066

Epoch: 6| Step: 12
Training loss: 2.7232582160211525
Validation loss: 3.3901637934518742

Epoch: 6| Step: 13
Training loss: 3.7220723673955995
Validation loss: 3.3890133853407

Epoch: 25| Step: 0
Training loss: 4.17984584615359
Validation loss: 3.388335282996179

Epoch: 6| Step: 1
Training loss: 3.3629721611383876
Validation loss: 3.387403462066696

Epoch: 6| Step: 2
Training loss: 3.9719140363766336
Validation loss: 3.3875890721236246

Epoch: 6| Step: 3
Training loss: 3.4822205866707234
Validation loss: 3.3872252302720054

Epoch: 6| Step: 4
Training loss: 3.681218632562801
Validation loss: 3.3871405007332536

Epoch: 6| Step: 5
Training loss: 3.321742281770069
Validation loss: 3.3865830515294264

Epoch: 6| Step: 6
Training loss: 4.101852203310443
Validation loss: 3.385771040752372

Epoch: 6| Step: 7
Training loss: 3.219419243134004
Validation loss: 3.3863659023771926

Epoch: 6| Step: 8
Training loss: 4.224401235192798
Validation loss: 3.3852594053534264

Epoch: 6| Step: 9
Training loss: 3.7298735618127026
Validation loss: 3.3840738687426026

Epoch: 6| Step: 10
Training loss: 3.426532101963817
Validation loss: 3.384477112344214

Epoch: 6| Step: 11
Training loss: 2.6883371513073135
Validation loss: 3.3824272786155656

Epoch: 6| Step: 12
Training loss: 3.5231175584022547
Validation loss: 3.382653791835872

Epoch: 6| Step: 13
Training loss: 3.2337557434809594
Validation loss: 3.3817580821409163

Epoch: 26| Step: 0
Training loss: 4.165721226558775
Validation loss: 3.381308251964247

Epoch: 6| Step: 1
Training loss: 3.5171264155068767
Validation loss: 3.380213983102755

Epoch: 6| Step: 2
Training loss: 3.6963138312413193
Validation loss: 3.3805495849153635

Epoch: 6| Step: 3
Training loss: 3.9356628249436034
Validation loss: 3.379605226560822

Epoch: 6| Step: 4
Training loss: 4.063777311967249
Validation loss: 3.3793236016597303

Epoch: 6| Step: 5
Training loss: 3.109602263306662
Validation loss: 3.3789621246458186

Epoch: 6| Step: 6
Training loss: 3.4605153259017336
Validation loss: 3.3787741453214073

Epoch: 6| Step: 7
Training loss: 3.999587753033288
Validation loss: 3.3786939112416925

Epoch: 6| Step: 8
Training loss: 3.639384963087293
Validation loss: 3.3769480477481624

Epoch: 6| Step: 9
Training loss: 3.2331463972762977
Validation loss: 3.3773355185124254

Epoch: 6| Step: 10
Training loss: 3.6748453016872706
Validation loss: 3.37671628372354

Epoch: 6| Step: 11
Training loss: 3.40191878983563
Validation loss: 3.376284419844675

Epoch: 6| Step: 12
Training loss: 3.3508820810087
Validation loss: 3.3755299536836847

Epoch: 6| Step: 13
Training loss: 2.6027066117795012
Validation loss: 3.3740597839140607

Epoch: 27| Step: 0
Training loss: 3.301433864385759
Validation loss: 3.3747229939080507

Epoch: 6| Step: 1
Training loss: 2.7756436881570297
Validation loss: 3.3738393136013056

Epoch: 6| Step: 2
Training loss: 3.306098510502223
Validation loss: 3.378650794804154

Epoch: 6| Step: 3
Training loss: 3.2736015187689724
Validation loss: 3.379505427132593

Epoch: 6| Step: 4
Training loss: 4.074135418311262
Validation loss: 3.3726125192943917

Epoch: 6| Step: 5
Training loss: 4.278385289858378
Validation loss: 3.371973980458414

Epoch: 6| Step: 6
Training loss: 3.284753291650945
Validation loss: 3.3714771533013668

Epoch: 6| Step: 7
Training loss: 3.3347178603763448
Validation loss: 3.3714276682175064

Epoch: 6| Step: 8
Training loss: 3.0130303640168155
Validation loss: 3.371665855757459

Epoch: 6| Step: 9
Training loss: 3.936294371087418
Validation loss: 3.3707611395577217

Epoch: 6| Step: 10
Training loss: 4.174615881147265
Validation loss: 3.37133489940736

Epoch: 6| Step: 11
Training loss: 3.952496746334544
Validation loss: 3.371264018112524

Epoch: 6| Step: 12
Training loss: 3.238505062380249
Validation loss: 3.3716979940091667

Epoch: 6| Step: 13
Training loss: 4.469025289952645
Validation loss: 3.3702377179066016

Epoch: 28| Step: 0
Training loss: 3.249648588695739
Validation loss: 3.37062350185284

Epoch: 6| Step: 1
Training loss: 4.352676769437871
Validation loss: 3.370129697912336

Epoch: 6| Step: 2
Training loss: 3.219688500921906
Validation loss: 3.36995768061648

Epoch: 6| Step: 3
Training loss: 2.9608782357195667
Validation loss: 3.3698521301948516

Epoch: 6| Step: 4
Training loss: 4.498206310949859
Validation loss: 3.370037187008589

Epoch: 6| Step: 5
Training loss: 3.4245550381725005
Validation loss: 3.3692088482408074

Epoch: 6| Step: 6
Training loss: 3.537923532749681
Validation loss: 3.368272501733455

Epoch: 6| Step: 7
Training loss: 4.093558270572827
Validation loss: 3.367785397453736

Epoch: 6| Step: 8
Training loss: 3.098625272061815
Validation loss: 3.3673970683761114

Epoch: 6| Step: 9
Training loss: 3.6530404635030695
Validation loss: 3.365606011535842

Epoch: 6| Step: 10
Training loss: 3.8951240478663323
Validation loss: 3.3663121180424924

Epoch: 6| Step: 11
Training loss: 3.4932166168380285
Validation loss: 3.364498423214156

Epoch: 6| Step: 12
Training loss: 3.002374027604779
Validation loss: 3.3637999337515105

Epoch: 6| Step: 13
Training loss: 3.4610357335187754
Validation loss: 3.3646003151000303

Epoch: 29| Step: 0
Training loss: 3.930114358883386
Validation loss: 3.3633922522237123

Epoch: 6| Step: 1
Training loss: 3.570339611793601
Validation loss: 3.362019414257234

Epoch: 6| Step: 2
Training loss: 3.5391782358541994
Validation loss: 3.3610033679442752

Epoch: 6| Step: 3
Training loss: 3.3638840333452227
Validation loss: 3.36071695442522

Epoch: 6| Step: 4
Training loss: 3.1480212823906966
Validation loss: 3.359978214030679

Epoch: 6| Step: 5
Training loss: 3.322142906546332
Validation loss: 3.3602508921691188

Epoch: 6| Step: 6
Training loss: 3.1312254883802333
Validation loss: 3.358826404219727

Epoch: 6| Step: 7
Training loss: 3.880284428543728
Validation loss: 3.35890576118164

Epoch: 6| Step: 8
Training loss: 3.580449977278683
Validation loss: 3.358433307244749

Epoch: 6| Step: 9
Training loss: 4.006822965834779
Validation loss: 3.35762089776391

Epoch: 6| Step: 10
Training loss: 3.7223844318883357
Validation loss: 3.357423519738368

Epoch: 6| Step: 11
Training loss: 4.046423691729916
Validation loss: 3.3572155417550595

Epoch: 6| Step: 12
Training loss: 3.455537117530339
Validation loss: 3.3563444684822765

Epoch: 6| Step: 13
Training loss: 3.3683683444592396
Validation loss: 3.3559868949336917

Epoch: 30| Step: 0
Training loss: 3.7110369538482297
Validation loss: 3.35491688452274

Epoch: 6| Step: 1
Training loss: 4.240832145652273
Validation loss: 3.3550836441750937

Epoch: 6| Step: 2
Training loss: 3.2049333631518224
Validation loss: 3.354331356757687

Epoch: 6| Step: 3
Training loss: 2.072432673963222
Validation loss: 3.3544877441995857

Epoch: 6| Step: 4
Training loss: 3.5574800693706954
Validation loss: 3.3545179423245552

Epoch: 6| Step: 5
Training loss: 3.6776393365558175
Validation loss: 3.3533253430820316

Epoch: 6| Step: 6
Training loss: 4.334486710058395
Validation loss: 3.3524785477401218

Epoch: 6| Step: 7
Training loss: 2.836770852129702
Validation loss: 3.352743504320537

Epoch: 6| Step: 8
Training loss: 3.216354515728888
Validation loss: 3.351994029340694

Epoch: 6| Step: 9
Training loss: 3.7698541848798803
Validation loss: 3.3515776061556553

Epoch: 6| Step: 10
Training loss: 3.640800504588103
Validation loss: 3.3500703335001196

Epoch: 6| Step: 11
Training loss: 3.733001328646661
Validation loss: 3.351057054322514

Epoch: 6| Step: 12
Training loss: 4.029430599831979
Validation loss: 3.350387805292294

Epoch: 6| Step: 13
Training loss: 3.643038886743081
Validation loss: 3.349949634597657

Epoch: 31| Step: 0
Training loss: 4.437061126927574
Validation loss: 3.3489867573928604

Epoch: 6| Step: 1
Training loss: 2.894728104336341
Validation loss: 3.3485563104483362

Epoch: 6| Step: 2
Training loss: 4.461006979058866
Validation loss: 3.34821833337714

Epoch: 6| Step: 3
Training loss: 3.6988910662844963
Validation loss: 3.3472902549225116

Epoch: 6| Step: 4
Training loss: 2.5246949266507923
Validation loss: 3.347868125291993

Epoch: 6| Step: 5
Training loss: 3.3419715215906685
Validation loss: 3.3470741441983662

Epoch: 6| Step: 6
Training loss: 3.9790820101109348
Validation loss: 3.346337731746655

Epoch: 6| Step: 7
Training loss: 3.080289128344412
Validation loss: 3.346117647524544

Epoch: 6| Step: 8
Training loss: 3.633108475636221
Validation loss: 3.344869541806533

Epoch: 6| Step: 9
Training loss: 3.5351559802313433
Validation loss: 3.344629173097486

Epoch: 6| Step: 10
Training loss: 3.3520269894571726
Validation loss: 3.345487110988459

Epoch: 6| Step: 11
Training loss: 3.9694184468756233
Validation loss: 3.3442188264331953

Epoch: 6| Step: 12
Training loss: 3.360088893531914
Validation loss: 3.345279221630408

Epoch: 6| Step: 13
Training loss: 3.1914546594018187
Validation loss: 3.344520419524073

Epoch: 32| Step: 0
Training loss: 4.336476555385175
Validation loss: 3.3429540055294487

Epoch: 6| Step: 1
Training loss: 3.9798299559493096
Validation loss: 3.343263196772557

Epoch: 6| Step: 2
Training loss: 3.363110545718741
Validation loss: 3.3423712618021546

Epoch: 6| Step: 3
Training loss: 3.2940786353373737
Validation loss: 3.3404666811204007

Epoch: 6| Step: 4
Training loss: 4.295625040139518
Validation loss: 3.3421428967294444

Epoch: 6| Step: 5
Training loss: 3.8035295357498264
Validation loss: 3.3411979546862

Epoch: 6| Step: 6
Training loss: 2.874003693813852
Validation loss: 3.3403133150275046

Epoch: 6| Step: 7
Training loss: 2.6371290551706963
Validation loss: 3.3401586325027557

Epoch: 6| Step: 8
Training loss: 3.1013789278758668
Validation loss: 3.3400732524173917

Epoch: 6| Step: 9
Training loss: 3.8132043406759624
Validation loss: 3.3390526210248686

Epoch: 6| Step: 10
Training loss: 4.3719827329219605
Validation loss: 3.3376226105458753

Epoch: 6| Step: 11
Training loss: 3.0918008848876397
Validation loss: 3.338186197536579

Epoch: 6| Step: 12
Training loss: 3.2505611522105307
Validation loss: 3.3387435619879287

Epoch: 6| Step: 13
Training loss: 3.1055330857624326
Validation loss: 3.3365761692909213

Epoch: 33| Step: 0
Training loss: 2.8254459400476652
Validation loss: 3.3377353278763104

Epoch: 6| Step: 1
Training loss: 3.9314392917588283
Validation loss: 3.3370945880469796

Epoch: 6| Step: 2
Training loss: 4.336798505096094
Validation loss: 3.338096076092049

Epoch: 6| Step: 3
Training loss: 3.4425606669480318
Validation loss: 3.337243840138364

Epoch: 6| Step: 4
Training loss: 3.8347864852016156
Validation loss: 3.335780823896188

Epoch: 6| Step: 5
Training loss: 3.236573435039414
Validation loss: 3.3360489770958073

Epoch: 6| Step: 6
Training loss: 4.053843033599655
Validation loss: 3.3357994606457315

Epoch: 6| Step: 7
Training loss: 4.030974149507057
Validation loss: 3.3354116057332512

Epoch: 6| Step: 8
Training loss: 3.3887078978632865
Validation loss: 3.3345818170909878

Epoch: 6| Step: 9
Training loss: 3.1743914764451375
Validation loss: 3.334966989602195

Epoch: 6| Step: 10
Training loss: 2.711454930244115
Validation loss: 3.333747207932835

Epoch: 6| Step: 11
Training loss: 3.470169464282666
Validation loss: 3.334045529934795

Epoch: 6| Step: 12
Training loss: 3.733996256372325
Validation loss: 3.333325343481353

Epoch: 6| Step: 13
Training loss: 3.3787713349148945
Validation loss: 3.3321346917087378

Epoch: 34| Step: 0
Training loss: 3.0707740339732927
Validation loss: 3.332065801709786

Epoch: 6| Step: 1
Training loss: 3.626711211304958
Validation loss: 3.331792289590944

Epoch: 6| Step: 2
Training loss: 3.366505706514853
Validation loss: 3.3321130285196117

Epoch: 6| Step: 3
Training loss: 3.8278321446096784
Validation loss: 3.3306889956068106

Epoch: 6| Step: 4
Training loss: 3.645954863929614
Validation loss: 3.3305138805382617

Epoch: 6| Step: 5
Training loss: 3.180203932454954
Validation loss: 3.328061614838033

Epoch: 6| Step: 6
Training loss: 3.5183209064456333
Validation loss: 3.330231129517993

Epoch: 6| Step: 7
Training loss: 3.379444445486837
Validation loss: 3.330380587587338

Epoch: 6| Step: 8
Training loss: 3.5111962121664506
Validation loss: 3.3291158341733524

Epoch: 6| Step: 9
Training loss: 3.4731563040733446
Validation loss: 3.329167330433268

Epoch: 6| Step: 10
Training loss: 3.6904869266945677
Validation loss: 3.33027594131598

Epoch: 6| Step: 11
Training loss: 4.013533110435798
Validation loss: 3.3263553850590952

Epoch: 6| Step: 12
Training loss: 3.4229205202130113
Validation loss: 3.3289348112556856

Epoch: 6| Step: 13
Training loss: 4.511336775294222
Validation loss: 3.338904073248649

Epoch: 35| Step: 0
Training loss: 3.8812834954774464
Validation loss: 3.326853285252479

Epoch: 6| Step: 1
Training loss: 2.9573740590383966
Validation loss: 3.3362279741824543

Epoch: 6| Step: 2
Training loss: 3.5007467835595505
Validation loss: 3.3755903194908474

Epoch: 6| Step: 3
Training loss: 3.624915681055655
Validation loss: 3.4064613315111765

Epoch: 6| Step: 4
Training loss: 3.6374331386228476
Validation loss: 3.3969175468965345

Epoch: 6| Step: 5
Training loss: 3.983842283053218
Validation loss: 3.394571603033207

Epoch: 6| Step: 6
Training loss: 3.5153246942051424
Validation loss: 3.377697225769047

Epoch: 6| Step: 7
Training loss: 3.178119394603126
Validation loss: 3.3572926925631092

Epoch: 6| Step: 8
Training loss: 3.27569152869282
Validation loss: 3.336260226356312

Epoch: 6| Step: 9
Training loss: 3.6195777592016483
Validation loss: 3.3518753439273405

Epoch: 6| Step: 10
Training loss: 3.595163614637813
Validation loss: 3.358096771612924

Epoch: 6| Step: 11
Training loss: 4.021143820573
Validation loss: 3.3525088297267835

Epoch: 6| Step: 12
Training loss: 3.304202934794072
Validation loss: 3.343178897449942

Epoch: 6| Step: 13
Training loss: 4.3852284346510695
Validation loss: 3.337977633823139

Epoch: 36| Step: 0
Training loss: 2.270675082044226
Validation loss: 3.3293370492224765

Epoch: 6| Step: 1
Training loss: 3.5243273370546806
Validation loss: 3.3215329232421364

Epoch: 6| Step: 2
Training loss: 3.890849279350721
Validation loss: 3.3216998971108427

Epoch: 6| Step: 3
Training loss: 3.5264341210156305
Validation loss: 3.3221748694953366

Epoch: 6| Step: 4
Training loss: 3.795669050182482
Validation loss: 3.321272130470517

Epoch: 6| Step: 5
Training loss: 3.6016125458324706
Validation loss: 3.3229851980693845

Epoch: 6| Step: 6
Training loss: 3.7938628630841627
Validation loss: 3.3234770650082335

Epoch: 6| Step: 7
Training loss: 3.8857702890335326
Validation loss: 3.321476267750085

Epoch: 6| Step: 8
Training loss: 3.197752974273131
Validation loss: 3.32036508633148

Epoch: 6| Step: 9
Training loss: 4.394408852462144
Validation loss: 3.3194154005930647

Epoch: 6| Step: 10
Training loss: 3.469871683304181
Validation loss: 3.319247421277055

Epoch: 6| Step: 11
Training loss: 3.5668585366189482
Validation loss: 3.3159758815921645

Epoch: 6| Step: 12
Training loss: 2.543400928437331
Validation loss: 3.315065714846864

Epoch: 6| Step: 13
Training loss: 4.085682381420585
Validation loss: 3.316157655206172

Epoch: 37| Step: 0
Training loss: 3.517718560668308
Validation loss: 3.3186968734787308

Epoch: 6| Step: 1
Training loss: 3.276000992482539
Validation loss: 3.318322515829489

Epoch: 6| Step: 2
Training loss: 2.9191684529129067
Validation loss: 3.3218479979504667

Epoch: 6| Step: 3
Training loss: 3.0519579621865867
Validation loss: 3.323087080653686

Epoch: 6| Step: 4
Training loss: 4.600260163289278
Validation loss: 3.3196289470720455

Epoch: 6| Step: 5
Training loss: 4.398909711136217
Validation loss: 3.3178026088036896

Epoch: 6| Step: 6
Training loss: 3.4895497031038443
Validation loss: 3.316087848835258

Epoch: 6| Step: 7
Training loss: 3.3764847209397746
Validation loss: 3.313694879072777

Epoch: 6| Step: 8
Training loss: 3.3046427694409215
Validation loss: 3.312802822351415

Epoch: 6| Step: 9
Training loss: 3.119573229921173
Validation loss: 3.311747763707853

Epoch: 6| Step: 10
Training loss: 3.814055328799972
Validation loss: 3.3120107647414376

Epoch: 6| Step: 11
Training loss: 3.0053142526737897
Validation loss: 3.3117479247216974

Epoch: 6| Step: 12
Training loss: 3.881572440939086
Validation loss: 3.3130941463745693

Epoch: 6| Step: 13
Training loss: 3.6216012214356916
Validation loss: 3.309936996166181

Epoch: 38| Step: 0
Training loss: 2.787721712335804
Validation loss: 3.309267215266613

Epoch: 6| Step: 1
Training loss: 2.943352246797938
Validation loss: 3.3094343958763615

Epoch: 6| Step: 2
Training loss: 3.145992872895779
Validation loss: 3.3074623632947855

Epoch: 6| Step: 3
Training loss: 4.348238594969713
Validation loss: 3.306391930210317

Epoch: 6| Step: 4
Training loss: 2.6460775027411225
Validation loss: 3.3069753472165875

Epoch: 6| Step: 5
Training loss: 4.07903317683429
Validation loss: 3.306366306047843

Epoch: 6| Step: 6
Training loss: 3.6456400502151087
Validation loss: 3.3050988841466244

Epoch: 6| Step: 7
Training loss: 3.5964969916944307
Validation loss: 3.3048998183818106

Epoch: 6| Step: 8
Training loss: 4.4189780083389865
Validation loss: 3.305397711607047

Epoch: 6| Step: 9
Training loss: 3.6009213751991602
Validation loss: 3.304219215665321

Epoch: 6| Step: 10
Training loss: 3.426078270244679
Validation loss: 3.3038061157351084

Epoch: 6| Step: 11
Training loss: 3.4257152729357974
Validation loss: 3.303940643743047

Epoch: 6| Step: 12
Training loss: 3.5109821773414596
Validation loss: 3.303028500258045

Epoch: 6| Step: 13
Training loss: 3.6444866345323135
Validation loss: 3.302886151554699

Epoch: 39| Step: 0
Training loss: 2.2294671637475436
Validation loss: 3.302711114780715

Epoch: 6| Step: 1
Training loss: 3.9679803777870952
Validation loss: 3.303156301503173

Epoch: 6| Step: 2
Training loss: 3.250116052756313
Validation loss: 3.300930339089104

Epoch: 6| Step: 3
Training loss: 3.4918704304990404
Validation loss: 3.3009787235215695

Epoch: 6| Step: 4
Training loss: 3.1025287650816677
Validation loss: 3.3009998509090828

Epoch: 6| Step: 5
Training loss: 3.400684534612859
Validation loss: 3.301292819875461

Epoch: 6| Step: 6
Training loss: 3.852905039452957
Validation loss: 3.3004796774267575

Epoch: 6| Step: 7
Training loss: 3.6969346726052303
Validation loss: 3.3001293936973517

Epoch: 6| Step: 8
Training loss: 2.608392770433286
Validation loss: 3.301566707782589

Epoch: 6| Step: 9
Training loss: 4.042088804451996
Validation loss: 3.299366658583992

Epoch: 6| Step: 10
Training loss: 4.543925269103387
Validation loss: 3.2982854772577452

Epoch: 6| Step: 11
Training loss: 3.6994405839059095
Validation loss: 3.2999752141320635

Epoch: 6| Step: 12
Training loss: 3.902634923876439
Validation loss: 3.297631055007696

Epoch: 6| Step: 13
Training loss: 2.799261428290469
Validation loss: 3.296690449255968

Epoch: 40| Step: 0
Training loss: 3.908676126463342
Validation loss: 3.301463487843882

Epoch: 6| Step: 1
Training loss: 3.094363681539054
Validation loss: 3.301976934160063

Epoch: 6| Step: 2
Training loss: 3.898647386791117
Validation loss: 3.2966973531427843

Epoch: 6| Step: 3
Training loss: 2.553277329344471
Validation loss: 3.296178900850785

Epoch: 6| Step: 4
Training loss: 2.7934568178776575
Validation loss: 3.2941543557861213

Epoch: 6| Step: 5
Training loss: 3.0061847195903213
Validation loss: 3.294031682741842

Epoch: 6| Step: 6
Training loss: 3.7715134542994693
Validation loss: 3.2953856583508983

Epoch: 6| Step: 7
Training loss: 3.877448877111947
Validation loss: 3.2943254589432

Epoch: 6| Step: 8
Training loss: 3.9554746377242993
Validation loss: 3.2930947400839132

Epoch: 6| Step: 9
Training loss: 3.676168844967405
Validation loss: 3.2939837846456546

Epoch: 6| Step: 10
Training loss: 3.0037062321655874
Validation loss: 3.293829550907818

Epoch: 6| Step: 11
Training loss: 3.93807833829333
Validation loss: 3.291919661664948

Epoch: 6| Step: 12
Training loss: 4.323073320729289
Validation loss: 3.2917994722549113

Epoch: 6| Step: 13
Training loss: 2.9285321615158533
Validation loss: 3.291880452036318

Epoch: 41| Step: 0
Training loss: 3.439687691639406
Validation loss: 3.2918901680432735

Epoch: 6| Step: 1
Training loss: 3.9486354015949616
Validation loss: 3.289965555416114

Epoch: 6| Step: 2
Training loss: 3.2998389349269703
Validation loss: 3.2889100091227057

Epoch: 6| Step: 3
Training loss: 3.909150046532329
Validation loss: 3.289029897247097

Epoch: 6| Step: 4
Training loss: 3.2132825618178242
Validation loss: 3.289102505508876

Epoch: 6| Step: 5
Training loss: 3.9024807253941374
Validation loss: 3.2902240502164024

Epoch: 6| Step: 6
Training loss: 4.149863937169686
Validation loss: 3.2891206584930215

Epoch: 6| Step: 7
Training loss: 3.56218423615169
Validation loss: 3.2893293809936544

Epoch: 6| Step: 8
Training loss: 3.563382223547419
Validation loss: 3.286910358466809

Epoch: 6| Step: 9
Training loss: 4.633670412238856
Validation loss: 3.288708167412294

Epoch: 6| Step: 10
Training loss: 1.6869450822358552
Validation loss: 3.2864716531217653

Epoch: 6| Step: 11
Training loss: 3.0381983138771242
Validation loss: 3.284281115931063

Epoch: 6| Step: 12
Training loss: 3.277720414933104
Validation loss: 3.286032889206894

Epoch: 6| Step: 13
Training loss: 2.42969692019878
Validation loss: 3.2876591496409544

Epoch: 42| Step: 0
Training loss: 3.3457451688014292
Validation loss: 3.2872056172729534

Epoch: 6| Step: 1
Training loss: 3.8933226030889903
Validation loss: 3.287416993485261

Epoch: 6| Step: 2
Training loss: 2.926812065469382
Validation loss: 3.288124966273502

Epoch: 6| Step: 3
Training loss: 3.9734846093568676
Validation loss: 3.2872004201186864

Epoch: 6| Step: 4
Training loss: 4.0902422371086455
Validation loss: 3.2858297191697354

Epoch: 6| Step: 5
Training loss: 4.373543415102242
Validation loss: 3.286544626798153

Epoch: 6| Step: 6
Training loss: 3.4618702615353216
Validation loss: 3.2870309965003797

Epoch: 6| Step: 7
Training loss: 2.1605147052274156
Validation loss: 3.286510630861166

Epoch: 6| Step: 8
Training loss: 3.3364809116278824
Validation loss: 3.2848554000861236

Epoch: 6| Step: 9
Training loss: 3.4568210343924894
Validation loss: 3.284550204809767

Epoch: 6| Step: 10
Training loss: 3.8442642984342035
Validation loss: 3.2851362381053772

Epoch: 6| Step: 11
Training loss: 3.175584249732392
Validation loss: 3.2829951304573592

Epoch: 6| Step: 12
Training loss: 3.3748556035553037
Validation loss: 3.284986327626055

Epoch: 6| Step: 13
Training loss: 3.3404471939771048
Validation loss: 3.2830105388379085

Epoch: 43| Step: 0
Training loss: 3.679754106765136
Validation loss: 3.2798373680303934

Epoch: 6| Step: 1
Training loss: 3.795351829654829
Validation loss: 3.2790292157679386

Epoch: 6| Step: 2
Training loss: 3.372660921299898
Validation loss: 3.27997812367619

Epoch: 6| Step: 3
Training loss: 3.8821896949656844
Validation loss: 3.2768346500179897

Epoch: 6| Step: 4
Training loss: 4.196874800033735
Validation loss: 3.2757540004173205

Epoch: 6| Step: 5
Training loss: 3.3039867478813805
Validation loss: 3.2783009759730892

Epoch: 6| Step: 6
Training loss: 3.6099555799546352
Validation loss: 3.278645521607649

Epoch: 6| Step: 7
Training loss: 3.203928181504125
Validation loss: 3.2749959462671554

Epoch: 6| Step: 8
Training loss: 3.177409787942099
Validation loss: 3.275582555631943

Epoch: 6| Step: 9
Training loss: 4.19112410222298
Validation loss: 3.276840874410644

Epoch: 6| Step: 10
Training loss: 2.910805853724809
Validation loss: 3.2754270515473616

Epoch: 6| Step: 11
Training loss: 2.620482053599548
Validation loss: 3.2763024128929987

Epoch: 6| Step: 12
Training loss: 3.3521642611549702
Validation loss: 3.275798101807293

Epoch: 6| Step: 13
Training loss: 3.7790667323337437
Validation loss: 3.2747324760616108

Epoch: 44| Step: 0
Training loss: 3.5744394036227414
Validation loss: 3.2776914192611177

Epoch: 6| Step: 1
Training loss: 3.0030649740867124
Validation loss: 3.2748307776863537

Epoch: 6| Step: 2
Training loss: 4.198955069846409
Validation loss: 3.275167093004257

Epoch: 6| Step: 3
Training loss: 3.8291878606619982
Validation loss: 3.2754610294648265

Epoch: 6| Step: 4
Training loss: 3.60604057034453
Validation loss: 3.27555079233664

Epoch: 6| Step: 5
Training loss: 4.133569312793953
Validation loss: 3.2754735985125434

Epoch: 6| Step: 6
Training loss: 3.060371126096206
Validation loss: 3.2748001390844332

Epoch: 6| Step: 7
Training loss: 2.7776555182784377
Validation loss: 3.2757892130208237

Epoch: 6| Step: 8
Training loss: 3.2299237420023386
Validation loss: 3.2770675591105585

Epoch: 6| Step: 9
Training loss: 2.965993143270519
Validation loss: 3.2766564502489404

Epoch: 6| Step: 10
Training loss: 4.091470098079242
Validation loss: 3.279127705998212

Epoch: 6| Step: 11
Training loss: 3.2248886976330797
Validation loss: 3.280065721440671

Epoch: 6| Step: 12
Training loss: 2.804145441829925
Validation loss: 3.2748959837684244

Epoch: 6| Step: 13
Training loss: 4.67918859506679
Validation loss: 3.2715904379046545

Epoch: 45| Step: 0
Training loss: 3.5310263773911448
Validation loss: 3.2735732352883353

Epoch: 6| Step: 1
Training loss: 3.916583012979374
Validation loss: 3.270375706423575

Epoch: 6| Step: 2
Training loss: 3.845342538802318
Validation loss: 3.27104858532467

Epoch: 6| Step: 3
Training loss: 3.763549992755993
Validation loss: 3.2699966118105004

Epoch: 6| Step: 4
Training loss: 3.8181645570505203
Validation loss: 3.2671092799794503

Epoch: 6| Step: 5
Training loss: 3.741704411872049
Validation loss: 3.269593376033709

Epoch: 6| Step: 6
Training loss: 2.228344441825818
Validation loss: 3.2671869970624647

Epoch: 6| Step: 7
Training loss: 3.9481623563921024
Validation loss: 3.2664745693928827

Epoch: 6| Step: 8
Training loss: 3.2115804580760994
Validation loss: 3.2681971603778877

Epoch: 6| Step: 9
Training loss: 3.3467195818493205
Validation loss: 3.2665823167048513

Epoch: 6| Step: 10
Training loss: 3.7078605664815325
Validation loss: 3.266463445135378

Epoch: 6| Step: 11
Training loss: 3.9369068001666285
Validation loss: 3.2662072784944147

Epoch: 6| Step: 12
Training loss: 3.0941260523501675
Validation loss: 3.2666821357213456

Epoch: 6| Step: 13
Training loss: 1.453110725578831
Validation loss: 3.265647993690292

Epoch: 46| Step: 0
Training loss: 3.48214828434895
Validation loss: 3.2654062967123285

Epoch: 6| Step: 1
Training loss: 3.800064819184652
Validation loss: 3.265221021004628

Epoch: 6| Step: 2
Training loss: 3.6673772007849035
Validation loss: 3.2645033158035406

Epoch: 6| Step: 3
Training loss: 3.5667439663315204
Validation loss: 3.2642012755074723

Epoch: 6| Step: 4
Training loss: 3.7659509288246746
Validation loss: 3.263197470618641

Epoch: 6| Step: 5
Training loss: 3.2557151135462896
Validation loss: 3.268591488273727

Epoch: 6| Step: 6
Training loss: 3.4985272169854964
Validation loss: 3.2885805343485797

Epoch: 6| Step: 7
Training loss: 1.8968619256613812
Validation loss: 3.304636637754142

Epoch: 6| Step: 8
Training loss: 3.87778569657599
Validation loss: 3.3442075376277445

Epoch: 6| Step: 9
Training loss: 3.6627780639498146
Validation loss: 3.3219843481784324

Epoch: 6| Step: 10
Training loss: 4.033375497602856
Validation loss: 3.2694558939504437

Epoch: 6| Step: 11
Training loss: 3.7574125144454045
Validation loss: 3.261573538821608

Epoch: 6| Step: 12
Training loss: 3.240898740237068
Validation loss: 3.26038594555619

Epoch: 6| Step: 13
Training loss: 3.060536747899247
Validation loss: 3.262821814701824

Epoch: 47| Step: 0
Training loss: 2.7850333209415794
Validation loss: 3.2605843465341366

Epoch: 6| Step: 1
Training loss: 3.4516189536040773
Validation loss: 3.270343640139034

Epoch: 6| Step: 2
Training loss: 3.783895654663117
Validation loss: 3.2837094263687154

Epoch: 6| Step: 3
Training loss: 4.132852651476745
Validation loss: 3.2660356873633876

Epoch: 6| Step: 4
Training loss: 2.6863090182744425
Validation loss: 3.258225919630833

Epoch: 6| Step: 5
Training loss: 3.0079123740520743
Validation loss: 3.2620006415643004

Epoch: 6| Step: 6
Training loss: 3.1743521202060494
Validation loss: 3.2640538138114166

Epoch: 6| Step: 7
Training loss: 3.2847225161429754
Validation loss: 3.2607034143477573

Epoch: 6| Step: 8
Training loss: 4.399675591387193
Validation loss: 3.2718904452661555

Epoch: 6| Step: 9
Training loss: 3.5756939621269344
Validation loss: 3.271325997522978

Epoch: 6| Step: 10
Training loss: 3.6735612609083415
Validation loss: 3.26931977129307

Epoch: 6| Step: 11
Training loss: 4.016319838200714
Validation loss: 3.2662365880363153

Epoch: 6| Step: 12
Training loss: 3.7072555747458757
Validation loss: 3.261997923884574

Epoch: 6| Step: 13
Training loss: 2.587740174724569
Validation loss: 3.260193732062983

Epoch: 48| Step: 0
Training loss: 4.207021729184909
Validation loss: 3.2618800083554667

Epoch: 6| Step: 1
Training loss: 3.3478063774498
Validation loss: 3.25647058807941

Epoch: 6| Step: 2
Training loss: 3.9358761784530594
Validation loss: 3.2596203393965815

Epoch: 6| Step: 3
Training loss: 3.451123239965742
Validation loss: 3.258935401513934

Epoch: 6| Step: 4
Training loss: 3.589609165434489
Validation loss: 3.2556848305065724

Epoch: 6| Step: 5
Training loss: 4.469417068737955
Validation loss: 3.2557793859197823

Epoch: 6| Step: 6
Training loss: 3.261352957127136
Validation loss: 3.254030235615097

Epoch: 6| Step: 7
Training loss: 3.3538963888197975
Validation loss: 3.2537718294821194

Epoch: 6| Step: 8
Training loss: 2.730201544396029
Validation loss: 3.2566275200417176

Epoch: 6| Step: 9
Training loss: 2.5052895853318176
Validation loss: 3.2568748291121876

Epoch: 6| Step: 10
Training loss: 3.659558356274166
Validation loss: 3.2567864044929697

Epoch: 6| Step: 11
Training loss: 3.4358914860120224
Validation loss: 3.2568891425695123

Epoch: 6| Step: 12
Training loss: 2.9074855352092763
Validation loss: 3.2564705518661334

Epoch: 6| Step: 13
Training loss: 3.6903878235089103
Validation loss: 3.2555334756552687

Epoch: 49| Step: 0
Training loss: 3.9627511651856437
Validation loss: 3.2544484123281476

Epoch: 6| Step: 1
Training loss: 3.56525929988651
Validation loss: 3.2558788818138793

Epoch: 6| Step: 2
Training loss: 3.8068622115550905
Validation loss: 3.2537222403737514

Epoch: 6| Step: 3
Training loss: 2.7921546870066307
Validation loss: 3.2554626008515473

Epoch: 6| Step: 4
Training loss: 3.769728960771995
Validation loss: 3.2562612512944558

Epoch: 6| Step: 5
Training loss: 2.8752399841988563
Validation loss: 3.2556486460860063

Epoch: 6| Step: 6
Training loss: 3.6248471458041283
Validation loss: 3.2531364395088467

Epoch: 6| Step: 7
Training loss: 3.720375154713444
Validation loss: 3.253763551814173

Epoch: 6| Step: 8
Training loss: 3.2146933463640397
Validation loss: 3.2537000464461903

Epoch: 6| Step: 9
Training loss: 3.072934028878167
Validation loss: 3.2485007984470555

Epoch: 6| Step: 10
Training loss: 3.650316689744166
Validation loss: 3.2479703416897303

Epoch: 6| Step: 11
Training loss: 4.024692850655098
Validation loss: 3.247831705124769

Epoch: 6| Step: 12
Training loss: 3.4778715605137958
Validation loss: 3.2463036603029503

Epoch: 6| Step: 13
Training loss: 2.6301132537476524
Validation loss: 3.248710082903488

Epoch: 50| Step: 0
Training loss: 3.2090077042384637
Validation loss: 3.2551324120640723

Epoch: 6| Step: 1
Training loss: 4.0188222543441405
Validation loss: 3.2505140331904427

Epoch: 6| Step: 2
Training loss: 3.3232695931227454
Validation loss: 3.2577160740115136

Epoch: 6| Step: 3
Training loss: 3.7380041898700873
Validation loss: 3.2575638581423068

Epoch: 6| Step: 4
Training loss: 3.222879224057099
Validation loss: 3.2506024281128036

Epoch: 6| Step: 5
Training loss: 3.4027823900117995
Validation loss: 3.250928518968106

Epoch: 6| Step: 6
Training loss: 3.2496904078992483
Validation loss: 3.251158357201798

Epoch: 6| Step: 7
Training loss: 3.1279417306297193
Validation loss: 3.2512410462899948

Epoch: 6| Step: 8
Training loss: 3.2195224760917664
Validation loss: 3.2465576165824315

Epoch: 6| Step: 9
Training loss: 3.3972056293749477
Validation loss: 3.247572393713036

Epoch: 6| Step: 10
Training loss: 4.155280896548828
Validation loss: 3.2426836219584088

Epoch: 6| Step: 11
Training loss: 3.801359816736483
Validation loss: 3.2428273595173565

Epoch: 6| Step: 12
Training loss: 3.647084804275886
Validation loss: 3.2421354469284873

Epoch: 6| Step: 13
Training loss: 2.7918270311745803
Validation loss: 3.2414326241312676

Epoch: 51| Step: 0
Training loss: 2.4804655780922142
Validation loss: 3.239910007309689

Epoch: 6| Step: 1
Training loss: 2.741051245571153
Validation loss: 3.2409449881318575

Epoch: 6| Step: 2
Training loss: 3.1545317854671335
Validation loss: 3.2399529729362557

Epoch: 6| Step: 3
Training loss: 4.029476988294428
Validation loss: 3.239758099074094

Epoch: 6| Step: 4
Training loss: 3.59114444650573
Validation loss: 3.2406255378176447

Epoch: 6| Step: 5
Training loss: 3.1871660843021314
Validation loss: 3.239993716167624

Epoch: 6| Step: 6
Training loss: 3.1409304645836413
Validation loss: 3.240956718883832

Epoch: 6| Step: 7
Training loss: 4.109087683783053
Validation loss: 3.2474032662133223

Epoch: 6| Step: 8
Training loss: 2.7931302537439753
Validation loss: 3.2418773907562515

Epoch: 6| Step: 9
Training loss: 3.764071195409477
Validation loss: 3.239736121261447

Epoch: 6| Step: 10
Training loss: 4.136598176432732
Validation loss: 3.2380316214173335

Epoch: 6| Step: 11
Training loss: 3.877832669437685
Validation loss: 3.2384178160235995

Epoch: 6| Step: 12
Training loss: 3.7846395889889544
Validation loss: 3.2379540849723507

Epoch: 6| Step: 13
Training loss: 3.419139447948001
Validation loss: 3.2365933297722953

Epoch: 52| Step: 0
Training loss: 4.327462817053822
Validation loss: 3.2374098683148618

Epoch: 6| Step: 1
Training loss: 3.449049257496861
Validation loss: 3.235884605981523

Epoch: 6| Step: 2
Training loss: 3.274743304493827
Validation loss: 3.2345404146449765

Epoch: 6| Step: 3
Training loss: 3.6856903549591844
Validation loss: 3.2341708819905883

Epoch: 6| Step: 4
Training loss: 3.8588043903043125
Validation loss: 3.234913030674077

Epoch: 6| Step: 5
Training loss: 3.671803834915423
Validation loss: 3.234513213093815

Epoch: 6| Step: 6
Training loss: 3.3407095517484104
Validation loss: 3.233370490558915

Epoch: 6| Step: 7
Training loss: 3.6665041338414666
Validation loss: 3.2330909444264475

Epoch: 6| Step: 8
Training loss: 3.2062700415983176
Validation loss: 3.2346339158547446

Epoch: 6| Step: 9
Training loss: 3.0127951829577007
Validation loss: 3.2339949465555455

Epoch: 6| Step: 10
Training loss: 3.4468756695605793
Validation loss: 3.2329339531657157

Epoch: 6| Step: 11
Training loss: 2.3775347183853457
Validation loss: 3.23304941165363

Epoch: 6| Step: 12
Training loss: 3.364552752628457
Validation loss: 3.232425964231934

Epoch: 6| Step: 13
Training loss: 3.8043892056128015
Validation loss: 3.2320405520096083

Epoch: 53| Step: 0
Training loss: 3.697954003946996
Validation loss: 3.2329174893458004

Epoch: 6| Step: 1
Training loss: 3.9859613589085274
Validation loss: 3.23174351274956

Epoch: 6| Step: 2
Training loss: 2.9988738171424583
Validation loss: 3.231802831244157

Epoch: 6| Step: 3
Training loss: 2.9583559886082798
Validation loss: 3.228286993833528

Epoch: 6| Step: 4
Training loss: 3.3750726197518524
Validation loss: 3.230117805969219

Epoch: 6| Step: 5
Training loss: 4.213595031224311
Validation loss: 3.2284650476373233

Epoch: 6| Step: 6
Training loss: 2.9672999002662532
Validation loss: 3.226836014784625

Epoch: 6| Step: 7
Training loss: 3.302371825763741
Validation loss: 3.2284056773435954

Epoch: 6| Step: 8
Training loss: 3.259768258031441
Validation loss: 3.229197266136312

Epoch: 6| Step: 9
Training loss: 3.9138456425391954
Validation loss: 3.2263636453408533

Epoch: 6| Step: 10
Training loss: 2.445472590169438
Validation loss: 3.228177483111399

Epoch: 6| Step: 11
Training loss: 3.431481381034114
Validation loss: 3.2278115426433507

Epoch: 6| Step: 12
Training loss: 4.19806533941459
Validation loss: 3.228054113522746

Epoch: 6| Step: 13
Training loss: 3.297570177883098
Validation loss: 3.227352288107767

Epoch: 54| Step: 0
Training loss: 2.7079994484916363
Validation loss: 3.2270692320490113

Epoch: 6| Step: 1
Training loss: 4.158515943494136
Validation loss: 3.2297064185537847

Epoch: 6| Step: 2
Training loss: 3.584490448772845
Validation loss: 3.229704996913303

Epoch: 6| Step: 3
Training loss: 2.992474016859152
Validation loss: 3.2326466513594503

Epoch: 6| Step: 4
Training loss: 3.3670617454040372
Validation loss: 3.231864130161608

Epoch: 6| Step: 5
Training loss: 4.0858310663718935
Validation loss: 3.2297095015508703

Epoch: 6| Step: 6
Training loss: 2.4985101074967027
Validation loss: 3.2288214640267707

Epoch: 6| Step: 7
Training loss: 4.396032729605823
Validation loss: 3.2274352217330127

Epoch: 6| Step: 8
Training loss: 2.174283236206258
Validation loss: 3.2271323399671052

Epoch: 6| Step: 9
Training loss: 3.627351721500771
Validation loss: 3.227029952625515

Epoch: 6| Step: 10
Training loss: 3.968839148774207
Validation loss: 3.2254773079193657

Epoch: 6| Step: 11
Training loss: 3.526023034516565
Validation loss: 3.2229577372391125

Epoch: 6| Step: 12
Training loss: 3.6393522076005227
Validation loss: 3.2246190869939815

Epoch: 6| Step: 13
Training loss: 2.6246859953038366
Validation loss: 3.2244073165950966

Epoch: 55| Step: 0
Training loss: 3.1598360444039892
Validation loss: 3.222827107315031

Epoch: 6| Step: 1
Training loss: 3.1152218235444638
Validation loss: 3.2243212360243985

Epoch: 6| Step: 2
Training loss: 3.3979253273359857
Validation loss: 3.226012749022996

Epoch: 6| Step: 3
Training loss: 4.2029847756290915
Validation loss: 3.23145851368056

Epoch: 6| Step: 4
Training loss: 3.4817012912117526
Validation loss: 3.2236252479354994

Epoch: 6| Step: 5
Training loss: 3.2782507858653607
Validation loss: 3.220521599625533

Epoch: 6| Step: 6
Training loss: 4.075846419161642
Validation loss: 3.2209280251136394

Epoch: 6| Step: 7
Training loss: 3.7460387606756522
Validation loss: 3.220433229226488

Epoch: 6| Step: 8
Training loss: 3.3218208028655156
Validation loss: 3.2202570519556204

Epoch: 6| Step: 9
Training loss: 2.9016822276683247
Validation loss: 3.219905940799031

Epoch: 6| Step: 10
Training loss: 3.3507423375494696
Validation loss: 3.2182614076809184

Epoch: 6| Step: 11
Training loss: 3.48795398232088
Validation loss: 3.2173392827031972

Epoch: 6| Step: 12
Training loss: 3.019837910426489
Validation loss: 3.2188152956131484

Epoch: 6| Step: 13
Training loss: 3.826966651518021
Validation loss: 3.218528496216925

Epoch: 56| Step: 0
Training loss: 3.4803980553636817
Validation loss: 3.217695086235769

Epoch: 6| Step: 1
Training loss: 3.0876521887703543
Validation loss: 3.2176700815015833

Epoch: 6| Step: 2
Training loss: 3.983437222092995
Validation loss: 3.2185916895553213

Epoch: 6| Step: 3
Training loss: 2.6872091801338076
Validation loss: 3.215764471590494

Epoch: 6| Step: 4
Training loss: 2.9983251982983727
Validation loss: 3.216567951247423

Epoch: 6| Step: 5
Training loss: 3.4192595218995274
Validation loss: 3.2182534983112547

Epoch: 6| Step: 6
Training loss: 3.768255937116956
Validation loss: 3.217783861670749

Epoch: 6| Step: 7
Training loss: 3.977321709665656
Validation loss: 3.218422007732134

Epoch: 6| Step: 8
Training loss: 3.241712714671504
Validation loss: 3.218214620318259

Epoch: 6| Step: 9
Training loss: 3.7499127695746397
Validation loss: 3.217183344416279

Epoch: 6| Step: 10
Training loss: 3.606633189452018
Validation loss: 3.2170809560024387

Epoch: 6| Step: 11
Training loss: 2.938901526318377
Validation loss: 3.216038158192413

Epoch: 6| Step: 12
Training loss: 3.568182178225607
Validation loss: 3.222536805824

Epoch: 6| Step: 13
Training loss: 3.6743903452381983
Validation loss: 3.225892340378062

Epoch: 57| Step: 0
Training loss: 3.63327384398402
Validation loss: 3.2409345735932082

Epoch: 6| Step: 1
Training loss: 3.0415408661489494
Validation loss: 3.2178002547343034

Epoch: 6| Step: 2
Training loss: 3.3220600869694614
Validation loss: 3.2149111519972386

Epoch: 6| Step: 3
Training loss: 3.3868748893956
Validation loss: 3.2097175263988635

Epoch: 6| Step: 4
Training loss: 3.5503095894798165
Validation loss: 3.2094247035416688

Epoch: 6| Step: 5
Training loss: 3.949153065724781
Validation loss: 3.2115538459433117

Epoch: 6| Step: 6
Training loss: 3.210273469821161
Validation loss: 3.214371393985426

Epoch: 6| Step: 7
Training loss: 2.6579839993089265
Validation loss: 3.2116218757525483

Epoch: 6| Step: 8
Training loss: 3.1239701672251754
Validation loss: 3.213208111016688

Epoch: 6| Step: 9
Training loss: 3.4786065082789857
Validation loss: 3.2092350751432788

Epoch: 6| Step: 10
Training loss: 4.559789191944687
Validation loss: 3.2065684755916397

Epoch: 6| Step: 11
Training loss: 2.866627984192553
Validation loss: 3.207747831217666

Epoch: 6| Step: 12
Training loss: 3.487892188987078
Validation loss: 3.207410770561655

Epoch: 6| Step: 13
Training loss: 3.91693071056998
Validation loss: 3.2052619438792602

Epoch: 58| Step: 0
Training loss: 3.0294959902424394
Validation loss: 3.2064680972207595

Epoch: 6| Step: 1
Training loss: 4.409518713606342
Validation loss: 3.205141758696846

Epoch: 6| Step: 2
Training loss: 3.3184884120916442
Validation loss: 3.204618510072466

Epoch: 6| Step: 3
Training loss: 3.2745245901510507
Validation loss: 3.2069689648060287

Epoch: 6| Step: 4
Training loss: 3.16130371385994
Validation loss: 3.2064739928879216

Epoch: 6| Step: 5
Training loss: 3.5937770676630105
Validation loss: 3.2080316938481976

Epoch: 6| Step: 6
Training loss: 3.986728825632109
Validation loss: 3.2089387082557574

Epoch: 6| Step: 7
Training loss: 2.9962385756840177
Validation loss: 3.2129797342545867

Epoch: 6| Step: 8
Training loss: 2.537286600995887
Validation loss: 3.2148329255496453

Epoch: 6| Step: 9
Training loss: 3.256782496984718
Validation loss: 3.214842858463474

Epoch: 6| Step: 10
Training loss: 3.9203378773092536
Validation loss: 3.2133431114599795

Epoch: 6| Step: 11
Training loss: 3.510397046012644
Validation loss: 3.2017219469920897

Epoch: 6| Step: 12
Training loss: 3.451708196601692
Validation loss: 3.197027484366772

Epoch: 6| Step: 13
Training loss: 3.505867535679917
Validation loss: 3.194783703921725

Epoch: 59| Step: 0
Training loss: 3.005104173323996
Validation loss: 3.1936497294659385

Epoch: 6| Step: 1
Training loss: 2.8059060682479315
Validation loss: 3.193234199397942

Epoch: 6| Step: 2
Training loss: 2.946825362401325
Validation loss: 3.1916954897610403

Epoch: 6| Step: 3
Training loss: 3.585880320639577
Validation loss: 3.189562961392239

Epoch: 6| Step: 4
Training loss: 3.8000628114829653
Validation loss: 3.190470209808555

Epoch: 6| Step: 5
Training loss: 3.6833696671386873
Validation loss: 3.186835790635002

Epoch: 6| Step: 6
Training loss: 3.2732221946831843
Validation loss: 3.186134188922619

Epoch: 6| Step: 7
Training loss: 3.5487101508493493
Validation loss: 3.184898658124478

Epoch: 6| Step: 8
Training loss: 3.513096828595449
Validation loss: 3.182864642858505

Epoch: 6| Step: 9
Training loss: 3.877296751538023
Validation loss: 3.184168946433787

Epoch: 6| Step: 10
Training loss: 3.6008367572660145
Validation loss: 3.187006690827342

Epoch: 6| Step: 11
Training loss: 3.7014429320270135
Validation loss: 3.1836713573952378

Epoch: 6| Step: 12
Training loss: 3.568274653054861
Validation loss: 3.182947926984792

Epoch: 6| Step: 13
Training loss: 2.5527012187319293
Validation loss: 3.1828332148214877

Epoch: 60| Step: 0
Training loss: 3.321747162477268
Validation loss: 3.1836069337919266

Epoch: 6| Step: 1
Training loss: 3.466897555756353
Validation loss: 3.1835261455690604

Epoch: 6| Step: 2
Training loss: 3.592358394372444
Validation loss: 3.1799224712677443

Epoch: 6| Step: 3
Training loss: 2.5876367062929995
Validation loss: 3.179871164543223

Epoch: 6| Step: 4
Training loss: 3.978877564691415
Validation loss: 3.1799067520201496

Epoch: 6| Step: 5
Training loss: 3.2918411079894216
Validation loss: 3.1787420619202402

Epoch: 6| Step: 6
Training loss: 4.13194245552991
Validation loss: 3.178628058534713

Epoch: 6| Step: 7
Training loss: 2.7007014705581494
Validation loss: 3.178254898182984

Epoch: 6| Step: 8
Training loss: 3.1576335631669297
Validation loss: 3.1777159318100643

Epoch: 6| Step: 9
Training loss: 3.9845815567629077
Validation loss: 3.178833439753972

Epoch: 6| Step: 10
Training loss: 3.238650826599827
Validation loss: 3.1770346011266133

Epoch: 6| Step: 11
Training loss: 4.443947205278846
Validation loss: 3.1759566890393636

Epoch: 6| Step: 12
Training loss: 2.429145678979713
Validation loss: 3.1763099545445233

Epoch: 6| Step: 13
Training loss: 2.5511909845115723
Validation loss: 3.1758897663919043

Epoch: 61| Step: 0
Training loss: 2.8013455768095534
Validation loss: 3.176215861546979

Epoch: 6| Step: 1
Training loss: 3.5514573396754563
Validation loss: 3.174986323581599

Epoch: 6| Step: 2
Training loss: 4.023384642022328
Validation loss: 3.1738351765973154

Epoch: 6| Step: 3
Training loss: 3.793006967495413
Validation loss: 3.1767754728188016

Epoch: 6| Step: 4
Training loss: 3.90577670472536
Validation loss: 3.1763046453516437

Epoch: 6| Step: 5
Training loss: 2.8798342985592424
Validation loss: 3.17657069618233

Epoch: 6| Step: 6
Training loss: 3.306423732180816
Validation loss: 3.177008130524838

Epoch: 6| Step: 7
Training loss: 3.485771959752317
Validation loss: 3.1750650860587184

Epoch: 6| Step: 8
Training loss: 2.854057996774101
Validation loss: 3.1747642357530585

Epoch: 6| Step: 9
Training loss: 3.2720921193891463
Validation loss: 3.1716410357999365

Epoch: 6| Step: 10
Training loss: 3.8122075703518874
Validation loss: 3.171504037541216

Epoch: 6| Step: 11
Training loss: 3.2526461759144536
Validation loss: 3.171594691119087

Epoch: 6| Step: 12
Training loss: 3.463815426822883
Validation loss: 3.1710420496141696

Epoch: 6| Step: 13
Training loss: 3.0207831192227865
Validation loss: 3.1712177653883393

Epoch: 62| Step: 0
Training loss: 3.0125463711663816
Validation loss: 3.169092777983007

Epoch: 6| Step: 1
Training loss: 3.37971153585817
Validation loss: 3.1690920418375503

Epoch: 6| Step: 2
Training loss: 4.1193158839108746
Validation loss: 3.1692721092466987

Epoch: 6| Step: 3
Training loss: 3.1605050892908864
Validation loss: 3.1676224144376035

Epoch: 6| Step: 4
Training loss: 3.5773663778562037
Validation loss: 3.1645567205807237

Epoch: 6| Step: 5
Training loss: 3.09066279342887
Validation loss: 3.1668659923580815

Epoch: 6| Step: 6
Training loss: 3.093003153964931
Validation loss: 3.1676758343894797

Epoch: 6| Step: 7
Training loss: 3.512933268585689
Validation loss: 3.1681037134540757

Epoch: 6| Step: 8
Training loss: 3.3496200516867014
Validation loss: 3.165882096519476

Epoch: 6| Step: 9
Training loss: 4.014923390646909
Validation loss: 3.1665411202673135

Epoch: 6| Step: 10
Training loss: 2.4437658519181955
Validation loss: 3.165148211232111

Epoch: 6| Step: 11
Training loss: 3.3371131129814895
Validation loss: 3.1657191112629848

Epoch: 6| Step: 12
Training loss: 4.123205083416554
Validation loss: 3.164271245826128

Epoch: 6| Step: 13
Training loss: 3.032137239525752
Validation loss: 3.1648052559637367

Epoch: 63| Step: 0
Training loss: 3.3889189616329904
Validation loss: 3.162773578144442

Epoch: 6| Step: 1
Training loss: 3.4533549098466287
Validation loss: 3.1640525745806882

Epoch: 6| Step: 2
Training loss: 3.767228667494305
Validation loss: 3.1626310204719528

Epoch: 6| Step: 3
Training loss: 3.6567682404321715
Validation loss: 3.161635990479109

Epoch: 6| Step: 4
Training loss: 3.018897144214455
Validation loss: 3.1636367817318347

Epoch: 6| Step: 5
Training loss: 3.295928963979003
Validation loss: 3.1623515313962134

Epoch: 6| Step: 6
Training loss: 2.841662300829922
Validation loss: 3.161803485162379

Epoch: 6| Step: 7
Training loss: 3.6372544562978266
Validation loss: 3.1611886290642195

Epoch: 6| Step: 8
Training loss: 3.2202826249144922
Validation loss: 3.1611162812782974

Epoch: 6| Step: 9
Training loss: 3.869697141797828
Validation loss: 3.160910337699414

Epoch: 6| Step: 10
Training loss: 3.777933479042519
Validation loss: 3.15956569588788

Epoch: 6| Step: 11
Training loss: 2.656983666917866
Validation loss: 3.15992033220668

Epoch: 6| Step: 12
Training loss: 3.3359173454730016
Validation loss: 3.1593541528904074

Epoch: 6| Step: 13
Training loss: 3.714925000959824
Validation loss: 3.1581119490175467

Epoch: 64| Step: 0
Training loss: 3.0834778073116715
Validation loss: 3.158225071133501

Epoch: 6| Step: 1
Training loss: 3.8767789633425367
Validation loss: 3.15768954712866

Epoch: 6| Step: 2
Training loss: 2.9817714019286212
Validation loss: 3.1586486464416206

Epoch: 6| Step: 3
Training loss: 3.048513275252724
Validation loss: 3.157455128165528

Epoch: 6| Step: 4
Training loss: 3.5487123007550605
Validation loss: 3.1575942935877253

Epoch: 6| Step: 5
Training loss: 3.406699194731074
Validation loss: 3.1567091711900996

Epoch: 6| Step: 6
Training loss: 3.6108036268995924
Validation loss: 3.156697790057825

Epoch: 6| Step: 7
Training loss: 2.959591844100634
Validation loss: 3.1549354430310683

Epoch: 6| Step: 8
Training loss: 3.3599786260469986
Validation loss: 3.153158385312878

Epoch: 6| Step: 9
Training loss: 3.10730831914607
Validation loss: 3.1530255449561033

Epoch: 6| Step: 10
Training loss: 2.515229946416353
Validation loss: 3.1547551911617657

Epoch: 6| Step: 11
Training loss: 3.645785231500017
Validation loss: 3.1522696052099644

Epoch: 6| Step: 12
Training loss: 3.7745549223796635
Validation loss: 3.152483500502637

Epoch: 6| Step: 13
Training loss: 4.992594002424679
Validation loss: 3.151386283566681

Epoch: 65| Step: 0
Training loss: 3.1624791080553747
Validation loss: 3.1508893609347646

Epoch: 6| Step: 1
Training loss: 3.006432630420127
Validation loss: 3.149471224709432

Epoch: 6| Step: 2
Training loss: 3.410091508772978
Validation loss: 3.1523762863010427

Epoch: 6| Step: 3
Training loss: 4.247551829991238
Validation loss: 3.15082134770537

Epoch: 6| Step: 4
Training loss: 2.924888321790473
Validation loss: 3.1507162022477297

Epoch: 6| Step: 5
Training loss: 2.8907962232861433
Validation loss: 3.1564856373960866

Epoch: 6| Step: 6
Training loss: 3.1107231552951093
Validation loss: 3.156590676763321

Epoch: 6| Step: 7
Training loss: 3.625221377222984
Validation loss: 3.1596288944383426

Epoch: 6| Step: 8
Training loss: 3.92420385753943
Validation loss: 3.1556328334885015

Epoch: 6| Step: 9
Training loss: 3.6056245416808568
Validation loss: 3.153176012761443

Epoch: 6| Step: 10
Training loss: 3.3887267534281094
Validation loss: 3.1496893666921117

Epoch: 6| Step: 11
Training loss: 3.2675578406890575
Validation loss: 3.150084248275748

Epoch: 6| Step: 12
Training loss: 3.9205260369538557
Validation loss: 3.148350485551929

Epoch: 6| Step: 13
Training loss: 2.250411949593028
Validation loss: 3.1452625824188796

Epoch: 66| Step: 0
Training loss: 3.1290277083655296
Validation loss: 3.1466502141113954

Epoch: 6| Step: 1
Training loss: 2.88244758922244
Validation loss: 3.1493249487918664

Epoch: 6| Step: 2
Training loss: 3.256861852173885
Validation loss: 3.152215550875433

Epoch: 6| Step: 3
Training loss: 3.0020876614188436
Validation loss: 3.1562738018667464

Epoch: 6| Step: 4
Training loss: 3.3627250113945237
Validation loss: 3.1562651547856295

Epoch: 6| Step: 5
Training loss: 3.5952213095083954
Validation loss: 3.159795737730701

Epoch: 6| Step: 6
Training loss: 3.864427849588512
Validation loss: 3.1555320811040035

Epoch: 6| Step: 7
Training loss: 3.4388958957773976
Validation loss: 3.151348359774578

Epoch: 6| Step: 8
Training loss: 4.283794899697671
Validation loss: 3.1464754924357385

Epoch: 6| Step: 9
Training loss: 3.5523679438401157
Validation loss: 3.1463367233524666

Epoch: 6| Step: 10
Training loss: 3.047075626908304
Validation loss: 3.1445813756346372

Epoch: 6| Step: 11
Training loss: 3.195281609197029
Validation loss: 3.1419292385161124

Epoch: 6| Step: 12
Training loss: 3.3967772188124385
Validation loss: 3.1422034965791616

Epoch: 6| Step: 13
Training loss: 3.498582961826644
Validation loss: 3.1419653357040507

Epoch: 67| Step: 0
Training loss: 3.7474318293401625
Validation loss: 3.1405784584302383

Epoch: 6| Step: 1
Training loss: 3.101081714792251
Validation loss: 3.1413361392126777

Epoch: 6| Step: 2
Training loss: 3.511057416958695
Validation loss: 3.143288280783734

Epoch: 6| Step: 3
Training loss: 3.6429675510248267
Validation loss: 3.14388226106292

Epoch: 6| Step: 4
Training loss: 3.7522050096832906
Validation loss: 3.141922528179405

Epoch: 6| Step: 5
Training loss: 3.6177739436274816
Validation loss: 3.143273244494479

Epoch: 6| Step: 6
Training loss: 3.0295169241281856
Validation loss: 3.1412363173187448

Epoch: 6| Step: 7
Training loss: 2.6930833527095133
Validation loss: 3.1399979761066317

Epoch: 6| Step: 8
Training loss: 3.036450202281048
Validation loss: 3.1405273872919204

Epoch: 6| Step: 9
Training loss: 3.101436122366244
Validation loss: 3.14090643054283

Epoch: 6| Step: 10
Training loss: 3.136710693044992
Validation loss: 3.139308179324308

Epoch: 6| Step: 11
Training loss: 3.4767078840739036
Validation loss: 3.136363559859735

Epoch: 6| Step: 12
Training loss: 3.7338994573328703
Validation loss: 3.1381416410219014

Epoch: 6| Step: 13
Training loss: 3.971434158603545
Validation loss: 3.1359822238065047

Epoch: 68| Step: 0
Training loss: 2.7438886533561453
Validation loss: 3.137003022708531

Epoch: 6| Step: 1
Training loss: 2.6170803674434997
Validation loss: 3.1358539877417217

Epoch: 6| Step: 2
Training loss: 3.827127754951769
Validation loss: 3.135926126180636

Epoch: 6| Step: 3
Training loss: 3.418181075994385
Validation loss: 3.1354044047750813

Epoch: 6| Step: 4
Training loss: 3.364825418146459
Validation loss: 3.136026319019365

Epoch: 6| Step: 5
Training loss: 2.9587020286084567
Validation loss: 3.1345795204158042

Epoch: 6| Step: 6
Training loss: 3.497238159412702
Validation loss: 3.1349916479064195

Epoch: 6| Step: 7
Training loss: 2.756916538185904
Validation loss: 3.133640650687333

Epoch: 6| Step: 8
Training loss: 3.3967292087575887
Validation loss: 3.133388592850863

Epoch: 6| Step: 9
Training loss: 4.0883385221062465
Validation loss: 3.133275593526936

Epoch: 6| Step: 10
Training loss: 3.44841711248292
Validation loss: 3.1333364799769967

Epoch: 6| Step: 11
Training loss: 3.3598628200047824
Validation loss: 3.1315267859927287

Epoch: 6| Step: 12
Training loss: 3.933132837864504
Validation loss: 3.130726811853827

Epoch: 6| Step: 13
Training loss: 3.86641517402265
Validation loss: 3.131774694440986

Epoch: 69| Step: 0
Training loss: 2.6911687427803406
Validation loss: 3.132183188603175

Epoch: 6| Step: 1
Training loss: 2.6733526415932256
Validation loss: 3.130281136127003

Epoch: 6| Step: 2
Training loss: 2.633962679958481
Validation loss: 3.12924792023103

Epoch: 6| Step: 3
Training loss: 3.896532590945417
Validation loss: 3.1304720798079804

Epoch: 6| Step: 4
Training loss: 3.6981912573648494
Validation loss: 3.1311809456611996

Epoch: 6| Step: 5
Training loss: 3.916383949519157
Validation loss: 3.1293276250006747

Epoch: 6| Step: 6
Training loss: 3.8008871347982183
Validation loss: 3.1289642030787

Epoch: 6| Step: 7
Training loss: 3.104106637941802
Validation loss: 3.1279532065565174

Epoch: 6| Step: 8
Training loss: 3.6427996120665043
Validation loss: 3.1298226009690517

Epoch: 6| Step: 9
Training loss: 3.26024918943655
Validation loss: 3.1297011816432754

Epoch: 6| Step: 10
Training loss: 3.076245193818704
Validation loss: 3.126970689472675

Epoch: 6| Step: 11
Training loss: 3.82216731877286
Validation loss: 3.128729629545009

Epoch: 6| Step: 12
Training loss: 3.337227708088671
Validation loss: 3.1278041752320638

Epoch: 6| Step: 13
Training loss: 3.46856578990741
Validation loss: 3.1264849246013324

Epoch: 70| Step: 0
Training loss: 3.0135153867646154
Validation loss: 3.1273879626189

Epoch: 6| Step: 1
Training loss: 3.131043959975151
Validation loss: 3.1258149230934347

Epoch: 6| Step: 2
Training loss: 2.4589163094357405
Validation loss: 3.1241867746466734

Epoch: 6| Step: 3
Training loss: 3.5200276252356137
Validation loss: 3.1261951581165284

Epoch: 6| Step: 4
Training loss: 4.683100555897812
Validation loss: 3.126403362227263

Epoch: 6| Step: 5
Training loss: 3.255210074869326
Validation loss: 3.124174066320912

Epoch: 6| Step: 6
Training loss: 3.0823128188476296
Validation loss: 3.123686780747583

Epoch: 6| Step: 7
Training loss: 3.88259008987161
Validation loss: 3.1240627351727146

Epoch: 6| Step: 8
Training loss: 3.7697800628295193
Validation loss: 3.1230287778700285

Epoch: 6| Step: 9
Training loss: 3.5369513743355396
Validation loss: 3.1229846953311875

Epoch: 6| Step: 10
Training loss: 3.25248417914235
Validation loss: 3.1229053450289865

Epoch: 6| Step: 11
Training loss: 2.8329776839896565
Validation loss: 3.122040153714767

Epoch: 6| Step: 12
Training loss: 3.08302250575569
Validation loss: 3.1229952528361706

Epoch: 6| Step: 13
Training loss: 3.2009456012254245
Validation loss: 3.123456564781276

Epoch: 71| Step: 0
Training loss: 3.53953390792338
Validation loss: 3.122485665772088

Epoch: 6| Step: 1
Training loss: 3.243997606297749
Validation loss: 3.12307014188084

Epoch: 6| Step: 2
Training loss: 3.5656641243368687
Validation loss: 3.1234470192071555

Epoch: 6| Step: 3
Training loss: 2.9551265331874434
Validation loss: 3.121226109544484

Epoch: 6| Step: 4
Training loss: 3.8996415046836383
Validation loss: 3.122176268296602

Epoch: 6| Step: 5
Training loss: 3.0797142921803577
Validation loss: 3.1206700457361585

Epoch: 6| Step: 6
Training loss: 3.295953124546304
Validation loss: 3.1191170099051932

Epoch: 6| Step: 7
Training loss: 3.3774153931903577
Validation loss: 3.1189328566619876

Epoch: 6| Step: 8
Training loss: 3.4522936066099934
Validation loss: 3.1178188268063596

Epoch: 6| Step: 9
Training loss: 3.1292646681419023
Validation loss: 3.1184787708010844

Epoch: 6| Step: 10
Training loss: 3.357305838736175
Validation loss: 3.1171158811068618

Epoch: 6| Step: 11
Training loss: 3.6430438605575817
Validation loss: 3.1180332025693454

Epoch: 6| Step: 12
Training loss: 2.8046506066406187
Validation loss: 3.1161807450422354

Epoch: 6| Step: 13
Training loss: 4.020199081653535
Validation loss: 3.1162967417162304

Epoch: 72| Step: 0
Training loss: 3.6479242196577664
Validation loss: 3.115266354155264

Epoch: 6| Step: 1
Training loss: 3.487425969476359
Validation loss: 3.1166638271057168

Epoch: 6| Step: 2
Training loss: 3.0918830864382043
Validation loss: 3.116285841503368

Epoch: 6| Step: 3
Training loss: 3.555397314947891
Validation loss: 3.115754139593891

Epoch: 6| Step: 4
Training loss: 2.9396414560203787
Validation loss: 3.113433530723939

Epoch: 6| Step: 5
Training loss: 3.907458553277444
Validation loss: 3.113329838285728

Epoch: 6| Step: 6
Training loss: 3.129112132105612
Validation loss: 3.11276646041119

Epoch: 6| Step: 7
Training loss: 2.9052305997367034
Validation loss: 3.114040848677035

Epoch: 6| Step: 8
Training loss: 3.2050596767826773
Validation loss: 3.1147625241554544

Epoch: 6| Step: 9
Training loss: 3.3997396145015477
Validation loss: 3.1139934536935714

Epoch: 6| Step: 10
Training loss: 3.258457915777278
Validation loss: 3.1140521733121864

Epoch: 6| Step: 11
Training loss: 3.896786265521592
Validation loss: 3.111966743226477

Epoch: 6| Step: 12
Training loss: 3.516081242096859
Validation loss: 3.1113887175064003

Epoch: 6| Step: 13
Training loss: 2.757095719251464
Validation loss: 3.1130050615106044

Epoch: 73| Step: 0
Training loss: 3.617271603622006
Validation loss: 3.111447721104313

Epoch: 6| Step: 1
Training loss: 3.30190699414348
Validation loss: 3.11185303027942

Epoch: 6| Step: 2
Training loss: 3.95719344474167
Validation loss: 3.1105454496353118

Epoch: 6| Step: 3
Training loss: 3.2370824124767066
Validation loss: 3.108554899513838

Epoch: 6| Step: 4
Training loss: 3.345303468723213
Validation loss: 3.1097784177956305

Epoch: 6| Step: 5
Training loss: 3.0121139089010747
Validation loss: 3.107315802211855

Epoch: 6| Step: 6
Training loss: 3.8052790062529827
Validation loss: 3.1081771732401786

Epoch: 6| Step: 7
Training loss: 3.4092181511454513
Validation loss: 3.1086907633876613

Epoch: 6| Step: 8
Training loss: 3.8822050482924397
Validation loss: 3.106537942990474

Epoch: 6| Step: 9
Training loss: 2.4933858160965334
Validation loss: 3.1070632103155273

Epoch: 6| Step: 10
Training loss: 2.6333625739522337
Validation loss: 3.10865311125104

Epoch: 6| Step: 11
Training loss: 3.059439706556447
Validation loss: 3.1063712267509564

Epoch: 6| Step: 12
Training loss: 3.5846146946576103
Validation loss: 3.1052597333629346

Epoch: 6| Step: 13
Training loss: 3.493459312069899
Validation loss: 3.107999260970034

Epoch: 74| Step: 0
Training loss: 3.7890594797024044
Validation loss: 3.105687795209271

Epoch: 6| Step: 1
Training loss: 4.133294061248598
Validation loss: 3.1070234113189628

Epoch: 6| Step: 2
Training loss: 3.6615868116748445
Validation loss: 3.10523222491222

Epoch: 6| Step: 3
Training loss: 3.914281538204316
Validation loss: 3.106945726103444

Epoch: 6| Step: 4
Training loss: 3.3553144177437297
Validation loss: 3.1055846944070997

Epoch: 6| Step: 5
Training loss: 2.4371538160930917
Validation loss: 3.1077873590641834

Epoch: 6| Step: 6
Training loss: 2.974850460108838
Validation loss: 3.103990332734819

Epoch: 6| Step: 7
Training loss: 3.64501125695017
Validation loss: 3.1045002851294248

Epoch: 6| Step: 8
Training loss: 3.4739228589459534
Validation loss: 3.1061495704812296

Epoch: 6| Step: 9
Training loss: 2.7021302614472718
Validation loss: 3.1037285850678544

Epoch: 6| Step: 10
Training loss: 3.817639373253622
Validation loss: 3.1038034640503462

Epoch: 6| Step: 11
Training loss: 3.6097125271278068
Validation loss: 3.1049527394376106

Epoch: 6| Step: 12
Training loss: 2.2596641260562262
Validation loss: 3.1062283344973634

Epoch: 6| Step: 13
Training loss: 1.8478287017540347
Validation loss: 3.1027083841083796

Epoch: 75| Step: 0
Training loss: 3.2799797869268836
Validation loss: 3.1034906849776442

Epoch: 6| Step: 1
Training loss: 3.90938033752321
Validation loss: 3.104506754299329

Epoch: 6| Step: 2
Training loss: 2.2626336706307373
Validation loss: 3.102691399482492

Epoch: 6| Step: 3
Training loss: 3.0868122647621026
Validation loss: 3.10400139836078

Epoch: 6| Step: 4
Training loss: 3.2245079315698444
Validation loss: 3.1034328228913055

Epoch: 6| Step: 5
Training loss: 3.6980416863311283
Validation loss: 3.1018908385693202

Epoch: 6| Step: 6
Training loss: 2.364893138156801
Validation loss: 3.101431124751217

Epoch: 6| Step: 7
Training loss: 3.3952915406929742
Validation loss: 3.1030110461850096

Epoch: 6| Step: 8
Training loss: 3.7970665149503926
Validation loss: 3.105085422093237

Epoch: 6| Step: 9
Training loss: 3.5171806454009173
Validation loss: 3.106951570508575

Epoch: 6| Step: 10
Training loss: 2.954420663292294
Validation loss: 3.1102987438359975

Epoch: 6| Step: 11
Training loss: 3.010039062753465
Validation loss: 3.145508211858039

Epoch: 6| Step: 12
Training loss: 4.073401744994354
Validation loss: 3.1685439324646953

Epoch: 6| Step: 13
Training loss: 4.432492076438539
Validation loss: 3.138902485985877

Epoch: 76| Step: 0
Training loss: 2.882588034060519
Validation loss: 3.098609097371159

Epoch: 6| Step: 1
Training loss: 3.1146552716541
Validation loss: 3.0989058477283504

Epoch: 6| Step: 2
Training loss: 3.1070517290153608
Validation loss: 3.0975627439442617

Epoch: 6| Step: 3
Training loss: 3.273649732314875
Validation loss: 3.1004210080700636

Epoch: 6| Step: 4
Training loss: 3.6049605948613266
Validation loss: 3.101773266718629

Epoch: 6| Step: 5
Training loss: 3.525869946639444
Validation loss: 3.1004895861357515

Epoch: 6| Step: 6
Training loss: 3.49539631115118
Validation loss: 3.1053962714024266

Epoch: 6| Step: 7
Training loss: 3.1077823106192226
Validation loss: 3.1061301723702783

Epoch: 6| Step: 8
Training loss: 3.8157674826872765
Validation loss: 3.0989641930778173

Epoch: 6| Step: 9
Training loss: 3.4869484742200068
Validation loss: 3.097246984761153

Epoch: 6| Step: 10
Training loss: 3.107233431393266
Validation loss: 3.0948039828639637

Epoch: 6| Step: 11
Training loss: 3.5668343394668884
Validation loss: 3.094164236707012

Epoch: 6| Step: 12
Training loss: 3.2562544868423684
Validation loss: 3.0937926321695883

Epoch: 6| Step: 13
Training loss: 3.7633138188367776
Validation loss: 3.0936176979842545

Epoch: 77| Step: 0
Training loss: 3.788893863032094
Validation loss: 3.096289909548355

Epoch: 6| Step: 1
Training loss: 3.599303225798387
Validation loss: 3.0964404013518334

Epoch: 6| Step: 2
Training loss: 3.216272530267396
Validation loss: 3.0953577329972917

Epoch: 6| Step: 3
Training loss: 2.7906792920545875
Validation loss: 3.0978836298677193

Epoch: 6| Step: 4
Training loss: 2.917502165518172
Validation loss: 3.097223149761827

Epoch: 6| Step: 5
Training loss: 3.0754367301137275
Validation loss: 3.093462683233138

Epoch: 6| Step: 6
Training loss: 3.3838557161094043
Validation loss: 3.097558317767603

Epoch: 6| Step: 7
Training loss: 3.374878068770032
Validation loss: 3.0941631869459174

Epoch: 6| Step: 8
Training loss: 3.3023503112366805
Validation loss: 3.0932839909515972

Epoch: 6| Step: 9
Training loss: 2.887853665181791
Validation loss: 3.0915526202507784

Epoch: 6| Step: 10
Training loss: 3.8972125680383503
Validation loss: 3.0905352567048268

Epoch: 6| Step: 11
Training loss: 3.417931361402649
Validation loss: 3.0892375140108657

Epoch: 6| Step: 12
Training loss: 3.087588407046134
Validation loss: 3.089168229720304

Epoch: 6| Step: 13
Training loss: 4.372393894554861
Validation loss: 3.090619019840251

Epoch: 78| Step: 0
Training loss: 2.8497060925370485
Validation loss: 3.09026386696766

Epoch: 6| Step: 1
Training loss: 3.146376623940652
Validation loss: 3.0893063502918356

Epoch: 6| Step: 2
Training loss: 4.019880481670327
Validation loss: 3.0898550156340927

Epoch: 6| Step: 3
Training loss: 3.7317084204953237
Validation loss: 3.088814443830621

Epoch: 6| Step: 4
Training loss: 3.258220400076716
Validation loss: 3.0870273105526707

Epoch: 6| Step: 5
Training loss: 2.5775055112141576
Validation loss: 3.0869444664631702

Epoch: 6| Step: 6
Training loss: 3.362056354057208
Validation loss: 3.0868889817040506

Epoch: 6| Step: 7
Training loss: 2.8465743240042194
Validation loss: 3.0872308403267748

Epoch: 6| Step: 8
Training loss: 3.37535164025521
Validation loss: 3.0857240814143676

Epoch: 6| Step: 9
Training loss: 3.4946769017090644
Validation loss: 3.090955648767479

Epoch: 6| Step: 10
Training loss: 3.491295617417093
Validation loss: 3.091789198488435

Epoch: 6| Step: 11
Training loss: 3.6482572653972642
Validation loss: 3.085739386499793

Epoch: 6| Step: 12
Training loss: 3.0528473055227314
Validation loss: 3.083150591059171

Epoch: 6| Step: 13
Training loss: 3.986844124262572
Validation loss: 3.0836653315880365

Epoch: 79| Step: 0
Training loss: 3.256064552107755
Validation loss: 3.0829372905503614

Epoch: 6| Step: 1
Training loss: 3.0560998797846457
Validation loss: 3.084586129823938

Epoch: 6| Step: 2
Training loss: 3.0383971596558417
Validation loss: 3.082194673189382

Epoch: 6| Step: 3
Training loss: 3.3312031297088196
Validation loss: 3.0815025726777394

Epoch: 6| Step: 4
Training loss: 3.8005486443629355
Validation loss: 3.0811456692379187

Epoch: 6| Step: 5
Training loss: 3.828986619791965
Validation loss: 3.0823864922827906

Epoch: 6| Step: 6
Training loss: 3.754871891238994
Validation loss: 3.0810765191685374

Epoch: 6| Step: 7
Training loss: 3.2169283554546904
Validation loss: 3.0806031571346364

Epoch: 6| Step: 8
Training loss: 2.48608934285196
Validation loss: 3.0793894308123173

Epoch: 6| Step: 9
Training loss: 3.613756962983566
Validation loss: 3.0794483099358074

Epoch: 6| Step: 10
Training loss: 2.8507336391697735
Validation loss: 3.0785586352177354

Epoch: 6| Step: 11
Training loss: 3.323451526291217
Validation loss: 3.0783308181176343

Epoch: 6| Step: 12
Training loss: 3.4944850523718083
Validation loss: 3.077339669757104

Epoch: 6| Step: 13
Training loss: 3.6126672831415907
Validation loss: 3.0781827198407514

Epoch: 80| Step: 0
Training loss: 3.0447920501809667
Validation loss: 3.078538885879316

Epoch: 6| Step: 1
Training loss: 3.0545498165702223
Validation loss: 3.078200404362379

Epoch: 6| Step: 2
Training loss: 2.7443562595993347
Validation loss: 3.0785049496313475

Epoch: 6| Step: 3
Training loss: 3.589139950306444
Validation loss: 3.078788333135067

Epoch: 6| Step: 4
Training loss: 2.8885257831021685
Validation loss: 3.078160078107955

Epoch: 6| Step: 5
Training loss: 4.326300170924957
Validation loss: 3.078154976074549

Epoch: 6| Step: 6
Training loss: 2.8681366308379204
Validation loss: 3.083158584261175

Epoch: 6| Step: 7
Training loss: 3.221255614187361
Validation loss: 3.087518766905057

Epoch: 6| Step: 8
Training loss: 3.9410225990574754
Validation loss: 3.0830181651407536

Epoch: 6| Step: 9
Training loss: 2.8841756270286987
Validation loss: 3.0773278934511863

Epoch: 6| Step: 10
Training loss: 3.0902499041687297
Validation loss: 3.0755136124457008

Epoch: 6| Step: 11
Training loss: 2.8538840680705335
Validation loss: 3.075573565193481

Epoch: 6| Step: 12
Training loss: 4.39634988410463
Validation loss: 3.0752558549975966

Epoch: 6| Step: 13
Training loss: 3.2157586280335115
Validation loss: 3.0763873629108396

Epoch: 81| Step: 0
Training loss: 3.5581416189347363
Validation loss: 3.086179049202425

Epoch: 6| Step: 1
Training loss: 2.6779601643956252
Validation loss: 3.0793387792964255

Epoch: 6| Step: 2
Training loss: 3.867570337939401
Validation loss: 3.075486526463932

Epoch: 6| Step: 3
Training loss: 3.3365252153543383
Validation loss: 3.073346124711005

Epoch: 6| Step: 4
Training loss: 3.1768025425301576
Validation loss: 3.074517388383905

Epoch: 6| Step: 5
Training loss: 3.233700004577495
Validation loss: 3.074426106262268

Epoch: 6| Step: 6
Training loss: 3.840745325275485
Validation loss: 3.072496734563738

Epoch: 6| Step: 7
Training loss: 2.6283973325953562
Validation loss: 3.0735434539317046

Epoch: 6| Step: 8
Training loss: 3.5951246203388556
Validation loss: 3.0728841494506054

Epoch: 6| Step: 9
Training loss: 3.053907055682693
Validation loss: 3.0734421942692687

Epoch: 6| Step: 10
Training loss: 2.8243279864658564
Validation loss: 3.0748283731509836

Epoch: 6| Step: 11
Training loss: 4.012973726537817
Validation loss: 3.077227124884469

Epoch: 6| Step: 12
Training loss: 3.3093680204294467
Validation loss: 3.0748534722828182

Epoch: 6| Step: 13
Training loss: 3.2356990739265723
Validation loss: 3.0814070239778637

Epoch: 82| Step: 0
Training loss: 3.178015416899558
Validation loss: 3.0708409048588656

Epoch: 6| Step: 1
Training loss: 2.7389029369892413
Validation loss: 3.0714520840284334

Epoch: 6| Step: 2
Training loss: 3.7954069839595808
Validation loss: 3.0681244493964956

Epoch: 6| Step: 3
Training loss: 3.1043952669972428
Validation loss: 3.0706405867231825

Epoch: 6| Step: 4
Training loss: 3.351826121670775
Validation loss: 3.0722708244303987

Epoch: 6| Step: 5
Training loss: 2.9771920086668455
Validation loss: 3.0702320246871624

Epoch: 6| Step: 6
Training loss: 3.8355520019745626
Validation loss: 3.0693860917477886

Epoch: 6| Step: 7
Training loss: 3.100730342355791
Validation loss: 3.070938592173348

Epoch: 6| Step: 8
Training loss: 3.833059439341809
Validation loss: 3.068262310760046

Epoch: 6| Step: 9
Training loss: 3.6241327761143425
Validation loss: 3.0682672713274965

Epoch: 6| Step: 10
Training loss: 2.868666763594077
Validation loss: 3.067305718010745

Epoch: 6| Step: 11
Training loss: 3.338686237190502
Validation loss: 3.067246614990978

Epoch: 6| Step: 12
Training loss: 3.6073058171131973
Validation loss: 3.0685571017646955

Epoch: 6| Step: 13
Training loss: 2.8513630000311743
Validation loss: 3.071895537464594

Epoch: 83| Step: 0
Training loss: 3.3769813655557157
Validation loss: 3.0701242837122273

Epoch: 6| Step: 1
Training loss: 3.4575068087452165
Validation loss: 3.081608482446953

Epoch: 6| Step: 2
Training loss: 3.4009997300526735
Validation loss: 3.080337193383987

Epoch: 6| Step: 3
Training loss: 3.427078262526327
Validation loss: 3.081233644707271

Epoch: 6| Step: 4
Training loss: 3.5734099259874323
Validation loss: 3.0793966087559634

Epoch: 6| Step: 5
Training loss: 3.22362142270216
Validation loss: 3.078596777829962

Epoch: 6| Step: 6
Training loss: 3.634800258432528
Validation loss: 3.070928477636649

Epoch: 6| Step: 7
Training loss: 3.775256237908261
Validation loss: 3.065858865317464

Epoch: 6| Step: 8
Training loss: 3.074173923344956
Validation loss: 3.064010810829177

Epoch: 6| Step: 9
Training loss: 3.1498971589270033
Validation loss: 3.059971571565116

Epoch: 6| Step: 10
Training loss: 3.6884536803053134
Validation loss: 3.0615681981714657

Epoch: 6| Step: 11
Training loss: 2.6456032500261775
Validation loss: 3.059360814741716

Epoch: 6| Step: 12
Training loss: 2.6203924340900686
Validation loss: 3.060098888368505

Epoch: 6| Step: 13
Training loss: 3.264971069862049
Validation loss: 3.0577965270785827

Epoch: 84| Step: 0
Training loss: 3.392882830300287
Validation loss: 3.058501954912468

Epoch: 6| Step: 1
Training loss: 3.508667975358129
Validation loss: 3.05811334089066

Epoch: 6| Step: 2
Training loss: 3.6060016936659474
Validation loss: 3.058607801154357

Epoch: 6| Step: 3
Training loss: 3.434682905506264
Validation loss: 3.059142516785709

Epoch: 6| Step: 4
Training loss: 2.9239501112244866
Validation loss: 3.0584474109842925

Epoch: 6| Step: 5
Training loss: 3.0079905271482446
Validation loss: 3.058645253820489

Epoch: 6| Step: 6
Training loss: 3.476047846386913
Validation loss: 3.056668221849295

Epoch: 6| Step: 7
Training loss: 3.0563994388671167
Validation loss: 3.0562040812254687

Epoch: 6| Step: 8
Training loss: 3.075329125631439
Validation loss: 3.0561154540239155

Epoch: 6| Step: 9
Training loss: 3.2949085608429876
Validation loss: 3.0534372730899366

Epoch: 6| Step: 10
Training loss: 3.8816951625417344
Validation loss: 3.0536715269843846

Epoch: 6| Step: 11
Training loss: 3.8797332404547924
Validation loss: 3.0546161160807856

Epoch: 6| Step: 12
Training loss: 2.3886966282957007
Validation loss: 3.052847433165332

Epoch: 6| Step: 13
Training loss: 3.294958778088764
Validation loss: 3.0519758675457567

Epoch: 85| Step: 0
Training loss: 3.7916998110709383
Validation loss: 3.0531403135312245

Epoch: 6| Step: 1
Training loss: 2.892247914611186
Validation loss: 3.055330311504944

Epoch: 6| Step: 2
Training loss: 3.179650608757889
Validation loss: 3.053960401383545

Epoch: 6| Step: 3
Training loss: 2.8851178470124754
Validation loss: 3.058000674422263

Epoch: 6| Step: 4
Training loss: 2.7412482497961577
Validation loss: 3.0533291720639464

Epoch: 6| Step: 5
Training loss: 3.63935129044265
Validation loss: 3.053062669626186

Epoch: 6| Step: 6
Training loss: 3.6666752786246226
Validation loss: 3.0553936674600726

Epoch: 6| Step: 7
Training loss: 3.7905666865732472
Validation loss: 3.054596484706982

Epoch: 6| Step: 8
Training loss: 3.5385372622626003
Validation loss: 3.051125160397718

Epoch: 6| Step: 9
Training loss: 3.500584553541265
Validation loss: 3.0527917233811803

Epoch: 6| Step: 10
Training loss: 3.023741714194947
Validation loss: 3.050953494477832

Epoch: 6| Step: 11
Training loss: 3.359737075100692
Validation loss: 3.0543494313246167

Epoch: 6| Step: 12
Training loss: 2.369572310024339
Validation loss: 3.0512932374878847

Epoch: 6| Step: 13
Training loss: 3.961436825189909
Validation loss: 3.0505947111521694

Epoch: 86| Step: 0
Training loss: 2.6022678827995587
Validation loss: 3.0504478253585128

Epoch: 6| Step: 1
Training loss: 3.157538726883263
Validation loss: 3.051475622033827

Epoch: 6| Step: 2
Training loss: 3.4397154171353925
Validation loss: 3.052372169343955

Epoch: 6| Step: 3
Training loss: 3.656813097247143
Validation loss: 3.0529714958903784

Epoch: 6| Step: 4
Training loss: 2.7032546524971632
Validation loss: 3.053651594861995

Epoch: 6| Step: 5
Training loss: 2.9550807067900156
Validation loss: 3.053656727761144

Epoch: 6| Step: 6
Training loss: 2.7634649947413203
Validation loss: 3.054181690299706

Epoch: 6| Step: 7
Training loss: 3.302270460793305
Validation loss: 3.050499673451091

Epoch: 6| Step: 8
Training loss: 3.760545525848283
Validation loss: 3.0439265277942

Epoch: 6| Step: 9
Training loss: 2.8906056996294014
Validation loss: 3.0479529136647963

Epoch: 6| Step: 10
Training loss: 3.0647148375538076
Validation loss: 3.0463887009847292

Epoch: 6| Step: 11
Training loss: 3.675650615580178
Validation loss: 3.046064566798593

Epoch: 6| Step: 12
Training loss: 3.8718547977539313
Validation loss: 3.0452267261078845

Epoch: 6| Step: 13
Training loss: 4.613424300544604
Validation loss: 3.0438153668575203

Epoch: 87| Step: 0
Training loss: 3.099325377368405
Validation loss: 3.045780272347305

Epoch: 6| Step: 1
Training loss: 3.2411204592956797
Validation loss: 3.043073138234487

Epoch: 6| Step: 2
Training loss: 3.674403841619562
Validation loss: 3.0445905351743425

Epoch: 6| Step: 3
Training loss: 3.173205768307889
Validation loss: 3.044878661295882

Epoch: 6| Step: 4
Training loss: 2.349617695654947
Validation loss: 3.0455170109616834

Epoch: 6| Step: 5
Training loss: 3.9689568893694034
Validation loss: 3.046353050016308

Epoch: 6| Step: 6
Training loss: 3.560345182078805
Validation loss: 3.049198827983512

Epoch: 6| Step: 7
Training loss: 3.678680346883031
Validation loss: 3.047655926110374

Epoch: 6| Step: 8
Training loss: 2.946203769843896
Validation loss: 3.05257749912516

Epoch: 6| Step: 9
Training loss: 3.5466699751023465
Validation loss: 3.042834636006393

Epoch: 6| Step: 10
Training loss: 4.131178880965239
Validation loss: 3.050470921542831

Epoch: 6| Step: 11
Training loss: 1.9668814253603628
Validation loss: 3.043988807273227

Epoch: 6| Step: 12
Training loss: 3.470041395484635
Validation loss: 3.046800348394373

Epoch: 6| Step: 13
Training loss: 2.530608295998873
Validation loss: 3.045447092312493

Epoch: 88| Step: 0
Training loss: 3.412352249244618
Validation loss: 3.039459368784142

Epoch: 6| Step: 1
Training loss: 3.1955458875264346
Validation loss: 3.0383328299621857

Epoch: 6| Step: 2
Training loss: 3.863882544523202
Validation loss: 3.0410696014822416

Epoch: 6| Step: 3
Training loss: 3.6268863373966562
Validation loss: 3.046747237461987

Epoch: 6| Step: 4
Training loss: 3.259081257268602
Validation loss: 3.0491412421905304

Epoch: 6| Step: 5
Training loss: 3.6640945140359147
Validation loss: 3.0445116046598817

Epoch: 6| Step: 6
Training loss: 3.0161782187162127
Validation loss: 3.039566797473808

Epoch: 6| Step: 7
Training loss: 3.081088890212298
Validation loss: 3.0375775186422365

Epoch: 6| Step: 8
Training loss: 3.0097821016745625
Validation loss: 3.0357864580186398

Epoch: 6| Step: 9
Training loss: 3.5089120479681415
Validation loss: 3.0359557262854753

Epoch: 6| Step: 10
Training loss: 2.6829849285508582
Validation loss: 3.0371803482468276

Epoch: 6| Step: 11
Training loss: 2.602094532861321
Validation loss: 3.042064988479193

Epoch: 6| Step: 12
Training loss: 3.549186591863999
Validation loss: 3.0395084320398302

Epoch: 6| Step: 13
Training loss: 3.7706498299869824
Validation loss: 3.0373167696973695

Epoch: 89| Step: 0
Training loss: 3.1761586996060207
Validation loss: 3.03674724060473

Epoch: 6| Step: 1
Training loss: 2.632050265217747
Validation loss: 3.035431667293659

Epoch: 6| Step: 2
Training loss: 2.9523064018687384
Validation loss: 3.0347170786356705

Epoch: 6| Step: 3
Training loss: 3.8805659528292793
Validation loss: 3.0344949870011524

Epoch: 6| Step: 4
Training loss: 2.1701363389741966
Validation loss: 3.033817313252681

Epoch: 6| Step: 5
Training loss: 3.5519217326674184
Validation loss: 3.0346308077169883

Epoch: 6| Step: 6
Training loss: 3.493306298648774
Validation loss: 3.0330708883647595

Epoch: 6| Step: 7
Training loss: 3.490126989726727
Validation loss: 3.0345033778680666

Epoch: 6| Step: 8
Training loss: 3.3409823077594587
Validation loss: 3.032926349005839

Epoch: 6| Step: 9
Training loss: 3.705931296323677
Validation loss: 3.031167881196571

Epoch: 6| Step: 10
Training loss: 3.3744626500488497
Validation loss: 3.0315364562324953

Epoch: 6| Step: 11
Training loss: 3.4495195579477533
Validation loss: 3.0296306963961777

Epoch: 6| Step: 12
Training loss: 3.0392642701938817
Validation loss: 3.0301627435727885

Epoch: 6| Step: 13
Training loss: 3.8073753559953123
Validation loss: 3.029796335087451

Epoch: 90| Step: 0
Training loss: 3.5444945022598486
Validation loss: 3.0291348871395294

Epoch: 6| Step: 1
Training loss: 3.195178637696871
Validation loss: 3.029361594601616

Epoch: 6| Step: 2
Training loss: 3.480505740807217
Validation loss: 3.0293305297716113

Epoch: 6| Step: 3
Training loss: 2.5849281945945264
Validation loss: 3.0286828132996995

Epoch: 6| Step: 4
Training loss: 3.391521704447831
Validation loss: 3.027495597765093

Epoch: 6| Step: 5
Training loss: 3.595994198863407
Validation loss: 3.0274679839504115

Epoch: 6| Step: 6
Training loss: 3.453578453152625
Validation loss: 3.026569458449087

Epoch: 6| Step: 7
Training loss: 3.265031240410188
Validation loss: 3.0279049182620246

Epoch: 6| Step: 8
Training loss: 3.0250422829439314
Validation loss: 3.027031449832829

Epoch: 6| Step: 9
Training loss: 3.4134655044218523
Validation loss: 3.029302208267002

Epoch: 6| Step: 10
Training loss: 3.121628888484253
Validation loss: 3.0288529944404905

Epoch: 6| Step: 11
Training loss: 3.363695497953717
Validation loss: 3.029019046365289

Epoch: 6| Step: 12
Training loss: 3.027055650353881
Validation loss: 3.0386833816778123

Epoch: 6| Step: 13
Training loss: 3.8688180895900697
Validation loss: 3.040778226022397

Epoch: 91| Step: 0
Training loss: 3.153976830464506
Validation loss: 3.027369887245444

Epoch: 6| Step: 1
Training loss: 3.5104899563859626
Validation loss: 3.026542319004457

Epoch: 6| Step: 2
Training loss: 2.9446301871520157
Validation loss: 3.0364891625780834

Epoch: 6| Step: 3
Training loss: 3.564405901870405
Validation loss: 3.088144865625388

Epoch: 6| Step: 4
Training loss: 2.8763374866375004
Validation loss: 3.1088455218519244

Epoch: 6| Step: 5
Training loss: 2.8690581910383854
Validation loss: 3.1175820463360826

Epoch: 6| Step: 6
Training loss: 3.473702821194989
Validation loss: 3.1126731438927155

Epoch: 6| Step: 7
Training loss: 2.9834706798741055
Validation loss: 3.0413394391786217

Epoch: 6| Step: 8
Training loss: 3.4415725165567483
Validation loss: 3.0346076213875324

Epoch: 6| Step: 9
Training loss: 3.5732255066312613
Validation loss: 3.031681784013089

Epoch: 6| Step: 10
Training loss: 3.020303684148735
Validation loss: 3.030752689461238

Epoch: 6| Step: 11
Training loss: 3.850192122186448
Validation loss: 3.02858948480799

Epoch: 6| Step: 12
Training loss: 3.4529330515266574
Validation loss: 3.0359200659565286

Epoch: 6| Step: 13
Training loss: 3.8631314054768375
Validation loss: 3.034727842687211

Epoch: 92| Step: 0
Training loss: 3.7175113955376315
Validation loss: 3.0332694254037293

Epoch: 6| Step: 1
Training loss: 3.227263663080164
Validation loss: 3.036262806618445

Epoch: 6| Step: 2
Training loss: 3.0748515271574495
Validation loss: 3.024517580673033

Epoch: 6| Step: 3
Training loss: 3.287315067557954
Validation loss: 3.0294780078700043

Epoch: 6| Step: 4
Training loss: 3.0147049048708148
Validation loss: 3.0327118931290378

Epoch: 6| Step: 5
Training loss: 3.512762235036334
Validation loss: 3.0294455157794684

Epoch: 6| Step: 6
Training loss: 3.033806106557817
Validation loss: 3.0267913371514172

Epoch: 6| Step: 7
Training loss: 3.3521996806081575
Validation loss: 3.0266783542939546

Epoch: 6| Step: 8
Training loss: 3.3216044706068293
Validation loss: 3.0266441770634813

Epoch: 6| Step: 9
Training loss: 3.7118946647990265
Validation loss: 3.0276847028643368

Epoch: 6| Step: 10
Training loss: 3.380140557611323
Validation loss: 3.0239364951211334

Epoch: 6| Step: 11
Training loss: 3.5565470432327393
Validation loss: 3.020084863483735

Epoch: 6| Step: 12
Training loss: 3.018806005238764
Validation loss: 3.020792279726527

Epoch: 6| Step: 13
Training loss: 2.389423143050006
Validation loss: 3.020018448500639

Epoch: 93| Step: 0
Training loss: 2.752111664558104
Validation loss: 3.019910661426822

Epoch: 6| Step: 1
Training loss: 3.03507785376754
Validation loss: 3.0202342292552644

Epoch: 6| Step: 2
Training loss: 2.8131099463388254
Validation loss: 3.0195840942036094

Epoch: 6| Step: 3
Training loss: 3.658112402105155
Validation loss: 3.017344526979485

Epoch: 6| Step: 4
Training loss: 3.6448727168712467
Validation loss: 3.017549846115906

Epoch: 6| Step: 5
Training loss: 2.2984667601755384
Validation loss: 3.0185337166576556

Epoch: 6| Step: 6
Training loss: 3.0678923486376752
Validation loss: 3.017159511650276

Epoch: 6| Step: 7
Training loss: 3.5055089918920945
Validation loss: 3.016540118155492

Epoch: 6| Step: 8
Training loss: 3.162225335900686
Validation loss: 3.0188737079642256

Epoch: 6| Step: 9
Training loss: 3.9389399968322723
Validation loss: 3.0182689485153675

Epoch: 6| Step: 10
Training loss: 3.834884467939848
Validation loss: 3.0191923058249044

Epoch: 6| Step: 11
Training loss: 3.587224990990435
Validation loss: 3.0193646830802425

Epoch: 6| Step: 12
Training loss: 2.9612766363540914
Validation loss: 3.0196018230645794

Epoch: 6| Step: 13
Training loss: 3.5293960430692684
Validation loss: 3.014011686648186

Epoch: 94| Step: 0
Training loss: 3.779580244140798
Validation loss: 3.0189715194332374

Epoch: 6| Step: 1
Training loss: 2.8856929458573717
Validation loss: 3.0189377406887066

Epoch: 6| Step: 2
Training loss: 3.623794092000237
Validation loss: 3.016004924930849

Epoch: 6| Step: 3
Training loss: 3.0613094273286183
Validation loss: 3.015316566091124

Epoch: 6| Step: 4
Training loss: 3.158432611869486
Validation loss: 3.0146690118758084

Epoch: 6| Step: 5
Training loss: 2.949163454055294
Validation loss: 3.0145355165937096

Epoch: 6| Step: 6
Training loss: 3.5991478229255227
Validation loss: 3.012958857629704

Epoch: 6| Step: 7
Training loss: 3.2573432126961768
Validation loss: 3.0130337657181716

Epoch: 6| Step: 8
Training loss: 3.5624009503431613
Validation loss: 3.0123427211665375

Epoch: 6| Step: 9
Training loss: 2.7249030279701367
Validation loss: 3.014342904164701

Epoch: 6| Step: 10
Training loss: 3.3523403589982266
Validation loss: 3.0100087089781886

Epoch: 6| Step: 11
Training loss: 3.84118467494486
Validation loss: 3.0103584985357346

Epoch: 6| Step: 12
Training loss: 3.2625889148507707
Validation loss: 3.012785349737143

Epoch: 6| Step: 13
Training loss: 2.144977349470719
Validation loss: 3.010606832906497

Epoch: 95| Step: 0
Training loss: 2.473900552710668
Validation loss: 3.020713557385402

Epoch: 6| Step: 1
Training loss: 4.114462600417505
Validation loss: 3.052989761420981

Epoch: 6| Step: 2
Training loss: 3.459030693859835
Validation loss: 3.0835279776328623

Epoch: 6| Step: 3
Training loss: 4.312619414956729
Validation loss: 3.1007259388900867

Epoch: 6| Step: 4
Training loss: 2.8293990326760907
Validation loss: 3.101195500297837

Epoch: 6| Step: 5
Training loss: 3.627297035391365
Validation loss: 3.0935219699006655

Epoch: 6| Step: 6
Training loss: 2.562701612775437
Validation loss: 3.09373320981737

Epoch: 6| Step: 7
Training loss: 3.53988159671337
Validation loss: 3.0904766112048594

Epoch: 6| Step: 8
Training loss: 3.3198336626230764
Validation loss: 3.0857202472384753

Epoch: 6| Step: 9
Training loss: 2.914849959842035
Validation loss: 3.086667663083522

Epoch: 6| Step: 10
Training loss: 3.413485061382608
Validation loss: 3.083097782022976

Epoch: 6| Step: 11
Training loss: 2.881852649212388
Validation loss: 3.0818422670449253

Epoch: 6| Step: 12
Training loss: 3.5372742435951805
Validation loss: 3.0811049838108393

Epoch: 6| Step: 13
Training loss: 3.0347515214387815
Validation loss: 3.081623387025135

Epoch: 96| Step: 0
Training loss: 3.3079852160454397
Validation loss: 3.0833389691803257

Epoch: 6| Step: 1
Training loss: 3.9164647936369046
Validation loss: 3.0812362672256435

Epoch: 6| Step: 2
Training loss: 2.767515581564386
Validation loss: 3.0815234976871517

Epoch: 6| Step: 3
Training loss: 3.784371844919592
Validation loss: 3.082187922632591

Epoch: 6| Step: 4
Training loss: 2.5166656047827227
Validation loss: 3.0813146422204833

Epoch: 6| Step: 5
Training loss: 3.0694476358235043
Validation loss: 3.083158989200744

Epoch: 6| Step: 6
Training loss: 3.6240735678879186
Validation loss: 3.0819746469983547

Epoch: 6| Step: 7
Training loss: 3.306884612417517
Validation loss: 3.0866786346672184

Epoch: 6| Step: 8
Training loss: 3.1806795039635154
Validation loss: 3.0936784732886857

Epoch: 6| Step: 9
Training loss: 3.3924561227703265
Validation loss: 3.1009325680460043

Epoch: 6| Step: 10
Training loss: 3.300979445787821
Validation loss: 3.088231185654592

Epoch: 6| Step: 11
Training loss: 3.6308027717565463
Validation loss: 3.082943653624291

Epoch: 6| Step: 12
Training loss: 3.6739856903179593
Validation loss: 3.0776472306494562

Epoch: 6| Step: 13
Training loss: 2.737883230061395
Validation loss: 3.0780890936220224

Epoch: 97| Step: 0
Training loss: 3.533880958464939
Validation loss: 3.0789361699755498

Epoch: 6| Step: 1
Training loss: 3.7313393740277663
Validation loss: 3.077217994085243

Epoch: 6| Step: 2
Training loss: 3.717055503679174
Validation loss: 3.075911013911682

Epoch: 6| Step: 3
Training loss: 3.7895395509533536
Validation loss: 3.073310504506715

Epoch: 6| Step: 4
Training loss: 2.9395577548342793
Validation loss: 3.072622819842048

Epoch: 6| Step: 5
Training loss: 2.374462669222091
Validation loss: 3.0741034972932813

Epoch: 6| Step: 6
Training loss: 3.4068241860339517
Validation loss: 3.0716654676595807

Epoch: 6| Step: 7
Training loss: 2.8241504539578934
Validation loss: 3.0701671905061367

Epoch: 6| Step: 8
Training loss: 2.9929591844645334
Validation loss: 3.0718773092389884

Epoch: 6| Step: 9
Training loss: 3.4408018033840455
Validation loss: 3.0703411671350347

Epoch: 6| Step: 10
Training loss: 3.4482403898058895
Validation loss: 3.0705289084186

Epoch: 6| Step: 11
Training loss: 3.4905697619269005
Validation loss: 3.0682570251609063

Epoch: 6| Step: 12
Training loss: 3.6841505970777364
Validation loss: 3.0697474189939737

Epoch: 6| Step: 13
Training loss: 2.6962779209634893
Validation loss: 3.070510211202291

Epoch: 98| Step: 0
Training loss: 3.244580959542749
Validation loss: 3.069786576357451

Epoch: 6| Step: 1
Training loss: 3.1262979482263016
Validation loss: 3.0706101014754967

Epoch: 6| Step: 2
Training loss: 3.4302330191510064
Validation loss: 3.0728610415227253

Epoch: 6| Step: 3
Training loss: 3.3846609514343604
Validation loss: 3.075445352713991

Epoch: 6| Step: 4
Training loss: 2.4543073198289607
Validation loss: 3.08256046871223

Epoch: 6| Step: 5
Training loss: 2.6182038568462613
Validation loss: 3.0914467028645074

Epoch: 6| Step: 6
Training loss: 3.5801849432543666
Validation loss: 3.0913986828460924

Epoch: 6| Step: 7
Training loss: 3.385556559484461
Validation loss: 3.081286189499028

Epoch: 6| Step: 8
Training loss: 3.0360117213609716
Validation loss: 3.0723800788582287

Epoch: 6| Step: 9
Training loss: 3.517171833100033
Validation loss: 3.0724267540211003

Epoch: 6| Step: 10
Training loss: 3.687589999894812
Validation loss: 3.068867191865311

Epoch: 6| Step: 11
Training loss: 3.7280548114676546
Validation loss: 3.0668466095432314

Epoch: 6| Step: 12
Training loss: 3.7586301044996664
Validation loss: 3.0663535120948606

Epoch: 6| Step: 13
Training loss: 3.44195503769389
Validation loss: 3.063931160672099

Epoch: 99| Step: 0
Training loss: 3.334352925450082
Validation loss: 3.0660348632170136

Epoch: 6| Step: 1
Training loss: 3.279567904970188
Validation loss: 3.0642517567874377

Epoch: 6| Step: 2
Training loss: 2.1421917381773357
Validation loss: 3.064470539066937

Epoch: 6| Step: 3
Training loss: 3.0426528237797172
Validation loss: 3.0638119196089875

Epoch: 6| Step: 4
Training loss: 2.1479862363434723
Validation loss: 3.0634783817902647

Epoch: 6| Step: 5
Training loss: 3.8584865520421396
Validation loss: 3.0623407345499016

Epoch: 6| Step: 6
Training loss: 3.8439293796272485
Validation loss: 3.062363858238746

Epoch: 6| Step: 7
Training loss: 3.5498061651045756
Validation loss: 3.0625425465122733

Epoch: 6| Step: 8
Training loss: 3.8557896813853367
Validation loss: 3.062591052464956

Epoch: 6| Step: 9
Training loss: 2.703834308327422
Validation loss: 3.0608445867380367

Epoch: 6| Step: 10
Training loss: 3.1386765846164884
Validation loss: 3.060895717666738

Epoch: 6| Step: 11
Training loss: 3.734661266894547
Validation loss: 3.0611056547459534

Epoch: 6| Step: 12
Training loss: 3.880512377541896
Validation loss: 3.061519622420922

Epoch: 6| Step: 13
Training loss: 3.4425522176844865
Validation loss: 3.0537449024685723

Epoch: 100| Step: 0
Training loss: 3.4282242905765403
Validation loss: 3.0211882255836646

Epoch: 6| Step: 1
Training loss: 4.022616345208947
Validation loss: 2.9947818696377637

Epoch: 6| Step: 2
Training loss: 3.7003580693371547
Validation loss: 2.9874052128373143

Epoch: 6| Step: 3
Training loss: 3.5589631576667657
Validation loss: 2.9886112179750057

Epoch: 6| Step: 4
Training loss: 2.4216653056271067
Validation loss: 2.9890892309659365

Epoch: 6| Step: 5
Training loss: 3.6885708046191112
Validation loss: 2.9889854978764836

Epoch: 6| Step: 6
Training loss: 3.2093322156749133
Validation loss: 2.991744130765814

Epoch: 6| Step: 7
Training loss: 2.5037103775705845
Validation loss: 2.99004606684954

Epoch: 6| Step: 8
Training loss: 2.7501503296424223
Validation loss: 2.9920011158340576

Epoch: 6| Step: 9
Training loss: 3.9630379007872447
Validation loss: 2.989568044777666

Epoch: 6| Step: 10
Training loss: 3.268441186033498
Validation loss: 2.9871317046018184

Epoch: 6| Step: 11
Training loss: 2.891874630913382
Validation loss: 2.986064077052851

Epoch: 6| Step: 12
Training loss: 2.88338838939987
Validation loss: 2.9871082783132907

Epoch: 6| Step: 13
Training loss: 2.7490975893362863
Validation loss: 2.9878512868952707

Epoch: 101| Step: 0
Training loss: 3.3494496477040645
Validation loss: 2.9895290286786795

Epoch: 6| Step: 1
Training loss: 3.876017775235985
Validation loss: 2.989424576770439

Epoch: 6| Step: 2
Training loss: 2.2390812747272
Validation loss: 2.9908047776640823

Epoch: 6| Step: 3
Training loss: 3.1316915965919363
Validation loss: 2.9910055468337746

Epoch: 6| Step: 4
Training loss: 3.6885338320034404
Validation loss: 2.996915043775673

Epoch: 6| Step: 5
Training loss: 2.8792586919612444
Validation loss: 2.997446574938257

Epoch: 6| Step: 6
Training loss: 3.189295393996683
Validation loss: 2.993648309012627

Epoch: 6| Step: 7
Training loss: 3.735256713460817
Validation loss: 2.9949531660722504

Epoch: 6| Step: 8
Training loss: 3.483716962457157
Validation loss: 2.9855236919595805

Epoch: 6| Step: 9
Training loss: 3.2736443429205235
Validation loss: 2.985639753737493

Epoch: 6| Step: 10
Training loss: 3.2546968999279167
Validation loss: 2.9811239412523487

Epoch: 6| Step: 11
Training loss: 3.175216493209173
Validation loss: 2.983468591819758

Epoch: 6| Step: 12
Training loss: 3.031794233722791
Validation loss: 2.980410429756584

Epoch: 6| Step: 13
Training loss: 2.871343692617666
Validation loss: 2.979267816241291

Epoch: 102| Step: 0
Training loss: 3.644377644890702
Validation loss: 2.97792256288157

Epoch: 6| Step: 1
Training loss: 3.2382308900826313
Validation loss: 2.977566779461387

Epoch: 6| Step: 2
Training loss: 3.2192370592505832
Validation loss: 2.977119442573599

Epoch: 6| Step: 3
Training loss: 3.6279784495797704
Validation loss: 2.976723042608911

Epoch: 6| Step: 4
Training loss: 3.3194422400417127
Validation loss: 2.976832160063857

Epoch: 6| Step: 5
Training loss: 3.0529549214558354
Validation loss: 2.9772239481749825

Epoch: 6| Step: 6
Training loss: 3.2898418019763884
Validation loss: 2.9789947562281216

Epoch: 6| Step: 7
Training loss: 2.9746957767634714
Validation loss: 2.9752416613043677

Epoch: 6| Step: 8
Training loss: 3.3799058086204834
Validation loss: 2.980571174520131

Epoch: 6| Step: 9
Training loss: 3.2638021976149614
Validation loss: 2.983272220533077

Epoch: 6| Step: 10
Training loss: 2.9847571642580646
Validation loss: 2.9723775353338877

Epoch: 6| Step: 11
Training loss: 3.2693889044581024
Validation loss: 2.976347424823693

Epoch: 6| Step: 12
Training loss: 3.077104273375947
Validation loss: 2.9775968957069447

Epoch: 6| Step: 13
Training loss: 3.115489372890361
Validation loss: 2.9799970081658715

Epoch: 103| Step: 0
Training loss: 3.4457878770947445
Validation loss: 2.974260276116811

Epoch: 6| Step: 1
Training loss: 3.253257292916749
Validation loss: 2.975575374777015

Epoch: 6| Step: 2
Training loss: 3.340238063802635
Validation loss: 2.9725005287855693

Epoch: 6| Step: 3
Training loss: 3.5089678996137907
Validation loss: 2.9756575915759833

Epoch: 6| Step: 4
Training loss: 2.66532094100061
Validation loss: 2.972759964749734

Epoch: 6| Step: 5
Training loss: 2.6994739196557562
Validation loss: 2.971883153053988

Epoch: 6| Step: 6
Training loss: 3.366644087485964
Validation loss: 2.9705812446305626

Epoch: 6| Step: 7
Training loss: 3.540131464311309
Validation loss: 2.974438999647106

Epoch: 6| Step: 8
Training loss: 3.1153427440006753
Validation loss: 2.9729858326119185

Epoch: 6| Step: 9
Training loss: 3.2262021803388037
Validation loss: 2.9718295356966076

Epoch: 6| Step: 10
Training loss: 3.803314901357972
Validation loss: 2.9724247803386077

Epoch: 6| Step: 11
Training loss: 2.7586020401209157
Validation loss: 2.975760227354254

Epoch: 6| Step: 12
Training loss: 3.3867452195837005
Validation loss: 2.9773685439576716

Epoch: 6| Step: 13
Training loss: 3.1844029059418038
Validation loss: 2.9759143281557408

Epoch: 104| Step: 0
Training loss: 2.882476373527685
Validation loss: 2.9789443503556825

Epoch: 6| Step: 1
Training loss: 3.006187733344402
Validation loss: 2.9775192888664397

Epoch: 6| Step: 2
Training loss: 3.5634915494512196
Validation loss: 2.9733781990980743

Epoch: 6| Step: 3
Training loss: 2.3989192714870713
Validation loss: 2.974903872212167

Epoch: 6| Step: 4
Training loss: 2.985759473890235
Validation loss: 2.9751146019563817

Epoch: 6| Step: 5
Training loss: 2.9659008609308097
Validation loss: 2.971031725737408

Epoch: 6| Step: 6
Training loss: 2.4694563422567843
Validation loss: 2.973332310843829

Epoch: 6| Step: 7
Training loss: 3.9556004911601605
Validation loss: 2.971844595754486

Epoch: 6| Step: 8
Training loss: 3.879547404211403
Validation loss: 2.9716086285371377

Epoch: 6| Step: 9
Training loss: 2.942366930757006
Validation loss: 2.968548779233894

Epoch: 6| Step: 10
Training loss: 3.9825217331307057
Validation loss: 2.9683239305637747

Epoch: 6| Step: 11
Training loss: 3.456400840737455
Validation loss: 2.9704763215018324

Epoch: 6| Step: 12
Training loss: 3.4422773975437577
Validation loss: 2.966833426653328

Epoch: 6| Step: 13
Training loss: 2.824352129349583
Validation loss: 2.968131095306062

Epoch: 105| Step: 0
Training loss: 3.1346725307438414
Validation loss: 2.9656822359941155

Epoch: 6| Step: 1
Training loss: 3.6058468439601215
Validation loss: 2.966717472542395

Epoch: 6| Step: 2
Training loss: 3.444085488706055
Validation loss: 2.967661772033631

Epoch: 6| Step: 3
Training loss: 2.9727824882340577
Validation loss: 2.967057836158282

Epoch: 6| Step: 4
Training loss: 2.5466481675313286
Validation loss: 2.965472530388911

Epoch: 6| Step: 5
Training loss: 3.3183289111682877
Validation loss: 2.966767244499471

Epoch: 6| Step: 6
Training loss: 3.817623010838139
Validation loss: 2.96871431390787

Epoch: 6| Step: 7
Training loss: 3.1895996359108056
Validation loss: 2.9643256542846053

Epoch: 6| Step: 8
Training loss: 3.1665607903164488
Validation loss: 2.965315865652158

Epoch: 6| Step: 9
Training loss: 3.8562730686480786
Validation loss: 2.962489802049321

Epoch: 6| Step: 10
Training loss: 2.6978481583507175
Validation loss: 2.9620797714870606

Epoch: 6| Step: 11
Training loss: 3.1542094971450267
Validation loss: 2.964447731310854

Epoch: 6| Step: 12
Training loss: 3.0332078411706735
Validation loss: 2.96421665417394

Epoch: 6| Step: 13
Training loss: 3.3166672027689694
Validation loss: 2.966040782113804

Epoch: 106| Step: 0
Training loss: 3.728565373595885
Validation loss: 2.96936492855154

Epoch: 6| Step: 1
Training loss: 2.944212204593322
Validation loss: 2.9681767193516864

Epoch: 6| Step: 2
Training loss: 2.8554610684104955
Validation loss: 2.967036500475152

Epoch: 6| Step: 3
Training loss: 2.7981080475260214
Validation loss: 2.9693468185882153

Epoch: 6| Step: 4
Training loss: 3.56793895263792
Validation loss: 2.963924274623602

Epoch: 6| Step: 5
Training loss: 3.1849842989787582
Validation loss: 2.9685952544023113

Epoch: 6| Step: 6
Training loss: 3.6284552582380227
Validation loss: 2.9679283451484233

Epoch: 6| Step: 7
Training loss: 2.800488572410475
Validation loss: 2.9661569657879805

Epoch: 6| Step: 8
Training loss: 3.3732634421284087
Validation loss: 2.9667536812529876

Epoch: 6| Step: 9
Training loss: 4.1511945453030865
Validation loss: 2.965254252549239

Epoch: 6| Step: 10
Training loss: 2.958010069328951
Validation loss: 2.960872754094658

Epoch: 6| Step: 11
Training loss: 2.881957219311284
Validation loss: 2.9609761672948016

Epoch: 6| Step: 12
Training loss: 3.4005638047783564
Validation loss: 2.959458574903648

Epoch: 6| Step: 13
Training loss: 2.2121158330985766
Validation loss: 2.958407039899802

Epoch: 107| Step: 0
Training loss: 3.803755440408788
Validation loss: 2.9572221398488723

Epoch: 6| Step: 1
Training loss: 3.0152755297627016
Validation loss: 2.960930453943704

Epoch: 6| Step: 2
Training loss: 2.758726146959581
Validation loss: 2.959264509619429

Epoch: 6| Step: 3
Training loss: 3.3089448096294727
Validation loss: 2.9573524801180806

Epoch: 6| Step: 4
Training loss: 3.6469873981430694
Validation loss: 2.9598302054033634

Epoch: 6| Step: 5
Training loss: 2.2214966013159243
Validation loss: 2.9591333612301405

Epoch: 6| Step: 6
Training loss: 4.412660305147897
Validation loss: 2.9585442046859964

Epoch: 6| Step: 7
Training loss: 2.767178374005632
Validation loss: 2.959854155067871

Epoch: 6| Step: 8
Training loss: 2.35450818670684
Validation loss: 2.9575652353449713

Epoch: 6| Step: 9
Training loss: 3.087353963139533
Validation loss: 2.9593947573379755

Epoch: 6| Step: 10
Training loss: 3.1544377629139646
Validation loss: 2.9595563949362846

Epoch: 6| Step: 11
Training loss: 2.2085577892699395
Validation loss: 2.95826292900207

Epoch: 6| Step: 12
Training loss: 3.798836911541895
Validation loss: 2.956745423186222

Epoch: 6| Step: 13
Training loss: 4.373827095845864
Validation loss: 2.958420877116041

Epoch: 108| Step: 0
Training loss: 3.295007836849172
Validation loss: 2.9548615780089786

Epoch: 6| Step: 1
Training loss: 3.2205112416308537
Validation loss: 2.9627558904231477

Epoch: 6| Step: 2
Training loss: 3.1934785313204914
Validation loss: 2.956300178647784

Epoch: 6| Step: 3
Training loss: 4.002229546029479
Validation loss: 2.9592305119518687

Epoch: 6| Step: 4
Training loss: 3.285565689825824
Validation loss: 2.9534246819262053

Epoch: 6| Step: 5
Training loss: 3.3573660587910528
Validation loss: 2.955316233587813

Epoch: 6| Step: 6
Training loss: 2.704547838365919
Validation loss: 2.9549894717638154

Epoch: 6| Step: 7
Training loss: 3.4329208391654
Validation loss: 2.9531201958691837

Epoch: 6| Step: 8
Training loss: 2.353588156947688
Validation loss: 2.9551400786626347

Epoch: 6| Step: 9
Training loss: 3.577506865702078
Validation loss: 2.9527022508467757

Epoch: 6| Step: 10
Training loss: 2.9899575312733724
Validation loss: 2.949949425419707

Epoch: 6| Step: 11
Training loss: 3.2967088124120774
Validation loss: 2.952392622735272

Epoch: 6| Step: 12
Training loss: 2.7644709533832343
Validation loss: 2.9524120645007055

Epoch: 6| Step: 13
Training loss: 3.778688177725495
Validation loss: 2.9501904132250796

Epoch: 109| Step: 0
Training loss: 3.7365662598086535
Validation loss: 2.9511703739108284

Epoch: 6| Step: 1
Training loss: 3.6182092661228196
Validation loss: 2.948833101513132

Epoch: 6| Step: 2
Training loss: 2.752764959099114
Validation loss: 2.950594872337114

Epoch: 6| Step: 3
Training loss: 3.1606438900649163
Validation loss: 2.9500155912042554

Epoch: 6| Step: 4
Training loss: 3.7640070941627126
Validation loss: 2.9497620992951177

Epoch: 6| Step: 5
Training loss: 2.473920309209571
Validation loss: 2.949885920965376

Epoch: 6| Step: 6
Training loss: 3.0904492581874954
Validation loss: 2.94939711173397

Epoch: 6| Step: 7
Training loss: 3.3116122801688364
Validation loss: 2.961538144100317

Epoch: 6| Step: 8
Training loss: 3.6289186015498895
Validation loss: 2.9542603318660254

Epoch: 6| Step: 9
Training loss: 3.1595105241182786
Validation loss: 2.9586108307342527

Epoch: 6| Step: 10
Training loss: 3.604785990930013
Validation loss: 2.9620250168306326

Epoch: 6| Step: 11
Training loss: 3.1088329973787303
Validation loss: 2.951158389493279

Epoch: 6| Step: 12
Training loss: 2.5974445916471915
Validation loss: 2.951675411715465

Epoch: 6| Step: 13
Training loss: 2.6532466289916155
Validation loss: 2.9515931374903253

Epoch: 110| Step: 0
Training loss: 3.066868216345969
Validation loss: 2.946937581649678

Epoch: 6| Step: 1
Training loss: 2.264125143359996
Validation loss: 2.9441031520816607

Epoch: 6| Step: 2
Training loss: 3.212617532086679
Validation loss: 2.9467921703658315

Epoch: 6| Step: 3
Training loss: 2.2245196691952343
Validation loss: 2.9446262371669154

Epoch: 6| Step: 4
Training loss: 3.35265896163584
Validation loss: 2.9482787413684033

Epoch: 6| Step: 5
Training loss: 3.494489009541334
Validation loss: 2.945808150247954

Epoch: 6| Step: 6
Training loss: 3.7796758732768674
Validation loss: 2.9458355844279667

Epoch: 6| Step: 7
Training loss: 3.3820959305741103
Validation loss: 2.945231250973901

Epoch: 6| Step: 8
Training loss: 2.954173068607713
Validation loss: 2.943336872851756

Epoch: 6| Step: 9
Training loss: 4.103537006131827
Validation loss: 2.9493517195855348

Epoch: 6| Step: 10
Training loss: 3.7183052886995043
Validation loss: 2.948722991423919

Epoch: 6| Step: 11
Training loss: 2.9364833289890586
Validation loss: 2.951337615566461

Epoch: 6| Step: 12
Training loss: 3.2979756185950144
Validation loss: 2.957258515967408

Epoch: 6| Step: 13
Training loss: 2.5405824777345596
Validation loss: 2.967181317093903

Epoch: 111| Step: 0
Training loss: 4.053130628218673
Validation loss: 2.967574869160974

Epoch: 6| Step: 1
Training loss: 2.9099717459339343
Validation loss: 2.955987117487547

Epoch: 6| Step: 2
Training loss: 3.3455982269749445
Validation loss: 2.9456310820729805

Epoch: 6| Step: 3
Training loss: 2.638868842690159
Validation loss: 2.943752783352575

Epoch: 6| Step: 4
Training loss: 3.088130586916717
Validation loss: 2.944793338585739

Epoch: 6| Step: 5
Training loss: 1.8605685210185163
Validation loss: 2.9424529558395145

Epoch: 6| Step: 6
Training loss: 3.0751177819497855
Validation loss: 2.9401881333499094

Epoch: 6| Step: 7
Training loss: 3.2464612621943774
Validation loss: 2.9396282054099943

Epoch: 6| Step: 8
Training loss: 3.373905145583747
Validation loss: 2.941403949055027

Epoch: 6| Step: 9
Training loss: 3.3124234172677367
Validation loss: 2.938937184493789

Epoch: 6| Step: 10
Training loss: 3.6431354822416053
Validation loss: 2.941434446017021

Epoch: 6| Step: 11
Training loss: 3.8195607824621476
Validation loss: 2.9413795441108306

Epoch: 6| Step: 12
Training loss: 3.3321115320871337
Validation loss: 2.9377965975933416

Epoch: 6| Step: 13
Training loss: 2.706869982034581
Validation loss: 2.9361514886608253

Epoch: 112| Step: 0
Training loss: 2.6219420105074067
Validation loss: 2.939793616607183

Epoch: 6| Step: 1
Training loss: 3.7760076832612315
Validation loss: 2.9395140648964064

Epoch: 6| Step: 2
Training loss: 3.2870319105734174
Validation loss: 2.935919919459852

Epoch: 6| Step: 3
Training loss: 3.123880872606667
Validation loss: 2.9375375620042554

Epoch: 6| Step: 4
Training loss: 2.7069305797535215
Validation loss: 2.93765947113705

Epoch: 6| Step: 5
Training loss: 2.9582745899940877
Validation loss: 2.935942474961602

Epoch: 6| Step: 6
Training loss: 1.5809351762225567
Validation loss: 2.9375294614286247

Epoch: 6| Step: 7
Training loss: 3.5560504019290238
Validation loss: 2.9356510013244645

Epoch: 6| Step: 8
Training loss: 3.6435707846485075
Validation loss: 2.9344642625321407

Epoch: 6| Step: 9
Training loss: 4.05171532745411
Validation loss: 2.935406377117232

Epoch: 6| Step: 10
Training loss: 3.2540333002938655
Validation loss: 2.9410595644542945

Epoch: 6| Step: 11
Training loss: 3.1780020630951626
Validation loss: 2.94740039620024

Epoch: 6| Step: 12
Training loss: 3.364416695041798
Validation loss: 2.943174840982152

Epoch: 6| Step: 13
Training loss: 3.3457089684074046
Validation loss: 2.9415674110290264

Epoch: 113| Step: 0
Training loss: 3.0928981648653644
Validation loss: 2.937593984398565

Epoch: 6| Step: 1
Training loss: 2.3376944068398906
Validation loss: 2.93584531156566

Epoch: 6| Step: 2
Training loss: 3.4674249816128384
Validation loss: 2.9348093345779507

Epoch: 6| Step: 3
Training loss: 2.817612049951516
Validation loss: 2.9340043188693916

Epoch: 6| Step: 4
Training loss: 3.073971807505697
Validation loss: 2.9305201418497395

Epoch: 6| Step: 5
Training loss: 3.333906140384439
Validation loss: 2.933901631794985

Epoch: 6| Step: 6
Training loss: 2.114881322250057
Validation loss: 2.9322012939818323

Epoch: 6| Step: 7
Training loss: 4.000586466711689
Validation loss: 2.9340893056081896

Epoch: 6| Step: 8
Training loss: 3.1010348161786805
Validation loss: 2.9327905623525203

Epoch: 6| Step: 9
Training loss: 3.1907545939550435
Validation loss: 2.9331091410111925

Epoch: 6| Step: 10
Training loss: 4.014070083652578
Validation loss: 2.930659449863607

Epoch: 6| Step: 11
Training loss: 2.8336683711009534
Validation loss: 2.931830365513956

Epoch: 6| Step: 12
Training loss: 3.62970244478063
Validation loss: 2.930525563026034

Epoch: 6| Step: 13
Training loss: 3.7168891161619633
Validation loss: 2.928190136291808

Epoch: 114| Step: 0
Training loss: 3.0748805263228793
Validation loss: 2.9311997778737653

Epoch: 6| Step: 1
Training loss: 3.466147056176218
Validation loss: 2.9310666031880754

Epoch: 6| Step: 2
Training loss: 3.520969245288793
Validation loss: 2.9314106068353514

Epoch: 6| Step: 3
Training loss: 3.609637890774454
Validation loss: 2.931305759661443

Epoch: 6| Step: 4
Training loss: 3.40238845743266
Validation loss: 2.933374358498115

Epoch: 6| Step: 5
Training loss: 3.2276198753593106
Validation loss: 2.940068856898545

Epoch: 6| Step: 6
Training loss: 3.064186099145304
Validation loss: 2.9773561492261433

Epoch: 6| Step: 7
Training loss: 3.1446331505228375
Validation loss: 2.9362440878284723

Epoch: 6| Step: 8
Training loss: 3.4932810460125685
Validation loss: 2.928526243797607

Epoch: 6| Step: 9
Training loss: 3.3518532935838623
Validation loss: 2.927674226686797

Epoch: 6| Step: 10
Training loss: 2.5650720481346294
Validation loss: 2.9278556915000875

Epoch: 6| Step: 11
Training loss: 3.0133810440720006
Validation loss: 2.9262105981972515

Epoch: 6| Step: 12
Training loss: 3.03465300208749
Validation loss: 2.926801260153376

Epoch: 6| Step: 13
Training loss: 2.624450262725235
Validation loss: 2.929454349551673

Epoch: 115| Step: 0
Training loss: 2.60093631024318
Validation loss: 2.928542720586368

Epoch: 6| Step: 1
Training loss: 3.548513832094352
Validation loss: 2.931658574378292

Epoch: 6| Step: 2
Training loss: 3.273393507777929
Validation loss: 2.936282404533583

Epoch: 6| Step: 3
Training loss: 2.8807416885389823
Validation loss: 2.942520919408867

Epoch: 6| Step: 4
Training loss: 3.661162898524354
Validation loss: 2.9520143850238223

Epoch: 6| Step: 5
Training loss: 2.7946993074761664
Validation loss: 2.951960956515045

Epoch: 6| Step: 6
Training loss: 2.7401020347085643
Validation loss: 2.937311803985135

Epoch: 6| Step: 7
Training loss: 3.2036069926040436
Validation loss: 2.9314798294868973

Epoch: 6| Step: 8
Training loss: 3.8463944433226094
Validation loss: 2.931788756112967

Epoch: 6| Step: 9
Training loss: 2.9644530670934075
Validation loss: 2.926335526782799

Epoch: 6| Step: 10
Training loss: 2.7554053156240266
Validation loss: 2.927276339295108

Epoch: 6| Step: 11
Training loss: 3.2918506683557056
Validation loss: 2.9281861623788448

Epoch: 6| Step: 12
Training loss: 3.3799518003920754
Validation loss: 2.9258266801249353

Epoch: 6| Step: 13
Training loss: 4.0788180759838575
Validation loss: 2.9258032957203977

Epoch: 116| Step: 0
Training loss: 3.3221384570201624
Validation loss: 2.92435599565468

Epoch: 6| Step: 1
Training loss: 3.7431596038895307
Validation loss: 2.9257223618768857

Epoch: 6| Step: 2
Training loss: 3.126043374403161
Validation loss: 2.9312758805999493

Epoch: 6| Step: 3
Training loss: 2.649435119882684
Validation loss: 2.9289153398314487

Epoch: 6| Step: 4
Training loss: 2.660337736013874
Validation loss: 2.9318294806043976

Epoch: 6| Step: 5
Training loss: 2.710721141965191
Validation loss: 2.934608088468215

Epoch: 6| Step: 6
Training loss: 3.413197283367961
Validation loss: 2.934995508245212

Epoch: 6| Step: 7
Training loss: 2.78556711555716
Validation loss: 2.9427284849135535

Epoch: 6| Step: 8
Training loss: 3.371169282811829
Validation loss: 2.9367706084476874

Epoch: 6| Step: 9
Training loss: 3.343074124202835
Validation loss: 2.948008073912723

Epoch: 6| Step: 10
Training loss: 3.682932724606776
Validation loss: 2.9323191987446346

Epoch: 6| Step: 11
Training loss: 2.3470970160542994
Validation loss: 2.9277526241514344

Epoch: 6| Step: 12
Training loss: 3.0996721401962795
Validation loss: 2.9220340710245933

Epoch: 6| Step: 13
Training loss: 4.788111133264066
Validation loss: 2.9221094412612247

Epoch: 117| Step: 0
Training loss: 3.2257831361912475
Validation loss: 2.9233073817252104

Epoch: 6| Step: 1
Training loss: 2.933135015835133
Validation loss: 2.9213542727568695

Epoch: 6| Step: 2
Training loss: 3.1827252098402306
Validation loss: 2.92044937988549

Epoch: 6| Step: 3
Training loss: 3.4296010208523446
Validation loss: 2.9204425073930955

Epoch: 6| Step: 4
Training loss: 3.4576869191956576
Validation loss: 2.9253239469706935

Epoch: 6| Step: 5
Training loss: 3.2307034353047093
Validation loss: 2.921516605735771

Epoch: 6| Step: 6
Training loss: 3.0748719971849665
Validation loss: 2.9225229778969144

Epoch: 6| Step: 7
Training loss: 3.4422954055835704
Validation loss: 2.920818968695099

Epoch: 6| Step: 8
Training loss: 3.7942334943237537
Validation loss: 2.917290776070831

Epoch: 6| Step: 9
Training loss: 2.7146392086560245
Validation loss: 2.9193076668309796

Epoch: 6| Step: 10
Training loss: 2.408873081992176
Validation loss: 2.916575336930811

Epoch: 6| Step: 11
Training loss: 3.1937746110479237
Validation loss: 2.916866250541521

Epoch: 6| Step: 12
Training loss: 3.4285978702252167
Validation loss: 2.9178404407746057

Epoch: 6| Step: 13
Training loss: 3.2004804906120854
Validation loss: 2.91614787033453

Epoch: 118| Step: 0
Training loss: 3.1599357914739015
Validation loss: 2.91454209913928

Epoch: 6| Step: 1
Training loss: 2.8508896961530006
Validation loss: 2.91325716241755

Epoch: 6| Step: 2
Training loss: 3.6452282794064317
Validation loss: 2.913033438066929

Epoch: 6| Step: 3
Training loss: 3.1911600080951166
Validation loss: 2.912292532371042

Epoch: 6| Step: 4
Training loss: 3.650777519709067
Validation loss: 2.91431124428682

Epoch: 6| Step: 5
Training loss: 2.642031684310095
Validation loss: 2.91469207730628

Epoch: 6| Step: 6
Training loss: 2.663697606488442
Validation loss: 2.9131593884757243

Epoch: 6| Step: 7
Training loss: 3.8745820835312657
Validation loss: 2.9159805991052656

Epoch: 6| Step: 8
Training loss: 3.0477842881473154
Validation loss: 2.9125597589636216

Epoch: 6| Step: 9
Training loss: 2.645679940009884
Validation loss: 2.915836710706807

Epoch: 6| Step: 10
Training loss: 3.420852578062937
Validation loss: 2.912637379414127

Epoch: 6| Step: 11
Training loss: 3.35605190836213
Validation loss: 2.9168355309844207

Epoch: 6| Step: 12
Training loss: 3.0504261156934596
Validation loss: 2.91341364528812

Epoch: 6| Step: 13
Training loss: 3.416492426701541
Validation loss: 2.9117164712377592

Epoch: 119| Step: 0
Training loss: 3.3283926269669637
Validation loss: 2.910389314183053

Epoch: 6| Step: 1
Training loss: 2.883851233773614
Validation loss: 2.909823067154856

Epoch: 6| Step: 2
Training loss: 3.1615533369308038
Validation loss: 2.9121260679219145

Epoch: 6| Step: 3
Training loss: 3.4221436556209954
Validation loss: 2.9103597392147633

Epoch: 6| Step: 4
Training loss: 3.024276104528305
Validation loss: 2.9090963823856866

Epoch: 6| Step: 5
Training loss: 3.352669059706546
Validation loss: 2.9104293956030913

Epoch: 6| Step: 6
Training loss: 3.0367115017721256
Validation loss: 2.911104497358254

Epoch: 6| Step: 7
Training loss: 2.693268551031641
Validation loss: 2.9101437773419696

Epoch: 6| Step: 8
Training loss: 3.1184243255774264
Validation loss: 2.908001609487083

Epoch: 6| Step: 9
Training loss: 2.933976352900596
Validation loss: 2.9087147761888144

Epoch: 6| Step: 10
Training loss: 2.8932628246218606
Validation loss: 2.9088946044313255

Epoch: 6| Step: 11
Training loss: 3.390699113308308
Validation loss: 2.91182058691752

Epoch: 6| Step: 12
Training loss: 3.5605537050383615
Validation loss: 2.9108781952934635

Epoch: 6| Step: 13
Training loss: 4.277811939273741
Validation loss: 2.9103736110794576

Epoch: 120| Step: 0
Training loss: 2.8768054434791637
Validation loss: 2.908091793883661

Epoch: 6| Step: 1
Training loss: 2.682104149840804
Validation loss: 2.9081417740530515

Epoch: 6| Step: 2
Training loss: 3.039959380480789
Validation loss: 2.9074317187108756

Epoch: 6| Step: 3
Training loss: 3.7663254462331532
Validation loss: 2.909917826526749

Epoch: 6| Step: 4
Training loss: 3.155667997276203
Validation loss: 2.9063391564302856

Epoch: 6| Step: 5
Training loss: 2.815467201747772
Validation loss: 2.907849989372202

Epoch: 6| Step: 6
Training loss: 2.8179579440322944
Validation loss: 2.9086956610726635

Epoch: 6| Step: 7
Training loss: 3.2403727036853436
Validation loss: 2.9048973240846907

Epoch: 6| Step: 8
Training loss: 3.521427909411067
Validation loss: 2.9064496999725677

Epoch: 6| Step: 9
Training loss: 3.7781551085377534
Validation loss: 2.902490405916473

Epoch: 6| Step: 10
Training loss: 2.863153015012982
Validation loss: 2.9033534231588476

Epoch: 6| Step: 11
Training loss: 3.431007496197705
Validation loss: 2.9060263440161163

Epoch: 6| Step: 12
Training loss: 3.635384779009655
Validation loss: 2.9046557611358277

Epoch: 6| Step: 13
Training loss: 2.5716363807752365
Validation loss: 2.9001640535443274

Epoch: 121| Step: 0
Training loss: 3.6894402006457057
Validation loss: 2.9031880329835436

Epoch: 6| Step: 1
Training loss: 3.068743511123168
Validation loss: 2.9012037085309457

Epoch: 6| Step: 2
Training loss: 3.1555948616170713
Validation loss: 2.899793585318421

Epoch: 6| Step: 3
Training loss: 2.83710903213417
Validation loss: 2.901991453507299

Epoch: 6| Step: 4
Training loss: 3.482044073247717
Validation loss: 2.9009217300641508

Epoch: 6| Step: 5
Training loss: 3.0088424702639816
Validation loss: 2.9010195647415644

Epoch: 6| Step: 6
Training loss: 3.1880522604838477
Validation loss: 2.8966089801766755

Epoch: 6| Step: 7
Training loss: 3.154293246901938
Validation loss: 2.9008597885478884

Epoch: 6| Step: 8
Training loss: 3.0317659233947816
Validation loss: 2.9009348446341305

Epoch: 6| Step: 9
Training loss: 3.435528831586359
Validation loss: 2.9204751114278373

Epoch: 6| Step: 10
Training loss: 2.6935485375072545
Validation loss: 2.908771616652444

Epoch: 6| Step: 11
Training loss: 3.1654229147633783
Validation loss: 2.901435078799007

Epoch: 6| Step: 12
Training loss: 3.1682634510545498
Validation loss: 2.8999920829718633

Epoch: 6| Step: 13
Training loss: 3.7320345004368827
Validation loss: 2.9004285341229012

Epoch: 122| Step: 0
Training loss: 2.9518365218840814
Validation loss: 2.9020851717984026

Epoch: 6| Step: 1
Training loss: 2.015483999125873
Validation loss: 2.9013843204038836

Epoch: 6| Step: 2
Training loss: 3.5097860039579483
Validation loss: 2.899888919956122

Epoch: 6| Step: 3
Training loss: 3.9363181141798624
Validation loss: 2.90031739868213

Epoch: 6| Step: 4
Training loss: 2.981822095316499
Validation loss: 2.8978244779009232

Epoch: 6| Step: 5
Training loss: 2.5665574863876746
Validation loss: 2.901395378539542

Epoch: 6| Step: 6
Training loss: 3.326689217923569
Validation loss: 2.903445138189082

Epoch: 6| Step: 7
Training loss: 3.7659872680140913
Validation loss: 2.9040024087288474

Epoch: 6| Step: 8
Training loss: 3.0025001280671026
Validation loss: 2.9033110603795005

Epoch: 6| Step: 9
Training loss: 3.1455792120214623
Validation loss: 2.901160036588595

Epoch: 6| Step: 10
Training loss: 3.3123351721870953
Validation loss: 2.9031733452877866

Epoch: 6| Step: 11
Training loss: 3.360259183696432
Validation loss: 2.9031833237099995

Epoch: 6| Step: 12
Training loss: 3.233825636938713
Validation loss: 2.904916835734892

Epoch: 6| Step: 13
Training loss: 3.013195264685812
Validation loss: 2.9092816574959106

Epoch: 123| Step: 0
Training loss: 2.9526329639802693
Validation loss: 2.9223058871009298

Epoch: 6| Step: 1
Training loss: 3.950363581861047
Validation loss: 2.9196187252306296

Epoch: 6| Step: 2
Training loss: 2.7811500445631365
Validation loss: 2.9169237987426433

Epoch: 6| Step: 3
Training loss: 3.155391160804877
Validation loss: 2.906440877672098

Epoch: 6| Step: 4
Training loss: 3.388626423731571
Validation loss: 2.9000502771892687

Epoch: 6| Step: 5
Training loss: 3.6360274332856
Validation loss: 2.894363863243231

Epoch: 6| Step: 6
Training loss: 3.3758727464059954
Validation loss: 2.8940370013254895

Epoch: 6| Step: 7
Training loss: 3.473581197342836
Validation loss: 2.897958476930937

Epoch: 6| Step: 8
Training loss: 2.6883634909987726
Validation loss: 2.8988610091374563

Epoch: 6| Step: 9
Training loss: 2.5197774604143532
Validation loss: 2.8968008010972035

Epoch: 6| Step: 10
Training loss: 2.9595547872229395
Validation loss: 2.898641254699728

Epoch: 6| Step: 11
Training loss: 2.461187150190521
Validation loss: 2.8979055769383573

Epoch: 6| Step: 12
Training loss: 3.2106232500953356
Validation loss: 2.8989271179320055

Epoch: 6| Step: 13
Training loss: 4.166380961477492
Validation loss: 2.897715464097361

Epoch: 124| Step: 0
Training loss: 3.61578724331452
Validation loss: 2.897931670543459

Epoch: 6| Step: 1
Training loss: 3.0047182491195072
Validation loss: 2.897778053183125

Epoch: 6| Step: 2
Training loss: 3.7664307804570907
Validation loss: 2.895157820593575

Epoch: 6| Step: 3
Training loss: 3.215239452978617
Validation loss: 2.895424905585514

Epoch: 6| Step: 4
Training loss: 3.075740762201374
Validation loss: 2.892326770638309

Epoch: 6| Step: 5
Training loss: 3.1381771739883964
Validation loss: 2.8922141981616383

Epoch: 6| Step: 6
Training loss: 4.012821153759602
Validation loss: 2.8916218775585936

Epoch: 6| Step: 7
Training loss: 2.608361784157252
Validation loss: 2.8921864290844237

Epoch: 6| Step: 8
Training loss: 3.3775634920038278
Validation loss: 2.891028060239117

Epoch: 6| Step: 9
Training loss: 3.533366826336542
Validation loss: 2.894757902773148

Epoch: 6| Step: 10
Training loss: 2.3571567844623456
Validation loss: 2.892402281257631

Epoch: 6| Step: 11
Training loss: 2.575492763591325
Validation loss: 2.8957981432971147

Epoch: 6| Step: 12
Training loss: 2.20339120108849
Validation loss: 2.895631540709487

Epoch: 6| Step: 13
Training loss: 3.714199327155949
Validation loss: 2.904421242099142

Epoch: 125| Step: 0
Training loss: 3.398934163599867
Validation loss: 2.9057392734988765

Epoch: 6| Step: 1
Training loss: 2.5635534772687403
Validation loss: 2.9052345265138473

Epoch: 6| Step: 2
Training loss: 3.4922699715862975
Validation loss: 2.905629909034623

Epoch: 6| Step: 3
Training loss: 3.4309798393135273
Validation loss: 2.8978199076524254

Epoch: 6| Step: 4
Training loss: 3.266209892204805
Validation loss: 2.8996095332244556

Epoch: 6| Step: 5
Training loss: 2.7157247088249417
Validation loss: 2.8981004682700786

Epoch: 6| Step: 6
Training loss: 3.221391797392035
Validation loss: 2.899578825352579

Epoch: 6| Step: 7
Training loss: 3.061926651826753
Validation loss: 2.896678275137671

Epoch: 6| Step: 8
Training loss: 2.9908546287846325
Validation loss: 2.8912697208037477

Epoch: 6| Step: 9
Training loss: 3.3486218478695524
Validation loss: 2.890956671836939

Epoch: 6| Step: 10
Training loss: 3.7089679189340043
Validation loss: 2.8924496307186423

Epoch: 6| Step: 11
Training loss: 2.8207178220853346
Validation loss: 2.8874068154730157

Epoch: 6| Step: 12
Training loss: 3.6246912594563683
Validation loss: 2.8858989248739007

Epoch: 6| Step: 13
Training loss: 2.071702943680157
Validation loss: 2.8883087802620624

Epoch: 126| Step: 0
Training loss: 2.627818819370263
Validation loss: 2.8900326171438366

Epoch: 6| Step: 1
Training loss: 3.720385536396559
Validation loss: 2.886022781664876

Epoch: 6| Step: 2
Training loss: 3.50531106980621
Validation loss: 2.885276398907498

Epoch: 6| Step: 3
Training loss: 3.4386774994096623
Validation loss: 2.886172495522485

Epoch: 6| Step: 4
Training loss: 3.1981531774350476
Validation loss: 2.8868140377633225

Epoch: 6| Step: 5
Training loss: 3.494010978327745
Validation loss: 2.8830162136656354

Epoch: 6| Step: 6
Training loss: 2.880393897776423
Validation loss: 2.887231592648971

Epoch: 6| Step: 7
Training loss: 2.579089360062008
Validation loss: 2.886927828712537

Epoch: 6| Step: 8
Training loss: 2.9794768236452454
Validation loss: 2.884938193086926

Epoch: 6| Step: 9
Training loss: 3.7878441179018227
Validation loss: 2.88466977900358

Epoch: 6| Step: 10
Training loss: 2.978091670647379
Validation loss: 2.8886986936558032

Epoch: 6| Step: 11
Training loss: 2.8507244394025073
Validation loss: 2.8903790095168076

Epoch: 6| Step: 12
Training loss: 2.9262851337212323
Validation loss: 2.8956696900892482

Epoch: 6| Step: 13
Training loss: 3.212625398674653
Validation loss: 2.9013909968190754

Epoch: 127| Step: 0
Training loss: 2.9900064911022346
Validation loss: 2.9048170821596795

Epoch: 6| Step: 1
Training loss: 3.1472071664586045
Validation loss: 2.899820506220315

Epoch: 6| Step: 2
Training loss: 3.4153863012001704
Validation loss: 2.9069965191936658

Epoch: 6| Step: 3
Training loss: 2.52244269541289
Validation loss: 2.8906963327392567

Epoch: 6| Step: 4
Training loss: 3.562794589528059
Validation loss: 2.8942773663425974

Epoch: 6| Step: 5
Training loss: 3.145732162229775
Validation loss: 2.8847223458391524

Epoch: 6| Step: 6
Training loss: 3.232871770522851
Validation loss: 2.8948818587465386

Epoch: 6| Step: 7
Training loss: 2.663625373663794
Validation loss: 2.8921029146017405

Epoch: 6| Step: 8
Training loss: 3.475261453357064
Validation loss: 2.8898597988231964

Epoch: 6| Step: 9
Training loss: 3.0209764819374123
Validation loss: 2.889793143712689

Epoch: 6| Step: 10
Training loss: 3.109557333349428
Validation loss: 2.8836528136838933

Epoch: 6| Step: 11
Training loss: 3.0954668309858206
Validation loss: 2.884755390914544

Epoch: 6| Step: 12
Training loss: 3.290055439954414
Validation loss: 2.882065486001053

Epoch: 6| Step: 13
Training loss: 3.7767155469091955
Validation loss: 2.878834691020081

Epoch: 128| Step: 0
Training loss: 2.87434860811271
Validation loss: 2.8822874541560046

Epoch: 6| Step: 1
Training loss: 2.8872575270006102
Validation loss: 2.881470988461191

Epoch: 6| Step: 2
Training loss: 3.8438613999513733
Validation loss: 2.8848879744302844

Epoch: 6| Step: 3
Training loss: 2.6149265828958845
Validation loss: 2.8805564974496614

Epoch: 6| Step: 4
Training loss: 2.9647207121518226
Validation loss: 2.8779564254290713

Epoch: 6| Step: 5
Training loss: 2.4264491047987615
Validation loss: 2.8815503164530654

Epoch: 6| Step: 6
Training loss: 3.1932252814927193
Validation loss: 2.8796671044519533

Epoch: 6| Step: 7
Training loss: 3.3323492186905646
Validation loss: 2.8789021911383217

Epoch: 6| Step: 8
Training loss: 3.3842285575426936
Validation loss: 2.8763716111194944

Epoch: 6| Step: 9
Training loss: 3.769574005991328
Validation loss: 2.877801526206661

Epoch: 6| Step: 10
Training loss: 3.3641337910285953
Validation loss: 2.87192325826661

Epoch: 6| Step: 11
Training loss: 2.67254933553465
Validation loss: 2.873989335981664

Epoch: 6| Step: 12
Training loss: 3.815944678859254
Validation loss: 2.8719136193467825

Epoch: 6| Step: 13
Training loss: 2.5532765823245955
Validation loss: 2.875661833541535

Epoch: 129| Step: 0
Training loss: 3.438452848673908
Validation loss: 2.873250526210688

Epoch: 6| Step: 1
Training loss: 3.3111534980717776
Validation loss: 2.873403279682001

Epoch: 6| Step: 2
Training loss: 2.7700194021433737
Validation loss: 2.8746651146352007

Epoch: 6| Step: 3
Training loss: 2.4635603233958974
Validation loss: 2.8736619443839846

Epoch: 6| Step: 4
Training loss: 3.2708785586460034
Validation loss: 2.8755114913147275

Epoch: 6| Step: 5
Training loss: 3.347024045558659
Validation loss: 2.871486882175417

Epoch: 6| Step: 6
Training loss: 2.9693101856349777
Validation loss: 2.871718138142532

Epoch: 6| Step: 7
Training loss: 3.626301498915273
Validation loss: 2.8733397751028775

Epoch: 6| Step: 8
Training loss: 3.1555715908246063
Validation loss: 2.878021273852055

Epoch: 6| Step: 9
Training loss: 2.5091718275544364
Validation loss: 2.879667403577921

Epoch: 6| Step: 10
Training loss: 3.8493935937272914
Validation loss: 2.8812764742137267

Epoch: 6| Step: 11
Training loss: 3.5538645703514664
Validation loss: 2.8834098336904783

Epoch: 6| Step: 12
Training loss: 2.6846711107565686
Validation loss: 2.8846771153117734

Epoch: 6| Step: 13
Training loss: 2.92364953973019
Validation loss: 2.883689067912362

Epoch: 130| Step: 0
Training loss: 2.9645754726696194
Validation loss: 2.8799633272091

Epoch: 6| Step: 1
Training loss: 3.8290181266413392
Validation loss: 2.8756327064411025

Epoch: 6| Step: 2
Training loss: 3.272048109078624
Validation loss: 2.870953171490166

Epoch: 6| Step: 3
Training loss: 3.0035868500951413
Validation loss: 2.870990330804382

Epoch: 6| Step: 4
Training loss: 2.697320427914475
Validation loss: 2.867572823915128

Epoch: 6| Step: 5
Training loss: 1.7573932062860163
Validation loss: 2.866414836483118

Epoch: 6| Step: 6
Training loss: 3.3295365326631976
Validation loss: 2.870794820664866

Epoch: 6| Step: 7
Training loss: 3.279751971566618
Validation loss: 2.8684555655777406

Epoch: 6| Step: 8
Training loss: 3.7261797630449713
Validation loss: 2.8702114883454803

Epoch: 6| Step: 9
Training loss: 3.427485634671414
Validation loss: 2.8687592461957294

Epoch: 6| Step: 10
Training loss: 3.2303485963333753
Validation loss: 2.868556079122906

Epoch: 6| Step: 11
Training loss: 2.7951579870568
Validation loss: 2.869845513074129

Epoch: 6| Step: 12
Training loss: 2.9346682920935274
Validation loss: 2.868696299226414

Epoch: 6| Step: 13
Training loss: 3.868513523448447
Validation loss: 2.8690865574666238

Epoch: 131| Step: 0
Training loss: 2.611472012443814
Validation loss: 2.867539701523376

Epoch: 6| Step: 1
Training loss: 2.958312468835745
Validation loss: 2.8693322594390898

Epoch: 6| Step: 2
Training loss: 3.293113841054026
Validation loss: 2.8800729898064685

Epoch: 6| Step: 3
Training loss: 2.6844958880985037
Validation loss: 2.8765242710398296

Epoch: 6| Step: 4
Training loss: 2.892685274538898
Validation loss: 2.8722118199407625

Epoch: 6| Step: 5
Training loss: 3.400018574159039
Validation loss: 2.885789187841033

Epoch: 6| Step: 6
Training loss: 3.504831113351637
Validation loss: 2.8742014563772007

Epoch: 6| Step: 7
Training loss: 2.8129112790650903
Validation loss: 2.8703818608309564

Epoch: 6| Step: 8
Training loss: 3.2308994361294867
Validation loss: 2.8639272102105533

Epoch: 6| Step: 9
Training loss: 3.2412619866893544
Validation loss: 2.866991413988302

Epoch: 6| Step: 10
Training loss: 2.8982114472369864
Validation loss: 2.863345222086987

Epoch: 6| Step: 11
Training loss: 4.0699399459119885
Validation loss: 2.8639661023659246

Epoch: 6| Step: 12
Training loss: 3.0468604454279777
Validation loss: 2.862603034700416

Epoch: 6| Step: 13
Training loss: 3.379604307183361
Validation loss: 2.869012975376301

Epoch: 132| Step: 0
Training loss: 2.9494033856732615
Validation loss: 2.8654949365775595

Epoch: 6| Step: 1
Training loss: 2.6617666067216423
Validation loss: 2.880717386396916

Epoch: 6| Step: 2
Training loss: 3.7731584718264384
Validation loss: 2.9318503292474527

Epoch: 6| Step: 3
Training loss: 3.2688292338758993
Validation loss: 2.9440710596291537

Epoch: 6| Step: 4
Training loss: 3.148120949405369
Validation loss: 2.964482023707614

Epoch: 6| Step: 5
Training loss: 2.7563762436930945
Validation loss: 2.9190601984467643

Epoch: 6| Step: 6
Training loss: 3.1102477722576998
Validation loss: 2.8794163761085394

Epoch: 6| Step: 7
Training loss: 3.9452094036266763
Validation loss: 2.862931364996589

Epoch: 6| Step: 8
Training loss: 3.6022955092685263
Validation loss: 2.8572028615615834

Epoch: 6| Step: 9
Training loss: 3.5477960541780043
Validation loss: 2.8582547779159615

Epoch: 6| Step: 10
Training loss: 2.4780120939339874
Validation loss: 2.8591207894136272

Epoch: 6| Step: 11
Training loss: 3.49539112723959
Validation loss: 2.8599315800719736

Epoch: 6| Step: 12
Training loss: 2.717289850414297
Validation loss: 2.8675636790656385

Epoch: 6| Step: 13
Training loss: 1.8518020539299245
Validation loss: 2.8697568478420674

Epoch: 133| Step: 0
Training loss: 3.2296773363164792
Validation loss: 2.871812754206681

Epoch: 6| Step: 1
Training loss: 2.8443845942114785
Validation loss: 2.8784946613771516

Epoch: 6| Step: 2
Training loss: 3.859627163328705
Validation loss: 2.8661269246313372

Epoch: 6| Step: 3
Training loss: 3.371880255015382
Validation loss: 2.8628753695417464

Epoch: 6| Step: 4
Training loss: 3.2107634485597694
Validation loss: 2.863714813990101

Epoch: 6| Step: 5
Training loss: 2.594311756749936
Validation loss: 2.855733412847631

Epoch: 6| Step: 6
Training loss: 3.215045760379315
Validation loss: 2.8602821475190723

Epoch: 6| Step: 7
Training loss: 3.2433476957478202
Validation loss: 2.8550100198085047

Epoch: 6| Step: 8
Training loss: 3.6773855861393576
Validation loss: 2.854600369674515

Epoch: 6| Step: 9
Training loss: 3.090220894926989
Validation loss: 2.858435979756966

Epoch: 6| Step: 10
Training loss: 3.1200863163574493
Validation loss: 2.8706441663859703

Epoch: 6| Step: 11
Training loss: 2.8964190176691504
Validation loss: 2.870091376953581

Epoch: 6| Step: 12
Training loss: 2.4488855162622514
Validation loss: 2.9083074457894753

Epoch: 6| Step: 13
Training loss: 3.2833774027957023
Validation loss: 2.8608517616026155

Epoch: 134| Step: 0
Training loss: 3.5695912239845695
Validation loss: 2.8582818496799827

Epoch: 6| Step: 1
Training loss: 2.5240071601463843
Validation loss: 2.860075346354866

Epoch: 6| Step: 2
Training loss: 2.2871764032329502
Validation loss: 2.8640168024493597

Epoch: 6| Step: 3
Training loss: 3.4798798582012354
Validation loss: 2.874294538650182

Epoch: 6| Step: 4
Training loss: 2.730123473508667
Validation loss: 2.883354291947008

Epoch: 6| Step: 5
Training loss: 3.2382341296330495
Validation loss: 2.887014833519089

Epoch: 6| Step: 6
Training loss: 2.717738785627323
Validation loss: 2.8921435481699977

Epoch: 6| Step: 7
Training loss: 3.1674997003640963
Validation loss: 2.884012256261583

Epoch: 6| Step: 8
Training loss: 3.2635251827820086
Validation loss: 2.8683750504956733

Epoch: 6| Step: 9
Training loss: 4.090550227753167
Validation loss: 2.859575736718449

Epoch: 6| Step: 10
Training loss: 3.349580903669086
Validation loss: 2.857913513395228

Epoch: 6| Step: 11
Training loss: 3.2548467735403572
Validation loss: 2.8562406695086433

Epoch: 6| Step: 12
Training loss: 3.164207172618443
Validation loss: 2.866358655967097

Epoch: 6| Step: 13
Training loss: 2.6824860042551766
Validation loss: 2.8685250053061817

Epoch: 135| Step: 0
Training loss: 3.496916911647014
Validation loss: 2.8674575666402466

Epoch: 6| Step: 1
Training loss: 3.270812081107974
Validation loss: 2.8746884441585427

Epoch: 6| Step: 2
Training loss: 2.9943135728548884
Validation loss: 2.8638301681844993

Epoch: 6| Step: 3
Training loss: 2.771111342936471
Validation loss: 2.8609018000013493

Epoch: 6| Step: 4
Training loss: 3.6489210441412614
Validation loss: 2.8587889411148977

Epoch: 6| Step: 5
Training loss: 2.8358458617145974
Validation loss: 2.8590224149701378

Epoch: 6| Step: 6
Training loss: 3.3040961419588895
Validation loss: 2.8538606654942256

Epoch: 6| Step: 7
Training loss: 3.5874630544002835
Validation loss: 2.857283579309797

Epoch: 6| Step: 8
Training loss: 2.1736322333542226
Validation loss: 2.8546255838717

Epoch: 6| Step: 9
Training loss: 3.9565036493499326
Validation loss: 2.8528390779927375

Epoch: 6| Step: 10
Training loss: 3.1042236903199254
Validation loss: 2.8551877677830997

Epoch: 6| Step: 11
Training loss: 2.3425727430710857
Validation loss: 2.853284695204244

Epoch: 6| Step: 12
Training loss: 3.284894681081252
Validation loss: 2.8512877863097814

Epoch: 6| Step: 13
Training loss: 2.8514277178121183
Validation loss: 2.8507174159042865

Epoch: 136| Step: 0
Training loss: 3.5704786399733384
Validation loss: 2.8524013048078842

Epoch: 6| Step: 1
Training loss: 2.9229796254416605
Validation loss: 2.8524372102741364

Epoch: 6| Step: 2
Training loss: 2.2640192063261675
Validation loss: 2.849327435281328

Epoch: 6| Step: 3
Training loss: 2.881432841492534
Validation loss: 2.8501892460222362

Epoch: 6| Step: 4
Training loss: 3.3640487450913352
Validation loss: 2.852932106025089

Epoch: 6| Step: 5
Training loss: 2.9356186706331795
Validation loss: 2.852443010829458

Epoch: 6| Step: 6
Training loss: 3.9534335411799155
Validation loss: 2.853019919317718

Epoch: 6| Step: 7
Training loss: 3.091232354298479
Validation loss: 2.851453253158797

Epoch: 6| Step: 8
Training loss: 3.1070649273500153
Validation loss: 2.844539635023734

Epoch: 6| Step: 9
Training loss: 2.8988642211361
Validation loss: 2.847407156034515

Epoch: 6| Step: 10
Training loss: 2.643115883390012
Validation loss: 2.8527916947501786

Epoch: 6| Step: 11
Training loss: 3.1377440946546358
Validation loss: 2.8476736736441173

Epoch: 6| Step: 12
Training loss: 3.972068060408038
Validation loss: 2.8518265679875263

Epoch: 6| Step: 13
Training loss: 2.6821829073192287
Validation loss: 2.8498870265196143

Epoch: 137| Step: 0
Training loss: 3.1203578802408627
Validation loss: 2.8553675750943404

Epoch: 6| Step: 1
Training loss: 2.780537546179755
Validation loss: 2.873231549009694

Epoch: 6| Step: 2
Training loss: 3.4457123193552226
Validation loss: 2.864652123543517

Epoch: 6| Step: 3
Training loss: 2.972582782333765
Validation loss: 2.8786613099799485

Epoch: 6| Step: 4
Training loss: 3.3389687267482944
Validation loss: 2.88754232604924

Epoch: 6| Step: 5
Training loss: 2.6826886423410388
Validation loss: 2.896494087928337

Epoch: 6| Step: 6
Training loss: 3.7468329725541207
Validation loss: 2.885751223216425

Epoch: 6| Step: 7
Training loss: 3.269645151139138
Validation loss: 2.8780637879702233

Epoch: 6| Step: 8
Training loss: 3.0897814024604124
Validation loss: 2.873745666494073

Epoch: 6| Step: 9
Training loss: 2.959634217266081
Validation loss: 2.856754663497007

Epoch: 6| Step: 10
Training loss: 3.3071008982669943
Validation loss: 2.8584203446090233

Epoch: 6| Step: 11
Training loss: 3.527647898795453
Validation loss: 2.850309098786433

Epoch: 6| Step: 12
Training loss: 3.0113569504940085
Validation loss: 2.841465157091284

Epoch: 6| Step: 13
Training loss: 2.2218301374195772
Validation loss: 2.8405973115624765

Epoch: 138| Step: 0
Training loss: 2.5264619353126014
Validation loss: 2.842070748017277

Epoch: 6| Step: 1
Training loss: 3.3333464304348817
Validation loss: 2.8433353464785247

Epoch: 6| Step: 2
Training loss: 4.050793021469155
Validation loss: 2.845676251584929

Epoch: 6| Step: 3
Training loss: 3.3001285065569856
Validation loss: 2.8423571902901568

Epoch: 6| Step: 4
Training loss: 2.9648907121198333
Validation loss: 2.8446577206237054

Epoch: 6| Step: 5
Training loss: 3.079099704150248
Validation loss: 2.842715084403227

Epoch: 6| Step: 6
Training loss: 3.2023171499375542
Validation loss: 2.845220309878862

Epoch: 6| Step: 7
Training loss: 3.424790903655966
Validation loss: 2.839231239831645

Epoch: 6| Step: 8
Training loss: 3.2906499008584205
Validation loss: 2.8403116738272445

Epoch: 6| Step: 9
Training loss: 3.055433879703062
Validation loss: 2.8418741350800425

Epoch: 6| Step: 10
Training loss: 2.664337591471953
Validation loss: 2.843391480598267

Epoch: 6| Step: 11
Training loss: 3.446646157602746
Validation loss: 2.8410114190251057

Epoch: 6| Step: 12
Training loss: 1.98328664174403
Validation loss: 2.8443155160242726

Epoch: 6| Step: 13
Training loss: 3.284832406609835
Validation loss: 2.8425682251015387

Epoch: 139| Step: 0
Training loss: 3.6323635685313964
Validation loss: 2.8410321274158328

Epoch: 6| Step: 1
Training loss: 2.704621710988126
Validation loss: 2.84132478727762

Epoch: 6| Step: 2
Training loss: 2.78262655074932
Validation loss: 2.84284284894452

Epoch: 6| Step: 3
Training loss: 2.8098331947639634
Validation loss: 2.8460605983594682

Epoch: 6| Step: 4
Training loss: 2.501652362264984
Validation loss: 2.8478269051142773

Epoch: 6| Step: 5
Training loss: 3.284862455278403
Validation loss: 2.8575312749433595

Epoch: 6| Step: 6
Training loss: 3.5219617912477115
Validation loss: 2.8483580160613915

Epoch: 6| Step: 7
Training loss: 3.3167452689462222
Validation loss: 2.8479851854400375

Epoch: 6| Step: 8
Training loss: 3.4489945093621635
Validation loss: 2.8483562447790205

Epoch: 6| Step: 9
Training loss: 2.0707726309135026
Validation loss: 2.8449587934249116

Epoch: 6| Step: 10
Training loss: 3.3016128124586497
Validation loss: 2.8510714667957013

Epoch: 6| Step: 11
Training loss: 2.7559626699834463
Validation loss: 2.8565818915657935

Epoch: 6| Step: 12
Training loss: 3.807955675716651
Validation loss: 2.845438695053702

Epoch: 6| Step: 13
Training loss: 3.781627793788272
Validation loss: 2.848026741895708

Epoch: 140| Step: 0
Training loss: 3.646506082136113
Validation loss: 2.838736806579761

Epoch: 6| Step: 1
Training loss: 3.261482933793951
Validation loss: 2.8369921694357267

Epoch: 6| Step: 2
Training loss: 3.4451987319120163
Validation loss: 2.8352152725882327

Epoch: 6| Step: 3
Training loss: 2.9060407993946993
Validation loss: 2.8367993597680417

Epoch: 6| Step: 4
Training loss: 2.9737618955460046
Validation loss: 2.834583253483346

Epoch: 6| Step: 5
Training loss: 2.8747170350516607
Validation loss: 2.8344734110139664

Epoch: 6| Step: 6
Training loss: 3.0750782406165027
Validation loss: 2.8374535180273073

Epoch: 6| Step: 7
Training loss: 3.587077439573213
Validation loss: 2.8358426741640743

Epoch: 6| Step: 8
Training loss: 3.5211440782524095
Validation loss: 2.8353907542497203

Epoch: 6| Step: 9
Training loss: 3.200397949508355
Validation loss: 2.8336554844199933

Epoch: 6| Step: 10
Training loss: 2.4906567503318544
Validation loss: 2.835259963000639

Epoch: 6| Step: 11
Training loss: 3.163032119071714
Validation loss: 2.833343434059433

Epoch: 6| Step: 12
Training loss: 2.938198087814173
Validation loss: 2.8339505072355506

Epoch: 6| Step: 13
Training loss: 2.045836206914537
Validation loss: 2.843446194497574

Epoch: 141| Step: 0
Training loss: 3.271005387043169
Validation loss: 2.8413376328591555

Epoch: 6| Step: 1
Training loss: 2.727470880592491
Validation loss: 2.846990812795247

Epoch: 6| Step: 2
Training loss: 3.5476656801274413
Validation loss: 2.842585441839238

Epoch: 6| Step: 3
Training loss: 3.8930653957593853
Validation loss: 2.8441669023741314

Epoch: 6| Step: 4
Training loss: 2.900836620012975
Validation loss: 2.8475715807710764

Epoch: 6| Step: 5
Training loss: 2.713181328354636
Validation loss: 2.8411185967838954

Epoch: 6| Step: 6
Training loss: 2.6034283519634975
Validation loss: 2.8473475275513085

Epoch: 6| Step: 7
Training loss: 3.016801831780856
Validation loss: 2.851160828196801

Epoch: 6| Step: 8
Training loss: 3.471714711716788
Validation loss: 2.8489632099266826

Epoch: 6| Step: 9
Training loss: 3.241772728552078
Validation loss: 2.8471140147557494

Epoch: 6| Step: 10
Training loss: 3.1266982995109314
Validation loss: 2.8414802431538964

Epoch: 6| Step: 11
Training loss: 3.2463775400542
Validation loss: 2.8341958478224893

Epoch: 6| Step: 12
Training loss: 2.549943631615033
Validation loss: 2.8338393954383734

Epoch: 6| Step: 13
Training loss: 3.2365223118982263
Validation loss: 2.828877632334002

Epoch: 142| Step: 0
Training loss: 3.1486059101205557
Validation loss: 2.8377173947585916

Epoch: 6| Step: 1
Training loss: 3.5576820587518148
Validation loss: 2.826389996818148

Epoch: 6| Step: 2
Training loss: 3.5127646784313855
Validation loss: 2.8280052930686037

Epoch: 6| Step: 3
Training loss: 2.9532590159529892
Validation loss: 2.825287214571131

Epoch: 6| Step: 4
Training loss: 3.4658117823577754
Validation loss: 2.8254571003098716

Epoch: 6| Step: 5
Training loss: 2.8461211662636923
Validation loss: 2.827414442010996

Epoch: 6| Step: 6
Training loss: 3.4681230957993963
Validation loss: 2.821499313449398

Epoch: 6| Step: 7
Training loss: 2.924458875894287
Validation loss: 2.826117646708883

Epoch: 6| Step: 8
Training loss: 2.355136322805757
Validation loss: 2.8214847547643456

Epoch: 6| Step: 9
Training loss: 3.3483739237194574
Validation loss: 2.825298128650891

Epoch: 6| Step: 10
Training loss: 3.1711736194883695
Validation loss: 2.8240059744776262

Epoch: 6| Step: 11
Training loss: 3.2079196679766477
Validation loss: 2.823668192613862

Epoch: 6| Step: 12
Training loss: 3.19946407360301
Validation loss: 2.8237582024266383

Epoch: 6| Step: 13
Training loss: 1.4310268111473006
Validation loss: 2.823490619528036

Epoch: 143| Step: 0
Training loss: 2.361159401443422
Validation loss: 2.8264929636102294

Epoch: 6| Step: 1
Training loss: 2.762909757854499
Validation loss: 2.8259684307632256

Epoch: 6| Step: 2
Training loss: 3.9830193101863545
Validation loss: 2.8240060425628384

Epoch: 6| Step: 3
Training loss: 3.2495058124124574
Validation loss: 2.8257951174141756

Epoch: 6| Step: 4
Training loss: 2.8373969239994055
Validation loss: 2.8255016492783356

Epoch: 6| Step: 5
Training loss: 3.119822370901357
Validation loss: 2.826556286297401

Epoch: 6| Step: 6
Training loss: 2.8385979229779905
Validation loss: 2.8287833220426903

Epoch: 6| Step: 7
Training loss: 3.338150612497697
Validation loss: 2.8362355710784675

Epoch: 6| Step: 8
Training loss: 3.0618973742428905
Validation loss: 2.8399061069857816

Epoch: 6| Step: 9
Training loss: 3.431488884842391
Validation loss: 2.835487869982991

Epoch: 6| Step: 10
Training loss: 2.722748633066587
Validation loss: 2.834972004239032

Epoch: 6| Step: 11
Training loss: 3.691646507558325
Validation loss: 2.829901319212641

Epoch: 6| Step: 12
Training loss: 2.915800583633604
Validation loss: 2.8312128252327353

Epoch: 6| Step: 13
Training loss: 3.104886750199978
Validation loss: 2.822535779101272

Epoch: 144| Step: 0
Training loss: 2.8261681631152196
Validation loss: 2.81841385717027

Epoch: 6| Step: 1
Training loss: 3.6215580351457453
Validation loss: 2.8211100292661606

Epoch: 6| Step: 2
Training loss: 2.818386276021564
Validation loss: 2.817728669213715

Epoch: 6| Step: 3
Training loss: 2.163516640246733
Validation loss: 2.821811906811976

Epoch: 6| Step: 4
Training loss: 3.1836632469408372
Validation loss: 2.8266580879487946

Epoch: 6| Step: 5
Training loss: 3.3763135543767646
Validation loss: 2.8206164131789953

Epoch: 6| Step: 6
Training loss: 3.3942772668216867
Validation loss: 2.8210865929003557

Epoch: 6| Step: 7
Training loss: 3.2173322499612356
Validation loss: 2.822215710031889

Epoch: 6| Step: 8
Training loss: 2.929036548775884
Validation loss: 2.81981831154757

Epoch: 6| Step: 9
Training loss: 2.999797973188169
Validation loss: 2.820129457674764

Epoch: 6| Step: 10
Training loss: 3.212798903990935
Validation loss: 2.819436338613643

Epoch: 6| Step: 11
Training loss: 3.254045462864594
Validation loss: 2.817651446739113

Epoch: 6| Step: 12
Training loss: 3.3604923253175367
Validation loss: 2.8145467131429416

Epoch: 6| Step: 13
Training loss: 3.272660119880142
Validation loss: 2.818943204289042

Epoch: 145| Step: 0
Training loss: 3.3184648466721223
Validation loss: 2.8169682406713177

Epoch: 6| Step: 1
Training loss: 2.5308553128946603
Validation loss: 2.819830536874555

Epoch: 6| Step: 2
Training loss: 2.228735362126264
Validation loss: 2.8182971907604317

Epoch: 6| Step: 3
Training loss: 3.3528144116644665
Validation loss: 2.817991343530356

Epoch: 6| Step: 4
Training loss: 3.1856076476230917
Validation loss: 2.813941215316617

Epoch: 6| Step: 5
Training loss: 3.204019561155425
Validation loss: 2.8120676198229417

Epoch: 6| Step: 6
Training loss: 2.847692251304921
Validation loss: 2.815384493818261

Epoch: 6| Step: 7
Training loss: 3.750843334736966
Validation loss: 2.8177200950076986

Epoch: 6| Step: 8
Training loss: 2.1972654079861003
Validation loss: 2.8147925363896875

Epoch: 6| Step: 9
Training loss: 3.6576259013035655
Validation loss: 2.8161136687483315

Epoch: 6| Step: 10
Training loss: 3.617754831993741
Validation loss: 2.8158162226465993

Epoch: 6| Step: 11
Training loss: 3.1079141069913025
Validation loss: 2.8208608713737244

Epoch: 6| Step: 12
Training loss: 3.2756148132503546
Validation loss: 2.82169569888977

Epoch: 6| Step: 13
Training loss: 2.739580877228036
Validation loss: 2.839482239188263

Epoch: 146| Step: 0
Training loss: 2.5673380514474826
Validation loss: 2.8461620905969967

Epoch: 6| Step: 1
Training loss: 3.2664526661693274
Validation loss: 2.854226842799331

Epoch: 6| Step: 2
Training loss: 2.9028894827814518
Validation loss: 2.868854329800537

Epoch: 6| Step: 3
Training loss: 3.370750577749333
Validation loss: 2.8862145751370294

Epoch: 6| Step: 4
Training loss: 3.3278064844007424
Validation loss: 2.897338989818845

Epoch: 6| Step: 5
Training loss: 2.8342581156022
Validation loss: 2.8347862368167767

Epoch: 6| Step: 6
Training loss: 3.352858215128459
Validation loss: 2.8112227936408547

Epoch: 6| Step: 7
Training loss: 3.0448487415547842
Validation loss: 2.814172245333615

Epoch: 6| Step: 8
Training loss: 3.5023297321720643
Validation loss: 2.815104914633031

Epoch: 6| Step: 9
Training loss: 2.870888465237545
Validation loss: 2.824492997753795

Epoch: 6| Step: 10
Training loss: 3.6423183972416204
Validation loss: 2.8334558718010707

Epoch: 6| Step: 11
Training loss: 2.7292608773857827
Validation loss: 2.8454338523627785

Epoch: 6| Step: 12
Training loss: 3.2099383579408163
Validation loss: 2.8762244042284735

Epoch: 6| Step: 13
Training loss: 3.1640228645762085
Validation loss: 2.8330489896034257

Epoch: 147| Step: 0
Training loss: 2.727156959590862
Validation loss: 2.82139159939025

Epoch: 6| Step: 1
Training loss: 4.053336269310674
Validation loss: 2.8203328322529098

Epoch: 6| Step: 2
Training loss: 2.5333959642833026
Validation loss: 2.8174312079893076

Epoch: 6| Step: 3
Training loss: 2.6030610038886564
Validation loss: 2.8133428397696245

Epoch: 6| Step: 4
Training loss: 3.23644643600695
Validation loss: 2.8156518865015028

Epoch: 6| Step: 5
Training loss: 2.8754365009161273
Validation loss: 2.813499291388011

Epoch: 6| Step: 6
Training loss: 3.127247726792133
Validation loss: 2.8100529460979056

Epoch: 6| Step: 7
Training loss: 3.1049664552998952
Validation loss: 2.816898285842966

Epoch: 6| Step: 8
Training loss: 3.0529941245758767
Validation loss: 2.8261000511596435

Epoch: 6| Step: 9
Training loss: 3.408031872488355
Validation loss: 2.841513661190494

Epoch: 6| Step: 10
Training loss: 3.482033665660271
Validation loss: 2.8449956741010327

Epoch: 6| Step: 11
Training loss: 2.851411998382816
Validation loss: 2.845922720749998

Epoch: 6| Step: 12
Training loss: 3.6152388594819564
Validation loss: 2.847544921254464

Epoch: 6| Step: 13
Training loss: 2.180821387035091
Validation loss: 2.8312139426096743

Epoch: 148| Step: 0
Training loss: 3.221862769265552
Validation loss: 2.8223621168963233

Epoch: 6| Step: 1
Training loss: 2.8283628922197113
Validation loss: 2.8269145938221443

Epoch: 6| Step: 2
Training loss: 2.6094480949717247
Validation loss: 2.808490094113292

Epoch: 6| Step: 3
Training loss: 2.2956426519374236
Validation loss: 2.8105623687390278

Epoch: 6| Step: 4
Training loss: 3.2055818393216646
Validation loss: 2.809683485347051

Epoch: 6| Step: 5
Training loss: 3.273067335080087
Validation loss: 2.812243040827467

Epoch: 6| Step: 6
Training loss: 3.639920669990719
Validation loss: 2.811122399210915

Epoch: 6| Step: 7
Training loss: 2.150431647329537
Validation loss: 2.8105840229797985

Epoch: 6| Step: 8
Training loss: 3.7285816152816618
Validation loss: 2.815233098076028

Epoch: 6| Step: 9
Training loss: 3.311907589318879
Validation loss: 2.8112460040076184

Epoch: 6| Step: 10
Training loss: 3.0848210500196815
Validation loss: 2.813866565637407

Epoch: 6| Step: 11
Training loss: 3.0856508532316673
Validation loss: 2.813983218955038

Epoch: 6| Step: 12
Training loss: 3.3120181614935307
Validation loss: 2.817692709051847

Epoch: 6| Step: 13
Training loss: 3.7147619838119526
Validation loss: 2.8162056669136284

Epoch: 149| Step: 0
Training loss: 2.2376305398209193
Validation loss: 2.815984359181026

Epoch: 6| Step: 1
Training loss: 2.6909021533881323
Validation loss: 2.8172295340061866

Epoch: 6| Step: 2
Training loss: 3.739338150416678
Validation loss: 2.816870773584088

Epoch: 6| Step: 3
Training loss: 2.83949296508498
Validation loss: 2.8167753568404716

Epoch: 6| Step: 4
Training loss: 3.719205171313253
Validation loss: 2.8203097748415864

Epoch: 6| Step: 5
Training loss: 2.3863255353255712
Validation loss: 2.8262256496128053

Epoch: 6| Step: 6
Training loss: 2.9346705668711044
Validation loss: 2.8239893807008154

Epoch: 6| Step: 7
Training loss: 3.0850173544125106
Validation loss: 2.8204027423425813

Epoch: 6| Step: 8
Training loss: 3.7214352185352353
Validation loss: 2.8239180596668314

Epoch: 6| Step: 9
Training loss: 3.4793924193702543
Validation loss: 2.814031390493902

Epoch: 6| Step: 10
Training loss: 2.9741930404125054
Validation loss: 2.809945747576664

Epoch: 6| Step: 11
Training loss: 2.8372545783160334
Validation loss: 2.8024147027750885

Epoch: 6| Step: 12
Training loss: 3.264003807551837
Validation loss: 2.804149979161688

Epoch: 6| Step: 13
Training loss: 3.447469369200357
Validation loss: 2.799795340531118

Epoch: 150| Step: 0
Training loss: 3.293998005341214
Validation loss: 2.8032940543319844

Epoch: 6| Step: 1
Training loss: 2.4138926227142212
Validation loss: 2.7989084964881257

Epoch: 6| Step: 2
Training loss: 3.136632554709614
Validation loss: 2.7961195425418275

Epoch: 6| Step: 3
Training loss: 3.064968437791522
Validation loss: 2.7976190967349734

Epoch: 6| Step: 4
Training loss: 2.663672902545767
Validation loss: 2.801794465791154

Epoch: 6| Step: 5
Training loss: 3.4333586281397093
Validation loss: 2.8014145377144573

Epoch: 6| Step: 6
Training loss: 4.229061156712198
Validation loss: 2.7952855994555312

Epoch: 6| Step: 7
Training loss: 2.8054638481469114
Validation loss: 2.7969602744963624

Epoch: 6| Step: 8
Training loss: 3.012135755116455
Validation loss: 2.797456564574811

Epoch: 6| Step: 9
Training loss: 3.020301631744139
Validation loss: 2.7985203845316007

Epoch: 6| Step: 10
Training loss: 3.4409768294530143
Validation loss: 2.8011742186872253

Epoch: 6| Step: 11
Training loss: 2.8442848457159378
Validation loss: 2.7953642844444078

Epoch: 6| Step: 12
Training loss: 2.732843635080732
Validation loss: 2.8008275241535703

Epoch: 6| Step: 13
Training loss: 3.035715962257243
Validation loss: 2.8018478445255957

Epoch: 151| Step: 0
Training loss: 3.190629955739984
Validation loss: 2.807748948667231

Epoch: 6| Step: 1
Training loss: 3.1999796985935913
Validation loss: 2.8015718284084548

Epoch: 6| Step: 2
Training loss: 3.339847890393998
Validation loss: 2.8040370364553677

Epoch: 6| Step: 3
Training loss: 3.2391883306725067
Validation loss: 2.8038629242991036

Epoch: 6| Step: 4
Training loss: 2.7673760167359567
Validation loss: 2.804752122994492

Epoch: 6| Step: 5
Training loss: 2.834695339080599
Validation loss: 2.798256200368789

Epoch: 6| Step: 6
Training loss: 3.5897130433903373
Validation loss: 2.7926797022092775

Epoch: 6| Step: 7
Training loss: 2.927960917008757
Validation loss: 2.793613061721319

Epoch: 6| Step: 8
Training loss: 1.982127320905011
Validation loss: 2.7925341131918815

Epoch: 6| Step: 9
Training loss: 3.247121122722761
Validation loss: 2.792950103901755

Epoch: 6| Step: 10
Training loss: 3.7740432537371773
Validation loss: 2.7890977759316486

Epoch: 6| Step: 11
Training loss: 3.2272547979015562
Validation loss: 2.788880776567564

Epoch: 6| Step: 12
Training loss: 3.100473515432354
Validation loss: 2.7910288876699956

Epoch: 6| Step: 13
Training loss: 2.272795176792096
Validation loss: 2.793878867707411

Epoch: 152| Step: 0
Training loss: 2.9288703287424473
Validation loss: 2.7872365888055426

Epoch: 6| Step: 1
Training loss: 3.062953370459527
Validation loss: 2.793792391590289

Epoch: 6| Step: 2
Training loss: 4.186573894064093
Validation loss: 2.7940284862374067

Epoch: 6| Step: 3
Training loss: 2.2812573158460387
Validation loss: 2.810074361591535

Epoch: 6| Step: 4
Training loss: 3.1511040463328768
Validation loss: 2.806193606136167

Epoch: 6| Step: 5
Training loss: 2.9814010102035216
Validation loss: 2.83711650949865

Epoch: 6| Step: 6
Training loss: 3.212517639586709
Validation loss: 2.8322954771282975

Epoch: 6| Step: 7
Training loss: 3.329214284951774
Validation loss: 2.829252313989665

Epoch: 6| Step: 8
Training loss: 3.0445120231602765
Validation loss: 2.8003603429794865

Epoch: 6| Step: 9
Training loss: 3.4943414996060618
Validation loss: 2.794254241268083

Epoch: 6| Step: 10
Training loss: 2.3957240757009792
Validation loss: 2.7905093882779948

Epoch: 6| Step: 11
Training loss: 3.482565097570105
Validation loss: 2.7899995735189598

Epoch: 6| Step: 12
Training loss: 2.81988116318314
Validation loss: 2.793342613154678

Epoch: 6| Step: 13
Training loss: 2.2152484611503303
Validation loss: 2.79612411581877

Epoch: 153| Step: 0
Training loss: 3.14683442681531
Validation loss: 2.797498063357288

Epoch: 6| Step: 1
Training loss: 2.8305003270518148
Validation loss: 2.7948899471977486

Epoch: 6| Step: 2
Training loss: 3.588598655982681
Validation loss: 2.798217498901692

Epoch: 6| Step: 3
Training loss: 3.5789713962090857
Validation loss: 2.800670075406511

Epoch: 6| Step: 4
Training loss: 2.811919258347634
Validation loss: 2.7975883735919824

Epoch: 6| Step: 5
Training loss: 3.212951474062846
Validation loss: 2.7974646693672938

Epoch: 6| Step: 6
Training loss: 2.564576586898578
Validation loss: 2.8012330097404523

Epoch: 6| Step: 7
Training loss: 3.3323858503979724
Validation loss: 2.7963572531809486

Epoch: 6| Step: 8
Training loss: 2.921368396924098
Validation loss: 2.798126098539071

Epoch: 6| Step: 9
Training loss: 2.855128736382715
Validation loss: 2.797705133852033

Epoch: 6| Step: 10
Training loss: 3.0736025976802526
Validation loss: 2.7938965101912854

Epoch: 6| Step: 11
Training loss: 3.08643717523061
Validation loss: 2.7910195048817252

Epoch: 6| Step: 12
Training loss: 3.4854779742941355
Validation loss: 2.7922693396987714

Epoch: 6| Step: 13
Training loss: 2.7745985582740462
Validation loss: 2.7926986016393727

Epoch: 154| Step: 0
Training loss: 3.297434971698172
Validation loss: 2.791220432028246

Epoch: 6| Step: 1
Training loss: 3.5736394360609083
Validation loss: 2.7899884496837815

Epoch: 6| Step: 2
Training loss: 3.0268234494923836
Validation loss: 2.793360172755809

Epoch: 6| Step: 3
Training loss: 3.6065959057121453
Validation loss: 2.7906625956509314

Epoch: 6| Step: 4
Training loss: 3.111073552389346
Validation loss: 2.791072523880337

Epoch: 6| Step: 5
Training loss: 2.6097550714967728
Validation loss: 2.798391190026121

Epoch: 6| Step: 6
Training loss: 2.440936868941255
Validation loss: 2.786593248062332

Epoch: 6| Step: 7
Training loss: 3.301146718395302
Validation loss: 2.7932683234310525

Epoch: 6| Step: 8
Training loss: 3.0907101579896947
Validation loss: 2.791944487817329

Epoch: 6| Step: 9
Training loss: 3.157680074188602
Validation loss: 2.8010655683582093

Epoch: 6| Step: 10
Training loss: 3.2708485272939463
Validation loss: 2.7936734030662813

Epoch: 6| Step: 11
Training loss: 3.205520701609151
Validation loss: 2.8018516142493275

Epoch: 6| Step: 12
Training loss: 2.681638135582421
Validation loss: 2.7951879188046913

Epoch: 6| Step: 13
Training loss: 2.5883781233050365
Validation loss: 2.7972431005938567

Epoch: 155| Step: 0
Training loss: 3.108242116072045
Validation loss: 2.8009031428319155

Epoch: 6| Step: 1
Training loss: 2.672139829483208
Validation loss: 2.809594730927477

Epoch: 6| Step: 2
Training loss: 2.17000405939663
Validation loss: 2.8105215061667037

Epoch: 6| Step: 3
Training loss: 3.002288104734548
Validation loss: 2.8182339663148412

Epoch: 6| Step: 4
Training loss: 3.042713316160565
Validation loss: 2.836678507826561

Epoch: 6| Step: 5
Training loss: 3.3829714977790095
Validation loss: 2.8283966900259028

Epoch: 6| Step: 6
Training loss: 3.2993360256025555
Validation loss: 2.816295724981156

Epoch: 6| Step: 7
Training loss: 3.469011451559335
Validation loss: 2.7944885244952364

Epoch: 6| Step: 8
Training loss: 2.9430905974348587
Validation loss: 2.7922767562689623

Epoch: 6| Step: 9
Training loss: 3.2665004013203753
Validation loss: 2.7830413565248207

Epoch: 6| Step: 10
Training loss: 3.1741562330402147
Validation loss: 2.7849496143664405

Epoch: 6| Step: 11
Training loss: 3.6939911687773272
Validation loss: 2.786160606201163

Epoch: 6| Step: 12
Training loss: 2.9174814085380287
Validation loss: 2.785027315552196

Epoch: 6| Step: 13
Training loss: 2.944324924834297
Validation loss: 2.786783491101706

Epoch: 156| Step: 0
Training loss: 3.3529837913678886
Validation loss: 2.784861301542871

Epoch: 6| Step: 1
Training loss: 3.3056942103038103
Validation loss: 2.79143009704778

Epoch: 6| Step: 2
Training loss: 2.456417716709111
Validation loss: 2.7890502786028204

Epoch: 6| Step: 3
Training loss: 3.1970237123089076
Validation loss: 2.7907030894245306

Epoch: 6| Step: 4
Training loss: 2.7471840919991606
Validation loss: 2.7907176855955416

Epoch: 6| Step: 5
Training loss: 3.434180026294913
Validation loss: 2.7940627021153217

Epoch: 6| Step: 6
Training loss: 2.811370283634673
Validation loss: 2.8044010020252617

Epoch: 6| Step: 7
Training loss: 3.750547750523259
Validation loss: 2.8067627556812025

Epoch: 6| Step: 8
Training loss: 3.5850853000851624
Validation loss: 2.7956637103021937

Epoch: 6| Step: 9
Training loss: 3.2056520495628047
Validation loss: 2.7963387286901313

Epoch: 6| Step: 10
Training loss: 3.1193352282065128
Validation loss: 2.7924403528283572

Epoch: 6| Step: 11
Training loss: 2.9190227438291227
Validation loss: 2.7878107575791327

Epoch: 6| Step: 12
Training loss: 2.66320858691485
Validation loss: 2.7886950147726766

Epoch: 6| Step: 13
Training loss: 2.3426197632878196
Validation loss: 2.783384874645388

Epoch: 157| Step: 0
Training loss: 2.9683890675433764
Validation loss: 2.7813484577275687

Epoch: 6| Step: 1
Training loss: 2.560974969874888
Validation loss: 2.784198919942953

Epoch: 6| Step: 2
Training loss: 3.0392840385592486
Validation loss: 2.782338199469072

Epoch: 6| Step: 3
Training loss: 3.247511864949577
Validation loss: 2.7848109398403618

Epoch: 6| Step: 4
Training loss: 3.0188603414584234
Validation loss: 2.783298364465913

Epoch: 6| Step: 5
Training loss: 2.730553097711412
Validation loss: 2.7829447794369586

Epoch: 6| Step: 6
Training loss: 3.033602087111097
Validation loss: 2.78305352324718

Epoch: 6| Step: 7
Training loss: 2.8609339732258268
Validation loss: 2.7843814387621704

Epoch: 6| Step: 8
Training loss: 3.4388372421152456
Validation loss: 2.7854355439315945

Epoch: 6| Step: 9
Training loss: 3.7508419363288614
Validation loss: 2.8047246232130867

Epoch: 6| Step: 10
Training loss: 2.8148557333965103
Validation loss: 2.7849191482085867

Epoch: 6| Step: 11
Training loss: 2.9310685221569948
Validation loss: 2.791684114061571

Epoch: 6| Step: 12
Training loss: 3.8151421068754825
Validation loss: 2.782875930617718

Epoch: 6| Step: 13
Training loss: 2.6066466361281937
Validation loss: 2.7816537055020176

Epoch: 158| Step: 0
Training loss: 3.2393035931438545
Validation loss: 2.7807084879461543

Epoch: 6| Step: 1
Training loss: 3.2151079034569867
Validation loss: 2.7772876840051954

Epoch: 6| Step: 2
Training loss: 2.9625416941867537
Validation loss: 2.778863067643388

Epoch: 6| Step: 3
Training loss: 2.7458714792692067
Validation loss: 2.7801130440522064

Epoch: 6| Step: 4
Training loss: 3.1311440151041845
Validation loss: 2.77971809860694

Epoch: 6| Step: 5
Training loss: 2.6827202809413295
Validation loss: 2.779284558082881

Epoch: 6| Step: 6
Training loss: 3.070013677212446
Validation loss: 2.7905360377968136

Epoch: 6| Step: 7
Training loss: 3.4754594403082923
Validation loss: 2.7921034652270373

Epoch: 6| Step: 8
Training loss: 2.2153586675477417
Validation loss: 2.7798390825710104

Epoch: 6| Step: 9
Training loss: 3.4164505556811533
Validation loss: 2.77786020655685

Epoch: 6| Step: 10
Training loss: 2.987172198966249
Validation loss: 2.7805824543306534

Epoch: 6| Step: 11
Training loss: 2.861161804573143
Validation loss: 2.779219076328422

Epoch: 6| Step: 12
Training loss: 3.570446854949469
Validation loss: 2.7783086380903503

Epoch: 6| Step: 13
Training loss: 3.7454011056005063
Validation loss: 2.7771707364394143

Epoch: 159| Step: 0
Training loss: 2.6711262328590304
Validation loss: 2.779266303523576

Epoch: 6| Step: 1
Training loss: 3.176340502005441
Validation loss: 2.7760963729297568

Epoch: 6| Step: 2
Training loss: 3.0125963884184217
Validation loss: 2.774448539677126

Epoch: 6| Step: 3
Training loss: 3.1533361902956556
Validation loss: 2.7733341718320235

Epoch: 6| Step: 4
Training loss: 3.478577721976968
Validation loss: 2.7712587271660767

Epoch: 6| Step: 5
Training loss: 2.418328032046326
Validation loss: 2.7750326590559484

Epoch: 6| Step: 6
Training loss: 3.437833041617014
Validation loss: 2.7733752698790193

Epoch: 6| Step: 7
Training loss: 3.477590893147867
Validation loss: 2.7762593319054982

Epoch: 6| Step: 8
Training loss: 2.79445846415905
Validation loss: 2.779337785258153

Epoch: 6| Step: 9
Training loss: 2.9313385647080796
Validation loss: 2.784699166324133

Epoch: 6| Step: 10
Training loss: 3.466903607511939
Validation loss: 2.775728507524012

Epoch: 6| Step: 11
Training loss: 2.875599010924656
Validation loss: 2.7784229505210827

Epoch: 6| Step: 12
Training loss: 2.9703666702138944
Validation loss: 2.7794971581407797

Epoch: 6| Step: 13
Training loss: 3.3529377141094145
Validation loss: 2.774911707587931

Epoch: 160| Step: 0
Training loss: 2.711104242215375
Validation loss: 2.7730346618217636

Epoch: 6| Step: 1
Training loss: 3.048732719419334
Validation loss: 2.7694399461512784

Epoch: 6| Step: 2
Training loss: 3.2092155795817874
Validation loss: 2.7749546927925763

Epoch: 6| Step: 3
Training loss: 3.2370766675918685
Validation loss: 2.771402939019854

Epoch: 6| Step: 4
Training loss: 2.6652419536180356
Validation loss: 2.769295524688549

Epoch: 6| Step: 5
Training loss: 2.9214163843580905
Validation loss: 2.7726415568609464

Epoch: 6| Step: 6
Training loss: 3.44569280692254
Validation loss: 2.774393782748891

Epoch: 6| Step: 7
Training loss: 3.2047133066671796
Validation loss: 2.7693542852511133

Epoch: 6| Step: 8
Training loss: 3.259826769292488
Validation loss: 2.773767345687201

Epoch: 6| Step: 9
Training loss: 2.6357769223581946
Validation loss: 2.7676778564296676

Epoch: 6| Step: 10
Training loss: 3.4954313705619504
Validation loss: 2.768210460737899

Epoch: 6| Step: 11
Training loss: 3.1055261762575594
Validation loss: 2.774008613975959

Epoch: 6| Step: 12
Training loss: 3.2920354966466627
Validation loss: 2.7686379971340016

Epoch: 6| Step: 13
Training loss: 2.630695793883214
Validation loss: 2.7661899077538923

Epoch: 161| Step: 0
Training loss: 3.4581592163621457
Validation loss: 2.76834206758029

Epoch: 6| Step: 1
Training loss: 2.8984457257506255
Validation loss: 2.7719784610235663

Epoch: 6| Step: 2
Training loss: 2.882507804337298
Validation loss: 2.7677475811693513

Epoch: 6| Step: 3
Training loss: 2.759281620851954
Validation loss: 2.7704430921455288

Epoch: 6| Step: 4
Training loss: 3.029989708105555
Validation loss: 2.7660729673655675

Epoch: 6| Step: 5
Training loss: 3.481973547539757
Validation loss: 2.773887946872835

Epoch: 6| Step: 6
Training loss: 1.8052055639152906
Validation loss: 2.7713704636775476

Epoch: 6| Step: 7
Training loss: 3.1046275025067485
Validation loss: 2.7770458688387407

Epoch: 6| Step: 8
Training loss: 3.690051214591553
Validation loss: 2.7809369218759357

Epoch: 6| Step: 9
Training loss: 3.471704822561964
Validation loss: 2.7711334923311366

Epoch: 6| Step: 10
Training loss: 2.7626983329726773
Validation loss: 2.765466418434816

Epoch: 6| Step: 11
Training loss: 2.8405797705076314
Validation loss: 2.771392892212506

Epoch: 6| Step: 12
Training loss: 3.2466115159893083
Validation loss: 2.7686690507906793

Epoch: 6| Step: 13
Training loss: 3.342361304430667
Validation loss: 2.7639645944874895

Epoch: 162| Step: 0
Training loss: 3.331076302929355
Validation loss: 2.7671167424424254

Epoch: 6| Step: 1
Training loss: 2.2858908491400305
Validation loss: 2.7612243907017957

Epoch: 6| Step: 2
Training loss: 3.0065794956514744
Validation loss: 2.762270319952001

Epoch: 6| Step: 3
Training loss: 3.3606882766405195
Validation loss: 2.7628725265358534

Epoch: 6| Step: 4
Training loss: 3.0712243199157867
Validation loss: 2.7616935211661664

Epoch: 6| Step: 5
Training loss: 3.0502252401762244
Validation loss: 2.764799450546897

Epoch: 6| Step: 6
Training loss: 2.889918225461322
Validation loss: 2.7631660720084708

Epoch: 6| Step: 7
Training loss: 3.0235125707330637
Validation loss: 2.7598213939293292

Epoch: 6| Step: 8
Training loss: 3.4591892209777018
Validation loss: 2.7644413623156368

Epoch: 6| Step: 9
Training loss: 3.0339378159851345
Validation loss: 2.7641487888456955

Epoch: 6| Step: 10
Training loss: 3.4546359109671383
Validation loss: 2.7629282457434416

Epoch: 6| Step: 11
Training loss: 2.8885223164250178
Validation loss: 2.764087801109543

Epoch: 6| Step: 12
Training loss: 3.0531510882009774
Validation loss: 2.772014053319047

Epoch: 6| Step: 13
Training loss: 2.8507724451340457
Validation loss: 2.768467550922463

Epoch: 163| Step: 0
Training loss: 3.5802480737417137
Validation loss: 2.771547063821114

Epoch: 6| Step: 1
Training loss: 2.763177597004338
Validation loss: 2.7788537388002643

Epoch: 6| Step: 2
Training loss: 3.351509573992076
Validation loss: 2.7782226877531233

Epoch: 6| Step: 3
Training loss: 2.464021621200523
Validation loss: 2.7789711570561177

Epoch: 6| Step: 4
Training loss: 3.012268412065586
Validation loss: 2.7826159474593166

Epoch: 6| Step: 5
Training loss: 2.617854975519378
Validation loss: 2.778987979975998

Epoch: 6| Step: 6
Training loss: 3.831369200901067
Validation loss: 2.7774259172817275

Epoch: 6| Step: 7
Training loss: 2.9578783643576285
Validation loss: 2.7663598567166794

Epoch: 6| Step: 8
Training loss: 3.1008752018118875
Validation loss: 2.761333545637965

Epoch: 6| Step: 9
Training loss: 2.6142811594260067
Validation loss: 2.7608964227233943

Epoch: 6| Step: 10
Training loss: 2.979037960091072
Validation loss: 2.7558223600685183

Epoch: 6| Step: 11
Training loss: 3.262101165830588
Validation loss: 2.7569780713865852

Epoch: 6| Step: 12
Training loss: 3.080837545587207
Validation loss: 2.75891398328631

Epoch: 6| Step: 13
Training loss: 3.2050364675842493
Validation loss: 2.7616139009529492

Epoch: 164| Step: 0
Training loss: 3.2100873503877025
Validation loss: 2.757586097853612

Epoch: 6| Step: 1
Training loss: 3.360928056704539
Validation loss: 2.75802623096379

Epoch: 6| Step: 2
Training loss: 2.9899415832732785
Validation loss: 2.7560858548081772

Epoch: 6| Step: 3
Training loss: 2.8693412154927294
Validation loss: 2.7576431063895144

Epoch: 6| Step: 4
Training loss: 3.1401002360095926
Validation loss: 2.7540689423090625

Epoch: 6| Step: 5
Training loss: 2.6862603810688013
Validation loss: 2.7544965125553693

Epoch: 6| Step: 6
Training loss: 2.9128142027762465
Validation loss: 2.7537232967088903

Epoch: 6| Step: 7
Training loss: 3.180764355716512
Validation loss: 2.7536950555135773

Epoch: 6| Step: 8
Training loss: 2.7076952451576624
Validation loss: 2.751241467126234

Epoch: 6| Step: 9
Training loss: 3.05921791304607
Validation loss: 2.7525483905948525

Epoch: 6| Step: 10
Training loss: 3.50461968310828
Validation loss: 2.7535173658072365

Epoch: 6| Step: 11
Training loss: 3.232370833717109
Validation loss: 2.7583550114181463

Epoch: 6| Step: 12
Training loss: 3.0599557078029447
Validation loss: 2.757386642372352

Epoch: 6| Step: 13
Training loss: 2.911178020342536
Validation loss: 2.7697943920789165

Epoch: 165| Step: 0
Training loss: 3.6048739553312656
Validation loss: 2.7630056123891373

Epoch: 6| Step: 1
Training loss: 2.63339009726786
Validation loss: 2.7683504168913755

Epoch: 6| Step: 2
Training loss: 3.744859096183534
Validation loss: 2.769865277857845

Epoch: 6| Step: 3
Training loss: 3.598826927218812
Validation loss: 2.7749218950159915

Epoch: 6| Step: 4
Training loss: 3.244473379984452
Validation loss: 2.754329275436464

Epoch: 6| Step: 5
Training loss: 3.044686808147037
Validation loss: 2.750994762486388

Epoch: 6| Step: 6
Training loss: 2.3137611867839287
Validation loss: 2.7516404989194854

Epoch: 6| Step: 7
Training loss: 3.3818594843336327
Validation loss: 2.7529115822554813

Epoch: 6| Step: 8
Training loss: 3.372572979883263
Validation loss: 2.754017158322412

Epoch: 6| Step: 9
Training loss: 2.4081314459882015
Validation loss: 2.7520243222126957

Epoch: 6| Step: 10
Training loss: 2.8710291433526027
Validation loss: 2.7556312122217776

Epoch: 6| Step: 11
Training loss: 2.6208507806129484
Validation loss: 2.7546396187082345

Epoch: 6| Step: 12
Training loss: 2.9435933000523833
Validation loss: 2.7512540209387857

Epoch: 6| Step: 13
Training loss: 2.6808270847799918
Validation loss: 2.7500469990552086

Epoch: 166| Step: 0
Training loss: 3.223919319241339
Validation loss: 2.749827798129786

Epoch: 6| Step: 1
Training loss: 3.418821322239353
Validation loss: 2.749528807230627

Epoch: 6| Step: 2
Training loss: 2.6781113329330566
Validation loss: 2.749276013687678

Epoch: 6| Step: 3
Training loss: 3.713890683473204
Validation loss: 2.747582324662481

Epoch: 6| Step: 4
Training loss: 2.6151946266350166
Validation loss: 2.7495451110013414

Epoch: 6| Step: 5
Training loss: 3.020782014257423
Validation loss: 2.7537816932011085

Epoch: 6| Step: 6
Training loss: 3.2825956945713792
Validation loss: 2.755560525000294

Epoch: 6| Step: 7
Training loss: 3.1172298724896588
Validation loss: 2.754741877108602

Epoch: 6| Step: 8
Training loss: 3.2017320534977656
Validation loss: 2.7522046135473146

Epoch: 6| Step: 9
Training loss: 2.995879522470685
Validation loss: 2.755952912000086

Epoch: 6| Step: 10
Training loss: 3.218909991093525
Validation loss: 2.755199662573363

Epoch: 6| Step: 11
Training loss: 2.468994128554367
Validation loss: 2.759475512894347

Epoch: 6| Step: 12
Training loss: 2.74283950748905
Validation loss: 2.7729253212512415

Epoch: 6| Step: 13
Training loss: 2.896518781667274
Validation loss: 2.7638299389884966

Epoch: 167| Step: 0
Training loss: 3.559234862880373
Validation loss: 2.758277668614484

Epoch: 6| Step: 1
Training loss: 2.8444645581262784
Validation loss: 2.762037559552995

Epoch: 6| Step: 2
Training loss: 3.0260540977831116
Validation loss: 2.7601460419190897

Epoch: 6| Step: 3
Training loss: 3.0912943640709654
Validation loss: 2.753278320143488

Epoch: 6| Step: 4
Training loss: 2.8890673590413436
Validation loss: 2.752199276126175

Epoch: 6| Step: 5
Training loss: 2.8402972377451405
Validation loss: 2.7475285522771253

Epoch: 6| Step: 6
Training loss: 3.293205931460533
Validation loss: 2.7493741431710466

Epoch: 6| Step: 7
Training loss: 3.3864365826442824
Validation loss: 2.7519799140663754

Epoch: 6| Step: 8
Training loss: 3.6648828039647974
Validation loss: 2.7451073265256807

Epoch: 6| Step: 9
Training loss: 2.3287638357409772
Validation loss: 2.749796507457599

Epoch: 6| Step: 10
Training loss: 3.012083513903053
Validation loss: 2.7475966432604455

Epoch: 6| Step: 11
Training loss: 3.1527503222942603
Validation loss: 2.7538317212164194

Epoch: 6| Step: 12
Training loss: 2.760217930579394
Validation loss: 2.7485788930012416

Epoch: 6| Step: 13
Training loss: 2.4926715249259694
Validation loss: 2.7540387330849705

Epoch: 168| Step: 0
Training loss: 3.5711082723585568
Validation loss: 2.746432257247725

Epoch: 6| Step: 1
Training loss: 3.07301176969271
Validation loss: 2.7468331001771973

Epoch: 6| Step: 2
Training loss: 3.6421030343243004
Validation loss: 2.7459178945213294

Epoch: 6| Step: 3
Training loss: 2.5659006395852746
Validation loss: 2.7481052269956416

Epoch: 6| Step: 4
Training loss: 2.255624099946893
Validation loss: 2.7493186602588175

Epoch: 6| Step: 5
Training loss: 3.2411704800785497
Validation loss: 2.752871835415599

Epoch: 6| Step: 6
Training loss: 3.1451689837592776
Validation loss: 2.745356284039208

Epoch: 6| Step: 7
Training loss: 2.5730827267657985
Validation loss: 2.749493015238432

Epoch: 6| Step: 8
Training loss: 2.8598924179116962
Validation loss: 2.747382448987382

Epoch: 6| Step: 9
Training loss: 3.1639301790425853
Validation loss: 2.7444053823761108

Epoch: 6| Step: 10
Training loss: 2.6422404928549783
Validation loss: 2.7408376126262244

Epoch: 6| Step: 11
Training loss: 2.4434645620219118
Validation loss: 2.7450291182844477

Epoch: 6| Step: 12
Training loss: 3.6351712352608603
Validation loss: 2.745572622907039

Epoch: 6| Step: 13
Training loss: 3.8938156587750123
Validation loss: 2.750315332092789

Epoch: 169| Step: 0
Training loss: 2.878426541614142
Validation loss: 2.750593594934612

Epoch: 6| Step: 1
Training loss: 2.3166231050672437
Validation loss: 2.7510989688356156

Epoch: 6| Step: 2
Training loss: 3.0561933391288014
Validation loss: 2.7601751607672917

Epoch: 6| Step: 3
Training loss: 3.3264892570061817
Validation loss: 2.7564871316876762

Epoch: 6| Step: 4
Training loss: 2.3005679797562992
Validation loss: 2.7540998167562036

Epoch: 6| Step: 5
Training loss: 3.129924251383246
Validation loss: 2.7635548967074817

Epoch: 6| Step: 6
Training loss: 3.0944723191557224
Validation loss: 2.767336196949554

Epoch: 6| Step: 7
Training loss: 3.6200793840334637
Validation loss: 2.7635321587281494

Epoch: 6| Step: 8
Training loss: 2.316819770016805
Validation loss: 2.746578421349928

Epoch: 6| Step: 9
Training loss: 3.623784617863628
Validation loss: 2.73962102276343

Epoch: 6| Step: 10
Training loss: 2.809129433088565
Validation loss: 2.7387386136260985

Epoch: 6| Step: 11
Training loss: 3.292224370010379
Validation loss: 2.742120357327506

Epoch: 6| Step: 12
Training loss: 3.59944563941905
Validation loss: 2.742146948894446

Epoch: 6| Step: 13
Training loss: 3.1356200767936175
Validation loss: 2.74618863716825

Epoch: 170| Step: 0
Training loss: 2.4940687391754905
Validation loss: 2.7476966399693774

Epoch: 6| Step: 1
Training loss: 3.800015630187967
Validation loss: 2.742574027812985

Epoch: 6| Step: 2
Training loss: 2.9682332442421235
Validation loss: 2.747236714928549

Epoch: 6| Step: 3
Training loss: 2.3359489313056416
Validation loss: 2.7435475457329983

Epoch: 6| Step: 4
Training loss: 2.6408776156788583
Validation loss: 2.74181350585081

Epoch: 6| Step: 5
Training loss: 3.5756874277192505
Validation loss: 2.7429816441728776

Epoch: 6| Step: 6
Training loss: 3.339840037918259
Validation loss: 2.7398130789282638

Epoch: 6| Step: 7
Training loss: 2.9763419001977174
Validation loss: 2.742506697364962

Epoch: 6| Step: 8
Training loss: 2.8554512159067507
Validation loss: 2.7428016420120365

Epoch: 6| Step: 9
Training loss: 3.1200106654840742
Validation loss: 2.749173082924601

Epoch: 6| Step: 10
Training loss: 3.278981614536257
Validation loss: 2.7456949681064753

Epoch: 6| Step: 11
Training loss: 3.0250164315273964
Validation loss: 2.7527201959642857

Epoch: 6| Step: 12
Training loss: 2.9975878236709126
Validation loss: 2.7722533038092587

Epoch: 6| Step: 13
Training loss: 3.1755429562062965
Validation loss: 2.767073377917183

Epoch: 171| Step: 0
Training loss: 2.6049386876481853
Validation loss: 2.786304205947483

Epoch: 6| Step: 1
Training loss: 3.622717303069477
Validation loss: 2.80670059309818

Epoch: 6| Step: 2
Training loss: 2.6978954378174103
Validation loss: 2.7894630446691755

Epoch: 6| Step: 3
Training loss: 3.334092784833076
Validation loss: 2.7714116592971942

Epoch: 6| Step: 4
Training loss: 2.738245116252544
Validation loss: 2.7496515745036842

Epoch: 6| Step: 5
Training loss: 2.1424532691372784
Validation loss: 2.732949372142041

Epoch: 6| Step: 6
Training loss: 3.1137021114138466
Validation loss: 2.7280570727817133

Epoch: 6| Step: 7
Training loss: 3.3978283566417433
Validation loss: 2.732633623467811

Epoch: 6| Step: 8
Training loss: 3.4220592153075446
Validation loss: 2.723730569780988

Epoch: 6| Step: 9
Training loss: 2.9926666593233673
Validation loss: 2.71970999231363

Epoch: 6| Step: 10
Training loss: 2.6548725820307926
Validation loss: 2.723802639291927

Epoch: 6| Step: 11
Training loss: 3.144912298583808
Validation loss: 2.7196179933757456

Epoch: 6| Step: 12
Training loss: 3.0438715289722222
Validation loss: 2.715740873810828

Epoch: 6| Step: 13
Training loss: 3.770252091658562
Validation loss: 2.720042955549782

Epoch: 172| Step: 0
Training loss: 2.919239507955723
Validation loss: 2.714737182140354

Epoch: 6| Step: 1
Training loss: 2.744463028074797
Validation loss: 2.7133360580866435

Epoch: 6| Step: 2
Training loss: 2.689537340672659
Validation loss: 2.715416099998191

Epoch: 6| Step: 3
Training loss: 3.3650616442629904
Validation loss: 2.7136956704735766

Epoch: 6| Step: 4
Training loss: 2.9593102001922533
Validation loss: 2.7138060834052653

Epoch: 6| Step: 5
Training loss: 2.6911172697838723
Validation loss: 2.716792019095379

Epoch: 6| Step: 6
Training loss: 2.639789155574489
Validation loss: 2.7182508106292405

Epoch: 6| Step: 7
Training loss: 3.346120689153611
Validation loss: 2.7151205570221175

Epoch: 6| Step: 8
Training loss: 3.1641288091045645
Validation loss: 2.715929579970439

Epoch: 6| Step: 9
Training loss: 3.28828127320177
Validation loss: 2.7166268225799883

Epoch: 6| Step: 10
Training loss: 2.5455752373544143
Validation loss: 2.717684272767112

Epoch: 6| Step: 11
Training loss: 3.1339433488819584
Validation loss: 2.714416901897523

Epoch: 6| Step: 12
Training loss: 3.4894492659744416
Validation loss: 2.7178482098968733

Epoch: 6| Step: 13
Training loss: 3.6803178834450656
Validation loss: 2.710784809460079

Epoch: 173| Step: 0
Training loss: 2.836728997029482
Validation loss: 2.712444610279681

Epoch: 6| Step: 1
Training loss: 2.865684011136708
Validation loss: 2.7118909624356426

Epoch: 6| Step: 2
Training loss: 3.2449107303889515
Validation loss: 2.7148258383629167

Epoch: 6| Step: 3
Training loss: 2.2256147542630353
Validation loss: 2.712379822975759

Epoch: 6| Step: 4
Training loss: 3.621081108392173
Validation loss: 2.7099687325822694

Epoch: 6| Step: 5
Training loss: 3.3467852640098608
Validation loss: 2.712622948605649

Epoch: 6| Step: 6
Training loss: 2.860259706136464
Validation loss: 2.71299264364998

Epoch: 6| Step: 7
Training loss: 3.128763297978975
Validation loss: 2.7149436622448544

Epoch: 6| Step: 8
Training loss: 3.662453629652595
Validation loss: 2.7115090908801034

Epoch: 6| Step: 9
Training loss: 3.4781545358450834
Validation loss: 2.7095766783688346

Epoch: 6| Step: 10
Training loss: 2.758572308962891
Validation loss: 2.710910648634853

Epoch: 6| Step: 11
Training loss: 2.5283276678267868
Validation loss: 2.7097132200546157

Epoch: 6| Step: 12
Training loss: 3.06107484004076
Validation loss: 2.714608172499471

Epoch: 6| Step: 13
Training loss: 2.0241967621481045
Validation loss: 2.73207873423739

Epoch: 174| Step: 0
Training loss: 2.3131982934693833
Validation loss: 2.734322394877284

Epoch: 6| Step: 1
Training loss: 2.5539410635138196
Validation loss: 2.762354928151848

Epoch: 6| Step: 2
Training loss: 3.1803175843198095
Validation loss: 2.7671041480297744

Epoch: 6| Step: 3
Training loss: 3.690166220707435
Validation loss: 2.770799360144869

Epoch: 6| Step: 4
Training loss: 2.4822922139254557
Validation loss: 2.7341359286238784

Epoch: 6| Step: 5
Training loss: 2.9386615485765826
Validation loss: 2.7201132594903323

Epoch: 6| Step: 6
Training loss: 2.8276739445750483
Validation loss: 2.7218557281921405

Epoch: 6| Step: 7
Training loss: 2.845614817446314
Validation loss: 2.7099375313063345

Epoch: 6| Step: 8
Training loss: 2.952484868824016
Validation loss: 2.708513851791527

Epoch: 6| Step: 9
Training loss: 3.322936405772991
Validation loss: 2.704469796640873

Epoch: 6| Step: 10
Training loss: 3.659339056318991
Validation loss: 2.7101171356981575

Epoch: 6| Step: 11
Training loss: 3.5728799949669536
Validation loss: 2.711854997939868

Epoch: 6| Step: 12
Training loss: 2.9597323337881245
Validation loss: 2.7140490444314844

Epoch: 6| Step: 13
Training loss: 2.99807709420845
Validation loss: 2.707752311863244

Epoch: 175| Step: 0
Training loss: 3.22400140605167
Validation loss: 2.706076219286783

Epoch: 6| Step: 1
Training loss: 3.566676318669554
Validation loss: 2.705012930962601

Epoch: 6| Step: 2
Training loss: 2.72404753111656
Validation loss: 2.7116635236851674

Epoch: 6| Step: 3
Training loss: 3.39094703656804
Validation loss: 2.7066123081961977

Epoch: 6| Step: 4
Training loss: 3.087626243821166
Validation loss: 2.712778347132423

Epoch: 6| Step: 5
Training loss: 3.3053853626051994
Validation loss: 2.7160807891719445

Epoch: 6| Step: 6
Training loss: 2.482662162286351
Validation loss: 2.7209471472627786

Epoch: 6| Step: 7
Training loss: 3.2640149103459892
Validation loss: 2.7322453975886303

Epoch: 6| Step: 8
Training loss: 3.37566453961059
Validation loss: 2.7161668994069212

Epoch: 6| Step: 9
Training loss: 3.4056920985827714
Validation loss: 2.7045686190956717

Epoch: 6| Step: 10
Training loss: 2.7055045883091866
Validation loss: 2.70619835455571

Epoch: 6| Step: 11
Training loss: 2.70530286605898
Validation loss: 2.706809243734161

Epoch: 6| Step: 12
Training loss: 1.9868135862407794
Validation loss: 2.7051544840890998

Epoch: 6| Step: 13
Training loss: 2.6977581041398335
Validation loss: 2.7081287000666676

Testing loss: 2.930810642640878
