Epoch: 1| Step: 0
Training loss: 4.957244796301569
Validation loss: 5.750676950319557

Epoch: 6| Step: 1
Training loss: 5.014505897286481
Validation loss: 5.745535677497229

Epoch: 6| Step: 2
Training loss: 7.1459879362622125
Validation loss: 5.740467507336977

Epoch: 6| Step: 3
Training loss: 5.40083685854174
Validation loss: 5.735779435962778

Epoch: 6| Step: 4
Training loss: 6.9345460393577785
Validation loss: 5.730748639401243

Epoch: 6| Step: 5
Training loss: 6.045558263654257
Validation loss: 5.726026906656024

Epoch: 6| Step: 6
Training loss: 5.047840699198748
Validation loss: 5.721215198956087

Epoch: 6| Step: 7
Training loss: 5.607181385799974
Validation loss: 5.71652401962882

Epoch: 6| Step: 8
Training loss: 5.082757427340552
Validation loss: 5.7117742137030545

Epoch: 6| Step: 9
Training loss: 6.5576467824397335
Validation loss: 5.707311239490988

Epoch: 6| Step: 10
Training loss: 3.880566321464016
Validation loss: 5.702304468086382

Epoch: 6| Step: 11
Training loss: 5.743307448181399
Validation loss: 5.697577956534829

Epoch: 6| Step: 12
Training loss: 5.5112361575026565
Validation loss: 5.692444370533033

Epoch: 6| Step: 13
Training loss: 7.392701968084201
Validation loss: 5.686725652539511

Epoch: 2| Step: 0
Training loss: 5.997887557412792
Validation loss: 5.680946047375412

Epoch: 6| Step: 1
Training loss: 5.567612773573604
Validation loss: 5.674708107058738

Epoch: 6| Step: 2
Training loss: 5.415775088758
Validation loss: 5.668999430046314

Epoch: 6| Step: 3
Training loss: 5.652998015757843
Validation loss: 5.662703249406015

Epoch: 6| Step: 4
Training loss: 4.631494858995986
Validation loss: 5.655691021896758

Epoch: 6| Step: 5
Training loss: 5.308797466082942
Validation loss: 5.648508128560011

Epoch: 6| Step: 6
Training loss: 5.689325060779775
Validation loss: 5.640420680418554

Epoch: 6| Step: 7
Training loss: 6.107592700780956
Validation loss: 5.633336961214359

Epoch: 6| Step: 8
Training loss: 6.321336660879231
Validation loss: 5.624835702189814

Epoch: 6| Step: 9
Training loss: 6.840986416724462
Validation loss: 5.615764482340809

Epoch: 6| Step: 10
Training loss: 5.294247135747915
Validation loss: 5.607072187328435

Epoch: 6| Step: 11
Training loss: 4.742305345657856
Validation loss: 5.597347688077467

Epoch: 6| Step: 12
Training loss: 5.734896519200455
Validation loss: 5.588150395898666

Epoch: 6| Step: 13
Training loss: 5.802207447781391
Validation loss: 5.5777226729782035

Epoch: 3| Step: 0
Training loss: 5.705187448135194
Validation loss: 5.567031721470694

Epoch: 6| Step: 1
Training loss: 6.318329791275409
Validation loss: 5.5556314944474545

Epoch: 6| Step: 2
Training loss: 4.627619439741902
Validation loss: 5.544716636509768

Epoch: 6| Step: 3
Training loss: 5.990270992001713
Validation loss: 5.53168888435363

Epoch: 6| Step: 4
Training loss: 5.229469483056455
Validation loss: 5.519843784774355

Epoch: 6| Step: 5
Training loss: 4.5567168071214095
Validation loss: 5.5054216930197

Epoch: 6| Step: 6
Training loss: 5.042302283371608
Validation loss: 5.493134756679593

Epoch: 6| Step: 7
Training loss: 6.46633202516072
Validation loss: 5.478068828454475

Epoch: 6| Step: 8
Training loss: 6.040172874553525
Validation loss: 5.463627475077318

Epoch: 6| Step: 9
Training loss: 4.841258337209207
Validation loss: 5.448702288172525

Epoch: 6| Step: 10
Training loss: 6.125379900925661
Validation loss: 5.432772629387838

Epoch: 6| Step: 11
Training loss: 5.4541140645839254
Validation loss: 5.416626592950116

Epoch: 6| Step: 12
Training loss: 4.960901359366389
Validation loss: 5.398875022935621

Epoch: 6| Step: 13
Training loss: 5.5583374221687585
Validation loss: 5.380126591638745

Epoch: 4| Step: 0
Training loss: 5.492766044608198
Validation loss: 5.362939429995566

Epoch: 6| Step: 1
Training loss: 4.256009509312611
Validation loss: 5.34494238791565

Epoch: 6| Step: 2
Training loss: 5.51857568415865
Validation loss: 5.326600871978792

Epoch: 6| Step: 3
Training loss: 5.197661776463036
Validation loss: 5.306509482855533

Epoch: 6| Step: 4
Training loss: 5.212367740846794
Validation loss: 5.286248875369276

Epoch: 6| Step: 5
Training loss: 5.933748365023902
Validation loss: 5.266346318720609

Epoch: 6| Step: 6
Training loss: 5.171649847287067
Validation loss: 5.245652140232241

Epoch: 6| Step: 7
Training loss: 5.406499250542644
Validation loss: 5.225494473314585

Epoch: 6| Step: 8
Training loss: 5.314266853474843
Validation loss: 5.204032066267167

Epoch: 6| Step: 9
Training loss: 5.3302105264794
Validation loss: 5.182886926263144

Epoch: 6| Step: 10
Training loss: 4.409130696883147
Validation loss: 5.161076646016965

Epoch: 6| Step: 11
Training loss: 5.689422617816424
Validation loss: 5.141745166409011

Epoch: 6| Step: 12
Training loss: 5.706257166445391
Validation loss: 5.120381853473083

Epoch: 6| Step: 13
Training loss: 4.964625536117219
Validation loss: 5.098251261403307

Epoch: 5| Step: 0
Training loss: 5.680966491675604
Validation loss: 5.07802814047346

Epoch: 6| Step: 1
Training loss: 5.3629348542999145
Validation loss: 5.056939761600862

Epoch: 6| Step: 2
Training loss: 5.164891255832044
Validation loss: 5.035958127115623

Epoch: 6| Step: 3
Training loss: 5.829026876013617
Validation loss: 5.016222365978012

Epoch: 6| Step: 4
Training loss: 3.921789768706273
Validation loss: 4.99612219984378

Epoch: 6| Step: 5
Training loss: 4.91430081273291
Validation loss: 4.977296021736191

Epoch: 6| Step: 6
Training loss: 5.108247871783443
Validation loss: 4.959486256085204

Epoch: 6| Step: 7
Training loss: 4.823965904621445
Validation loss: 4.940472616775737

Epoch: 6| Step: 8
Training loss: 4.7165036949516095
Validation loss: 4.921513771959897

Epoch: 6| Step: 9
Training loss: 5.064951738615281
Validation loss: 4.9039036381306955

Epoch: 6| Step: 10
Training loss: 4.842502162540959
Validation loss: 4.887216415383888

Epoch: 6| Step: 11
Training loss: 5.822959758710557
Validation loss: 4.869921106084923

Epoch: 6| Step: 12
Training loss: 4.56785645311824
Validation loss: 4.851489690144098

Epoch: 6| Step: 13
Training loss: 3.2530588280711434
Validation loss: 4.834743929699209

Epoch: 6| Step: 0
Training loss: 4.871701420596844
Validation loss: 4.8190385422700714

Epoch: 6| Step: 1
Training loss: 4.8499664777403435
Validation loss: 4.803359508629389

Epoch: 6| Step: 2
Training loss: 4.992940496687979
Validation loss: 4.785229145538688

Epoch: 6| Step: 3
Training loss: 4.6609952160250705
Validation loss: 4.770786822351543

Epoch: 6| Step: 4
Training loss: 4.8859741717049
Validation loss: 4.753377209302556

Epoch: 6| Step: 5
Training loss: 3.821182370371977
Validation loss: 4.737896938385258

Epoch: 6| Step: 6
Training loss: 5.197568016616379
Validation loss: 4.722673295104794

Epoch: 6| Step: 7
Training loss: 4.636576212465295
Validation loss: 4.7083683032582

Epoch: 6| Step: 8
Training loss: 5.112799660404429
Validation loss: 4.692950820771837

Epoch: 6| Step: 9
Training loss: 4.9903799972637195
Validation loss: 4.676763029943138

Epoch: 6| Step: 10
Training loss: 5.878247601185224
Validation loss: 4.66394361399178

Epoch: 6| Step: 11
Training loss: 4.3166214418926545
Validation loss: 4.647652841648997

Epoch: 6| Step: 12
Training loss: 4.150024110655088
Validation loss: 4.6329852598382155

Epoch: 6| Step: 13
Training loss: 4.302662118520619
Validation loss: 4.616856641463864

Epoch: 7| Step: 0
Training loss: 5.168760531690355
Validation loss: 4.6022738811422

Epoch: 6| Step: 1
Training loss: 3.9601950165865536
Validation loss: 4.5868639632674615

Epoch: 6| Step: 2
Training loss: 4.210793006130617
Validation loss: 4.572402003864475

Epoch: 6| Step: 3
Training loss: 4.804329413739513
Validation loss: 4.558456577846244

Epoch: 6| Step: 4
Training loss: 5.314173894722454
Validation loss: 4.541713409920861

Epoch: 6| Step: 5
Training loss: 4.502416173990205
Validation loss: 4.528390736882264

Epoch: 6| Step: 6
Training loss: 4.708442799243716
Validation loss: 4.513720470449135

Epoch: 6| Step: 7
Training loss: 3.435728553014985
Validation loss: 4.498893802362946

Epoch: 6| Step: 8
Training loss: 4.141303701377852
Validation loss: 4.485865257830367

Epoch: 6| Step: 9
Training loss: 5.191097988049657
Validation loss: 4.470830207015252

Epoch: 6| Step: 10
Training loss: 5.182659234537132
Validation loss: 4.457612546460953

Epoch: 6| Step: 11
Training loss: 3.6778430244008224
Validation loss: 4.445082300484702

Epoch: 6| Step: 12
Training loss: 5.146426559210352
Validation loss: 4.434007928968904

Epoch: 6| Step: 13
Training loss: 4.521850307478905
Validation loss: 4.419219313530709

Epoch: 8| Step: 0
Training loss: 4.413155413572663
Validation loss: 4.40829815110315

Epoch: 6| Step: 1
Training loss: 5.051222307695219
Validation loss: 4.396138159902008

Epoch: 6| Step: 2
Training loss: 5.643339988372598
Validation loss: 4.383822324638484

Epoch: 6| Step: 3
Training loss: 4.407294832626837
Validation loss: 4.371015316830255

Epoch: 6| Step: 4
Training loss: 4.911013872000013
Validation loss: 4.357669306827587

Epoch: 6| Step: 5
Training loss: 3.3034411666109276
Validation loss: 4.346109309767183

Epoch: 6| Step: 6
Training loss: 3.239730161097315
Validation loss: 4.333958352751727

Epoch: 6| Step: 7
Training loss: 3.402134360035675
Validation loss: 4.3227880172870075

Epoch: 6| Step: 8
Training loss: 4.183360544751993
Validation loss: 4.311534133188246

Epoch: 6| Step: 9
Training loss: 4.69371129818744
Validation loss: 4.300868130023446

Epoch: 6| Step: 10
Training loss: 4.112893110693522
Validation loss: 4.290914622354026

Epoch: 6| Step: 11
Training loss: 4.81096476057456
Validation loss: 4.282045579532962

Epoch: 6| Step: 12
Training loss: 4.3408918239680405
Validation loss: 4.271539986907732

Epoch: 6| Step: 13
Training loss: 5.45705746403421
Validation loss: 4.261653763963687

Epoch: 9| Step: 0
Training loss: 4.2063765304148655
Validation loss: 4.252023915918848

Epoch: 6| Step: 1
Training loss: 4.789501972787867
Validation loss: 4.241804220242261

Epoch: 6| Step: 2
Training loss: 3.966827888311188
Validation loss: 4.23332430234848

Epoch: 6| Step: 3
Training loss: 4.873996533529985
Validation loss: 4.222857618169749

Epoch: 6| Step: 4
Training loss: 4.235999890032975
Validation loss: 4.214820196411007

Epoch: 6| Step: 5
Training loss: 4.5156279567194035
Validation loss: 4.204099317233752

Epoch: 6| Step: 6
Training loss: 4.794065367111782
Validation loss: 4.198170129408793

Epoch: 6| Step: 7
Training loss: 4.099174807243745
Validation loss: 4.190064018861374

Epoch: 6| Step: 8
Training loss: 3.7295129000799547
Validation loss: 4.178279453921724

Epoch: 6| Step: 9
Training loss: 3.9367682367368637
Validation loss: 4.171580728689082

Epoch: 6| Step: 10
Training loss: 4.390721004427485
Validation loss: 4.164036972256086

Epoch: 6| Step: 11
Training loss: 4.498078041780321
Validation loss: 4.154545889468621

Epoch: 6| Step: 12
Training loss: 3.8830452125858437
Validation loss: 4.147048029384008

Epoch: 6| Step: 13
Training loss: 4.547850618859951
Validation loss: 4.137319936720049

Epoch: 10| Step: 0
Training loss: 3.0916236737356053
Validation loss: 4.1324628937227965

Epoch: 6| Step: 1
Training loss: 4.089214112528894
Validation loss: 4.126698658488985

Epoch: 6| Step: 2
Training loss: 4.846796468249794
Validation loss: 4.118729985435427

Epoch: 6| Step: 3
Training loss: 3.497233523619146
Validation loss: 4.113372160084336

Epoch: 6| Step: 4
Training loss: 4.442770178999058
Validation loss: 4.106880215819201

Epoch: 6| Step: 5
Training loss: 3.706456741819536
Validation loss: 4.099112373930126

Epoch: 6| Step: 6
Training loss: 4.8429940895172106
Validation loss: 4.092705287796551

Epoch: 6| Step: 7
Training loss: 3.7829781358547367
Validation loss: 4.0865390859958

Epoch: 6| Step: 8
Training loss: 4.902507156141195
Validation loss: 4.082291418468043

Epoch: 6| Step: 9
Training loss: 5.446999506093677
Validation loss: 4.072658329940277

Epoch: 6| Step: 10
Training loss: 3.348988787491334
Validation loss: 4.065069374633027

Epoch: 6| Step: 11
Training loss: 4.321073109893527
Validation loss: 4.059629700097859

Epoch: 6| Step: 12
Training loss: 3.8618507012341956
Validation loss: 4.053960748910794

Epoch: 6| Step: 13
Training loss: 4.372946120852498
Validation loss: 4.0491524880494465

Epoch: 11| Step: 0
Training loss: 3.3554616446192234
Validation loss: 4.040678249547837

Epoch: 6| Step: 1
Training loss: 4.2617012953641185
Validation loss: 4.035431611326094

Epoch: 6| Step: 2
Training loss: 4.771803356099988
Validation loss: 4.029877123872813

Epoch: 6| Step: 3
Training loss: 4.079589580761885
Validation loss: 4.022263521805702

Epoch: 6| Step: 4
Training loss: 4.586734734924667
Validation loss: 4.022048800061937

Epoch: 6| Step: 5
Training loss: 3.8652156233754345
Validation loss: 4.012586515731696

Epoch: 6| Step: 6
Training loss: 3.995468672473822
Validation loss: 4.009975039656297

Epoch: 6| Step: 7
Training loss: 4.628202412207074
Validation loss: 4.003929210549987

Epoch: 6| Step: 8
Training loss: 4.652396226614202
Validation loss: 3.9967399432918564

Epoch: 6| Step: 9
Training loss: 4.792227117961134
Validation loss: 3.990372541509459

Epoch: 6| Step: 10
Training loss: 3.402883143102024
Validation loss: 3.984929970767616

Epoch: 6| Step: 11
Training loss: 3.912956157576172
Validation loss: 3.9788526271414444

Epoch: 6| Step: 12
Training loss: 3.7123998711951685
Validation loss: 3.974141716699002

Epoch: 6| Step: 13
Training loss: 3.4931995538279472
Validation loss: 3.9661535933430656

Epoch: 12| Step: 0
Training loss: 3.993245501584556
Validation loss: 3.9636881766208014

Epoch: 6| Step: 1
Training loss: 4.441195815980073
Validation loss: 3.9551133267258956

Epoch: 6| Step: 2
Training loss: 4.079946761438423
Validation loss: 3.950267351126075

Epoch: 6| Step: 3
Training loss: 3.9213793923964215
Validation loss: 3.9462528777614256

Epoch: 6| Step: 4
Training loss: 4.61479132580368
Validation loss: 3.938508470562139

Epoch: 6| Step: 5
Training loss: 3.9621109587966985
Validation loss: 3.9356836106562763

Epoch: 6| Step: 6
Training loss: 4.600546447804674
Validation loss: 3.9285059393527675

Epoch: 6| Step: 7
Training loss: 3.9343050149839343
Validation loss: 3.9259205930123313

Epoch: 6| Step: 8
Training loss: 3.708533863832101
Validation loss: 3.9186372942014738

Epoch: 6| Step: 9
Training loss: 4.591399337454384
Validation loss: 3.9127461171188784

Epoch: 6| Step: 10
Training loss: 4.416514244088578
Validation loss: 3.9040167454720667

Epoch: 6| Step: 11
Training loss: 3.787532159146293
Validation loss: 3.89982419171197

Epoch: 6| Step: 12
Training loss: 3.3823030365679476
Validation loss: 3.8955451095818785

Epoch: 6| Step: 13
Training loss: 3.017927170599625
Validation loss: 3.8910513924796204

Epoch: 13| Step: 0
Training loss: 3.638608709781186
Validation loss: 3.889510514540613

Epoch: 6| Step: 1
Training loss: 4.16096997250167
Validation loss: 3.8834062918975705

Epoch: 6| Step: 2
Training loss: 4.369576716753437
Validation loss: 3.87917973898033

Epoch: 6| Step: 3
Training loss: 4.488262339154569
Validation loss: 3.8742547828705516

Epoch: 6| Step: 4
Training loss: 3.4627850081274474
Validation loss: 3.8685093219663123

Epoch: 6| Step: 5
Training loss: 3.8611369570470067
Validation loss: 3.8625643188418395

Epoch: 6| Step: 6
Training loss: 4.5051208605203374
Validation loss: 3.8580138787291642

Epoch: 6| Step: 7
Training loss: 3.439813840841326
Validation loss: 3.8519601072324425

Epoch: 6| Step: 8
Training loss: 4.104777618220498
Validation loss: 3.8456240571665057

Epoch: 6| Step: 9
Training loss: 3.779499626142491
Validation loss: 3.8414884887942606

Epoch: 6| Step: 10
Training loss: 4.927377682604244
Validation loss: 3.836505623683017

Epoch: 6| Step: 11
Training loss: 3.816106247604405
Validation loss: 3.833001314116812

Epoch: 6| Step: 12
Training loss: 3.9117399165984774
Validation loss: 3.829280326845591

Epoch: 6| Step: 13
Training loss: 3.106401257890618
Validation loss: 3.82487924449401

Epoch: 14| Step: 0
Training loss: 4.458414998004739
Validation loss: 3.8185916852310595

Epoch: 6| Step: 1
Training loss: 4.057525641077691
Validation loss: 3.811572184735482

Epoch: 6| Step: 2
Training loss: 3.0720362204760856
Validation loss: 3.8074671224253915

Epoch: 6| Step: 3
Training loss: 4.339968565374351
Validation loss: 3.801964373152643

Epoch: 6| Step: 4
Training loss: 4.0476573055393334
Validation loss: 3.795939090578742

Epoch: 6| Step: 5
Training loss: 3.2525029447924854
Validation loss: 3.7925554162688537

Epoch: 6| Step: 6
Training loss: 4.576600325386747
Validation loss: 3.789197293213869

Epoch: 6| Step: 7
Training loss: 2.9060721394247966
Validation loss: 3.785111494549094

Epoch: 6| Step: 8
Training loss: 3.811216419706359
Validation loss: 3.7813272518306507

Epoch: 6| Step: 9
Training loss: 4.573654960985627
Validation loss: 3.7748019792308063

Epoch: 6| Step: 10
Training loss: 4.269423138784475
Validation loss: 3.7744750800128504

Epoch: 6| Step: 11
Training loss: 4.57088379508962
Validation loss: 3.7678357419339674

Epoch: 6| Step: 12
Training loss: 3.2356974528827314
Validation loss: 3.764709361334203

Epoch: 6| Step: 13
Training loss: 3.476577312995128
Validation loss: 3.7618271981345424

Epoch: 15| Step: 0
Training loss: 5.425649774549977
Validation loss: 3.7584394698948262

Epoch: 6| Step: 1
Training loss: 4.253328254321981
Validation loss: 3.755380134543317

Epoch: 6| Step: 2
Training loss: 4.070183164331912
Validation loss: 3.7475529825560643

Epoch: 6| Step: 3
Training loss: 3.794400134618356
Validation loss: 3.748000746177667

Epoch: 6| Step: 4
Training loss: 4.1184710070946595
Validation loss: 3.7439923514245166

Epoch: 6| Step: 5
Training loss: 4.773836858997513
Validation loss: 3.738365984086551

Epoch: 6| Step: 6
Training loss: 3.622248164151003
Validation loss: 3.737089464171258

Epoch: 6| Step: 7
Training loss: 3.384617700442609
Validation loss: 3.733531996627828

Epoch: 6| Step: 8
Training loss: 2.989609526587036
Validation loss: 3.7305698217225176

Epoch: 6| Step: 9
Training loss: 3.239141370711999
Validation loss: 3.7297099470435535

Epoch: 6| Step: 10
Training loss: 3.476200110589479
Validation loss: 3.727222704294215

Epoch: 6| Step: 11
Training loss: 3.410978482498658
Validation loss: 3.723003443268598

Epoch: 6| Step: 12
Training loss: 2.990852077875701
Validation loss: 3.7221534991319096

Epoch: 6| Step: 13
Training loss: 4.875762488572501
Validation loss: 3.7177625258321347

Epoch: 16| Step: 0
Training loss: 4.3678290317318345
Validation loss: 3.7159860883344384

Epoch: 6| Step: 1
Training loss: 3.8273572502201816
Validation loss: 3.714167849910747

Epoch: 6| Step: 2
Training loss: 4.196408943663729
Validation loss: 3.712208546185649

Epoch: 6| Step: 3
Training loss: 3.48372846002014
Validation loss: 3.708688016389743

Epoch: 6| Step: 4
Training loss: 3.691009274082733
Validation loss: 3.7063285567668207

Epoch: 6| Step: 5
Training loss: 3.9305608245370967
Validation loss: 3.704180651676549

Epoch: 6| Step: 6
Training loss: 4.308409146515602
Validation loss: 3.701667625903347

Epoch: 6| Step: 7
Training loss: 3.5289647632719485
Validation loss: 3.698440673157995

Epoch: 6| Step: 8
Training loss: 4.161521608765203
Validation loss: 3.698401081963973

Epoch: 6| Step: 9
Training loss: 3.375130262333548
Validation loss: 3.691642777004919

Epoch: 6| Step: 10
Training loss: 3.6445506137280343
Validation loss: 3.6911385703860526

Epoch: 6| Step: 11
Training loss: 3.7032396001024024
Validation loss: 3.6888410835052947

Epoch: 6| Step: 12
Training loss: 3.8409771105246406
Validation loss: 3.688072270029499

Epoch: 6| Step: 13
Training loss: 4.396399559446765
Validation loss: 3.686642490945518

Epoch: 17| Step: 0
Training loss: 3.2210018836000818
Validation loss: 3.682621628911246

Epoch: 6| Step: 1
Training loss: 3.6182593452787857
Validation loss: 3.680804540088831

Epoch: 6| Step: 2
Training loss: 4.210327557214295
Validation loss: 3.6781212455840544

Epoch: 6| Step: 3
Training loss: 4.524489838731131
Validation loss: 3.6759601880879047

Epoch: 6| Step: 4
Training loss: 3.695750688376418
Validation loss: 3.6742718562682755

Epoch: 6| Step: 5
Training loss: 4.663294232095244
Validation loss: 3.671170203213793

Epoch: 6| Step: 6
Training loss: 3.731144868784962
Validation loss: 3.670096009341973

Epoch: 6| Step: 7
Training loss: 4.104168164144847
Validation loss: 3.6666634430036793

Epoch: 6| Step: 8
Training loss: 3.5533349450723835
Validation loss: 3.662437528700206

Epoch: 6| Step: 9
Training loss: 3.659807088802099
Validation loss: 3.6622315825823324

Epoch: 6| Step: 10
Training loss: 3.2738677768561324
Validation loss: 3.6586158417619767

Epoch: 6| Step: 11
Training loss: 4.143536620018646
Validation loss: 3.656965687902233

Epoch: 6| Step: 12
Training loss: 3.5134843200533488
Validation loss: 3.655300624685233

Epoch: 6| Step: 13
Training loss: 3.7121668656513735
Validation loss: 3.6544006609676174

Epoch: 18| Step: 0
Training loss: 3.179862052756463
Validation loss: 3.6509202735655286

Epoch: 6| Step: 1
Training loss: 3.909835756564532
Validation loss: 3.6476569265050025

Epoch: 6| Step: 2
Training loss: 4.096685623692064
Validation loss: 3.649060130259595

Epoch: 6| Step: 3
Training loss: 3.8375357660372673
Validation loss: 3.6442504770438897

Epoch: 6| Step: 4
Training loss: 3.9015665282693464
Validation loss: 3.6431089614491676

Epoch: 6| Step: 5
Training loss: 3.9667669433185737
Validation loss: 3.6423814854589587

Epoch: 6| Step: 6
Training loss: 3.3841179493849087
Validation loss: 3.640728814478703

Epoch: 6| Step: 7
Training loss: 3.8350206199996832
Validation loss: 3.6386737040215897

Epoch: 6| Step: 8
Training loss: 4.485163071133334
Validation loss: 3.6372847440624136

Epoch: 6| Step: 9
Training loss: 2.9598776498200556
Validation loss: 3.635468728208409

Epoch: 6| Step: 10
Training loss: 4.01217919133771
Validation loss: 3.635976040635255

Epoch: 6| Step: 11
Training loss: 3.848545215754904
Validation loss: 3.631920148017042

Epoch: 6| Step: 12
Training loss: 3.717835257727415
Validation loss: 3.6302882607216476

Epoch: 6| Step: 13
Training loss: 4.549883604132882
Validation loss: 3.628363332272295

Epoch: 19| Step: 0
Training loss: 2.7572405602984182
Validation loss: 3.6252780916548244

Epoch: 6| Step: 1
Training loss: 3.735340967100986
Validation loss: 3.6243073618901733

Epoch: 6| Step: 2
Training loss: 3.4325753742563574
Validation loss: 3.625527297931076

Epoch: 6| Step: 3
Training loss: 3.638178842654343
Validation loss: 3.6274994566639065

Epoch: 6| Step: 4
Training loss: 4.42191791850583
Validation loss: 3.6218697905439963

Epoch: 6| Step: 5
Training loss: 4.821490720318072
Validation loss: 3.619167273261462

Epoch: 6| Step: 6
Training loss: 4.336314911783986
Validation loss: 3.618238314668422

Epoch: 6| Step: 7
Training loss: 3.1661933411334027
Validation loss: 3.617109647054918

Epoch: 6| Step: 8
Training loss: 3.2265933868924948
Validation loss: 3.615789808523119

Epoch: 6| Step: 9
Training loss: 2.8375874913376844
Validation loss: 3.614539527940878

Epoch: 6| Step: 10
Training loss: 4.16453472272559
Validation loss: 3.613398307892987

Epoch: 6| Step: 11
Training loss: 4.312366870539083
Validation loss: 3.612475761510809

Epoch: 6| Step: 12
Training loss: 3.7789565768547035
Validation loss: 3.609625591146206

Epoch: 6| Step: 13
Training loss: 4.3126782366643175
Validation loss: 3.608514024034207

Epoch: 20| Step: 0
Training loss: 4.249689427416101
Validation loss: 3.606737529558974

Epoch: 6| Step: 1
Training loss: 3.3890313829019694
Validation loss: 3.6057157889024594

Epoch: 6| Step: 2
Training loss: 3.8995812215689623
Validation loss: 3.6036574154315364

Epoch: 6| Step: 3
Training loss: 4.1112520405667725
Validation loss: 3.603392951443068

Epoch: 6| Step: 4
Training loss: 4.436387043392325
Validation loss: 3.6016245781397673

Epoch: 6| Step: 5
Training loss: 2.8689159204043624
Validation loss: 3.6001418344980736

Epoch: 6| Step: 6
Training loss: 3.0474248927861787
Validation loss: 3.5985871278750934

Epoch: 6| Step: 7
Training loss: 3.894621363049743
Validation loss: 3.5959349222880435

Epoch: 6| Step: 8
Training loss: 3.622955534984066
Validation loss: 3.594238265201561

Epoch: 6| Step: 9
Training loss: 3.9189785295985105
Validation loss: 3.5928056529264687

Epoch: 6| Step: 10
Training loss: 3.840160647846589
Validation loss: 3.5913824799586855

Epoch: 6| Step: 11
Training loss: 3.497157986587723
Validation loss: 3.5899250550173507

Epoch: 6| Step: 12
Training loss: 3.703440721146867
Validation loss: 3.588214813601402

Epoch: 6| Step: 13
Training loss: 4.698429234773035
Validation loss: 3.5874802636216105

Epoch: 21| Step: 0
Training loss: 3.9604053628925073
Validation loss: 3.5869318189695427

Epoch: 6| Step: 1
Training loss: 3.3844782227953796
Validation loss: 3.5835225874957812

Epoch: 6| Step: 2
Training loss: 3.309477668877054
Validation loss: 3.582956519397951

Epoch: 6| Step: 3
Training loss: 2.660150334691936
Validation loss: 3.5829013660441937

Epoch: 6| Step: 4
Training loss: 3.8708803982263578
Validation loss: 3.5809800408893087

Epoch: 6| Step: 5
Training loss: 4.303228169009929
Validation loss: 3.580703035171633

Epoch: 6| Step: 6
Training loss: 4.514287519540822
Validation loss: 3.5789162659675444

Epoch: 6| Step: 7
Training loss: 3.155048406021045
Validation loss: 3.578342163012991

Epoch: 6| Step: 8
Training loss: 3.8114192243711855
Validation loss: 3.579374828834641

Epoch: 6| Step: 9
Training loss: 3.9300180224134014
Validation loss: 3.5782662561841074

Epoch: 6| Step: 10
Training loss: 3.9777005408926374
Validation loss: 3.575570146191201

Epoch: 6| Step: 11
Training loss: 3.4804068237686736
Validation loss: 3.57484839775029

Epoch: 6| Step: 12
Training loss: 4.187433042987309
Validation loss: 3.573976708486628

Epoch: 6| Step: 13
Training loss: 4.105276406352999
Validation loss: 3.5729695111758044

Epoch: 22| Step: 0
Training loss: 3.8459198572434974
Validation loss: 3.571685655485102

Epoch: 6| Step: 1
Training loss: 4.4166984317045115
Validation loss: 3.5738212875053628

Epoch: 6| Step: 2
Training loss: 4.082119092954357
Validation loss: 3.5718727668839416

Epoch: 6| Step: 3
Training loss: 3.1386638230586668
Validation loss: 3.572093518054352

Epoch: 6| Step: 4
Training loss: 3.6187564092128044
Validation loss: 3.573395953461563

Epoch: 6| Step: 5
Training loss: 3.498234439764814
Validation loss: 3.570792927993645

Epoch: 6| Step: 6
Training loss: 3.101813856264359
Validation loss: 3.5695102874921236

Epoch: 6| Step: 7
Training loss: 3.6201930566807015
Validation loss: 3.5697661561395932

Epoch: 6| Step: 8
Training loss: 3.9374286705701267
Validation loss: 3.5674358645016957

Epoch: 6| Step: 9
Training loss: 4.303225066351944
Validation loss: 3.5676882459510493

Epoch: 6| Step: 10
Training loss: 3.4870548634174656
Validation loss: 3.5679773502170806

Epoch: 6| Step: 11
Training loss: 3.5963176013690714
Validation loss: 3.566840481847476

Epoch: 6| Step: 12
Training loss: 3.709838190380237
Validation loss: 3.566129654965509

Epoch: 6| Step: 13
Training loss: 4.500348819352741
Validation loss: 3.5647617220774066

Epoch: 23| Step: 0
Training loss: 4.572982660163523
Validation loss: 3.5627563735487313

Epoch: 6| Step: 1
Training loss: 3.9960987616812416
Validation loss: 3.5615524934637146

Epoch: 6| Step: 2
Training loss: 4.282159861759605
Validation loss: 3.5607160654345322

Epoch: 6| Step: 3
Training loss: 4.498131258028508
Validation loss: 3.5595001460009525

Epoch: 6| Step: 4
Training loss: 4.16812273650938
Validation loss: 3.560485415585568

Epoch: 6| Step: 5
Training loss: 3.6352713190587833
Validation loss: 3.556677671247227

Epoch: 6| Step: 6
Training loss: 3.778670006150426
Validation loss: 3.5560014306939465

Epoch: 6| Step: 7
Training loss: 4.028947039315045
Validation loss: 3.5558676632885606

Epoch: 6| Step: 8
Training loss: 3.273519947406665
Validation loss: 3.554901652447661

Epoch: 6| Step: 9
Training loss: 3.246125332418188
Validation loss: 3.553924694339877

Epoch: 6| Step: 10
Training loss: 3.2595385911801347
Validation loss: 3.553208635725604

Epoch: 6| Step: 11
Training loss: 2.7383878200107454
Validation loss: 3.551916989247159

Epoch: 6| Step: 12
Training loss: 3.222939736584334
Validation loss: 3.551050448031472

Epoch: 6| Step: 13
Training loss: 3.200563476543281
Validation loss: 3.5497580841427143

Epoch: 24| Step: 0
Training loss: 3.250825337003528
Validation loss: 3.549096546585334

Epoch: 6| Step: 1
Training loss: 4.566935225523346
Validation loss: 3.5471100632850687

Epoch: 6| Step: 2
Training loss: 4.367950864075346
Validation loss: 3.546566671023811

Epoch: 6| Step: 3
Training loss: 2.8618433569820594
Validation loss: 3.546243858371555

Epoch: 6| Step: 4
Training loss: 4.12202346222043
Validation loss: 3.54319636819903

Epoch: 6| Step: 5
Training loss: 3.2761915179712493
Validation loss: 3.5410944559052098

Epoch: 6| Step: 6
Training loss: 2.750603956312359
Validation loss: 3.539392279334715

Epoch: 6| Step: 7
Training loss: 3.780230297964908
Validation loss: 3.5379067099942016

Epoch: 6| Step: 8
Training loss: 3.3745491291810152
Validation loss: 3.5353922215227174

Epoch: 6| Step: 9
Training loss: 3.6925663169737417
Validation loss: 3.534613439611621

Epoch: 6| Step: 10
Training loss: 3.751853357723205
Validation loss: 3.534867022973663

Epoch: 6| Step: 11
Training loss: 3.619363019340763
Validation loss: 3.531257660603651

Epoch: 6| Step: 12
Training loss: 4.608530568506028
Validation loss: 3.530467545001785

Epoch: 6| Step: 13
Training loss: 3.975818017245005
Validation loss: 3.530090366680136

Epoch: 25| Step: 0
Training loss: 3.9247888933496586
Validation loss: 3.5299317816751694

Epoch: 6| Step: 1
Training loss: 3.1482280349153013
Validation loss: 3.530239045089875

Epoch: 6| Step: 2
Training loss: 3.5893299287134646
Validation loss: 3.5273777767229024

Epoch: 6| Step: 3
Training loss: 2.9443124545601687
Validation loss: 3.5259712832516232

Epoch: 6| Step: 4
Training loss: 2.9712956807529167
Validation loss: 3.5251563242414865

Epoch: 6| Step: 5
Training loss: 4.310779615375157
Validation loss: 3.5251150646701053

Epoch: 6| Step: 6
Training loss: 4.084133355275251
Validation loss: 3.524788808041565

Epoch: 6| Step: 7
Training loss: 3.9108608041726898
Validation loss: 3.5243594900063298

Epoch: 6| Step: 8
Training loss: 3.5038240523037043
Validation loss: 3.5221836733293386

Epoch: 6| Step: 9
Training loss: 3.2752284428951537
Validation loss: 3.5219947883157587

Epoch: 6| Step: 10
Training loss: 4.781057117037201
Validation loss: 3.520584109760195

Epoch: 6| Step: 11
Training loss: 3.9873469021384587
Validation loss: 3.520826510219925

Epoch: 6| Step: 12
Training loss: 3.3115460443695315
Validation loss: 3.520917913405526

Epoch: 6| Step: 13
Training loss: 4.247969871787724
Validation loss: 3.5192239141934336

Epoch: 26| Step: 0
Training loss: 2.6486528247183836
Validation loss: 3.5192161967991065

Epoch: 6| Step: 1
Training loss: 3.4467374661796626
Validation loss: 3.5183644170560613

Epoch: 6| Step: 2
Training loss: 3.6331746238785736
Validation loss: 3.5170525871595144

Epoch: 6| Step: 3
Training loss: 4.37368493070167
Validation loss: 3.5169149998615223

Epoch: 6| Step: 4
Training loss: 4.682478593002405
Validation loss: 3.5163733754348243

Epoch: 6| Step: 5
Training loss: 3.839607798097729
Validation loss: 3.5164439089153725

Epoch: 6| Step: 6
Training loss: 3.5218375013600967
Validation loss: 3.5158117422004858

Epoch: 6| Step: 7
Training loss: 4.059283817433025
Validation loss: 3.5150974241520756

Epoch: 6| Step: 8
Training loss: 3.0725383116131466
Validation loss: 3.5143892474904215

Epoch: 6| Step: 9
Training loss: 3.145728675836099
Validation loss: 3.513859040554278

Epoch: 6| Step: 10
Training loss: 3.9690260903752073
Validation loss: 3.5131463847608906

Epoch: 6| Step: 11
Training loss: 3.9229880649405517
Validation loss: 3.5129213134390516

Epoch: 6| Step: 12
Training loss: 3.4224432207835536
Validation loss: 3.5122491953630224

Epoch: 6| Step: 13
Training loss: 4.094380104552062
Validation loss: 3.511361270940877

Epoch: 27| Step: 0
Training loss: 4.0820445667396426
Validation loss: 3.5116737480829414

Epoch: 6| Step: 1
Training loss: 4.13460416843483
Validation loss: 3.509827883440733

Epoch: 6| Step: 2
Training loss: 4.1157666528839085
Validation loss: 3.511944685306837

Epoch: 6| Step: 3
Training loss: 3.196366935921202
Validation loss: 3.5099480964593712

Epoch: 6| Step: 4
Training loss: 3.2078915741878817
Validation loss: 3.509498933881063

Epoch: 6| Step: 5
Training loss: 4.369932673304461
Validation loss: 3.5094044566341585

Epoch: 6| Step: 6
Training loss: 3.716088632928876
Validation loss: 3.5072520198563426

Epoch: 6| Step: 7
Training loss: 3.243652012985927
Validation loss: 3.507096387480165

Epoch: 6| Step: 8
Training loss: 3.8428863547577747
Validation loss: 3.507475721258721

Epoch: 6| Step: 9
Training loss: 3.5741401705416087
Validation loss: 3.507067835025433

Epoch: 6| Step: 10
Training loss: 3.347955501183197
Validation loss: 3.5058901134620433

Epoch: 6| Step: 11
Training loss: 4.0551178984900424
Validation loss: 3.504875581394476

Epoch: 6| Step: 12
Training loss: 3.3921634682006583
Validation loss: 3.504749826821394

Epoch: 6| Step: 13
Training loss: 3.3974919549370983
Validation loss: 3.5039374679960162

Epoch: 28| Step: 0
Training loss: 3.809897738508616
Validation loss: 3.5047971076527937

Epoch: 6| Step: 1
Training loss: 3.622856032288404
Validation loss: 3.505093742681557

Epoch: 6| Step: 2
Training loss: 2.919996994226032
Validation loss: 3.5037267594172903

Epoch: 6| Step: 3
Training loss: 3.1798860455134506
Validation loss: 3.502750089787827

Epoch: 6| Step: 4
Training loss: 4.31204199086482
Validation loss: 3.5023625657811523

Epoch: 6| Step: 5
Training loss: 3.105178838668908
Validation loss: 3.5026406933957155

Epoch: 6| Step: 6
Training loss: 2.8035231699794845
Validation loss: 3.5014013540845954

Epoch: 6| Step: 7
Training loss: 3.7232687287174313
Validation loss: 3.5010428977070043

Epoch: 6| Step: 8
Training loss: 3.995518558157875
Validation loss: 3.5009813456480425

Epoch: 6| Step: 9
Training loss: 3.88668243544593
Validation loss: 3.5015147354978393

Epoch: 6| Step: 10
Training loss: 4.020672309036188
Validation loss: 3.5006855162948933

Epoch: 6| Step: 11
Training loss: 4.20970257431094
Validation loss: 3.500296600654106

Epoch: 6| Step: 12
Training loss: 4.195019702887841
Validation loss: 3.5011428440888355

Epoch: 6| Step: 13
Training loss: 3.871006415158561
Validation loss: 3.499474005427831

Epoch: 29| Step: 0
Training loss: 4.046524091552
Validation loss: 3.4983143592797563

Epoch: 6| Step: 1
Training loss: 4.35437775363345
Validation loss: 3.499136661516291

Epoch: 6| Step: 2
Training loss: 3.567879480122637
Validation loss: 3.498839040781505

Epoch: 6| Step: 3
Training loss: 3.2701189431306132
Validation loss: 3.497195890922751

Epoch: 6| Step: 4
Training loss: 3.52144646055574
Validation loss: 3.4968237491426555

Epoch: 6| Step: 5
Training loss: 3.4251328379912134
Validation loss: 3.497703578228139

Epoch: 6| Step: 6
Training loss: 4.328014165788127
Validation loss: 3.496914266568751

Epoch: 6| Step: 7
Training loss: 3.8051875293050554
Validation loss: 3.495828793045207

Epoch: 6| Step: 8
Training loss: 3.9724625171695935
Validation loss: 3.4959318745798025

Epoch: 6| Step: 9
Training loss: 3.4030273311390684
Validation loss: 3.4953074384212766

Epoch: 6| Step: 10
Training loss: 3.586585557675212
Validation loss: 3.4952462093023726

Epoch: 6| Step: 11
Training loss: 3.4987182995176793
Validation loss: 3.495478840511208

Epoch: 6| Step: 12
Training loss: 3.906324462180914
Validation loss: 3.495142030787098

Epoch: 6| Step: 13
Training loss: 2.3158107461705195
Validation loss: 3.496384352820471

Epoch: 30| Step: 0
Training loss: 3.863109681241494
Validation loss: 3.498542523200121

Epoch: 6| Step: 1
Training loss: 4.122540058336944
Validation loss: 3.494624633426072

Epoch: 6| Step: 2
Training loss: 3.5131604859928895
Validation loss: 3.494225572144453

Epoch: 6| Step: 3
Training loss: 3.363780127553077
Validation loss: 3.4929563869692637

Epoch: 6| Step: 4
Training loss: 3.4050528846252486
Validation loss: 3.4926180215711313

Epoch: 6| Step: 5
Training loss: 3.750783838367741
Validation loss: 3.492676401850966

Epoch: 6| Step: 6
Training loss: 4.3343718580304715
Validation loss: 3.493993796664396

Epoch: 6| Step: 7
Training loss: 4.09347673042778
Validation loss: 3.4925595815931003

Epoch: 6| Step: 8
Training loss: 3.2701746445427875
Validation loss: 3.491881585521649

Epoch: 6| Step: 9
Training loss: 2.5010106904763427
Validation loss: 3.4907690074714988

Epoch: 6| Step: 10
Training loss: 4.261522493117992
Validation loss: 3.492159578113965

Epoch: 6| Step: 11
Training loss: 3.4988866125041325
Validation loss: 3.4914471858158183

Epoch: 6| Step: 12
Training loss: 3.986165201763102
Validation loss: 3.490189786522986

Epoch: 6| Step: 13
Training loss: 3.4012774648121784
Validation loss: 3.49025540125437

Epoch: 31| Step: 0
Training loss: 4.477731495490001
Validation loss: 3.4899668517534916

Epoch: 6| Step: 1
Training loss: 3.417547546591756
Validation loss: 3.4900639890636524

Epoch: 6| Step: 2
Training loss: 4.269053663676484
Validation loss: 3.4894962530730047

Epoch: 6| Step: 3
Training loss: 2.758486225082026
Validation loss: 3.488985774829898

Epoch: 6| Step: 4
Training loss: 3.314443485963076
Validation loss: 3.4889502538635

Epoch: 6| Step: 5
Training loss: 3.1787482896710952
Validation loss: 3.4881720583521347

Epoch: 6| Step: 6
Training loss: 3.198899026062384
Validation loss: 3.487934773819509

Epoch: 6| Step: 7
Training loss: 3.618921379287327
Validation loss: 3.487602601571115

Epoch: 6| Step: 8
Training loss: 4.567317144098425
Validation loss: 3.48713019804574

Epoch: 6| Step: 9
Training loss: 3.6896498280842094
Validation loss: 3.48732270267813

Epoch: 6| Step: 10
Training loss: 4.323368695383347
Validation loss: 3.487102901736083

Epoch: 6| Step: 11
Training loss: 3.4505025304152936
Validation loss: 3.4861129516479914

Epoch: 6| Step: 12
Training loss: 3.6947418481984777
Validation loss: 3.4858610726494184

Epoch: 6| Step: 13
Training loss: 3.1046520766765338
Validation loss: 3.4858367008278677

Epoch: 32| Step: 0
Training loss: 3.561343624428129
Validation loss: 3.484895727322213

Epoch: 6| Step: 1
Training loss: 3.2051481975029708
Validation loss: 3.4850127191464924

Epoch: 6| Step: 2
Training loss: 3.545001505648316
Validation loss: 3.485014115350565

Epoch: 6| Step: 3
Training loss: 4.34498962717168
Validation loss: 3.485303884003403

Epoch: 6| Step: 4
Training loss: 4.4766737040343445
Validation loss: 3.484755847802423

Epoch: 6| Step: 5
Training loss: 3.9793926128263095
Validation loss: 3.483822743903579

Epoch: 6| Step: 6
Training loss: 4.032117883275958
Validation loss: 3.4838886271932714

Epoch: 6| Step: 7
Training loss: 3.3635180098685304
Validation loss: 3.4836269734357

Epoch: 6| Step: 8
Training loss: 3.2694990186116644
Validation loss: 3.484166136903515

Epoch: 6| Step: 9
Training loss: 3.9137035822057498
Validation loss: 3.4843853402624663

Epoch: 6| Step: 10
Training loss: 3.131257772531209
Validation loss: 3.483517499014676

Epoch: 6| Step: 11
Training loss: 3.782570474375292
Validation loss: 3.483607894145744

Epoch: 6| Step: 12
Training loss: 3.3993522026923335
Validation loss: 3.482730073460016

Epoch: 6| Step: 13
Training loss: 3.326335873819567
Validation loss: 3.4820815229297377

Epoch: 33| Step: 0
Training loss: 3.129574441224638
Validation loss: 3.4817494225385763

Epoch: 6| Step: 1
Training loss: 4.221178952094482
Validation loss: 3.4812827397443638

Epoch: 6| Step: 2
Training loss: 4.160550065720305
Validation loss: 3.481116590600031

Epoch: 6| Step: 3
Training loss: 4.082203663374425
Validation loss: 3.4804966632906873

Epoch: 6| Step: 4
Training loss: 3.9097175771272723
Validation loss: 3.4800502742398

Epoch: 6| Step: 5
Training loss: 3.6209286155206497
Validation loss: 3.4794958566916363

Epoch: 6| Step: 6
Training loss: 4.227950849985437
Validation loss: 3.4794487478082443

Epoch: 6| Step: 7
Training loss: 3.167321605882537
Validation loss: 3.4791121208086198

Epoch: 6| Step: 8
Training loss: 3.938782982477791
Validation loss: 3.478355685062406

Epoch: 6| Step: 9
Training loss: 4.021329279276105
Validation loss: 3.4781681804436393

Epoch: 6| Step: 10
Training loss: 2.857406689179145
Validation loss: 3.478334536757091

Epoch: 6| Step: 11
Training loss: 2.782127670506873
Validation loss: 3.477556941020343

Epoch: 6| Step: 12
Training loss: 3.886536437699688
Validation loss: 3.478586301882279

Epoch: 6| Step: 13
Training loss: 2.9473612411490446
Validation loss: 3.4777446274999724

Epoch: 34| Step: 0
Training loss: 3.9486085927869277
Validation loss: 3.4779240687779143

Epoch: 6| Step: 1
Training loss: 3.96064170319796
Validation loss: 3.4772429787143784

Epoch: 6| Step: 2
Training loss: 3.0147887340309345
Validation loss: 3.477473830038529

Epoch: 6| Step: 3
Training loss: 4.182447887399261
Validation loss: 3.476631320015499

Epoch: 6| Step: 4
Training loss: 4.018329110656907
Validation loss: 3.4772719264662446

Epoch: 6| Step: 5
Training loss: 4.142798202546376
Validation loss: 3.4764153901412493

Epoch: 6| Step: 6
Training loss: 3.443501868196382
Validation loss: 3.4764160007398175

Epoch: 6| Step: 7
Training loss: 4.177204285707278
Validation loss: 3.47637669360694

Epoch: 6| Step: 8
Training loss: 3.0358314106890023
Validation loss: 3.475674259746115

Epoch: 6| Step: 9
Training loss: 4.130913166390313
Validation loss: 3.476056065254641

Epoch: 6| Step: 10
Training loss: 3.67775537907239
Validation loss: 3.4741912604801355

Epoch: 6| Step: 11
Training loss: 3.5345455759239677
Validation loss: 3.4757014075688617

Epoch: 6| Step: 12
Training loss: 2.739822976735478
Validation loss: 3.474556661698693

Epoch: 6| Step: 13
Training loss: 2.9404645529421667
Validation loss: 3.4745278005249243

Epoch: 35| Step: 0
Training loss: 2.916132378460562
Validation loss: 3.473359384253837

Epoch: 6| Step: 1
Training loss: 4.81411577323402
Validation loss: 3.472800213414795

Epoch: 6| Step: 2
Training loss: 2.874876268460951
Validation loss: 3.473816278632407

Epoch: 6| Step: 3
Training loss: 2.9142410182731027
Validation loss: 3.4728801675451324

Epoch: 6| Step: 4
Training loss: 4.163679552630364
Validation loss: 3.472701881557642

Epoch: 6| Step: 5
Training loss: 2.883030994271172
Validation loss: 3.472557062117427

Epoch: 6| Step: 6
Training loss: 3.965965435544982
Validation loss: 3.472076630086518

Epoch: 6| Step: 7
Training loss: 3.4008675141701694
Validation loss: 3.4718401284493177

Epoch: 6| Step: 8
Training loss: 4.478281380158358
Validation loss: 3.4716404478470864

Epoch: 6| Step: 9
Training loss: 3.6252880639685627
Validation loss: 3.4706611309215925

Epoch: 6| Step: 10
Training loss: 3.720696332629955
Validation loss: 3.470941200515877

Epoch: 6| Step: 11
Training loss: 4.226275027047819
Validation loss: 3.4710814964173036

Epoch: 6| Step: 12
Training loss: 3.423704311571566
Validation loss: 3.473196616067646

Epoch: 6| Step: 13
Training loss: 3.465497390695453
Validation loss: 3.470266096387886

Epoch: 36| Step: 0
Training loss: 4.236171890128497
Validation loss: 3.470853799282136

Epoch: 6| Step: 1
Training loss: 3.525772031826527
Validation loss: 3.469886035021162

Epoch: 6| Step: 2
Training loss: 4.064280193266685
Validation loss: 3.469195386737126

Epoch: 6| Step: 3
Training loss: 3.635746646686763
Validation loss: 3.4685931633596305

Epoch: 6| Step: 4
Training loss: 4.1498984083127155
Validation loss: 3.468772962753413

Epoch: 6| Step: 5
Training loss: 3.5430192197256303
Validation loss: 3.4686391499182863

Epoch: 6| Step: 6
Training loss: 4.146854421856323
Validation loss: 3.4678196744511354

Epoch: 6| Step: 7
Training loss: 2.740655280786518
Validation loss: 3.4680862981701472

Epoch: 6| Step: 8
Training loss: 3.660512412217054
Validation loss: 3.467701378809571

Epoch: 6| Step: 9
Training loss: 3.483842749207905
Validation loss: 3.4674298790637326

Epoch: 6| Step: 10
Training loss: 3.964688362872581
Validation loss: 3.4668784760931586

Epoch: 6| Step: 11
Training loss: 3.3764300672128984
Validation loss: 3.466257221209121

Epoch: 6| Step: 12
Training loss: 3.3442661920854015
Validation loss: 3.4660708623788477

Epoch: 6| Step: 13
Training loss: 3.2797337979942163
Validation loss: 3.466698127344307

Epoch: 37| Step: 0
Training loss: 3.9920831058237893
Validation loss: 3.46494779328728

Epoch: 6| Step: 1
Training loss: 4.015961035535632
Validation loss: 3.467014853225009

Epoch: 6| Step: 2
Training loss: 3.038672571737531
Validation loss: 3.4656234377998025

Epoch: 6| Step: 3
Training loss: 3.6404060003202896
Validation loss: 3.4645121239128986

Epoch: 6| Step: 4
Training loss: 2.933080717248757
Validation loss: 3.4643402434820865

Epoch: 6| Step: 5
Training loss: 4.15737096828271
Validation loss: 3.466785093521742

Epoch: 6| Step: 6
Training loss: 4.316668720809467
Validation loss: 3.4648175411350133

Epoch: 6| Step: 7
Training loss: 2.7546359779529337
Validation loss: 3.464470703384094

Epoch: 6| Step: 8
Training loss: 4.24474054161441
Validation loss: 3.4641038234740185

Epoch: 6| Step: 9
Training loss: 3.652980549014666
Validation loss: 3.463061687560697

Epoch: 6| Step: 10
Training loss: 4.067317277945936
Validation loss: 3.462712741238115

Epoch: 6| Step: 11
Training loss: 2.805646387104957
Validation loss: 3.462521316867257

Epoch: 6| Step: 12
Training loss: 3.741202143074041
Validation loss: 3.461765795463763

Epoch: 6| Step: 13
Training loss: 3.699101705018702
Validation loss: 3.462307723494293

Epoch: 38| Step: 0
Training loss: 4.560161670696624
Validation loss: 3.462462925700434

Epoch: 6| Step: 1
Training loss: 2.6398985275360975
Validation loss: 3.462505134711096

Epoch: 6| Step: 2
Training loss: 3.7162223367851523
Validation loss: 3.461376313754753

Epoch: 6| Step: 3
Training loss: 3.364418679254472
Validation loss: 3.4615306349231916

Epoch: 6| Step: 4
Training loss: 3.838107549928654
Validation loss: 3.4603420852704443

Epoch: 6| Step: 5
Training loss: 3.795024279490368
Validation loss: 3.4599614976543482

Epoch: 6| Step: 6
Training loss: 4.699173696401855
Validation loss: 3.459507726612447

Epoch: 6| Step: 7
Training loss: 3.5503700278414256
Validation loss: 3.4621485690726566

Epoch: 6| Step: 8
Training loss: 3.0446689542268004
Validation loss: 3.4584745982901293

Epoch: 6| Step: 9
Training loss: 3.2204184050639006
Validation loss: 3.461973966168202

Epoch: 6| Step: 10
Training loss: 2.6386287750632054
Validation loss: 3.4611243544741694

Epoch: 6| Step: 11
Training loss: 4.068686601698611
Validation loss: 3.461731129739363

Epoch: 6| Step: 12
Training loss: 3.681711988491051
Validation loss: 3.462110627574861

Epoch: 6| Step: 13
Training loss: 4.342830423401975
Validation loss: 3.463336169376231

Epoch: 39| Step: 0
Training loss: 4.159075930739453
Validation loss: 3.4616190313998594

Epoch: 6| Step: 1
Training loss: 3.464647358486077
Validation loss: 3.463174395071495

Epoch: 6| Step: 2
Training loss: 2.8072194011684206
Validation loss: 3.4613715647550656

Epoch: 6| Step: 3
Training loss: 3.5495404550471883
Validation loss: 3.4622729062204654

Epoch: 6| Step: 4
Training loss: 3.075584796409422
Validation loss: 3.4618334285442995

Epoch: 6| Step: 5
Training loss: 4.224848429652837
Validation loss: 3.461931075324171

Epoch: 6| Step: 6
Training loss: 4.100165545215089
Validation loss: 3.4609062615448702

Epoch: 6| Step: 7
Training loss: 2.9735289005859062
Validation loss: 3.46063710152096

Epoch: 6| Step: 8
Training loss: 3.5292747171758783
Validation loss: 3.4600893127249557

Epoch: 6| Step: 9
Training loss: 3.8613231853787324
Validation loss: 3.4591360548010397

Epoch: 6| Step: 10
Training loss: 4.72618214992116
Validation loss: 3.4599511703496866

Epoch: 6| Step: 11
Training loss: 3.766456607148841
Validation loss: 3.4583219821317153

Epoch: 6| Step: 12
Training loss: 3.5744458069102243
Validation loss: 3.4582146941639764

Epoch: 6| Step: 13
Training loss: 2.7495495687408757
Validation loss: 3.4567017089663636

Epoch: 40| Step: 0
Training loss: 3.733970205162595
Validation loss: 3.456058351903249

Epoch: 6| Step: 1
Training loss: 3.5959407597330864
Validation loss: 3.45591759448695

Epoch: 6| Step: 2
Training loss: 2.8532544276952585
Validation loss: 3.4556278439830694

Epoch: 6| Step: 3
Training loss: 3.2616275249218947
Validation loss: 3.455721206087735

Epoch: 6| Step: 4
Training loss: 4.030545905081438
Validation loss: 3.4543011897368663

Epoch: 6| Step: 5
Training loss: 4.602564652386159
Validation loss: 3.453888306475784

Epoch: 6| Step: 6
Training loss: 3.4324934132645457
Validation loss: 3.4543685058687545

Epoch: 6| Step: 7
Training loss: 3.6314182682412137
Validation loss: 3.453782835921395

Epoch: 6| Step: 8
Training loss: 3.810127020092732
Validation loss: 3.4527329115702456

Epoch: 6| Step: 9
Training loss: 3.024867623955808
Validation loss: 3.452556008833469

Epoch: 6| Step: 10
Training loss: 3.702945753177673
Validation loss: 3.452492576531083

Epoch: 6| Step: 11
Training loss: 4.02068179673494
Validation loss: 3.450818826071136

Epoch: 6| Step: 12
Training loss: 4.040008021054001
Validation loss: 3.4520474944154014

Epoch: 6| Step: 13
Training loss: 3.0721493727508844
Validation loss: 3.4506217878931382

Epoch: 41| Step: 0
Training loss: 3.2798572309172536
Validation loss: 3.447255513998125

Epoch: 6| Step: 1
Training loss: 3.3370596720224635
Validation loss: 3.44841774811152

Epoch: 6| Step: 2
Training loss: 3.3667034323419065
Validation loss: 3.45135298009892

Epoch: 6| Step: 3
Training loss: 3.9388663933498234
Validation loss: 3.4579068165637503

Epoch: 6| Step: 4
Training loss: 4.385053581858663
Validation loss: 3.4346805439020107

Epoch: 6| Step: 5
Training loss: 3.254088104771554
Validation loss: 3.432455146206763

Epoch: 6| Step: 6
Training loss: 2.8287681564847427
Validation loss: 3.4346211748469027

Epoch: 6| Step: 7
Training loss: 4.231966241481962
Validation loss: 3.4405155084848045

Epoch: 6| Step: 8
Training loss: 3.7262031813799124
Validation loss: 3.4395461152139877

Epoch: 6| Step: 9
Training loss: 3.7691903231919515
Validation loss: 3.4335477286148333

Epoch: 6| Step: 10
Training loss: 3.2766911399085177
Validation loss: 3.432756637475761

Epoch: 6| Step: 11
Training loss: 3.6214434836503298
Validation loss: 3.433918856739122

Epoch: 6| Step: 12
Training loss: 4.347906964005942
Validation loss: 3.4335253784759643

Epoch: 6| Step: 13
Training loss: 3.425497706650676
Validation loss: 3.4307893239943925

Epoch: 42| Step: 0
Training loss: 3.6637424744054004
Validation loss: 3.432755245408796

Epoch: 6| Step: 1
Training loss: 2.644017134352667
Validation loss: 3.428914140119096

Epoch: 6| Step: 2
Training loss: 3.335169540739798
Validation loss: 3.428259223325494

Epoch: 6| Step: 3
Training loss: 3.874083625974024
Validation loss: 3.42710524922705

Epoch: 6| Step: 4
Training loss: 3.8910835945680984
Validation loss: 3.4255365468656795

Epoch: 6| Step: 5
Training loss: 3.0717651968470094
Validation loss: 3.4257040251878275

Epoch: 6| Step: 6
Training loss: 4.075833784119097
Validation loss: 3.424750397667035

Epoch: 6| Step: 7
Training loss: 4.356445203044439
Validation loss: 3.424476911317209

Epoch: 6| Step: 8
Training loss: 3.4310124994293205
Validation loss: 3.4231229843741264

Epoch: 6| Step: 9
Training loss: 3.8860009838972744
Validation loss: 3.4218685988994113

Epoch: 6| Step: 10
Training loss: 4.020159940052574
Validation loss: 3.422350919454212

Epoch: 6| Step: 11
Training loss: 4.174737641091742
Validation loss: 3.4219274999607086

Epoch: 6| Step: 12
Training loss: 2.8286865688465643
Validation loss: 3.4214935412268326

Epoch: 6| Step: 13
Training loss: 3.133133184520077
Validation loss: 3.4207475001241403

Epoch: 43| Step: 0
Training loss: 3.7087717261479987
Validation loss: 3.420554486478598

Epoch: 6| Step: 1
Training loss: 4.036086618679218
Validation loss: 3.4206842056912845

Epoch: 6| Step: 2
Training loss: 4.057072931872945
Validation loss: 3.419381139094552

Epoch: 6| Step: 3
Training loss: 3.7734660587849147
Validation loss: 3.419388150638942

Epoch: 6| Step: 4
Training loss: 2.5362427063033812
Validation loss: 3.4185737159330474

Epoch: 6| Step: 5
Training loss: 4.359133040300228
Validation loss: 3.418035256859435

Epoch: 6| Step: 6
Training loss: 2.8513133319007236
Validation loss: 3.4172720374066183

Epoch: 6| Step: 7
Training loss: 4.048719066985758
Validation loss: 3.416122231574539

Epoch: 6| Step: 8
Training loss: 3.41541729545952
Validation loss: 3.416923006607641

Epoch: 6| Step: 9
Training loss: 3.712800339389186
Validation loss: 3.4153517487096865

Epoch: 6| Step: 10
Training loss: 2.8126838623983574
Validation loss: 3.4159099937506032

Epoch: 6| Step: 11
Training loss: 3.1900980216246086
Validation loss: 3.415413351761134

Epoch: 6| Step: 12
Training loss: 4.011818116618708
Validation loss: 3.414530165378863

Epoch: 6| Step: 13
Training loss: 4.191659484209969
Validation loss: 3.4145543351542793

Epoch: 44| Step: 0
Training loss: 3.4836312770426274
Validation loss: 3.413862212428271

Epoch: 6| Step: 1
Training loss: 3.8747024421886813
Validation loss: 3.4130297877364213

Epoch: 6| Step: 2
Training loss: 2.9822528743763623
Validation loss: 3.412619508290405

Epoch: 6| Step: 3
Training loss: 3.8154858013134336
Validation loss: 3.414163459345158

Epoch: 6| Step: 4
Training loss: 2.587292826001817
Validation loss: 3.4132034964328017

Epoch: 6| Step: 5
Training loss: 4.443507895869467
Validation loss: 3.4137447437674826

Epoch: 6| Step: 6
Training loss: 3.5873637635417817
Validation loss: 3.416187990173618

Epoch: 6| Step: 7
Training loss: 3.3712879536054894
Validation loss: 3.414186466352686

Epoch: 6| Step: 8
Training loss: 3.720350417993716
Validation loss: 3.4134453089634453

Epoch: 6| Step: 9
Training loss: 3.6786405527760278
Validation loss: 3.4131068877035573

Epoch: 6| Step: 10
Training loss: 3.3109000318638575
Validation loss: 3.4162077311644237

Epoch: 6| Step: 11
Training loss: 3.6661857520794006
Validation loss: 3.4183971340729813

Epoch: 6| Step: 12
Training loss: 3.630578320046034
Validation loss: 3.4154309399902916

Epoch: 6| Step: 13
Training loss: 4.930988702269473
Validation loss: 3.4120245781645018

Epoch: 45| Step: 0
Training loss: 3.57421768271842
Validation loss: 3.414019327127024

Epoch: 6| Step: 1
Training loss: 2.2500423851259517
Validation loss: 3.41287063989227

Epoch: 6| Step: 2
Training loss: 3.4139300916472055
Validation loss: 3.4129219668442348

Epoch: 6| Step: 3
Training loss: 3.0342254193226434
Validation loss: 3.4114783191197247

Epoch: 6| Step: 4
Training loss: 4.1119425479868195
Validation loss: 3.4097146353690713

Epoch: 6| Step: 5
Training loss: 3.491547869449623
Validation loss: 3.4104426819904465

Epoch: 6| Step: 6
Training loss: 3.8431454314865774
Validation loss: 3.407922417538643

Epoch: 6| Step: 7
Training loss: 2.9483709266153477
Validation loss: 3.4096281925046186

Epoch: 6| Step: 8
Training loss: 4.583518746989468
Validation loss: 3.4077427492582113

Epoch: 6| Step: 9
Training loss: 4.834953738033672
Validation loss: 3.407770299831933

Epoch: 6| Step: 10
Training loss: 3.3396255868073883
Validation loss: 3.406591429339418

Epoch: 6| Step: 11
Training loss: 3.414460532164343
Validation loss: 3.4053398181447116

Epoch: 6| Step: 12
Training loss: 3.4523241314025195
Validation loss: 3.4056595554642883

Epoch: 6| Step: 13
Training loss: 3.986741862677651
Validation loss: 3.404580087671052

Epoch: 46| Step: 0
Training loss: 3.7180398214833232
Validation loss: 3.4039451566112713

Epoch: 6| Step: 1
Training loss: 4.0516484802750155
Validation loss: 3.4035253315697354

Epoch: 6| Step: 2
Training loss: 3.128699897124147
Validation loss: 3.4032980998150864

Epoch: 6| Step: 3
Training loss: 3.8675300215263007
Validation loss: 3.4024237548972964

Epoch: 6| Step: 4
Training loss: 3.526294032447023
Validation loss: 3.403007884334205

Epoch: 6| Step: 5
Training loss: 3.847900382879913
Validation loss: 3.401478935064362

Epoch: 6| Step: 6
Training loss: 4.0119578913326315
Validation loss: 3.4017362150022388

Epoch: 6| Step: 7
Training loss: 3.6252962188710245
Validation loss: 3.402777339245219

Epoch: 6| Step: 8
Training loss: 3.6534711923367977
Validation loss: 3.4010958836927623

Epoch: 6| Step: 9
Training loss: 4.0842146149530505
Validation loss: 3.400801892032052

Epoch: 6| Step: 10
Training loss: 3.2778645807471665
Validation loss: 3.4024059849006734

Epoch: 6| Step: 11
Training loss: 3.944974314481521
Validation loss: 3.400196990351239

Epoch: 6| Step: 12
Training loss: 3.0076409625395613
Validation loss: 3.3997184205524626

Epoch: 6| Step: 13
Training loss: 1.8892973344483106
Validation loss: 3.401217398129692

Epoch: 47| Step: 0
Training loss: 2.6708728182329344
Validation loss: 3.3984416278478826

Epoch: 6| Step: 1
Training loss: 3.1978841939430973
Validation loss: 3.399180875329867

Epoch: 6| Step: 2
Training loss: 4.649807357899483
Validation loss: 3.398942909852995

Epoch: 6| Step: 3
Training loss: 4.195005608101371
Validation loss: 3.3986313088174307

Epoch: 6| Step: 4
Training loss: 4.049758649628303
Validation loss: 3.3986706582175428

Epoch: 6| Step: 5
Training loss: 2.8545590059105623
Validation loss: 3.398158045410305

Epoch: 6| Step: 6
Training loss: 3.249943365924069
Validation loss: 3.398287850058737

Epoch: 6| Step: 7
Training loss: 3.4394473022203695
Validation loss: 3.3981651143245366

Epoch: 6| Step: 8
Training loss: 3.8256864293324684
Validation loss: 3.3978859240356654

Epoch: 6| Step: 9
Training loss: 3.2082591523020825
Validation loss: 3.39713147237208

Epoch: 6| Step: 10
Training loss: 3.0507046620308107
Validation loss: 3.3969716604444233

Epoch: 6| Step: 11
Training loss: 3.5401981375896963
Validation loss: 3.397056633042383

Epoch: 6| Step: 12
Training loss: 4.322862641636561
Validation loss: 3.396389131693617

Epoch: 6| Step: 13
Training loss: 4.125259853616894
Validation loss: 3.3964441080956855

Epoch: 48| Step: 0
Training loss: 3.056007041713331
Validation loss: 3.3956530324507375

Epoch: 6| Step: 1
Training loss: 3.004792200606099
Validation loss: 3.395923431870148

Epoch: 6| Step: 2
Training loss: 3.281958657896396
Validation loss: 3.395438640845629

Epoch: 6| Step: 3
Training loss: 3.987603170082653
Validation loss: 3.3954219381442616

Epoch: 6| Step: 4
Training loss: 3.664888789010579
Validation loss: 3.3962815441457623

Epoch: 6| Step: 5
Training loss: 3.2486044014701108
Validation loss: 3.3959291088419206

Epoch: 6| Step: 6
Training loss: 3.381869636211326
Validation loss: 3.395150799572243

Epoch: 6| Step: 7
Training loss: 2.9928618385858177
Validation loss: 3.395741174895442

Epoch: 6| Step: 8
Training loss: 4.248017690273311
Validation loss: 3.3948440353841565

Epoch: 6| Step: 9
Training loss: 3.8111192047606575
Validation loss: 3.393535719758239

Epoch: 6| Step: 10
Training loss: 3.557102062409436
Validation loss: 3.395306539123741

Epoch: 6| Step: 11
Training loss: 4.196353264686602
Validation loss: 3.3931462525023366

Epoch: 6| Step: 12
Training loss: 3.660185171560628
Validation loss: 3.3923108430480267

Epoch: 6| Step: 13
Training loss: 4.7286590214084026
Validation loss: 3.393036969409607

Epoch: 49| Step: 0
Training loss: 3.637924043773674
Validation loss: 3.3930089788443483

Epoch: 6| Step: 1
Training loss: 3.5897180910916586
Validation loss: 3.393068456441753

Epoch: 6| Step: 2
Training loss: 2.9495592337605148
Validation loss: 3.392179267954064

Epoch: 6| Step: 3
Training loss: 3.149227980210053
Validation loss: 3.392097978473479

Epoch: 6| Step: 4
Training loss: 3.49779441003374
Validation loss: 3.3908658974853316

Epoch: 6| Step: 5
Training loss: 3.954986736984295
Validation loss: 3.3912533459070597

Epoch: 6| Step: 6
Training loss: 4.113498721844841
Validation loss: 3.390244164421585

Epoch: 6| Step: 7
Training loss: 3.297296433835303
Validation loss: 3.390391243111259

Epoch: 6| Step: 8
Training loss: 3.0058793630548877
Validation loss: 3.390803293517723

Epoch: 6| Step: 9
Training loss: 3.70266579142821
Validation loss: 3.3904728623542266

Epoch: 6| Step: 10
Training loss: 4.252935181361262
Validation loss: 3.3902085768110837

Epoch: 6| Step: 11
Training loss: 3.8198239378774823
Validation loss: 3.389273655328468

Epoch: 6| Step: 12
Training loss: 3.8814692486005904
Validation loss: 3.389871980088586

Epoch: 6| Step: 13
Training loss: 3.5469281028771897
Validation loss: 3.390388968614581

Epoch: 50| Step: 0
Training loss: 2.839980089359604
Validation loss: 3.389177748725594

Epoch: 6| Step: 1
Training loss: 2.2416927841915113
Validation loss: 3.3887707659812576

Epoch: 6| Step: 2
Training loss: 4.232412411301141
Validation loss: 3.388994475392549

Epoch: 6| Step: 3
Training loss: 3.8970646399857856
Validation loss: 3.388577092248199

Epoch: 6| Step: 4
Training loss: 3.212760315081579
Validation loss: 3.3885787445611406

Epoch: 6| Step: 5
Training loss: 3.942353058316007
Validation loss: 3.388202884650845

Epoch: 6| Step: 6
Training loss: 3.6394585963453023
Validation loss: 3.3875957075149308

Epoch: 6| Step: 7
Training loss: 3.875792022487108
Validation loss: 3.3863226625627134

Epoch: 6| Step: 8
Training loss: 3.7068617111685644
Validation loss: 3.3870304539189484

Epoch: 6| Step: 9
Training loss: 3.673200392443472
Validation loss: 3.386916845985344

Epoch: 6| Step: 10
Training loss: 4.547571083087905
Validation loss: 3.385871465659459

Epoch: 6| Step: 11
Training loss: 3.622699138888478
Validation loss: 3.3865762672958675

Epoch: 6| Step: 12
Training loss: 3.1872352041322523
Validation loss: 3.3854419509789113

Epoch: 6| Step: 13
Training loss: 3.3058779761381447
Validation loss: 3.3851523781627506

Testing loss: 3.5707574219797213
