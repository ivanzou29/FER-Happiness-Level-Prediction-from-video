Epoch: 1| Step: 0
Training loss: 6.1279790990288765
Validation loss: 5.824418336818801

Epoch: 6| Step: 1
Training loss: 6.2000383437416895
Validation loss: 5.812898614918538

Epoch: 6| Step: 2
Training loss: 6.415122833146336
Validation loss: 5.802158806422768

Epoch: 6| Step: 3
Training loss: 4.846445428835214
Validation loss: 5.792454810292625

Epoch: 6| Step: 4
Training loss: 6.039203360865299
Validation loss: 5.783186130979614

Epoch: 6| Step: 5
Training loss: 6.296568453689056
Validation loss: 5.7741928702110155

Epoch: 6| Step: 6
Training loss: 5.2667034188127015
Validation loss: 5.764452933658212

Epoch: 6| Step: 7
Training loss: 5.310251994502444
Validation loss: 5.753988337152799

Epoch: 6| Step: 8
Training loss: 5.971592411080336
Validation loss: 5.742712889947972

Epoch: 6| Step: 9
Training loss: 5.649926460260138
Validation loss: 5.73031283759399

Epoch: 6| Step: 10
Training loss: 5.319836028017239
Validation loss: 5.716761214936574

Epoch: 6| Step: 11
Training loss: 4.975688959464597
Validation loss: 5.701685920697186

Epoch: 6| Step: 12
Training loss: 6.376121871070698
Validation loss: 5.686225457119148

Epoch: 6| Step: 13
Training loss: 6.062264034752262
Validation loss: 5.668909426497988

Epoch: 2| Step: 0
Training loss: 6.779357646119147
Validation loss: 5.6497430107526165

Epoch: 6| Step: 1
Training loss: 4.163612670649301
Validation loss: 5.629539486520724

Epoch: 6| Step: 2
Training loss: 5.270461399792168
Validation loss: 5.607353080729009

Epoch: 6| Step: 3
Training loss: 5.881365634863814
Validation loss: 5.584193995184465

Epoch: 6| Step: 4
Training loss: 6.824498800242529
Validation loss: 5.557912127517291

Epoch: 6| Step: 5
Training loss: 5.487210923490373
Validation loss: 5.530320790451482

Epoch: 6| Step: 6
Training loss: 5.273289205090817
Validation loss: 5.50074529958426

Epoch: 6| Step: 7
Training loss: 6.4860190639821464
Validation loss: 5.470587076534914

Epoch: 6| Step: 8
Training loss: 3.8026108606594207
Validation loss: 5.435707218236697

Epoch: 6| Step: 9
Training loss: 6.136902435486941
Validation loss: 5.401027721867578

Epoch: 6| Step: 10
Training loss: 5.758002641662013
Validation loss: 5.363752738512657

Epoch: 6| Step: 11
Training loss: 4.814245130522314
Validation loss: 5.324195042542197

Epoch: 6| Step: 12
Training loss: 5.099168201007208
Validation loss: 5.283888151420923

Epoch: 6| Step: 13
Training loss: 3.7228100835951956
Validation loss: 5.240741218280437

Epoch: 3| Step: 0
Training loss: 5.471969615874231
Validation loss: 5.198631941540253

Epoch: 6| Step: 1
Training loss: 5.423855026997112
Validation loss: 5.154475844885596

Epoch: 6| Step: 2
Training loss: 3.643365573397215
Validation loss: 5.108365677747202

Epoch: 6| Step: 3
Training loss: 4.034296821291805
Validation loss: 5.063211664220511

Epoch: 6| Step: 4
Training loss: 5.284413490628966
Validation loss: 5.0154630159310285

Epoch: 6| Step: 5
Training loss: 5.125124115720329
Validation loss: 4.9690322986685365

Epoch: 6| Step: 6
Training loss: 5.996491359984694
Validation loss: 4.917922837494641

Epoch: 6| Step: 7
Training loss: 4.522888466518538
Validation loss: 4.870608008648734

Epoch: 6| Step: 8
Training loss: 4.102912491744979
Validation loss: 4.818928635711779

Epoch: 6| Step: 9
Training loss: 4.917468614424757
Validation loss: 4.76941572615836

Epoch: 6| Step: 10
Training loss: 5.058500806035627
Validation loss: 4.723480750031137

Epoch: 6| Step: 11
Training loss: 5.368796383676234
Validation loss: 4.675561325051305

Epoch: 6| Step: 12
Training loss: 4.305905593808123
Validation loss: 4.628374590823303

Epoch: 6| Step: 13
Training loss: 6.070728813044872
Validation loss: 4.581498654591742

Epoch: 4| Step: 0
Training loss: 5.282380293479579
Validation loss: 4.5333037523074236

Epoch: 6| Step: 1
Training loss: 4.566443842071527
Validation loss: 4.488176872654555

Epoch: 6| Step: 2
Training loss: 4.410002280859671
Validation loss: 4.446225510262708

Epoch: 6| Step: 3
Training loss: 4.027659155023295
Validation loss: 4.403539105997533

Epoch: 6| Step: 4
Training loss: 3.84654543570467
Validation loss: 4.366124063596556

Epoch: 6| Step: 5
Training loss: 4.800499556295182
Validation loss: 4.332579887208461

Epoch: 6| Step: 6
Training loss: 4.506796472775477
Validation loss: 4.303346740341345

Epoch: 6| Step: 7
Training loss: 4.868850350478187
Validation loss: 4.2730067755684695

Epoch: 6| Step: 8
Training loss: 4.156812586748127
Validation loss: 4.245505610049046

Epoch: 6| Step: 9
Training loss: 4.054585420650255
Validation loss: 4.21776413665138

Epoch: 6| Step: 10
Training loss: 2.7663069924035373
Validation loss: 4.196807384177645

Epoch: 6| Step: 11
Training loss: 4.358508608462196
Validation loss: 4.178379289361333

Epoch: 6| Step: 12
Training loss: 4.939683262481774
Validation loss: 4.161280912220286

Epoch: 6| Step: 13
Training loss: 5.287781778677711
Validation loss: 4.144994362154946

Epoch: 5| Step: 0
Training loss: 4.417317228567893
Validation loss: 4.129951222731651

Epoch: 6| Step: 1
Training loss: 3.515175481244205
Validation loss: 4.112199023597628

Epoch: 6| Step: 2
Training loss: 4.318754663754718
Validation loss: 4.090328136272235

Epoch: 6| Step: 3
Training loss: 3.8190764941605337
Validation loss: 4.061509891888205

Epoch: 6| Step: 4
Training loss: 3.8553636221577876
Validation loss: 4.036916327187824

Epoch: 6| Step: 5
Training loss: 4.506316731841083
Validation loss: 4.011830457395475

Epoch: 6| Step: 6
Training loss: 4.73881176827036
Validation loss: 3.99021825774652

Epoch: 6| Step: 7
Training loss: 4.416924283173871
Validation loss: 3.968807910887161

Epoch: 6| Step: 8
Training loss: 3.717521015613211
Validation loss: 3.9526255003972057

Epoch: 6| Step: 9
Training loss: 3.7830122947321656
Validation loss: 3.9391449114506765

Epoch: 6| Step: 10
Training loss: 4.192889261389617
Validation loss: 3.923849042659285

Epoch: 6| Step: 11
Training loss: 4.109130852122293
Validation loss: 3.907602677630051

Epoch: 6| Step: 12
Training loss: 4.82328499471665
Validation loss: 3.8908560369179352

Epoch: 6| Step: 13
Training loss: 3.0477065296616703
Validation loss: 3.877735239054901

Epoch: 6| Step: 0
Training loss: 3.8294229603623817
Validation loss: 3.862202400838233

Epoch: 6| Step: 1
Training loss: 3.1708557295206736
Validation loss: 3.8491522809393177

Epoch: 6| Step: 2
Training loss: 4.358670522995211
Validation loss: 3.837677142804639

Epoch: 6| Step: 3
Training loss: 3.884831906957172
Validation loss: 3.8269860996691527

Epoch: 6| Step: 4
Training loss: 3.1764341764710964
Validation loss: 3.811507820980467

Epoch: 6| Step: 5
Training loss: 3.6952851437610565
Validation loss: 3.8014532160729235

Epoch: 6| Step: 6
Training loss: 3.610048305579265
Validation loss: 3.7943615095528385

Epoch: 6| Step: 7
Training loss: 4.73443281182473
Validation loss: 3.784334827345797

Epoch: 6| Step: 8
Training loss: 3.478869412148117
Validation loss: 3.7733939249487443

Epoch: 6| Step: 9
Training loss: 4.819462879058926
Validation loss: 3.766514584513622

Epoch: 6| Step: 10
Training loss: 4.244553610400333
Validation loss: 3.7575944532770365

Epoch: 6| Step: 11
Training loss: 4.079594256103613
Validation loss: 3.75021304000535

Epoch: 6| Step: 12
Training loss: 4.327576089473259
Validation loss: 3.7433625371988537

Epoch: 6| Step: 13
Training loss: 3.413192812838487
Validation loss: 3.740312147706779

Epoch: 7| Step: 0
Training loss: 4.007568827875106
Validation loss: 3.734381560168273

Epoch: 6| Step: 1
Training loss: 3.9277706742091305
Validation loss: 3.7267734939695494

Epoch: 6| Step: 2
Training loss: 3.403160584038666
Validation loss: 3.7126695685015743

Epoch: 6| Step: 3
Training loss: 4.421392946960343
Validation loss: 3.703852113999854

Epoch: 6| Step: 4
Training loss: 3.1800449929563204
Validation loss: 3.695222561925985

Epoch: 6| Step: 5
Training loss: 3.9058993983285437
Validation loss: 3.6888163841237946

Epoch: 6| Step: 6
Training loss: 4.527967434728945
Validation loss: 3.68040987282262

Epoch: 6| Step: 7
Training loss: 3.788083797571257
Validation loss: 3.6742810578874505

Epoch: 6| Step: 8
Training loss: 3.9498999184592924
Validation loss: 3.6622439043390362

Epoch: 6| Step: 9
Training loss: 3.926943721701166
Validation loss: 3.655317744568874

Epoch: 6| Step: 10
Training loss: 3.3708760532710356
Validation loss: 3.6566484302743505

Epoch: 6| Step: 11
Training loss: 3.55820487249861
Validation loss: 3.647289876557158

Epoch: 6| Step: 12
Training loss: 4.416161178356453
Validation loss: 3.643720597718224

Epoch: 6| Step: 13
Training loss: 3.159263607366837
Validation loss: 3.6271719983169763

Epoch: 8| Step: 0
Training loss: 4.2065465678035245
Validation loss: 3.6213355533168006

Epoch: 6| Step: 1
Training loss: 3.761775918528144
Validation loss: 3.6167827521412512

Epoch: 6| Step: 2
Training loss: 2.8557065350720343
Validation loss: 3.612213545683462

Epoch: 6| Step: 3
Training loss: 3.749302608492522
Validation loss: 3.606777009580726

Epoch: 6| Step: 4
Training loss: 3.5725672841126057
Validation loss: 3.6011533007565166

Epoch: 6| Step: 5
Training loss: 3.842792919065929
Validation loss: 3.592006816640396

Epoch: 6| Step: 6
Training loss: 4.377547040389207
Validation loss: 3.585773594833068

Epoch: 6| Step: 7
Training loss: 3.8151807271763767
Validation loss: 3.5754549731312015

Epoch: 6| Step: 8
Training loss: 3.5576465405476556
Validation loss: 3.5689310324654078

Epoch: 6| Step: 9
Training loss: 3.9087656694323227
Validation loss: 3.5668523382077066

Epoch: 6| Step: 10
Training loss: 3.1366362032355224
Validation loss: 3.5568991968122385

Epoch: 6| Step: 11
Training loss: 4.405229166155565
Validation loss: 3.550463830184738

Epoch: 6| Step: 12
Training loss: 4.136653737538
Validation loss: 3.5450754693127005

Epoch: 6| Step: 13
Training loss: 2.863806120889973
Validation loss: 3.537635649419585

Epoch: 9| Step: 0
Training loss: 4.318599423379559
Validation loss: 3.533688305162371

Epoch: 6| Step: 1
Training loss: 3.2039659838257797
Validation loss: 3.529078527487197

Epoch: 6| Step: 2
Training loss: 3.0607258854496946
Validation loss: 3.5228109502749336

Epoch: 6| Step: 3
Training loss: 3.2680425866759504
Validation loss: 3.5179321652398436

Epoch: 6| Step: 4
Training loss: 4.7669285726731605
Validation loss: 3.515946372963349

Epoch: 6| Step: 5
Training loss: 3.5608345288013465
Validation loss: 3.509636952887302

Epoch: 6| Step: 6
Training loss: 3.882297412624803
Validation loss: 3.5042979341970457

Epoch: 6| Step: 7
Training loss: 4.179231365662741
Validation loss: 3.498661651155313

Epoch: 6| Step: 8
Training loss: 4.514779298780752
Validation loss: 3.4932481050282607

Epoch: 6| Step: 9
Training loss: 4.466783210790206
Validation loss: 3.4883939246244693

Epoch: 6| Step: 10
Training loss: 3.252273937816672
Validation loss: 3.4880551004665605

Epoch: 6| Step: 11
Training loss: 2.4571258575225263
Validation loss: 3.47957403460472

Epoch: 6| Step: 12
Training loss: 2.4981311488606757
Validation loss: 3.474032380386691

Epoch: 6| Step: 13
Training loss: 3.6577305852622324
Validation loss: 3.4715674673228616

Epoch: 10| Step: 0
Training loss: 4.307014182707546
Validation loss: 3.4655105954083707

Epoch: 6| Step: 1
Training loss: 3.6304661546586647
Validation loss: 3.460079215486879

Epoch: 6| Step: 2
Training loss: 2.577223741617221
Validation loss: 3.4573570491441385

Epoch: 6| Step: 3
Training loss: 4.126172910453813
Validation loss: 3.4551504120810805

Epoch: 6| Step: 4
Training loss: 3.720739393483009
Validation loss: 3.453962460677999

Epoch: 6| Step: 5
Training loss: 2.8898348991462695
Validation loss: 3.444675967429244

Epoch: 6| Step: 6
Training loss: 3.825780282810144
Validation loss: 3.4395682667281093

Epoch: 6| Step: 7
Training loss: 3.486934252281842
Validation loss: 3.4406191668049737

Epoch: 6| Step: 8
Training loss: 3.267603516693782
Validation loss: 3.427796154892929

Epoch: 6| Step: 9
Training loss: 3.4386611364565938
Validation loss: 3.421308585110089

Epoch: 6| Step: 10
Training loss: 3.9410988240719202
Validation loss: 3.4166695639545233

Epoch: 6| Step: 11
Training loss: 4.381577696904811
Validation loss: 3.4122365617942685

Epoch: 6| Step: 12
Training loss: 3.4409462039980507
Validation loss: 3.407113358619549

Epoch: 6| Step: 13
Training loss: 3.7928572381989163
Validation loss: 3.4018896470072932

Epoch: 11| Step: 0
Training loss: 2.4286304394580913
Validation loss: 3.3973185068880305

Epoch: 6| Step: 1
Training loss: 3.5836331145987628
Validation loss: 3.4004589284413482

Epoch: 6| Step: 2
Training loss: 4.791463079135714
Validation loss: 3.396661992635052

Epoch: 6| Step: 3
Training loss: 2.5622385403364474
Validation loss: 3.3864853639167003

Epoch: 6| Step: 4
Training loss: 4.065828104538998
Validation loss: 3.388484230814536

Epoch: 6| Step: 5
Training loss: 4.023330835206258
Validation loss: 3.4036895756423307

Epoch: 6| Step: 6
Training loss: 2.9174905612403887
Validation loss: 3.3868807889337766

Epoch: 6| Step: 7
Training loss: 3.6836325844652293
Validation loss: 3.3763856978981157

Epoch: 6| Step: 8
Training loss: 3.6676694770249125
Validation loss: 3.363699474850239

Epoch: 6| Step: 9
Training loss: 4.259258507683975
Validation loss: 3.359082009315724

Epoch: 6| Step: 10
Training loss: 2.9383240213605433
Validation loss: 3.354824982684854

Epoch: 6| Step: 11
Training loss: 2.568547254297377
Validation loss: 3.357393871563952

Epoch: 6| Step: 12
Training loss: 3.7973044823647086
Validation loss: 3.3535381200305183

Epoch: 6| Step: 13
Training loss: 4.682464743510489
Validation loss: 3.346836971737415

Epoch: 12| Step: 0
Training loss: 4.562003121688959
Validation loss: 3.340181329545512

Epoch: 6| Step: 1
Training loss: 3.846560807338897
Validation loss: 3.336523694008241

Epoch: 6| Step: 2
Training loss: 3.84713943031243
Validation loss: 3.326437564379282

Epoch: 6| Step: 3
Training loss: 3.271503323172739
Validation loss: 3.320918058685444

Epoch: 6| Step: 4
Training loss: 3.1882534258637185
Validation loss: 3.3207810254606134

Epoch: 6| Step: 5
Training loss: 3.49756360403147
Validation loss: 3.3194351116066443

Epoch: 6| Step: 6
Training loss: 4.594147749308948
Validation loss: 3.320701767978395

Epoch: 6| Step: 7
Training loss: 3.030948584603468
Validation loss: 3.308871649710513

Epoch: 6| Step: 8
Training loss: 3.422440155598392
Validation loss: 3.305855104066333

Epoch: 6| Step: 9
Training loss: 3.3056994031991964
Validation loss: 3.303064766374038

Epoch: 6| Step: 10
Training loss: 3.302784617632332
Validation loss: 3.306453766060525

Epoch: 6| Step: 11
Training loss: 3.47989739760056
Validation loss: 3.2976187375599855

Epoch: 6| Step: 12
Training loss: 2.43746488496967
Validation loss: 3.2902184464280673

Epoch: 6| Step: 13
Training loss: 3.335308649973549
Validation loss: 3.2875810914877968

Epoch: 13| Step: 0
Training loss: 3.2990056244801345
Validation loss: 3.284806383251144

Epoch: 6| Step: 1
Training loss: 3.4277011271980844
Validation loss: 3.2811835716387123

Epoch: 6| Step: 2
Training loss: 2.8843044152514254
Validation loss: 3.27756156521714

Epoch: 6| Step: 3
Training loss: 3.558626712851588
Validation loss: 3.2727574810919124

Epoch: 6| Step: 4
Training loss: 3.7001313933678133
Validation loss: 3.2712861366800583

Epoch: 6| Step: 5
Training loss: 3.9937000731211465
Validation loss: 3.2689332082211107

Epoch: 6| Step: 6
Training loss: 3.4351140845398005
Validation loss: 3.269460917009273

Epoch: 6| Step: 7
Training loss: 3.9844087487081725
Validation loss: 3.2719089241030925

Epoch: 6| Step: 8
Training loss: 3.813325136038055
Validation loss: 3.259747959726293

Epoch: 6| Step: 9
Training loss: 3.4764205389291973
Validation loss: 3.2564773882958065

Epoch: 6| Step: 10
Training loss: 3.5929617639296616
Validation loss: 3.2533512711480137

Epoch: 6| Step: 11
Training loss: 3.2446425369470084
Validation loss: 3.2535866713124237

Epoch: 6| Step: 12
Training loss: 3.3701959963891044
Validation loss: 3.251632252148272

Epoch: 6| Step: 13
Training loss: 3.0764420454275605
Validation loss: 3.2484660381909944

Epoch: 14| Step: 0
Training loss: 3.3881834178308248
Validation loss: 3.2467282883878466

Epoch: 6| Step: 1
Training loss: 3.6434951405195064
Validation loss: 3.2477049189998644

Epoch: 6| Step: 2
Training loss: 3.6236639520403786
Validation loss: 3.2454591460036997

Epoch: 6| Step: 3
Training loss: 2.3178827684460828
Validation loss: 3.237378090008185

Epoch: 6| Step: 4
Training loss: 3.957598300081701
Validation loss: 3.2360699752955138

Epoch: 6| Step: 5
Training loss: 2.970309199412126
Validation loss: 3.2344269274989332

Epoch: 6| Step: 6
Training loss: 4.04938349799907
Validation loss: 3.236765969286965

Epoch: 6| Step: 7
Training loss: 3.0244230492581208
Validation loss: 3.2280631639310418

Epoch: 6| Step: 8
Training loss: 3.317319279270923
Validation loss: 3.227457737662529

Epoch: 6| Step: 9
Training loss: 3.277752856431033
Validation loss: 3.225118827236444

Epoch: 6| Step: 10
Training loss: 3.9003527261710325
Validation loss: 3.220284906512822

Epoch: 6| Step: 11
Training loss: 3.828589960004616
Validation loss: 3.216824796975486

Epoch: 6| Step: 12
Training loss: 3.7518961880765724
Validation loss: 3.215957824358442

Epoch: 6| Step: 13
Training loss: 3.2731780538871895
Validation loss: 3.2156044866319227

Epoch: 15| Step: 0
Training loss: 3.179952624465914
Validation loss: 3.21589287569378

Epoch: 6| Step: 1
Training loss: 3.5601600859577207
Validation loss: 3.211000008410389

Epoch: 6| Step: 2
Training loss: 3.616025668061564
Validation loss: 3.2093975143792375

Epoch: 6| Step: 3
Training loss: 3.4367258760795067
Validation loss: 3.2095255294060587

Epoch: 6| Step: 4
Training loss: 3.4570149739200184
Validation loss: 3.2062097725660115

Epoch: 6| Step: 5
Training loss: 3.932410932673263
Validation loss: 3.202512331239333

Epoch: 6| Step: 6
Training loss: 4.474431834035106
Validation loss: 3.202218116178508

Epoch: 6| Step: 7
Training loss: 2.8659785161833664
Validation loss: 3.199591625533155

Epoch: 6| Step: 8
Training loss: 3.070689248613062
Validation loss: 3.1991233530492966

Epoch: 6| Step: 9
Training loss: 2.7071733974110157
Validation loss: 3.1948841051599546

Epoch: 6| Step: 10
Training loss: 3.8702057744797504
Validation loss: 3.194017224117103

Epoch: 6| Step: 11
Training loss: 3.4452394231195584
Validation loss: 3.195173935942484

Epoch: 6| Step: 12
Training loss: 3.0182982934118185
Validation loss: 3.1902976147895115

Epoch: 6| Step: 13
Training loss: 3.4794971210146053
Validation loss: 3.1888305618305535

Epoch: 16| Step: 0
Training loss: 4.114773181768631
Validation loss: 3.1868469659937606

Epoch: 6| Step: 1
Training loss: 3.2440177439476
Validation loss: 3.184627564959573

Epoch: 6| Step: 2
Training loss: 2.900657276778679
Validation loss: 3.1843696679933458

Epoch: 6| Step: 3
Training loss: 4.378180955070473
Validation loss: 3.185135888173706

Epoch: 6| Step: 4
Training loss: 3.5668439648730046
Validation loss: 3.180747812075222

Epoch: 6| Step: 5
Training loss: 3.16609936367513
Validation loss: 3.179313730217618

Epoch: 6| Step: 6
Training loss: 3.4017825446670122
Validation loss: 3.179742262822888

Epoch: 6| Step: 7
Training loss: 3.152575780939362
Validation loss: 3.1796981635177795

Epoch: 6| Step: 8
Training loss: 3.0741568611245778
Validation loss: 3.183088767740869

Epoch: 6| Step: 9
Training loss: 3.5265409415705418
Validation loss: 3.1855553862629646

Epoch: 6| Step: 10
Training loss: 3.1929850040971317
Validation loss: 3.185054741113396

Epoch: 6| Step: 11
Training loss: 3.4213574161747364
Validation loss: 3.1782939689516345

Epoch: 6| Step: 12
Training loss: 3.3155499218809634
Validation loss: 3.176526492317436

Epoch: 6| Step: 13
Training loss: 3.5538396138509913
Validation loss: 3.1732880763394853

Epoch: 17| Step: 0
Training loss: 4.522796954458576
Validation loss: 3.171068340419072

Epoch: 6| Step: 1
Training loss: 2.879364349895345
Validation loss: 3.169750013223981

Epoch: 6| Step: 2
Training loss: 3.3214281788252964
Validation loss: 3.1683197974078743

Epoch: 6| Step: 3
Training loss: 4.469523756357335
Validation loss: 3.170372896273103

Epoch: 6| Step: 4
Training loss: 2.412442351922399
Validation loss: 3.1662120571029475

Epoch: 6| Step: 5
Training loss: 3.5510452558447656
Validation loss: 3.1629519692352224

Epoch: 6| Step: 6
Training loss: 3.466081847477507
Validation loss: 3.1622957272510748

Epoch: 6| Step: 7
Training loss: 3.1571357919309406
Validation loss: 3.1604564102404513

Epoch: 6| Step: 8
Training loss: 3.8541711480741823
Validation loss: 3.161072099736678

Epoch: 6| Step: 9
Training loss: 2.965193857220954
Validation loss: 3.160179414021216

Epoch: 6| Step: 10
Training loss: 3.136732127539967
Validation loss: 3.157591516899521

Epoch: 6| Step: 11
Training loss: 3.1465125624319366
Validation loss: 3.1612342780350877

Epoch: 6| Step: 12
Training loss: 3.0217280323539497
Validation loss: 3.165342799547271

Epoch: 6| Step: 13
Training loss: 3.5274979905109913
Validation loss: 3.1667920070533424

Epoch: 18| Step: 0
Training loss: 3.2030094777186453
Validation loss: 3.2081383857794523

Epoch: 6| Step: 1
Training loss: 4.032051893808565
Validation loss: 3.156057320432432

Epoch: 6| Step: 2
Training loss: 3.2647943489771727
Validation loss: 3.1523299588920364

Epoch: 6| Step: 3
Training loss: 3.5331237682837715
Validation loss: 3.1486271903592193

Epoch: 6| Step: 4
Training loss: 3.653869114544962
Validation loss: 3.148970337961481

Epoch: 6| Step: 5
Training loss: 2.970647907935224
Validation loss: 3.1498502643973625

Epoch: 6| Step: 6
Training loss: 3.7246995023836003
Validation loss: 3.1493403827366437

Epoch: 6| Step: 7
Training loss: 2.2712071545621564
Validation loss: 3.1525320326822395

Epoch: 6| Step: 8
Training loss: 3.4303667442951653
Validation loss: 3.150745323332726

Epoch: 6| Step: 9
Training loss: 2.9174823891860835
Validation loss: 3.147682981576842

Epoch: 6| Step: 10
Training loss: 3.40273362388423
Validation loss: 3.1469415463278567

Epoch: 6| Step: 11
Training loss: 3.726762618283744
Validation loss: 3.1443036820930064

Epoch: 6| Step: 12
Training loss: 3.2600409115523563
Validation loss: 3.142173935710641

Epoch: 6| Step: 13
Training loss: 4.543379760937842
Validation loss: 3.141490961580176

Epoch: 19| Step: 0
Training loss: 3.4495225990706344
Validation loss: 3.1409612663466917

Epoch: 6| Step: 1
Training loss: 2.253551223799036
Validation loss: 3.1392945310245457

Epoch: 6| Step: 2
Training loss: 4.437520201731084
Validation loss: 3.139271688996699

Epoch: 6| Step: 3
Training loss: 3.060647209387588
Validation loss: 3.136744082932466

Epoch: 6| Step: 4
Training loss: 3.2549433160349484
Validation loss: 3.1367499069607345

Epoch: 6| Step: 5
Training loss: 3.540462393869245
Validation loss: 3.140686870421217

Epoch: 6| Step: 6
Training loss: 3.7173618322271533
Validation loss: 3.135586740344567

Epoch: 6| Step: 7
Training loss: 3.1248646516099456
Validation loss: 3.132073693224513

Epoch: 6| Step: 8
Training loss: 3.5321554187869224
Validation loss: 3.1308904035788085

Epoch: 6| Step: 9
Training loss: 4.085678880139883
Validation loss: 3.131007880982568

Epoch: 6| Step: 10
Training loss: 3.076613931531125
Validation loss: 3.1305647986218217

Epoch: 6| Step: 11
Training loss: 3.178777991084241
Validation loss: 3.1304457436951223

Epoch: 6| Step: 12
Training loss: 3.240861221576686
Validation loss: 3.129032789715966

Epoch: 6| Step: 13
Training loss: 3.150636723668149
Validation loss: 3.127744376129891

Epoch: 20| Step: 0
Training loss: 3.5598070105201542
Validation loss: 3.126539234378341

Epoch: 6| Step: 1
Training loss: 3.8861324002204887
Validation loss: 3.1258114882986225

Epoch: 6| Step: 2
Training loss: 3.43004423819171
Validation loss: 3.123437064857688

Epoch: 6| Step: 3
Training loss: 2.7202962227410508
Validation loss: 3.124179758692242

Epoch: 6| Step: 4
Training loss: 3.1427152898903437
Validation loss: 3.123622725325285

Epoch: 6| Step: 5
Training loss: 3.4320660730684116
Validation loss: 3.1214540606176073

Epoch: 6| Step: 6
Training loss: 3.5773353205004828
Validation loss: 3.1219063768410646

Epoch: 6| Step: 7
Training loss: 2.2462784400969387
Validation loss: 3.1211297431786393

Epoch: 6| Step: 8
Training loss: 3.3959031049117434
Validation loss: 3.119649488008812

Epoch: 6| Step: 9
Training loss: 3.5654613835125653
Validation loss: 3.1177129087574924

Epoch: 6| Step: 10
Training loss: 3.224881156683366
Validation loss: 3.1161835339490986

Epoch: 6| Step: 11
Training loss: 3.754885098341307
Validation loss: 3.1154957089777158

Epoch: 6| Step: 12
Training loss: 3.863498970893574
Validation loss: 3.1149016538072516

Epoch: 6| Step: 13
Training loss: 3.2976680723772325
Validation loss: 3.116091773489935

Epoch: 21| Step: 0
Training loss: 3.5305261460813546
Validation loss: 3.114596726380549

Epoch: 6| Step: 1
Training loss: 3.5276331650804464
Validation loss: 3.1130435331139363

Epoch: 6| Step: 2
Training loss: 3.6757477810478143
Validation loss: 3.12356639013518

Epoch: 6| Step: 3
Training loss: 3.019409019295939
Validation loss: 3.1228263596689336

Epoch: 6| Step: 4
Training loss: 3.135611864944085
Validation loss: 3.1157156603195593

Epoch: 6| Step: 5
Training loss: 2.6475257767096974
Validation loss: 3.108028830138047

Epoch: 6| Step: 6
Training loss: 2.802239414864514
Validation loss: 3.1218812010663854

Epoch: 6| Step: 7
Training loss: 3.1381521026042685
Validation loss: 3.1417327430870063

Epoch: 6| Step: 8
Training loss: 3.4839449903698037
Validation loss: 3.136178234297118

Epoch: 6| Step: 9
Training loss: 3.370906466589386
Validation loss: 3.1029899182534004

Epoch: 6| Step: 10
Training loss: 3.9268960005839033
Validation loss: 3.1178650585464616

Epoch: 6| Step: 11
Training loss: 4.141089992684854
Validation loss: 3.1025664890632605

Epoch: 6| Step: 12
Training loss: 3.612333860173835
Validation loss: 3.1017339362562666

Epoch: 6| Step: 13
Training loss: 2.9153285817281245
Validation loss: 3.1002559160603678

Epoch: 22| Step: 0
Training loss: 3.182183413165309
Validation loss: 3.0996543499056224

Epoch: 6| Step: 1
Training loss: 3.880139541869581
Validation loss: 3.0959541322296658

Epoch: 6| Step: 2
Training loss: 3.1366190247223202
Validation loss: 3.0940957363561985

Epoch: 6| Step: 3
Training loss: 3.5503001878644285
Validation loss: 3.0953337161482013

Epoch: 6| Step: 4
Training loss: 3.84628857156569
Validation loss: 3.0901931596869323

Epoch: 6| Step: 5
Training loss: 4.09397456594225
Validation loss: 3.0864474283236247

Epoch: 6| Step: 6
Training loss: 3.018999020748479
Validation loss: 3.0871128156190797

Epoch: 6| Step: 7
Training loss: 2.898059912915897
Validation loss: 3.0827976671663095

Epoch: 6| Step: 8
Training loss: 3.0023190753686166
Validation loss: 3.0795502412105384

Epoch: 6| Step: 9
Training loss: 3.149289756510027
Validation loss: 3.081961724685446

Epoch: 6| Step: 10
Training loss: 3.0405489466095617
Validation loss: 3.0852057598127325

Epoch: 6| Step: 11
Training loss: 3.403995012479147
Validation loss: 3.0752993062430014

Epoch: 6| Step: 12
Training loss: 2.9544663385322263
Validation loss: 3.076646960388277

Epoch: 6| Step: 13
Training loss: 3.9402164595344047
Validation loss: 3.073412292344731

Epoch: 23| Step: 0
Training loss: 3.2244635675507194
Validation loss: 3.0737772931335754

Epoch: 6| Step: 1
Training loss: 3.60350715615536
Validation loss: 3.06973953701931

Epoch: 6| Step: 2
Training loss: 3.978543910214868
Validation loss: 3.070798378984487

Epoch: 6| Step: 3
Training loss: 3.661660779816021
Validation loss: 3.0659107772277974

Epoch: 6| Step: 4
Training loss: 3.3612762039315083
Validation loss: 3.0679104785381277

Epoch: 6| Step: 5
Training loss: 4.026017215682477
Validation loss: 3.0689167690239096

Epoch: 6| Step: 6
Training loss: 2.331310371660374
Validation loss: 3.0672352462590418

Epoch: 6| Step: 7
Training loss: 2.89904844523464
Validation loss: 3.069823362344665

Epoch: 6| Step: 8
Training loss: 3.325026811764109
Validation loss: 3.0731600996439465

Epoch: 6| Step: 9
Training loss: 3.6846024071786654
Validation loss: 3.071948263679841

Epoch: 6| Step: 10
Training loss: 2.72577531266707
Validation loss: 3.0652020295612052

Epoch: 6| Step: 11
Training loss: 3.042695764091011
Validation loss: 3.0630570960361303

Epoch: 6| Step: 12
Training loss: 3.4710333929453063
Validation loss: 3.059447437422517

Epoch: 6| Step: 13
Training loss: 3.025460919030852
Validation loss: 3.059086500946203

Epoch: 24| Step: 0
Training loss: 3.844921646808004
Validation loss: 3.0570011860765685

Epoch: 6| Step: 1
Training loss: 3.0747249821439824
Validation loss: 3.0570391313976493

Epoch: 6| Step: 2
Training loss: 3.717880275544942
Validation loss: 3.0562479903902795

Epoch: 6| Step: 3
Training loss: 3.6143762857170003
Validation loss: 3.055314585586126

Epoch: 6| Step: 4
Training loss: 3.9217625332090575
Validation loss: 3.054994343062483

Epoch: 6| Step: 5
Training loss: 3.040879204249795
Validation loss: 3.056255050726474

Epoch: 6| Step: 6
Training loss: 3.250622029566274
Validation loss: 3.058950379907808

Epoch: 6| Step: 7
Training loss: 3.4915253354939293
Validation loss: 3.0621193772120194

Epoch: 6| Step: 8
Training loss: 2.1577531302293145
Validation loss: 3.057212799363688

Epoch: 6| Step: 9
Training loss: 3.7135743099167193
Validation loss: 3.057873235046497

Epoch: 6| Step: 10
Training loss: 2.9779305905976035
Validation loss: 3.059187541909474

Epoch: 6| Step: 11
Training loss: 3.3812112520433892
Validation loss: 3.053081878422413

Epoch: 6| Step: 12
Training loss: 2.731856139638741
Validation loss: 3.05464829511336

Epoch: 6| Step: 13
Training loss: 3.474013725117488
Validation loss: 3.051371117133528

Epoch: 25| Step: 0
Training loss: 2.6124375696343094
Validation loss: 3.047150934733165

Epoch: 6| Step: 1
Training loss: 3.129312819832053
Validation loss: 3.0461408136000423

Epoch: 6| Step: 2
Training loss: 3.374844582829253
Validation loss: 3.0432608895428532

Epoch: 6| Step: 3
Training loss: 3.111514175130194
Validation loss: 3.0432428773091744

Epoch: 6| Step: 4
Training loss: 3.1617661420033505
Validation loss: 3.0404038293417943

Epoch: 6| Step: 5
Training loss: 3.259125296371517
Validation loss: 3.039299833083734

Epoch: 6| Step: 6
Training loss: 3.2952958071753
Validation loss: 3.0397990150132914

Epoch: 6| Step: 7
Training loss: 3.7349218502831043
Validation loss: 3.038003414463295

Epoch: 6| Step: 8
Training loss: 3.5681092122901843
Validation loss: 3.0375126601299316

Epoch: 6| Step: 9
Training loss: 3.1759473093307937
Validation loss: 3.0357679471072716

Epoch: 6| Step: 10
Training loss: 3.5136137910360317
Validation loss: 3.0347074921605137

Epoch: 6| Step: 11
Training loss: 3.9636055351789206
Validation loss: 3.035446643207661

Epoch: 6| Step: 12
Training loss: 3.090753510583397
Validation loss: 3.035461065013953

Epoch: 6| Step: 13
Training loss: 3.4137416662661315
Validation loss: 3.0308993201918497

Epoch: 26| Step: 0
Training loss: 3.124720293878802
Validation loss: 3.0371833852658177

Epoch: 6| Step: 1
Training loss: 3.185090145110953
Validation loss: 3.037570967698286

Epoch: 6| Step: 2
Training loss: 2.760970514744512
Validation loss: 3.0413292009161084

Epoch: 6| Step: 3
Training loss: 4.140621545178393
Validation loss: 3.0412426724815216

Epoch: 6| Step: 4
Training loss: 3.508395615943794
Validation loss: 3.033124516849771

Epoch: 6| Step: 5
Training loss: 3.1999670325011533
Validation loss: 3.0251416440918155

Epoch: 6| Step: 6
Training loss: 3.675086122917973
Validation loss: 3.0185332622821304

Epoch: 6| Step: 7
Training loss: 3.419627945499997
Validation loss: 3.017503499641091

Epoch: 6| Step: 8
Training loss: 3.1438454585058366
Validation loss: 3.0187891616952807

Epoch: 6| Step: 9
Training loss: 3.3035680439464064
Validation loss: 3.0247592714643003

Epoch: 6| Step: 10
Training loss: 3.261373280029732
Validation loss: 3.0317215378830387

Epoch: 6| Step: 11
Training loss: 2.8304447334148772
Validation loss: 3.012827846106046

Epoch: 6| Step: 12
Training loss: 3.474186803500594
Validation loss: 3.008222240362108

Epoch: 6| Step: 13
Training loss: 2.7750918330213254
Validation loss: 3.0051176274618974

Epoch: 27| Step: 0
Training loss: 3.3971569235566736
Validation loss: 3.012206899757549

Epoch: 6| Step: 1
Training loss: 3.7304911188383674
Validation loss: 3.0140289634621995

Epoch: 6| Step: 2
Training loss: 2.9966987884236946
Validation loss: 3.0032888334003

Epoch: 6| Step: 3
Training loss: 2.665787571805136
Validation loss: 3.0056155281097703

Epoch: 6| Step: 4
Training loss: 3.2716528641313563
Validation loss: 3.001719481932718

Epoch: 6| Step: 5
Training loss: 3.2631031867267946
Validation loss: 3.003625405341689

Epoch: 6| Step: 6
Training loss: 3.6544631112810357
Validation loss: 3.0059113252443375

Epoch: 6| Step: 7
Training loss: 3.384642214101879
Validation loss: 3.014913112889218

Epoch: 6| Step: 8
Training loss: 3.1510568329417215
Validation loss: 3.026653724704358

Epoch: 6| Step: 9
Training loss: 3.7801426298490317
Validation loss: 3.015696926025355

Epoch: 6| Step: 10
Training loss: 2.6627102549459702
Validation loss: 2.9975100938169534

Epoch: 6| Step: 11
Training loss: 3.5903054356611346
Validation loss: 2.9932810973107857

Epoch: 6| Step: 12
Training loss: 2.983042154718262
Validation loss: 2.992157785075381

Epoch: 6| Step: 13
Training loss: 3.4317748510850823
Validation loss: 2.9948291549726016

Epoch: 28| Step: 0
Training loss: 3.535174863987597
Validation loss: 2.998578690290767

Epoch: 6| Step: 1
Training loss: 3.3088432136897574
Validation loss: 2.9993314203135246

Epoch: 6| Step: 2
Training loss: 2.8936349405108643
Validation loss: 2.999130162229636

Epoch: 6| Step: 3
Training loss: 3.265482922251338
Validation loss: 2.9986883068037153

Epoch: 6| Step: 4
Training loss: 2.4116938059276523
Validation loss: 2.991451303412539

Epoch: 6| Step: 5
Training loss: 3.00488122562519
Validation loss: 2.988045619012615

Epoch: 6| Step: 6
Training loss: 2.81676380358654
Validation loss: 2.9867171756541238

Epoch: 6| Step: 7
Training loss: 3.528610458290547
Validation loss: 2.985394143675219

Epoch: 6| Step: 8
Training loss: 2.8175300546446143
Validation loss: 2.983324490197965

Epoch: 6| Step: 9
Training loss: 4.097748412631339
Validation loss: 2.9819068488980958

Epoch: 6| Step: 10
Training loss: 3.159782019714236
Validation loss: 2.9824183231988606

Epoch: 6| Step: 11
Training loss: 3.181185882461824
Validation loss: 2.9832670748097807

Epoch: 6| Step: 12
Training loss: 3.6937288596747253
Validation loss: 2.990567836763143

Epoch: 6| Step: 13
Training loss: 4.098622225497108
Validation loss: 2.9986255908769026

Epoch: 29| Step: 0
Training loss: 3.6043527514685687
Validation loss: 2.9836759877709222

Epoch: 6| Step: 1
Training loss: 2.259369310131796
Validation loss: 2.9802175163376483

Epoch: 6| Step: 2
Training loss: 3.357477832303466
Validation loss: 2.9819641959076693

Epoch: 6| Step: 3
Training loss: 2.563071210511204
Validation loss: 2.9808583624301095

Epoch: 6| Step: 4
Training loss: 3.820548894702373
Validation loss: 2.9792332698078487

Epoch: 6| Step: 5
Training loss: 3.5739743341977017
Validation loss: 2.974570009285133

Epoch: 6| Step: 6
Training loss: 3.630987549848967
Validation loss: 2.973788697701315

Epoch: 6| Step: 7
Training loss: 2.8089913417075687
Validation loss: 2.974360087356208

Epoch: 6| Step: 8
Training loss: 3.3576793560827336
Validation loss: 2.97456560866295

Epoch: 6| Step: 9
Training loss: 3.835567914946048
Validation loss: 2.9763988169630338

Epoch: 6| Step: 10
Training loss: 2.86954345368185
Validation loss: 2.9696999619444693

Epoch: 6| Step: 11
Training loss: 3.5021325835048405
Validation loss: 2.9718245073214176

Epoch: 6| Step: 12
Training loss: 2.774851951430194
Validation loss: 2.9684739196590413

Epoch: 6| Step: 13
Training loss: 3.279257032869194
Validation loss: 2.9685330806598906

Epoch: 30| Step: 0
Training loss: 3.863968559508427
Validation loss: 2.9670540024342773

Epoch: 6| Step: 1
Training loss: 2.803361329457863
Validation loss: 2.966465974771091

Epoch: 6| Step: 2
Training loss: 3.510522012610858
Validation loss: 2.9669522967748265

Epoch: 6| Step: 3
Training loss: 3.8986214573331077
Validation loss: 2.967420224701007

Epoch: 6| Step: 4
Training loss: 3.0731995188390835
Validation loss: 2.9649307372457265

Epoch: 6| Step: 5
Training loss: 2.970563956768553
Validation loss: 2.967081374959563

Epoch: 6| Step: 6
Training loss: 2.6968465226704317
Validation loss: 2.9715450235958705

Epoch: 6| Step: 7
Training loss: 2.8223656448539676
Validation loss: 2.9691040631022885

Epoch: 6| Step: 8
Training loss: 3.267336894067322
Validation loss: 2.9627735595756577

Epoch: 6| Step: 9
Training loss: 3.227186239697951
Validation loss: 2.9626845170501532

Epoch: 6| Step: 10
Training loss: 3.36528807700731
Validation loss: 2.9642405986679647

Epoch: 6| Step: 11
Training loss: 2.2291668568073324
Validation loss: 2.961297423984035

Epoch: 6| Step: 12
Training loss: 3.890365775790986
Validation loss: 2.9598179658902124

Epoch: 6| Step: 13
Training loss: 3.625298454889463
Validation loss: 2.95789518033452

Epoch: 31| Step: 0
Training loss: 3.6689091818489814
Validation loss: 2.954433052721023

Epoch: 6| Step: 1
Training loss: 3.714978782213288
Validation loss: 2.955354495594387

Epoch: 6| Step: 2
Training loss: 2.970652402385843
Validation loss: 2.957256648669151

Epoch: 6| Step: 3
Training loss: 3.1173104857082556
Validation loss: 2.954254958582879

Epoch: 6| Step: 4
Training loss: 2.9732683030388407
Validation loss: 2.957077946064388

Epoch: 6| Step: 5
Training loss: 2.891698194729501
Validation loss: 2.9611005615613575

Epoch: 6| Step: 6
Training loss: 2.9576853906692344
Validation loss: 2.9591146969931947

Epoch: 6| Step: 7
Training loss: 3.6429857450379632
Validation loss: 2.956108510325858

Epoch: 6| Step: 8
Training loss: 2.786564068555845
Validation loss: 2.9533394694803334

Epoch: 6| Step: 9
Training loss: 3.3741831320746143
Validation loss: 2.9488970233274627

Epoch: 6| Step: 10
Training loss: 2.5583889245901084
Validation loss: 2.9485997277898783

Epoch: 6| Step: 11
Training loss: 2.702888963570211
Validation loss: 2.9492337221122664

Epoch: 6| Step: 12
Training loss: 3.8364508570856226
Validation loss: 2.957559062800137

Epoch: 6| Step: 13
Training loss: 4.290661123058404
Validation loss: 2.971802353556822

Epoch: 32| Step: 0
Training loss: 3.436836317322999
Validation loss: 2.967526716736516

Epoch: 6| Step: 1
Training loss: 3.0362862504952144
Validation loss: 2.9518460144650165

Epoch: 6| Step: 2
Training loss: 3.06348418945297
Validation loss: 2.940598706495368

Epoch: 6| Step: 3
Training loss: 3.3696123141278393
Validation loss: 2.9352926322752935

Epoch: 6| Step: 4
Training loss: 2.73512048640728
Validation loss: 2.936908490441621

Epoch: 6| Step: 5
Training loss: 3.67397673497442
Validation loss: 2.9357366529678637

Epoch: 6| Step: 6
Training loss: 3.8099152605139874
Validation loss: 2.9347556670950357

Epoch: 6| Step: 7
Training loss: 2.7904205008116785
Validation loss: 2.937709885506096

Epoch: 6| Step: 8
Training loss: 3.1639687606677542
Validation loss: 2.940258952461673

Epoch: 6| Step: 9
Training loss: 3.1621111845655725
Validation loss: 2.996460265381899

Epoch: 6| Step: 10
Training loss: 3.1361379881492604
Validation loss: 3.0073794337228454

Epoch: 6| Step: 11
Training loss: 3.4759121747351682
Validation loss: 3.0019776019872393

Epoch: 6| Step: 12
Training loss: 3.3080636312506626
Validation loss: 2.9387186507737337

Epoch: 6| Step: 13
Training loss: 2.9785204277625215
Validation loss: 2.9310354315748666

Epoch: 33| Step: 0
Training loss: 2.717386188668121
Validation loss: 2.928914208960817

Epoch: 6| Step: 1
Training loss: 3.5019866209880215
Validation loss: 2.92846162783912

Epoch: 6| Step: 2
Training loss: 2.7093710647431233
Validation loss: 2.9286915117175045

Epoch: 6| Step: 3
Training loss: 3.3698668827740343
Validation loss: 2.931566633154957

Epoch: 6| Step: 4
Training loss: 3.0898295521560657
Validation loss: 2.9272205009868477

Epoch: 6| Step: 5
Training loss: 4.057083509767159
Validation loss: 2.9282109600678816

Epoch: 6| Step: 6
Training loss: 3.2938014162165596
Validation loss: 2.9271097705709703

Epoch: 6| Step: 7
Training loss: 3.2976414661848783
Validation loss: 2.925542160677608

Epoch: 6| Step: 8
Training loss: 2.67091629050249
Validation loss: 2.921725594990867

Epoch: 6| Step: 9
Training loss: 2.825982478293319
Validation loss: 2.92393576893588

Epoch: 6| Step: 10
Training loss: 2.8128545749527762
Validation loss: 2.9214850487895347

Epoch: 6| Step: 11
Training loss: 3.133396313081699
Validation loss: 2.9185962435276784

Epoch: 6| Step: 12
Training loss: 3.639896434526283
Validation loss: 2.918418784009996

Epoch: 6| Step: 13
Training loss: 3.833519571728274
Validation loss: 2.917906342728176

Epoch: 34| Step: 0
Training loss: 3.1252007992128106
Validation loss: 2.9204138874887566

Epoch: 6| Step: 1
Training loss: 3.1814337956483945
Validation loss: 2.9184612384553286

Epoch: 6| Step: 2
Training loss: 3.570720090075659
Validation loss: 2.9185664627329744

Epoch: 6| Step: 3
Training loss: 3.340849286678288
Validation loss: 2.915823061777076

Epoch: 6| Step: 4
Training loss: 3.588797963830691
Validation loss: 2.9143031891109055

Epoch: 6| Step: 5
Training loss: 3.1825792814269938
Validation loss: 2.9127935848947426

Epoch: 6| Step: 6
Training loss: 3.0210232028265858
Validation loss: 2.912364790357579

Epoch: 6| Step: 7
Training loss: 2.9911403168185644
Validation loss: 2.9151637469591516

Epoch: 6| Step: 8
Training loss: 3.198251878563562
Validation loss: 2.920000713262332

Epoch: 6| Step: 9
Training loss: 2.6053281914859716
Validation loss: 2.915618102102626

Epoch: 6| Step: 10
Training loss: 3.0907433281783057
Validation loss: 2.91047061010436

Epoch: 6| Step: 11
Training loss: 3.723137583241468
Validation loss: 2.9093976828364982

Epoch: 6| Step: 12
Training loss: 2.4140316859380473
Validation loss: 2.9072113934513157

Epoch: 6| Step: 13
Training loss: 3.8751502469375727
Validation loss: 2.9055883920569934

Epoch: 35| Step: 0
Training loss: 3.493080656459879
Validation loss: 2.9074682777808833

Epoch: 6| Step: 1
Training loss: 3.5008334121274283
Validation loss: 2.9077255202953114

Epoch: 6| Step: 2
Training loss: 2.947518653195854
Validation loss: 2.9038603440155755

Epoch: 6| Step: 3
Training loss: 2.668094034450878
Validation loss: 2.906546013195342

Epoch: 6| Step: 4
Training loss: 3.696615299960671
Validation loss: 2.9024772701108463

Epoch: 6| Step: 5
Training loss: 3.3112584792446556
Validation loss: 2.9044065765278813

Epoch: 6| Step: 6
Training loss: 2.354116681223749
Validation loss: 2.9036911730447907

Epoch: 6| Step: 7
Training loss: 3.229884176628257
Validation loss: 2.907370642470884

Epoch: 6| Step: 8
Training loss: 3.6968882388783184
Validation loss: 2.904157421738631

Epoch: 6| Step: 9
Training loss: 3.1772332995098362
Validation loss: 2.903659913264215

Epoch: 6| Step: 10
Training loss: 3.220541742375013
Validation loss: 2.904687117874927

Epoch: 6| Step: 11
Training loss: 3.15849481201712
Validation loss: 2.9020625651624328

Epoch: 6| Step: 12
Training loss: 3.277693792298075
Validation loss: 2.903212006626124

Epoch: 6| Step: 13
Training loss: 2.389080471173313
Validation loss: 2.900986377957071

Epoch: 36| Step: 0
Training loss: 3.1931088037205155
Validation loss: 2.9019615164439543

Epoch: 6| Step: 1
Training loss: 2.930507046828871
Validation loss: 2.9036751255872013

Epoch: 6| Step: 2
Training loss: 2.200092582488518
Validation loss: 2.9043302552229338

Epoch: 6| Step: 3
Training loss: 2.927928182690478
Validation loss: 2.9035047377195045

Epoch: 6| Step: 4
Training loss: 2.7487748624849044
Validation loss: 2.9009473988630305

Epoch: 6| Step: 5
Training loss: 2.893693110193098
Validation loss: 2.9040341794869784

Epoch: 6| Step: 6
Training loss: 3.4883605332885357
Validation loss: 2.915063690605334

Epoch: 6| Step: 7
Training loss: 3.61593810681737
Validation loss: 2.916589949224423

Epoch: 6| Step: 8
Training loss: 3.522565848044376
Validation loss: 2.905983138008228

Epoch: 6| Step: 9
Training loss: 3.3514335981003094
Validation loss: 2.906189710485923

Epoch: 6| Step: 10
Training loss: 2.7936003711066597
Validation loss: 2.899255858432944

Epoch: 6| Step: 11
Training loss: 3.848621537783219
Validation loss: 2.90008405458237

Epoch: 6| Step: 12
Training loss: 3.5303967550643574
Validation loss: 2.90825834644512

Epoch: 6| Step: 13
Training loss: 3.5110416629484704
Validation loss: 2.902528959763305

Epoch: 37| Step: 0
Training loss: 2.9683195103175857
Validation loss: 2.8969047395743126

Epoch: 6| Step: 1
Training loss: 2.602127517882959
Validation loss: 2.8955336762657455

Epoch: 6| Step: 2
Training loss: 3.3920798278897943
Validation loss: 2.9003237063089053

Epoch: 6| Step: 3
Training loss: 3.527669255814378
Validation loss: 2.9016074983811553

Epoch: 6| Step: 4
Training loss: 2.7979619988021143
Validation loss: 2.8979667146568597

Epoch: 6| Step: 5
Training loss: 3.442357186296459
Validation loss: 2.898341318899629

Epoch: 6| Step: 6
Training loss: 2.332022457649359
Validation loss: 2.8961101803042344

Epoch: 6| Step: 7
Training loss: 2.8177934634921646
Validation loss: 2.8967817294932683

Epoch: 6| Step: 8
Training loss: 3.155755183646819
Validation loss: 2.897201337719952

Epoch: 6| Step: 9
Training loss: 3.3813886575244294
Validation loss: 2.9000571688348393

Epoch: 6| Step: 10
Training loss: 2.9201207734305954
Validation loss: 2.8948965876248347

Epoch: 6| Step: 11
Training loss: 3.2945049137386255
Validation loss: 2.893327213022106

Epoch: 6| Step: 12
Training loss: 3.9106292590946796
Validation loss: 2.898257033539829

Epoch: 6| Step: 13
Training loss: 4.266512488520017
Validation loss: 2.8990943676708882

Epoch: 38| Step: 0
Training loss: 3.3968833438942774
Validation loss: 2.896824651487841

Epoch: 6| Step: 1
Training loss: 2.7977104431033792
Validation loss: 2.891762458392222

Epoch: 6| Step: 2
Training loss: 2.921436950159932
Validation loss: 2.8900333010692307

Epoch: 6| Step: 3
Training loss: 3.135276681472429
Validation loss: 2.8907158613128643

Epoch: 6| Step: 4
Training loss: 3.069165818891599
Validation loss: 2.889150643605082

Epoch: 6| Step: 5
Training loss: 2.6671188587011283
Validation loss: 2.8868732648878903

Epoch: 6| Step: 6
Training loss: 3.320206512554715
Validation loss: 2.887973893574893

Epoch: 6| Step: 7
Training loss: 3.4853087401491645
Validation loss: 2.8869517517880903

Epoch: 6| Step: 8
Training loss: 3.3447385378435253
Validation loss: 2.8879198146754517

Epoch: 6| Step: 9
Training loss: 3.5757994444844488
Validation loss: 2.8867563955163655

Epoch: 6| Step: 10
Training loss: 3.3395224968851682
Validation loss: 2.8837930922589834

Epoch: 6| Step: 11
Training loss: 3.351930398022679
Validation loss: 2.882632353777315

Epoch: 6| Step: 12
Training loss: 2.6333785085384473
Validation loss: 2.884653051617903

Epoch: 6| Step: 13
Training loss: 3.6703293164591875
Validation loss: 2.8830840195812844

Epoch: 39| Step: 0
Training loss: 2.9499024261889826
Validation loss: 2.8827258930546673

Epoch: 6| Step: 1
Training loss: 3.953590576739874
Validation loss: 2.881174356584581

Epoch: 6| Step: 2
Training loss: 3.30093235369744
Validation loss: 2.8815880544012034

Epoch: 6| Step: 3
Training loss: 3.130887398502158
Validation loss: 2.8792673811878426

Epoch: 6| Step: 4
Training loss: 3.4423502602627547
Validation loss: 2.879548717569099

Epoch: 6| Step: 5
Training loss: 2.090471348155362
Validation loss: 2.880731840625205

Epoch: 6| Step: 6
Training loss: 2.845634255397331
Validation loss: 2.8800890886605988

Epoch: 6| Step: 7
Training loss: 3.2759487379485948
Validation loss: 2.8815211127533042

Epoch: 6| Step: 8
Training loss: 3.4921814920599887
Validation loss: 2.8809667557187053

Epoch: 6| Step: 9
Training loss: 3.0739792532980816
Validation loss: 2.8813457437604177

Epoch: 6| Step: 10
Training loss: 3.3827327163837766
Validation loss: 2.8799259863535647

Epoch: 6| Step: 11
Training loss: 3.3654782234000824
Validation loss: 2.879874961020374

Epoch: 6| Step: 12
Training loss: 2.572835038057559
Validation loss: 2.8771625952665887

Epoch: 6| Step: 13
Training loss: 3.510538312273968
Validation loss: 2.8754139121181317

Epoch: 40| Step: 0
Training loss: 3.473645167078114
Validation loss: 2.8749878933488024

Epoch: 6| Step: 1
Training loss: 3.360867191077626
Validation loss: 2.880422683023886

Epoch: 6| Step: 2
Training loss: 3.0933208745946685
Validation loss: 2.892458449605293

Epoch: 6| Step: 3
Training loss: 3.1948455245473473
Validation loss: 2.8856990695706295

Epoch: 6| Step: 4
Training loss: 3.6251035215131457
Validation loss: 2.8803406120015116

Epoch: 6| Step: 5
Training loss: 3.010074230812257
Validation loss: 2.8748607949560525

Epoch: 6| Step: 6
Training loss: 3.1011805839719004
Validation loss: 2.874312236963222

Epoch: 6| Step: 7
Training loss: 3.0281351347164156
Validation loss: 2.873533071727559

Epoch: 6| Step: 8
Training loss: 3.5029156665718144
Validation loss: 2.8720249693047313

Epoch: 6| Step: 9
Training loss: 2.9495417740109637
Validation loss: 2.8734041165622894

Epoch: 6| Step: 10
Training loss: 2.3551193155244694
Validation loss: 2.877934605565899

Epoch: 6| Step: 11
Training loss: 2.7588710752466783
Validation loss: 2.878258531802429

Epoch: 6| Step: 12
Training loss: 3.6721606853623787
Validation loss: 2.876328338458801

Epoch: 6| Step: 13
Training loss: 3.1239297178424232
Validation loss: 2.877103799995145

Epoch: 41| Step: 0
Training loss: 2.830221000102965
Validation loss: 2.8783315212704514

Epoch: 6| Step: 1
Training loss: 2.3417808907594084
Validation loss: 2.873376063988038

Epoch: 6| Step: 2
Training loss: 3.9501257816037607
Validation loss: 2.8781175915511374

Epoch: 6| Step: 3
Training loss: 3.1670948709455837
Validation loss: 2.8729147623008187

Epoch: 6| Step: 4
Training loss: 2.554457161228155
Validation loss: 2.8717763750434693

Epoch: 6| Step: 5
Training loss: 3.415680874911091
Validation loss: 2.8781604471745337

Epoch: 6| Step: 6
Training loss: 3.9165949442904613
Validation loss: 2.877754796290163

Epoch: 6| Step: 7
Training loss: 3.37278788090796
Validation loss: 2.879634671356544

Epoch: 6| Step: 8
Training loss: 2.3714534983088145
Validation loss: 2.8834912661289342

Epoch: 6| Step: 9
Training loss: 3.2037099908837687
Validation loss: 2.8852568006417774

Epoch: 6| Step: 10
Training loss: 3.541858772602809
Validation loss: 2.8871038007659293

Epoch: 6| Step: 11
Training loss: 3.0297729983765938
Validation loss: 2.873529956316068

Epoch: 6| Step: 12
Training loss: 3.145011912506783
Validation loss: 2.8714097439069337

Epoch: 6| Step: 13
Training loss: 3.09337251460265
Validation loss: 2.870884505769751

Epoch: 42| Step: 0
Training loss: 3.050366714194287
Validation loss: 2.8701146989932806

Epoch: 6| Step: 1
Training loss: 3.2305688254412854
Validation loss: 2.8730316432743948

Epoch: 6| Step: 2
Training loss: 3.3435939859375647
Validation loss: 2.873188095217482

Epoch: 6| Step: 3
Training loss: 2.7052231952864663
Validation loss: 2.8752710269052155

Epoch: 6| Step: 4
Training loss: 3.0997573634528677
Validation loss: 2.8727612180702797

Epoch: 6| Step: 5
Training loss: 3.2521529769201396
Validation loss: 2.871872717402653

Epoch: 6| Step: 6
Training loss: 3.0113045374205916
Validation loss: 2.8692905040610497

Epoch: 6| Step: 7
Training loss: 3.5819047845212157
Validation loss: 2.8681569798112014

Epoch: 6| Step: 8
Training loss: 3.9880174928853522
Validation loss: 2.8660411060118633

Epoch: 6| Step: 9
Training loss: 3.114157367951357
Validation loss: 2.8655880484822784

Epoch: 6| Step: 10
Training loss: 3.2080926846174043
Validation loss: 2.869525474910453

Epoch: 6| Step: 11
Training loss: 2.972026422375456
Validation loss: 2.868144616347853

Epoch: 6| Step: 12
Training loss: 2.7763917474401745
Validation loss: 2.8686835958139505

Epoch: 6| Step: 13
Training loss: 2.7112365909454117
Validation loss: 2.8681395375875613

Epoch: 43| Step: 0
Training loss: 3.315673315790978
Validation loss: 2.86676599900906

Epoch: 6| Step: 1
Training loss: 3.2101123055750396
Validation loss: 2.864391254387889

Epoch: 6| Step: 2
Training loss: 3.6229923871408114
Validation loss: 2.8686491251805037

Epoch: 6| Step: 3
Training loss: 3.158809719208026
Validation loss: 2.8630921573452337

Epoch: 6| Step: 4
Training loss: 3.4149950792045383
Validation loss: 2.861720575935278

Epoch: 6| Step: 5
Training loss: 1.580738660437173
Validation loss: 2.8616484205766173

Epoch: 6| Step: 6
Training loss: 3.8469654063332066
Validation loss: 2.8595375549635307

Epoch: 6| Step: 7
Training loss: 3.150985406210471
Validation loss: 2.863572750578554

Epoch: 6| Step: 8
Training loss: 3.587754265151706
Validation loss: 2.8633794333606963

Epoch: 6| Step: 9
Training loss: 3.1921151353249164
Validation loss: 2.859186374380965

Epoch: 6| Step: 10
Training loss: 3.144357313949171
Validation loss: 2.857738488967378

Epoch: 6| Step: 11
Training loss: 2.9102086824135673
Validation loss: 2.8567277082816913

Epoch: 6| Step: 12
Training loss: 2.6551035482613
Validation loss: 2.8596794333502125

Epoch: 6| Step: 13
Training loss: 2.7415548176159388
Validation loss: 2.8603969410685335

Epoch: 44| Step: 0
Training loss: 2.719432613575231
Validation loss: 2.8580038834820893

Epoch: 6| Step: 1
Training loss: 2.7720870047672586
Validation loss: 2.8562108969177653

Epoch: 6| Step: 2
Training loss: 3.15728833332513
Validation loss: 2.8559491368844743

Epoch: 6| Step: 3
Training loss: 2.8250214634982997
Validation loss: 2.8563073877790504

Epoch: 6| Step: 4
Training loss: 3.891938382342177
Validation loss: 2.8572046309486425

Epoch: 6| Step: 5
Training loss: 3.046520036414563
Validation loss: 2.8613553603165216

Epoch: 6| Step: 6
Training loss: 2.442141393225047
Validation loss: 2.8649459919549907

Epoch: 6| Step: 7
Training loss: 2.6539766344423175
Validation loss: 2.8703481447586463

Epoch: 6| Step: 8
Training loss: 3.286257165877059
Validation loss: 2.8650681184831672

Epoch: 6| Step: 9
Training loss: 3.126605270070327
Validation loss: 2.853913293174074

Epoch: 6| Step: 10
Training loss: 3.874158214073837
Validation loss: 2.8521333036350214

Epoch: 6| Step: 11
Training loss: 2.898545090973949
Validation loss: 2.8542425296606515

Epoch: 6| Step: 12
Training loss: 3.68357912224528
Validation loss: 2.861301220933233

Epoch: 6| Step: 13
Training loss: 3.739097003960889
Validation loss: 2.8624050010159965

Epoch: 45| Step: 0
Training loss: 3.577040995349322
Validation loss: 2.8669676748822024

Epoch: 6| Step: 1
Training loss: 3.4856160096423134
Validation loss: 2.8660224218764436

Epoch: 6| Step: 2
Training loss: 2.652563611273635
Validation loss: 2.8635875124739774

Epoch: 6| Step: 3
Training loss: 2.611575175591565
Validation loss: 2.854765958828302

Epoch: 6| Step: 4
Training loss: 2.66942318861437
Validation loss: 2.8509932474198165

Epoch: 6| Step: 5
Training loss: 3.602653553302353
Validation loss: 2.8512395159188255

Epoch: 6| Step: 6
Training loss: 2.765890162628233
Validation loss: 2.851344620711961

Epoch: 6| Step: 7
Training loss: 2.8166099188992604
Validation loss: 2.8524011376374476

Epoch: 6| Step: 8
Training loss: 3.65752121434868
Validation loss: 2.862153240587143

Epoch: 6| Step: 9
Training loss: 2.721294133499142
Validation loss: 2.8655367812595323

Epoch: 6| Step: 10
Training loss: 2.990916487660133
Validation loss: 2.8682724806941535

Epoch: 6| Step: 11
Training loss: 3.1947970172715796
Validation loss: 2.8683089731189018

Epoch: 6| Step: 12
Training loss: 3.887204792552505
Validation loss: 2.859384157589865

Epoch: 6| Step: 13
Training loss: 3.487409014865175
Validation loss: 2.8506152926448562

Epoch: 46| Step: 0
Training loss: 2.7822526131853413
Validation loss: 2.851512532366023

Epoch: 6| Step: 1
Training loss: 1.9744553623829035
Validation loss: 2.8472966639040247

Epoch: 6| Step: 2
Training loss: 3.1827697061874445
Validation loss: 2.849058805727978

Epoch: 6| Step: 3
Training loss: 2.9098360640764294
Validation loss: 2.8509608037511027

Epoch: 6| Step: 4
Training loss: 4.19687207322008
Validation loss: 2.848925927981527

Epoch: 6| Step: 5
Training loss: 2.9699399470670396
Validation loss: 2.8458920038042574

Epoch: 6| Step: 6
Training loss: 3.1310220296566604
Validation loss: 2.8487782450752777

Epoch: 6| Step: 7
Training loss: 3.174345811145243
Validation loss: 2.845583611581525

Epoch: 6| Step: 8
Training loss: 3.499967847403934
Validation loss: 2.8470736128585177

Epoch: 6| Step: 9
Training loss: 3.296840287880058
Validation loss: 2.846670397181856

Epoch: 6| Step: 10
Training loss: 2.946075259737123
Validation loss: 2.8471794071841745

Epoch: 6| Step: 11
Training loss: 3.5370816040633994
Validation loss: 2.847998995652067

Epoch: 6| Step: 12
Training loss: 3.2416647616056387
Validation loss: 2.85166376495698

Epoch: 6| Step: 13
Training loss: 2.549048496819106
Validation loss: 2.8478061111007333

Epoch: 47| Step: 0
Training loss: 3.303405657405389
Validation loss: 2.8432619112532977

Epoch: 6| Step: 1
Training loss: 3.4044868035443776
Validation loss: 2.8447365125272284

Epoch: 6| Step: 2
Training loss: 3.062640907004337
Validation loss: 2.844610077634484

Epoch: 6| Step: 3
Training loss: 3.1379823716630666
Validation loss: 2.8438013624988674

Epoch: 6| Step: 4
Training loss: 3.5586544496486865
Validation loss: 2.843366109977947

Epoch: 6| Step: 5
Training loss: 3.4239623788210687
Validation loss: 2.8425906979288493

Epoch: 6| Step: 6
Training loss: 3.2413542262692934
Validation loss: 2.842988162001532

Epoch: 6| Step: 7
Training loss: 2.6244660697338196
Validation loss: 2.842356429953155

Epoch: 6| Step: 8
Training loss: 3.494847046611829
Validation loss: 2.8416028874074972

Epoch: 6| Step: 9
Training loss: 2.825298435347901
Validation loss: 2.840279995403368

Epoch: 6| Step: 10
Training loss: 3.097942555534653
Validation loss: 2.8441114704146426

Epoch: 6| Step: 11
Training loss: 2.285081337246986
Validation loss: 2.8452072565673303

Epoch: 6| Step: 12
Training loss: 3.3500799710421734
Validation loss: 2.846871405664373

Epoch: 6| Step: 13
Training loss: 2.9767148436961763
Validation loss: 2.843795458675847

Epoch: 48| Step: 0
Training loss: 3.4811400034869258
Validation loss: 2.8428011418605226

Epoch: 6| Step: 1
Training loss: 2.6211223117505864
Validation loss: 2.8393825947546056

Epoch: 6| Step: 2
Training loss: 3.727380690734402
Validation loss: 2.837119518511061

Epoch: 6| Step: 3
Training loss: 3.332403879918592
Validation loss: 2.84158933841829

Epoch: 6| Step: 4
Training loss: 3.722372006175089
Validation loss: 2.8387089641153906

Epoch: 6| Step: 5
Training loss: 2.231848829250036
Validation loss: 2.8396848380315887

Epoch: 6| Step: 6
Training loss: 2.9256782462676227
Validation loss: 2.845216358841414

Epoch: 6| Step: 7
Training loss: 3.3927346974700208
Validation loss: 2.8410455355874427

Epoch: 6| Step: 8
Training loss: 3.1829045398046856
Validation loss: 2.8450734546437175

Epoch: 6| Step: 9
Training loss: 3.041499006971993
Validation loss: 2.8600999897155504

Epoch: 6| Step: 10
Training loss: 3.2573004670121333
Validation loss: 2.8605691733905823

Epoch: 6| Step: 11
Training loss: 2.9064960990812647
Validation loss: 2.8611941917068586

Epoch: 6| Step: 12
Training loss: 2.9609305751588715
Validation loss: 2.860303182906334

Epoch: 6| Step: 13
Training loss: 2.7782623016790824
Validation loss: 2.848973570785152

Epoch: 49| Step: 0
Training loss: 2.686374783606492
Validation loss: 2.8383029406478104

Epoch: 6| Step: 1
Training loss: 2.8013998755653184
Validation loss: 2.835535962793159

Epoch: 6| Step: 2
Training loss: 3.1272608398913215
Validation loss: 2.838226254473526

Epoch: 6| Step: 3
Training loss: 3.0070571545470983
Validation loss: 2.839128491217956

Epoch: 6| Step: 4
Training loss: 3.412067729693624
Validation loss: 2.8373861160904283

Epoch: 6| Step: 5
Training loss: 2.749192466079022
Validation loss: 2.8381732329391403

Epoch: 6| Step: 6
Training loss: 3.600474956758567
Validation loss: 2.837931200990563

Epoch: 6| Step: 7
Training loss: 3.040388979871783
Validation loss: 2.837443691538995

Epoch: 6| Step: 8
Training loss: 2.758324767346253
Validation loss: 2.838576145570464

Epoch: 6| Step: 9
Training loss: 3.437580593204737
Validation loss: 2.8336081947565495

Epoch: 6| Step: 10
Training loss: 3.9939555752518032
Validation loss: 2.8330980133209525

Epoch: 6| Step: 11
Training loss: 2.7951807612619013
Validation loss: 2.8288740635606215

Epoch: 6| Step: 12
Training loss: 3.1627886433112
Validation loss: 2.8282532976440162

Epoch: 6| Step: 13
Training loss: 3.063553765065623
Validation loss: 2.828428016627747

Epoch: 50| Step: 0
Training loss: 2.83135767851943
Validation loss: 2.8277509667819536

Epoch: 6| Step: 1
Training loss: 2.913510349520436
Validation loss: 2.829815307933671

Epoch: 6| Step: 2
Training loss: 3.4407580108294327
Validation loss: 2.8299056431257483

Epoch: 6| Step: 3
Training loss: 3.0454827673547724
Validation loss: 2.827019560122847

Epoch: 6| Step: 4
Training loss: 3.246211851980621
Validation loss: 2.828652886886582

Epoch: 6| Step: 5
Training loss: 2.9811719712256597
Validation loss: 2.8262060173987273

Epoch: 6| Step: 6
Training loss: 3.4413666219518912
Validation loss: 2.826239970711268

Epoch: 6| Step: 7
Training loss: 2.7321482283453054
Validation loss: 2.8294368790710083

Epoch: 6| Step: 8
Training loss: 3.1204240483883363
Validation loss: 2.826936989765228

Epoch: 6| Step: 9
Training loss: 2.7364980248712976
Validation loss: 2.827631318360365

Epoch: 6| Step: 10
Training loss: 3.4867358228439422
Validation loss: 2.8340560026452795

Epoch: 6| Step: 11
Training loss: 2.3699429530106633
Validation loss: 2.829850594045778

Epoch: 6| Step: 12
Training loss: 4.055073684794313
Validation loss: 2.825045141730064

Epoch: 6| Step: 13
Training loss: 3.1596596307575235
Validation loss: 2.8235598485560534

Epoch: 51| Step: 0
Training loss: 3.85283969339537
Validation loss: 2.8209765057137517

Epoch: 6| Step: 1
Training loss: 3.459772262575489
Validation loss: 2.8265529086878773

Epoch: 6| Step: 2
Training loss: 3.247528310040071
Validation loss: 2.8252825669098

Epoch: 6| Step: 3
Training loss: 2.2656948736531244
Validation loss: 2.8291143557475587

Epoch: 6| Step: 4
Training loss: 2.5830019974237475
Validation loss: 2.8289022765034693

Epoch: 6| Step: 5
Training loss: 3.3987012738869966
Validation loss: 2.8303882220612344

Epoch: 6| Step: 6
Training loss: 3.0689939817566594
Validation loss: 2.8309071182422008

Epoch: 6| Step: 7
Training loss: 2.87685997547351
Validation loss: 2.8265765990325997

Epoch: 6| Step: 8
Training loss: 2.900782374374866
Validation loss: 2.8231606780802148

Epoch: 6| Step: 9
Training loss: 3.392389638141559
Validation loss: 2.8213537141316687

Epoch: 6| Step: 10
Training loss: 3.398574440488109
Validation loss: 2.8206051928633062

Epoch: 6| Step: 11
Training loss: 2.8705552614703786
Validation loss: 2.8194912164128008

Epoch: 6| Step: 12
Training loss: 2.905307740081108
Validation loss: 2.82395555284232

Epoch: 6| Step: 13
Training loss: 3.626505046029435
Validation loss: 2.823414353227102

Epoch: 52| Step: 0
Training loss: 3.574975505824975
Validation loss: 2.8263903886581554

Epoch: 6| Step: 1
Training loss: 3.0005176415492936
Validation loss: 2.835960274868213

Epoch: 6| Step: 2
Training loss: 2.6432258392964485
Validation loss: 2.847482538882868

Epoch: 6| Step: 3
Training loss: 2.9869942081319913
Validation loss: 2.8495646037483406

Epoch: 6| Step: 4
Training loss: 3.049742615892915
Validation loss: 2.835156008895416

Epoch: 6| Step: 5
Training loss: 2.472800107510533
Validation loss: 2.8190294536175236

Epoch: 6| Step: 6
Training loss: 3.075097623686545
Validation loss: 2.819638802151361

Epoch: 6| Step: 7
Training loss: 3.0932354740032055
Validation loss: 2.8187350828143813

Epoch: 6| Step: 8
Training loss: 3.423126967121177
Validation loss: 2.81880836394561

Epoch: 6| Step: 9
Training loss: 3.146742295741052
Validation loss: 2.8170936661165227

Epoch: 6| Step: 10
Training loss: 2.390959971776902
Validation loss: 2.81886080297707

Epoch: 6| Step: 11
Training loss: 4.265327638874107
Validation loss: 2.815387198247815

Epoch: 6| Step: 12
Training loss: 3.038807679307199
Validation loss: 2.816369680371169

Epoch: 6| Step: 13
Training loss: 3.1558216673020336
Validation loss: 2.8123388210039098

Epoch: 53| Step: 0
Training loss: 3.4564052553814797
Validation loss: 2.815566549852734

Epoch: 6| Step: 1
Training loss: 2.0952212729852127
Validation loss: 2.815100582557227

Epoch: 6| Step: 2
Training loss: 2.2356213914662395
Validation loss: 2.812623046589766

Epoch: 6| Step: 3
Training loss: 3.6938069605429265
Validation loss: 2.814239716801086

Epoch: 6| Step: 4
Training loss: 3.1305462257617056
Validation loss: 2.8126265065535456

Epoch: 6| Step: 5
Training loss: 2.670268507182688
Validation loss: 2.81217444574052

Epoch: 6| Step: 6
Training loss: 3.559348871069866
Validation loss: 2.8160982865730295

Epoch: 6| Step: 7
Training loss: 3.391270589235194
Validation loss: 2.820604580266414

Epoch: 6| Step: 8
Training loss: 2.9092916343537483
Validation loss: 2.819033894240642

Epoch: 6| Step: 9
Training loss: 3.197229085723937
Validation loss: 2.818151196764006

Epoch: 6| Step: 10
Training loss: 2.205829448439527
Validation loss: 2.8194397311135284

Epoch: 6| Step: 11
Training loss: 4.177614300372377
Validation loss: 2.818088376592712

Epoch: 6| Step: 12
Training loss: 2.8441668194482874
Validation loss: 2.815052537686646

Epoch: 6| Step: 13
Training loss: 3.6455492762760504
Validation loss: 2.812084203723328

Epoch: 54| Step: 0
Training loss: 2.624152182858778
Validation loss: 2.8131923137924337

Epoch: 6| Step: 1
Training loss: 3.129204325104379
Validation loss: 2.813425285148083

Epoch: 6| Step: 2
Training loss: 3.649505262942582
Validation loss: 2.812867147712081

Epoch: 6| Step: 3
Training loss: 3.4592178929327555
Validation loss: 2.8072255298570146

Epoch: 6| Step: 4
Training loss: 3.182239155354311
Validation loss: 2.8053149363782746

Epoch: 6| Step: 5
Training loss: 2.6626079985156967
Validation loss: 2.8082967416268385

Epoch: 6| Step: 6
Training loss: 3.9651872157266066
Validation loss: 2.8070448498424567

Epoch: 6| Step: 7
Training loss: 2.509145127120274
Validation loss: 2.8058175790025035

Epoch: 6| Step: 8
Training loss: 3.1709375358499585
Validation loss: 2.8071250390447124

Epoch: 6| Step: 9
Training loss: 2.780956552862247
Validation loss: 2.8073262618088397

Epoch: 6| Step: 10
Training loss: 2.78876654072451
Validation loss: 2.8061966067392423

Epoch: 6| Step: 11
Training loss: 2.842812184391128
Validation loss: 2.809394392449218

Epoch: 6| Step: 12
Training loss: 3.299077893519607
Validation loss: 2.8084631001262492

Epoch: 6| Step: 13
Training loss: 3.394504419710207
Validation loss: 2.8117425279112487

Epoch: 55| Step: 0
Training loss: 3.2025854633252715
Validation loss: 2.8089891002254324

Epoch: 6| Step: 1
Training loss: 2.9587029955941326
Validation loss: 2.8107628182422606

Epoch: 6| Step: 2
Training loss: 3.3132026934693712
Validation loss: 2.804893182415449

Epoch: 6| Step: 3
Training loss: 3.503742533147438
Validation loss: 2.805130892574127

Epoch: 6| Step: 4
Training loss: 2.7737230610581514
Validation loss: 2.80294091506006

Epoch: 6| Step: 5
Training loss: 2.733326040428791
Validation loss: 2.805181411304413

Epoch: 6| Step: 6
Training loss: 2.8146891233571463
Validation loss: 2.807518254816667

Epoch: 6| Step: 7
Training loss: 3.3170971908890023
Validation loss: 2.8059379693755573

Epoch: 6| Step: 8
Training loss: 3.084523632793201
Validation loss: 2.8045686309338063

Epoch: 6| Step: 9
Training loss: 3.6717108507191933
Validation loss: 2.804109525979828

Epoch: 6| Step: 10
Training loss: 2.7688739895236907
Validation loss: 2.801937985282505

Epoch: 6| Step: 11
Training loss: 3.04383079844551
Validation loss: 2.80232220063236

Epoch: 6| Step: 12
Training loss: 2.665609676768723
Validation loss: 2.7982816611585357

Epoch: 6| Step: 13
Training loss: 3.857137919730604
Validation loss: 2.798586710879626

Epoch: 56| Step: 0
Training loss: 3.1344735553190013
Validation loss: 2.7969873497096605

Epoch: 6| Step: 1
Training loss: 2.959902781359154
Validation loss: 2.7988161560035785

Epoch: 6| Step: 2
Training loss: 3.294265944083987
Validation loss: 2.801556227298232

Epoch: 6| Step: 3
Training loss: 3.271477670235667
Validation loss: 2.7951184163080223

Epoch: 6| Step: 4
Training loss: 3.222213659238582
Validation loss: 2.794633462206701

Epoch: 6| Step: 5
Training loss: 2.714765149632187
Validation loss: 2.795930641698349

Epoch: 6| Step: 6
Training loss: 3.034660701482147
Validation loss: 2.79841609534473

Epoch: 6| Step: 7
Training loss: 2.9768551660069598
Validation loss: 2.8013803237784454

Epoch: 6| Step: 8
Training loss: 3.5922078680030975
Validation loss: 2.8020407508816394

Epoch: 6| Step: 9
Training loss: 3.510101998523556
Validation loss: 2.8044708878527267

Epoch: 6| Step: 10
Training loss: 3.058587669863449
Validation loss: 2.799549643604072

Epoch: 6| Step: 11
Training loss: 3.226931054446526
Validation loss: 2.8004938379370756

Epoch: 6| Step: 12
Training loss: 2.9614656727141146
Validation loss: 2.800568734220833

Epoch: 6| Step: 13
Training loss: 1.9480651622072205
Validation loss: 2.800289157104158

Epoch: 57| Step: 0
Training loss: 2.2699175980185786
Validation loss: 2.797951892515006

Epoch: 6| Step: 1
Training loss: 3.1541165232399537
Validation loss: 2.798094046045897

Epoch: 6| Step: 2
Training loss: 3.2035534083744595
Validation loss: 2.8027402747616197

Epoch: 6| Step: 3
Training loss: 3.446003885595751
Validation loss: 2.799302734554082

Epoch: 6| Step: 4
Training loss: 3.2631788811713127
Validation loss: 2.802461399115026

Epoch: 6| Step: 5
Training loss: 3.13032413888363
Validation loss: 2.8042724998854642

Epoch: 6| Step: 6
Training loss: 2.7622490229456873
Validation loss: 2.8115863332324205

Epoch: 6| Step: 7
Training loss: 3.0115361931437494
Validation loss: 2.80474222123961

Epoch: 6| Step: 8
Training loss: 3.726075082568125
Validation loss: 2.814391303527227

Epoch: 6| Step: 9
Training loss: 2.3835483102833965
Validation loss: 2.7960468614582776

Epoch: 6| Step: 10
Training loss: 2.8410641908788925
Validation loss: 2.8018704746865803

Epoch: 6| Step: 11
Training loss: 3.271292117718288
Validation loss: 2.8018145389790634

Epoch: 6| Step: 12
Training loss: 3.3123767757888225
Validation loss: 2.794409197424626

Epoch: 6| Step: 13
Training loss: 3.6661282635366357
Validation loss: 2.7992155806738226

Epoch: 58| Step: 0
Training loss: 3.6255529573881793
Validation loss: 2.7998144538038603

Epoch: 6| Step: 1
Training loss: 3.1032319848556367
Validation loss: 2.800277176958096

Epoch: 6| Step: 2
Training loss: 3.4435080995427048
Validation loss: 2.799306950042751

Epoch: 6| Step: 3
Training loss: 2.5048257029308423
Validation loss: 2.797521438913103

Epoch: 6| Step: 4
Training loss: 2.9208964784973372
Validation loss: 2.7958358866479407

Epoch: 6| Step: 5
Training loss: 2.95684999341274
Validation loss: 2.794081505943293

Epoch: 6| Step: 6
Training loss: 3.4267635176908193
Validation loss: 2.7938890621348884

Epoch: 6| Step: 7
Training loss: 3.5981882304668438
Validation loss: 2.7950434794560644

Epoch: 6| Step: 8
Training loss: 3.0338521583561397
Validation loss: 2.7934326355732435

Epoch: 6| Step: 9
Training loss: 3.1996508109784143
Validation loss: 2.794323749662577

Epoch: 6| Step: 10
Training loss: 2.6843909088835733
Validation loss: 2.7927257994096024

Epoch: 6| Step: 11
Training loss: 3.3105618546858735
Validation loss: 2.7916555580453215

Epoch: 6| Step: 12
Training loss: 2.755577673190919
Validation loss: 2.7942597754334324

Epoch: 6| Step: 13
Training loss: 2.5073336800728256
Validation loss: 2.795273177817498

Epoch: 59| Step: 0
Training loss: 3.8172275436493326
Validation loss: 2.7981472351726606

Epoch: 6| Step: 1
Training loss: 3.57906119413626
Validation loss: 2.796861696306171

Epoch: 6| Step: 2
Training loss: 3.5380143725080093
Validation loss: 2.7949293120488865

Epoch: 6| Step: 3
Training loss: 2.9203034933001324
Validation loss: 2.7962001129046277

Epoch: 6| Step: 4
Training loss: 2.94272133253259
Validation loss: 2.794067694399935

Epoch: 6| Step: 5
Training loss: 2.964609893300973
Validation loss: 2.790272620087736

Epoch: 6| Step: 6
Training loss: 2.737058009867062
Validation loss: 2.79259941400691

Epoch: 6| Step: 7
Training loss: 2.6595105971519506
Validation loss: 2.7937943130865532

Epoch: 6| Step: 8
Training loss: 2.579454391363182
Validation loss: 2.7937485161483475

Epoch: 6| Step: 9
Training loss: 2.6981841338929864
Validation loss: 2.789387718765904

Epoch: 6| Step: 10
Training loss: 3.4966441824026187
Validation loss: 2.787180264672604

Epoch: 6| Step: 11
Training loss: 3.5655451024270337
Validation loss: 2.7858268279034077

Epoch: 6| Step: 12
Training loss: 2.8284982677317525
Validation loss: 2.78734145999138

Epoch: 6| Step: 13
Training loss: 2.4810125280553654
Validation loss: 2.7838860868936197

Epoch: 60| Step: 0
Training loss: 2.3520864112187385
Validation loss: 2.7824211982166416

Epoch: 6| Step: 1
Training loss: 3.4202182887500316
Validation loss: 2.7827736558283007

Epoch: 6| Step: 2
Training loss: 3.0193167902697593
Validation loss: 2.783996424299873

Epoch: 6| Step: 3
Training loss: 2.8174106537023422
Validation loss: 2.7905586025964975

Epoch: 6| Step: 4
Training loss: 2.98065080999077
Validation loss: 2.7962979718113297

Epoch: 6| Step: 5
Training loss: 3.548578332267278
Validation loss: 2.7906033485635655

Epoch: 6| Step: 6
Training loss: 3.561238115584741
Validation loss: 2.792848030049778

Epoch: 6| Step: 7
Training loss: 2.983279361627355
Validation loss: 2.789762459727367

Epoch: 6| Step: 8
Training loss: 3.6186362345837124
Validation loss: 2.7838312245928543

Epoch: 6| Step: 9
Training loss: 3.1579114110406055
Validation loss: 2.7866958187282163

Epoch: 6| Step: 10
Training loss: 3.1969983566513824
Validation loss: 2.788163223949632

Epoch: 6| Step: 11
Training loss: 2.98757395632832
Validation loss: 2.7907963257578476

Epoch: 6| Step: 12
Training loss: 2.564916448291981
Validation loss: 2.785174033339428

Epoch: 6| Step: 13
Training loss: 2.7395578148720663
Validation loss: 2.78326047097413

Epoch: 61| Step: 0
Training loss: 2.5714630056527974
Validation loss: 2.778984894182627

Epoch: 6| Step: 1
Training loss: 2.4652186379181984
Validation loss: 2.779834561814146

Epoch: 6| Step: 2
Training loss: 3.1478152736961
Validation loss: 2.7804109700344455

Epoch: 6| Step: 3
Training loss: 3.1265677524962907
Validation loss: 2.7824439131299923

Epoch: 6| Step: 4
Training loss: 2.8750011609945854
Validation loss: 2.786289580215515

Epoch: 6| Step: 5
Training loss: 2.4485224413911535
Validation loss: 2.787938875479471

Epoch: 6| Step: 6
Training loss: 3.2703049996367946
Validation loss: 2.7946496624572923

Epoch: 6| Step: 7
Training loss: 3.4900868218670325
Validation loss: 2.791970058503924

Epoch: 6| Step: 8
Training loss: 3.0090163162717074
Validation loss: 2.7935474588171476

Epoch: 6| Step: 9
Training loss: 3.1001394548120293
Validation loss: 2.7888499470478565

Epoch: 6| Step: 10
Training loss: 3.5026935022393673
Validation loss: 2.784453885733679

Epoch: 6| Step: 11
Training loss: 3.247031102911761
Validation loss: 2.775359592052228

Epoch: 6| Step: 12
Training loss: 3.8044405941285153
Validation loss: 2.7763680739442096

Epoch: 6| Step: 13
Training loss: 2.822273227985001
Validation loss: 2.7771951591157626

Epoch: 62| Step: 0
Training loss: 2.9499303906520207
Validation loss: 2.775840244205615

Epoch: 6| Step: 1
Training loss: 2.764573926605419
Validation loss: 2.7778492057668127

Epoch: 6| Step: 2
Training loss: 3.0078944603788598
Validation loss: 2.777129330848909

Epoch: 6| Step: 3
Training loss: 3.389366514043017
Validation loss: 2.775390480902104

Epoch: 6| Step: 4
Training loss: 3.60412718176115
Validation loss: 2.775153699478351

Epoch: 6| Step: 5
Training loss: 3.1569575659165974
Validation loss: 2.776959874801334

Epoch: 6| Step: 6
Training loss: 3.394129194849985
Validation loss: 2.7754651632523393

Epoch: 6| Step: 7
Training loss: 3.000357924408444
Validation loss: 2.774427287179699

Epoch: 6| Step: 8
Training loss: 3.361086103558227
Validation loss: 2.773432954018712

Epoch: 6| Step: 9
Training loss: 2.7006786058787107
Validation loss: 2.7771473557511146

Epoch: 6| Step: 10
Training loss: 2.6617112509238634
Validation loss: 2.7727471779231885

Epoch: 6| Step: 11
Training loss: 3.1760867864536464
Validation loss: 2.7773445105970973

Epoch: 6| Step: 12
Training loss: 3.1627639177893774
Validation loss: 2.778262853483333

Epoch: 6| Step: 13
Training loss: 2.60914939773126
Validation loss: 2.7780065092304085

Epoch: 63| Step: 0
Training loss: 3.242491043772567
Validation loss: 2.7768147651916695

Epoch: 6| Step: 1
Training loss: 3.907082186746173
Validation loss: 2.771074228287857

Epoch: 6| Step: 2
Training loss: 3.2455172801529626
Validation loss: 2.7707990779481695

Epoch: 6| Step: 3
Training loss: 2.9448790699299066
Validation loss: 2.7677993064823347

Epoch: 6| Step: 4
Training loss: 3.312409021819623
Validation loss: 2.7699670658009885

Epoch: 6| Step: 5
Training loss: 2.8159087822401956
Validation loss: 2.7694527197070284

Epoch: 6| Step: 6
Training loss: 2.904032691992235
Validation loss: 2.7687572282395725

Epoch: 6| Step: 7
Training loss: 2.471067089669058
Validation loss: 2.7737160348264887

Epoch: 6| Step: 8
Training loss: 3.094465230860163
Validation loss: 2.769610011325665

Epoch: 6| Step: 9
Training loss: 2.8303483685240995
Validation loss: 2.769522143354954

Epoch: 6| Step: 10
Training loss: 3.2444507466723866
Validation loss: 2.767500548993838

Epoch: 6| Step: 11
Training loss: 3.1399966697918185
Validation loss: 2.767680002616239

Epoch: 6| Step: 12
Training loss: 2.7008217938474917
Validation loss: 2.771393737696086

Epoch: 6| Step: 13
Training loss: 3.1324429187003577
Validation loss: 2.769408101334181

Epoch: 64| Step: 0
Training loss: 3.377753088537412
Validation loss: 2.7733750036588125

Epoch: 6| Step: 1
Training loss: 2.8684280580539157
Validation loss: 2.7782190003903993

Epoch: 6| Step: 2
Training loss: 3.3509044223452378
Validation loss: 2.7723107135307212

Epoch: 6| Step: 3
Training loss: 2.7414589808065384
Validation loss: 2.768892551471754

Epoch: 6| Step: 4
Training loss: 3.54064043922122
Validation loss: 2.7699593146184465

Epoch: 6| Step: 5
Training loss: 2.910441339852877
Validation loss: 2.766019268053098

Epoch: 6| Step: 6
Training loss: 2.4842573413938105
Validation loss: 2.76857437757904

Epoch: 6| Step: 7
Training loss: 3.15497268664935
Validation loss: 2.7663229359508423

Epoch: 6| Step: 8
Training loss: 2.3751233721361573
Validation loss: 2.764477517180497

Epoch: 6| Step: 9
Training loss: 2.963872013999365
Validation loss: 2.7628025729825265

Epoch: 6| Step: 10
Training loss: 2.417786623700562
Validation loss: 2.765092970393911

Epoch: 6| Step: 11
Training loss: 3.6851078614969603
Validation loss: 2.76378983157806

Epoch: 6| Step: 12
Training loss: 3.3856709233198052
Validation loss: 2.7628034684185003

Epoch: 6| Step: 13
Training loss: 3.882894411508674
Validation loss: 2.7610587421413086

Epoch: 65| Step: 0
Training loss: 2.622694183520724
Validation loss: 2.7605518353632403

Epoch: 6| Step: 1
Training loss: 2.709220936408729
Validation loss: 2.7632679740548367

Epoch: 6| Step: 2
Training loss: 3.3802218130790225
Validation loss: 2.7615815240089647

Epoch: 6| Step: 3
Training loss: 2.702167848683441
Validation loss: 2.7601416365879756

Epoch: 6| Step: 4
Training loss: 3.7097649257659655
Validation loss: 2.765049852277357

Epoch: 6| Step: 5
Training loss: 2.827310602943001
Validation loss: 2.7655983783322875

Epoch: 6| Step: 6
Training loss: 3.10633924267788
Validation loss: 2.761776594061635

Epoch: 6| Step: 7
Training loss: 3.207140977587682
Validation loss: 2.761149081771582

Epoch: 6| Step: 8
Training loss: 2.494815409526786
Validation loss: 2.758623098567994

Epoch: 6| Step: 9
Training loss: 3.0347688052057284
Validation loss: 2.7601598940993424

Epoch: 6| Step: 10
Training loss: 3.122290390223784
Validation loss: 2.7601747530256606

Epoch: 6| Step: 11
Training loss: 3.3891563223149506
Validation loss: 2.7604201292239527

Epoch: 6| Step: 12
Training loss: 3.2724906626335737
Validation loss: 2.7585790299128656

Epoch: 6| Step: 13
Training loss: 3.4416305694041776
Validation loss: 2.757700293165484

Epoch: 66| Step: 0
Training loss: 2.9486049392291407
Validation loss: 2.7594908130774365

Epoch: 6| Step: 1
Training loss: 3.0671118440785485
Validation loss: 2.7565331477750235

Epoch: 6| Step: 2
Training loss: 3.127954078600655
Validation loss: 2.7606360755568655

Epoch: 6| Step: 3
Training loss: 3.3665663285615643
Validation loss: 2.758272726802561

Epoch: 6| Step: 4
Training loss: 3.3194988375738
Validation loss: 2.755807528839471

Epoch: 6| Step: 5
Training loss: 3.3826393981764746
Validation loss: 2.755360036201949

Epoch: 6| Step: 6
Training loss: 2.711191214965788
Validation loss: 2.758217183090208

Epoch: 6| Step: 7
Training loss: 3.388893775380543
Validation loss: 2.7547312418683347

Epoch: 6| Step: 8
Training loss: 2.3780754655649337
Validation loss: 2.757281157197588

Epoch: 6| Step: 9
Training loss: 2.9911074768366785
Validation loss: 2.7554434861217105

Epoch: 6| Step: 10
Training loss: 3.1171198863868548
Validation loss: 2.755033806704583

Epoch: 6| Step: 11
Training loss: 2.5058346373243103
Validation loss: 2.755242184890188

Epoch: 6| Step: 12
Training loss: 3.4155696100069783
Validation loss: 2.753319900056037

Epoch: 6| Step: 13
Training loss: 3.1070729077112125
Validation loss: 2.753234327025932

Epoch: 67| Step: 0
Training loss: 2.6151350029547613
Validation loss: 2.7505235183007746

Epoch: 6| Step: 1
Training loss: 2.8010488725434537
Validation loss: 2.7509567129152077

Epoch: 6| Step: 2
Training loss: 2.548936068415915
Validation loss: 2.7524024745980142

Epoch: 6| Step: 3
Training loss: 3.1614958725805336
Validation loss: 2.757253522399225

Epoch: 6| Step: 4
Training loss: 3.458536594040094
Validation loss: 2.7539686929161267

Epoch: 6| Step: 5
Training loss: 3.593471881221949
Validation loss: 2.7594453898012894

Epoch: 6| Step: 6
Training loss: 2.9895495546849515
Validation loss: 2.7624418705515077

Epoch: 6| Step: 7
Training loss: 3.473916682156178
Validation loss: 2.7662467167349405

Epoch: 6| Step: 8
Training loss: 2.1571941796389615
Validation loss: 2.769074305329605

Epoch: 6| Step: 9
Training loss: 3.7866328993711034
Validation loss: 2.766190815995009

Epoch: 6| Step: 10
Training loss: 3.1483178506460066
Validation loss: 2.7568471188518067

Epoch: 6| Step: 11
Training loss: 3.1652103555448936
Validation loss: 2.756593451699879

Epoch: 6| Step: 12
Training loss: 2.691639661702682
Validation loss: 2.7521886441014565

Epoch: 6| Step: 13
Training loss: 2.9603678374231
Validation loss: 2.7490742393938428

Epoch: 68| Step: 0
Training loss: 2.499253161456692
Validation loss: 2.7478693299170143

Epoch: 6| Step: 1
Training loss: 2.5266995441777107
Validation loss: 2.748772069201355

Epoch: 6| Step: 2
Training loss: 3.161779715193205
Validation loss: 2.7490446178148042

Epoch: 6| Step: 3
Training loss: 2.92281681324357
Validation loss: 2.7485796876742676

Epoch: 6| Step: 4
Training loss: 3.1051416764670523
Validation loss: 2.7456889112227576

Epoch: 6| Step: 5
Training loss: 2.4451764833689524
Validation loss: 2.7470499064790532

Epoch: 6| Step: 6
Training loss: 3.8614313616383926
Validation loss: 2.746515871085628

Epoch: 6| Step: 7
Training loss: 2.502850623934145
Validation loss: 2.7464448428439647

Epoch: 6| Step: 8
Training loss: 3.6690985388968183
Validation loss: 2.7454802641022935

Epoch: 6| Step: 9
Training loss: 3.3784760835282905
Validation loss: 2.7432878865159864

Epoch: 6| Step: 10
Training loss: 2.936843149321363
Validation loss: 2.7478054515566632

Epoch: 6| Step: 11
Training loss: 3.5130186465034816
Validation loss: 2.7426473360961485

Epoch: 6| Step: 12
Training loss: 2.773200656287857
Validation loss: 2.7436297692678946

Epoch: 6| Step: 13
Training loss: 3.3620084155066445
Validation loss: 2.744253898194695

Epoch: 69| Step: 0
Training loss: 3.1815340646001933
Validation loss: 2.743474728729469

Epoch: 6| Step: 1
Training loss: 3.004251011384418
Validation loss: 2.7444276987314735

Epoch: 6| Step: 2
Training loss: 3.506524952054367
Validation loss: 2.7457016328106247

Epoch: 6| Step: 3
Training loss: 2.7635812913047992
Validation loss: 2.7459644182204452

Epoch: 6| Step: 4
Training loss: 2.897625668082249
Validation loss: 2.7510365837909934

Epoch: 6| Step: 5
Training loss: 3.370935323623799
Validation loss: 2.7503341339435803

Epoch: 6| Step: 6
Training loss: 3.596306331168147
Validation loss: 2.7488627361506324

Epoch: 6| Step: 7
Training loss: 3.3424466168656575
Validation loss: 2.756941100301282

Epoch: 6| Step: 8
Training loss: 2.4502562252666573
Validation loss: 2.7602556175079376

Epoch: 6| Step: 9
Training loss: 3.2279015965075266
Validation loss: 2.769113322451524

Epoch: 6| Step: 10
Training loss: 2.780621918470579
Validation loss: 2.7695406444939894

Epoch: 6| Step: 11
Training loss: 3.1597406705846414
Validation loss: 2.7828025028971144

Epoch: 6| Step: 12
Training loss: 2.522499406132094
Validation loss: 2.763503768227691

Epoch: 6| Step: 13
Training loss: 2.767587515008109
Validation loss: 2.7547656927134163

Epoch: 70| Step: 0
Training loss: 2.6344970385248287
Validation loss: 2.745836350108826

Epoch: 6| Step: 1
Training loss: 3.041934345607788
Validation loss: 2.7478214352805486

Epoch: 6| Step: 2
Training loss: 3.6038175792358276
Validation loss: 2.743261002288653

Epoch: 6| Step: 3
Training loss: 3.446398920571203
Validation loss: 2.739924553044327

Epoch: 6| Step: 4
Training loss: 2.730155523013311
Validation loss: 2.741403125419862

Epoch: 6| Step: 5
Training loss: 3.693022391339453
Validation loss: 2.7397113946199974

Epoch: 6| Step: 6
Training loss: 2.9373639663689706
Validation loss: 2.7422545681089914

Epoch: 6| Step: 7
Training loss: 2.523787341358831
Validation loss: 2.7376923654256604

Epoch: 6| Step: 8
Training loss: 2.7208738252938054
Validation loss: 2.7412131867078644

Epoch: 6| Step: 9
Training loss: 3.419666709944771
Validation loss: 2.7361290678149195

Epoch: 6| Step: 10
Training loss: 3.228031295199234
Validation loss: 2.7365933290686018

Epoch: 6| Step: 11
Training loss: 2.6389338930096002
Validation loss: 2.7394468723539958

Epoch: 6| Step: 12
Training loss: 3.0966513544312475
Validation loss: 2.73901033080322

Epoch: 6| Step: 13
Training loss: 2.7325128808725716
Validation loss: 2.7460650821194665

Epoch: 71| Step: 0
Training loss: 2.076625426338587
Validation loss: 2.7454879938199626

Epoch: 6| Step: 1
Training loss: 3.233134451055365
Validation loss: 2.7521622361875724

Epoch: 6| Step: 2
Training loss: 3.3092612501844965
Validation loss: 2.7481265673776964

Epoch: 6| Step: 3
Training loss: 3.6144299799830395
Validation loss: 2.7391477712953503

Epoch: 6| Step: 4
Training loss: 2.798960925490146
Validation loss: 2.734217487257741

Epoch: 6| Step: 5
Training loss: 3.3896345106941643
Validation loss: 2.7356558972958007

Epoch: 6| Step: 6
Training loss: 2.62882861721369
Validation loss: 2.737772343288613

Epoch: 6| Step: 7
Training loss: 3.2927005608835094
Validation loss: 2.737214422564505

Epoch: 6| Step: 8
Training loss: 3.0173745886049654
Validation loss: 2.7364580948997155

Epoch: 6| Step: 9
Training loss: 3.0885431419399056
Validation loss: 2.7392878487496337

Epoch: 6| Step: 10
Training loss: 3.016831072828716
Validation loss: 2.733710245406549

Epoch: 6| Step: 11
Training loss: 2.6319772544388185
Validation loss: 2.7380205857475697

Epoch: 6| Step: 12
Training loss: 3.2579329580454313
Validation loss: 2.7364928985183568

Epoch: 6| Step: 13
Training loss: 3.3091906444865966
Validation loss: 2.736911539654866

Epoch: 72| Step: 0
Training loss: 2.979820090886
Validation loss: 2.733218520814776

Epoch: 6| Step: 1
Training loss: 3.078151025032748
Validation loss: 2.735396122513012

Epoch: 6| Step: 2
Training loss: 3.310243377727323
Validation loss: 2.733743127806858

Epoch: 6| Step: 3
Training loss: 2.7882873141756432
Validation loss: 2.734039032859622

Epoch: 6| Step: 4
Training loss: 3.016574848386489
Validation loss: 2.732677222111921

Epoch: 6| Step: 5
Training loss: 3.029383920664685
Validation loss: 2.7343689958591435

Epoch: 6| Step: 6
Training loss: 3.6984194704751707
Validation loss: 2.7320931200128125

Epoch: 6| Step: 7
Training loss: 2.693242436360753
Validation loss: 2.7328371819838457

Epoch: 6| Step: 8
Training loss: 3.077056699382281
Validation loss: 2.739947775117077

Epoch: 6| Step: 9
Training loss: 2.661163453091949
Validation loss: 2.7479121727793827

Epoch: 6| Step: 10
Training loss: 3.1017909506348795
Validation loss: 2.7515212211594875

Epoch: 6| Step: 11
Training loss: 2.9276060314180445
Validation loss: 2.755388887428368

Epoch: 6| Step: 12
Training loss: 3.280920974947074
Validation loss: 2.763564578682851

Epoch: 6| Step: 13
Training loss: 3.1244610130892103
Validation loss: 2.747803762866886

Epoch: 73| Step: 0
Training loss: 3.8129302235483458
Validation loss: 2.734456690257994

Epoch: 6| Step: 1
Training loss: 3.3645584215751674
Validation loss: 2.731508775692146

Epoch: 6| Step: 2
Training loss: 3.0092402252725585
Validation loss: 2.7280341526388794

Epoch: 6| Step: 3
Training loss: 2.636032354234447
Validation loss: 2.7275772658053006

Epoch: 6| Step: 4
Training loss: 2.6050732268074173
Validation loss: 2.728243245995441

Epoch: 6| Step: 5
Training loss: 3.726312720926764
Validation loss: 2.7315300843075447

Epoch: 6| Step: 6
Training loss: 3.247998868641398
Validation loss: 2.730115280546581

Epoch: 6| Step: 7
Training loss: 2.4958355550697724
Validation loss: 2.7323247495632548

Epoch: 6| Step: 8
Training loss: 3.096094495420441
Validation loss: 2.7297697724572725

Epoch: 6| Step: 9
Training loss: 2.772971530508164
Validation loss: 2.7286571868481833

Epoch: 6| Step: 10
Training loss: 3.1280694764170427
Validation loss: 2.72855329317618

Epoch: 6| Step: 11
Training loss: 2.9553863102474187
Validation loss: 2.7269563106983714

Epoch: 6| Step: 12
Training loss: 2.4591842945811027
Validation loss: 2.7260705882761136

Epoch: 6| Step: 13
Training loss: 3.253315774708668
Validation loss: 2.7259179074487423

Epoch: 74| Step: 0
Training loss: 2.7159684081508546
Validation loss: 2.7256792201343814

Epoch: 6| Step: 1
Training loss: 3.872534921487429
Validation loss: 2.7303841724617564

Epoch: 6| Step: 2
Training loss: 3.0698170347085694
Validation loss: 2.724572652509829

Epoch: 6| Step: 3
Training loss: 3.4361974849413963
Validation loss: 2.7247678326843374

Epoch: 6| Step: 4
Training loss: 2.43767977320582
Validation loss: 2.7232196706463228

Epoch: 6| Step: 5
Training loss: 2.627336824324614
Validation loss: 2.7255084868888844

Epoch: 6| Step: 6
Training loss: 3.628485352382398
Validation loss: 2.723155278083887

Epoch: 6| Step: 7
Training loss: 2.648943197307378
Validation loss: 2.723407114000253

Epoch: 6| Step: 8
Training loss: 3.0575209644812227
Validation loss: 2.724587232229451

Epoch: 6| Step: 9
Training loss: 3.1446704525671723
Validation loss: 2.7244957884812337

Epoch: 6| Step: 10
Training loss: 2.577182111848962
Validation loss: 2.7231396315909704

Epoch: 6| Step: 11
Training loss: 2.661465629274007
Validation loss: 2.7270158792181847

Epoch: 6| Step: 12
Training loss: 3.0361395658195236
Validation loss: 2.723176430832018

Epoch: 6| Step: 13
Training loss: 3.6346674951490363
Validation loss: 2.7227439186542393

Epoch: 75| Step: 0
Training loss: 3.456542382453775
Validation loss: 2.7250010689579685

Epoch: 6| Step: 1
Training loss: 2.782020547830703
Validation loss: 2.7248801396285414

Epoch: 6| Step: 2
Training loss: 2.7787623906856735
Validation loss: 2.7253294340058853

Epoch: 6| Step: 3
Training loss: 2.302202753850413
Validation loss: 2.7227153570688523

Epoch: 6| Step: 4
Training loss: 2.7773301865988254
Validation loss: 2.723282726811368

Epoch: 6| Step: 5
Training loss: 2.2871789050263236
Validation loss: 2.724988875413901

Epoch: 6| Step: 6
Training loss: 2.521520211033832
Validation loss: 2.721208491692311

Epoch: 6| Step: 7
Training loss: 3.384749846688556
Validation loss: 2.7255313398545056

Epoch: 6| Step: 8
Training loss: 3.5209505562012464
Validation loss: 2.7326742416315795

Epoch: 6| Step: 9
Training loss: 2.884697192083538
Validation loss: 2.7254178359703687

Epoch: 6| Step: 10
Training loss: 3.765178733119317
Validation loss: 2.725117851765301

Epoch: 6| Step: 11
Training loss: 3.749864702962941
Validation loss: 2.723925759001059

Epoch: 6| Step: 12
Training loss: 2.6005512826854527
Validation loss: 2.7226678165334817

Epoch: 6| Step: 13
Training loss: 3.5443949494315885
Validation loss: 2.719387061369822

Epoch: 76| Step: 0
Training loss: 3.3054836026721084
Validation loss: 2.7178334487630083

Epoch: 6| Step: 1
Training loss: 2.7430170005524617
Validation loss: 2.716572497852284

Epoch: 6| Step: 2
Training loss: 2.2995390720419726
Validation loss: 2.7152984476800706

Epoch: 6| Step: 3
Training loss: 2.0755100864210343
Validation loss: 2.7198194522716905

Epoch: 6| Step: 4
Training loss: 3.397495323329511
Validation loss: 2.7138930630881046

Epoch: 6| Step: 5
Training loss: 3.382646023572164
Validation loss: 2.7169728933241233

Epoch: 6| Step: 6
Training loss: 3.0537752706486914
Validation loss: 2.7157042579597763

Epoch: 6| Step: 7
Training loss: 3.243622170577428
Validation loss: 2.7187207184693856

Epoch: 6| Step: 8
Training loss: 3.308667827258834
Validation loss: 2.7175993633827824

Epoch: 6| Step: 9
Training loss: 2.8895241780587226
Validation loss: 2.7189087605094215

Epoch: 6| Step: 10
Training loss: 3.1783210386356173
Validation loss: 2.7238482051835855

Epoch: 6| Step: 11
Training loss: 3.0325119695089158
Validation loss: 2.7260539861199593

Epoch: 6| Step: 12
Training loss: 3.425902343836852
Validation loss: 2.729582474880017

Epoch: 6| Step: 13
Training loss: 2.84435475385179
Validation loss: 2.7211447025417015

Epoch: 77| Step: 0
Training loss: 3.23006369324234
Validation loss: 2.7159956635311824

Epoch: 6| Step: 1
Training loss: 2.9914868682414983
Validation loss: 2.715923597351315

Epoch: 6| Step: 2
Training loss: 3.2512586063914948
Validation loss: 2.7143712409629264

Epoch: 6| Step: 3
Training loss: 3.2516379996997373
Validation loss: 2.713025351929617

Epoch: 6| Step: 4
Training loss: 3.4719560258339546
Validation loss: 2.7127542583637987

Epoch: 6| Step: 5
Training loss: 3.3111013662662807
Validation loss: 2.7125676987752585

Epoch: 6| Step: 6
Training loss: 1.7365200078302019
Validation loss: 2.7155334290689894

Epoch: 6| Step: 7
Training loss: 3.133891768776995
Validation loss: 2.7179047125391156

Epoch: 6| Step: 8
Training loss: 3.283538311080294
Validation loss: 2.718475752291545

Epoch: 6| Step: 9
Training loss: 2.967074915481095
Validation loss: 2.7165688268408097

Epoch: 6| Step: 10
Training loss: 2.850506145305396
Validation loss: 2.7178837404257292

Epoch: 6| Step: 11
Training loss: 3.2034181042058814
Validation loss: 2.714853047611501

Epoch: 6| Step: 12
Training loss: 2.605684514526961
Validation loss: 2.7144149922118053

Epoch: 6| Step: 13
Training loss: 2.8937067873140268
Validation loss: 2.7164308658782557

Epoch: 78| Step: 0
Training loss: 2.589166290836493
Validation loss: 2.714101844137014

Epoch: 6| Step: 1
Training loss: 2.8158320715966227
Validation loss: 2.7167570725564985

Epoch: 6| Step: 2
Training loss: 3.108293354776171
Validation loss: 2.7187957514655765

Epoch: 6| Step: 3
Training loss: 3.165078233231075
Validation loss: 2.7207047023618003

Epoch: 6| Step: 4
Training loss: 3.2928056959371728
Validation loss: 2.721536600307978

Epoch: 6| Step: 5
Training loss: 2.4470485581855876
Validation loss: 2.717984713336448

Epoch: 6| Step: 6
Training loss: 2.9583654983992664
Validation loss: 2.7166370473903236

Epoch: 6| Step: 7
Training loss: 2.9389682103657617
Validation loss: 2.714865084599936

Epoch: 6| Step: 8
Training loss: 2.954130939936571
Validation loss: 2.7140071726978308

Epoch: 6| Step: 9
Training loss: 2.968498460252339
Validation loss: 2.7115049015154176

Epoch: 6| Step: 10
Training loss: 3.1185455805689193
Validation loss: 2.7137270628240544

Epoch: 6| Step: 11
Training loss: 3.2347305765822556
Validation loss: 2.7105316901443066

Epoch: 6| Step: 12
Training loss: 3.351614144734311
Validation loss: 2.7137465763452573

Epoch: 6| Step: 13
Training loss: 3.664166869932101
Validation loss: 2.71218878844026

Epoch: 79| Step: 0
Training loss: 2.831969288115273
Validation loss: 2.709308039637366

Epoch: 6| Step: 1
Training loss: 2.364882250026
Validation loss: 2.7094174968826445

Epoch: 6| Step: 2
Training loss: 3.254247970314328
Validation loss: 2.706157906455498

Epoch: 6| Step: 3
Training loss: 3.2471239128564737
Validation loss: 2.704810211915769

Epoch: 6| Step: 4
Training loss: 2.9459036883882956
Validation loss: 2.7068722711422355

Epoch: 6| Step: 5
Training loss: 2.851578553037006
Validation loss: 2.7063094371221545

Epoch: 6| Step: 6
Training loss: 3.3761607399319584
Validation loss: 2.7056521456928917

Epoch: 6| Step: 7
Training loss: 3.6032575809539553
Validation loss: 2.7046663744428496

Epoch: 6| Step: 8
Training loss: 2.599198925881767
Validation loss: 2.7022247161968527

Epoch: 6| Step: 9
Training loss: 3.379017169873772
Validation loss: 2.701875419516754

Epoch: 6| Step: 10
Training loss: 3.1068049405259677
Validation loss: 2.7036471929738037

Epoch: 6| Step: 11
Training loss: 2.873112100136995
Validation loss: 2.7052123549447016

Epoch: 6| Step: 12
Training loss: 2.437313366127168
Validation loss: 2.702437722740145

Epoch: 6| Step: 13
Training loss: 3.4704657083259036
Validation loss: 2.7024352059969408

Epoch: 80| Step: 0
Training loss: 2.9638232659945802
Validation loss: 2.7047531229445534

Epoch: 6| Step: 1
Training loss: 2.1045164314873834
Validation loss: 2.7101025642148833

Epoch: 6| Step: 2
Training loss: 3.1040479564796497
Validation loss: 2.717986572410173

Epoch: 6| Step: 3
Training loss: 3.73204842719808
Validation loss: 2.7217127359699025

Epoch: 6| Step: 4
Training loss: 2.644605266487505
Validation loss: 2.7236355854440744

Epoch: 6| Step: 5
Training loss: 3.331183089681133
Validation loss: 2.713288383448172

Epoch: 6| Step: 6
Training loss: 3.1009730011848133
Validation loss: 2.7028307242713234

Epoch: 6| Step: 7
Training loss: 2.992765923510358
Validation loss: 2.7031840390803366

Epoch: 6| Step: 8
Training loss: 2.89464261024819
Validation loss: 2.7033702561967083

Epoch: 6| Step: 9
Training loss: 2.913499547667343
Validation loss: 2.7104488825052564

Epoch: 6| Step: 10
Training loss: 2.7633976992422293
Validation loss: 2.7152723721055425

Epoch: 6| Step: 11
Training loss: 3.605401299900636
Validation loss: 2.7239936150742885

Epoch: 6| Step: 12
Training loss: 3.0809985075603117
Validation loss: 2.7104903296759

Epoch: 6| Step: 13
Training loss: 2.7949780899035277
Validation loss: 2.719572045528878

Epoch: 81| Step: 0
Training loss: 3.4970423599570517
Validation loss: 2.7176844916168914

Epoch: 6| Step: 1
Training loss: 3.4653138333171074
Validation loss: 2.7054816808356574

Epoch: 6| Step: 2
Training loss: 3.5283319350071514
Validation loss: 2.703889965110695

Epoch: 6| Step: 3
Training loss: 3.8614777925280754
Validation loss: 2.6986891843780745

Epoch: 6| Step: 4
Training loss: 2.942073103047706
Validation loss: 2.697868593482657

Epoch: 6| Step: 5
Training loss: 3.1268093211877974
Validation loss: 2.696153603850889

Epoch: 6| Step: 6
Training loss: 3.0887524863603217
Validation loss: 2.693303823283005

Epoch: 6| Step: 7
Training loss: 2.361538532938582
Validation loss: 2.7058523998964876

Epoch: 6| Step: 8
Training loss: 3.1435581763047584
Validation loss: 2.6993164588084446

Epoch: 6| Step: 9
Training loss: 2.700237164854221
Validation loss: 2.7002127762194355

Epoch: 6| Step: 10
Training loss: 2.8018768593728582
Validation loss: 2.69680363190128

Epoch: 6| Step: 11
Training loss: 1.952782562754041
Validation loss: 2.6988527155955144

Epoch: 6| Step: 12
Training loss: 2.693038733236746
Validation loss: 2.6957926156860577

Epoch: 6| Step: 13
Training loss: 2.437047280549115
Validation loss: 2.696707205744586

Epoch: 82| Step: 0
Training loss: 2.499077817586818
Validation loss: 2.698933814003292

Epoch: 6| Step: 1
Training loss: 3.124321978447837
Validation loss: 2.6970240046254146

Epoch: 6| Step: 2
Training loss: 2.8697820664445444
Validation loss: 2.698188473158502

Epoch: 6| Step: 3
Training loss: 2.9658384803012035
Validation loss: 2.6956542400178365

Epoch: 6| Step: 4
Training loss: 3.2503811539378
Validation loss: 2.6998910616474463

Epoch: 6| Step: 5
Training loss: 3.1101938060954675
Validation loss: 2.7032738053737932

Epoch: 6| Step: 6
Training loss: 3.6593781481826233
Validation loss: 2.6978250841877305

Epoch: 6| Step: 7
Training loss: 3.439495409175417
Validation loss: 2.7039562604292677

Epoch: 6| Step: 8
Training loss: 3.1315687188677837
Validation loss: 2.7064472282259553

Epoch: 6| Step: 9
Training loss: 2.9951969480637546
Validation loss: 2.712013137385847

Epoch: 6| Step: 10
Training loss: 2.2068685556045944
Validation loss: 2.7153913643082994

Epoch: 6| Step: 11
Training loss: 3.127333723324234
Validation loss: 2.735050334829805

Epoch: 6| Step: 12
Training loss: 2.7880535277505514
Validation loss: 2.712647944862057

Epoch: 6| Step: 13
Training loss: 2.8776385597256513
Validation loss: 2.7040950758907285

Epoch: 83| Step: 0
Training loss: 3.5973959299480285
Validation loss: 2.7004245876934534

Epoch: 6| Step: 1
Training loss: 3.4601123937091423
Validation loss: 2.6947476302043394

Epoch: 6| Step: 2
Training loss: 2.489100155303093
Validation loss: 2.696064214758323

Epoch: 6| Step: 3
Training loss: 2.9327230367698194
Validation loss: 2.696805516033259

Epoch: 6| Step: 4
Training loss: 2.9695170164582585
Validation loss: 2.7048607807886826

Epoch: 6| Step: 5
Training loss: 2.7727698153715616
Validation loss: 2.7021975334831065

Epoch: 6| Step: 6
Training loss: 2.158473319837132
Validation loss: 2.7178492172995976

Epoch: 6| Step: 7
Training loss: 3.5615265168704124
Validation loss: 2.7400676390141627

Epoch: 6| Step: 8
Training loss: 2.8636824052310312
Validation loss: 2.740997282395529

Epoch: 6| Step: 9
Training loss: 3.336837754285529
Validation loss: 2.7244089591038674

Epoch: 6| Step: 10
Training loss: 2.741227114921537
Validation loss: 2.7016613589970495

Epoch: 6| Step: 11
Training loss: 3.0925722288610586
Validation loss: 2.692358064202809

Epoch: 6| Step: 12
Training loss: 3.3276929977930707
Validation loss: 2.692614451474177

Epoch: 6| Step: 13
Training loss: 2.456757304289326
Validation loss: 2.693676301130589

Epoch: 84| Step: 0
Training loss: 3.3651883237835007
Validation loss: 2.6934674387584887

Epoch: 6| Step: 1
Training loss: 3.037799641464547
Validation loss: 2.6936489807575903

Epoch: 6| Step: 2
Training loss: 3.130143167554744
Validation loss: 2.697463712410075

Epoch: 6| Step: 3
Training loss: 3.300057994448527
Validation loss: 2.6949094818497454

Epoch: 6| Step: 4
Training loss: 2.9330860821238995
Validation loss: 2.6960651390160826

Epoch: 6| Step: 5
Training loss: 2.9188007358495205
Validation loss: 2.695290077547789

Epoch: 6| Step: 6
Training loss: 2.914044500300475
Validation loss: 2.6930396642445618

Epoch: 6| Step: 7
Training loss: 2.8155149618275264
Validation loss: 2.6967173026420754

Epoch: 6| Step: 8
Training loss: 2.542313873770049
Validation loss: 2.696578983931423

Epoch: 6| Step: 9
Training loss: 3.0653612433622124
Validation loss: 2.6928688198727775

Epoch: 6| Step: 10
Training loss: 3.8530602318981164
Validation loss: 2.699351183817932

Epoch: 6| Step: 11
Training loss: 2.2499290031252106
Validation loss: 2.696296587147102

Epoch: 6| Step: 12
Training loss: 2.5360144527697357
Validation loss: 2.6949557388838037

Epoch: 6| Step: 13
Training loss: 3.70615826086332
Validation loss: 2.692485261612595

Epoch: 85| Step: 0
Training loss: 2.8901939276865543
Validation loss: 2.6874080240622957

Epoch: 6| Step: 1
Training loss: 3.5549120486253827
Validation loss: 2.6858240068472967

Epoch: 6| Step: 2
Training loss: 3.4113029308692635
Validation loss: 2.684035116408505

Epoch: 6| Step: 3
Training loss: 3.3488556572741137
Validation loss: 2.688757621009982

Epoch: 6| Step: 4
Training loss: 3.532384369530933
Validation loss: 2.6826164554727083

Epoch: 6| Step: 5
Training loss: 2.510803815396169
Validation loss: 2.6877619593498556

Epoch: 6| Step: 6
Training loss: 3.1271207098577114
Validation loss: 2.6848207221773985

Epoch: 6| Step: 7
Training loss: 2.9319893301110027
Validation loss: 2.6878996864497053

Epoch: 6| Step: 8
Training loss: 2.420755139749734
Validation loss: 2.6866845202704566

Epoch: 6| Step: 9
Training loss: 2.4611169174428187
Validation loss: 2.686226291363574

Epoch: 6| Step: 10
Training loss: 3.186135242980131
Validation loss: 2.6819760949435523

Epoch: 6| Step: 11
Training loss: 2.330267924838683
Validation loss: 2.6811353080718163

Epoch: 6| Step: 12
Training loss: 3.3099090231755945
Validation loss: 2.682959792574227

Epoch: 6| Step: 13
Training loss: 2.798243608685381
Validation loss: 2.684972885110111

Epoch: 86| Step: 0
Training loss: 3.0220846456492163
Validation loss: 2.7039799791252497

Epoch: 6| Step: 1
Training loss: 3.038100063250671
Validation loss: 2.7295299070058525

Epoch: 6| Step: 2
Training loss: 3.11666016671494
Validation loss: 2.74487123624865

Epoch: 6| Step: 3
Training loss: 2.845166031965566
Validation loss: 2.7211560541032553

Epoch: 6| Step: 4
Training loss: 3.3476391572638313
Validation loss: 2.700751656934741

Epoch: 6| Step: 5
Training loss: 3.0319518230505915
Validation loss: 2.6848334877337328

Epoch: 6| Step: 6
Training loss: 3.5763069431500893
Validation loss: 2.680560402222274

Epoch: 6| Step: 7
Training loss: 2.9780409137587407
Validation loss: 2.676329157486188

Epoch: 6| Step: 8
Training loss: 3.45346274817073
Validation loss: 2.6776484572914687

Epoch: 6| Step: 9
Training loss: 3.1329047363097384
Validation loss: 2.677615059317303

Epoch: 6| Step: 10
Training loss: 3.182403229517998
Validation loss: 2.680092137567652

Epoch: 6| Step: 11
Training loss: 2.4340610208628073
Validation loss: 2.6790896881098036

Epoch: 6| Step: 12
Training loss: 2.4142483636606213
Validation loss: 2.679531612721379

Epoch: 6| Step: 13
Training loss: 2.0361179415299273
Validation loss: 2.6775334712635392

Epoch: 87| Step: 0
Training loss: 3.0743684259644115
Validation loss: 2.677435613830674

Epoch: 6| Step: 1
Training loss: 2.975902414096043
Validation loss: 2.675840747717579

Epoch: 6| Step: 2
Training loss: 2.8016185918704144
Validation loss: 2.6800132976031277

Epoch: 6| Step: 3
Training loss: 3.0262264823393688
Validation loss: 2.676289908434423

Epoch: 6| Step: 4
Training loss: 2.8250776702196063
Validation loss: 2.67917103548312

Epoch: 6| Step: 5
Training loss: 3.7296424150239003
Validation loss: 2.6784845155638743

Epoch: 6| Step: 6
Training loss: 1.7884632422957338
Validation loss: 2.678104195615868

Epoch: 6| Step: 7
Training loss: 3.631378744078725
Validation loss: 2.6814044986187655

Epoch: 6| Step: 8
Training loss: 2.933863235063227
Validation loss: 2.682237977301869

Epoch: 6| Step: 9
Training loss: 2.802214570972398
Validation loss: 2.690045692827954

Epoch: 6| Step: 10
Training loss: 2.913430807663865
Validation loss: 2.6879174627738767

Epoch: 6| Step: 11
Training loss: 2.7032674410119872
Validation loss: 2.6886988372434604

Epoch: 6| Step: 12
Training loss: 3.426626868802328
Validation loss: 2.6900433722474317

Epoch: 6| Step: 13
Training loss: 3.1255791699627573
Validation loss: 2.6981031336224888

Epoch: 88| Step: 0
Training loss: 2.851816328065073
Validation loss: 2.693683719821256

Epoch: 6| Step: 1
Training loss: 3.8260980962131255
Validation loss: 2.694314236721481

Epoch: 6| Step: 2
Training loss: 2.9768514818299296
Validation loss: 2.6806840959477247

Epoch: 6| Step: 3
Training loss: 3.275585116467684
Validation loss: 2.674809052233613

Epoch: 6| Step: 4
Training loss: 2.7068638164929575
Validation loss: 2.679561492799635

Epoch: 6| Step: 5
Training loss: 3.3172403641314343
Validation loss: 2.6902675158362372

Epoch: 6| Step: 6
Training loss: 2.694943433178557
Validation loss: 2.693060781281198

Epoch: 6| Step: 7
Training loss: 2.774520963269616
Validation loss: 2.6981224874448717

Epoch: 6| Step: 8
Training loss: 2.5851532360530842
Validation loss: 2.6826206517256623

Epoch: 6| Step: 9
Training loss: 3.116302594086485
Validation loss: 2.677406322833252

Epoch: 6| Step: 10
Training loss: 2.91591554688446
Validation loss: 2.6744114268246504

Epoch: 6| Step: 11
Training loss: 3.129248515826717
Validation loss: 2.67517135013047

Epoch: 6| Step: 12
Training loss: 3.0152926088875542
Validation loss: 2.6820667335411152

Epoch: 6| Step: 13
Training loss: 2.90865431565501
Validation loss: 2.700355489519728

Epoch: 89| Step: 0
Training loss: 2.702394949170774
Validation loss: 2.741376271337594

Epoch: 6| Step: 1
Training loss: 3.0641073563096985
Validation loss: 2.7789614678715195

Epoch: 6| Step: 2
Training loss: 3.0261453336115833
Validation loss: 2.7772817384824817

Epoch: 6| Step: 3
Training loss: 3.494418871458678
Validation loss: 2.7811302158342235

Epoch: 6| Step: 4
Training loss: 2.972910966624886
Validation loss: 2.711102676288823

Epoch: 6| Step: 5
Training loss: 3.020874198549472
Validation loss: 2.6889546400405604

Epoch: 6| Step: 6
Training loss: 2.746760975073552
Validation loss: 2.679368569028741

Epoch: 6| Step: 7
Training loss: 3.6140777204945924
Validation loss: 2.6722224168641877

Epoch: 6| Step: 8
Training loss: 3.2660319243609397
Validation loss: 2.670579702928543

Epoch: 6| Step: 9
Training loss: 2.738312942822122
Validation loss: 2.6722702360589268

Epoch: 6| Step: 10
Training loss: 2.7545307290078176
Validation loss: 2.6703819656656362

Epoch: 6| Step: 11
Training loss: 2.4567252788858482
Validation loss: 2.6708024419713317

Epoch: 6| Step: 12
Training loss: 3.001925803998967
Validation loss: 2.674702648081334

Epoch: 6| Step: 13
Training loss: 3.2707021569515167
Validation loss: 2.671357740020043

Epoch: 90| Step: 0
Training loss: 3.2736682309793457
Validation loss: 2.672391056659101

Epoch: 6| Step: 1
Training loss: 3.0798914144621934
Validation loss: 2.674247256120322

Epoch: 6| Step: 2
Training loss: 2.8471876891815118
Validation loss: 2.6705274903781793

Epoch: 6| Step: 3
Training loss: 2.743130165941785
Validation loss: 2.6713432296640907

Epoch: 6| Step: 4
Training loss: 2.8558419501652628
Validation loss: 2.6665089215131568

Epoch: 6| Step: 5
Training loss: 2.9544432589056053
Validation loss: 2.667076427051685

Epoch: 6| Step: 6
Training loss: 2.4614856896566595
Validation loss: 2.664770200566401

Epoch: 6| Step: 7
Training loss: 2.8856164378798685
Validation loss: 2.6649381719879464

Epoch: 6| Step: 8
Training loss: 3.2111176303355893
Validation loss: 2.670042966050121

Epoch: 6| Step: 9
Training loss: 3.6181228120539894
Validation loss: 2.6728537819505864

Epoch: 6| Step: 10
Training loss: 3.0694939296256623
Validation loss: 2.6772852536162173

Epoch: 6| Step: 11
Training loss: 2.787060614883127
Validation loss: 2.6837425904148513

Epoch: 6| Step: 12
Training loss: 3.0058450977365605
Validation loss: 2.6746372178156452

Epoch: 6| Step: 13
Training loss: 3.245894847151498
Validation loss: 2.6777004208884843

Epoch: 91| Step: 0
Training loss: 2.4444857531245714
Validation loss: 2.677223502271756

Epoch: 6| Step: 1
Training loss: 3.0960356620982075
Validation loss: 2.683366791380201

Epoch: 6| Step: 2
Training loss: 2.8957273248896045
Validation loss: 2.6863045605686224

Epoch: 6| Step: 3
Training loss: 2.639532551707256
Validation loss: 2.6814075896277503

Epoch: 6| Step: 4
Training loss: 2.937965843111197
Validation loss: 2.683131050997798

Epoch: 6| Step: 5
Training loss: 3.22713614991722
Validation loss: 2.6826378370857507

Epoch: 6| Step: 6
Training loss: 3.545984769845476
Validation loss: 2.679929523055597

Epoch: 6| Step: 7
Training loss: 3.128958521869472
Validation loss: 2.684249393506476

Epoch: 6| Step: 8
Training loss: 3.1420538389666928
Validation loss: 2.675971756642894

Epoch: 6| Step: 9
Training loss: 2.8872928693718256
Validation loss: 2.676023357142885

Epoch: 6| Step: 10
Training loss: 2.784486580442182
Validation loss: 2.6701928191111333

Epoch: 6| Step: 11
Training loss: 3.0678965451977245
Validation loss: 2.664121957274881

Epoch: 6| Step: 12
Training loss: 2.814638977479592
Validation loss: 2.6635778679957176

Epoch: 6| Step: 13
Training loss: 3.4915178241430467
Validation loss: 2.661099663887639

Epoch: 92| Step: 0
Training loss: 3.3318858500661594
Validation loss: 2.661814756295229

Epoch: 6| Step: 1
Training loss: 3.4738538155377343
Validation loss: 2.6601630654054294

Epoch: 6| Step: 2
Training loss: 2.9222012098046046
Validation loss: 2.66320366121683

Epoch: 6| Step: 3
Training loss: 3.1368389937938863
Validation loss: 2.6596442062225574

Epoch: 6| Step: 4
Training loss: 3.288377704143772
Validation loss: 2.658417577723741

Epoch: 6| Step: 5
Training loss: 3.1591200668156976
Validation loss: 2.661233761059879

Epoch: 6| Step: 6
Training loss: 2.601755129352644
Validation loss: 2.663204551635849

Epoch: 6| Step: 7
Training loss: 2.7995796978073333
Validation loss: 2.6657851483647215

Epoch: 6| Step: 8
Training loss: 2.1936843644889796
Validation loss: 2.6697836900310494

Epoch: 6| Step: 9
Training loss: 2.8781631318091865
Validation loss: 2.666372410500453

Epoch: 6| Step: 10
Training loss: 3.3969730422708024
Validation loss: 2.663104839220193

Epoch: 6| Step: 11
Training loss: 3.2780100494100384
Validation loss: 2.664086719181881

Epoch: 6| Step: 12
Training loss: 2.743597466958202
Validation loss: 2.6608846324756477

Epoch: 6| Step: 13
Training loss: 2.344727782694393
Validation loss: 2.6590878223861143

Epoch: 93| Step: 0
Training loss: 3.199148398570191
Validation loss: 2.6651486477845534

Epoch: 6| Step: 1
Training loss: 2.999827379982452
Validation loss: 2.6747742510963297

Epoch: 6| Step: 2
Training loss: 2.9614508593976288
Validation loss: 2.6914454814974

Epoch: 6| Step: 3
Training loss: 3.0584372216093287
Validation loss: 2.6914129824616446

Epoch: 6| Step: 4
Training loss: 3.454016246825918
Validation loss: 2.689051021958444

Epoch: 6| Step: 5
Training loss: 2.8870694124276426
Validation loss: 2.6763302925907775

Epoch: 6| Step: 6
Training loss: 3.6680055399096805
Validation loss: 2.667402311793037

Epoch: 6| Step: 7
Training loss: 2.4471095492803747
Validation loss: 2.6621651173456504

Epoch: 6| Step: 8
Training loss: 3.238741815483797
Validation loss: 2.6580630326219628

Epoch: 6| Step: 9
Training loss: 2.3902432005934875
Validation loss: 2.6580472783258657

Epoch: 6| Step: 10
Training loss: 3.007296272664539
Validation loss: 2.6583618194810787

Epoch: 6| Step: 11
Training loss: 3.0820697738502525
Validation loss: 2.6658097038689563

Epoch: 6| Step: 12
Training loss: 2.5192139418348547
Validation loss: 2.668928453930928

Epoch: 6| Step: 13
Training loss: 2.9898962904891633
Validation loss: 2.6673934879184005

Epoch: 94| Step: 0
Training loss: 2.428728803776766
Validation loss: 2.669829529709551

Epoch: 6| Step: 1
Training loss: 3.0842864822934977
Validation loss: 2.673210631056547

Epoch: 6| Step: 2
Training loss: 3.317730067654517
Validation loss: 2.670814487435003

Epoch: 6| Step: 3
Training loss: 2.8511189991158106
Validation loss: 2.6705283927548815

Epoch: 6| Step: 4
Training loss: 2.669751489053928
Validation loss: 2.670471062429336

Epoch: 6| Step: 5
Training loss: 3.458851756262728
Validation loss: 2.6692603150327323

Epoch: 6| Step: 6
Training loss: 2.9487881579806596
Validation loss: 2.668392151583498

Epoch: 6| Step: 7
Training loss: 3.013258880381869
Validation loss: 2.667079523131576

Epoch: 6| Step: 8
Training loss: 3.2113904053495723
Validation loss: 2.6697319535667785

Epoch: 6| Step: 9
Training loss: 3.4931996903323586
Validation loss: 2.665996194839516

Epoch: 6| Step: 10
Training loss: 2.976956238824477
Validation loss: 2.6616662028177673

Epoch: 6| Step: 11
Training loss: 2.8453833950873935
Validation loss: 2.658420260539529

Epoch: 6| Step: 12
Training loss: 3.0144503979128685
Validation loss: 2.65551239524135

Epoch: 6| Step: 13
Training loss: 2.6012361338959384
Validation loss: 2.6537138401571347

Epoch: 95| Step: 0
Training loss: 2.419355891237748
Validation loss: 2.6553429518886214

Epoch: 6| Step: 1
Training loss: 2.734132505290853
Validation loss: 2.662490870477304

Epoch: 6| Step: 2
Training loss: 2.3815608505045094
Validation loss: 2.675201665103887

Epoch: 6| Step: 3
Training loss: 3.013556210565969
Validation loss: 2.6828856139844786

Epoch: 6| Step: 4
Training loss: 4.06848947186073
Validation loss: 2.691218743986552

Epoch: 6| Step: 5
Training loss: 2.781188792723184
Validation loss: 2.672211531869844

Epoch: 6| Step: 6
Training loss: 2.6934594017525417
Validation loss: 2.6594338587156825

Epoch: 6| Step: 7
Training loss: 3.0075962533871916
Validation loss: 2.6580614991031046

Epoch: 6| Step: 8
Training loss: 3.2438750138199905
Validation loss: 2.6522243011992543

Epoch: 6| Step: 9
Training loss: 2.556660674667134
Validation loss: 2.65365006122874

Epoch: 6| Step: 10
Training loss: 3.465159714666054
Validation loss: 2.6522250251827324

Epoch: 6| Step: 11
Training loss: 3.2878476615383807
Validation loss: 2.650300265060674

Epoch: 6| Step: 12
Training loss: 3.0657684634798303
Validation loss: 2.651897317880514

Epoch: 6| Step: 13
Training loss: 2.765149867737035
Validation loss: 2.652208903212797

Epoch: 96| Step: 0
Training loss: 3.11773477974961
Validation loss: 2.650625529403671

Epoch: 6| Step: 1
Training loss: 3.184428511629475
Validation loss: 2.6633603636418934

Epoch: 6| Step: 2
Training loss: 3.270698220606842
Validation loss: 2.660404997131989

Epoch: 6| Step: 3
Training loss: 3.3231981371511163
Validation loss: 2.6565325891302005

Epoch: 6| Step: 4
Training loss: 3.251723492737009
Validation loss: 2.6584422803565997

Epoch: 6| Step: 5
Training loss: 3.1021202220136748
Validation loss: 2.6536582468195684

Epoch: 6| Step: 6
Training loss: 2.5477683717912916
Validation loss: 2.6551796094989792

Epoch: 6| Step: 7
Training loss: 2.983539244580201
Validation loss: 2.652379730795848

Epoch: 6| Step: 8
Training loss: 2.219897336218414
Validation loss: 2.6515974980386776

Epoch: 6| Step: 9
Training loss: 3.416681956435317
Validation loss: 2.654438705619215

Epoch: 6| Step: 10
Training loss: 2.340426721056077
Validation loss: 2.649736436354874

Epoch: 6| Step: 11
Training loss: 3.0785258850228723
Validation loss: 2.6540325649859544

Epoch: 6| Step: 12
Training loss: 2.8654638613257655
Validation loss: 2.6516735921686685

Epoch: 6| Step: 13
Training loss: 2.852718756375839
Validation loss: 2.6522996823806233

Epoch: 97| Step: 0
Training loss: 2.666186696806468
Validation loss: 2.658217193047187

Epoch: 6| Step: 1
Training loss: 2.799715783816959
Validation loss: 2.6590143719742807

Epoch: 6| Step: 2
Training loss: 2.680638625505452
Validation loss: 2.65714877882006

Epoch: 6| Step: 3
Training loss: 2.9283424646810183
Validation loss: 2.664440795649191

Epoch: 6| Step: 4
Training loss: 2.9311822358780013
Validation loss: 2.6687332043281717

Epoch: 6| Step: 5
Training loss: 3.201963930669061
Validation loss: 2.687041367290233

Epoch: 6| Step: 6
Training loss: 2.988050983009324
Validation loss: 2.6992352512769915

Epoch: 6| Step: 7
Training loss: 3.6111165918813994
Validation loss: 2.6688105735274354

Epoch: 6| Step: 8
Training loss: 3.072245448022587
Validation loss: 2.6516821763807017

Epoch: 6| Step: 9
Training loss: 2.831050476723757
Validation loss: 2.6470159849689314

Epoch: 6| Step: 10
Training loss: 2.909808697524455
Validation loss: 2.6470289541492633

Epoch: 6| Step: 11
Training loss: 2.7027187152336656
Validation loss: 2.64782789041558

Epoch: 6| Step: 12
Training loss: 3.1479128265525746
Validation loss: 2.650878403846275

Epoch: 6| Step: 13
Training loss: 3.5989017877769274
Validation loss: 2.6544798056250456

Epoch: 98| Step: 0
Training loss: 2.782513963470656
Validation loss: 2.656112101749684

Epoch: 6| Step: 1
Training loss: 3.612580168471395
Validation loss: 2.6526071187935094

Epoch: 6| Step: 2
Training loss: 3.1066167664783904
Validation loss: 2.6520299040013304

Epoch: 6| Step: 3
Training loss: 3.0477013665531505
Validation loss: 2.6497187309032193

Epoch: 6| Step: 4
Training loss: 3.038994874177296
Validation loss: 2.6483647880430476

Epoch: 6| Step: 5
Training loss: 2.7437915946570883
Validation loss: 2.6502423984912182

Epoch: 6| Step: 6
Training loss: 3.1621472248641918
Validation loss: 2.647526336396082

Epoch: 6| Step: 7
Training loss: 2.1904597286727303
Validation loss: 2.6419844424376304

Epoch: 6| Step: 8
Training loss: 2.9562042168263734
Validation loss: 2.6451182685812995

Epoch: 6| Step: 9
Training loss: 3.453438861098628
Validation loss: 2.6430443218651614

Epoch: 6| Step: 10
Training loss: 2.4364664869972543
Validation loss: 2.6502017425577145

Epoch: 6| Step: 11
Training loss: 3.144773258350361
Validation loss: 2.6601624794662824

Epoch: 6| Step: 12
Training loss: 3.0607765174894177
Validation loss: 2.655454281183742

Epoch: 6| Step: 13
Training loss: 2.900980776975916
Validation loss: 2.664626893679056

Epoch: 99| Step: 0
Training loss: 2.9948345855733485
Validation loss: 2.6587049650032992

Epoch: 6| Step: 1
Training loss: 3.43956264687565
Validation loss: 2.6669790443250987

Epoch: 6| Step: 2
Training loss: 3.0347263812384098
Validation loss: 2.6587989212189034

Epoch: 6| Step: 3
Training loss: 2.5990617893296455
Validation loss: 2.648114124800967

Epoch: 6| Step: 4
Training loss: 2.751989858475562
Validation loss: 2.6479312820581784

Epoch: 6| Step: 5
Training loss: 2.408022339308522
Validation loss: 2.643650537851788

Epoch: 6| Step: 6
Training loss: 2.963939101526648
Validation loss: 2.639477487200419

Epoch: 6| Step: 7
Training loss: 3.0708715497713857
Validation loss: 2.639673982019026

Epoch: 6| Step: 8
Training loss: 3.4422146457150653
Validation loss: 2.6386635632502946

Epoch: 6| Step: 9
Training loss: 2.882030349942256
Validation loss: 2.637149658480676

Epoch: 6| Step: 10
Training loss: 2.465660189726803
Validation loss: 2.6382995936961047

Epoch: 6| Step: 11
Training loss: 3.016393059674767
Validation loss: 2.6394543641163075

Epoch: 6| Step: 12
Training loss: 3.355251602767085
Validation loss: 2.6400152420953815

Epoch: 6| Step: 13
Training loss: 3.140036152917029
Validation loss: 2.640882490797384

Epoch: 100| Step: 0
Training loss: 3.079399967947921
Validation loss: 2.636334744545953

Epoch: 6| Step: 1
Training loss: 3.2932185285328948
Validation loss: 2.6390254425946305

Epoch: 6| Step: 2
Training loss: 2.426162959978992
Validation loss: 2.637912384843536

Epoch: 6| Step: 3
Training loss: 2.9235707630344314
Validation loss: 2.640213846681176

Epoch: 6| Step: 4
Training loss: 2.8449587087199153
Validation loss: 2.638520037403701

Epoch: 6| Step: 5
Training loss: 3.3381900374050124
Validation loss: 2.646844554539627

Epoch: 6| Step: 6
Training loss: 3.4192754198766524
Validation loss: 2.6439835394171824

Epoch: 6| Step: 7
Training loss: 2.756193642245531
Validation loss: 2.6480434835007163

Epoch: 6| Step: 8
Training loss: 2.0555392628387756
Validation loss: 2.6534361680940406

Epoch: 6| Step: 9
Training loss: 3.2886913389152608
Validation loss: 2.6696055705679465

Epoch: 6| Step: 10
Training loss: 2.841668845107809
Validation loss: 2.679191139420851

Epoch: 6| Step: 11
Training loss: 3.232591220073109
Validation loss: 2.6599204562878005

Epoch: 6| Step: 12
Training loss: 3.154990369779033
Validation loss: 2.6461321411953813

Epoch: 6| Step: 13
Training loss: 2.681002725078332
Validation loss: 2.6345783206806854

Epoch: 101| Step: 0
Training loss: 3.3959471950671687
Validation loss: 2.6346581621689573

Epoch: 6| Step: 1
Training loss: 3.3622078240385984
Validation loss: 2.633464212723126

Epoch: 6| Step: 2
Training loss: 3.134294344928283
Validation loss: 2.6360291954303605

Epoch: 6| Step: 3
Training loss: 1.8974630107465835
Validation loss: 2.6378432994009486

Epoch: 6| Step: 4
Training loss: 3.080630294662139
Validation loss: 2.638297823254713

Epoch: 6| Step: 5
Training loss: 2.2883724695884435
Validation loss: 2.6333419697312146

Epoch: 6| Step: 6
Training loss: 2.8972132480182036
Validation loss: 2.631415937499028

Epoch: 6| Step: 7
Training loss: 3.054878248420205
Validation loss: 2.6339664612332863

Epoch: 6| Step: 8
Training loss: 2.853076104604816
Validation loss: 2.642986405068891

Epoch: 6| Step: 9
Training loss: 3.288058818708705
Validation loss: 2.635064610585793

Epoch: 6| Step: 10
Training loss: 3.263422903429903
Validation loss: 2.6447020287264724

Epoch: 6| Step: 11
Training loss: 2.555293113482872
Validation loss: 2.6414961460715376

Epoch: 6| Step: 12
Training loss: 3.304461388033221
Validation loss: 2.6417187889357736

Epoch: 6| Step: 13
Training loss: 2.804599516187206
Validation loss: 2.6373512443455533

Epoch: 102| Step: 0
Training loss: 3.3354396046491694
Validation loss: 2.632316829215502

Epoch: 6| Step: 1
Training loss: 3.023192087706291
Validation loss: 2.630634379515545

Epoch: 6| Step: 2
Training loss: 2.715590120537116
Validation loss: 2.6298636973471585

Epoch: 6| Step: 3
Training loss: 2.7209582951948112
Validation loss: 2.628360962045181

Epoch: 6| Step: 4
Training loss: 2.7545760834871196
Validation loss: 2.6285533898908864

Epoch: 6| Step: 5
Training loss: 2.8997501989180874
Validation loss: 2.631255433733627

Epoch: 6| Step: 6
Training loss: 2.6721027121075895
Validation loss: 2.631983186311463

Epoch: 6| Step: 7
Training loss: 3.100072392264457
Validation loss: 2.629034406174301

Epoch: 6| Step: 8
Training loss: 3.2083209809565036
Validation loss: 2.6295334830594017

Epoch: 6| Step: 9
Training loss: 2.8387952965398435
Validation loss: 2.63225615584854

Epoch: 6| Step: 10
Training loss: 3.4427106725518404
Validation loss: 2.62682025593379

Epoch: 6| Step: 11
Training loss: 3.271528101386883
Validation loss: 2.6273413303636546

Epoch: 6| Step: 12
Training loss: 2.869242002229578
Validation loss: 2.6270356203413434

Epoch: 6| Step: 13
Training loss: 2.4190956164509045
Validation loss: 2.6252271453353107

Epoch: 103| Step: 0
Training loss: 3.402369257133865
Validation loss: 2.632592995255192

Epoch: 6| Step: 1
Training loss: 2.7762548616479235
Validation loss: 2.63302118577019

Epoch: 6| Step: 2
Training loss: 2.9421910914451326
Validation loss: 2.667934263217845

Epoch: 6| Step: 3
Training loss: 2.4605600218929613
Validation loss: 2.7007621240987376

Epoch: 6| Step: 4
Training loss: 3.3248709230537448
Validation loss: 2.761990337568095

Epoch: 6| Step: 5
Training loss: 3.0463754097627285
Validation loss: 2.751770935290258

Epoch: 6| Step: 6
Training loss: 3.5179915537339705
Validation loss: 2.695581855411058

Epoch: 6| Step: 7
Training loss: 3.340431634571949
Validation loss: 2.6351769366785684

Epoch: 6| Step: 8
Training loss: 2.7121313802690925
Validation loss: 2.625672755680443

Epoch: 6| Step: 9
Training loss: 3.232486781825679
Validation loss: 2.630426993591822

Epoch: 6| Step: 10
Training loss: 2.8541859721252507
Validation loss: 2.639259881123034

Epoch: 6| Step: 11
Training loss: 2.571089514071355
Validation loss: 2.644391852619056

Epoch: 6| Step: 12
Training loss: 3.2595312766833144
Validation loss: 2.648547307572246

Epoch: 6| Step: 13
Training loss: 1.891802523547634
Validation loss: 2.6523660792990067

Epoch: 104| Step: 0
Training loss: 2.8293577426513035
Validation loss: 2.649202981100675

Epoch: 6| Step: 1
Training loss: 3.3629418178565156
Validation loss: 2.643295247656094

Epoch: 6| Step: 2
Training loss: 3.064073897772895
Validation loss: 2.6391876837007677

Epoch: 6| Step: 3
Training loss: 1.8711175777694053
Validation loss: 2.6346336335394396

Epoch: 6| Step: 4
Training loss: 2.5911225948857175
Validation loss: 2.6332248342827755

Epoch: 6| Step: 5
Training loss: 3.200740168323894
Validation loss: 2.6296947850651113

Epoch: 6| Step: 6
Training loss: 3.7164848545463314
Validation loss: 2.6365333541172005

Epoch: 6| Step: 7
Training loss: 3.0281271037910327
Validation loss: 2.639955495827931

Epoch: 6| Step: 8
Training loss: 3.0985529444777034
Validation loss: 2.645155844081291

Epoch: 6| Step: 9
Training loss: 3.0707973262447767
Validation loss: 2.6492812728910486

Epoch: 6| Step: 10
Training loss: 2.2215861072324308
Validation loss: 2.649092051995908

Epoch: 6| Step: 11
Training loss: 3.529052320577306
Validation loss: 2.6511681797263025

Epoch: 6| Step: 12
Training loss: 2.77554198462402
Validation loss: 2.6504605218366066

Epoch: 6| Step: 13
Training loss: 3.0719992782274033
Validation loss: 2.648902735319977

Epoch: 105| Step: 0
Training loss: 3.2852116964516807
Validation loss: 2.640428150691751

Epoch: 6| Step: 1
Training loss: 2.3887642993029914
Validation loss: 2.6357623902253717

Epoch: 6| Step: 2
Training loss: 2.7242997625944483
Validation loss: 2.639225923538873

Epoch: 6| Step: 3
Training loss: 3.19102118981145
Validation loss: 2.6350560763388597

Epoch: 6| Step: 4
Training loss: 3.100166833141492
Validation loss: 2.6512086651573714

Epoch: 6| Step: 5
Training loss: 2.860339392951664
Validation loss: 2.6570672618354303

Epoch: 6| Step: 6
Training loss: 2.676276346332661
Validation loss: 2.6478865020028564

Epoch: 6| Step: 7
Training loss: 3.5433205426745755
Validation loss: 2.647273266679898

Epoch: 6| Step: 8
Training loss: 3.1436045922083333
Validation loss: 2.6325591143024165

Epoch: 6| Step: 9
Training loss: 2.3983625468617054
Validation loss: 2.628898044874401

Epoch: 6| Step: 10
Training loss: 3.3391697967669485
Validation loss: 2.6236888151999014

Epoch: 6| Step: 11
Training loss: 3.2619751606737504
Validation loss: 2.6262951218132504

Epoch: 6| Step: 12
Training loss: 2.347580589560495
Validation loss: 2.6248331461281684

Epoch: 6| Step: 13
Training loss: 3.1332532615440716
Validation loss: 2.6266367712542813

Epoch: 106| Step: 0
Training loss: 3.212490328169338
Validation loss: 2.6243019933903717

Epoch: 6| Step: 1
Training loss: 3.5817990825796957
Validation loss: 2.627463977914495

Epoch: 6| Step: 2
Training loss: 2.76401296067684
Validation loss: 2.6210741844050345

Epoch: 6| Step: 3
Training loss: 2.804202237028782
Validation loss: 2.6254262856400183

Epoch: 6| Step: 4
Training loss: 3.098708215872656
Validation loss: 2.6237471638352354

Epoch: 6| Step: 5
Training loss: 3.0185412601306822
Validation loss: 2.6203554407517036

Epoch: 6| Step: 6
Training loss: 2.7980443119142246
Validation loss: 2.619617248325112

Epoch: 6| Step: 7
Training loss: 2.5532356826528715
Validation loss: 2.6218959711052032

Epoch: 6| Step: 8
Training loss: 2.7619046117676067
Validation loss: 2.622114227233325

Epoch: 6| Step: 9
Training loss: 2.955960643067539
Validation loss: 2.6252940218832532

Epoch: 6| Step: 10
Training loss: 3.263609341673509
Validation loss: 2.6343452162417664

Epoch: 6| Step: 11
Training loss: 2.566741317637736
Validation loss: 2.643354982931603

Epoch: 6| Step: 12
Training loss: 3.0568897474857826
Validation loss: 2.645148773880315

Epoch: 6| Step: 13
Training loss: 3.065464997855329
Validation loss: 2.6458210901647776

Epoch: 107| Step: 0
Training loss: 2.6879984371260233
Validation loss: 2.6415836608315315

Epoch: 6| Step: 1
Training loss: 3.207824683224322
Validation loss: 2.6442751945368137

Epoch: 6| Step: 2
Training loss: 3.664757636202494
Validation loss: 2.6484502299046975

Epoch: 6| Step: 3
Training loss: 3.21854140707596
Validation loss: 2.6363856782728563

Epoch: 6| Step: 4
Training loss: 2.9398361007262466
Validation loss: 2.6195272224426893

Epoch: 6| Step: 5
Training loss: 2.497826680611225
Validation loss: 2.615454972934888

Epoch: 6| Step: 6
Training loss: 2.5829714449826393
Validation loss: 2.6179412486158387

Epoch: 6| Step: 7
Training loss: 3.0434942807788863
Validation loss: 2.6152558193390423

Epoch: 6| Step: 8
Training loss: 3.467156121351362
Validation loss: 2.616192287863696

Epoch: 6| Step: 9
Training loss: 2.7797998655443648
Validation loss: 2.617096955605437

Epoch: 6| Step: 10
Training loss: 2.5211877389841195
Validation loss: 2.618001546729069

Epoch: 6| Step: 11
Training loss: 2.988303270445827
Validation loss: 2.616877676572786

Epoch: 6| Step: 12
Training loss: 2.6663506042414546
Validation loss: 2.6122962486752574

Epoch: 6| Step: 13
Training loss: 2.968679969363159
Validation loss: 2.615404713252361

Epoch: 108| Step: 0
Training loss: 3.4228617321086445
Validation loss: 2.6168375279913603

Epoch: 6| Step: 1
Training loss: 3.0869342980691545
Validation loss: 2.621057506977206

Epoch: 6| Step: 2
Training loss: 3.0991338258093792
Validation loss: 2.618247983301505

Epoch: 6| Step: 3
Training loss: 2.8739861068867616
Validation loss: 2.6147191933605973

Epoch: 6| Step: 4
Training loss: 3.0149870677057002
Validation loss: 2.609407819306108

Epoch: 6| Step: 5
Training loss: 2.7229551920151325
Validation loss: 2.609328497170849

Epoch: 6| Step: 6
Training loss: 2.654485767371614
Validation loss: 2.609436492264135

Epoch: 6| Step: 7
Training loss: 3.1890317938754755
Validation loss: 2.6102924705072184

Epoch: 6| Step: 8
Training loss: 2.6439035141115026
Validation loss: 2.612166892477021

Epoch: 6| Step: 9
Training loss: 2.5158913986650355
Validation loss: 2.6094738584963086

Epoch: 6| Step: 10
Training loss: 2.932156836942844
Validation loss: 2.608238131225203

Epoch: 6| Step: 11
Training loss: 3.553977274944959
Validation loss: 2.6126245703978954

Epoch: 6| Step: 12
Training loss: 2.947520109177603
Validation loss: 2.6133946241914203

Epoch: 6| Step: 13
Training loss: 2.356324807353138
Validation loss: 2.619825479186536

Epoch: 109| Step: 0
Training loss: 3.1173542331857527
Validation loss: 2.6319106870017377

Epoch: 6| Step: 1
Training loss: 3.1060414296056575
Validation loss: 2.6243436464492973

Epoch: 6| Step: 2
Training loss: 3.0121386046111276
Validation loss: 2.613819399158279

Epoch: 6| Step: 3
Training loss: 2.7655471532178115
Validation loss: 2.6072123968590617

Epoch: 6| Step: 4
Training loss: 2.8440450997297626
Validation loss: 2.6148801885997073

Epoch: 6| Step: 5
Training loss: 3.1408457512397923
Validation loss: 2.6121144947596147

Epoch: 6| Step: 6
Training loss: 3.1013400288698447
Validation loss: 2.610858784462423

Epoch: 6| Step: 7
Training loss: 2.901384444106793
Validation loss: 2.613699683585192

Epoch: 6| Step: 8
Training loss: 2.835724961904859
Validation loss: 2.6182028071864707

Epoch: 6| Step: 9
Training loss: 2.39286410121272
Validation loss: 2.6082088582945824

Epoch: 6| Step: 10
Training loss: 3.1469915586248645
Validation loss: 2.6107433764944306

Epoch: 6| Step: 11
Training loss: 2.906336137048864
Validation loss: 2.607013092498471

Epoch: 6| Step: 12
Training loss: 2.725684431723139
Validation loss: 2.6070005142699344

Epoch: 6| Step: 13
Training loss: 3.538597362680023
Validation loss: 2.6035550396398106

Epoch: 110| Step: 0
Training loss: 2.4517662999360184
Validation loss: 2.60242529074791

Epoch: 6| Step: 1
Training loss: 3.1190134307973314
Validation loss: 2.6080072414231728

Epoch: 6| Step: 2
Training loss: 2.673868785072513
Validation loss: 2.6052684413905425

Epoch: 6| Step: 3
Training loss: 2.9974083832523073
Validation loss: 2.6065655333734195

Epoch: 6| Step: 4
Training loss: 2.393192782175617
Validation loss: 2.602829777956013

Epoch: 6| Step: 5
Training loss: 3.018348215348368
Validation loss: 2.6012594636614272

Epoch: 6| Step: 6
Training loss: 3.0234231480299707
Validation loss: 2.607194517672247

Epoch: 6| Step: 7
Training loss: 2.9461828913792107
Validation loss: 2.6041486979859334

Epoch: 6| Step: 8
Training loss: 3.0903707216456393
Validation loss: 2.601694606452219

Epoch: 6| Step: 9
Training loss: 3.447123840701451
Validation loss: 2.6051562870732354

Epoch: 6| Step: 10
Training loss: 3.3465604290558186
Validation loss: 2.6016361899056863

Epoch: 6| Step: 11
Training loss: 2.741568731937698
Validation loss: 2.6028398883828396

Epoch: 6| Step: 12
Training loss: 2.4006776568242345
Validation loss: 2.6034548791245706

Epoch: 6| Step: 13
Training loss: 3.795096777685907
Validation loss: 2.6041286044056675

Epoch: 111| Step: 0
Training loss: 2.8012340823346418
Validation loss: 2.6041208853030158

Epoch: 6| Step: 1
Training loss: 3.088234657266161
Validation loss: 2.600463144166369

Epoch: 6| Step: 2
Training loss: 2.3623927944826586
Validation loss: 2.607997749670761

Epoch: 6| Step: 3
Training loss: 2.4330127200018743
Validation loss: 2.608063381247407

Epoch: 6| Step: 4
Training loss: 3.287059327966827
Validation loss: 2.6087782788291847

Epoch: 6| Step: 5
Training loss: 2.962893360918727
Validation loss: 2.6059147522737134

Epoch: 6| Step: 6
Training loss: 3.023305333129471
Validation loss: 2.6113047742519417

Epoch: 6| Step: 7
Training loss: 3.305165357738125
Validation loss: 2.6044866507224387

Epoch: 6| Step: 8
Training loss: 2.874431056243083
Validation loss: 2.6051594390284674

Epoch: 6| Step: 9
Training loss: 2.7148200383969003
Validation loss: 2.6076834377507745

Epoch: 6| Step: 10
Training loss: 3.0020654244101617
Validation loss: 2.600660204148006

Epoch: 6| Step: 11
Training loss: 2.9647097752070937
Validation loss: 2.600826191872954

Epoch: 6| Step: 12
Training loss: 3.3239060287321296
Validation loss: 2.6060165840577407

Epoch: 6| Step: 13
Training loss: 3.105849371083043
Validation loss: 2.609173488959843

Epoch: 112| Step: 0
Training loss: 2.8707785089477946
Validation loss: 2.608500226378966

Epoch: 6| Step: 1
Training loss: 2.9297801092133664
Validation loss: 2.6138676002533505

Epoch: 6| Step: 2
Training loss: 3.134594189480841
Validation loss: 2.613630873289174

Epoch: 6| Step: 3
Training loss: 2.6523773685622545
Validation loss: 2.608619699015958

Epoch: 6| Step: 4
Training loss: 3.019156646192451
Validation loss: 2.6058601835248627

Epoch: 6| Step: 5
Training loss: 3.359373580577462
Validation loss: 2.606891067058109

Epoch: 6| Step: 6
Training loss: 2.8585120394554777
Validation loss: 2.6023260960201897

Epoch: 6| Step: 7
Training loss: 3.1261136931515727
Validation loss: 2.606943055450011

Epoch: 6| Step: 8
Training loss: 3.0325783247554163
Validation loss: 2.6081924612996192

Epoch: 6| Step: 9
Training loss: 2.972675178056526
Validation loss: 2.622115939185169

Epoch: 6| Step: 10
Training loss: 3.120756090445039
Validation loss: 2.6165896398168256

Epoch: 6| Step: 11
Training loss: 2.288163460994637
Validation loss: 2.6252748742950303

Epoch: 6| Step: 12
Training loss: 3.1086029167644122
Validation loss: 2.6339154889976326

Epoch: 6| Step: 13
Training loss: 2.915432605344557
Validation loss: 2.63038818823105

Epoch: 113| Step: 0
Training loss: 2.999490217764893
Validation loss: 2.6175027969902818

Epoch: 6| Step: 1
Training loss: 2.64724137293838
Validation loss: 2.613814891386042

Epoch: 6| Step: 2
Training loss: 2.885908578377684
Validation loss: 2.6118337222896115

Epoch: 6| Step: 3
Training loss: 2.6988019828507537
Validation loss: 2.6158112856541877

Epoch: 6| Step: 4
Training loss: 2.721171123183312
Validation loss: 2.6068403895230925

Epoch: 6| Step: 5
Training loss: 2.984444023252855
Validation loss: 2.598735350861447

Epoch: 6| Step: 6
Training loss: 3.1688020600325455
Validation loss: 2.600164457906664

Epoch: 6| Step: 7
Training loss: 3.188728245474413
Validation loss: 2.598637255847092

Epoch: 6| Step: 8
Training loss: 2.9278340491288577
Validation loss: 2.598856472911358

Epoch: 6| Step: 9
Training loss: 3.1321290143408183
Validation loss: 2.5959471672398338

Epoch: 6| Step: 10
Training loss: 3.137966872050738
Validation loss: 2.5953400363016828

Epoch: 6| Step: 11
Training loss: 2.984186296338974
Validation loss: 2.5968679157880765

Epoch: 6| Step: 12
Training loss: 3.026797140672981
Validation loss: 2.5983453836211408

Epoch: 6| Step: 13
Training loss: 2.462713660251166
Validation loss: 2.6000644517298066

Epoch: 114| Step: 0
Training loss: 2.3615433789658207
Validation loss: 2.5979200916455363

Epoch: 6| Step: 1
Training loss: 3.2793977868444615
Validation loss: 2.6022061088248334

Epoch: 6| Step: 2
Training loss: 3.2969123151213218
Validation loss: 2.600840957653084

Epoch: 6| Step: 3
Training loss: 2.714345938509196
Validation loss: 2.609981002523172

Epoch: 6| Step: 4
Training loss: 2.746502299189929
Validation loss: 2.6082067705879663

Epoch: 6| Step: 5
Training loss: 2.5582188455352313
Validation loss: 2.6196412149072548

Epoch: 6| Step: 6
Training loss: 2.891353371071452
Validation loss: 2.612924025173141

Epoch: 6| Step: 7
Training loss: 3.221018760117262
Validation loss: 2.609510921607504

Epoch: 6| Step: 8
Training loss: 2.944747425381673
Validation loss: 2.6042147632382258

Epoch: 6| Step: 9
Training loss: 2.442536164311789
Validation loss: 2.596587687503956

Epoch: 6| Step: 10
Training loss: 3.183274703625987
Validation loss: 2.5941265725850235

Epoch: 6| Step: 11
Training loss: 3.281894729488119
Validation loss: 2.59405886188333

Epoch: 6| Step: 12
Training loss: 2.7907086811569415
Validation loss: 2.5932408156851476

Epoch: 6| Step: 13
Training loss: 3.540204602810513
Validation loss: 2.5941700566189887

Epoch: 115| Step: 0
Training loss: 3.0553393046602144
Validation loss: 2.5970178436922957

Epoch: 6| Step: 1
Training loss: 2.648731316666646
Validation loss: 2.591093178062214

Epoch: 6| Step: 2
Training loss: 3.261989193971512
Validation loss: 2.5914183800364485

Epoch: 6| Step: 3
Training loss: 2.9288421631988215
Validation loss: 2.5937030351609507

Epoch: 6| Step: 4
Training loss: 2.578498397143156
Validation loss: 2.5916532236850642

Epoch: 6| Step: 5
Training loss: 2.6166772145668165
Validation loss: 2.5931018128641887

Epoch: 6| Step: 6
Training loss: 3.1893332202469074
Validation loss: 2.5907469195602117

Epoch: 6| Step: 7
Training loss: 2.8877651604779624
Validation loss: 2.58958843091673

Epoch: 6| Step: 8
Training loss: 2.928794460244086
Validation loss: 2.592415974728226

Epoch: 6| Step: 9
Training loss: 3.0929826497659065
Validation loss: 2.591339871495753

Epoch: 6| Step: 10
Training loss: 3.2712870159685967
Validation loss: 2.5962945204265093

Epoch: 6| Step: 11
Training loss: 2.507386358544128
Validation loss: 2.5938697645951176

Epoch: 6| Step: 12
Training loss: 3.287427482240296
Validation loss: 2.595291570127499

Epoch: 6| Step: 13
Training loss: 2.6706841921613
Validation loss: 2.595506137085588

Epoch: 116| Step: 0
Training loss: 2.1885996643060572
Validation loss: 2.6036394362442272

Epoch: 6| Step: 1
Training loss: 2.847114668471364
Validation loss: 2.6121259717250354

Epoch: 6| Step: 2
Training loss: 3.0414132487316725
Validation loss: 2.6289056044348302

Epoch: 6| Step: 3
Training loss: 3.289860789359741
Validation loss: 2.6269885479390354

Epoch: 6| Step: 4
Training loss: 1.745684957761847
Validation loss: 2.6052891736608825

Epoch: 6| Step: 5
Training loss: 3.336331132093101
Validation loss: 2.599854618422127

Epoch: 6| Step: 6
Training loss: 2.9021707434451347
Validation loss: 2.594223925054329

Epoch: 6| Step: 7
Training loss: 3.0601601517598627
Validation loss: 2.5923115991570826

Epoch: 6| Step: 8
Training loss: 3.4322583549553976
Validation loss: 2.59260894449494

Epoch: 6| Step: 9
Training loss: 2.915743999771686
Validation loss: 2.5892270511383275

Epoch: 6| Step: 10
Training loss: 2.9401953485685506
Validation loss: 2.590827152968338

Epoch: 6| Step: 11
Training loss: 3.295924334389001
Validation loss: 2.5880149380836563

Epoch: 6| Step: 12
Training loss: 3.1308292189946645
Validation loss: 2.5893979438477546

Epoch: 6| Step: 13
Training loss: 2.340751357290324
Validation loss: 2.5888021357918003

Epoch: 117| Step: 0
Training loss: 3.1951471486480356
Validation loss: 2.590206118599988

Epoch: 6| Step: 1
Training loss: 2.7864318751329775
Validation loss: 2.5929825368015655

Epoch: 6| Step: 2
Training loss: 3.0900023910365064
Validation loss: 2.5892571980795225

Epoch: 6| Step: 3
Training loss: 2.7866146340904407
Validation loss: 2.59300899286474

Epoch: 6| Step: 4
Training loss: 3.4451509814127164
Validation loss: 2.595631514604146

Epoch: 6| Step: 5
Training loss: 3.0934415721317365
Validation loss: 2.5993865308923594

Epoch: 6| Step: 6
Training loss: 2.8597163429177175
Validation loss: 2.5948875276324213

Epoch: 6| Step: 7
Training loss: 2.97564923551193
Validation loss: 2.5969319362215124

Epoch: 6| Step: 8
Training loss: 2.9018677517539344
Validation loss: 2.59974937493124

Epoch: 6| Step: 9
Training loss: 2.5036337193851432
Validation loss: 2.607472665115478

Epoch: 6| Step: 10
Training loss: 3.4564747852811224
Validation loss: 2.60824172962436

Epoch: 6| Step: 11
Training loss: 2.815333486151264
Validation loss: 2.6122087704416295

Epoch: 6| Step: 12
Training loss: 2.6528699125453143
Validation loss: 2.605428799516962

Epoch: 6| Step: 13
Training loss: 1.810678158375749
Validation loss: 2.6078380656136475

Epoch: 118| Step: 0
Training loss: 2.66317519460455
Validation loss: 2.6013255490732115

Epoch: 6| Step: 1
Training loss: 2.5505395281117385
Validation loss: 2.6100729969808167

Epoch: 6| Step: 2
Training loss: 3.50462961544513
Validation loss: 2.617678387808919

Epoch: 6| Step: 3
Training loss: 3.1327819061688054
Validation loss: 2.6274550921162714

Epoch: 6| Step: 4
Training loss: 2.3302123677800437
Validation loss: 2.6206546695225397

Epoch: 6| Step: 5
Training loss: 2.855783677379522
Validation loss: 2.6130900148169647

Epoch: 6| Step: 6
Training loss: 2.5606830016613844
Validation loss: 2.6178321031094023

Epoch: 6| Step: 7
Training loss: 2.716360335446103
Validation loss: 2.6299378926856516

Epoch: 6| Step: 8
Training loss: 2.6331149417115554
Validation loss: 2.612632676500347

Epoch: 6| Step: 9
Training loss: 2.6800677416196796
Validation loss: 2.6086964129230146

Epoch: 6| Step: 10
Training loss: 3.5375366963885897
Validation loss: 2.6044770388486387

Epoch: 6| Step: 11
Training loss: 2.962053637135489
Validation loss: 2.603206220816621

Epoch: 6| Step: 12
Training loss: 3.459437060122531
Validation loss: 2.594462757743214

Epoch: 6| Step: 13
Training loss: 3.3262177496102483
Validation loss: 2.5962274952705138

Epoch: 119| Step: 0
Training loss: 2.3130866672624557
Validation loss: 2.5908140726472255

Epoch: 6| Step: 1
Training loss: 2.789168155496149
Validation loss: 2.5917281864797754

Epoch: 6| Step: 2
Training loss: 2.467659431725514
Validation loss: 2.5892521336793215

Epoch: 6| Step: 3
Training loss: 3.2220129862262574
Validation loss: 2.586216603349181

Epoch: 6| Step: 4
Training loss: 2.4393153155504925
Validation loss: 2.583872118353525

Epoch: 6| Step: 5
Training loss: 2.8564436431619056
Validation loss: 2.5872271421605593

Epoch: 6| Step: 6
Training loss: 2.962599637573195
Validation loss: 2.5837566301504933

Epoch: 6| Step: 7
Training loss: 2.5849432287124805
Validation loss: 2.5839606799224994

Epoch: 6| Step: 8
Training loss: 3.0335087177031252
Validation loss: 2.5822188394391494

Epoch: 6| Step: 9
Training loss: 2.833459028560025
Validation loss: 2.579408558671346

Epoch: 6| Step: 10
Training loss: 3.4774166129540514
Validation loss: 2.5852799387061447

Epoch: 6| Step: 11
Training loss: 3.1260752544655785
Validation loss: 2.580486724589138

Epoch: 6| Step: 12
Training loss: 3.3541289775618526
Validation loss: 2.588485576201605

Epoch: 6| Step: 13
Training loss: 3.636589597053798
Validation loss: 2.5968771599579616

Epoch: 120| Step: 0
Training loss: 2.8481161952264573
Validation loss: 2.595877258266774

Epoch: 6| Step: 1
Training loss: 2.4945822185180204
Validation loss: 2.5930623559960946

Epoch: 6| Step: 2
Training loss: 2.6389263942351016
Validation loss: 2.60019324166695

Epoch: 6| Step: 3
Training loss: 3.379680355239067
Validation loss: 2.600624157417775

Epoch: 6| Step: 4
Training loss: 2.4887049148131517
Validation loss: 2.6022902920537456

Epoch: 6| Step: 5
Training loss: 2.9008624274301558
Validation loss: 2.600812782342851

Epoch: 6| Step: 6
Training loss: 3.404152880811539
Validation loss: 2.6138511151767245

Epoch: 6| Step: 7
Training loss: 3.368273354181452
Validation loss: 2.623386799526153

Epoch: 6| Step: 8
Training loss: 2.9739778766335108
Validation loss: 2.6222749590922407

Epoch: 6| Step: 9
Training loss: 2.854949695257549
Validation loss: 2.6168285247965817

Epoch: 6| Step: 10
Training loss: 2.9408381548011744
Validation loss: 2.6075642614050274

Epoch: 6| Step: 11
Training loss: 2.6932281838403394
Validation loss: 2.6070240284572477

Epoch: 6| Step: 12
Training loss: 3.133829536782879
Validation loss: 2.5786604359149763

Epoch: 6| Step: 13
Training loss: 2.5951052882126344
Validation loss: 2.581712131377826

Epoch: 121| Step: 0
Training loss: 3.2472365441471953
Validation loss: 2.5778110485766907

Epoch: 6| Step: 1
Training loss: 2.483931303889588
Validation loss: 2.5809488512298056

Epoch: 6| Step: 2
Training loss: 2.891695721248539
Validation loss: 2.579208047096089

Epoch: 6| Step: 3
Training loss: 2.7641147433918567
Validation loss: 2.5803106535336724

Epoch: 6| Step: 4
Training loss: 3.2940599617795843
Validation loss: 2.578735869854494

Epoch: 6| Step: 5
Training loss: 2.9431246212683413
Validation loss: 2.578434701007345

Epoch: 6| Step: 6
Training loss: 2.603992232520594
Validation loss: 2.575527889955776

Epoch: 6| Step: 7
Training loss: 2.8859964791195147
Validation loss: 2.576737664948213

Epoch: 6| Step: 8
Training loss: 2.9869488706551715
Validation loss: 2.576269154645187

Epoch: 6| Step: 9
Training loss: 2.6110037100687773
Validation loss: 2.578582558001472

Epoch: 6| Step: 10
Training loss: 3.173690501823892
Validation loss: 2.5838506606018634

Epoch: 6| Step: 11
Training loss: 3.3085910117037813
Validation loss: 2.5897275649016223

Epoch: 6| Step: 12
Training loss: 2.8529447366982588
Validation loss: 2.6006794846604087

Epoch: 6| Step: 13
Training loss: 2.834840336362176
Validation loss: 2.6085739748386843

Epoch: 122| Step: 0
Training loss: 3.0725640735820448
Validation loss: 2.623156278501154

Epoch: 6| Step: 1
Training loss: 2.5946405559466204
Validation loss: 2.610015080306679

Epoch: 6| Step: 2
Training loss: 3.187080954139657
Validation loss: 2.6257714057577197

Epoch: 6| Step: 3
Training loss: 3.5205132303182998
Validation loss: 2.6416946694059065

Epoch: 6| Step: 4
Training loss: 2.5505071846210727
Validation loss: 2.6284255301788426

Epoch: 6| Step: 5
Training loss: 3.27120771917905
Validation loss: 2.5981772126840963

Epoch: 6| Step: 6
Training loss: 2.9816279525617477
Validation loss: 2.599452039639985

Epoch: 6| Step: 7
Training loss: 3.5457140665283697
Validation loss: 2.5919602217728084

Epoch: 6| Step: 8
Training loss: 2.396222909407091
Validation loss: 2.5752567623009224

Epoch: 6| Step: 9
Training loss: 3.0350176805361433
Validation loss: 2.5743611913003965

Epoch: 6| Step: 10
Training loss: 1.8543723631641758
Validation loss: 2.572750223837654

Epoch: 6| Step: 11
Training loss: 2.6914253843205898
Validation loss: 2.5716824825736975

Epoch: 6| Step: 12
Training loss: 3.076880343764006
Validation loss: 2.5717078418989723

Epoch: 6| Step: 13
Training loss: 2.629394848610125
Validation loss: 2.57210051317726

Epoch: 123| Step: 0
Training loss: 2.5037625609305154
Validation loss: 2.5725045251245953

Epoch: 6| Step: 1
Training loss: 2.806140831266079
Validation loss: 2.5768701765532964

Epoch: 6| Step: 2
Training loss: 2.148114433273684
Validation loss: 2.5780935017689837

Epoch: 6| Step: 3
Training loss: 3.1948386589469053
Validation loss: 2.571363895150293

Epoch: 6| Step: 4
Training loss: 2.458328462585107
Validation loss: 2.576595754009644

Epoch: 6| Step: 5
Training loss: 2.8785261009295904
Validation loss: 2.5831856508413065

Epoch: 6| Step: 6
Training loss: 3.1492252547571433
Validation loss: 2.5760785872989413

Epoch: 6| Step: 7
Training loss: 2.9453167093181127
Validation loss: 2.5804204293683544

Epoch: 6| Step: 8
Training loss: 3.158287372774732
Validation loss: 2.5932426050245416

Epoch: 6| Step: 9
Training loss: 3.253871372580938
Validation loss: 2.580834620901845

Epoch: 6| Step: 10
Training loss: 3.053097674619435
Validation loss: 2.583734440171491

Epoch: 6| Step: 11
Training loss: 3.0367306586626546
Validation loss: 2.5876214629279235

Epoch: 6| Step: 12
Training loss: 3.02672624750633
Validation loss: 2.581661072789193

Epoch: 6| Step: 13
Training loss: 3.3647867304654113
Validation loss: 2.5815951195418214

Epoch: 124| Step: 0
Training loss: 2.1869132208611735
Validation loss: 2.5781001850822016

Epoch: 6| Step: 1
Training loss: 3.348467342441314
Validation loss: 2.5809789865961585

Epoch: 6| Step: 2
Training loss: 2.6410460728906
Validation loss: 2.574113345752996

Epoch: 6| Step: 3
Training loss: 3.3353239473460796
Validation loss: 2.575620914923832

Epoch: 6| Step: 4
Training loss: 3.5031827351885383
Validation loss: 2.5725266076781796

Epoch: 6| Step: 5
Training loss: 2.9379817486449933
Validation loss: 2.573331901924585

Epoch: 6| Step: 6
Training loss: 2.514094769903164
Validation loss: 2.5719520577738106

Epoch: 6| Step: 7
Training loss: 2.3222875954989934
Validation loss: 2.5688804070205817

Epoch: 6| Step: 8
Training loss: 3.1278054423790453
Validation loss: 2.56914185332448

Epoch: 6| Step: 9
Training loss: 2.966859556920948
Validation loss: 2.571570854308474

Epoch: 6| Step: 10
Training loss: 3.0585533714308655
Validation loss: 2.5697677578138447

Epoch: 6| Step: 11
Training loss: 2.84739501759599
Validation loss: 2.570471596016613

Epoch: 6| Step: 12
Training loss: 3.2035033956181946
Validation loss: 2.5734582611379606

Epoch: 6| Step: 13
Training loss: 2.311956908916718
Validation loss: 2.574173543134345

Epoch: 125| Step: 0
Training loss: 2.8759306355097776
Validation loss: 2.575602326721915

Epoch: 6| Step: 1
Training loss: 3.164035373147604
Validation loss: 2.577650236415263

Epoch: 6| Step: 2
Training loss: 3.0948259428564233
Validation loss: 2.594159135155282

Epoch: 6| Step: 3
Training loss: 3.1697568539051098
Validation loss: 2.6061635712055313

Epoch: 6| Step: 4
Training loss: 3.0499855791595234
Validation loss: 2.638010974681738

Epoch: 6| Step: 5
Training loss: 2.877876501300617
Validation loss: 2.6291825636672432

Epoch: 6| Step: 6
Training loss: 2.586905030479231
Validation loss: 2.6156951582423695

Epoch: 6| Step: 7
Training loss: 3.0749901624072504
Validation loss: 2.604574905063148

Epoch: 6| Step: 8
Training loss: 2.1796096186243097
Validation loss: 2.572389847063641

Epoch: 6| Step: 9
Training loss: 3.4163070737591488
Validation loss: 2.566920282935387

Epoch: 6| Step: 10
Training loss: 3.1614207601226036
Validation loss: 2.565360227032407

Epoch: 6| Step: 11
Training loss: 2.397514637891458
Validation loss: 2.570651363712928

Epoch: 6| Step: 12
Training loss: 2.653785190286064
Validation loss: 2.5714155151195563

Epoch: 6| Step: 13
Training loss: 3.3076317479658113
Validation loss: 2.572935454949434

Epoch: 126| Step: 0
Training loss: 2.560645572206345
Validation loss: 2.567108738918173

Epoch: 6| Step: 1
Training loss: 2.992865025080418
Validation loss: 2.5658385265891823

Epoch: 6| Step: 2
Training loss: 3.342771297791822
Validation loss: 2.5655886816146847

Epoch: 6| Step: 3
Training loss: 2.544790713955085
Validation loss: 2.5657454886653346

Epoch: 6| Step: 4
Training loss: 3.2364946137207697
Validation loss: 2.567687731272927

Epoch: 6| Step: 5
Training loss: 2.761454222877654
Validation loss: 2.572251073913681

Epoch: 6| Step: 6
Training loss: 2.5797178029822723
Validation loss: 2.5767226317053926

Epoch: 6| Step: 7
Training loss: 3.3335321049234947
Validation loss: 2.58377448597984

Epoch: 6| Step: 8
Training loss: 3.020544279453725
Validation loss: 2.587884685179073

Epoch: 6| Step: 9
Training loss: 3.165125086814982
Validation loss: 2.5839431448498167

Epoch: 6| Step: 10
Training loss: 3.1838592980221425
Validation loss: 2.575726755131761

Epoch: 6| Step: 11
Training loss: 2.165422914001876
Validation loss: 2.572682311257306

Epoch: 6| Step: 12
Training loss: 3.144472413075331
Validation loss: 2.581821730454379

Epoch: 6| Step: 13
Training loss: 2.4389132779677736
Validation loss: 2.5860045350962775

Epoch: 127| Step: 0
Training loss: 2.2505142895715897
Validation loss: 2.5891458126518785

Epoch: 6| Step: 1
Training loss: 3.208720757678492
Validation loss: 2.594965402275816

Epoch: 6| Step: 2
Training loss: 2.7556505239009335
Validation loss: 2.6018140496874396

Epoch: 6| Step: 3
Training loss: 2.9940428397478076
Validation loss: 2.5823438504606844

Epoch: 6| Step: 4
Training loss: 2.8805241793872636
Validation loss: 2.5818275928719694

Epoch: 6| Step: 5
Training loss: 2.7652320367119123
Validation loss: 2.572326631028377

Epoch: 6| Step: 6
Training loss: 2.585912421989426
Validation loss: 2.5777943935823533

Epoch: 6| Step: 7
Training loss: 3.1586791406978003
Validation loss: 2.5910626458323627

Epoch: 6| Step: 8
Training loss: 2.89293846137179
Validation loss: 2.582539632642608

Epoch: 6| Step: 9
Training loss: 2.705956536078598
Validation loss: 2.568808400182599

Epoch: 6| Step: 10
Training loss: 2.769129111897926
Validation loss: 2.5700000166921932

Epoch: 6| Step: 11
Training loss: 2.8943487153561827
Validation loss: 2.5710979216286867

Epoch: 6| Step: 12
Training loss: 3.206178279914836
Validation loss: 2.5726355417814357

Epoch: 6| Step: 13
Training loss: 3.9788405333012427
Validation loss: 2.5699852687336406

Epoch: 128| Step: 0
Training loss: 3.247891989551601
Validation loss: 2.5747131553071396

Epoch: 6| Step: 1
Training loss: 2.7121055351360908
Validation loss: 2.574556253175558

Epoch: 6| Step: 2
Training loss: 3.023175210936023
Validation loss: 2.565890274701593

Epoch: 6| Step: 3
Training loss: 3.1736595508116507
Validation loss: 2.5678470088811363

Epoch: 6| Step: 4
Training loss: 2.7541945286282665
Validation loss: 2.5754308142447506

Epoch: 6| Step: 5
Training loss: 2.9395319627093763
Validation loss: 2.567159169199868

Epoch: 6| Step: 6
Training loss: 2.6595196515379436
Validation loss: 2.5611469949744525

Epoch: 6| Step: 7
Training loss: 2.711799154845263
Validation loss: 2.5649963942597998

Epoch: 6| Step: 8
Training loss: 2.838187005987631
Validation loss: 2.562450451475652

Epoch: 6| Step: 9
Training loss: 2.554853988028765
Validation loss: 2.5719466682412193

Epoch: 6| Step: 10
Training loss: 2.8596759908713634
Validation loss: 2.574597912457769

Epoch: 6| Step: 11
Training loss: 3.174818355140143
Validation loss: 2.5756592604426625

Epoch: 6| Step: 12
Training loss: 3.1442946824833338
Validation loss: 2.5672964496102675

Epoch: 6| Step: 13
Training loss: 3.0464286281602937
Validation loss: 2.5678506339306604

Epoch: 129| Step: 0
Training loss: 3.066686921121909
Validation loss: 2.5713352303460284

Epoch: 6| Step: 1
Training loss: 3.0963088733556914
Validation loss: 2.5692267188102265

Epoch: 6| Step: 2
Training loss: 3.3028874105215924
Validation loss: 2.5597585664811455

Epoch: 6| Step: 3
Training loss: 3.3474793359575927
Validation loss: 2.568234013679993

Epoch: 6| Step: 4
Training loss: 2.76414959017202
Validation loss: 2.577114696061326

Epoch: 6| Step: 5
Training loss: 2.78186336997418
Validation loss: 2.577320916905265

Epoch: 6| Step: 6
Training loss: 2.907038099839081
Validation loss: 2.5831063571445743

Epoch: 6| Step: 7
Training loss: 2.97030406230308
Validation loss: 2.581088890938003

Epoch: 6| Step: 8
Training loss: 3.05063432444699
Validation loss: 2.5780176224259588

Epoch: 6| Step: 9
Training loss: 2.9418419746991105
Validation loss: 2.581066837936885

Epoch: 6| Step: 10
Training loss: 2.969408303605779
Validation loss: 2.5755014603699498

Epoch: 6| Step: 11
Training loss: 2.1008660392631415
Validation loss: 2.572580311968351

Epoch: 6| Step: 12
Training loss: 2.7910709789384893
Validation loss: 2.572004193218553

Epoch: 6| Step: 13
Training loss: 2.203606410895976
Validation loss: 2.569534565539563

Epoch: 130| Step: 0
Training loss: 2.4876206028518317
Validation loss: 2.570944473396607

Epoch: 6| Step: 1
Training loss: 2.8856921196481466
Validation loss: 2.5701778708368446

Epoch: 6| Step: 2
Training loss: 3.3388716147327333
Validation loss: 2.568276734279825

Epoch: 6| Step: 3
Training loss: 2.5815714601315745
Validation loss: 2.571955183637733

Epoch: 6| Step: 4
Training loss: 3.121435497609211
Validation loss: 2.589341838928942

Epoch: 6| Step: 5
Training loss: 2.9178867149822194
Validation loss: 2.594220980183859

Epoch: 6| Step: 6
Training loss: 3.0381256463874737
Validation loss: 2.59678763406045

Epoch: 6| Step: 7
Training loss: 2.5614841587605133
Validation loss: 2.59772595319694

Epoch: 6| Step: 8
Training loss: 2.4411557488673825
Validation loss: 2.6019463877169002

Epoch: 6| Step: 9
Training loss: 2.7020647913508133
Validation loss: 2.5982456093528428

Epoch: 6| Step: 10
Training loss: 3.0354222165181137
Validation loss: 2.5848564086741916

Epoch: 6| Step: 11
Training loss: 3.2606411370142605
Validation loss: 2.575039121715118

Epoch: 6| Step: 12
Training loss: 3.067383589770277
Validation loss: 2.5677324393046765

Epoch: 6| Step: 13
Training loss: 3.336369578054078
Validation loss: 2.565148800131109

Epoch: 131| Step: 0
Training loss: 2.6667264891907934
Validation loss: 2.562996552841478

Epoch: 6| Step: 1
Training loss: 3.4415545047343965
Validation loss: 2.561245113536238

Epoch: 6| Step: 2
Training loss: 2.669279120207538
Validation loss: 2.56069618984247

Epoch: 6| Step: 3
Training loss: 3.4910889674935355
Validation loss: 2.5646377268481286

Epoch: 6| Step: 4
Training loss: 2.938332622295026
Validation loss: 2.564655061047637

Epoch: 6| Step: 5
Training loss: 2.696574659188602
Validation loss: 2.5667123594985886

Epoch: 6| Step: 6
Training loss: 2.4259563880390513
Validation loss: 2.567479417664106

Epoch: 6| Step: 7
Training loss: 2.44877657024462
Validation loss: 2.564145418054325

Epoch: 6| Step: 8
Training loss: 3.343081969082115
Validation loss: 2.558720417232923

Epoch: 6| Step: 9
Training loss: 3.506405554600049
Validation loss: 2.5584379194897573

Epoch: 6| Step: 10
Training loss: 2.9538087406524784
Validation loss: 2.564493028043063

Epoch: 6| Step: 11
Training loss: 2.436235833633283
Validation loss: 2.559290122327168

Epoch: 6| Step: 12
Training loss: 2.694569891754581
Validation loss: 2.5735845095529886

Epoch: 6| Step: 13
Training loss: 2.6724285422354126
Validation loss: 2.589764255287402

Epoch: 132| Step: 0
Training loss: 3.1263989178416507
Validation loss: 2.620396859128339

Epoch: 6| Step: 1
Training loss: 2.468492132312274
Validation loss: 2.642300145250275

Epoch: 6| Step: 2
Training loss: 3.2133767916746767
Validation loss: 2.608995859681895

Epoch: 6| Step: 3
Training loss: 3.028273231807112
Validation loss: 2.6117790887465318

Epoch: 6| Step: 4
Training loss: 3.016048421435627
Validation loss: 2.620438466645389

Epoch: 6| Step: 5
Training loss: 2.798539843623395
Validation loss: 2.592126331439502

Epoch: 6| Step: 6
Training loss: 2.4498119943846324
Validation loss: 2.5765554304637917

Epoch: 6| Step: 7
Training loss: 2.7029502679876667
Validation loss: 2.568964379016723

Epoch: 6| Step: 8
Training loss: 3.0866369299832823
Validation loss: 2.583526039147286

Epoch: 6| Step: 9
Training loss: 3.1478810161706834
Validation loss: 2.577365768671732

Epoch: 6| Step: 10
Training loss: 3.110718709934086
Validation loss: 2.579073573146744

Epoch: 6| Step: 11
Training loss: 2.974581001331765
Validation loss: 2.5551462229815076

Epoch: 6| Step: 12
Training loss: 2.709700684293731
Validation loss: 2.55407033234522

Epoch: 6| Step: 13
Training loss: 2.677352822441178
Validation loss: 2.5537257197130323

Epoch: 133| Step: 0
Training loss: 3.0461449946798793
Validation loss: 2.5511986939387996

Epoch: 6| Step: 1
Training loss: 3.100771401933451
Validation loss: 2.5501425004166736

Epoch: 6| Step: 2
Training loss: 2.793927392298787
Validation loss: 2.552226150531363

Epoch: 6| Step: 3
Training loss: 3.054125019394956
Validation loss: 2.5515788005050997

Epoch: 6| Step: 4
Training loss: 2.712003734563546
Validation loss: 2.548637128321643

Epoch: 6| Step: 5
Training loss: 2.6248373253688806
Validation loss: 2.5536801681369914

Epoch: 6| Step: 6
Training loss: 2.686477466607317
Validation loss: 2.5507608717001506

Epoch: 6| Step: 7
Training loss: 2.4400512841572874
Validation loss: 2.5523594204451645

Epoch: 6| Step: 8
Training loss: 3.256035995040745
Validation loss: 2.577313780974594

Epoch: 6| Step: 9
Training loss: 3.1722667433388314
Validation loss: 2.629781374558671

Epoch: 6| Step: 10
Training loss: 3.006911739869454
Validation loss: 2.628414302875637

Epoch: 6| Step: 11
Training loss: 2.727312394778449
Validation loss: 2.6254621197605625

Epoch: 6| Step: 12
Training loss: 2.9827365072250687
Validation loss: 2.6173270308171315

Epoch: 6| Step: 13
Training loss: 3.2588770016884325
Validation loss: 2.615199083014775

Epoch: 134| Step: 0
Training loss: 2.8832921401886815
Validation loss: 2.5494573242501404

Epoch: 6| Step: 1
Training loss: 2.8384957872701846
Validation loss: 2.5478844266949325

Epoch: 6| Step: 2
Training loss: 2.313202003943314
Validation loss: 2.579126477122632

Epoch: 6| Step: 3
Training loss: 2.9541461127839073
Validation loss: 2.6245524195276495

Epoch: 6| Step: 4
Training loss: 2.914097517278713
Validation loss: 2.6601377658232823

Epoch: 6| Step: 5
Training loss: 2.813620789051019
Validation loss: 2.6573939235087702

Epoch: 6| Step: 6
Training loss: 2.9261935545811166
Validation loss: 2.6456333660058973

Epoch: 6| Step: 7
Training loss: 3.3730652526460854
Validation loss: 2.641220786705124

Epoch: 6| Step: 8
Training loss: 3.5170499499355703
Validation loss: 2.6194731858544027

Epoch: 6| Step: 9
Training loss: 2.884966616644011
Validation loss: 2.6067485553700465

Epoch: 6| Step: 10
Training loss: 3.470371726405342
Validation loss: 2.6208547128580424

Epoch: 6| Step: 11
Training loss: 2.148013985245568
Validation loss: 2.630128221602563

Epoch: 6| Step: 12
Training loss: 3.5247292867828843
Validation loss: 2.6388538204627032

Epoch: 6| Step: 13
Training loss: 3.033433265576974
Validation loss: 2.6290347845232844

Epoch: 135| Step: 0
Training loss: 2.3041867504198845
Validation loss: 2.6261869345886426

Epoch: 6| Step: 1
Training loss: 3.2523287719410994
Validation loss: 2.6429000057099414

Epoch: 6| Step: 2
Training loss: 2.604607526973665
Validation loss: 2.6383068212046767

Epoch: 6| Step: 3
Training loss: 2.8040578661401763
Validation loss: 2.6339575272936755

Epoch: 6| Step: 4
Training loss: 2.729784441811273
Validation loss: 2.6166673075049

Epoch: 6| Step: 5
Training loss: 3.358672170528775
Validation loss: 2.6076258789525624

Epoch: 6| Step: 6
Training loss: 2.9788175436118745
Validation loss: 2.6075325947635415

Epoch: 6| Step: 7
Training loss: 2.685148585521957
Validation loss: 2.6075351726267817

Epoch: 6| Step: 8
Training loss: 2.969723190611782
Validation loss: 2.6001176276627422

Epoch: 6| Step: 9
Training loss: 3.13813478044005
Validation loss: 2.6057278258524463

Epoch: 6| Step: 10
Training loss: 3.122280921550169
Validation loss: 2.6138289492149025

Epoch: 6| Step: 11
Training loss: 2.456616389391157
Validation loss: 2.59966370614013

Epoch: 6| Step: 12
Training loss: 3.3692314865465276
Validation loss: 2.5929362966220593

Epoch: 6| Step: 13
Training loss: 3.4175568948291892
Validation loss: 2.5944509398006583

Epoch: 136| Step: 0
Training loss: 3.1323159602019928
Validation loss: 2.5882813651333847

Epoch: 6| Step: 1
Training loss: 2.158755408690568
Validation loss: 2.5787596994303836

Epoch: 6| Step: 2
Training loss: 2.899084466257007
Validation loss: 2.5873115482021265

Epoch: 6| Step: 3
Training loss: 3.0026700535625825
Validation loss: 2.5772240261098593

Epoch: 6| Step: 4
Training loss: 3.0510575759141236
Validation loss: 2.5747280439589133

Epoch: 6| Step: 5
Training loss: 3.3372368526658422
Validation loss: 2.5756870738992887

Epoch: 6| Step: 6
Training loss: 3.30380605210591
Validation loss: 2.5728774117357345

Epoch: 6| Step: 7
Training loss: 2.763811281819667
Validation loss: 2.572974594744134

Epoch: 6| Step: 8
Training loss: 3.1338549470617867
Validation loss: 2.5771142046440842

Epoch: 6| Step: 9
Training loss: 3.072743935768128
Validation loss: 2.570198962965547

Epoch: 6| Step: 10
Training loss: 2.6792298751976493
Validation loss: 2.569975974718114

Epoch: 6| Step: 11
Training loss: 1.9523610566506706
Validation loss: 2.580299817968801

Epoch: 6| Step: 12
Training loss: 3.4173847157275232
Validation loss: 2.5726028627323534

Epoch: 6| Step: 13
Training loss: 2.6873902586776084
Validation loss: 2.5777709240492834

Epoch: 137| Step: 0
Training loss: 2.039619691217519
Validation loss: 2.582500115158437

Epoch: 6| Step: 1
Training loss: 2.7316581089459055
Validation loss: 2.5927286194138013

Epoch: 6| Step: 2
Training loss: 2.5819964384886203
Validation loss: 2.6007911252734535

Epoch: 6| Step: 3
Training loss: 3.2003508673477197
Validation loss: 2.6214868364996975

Epoch: 6| Step: 4
Training loss: 3.4123701357322456
Validation loss: 2.602320206880822

Epoch: 6| Step: 5
Training loss: 3.248139215511288
Validation loss: 2.5666712624112256

Epoch: 6| Step: 6
Training loss: 2.7183780634989057
Validation loss: 2.561991702453664

Epoch: 6| Step: 7
Training loss: 2.7357488178263516
Validation loss: 2.5559839899674555

Epoch: 6| Step: 8
Training loss: 3.074285600994471
Validation loss: 2.550446926210933

Epoch: 6| Step: 9
Training loss: 3.1971129029652112
Validation loss: 2.546778425606079

Epoch: 6| Step: 10
Training loss: 2.5171533526632768
Validation loss: 2.5503924120757624

Epoch: 6| Step: 11
Training loss: 2.533925279257819
Validation loss: 2.5435316425810686

Epoch: 6| Step: 12
Training loss: 3.161446853608474
Validation loss: 2.5460527709506233

Epoch: 6| Step: 13
Training loss: 3.563445785527548
Validation loss: 2.5426134771444917

Epoch: 138| Step: 0
Training loss: 2.435227924622424
Validation loss: 2.545948729059708

Epoch: 6| Step: 1
Training loss: 2.4592159001657277
Validation loss: 2.5427171085418294

Epoch: 6| Step: 2
Training loss: 3.4361292099910776
Validation loss: 2.549228513647282

Epoch: 6| Step: 3
Training loss: 2.9294212118564666
Validation loss: 2.548500460843001

Epoch: 6| Step: 4
Training loss: 3.016804992988883
Validation loss: 2.5512082804464167

Epoch: 6| Step: 5
Training loss: 2.6753370375745034
Validation loss: 2.557129359902251

Epoch: 6| Step: 6
Training loss: 3.214177114680542
Validation loss: 2.5673804988761804

Epoch: 6| Step: 7
Training loss: 2.7190969837677748
Validation loss: 2.562215079397943

Epoch: 6| Step: 8
Training loss: 3.2035522176036224
Validation loss: 2.5469910332052756

Epoch: 6| Step: 9
Training loss: 3.188999346977351
Validation loss: 2.5488838604289854

Epoch: 6| Step: 10
Training loss: 2.728297864543184
Validation loss: 2.5402615975597884

Epoch: 6| Step: 11
Training loss: 2.6871698753399134
Validation loss: 2.547496119741425

Epoch: 6| Step: 12
Training loss: 3.3123643955328865
Validation loss: 2.536766508729971

Epoch: 6| Step: 13
Training loss: 2.0268550570457
Validation loss: 2.543012964138906

Epoch: 139| Step: 0
Training loss: 2.68855069935013
Validation loss: 2.5434964004019878

Epoch: 6| Step: 1
Training loss: 2.8624914310776832
Validation loss: 2.5409739730690175

Epoch: 6| Step: 2
Training loss: 2.8181609085851087
Validation loss: 2.5412512274465278

Epoch: 6| Step: 3
Training loss: 2.921122244904813
Validation loss: 2.54460790427521

Epoch: 6| Step: 4
Training loss: 3.147427910546547
Validation loss: 2.5442484041026137

Epoch: 6| Step: 5
Training loss: 2.4922707283687875
Validation loss: 2.5446570275004388

Epoch: 6| Step: 6
Training loss: 2.9229045828698417
Validation loss: 2.5488952771200846

Epoch: 6| Step: 7
Training loss: 2.7772979947169407
Validation loss: 2.5698315286079674

Epoch: 6| Step: 8
Training loss: 3.1297044057479932
Validation loss: 2.5721212147794907

Epoch: 6| Step: 9
Training loss: 3.091734875306188
Validation loss: 2.5717801024925757

Epoch: 6| Step: 10
Training loss: 3.1419017720642213
Validation loss: 2.5815250850723483

Epoch: 6| Step: 11
Training loss: 2.7901610874173186
Validation loss: 2.621218806343136

Epoch: 6| Step: 12
Training loss: 2.2305906032006217
Validation loss: 2.6433102475520025

Epoch: 6| Step: 13
Training loss: 4.07356422265247
Validation loss: 2.7436561948346636

Epoch: 140| Step: 0
Training loss: 2.7491749479506935
Validation loss: 2.65372473726539

Epoch: 6| Step: 1
Training loss: 2.5203058515864245
Validation loss: 2.6014866370567584

Epoch: 6| Step: 2
Training loss: 3.146734415984484
Validation loss: 2.550046886203664

Epoch: 6| Step: 3
Training loss: 3.013715861129907
Validation loss: 2.543424609286082

Epoch: 6| Step: 4
Training loss: 2.972892360859675
Validation loss: 2.540680070657178

Epoch: 6| Step: 5
Training loss: 3.24802984530262
Validation loss: 2.5448401066536084

Epoch: 6| Step: 6
Training loss: 3.0659369042679514
Validation loss: 2.5558977910741114

Epoch: 6| Step: 7
Training loss: 2.9975221255442706
Validation loss: 2.5625964410953443

Epoch: 6| Step: 8
Training loss: 2.7131612929680675
Validation loss: 2.5668307728823376

Epoch: 6| Step: 9
Training loss: 2.842072715349827
Validation loss: 2.569084705319222

Epoch: 6| Step: 10
Training loss: 3.3014402194471137
Validation loss: 2.565663586601972

Epoch: 6| Step: 11
Training loss: 2.1194591089521553
Validation loss: 2.566573845722206

Epoch: 6| Step: 12
Training loss: 2.9606450321420934
Validation loss: 2.56079129531087

Epoch: 6| Step: 13
Training loss: 3.360313390921311
Validation loss: 2.5593355970947913

Epoch: 141| Step: 0
Training loss: 3.245874868052929
Validation loss: 2.5577055215249587

Epoch: 6| Step: 1
Training loss: 3.115661553538627
Validation loss: 2.554235755547944

Epoch: 6| Step: 2
Training loss: 2.891574682995213
Validation loss: 2.550698516669341

Epoch: 6| Step: 3
Training loss: 2.256099592357568
Validation loss: 2.5445346947145993

Epoch: 6| Step: 4
Training loss: 3.29766706018906
Validation loss: 2.5466757743678814

Epoch: 6| Step: 5
Training loss: 2.695164242412529
Validation loss: 2.5399361843111743

Epoch: 6| Step: 6
Training loss: 3.3733943369278654
Validation loss: 2.540574851127207

Epoch: 6| Step: 7
Training loss: 2.61431855055283
Validation loss: 2.534461990133413

Epoch: 6| Step: 8
Training loss: 3.013621875597871
Validation loss: 2.539757458510634

Epoch: 6| Step: 9
Training loss: 2.8073191078180115
Validation loss: 2.5554355432949256

Epoch: 6| Step: 10
Training loss: 2.556690422488196
Validation loss: 2.550081357757925

Epoch: 6| Step: 11
Training loss: 3.28534914736327
Validation loss: 2.553764129977519

Epoch: 6| Step: 12
Training loss: 3.0323877460682502
Validation loss: 2.5585534593656383

Epoch: 6| Step: 13
Training loss: 2.0099587454286705
Validation loss: 2.5747339145626027

Epoch: 142| Step: 0
Training loss: 2.7310959691799725
Validation loss: 2.571815216765539

Epoch: 6| Step: 1
Training loss: 2.7016952349662167
Validation loss: 2.578055793079425

Epoch: 6| Step: 2
Training loss: 3.168584460386843
Validation loss: 2.6071140160562845

Epoch: 6| Step: 3
Training loss: 3.453295120950831
Validation loss: 2.614731150103848

Epoch: 6| Step: 4
Training loss: 2.590624845387416
Validation loss: 2.596366490708505

Epoch: 6| Step: 5
Training loss: 2.4409384317412166
Validation loss: 2.5516761366201193

Epoch: 6| Step: 6
Training loss: 2.925340688052302
Validation loss: 2.540781671605725

Epoch: 6| Step: 7
Training loss: 2.881816578266473
Validation loss: 2.5430772032171927

Epoch: 6| Step: 8
Training loss: 3.0162495178905218
Validation loss: 2.5351152278786113

Epoch: 6| Step: 9
Training loss: 3.1868168715932343
Validation loss: 2.5312031891349487

Epoch: 6| Step: 10
Training loss: 3.1464145115129503
Validation loss: 2.5321333870632947

Epoch: 6| Step: 11
Training loss: 2.6464294202666045
Validation loss: 2.5336910890442867

Epoch: 6| Step: 12
Training loss: 2.7516634851626374
Validation loss: 2.534500736844909

Epoch: 6| Step: 13
Training loss: 2.927664991985567
Validation loss: 2.5320243972573353

Epoch: 143| Step: 0
Training loss: 2.6516617584982316
Validation loss: 2.5346040652561315

Epoch: 6| Step: 1
Training loss: 2.808440775943118
Validation loss: 2.5329925229199235

Epoch: 6| Step: 2
Training loss: 2.361821100286709
Validation loss: 2.5334841299053408

Epoch: 6| Step: 3
Training loss: 2.8335741352152306
Validation loss: 2.5388367199593613

Epoch: 6| Step: 4
Training loss: 3.0996933693132696
Validation loss: 2.5441515818787073

Epoch: 6| Step: 5
Training loss: 3.2003876689690975
Validation loss: 2.547537451696045

Epoch: 6| Step: 6
Training loss: 2.3246690329971864
Validation loss: 2.544716809485486

Epoch: 6| Step: 7
Training loss: 2.8858930467652755
Validation loss: 2.5535227697680596

Epoch: 6| Step: 8
Training loss: 2.9603135551161626
Validation loss: 2.5544909119076835

Epoch: 6| Step: 9
Training loss: 3.8544813010518926
Validation loss: 2.582424866125262

Epoch: 6| Step: 10
Training loss: 2.3051699375885737
Validation loss: 2.5764507894757678

Epoch: 6| Step: 11
Training loss: 3.429443350684866
Validation loss: 2.5692445668578254

Epoch: 6| Step: 12
Training loss: 2.389330544663119
Validation loss: 2.5610430117216376

Epoch: 6| Step: 13
Training loss: 3.254385117261797
Validation loss: 2.5619399746604916

Epoch: 144| Step: 0
Training loss: 2.704193785952187
Validation loss: 2.576413249781525

Epoch: 6| Step: 1
Training loss: 3.2267686533245046
Validation loss: 2.597241957555528

Epoch: 6| Step: 2
Training loss: 2.9386805333308246
Validation loss: 2.583839818054315

Epoch: 6| Step: 3
Training loss: 2.608327963907811
Validation loss: 2.5650893823974137

Epoch: 6| Step: 4
Training loss: 3.0315288926650505
Validation loss: 2.5542576568005413

Epoch: 6| Step: 5
Training loss: 3.0239601176422317
Validation loss: 2.542863613073783

Epoch: 6| Step: 6
Training loss: 2.875505983360034
Validation loss: 2.537867149254767

Epoch: 6| Step: 7
Training loss: 2.58536857500824
Validation loss: 2.539982448672594

Epoch: 6| Step: 8
Training loss: 2.7566599396143445
Validation loss: 2.5328850589445877

Epoch: 6| Step: 9
Training loss: 3.1398891516879535
Validation loss: 2.5320695972907528

Epoch: 6| Step: 10
Training loss: 3.0879417381423537
Validation loss: 2.534669115206277

Epoch: 6| Step: 11
Training loss: 2.991699497676766
Validation loss: 2.539634322402985

Epoch: 6| Step: 12
Training loss: 2.533898745566445
Validation loss: 2.5391706990425784

Epoch: 6| Step: 13
Training loss: 3.230599674030383
Validation loss: 2.5369597329789744

Epoch: 145| Step: 0
Training loss: 3.04180987992035
Validation loss: 2.5361385217538452

Epoch: 6| Step: 1
Training loss: 2.776319956235169
Validation loss: 2.5461351105191894

Epoch: 6| Step: 2
Training loss: 2.6784236140564937
Validation loss: 2.5428773382729015

Epoch: 6| Step: 3
Training loss: 2.8046689683732304
Validation loss: 2.5431542278891253

Epoch: 6| Step: 4
Training loss: 3.0350428183235927
Validation loss: 2.537902336769938

Epoch: 6| Step: 5
Training loss: 2.3449824843738734
Validation loss: 2.539364655014303

Epoch: 6| Step: 6
Training loss: 2.8613962835845417
Validation loss: 2.546542654995863

Epoch: 6| Step: 7
Training loss: 2.6542561845839407
Validation loss: 2.541930281996746

Epoch: 6| Step: 8
Training loss: 3.1701703682253766
Validation loss: 2.550099769070555

Epoch: 6| Step: 9
Training loss: 3.305109957483213
Validation loss: 2.5528844922347886

Epoch: 6| Step: 10
Training loss: 3.0504214261434757
Validation loss: 2.5771011412671916

Epoch: 6| Step: 11
Training loss: 2.3539825862606665
Validation loss: 2.570698792571604

Epoch: 6| Step: 12
Training loss: 3.5336854351394384
Validation loss: 2.581540170787118

Epoch: 6| Step: 13
Training loss: 2.7526206620852025
Validation loss: 2.6018792470492125

Epoch: 146| Step: 0
Training loss: 2.1543548659182554
Validation loss: 2.5863376693573885

Epoch: 6| Step: 1
Training loss: 3.120181832516937
Validation loss: 2.589577153040537

Epoch: 6| Step: 2
Training loss: 3.6457237590490754
Validation loss: 2.5703243062471035

Epoch: 6| Step: 3
Training loss: 2.8876588191492685
Validation loss: 2.5592159874479345

Epoch: 6| Step: 4
Training loss: 3.0661308407869203
Validation loss: 2.5670686797973343

Epoch: 6| Step: 5
Training loss: 2.439299188403935
Validation loss: 2.5705772004527345

Epoch: 6| Step: 6
Training loss: 2.835168991838101
Validation loss: 2.6037162023635467

Epoch: 6| Step: 7
Training loss: 2.8532781587001868
Validation loss: 2.6261975866825638

Epoch: 6| Step: 8
Training loss: 2.4114345826750094
Validation loss: 2.6133532792618923

Epoch: 6| Step: 9
Training loss: 3.2348762160708375
Validation loss: 2.5988853550054105

Epoch: 6| Step: 10
Training loss: 2.465571614933685
Validation loss: 2.607563454725975

Epoch: 6| Step: 11
Training loss: 2.879206027154319
Validation loss: 2.616025994295094

Epoch: 6| Step: 12
Training loss: 3.2439898157865352
Validation loss: 2.6234333458325048

Epoch: 6| Step: 13
Training loss: 3.43612171631635
Validation loss: 2.6374853704019854

Epoch: 147| Step: 0
Training loss: 2.9026345355046166
Validation loss: 2.597357141269193

Epoch: 6| Step: 1
Training loss: 2.546565873746174
Validation loss: 2.5808026352258406

Epoch: 6| Step: 2
Training loss: 3.2933187242201925
Validation loss: 2.5821131988195463

Epoch: 6| Step: 3
Training loss: 2.940029272854973
Validation loss: 2.5645643073522697

Epoch: 6| Step: 4
Training loss: 2.6607823020309778
Validation loss: 2.545244746154765

Epoch: 6| Step: 5
Training loss: 2.6307411988584306
Validation loss: 2.5449000152952834

Epoch: 6| Step: 6
Training loss: 3.2758876034525515
Validation loss: 2.5403608719673905

Epoch: 6| Step: 7
Training loss: 2.7106458523550523
Validation loss: 2.533469345956815

Epoch: 6| Step: 8
Training loss: 3.1903971053585747
Validation loss: 2.5347154686238893

Epoch: 6| Step: 9
Training loss: 2.6572487243827294
Validation loss: 2.5353035928795706

Epoch: 6| Step: 10
Training loss: 3.423338973187113
Validation loss: 2.534899160611591

Epoch: 6| Step: 11
Training loss: 2.8294037514976997
Validation loss: 2.533542942047159

Epoch: 6| Step: 12
Training loss: 2.6921393692930367
Validation loss: 2.5366065105081526

Epoch: 6| Step: 13
Training loss: 2.724397078142628
Validation loss: 2.5297742557749783

Epoch: 148| Step: 0
Training loss: 3.2448090399230596
Validation loss: 2.5279666272362356

Epoch: 6| Step: 1
Training loss: 2.934292442127283
Validation loss: 2.5251494005357316

Epoch: 6| Step: 2
Training loss: 2.944155356972728
Validation loss: 2.522351514505839

Epoch: 6| Step: 3
Training loss: 2.7954565958888167
Validation loss: 2.5219144225913275

Epoch: 6| Step: 4
Training loss: 2.7156565814711455
Validation loss: 2.520743430912631

Epoch: 6| Step: 5
Training loss: 2.8603258896935966
Validation loss: 2.5230149283848538

Epoch: 6| Step: 6
Training loss: 2.5376731475235554
Validation loss: 2.526106293010898

Epoch: 6| Step: 7
Training loss: 3.268657243918771
Validation loss: 2.526466123040897

Epoch: 6| Step: 8
Training loss: 2.9721412964575555
Validation loss: 2.5276985924207325

Epoch: 6| Step: 9
Training loss: 3.0139963762733633
Validation loss: 2.525617267531751

Epoch: 6| Step: 10
Training loss: 2.344656095196571
Validation loss: 2.5264952157395077

Epoch: 6| Step: 11
Training loss: 2.8843938527260877
Validation loss: 2.5346032439536796

Epoch: 6| Step: 12
Training loss: 2.589885636533213
Validation loss: 2.5352100036889618

Epoch: 6| Step: 13
Training loss: 3.5403578789626358
Validation loss: 2.531906680810184

Epoch: 149| Step: 0
Training loss: 3.354600361019673
Validation loss: 2.5399884954674343

Epoch: 6| Step: 1
Training loss: 2.974818562336332
Validation loss: 2.5374101713114

Epoch: 6| Step: 2
Training loss: 3.0278666383106327
Validation loss: 2.546800157454043

Epoch: 6| Step: 3
Training loss: 3.0274921208601215
Validation loss: 2.5592078193373866

Epoch: 6| Step: 4
Training loss: 2.206280984201695
Validation loss: 2.5507628848132664

Epoch: 6| Step: 5
Training loss: 2.6877767730846984
Validation loss: 2.5609210462381418

Epoch: 6| Step: 6
Training loss: 3.212715640419153
Validation loss: 2.5700616346019616

Epoch: 6| Step: 7
Training loss: 2.640378500363746
Validation loss: 2.551087097908523

Epoch: 6| Step: 8
Training loss: 3.283996595076586
Validation loss: 2.5495094460837144

Epoch: 6| Step: 9
Training loss: 2.9698895325330232
Validation loss: 2.5364182068916525

Epoch: 6| Step: 10
Training loss: 2.856762635953276
Validation loss: 2.533788866457229

Epoch: 6| Step: 11
Training loss: 2.9275118874977144
Validation loss: 2.526534878113687

Epoch: 6| Step: 12
Training loss: 2.16205445920266
Validation loss: 2.524528962016455

Epoch: 6| Step: 13
Training loss: 2.7660476447833777
Validation loss: 2.523620915773723

Epoch: 150| Step: 0
Training loss: 2.601049974148436
Validation loss: 2.532236909265236

Epoch: 6| Step: 1
Training loss: 3.161148198526041
Validation loss: 2.524007205853001

Epoch: 6| Step: 2
Training loss: 3.3817829212744472
Validation loss: 2.524132947716206

Epoch: 6| Step: 3
Training loss: 2.5685537518533006
Validation loss: 2.524643801469589

Epoch: 6| Step: 4
Training loss: 2.723629486092895
Validation loss: 2.5254653528649675

Epoch: 6| Step: 5
Training loss: 2.707637570338909
Validation loss: 2.5243809140777045

Epoch: 6| Step: 6
Training loss: 3.3011649185304175
Validation loss: 2.523401739959928

Epoch: 6| Step: 7
Training loss: 2.9267185477116744
Validation loss: 2.5221423146690474

Epoch: 6| Step: 8
Training loss: 2.936634341988277
Validation loss: 2.5238501032610805

Epoch: 6| Step: 9
Training loss: 2.640146065341441
Validation loss: 2.5227297452598214

Epoch: 6| Step: 10
Training loss: 2.770328638295492
Validation loss: 2.522387373792476

Epoch: 6| Step: 11
Training loss: 3.070683037139326
Validation loss: 2.526631743296098

Epoch: 6| Step: 12
Training loss: 2.8461394279891996
Validation loss: 2.544375225283384

Epoch: 6| Step: 13
Training loss: 2.3438228341547647
Validation loss: 2.5460061345774485

Epoch: 151| Step: 0
Training loss: 3.351153013027551
Validation loss: 2.565337222359841

Epoch: 6| Step: 1
Training loss: 3.182965662496278
Validation loss: 2.5957177875787103

Epoch: 6| Step: 2
Training loss: 2.857668007544826
Validation loss: 2.5854057328108495

Epoch: 6| Step: 3
Training loss: 3.135219039687474
Validation loss: 2.607215718403774

Epoch: 6| Step: 4
Training loss: 2.930949597938234
Validation loss: 2.550698985033759

Epoch: 6| Step: 5
Training loss: 2.483822935172919
Validation loss: 2.5432435662476878

Epoch: 6| Step: 6
Training loss: 2.7258476478840663
Validation loss: 2.529991473071254

Epoch: 6| Step: 7
Training loss: 2.706537110778096
Validation loss: 2.522698693544706

Epoch: 6| Step: 8
Training loss: 2.804954749845644
Validation loss: 2.5249823387793

Epoch: 6| Step: 9
Training loss: 2.5274350652456343
Validation loss: 2.5205971968178877

Epoch: 6| Step: 10
Training loss: 2.9698159964233986
Validation loss: 2.519228546892066

Epoch: 6| Step: 11
Training loss: 3.357034124915135
Validation loss: 2.5191831551308086

Epoch: 6| Step: 12
Training loss: 2.7055587837292236
Validation loss: 2.5161389077110843

Epoch: 6| Step: 13
Training loss: 2.514926031401403
Validation loss: 2.516285492083955

Epoch: 152| Step: 0
Training loss: 2.8415802443741205
Validation loss: 2.5205418824955617

Epoch: 6| Step: 1
Training loss: 3.5636145203580916
Validation loss: 2.5152243109932484

Epoch: 6| Step: 2
Training loss: 2.2267282524652954
Validation loss: 2.5304008020561968

Epoch: 6| Step: 3
Training loss: 2.9068123878325274
Validation loss: 2.538660104574078

Epoch: 6| Step: 4
Training loss: 3.258112978171235
Validation loss: 2.54031191594284

Epoch: 6| Step: 5
Training loss: 2.8305697333326356
Validation loss: 2.5349323747668007

Epoch: 6| Step: 6
Training loss: 3.1429392320885814
Validation loss: 2.5392939656582882

Epoch: 6| Step: 7
Training loss: 2.420924437007423
Validation loss: 2.524094854385459

Epoch: 6| Step: 8
Training loss: 2.7992495893631575
Validation loss: 2.5359954256600896

Epoch: 6| Step: 9
Training loss: 3.4819399959733772
Validation loss: 2.5210538961039934

Epoch: 6| Step: 10
Training loss: 1.711448697577493
Validation loss: 2.5359704208974247

Epoch: 6| Step: 11
Training loss: 2.3337153962097847
Validation loss: 2.5417705866325093

Epoch: 6| Step: 12
Training loss: 3.426561325497476
Validation loss: 2.5421793340121264

Epoch: 6| Step: 13
Training loss: 2.5864714563912283
Validation loss: 2.559759680167336

Epoch: 153| Step: 0
Training loss: 2.7955812839950807
Validation loss: 2.5742036632068546

Epoch: 6| Step: 1
Training loss: 3.0976196132961125
Validation loss: 2.5686165267790537

Epoch: 6| Step: 2
Training loss: 2.0254618412398204
Validation loss: 2.6371345428567468

Epoch: 6| Step: 3
Training loss: 2.9834920965249525
Validation loss: 2.67851373160121

Epoch: 6| Step: 4
Training loss: 3.140896458067781
Validation loss: 2.7153316682299793

Epoch: 6| Step: 5
Training loss: 2.5789621554523383
Validation loss: 2.6681063438837525

Epoch: 6| Step: 6
Training loss: 3.139159206877384
Validation loss: 2.609768772999304

Epoch: 6| Step: 7
Training loss: 2.4415619091002463
Validation loss: 2.5507628858183153

Epoch: 6| Step: 8
Training loss: 3.0272037202997715
Validation loss: 2.5267462913607157

Epoch: 6| Step: 9
Training loss: 3.211421883609559
Validation loss: 2.5242170341746553

Epoch: 6| Step: 10
Training loss: 3.1643985522736915
Validation loss: 2.5163836305020792

Epoch: 6| Step: 11
Training loss: 2.90487162399933
Validation loss: 2.5146369417865433

Epoch: 6| Step: 12
Training loss: 2.8615600908533185
Validation loss: 2.515550444531331

Epoch: 6| Step: 13
Training loss: 2.6685120237500217
Validation loss: 2.517801796078688

Epoch: 154| Step: 0
Training loss: 3.359594719377145
Validation loss: 2.5197741518027987

Epoch: 6| Step: 1
Training loss: 2.904463352134367
Validation loss: 2.516414184539465

Epoch: 6| Step: 2
Training loss: 2.3711677552289503
Validation loss: 2.515082948353646

Epoch: 6| Step: 3
Training loss: 3.1433640108468985
Validation loss: 2.5196052969649387

Epoch: 6| Step: 4
Training loss: 2.94814724688762
Validation loss: 2.5158223690200323

Epoch: 6| Step: 5
Training loss: 2.992005504521493
Validation loss: 2.527023585004216

Epoch: 6| Step: 6
Training loss: 3.28062069625703
Validation loss: 2.5264342253038268

Epoch: 6| Step: 7
Training loss: 3.290887829028372
Validation loss: 2.5357296175181765

Epoch: 6| Step: 8
Training loss: 2.6225600937757534
Validation loss: 2.530311176415037

Epoch: 6| Step: 9
Training loss: 2.51187536721323
Validation loss: 2.535182369073675

Epoch: 6| Step: 10
Training loss: 2.098894318644901
Validation loss: 2.545950988652357

Epoch: 6| Step: 11
Training loss: 2.884945129718979
Validation loss: 2.551403875521648

Epoch: 6| Step: 12
Training loss: 2.7366376833788415
Validation loss: 2.557117070659902

Epoch: 6| Step: 13
Training loss: 2.9493314405726085
Validation loss: 2.5606619572964413

Epoch: 155| Step: 0
Training loss: 2.79024192171386
Validation loss: 2.5431070101306394

Epoch: 6| Step: 1
Training loss: 2.7301895806576852
Validation loss: 2.5643370011728934

Epoch: 6| Step: 2
Training loss: 2.650377671302169
Validation loss: 2.6002659115042683

Epoch: 6| Step: 3
Training loss: 3.1915183076830953
Validation loss: 2.602708852631355

Epoch: 6| Step: 4
Training loss: 3.119275763157386
Validation loss: 2.6089649827619175

Epoch: 6| Step: 5
Training loss: 2.450358975639502
Validation loss: 2.5981261017256925

Epoch: 6| Step: 6
Training loss: 2.747687668087897
Validation loss: 2.58423217461308

Epoch: 6| Step: 7
Training loss: 3.1677699091323834
Validation loss: 2.5909662412128114

Epoch: 6| Step: 8
Training loss: 3.2086522492936145
Validation loss: 2.562420289295262

Epoch: 6| Step: 9
Training loss: 2.752952811044913
Validation loss: 2.5534402597999524

Epoch: 6| Step: 10
Training loss: 2.5294574936935277
Validation loss: 2.541124469277596

Epoch: 6| Step: 11
Training loss: 2.6971830649588617
Validation loss: 2.534721887033796

Epoch: 6| Step: 12
Training loss: 3.188414498582408
Validation loss: 2.528032560879417

Epoch: 6| Step: 13
Training loss: 2.933022515851389
Validation loss: 2.5228655772854043

Epoch: 156| Step: 0
Training loss: 2.944081502014326
Validation loss: 2.5179447328562032

Epoch: 6| Step: 1
Training loss: 2.614525924802124
Validation loss: 2.525306214184768

Epoch: 6| Step: 2
Training loss: 3.045247587213828
Validation loss: 2.5189526056812586

Epoch: 6| Step: 3
Training loss: 3.2909915730760564
Validation loss: 2.524156007989158

Epoch: 6| Step: 4
Training loss: 3.0629969602364886
Validation loss: 2.515258690037415

Epoch: 6| Step: 5
Training loss: 2.7649115380317086
Validation loss: 2.5231736354847865

Epoch: 6| Step: 6
Training loss: 2.5470952599889647
Validation loss: 2.519927470658839

Epoch: 6| Step: 7
Training loss: 2.7677063087816816
Validation loss: 2.523197613870842

Epoch: 6| Step: 8
Training loss: 2.417815516335503
Validation loss: 2.5304054574127215

Epoch: 6| Step: 9
Training loss: 3.1226817878478648
Validation loss: 2.524198664622328

Epoch: 6| Step: 10
Training loss: 2.860363898701633
Validation loss: 2.540019444819235

Epoch: 6| Step: 11
Training loss: 3.0384059481192445
Validation loss: 2.55153202198711

Epoch: 6| Step: 12
Training loss: 2.340623321328879
Validation loss: 2.554994463647595

Epoch: 6| Step: 13
Training loss: 3.455863315687394
Validation loss: 2.58270403639697

Epoch: 157| Step: 0
Training loss: 3.077932129060203
Validation loss: 2.562396012624117

Epoch: 6| Step: 1
Training loss: 2.3601720613052906
Validation loss: 2.566003138177542

Epoch: 6| Step: 2
Training loss: 3.389600467150118
Validation loss: 2.5588104013539996

Epoch: 6| Step: 3
Training loss: 3.3229923698069066
Validation loss: 2.556954753481137

Epoch: 6| Step: 4
Training loss: 2.8010686197588335
Validation loss: 2.5491756705323985

Epoch: 6| Step: 5
Training loss: 2.9188409239760804
Validation loss: 2.550942604285644

Epoch: 6| Step: 6
Training loss: 2.812364871699585
Validation loss: 2.560105272046201

Epoch: 6| Step: 7
Training loss: 2.9586694732395986
Validation loss: 2.5432252806973277

Epoch: 6| Step: 8
Training loss: 2.903195981245079
Validation loss: 2.5461232404382277

Epoch: 6| Step: 9
Training loss: 2.5360372978500187
Validation loss: 2.527096171749263

Epoch: 6| Step: 10
Training loss: 2.651884013854492
Validation loss: 2.5258615642483773

Epoch: 6| Step: 11
Training loss: 2.66530475011972
Validation loss: 2.51787626044759

Epoch: 6| Step: 12
Training loss: 2.592988511412768
Validation loss: 2.509527885879509

Epoch: 6| Step: 13
Training loss: 3.013036852601421
Validation loss: 2.5119007057255893

Epoch: 158| Step: 0
Training loss: 3.3013258264709973
Validation loss: 2.517863066891214

Epoch: 6| Step: 1
Training loss: 2.4865266131862525
Validation loss: 2.5150620203732257

Epoch: 6| Step: 2
Training loss: 2.8115738085427866
Validation loss: 2.5107369616641924

Epoch: 6| Step: 3
Training loss: 2.5803834213299037
Validation loss: 2.5115042629824385

Epoch: 6| Step: 4
Training loss: 3.625217168156466
Validation loss: 2.5224712257390935

Epoch: 6| Step: 5
Training loss: 2.8634790870005413
Validation loss: 2.515473917859443

Epoch: 6| Step: 6
Training loss: 2.213489905855451
Validation loss: 2.528128547300404

Epoch: 6| Step: 7
Training loss: 3.10902349124155
Validation loss: 2.532179226016093

Epoch: 6| Step: 8
Training loss: 3.1663596021113602
Validation loss: 2.552502399633197

Epoch: 6| Step: 9
Training loss: 2.838549879336361
Validation loss: 2.552344262699198

Epoch: 6| Step: 10
Training loss: 2.808258418622503
Validation loss: 2.560875211205182

Epoch: 6| Step: 11
Training loss: 2.808599692220331
Validation loss: 2.565961880865908

Epoch: 6| Step: 12
Training loss: 2.6829484055342983
Validation loss: 2.566336520275005

Epoch: 6| Step: 13
Training loss: 2.44400681807196
Validation loss: 2.542374898706253

Epoch: 159| Step: 0
Training loss: 3.156599573095733
Validation loss: 2.5511021937849887

Epoch: 6| Step: 1
Training loss: 2.958995655403416
Validation loss: 2.541626969432091

Epoch: 6| Step: 2
Training loss: 2.812863813817336
Validation loss: 2.539679527309922

Epoch: 6| Step: 3
Training loss: 2.803076831484568
Validation loss: 2.540168078005476

Epoch: 6| Step: 4
Training loss: 3.2951670195371747
Validation loss: 2.55728454635635

Epoch: 6| Step: 5
Training loss: 2.649993709340816
Validation loss: 2.5880581290732496

Epoch: 6| Step: 6
Training loss: 2.5803685454391485
Validation loss: 2.5692185845216517

Epoch: 6| Step: 7
Training loss: 2.9179362304182725
Validation loss: 2.581793915564037

Epoch: 6| Step: 8
Training loss: 2.6459194579837853
Validation loss: 2.5741673963813665

Epoch: 6| Step: 9
Training loss: 2.8064899231569918
Validation loss: 2.5797699702985155

Epoch: 6| Step: 10
Training loss: 2.8052674440392793
Validation loss: 2.603833530570476

Epoch: 6| Step: 11
Training loss: 2.80582075680606
Validation loss: 2.5802870528877317

Epoch: 6| Step: 12
Training loss: 2.730811363630844
Validation loss: 2.56538755855378

Epoch: 6| Step: 13
Training loss: 2.9836696570150627
Validation loss: 2.5452588029836676

Epoch: 160| Step: 0
Training loss: 2.326854589609966
Validation loss: 2.522640362317723

Epoch: 6| Step: 1
Training loss: 2.3033362613922512
Validation loss: 2.51502418973862

Epoch: 6| Step: 2
Training loss: 3.2826802360983476
Validation loss: 2.5081082576227676

Epoch: 6| Step: 3
Training loss: 2.8591115027583442
Validation loss: 2.512424838299397

Epoch: 6| Step: 4
Training loss: 2.7476111353298833
Validation loss: 2.51588157364982

Epoch: 6| Step: 5
Training loss: 2.3661874603857505
Validation loss: 2.516308972197175

Epoch: 6| Step: 6
Training loss: 2.774298907545069
Validation loss: 2.516133887690142

Epoch: 6| Step: 7
Training loss: 3.103012399464899
Validation loss: 2.5195149515204633

Epoch: 6| Step: 8
Training loss: 3.063871426925017
Validation loss: 2.5183543748378927

Epoch: 6| Step: 9
Training loss: 3.7747533806080127
Validation loss: 2.519133125043806

Epoch: 6| Step: 10
Training loss: 3.479291963129462
Validation loss: 2.515749792255757

Epoch: 6| Step: 11
Training loss: 2.3791742283511095
Validation loss: 2.518785299325909

Epoch: 6| Step: 12
Training loss: 2.5033367776995186
Validation loss: 2.514916972242176

Epoch: 6| Step: 13
Training loss: 2.9752620549548734
Validation loss: 2.5121546411262994

Epoch: 161| Step: 0
Training loss: 2.3293701528831923
Validation loss: 2.511211782159824

Epoch: 6| Step: 1
Training loss: 2.857822184183889
Validation loss: 2.511656811806142

Epoch: 6| Step: 2
Training loss: 3.4241226687606003
Validation loss: 2.5121815718385383

Epoch: 6| Step: 3
Training loss: 3.137257150925036
Validation loss: 2.5086659821216184

Epoch: 6| Step: 4
Training loss: 3.178284131532603
Validation loss: 2.5120788396732614

Epoch: 6| Step: 5
Training loss: 2.2286870089800814
Validation loss: 2.515624627014145

Epoch: 6| Step: 6
Training loss: 3.1249023422240736
Validation loss: 2.5275812282983505

Epoch: 6| Step: 7
Training loss: 2.5861570144095913
Validation loss: 2.5228595046927884

Epoch: 6| Step: 8
Training loss: 3.208573782361551
Validation loss: 2.5285217802875746

Epoch: 6| Step: 9
Training loss: 2.9706769612280617
Validation loss: 2.528798165541303

Epoch: 6| Step: 10
Training loss: 2.6636369203063306
Validation loss: 2.531700398045439

Epoch: 6| Step: 11
Training loss: 2.496520673034019
Validation loss: 2.5306193038101585

Epoch: 6| Step: 12
Training loss: 2.7271953383938827
Validation loss: 2.5294106831018093

Epoch: 6| Step: 13
Training loss: 2.9567506523489624
Validation loss: 2.537149980911268

Epoch: 162| Step: 0
Training loss: 3.050386879569749
Validation loss: 2.539746972803108

Epoch: 6| Step: 1
Training loss: 3.2473758961000017
Validation loss: 2.5375582541776263

Epoch: 6| Step: 2
Training loss: 2.782391860245199
Validation loss: 2.5483683140133775

Epoch: 6| Step: 3
Training loss: 3.068809082954179
Validation loss: 2.55686495772443

Epoch: 6| Step: 4
Training loss: 2.8307877118964995
Validation loss: 2.5433656980546258

Epoch: 6| Step: 5
Training loss: 2.5660465168352853
Validation loss: 2.5281307873287684

Epoch: 6| Step: 6
Training loss: 3.2174745273248666
Validation loss: 2.5302497308350587

Epoch: 6| Step: 7
Training loss: 2.067919690710692
Validation loss: 2.523263954070295

Epoch: 6| Step: 8
Training loss: 2.98947028146823
Validation loss: 2.5242872408498194

Epoch: 6| Step: 9
Training loss: 3.0294182345431797
Validation loss: 2.5329649056084844

Epoch: 6| Step: 10
Training loss: 2.5135445847845443
Validation loss: 2.5182016881067573

Epoch: 6| Step: 11
Training loss: 2.651587309577971
Validation loss: 2.522315940313214

Epoch: 6| Step: 12
Training loss: 2.948058449578527
Validation loss: 2.5273215181374225

Epoch: 6| Step: 13
Training loss: 2.836792535854445
Validation loss: 2.5220734611952533

Epoch: 163| Step: 0
Training loss: 2.899805943803611
Validation loss: 2.5289643771369517

Epoch: 6| Step: 1
Training loss: 2.3310481416173277
Validation loss: 2.5375265029451843

Epoch: 6| Step: 2
Training loss: 2.9067603862888904
Validation loss: 2.525917622741031

Epoch: 6| Step: 3
Training loss: 2.611610414458707
Validation loss: 2.5246779166864117

Epoch: 6| Step: 4
Training loss: 2.8263579691560676
Validation loss: 2.525454186562764

Epoch: 6| Step: 5
Training loss: 3.0332135005658025
Validation loss: 2.5352821720158913

Epoch: 6| Step: 6
Training loss: 2.3618823742757704
Validation loss: 2.5518616296043106

Epoch: 6| Step: 7
Training loss: 2.885894699068441
Validation loss: 2.5713176889353795

Epoch: 6| Step: 8
Training loss: 3.7079477574064166
Validation loss: 2.5821059093342815

Epoch: 6| Step: 9
Training loss: 2.591717118715622
Validation loss: 2.592353827540119

Epoch: 6| Step: 10
Training loss: 2.9436151688265904
Validation loss: 2.598307765591342

Epoch: 6| Step: 11
Training loss: 3.090586576618303
Validation loss: 2.5986996493453742

Epoch: 6| Step: 12
Training loss: 3.1499095722116137
Validation loss: 2.6240488976959324

Epoch: 6| Step: 13
Training loss: 2.3727256526097764
Validation loss: 2.6063240896711712

Epoch: 164| Step: 0
Training loss: 3.229725762644886
Validation loss: 2.612598543565076

Epoch: 6| Step: 1
Training loss: 3.062064470734901
Validation loss: 2.5907414691831927

Epoch: 6| Step: 2
Training loss: 2.8888319898365378
Validation loss: 2.5754150437248367

Epoch: 6| Step: 3
Training loss: 2.525326237517837
Validation loss: 2.5611809958214358

Epoch: 6| Step: 4
Training loss: 2.9520256781663035
Validation loss: 2.5531851068839986

Epoch: 6| Step: 5
Training loss: 3.1809706289835584
Validation loss: 2.5497540859042007

Epoch: 6| Step: 6
Training loss: 2.7768453802760953
Validation loss: 2.5491513421476326

Epoch: 6| Step: 7
Training loss: 2.8021141721784537
Validation loss: 2.55376418418636

Epoch: 6| Step: 8
Training loss: 2.7371229913720465
Validation loss: 2.5459844503264017

Epoch: 6| Step: 9
Training loss: 2.351398956593727
Validation loss: 2.552016630089999

Epoch: 6| Step: 10
Training loss: 2.8099076933989067
Validation loss: 2.5540880092738556

Epoch: 6| Step: 11
Training loss: 2.8962207964930045
Validation loss: 2.5810980595198205

Epoch: 6| Step: 12
Training loss: 3.3247832951879643
Validation loss: 2.593285445988472

Epoch: 6| Step: 13
Training loss: 2.7333877088984253
Validation loss: 2.6037821338557112

Epoch: 165| Step: 0
Training loss: 3.0571332345665936
Validation loss: 2.6131590394892745

Epoch: 6| Step: 1
Training loss: 3.1263690238542585
Validation loss: 2.609054027925438

Epoch: 6| Step: 2
Training loss: 2.61841210709572
Validation loss: 2.6096912467731475

Epoch: 6| Step: 3
Training loss: 2.679127804329452
Validation loss: 2.5884290860407786

Epoch: 6| Step: 4
Training loss: 2.5984890398796674
Validation loss: 2.599725224968409

Epoch: 6| Step: 5
Training loss: 2.7443877085159305
Validation loss: 2.5829340278487694

Epoch: 6| Step: 6
Training loss: 2.693790968297984
Validation loss: 2.5647037893029005

Epoch: 6| Step: 7
Training loss: 2.7394645191338065
Validation loss: 2.560669582144366

Epoch: 6| Step: 8
Training loss: 2.4496285371026354
Validation loss: 2.5715698633735835

Epoch: 6| Step: 9
Training loss: 3.1917675098659886
Validation loss: 2.5857986696958344

Epoch: 6| Step: 10
Training loss: 3.357139233758241
Validation loss: 2.597166932797988

Epoch: 6| Step: 11
Training loss: 2.8614767719494507
Validation loss: 2.588544211282497

Epoch: 6| Step: 12
Training loss: 2.747396103315054
Validation loss: 2.6094999312307454

Epoch: 6| Step: 13
Training loss: 3.8500998545986906
Validation loss: 2.596623124830363

Epoch: 166| Step: 0
Training loss: 2.6660393235267676
Validation loss: 2.590344941304206

Epoch: 6| Step: 1
Training loss: 2.333585748189432
Validation loss: 2.5644383376438795

Epoch: 6| Step: 2
Training loss: 2.8089964343191287
Validation loss: 2.543016416918479

Epoch: 6| Step: 3
Training loss: 3.0686860180806175
Validation loss: 2.5341680699668445

Epoch: 6| Step: 4
Training loss: 3.115635841832863
Validation loss: 2.527354481923719

Epoch: 6| Step: 5
Training loss: 3.5931004476247517
Validation loss: 2.5187721995898538

Epoch: 6| Step: 6
Training loss: 3.129034261192236
Validation loss: 2.5123591011761093

Epoch: 6| Step: 7
Training loss: 2.6664432392298676
Validation loss: 2.507962584991997

Epoch: 6| Step: 8
Training loss: 2.9728496954756474
Validation loss: 2.5123654073125357

Epoch: 6| Step: 9
Training loss: 2.692116077646895
Validation loss: 2.5049898137002624

Epoch: 6| Step: 10
Training loss: 2.3871361699923392
Validation loss: 2.506609873445199

Epoch: 6| Step: 11
Training loss: 2.7750540307086005
Validation loss: 2.5041781408031265

Epoch: 6| Step: 12
Training loss: 2.8322366574215825
Validation loss: 2.499025534350787

Epoch: 6| Step: 13
Training loss: 3.338518988680574
Validation loss: 2.5054291614251

Epoch: 167| Step: 0
Training loss: 2.95713251663622
Validation loss: 2.5078161576496467

Epoch: 6| Step: 1
Training loss: 2.3897537937798643
Validation loss: 2.51045167456299

Epoch: 6| Step: 2
Training loss: 3.1000425520406796
Validation loss: 2.512509160480953

Epoch: 6| Step: 3
Training loss: 3.54192824052249
Validation loss: 2.5153281703533192

Epoch: 6| Step: 4
Training loss: 2.3841256947504132
Validation loss: 2.5165151362472846

Epoch: 6| Step: 5
Training loss: 3.018344423837857
Validation loss: 2.515342723571133

Epoch: 6| Step: 6
Training loss: 2.8247344204457567
Validation loss: 2.519855962358777

Epoch: 6| Step: 7
Training loss: 2.6441603249723182
Validation loss: 2.5216212175739425

Epoch: 6| Step: 8
Training loss: 1.9407045873271973
Validation loss: 2.516773241817079

Epoch: 6| Step: 9
Training loss: 3.04150857035533
Validation loss: 2.5227841752829594

Epoch: 6| Step: 10
Training loss: 2.3429667880821854
Validation loss: 2.5215670959202954

Epoch: 6| Step: 11
Training loss: 3.3013191823127097
Validation loss: 2.510009257367296

Epoch: 6| Step: 12
Training loss: 2.7231533302792887
Validation loss: 2.540400034291293

Epoch: 6| Step: 13
Training loss: 3.569663090983501
Validation loss: 2.5267311189639874

Epoch: 168| Step: 0
Training loss: 2.4508044693211417
Validation loss: 2.530636599025255

Epoch: 6| Step: 1
Training loss: 2.8757094461585626
Validation loss: 2.514692975247292

Epoch: 6| Step: 2
Training loss: 2.7355208257720176
Validation loss: 2.5089435492385768

Epoch: 6| Step: 3
Training loss: 2.8154664396122726
Validation loss: 2.516743061903013

Epoch: 6| Step: 4
Training loss: 3.208449093270212
Validation loss: 2.506900756938253

Epoch: 6| Step: 5
Training loss: 2.8877129810606745
Validation loss: 2.517901301338303

Epoch: 6| Step: 6
Training loss: 3.0495412262623747
Validation loss: 2.522513510438794

Epoch: 6| Step: 7
Training loss: 2.5435365667007424
Validation loss: 2.5170991140643486

Epoch: 6| Step: 8
Training loss: 3.0448512472265072
Validation loss: 2.5150151961703426

Epoch: 6| Step: 9
Training loss: 2.8641197985522506
Validation loss: 2.512523972869297

Epoch: 6| Step: 10
Training loss: 2.7024283862087204
Validation loss: 2.520551773763957

Epoch: 6| Step: 11
Training loss: 2.444796766794024
Validation loss: 2.506379411222604

Epoch: 6| Step: 12
Training loss: 3.436557987491496
Validation loss: 2.5130004460326414

Epoch: 6| Step: 13
Training loss: 2.4943145954156063
Validation loss: 2.500685868470835

Epoch: 169| Step: 0
Training loss: 2.5733602247002527
Validation loss: 2.49436483448976

Epoch: 6| Step: 1
Training loss: 2.7172754608008747
Validation loss: 2.4964110382874

Epoch: 6| Step: 2
Training loss: 3.232637832665103
Validation loss: 2.4992298385816802

Epoch: 6| Step: 3
Training loss: 2.9158802243765356
Validation loss: 2.5095015907121803

Epoch: 6| Step: 4
Training loss: 2.2836656713758705
Validation loss: 2.5143114045104746

Epoch: 6| Step: 5
Training loss: 2.994773762967317
Validation loss: 2.51022033747471

Epoch: 6| Step: 6
Training loss: 2.520126201557641
Validation loss: 2.53400415732613

Epoch: 6| Step: 7
Training loss: 2.819810817405925
Validation loss: 2.56803895575252

Epoch: 6| Step: 8
Training loss: 2.961124464589018
Validation loss: 2.606958728666017

Epoch: 6| Step: 9
Training loss: 3.0761858258612227
Validation loss: 2.598995762751394

Epoch: 6| Step: 10
Training loss: 3.1054123975331267
Validation loss: 2.573704166135427

Epoch: 6| Step: 11
Training loss: 3.0054744997061262
Validation loss: 2.5119122394762035

Epoch: 6| Step: 12
Training loss: 2.8013935776444687
Validation loss: 2.492757216693904

Epoch: 6| Step: 13
Training loss: 3.1363295602266614
Validation loss: 2.4860850468936726

Epoch: 170| Step: 0
Training loss: 2.68569459820984
Validation loss: 2.49493064256075

Epoch: 6| Step: 1
Training loss: 2.5559968072157906
Validation loss: 2.499857669285776

Epoch: 6| Step: 2
Training loss: 2.603065400282792
Validation loss: 2.505564266640467

Epoch: 6| Step: 3
Training loss: 3.0632239284079916
Validation loss: 2.51423883511269

Epoch: 6| Step: 4
Training loss: 2.8977571496086263
Validation loss: 2.5151788581789694

Epoch: 6| Step: 5
Training loss: 2.979008988340301
Validation loss: 2.504710030570977

Epoch: 6| Step: 6
Training loss: 3.0864765710428115
Validation loss: 2.5024213078829995

Epoch: 6| Step: 7
Training loss: 2.700267185130714
Validation loss: 2.495389526369288

Epoch: 6| Step: 8
Training loss: 2.4198940912826954
Validation loss: 2.49960991266914

Epoch: 6| Step: 9
Training loss: 3.447397997856853
Validation loss: 2.4960071282232406

Epoch: 6| Step: 10
Training loss: 2.897319732403537
Validation loss: 2.5008988159312477

Epoch: 6| Step: 11
Training loss: 2.7666827404367256
Validation loss: 2.50825487232914

Epoch: 6| Step: 12
Training loss: 3.3515519717746933
Validation loss: 2.513452316103651

Epoch: 6| Step: 13
Training loss: 2.530860965173042
Validation loss: 2.533953554846414

Epoch: 171| Step: 0
Training loss: 2.974281538432574
Validation loss: 2.508213041255127

Epoch: 6| Step: 1
Training loss: 2.3058187520906053
Validation loss: 2.5094859018462015

Epoch: 6| Step: 2
Training loss: 3.2919039741314364
Validation loss: 2.496069597515801

Epoch: 6| Step: 3
Training loss: 3.0791607193809822
Validation loss: 2.502377221733751

Epoch: 6| Step: 4
Training loss: 2.3116109015191055
Validation loss: 2.5049111590368374

Epoch: 6| Step: 5
Training loss: 2.8873135130800986
Validation loss: 2.5127037297560486

Epoch: 6| Step: 6
Training loss: 3.1644437583763056
Validation loss: 2.515940715748872

Epoch: 6| Step: 7
Training loss: 2.522152411082448
Validation loss: 2.510610288487918

Epoch: 6| Step: 8
Training loss: 2.7394260511225874
Validation loss: 2.5149663869242165

Epoch: 6| Step: 9
Training loss: 2.680948211118496
Validation loss: 2.5124690052761975

Epoch: 6| Step: 10
Training loss: 3.517453544651548
Validation loss: 2.5079535129460555

Epoch: 6| Step: 11
Training loss: 2.9339601006060465
Validation loss: 2.516344265564192

Epoch: 6| Step: 12
Training loss: 2.6436212458720285
Validation loss: 2.514485716675808

Epoch: 6| Step: 13
Training loss: 2.9949364845533517
Validation loss: 2.516142591974192

Epoch: 172| Step: 0
Training loss: 3.056319403299156
Validation loss: 2.517683420751232

Epoch: 6| Step: 1
Training loss: 2.8900127690439046
Validation loss: 2.5067003557175083

Epoch: 6| Step: 2
Training loss: 3.3975284456770294
Validation loss: 2.517526375665527

Epoch: 6| Step: 3
Training loss: 3.307672401600345
Validation loss: 2.51867997177414

Epoch: 6| Step: 4
Training loss: 2.905551129060789
Validation loss: 2.5253000307151594

Epoch: 6| Step: 5
Training loss: 2.499898240879456
Validation loss: 2.527317889731195

Epoch: 6| Step: 6
Training loss: 3.1628288972533403
Validation loss: 2.531696903504795

Epoch: 6| Step: 7
Training loss: 2.574397218390243
Validation loss: 2.546025049618459

Epoch: 6| Step: 8
Training loss: 2.608788430077551
Validation loss: 2.5609258363151284

Epoch: 6| Step: 9
Training loss: 2.4045499270263657
Validation loss: 2.583536337247281

Epoch: 6| Step: 10
Training loss: 2.6274958053540867
Validation loss: 2.5921905213941403

Epoch: 6| Step: 11
Training loss: 3.0786067372675294
Validation loss: 2.60517702318828

Epoch: 6| Step: 12
Training loss: 2.456385298635286
Validation loss: 2.5981855079198146

Epoch: 6| Step: 13
Training loss: 2.353571644982924
Validation loss: 2.622019065004301

Epoch: 173| Step: 0
Training loss: 2.4828811088670846
Validation loss: 2.6060816192276257

Epoch: 6| Step: 1
Training loss: 3.6241130401463457
Validation loss: 2.615551645245613

Epoch: 6| Step: 2
Training loss: 2.6758216130908705
Validation loss: 2.592244216359892

Epoch: 6| Step: 3
Training loss: 2.2720129000069194
Validation loss: 2.5780551874845674

Epoch: 6| Step: 4
Training loss: 2.9868977853497016
Validation loss: 2.55386628600143

Epoch: 6| Step: 5
Training loss: 2.7837690453976265
Validation loss: 2.5490064028765063

Epoch: 6| Step: 6
Training loss: 1.9915316829933827
Validation loss: 2.529719407629553

Epoch: 6| Step: 7
Training loss: 2.4693554485901648
Validation loss: 2.516985683789103

Epoch: 6| Step: 8
Training loss: 2.713179219373543
Validation loss: 2.5106105703177097

Epoch: 6| Step: 9
Training loss: 3.0566635569726843
Validation loss: 2.5074467009343424

Epoch: 6| Step: 10
Training loss: 3.1311251312758994
Validation loss: 2.506060615818391

Epoch: 6| Step: 11
Training loss: 3.1804112915755947
Validation loss: 2.509842068319718

Epoch: 6| Step: 12
Training loss: 3.1913795049847056
Validation loss: 2.509863674131423

Epoch: 6| Step: 13
Training loss: 2.6446552106690753
Validation loss: 2.50606552200796

Epoch: 174| Step: 0
Training loss: 2.5883077494021522
Validation loss: 2.502381615733559

Epoch: 6| Step: 1
Training loss: 2.8273506579771923
Validation loss: 2.501270435919651

Epoch: 6| Step: 2
Training loss: 3.036621211521645
Validation loss: 2.5105235283373615

Epoch: 6| Step: 3
Training loss: 2.941044718091426
Validation loss: 2.494509269403469

Epoch: 6| Step: 4
Training loss: 2.5786579852715796
Validation loss: 2.499360478547856

Epoch: 6| Step: 5
Training loss: 2.821803494008977
Validation loss: 2.5011060011520216

Epoch: 6| Step: 6
Training loss: 2.5917442563658306
Validation loss: 2.5033454640106605

Epoch: 6| Step: 7
Training loss: 3.2244495188174143
Validation loss: 2.5085518337859427

Epoch: 6| Step: 8
Training loss: 2.915684634597462
Validation loss: 2.5196497776177353

Epoch: 6| Step: 9
Training loss: 2.586847519729764
Validation loss: 2.502899043622771

Epoch: 6| Step: 10
Training loss: 2.6839520299919846
Validation loss: 2.5139739480074828

Epoch: 6| Step: 11
Training loss: 2.8531325942875383
Validation loss: 2.504631979210172

Epoch: 6| Step: 12
Training loss: 3.0231189017779485
Validation loss: 2.5220796159823147

Epoch: 6| Step: 13
Training loss: 3.0918701317422856
Validation loss: 2.516647683335311

Epoch: 175| Step: 0
Training loss: 2.174056240838787
Validation loss: 2.5157082091123644

Epoch: 6| Step: 1
Training loss: 3.229619607640905
Validation loss: 2.514398454027768

Epoch: 6| Step: 2
Training loss: 2.83454949326572
Validation loss: 2.517394650841349

Epoch: 6| Step: 3
Training loss: 2.5410619756413446
Validation loss: 2.511043559325948

Epoch: 6| Step: 4
Training loss: 2.1635510222358683
Validation loss: 2.5112015682555637

Epoch: 6| Step: 5
Training loss: 2.8798703943336026
Validation loss: 2.5078939831552614

Epoch: 6| Step: 6
Training loss: 2.4495740325572943
Validation loss: 2.515461625883354

Epoch: 6| Step: 7
Training loss: 2.9077935170533316
Validation loss: 2.51764307517708

Epoch: 6| Step: 8
Training loss: 2.890771150760526
Validation loss: 2.5159795092598616

Epoch: 6| Step: 9
Training loss: 3.099827509357344
Validation loss: 2.5210783766536182

Epoch: 6| Step: 10
Training loss: 3.18111213430315
Validation loss: 2.5339238061828704

Epoch: 6| Step: 11
Training loss: 2.7363141840294407
Validation loss: 2.536272477296628

Epoch: 6| Step: 12
Training loss: 3.01479790764658
Validation loss: 2.5461919026889266

Epoch: 6| Step: 13
Training loss: 3.6219124634905904
Validation loss: 2.5362576873639666

Epoch: 176| Step: 0
Training loss: 2.607015308014731
Validation loss: 2.530647615324246

Epoch: 6| Step: 1
Training loss: 2.9755086960765627
Validation loss: 2.5073610388254397

Epoch: 6| Step: 2
Training loss: 2.982942726805422
Validation loss: 2.518450149898452

Epoch: 6| Step: 3
Training loss: 2.876270179462227
Validation loss: 2.5182633024423966

Epoch: 6| Step: 4
Training loss: 3.0315122196002195
Validation loss: 2.5126996945780316

Epoch: 6| Step: 5
Training loss: 2.060660264208369
Validation loss: 2.5038081482935874

Epoch: 6| Step: 6
Training loss: 2.7062546798277953
Validation loss: 2.529399256507464

Epoch: 6| Step: 7
Training loss: 3.015576456104183
Validation loss: 2.541674638315735

Epoch: 6| Step: 8
Training loss: 3.0450239770004788
Validation loss: 2.539943311199339

Epoch: 6| Step: 9
Training loss: 3.111447357747545
Validation loss: 2.5451195698725986

Epoch: 6| Step: 10
Training loss: 2.9620566957908805
Validation loss: 2.5439370228004834

Epoch: 6| Step: 11
Training loss: 2.676967742047272
Validation loss: 2.5417663837750935

Epoch: 6| Step: 12
Training loss: 2.5172089512465665
Validation loss: 2.539933871928916

Epoch: 6| Step: 13
Training loss: 2.7627489901223155
Validation loss: 2.5266090810420776

Epoch: 177| Step: 0
Training loss: 2.130886451835873
Validation loss: 2.563174897444887

Epoch: 6| Step: 1
Training loss: 3.489740867285246
Validation loss: 2.6077374650047167

Epoch: 6| Step: 2
Training loss: 2.6472199378504664
Validation loss: 2.6476577654937987

Epoch: 6| Step: 3
Training loss: 2.867500641481017
Validation loss: 2.6285109852484485

Epoch: 6| Step: 4
Training loss: 2.7569862403125014
Validation loss: 2.626250005054167

Epoch: 6| Step: 5
Training loss: 2.439786669832675
Validation loss: 2.590624043824334

Epoch: 6| Step: 6
Training loss: 3.559691275593863
Validation loss: 2.559600460188583

Epoch: 6| Step: 7
Training loss: 2.432804377645802
Validation loss: 2.559901675193426

Epoch: 6| Step: 8
Training loss: 2.651610147995577
Validation loss: 2.524951939189902

Epoch: 6| Step: 9
Training loss: 2.7946459875955463
Validation loss: 2.543352917949387

Epoch: 6| Step: 10
Training loss: 2.9471687113891383
Validation loss: 2.509245753161

Epoch: 6| Step: 11
Training loss: 2.837927926350691
Validation loss: 2.503267391609425

Epoch: 6| Step: 12
Training loss: 3.0032666223577724
Validation loss: 2.5041247130127586

Epoch: 6| Step: 13
Training loss: 2.3251442485074314
Validation loss: 2.503195092970927

Epoch: 178| Step: 0
Training loss: 2.5606263917263234
Validation loss: 2.497032663590398

Epoch: 6| Step: 1
Training loss: 3.163105836518914
Validation loss: 2.504605081961031

Epoch: 6| Step: 2
Training loss: 2.720275450952115
Validation loss: 2.501041461018475

Epoch: 6| Step: 3
Training loss: 2.8689282197798227
Validation loss: 2.502804775345166

Epoch: 6| Step: 4
Training loss: 2.4301645479101683
Validation loss: 2.5014083853467257

Epoch: 6| Step: 5
Training loss: 3.026791311741929
Validation loss: 2.5028816207550375

Epoch: 6| Step: 6
Training loss: 2.7361247540524847
Validation loss: 2.5041861280513236

Epoch: 6| Step: 7
Training loss: 3.02459710330634
Validation loss: 2.509840611752927

Epoch: 6| Step: 8
Training loss: 3.197686169463618
Validation loss: 2.501937595269379

Epoch: 6| Step: 9
Training loss: 2.561350681007228
Validation loss: 2.5056968343846595

Epoch: 6| Step: 10
Training loss: 2.834432912148686
Validation loss: 2.50713456504363

Epoch: 6| Step: 11
Training loss: 2.7367179206326355
Validation loss: 2.5150270932996133

Epoch: 6| Step: 12
Training loss: 3.0203684131165436
Validation loss: 2.518351562150726

Epoch: 6| Step: 13
Training loss: 2.86463819046669
Validation loss: 2.534590755470923

Epoch: 179| Step: 0
Training loss: 2.8087381423951157
Validation loss: 2.5470238712622115

Epoch: 6| Step: 1
Training loss: 2.7859590077064755
Validation loss: 2.5524361519512833

Epoch: 6| Step: 2
Training loss: 3.185803279696703
Validation loss: 2.55847793939478

Epoch: 6| Step: 3
Training loss: 2.914488896732119
Validation loss: 2.5411731665174444

Epoch: 6| Step: 4
Training loss: 2.5114514340643863
Validation loss: 2.539622702566773

Epoch: 6| Step: 5
Training loss: 2.9793598316943637
Validation loss: 2.512369878741427

Epoch: 6| Step: 6
Training loss: 3.0602927525421824
Validation loss: 2.5169142650656853

Epoch: 6| Step: 7
Training loss: 2.6439502252461375
Validation loss: 2.5081098766938115

Epoch: 6| Step: 8
Training loss: 2.6326673337494904
Validation loss: 2.4967225392470054

Epoch: 6| Step: 9
Training loss: 2.8652212276560154
Validation loss: 2.501503223791081

Epoch: 6| Step: 10
Training loss: 2.1616889799912986
Validation loss: 2.509429386892823

Epoch: 6| Step: 11
Training loss: 3.042083258819335
Validation loss: 2.509219378410446

Epoch: 6| Step: 12
Training loss: 2.7411679711964894
Validation loss: 2.5177565618753937

Epoch: 6| Step: 13
Training loss: 3.146198697799094
Validation loss: 2.516988674209145

Epoch: 180| Step: 0
Training loss: 3.008420253635677
Validation loss: 2.522846682694702

Epoch: 6| Step: 1
Training loss: 1.6903162873575326
Validation loss: 2.5190372690911214

Epoch: 6| Step: 2
Training loss: 2.728547606011125
Validation loss: 2.5409735503313087

Epoch: 6| Step: 3
Training loss: 3.2709186486134394
Validation loss: 2.5438692076906033

Epoch: 6| Step: 4
Training loss: 3.114593420788474
Validation loss: 2.5493437946350963

Epoch: 6| Step: 5
Training loss: 1.9965742096592638
Validation loss: 2.5483633786070365

Epoch: 6| Step: 6
Training loss: 3.439520779431151
Validation loss: 2.54489291790239

Epoch: 6| Step: 7
Training loss: 2.939554997196509
Validation loss: 2.5161265660016974

Epoch: 6| Step: 8
Training loss: 2.734973689341523
Validation loss: 2.5097777477310146

Epoch: 6| Step: 9
Training loss: 2.3783417331018817
Validation loss: 2.498986951604316

Epoch: 6| Step: 10
Training loss: 2.8557527873117396
Validation loss: 2.5007528463573316

Epoch: 6| Step: 11
Training loss: 2.3434218113322314
Validation loss: 2.496129366168544

Epoch: 6| Step: 12
Training loss: 3.278558989999009
Validation loss: 2.501991430437023

Epoch: 6| Step: 13
Training loss: 3.302029309397424
Validation loss: 2.49362460687346

Epoch: 181| Step: 0
Training loss: 3.4339023143313376
Validation loss: 2.4906647310204093

Epoch: 6| Step: 1
Training loss: 2.2770472443126937
Validation loss: 2.486948821394816

Epoch: 6| Step: 2
Training loss: 2.812881613379104
Validation loss: 2.482633577201476

Epoch: 6| Step: 3
Training loss: 2.8688452810782836
Validation loss: 2.4855000218898664

Epoch: 6| Step: 4
Training loss: 2.931783592606131
Validation loss: 2.4915111847036617

Epoch: 6| Step: 5
Training loss: 2.5529077145624095
Validation loss: 2.488161788594149

Epoch: 6| Step: 6
Training loss: 2.8032873372474896
Validation loss: 2.502299211329362

Epoch: 6| Step: 7
Training loss: 2.195003501350547
Validation loss: 2.5136152792489397

Epoch: 6| Step: 8
Training loss: 2.738519372531304
Validation loss: 2.5252482152639795

Epoch: 6| Step: 9
Training loss: 3.156624195843043
Validation loss: 2.526248653360543

Epoch: 6| Step: 10
Training loss: 2.981463864890689
Validation loss: 2.52544226292774

Epoch: 6| Step: 11
Training loss: 2.8506553565652344
Validation loss: 2.5130851844906315

Epoch: 6| Step: 12
Training loss: 2.6603832624146078
Validation loss: 2.5119135376704613

Epoch: 6| Step: 13
Training loss: 3.0930284371510233
Validation loss: 2.506835715582788

Epoch: 182| Step: 0
Training loss: 2.997483469557181
Validation loss: 2.4967509722697

Epoch: 6| Step: 1
Training loss: 2.6217218547556898
Validation loss: 2.503619940834771

Epoch: 6| Step: 2
Training loss: 2.233344634108159
Validation loss: 2.49969609372

Epoch: 6| Step: 3
Training loss: 2.9631004787251958
Validation loss: 2.495016437579697

Epoch: 6| Step: 4
Training loss: 2.5152661559254605
Validation loss: 2.496289660367

Epoch: 6| Step: 5
Training loss: 2.3769673681655226
Validation loss: 2.4944879021223825

Epoch: 6| Step: 6
Training loss: 3.1469662544179453
Validation loss: 2.494442831985144

Epoch: 6| Step: 7
Training loss: 2.636450181634711
Validation loss: 2.51194232638455

Epoch: 6| Step: 8
Training loss: 2.9482240730024825
Validation loss: 2.5042069805662805

Epoch: 6| Step: 9
Training loss: 2.7877720858267176
Validation loss: 2.5103522518694743

Epoch: 6| Step: 10
Training loss: 2.884814551887053
Validation loss: 2.5114226519726515

Epoch: 6| Step: 11
Training loss: 3.0523363514115607
Validation loss: 2.4971595193925933

Epoch: 6| Step: 12
Training loss: 3.2172246485265705
Validation loss: 2.5078979074872967

Epoch: 6| Step: 13
Training loss: 2.629677465264434
Validation loss: 2.5050074306799717

Epoch: 183| Step: 0
Training loss: 3.0165433918193525
Validation loss: 2.5014357084685583

Epoch: 6| Step: 1
Training loss: 2.949751769144779
Validation loss: 2.5116928390906437

Epoch: 6| Step: 2
Training loss: 2.821973992826037
Validation loss: 2.5016673619092407

Epoch: 6| Step: 3
Training loss: 1.8357125651768695
Validation loss: 2.500047629938373

Epoch: 6| Step: 4
Training loss: 2.7254098461512704
Validation loss: 2.4947703514718813

Epoch: 6| Step: 5
Training loss: 2.145870159043048
Validation loss: 2.5192875096755656

Epoch: 6| Step: 6
Training loss: 2.78427097113378
Validation loss: 2.513578017882033

Epoch: 6| Step: 7
Training loss: 3.08868548533899
Validation loss: 2.5253446658689795

Epoch: 6| Step: 8
Training loss: 2.9699582502211443
Validation loss: 2.5279771881738378

Epoch: 6| Step: 9
Training loss: 2.812552727099068
Validation loss: 2.5462147853313755

Epoch: 6| Step: 10
Training loss: 2.986965153912659
Validation loss: 2.572016271785282

Epoch: 6| Step: 11
Training loss: 2.9939993609145508
Validation loss: 2.579564050587557

Epoch: 6| Step: 12
Training loss: 2.7522815429864753
Validation loss: 2.559468974601715

Epoch: 6| Step: 13
Training loss: 3.2771511089464798
Validation loss: 2.513970659291439

Epoch: 184| Step: 0
Training loss: 2.6884915496596884
Validation loss: 2.498008436210186

Epoch: 6| Step: 1
Training loss: 2.5388728144290096
Validation loss: 2.4949971204201793

Epoch: 6| Step: 2
Training loss: 2.8933742336892334
Validation loss: 2.490563086108661

Epoch: 6| Step: 3
Training loss: 2.2147180161621662
Validation loss: 2.484219749069495

Epoch: 6| Step: 4
Training loss: 3.2312816625700287
Validation loss: 2.4796233783257184

Epoch: 6| Step: 5
Training loss: 3.1669294014069993
Validation loss: 2.4917393994955566

Epoch: 6| Step: 6
Training loss: 2.4933903102518493
Validation loss: 2.486947137005423

Epoch: 6| Step: 7
Training loss: 3.0500174725141496
Validation loss: 2.484403755948734

Epoch: 6| Step: 8
Training loss: 2.9401825364206804
Validation loss: 2.4922343411156596

Epoch: 6| Step: 9
Training loss: 2.8298786269401894
Validation loss: 2.508416582367548

Epoch: 6| Step: 10
Training loss: 2.451144056428298
Validation loss: 2.5122684777985076

Epoch: 6| Step: 11
Training loss: 2.5845597852632185
Validation loss: 2.497624621369904

Epoch: 6| Step: 12
Training loss: 3.1561534602442602
Validation loss: 2.516172918165601

Epoch: 6| Step: 13
Training loss: 2.4939056500879353
Validation loss: 2.55658366182944

Epoch: 185| Step: 0
Training loss: 3.1536894127721973
Validation loss: 2.5612413670326855

Epoch: 6| Step: 1
Training loss: 3.1707848991741865
Validation loss: 2.6129801564910142

Epoch: 6| Step: 2
Training loss: 3.520677115381222
Validation loss: 2.6487657553684905

Epoch: 6| Step: 3
Training loss: 2.692436209430375
Validation loss: 2.6759604260890826

Epoch: 6| Step: 4
Training loss: 2.8570155013174268
Validation loss: 2.6401983990392224

Epoch: 6| Step: 5
Training loss: 3.11488674221216
Validation loss: 2.5637022990087366

Epoch: 6| Step: 6
Training loss: 2.7222681193039944
Validation loss: 2.4994581189010305

Epoch: 6| Step: 7
Training loss: 2.7380073181790174
Validation loss: 2.478838439650781

Epoch: 6| Step: 8
Training loss: 2.3618123178878454
Validation loss: 2.489413101431857

Epoch: 6| Step: 9
Training loss: 1.9569273900171142
Validation loss: 2.4796694642692576

Epoch: 6| Step: 10
Training loss: 2.7268890797375933
Validation loss: 2.487766876143445

Epoch: 6| Step: 11
Training loss: 2.8741048995102236
Validation loss: 2.484883476236211

Epoch: 6| Step: 12
Training loss: 2.6021518898803375
Validation loss: 2.488588153188911

Epoch: 6| Step: 13
Training loss: 3.263100264126163
Validation loss: 2.4893187704411655

Epoch: 186| Step: 0
Training loss: 2.3918344268268243
Validation loss: 2.48985915771988

Epoch: 6| Step: 1
Training loss: 2.902073145453943
Validation loss: 2.485206085769054

Epoch: 6| Step: 2
Training loss: 2.93630015441231
Validation loss: 2.4908947755857462

Epoch: 6| Step: 3
Training loss: 2.645177404443143
Validation loss: 2.496178199692252

Epoch: 6| Step: 4
Training loss: 2.121237396940108
Validation loss: 2.497602468826608

Epoch: 6| Step: 5
Training loss: 2.6344764047385247
Validation loss: 2.5208455058934236

Epoch: 6| Step: 6
Training loss: 2.6879400735771335
Validation loss: 2.5521500545885174

Epoch: 6| Step: 7
Training loss: 2.5754672135858407
Validation loss: 2.5765137530822257

Epoch: 6| Step: 8
Training loss: 2.8842204307726087
Validation loss: 2.5873426280436287

Epoch: 6| Step: 9
Training loss: 2.980192759123269
Validation loss: 2.5781534292195527

Epoch: 6| Step: 10
Training loss: 3.3477452732565864
Validation loss: 2.554559792820725

Epoch: 6| Step: 11
Training loss: 3.003171357145379
Validation loss: 2.5273073544410973

Epoch: 6| Step: 12
Training loss: 3.244924543587894
Validation loss: 2.5082414697400175

Epoch: 6| Step: 13
Training loss: 2.934134808054732
Validation loss: 2.4941116554757623

Epoch: 187| Step: 0
Training loss: 2.8441617898110323
Validation loss: 2.496278579223537

Epoch: 6| Step: 1
Training loss: 3.0970660076651515
Validation loss: 2.4899709820818137

Epoch: 6| Step: 2
Training loss: 3.0772995204996194
Validation loss: 2.4861451050781613

Epoch: 6| Step: 3
Training loss: 2.794923069258567
Validation loss: 2.485996450121745

Epoch: 6| Step: 4
Training loss: 2.5849579860438383
Validation loss: 2.493054407653657

Epoch: 6| Step: 5
Training loss: 2.5679588788860896
Validation loss: 2.4918875174109485

Epoch: 6| Step: 6
Training loss: 2.5909053416126144
Validation loss: 2.500479126209709

Epoch: 6| Step: 7
Training loss: 2.953467293737275
Validation loss: 2.5011092073587013

Epoch: 6| Step: 8
Training loss: 2.4459832097348273
Validation loss: 2.5028458937662603

Epoch: 6| Step: 9
Training loss: 2.746263219344037
Validation loss: 2.4947375809057357

Epoch: 6| Step: 10
Training loss: 2.7360749110512814
Validation loss: 2.511142693296879

Epoch: 6| Step: 11
Training loss: 3.2742920263196753
Validation loss: 2.5076466468687264

Epoch: 6| Step: 12
Training loss: 3.013446712920899
Validation loss: 2.5155642239767686

Epoch: 6| Step: 13
Training loss: 1.8044165866183326
Validation loss: 2.5183571773421045

Epoch: 188| Step: 0
Training loss: 1.9025387517163026
Validation loss: 2.518137008891695

Epoch: 6| Step: 1
Training loss: 2.6214060931283294
Validation loss: 2.5347577695498047

Epoch: 6| Step: 2
Training loss: 2.6569516321158035
Validation loss: 2.5162249485183756

Epoch: 6| Step: 3
Training loss: 3.2800098800510376
Validation loss: 2.5351048362305812

Epoch: 6| Step: 4
Training loss: 2.815964662850348
Validation loss: 2.5140041764601437

Epoch: 6| Step: 5
Training loss: 2.7064027703490074
Validation loss: 2.5028252639635453

Epoch: 6| Step: 6
Training loss: 2.899680310748241
Validation loss: 2.5098743332023994

Epoch: 6| Step: 7
Training loss: 2.739235182615971
Validation loss: 2.505976283301563

Epoch: 6| Step: 8
Training loss: 2.6866620553910256
Validation loss: 2.5013871702638526

Epoch: 6| Step: 9
Training loss: 3.1439455612361678
Validation loss: 2.5003254155668624

Epoch: 6| Step: 10
Training loss: 2.4491435013547638
Validation loss: 2.4947120207984623

Epoch: 6| Step: 11
Training loss: 3.0766387294549276
Validation loss: 2.506619969011334

Epoch: 6| Step: 12
Training loss: 2.9865194076042885
Validation loss: 2.496963188563466

Epoch: 6| Step: 13
Training loss: 2.792249893831942
Validation loss: 2.480257173105495

Epoch: 189| Step: 0
Training loss: 2.8369006158244146
Validation loss: 2.492365879543086

Epoch: 6| Step: 1
Training loss: 2.7525895670801677
Validation loss: 2.4952174946432697

Epoch: 6| Step: 2
Training loss: 3.222262345718267
Validation loss: 2.489272043362253

Epoch: 6| Step: 3
Training loss: 2.9512759278066123
Validation loss: 2.4861567356282177

Epoch: 6| Step: 4
Training loss: 2.669504910261801
Validation loss: 2.4904260831258602

Epoch: 6| Step: 5
Training loss: 2.901208586259583
Validation loss: 2.4934148855605143

Epoch: 6| Step: 6
Training loss: 2.5691267716433175
Validation loss: 2.4762538993122987

Epoch: 6| Step: 7
Training loss: 2.9545622058206806
Validation loss: 2.487882083235179

Epoch: 6| Step: 8
Training loss: 2.78616182169769
Validation loss: 2.478278982423821

Epoch: 6| Step: 9
Training loss: 2.5875096454532724
Validation loss: 2.4836221282839275

Epoch: 6| Step: 10
Training loss: 2.7147921111320916
Validation loss: 2.5123339315749007

Epoch: 6| Step: 11
Training loss: 2.4663742802855575
Validation loss: 2.5238891388391473

Epoch: 6| Step: 12
Training loss: 2.5555000529504754
Validation loss: 2.551515576257724

Epoch: 6| Step: 13
Training loss: 3.0143918693461176
Validation loss: 2.5377989850618414

Epoch: 190| Step: 0
Training loss: 2.606065490192517
Validation loss: 2.5526450745419553

Epoch: 6| Step: 1
Training loss: 3.194100819410005
Validation loss: 2.5668558355723747

Epoch: 6| Step: 2
Training loss: 2.509504371434045
Validation loss: 2.5206986878397317

Epoch: 6| Step: 3
Training loss: 2.8451661995611084
Validation loss: 2.514438530499831

Epoch: 6| Step: 4
Training loss: 2.6105769695514893
Validation loss: 2.5007549069030435

Epoch: 6| Step: 5
Training loss: 3.095447883552957
Validation loss: 2.4800687496303273

Epoch: 6| Step: 6
Training loss: 3.1569838473342084
Validation loss: 2.4751312352821637

Epoch: 6| Step: 7
Training loss: 2.9545236333294653
Validation loss: 2.4900711881801

Epoch: 6| Step: 8
Training loss: 2.721676358705804
Validation loss: 2.4820093185951118

Epoch: 6| Step: 9
Training loss: 2.485991905475429
Validation loss: 2.4784068736329132

Epoch: 6| Step: 10
Training loss: 2.5957378445406554
Validation loss: 2.4825439670953147

Epoch: 6| Step: 11
Training loss: 2.8901063195969483
Validation loss: 2.5031384221596453

Epoch: 6| Step: 12
Training loss: 2.530244604054647
Validation loss: 2.5045849482424076

Epoch: 6| Step: 13
Training loss: 2.761194419456876
Validation loss: 2.5165050803779963

Epoch: 191| Step: 0
Training loss: 2.205751625376058
Validation loss: 2.5274015131797563

Epoch: 6| Step: 1
Training loss: 3.1545688193047843
Validation loss: 2.5045393340746602

Epoch: 6| Step: 2
Training loss: 2.6650616067203297
Validation loss: 2.514165502940164

Epoch: 6| Step: 3
Training loss: 2.782974480054483
Validation loss: 2.5191970480172303

Epoch: 6| Step: 4
Training loss: 2.215723794690279
Validation loss: 2.5339788870696065

Epoch: 6| Step: 5
Training loss: 2.9600371348139434
Validation loss: 2.5378418528129227

Epoch: 6| Step: 6
Training loss: 2.75063004645587
Validation loss: 2.5390160583338006

Epoch: 6| Step: 7
Training loss: 3.4072359390545244
Validation loss: 2.5136381188250843

Epoch: 6| Step: 8
Training loss: 2.5422122140537717
Validation loss: 2.5134041394989652

Epoch: 6| Step: 9
Training loss: 3.024315521733802
Validation loss: 2.497601049258822

Epoch: 6| Step: 10
Training loss: 2.9199934016113978
Validation loss: 2.4882424367737

Epoch: 6| Step: 11
Training loss: 2.8862804859611506
Validation loss: 2.4935947369159184

Epoch: 6| Step: 12
Training loss: 2.491501094798736
Validation loss: 2.4856656973801545

Epoch: 6| Step: 13
Training loss: 2.755631489459482
Validation loss: 2.482578299929684

Epoch: 192| Step: 0
Training loss: 2.4227133991742758
Validation loss: 2.48681447177928

Epoch: 6| Step: 1
Training loss: 2.911854907455932
Validation loss: 2.498701387932534

Epoch: 6| Step: 2
Training loss: 2.629003015695658
Validation loss: 2.513620315518762

Epoch: 6| Step: 3
Training loss: 2.919009185327007
Validation loss: 2.533511725366544

Epoch: 6| Step: 4
Training loss: 2.68665229380181
Validation loss: 2.594260276141514

Epoch: 6| Step: 5
Training loss: 2.8303780196091686
Validation loss: 2.6241611697193643

Epoch: 6| Step: 6
Training loss: 2.9030001938912133
Validation loss: 2.5920018990407288

Epoch: 6| Step: 7
Training loss: 3.4403846428093643
Validation loss: 2.584134443739009

Epoch: 6| Step: 8
Training loss: 3.0541123729284436
Validation loss: 2.596059631518657

Epoch: 6| Step: 9
Training loss: 2.0357718973444885
Validation loss: 2.5766071324843334

Epoch: 6| Step: 10
Training loss: 2.5215885722927682
Validation loss: 2.5712942390509275

Epoch: 6| Step: 11
Training loss: 2.846146129510455
Validation loss: 2.520406373804109

Epoch: 6| Step: 12
Training loss: 2.6336181494647133
Validation loss: 2.4950217785424096

Epoch: 6| Step: 13
Training loss: 2.9792349925353436
Validation loss: 2.479022614314882

Epoch: 193| Step: 0
Training loss: 2.6644627782190713
Validation loss: 2.4700274357611516

Epoch: 6| Step: 1
Training loss: 2.849860532593975
Validation loss: 2.4839853321809056

Epoch: 6| Step: 2
Training loss: 2.3963838912180484
Validation loss: 2.4731443887186626

Epoch: 6| Step: 3
Training loss: 2.749031069594201
Validation loss: 2.48255803714005

Epoch: 6| Step: 4
Training loss: 2.767263670550942
Validation loss: 2.4880529385133108

Epoch: 6| Step: 5
Training loss: 2.9120959480533855
Validation loss: 2.4757084360963075

Epoch: 6| Step: 6
Training loss: 2.5606244364266013
Validation loss: 2.4822585639365955

Epoch: 6| Step: 7
Training loss: 3.0467461974477947
Validation loss: 2.4808153192798352

Epoch: 6| Step: 8
Training loss: 3.3448692658882484
Validation loss: 2.5061823593175894

Epoch: 6| Step: 9
Training loss: 2.4976633596214692
Validation loss: 2.4952646179226385

Epoch: 6| Step: 10
Training loss: 2.7491778965543636
Validation loss: 2.5051182406272434

Epoch: 6| Step: 11
Training loss: 2.9691084795901648
Validation loss: 2.5029643829057218

Epoch: 6| Step: 12
Training loss: 2.7157178610496295
Validation loss: 2.5111551666953744

Epoch: 6| Step: 13
Training loss: 2.622935800480054
Validation loss: 2.516285265396614

Epoch: 194| Step: 0
Training loss: 2.60407344396945
Validation loss: 2.51266402862801

Epoch: 6| Step: 1
Training loss: 2.565446973378669
Validation loss: 2.551256531987803

Epoch: 6| Step: 2
Training loss: 2.6875468405256737
Validation loss: 2.5369258632585994

Epoch: 6| Step: 3
Training loss: 2.8998615231830804
Validation loss: 2.4938848851658837

Epoch: 6| Step: 4
Training loss: 3.169771897204917
Validation loss: 2.4999939949209633

Epoch: 6| Step: 5
Training loss: 2.5158511231955822
Validation loss: 2.5002468110354235

Epoch: 6| Step: 6
Training loss: 2.989581295282996
Validation loss: 2.487239607836917

Epoch: 6| Step: 7
Training loss: 2.965902950980735
Validation loss: 2.497121536117252

Epoch: 6| Step: 8
Training loss: 2.3467029533867994
Validation loss: 2.4901916688123977

Epoch: 6| Step: 9
Training loss: 2.7015953366439014
Validation loss: 2.488080542247371

Epoch: 6| Step: 10
Training loss: 3.0653529988515773
Validation loss: 2.491697946548913

Epoch: 6| Step: 11
Training loss: 2.725820883202836
Validation loss: 2.4887543791894147

Epoch: 6| Step: 12
Training loss: 2.6921120923640576
Validation loss: 2.502109510244469

Epoch: 6| Step: 13
Training loss: 2.7986255473944364
Validation loss: 2.5105519597618895

Epoch: 195| Step: 0
Training loss: 3.3406531708317293
Validation loss: 2.5339243145759354

Epoch: 6| Step: 1
Training loss: 2.926133260700032
Validation loss: 2.5427909597253135

Epoch: 6| Step: 2
Training loss: 2.8866283934289996
Validation loss: 2.5772808633291127

Epoch: 6| Step: 3
Training loss: 2.738179290658175
Validation loss: 2.588010812306946

Epoch: 6| Step: 4
Training loss: 2.7252188708399063
Validation loss: 2.565314597233043

Epoch: 6| Step: 5
Training loss: 2.655125817660056
Validation loss: 2.544701542746734

Epoch: 6| Step: 6
Training loss: 2.7850302390848807
Validation loss: 2.5074014312418504

Epoch: 6| Step: 7
Training loss: 2.8638947000166057
Validation loss: 2.495184982698737

Epoch: 6| Step: 8
Training loss: 2.8373312139515146
Validation loss: 2.4853704347560197

Epoch: 6| Step: 9
Training loss: 2.697056037776105
Validation loss: 2.4805588329682298

Epoch: 6| Step: 10
Training loss: 2.874547839889515
Validation loss: 2.4782102581888426

Epoch: 6| Step: 11
Training loss: 2.6224383616226814
Validation loss: 2.477095115816646

Epoch: 6| Step: 12
Training loss: 2.3593228568068776
Validation loss: 2.4824010191814794

Epoch: 6| Step: 13
Training loss: 2.365151010897995
Validation loss: 2.478692206252493

Epoch: 196| Step: 0
Training loss: 3.0271430755061712
Validation loss: 2.4746427394794797

Epoch: 6| Step: 1
Training loss: 3.014795851493776
Validation loss: 2.4799124434546216

Epoch: 6| Step: 2
Training loss: 2.5569480670344062
Validation loss: 2.4948950873738274

Epoch: 6| Step: 3
Training loss: 3.09745428093151
Validation loss: 2.5146867238821864

Epoch: 6| Step: 4
Training loss: 2.895557216589487
Validation loss: 2.5177765424093903

Epoch: 6| Step: 5
Training loss: 2.4068758262171253
Validation loss: 2.5380666835013743

Epoch: 6| Step: 6
Training loss: 2.539968100219819
Validation loss: 2.5694710647444188

Epoch: 6| Step: 7
Training loss: 3.014218649767053
Validation loss: 2.5879388384856297

Epoch: 6| Step: 8
Training loss: 3.004014190599675
Validation loss: 2.5252404052919584

Epoch: 6| Step: 9
Training loss: 2.7519966159955
Validation loss: 2.504728339371406

Epoch: 6| Step: 10
Training loss: 2.8519726601958153
Validation loss: 2.4854543555582618

Epoch: 6| Step: 11
Training loss: 2.25531670454621
Validation loss: 2.4735879292854452

Epoch: 6| Step: 12
Training loss: 2.648318037641498
Validation loss: 2.4643367232002142

Epoch: 6| Step: 13
Training loss: 2.9229290534853876
Validation loss: 2.4770952834766464

Epoch: 197| Step: 0
Training loss: 3.0344001682545954
Validation loss: 2.4798527760293902

Epoch: 6| Step: 1
Training loss: 2.8687164637115887
Validation loss: 2.4802158631494127

Epoch: 6| Step: 2
Training loss: 2.894260079761623
Validation loss: 2.4813282226984676

Epoch: 6| Step: 3
Training loss: 2.7745553356323316
Validation loss: 2.4736156669739446

Epoch: 6| Step: 4
Training loss: 3.03419178842735
Validation loss: 2.4723822738637273

Epoch: 6| Step: 5
Training loss: 2.9801757988503335
Validation loss: 2.472439286726568

Epoch: 6| Step: 6
Training loss: 2.500170511152963
Validation loss: 2.4721609217997162

Epoch: 6| Step: 7
Training loss: 1.943991400150225
Validation loss: 2.4824189694474743

Epoch: 6| Step: 8
Training loss: 2.7347637663084226
Validation loss: 2.494474883931098

Epoch: 6| Step: 9
Training loss: 2.7837620224198476
Validation loss: 2.507199945277795

Epoch: 6| Step: 10
Training loss: 2.9549090128411604
Validation loss: 2.5237230795662406

Epoch: 6| Step: 11
Training loss: 2.5596596397697224
Validation loss: 2.53934219220798

Epoch: 6| Step: 12
Training loss: 2.933994555363612
Validation loss: 2.5774125065221574

Epoch: 6| Step: 13
Training loss: 2.995610681854164
Validation loss: 2.576729184260002

Epoch: 198| Step: 0
Training loss: 2.998860460658348
Validation loss: 2.5438833215009327

Epoch: 6| Step: 1
Training loss: 2.4784200062204724
Validation loss: 2.5395044529970323

Epoch: 6| Step: 2
Training loss: 3.0987748463055045
Validation loss: 2.5352177465451122

Epoch: 6| Step: 3
Training loss: 2.8174244472660215
Validation loss: 2.5267306887703223

Epoch: 6| Step: 4
Training loss: 2.5569239168749256
Validation loss: 2.51502995200682

Epoch: 6| Step: 5
Training loss: 2.61800415051556
Validation loss: 2.4945179525389847

Epoch: 6| Step: 6
Training loss: 2.5657793786163037
Validation loss: 2.4936107596522312

Epoch: 6| Step: 7
Training loss: 2.6078190533171104
Validation loss: 2.4825112922713255

Epoch: 6| Step: 8
Training loss: 2.461330225050187
Validation loss: 2.4752036524539376

Epoch: 6| Step: 9
Training loss: 3.0192138189188564
Validation loss: 2.477046502217272

Epoch: 6| Step: 10
Training loss: 2.3324321868622535
Validation loss: 2.48063575157254

Epoch: 6| Step: 11
Training loss: 2.6552108527184424
Validation loss: 2.4806284759954913

Epoch: 6| Step: 12
Training loss: 3.5714770531769666
Validation loss: 2.4869245759736205

Epoch: 6| Step: 13
Training loss: 2.9222248704299565
Validation loss: 2.4903000506901987

Epoch: 199| Step: 0
Training loss: 3.152738222685361
Validation loss: 2.481124267054015

Epoch: 6| Step: 1
Training loss: 2.448761186949027
Validation loss: 2.4994688269623904

Epoch: 6| Step: 2
Training loss: 2.5754338871108033
Validation loss: 2.512760979612649

Epoch: 6| Step: 3
Training loss: 2.1362151227127364
Validation loss: 2.532141820699153

Epoch: 6| Step: 4
Training loss: 2.9603523743153866
Validation loss: 2.5225322357709654

Epoch: 6| Step: 5
Training loss: 2.7462629588971263
Validation loss: 2.522244663371189

Epoch: 6| Step: 6
Training loss: 2.41970412881077
Validation loss: 2.548086486597952

Epoch: 6| Step: 7
Training loss: 3.1076538843305768
Validation loss: 2.523448604111156

Epoch: 6| Step: 8
Training loss: 2.9859155004340665
Validation loss: 2.541888086312661

Epoch: 6| Step: 9
Training loss: 2.523458569323564
Validation loss: 2.5427562970853193

Epoch: 6| Step: 10
Training loss: 2.5047691631747258
Validation loss: 2.5537241837723

Epoch: 6| Step: 11
Training loss: 2.9864232888287274
Validation loss: 2.578853040253876

Epoch: 6| Step: 12
Training loss: 3.2095269959290973
Validation loss: 2.558084073967164

Epoch: 6| Step: 13
Training loss: 2.6948984021514986
Validation loss: 2.5125950398961474

Epoch: 200| Step: 0
Training loss: 2.5077800808055923
Validation loss: 2.5122673767343198

Epoch: 6| Step: 1
Training loss: 2.844420636925141
Validation loss: 2.517616158081686

Epoch: 6| Step: 2
Training loss: 2.9268817945357086
Validation loss: 2.516839911782273

Epoch: 6| Step: 3
Training loss: 2.75721505153172
Validation loss: 2.504985788611352

Epoch: 6| Step: 4
Training loss: 2.6527546942096563
Validation loss: 2.507012006765635

Epoch: 6| Step: 5
Training loss: 2.51420448902759
Validation loss: 2.5048671607183945

Epoch: 6| Step: 6
Training loss: 2.5210356723087965
Validation loss: 2.499954712365252

Epoch: 6| Step: 7
Training loss: 2.2564470326626678
Validation loss: 2.507865528242075

Epoch: 6| Step: 8
Training loss: 3.0887128108158186
Validation loss: 2.511257384362004

Epoch: 6| Step: 9
Training loss: 2.8105249039544713
Validation loss: 2.496227159609398

Epoch: 6| Step: 10
Training loss: 2.4601434304517236
Validation loss: 2.4966277913135744

Epoch: 6| Step: 11
Training loss: 3.107906895925725
Validation loss: 2.488811015975422

Epoch: 6| Step: 12
Training loss: 3.530409991523924
Validation loss: 2.49813272616554

Epoch: 6| Step: 13
Training loss: 2.181085828488955
Validation loss: 2.522735413711397

Epoch: 201| Step: 0
Training loss: 2.8268868280838455
Validation loss: 2.5288868797218043

Epoch: 6| Step: 1
Training loss: 2.4685339531343495
Validation loss: 2.5553014355670705

Epoch: 6| Step: 2
Training loss: 2.6344794817169106
Validation loss: 2.5525879423630604

Epoch: 6| Step: 3
Training loss: 2.7288998966050255
Validation loss: 2.542574593422625

Epoch: 6| Step: 4
Training loss: 2.697226731933567
Validation loss: 2.533672387496594

Epoch: 6| Step: 5
Training loss: 3.083130924351396
Validation loss: 2.529121676976709

Epoch: 6| Step: 6
Training loss: 2.4611513075214217
Validation loss: 2.526454148372185

Epoch: 6| Step: 7
Training loss: 2.7327337080260734
Validation loss: 2.5024078412669977

Epoch: 6| Step: 8
Training loss: 1.930592066223668
Validation loss: 2.4990350029848254

Epoch: 6| Step: 9
Training loss: 2.661352126857219
Validation loss: 2.5002781400493026

Epoch: 6| Step: 10
Training loss: 3.01844047396954
Validation loss: 2.513860350713704

Epoch: 6| Step: 11
Training loss: 2.7069112027234903
Validation loss: 2.508415543488574

Epoch: 6| Step: 12
Training loss: 3.0801244138385258
Validation loss: 2.463910434240236

Epoch: 6| Step: 13
Training loss: 3.4727356153929922
Validation loss: 2.4759075064272444

Epoch: 202| Step: 0
Training loss: 2.7242204723566035
Validation loss: 2.4613515447952454

Epoch: 6| Step: 1
Training loss: 2.499902341842577
Validation loss: 2.4602023817057894

Epoch: 6| Step: 2
Training loss: 2.9603593005090363
Validation loss: 2.4556218797195783

Epoch: 6| Step: 3
Training loss: 2.623287368849984
Validation loss: 2.46898897633551

Epoch: 6| Step: 4
Training loss: 3.334695839573418
Validation loss: 2.4630508154117523

Epoch: 6| Step: 5
Training loss: 2.9841008085347998
Validation loss: 2.4656964898329696

Epoch: 6| Step: 6
Training loss: 2.7110043388284137
Validation loss: 2.4649040719616693

Epoch: 6| Step: 7
Training loss: 2.0403468738429225
Validation loss: 2.471528716540397

Epoch: 6| Step: 8
Training loss: 3.0873902583213764
Validation loss: 2.481096635524012

Epoch: 6| Step: 9
Training loss: 3.3178831300945215
Validation loss: 2.5014915877303325

Epoch: 6| Step: 10
Training loss: 2.4747037922250272
Validation loss: 2.5146913879403052

Epoch: 6| Step: 11
Training loss: 2.4325115314143666
Validation loss: 2.5455781005289615

Epoch: 6| Step: 12
Training loss: 2.519333185498584
Validation loss: 2.5767358860356366

Epoch: 6| Step: 13
Training loss: 2.886297337146748
Validation loss: 2.592221359778176

Epoch: 203| Step: 0
Training loss: 2.645389028975516
Validation loss: 2.544222193704448

Epoch: 6| Step: 1
Training loss: 2.81008078055153
Validation loss: 2.5110258141955764

Epoch: 6| Step: 2
Training loss: 2.374686873022118
Validation loss: 2.502148131930507

Epoch: 6| Step: 3
Training loss: 2.7217481896765934
Validation loss: 2.49113713430006

Epoch: 6| Step: 4
Training loss: 2.7718399819760795
Validation loss: 2.49371134636313

Epoch: 6| Step: 5
Training loss: 2.332038099831596
Validation loss: 2.48383340822489

Epoch: 6| Step: 6
Training loss: 2.9979853223017647
Validation loss: 2.4815335118253334

Epoch: 6| Step: 7
Training loss: 3.08566290683963
Validation loss: 2.4987504953969952

Epoch: 6| Step: 8
Training loss: 2.129019358018815
Validation loss: 2.49324690044433

Epoch: 6| Step: 9
Training loss: 3.5444973273668774
Validation loss: 2.501271794983633

Epoch: 6| Step: 10
Training loss: 2.6444604771214437
Validation loss: 2.520884029685796

Epoch: 6| Step: 11
Training loss: 2.504661029716256
Validation loss: 2.5276393603068152

Epoch: 6| Step: 12
Training loss: 2.7574929546636255
Validation loss: 2.520891056876215

Epoch: 6| Step: 13
Training loss: 3.2322156396633224
Validation loss: 2.517969676342857

Epoch: 204| Step: 0
Training loss: 3.119058377418282
Validation loss: 2.530080547675892

Epoch: 6| Step: 1
Training loss: 2.753216856031404
Validation loss: 2.5177648929719316

Epoch: 6| Step: 2
Training loss: 2.584839556084803
Validation loss: 2.489893057119144

Epoch: 6| Step: 3
Training loss: 2.5829747679242625
Validation loss: 2.453395027351427

Epoch: 6| Step: 4
Training loss: 2.395102403239405
Validation loss: 2.478749237393871

Epoch: 6| Step: 5
Training loss: 3.083989941215686
Validation loss: 2.4756911749866783

Epoch: 6| Step: 6
Training loss: 2.6549361626085957
Validation loss: 2.470080257023754

Epoch: 6| Step: 7
Training loss: 2.7649454262505877
Validation loss: 2.4692772784695354

Epoch: 6| Step: 8
Training loss: 2.9717344040209905
Validation loss: 2.4817527552807506

Epoch: 6| Step: 9
Training loss: 2.9968122394183516
Validation loss: 2.480275048445951

Epoch: 6| Step: 10
Training loss: 2.810653928370748
Validation loss: 2.495001944586528

Epoch: 6| Step: 11
Training loss: 2.340963207302831
Validation loss: 2.494859240878114

Epoch: 6| Step: 12
Training loss: 2.76168508117958
Validation loss: 2.492204804240974

Epoch: 6| Step: 13
Training loss: 2.3471880301468704
Validation loss: 2.5298333750751083

Epoch: 205| Step: 0
Training loss: 2.5114081444321075
Validation loss: 2.565279696284493

Epoch: 6| Step: 1
Training loss: 3.1019806471909
Validation loss: 2.544256070079151

Epoch: 6| Step: 2
Training loss: 2.492933012330513
Validation loss: 2.5746741006889304

Epoch: 6| Step: 3
Training loss: 2.4313824497418834
Validation loss: 2.5537440324724776

Epoch: 6| Step: 4
Training loss: 3.156313753900509
Validation loss: 2.5320090762645737

Epoch: 6| Step: 5
Training loss: 2.1842166783228647
Validation loss: 2.4856573236743094

Epoch: 6| Step: 6
Training loss: 2.287610736105216
Validation loss: 2.4712020142712916

Epoch: 6| Step: 7
Training loss: 3.2173752302447385
Validation loss: 2.462674219208643

Epoch: 6| Step: 8
Training loss: 2.677073101415018
Validation loss: 2.471703169728937

Epoch: 6| Step: 9
Training loss: 2.8359494379806414
Validation loss: 2.462922060197455

Epoch: 6| Step: 10
Training loss: 2.790047351476355
Validation loss: 2.463550993141125

Epoch: 6| Step: 11
Training loss: 3.1721137196575175
Validation loss: 2.4760583626016164

Epoch: 6| Step: 12
Training loss: 2.876711626139864
Validation loss: 2.461442002974673

Epoch: 6| Step: 13
Training loss: 2.75005453229068
Validation loss: 2.4629343323063773

Epoch: 206| Step: 0
Training loss: 2.8905164543598096
Validation loss: 2.468824068502755

Epoch: 6| Step: 1
Training loss: 3.1079951152591296
Validation loss: 2.477809436947834

Epoch: 6| Step: 2
Training loss: 2.4858252173289253
Validation loss: 2.483893984267273

Epoch: 6| Step: 3
Training loss: 2.7644159292683645
Validation loss: 2.4768481403150475

Epoch: 6| Step: 4
Training loss: 2.7384609538929148
Validation loss: 2.4831750476431926

Epoch: 6| Step: 5
Training loss: 2.6811811104841086
Validation loss: 2.480861587687862

Epoch: 6| Step: 6
Training loss: 2.536107900068969
Validation loss: 2.504342133290124

Epoch: 6| Step: 7
Training loss: 2.595569569845266
Validation loss: 2.5004302085374164

Epoch: 6| Step: 8
Training loss: 2.7675262640143594
Validation loss: 2.5197205500624533

Epoch: 6| Step: 9
Training loss: 3.026212616303135
Validation loss: 2.53683095449184

Epoch: 6| Step: 10
Training loss: 2.899636568118986
Validation loss: 2.542520862338513

Epoch: 6| Step: 11
Training loss: 2.579004865839237
Validation loss: 2.5796968085570735

Epoch: 6| Step: 12
Training loss: 2.7746294066264436
Validation loss: 2.5550968007486166

Epoch: 6| Step: 13
Training loss: 2.5486367340139573
Validation loss: 2.5360674988536243

Epoch: 207| Step: 0
Training loss: 2.0112278015163487
Validation loss: 2.490218499374535

Epoch: 6| Step: 1
Training loss: 2.469154421359376
Validation loss: 2.474374750105079

Epoch: 6| Step: 2
Training loss: 2.3650258080201403
Validation loss: 2.4769690250380916

Epoch: 6| Step: 3
Training loss: 3.31280141934565
Validation loss: 2.479375791290827

Epoch: 6| Step: 4
Training loss: 2.834213867990861
Validation loss: 2.479021626717076

Epoch: 6| Step: 5
Training loss: 2.601617669331043
Validation loss: 2.473182070608505

Epoch: 6| Step: 6
Training loss: 3.0226480404527147
Validation loss: 2.4749400681305462

Epoch: 6| Step: 7
Training loss: 2.7253192154686015
Validation loss: 2.4737771344927535

Epoch: 6| Step: 8
Training loss: 2.635670907242902
Validation loss: 2.4759425691054417

Epoch: 6| Step: 9
Training loss: 3.023501531036277
Validation loss: 2.4874020116127853

Epoch: 6| Step: 10
Training loss: 2.9902855627660725
Validation loss: 2.4795337038898446

Epoch: 6| Step: 11
Training loss: 2.5307140018322545
Validation loss: 2.4929518431326105

Epoch: 6| Step: 12
Training loss: 2.9090356090014566
Validation loss: 2.4741697726003298

Epoch: 6| Step: 13
Training loss: 2.8641795665667638
Validation loss: 2.5048832177890636

Epoch: 208| Step: 0
Training loss: 3.1907816430925644
Validation loss: 2.51062867526275

Epoch: 6| Step: 1
Training loss: 2.583964998687273
Validation loss: 2.546155354674141

Epoch: 6| Step: 2
Training loss: 3.354524170835519
Validation loss: 2.5621883964215573

Epoch: 6| Step: 3
Training loss: 2.7801806505086843
Validation loss: 2.5563641511812927

Epoch: 6| Step: 4
Training loss: 2.3055359393999892
Validation loss: 2.566437445157367

Epoch: 6| Step: 5
Training loss: 2.5772794319446053
Validation loss: 2.53744440737678

Epoch: 6| Step: 6
Training loss: 3.1722724552783257
Validation loss: 2.5363579159739364

Epoch: 6| Step: 7
Training loss: 2.4827291927201336
Validation loss: 2.5300322499656325

Epoch: 6| Step: 8
Training loss: 2.9346136969026824
Validation loss: 2.5322690097847143

Epoch: 6| Step: 9
Training loss: 2.1731777537813213
Validation loss: 2.51687280505676

Epoch: 6| Step: 10
Training loss: 2.1578302535998586
Validation loss: 2.509140536533708

Epoch: 6| Step: 11
Training loss: 2.7005001841055756
Validation loss: 2.49891278201287

Epoch: 6| Step: 12
Training loss: 3.16314910137806
Validation loss: 2.49502137062396

Epoch: 6| Step: 13
Training loss: 2.158638557247925
Validation loss: 2.4918483220827543

Epoch: 209| Step: 0
Training loss: 2.606615994961749
Validation loss: 2.5020395808837774

Epoch: 6| Step: 1
Training loss: 3.204349042036951
Validation loss: 2.4871103597573483

Epoch: 6| Step: 2
Training loss: 2.163058712617893
Validation loss: 2.484983473277742

Epoch: 6| Step: 3
Training loss: 2.454086406887146
Validation loss: 2.4961441699712017

Epoch: 6| Step: 4
Training loss: 2.5236934378540954
Validation loss: 2.5004079567904602

Epoch: 6| Step: 5
Training loss: 2.5014442087067343
Validation loss: 2.526209946509537

Epoch: 6| Step: 6
Training loss: 2.190458531387497
Validation loss: 2.521551583793978

Epoch: 6| Step: 7
Training loss: 3.0510241305566983
Validation loss: 2.519675904814915

Epoch: 6| Step: 8
Training loss: 2.8574397307520543
Validation loss: 2.532278107599795

Epoch: 6| Step: 9
Training loss: 3.0958012417909386
Validation loss: 2.5146063855250436

Epoch: 6| Step: 10
Training loss: 2.300820627183197
Validation loss: 2.519196763077464

Epoch: 6| Step: 11
Training loss: 3.0095720173169127
Validation loss: 2.5044183490726706

Epoch: 6| Step: 12
Training loss: 3.0945849592386843
Validation loss: 2.4956411509536975

Epoch: 6| Step: 13
Training loss: 2.8505784100298865
Validation loss: 2.485147501721554

Epoch: 210| Step: 0
Training loss: 2.4047188779730737
Validation loss: 2.4885830611094484

Epoch: 6| Step: 1
Training loss: 2.9909962008192905
Validation loss: 2.4925647405978273

Epoch: 6| Step: 2
Training loss: 2.4879932087134007
Validation loss: 2.4902899219061183

Epoch: 6| Step: 3
Training loss: 3.030352587439161
Validation loss: 2.4924352266034657

Epoch: 6| Step: 4
Training loss: 2.6850709805616493
Validation loss: 2.495986284236176

Epoch: 6| Step: 5
Training loss: 3.3009173303125325
Validation loss: 2.500361486162494

Epoch: 6| Step: 6
Training loss: 2.90218536643045
Validation loss: 2.484722821764215

Epoch: 6| Step: 7
Training loss: 2.5409343685965475
Validation loss: 2.4943697009898003

Epoch: 6| Step: 8
Training loss: 2.616938883801361
Validation loss: 2.496089052218396

Epoch: 6| Step: 9
Training loss: 2.892729122282683
Validation loss: 2.4940600493365346

Epoch: 6| Step: 10
Training loss: 2.960565790281308
Validation loss: 2.501682523376686

Epoch: 6| Step: 11
Training loss: 2.29293225338954
Validation loss: 2.5199937875846574

Epoch: 6| Step: 12
Training loss: 2.6005437649134038
Validation loss: 2.5200431301842343

Epoch: 6| Step: 13
Training loss: 2.3223123377279857
Validation loss: 2.533311497389635

Epoch: 211| Step: 0
Training loss: 2.485622644536027
Validation loss: 2.565386104544163

Epoch: 6| Step: 1
Training loss: 2.658696921266663
Validation loss: 2.5601819806828647

Epoch: 6| Step: 2
Training loss: 2.942203246574382
Validation loss: 2.527173797116581

Epoch: 6| Step: 3
Training loss: 3.3457951931107743
Validation loss: 2.528468565758953

Epoch: 6| Step: 4
Training loss: 3.11477697954833
Validation loss: 2.4940296326059292

Epoch: 6| Step: 5
Training loss: 2.653198643753025
Validation loss: 2.496379567803868

Epoch: 6| Step: 6
Training loss: 2.4537387736098175
Validation loss: 2.4897609566150902

Epoch: 6| Step: 7
Training loss: 2.6372782247871616
Validation loss: 2.4995605636287728

Epoch: 6| Step: 8
Training loss: 2.6981361525717973
Validation loss: 2.4799831383671447

Epoch: 6| Step: 9
Training loss: 2.6464518527464334
Validation loss: 2.486790555968205

Epoch: 6| Step: 10
Training loss: 2.303900425885155
Validation loss: 2.4856265906222554

Epoch: 6| Step: 11
Training loss: 3.008208489051022
Validation loss: 2.488292463604493

Epoch: 6| Step: 12
Training loss: 2.4634320891341575
Validation loss: 2.491797258589734

Epoch: 6| Step: 13
Training loss: 2.4995494436527252
Validation loss: 2.4946972424092646

Epoch: 212| Step: 0
Training loss: 3.001403480300924
Validation loss: 2.488643763622477

Epoch: 6| Step: 1
Training loss: 2.5802544324933088
Validation loss: 2.5105175770227595

Epoch: 6| Step: 2
Training loss: 2.7409200755243845
Validation loss: 2.5155409942401157

Epoch: 6| Step: 3
Training loss: 3.1115160141204368
Validation loss: 2.5226178979468923

Epoch: 6| Step: 4
Training loss: 2.356719284477393
Validation loss: 2.550030632969081

Epoch: 6| Step: 5
Training loss: 2.872894511276877
Validation loss: 2.556867701975992

Epoch: 6| Step: 6
Training loss: 2.9736531775267343
Validation loss: 2.566915835620948

Epoch: 6| Step: 7
Training loss: 2.4212109055166837
Validation loss: 2.547673086581364

Epoch: 6| Step: 8
Training loss: 2.307766167363483
Validation loss: 2.526103305265483

Epoch: 6| Step: 9
Training loss: 3.267897403894867
Validation loss: 2.4940244437055163

Epoch: 6| Step: 10
Training loss: 2.6860661784843933
Validation loss: 2.4618033968414337

Epoch: 6| Step: 11
Training loss: 2.445719627150444
Validation loss: 2.475666265302322

Epoch: 6| Step: 12
Training loss: 2.1649256337985214
Validation loss: 2.4628303880034084

Epoch: 6| Step: 13
Training loss: 3.1359302864695
Validation loss: 2.4615923256271697

Epoch: 213| Step: 0
Training loss: 2.7656198275242945
Validation loss: 2.4719722742508456

Epoch: 6| Step: 1
Training loss: 2.636400986350073
Validation loss: 2.480710896493769

Epoch: 6| Step: 2
Training loss: 2.8368195982551363
Validation loss: 2.484329903249344

Epoch: 6| Step: 3
Training loss: 2.6798057418849415
Validation loss: 2.483703362032989

Epoch: 6| Step: 4
Training loss: 2.613311448086685
Validation loss: 2.48158435056131

Epoch: 6| Step: 5
Training loss: 2.923468986272351
Validation loss: 2.475472390942803

Epoch: 6| Step: 6
Training loss: 3.04839345801452
Validation loss: 2.4922481023776606

Epoch: 6| Step: 7
Training loss: 2.925823297949689
Validation loss: 2.48231947481209

Epoch: 6| Step: 8
Training loss: 2.5404106434462923
Validation loss: 2.521864210845431

Epoch: 6| Step: 9
Training loss: 2.235950901249912
Validation loss: 2.5346040682905

Epoch: 6| Step: 10
Training loss: 2.798840562003508
Validation loss: 2.5337709578618415

Epoch: 6| Step: 11
Training loss: 2.396326086262143
Validation loss: 2.5566391870733436

Epoch: 6| Step: 12
Training loss: 3.0527207855683614
Validation loss: 2.597726720001644

Epoch: 6| Step: 13
Training loss: 2.559659919203631
Validation loss: 2.618387550620399

Epoch: 214| Step: 0
Training loss: 2.545505272372227
Validation loss: 2.6571321338857894

Epoch: 6| Step: 1
Training loss: 2.5172072463678856
Validation loss: 2.716901206911664

Epoch: 6| Step: 2
Training loss: 2.8078863661724123
Validation loss: 2.733712391064628

Epoch: 6| Step: 3
Training loss: 2.623089231147692
Validation loss: 2.7021659891626206

Epoch: 6| Step: 4
Training loss: 3.7445925826349007
Validation loss: 2.727409302988709

Epoch: 6| Step: 5
Training loss: 3.0789564529813456
Validation loss: 2.6931407147572557

Epoch: 6| Step: 6
Training loss: 1.716793542018949
Validation loss: 2.6285102020659745

Epoch: 6| Step: 7
Training loss: 2.50556612268641
Validation loss: 2.559558426601062

Epoch: 6| Step: 8
Training loss: 1.8898756575680091
Validation loss: 2.5207809473986407

Epoch: 6| Step: 9
Training loss: 2.714449144405225
Validation loss: 2.492323193421173

Epoch: 6| Step: 10
Training loss: 2.936771545990986
Validation loss: 2.4708876362930603

Epoch: 6| Step: 11
Training loss: 2.6878551869439407
Validation loss: 2.457563501508035

Epoch: 6| Step: 12
Training loss: 3.1594391375784565
Validation loss: 2.4428504758883283

Epoch: 6| Step: 13
Training loss: 2.9500933228295203
Validation loss: 2.446570686993897

Epoch: 215| Step: 0
Training loss: 2.399492659191708
Validation loss: 2.4567177780565213

Epoch: 6| Step: 1
Training loss: 3.0944632276432578
Validation loss: 2.4516117676676705

Epoch: 6| Step: 2
Training loss: 2.130215359577508
Validation loss: 2.4522016208825956

Epoch: 6| Step: 3
Training loss: 2.8040034487998313
Validation loss: 2.4501269452237455

Epoch: 6| Step: 4
Training loss: 2.7607641229341686
Validation loss: 2.4681384210585167

Epoch: 6| Step: 5
Training loss: 2.235307725549028
Validation loss: 2.4600589828096435

Epoch: 6| Step: 6
Training loss: 2.7557979498492022
Validation loss: 2.4688955949183042

Epoch: 6| Step: 7
Training loss: 2.77630621607998
Validation loss: 2.487254118231282

Epoch: 6| Step: 8
Training loss: 2.905732139471466
Validation loss: 2.5176634119851387

Epoch: 6| Step: 9
Training loss: 2.8283547998294454
Validation loss: 2.5154912168209673

Epoch: 6| Step: 10
Training loss: 2.6506133467353554
Validation loss: 2.5334496946062637

Epoch: 6| Step: 11
Training loss: 3.3945777459686046
Validation loss: 2.5459251401621543

Epoch: 6| Step: 12
Training loss: 2.79250416126129
Validation loss: 2.540651261473521

Epoch: 6| Step: 13
Training loss: 2.153145365625632
Validation loss: 2.5366645448353573

Epoch: 216| Step: 0
Training loss: 2.4895705112355864
Validation loss: 2.552548581864923

Epoch: 6| Step: 1
Training loss: 3.1555990926518094
Validation loss: 2.5496848298272514

Epoch: 6| Step: 2
Training loss: 2.881888719706824
Validation loss: 2.5435005550444187

Epoch: 6| Step: 3
Training loss: 2.917100074900562
Validation loss: 2.523731333065316

Epoch: 6| Step: 4
Training loss: 2.4188027861599135
Validation loss: 2.5252813878331906

Epoch: 6| Step: 5
Training loss: 2.3533729858227725
Validation loss: 2.4792846561301407

Epoch: 6| Step: 6
Training loss: 2.4790664673973892
Validation loss: 2.479952927333543

Epoch: 6| Step: 7
Training loss: 2.206455932170215
Validation loss: 2.4629190978115334

Epoch: 6| Step: 8
Training loss: 3.4610780295608743
Validation loss: 2.4675611315395183

Epoch: 6| Step: 9
Training loss: 2.621851622485218
Validation loss: 2.4831022631046524

Epoch: 6| Step: 10
Training loss: 2.6881893959305683
Validation loss: 2.4800585924988074

Epoch: 6| Step: 11
Training loss: 2.53103938227248
Validation loss: 2.4651900169569316

Epoch: 6| Step: 12
Training loss: 2.2048203458713727
Validation loss: 2.4750588884968354

Epoch: 6| Step: 13
Training loss: 3.131484665900275
Validation loss: 2.4902418258333547

Epoch: 217| Step: 0
Training loss: 2.3617252997112907
Validation loss: 2.512611055743573

Epoch: 6| Step: 1
Training loss: 2.728296291571363
Validation loss: 2.5147333232961744

Epoch: 6| Step: 2
Training loss: 2.361437369849387
Validation loss: 2.527244856931293

Epoch: 6| Step: 3
Training loss: 2.4917946628453693
Validation loss: 2.5066765017939425

Epoch: 6| Step: 4
Training loss: 2.3631074195173563
Validation loss: 2.5093879993700536

Epoch: 6| Step: 5
Training loss: 2.830623976862464
Validation loss: 2.5308587609885653

Epoch: 6| Step: 6
Training loss: 3.083313263149065
Validation loss: 2.5143237255608746

Epoch: 6| Step: 7
Training loss: 2.4216075134228836
Validation loss: 2.515447922312795

Epoch: 6| Step: 8
Training loss: 2.676424224898272
Validation loss: 2.5241547191382363

Epoch: 6| Step: 9
Training loss: 2.920956064240548
Validation loss: 2.5225111312699475

Epoch: 6| Step: 10
Training loss: 2.2249247634683025
Validation loss: 2.5174447195510785

Epoch: 6| Step: 11
Training loss: 2.7507467989834904
Validation loss: 2.5159570862921816

Epoch: 6| Step: 12
Training loss: 2.961707988730532
Validation loss: 2.5182851612578623

Epoch: 6| Step: 13
Training loss: 3.309897786201643
Validation loss: 2.518523605685405

Epoch: 218| Step: 0
Training loss: 2.5485009929856375
Validation loss: 2.5279300550600032

Epoch: 6| Step: 1
Training loss: 2.359649844297944
Validation loss: 2.532809329310051

Epoch: 6| Step: 2
Training loss: 2.9122695111277626
Validation loss: 2.5298245881855155

Epoch: 6| Step: 3
Training loss: 3.116441221464127
Validation loss: 2.5105422879568677

Epoch: 6| Step: 4
Training loss: 2.3067718907796904
Validation loss: 2.4936344013534715

Epoch: 6| Step: 5
Training loss: 2.841186373963644
Validation loss: 2.4947019993316624

Epoch: 6| Step: 6
Training loss: 2.7607741406335324
Validation loss: 2.4937098721501005

Epoch: 6| Step: 7
Training loss: 2.1134209154835717
Validation loss: 2.4978204537471904

Epoch: 6| Step: 8
Training loss: 2.786384814471983
Validation loss: 2.4932569257033363

Epoch: 6| Step: 9
Training loss: 2.72868076881451
Validation loss: 2.5084408116830708

Epoch: 6| Step: 10
Training loss: 2.2944680402320894
Validation loss: 2.5281227023279556

Epoch: 6| Step: 11
Training loss: 2.48684569528268
Validation loss: 2.5276430704051425

Epoch: 6| Step: 12
Training loss: 3.2825015632991743
Validation loss: 2.539239403909538

Epoch: 6| Step: 13
Training loss: 2.614067472554623
Validation loss: 2.5536000496019455

Epoch: 219| Step: 0
Training loss: 2.970706335262894
Validation loss: 2.5599778671839664

Epoch: 6| Step: 1
Training loss: 3.069206834651596
Validation loss: 2.574948657342642

Epoch: 6| Step: 2
Training loss: 2.877748585294764
Validation loss: 2.578414597440679

Epoch: 6| Step: 3
Training loss: 3.3372091330891496
Validation loss: 2.5424604106126285

Epoch: 6| Step: 4
Training loss: 2.4825248306738263
Validation loss: 2.538706982935847

Epoch: 6| Step: 5
Training loss: 2.405393968381779
Validation loss: 2.485899810403213

Epoch: 6| Step: 6
Training loss: 2.9055417746352212
Validation loss: 2.4787917280611604

Epoch: 6| Step: 7
Training loss: 2.4869888278846757
Validation loss: 2.466124933255179

Epoch: 6| Step: 8
Training loss: 2.775041916676709
Validation loss: 2.4647370300336813

Epoch: 6| Step: 9
Training loss: 2.492308036735344
Validation loss: 2.4570448192431273

Epoch: 6| Step: 10
Training loss: 2.2813657966383403
Validation loss: 2.455026654355514

Epoch: 6| Step: 11
Training loss: 2.0941973535688034
Validation loss: 2.452697750141778

Epoch: 6| Step: 12
Training loss: 2.9535296127619772
Validation loss: 2.447454487342038

Epoch: 6| Step: 13
Training loss: 2.1304698556604094
Validation loss: 2.460169265305143

Epoch: 220| Step: 0
Training loss: 2.895529385722753
Validation loss: 2.482924025461728

Epoch: 6| Step: 1
Training loss: 2.700422932031355
Validation loss: 2.4962597791654884

Epoch: 6| Step: 2
Training loss: 2.4542365987644392
Validation loss: 2.5232677320700367

Epoch: 6| Step: 3
Training loss: 2.848103136284666
Validation loss: 2.545191480382759

Epoch: 6| Step: 4
Training loss: 2.5845222403524533
Validation loss: 2.5250324458772146

Epoch: 6| Step: 5
Training loss: 2.274485762609642
Validation loss: 2.5314521977183446

Epoch: 6| Step: 6
Training loss: 2.696223008432342
Validation loss: 2.527073539529126

Epoch: 6| Step: 7
Training loss: 2.9162770873968875
Validation loss: 2.51671329214152

Epoch: 6| Step: 8
Training loss: 2.293415812332521
Validation loss: 2.5216006392009986

Epoch: 6| Step: 9
Training loss: 2.349216241204077
Validation loss: 2.5171002063947894

Epoch: 6| Step: 10
Training loss: 3.630476136730569
Validation loss: 2.519865407658591

Epoch: 6| Step: 11
Training loss: 2.765851889748508
Validation loss: 2.537631151798794

Epoch: 6| Step: 12
Training loss: 2.454821734822278
Validation loss: 2.545373056156553

Epoch: 6| Step: 13
Training loss: 2.721272580811398
Validation loss: 2.524553328645283

Epoch: 221| Step: 0
Training loss: 2.777021129128033
Validation loss: 2.4971539396920126

Epoch: 6| Step: 1
Training loss: 2.5025276757233335
Validation loss: 2.4900066173617255

Epoch: 6| Step: 2
Training loss: 2.395444512259868
Validation loss: 2.490643734760546

Epoch: 6| Step: 3
Training loss: 3.366599188654019
Validation loss: 2.481969449784423

Epoch: 6| Step: 4
Training loss: 2.210066660915665
Validation loss: 2.4730216998796792

Epoch: 6| Step: 5
Training loss: 2.340050384109474
Validation loss: 2.475721073525662

Epoch: 6| Step: 6
Training loss: 2.9565629273299288
Validation loss: 2.455570934647593

Epoch: 6| Step: 7
Training loss: 2.5550719738880248
Validation loss: 2.4798410006456777

Epoch: 6| Step: 8
Training loss: 3.249103128953916
Validation loss: 2.4679700357419714

Epoch: 6| Step: 9
Training loss: 2.819189297093524
Validation loss: 2.466827632714994

Epoch: 6| Step: 10
Training loss: 2.772225472400147
Validation loss: 2.5005520969833146

Epoch: 6| Step: 11
Training loss: 1.5416134833707817
Validation loss: 2.492008278520201

Epoch: 6| Step: 12
Training loss: 2.754728067481261
Validation loss: 2.5227100986617295

Epoch: 6| Step: 13
Training loss: 2.943001323506521
Validation loss: 2.5372305562474455

Epoch: 222| Step: 0
Training loss: 2.5736473271259617
Validation loss: 2.5229367355803474

Epoch: 6| Step: 1
Training loss: 3.282028541845318
Validation loss: 2.53785347272166

Epoch: 6| Step: 2
Training loss: 2.7872409375154863
Validation loss: 2.5629781241452614

Epoch: 6| Step: 3
Training loss: 2.552235024024803
Validation loss: 2.5411237953585526

Epoch: 6| Step: 4
Training loss: 2.6869177076588544
Validation loss: 2.4922570978692717

Epoch: 6| Step: 5
Training loss: 2.954082676850789
Validation loss: 2.477156650414441

Epoch: 6| Step: 6
Training loss: 2.28118290214626
Validation loss: 2.465930880018345

Epoch: 6| Step: 7
Training loss: 2.6567542102450474
Validation loss: 2.4701251749141506

Epoch: 6| Step: 8
Training loss: 2.653367846262894
Validation loss: 2.469244097934381

Epoch: 6| Step: 9
Training loss: 2.012444641110089
Validation loss: 2.4507522159049766

Epoch: 6| Step: 10
Training loss: 2.6645182558115414
Validation loss: 2.4513269934658997

Epoch: 6| Step: 11
Training loss: 2.513120269125826
Validation loss: 2.450843793850719

Epoch: 6| Step: 12
Training loss: 3.1498475052993635
Validation loss: 2.4390233214912755

Epoch: 6| Step: 13
Training loss: 2.292994952336448
Validation loss: 2.4538433798892276

Epoch: 223| Step: 0
Training loss: 2.4910213408779196
Validation loss: 2.4541712031555893

Epoch: 6| Step: 1
Training loss: 2.662927917335733
Validation loss: 2.458167665119433

Epoch: 6| Step: 2
Training loss: 2.4721557689217297
Validation loss: 2.4707731060075284

Epoch: 6| Step: 3
Training loss: 2.9757666938247462
Validation loss: 2.479721962286306

Epoch: 6| Step: 4
Training loss: 2.8991900595517723
Validation loss: 2.494379428822563

Epoch: 6| Step: 5
Training loss: 2.910151989824902
Validation loss: 2.527835606688778

Epoch: 6| Step: 6
Training loss: 2.9232481315604866
Validation loss: 2.540731189984158

Epoch: 6| Step: 7
Training loss: 1.7983053733884136
Validation loss: 2.551051972667955

Epoch: 6| Step: 8
Training loss: 3.1219430849213574
Validation loss: 2.5523359821988008

Epoch: 6| Step: 9
Training loss: 2.2047680078375116
Validation loss: 2.5596237888472926

Epoch: 6| Step: 10
Training loss: 2.542981500784085
Validation loss: 2.5513243697923476

Epoch: 6| Step: 11
Training loss: 3.18716503702045
Validation loss: 2.505083797124878

Epoch: 6| Step: 12
Training loss: 1.9330874618304417
Validation loss: 2.5004606181519766

Epoch: 6| Step: 13
Training loss: 2.9442191687562724
Validation loss: 2.479337909878839

Epoch: 224| Step: 0
Training loss: 1.9500738496734675
Validation loss: 2.4800405698452206

Epoch: 6| Step: 1
Training loss: 2.5805612785988554
Validation loss: 2.4708030931108413

Epoch: 6| Step: 2
Training loss: 2.0986266777335882
Validation loss: 2.4673279757819806

Epoch: 6| Step: 3
Training loss: 3.1171391610052104
Validation loss: 2.4556262143553838

Epoch: 6| Step: 4
Training loss: 3.153836980308947
Validation loss: 2.4736515057398334

Epoch: 6| Step: 5
Training loss: 2.701556858919519
Validation loss: 2.4599633573638835

Epoch: 6| Step: 6
Training loss: 2.400236567123232
Validation loss: 2.461671588542394

Epoch: 6| Step: 7
Training loss: 2.1428416115334192
Validation loss: 2.4697740818397484

Epoch: 6| Step: 8
Training loss: 2.7783496607083498
Validation loss: 2.46400446029758

Epoch: 6| Step: 9
Training loss: 2.4269435880539016
Validation loss: 2.478892049955626

Epoch: 6| Step: 10
Training loss: 3.4150928190918464
Validation loss: 2.4860356407773683

Epoch: 6| Step: 11
Training loss: 2.9341141687398933
Validation loss: 2.5150811829140043

Epoch: 6| Step: 12
Training loss: 2.251456636882543
Validation loss: 2.5465429751309565

Epoch: 6| Step: 13
Training loss: 3.0312872815543215
Validation loss: 2.535069170993923

Epoch: 225| Step: 0
Training loss: 2.1422653039427226
Validation loss: 2.5555546888591025

Epoch: 6| Step: 1
Training loss: 3.2593109563458733
Validation loss: 2.572740239795305

Epoch: 6| Step: 2
Training loss: 2.7532314041827335
Validation loss: 2.589307881140225

Epoch: 6| Step: 3
Training loss: 2.950002321145389
Validation loss: 2.569330679176331

Epoch: 6| Step: 4
Training loss: 3.065624744909122
Validation loss: 2.553717302144148

Epoch: 6| Step: 5
Training loss: 2.818647151855407
Validation loss: 2.52979555100219

Epoch: 6| Step: 6
Training loss: 2.61961357062438
Validation loss: 2.4913666294869907

Epoch: 6| Step: 7
Training loss: 2.2911798364663096
Validation loss: 2.4834696277739603

Epoch: 6| Step: 8
Training loss: 2.7191240776795924
Validation loss: 2.4765262173451146

Epoch: 6| Step: 9
Training loss: 2.3350252647585092
Validation loss: 2.474498086715057

Epoch: 6| Step: 10
Training loss: 2.6038609337947993
Validation loss: 2.4793405269368036

Epoch: 6| Step: 11
Training loss: 2.6416138371942175
Validation loss: 2.4853042966483585

Epoch: 6| Step: 12
Training loss: 2.0991887296653213
Validation loss: 2.4892911001081264

Epoch: 6| Step: 13
Training loss: 2.7022347279658026
Validation loss: 2.4832549420630925

Epoch: 226| Step: 0
Training loss: 2.747053301582596
Validation loss: 2.4873691851968514

Epoch: 6| Step: 1
Training loss: 2.5470007180855814
Validation loss: 2.488460123837711

Epoch: 6| Step: 2
Training loss: 3.0141370195557218
Validation loss: 2.48756865181326

Epoch: 6| Step: 3
Training loss: 2.9733215469788186
Validation loss: 2.4926503198185483

Epoch: 6| Step: 4
Training loss: 2.8779401257975783
Validation loss: 2.500559972786571

Epoch: 6| Step: 5
Training loss: 2.3541735983777468
Validation loss: 2.500981330030176

Epoch: 6| Step: 6
Training loss: 2.720522072841152
Validation loss: 2.5086591741219846

Epoch: 6| Step: 7
Training loss: 2.2764187172417327
Validation loss: 2.4999062182156364

Epoch: 6| Step: 8
Training loss: 2.690097263520583
Validation loss: 2.497795779119819

Epoch: 6| Step: 9
Training loss: 3.0320788951060393
Validation loss: 2.4873464208279104

Epoch: 6| Step: 10
Training loss: 1.905550906704248
Validation loss: 2.490758092420919

Epoch: 6| Step: 11
Training loss: 2.900669277176252
Validation loss: 2.489768895384367

Epoch: 6| Step: 12
Training loss: 2.2136384351933214
Validation loss: 2.5146087660558836

Epoch: 6| Step: 13
Training loss: 2.209588168164893
Validation loss: 2.517782252558857

Epoch: 227| Step: 0
Training loss: 2.940158371584769
Validation loss: 2.5202190905433843

Epoch: 6| Step: 1
Training loss: 2.406268429375955
Validation loss: 2.536284898873136

Epoch: 6| Step: 2
Training loss: 1.9522052277648105
Validation loss: 2.5370213131303023

Epoch: 6| Step: 3
Training loss: 2.3764511493627674
Validation loss: 2.499138692951425

Epoch: 6| Step: 4
Training loss: 2.9266263304112545
Validation loss: 2.4992381524520053

Epoch: 6| Step: 5
Training loss: 2.3643372753581393
Validation loss: 2.4887255040581597

Epoch: 6| Step: 6
Training loss: 2.1638458914749967
Validation loss: 2.478390664680077

Epoch: 6| Step: 7
Training loss: 2.9532276922869043
Validation loss: 2.466206707996652

Epoch: 6| Step: 8
Training loss: 2.658646075069815
Validation loss: 2.468729575942242

Epoch: 6| Step: 9
Training loss: 2.551472078158999
Validation loss: 2.475239920316732

Epoch: 6| Step: 10
Training loss: 3.278480741764559
Validation loss: 2.4784709595049317

Epoch: 6| Step: 11
Training loss: 2.6288432188824253
Validation loss: 2.4723964266228915

Epoch: 6| Step: 12
Training loss: 2.9568383822918256
Validation loss: 2.4763389510575693

Epoch: 6| Step: 13
Training loss: 2.6509795915472085
Validation loss: 2.489991506805115

Epoch: 228| Step: 0
Training loss: 2.415938651385987
Validation loss: 2.507627330904581

Epoch: 6| Step: 1
Training loss: 2.3569347570466626
Validation loss: 2.5493915836984153

Epoch: 6| Step: 2
Training loss: 3.2031714459285063
Validation loss: 2.57848433261654

Epoch: 6| Step: 3
Training loss: 2.3631357699927937
Validation loss: 2.640907048754611

Epoch: 6| Step: 4
Training loss: 2.927106447682915
Validation loss: 2.6708354663198848

Epoch: 6| Step: 5
Training loss: 2.9711932919699233
Validation loss: 2.683661685393047

Epoch: 6| Step: 6
Training loss: 2.125805645977594
Validation loss: 2.67283705641716

Epoch: 6| Step: 7
Training loss: 2.7988069990043583
Validation loss: 2.6068590096881907

Epoch: 6| Step: 8
Training loss: 3.119039573298525
Validation loss: 2.577221853619827

Epoch: 6| Step: 9
Training loss: 2.0745778033454876
Validation loss: 2.5442420732057847

Epoch: 6| Step: 10
Training loss: 2.3220350248864285
Validation loss: 2.5037392534394955

Epoch: 6| Step: 11
Training loss: 2.8143525697956675
Validation loss: 2.4840471295524624

Epoch: 6| Step: 12
Training loss: 2.949296518273087
Validation loss: 2.4723308342425137

Epoch: 6| Step: 13
Training loss: 3.063993284541806
Validation loss: 2.47899574944608

Epoch: 229| Step: 0
Training loss: 3.085063260015642
Validation loss: 2.4601917330288567

Epoch: 6| Step: 1
Training loss: 2.9135384996160796
Validation loss: 2.468934213876919

Epoch: 6| Step: 2
Training loss: 2.5367610889093575
Validation loss: 2.464477387025361

Epoch: 6| Step: 3
Training loss: 2.625091732783787
Validation loss: 2.4558207076034333

Epoch: 6| Step: 4
Training loss: 2.8263982907533807
Validation loss: 2.465614526089744

Epoch: 6| Step: 5
Training loss: 3.0371732748000513
Validation loss: 2.467954310868892

Epoch: 6| Step: 6
Training loss: 2.8084207409878323
Validation loss: 2.4786305473918215

Epoch: 6| Step: 7
Training loss: 2.587590452815411
Validation loss: 2.5038038100399596

Epoch: 6| Step: 8
Training loss: 2.6684823609988344
Validation loss: 2.579620866062814

Epoch: 6| Step: 9
Training loss: 2.60558669982856
Validation loss: 2.644009766347339

Epoch: 6| Step: 10
Training loss: 2.5331427008864305
Validation loss: 2.7150031855585333

Epoch: 6| Step: 11
Training loss: 2.6501219127610596
Validation loss: 2.730252623269327

Epoch: 6| Step: 12
Training loss: 2.3147747090008943
Validation loss: 2.672724424421444

Epoch: 6| Step: 13
Training loss: 1.8350717004597523
Validation loss: 2.6120665037348663

Epoch: 230| Step: 0
Training loss: 2.691849759215805
Validation loss: 2.569418430908039

Epoch: 6| Step: 1
Training loss: 3.25185400092922
Validation loss: 2.5124507192114054

Epoch: 6| Step: 2
Training loss: 2.2340217791309347
Validation loss: 2.475187281664469

Epoch: 6| Step: 3
Training loss: 2.7864736301085435
Validation loss: 2.452845196729594

Epoch: 6| Step: 4
Training loss: 2.6264132373886393
Validation loss: 2.4625243399844297

Epoch: 6| Step: 5
Training loss: 2.561248659847536
Validation loss: 2.4583715032996847

Epoch: 6| Step: 6
Training loss: 2.674105956506955
Validation loss: 2.4559544045565698

Epoch: 6| Step: 7
Training loss: 2.3545640818166023
Validation loss: 2.452674985906559

Epoch: 6| Step: 8
Training loss: 2.5030541837392613
Validation loss: 2.4548612393680784

Epoch: 6| Step: 9
Training loss: 2.7649219718532767
Validation loss: 2.4606155843854993

Epoch: 6| Step: 10
Training loss: 2.904656742583593
Validation loss: 2.454482803806788

Epoch: 6| Step: 11
Training loss: 2.5947179252184998
Validation loss: 2.469616169589999

Epoch: 6| Step: 12
Training loss: 2.534534536813089
Validation loss: 2.4762174816872156

Epoch: 6| Step: 13
Training loss: 2.7926743145447377
Validation loss: 2.4857729688739973

Epoch: 231| Step: 0
Training loss: 2.600558158677444
Validation loss: 2.48699322742537

Epoch: 6| Step: 1
Training loss: 2.31761459561072
Validation loss: 2.5022690207679616

Epoch: 6| Step: 2
Training loss: 2.5925347112320156
Validation loss: 2.51636248258358

Epoch: 6| Step: 3
Training loss: 2.5768429429463304
Validation loss: 2.5509570457754647

Epoch: 6| Step: 4
Training loss: 1.8809607172488676
Validation loss: 2.5569294263036664

Epoch: 6| Step: 5
Training loss: 2.9411663145002156
Validation loss: 2.5490269631599523

Epoch: 6| Step: 6
Training loss: 2.718354996673439
Validation loss: 2.531453167899516

Epoch: 6| Step: 7
Training loss: 2.5370476342985664
Validation loss: 2.499920411022318

Epoch: 6| Step: 8
Training loss: 2.0849944422439672
Validation loss: 2.5004050439428713

Epoch: 6| Step: 9
Training loss: 3.291629613997764
Validation loss: 2.4923237169860744

Epoch: 6| Step: 10
Training loss: 2.425661928740587
Validation loss: 2.4888372258772877

Epoch: 6| Step: 11
Training loss: 2.869675723374371
Validation loss: 2.4864712255335544

Epoch: 6| Step: 12
Training loss: 2.5124599852151137
Validation loss: 2.4848405682070096

Epoch: 6| Step: 13
Training loss: 3.29453718995863
Validation loss: 2.4920382333321585

Epoch: 232| Step: 0
Training loss: 2.8825264972352262
Validation loss: 2.4936357142035943

Epoch: 6| Step: 1
Training loss: 2.3956547103858776
Validation loss: 2.4926120785872987

Epoch: 6| Step: 2
Training loss: 2.5691122945830402
Validation loss: 2.487683225032203

Epoch: 6| Step: 3
Training loss: 3.3059280267578464
Validation loss: 2.502846468393022

Epoch: 6| Step: 4
Training loss: 2.9753096539564194
Validation loss: 2.49770806372644

Epoch: 6| Step: 5
Training loss: 2.636637187685265
Validation loss: 2.5110853575406082

Epoch: 6| Step: 6
Training loss: 2.6454127320319283
Validation loss: 2.5243383915326585

Epoch: 6| Step: 7
Training loss: 2.5741022341209647
Validation loss: 2.5206340137078453

Epoch: 6| Step: 8
Training loss: 2.8319942077318863
Validation loss: 2.5213679234368094

Epoch: 6| Step: 9
Training loss: 2.9585969476151193
Validation loss: 2.4885096507704163

Epoch: 6| Step: 10
Training loss: 2.4370059955509085
Validation loss: 2.4838763940310007

Epoch: 6| Step: 11
Training loss: 2.432026415022649
Validation loss: 2.4944082611149105

Epoch: 6| Step: 12
Training loss: 1.625740102809091
Validation loss: 2.477359711090129

Epoch: 6| Step: 13
Training loss: 1.2533969498444595
Validation loss: 2.478137287485525

Epoch: 233| Step: 0
Training loss: 2.8134115649219322
Validation loss: 2.481963622123068

Epoch: 6| Step: 1
Training loss: 3.01412657832271
Validation loss: 2.4820998744714373

Epoch: 6| Step: 2
Training loss: 2.680283193856123
Validation loss: 2.488645613745398

Epoch: 6| Step: 3
Training loss: 2.8409836277286886
Validation loss: 2.4838286036519825

Epoch: 6| Step: 4
Training loss: 2.65131116495256
Validation loss: 2.495564184290107

Epoch: 6| Step: 5
Training loss: 2.494326256734796
Validation loss: 2.492593541941595

Epoch: 6| Step: 6
Training loss: 1.8966828703006582
Validation loss: 2.489797332651321

Epoch: 6| Step: 7
Training loss: 2.9644469547245214
Validation loss: 2.5153250087705317

Epoch: 6| Step: 8
Training loss: 2.327384779851124
Validation loss: 2.535170763213962

Epoch: 6| Step: 9
Training loss: 2.123431917454088
Validation loss: 2.546721988774613

Epoch: 6| Step: 10
Training loss: 2.7996032024968582
Validation loss: 2.5612446821330894

Epoch: 6| Step: 11
Training loss: 2.3592674786655015
Validation loss: 2.572678273494866

Epoch: 6| Step: 12
Training loss: 2.4918342746595656
Validation loss: 2.56998655554864

Epoch: 6| Step: 13
Training loss: 2.883012470039765
Validation loss: 2.563775687193098

Epoch: 234| Step: 0
Training loss: 2.239048265517057
Validation loss: 2.5523384912615588

Epoch: 6| Step: 1
Training loss: 2.7034567921485557
Validation loss: 2.541401154441294

Epoch: 6| Step: 2
Training loss: 2.472719309215166
Validation loss: 2.5423592165729265

Epoch: 6| Step: 3
Training loss: 2.3108332013986383
Validation loss: 2.5222694565958816

Epoch: 6| Step: 4
Training loss: 2.3445610169068987
Validation loss: 2.5198362455374053

Epoch: 6| Step: 5
Training loss: 2.117398522477694
Validation loss: 2.519681683916141

Epoch: 6| Step: 6
Training loss: 2.483288893419356
Validation loss: 2.500162814591411

Epoch: 6| Step: 7
Training loss: 2.78836931435338
Validation loss: 2.490160866122317

Epoch: 6| Step: 8
Training loss: 2.6749209169480634
Validation loss: 2.476569037032377

Epoch: 6| Step: 9
Training loss: 2.551370409563628
Validation loss: 2.4824032447054982

Epoch: 6| Step: 10
Training loss: 3.043947348962665
Validation loss: 2.484207327213702

Epoch: 6| Step: 11
Training loss: 2.9494872924613715
Validation loss: 2.4769210537759423

Epoch: 6| Step: 12
Training loss: 2.789797133176713
Validation loss: 2.473465779639003

Epoch: 6| Step: 13
Training loss: 2.792147172787132
Validation loss: 2.481060125722902

Epoch: 235| Step: 0
Training loss: 2.5178180873203293
Validation loss: 2.5017445271348007

Epoch: 6| Step: 1
Training loss: 2.453422382576857
Validation loss: 2.496533033623006

Epoch: 6| Step: 2
Training loss: 2.8172426714495904
Validation loss: 2.5083999229485183

Epoch: 6| Step: 3
Training loss: 2.7046911740952986
Validation loss: 2.4924648471462767

Epoch: 6| Step: 4
Training loss: 2.0047693606021078
Validation loss: 2.510824140211524

Epoch: 6| Step: 5
Training loss: 3.1329163037081025
Validation loss: 2.5194246476084428

Epoch: 6| Step: 6
Training loss: 2.1455667077004112
Validation loss: 2.5143248104303444

Epoch: 6| Step: 7
Training loss: 2.3552534469969606
Validation loss: 2.5114798401833274

Epoch: 6| Step: 8
Training loss: 2.0073443508971285
Validation loss: 2.5118274175610087

Epoch: 6| Step: 9
Training loss: 2.2254385269577917
Validation loss: 2.5294346023622665

Epoch: 6| Step: 10
Training loss: 2.9832776034245017
Validation loss: 2.529132732817774

Epoch: 6| Step: 11
Training loss: 2.6800628488202864
Validation loss: 2.569657293444708

Epoch: 6| Step: 12
Training loss: 2.601024125212791
Validation loss: 2.5622323309329076

Epoch: 6| Step: 13
Training loss: 3.2226450047152286
Validation loss: 2.534549407604355

Epoch: 236| Step: 0
Training loss: 2.3390454696208574
Validation loss: 2.54431718445746

Epoch: 6| Step: 1
Training loss: 2.9540126213367137
Validation loss: 2.5318377698718737

Epoch: 6| Step: 2
Training loss: 2.450961087954925
Validation loss: 2.503664819145935

Epoch: 6| Step: 3
Training loss: 1.970192214476611
Validation loss: 2.500723301430621

Epoch: 6| Step: 4
Training loss: 2.278807285946834
Validation loss: 2.5177674181583005

Epoch: 6| Step: 5
Training loss: 1.9167581066489054
Validation loss: 2.517654940032187

Epoch: 6| Step: 6
Training loss: 2.653367936117972
Validation loss: 2.5194944302233515

Epoch: 6| Step: 7
Training loss: 2.754837895797646
Validation loss: 2.5104225409497785

Epoch: 6| Step: 8
Training loss: 3.134842745108606
Validation loss: 2.511501027174254

Epoch: 6| Step: 9
Training loss: 2.3296579524110257
Validation loss: 2.530513660885013

Epoch: 6| Step: 10
Training loss: 2.5248606539508067
Validation loss: 2.502629587096579

Epoch: 6| Step: 11
Training loss: 2.6207106831956613
Validation loss: 2.5031285849822558

Epoch: 6| Step: 12
Training loss: 2.8816052728764627
Validation loss: 2.4915904156869675

Epoch: 6| Step: 13
Training loss: 3.079501081656941
Validation loss: 2.4966997328352694

Epoch: 237| Step: 0
Training loss: 2.4866357269953174
Validation loss: 2.4876171803619243

Epoch: 6| Step: 1
Training loss: 2.1886400794069085
Validation loss: 2.485907242774527

Epoch: 6| Step: 2
Training loss: 2.5452177120236925
Validation loss: 2.493668903277446

Epoch: 6| Step: 3
Training loss: 2.8058338425940503
Validation loss: 2.46688008601834

Epoch: 6| Step: 4
Training loss: 1.8324787431137157
Validation loss: 2.4674568959024414

Epoch: 6| Step: 5
Training loss: 2.2446148324043502
Validation loss: 2.478403795284741

Epoch: 6| Step: 6
Training loss: 2.5949801549722316
Validation loss: 2.4668897694872256

Epoch: 6| Step: 7
Training loss: 2.7247917305687026
Validation loss: 2.488879122004717

Epoch: 6| Step: 8
Training loss: 3.1303532334661486
Validation loss: 2.481214566963325

Epoch: 6| Step: 9
Training loss: 2.841716500420513
Validation loss: 2.4976865472686516

Epoch: 6| Step: 10
Training loss: 2.425023450443103
Validation loss: 2.48067635179438

Epoch: 6| Step: 11
Training loss: 2.835514762203647
Validation loss: 2.4768022430441854

Epoch: 6| Step: 12
Training loss: 2.561761517064479
Validation loss: 2.482374151630592

Epoch: 6| Step: 13
Training loss: 2.1553568441467763
Validation loss: 2.5049701589650257

Epoch: 238| Step: 0
Training loss: 2.3708457754263423
Validation loss: 2.538433629763204

Epoch: 6| Step: 1
Training loss: 2.239888996882049
Validation loss: 2.5602644976800613

Epoch: 6| Step: 2
Training loss: 2.189285639431947
Validation loss: 2.55997013312236

Epoch: 6| Step: 3
Training loss: 2.544329535523918
Validation loss: 2.6023906293962065

Epoch: 6| Step: 4
Training loss: 3.01657642910985
Validation loss: 2.603447616406852

Epoch: 6| Step: 5
Training loss: 2.7923043694610774
Validation loss: 2.5850983768133666

Epoch: 6| Step: 6
Training loss: 2.6776405279073394
Validation loss: 2.5356554681626564

Epoch: 6| Step: 7
Training loss: 2.0021000803532494
Validation loss: 2.5185387847744027

Epoch: 6| Step: 8
Training loss: 2.6316676155009704
Validation loss: 2.541795197465851

Epoch: 6| Step: 9
Training loss: 2.0565913557652027
Validation loss: 2.511259910987678

Epoch: 6| Step: 10
Training loss: 3.112051727002314
Validation loss: 2.5091225184258046

Epoch: 6| Step: 11
Training loss: 3.0930063914576147
Validation loss: 2.5075514784731765

Epoch: 6| Step: 12
Training loss: 1.7491985938345045
Validation loss: 2.4940019220257157

Epoch: 6| Step: 13
Training loss: 3.2919478638368824
Validation loss: 2.5044071483008135

Epoch: 239| Step: 0
Training loss: 2.212714246301341
Validation loss: 2.5034136241878975

Epoch: 6| Step: 1
Training loss: 2.6521715156016863
Validation loss: 2.501426392403911

Epoch: 6| Step: 2
Training loss: 2.4614510136669154
Validation loss: 2.492580454202988

Epoch: 6| Step: 3
Training loss: 2.4603345344222505
Validation loss: 2.515204096140513

Epoch: 6| Step: 4
Training loss: 2.7813833826206276
Validation loss: 2.5163663437882446

Epoch: 6| Step: 5
Training loss: 2.7775626438331646
Validation loss: 2.5086455100369447

Epoch: 6| Step: 6
Training loss: 2.3551782330818445
Validation loss: 2.5380928160571097

Epoch: 6| Step: 7
Training loss: 2.4846417745672724
Validation loss: 2.506288439677063

Epoch: 6| Step: 8
Training loss: 2.628788620923119
Validation loss: 2.4938770088418063

Epoch: 6| Step: 9
Training loss: 2.8915074006852852
Validation loss: 2.4891484696366155

Epoch: 6| Step: 10
Training loss: 2.531667227561877
Validation loss: 2.462129258557805

Epoch: 6| Step: 11
Training loss: 2.7150709317884005
Validation loss: 2.4704038626255693

Epoch: 6| Step: 12
Training loss: 1.871426291968768
Validation loss: 2.484456866950843

Epoch: 6| Step: 13
Training loss: 2.5057359696267283
Validation loss: 2.490063284349685

Epoch: 240| Step: 0
Training loss: 2.9716731086129116
Validation loss: 2.4834863403609675

Epoch: 6| Step: 1
Training loss: 2.0309455056479533
Validation loss: 2.4697978136598695

Epoch: 6| Step: 2
Training loss: 2.425427986996312
Validation loss: 2.4683108704419574

Epoch: 6| Step: 3
Training loss: 2.700207232540371
Validation loss: 2.4751436975088255

Epoch: 6| Step: 4
Training loss: 2.774930997798234
Validation loss: 2.480319286620568

Epoch: 6| Step: 5
Training loss: 2.6314275251291503
Validation loss: 2.4680032427547376

Epoch: 6| Step: 6
Training loss: 3.0348611931269365
Validation loss: 2.482309285579529

Epoch: 6| Step: 7
Training loss: 2.5063231612107866
Validation loss: 2.4864033092524904

Epoch: 6| Step: 8
Training loss: 2.6008358418816084
Validation loss: 2.4958474568287476

Epoch: 6| Step: 9
Training loss: 2.7432954728892596
Validation loss: 2.5131498672297963

Epoch: 6| Step: 10
Training loss: 2.7848631288600836
Validation loss: 2.516299304690923

Epoch: 6| Step: 11
Training loss: 1.6560234778624268
Validation loss: 2.5413185908761293

Epoch: 6| Step: 12
Training loss: 2.1142904019211755
Validation loss: 2.547792273663487

Epoch: 6| Step: 13
Training loss: 1.9997656208033412
Validation loss: 2.579111931942497

Epoch: 241| Step: 0
Training loss: 2.32839329344926
Validation loss: 2.6098243759209847

Epoch: 6| Step: 1
Training loss: 2.4068211459759614
Validation loss: 2.610827456285775

Epoch: 6| Step: 2
Training loss: 2.6449980330865537
Validation loss: 2.6124601968428847

Epoch: 6| Step: 3
Training loss: 2.742796914398741
Validation loss: 2.667762035474766

Epoch: 6| Step: 4
Training loss: 2.480070788080776
Validation loss: 2.6479495939122835

Epoch: 6| Step: 5
Training loss: 2.0859535016649815
Validation loss: 2.5805431710490785

Epoch: 6| Step: 6
Training loss: 2.282718133771025
Validation loss: 2.5167565139507273

Epoch: 6| Step: 7
Training loss: 2.8484513542436836
Validation loss: 2.4759261845639955

Epoch: 6| Step: 8
Training loss: 2.4092578666505537
Validation loss: 2.4519357656229968

Epoch: 6| Step: 9
Training loss: 2.6837385602191084
Validation loss: 2.454557416679306

Epoch: 6| Step: 10
Training loss: 2.752357512760971
Validation loss: 2.45367080074962

Epoch: 6| Step: 11
Training loss: 2.916386472776499
Validation loss: 2.4551007949023007

Epoch: 6| Step: 12
Training loss: 2.4282681652463003
Validation loss: 2.4578970366747512

Epoch: 6| Step: 13
Training loss: 2.4596245063524953
Validation loss: 2.463384941787454

Epoch: 242| Step: 0
Training loss: 2.3749216970284728
Validation loss: 2.465369300658959

Epoch: 6| Step: 1
Training loss: 2.311525087795144
Validation loss: 2.4632009592225335

Epoch: 6| Step: 2
Training loss: 2.815122864855489
Validation loss: 2.4718788779691527

Epoch: 6| Step: 3
Training loss: 2.003902918643673
Validation loss: 2.480740805839551

Epoch: 6| Step: 4
Training loss: 2.591465690973013
Validation loss: 2.516198578660366

Epoch: 6| Step: 5
Training loss: 2.3683456760257573
Validation loss: 2.5462794480481614

Epoch: 6| Step: 6
Training loss: 3.3832571957544864
Validation loss: 2.5410773116638725

Epoch: 6| Step: 7
Training loss: 1.9275976439802593
Validation loss: 2.5400562335236088

Epoch: 6| Step: 8
Training loss: 2.493819799378548
Validation loss: 2.537489920037988

Epoch: 6| Step: 9
Training loss: 2.842549164815717
Validation loss: 2.517688919315587

Epoch: 6| Step: 10
Training loss: 2.4125245760125433
Validation loss: 2.53343201635583

Epoch: 6| Step: 11
Training loss: 2.552792841060096
Validation loss: 2.4921836599687563

Epoch: 6| Step: 12
Training loss: 2.3345112098266205
Validation loss: 2.505638618928968

Epoch: 6| Step: 13
Training loss: 2.95994933858252
Validation loss: 2.4967256309470454

Epoch: 243| Step: 0
Training loss: 2.345051111831478
Validation loss: 2.4898790110202174

Epoch: 6| Step: 1
Training loss: 2.381280425270328
Validation loss: 2.505883142581449

Epoch: 6| Step: 2
Training loss: 2.2243055181324314
Validation loss: 2.5029246215249232

Epoch: 6| Step: 3
Training loss: 2.921520354427716
Validation loss: 2.511646362908963

Epoch: 6| Step: 4
Training loss: 2.621035352076255
Validation loss: 2.5133863845150133

Epoch: 6| Step: 5
Training loss: 2.9702213857322537
Validation loss: 2.552119308596491

Epoch: 6| Step: 6
Training loss: 2.2007401998454013
Validation loss: 2.507248794263629

Epoch: 6| Step: 7
Training loss: 2.476910780235055
Validation loss: 2.5197008352337873

Epoch: 6| Step: 8
Training loss: 2.519950796282744
Validation loss: 2.515475366068573

Epoch: 6| Step: 9
Training loss: 2.9356576539518455
Validation loss: 2.4900460414136143

Epoch: 6| Step: 10
Training loss: 2.349461018864241
Validation loss: 2.500809812132311

Epoch: 6| Step: 11
Training loss: 2.3150278657426653
Validation loss: 2.4827546583171425

Epoch: 6| Step: 12
Training loss: 2.5091380006218373
Validation loss: 2.4833486610077764

Epoch: 6| Step: 13
Training loss: 1.5638309151063872
Validation loss: 2.491638505791416

Epoch: 244| Step: 0
Training loss: 2.2948723191125584
Validation loss: 2.504423286117874

Epoch: 6| Step: 1
Training loss: 2.294695280535408
Validation loss: 2.501314820353712

Epoch: 6| Step: 2
Training loss: 2.5087329922086745
Validation loss: 2.520149641309498

Epoch: 6| Step: 3
Training loss: 2.7198680464208933
Validation loss: 2.5679640841130253

Epoch: 6| Step: 4
Training loss: 2.3971727248477332
Validation loss: 2.5705873360084412

Epoch: 6| Step: 5
Training loss: 2.882585718182281
Validation loss: 2.591592773998715

Epoch: 6| Step: 6
Training loss: 2.39613345933864
Validation loss: 2.6074966086277476

Epoch: 6| Step: 7
Training loss: 2.087379214510017
Validation loss: 2.6391582197932566

Epoch: 6| Step: 8
Training loss: 2.5447706644568537
Validation loss: 2.6264790647136693

Epoch: 6| Step: 9
Training loss: 1.9202527899029667
Validation loss: 2.582041141026336

Epoch: 6| Step: 10
Training loss: 2.219355218574115
Validation loss: 2.5616865755378586

Epoch: 6| Step: 11
Training loss: 3.074392776701534
Validation loss: 2.558308242039359

Epoch: 6| Step: 12
Training loss: 2.746922244554249
Validation loss: 2.5475614463028373

Epoch: 6| Step: 13
Training loss: 2.8978344888962555
Validation loss: 2.49622545888664

Epoch: 245| Step: 0
Training loss: 2.9101487127628904
Validation loss: 2.4911503006292692

Epoch: 6| Step: 1
Training loss: 2.1942811763026793
Validation loss: 2.4773640599500326

Epoch: 6| Step: 2
Training loss: 2.6686362106042743
Validation loss: 2.457043825941597

Epoch: 6| Step: 3
Training loss: 2.2364972046481357
Validation loss: 2.453772255752172

Epoch: 6| Step: 4
Training loss: 1.699703103674362
Validation loss: 2.4806727729744673

Epoch: 6| Step: 5
Training loss: 2.4677145029691063
Validation loss: 2.46240958468463

Epoch: 6| Step: 6
Training loss: 2.3062706633678496
Validation loss: 2.4741377099145385

Epoch: 6| Step: 7
Training loss: 2.7842615517603297
Validation loss: 2.466870024232446

Epoch: 6| Step: 8
Training loss: 2.9295922836089585
Validation loss: 2.4765554650366166

Epoch: 6| Step: 9
Training loss: 2.0774741623576625
Validation loss: 2.4964636145214874

Epoch: 6| Step: 10
Training loss: 3.010218542282644
Validation loss: 2.495914152672983

Epoch: 6| Step: 11
Training loss: 2.2646082207915694
Validation loss: 2.5079824166256985

Epoch: 6| Step: 12
Training loss: 2.7126511316342885
Validation loss: 2.505445624184977

Epoch: 6| Step: 13
Training loss: 2.1393466668756087
Validation loss: 2.5287153577624273

Epoch: 246| Step: 0
Training loss: 2.986355269354235
Validation loss: 2.572909535791756

Epoch: 6| Step: 1
Training loss: 2.1523453008019593
Validation loss: 2.5726699558038444

Epoch: 6| Step: 2
Training loss: 2.2967599852953096
Validation loss: 2.5827355985047666

Epoch: 6| Step: 3
Training loss: 2.289421496053223
Validation loss: 2.5418592242549765

Epoch: 6| Step: 4
Training loss: 2.7849067051874288
Validation loss: 2.5637514213565713

Epoch: 6| Step: 5
Training loss: 2.658719160567371
Validation loss: 2.5715181009499193

Epoch: 6| Step: 6
Training loss: 2.54562384643079
Validation loss: 2.593631679911566

Epoch: 6| Step: 7
Training loss: 2.5801453967857486
Validation loss: 2.612220858406805

Epoch: 6| Step: 8
Training loss: 2.7574339868939086
Validation loss: 2.595654653753428

Epoch: 6| Step: 9
Training loss: 2.4824153440856263
Validation loss: 2.5571735768255066

Epoch: 6| Step: 10
Training loss: 2.5433538704872474
Validation loss: 2.520012936530412

Epoch: 6| Step: 11
Training loss: 2.5182515524362645
Validation loss: 2.4740922177695555

Epoch: 6| Step: 12
Training loss: 1.9212755338303618
Validation loss: 2.468463852564706

Epoch: 6| Step: 13
Training loss: 2.202215453352514
Validation loss: 2.4598184781483003

Epoch: 247| Step: 0
Training loss: 2.8830354599162957
Validation loss: 2.4340556883232183

Epoch: 6| Step: 1
Training loss: 2.829950575919303
Validation loss: 2.433130039208089

Epoch: 6| Step: 2
Training loss: 2.412617173585925
Validation loss: 2.442464988008245

Epoch: 6| Step: 3
Training loss: 2.779747889496923
Validation loss: 2.4500648008210306

Epoch: 6| Step: 4
Training loss: 2.949752900717782
Validation loss: 2.4468090545891834

Epoch: 6| Step: 5
Training loss: 2.1976752005423497
Validation loss: 2.48419623242233

Epoch: 6| Step: 6
Training loss: 1.9607737803409984
Validation loss: 2.5203308001864566

Epoch: 6| Step: 7
Training loss: 2.248859328304778
Validation loss: 2.5469372714852696

Epoch: 6| Step: 8
Training loss: 2.304461141558716
Validation loss: 2.564585274712051

Epoch: 6| Step: 9
Training loss: 1.9649501036115975
Validation loss: 2.5943217847563314

Epoch: 6| Step: 10
Training loss: 2.6276344521890893
Validation loss: 2.6289344889327517

Epoch: 6| Step: 11
Training loss: 2.382843317551739
Validation loss: 2.6550851061533733

Epoch: 6| Step: 12
Training loss: 2.710157474573628
Validation loss: 2.6260747589345663

Epoch: 6| Step: 13
Training loss: 2.918757606512773
Validation loss: 2.591357065661179

Epoch: 248| Step: 0
Training loss: 2.479863322706354
Validation loss: 2.537975125517076

Epoch: 6| Step: 1
Training loss: 2.36838080918549
Validation loss: 2.457967368726686

Epoch: 6| Step: 2
Training loss: 2.4903250404757324
Validation loss: 2.4282319179602174

Epoch: 6| Step: 3
Training loss: 2.694427521861136
Validation loss: 2.427085481069087

Epoch: 6| Step: 4
Training loss: 2.8256957016140496
Validation loss: 2.4374491000270937

Epoch: 6| Step: 5
Training loss: 2.6523948068999688
Validation loss: 2.417485547816443

Epoch: 6| Step: 6
Training loss: 2.678826730459615
Validation loss: 2.4269167202845714

Epoch: 6| Step: 7
Training loss: 2.819604335650508
Validation loss: 2.4280780565503104

Epoch: 6| Step: 8
Training loss: 2.5327901981602676
Validation loss: 2.436297191174034

Epoch: 6| Step: 9
Training loss: 2.3583310072205554
Validation loss: 2.455078897722364

Epoch: 6| Step: 10
Training loss: 1.979734988346792
Validation loss: 2.4626447129650177

Epoch: 6| Step: 11
Training loss: 2.415206983553787
Validation loss: 2.4839546321100947

Epoch: 6| Step: 12
Training loss: 2.316774284369713
Validation loss: 2.519500366438835

Epoch: 6| Step: 13
Training loss: 2.1797754413543258
Validation loss: 2.581873830436866

Epoch: 249| Step: 0
Training loss: 2.4899839028447115
Validation loss: 2.614392814432664

Epoch: 6| Step: 1
Training loss: 3.189441912153055
Validation loss: 2.634382394602112

Epoch: 6| Step: 2
Training loss: 2.42189370424985
Validation loss: 2.602262886081937

Epoch: 6| Step: 3
Training loss: 2.7492300169384074
Validation loss: 2.5797835945443617

Epoch: 6| Step: 4
Training loss: 2.281850866327523
Validation loss: 2.5292786933656255

Epoch: 6| Step: 5
Training loss: 2.1730275560748074
Validation loss: 2.4770632798746797

Epoch: 6| Step: 6
Training loss: 1.9993855009193753
Validation loss: 2.4890239463159207

Epoch: 6| Step: 7
Training loss: 2.283634141844711
Validation loss: 2.4628226460544345

Epoch: 6| Step: 8
Training loss: 2.511740866841049
Validation loss: 2.46433801056668

Epoch: 6| Step: 9
Training loss: 2.731334805426815
Validation loss: 2.4926580128359803

Epoch: 6| Step: 10
Training loss: 2.500096128522955
Validation loss: 2.512066503530143

Epoch: 6| Step: 11
Training loss: 2.712141841324336
Validation loss: 2.526636067720133

Epoch: 6| Step: 12
Training loss: 2.209024309224024
Validation loss: 2.511344907235911

Epoch: 6| Step: 13
Training loss: 2.2355898242259507
Validation loss: 2.507161786905366

Epoch: 250| Step: 0
Training loss: 2.404916567237528
Validation loss: 2.505627946443232

Epoch: 6| Step: 1
Training loss: 2.147045669546109
Validation loss: 2.500723897048309

Epoch: 6| Step: 2
Training loss: 2.5785405604360707
Validation loss: 2.4930458962911706

Epoch: 6| Step: 3
Training loss: 2.589616170006471
Validation loss: 2.4589643598369415

Epoch: 6| Step: 4
Training loss: 2.3217045881903706
Validation loss: 2.460518458340321

Epoch: 6| Step: 5
Training loss: 2.9809333169229744
Validation loss: 2.442022809410985

Epoch: 6| Step: 6
Training loss: 2.1566884797460744
Validation loss: 2.4391220360573893

Epoch: 6| Step: 7
Training loss: 2.1566542094527787
Validation loss: 2.4625378789591603

Epoch: 6| Step: 8
Training loss: 2.698889087027688
Validation loss: 2.4701151574827103

Epoch: 6| Step: 9
Training loss: 2.010819732371291
Validation loss: 2.472457353383036

Epoch: 6| Step: 10
Training loss: 2.60688196657357
Validation loss: 2.469716944131414

Epoch: 6| Step: 11
Training loss: 2.869619227015431
Validation loss: 2.4815385336573823

Epoch: 6| Step: 12
Training loss: 2.4964998538725656
Validation loss: 2.498840445613158

Epoch: 6| Step: 13
Training loss: 1.903793315332064
Validation loss: 2.542777438221445

Epoch: 251| Step: 0
Training loss: 2.4486687877793667
Validation loss: 2.54820152699115

Epoch: 6| Step: 1
Training loss: 2.576440064046802
Validation loss: 2.56278093660334

Epoch: 6| Step: 2
Training loss: 2.135784607489108
Validation loss: 2.58546802222216

Epoch: 6| Step: 3
Training loss: 2.253594176903278
Validation loss: 2.5897081979019374

Epoch: 6| Step: 4
Training loss: 2.8285881211254793
Validation loss: 2.5947866788426523

Epoch: 6| Step: 5
Training loss: 2.6076065740997216
Validation loss: 2.6169199591756565

Epoch: 6| Step: 6
Training loss: 2.730964844786449
Validation loss: 2.6027499598544206

Epoch: 6| Step: 7
Training loss: 2.2271647391742584
Validation loss: 2.5450268251592196

Epoch: 6| Step: 8
Training loss: 2.650477251226888
Validation loss: 2.514691215140929

Epoch: 6| Step: 9
Training loss: 2.0961072946196864
Validation loss: 2.492051163436971

Epoch: 6| Step: 10
Training loss: 1.7560917548840251
Validation loss: 2.4623548825662462

Epoch: 6| Step: 11
Training loss: 2.592440262991878
Validation loss: 2.4357732352237567

Epoch: 6| Step: 12
Training loss: 2.3988678884634873
Validation loss: 2.4224548450198595

Epoch: 6| Step: 13
Training loss: 3.1634661077110073
Validation loss: 2.4436094739806373

Epoch: 252| Step: 0
Training loss: 2.5391958348404122
Validation loss: 2.4457253273383865

Epoch: 6| Step: 1
Training loss: 2.0980118604602978
Validation loss: 2.429939323706551

Epoch: 6| Step: 2
Training loss: 2.4975690466698413
Validation loss: 2.4431315917114236

Epoch: 6| Step: 3
Training loss: 2.393182520918573
Validation loss: 2.436408623939976

Epoch: 6| Step: 4
Training loss: 2.1268855312735733
Validation loss: 2.487657374998258

Epoch: 6| Step: 5
Training loss: 2.5166985726597138
Validation loss: 2.505426515340235

Epoch: 6| Step: 6
Training loss: 1.9836299428684123
Validation loss: 2.526414612587202

Epoch: 6| Step: 7
Training loss: 1.735903092531774
Validation loss: 2.5214463016426474

Epoch: 6| Step: 8
Training loss: 2.170919304119801
Validation loss: 2.5057031511493677

Epoch: 6| Step: 9
Training loss: 2.627906461830662
Validation loss: 2.4969899196705225

Epoch: 6| Step: 10
Training loss: 3.0514457652963327
Validation loss: 2.5024773034363075

Epoch: 6| Step: 11
Training loss: 2.886681088007025
Validation loss: 2.50740492488026

Epoch: 6| Step: 12
Training loss: 2.540608097034264
Validation loss: 2.482538572438298

Epoch: 6| Step: 13
Training loss: 3.136198805949561
Validation loss: 2.490514302035991

Epoch: 253| Step: 0
Training loss: 2.4244772436104975
Validation loss: 2.5333349517591497

Epoch: 6| Step: 1
Training loss: 3.0184284678702284
Validation loss: 2.5543677594140948

Epoch: 6| Step: 2
Training loss: 1.8674900974894597
Validation loss: 2.5882875150157005

Epoch: 6| Step: 3
Training loss: 1.3830716165134145
Validation loss: 2.6237651090334406

Epoch: 6| Step: 4
Training loss: 2.6367773430989727
Validation loss: 2.644294031971066

Epoch: 6| Step: 5
Training loss: 2.625695454343005
Validation loss: 2.5995394570193273

Epoch: 6| Step: 6
Training loss: 2.429246672353716
Validation loss: 2.5427054251595784

Epoch: 6| Step: 7
Training loss: 2.843142601792245
Validation loss: 2.5160316918654315

Epoch: 6| Step: 8
Training loss: 2.3074725376532492
Validation loss: 2.4853940279689732

Epoch: 6| Step: 9
Training loss: 3.1116389175046786
Validation loss: 2.4716216520396364

Epoch: 6| Step: 10
Training loss: 2.4678452197897482
Validation loss: 2.4577627939938353

Epoch: 6| Step: 11
Training loss: 2.332954671197829
Validation loss: 2.4590516004844343

Epoch: 6| Step: 12
Training loss: 2.023464011235892
Validation loss: 2.441662901286394

Epoch: 6| Step: 13
Training loss: 2.1482573832524086
Validation loss: 2.4384316850659324

Epoch: 254| Step: 0
Training loss: 2.2521225136857876
Validation loss: 2.426576620548322

Epoch: 6| Step: 1
Training loss: 2.351003789589577
Validation loss: 2.4316356129270744

Epoch: 6| Step: 2
Training loss: 2.450969356362424
Validation loss: 2.4549051888380675

Epoch: 6| Step: 3
Training loss: 2.9455750851739393
Validation loss: 2.4755229440575417

Epoch: 6| Step: 4
Training loss: 2.734346226132088
Validation loss: 2.467505459470694

Epoch: 6| Step: 5
Training loss: 2.2673236661437786
Validation loss: 2.4956104617518986

Epoch: 6| Step: 6
Training loss: 2.180004575357098
Validation loss: 2.500770010343737

Epoch: 6| Step: 7
Training loss: 2.1632677953321657
Validation loss: 2.53610912825907

Epoch: 6| Step: 8
Training loss: 2.920709550949197
Validation loss: 2.522110124394565

Epoch: 6| Step: 9
Training loss: 2.219820865586448
Validation loss: 2.493615229756256

Epoch: 6| Step: 10
Training loss: 2.244370305166112
Validation loss: 2.4950689435350504

Epoch: 6| Step: 11
Training loss: 2.4844102197225926
Validation loss: 2.496692056378784

Epoch: 6| Step: 12
Training loss: 2.0961625732315583
Validation loss: 2.5032217974707853

Epoch: 6| Step: 13
Training loss: 2.6174503023663442
Validation loss: 2.50679557381072

Epoch: 255| Step: 0
Training loss: 2.0053988543739902
Validation loss: 2.526640472293645

Epoch: 6| Step: 1
Training loss: 1.9918718873386583
Validation loss: 2.565734288836385

Epoch: 6| Step: 2
Training loss: 2.6234643167984757
Validation loss: 2.591707457505077

Epoch: 6| Step: 3
Training loss: 2.698202513252249
Validation loss: 2.5697166314963633

Epoch: 6| Step: 4
Training loss: 2.2391647539129442
Validation loss: 2.527938698444633

Epoch: 6| Step: 5
Training loss: 2.2371584754166207
Validation loss: 2.506835506960137

Epoch: 6| Step: 6
Training loss: 2.783859742994347
Validation loss: 2.48312418882097

Epoch: 6| Step: 7
Training loss: 1.813419897850917
Validation loss: 2.474366046014133

Epoch: 6| Step: 8
Training loss: 2.6063988439563226
Validation loss: 2.471430127322118

Epoch: 6| Step: 9
Training loss: 2.6364612142747332
Validation loss: 2.477489681531805

Epoch: 6| Step: 10
Training loss: 2.295251077618277
Validation loss: 2.4995383369606006

Epoch: 6| Step: 11
Training loss: 2.709103010312343
Validation loss: 2.5075150890614264

Epoch: 6| Step: 12
Training loss: 2.7971379673262557
Validation loss: 2.555368911168713

Epoch: 6| Step: 13
Training loss: 1.9743635890591096
Validation loss: 2.560884772501216

Epoch: 256| Step: 0
Training loss: 2.195379290124726
Validation loss: 2.581501108227302

Epoch: 6| Step: 1
Training loss: 3.3158169819352863
Validation loss: 2.544920992556571

Epoch: 6| Step: 2
Training loss: 1.831067447872204
Validation loss: 2.5136455997253533

Epoch: 6| Step: 3
Training loss: 1.91645495309693
Validation loss: 2.479851683315833

Epoch: 6| Step: 4
Training loss: 2.6577725702927237
Validation loss: 2.4761562004424285

Epoch: 6| Step: 5
Training loss: 2.471831511104086
Validation loss: 2.4611497919306244

Epoch: 6| Step: 6
Training loss: 2.356549927420339
Validation loss: 2.4685039883157143

Epoch: 6| Step: 7
Training loss: 2.4370934563062017
Validation loss: 2.4554798389084835

Epoch: 6| Step: 8
Training loss: 2.722407106578473
Validation loss: 2.483628553835597

Epoch: 6| Step: 9
Training loss: 2.382073760036493
Validation loss: 2.5131090290996885

Epoch: 6| Step: 10
Training loss: 2.514366735586551
Validation loss: 2.566251232543577

Epoch: 6| Step: 11
Training loss: 2.5765832163369433
Validation loss: 2.632171635628375

Epoch: 6| Step: 12
Training loss: 2.0607554831829287
Validation loss: 2.646190410571261

Epoch: 6| Step: 13
Training loss: 2.2213215499457015
Validation loss: 2.669207782776051

Epoch: 257| Step: 0
Training loss: 2.5568979015830635
Validation loss: 2.6561276450499722

Epoch: 6| Step: 1
Training loss: 1.6327419722077454
Validation loss: 2.591774610433098

Epoch: 6| Step: 2
Training loss: 2.035446995561595
Validation loss: 2.5118526146912408

Epoch: 6| Step: 3
Training loss: 2.7250807268976693
Validation loss: 2.4661445612907973

Epoch: 6| Step: 4
Training loss: 2.5224329599445356
Validation loss: 2.4393739230889877

Epoch: 6| Step: 5
Training loss: 2.8028179089794607
Validation loss: 2.4277057461385434

Epoch: 6| Step: 6
Training loss: 2.7795075519676704
Validation loss: 2.4238133961973385

Epoch: 6| Step: 7
Training loss: 2.4080922394382194
Validation loss: 2.4218089120814317

Epoch: 6| Step: 8
Training loss: 2.082070527412995
Validation loss: 2.4211369941106344

Epoch: 6| Step: 9
Training loss: 3.026731288853022
Validation loss: 2.4133505815693996

Epoch: 6| Step: 10
Training loss: 2.252778774542953
Validation loss: 2.418727849365145

Epoch: 6| Step: 11
Training loss: 2.6302520345450304
Validation loss: 2.4389991189009863

Epoch: 6| Step: 12
Training loss: 2.510898485812337
Validation loss: 2.448984580727341

Epoch: 6| Step: 13
Training loss: 1.793360449197157
Validation loss: 2.4709466881190956

Epoch: 258| Step: 0
Training loss: 2.267407472482781
Validation loss: 2.475960996407907

Epoch: 6| Step: 1
Training loss: 2.4499070753264043
Validation loss: 2.5317429204770865

Epoch: 6| Step: 2
Training loss: 2.322078148643099
Validation loss: 2.557068349719262

Epoch: 6| Step: 3
Training loss: 2.3362722507843894
Validation loss: 2.595045083424695

Epoch: 6| Step: 4
Training loss: 2.47340417912993
Validation loss: 2.543268328140914

Epoch: 6| Step: 5
Training loss: 2.428699550134141
Validation loss: 2.494054929368747

Epoch: 6| Step: 6
Training loss: 2.5514853471069485
Validation loss: 2.4763875661239676

Epoch: 6| Step: 7
Training loss: 2.2357694102829635
Validation loss: 2.454975532460103

Epoch: 6| Step: 8
Training loss: 2.41341739664444
Validation loss: 2.4477944292291847

Epoch: 6| Step: 9
Training loss: 2.004657805201324
Validation loss: 2.4616748679802445

Epoch: 6| Step: 10
Training loss: 2.1868559843001405
Validation loss: 2.462014126122958

Epoch: 6| Step: 11
Training loss: 2.7744675133996717
Validation loss: 2.4634046192331964

Epoch: 6| Step: 12
Training loss: 2.4580464168725538
Validation loss: 2.47136214001381

Epoch: 6| Step: 13
Training loss: 3.230679967541406
Validation loss: 2.4936693797830958

Epoch: 259| Step: 0
Training loss: 2.37890845488147
Validation loss: 2.517197410193423

Epoch: 6| Step: 1
Training loss: 2.612779965526067
Validation loss: 2.5248136961946237

Epoch: 6| Step: 2
Training loss: 2.3341614979209266
Validation loss: 2.567697080496711

Epoch: 6| Step: 3
Training loss: 2.015900349106894
Validation loss: 2.5877759739435624

Epoch: 6| Step: 4
Training loss: 2.4108050939824803
Validation loss: 2.6209905663467503

Epoch: 6| Step: 5
Training loss: 2.2268499891497013
Validation loss: 2.646853258049183

Epoch: 6| Step: 6
Training loss: 2.255406242537733
Validation loss: 2.6493533336269413

Epoch: 6| Step: 7
Training loss: 2.820434905801112
Validation loss: 2.622910350004919

Epoch: 6| Step: 8
Training loss: 2.562385556526459
Validation loss: 2.5719489727736446

Epoch: 6| Step: 9
Training loss: 2.055887198400337
Validation loss: 2.5307628092353385

Epoch: 6| Step: 10
Training loss: 2.6799284267831975
Validation loss: 2.489968193445079

Epoch: 6| Step: 11
Training loss: 2.302692959763277
Validation loss: 2.4824745946710913

Epoch: 6| Step: 12
Training loss: 2.4536340270422703
Validation loss: 2.457114859552547

Epoch: 6| Step: 13
Training loss: 2.1560496361562125
Validation loss: 2.4552827939476636

Epoch: 260| Step: 0
Training loss: 2.4520825157283004
Validation loss: 2.439516603216744

Epoch: 6| Step: 1
Training loss: 2.271441760200536
Validation loss: 2.4451598821853984

Epoch: 6| Step: 2
Training loss: 2.225315641666954
Validation loss: 2.436777193332916

Epoch: 6| Step: 3
Training loss: 2.254336099608929
Validation loss: 2.4795604166319984

Epoch: 6| Step: 4
Training loss: 2.582270762636045
Validation loss: 2.50218232999068

Epoch: 6| Step: 5
Training loss: 2.492140240355686
Validation loss: 2.5247900540193124

Epoch: 6| Step: 6
Training loss: 2.612526275648647
Validation loss: 2.5202281975263117

Epoch: 6| Step: 7
Training loss: 2.575366677407667
Validation loss: 2.5127117745859313

Epoch: 6| Step: 8
Training loss: 2.1637095910700506
Validation loss: 2.4894805968011964

Epoch: 6| Step: 9
Training loss: 2.015264197888823
Validation loss: 2.482325137429539

Epoch: 6| Step: 10
Training loss: 2.3824926943431817
Validation loss: 2.4908419335970216

Epoch: 6| Step: 11
Training loss: 2.7951801641877316
Validation loss: 2.4732858566174496

Epoch: 6| Step: 12
Training loss: 2.7589458265748186
Validation loss: 2.4366446888364846

Epoch: 6| Step: 13
Training loss: 1.4021279851747852
Validation loss: 2.458901382634758

Epoch: 261| Step: 0
Training loss: 2.0574713004834924
Validation loss: 2.4341836502513936

Epoch: 6| Step: 1
Training loss: 2.5056324452427328
Validation loss: 2.4600551728695215

Epoch: 6| Step: 2
Training loss: 2.563216597681444
Validation loss: 2.452412049372264

Epoch: 6| Step: 3
Training loss: 3.2591004238616126
Validation loss: 2.4733436592012987

Epoch: 6| Step: 4
Training loss: 2.4326785404120796
Validation loss: 2.4910618428420537

Epoch: 6| Step: 5
Training loss: 2.1910358734745854
Validation loss: 2.497107930042652

Epoch: 6| Step: 6
Training loss: 1.9400791106856943
Validation loss: 2.518118144995453

Epoch: 6| Step: 7
Training loss: 2.5290360364115054
Validation loss: 2.517299257243902

Epoch: 6| Step: 8
Training loss: 2.1237879269577284
Validation loss: 2.5123765231149586

Epoch: 6| Step: 9
Training loss: 2.1832590682622093
Validation loss: 2.521346866129475

Epoch: 6| Step: 10
Training loss: 2.0709531548551485
Validation loss: 2.5242536124129344

Epoch: 6| Step: 11
Training loss: 2.3666749909303797
Validation loss: 2.5085788788001806

Epoch: 6| Step: 12
Training loss: 2.276536330555073
Validation loss: 2.4971862052803364

Epoch: 6| Step: 13
Training loss: 2.43496268821501
Validation loss: 2.475412721094219

Epoch: 262| Step: 0
Training loss: 2.334188974263228
Validation loss: 2.4627214093091156

Epoch: 6| Step: 1
Training loss: 2.9437238623234183
Validation loss: 2.462179916956128

Epoch: 6| Step: 2
Training loss: 2.5860754247111437
Validation loss: 2.4626485511701826

Epoch: 6| Step: 3
Training loss: 2.830418452406403
Validation loss: 2.443219015762764

Epoch: 6| Step: 4
Training loss: 2.04186958809688
Validation loss: 2.418955768637108

Epoch: 6| Step: 5
Training loss: 2.38228834046628
Validation loss: 2.417741195221322

Epoch: 6| Step: 6
Training loss: 1.8629370157485186
Validation loss: 2.420767922149849

Epoch: 6| Step: 7
Training loss: 2.324407079423487
Validation loss: 2.4169624576871875

Epoch: 6| Step: 8
Training loss: 2.0504472151694237
Validation loss: 2.4309719312289624

Epoch: 6| Step: 9
Training loss: 1.8159678596685689
Validation loss: 2.43979101368826

Epoch: 6| Step: 10
Training loss: 2.552297985366034
Validation loss: 2.4540246688394203

Epoch: 6| Step: 11
Training loss: 2.0347675091329585
Validation loss: 2.4522343315765966

Epoch: 6| Step: 12
Training loss: 2.4387142384858067
Validation loss: 2.4943978411987824

Epoch: 6| Step: 13
Training loss: 2.8807646965374327
Validation loss: 2.5153369793459093

Epoch: 263| Step: 0
Training loss: 2.2370629848161783
Validation loss: 2.563664219641855

Epoch: 6| Step: 1
Training loss: 2.1101309092983356
Validation loss: 2.5500017776177435

Epoch: 6| Step: 2
Training loss: 2.663881894251507
Validation loss: 2.5380920726486056

Epoch: 6| Step: 3
Training loss: 1.5920233255335705
Validation loss: 2.540376757167607

Epoch: 6| Step: 4
Training loss: 2.860251703990518
Validation loss: 2.5450856334738874

Epoch: 6| Step: 5
Training loss: 2.160292664233622
Validation loss: 2.4893848678011303

Epoch: 6| Step: 6
Training loss: 2.4928576486206793
Validation loss: 2.4518672513523456

Epoch: 6| Step: 7
Training loss: 2.0217757894947352
Validation loss: 2.4186637163704

Epoch: 6| Step: 8
Training loss: 2.9513683443040053
Validation loss: 2.4150704072060196

Epoch: 6| Step: 9
Training loss: 2.2975987961274504
Validation loss: 2.392644669404935

Epoch: 6| Step: 10
Training loss: 1.977767215330277
Validation loss: 2.374906774481961

Epoch: 6| Step: 11
Training loss: 2.449719829499282
Validation loss: 2.4020533974088134

Epoch: 6| Step: 12
Training loss: 2.4502796753050733
Validation loss: 2.376892129506416

Epoch: 6| Step: 13
Training loss: 2.3358981023929926
Validation loss: 2.4154394433322945

Epoch: 264| Step: 0
Training loss: 2.5370678388030865
Validation loss: 2.422098249664326

Epoch: 6| Step: 1
Training loss: 2.7321676881803336
Validation loss: 2.446300326069191

Epoch: 6| Step: 2
Training loss: 1.812455406955815
Validation loss: 2.4766454408772542

Epoch: 6| Step: 3
Training loss: 2.0681071501371107
Validation loss: 2.49567030406181

Epoch: 6| Step: 4
Training loss: 2.099949327493297
Validation loss: 2.5491006239949217

Epoch: 6| Step: 5
Training loss: 2.6398719752220456
Validation loss: 2.585948188020331

Epoch: 6| Step: 6
Training loss: 1.948851831796233
Validation loss: 2.58759440588237

Epoch: 6| Step: 7
Training loss: 2.5600082564220803
Validation loss: 2.6204794640148927

Epoch: 6| Step: 8
Training loss: 2.6222097008167315
Validation loss: 2.536077444807651

Epoch: 6| Step: 9
Training loss: 2.4635314833663795
Validation loss: 2.468526335522669

Epoch: 6| Step: 10
Training loss: 1.7645766259988842
Validation loss: 2.427931678031614

Epoch: 6| Step: 11
Training loss: 2.46877404696185
Validation loss: 2.410794467442244

Epoch: 6| Step: 12
Training loss: 2.3530341831225825
Validation loss: 2.4016574864185976

Epoch: 6| Step: 13
Training loss: 3.235002981948068
Validation loss: 2.3993629988595413

Epoch: 265| Step: 0
Training loss: 2.8673925508357554
Validation loss: 2.403344806120762

Epoch: 6| Step: 1
Training loss: 2.3856902208574815
Validation loss: 2.419851442560633

Epoch: 6| Step: 2
Training loss: 2.004857125840078
Validation loss: 2.4348868768612943

Epoch: 6| Step: 3
Training loss: 3.010322454929672
Validation loss: 2.440814189698085

Epoch: 6| Step: 4
Training loss: 2.5758581194574184
Validation loss: 2.4556414993142712

Epoch: 6| Step: 5
Training loss: 2.607710804450608
Validation loss: 2.487491097333583

Epoch: 6| Step: 6
Training loss: 2.180781592325117
Validation loss: 2.518219611729243

Epoch: 6| Step: 7
Training loss: 2.276251869766498
Validation loss: 2.5482536936254547

Epoch: 6| Step: 8
Training loss: 2.6567798759178434
Validation loss: 2.5708094325726045

Epoch: 6| Step: 9
Training loss: 2.0680237985049548
Validation loss: 2.6077332214932607

Epoch: 6| Step: 10
Training loss: 2.71840113012864
Validation loss: 2.611252571296764

Epoch: 6| Step: 11
Training loss: 2.017123589363841
Validation loss: 2.5994005079661706

Epoch: 6| Step: 12
Training loss: 1.3473328575553098
Validation loss: 2.5657564841140443

Epoch: 6| Step: 13
Training loss: 1.4071046139718786
Validation loss: 2.508808427765459

Epoch: 266| Step: 0
Training loss: 3.028927414657565
Validation loss: 2.501862038619085

Epoch: 6| Step: 1
Training loss: 1.8184973708420364
Validation loss: 2.4579932337525725

Epoch: 6| Step: 2
Training loss: 2.287193394525789
Validation loss: 2.447514876514093

Epoch: 6| Step: 3
Training loss: 1.8933970408847565
Validation loss: 2.4190707757440646

Epoch: 6| Step: 4
Training loss: 2.4684025000807273
Validation loss: 2.423744081147699

Epoch: 6| Step: 5
Training loss: 1.8714874426797286
Validation loss: 2.4320151749460215

Epoch: 6| Step: 6
Training loss: 1.6617825071283923
Validation loss: 2.4316838713591302

Epoch: 6| Step: 7
Training loss: 2.0305431603318507
Validation loss: 2.4507817502630784

Epoch: 6| Step: 8
Training loss: 2.433727670967795
Validation loss: 2.469835185909698

Epoch: 6| Step: 9
Training loss: 2.404474073708526
Validation loss: 2.4928528686393174

Epoch: 6| Step: 10
Training loss: 2.5628686035028796
Validation loss: 2.499926573177531

Epoch: 6| Step: 11
Training loss: 2.8203028628536004
Validation loss: 2.531043429740038

Epoch: 6| Step: 12
Training loss: 2.4968476447945154
Validation loss: 2.534098172951921

Epoch: 6| Step: 13
Training loss: 2.6655108410627864
Validation loss: 2.530794828673877

Epoch: 267| Step: 0
Training loss: 2.4432379847193735
Validation loss: 2.5438083526391817

Epoch: 6| Step: 1
Training loss: 2.8317256367968073
Validation loss: 2.5299488674961266

Epoch: 6| Step: 2
Training loss: 2.312323176866435
Validation loss: 2.5137018816947188

Epoch: 6| Step: 3
Training loss: 2.158503916221037
Validation loss: 2.526890878086955

Epoch: 6| Step: 4
Training loss: 2.140351215312603
Validation loss: 2.5391498519726423

Epoch: 6| Step: 5
Training loss: 2.2391994650052034
Validation loss: 2.540904497856192

Epoch: 6| Step: 6
Training loss: 2.63603579118016
Validation loss: 2.5393012690071477

Epoch: 6| Step: 7
Training loss: 2.436611502667013
Validation loss: 2.531668334365556

Epoch: 6| Step: 8
Training loss: 1.7983122012240502
Validation loss: 2.501014673785816

Epoch: 6| Step: 9
Training loss: 1.887913485577469
Validation loss: 2.470353850242722

Epoch: 6| Step: 10
Training loss: 2.8083630123513355
Validation loss: 2.468393605640717

Epoch: 6| Step: 11
Training loss: 1.352463570701769
Validation loss: 2.465184230744454

Epoch: 6| Step: 12
Training loss: 2.5617181469078085
Validation loss: 2.459605994180186

Epoch: 6| Step: 13
Training loss: 2.8674312976432583
Validation loss: 2.454224182883393

Epoch: 268| Step: 0
Training loss: 2.3182012026787224
Validation loss: 2.453663138038806

Epoch: 6| Step: 1
Training loss: 2.916611443859659
Validation loss: 2.444276810198131

Epoch: 6| Step: 2
Training loss: 1.6975194392264006
Validation loss: 2.4445782286039037

Epoch: 6| Step: 3
Training loss: 2.1702088476136905
Validation loss: 2.442052739085001

Epoch: 6| Step: 4
Training loss: 1.9439638664121346
Validation loss: 2.4339721661475724

Epoch: 6| Step: 5
Training loss: 2.5377432344865247
Validation loss: 2.462748984681619

Epoch: 6| Step: 6
Training loss: 2.2091810170957893
Validation loss: 2.463656391954332

Epoch: 6| Step: 7
Training loss: 2.3238695411242514
Validation loss: 2.4889371536818237

Epoch: 6| Step: 8
Training loss: 2.2871639984670513
Validation loss: 2.5059435487903166

Epoch: 6| Step: 9
Training loss: 2.7675484041221274
Validation loss: 2.488534161987892

Epoch: 6| Step: 10
Training loss: 2.537066147269345
Validation loss: 2.480503664488819

Epoch: 6| Step: 11
Training loss: 2.0978944668041946
Validation loss: 2.4493679990239436

Epoch: 6| Step: 12
Training loss: 2.342198176038356
Validation loss: 2.447790496514001

Epoch: 6| Step: 13
Training loss: 2.3924266533685095
Validation loss: 2.444756549087849

Epoch: 269| Step: 0
Training loss: 2.7704559202985233
Validation loss: 2.4535011780071487

Epoch: 6| Step: 1
Training loss: 1.9795644527694614
Validation loss: 2.448913061091356

Epoch: 6| Step: 2
Training loss: 2.049224553334508
Validation loss: 2.4549809083212333

Epoch: 6| Step: 3
Training loss: 2.4937106174810646
Validation loss: 2.452603200722834

Epoch: 6| Step: 4
Training loss: 2.3678011964264103
Validation loss: 2.4594747550284533

Epoch: 6| Step: 5
Training loss: 2.734973166297511
Validation loss: 2.4579791466871606

Epoch: 6| Step: 6
Training loss: 2.3950139068008625
Validation loss: 2.4671522686720166

Epoch: 6| Step: 7
Training loss: 1.6912758580928555
Validation loss: 2.4789469156121187

Epoch: 6| Step: 8
Training loss: 2.4440216459823496
Validation loss: 2.4998605217531176

Epoch: 6| Step: 9
Training loss: 1.7145233897796677
Validation loss: 2.516744658102348

Epoch: 6| Step: 10
Training loss: 2.700033283028502
Validation loss: 2.508496496063838

Epoch: 6| Step: 11
Training loss: 2.406684043677127
Validation loss: 2.5058092344031895

Epoch: 6| Step: 12
Training loss: 2.178379992934135
Validation loss: 2.48760999115972

Epoch: 6| Step: 13
Training loss: 1.94160930101299
Validation loss: 2.454954567742338

Epoch: 270| Step: 0
Training loss: 2.0279090989787245
Validation loss: 2.445620359936923

Epoch: 6| Step: 1
Training loss: 2.992833797287045
Validation loss: 2.4458579058949312

Epoch: 6| Step: 2
Training loss: 2.386796665948937
Validation loss: 2.430947925834591

Epoch: 6| Step: 3
Training loss: 2.6983574073978938
Validation loss: 2.437624251630394

Epoch: 6| Step: 4
Training loss: 2.141715224590087
Validation loss: 2.4444408769416817

Epoch: 6| Step: 5
Training loss: 1.6542908219155787
Validation loss: 2.443156884525869

Epoch: 6| Step: 6
Training loss: 1.6647264472382606
Validation loss: 2.453395463089674

Epoch: 6| Step: 7
Training loss: 2.1581076760567526
Validation loss: 2.477813736907741

Epoch: 6| Step: 8
Training loss: 2.426027343847489
Validation loss: 2.492260297972866

Epoch: 6| Step: 9
Training loss: 2.26037737084144
Validation loss: 2.5192320393932017

Epoch: 6| Step: 10
Training loss: 1.8419610088914389
Validation loss: 2.5328760964068247

Epoch: 6| Step: 11
Training loss: 2.6132692071611525
Validation loss: 2.5698305200433347

Epoch: 6| Step: 12
Training loss: 2.55369021113721
Validation loss: 2.531435922316765

Epoch: 6| Step: 13
Training loss: 2.5875592174295905
Validation loss: 2.474473482046953

Epoch: 271| Step: 0
Training loss: 2.478834103202542
Validation loss: 2.473434602301203

Epoch: 6| Step: 1
Training loss: 2.455281955509099
Validation loss: 2.442825358309081

Epoch: 6| Step: 2
Training loss: 2.4830783363180453
Validation loss: 2.4224096496022787

Epoch: 6| Step: 3
Training loss: 1.8066638512020532
Validation loss: 2.410969412848724

Epoch: 6| Step: 4
Training loss: 2.263713898815868
Validation loss: 2.4154552065370334

Epoch: 6| Step: 5
Training loss: 2.7040873672151333
Validation loss: 2.422139588721425

Epoch: 6| Step: 6
Training loss: 2.1026925944727597
Validation loss: 2.4292875114394894

Epoch: 6| Step: 7
Training loss: 1.9704138370503548
Validation loss: 2.4524771991976198

Epoch: 6| Step: 8
Training loss: 2.0132287737661656
Validation loss: 2.4881224140235267

Epoch: 6| Step: 9
Training loss: 2.676539136937175
Validation loss: 2.496599673158725

Epoch: 6| Step: 10
Training loss: 2.337007513541017
Validation loss: 2.530269426288733

Epoch: 6| Step: 11
Training loss: 1.9565042787500706
Validation loss: 2.537881463118821

Epoch: 6| Step: 12
Training loss: 2.934134157999786
Validation loss: 2.518626912684387

Epoch: 6| Step: 13
Training loss: 1.5930189812314224
Validation loss: 2.4966153213211566

Epoch: 272| Step: 0
Training loss: 2.412850479995032
Validation loss: 2.497549832396781

Epoch: 6| Step: 1
Training loss: 1.8955416472460034
Validation loss: 2.499277165214033

Epoch: 6| Step: 2
Training loss: 2.9190924956096893
Validation loss: 2.4834195822453595

Epoch: 6| Step: 3
Training loss: 2.6524394808812413
Validation loss: 2.4604972834970082

Epoch: 6| Step: 4
Training loss: 1.776092558399189
Validation loss: 2.464071982672904

Epoch: 6| Step: 5
Training loss: 1.5216496858906274
Validation loss: 2.4677832332944707

Epoch: 6| Step: 6
Training loss: 2.8768619644628837
Validation loss: 2.4677870642867097

Epoch: 6| Step: 7
Training loss: 1.4072490957707549
Validation loss: 2.475076940174827

Epoch: 6| Step: 8
Training loss: 1.7372763482924367
Validation loss: 2.47831718621236

Epoch: 6| Step: 9
Training loss: 2.705315027983759
Validation loss: 2.466512864524725

Epoch: 6| Step: 10
Training loss: 2.774024922661188
Validation loss: 2.497435670761382

Epoch: 6| Step: 11
Training loss: 2.3155480993683293
Validation loss: 2.5037950403350773

Epoch: 6| Step: 12
Training loss: 2.386064655185774
Validation loss: 2.520566308009768

Epoch: 6| Step: 13
Training loss: 1.514938828394756
Validation loss: 2.5061658093332517

Epoch: 273| Step: 0
Training loss: 2.426536356532742
Validation loss: 2.485732753048639

Epoch: 6| Step: 1
Training loss: 2.2837203772116026
Validation loss: 2.468709299175961

Epoch: 6| Step: 2
Training loss: 2.4252101453198653
Validation loss: 2.4841847949625193

Epoch: 6| Step: 3
Training loss: 1.8777968210399623
Validation loss: 2.4593404483600123

Epoch: 6| Step: 4
Training loss: 2.383124459279357
Validation loss: 2.4605296067601032

Epoch: 6| Step: 5
Training loss: 2.124528495987105
Validation loss: 2.453075064866811

Epoch: 6| Step: 6
Training loss: 1.8793085187108436
Validation loss: 2.4668566628406454

Epoch: 6| Step: 7
Training loss: 1.8851302826883718
Validation loss: 2.435484697512507

Epoch: 6| Step: 8
Training loss: 2.719920903766836
Validation loss: 2.4802597395798407

Epoch: 6| Step: 9
Training loss: 2.188112445654725
Validation loss: 2.5019038641902616

Epoch: 6| Step: 10
Training loss: 2.1576518049352478
Validation loss: 2.519179315543572

Epoch: 6| Step: 11
Training loss: 2.6314652162369803
Validation loss: 2.5548479412970053

Epoch: 6| Step: 12
Training loss: 2.691205685787114
Validation loss: 2.509782648697154

Epoch: 6| Step: 13
Training loss: 1.867212973704208
Validation loss: 2.493507496784904

Epoch: 274| Step: 0
Training loss: 2.381710610683933
Validation loss: 2.503713523101775

Epoch: 6| Step: 1
Training loss: 1.9965593425817119
Validation loss: 2.495078172369252

Epoch: 6| Step: 2
Training loss: 2.3443357625762764
Validation loss: 2.5127910879859288

Epoch: 6| Step: 3
Training loss: 2.0321715391923414
Validation loss: 2.4913657723216938

Epoch: 6| Step: 4
Training loss: 2.857425713161725
Validation loss: 2.488100471561451

Epoch: 6| Step: 5
Training loss: 2.200376053661477
Validation loss: 2.494363563134331

Epoch: 6| Step: 6
Training loss: 2.1054046564484983
Validation loss: 2.497785378980281

Epoch: 6| Step: 7
Training loss: 2.472850629208121
Validation loss: 2.5000429652223928

Epoch: 6| Step: 8
Training loss: 1.8899009516158076
Validation loss: 2.4929085793288865

Epoch: 6| Step: 9
Training loss: 2.1273801600842335
Validation loss: 2.5052790310847697

Epoch: 6| Step: 10
Training loss: 2.816330907398536
Validation loss: 2.5095173331123553

Epoch: 6| Step: 11
Training loss: 1.8889823902898606
Validation loss: 2.506378352576572

Epoch: 6| Step: 12
Training loss: 2.3088989056131393
Validation loss: 2.499696656763865

Epoch: 6| Step: 13
Training loss: 1.7162716423387123
Validation loss: 2.487059861785168

Epoch: 275| Step: 0
Training loss: 2.2387735248226375
Validation loss: 2.4834206455168695

Epoch: 6| Step: 1
Training loss: 1.6374689900031836
Validation loss: 2.469450932504947

Epoch: 6| Step: 2
Training loss: 2.1086612200180723
Validation loss: 2.4750183877503242

Epoch: 6| Step: 3
Training loss: 1.8701684372057261
Validation loss: 2.4756933444110527

Epoch: 6| Step: 4
Training loss: 2.6600417954165754
Validation loss: 2.4851180931252355

Epoch: 6| Step: 5
Training loss: 2.1248579538777914
Validation loss: 2.485248549597618

Epoch: 6| Step: 6
Training loss: 2.1668155936874554
Validation loss: 2.467748294142246

Epoch: 6| Step: 7
Training loss: 2.5444803974808026
Validation loss: 2.4695370926321236

Epoch: 6| Step: 8
Training loss: 1.8869233899073041
Validation loss: 2.4880890767777464

Epoch: 6| Step: 9
Training loss: 2.1768637246763443
Validation loss: 2.4596335648732888

Epoch: 6| Step: 10
Training loss: 2.5859924494964286
Validation loss: 2.4854297242301544

Epoch: 6| Step: 11
Training loss: 2.906096423613615
Validation loss: 2.503868008668506

Epoch: 6| Step: 12
Training loss: 2.2087534978608963
Validation loss: 2.521051034567057

Epoch: 6| Step: 13
Training loss: 2.0512435537326463
Validation loss: 2.5623457687388376

Epoch: 276| Step: 0
Training loss: 2.704371170594881
Validation loss: 2.527441584304162

Epoch: 6| Step: 1
Training loss: 2.38978033165589
Validation loss: 2.5329995063973088

Epoch: 6| Step: 2
Training loss: 1.6061728017342225
Validation loss: 2.5174733197573524

Epoch: 6| Step: 3
Training loss: 1.9675101357263172
Validation loss: 2.5041479145403285

Epoch: 6| Step: 4
Training loss: 2.346437261523441
Validation loss: 2.485265029473245

Epoch: 6| Step: 5
Training loss: 2.2951107385716987
Validation loss: 2.4819564051828187

Epoch: 6| Step: 6
Training loss: 2.48636571431719
Validation loss: 2.4585373322648723

Epoch: 6| Step: 7
Training loss: 1.7118629495810094
Validation loss: 2.4549903693069886

Epoch: 6| Step: 8
Training loss: 2.810579449515885
Validation loss: 2.4504591365750445

Epoch: 6| Step: 9
Training loss: 2.1738211056715064
Validation loss: 2.447657918946014

Epoch: 6| Step: 10
Training loss: 2.336299804352573
Validation loss: 2.4770564160660764

Epoch: 6| Step: 11
Training loss: 2.0654985998033975
Validation loss: 2.4795368821593113

Epoch: 6| Step: 12
Training loss: 1.6417816444578168
Validation loss: 2.4914526326402435

Epoch: 6| Step: 13
Training loss: 2.7450016720737165
Validation loss: 2.520577362727462

Epoch: 277| Step: 0
Training loss: 2.9685439188854947
Validation loss: 2.516279988924604

Epoch: 6| Step: 1
Training loss: 1.943423966911025
Validation loss: 2.506281482015075

Epoch: 6| Step: 2
Training loss: 2.080889705596601
Validation loss: 2.507306929390107

Epoch: 6| Step: 3
Training loss: 2.035718141040641
Validation loss: 2.4678543405899527

Epoch: 6| Step: 4
Training loss: 2.319129102619494
Validation loss: 2.4573186682186052

Epoch: 6| Step: 5
Training loss: 2.5604185629440086
Validation loss: 2.4438711997762534

Epoch: 6| Step: 6
Training loss: 2.5350030461881796
Validation loss: 2.4443234451084384

Epoch: 6| Step: 7
Training loss: 1.9143898197488431
Validation loss: 2.44087656069267

Epoch: 6| Step: 8
Training loss: 1.7692717305037864
Validation loss: 2.4477152709919037

Epoch: 6| Step: 9
Training loss: 2.11282518581356
Validation loss: 2.432437595561469

Epoch: 6| Step: 10
Training loss: 2.3199286865915427
Validation loss: 2.4513195294551333

Epoch: 6| Step: 11
Training loss: 2.3681500684187045
Validation loss: 2.468822428859834

Epoch: 6| Step: 12
Training loss: 2.046047596740467
Validation loss: 2.4464761653737113

Epoch: 6| Step: 13
Training loss: 2.2200367379800174
Validation loss: 2.4382962802812034

Epoch: 278| Step: 0
Training loss: 1.9191194955138993
Validation loss: 2.4664903743485036

Epoch: 6| Step: 1
Training loss: 2.411381192274578
Validation loss: 2.475894475446799

Epoch: 6| Step: 2
Training loss: 1.6263481563234798
Validation loss: 2.4853580361868284

Epoch: 6| Step: 3
Training loss: 1.965297275022643
Validation loss: 2.483807680170474

Epoch: 6| Step: 4
Training loss: 1.8548085533943586
Validation loss: 2.4891193348977287

Epoch: 6| Step: 5
Training loss: 2.4551327015736697
Validation loss: 2.478865748861677

Epoch: 6| Step: 6
Training loss: 2.2521102334344203
Validation loss: 2.494316266607478

Epoch: 6| Step: 7
Training loss: 3.1217636134349607
Validation loss: 2.5328446184678493

Epoch: 6| Step: 8
Training loss: 1.8988440435448966
Validation loss: 2.526787218025499

Epoch: 6| Step: 9
Training loss: 2.5109803343883557
Validation loss: 2.5361380476679227

Epoch: 6| Step: 10
Training loss: 2.294203261824763
Validation loss: 2.5170726367461005

Epoch: 6| Step: 11
Training loss: 2.1458787141711007
Validation loss: 2.490894884681443

Epoch: 6| Step: 12
Training loss: 2.426339249617794
Validation loss: 2.495923412277299

Epoch: 6| Step: 13
Training loss: 1.533805272133163
Validation loss: 2.483370427635538

Epoch: 279| Step: 0
Training loss: 2.9998207038706655
Validation loss: 2.4754056155463258

Epoch: 6| Step: 1
Training loss: 2.4875001265175944
Validation loss: 2.4996441762231933

Epoch: 6| Step: 2
Training loss: 2.3260712237486754
Validation loss: 2.509702463377914

Epoch: 6| Step: 3
Training loss: 1.7969816093331663
Validation loss: 2.5031796866748435

Epoch: 6| Step: 4
Training loss: 2.521825316742145
Validation loss: 2.5009654221683

Epoch: 6| Step: 5
Training loss: 2.1351579338818025
Validation loss: 2.5083055435465678

Epoch: 6| Step: 6
Training loss: 1.9023636771848376
Validation loss: 2.519081711942501

Epoch: 6| Step: 7
Training loss: 2.220300696688586
Validation loss: 2.507031959425172

Epoch: 6| Step: 8
Training loss: 1.8566602876417793
Validation loss: 2.483973855563329

Epoch: 6| Step: 9
Training loss: 2.6030935187113395
Validation loss: 2.4982004169534657

Epoch: 6| Step: 10
Training loss: 1.971468365753338
Validation loss: 2.480068166624921

Epoch: 6| Step: 11
Training loss: 1.962925970414047
Validation loss: 2.459275278119374

Epoch: 6| Step: 12
Training loss: 2.298325787597102
Validation loss: 2.441301343932274

Epoch: 6| Step: 13
Training loss: 1.6603789056802234
Validation loss: 2.4439297819793606

Epoch: 280| Step: 0
Training loss: 2.50159289158713
Validation loss: 2.4362382044544746

Epoch: 6| Step: 1
Training loss: 2.174808414834592
Validation loss: 2.4299650819441174

Epoch: 6| Step: 2
Training loss: 1.841444546119626
Validation loss: 2.4520562192906388

Epoch: 6| Step: 3
Training loss: 2.346561119332176
Validation loss: 2.453261956897977

Epoch: 6| Step: 4
Training loss: 1.5969563562380933
Validation loss: 2.462219790722518

Epoch: 6| Step: 5
Training loss: 1.8745280625549217
Validation loss: 2.476906828543362

Epoch: 6| Step: 6
Training loss: 2.4422570783059765
Validation loss: 2.5114554069389268

Epoch: 6| Step: 7
Training loss: 2.6170646980284977
Validation loss: 2.527443202147886

Epoch: 6| Step: 8
Training loss: 2.2325878331932123
Validation loss: 2.5503560137202026

Epoch: 6| Step: 9
Training loss: 2.4682500791794055
Validation loss: 2.5686719466130556

Epoch: 6| Step: 10
Training loss: 2.055701756075141
Validation loss: 2.5177316559885234

Epoch: 6| Step: 11
Training loss: 2.111087584225023
Validation loss: 2.4991581924913513

Epoch: 6| Step: 12
Training loss: 2.1904946673445234
Validation loss: 2.480361623261839

Epoch: 6| Step: 13
Training loss: 2.565366583760677
Validation loss: 2.460904651845173

Epoch: 281| Step: 0
Training loss: 2.0766161266604146
Validation loss: 2.4703450084902334

Epoch: 6| Step: 1
Training loss: 2.217566805997623
Validation loss: 2.470857235714161

Epoch: 6| Step: 2
Training loss: 2.221251246463252
Validation loss: 2.4673900396914483

Epoch: 6| Step: 3
Training loss: 2.1274348502488207
Validation loss: 2.468885493581021

Epoch: 6| Step: 4
Training loss: 2.1878698853713723
Validation loss: 2.4941333250898605

Epoch: 6| Step: 5
Training loss: 2.2985240180914284
Validation loss: 2.4877209463905445

Epoch: 6| Step: 6
Training loss: 2.0372203237104394
Validation loss: 2.5386355673620713

Epoch: 6| Step: 7
Training loss: 2.267289175307767
Validation loss: 2.5320958231257595

Epoch: 6| Step: 8
Training loss: 2.0726385904502345
Validation loss: 2.5120816103985972

Epoch: 6| Step: 9
Training loss: 1.9724582081707958
Validation loss: 2.5094180715922834

Epoch: 6| Step: 10
Training loss: 2.4738449445472255
Validation loss: 2.4899646485720903

Epoch: 6| Step: 11
Training loss: 1.8458404328473075
Validation loss: 2.489374729114349

Epoch: 6| Step: 12
Training loss: 1.922489471208292
Validation loss: 2.4801863671344613

Epoch: 6| Step: 13
Training loss: 3.3239416058457265
Validation loss: 2.4837425697758397

Epoch: 282| Step: 0
Training loss: 2.1133196081604297
Validation loss: 2.5243484334621673

Epoch: 6| Step: 1
Training loss: 1.8795520204092029
Validation loss: 2.520965650667813

Epoch: 6| Step: 2
Training loss: 2.0116879358987143
Validation loss: 2.515380411315371

Epoch: 6| Step: 3
Training loss: 2.785598013620693
Validation loss: 2.5253604785316544

Epoch: 6| Step: 4
Training loss: 2.0661660182753185
Validation loss: 2.5208149516663387

Epoch: 6| Step: 5
Training loss: 2.368258293872647
Validation loss: 2.511296339032635

Epoch: 6| Step: 6
Training loss: 1.9896791711330064
Validation loss: 2.512274390270242

Epoch: 6| Step: 7
Training loss: 1.977871306966504
Validation loss: 2.5103445119746786

Epoch: 6| Step: 8
Training loss: 2.0631962381317526
Validation loss: 2.511888970863294

Epoch: 6| Step: 9
Training loss: 1.9485246114216566
Validation loss: 2.511697575052441

Epoch: 6| Step: 10
Training loss: 2.0851555548073963
Validation loss: 2.5403475338123247

Epoch: 6| Step: 11
Training loss: 2.4865403245869793
Validation loss: 2.5292130973048894

Epoch: 6| Step: 12
Training loss: 1.9554569818597525
Validation loss: 2.515489675879062

Epoch: 6| Step: 13
Training loss: 2.993256300832039
Validation loss: 2.519988146537721

Epoch: 283| Step: 0
Training loss: 2.2630275174573744
Validation loss: 2.4982961139562057

Epoch: 6| Step: 1
Training loss: 2.2402240516803884
Validation loss: 2.496383837831064

Epoch: 6| Step: 2
Training loss: 1.9621005921392245
Validation loss: 2.487419242988785

Epoch: 6| Step: 3
Training loss: 2.217948338924278
Validation loss: 2.4994827966056614

Epoch: 6| Step: 4
Training loss: 2.62699723330767
Validation loss: 2.486236545574988

Epoch: 6| Step: 5
Training loss: 2.0653345685839835
Validation loss: 2.5051028502519213

Epoch: 6| Step: 6
Training loss: 2.433492643114377
Validation loss: 2.513810063757991

Epoch: 6| Step: 7
Training loss: 1.9658683395772583
Validation loss: 2.5110341012615964

Epoch: 6| Step: 8
Training loss: 2.0338714116953223
Validation loss: 2.5251524909339933

Epoch: 6| Step: 9
Training loss: 2.0560944240350674
Validation loss: 2.530329181431996

Epoch: 6| Step: 10
Training loss: 1.733471884447487
Validation loss: 2.528361765276682

Epoch: 6| Step: 11
Training loss: 2.3005976190779704
Validation loss: 2.537041678511439

Epoch: 6| Step: 12
Training loss: 2.4370550091795904
Validation loss: 2.522992037534077

Epoch: 6| Step: 13
Training loss: 1.4004912400113
Validation loss: 2.5379048883862456

Epoch: 284| Step: 0
Training loss: 2.269169842674264
Validation loss: 2.51922395229185

Epoch: 6| Step: 1
Training loss: 2.626738744447112
Validation loss: 2.502566325273451

Epoch: 6| Step: 2
Training loss: 2.1851018566771563
Validation loss: 2.5171472102740893

Epoch: 6| Step: 3
Training loss: 1.7690194507691845
Validation loss: 2.512238764713184

Epoch: 6| Step: 4
Training loss: 2.1868567474641414
Validation loss: 2.5180977813173495

Epoch: 6| Step: 5
Training loss: 1.8963963717030252
Validation loss: 2.5174555537568186

Epoch: 6| Step: 6
Training loss: 2.485247572726246
Validation loss: 2.492449867206055

Epoch: 6| Step: 7
Training loss: 2.0763762724233334
Validation loss: 2.470010541810614

Epoch: 6| Step: 8
Training loss: 2.7163182926501976
Validation loss: 2.4640931975446816

Epoch: 6| Step: 9
Training loss: 1.9774666026462493
Validation loss: 2.46710919306294

Epoch: 6| Step: 10
Training loss: 1.71238974334632
Validation loss: 2.439505464907994

Epoch: 6| Step: 11
Training loss: 2.140344531766006
Validation loss: 2.4417111305769716

Epoch: 6| Step: 12
Training loss: 1.8783772887824406
Validation loss: 2.4781616995687648

Epoch: 6| Step: 13
Training loss: 2.1438737705634883
Validation loss: 2.4530611319242337

Epoch: 285| Step: 0
Training loss: 2.561044512241609
Validation loss: 2.482065783939961

Epoch: 6| Step: 1
Training loss: 2.1574254909127992
Validation loss: 2.4694135861036135

Epoch: 6| Step: 2
Training loss: 2.1362417968449643
Validation loss: 2.491169768021662

Epoch: 6| Step: 3
Training loss: 2.1893488019442464
Validation loss: 2.5223326536702793

Epoch: 6| Step: 4
Training loss: 2.385636254299802
Validation loss: 2.5660120219753564

Epoch: 6| Step: 5
Training loss: 1.9937968616299797
Validation loss: 2.5898990105829025

Epoch: 6| Step: 6
Training loss: 1.9405437065457094
Validation loss: 2.578797765652326

Epoch: 6| Step: 7
Training loss: 1.974096516492292
Validation loss: 2.56057469842588

Epoch: 6| Step: 8
Training loss: 1.5673968828466975
Validation loss: 2.54262543872631

Epoch: 6| Step: 9
Training loss: 2.1365653197384424
Validation loss: 2.5071850002059923

Epoch: 6| Step: 10
Training loss: 2.5073000185206267
Validation loss: 2.4886563446372443

Epoch: 6| Step: 11
Training loss: 2.3023044485744673
Validation loss: 2.481461569685556

Epoch: 6| Step: 12
Training loss: 2.474895698584502
Validation loss: 2.48864141491211

Epoch: 6| Step: 13
Training loss: 1.0958285608417357
Validation loss: 2.49459694774629

Epoch: 286| Step: 0
Training loss: 2.2218161874276037
Validation loss: 2.4789893708325685

Epoch: 6| Step: 1
Training loss: 2.310153389168788
Validation loss: 2.5039348010989793

Epoch: 6| Step: 2
Training loss: 1.7481340269388264
Validation loss: 2.518025096039271

Epoch: 6| Step: 3
Training loss: 2.5870833609723274
Validation loss: 2.5388177155157963

Epoch: 6| Step: 4
Training loss: 2.0732761116145277
Validation loss: 2.5503098365170094

Epoch: 6| Step: 5
Training loss: 1.9938630481586799
Validation loss: 2.5778576624964753

Epoch: 6| Step: 6
Training loss: 1.6923043419397974
Validation loss: 2.6373363719191363

Epoch: 6| Step: 7
Training loss: 2.7826532831325603
Validation loss: 2.660423548832758

Epoch: 6| Step: 8
Training loss: 2.3397618249169865
Validation loss: 2.6476343536534204

Epoch: 6| Step: 9
Training loss: 2.2877058884981887
Validation loss: 2.5731929315043103

Epoch: 6| Step: 10
Training loss: 1.3602102936114988
Validation loss: 2.5316857403846624

Epoch: 6| Step: 11
Training loss: 2.0999615892802983
Validation loss: 2.4843970403753235

Epoch: 6| Step: 12
Training loss: 2.234614646171085
Validation loss: 2.4547842243397215

Epoch: 6| Step: 13
Training loss: 1.9744419589134652
Validation loss: 2.4340242089338364

Epoch: 287| Step: 0
Training loss: 1.4044250514674
Validation loss: 2.446382934820618

Epoch: 6| Step: 1
Training loss: 2.617299911590086
Validation loss: 2.4220312845466756

Epoch: 6| Step: 2
Training loss: 2.5689130411127334
Validation loss: 2.423723680831755

Epoch: 6| Step: 3
Training loss: 1.8956641516461141
Validation loss: 2.4403739395979582

Epoch: 6| Step: 4
Training loss: 2.7530631431879
Validation loss: 2.464600445033838

Epoch: 6| Step: 5
Training loss: 1.8409010001795747
Validation loss: 2.486677969499133

Epoch: 6| Step: 6
Training loss: 2.1567283873690597
Validation loss: 2.493118814187654

Epoch: 6| Step: 7
Training loss: 2.0925129894368433
Validation loss: 2.5059407027356633

Epoch: 6| Step: 8
Training loss: 1.9758411644252565
Validation loss: 2.5039844601510755

Epoch: 6| Step: 9
Training loss: 1.846387108713828
Validation loss: 2.5209328321527753

Epoch: 6| Step: 10
Training loss: 1.9301229750041617
Validation loss: 2.5114556478427303

Epoch: 6| Step: 11
Training loss: 2.6512496556880283
Validation loss: 2.4855416380256536

Epoch: 6| Step: 12
Training loss: 1.6061164681707312
Validation loss: 2.5054011645595646

Epoch: 6| Step: 13
Training loss: 2.0441088440165127
Validation loss: 2.531452989155309

Epoch: 288| Step: 0
Training loss: 2.142795548234979
Validation loss: 2.538438419857347

Epoch: 6| Step: 1
Training loss: 2.519124505382893
Validation loss: 2.5717037786817922

Epoch: 6| Step: 2
Training loss: 2.639062904732799
Validation loss: 2.5059700623655714

Epoch: 6| Step: 3
Training loss: 2.2121160486556137
Validation loss: 2.4942301093489436

Epoch: 6| Step: 4
Training loss: 1.608219361425963
Validation loss: 2.485912441399282

Epoch: 6| Step: 5
Training loss: 2.1735784861994163
Validation loss: 2.49314776028703

Epoch: 6| Step: 6
Training loss: 1.7457968098803909
Validation loss: 2.469125433823229

Epoch: 6| Step: 7
Training loss: 1.968871703246302
Validation loss: 2.4623266864221027

Epoch: 6| Step: 8
Training loss: 1.805802500376046
Validation loss: 2.467566951657901

Epoch: 6| Step: 9
Training loss: 2.0912041060205264
Validation loss: 2.4539107639726607

Epoch: 6| Step: 10
Training loss: 2.6498562323960453
Validation loss: 2.4793458230843752

Epoch: 6| Step: 11
Training loss: 2.082278811281668
Validation loss: 2.4973104848297005

Epoch: 6| Step: 12
Training loss: 1.6558735257655697
Validation loss: 2.5544491665772484

Epoch: 6| Step: 13
Training loss: 2.3977459336080185
Validation loss: 2.614473789105032

Epoch: 289| Step: 0
Training loss: 1.855095434278782
Validation loss: 2.6247832896857104

Epoch: 6| Step: 1
Training loss: 1.550861654431272
Validation loss: 2.6640077789270915

Epoch: 6| Step: 2
Training loss: 2.067636970678627
Validation loss: 2.6879076728388847

Epoch: 6| Step: 3
Training loss: 2.765747584842833
Validation loss: 2.6231724480690652

Epoch: 6| Step: 4
Training loss: 2.3575537517483696
Validation loss: 2.5601070885505903

Epoch: 6| Step: 5
Training loss: 2.8332185347992795
Validation loss: 2.5227730123563155

Epoch: 6| Step: 6
Training loss: 2.103777544155215
Validation loss: 2.5120152550242545

Epoch: 6| Step: 7
Training loss: 1.4018329338194406
Validation loss: 2.4829924829417394

Epoch: 6| Step: 8
Training loss: 1.5972396941772757
Validation loss: 2.458348207618205

Epoch: 6| Step: 9
Training loss: 2.2512606162287425
Validation loss: 2.4668240213326618

Epoch: 6| Step: 10
Training loss: 1.8287014826650674
Validation loss: 2.4531038930149633

Epoch: 6| Step: 11
Training loss: 2.5957898311327345
Validation loss: 2.463651442933377

Epoch: 6| Step: 12
Training loss: 2.143192171972602
Validation loss: 2.445348421763598

Epoch: 6| Step: 13
Training loss: 1.993863944980025
Validation loss: 2.4672511472835406

Epoch: 290| Step: 0
Training loss: 1.6440531200959985
Validation loss: 2.5129875727105966

Epoch: 6| Step: 1
Training loss: 2.311476197301923
Validation loss: 2.5372560386349217

Epoch: 6| Step: 2
Training loss: 2.1752937907721512
Validation loss: 2.6091774908785905

Epoch: 6| Step: 3
Training loss: 1.9930247623074773
Validation loss: 2.6230170225845133

Epoch: 6| Step: 4
Training loss: 2.145886269320761
Validation loss: 2.6135831013821975

Epoch: 6| Step: 5
Training loss: 2.708639968728604
Validation loss: 2.546897874492003

Epoch: 6| Step: 6
Training loss: 2.3073576378845138
Validation loss: 2.524958387495168

Epoch: 6| Step: 7
Training loss: 2.1700715185940274
Validation loss: 2.513275748361566

Epoch: 6| Step: 8
Training loss: 2.175826614975343
Validation loss: 2.4936413912186426

Epoch: 6| Step: 9
Training loss: 2.0142536081540046
Validation loss: 2.4939227810184716

Epoch: 6| Step: 10
Training loss: 1.6915464981819077
Validation loss: 2.4914634265568765

Epoch: 6| Step: 11
Training loss: 2.2648204558833567
Validation loss: 2.498169887467355

Epoch: 6| Step: 12
Training loss: 1.93379694323778
Validation loss: 2.497702830121486

Epoch: 6| Step: 13
Training loss: 2.0961937378968805
Validation loss: 2.4997870036625147

Epoch: 291| Step: 0
Training loss: 2.18469821792525
Validation loss: 2.5130889283168183

Epoch: 6| Step: 1
Training loss: 2.4497630413450673
Validation loss: 2.498623551075598

Epoch: 6| Step: 2
Training loss: 1.6337302517153416
Validation loss: 2.523178561232858

Epoch: 6| Step: 3
Training loss: 2.184774062742121
Validation loss: 2.515731569271164

Epoch: 6| Step: 4
Training loss: 1.891558960300463
Validation loss: 2.5189821891947526

Epoch: 6| Step: 5
Training loss: 2.292389622717423
Validation loss: 2.5235256132824824

Epoch: 6| Step: 6
Training loss: 1.524982002027023
Validation loss: 2.5094157765497047

Epoch: 6| Step: 7
Training loss: 2.328125819263698
Validation loss: 2.5121919511579835

Epoch: 6| Step: 8
Training loss: 2.400829402342622
Validation loss: 2.524359226866938

Epoch: 6| Step: 9
Training loss: 1.5350726155802434
Validation loss: 2.5131373914904054

Epoch: 6| Step: 10
Training loss: 2.2593545366682233
Validation loss: 2.525201145933738

Epoch: 6| Step: 11
Training loss: 1.945851201609134
Validation loss: 2.52187131154679

Epoch: 6| Step: 12
Training loss: 2.117979570147977
Validation loss: 2.518230378465104

Epoch: 6| Step: 13
Training loss: 2.046304171805796
Validation loss: 2.49216938195445

Epoch: 292| Step: 0
Training loss: 2.537505532244585
Validation loss: 2.480469076595684

Epoch: 6| Step: 1
Training loss: 2.324222545460399
Validation loss: 2.4858648293867507

Epoch: 6| Step: 2
Training loss: 1.8208265765637255
Validation loss: 2.476053795573051

Epoch: 6| Step: 3
Training loss: 2.2151456758287527
Validation loss: 2.500747482779636

Epoch: 6| Step: 4
Training loss: 1.9304990104548267
Validation loss: 2.502895315282674

Epoch: 6| Step: 5
Training loss: 1.973290369826938
Validation loss: 2.493284612688739

Epoch: 6| Step: 6
Training loss: 1.7840336247598254
Validation loss: 2.4866659599336627

Epoch: 6| Step: 7
Training loss: 2.1123876462774893
Validation loss: 2.5090273048557385

Epoch: 6| Step: 8
Training loss: 1.9528445843621574
Validation loss: 2.5212336417044483

Epoch: 6| Step: 9
Training loss: 1.844968231672
Validation loss: 2.5199476527076725

Epoch: 6| Step: 10
Training loss: 1.8483936862476975
Validation loss: 2.510093119389678

Epoch: 6| Step: 11
Training loss: 2.1995623846899788
Validation loss: 2.501486648998386

Epoch: 6| Step: 12
Training loss: 2.444474439244283
Validation loss: 2.497449687704861

Epoch: 6| Step: 13
Training loss: 1.621952647443416
Validation loss: 2.4956836211047193

Epoch: 293| Step: 0
Training loss: 1.5372294242153122
Validation loss: 2.515351225224614

Epoch: 6| Step: 1
Training loss: 1.9081285319590813
Validation loss: 2.5061587009591877

Epoch: 6| Step: 2
Training loss: 2.092066757216507
Validation loss: 2.452284541000045

Epoch: 6| Step: 3
Training loss: 2.0312619722453666
Validation loss: 2.4597167409843257

Epoch: 6| Step: 4
Training loss: 2.485110863682194
Validation loss: 2.4518462621481536

Epoch: 6| Step: 5
Training loss: 1.460260244455373
Validation loss: 2.46276675913048

Epoch: 6| Step: 6
Training loss: 2.075204158988497
Validation loss: 2.449237987549197

Epoch: 6| Step: 7
Training loss: 1.7183715403638475
Validation loss: 2.446139971469121

Epoch: 6| Step: 8
Training loss: 2.45906145552219
Validation loss: 2.471331398277692

Epoch: 6| Step: 9
Training loss: 1.9412174862253082
Validation loss: 2.504890586669694

Epoch: 6| Step: 10
Training loss: 2.134658405930505
Validation loss: 2.5212330727936285

Epoch: 6| Step: 11
Training loss: 2.368400036568006
Validation loss: 2.501846022615496

Epoch: 6| Step: 12
Training loss: 1.8501231075256825
Validation loss: 2.4854297634259295

Epoch: 6| Step: 13
Training loss: 2.781045198936733
Validation loss: 2.493712527583401

Epoch: 294| Step: 0
Training loss: 2.0590617102203037
Validation loss: 2.4875351113331194

Epoch: 6| Step: 1
Training loss: 1.6921950124360743
Validation loss: 2.5041674774492386

Epoch: 6| Step: 2
Training loss: 1.8176630081894531
Validation loss: 2.4832404248182534

Epoch: 6| Step: 3
Training loss: 1.9358756116283684
Validation loss: 2.471353597511366

Epoch: 6| Step: 4
Training loss: 1.9869183438959082
Validation loss: 2.4665544434749314

Epoch: 6| Step: 5
Training loss: 2.167676421380751
Validation loss: 2.479843669379172

Epoch: 6| Step: 6
Training loss: 1.4714558614059887
Validation loss: 2.471671924002007

Epoch: 6| Step: 7
Training loss: 2.4261130384006546
Validation loss: 2.5048782448058424

Epoch: 6| Step: 8
Training loss: 2.2261309289120197
Validation loss: 2.488146828082294

Epoch: 6| Step: 9
Training loss: 2.2677370947183713
Validation loss: 2.5105693574802745

Epoch: 6| Step: 10
Training loss: 2.0631593748393624
Validation loss: 2.517470023392658

Epoch: 6| Step: 11
Training loss: 2.450657666744328
Validation loss: 2.503891354891648

Epoch: 6| Step: 12
Training loss: 2.2321200429567924
Validation loss: 2.5135921171733613

Epoch: 6| Step: 13
Training loss: 1.0566428249709943
Validation loss: 2.5312596250913413

Epoch: 295| Step: 0
Training loss: 2.451406569472669
Validation loss: 2.563585587159317

Epoch: 6| Step: 1
Training loss: 1.7723612607561559
Validation loss: 2.5502745713976576

Epoch: 6| Step: 2
Training loss: 1.823555803424654
Validation loss: 2.537358243474174

Epoch: 6| Step: 3
Training loss: 1.7762985342053963
Validation loss: 2.510754496454802

Epoch: 6| Step: 4
Training loss: 2.0738669921543815
Validation loss: 2.4986779737233222

Epoch: 6| Step: 5
Training loss: 1.735131863247063
Validation loss: 2.506756483746476

Epoch: 6| Step: 6
Training loss: 2.235634402158534
Validation loss: 2.487335567818229

Epoch: 6| Step: 7
Training loss: 1.3769243819030164
Validation loss: 2.501945160338241

Epoch: 6| Step: 8
Training loss: 2.2853183786636624
Validation loss: 2.4838113019518633

Epoch: 6| Step: 9
Training loss: 1.7577174182183977
Validation loss: 2.4975051942337494

Epoch: 6| Step: 10
Training loss: 2.351766685163065
Validation loss: 2.5081881898305536

Epoch: 6| Step: 11
Training loss: 2.163441042028644
Validation loss: 2.5220693881511966

Epoch: 6| Step: 12
Training loss: 2.081120447474036
Validation loss: 2.5252980399413083

Epoch: 6| Step: 13
Training loss: 2.3675940639737876
Validation loss: 2.5413034903488585

Epoch: 296| Step: 0
Training loss: 2.10711164197361
Validation loss: 2.5281178957304937

Epoch: 6| Step: 1
Training loss: 2.1041339330361786
Validation loss: 2.545732668905208

Epoch: 6| Step: 2
Training loss: 2.1180053482636527
Validation loss: 2.4979579214762246

Epoch: 6| Step: 3
Training loss: 2.2276376370464934
Validation loss: 2.4909665286462634

Epoch: 6| Step: 4
Training loss: 1.7874848851985385
Validation loss: 2.4824396356128813

Epoch: 6| Step: 5
Training loss: 1.7974713869961052
Validation loss: 2.4908621248815286

Epoch: 6| Step: 6
Training loss: 1.816921891065668
Validation loss: 2.4961897701436184

Epoch: 6| Step: 7
Training loss: 1.6491470617690687
Validation loss: 2.5313285188537615

Epoch: 6| Step: 8
Training loss: 2.657751937795174
Validation loss: 2.5405515796415856

Epoch: 6| Step: 9
Training loss: 2.009117800565176
Validation loss: 2.566923323044395

Epoch: 6| Step: 10
Training loss: 1.871450370299697
Validation loss: 2.5407418724233146

Epoch: 6| Step: 11
Training loss: 1.9757854758775921
Validation loss: 2.495327411961784

Epoch: 6| Step: 12
Training loss: 2.122931764178987
Validation loss: 2.466403970584772

Epoch: 6| Step: 13
Training loss: 1.883102774503142
Validation loss: 2.4349461216274313

Epoch: 297| Step: 0
Training loss: 2.595926313944446
Validation loss: 2.454365891610223

Epoch: 6| Step: 1
Training loss: 1.8896746808578184
Validation loss: 2.467874995234196

Epoch: 6| Step: 2
Training loss: 2.1032288478928978
Validation loss: 2.4591511097395573

Epoch: 6| Step: 3
Training loss: 2.0167598634523336
Validation loss: 2.49251432227452

Epoch: 6| Step: 4
Training loss: 2.091037188439627
Validation loss: 2.5081535278453364

Epoch: 6| Step: 5
Training loss: 2.258074260176453
Validation loss: 2.5206281666126196

Epoch: 6| Step: 6
Training loss: 2.4838006657278906
Validation loss: 2.559123410996517

Epoch: 6| Step: 7
Training loss: 1.6554814120821508
Validation loss: 2.572963161346496

Epoch: 6| Step: 8
Training loss: 1.3963693851531875
Validation loss: 2.5697312458178105

Epoch: 6| Step: 9
Training loss: 1.997477609750016
Validation loss: 2.57452953778669

Epoch: 6| Step: 10
Training loss: 2.2810897770882397
Validation loss: 2.5540739428209114

Epoch: 6| Step: 11
Training loss: 1.4070997425885101
Validation loss: 2.5637911953292285

Epoch: 6| Step: 12
Training loss: 1.8728234691861962
Validation loss: 2.5403984186441875

Epoch: 6| Step: 13
Training loss: 2.276639904834891
Validation loss: 2.523124690421012

Epoch: 298| Step: 0
Training loss: 1.864059637535948
Validation loss: 2.5287266708593212

Epoch: 6| Step: 1
Training loss: 2.015434315259611
Validation loss: 2.546791735114111

Epoch: 6| Step: 2
Training loss: 1.9874073198889843
Validation loss: 2.539029745769399

Epoch: 6| Step: 3
Training loss: 2.2752103938813617
Validation loss: 2.5388486114855087

Epoch: 6| Step: 4
Training loss: 2.065314482233265
Validation loss: 2.4993219881594433

Epoch: 6| Step: 5
Training loss: 1.6804400510301465
Validation loss: 2.455092934077344

Epoch: 6| Step: 6
Training loss: 1.5875737811387167
Validation loss: 2.4249311199286154

Epoch: 6| Step: 7
Training loss: 2.295714623716311
Validation loss: 2.426937167703437

Epoch: 6| Step: 8
Training loss: 2.2044935372271497
Validation loss: 2.4257936254585313

Epoch: 6| Step: 9
Training loss: 2.286346177903697
Validation loss: 2.436440216674575

Epoch: 6| Step: 10
Training loss: 1.6947566232964046
Validation loss: 2.4630757891886548

Epoch: 6| Step: 11
Training loss: 2.010362008361451
Validation loss: 2.486627758634691

Epoch: 6| Step: 12
Training loss: 2.399873682512603
Validation loss: 2.5034165652806153

Epoch: 6| Step: 13
Training loss: 1.6846854438691354
Validation loss: 2.513239173557729

Epoch: 299| Step: 0
Training loss: 1.9787195671088411
Validation loss: 2.516900298464433

Epoch: 6| Step: 1
Training loss: 2.3662361272777024
Validation loss: 2.5239686220641158

Epoch: 6| Step: 2
Training loss: 2.248136596480095
Validation loss: 2.5013558597524215

Epoch: 6| Step: 3
Training loss: 1.5781023382693753
Validation loss: 2.522082975442739

Epoch: 6| Step: 4
Training loss: 1.6034493101581297
Validation loss: 2.520303643256727

Epoch: 6| Step: 5
Training loss: 2.194832311494396
Validation loss: 2.523314485936185

Epoch: 6| Step: 6
Training loss: 1.4407706164331802
Validation loss: 2.5454081796936134

Epoch: 6| Step: 7
Training loss: 1.9518563995305669
Validation loss: 2.5363999631021374

Epoch: 6| Step: 8
Training loss: 1.9922605014964168
Validation loss: 2.5888506056142515

Epoch: 6| Step: 9
Training loss: 1.7887618965910255
Validation loss: 2.571283694509372

Epoch: 6| Step: 10
Training loss: 2.046830970348846
Validation loss: 2.614646657554298

Epoch: 6| Step: 11
Training loss: 2.084468710192593
Validation loss: 2.6234491467532663

Epoch: 6| Step: 12
Training loss: 2.313195304472167
Validation loss: 2.6556683950179925

Epoch: 6| Step: 13
Training loss: 1.992231839752433
Validation loss: 2.605253459617347

Epoch: 300| Step: 0
Training loss: 2.461530922685596
Validation loss: 2.583645374718992

Epoch: 6| Step: 1
Training loss: 1.8434997647406621
Validation loss: 2.578434031371542

Epoch: 6| Step: 2
Training loss: 2.301405091869118
Validation loss: 2.536993614373218

Epoch: 6| Step: 3
Training loss: 2.0994097379653573
Validation loss: 2.5052894400244714

Epoch: 6| Step: 4
Training loss: 2.504905275240412
Validation loss: 2.456015606109345

Epoch: 6| Step: 5
Training loss: 2.01946431091462
Validation loss: 2.4730595163272038

Epoch: 6| Step: 6
Training loss: 1.1151126187161744
Validation loss: 2.4711356598335743

Epoch: 6| Step: 7
Training loss: 1.6145684600473171
Validation loss: 2.4916446277240345

Epoch: 6| Step: 8
Training loss: 2.0119346724990375
Validation loss: 2.505995648819921

Epoch: 6| Step: 9
Training loss: 2.266633118586884
Validation loss: 2.5107134820273527

Epoch: 6| Step: 10
Training loss: 1.7432195232555066
Validation loss: 2.537090065087915

Epoch: 6| Step: 11
Training loss: 1.667276993899513
Validation loss: 2.5629191782344334

Epoch: 6| Step: 12
Training loss: 1.8766905474907842
Validation loss: 2.533516099772547

Epoch: 6| Step: 13
Training loss: 1.5502808193421573
Validation loss: 2.5121519735515934

Testing loss: 2.305644055727222
