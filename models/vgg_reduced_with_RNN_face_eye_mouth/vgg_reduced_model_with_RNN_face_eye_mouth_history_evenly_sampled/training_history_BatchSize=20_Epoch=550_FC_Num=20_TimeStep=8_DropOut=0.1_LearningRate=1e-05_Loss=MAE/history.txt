Epoch: 1| Step: 0
Training loss: 5.490382194519043
Validation loss: 5.117684138718472

Epoch: 5| Step: 1
Training loss: 4.626622676849365
Validation loss: 5.109020058826734

Epoch: 5| Step: 2
Training loss: 5.5279669761657715
Validation loss: 5.100734685056953

Epoch: 5| Step: 3
Training loss: 5.518921852111816
Validation loss: 5.092679633889147

Epoch: 5| Step: 4
Training loss: 4.230404376983643
Validation loss: 5.084210518867739

Epoch: 5| Step: 5
Training loss: 4.393960952758789
Validation loss: 5.075604490054551

Epoch: 5| Step: 6
Training loss: 3.8189072608947754
Validation loss: 5.066806495830577

Epoch: 5| Step: 7
Training loss: 4.712246894836426
Validation loss: 5.057308843058925

Epoch: 5| Step: 8
Training loss: 4.239495754241943
Validation loss: 5.046896688399777

Epoch: 5| Step: 9
Training loss: 5.581386566162109
Validation loss: 5.0363539931594685

Epoch: 5| Step: 10
Training loss: 5.544066905975342
Validation loss: 5.024512270445465

Epoch: 2| Step: 0
Training loss: 3.479355573654175
Validation loss: 5.012170432716288

Epoch: 5| Step: 1
Training loss: 5.016324043273926
Validation loss: 4.999259456511466

Epoch: 5| Step: 2
Training loss: 5.468512535095215
Validation loss: 4.984772374553065

Epoch: 5| Step: 3
Training loss: 4.486786842346191
Validation loss: 4.969562663826891

Epoch: 5| Step: 4
Training loss: 4.846257209777832
Validation loss: 4.952107162885769

Epoch: 5| Step: 5
Training loss: 4.908754348754883
Validation loss: 4.933812823346866

Epoch: 5| Step: 6
Training loss: 5.740992546081543
Validation loss: 4.914329913354689

Epoch: 5| Step: 7
Training loss: 5.534139633178711
Validation loss: 4.892071577810472

Epoch: 5| Step: 8
Training loss: 3.923670530319214
Validation loss: 4.868475519200807

Epoch: 5| Step: 9
Training loss: 3.2066447734832764
Validation loss: 4.84339698155721

Epoch: 5| Step: 10
Training loss: 5.382099628448486
Validation loss: 4.815108586383122

Epoch: 3| Step: 0
Training loss: 4.914985656738281
Validation loss: 4.785446438738095

Epoch: 5| Step: 1
Training loss: 3.464427947998047
Validation loss: 4.753069308496291

Epoch: 5| Step: 2
Training loss: 4.1134114265441895
Validation loss: 4.719345943902129

Epoch: 5| Step: 3
Training loss: 4.0156660079956055
Validation loss: 4.684732954989197

Epoch: 5| Step: 4
Training loss: 5.340540885925293
Validation loss: 4.645596432429488

Epoch: 5| Step: 5
Training loss: 3.826615810394287
Validation loss: 4.605978422267462

Epoch: 5| Step: 6
Training loss: 5.021391868591309
Validation loss: 4.566112728529079

Epoch: 5| Step: 7
Training loss: 3.6017532348632812
Validation loss: 4.525388184414115

Epoch: 5| Step: 8
Training loss: 5.5980353355407715
Validation loss: 4.483644649546633

Epoch: 5| Step: 9
Training loss: 4.267910480499268
Validation loss: 4.44190997974847

Epoch: 5| Step: 10
Training loss: 4.039028167724609
Validation loss: 4.399877143162553

Epoch: 4| Step: 0
Training loss: 4.154612064361572
Validation loss: 4.360298156738281

Epoch: 5| Step: 1
Training loss: 4.4947190284729
Validation loss: 4.320074460839712

Epoch: 5| Step: 2
Training loss: 4.036995887756348
Validation loss: 4.280819539100893

Epoch: 5| Step: 3
Training loss: 4.600167274475098
Validation loss: 4.244533528563797

Epoch: 5| Step: 4
Training loss: 4.193968296051025
Validation loss: 4.208969585357174

Epoch: 5| Step: 5
Training loss: 3.848560333251953
Validation loss: 4.1741475315504175

Epoch: 5| Step: 6
Training loss: 3.4699997901916504
Validation loss: 4.143043876976095

Epoch: 5| Step: 7
Training loss: 4.302690505981445
Validation loss: 4.112372190721573

Epoch: 5| Step: 8
Training loss: 4.049489498138428
Validation loss: 4.08636902224633

Epoch: 5| Step: 9
Training loss: 3.8730263710021973
Validation loss: 4.05945163132042

Epoch: 5| Step: 10
Training loss: 2.8388450145721436
Validation loss: 4.034224310228901

Epoch: 5| Step: 0
Training loss: 4.686631202697754
Validation loss: 4.01232115427653

Epoch: 5| Step: 1
Training loss: 2.8050615787506104
Validation loss: 3.9904190442895375

Epoch: 5| Step: 2
Training loss: 4.512875080108643
Validation loss: 3.9704567693894908

Epoch: 5| Step: 3
Training loss: 4.039278984069824
Validation loss: 3.951197265296854

Epoch: 5| Step: 4
Training loss: 4.35400915145874
Validation loss: 3.9327404268326296

Epoch: 5| Step: 5
Training loss: 3.803880214691162
Validation loss: 3.913781048149191

Epoch: 5| Step: 6
Training loss: 3.4639949798583984
Validation loss: 3.890901457878851

Epoch: 5| Step: 7
Training loss: 3.629742383956909
Validation loss: 3.870712205927859

Epoch: 5| Step: 8
Training loss: 2.902801036834717
Validation loss: 3.8486414724780666

Epoch: 5| Step: 9
Training loss: 3.8675639629364014
Validation loss: 3.8257662121967604

Epoch: 5| Step: 10
Training loss: 3.459859848022461
Validation loss: 3.803992502150997

Epoch: 6| Step: 0
Training loss: 4.589797019958496
Validation loss: 3.7804569890422206

Epoch: 5| Step: 1
Training loss: 4.162711143493652
Validation loss: 3.7648288870370514

Epoch: 5| Step: 2
Training loss: 3.716162919998169
Validation loss: 3.7484646740780083

Epoch: 5| Step: 3
Training loss: 3.177258014678955
Validation loss: 3.7325909265907864

Epoch: 5| Step: 4
Training loss: 3.305407762527466
Validation loss: 3.716966518791773

Epoch: 5| Step: 5
Training loss: 3.38960599899292
Validation loss: 3.7057763479089223

Epoch: 5| Step: 6
Training loss: 4.100029945373535
Validation loss: 3.6930111864561677

Epoch: 5| Step: 7
Training loss: 3.741332530975342
Validation loss: 3.676578767838017

Epoch: 5| Step: 8
Training loss: 3.0428404808044434
Validation loss: 3.659131580783475

Epoch: 5| Step: 9
Training loss: 3.532039165496826
Validation loss: 3.647003055900656

Epoch: 5| Step: 10
Training loss: 2.7786035537719727
Validation loss: 3.636759001721618

Epoch: 7| Step: 0
Training loss: 3.6884067058563232
Validation loss: 3.6319730640739523

Epoch: 5| Step: 1
Training loss: 3.4987831115722656
Validation loss: 3.6172045943557576

Epoch: 5| Step: 2
Training loss: 3.909318447113037
Validation loss: 3.6002324319654897

Epoch: 5| Step: 3
Training loss: 3.240252733230591
Validation loss: 3.5873452360912035

Epoch: 5| Step: 4
Training loss: 3.0410656929016113
Validation loss: 3.579026791357225

Epoch: 5| Step: 5
Training loss: 2.7096455097198486
Validation loss: 3.5719859907704015

Epoch: 5| Step: 6
Training loss: 3.478699207305908
Validation loss: 3.563567074396277

Epoch: 5| Step: 7
Training loss: 3.4409682750701904
Validation loss: 3.5489128507593626

Epoch: 5| Step: 8
Training loss: 3.6118862628936768
Validation loss: 3.534224151283182

Epoch: 5| Step: 9
Training loss: 4.010408878326416
Validation loss: 3.5255728537036526

Epoch: 5| Step: 10
Training loss: 3.9239273071289062
Validation loss: 3.5130767258264686

Epoch: 8| Step: 0
Training loss: 3.4486286640167236
Validation loss: 3.5021515328397035

Epoch: 5| Step: 1
Training loss: 3.3449981212615967
Validation loss: 3.490537981833181

Epoch: 5| Step: 2
Training loss: 3.551886796951294
Validation loss: 3.479138863983975

Epoch: 5| Step: 3
Training loss: 3.26763916015625
Validation loss: 3.469281073539488

Epoch: 5| Step: 4
Training loss: 3.4175662994384766
Validation loss: 3.459255859416018

Epoch: 5| Step: 5
Training loss: 4.518977165222168
Validation loss: 3.4483702131496963

Epoch: 5| Step: 6
Training loss: 3.1903345584869385
Validation loss: 3.4387206569794686

Epoch: 5| Step: 7
Training loss: 2.90716814994812
Validation loss: 3.427636656709897

Epoch: 5| Step: 8
Training loss: 3.4284491539001465
Validation loss: 3.420074942291424

Epoch: 5| Step: 9
Training loss: 2.8257381916046143
Validation loss: 3.409894435636459

Epoch: 5| Step: 10
Training loss: 3.396272659301758
Validation loss: 3.401901839881815

Epoch: 9| Step: 0
Training loss: 3.806551694869995
Validation loss: 3.390139497736449

Epoch: 5| Step: 1
Training loss: 3.500725269317627
Validation loss: 3.379247498768632

Epoch: 5| Step: 2
Training loss: 2.8297040462493896
Validation loss: 3.376271252991051

Epoch: 5| Step: 3
Training loss: 3.2553069591522217
Validation loss: 3.3655710245973323

Epoch: 5| Step: 4
Training loss: 3.2389931678771973
Validation loss: 3.350123174728886

Epoch: 5| Step: 5
Training loss: 3.2336647510528564
Validation loss: 3.337757279795985

Epoch: 5| Step: 6
Training loss: 3.8375606536865234
Validation loss: 3.3267951037294123

Epoch: 5| Step: 7
Training loss: 3.0700366497039795
Validation loss: 3.3113529964159896

Epoch: 5| Step: 8
Training loss: 3.6509900093078613
Validation loss: 3.3040470282236734

Epoch: 5| Step: 9
Training loss: 2.772178888320923
Validation loss: 3.295077205986105

Epoch: 5| Step: 10
Training loss: 3.147087574005127
Validation loss: 3.2875349649818997

Epoch: 10| Step: 0
Training loss: 2.998713493347168
Validation loss: 3.281456919126613

Epoch: 5| Step: 1
Training loss: 3.4179186820983887
Validation loss: 3.270796339998963

Epoch: 5| Step: 2
Training loss: 3.175755262374878
Validation loss: 3.270408953389814

Epoch: 5| Step: 3
Training loss: 3.3879265785217285
Validation loss: 3.260961348010648

Epoch: 5| Step: 4
Training loss: 3.6233437061309814
Validation loss: 3.250727240757276

Epoch: 5| Step: 5
Training loss: 3.8290939331054688
Validation loss: 3.2439219054355415

Epoch: 5| Step: 6
Training loss: 3.1007332801818848
Validation loss: 3.240064485098726

Epoch: 5| Step: 7
Training loss: 3.4858040809631348
Validation loss: 3.2316813417660293

Epoch: 5| Step: 8
Training loss: 2.38085675239563
Validation loss: 3.222516844349523

Epoch: 5| Step: 9
Training loss: 3.150919198989868
Validation loss: 3.2205109468070408

Epoch: 5| Step: 10
Training loss: 2.9257235527038574
Validation loss: 3.2151152036523305

Epoch: 11| Step: 0
Training loss: 3.8453707695007324
Validation loss: 3.2091494862751295

Epoch: 5| Step: 1
Training loss: 3.8949859142303467
Validation loss: 3.2003747032534693

Epoch: 5| Step: 2
Training loss: 2.6684043407440186
Validation loss: 3.191536652144565

Epoch: 5| Step: 3
Training loss: 2.985898494720459
Validation loss: 3.186805917370704

Epoch: 5| Step: 4
Training loss: 3.2117648124694824
Validation loss: 3.18091574791939

Epoch: 5| Step: 5
Training loss: 3.32989501953125
Validation loss: 3.1773674026612313

Epoch: 5| Step: 6
Training loss: 3.0284359455108643
Validation loss: 3.1742273197379163

Epoch: 5| Step: 7
Training loss: 3.6756491661071777
Validation loss: 3.169562021891276

Epoch: 5| Step: 8
Training loss: 2.9354240894317627
Validation loss: 3.158220370610555

Epoch: 5| Step: 9
Training loss: 2.1694083213806152
Validation loss: 3.152992028062062

Epoch: 5| Step: 10
Training loss: 3.266418695449829
Validation loss: 3.147754748662313

Epoch: 12| Step: 0
Training loss: 2.513267993927002
Validation loss: 3.146407063289355

Epoch: 5| Step: 1
Training loss: 3.0573787689208984
Validation loss: 3.147189417193013

Epoch: 5| Step: 2
Training loss: 3.7773079872131348
Validation loss: 3.141432282745197

Epoch: 5| Step: 3
Training loss: 3.6685497760772705
Validation loss: 3.1344550450642905

Epoch: 5| Step: 4
Training loss: 2.7651615142822266
Validation loss: 3.128854202967818

Epoch: 5| Step: 5
Training loss: 2.925015687942505
Validation loss: 3.126527124835599

Epoch: 5| Step: 6
Training loss: 2.708425283432007
Validation loss: 3.1163186770613476

Epoch: 5| Step: 7
Training loss: 3.9646270275115967
Validation loss: 3.1128521785941174

Epoch: 5| Step: 8
Training loss: 2.464691162109375
Validation loss: 3.112012368376537

Epoch: 5| Step: 9
Training loss: 3.249610185623169
Validation loss: 3.1044186879229803

Epoch: 5| Step: 10
Training loss: 3.5576095581054688
Validation loss: 3.1032573920424267

Epoch: 13| Step: 0
Training loss: 2.667907238006592
Validation loss: 3.095962042449623

Epoch: 5| Step: 1
Training loss: 2.6896462440490723
Validation loss: 3.0918716666519

Epoch: 5| Step: 2
Training loss: 2.617302894592285
Validation loss: 3.0866137627632386

Epoch: 5| Step: 3
Training loss: 3.7160282135009766
Validation loss: 3.0836249295101372

Epoch: 5| Step: 4
Training loss: 3.8909053802490234
Validation loss: 3.0791023700468

Epoch: 5| Step: 5
Training loss: 3.4219393730163574
Validation loss: 3.077562132189351

Epoch: 5| Step: 6
Training loss: 2.5843162536621094
Validation loss: 3.073698789842667

Epoch: 5| Step: 7
Training loss: 3.831185817718506
Validation loss: 3.0694495067801526

Epoch: 5| Step: 8
Training loss: 2.733354091644287
Validation loss: 3.064217452080019

Epoch: 5| Step: 9
Training loss: 2.2571511268615723
Validation loss: 3.0616414393148115

Epoch: 5| Step: 10
Training loss: 3.9628071784973145
Validation loss: 3.0613767536737586

Epoch: 14| Step: 0
Training loss: 3.9740052223205566
Validation loss: 3.0539568752370854

Epoch: 5| Step: 1
Training loss: 3.034269332885742
Validation loss: 3.0550680980887464

Epoch: 5| Step: 2
Training loss: 2.8048198223114014
Validation loss: 3.054728490050121

Epoch: 5| Step: 3
Training loss: 3.4788970947265625
Validation loss: 3.05375833665171

Epoch: 5| Step: 4
Training loss: 3.245241641998291
Validation loss: 3.043169134406633

Epoch: 5| Step: 5
Training loss: 2.3180806636810303
Validation loss: 3.0439808266137236

Epoch: 5| Step: 6
Training loss: 3.60121488571167
Validation loss: 3.044956704621674

Epoch: 5| Step: 7
Training loss: 3.3958256244659424
Validation loss: 3.0351232790177867

Epoch: 5| Step: 8
Training loss: 3.148038387298584
Validation loss: 3.0331285486939135

Epoch: 5| Step: 9
Training loss: 2.630425214767456
Validation loss: 3.0299505469619588

Epoch: 5| Step: 10
Training loss: 2.2977757453918457
Validation loss: 3.030393954246275

Epoch: 15| Step: 0
Training loss: 3.305614471435547
Validation loss: 3.0304431120554605

Epoch: 5| Step: 1
Training loss: 3.1205646991729736
Validation loss: 3.0313069948586087

Epoch: 5| Step: 2
Training loss: 2.5500149726867676
Validation loss: 3.0259522314994567

Epoch: 5| Step: 3
Training loss: 2.4622726440429688
Validation loss: 3.0245920547875027

Epoch: 5| Step: 4
Training loss: 3.1244583129882812
Validation loss: 3.023680871532809

Epoch: 5| Step: 5
Training loss: 3.0431079864501953
Validation loss: 3.0168169634316557

Epoch: 5| Step: 6
Training loss: 2.5740537643432617
Validation loss: 3.007317009792533

Epoch: 5| Step: 7
Training loss: 3.841844081878662
Validation loss: 3.00785130839194

Epoch: 5| Step: 8
Training loss: 3.1779568195343018
Validation loss: 3.0070685801967496

Epoch: 5| Step: 9
Training loss: 3.2538223266601562
Validation loss: 3.004687488719981

Epoch: 5| Step: 10
Training loss: 3.4142470359802246
Validation loss: 2.998295609669019

Epoch: 16| Step: 0
Training loss: 2.905698776245117
Validation loss: 2.991894652766566

Epoch: 5| Step: 1
Training loss: 3.0765883922576904
Validation loss: 2.9859854149562057

Epoch: 5| Step: 2
Training loss: 2.8102970123291016
Validation loss: 2.9827466651957524

Epoch: 5| Step: 3
Training loss: 3.1681811809539795
Validation loss: 2.9825079748707433

Epoch: 5| Step: 4
Training loss: 2.6744744777679443
Validation loss: 2.98226882309042

Epoch: 5| Step: 5
Training loss: 3.369743824005127
Validation loss: 2.9860115922907347

Epoch: 5| Step: 6
Training loss: 3.2507166862487793
Validation loss: 2.9737627326801257

Epoch: 5| Step: 7
Training loss: 2.6813111305236816
Validation loss: 2.9700999567585606

Epoch: 5| Step: 8
Training loss: 2.912442684173584
Validation loss: 2.96522000528151

Epoch: 5| Step: 9
Training loss: 3.351612091064453
Validation loss: 2.9611231729548466

Epoch: 5| Step: 10
Training loss: 3.3693172931671143
Validation loss: 2.962696365130845

Epoch: 17| Step: 0
Training loss: 3.4094796180725098
Validation loss: 2.957364877065023

Epoch: 5| Step: 1
Training loss: 3.147345781326294
Validation loss: 2.958669218965756

Epoch: 5| Step: 2
Training loss: 2.615567445755005
Validation loss: 2.9534944334337787

Epoch: 5| Step: 3
Training loss: 3.196341037750244
Validation loss: 2.9520999744374263

Epoch: 5| Step: 4
Training loss: 2.470585346221924
Validation loss: 2.949095556812902

Epoch: 5| Step: 5
Training loss: 2.642878293991089
Validation loss: 2.948496392978135

Epoch: 5| Step: 6
Training loss: 3.9961490631103516
Validation loss: 2.9448190273777133

Epoch: 5| Step: 7
Training loss: 2.662436008453369
Validation loss: 2.94267023763349

Epoch: 5| Step: 8
Training loss: 3.134680986404419
Validation loss: 2.93945820869938

Epoch: 5| Step: 9
Training loss: 2.9381585121154785
Validation loss: 2.9388493030301985

Epoch: 5| Step: 10
Training loss: 3.099727153778076
Validation loss: 2.936216277460898

Epoch: 18| Step: 0
Training loss: 3.413403272628784
Validation loss: 2.934975657411801

Epoch: 5| Step: 1
Training loss: 2.272250175476074
Validation loss: 2.9303102954741447

Epoch: 5| Step: 2
Training loss: 2.093087673187256
Validation loss: 2.929907747494277

Epoch: 5| Step: 3
Training loss: 3.7196991443634033
Validation loss: 2.9288908409815964

Epoch: 5| Step: 4
Training loss: 3.204169750213623
Validation loss: 2.924517047020697

Epoch: 5| Step: 5
Training loss: 2.6996006965637207
Validation loss: 2.9232257437962357

Epoch: 5| Step: 6
Training loss: 3.644202470779419
Validation loss: 2.918717840666412

Epoch: 5| Step: 7
Training loss: 2.572329044342041
Validation loss: 2.914815018253942

Epoch: 5| Step: 8
Training loss: 2.8141493797302246
Validation loss: 2.9128439939150246

Epoch: 5| Step: 9
Training loss: 3.681588649749756
Validation loss: 2.9102795406054427

Epoch: 5| Step: 10
Training loss: 3.0081169605255127
Validation loss: 2.907484241711196

Epoch: 19| Step: 0
Training loss: 3.1345534324645996
Validation loss: 2.906623404513123

Epoch: 5| Step: 1
Training loss: 2.8366382122039795
Validation loss: 2.9060296115054878

Epoch: 5| Step: 2
Training loss: 2.902083158493042
Validation loss: 2.9031467130107265

Epoch: 5| Step: 3
Training loss: 3.000793933868408
Validation loss: 2.9000485763754895

Epoch: 5| Step: 4
Training loss: 3.456941604614258
Validation loss: 2.898157327405868

Epoch: 5| Step: 5
Training loss: 2.598005533218384
Validation loss: 2.8976939544882825

Epoch: 5| Step: 6
Training loss: 2.977165699005127
Validation loss: 2.893024108743155

Epoch: 5| Step: 7
Training loss: 2.360093593597412
Validation loss: 2.898469340416693

Epoch: 5| Step: 8
Training loss: 2.6899962425231934
Validation loss: 2.894174711678618

Epoch: 5| Step: 9
Training loss: 3.125229597091675
Validation loss: 2.893274889197401

Epoch: 5| Step: 10
Training loss: 4.025013446807861
Validation loss: 2.8917256196339927

Epoch: 20| Step: 0
Training loss: 3.180205821990967
Validation loss: 2.8859733176487747

Epoch: 5| Step: 1
Training loss: 3.1498312950134277
Validation loss: 2.885330407850204

Epoch: 5| Step: 2
Training loss: 3.517439603805542
Validation loss: 2.8837532304948374

Epoch: 5| Step: 3
Training loss: 3.02125883102417
Validation loss: 2.8848141367717455

Epoch: 5| Step: 4
Training loss: 2.6581950187683105
Validation loss: 2.8812761870763635

Epoch: 5| Step: 5
Training loss: 3.030075788497925
Validation loss: 2.879438687396306

Epoch: 5| Step: 6
Training loss: 3.002811908721924
Validation loss: 2.874976970816171

Epoch: 5| Step: 7
Training loss: 3.0659334659576416
Validation loss: 2.873992504612092

Epoch: 5| Step: 8
Training loss: 2.3842856884002686
Validation loss: 2.8726971867263957

Epoch: 5| Step: 9
Training loss: 3.06278133392334
Validation loss: 2.8744941962662565

Epoch: 5| Step: 10
Training loss: 2.6967992782592773
Validation loss: 2.873912083205356

Epoch: 21| Step: 0
Training loss: 2.8232293128967285
Validation loss: 2.871144494702739

Epoch: 5| Step: 1
Training loss: 3.0661652088165283
Validation loss: 2.8643616143093316

Epoch: 5| Step: 2
Training loss: 3.8409335613250732
Validation loss: 2.860220060553602

Epoch: 5| Step: 3
Training loss: 2.3898894786834717
Validation loss: 2.85870450030091

Epoch: 5| Step: 4
Training loss: 2.970324754714966
Validation loss: 2.8548436036673923

Epoch: 5| Step: 5
Training loss: 2.5667777061462402
Validation loss: 2.8541691867254113

Epoch: 5| Step: 6
Training loss: 2.6143109798431396
Validation loss: 2.851209940448884

Epoch: 5| Step: 7
Training loss: 3.70227313041687
Validation loss: 2.850225866481822

Epoch: 5| Step: 8
Training loss: 2.333106279373169
Validation loss: 2.8455108288795716

Epoch: 5| Step: 9
Training loss: 3.0186996459960938
Validation loss: 2.8435112276384906

Epoch: 5| Step: 10
Training loss: 3.3781702518463135
Validation loss: 2.844704061426142

Epoch: 22| Step: 0
Training loss: 3.1452784538269043
Validation loss: 2.843090977720035

Epoch: 5| Step: 1
Training loss: 3.2652525901794434
Validation loss: 2.8423716355395574

Epoch: 5| Step: 2
Training loss: 3.8707504272460938
Validation loss: 2.841388525501374

Epoch: 5| Step: 3
Training loss: 3.584308624267578
Validation loss: 2.842650205858292

Epoch: 5| Step: 4
Training loss: 2.7547895908355713
Validation loss: 2.830028533935547

Epoch: 5| Step: 5
Training loss: 2.374634265899658
Validation loss: 2.8302154130833124

Epoch: 5| Step: 6
Training loss: 2.839228630065918
Validation loss: 2.8291987039709605

Epoch: 5| Step: 7
Training loss: 3.0449814796447754
Validation loss: 2.825655319357431

Epoch: 5| Step: 8
Training loss: 2.374866008758545
Validation loss: 2.8237452507019043

Epoch: 5| Step: 9
Training loss: 2.0963127613067627
Validation loss: 2.8272360960642495

Epoch: 5| Step: 10
Training loss: 3.205421209335327
Validation loss: 2.8268960291339504

Epoch: 23| Step: 0
Training loss: 2.751024007797241
Validation loss: 2.8249368770148164

Epoch: 5| Step: 1
Training loss: 2.5822272300720215
Validation loss: 2.8255488052163074

Epoch: 5| Step: 2
Training loss: 3.1904284954071045
Validation loss: 2.8236865048767417

Epoch: 5| Step: 3
Training loss: 2.673819065093994
Validation loss: 2.818696037415535

Epoch: 5| Step: 4
Training loss: 3.6924514770507812
Validation loss: 2.8202310787734164

Epoch: 5| Step: 5
Training loss: 3.5280563831329346
Validation loss: 2.8235299382158505

Epoch: 5| Step: 6
Training loss: 3.04622220993042
Validation loss: 2.8275540413395053

Epoch: 5| Step: 7
Training loss: 2.492448329925537
Validation loss: 2.8217938202683643

Epoch: 5| Step: 8
Training loss: 3.0812034606933594
Validation loss: 2.8199954186716387

Epoch: 5| Step: 9
Training loss: 2.736147165298462
Validation loss: 2.8116332946285123

Epoch: 5| Step: 10
Training loss: 2.570317029953003
Validation loss: 2.800776325246339

Epoch: 24| Step: 0
Training loss: 2.280306339263916
Validation loss: 2.816353310820877

Epoch: 5| Step: 1
Training loss: 2.9207260608673096
Validation loss: 2.8955232404893443

Epoch: 5| Step: 2
Training loss: 3.2601819038391113
Validation loss: 2.9221120829223306

Epoch: 5| Step: 3
Training loss: 2.996267080307007
Validation loss: 2.9095006911985335

Epoch: 5| Step: 4
Training loss: 2.452644109725952
Validation loss: 2.889854541388891

Epoch: 5| Step: 5
Training loss: 3.415027141571045
Validation loss: 2.8783760737347346

Epoch: 5| Step: 6
Training loss: 2.3772213459014893
Validation loss: 2.834768687525103

Epoch: 5| Step: 7
Training loss: 2.9736409187316895
Validation loss: 2.8026651900301696

Epoch: 5| Step: 8
Training loss: 3.36444091796875
Validation loss: 2.812713271828108

Epoch: 5| Step: 9
Training loss: 3.3484549522399902
Validation loss: 2.8563247137172247

Epoch: 5| Step: 10
Training loss: 3.3876612186431885
Validation loss: 2.858791143663468

Epoch: 25| Step: 0
Training loss: 4.0079803466796875
Validation loss: 2.839281705117995

Epoch: 5| Step: 1
Training loss: 2.9773025512695312
Validation loss: 2.815855392845728

Epoch: 5| Step: 2
Training loss: 2.0762407779693604
Validation loss: 2.8076050153342624

Epoch: 5| Step: 3
Training loss: 2.3788585662841797
Validation loss: 2.7910452119765745

Epoch: 5| Step: 4
Training loss: 3.098177433013916
Validation loss: 2.7896441951874764

Epoch: 5| Step: 5
Training loss: 3.6109561920166016
Validation loss: 2.79648934384828

Epoch: 5| Step: 6
Training loss: 2.7860074043273926
Validation loss: 2.8004472794071322

Epoch: 5| Step: 7
Training loss: 3.1037826538085938
Validation loss: 2.801220283713392

Epoch: 5| Step: 8
Training loss: 2.6963088512420654
Validation loss: 2.79751334651824

Epoch: 5| Step: 9
Training loss: 2.8666937351226807
Validation loss: 2.7884140168466875

Epoch: 5| Step: 10
Training loss: 2.565511465072632
Validation loss: 2.7804811000823975

Epoch: 26| Step: 0
Training loss: 2.7326056957244873
Validation loss: 2.7758721356750815

Epoch: 5| Step: 1
Training loss: 2.862947463989258
Validation loss: 2.7716642759179555

Epoch: 5| Step: 2
Training loss: 2.79378604888916
Validation loss: 2.771033061447964

Epoch: 5| Step: 3
Training loss: 3.2195916175842285
Validation loss: 2.775618355761292

Epoch: 5| Step: 4
Training loss: 2.691263198852539
Validation loss: 2.7719409235062136

Epoch: 5| Step: 5
Training loss: 2.325765609741211
Validation loss: 2.7670928842277935

Epoch: 5| Step: 6
Training loss: 3.0618584156036377
Validation loss: 2.7713628148519867

Epoch: 5| Step: 7
Training loss: 3.3651375770568848
Validation loss: 2.759329413854948

Epoch: 5| Step: 8
Training loss: 3.055729627609253
Validation loss: 2.759176456800071

Epoch: 5| Step: 9
Training loss: 2.6088268756866455
Validation loss: 2.7768149529733965

Epoch: 5| Step: 10
Training loss: 3.35308837890625
Validation loss: 2.777221110559279

Epoch: 27| Step: 0
Training loss: 3.248509168624878
Validation loss: 2.7439983506356516

Epoch: 5| Step: 1
Training loss: 3.4786629676818848
Validation loss: 2.746013105556529

Epoch: 5| Step: 2
Training loss: 3.515411853790283
Validation loss: 2.74808249678663

Epoch: 5| Step: 3
Training loss: 2.2888436317443848
Validation loss: 2.7551894341745684

Epoch: 5| Step: 4
Training loss: 3.3026232719421387
Validation loss: 2.7531079784516366

Epoch: 5| Step: 5
Training loss: 3.079028606414795
Validation loss: 2.767479973454629

Epoch: 5| Step: 6
Training loss: 2.5994255542755127
Validation loss: 2.807882960124682

Epoch: 5| Step: 7
Training loss: 2.647904634475708
Validation loss: 2.7552820764562136

Epoch: 5| Step: 8
Training loss: 2.2008187770843506
Validation loss: 2.7422469508263374

Epoch: 5| Step: 9
Training loss: 2.483034610748291
Validation loss: 2.7384621199741157

Epoch: 5| Step: 10
Training loss: 3.1032254695892334
Validation loss: 2.7395321297389206

Epoch: 28| Step: 0
Training loss: 2.5333080291748047
Validation loss: 2.7413884747412895

Epoch: 5| Step: 1
Training loss: 2.871488094329834
Validation loss: 2.7495184867612776

Epoch: 5| Step: 2
Training loss: 3.1507625579833984
Validation loss: 2.753430346006988

Epoch: 5| Step: 3
Training loss: 3.312986373901367
Validation loss: 2.7505974974683536

Epoch: 5| Step: 4
Training loss: 3.350140333175659
Validation loss: 2.744349677075622

Epoch: 5| Step: 5
Training loss: 2.9968953132629395
Validation loss: 2.735489078747329

Epoch: 5| Step: 6
Training loss: 2.377872943878174
Validation loss: 2.7291523128427486

Epoch: 5| Step: 7
Training loss: 2.5573372840881348
Validation loss: 2.7268958578827562

Epoch: 5| Step: 8
Training loss: 3.529393434524536
Validation loss: 2.7198020899167625

Epoch: 5| Step: 9
Training loss: 2.422006130218506
Validation loss: 2.7202462304023003

Epoch: 5| Step: 10
Training loss: 2.6580638885498047
Validation loss: 2.718320864503102

Epoch: 29| Step: 0
Training loss: 2.0834619998931885
Validation loss: 2.717380290390343

Epoch: 5| Step: 1
Training loss: 2.9009034633636475
Validation loss: 2.7191835782861196

Epoch: 5| Step: 2
Training loss: 2.5558271408081055
Validation loss: 2.7141655363062376

Epoch: 5| Step: 3
Training loss: 2.89428973197937
Validation loss: 2.71194169598241

Epoch: 5| Step: 4
Training loss: 3.189126968383789
Validation loss: 2.711128586082048

Epoch: 5| Step: 5
Training loss: 3.049424648284912
Validation loss: 2.7076063745765278

Epoch: 5| Step: 6
Training loss: 2.8558990955352783
Validation loss: 2.718043916968889

Epoch: 5| Step: 7
Training loss: 3.130002498626709
Validation loss: 2.705598387666928

Epoch: 5| Step: 8
Training loss: 3.364652156829834
Validation loss: 2.7037894777072373

Epoch: 5| Step: 9
Training loss: 2.450566530227661
Validation loss: 2.703889810910789

Epoch: 5| Step: 10
Training loss: 3.1260762214660645
Validation loss: 2.700645859523486

Epoch: 30| Step: 0
Training loss: 2.5444958209991455
Validation loss: 2.700245875184254

Epoch: 5| Step: 1
Training loss: 3.5833821296691895
Validation loss: 2.6967890852241108

Epoch: 5| Step: 2
Training loss: 2.8028616905212402
Validation loss: 2.6960327856002317

Epoch: 5| Step: 3
Training loss: 2.8920037746429443
Validation loss: 2.693936522288989

Epoch: 5| Step: 4
Training loss: 3.376417875289917
Validation loss: 2.6926871756071686

Epoch: 5| Step: 5
Training loss: 2.352374792098999
Validation loss: 2.690947009671119

Epoch: 5| Step: 6
Training loss: 2.5746586322784424
Validation loss: 2.6921944643861506

Epoch: 5| Step: 7
Training loss: 2.2711434364318848
Validation loss: 2.690234820048014

Epoch: 5| Step: 8
Training loss: 2.5217387676239014
Validation loss: 2.6894826248127925

Epoch: 5| Step: 9
Training loss: 3.3126220703125
Validation loss: 2.6924335264390513

Epoch: 5| Step: 10
Training loss: 3.311201572418213
Validation loss: 2.6920367338324107

Epoch: 31| Step: 0
Training loss: 2.4932568073272705
Validation loss: 2.692874377773654

Epoch: 5| Step: 1
Training loss: 2.8963711261749268
Validation loss: 2.689378651239539

Epoch: 5| Step: 2
Training loss: 3.8122477531433105
Validation loss: 2.6857205513984925

Epoch: 5| Step: 3
Training loss: 2.569276809692383
Validation loss: 2.683081849928825

Epoch: 5| Step: 4
Training loss: 2.8623528480529785
Validation loss: 2.683025519053141

Epoch: 5| Step: 5
Training loss: 3.1059746742248535
Validation loss: 2.6791069687053723

Epoch: 5| Step: 6
Training loss: 1.976419448852539
Validation loss: 2.678379830493722

Epoch: 5| Step: 7
Training loss: 2.836498975753784
Validation loss: 2.6815087256893033

Epoch: 5| Step: 8
Training loss: 3.6631016731262207
Validation loss: 2.681368863710793

Epoch: 5| Step: 9
Training loss: 2.484103202819824
Validation loss: 2.683972409976426

Epoch: 5| Step: 10
Training loss: 2.655839443206787
Validation loss: 2.6816314728029313

Epoch: 32| Step: 0
Training loss: 2.496321439743042
Validation loss: 2.678819076989287

Epoch: 5| Step: 1
Training loss: 2.984285831451416
Validation loss: 2.6735878349632345

Epoch: 5| Step: 2
Training loss: 3.3673839569091797
Validation loss: 2.6809578070076565

Epoch: 5| Step: 3
Training loss: 2.5728542804718018
Validation loss: 2.678748599944576

Epoch: 5| Step: 4
Training loss: 3.4581844806671143
Validation loss: 2.6738921955067623

Epoch: 5| Step: 5
Training loss: 2.416985034942627
Validation loss: 2.674190036712154

Epoch: 5| Step: 6
Training loss: 1.9051332473754883
Validation loss: 2.670667661133633

Epoch: 5| Step: 7
Training loss: 2.604851245880127
Validation loss: 2.6741823047719975

Epoch: 5| Step: 8
Training loss: 3.8114724159240723
Validation loss: 2.6706328853484123

Epoch: 5| Step: 9
Training loss: 2.765139579772949
Validation loss: 2.6706451651870564

Epoch: 5| Step: 10
Training loss: 2.9476003646850586
Validation loss: 2.677274032305646

Epoch: 33| Step: 0
Training loss: 2.814641237258911
Validation loss: 2.6756255011404715

Epoch: 5| Step: 1
Training loss: 2.8940799236297607
Validation loss: 2.67135513213373

Epoch: 5| Step: 2
Training loss: 2.047943592071533
Validation loss: 2.671673754210113

Epoch: 5| Step: 3
Training loss: 2.3960177898406982
Validation loss: 2.6671686582667853

Epoch: 5| Step: 4
Training loss: 2.734241485595703
Validation loss: 2.6661848688638337

Epoch: 5| Step: 5
Training loss: 2.7624831199645996
Validation loss: 2.6621813979200137

Epoch: 5| Step: 6
Training loss: 3.583414077758789
Validation loss: 2.6625230286711004

Epoch: 5| Step: 7
Training loss: 2.628710985183716
Validation loss: 2.6609812808293167

Epoch: 5| Step: 8
Training loss: 3.304119825363159
Validation loss: 2.661566852241434

Epoch: 5| Step: 9
Training loss: 2.5957860946655273
Validation loss: 2.6665796464489353

Epoch: 5| Step: 10
Training loss: 3.608473777770996
Validation loss: 2.664320743212136

Epoch: 34| Step: 0
Training loss: 2.8310065269470215
Validation loss: 2.6568566983745945

Epoch: 5| Step: 1
Training loss: 3.2885589599609375
Validation loss: 2.6563102301730903

Epoch: 5| Step: 2
Training loss: 2.4626262187957764
Validation loss: 2.654939397688835

Epoch: 5| Step: 3
Training loss: 3.6253883838653564
Validation loss: 2.6580781449553785

Epoch: 5| Step: 4
Training loss: 2.3731696605682373
Validation loss: 2.6584872302188667

Epoch: 5| Step: 5
Training loss: 2.815434694290161
Validation loss: 2.6571234169826714

Epoch: 5| Step: 6
Training loss: 3.0446059703826904
Validation loss: 2.653378212323753

Epoch: 5| Step: 7
Training loss: 2.7567334175109863
Validation loss: 2.6577160794247865

Epoch: 5| Step: 8
Training loss: 2.317281484603882
Validation loss: 2.6540821649694957

Epoch: 5| Step: 9
Training loss: 2.7696454524993896
Validation loss: 2.6515582428183606

Epoch: 5| Step: 10
Training loss: 2.913496971130371
Validation loss: 2.6522076642641457

Epoch: 35| Step: 0
Training loss: 2.5437886714935303
Validation loss: 2.6485844094266175

Epoch: 5| Step: 1
Training loss: 2.579008102416992
Validation loss: 2.649583726800898

Epoch: 5| Step: 2
Training loss: 3.275592088699341
Validation loss: 2.6500680677352415

Epoch: 5| Step: 3
Training loss: 2.3861732482910156
Validation loss: 2.6474000330894225

Epoch: 5| Step: 4
Training loss: 3.24157452583313
Validation loss: 2.6509214062844553

Epoch: 5| Step: 5
Training loss: 2.789760112762451
Validation loss: 2.6548148150085122

Epoch: 5| Step: 6
Training loss: 3.213606595993042
Validation loss: 2.65775304712275

Epoch: 5| Step: 7
Training loss: 2.949510097503662
Validation loss: 2.6513468373206353

Epoch: 5| Step: 8
Training loss: 2.9346091747283936
Validation loss: 2.6524481337557555

Epoch: 5| Step: 9
Training loss: 2.4724597930908203
Validation loss: 2.647192201306743

Epoch: 5| Step: 10
Training loss: 2.7279796600341797
Validation loss: 2.6440261358855874

Epoch: 36| Step: 0
Training loss: 3.5380706787109375
Validation loss: 2.643629176642305

Epoch: 5| Step: 1
Training loss: 1.958176851272583
Validation loss: 2.6428697391222884

Epoch: 5| Step: 2
Training loss: 2.2438321113586426
Validation loss: 2.6422614538541405

Epoch: 5| Step: 3
Training loss: 3.370434284210205
Validation loss: 2.6452479054850917

Epoch: 5| Step: 4
Training loss: 2.6575465202331543
Validation loss: 2.6433334530040784

Epoch: 5| Step: 5
Training loss: 2.3531901836395264
Validation loss: 2.6407877681075886

Epoch: 5| Step: 6
Training loss: 3.048279285430908
Validation loss: 2.638608160839286

Epoch: 5| Step: 7
Training loss: 3.120612621307373
Validation loss: 2.6358392802617883

Epoch: 5| Step: 8
Training loss: 3.217938184738159
Validation loss: 2.6352651990869993

Epoch: 5| Step: 9
Training loss: 2.7923903465270996
Validation loss: 2.6330119820051294

Epoch: 5| Step: 10
Training loss: 2.7269182205200195
Validation loss: 2.6318022999712216

Epoch: 37| Step: 0
Training loss: 2.5979740619659424
Validation loss: 2.6347766896729827

Epoch: 5| Step: 1
Training loss: 2.707953691482544
Validation loss: 2.6348020543334303

Epoch: 5| Step: 2
Training loss: 3.1427595615386963
Validation loss: 2.6346401040272047

Epoch: 5| Step: 3
Training loss: 3.4437572956085205
Validation loss: 2.629039482403827

Epoch: 5| Step: 4
Training loss: 2.726024627685547
Validation loss: 2.6309946736981793

Epoch: 5| Step: 5
Training loss: 2.5902414321899414
Validation loss: 2.628006548009893

Epoch: 5| Step: 6
Training loss: 2.615090847015381
Validation loss: 2.629158414820189

Epoch: 5| Step: 7
Training loss: 2.420024871826172
Validation loss: 2.6262583399331696

Epoch: 5| Step: 8
Training loss: 3.1869356632232666
Validation loss: 2.622854114860617

Epoch: 5| Step: 9
Training loss: 2.896223306655884
Validation loss: 2.6264128261996853

Epoch: 5| Step: 10
Training loss: 2.5439229011535645
Validation loss: 2.621754715519567

Epoch: 38| Step: 0
Training loss: 2.5661697387695312
Validation loss: 2.624791614470943

Epoch: 5| Step: 1
Training loss: 2.951465129852295
Validation loss: 2.622871063088858

Epoch: 5| Step: 2
Training loss: 2.815443515777588
Validation loss: 2.6203237502805647

Epoch: 5| Step: 3
Training loss: 2.4965336322784424
Validation loss: 2.6253916166161977

Epoch: 5| Step: 4
Training loss: 3.65061616897583
Validation loss: 2.61658545847862

Epoch: 5| Step: 5
Training loss: 3.074249744415283
Validation loss: 2.616291276870235

Epoch: 5| Step: 6
Training loss: 2.8085696697235107
Validation loss: 2.618581433450022

Epoch: 5| Step: 7
Training loss: 3.058675765991211
Validation loss: 2.617677770635133

Epoch: 5| Step: 8
Training loss: 2.751976490020752
Validation loss: 2.623031029137232

Epoch: 5| Step: 9
Training loss: 1.9414691925048828
Validation loss: 2.6175758454107467

Epoch: 5| Step: 10
Training loss: 2.6935393810272217
Validation loss: 2.61188760624137

Epoch: 39| Step: 0
Training loss: 2.480165958404541
Validation loss: 2.6186951437304096

Epoch: 5| Step: 1
Training loss: 2.6298129558563232
Validation loss: 2.6175820724938506

Epoch: 5| Step: 2
Training loss: 2.24220609664917
Validation loss: 2.6167398755268385

Epoch: 5| Step: 3
Training loss: 3.4177184104919434
Validation loss: 2.6186491597083306

Epoch: 5| Step: 4
Training loss: 2.88252592086792
Validation loss: 2.610479611222462

Epoch: 5| Step: 5
Training loss: 2.4778668880462646
Validation loss: 2.610521303710117

Epoch: 5| Step: 6
Training loss: 3.3752822875976562
Validation loss: 2.6102993513948176

Epoch: 5| Step: 7
Training loss: 3.2920711040496826
Validation loss: 2.6108175657128774

Epoch: 5| Step: 8
Training loss: 2.8276126384735107
Validation loss: 2.6075532103097565

Epoch: 5| Step: 9
Training loss: 1.9686574935913086
Validation loss: 2.6030289306435535

Epoch: 5| Step: 10
Training loss: 3.201267957687378
Validation loss: 2.6113101487518637

Epoch: 40| Step: 0
Training loss: 3.4173972606658936
Validation loss: 2.6093047049737748

Epoch: 5| Step: 1
Training loss: 2.7430648803710938
Validation loss: 2.6082072181086384

Epoch: 5| Step: 2
Training loss: 2.782503366470337
Validation loss: 2.6019646198518815

Epoch: 5| Step: 3
Training loss: 3.0422158241271973
Validation loss: 2.597688087853052

Epoch: 5| Step: 4
Training loss: 2.404059410095215
Validation loss: 2.5955790960660545

Epoch: 5| Step: 5
Training loss: 2.630872964859009
Validation loss: 2.5965039550617175

Epoch: 5| Step: 6
Training loss: 2.5517399311065674
Validation loss: 2.5990667881504184

Epoch: 5| Step: 7
Training loss: 2.719388961791992
Validation loss: 2.6062344069121988

Epoch: 5| Step: 8
Training loss: 2.646836996078491
Validation loss: 2.60870724339639

Epoch: 5| Step: 9
Training loss: 3.1329081058502197
Validation loss: 2.6081911876637447

Epoch: 5| Step: 10
Training loss: 2.588738441467285
Validation loss: 2.6169586771277973

Epoch: 41| Step: 0
Training loss: 2.5671164989471436
Validation loss: 2.605878130082161

Epoch: 5| Step: 1
Training loss: 3.5279953479766846
Validation loss: 2.605415987712081

Epoch: 5| Step: 2
Training loss: 2.7258167266845703
Validation loss: 2.6057652145303707

Epoch: 5| Step: 3
Training loss: 3.007686138153076
Validation loss: 2.608793845740698

Epoch: 5| Step: 4
Training loss: 1.5476146936416626
Validation loss: 2.6245852413997857

Epoch: 5| Step: 5
Training loss: 3.3762295246124268
Validation loss: 2.630203475234329

Epoch: 5| Step: 6
Training loss: 2.7159533500671387
Validation loss: 2.5967978867151404

Epoch: 5| Step: 7
Training loss: 2.6426682472229004
Validation loss: 2.5886038298247964

Epoch: 5| Step: 8
Training loss: 2.1623237133026123
Validation loss: 2.589492618396718

Epoch: 5| Step: 9
Training loss: 2.5449423789978027
Validation loss: 2.593548636282644

Epoch: 5| Step: 10
Training loss: 4.0988240242004395
Validation loss: 2.6066081293167604

Epoch: 42| Step: 0
Training loss: 2.26314640045166
Validation loss: 2.6112339368430515

Epoch: 5| Step: 1
Training loss: 2.768956184387207
Validation loss: 2.6059717542381695

Epoch: 5| Step: 2
Training loss: 2.934002637863159
Validation loss: 2.599827907418692

Epoch: 5| Step: 3
Training loss: 3.213818311691284
Validation loss: 2.5959511751769693

Epoch: 5| Step: 4
Training loss: 2.802687168121338
Validation loss: 2.594489294995544

Epoch: 5| Step: 5
Training loss: 2.433084011077881
Validation loss: 2.5956778782670216

Epoch: 5| Step: 6
Training loss: 2.906033992767334
Validation loss: 2.601600875136673

Epoch: 5| Step: 7
Training loss: 2.5911343097686768
Validation loss: 2.6082405633823846

Epoch: 5| Step: 8
Training loss: 3.2006804943084717
Validation loss: 2.6059248267963366

Epoch: 5| Step: 9
Training loss: 3.1751787662506104
Validation loss: 2.6014659430391047

Epoch: 5| Step: 10
Training loss: 2.437659978866577
Validation loss: 2.595137398730042

Epoch: 43| Step: 0
Training loss: 2.3634324073791504
Validation loss: 2.5899395250505015

Epoch: 5| Step: 1
Training loss: 2.840172529220581
Validation loss: 2.5909187434822

Epoch: 5| Step: 2
Training loss: 2.8650779724121094
Validation loss: 2.588182842859658

Epoch: 5| Step: 3
Training loss: 2.910364866256714
Validation loss: 2.589165711915621

Epoch: 5| Step: 4
Training loss: 2.50521183013916
Validation loss: 2.59339222087655

Epoch: 5| Step: 5
Training loss: 3.6819756031036377
Validation loss: 2.6000975126861245

Epoch: 5| Step: 6
Training loss: 3.1743462085723877
Validation loss: 2.5891169732616794

Epoch: 5| Step: 7
Training loss: 2.4254202842712402
Validation loss: 2.5914779119594122

Epoch: 5| Step: 8
Training loss: 2.2137820720672607
Validation loss: 2.5811298278070267

Epoch: 5| Step: 9
Training loss: 2.6284165382385254
Validation loss: 2.5866656200860136

Epoch: 5| Step: 10
Training loss: 3.026198387145996
Validation loss: 2.580759168953024

Epoch: 44| Step: 0
Training loss: 2.6537997722625732
Validation loss: 2.577237372757286

Epoch: 5| Step: 1
Training loss: 2.5645592212677
Validation loss: 2.5787290642338414

Epoch: 5| Step: 2
Training loss: 2.9592220783233643
Validation loss: 2.5803360657025407

Epoch: 5| Step: 3
Training loss: 2.854576587677002
Validation loss: 2.587632409987911

Epoch: 5| Step: 4
Training loss: 2.616826295852661
Validation loss: 2.5818714377700642

Epoch: 5| Step: 5
Training loss: 3.1368885040283203
Validation loss: 2.5821929695785686

Epoch: 5| Step: 6
Training loss: 3.2088348865509033
Validation loss: 2.5744276764572307

Epoch: 5| Step: 7
Training loss: 2.275846004486084
Validation loss: 2.5695440769195557

Epoch: 5| Step: 8
Training loss: 2.250310182571411
Validation loss: 2.5684624436081096

Epoch: 5| Step: 9
Training loss: 3.44604229927063
Validation loss: 2.5758698422421693

Epoch: 5| Step: 10
Training loss: 2.580446243286133
Validation loss: 2.5815622447639384

Epoch: 45| Step: 0
Training loss: 2.617152690887451
Validation loss: 2.580983502890474

Epoch: 5| Step: 1
Training loss: 2.0418059825897217
Validation loss: 2.578750169405373

Epoch: 5| Step: 2
Training loss: 2.427504301071167
Validation loss: 2.574754653438445

Epoch: 5| Step: 3
Training loss: 2.3629250526428223
Validation loss: 2.576282060274514

Epoch: 5| Step: 4
Training loss: 2.8180341720581055
Validation loss: 2.5815527105844147

Epoch: 5| Step: 5
Training loss: 2.926197052001953
Validation loss: 2.5759833038494153

Epoch: 5| Step: 6
Training loss: 2.4044055938720703
Validation loss: 2.571497740284089

Epoch: 5| Step: 7
Training loss: 3.4152278900146484
Validation loss: 2.564259133031291

Epoch: 5| Step: 8
Training loss: 2.9084863662719727
Validation loss: 2.5691970830322592

Epoch: 5| Step: 9
Training loss: 2.9172933101654053
Validation loss: 2.567955014526203

Epoch: 5| Step: 10
Training loss: 3.7266416549682617
Validation loss: 2.56425138186383

Epoch: 46| Step: 0
Training loss: 2.7010698318481445
Validation loss: 2.559166436554283

Epoch: 5| Step: 1
Training loss: 3.3138675689697266
Validation loss: 2.5643581728781424

Epoch: 5| Step: 2
Training loss: 3.36704683303833
Validation loss: 2.560924268537952

Epoch: 5| Step: 3
Training loss: 2.9481046199798584
Validation loss: 2.5670891346470004

Epoch: 5| Step: 4
Training loss: 2.6708409786224365
Validation loss: 2.563730634668822

Epoch: 5| Step: 5
Training loss: 2.320687770843506
Validation loss: 2.5634008966466433

Epoch: 5| Step: 6
Training loss: 2.335232973098755
Validation loss: 2.558473748545493

Epoch: 5| Step: 7
Training loss: 2.871577024459839
Validation loss: 2.5592063268025718

Epoch: 5| Step: 8
Training loss: 2.9853179454803467
Validation loss: 2.559186963624852

Epoch: 5| Step: 9
Training loss: 2.74867844581604
Validation loss: 2.562913660080202

Epoch: 5| Step: 10
Training loss: 2.0034053325653076
Validation loss: 2.565168349973617

Epoch: 47| Step: 0
Training loss: 3.214916944503784
Validation loss: 2.567670632434148

Epoch: 5| Step: 1
Training loss: 2.577235698699951
Validation loss: 2.568436397019253

Epoch: 5| Step: 2
Training loss: 2.564282178878784
Validation loss: 2.563985465675272

Epoch: 5| Step: 3
Training loss: 2.859652042388916
Validation loss: 2.564300698618735

Epoch: 5| Step: 4
Training loss: 2.777162790298462
Validation loss: 2.567111348593107

Epoch: 5| Step: 5
Training loss: 2.1217150688171387
Validation loss: 2.564443770275321

Epoch: 5| Step: 6
Training loss: 2.920820951461792
Validation loss: 2.561132382321101

Epoch: 5| Step: 7
Training loss: 2.2516207695007324
Validation loss: 2.557170234700685

Epoch: 5| Step: 8
Training loss: 3.292252779006958
Validation loss: 2.5617906380725164

Epoch: 5| Step: 9
Training loss: 2.885026454925537
Validation loss: 2.5648363328749135

Epoch: 5| Step: 10
Training loss: 2.759793281555176
Validation loss: 2.56087746671451

Epoch: 48| Step: 0
Training loss: 3.053187608718872
Validation loss: 2.56419857599402

Epoch: 5| Step: 1
Training loss: 2.2009267807006836
Validation loss: 2.5570820403355423

Epoch: 5| Step: 2
Training loss: 2.900728940963745
Validation loss: 2.553067163754535

Epoch: 5| Step: 3
Training loss: 2.6765544414520264
Validation loss: 2.5522736093049407

Epoch: 5| Step: 4
Training loss: 3.341951847076416
Validation loss: 2.561934168620776

Epoch: 5| Step: 5
Training loss: 2.907428503036499
Validation loss: 2.5645523148198284

Epoch: 5| Step: 6
Training loss: 2.8908627033233643
Validation loss: 2.5666946288078063

Epoch: 5| Step: 7
Training loss: 2.1948740482330322
Validation loss: 2.5733270927142073

Epoch: 5| Step: 8
Training loss: 2.2863385677337646
Validation loss: 2.569771279570877

Epoch: 5| Step: 9
Training loss: 3.1585869789123535
Validation loss: 2.5615089811304563

Epoch: 5| Step: 10
Training loss: 2.4935011863708496
Validation loss: 2.563652494902252

Epoch: 49| Step: 0
Training loss: 2.5012869834899902
Validation loss: 2.5629423664462183

Epoch: 5| Step: 1
Training loss: 3.0892577171325684
Validation loss: 2.5569323160315074

Epoch: 5| Step: 2
Training loss: 1.928304672241211
Validation loss: 2.558112713598436

Epoch: 5| Step: 3
Training loss: 2.0345966815948486
Validation loss: 2.55844678930057

Epoch: 5| Step: 4
Training loss: 2.433990478515625
Validation loss: 2.5480350140602357

Epoch: 5| Step: 5
Training loss: 3.2482681274414062
Validation loss: 2.5474540905285905

Epoch: 5| Step: 6
Training loss: 2.2676963806152344
Validation loss: 2.544619124422791

Epoch: 5| Step: 7
Training loss: 3.101133346557617
Validation loss: 2.5510526216158302

Epoch: 5| Step: 8
Training loss: 2.981214761734009
Validation loss: 2.5488067826917096

Epoch: 5| Step: 9
Training loss: 3.2825093269348145
Validation loss: 2.5498748620351157

Epoch: 5| Step: 10
Training loss: 3.369227886199951
Validation loss: 2.549460521308325

Epoch: 50| Step: 0
Training loss: 2.9817352294921875
Validation loss: 2.548988614031064

Epoch: 5| Step: 1
Training loss: 1.8157075643539429
Validation loss: 2.542524463386946

Epoch: 5| Step: 2
Training loss: 2.1485378742218018
Validation loss: 2.5427834398003033

Epoch: 5| Step: 3
Training loss: 2.713061571121216
Validation loss: 2.544708574971845

Epoch: 5| Step: 4
Training loss: 3.185380220413208
Validation loss: 2.547193122166459

Epoch: 5| Step: 5
Training loss: 2.724095582962036
Validation loss: 2.5448769984706754

Epoch: 5| Step: 6
Training loss: 3.428253650665283
Validation loss: 2.5459556374498593

Epoch: 5| Step: 7
Training loss: 2.5183892250061035
Validation loss: 2.558220055795485

Epoch: 5| Step: 8
Training loss: 3.3390870094299316
Validation loss: 2.5624535622135287

Epoch: 5| Step: 9
Training loss: 2.552031993865967
Validation loss: 2.566805988229731

Epoch: 5| Step: 10
Training loss: 2.5769684314727783
Validation loss: 2.562859332689675

Epoch: 51| Step: 0
Training loss: 2.429652690887451
Validation loss: 2.559899991558444

Epoch: 5| Step: 1
Training loss: 2.824420928955078
Validation loss: 2.5538226019951606

Epoch: 5| Step: 2
Training loss: 2.6965928077697754
Validation loss: 2.551798297512916

Epoch: 5| Step: 3
Training loss: 2.478092670440674
Validation loss: 2.5489871937741517

Epoch: 5| Step: 4
Training loss: 2.9027819633483887
Validation loss: 2.553439804302749

Epoch: 5| Step: 5
Training loss: 3.389827251434326
Validation loss: 2.557645079910114

Epoch: 5| Step: 6
Training loss: 2.5750393867492676
Validation loss: 2.560580704801826

Epoch: 5| Step: 7
Training loss: 2.8386294841766357
Validation loss: 2.568451771172144

Epoch: 5| Step: 8
Training loss: 2.8394196033477783
Validation loss: 2.55745207366123

Epoch: 5| Step: 9
Training loss: 2.5174572467803955
Validation loss: 2.5377662771491596

Epoch: 5| Step: 10
Training loss: 2.5420267581939697
Validation loss: 2.5336553435171805

Epoch: 52| Step: 0
Training loss: 2.474287271499634
Validation loss: 2.5359643915648102

Epoch: 5| Step: 1
Training loss: 2.973379611968994
Validation loss: 2.563970299177272

Epoch: 5| Step: 2
Training loss: 2.3485941886901855
Validation loss: 2.5836946989900325

Epoch: 5| Step: 3
Training loss: 3.3109652996063232
Validation loss: 2.572063958773049

Epoch: 5| Step: 4
Training loss: 2.453092098236084
Validation loss: 2.557864386548278

Epoch: 5| Step: 5
Training loss: 3.2087502479553223
Validation loss: 2.5544347045242146

Epoch: 5| Step: 6
Training loss: 2.7637572288513184
Validation loss: 2.546214408771966

Epoch: 5| Step: 7
Training loss: 2.670151472091675
Validation loss: 2.5575253860924834

Epoch: 5| Step: 8
Training loss: 2.6918625831604004
Validation loss: 2.5515598225337204

Epoch: 5| Step: 9
Training loss: 2.2090444564819336
Validation loss: 2.549331671448164

Epoch: 5| Step: 10
Training loss: 3.1096854209899902
Validation loss: 2.5301174143309235

Epoch: 53| Step: 0
Training loss: 2.603041410446167
Validation loss: 2.532492273597307

Epoch: 5| Step: 1
Training loss: 2.282423496246338
Validation loss: 2.5354122423356578

Epoch: 5| Step: 2
Training loss: 3.008279800415039
Validation loss: 2.5380759751924904

Epoch: 5| Step: 3
Training loss: 2.7566721439361572
Validation loss: 2.5373836896752797

Epoch: 5| Step: 4
Training loss: 3.334439754486084
Validation loss: 2.540170136318412

Epoch: 5| Step: 5
Training loss: 2.184767246246338
Validation loss: 2.5359803963732976

Epoch: 5| Step: 6
Training loss: 2.344268798828125
Validation loss: 2.531405210494995

Epoch: 5| Step: 7
Training loss: 2.8624494075775146
Validation loss: 2.520682427190965

Epoch: 5| Step: 8
Training loss: 2.6362853050231934
Validation loss: 2.516895737699283

Epoch: 5| Step: 9
Training loss: 2.8924508094787598
Validation loss: 2.5231397818493586

Epoch: 5| Step: 10
Training loss: 3.153916835784912
Validation loss: 2.5260589917500815

Epoch: 54| Step: 0
Training loss: 3.286733627319336
Validation loss: 2.53371674014676

Epoch: 5| Step: 1
Training loss: 2.395266532897949
Validation loss: 2.531222105026245

Epoch: 5| Step: 2
Training loss: 3.0677924156188965
Validation loss: 2.53169269715586

Epoch: 5| Step: 3
Training loss: 3.1730430126190186
Validation loss: 2.5272998502177577

Epoch: 5| Step: 4
Training loss: 2.363304853439331
Validation loss: 2.524524168301654

Epoch: 5| Step: 5
Training loss: 2.1372413635253906
Validation loss: 2.5211856749749955

Epoch: 5| Step: 6
Training loss: 2.90067982673645
Validation loss: 2.5197923465441634

Epoch: 5| Step: 7
Training loss: 3.1652188301086426
Validation loss: 2.5231649824368056

Epoch: 5| Step: 8
Training loss: 2.041869878768921
Validation loss: 2.5278880314160417

Epoch: 5| Step: 9
Training loss: 2.5951602458953857
Validation loss: 2.5451807232313257

Epoch: 5| Step: 10
Training loss: 2.8894662857055664
Validation loss: 2.571901959757651

Epoch: 55| Step: 0
Training loss: 2.883333206176758
Validation loss: 2.5668154198636293

Epoch: 5| Step: 1
Training loss: 2.775524616241455
Validation loss: 2.560258755119898

Epoch: 5| Step: 2
Training loss: 2.2798426151275635
Validation loss: 2.5534973631622973

Epoch: 5| Step: 3
Training loss: 2.4826138019561768
Validation loss: 2.529214900027039

Epoch: 5| Step: 4
Training loss: 2.7753701210021973
Validation loss: 2.52503397387843

Epoch: 5| Step: 5
Training loss: 2.5786845684051514
Validation loss: 2.525379116817187

Epoch: 5| Step: 6
Training loss: 2.9144890308380127
Validation loss: 2.5249121240390244

Epoch: 5| Step: 7
Training loss: 2.6499104499816895
Validation loss: 2.5310216924195648

Epoch: 5| Step: 8
Training loss: 2.6248111724853516
Validation loss: 2.5333048220603698

Epoch: 5| Step: 9
Training loss: 3.1713595390319824
Validation loss: 2.526250421359975

Epoch: 5| Step: 10
Training loss: 2.7094473838806152
Validation loss: 2.522200148592713

Epoch: 56| Step: 0
Training loss: 2.925372838973999
Validation loss: 2.5171729518521215

Epoch: 5| Step: 1
Training loss: 2.5978784561157227
Validation loss: 2.520900995500626

Epoch: 5| Step: 2
Training loss: 2.0034921169281006
Validation loss: 2.5265128920155187

Epoch: 5| Step: 3
Training loss: 3.274055004119873
Validation loss: 2.511616911939395

Epoch: 5| Step: 4
Training loss: 2.637800931930542
Validation loss: 2.5081147327218005

Epoch: 5| Step: 5
Training loss: 3.155266046524048
Validation loss: 2.5081205137314333

Epoch: 5| Step: 6
Training loss: 2.9773359298706055
Validation loss: 2.50816483395074

Epoch: 5| Step: 7
Training loss: 2.346200704574585
Validation loss: 2.5070774683388333

Epoch: 5| Step: 8
Training loss: 2.7038700580596924
Validation loss: 2.5123037010110836

Epoch: 5| Step: 9
Training loss: 2.477104425430298
Validation loss: 2.520706404921829

Epoch: 5| Step: 10
Training loss: 2.7477996349334717
Validation loss: 2.5196812178498957

Epoch: 57| Step: 0
Training loss: 3.5384719371795654
Validation loss: 2.520340686203331

Epoch: 5| Step: 1
Training loss: 2.1777915954589844
Validation loss: 2.5114752682306434

Epoch: 5| Step: 2
Training loss: 2.4831206798553467
Validation loss: 2.50954935883963

Epoch: 5| Step: 3
Training loss: 2.8396084308624268
Validation loss: 2.509376710461032

Epoch: 5| Step: 4
Training loss: 2.48510479927063
Validation loss: 2.514171426014234

Epoch: 5| Step: 5
Training loss: 2.335366725921631
Validation loss: 2.512885550016998

Epoch: 5| Step: 6
Training loss: 3.0799779891967773
Validation loss: 2.5157852147215154

Epoch: 5| Step: 7
Training loss: 3.0003907680511475
Validation loss: 2.520167291805308

Epoch: 5| Step: 8
Training loss: 2.80808687210083
Validation loss: 2.5264552280467045

Epoch: 5| Step: 9
Training loss: 2.8118202686309814
Validation loss: 2.5352089687060286

Epoch: 5| Step: 10
Training loss: 2.1812796592712402
Validation loss: 2.542506225647465

Epoch: 58| Step: 0
Training loss: 2.1884140968322754
Validation loss: 2.5229181192254506

Epoch: 5| Step: 1
Training loss: 2.837160587310791
Validation loss: 2.520347797742454

Epoch: 5| Step: 2
Training loss: 2.4079737663269043
Validation loss: 2.5158982251280095

Epoch: 5| Step: 3
Training loss: 2.380157947540283
Validation loss: 2.5152338192027104

Epoch: 5| Step: 4
Training loss: 2.245133876800537
Validation loss: 2.513939793391894

Epoch: 5| Step: 5
Training loss: 3.530472993850708
Validation loss: 2.514287328207365

Epoch: 5| Step: 6
Training loss: 2.898108720779419
Validation loss: 2.5111910553388697

Epoch: 5| Step: 7
Training loss: 3.2194430828094482
Validation loss: 2.5105954780373523

Epoch: 5| Step: 8
Training loss: 2.857347011566162
Validation loss: 2.5097668119656142

Epoch: 5| Step: 9
Training loss: 2.473808765411377
Validation loss: 2.5075624681288198

Epoch: 5| Step: 10
Training loss: 2.7741096019744873
Validation loss: 2.5026407421276136

Epoch: 59| Step: 0
Training loss: 2.592942953109741
Validation loss: 2.509978025190292

Epoch: 5| Step: 1
Training loss: 3.5409111976623535
Validation loss: 2.5039549873721216

Epoch: 5| Step: 2
Training loss: 2.6699469089508057
Validation loss: 2.5042984024170907

Epoch: 5| Step: 3
Training loss: 2.547072172164917
Validation loss: 2.508115601795976

Epoch: 5| Step: 4
Training loss: 2.9121456146240234
Validation loss: 2.5055000653830906

Epoch: 5| Step: 5
Training loss: 2.136486768722534
Validation loss: 2.5057025981205765

Epoch: 5| Step: 6
Training loss: 2.461501359939575
Validation loss: 2.5022564626509145

Epoch: 5| Step: 7
Training loss: 2.6967825889587402
Validation loss: 2.501611419903335

Epoch: 5| Step: 8
Training loss: 2.9281821250915527
Validation loss: 2.5024270498624412

Epoch: 5| Step: 9
Training loss: 2.5870306491851807
Validation loss: 2.5033228435823993

Epoch: 5| Step: 10
Training loss: 2.6138248443603516
Validation loss: 2.5053453624889417

Epoch: 60| Step: 0
Training loss: 2.473278522491455
Validation loss: 2.5174816193119174

Epoch: 5| Step: 1
Training loss: 3.366900682449341
Validation loss: 2.5047968459385697

Epoch: 5| Step: 2
Training loss: 2.5495495796203613
Validation loss: 2.501158624567011

Epoch: 5| Step: 3
Training loss: 2.2607765197753906
Validation loss: 2.496843253412554

Epoch: 5| Step: 4
Training loss: 2.5204734802246094
Validation loss: 2.4968698537477882

Epoch: 5| Step: 5
Training loss: 3.3445873260498047
Validation loss: 2.4925381701479674

Epoch: 5| Step: 6
Training loss: 1.8985933065414429
Validation loss: 2.494759116121518

Epoch: 5| Step: 7
Training loss: 3.22778582572937
Validation loss: 2.497014581516225

Epoch: 5| Step: 8
Training loss: 1.9415782690048218
Validation loss: 2.5055219255467898

Epoch: 5| Step: 9
Training loss: 2.792423963546753
Validation loss: 2.5050417736012447

Epoch: 5| Step: 10
Training loss: 3.4273810386657715
Validation loss: 2.508060706559048

Epoch: 61| Step: 0
Training loss: 2.015933036804199
Validation loss: 2.503870197521743

Epoch: 5| Step: 1
Training loss: 2.7340970039367676
Validation loss: 2.5016540660653064

Epoch: 5| Step: 2
Training loss: 2.550210475921631
Validation loss: 2.496892367639849

Epoch: 5| Step: 3
Training loss: 2.846263885498047
Validation loss: 2.494142847676431

Epoch: 5| Step: 4
Training loss: 2.665651559829712
Validation loss: 2.488305386676583

Epoch: 5| Step: 5
Training loss: 3.7466728687286377
Validation loss: 2.4903884369839906

Epoch: 5| Step: 6
Training loss: 2.686004161834717
Validation loss: 2.4918197662599626

Epoch: 5| Step: 7
Training loss: 2.953336238861084
Validation loss: 2.4910336950773835

Epoch: 5| Step: 8
Training loss: 2.8096413612365723
Validation loss: 2.487372065103182

Epoch: 5| Step: 9
Training loss: 2.371654987335205
Validation loss: 2.4892846973993445

Epoch: 5| Step: 10
Training loss: 2.1849777698516846
Validation loss: 2.4964464120967413

Epoch: 62| Step: 0
Training loss: 2.6226658821105957
Validation loss: 2.5016300165525047

Epoch: 5| Step: 1
Training loss: 3.2665038108825684
Validation loss: 2.494964999537314

Epoch: 5| Step: 2
Training loss: 2.7524571418762207
Validation loss: 2.4957902739124913

Epoch: 5| Step: 3
Training loss: 3.0350680351257324
Validation loss: 2.507994128811744

Epoch: 5| Step: 4
Training loss: 2.9299793243408203
Validation loss: 2.497862462074526

Epoch: 5| Step: 5
Training loss: 2.3987720012664795
Validation loss: 2.4996424157132386

Epoch: 5| Step: 6
Training loss: 3.183807849884033
Validation loss: 2.491084096252277

Epoch: 5| Step: 7
Training loss: 2.9643242359161377
Validation loss: 2.4939375692798245

Epoch: 5| Step: 8
Training loss: 2.1851859092712402
Validation loss: 2.499759920181767

Epoch: 5| Step: 9
Training loss: 1.7785125970840454
Validation loss: 2.5037316660727225

Epoch: 5| Step: 10
Training loss: 2.403536319732666
Validation loss: 2.5022182720963673

Epoch: 63| Step: 0
Training loss: 2.8992908000946045
Validation loss: 2.5021791791403167

Epoch: 5| Step: 1
Training loss: 3.090733766555786
Validation loss: 2.505199334954703

Epoch: 5| Step: 2
Training loss: 2.8862767219543457
Validation loss: 2.4985742081878004

Epoch: 5| Step: 3
Training loss: 2.7015271186828613
Validation loss: 2.4975833251912105

Epoch: 5| Step: 4
Training loss: 2.7822377681732178
Validation loss: 2.4941019422264508

Epoch: 5| Step: 5
Training loss: 2.791229248046875
Validation loss: 2.4914812657140915

Epoch: 5| Step: 6
Training loss: 2.10842227935791
Validation loss: 2.488264412008306

Epoch: 5| Step: 7
Training loss: 2.879718780517578
Validation loss: 2.4992428441201486

Epoch: 5| Step: 8
Training loss: 2.554360866546631
Validation loss: 2.498360537713574

Epoch: 5| Step: 9
Training loss: 2.9707717895507812
Validation loss: 2.4948608054909656

Epoch: 5| Step: 10
Training loss: 1.7784239053726196
Validation loss: 2.509033772253221

Epoch: 64| Step: 0
Training loss: 2.551358699798584
Validation loss: 2.498827426664291

Epoch: 5| Step: 1
Training loss: 2.95011305809021
Validation loss: 2.5077331707041752

Epoch: 5| Step: 2
Training loss: 2.7389514446258545
Validation loss: 2.5194154913707445

Epoch: 5| Step: 3
Training loss: 2.8550827503204346
Validation loss: 2.5038461505725818

Epoch: 5| Step: 4
Training loss: 2.6497802734375
Validation loss: 2.4881420699498986

Epoch: 5| Step: 5
Training loss: 2.412468433380127
Validation loss: 2.478481146597093

Epoch: 5| Step: 6
Training loss: 2.338543176651001
Validation loss: 2.4773781350863877

Epoch: 5| Step: 7
Training loss: 2.958031177520752
Validation loss: 2.484800172108476

Epoch: 5| Step: 8
Training loss: 2.498865842819214
Validation loss: 2.48447351045506

Epoch: 5| Step: 9
Training loss: 2.8506343364715576
Validation loss: 2.485493170317783

Epoch: 5| Step: 10
Training loss: 2.728581190109253
Validation loss: 2.4895642521560832

Epoch: 65| Step: 0
Training loss: 2.6270289421081543
Validation loss: 2.4863450745100617

Epoch: 5| Step: 1
Training loss: 2.023921012878418
Validation loss: 2.4854962364319833

Epoch: 5| Step: 2
Training loss: 2.87106990814209
Validation loss: 2.4822038040366223

Epoch: 5| Step: 3
Training loss: 2.3884472846984863
Validation loss: 2.48175706401948

Epoch: 5| Step: 4
Training loss: 3.0036556720733643
Validation loss: 2.4903564837671097

Epoch: 5| Step: 5
Training loss: 3.400468349456787
Validation loss: 2.495086175139232

Epoch: 5| Step: 6
Training loss: 2.8131461143493652
Validation loss: 2.5047986584324993

Epoch: 5| Step: 7
Training loss: 2.8379523754119873
Validation loss: 2.5179619250759

Epoch: 5| Step: 8
Training loss: 2.2915360927581787
Validation loss: 2.50822865322072

Epoch: 5| Step: 9
Training loss: 3.185114622116089
Validation loss: 2.4956363298559703

Epoch: 5| Step: 10
Training loss: 2.1089513301849365
Validation loss: 2.4841509583175823

Epoch: 66| Step: 0
Training loss: 2.675372838973999
Validation loss: 2.472546677435598

Epoch: 5| Step: 1
Training loss: 3.038029432296753
Validation loss: 2.474788837535407

Epoch: 5| Step: 2
Training loss: 2.4005045890808105
Validation loss: 2.477060878148643

Epoch: 5| Step: 3
Training loss: 2.495910167694092
Validation loss: 2.4724177109297885

Epoch: 5| Step: 4
Training loss: 2.402095079421997
Validation loss: 2.4731693678004767

Epoch: 5| Step: 5
Training loss: 2.2538793087005615
Validation loss: 2.4727757361627396

Epoch: 5| Step: 6
Training loss: 3.1184749603271484
Validation loss: 2.4726745056849655

Epoch: 5| Step: 7
Training loss: 2.7541556358337402
Validation loss: 2.4733636148514284

Epoch: 5| Step: 8
Training loss: 2.311096668243408
Validation loss: 2.4743343527599047

Epoch: 5| Step: 9
Training loss: 3.454730272293091
Validation loss: 2.4734808629558933

Epoch: 5| Step: 10
Training loss: 2.5727057456970215
Validation loss: 2.475684227481965

Epoch: 67| Step: 0
Training loss: 2.488032102584839
Validation loss: 2.482797953390306

Epoch: 5| Step: 1
Training loss: 2.6697676181793213
Validation loss: 2.4933533232699157

Epoch: 5| Step: 2
Training loss: 2.4731061458587646
Validation loss: 2.5129853628015004

Epoch: 5| Step: 3
Training loss: 2.482257604598999
Validation loss: 2.527247077675276

Epoch: 5| Step: 4
Training loss: 2.434950113296509
Validation loss: 2.5151313504865094

Epoch: 5| Step: 5
Training loss: 2.797849178314209
Validation loss: 2.5209846394036406

Epoch: 5| Step: 6
Training loss: 2.968684673309326
Validation loss: 2.5123703043947936

Epoch: 5| Step: 7
Training loss: 2.357093334197998
Validation loss: 2.5321048895517984

Epoch: 5| Step: 8
Training loss: 2.3036537170410156
Validation loss: 2.554513974856305

Epoch: 5| Step: 9
Training loss: 3.585808515548706
Validation loss: 2.4959008206603346

Epoch: 5| Step: 10
Training loss: 3.1627371311187744
Validation loss: 2.476392517807663

Epoch: 68| Step: 0
Training loss: 2.3612887859344482
Validation loss: 2.477627026137485

Epoch: 5| Step: 1
Training loss: 2.48695969581604
Validation loss: 2.4898490162305933

Epoch: 5| Step: 2
Training loss: 2.8600947856903076
Validation loss: 2.490821305141654

Epoch: 5| Step: 3
Training loss: 2.836548328399658
Validation loss: 2.4890591893144833

Epoch: 5| Step: 4
Training loss: 3.223252773284912
Validation loss: 2.483717164685649

Epoch: 5| Step: 5
Training loss: 2.6769049167633057
Validation loss: 2.473326813790106

Epoch: 5| Step: 6
Training loss: 2.2512712478637695
Validation loss: 2.46989667800165

Epoch: 5| Step: 7
Training loss: 2.245783805847168
Validation loss: 2.467613338142313

Epoch: 5| Step: 8
Training loss: 2.681123971939087
Validation loss: 2.475010100231376

Epoch: 5| Step: 9
Training loss: 2.912557601928711
Validation loss: 2.478447296286142

Epoch: 5| Step: 10
Training loss: 3.032308578491211
Validation loss: 2.4839650815533054

Epoch: 69| Step: 0
Training loss: 2.8915300369262695
Validation loss: 2.496472438176473

Epoch: 5| Step: 1
Training loss: 3.092658519744873
Validation loss: 2.502745656556981

Epoch: 5| Step: 2
Training loss: 2.9768548011779785
Validation loss: 2.5155382335826917

Epoch: 5| Step: 3
Training loss: 2.670290470123291
Validation loss: 2.4981181262641825

Epoch: 5| Step: 4
Training loss: 2.8026037216186523
Validation loss: 2.4836793791863228

Epoch: 5| Step: 5
Training loss: 2.3914573192596436
Validation loss: 2.4734465434987056

Epoch: 5| Step: 6
Training loss: 2.6068484783172607
Validation loss: 2.4720630940570625

Epoch: 5| Step: 7
Training loss: 2.190584659576416
Validation loss: 2.4636446122200257

Epoch: 5| Step: 8
Training loss: 2.250359535217285
Validation loss: 2.461413634720669

Epoch: 5| Step: 9
Training loss: 3.5319297313690186
Validation loss: 2.4648730319033385

Epoch: 5| Step: 10
Training loss: 2.0196938514709473
Validation loss: 2.4683161115133636

Epoch: 70| Step: 0
Training loss: 2.182957887649536
Validation loss: 2.471668589499689

Epoch: 5| Step: 1
Training loss: 2.448058605194092
Validation loss: 2.471798534034401

Epoch: 5| Step: 2
Training loss: 2.570136547088623
Validation loss: 2.4684048288611957

Epoch: 5| Step: 3
Training loss: 1.8421951532363892
Validation loss: 2.4683798461832027

Epoch: 5| Step: 4
Training loss: 3.403528928756714
Validation loss: 2.4745404797215618

Epoch: 5| Step: 5
Training loss: 2.8076741695404053
Validation loss: 2.475323669372066

Epoch: 5| Step: 6
Training loss: 2.214816093444824
Validation loss: 2.482499478965677

Epoch: 5| Step: 7
Training loss: 2.414790630340576
Validation loss: 2.486965287116266

Epoch: 5| Step: 8
Training loss: 2.9473507404327393
Validation loss: 2.4839175798559703

Epoch: 5| Step: 9
Training loss: 3.454549789428711
Validation loss: 2.4863563276106313

Epoch: 5| Step: 10
Training loss: 3.2547953128814697
Validation loss: 2.4849628761250484

Epoch: 71| Step: 0
Training loss: 2.4786152839660645
Validation loss: 2.477558897387597

Epoch: 5| Step: 1
Training loss: 2.6751372814178467
Validation loss: 2.4766456927022626

Epoch: 5| Step: 2
Training loss: 2.657648801803589
Validation loss: 2.4679875194385485

Epoch: 5| Step: 3
Training loss: 2.9049174785614014
Validation loss: 2.463350393438852

Epoch: 5| Step: 4
Training loss: 2.721750497817993
Validation loss: 2.462910972615724

Epoch: 5| Step: 5
Training loss: 2.3460562229156494
Validation loss: 2.455306581271592

Epoch: 5| Step: 6
Training loss: 2.908097505569458
Validation loss: 2.458251178905528

Epoch: 5| Step: 7
Training loss: 2.365816593170166
Validation loss: 2.460755399478379

Epoch: 5| Step: 8
Training loss: 2.710930347442627
Validation loss: 2.463488119904713

Epoch: 5| Step: 9
Training loss: 2.4627137184143066
Validation loss: 2.4667996642410115

Epoch: 5| Step: 10
Training loss: 3.274827241897583
Validation loss: 2.4637675874976703

Epoch: 72| Step: 0
Training loss: 3.498589038848877
Validation loss: 2.4604974177575882

Epoch: 5| Step: 1
Training loss: 2.6887755393981934
Validation loss: 2.461009210155856

Epoch: 5| Step: 2
Training loss: 2.503239393234253
Validation loss: 2.454690971682149

Epoch: 5| Step: 3
Training loss: 2.76495361328125
Validation loss: 2.4512234246858986

Epoch: 5| Step: 4
Training loss: 2.330096960067749
Validation loss: 2.45382341518197

Epoch: 5| Step: 5
Training loss: 3.222532272338867
Validation loss: 2.450732751559186

Epoch: 5| Step: 6
Training loss: 2.7460741996765137
Validation loss: 2.452218363361974

Epoch: 5| Step: 7
Training loss: 2.7401604652404785
Validation loss: 2.453452540982154

Epoch: 5| Step: 8
Training loss: 2.4213433265686035
Validation loss: 2.45088485235809

Epoch: 5| Step: 9
Training loss: 2.250887393951416
Validation loss: 2.450392112937025

Epoch: 5| Step: 10
Training loss: 2.0617456436157227
Validation loss: 2.448507962688323

Epoch: 73| Step: 0
Training loss: 2.9497013092041016
Validation loss: 2.452270230939311

Epoch: 5| Step: 1
Training loss: 2.9359679222106934
Validation loss: 2.459201992198985

Epoch: 5| Step: 2
Training loss: 2.7907588481903076
Validation loss: 2.4633407131318124

Epoch: 5| Step: 3
Training loss: 2.6169934272766113
Validation loss: 2.464416547488141

Epoch: 5| Step: 4
Training loss: 2.9661965370178223
Validation loss: 2.4684044827697096

Epoch: 5| Step: 5
Training loss: 1.9269644021987915
Validation loss: 2.472503367290702

Epoch: 5| Step: 6
Training loss: 2.3844892978668213
Validation loss: 2.4695972575936267

Epoch: 5| Step: 7
Training loss: 2.7815909385681152
Validation loss: 2.472197840290685

Epoch: 5| Step: 8
Training loss: 2.8933229446411133
Validation loss: 2.468986711194438

Epoch: 5| Step: 9
Training loss: 2.5986809730529785
Validation loss: 2.470718260734312

Epoch: 5| Step: 10
Training loss: 2.4287643432617188
Validation loss: 2.4718275403463714

Epoch: 74| Step: 0
Training loss: 2.80476713180542
Validation loss: 2.4653092251029065

Epoch: 5| Step: 1
Training loss: 2.4629034996032715
Validation loss: 2.461535866542529

Epoch: 5| Step: 2
Training loss: 2.7275583744049072
Validation loss: 2.4613685172091246

Epoch: 5| Step: 3
Training loss: 2.84393572807312
Validation loss: 2.4571435848871865

Epoch: 5| Step: 4
Training loss: 3.0687217712402344
Validation loss: 2.456683808757413

Epoch: 5| Step: 5
Training loss: 2.8253626823425293
Validation loss: 2.4526330988894225

Epoch: 5| Step: 6
Training loss: 2.7358460426330566
Validation loss: 2.454404584823116

Epoch: 5| Step: 7
Training loss: 2.8004050254821777
Validation loss: 2.454634566460886

Epoch: 5| Step: 8
Training loss: 2.1346635818481445
Validation loss: 2.4517748945502826

Epoch: 5| Step: 9
Training loss: 2.514847993850708
Validation loss: 2.451323519470871

Epoch: 5| Step: 10
Training loss: 2.2796669006347656
Validation loss: 2.449514981239073

Epoch: 75| Step: 0
Training loss: 2.581834316253662
Validation loss: 2.447166048070436

Epoch: 5| Step: 1
Training loss: 2.0712242126464844
Validation loss: 2.4475242707037155

Epoch: 5| Step: 2
Training loss: 3.3699288368225098
Validation loss: 2.4535710760342178

Epoch: 5| Step: 3
Training loss: 2.2685811519622803
Validation loss: 2.461930941509944

Epoch: 5| Step: 4
Training loss: 2.371717929840088
Validation loss: 2.466632843017578

Epoch: 5| Step: 5
Training loss: 2.5181050300598145
Validation loss: 2.4785903038517123

Epoch: 5| Step: 6
Training loss: 3.0140864849090576
Validation loss: 2.4714009659264677

Epoch: 5| Step: 7
Training loss: 2.9538445472717285
Validation loss: 2.4708853690854964

Epoch: 5| Step: 8
Training loss: 2.863147258758545
Validation loss: 2.4566394488016763

Epoch: 5| Step: 9
Training loss: 2.9227867126464844
Validation loss: 2.4572378845625025

Epoch: 5| Step: 10
Training loss: 2.3041956424713135
Validation loss: 2.4492499264337684

Epoch: 76| Step: 0
Training loss: 2.7337207794189453
Validation loss: 2.442780699781192

Epoch: 5| Step: 1
Training loss: 2.4849753379821777
Validation loss: 2.4399868647257485

Epoch: 5| Step: 2
Training loss: 2.2668066024780273
Validation loss: 2.4404709749324347

Epoch: 5| Step: 3
Training loss: 3.198352575302124
Validation loss: 2.4433224201202393

Epoch: 5| Step: 4
Training loss: 2.4910130500793457
Validation loss: 2.4515340020579677

Epoch: 5| Step: 5
Training loss: 3.242464542388916
Validation loss: 2.458151161029775

Epoch: 5| Step: 6
Training loss: 2.8762569427490234
Validation loss: 2.4690551065629527

Epoch: 5| Step: 7
Training loss: 2.5987632274627686
Validation loss: 2.48243688255228

Epoch: 5| Step: 8
Training loss: 2.5258936882019043
Validation loss: 2.479783537567303

Epoch: 5| Step: 9
Training loss: 1.972063422203064
Validation loss: 2.4756026934551936

Epoch: 5| Step: 10
Training loss: 2.9639036655426025
Validation loss: 2.4782892042590725

Epoch: 77| Step: 0
Training loss: 3.2469444274902344
Validation loss: 2.4542791997232745

Epoch: 5| Step: 1
Training loss: 2.334958553314209
Validation loss: 2.45288695058515

Epoch: 5| Step: 2
Training loss: 2.171651601791382
Validation loss: 2.457244657701062

Epoch: 5| Step: 3
Training loss: 2.8683810234069824
Validation loss: 2.461791576877717

Epoch: 5| Step: 4
Training loss: 1.9282127618789673
Validation loss: 2.465914608329855

Epoch: 5| Step: 5
Training loss: 3.129350185394287
Validation loss: 2.4737788425978793

Epoch: 5| Step: 6
Training loss: 2.140793561935425
Validation loss: 2.484130190264794

Epoch: 5| Step: 7
Training loss: 2.908898115158081
Validation loss: 2.4944036391473587

Epoch: 5| Step: 8
Training loss: 2.240405797958374
Validation loss: 2.4866863989060923

Epoch: 5| Step: 9
Training loss: 2.9806225299835205
Validation loss: 2.4878239682925645

Epoch: 5| Step: 10
Training loss: 3.3555068969726562
Validation loss: 2.4815394083658853

Epoch: 78| Step: 0
Training loss: 2.1513500213623047
Validation loss: 2.476526742340416

Epoch: 5| Step: 1
Training loss: 1.8890407085418701
Validation loss: 2.4627135517776653

Epoch: 5| Step: 2
Training loss: 2.7926979064941406
Validation loss: 2.448771128090479

Epoch: 5| Step: 3
Training loss: 2.6994338035583496
Validation loss: 2.4358494435587237

Epoch: 5| Step: 4
Training loss: 2.724846363067627
Validation loss: 2.4392573346373854

Epoch: 5| Step: 5
Training loss: 2.723519802093506
Validation loss: 2.430910195073774

Epoch: 5| Step: 6
Training loss: 2.9897589683532715
Validation loss: 2.4339782858407624

Epoch: 5| Step: 7
Training loss: 2.324533462524414
Validation loss: 2.43478306903634

Epoch: 5| Step: 8
Training loss: 3.6134085655212402
Validation loss: 2.4258460639625468

Epoch: 5| Step: 9
Training loss: 2.7789254188537598
Validation loss: 2.427541563587804

Epoch: 5| Step: 10
Training loss: 2.447828531265259
Validation loss: 2.431171489018266

Epoch: 79| Step: 0
Training loss: 2.5763323307037354
Validation loss: 2.4297125108780397

Epoch: 5| Step: 1
Training loss: 2.5196614265441895
Validation loss: 2.4328648390308505

Epoch: 5| Step: 2
Training loss: 2.3081367015838623
Validation loss: 2.4350774980360463

Epoch: 5| Step: 3
Training loss: 2.5240859985351562
Validation loss: 2.436729755452884

Epoch: 5| Step: 4
Training loss: 3.1663365364074707
Validation loss: 2.441925646156393

Epoch: 5| Step: 5
Training loss: 2.2413268089294434
Validation loss: 2.4439028873238513

Epoch: 5| Step: 6
Training loss: 2.6725828647613525
Validation loss: 2.4290434878359557

Epoch: 5| Step: 7
Training loss: 2.6690425872802734
Validation loss: 2.432529498172063

Epoch: 5| Step: 8
Training loss: 2.4325337409973145
Validation loss: 2.4290689601693103

Epoch: 5| Step: 9
Training loss: 2.7478954792022705
Validation loss: 2.427150054644513

Epoch: 5| Step: 10
Training loss: 3.509347915649414
Validation loss: 2.426601868803783

Epoch: 80| Step: 0
Training loss: 2.4803080558776855
Validation loss: 2.4266141460787867

Epoch: 5| Step: 1
Training loss: 2.439413547515869
Validation loss: 2.429478181305752

Epoch: 5| Step: 2
Training loss: 2.7774617671966553
Validation loss: 2.4275119509748233

Epoch: 5| Step: 3
Training loss: 2.414490222930908
Validation loss: 2.427151113428095

Epoch: 5| Step: 4
Training loss: 2.582500696182251
Validation loss: 2.4253975217060377

Epoch: 5| Step: 5
Training loss: 2.0609633922576904
Validation loss: 2.4256250653215634

Epoch: 5| Step: 6
Training loss: 3.577409267425537
Validation loss: 2.428202362470729

Epoch: 5| Step: 7
Training loss: 2.175809860229492
Validation loss: 2.436026978236373

Epoch: 5| Step: 8
Training loss: 2.391317844390869
Validation loss: 2.4466769759373

Epoch: 5| Step: 9
Training loss: 3.071331739425659
Validation loss: 2.4632507601091937

Epoch: 5| Step: 10
Training loss: 3.255915880203247
Validation loss: 2.4742625580039075

Epoch: 81| Step: 0
Training loss: 2.9609904289245605
Validation loss: 2.4883823087138515

Epoch: 5| Step: 1
Training loss: 2.4279980659484863
Validation loss: 2.526172661012219

Epoch: 5| Step: 2
Training loss: 2.3931643962860107
Validation loss: 2.544345034066067

Epoch: 5| Step: 3
Training loss: 2.5537290573120117
Validation loss: 2.538650684459235

Epoch: 5| Step: 4
Training loss: 2.6862430572509766
Validation loss: 2.552626373947308

Epoch: 5| Step: 5
Training loss: 2.336949348449707
Validation loss: 2.5242387504987818

Epoch: 5| Step: 6
Training loss: 2.886093854904175
Validation loss: 2.4890073986463648

Epoch: 5| Step: 7
Training loss: 2.333219051361084
Validation loss: 2.454655444750222

Epoch: 5| Step: 8
Training loss: 2.57183837890625
Validation loss: 2.4446190787899877

Epoch: 5| Step: 9
Training loss: 3.296199083328247
Validation loss: 2.4401254141202537

Epoch: 5| Step: 10
Training loss: 3.0729522705078125
Validation loss: 2.4545742619422173

Epoch: 82| Step: 0
Training loss: 2.4448540210723877
Validation loss: 2.463502889038414

Epoch: 5| Step: 1
Training loss: 3.1093249320983887
Validation loss: 2.467206467864334

Epoch: 5| Step: 2
Training loss: 2.6321005821228027
Validation loss: 2.462922280834567

Epoch: 5| Step: 3
Training loss: 2.4458842277526855
Validation loss: 2.4545519582686888

Epoch: 5| Step: 4
Training loss: 2.3535473346710205
Validation loss: 2.451059951577135

Epoch: 5| Step: 5
Training loss: 2.3963475227355957
Validation loss: 2.446233208461474

Epoch: 5| Step: 6
Training loss: 3.1935336589813232
Validation loss: 2.4372012153748543

Epoch: 5| Step: 7
Training loss: 2.492514133453369
Validation loss: 2.4343529837105864

Epoch: 5| Step: 8
Training loss: 3.2493979930877686
Validation loss: 2.430765364759712

Epoch: 5| Step: 9
Training loss: 2.1228623390197754
Validation loss: 2.43117178896422

Epoch: 5| Step: 10
Training loss: 2.953209161758423
Validation loss: 2.441881779701479

Epoch: 83| Step: 0
Training loss: 2.31623911857605
Validation loss: 2.4457520720779256

Epoch: 5| Step: 1
Training loss: 2.7855257987976074
Validation loss: 2.4382522080534246

Epoch: 5| Step: 2
Training loss: 3.0698885917663574
Validation loss: 2.4396635076051116

Epoch: 5| Step: 3
Training loss: 2.2754106521606445
Validation loss: 2.4340614887975875

Epoch: 5| Step: 4
Training loss: 2.2733654975891113
Validation loss: 2.4409746764808573

Epoch: 5| Step: 5
Training loss: 2.8874459266662598
Validation loss: 2.4332223733266196

Epoch: 5| Step: 6
Training loss: 2.5510311126708984
Validation loss: 2.430084505388814

Epoch: 5| Step: 7
Training loss: 3.100891351699829
Validation loss: 2.443630636379283

Epoch: 5| Step: 8
Training loss: 2.653200387954712
Validation loss: 2.4709013841485463

Epoch: 5| Step: 9
Training loss: 2.5902817249298096
Validation loss: 2.439339194246518

Epoch: 5| Step: 10
Training loss: 2.7050106525421143
Validation loss: 2.430337687974335

Epoch: 84| Step: 0
Training loss: 2.6081244945526123
Validation loss: 2.4257597256732244

Epoch: 5| Step: 1
Training loss: 2.8782687187194824
Validation loss: 2.426874976004324

Epoch: 5| Step: 2
Training loss: 2.0371127128601074
Validation loss: 2.4257409931511007

Epoch: 5| Step: 3
Training loss: 2.701103687286377
Validation loss: 2.4369262751712593

Epoch: 5| Step: 4
Training loss: 2.9037468433380127
Validation loss: 2.4387992761468373

Epoch: 5| Step: 5
Training loss: 2.253025531768799
Validation loss: 2.438951482055008

Epoch: 5| Step: 6
Training loss: 2.466392993927002
Validation loss: 2.4359560012817383

Epoch: 5| Step: 7
Training loss: 2.739805221557617
Validation loss: 2.435182832902478

Epoch: 5| Step: 8
Training loss: 2.6002321243286133
Validation loss: 2.4306746208539574

Epoch: 5| Step: 9
Training loss: 3.062828540802002
Validation loss: 2.4212229533862044

Epoch: 5| Step: 10
Training loss: 2.8775649070739746
Validation loss: 2.4198140995476836

Epoch: 85| Step: 0
Training loss: 3.1005501747131348
Validation loss: 2.414731030823082

Epoch: 5| Step: 1
Training loss: 2.907696008682251
Validation loss: 2.415790452752062

Epoch: 5| Step: 2
Training loss: 2.5525615215301514
Validation loss: 2.4134367922300934

Epoch: 5| Step: 3
Training loss: 2.723597764968872
Validation loss: 2.4065492922259915

Epoch: 5| Step: 4
Training loss: 2.3953824043273926
Validation loss: 2.4073002774228334

Epoch: 5| Step: 5
Training loss: 2.4627811908721924
Validation loss: 2.4032581211418234

Epoch: 5| Step: 6
Training loss: 2.313429832458496
Validation loss: 2.4122722200168076

Epoch: 5| Step: 7
Training loss: 2.884493112564087
Validation loss: 2.407965903641075

Epoch: 5| Step: 8
Training loss: 2.703017473220825
Validation loss: 2.40926294942056

Epoch: 5| Step: 9
Training loss: 2.086503505706787
Validation loss: 2.4088578121636504

Epoch: 5| Step: 10
Training loss: 2.9390408992767334
Validation loss: 2.407959735521706

Epoch: 86| Step: 0
Training loss: 2.0055668354034424
Validation loss: 2.4108681576226347

Epoch: 5| Step: 1
Training loss: 2.5893423557281494
Validation loss: 2.4102368636797835

Epoch: 5| Step: 2
Training loss: 3.1229419708251953
Validation loss: 2.4124478127366755

Epoch: 5| Step: 3
Training loss: 3.4371237754821777
Validation loss: 2.414506858394992

Epoch: 5| Step: 4
Training loss: 2.995924234390259
Validation loss: 2.4093877371921333

Epoch: 5| Step: 5
Training loss: 2.2305591106414795
Validation loss: 2.4152680417542816

Epoch: 5| Step: 6
Training loss: 2.8114800453186035
Validation loss: 2.4182962243274977

Epoch: 5| Step: 7
Training loss: 2.429861307144165
Validation loss: 2.4231011149703816

Epoch: 5| Step: 8
Training loss: 2.6571919918060303
Validation loss: 2.4229044145153416

Epoch: 5| Step: 9
Training loss: 2.501499891281128
Validation loss: 2.4341362419948784

Epoch: 5| Step: 10
Training loss: 2.291123151779175
Validation loss: 2.4227970082272767

Epoch: 87| Step: 0
Training loss: 3.0746631622314453
Validation loss: 2.4173274834950766

Epoch: 5| Step: 1
Training loss: 2.8500072956085205
Validation loss: 2.4165362414493354

Epoch: 5| Step: 2
Training loss: 2.853036403656006
Validation loss: 2.429066816965739

Epoch: 5| Step: 3
Training loss: 2.2866358757019043
Validation loss: 2.451909395956224

Epoch: 5| Step: 4
Training loss: 2.1189451217651367
Validation loss: 2.464358422064012

Epoch: 5| Step: 5
Training loss: 3.244861602783203
Validation loss: 2.453160698695849

Epoch: 5| Step: 6
Training loss: 3.429943799972534
Validation loss: 2.4313209620855187

Epoch: 5| Step: 7
Training loss: 2.7218403816223145
Validation loss: 2.4155341476522465

Epoch: 5| Step: 8
Training loss: 2.4007182121276855
Validation loss: 2.406709619747695

Epoch: 5| Step: 9
Training loss: 2.128654956817627
Validation loss: 2.4001945705824

Epoch: 5| Step: 10
Training loss: 1.879249930381775
Validation loss: 2.399013086031842

Epoch: 88| Step: 0
Training loss: 3.3423492908477783
Validation loss: 2.414967442071566

Epoch: 5| Step: 1
Training loss: 2.153517484664917
Validation loss: 2.424034836471722

Epoch: 5| Step: 2
Training loss: 2.5373549461364746
Validation loss: 2.432020254032586

Epoch: 5| Step: 3
Training loss: 2.875115156173706
Validation loss: 2.441532286264563

Epoch: 5| Step: 4
Training loss: 2.836210250854492
Validation loss: 2.42302595415423

Epoch: 5| Step: 5
Training loss: 2.462986469268799
Validation loss: 2.4158619860167145

Epoch: 5| Step: 6
Training loss: 3.0567984580993652
Validation loss: 2.406498529577768

Epoch: 5| Step: 7
Training loss: 3.031475782394409
Validation loss: 2.404565111283333

Epoch: 5| Step: 8
Training loss: 2.0043704509735107
Validation loss: 2.399786614602612

Epoch: 5| Step: 9
Training loss: 1.8802881240844727
Validation loss: 2.3962013465102

Epoch: 5| Step: 10
Training loss: 2.93725323677063
Validation loss: 2.4004664946627874

Epoch: 89| Step: 0
Training loss: 2.503493547439575
Validation loss: 2.400405283897154

Epoch: 5| Step: 1
Training loss: 2.652850389480591
Validation loss: 2.3987631797790527

Epoch: 5| Step: 2
Training loss: 2.977412223815918
Validation loss: 2.4026194387866604

Epoch: 5| Step: 3
Training loss: 2.5387396812438965
Validation loss: 2.404347683793755

Epoch: 5| Step: 4
Training loss: 2.5500035285949707
Validation loss: 2.408527530649657

Epoch: 5| Step: 5
Training loss: 2.630300998687744
Validation loss: 2.4329439440081195

Epoch: 5| Step: 6
Training loss: 2.7968270778656006
Validation loss: 2.4792599485766504

Epoch: 5| Step: 7
Training loss: 2.871070384979248
Validation loss: 2.418141952124975

Epoch: 5| Step: 8
Training loss: 2.5284383296966553
Validation loss: 2.407471820872317

Epoch: 5| Step: 9
Training loss: 2.7861733436584473
Validation loss: 2.3990591290176555

Epoch: 5| Step: 10
Training loss: 2.130749225616455
Validation loss: 2.3976295327627533

Epoch: 90| Step: 0
Training loss: 2.1297669410705566
Validation loss: 2.3977573815212456

Epoch: 5| Step: 1
Training loss: 2.956181764602661
Validation loss: 2.4064818633499967

Epoch: 5| Step: 2
Training loss: 2.7930893898010254
Validation loss: 2.419779216089556

Epoch: 5| Step: 3
Training loss: 2.737483263015747
Validation loss: 2.43346833157283

Epoch: 5| Step: 4
Training loss: 2.9535603523254395
Validation loss: 2.414023196825417

Epoch: 5| Step: 5
Training loss: 3.340909957885742
Validation loss: 2.413053153663553

Epoch: 5| Step: 6
Training loss: 2.332418918609619
Validation loss: 2.401355699826312

Epoch: 5| Step: 7
Training loss: 2.270627975463867
Validation loss: 2.394110615535449

Epoch: 5| Step: 8
Training loss: 2.3714370727539062
Validation loss: 2.3935737738045315

Epoch: 5| Step: 9
Training loss: 2.8360326290130615
Validation loss: 2.3981018168951875

Epoch: 5| Step: 10
Training loss: 2.1837961673736572
Validation loss: 2.4005492374461186

Epoch: 91| Step: 0
Training loss: 2.8421196937561035
Validation loss: 2.4041065657010643

Epoch: 5| Step: 1
Training loss: 3.10219144821167
Validation loss: 2.4108845918409285

Epoch: 5| Step: 2
Training loss: 2.508388042449951
Validation loss: 2.4170785950076197

Epoch: 5| Step: 3
Training loss: 2.486971139907837
Validation loss: 2.422693798618932

Epoch: 5| Step: 4
Training loss: 3.080030679702759
Validation loss: 2.4195981000059392

Epoch: 5| Step: 5
Training loss: 2.966763973236084
Validation loss: 2.4177650277332594

Epoch: 5| Step: 6
Training loss: 2.688321113586426
Validation loss: 2.429231113003146

Epoch: 5| Step: 7
Training loss: 2.0523948669433594
Validation loss: 2.4383094413306123

Epoch: 5| Step: 8
Training loss: 2.1334948539733887
Validation loss: 2.4362070406636884

Epoch: 5| Step: 9
Training loss: 2.2601523399353027
Validation loss: 2.430291211733254

Epoch: 5| Step: 10
Training loss: 2.8781392574310303
Validation loss: 2.4150852259769233

Epoch: 92| Step: 0
Training loss: 2.187283992767334
Validation loss: 2.4107901178380495

Epoch: 5| Step: 1
Training loss: 3.4605698585510254
Validation loss: 2.4010286920814106

Epoch: 5| Step: 2
Training loss: 2.784339427947998
Validation loss: 2.395243008931478

Epoch: 5| Step: 3
Training loss: 2.7868547439575195
Validation loss: 2.3940357341561267

Epoch: 5| Step: 4
Training loss: 2.3792128562927246
Validation loss: 2.3925384808612127

Epoch: 5| Step: 5
Training loss: 2.615074872970581
Validation loss: 2.4109218197484172

Epoch: 5| Step: 6
Training loss: 3.2464237213134766
Validation loss: 2.4420730196019655

Epoch: 5| Step: 7
Training loss: 2.6739754676818848
Validation loss: 2.457527752845518

Epoch: 5| Step: 8
Training loss: 2.246016263961792
Validation loss: 2.4720251867848058

Epoch: 5| Step: 9
Training loss: 2.2082648277282715
Validation loss: 2.48087643038842

Epoch: 5| Step: 10
Training loss: 2.4126157760620117
Validation loss: 2.4780045581120316

Epoch: 93| Step: 0
Training loss: 3.2370553016662598
Validation loss: 2.4752554303856305

Epoch: 5| Step: 1
Training loss: 2.0600147247314453
Validation loss: 2.4835181056812243

Epoch: 5| Step: 2
Training loss: 3.206502914428711
Validation loss: 2.4934261768094954

Epoch: 5| Step: 3
Training loss: 2.023561477661133
Validation loss: 2.490285296593943

Epoch: 5| Step: 4
Training loss: 2.4282100200653076
Validation loss: 2.487423176406532

Epoch: 5| Step: 5
Training loss: 3.014871120452881
Validation loss: 2.4924888226293747

Epoch: 5| Step: 6
Training loss: 2.2927286624908447
Validation loss: 2.473349842973935

Epoch: 5| Step: 7
Training loss: 2.410587787628174
Validation loss: 2.4771085503280803

Epoch: 5| Step: 8
Training loss: 3.104424238204956
Validation loss: 2.4670603736754386

Epoch: 5| Step: 9
Training loss: 2.840585947036743
Validation loss: 2.4617423062683432

Epoch: 5| Step: 10
Training loss: 2.7572662830352783
Validation loss: 2.457310438156128

Epoch: 94| Step: 0
Training loss: 2.7107644081115723
Validation loss: 2.4442805320985856

Epoch: 5| Step: 1
Training loss: 2.869412899017334
Validation loss: 2.434644078695646

Epoch: 5| Step: 2
Training loss: 2.7994189262390137
Validation loss: 2.4130218054658625

Epoch: 5| Step: 3
Training loss: 2.4080584049224854
Validation loss: 2.399921735127767

Epoch: 5| Step: 4
Training loss: 3.138392925262451
Validation loss: 2.386104086393951

Epoch: 5| Step: 5
Training loss: 2.4977145195007324
Validation loss: 2.3863687463985976

Epoch: 5| Step: 6
Training loss: 2.49407696723938
Validation loss: 2.3975251541342786

Epoch: 5| Step: 7
Training loss: 2.7129621505737305
Validation loss: 2.401247268081993

Epoch: 5| Step: 8
Training loss: 2.657782554626465
Validation loss: 2.414510933301782

Epoch: 5| Step: 9
Training loss: 2.4509167671203613
Validation loss: 2.4195545129878546

Epoch: 5| Step: 10
Training loss: 2.2147254943847656
Validation loss: 2.423638028483237

Epoch: 95| Step: 0
Training loss: 2.590805768966675
Validation loss: 2.416603516506892

Epoch: 5| Step: 1
Training loss: 3.032869338989258
Validation loss: 2.4144301055580057

Epoch: 5| Step: 2
Training loss: 2.0680809020996094
Validation loss: 2.397692423994823

Epoch: 5| Step: 3
Training loss: 2.7635550498962402
Validation loss: 2.399398298673732

Epoch: 5| Step: 4
Training loss: 2.8295531272888184
Validation loss: 2.391084066001318

Epoch: 5| Step: 5
Training loss: 2.686098098754883
Validation loss: 2.3910749035496868

Epoch: 5| Step: 6
Training loss: 2.830343723297119
Validation loss: 2.384886992874966

Epoch: 5| Step: 7
Training loss: 2.888185501098633
Validation loss: 2.388801800307407

Epoch: 5| Step: 8
Training loss: 2.2668304443359375
Validation loss: 2.3851264599830873

Epoch: 5| Step: 9
Training loss: 2.1617138385772705
Validation loss: 2.382773432680356

Epoch: 5| Step: 10
Training loss: 2.8799686431884766
Validation loss: 2.388519674219111

Epoch: 96| Step: 0
Training loss: 3.039597988128662
Validation loss: 2.40230849225034

Epoch: 5| Step: 1
Training loss: 3.119305372238159
Validation loss: 2.408568161790089

Epoch: 5| Step: 2
Training loss: 1.9082475900650024
Validation loss: 2.4245518189604565

Epoch: 5| Step: 3
Training loss: 2.7893834114074707
Validation loss: 2.443836878704768

Epoch: 5| Step: 4
Training loss: 2.243781089782715
Validation loss: 2.463425072290564

Epoch: 5| Step: 5
Training loss: 3.1327972412109375
Validation loss: 2.482198917737571

Epoch: 5| Step: 6
Training loss: 2.6896607875823975
Validation loss: 2.4819623475433676

Epoch: 5| Step: 7
Training loss: 2.025857925415039
Validation loss: 2.471204916636149

Epoch: 5| Step: 8
Training loss: 2.309464693069458
Validation loss: 2.462360441043813

Epoch: 5| Step: 9
Training loss: 3.026099443435669
Validation loss: 2.439943831454041

Epoch: 5| Step: 10
Training loss: 2.6778244972229004
Validation loss: 2.4333104292551675

Epoch: 97| Step: 0
Training loss: 2.8795406818389893
Validation loss: 2.4205164729907946

Epoch: 5| Step: 1
Training loss: 2.494173526763916
Validation loss: 2.411970592314197

Epoch: 5| Step: 2
Training loss: 1.9904552698135376
Validation loss: 2.413263572159634

Epoch: 5| Step: 3
Training loss: 2.7912988662719727
Validation loss: 2.4009722791692263

Epoch: 5| Step: 4
Training loss: 3.45910382270813
Validation loss: 2.394603375465639

Epoch: 5| Step: 5
Training loss: 1.9972965717315674
Validation loss: 2.3870655259778424

Epoch: 5| Step: 6
Training loss: 3.0118303298950195
Validation loss: 2.3821491144036733

Epoch: 5| Step: 7
Training loss: 2.3831822872161865
Validation loss: 2.3812219686405633

Epoch: 5| Step: 8
Training loss: 2.7258198261260986
Validation loss: 2.3802478467264483

Epoch: 5| Step: 9
Training loss: 2.2753798961639404
Validation loss: 2.379785427483179

Epoch: 5| Step: 10
Training loss: 2.844097852706909
Validation loss: 2.390018573371313

Epoch: 98| Step: 0
Training loss: 2.840378761291504
Validation loss: 2.398184855779012

Epoch: 5| Step: 1
Training loss: 2.3946516513824463
Validation loss: 2.4000442104954876

Epoch: 5| Step: 2
Training loss: 2.751781940460205
Validation loss: 2.3907054175612745

Epoch: 5| Step: 3
Training loss: 2.5484697818756104
Validation loss: 2.394737776889596

Epoch: 5| Step: 4
Training loss: 3.2225098609924316
Validation loss: 2.403088859332505

Epoch: 5| Step: 5
Training loss: 2.8487114906311035
Validation loss: 2.4058130787264917

Epoch: 5| Step: 6
Training loss: 2.2675774097442627
Validation loss: 2.4057138940339446

Epoch: 5| Step: 7
Training loss: 2.5502898693084717
Validation loss: 2.3985431527578704

Epoch: 5| Step: 8
Training loss: 2.294968843460083
Validation loss: 2.3967545699047785

Epoch: 5| Step: 9
Training loss: 2.2439897060394287
Validation loss: 2.400873996878183

Epoch: 5| Step: 10
Training loss: 2.867178440093994
Validation loss: 2.404348491340555

Epoch: 99| Step: 0
Training loss: 2.2715888023376465
Validation loss: 2.4136523687711327

Epoch: 5| Step: 1
Training loss: 2.476370334625244
Validation loss: 2.4575044865249307

Epoch: 5| Step: 2
Training loss: 3.1908369064331055
Validation loss: 2.453254791998094

Epoch: 5| Step: 3
Training loss: 2.629357099533081
Validation loss: 2.4024164420302196

Epoch: 5| Step: 4
Training loss: 2.786346197128296
Validation loss: 2.3932886841476604

Epoch: 5| Step: 5
Training loss: 1.9429857730865479
Validation loss: 2.3837818202152046

Epoch: 5| Step: 6
Training loss: 2.8994340896606445
Validation loss: 2.378662960503691

Epoch: 5| Step: 7
Training loss: 2.7336339950561523
Validation loss: 2.378598141413863

Epoch: 5| Step: 8
Training loss: 2.2524666786193848
Validation loss: 2.385656249138617

Epoch: 5| Step: 9
Training loss: 2.7550461292266846
Validation loss: 2.3870263766216975

Epoch: 5| Step: 10
Training loss: 2.9264962673187256
Validation loss: 2.4180091170854467

Epoch: 100| Step: 0
Training loss: 2.0612289905548096
Validation loss: 2.4205223052732405

Epoch: 5| Step: 1
Training loss: 1.941983938217163
Validation loss: 2.435134377530826

Epoch: 5| Step: 2
Training loss: 3.1570088863372803
Validation loss: 2.42127550032831

Epoch: 5| Step: 3
Training loss: 2.32436203956604
Validation loss: 2.4159304557308072

Epoch: 5| Step: 4
Training loss: 2.5749220848083496
Validation loss: 2.430817929647302

Epoch: 5| Step: 5
Training loss: 2.7018256187438965
Validation loss: 2.437486684450539

Epoch: 5| Step: 6
Training loss: 2.848665237426758
Validation loss: 2.4296609124829693

Epoch: 5| Step: 7
Training loss: 2.6115310192108154
Validation loss: 2.4286172518166165

Epoch: 5| Step: 8
Training loss: 2.2933249473571777
Validation loss: 2.415237029393514

Epoch: 5| Step: 9
Training loss: 3.30122447013855
Validation loss: 2.403005648684758

Epoch: 5| Step: 10
Training loss: 3.087973117828369
Validation loss: 2.3860791908797396

Epoch: 101| Step: 0
Training loss: 3.2767748832702637
Validation loss: 2.377980670621318

Epoch: 5| Step: 1
Training loss: 2.59100604057312
Validation loss: 2.3773843011548443

Epoch: 5| Step: 2
Training loss: 2.6062233448028564
Validation loss: 2.3812039488105365

Epoch: 5| Step: 3
Training loss: 2.1336662769317627
Validation loss: 2.393454808060841

Epoch: 5| Step: 4
Training loss: 2.3482871055603027
Validation loss: 2.399981748673224

Epoch: 5| Step: 5
Training loss: 2.4443233013153076
Validation loss: 2.4120784113484044

Epoch: 5| Step: 6
Training loss: 2.8270506858825684
Validation loss: 2.406145265025477

Epoch: 5| Step: 7
Training loss: 2.6415228843688965
Validation loss: 2.3969342772678663

Epoch: 5| Step: 8
Training loss: 2.5403761863708496
Validation loss: 2.3812758961031513

Epoch: 5| Step: 9
Training loss: 2.578439235687256
Validation loss: 2.3770253555749052

Epoch: 5| Step: 10
Training loss: 2.6784417629241943
Validation loss: 2.37651055089889

Epoch: 102| Step: 0
Training loss: 2.4060845375061035
Validation loss: 2.3748124748147945

Epoch: 5| Step: 1
Training loss: 2.5618844032287598
Validation loss: 2.377302885055542

Epoch: 5| Step: 2
Training loss: 2.8402934074401855
Validation loss: 2.370299954568186

Epoch: 5| Step: 3
Training loss: 3.3382773399353027
Validation loss: 2.375196341545351

Epoch: 5| Step: 4
Training loss: 2.6887965202331543
Validation loss: 2.3738462489138366

Epoch: 5| Step: 5
Training loss: 2.197187900543213
Validation loss: 2.376379156625399

Epoch: 5| Step: 6
Training loss: 3.0359702110290527
Validation loss: 2.3816365836769022

Epoch: 5| Step: 7
Training loss: 2.112332820892334
Validation loss: 2.3900218138130764

Epoch: 5| Step: 8
Training loss: 2.708148241043091
Validation loss: 2.397511068210807

Epoch: 5| Step: 9
Training loss: 2.378180980682373
Validation loss: 2.406271508944932

Epoch: 5| Step: 10
Training loss: 2.332893133163452
Validation loss: 2.428083978673463

Epoch: 103| Step: 0
Training loss: 2.426135540008545
Validation loss: 2.4236040961357856

Epoch: 5| Step: 1
Training loss: 2.6595711708068848
Validation loss: 2.422066278355096

Epoch: 5| Step: 2
Training loss: 1.9859981536865234
Validation loss: 2.422437614010226

Epoch: 5| Step: 3
Training loss: 2.9840874671936035
Validation loss: 2.416371072492292

Epoch: 5| Step: 4
Training loss: 2.3418049812316895
Validation loss: 2.414771620945264

Epoch: 5| Step: 5
Training loss: 2.2723960876464844
Validation loss: 2.4082247467451197

Epoch: 5| Step: 6
Training loss: 2.42258358001709
Validation loss: 2.409955722029491

Epoch: 5| Step: 7
Training loss: 3.3139617443084717
Validation loss: 2.4175378661001883

Epoch: 5| Step: 8
Training loss: 2.5709705352783203
Validation loss: 2.4023595163899083

Epoch: 5| Step: 9
Training loss: 2.80410099029541
Validation loss: 2.402306277264831

Epoch: 5| Step: 10
Training loss: 2.8751261234283447
Validation loss: 2.3922384682522027

Epoch: 104| Step: 0
Training loss: 2.541719675064087
Validation loss: 2.3851870400931245

Epoch: 5| Step: 1
Training loss: 2.998750686645508
Validation loss: 2.3839940101869646

Epoch: 5| Step: 2
Training loss: 1.8431510925292969
Validation loss: 2.389067662659512

Epoch: 5| Step: 3
Training loss: 3.1051135063171387
Validation loss: 2.389251985857564

Epoch: 5| Step: 4
Training loss: 2.843413829803467
Validation loss: 2.3908689329701085

Epoch: 5| Step: 5
Training loss: 3.00392484664917
Validation loss: 2.3927761226572017

Epoch: 5| Step: 6
Training loss: 2.105416774749756
Validation loss: 2.3815003953954226

Epoch: 5| Step: 7
Training loss: 2.439798355102539
Validation loss: 2.378725964535949

Epoch: 5| Step: 8
Training loss: 2.541410446166992
Validation loss: 2.383301773378926

Epoch: 5| Step: 9
Training loss: 2.7313318252563477
Validation loss: 2.378981823562294

Epoch: 5| Step: 10
Training loss: 2.505777359008789
Validation loss: 2.364038472534508

Epoch: 105| Step: 0
Training loss: 2.1297805309295654
Validation loss: 2.365207055563568

Epoch: 5| Step: 1
Training loss: 2.2706542015075684
Validation loss: 2.367907142126432

Epoch: 5| Step: 2
Training loss: 2.9292163848876953
Validation loss: 2.3775164363204793

Epoch: 5| Step: 3
Training loss: 2.4711132049560547
Validation loss: 2.380403262312694

Epoch: 5| Step: 4
Training loss: 2.6344542503356934
Validation loss: 2.3793521952885452

Epoch: 5| Step: 5
Training loss: 2.221034288406372
Validation loss: 2.376527440163397

Epoch: 5| Step: 6
Training loss: 2.0886566638946533
Validation loss: 2.3648236874611146

Epoch: 5| Step: 7
Training loss: 2.8508167266845703
Validation loss: 2.3561293719917216

Epoch: 5| Step: 8
Training loss: 3.62394380569458
Validation loss: 2.3487430336654826

Epoch: 5| Step: 9
Training loss: 2.442600727081299
Validation loss: 2.3457595994395595

Epoch: 5| Step: 10
Training loss: 3.14367938041687
Validation loss: 2.3513993447826755

Epoch: 106| Step: 0
Training loss: 2.383251667022705
Validation loss: 2.3472012473690893

Epoch: 5| Step: 1
Training loss: 3.2070717811584473
Validation loss: 2.3504240205211024

Epoch: 5| Step: 2
Training loss: 2.738649845123291
Validation loss: 2.353620477901992

Epoch: 5| Step: 3
Training loss: 2.406655788421631
Validation loss: 2.3535244131600983

Epoch: 5| Step: 4
Training loss: 2.458824634552002
Validation loss: 2.3577599986906974

Epoch: 5| Step: 5
Training loss: 2.6218819618225098
Validation loss: 2.354815408747683

Epoch: 5| Step: 6
Training loss: 2.1926417350769043
Validation loss: 2.3644101440265612

Epoch: 5| Step: 7
Training loss: 2.664855480194092
Validation loss: 2.366415418604369

Epoch: 5| Step: 8
Training loss: 2.4547648429870605
Validation loss: 2.3677562257295013

Epoch: 5| Step: 9
Training loss: 2.104435443878174
Validation loss: 2.3732419911251275

Epoch: 5| Step: 10
Training loss: 3.5215628147125244
Validation loss: 2.3857139643802436

Epoch: 107| Step: 0
Training loss: 2.967919111251831
Validation loss: 2.3909143068457164

Epoch: 5| Step: 1
Training loss: 2.0095438957214355
Validation loss: 2.391231313828499

Epoch: 5| Step: 2
Training loss: 2.673402786254883
Validation loss: 2.3921532207919705

Epoch: 5| Step: 3
Training loss: 2.8709781169891357
Validation loss: 2.399505526788773

Epoch: 5| Step: 4
Training loss: 2.135765314102173
Validation loss: 2.397218188931865

Epoch: 5| Step: 5
Training loss: 2.184556484222412
Validation loss: 2.3990569422321935

Epoch: 5| Step: 6
Training loss: 3.227036237716675
Validation loss: 2.3962994467827583

Epoch: 5| Step: 7
Training loss: 2.3785996437072754
Validation loss: 2.379729414498934

Epoch: 5| Step: 8
Training loss: 2.5239648818969727
Validation loss: 2.385761971114784

Epoch: 5| Step: 9
Training loss: 2.86830472946167
Validation loss: 2.3811226737114692

Epoch: 5| Step: 10
Training loss: 2.6409130096435547
Validation loss: 2.3701260602602394

Epoch: 108| Step: 0
Training loss: 2.967386245727539
Validation loss: 2.3829119769475793

Epoch: 5| Step: 1
Training loss: 1.8326934576034546
Validation loss: 2.3857670189231954

Epoch: 5| Step: 2
Training loss: 2.669229030609131
Validation loss: 2.3897125977341847

Epoch: 5| Step: 3
Training loss: 2.688333749771118
Validation loss: 2.3873334597515803

Epoch: 5| Step: 4
Training loss: 2.720757007598877
Validation loss: 2.384241629672307

Epoch: 5| Step: 5
Training loss: 3.035562038421631
Validation loss: 2.3802227307391424

Epoch: 5| Step: 6
Training loss: 2.164616823196411
Validation loss: 2.380715339414535

Epoch: 5| Step: 7
Training loss: 2.912728786468506
Validation loss: 2.3799508489588255

Epoch: 5| Step: 8
Training loss: 1.8554893732070923
Validation loss: 2.381843736094813

Epoch: 5| Step: 9
Training loss: 3.427218198776245
Validation loss: 2.3947582834510395

Epoch: 5| Step: 10
Training loss: 2.2060561180114746
Validation loss: 2.395166543222243

Epoch: 109| Step: 0
Training loss: 2.1048569679260254
Validation loss: 2.3918468593269266

Epoch: 5| Step: 1
Training loss: 2.679157018661499
Validation loss: 2.389067267858854

Epoch: 5| Step: 2
Training loss: 2.282127857208252
Validation loss: 2.370551029841105

Epoch: 5| Step: 3
Training loss: 2.022648334503174
Validation loss: 2.3676543825416156

Epoch: 5| Step: 4
Training loss: 2.8360111713409424
Validation loss: 2.3677760144715667

Epoch: 5| Step: 5
Training loss: 2.686938524246216
Validation loss: 2.369651150959794

Epoch: 5| Step: 6
Training loss: 2.792332410812378
Validation loss: 2.377132192734749

Epoch: 5| Step: 7
Training loss: 2.099888324737549
Validation loss: 2.3855986492608183

Epoch: 5| Step: 8
Training loss: 2.7089486122131348
Validation loss: 2.3948557863953295

Epoch: 5| Step: 9
Training loss: 3.257544994354248
Validation loss: 2.3997172386415544

Epoch: 5| Step: 10
Training loss: 3.0773074626922607
Validation loss: 2.396462009799096

Epoch: 110| Step: 0
Training loss: 2.4372897148132324
Validation loss: 2.385951695903655

Epoch: 5| Step: 1
Training loss: 2.8298721313476562
Validation loss: 2.383066367077571

Epoch: 5| Step: 2
Training loss: 2.7296650409698486
Validation loss: 2.375051584295047

Epoch: 5| Step: 3
Training loss: 2.35902738571167
Validation loss: 2.383845352357434

Epoch: 5| Step: 4
Training loss: 1.9994323253631592
Validation loss: 2.380085055546094

Epoch: 5| Step: 5
Training loss: 2.1593027114868164
Validation loss: 2.3805120504030617

Epoch: 5| Step: 6
Training loss: 2.683877944946289
Validation loss: 2.3903175246331

Epoch: 5| Step: 7
Training loss: 2.571489095687866
Validation loss: 2.3972956647155104

Epoch: 5| Step: 8
Training loss: 2.856301784515381
Validation loss: 2.4047129128568914

Epoch: 5| Step: 9
Training loss: 3.461817502975464
Validation loss: 2.4125715173700804

Epoch: 5| Step: 10
Training loss: 2.247819423675537
Validation loss: 2.4321916821182414

Epoch: 111| Step: 0
Training loss: 2.4018547534942627
Validation loss: 2.4402632841499905

Epoch: 5| Step: 1
Training loss: 2.430332660675049
Validation loss: 2.463003730261198

Epoch: 5| Step: 2
Training loss: 2.649426221847534
Validation loss: 2.4588266495735414

Epoch: 5| Step: 3
Training loss: 2.426490306854248
Validation loss: 2.4649284937048472

Epoch: 5| Step: 4
Training loss: 2.1028823852539062
Validation loss: 2.4695409138997397

Epoch: 5| Step: 5
Training loss: 2.589653968811035
Validation loss: 2.460878574719993

Epoch: 5| Step: 6
Training loss: 2.929443359375
Validation loss: 2.464055363849927

Epoch: 5| Step: 7
Training loss: 3.0617027282714844
Validation loss: 2.466211877843385

Epoch: 5| Step: 8
Training loss: 2.8564600944519043
Validation loss: 2.4484249878955144

Epoch: 5| Step: 9
Training loss: 2.901411533355713
Validation loss: 2.4371005412070983

Epoch: 5| Step: 10
Training loss: 2.410951614379883
Validation loss: 2.4217313874152397

Epoch: 112| Step: 0
Training loss: 2.127653121948242
Validation loss: 2.401513466271021

Epoch: 5| Step: 1
Training loss: 2.926203489303589
Validation loss: 2.4114289950299006

Epoch: 5| Step: 2
Training loss: 2.5852837562561035
Validation loss: 2.400402392110517

Epoch: 5| Step: 3
Training loss: 2.1860108375549316
Validation loss: 2.390829743877534

Epoch: 5| Step: 4
Training loss: 2.7039902210235596
Validation loss: 2.375719480617072

Epoch: 5| Step: 5
Training loss: 1.8662559986114502
Validation loss: 2.3643509085460375

Epoch: 5| Step: 6
Training loss: 2.5712153911590576
Validation loss: 2.359260871846189

Epoch: 5| Step: 7
Training loss: 2.186391592025757
Validation loss: 2.364421529154624

Epoch: 5| Step: 8
Training loss: 2.8567185401916504
Validation loss: 2.364745145202965

Epoch: 5| Step: 9
Training loss: 3.5662708282470703
Validation loss: 2.3717165044558945

Epoch: 5| Step: 10
Training loss: 2.852661371231079
Validation loss: 2.3757627151345693

Epoch: 113| Step: 0
Training loss: 2.6436896324157715
Validation loss: 2.367189925204041

Epoch: 5| Step: 1
Training loss: 2.3482117652893066
Validation loss: 2.355433105140604

Epoch: 5| Step: 2
Training loss: 2.6278719902038574
Validation loss: 2.3484175538503997

Epoch: 5| Step: 3
Training loss: 2.9827442169189453
Validation loss: 2.345069323816607

Epoch: 5| Step: 4
Training loss: 2.3393945693969727
Validation loss: 2.338192709030644

Epoch: 5| Step: 5
Training loss: 2.2812952995300293
Validation loss: 2.342555308854708

Epoch: 5| Step: 6
Training loss: 2.7197022438049316
Validation loss: 2.352696334162066

Epoch: 5| Step: 7
Training loss: 2.525806427001953
Validation loss: 2.35640376101258

Epoch: 5| Step: 8
Training loss: 2.6781530380249023
Validation loss: 2.366618110287574

Epoch: 5| Step: 9
Training loss: 2.3739521503448486
Validation loss: 2.3618646667849634

Epoch: 5| Step: 10
Training loss: 3.091062068939209
Validation loss: 2.348450409468784

Epoch: 114| Step: 0
Training loss: 2.5711350440979004
Validation loss: 2.34744401900999

Epoch: 5| Step: 1
Training loss: 2.130608558654785
Validation loss: 2.3463375145389187

Epoch: 5| Step: 2
Training loss: 2.272005558013916
Validation loss: 2.3444760255916144

Epoch: 5| Step: 3
Training loss: 2.3218164443969727
Validation loss: 2.345931481289607

Epoch: 5| Step: 4
Training loss: 2.110095500946045
Validation loss: 2.35081567559191

Epoch: 5| Step: 5
Training loss: 3.483614444732666
Validation loss: 2.35062740695092

Epoch: 5| Step: 6
Training loss: 2.5225818157196045
Validation loss: 2.345009060316188

Epoch: 5| Step: 7
Training loss: 2.5710015296936035
Validation loss: 2.3481276548036965

Epoch: 5| Step: 8
Training loss: 2.6640219688415527
Validation loss: 2.343211479084466

Epoch: 5| Step: 9
Training loss: 2.527526378631592
Validation loss: 2.354313096692485

Epoch: 5| Step: 10
Training loss: 3.2631003856658936
Validation loss: 2.3663202255002913

Epoch: 115| Step: 0
Training loss: 2.206953763961792
Validation loss: 2.360272794641474

Epoch: 5| Step: 1
Training loss: 2.9168665409088135
Validation loss: 2.3513026904034358

Epoch: 5| Step: 2
Training loss: 2.3184571266174316
Validation loss: 2.3434833326647357

Epoch: 5| Step: 3
Training loss: 2.4497125148773193
Validation loss: 2.3410111729816725

Epoch: 5| Step: 4
Training loss: 2.3035027980804443
Validation loss: 2.339287006726829

Epoch: 5| Step: 5
Training loss: 2.9210500717163086
Validation loss: 2.339570576144803

Epoch: 5| Step: 6
Training loss: 2.7653610706329346
Validation loss: 2.3550928997737106

Epoch: 5| Step: 7
Training loss: 2.2213315963745117
Validation loss: 2.365710622520857

Epoch: 5| Step: 8
Training loss: 2.776245594024658
Validation loss: 2.3833993839961227

Epoch: 5| Step: 9
Training loss: 2.8985841274261475
Validation loss: 2.3877473569685415

Epoch: 5| Step: 10
Training loss: 2.5582566261291504
Validation loss: 2.3933964057635237

Epoch: 116| Step: 0
Training loss: 2.645932197570801
Validation loss: 2.4177625486927647

Epoch: 5| Step: 1
Training loss: 2.4547410011291504
Validation loss: 2.407253647363314

Epoch: 5| Step: 2
Training loss: 2.7795193195343018
Validation loss: 2.3909594961391982

Epoch: 5| Step: 3
Training loss: 1.670830488204956
Validation loss: 2.3771500946373068

Epoch: 5| Step: 4
Training loss: 2.4470467567443848
Validation loss: 2.3667328921697472

Epoch: 5| Step: 5
Training loss: 2.496833086013794
Validation loss: 2.3647341882028887

Epoch: 5| Step: 6
Training loss: 3.1903023719787598
Validation loss: 2.368724469215639

Epoch: 5| Step: 7
Training loss: 2.7080044746398926
Validation loss: 2.3722805951231267

Epoch: 5| Step: 8
Training loss: 2.687854290008545
Validation loss: 2.3734714677256923

Epoch: 5| Step: 9
Training loss: 3.1284611225128174
Validation loss: 2.3637140233029603

Epoch: 5| Step: 10
Training loss: 2.117483139038086
Validation loss: 2.3540473266314437

Epoch: 117| Step: 0
Training loss: 2.4916419982910156
Validation loss: 2.353827320119386

Epoch: 5| Step: 1
Training loss: 2.4358322620391846
Validation loss: 2.355422991578297

Epoch: 5| Step: 2
Training loss: 3.032606601715088
Validation loss: 2.35146822467927

Epoch: 5| Step: 3
Training loss: 2.6185717582702637
Validation loss: 2.339477321153046

Epoch: 5| Step: 4
Training loss: 2.717355489730835
Validation loss: 2.3313098748524985

Epoch: 5| Step: 5
Training loss: 2.459089756011963
Validation loss: 2.3285473751765426

Epoch: 5| Step: 6
Training loss: 3.026623010635376
Validation loss: 2.338299092426095

Epoch: 5| Step: 7
Training loss: 2.0318424701690674
Validation loss: 2.340562366670178

Epoch: 5| Step: 8
Training loss: 2.2875614166259766
Validation loss: 2.3360833557703162

Epoch: 5| Step: 9
Training loss: 2.5684356689453125
Validation loss: 2.336792725388722

Epoch: 5| Step: 10
Training loss: 2.610639810562134
Validation loss: 2.3373042973138953

Epoch: 118| Step: 0
Training loss: 2.3077492713928223
Validation loss: 2.3429684946613927

Epoch: 5| Step: 1
Training loss: 3.4616236686706543
Validation loss: 2.3453433385459324

Epoch: 5| Step: 2
Training loss: 2.582230806350708
Validation loss: 2.338736170081682

Epoch: 5| Step: 3
Training loss: 2.8952698707580566
Validation loss: 2.3324562580354753

Epoch: 5| Step: 4
Training loss: 2.5601611137390137
Validation loss: 2.324767412677888

Epoch: 5| Step: 5
Training loss: 2.6607608795166016
Validation loss: 2.3339149336661063

Epoch: 5| Step: 6
Training loss: 1.4213632345199585
Validation loss: 2.343696886493314

Epoch: 5| Step: 7
Training loss: 2.8061580657958984
Validation loss: 2.3494253517479025

Epoch: 5| Step: 8
Training loss: 2.6020283699035645
Validation loss: 2.3441789944966636

Epoch: 5| Step: 9
Training loss: 2.8922882080078125
Validation loss: 2.3470770159075336

Epoch: 5| Step: 10
Training loss: 1.9202508926391602
Validation loss: 2.3512296958636214

Epoch: 119| Step: 0
Training loss: 2.486051082611084
Validation loss: 2.3607613348191783

Epoch: 5| Step: 1
Training loss: 2.814406156539917
Validation loss: 2.354068535630421

Epoch: 5| Step: 2
Training loss: 2.741133689880371
Validation loss: 2.3647708918458674

Epoch: 5| Step: 3
Training loss: 2.5148160457611084
Validation loss: 2.3537569994567544

Epoch: 5| Step: 4
Training loss: 2.566532611846924
Validation loss: 2.3496955440890406

Epoch: 5| Step: 5
Training loss: 2.1065211296081543
Validation loss: 2.339790810820877

Epoch: 5| Step: 6
Training loss: 2.6628308296203613
Validation loss: 2.330307729782597

Epoch: 5| Step: 7
Training loss: 2.8255538940429688
Validation loss: 2.3343776477280485

Epoch: 5| Step: 8
Training loss: 2.1715426445007324
Validation loss: 2.3258414935040217

Epoch: 5| Step: 9
Training loss: 3.1733264923095703
Validation loss: 2.336396799292616

Epoch: 5| Step: 10
Training loss: 1.9460469484329224
Validation loss: 2.3422482064975205

Epoch: 120| Step: 0
Training loss: 2.060012102127075
Validation loss: 2.3447994673123924

Epoch: 5| Step: 1
Training loss: 2.202211618423462
Validation loss: 2.3546969172775105

Epoch: 5| Step: 2
Training loss: 2.844507932662964
Validation loss: 2.3603478529120006

Epoch: 5| Step: 3
Training loss: 2.5372674465179443
Validation loss: 2.3557917277018228

Epoch: 5| Step: 4
Training loss: 2.9108710289001465
Validation loss: 2.355246284956573

Epoch: 5| Step: 5
Training loss: 2.7014873027801514
Validation loss: 2.3566344989243375

Epoch: 5| Step: 6
Training loss: 2.678765058517456
Validation loss: 2.3626298827509724

Epoch: 5| Step: 7
Training loss: 2.501122236251831
Validation loss: 2.367111690582768

Epoch: 5| Step: 8
Training loss: 2.1249990463256836
Validation loss: 2.3625651431340042

Epoch: 5| Step: 9
Training loss: 2.524514675140381
Validation loss: 2.3708545700196297

Epoch: 5| Step: 10
Training loss: 3.2153775691986084
Validation loss: 2.352132219140248

Epoch: 121| Step: 0
Training loss: 2.749403953552246
Validation loss: 2.3447660553839897

Epoch: 5| Step: 1
Training loss: 2.273035764694214
Validation loss: 2.3390250693085375

Epoch: 5| Step: 2
Training loss: 2.4931061267852783
Validation loss: 2.327688201781242

Epoch: 5| Step: 3
Training loss: 2.797356128692627
Validation loss: 2.3254571396817445

Epoch: 5| Step: 4
Training loss: 2.684537410736084
Validation loss: 2.3181691887558147

Epoch: 5| Step: 5
Training loss: 3.3851215839385986
Validation loss: 2.3143300189766833

Epoch: 5| Step: 6
Training loss: 2.203321933746338
Validation loss: 2.3151021490814867

Epoch: 5| Step: 7
Training loss: 1.6903917789459229
Validation loss: 2.319870097662813

Epoch: 5| Step: 8
Training loss: 2.662194013595581
Validation loss: 2.329504423244025

Epoch: 5| Step: 9
Training loss: 2.5459792613983154
Validation loss: 2.3323529253723803

Epoch: 5| Step: 10
Training loss: 2.714568614959717
Validation loss: 2.3415583077297417

Epoch: 122| Step: 0
Training loss: 2.606348752975464
Validation loss: 2.348474689709243

Epoch: 5| Step: 1
Training loss: 2.2263360023498535
Validation loss: 2.3417130490785003

Epoch: 5| Step: 2
Training loss: 2.6649491786956787
Validation loss: 2.3382701412323983

Epoch: 5| Step: 3
Training loss: 2.5851447582244873
Validation loss: 2.334788150684808

Epoch: 5| Step: 4
Training loss: 3.195438861846924
Validation loss: 2.3365445419024398

Epoch: 5| Step: 5
Training loss: 2.645094156265259
Validation loss: 2.3445284571698917

Epoch: 5| Step: 6
Training loss: 3.1286661624908447
Validation loss: 2.3473616646182154

Epoch: 5| Step: 7
Training loss: 2.4093968868255615
Validation loss: 2.3475971016832577

Epoch: 5| Step: 8
Training loss: 2.878934383392334
Validation loss: 2.352198403368714

Epoch: 5| Step: 9
Training loss: 1.5493792295455933
Validation loss: 2.359364019927158

Epoch: 5| Step: 10
Training loss: 2.094425678253174
Validation loss: 2.3652062800622757

Epoch: 123| Step: 0
Training loss: 2.680683135986328
Validation loss: 2.34738859053581

Epoch: 5| Step: 1
Training loss: 2.074345827102661
Validation loss: 2.342986504236857

Epoch: 5| Step: 2
Training loss: 3.188965320587158
Validation loss: 2.332245688284597

Epoch: 5| Step: 3
Training loss: 1.9945363998413086
Validation loss: 2.3315116269614107

Epoch: 5| Step: 4
Training loss: 2.160914897918701
Validation loss: 2.3423786829876643

Epoch: 5| Step: 5
Training loss: 3.0226755142211914
Validation loss: 2.3420114158302225

Epoch: 5| Step: 6
Training loss: 2.1301980018615723
Validation loss: 2.3481423316463346

Epoch: 5| Step: 7
Training loss: 3.066380739212036
Validation loss: 2.355584593229396

Epoch: 5| Step: 8
Training loss: 2.2748990058898926
Validation loss: 2.357385916094626

Epoch: 5| Step: 9
Training loss: 2.4904897212982178
Validation loss: 2.3599560491500364

Epoch: 5| Step: 10
Training loss: 2.9627039432525635
Validation loss: 2.356179457838817

Epoch: 124| Step: 0
Training loss: 2.668919801712036
Validation loss: 2.357875672719812

Epoch: 5| Step: 1
Training loss: 2.775238037109375
Validation loss: 2.350556545360114

Epoch: 5| Step: 2
Training loss: 2.5042099952697754
Validation loss: 2.3382547414431007

Epoch: 5| Step: 3
Training loss: 2.9422385692596436
Validation loss: 2.3387199140364126

Epoch: 5| Step: 4
Training loss: 2.269357204437256
Validation loss: 2.3286028677417385

Epoch: 5| Step: 5
Training loss: 2.6954140663146973
Validation loss: 2.3323658076665734

Epoch: 5| Step: 6
Training loss: 2.811793565750122
Validation loss: 2.327913499647571

Epoch: 5| Step: 7
Training loss: 1.961660623550415
Validation loss: 2.3354777366884294

Epoch: 5| Step: 8
Training loss: 2.255870819091797
Validation loss: 2.325839783555718

Epoch: 5| Step: 9
Training loss: 2.782015323638916
Validation loss: 2.336439965873636

Epoch: 5| Step: 10
Training loss: 2.2670114040374756
Validation loss: 2.3281752422291744

Epoch: 125| Step: 0
Training loss: 2.974092960357666
Validation loss: 2.3292299803867134

Epoch: 5| Step: 1
Training loss: 2.880688190460205
Validation loss: 2.3349285946097424

Epoch: 5| Step: 2
Training loss: 2.376291036605835
Validation loss: 2.3446643993418705

Epoch: 5| Step: 3
Training loss: 2.2846012115478516
Validation loss: 2.339387083566317

Epoch: 5| Step: 4
Training loss: 1.8680779933929443
Validation loss: 2.3400511152000836

Epoch: 5| Step: 5
Training loss: 2.5087852478027344
Validation loss: 2.3463044576747443

Epoch: 5| Step: 6
Training loss: 2.5117855072021484
Validation loss: 2.3520804656449186

Epoch: 5| Step: 7
Training loss: 2.678626775741577
Validation loss: 2.348136430145592

Epoch: 5| Step: 8
Training loss: 2.6287906169891357
Validation loss: 2.3319025501128166

Epoch: 5| Step: 9
Training loss: 3.1632308959960938
Validation loss: 2.327594131551763

Epoch: 5| Step: 10
Training loss: 1.9835920333862305
Validation loss: 2.327301653482581

Epoch: 126| Step: 0
Training loss: 1.8182342052459717
Validation loss: 2.3313270691902406

Epoch: 5| Step: 1
Training loss: 2.184204339981079
Validation loss: 2.3378756764114543

Epoch: 5| Step: 2
Training loss: 2.2263553142547607
Validation loss: 2.346872250239054

Epoch: 5| Step: 3
Training loss: 3.649932861328125
Validation loss: 2.3457293818073888

Epoch: 5| Step: 4
Training loss: 2.7451486587524414
Validation loss: 2.341565680760209

Epoch: 5| Step: 5
Training loss: 2.7209243774414062
Validation loss: 2.3339376411130353

Epoch: 5| Step: 6
Training loss: 2.217529296875
Validation loss: 2.331252674902639

Epoch: 5| Step: 7
Training loss: 2.6408731937408447
Validation loss: 2.3428567660752164

Epoch: 5| Step: 8
Training loss: 2.5054383277893066
Validation loss: 2.3476710075973184

Epoch: 5| Step: 9
Training loss: 2.696072816848755
Validation loss: 2.364933242080032

Epoch: 5| Step: 10
Training loss: 2.5574305057525635
Validation loss: 2.36101592997069

Epoch: 127| Step: 0
Training loss: 1.8932783603668213
Validation loss: 2.338445463488179

Epoch: 5| Step: 1
Training loss: 2.1586384773254395
Validation loss: 2.32942117926895

Epoch: 5| Step: 2
Training loss: 2.6879160404205322
Validation loss: 2.3222929495637135

Epoch: 5| Step: 3
Training loss: 2.599348783493042
Validation loss: 2.3286817971096245

Epoch: 5| Step: 4
Training loss: 2.5761258602142334
Validation loss: 2.3238226803400184

Epoch: 5| Step: 5
Training loss: 3.1477303504943848
Validation loss: 2.3257878852146927

Epoch: 5| Step: 6
Training loss: 1.8920844793319702
Validation loss: 2.3329219254114295

Epoch: 5| Step: 7
Training loss: 2.3775882720947266
Validation loss: 2.33108111094403

Epoch: 5| Step: 8
Training loss: 2.8266677856445312
Validation loss: 2.3300859928131104

Epoch: 5| Step: 9
Training loss: 2.68538236618042
Validation loss: 2.333108486667756

Epoch: 5| Step: 10
Training loss: 3.04504656791687
Validation loss: 2.3339168076874106

Epoch: 128| Step: 0
Training loss: 2.197821855545044
Validation loss: 2.339598068626978

Epoch: 5| Step: 1
Training loss: 2.8624541759490967
Validation loss: 2.331404511646558

Epoch: 5| Step: 2
Training loss: 2.3256449699401855
Validation loss: 2.333208527616275

Epoch: 5| Step: 3
Training loss: 2.0583302974700928
Validation loss: 2.3291787767923005

Epoch: 5| Step: 4
Training loss: 2.4055848121643066
Validation loss: 2.3283411661783853

Epoch: 5| Step: 5
Training loss: 3.2918498516082764
Validation loss: 2.322408050619146

Epoch: 5| Step: 6
Training loss: 3.0256335735321045
Validation loss: 2.324232315504423

Epoch: 5| Step: 7
Training loss: 2.307908296585083
Validation loss: 2.3225517337040236

Epoch: 5| Step: 8
Training loss: 2.4715704917907715
Validation loss: 2.3185427445237354

Epoch: 5| Step: 9
Training loss: 2.6963908672332764
Validation loss: 2.3187481357205297

Epoch: 5| Step: 10
Training loss: 2.07791805267334
Validation loss: 2.317384296847928

Epoch: 129| Step: 0
Training loss: 2.7035300731658936
Validation loss: 2.3144765054025958

Epoch: 5| Step: 1
Training loss: 2.6279523372650146
Validation loss: 2.308809817478221

Epoch: 5| Step: 2
Training loss: 2.7767751216888428
Validation loss: 2.3215042365494596

Epoch: 5| Step: 3
Training loss: 2.475916624069214
Validation loss: 2.326329802954069

Epoch: 5| Step: 4
Training loss: 2.8229517936706543
Validation loss: 2.3192761713458645

Epoch: 5| Step: 5
Training loss: 2.05399227142334
Validation loss: 2.322567806448988

Epoch: 5| Step: 6
Training loss: 3.180532217025757
Validation loss: 2.322144518616379

Epoch: 5| Step: 7
Training loss: 1.9834043979644775
Validation loss: 2.3222032593142603

Epoch: 5| Step: 8
Training loss: 2.5306055545806885
Validation loss: 2.31174728690937

Epoch: 5| Step: 9
Training loss: 2.0514094829559326
Validation loss: 2.309874350024808

Epoch: 5| Step: 10
Training loss: 2.6087210178375244
Validation loss: 2.3111006598318777

Epoch: 130| Step: 0
Training loss: 2.5619349479675293
Validation loss: 2.3057309991569928

Epoch: 5| Step: 1
Training loss: 2.2160375118255615
Validation loss: 2.3171746141167096

Epoch: 5| Step: 2
Training loss: 2.3145060539245605
Validation loss: 2.32766390872258

Epoch: 5| Step: 3
Training loss: 3.1115057468414307
Validation loss: 2.335732711258755

Epoch: 5| Step: 4
Training loss: 3.0155513286590576
Validation loss: 2.3299911970733316

Epoch: 5| Step: 5
Training loss: 2.834102153778076
Validation loss: 2.3311976309745543

Epoch: 5| Step: 6
Training loss: 2.845900774002075
Validation loss: 2.3240233031652306

Epoch: 5| Step: 7
Training loss: 2.200050115585327
Validation loss: 2.327814922537855

Epoch: 5| Step: 8
Training loss: 2.0876035690307617
Validation loss: 2.3430053905774186

Epoch: 5| Step: 9
Training loss: 2.3155243396759033
Validation loss: 2.3764131979275773

Epoch: 5| Step: 10
Training loss: 2.3479044437408447
Validation loss: 2.3920590774987334

Epoch: 131| Step: 0
Training loss: 2.514399528503418
Validation loss: 2.3791743465649184

Epoch: 5| Step: 1
Training loss: 2.4564006328582764
Validation loss: 2.3691452856986754

Epoch: 5| Step: 2
Training loss: 2.158060312271118
Validation loss: 2.3342862206120647

Epoch: 5| Step: 3
Training loss: 3.1004180908203125
Validation loss: 2.317938050916118

Epoch: 5| Step: 4
Training loss: 2.1554276943206787
Validation loss: 2.3113605540285826

Epoch: 5| Step: 5
Training loss: 2.8598990440368652
Validation loss: 2.327335775539439

Epoch: 5| Step: 6
Training loss: 2.7406203746795654
Validation loss: 2.342223567347373

Epoch: 5| Step: 7
Training loss: 2.3509490489959717
Validation loss: 2.346340117915984

Epoch: 5| Step: 8
Training loss: 2.849936008453369
Validation loss: 2.3435870473102858

Epoch: 5| Step: 9
Training loss: 2.366321563720703
Validation loss: 2.3417787551879883

Epoch: 5| Step: 10
Training loss: 2.444789171218872
Validation loss: 2.3164750760601414

Epoch: 132| Step: 0
Training loss: 2.3804683685302734
Validation loss: 2.3141718654222387

Epoch: 5| Step: 1
Training loss: 2.4401707649230957
Validation loss: 2.2987424532572427

Epoch: 5| Step: 2
Training loss: 2.8937745094299316
Validation loss: 2.3038067766415176

Epoch: 5| Step: 3
Training loss: 2.1715247631073
Validation loss: 2.296280425081971

Epoch: 5| Step: 4
Training loss: 2.306364059448242
Validation loss: 2.3162909835897465

Epoch: 5| Step: 5
Training loss: 2.215852737426758
Validation loss: 2.330348748032765

Epoch: 5| Step: 6
Training loss: 2.645160675048828
Validation loss: 2.346088799097205

Epoch: 5| Step: 7
Training loss: 3.041456699371338
Validation loss: 2.3540663398722166

Epoch: 5| Step: 8
Training loss: 3.2211098670959473
Validation loss: 2.358739306849818

Epoch: 5| Step: 9
Training loss: 2.1257762908935547
Validation loss: 2.3255900670123357

Epoch: 5| Step: 10
Training loss: 2.448599338531494
Validation loss: 2.326386423521144

Epoch: 133| Step: 0
Training loss: 2.8901736736297607
Validation loss: 2.3152705341257076

Epoch: 5| Step: 1
Training loss: 2.6214776039123535
Validation loss: 2.3281711096404702

Epoch: 5| Step: 2
Training loss: 2.2877304553985596
Validation loss: 2.339334116187147

Epoch: 5| Step: 3
Training loss: 2.9208121299743652
Validation loss: 2.369581832680651

Epoch: 5| Step: 4
Training loss: 2.409682273864746
Validation loss: 2.3826187477316907

Epoch: 5| Step: 5
Training loss: 2.7711644172668457
Validation loss: 2.379734395652689

Epoch: 5| Step: 6
Training loss: 2.9484190940856934
Validation loss: 2.3574556586562947

Epoch: 5| Step: 7
Training loss: 2.421750545501709
Validation loss: 2.3321690354295956

Epoch: 5| Step: 8
Training loss: 2.420508861541748
Validation loss: 2.3131038706789733

Epoch: 5| Step: 9
Training loss: 1.8915414810180664
Validation loss: 2.3060863761491674

Epoch: 5| Step: 10
Training loss: 2.430537462234497
Validation loss: 2.3096896499715824

Epoch: 134| Step: 0
Training loss: 2.2038791179656982
Validation loss: 2.3048452561901462

Epoch: 5| Step: 1
Training loss: 1.6925064325332642
Validation loss: 2.3001509686951995

Epoch: 5| Step: 2
Training loss: 2.6591391563415527
Validation loss: 2.3030583922581007

Epoch: 5| Step: 3
Training loss: 3.012897491455078
Validation loss: 2.303026250613633

Epoch: 5| Step: 4
Training loss: 2.2975289821624756
Validation loss: 2.295616042229437

Epoch: 5| Step: 5
Training loss: 3.0214459896087646
Validation loss: 2.3035918948470906

Epoch: 5| Step: 6
Training loss: 1.9379146099090576
Validation loss: 2.298120408929804

Epoch: 5| Step: 7
Training loss: 2.555820941925049
Validation loss: 2.30254013563997

Epoch: 5| Step: 8
Training loss: 2.979933023452759
Validation loss: 2.3016396017484766

Epoch: 5| Step: 9
Training loss: 2.4825973510742188
Validation loss: 2.306030487501493

Epoch: 5| Step: 10
Training loss: 2.9534311294555664
Validation loss: 2.3014580395913895

Epoch: 135| Step: 0
Training loss: 1.9970706701278687
Validation loss: 2.310425655816191

Epoch: 5| Step: 1
Training loss: 2.6060283184051514
Validation loss: 2.3309078370371172

Epoch: 5| Step: 2
Training loss: 2.521690845489502
Validation loss: 2.3345991180789087

Epoch: 5| Step: 3
Training loss: 2.1592857837677
Validation loss: 2.3480983677730767

Epoch: 5| Step: 4
Training loss: 2.5471255779266357
Validation loss: 2.3460633677821003

Epoch: 5| Step: 5
Training loss: 2.787062168121338
Validation loss: 2.342733536997149

Epoch: 5| Step: 6
Training loss: 2.535912275314331
Validation loss: 2.3473037853035876

Epoch: 5| Step: 7
Training loss: 2.484067916870117
Validation loss: 2.346519826560892

Epoch: 5| Step: 8
Training loss: 2.9607672691345215
Validation loss: 2.3425542052074144

Epoch: 5| Step: 9
Training loss: 2.7499513626098633
Validation loss: 2.339888144564885

Epoch: 5| Step: 10
Training loss: 2.4818296432495117
Validation loss: 2.3389871453726165

Epoch: 136| Step: 0
Training loss: 2.65104079246521
Validation loss: 2.328897797933189

Epoch: 5| Step: 1
Training loss: 3.024949550628662
Validation loss: 2.3199849923451743

Epoch: 5| Step: 2
Training loss: 2.2480480670928955
Validation loss: 2.308232799653084

Epoch: 5| Step: 3
Training loss: 2.2600886821746826
Validation loss: 2.31062162563365

Epoch: 5| Step: 4
Training loss: 2.586033582687378
Validation loss: 2.324075973162087

Epoch: 5| Step: 5
Training loss: 2.314272403717041
Validation loss: 2.3217386225218415

Epoch: 5| Step: 6
Training loss: 2.342141628265381
Validation loss: 2.3213511128579416

Epoch: 5| Step: 7
Training loss: 2.9739766120910645
Validation loss: 2.302953412455897

Epoch: 5| Step: 8
Training loss: 2.262202739715576
Validation loss: 2.308091678927022

Epoch: 5| Step: 9
Training loss: 2.545642614364624
Validation loss: 2.3019764833552863

Epoch: 5| Step: 10
Training loss: 2.4647226333618164
Validation loss: 2.2900185021021033

Epoch: 137| Step: 0
Training loss: 1.9596561193466187
Validation loss: 2.290260955851565

Epoch: 5| Step: 1
Training loss: 2.2549216747283936
Validation loss: 2.286400559127972

Epoch: 5| Step: 2
Training loss: 2.011843204498291
Validation loss: 2.28497435456963

Epoch: 5| Step: 3
Training loss: 2.1287055015563965
Validation loss: 2.286673948328982

Epoch: 5| Step: 4
Training loss: 2.1879241466522217
Validation loss: 2.287606809728889

Epoch: 5| Step: 5
Training loss: 3.029526472091675
Validation loss: 2.2927835295277257

Epoch: 5| Step: 6
Training loss: 2.7643580436706543
Validation loss: 2.293626077713505

Epoch: 5| Step: 7
Training loss: 3.250511884689331
Validation loss: 2.2979693310235136

Epoch: 5| Step: 8
Training loss: 2.6194376945495605
Validation loss: 2.299580133089455

Epoch: 5| Step: 9
Training loss: 2.739375352859497
Validation loss: 2.306414120940752

Epoch: 5| Step: 10
Training loss: 2.5245490074157715
Validation loss: 2.3133668796990507

Epoch: 138| Step: 0
Training loss: 2.726839542388916
Validation loss: 2.327979956903765

Epoch: 5| Step: 1
Training loss: 2.373162031173706
Validation loss: 2.3189189203323854

Epoch: 5| Step: 2
Training loss: 2.60455584526062
Validation loss: 2.330901468953779

Epoch: 5| Step: 3
Training loss: 2.5753941535949707
Validation loss: 2.342396628472113

Epoch: 5| Step: 4
Training loss: 2.316141128540039
Validation loss: 2.3418935216883177

Epoch: 5| Step: 5
Training loss: 2.6681087017059326
Validation loss: 2.342861129391578

Epoch: 5| Step: 6
Training loss: 2.1988494396209717
Validation loss: 2.3421215703410487

Epoch: 5| Step: 7
Training loss: 2.3860716819763184
Validation loss: 2.3495211575620916

Epoch: 5| Step: 8
Training loss: 2.281169891357422
Validation loss: 2.334675032605407

Epoch: 5| Step: 9
Training loss: 3.155670642852783
Validation loss: 2.3244422328087593

Epoch: 5| Step: 10
Training loss: 2.043013095855713
Validation loss: 2.3203503841994912

Epoch: 139| Step: 0
Training loss: 2.0802676677703857
Validation loss: 2.313058494239725

Epoch: 5| Step: 1
Training loss: 2.394869565963745
Validation loss: 2.311931138397545

Epoch: 5| Step: 2
Training loss: 2.7064366340637207
Validation loss: 2.300195404278335

Epoch: 5| Step: 3
Training loss: 2.424204111099243
Validation loss: 2.292411781126453

Epoch: 5| Step: 4
Training loss: 2.399707794189453
Validation loss: 2.285626921602475

Epoch: 5| Step: 5
Training loss: 2.6689887046813965
Validation loss: 2.2761390593744095

Epoch: 5| Step: 6
Training loss: 2.2182090282440186
Validation loss: 2.293917094507525

Epoch: 5| Step: 7
Training loss: 2.4174888134002686
Validation loss: 2.290456912850821

Epoch: 5| Step: 8
Training loss: 3.0600132942199707
Validation loss: 2.2976338119917017

Epoch: 5| Step: 9
Training loss: 2.752697467803955
Validation loss: 2.3120584590460664

Epoch: 5| Step: 10
Training loss: 2.288933277130127
Validation loss: 2.320551146743118

Epoch: 140| Step: 0
Training loss: 1.9664055109024048
Validation loss: 2.3351185334626066

Epoch: 5| Step: 1
Training loss: 1.6966180801391602
Validation loss: 2.330764642325781

Epoch: 5| Step: 2
Training loss: 2.326206684112549
Validation loss: 2.32044889080909

Epoch: 5| Step: 3
Training loss: 2.5413572788238525
Validation loss: 2.318423501906856

Epoch: 5| Step: 4
Training loss: 1.8196344375610352
Validation loss: 2.3029790565531743

Epoch: 5| Step: 5
Training loss: 3.3480401039123535
Validation loss: 2.3025646081534763

Epoch: 5| Step: 6
Training loss: 2.7213988304138184
Validation loss: 2.2954761969145907

Epoch: 5| Step: 7
Training loss: 2.7399914264678955
Validation loss: 2.298440597390616

Epoch: 5| Step: 8
Training loss: 2.700829029083252
Validation loss: 2.2956913722458707

Epoch: 5| Step: 9
Training loss: 2.479858875274658
Validation loss: 2.2967258294423423

Epoch: 5| Step: 10
Training loss: 3.123518705368042
Validation loss: 2.3049528650058213

Epoch: 141| Step: 0
Training loss: 2.600831985473633
Validation loss: 2.3014097649564027

Epoch: 5| Step: 1
Training loss: 2.917832851409912
Validation loss: 2.295105298360189

Epoch: 5| Step: 2
Training loss: 2.544588565826416
Validation loss: 2.2905106467585408

Epoch: 5| Step: 3
Training loss: 2.066178798675537
Validation loss: 2.2856692857639764

Epoch: 5| Step: 4
Training loss: 2.785709857940674
Validation loss: 2.2915517437842583

Epoch: 5| Step: 5
Training loss: 2.5881505012512207
Validation loss: 2.290731350580851

Epoch: 5| Step: 6
Training loss: 2.105329751968384
Validation loss: 2.2860922121232554

Epoch: 5| Step: 7
Training loss: 2.1717631816864014
Validation loss: 2.2872136895374586

Epoch: 5| Step: 8
Training loss: 2.993952989578247
Validation loss: 2.296032710741925

Epoch: 5| Step: 9
Training loss: 2.396790027618408
Validation loss: 2.2893846932277886

Epoch: 5| Step: 10
Training loss: 2.1166067123413086
Validation loss: 2.29063739315156

Epoch: 142| Step: 0
Training loss: 2.7819297313690186
Validation loss: 2.2983752322453324

Epoch: 5| Step: 1
Training loss: 2.1700127124786377
Validation loss: 2.2952851069870817

Epoch: 5| Step: 2
Training loss: 2.6586475372314453
Validation loss: 2.3066709067231868

Epoch: 5| Step: 3
Training loss: 2.392064094543457
Validation loss: 2.303284006734048

Epoch: 5| Step: 4
Training loss: 1.9899890422821045
Validation loss: 2.31618001896848

Epoch: 5| Step: 5
Training loss: 2.6100995540618896
Validation loss: 2.321691648934477

Epoch: 5| Step: 6
Training loss: 2.7488455772399902
Validation loss: 2.326674335746355

Epoch: 5| Step: 7
Training loss: 2.4593186378479004
Validation loss: 2.332152165392394

Epoch: 5| Step: 8
Training loss: 2.6201043128967285
Validation loss: 2.3238371097913353

Epoch: 5| Step: 9
Training loss: 2.4571471214294434
Validation loss: 2.307828467379334

Epoch: 5| Step: 10
Training loss: 2.3763158321380615
Validation loss: 2.302598004700035

Epoch: 143| Step: 0
Training loss: 2.5372633934020996
Validation loss: 2.3005438235498246

Epoch: 5| Step: 1
Training loss: 2.4408135414123535
Validation loss: 2.3084141644098426

Epoch: 5| Step: 2
Training loss: 2.654003143310547
Validation loss: 2.3078493020867787

Epoch: 5| Step: 3
Training loss: 2.477080821990967
Validation loss: 2.313117672038335

Epoch: 5| Step: 4
Training loss: 2.4874274730682373
Validation loss: 2.2907773243483676

Epoch: 5| Step: 5
Training loss: 2.624490976333618
Validation loss: 2.280324892331195

Epoch: 5| Step: 6
Training loss: 2.601125717163086
Validation loss: 2.260463019852997

Epoch: 5| Step: 7
Training loss: 2.503840923309326
Validation loss: 2.2470715866293958

Epoch: 5| Step: 8
Training loss: 1.8751424551010132
Validation loss: 2.247646685569517

Epoch: 5| Step: 9
Training loss: 2.6004414558410645
Validation loss: 2.2433418573871737

Epoch: 5| Step: 10
Training loss: 2.7525720596313477
Validation loss: 2.2449210754004856

Epoch: 144| Step: 0
Training loss: 2.584963321685791
Validation loss: 2.2457149426142373

Epoch: 5| Step: 1
Training loss: 2.7475271224975586
Validation loss: 2.239826222901703

Epoch: 5| Step: 2
Training loss: 2.438366651535034
Validation loss: 2.2272345827471827

Epoch: 5| Step: 3
Training loss: 2.3480913639068604
Validation loss: 2.2331556863682245

Epoch: 5| Step: 4
Training loss: 2.9112725257873535
Validation loss: 2.2433457425845567

Epoch: 5| Step: 5
Training loss: 2.4692583084106445
Validation loss: 2.240263646648776

Epoch: 5| Step: 6
Training loss: 2.3431472778320312
Validation loss: 2.2481510664827082

Epoch: 5| Step: 7
Training loss: 2.455275058746338
Validation loss: 2.247807510437504

Epoch: 5| Step: 8
Training loss: 2.2119743824005127
Validation loss: 2.247160200149782

Epoch: 5| Step: 9
Training loss: 2.916349411010742
Validation loss: 2.2470046448451217

Epoch: 5| Step: 10
Training loss: 2.06330943107605
Validation loss: 2.2534916477818645

Epoch: 145| Step: 0
Training loss: 2.925264835357666
Validation loss: 2.2547068903523106

Epoch: 5| Step: 1
Training loss: 2.8014748096466064
Validation loss: 2.257053020179913

Epoch: 5| Step: 2
Training loss: 2.519392490386963
Validation loss: 2.2735681277449413

Epoch: 5| Step: 3
Training loss: 2.6293036937713623
Validation loss: 2.273301770610194

Epoch: 5| Step: 4
Training loss: 2.3252620697021484
Validation loss: 2.278294215920151

Epoch: 5| Step: 5
Training loss: 2.5973057746887207
Validation loss: 2.2903655241894465

Epoch: 5| Step: 6
Training loss: 2.2233285903930664
Validation loss: 2.2862046572469894

Epoch: 5| Step: 7
Training loss: 2.405547618865967
Validation loss: 2.303769942252867

Epoch: 5| Step: 8
Training loss: 2.1408584117889404
Validation loss: 2.31525146320302

Epoch: 5| Step: 9
Training loss: 2.3441011905670166
Validation loss: 2.326233248556814

Epoch: 5| Step: 10
Training loss: 2.4854636192321777
Validation loss: 2.3391341073538667

Epoch: 146| Step: 0
Training loss: 2.4789652824401855
Validation loss: 2.3282319499600317

Epoch: 5| Step: 1
Training loss: 2.4132916927337646
Validation loss: 2.3225541448080413

Epoch: 5| Step: 2
Training loss: 2.042917490005493
Validation loss: 2.3067272427261516

Epoch: 5| Step: 3
Training loss: 2.6360268592834473
Validation loss: 2.297682839055215

Epoch: 5| Step: 4
Training loss: 2.591108798980713
Validation loss: 2.295561303374588

Epoch: 5| Step: 5
Training loss: 2.79921293258667
Validation loss: 2.295377149376818

Epoch: 5| Step: 6
Training loss: 1.913666009902954
Validation loss: 2.2891577418132494

Epoch: 5| Step: 7
Training loss: 2.568661689758301
Validation loss: 2.2738642474656463

Epoch: 5| Step: 8
Training loss: 2.676365375518799
Validation loss: 2.2664316674714446

Epoch: 5| Step: 9
Training loss: 3.0173451900482178
Validation loss: 2.2699352182367796

Epoch: 5| Step: 10
Training loss: 1.9867876768112183
Validation loss: 2.2837748553163264

Epoch: 147| Step: 0
Training loss: 2.215810537338257
Validation loss: 2.2964105580442693

Epoch: 5| Step: 1
Training loss: 2.5221946239471436
Validation loss: 2.3059489009200886

Epoch: 5| Step: 2
Training loss: 3.164991855621338
Validation loss: 2.324654743235598

Epoch: 5| Step: 3
Training loss: 2.6384825706481934
Validation loss: 2.3312057115698375

Epoch: 5| Step: 4
Training loss: 2.2426276206970215
Validation loss: 2.350963164401311

Epoch: 5| Step: 5
Training loss: 2.4117677211761475
Validation loss: 2.334222011668708

Epoch: 5| Step: 6
Training loss: 2.5628275871276855
Validation loss: 2.331502288900396

Epoch: 5| Step: 7
Training loss: 1.9247115850448608
Validation loss: 2.3252482337336384

Epoch: 5| Step: 8
Training loss: 2.5196287631988525
Validation loss: 2.3200565307371077

Epoch: 5| Step: 9
Training loss: 2.3547303676605225
Validation loss: 2.331354997491324

Epoch: 5| Step: 10
Training loss: 2.691183090209961
Validation loss: 2.340257526725851

Epoch: 148| Step: 0
Training loss: 1.8027013540267944
Validation loss: 2.3308358858990412

Epoch: 5| Step: 1
Training loss: 2.138571262359619
Validation loss: 2.3247538971644577

Epoch: 5| Step: 2
Training loss: 2.985250473022461
Validation loss: 2.304151588870633

Epoch: 5| Step: 3
Training loss: 2.806088924407959
Validation loss: 2.2905965876835648

Epoch: 5| Step: 4
Training loss: 2.541667938232422
Validation loss: 2.278226162797661

Epoch: 5| Step: 5
Training loss: 2.2067482471466064
Validation loss: 2.2782138880862983

Epoch: 5| Step: 6
Training loss: 3.0048954486846924
Validation loss: 2.2875914983851935

Epoch: 5| Step: 7
Training loss: 2.1888222694396973
Validation loss: 2.2838217981400026

Epoch: 5| Step: 8
Training loss: 2.382918119430542
Validation loss: 2.287123123804728

Epoch: 5| Step: 9
Training loss: 2.7029049396514893
Validation loss: 2.2811401056986984

Epoch: 5| Step: 10
Training loss: 2.514625072479248
Validation loss: 2.2684432409142934

Epoch: 149| Step: 0
Training loss: 2.620527505874634
Validation loss: 2.2641409007451867

Epoch: 5| Step: 1
Training loss: 2.312366485595703
Validation loss: 2.2583058508493568

Epoch: 5| Step: 2
Training loss: 2.356562376022339
Validation loss: 2.2684210295318277

Epoch: 5| Step: 3
Training loss: 2.497404098510742
Validation loss: 2.281529382992816

Epoch: 5| Step: 4
Training loss: 2.346142530441284
Validation loss: 2.287910774189939

Epoch: 5| Step: 5
Training loss: 2.6839699745178223
Validation loss: 2.2968641737455964

Epoch: 5| Step: 6
Training loss: 2.49910044670105
Validation loss: 2.312214230978361

Epoch: 5| Step: 7
Training loss: 2.4782519340515137
Validation loss: 2.3042271726874897

Epoch: 5| Step: 8
Training loss: 1.9549328088760376
Validation loss: 2.2943953647408435

Epoch: 5| Step: 9
Training loss: 3.3825764656066895
Validation loss: 2.281927083128242

Epoch: 5| Step: 10
Training loss: 1.9516617059707642
Validation loss: 2.2682695619521605

Epoch: 150| Step: 0
Training loss: 2.4119150638580322
Validation loss: 2.266430047250563

Epoch: 5| Step: 1
Training loss: 3.0894689559936523
Validation loss: 2.265395810527186

Epoch: 5| Step: 2
Training loss: 2.455061674118042
Validation loss: 2.261641279343636

Epoch: 5| Step: 3
Training loss: 2.568598985671997
Validation loss: 2.261626428173434

Epoch: 5| Step: 4
Training loss: 2.5012760162353516
Validation loss: 2.2673048998719905

Epoch: 5| Step: 5
Training loss: 1.9939342737197876
Validation loss: 2.265185494576731

Epoch: 5| Step: 6
Training loss: 2.4710075855255127
Validation loss: 2.270222113978478

Epoch: 5| Step: 7
Training loss: 2.8346550464630127
Validation loss: 2.251057514580347

Epoch: 5| Step: 8
Training loss: 2.2441811561584473
Validation loss: 2.2570122723938315

Epoch: 5| Step: 9
Training loss: 2.5382418632507324
Validation loss: 2.246113875860809

Epoch: 5| Step: 10
Training loss: 1.8121556043624878
Validation loss: 2.252534463841428

Epoch: 151| Step: 0
Training loss: 2.392909526824951
Validation loss: 2.255446546821184

Epoch: 5| Step: 1
Training loss: 1.6942150592803955
Validation loss: 2.2603064813921527

Epoch: 5| Step: 2
Training loss: 2.704134464263916
Validation loss: 2.262994166343443

Epoch: 5| Step: 3
Training loss: 2.7368826866149902
Validation loss: 2.270366814828688

Epoch: 5| Step: 4
Training loss: 2.1569390296936035
Validation loss: 2.2770387934100245

Epoch: 5| Step: 5
Training loss: 2.335188388824463
Validation loss: 2.2900207324694564

Epoch: 5| Step: 6
Training loss: 2.5236728191375732
Validation loss: 2.3044147029999764

Epoch: 5| Step: 7
Training loss: 2.5507428646087646
Validation loss: 2.3153831010223715

Epoch: 5| Step: 8
Training loss: 3.284303665161133
Validation loss: 2.335113243390155

Epoch: 5| Step: 9
Training loss: 2.440683364868164
Validation loss: 2.35130407733302

Epoch: 5| Step: 10
Training loss: 2.1845316886901855
Validation loss: 2.3482038051851335

Epoch: 152| Step: 0
Training loss: 2.3791685104370117
Validation loss: 2.330950806217809

Epoch: 5| Step: 1
Training loss: 2.2784512042999268
Validation loss: 2.327302486665787

Epoch: 5| Step: 2
Training loss: 1.9181019067764282
Validation loss: 2.2999442802962435

Epoch: 5| Step: 3
Training loss: 3.0502734184265137
Validation loss: 2.2845123788361907

Epoch: 5| Step: 4
Training loss: 2.165555238723755
Validation loss: 2.2783374145466793

Epoch: 5| Step: 5
Training loss: 2.6635499000549316
Validation loss: 2.2785496019547984

Epoch: 5| Step: 6
Training loss: 1.832370400428772
Validation loss: 2.278932240701491

Epoch: 5| Step: 7
Training loss: 2.7940585613250732
Validation loss: 2.273532793086062

Epoch: 5| Step: 8
Training loss: 3.0338714122772217
Validation loss: 2.276867804988738

Epoch: 5| Step: 9
Training loss: 2.12013578414917
Validation loss: 2.2704753286095074

Epoch: 5| Step: 10
Training loss: 2.608483076095581
Validation loss: 2.276515578710905

Epoch: 153| Step: 0
Training loss: 2.473792314529419
Validation loss: 2.284327704419372

Epoch: 5| Step: 1
Training loss: 2.5261876583099365
Validation loss: 2.2718587613874868

Epoch: 5| Step: 2
Training loss: 2.404034376144409
Validation loss: 2.2709668733740367

Epoch: 5| Step: 3
Training loss: 2.053657054901123
Validation loss: 2.2598614282505487

Epoch: 5| Step: 4
Training loss: 3.0563971996307373
Validation loss: 2.243208349391978

Epoch: 5| Step: 5
Training loss: 2.165255069732666
Validation loss: 2.2436433299895255

Epoch: 5| Step: 6
Training loss: 2.5278217792510986
Validation loss: 2.2480507460973596

Epoch: 5| Step: 7
Training loss: 2.7225799560546875
Validation loss: 2.259014521875689

Epoch: 5| Step: 8
Training loss: 2.8416616916656494
Validation loss: 2.261051777870424

Epoch: 5| Step: 9
Training loss: 1.939536452293396
Validation loss: 2.261463830547948

Epoch: 5| Step: 10
Training loss: 2.2154741287231445
Validation loss: 2.2593111786791074

Epoch: 154| Step: 0
Training loss: 2.0670902729034424
Validation loss: 2.2722785229324014

Epoch: 5| Step: 1
Training loss: 2.423189163208008
Validation loss: 2.2807471470166276

Epoch: 5| Step: 2
Training loss: 3.1068079471588135
Validation loss: 2.2859714877220894

Epoch: 5| Step: 3
Training loss: 2.224484920501709
Validation loss: 2.307205723178002

Epoch: 5| Step: 4
Training loss: 2.0138537883758545
Validation loss: 2.2949379156994563

Epoch: 5| Step: 5
Training loss: 2.969006299972534
Validation loss: 2.2838308926551574

Epoch: 5| Step: 6
Training loss: 2.782226085662842
Validation loss: 2.2734370949447795

Epoch: 5| Step: 7
Training loss: 2.73785662651062
Validation loss: 2.258612104641494

Epoch: 5| Step: 8
Training loss: 2.0736589431762695
Validation loss: 2.2479787975229244

Epoch: 5| Step: 9
Training loss: 2.065093517303467
Validation loss: 2.2450978986678587

Epoch: 5| Step: 10
Training loss: 2.471757650375366
Validation loss: 2.234729464336108

Epoch: 155| Step: 0
Training loss: 2.122826099395752
Validation loss: 2.236827383759201

Epoch: 5| Step: 1
Training loss: 2.441343307495117
Validation loss: 2.2364880846392725

Epoch: 5| Step: 2
Training loss: 2.166386127471924
Validation loss: 2.220767894098836

Epoch: 5| Step: 3
Training loss: 2.337045907974243
Validation loss: 2.224398671939809

Epoch: 5| Step: 4
Training loss: 2.665947675704956
Validation loss: 2.227027298301779

Epoch: 5| Step: 5
Training loss: 2.24534273147583
Validation loss: 2.231820742289225

Epoch: 5| Step: 6
Training loss: 2.6199398040771484
Validation loss: 2.2338394221439155

Epoch: 5| Step: 7
Training loss: 2.8571431636810303
Validation loss: 2.249737411416987

Epoch: 5| Step: 8
Training loss: 2.3506417274475098
Validation loss: 2.269041524138502

Epoch: 5| Step: 9
Training loss: 2.3471570014953613
Validation loss: 2.2671411703991633

Epoch: 5| Step: 10
Training loss: 2.6901633739471436
Validation loss: 2.271869562005484

Epoch: 156| Step: 0
Training loss: 2.393983840942383
Validation loss: 2.2722146357259443

Epoch: 5| Step: 1
Training loss: 2.1285805702209473
Validation loss: 2.2744885054967736

Epoch: 5| Step: 2
Training loss: 2.900566577911377
Validation loss: 2.2697584731604463

Epoch: 5| Step: 3
Training loss: 2.527711868286133
Validation loss: 2.2680047686382006

Epoch: 5| Step: 4
Training loss: 2.095428466796875
Validation loss: 2.262760580226939

Epoch: 5| Step: 5
Training loss: 2.38078236579895
Validation loss: 2.2604055122662614

Epoch: 5| Step: 6
Training loss: 2.1403777599334717
Validation loss: 2.2708966296206237

Epoch: 5| Step: 7
Training loss: 2.886219024658203
Validation loss: 2.2718166535900486

Epoch: 5| Step: 8
Training loss: 2.4668097496032715
Validation loss: 2.275808452278055

Epoch: 5| Step: 9
Training loss: 2.22328519821167
Validation loss: 2.2580079468347694

Epoch: 5| Step: 10
Training loss: 2.5020840167999268
Validation loss: 2.2572827569900022

Epoch: 157| Step: 0
Training loss: 2.457880735397339
Validation loss: 2.269541044389048

Epoch: 5| Step: 1
Training loss: 2.479595184326172
Validation loss: 2.264378989896467

Epoch: 5| Step: 2
Training loss: 2.6770734786987305
Validation loss: 2.295915444691976

Epoch: 5| Step: 3
Training loss: 1.984980821609497
Validation loss: 2.2968026386794222

Epoch: 5| Step: 4
Training loss: 2.248800754547119
Validation loss: 2.3354262100752963

Epoch: 5| Step: 5
Training loss: 2.514676809310913
Validation loss: 2.341691409387896

Epoch: 5| Step: 6
Training loss: 2.559173107147217
Validation loss: 2.357689378082111

Epoch: 5| Step: 7
Training loss: 2.9426662921905518
Validation loss: 2.337018161691645

Epoch: 5| Step: 8
Training loss: 2.3760428428649902
Validation loss: 2.276426035870788

Epoch: 5| Step: 9
Training loss: 2.509787082672119
Validation loss: 2.257557210101876

Epoch: 5| Step: 10
Training loss: 2.142310857772827
Validation loss: 2.239917791017922

Epoch: 158| Step: 0
Training loss: 2.3729355335235596
Validation loss: 2.229418135458423

Epoch: 5| Step: 1
Training loss: 1.9167735576629639
Validation loss: 2.244361739004812

Epoch: 5| Step: 2
Training loss: 2.319354295730591
Validation loss: 2.2476797949883247

Epoch: 5| Step: 3
Training loss: 1.6889007091522217
Validation loss: 2.2567789939142044

Epoch: 5| Step: 4
Training loss: 2.2667737007141113
Validation loss: 2.2661682764689126

Epoch: 5| Step: 5
Training loss: 2.090101718902588
Validation loss: 2.2480739496087514

Epoch: 5| Step: 6
Training loss: 2.62524676322937
Validation loss: 2.247438156476585

Epoch: 5| Step: 7
Training loss: 2.909111499786377
Validation loss: 2.2539544925894788

Epoch: 5| Step: 8
Training loss: 3.0429742336273193
Validation loss: 2.2592667328414096

Epoch: 5| Step: 9
Training loss: 2.9693596363067627
Validation loss: 2.2441373320036035

Epoch: 5| Step: 10
Training loss: 2.372769355773926
Validation loss: 2.2332143732296523

Epoch: 159| Step: 0
Training loss: 1.9490448236465454
Validation loss: 2.2392769116227345

Epoch: 5| Step: 1
Training loss: 1.980592966079712
Validation loss: 2.239559245365922

Epoch: 5| Step: 2
Training loss: 2.8458099365234375
Validation loss: 2.2408254684940463

Epoch: 5| Step: 3
Training loss: 2.6127543449401855
Validation loss: 2.244504882443336

Epoch: 5| Step: 4
Training loss: 2.4598841667175293
Validation loss: 2.2543215136374197

Epoch: 5| Step: 5
Training loss: 2.4215457439422607
Validation loss: 2.245726769970309

Epoch: 5| Step: 6
Training loss: 2.3136963844299316
Validation loss: 2.2504337551773235

Epoch: 5| Step: 7
Training loss: 2.177565336227417
Validation loss: 2.2609154921706005

Epoch: 5| Step: 8
Training loss: 2.9318010807037354
Validation loss: 2.271711972451979

Epoch: 5| Step: 9
Training loss: 2.528141498565674
Validation loss: 2.280046614267493

Epoch: 5| Step: 10
Training loss: 2.5816218852996826
Validation loss: 2.2972926337231874

Epoch: 160| Step: 0
Training loss: 2.6476166248321533
Validation loss: 2.2932005031134493

Epoch: 5| Step: 1
Training loss: 3.427417278289795
Validation loss: 2.2850175442234164

Epoch: 5| Step: 2
Training loss: 2.045865297317505
Validation loss: 2.281209481659756

Epoch: 5| Step: 3
Training loss: 2.056096315383911
Validation loss: 2.2734997554491927

Epoch: 5| Step: 4
Training loss: 1.9632513523101807
Validation loss: 2.2626629337187736

Epoch: 5| Step: 5
Training loss: 2.3521552085876465
Validation loss: 2.275113413410802

Epoch: 5| Step: 6
Training loss: 2.5979418754577637
Validation loss: 2.300940639229231

Epoch: 5| Step: 7
Training loss: 2.300657272338867
Validation loss: 2.2943669775480866

Epoch: 5| Step: 8
Training loss: 2.041663885116577
Validation loss: 2.25750377357647

Epoch: 5| Step: 9
Training loss: 2.8785252571105957
Validation loss: 2.2478923618152575

Epoch: 5| Step: 10
Training loss: 2.2515180110931396
Validation loss: 2.2612424947882213

Epoch: 161| Step: 0
Training loss: 2.171386241912842
Validation loss: 2.2830472607766428

Epoch: 5| Step: 1
Training loss: 2.3101742267608643
Validation loss: 2.286154108662759

Epoch: 5| Step: 2
Training loss: 2.5405421257019043
Validation loss: 2.28678568204244

Epoch: 5| Step: 3
Training loss: 2.2374980449676514
Validation loss: 2.264816952008073

Epoch: 5| Step: 4
Training loss: 2.1949009895324707
Validation loss: 2.2751184817283385

Epoch: 5| Step: 5
Training loss: 2.9743990898132324
Validation loss: 2.2604462767160065

Epoch: 5| Step: 6
Training loss: 2.6116576194763184
Validation loss: 2.2342640302514516

Epoch: 5| Step: 7
Training loss: 2.209716320037842
Validation loss: 2.2274619430624027

Epoch: 5| Step: 8
Training loss: 2.770721912384033
Validation loss: 2.2195381541405954

Epoch: 5| Step: 9
Training loss: 2.2828452587127686
Validation loss: 2.2055673958152853

Epoch: 5| Step: 10
Training loss: 2.4097607135772705
Validation loss: 2.2158113371941353

Epoch: 162| Step: 0
Training loss: 2.8346362113952637
Validation loss: 2.2248546872087704

Epoch: 5| Step: 1
Training loss: 2.6546072959899902
Validation loss: 2.2400168526557183

Epoch: 5| Step: 2
Training loss: 2.5642664432525635
Validation loss: 2.2676996428479432

Epoch: 5| Step: 3
Training loss: 2.0933403968811035
Validation loss: 2.2888832681922504

Epoch: 5| Step: 4
Training loss: 2.4487080574035645
Validation loss: 2.292869198706842

Epoch: 5| Step: 5
Training loss: 2.514997720718384
Validation loss: 2.277688390465193

Epoch: 5| Step: 6
Training loss: 2.315871000289917
Validation loss: 2.2872420536574496

Epoch: 5| Step: 7
Training loss: 1.7537654638290405
Validation loss: 2.285976138166202

Epoch: 5| Step: 8
Training loss: 1.8154703378677368
Validation loss: 2.294923015820083

Epoch: 5| Step: 9
Training loss: 2.5161643028259277
Validation loss: 2.2929556369781494

Epoch: 5| Step: 10
Training loss: 3.0285158157348633
Validation loss: 2.2978417617018505

Epoch: 163| Step: 0
Training loss: 3.063298463821411
Validation loss: 2.296875601173729

Epoch: 5| Step: 1
Training loss: 1.8075122833251953
Validation loss: 2.2781320694954164

Epoch: 5| Step: 2
Training loss: 2.5986216068267822
Validation loss: 2.2804393640128513

Epoch: 5| Step: 3
Training loss: 2.416194438934326
Validation loss: 2.2590224819798626

Epoch: 5| Step: 4
Training loss: 2.3402020931243896
Validation loss: 2.259473741695445

Epoch: 5| Step: 5
Training loss: 1.472964882850647
Validation loss: 2.254862859684934

Epoch: 5| Step: 6
Training loss: 2.5526299476623535
Validation loss: 2.2649817453917636

Epoch: 5| Step: 7
Training loss: 2.6052932739257812
Validation loss: 2.261179739429105

Epoch: 5| Step: 8
Training loss: 2.4707446098327637
Validation loss: 2.2478264044689875

Epoch: 5| Step: 9
Training loss: 2.8548696041107178
Validation loss: 2.2535263774215535

Epoch: 5| Step: 10
Training loss: 2.2363815307617188
Validation loss: 2.252829031277728

Epoch: 164| Step: 0
Training loss: 2.592658519744873
Validation loss: 2.2484364022490797

Epoch: 5| Step: 1
Training loss: 2.3878602981567383
Validation loss: 2.2428601198298956

Epoch: 5| Step: 2
Training loss: 1.1198217868804932
Validation loss: 2.2408662098710255

Epoch: 5| Step: 3
Training loss: 2.3688395023345947
Validation loss: 2.233080651170464

Epoch: 5| Step: 4
Training loss: 2.229407548904419
Validation loss: 2.245236578808036

Epoch: 5| Step: 5
Training loss: 2.612211227416992
Validation loss: 2.24287655533001

Epoch: 5| Step: 6
Training loss: 3.0399184226989746
Validation loss: 2.244071122138731

Epoch: 5| Step: 7
Training loss: 3.0852138996124268
Validation loss: 2.22639105396886

Epoch: 5| Step: 8
Training loss: 2.859923839569092
Validation loss: 2.2363912315778833

Epoch: 5| Step: 9
Training loss: 1.7839529514312744
Validation loss: 2.228885172515787

Epoch: 5| Step: 10
Training loss: 2.120523452758789
Validation loss: 2.231952092980826

Epoch: 165| Step: 0
Training loss: 2.5595226287841797
Validation loss: 2.2295964020554737

Epoch: 5| Step: 1
Training loss: 1.5554640293121338
Validation loss: 2.23120290745971

Epoch: 5| Step: 2
Training loss: 2.7603695392608643
Validation loss: 2.237473980073006

Epoch: 5| Step: 3
Training loss: 1.9145195484161377
Validation loss: 2.251623838178573

Epoch: 5| Step: 4
Training loss: 2.747840404510498
Validation loss: 2.258416147642238

Epoch: 5| Step: 5
Training loss: 2.4290778636932373
Validation loss: 2.249450163174701

Epoch: 5| Step: 6
Training loss: 1.9111645221710205
Validation loss: 2.2389083523904123

Epoch: 5| Step: 7
Training loss: 2.379812240600586
Validation loss: 2.254080808290871

Epoch: 5| Step: 8
Training loss: 2.799056053161621
Validation loss: 2.2657762958157446

Epoch: 5| Step: 9
Training loss: 2.999541759490967
Validation loss: 2.2897790939577165

Epoch: 5| Step: 10
Training loss: 2.204749345779419
Validation loss: 2.285216933937483

Epoch: 166| Step: 0
Training loss: 2.571254014968872
Validation loss: 2.2908239287714802

Epoch: 5| Step: 1
Training loss: 1.958017110824585
Validation loss: 2.2769096359129875

Epoch: 5| Step: 2
Training loss: 2.649550676345825
Validation loss: 2.262533149411601

Epoch: 5| Step: 3
Training loss: 2.3119516372680664
Validation loss: 2.2579690294881023

Epoch: 5| Step: 4
Training loss: 2.7977168560028076
Validation loss: 2.2459287002522457

Epoch: 5| Step: 5
Training loss: 2.1078085899353027
Validation loss: 2.237330690506966

Epoch: 5| Step: 6
Training loss: 2.6498301029205322
Validation loss: 2.2267868159919657

Epoch: 5| Step: 7
Training loss: 2.019231081008911
Validation loss: 2.2224096790436776

Epoch: 5| Step: 8
Training loss: 2.544188976287842
Validation loss: 2.2257147578782934

Epoch: 5| Step: 9
Training loss: 2.0567305088043213
Validation loss: 2.2196443209084133

Epoch: 5| Step: 10
Training loss: 2.602891683578491
Validation loss: 2.2244494320243917

Epoch: 167| Step: 0
Training loss: 2.225449800491333
Validation loss: 2.2131251058270855

Epoch: 5| Step: 1
Training loss: 2.4438412189483643
Validation loss: 2.220002212832051

Epoch: 5| Step: 2
Training loss: 1.9696153402328491
Validation loss: 2.2251298735218663

Epoch: 5| Step: 3
Training loss: 1.9818519353866577
Validation loss: 2.228001435597738

Epoch: 5| Step: 4
Training loss: 2.3693113327026367
Validation loss: 2.2251059983366277

Epoch: 5| Step: 5
Training loss: 3.0749287605285645
Validation loss: 2.2212475768981443

Epoch: 5| Step: 6
Training loss: 2.08141827583313
Validation loss: 2.215973215718423

Epoch: 5| Step: 7
Training loss: 2.1450979709625244
Validation loss: 2.2084263473428707

Epoch: 5| Step: 8
Training loss: 2.0731587409973145
Validation loss: 2.2178276636267222

Epoch: 5| Step: 9
Training loss: 3.4899792671203613
Validation loss: 2.2195542909765757

Epoch: 5| Step: 10
Training loss: 2.078476905822754
Validation loss: 2.2261554630853797

Epoch: 168| Step: 0
Training loss: 2.5143303871154785
Validation loss: 2.2379379426279375

Epoch: 5| Step: 1
Training loss: 2.1880125999450684
Validation loss: 2.238500274637694

Epoch: 5| Step: 2
Training loss: 3.0164146423339844
Validation loss: 2.2536503397008425

Epoch: 5| Step: 3
Training loss: 3.0677132606506348
Validation loss: 2.25828577369772

Epoch: 5| Step: 4
Training loss: 1.9475038051605225
Validation loss: 2.2538477015751663

Epoch: 5| Step: 5
Training loss: 2.5907342433929443
Validation loss: 2.264874712113411

Epoch: 5| Step: 6
Training loss: 2.091622829437256
Validation loss: 2.26053705523091

Epoch: 5| Step: 7
Training loss: 1.7486646175384521
Validation loss: 2.233886400858561

Epoch: 5| Step: 8
Training loss: 2.1102850437164307
Validation loss: 2.2277548697686966

Epoch: 5| Step: 9
Training loss: 2.5850350856781006
Validation loss: 2.2133134577863958

Epoch: 5| Step: 10
Training loss: 2.2124338150024414
Validation loss: 2.248154619688629

Epoch: 169| Step: 0
Training loss: 2.13015079498291
Validation loss: 2.2716686674343642

Epoch: 5| Step: 1
Training loss: 2.8991456031799316
Validation loss: 2.260810862305344

Epoch: 5| Step: 2
Training loss: 2.582883358001709
Validation loss: 2.2192282753606

Epoch: 5| Step: 3
Training loss: 2.3733410835266113
Validation loss: 2.2011214956160514

Epoch: 5| Step: 4
Training loss: 2.368877410888672
Validation loss: 2.2131819263581307

Epoch: 5| Step: 5
Training loss: 2.39754056930542
Validation loss: 2.2256543482503583

Epoch: 5| Step: 6
Training loss: 2.4914722442626953
Validation loss: 2.251344688477055

Epoch: 5| Step: 7
Training loss: 2.0736217498779297
Validation loss: 2.241345654251755

Epoch: 5| Step: 8
Training loss: 2.399465799331665
Validation loss: 2.24468852884026

Epoch: 5| Step: 9
Training loss: 2.1434755325317383
Validation loss: 2.2398871093667965

Epoch: 5| Step: 10
Training loss: 2.4068150520324707
Validation loss: 2.241852614187425

Epoch: 170| Step: 0
Training loss: 2.560809850692749
Validation loss: 2.2326106820055234

Epoch: 5| Step: 1
Training loss: 2.22184157371521
Validation loss: 2.2203988388020504

Epoch: 5| Step: 2
Training loss: 3.026280164718628
Validation loss: 2.219341424203688

Epoch: 5| Step: 3
Training loss: 2.806809902191162
Validation loss: 2.215918788345911

Epoch: 5| Step: 4
Training loss: 1.99126398563385
Validation loss: 2.2362223594419417

Epoch: 5| Step: 5
Training loss: 2.2850046157836914
Validation loss: 2.2583658797766573

Epoch: 5| Step: 6
Training loss: 1.5889822244644165
Validation loss: 2.2702060361062326

Epoch: 5| Step: 7
Training loss: 1.5413764715194702
Validation loss: 2.26610493147245

Epoch: 5| Step: 8
Training loss: 2.1806130409240723
Validation loss: 2.2694375258620068

Epoch: 5| Step: 9
Training loss: 2.8555803298950195
Validation loss: 2.2450341716889413

Epoch: 5| Step: 10
Training loss: 2.999516725540161
Validation loss: 2.2296529380224084

Epoch: 171| Step: 0
Training loss: 1.694014310836792
Validation loss: 2.227983961823166

Epoch: 5| Step: 1
Training loss: 2.2209362983703613
Validation loss: 2.2272408264939503

Epoch: 5| Step: 2
Training loss: 2.5895462036132812
Validation loss: 2.229154994410853

Epoch: 5| Step: 3
Training loss: 2.6501870155334473
Validation loss: 2.2204165561224825

Epoch: 5| Step: 4
Training loss: 1.7102394104003906
Validation loss: 2.227219538022113

Epoch: 5| Step: 5
Training loss: 2.6794447898864746
Validation loss: 2.21952405283528

Epoch: 5| Step: 6
Training loss: 2.5903162956237793
Validation loss: 2.222410161008117

Epoch: 5| Step: 7
Training loss: 2.131743907928467
Validation loss: 2.2074923361501386

Epoch: 5| Step: 8
Training loss: 2.527884006500244
Validation loss: 2.1971156212591354

Epoch: 5| Step: 9
Training loss: 2.5913894176483154
Validation loss: 2.198799676792596

Epoch: 5| Step: 10
Training loss: 2.5446808338165283
Validation loss: 2.178736993061599

Epoch: 172| Step: 0
Training loss: 1.9459069967269897
Validation loss: 2.1883570404462915

Epoch: 5| Step: 1
Training loss: 2.151815891265869
Validation loss: 2.1959550483252412

Epoch: 5| Step: 2
Training loss: 2.3866496086120605
Validation loss: 2.209542885903389

Epoch: 5| Step: 3
Training loss: 2.4712958335876465
Validation loss: 2.2197739206334597

Epoch: 5| Step: 4
Training loss: 2.359532356262207
Validation loss: 2.219045962056806

Epoch: 5| Step: 5
Training loss: 2.7715439796447754
Validation loss: 2.236513655672791

Epoch: 5| Step: 6
Training loss: 1.577947974205017
Validation loss: 2.2302980948519964

Epoch: 5| Step: 7
Training loss: 2.925832748413086
Validation loss: 2.2282146176984234

Epoch: 5| Step: 8
Training loss: 2.021338939666748
Validation loss: 2.234767251117255

Epoch: 5| Step: 9
Training loss: 2.3710055351257324
Validation loss: 2.229786565226893

Epoch: 5| Step: 10
Training loss: 2.9129419326782227
Validation loss: 2.226424660733951

Epoch: 173| Step: 0
Training loss: 2.084360361099243
Validation loss: 2.2322882170318277

Epoch: 5| Step: 1
Training loss: 2.4435653686523438
Validation loss: 2.2352309816627094

Epoch: 5| Step: 2
Training loss: 3.0017077922821045
Validation loss: 2.22859521578717

Epoch: 5| Step: 3
Training loss: 2.0941989421844482
Validation loss: 2.2191156930820917

Epoch: 5| Step: 4
Training loss: 2.2229256629943848
Validation loss: 2.220021299136582

Epoch: 5| Step: 5
Training loss: 3.2162139415740967
Validation loss: 2.20861731806109

Epoch: 5| Step: 6
Training loss: 2.319103240966797
Validation loss: 2.1910590535850933

Epoch: 5| Step: 7
Training loss: 1.4193389415740967
Validation loss: 2.1953103080872567

Epoch: 5| Step: 8
Training loss: 2.098076105117798
Validation loss: 2.2028705022668325

Epoch: 5| Step: 9
Training loss: 2.595221757888794
Validation loss: 2.19441456179465

Epoch: 5| Step: 10
Training loss: 2.1340737342834473
Validation loss: 2.2037695261739914

Epoch: 174| Step: 0
Training loss: 2.6547131538391113
Validation loss: 2.2212773933205554

Epoch: 5| Step: 1
Training loss: 2.472254991531372
Validation loss: 2.2210182348887124

Epoch: 5| Step: 2
Training loss: 2.1448302268981934
Validation loss: 2.227855529836429

Epoch: 5| Step: 3
Training loss: 2.0842247009277344
Validation loss: 2.2247044681220927

Epoch: 5| Step: 4
Training loss: 2.113098621368408
Validation loss: 2.2186585703203754

Epoch: 5| Step: 5
Training loss: 2.4485652446746826
Validation loss: 2.2202517819660965

Epoch: 5| Step: 6
Training loss: 2.277588129043579
Validation loss: 2.2233670911481305

Epoch: 5| Step: 7
Training loss: 2.6329081058502197
Validation loss: 2.2448478437239126

Epoch: 5| Step: 8
Training loss: 2.3222403526306152
Validation loss: 2.239426323162612

Epoch: 5| Step: 9
Training loss: 1.9032602310180664
Validation loss: 2.2520862830582487

Epoch: 5| Step: 10
Training loss: 2.6158766746520996
Validation loss: 2.2505535297496344

Epoch: 175| Step: 0
Training loss: 2.1222126483917236
Validation loss: 2.243552971911687

Epoch: 5| Step: 1
Training loss: 2.3302409648895264
Validation loss: 2.2452101951004355

Epoch: 5| Step: 2
Training loss: 2.206071138381958
Validation loss: 2.248192569260956

Epoch: 5| Step: 3
Training loss: 2.251511573791504
Validation loss: 2.242140086748267

Epoch: 5| Step: 4
Training loss: 2.5828018188476562
Validation loss: 2.2464034095887215

Epoch: 5| Step: 5
Training loss: 2.7408552169799805
Validation loss: 2.225956513035682

Epoch: 5| Step: 6
Training loss: 1.740700125694275
Validation loss: 2.229401111602783

Epoch: 5| Step: 7
Training loss: 2.3258609771728516
Validation loss: 2.231720688522503

Epoch: 5| Step: 8
Training loss: 2.3135578632354736
Validation loss: 2.2373200834438367

Epoch: 5| Step: 9
Training loss: 2.3153038024902344
Validation loss: 2.2279540646460747

Epoch: 5| Step: 10
Training loss: 2.5831027030944824
Validation loss: 2.213609755680125

Epoch: 176| Step: 0
Training loss: 1.8311946392059326
Validation loss: 2.1923840686839116

Epoch: 5| Step: 1
Training loss: 2.594822406768799
Validation loss: 2.174744172762799

Epoch: 5| Step: 2
Training loss: 3.0484986305236816
Validation loss: 2.180611656558129

Epoch: 5| Step: 3
Training loss: 2.666539192199707
Validation loss: 2.1911485272069133

Epoch: 5| Step: 4
Training loss: 2.2659800052642822
Validation loss: 2.1972077354308097

Epoch: 5| Step: 5
Training loss: 2.303253412246704
Validation loss: 2.211706675508971

Epoch: 5| Step: 6
Training loss: 2.440922975540161
Validation loss: 2.2243723971869356

Epoch: 5| Step: 7
Training loss: 1.9603583812713623
Validation loss: 2.2041191131837907

Epoch: 5| Step: 8
Training loss: 2.39782977104187
Validation loss: 2.2064099440010647

Epoch: 5| Step: 9
Training loss: 2.3176684379577637
Validation loss: 2.2063651982174126

Epoch: 5| Step: 10
Training loss: 1.8964864015579224
Validation loss: 2.200015060363277

Epoch: 177| Step: 0
Training loss: 2.268105983734131
Validation loss: 2.2065299582737747

Epoch: 5| Step: 1
Training loss: 3.1552395820617676
Validation loss: 2.2207407284808416

Epoch: 5| Step: 2
Training loss: 2.7300195693969727
Validation loss: 2.2147585140761508

Epoch: 5| Step: 3
Training loss: 2.5542550086975098
Validation loss: 2.217314702208324

Epoch: 5| Step: 4
Training loss: 1.9320509433746338
Validation loss: 2.216666057545652

Epoch: 5| Step: 5
Training loss: 1.97420334815979
Validation loss: 2.219953585696477

Epoch: 5| Step: 6
Training loss: 2.0359044075012207
Validation loss: 2.236492790201659

Epoch: 5| Step: 7
Training loss: 2.3380866050720215
Validation loss: 2.2415824397917716

Epoch: 5| Step: 8
Training loss: 2.4737205505371094
Validation loss: 2.2457773172727196

Epoch: 5| Step: 9
Training loss: 1.848679780960083
Validation loss: 2.2265335077880533

Epoch: 5| Step: 10
Training loss: 2.186189889907837
Validation loss: 2.210933554557062

Epoch: 178| Step: 0
Training loss: 1.5401496887207031
Validation loss: 2.233297235222273

Epoch: 5| Step: 1
Training loss: 1.964922547340393
Validation loss: 2.2517591702040805

Epoch: 5| Step: 2
Training loss: 2.5655617713928223
Validation loss: 2.2573464147506224

Epoch: 5| Step: 3
Training loss: 2.393763303756714
Validation loss: 2.2639679754934003

Epoch: 5| Step: 4
Training loss: 2.6987829208374023
Validation loss: 2.242487971500684

Epoch: 5| Step: 5
Training loss: 2.2767727375030518
Validation loss: 2.230703551282165

Epoch: 5| Step: 6
Training loss: 2.306407928466797
Validation loss: 2.219264896967078

Epoch: 5| Step: 7
Training loss: 2.78070330619812
Validation loss: 2.232290132071382

Epoch: 5| Step: 8
Training loss: 2.213923931121826
Validation loss: 2.244031306236021

Epoch: 5| Step: 9
Training loss: 2.484171152114868
Validation loss: 2.2403496773012224

Epoch: 5| Step: 10
Training loss: 2.498682737350464
Validation loss: 2.2256086513560307

Epoch: 179| Step: 0
Training loss: 2.7596354484558105
Validation loss: 2.2348207760882635

Epoch: 5| Step: 1
Training loss: 2.2128443717956543
Validation loss: 2.2384530728863132

Epoch: 5| Step: 2
Training loss: 1.8972065448760986
Validation loss: 2.240318857213502

Epoch: 5| Step: 3
Training loss: 2.3465189933776855
Validation loss: 2.2371332542870634

Epoch: 5| Step: 4
Training loss: 2.2519965171813965
Validation loss: 2.2198106909310944

Epoch: 5| Step: 5
Training loss: 2.688664197921753
Validation loss: 2.1986815006502214

Epoch: 5| Step: 6
Training loss: 2.408039093017578
Validation loss: 2.177331324546568

Epoch: 5| Step: 7
Training loss: 2.0389976501464844
Validation loss: 2.1744839017109205

Epoch: 5| Step: 8
Training loss: 2.8227458000183105
Validation loss: 2.177822818038284

Epoch: 5| Step: 9
Training loss: 2.102588415145874
Validation loss: 2.1979743203809186

Epoch: 5| Step: 10
Training loss: 2.035442590713501
Validation loss: 2.23156391420672

Epoch: 180| Step: 0
Training loss: 2.809844493865967
Validation loss: 2.266641923176345

Epoch: 5| Step: 1
Training loss: 2.1772923469543457
Validation loss: 2.2777579240901495

Epoch: 5| Step: 2
Training loss: 2.7147223949432373
Validation loss: 2.268909090308733

Epoch: 5| Step: 3
Training loss: 2.479802370071411
Validation loss: 2.2282899938603884

Epoch: 5| Step: 4
Training loss: 1.7296628952026367
Validation loss: 2.1816622005995883

Epoch: 5| Step: 5
Training loss: 1.8201878070831299
Validation loss: 2.170818187857187

Epoch: 5| Step: 6
Training loss: 2.115081787109375
Validation loss: 2.1766945444127566

Epoch: 5| Step: 7
Training loss: 2.425539493560791
Validation loss: 2.192253344802446

Epoch: 5| Step: 8
Training loss: 2.597226619720459
Validation loss: 2.217536139231856

Epoch: 5| Step: 9
Training loss: 2.625640392303467
Validation loss: 2.2259100380764214

Epoch: 5| Step: 10
Training loss: 2.258229970932007
Validation loss: 2.218246747088689

Epoch: 181| Step: 0
Training loss: 2.646918535232544
Validation loss: 2.2144514694008777

Epoch: 5| Step: 1
Training loss: 2.0764853954315186
Validation loss: 2.2186580037557952

Epoch: 5| Step: 2
Training loss: 2.0381088256835938
Validation loss: 2.211750791918847

Epoch: 5| Step: 3
Training loss: 2.613478183746338
Validation loss: 2.2062373468952794

Epoch: 5| Step: 4
Training loss: 2.5449905395507812
Validation loss: 2.2139468731418734

Epoch: 5| Step: 5
Training loss: 2.5103061199188232
Validation loss: 2.2114113300077376

Epoch: 5| Step: 6
Training loss: 2.1096396446228027
Validation loss: 2.194694544679375

Epoch: 5| Step: 7
Training loss: 1.985032320022583
Validation loss: 2.1938855135312645

Epoch: 5| Step: 8
Training loss: 2.5234642028808594
Validation loss: 2.191461915610939

Epoch: 5| Step: 9
Training loss: 2.4494917392730713
Validation loss: 2.20475273747598

Epoch: 5| Step: 10
Training loss: 1.7261875867843628
Validation loss: 2.1989136972735004

Epoch: 182| Step: 0
Training loss: 2.18272066116333
Validation loss: 2.224199228389289

Epoch: 5| Step: 1
Training loss: 2.2994697093963623
Validation loss: 2.213246565993114

Epoch: 5| Step: 2
Training loss: 1.9541518688201904
Validation loss: 2.242803668463102

Epoch: 5| Step: 3
Training loss: 2.2127015590667725
Validation loss: 2.246239503224691

Epoch: 5| Step: 4
Training loss: 2.4092254638671875
Validation loss: 2.2616703830739504

Epoch: 5| Step: 5
Training loss: 3.0031776428222656
Validation loss: 2.270657067657799

Epoch: 5| Step: 6
Training loss: 2.1895174980163574
Validation loss: 2.2535113391055854

Epoch: 5| Step: 7
Training loss: 2.124768018722534
Validation loss: 2.2500851436327864

Epoch: 5| Step: 8
Training loss: 2.2137255668640137
Validation loss: 2.247447602210506

Epoch: 5| Step: 9
Training loss: 2.1461851596832275
Validation loss: 2.2266930469902615

Epoch: 5| Step: 10
Training loss: 2.7111291885375977
Validation loss: 2.2018861975721133

Epoch: 183| Step: 0
Training loss: 2.8536617755889893
Validation loss: 2.1971374327136624

Epoch: 5| Step: 1
Training loss: 2.3209757804870605
Validation loss: 2.192800403923117

Epoch: 5| Step: 2
Training loss: 2.018887996673584
Validation loss: 2.1790186807673466

Epoch: 5| Step: 3
Training loss: 2.7172272205352783
Validation loss: 2.1719936965614237

Epoch: 5| Step: 4
Training loss: 1.7860276699066162
Validation loss: 2.154993018796367

Epoch: 5| Step: 5
Training loss: 2.4557106494903564
Validation loss: 2.1659521338760213

Epoch: 5| Step: 6
Training loss: 1.9813038110733032
Validation loss: 2.160089664561774

Epoch: 5| Step: 7
Training loss: 1.987921118736267
Validation loss: 2.166330219596945

Epoch: 5| Step: 8
Training loss: 2.275036334991455
Validation loss: 2.1536579439716954

Epoch: 5| Step: 9
Training loss: 2.6942222118377686
Validation loss: 2.1612736512255926

Epoch: 5| Step: 10
Training loss: 2.1586110591888428
Validation loss: 2.1609645530741703

Epoch: 184| Step: 0
Training loss: 1.970785140991211
Validation loss: 2.1641464541035313

Epoch: 5| Step: 1
Training loss: 2.6053965091705322
Validation loss: 2.190449471114784

Epoch: 5| Step: 2
Training loss: 1.996647834777832
Validation loss: 2.2074536661947928

Epoch: 5| Step: 3
Training loss: 2.542757272720337
Validation loss: 2.2015020232046805

Epoch: 5| Step: 4
Training loss: 1.8022197484970093
Validation loss: 2.1959841148827666

Epoch: 5| Step: 5
Training loss: 2.564265489578247
Validation loss: 2.2005932356721614

Epoch: 5| Step: 6
Training loss: 2.5384628772735596
Validation loss: 2.192583255870368

Epoch: 5| Step: 7
Training loss: 1.7182080745697021
Validation loss: 2.208406432982414

Epoch: 5| Step: 8
Training loss: 2.9127917289733887
Validation loss: 2.2182675330869612

Epoch: 5| Step: 9
Training loss: 2.153625011444092
Validation loss: 2.2209149816984772

Epoch: 5| Step: 10
Training loss: 2.6176810264587402
Validation loss: 2.2346139671981975

Epoch: 185| Step: 0
Training loss: 2.0151073932647705
Validation loss: 2.2404329853673137

Epoch: 5| Step: 1
Training loss: 2.1108365058898926
Validation loss: 2.2268342433437223

Epoch: 5| Step: 2
Training loss: 2.1481120586395264
Validation loss: 2.202722798111618

Epoch: 5| Step: 3
Training loss: 2.7256546020507812
Validation loss: 2.1789122166172152

Epoch: 5| Step: 4
Training loss: 2.2436816692352295
Validation loss: 2.168246974227249

Epoch: 5| Step: 5
Training loss: 1.7322947978973389
Validation loss: 2.1678067689300864

Epoch: 5| Step: 6
Training loss: 2.968536138534546
Validation loss: 2.16132676985956

Epoch: 5| Step: 7
Training loss: 1.7063095569610596
Validation loss: 2.1579601533951296

Epoch: 5| Step: 8
Training loss: 2.490246295928955
Validation loss: 2.1635548427540767

Epoch: 5| Step: 9
Training loss: 2.602393627166748
Validation loss: 2.173521339252431

Epoch: 5| Step: 10
Training loss: 2.5892441272735596
Validation loss: 2.177030522336242

Epoch: 186| Step: 0
Training loss: 2.5951571464538574
Validation loss: 2.1744930590352705

Epoch: 5| Step: 1
Training loss: 2.053997039794922
Validation loss: 2.179295152746221

Epoch: 5| Step: 2
Training loss: 1.5864487886428833
Validation loss: 2.1783086343478133

Epoch: 5| Step: 3
Training loss: 2.325068473815918
Validation loss: 2.1793965985698085

Epoch: 5| Step: 4
Training loss: 1.972979187965393
Validation loss: 2.197429264745405

Epoch: 5| Step: 5
Training loss: 2.501008987426758
Validation loss: 2.194632726330911

Epoch: 5| Step: 6
Training loss: 2.817580461502075
Validation loss: 2.2269360685861237

Epoch: 5| Step: 7
Training loss: 2.400139331817627
Validation loss: 2.2235993364805817

Epoch: 5| Step: 8
Training loss: 2.6126489639282227
Validation loss: 2.239523042914688

Epoch: 5| Step: 9
Training loss: 1.6975338459014893
Validation loss: 2.2333222204639065

Epoch: 5| Step: 10
Training loss: 2.5613999366760254
Validation loss: 2.222702013548984

Epoch: 187| Step: 0
Training loss: 2.195422410964966
Validation loss: 2.211998365258658

Epoch: 5| Step: 1
Training loss: 2.014615535736084
Validation loss: 2.2195962475192164

Epoch: 5| Step: 2
Training loss: 1.6371805667877197
Validation loss: 2.2059053579966226

Epoch: 5| Step: 3
Training loss: 2.513622999191284
Validation loss: 2.2016697840024064

Epoch: 5| Step: 4
Training loss: 2.2953431606292725
Validation loss: 2.1927317368086947

Epoch: 5| Step: 5
Training loss: 1.8657598495483398
Validation loss: 2.1805380800718903

Epoch: 5| Step: 6
Training loss: 2.399789333343506
Validation loss: 2.1735892398383028

Epoch: 5| Step: 7
Training loss: 2.9120965003967285
Validation loss: 2.1803598339839647

Epoch: 5| Step: 8
Training loss: 2.207954168319702
Validation loss: 2.1812751703364874

Epoch: 5| Step: 9
Training loss: 2.6818461418151855
Validation loss: 2.1758224195049656

Epoch: 5| Step: 10
Training loss: 2.1736979484558105
Validation loss: 2.179378442866828

Epoch: 188| Step: 0
Training loss: 2.6074538230895996
Validation loss: 2.17892248271614

Epoch: 5| Step: 1
Training loss: 2.1117091178894043
Validation loss: 2.170340450861121

Epoch: 5| Step: 2
Training loss: 1.7578132152557373
Validation loss: 2.1741367206778577

Epoch: 5| Step: 3
Training loss: 1.892194390296936
Validation loss: 2.174048944186139

Epoch: 5| Step: 4
Training loss: 2.1488213539123535
Validation loss: 2.1759049636061474

Epoch: 5| Step: 5
Training loss: 1.5941468477249146
Validation loss: 2.1766409309961463

Epoch: 5| Step: 6
Training loss: 3.0211987495422363
Validation loss: 2.1842779728674118

Epoch: 5| Step: 7
Training loss: 2.5131497383117676
Validation loss: 2.1952342910151326

Epoch: 5| Step: 8
Training loss: 2.7048659324645996
Validation loss: 2.183350437430925

Epoch: 5| Step: 9
Training loss: 2.2200100421905518
Validation loss: 2.180068483916662

Epoch: 5| Step: 10
Training loss: 2.1499290466308594
Validation loss: 2.189435310261224

Epoch: 189| Step: 0
Training loss: 2.3274335861206055
Validation loss: 2.1836644859724146

Epoch: 5| Step: 1
Training loss: 2.383423328399658
Validation loss: 2.1858492128310667

Epoch: 5| Step: 2
Training loss: 2.500887393951416
Validation loss: 2.183868396666742

Epoch: 5| Step: 3
Training loss: 2.044477701187134
Validation loss: 2.193804781924012

Epoch: 5| Step: 4
Training loss: 2.2268741130828857
Validation loss: 2.1974635560025453

Epoch: 5| Step: 5
Training loss: 1.8940036296844482
Validation loss: 2.205305168705602

Epoch: 5| Step: 6
Training loss: 2.943434238433838
Validation loss: 2.204986846575173

Epoch: 5| Step: 7
Training loss: 2.1104466915130615
Validation loss: 2.205075648523146

Epoch: 5| Step: 8
Training loss: 1.7464332580566406
Validation loss: 2.1985474542904924

Epoch: 5| Step: 9
Training loss: 2.171555995941162
Validation loss: 2.197291238333589

Epoch: 5| Step: 10
Training loss: 2.4113216400146484
Validation loss: 2.1856708244610856

Epoch: 190| Step: 0
Training loss: 1.944850206375122
Validation loss: 2.2030037628707064

Epoch: 5| Step: 1
Training loss: 2.4268383979797363
Validation loss: 2.1938834190368652

Epoch: 5| Step: 2
Training loss: 2.129063129425049
Validation loss: 2.192229914408858

Epoch: 5| Step: 3
Training loss: 2.1292290687561035
Validation loss: 2.192211938160722

Epoch: 5| Step: 4
Training loss: 2.516556978225708
Validation loss: 2.1986737840919086

Epoch: 5| Step: 5
Training loss: 1.8819774389266968
Validation loss: 2.207524538040161

Epoch: 5| Step: 6
Training loss: 2.529949188232422
Validation loss: 2.1926380331798265

Epoch: 5| Step: 7
Training loss: 2.8008408546447754
Validation loss: 2.192159183563725

Epoch: 5| Step: 8
Training loss: 2.175236463546753
Validation loss: 2.1917668542554303

Epoch: 5| Step: 9
Training loss: 2.0534274578094482
Validation loss: 2.191519470625026

Epoch: 5| Step: 10
Training loss: 2.0696654319763184
Validation loss: 2.1885219235574045

Epoch: 191| Step: 0
Training loss: 1.3107078075408936
Validation loss: 2.177473812974909

Epoch: 5| Step: 1
Training loss: 2.4780666828155518
Validation loss: 2.1771689653396606

Epoch: 5| Step: 2
Training loss: 1.4305267333984375
Validation loss: 2.1628638980209187

Epoch: 5| Step: 3
Training loss: 1.990573525428772
Validation loss: 2.1749462696813766

Epoch: 5| Step: 4
Training loss: 2.314744472503662
Validation loss: 2.167484632102392

Epoch: 5| Step: 5
Training loss: 2.816032886505127
Validation loss: 2.1892611595892135

Epoch: 5| Step: 6
Training loss: 1.9495751857757568
Validation loss: 2.184540508895792

Epoch: 5| Step: 7
Training loss: 2.5107312202453613
Validation loss: 2.174112494273852

Epoch: 5| Step: 8
Training loss: 2.4514660835266113
Validation loss: 2.181622379569597

Epoch: 5| Step: 9
Training loss: 3.02555513381958
Validation loss: 2.1757586207441104

Epoch: 5| Step: 10
Training loss: 2.3114583492279053
Validation loss: 2.1666369861172092

Epoch: 192| Step: 0
Training loss: 1.7857789993286133
Validation loss: 2.1636045081641084

Epoch: 5| Step: 1
Training loss: 2.160428524017334
Validation loss: 2.1444584400423112

Epoch: 5| Step: 2
Training loss: 2.480945587158203
Validation loss: 2.151286795575132

Epoch: 5| Step: 3
Training loss: 2.494541645050049
Validation loss: 2.1427206211192633

Epoch: 5| Step: 4
Training loss: 1.9074411392211914
Validation loss: 2.158788392620702

Epoch: 5| Step: 5
Training loss: 2.4722096920013428
Validation loss: 2.1470286384705575

Epoch: 5| Step: 6
Training loss: 2.4023640155792236
Validation loss: 2.149478150952247

Epoch: 5| Step: 7
Training loss: 1.8862937688827515
Validation loss: 2.1644772252728863

Epoch: 5| Step: 8
Training loss: 2.3261656761169434
Validation loss: 2.1631574015463553

Epoch: 5| Step: 9
Training loss: 1.9575351476669312
Validation loss: 2.1768209190778833

Epoch: 5| Step: 10
Training loss: 2.7767560482025146
Validation loss: 2.2033783774222098

Epoch: 193| Step: 0
Training loss: 2.1190524101257324
Validation loss: 2.209341679849932

Epoch: 5| Step: 1
Training loss: 1.915300726890564
Validation loss: 2.2039667790935886

Epoch: 5| Step: 2
Training loss: 2.5455031394958496
Validation loss: 2.228085538392426

Epoch: 5| Step: 3
Training loss: 2.074418783187866
Validation loss: 2.235108583204208

Epoch: 5| Step: 4
Training loss: 2.0836119651794434
Validation loss: 2.2185623056145123

Epoch: 5| Step: 5
Training loss: 2.4790265560150146
Validation loss: 2.2320424997678368

Epoch: 5| Step: 6
Training loss: 2.773322582244873
Validation loss: 2.226000342317807

Epoch: 5| Step: 7
Training loss: 1.5182511806488037
Validation loss: 2.1937828961239068

Epoch: 5| Step: 8
Training loss: 2.3720147609710693
Validation loss: 2.1971221713609594

Epoch: 5| Step: 9
Training loss: 2.48673939704895
Validation loss: 2.1797293591242966

Epoch: 5| Step: 10
Training loss: 2.0507144927978516
Validation loss: 2.15646513559485

Epoch: 194| Step: 0
Training loss: 3.008202314376831
Validation loss: 2.1471293510929232

Epoch: 5| Step: 1
Training loss: 1.8265178203582764
Validation loss: 2.152508330601518

Epoch: 5| Step: 2
Training loss: 2.9196295738220215
Validation loss: 2.1377959174494587

Epoch: 5| Step: 3
Training loss: 1.940477728843689
Validation loss: 2.1490043004353843

Epoch: 5| Step: 4
Training loss: 2.2837724685668945
Validation loss: 2.1679260679470596

Epoch: 5| Step: 5
Training loss: 2.3687756061553955
Validation loss: 2.1647531806781726

Epoch: 5| Step: 6
Training loss: 1.76242995262146
Validation loss: 2.139819017020605

Epoch: 5| Step: 7
Training loss: 2.0965964794158936
Validation loss: 2.1465442911271126

Epoch: 5| Step: 8
Training loss: 1.8239904642105103
Validation loss: 2.1656279589540217

Epoch: 5| Step: 9
Training loss: 2.362279176712036
Validation loss: 2.155327561081097

Epoch: 5| Step: 10
Training loss: 1.976191759109497
Validation loss: 2.1739720503489175

Epoch: 195| Step: 0
Training loss: 2.2543303966522217
Validation loss: 2.1996846839945805

Epoch: 5| Step: 1
Training loss: 2.102020740509033
Validation loss: 2.2148748905427995

Epoch: 5| Step: 2
Training loss: 2.2837588787078857
Validation loss: 2.223604538107431

Epoch: 5| Step: 3
Training loss: 2.0547454357147217
Validation loss: 2.244966189066569

Epoch: 5| Step: 4
Training loss: 1.9568836688995361
Validation loss: 2.235858676254108

Epoch: 5| Step: 5
Training loss: 2.4592700004577637
Validation loss: 2.2335714037700365

Epoch: 5| Step: 6
Training loss: 2.1701226234436035
Validation loss: 2.2227994793204853

Epoch: 5| Step: 7
Training loss: 1.9395761489868164
Validation loss: 2.2095704386311192

Epoch: 5| Step: 8
Training loss: 2.395507335662842
Validation loss: 2.20392212944646

Epoch: 5| Step: 9
Training loss: 2.3774516582489014
Validation loss: 2.1934257963652253

Epoch: 5| Step: 10
Training loss: 2.4694483280181885
Validation loss: 2.1776859683375203

Epoch: 196| Step: 0
Training loss: 2.670074701309204
Validation loss: 2.161995110973235

Epoch: 5| Step: 1
Training loss: 2.3354358673095703
Validation loss: 2.184871986348142

Epoch: 5| Step: 2
Training loss: 2.161813259124756
Validation loss: 2.1714367097423923

Epoch: 5| Step: 3
Training loss: 2.367366075515747
Validation loss: 2.177759059013859

Epoch: 5| Step: 4
Training loss: 1.711369514465332
Validation loss: 2.163540570966659

Epoch: 5| Step: 5
Training loss: 2.3514580726623535
Validation loss: 2.177463790421845

Epoch: 5| Step: 6
Training loss: 1.401902437210083
Validation loss: 2.176094100039492

Epoch: 5| Step: 7
Training loss: 2.1366448402404785
Validation loss: 2.176633632311257

Epoch: 5| Step: 8
Training loss: 2.4182918071746826
Validation loss: 2.186296224594116

Epoch: 5| Step: 9
Training loss: 2.315648317337036
Validation loss: 2.200885218958701

Epoch: 5| Step: 10
Training loss: 2.4668798446655273
Validation loss: 2.20638697121733

Epoch: 197| Step: 0
Training loss: 2.3967185020446777
Validation loss: 2.2145573375045613

Epoch: 5| Step: 1
Training loss: 2.3891687393188477
Validation loss: 2.196250105416903

Epoch: 5| Step: 2
Training loss: 2.2584311962127686
Validation loss: 2.1789907447753416

Epoch: 5| Step: 3
Training loss: 2.30338978767395
Validation loss: 2.1685469201816026

Epoch: 5| Step: 4
Training loss: 1.8024685382843018
Validation loss: 2.1675914718258764

Epoch: 5| Step: 5
Training loss: 2.4179282188415527
Validation loss: 2.168512363587656

Epoch: 5| Step: 6
Training loss: 2.488185405731201
Validation loss: 2.154555182303152

Epoch: 5| Step: 7
Training loss: 2.180901050567627
Validation loss: 2.1537717606431697

Epoch: 5| Step: 8
Training loss: 1.5841398239135742
Validation loss: 2.137758962569698

Epoch: 5| Step: 9
Training loss: 1.797908067703247
Validation loss: 2.1463641428178355

Epoch: 5| Step: 10
Training loss: 2.7090606689453125
Validation loss: 2.155690634122459

Epoch: 198| Step: 0
Training loss: 1.9036924839019775
Validation loss: 2.1667932259139193

Epoch: 5| Step: 1
Training loss: 2.3637802600860596
Validation loss: 2.1697516236253964

Epoch: 5| Step: 2
Training loss: 2.303584337234497
Validation loss: 2.1747404426656742

Epoch: 5| Step: 3
Training loss: 2.498180866241455
Validation loss: 2.171992119922433

Epoch: 5| Step: 4
Training loss: 2.1843581199645996
Validation loss: 2.1708305164050032

Epoch: 5| Step: 5
Training loss: 2.1548619270324707
Validation loss: 2.1608703508171985

Epoch: 5| Step: 6
Training loss: 2.077186107635498
Validation loss: 2.165818346443997

Epoch: 5| Step: 7
Training loss: 2.0559563636779785
Validation loss: 2.1634208015216294

Epoch: 5| Step: 8
Training loss: 1.7668569087982178
Validation loss: 2.163653982582913

Epoch: 5| Step: 9
Training loss: 2.3335318565368652
Validation loss: 2.1677832141999276

Epoch: 5| Step: 10
Training loss: 2.517206907272339
Validation loss: 2.1645540678372948

Epoch: 199| Step: 0
Training loss: 2.8476693630218506
Validation loss: 2.1733280663849204

Epoch: 5| Step: 1
Training loss: 2.4958736896514893
Validation loss: 2.1793934196554203

Epoch: 5| Step: 2
Training loss: 1.7006635665893555
Validation loss: 2.1899899667309177

Epoch: 5| Step: 3
Training loss: 2.2368617057800293
Validation loss: 2.1972783868030836

Epoch: 5| Step: 4
Training loss: 2.9689621925354004
Validation loss: 2.199350013527819

Epoch: 5| Step: 5
Training loss: 1.6871964931488037
Validation loss: 2.198440444084906

Epoch: 5| Step: 6
Training loss: 2.0117063522338867
Validation loss: 2.172008832295736

Epoch: 5| Step: 7
Training loss: 2.279585361480713
Validation loss: 2.1644266074703586

Epoch: 5| Step: 8
Training loss: 1.3829891681671143
Validation loss: 2.1996249486041326

Epoch: 5| Step: 9
Training loss: 2.3665943145751953
Validation loss: 2.2276010077486754

Epoch: 5| Step: 10
Training loss: 2.4902384281158447
Validation loss: 2.245644091277994

Epoch: 200| Step: 0
Training loss: 1.8861541748046875
Validation loss: 2.2240960239082255

Epoch: 5| Step: 1
Training loss: 2.1237998008728027
Validation loss: 2.1997521743979505

Epoch: 5| Step: 2
Training loss: 2.0252861976623535
Validation loss: 2.1844569265201526

Epoch: 5| Step: 3
Training loss: 1.409716248512268
Validation loss: 2.18246937951734

Epoch: 5| Step: 4
Training loss: 2.600252628326416
Validation loss: 2.167202473968588

Epoch: 5| Step: 5
Training loss: 3.164156436920166
Validation loss: 2.177454084478399

Epoch: 5| Step: 6
Training loss: 2.4482007026672363
Validation loss: 2.1829170129632436

Epoch: 5| Step: 7
Training loss: 2.207991600036621
Validation loss: 2.1835413491854103

Epoch: 5| Step: 8
Training loss: 1.825626015663147
Validation loss: 2.185707224312649

Epoch: 5| Step: 9
Training loss: 2.1094343662261963
Validation loss: 2.1795534421038885

Epoch: 5| Step: 10
Training loss: 2.59403920173645
Validation loss: 2.1686715925893476

Epoch: 201| Step: 0
Training loss: 2.002385377883911
Validation loss: 2.158105913028922

Epoch: 5| Step: 1
Training loss: 2.353719472885132
Validation loss: 2.151647331894085

Epoch: 5| Step: 2
Training loss: 1.8423839807510376
Validation loss: 2.1575737755785704

Epoch: 5| Step: 3
Training loss: 2.127934455871582
Validation loss: 2.1603837820791427

Epoch: 5| Step: 4
Training loss: 2.0297532081604004
Validation loss: 2.159714347572737

Epoch: 5| Step: 5
Training loss: 2.7048211097717285
Validation loss: 2.1455643394941926

Epoch: 5| Step: 6
Training loss: 1.8923057317733765
Validation loss: 2.157363742910406

Epoch: 5| Step: 7
Training loss: 2.2865374088287354
Validation loss: 2.1640611130704164

Epoch: 5| Step: 8
Training loss: 2.462918758392334
Validation loss: 2.175626552233132

Epoch: 5| Step: 9
Training loss: 2.1804652214050293
Validation loss: 2.1800990386675765

Epoch: 5| Step: 10
Training loss: 2.05584454536438
Validation loss: 2.1804362779022544

Epoch: 202| Step: 0
Training loss: 1.9506351947784424
Validation loss: 2.1702010323924403

Epoch: 5| Step: 1
Training loss: 2.375230550765991
Validation loss: 2.149154629758609

Epoch: 5| Step: 2
Training loss: 2.447882890701294
Validation loss: 2.1357354733251754

Epoch: 5| Step: 3
Training loss: 2.313920736312866
Validation loss: 2.1103217935049408

Epoch: 5| Step: 4
Training loss: 2.2489778995513916
Validation loss: 2.1150131135858516

Epoch: 5| Step: 5
Training loss: 2.339714288711548
Validation loss: 2.1255838166001024

Epoch: 5| Step: 6
Training loss: 1.8715397119522095
Validation loss: 2.140281774664438

Epoch: 5| Step: 7
Training loss: 2.101994514465332
Validation loss: 2.1632918542431248

Epoch: 5| Step: 8
Training loss: 2.3602709770202637
Validation loss: 2.167072688379595

Epoch: 5| Step: 9
Training loss: 1.83322274684906
Validation loss: 2.1835328430257817

Epoch: 5| Step: 10
Training loss: 2.3046605587005615
Validation loss: 2.2014524936676025

Epoch: 203| Step: 0
Training loss: 2.2264022827148438
Validation loss: 2.2349118904400895

Epoch: 5| Step: 1
Training loss: 2.155411720275879
Validation loss: 2.2453286263250534

Epoch: 5| Step: 2
Training loss: 2.1405155658721924
Validation loss: 2.2471686165819884

Epoch: 5| Step: 3
Training loss: 3.265216112136841
Validation loss: 2.2646602661378923

Epoch: 5| Step: 4
Training loss: 2.0516650676727295
Validation loss: 2.246825636074107

Epoch: 5| Step: 5
Training loss: 2.5304718017578125
Validation loss: 2.2100544719285864

Epoch: 5| Step: 6
Training loss: 1.4580186605453491
Validation loss: 2.182977553336851

Epoch: 5| Step: 7
Training loss: 2.0455985069274902
Validation loss: 2.1847635366583384

Epoch: 5| Step: 8
Training loss: 2.0323338508605957
Validation loss: 2.1772144340699717

Epoch: 5| Step: 9
Training loss: 2.3827154636383057
Validation loss: 2.1762279105442826

Epoch: 5| Step: 10
Training loss: 1.9646018743515015
Validation loss: 2.1663656696196525

Epoch: 204| Step: 0
Training loss: 2.7516391277313232
Validation loss: 2.141637784178539

Epoch: 5| Step: 1
Training loss: 2.2252984046936035
Validation loss: 2.1287230214764996

Epoch: 5| Step: 2
Training loss: 2.193711280822754
Validation loss: 2.1070168390068957

Epoch: 5| Step: 3
Training loss: 2.6304562091827393
Validation loss: 2.092430240364485

Epoch: 5| Step: 4
Training loss: 1.7379701137542725
Validation loss: 2.0836530193205802

Epoch: 5| Step: 5
Training loss: 2.3740057945251465
Validation loss: 2.0900115941160466

Epoch: 5| Step: 6
Training loss: 2.1602940559387207
Validation loss: 2.095243707779915

Epoch: 5| Step: 7
Training loss: 2.1089882850646973
Validation loss: 2.0926092017081475

Epoch: 5| Step: 8
Training loss: 1.8715183734893799
Validation loss: 2.132665646973477

Epoch: 5| Step: 9
Training loss: 2.082078218460083
Validation loss: 2.1734849099190003

Epoch: 5| Step: 10
Training loss: 1.9259618520736694
Validation loss: 2.1896880698460404

Epoch: 205| Step: 0
Training loss: 2.3447396755218506
Validation loss: 2.2247534567309963

Epoch: 5| Step: 1
Training loss: 2.3922271728515625
Validation loss: 2.24317027420126

Epoch: 5| Step: 2
Training loss: 3.052147388458252
Validation loss: 2.2473132815412296

Epoch: 5| Step: 3
Training loss: 1.5788311958312988
Validation loss: 2.2552133606326197

Epoch: 5| Step: 4
Training loss: 2.069016218185425
Validation loss: 2.2363597667345436

Epoch: 5| Step: 5
Training loss: 1.625847578048706
Validation loss: 2.2206828914662844

Epoch: 5| Step: 6
Training loss: 1.972895622253418
Validation loss: 2.191121539761943

Epoch: 5| Step: 7
Training loss: 2.042573928833008
Validation loss: 2.1837451368249874

Epoch: 5| Step: 8
Training loss: 2.33223295211792
Validation loss: 2.1522862347223426

Epoch: 5| Step: 9
Training loss: 2.0333504676818848
Validation loss: 2.155133629357943

Epoch: 5| Step: 10
Training loss: 2.414693593978882
Validation loss: 2.153125501448108

Epoch: 206| Step: 0
Training loss: 2.330742597579956
Validation loss: 2.1394513037896927

Epoch: 5| Step: 1
Training loss: 1.9834277629852295
Validation loss: 2.1388964832469983

Epoch: 5| Step: 2
Training loss: 2.1518771648406982
Validation loss: 2.1214448636577976

Epoch: 5| Step: 3
Training loss: 1.8851673603057861
Validation loss: 2.1111119062669816

Epoch: 5| Step: 4
Training loss: 2.2308831214904785
Validation loss: 2.118994015519337

Epoch: 5| Step: 5
Training loss: 2.1992478370666504
Validation loss: 2.1190425965093795

Epoch: 5| Step: 6
Training loss: 2.805433750152588
Validation loss: 2.139892566588617

Epoch: 5| Step: 7
Training loss: 2.5113253593444824
Validation loss: 2.145738140229256

Epoch: 5| Step: 8
Training loss: 2.0899202823638916
Validation loss: 2.153354917803118

Epoch: 5| Step: 9
Training loss: 1.695335030555725
Validation loss: 2.1584188809958835

Epoch: 5| Step: 10
Training loss: 1.8648288249969482
Validation loss: 2.1721824292213685

Epoch: 207| Step: 0
Training loss: 2.6230664253234863
Validation loss: 2.165722131729126

Epoch: 5| Step: 1
Training loss: 1.6282901763916016
Validation loss: 2.181955599015759

Epoch: 5| Step: 2
Training loss: 1.7678191661834717
Validation loss: 2.173021904883846

Epoch: 5| Step: 3
Training loss: 1.9999592304229736
Validation loss: 2.1681712519737983

Epoch: 5| Step: 4
Training loss: 1.4891304969787598
Validation loss: 2.1930041543899046

Epoch: 5| Step: 5
Training loss: 3.2916438579559326
Validation loss: 2.2229033695754183

Epoch: 5| Step: 6
Training loss: 2.6743648052215576
Validation loss: 2.2380071096522833

Epoch: 5| Step: 7
Training loss: 2.0153110027313232
Validation loss: 2.237768850018901

Epoch: 5| Step: 8
Training loss: 2.175126314163208
Validation loss: 2.237205425898234

Epoch: 5| Step: 9
Training loss: 2.1881611347198486
Validation loss: 2.2048917201257523

Epoch: 5| Step: 10
Training loss: 1.863537311553955
Validation loss: 2.1952924754029963

Epoch: 208| Step: 0
Training loss: 2.182569980621338
Validation loss: 2.1948989975836968

Epoch: 5| Step: 1
Training loss: 1.8234326839447021
Validation loss: 2.1976424827370593

Epoch: 5| Step: 2
Training loss: 1.9213424921035767
Validation loss: 2.189133572322066

Epoch: 5| Step: 3
Training loss: 2.2735583782196045
Validation loss: 2.1774723811816146

Epoch: 5| Step: 4
Training loss: 1.6409591436386108
Validation loss: 2.178078264318487

Epoch: 5| Step: 5
Training loss: 2.2360002994537354
Validation loss: 2.1811846866402576

Epoch: 5| Step: 6
Training loss: 2.1216742992401123
Validation loss: 2.1695979231147358

Epoch: 5| Step: 7
Training loss: 2.2026591300964355
Validation loss: 2.153520873797837

Epoch: 5| Step: 8
Training loss: 2.620323896408081
Validation loss: 2.137843660129014

Epoch: 5| Step: 9
Training loss: 2.649793863296509
Validation loss: 2.1349506762719925

Epoch: 5| Step: 10
Training loss: 1.8739978075027466
Validation loss: 2.12727366980686

Epoch: 209| Step: 0
Training loss: 2.7584519386291504
Validation loss: 2.10394621920842

Epoch: 5| Step: 1
Training loss: 2.0530755519866943
Validation loss: 2.099580277678787

Epoch: 5| Step: 2
Training loss: 2.0625791549682617
Validation loss: 2.1166911804547874

Epoch: 5| Step: 3
Training loss: 2.0135598182678223
Validation loss: 2.1078786439793085

Epoch: 5| Step: 4
Training loss: 1.8758647441864014
Validation loss: 2.1309692731467624

Epoch: 5| Step: 5
Training loss: 1.9406883716583252
Validation loss: 2.1551257051447386

Epoch: 5| Step: 6
Training loss: 2.558589458465576
Validation loss: 2.1721202147904264

Epoch: 5| Step: 7
Training loss: 2.118194103240967
Validation loss: 2.1575020538863314

Epoch: 5| Step: 8
Training loss: 2.357577085494995
Validation loss: 2.1497374862752934

Epoch: 5| Step: 9
Training loss: 1.8988101482391357
Validation loss: 2.1355490351235993

Epoch: 5| Step: 10
Training loss: 2.078770875930786
Validation loss: 2.138090214421672

Epoch: 210| Step: 0
Training loss: 1.986660361289978
Validation loss: 2.1708061618189656

Epoch: 5| Step: 1
Training loss: 1.9228025674819946
Validation loss: 2.184910084611626

Epoch: 5| Step: 2
Training loss: 1.787959337234497
Validation loss: 2.2072214336805445

Epoch: 5| Step: 3
Training loss: 1.6646400690078735
Validation loss: 2.2216964908825454

Epoch: 5| Step: 4
Training loss: 2.578622579574585
Validation loss: 2.2052931170309744

Epoch: 5| Step: 5
Training loss: 2.0875179767608643
Validation loss: 2.1963532906706615

Epoch: 5| Step: 6
Training loss: 2.7068397998809814
Validation loss: 2.1939875592467604

Epoch: 5| Step: 7
Training loss: 2.308234930038452
Validation loss: 2.179667419002902

Epoch: 5| Step: 8
Training loss: 1.651741623878479
Validation loss: 2.1742340736491705

Epoch: 5| Step: 9
Training loss: 2.4499289989471436
Validation loss: 2.1766529852344143

Epoch: 5| Step: 10
Training loss: 2.394063949584961
Validation loss: 2.1928066361335015

Epoch: 211| Step: 0
Training loss: 2.469503164291382
Validation loss: 2.1904501415068105

Epoch: 5| Step: 1
Training loss: 2.186645030975342
Validation loss: 2.1651016691679597

Epoch: 5| Step: 2
Training loss: 2.087294101715088
Validation loss: 2.1471466864309003

Epoch: 5| Step: 3
Training loss: 2.630706548690796
Validation loss: 2.152162321152226

Epoch: 5| Step: 4
Training loss: 1.6339943408966064
Validation loss: 2.1412128222885953

Epoch: 5| Step: 5
Training loss: 1.673248529434204
Validation loss: 2.141526565756849

Epoch: 5| Step: 6
Training loss: 2.337237596511841
Validation loss: 2.146673804970198

Epoch: 5| Step: 7
Training loss: 2.1026782989501953
Validation loss: 2.1549547820962887

Epoch: 5| Step: 8
Training loss: 2.0621657371520996
Validation loss: 2.1707487439596527

Epoch: 5| Step: 9
Training loss: 2.6763458251953125
Validation loss: 2.18867665208796

Epoch: 5| Step: 10
Training loss: 1.769816279411316
Validation loss: 2.1922109716682026

Epoch: 212| Step: 0
Training loss: 2.0861949920654297
Validation loss: 2.188035483001381

Epoch: 5| Step: 1
Training loss: 2.023463726043701
Validation loss: 2.181007395508469

Epoch: 5| Step: 2
Training loss: 2.1965415477752686
Validation loss: 2.1715633946080364

Epoch: 5| Step: 3
Training loss: 2.026301860809326
Validation loss: 2.163924664579412

Epoch: 5| Step: 4
Training loss: 2.014829158782959
Validation loss: 2.174404985161238

Epoch: 5| Step: 5
Training loss: 1.9150207042694092
Validation loss: 2.168971109133895

Epoch: 5| Step: 6
Training loss: 2.6482651233673096
Validation loss: 2.1691510510701004

Epoch: 5| Step: 7
Training loss: 1.435066819190979
Validation loss: 2.158148237453994

Epoch: 5| Step: 8
Training loss: 2.847568988800049
Validation loss: 2.1579248930818293

Epoch: 5| Step: 9
Training loss: 2.00412917137146
Validation loss: 2.1487248841152398

Epoch: 5| Step: 10
Training loss: 2.2801454067230225
Validation loss: 2.1313017055552494

Epoch: 213| Step: 0
Training loss: 2.1898226737976074
Validation loss: 2.1238555318565777

Epoch: 5| Step: 1
Training loss: 1.9055455923080444
Validation loss: 2.1115463202999485

Epoch: 5| Step: 2
Training loss: 2.3543264865875244
Validation loss: 2.1328762359516595

Epoch: 5| Step: 3
Training loss: 1.8807518482208252
Validation loss: 2.158760204110094

Epoch: 5| Step: 4
Training loss: 2.743664264678955
Validation loss: 2.1547606196454776

Epoch: 5| Step: 5
Training loss: 1.7988485097885132
Validation loss: 2.176207620610473

Epoch: 5| Step: 6
Training loss: 1.7403762340545654
Validation loss: 2.149187313613071

Epoch: 5| Step: 7
Training loss: 2.789064645767212
Validation loss: 2.1503686789543397

Epoch: 5| Step: 8
Training loss: 1.4964759349822998
Validation loss: 2.1594795770542596

Epoch: 5| Step: 9
Training loss: 2.69956636428833
Validation loss: 2.1407439952255576

Epoch: 5| Step: 10
Training loss: 1.7259447574615479
Validation loss: 2.1479744372829312

Epoch: 214| Step: 0
Training loss: 2.046849012374878
Validation loss: 2.13110625872048

Epoch: 5| Step: 1
Training loss: 1.8537101745605469
Validation loss: 2.1294687742828042

Epoch: 5| Step: 2
Training loss: 1.9493519067764282
Validation loss: 2.1222620958923013

Epoch: 5| Step: 3
Training loss: 1.805119514465332
Validation loss: 2.1102371215820312

Epoch: 5| Step: 4
Training loss: 1.8001558780670166
Validation loss: 2.0999941774593887

Epoch: 5| Step: 5
Training loss: 1.8561265468597412
Validation loss: 2.1025002259080128

Epoch: 5| Step: 6
Training loss: 2.014812469482422
Validation loss: 2.117607009026312

Epoch: 5| Step: 7
Training loss: 3.2883541584014893
Validation loss: 2.140734395673198

Epoch: 5| Step: 8
Training loss: 1.8204138278961182
Validation loss: 2.1340184480913225

Epoch: 5| Step: 9
Training loss: 2.040691375732422
Validation loss: 2.162558554321207

Epoch: 5| Step: 10
Training loss: 2.9053523540496826
Validation loss: 2.1753482408421014

Epoch: 215| Step: 0
Training loss: 1.7393802404403687
Validation loss: 2.173257722649523

Epoch: 5| Step: 1
Training loss: 1.9810526371002197
Validation loss: 2.1543695349847116

Epoch: 5| Step: 2
Training loss: 1.4773905277252197
Validation loss: 2.156770021684708

Epoch: 5| Step: 3
Training loss: 2.404193878173828
Validation loss: 2.14646743189904

Epoch: 5| Step: 4
Training loss: 2.3696844577789307
Validation loss: 2.169535016500822

Epoch: 5| Step: 5
Training loss: 2.0650739669799805
Validation loss: 2.1504550185254825

Epoch: 5| Step: 6
Training loss: 2.133805274963379
Validation loss: 2.143518809349306

Epoch: 5| Step: 7
Training loss: 2.11125111579895
Validation loss: 2.123624941354157

Epoch: 5| Step: 8
Training loss: 2.639909267425537
Validation loss: 2.1121674404349378

Epoch: 5| Step: 9
Training loss: 2.258333444595337
Validation loss: 2.1163234608147734

Epoch: 5| Step: 10
Training loss: 1.9449381828308105
Validation loss: 2.1154800268911544

Epoch: 216| Step: 0
Training loss: 2.8052749633789062
Validation loss: 2.137137838589248

Epoch: 5| Step: 1
Training loss: 1.8587844371795654
Validation loss: 2.142016656937138

Epoch: 5| Step: 2
Training loss: 1.7487484216690063
Validation loss: 2.1433876983581053

Epoch: 5| Step: 3
Training loss: 1.9900696277618408
Validation loss: 2.1574313602139874

Epoch: 5| Step: 4
Training loss: 1.7732248306274414
Validation loss: 2.172306499173564

Epoch: 5| Step: 5
Training loss: 2.1890556812286377
Validation loss: 2.1725279336334555

Epoch: 5| Step: 6
Training loss: 2.1220312118530273
Validation loss: 2.1463768892390753

Epoch: 5| Step: 7
Training loss: 2.278916835784912
Validation loss: 2.1422820450157247

Epoch: 5| Step: 8
Training loss: 1.8746486902236938
Validation loss: 2.136529476411881

Epoch: 5| Step: 9
Training loss: 2.1534626483917236
Validation loss: 2.101002476548636

Epoch: 5| Step: 10
Training loss: 2.268240213394165
Validation loss: 2.0924227442792667

Epoch: 217| Step: 0
Training loss: 2.372056245803833
Validation loss: 2.0763304195096417

Epoch: 5| Step: 1
Training loss: 1.9029251337051392
Validation loss: 2.0791347924099175

Epoch: 5| Step: 2
Training loss: 2.122986316680908
Validation loss: 2.079740755019649

Epoch: 5| Step: 3
Training loss: 2.225254535675049
Validation loss: 2.0704094209978656

Epoch: 5| Step: 4
Training loss: 1.5524089336395264
Validation loss: 2.0807448664019184

Epoch: 5| Step: 5
Training loss: 2.548980712890625
Validation loss: 2.138407520068589

Epoch: 5| Step: 6
Training loss: 2.7674720287323
Validation loss: 2.172631417551348

Epoch: 5| Step: 7
Training loss: 1.590708613395691
Validation loss: 2.1727092624992452

Epoch: 5| Step: 8
Training loss: 2.1946449279785156
Validation loss: 2.166238416907608

Epoch: 5| Step: 9
Training loss: 1.695488691329956
Validation loss: 2.154184159412179

Epoch: 5| Step: 10
Training loss: 2.4364447593688965
Validation loss: 2.1504390444806827

Epoch: 218| Step: 0
Training loss: 2.581923484802246
Validation loss: 2.1414703374267905

Epoch: 5| Step: 1
Training loss: 2.8669538497924805
Validation loss: 2.1350135367403746

Epoch: 5| Step: 2
Training loss: 2.053811550140381
Validation loss: 2.137400516899683

Epoch: 5| Step: 3
Training loss: 1.8329635858535767
Validation loss: 2.157034130506618

Epoch: 5| Step: 4
Training loss: 2.147106170654297
Validation loss: 2.17879343289201

Epoch: 5| Step: 5
Training loss: 1.4212559461593628
Validation loss: 2.1611090270421838

Epoch: 5| Step: 6
Training loss: 1.3881175518035889
Validation loss: 2.1596002591553556

Epoch: 5| Step: 7
Training loss: 2.0665366649627686
Validation loss: 2.1311210945088375

Epoch: 5| Step: 8
Training loss: 2.4268293380737305
Validation loss: 2.1113441298084874

Epoch: 5| Step: 9
Training loss: 2.363359212875366
Validation loss: 2.1157330082308863

Epoch: 5| Step: 10
Training loss: 2.030794382095337
Validation loss: 2.1148042537832774

Epoch: 219| Step: 0
Training loss: 2.379580020904541
Validation loss: 2.136492636895949

Epoch: 5| Step: 1
Training loss: 1.9019708633422852
Validation loss: 2.1606396910964802

Epoch: 5| Step: 2
Training loss: 1.8209741115570068
Validation loss: 2.181215445200602

Epoch: 5| Step: 3
Training loss: 2.057765483856201
Validation loss: 2.1782331300038162

Epoch: 5| Step: 4
Training loss: 1.763827919960022
Validation loss: 2.170479687311316

Epoch: 5| Step: 5
Training loss: 2.7001707553863525
Validation loss: 2.1740798911740704

Epoch: 5| Step: 6
Training loss: 1.9456322193145752
Validation loss: 2.147230861007526

Epoch: 5| Step: 7
Training loss: 2.655085802078247
Validation loss: 2.1282476199570524

Epoch: 5| Step: 8
Training loss: 1.9697643518447876
Validation loss: 2.136329092005248

Epoch: 5| Step: 9
Training loss: 2.013685703277588
Validation loss: 2.1557315062451106

Epoch: 5| Step: 10
Training loss: 2.0263614654541016
Validation loss: 2.1307951083747287

Epoch: 220| Step: 0
Training loss: 1.8790076971054077
Validation loss: 2.11794707082933

Epoch: 5| Step: 1
Training loss: 2.102898359298706
Validation loss: 2.104647692813668

Epoch: 5| Step: 2
Training loss: 2.0464491844177246
Validation loss: 2.0926009160216137

Epoch: 5| Step: 3
Training loss: 2.4329452514648438
Validation loss: 2.092642722591277

Epoch: 5| Step: 4
Training loss: 1.8065783977508545
Validation loss: 2.081888441116579

Epoch: 5| Step: 5
Training loss: 1.8360583782196045
Validation loss: 2.093106100636144

Epoch: 5| Step: 6
Training loss: 2.0788516998291016
Validation loss: 2.1114324754284275

Epoch: 5| Step: 7
Training loss: 2.2378244400024414
Validation loss: 2.1598991706807125

Epoch: 5| Step: 8
Training loss: 2.2433576583862305
Validation loss: 2.193508517357611

Epoch: 5| Step: 9
Training loss: 1.8568769693374634
Validation loss: 2.232770953127133

Epoch: 5| Step: 10
Training loss: 2.7621026039123535
Validation loss: 2.2088333868211314

Epoch: 221| Step: 0
Training loss: 2.813645839691162
Validation loss: 2.156546247902737

Epoch: 5| Step: 1
Training loss: 1.6829372644424438
Validation loss: 2.110353554448774

Epoch: 5| Step: 2
Training loss: 1.9425880908966064
Validation loss: 2.0812491293876403

Epoch: 5| Step: 3
Training loss: 2.4531798362731934
Validation loss: 2.1082944703358475

Epoch: 5| Step: 4
Training loss: 1.9787784814834595
Validation loss: 2.137395517800444

Epoch: 5| Step: 5
Training loss: 1.6858961582183838
Validation loss: 2.1471807456785634

Epoch: 5| Step: 6
Training loss: 2.0226030349731445
Validation loss: 2.1372878577119563

Epoch: 5| Step: 7
Training loss: 2.6705143451690674
Validation loss: 2.1375822392843102

Epoch: 5| Step: 8
Training loss: 1.913560152053833
Validation loss: 2.1171553980919624

Epoch: 5| Step: 9
Training loss: 1.7350505590438843
Validation loss: 2.0803634889664187

Epoch: 5| Step: 10
Training loss: 2.1240241527557373
Validation loss: 2.0864576934486307

Epoch: 222| Step: 0
Training loss: 1.848783254623413
Validation loss: 2.0904515891946773

Epoch: 5| Step: 1
Training loss: 2.191502571105957
Validation loss: 2.1051671620338195

Epoch: 5| Step: 2
Training loss: 1.9796606302261353
Validation loss: 2.1217639600076983

Epoch: 5| Step: 3
Training loss: 2.2270216941833496
Validation loss: 2.1366400693052556

Epoch: 5| Step: 4
Training loss: 2.682311534881592
Validation loss: 2.137126697007046

Epoch: 5| Step: 5
Training loss: 2.0152459144592285
Validation loss: 2.1362160175077376

Epoch: 5| Step: 6
Training loss: 1.9125566482543945
Validation loss: 2.1006004938515286

Epoch: 5| Step: 7
Training loss: 2.05584716796875
Validation loss: 2.0749185828752417

Epoch: 5| Step: 8
Training loss: 2.17036771774292
Validation loss: 2.0676096049688195

Epoch: 5| Step: 9
Training loss: 2.065365791320801
Validation loss: 2.072529057020782

Epoch: 5| Step: 10
Training loss: 1.954100489616394
Validation loss: 2.0748089744198706

Epoch: 223| Step: 0
Training loss: 1.4896328449249268
Validation loss: 2.083034771744923

Epoch: 5| Step: 1
Training loss: 2.4894278049468994
Validation loss: 2.104826909239574

Epoch: 5| Step: 2
Training loss: 1.9544814825057983
Validation loss: 2.1240643865318707

Epoch: 5| Step: 3
Training loss: 1.9184677600860596
Validation loss: 2.156862942121362

Epoch: 5| Step: 4
Training loss: 1.656292200088501
Validation loss: 2.168047620404151

Epoch: 5| Step: 5
Training loss: 2.2913196086883545
Validation loss: 2.1803192579618065

Epoch: 5| Step: 6
Training loss: 2.0939595699310303
Validation loss: 2.1636784576600596

Epoch: 5| Step: 7
Training loss: 2.7032878398895264
Validation loss: 2.1702957409684376

Epoch: 5| Step: 8
Training loss: 1.9502503871917725
Validation loss: 2.1661807772933797

Epoch: 5| Step: 9
Training loss: 2.215074062347412
Validation loss: 2.137734397765129

Epoch: 5| Step: 10
Training loss: 2.1366629600524902
Validation loss: 2.129140402681084

Epoch: 224| Step: 0
Training loss: 2.673948049545288
Validation loss: 2.122800438634811

Epoch: 5| Step: 1
Training loss: 2.4090800285339355
Validation loss: 2.1107550974815124

Epoch: 5| Step: 2
Training loss: 1.31802237033844
Validation loss: 2.097296994219544

Epoch: 5| Step: 3
Training loss: 2.8151237964630127
Validation loss: 2.0900947099090903

Epoch: 5| Step: 4
Training loss: 1.9474728107452393
Validation loss: 2.0845812033581477

Epoch: 5| Step: 5
Training loss: 2.1402244567871094
Validation loss: 2.0762702265093402

Epoch: 5| Step: 6
Training loss: 2.4848735332489014
Validation loss: 2.080569521073372

Epoch: 5| Step: 7
Training loss: 1.878658652305603
Validation loss: 2.078857955112252

Epoch: 5| Step: 8
Training loss: 1.9343042373657227
Validation loss: 2.0866300546994774

Epoch: 5| Step: 9
Training loss: 1.566845178604126
Validation loss: 2.097371521816459

Epoch: 5| Step: 10
Training loss: 1.432757019996643
Validation loss: 2.1046560118275304

Epoch: 225| Step: 0
Training loss: 1.6854183673858643
Validation loss: 2.1209852618555867

Epoch: 5| Step: 1
Training loss: 1.9881603717803955
Validation loss: 2.1241774648748417

Epoch: 5| Step: 2
Training loss: 1.6712348461151123
Validation loss: 2.1271731712484874

Epoch: 5| Step: 3
Training loss: 2.2844138145446777
Validation loss: 2.1055012620905393

Epoch: 5| Step: 4
Training loss: 1.6413511037826538
Validation loss: 2.1162325412996355

Epoch: 5| Step: 5
Training loss: 1.6242519617080688
Validation loss: 2.1153332097556

Epoch: 5| Step: 6
Training loss: 1.9950695037841797
Validation loss: 2.108407046205254

Epoch: 5| Step: 7
Training loss: 2.130953311920166
Validation loss: 2.109549576236356

Epoch: 5| Step: 8
Training loss: 2.3146281242370605
Validation loss: 2.1122353282026065

Epoch: 5| Step: 9
Training loss: 2.6334667205810547
Validation loss: 2.1058624944379254

Epoch: 5| Step: 10
Training loss: 2.6703124046325684
Validation loss: 2.0890033386086904

Epoch: 226| Step: 0
Training loss: 2.3348865509033203
Validation loss: 2.101092520580497

Epoch: 5| Step: 1
Training loss: 1.5268243551254272
Validation loss: 2.083782547263689

Epoch: 5| Step: 2
Training loss: 2.246330738067627
Validation loss: 2.0747270302105973

Epoch: 5| Step: 3
Training loss: 2.1428921222686768
Validation loss: 2.066605180822393

Epoch: 5| Step: 4
Training loss: 2.63862943649292
Validation loss: 2.0833069662893973

Epoch: 5| Step: 5
Training loss: 1.9308617115020752
Validation loss: 2.0839128468626287

Epoch: 5| Step: 6
Training loss: 1.7084972858428955
Validation loss: 2.104391247995438

Epoch: 5| Step: 7
Training loss: 2.35963773727417
Validation loss: 2.123419133565759

Epoch: 5| Step: 8
Training loss: 1.580533742904663
Validation loss: 2.115443229675293

Epoch: 5| Step: 9
Training loss: 1.9302291870117188
Validation loss: 2.135877663089383

Epoch: 5| Step: 10
Training loss: 2.341648817062378
Validation loss: 2.1342439523307224

Epoch: 227| Step: 0
Training loss: 1.8372598886489868
Validation loss: 2.1586684014207576

Epoch: 5| Step: 1
Training loss: 2.276160717010498
Validation loss: 2.180846312994598

Epoch: 5| Step: 2
Training loss: 2.472486734390259
Validation loss: 2.1795883717075473

Epoch: 5| Step: 3
Training loss: 1.4402446746826172
Validation loss: 2.1588364006370626

Epoch: 5| Step: 4
Training loss: 1.9878828525543213
Validation loss: 2.1347920240894442

Epoch: 5| Step: 5
Training loss: 2.369210720062256
Validation loss: 2.122414312055034

Epoch: 5| Step: 6
Training loss: 1.9255609512329102
Validation loss: 2.129615363254342

Epoch: 5| Step: 7
Training loss: 1.9427131414413452
Validation loss: 2.1277927660172984

Epoch: 5| Step: 8
Training loss: 1.6600253582000732
Validation loss: 2.117573102315267

Epoch: 5| Step: 9
Training loss: 2.37644362449646
Validation loss: 2.1062592050080657

Epoch: 5| Step: 10
Training loss: 2.4157392978668213
Validation loss: 2.0852209086059244

Epoch: 228| Step: 0
Training loss: 2.1805644035339355
Validation loss: 2.0814327116935485

Epoch: 5| Step: 1
Training loss: 1.7832496166229248
Validation loss: 2.0731958573864353

Epoch: 5| Step: 2
Training loss: 1.9622408151626587
Validation loss: 2.0640636362055296

Epoch: 5| Step: 3
Training loss: 2.208800792694092
Validation loss: 2.0595554203115483

Epoch: 5| Step: 4
Training loss: 2.204606294631958
Validation loss: 2.055705690896639

Epoch: 5| Step: 5
Training loss: 1.6312437057495117
Validation loss: 2.0590048784850747

Epoch: 5| Step: 6
Training loss: 1.5120049715042114
Validation loss: 2.067988185472386

Epoch: 5| Step: 7
Training loss: 2.258847951889038
Validation loss: 2.080106915966157

Epoch: 5| Step: 8
Training loss: 2.058152914047241
Validation loss: 2.089770519605247

Epoch: 5| Step: 9
Training loss: 2.977492094039917
Validation loss: 2.1151255792187107

Epoch: 5| Step: 10
Training loss: 1.727361798286438
Validation loss: 2.12203041712443

Epoch: 229| Step: 0
Training loss: 2.3479533195495605
Validation loss: 2.1289347038474133

Epoch: 5| Step: 1
Training loss: 2.158830165863037
Validation loss: 2.138171463884333

Epoch: 5| Step: 2
Training loss: 1.5556206703186035
Validation loss: 2.1319184764739005

Epoch: 5| Step: 3
Training loss: 2.031604051589966
Validation loss: 2.129690113887992

Epoch: 5| Step: 4
Training loss: 1.729119062423706
Validation loss: 2.111246742228026

Epoch: 5| Step: 5
Training loss: 2.7651114463806152
Validation loss: 2.1043759571608676

Epoch: 5| Step: 6
Training loss: 2.1538920402526855
Validation loss: 2.089002768198649

Epoch: 5| Step: 7
Training loss: 2.084017276763916
Validation loss: 2.08623844064692

Epoch: 5| Step: 8
Training loss: 2.0341484546661377
Validation loss: 2.0724084120924755

Epoch: 5| Step: 9
Training loss: 1.7164300680160522
Validation loss: 2.0624702028048936

Epoch: 5| Step: 10
Training loss: 1.8917014598846436
Validation loss: 2.0667267563522502

Epoch: 230| Step: 0
Training loss: 1.5465192794799805
Validation loss: 2.0868264987904537

Epoch: 5| Step: 1
Training loss: 1.9519317150115967
Validation loss: 2.084557460200402

Epoch: 5| Step: 2
Training loss: 2.4477410316467285
Validation loss: 2.108674451869021

Epoch: 5| Step: 3
Training loss: 2.2610201835632324
Validation loss: 2.0981954220802552

Epoch: 5| Step: 4
Training loss: 1.6686456203460693
Validation loss: 2.061924849787066

Epoch: 5| Step: 5
Training loss: 2.043203830718994
Validation loss: 2.0592884197030017

Epoch: 5| Step: 6
Training loss: 1.9177510738372803
Validation loss: 2.0788233805728216

Epoch: 5| Step: 7
Training loss: 2.153743028640747
Validation loss: 2.0731923939079366

Epoch: 5| Step: 8
Training loss: 2.1294045448303223
Validation loss: 2.102986717736849

Epoch: 5| Step: 9
Training loss: 2.3491687774658203
Validation loss: 2.1166777328778337

Epoch: 5| Step: 10
Training loss: 1.9135109186172485
Validation loss: 2.136891835479326

Epoch: 231| Step: 0
Training loss: 2.696901798248291
Validation loss: 2.161299717041754

Epoch: 5| Step: 1
Training loss: 1.5893869400024414
Validation loss: 2.1695967848582933

Epoch: 5| Step: 2
Training loss: 2.243281602859497
Validation loss: 2.1440070829083844

Epoch: 5| Step: 3
Training loss: 1.7108074426651
Validation loss: 2.115695148385981

Epoch: 5| Step: 4
Training loss: 2.314352035522461
Validation loss: 2.1061718617716143

Epoch: 5| Step: 5
Training loss: 2.1847944259643555
Validation loss: 2.092757640346404

Epoch: 5| Step: 6
Training loss: 1.5903055667877197
Validation loss: 2.0939752273662116

Epoch: 5| Step: 7
Training loss: 1.4190458059310913
Validation loss: 2.08022589196441

Epoch: 5| Step: 8
Training loss: 2.5804924964904785
Validation loss: 2.099318624824606

Epoch: 5| Step: 9
Training loss: 2.2789065837860107
Validation loss: 2.138135166578395

Epoch: 5| Step: 10
Training loss: 1.9440706968307495
Validation loss: 2.1566188668691986

Epoch: 232| Step: 0
Training loss: 2.329798936843872
Validation loss: 2.1495526554763957

Epoch: 5| Step: 1
Training loss: 1.7161865234375
Validation loss: 2.1569247091970136

Epoch: 5| Step: 2
Training loss: 1.3844181299209595
Validation loss: 2.1537390191067933

Epoch: 5| Step: 3
Training loss: 2.091946840286255
Validation loss: 2.159019313832765

Epoch: 5| Step: 4
Training loss: 2.3813796043395996
Validation loss: 2.1387932890204975

Epoch: 5| Step: 5
Training loss: 1.5636069774627686
Validation loss: 2.1274095081513926

Epoch: 5| Step: 6
Training loss: 2.5666518211364746
Validation loss: 2.1179240634364467

Epoch: 5| Step: 7
Training loss: 2.164597988128662
Validation loss: 2.1061497042256017

Epoch: 5| Step: 8
Training loss: 2.180903911590576
Validation loss: 2.088644460965228

Epoch: 5| Step: 9
Training loss: 1.6912431716918945
Validation loss: 2.094933650826895

Epoch: 5| Step: 10
Training loss: 2.4629127979278564
Validation loss: 2.1092790544673963

Epoch: 233| Step: 0
Training loss: 2.6206021308898926
Validation loss: 2.109007130387009

Epoch: 5| Step: 1
Training loss: 1.991715431213379
Validation loss: 2.084324872621926

Epoch: 5| Step: 2
Training loss: 2.2768285274505615
Validation loss: 2.082606359194684

Epoch: 5| Step: 3
Training loss: 2.3810887336730957
Validation loss: 2.072838993482692

Epoch: 5| Step: 4
Training loss: 2.079587459564209
Validation loss: 2.0783613445938274

Epoch: 5| Step: 5
Training loss: 1.5125378370285034
Validation loss: 2.0646696911063245

Epoch: 5| Step: 6
Training loss: 1.8835493326187134
Validation loss: 2.08161344323107

Epoch: 5| Step: 7
Training loss: 2.1369986534118652
Validation loss: 2.0941465234243744

Epoch: 5| Step: 8
Training loss: 1.9387257099151611
Validation loss: 2.0667723417282104

Epoch: 5| Step: 9
Training loss: 1.6103525161743164
Validation loss: 2.0886083367050334

Epoch: 5| Step: 10
Training loss: 1.7833225727081299
Validation loss: 2.1054615256606892

Epoch: 234| Step: 0
Training loss: 1.5763508081436157
Validation loss: 2.102156928790513

Epoch: 5| Step: 1
Training loss: 2.4300389289855957
Validation loss: 2.1104978181982554

Epoch: 5| Step: 2
Training loss: 1.9781248569488525
Validation loss: 2.1163649597475604

Epoch: 5| Step: 3
Training loss: 1.3843200206756592
Validation loss: 2.109509914152084

Epoch: 5| Step: 4
Training loss: 1.8650010824203491
Validation loss: 2.1109496137147308

Epoch: 5| Step: 5
Training loss: 2.0769639015197754
Validation loss: 2.101348703907382

Epoch: 5| Step: 6
Training loss: 2.0246405601501465
Validation loss: 2.1016360303407073

Epoch: 5| Step: 7
Training loss: 1.6856660842895508
Validation loss: 2.1175780706508185

Epoch: 5| Step: 8
Training loss: 2.4865822792053223
Validation loss: 2.1270247890103247

Epoch: 5| Step: 9
Training loss: 2.223811149597168
Validation loss: 2.135976755490867

Epoch: 5| Step: 10
Training loss: 2.599231243133545
Validation loss: 2.1099715450758576

Epoch: 235| Step: 0
Training loss: 1.8021494150161743
Validation loss: 2.109852247340705

Epoch: 5| Step: 1
Training loss: 1.7496116161346436
Validation loss: 2.145516990333475

Epoch: 5| Step: 2
Training loss: 1.9628121852874756
Validation loss: 2.171486839171379

Epoch: 5| Step: 3
Training loss: 1.953885793685913
Validation loss: 2.176517940336658

Epoch: 5| Step: 4
Training loss: 2.575824737548828
Validation loss: 2.1502910660159205

Epoch: 5| Step: 5
Training loss: 1.5930503606796265
Validation loss: 2.1210648885337253

Epoch: 5| Step: 6
Training loss: 2.124136447906494
Validation loss: 2.097613342346684

Epoch: 5| Step: 7
Training loss: 2.1123874187469482
Validation loss: 2.1171569221763202

Epoch: 5| Step: 8
Training loss: 1.9184939861297607
Validation loss: 2.1164936224619546

Epoch: 5| Step: 9
Training loss: 2.6883270740509033
Validation loss: 2.1231626874657086

Epoch: 5| Step: 10
Training loss: 2.1948037147521973
Validation loss: 2.135648547962148

Epoch: 236| Step: 0
Training loss: 2.782258987426758
Validation loss: 2.110141315767842

Epoch: 5| Step: 1
Training loss: 1.9797308444976807
Validation loss: 2.100097975423259

Epoch: 5| Step: 2
Training loss: 2.067375659942627
Validation loss: 2.075510178842852

Epoch: 5| Step: 3
Training loss: 1.996485948562622
Validation loss: 2.047197962319979

Epoch: 5| Step: 4
Training loss: 1.8590080738067627
Validation loss: 2.0285526629417174

Epoch: 5| Step: 5
Training loss: 2.1568362712860107
Validation loss: 2.0191324103263115

Epoch: 5| Step: 6
Training loss: 1.743093490600586
Validation loss: 2.0320614012338782

Epoch: 5| Step: 7
Training loss: 1.914380431175232
Validation loss: 2.0392236017411753

Epoch: 5| Step: 8
Training loss: 1.8468506336212158
Validation loss: 2.035238769746596

Epoch: 5| Step: 9
Training loss: 1.97823965549469
Validation loss: 2.0452557071562736

Epoch: 5| Step: 10
Training loss: 2.4210057258605957
Validation loss: 2.0661493193718696

Epoch: 237| Step: 0
Training loss: 2.1694369316101074
Validation loss: 2.0924826975791686

Epoch: 5| Step: 1
Training loss: 2.7308809757232666
Validation loss: 2.10702246491627

Epoch: 5| Step: 2
Training loss: 2.3031654357910156
Validation loss: 2.122008103196339

Epoch: 5| Step: 3
Training loss: 1.5882762670516968
Validation loss: 2.1380628744761148

Epoch: 5| Step: 4
Training loss: 2.0266950130462646
Validation loss: 2.1448604663213096

Epoch: 5| Step: 5
Training loss: 1.1283565759658813
Validation loss: 2.1448646104463966

Epoch: 5| Step: 6
Training loss: 2.0675554275512695
Validation loss: 2.1324086445634083

Epoch: 5| Step: 7
Training loss: 2.2042126655578613
Validation loss: 2.1215223368778022

Epoch: 5| Step: 8
Training loss: 2.4421212673187256
Validation loss: 2.0957173839692147

Epoch: 5| Step: 9
Training loss: 1.7764122486114502
Validation loss: 2.0817756986105316

Epoch: 5| Step: 10
Training loss: 1.6908825635910034
Validation loss: 2.0806458803915207

Epoch: 238| Step: 0
Training loss: 1.8555119037628174
Validation loss: 2.0810574972501366

Epoch: 5| Step: 1
Training loss: 1.618075966835022
Validation loss: 2.087210214266213

Epoch: 5| Step: 2
Training loss: 2.2108070850372314
Validation loss: 2.070998432815716

Epoch: 5| Step: 3
Training loss: 2.108285665512085
Validation loss: 2.049465985708339

Epoch: 5| Step: 4
Training loss: 2.8092291355133057
Validation loss: 2.019208550453186

Epoch: 5| Step: 5
Training loss: 1.9025239944458008
Validation loss: 2.010543651478265

Epoch: 5| Step: 6
Training loss: 1.7182292938232422
Validation loss: 1.994173160163305

Epoch: 5| Step: 7
Training loss: 1.7535642385482788
Validation loss: 1.9942665241097892

Epoch: 5| Step: 8
Training loss: 2.411667585372925
Validation loss: 2.004850508064352

Epoch: 5| Step: 9
Training loss: 2.2391581535339355
Validation loss: 2.0218789116028817

Epoch: 5| Step: 10
Training loss: 1.8546116352081299
Validation loss: 2.0586823558294647

Epoch: 239| Step: 0
Training loss: 1.9855735301971436
Validation loss: 2.1107699922336045

Epoch: 5| Step: 1
Training loss: 1.5835012197494507
Validation loss: 2.1243696135859333

Epoch: 5| Step: 2
Training loss: 2.145207405090332
Validation loss: 2.1173534136946484

Epoch: 5| Step: 3
Training loss: 2.195159435272217
Validation loss: 2.1432330505822295

Epoch: 5| Step: 4
Training loss: 1.9713913202285767
Validation loss: 2.12945209780047

Epoch: 5| Step: 5
Training loss: 2.6623685359954834
Validation loss: 2.139437221711682

Epoch: 5| Step: 6
Training loss: 1.6797659397125244
Validation loss: 2.1250567218308807

Epoch: 5| Step: 7
Training loss: 1.4344065189361572
Validation loss: 2.1281104395466466

Epoch: 5| Step: 8
Training loss: 1.83391535282135
Validation loss: 2.1151253484910533

Epoch: 5| Step: 9
Training loss: 2.2228825092315674
Validation loss: 2.135478755479218

Epoch: 5| Step: 10
Training loss: 2.377739906311035
Validation loss: 2.1172573925346456

Epoch: 240| Step: 0
Training loss: 1.8062843084335327
Validation loss: 2.124435458132016

Epoch: 5| Step: 1
Training loss: 1.5818521976470947
Validation loss: 2.120302482317853

Epoch: 5| Step: 2
Training loss: 2.329998254776001
Validation loss: 2.1340988579616753

Epoch: 5| Step: 3
Training loss: 1.758721113204956
Validation loss: 2.1436689643449682

Epoch: 5| Step: 4
Training loss: 1.9225431680679321
Validation loss: 2.1529905103868052

Epoch: 5| Step: 5
Training loss: 2.0532891750335693
Validation loss: 2.131254465349259

Epoch: 5| Step: 6
Training loss: 2.3016905784606934
Validation loss: 2.1153643977257515

Epoch: 5| Step: 7
Training loss: 2.510505199432373
Validation loss: 2.08530475888201

Epoch: 5| Step: 8
Training loss: 1.905858039855957
Validation loss: 2.085062042359383

Epoch: 5| Step: 9
Training loss: 2.2031760215759277
Validation loss: 2.087751075785647

Epoch: 5| Step: 10
Training loss: 1.5122575759887695
Validation loss: 2.09144853520137

Epoch: 241| Step: 0
Training loss: 2.116558313369751
Validation loss: 2.0871275830012497

Epoch: 5| Step: 1
Training loss: 2.6344664096832275
Validation loss: 2.0752928205715713

Epoch: 5| Step: 2
Training loss: 2.023207187652588
Validation loss: 2.0761836151922903

Epoch: 5| Step: 3
Training loss: 2.6439707279205322
Validation loss: 2.0843178392738424

Epoch: 5| Step: 4
Training loss: 2.5750131607055664
Validation loss: 2.0796227762776036

Epoch: 5| Step: 5
Training loss: 1.7203304767608643
Validation loss: 2.0991804369034304

Epoch: 5| Step: 6
Training loss: 1.7587209939956665
Validation loss: 2.1321932500408542

Epoch: 5| Step: 7
Training loss: 1.8311302661895752
Validation loss: 2.123964963420745

Epoch: 5| Step: 8
Training loss: 1.9138031005859375
Validation loss: 2.1062316381803123

Epoch: 5| Step: 9
Training loss: 1.0170398950576782
Validation loss: 2.0934706041889806

Epoch: 5| Step: 10
Training loss: 1.6011799573898315
Validation loss: 2.0870397167821086

Epoch: 242| Step: 0
Training loss: 1.7066500186920166
Validation loss: 2.073063309474658

Epoch: 5| Step: 1
Training loss: 2.1013636589050293
Validation loss: 2.05370916346068

Epoch: 5| Step: 2
Training loss: 1.6004524230957031
Validation loss: 2.044802152982322

Epoch: 5| Step: 3
Training loss: 2.449512481689453
Validation loss: 2.0572952275635092

Epoch: 5| Step: 4
Training loss: 1.747178316116333
Validation loss: 2.07124686497514

Epoch: 5| Step: 5
Training loss: 2.2054014205932617
Validation loss: 2.0727131520548174

Epoch: 5| Step: 6
Training loss: 1.6615644693374634
Validation loss: 2.10445971386407

Epoch: 5| Step: 7
Training loss: 2.6125705242156982
Validation loss: 2.1484863296631844

Epoch: 5| Step: 8
Training loss: 2.0705225467681885
Validation loss: 2.166641475051962

Epoch: 5| Step: 9
Training loss: 1.7351064682006836
Validation loss: 2.1413881855626262

Epoch: 5| Step: 10
Training loss: 2.3697023391723633
Validation loss: 2.1079468034928843

Epoch: 243| Step: 0
Training loss: 1.271878957748413
Validation loss: 2.0942836230801

Epoch: 5| Step: 1
Training loss: 1.8270902633666992
Validation loss: 2.092252016067505

Epoch: 5| Step: 2
Training loss: 2.053579330444336
Validation loss: 2.1066656266489336

Epoch: 5| Step: 3
Training loss: 2.8061203956604004
Validation loss: 2.128372379528579

Epoch: 5| Step: 4
Training loss: 2.056614875793457
Validation loss: 2.112715951858028

Epoch: 5| Step: 5
Training loss: 1.4829046726226807
Validation loss: 2.1094151094395626

Epoch: 5| Step: 6
Training loss: 1.6781307458877563
Validation loss: 2.1217095492988505

Epoch: 5| Step: 7
Training loss: 1.926477074623108
Validation loss: 2.117330410147226

Epoch: 5| Step: 8
Training loss: 2.230637311935425
Validation loss: 2.1069833155601256

Epoch: 5| Step: 9
Training loss: 2.2708373069763184
Validation loss: 2.050168627051897

Epoch: 5| Step: 10
Training loss: 2.230372190475464
Validation loss: 2.06010466237222

Epoch: 244| Step: 0
Training loss: 1.8907359838485718
Validation loss: 2.044131648155951

Epoch: 5| Step: 1
Training loss: 1.8898099660873413
Validation loss: 2.0466413139015116

Epoch: 5| Step: 2
Training loss: 1.9601852893829346
Validation loss: 2.0398280287301667

Epoch: 5| Step: 3
Training loss: 1.867618203163147
Validation loss: 2.0546530677426245

Epoch: 5| Step: 4
Training loss: 2.201122760772705
Validation loss: 2.079963796882219

Epoch: 5| Step: 5
Training loss: 2.544159173965454
Validation loss: 2.098491476428124

Epoch: 5| Step: 6
Training loss: 2.2943339347839355
Validation loss: 2.107114448342272

Epoch: 5| Step: 7
Training loss: 1.8894004821777344
Validation loss: 2.1042802513286634

Epoch: 5| Step: 8
Training loss: 1.2595795392990112
Validation loss: 2.0927801286020586

Epoch: 5| Step: 9
Training loss: 1.738490343093872
Validation loss: 2.072805982764049

Epoch: 5| Step: 10
Training loss: 2.3499927520751953
Validation loss: 2.065036357090037

Epoch: 245| Step: 0
Training loss: 1.8069242238998413
Validation loss: 2.044196799237241

Epoch: 5| Step: 1
Training loss: 1.798897385597229
Validation loss: 2.0612505892271638

Epoch: 5| Step: 2
Training loss: 1.8241939544677734
Validation loss: 2.067396012685632

Epoch: 5| Step: 3
Training loss: 2.55615234375
Validation loss: 2.075880960751605

Epoch: 5| Step: 4
Training loss: 2.0585577487945557
Validation loss: 2.075043314246721

Epoch: 5| Step: 5
Training loss: 2.1862881183624268
Validation loss: 2.077132168636527

Epoch: 5| Step: 6
Training loss: 1.929727554321289
Validation loss: 2.0943233018280356

Epoch: 5| Step: 7
Training loss: 1.6832542419433594
Validation loss: 2.1172092217271046

Epoch: 5| Step: 8
Training loss: 2.362088918685913
Validation loss: 2.1299423453628377

Epoch: 5| Step: 9
Training loss: 2.0577292442321777
Validation loss: 2.1257308221632436

Epoch: 5| Step: 10
Training loss: 1.6830854415893555
Validation loss: 2.1118188442722445

Epoch: 246| Step: 0
Training loss: 2.3818278312683105
Validation loss: 2.1025823982813026

Epoch: 5| Step: 1
Training loss: 2.0383477210998535
Validation loss: 2.0820097026004585

Epoch: 5| Step: 2
Training loss: 2.3962652683258057
Validation loss: 2.080047840713173

Epoch: 5| Step: 3
Training loss: 2.617709159851074
Validation loss: 2.0725284520015923

Epoch: 5| Step: 4
Training loss: 2.2321574687957764
Validation loss: 2.0693465535358717

Epoch: 5| Step: 5
Training loss: 2.199693202972412
Validation loss: 2.08299688113633

Epoch: 5| Step: 6
Training loss: 1.7720361948013306
Validation loss: 2.0649041975698164

Epoch: 5| Step: 7
Training loss: 1.4728286266326904
Validation loss: 2.090015180649296

Epoch: 5| Step: 8
Training loss: 1.1699286699295044
Validation loss: 2.073290335234775

Epoch: 5| Step: 9
Training loss: 1.851383924484253
Validation loss: 2.0796955375261206

Epoch: 5| Step: 10
Training loss: 1.1579288244247437
Validation loss: 2.0777997316852694

Epoch: 247| Step: 0
Training loss: 2.0146872997283936
Validation loss: 2.1058925582516577

Epoch: 5| Step: 1
Training loss: 1.7243843078613281
Validation loss: 2.094293394396382

Epoch: 5| Step: 2
Training loss: 2.0443243980407715
Validation loss: 2.1068743403239916

Epoch: 5| Step: 3
Training loss: 2.170886278152466
Validation loss: 2.127270831856676

Epoch: 5| Step: 4
Training loss: 1.788092851638794
Validation loss: 2.137047234401908

Epoch: 5| Step: 5
Training loss: 1.911930799484253
Validation loss: 2.1329218290185414

Epoch: 5| Step: 6
Training loss: 2.13988995552063
Validation loss: 2.107038487670242

Epoch: 5| Step: 7
Training loss: 2.056190013885498
Validation loss: 2.0943359098126813

Epoch: 5| Step: 8
Training loss: 1.7804912328720093
Validation loss: 2.0766166871593845

Epoch: 5| Step: 9
Training loss: 1.9315773248672485
Validation loss: 2.0820273917208434

Epoch: 5| Step: 10
Training loss: 1.9022380113601685
Validation loss: 2.0890296812980407

Epoch: 248| Step: 0
Training loss: 2.388684034347534
Validation loss: 2.1192811894160446

Epoch: 5| Step: 1
Training loss: 2.5627994537353516
Validation loss: 2.1040098180053053

Epoch: 5| Step: 2
Training loss: 1.4618562459945679
Validation loss: 2.0924523927832164

Epoch: 5| Step: 3
Training loss: 1.8675785064697266
Validation loss: 2.0629236134149695

Epoch: 5| Step: 4
Training loss: 1.5243511199951172
Validation loss: 2.0553496012123684

Epoch: 5| Step: 5
Training loss: 2.0286872386932373
Validation loss: 2.0991607891616

Epoch: 5| Step: 6
Training loss: 2.3547117710113525
Validation loss: 2.136717232324744

Epoch: 5| Step: 7
Training loss: 1.8329124450683594
Validation loss: 2.1622978718050065

Epoch: 5| Step: 8
Training loss: 1.902991533279419
Validation loss: 2.1734248104915825

Epoch: 5| Step: 9
Training loss: 2.260394811630249
Validation loss: 2.1690791563321183

Epoch: 5| Step: 10
Training loss: 1.6925525665283203
Validation loss: 2.1165492150091354

Epoch: 249| Step: 0
Training loss: 1.720491647720337
Validation loss: 2.0766553160964802

Epoch: 5| Step: 1
Training loss: 1.5163168907165527
Validation loss: 2.0317949146352787

Epoch: 5| Step: 2
Training loss: 2.23945689201355
Validation loss: 2.0082842880679714

Epoch: 5| Step: 3
Training loss: 1.4338353872299194
Validation loss: 2.053256129705778

Epoch: 5| Step: 4
Training loss: 2.372260570526123
Validation loss: 2.083172277737689

Epoch: 5| Step: 5
Training loss: 1.991809606552124
Validation loss: 2.1242272802578506

Epoch: 5| Step: 6
Training loss: 2.1055185794830322
Validation loss: 2.1677517275656424

Epoch: 5| Step: 7
Training loss: 2.3664307594299316
Validation loss: 2.1665774417179886

Epoch: 5| Step: 8
Training loss: 1.7657434940338135
Validation loss: 2.070854156248031

Epoch: 5| Step: 9
Training loss: 2.3368053436279297
Validation loss: 2.0166919257051203

Epoch: 5| Step: 10
Training loss: 2.2020936012268066
Validation loss: 2.0422954546507968

Epoch: 250| Step: 0
Training loss: 1.8576488494873047
Validation loss: 2.088773060870427

Epoch: 5| Step: 1
Training loss: 1.6315135955810547
Validation loss: 2.109370041919011

Epoch: 5| Step: 2
Training loss: 2.0856728553771973
Validation loss: 2.1479743680646344

Epoch: 5| Step: 3
Training loss: 2.1998696327209473
Validation loss: 2.1654924013281382

Epoch: 5| Step: 4
Training loss: 1.613669753074646
Validation loss: 2.1236392862053326

Epoch: 5| Step: 5
Training loss: 2.071699619293213
Validation loss: 2.0456901416983655

Epoch: 5| Step: 6
Training loss: 2.3647913932800293
Validation loss: 2.0167999357305546

Epoch: 5| Step: 7
Training loss: 1.867821455001831
Validation loss: 2.0024235620293567

Epoch: 5| Step: 8
Training loss: 1.9609956741333008
Validation loss: 2.0154634432126115

Epoch: 5| Step: 9
Training loss: 2.2570009231567383
Validation loss: 2.0284985342333393

Epoch: 5| Step: 10
Training loss: 1.8884210586547852
Validation loss: 2.037544555561517

Epoch: 251| Step: 0
Training loss: 2.155996084213257
Validation loss: 2.0785189943928875

Epoch: 5| Step: 1
Training loss: 2.069852352142334
Validation loss: 2.08046640119245

Epoch: 5| Step: 2
Training loss: 2.385723829269409
Validation loss: 2.0727056405877553

Epoch: 5| Step: 3
Training loss: 1.9153896570205688
Validation loss: 2.0614591413928616

Epoch: 5| Step: 4
Training loss: 2.3457326889038086
Validation loss: 2.0663505420889905

Epoch: 5| Step: 5
Training loss: 1.3846614360809326
Validation loss: 2.075983326922181

Epoch: 5| Step: 6
Training loss: 1.714368224143982
Validation loss: 2.0971435975002986

Epoch: 5| Step: 7
Training loss: 2.034965991973877
Validation loss: 2.1223136648055045

Epoch: 5| Step: 8
Training loss: 1.6520370244979858
Validation loss: 2.1246835441999536

Epoch: 5| Step: 9
Training loss: 2.0135040283203125
Validation loss: 2.129829922030049

Epoch: 5| Step: 10
Training loss: 1.6938047409057617
Validation loss: 2.1304520919758785

Epoch: 252| Step: 0
Training loss: 1.3230539560317993
Validation loss: 2.1181789469975296

Epoch: 5| Step: 1
Training loss: 2.3514742851257324
Validation loss: 2.0781687075091946

Epoch: 5| Step: 2
Training loss: 2.204707384109497
Validation loss: 2.060570022111298

Epoch: 5| Step: 3
Training loss: 1.9955838918685913
Validation loss: 2.0431421879799134

Epoch: 5| Step: 4
Training loss: 2.0734968185424805
Validation loss: 2.016749808865209

Epoch: 5| Step: 5
Training loss: 1.8532283306121826
Validation loss: 2.022442981760989

Epoch: 5| Step: 6
Training loss: 2.0636658668518066
Validation loss: 2.02253379360322

Epoch: 5| Step: 7
Training loss: 2.1880240440368652
Validation loss: 2.004242097177813

Epoch: 5| Step: 8
Training loss: 1.617774248123169
Validation loss: 1.9980700323658604

Epoch: 5| Step: 9
Training loss: 1.9557443857192993
Validation loss: 1.986231843630473

Epoch: 5| Step: 10
Training loss: 1.8080750703811646
Validation loss: 1.9898816334303988

Epoch: 253| Step: 0
Training loss: 1.6501147747039795
Validation loss: 1.9851774028552476

Epoch: 5| Step: 1
Training loss: 1.9956209659576416
Validation loss: 1.9899633648574993

Epoch: 5| Step: 2
Training loss: 2.082831382751465
Validation loss: 2.0089552940860873

Epoch: 5| Step: 3
Training loss: 2.909013271331787
Validation loss: 2.036021360787012

Epoch: 5| Step: 4
Training loss: 1.263045072555542
Validation loss: 2.0498886531399143

Epoch: 5| Step: 5
Training loss: 1.59035325050354
Validation loss: 2.0800138083837365

Epoch: 5| Step: 6
Training loss: 1.764855980873108
Validation loss: 2.0830747517206336

Epoch: 5| Step: 7
Training loss: 1.5776054859161377
Validation loss: 2.1145644021290604

Epoch: 5| Step: 8
Training loss: 2.0643348693847656
Validation loss: 2.150160058852165

Epoch: 5| Step: 9
Training loss: 2.0504658222198486
Validation loss: 2.1998417351835515

Epoch: 5| Step: 10
Training loss: 2.5612404346466064
Validation loss: 2.2148191877590713

Epoch: 254| Step: 0
Training loss: 2.5344865322113037
Validation loss: 2.20376064444101

Epoch: 5| Step: 1
Training loss: 1.8634589910507202
Validation loss: 2.17571420310646

Epoch: 5| Step: 2
Training loss: 2.593557357788086
Validation loss: 2.1530935200311805

Epoch: 5| Step: 3
Training loss: 2.4550423622131348
Validation loss: 2.111734346676898

Epoch: 5| Step: 4
Training loss: 1.4226624965667725
Validation loss: 2.099991625355136

Epoch: 5| Step: 5
Training loss: 2.031132459640503
Validation loss: 2.051075686690628

Epoch: 5| Step: 6
Training loss: 1.84526789188385
Validation loss: 2.0335925907217045

Epoch: 5| Step: 7
Training loss: 1.7584444284439087
Validation loss: 2.0395055381200646

Epoch: 5| Step: 8
Training loss: 1.6094506978988647
Validation loss: 2.0353790329348658

Epoch: 5| Step: 9
Training loss: 1.3522560596466064
Validation loss: 2.0362266455927203

Epoch: 5| Step: 10
Training loss: 1.652453899383545
Validation loss: 2.036208120725488

Epoch: 255| Step: 0
Training loss: 1.8859007358551025
Validation loss: 2.018083644169633

Epoch: 5| Step: 1
Training loss: 2.213858127593994
Validation loss: 2.0218480222968647

Epoch: 5| Step: 2
Training loss: 1.5020273923873901
Validation loss: 2.0368700899103636

Epoch: 5| Step: 3
Training loss: 1.6863634586334229
Validation loss: 2.0433050022330335

Epoch: 5| Step: 4
Training loss: 2.037565231323242
Validation loss: 2.0735794639074676

Epoch: 5| Step: 5
Training loss: 2.2126400470733643
Validation loss: 2.08144982143115

Epoch: 5| Step: 6
Training loss: 1.6679623126983643
Validation loss: 2.0988439372790757

Epoch: 5| Step: 7
Training loss: 2.1869611740112305
Validation loss: 2.1057382834854947

Epoch: 5| Step: 8
Training loss: 2.24320650100708
Validation loss: 2.1001131611485637

Epoch: 5| Step: 9
Training loss: 1.954281210899353
Validation loss: 2.0899202131455943

Epoch: 5| Step: 10
Training loss: 1.3052334785461426
Validation loss: 2.105224547847625

Epoch: 256| Step: 0
Training loss: 1.8822654485702515
Validation loss: 2.0721186745551323

Epoch: 5| Step: 1
Training loss: 1.7747290134429932
Validation loss: 2.0713248304141465

Epoch: 5| Step: 2
Training loss: 2.1041576862335205
Validation loss: 2.0693088834003737

Epoch: 5| Step: 3
Training loss: 1.8039710521697998
Validation loss: 2.0856559404762844

Epoch: 5| Step: 4
Training loss: 1.6720622777938843
Validation loss: 2.0802297745981524

Epoch: 5| Step: 5
Training loss: 1.6413037776947021
Validation loss: 2.0442774744443994

Epoch: 5| Step: 6
Training loss: 1.595615267753601
Validation loss: 2.0582516859936457

Epoch: 5| Step: 7
Training loss: 2.142784833908081
Validation loss: 2.0400125365103445

Epoch: 5| Step: 8
Training loss: 2.251155376434326
Validation loss: 2.0319574404788274

Epoch: 5| Step: 9
Training loss: 2.063546895980835
Validation loss: 2.0489384256383425

Epoch: 5| Step: 10
Training loss: 1.8928673267364502
Validation loss: 2.040637536715436

Epoch: 257| Step: 0
Training loss: 2.1146793365478516
Validation loss: 2.0354843857467815

Epoch: 5| Step: 1
Training loss: 1.767062783241272
Validation loss: 2.0384193210191626

Epoch: 5| Step: 2
Training loss: 1.854536771774292
Validation loss: 2.0255648500175885

Epoch: 5| Step: 3
Training loss: 1.3894790410995483
Validation loss: 2.0119459372694775

Epoch: 5| Step: 4
Training loss: 2.40834903717041
Validation loss: 2.021461517580094

Epoch: 5| Step: 5
Training loss: 2.159865379333496
Validation loss: 2.019165036498859

Epoch: 5| Step: 6
Training loss: 1.8378251791000366
Validation loss: 2.0200702144253637

Epoch: 5| Step: 7
Training loss: 2.092916488647461
Validation loss: 2.035532170726407

Epoch: 5| Step: 8
Training loss: 1.2389624118804932
Validation loss: 2.03567740994115

Epoch: 5| Step: 9
Training loss: 2.1500399112701416
Validation loss: 2.078911969738622

Epoch: 5| Step: 10
Training loss: 1.9398307800292969
Validation loss: 2.0870038142768284

Epoch: 258| Step: 0
Training loss: 2.252192258834839
Validation loss: 2.1038957103606193

Epoch: 5| Step: 1
Training loss: 1.7865009307861328
Validation loss: 2.111229163344188

Epoch: 5| Step: 2
Training loss: 0.9719573855400085
Validation loss: 2.105915133671094

Epoch: 5| Step: 3
Training loss: 2.0407283306121826
Validation loss: 2.0873233913093485

Epoch: 5| Step: 4
Training loss: 2.3143906593322754
Validation loss: 2.1073301146107335

Epoch: 5| Step: 5
Training loss: 2.1385881900787354
Validation loss: 2.082929362532913

Epoch: 5| Step: 6
Training loss: 1.8533039093017578
Validation loss: 2.0907669836475002

Epoch: 5| Step: 7
Training loss: 1.6567760705947876
Validation loss: 2.094926885379258

Epoch: 5| Step: 8
Training loss: 1.9089444875717163
Validation loss: 2.056608896101675

Epoch: 5| Step: 9
Training loss: 2.050861358642578
Validation loss: 2.0367984207727576

Epoch: 5| Step: 10
Training loss: 2.002613067626953
Validation loss: 2.028332402629237

Epoch: 259| Step: 0
Training loss: 2.1419107913970947
Validation loss: 2.0159478482379707

Epoch: 5| Step: 1
Training loss: 1.7247194051742554
Validation loss: 2.013909834687428

Epoch: 5| Step: 2
Training loss: 2.193376064300537
Validation loss: 2.028619440652991

Epoch: 5| Step: 3
Training loss: 2.0490565299987793
Validation loss: 2.0264241772313274

Epoch: 5| Step: 4
Training loss: 1.4422978162765503
Validation loss: 2.025212639121599

Epoch: 5| Step: 5
Training loss: 1.518385648727417
Validation loss: 2.019177107400792

Epoch: 5| Step: 6
Training loss: 1.6843159198760986
Validation loss: 2.043371623562228

Epoch: 5| Step: 7
Training loss: 2.1305594444274902
Validation loss: 2.0595469090246383

Epoch: 5| Step: 8
Training loss: 1.7881357669830322
Validation loss: 2.0908271369113716

Epoch: 5| Step: 9
Training loss: 1.8455991744995117
Validation loss: 2.111328814619331

Epoch: 5| Step: 10
Training loss: 2.195977210998535
Validation loss: 2.0971263749625093

Epoch: 260| Step: 0
Training loss: 1.947021722793579
Validation loss: 2.101746125887799

Epoch: 5| Step: 1
Training loss: 1.7768453359603882
Validation loss: 2.0835585363449587

Epoch: 5| Step: 2
Training loss: 2.411700487136841
Validation loss: 2.0578690549378753

Epoch: 5| Step: 3
Training loss: 2.6727654933929443
Validation loss: 2.0439640257948186

Epoch: 5| Step: 4
Training loss: 1.6489146947860718
Validation loss: 2.0055510869590183

Epoch: 5| Step: 5
Training loss: 1.334824800491333
Validation loss: 2.0173174258201354

Epoch: 5| Step: 6
Training loss: 2.1004319190979004
Validation loss: 1.9995892150427705

Epoch: 5| Step: 7
Training loss: 1.3349066972732544
Validation loss: 2.0180701389107654

Epoch: 5| Step: 8
Training loss: 1.8227260112762451
Validation loss: 2.0191419380967335

Epoch: 5| Step: 9
Training loss: 2.4612627029418945
Validation loss: 2.0042574969671105

Epoch: 5| Step: 10
Training loss: 1.4317837953567505
Validation loss: 2.021409314165833

Epoch: 261| Step: 0
Training loss: 1.6753685474395752
Validation loss: 2.046237685347116

Epoch: 5| Step: 1
Training loss: 1.7555325031280518
Validation loss: 2.0538949402429725

Epoch: 5| Step: 2
Training loss: 2.0435187816619873
Validation loss: 2.0553901656981437

Epoch: 5| Step: 3
Training loss: 2.4318430423736572
Validation loss: 2.0494358578035907

Epoch: 5| Step: 4
Training loss: 1.8142515420913696
Validation loss: 2.0444345589606994

Epoch: 5| Step: 5
Training loss: 1.905757188796997
Validation loss: 2.0543726798026793

Epoch: 5| Step: 6
Training loss: 1.9248288869857788
Validation loss: 2.0385268298528527

Epoch: 5| Step: 7
Training loss: 1.6847912073135376
Validation loss: 2.0812472156299058

Epoch: 5| Step: 8
Training loss: 2.1008269786834717
Validation loss: 2.1111468602252264

Epoch: 5| Step: 9
Training loss: 1.1634225845336914
Validation loss: 2.1109128831535258

Epoch: 5| Step: 10
Training loss: 2.468658447265625
Validation loss: 2.110404242751419

Epoch: 262| Step: 0
Training loss: 1.8119900226593018
Validation loss: 2.089408827084367

Epoch: 5| Step: 1
Training loss: 1.5353453159332275
Validation loss: 2.0573995972192414

Epoch: 5| Step: 2
Training loss: 2.0749335289001465
Validation loss: 2.0207780074047785

Epoch: 5| Step: 3
Training loss: 1.9916350841522217
Validation loss: 2.0133989036724134

Epoch: 5| Step: 4
Training loss: 2.504394054412842
Validation loss: 2.018140095536427

Epoch: 5| Step: 5
Training loss: 1.7424662113189697
Validation loss: 2.0110139641710507

Epoch: 5| Step: 6
Training loss: 1.63906729221344
Validation loss: 2.016466507347681

Epoch: 5| Step: 7
Training loss: 1.3906911611557007
Validation loss: 2.011542445869856

Epoch: 5| Step: 8
Training loss: 2.379234790802002
Validation loss: 2.0274287769871373

Epoch: 5| Step: 9
Training loss: 1.7379623651504517
Validation loss: 2.040761811758882

Epoch: 5| Step: 10
Training loss: 1.8402929306030273
Validation loss: 2.067217625597472

Epoch: 263| Step: 0
Training loss: 2.3418734073638916
Validation loss: 2.0404480554724254

Epoch: 5| Step: 1
Training loss: 1.4893488883972168
Validation loss: 2.032104258896202

Epoch: 5| Step: 2
Training loss: 2.3940346240997314
Validation loss: 2.02447703448675

Epoch: 5| Step: 3
Training loss: 1.7933944463729858
Validation loss: 2.0325290451767626

Epoch: 5| Step: 4
Training loss: 1.1933144330978394
Validation loss: 2.038090641780566

Epoch: 5| Step: 5
Training loss: 2.0907046794891357
Validation loss: 2.0398929478019796

Epoch: 5| Step: 6
Training loss: 1.595960021018982
Validation loss: 2.0500806826417164

Epoch: 5| Step: 7
Training loss: 1.298316240310669
Validation loss: 2.0450884949776436

Epoch: 5| Step: 8
Training loss: 2.1751537322998047
Validation loss: 2.0444750785827637

Epoch: 5| Step: 9
Training loss: 2.387267827987671
Validation loss: 2.0292880265943465

Epoch: 5| Step: 10
Training loss: 1.7496896982192993
Validation loss: 2.0334501112661054

Epoch: 264| Step: 0
Training loss: 1.9586204290390015
Validation loss: 2.0501985011562223

Epoch: 5| Step: 1
Training loss: 2.106997489929199
Validation loss: 2.0600853427763908

Epoch: 5| Step: 2
Training loss: 2.312739610671997
Validation loss: 2.094680751523664

Epoch: 5| Step: 3
Training loss: 1.6896836757659912
Validation loss: 2.0973285128993373

Epoch: 5| Step: 4
Training loss: 1.9004039764404297
Validation loss: 2.1108747066990023

Epoch: 5| Step: 5
Training loss: 2.109532117843628
Validation loss: 2.1098589871519353

Epoch: 5| Step: 6
Training loss: 2.101179361343384
Validation loss: 2.0896031266899517

Epoch: 5| Step: 7
Training loss: 1.5040634870529175
Validation loss: 2.0989218629816526

Epoch: 5| Step: 8
Training loss: 1.5103166103363037
Validation loss: 2.0757778588161675

Epoch: 5| Step: 9
Training loss: 1.7694718837738037
Validation loss: 2.1018877619056293

Epoch: 5| Step: 10
Training loss: 1.4176667928695679
Validation loss: 2.0937340362097627

Epoch: 265| Step: 0
Training loss: 1.6768306493759155
Validation loss: 2.0712752675497406

Epoch: 5| Step: 1
Training loss: 2.1647722721099854
Validation loss: 2.0553178300139723

Epoch: 5| Step: 2
Training loss: 1.9673235416412354
Validation loss: 2.049930046963435

Epoch: 5| Step: 3
Training loss: 1.835186243057251
Validation loss: 2.0172184962098316

Epoch: 5| Step: 4
Training loss: 2.1201019287109375
Validation loss: 1.996364075650451

Epoch: 5| Step: 5
Training loss: 2.4713048934936523
Validation loss: 2.0204215459926154

Epoch: 5| Step: 6
Training loss: 2.4509010314941406
Validation loss: 2.0334211344360025

Epoch: 5| Step: 7
Training loss: 1.291468858718872
Validation loss: 2.05227017659013

Epoch: 5| Step: 8
Training loss: 1.1933633089065552
Validation loss: 2.0705549511858212

Epoch: 5| Step: 9
Training loss: 1.5161077976226807
Validation loss: 2.0778669977700837

Epoch: 5| Step: 10
Training loss: 1.780653953552246
Validation loss: 2.0747469958438667

Epoch: 266| Step: 0
Training loss: 1.3941383361816406
Validation loss: 2.050529254380093

Epoch: 5| Step: 1
Training loss: 2.006239891052246
Validation loss: 2.054673966541085

Epoch: 5| Step: 2
Training loss: 1.8412529230117798
Validation loss: 2.043148766281784

Epoch: 5| Step: 3
Training loss: 2.0948116779327393
Validation loss: 2.0435791553989535

Epoch: 5| Step: 4
Training loss: 1.8343976736068726
Validation loss: 2.042719999949137

Epoch: 5| Step: 5
Training loss: 1.7851530313491821
Validation loss: 2.0523230824419247

Epoch: 5| Step: 6
Training loss: 1.615692138671875
Validation loss: 2.0612236889459754

Epoch: 5| Step: 7
Training loss: 1.9790441989898682
Validation loss: 2.0956152408353743

Epoch: 5| Step: 8
Training loss: 1.7041537761688232
Validation loss: 2.0985433952782744

Epoch: 5| Step: 9
Training loss: 2.0118155479431152
Validation loss: 2.109906477953798

Epoch: 5| Step: 10
Training loss: 2.1411876678466797
Validation loss: 2.1024745510470484

Epoch: 267| Step: 0
Training loss: 1.8621734380722046
Validation loss: 2.122306449438936

Epoch: 5| Step: 1
Training loss: 1.588744878768921
Validation loss: 2.118374455359674

Epoch: 5| Step: 2
Training loss: 1.677053451538086
Validation loss: 2.094148405136601

Epoch: 5| Step: 3
Training loss: 1.8996937274932861
Validation loss: 2.0667927649713334

Epoch: 5| Step: 4
Training loss: 2.380786180496216
Validation loss: 2.03397342722903

Epoch: 5| Step: 5
Training loss: 2.00709867477417
Validation loss: 2.011598539608781

Epoch: 5| Step: 6
Training loss: 1.9839614629745483
Validation loss: 2.002852575753325

Epoch: 5| Step: 7
Training loss: 1.598388433456421
Validation loss: 2.002168901505009

Epoch: 5| Step: 8
Training loss: 1.6608623266220093
Validation loss: 1.9775574463669972

Epoch: 5| Step: 9
Training loss: 1.8697006702423096
Validation loss: 2.015290848670467

Epoch: 5| Step: 10
Training loss: 1.9851711988449097
Validation loss: 1.9918432876627932

Epoch: 268| Step: 0
Training loss: 2.0041327476501465
Validation loss: 2.016147727607399

Epoch: 5| Step: 1
Training loss: 1.7265684604644775
Validation loss: 2.024019907879573

Epoch: 5| Step: 2
Training loss: 2.274064302444458
Validation loss: 2.0301122870496524

Epoch: 5| Step: 3
Training loss: 1.7936460971832275
Validation loss: 2.0718161534237605

Epoch: 5| Step: 4
Training loss: 1.220543622970581
Validation loss: 2.0791360280847035

Epoch: 5| Step: 5
Training loss: 2.2191011905670166
Validation loss: 2.122310512809343

Epoch: 5| Step: 6
Training loss: 2.0223984718322754
Validation loss: 2.13649377130693

Epoch: 5| Step: 7
Training loss: 1.3554737567901611
Validation loss: 2.1093001224661387

Epoch: 5| Step: 8
Training loss: 1.7794796228408813
Validation loss: 2.085697389418079

Epoch: 5| Step: 9
Training loss: 1.9295161962509155
Validation loss: 2.074269122974847

Epoch: 5| Step: 10
Training loss: 2.2946693897247314
Validation loss: 2.0882850475208734

Epoch: 269| Step: 0
Training loss: 1.8813650608062744
Validation loss: 2.0779394411271617

Epoch: 5| Step: 1
Training loss: 2.092726230621338
Validation loss: 2.0662721280128724

Epoch: 5| Step: 2
Training loss: 1.6911693811416626
Validation loss: 2.0650129600237777

Epoch: 5| Step: 3
Training loss: 1.8196531534194946
Validation loss: 2.0486357545339935

Epoch: 5| Step: 4
Training loss: 1.8950916528701782
Validation loss: 2.0186584303455968

Epoch: 5| Step: 5
Training loss: 2.332815647125244
Validation loss: 2.006678214637182

Epoch: 5| Step: 6
Training loss: 1.8156226873397827
Validation loss: 1.997395069368424

Epoch: 5| Step: 7
Training loss: 1.568589448928833
Validation loss: 1.9693564932833436

Epoch: 5| Step: 8
Training loss: 1.701321005821228
Validation loss: 2.007508941875991

Epoch: 5| Step: 9
Training loss: 1.5773974657058716
Validation loss: 2.022883753622732

Epoch: 5| Step: 10
Training loss: 2.152041435241699
Validation loss: 2.0764778147461596

Epoch: 270| Step: 0
Training loss: 1.6884853839874268
Validation loss: 2.082474177883517

Epoch: 5| Step: 1
Training loss: 1.452534794807434
Validation loss: 2.0933078488995953

Epoch: 5| Step: 2
Training loss: 2.1195766925811768
Validation loss: 2.121223326652281

Epoch: 5| Step: 3
Training loss: 2.153926134109497
Validation loss: 2.158395157065443

Epoch: 5| Step: 4
Training loss: 2.183562755584717
Validation loss: 2.1828541422402985

Epoch: 5| Step: 5
Training loss: 2.331005096435547
Validation loss: 2.176621849818896

Epoch: 5| Step: 6
Training loss: 1.501091718673706
Validation loss: 2.1911570269574403

Epoch: 5| Step: 7
Training loss: 1.4198920726776123
Validation loss: 2.154430727804861

Epoch: 5| Step: 8
Training loss: 1.9410717487335205
Validation loss: 2.1170319126498316

Epoch: 5| Step: 9
Training loss: 1.520180344581604
Validation loss: 2.089628968187558

Epoch: 5| Step: 10
Training loss: 2.286252975463867
Validation loss: 2.0497630616670013

Epoch: 271| Step: 0
Training loss: 1.8916633129119873
Validation loss: 2.033870215057045

Epoch: 5| Step: 1
Training loss: 2.3606653213500977
Validation loss: 2.0108947548815

Epoch: 5| Step: 2
Training loss: 2.223153829574585
Validation loss: 2.0277397376234814

Epoch: 5| Step: 3
Training loss: 1.5534756183624268
Validation loss: 2.0113883838858655

Epoch: 5| Step: 4
Training loss: 1.5844135284423828
Validation loss: 2.037106784441138

Epoch: 5| Step: 5
Training loss: 1.701870322227478
Validation loss: 2.0704743400696786

Epoch: 5| Step: 6
Training loss: 2.084125280380249
Validation loss: 2.108231673958481

Epoch: 5| Step: 7
Training loss: 1.5814765691757202
Validation loss: 2.085688334639354

Epoch: 5| Step: 8
Training loss: 1.784406304359436
Validation loss: 2.093385422101585

Epoch: 5| Step: 9
Training loss: 2.094254970550537
Validation loss: 2.04591566260143

Epoch: 5| Step: 10
Training loss: 1.4007104635238647
Validation loss: 2.0336810286327074

Epoch: 272| Step: 0
Training loss: 2.033440113067627
Validation loss: 2.0382504309377363

Epoch: 5| Step: 1
Training loss: 2.3253302574157715
Validation loss: 2.036502335661201

Epoch: 5| Step: 2
Training loss: 1.6546909809112549
Validation loss: 2.049636125564575

Epoch: 5| Step: 3
Training loss: 1.4016807079315186
Validation loss: 2.074207035444116

Epoch: 5| Step: 4
Training loss: 1.978126883506775
Validation loss: 2.0710111254005024

Epoch: 5| Step: 5
Training loss: 2.415271759033203
Validation loss: 2.0604098907081028

Epoch: 5| Step: 6
Training loss: 1.6769880056381226
Validation loss: 2.0792456109036683

Epoch: 5| Step: 7
Training loss: 2.252636194229126
Validation loss: 2.0793575779084237

Epoch: 5| Step: 8
Training loss: 1.4058091640472412
Validation loss: 2.098927408136347

Epoch: 5| Step: 9
Training loss: 0.8361138105392456
Validation loss: 2.080979352356285

Epoch: 5| Step: 10
Training loss: 2.0039098262786865
Validation loss: 2.102148637976698

Epoch: 273| Step: 0
Training loss: 2.3511462211608887
Validation loss: 2.0790175519963747

Epoch: 5| Step: 1
Training loss: 2.1524465084075928
Validation loss: 2.08551602209768

Epoch: 5| Step: 2
Training loss: 1.7218830585479736
Validation loss: 2.067847377510481

Epoch: 5| Step: 3
Training loss: 1.904552698135376
Validation loss: 2.089316038675206

Epoch: 5| Step: 4
Training loss: 1.6731065511703491
Validation loss: 2.055348819301974

Epoch: 5| Step: 5
Training loss: 2.1263227462768555
Validation loss: 2.030748572400821

Epoch: 5| Step: 6
Training loss: 2.0272116661071777
Validation loss: 2.035977776332568

Epoch: 5| Step: 7
Training loss: 1.3974545001983643
Validation loss: 2.020787708220943

Epoch: 5| Step: 8
Training loss: 1.6699903011322021
Validation loss: 2.0223725944437008

Epoch: 5| Step: 9
Training loss: 1.7648251056671143
Validation loss: 2.0520464348536667

Epoch: 5| Step: 10
Training loss: 1.2069841623306274
Validation loss: 2.078591118576706

Epoch: 274| Step: 0
Training loss: 1.4702415466308594
Validation loss: 2.1049062077717116

Epoch: 5| Step: 1
Training loss: 1.4771366119384766
Validation loss: 2.118235662419309

Epoch: 5| Step: 2
Training loss: 1.2493202686309814
Validation loss: 2.1338791731865174

Epoch: 5| Step: 3
Training loss: 1.690863013267517
Validation loss: 2.1488729984529558

Epoch: 5| Step: 4
Training loss: 1.857403039932251
Validation loss: 2.1368258563421105

Epoch: 5| Step: 5
Training loss: 2.4264259338378906
Validation loss: 2.132828522753972

Epoch: 5| Step: 6
Training loss: 1.6800663471221924
Validation loss: 2.131046401557102

Epoch: 5| Step: 7
Training loss: 2.2848453521728516
Validation loss: 2.1132215953642324

Epoch: 5| Step: 8
Training loss: 1.4209461212158203
Validation loss: 2.0783104435090096

Epoch: 5| Step: 9
Training loss: 2.2651989459991455
Validation loss: 2.0676667151912564

Epoch: 5| Step: 10
Training loss: 2.4465038776397705
Validation loss: 2.051438787932037

Epoch: 275| Step: 0
Training loss: 1.632886290550232
Validation loss: 2.0252882229384555

Epoch: 5| Step: 1
Training loss: 1.5155144929885864
Validation loss: 2.035718250018294

Epoch: 5| Step: 2
Training loss: 1.8081926107406616
Validation loss: 2.019317119352279

Epoch: 5| Step: 3
Training loss: 2.708667278289795
Validation loss: 2.047072325983355

Epoch: 5| Step: 4
Training loss: 1.6444240808486938
Validation loss: 2.0520008815232145

Epoch: 5| Step: 5
Training loss: 1.8818104267120361
Validation loss: 2.0274269196294967

Epoch: 5| Step: 6
Training loss: 1.7125904560089111
Validation loss: 2.051825759231403

Epoch: 5| Step: 7
Training loss: 1.8565305471420288
Validation loss: 2.0499716535691292

Epoch: 5| Step: 8
Training loss: 1.7482430934906006
Validation loss: 2.0790415656182075

Epoch: 5| Step: 9
Training loss: 1.6545507907867432
Validation loss: 2.0851918446120394

Epoch: 5| Step: 10
Training loss: 2.0403072834014893
Validation loss: 2.083728030163755

Epoch: 276| Step: 0
Training loss: 1.5095198154449463
Validation loss: 2.077706193411222

Epoch: 5| Step: 1
Training loss: 1.1547971963882446
Validation loss: 2.05224254310772

Epoch: 5| Step: 2
Training loss: 1.9539177417755127
Validation loss: 2.043499731248425

Epoch: 5| Step: 3
Training loss: 2.233734607696533
Validation loss: 2.020302016247985

Epoch: 5| Step: 4
Training loss: 1.7034614086151123
Validation loss: 1.9862292658898137

Epoch: 5| Step: 5
Training loss: 1.3539751768112183
Validation loss: 1.9560032608688518

Epoch: 5| Step: 6
Training loss: 2.084296226501465
Validation loss: 1.9638970949316537

Epoch: 5| Step: 7
Training loss: 2.3419368267059326
Validation loss: 1.9703885265575942

Epoch: 5| Step: 8
Training loss: 1.7298634052276611
Validation loss: 1.9776644629816855

Epoch: 5| Step: 9
Training loss: 1.9591785669326782
Validation loss: 2.000524959256572

Epoch: 5| Step: 10
Training loss: 1.890899896621704
Validation loss: 2.018289855731431

Epoch: 277| Step: 0
Training loss: 1.7025610208511353
Validation loss: 2.0629117899043585

Epoch: 5| Step: 1
Training loss: 1.6446707248687744
Validation loss: 2.0606082306113294

Epoch: 5| Step: 2
Training loss: 1.755984902381897
Validation loss: 2.0692420057071153

Epoch: 5| Step: 3
Training loss: 2.1106386184692383
Validation loss: 2.0674801513712895

Epoch: 5| Step: 4
Training loss: 1.8671032190322876
Validation loss: 2.0679262697055774

Epoch: 5| Step: 5
Training loss: 1.8637574911117554
Validation loss: 2.0920652817654353

Epoch: 5| Step: 6
Training loss: 1.9874217510223389
Validation loss: 2.0929431351282264

Epoch: 5| Step: 7
Training loss: 1.5938093662261963
Validation loss: 2.0564456729478735

Epoch: 5| Step: 8
Training loss: 1.7358598709106445
Validation loss: 2.05349414835694

Epoch: 5| Step: 9
Training loss: 1.7565377950668335
Validation loss: 2.0381236794174358

Epoch: 5| Step: 10
Training loss: 1.8471136093139648
Validation loss: 2.055217014845981

Epoch: 278| Step: 0
Training loss: 1.9503142833709717
Validation loss: 2.056416101353143

Epoch: 5| Step: 1
Training loss: 1.724041223526001
Validation loss: 2.025447134048708

Epoch: 5| Step: 2
Training loss: 1.247814416885376
Validation loss: 2.0127490438440794

Epoch: 5| Step: 3
Training loss: 1.908475637435913
Validation loss: 2.0353284087232364

Epoch: 5| Step: 4
Training loss: 1.263906478881836
Validation loss: 2.0191766279999928

Epoch: 5| Step: 5
Training loss: 1.8294597864151
Validation loss: 2.029978247099025

Epoch: 5| Step: 6
Training loss: 1.7297636270523071
Validation loss: 2.0455127851937407

Epoch: 5| Step: 7
Training loss: 2.2297921180725098
Validation loss: 2.041060034946729

Epoch: 5| Step: 8
Training loss: 1.410478949546814
Validation loss: 2.060196427888768

Epoch: 5| Step: 9
Training loss: 2.3475637435913086
Validation loss: 2.0937610992821316

Epoch: 5| Step: 10
Training loss: 2.1105542182922363
Validation loss: 2.1123224125113538

Epoch: 279| Step: 0
Training loss: 2.0684897899627686
Validation loss: 2.1311674246224026

Epoch: 5| Step: 1
Training loss: 1.6743133068084717
Validation loss: 2.1348610283226095

Epoch: 5| Step: 2
Training loss: 1.7922227382659912
Validation loss: 2.1225481956235823

Epoch: 5| Step: 3
Training loss: 1.9655811786651611
Validation loss: 2.1095429594798754

Epoch: 5| Step: 4
Training loss: 2.0899763107299805
Validation loss: 2.083880042517057

Epoch: 5| Step: 5
Training loss: 1.639220952987671
Validation loss: 2.0499402810168523

Epoch: 5| Step: 6
Training loss: 1.699493169784546
Validation loss: 2.0479454507109938

Epoch: 5| Step: 7
Training loss: 1.9955726861953735
Validation loss: 2.0377880937309674

Epoch: 5| Step: 8
Training loss: 1.879034399986267
Validation loss: 2.035029031897104

Epoch: 5| Step: 9
Training loss: 1.358504056930542
Validation loss: 2.028153120830495

Epoch: 5| Step: 10
Training loss: 1.4322563409805298
Validation loss: 2.0531288064936155

Epoch: 280| Step: 0
Training loss: 1.8539320230484009
Validation loss: 2.0539183539728962

Epoch: 5| Step: 1
Training loss: 1.491682767868042
Validation loss: 2.0566564964991745

Epoch: 5| Step: 2
Training loss: 2.01611065864563
Validation loss: 2.0623137502260107

Epoch: 5| Step: 3
Training loss: 1.9400081634521484
Validation loss: 2.0481598659228255

Epoch: 5| Step: 4
Training loss: 1.465288758277893
Validation loss: 2.0419145296978694

Epoch: 5| Step: 5
Training loss: 1.099618911743164
Validation loss: 2.033571743196057

Epoch: 5| Step: 6
Training loss: 2.070777654647827
Validation loss: 2.052613078906972

Epoch: 5| Step: 7
Training loss: 2.275848388671875
Validation loss: 2.055639710477603

Epoch: 5| Step: 8
Training loss: 2.0742645263671875
Validation loss: 2.042413442365585

Epoch: 5| Step: 9
Training loss: 1.7540076971054077
Validation loss: 2.017868713666034

Epoch: 5| Step: 10
Training loss: 1.4548858404159546
Validation loss: 2.009156500139544

Epoch: 281| Step: 0
Training loss: 1.9305540323257446
Validation loss: 2.0022424241547943

Epoch: 5| Step: 1
Training loss: 1.7403854131698608
Validation loss: 2.0027622484391734

Epoch: 5| Step: 2
Training loss: 1.8611342906951904
Validation loss: 2.007633852702315

Epoch: 5| Step: 3
Training loss: 1.5120985507965088
Validation loss: 2.0121790004032913

Epoch: 5| Step: 4
Training loss: 2.243955135345459
Validation loss: 2.034882471125613

Epoch: 5| Step: 5
Training loss: 2.1478285789489746
Validation loss: 2.056750419319317

Epoch: 5| Step: 6
Training loss: 1.8360637426376343
Validation loss: 2.0803122520446777

Epoch: 5| Step: 7
Training loss: 1.6256691217422485
Validation loss: 2.054713144097277

Epoch: 5| Step: 8
Training loss: 1.7524980306625366
Validation loss: 2.0782805386409966

Epoch: 5| Step: 9
Training loss: 1.2560926675796509
Validation loss: 2.0624092599397064

Epoch: 5| Step: 10
Training loss: 1.4213719367980957
Validation loss: 2.0552889736749793

Epoch: 282| Step: 0
Training loss: 1.6235822439193726
Validation loss: 2.0630450787082797

Epoch: 5| Step: 1
Training loss: 2.0957865715026855
Validation loss: 2.0504266344090945

Epoch: 5| Step: 2
Training loss: 1.5424425601959229
Validation loss: 2.039515813191732

Epoch: 5| Step: 3
Training loss: 1.783160924911499
Validation loss: 2.038947546353904

Epoch: 5| Step: 4
Training loss: 1.7252603769302368
Validation loss: 2.0397295195569276

Epoch: 5| Step: 5
Training loss: 2.080509901046753
Validation loss: 2.0381904853287565

Epoch: 5| Step: 6
Training loss: 1.8191444873809814
Validation loss: 2.0709232719995643

Epoch: 5| Step: 7
Training loss: 1.5862802267074585
Validation loss: 2.053500034475839

Epoch: 5| Step: 8
Training loss: 1.692842721939087
Validation loss: 2.0637068761292325

Epoch: 5| Step: 9
Training loss: 1.6294183731079102
Validation loss: 2.061414036699521

Epoch: 5| Step: 10
Training loss: 1.600707769393921
Validation loss: 2.0613577801694154

Epoch: 283| Step: 0
Training loss: 2.105848789215088
Validation loss: 2.0810119772470124

Epoch: 5| Step: 1
Training loss: 1.1153026819229126
Validation loss: 2.064138532966696

Epoch: 5| Step: 2
Training loss: 1.4900872707366943
Validation loss: 2.0547600382117817

Epoch: 5| Step: 3
Training loss: 2.164607524871826
Validation loss: 2.047489073968703

Epoch: 5| Step: 4
Training loss: 1.2416622638702393
Validation loss: 2.0412602193893923

Epoch: 5| Step: 5
Training loss: 1.792061448097229
Validation loss: 2.0604957252420406

Epoch: 5| Step: 6
Training loss: 1.6470285654067993
Validation loss: 2.0694576309573267

Epoch: 5| Step: 7
Training loss: 1.6063274145126343
Validation loss: 2.086939332305744

Epoch: 5| Step: 8
Training loss: 1.874585747718811
Validation loss: 2.0907733107125885

Epoch: 5| Step: 9
Training loss: 2.3357367515563965
Validation loss: 2.089046717971884

Epoch: 5| Step: 10
Training loss: 1.8101484775543213
Validation loss: 2.0850054820378623

Epoch: 284| Step: 0
Training loss: 1.8474022150039673
Validation loss: 2.0468032513895342

Epoch: 5| Step: 1
Training loss: 2.0570054054260254
Validation loss: 2.040299145124292

Epoch: 5| Step: 2
Training loss: 1.9541534185409546
Validation loss: 2.0426548347678235

Epoch: 5| Step: 3
Training loss: 1.3545491695404053
Validation loss: 2.0499205191930137

Epoch: 5| Step: 4
Training loss: 1.3904005289077759
Validation loss: 2.034667125312231

Epoch: 5| Step: 5
Training loss: 1.8680086135864258
Validation loss: 2.028671367194063

Epoch: 5| Step: 6
Training loss: 1.3552792072296143
Validation loss: 2.0136563598468737

Epoch: 5| Step: 7
Training loss: 2.040614604949951
Validation loss: 2.0343517218866656

Epoch: 5| Step: 8
Training loss: 1.8612048625946045
Validation loss: 2.060224425408148

Epoch: 5| Step: 9
Training loss: 1.9774143695831299
Validation loss: 2.0734662650733866

Epoch: 5| Step: 10
Training loss: 1.669051170349121
Validation loss: 2.1004111920633624

Epoch: 285| Step: 0
Training loss: 1.7205779552459717
Validation loss: 2.106828378092858

Epoch: 5| Step: 1
Training loss: 1.5630161762237549
Validation loss: 2.0926733862969185

Epoch: 5| Step: 2
Training loss: 2.2639124393463135
Validation loss: 2.0788356488750828

Epoch: 5| Step: 3
Training loss: 1.7593986988067627
Validation loss: 2.0646848191497145

Epoch: 5| Step: 4
Training loss: 1.8167572021484375
Validation loss: 2.037069660361095

Epoch: 5| Step: 5
Training loss: 1.1851272583007812
Validation loss: 2.0463096710943405

Epoch: 5| Step: 6
Training loss: 2.0297749042510986
Validation loss: 2.0462543195293796

Epoch: 5| Step: 7
Training loss: 1.8956581354141235
Validation loss: 2.0563828881068895

Epoch: 5| Step: 8
Training loss: 2.126389980316162
Validation loss: 2.0434843647864556

Epoch: 5| Step: 9
Training loss: 1.3312623500823975
Validation loss: 2.0448309247211744

Epoch: 5| Step: 10
Training loss: 1.5222879648208618
Validation loss: 2.066324508318337

Epoch: 286| Step: 0
Training loss: 1.9676086902618408
Validation loss: 2.068164433202436

Epoch: 5| Step: 1
Training loss: 1.5688165426254272
Validation loss: 2.0617255703095467

Epoch: 5| Step: 2
Training loss: 1.701894760131836
Validation loss: 2.087774130605882

Epoch: 5| Step: 3
Training loss: 1.8531010150909424
Validation loss: 2.086350438415363

Epoch: 5| Step: 4
Training loss: 1.7531856298446655
Validation loss: 2.054551116881832

Epoch: 5| Step: 5
Training loss: 1.7965589761734009
Validation loss: 2.0406502472457064

Epoch: 5| Step: 6
Training loss: 1.80289626121521
Validation loss: 2.009850643014395

Epoch: 5| Step: 7
Training loss: 2.0488057136535645
Validation loss: 2.015678131452171

Epoch: 5| Step: 8
Training loss: 1.229953646659851
Validation loss: 2.0318466578760455

Epoch: 5| Step: 9
Training loss: 1.5369703769683838
Validation loss: 2.0485661055452082

Epoch: 5| Step: 10
Training loss: 1.8154147863388062
Validation loss: 2.045968747908069

Epoch: 287| Step: 0
Training loss: 2.02201509475708
Validation loss: 2.05327171151356

Epoch: 5| Step: 1
Training loss: 1.7557613849639893
Validation loss: 2.0740952312305407

Epoch: 5| Step: 2
Training loss: 2.313878297805786
Validation loss: 2.0876952858381372

Epoch: 5| Step: 3
Training loss: 1.9757804870605469
Validation loss: 2.056856293832102

Epoch: 5| Step: 4
Training loss: 1.2146707773208618
Validation loss: 2.0336888938821773

Epoch: 5| Step: 5
Training loss: 1.2105671167373657
Validation loss: 2.043227070121355

Epoch: 5| Step: 6
Training loss: 1.7254664897918701
Validation loss: 2.0270442283281715

Epoch: 5| Step: 7
Training loss: 1.4556360244750977
Validation loss: 2.020720813864021

Epoch: 5| Step: 8
Training loss: 2.017101764678955
Validation loss: 2.03640515060835

Epoch: 5| Step: 9
Training loss: 1.3927959203720093
Validation loss: 2.01970346384151

Epoch: 5| Step: 10
Training loss: 1.8735207319259644
Validation loss: 2.0299778048710158

Epoch: 288| Step: 0
Training loss: 1.7389323711395264
Validation loss: 2.0290525267201085

Epoch: 5| Step: 1
Training loss: 2.160407304763794
Validation loss: 2.06861339974147

Epoch: 5| Step: 2
Training loss: 1.9424617290496826
Validation loss: 2.061032772064209

Epoch: 5| Step: 3
Training loss: 1.8815711736679077
Validation loss: 2.0691479059957687

Epoch: 5| Step: 4
Training loss: 1.5433764457702637
Validation loss: 2.0887566625431018

Epoch: 5| Step: 5
Training loss: 1.703031301498413
Validation loss: 2.0765349634232058

Epoch: 5| Step: 6
Training loss: 2.093109369277954
Validation loss: 2.0865590931266866

Epoch: 5| Step: 7
Training loss: 0.7037887573242188
Validation loss: 2.0714508102786158

Epoch: 5| Step: 8
Training loss: 1.1740831136703491
Validation loss: 2.039217036257508

Epoch: 5| Step: 9
Training loss: 2.1967520713806152
Validation loss: 2.034150271005528

Epoch: 5| Step: 10
Training loss: 1.610925555229187
Validation loss: 2.0389791893702682

Epoch: 289| Step: 0
Training loss: 1.3468736410140991
Validation loss: 2.045881267516844

Epoch: 5| Step: 1
Training loss: 1.6981267929077148
Validation loss: 2.0525754395351616

Epoch: 5| Step: 2
Training loss: 2.017601728439331
Validation loss: 2.0749598869713406

Epoch: 5| Step: 3
Training loss: 1.494820475578308
Validation loss: 2.075341179806699

Epoch: 5| Step: 4
Training loss: 1.4735735654830933
Validation loss: 2.055573060948362

Epoch: 5| Step: 5
Training loss: 0.8771575093269348
Validation loss: 2.0546985826184674

Epoch: 5| Step: 6
Training loss: 2.308149814605713
Validation loss: 2.0603505719092583

Epoch: 5| Step: 7
Training loss: 1.5015500783920288
Validation loss: 2.0704196627422045

Epoch: 5| Step: 8
Training loss: 1.830248475074768
Validation loss: 2.08690672023322

Epoch: 5| Step: 9
Training loss: 1.9628639221191406
Validation loss: 2.0815238542454217

Epoch: 5| Step: 10
Training loss: 2.2749907970428467
Validation loss: 2.090334000126008

Epoch: 290| Step: 0
Training loss: 1.5979928970336914
Validation loss: 2.0877678163589968

Epoch: 5| Step: 1
Training loss: 2.1310925483703613
Validation loss: 2.0814357919077717

Epoch: 5| Step: 2
Training loss: 1.6827369928359985
Validation loss: 2.060511121185877

Epoch: 5| Step: 3
Training loss: 2.076685667037964
Validation loss: 2.0696565258887505

Epoch: 5| Step: 4
Training loss: 1.4584773778915405
Validation loss: 2.065851949876355

Epoch: 5| Step: 5
Training loss: 2.015930652618408
Validation loss: 2.0696057452950427

Epoch: 5| Step: 6
Training loss: 1.9394668340682983
Validation loss: 2.0558146558782107

Epoch: 5| Step: 7
Training loss: 1.8396294116973877
Validation loss: 2.048973580842377

Epoch: 5| Step: 8
Training loss: 0.9209844470024109
Validation loss: 2.0495369562538723

Epoch: 5| Step: 9
Training loss: 1.304940938949585
Validation loss: 2.030301450401224

Epoch: 5| Step: 10
Training loss: 1.7121820449829102
Validation loss: 2.0262384901764574

Epoch: 291| Step: 0
Training loss: 1.6875574588775635
Validation loss: 2.018186212867819

Epoch: 5| Step: 1
Training loss: 1.4996802806854248
Validation loss: 2.0096980038509575

Epoch: 5| Step: 2
Training loss: 1.925929307937622
Validation loss: 2.0169358625206897

Epoch: 5| Step: 3
Training loss: 1.3060963153839111
Validation loss: 2.0437072528305875

Epoch: 5| Step: 4
Training loss: 1.3977694511413574
Validation loss: 2.0784890497884443

Epoch: 5| Step: 5
Training loss: 2.015777111053467
Validation loss: 2.109471800506756

Epoch: 5| Step: 6
Training loss: 2.1254448890686035
Validation loss: 2.1379677223902878

Epoch: 5| Step: 7
Training loss: 1.9122045040130615
Validation loss: 2.136185707584504

Epoch: 5| Step: 8
Training loss: 1.869253158569336
Validation loss: 2.157406739009324

Epoch: 5| Step: 9
Training loss: 1.5537726879119873
Validation loss: 2.157589840632613

Epoch: 5| Step: 10
Training loss: 1.5361652374267578
Validation loss: 2.1299334546571136

Epoch: 292| Step: 0
Training loss: 1.9224941730499268
Validation loss: 2.0929947514687814

Epoch: 5| Step: 1
Training loss: 0.9582771062850952
Validation loss: 2.079758694094996

Epoch: 5| Step: 2
Training loss: 1.9146331548690796
Validation loss: 2.0613226736745527

Epoch: 5| Step: 3
Training loss: 1.4986430406570435
Validation loss: 2.047550429580032

Epoch: 5| Step: 4
Training loss: 1.7170913219451904
Validation loss: 2.0322878335111882

Epoch: 5| Step: 5
Training loss: 1.9331443309783936
Validation loss: 2.073248250510103

Epoch: 5| Step: 6
Training loss: 1.5502676963806152
Validation loss: 2.0940870187615834

Epoch: 5| Step: 7
Training loss: 1.865981101989746
Validation loss: 2.073397736395559

Epoch: 5| Step: 8
Training loss: 2.1708617210388184
Validation loss: 2.0676354874846754

Epoch: 5| Step: 9
Training loss: 1.2802066802978516
Validation loss: 2.008406173798346

Epoch: 5| Step: 10
Training loss: 2.021026611328125
Validation loss: 1.9988854392882316

Epoch: 293| Step: 0
Training loss: 1.418526291847229
Validation loss: 1.9816933780588128

Epoch: 5| Step: 1
Training loss: 2.130164623260498
Validation loss: 1.9858534900091027

Epoch: 5| Step: 2
Training loss: 1.2997862100601196
Validation loss: 1.9926087933201944

Epoch: 5| Step: 3
Training loss: 2.7373909950256348
Validation loss: 2.010564342621834

Epoch: 5| Step: 4
Training loss: 1.99888014793396
Validation loss: 2.024670534236457

Epoch: 5| Step: 5
Training loss: 1.5435526371002197
Validation loss: 2.0293069001167052

Epoch: 5| Step: 6
Training loss: 2.0845119953155518
Validation loss: 2.030224620655019

Epoch: 5| Step: 7
Training loss: 1.4418548345565796
Validation loss: 2.055904375609531

Epoch: 5| Step: 8
Training loss: 1.3884183168411255
Validation loss: 2.106620598864812

Epoch: 5| Step: 9
Training loss: 1.2511881589889526
Validation loss: 2.1650681111120407

Epoch: 5| Step: 10
Training loss: 1.7619702816009521
Validation loss: 2.1675819761009625

Epoch: 294| Step: 0
Training loss: 1.886070966720581
Validation loss: 2.1118968943113923

Epoch: 5| Step: 1
Training loss: 1.764499306678772
Validation loss: 2.0654074350992837

Epoch: 5| Step: 2
Training loss: 1.6838910579681396
Validation loss: 2.0198979595656037

Epoch: 5| Step: 3
Training loss: 2.0114283561706543
Validation loss: 2.012176145789444

Epoch: 5| Step: 4
Training loss: 2.0997226238250732
Validation loss: 2.007354267181889

Epoch: 5| Step: 5
Training loss: 1.829972267150879
Validation loss: 1.9865669614525252

Epoch: 5| Step: 6
Training loss: 1.6110222339630127
Validation loss: 2.00802936989774

Epoch: 5| Step: 7
Training loss: 1.2320497035980225
Validation loss: 2.016152528024489

Epoch: 5| Step: 8
Training loss: 1.393559217453003
Validation loss: 2.0433935606351463

Epoch: 5| Step: 9
Training loss: 2.2788329124450684
Validation loss: 2.084250796225763

Epoch: 5| Step: 10
Training loss: 1.0637229681015015
Validation loss: 2.103354413022277

Epoch: 295| Step: 0
Training loss: 1.5726318359375
Validation loss: 2.1191453741442774

Epoch: 5| Step: 1
Training loss: 1.4943320751190186
Validation loss: 2.1595537021595943

Epoch: 5| Step: 2
Training loss: 1.9613615274429321
Validation loss: 2.136262830867562

Epoch: 5| Step: 3
Training loss: 1.779109239578247
Validation loss: 2.14280193339112

Epoch: 5| Step: 4
Training loss: 1.6640479564666748
Validation loss: 2.1438468002503916

Epoch: 5| Step: 5
Training loss: 1.6195876598358154
Validation loss: 2.123741647248627

Epoch: 5| Step: 6
Training loss: 1.5473105907440186
Validation loss: 2.1332728273125103

Epoch: 5| Step: 7
Training loss: 1.9796011447906494
Validation loss: 2.1243585309674664

Epoch: 5| Step: 8
Training loss: 1.734653115272522
Validation loss: 2.07682974876896

Epoch: 5| Step: 9
Training loss: 1.7530241012573242
Validation loss: 2.080970835942094

Epoch: 5| Step: 10
Training loss: 1.7074992656707764
Validation loss: 2.032164404469152

Epoch: 296| Step: 0
Training loss: 1.1977038383483887
Validation loss: 1.9920825599342264

Epoch: 5| Step: 1
Training loss: 2.0914676189422607
Validation loss: 1.9769319385610602

Epoch: 5| Step: 2
Training loss: 1.4569251537322998
Validation loss: 1.9663882511918263

Epoch: 5| Step: 3
Training loss: 1.8188121318817139
Validation loss: 1.946897381095476

Epoch: 5| Step: 4
Training loss: 2.1304874420166016
Validation loss: 1.937026108464887

Epoch: 5| Step: 5
Training loss: 2.304560899734497
Validation loss: 1.939527033477701

Epoch: 5| Step: 6
Training loss: 1.3830757141113281
Validation loss: 1.9564152968827115

Epoch: 5| Step: 7
Training loss: 1.4336210489273071
Validation loss: 1.9588063173396613

Epoch: 5| Step: 8
Training loss: 1.603602409362793
Validation loss: 1.9813337197867773

Epoch: 5| Step: 9
Training loss: 1.5280665159225464
Validation loss: 2.02728691152347

Epoch: 5| Step: 10
Training loss: 1.751140832901001
Validation loss: 2.0574858086083525

Epoch: 297| Step: 0
Training loss: 1.332391381263733
Validation loss: 2.107138528618761

Epoch: 5| Step: 1
Training loss: 1.3488460779190063
Validation loss: 2.12158142623081

Epoch: 5| Step: 2
Training loss: 1.6962783336639404
Validation loss: 2.136619439689062

Epoch: 5| Step: 3
Training loss: 1.784428358078003
Validation loss: 2.1720631968590522

Epoch: 5| Step: 4
Training loss: 1.6289039850234985
Validation loss: 2.172957517767465

Epoch: 5| Step: 5
Training loss: 1.89456045627594
Validation loss: 2.129225395059073

Epoch: 5| Step: 6
Training loss: 1.9265193939208984
Validation loss: 2.0928725606651715

Epoch: 5| Step: 7
Training loss: 1.552430510520935
Validation loss: 2.065366928295423

Epoch: 5| Step: 8
Training loss: 1.9995094537734985
Validation loss: 2.0586141283794115

Epoch: 5| Step: 9
Training loss: 2.28678822517395
Validation loss: 2.0397872232621714

Epoch: 5| Step: 10
Training loss: 0.9249099493026733
Validation loss: 2.028480481075984

Epoch: 298| Step: 0
Training loss: 1.3415181636810303
Validation loss: 2.049350230924545

Epoch: 5| Step: 1
Training loss: 1.3788515329360962
Validation loss: 2.017998159572642

Epoch: 5| Step: 2
Training loss: 1.471692681312561
Validation loss: 2.0258616350030385

Epoch: 5| Step: 3
Training loss: 1.303316593170166
Validation loss: 2.0105561876809723

Epoch: 5| Step: 4
Training loss: 1.701528549194336
Validation loss: 1.9960016794102167

Epoch: 5| Step: 5
Training loss: 1.6659616231918335
Validation loss: 2.0098516287342196

Epoch: 5| Step: 6
Training loss: 1.7542282342910767
Validation loss: 2.0142393266001055

Epoch: 5| Step: 7
Training loss: 1.705207109451294
Validation loss: 2.049400455208235

Epoch: 5| Step: 8
Training loss: 1.379010558128357
Validation loss: 2.0648226584157636

Epoch: 5| Step: 9
Training loss: 2.176945447921753
Validation loss: 2.0771835119493547

Epoch: 5| Step: 10
Training loss: 2.5432567596435547
Validation loss: 2.090925301274946

Epoch: 299| Step: 0
Training loss: 1.2739070653915405
Validation loss: 2.078048118980982

Epoch: 5| Step: 1
Training loss: 1.2924433946609497
Validation loss: 2.0962375530632595

Epoch: 5| Step: 2
Training loss: 1.3815078735351562
Validation loss: 2.1122389147358556

Epoch: 5| Step: 3
Training loss: 1.719193696975708
Validation loss: 2.143824049221572

Epoch: 5| Step: 4
Training loss: 2.0861587524414062
Validation loss: 2.13036685861567

Epoch: 5| Step: 5
Training loss: 1.6253961324691772
Validation loss: 2.117801263768186

Epoch: 5| Step: 6
Training loss: 1.8185908794403076
Validation loss: 2.087862448025775

Epoch: 5| Step: 7
Training loss: 2.284170389175415
Validation loss: 2.064981916899322

Epoch: 5| Step: 8
Training loss: 1.4763171672821045
Validation loss: 2.014160212650094

Epoch: 5| Step: 9
Training loss: 1.359755277633667
Validation loss: 2.00508503888243

Epoch: 5| Step: 10
Training loss: 1.6963350772857666
Validation loss: 2.0101067250774753

Epoch: 300| Step: 0
Training loss: 0.592232346534729
Validation loss: 1.987506986946188

Epoch: 5| Step: 1
Training loss: 1.5379085540771484
Validation loss: 1.9967594736365861

Epoch: 5| Step: 2
Training loss: 2.3606278896331787
Validation loss: 2.0255509115034536

Epoch: 5| Step: 3
Training loss: 1.245968222618103
Validation loss: 2.023036882441531

Epoch: 5| Step: 4
Training loss: 2.3441414833068848
Validation loss: 2.0017606378883444

Epoch: 5| Step: 5
Training loss: 1.4837331771850586
Validation loss: 2.040331837951496

Epoch: 5| Step: 6
Training loss: 1.2110919952392578
Validation loss: 2.0303117107319575

Epoch: 5| Step: 7
Training loss: 1.8532402515411377
Validation loss: 2.0485797261679046

Epoch: 5| Step: 8
Training loss: 1.6444228887557983
Validation loss: 2.0856659207292783

Epoch: 5| Step: 9
Training loss: 2.2082362174987793
Validation loss: 2.0851563125528316

Epoch: 5| Step: 10
Training loss: 1.4350749254226685
Validation loss: 2.08942441017397

Epoch: 301| Step: 0
Training loss: 1.4924595355987549
Validation loss: 2.1208618302499094

Epoch: 5| Step: 1
Training loss: 2.19350528717041
Validation loss: 2.108080123060493

Epoch: 5| Step: 2
Training loss: 1.0644237995147705
Validation loss: 2.0951957420636247

Epoch: 5| Step: 3
Training loss: 2.297050952911377
Validation loss: 2.1273827450249785

Epoch: 5| Step: 4
Training loss: 1.6355130672454834
Validation loss: 2.1144335731383292

Epoch: 5| Step: 5
Training loss: 1.2538570165634155
Validation loss: 2.116102618555869

Epoch: 5| Step: 6
Training loss: 1.27140474319458
Validation loss: 2.106334402997007

Epoch: 5| Step: 7
Training loss: 1.8796848058700562
Validation loss: 2.108237845923311

Epoch: 5| Step: 8
Training loss: 1.8272682428359985
Validation loss: 2.0885785369462866

Epoch: 5| Step: 9
Training loss: 1.1815335750579834
Validation loss: 2.0893558827779626

Epoch: 5| Step: 10
Training loss: 1.6090915203094482
Validation loss: 2.098346564077562

Epoch: 302| Step: 0
Training loss: 1.3947726488113403
Validation loss: 2.0752160574800227

Epoch: 5| Step: 1
Training loss: 1.6194934844970703
Validation loss: 2.0801671910029587

Epoch: 5| Step: 2
Training loss: 2.4391846656799316
Validation loss: 2.089978410351661

Epoch: 5| Step: 3
Training loss: 1.5144470930099487
Validation loss: 2.049616400913526

Epoch: 5| Step: 4
Training loss: 1.2491048574447632
Validation loss: 2.0436612688085085

Epoch: 5| Step: 5
Training loss: 1.3090999126434326
Validation loss: 2.0234609188572055

Epoch: 5| Step: 6
Training loss: 1.7873194217681885
Validation loss: 2.022988998761741

Epoch: 5| Step: 7
Training loss: 1.575913667678833
Validation loss: 2.0239023200927244

Epoch: 5| Step: 8
Training loss: 2.098445415496826
Validation loss: 2.030386524815713

Epoch: 5| Step: 9
Training loss: 1.4171384572982788
Validation loss: 2.033577346032666

Epoch: 5| Step: 10
Training loss: 1.3542108535766602
Validation loss: 2.061914643933696

Epoch: 303| Step: 0
Training loss: 1.6790218353271484
Validation loss: 2.0747253561532624

Epoch: 5| Step: 1
Training loss: 1.4711291790008545
Validation loss: 2.085690523988457

Epoch: 5| Step: 2
Training loss: 1.8268630504608154
Validation loss: 2.070705179245241

Epoch: 5| Step: 3
Training loss: 0.9751855134963989
Validation loss: 2.0540975306623723

Epoch: 5| Step: 4
Training loss: 2.263237714767456
Validation loss: 2.0480014816407235

Epoch: 5| Step: 5
Training loss: 1.2716892957687378
Validation loss: 2.062456420672837

Epoch: 5| Step: 6
Training loss: 1.7782142162322998
Validation loss: 2.0528946384306876

Epoch: 5| Step: 7
Training loss: 1.5942115783691406
Validation loss: 2.092861803629065

Epoch: 5| Step: 8
Training loss: 1.615873098373413
Validation loss: 2.0808258056640625

Epoch: 5| Step: 9
Training loss: 1.549344778060913
Validation loss: 2.0469194407104165

Epoch: 5| Step: 10
Training loss: 2.0440194606781006
Validation loss: 2.015451313346945

Epoch: 304| Step: 0
Training loss: 1.549842357635498
Validation loss: 1.9942363462140482

Epoch: 5| Step: 1
Training loss: 1.9206273555755615
Validation loss: 2.0118743296592467

Epoch: 5| Step: 2
Training loss: 2.090113878250122
Validation loss: 1.9952124023950228

Epoch: 5| Step: 3
Training loss: 1.7147495746612549
Validation loss: 1.9716379334849696

Epoch: 5| Step: 4
Training loss: 1.194929838180542
Validation loss: 1.967383248831636

Epoch: 5| Step: 5
Training loss: 1.1267956495285034
Validation loss: 2.009313278300788

Epoch: 5| Step: 6
Training loss: 2.135967254638672
Validation loss: 2.0464262141976306

Epoch: 5| Step: 7
Training loss: 1.550907015800476
Validation loss: 2.082139338216474

Epoch: 5| Step: 8
Training loss: 1.5028760433197021
Validation loss: 2.131560616595771

Epoch: 5| Step: 9
Training loss: 1.3636243343353271
Validation loss: 2.0735896992427048

Epoch: 5| Step: 10
Training loss: 1.673615574836731
Validation loss: 2.073862429588072

Epoch: 305| Step: 0
Training loss: 1.6817617416381836
Validation loss: 2.059770086760162

Epoch: 5| Step: 1
Training loss: 1.8223371505737305
Validation loss: 2.021165763178179

Epoch: 5| Step: 2
Training loss: 1.3994014263153076
Validation loss: 2.0217716129877235

Epoch: 5| Step: 3
Training loss: 1.3849114179611206
Validation loss: 2.012777018290694

Epoch: 5| Step: 4
Training loss: 1.9850170612335205
Validation loss: 2.0263454503910516

Epoch: 5| Step: 5
Training loss: 1.2194935083389282
Validation loss: 2.001084945535147

Epoch: 5| Step: 6
Training loss: 0.9095615148544312
Validation loss: 2.0079950030132006

Epoch: 5| Step: 7
Training loss: 1.8408199548721313
Validation loss: 2.0079131664768344

Epoch: 5| Step: 8
Training loss: 2.250908374786377
Validation loss: 1.990658567797753

Epoch: 5| Step: 9
Training loss: 1.2239880561828613
Validation loss: 2.012678392471806

Epoch: 5| Step: 10
Training loss: 1.7957072257995605
Validation loss: 2.001523834402843

Epoch: 306| Step: 0
Training loss: 1.8803017139434814
Validation loss: 2.0317000650590464

Epoch: 5| Step: 1
Training loss: 1.5724204778671265
Validation loss: 2.0439667573539158

Epoch: 5| Step: 2
Training loss: 1.3011009693145752
Validation loss: 2.0500736467299925

Epoch: 5| Step: 3
Training loss: 2.129650592803955
Validation loss: 2.0453522371989425

Epoch: 5| Step: 4
Training loss: 1.4150283336639404
Validation loss: 2.0581002107230564

Epoch: 5| Step: 5
Training loss: 1.512589454650879
Validation loss: 2.074783650777673

Epoch: 5| Step: 6
Training loss: 1.7764228582382202
Validation loss: 2.0673194751944592

Epoch: 5| Step: 7
Training loss: 1.2924540042877197
Validation loss: 2.0380476674725934

Epoch: 5| Step: 8
Training loss: 1.953001618385315
Validation loss: 2.0475928680871123

Epoch: 5| Step: 9
Training loss: 1.2263175249099731
Validation loss: 2.0156905394728466

Epoch: 5| Step: 10
Training loss: 1.3500109910964966
Validation loss: 1.9901956486445602

Epoch: 307| Step: 0
Training loss: 1.636875867843628
Validation loss: 1.9922031587170017

Epoch: 5| Step: 1
Training loss: 1.738769769668579
Validation loss: 2.0071932474772134

Epoch: 5| Step: 2
Training loss: 1.6269943714141846
Validation loss: 2.022939646115867

Epoch: 5| Step: 3
Training loss: 1.4200712442398071
Validation loss: 2.0522468730967534

Epoch: 5| Step: 4
Training loss: 1.3504455089569092
Validation loss: 2.0549945216025076

Epoch: 5| Step: 5
Training loss: 1.7495044469833374
Validation loss: 2.051772848252327

Epoch: 5| Step: 6
Training loss: 1.658376693725586
Validation loss: 2.0588047888971146

Epoch: 5| Step: 7
Training loss: 1.4371206760406494
Validation loss: 2.0412387514627106

Epoch: 5| Step: 8
Training loss: 2.130366563796997
Validation loss: 2.066970638049546

Epoch: 5| Step: 9
Training loss: 0.8159921765327454
Validation loss: 2.0721781279451106

Epoch: 5| Step: 10
Training loss: 1.605841040611267
Validation loss: 2.0662005152753604

Epoch: 308| Step: 0
Training loss: 2.190669536590576
Validation loss: 2.101218036426011

Epoch: 5| Step: 1
Training loss: 1.4133180379867554
Validation loss: 2.0829687810713247

Epoch: 5| Step: 2
Training loss: 1.8789875507354736
Validation loss: 2.0858688008400703

Epoch: 5| Step: 3
Training loss: 1.0543549060821533
Validation loss: 2.0462578445352535

Epoch: 5| Step: 4
Training loss: 1.9411424398422241
Validation loss: 2.0015177316563104

Epoch: 5| Step: 5
Training loss: 1.2414023876190186
Validation loss: 2.001068745889971

Epoch: 5| Step: 6
Training loss: 1.242472767829895
Validation loss: 1.9946703090462634

Epoch: 5| Step: 7
Training loss: 1.3025829792022705
Validation loss: 1.9997613289022957

Epoch: 5| Step: 8
Training loss: 1.4415167570114136
Validation loss: 2.0112403631210327

Epoch: 5| Step: 9
Training loss: 1.7628265619277954
Validation loss: 2.016792720363986

Epoch: 5| Step: 10
Training loss: 1.8906413316726685
Validation loss: 2.062057779681298

Epoch: 309| Step: 0
Training loss: 1.0152970552444458
Validation loss: 2.0609641510953187

Epoch: 5| Step: 1
Training loss: 1.4415925741195679
Validation loss: 2.071167461333736

Epoch: 5| Step: 2
Training loss: 1.9962031841278076
Validation loss: 2.0990818162118234

Epoch: 5| Step: 3
Training loss: 1.3005292415618896
Validation loss: 2.1086045593343754

Epoch: 5| Step: 4
Training loss: 1.2723538875579834
Validation loss: 2.1335384371460124

Epoch: 5| Step: 5
Training loss: 1.653794527053833
Validation loss: 2.107346083528252

Epoch: 5| Step: 6
Training loss: 1.552915334701538
Validation loss: 2.063342768658874

Epoch: 5| Step: 7
Training loss: 1.9809188842773438
Validation loss: 2.053021482242051

Epoch: 5| Step: 8
Training loss: 1.223186731338501
Validation loss: 2.007251260101154

Epoch: 5| Step: 9
Training loss: 1.8262221813201904
Validation loss: 2.0335071086883545

Epoch: 5| Step: 10
Training loss: 1.9322065114974976
Validation loss: 2.0662441843299457

Epoch: 310| Step: 0
Training loss: 1.4637324810028076
Validation loss: 2.1219345318373812

Epoch: 5| Step: 1
Training loss: 1.5427091121673584
Validation loss: 2.173138672305692

Epoch: 5| Step: 2
Training loss: 1.61171555519104
Validation loss: 2.1822359305556103

Epoch: 5| Step: 3
Training loss: 1.4060261249542236
Validation loss: 2.1267523893746

Epoch: 5| Step: 4
Training loss: 1.6888307332992554
Validation loss: 2.052267502712947

Epoch: 5| Step: 5
Training loss: 1.0616822242736816
Validation loss: 1.9868844837270758

Epoch: 5| Step: 6
Training loss: 1.5359091758728027
Validation loss: 1.999416346191078

Epoch: 5| Step: 7
Training loss: 1.9852030277252197
Validation loss: 2.014512779892132

Epoch: 5| Step: 8
Training loss: 1.7613792419433594
Validation loss: 2.017840946874311

Epoch: 5| Step: 9
Training loss: 2.017805576324463
Validation loss: 1.9999757979505806

Epoch: 5| Step: 10
Training loss: 1.5328433513641357
Validation loss: 1.9797268221455235

Epoch: 311| Step: 0
Training loss: 1.5493719577789307
Validation loss: 1.9264755479751094

Epoch: 5| Step: 1
Training loss: 1.1256420612335205
Validation loss: 1.9471031209473968

Epoch: 5| Step: 2
Training loss: 1.4453656673431396
Validation loss: 1.9665070323533909

Epoch: 5| Step: 3
Training loss: 1.3493999242782593
Validation loss: 2.045765362760072

Epoch: 5| Step: 4
Training loss: 1.6385608911514282
Validation loss: 2.099584343612835

Epoch: 5| Step: 5
Training loss: 1.8369407653808594
Validation loss: 2.1823140472494145

Epoch: 5| Step: 6
Training loss: 1.5314723253250122
Validation loss: 2.160789338491296

Epoch: 5| Step: 7
Training loss: 1.5319106578826904
Validation loss: 2.0893391729683004

Epoch: 5| Step: 8
Training loss: 1.824292540550232
Validation loss: 2.0937617414741108

Epoch: 5| Step: 9
Training loss: 1.9297125339508057
Validation loss: 2.037975903480284

Epoch: 5| Step: 10
Training loss: 1.9116590023040771
Validation loss: 1.9511945760378273

Epoch: 312| Step: 0
Training loss: 1.4199684858322144
Validation loss: 1.944749778316867

Epoch: 5| Step: 1
Training loss: 1.7182471752166748
Validation loss: 1.9736722874385055

Epoch: 5| Step: 2
Training loss: 1.3195164203643799
Validation loss: 2.010113790471067

Epoch: 5| Step: 3
Training loss: 2.0348188877105713
Validation loss: 2.037069618061025

Epoch: 5| Step: 4
Training loss: 1.60797119140625
Validation loss: 2.016790641251431

Epoch: 5| Step: 5
Training loss: 2.0617549419403076
Validation loss: 2.014195162762878

Epoch: 5| Step: 6
Training loss: 1.471236228942871
Validation loss: 2.0280573239890476

Epoch: 5| Step: 7
Training loss: 1.0944169759750366
Validation loss: 2.0435830111144693

Epoch: 5| Step: 8
Training loss: 1.3012444972991943
Validation loss: 2.047474148452923

Epoch: 5| Step: 9
Training loss: 1.8490374088287354
Validation loss: 2.074634270001483

Epoch: 5| Step: 10
Training loss: 1.410090446472168
Validation loss: 2.044241714221175

Epoch: 313| Step: 0
Training loss: 1.3801201581954956
Validation loss: 2.018285528306038

Epoch: 5| Step: 1
Training loss: 1.9999252557754517
Validation loss: 2.0096714240248486

Epoch: 5| Step: 2
Training loss: 1.5115464925765991
Validation loss: 1.9929560615170387

Epoch: 5| Step: 3
Training loss: 1.219174861907959
Validation loss: 1.9889284282602289

Epoch: 5| Step: 4
Training loss: 1.84580397605896
Validation loss: 2.0070827084202922

Epoch: 5| Step: 5
Training loss: 1.5133634805679321
Validation loss: 2.073978862454814

Epoch: 5| Step: 6
Training loss: 1.0043810606002808
Validation loss: 2.095350644921744

Epoch: 5| Step: 7
Training loss: 1.5522725582122803
Validation loss: 2.078535441429384

Epoch: 5| Step: 8
Training loss: 1.9684635400772095
Validation loss: 2.043513867162889

Epoch: 5| Step: 9
Training loss: 1.4924930334091187
Validation loss: 2.0267201879973054

Epoch: 5| Step: 10
Training loss: 1.4246859550476074
Validation loss: 2.0302331909056632

Epoch: 314| Step: 0
Training loss: 1.6664257049560547
Validation loss: 2.0782474266585482

Epoch: 5| Step: 1
Training loss: 1.4515678882598877
Validation loss: 2.0761771330269436

Epoch: 5| Step: 2
Training loss: 1.6284250020980835
Validation loss: 2.0806232677992953

Epoch: 5| Step: 3
Training loss: 1.8208621740341187
Validation loss: 2.0923341653680287

Epoch: 5| Step: 4
Training loss: 1.5255002975463867
Validation loss: 2.093641111927648

Epoch: 5| Step: 5
Training loss: 0.8296264410018921
Validation loss: 2.039979073309129

Epoch: 5| Step: 6
Training loss: 1.4245915412902832
Validation loss: 2.08954978758289

Epoch: 5| Step: 7
Training loss: 1.4862215518951416
Validation loss: 2.0713983351184475

Epoch: 5| Step: 8
Training loss: 1.3676496744155884
Validation loss: 2.022117430163968

Epoch: 5| Step: 9
Training loss: 1.5029852390289307
Validation loss: 1.9814367832676056

Epoch: 5| Step: 10
Training loss: 1.9324722290039062
Validation loss: 1.969337833824978

Epoch: 315| Step: 0
Training loss: 2.1618709564208984
Validation loss: 1.931015496612877

Epoch: 5| Step: 1
Training loss: 1.5541188716888428
Validation loss: 1.890238042800657

Epoch: 5| Step: 2
Training loss: 1.4947404861450195
Validation loss: 1.9238579798770208

Epoch: 5| Step: 3
Training loss: 1.4087568521499634
Validation loss: 1.958938221777639

Epoch: 5| Step: 4
Training loss: 1.1533949375152588
Validation loss: 2.0006266306805354

Epoch: 5| Step: 5
Training loss: 1.3693945407867432
Validation loss: 2.0343003478101505

Epoch: 5| Step: 6
Training loss: 1.4704139232635498
Validation loss: 2.0745269175498717

Epoch: 5| Step: 7
Training loss: 1.430602788925171
Validation loss: 2.0909775021255657

Epoch: 5| Step: 8
Training loss: 1.3299858570098877
Validation loss: 2.1043172728630806

Epoch: 5| Step: 9
Training loss: 1.4893333911895752
Validation loss: 2.1230460546349965

Epoch: 5| Step: 10
Training loss: 1.8032137155532837
Validation loss: 2.090473455767478

Epoch: 316| Step: 0
Training loss: 1.5659542083740234
Validation loss: 2.0401607123754357

Epoch: 5| Step: 1
Training loss: 1.3451820611953735
Validation loss: 2.0518603504344983

Epoch: 5| Step: 2
Training loss: 1.4456584453582764
Validation loss: 2.036591622137254

Epoch: 5| Step: 3
Training loss: 1.865407943725586
Validation loss: 2.028535485267639

Epoch: 5| Step: 4
Training loss: 1.500554084777832
Validation loss: 2.024153091574228

Epoch: 5| Step: 5
Training loss: 1.37965989112854
Validation loss: 2.0277599852572203

Epoch: 5| Step: 6
Training loss: 1.3243138790130615
Validation loss: 2.039255383194134

Epoch: 5| Step: 7
Training loss: 1.733100175857544
Validation loss: 2.010004933162402

Epoch: 5| Step: 8
Training loss: 1.3119070529937744
Validation loss: 2.0230383693530993

Epoch: 5| Step: 9
Training loss: 1.5871332883834839
Validation loss: 2.0158242282047065

Epoch: 5| Step: 10
Training loss: 1.5661925077438354
Validation loss: 2.029508613771008

Epoch: 317| Step: 0
Training loss: 1.179365873336792
Validation loss: 2.0493446383424985

Epoch: 5| Step: 1
Training loss: 1.7142741680145264
Validation loss: 2.065306459703753

Epoch: 5| Step: 2
Training loss: 1.6590378284454346
Validation loss: 2.0516776782210155

Epoch: 5| Step: 3
Training loss: 1.4035683870315552
Validation loss: 1.9930672158477127

Epoch: 5| Step: 4
Training loss: 1.4818317890167236
Validation loss: 2.0045883578638874

Epoch: 5| Step: 5
Training loss: 1.594740867614746
Validation loss: 2.0121458820117417

Epoch: 5| Step: 6
Training loss: 1.582000494003296
Validation loss: 2.0286630840711695

Epoch: 5| Step: 7
Training loss: 1.3582375049591064
Validation loss: 2.032847219897855

Epoch: 5| Step: 8
Training loss: 1.445373296737671
Validation loss: 2.032182910109079

Epoch: 5| Step: 9
Training loss: 1.8066844940185547
Validation loss: 2.0692488185821043

Epoch: 5| Step: 10
Training loss: 0.8320668339729309
Validation loss: 2.030086245588077

Epoch: 318| Step: 0
Training loss: 2.0000810623168945
Validation loss: 2.04281283450383

Epoch: 5| Step: 1
Training loss: 0.9274219274520874
Validation loss: 2.0179128198213476

Epoch: 5| Step: 2
Training loss: 1.2179932594299316
Validation loss: 2.0096690244572137

Epoch: 5| Step: 3
Training loss: 1.4024494886398315
Validation loss: 1.9783387299506896

Epoch: 5| Step: 4
Training loss: 1.0780093669891357
Validation loss: 2.0128003679296023

Epoch: 5| Step: 5
Training loss: 1.083299994468689
Validation loss: 2.039773028383973

Epoch: 5| Step: 6
Training loss: 2.0116324424743652
Validation loss: 2.001619554335071

Epoch: 5| Step: 7
Training loss: 1.3921972513198853
Validation loss: 2.032705327515961

Epoch: 5| Step: 8
Training loss: 1.2323697805404663
Validation loss: 2.0390877262238534

Epoch: 5| Step: 9
Training loss: 1.9264204502105713
Validation loss: 2.0068941629061134

Epoch: 5| Step: 10
Training loss: 1.7274154424667358
Validation loss: 2.0223541823766564

Epoch: 319| Step: 0
Training loss: 1.2911276817321777
Validation loss: 2.0265841766070296

Epoch: 5| Step: 1
Training loss: 1.4734632968902588
Validation loss: 2.0086338263685986

Epoch: 5| Step: 2
Training loss: 1.490035057067871
Validation loss: 2.0143778003672117

Epoch: 5| Step: 3
Training loss: 1.7691948413848877
Validation loss: 2.0435168358587448

Epoch: 5| Step: 4
Training loss: 1.7839101552963257
Validation loss: 2.013569326810939

Epoch: 5| Step: 5
Training loss: 0.8885620832443237
Validation loss: 2.038756956336319

Epoch: 5| Step: 6
Training loss: 1.2745380401611328
Validation loss: 2.04624347020221

Epoch: 5| Step: 7
Training loss: 1.0448991060256958
Validation loss: 2.065996441789853

Epoch: 5| Step: 8
Training loss: 1.8476959466934204
Validation loss: 2.0550420130452802

Epoch: 5| Step: 9
Training loss: 2.1201300621032715
Validation loss: 2.0403959571674304

Epoch: 5| Step: 10
Training loss: 1.024505853652954
Validation loss: 1.9451689617608183

Epoch: 320| Step: 0
Training loss: 2.0933377742767334
Validation loss: 1.9381406179038427

Epoch: 5| Step: 1
Training loss: 1.2074611186981201
Validation loss: 1.921220951182868

Epoch: 5| Step: 2
Training loss: 1.1447584629058838
Validation loss: 1.9578527955598728

Epoch: 5| Step: 3
Training loss: 1.3710190057754517
Validation loss: 1.9615162316189017

Epoch: 5| Step: 4
Training loss: 1.8674694299697876
Validation loss: 1.997807579655801

Epoch: 5| Step: 5
Training loss: 1.7017415761947632
Validation loss: 2.0119972869914067

Epoch: 5| Step: 6
Training loss: 1.3033277988433838
Validation loss: 2.0601225104383243

Epoch: 5| Step: 7
Training loss: 1.3817310333251953
Validation loss: 2.126651197351435

Epoch: 5| Step: 8
Training loss: 1.4674197435379028
Validation loss: 2.1295739117489068

Epoch: 5| Step: 9
Training loss: 1.3119207620620728
Validation loss: 2.20977722701206

Epoch: 5| Step: 10
Training loss: 1.3163949251174927
Validation loss: 2.1480232323369672

Epoch: 321| Step: 0
Training loss: 1.2666189670562744
Validation loss: 2.1227666626694384

Epoch: 5| Step: 1
Training loss: 0.9942957162857056
Validation loss: 2.0661753672425465

Epoch: 5| Step: 2
Training loss: 1.6999452114105225
Validation loss: 2.019501414350284

Epoch: 5| Step: 3
Training loss: 1.2214505672454834
Validation loss: 1.980656229039674

Epoch: 5| Step: 4
Training loss: 1.3422750234603882
Validation loss: 1.9696570545114496

Epoch: 5| Step: 5
Training loss: 1.735910415649414
Validation loss: 1.9540234919517272

Epoch: 5| Step: 6
Training loss: 1.5265941619873047
Validation loss: 1.947073330161392

Epoch: 5| Step: 7
Training loss: 1.8166602849960327
Validation loss: 1.9618331258014967

Epoch: 5| Step: 8
Training loss: 1.757297158241272
Validation loss: 1.951424817885122

Epoch: 5| Step: 9
Training loss: 1.1919149160385132
Validation loss: 1.9763726675382225

Epoch: 5| Step: 10
Training loss: 1.6598985195159912
Validation loss: 2.009526862893053

Epoch: 322| Step: 0
Training loss: 0.8128337860107422
Validation loss: 2.0595223108927407

Epoch: 5| Step: 1
Training loss: 1.854802131652832
Validation loss: 2.127737234997493

Epoch: 5| Step: 2
Training loss: 1.2234458923339844
Validation loss: 2.154606009042391

Epoch: 5| Step: 3
Training loss: 1.2514610290527344
Validation loss: 2.1204548881899927

Epoch: 5| Step: 4
Training loss: 1.8659206628799438
Validation loss: 2.076841328733711

Epoch: 5| Step: 5
Training loss: 1.2573977708816528
Validation loss: 2.0746465075400566

Epoch: 5| Step: 6
Training loss: 2.167569398880005
Validation loss: 2.061378571294969

Epoch: 5| Step: 7
Training loss: 1.9791290760040283
Validation loss: 2.025823199620811

Epoch: 5| Step: 8
Training loss: 1.3187744617462158
Validation loss: 1.9773763200288177

Epoch: 5| Step: 9
Training loss: 0.799047589302063
Validation loss: 1.9617306519580144

Epoch: 5| Step: 10
Training loss: 1.5043911933898926
Validation loss: 1.9382967782276932

Epoch: 323| Step: 0
Training loss: 0.9422279596328735
Validation loss: 1.9659697932581748

Epoch: 5| Step: 1
Training loss: 1.3478553295135498
Validation loss: 1.9985757271448772

Epoch: 5| Step: 2
Training loss: 1.7670822143554688
Validation loss: 2.050332175788059

Epoch: 5| Step: 3
Training loss: 1.4202624559402466
Validation loss: 1.9996532829858924

Epoch: 5| Step: 4
Training loss: 1.2241531610488892
Validation loss: 1.9959425310934744

Epoch: 5| Step: 5
Training loss: 1.423611044883728
Validation loss: 1.969418027067697

Epoch: 5| Step: 6
Training loss: 1.6260898113250732
Validation loss: 1.9609804614897697

Epoch: 5| Step: 7
Training loss: 1.1920232772827148
Validation loss: 1.9686928564502346

Epoch: 5| Step: 8
Training loss: 1.627252221107483
Validation loss: 1.9917226555526897

Epoch: 5| Step: 9
Training loss: 1.604393720626831
Validation loss: 1.9988150288981776

Epoch: 5| Step: 10
Training loss: 1.7514536380767822
Validation loss: 1.9927893633483558

Epoch: 324| Step: 0
Training loss: 1.3152430057525635
Validation loss: 2.052780459004064

Epoch: 5| Step: 1
Training loss: 1.7373768091201782
Validation loss: 2.0784664205325547

Epoch: 5| Step: 2
Training loss: 1.3380227088928223
Validation loss: 2.0831648790708153

Epoch: 5| Step: 3
Training loss: 1.6088802814483643
Validation loss: 2.121154646719656

Epoch: 5| Step: 4
Training loss: 1.2730547189712524
Validation loss: 2.0852245130846576

Epoch: 5| Step: 5
Training loss: 1.096056580543518
Validation loss: 2.04903591832807

Epoch: 5| Step: 6
Training loss: 1.112682580947876
Validation loss: 1.9898977202753867

Epoch: 5| Step: 7
Training loss: 2.0532641410827637
Validation loss: 1.9814093433400637

Epoch: 5| Step: 8
Training loss: 1.3029437065124512
Validation loss: 1.972333078743309

Epoch: 5| Step: 9
Training loss: 1.2705354690551758
Validation loss: 1.9418300544061968

Epoch: 5| Step: 10
Training loss: 1.4646655321121216
Validation loss: 1.959731166080762

Epoch: 325| Step: 0
Training loss: 1.624193549156189
Validation loss: 1.9512937171484834

Epoch: 5| Step: 1
Training loss: 1.2143582105636597
Validation loss: 1.999771075863992

Epoch: 5| Step: 2
Training loss: 1.411604881286621
Validation loss: 2.011882466654624

Epoch: 5| Step: 3
Training loss: 1.2235511541366577
Validation loss: 2.0312769412994385

Epoch: 5| Step: 4
Training loss: 0.8986592292785645
Validation loss: 2.0457063451890023

Epoch: 5| Step: 5
Training loss: 1.5022259950637817
Validation loss: 2.034794940743395

Epoch: 5| Step: 6
Training loss: 1.317582130432129
Validation loss: 2.031627737065797

Epoch: 5| Step: 7
Training loss: 1.596035122871399
Validation loss: 2.039396239865211

Epoch: 5| Step: 8
Training loss: 1.501965045928955
Validation loss: 2.0277699129555815

Epoch: 5| Step: 9
Training loss: 1.5960330963134766
Validation loss: 2.009908540274507

Epoch: 5| Step: 10
Training loss: 1.7029528617858887
Validation loss: 1.9671214037044074

Epoch: 326| Step: 0
Training loss: 1.7304527759552002
Validation loss: 1.9631192068899832

Epoch: 5| Step: 1
Training loss: 1.5531030893325806
Validation loss: 1.9332377923432218

Epoch: 5| Step: 2
Training loss: 1.1129685640335083
Validation loss: 1.9981560014909314

Epoch: 5| Step: 3
Training loss: 1.4866125583648682
Validation loss: 1.9869947023289178

Epoch: 5| Step: 4
Training loss: 1.1876344680786133
Validation loss: 2.0083903933084137

Epoch: 5| Step: 5
Training loss: 1.7771762609481812
Validation loss: 2.0641483312012046

Epoch: 5| Step: 6
Training loss: 1.2035701274871826
Validation loss: 2.062576206781531

Epoch: 5| Step: 7
Training loss: 1.5443933010101318
Validation loss: 2.055884304866996

Epoch: 5| Step: 8
Training loss: 1.4764587879180908
Validation loss: 2.0617435157939954

Epoch: 5| Step: 9
Training loss: 1.3781548738479614
Validation loss: 2.028156870154924

Epoch: 5| Step: 10
Training loss: 0.9190476536750793
Validation loss: 1.9871434037403395

Epoch: 327| Step: 0
Training loss: 1.6236293315887451
Validation loss: 1.9780316660481114

Epoch: 5| Step: 1
Training loss: 0.9703346490859985
Validation loss: 1.9680176716978832

Epoch: 5| Step: 2
Training loss: 0.9775092005729675
Validation loss: 1.9369257098884993

Epoch: 5| Step: 3
Training loss: 1.0417922735214233
Validation loss: 1.929486705410865

Epoch: 5| Step: 4
Training loss: 1.590948224067688
Validation loss: 1.9586847366825226

Epoch: 5| Step: 5
Training loss: 1.8095550537109375
Validation loss: 2.0105123007169334

Epoch: 5| Step: 6
Training loss: 1.64958918094635
Validation loss: 2.0749123916831067

Epoch: 5| Step: 7
Training loss: 1.2703611850738525
Validation loss: 2.131048548606134

Epoch: 5| Step: 8
Training loss: 2.25895094871521
Validation loss: 2.1494002624224593

Epoch: 5| Step: 9
Training loss: 1.572459101676941
Validation loss: 2.112894594028432

Epoch: 5| Step: 10
Training loss: 1.0914136171340942
Validation loss: 2.058340057249992

Epoch: 328| Step: 0
Training loss: 1.0428098440170288
Validation loss: 1.9735088938026017

Epoch: 5| Step: 1
Training loss: 1.6636813879013062
Validation loss: 1.947663281553535

Epoch: 5| Step: 2
Training loss: 1.3328241109848022
Validation loss: 1.932886633821713

Epoch: 5| Step: 3
Training loss: 1.4955313205718994
Validation loss: 1.935975956660445

Epoch: 5| Step: 4
Training loss: 1.315267562866211
Validation loss: 1.9321037133534749

Epoch: 5| Step: 5
Training loss: 1.2647873163223267
Validation loss: 1.935943611206547

Epoch: 5| Step: 6
Training loss: 1.2832725048065186
Validation loss: 1.9434277524230301

Epoch: 5| Step: 7
Training loss: 1.7645803689956665
Validation loss: 1.9543645766473585

Epoch: 5| Step: 8
Training loss: 1.2585561275482178
Validation loss: 1.9792200493556198

Epoch: 5| Step: 9
Training loss: 1.4858760833740234
Validation loss: 1.9708339680907547

Epoch: 5| Step: 10
Training loss: 1.2793337106704712
Validation loss: 2.0026730196450346

Epoch: 329| Step: 0
Training loss: 1.8240190744400024
Validation loss: 2.0045688049767607

Epoch: 5| Step: 1
Training loss: 1.0096040964126587
Validation loss: 2.017502961620208

Epoch: 5| Step: 2
Training loss: 1.6166362762451172
Validation loss: 2.0403575692125546

Epoch: 5| Step: 3
Training loss: 1.3767706155776978
Validation loss: 2.0558219981449906

Epoch: 5| Step: 4
Training loss: 1.1739399433135986
Validation loss: 2.0148020034195273

Epoch: 5| Step: 5
Training loss: 2.3363776206970215
Validation loss: 2.0150914833109868

Epoch: 5| Step: 6
Training loss: 1.3454246520996094
Validation loss: 1.994742347348121

Epoch: 5| Step: 7
Training loss: 1.4049584865570068
Validation loss: 1.9789130726168234

Epoch: 5| Step: 8
Training loss: 0.6757336854934692
Validation loss: 1.9296612675471971

Epoch: 5| Step: 9
Training loss: 1.0820434093475342
Validation loss: 1.9509813965007823

Epoch: 5| Step: 10
Training loss: 1.4232795238494873
Validation loss: 1.9422633635100497

Epoch: 330| Step: 0
Training loss: 2.0398311614990234
Validation loss: 1.9383465372106081

Epoch: 5| Step: 1
Training loss: 1.4190425872802734
Validation loss: 1.905452900035407

Epoch: 5| Step: 2
Training loss: 1.0665080547332764
Validation loss: 1.915883243724864

Epoch: 5| Step: 3
Training loss: 0.909157931804657
Validation loss: 1.9057748368991319

Epoch: 5| Step: 4
Training loss: 1.4866008758544922
Validation loss: 1.920663990000243

Epoch: 5| Step: 5
Training loss: 1.0841567516326904
Validation loss: 1.942449628665883

Epoch: 5| Step: 6
Training loss: 1.4483672380447388
Validation loss: 1.9798149934379004

Epoch: 5| Step: 7
Training loss: 1.539933443069458
Validation loss: 2.015614514709801

Epoch: 5| Step: 8
Training loss: 1.4409452676773071
Validation loss: 2.0354105862238074

Epoch: 5| Step: 9
Training loss: 1.7967649698257446
Validation loss: 2.0353728237972466

Epoch: 5| Step: 10
Training loss: 1.0427262783050537
Validation loss: 2.0462103889834498

Epoch: 331| Step: 0
Training loss: 1.356252908706665
Validation loss: 2.0210795646072715

Epoch: 5| Step: 1
Training loss: 1.6766245365142822
Validation loss: 1.994639269767269

Epoch: 5| Step: 2
Training loss: 1.6867239475250244
Validation loss: 1.984263680314505

Epoch: 5| Step: 3
Training loss: 1.3498283624649048
Validation loss: 1.984134474108296

Epoch: 5| Step: 4
Training loss: 1.1915066242218018
Validation loss: 1.9852870959107594

Epoch: 5| Step: 5
Training loss: 1.6304820775985718
Validation loss: 1.9698327523405834

Epoch: 5| Step: 6
Training loss: 0.8219572305679321
Validation loss: 1.9213726469265517

Epoch: 5| Step: 7
Training loss: 1.4681854248046875
Validation loss: 1.9601708099406252

Epoch: 5| Step: 8
Training loss: 1.3601291179656982
Validation loss: 1.9653564806907409

Epoch: 5| Step: 9
Training loss: 0.9786888360977173
Validation loss: 1.9536779849759993

Epoch: 5| Step: 10
Training loss: 1.4213265180587769
Validation loss: 2.0078002739978094

Epoch: 332| Step: 0
Training loss: 1.2812470197677612
Validation loss: 2.010845366344657

Epoch: 5| Step: 1
Training loss: 1.5416306257247925
Validation loss: 2.0022339564497753

Epoch: 5| Step: 2
Training loss: 1.5780271291732788
Validation loss: 1.9745619194481963

Epoch: 5| Step: 3
Training loss: 1.449572205543518
Validation loss: 1.9640549100855345

Epoch: 5| Step: 4
Training loss: 1.4651141166687012
Validation loss: 1.9611379869522587

Epoch: 5| Step: 5
Training loss: 1.6288845539093018
Validation loss: 1.9389465201285578

Epoch: 5| Step: 6
Training loss: 1.2330656051635742
Validation loss: 1.9348257574983823

Epoch: 5| Step: 7
Training loss: 1.393005609512329
Validation loss: 1.938945516463249

Epoch: 5| Step: 8
Training loss: 1.056305170059204
Validation loss: 1.9498902469552972

Epoch: 5| Step: 9
Training loss: 1.526610255241394
Validation loss: 1.9830457984760244

Epoch: 5| Step: 10
Training loss: 0.9395865201950073
Validation loss: 2.000694255675039

Epoch: 333| Step: 0
Training loss: 1.491725206375122
Validation loss: 2.0252851888697636

Epoch: 5| Step: 1
Training loss: 1.6193857192993164
Validation loss: 2.0223768385507728

Epoch: 5| Step: 2
Training loss: 1.4267780780792236
Validation loss: 2.002629928691413

Epoch: 5| Step: 3
Training loss: 0.9920248985290527
Validation loss: 1.9742684851410568

Epoch: 5| Step: 4
Training loss: 1.537607192993164
Validation loss: 1.9361757706570368

Epoch: 5| Step: 5
Training loss: 1.312531590461731
Validation loss: 1.943262187383508

Epoch: 5| Step: 6
Training loss: 1.2250001430511475
Validation loss: 1.9570242076791742

Epoch: 5| Step: 7
Training loss: 1.0890253782272339
Validation loss: 1.9771617484349076

Epoch: 5| Step: 8
Training loss: 2.1450870037078857
Validation loss: 1.965392699805639

Epoch: 5| Step: 9
Training loss: 1.0831165313720703
Validation loss: 1.9966102594970374

Epoch: 5| Step: 10
Training loss: 0.9991925358772278
Validation loss: 2.0163038853676087

Epoch: 334| Step: 0
Training loss: 1.002725601196289
Validation loss: 1.9944854090290685

Epoch: 5| Step: 1
Training loss: 1.5455293655395508
Validation loss: 1.9826923493416078

Epoch: 5| Step: 2
Training loss: 0.8765271902084351
Validation loss: 1.9690708498800955

Epoch: 5| Step: 3
Training loss: 1.4876658916473389
Validation loss: 1.9300772464403542

Epoch: 5| Step: 4
Training loss: 1.153031826019287
Validation loss: 1.9464101022289646

Epoch: 5| Step: 5
Training loss: 1.6461015939712524
Validation loss: 1.946184765908026

Epoch: 5| Step: 6
Training loss: 1.3549997806549072
Validation loss: 1.9791574042330506

Epoch: 5| Step: 7
Training loss: 1.1807957887649536
Validation loss: 2.0099971371312297

Epoch: 5| Step: 8
Training loss: 1.3099167346954346
Validation loss: 2.0157400690099245

Epoch: 5| Step: 9
Training loss: 1.626621961593628
Validation loss: 2.0290510346812587

Epoch: 5| Step: 10
Training loss: 1.8411076068878174
Validation loss: 2.0292137720251597

Epoch: 335| Step: 0
Training loss: 1.991400957107544
Validation loss: 2.0344432746210406

Epoch: 5| Step: 1
Training loss: 1.523260474205017
Validation loss: 2.0280829193771526

Epoch: 5| Step: 2
Training loss: 1.4361382722854614
Validation loss: 2.0364875203819683

Epoch: 5| Step: 3
Training loss: 1.0424482822418213
Validation loss: 2.0108319546586726

Epoch: 5| Step: 4
Training loss: 1.9973138570785522
Validation loss: 1.9668614736167334

Epoch: 5| Step: 5
Training loss: 1.3443691730499268
Validation loss: 1.9347952117202103

Epoch: 5| Step: 6
Training loss: 1.0622767210006714
Validation loss: 1.9424925696465276

Epoch: 5| Step: 7
Training loss: 0.8025742769241333
Validation loss: 1.9420230619369014

Epoch: 5| Step: 8
Training loss: 0.6591177582740784
Validation loss: 1.964732644378498

Epoch: 5| Step: 9
Training loss: 1.4225614070892334
Validation loss: 1.9988517440775389

Epoch: 5| Step: 10
Training loss: 1.6171679496765137
Validation loss: 1.9642421301975046

Epoch: 336| Step: 0
Training loss: 1.129355788230896
Validation loss: 1.9443738909177883

Epoch: 5| Step: 1
Training loss: 1.4856597185134888
Validation loss: 1.9411918540154733

Epoch: 5| Step: 2
Training loss: 1.4348785877227783
Validation loss: 1.9272965743977537

Epoch: 5| Step: 3
Training loss: 1.562395691871643
Validation loss: 1.9292098219676683

Epoch: 5| Step: 4
Training loss: 1.3771531581878662
Validation loss: 1.9282910388003114

Epoch: 5| Step: 5
Training loss: 1.5931679010391235
Validation loss: 1.923538165707742

Epoch: 5| Step: 6
Training loss: 1.3895899057388306
Validation loss: 1.900532800664184

Epoch: 5| Step: 7
Training loss: 1.3854879140853882
Validation loss: 1.909656701549407

Epoch: 5| Step: 8
Training loss: 1.1904851198196411
Validation loss: 1.9539171829018542

Epoch: 5| Step: 9
Training loss: 1.0781326293945312
Validation loss: 2.0117922290678947

Epoch: 5| Step: 10
Training loss: 1.1783655881881714
Validation loss: 2.041938658683531

Epoch: 337| Step: 0
Training loss: 1.408896565437317
Validation loss: 1.9910794419627036

Epoch: 5| Step: 1
Training loss: 1.0623481273651123
Validation loss: 1.9475775534106838

Epoch: 5| Step: 2
Training loss: 1.4317481517791748
Validation loss: 1.9544619027004446

Epoch: 5| Step: 3
Training loss: 0.9821394681930542
Validation loss: 1.953306762121057

Epoch: 5| Step: 4
Training loss: 1.490643858909607
Validation loss: 1.9658906280353505

Epoch: 5| Step: 5
Training loss: 1.182521939277649
Validation loss: 1.9430086151246102

Epoch: 5| Step: 6
Training loss: 1.2818050384521484
Validation loss: 1.9598016879891837

Epoch: 5| Step: 7
Training loss: 1.4239542484283447
Validation loss: 1.914353028420479

Epoch: 5| Step: 8
Training loss: 1.554607629776001
Validation loss: 1.8945877321304814

Epoch: 5| Step: 9
Training loss: 1.2718663215637207
Validation loss: 1.929913072175877

Epoch: 5| Step: 10
Training loss: 1.9270358085632324
Validation loss: 1.9800762796914706

Epoch: 338| Step: 0
Training loss: 1.2668591737747192
Validation loss: 1.9635907706393991

Epoch: 5| Step: 1
Training loss: 1.3534891605377197
Validation loss: 1.9849177996317546

Epoch: 5| Step: 2
Training loss: 1.5640901327133179
Validation loss: 1.994382014838598

Epoch: 5| Step: 3
Training loss: 0.8076151013374329
Validation loss: 1.9689961159101097

Epoch: 5| Step: 4
Training loss: 1.3807599544525146
Validation loss: 1.9413019521262056

Epoch: 5| Step: 5
Training loss: 1.785116195678711
Validation loss: 1.9472217277813983

Epoch: 5| Step: 6
Training loss: 1.4834569692611694
Validation loss: 1.921614860975614

Epoch: 5| Step: 7
Training loss: 1.1603279113769531
Validation loss: 1.9388813690472675

Epoch: 5| Step: 8
Training loss: 1.5094783306121826
Validation loss: 1.9427525766434208

Epoch: 5| Step: 9
Training loss: 1.3383910655975342
Validation loss: 1.9769694048871276

Epoch: 5| Step: 10
Training loss: 1.0254284143447876
Validation loss: 1.9951399167378743

Epoch: 339| Step: 0
Training loss: 1.672067642211914
Validation loss: 1.9934668412772558

Epoch: 5| Step: 1
Training loss: 1.2153956890106201
Validation loss: 1.985546822189003

Epoch: 5| Step: 2
Training loss: 1.2258648872375488
Validation loss: 1.9635880416439426

Epoch: 5| Step: 3
Training loss: 0.9015371203422546
Validation loss: 1.9612697862809705

Epoch: 5| Step: 4
Training loss: 1.153939127922058
Validation loss: 1.959514364119499

Epoch: 5| Step: 5
Training loss: 1.596436858177185
Validation loss: 1.9542209307352703

Epoch: 5| Step: 6
Training loss: 1.0724481344223022
Validation loss: 1.9480792655739734

Epoch: 5| Step: 7
Training loss: 1.3749747276306152
Validation loss: 1.9710404949803506

Epoch: 5| Step: 8
Training loss: 1.27133309841156
Validation loss: 1.9528572123537782

Epoch: 5| Step: 9
Training loss: 1.7470108270645142
Validation loss: 1.9340962312554801

Epoch: 5| Step: 10
Training loss: 1.255924940109253
Validation loss: 1.9575688890231553

Epoch: 340| Step: 0
Training loss: 1.5535786151885986
Validation loss: 1.9640472140363467

Epoch: 5| Step: 1
Training loss: 1.6946828365325928
Validation loss: 1.9634800854549612

Epoch: 5| Step: 2
Training loss: 0.9466697573661804
Validation loss: 1.964627860694803

Epoch: 5| Step: 3
Training loss: 1.135758876800537
Validation loss: 1.9500499489486858

Epoch: 5| Step: 4
Training loss: 1.0485020875930786
Validation loss: 1.936043757264332

Epoch: 5| Step: 5
Training loss: 1.6551973819732666
Validation loss: 1.9411470569590086

Epoch: 5| Step: 6
Training loss: 1.2163188457489014
Validation loss: 1.932951334984072

Epoch: 5| Step: 7
Training loss: 1.6258169412612915
Validation loss: 1.9507621295990483

Epoch: 5| Step: 8
Training loss: 0.6400688886642456
Validation loss: 1.9631576512449531

Epoch: 5| Step: 9
Training loss: 1.2274072170257568
Validation loss: 1.9392758902683054

Epoch: 5| Step: 10
Training loss: 1.6601108312606812
Validation loss: 1.8998642608683596

Epoch: 341| Step: 0
Training loss: 1.348035216331482
Validation loss: 1.889564666696774

Epoch: 5| Step: 1
Training loss: 1.2823879718780518
Validation loss: 1.8667689061933948

Epoch: 5| Step: 2
Training loss: 1.6393916606903076
Validation loss: 1.886352482662406

Epoch: 5| Step: 3
Training loss: 0.6374441385269165
Validation loss: 1.931246179406361

Epoch: 5| Step: 4
Training loss: 1.1706066131591797
Validation loss: 1.9492984279509513

Epoch: 5| Step: 5
Training loss: 1.2102701663970947
Validation loss: 1.9875527235769457

Epoch: 5| Step: 6
Training loss: 2.055088758468628
Validation loss: 2.0139185485019477

Epoch: 5| Step: 7
Training loss: 1.7788593769073486
Validation loss: 1.9959803870929185

Epoch: 5| Step: 8
Training loss: 0.7405122518539429
Validation loss: 1.9723991578625095

Epoch: 5| Step: 9
Training loss: 1.2322887182235718
Validation loss: 1.9548137649413078

Epoch: 5| Step: 10
Training loss: 1.660953164100647
Validation loss: 1.916069753708378

Epoch: 342| Step: 0
Training loss: 1.6598584651947021
Validation loss: 1.8841798831057806

Epoch: 5| Step: 1
Training loss: 1.206341028213501
Validation loss: 1.8879062616696922

Epoch: 5| Step: 2
Training loss: 0.812118411064148
Validation loss: 1.9068975884427306

Epoch: 5| Step: 3
Training loss: 1.4499469995498657
Validation loss: 1.9373987849040697

Epoch: 5| Step: 4
Training loss: 2.080582857131958
Validation loss: 1.9614057028165428

Epoch: 5| Step: 5
Training loss: 1.5494883060455322
Validation loss: 1.9657302043771232

Epoch: 5| Step: 6
Training loss: 1.4405065774917603
Validation loss: 1.9742707180720505

Epoch: 5| Step: 7
Training loss: 0.76170414686203
Validation loss: 1.9885667857303415

Epoch: 5| Step: 8
Training loss: 1.5103585720062256
Validation loss: 1.9639259333251624

Epoch: 5| Step: 9
Training loss: 1.093226432800293
Validation loss: 1.9325189026453162

Epoch: 5| Step: 10
Training loss: 1.269687533378601
Validation loss: 1.9558752224009524

Epoch: 343| Step: 0
Training loss: 1.4275600910186768
Validation loss: 1.9595633450374808

Epoch: 5| Step: 1
Training loss: 1.5602073669433594
Validation loss: 1.949168961535218

Epoch: 5| Step: 2
Training loss: 1.0938059091567993
Validation loss: 1.9601995611703524

Epoch: 5| Step: 3
Training loss: 1.1890323162078857
Validation loss: 1.961447879832278

Epoch: 5| Step: 4
Training loss: 1.2405951023101807
Validation loss: 1.9308951823942122

Epoch: 5| Step: 5
Training loss: 1.1376701593399048
Validation loss: 1.9000512938345633

Epoch: 5| Step: 6
Training loss: 1.4069961309432983
Validation loss: 1.884621403550589

Epoch: 5| Step: 7
Training loss: 1.1060055494308472
Validation loss: 1.9018115997314453

Epoch: 5| Step: 8
Training loss: 1.9238231182098389
Validation loss: 1.9103571381620181

Epoch: 5| Step: 9
Training loss: 1.1023184061050415
Validation loss: 1.9088544922490274

Epoch: 5| Step: 10
Training loss: 1.444493293762207
Validation loss: 1.9127967549908547

Epoch: 344| Step: 0
Training loss: 0.9936795234680176
Validation loss: 1.880170178669755

Epoch: 5| Step: 1
Training loss: 1.5841948986053467
Validation loss: 1.8796631648976316

Epoch: 5| Step: 2
Training loss: 1.0345237255096436
Validation loss: 1.8670201378483926

Epoch: 5| Step: 3
Training loss: 1.1117641925811768
Validation loss: 1.8777929787994714

Epoch: 5| Step: 4
Training loss: 1.3865785598754883
Validation loss: 1.898902129101497

Epoch: 5| Step: 5
Training loss: 1.9661273956298828
Validation loss: 1.945249424185804

Epoch: 5| Step: 6
Training loss: 1.297671914100647
Validation loss: 1.9656485101228118

Epoch: 5| Step: 7
Training loss: 1.2265160083770752
Validation loss: 1.9432201103497577

Epoch: 5| Step: 8
Training loss: 1.7262799739837646
Validation loss: 1.95198183162238

Epoch: 5| Step: 9
Training loss: 1.1745249032974243
Validation loss: 1.9639970743527977

Epoch: 5| Step: 10
Training loss: 1.3325257301330566
Validation loss: 1.990927864146489

Epoch: 345| Step: 0
Training loss: 1.1351110935211182
Validation loss: 1.9468901247106574

Epoch: 5| Step: 1
Training loss: 1.3514821529388428
Validation loss: 1.929812257007886

Epoch: 5| Step: 2
Training loss: 1.0177252292633057
Validation loss: 1.9233743298438288

Epoch: 5| Step: 3
Training loss: 1.2522594928741455
Validation loss: 1.8898350231109127

Epoch: 5| Step: 4
Training loss: 1.405677080154419
Validation loss: 1.9224449075678343

Epoch: 5| Step: 5
Training loss: 1.4785908460617065
Validation loss: 1.935693266571209

Epoch: 5| Step: 6
Training loss: 1.323009729385376
Validation loss: 1.9154156408002299

Epoch: 5| Step: 7
Training loss: 1.4159433841705322
Validation loss: 1.8822791576385498

Epoch: 5| Step: 8
Training loss: 1.3134171962738037
Validation loss: 1.9380075380366335

Epoch: 5| Step: 9
Training loss: 1.5478990077972412
Validation loss: 1.9853185504995368

Epoch: 5| Step: 10
Training loss: 1.503058671951294
Validation loss: 2.0004723174597627

Epoch: 346| Step: 0
Training loss: 1.4649790525436401
Validation loss: 2.022190543913072

Epoch: 5| Step: 1
Training loss: 1.2424201965332031
Validation loss: 2.0197546443631573

Epoch: 5| Step: 2
Training loss: 1.2558943033218384
Validation loss: 2.0153272972312024

Epoch: 5| Step: 3
Training loss: 1.255096673965454
Validation loss: 1.967861867720081

Epoch: 5| Step: 4
Training loss: 1.2484965324401855
Validation loss: 1.965085566684764

Epoch: 5| Step: 5
Training loss: 1.4514598846435547
Validation loss: 1.9864679844148698

Epoch: 5| Step: 6
Training loss: 0.7846291065216064
Validation loss: 1.9657857828242804

Epoch: 5| Step: 7
Training loss: 1.035814881324768
Validation loss: 1.9531806079290246

Epoch: 5| Step: 8
Training loss: 1.3808733224868774
Validation loss: 1.9448380777912755

Epoch: 5| Step: 9
Training loss: 1.8553831577301025
Validation loss: 1.915024157493345

Epoch: 5| Step: 10
Training loss: 1.5553178787231445
Validation loss: 1.9350751189775364

Epoch: 347| Step: 0
Training loss: 1.3942638635635376
Validation loss: 1.9381405051036547

Epoch: 5| Step: 1
Training loss: 1.1596529483795166
Validation loss: 1.941907040534481

Epoch: 5| Step: 2
Training loss: 1.3379805088043213
Validation loss: 1.936789083224471

Epoch: 5| Step: 3
Training loss: 1.0243918895721436
Validation loss: 1.9488890132596415

Epoch: 5| Step: 4
Training loss: 0.5680855512619019
Validation loss: 1.9655471181356778

Epoch: 5| Step: 5
Training loss: 1.2598278522491455
Validation loss: 1.975242394272999

Epoch: 5| Step: 6
Training loss: 1.157273769378662
Validation loss: 1.9744758298320155

Epoch: 5| Step: 7
Training loss: 1.7710822820663452
Validation loss: 1.9795829916513095

Epoch: 5| Step: 8
Training loss: 1.2567150592803955
Validation loss: 1.9952995725857314

Epoch: 5| Step: 9
Training loss: 1.720342993736267
Validation loss: 1.9743529981182468

Epoch: 5| Step: 10
Training loss: 1.6296372413635254
Validation loss: 1.9559591316407727

Epoch: 348| Step: 0
Training loss: 1.5799925327301025
Validation loss: 1.9336121107942315

Epoch: 5| Step: 1
Training loss: 1.3785409927368164
Validation loss: 1.905104003926759

Epoch: 5| Step: 2
Training loss: 0.9108111262321472
Validation loss: 1.899537581269459

Epoch: 5| Step: 3
Training loss: 1.0392141342163086
Validation loss: 1.9045680081972511

Epoch: 5| Step: 4
Training loss: 1.318091630935669
Validation loss: 1.8757035193904754

Epoch: 5| Step: 5
Training loss: 1.4142558574676514
Validation loss: 1.8862587354516471

Epoch: 5| Step: 6
Training loss: 1.3946260213851929
Validation loss: 1.9187285720661122

Epoch: 5| Step: 7
Training loss: 1.1443595886230469
Validation loss: 1.9377889376814648

Epoch: 5| Step: 8
Training loss: 1.29625403881073
Validation loss: 1.97840408355959

Epoch: 5| Step: 9
Training loss: 1.5252134799957275
Validation loss: 2.02817048821398

Epoch: 5| Step: 10
Training loss: 1.1626027822494507
Validation loss: 1.9967847254968458

Epoch: 349| Step: 0
Training loss: 1.132098913192749
Validation loss: 1.9500048032370947

Epoch: 5| Step: 1
Training loss: 1.1373114585876465
Validation loss: 1.941197100506034

Epoch: 5| Step: 2
Training loss: 1.2598100900650024
Validation loss: 1.9168418274130872

Epoch: 5| Step: 3
Training loss: 1.1200363636016846
Validation loss: 1.9335256302228538

Epoch: 5| Step: 4
Training loss: 1.3986761569976807
Validation loss: 1.9216171259521155

Epoch: 5| Step: 5
Training loss: 1.3547580242156982
Validation loss: 1.93507682764402

Epoch: 5| Step: 6
Training loss: 1.316284418106079
Validation loss: 1.91711595237896

Epoch: 5| Step: 7
Training loss: 1.326585054397583
Validation loss: 1.9161003353775188

Epoch: 5| Step: 8
Training loss: 1.109929084777832
Validation loss: 1.936865077223829

Epoch: 5| Step: 9
Training loss: 1.4307740926742554
Validation loss: 1.9463415248419649

Epoch: 5| Step: 10
Training loss: 1.5683135986328125
Validation loss: 1.8959073148747927

Epoch: 350| Step: 0
Training loss: 0.7258987426757812
Validation loss: 1.9087707688731532

Epoch: 5| Step: 1
Training loss: 1.7890732288360596
Validation loss: 1.896914441098449

Epoch: 5| Step: 2
Training loss: 0.607218861579895
Validation loss: 1.899480535138038

Epoch: 5| Step: 3
Training loss: 1.8072134256362915
Validation loss: 1.9509516813421761

Epoch: 5| Step: 4
Training loss: 1.07518470287323
Validation loss: 2.0306858439599313

Epoch: 5| Step: 5
Training loss: 1.1571247577667236
Validation loss: 2.037906362164405

Epoch: 5| Step: 6
Training loss: 1.2737228870391846
Validation loss: 2.079076620840257

Epoch: 5| Step: 7
Training loss: 1.654658317565918
Validation loss: 2.020276072204754

Epoch: 5| Step: 8
Training loss: 1.3293540477752686
Validation loss: 1.9974767418317898

Epoch: 5| Step: 9
Training loss: 1.5963544845581055
Validation loss: 1.9673159045557822

Epoch: 5| Step: 10
Training loss: 1.431042194366455
Validation loss: 1.9228085369192145

Epoch: 351| Step: 0
Training loss: 1.07843017578125
Validation loss: 1.8960530745085848

Epoch: 5| Step: 1
Training loss: 1.1723271608352661
Validation loss: 1.8972261105814288

Epoch: 5| Step: 2
Training loss: 1.1899195909500122
Validation loss: 1.94802398579095

Epoch: 5| Step: 3
Training loss: 0.9631209373474121
Validation loss: 1.9752092617814259

Epoch: 5| Step: 4
Training loss: 1.5595219135284424
Validation loss: 1.9748083340224398

Epoch: 5| Step: 5
Training loss: 1.7348817586898804
Validation loss: 1.9763657251993816

Epoch: 5| Step: 6
Training loss: 1.3810755014419556
Validation loss: 1.9568182627360027

Epoch: 5| Step: 7
Training loss: 0.9472139477729797
Validation loss: 1.9322549527691257

Epoch: 5| Step: 8
Training loss: 1.3279129266738892
Validation loss: 1.9079821417408604

Epoch: 5| Step: 9
Training loss: 1.6172056198120117
Validation loss: 1.9097112353130052

Epoch: 5| Step: 10
Training loss: 1.2932116985321045
Validation loss: 1.925509609201903

Epoch: 352| Step: 0
Training loss: 1.4556775093078613
Validation loss: 1.935072709155339

Epoch: 5| Step: 1
Training loss: 1.40547776222229
Validation loss: 1.949045681184338

Epoch: 5| Step: 2
Training loss: 1.0027565956115723
Validation loss: 1.9367525308362898

Epoch: 5| Step: 3
Training loss: 1.3797690868377686
Validation loss: 1.9915798582056516

Epoch: 5| Step: 4
Training loss: 1.647035002708435
Validation loss: 2.019035752101611

Epoch: 5| Step: 5
Training loss: 0.8152793645858765
Validation loss: 2.063740937940536

Epoch: 5| Step: 6
Training loss: 1.421465277671814
Validation loss: 2.0659449587586107

Epoch: 5| Step: 7
Training loss: 1.3141320943832397
Validation loss: 2.080835779507955

Epoch: 5| Step: 8
Training loss: 1.1486320495605469
Validation loss: 2.019033756307376

Epoch: 5| Step: 9
Training loss: 1.4137237071990967
Validation loss: 1.9800405028045818

Epoch: 5| Step: 10
Training loss: 1.1933680772781372
Validation loss: 1.9527684898786648

Epoch: 353| Step: 0
Training loss: 1.5786980390548706
Validation loss: 1.9587777532557005

Epoch: 5| Step: 1
Training loss: 1.1367290019989014
Validation loss: 1.9000704570483136

Epoch: 5| Step: 2
Training loss: 1.0997493267059326
Validation loss: 1.8706893126169841

Epoch: 5| Step: 3
Training loss: 1.1834989786148071
Validation loss: 1.8652169127618112

Epoch: 5| Step: 4
Training loss: 1.0063402652740479
Validation loss: 1.8828230442539338

Epoch: 5| Step: 5
Training loss: 1.3469005823135376
Validation loss: 1.8896440254744662

Epoch: 5| Step: 6
Training loss: 1.168633222579956
Validation loss: 1.8832915098436418

Epoch: 5| Step: 7
Training loss: 1.4145658016204834
Validation loss: 1.9384387539279075

Epoch: 5| Step: 8
Training loss: 1.377493143081665
Validation loss: 1.9318438999114498

Epoch: 5| Step: 9
Training loss: 1.3767131567001343
Validation loss: 1.9287909717969998

Epoch: 5| Step: 10
Training loss: 1.2922582626342773
Validation loss: 1.9156586713688348

Epoch: 354| Step: 0
Training loss: 1.503365159034729
Validation loss: 1.9168464265843874

Epoch: 5| Step: 1
Training loss: 1.231091022491455
Validation loss: 1.8988169752141482

Epoch: 5| Step: 2
Training loss: 0.6754152774810791
Validation loss: 1.8945472445539249

Epoch: 5| Step: 3
Training loss: 1.0148651599884033
Validation loss: 1.9167302411089662

Epoch: 5| Step: 4
Training loss: 2.0370101928710938
Validation loss: 1.9313848275010304

Epoch: 5| Step: 5
Training loss: 1.0892508029937744
Validation loss: 1.9465505384629773

Epoch: 5| Step: 6
Training loss: 1.416865587234497
Validation loss: 1.962631489640923

Epoch: 5| Step: 7
Training loss: 1.3130223751068115
Validation loss: 1.9043163138051187

Epoch: 5| Step: 8
Training loss: 1.52046799659729
Validation loss: 1.8716581072858585

Epoch: 5| Step: 9
Training loss: 0.6903520226478577
Validation loss: 1.8746802755581435

Epoch: 5| Step: 10
Training loss: 1.023406982421875
Validation loss: 1.8651179190604918

Epoch: 355| Step: 0
Training loss: 1.483938217163086
Validation loss: 1.8609876491690194

Epoch: 5| Step: 1
Training loss: 1.269330382347107
Validation loss: 1.902512377308261

Epoch: 5| Step: 2
Training loss: 1.125558853149414
Validation loss: 1.9110695085217875

Epoch: 5| Step: 3
Training loss: 0.9616581201553345
Validation loss: 1.9041344978476082

Epoch: 5| Step: 4
Training loss: 0.7256057262420654
Validation loss: 1.9324426779183008

Epoch: 5| Step: 5
Training loss: 1.4176486730575562
Validation loss: 1.9892962748004543

Epoch: 5| Step: 6
Training loss: 1.22642183303833
Validation loss: 2.0077092160460768

Epoch: 5| Step: 7
Training loss: 1.7606127262115479
Validation loss: 2.0226427175665416

Epoch: 5| Step: 8
Training loss: 1.1767690181732178
Validation loss: 2.022083579853017

Epoch: 5| Step: 9
Training loss: 1.3355270624160767
Validation loss: 1.9834490104388165

Epoch: 5| Step: 10
Training loss: 0.9405688047409058
Validation loss: 1.9504160522132792

Epoch: 356| Step: 0
Training loss: 1.2408345937728882
Validation loss: 1.9468581112482215

Epoch: 5| Step: 1
Training loss: 1.1545332670211792
Validation loss: 1.9278186277676654

Epoch: 5| Step: 2
Training loss: 1.2968112230300903
Validation loss: 1.9142105041011688

Epoch: 5| Step: 3
Training loss: 1.241674780845642
Validation loss: 1.909139121732404

Epoch: 5| Step: 4
Training loss: 1.009361743927002
Validation loss: 1.892390686978576

Epoch: 5| Step: 5
Training loss: 1.254958152770996
Validation loss: 1.9125904806198613

Epoch: 5| Step: 6
Training loss: 1.1127327680587769
Validation loss: 1.9281318174895419

Epoch: 5| Step: 7
Training loss: 1.1951584815979004
Validation loss: 1.944067160288493

Epoch: 5| Step: 8
Training loss: 1.2329089641571045
Validation loss: 1.9237594719856017

Epoch: 5| Step: 9
Training loss: 1.6289207935333252
Validation loss: 1.9329296171024282

Epoch: 5| Step: 10
Training loss: 1.1972968578338623
Validation loss: 1.9210727214813232

Epoch: 357| Step: 0
Training loss: 1.544382095336914
Validation loss: 1.898401564167392

Epoch: 5| Step: 1
Training loss: 1.4631868600845337
Validation loss: 1.8690729128417147

Epoch: 5| Step: 2
Training loss: 0.9663224220275879
Validation loss: 1.888936654213936

Epoch: 5| Step: 3
Training loss: 1.0157486200332642
Validation loss: 1.8655682097199142

Epoch: 5| Step: 4
Training loss: 1.200418472290039
Validation loss: 1.8873500195882653

Epoch: 5| Step: 5
Training loss: 1.23259437084198
Validation loss: 1.8794230248338433

Epoch: 5| Step: 6
Training loss: 0.9095643758773804
Validation loss: 1.8906337522691297

Epoch: 5| Step: 7
Training loss: 1.8343989849090576
Validation loss: 1.9313327817506687

Epoch: 5| Step: 8
Training loss: 0.8928289413452148
Validation loss: 1.9349472445826377

Epoch: 5| Step: 9
Training loss: 0.941746711730957
Validation loss: 1.9592846260275891

Epoch: 5| Step: 10
Training loss: 1.6246310472488403
Validation loss: 1.9722274759764313

Epoch: 358| Step: 0
Training loss: 1.8401784896850586
Validation loss: 1.9646504796961302

Epoch: 5| Step: 1
Training loss: 1.3517416715621948
Validation loss: 1.941401671337825

Epoch: 5| Step: 2
Training loss: 0.9940937757492065
Validation loss: 1.937829980286219

Epoch: 5| Step: 3
Training loss: 0.9164921641349792
Validation loss: 1.940020461236277

Epoch: 5| Step: 4
Training loss: 1.0933256149291992
Validation loss: 1.9021953998073455

Epoch: 5| Step: 5
Training loss: 0.8998352885246277
Validation loss: 1.9115591920832151

Epoch: 5| Step: 6
Training loss: 1.3056707382202148
Validation loss: 1.9361509148792555

Epoch: 5| Step: 7
Training loss: 1.5300183296203613
Validation loss: 1.9754592910889657

Epoch: 5| Step: 8
Training loss: 1.3360083103179932
Validation loss: 1.9478686201956965

Epoch: 5| Step: 9
Training loss: 0.662775993347168
Validation loss: 1.9781070704101233

Epoch: 5| Step: 10
Training loss: 1.5982791185379028
Validation loss: 1.9779313302809192

Epoch: 359| Step: 0
Training loss: 1.2311674356460571
Validation loss: 1.9883414596639655

Epoch: 5| Step: 1
Training loss: 1.2675052881240845
Validation loss: 1.994702354554207

Epoch: 5| Step: 2
Training loss: 1.703477144241333
Validation loss: 1.9502474313141198

Epoch: 5| Step: 3
Training loss: 1.171654224395752
Validation loss: 1.9437739246635026

Epoch: 5| Step: 4
Training loss: 1.0438894033432007
Validation loss: 1.9487947007661224

Epoch: 5| Step: 5
Training loss: 1.0636107921600342
Validation loss: 1.9096601214460147

Epoch: 5| Step: 6
Training loss: 1.6279170513153076
Validation loss: 1.9234485446765859

Epoch: 5| Step: 7
Training loss: 1.5295906066894531
Validation loss: 1.9527457811499154

Epoch: 5| Step: 8
Training loss: 1.0739339590072632
Validation loss: 1.9275408842230355

Epoch: 5| Step: 9
Training loss: 1.1119378805160522
Validation loss: 1.9600401488683556

Epoch: 5| Step: 10
Training loss: 0.5725948810577393
Validation loss: 1.9632528853672806

Epoch: 360| Step: 0
Training loss: 0.8813117742538452
Validation loss: 1.9561229675046858

Epoch: 5| Step: 1
Training loss: 1.579885721206665
Validation loss: 1.9424516180510163

Epoch: 5| Step: 2
Training loss: 1.4792038202285767
Validation loss: 1.9009335117955362

Epoch: 5| Step: 3
Training loss: 1.4989399909973145
Validation loss: 1.8994869596214705

Epoch: 5| Step: 4
Training loss: 1.1099793910980225
Validation loss: 1.8616732128204838

Epoch: 5| Step: 5
Training loss: 1.3834047317504883
Validation loss: 1.8419567756755377

Epoch: 5| Step: 6
Training loss: 0.8801679611206055
Validation loss: 1.8599463842248405

Epoch: 5| Step: 7
Training loss: 1.6087315082550049
Validation loss: 1.87421235217843

Epoch: 5| Step: 8
Training loss: 0.9260245561599731
Validation loss: 1.8899207409992014

Epoch: 5| Step: 9
Training loss: 0.9014576077461243
Validation loss: 1.909096606316105

Epoch: 5| Step: 10
Training loss: 1.1578723192214966
Validation loss: 1.8963372553548505

Epoch: 361| Step: 0
Training loss: 0.9891588091850281
Validation loss: 1.9137156804402669

Epoch: 5| Step: 1
Training loss: 1.092077374458313
Validation loss: 1.9223303256496307

Epoch: 5| Step: 2
Training loss: 1.6410877704620361
Validation loss: 1.9400440223755375

Epoch: 5| Step: 3
Training loss: 1.3870728015899658
Validation loss: 1.9619159839486564

Epoch: 5| Step: 4
Training loss: 1.2060811519622803
Validation loss: 1.9739753533435125

Epoch: 5| Step: 5
Training loss: 1.1394109725952148
Validation loss: 1.964394764233661

Epoch: 5| Step: 6
Training loss: 1.236951231956482
Validation loss: 1.9713659927409182

Epoch: 5| Step: 7
Training loss: 0.7133423686027527
Validation loss: 1.9270656852311985

Epoch: 5| Step: 8
Training loss: 1.064025640487671
Validation loss: 1.8804694875594108

Epoch: 5| Step: 9
Training loss: 1.5600354671478271
Validation loss: 1.8682139099285167

Epoch: 5| Step: 10
Training loss: 1.144500732421875
Validation loss: 1.8599799345898371

Epoch: 362| Step: 0
Training loss: 1.1324608325958252
Validation loss: 1.8617439654565626

Epoch: 5| Step: 1
Training loss: 1.210140585899353
Validation loss: 1.8606694552206224

Epoch: 5| Step: 2
Training loss: 1.3679440021514893
Validation loss: 1.862929303158996

Epoch: 5| Step: 3
Training loss: 1.161388635635376
Validation loss: 1.8644856688796834

Epoch: 5| Step: 4
Training loss: 1.2286221981048584
Validation loss: 1.8815256998103151

Epoch: 5| Step: 5
Training loss: 0.9462475776672363
Validation loss: 1.9061092663836736

Epoch: 5| Step: 6
Training loss: 0.9771356582641602
Validation loss: 1.9241650758251068

Epoch: 5| Step: 7
Training loss: 1.2961275577545166
Validation loss: 1.9022350144642655

Epoch: 5| Step: 8
Training loss: 1.1790244579315186
Validation loss: 1.8862241788577008

Epoch: 5| Step: 9
Training loss: 1.1260396242141724
Validation loss: 1.8890699135359896

Epoch: 5| Step: 10
Training loss: 1.5718261003494263
Validation loss: 1.922045426983987

Epoch: 363| Step: 0
Training loss: 1.3046693801879883
Validation loss: 1.9282379919482815

Epoch: 5| Step: 1
Training loss: 0.7371851205825806
Validation loss: 1.9539545787278043

Epoch: 5| Step: 2
Training loss: 0.9063213467597961
Validation loss: 1.9370439642219133

Epoch: 5| Step: 3
Training loss: 0.8443233370780945
Validation loss: 1.938382774270991

Epoch: 5| Step: 4
Training loss: 0.9997803568840027
Validation loss: 1.8989007652446788

Epoch: 5| Step: 5
Training loss: 1.1057498455047607
Validation loss: 1.8847358162685106

Epoch: 5| Step: 6
Training loss: 1.1901614665985107
Validation loss: 1.8608518979882682

Epoch: 5| Step: 7
Training loss: 1.6900631189346313
Validation loss: 1.8661069869995117

Epoch: 5| Step: 8
Training loss: 1.2151062488555908
Validation loss: 1.8630790364357732

Epoch: 5| Step: 9
Training loss: 1.4594300985336304
Validation loss: 1.8630193689818024

Epoch: 5| Step: 10
Training loss: 1.5943856239318848
Validation loss: 1.8671247266953992

Epoch: 364| Step: 0
Training loss: 1.5616093873977661
Validation loss: 1.8536191242997364

Epoch: 5| Step: 1
Training loss: 0.7245597243309021
Validation loss: 1.8456159432729085

Epoch: 5| Step: 2
Training loss: 1.345470666885376
Validation loss: 1.865930426505304

Epoch: 5| Step: 3
Training loss: 1.2091405391693115
Validation loss: 1.90605253301641

Epoch: 5| Step: 4
Training loss: 1.1101653575897217
Validation loss: 1.899424422171808

Epoch: 5| Step: 5
Training loss: 0.9473546147346497
Validation loss: 1.9255077890170518

Epoch: 5| Step: 6
Training loss: 1.402477502822876
Validation loss: 1.882793713641423

Epoch: 5| Step: 7
Training loss: 0.9775686264038086
Validation loss: 1.8775757448647612

Epoch: 5| Step: 8
Training loss: 0.9265238046646118
Validation loss: 1.879843517016339

Epoch: 5| Step: 9
Training loss: 1.197729468345642
Validation loss: 1.8887769124841178

Epoch: 5| Step: 10
Training loss: 1.4662413597106934
Validation loss: 1.9003656416810968

Epoch: 365| Step: 0
Training loss: 1.2043324708938599
Validation loss: 1.8844315441705848

Epoch: 5| Step: 1
Training loss: 1.2045992612838745
Validation loss: 1.8921455490973689

Epoch: 5| Step: 2
Training loss: 0.7320130467414856
Validation loss: 1.8910238358282274

Epoch: 5| Step: 3
Training loss: 1.7004890441894531
Validation loss: 1.8634020743831512

Epoch: 5| Step: 4
Training loss: 1.059486746788025
Validation loss: 1.8827776960147324

Epoch: 5| Step: 5
Training loss: 1.0844532251358032
Validation loss: 1.8825938893902687

Epoch: 5| Step: 6
Training loss: 1.083467721939087
Validation loss: 1.8898399927282845

Epoch: 5| Step: 7
Training loss: 1.5886424779891968
Validation loss: 1.9236436659289944

Epoch: 5| Step: 8
Training loss: 0.9908183813095093
Validation loss: 1.9008371599258915

Epoch: 5| Step: 9
Training loss: 0.9231821894645691
Validation loss: 1.838705458948689

Epoch: 5| Step: 10
Training loss: 1.2620218992233276
Validation loss: 1.9070929647773824

Epoch: 366| Step: 0
Training loss: 1.068561315536499
Validation loss: 1.8964434592954573

Epoch: 5| Step: 1
Training loss: 1.1263411045074463
Validation loss: 1.8953509151294667

Epoch: 5| Step: 2
Training loss: 0.9574454426765442
Validation loss: 1.9051674860779957

Epoch: 5| Step: 3
Training loss: 0.8906511068344116
Validation loss: 1.924606168141929

Epoch: 5| Step: 4
Training loss: 1.5507988929748535
Validation loss: 1.9502037827686598

Epoch: 5| Step: 5
Training loss: 0.892780601978302
Validation loss: 1.9287719021561325

Epoch: 5| Step: 6
Training loss: 1.279722809791565
Validation loss: 1.88781996439862

Epoch: 5| Step: 7
Training loss: 1.0635933876037598
Validation loss: 1.8689389446730256

Epoch: 5| Step: 8
Training loss: 1.392552137374878
Validation loss: 1.8625622321200628

Epoch: 5| Step: 9
Training loss: 1.4846426248550415
Validation loss: 1.8584148217273015

Epoch: 5| Step: 10
Training loss: 1.0571619272232056
Validation loss: 1.8812529476740028

Epoch: 367| Step: 0
Training loss: 1.7238693237304688
Validation loss: 1.9179870467032156

Epoch: 5| Step: 1
Training loss: 0.9726337194442749
Validation loss: 1.932673615794028

Epoch: 5| Step: 2
Training loss: 1.4024078845977783
Validation loss: 1.988243966974238

Epoch: 5| Step: 3
Training loss: 1.0538784265518188
Validation loss: 1.9595654818319506

Epoch: 5| Step: 4
Training loss: 1.3278234004974365
Validation loss: 1.9730733876587243

Epoch: 5| Step: 5
Training loss: 1.169120192527771
Validation loss: 1.9725998473423783

Epoch: 5| Step: 6
Training loss: 0.8421314358711243
Validation loss: 1.9071775290273851

Epoch: 5| Step: 7
Training loss: 1.0946813821792603
Validation loss: 1.8793121563491

Epoch: 5| Step: 8
Training loss: 1.2703182697296143
Validation loss: 1.8844587982341807

Epoch: 5| Step: 9
Training loss: 0.9765043258666992
Validation loss: 1.9427904518701697

Epoch: 5| Step: 10
Training loss: 1.1340047121047974
Validation loss: 1.953524717720606

Epoch: 368| Step: 0
Training loss: 1.016061544418335
Validation loss: 1.9538894417465373

Epoch: 5| Step: 1
Training loss: 1.4313565492630005
Validation loss: 1.960997825027794

Epoch: 5| Step: 2
Training loss: 0.713159441947937
Validation loss: 2.010975524943362

Epoch: 5| Step: 3
Training loss: 1.4471954107284546
Validation loss: 2.025060090967404

Epoch: 5| Step: 4
Training loss: 1.6579405069351196
Validation loss: 2.006412552249047

Epoch: 5| Step: 5
Training loss: 1.1426122188568115
Validation loss: 2.002455572928152

Epoch: 5| Step: 6
Training loss: 1.2084672451019287
Validation loss: 1.966086636307419

Epoch: 5| Step: 7
Training loss: 1.35822594165802
Validation loss: 1.9282429205474032

Epoch: 5| Step: 8
Training loss: 1.0830256938934326
Validation loss: 1.90332725099338

Epoch: 5| Step: 9
Training loss: 0.576786994934082
Validation loss: 1.8825795753027803

Epoch: 5| Step: 10
Training loss: 0.9569175839424133
Validation loss: 1.8676871945781093

Epoch: 369| Step: 0
Training loss: 1.4110667705535889
Validation loss: 1.872661857194798

Epoch: 5| Step: 1
Training loss: 1.1727173328399658
Validation loss: 1.844598827823516

Epoch: 5| Step: 2
Training loss: 1.0218148231506348
Validation loss: 1.8597047495585617

Epoch: 5| Step: 3
Training loss: 1.23466956615448
Validation loss: 1.8729677738681916

Epoch: 5| Step: 4
Training loss: 0.986158013343811
Validation loss: 1.917793677058271

Epoch: 5| Step: 5
Training loss: 1.269243836402893
Validation loss: 1.9674714085876301

Epoch: 5| Step: 6
Training loss: 1.090700387954712
Validation loss: 1.9593307856590516

Epoch: 5| Step: 7
Training loss: 1.0768921375274658
Validation loss: 1.939610586371473

Epoch: 5| Step: 8
Training loss: 0.6487597227096558
Validation loss: 1.9079359244274836

Epoch: 5| Step: 9
Training loss: 1.2766339778900146
Validation loss: 1.8514623077966834

Epoch: 5| Step: 10
Training loss: 1.685712456703186
Validation loss: 1.8469482878203034

Epoch: 370| Step: 0
Training loss: 0.5423237085342407
Validation loss: 1.8219939739473405

Epoch: 5| Step: 1
Training loss: 1.6151063442230225
Validation loss: 1.8234449355832991

Epoch: 5| Step: 2
Training loss: 1.0447883605957031
Validation loss: 1.822938323020935

Epoch: 5| Step: 3
Training loss: 1.156886339187622
Validation loss: 1.846250440484734

Epoch: 5| Step: 4
Training loss: 1.189077615737915
Validation loss: 1.8866479819820774

Epoch: 5| Step: 5
Training loss: 0.8865984082221985
Validation loss: 1.9324184322869906

Epoch: 5| Step: 6
Training loss: 1.0688649415969849
Validation loss: 1.9415830078945364

Epoch: 5| Step: 7
Training loss: 1.5674121379852295
Validation loss: 1.9565550793883622

Epoch: 5| Step: 8
Training loss: 0.8779857754707336
Validation loss: 1.9365744821486934

Epoch: 5| Step: 9
Training loss: 1.3353395462036133
Validation loss: 1.92502551181342

Epoch: 5| Step: 10
Training loss: 1.462671160697937
Validation loss: 1.8827638600462226

Epoch: 371| Step: 0
Training loss: 0.7604461908340454
Validation loss: 1.8707046521607267

Epoch: 5| Step: 1
Training loss: 1.3106913566589355
Validation loss: 1.8540805347504155

Epoch: 5| Step: 2
Training loss: 1.1091448068618774
Validation loss: 1.8562668920845113

Epoch: 5| Step: 3
Training loss: 1.3913276195526123
Validation loss: 1.8768929819906912

Epoch: 5| Step: 4
Training loss: 0.9303520321846008
Validation loss: 1.9103172235591437

Epoch: 5| Step: 5
Training loss: 0.9814850091934204
Validation loss: 1.9497069030679681

Epoch: 5| Step: 6
Training loss: 1.4837439060211182
Validation loss: 2.007982985947722

Epoch: 5| Step: 7
Training loss: 0.9777296185493469
Validation loss: 1.9973333804838118

Epoch: 5| Step: 8
Training loss: 1.236535906791687
Validation loss: 1.9559894402821858

Epoch: 5| Step: 9
Training loss: 1.3325144052505493
Validation loss: 1.9248598262827883

Epoch: 5| Step: 10
Training loss: 1.1864979267120361
Validation loss: 1.859748137894497

Epoch: 372| Step: 0
Training loss: 1.1697630882263184
Validation loss: 1.8850637610240648

Epoch: 5| Step: 1
Training loss: 0.9395328760147095
Validation loss: 1.8600533367485128

Epoch: 5| Step: 2
Training loss: 1.1538110971450806
Validation loss: 1.857244631295563

Epoch: 5| Step: 3
Training loss: 1.4050897359848022
Validation loss: 1.8421610939887263

Epoch: 5| Step: 4
Training loss: 0.9895368814468384
Validation loss: 1.8348435394225582

Epoch: 5| Step: 5
Training loss: 1.0623843669891357
Validation loss: 1.865820138685165

Epoch: 5| Step: 6
Training loss: 1.3547037839889526
Validation loss: 1.8926078939950595

Epoch: 5| Step: 7
Training loss: 1.0484340190887451
Validation loss: 1.9333977660825175

Epoch: 5| Step: 8
Training loss: 1.3806434869766235
Validation loss: 1.9520686467488606

Epoch: 5| Step: 9
Training loss: 1.2085559368133545
Validation loss: 1.8645095299648982

Epoch: 5| Step: 10
Training loss: 0.885333776473999
Validation loss: 1.8724849070272138

Epoch: 373| Step: 0
Training loss: 0.7372338175773621
Validation loss: 1.8753256015880133

Epoch: 5| Step: 1
Training loss: 1.0252587795257568
Validation loss: 1.860311915797572

Epoch: 5| Step: 2
Training loss: 1.2315713167190552
Validation loss: 1.8711340196671025

Epoch: 5| Step: 3
Training loss: 1.1146965026855469
Validation loss: 1.9294900765983007

Epoch: 5| Step: 4
Training loss: 1.3214352130889893
Validation loss: 1.9031372493313206

Epoch: 5| Step: 5
Training loss: 1.029296636581421
Validation loss: 1.9164241744625954

Epoch: 5| Step: 6
Training loss: 1.4454114437103271
Validation loss: 1.9513615574888004

Epoch: 5| Step: 7
Training loss: 0.9976951479911804
Validation loss: 1.9433115067020539

Epoch: 5| Step: 8
Training loss: 1.1339530944824219
Validation loss: 1.940621824674709

Epoch: 5| Step: 9
Training loss: 1.1781752109527588
Validation loss: 1.9050686051768642

Epoch: 5| Step: 10
Training loss: 1.2255715131759644
Validation loss: 1.8606039029295727

Epoch: 374| Step: 0
Training loss: 0.8927985429763794
Validation loss: 1.8308562501784293

Epoch: 5| Step: 1
Training loss: 1.4413975477218628
Validation loss: 1.818676766528878

Epoch: 5| Step: 2
Training loss: 1.2820990085601807
Validation loss: 1.8043830394744873

Epoch: 5| Step: 3
Training loss: 1.1637436151504517
Validation loss: 1.8279626548931163

Epoch: 5| Step: 4
Training loss: 1.538010835647583
Validation loss: 1.811565460697297

Epoch: 5| Step: 5
Training loss: 0.6207032799720764
Validation loss: 1.8500009070160568

Epoch: 5| Step: 6
Training loss: 1.2192765474319458
Validation loss: 1.94224561414411

Epoch: 5| Step: 7
Training loss: 1.122477412223816
Validation loss: 1.954155711717503

Epoch: 5| Step: 8
Training loss: 1.0488148927688599
Validation loss: 1.995881906119726

Epoch: 5| Step: 9
Training loss: 1.334233045578003
Validation loss: 2.0041094505658714

Epoch: 5| Step: 10
Training loss: 1.069116234779358
Validation loss: 1.9691100171817246

Epoch: 375| Step: 0
Training loss: 1.154961109161377
Validation loss: 1.9161997174703946

Epoch: 5| Step: 1
Training loss: 0.8853359222412109
Validation loss: 1.8885437391137565

Epoch: 5| Step: 2
Training loss: 0.7957505583763123
Validation loss: 1.8741148453886791

Epoch: 5| Step: 3
Training loss: 1.267918348312378
Validation loss: 1.872639565057652

Epoch: 5| Step: 4
Training loss: 1.1584293842315674
Validation loss: 1.9123193487044303

Epoch: 5| Step: 5
Training loss: 1.3830431699752808
Validation loss: 1.9275472625609367

Epoch: 5| Step: 6
Training loss: 1.1483412981033325
Validation loss: 1.939438742976035

Epoch: 5| Step: 7
Training loss: 1.0950369834899902
Validation loss: 1.9424829841941915

Epoch: 5| Step: 8
Training loss: 0.6176444292068481
Validation loss: 1.928297915766316

Epoch: 5| Step: 9
Training loss: 1.4492088556289673
Validation loss: 1.889526553051446

Epoch: 5| Step: 10
Training loss: 1.6475481986999512
Validation loss: 1.898466411457267

Epoch: 376| Step: 0
Training loss: 1.0091818571090698
Validation loss: 1.9079557759787447

Epoch: 5| Step: 1
Training loss: 1.1566407680511475
Validation loss: 1.8791395618069557

Epoch: 5| Step: 2
Training loss: 1.1054785251617432
Validation loss: 1.8836110227851457

Epoch: 5| Step: 3
Training loss: 0.7338898777961731
Validation loss: 1.8496902219710811

Epoch: 5| Step: 4
Training loss: 1.0377357006072998
Validation loss: 1.8613650414251512

Epoch: 5| Step: 5
Training loss: 1.1009161472320557
Validation loss: 1.8607136049578268

Epoch: 5| Step: 6
Training loss: 1.215898871421814
Validation loss: 1.8759911649970598

Epoch: 5| Step: 7
Training loss: 1.5834277868270874
Validation loss: 1.864970322578184

Epoch: 5| Step: 8
Training loss: 0.9788042306900024
Validation loss: 1.9056406508209884

Epoch: 5| Step: 9
Training loss: 1.1622248888015747
Validation loss: 1.8866771408306655

Epoch: 5| Step: 10
Training loss: 1.2041945457458496
Validation loss: 1.898913045083323

Epoch: 377| Step: 0
Training loss: 1.391688585281372
Validation loss: 1.89603058497111

Epoch: 5| Step: 1
Training loss: 1.0248494148254395
Validation loss: 1.908289663253292

Epoch: 5| Step: 2
Training loss: 1.1346808671951294
Validation loss: 1.8932309240423224

Epoch: 5| Step: 3
Training loss: 1.3309391736984253
Validation loss: 1.8695382161806988

Epoch: 5| Step: 4
Training loss: 1.2632049322128296
Validation loss: 1.881495967988045

Epoch: 5| Step: 5
Training loss: 1.2288786172866821
Validation loss: 1.8464091183036886

Epoch: 5| Step: 6
Training loss: 0.9284502267837524
Validation loss: 1.8486837315303024

Epoch: 5| Step: 7
Training loss: 1.1272404193878174
Validation loss: 1.851330122640056

Epoch: 5| Step: 8
Training loss: 1.2093846797943115
Validation loss: 1.8408793198165072

Epoch: 5| Step: 9
Training loss: 0.9331477880477905
Validation loss: 1.8730454214157597

Epoch: 5| Step: 10
Training loss: 0.6212815642356873
Validation loss: 1.878843125476632

Epoch: 378| Step: 0
Training loss: 1.1634199619293213
Validation loss: 1.8683843228124803

Epoch: 5| Step: 1
Training loss: 0.8588457107543945
Validation loss: 1.8622962454313874

Epoch: 5| Step: 2
Training loss: 1.2838225364685059
Validation loss: 1.856724985184208

Epoch: 5| Step: 3
Training loss: 1.0839567184448242
Validation loss: 1.8524129800899054

Epoch: 5| Step: 4
Training loss: 1.3475836515426636
Validation loss: 1.8658307072936848

Epoch: 5| Step: 5
Training loss: 0.7287996411323547
Validation loss: 1.843689376308072

Epoch: 5| Step: 6
Training loss: 1.2156645059585571
Validation loss: 1.8143793844407605

Epoch: 5| Step: 7
Training loss: 1.400750756263733
Validation loss: 1.8512840232541483

Epoch: 5| Step: 8
Training loss: 0.9620438814163208
Validation loss: 1.8776466820829658

Epoch: 5| Step: 9
Training loss: 1.3144593238830566
Validation loss: 1.8948356406663054

Epoch: 5| Step: 10
Training loss: 1.1755990982055664
Validation loss: 1.9556512717277772

Epoch: 379| Step: 0
Training loss: 0.9078261256217957
Validation loss: 1.9117118825194657

Epoch: 5| Step: 1
Training loss: 1.319894552230835
Validation loss: 1.8644599888914375

Epoch: 5| Step: 2
Training loss: 1.1242724657058716
Validation loss: 1.8708135748422274

Epoch: 5| Step: 3
Training loss: 1.0013070106506348
Validation loss: 1.8410911918968282

Epoch: 5| Step: 4
Training loss: 1.3528480529785156
Validation loss: 1.8148190847007177

Epoch: 5| Step: 5
Training loss: 1.1216518878936768
Validation loss: 1.7819832294218

Epoch: 5| Step: 6
Training loss: 1.0487697124481201
Validation loss: 1.7995647768820486

Epoch: 5| Step: 7
Training loss: 0.91570645570755
Validation loss: 1.8655850810389365

Epoch: 5| Step: 8
Training loss: 1.6431834697723389
Validation loss: 1.8931077141915598

Epoch: 5| Step: 9
Training loss: 1.020231008529663
Validation loss: 1.9585857506721251

Epoch: 5| Step: 10
Training loss: 0.8170421123504639
Validation loss: 1.9708724919185843

Epoch: 380| Step: 0
Training loss: 1.0497171878814697
Validation loss: 1.9690344666921964

Epoch: 5| Step: 1
Training loss: 0.9811557531356812
Validation loss: 1.9546934507226432

Epoch: 5| Step: 2
Training loss: 1.4385889768600464
Validation loss: 1.9288481871287029

Epoch: 5| Step: 3
Training loss: 1.363799810409546
Validation loss: 1.9101899541834348

Epoch: 5| Step: 4
Training loss: 1.093677282333374
Validation loss: 1.9070121370336062

Epoch: 5| Step: 5
Training loss: 1.0031594038009644
Validation loss: 1.8702449516583515

Epoch: 5| Step: 6
Training loss: 1.3416492938995361
Validation loss: 1.8410267291530487

Epoch: 5| Step: 7
Training loss: 0.6329723596572876
Validation loss: 1.8277063715842463

Epoch: 5| Step: 8
Training loss: 1.3603965044021606
Validation loss: 1.8421530736389982

Epoch: 5| Step: 9
Training loss: 0.7388888597488403
Validation loss: 1.8303974469502766

Epoch: 5| Step: 10
Training loss: 1.2086548805236816
Validation loss: 1.8529629515063377

Epoch: 381| Step: 0
Training loss: 1.1739332675933838
Validation loss: 1.8875479211089432

Epoch: 5| Step: 1
Training loss: 1.2533419132232666
Validation loss: 1.9155885429792507

Epoch: 5| Step: 2
Training loss: 1.1731007099151611
Validation loss: 1.9139004010026173

Epoch: 5| Step: 3
Training loss: 0.921960175037384
Validation loss: 1.8969540724190332

Epoch: 5| Step: 4
Training loss: 1.4068787097930908
Validation loss: 1.9217901614404493

Epoch: 5| Step: 5
Training loss: 0.9092541933059692
Validation loss: 1.8928997132085985

Epoch: 5| Step: 6
Training loss: 0.712537944316864
Validation loss: 1.9390524330959524

Epoch: 5| Step: 7
Training loss: 0.9981206655502319
Validation loss: 1.9492128177355694

Epoch: 5| Step: 8
Training loss: 1.0943368673324585
Validation loss: 1.9214579546323387

Epoch: 5| Step: 9
Training loss: 1.2456414699554443
Validation loss: 1.9253463360571093

Epoch: 5| Step: 10
Training loss: 1.0950498580932617
Validation loss: 1.8811210983542985

Epoch: 382| Step: 0
Training loss: 0.831236720085144
Validation loss: 1.859518447229939

Epoch: 5| Step: 1
Training loss: 1.105318546295166
Validation loss: 1.8418945881628221

Epoch: 5| Step: 2
Training loss: 1.6878433227539062
Validation loss: 1.8580716502281927

Epoch: 5| Step: 3
Training loss: 0.8024286031723022
Validation loss: 1.8924416303634644

Epoch: 5| Step: 4
Training loss: 1.46384596824646
Validation loss: 1.887238247420198

Epoch: 5| Step: 5
Training loss: 0.9341405630111694
Validation loss: 1.8848063253587293

Epoch: 5| Step: 6
Training loss: 0.9268831014633179
Validation loss: 1.9101903669295772

Epoch: 5| Step: 7
Training loss: 1.3603465557098389
Validation loss: 1.9332842967843498

Epoch: 5| Step: 8
Training loss: 1.203580617904663
Validation loss: 1.8693821853207004

Epoch: 5| Step: 9
Training loss: 0.8412289619445801
Validation loss: 1.854701506194248

Epoch: 5| Step: 10
Training loss: 0.7064557075500488
Validation loss: 1.8648277123769124

Epoch: 383| Step: 0
Training loss: 1.2181891202926636
Validation loss: 1.8774487459531395

Epoch: 5| Step: 1
Training loss: 1.0661406517028809
Validation loss: 1.921039463371359

Epoch: 5| Step: 2
Training loss: 1.0029354095458984
Validation loss: 1.9370115636497416

Epoch: 5| Step: 3
Training loss: 1.0508261919021606
Validation loss: 1.9181917867352885

Epoch: 5| Step: 4
Training loss: 0.44517287611961365
Validation loss: 1.9431674121528544

Epoch: 5| Step: 5
Training loss: 0.8254812955856323
Validation loss: 1.9723312726584814

Epoch: 5| Step: 6
Training loss: 1.4753978252410889
Validation loss: 1.9627802987252512

Epoch: 5| Step: 7
Training loss: 1.3477269411087036
Validation loss: 1.9604031975551317

Epoch: 5| Step: 8
Training loss: 1.1821272373199463
Validation loss: 1.9283849680295555

Epoch: 5| Step: 9
Training loss: 1.365290880203247
Validation loss: 1.9082723676517446

Epoch: 5| Step: 10
Training loss: 1.0793977975845337
Validation loss: 1.8942456014694706

Epoch: 384| Step: 0
Training loss: 1.0738482475280762
Validation loss: 1.8902952824869463

Epoch: 5| Step: 1
Training loss: 0.9221323728561401
Validation loss: 1.8782728461809055

Epoch: 5| Step: 2
Training loss: 1.6888856887817383
Validation loss: 1.8663577059263825

Epoch: 5| Step: 3
Training loss: 0.8889150619506836
Validation loss: 1.8264590258239417

Epoch: 5| Step: 4
Training loss: 1.2188842296600342
Validation loss: 1.8642031338907057

Epoch: 5| Step: 5
Training loss: 1.2209413051605225
Validation loss: 1.8436833863617272

Epoch: 5| Step: 6
Training loss: 0.9078262448310852
Validation loss: 1.8508810099735056

Epoch: 5| Step: 7
Training loss: 1.0587130784988403
Validation loss: 1.872797748093964

Epoch: 5| Step: 8
Training loss: 1.4294407367706299
Validation loss: 1.8654051339754494

Epoch: 5| Step: 9
Training loss: 0.8718680143356323
Validation loss: 1.868158741663861

Epoch: 5| Step: 10
Training loss: 0.6921371221542358
Validation loss: 1.8733185375890424

Epoch: 385| Step: 0
Training loss: 0.48332929611206055
Validation loss: 1.8885622767991916

Epoch: 5| Step: 1
Training loss: 1.4983670711517334
Validation loss: 1.923315462245736

Epoch: 5| Step: 2
Training loss: 0.9936931729316711
Validation loss: 1.9262738599572131

Epoch: 5| Step: 3
Training loss: 1.1562728881835938
Validation loss: 1.9226557259918542

Epoch: 5| Step: 4
Training loss: 1.0579345226287842
Validation loss: 1.90669096157115

Epoch: 5| Step: 5
Training loss: 1.3946540355682373
Validation loss: 1.8866610860311857

Epoch: 5| Step: 6
Training loss: 1.6236079931259155
Validation loss: 1.8933485143928117

Epoch: 5| Step: 7
Training loss: 0.9395675659179688
Validation loss: 1.9004327981702742

Epoch: 5| Step: 8
Training loss: 1.1518313884735107
Validation loss: 1.945099671681722

Epoch: 5| Step: 9
Training loss: 0.6062508821487427
Validation loss: 1.9579136756158644

Epoch: 5| Step: 10
Training loss: 1.003942608833313
Validation loss: 1.9399764204537997

Epoch: 386| Step: 0
Training loss: 0.9851354360580444
Validation loss: 1.9332840263202626

Epoch: 5| Step: 1
Training loss: 0.7824673056602478
Validation loss: 1.9164129931439635

Epoch: 5| Step: 2
Training loss: 1.438840627670288
Validation loss: 1.9019451551539923

Epoch: 5| Step: 3
Training loss: 1.244922161102295
Validation loss: 1.8858367448212

Epoch: 5| Step: 4
Training loss: 0.6138578653335571
Validation loss: 1.869069799300163

Epoch: 5| Step: 5
Training loss: 0.9180811643600464
Validation loss: 1.8777175744374592

Epoch: 5| Step: 6
Training loss: 1.0582187175750732
Validation loss: 1.886512210292201

Epoch: 5| Step: 7
Training loss: 1.3211904764175415
Validation loss: 1.8728100369053502

Epoch: 5| Step: 8
Training loss: 0.8316795229911804
Validation loss: 1.9008937484474593

Epoch: 5| Step: 9
Training loss: 1.2655627727508545
Validation loss: 1.9127346264418734

Epoch: 5| Step: 10
Training loss: 1.3963145017623901
Validation loss: 1.9451026865231094

Epoch: 387| Step: 0
Training loss: 0.7172335982322693
Validation loss: 1.8993653097460348

Epoch: 5| Step: 1
Training loss: 0.9202978014945984
Validation loss: 1.8941292096209783

Epoch: 5| Step: 2
Training loss: 1.5243780612945557
Validation loss: 1.8749018805001372

Epoch: 5| Step: 3
Training loss: 0.7566095590591431
Validation loss: 1.8737453286365797

Epoch: 5| Step: 4
Training loss: 1.0147846937179565
Validation loss: 1.8351381568498508

Epoch: 5| Step: 5
Training loss: 1.0805987119674683
Validation loss: 1.8320361183535667

Epoch: 5| Step: 6
Training loss: 1.1386319398880005
Validation loss: 1.8158429373977005

Epoch: 5| Step: 7
Training loss: 1.3799574375152588
Validation loss: 1.8275494511409471

Epoch: 5| Step: 8
Training loss: 1.23329758644104
Validation loss: 1.835364431463262

Epoch: 5| Step: 9
Training loss: 0.619963526725769
Validation loss: 1.8430737859459334

Epoch: 5| Step: 10
Training loss: 1.5156663656234741
Validation loss: 1.9354111097192253

Epoch: 388| Step: 0
Training loss: 0.8145173192024231
Validation loss: 1.9597915731450564

Epoch: 5| Step: 1
Training loss: 1.1124942302703857
Validation loss: 1.987497386112008

Epoch: 5| Step: 2
Training loss: 1.0618404150009155
Validation loss: 1.9897940620299308

Epoch: 5| Step: 3
Training loss: 0.9857217073440552
Validation loss: 1.9677911855841195

Epoch: 5| Step: 4
Training loss: 1.2563797235488892
Validation loss: 1.9194937188138244

Epoch: 5| Step: 5
Training loss: 0.8782588839530945
Validation loss: 1.830209373145975

Epoch: 5| Step: 6
Training loss: 1.069428563117981
Validation loss: 1.8163482143032936

Epoch: 5| Step: 7
Training loss: 0.8479464650154114
Validation loss: 1.8179177994369178

Epoch: 5| Step: 8
Training loss: 1.4893310070037842
Validation loss: 1.832689449351321

Epoch: 5| Step: 9
Training loss: 1.232891321182251
Validation loss: 1.862303267243088

Epoch: 5| Step: 10
Training loss: 1.132974624633789
Validation loss: 1.8664484241957306

Epoch: 389| Step: 0
Training loss: 1.0768392086029053
Validation loss: 1.8959430212615638

Epoch: 5| Step: 1
Training loss: 0.7519766092300415
Validation loss: 1.9090344277761315

Epoch: 5| Step: 2
Training loss: 1.2547770738601685
Validation loss: 1.8974377596250145

Epoch: 5| Step: 3
Training loss: 1.3936020135879517
Validation loss: 1.9396047387071835

Epoch: 5| Step: 4
Training loss: 0.9998655319213867
Validation loss: 1.9035815320989138

Epoch: 5| Step: 5
Training loss: 0.7699644565582275
Validation loss: 1.8934108826421923

Epoch: 5| Step: 6
Training loss: 1.2309174537658691
Validation loss: 1.8639745994280743

Epoch: 5| Step: 7
Training loss: 1.0415728092193604
Validation loss: 1.8513024391666535

Epoch: 5| Step: 8
Training loss: 0.49220532178878784
Validation loss: 1.837487095145769

Epoch: 5| Step: 9
Training loss: 1.244316816329956
Validation loss: 1.8196218731582805

Epoch: 5| Step: 10
Training loss: 1.4610192775726318
Validation loss: 1.851304566988381

Epoch: 390| Step: 0
Training loss: 1.0798882246017456
Validation loss: 1.8524690481924242

Epoch: 5| Step: 1
Training loss: 0.9868294596672058
Validation loss: 1.8452648706333612

Epoch: 5| Step: 2
Training loss: 0.9973639249801636
Validation loss: 1.8441978372553343

Epoch: 5| Step: 3
Training loss: 1.46371328830719
Validation loss: 1.8743824753710019

Epoch: 5| Step: 4
Training loss: 0.6192845106124878
Validation loss: 1.8843971516496392

Epoch: 5| Step: 5
Training loss: 1.0452951192855835
Validation loss: 1.874243140220642

Epoch: 5| Step: 6
Training loss: 1.3184278011322021
Validation loss: 1.873381099393291

Epoch: 5| Step: 7
Training loss: 1.0195585489273071
Validation loss: 1.8352310439591766

Epoch: 5| Step: 8
Training loss: 1.108018398284912
Validation loss: 1.8300045613319642

Epoch: 5| Step: 9
Training loss: 0.7372170090675354
Validation loss: 1.8281894447982951

Epoch: 5| Step: 10
Training loss: 1.320509672164917
Validation loss: 1.8186298416506859

Epoch: 391| Step: 0
Training loss: 1.3591864109039307
Validation loss: 1.8205214533754575

Epoch: 5| Step: 1
Training loss: 1.1682054996490479
Validation loss: 1.84560788062311

Epoch: 5| Step: 2
Training loss: 0.667929470539093
Validation loss: 1.8253223780662782

Epoch: 5| Step: 3
Training loss: 1.2438057661056519
Validation loss: 1.8135830458774362

Epoch: 5| Step: 4
Training loss: 1.5612140893936157
Validation loss: 1.855984672423332

Epoch: 5| Step: 5
Training loss: 0.6365236639976501
Validation loss: 1.8625451018733363

Epoch: 5| Step: 6
Training loss: 1.1407966613769531
Validation loss: 1.9068057729351906

Epoch: 5| Step: 7
Training loss: 0.8416193723678589
Validation loss: 1.9051837600687498

Epoch: 5| Step: 8
Training loss: 0.9770445823669434
Validation loss: 1.8772045284189203

Epoch: 5| Step: 9
Training loss: 0.9913463592529297
Validation loss: 1.8708011745124735

Epoch: 5| Step: 10
Training loss: 1.1026904582977295
Validation loss: 1.8943457385545135

Epoch: 392| Step: 0
Training loss: 0.7384973168373108
Validation loss: 1.8603496551513672

Epoch: 5| Step: 1
Training loss: 0.7984260320663452
Validation loss: 1.827341797531292

Epoch: 5| Step: 2
Training loss: 1.3611377477645874
Validation loss: 1.7734092358619935

Epoch: 5| Step: 3
Training loss: 1.106891393661499
Validation loss: 1.8129290989650193

Epoch: 5| Step: 4
Training loss: 0.8384718894958496
Validation loss: 1.8462059318378408

Epoch: 5| Step: 5
Training loss: 1.1998980045318604
Validation loss: 1.8561523909209876

Epoch: 5| Step: 6
Training loss: 0.9720426797866821
Validation loss: 1.8863737121705086

Epoch: 5| Step: 7
Training loss: 1.3275649547576904
Validation loss: 1.8555321821602442

Epoch: 5| Step: 8
Training loss: 1.4730604887008667
Validation loss: 1.9207186852732012

Epoch: 5| Step: 9
Training loss: 0.9197268486022949
Validation loss: 1.9608989069538731

Epoch: 5| Step: 10
Training loss: 0.9640266299247742
Validation loss: 1.9350417865219938

Epoch: 393| Step: 0
Training loss: 1.0553622245788574
Validation loss: 1.9343066971789125

Epoch: 5| Step: 1
Training loss: 1.5366697311401367
Validation loss: 1.9112923965659192

Epoch: 5| Step: 2
Training loss: 1.20241117477417
Validation loss: 1.8780432695983558

Epoch: 5| Step: 3
Training loss: 1.0918267965316772
Validation loss: 1.8381484016295402

Epoch: 5| Step: 4
Training loss: 0.7205427289009094
Validation loss: 1.8468642337347871

Epoch: 5| Step: 5
Training loss: 0.8985228538513184
Validation loss: 1.8105622260801253

Epoch: 5| Step: 6
Training loss: 0.8283683657646179
Validation loss: 1.793507545225082

Epoch: 5| Step: 7
Training loss: 0.702083945274353
Validation loss: 1.8329252453260525

Epoch: 5| Step: 8
Training loss: 1.0408021211624146
Validation loss: 1.8647501763477121

Epoch: 5| Step: 9
Training loss: 1.3007078170776367
Validation loss: 1.9202735975224485

Epoch: 5| Step: 10
Training loss: 1.2399038076400757
Validation loss: 1.961526829709289

Epoch: 394| Step: 0
Training loss: 1.1875174045562744
Validation loss: 1.9334077206991052

Epoch: 5| Step: 1
Training loss: 1.5610346794128418
Validation loss: 1.905401369576813

Epoch: 5| Step: 2
Training loss: 0.8022292852401733
Validation loss: 1.9205106176355833

Epoch: 5| Step: 3
Training loss: 1.1723161935806274
Validation loss: 1.867495531676918

Epoch: 5| Step: 4
Training loss: 0.7098474502563477
Validation loss: 1.857346950038787

Epoch: 5| Step: 5
Training loss: 1.0022560358047485
Validation loss: 1.8645387529045023

Epoch: 5| Step: 6
Training loss: 0.9455621838569641
Validation loss: 1.828933600456484

Epoch: 5| Step: 7
Training loss: 1.0121972560882568
Validation loss: 1.8649219287339078

Epoch: 5| Step: 8
Training loss: 1.41081964969635
Validation loss: 1.8348762527588875

Epoch: 5| Step: 9
Training loss: 0.7085794806480408
Validation loss: 1.852650309121737

Epoch: 5| Step: 10
Training loss: 1.1176475286483765
Validation loss: 1.8566478324192826

Epoch: 395| Step: 0
Training loss: 0.8482591509819031
Validation loss: 1.8723451527216102

Epoch: 5| Step: 1
Training loss: 1.156662940979004
Validation loss: 1.8887376490459646

Epoch: 5| Step: 2
Training loss: 1.7819608449935913
Validation loss: 1.847627466724765

Epoch: 5| Step: 3
Training loss: 0.8925085067749023
Validation loss: 1.819241282760456

Epoch: 5| Step: 4
Training loss: 0.866761326789856
Validation loss: 1.8176344094737884

Epoch: 5| Step: 5
Training loss: 0.4111558496952057
Validation loss: 1.8246351877848308

Epoch: 5| Step: 6
Training loss: 1.4558767080307007
Validation loss: 1.7978699002214658

Epoch: 5| Step: 7
Training loss: 0.9084736704826355
Validation loss: 1.810359465178623

Epoch: 5| Step: 8
Training loss: 0.8019221425056458
Validation loss: 1.8284451089879519

Epoch: 5| Step: 9
Training loss: 1.2295305728912354
Validation loss: 1.8200047028962003

Epoch: 5| Step: 10
Training loss: 1.007909893989563
Validation loss: 1.8247790048199315

Epoch: 396| Step: 0
Training loss: 1.1825587749481201
Validation loss: 1.8550031377423195

Epoch: 5| Step: 1
Training loss: 0.8110638856887817
Validation loss: 1.8384483219474874

Epoch: 5| Step: 2
Training loss: 0.9423635601997375
Validation loss: 1.8316521516410254

Epoch: 5| Step: 3
Training loss: 0.8584089279174805
Validation loss: 1.8851873182481336

Epoch: 5| Step: 4
Training loss: 1.146967887878418
Validation loss: 1.9465046646774455

Epoch: 5| Step: 5
Training loss: 1.2008812427520752
Validation loss: 1.9082745134189565

Epoch: 5| Step: 6
Training loss: 0.9748546481132507
Validation loss: 1.8893755635907572

Epoch: 5| Step: 7
Training loss: 0.7635719180107117
Validation loss: 1.821590321038359

Epoch: 5| Step: 8
Training loss: 1.2650272846221924
Validation loss: 1.7817953055904758

Epoch: 5| Step: 9
Training loss: 1.338768720626831
Validation loss: 1.7887854729929278

Epoch: 5| Step: 10
Training loss: 1.222200632095337
Validation loss: 1.7860082323833177

Epoch: 397| Step: 0
Training loss: 0.5101562738418579
Validation loss: 1.755691143774217

Epoch: 5| Step: 1
Training loss: 0.49028950929641724
Validation loss: 1.8083889087041218

Epoch: 5| Step: 2
Training loss: 0.6330984234809875
Validation loss: 1.7987889820529568

Epoch: 5| Step: 3
Training loss: 1.0402127504348755
Validation loss: 1.8642232071968816

Epoch: 5| Step: 4
Training loss: 0.9442201852798462
Validation loss: 1.9096658960465462

Epoch: 5| Step: 5
Training loss: 1.7255970239639282
Validation loss: 2.01273089326838

Epoch: 5| Step: 6
Training loss: 1.6272770166397095
Validation loss: 2.0579799759772515

Epoch: 5| Step: 7
Training loss: 1.0162302255630493
Validation loss: 2.0263846407654467

Epoch: 5| Step: 8
Training loss: 1.1799638271331787
Validation loss: 1.9841572161643737

Epoch: 5| Step: 9
Training loss: 1.2331264019012451
Validation loss: 1.9353882189719909

Epoch: 5| Step: 10
Training loss: 1.2992582321166992
Validation loss: 1.8782066568251579

Epoch: 398| Step: 0
Training loss: 0.8382309079170227
Validation loss: 1.8448920044847714

Epoch: 5| Step: 1
Training loss: 0.9491952657699585
Validation loss: 1.8409479933400308

Epoch: 5| Step: 2
Training loss: 0.9262550473213196
Validation loss: 1.8017494204223796

Epoch: 5| Step: 3
Training loss: 1.19381844997406
Validation loss: 1.7879384871452086

Epoch: 5| Step: 4
Training loss: 0.9536906480789185
Validation loss: 1.8170186447840866

Epoch: 5| Step: 5
Training loss: 0.9142972826957703
Validation loss: 1.8609435404500654

Epoch: 5| Step: 6
Training loss: 0.7238378524780273
Validation loss: 1.8676870305051085

Epoch: 5| Step: 7
Training loss: 1.7292112112045288
Validation loss: 1.932724214369251

Epoch: 5| Step: 8
Training loss: 0.8988540768623352
Validation loss: 1.9600188078418854

Epoch: 5| Step: 9
Training loss: 1.3999979496002197
Validation loss: 1.9678176679918844

Epoch: 5| Step: 10
Training loss: 1.1078147888183594
Validation loss: 1.9258153079658427

Epoch: 399| Step: 0
Training loss: 0.9390482902526855
Validation loss: 1.8739513581798923

Epoch: 5| Step: 1
Training loss: 1.1365878582000732
Validation loss: 1.872184484235702

Epoch: 5| Step: 2
Training loss: 0.9304041862487793
Validation loss: 1.8771736237310594

Epoch: 5| Step: 3
Training loss: 1.1941646337509155
Validation loss: 1.860653615766956

Epoch: 5| Step: 4
Training loss: 1.2354140281677246
Validation loss: 1.8621992321424587

Epoch: 5| Step: 5
Training loss: 0.9726794362068176
Validation loss: 1.876682267394117

Epoch: 5| Step: 6
Training loss: 0.6764602065086365
Validation loss: 1.9099411772143455

Epoch: 5| Step: 7
Training loss: 0.8887141942977905
Validation loss: 1.899042158998469

Epoch: 5| Step: 8
Training loss: 0.9160153269767761
Validation loss: 1.890716819353001

Epoch: 5| Step: 9
Training loss: 1.4371932744979858
Validation loss: 1.9001707235972087

Epoch: 5| Step: 10
Training loss: 1.0280659198760986
Validation loss: 1.9104068663812452

Epoch: 400| Step: 0
Training loss: 1.2885797023773193
Validation loss: 1.9087897436593169

Epoch: 5| Step: 1
Training loss: 1.3871020078659058
Validation loss: 1.9011866687446513

Epoch: 5| Step: 2
Training loss: 1.074786901473999
Validation loss: 1.8172419007106493

Epoch: 5| Step: 3
Training loss: 0.8643592596054077
Validation loss: 1.7892921432372062

Epoch: 5| Step: 4
Training loss: 1.3118927478790283
Validation loss: 1.7763181258273382

Epoch: 5| Step: 5
Training loss: 0.8954682350158691
Validation loss: 1.7644690006009993

Epoch: 5| Step: 6
Training loss: 1.2092409133911133
Validation loss: 1.774690927997712

Epoch: 5| Step: 7
Training loss: 0.5756329298019409
Validation loss: 1.79112648066654

Epoch: 5| Step: 8
Training loss: 0.8063310384750366
Validation loss: 1.823390027528168

Epoch: 5| Step: 9
Training loss: 1.035370945930481
Validation loss: 1.8925854390667332

Epoch: 5| Step: 10
Training loss: 0.8580591678619385
Validation loss: 1.9390555504829652

Epoch: 401| Step: 0
Training loss: 0.9401324987411499
Validation loss: 1.908538503031577

Epoch: 5| Step: 1
Training loss: 1.4901598691940308
Validation loss: 1.90767252573403

Epoch: 5| Step: 2
Training loss: 1.15315842628479
Validation loss: 1.8546396481093539

Epoch: 5| Step: 3
Training loss: 0.5705631375312805
Validation loss: 1.8426928366384199

Epoch: 5| Step: 4
Training loss: 1.0911115407943726
Validation loss: 1.8214507449057795

Epoch: 5| Step: 5
Training loss: 0.7087772488594055
Validation loss: 1.779058684584915

Epoch: 5| Step: 6
Training loss: 0.8259499669075012
Validation loss: 1.7855446697563253

Epoch: 5| Step: 7
Training loss: 1.057347059249878
Validation loss: 1.7922278604199808

Epoch: 5| Step: 8
Training loss: 1.4195154905319214
Validation loss: 1.8204701754354662

Epoch: 5| Step: 9
Training loss: 1.1139013767242432
Validation loss: 1.8657077666251891

Epoch: 5| Step: 10
Training loss: 1.180128812789917
Validation loss: 1.8875310792717883

Epoch: 402| Step: 0
Training loss: 1.085447072982788
Validation loss: 1.8878043159361808

Epoch: 5| Step: 1
Training loss: 0.9257791638374329
Validation loss: 1.8777566686753304

Epoch: 5| Step: 2
Training loss: 0.9536809921264648
Validation loss: 1.878984897367416

Epoch: 5| Step: 3
Training loss: 1.1409515142440796
Validation loss: 1.861197861292029

Epoch: 5| Step: 4
Training loss: 1.1449658870697021
Validation loss: 1.824145972087819

Epoch: 5| Step: 5
Training loss: 1.161220908164978
Validation loss: 1.793867031733195

Epoch: 5| Step: 6
Training loss: 1.1004245281219482
Validation loss: 1.7836095940682195

Epoch: 5| Step: 7
Training loss: 0.9890758395195007
Validation loss: 1.7937574924961213

Epoch: 5| Step: 8
Training loss: 1.1971591711044312
Validation loss: 1.8019343858124108

Epoch: 5| Step: 9
Training loss: 0.6061748266220093
Validation loss: 1.7930037885583856

Epoch: 5| Step: 10
Training loss: 0.7972068190574646
Validation loss: 1.8344671021225631

Epoch: 403| Step: 0
Training loss: 0.9422712326049805
Validation loss: 1.8441462837239748

Epoch: 5| Step: 1
Training loss: 0.9259175062179565
Validation loss: 1.8633348326529227

Epoch: 5| Step: 2
Training loss: 0.7501339912414551
Validation loss: 1.9118164559846282

Epoch: 5| Step: 3
Training loss: 1.166444182395935
Validation loss: 1.8816687663396199

Epoch: 5| Step: 4
Training loss: 1.2512441873550415
Validation loss: 1.8623178594855851

Epoch: 5| Step: 5
Training loss: 0.8997277021408081
Validation loss: 1.872913868196549

Epoch: 5| Step: 6
Training loss: 1.4926176071166992
Validation loss: 1.8594736540189354

Epoch: 5| Step: 7
Training loss: 1.1290136575698853
Validation loss: 1.8612907958287064

Epoch: 5| Step: 8
Training loss: 1.0107377767562866
Validation loss: 1.8440813710612636

Epoch: 5| Step: 9
Training loss: 0.8730146288871765
Validation loss: 1.852391348090223

Epoch: 5| Step: 10
Training loss: 0.6482612490653992
Validation loss: 1.8241682385885587

Epoch: 404| Step: 0
Training loss: 1.0843405723571777
Validation loss: 1.813194631248392

Epoch: 5| Step: 1
Training loss: 1.2758926153182983
Validation loss: 1.7877324037654425

Epoch: 5| Step: 2
Training loss: 0.920619010925293
Validation loss: 1.8207977869177376

Epoch: 5| Step: 3
Training loss: 1.293588638305664
Validation loss: 1.8395411673412527

Epoch: 5| Step: 4
Training loss: 0.8406179547309875
Validation loss: 1.8269226756147159

Epoch: 5| Step: 5
Training loss: 0.8521400690078735
Validation loss: 1.8138962663630003

Epoch: 5| Step: 6
Training loss: 1.0096356868743896
Validation loss: 1.8170070635375155

Epoch: 5| Step: 7
Training loss: 1.0546355247497559
Validation loss: 1.8333817694776802

Epoch: 5| Step: 8
Training loss: 0.5837353467941284
Validation loss: 1.795918087805471

Epoch: 5| Step: 9
Training loss: 1.0215365886688232
Validation loss: 1.8153412444617159

Epoch: 5| Step: 10
Training loss: 0.9284380674362183
Validation loss: 1.8687936144490396

Epoch: 405| Step: 0
Training loss: 0.17927967011928558
Validation loss: 1.8781282055762507

Epoch: 5| Step: 1
Training loss: 0.9109722375869751
Validation loss: 1.877219016833972

Epoch: 5| Step: 2
Training loss: 0.932336688041687
Validation loss: 1.8677440830456313

Epoch: 5| Step: 3
Training loss: 1.3170671463012695
Validation loss: 1.8582020267363517

Epoch: 5| Step: 4
Training loss: 1.2424595355987549
Validation loss: 1.853324354335826

Epoch: 5| Step: 5
Training loss: 1.0687320232391357
Validation loss: 1.8512149241662794

Epoch: 5| Step: 6
Training loss: 1.0593359470367432
Validation loss: 1.8197771797897995

Epoch: 5| Step: 7
Training loss: 1.1173804998397827
Validation loss: 1.8280445452659362

Epoch: 5| Step: 8
Training loss: 0.8743016123771667
Validation loss: 1.8190065148056194

Epoch: 5| Step: 9
Training loss: 1.2033627033233643
Validation loss: 1.8466524347182243

Epoch: 5| Step: 10
Training loss: 0.9860022068023682
Validation loss: 1.841363158277286

Epoch: 406| Step: 0
Training loss: 0.9758453369140625
Validation loss: 1.8500838997543498

Epoch: 5| Step: 1
Training loss: 0.9814504384994507
Validation loss: 1.8453779976855043

Epoch: 5| Step: 2
Training loss: 1.0563890933990479
Validation loss: 1.8465091464340047

Epoch: 5| Step: 3
Training loss: 1.120903491973877
Validation loss: 1.8352863955241379

Epoch: 5| Step: 4
Training loss: 1.063353419303894
Validation loss: 1.832971731821696

Epoch: 5| Step: 5
Training loss: 1.1877906322479248
Validation loss: 1.8212839441914712

Epoch: 5| Step: 6
Training loss: 0.6860902905464172
Validation loss: 1.8132184705426615

Epoch: 5| Step: 7
Training loss: 0.7632147073745728
Validation loss: 1.8196383817221529

Epoch: 5| Step: 8
Training loss: 0.9572092890739441
Validation loss: 1.790981443979407

Epoch: 5| Step: 9
Training loss: 0.9460493326187134
Validation loss: 1.822389982079947

Epoch: 5| Step: 10
Training loss: 1.0473302602767944
Validation loss: 1.8591625767369424

Epoch: 407| Step: 0
Training loss: 1.2979066371917725
Validation loss: 1.860419588704263

Epoch: 5| Step: 1
Training loss: 0.8905805349349976
Validation loss: 1.8582366217849076

Epoch: 5| Step: 2
Training loss: 1.1784636974334717
Validation loss: 1.8544521844515236

Epoch: 5| Step: 3
Training loss: 1.2457680702209473
Validation loss: 1.8578351697614115

Epoch: 5| Step: 4
Training loss: 1.0746150016784668
Validation loss: 1.858749125593452

Epoch: 5| Step: 5
Training loss: 0.7940399646759033
Validation loss: 1.8325700708614883

Epoch: 5| Step: 6
Training loss: 0.7267549633979797
Validation loss: 1.8035589033557522

Epoch: 5| Step: 7
Training loss: 0.6364720463752747
Validation loss: 1.8445384489592684

Epoch: 5| Step: 8
Training loss: 1.0833338499069214
Validation loss: 1.8624581854830506

Epoch: 5| Step: 9
Training loss: 0.6459473371505737
Validation loss: 1.8644690744338497

Epoch: 5| Step: 10
Training loss: 1.242449402809143
Validation loss: 1.8759795119685512

Epoch: 408| Step: 0
Training loss: 0.7896250486373901
Validation loss: 1.868113633125059

Epoch: 5| Step: 1
Training loss: 1.0396429300308228
Validation loss: 1.8593553189308412

Epoch: 5| Step: 2
Training loss: 1.208849310874939
Validation loss: 1.844135840733846

Epoch: 5| Step: 3
Training loss: 0.9075295329093933
Validation loss: 1.80768750047171

Epoch: 5| Step: 4
Training loss: 1.1179653406143188
Validation loss: 1.8078292595442904

Epoch: 5| Step: 5
Training loss: 1.0593465566635132
Validation loss: 1.8123600944395988

Epoch: 5| Step: 6
Training loss: 0.9436175227165222
Validation loss: 1.8073512431113952

Epoch: 5| Step: 7
Training loss: 0.7160953283309937
Validation loss: 1.809694472179618

Epoch: 5| Step: 8
Training loss: 0.9593033790588379
Validation loss: 1.8927216183754705

Epoch: 5| Step: 9
Training loss: 0.8330851793289185
Validation loss: 1.9378708767634567

Epoch: 5| Step: 10
Training loss: 1.3059724569320679
Validation loss: 1.954505971682969

Epoch: 409| Step: 0
Training loss: 1.0853502750396729
Validation loss: 1.9422950872810938

Epoch: 5| Step: 1
Training loss: 0.8893035054206848
Validation loss: 1.9685872600924583

Epoch: 5| Step: 2
Training loss: 0.9486557245254517
Validation loss: 1.9090080222775858

Epoch: 5| Step: 3
Training loss: 0.8560692667961121
Validation loss: 1.8764334852977465

Epoch: 5| Step: 4
Training loss: 0.4788736402988434
Validation loss: 1.8343495463812223

Epoch: 5| Step: 5
Training loss: 1.3825700283050537
Validation loss: 1.8413636530599287

Epoch: 5| Step: 6
Training loss: 1.2567193508148193
Validation loss: 1.8307822878642748

Epoch: 5| Step: 7
Training loss: 0.660150408744812
Validation loss: 1.8392000403455508

Epoch: 5| Step: 8
Training loss: 1.4069043397903442
Validation loss: 1.8408992854497765

Epoch: 5| Step: 9
Training loss: 1.0725244283676147
Validation loss: 1.8376247485478718

Epoch: 5| Step: 10
Training loss: 0.5857177972793579
Validation loss: 1.8223654121480963

Epoch: 410| Step: 0
Training loss: 0.7453872561454773
Validation loss: 1.7932788902713406

Epoch: 5| Step: 1
Training loss: 0.7242652177810669
Validation loss: 1.8227338098710584

Epoch: 5| Step: 2
Training loss: 0.9278071522712708
Validation loss: 1.8474135270682714

Epoch: 5| Step: 3
Training loss: 1.2458550930023193
Validation loss: 1.8511782269324026

Epoch: 5| Step: 4
Training loss: 0.8601883053779602
Validation loss: 1.832456006798693

Epoch: 5| Step: 5
Training loss: 0.8154351115226746
Validation loss: 1.8245364389111918

Epoch: 5| Step: 6
Training loss: 1.5378862619400024
Validation loss: 1.8238831720044535

Epoch: 5| Step: 7
Training loss: 0.9851264953613281
Validation loss: 1.8580038316788212

Epoch: 5| Step: 8
Training loss: 1.174365758895874
Validation loss: 1.882366959766675

Epoch: 5| Step: 9
Training loss: 0.8961746096611023
Validation loss: 1.8961944464714295

Epoch: 5| Step: 10
Training loss: 0.9990674257278442
Validation loss: 1.8879064077972083

Epoch: 411| Step: 0
Training loss: 1.1455907821655273
Validation loss: 1.8413505144016717

Epoch: 5| Step: 1
Training loss: 1.5030725002288818
Validation loss: 1.8259636304711784

Epoch: 5| Step: 2
Training loss: 1.1101653575897217
Validation loss: 1.800428782739947

Epoch: 5| Step: 3
Training loss: 0.665395975112915
Validation loss: 1.8217429960927656

Epoch: 5| Step: 4
Training loss: 0.8880950808525085
Validation loss: 1.8045631608655375

Epoch: 5| Step: 5
Training loss: 1.0491129159927368
Validation loss: 1.842462315354296

Epoch: 5| Step: 6
Training loss: 0.8775795698165894
Validation loss: 1.8475944406242781

Epoch: 5| Step: 7
Training loss: 1.1885699033737183
Validation loss: 1.8999076825316235

Epoch: 5| Step: 8
Training loss: 0.8119681477546692
Validation loss: 1.8871106947621992

Epoch: 5| Step: 9
Training loss: 0.9791220426559448
Validation loss: 1.9112383242576354

Epoch: 5| Step: 10
Training loss: 0.8187173008918762
Validation loss: 1.934656172670344

Epoch: 412| Step: 0
Training loss: 1.172297477722168
Validation loss: 1.8815036563463108

Epoch: 5| Step: 1
Training loss: 0.7263299226760864
Validation loss: 1.8464820384979248

Epoch: 5| Step: 2
Training loss: 1.0894250869750977
Validation loss: 1.847019108392859

Epoch: 5| Step: 3
Training loss: 1.3522984981536865
Validation loss: 1.836591382180491

Epoch: 5| Step: 4
Training loss: 0.7602785229682922
Validation loss: 1.787770648156443

Epoch: 5| Step: 5
Training loss: 0.9283397793769836
Validation loss: 1.8019326797095678

Epoch: 5| Step: 6
Training loss: 1.2053029537200928
Validation loss: 1.8172936631787209

Epoch: 5| Step: 7
Training loss: 1.0199989080429077
Validation loss: 1.869567181474419

Epoch: 5| Step: 8
Training loss: 1.2068367004394531
Validation loss: 1.8665902986321399

Epoch: 5| Step: 9
Training loss: 0.4904612898826599
Validation loss: 1.9161701638211486

Epoch: 5| Step: 10
Training loss: 0.9142704010009766
Validation loss: 1.8931225397253548

Epoch: 413| Step: 0
Training loss: 0.9976481199264526
Validation loss: 1.865951479122203

Epoch: 5| Step: 1
Training loss: 0.8956762552261353
Validation loss: 1.8365034980158652

Epoch: 5| Step: 2
Training loss: 0.9552135467529297
Validation loss: 1.799024333236038

Epoch: 5| Step: 3
Training loss: 0.8047994375228882
Validation loss: 1.7734296924324446

Epoch: 5| Step: 4
Training loss: 0.7785689234733582
Validation loss: 1.7740850910063712

Epoch: 5| Step: 5
Training loss: 0.7331911325454712
Validation loss: 1.796939165361466

Epoch: 5| Step: 6
Training loss: 0.9179658889770508
Validation loss: 1.8280789121504752

Epoch: 5| Step: 7
Training loss: 1.1266645193099976
Validation loss: 1.8420620118418047

Epoch: 5| Step: 8
Training loss: 1.1357547044754028
Validation loss: 1.8515359291466333

Epoch: 5| Step: 9
Training loss: 1.0455725193023682
Validation loss: 1.8694933793878044

Epoch: 5| Step: 10
Training loss: 1.424909234046936
Validation loss: 1.8710813022428943

Epoch: 414| Step: 0
Training loss: 1.1008336544036865
Validation loss: 1.855454917876951

Epoch: 5| Step: 1
Training loss: 0.9702093005180359
Validation loss: 1.8357425274387482

Epoch: 5| Step: 2
Training loss: 0.9050179719924927
Validation loss: 1.8185277626078615

Epoch: 5| Step: 3
Training loss: 0.7084379196166992
Validation loss: 1.8403191912558772

Epoch: 5| Step: 4
Training loss: 0.738105058670044
Validation loss: 1.8314377953929286

Epoch: 5| Step: 5
Training loss: 0.9671877026557922
Validation loss: 1.8110591929445985

Epoch: 5| Step: 6
Training loss: 1.2332881689071655
Validation loss: 1.8218457673185615

Epoch: 5| Step: 7
Training loss: 1.2330483198165894
Validation loss: 1.8383939753296554

Epoch: 5| Step: 8
Training loss: 0.8112519383430481
Validation loss: 1.80921676851088

Epoch: 5| Step: 9
Training loss: 1.0496513843536377
Validation loss: 1.8148818605689592

Epoch: 5| Step: 10
Training loss: 0.9186237454414368
Validation loss: 1.7951031948930474

Epoch: 415| Step: 0
Training loss: 0.8355677723884583
Validation loss: 1.8237673941478934

Epoch: 5| Step: 1
Training loss: 0.6874082088470459
Validation loss: 1.8029475160824355

Epoch: 5| Step: 2
Training loss: 1.1731266975402832
Validation loss: 1.7923432114303752

Epoch: 5| Step: 3
Training loss: 1.2323052883148193
Validation loss: 1.8484646216515572

Epoch: 5| Step: 4
Training loss: 1.0919173955917358
Validation loss: 1.8348604120234007

Epoch: 5| Step: 5
Training loss: 0.9396350979804993
Validation loss: 1.8883710189532208

Epoch: 5| Step: 6
Training loss: 0.8175562024116516
Validation loss: 1.9029012700562835

Epoch: 5| Step: 7
Training loss: 1.0630134344100952
Validation loss: 1.8827042169468378

Epoch: 5| Step: 8
Training loss: 1.0677884817123413
Validation loss: 1.9233215649922688

Epoch: 5| Step: 9
Training loss: 0.9001525640487671
Validation loss: 1.8555858763315345

Epoch: 5| Step: 10
Training loss: 0.8301711082458496
Validation loss: 1.8450048251818585

Epoch: 416| Step: 0
Training loss: 1.2240086793899536
Validation loss: 1.8449659052715506

Epoch: 5| Step: 1
Training loss: 1.165085792541504
Validation loss: 1.8021460284468949

Epoch: 5| Step: 2
Training loss: 1.0149924755096436
Validation loss: 1.8225832690474808

Epoch: 5| Step: 3
Training loss: 0.9718561172485352
Validation loss: 1.820001276590491

Epoch: 5| Step: 4
Training loss: 1.053436517715454
Validation loss: 1.8365748569529543

Epoch: 5| Step: 5
Training loss: 0.7941939234733582
Validation loss: 1.8125796010417323

Epoch: 5| Step: 6
Training loss: 1.0876346826553345
Validation loss: 1.8460080136534989

Epoch: 5| Step: 7
Training loss: 0.8800379037857056
Validation loss: 1.7894340958646549

Epoch: 5| Step: 8
Training loss: 0.866420567035675
Validation loss: 1.7722545990379908

Epoch: 5| Step: 9
Training loss: 0.572918713092804
Validation loss: 1.772652651674004

Epoch: 5| Step: 10
Training loss: 1.168121576309204
Validation loss: 1.7348051635167931

Epoch: 417| Step: 0
Training loss: 1.043653130531311
Validation loss: 1.7503102338442238

Epoch: 5| Step: 1
Training loss: 1.0654436349868774
Validation loss: 1.7915431248244418

Epoch: 5| Step: 2
Training loss: 0.8450384140014648
Validation loss: 1.7801707893289545

Epoch: 5| Step: 3
Training loss: 1.0668294429779053
Validation loss: 1.813904962232036

Epoch: 5| Step: 4
Training loss: 0.7654730081558228
Validation loss: 1.8620529328623125

Epoch: 5| Step: 5
Training loss: 0.6367136836051941
Validation loss: 1.8707523589493127

Epoch: 5| Step: 6
Training loss: 1.127539038658142
Validation loss: 1.8717525646250734

Epoch: 5| Step: 7
Training loss: 0.7124301195144653
Validation loss: 1.8471797256059543

Epoch: 5| Step: 8
Training loss: 1.1040990352630615
Validation loss: 1.8005694035560853

Epoch: 5| Step: 9
Training loss: 0.812301516532898
Validation loss: 1.8027397919726629

Epoch: 5| Step: 10
Training loss: 1.2699581384658813
Validation loss: 1.8098614856760988

Epoch: 418| Step: 0
Training loss: 1.2767999172210693
Validation loss: 1.79891759990364

Epoch: 5| Step: 1
Training loss: 1.0224831104278564
Validation loss: 1.797227104504903

Epoch: 5| Step: 2
Training loss: 0.7460328936576843
Validation loss: 1.7958061105461531

Epoch: 5| Step: 3
Training loss: 0.7060307860374451
Validation loss: 1.801338929002003

Epoch: 5| Step: 4
Training loss: 0.9578841328620911
Validation loss: 1.8341113867298249

Epoch: 5| Step: 5
Training loss: 0.9152000546455383
Validation loss: 1.8281166066405594

Epoch: 5| Step: 6
Training loss: 0.9493275880813599
Validation loss: 1.870416679689961

Epoch: 5| Step: 7
Training loss: 1.1363229751586914
Validation loss: 1.9146746076563352

Epoch: 5| Step: 8
Training loss: 0.8956294059753418
Validation loss: 1.889049877402603

Epoch: 5| Step: 9
Training loss: 0.7826104164123535
Validation loss: 1.8711857231714393

Epoch: 5| Step: 10
Training loss: 1.2051575183868408
Validation loss: 1.8838805998525312

Epoch: 419| Step: 0
Training loss: 0.8140062093734741
Validation loss: 1.8303493107518842

Epoch: 5| Step: 1
Training loss: 0.9632436633110046
Validation loss: 1.83368057076649

Epoch: 5| Step: 2
Training loss: 0.8188264966011047
Validation loss: 1.814482981158841

Epoch: 5| Step: 3
Training loss: 0.9426129460334778
Validation loss: 1.7925139768149263

Epoch: 5| Step: 4
Training loss: 1.0425230264663696
Validation loss: 1.7908941135611585

Epoch: 5| Step: 5
Training loss: 0.9576894044876099
Validation loss: 1.7875148301483483

Epoch: 5| Step: 6
Training loss: 1.0744166374206543
Validation loss: 1.8073728808792688

Epoch: 5| Step: 7
Training loss: 0.8696576952934265
Validation loss: 1.8209347109640799

Epoch: 5| Step: 8
Training loss: 0.9931289553642273
Validation loss: 1.847876888449474

Epoch: 5| Step: 9
Training loss: 0.9363530874252319
Validation loss: 1.8345794357279295

Epoch: 5| Step: 10
Training loss: 1.0909923315048218
Validation loss: 1.8652425991591586

Epoch: 420| Step: 0
Training loss: 1.1570392847061157
Validation loss: 1.8692469930136075

Epoch: 5| Step: 1
Training loss: 1.1800549030303955
Validation loss: 1.880524940388177

Epoch: 5| Step: 2
Training loss: 0.8592910766601562
Validation loss: 1.9156177902734408

Epoch: 5| Step: 3
Training loss: 1.1454463005065918
Validation loss: 1.8830575135446364

Epoch: 5| Step: 4
Training loss: 0.8029242753982544
Validation loss: 1.8284485058117939

Epoch: 5| Step: 5
Training loss: 0.5918275117874146
Validation loss: 1.8406001572967858

Epoch: 5| Step: 6
Training loss: 0.8482656478881836
Validation loss: 1.7704676646058277

Epoch: 5| Step: 7
Training loss: 1.0141513347625732
Validation loss: 1.7568410058175363

Epoch: 5| Step: 8
Training loss: 0.6594186425209045
Validation loss: 1.7282246056423392

Epoch: 5| Step: 9
Training loss: 1.1572879552841187
Validation loss: 1.7265364290565572

Epoch: 5| Step: 10
Training loss: 0.9111946225166321
Validation loss: 1.746604602183065

Epoch: 421| Step: 0
Training loss: 0.5791098475456238
Validation loss: 1.7167820815117127

Epoch: 5| Step: 1
Training loss: 0.953799843788147
Validation loss: 1.7674872913668234

Epoch: 5| Step: 2
Training loss: 0.8434538841247559
Validation loss: 1.766891546146844

Epoch: 5| Step: 3
Training loss: 0.9149195551872253
Validation loss: 1.8331237941659906

Epoch: 5| Step: 4
Training loss: 1.1435108184814453
Validation loss: 1.8238306430078322

Epoch: 5| Step: 5
Training loss: 1.0378068685531616
Validation loss: 1.8367335745083389

Epoch: 5| Step: 6
Training loss: 0.9639222025871277
Validation loss: 1.7891302429219729

Epoch: 5| Step: 7
Training loss: 1.3637721538543701
Validation loss: 1.773315816797236

Epoch: 5| Step: 8
Training loss: 0.7575869560241699
Validation loss: 1.7756106891939718

Epoch: 5| Step: 9
Training loss: 0.8404792547225952
Validation loss: 1.793930067810961

Epoch: 5| Step: 10
Training loss: 0.9067114591598511
Validation loss: 1.7940795588236984

Epoch: 422| Step: 0
Training loss: 0.6799303293228149
Validation loss: 1.7780868943019579

Epoch: 5| Step: 1
Training loss: 0.785520613193512
Validation loss: 1.7654169451805852

Epoch: 5| Step: 2
Training loss: 0.9958034753799438
Validation loss: 1.7682989092283352

Epoch: 5| Step: 3
Training loss: 0.8741756677627563
Validation loss: 1.7600487137353549

Epoch: 5| Step: 4
Training loss: 0.7971903085708618
Validation loss: 1.7640575465335642

Epoch: 5| Step: 5
Training loss: 0.5946448445320129
Validation loss: 1.7776878136460499

Epoch: 5| Step: 6
Training loss: 1.299612283706665
Validation loss: 1.816070004176068

Epoch: 5| Step: 7
Training loss: 0.9212720990180969
Validation loss: 1.8634559172455982

Epoch: 5| Step: 8
Training loss: 0.8857954740524292
Validation loss: 1.873135975612107

Epoch: 5| Step: 9
Training loss: 0.8755813837051392
Validation loss: 1.8470187148740214

Epoch: 5| Step: 10
Training loss: 1.5466798543930054
Validation loss: 1.858918228457051

Epoch: 423| Step: 0
Training loss: 0.8764506578445435
Validation loss: 1.8310135820860505

Epoch: 5| Step: 1
Training loss: 0.8247088193893433
Validation loss: 1.8308740418444398

Epoch: 5| Step: 2
Training loss: 0.7853089570999146
Validation loss: 1.7920286052970475

Epoch: 5| Step: 3
Training loss: 1.255475640296936
Validation loss: 1.7818892489197433

Epoch: 5| Step: 4
Training loss: 1.221616506576538
Validation loss: 1.7868911156090357

Epoch: 5| Step: 5
Training loss: 0.7590110898017883
Validation loss: 1.7782758230804114

Epoch: 5| Step: 6
Training loss: 0.9618802070617676
Validation loss: 1.7640600704377698

Epoch: 5| Step: 7
Training loss: 0.8661320805549622
Validation loss: 1.7703414937501312

Epoch: 5| Step: 8
Training loss: 1.172131061553955
Validation loss: 1.7601582081087175

Epoch: 5| Step: 9
Training loss: 0.9174178242683411
Validation loss: 1.7788318075159544

Epoch: 5| Step: 10
Training loss: 0.4135453701019287
Validation loss: 1.7740050003092775

Epoch: 424| Step: 0
Training loss: 0.904321014881134
Validation loss: 1.8066168549240276

Epoch: 5| Step: 1
Training loss: 0.7821481823921204
Validation loss: 1.808512818428778

Epoch: 5| Step: 2
Training loss: 1.1538280248641968
Validation loss: 1.8562400469215967

Epoch: 5| Step: 3
Training loss: 1.0227895975112915
Validation loss: 1.9089239233283586

Epoch: 5| Step: 4
Training loss: 1.0988807678222656
Validation loss: 1.8896094778532624

Epoch: 5| Step: 5
Training loss: 0.856209933757782
Validation loss: 1.865356586312735

Epoch: 5| Step: 6
Training loss: 1.0661265850067139
Validation loss: 1.8094776394546672

Epoch: 5| Step: 7
Training loss: 0.8685228228569031
Validation loss: 1.7627269811527704

Epoch: 5| Step: 8
Training loss: 0.8382562398910522
Validation loss: 1.7681190570195515

Epoch: 5| Step: 9
Training loss: 0.8002379536628723
Validation loss: 1.731568444159723

Epoch: 5| Step: 10
Training loss: 1.2105079889297485
Validation loss: 1.748916756722235

Epoch: 425| Step: 0
Training loss: 0.9339441061019897
Validation loss: 1.7664028726598269

Epoch: 5| Step: 1
Training loss: 1.2032396793365479
Validation loss: 1.7685246313771894

Epoch: 5| Step: 2
Training loss: 0.9949209094047546
Validation loss: 1.81963481954349

Epoch: 5| Step: 3
Training loss: 0.8400065302848816
Validation loss: 1.8545058517045871

Epoch: 5| Step: 4
Training loss: 1.523327112197876
Validation loss: 1.8537673027284685

Epoch: 5| Step: 5
Training loss: 0.9696024060249329
Validation loss: 1.8388043135725043

Epoch: 5| Step: 6
Training loss: 1.5761137008666992
Validation loss: 1.8397544583966654

Epoch: 5| Step: 7
Training loss: 1.1967045068740845
Validation loss: 1.8040836972575034

Epoch: 5| Step: 8
Training loss: 0.33754444122314453
Validation loss: 1.833432052725105

Epoch: 5| Step: 9
Training loss: 0.47331729531288147
Validation loss: 1.7978554848701722

Epoch: 5| Step: 10
Training loss: 0.43176376819610596
Validation loss: 1.7994177264551963

Epoch: 426| Step: 0
Training loss: 0.5911794900894165
Validation loss: 1.7767967831703924

Epoch: 5| Step: 1
Training loss: 0.7373157739639282
Validation loss: 1.782954728731545

Epoch: 5| Step: 2
Training loss: 0.9261911511421204
Validation loss: 1.8306243573465655

Epoch: 5| Step: 3
Training loss: 0.6679765582084656
Validation loss: 1.8175158321216542

Epoch: 5| Step: 4
Training loss: 0.9777841567993164
Validation loss: 1.7874153852462769

Epoch: 5| Step: 5
Training loss: 1.2151098251342773
Validation loss: 1.8292829285385788

Epoch: 5| Step: 6
Training loss: 0.9833067059516907
Validation loss: 1.8163335220788115

Epoch: 5| Step: 7
Training loss: 0.9289464950561523
Validation loss: 1.7982271589258665

Epoch: 5| Step: 8
Training loss: 1.1013991832733154
Validation loss: 1.7849035032333866

Epoch: 5| Step: 9
Training loss: 0.9338942766189575
Validation loss: 1.771377848040673

Epoch: 5| Step: 10
Training loss: 1.0675897598266602
Validation loss: 1.7829419464193366

Epoch: 427| Step: 0
Training loss: 1.152953863143921
Validation loss: 1.7871073163965696

Epoch: 5| Step: 1
Training loss: 0.9362868070602417
Validation loss: 1.7977480657639042

Epoch: 5| Step: 2
Training loss: 0.904457688331604
Validation loss: 1.805746365618962

Epoch: 5| Step: 3
Training loss: 1.0404132604599
Validation loss: 1.7884357590829172

Epoch: 5| Step: 4
Training loss: 0.7463423013687134
Validation loss: 1.746513892245549

Epoch: 5| Step: 5
Training loss: 1.0444834232330322
Validation loss: 1.742607516627158

Epoch: 5| Step: 6
Training loss: 1.5358879566192627
Validation loss: 1.7669162352879841

Epoch: 5| Step: 7
Training loss: 0.5880810022354126
Validation loss: 1.787734971251539

Epoch: 5| Step: 8
Training loss: 0.35699862241744995
Validation loss: 1.7834539682634416

Epoch: 5| Step: 9
Training loss: 1.1690139770507812
Validation loss: 1.785363628018287

Epoch: 5| Step: 10
Training loss: 0.5270035266876221
Validation loss: 1.800603594831241

Epoch: 428| Step: 0
Training loss: 0.9333230257034302
Validation loss: 1.7977277668573524

Epoch: 5| Step: 1
Training loss: 0.925271213054657
Validation loss: 1.8220840295155842

Epoch: 5| Step: 2
Training loss: 0.8965743184089661
Validation loss: 1.8108257785920174

Epoch: 5| Step: 3
Training loss: 0.9416371583938599
Validation loss: 1.81664688100097

Epoch: 5| Step: 4
Training loss: 0.8098186254501343
Validation loss: 1.800915534778308

Epoch: 5| Step: 5
Training loss: 0.6198292970657349
Validation loss: 1.7805503081249934

Epoch: 5| Step: 6
Training loss: 1.2703860998153687
Validation loss: 1.806829119241366

Epoch: 5| Step: 7
Training loss: 0.9673412442207336
Validation loss: 1.839369289336666

Epoch: 5| Step: 8
Training loss: 0.5028623342514038
Validation loss: 1.8022191473232803

Epoch: 5| Step: 9
Training loss: 1.16580331325531
Validation loss: 1.804837562704599

Epoch: 5| Step: 10
Training loss: 0.9648804664611816
Validation loss: 1.7774911208819317

Epoch: 429| Step: 0
Training loss: 0.8838279843330383
Validation loss: 1.7353747365295247

Epoch: 5| Step: 1
Training loss: 0.9285170435905457
Validation loss: 1.7696269968504548

Epoch: 5| Step: 2
Training loss: 0.5468985438346863
Validation loss: 1.75641760646656

Epoch: 5| Step: 3
Training loss: 0.7317999601364136
Validation loss: 1.7786770328398673

Epoch: 5| Step: 4
Training loss: 0.7875076532363892
Validation loss: 1.7770642561297263

Epoch: 5| Step: 5
Training loss: 1.0733389854431152
Validation loss: 1.7772846132196405

Epoch: 5| Step: 6
Training loss: 0.5399709939956665
Validation loss: 1.823182354691208

Epoch: 5| Step: 7
Training loss: 1.0091270208358765
Validation loss: 1.7960207103401102

Epoch: 5| Step: 8
Training loss: 0.8727886080741882
Validation loss: 1.7987882501335555

Epoch: 5| Step: 9
Training loss: 1.5444068908691406
Validation loss: 1.7737924001550163

Epoch: 5| Step: 10
Training loss: 1.194804310798645
Validation loss: 1.74967489575827

Epoch: 430| Step: 0
Training loss: 0.6313900351524353
Validation loss: 1.7247272640146234

Epoch: 5| Step: 1
Training loss: 0.9326211810112
Validation loss: 1.7354759746982205

Epoch: 5| Step: 2
Training loss: 0.5185936689376831
Validation loss: 1.724456552536257

Epoch: 5| Step: 3
Training loss: 1.0828380584716797
Validation loss: 1.7417045870134908

Epoch: 5| Step: 4
Training loss: 1.1246507167816162
Validation loss: 1.7628007127392677

Epoch: 5| Step: 5
Training loss: 0.973119854927063
Validation loss: 1.7635262730301067

Epoch: 5| Step: 6
Training loss: 0.7269819378852844
Validation loss: 1.8004841394321893

Epoch: 5| Step: 7
Training loss: 1.0848462581634521
Validation loss: 1.7903280104360273

Epoch: 5| Step: 8
Training loss: 0.874040424823761
Validation loss: 1.7954157783139137

Epoch: 5| Step: 9
Training loss: 0.974639892578125
Validation loss: 1.7614743273745301

Epoch: 5| Step: 10
Training loss: 1.1694200038909912
Validation loss: 1.7796039542844218

Epoch: 431| Step: 0
Training loss: 0.7488917112350464
Validation loss: 1.741736464602973

Epoch: 5| Step: 1
Training loss: 0.6741983294487
Validation loss: 1.73542570811446

Epoch: 5| Step: 2
Training loss: 0.633819580078125
Validation loss: 1.7283039862109768

Epoch: 5| Step: 3
Training loss: 0.7511913180351257
Validation loss: 1.7038937794264926

Epoch: 5| Step: 4
Training loss: 1.1395082473754883
Validation loss: 1.724164003966957

Epoch: 5| Step: 5
Training loss: 0.8675798177719116
Validation loss: 1.7471752089838828

Epoch: 5| Step: 6
Training loss: 1.053566575050354
Validation loss: 1.8095632189063615

Epoch: 5| Step: 7
Training loss: 1.261651635169983
Validation loss: 1.7993764236409178

Epoch: 5| Step: 8
Training loss: 1.1083166599273682
Validation loss: 1.8178695235201108

Epoch: 5| Step: 9
Training loss: 0.5955440402030945
Validation loss: 1.8433365437292284

Epoch: 5| Step: 10
Training loss: 1.0764734745025635
Validation loss: 1.8712221704503542

Epoch: 432| Step: 0
Training loss: 1.2215427160263062
Validation loss: 1.8900965823922107

Epoch: 5| Step: 1
Training loss: 1.0374810695648193
Validation loss: 1.8642627487900436

Epoch: 5| Step: 2
Training loss: 0.6768966317176819
Validation loss: 1.86436891043058

Epoch: 5| Step: 3
Training loss: 0.9233347177505493
Validation loss: 1.8121930911976805

Epoch: 5| Step: 4
Training loss: 0.6017709970474243
Validation loss: 1.7662210720841602

Epoch: 5| Step: 5
Training loss: 0.48910942673683167
Validation loss: 1.7513460497702322

Epoch: 5| Step: 6
Training loss: 0.791242778301239
Validation loss: 1.7632319068395963

Epoch: 5| Step: 7
Training loss: 1.1898267269134521
Validation loss: 1.728146300520948

Epoch: 5| Step: 8
Training loss: 0.8822558522224426
Validation loss: 1.7063310748787337

Epoch: 5| Step: 9
Training loss: 1.1028003692626953
Validation loss: 1.7392535517292638

Epoch: 5| Step: 10
Training loss: 1.1255539655685425
Validation loss: 1.7464324799917077

Epoch: 433| Step: 0
Training loss: 0.7195274233818054
Validation loss: 1.734963176071003

Epoch: 5| Step: 1
Training loss: 0.5756481885910034
Validation loss: 1.7721995653644684

Epoch: 5| Step: 2
Training loss: 1.593004584312439
Validation loss: 1.745380606702579

Epoch: 5| Step: 3
Training loss: 0.8600730895996094
Validation loss: 1.77126774608448

Epoch: 5| Step: 4
Training loss: 1.3245937824249268
Validation loss: 1.7632695654387116

Epoch: 5| Step: 5
Training loss: 0.6232587695121765
Validation loss: 1.7579974230899607

Epoch: 5| Step: 6
Training loss: 0.6306585073471069
Validation loss: 1.7530041433149768

Epoch: 5| Step: 7
Training loss: 0.9629595875740051
Validation loss: 1.7815625962390695

Epoch: 5| Step: 8
Training loss: 0.8553188443183899
Validation loss: 1.7683391955591017

Epoch: 5| Step: 9
Training loss: 0.3768695592880249
Validation loss: 1.8227277096881662

Epoch: 5| Step: 10
Training loss: 1.1458131074905396
Validation loss: 1.805244391964328

Epoch: 434| Step: 0
Training loss: 0.5768168568611145
Validation loss: 1.7796284665343582

Epoch: 5| Step: 1
Training loss: 1.1965161561965942
Validation loss: 1.8030616262907624

Epoch: 5| Step: 2
Training loss: 0.9629594087600708
Validation loss: 1.774534644619111

Epoch: 5| Step: 3
Training loss: 0.561137855052948
Validation loss: 1.7829726665250716

Epoch: 5| Step: 4
Training loss: 0.8015937805175781
Validation loss: 1.7623079156362882

Epoch: 5| Step: 5
Training loss: 0.9072351455688477
Validation loss: 1.759045845718794

Epoch: 5| Step: 6
Training loss: 0.8632556796073914
Validation loss: 1.7387652807338263

Epoch: 5| Step: 7
Training loss: 1.195544719696045
Validation loss: 1.7352969889999719

Epoch: 5| Step: 8
Training loss: 1.1641329526901245
Validation loss: 1.7788525806960238

Epoch: 5| Step: 9
Training loss: 1.1424907445907593
Validation loss: 1.822637027309787

Epoch: 5| Step: 10
Training loss: 0.5126941800117493
Validation loss: 1.8477160417905418

Epoch: 435| Step: 0
Training loss: 0.7058616876602173
Validation loss: 1.888567723253722

Epoch: 5| Step: 1
Training loss: 1.0105807781219482
Validation loss: 1.9022147873396515

Epoch: 5| Step: 2
Training loss: 1.0632975101470947
Validation loss: 1.91790916714617

Epoch: 5| Step: 3
Training loss: 0.6408659815788269
Validation loss: 1.9031459093093872

Epoch: 5| Step: 4
Training loss: 0.7658512592315674
Validation loss: 1.8452165152436943

Epoch: 5| Step: 5
Training loss: 1.085735559463501
Validation loss: 1.7755903864419589

Epoch: 5| Step: 6
Training loss: 0.9556728601455688
Validation loss: 1.7546325050374514

Epoch: 5| Step: 7
Training loss: 1.064672827720642
Validation loss: 1.7673010800474434

Epoch: 5| Step: 8
Training loss: 0.7443227767944336
Validation loss: 1.724225354451005

Epoch: 5| Step: 9
Training loss: 1.0646331310272217
Validation loss: 1.7442020729023924

Epoch: 5| Step: 10
Training loss: 0.927331268787384
Validation loss: 1.7513204684821508

Epoch: 436| Step: 0
Training loss: 1.1247928142547607
Validation loss: 1.7386292488344255

Epoch: 5| Step: 1
Training loss: 1.0594691038131714
Validation loss: 1.7659586219377414

Epoch: 5| Step: 2
Training loss: 0.6423609852790833
Validation loss: 1.7765792595442904

Epoch: 5| Step: 3
Training loss: 0.8314069509506226
Validation loss: 1.7666523123300204

Epoch: 5| Step: 4
Training loss: 1.0962483882904053
Validation loss: 1.786294944824711

Epoch: 5| Step: 5
Training loss: 1.1066383123397827
Validation loss: 1.8032693414277927

Epoch: 5| Step: 6
Training loss: 0.7257999181747437
Validation loss: 1.8119923978723504

Epoch: 5| Step: 7
Training loss: 0.9714990854263306
Validation loss: 1.8438478592903382

Epoch: 5| Step: 8
Training loss: 0.9574334025382996
Validation loss: 1.8469455639521282

Epoch: 5| Step: 9
Training loss: 0.5330525636672974
Validation loss: 1.814962447330516

Epoch: 5| Step: 10
Training loss: 0.8735678791999817
Validation loss: 1.760272269607872

Epoch: 437| Step: 0
Training loss: 1.2877622842788696
Validation loss: 1.7430033504322011

Epoch: 5| Step: 1
Training loss: 1.1293004751205444
Validation loss: 1.7384992402086976

Epoch: 5| Step: 2
Training loss: 0.699447751045227
Validation loss: 1.7073336852494108

Epoch: 5| Step: 3
Training loss: 0.6399394273757935
Validation loss: 1.7269954912124141

Epoch: 5| Step: 4
Training loss: 1.1762126684188843
Validation loss: 1.7554686838580715

Epoch: 5| Step: 5
Training loss: 0.8744688034057617
Validation loss: 1.7990891343803816

Epoch: 5| Step: 6
Training loss: 0.9705079793930054
Validation loss: 1.7966033079290902

Epoch: 5| Step: 7
Training loss: 0.6447447538375854
Validation loss: 1.7903578178856963

Epoch: 5| Step: 8
Training loss: 0.6938548684120178
Validation loss: 1.693929942705298

Epoch: 5| Step: 9
Training loss: 0.6607886552810669
Validation loss: 1.6789787994918002

Epoch: 5| Step: 10
Training loss: 1.111891269683838
Validation loss: 1.6936788699960197

Epoch: 438| Step: 0
Training loss: 0.650723934173584
Validation loss: 1.6974523272565616

Epoch: 5| Step: 1
Training loss: 0.6453052759170532
Validation loss: 1.6788917805558892

Epoch: 5| Step: 2
Training loss: 0.9177762866020203
Validation loss: 1.7534231780677714

Epoch: 5| Step: 3
Training loss: 1.1107763051986694
Validation loss: 1.786261079131916

Epoch: 5| Step: 4
Training loss: 0.9734588861465454
Validation loss: 1.80654981828505

Epoch: 5| Step: 5
Training loss: 0.9488010406494141
Validation loss: 1.83912500386597

Epoch: 5| Step: 6
Training loss: 0.7377386689186096
Validation loss: 1.8499291596874115

Epoch: 5| Step: 7
Training loss: 1.1944878101348877
Validation loss: 1.8777972626429733

Epoch: 5| Step: 8
Training loss: 0.9733096957206726
Validation loss: 1.8571911986156175

Epoch: 5| Step: 9
Training loss: 0.9477860331535339
Validation loss: 1.837588402532762

Epoch: 5| Step: 10
Training loss: 0.6571251749992371
Validation loss: 1.8181298753266693

Epoch: 439| Step: 0
Training loss: 0.9653215408325195
Validation loss: 1.811479107026131

Epoch: 5| Step: 1
Training loss: 1.1820557117462158
Validation loss: 1.794694923585461

Epoch: 5| Step: 2
Training loss: 0.8077190518379211
Validation loss: 1.7386136529266194

Epoch: 5| Step: 3
Training loss: 0.6359659433364868
Validation loss: 1.7166595510257188

Epoch: 5| Step: 4
Training loss: 1.0880553722381592
Validation loss: 1.690257909477398

Epoch: 5| Step: 5
Training loss: 0.8121871948242188
Validation loss: 1.701678688808154

Epoch: 5| Step: 6
Training loss: 1.0134010314941406
Validation loss: 1.697626624056088

Epoch: 5| Step: 7
Training loss: 0.7845867872238159
Validation loss: 1.7057275643912695

Epoch: 5| Step: 8
Training loss: 0.7013995051383972
Validation loss: 1.73863818184022

Epoch: 5| Step: 9
Training loss: 0.8069850206375122
Validation loss: 1.7837993432116765

Epoch: 5| Step: 10
Training loss: 0.8193781971931458
Validation loss: 1.8234961366140714

Epoch: 440| Step: 0
Training loss: 1.0527857542037964
Validation loss: 1.8499075366604714

Epoch: 5| Step: 1
Training loss: 1.0155718326568604
Validation loss: 1.8452266711060719

Epoch: 5| Step: 2
Training loss: 0.5206522941589355
Validation loss: 1.8043500851559382

Epoch: 5| Step: 3
Training loss: 1.1956268548965454
Validation loss: 1.7615070048198904

Epoch: 5| Step: 4
Training loss: 0.7313650846481323
Validation loss: 1.7780971142553514

Epoch: 5| Step: 5
Training loss: 1.1816924810409546
Validation loss: 1.7485974565629037

Epoch: 5| Step: 6
Training loss: 0.8624942898750305
Validation loss: 1.7453821346323977

Epoch: 5| Step: 7
Training loss: 1.0739628076553345
Validation loss: 1.7330811728713333

Epoch: 5| Step: 8
Training loss: 0.8165889978408813
Validation loss: 1.744135445164096

Epoch: 5| Step: 9
Training loss: 0.594990611076355
Validation loss: 1.748337520066128

Epoch: 5| Step: 10
Training loss: 0.7077121734619141
Validation loss: 1.7673629150595715

Epoch: 441| Step: 0
Training loss: 0.47662514448165894
Validation loss: 1.7885152806517899

Epoch: 5| Step: 1
Training loss: 1.025377631187439
Validation loss: 1.7665783230976393

Epoch: 5| Step: 2
Training loss: 1.0023318529129028
Validation loss: 1.7736558888548164

Epoch: 5| Step: 3
Training loss: 0.8171695470809937
Validation loss: 1.7490408830745245

Epoch: 5| Step: 4
Training loss: 1.4116846323013306
Validation loss: 1.75338355828357

Epoch: 5| Step: 5
Training loss: 0.918303370475769
Validation loss: 1.7419037447180798

Epoch: 5| Step: 6
Training loss: 1.101447343826294
Validation loss: 1.7230622460765224

Epoch: 5| Step: 7
Training loss: 0.5057921409606934
Validation loss: 1.7222019190429358

Epoch: 5| Step: 8
Training loss: 0.5840010643005371
Validation loss: 1.7484890786550378

Epoch: 5| Step: 9
Training loss: 0.87293541431427
Validation loss: 1.7680396341508435

Epoch: 5| Step: 10
Training loss: 0.8431364893913269
Validation loss: 1.757955216592358

Epoch: 442| Step: 0
Training loss: 0.9475166201591492
Validation loss: 1.788036084944202

Epoch: 5| Step: 1
Training loss: 0.6211755871772766
Validation loss: 1.7771232025597685

Epoch: 5| Step: 2
Training loss: 0.7852221727371216
Validation loss: 1.7622213261101836

Epoch: 5| Step: 3
Training loss: 0.8009004592895508
Validation loss: 1.7924617567370016

Epoch: 5| Step: 4
Training loss: 1.2443902492523193
Validation loss: 1.8186080750598703

Epoch: 5| Step: 5
Training loss: 0.9565684199333191
Validation loss: 1.7945733711283693

Epoch: 5| Step: 6
Training loss: 0.8593761324882507
Validation loss: 1.77450317464849

Epoch: 5| Step: 7
Training loss: 0.8212848901748657
Validation loss: 1.7565868567394953

Epoch: 5| Step: 8
Training loss: 0.9980905652046204
Validation loss: 1.7632576124642485

Epoch: 5| Step: 9
Training loss: 0.8309909701347351
Validation loss: 1.7291176472940752

Epoch: 5| Step: 10
Training loss: 0.5559110641479492
Validation loss: 1.7468747503014022

Epoch: 443| Step: 0
Training loss: 0.6967810988426208
Validation loss: 1.7328029281349593

Epoch: 5| Step: 1
Training loss: 0.8383597135543823
Validation loss: 1.7466761668523152

Epoch: 5| Step: 2
Training loss: 0.6157323718070984
Validation loss: 1.7854529132125199

Epoch: 5| Step: 3
Training loss: 1.2080907821655273
Validation loss: 1.7430096044335315

Epoch: 5| Step: 4
Training loss: 0.6076258420944214
Validation loss: 1.7709564893476424

Epoch: 5| Step: 5
Training loss: 0.5484604835510254
Validation loss: 1.7489325205485027

Epoch: 5| Step: 6
Training loss: 1.3750184774398804
Validation loss: 1.7718380599893548

Epoch: 5| Step: 7
Training loss: 0.7013397812843323
Validation loss: 1.7702811507768528

Epoch: 5| Step: 8
Training loss: 0.951966404914856
Validation loss: 1.766128029874576

Epoch: 5| Step: 9
Training loss: 1.0424387454986572
Validation loss: 1.7630104352069158

Epoch: 5| Step: 10
Training loss: 0.7910099029541016
Validation loss: 1.7871845127433859

Epoch: 444| Step: 0
Training loss: 0.8513181805610657
Validation loss: 1.7572440101254372

Epoch: 5| Step: 1
Training loss: 0.7167348861694336
Validation loss: 1.747527148133965

Epoch: 5| Step: 2
Training loss: 0.6310688257217407
Validation loss: 1.758472425963289

Epoch: 5| Step: 3
Training loss: 1.1412343978881836
Validation loss: 1.7564324473821988

Epoch: 5| Step: 4
Training loss: 0.7326725721359253
Validation loss: 1.7487751655681159

Epoch: 5| Step: 5
Training loss: 1.2421753406524658
Validation loss: 1.7471079249535837

Epoch: 5| Step: 6
Training loss: 0.9287317991256714
Validation loss: 1.772768328266759

Epoch: 5| Step: 7
Training loss: 0.9879457354545593
Validation loss: 1.754201485264686

Epoch: 5| Step: 8
Training loss: 0.5820239186286926
Validation loss: 1.7252698124095958

Epoch: 5| Step: 9
Training loss: 0.4534519612789154
Validation loss: 1.7575936983990412

Epoch: 5| Step: 10
Training loss: 1.1167478561401367
Validation loss: 1.6995180114623039

Epoch: 445| Step: 0
Training loss: 0.4283931255340576
Validation loss: 1.750388253119684

Epoch: 5| Step: 1
Training loss: 0.7510156035423279
Validation loss: 1.7391911142615861

Epoch: 5| Step: 2
Training loss: 0.9442309141159058
Validation loss: 1.727906434766708

Epoch: 5| Step: 3
Training loss: 0.9846510887145996
Validation loss: 1.7482793420873664

Epoch: 5| Step: 4
Training loss: 0.8975422978401184
Validation loss: 1.7598372749103013

Epoch: 5| Step: 5
Training loss: 0.803356945514679
Validation loss: 1.7637792261697913

Epoch: 5| Step: 6
Training loss: 1.11640202999115
Validation loss: 1.8082383435259584

Epoch: 5| Step: 7
Training loss: 0.827795147895813
Validation loss: 1.8153217710474485

Epoch: 5| Step: 8
Training loss: 0.6596077084541321
Validation loss: 1.8364277655078518

Epoch: 5| Step: 9
Training loss: 0.8593867421150208
Validation loss: 1.8155188650213263

Epoch: 5| Step: 10
Training loss: 0.977121889591217
Validation loss: 1.8018942084363712

Epoch: 446| Step: 0
Training loss: 1.199951410293579
Validation loss: 1.7337471259537565

Epoch: 5| Step: 1
Training loss: 0.5264260172843933
Validation loss: 1.7576440816284509

Epoch: 5| Step: 2
Training loss: 1.282615303993225
Validation loss: 1.7689719123225058

Epoch: 5| Step: 3
Training loss: 0.8612915277481079
Validation loss: 1.7644423464293122

Epoch: 5| Step: 4
Training loss: 1.0666927099227905
Validation loss: 1.7841576824906051

Epoch: 5| Step: 5
Training loss: 1.0771055221557617
Validation loss: 1.7587268198690107

Epoch: 5| Step: 6
Training loss: 0.49502119421958923
Validation loss: 1.7611724176714498

Epoch: 5| Step: 7
Training loss: 1.0113662481307983
Validation loss: 1.78018751195682

Epoch: 5| Step: 8
Training loss: 0.5079967975616455
Validation loss: 1.784705610685451

Epoch: 5| Step: 9
Training loss: 0.5232769250869751
Validation loss: 1.7677060275949457

Epoch: 5| Step: 10
Training loss: 0.831387996673584
Validation loss: 1.7284845921301073

Epoch: 447| Step: 0
Training loss: 0.6566667556762695
Validation loss: 1.699101524968301

Epoch: 5| Step: 1
Training loss: 1.1056104898452759
Validation loss: 1.7114320237149474

Epoch: 5| Step: 2
Training loss: 1.1258530616760254
Validation loss: 1.7278311098775556

Epoch: 5| Step: 3
Training loss: 0.5713696479797363
Validation loss: 1.657077399633264

Epoch: 5| Step: 4
Training loss: 0.8584342002868652
Validation loss: 1.6993466961768366

Epoch: 5| Step: 5
Training loss: 0.37377503514289856
Validation loss: 1.7437798912807176

Epoch: 5| Step: 6
Training loss: 0.8581827878952026
Validation loss: 1.7919032240426669

Epoch: 5| Step: 7
Training loss: 1.462723970413208
Validation loss: 1.834320100404883

Epoch: 5| Step: 8
Training loss: 0.655937671661377
Validation loss: 1.825297878634545

Epoch: 5| Step: 9
Training loss: 0.840528130531311
Validation loss: 1.7831388442747054

Epoch: 5| Step: 10
Training loss: 1.0457137823104858
Validation loss: 1.733785169098967

Epoch: 448| Step: 0
Training loss: 1.526505708694458
Validation loss: 1.7280667789520756

Epoch: 5| Step: 1
Training loss: 0.8843741416931152
Validation loss: 1.6703133659978067

Epoch: 5| Step: 2
Training loss: 0.5870057940483093
Validation loss: 1.6379602378414524

Epoch: 5| Step: 3
Training loss: 0.8906879425048828
Validation loss: 1.6479921148669334

Epoch: 5| Step: 4
Training loss: 1.0371496677398682
Validation loss: 1.6563849320975683

Epoch: 5| Step: 5
Training loss: 1.0144206285476685
Validation loss: 1.6558509142168107

Epoch: 5| Step: 6
Training loss: 0.7103018164634705
Validation loss: 1.6802729201573197

Epoch: 5| Step: 7
Training loss: 0.5732196569442749
Validation loss: 1.73388679950468

Epoch: 5| Step: 8
Training loss: 0.6592413783073425
Validation loss: 1.8326361461352276

Epoch: 5| Step: 9
Training loss: 0.9893283843994141
Validation loss: 1.8586208487069735

Epoch: 5| Step: 10
Training loss: 0.8210879564285278
Validation loss: 1.845860715835325

Epoch: 449| Step: 0
Training loss: 0.966249942779541
Validation loss: 1.8190559558970953

Epoch: 5| Step: 1
Training loss: 1.0518579483032227
Validation loss: 1.850458803997245

Epoch: 5| Step: 2
Training loss: 1.184915542602539
Validation loss: 1.8020055986219836

Epoch: 5| Step: 3
Training loss: 0.9220641851425171
Validation loss: 1.7364371361271027

Epoch: 5| Step: 4
Training loss: 0.6098815202713013
Validation loss: 1.6908924195074266

Epoch: 5| Step: 5
Training loss: 0.9963995814323425
Validation loss: 1.6953421190220823

Epoch: 5| Step: 6
Training loss: 0.7093586921691895
Validation loss: 1.6831043535663235

Epoch: 5| Step: 7
Training loss: 0.8398109674453735
Validation loss: 1.6625759716956847

Epoch: 5| Step: 8
Training loss: 0.7626031041145325
Validation loss: 1.732634739209247

Epoch: 5| Step: 9
Training loss: 0.4230721890926361
Validation loss: 1.743356345802225

Epoch: 5| Step: 10
Training loss: 0.8953100442886353
Validation loss: 1.7506776073927521

Epoch: 450| Step: 0
Training loss: 0.9857096672058105
Validation loss: 1.7780452325779905

Epoch: 5| Step: 1
Training loss: 0.3794601559638977
Validation loss: 1.8158503924646685

Epoch: 5| Step: 2
Training loss: 0.8134452700614929
Validation loss: 1.862951692714486

Epoch: 5| Step: 3
Training loss: 0.815827488899231
Validation loss: 1.819379634754632

Epoch: 5| Step: 4
Training loss: 1.266655683517456
Validation loss: 1.781858157086116

Epoch: 5| Step: 5
Training loss: 1.1211353540420532
Validation loss: 1.7265210267036193

Epoch: 5| Step: 6
Training loss: 0.6155922412872314
Validation loss: 1.687909310863864

Epoch: 5| Step: 7
Training loss: 0.4622930884361267
Validation loss: 1.6891407338521813

Epoch: 5| Step: 8
Training loss: 1.0524985790252686
Validation loss: 1.6851155437448972

Epoch: 5| Step: 9
Training loss: 0.9082118272781372
Validation loss: 1.6770683180901311

Epoch: 5| Step: 10
Training loss: 1.0456476211547852
Validation loss: 1.6712722086137342

Epoch: 451| Step: 0
Training loss: 1.0738729238510132
Validation loss: 1.6718454822417228

Epoch: 5| Step: 1
Training loss: 0.7206065654754639
Validation loss: 1.7181449359463108

Epoch: 5| Step: 2
Training loss: 0.7311440110206604
Validation loss: 1.6922805181113623

Epoch: 5| Step: 3
Training loss: 1.1846016645431519
Validation loss: 1.747601229657409

Epoch: 5| Step: 4
Training loss: 1.00507652759552
Validation loss: 1.7561125140036307

Epoch: 5| Step: 5
Training loss: 0.9343830943107605
Validation loss: 1.7789098947278914

Epoch: 5| Step: 6
Training loss: 0.5725192427635193
Validation loss: 1.812183871064135

Epoch: 5| Step: 7
Training loss: 0.8727858662605286
Validation loss: 1.7778991063435872

Epoch: 5| Step: 8
Training loss: 0.6783570647239685
Validation loss: 1.7754793654205978

Epoch: 5| Step: 9
Training loss: 0.8818948864936829
Validation loss: 1.7490197484211256

Epoch: 5| Step: 10
Training loss: 0.5730313658714294
Validation loss: 1.714838453518447

Epoch: 452| Step: 0
Training loss: 0.6795805096626282
Validation loss: 1.714449627425081

Epoch: 5| Step: 1
Training loss: 1.426865816116333
Validation loss: 1.7266456888568016

Epoch: 5| Step: 2
Training loss: 0.5381792187690735
Validation loss: 1.7125598999761766

Epoch: 5| Step: 3
Training loss: 0.5908499956130981
Validation loss: 1.7241645756588186

Epoch: 5| Step: 4
Training loss: 1.0059064626693726
Validation loss: 1.7408784410004974

Epoch: 5| Step: 5
Training loss: 0.6958891749382019
Validation loss: 1.7634711701382872

Epoch: 5| Step: 6
Training loss: 1.0490942001342773
Validation loss: 1.7581323667239117

Epoch: 5| Step: 7
Training loss: 0.6271418929100037
Validation loss: 1.7249634214626846

Epoch: 5| Step: 8
Training loss: 1.0877244472503662
Validation loss: 1.7621135122032576

Epoch: 5| Step: 9
Training loss: 0.7778189182281494
Validation loss: 1.7604137005344513

Epoch: 5| Step: 10
Training loss: 0.8075360655784607
Validation loss: 1.7387172073446295

Epoch: 453| Step: 0
Training loss: 1.4968833923339844
Validation loss: 1.7492975009384977

Epoch: 5| Step: 1
Training loss: 0.5725533962249756
Validation loss: 1.7535257800932853

Epoch: 5| Step: 2
Training loss: 1.2227174043655396
Validation loss: 1.7430612579468758

Epoch: 5| Step: 3
Training loss: 0.9992023706436157
Validation loss: 1.741798068887444

Epoch: 5| Step: 4
Training loss: 0.4266067445278168
Validation loss: 1.7299570678382792

Epoch: 5| Step: 5
Training loss: 0.8620689511299133
Validation loss: 1.7371955366544827

Epoch: 5| Step: 6
Training loss: 0.7161369323730469
Validation loss: 1.7285313324261737

Epoch: 5| Step: 7
Training loss: 0.6403425931930542
Validation loss: 1.7558549104198333

Epoch: 5| Step: 8
Training loss: 0.6123903393745422
Validation loss: 1.7459109944681968

Epoch: 5| Step: 9
Training loss: 0.7102009654045105
Validation loss: 1.7632667685067782

Epoch: 5| Step: 10
Training loss: 0.8504631519317627
Validation loss: 1.807510652849751

Epoch: 454| Step: 0
Training loss: 0.7717978954315186
Validation loss: 1.7866183006635277

Epoch: 5| Step: 1
Training loss: 0.8250028491020203
Validation loss: 1.7597790174586798

Epoch: 5| Step: 2
Training loss: 0.8249620199203491
Validation loss: 1.756252823337432

Epoch: 5| Step: 3
Training loss: 1.0300425291061401
Validation loss: 1.7035218041430238

Epoch: 5| Step: 4
Training loss: 0.6659139394760132
Validation loss: 1.7132198092758015

Epoch: 5| Step: 5
Training loss: 1.3185087442398071
Validation loss: 1.6828822051325152

Epoch: 5| Step: 6
Training loss: 0.35803496837615967
Validation loss: 1.6714654096993067

Epoch: 5| Step: 7
Training loss: 1.0196096897125244
Validation loss: 1.669389796513383

Epoch: 5| Step: 8
Training loss: 0.7625979781150818
Validation loss: 1.697914529872197

Epoch: 5| Step: 9
Training loss: 0.6505364179611206
Validation loss: 1.6672430230725197

Epoch: 5| Step: 10
Training loss: 0.7382908463478088
Validation loss: 1.6977893319181216

Epoch: 455| Step: 0
Training loss: 0.9513535499572754
Validation loss: 1.7198644966207526

Epoch: 5| Step: 1
Training loss: 0.8382920026779175
Validation loss: 1.7733515693295387

Epoch: 5| Step: 2
Training loss: 0.8137603998184204
Validation loss: 1.7795309764082714

Epoch: 5| Step: 3
Training loss: 0.6656109094619751
Validation loss: 1.748111729980797

Epoch: 5| Step: 4
Training loss: 0.6662001609802246
Validation loss: 1.7271442067238592

Epoch: 5| Step: 5
Training loss: 0.9919189214706421
Validation loss: 1.6964052736118276

Epoch: 5| Step: 6
Training loss: 0.6410549879074097
Validation loss: 1.6748722791671753

Epoch: 5| Step: 7
Training loss: 0.9222795367240906
Validation loss: 1.6644952143392255

Epoch: 5| Step: 8
Training loss: 0.9673691987991333
Validation loss: 1.6574728053103212

Epoch: 5| Step: 9
Training loss: 0.7874523997306824
Validation loss: 1.708608914447087

Epoch: 5| Step: 10
Training loss: 1.1351971626281738
Validation loss: 1.7126014130089873

Epoch: 456| Step: 0
Training loss: 0.7019610404968262
Validation loss: 1.7435192177372594

Epoch: 5| Step: 1
Training loss: 0.7413415908813477
Validation loss: 1.774021997246691

Epoch: 5| Step: 2
Training loss: 0.9916011095046997
Validation loss: 1.7991014590827368

Epoch: 5| Step: 3
Training loss: 0.8278342485427856
Validation loss: 1.7778196898839806

Epoch: 5| Step: 4
Training loss: 1.074022650718689
Validation loss: 1.753493752530826

Epoch: 5| Step: 5
Training loss: 0.7363995909690857
Validation loss: 1.73778441644484

Epoch: 5| Step: 6
Training loss: 0.9800580739974976
Validation loss: 1.7608975018224409

Epoch: 5| Step: 7
Training loss: 0.8571113348007202
Validation loss: 1.7613911064722205

Epoch: 5| Step: 8
Training loss: 0.7561812400817871
Validation loss: 1.7701607840035551

Epoch: 5| Step: 9
Training loss: 0.9813404083251953
Validation loss: 1.7252574095162012

Epoch: 5| Step: 10
Training loss: 0.5778433680534363
Validation loss: 1.7113364486284153

Epoch: 457| Step: 0
Training loss: 0.990138828754425
Validation loss: 1.7427423871973509

Epoch: 5| Step: 1
Training loss: 0.6107653975486755
Validation loss: 1.7302796199757566

Epoch: 5| Step: 2
Training loss: 0.7158702611923218
Validation loss: 1.7512111971455235

Epoch: 5| Step: 3
Training loss: 0.933261513710022
Validation loss: 1.746764317635567

Epoch: 5| Step: 4
Training loss: 0.9352355003356934
Validation loss: 1.7748339958088373

Epoch: 5| Step: 5
Training loss: 0.9711341857910156
Validation loss: 1.7708828526158487

Epoch: 5| Step: 6
Training loss: 0.9569244384765625
Validation loss: 1.77992642823086

Epoch: 5| Step: 7
Training loss: 0.8584142923355103
Validation loss: 1.764593824263542

Epoch: 5| Step: 8
Training loss: 0.5289570689201355
Validation loss: 1.7413599414210166

Epoch: 5| Step: 9
Training loss: 0.909866988658905
Validation loss: 1.7504158930111957

Epoch: 5| Step: 10
Training loss: 0.6555275917053223
Validation loss: 1.7320587506858252

Epoch: 458| Step: 0
Training loss: 0.8394225239753723
Validation loss: 1.7555003217471543

Epoch: 5| Step: 1
Training loss: 0.7189655303955078
Validation loss: 1.7844058852041922

Epoch: 5| Step: 2
Training loss: 0.7480353116989136
Validation loss: 1.7656806425381733

Epoch: 5| Step: 3
Training loss: 0.78289395570755
Validation loss: 1.7619680050880677

Epoch: 5| Step: 4
Training loss: 0.873274028301239
Validation loss: 1.7656292094979236

Epoch: 5| Step: 5
Training loss: 0.9076336622238159
Validation loss: 1.7323160440691057

Epoch: 5| Step: 6
Training loss: 0.6699439287185669
Validation loss: 1.7313522292721657

Epoch: 5| Step: 7
Training loss: 0.7555683851242065
Validation loss: 1.7323174630441973

Epoch: 5| Step: 8
Training loss: 0.6744059324264526
Validation loss: 1.7051211416080434

Epoch: 5| Step: 9
Training loss: 0.9684866666793823
Validation loss: 1.7054746894426243

Epoch: 5| Step: 10
Training loss: 0.9259524345397949
Validation loss: 1.6789378863508984

Epoch: 459| Step: 0
Training loss: 0.9368111491203308
Validation loss: 1.7106711864471436

Epoch: 5| Step: 1
Training loss: 0.6623031497001648
Validation loss: 1.7114705885610273

Epoch: 5| Step: 2
Training loss: 0.6252421140670776
Validation loss: 1.7378179386097898

Epoch: 5| Step: 3
Training loss: 0.929007887840271
Validation loss: 1.730284224274338

Epoch: 5| Step: 4
Training loss: 0.6180843710899353
Validation loss: 1.769333399752135

Epoch: 5| Step: 5
Training loss: 0.8158242106437683
Validation loss: 1.7802999147804834

Epoch: 5| Step: 6
Training loss: 1.000422477722168
Validation loss: 1.7759074908430859

Epoch: 5| Step: 7
Training loss: 0.5051937103271484
Validation loss: 1.7841686779452908

Epoch: 5| Step: 8
Training loss: 0.8232609629631042
Validation loss: 1.7600686357867332

Epoch: 5| Step: 9
Training loss: 0.8852740526199341
Validation loss: 1.7471435403311124

Epoch: 5| Step: 10
Training loss: 1.1032625436782837
Validation loss: 1.7437141479984406

Epoch: 460| Step: 0
Training loss: 0.7873350381851196
Validation loss: 1.70807683467865

Epoch: 5| Step: 1
Training loss: 1.0528672933578491
Validation loss: 1.699310116870429

Epoch: 5| Step: 2
Training loss: 0.7853572368621826
Validation loss: 1.7075040776242492

Epoch: 5| Step: 3
Training loss: 0.9963630437850952
Validation loss: 1.7390188786291307

Epoch: 5| Step: 4
Training loss: 0.7684037685394287
Validation loss: 1.7213358622725292

Epoch: 5| Step: 5
Training loss: 1.0980284214019775
Validation loss: 1.7355130462236301

Epoch: 5| Step: 6
Training loss: 0.433694064617157
Validation loss: 1.7703539966255106

Epoch: 5| Step: 7
Training loss: 0.446319043636322
Validation loss: 1.7530695917785808

Epoch: 5| Step: 8
Training loss: 1.2780447006225586
Validation loss: 1.7684831503898866

Epoch: 5| Step: 9
Training loss: 0.6234248876571655
Validation loss: 1.825857498312509

Epoch: 5| Step: 10
Training loss: 0.7811002135276794
Validation loss: 1.7702516150730911

Epoch: 461| Step: 0
Training loss: 0.8719383478164673
Validation loss: 1.7930555997356292

Epoch: 5| Step: 1
Training loss: 0.7776378393173218
Validation loss: 1.7121638162161714

Epoch: 5| Step: 2
Training loss: 0.8657029271125793
Validation loss: 1.7136036285790064

Epoch: 5| Step: 3
Training loss: 0.9221650958061218
Validation loss: 1.711045503616333

Epoch: 5| Step: 4
Training loss: 0.9482911825180054
Validation loss: 1.7054447076653922

Epoch: 5| Step: 5
Training loss: 0.8721162676811218
Validation loss: 1.7396266627055343

Epoch: 5| Step: 6
Training loss: 0.9212141036987305
Validation loss: 1.7462544389950332

Epoch: 5| Step: 7
Training loss: 0.8915845155715942
Validation loss: 1.7218783734947123

Epoch: 5| Step: 8
Training loss: 0.6108408570289612
Validation loss: 1.7599858212214645

Epoch: 5| Step: 9
Training loss: 0.6871627569198608
Validation loss: 1.7423000322875155

Epoch: 5| Step: 10
Training loss: 0.6527164578437805
Validation loss: 1.770521443377259

Epoch: 462| Step: 0
Training loss: 0.7896522283554077
Validation loss: 1.761128605052989

Epoch: 5| Step: 1
Training loss: 0.8509367108345032
Validation loss: 1.6986748774846394

Epoch: 5| Step: 2
Training loss: 0.7742564678192139
Validation loss: 1.6892121479075441

Epoch: 5| Step: 3
Training loss: 1.196869134902954
Validation loss: 1.6936680693780222

Epoch: 5| Step: 4
Training loss: 0.7499960660934448
Validation loss: 1.6894103339923325

Epoch: 5| Step: 5
Training loss: 0.6128727793693542
Validation loss: 1.6999003451357606

Epoch: 5| Step: 6
Training loss: 0.5741671323776245
Validation loss: 1.6764871894672353

Epoch: 5| Step: 7
Training loss: 0.5734984278678894
Validation loss: 1.6999330841084963

Epoch: 5| Step: 8
Training loss: 0.9493149518966675
Validation loss: 1.7560883055451095

Epoch: 5| Step: 9
Training loss: 0.5911710262298584
Validation loss: 1.7604293880924102

Epoch: 5| Step: 10
Training loss: 1.430088996887207
Validation loss: 1.8258985575809275

Epoch: 463| Step: 0
Training loss: 1.095763087272644
Validation loss: 1.849569636006509

Epoch: 5| Step: 1
Training loss: 0.8845847845077515
Validation loss: 1.8909250305544945

Epoch: 5| Step: 2
Training loss: 1.0920881032943726
Validation loss: 1.7900911479867914

Epoch: 5| Step: 3
Training loss: 0.9178472757339478
Validation loss: 1.7674122753963675

Epoch: 5| Step: 4
Training loss: 0.7247761487960815
Validation loss: 1.7374450186247468

Epoch: 5| Step: 5
Training loss: 0.6908015608787537
Validation loss: 1.7168141949561335

Epoch: 5| Step: 6
Training loss: 0.664361298084259
Validation loss: 1.682580158274661

Epoch: 5| Step: 7
Training loss: 0.7456488609313965
Validation loss: 1.6711706089717087

Epoch: 5| Step: 8
Training loss: 0.7869869470596313
Validation loss: 1.6710852935749998

Epoch: 5| Step: 9
Training loss: 0.7097527980804443
Validation loss: 1.6833170242207025

Epoch: 5| Step: 10
Training loss: 0.8900003433227539
Validation loss: 1.6903150466180616

Epoch: 464| Step: 0
Training loss: 0.5455933809280396
Validation loss: 1.7188831965128581

Epoch: 5| Step: 1
Training loss: 0.6437052488327026
Validation loss: 1.7142883372563187

Epoch: 5| Step: 2
Training loss: 0.8608235120773315
Validation loss: 1.7159985957607147

Epoch: 5| Step: 3
Training loss: 0.694654643535614
Validation loss: 1.7616671080230384

Epoch: 5| Step: 4
Training loss: 1.2699248790740967
Validation loss: 1.7674172334773566

Epoch: 5| Step: 5
Training loss: 0.9189766645431519
Validation loss: 1.7658257689527286

Epoch: 5| Step: 6
Training loss: 1.0194138288497925
Validation loss: 1.7636509813288206

Epoch: 5| Step: 7
Training loss: 0.44204455614089966
Validation loss: 1.748104827378386

Epoch: 5| Step: 8
Training loss: 0.6455574631690979
Validation loss: 1.7623959267011253

Epoch: 5| Step: 9
Training loss: 0.7446199655532837
Validation loss: 1.742932975933116

Epoch: 5| Step: 10
Training loss: 0.8341745138168335
Validation loss: 1.744979517434233

Epoch: 465| Step: 0
Training loss: 0.8082417249679565
Validation loss: 1.6822568844723444

Epoch: 5| Step: 1
Training loss: 0.6511397361755371
Validation loss: 1.689789702174484

Epoch: 5| Step: 2
Training loss: 0.6559266448020935
Validation loss: 1.6709021214515931

Epoch: 5| Step: 3
Training loss: 0.7831516861915588
Validation loss: 1.6625471653476838

Epoch: 5| Step: 4
Training loss: 0.939254641532898
Validation loss: 1.6824029735339585

Epoch: 5| Step: 5
Training loss: 0.7339118123054504
Validation loss: 1.6920488970254057

Epoch: 5| Step: 6
Training loss: 0.9061859250068665
Validation loss: 1.7157271882539153

Epoch: 5| Step: 7
Training loss: 0.635979950428009
Validation loss: 1.7475400304281583

Epoch: 5| Step: 8
Training loss: 0.5450980067253113
Validation loss: 1.7590982247424383

Epoch: 5| Step: 9
Training loss: 1.0278944969177246
Validation loss: 1.716809190729613

Epoch: 5| Step: 10
Training loss: 1.1572496891021729
Validation loss: 1.715005292687365

Epoch: 466| Step: 0
Training loss: 0.5139118432998657
Validation loss: 1.7034382384310487

Epoch: 5| Step: 1
Training loss: 0.8910864591598511
Validation loss: 1.7004048824310303

Epoch: 5| Step: 2
Training loss: 1.076308012008667
Validation loss: 1.6787735262224752

Epoch: 5| Step: 3
Training loss: 0.8411456346511841
Validation loss: 1.671291212881765

Epoch: 5| Step: 4
Training loss: 0.5327158570289612
Validation loss: 1.6771760525241974

Epoch: 5| Step: 5
Training loss: 0.8572530746459961
Validation loss: 1.6861899091351418

Epoch: 5| Step: 6
Training loss: 1.011958360671997
Validation loss: 1.7326254524210447

Epoch: 5| Step: 7
Training loss: 0.6352571249008179
Validation loss: 1.7446331362570486

Epoch: 5| Step: 8
Training loss: 0.7263003587722778
Validation loss: 1.7257881215823594

Epoch: 5| Step: 9
Training loss: 0.8775436282157898
Validation loss: 1.7247419716209493

Epoch: 5| Step: 10
Training loss: 0.7186003923416138
Validation loss: 1.6931834490068498

Epoch: 467| Step: 0
Training loss: 0.378153532743454
Validation loss: 1.7214451554001018

Epoch: 5| Step: 1
Training loss: 1.0116772651672363
Validation loss: 1.7048643481346868

Epoch: 5| Step: 2
Training loss: 0.4083167612552643
Validation loss: 1.7790856489571192

Epoch: 5| Step: 3
Training loss: 0.6443269848823547
Validation loss: 1.7482188042773996

Epoch: 5| Step: 4
Training loss: 1.0816066265106201
Validation loss: 1.727335153087493

Epoch: 5| Step: 5
Training loss: 0.8217673301696777
Validation loss: 1.7211011866087556

Epoch: 5| Step: 6
Training loss: 0.7218402624130249
Validation loss: 1.68278589171748

Epoch: 5| Step: 7
Training loss: 0.7977537512779236
Validation loss: 1.6842457273954987

Epoch: 5| Step: 8
Training loss: 0.787345290184021
Validation loss: 1.6784453686847483

Epoch: 5| Step: 9
Training loss: 0.9887788891792297
Validation loss: 1.6704472546936364

Epoch: 5| Step: 10
Training loss: 1.0583045482635498
Validation loss: 1.7143975970565632

Epoch: 468| Step: 0
Training loss: 0.4175395965576172
Validation loss: 1.7113522752638786

Epoch: 5| Step: 1
Training loss: 0.7558640241622925
Validation loss: 1.7068953450008104

Epoch: 5| Step: 2
Training loss: 0.7992681264877319
Validation loss: 1.6985372445916618

Epoch: 5| Step: 3
Training loss: 0.860880970954895
Validation loss: 1.7030491264917518

Epoch: 5| Step: 4
Training loss: 0.6882206201553345
Validation loss: 1.6915557512672998

Epoch: 5| Step: 5
Training loss: 0.9121736288070679
Validation loss: 1.6840714587960193

Epoch: 5| Step: 6
Training loss: 0.76652991771698
Validation loss: 1.6805778293199436

Epoch: 5| Step: 7
Training loss: 0.9111440777778625
Validation loss: 1.6654223421568513

Epoch: 5| Step: 8
Training loss: 1.0234867334365845
Validation loss: 1.678637610968723

Epoch: 5| Step: 9
Training loss: 0.8795514106750488
Validation loss: 1.6875457391943982

Epoch: 5| Step: 10
Training loss: 0.5591359734535217
Validation loss: 1.6867031205085017

Epoch: 469| Step: 0
Training loss: 0.6548059582710266
Validation loss: 1.7024215716187672

Epoch: 5| Step: 1
Training loss: 0.7662392854690552
Validation loss: 1.7307257319009433

Epoch: 5| Step: 2
Training loss: 0.6319471597671509
Validation loss: 1.7298211282299412

Epoch: 5| Step: 3
Training loss: 0.8941853642463684
Validation loss: 1.710231706660281

Epoch: 5| Step: 4
Training loss: 0.7916966676712036
Validation loss: 1.7342964462054673

Epoch: 5| Step: 5
Training loss: 0.5875656604766846
Validation loss: 1.6914849640220724

Epoch: 5| Step: 6
Training loss: 0.9427655935287476
Validation loss: 1.7154923959444928

Epoch: 5| Step: 7
Training loss: 1.0672733783721924
Validation loss: 1.713410703084802

Epoch: 5| Step: 8
Training loss: 0.5869182348251343
Validation loss: 1.6830147209987845

Epoch: 5| Step: 9
Training loss: 1.0916965007781982
Validation loss: 1.7013761984404696

Epoch: 5| Step: 10
Training loss: 0.649482786655426
Validation loss: 1.6963868628266037

Epoch: 470| Step: 0
Training loss: 1.1018288135528564
Validation loss: 1.7015053892648349

Epoch: 5| Step: 1
Training loss: 0.6824771165847778
Validation loss: 1.720450524360903

Epoch: 5| Step: 2
Training loss: 0.6929135918617249
Validation loss: 1.710625002461095

Epoch: 5| Step: 3
Training loss: 0.8526407480239868
Validation loss: 1.6828325692043509

Epoch: 5| Step: 4
Training loss: 0.5685564875602722
Validation loss: 1.691754159107003

Epoch: 5| Step: 5
Training loss: 1.12630295753479
Validation loss: 1.7255579604897449

Epoch: 5| Step: 6
Training loss: 0.2775402367115021
Validation loss: 1.7449674016685897

Epoch: 5| Step: 7
Training loss: 0.9616378545761108
Validation loss: 1.7797382352172688

Epoch: 5| Step: 8
Training loss: 0.9522735476493835
Validation loss: 1.7769136377560195

Epoch: 5| Step: 9
Training loss: 0.6607519388198853
Validation loss: 1.7491013567934754

Epoch: 5| Step: 10
Training loss: 1.0849248170852661
Validation loss: 1.7191331348111552

Epoch: 471| Step: 0
Training loss: 0.6373018026351929
Validation loss: 1.6711596250534058

Epoch: 5| Step: 1
Training loss: 0.8578413128852844
Validation loss: 1.6729722689556819

Epoch: 5| Step: 2
Training loss: 0.8241193890571594
Validation loss: 1.680673312115413

Epoch: 5| Step: 3
Training loss: 1.2455275058746338
Validation loss: 1.6858767463314919

Epoch: 5| Step: 4
Training loss: 0.7271021008491516
Validation loss: 1.6992703599314536

Epoch: 5| Step: 5
Training loss: 0.3713056445121765
Validation loss: 1.6797112662305114

Epoch: 5| Step: 6
Training loss: 0.7312241792678833
Validation loss: 1.7076458072149625

Epoch: 5| Step: 7
Training loss: 1.1724317073822021
Validation loss: 1.7234190381983274

Epoch: 5| Step: 8
Training loss: 0.7167038917541504
Validation loss: 1.727174150046482

Epoch: 5| Step: 9
Training loss: 0.6387061476707458
Validation loss: 1.6917136048757901

Epoch: 5| Step: 10
Training loss: 0.6585554480552673
Validation loss: 1.7101000175681165

Epoch: 472| Step: 0
Training loss: 0.36056044697761536
Validation loss: 1.7215330921193606

Epoch: 5| Step: 1
Training loss: 0.650501549243927
Validation loss: 1.7342873132357033

Epoch: 5| Step: 2
Training loss: 0.7518742084503174
Validation loss: 1.734421363440893

Epoch: 5| Step: 3
Training loss: 0.4924878478050232
Validation loss: 1.7422192865802395

Epoch: 5| Step: 4
Training loss: 0.7536875009536743
Validation loss: 1.7046113680767756

Epoch: 5| Step: 5
Training loss: 1.0175793170928955
Validation loss: 1.716469375036096

Epoch: 5| Step: 6
Training loss: 0.9365118145942688
Validation loss: 1.7208003715802265

Epoch: 5| Step: 7
Training loss: 1.094739317893982
Validation loss: 1.6634292141083749

Epoch: 5| Step: 8
Training loss: 1.004692792892456
Validation loss: 1.6802431255258539

Epoch: 5| Step: 9
Training loss: 0.5637606382369995
Validation loss: 1.6515848444354149

Epoch: 5| Step: 10
Training loss: 1.0314449071884155
Validation loss: 1.6911028501808003

Epoch: 473| Step: 0
Training loss: 0.9642280340194702
Validation loss: 1.6480564109740719

Epoch: 5| Step: 1
Training loss: 0.6183947324752808
Validation loss: 1.694549440055765

Epoch: 5| Step: 2
Training loss: 0.9746187329292297
Validation loss: 1.6694789009709512

Epoch: 5| Step: 3
Training loss: 0.720731258392334
Validation loss: 1.7045932187828967

Epoch: 5| Step: 4
Training loss: 0.714844822883606
Validation loss: 1.776802127079297

Epoch: 5| Step: 5
Training loss: 0.6954116225242615
Validation loss: 1.8078264600487166

Epoch: 5| Step: 6
Training loss: 1.003539800643921
Validation loss: 1.8433540918493783

Epoch: 5| Step: 7
Training loss: 1.0999006032943726
Validation loss: 1.8250070246317054

Epoch: 5| Step: 8
Training loss: 0.47694188356399536
Validation loss: 1.7853254015727709

Epoch: 5| Step: 9
Training loss: 0.9166873693466187
Validation loss: 1.7741968439471336

Epoch: 5| Step: 10
Training loss: 0.5779102444648743
Validation loss: 1.7178159016434864

Epoch: 474| Step: 0
Training loss: 0.9627425074577332
Validation loss: 1.6912363818896714

Epoch: 5| Step: 1
Training loss: 0.6005944609642029
Validation loss: 1.6420448172476985

Epoch: 5| Step: 2
Training loss: 0.6774824261665344
Validation loss: 1.6517112537096905

Epoch: 5| Step: 3
Training loss: 1.081106185913086
Validation loss: 1.64636787163314

Epoch: 5| Step: 4
Training loss: 0.8440910577774048
Validation loss: 1.6632044520429385

Epoch: 5| Step: 5
Training loss: 1.007918119430542
Validation loss: 1.6998908212107997

Epoch: 5| Step: 6
Training loss: 0.7119024991989136
Validation loss: 1.7157723749837568

Epoch: 5| Step: 7
Training loss: 0.6680583357810974
Validation loss: 1.7172814825529694

Epoch: 5| Step: 8
Training loss: 0.6518703699111938
Validation loss: 1.7522237800782727

Epoch: 5| Step: 9
Training loss: 0.6509321928024292
Validation loss: 1.7535093497204524

Epoch: 5| Step: 10
Training loss: 1.1268872022628784
Validation loss: 1.8186283188481485

Epoch: 475| Step: 0
Training loss: 0.9464315176010132
Validation loss: 1.7836315144774735

Epoch: 5| Step: 1
Training loss: 0.9972265958786011
Validation loss: 1.7550938885699037

Epoch: 5| Step: 2
Training loss: 0.7135363817214966
Validation loss: 1.7584543971605198

Epoch: 5| Step: 3
Training loss: 0.6707810163497925
Validation loss: 1.75582472226953

Epoch: 5| Step: 4
Training loss: 0.6097384691238403
Validation loss: 1.6789911767487884

Epoch: 5| Step: 5
Training loss: 0.5479667782783508
Validation loss: 1.6694325157391128

Epoch: 5| Step: 6
Training loss: 1.1025153398513794
Validation loss: 1.6463425364545596

Epoch: 5| Step: 7
Training loss: 0.8986786007881165
Validation loss: 1.6726208861156175

Epoch: 5| Step: 8
Training loss: 1.1725099086761475
Validation loss: 1.6687632376147854

Epoch: 5| Step: 9
Training loss: 0.6936704516410828
Validation loss: 1.6810556868071198

Epoch: 5| Step: 10
Training loss: 0.5920760631561279
Validation loss: 1.7130242957863757

Epoch: 476| Step: 0
Training loss: 0.7456100583076477
Validation loss: 1.7138847779202204

Epoch: 5| Step: 1
Training loss: 0.8869379162788391
Validation loss: 1.7834797341336486

Epoch: 5| Step: 2
Training loss: 0.9727073907852173
Validation loss: 1.8168790071241316

Epoch: 5| Step: 3
Training loss: 0.5700191259384155
Validation loss: 1.8235374548101937

Epoch: 5| Step: 4
Training loss: 1.4296855926513672
Validation loss: 1.789112373064923

Epoch: 5| Step: 5
Training loss: 0.48033127188682556
Validation loss: 1.7624363617230487

Epoch: 5| Step: 6
Training loss: 0.7546338438987732
Validation loss: 1.7490087042572677

Epoch: 5| Step: 7
Training loss: 0.6138635873794556
Validation loss: 1.7069253178053005

Epoch: 5| Step: 8
Training loss: 0.5132818818092346
Validation loss: 1.6711164828269713

Epoch: 5| Step: 9
Training loss: 0.548974871635437
Validation loss: 1.6512162557212255

Epoch: 5| Step: 10
Training loss: 1.163394570350647
Validation loss: 1.658623199309072

Epoch: 477| Step: 0
Training loss: 0.8438085317611694
Validation loss: 1.6517057752096524

Epoch: 5| Step: 1
Training loss: 0.4619651436805725
Validation loss: 1.6808514966759631

Epoch: 5| Step: 2
Training loss: 1.0672584772109985
Validation loss: 1.7093959021311935

Epoch: 5| Step: 3
Training loss: 1.086146593093872
Validation loss: 1.732707469694076

Epoch: 5| Step: 4
Training loss: 0.7614594101905823
Validation loss: 1.7239993759380874

Epoch: 5| Step: 5
Training loss: 0.88200843334198
Validation loss: 1.7698711041481263

Epoch: 5| Step: 6
Training loss: 0.8024576902389526
Validation loss: 1.7469071457462926

Epoch: 5| Step: 7
Training loss: 0.883602499961853
Validation loss: 1.7640564698044972

Epoch: 5| Step: 8
Training loss: 0.3156062662601471
Validation loss: 1.7300313954712243

Epoch: 5| Step: 9
Training loss: 0.6651386618614197
Validation loss: 1.7116664071236887

Epoch: 5| Step: 10
Training loss: 0.788917601108551
Validation loss: 1.6869231424024027

Epoch: 478| Step: 0
Training loss: 0.6858425140380859
Validation loss: 1.6926431117519256

Epoch: 5| Step: 1
Training loss: 0.8810327649116516
Validation loss: 1.6519018142454085

Epoch: 5| Step: 2
Training loss: 0.8719944953918457
Validation loss: 1.667161549291303

Epoch: 5| Step: 3
Training loss: 1.0102214813232422
Validation loss: 1.644118139820714

Epoch: 5| Step: 4
Training loss: 0.7920405268669128
Validation loss: 1.6468586716600644

Epoch: 5| Step: 5
Training loss: 0.4436158239841461
Validation loss: 1.661924180164132

Epoch: 5| Step: 6
Training loss: 0.7553256750106812
Validation loss: 1.6764959276363414

Epoch: 5| Step: 7
Training loss: 0.8655813932418823
Validation loss: 1.709872507279919

Epoch: 5| Step: 8
Training loss: 0.522813618183136
Validation loss: 1.7515957470863097

Epoch: 5| Step: 9
Training loss: 0.7621196508407593
Validation loss: 1.761833498554845

Epoch: 5| Step: 10
Training loss: 0.8352839350700378
Validation loss: 1.7564551163745183

Epoch: 479| Step: 0
Training loss: 1.0253738164901733
Validation loss: 1.729524484244726

Epoch: 5| Step: 1
Training loss: 0.987453281879425
Validation loss: 1.7277083986548967

Epoch: 5| Step: 2
Training loss: 0.5680691003799438
Validation loss: 1.7110911171923402

Epoch: 5| Step: 3
Training loss: 0.5299968719482422
Validation loss: 1.6673860857563634

Epoch: 5| Step: 4
Training loss: 0.8011013865470886
Validation loss: 1.6351230913592922

Epoch: 5| Step: 5
Training loss: 0.5976236462593079
Validation loss: 1.6728399991989136

Epoch: 5| Step: 6
Training loss: 0.5446006059646606
Validation loss: 1.671055575852753

Epoch: 5| Step: 7
Training loss: 0.8521884083747864
Validation loss: 1.6580147538133847

Epoch: 5| Step: 8
Training loss: 1.18294358253479
Validation loss: 1.6536742705170826

Epoch: 5| Step: 9
Training loss: 0.8977915048599243
Validation loss: 1.6948622657406716

Epoch: 5| Step: 10
Training loss: 0.49113643169403076
Validation loss: 1.693207222928283

Epoch: 480| Step: 0
Training loss: 0.8202048540115356
Validation loss: 1.7060841386036207

Epoch: 5| Step: 1
Training loss: 0.6668251752853394
Validation loss: 1.7590089087845178

Epoch: 5| Step: 2
Training loss: 0.9113539457321167
Validation loss: 1.7057972274800783

Epoch: 5| Step: 3
Training loss: 0.8707811236381531
Validation loss: 1.6863075443493423

Epoch: 5| Step: 4
Training loss: 0.7982837557792664
Validation loss: 1.664004123339089

Epoch: 5| Step: 5
Training loss: 0.5597516298294067
Validation loss: 1.7059358448110602

Epoch: 5| Step: 6
Training loss: 0.8730759620666504
Validation loss: 1.6691135757712907

Epoch: 5| Step: 7
Training loss: 1.0941656827926636
Validation loss: 1.6565898861936343

Epoch: 5| Step: 8
Training loss: 0.4060855507850647
Validation loss: 1.6727732868604763

Epoch: 5| Step: 9
Training loss: 0.6723834872245789
Validation loss: 1.669204169704068

Epoch: 5| Step: 10
Training loss: 0.6456749439239502
Validation loss: 1.71131085195849

Epoch: 481| Step: 0
Training loss: 0.7486406564712524
Validation loss: 1.73074221739205

Epoch: 5| Step: 1
Training loss: 0.5357515215873718
Validation loss: 1.7443216552016556

Epoch: 5| Step: 2
Training loss: 0.6624711751937866
Validation loss: 1.7489039680009246

Epoch: 5| Step: 3
Training loss: 1.0651054382324219
Validation loss: 1.7085509864232873

Epoch: 5| Step: 4
Training loss: 0.8668753504753113
Validation loss: 1.6613547314879715

Epoch: 5| Step: 5
Training loss: 0.9260212182998657
Validation loss: 1.6391724463432067

Epoch: 5| Step: 6
Training loss: 0.9912662506103516
Validation loss: 1.615547808267737

Epoch: 5| Step: 7
Training loss: 0.8677700161933899
Validation loss: 1.6121323031763877

Epoch: 5| Step: 8
Training loss: 0.5268216133117676
Validation loss: 1.6572149979170931

Epoch: 5| Step: 9
Training loss: 1.016689658164978
Validation loss: 1.654683239998356

Epoch: 5| Step: 10
Training loss: 0.36557942628860474
Validation loss: 1.6823915018830249

Epoch: 482| Step: 0
Training loss: 1.0256526470184326
Validation loss: 1.6955748488826137

Epoch: 5| Step: 1
Training loss: 0.6796642541885376
Validation loss: 1.7277762146406277

Epoch: 5| Step: 2
Training loss: 0.7128718495368958
Validation loss: 1.7479033700881466

Epoch: 5| Step: 3
Training loss: 0.9991605877876282
Validation loss: 1.796614953266677

Epoch: 5| Step: 4
Training loss: 0.7082949876785278
Validation loss: 1.7971494633664367

Epoch: 5| Step: 5
Training loss: 0.5639032125473022
Validation loss: 1.7864896789673836

Epoch: 5| Step: 6
Training loss: 0.7241545915603638
Validation loss: 1.8003514838475052

Epoch: 5| Step: 7
Training loss: 0.546051025390625
Validation loss: 1.7493569799648818

Epoch: 5| Step: 8
Training loss: 0.7454417943954468
Validation loss: 1.7384930567074848

Epoch: 5| Step: 9
Training loss: 0.9974961280822754
Validation loss: 1.718390154582198

Epoch: 5| Step: 10
Training loss: 0.682593047618866
Validation loss: 1.7095340977432907

Epoch: 483| Step: 0
Training loss: 0.43380799889564514
Validation loss: 1.712501871970392

Epoch: 5| Step: 1
Training loss: 0.9396421313285828
Validation loss: 1.7147780054359025

Epoch: 5| Step: 2
Training loss: 0.6952086687088013
Validation loss: 1.7248864161070956

Epoch: 5| Step: 3
Training loss: 0.7445014119148254
Validation loss: 1.7116756118753904

Epoch: 5| Step: 4
Training loss: 0.8361576199531555
Validation loss: 1.7065718917436496

Epoch: 5| Step: 5
Training loss: 0.6893733143806458
Validation loss: 1.7072226937099169

Epoch: 5| Step: 6
Training loss: 0.8678027987480164
Validation loss: 1.6897822721030122

Epoch: 5| Step: 7
Training loss: 0.8229357600212097
Validation loss: 1.6949717255048855

Epoch: 5| Step: 8
Training loss: 0.7856107950210571
Validation loss: 1.7279920321638866

Epoch: 5| Step: 9
Training loss: 0.46741390228271484
Validation loss: 1.6974159735505299

Epoch: 5| Step: 10
Training loss: 0.817359983921051
Validation loss: 1.6890547775453137

Epoch: 484| Step: 0
Training loss: 0.3849669098854065
Validation loss: 1.721430188866072

Epoch: 5| Step: 1
Training loss: 0.868586540222168
Validation loss: 1.724482613225137

Epoch: 5| Step: 2
Training loss: 0.96654212474823
Validation loss: 1.7268938761885448

Epoch: 5| Step: 3
Training loss: 0.7528196573257446
Validation loss: 1.7386201632920133

Epoch: 5| Step: 4
Training loss: 0.7514674663543701
Validation loss: 1.7448561012103994

Epoch: 5| Step: 5
Training loss: 0.564543604850769
Validation loss: 1.6968429960230345

Epoch: 5| Step: 6
Training loss: 0.8770330548286438
Validation loss: 1.7098193399367794

Epoch: 5| Step: 7
Training loss: 1.0587148666381836
Validation loss: 1.6984641757062686

Epoch: 5| Step: 8
Training loss: 0.796351432800293
Validation loss: 1.6845808285538868

Epoch: 5| Step: 9
Training loss: 0.7422842979431152
Validation loss: 1.738534294148927

Epoch: 5| Step: 10
Training loss: 0.4016704261302948
Validation loss: 1.73378844927716

Epoch: 485| Step: 0
Training loss: 0.6813880801200867
Validation loss: 1.7291902201150053

Epoch: 5| Step: 1
Training loss: 0.645423948764801
Validation loss: 1.7643123506217875

Epoch: 5| Step: 2
Training loss: 0.7532001733779907
Validation loss: 1.7883563938961233

Epoch: 5| Step: 3
Training loss: 0.7544742822647095
Validation loss: 1.7336407169218986

Epoch: 5| Step: 4
Training loss: 0.5310627818107605
Validation loss: 1.7422224488309634

Epoch: 5| Step: 5
Training loss: 0.7789427638053894
Validation loss: 1.744054909675352

Epoch: 5| Step: 6
Training loss: 0.8487004041671753
Validation loss: 1.7246952223521408

Epoch: 5| Step: 7
Training loss: 0.9480836987495422
Validation loss: 1.7234184011336295

Epoch: 5| Step: 8
Training loss: 0.6248345971107483
Validation loss: 1.7128097267561062

Epoch: 5| Step: 9
Training loss: 0.7950097322463989
Validation loss: 1.6948917027442687

Epoch: 5| Step: 10
Training loss: 0.691443145275116
Validation loss: 1.6752714457050446

Epoch: 486| Step: 0
Training loss: 0.6619325280189514
Validation loss: 1.663000855394589

Epoch: 5| Step: 1
Training loss: 0.7840489149093628
Validation loss: 1.662501472298817

Epoch: 5| Step: 2
Training loss: 0.6382302641868591
Validation loss: 1.6831622508264357

Epoch: 5| Step: 3
Training loss: 0.9481102824211121
Validation loss: 1.657568266314845

Epoch: 5| Step: 4
Training loss: 0.5618695020675659
Validation loss: 1.6944478045227707

Epoch: 5| Step: 5
Training loss: 0.3520401120185852
Validation loss: 1.7175441070269513

Epoch: 5| Step: 6
Training loss: 1.290235996246338
Validation loss: 1.7070404329607565

Epoch: 5| Step: 7
Training loss: 0.48389023542404175
Validation loss: 1.7059941778900802

Epoch: 5| Step: 8
Training loss: 0.6248564720153809
Validation loss: 1.7144388806435369

Epoch: 5| Step: 9
Training loss: 0.6277832984924316
Validation loss: 1.7270390141394831

Epoch: 5| Step: 10
Training loss: 1.0993684530258179
Validation loss: 1.704137038159114

Epoch: 487| Step: 0
Training loss: 0.6410790085792542
Validation loss: 1.6720738193040252

Epoch: 5| Step: 1
Training loss: 0.6830865144729614
Validation loss: 1.619738369859675

Epoch: 5| Step: 2
Training loss: 0.7537749409675598
Validation loss: 1.6834742689645419

Epoch: 5| Step: 3
Training loss: 1.1202199459075928
Validation loss: 1.6400943686885219

Epoch: 5| Step: 4
Training loss: 0.7088692784309387
Validation loss: 1.6684240359132008

Epoch: 5| Step: 5
Training loss: 0.5259575843811035
Validation loss: 1.6906964118762682

Epoch: 5| Step: 6
Training loss: 0.9192012548446655
Validation loss: 1.7423006180794007

Epoch: 5| Step: 7
Training loss: 0.8487342596054077
Validation loss: 1.740899880727132

Epoch: 5| Step: 8
Training loss: 0.9185201525688171
Validation loss: 1.6878997190024263

Epoch: 5| Step: 9
Training loss: 0.6405432820320129
Validation loss: 1.6761193634361349

Epoch: 5| Step: 10
Training loss: 0.45846474170684814
Validation loss: 1.6527804700277184

Epoch: 488| Step: 0
Training loss: 0.6868191957473755
Validation loss: 1.6596652051453948

Epoch: 5| Step: 1
Training loss: 0.7207082509994507
Validation loss: 1.6626940811834028

Epoch: 5| Step: 2
Training loss: 0.8841110467910767
Validation loss: 1.6555655438412902

Epoch: 5| Step: 3
Training loss: 0.8663527369499207
Validation loss: 1.7075183942753782

Epoch: 5| Step: 4
Training loss: 0.6636027097702026
Validation loss: 1.7245428151981805

Epoch: 5| Step: 5
Training loss: 0.5739367604255676
Validation loss: 1.7394664954113703

Epoch: 5| Step: 6
Training loss: 0.6630256175994873
Validation loss: 1.736098458690028

Epoch: 5| Step: 7
Training loss: 0.6261255145072937
Validation loss: 1.7109595614094888

Epoch: 5| Step: 8
Training loss: 0.5065432190895081
Validation loss: 1.6660295481322913

Epoch: 5| Step: 9
Training loss: 1.1119322776794434
Validation loss: 1.6776780582243396

Epoch: 5| Step: 10
Training loss: 0.7674914002418518
Validation loss: 1.66582570152898

Epoch: 489| Step: 0
Training loss: 0.6214281916618347
Validation loss: 1.6810123048802859

Epoch: 5| Step: 1
Training loss: 0.9910763502120972
Validation loss: 1.6533105565655617

Epoch: 5| Step: 2
Training loss: 0.681187093257904
Validation loss: 1.688652983916703

Epoch: 5| Step: 3
Training loss: 0.8396687507629395
Validation loss: 1.7073986466212938

Epoch: 5| Step: 4
Training loss: 0.6616924405097961
Validation loss: 1.7133437036186137

Epoch: 5| Step: 5
Training loss: 1.0106168985366821
Validation loss: 1.7284513250474007

Epoch: 5| Step: 6
Training loss: 0.6022966504096985
Validation loss: 1.7319499523408952

Epoch: 5| Step: 7
Training loss: 0.6196783185005188
Validation loss: 1.7731373822817238

Epoch: 5| Step: 8
Training loss: 0.6460293531417847
Validation loss: 1.7914012068061418

Epoch: 5| Step: 9
Training loss: 0.6748218536376953
Validation loss: 1.737432276048968

Epoch: 5| Step: 10
Training loss: 0.7935088872909546
Validation loss: 1.7284564754014373

Epoch: 490| Step: 0
Training loss: 0.8477363586425781
Validation loss: 1.7060222536004999

Epoch: 5| Step: 1
Training loss: 0.7047961950302124
Validation loss: 1.6627746012903029

Epoch: 5| Step: 2
Training loss: 0.7458977103233337
Validation loss: 1.6758405495715398

Epoch: 5| Step: 3
Training loss: 0.7352679371833801
Validation loss: 1.6803243724248742

Epoch: 5| Step: 4
Training loss: 0.8522626161575317
Validation loss: 1.660174245475441

Epoch: 5| Step: 5
Training loss: 0.6051116585731506
Validation loss: 1.6772158248450166

Epoch: 5| Step: 6
Training loss: 0.8976482152938843
Validation loss: 1.7095480401028869

Epoch: 5| Step: 7
Training loss: 0.8855430483818054
Validation loss: 1.697714356965916

Epoch: 5| Step: 8
Training loss: 0.6486326456069946
Validation loss: 1.743626327924831

Epoch: 5| Step: 9
Training loss: 0.5092681050300598
Validation loss: 1.779505609184183

Epoch: 5| Step: 10
Training loss: 0.7388506531715393
Validation loss: 1.7657203289770311

Epoch: 491| Step: 0
Training loss: 1.1782710552215576
Validation loss: 1.7377328795771445

Epoch: 5| Step: 1
Training loss: 0.8199467658996582
Validation loss: 1.6951698013531264

Epoch: 5| Step: 2
Training loss: 0.5514858961105347
Validation loss: 1.671216005920082

Epoch: 5| Step: 3
Training loss: 0.4365712106227875
Validation loss: 1.6560184301868561

Epoch: 5| Step: 4
Training loss: 0.5922515988349915
Validation loss: 1.651132760509368

Epoch: 5| Step: 5
Training loss: 0.8695723414421082
Validation loss: 1.668999900740962

Epoch: 5| Step: 6
Training loss: 0.9244382977485657
Validation loss: 1.6966983554183797

Epoch: 5| Step: 7
Training loss: 0.6871569752693176
Validation loss: 1.717849644281531

Epoch: 5| Step: 8
Training loss: 0.509970486164093
Validation loss: 1.7075333210729784

Epoch: 5| Step: 9
Training loss: 0.8820139169692993
Validation loss: 1.725705446735505

Epoch: 5| Step: 10
Training loss: 0.26387712359428406
Validation loss: 1.718326800612993

Epoch: 492| Step: 0
Training loss: 0.49291688203811646
Validation loss: 1.6939818423281434

Epoch: 5| Step: 1
Training loss: 0.7043598890304565
Validation loss: 1.7039690568882933

Epoch: 5| Step: 2
Training loss: 0.9431597590446472
Validation loss: 1.7028040539833806

Epoch: 5| Step: 3
Training loss: 0.7870703935623169
Validation loss: 1.6550026209123674

Epoch: 5| Step: 4
Training loss: 0.9219009280204773
Validation loss: 1.672445830478463

Epoch: 5| Step: 5
Training loss: 0.8375669717788696
Validation loss: 1.6470006665875834

Epoch: 5| Step: 6
Training loss: 0.8499371409416199
Validation loss: 1.6502954690687117

Epoch: 5| Step: 7
Training loss: 0.49131494760513306
Validation loss: 1.6912742378891155

Epoch: 5| Step: 8
Training loss: 0.7269484400749207
Validation loss: 1.662918031856578

Epoch: 5| Step: 9
Training loss: 0.6675939559936523
Validation loss: 1.6601935176439182

Epoch: 5| Step: 10
Training loss: 0.5973751544952393
Validation loss: 1.6981245958676903

Epoch: 493| Step: 0
Training loss: 0.6059890389442444
Validation loss: 1.686131299182933

Epoch: 5| Step: 1
Training loss: 0.7957099080085754
Validation loss: 1.6945893226131317

Epoch: 5| Step: 2
Training loss: 0.7084757089614868
Validation loss: 1.6786972245862406

Epoch: 5| Step: 3
Training loss: 0.47202491760253906
Validation loss: 1.7055929117305304

Epoch: 5| Step: 4
Training loss: 0.9536260366439819
Validation loss: 1.6811539588436004

Epoch: 5| Step: 5
Training loss: 0.5639517903327942
Validation loss: 1.683989394095636

Epoch: 5| Step: 6
Training loss: 0.84321129322052
Validation loss: 1.6786128519683756

Epoch: 5| Step: 7
Training loss: 0.9845377206802368
Validation loss: 1.6931089303826774

Epoch: 5| Step: 8
Training loss: 0.6262843608856201
Validation loss: 1.6841901258755756

Epoch: 5| Step: 9
Training loss: 0.8524225950241089
Validation loss: 1.6820778833922518

Epoch: 5| Step: 10
Training loss: 0.40260976552963257
Validation loss: 1.6966982964546449

Epoch: 494| Step: 0
Training loss: 0.9358618855476379
Validation loss: 1.6816617724716023

Epoch: 5| Step: 1
Training loss: 0.7745105028152466
Validation loss: 1.6839198643161404

Epoch: 5| Step: 2
Training loss: 0.5015450119972229
Validation loss: 1.7165686956015966

Epoch: 5| Step: 3
Training loss: 1.0333242416381836
Validation loss: 1.730549963571692

Epoch: 5| Step: 4
Training loss: 0.9510723948478699
Validation loss: 1.703148513711909

Epoch: 5| Step: 5
Training loss: 0.806699275970459
Validation loss: 1.6740151656571256

Epoch: 5| Step: 6
Training loss: 0.4687122404575348
Validation loss: 1.686016180182016

Epoch: 5| Step: 7
Training loss: 0.6777821779251099
Validation loss: 1.6964887983055525

Epoch: 5| Step: 8
Training loss: 0.9710078239440918
Validation loss: 1.7416507633783485

Epoch: 5| Step: 9
Training loss: 0.5414859056472778
Validation loss: 1.7276394162126767

Epoch: 5| Step: 10
Training loss: 0.3250138759613037
Validation loss: 1.7082617898141184

Epoch: 495| Step: 0
Training loss: 0.905121922492981
Validation loss: 1.7234724849782965

Epoch: 5| Step: 1
Training loss: 0.7744516730308533
Validation loss: 1.6957821743462675

Epoch: 5| Step: 2
Training loss: 0.7584502100944519
Validation loss: 1.6927023690233949

Epoch: 5| Step: 3
Training loss: 0.5163908004760742
Validation loss: 1.654233335166849

Epoch: 5| Step: 4
Training loss: 0.8815041780471802
Validation loss: 1.6063690762366019

Epoch: 5| Step: 5
Training loss: 0.9024091958999634
Validation loss: 1.6336115585860385

Epoch: 5| Step: 6
Training loss: 0.5043343305587769
Validation loss: 1.6351407125432005

Epoch: 5| Step: 7
Training loss: 0.5890657305717468
Validation loss: 1.608780389191002

Epoch: 5| Step: 8
Training loss: 0.7109283804893494
Validation loss: 1.6196196694527902

Epoch: 5| Step: 9
Training loss: 0.7766193151473999
Validation loss: 1.6776733898347425

Epoch: 5| Step: 10
Training loss: 0.8949020504951477
Validation loss: 1.6993975767525293

Epoch: 496| Step: 0
Training loss: 1.2100238800048828
Validation loss: 1.7444210372945315

Epoch: 5| Step: 1
Training loss: 0.6864379644393921
Validation loss: 1.7257346594205467

Epoch: 5| Step: 2
Training loss: 0.7053518295288086
Validation loss: 1.7267511839507728

Epoch: 5| Step: 3
Training loss: 0.8123943209648132
Validation loss: 1.6853151577775196

Epoch: 5| Step: 4
Training loss: 0.9364272356033325
Validation loss: 1.6767045092839066

Epoch: 5| Step: 5
Training loss: 0.7040513753890991
Validation loss: 1.6981820265452068

Epoch: 5| Step: 6
Training loss: 0.6757968664169312
Validation loss: 1.6892270952142694

Epoch: 5| Step: 7
Training loss: 0.6051185727119446
Validation loss: 1.68704435389529

Epoch: 5| Step: 8
Training loss: 0.35776954889297485
Validation loss: 1.6825715470057663

Epoch: 5| Step: 9
Training loss: 0.6714974641799927
Validation loss: 1.6601265732960035

Epoch: 5| Step: 10
Training loss: 0.8239107728004456
Validation loss: 1.6573464473088582

Epoch: 497| Step: 0
Training loss: 0.2528991401195526
Validation loss: 1.6790474973699099

Epoch: 5| Step: 1
Training loss: 0.9483646154403687
Validation loss: 1.7260935588549542

Epoch: 5| Step: 2
Training loss: 0.5263746380805969
Validation loss: 1.7650061358687699

Epoch: 5| Step: 3
Training loss: 0.6849693059921265
Validation loss: 1.74646827097862

Epoch: 5| Step: 4
Training loss: 0.7785921692848206
Validation loss: 1.739252669836885

Epoch: 5| Step: 5
Training loss: 0.958531379699707
Validation loss: 1.6964859539462673

Epoch: 5| Step: 6
Training loss: 0.8909963369369507
Validation loss: 1.677024684926515

Epoch: 5| Step: 7
Training loss: 0.7996912002563477
Validation loss: 1.6551176578767839

Epoch: 5| Step: 8
Training loss: 0.817893385887146
Validation loss: 1.6639438367659045

Epoch: 5| Step: 9
Training loss: 0.8328625559806824
Validation loss: 1.6564805366659676

Epoch: 5| Step: 10
Training loss: 0.46554264426231384
Validation loss: 1.6643329615234046

Epoch: 498| Step: 0
Training loss: 0.8272563815116882
Validation loss: 1.6969511009031726

Epoch: 5| Step: 1
Training loss: 0.551871657371521
Validation loss: 1.6886375424682454

Epoch: 5| Step: 2
Training loss: 0.5201593637466431
Validation loss: 1.6966950662674443

Epoch: 5| Step: 3
Training loss: 0.5432220697402954
Validation loss: 1.6943567798983665

Epoch: 5| Step: 4
Training loss: 1.0190513134002686
Validation loss: 1.7494020628672775

Epoch: 5| Step: 5
Training loss: 0.7809334993362427
Validation loss: 1.726012114555605

Epoch: 5| Step: 6
Training loss: 0.6390618085861206
Validation loss: 1.73637681622659

Epoch: 5| Step: 7
Training loss: 0.8185626268386841
Validation loss: 1.7329372295769312

Epoch: 5| Step: 8
Training loss: 0.617519199848175
Validation loss: 1.7097771167755127

Epoch: 5| Step: 9
Training loss: 0.6619788408279419
Validation loss: 1.709187239728948

Epoch: 5| Step: 10
Training loss: 0.8566159605979919
Validation loss: 1.6771490561064852

Epoch: 499| Step: 0
Training loss: 0.749725341796875
Validation loss: 1.7007490883591354

Epoch: 5| Step: 1
Training loss: 0.6889547109603882
Validation loss: 1.7116769283048567

Epoch: 5| Step: 2
Training loss: 0.8429036140441895
Validation loss: 1.6798116942887664

Epoch: 5| Step: 3
Training loss: 0.5419074892997742
Validation loss: 1.6936010878573182

Epoch: 5| Step: 4
Training loss: 0.764249324798584
Validation loss: 1.7011542243342246

Epoch: 5| Step: 5
Training loss: 0.7071081399917603
Validation loss: 1.733022088645607

Epoch: 5| Step: 6
Training loss: 0.7417515516281128
Validation loss: 1.7050517912833922

Epoch: 5| Step: 7
Training loss: 0.6667451858520508
Validation loss: 1.694432641870232

Epoch: 5| Step: 8
Training loss: 0.9024206399917603
Validation loss: 1.6519308628574494

Epoch: 5| Step: 9
Training loss: 0.5946296453475952
Validation loss: 1.6580383777618408

Epoch: 5| Step: 10
Training loss: 0.5818802714347839
Validation loss: 1.6567287201522498

Epoch: 500| Step: 0
Training loss: 0.4027833044528961
Validation loss: 1.6490178287670176

Epoch: 5| Step: 1
Training loss: 0.5878741145133972
Validation loss: 1.6789450760810607

Epoch: 5| Step: 2
Training loss: 0.6021496057510376
Validation loss: 1.6852119135600265

Epoch: 5| Step: 3
Training loss: 0.9773349761962891
Validation loss: 1.7101485985581593

Epoch: 5| Step: 4
Training loss: 0.8831019401550293
Validation loss: 1.7049335625863844

Epoch: 5| Step: 5
Training loss: 0.6505789756774902
Validation loss: 1.7004775975340156

Epoch: 5| Step: 6
Training loss: 0.5050840377807617
Validation loss: 1.6933903258333924

Epoch: 5| Step: 7
Training loss: 0.900835394859314
Validation loss: 1.681998824560514

Epoch: 5| Step: 8
Training loss: 0.671434760093689
Validation loss: 1.6814411276130266

Epoch: 5| Step: 9
Training loss: 0.6534653902053833
Validation loss: 1.643659596802086

Epoch: 5| Step: 10
Training loss: 0.8928722739219666
Validation loss: 1.628023878220589

Epoch: 501| Step: 0
Training loss: 0.7211307287216187
Validation loss: 1.6346125032312127

Epoch: 5| Step: 1
Training loss: 0.6462836861610413
Validation loss: 1.626200791328184

Epoch: 5| Step: 2
Training loss: 0.5668466687202454
Validation loss: 1.6631699044217345

Epoch: 5| Step: 3
Training loss: 0.8218287229537964
Validation loss: 1.626829977958433

Epoch: 5| Step: 4
Training loss: 0.5778964161872864
Validation loss: 1.6304662112266786

Epoch: 5| Step: 5
Training loss: 0.6700883507728577
Validation loss: 1.6790730389215613

Epoch: 5| Step: 6
Training loss: 1.0511066913604736
Validation loss: 1.7012433185372302

Epoch: 5| Step: 7
Training loss: 0.5057603120803833
Validation loss: 1.698494916321129

Epoch: 5| Step: 8
Training loss: 0.8156313896179199
Validation loss: 1.7667652471091158

Epoch: 5| Step: 9
Training loss: 0.5981435179710388
Validation loss: 1.728781133569697

Epoch: 5| Step: 10
Training loss: 0.697692334651947
Validation loss: 1.7506365135151853

Epoch: 502| Step: 0
Training loss: 0.5905083417892456
Validation loss: 1.775469890204809

Epoch: 5| Step: 1
Training loss: 0.70399409532547
Validation loss: 1.7784196164018364

Epoch: 5| Step: 2
Training loss: 0.9542943835258484
Validation loss: 1.7547103807490358

Epoch: 5| Step: 3
Training loss: 0.6986767649650574
Validation loss: 1.727390464916024

Epoch: 5| Step: 4
Training loss: 0.6357987523078918
Validation loss: 1.6884643659796765

Epoch: 5| Step: 5
Training loss: 0.7964531183242798
Validation loss: 1.6716147058753557

Epoch: 5| Step: 6
Training loss: 0.6483848094940186
Validation loss: 1.6454693655813895

Epoch: 5| Step: 7
Training loss: 0.700594961643219
Validation loss: 1.6578998796401485

Epoch: 5| Step: 8
Training loss: 0.6726052761077881
Validation loss: 1.6441761985901864

Epoch: 5| Step: 9
Training loss: 0.6987267732620239
Validation loss: 1.666031822081535

Epoch: 5| Step: 10
Training loss: 0.6766524314880371
Validation loss: 1.684181356942782

Epoch: 503| Step: 0
Training loss: 0.6237287521362305
Validation loss: 1.710800209353047

Epoch: 5| Step: 1
Training loss: 0.596931517124176
Validation loss: 1.6542633477077688

Epoch: 5| Step: 2
Training loss: 0.6650583148002625
Validation loss: 1.6854038225707186

Epoch: 5| Step: 3
Training loss: 0.6476964950561523
Validation loss: 1.655159846428902

Epoch: 5| Step: 4
Training loss: 0.7332667112350464
Validation loss: 1.681841786189746

Epoch: 5| Step: 5
Training loss: 0.7097819447517395
Validation loss: 1.7111427719875048

Epoch: 5| Step: 6
Training loss: 0.6198225021362305
Validation loss: 1.7101002790594613

Epoch: 5| Step: 7
Training loss: 0.8822011947631836
Validation loss: 1.6602675222581433

Epoch: 5| Step: 8
Training loss: 0.782424807548523
Validation loss: 1.6611975367351244

Epoch: 5| Step: 9
Training loss: 0.7563544511795044
Validation loss: 1.6426638146882415

Epoch: 5| Step: 10
Training loss: 0.6342337131500244
Validation loss: 1.6850972508871427

Epoch: 504| Step: 0
Training loss: 0.5856465697288513
Validation loss: 1.6593066171933246

Epoch: 5| Step: 1
Training loss: 0.8269721269607544
Validation loss: 1.6830356223608858

Epoch: 5| Step: 2
Training loss: 0.8379417657852173
Validation loss: 1.6844846356299616

Epoch: 5| Step: 3
Training loss: 0.45258331298828125
Validation loss: 1.6776499414956698

Epoch: 5| Step: 4
Training loss: 0.6459997296333313
Validation loss: 1.675180087807358

Epoch: 5| Step: 5
Training loss: 0.5945243835449219
Validation loss: 1.6900287994774439

Epoch: 5| Step: 6
Training loss: 0.8683944940567017
Validation loss: 1.6941797041123914

Epoch: 5| Step: 7
Training loss: 0.5484983921051025
Validation loss: 1.6981258315424765

Epoch: 5| Step: 8
Training loss: 0.9078413248062134
Validation loss: 1.6833305448614142

Epoch: 5| Step: 9
Training loss: 0.9753425717353821
Validation loss: 1.7057772490286058

Epoch: 5| Step: 10
Training loss: 0.29015490412712097
Validation loss: 1.6732454376835977

Epoch: 505| Step: 0
Training loss: 0.45337367057800293
Validation loss: 1.663627713598231

Epoch: 5| Step: 1
Training loss: 0.9825426340103149
Validation loss: 1.6835322213429276

Epoch: 5| Step: 2
Training loss: 0.6039949059486389
Validation loss: 1.688729481030536

Epoch: 5| Step: 3
Training loss: 0.5336600542068481
Validation loss: 1.6777631352024693

Epoch: 5| Step: 4
Training loss: 0.7002270221710205
Validation loss: 1.6944951421471053

Epoch: 5| Step: 5
Training loss: 0.578885018825531
Validation loss: 1.6746540146489297

Epoch: 5| Step: 6
Training loss: 0.821273922920227
Validation loss: 1.7046260596603475

Epoch: 5| Step: 7
Training loss: 0.36916384100914
Validation loss: 1.688152818269627

Epoch: 5| Step: 8
Training loss: 0.9041337966918945
Validation loss: 1.6729398562062172

Epoch: 5| Step: 9
Training loss: 0.8837717175483704
Validation loss: 1.6678425996534285

Epoch: 5| Step: 10
Training loss: 0.6049150824546814
Validation loss: 1.6199866648643249

Epoch: 506| Step: 0
Training loss: 0.673876166343689
Validation loss: 1.600803166307429

Epoch: 5| Step: 1
Training loss: 0.8206619024276733
Validation loss: 1.6266205413367159

Epoch: 5| Step: 2
Training loss: 0.5771358609199524
Validation loss: 1.6635065770918323

Epoch: 5| Step: 3
Training loss: 0.7187387347221375
Validation loss: 1.674857662570092

Epoch: 5| Step: 4
Training loss: 0.7972650527954102
Validation loss: 1.6685083104718117

Epoch: 5| Step: 5
Training loss: 0.800532341003418
Validation loss: 1.7071329457785493

Epoch: 5| Step: 6
Training loss: 1.0501224994659424
Validation loss: 1.7060082471498879

Epoch: 5| Step: 7
Training loss: 0.8339923620223999
Validation loss: 1.7094984182747461

Epoch: 5| Step: 8
Training loss: 0.6194635629653931
Validation loss: 1.7174976923132454

Epoch: 5| Step: 9
Training loss: 0.37348079681396484
Validation loss: 1.7289968152200021

Epoch: 5| Step: 10
Training loss: 0.29408136010169983
Validation loss: 1.6800451009504256

Epoch: 507| Step: 0
Training loss: 0.9161604046821594
Validation loss: 1.6670137400268226

Epoch: 5| Step: 1
Training loss: 0.5226253271102905
Validation loss: 1.619262280002717

Epoch: 5| Step: 2
Training loss: 0.8388544321060181
Validation loss: 1.6373237909809235

Epoch: 5| Step: 3
Training loss: 0.7544018626213074
Validation loss: 1.6351537550649335

Epoch: 5| Step: 4
Training loss: 0.7448172569274902
Validation loss: 1.6251692912911857

Epoch: 5| Step: 5
Training loss: 0.9099005460739136
Validation loss: 1.6349858263487458

Epoch: 5| Step: 6
Training loss: 0.5261666178703308
Validation loss: 1.6561930641051261

Epoch: 5| Step: 7
Training loss: 0.6316967606544495
Validation loss: 1.6867315410285868

Epoch: 5| Step: 8
Training loss: 0.9431532621383667
Validation loss: 1.7046095094373148

Epoch: 5| Step: 9
Training loss: 0.3335264325141907
Validation loss: 1.705152282150843

Epoch: 5| Step: 10
Training loss: 0.5936482548713684
Validation loss: 1.709594177943404

Epoch: 508| Step: 0
Training loss: 0.4746645987033844
Validation loss: 1.7118203742529756

Epoch: 5| Step: 1
Training loss: 0.7380321025848389
Validation loss: 1.6931882596785022

Epoch: 5| Step: 2
Training loss: 0.5010773539543152
Validation loss: 1.6932772077539915

Epoch: 5| Step: 3
Training loss: 0.584586501121521
Validation loss: 1.6558870705225135

Epoch: 5| Step: 4
Training loss: 0.47091254591941833
Validation loss: 1.6587173784932783

Epoch: 5| Step: 5
Training loss: 0.782412052154541
Validation loss: 1.6381456121321647

Epoch: 5| Step: 6
Training loss: 0.8570237159729004
Validation loss: 1.6750770576538578

Epoch: 5| Step: 7
Training loss: 0.6333686113357544
Validation loss: 1.6533736554525231

Epoch: 5| Step: 8
Training loss: 0.8013638257980347
Validation loss: 1.6721562313777145

Epoch: 5| Step: 9
Training loss: 0.6559127569198608
Validation loss: 1.6710989872614543

Epoch: 5| Step: 10
Training loss: 0.9049831032752991
Validation loss: 1.6606409242076259

Epoch: 509| Step: 0
Training loss: 0.5819248557090759
Validation loss: 1.666577403263379

Epoch: 5| Step: 1
Training loss: 0.46408718824386597
Validation loss: 1.6682532859104935

Epoch: 5| Step: 2
Training loss: 0.8597549200057983
Validation loss: 1.6626294415484193

Epoch: 5| Step: 3
Training loss: 0.7765394449234009
Validation loss: 1.6802891608207458

Epoch: 5| Step: 4
Training loss: 0.38464832305908203
Validation loss: 1.6596711066461378

Epoch: 5| Step: 5
Training loss: 0.6569739580154419
Validation loss: 1.6488670174793532

Epoch: 5| Step: 6
Training loss: 0.7540742754936218
Validation loss: 1.6452412938558927

Epoch: 5| Step: 7
Training loss: 0.6875171065330505
Validation loss: 1.6422651813876243

Epoch: 5| Step: 8
Training loss: 0.8408376574516296
Validation loss: 1.6695254054120792

Epoch: 5| Step: 9
Training loss: 0.6556822061538696
Validation loss: 1.6529571099947857

Epoch: 5| Step: 10
Training loss: 0.7503231167793274
Validation loss: 1.671968940765627

Epoch: 510| Step: 0
Training loss: 0.7946324944496155
Validation loss: 1.6759800789176778

Epoch: 5| Step: 1
Training loss: 0.6873415112495422
Validation loss: 1.6409790028807938

Epoch: 5| Step: 2
Training loss: 0.8550952076911926
Validation loss: 1.6443334625613304

Epoch: 5| Step: 3
Training loss: 0.4820269048213959
Validation loss: 1.6323478144984092

Epoch: 5| Step: 4
Training loss: 0.6165229082107544
Validation loss: 1.6422869210602136

Epoch: 5| Step: 5
Training loss: 0.7344909906387329
Validation loss: 1.655340648466541

Epoch: 5| Step: 6
Training loss: 0.7905513644218445
Validation loss: 1.6512837653519006

Epoch: 5| Step: 7
Training loss: 0.5991002321243286
Validation loss: 1.6315007517414708

Epoch: 5| Step: 8
Training loss: 0.337830126285553
Validation loss: 1.6652648833490187

Epoch: 5| Step: 9
Training loss: 0.6937851309776306
Validation loss: 1.6513502956718527

Epoch: 5| Step: 10
Training loss: 0.5237064957618713
Validation loss: 1.6765159022423528

Epoch: 511| Step: 0
Training loss: 0.5686945915222168
Validation loss: 1.6372855927354546

Epoch: 5| Step: 1
Training loss: 0.6216849088668823
Validation loss: 1.6538161257261872

Epoch: 5| Step: 2
Training loss: 0.5911072492599487
Validation loss: 1.657952001017909

Epoch: 5| Step: 3
Training loss: 0.5444023013114929
Validation loss: 1.6589105206151162

Epoch: 5| Step: 4
Training loss: 0.7232979536056519
Validation loss: 1.656230390712779

Epoch: 5| Step: 5
Training loss: 0.586328387260437
Validation loss: 1.674505974656792

Epoch: 5| Step: 6
Training loss: 0.8992825746536255
Validation loss: 1.6939844892870994

Epoch: 5| Step: 7
Training loss: 0.590467631816864
Validation loss: 1.7074480889945902

Epoch: 5| Step: 8
Training loss: 0.7392821311950684
Validation loss: 1.705779621678014

Epoch: 5| Step: 9
Training loss: 1.0324161052703857
Validation loss: 1.7249494803849088

Epoch: 5| Step: 10
Training loss: 0.4785652160644531
Validation loss: 1.721732388260544

Epoch: 512| Step: 0
Training loss: 0.809907078742981
Validation loss: 1.654124653467568

Epoch: 5| Step: 1
Training loss: 0.9165061712265015
Validation loss: 1.6489144986675632

Epoch: 5| Step: 2
Training loss: 0.39679351449012756
Validation loss: 1.6590555739659134

Epoch: 5| Step: 3
Training loss: 0.8963304758071899
Validation loss: 1.6662058368805917

Epoch: 5| Step: 4
Training loss: 0.5619909167289734
Validation loss: 1.642214265561873

Epoch: 5| Step: 5
Training loss: 0.5571277737617493
Validation loss: 1.646454744441535

Epoch: 5| Step: 6
Training loss: 0.7421788573265076
Validation loss: 1.653414886484864

Epoch: 5| Step: 7
Training loss: 0.368137925863266
Validation loss: 1.6603203037733674

Epoch: 5| Step: 8
Training loss: 0.5267132520675659
Validation loss: 1.6789029202153605

Epoch: 5| Step: 9
Training loss: 0.8570505380630493
Validation loss: 1.6683016977002543

Epoch: 5| Step: 10
Training loss: 0.6263505220413208
Validation loss: 1.6454043747276388

Epoch: 513| Step: 0
Training loss: 0.9336014986038208
Validation loss: 1.6511540746176114

Epoch: 5| Step: 1
Training loss: 0.23421509563922882
Validation loss: 1.645290033791655

Epoch: 5| Step: 2
Training loss: 0.652272641658783
Validation loss: 1.6470022727084417

Epoch: 5| Step: 3
Training loss: 0.572515606880188
Validation loss: 1.6497674013978691

Epoch: 5| Step: 4
Training loss: 0.5350839495658875
Validation loss: 1.7034456037705945

Epoch: 5| Step: 5
Training loss: 0.6939512491226196
Validation loss: 1.719014322885903

Epoch: 5| Step: 6
Training loss: 1.2101900577545166
Validation loss: 1.7078453353656236

Epoch: 5| Step: 7
Training loss: 0.916303813457489
Validation loss: 1.701101021100116

Epoch: 5| Step: 8
Training loss: 0.6785901784896851
Validation loss: 1.6813974585584415

Epoch: 5| Step: 9
Training loss: 0.401973158121109
Validation loss: 1.6867016041150658

Epoch: 5| Step: 10
Training loss: 0.5119902491569519
Validation loss: 1.6488509242252638

Epoch: 514| Step: 0
Training loss: 0.4861176609992981
Validation loss: 1.6562049350430887

Epoch: 5| Step: 1
Training loss: 0.6394555568695068
Validation loss: 1.6236936276958835

Epoch: 5| Step: 2
Training loss: 0.878627598285675
Validation loss: 1.6505268927543395

Epoch: 5| Step: 3
Training loss: 0.5933570861816406
Validation loss: 1.6292098542695403

Epoch: 5| Step: 4
Training loss: 0.9033730626106262
Validation loss: 1.6440424124399822

Epoch: 5| Step: 5
Training loss: 1.0420253276824951
Validation loss: 1.6688266518295451

Epoch: 5| Step: 6
Training loss: 0.888049304485321
Validation loss: 1.688693772080124

Epoch: 5| Step: 7
Training loss: 0.3174286484718323
Validation loss: 1.716863110501279

Epoch: 5| Step: 8
Training loss: 0.6663256287574768
Validation loss: 1.7465289382524387

Epoch: 5| Step: 9
Training loss: 0.4853379726409912
Validation loss: 1.7397265536810762

Epoch: 5| Step: 10
Training loss: 0.3998086750507355
Validation loss: 1.715499621565624

Epoch: 515| Step: 0
Training loss: 0.6790573000907898
Validation loss: 1.7152987359672465

Epoch: 5| Step: 1
Training loss: 0.4390331208705902
Validation loss: 1.65829602877299

Epoch: 5| Step: 2
Training loss: 1.097444772720337
Validation loss: 1.6409328701675578

Epoch: 5| Step: 3
Training loss: 0.6365106701850891
Validation loss: 1.6488964749920754

Epoch: 5| Step: 4
Training loss: 0.5298418998718262
Validation loss: 1.6275518209703508

Epoch: 5| Step: 5
Training loss: 0.6796475052833557
Validation loss: 1.6376469007102392

Epoch: 5| Step: 6
Training loss: 0.8451066017150879
Validation loss: 1.6313130189013738

Epoch: 5| Step: 7
Training loss: 0.9904284477233887
Validation loss: 1.662396602733161

Epoch: 5| Step: 8
Training loss: 0.5142689943313599
Validation loss: 1.6377488669528757

Epoch: 5| Step: 9
Training loss: 0.29874393343925476
Validation loss: 1.652705427139036

Epoch: 5| Step: 10
Training loss: 0.6452729105949402
Validation loss: 1.672516974069739

Epoch: 516| Step: 0
Training loss: 0.3841039538383484
Validation loss: 1.6810383309600174

Epoch: 5| Step: 1
Training loss: 0.40963196754455566
Validation loss: 1.6817741483770392

Epoch: 5| Step: 2
Training loss: 0.7167736887931824
Validation loss: 1.7109187559414936

Epoch: 5| Step: 3
Training loss: 0.7026942372322083
Validation loss: 1.6750989498630646

Epoch: 5| Step: 4
Training loss: 0.640804648399353
Validation loss: 1.6851267673635995

Epoch: 5| Step: 5
Training loss: 0.6462337970733643
Validation loss: 1.6557311960445937

Epoch: 5| Step: 6
Training loss: 0.8566924929618835
Validation loss: 1.6663818705466487

Epoch: 5| Step: 7
Training loss: 0.7493066787719727
Validation loss: 1.6428372372863114

Epoch: 5| Step: 8
Training loss: 0.8477892875671387
Validation loss: 1.6902971549700665

Epoch: 5| Step: 9
Training loss: 0.47888851165771484
Validation loss: 1.6682786992801133

Epoch: 5| Step: 10
Training loss: 0.8387940526008606
Validation loss: 1.6795358170745194

Epoch: 517| Step: 0
Training loss: 0.5207171440124512
Validation loss: 1.681993192242038

Epoch: 5| Step: 1
Training loss: 0.7326602935791016
Validation loss: 1.6860538041719826

Epoch: 5| Step: 2
Training loss: 0.8272469639778137
Validation loss: 1.7014402984290995

Epoch: 5| Step: 3
Training loss: 0.716324508190155
Validation loss: 1.6704247254197315

Epoch: 5| Step: 4
Training loss: 0.8454307317733765
Validation loss: 1.7037875344676356

Epoch: 5| Step: 5
Training loss: 0.7521116137504578
Validation loss: 1.695744809284005

Epoch: 5| Step: 6
Training loss: 0.5562440752983093
Validation loss: 1.6541037803055139

Epoch: 5| Step: 7
Training loss: 0.7014032602310181
Validation loss: 1.6616644500404276

Epoch: 5| Step: 8
Training loss: 0.597950279712677
Validation loss: 1.672298430114664

Epoch: 5| Step: 9
Training loss: 0.5828142762184143
Validation loss: 1.6852081321900891

Epoch: 5| Step: 10
Training loss: 0.47729212045669556
Validation loss: 1.7287001225256151

Epoch: 518| Step: 0
Training loss: 0.7238025665283203
Validation loss: 1.7394051244181972

Epoch: 5| Step: 1
Training loss: 0.36134132742881775
Validation loss: 1.7805254792654386

Epoch: 5| Step: 2
Training loss: 0.7878265380859375
Validation loss: 1.7781687449383479

Epoch: 5| Step: 3
Training loss: 0.747580885887146
Validation loss: 1.804387725809569

Epoch: 5| Step: 4
Training loss: 0.6696355938911438
Validation loss: 1.7774454983331824

Epoch: 5| Step: 5
Training loss: 0.7043410539627075
Validation loss: 1.7782151417065692

Epoch: 5| Step: 6
Training loss: 0.5596728324890137
Validation loss: 1.7207545016401558

Epoch: 5| Step: 7
Training loss: 0.6352342367172241
Validation loss: 1.7188293715958953

Epoch: 5| Step: 8
Training loss: 0.8524183034896851
Validation loss: 1.6731927766594836

Epoch: 5| Step: 9
Training loss: 0.6474899053573608
Validation loss: 1.6495924175426524

Epoch: 5| Step: 10
Training loss: 0.8331931829452515
Validation loss: 1.6546696155301985

Epoch: 519| Step: 0
Training loss: 0.35974329710006714
Validation loss: 1.6072920958201091

Epoch: 5| Step: 1
Training loss: 0.3330203890800476
Validation loss: 1.6450323302258727

Epoch: 5| Step: 2
Training loss: 0.8340757489204407
Validation loss: 1.6371335291093396

Epoch: 5| Step: 3
Training loss: 0.8532606363296509
Validation loss: 1.6242133378982544

Epoch: 5| Step: 4
Training loss: 0.4540548324584961
Validation loss: 1.6384551204660887

Epoch: 5| Step: 5
Training loss: 0.8061666488647461
Validation loss: 1.6455752285577918

Epoch: 5| Step: 6
Training loss: 0.724853515625
Validation loss: 1.6655481451301164

Epoch: 5| Step: 7
Training loss: 0.6642950773239136
Validation loss: 1.6524252583903651

Epoch: 5| Step: 8
Training loss: 0.7992268800735474
Validation loss: 1.6671135810113722

Epoch: 5| Step: 9
Training loss: 0.9271400570869446
Validation loss: 1.6676596544122184

Epoch: 5| Step: 10
Training loss: 0.644039511680603
Validation loss: 1.6800366819545787

Epoch: 520| Step: 0
Training loss: 0.46929293870925903
Validation loss: 1.6583009080220295

Epoch: 5| Step: 1
Training loss: 0.532337486743927
Validation loss: 1.6068220010367773

Epoch: 5| Step: 2
Training loss: 0.5759174823760986
Validation loss: 1.5751572834548129

Epoch: 5| Step: 3
Training loss: 0.9111417531967163
Validation loss: 1.589777091498016

Epoch: 5| Step: 4
Training loss: 0.5230876207351685
Validation loss: 1.5848823106417091

Epoch: 5| Step: 5
Training loss: 0.8189682960510254
Validation loss: 1.6190659410210066

Epoch: 5| Step: 6
Training loss: 0.6647648215293884
Validation loss: 1.629288549064308

Epoch: 5| Step: 7
Training loss: 0.798056960105896
Validation loss: 1.6751889862040037

Epoch: 5| Step: 8
Training loss: 0.7817854881286621
Validation loss: 1.6946865345842095

Epoch: 5| Step: 9
Training loss: 0.48388272523880005
Validation loss: 1.7258480877004645

Epoch: 5| Step: 10
Training loss: 0.9511772394180298
Validation loss: 1.7426896851549867

Epoch: 521| Step: 0
Training loss: 0.6157341003417969
Validation loss: 1.7253124419079031

Epoch: 5| Step: 1
Training loss: 0.5556307435035706
Validation loss: 1.7546157811277656

Epoch: 5| Step: 2
Training loss: 1.1847326755523682
Validation loss: 1.7088915327543854

Epoch: 5| Step: 3
Training loss: 0.49349260330200195
Validation loss: 1.6891291295328448

Epoch: 5| Step: 4
Training loss: 0.6047734022140503
Validation loss: 1.699663414750048

Epoch: 5| Step: 5
Training loss: 0.6369878053665161
Validation loss: 1.6839378879916282

Epoch: 5| Step: 6
Training loss: 0.7626121044158936
Validation loss: 1.6791395538596696

Epoch: 5| Step: 7
Training loss: 0.5746292471885681
Validation loss: 1.6756143300764021

Epoch: 5| Step: 8
Training loss: 0.6288437843322754
Validation loss: 1.6856909375036917

Epoch: 5| Step: 9
Training loss: 0.5359402894973755
Validation loss: 1.7119336371780725

Epoch: 5| Step: 10
Training loss: 0.7558104395866394
Validation loss: 1.7469763627616308

Epoch: 522| Step: 0
Training loss: 0.5925680994987488
Validation loss: 1.7039574038597844

Epoch: 5| Step: 1
Training loss: 0.5947610139846802
Validation loss: 1.7233407484587802

Epoch: 5| Step: 2
Training loss: 0.6937881708145142
Validation loss: 1.6781933499920754

Epoch: 5| Step: 3
Training loss: 0.624874472618103
Validation loss: 1.6682460820803078

Epoch: 5| Step: 4
Training loss: 0.5510215759277344
Validation loss: 1.6699155030712005

Epoch: 5| Step: 5
Training loss: 1.0202851295471191
Validation loss: 1.6759493158709617

Epoch: 5| Step: 6
Training loss: 0.6509793996810913
Validation loss: 1.730561779391381

Epoch: 5| Step: 7
Training loss: 0.8622772097587585
Validation loss: 1.6546627526642175

Epoch: 5| Step: 8
Training loss: 0.41129428148269653
Validation loss: 1.6589975164782615

Epoch: 5| Step: 9
Training loss: 0.6272189617156982
Validation loss: 1.6710418783208376

Epoch: 5| Step: 10
Training loss: 0.7419339418411255
Validation loss: 1.6832464048939366

Epoch: 523| Step: 0
Training loss: 0.37309473752975464
Validation loss: 1.6808514056667205

Epoch: 5| Step: 1
Training loss: 0.29829585552215576
Validation loss: 1.680284374503679

Epoch: 5| Step: 2
Training loss: 0.8029648065567017
Validation loss: 1.6761448883241223

Epoch: 5| Step: 3
Training loss: 1.0234477519989014
Validation loss: 1.6668075887105798

Epoch: 5| Step: 4
Training loss: 0.7131608724594116
Validation loss: 1.6597797550180906

Epoch: 5| Step: 5
Training loss: 0.6431230306625366
Validation loss: 1.6679290520247592

Epoch: 5| Step: 6
Training loss: 0.614601731300354
Validation loss: 1.6767139024631952

Epoch: 5| Step: 7
Training loss: 0.5780803561210632
Validation loss: 1.6981448588832733

Epoch: 5| Step: 8
Training loss: 0.9226590394973755
Validation loss: 1.693274651804278

Epoch: 5| Step: 9
Training loss: 0.8231350183486938
Validation loss: 1.6858195873998827

Epoch: 5| Step: 10
Training loss: 0.3430078625679016
Validation loss: 1.687865852027811

Epoch: 524| Step: 0
Training loss: 0.6469188332557678
Validation loss: 1.6699459834765362

Epoch: 5| Step: 1
Training loss: 0.5467451810836792
Validation loss: 1.6737048113217918

Epoch: 5| Step: 2
Training loss: 0.09787802398204803
Validation loss: 1.6674824965897428

Epoch: 5| Step: 3
Training loss: 0.8150953054428101
Validation loss: 1.690487168168509

Epoch: 5| Step: 4
Training loss: 0.5345461964607239
Validation loss: 1.6792446746621081

Epoch: 5| Step: 5
Training loss: 0.8598949313163757
Validation loss: 1.670168407501713

Epoch: 5| Step: 6
Training loss: 0.8675510287284851
Validation loss: 1.6410264186961676

Epoch: 5| Step: 7
Training loss: 0.682715892791748
Validation loss: 1.6325567896648119

Epoch: 5| Step: 8
Training loss: 0.45783060789108276
Validation loss: 1.6283600663626066

Epoch: 5| Step: 9
Training loss: 0.7871009111404419
Validation loss: 1.62041542478787

Epoch: 5| Step: 10
Training loss: 0.7607523798942566
Validation loss: 1.6657502215395692

Epoch: 525| Step: 0
Training loss: 0.5161803364753723
Validation loss: 1.6608237220394997

Epoch: 5| Step: 1
Training loss: 0.9168657064437866
Validation loss: 1.6672740905515608

Epoch: 5| Step: 2
Training loss: 0.5675775408744812
Validation loss: 1.6937398070930152

Epoch: 5| Step: 3
Training loss: 0.5613662004470825
Validation loss: 1.7066774381104337

Epoch: 5| Step: 4
Training loss: 0.745437502861023
Validation loss: 1.699490834307927

Epoch: 5| Step: 5
Training loss: 0.4029398560523987
Validation loss: 1.687264903899162

Epoch: 5| Step: 6
Training loss: 0.8405554890632629
Validation loss: 1.650023559088348

Epoch: 5| Step: 7
Training loss: 0.5842306017875671
Validation loss: 1.655858992248453

Epoch: 5| Step: 8
Training loss: 0.5459448099136353
Validation loss: 1.6645333305481942

Epoch: 5| Step: 9
Training loss: 0.7694876790046692
Validation loss: 1.6369953258063203

Epoch: 5| Step: 10
Training loss: 0.3601183295249939
Validation loss: 1.6203234387982277

Epoch: 526| Step: 0
Training loss: 0.5957843065261841
Validation loss: 1.6327666595417967

Epoch: 5| Step: 1
Training loss: 0.6466871500015259
Validation loss: 1.6731634716833792

Epoch: 5| Step: 2
Training loss: 0.6525791883468628
Validation loss: 1.6506684236629035

Epoch: 5| Step: 3
Training loss: 0.5501871705055237
Validation loss: 1.6900833909229567

Epoch: 5| Step: 4
Training loss: 0.5087710618972778
Validation loss: 1.713961862748669

Epoch: 5| Step: 5
Training loss: 0.6082596182823181
Validation loss: 1.6902576133769045

Epoch: 5| Step: 6
Training loss: 0.378335177898407
Validation loss: 1.6943763520127983

Epoch: 5| Step: 7
Training loss: 0.7456182241439819
Validation loss: 1.6647138877581524

Epoch: 5| Step: 8
Training loss: 0.9453620910644531
Validation loss: 1.6714305518775858

Epoch: 5| Step: 9
Training loss: 0.6492809057235718
Validation loss: 1.6401558935001332

Epoch: 5| Step: 10
Training loss: 0.8180021643638611
Validation loss: 1.6258794799927743

Epoch: 527| Step: 0
Training loss: 0.7647652626037598
Validation loss: 1.6095838854389806

Epoch: 5| Step: 1
Training loss: 0.6226593255996704
Validation loss: 1.6258281507799703

Epoch: 5| Step: 2
Training loss: 0.504554271697998
Validation loss: 1.6455433855774582

Epoch: 5| Step: 3
Training loss: 0.2820054292678833
Validation loss: 1.6610530448216263

Epoch: 5| Step: 4
Training loss: 0.613670825958252
Validation loss: 1.6637060757606261

Epoch: 5| Step: 5
Training loss: 0.7335222959518433
Validation loss: 1.6801524341747325

Epoch: 5| Step: 6
Training loss: 0.9601849317550659
Validation loss: 1.7129756045597855

Epoch: 5| Step: 7
Training loss: 0.719077467918396
Validation loss: 1.7061255798544934

Epoch: 5| Step: 8
Training loss: 0.5218640565872192
Validation loss: 1.7016834879434237

Epoch: 5| Step: 9
Training loss: 0.48755091428756714
Validation loss: 1.7620610652431365

Epoch: 5| Step: 10
Training loss: 0.8543979525566101
Validation loss: 1.7173993267038816

Epoch: 528| Step: 0
Training loss: 0.8985248804092407
Validation loss: 1.723534873736802

Epoch: 5| Step: 1
Training loss: 0.7506571412086487
Validation loss: 1.6945299333141697

Epoch: 5| Step: 2
Training loss: 0.3833477199077606
Validation loss: 1.680108113955426

Epoch: 5| Step: 3
Training loss: 0.606001079082489
Validation loss: 1.627861451077205

Epoch: 5| Step: 4
Training loss: 0.5653692483901978
Validation loss: 1.685692806397715

Epoch: 5| Step: 5
Training loss: 0.4941047728061676
Validation loss: 1.6966337862835135

Epoch: 5| Step: 6
Training loss: 0.8621969223022461
Validation loss: 1.6961828611230338

Epoch: 5| Step: 7
Training loss: 0.5110436677932739
Validation loss: 1.7525620678419709

Epoch: 5| Step: 8
Training loss: 0.8112491369247437
Validation loss: 1.6966378124811317

Epoch: 5| Step: 9
Training loss: 0.504131019115448
Validation loss: 1.7367250252795476

Epoch: 5| Step: 10
Training loss: 0.48608601093292236
Validation loss: 1.67208343936551

Epoch: 529| Step: 0
Training loss: 0.5763241052627563
Validation loss: 1.6899866750163417

Epoch: 5| Step: 1
Training loss: 0.6637144088745117
Validation loss: 1.676719404035999

Epoch: 5| Step: 2
Training loss: 0.6846883893013
Validation loss: 1.6525870087326213

Epoch: 5| Step: 3
Training loss: 0.3846557140350342
Validation loss: 1.6807237030357443

Epoch: 5| Step: 4
Training loss: 0.5965398550033569
Validation loss: 1.7014760125067927

Epoch: 5| Step: 5
Training loss: 0.4112236499786377
Validation loss: 1.6811702277070733

Epoch: 5| Step: 6
Training loss: 1.2320892810821533
Validation loss: 1.708705493198928

Epoch: 5| Step: 7
Training loss: 0.546822726726532
Validation loss: 1.7432876479241155

Epoch: 5| Step: 8
Training loss: 0.6090145111083984
Validation loss: 1.7253479919125956

Epoch: 5| Step: 9
Training loss: 0.464647114276886
Validation loss: 1.7350641296755882

Epoch: 5| Step: 10
Training loss: 0.7060254812240601
Validation loss: 1.6884293395985839

Epoch: 530| Step: 0
Training loss: 0.4606310725212097
Validation loss: 1.6994995692724824

Epoch: 5| Step: 1
Training loss: 0.6123883128166199
Validation loss: 1.6902260267606346

Epoch: 5| Step: 2
Training loss: 0.7267315983772278
Validation loss: 1.6579865204390658

Epoch: 5| Step: 3
Training loss: 0.7247084379196167
Validation loss: 1.6733601695747786

Epoch: 5| Step: 4
Training loss: 0.5277963876724243
Validation loss: 1.6477052883435321

Epoch: 5| Step: 5
Training loss: 0.7959280610084534
Validation loss: 1.6727640814678644

Epoch: 5| Step: 6
Training loss: 0.7816673517227173
Validation loss: 1.726693053399363

Epoch: 5| Step: 7
Training loss: 0.7043365240097046
Validation loss: 1.7234146748819659

Epoch: 5| Step: 8
Training loss: 0.5947251319885254
Validation loss: 1.7405907441211004

Epoch: 5| Step: 9
Training loss: 0.5922761559486389
Validation loss: 1.6965256288487425

Epoch: 5| Step: 10
Training loss: 0.4836697280406952
Validation loss: 1.6513222340614564

Epoch: 531| Step: 0
Training loss: 0.5320663452148438
Validation loss: 1.6512918215925976

Epoch: 5| Step: 1
Training loss: 0.8963117599487305
Validation loss: 1.6803386660032376

Epoch: 5| Step: 2
Training loss: 0.5262383818626404
Validation loss: 1.6600267015477663

Epoch: 5| Step: 3
Training loss: 0.8460725545883179
Validation loss: 1.672100208138907

Epoch: 5| Step: 4
Training loss: 0.49925127625465393
Validation loss: 1.6725699183761433

Epoch: 5| Step: 5
Training loss: 0.6907180547714233
Validation loss: 1.7050516797650246

Epoch: 5| Step: 6
Training loss: 0.4082791209220886
Validation loss: 1.6985437331661102

Epoch: 5| Step: 7
Training loss: 0.930207371711731
Validation loss: 1.7458353106693556

Epoch: 5| Step: 8
Training loss: 0.3935707211494446
Validation loss: 1.7287875503622077

Epoch: 5| Step: 9
Training loss: 0.43406566977500916
Validation loss: 1.6908968776784918

Epoch: 5| Step: 10
Training loss: 0.9299319982528687
Validation loss: 1.721441057420546

Epoch: 532| Step: 0
Training loss: 0.982222855091095
Validation loss: 1.6703694392276067

Epoch: 5| Step: 1
Training loss: 0.38225436210632324
Validation loss: 1.6681663067110124

Epoch: 5| Step: 2
Training loss: 0.42353448271751404
Validation loss: 1.6587715892381565

Epoch: 5| Step: 3
Training loss: 0.509871244430542
Validation loss: 1.6489313315319758

Epoch: 5| Step: 4
Training loss: 0.5590677261352539
Validation loss: 1.6688013743328791

Epoch: 5| Step: 5
Training loss: 0.8170671463012695
Validation loss: 1.6552820397961525

Epoch: 5| Step: 6
Training loss: 0.8597437739372253
Validation loss: 1.6587356008509153

Epoch: 5| Step: 7
Training loss: 0.4194397032260895
Validation loss: 1.6789829679714736

Epoch: 5| Step: 8
Training loss: 0.5071665644645691
Validation loss: 1.660007977998385

Epoch: 5| Step: 9
Training loss: 0.718755304813385
Validation loss: 1.6266296986610658

Epoch: 5| Step: 10
Training loss: 0.5584683418273926
Validation loss: 1.6826400500471874

Epoch: 533| Step: 0
Training loss: 0.38028663396835327
Validation loss: 1.6340616685087963

Epoch: 5| Step: 1
Training loss: 0.6934780478477478
Validation loss: 1.6745585190352572

Epoch: 5| Step: 2
Training loss: 0.8771289587020874
Validation loss: 1.641584796290244

Epoch: 5| Step: 3
Training loss: 0.5945561528205872
Validation loss: 1.6933184913409653

Epoch: 5| Step: 4
Training loss: 0.3751397132873535
Validation loss: 1.6370157093130133

Epoch: 5| Step: 5
Training loss: 0.532831609249115
Validation loss: 1.650431013876392

Epoch: 5| Step: 6
Training loss: 0.6461600065231323
Validation loss: 1.6342522405808972

Epoch: 5| Step: 7
Training loss: 0.5698943138122559
Validation loss: 1.6324152485016854

Epoch: 5| Step: 8
Training loss: 0.8953639268875122
Validation loss: 1.6451288487321587

Epoch: 5| Step: 9
Training loss: 0.6691829562187195
Validation loss: 1.60917483093918

Epoch: 5| Step: 10
Training loss: 0.5351971983909607
Validation loss: 1.6216872507526028

Epoch: 534| Step: 0
Training loss: 0.5924490690231323
Validation loss: 1.611026160178646

Epoch: 5| Step: 1
Training loss: 0.7260531187057495
Validation loss: 1.6181057435210033

Epoch: 5| Step: 2
Training loss: 0.4794597029685974
Validation loss: 1.574589729309082

Epoch: 5| Step: 3
Training loss: 0.6568590998649597
Validation loss: 1.5794109106063843

Epoch: 5| Step: 4
Training loss: 0.5765961408615112
Validation loss: 1.5923252169803908

Epoch: 5| Step: 5
Training loss: 0.753605306148529
Validation loss: 1.6429603843278782

Epoch: 5| Step: 6
Training loss: 0.615156352519989
Validation loss: 1.6798210195315781

Epoch: 5| Step: 7
Training loss: 0.8108779788017273
Validation loss: 1.7094916758998748

Epoch: 5| Step: 8
Training loss: 0.7113782167434692
Validation loss: 1.6911046466519755

Epoch: 5| Step: 9
Training loss: 0.4814223349094391
Validation loss: 1.6940087618366364

Epoch: 5| Step: 10
Training loss: 0.4887889325618744
Validation loss: 1.6432846515409407

Epoch: 535| Step: 0
Training loss: 0.7638527154922485
Validation loss: 1.6702643004796838

Epoch: 5| Step: 1
Training loss: 0.4926539361476898
Validation loss: 1.6230648115117063

Epoch: 5| Step: 2
Training loss: 0.7082878351211548
Validation loss: 1.6288960774739583

Epoch: 5| Step: 3
Training loss: 0.6840946078300476
Validation loss: 1.632879848121315

Epoch: 5| Step: 4
Training loss: 0.9231531023979187
Validation loss: 1.6002540614015313

Epoch: 5| Step: 5
Training loss: 0.44404879212379456
Validation loss: 1.6411963188520042

Epoch: 5| Step: 6
Training loss: 0.6361621618270874
Validation loss: 1.65193619010269

Epoch: 5| Step: 7
Training loss: 0.6130275726318359
Validation loss: 1.671092830678468

Epoch: 5| Step: 8
Training loss: 0.4631122648715973
Validation loss: 1.6546290484807824

Epoch: 5| Step: 9
Training loss: 0.6408449411392212
Validation loss: 1.6677510148735457

Epoch: 5| Step: 10
Training loss: 0.5035802125930786
Validation loss: 1.6809406101062734

Epoch: 536| Step: 0
Training loss: 0.8751153945922852
Validation loss: 1.700676313010595

Epoch: 5| Step: 1
Training loss: 0.4362548291683197
Validation loss: 1.706944170818534

Epoch: 5| Step: 2
Training loss: 0.8029929399490356
Validation loss: 1.680719316646617

Epoch: 5| Step: 3
Training loss: 0.5796321034431458
Validation loss: 1.6691991911139539

Epoch: 5| Step: 4
Training loss: 0.29768094420433044
Validation loss: 1.6658123385521673

Epoch: 5| Step: 5
Training loss: 0.790748119354248
Validation loss: 1.6501940629815544

Epoch: 5| Step: 6
Training loss: 0.2648370862007141
Validation loss: 1.6689849899661156

Epoch: 5| Step: 7
Training loss: 0.5469191074371338
Validation loss: 1.6792715569978118

Epoch: 5| Step: 8
Training loss: 0.5240556001663208
Validation loss: 1.7162696943488172

Epoch: 5| Step: 9
Training loss: 0.7004715204238892
Validation loss: 1.7249325116475422

Epoch: 5| Step: 10
Training loss: 1.0453951358795166
Validation loss: 1.6632980210806734

Epoch: 537| Step: 0
Training loss: 0.5916572213172913
Validation loss: 1.6528757810592651

Epoch: 5| Step: 1
Training loss: 0.5440671443939209
Validation loss: 1.6353310795240505

Epoch: 5| Step: 2
Training loss: 0.873885452747345
Validation loss: 1.615992239726487

Epoch: 5| Step: 3
Training loss: 0.625063955783844
Validation loss: 1.6262571093856648

Epoch: 5| Step: 4
Training loss: 0.7077009081840515
Validation loss: 1.6261823933611634

Epoch: 5| Step: 5
Training loss: 0.8400295972824097
Validation loss: 1.6229858488164923

Epoch: 5| Step: 6
Training loss: 0.7602745294570923
Validation loss: 1.622155757360561

Epoch: 5| Step: 7
Training loss: 0.3789786100387573
Validation loss: 1.6495539155057681

Epoch: 5| Step: 8
Training loss: 0.38476163148880005
Validation loss: 1.6538174421556535

Epoch: 5| Step: 9
Training loss: 0.3403433561325073
Validation loss: 1.6738337739821403

Epoch: 5| Step: 10
Training loss: 0.6213781237602234
Validation loss: 1.6914495896267634

Epoch: 538| Step: 0
Training loss: 0.33795779943466187
Validation loss: 1.6843763602677213

Epoch: 5| Step: 1
Training loss: 0.7161678075790405
Validation loss: 1.736544938497646

Epoch: 5| Step: 2
Training loss: 0.7739561200141907
Validation loss: 1.7223345848821825

Epoch: 5| Step: 3
Training loss: 0.6344724893569946
Validation loss: 1.6834566798261417

Epoch: 5| Step: 4
Training loss: 0.7315891981124878
Validation loss: 1.6620735993949316

Epoch: 5| Step: 5
Training loss: 0.6506423950195312
Validation loss: 1.6135540226454377

Epoch: 5| Step: 6
Training loss: 0.6670796871185303
Validation loss: 1.5858762635979602

Epoch: 5| Step: 7
Training loss: 0.6192386150360107
Validation loss: 1.6177395466835267

Epoch: 5| Step: 8
Training loss: 0.608944833278656
Validation loss: 1.5996344230508293

Epoch: 5| Step: 9
Training loss: 0.6972053647041321
Validation loss: 1.6210721410730833

Epoch: 5| Step: 10
Training loss: 0.39138373732566833
Validation loss: 1.6063933385315763

Epoch: 539| Step: 0
Training loss: 0.5579282641410828
Validation loss: 1.6486103611607705

Epoch: 5| Step: 1
Training loss: 0.4537566602230072
Validation loss: 1.5940338065547328

Epoch: 5| Step: 2
Training loss: 0.7127561569213867
Validation loss: 1.6441541666625648

Epoch: 5| Step: 3
Training loss: 0.5084740519523621
Validation loss: 1.6674326017338743

Epoch: 5| Step: 4
Training loss: 0.773756206035614
Validation loss: 1.655880243547501

Epoch: 5| Step: 5
Training loss: 0.7044050097465515
Validation loss: 1.6976032282716484

Epoch: 5| Step: 6
Training loss: 0.7019104957580566
Validation loss: 1.7358758244463193

Epoch: 5| Step: 7
Training loss: 0.6597779989242554
Validation loss: 1.6862857700676046

Epoch: 5| Step: 8
Training loss: 0.5196999311447144
Validation loss: 1.711366162505201

Epoch: 5| Step: 9
Training loss: 0.5558594465255737
Validation loss: 1.6469162125741281

Epoch: 5| Step: 10
Training loss: 0.3650602102279663
Validation loss: 1.6376974839036182

Epoch: 540| Step: 0
Training loss: 0.7722162008285522
Validation loss: 1.6204143781815805

Epoch: 5| Step: 1
Training loss: 0.3393619656562805
Validation loss: 1.6371481008427118

Epoch: 5| Step: 2
Training loss: 0.3772103488445282
Validation loss: 1.6621435521751322

Epoch: 5| Step: 3
Training loss: 0.7067073583602905
Validation loss: 1.6870331969312442

Epoch: 5| Step: 4
Training loss: 0.43272271752357483
Validation loss: 1.6945753110352384

Epoch: 5| Step: 5
Training loss: 0.7291486859321594
Validation loss: 1.6775491622186476

Epoch: 5| Step: 6
Training loss: 0.6288295388221741
Validation loss: 1.7010718007241525

Epoch: 5| Step: 7
Training loss: 0.6506336331367493
Validation loss: 1.6727754351913289

Epoch: 5| Step: 8
Training loss: 0.6884698271751404
Validation loss: 1.6782132874252975

Epoch: 5| Step: 9
Training loss: 0.7685179710388184
Validation loss: 1.6790242374584239

Epoch: 5| Step: 10
Training loss: 0.6054336428642273
Validation loss: 1.6816627223004577

Epoch: 541| Step: 0
Training loss: 0.4666624665260315
Validation loss: 1.6789311952488397

Epoch: 5| Step: 1
Training loss: 0.5598228573799133
Validation loss: 1.6904673601991387

Epoch: 5| Step: 2
Training loss: 0.31173041462898254
Validation loss: 1.7199846442027757

Epoch: 5| Step: 3
Training loss: 1.0087382793426514
Validation loss: 1.7196070019916823

Epoch: 5| Step: 4
Training loss: 0.5323928594589233
Validation loss: 1.70231000069649

Epoch: 5| Step: 5
Training loss: 0.9332126379013062
Validation loss: 1.687914547099862

Epoch: 5| Step: 6
Training loss: 0.7215761542320251
Validation loss: 1.6714655699268464

Epoch: 5| Step: 7
Training loss: 0.5298616290092468
Validation loss: 1.6553694278963151

Epoch: 5| Step: 8
Training loss: 0.4929484724998474
Validation loss: 1.6655285025155673

Epoch: 5| Step: 9
Training loss: 0.3263869881629944
Validation loss: 1.6548035708806847

Epoch: 5| Step: 10
Training loss: 0.6317892670631409
Validation loss: 1.6511737082594184

Epoch: 542| Step: 0
Training loss: 0.6033212542533875
Validation loss: 1.6730513495783652

Epoch: 5| Step: 1
Training loss: 0.5148912668228149
Validation loss: 1.6733964950807634

Epoch: 5| Step: 2
Training loss: 0.7314921021461487
Validation loss: 1.6537803449938375

Epoch: 5| Step: 3
Training loss: 0.7000421285629272
Validation loss: 1.6586680860929592

Epoch: 5| Step: 4
Training loss: 0.6635185480117798
Validation loss: 1.6605095299341346

Epoch: 5| Step: 5
Training loss: 0.7395120859146118
Validation loss: 1.6892683813648839

Epoch: 5| Step: 6
Training loss: 0.3588220477104187
Validation loss: 1.657986302529612

Epoch: 5| Step: 7
Training loss: 0.6686382293701172
Validation loss: 1.6857201463432723

Epoch: 5| Step: 8
Training loss: 0.5259442925453186
Validation loss: 1.634686472595379

Epoch: 5| Step: 9
Training loss: 0.4505949914455414
Validation loss: 1.6311767921652844

Epoch: 5| Step: 10
Training loss: 0.5349729061126709
Validation loss: 1.6420371788804249

Epoch: 543| Step: 0
Training loss: 0.550284206867218
Validation loss: 1.6367421047661894

Epoch: 5| Step: 1
Training loss: 0.6451179385185242
Validation loss: 1.6600243378711004

Epoch: 5| Step: 2
Training loss: 0.33478179574012756
Validation loss: 1.637029194062756

Epoch: 5| Step: 3
Training loss: 0.620066225528717
Validation loss: 1.6541305895774596

Epoch: 5| Step: 4
Training loss: 0.4175642132759094
Validation loss: 1.6473452660345262

Epoch: 5| Step: 5
Training loss: 0.47201529145240784
Validation loss: 1.671507889224637

Epoch: 5| Step: 6
Training loss: 0.5010210871696472
Validation loss: 1.655398823881662

Epoch: 5| Step: 7
Training loss: 0.9057894945144653
Validation loss: 1.6619445591844537

Epoch: 5| Step: 8
Training loss: 0.34577125310897827
Validation loss: 1.6597301216535671

Epoch: 5| Step: 9
Training loss: 0.7206665277481079
Validation loss: 1.677832422717925

Epoch: 5| Step: 10
Training loss: 0.9363229870796204
Validation loss: 1.6737773674790577

Epoch: 544| Step: 0
Training loss: 0.7147365808486938
Validation loss: 1.6819491668414044

Epoch: 5| Step: 1
Training loss: 0.45966124534606934
Validation loss: 1.6559159960798038

Epoch: 5| Step: 2
Training loss: 0.5504041910171509
Validation loss: 1.6858251658819055

Epoch: 5| Step: 3
Training loss: 0.6797139048576355
Validation loss: 1.6638122886739752

Epoch: 5| Step: 4
Training loss: 0.35810917615890503
Validation loss: 1.6697079866163191

Epoch: 5| Step: 5
Training loss: 0.5999076962471008
Validation loss: 1.658388485190689

Epoch: 5| Step: 6
Training loss: 0.8677056431770325
Validation loss: 1.6842604042381368

Epoch: 5| Step: 7
Training loss: 0.7611203789710999
Validation loss: 1.6613863225906127

Epoch: 5| Step: 8
Training loss: 0.504680871963501
Validation loss: 1.6427793413080194

Epoch: 5| Step: 9
Training loss: 0.5572205185890198
Validation loss: 1.668792684872945

Epoch: 5| Step: 10
Training loss: 0.4475148022174835
Validation loss: 1.6596929821916806

Epoch: 545| Step: 0
Training loss: 0.9969808459281921
Validation loss: 1.612711178359165

Epoch: 5| Step: 1
Training loss: 0.45873650908470154
Validation loss: 1.6605435417544456

Epoch: 5| Step: 2
Training loss: 0.41959840059280396
Validation loss: 1.6395051261430145

Epoch: 5| Step: 3
Training loss: 0.6298733949661255
Validation loss: 1.639978475468133

Epoch: 5| Step: 4
Training loss: 0.3141915202140808
Validation loss: 1.6356389766098351

Epoch: 5| Step: 5
Training loss: 0.41267746686935425
Validation loss: 1.6474045168968938

Epoch: 5| Step: 6
Training loss: 0.6837150454521179
Validation loss: 1.6578928360375025

Epoch: 5| Step: 7
Training loss: 0.6351161003112793
Validation loss: 1.6905710940719934

Epoch: 5| Step: 8
Training loss: 0.5570029020309448
Validation loss: 1.6875607749467254

Epoch: 5| Step: 9
Training loss: 0.5496651530265808
Validation loss: 1.6658982935772146

Epoch: 5| Step: 10
Training loss: 0.6955636143684387
Validation loss: 1.6835144668497064

Epoch: 546| Step: 0
Training loss: 0.5677346587181091
Validation loss: 1.6625078673003821

Epoch: 5| Step: 1
Training loss: 0.7578732371330261
Validation loss: 1.6250407208678543

Epoch: 5| Step: 2
Training loss: 0.8012977838516235
Validation loss: 1.6184083338706725

Epoch: 5| Step: 3
Training loss: 0.7805474996566772
Validation loss: 1.5719601620909989

Epoch: 5| Step: 4
Training loss: 0.5087718963623047
Validation loss: 1.5787689544821297

Epoch: 5| Step: 5
Training loss: 0.3434607684612274
Validation loss: 1.609213371430674

Epoch: 5| Step: 6
Training loss: 0.8114951848983765
Validation loss: 1.6444283352103284

Epoch: 5| Step: 7
Training loss: 0.387112557888031
Validation loss: 1.6359454560023483

Epoch: 5| Step: 8
Training loss: 0.41178861260414124
Validation loss: 1.6480262138510262

Epoch: 5| Step: 9
Training loss: 0.633232057094574
Validation loss: 1.6828279482421054

Epoch: 5| Step: 10
Training loss: 0.3727605640888214
Validation loss: 1.6860164474415522

Epoch: 547| Step: 0
Training loss: 0.7102798223495483
Validation loss: 1.7537536492911718

Epoch: 5| Step: 1
Training loss: 0.49331751465797424
Validation loss: 1.7636147199138519

Epoch: 5| Step: 2
Training loss: 0.6526095867156982
Validation loss: 1.7132284513083837

Epoch: 5| Step: 3
Training loss: 0.47939762473106384
Validation loss: 1.7002045954427412

Epoch: 5| Step: 4
Training loss: 0.8475225567817688
Validation loss: 1.6595029472022929

Epoch: 5| Step: 5
Training loss: 0.6604061722755432
Validation loss: 1.6564738417184481

Epoch: 5| Step: 6
Training loss: 0.4724232256412506
Validation loss: 1.6500929786312966

Epoch: 5| Step: 7
Training loss: 0.41772526502609253
Validation loss: 1.6753799120585124

Epoch: 5| Step: 8
Training loss: 0.5956082940101624
Validation loss: 1.642620058469875

Epoch: 5| Step: 9
Training loss: 0.5567046403884888
Validation loss: 1.614363916458622

Epoch: 5| Step: 10
Training loss: 0.44140926003456116
Validation loss: 1.6411761647911483

Epoch: 548| Step: 0
Training loss: 0.5281294584274292
Validation loss: 1.6634952227274578

Epoch: 5| Step: 1
Training loss: 0.42691120505332947
Validation loss: 1.6924521000154558

Epoch: 5| Step: 2
Training loss: 0.6349686980247498
Validation loss: 1.707304657146495

Epoch: 5| Step: 3
Training loss: 0.5690416097640991
Validation loss: 1.6800644833554503

Epoch: 5| Step: 4
Training loss: 0.40561920404434204
Validation loss: 1.6494582891464233

Epoch: 5| Step: 5
Training loss: 0.5840203166007996
Validation loss: 1.6460445491216515

Epoch: 5| Step: 6
Training loss: 0.6471766829490662
Validation loss: 1.6198313774601105

Epoch: 5| Step: 7
Training loss: 0.8570844531059265
Validation loss: 1.6032710216378654

Epoch: 5| Step: 8
Training loss: 0.6617204546928406
Validation loss: 1.6244292041306854

Epoch: 5| Step: 9
Training loss: 0.491396427154541
Validation loss: 1.623225861980069

Epoch: 5| Step: 10
Training loss: 0.448687881231308
Validation loss: 1.6189147272417623

Epoch: 549| Step: 0
Training loss: 0.7545493841171265
Validation loss: 1.6369388872577297

Epoch: 5| Step: 1
Training loss: 0.5393099188804626
Validation loss: 1.6362214947259555

Epoch: 5| Step: 2
Training loss: 0.6831054091453552
Validation loss: 1.6666437028556742

Epoch: 5| Step: 3
Training loss: 0.4204080104827881
Validation loss: 1.6606719698957217

Epoch: 5| Step: 4
Training loss: 0.6396581530570984
Validation loss: 1.7144997927450365

Epoch: 5| Step: 5
Training loss: 0.386235773563385
Validation loss: 1.7287325500160136

Epoch: 5| Step: 6
Training loss: 0.8541589975357056
Validation loss: 1.7035134569291146

Epoch: 5| Step: 7
Training loss: 0.47052425146102905
Validation loss: 1.6642412665069743

Epoch: 5| Step: 8
Training loss: 0.497823566198349
Validation loss: 1.6501844377927883

Epoch: 5| Step: 9
Training loss: 0.6023483872413635
Validation loss: 1.5915158102589269

Epoch: 5| Step: 10
Training loss: 0.45938369631767273
Validation loss: 1.6180561511747298

Epoch: 550| Step: 0
Training loss: 0.8501151204109192
Validation loss: 1.5720513379702004

Epoch: 5| Step: 1
Training loss: 0.47768449783325195
Validation loss: 1.5816242797400362

Epoch: 5| Step: 2
Training loss: 0.7169969081878662
Validation loss: 1.5578899793727423

Epoch: 5| Step: 3
Training loss: 0.5960482358932495
Validation loss: 1.553783134747577

Epoch: 5| Step: 4
Training loss: 0.5549903512001038
Validation loss: 1.5990978389657953

Epoch: 5| Step: 5
Training loss: 0.24135836958885193
Validation loss: 1.6181791572160618

Epoch: 5| Step: 6
Training loss: 0.7746781706809998
Validation loss: 1.6283279426636235

Epoch: 5| Step: 7
Training loss: 0.7244088053703308
Validation loss: 1.6610144158845306

Epoch: 5| Step: 8
Training loss: 0.5835317969322205
Validation loss: 1.6484220694470149

Epoch: 5| Step: 9
Training loss: 0.4574642777442932
Validation loss: 1.6434718024346135

Epoch: 5| Step: 10
Training loss: 0.2738112807273865
Validation loss: 1.633679082316737

Testing loss: 2.2085112068388195
