Epoch: 1| Step: 0
Training loss: 5.539730833379798
Validation loss: 5.769295100907012

Epoch: 6| Step: 1
Training loss: 5.122376491534033
Validation loss: 5.764072423823926

Epoch: 6| Step: 2
Training loss: 6.270538154151985
Validation loss: 5.759539247212952

Epoch: 6| Step: 3
Training loss: 5.885884044172576
Validation loss: 5.754884379671187

Epoch: 6| Step: 4
Training loss: 6.617458729775593
Validation loss: 5.749799365537651

Epoch: 6| Step: 5
Training loss: 6.247718699864513
Validation loss: 5.745028950298157

Epoch: 6| Step: 6
Training loss: 5.634031547449937
Validation loss: 5.739844007550165

Epoch: 6| Step: 7
Training loss: 4.416512300684739
Validation loss: 5.734480311546141

Epoch: 6| Step: 8
Training loss: 6.16145778300223
Validation loss: 5.729164453172302

Epoch: 6| Step: 9
Training loss: 6.220563001267198
Validation loss: 5.72337940673661

Epoch: 6| Step: 10
Training loss: 6.077719863686963
Validation loss: 5.71774197933695

Epoch: 6| Step: 11
Training loss: 4.0697876341055865
Validation loss: 5.711370977434755

Epoch: 6| Step: 12
Training loss: 6.109359702166748
Validation loss: 5.705243464151431

Epoch: 6| Step: 13
Training loss: 5.916170699416043
Validation loss: 5.698825303083145

Epoch: 2| Step: 0
Training loss: 5.11562159217157
Validation loss: 5.692283532634989

Epoch: 6| Step: 1
Training loss: 6.541720671542191
Validation loss: 5.685356001971304

Epoch: 6| Step: 2
Training loss: 6.073447499268203
Validation loss: 5.6780844769124545

Epoch: 6| Step: 3
Training loss: 6.480436374429375
Validation loss: 5.6700489432828345

Epoch: 6| Step: 4
Training loss: 5.598805790678783
Validation loss: 5.661822042663172

Epoch: 6| Step: 5
Training loss: 5.2809321742383935
Validation loss: 5.654202573100629

Epoch: 6| Step: 6
Training loss: 6.5340932105742615
Validation loss: 5.64540526699337

Epoch: 6| Step: 7
Training loss: 6.1464170361937285
Validation loss: 5.635958808143515

Epoch: 6| Step: 8
Training loss: 4.758738260136946
Validation loss: 5.625884271207005

Epoch: 6| Step: 9
Training loss: 6.254013908836774
Validation loss: 5.616418842758714

Epoch: 6| Step: 10
Training loss: 4.883957092409101
Validation loss: 5.606322426220152

Epoch: 6| Step: 11
Training loss: 4.807033852896256
Validation loss: 5.595449358502509

Epoch: 6| Step: 12
Training loss: 3.964058934602198
Validation loss: 5.584114291299759

Epoch: 6| Step: 13
Training loss: 6.746500591651519
Validation loss: 5.572630173736257

Epoch: 3| Step: 0
Training loss: 5.887990671108983
Validation loss: 5.560681526876845

Epoch: 6| Step: 1
Training loss: 5.059988835439314
Validation loss: 5.548048102357863

Epoch: 6| Step: 2
Training loss: 5.21854642368189
Validation loss: 5.534966786325661

Epoch: 6| Step: 3
Training loss: 5.049197391899842
Validation loss: 5.521344417505673

Epoch: 6| Step: 4
Training loss: 6.1962221880010215
Validation loss: 5.50653944428146

Epoch: 6| Step: 5
Training loss: 5.535533388759505
Validation loss: 5.491395745657838

Epoch: 6| Step: 6
Training loss: 4.577394186283403
Validation loss: 5.475788116182741

Epoch: 6| Step: 7
Training loss: 6.179544285635066
Validation loss: 5.4593935026697045

Epoch: 6| Step: 8
Training loss: 4.964327013210531
Validation loss: 5.443034971052218

Epoch: 6| Step: 9
Training loss: 5.853693208746843
Validation loss: 5.42509244648479

Epoch: 6| Step: 10
Training loss: 4.705773504484964
Validation loss: 5.40749153156304

Epoch: 6| Step: 11
Training loss: 6.626571468894985
Validation loss: 5.388877694136958

Epoch: 6| Step: 12
Training loss: 5.2297251531033595
Validation loss: 5.3692564119004045

Epoch: 6| Step: 13
Training loss: 5.610369325880278
Validation loss: 5.349007668754775

Epoch: 4| Step: 0
Training loss: 4.16602478169411
Validation loss: 5.328247269069031

Epoch: 6| Step: 1
Training loss: 5.119075607358475
Validation loss: 5.306553859444387

Epoch: 6| Step: 2
Training loss: 5.3616481219963
Validation loss: 5.286408074058878

Epoch: 6| Step: 3
Training loss: 5.20215512879122
Validation loss: 5.265230450509667

Epoch: 6| Step: 4
Training loss: 4.954313791377431
Validation loss: 5.24256759763734

Epoch: 6| Step: 5
Training loss: 5.473034733298751
Validation loss: 5.220346663530835

Epoch: 6| Step: 6
Training loss: 4.471668064279773
Validation loss: 5.197452360766868

Epoch: 6| Step: 7
Training loss: 6.576396651656732
Validation loss: 5.175020535320168

Epoch: 6| Step: 8
Training loss: 6.597964128862172
Validation loss: 5.1523334702378305

Epoch: 6| Step: 9
Training loss: 4.957267689458205
Validation loss: 5.127702726179166

Epoch: 6| Step: 10
Training loss: 4.086488296408016
Validation loss: 5.103034655080069

Epoch: 6| Step: 11
Training loss: 4.891445103338543
Validation loss: 5.080419373268421

Epoch: 6| Step: 12
Training loss: 5.483015364652344
Validation loss: 5.0560451787181675

Epoch: 6| Step: 13
Training loss: 5.323452598431682
Validation loss: 5.033080805149774

Epoch: 5| Step: 0
Training loss: 5.105230768052348
Validation loss: 5.010273270952067

Epoch: 6| Step: 1
Training loss: 3.8884284624894345
Validation loss: 4.98510114757937

Epoch: 6| Step: 2
Training loss: 4.294058913844384
Validation loss: 4.963766849600049

Epoch: 6| Step: 3
Training loss: 6.0226806481783015
Validation loss: 4.940073335722746

Epoch: 6| Step: 4
Training loss: 4.445041105168291
Validation loss: 4.916514921827452

Epoch: 6| Step: 5
Training loss: 5.713587030203442
Validation loss: 4.894608097890437

Epoch: 6| Step: 6
Training loss: 4.593603430245719
Validation loss: 4.870071757721303

Epoch: 6| Step: 7
Training loss: 5.008446996904408
Validation loss: 4.8469716737675625

Epoch: 6| Step: 8
Training loss: 4.4877918796664575
Validation loss: 4.823635113276332

Epoch: 6| Step: 9
Training loss: 4.699657492636639
Validation loss: 4.80007359865294

Epoch: 6| Step: 10
Training loss: 4.606844760379954
Validation loss: 4.777012304064876

Epoch: 6| Step: 11
Training loss: 5.500759939231816
Validation loss: 4.754495275756868

Epoch: 6| Step: 12
Training loss: 5.584223813837277
Validation loss: 4.732367226118858

Epoch: 6| Step: 13
Training loss: 4.3856685804681
Validation loss: 4.711976103108821

Epoch: 6| Step: 0
Training loss: 5.507214755906635
Validation loss: 4.689759517253514

Epoch: 6| Step: 1
Training loss: 3.344147417925804
Validation loss: 4.668201624053699

Epoch: 6| Step: 2
Training loss: 5.909665043822347
Validation loss: 4.647651566351946

Epoch: 6| Step: 3
Training loss: 4.549528101669004
Validation loss: 4.625313364380961

Epoch: 6| Step: 4
Training loss: 4.81197800220462
Validation loss: 4.604443453211135

Epoch: 6| Step: 5
Training loss: 5.420499687668442
Validation loss: 4.585717955566555

Epoch: 6| Step: 6
Training loss: 4.907000636123856
Validation loss: 4.5672201681816

Epoch: 6| Step: 7
Training loss: 4.237572395358952
Validation loss: 4.551065363177632

Epoch: 6| Step: 8
Training loss: 3.9970243830200776
Validation loss: 4.53576199928534

Epoch: 6| Step: 9
Training loss: 3.778522737453569
Validation loss: 4.519393448133592

Epoch: 6| Step: 10
Training loss: 4.678449107061365
Validation loss: 4.507839204294626

Epoch: 6| Step: 11
Training loss: 4.613824487755098
Validation loss: 4.492384390134277

Epoch: 6| Step: 12
Training loss: 4.6374827834475525
Validation loss: 4.479470514216139

Epoch: 6| Step: 13
Training loss: 3.9750158153675157
Validation loss: 4.464880759433075

Epoch: 7| Step: 0
Training loss: 4.741477749798164
Validation loss: 4.452652009413392

Epoch: 6| Step: 1
Training loss: 4.340194015033748
Validation loss: 4.440790488819421

Epoch: 6| Step: 2
Training loss: 5.243854922675993
Validation loss: 4.427276909762441

Epoch: 6| Step: 3
Training loss: 4.349073263084983
Validation loss: 4.415892520204275

Epoch: 6| Step: 4
Training loss: 4.190601168457357
Validation loss: 4.4034794254307466

Epoch: 6| Step: 5
Training loss: 3.5265793420932843
Validation loss: 4.392002719119284

Epoch: 6| Step: 6
Training loss: 5.075752337835638
Validation loss: 4.3811619353543

Epoch: 6| Step: 7
Training loss: 4.795729111975999
Validation loss: 4.369666467200153

Epoch: 6| Step: 8
Training loss: 3.918752939810251
Validation loss: 4.359158524117831

Epoch: 6| Step: 9
Training loss: 4.260764906003207
Validation loss: 4.347405479077436

Epoch: 6| Step: 10
Training loss: 4.124218259776326
Validation loss: 4.337112288006313

Epoch: 6| Step: 11
Training loss: 5.039119655077994
Validation loss: 4.3275221621052395

Epoch: 6| Step: 12
Training loss: 4.899788848064295
Validation loss: 4.318379433564167

Epoch: 6| Step: 13
Training loss: 3.58867200255796
Validation loss: 4.3084199618008086

Epoch: 8| Step: 0
Training loss: 4.702627770382995
Validation loss: 4.300007864622234

Epoch: 6| Step: 1
Training loss: 4.446632765755591
Validation loss: 4.289842455439627

Epoch: 6| Step: 2
Training loss: 3.6755391769884795
Validation loss: 4.282310522751672

Epoch: 6| Step: 3
Training loss: 3.9826230255109607
Validation loss: 4.2746389813614165

Epoch: 6| Step: 4
Training loss: 4.020459304305682
Validation loss: 4.264894729698273

Epoch: 6| Step: 5
Training loss: 5.3743738208906535
Validation loss: 4.256832066293842

Epoch: 6| Step: 6
Training loss: 4.538988542857043
Validation loss: 4.249330930023156

Epoch: 6| Step: 7
Training loss: 4.7116022605708565
Validation loss: 4.2423720699522764

Epoch: 6| Step: 8
Training loss: 4.359533382259523
Validation loss: 4.234045625473978

Epoch: 6| Step: 9
Training loss: 4.324726850230146
Validation loss: 4.226170065261828

Epoch: 6| Step: 10
Training loss: 4.057149327155928
Validation loss: 4.218866107395736

Epoch: 6| Step: 11
Training loss: 4.725812061100274
Validation loss: 4.213133209341388

Epoch: 6| Step: 12
Training loss: 3.525304329362789
Validation loss: 4.203319872731578

Epoch: 6| Step: 13
Training loss: 4.530325117760029
Validation loss: 4.197444499086175

Epoch: 9| Step: 0
Training loss: 3.9963450422729285
Validation loss: 4.190483417755791

Epoch: 6| Step: 1
Training loss: 5.478971335213376
Validation loss: 4.183914764357166

Epoch: 6| Step: 2
Training loss: 4.763956547075328
Validation loss: 4.1754421156007195

Epoch: 6| Step: 3
Training loss: 4.5484767334221266
Validation loss: 4.168809063500361

Epoch: 6| Step: 4
Training loss: 3.251006044051889
Validation loss: 4.1609928993512115

Epoch: 6| Step: 5
Training loss: 4.130038334481547
Validation loss: 4.155233802518175

Epoch: 6| Step: 6
Training loss: 3.2131791283842213
Validation loss: 4.148181073474724

Epoch: 6| Step: 7
Training loss: 4.850359928893869
Validation loss: 4.141347100942065

Epoch: 6| Step: 8
Training loss: 4.001253170165904
Validation loss: 4.136526990542338

Epoch: 6| Step: 9
Training loss: 3.9494346310616786
Validation loss: 4.128832950784091

Epoch: 6| Step: 10
Training loss: 4.091412058650044
Validation loss: 4.123827056829765

Epoch: 6| Step: 11
Training loss: 4.651152822683431
Validation loss: 4.116782048490674

Epoch: 6| Step: 12
Training loss: 4.352354679562991
Validation loss: 4.114317215143078

Epoch: 6| Step: 13
Training loss: 4.085793953994385
Validation loss: 4.106028861699437

Epoch: 10| Step: 0
Training loss: 3.5512077318822772
Validation loss: 4.100006587825818

Epoch: 6| Step: 1
Training loss: 4.1991465291754615
Validation loss: 4.093164468006202

Epoch: 6| Step: 2
Training loss: 4.322783220674988
Validation loss: 4.086882689583195

Epoch: 6| Step: 3
Training loss: 2.958463173466062
Validation loss: 4.082678494778622

Epoch: 6| Step: 4
Training loss: 3.9987049390490412
Validation loss: 4.077426117373116

Epoch: 6| Step: 5
Training loss: 4.035414326512346
Validation loss: 4.070709185881418

Epoch: 6| Step: 6
Training loss: 4.804674796731174
Validation loss: 4.067912895499347

Epoch: 6| Step: 7
Training loss: 4.914837944331732
Validation loss: 4.060703306240986

Epoch: 6| Step: 8
Training loss: 3.642214972262731
Validation loss: 4.055512277793

Epoch: 6| Step: 9
Training loss: 4.9317906845981865
Validation loss: 4.049694741667059

Epoch: 6| Step: 10
Training loss: 4.4195716709057296
Validation loss: 4.045248837805945

Epoch: 6| Step: 11
Training loss: 3.79510582415731
Validation loss: 4.038096406415208

Epoch: 6| Step: 12
Training loss: 4.565450054266068
Validation loss: 4.032457711804476

Epoch: 6| Step: 13
Training loss: 4.302610031042046
Validation loss: 4.029001931732741

Epoch: 11| Step: 0
Training loss: 4.715051275077645
Validation loss: 4.022031034501858

Epoch: 6| Step: 1
Training loss: 3.57713070843443
Validation loss: 4.018632222030194

Epoch: 6| Step: 2
Training loss: 4.142870254683769
Validation loss: 4.014672533289941

Epoch: 6| Step: 3
Training loss: 4.2760352236489725
Validation loss: 4.01118102740828

Epoch: 6| Step: 4
Training loss: 3.399764580149551
Validation loss: 4.005402418669614

Epoch: 6| Step: 5
Training loss: 4.347539991005106
Validation loss: 3.9996123254221367

Epoch: 6| Step: 6
Training loss: 4.655149188903323
Validation loss: 3.993241453166788

Epoch: 6| Step: 7
Training loss: 3.6920316620499207
Validation loss: 3.98735816907262

Epoch: 6| Step: 8
Training loss: 3.92135142444777
Validation loss: 3.983736098697964

Epoch: 6| Step: 9
Training loss: 4.886216001316708
Validation loss: 3.9772142025781196

Epoch: 6| Step: 10
Training loss: 4.2403600982484235
Validation loss: 3.9705144622313435

Epoch: 6| Step: 11
Training loss: 3.6968670855426957
Validation loss: 3.9674398623811205

Epoch: 6| Step: 12
Training loss: 4.067353621031201
Validation loss: 3.9631107733150626

Epoch: 6| Step: 13
Training loss: 4.004769104815625
Validation loss: 3.956394226195936

Epoch: 12| Step: 0
Training loss: 3.707019544609088
Validation loss: 3.952821966953846

Epoch: 6| Step: 1
Training loss: 4.653178385984883
Validation loss: 3.9489512659225388

Epoch: 6| Step: 2
Training loss: 4.509500435441391
Validation loss: 3.9442736102283527

Epoch: 6| Step: 3
Training loss: 3.148165934851105
Validation loss: 3.9423061376002684

Epoch: 6| Step: 4
Training loss: 5.154082426443075
Validation loss: 3.936159634010576

Epoch: 6| Step: 5
Training loss: 3.114784480885591
Validation loss: 3.931786497129163

Epoch: 6| Step: 6
Training loss: 3.4547916032624393
Validation loss: 3.9254925479604106

Epoch: 6| Step: 7
Training loss: 4.06593177804976
Validation loss: 3.920335800415611

Epoch: 6| Step: 8
Training loss: 3.6947093253598946
Validation loss: 3.9172255004577328

Epoch: 6| Step: 9
Training loss: 4.504371850594999
Validation loss: 3.9158838760103034

Epoch: 6| Step: 10
Training loss: 4.166855896785393
Validation loss: 3.9086091298966905

Epoch: 6| Step: 11
Training loss: 4.154126076354924
Validation loss: 3.9062375317446345

Epoch: 6| Step: 12
Training loss: 3.844232544421685
Validation loss: 3.9032005972231647

Epoch: 6| Step: 13
Training loss: 4.682476352646196
Validation loss: 3.8979527344281344

Epoch: 13| Step: 0
Training loss: 3.4202659690901824
Validation loss: 3.894639663716957

Epoch: 6| Step: 1
Training loss: 3.4369869889741986
Validation loss: 3.8919673916176913

Epoch: 6| Step: 2
Training loss: 3.820121775977931
Validation loss: 3.8868633742789687

Epoch: 6| Step: 3
Training loss: 4.034073188537674
Validation loss: 3.8839702060898755

Epoch: 6| Step: 4
Training loss: 4.012550215837696
Validation loss: 3.8789332946879447

Epoch: 6| Step: 5
Training loss: 4.51464326211714
Validation loss: 3.874414061600109

Epoch: 6| Step: 6
Training loss: 4.540714455738732
Validation loss: 3.870442204495336

Epoch: 6| Step: 7
Training loss: 4.417324568973425
Validation loss: 3.864875349687323

Epoch: 6| Step: 8
Training loss: 4.384465033544126
Validation loss: 3.860158963469612

Epoch: 6| Step: 9
Training loss: 3.6773387758972227
Validation loss: 3.857870821722815

Epoch: 6| Step: 10
Training loss: 4.068658005572426
Validation loss: 3.8553997795434922

Epoch: 6| Step: 11
Training loss: 4.49793153483254
Validation loss: 3.8506422966418095

Epoch: 6| Step: 12
Training loss: 3.285437536727682
Validation loss: 3.845257316567039

Epoch: 6| Step: 13
Training loss: 4.087319718331122
Validation loss: 3.8420796927444263

Epoch: 14| Step: 0
Training loss: 4.588732411998523
Validation loss: 3.8364120593182394

Epoch: 6| Step: 1
Training loss: 4.60909216061514
Validation loss: 3.8336183585573105

Epoch: 6| Step: 2
Training loss: 3.606334247629779
Validation loss: 3.831270149985085

Epoch: 6| Step: 3
Training loss: 4.323114572920281
Validation loss: 3.826460211839469

Epoch: 6| Step: 4
Training loss: 3.5706776238183844
Validation loss: 3.824604191851469

Epoch: 6| Step: 5
Training loss: 4.803451552797047
Validation loss: 3.819777855712974

Epoch: 6| Step: 6
Training loss: 4.149219963577774
Validation loss: 3.8157678239893578

Epoch: 6| Step: 7
Training loss: 4.2671441248138775
Validation loss: 3.8112304795528282

Epoch: 6| Step: 8
Training loss: 3.9071864111986607
Validation loss: 3.80918142323598

Epoch: 6| Step: 9
Training loss: 4.125098949748338
Validation loss: 3.804386647624489

Epoch: 6| Step: 10
Training loss: 2.533680349558526
Validation loss: 3.8014588525733166

Epoch: 6| Step: 11
Training loss: 2.852529199903782
Validation loss: 3.795625738461894

Epoch: 6| Step: 12
Training loss: 4.291328095843043
Validation loss: 3.7939621216466595

Epoch: 6| Step: 13
Training loss: 3.0759334605030686
Validation loss: 3.790569163260697

Epoch: 15| Step: 0
Training loss: 4.08077951614034
Validation loss: 3.787402809759091

Epoch: 6| Step: 1
Training loss: 4.759656627034706
Validation loss: 3.783976910702598

Epoch: 6| Step: 2
Training loss: 4.688854174513069
Validation loss: 3.779275062300734

Epoch: 6| Step: 3
Training loss: 3.876158141296654
Validation loss: 3.777601585908103

Epoch: 6| Step: 4
Training loss: 3.1067025666625248
Validation loss: 3.7722420846967695

Epoch: 6| Step: 5
Training loss: 3.552036244070014
Validation loss: 3.7684444614845902

Epoch: 6| Step: 6
Training loss: 3.1116646622370547
Validation loss: 3.7642806140848197

Epoch: 6| Step: 7
Training loss: 4.269346297743788
Validation loss: 3.7630520649819736

Epoch: 6| Step: 8
Training loss: 4.183553401634914
Validation loss: 3.758081963016396

Epoch: 6| Step: 9
Training loss: 2.9527077354847373
Validation loss: 3.7574493728724754

Epoch: 6| Step: 10
Training loss: 2.9599221131671056
Validation loss: 3.7539627439553693

Epoch: 6| Step: 11
Training loss: 4.815911211126823
Validation loss: 3.750773718532504

Epoch: 6| Step: 12
Training loss: 3.8400709952308287
Validation loss: 3.7455484856414993

Epoch: 6| Step: 13
Training loss: 4.527862966681296
Validation loss: 3.7436102528288364

Epoch: 16| Step: 0
Training loss: 3.495641037597097
Validation loss: 3.742104414428291

Epoch: 6| Step: 1
Training loss: 4.659589964873204
Validation loss: 3.7393463061475893

Epoch: 6| Step: 2
Training loss: 3.612594819721959
Validation loss: 3.734244019393583

Epoch: 6| Step: 3
Training loss: 4.538549397499703
Validation loss: 3.7287316003517854

Epoch: 6| Step: 4
Training loss: 4.16077790249687
Validation loss: 3.7240654147834586

Epoch: 6| Step: 5
Training loss: 2.6572165133262753
Validation loss: 3.7209021969823173

Epoch: 6| Step: 6
Training loss: 4.426092609924241
Validation loss: 3.71778376714596

Epoch: 6| Step: 7
Training loss: 4.7096504237201575
Validation loss: 3.7127540046555803

Epoch: 6| Step: 8
Training loss: 3.9997850598760327
Validation loss: 3.7103196968005796

Epoch: 6| Step: 9
Training loss: 2.6312055352955093
Validation loss: 3.7091504881517765

Epoch: 6| Step: 10
Training loss: 4.303626620351996
Validation loss: 3.708655870234479

Epoch: 6| Step: 11
Training loss: 3.42604110932725
Validation loss: 3.704012646237868

Epoch: 6| Step: 12
Training loss: 3.2597824471087065
Validation loss: 3.7011017359415446

Epoch: 6| Step: 13
Training loss: 3.986974249831975
Validation loss: 3.6946253275183163

Epoch: 17| Step: 0
Training loss: 2.7623648528445175
Validation loss: 3.6937912100217853

Epoch: 6| Step: 1
Training loss: 4.244940045655643
Validation loss: 3.693829629126964

Epoch: 6| Step: 2
Training loss: 4.029644550332742
Validation loss: 3.688025268719036

Epoch: 6| Step: 3
Training loss: 4.141427822377082
Validation loss: 3.6809666736334616

Epoch: 6| Step: 4
Training loss: 4.3616488962731
Validation loss: 3.681707779945433

Epoch: 6| Step: 5
Training loss: 3.583628590566002
Validation loss: 3.679977734040486

Epoch: 6| Step: 6
Training loss: 3.4511318064135508
Validation loss: 3.680538241737234

Epoch: 6| Step: 7
Training loss: 3.1244428519450955
Validation loss: 3.675686078755699

Epoch: 6| Step: 8
Training loss: 4.602629921492045
Validation loss: 3.6730960293298107

Epoch: 6| Step: 9
Training loss: 4.492969106595578
Validation loss: 3.6660730929318626

Epoch: 6| Step: 10
Training loss: 4.369888807754572
Validation loss: 3.6644263167903133

Epoch: 6| Step: 11
Training loss: 3.7548943686834524
Validation loss: 3.6642072913873416

Epoch: 6| Step: 12
Training loss: 3.6106694530136347
Validation loss: 3.662082874008055

Epoch: 6| Step: 13
Training loss: 2.014366525886079
Validation loss: 3.6603001355162292

Epoch: 18| Step: 0
Training loss: 4.180978736004043
Validation loss: 3.6598430403270092

Epoch: 6| Step: 1
Training loss: 3.592586030295002
Validation loss: 3.650690909958038

Epoch: 6| Step: 2
Training loss: 4.193303655530488
Validation loss: 3.647408242582249

Epoch: 6| Step: 3
Training loss: 4.3125088456657465
Validation loss: 3.647232540029288

Epoch: 6| Step: 4
Training loss: 3.3175774293443134
Validation loss: 3.644858562521197

Epoch: 6| Step: 5
Training loss: 3.2986749011558603
Validation loss: 3.640747411892392

Epoch: 6| Step: 6
Training loss: 3.3342256464306548
Validation loss: 3.6382708489758997

Epoch: 6| Step: 7
Training loss: 4.086031794143788
Validation loss: 3.634730520085116

Epoch: 6| Step: 8
Training loss: 3.2830716843762975
Validation loss: 3.630861544046186

Epoch: 6| Step: 9
Training loss: 3.563645429679294
Validation loss: 3.6305841427447514

Epoch: 6| Step: 10
Training loss: 4.990224437367796
Validation loss: 3.6264369904231057

Epoch: 6| Step: 11
Training loss: 2.631907955734257
Validation loss: 3.622868588448572

Epoch: 6| Step: 12
Training loss: 4.591167736235628
Validation loss: 3.6229109212954858

Epoch: 6| Step: 13
Training loss: 3.3776867380198703
Validation loss: 3.6214576573113546

Epoch: 19| Step: 0
Training loss: 3.9432563484869725
Validation loss: 3.621239374514944

Epoch: 6| Step: 1
Training loss: 3.8661412528845682
Validation loss: 3.61725103077591

Epoch: 6| Step: 2
Training loss: 4.333159565498178
Validation loss: 3.617161329021424

Epoch: 6| Step: 3
Training loss: 4.670919161078061
Validation loss: 3.6133889952217904

Epoch: 6| Step: 4
Training loss: 2.892832310215097
Validation loss: 3.6108282173786765

Epoch: 6| Step: 5
Training loss: 3.441386574592592
Validation loss: 3.605886079210128

Epoch: 6| Step: 6
Training loss: 3.810224010059768
Validation loss: 3.6031755280394386

Epoch: 6| Step: 7
Training loss: 3.5705747946253235
Validation loss: 3.6016276958275992

Epoch: 6| Step: 8
Training loss: 4.492363277810936
Validation loss: 3.5985060613146014

Epoch: 6| Step: 9
Training loss: 3.801920360399314
Validation loss: 3.5945848790836257

Epoch: 6| Step: 10
Training loss: 3.4864185310844653
Validation loss: 3.5932576959158884

Epoch: 6| Step: 11
Training loss: 3.8501207852923693
Validation loss: 3.593714166278002

Epoch: 6| Step: 12
Training loss: 3.5969173902835765
Validation loss: 3.5887932377196687

Epoch: 6| Step: 13
Training loss: 2.294152131547851
Validation loss: 3.587861870935109

Epoch: 20| Step: 0
Training loss: 3.8528333815015663
Validation loss: 3.5845977506001145

Epoch: 6| Step: 1
Training loss: 4.309362624761283
Validation loss: 3.5797604226088597

Epoch: 6| Step: 2
Training loss: 3.643855286740681
Validation loss: 3.580592746973657

Epoch: 6| Step: 3
Training loss: 2.941593969669754
Validation loss: 3.58219415843945

Epoch: 6| Step: 4
Training loss: 3.7556724878750596
Validation loss: 3.5753925653809504

Epoch: 6| Step: 5
Training loss: 3.7458310159429242
Validation loss: 3.5769185218672446

Epoch: 6| Step: 6
Training loss: 3.829145023145032
Validation loss: 3.5733076776312958

Epoch: 6| Step: 7
Training loss: 2.9364664410310835
Validation loss: 3.572634336582495

Epoch: 6| Step: 8
Training loss: 3.7757321285665184
Validation loss: 3.5710135190597248

Epoch: 6| Step: 9
Training loss: 4.54325507615539
Validation loss: 3.565709980576445

Epoch: 6| Step: 10
Training loss: 4.083196417141481
Validation loss: 3.563646046913393

Epoch: 6| Step: 11
Training loss: 3.0612586483379554
Validation loss: 3.560527091863235

Epoch: 6| Step: 12
Training loss: 4.189562389309415
Validation loss: 3.5576074780402016

Epoch: 6| Step: 13
Training loss: 3.7769119978498247
Validation loss: 3.5581610767014906

Epoch: 21| Step: 0
Training loss: 3.144473929504737
Validation loss: 3.556383379505658

Epoch: 6| Step: 1
Training loss: 4.111951593166074
Validation loss: 3.5564070335988975

Epoch: 6| Step: 2
Training loss: 3.651168813772521
Validation loss: 3.553918883100861

Epoch: 6| Step: 3
Training loss: 3.9335941136652637
Validation loss: 3.5502033931036885

Epoch: 6| Step: 4
Training loss: 3.642650646479814
Validation loss: 3.5466447467883726

Epoch: 6| Step: 5
Training loss: 4.787731888137683
Validation loss: 3.545311975197753

Epoch: 6| Step: 6
Training loss: 3.87910785131942
Validation loss: 3.542629124679899

Epoch: 6| Step: 7
Training loss: 3.4317483119753414
Validation loss: 3.540525617170315

Epoch: 6| Step: 8
Training loss: 3.660927673925807
Validation loss: 3.539680806341343

Epoch: 6| Step: 9
Training loss: 4.186247908875611
Validation loss: 3.539086009083789

Epoch: 6| Step: 10
Training loss: 3.4654109795876
Validation loss: 3.534983112303975

Epoch: 6| Step: 11
Training loss: 3.3789864062024253
Validation loss: 3.5335732383414107

Epoch: 6| Step: 12
Training loss: 3.1021091546358246
Validation loss: 3.533361673463952

Epoch: 6| Step: 13
Training loss: 3.7983817419293016
Validation loss: 3.533895061111603

Epoch: 22| Step: 0
Training loss: 2.957260062512518
Validation loss: 3.53086461940742

Epoch: 6| Step: 1
Training loss: 3.079627430415643
Validation loss: 3.529815197936245

Epoch: 6| Step: 2
Training loss: 3.9167300821134985
Validation loss: 3.527271458295372

Epoch: 6| Step: 3
Training loss: 4.1421699376779
Validation loss: 3.5268899432197007

Epoch: 6| Step: 4
Training loss: 3.7597632152995524
Validation loss: 3.5247774676886334

Epoch: 6| Step: 5
Training loss: 4.112645229569621
Validation loss: 3.521982530551048

Epoch: 6| Step: 6
Training loss: 2.9502172939639553
Validation loss: 3.520887948345772

Epoch: 6| Step: 7
Training loss: 3.8381455664370203
Validation loss: 3.519507399058656

Epoch: 6| Step: 8
Training loss: 4.189361841590018
Validation loss: 3.5179435538934953

Epoch: 6| Step: 9
Training loss: 3.602480293553581
Validation loss: 3.5147000578878336

Epoch: 6| Step: 10
Training loss: 3.8168553973404
Validation loss: 3.52023370370406

Epoch: 6| Step: 11
Training loss: 2.6410747799612126
Validation loss: 3.512325237003403

Epoch: 6| Step: 12
Training loss: 4.621433842092293
Validation loss: 3.5102661155057793

Epoch: 6| Step: 13
Training loss: 4.256691321349132
Validation loss: 3.5071105744403512

Epoch: 23| Step: 0
Training loss: 4.051048689339396
Validation loss: 3.5071880461602793

Epoch: 6| Step: 1
Training loss: 2.724955000199598
Validation loss: 3.5060197157180064

Epoch: 6| Step: 2
Training loss: 4.023709363918831
Validation loss: 3.503565441548014

Epoch: 6| Step: 3
Training loss: 3.878845152897162
Validation loss: 3.501526824036847

Epoch: 6| Step: 4
Training loss: 3.2011720239570587
Validation loss: 3.499940124562102

Epoch: 6| Step: 5
Training loss: 3.336281966352483
Validation loss: 3.5002485456567136

Epoch: 6| Step: 6
Training loss: 3.7451548747288896
Validation loss: 3.498504574832551

Epoch: 6| Step: 7
Training loss: 4.418035666905908
Validation loss: 3.4979789307120184

Epoch: 6| Step: 8
Training loss: 3.875173503313901
Validation loss: 3.4946078267145215

Epoch: 6| Step: 9
Training loss: 2.7159219700162223
Validation loss: 3.493820844653259

Epoch: 6| Step: 10
Training loss: 3.872879432525231
Validation loss: 3.4919528655243597

Epoch: 6| Step: 11
Training loss: 4.163194404851627
Validation loss: 3.4932274123596385

Epoch: 6| Step: 12
Training loss: 3.3655857604563173
Validation loss: 3.492572757391975

Epoch: 6| Step: 13
Training loss: 4.358565498037581
Validation loss: 3.4916846325357036

Epoch: 24| Step: 0
Training loss: 3.391403741666459
Validation loss: 3.4893041923641164

Epoch: 6| Step: 1
Training loss: 4.14654532345986
Validation loss: 3.485932500763421

Epoch: 6| Step: 2
Training loss: 4.072233775355066
Validation loss: 3.4860322052678048

Epoch: 6| Step: 3
Training loss: 3.1470845915047194
Validation loss: 3.4854001509392565

Epoch: 6| Step: 4
Training loss: 4.297891836361234
Validation loss: 3.4842112880870295

Epoch: 6| Step: 5
Training loss: 3.2036215792668976
Validation loss: 3.479776202435987

Epoch: 6| Step: 6
Training loss: 4.253385205405973
Validation loss: 3.4808054667530404

Epoch: 6| Step: 7
Training loss: 3.7134800603107045
Validation loss: 3.4789585471039697

Epoch: 6| Step: 8
Training loss: 4.1463219947303145
Validation loss: 3.4772468626107322

Epoch: 6| Step: 9
Training loss: 4.292101396683687
Validation loss: 3.476831914388395

Epoch: 6| Step: 10
Training loss: 3.5563503526094515
Validation loss: 3.4765853197142254

Epoch: 6| Step: 11
Training loss: 2.904081130079359
Validation loss: 3.4760505501192345

Epoch: 6| Step: 12
Training loss: 3.371114118565348
Validation loss: 3.473688661633273

Epoch: 6| Step: 13
Training loss: 1.6117258031989392
Validation loss: 3.47164033707925

Epoch: 25| Step: 0
Training loss: 3.725190427892252
Validation loss: 3.4707716741519947

Epoch: 6| Step: 1
Training loss: 2.7971042134220543
Validation loss: 3.4695904692889563

Epoch: 6| Step: 2
Training loss: 3.3264201637732165
Validation loss: 3.4673819851867718

Epoch: 6| Step: 3
Training loss: 3.589748642816585
Validation loss: 3.4681149985803734

Epoch: 6| Step: 4
Training loss: 4.200587077208719
Validation loss: 3.46451742358556

Epoch: 6| Step: 5
Training loss: 4.286263308099761
Validation loss: 3.4675931441696624

Epoch: 6| Step: 6
Training loss: 3.8600903052800453
Validation loss: 3.4644937607286064

Epoch: 6| Step: 7
Training loss: 3.007199073760511
Validation loss: 3.466011424491949

Epoch: 6| Step: 8
Training loss: 3.5405236737262906
Validation loss: 3.467128325439755

Epoch: 6| Step: 9
Training loss: 4.597128527487804
Validation loss: 3.4650264340885895

Epoch: 6| Step: 10
Training loss: 3.855097574070341
Validation loss: 3.4630642629992137

Epoch: 6| Step: 11
Training loss: 3.358617226943854
Validation loss: 3.4614933287671628

Epoch: 6| Step: 12
Training loss: 3.724824448103488
Validation loss: 3.463444762069764

Epoch: 6| Step: 13
Training loss: 2.933237432588351
Validation loss: 3.4671208189082794

Epoch: 26| Step: 0
Training loss: 4.154732333856323
Validation loss: 3.4681227956837097

Epoch: 6| Step: 1
Training loss: 3.752703391604688
Validation loss: 3.4624636202045274

Epoch: 6| Step: 2
Training loss: 3.5690360093292237
Validation loss: 3.4555603068186453

Epoch: 6| Step: 3
Training loss: 3.7291545050793893
Validation loss: 3.456295391966209

Epoch: 6| Step: 4
Training loss: 4.415825577788062
Validation loss: 3.454305854945042

Epoch: 6| Step: 5
Training loss: 3.3332843459026487
Validation loss: 3.454953804956831

Epoch: 6| Step: 6
Training loss: 4.047453260899985
Validation loss: 3.4535247863817786

Epoch: 6| Step: 7
Training loss: 3.3433101756953696
Validation loss: 3.4526243866383406

Epoch: 6| Step: 8
Training loss: 3.8469391285240446
Validation loss: 3.4498002158385552

Epoch: 6| Step: 9
Training loss: 2.6022090623919
Validation loss: 3.4493846555877408

Epoch: 6| Step: 10
Training loss: 3.617589808722089
Validation loss: 3.446796409356486

Epoch: 6| Step: 11
Training loss: 3.651837286283539
Validation loss: 3.4455653461904676

Epoch: 6| Step: 12
Training loss: 3.01408259818662
Validation loss: 3.4460285830249076

Epoch: 6| Step: 13
Training loss: 4.180150657019536
Validation loss: 3.4454950782761835

Epoch: 27| Step: 0
Training loss: 4.13658641859279
Validation loss: 3.4458441656261107

Epoch: 6| Step: 1
Training loss: 3.9728137259840395
Validation loss: 3.4462850975939228

Epoch: 6| Step: 2
Training loss: 3.2290227714390123
Validation loss: 3.446993056341462

Epoch: 6| Step: 3
Training loss: 3.0691216952650606
Validation loss: 3.4475987865980793

Epoch: 6| Step: 4
Training loss: 3.4592416022545396
Validation loss: 3.445490677927306

Epoch: 6| Step: 5
Training loss: 4.598310425662012
Validation loss: 3.4450014630784045

Epoch: 6| Step: 6
Training loss: 3.8562908745427946
Validation loss: 3.44314636201088

Epoch: 6| Step: 7
Training loss: 3.023002021438069
Validation loss: 3.440984451130217

Epoch: 6| Step: 8
Training loss: 4.142815467549688
Validation loss: 3.441374993672078

Epoch: 6| Step: 9
Training loss: 3.922153903725201
Validation loss: 3.4406870680327755

Epoch: 6| Step: 10
Training loss: 3.3976439503201292
Validation loss: 3.4390816116113196

Epoch: 6| Step: 11
Training loss: 3.9959448286033914
Validation loss: 3.436277856529408

Epoch: 6| Step: 12
Training loss: 2.7412045882708354
Validation loss: 3.4364083862245827

Epoch: 6| Step: 13
Training loss: 2.882900660544323
Validation loss: 3.435081908222713

Epoch: 28| Step: 0
Training loss: 3.6454779896817913
Validation loss: 3.434355271889341

Epoch: 6| Step: 1
Training loss: 3.28869061395028
Validation loss: 3.434707121559349

Epoch: 6| Step: 2
Training loss: 4.037721629009254
Validation loss: 3.43421300832433

Epoch: 6| Step: 3
Training loss: 3.6508462212346764
Validation loss: 3.4317483642678837

Epoch: 6| Step: 4
Training loss: 3.1502804343717634
Validation loss: 3.431813960899352

Epoch: 6| Step: 5
Training loss: 2.9073523614976997
Validation loss: 3.4302572068293773

Epoch: 6| Step: 6
Training loss: 3.345998418083661
Validation loss: 3.4300354695962367

Epoch: 6| Step: 7
Training loss: 4.351839286178833
Validation loss: 3.4288872775610306

Epoch: 6| Step: 8
Training loss: 4.190996901973161
Validation loss: 3.428631952754303

Epoch: 6| Step: 9
Training loss: 3.8371985202124357
Validation loss: 3.4264748183264593

Epoch: 6| Step: 10
Training loss: 3.827441594371519
Validation loss: 3.4256958726054356

Epoch: 6| Step: 11
Training loss: 3.7545052486133557
Validation loss: 3.423867416935561

Epoch: 6| Step: 12
Training loss: 3.285644930350418
Validation loss: 3.423728846385452

Epoch: 6| Step: 13
Training loss: 3.5229464778770523
Validation loss: 3.4224688447851537

Epoch: 29| Step: 0
Training loss: 4.592636492449868
Validation loss: 3.420978194315341

Epoch: 6| Step: 1
Training loss: 3.6123354442036795
Validation loss: 3.419582568320841

Epoch: 6| Step: 2
Training loss: 3.192755909866552
Validation loss: 3.4176962091922016

Epoch: 6| Step: 3
Training loss: 3.551552129647269
Validation loss: 3.416491571277227

Epoch: 6| Step: 4
Training loss: 3.168239069269999
Validation loss: 3.417685845686918

Epoch: 6| Step: 5
Training loss: 3.957925889310698
Validation loss: 3.4197555543433924

Epoch: 6| Step: 6
Training loss: 3.808329317743256
Validation loss: 3.41735007391598

Epoch: 6| Step: 7
Training loss: 3.1262650027519485
Validation loss: 3.4179131319879614

Epoch: 6| Step: 8
Training loss: 3.7500588730323283
Validation loss: 3.414254652986221

Epoch: 6| Step: 9
Training loss: 3.7062748256836127
Validation loss: 3.4158101405104446

Epoch: 6| Step: 10
Training loss: 3.881649833392645
Validation loss: 3.419547926283647

Epoch: 6| Step: 11
Training loss: 3.219801055259349
Validation loss: 3.4198876891746655

Epoch: 6| Step: 12
Training loss: 3.492311206649103
Validation loss: 3.422498914989509

Epoch: 6| Step: 13
Training loss: 3.7172348397869586
Validation loss: 3.4227507201099128

Epoch: 30| Step: 0
Training loss: 2.285600876549168
Validation loss: 3.4195311329260214

Epoch: 6| Step: 1
Training loss: 2.774505581499385
Validation loss: 3.416867674690582

Epoch: 6| Step: 2
Training loss: 4.035990448773125
Validation loss: 3.4165586659079135

Epoch: 6| Step: 3
Training loss: 3.7063643696782314
Validation loss: 3.413817371393261

Epoch: 6| Step: 4
Training loss: 3.581358136047387
Validation loss: 3.4110865963032486

Epoch: 6| Step: 5
Training loss: 3.4868409877498774
Validation loss: 3.4116900691825354

Epoch: 6| Step: 6
Training loss: 3.263935436881804
Validation loss: 3.4124997754062916

Epoch: 6| Step: 7
Training loss: 3.8382084295103436
Validation loss: 3.4126760982533444

Epoch: 6| Step: 8
Training loss: 3.8319513621737724
Validation loss: 3.4109317005143063

Epoch: 6| Step: 9
Training loss: 4.351059725359166
Validation loss: 3.410518215297116

Epoch: 6| Step: 10
Training loss: 3.531156825634013
Validation loss: 3.4072542662240464

Epoch: 6| Step: 11
Training loss: 3.879111293202198
Validation loss: 3.4072042910104385

Epoch: 6| Step: 12
Training loss: 3.4852492257846523
Validation loss: 3.4046719415972153

Epoch: 6| Step: 13
Training loss: 4.76356436782901
Validation loss: 3.4043669495467372

Epoch: 31| Step: 0
Training loss: 3.7032795161592498
Validation loss: 3.4036982765353203

Epoch: 6| Step: 1
Training loss: 4.599217903988584
Validation loss: 3.403341526201896

Epoch: 6| Step: 2
Training loss: 3.5302918070925946
Validation loss: 3.4032704603073474

Epoch: 6| Step: 3
Training loss: 3.67456229062033
Validation loss: 3.4034467340249903

Epoch: 6| Step: 4
Training loss: 4.085335273197733
Validation loss: 3.4006480867858393

Epoch: 6| Step: 5
Training loss: 3.262000742160846
Validation loss: 3.399220762889663

Epoch: 6| Step: 6
Training loss: 3.993425330395674
Validation loss: 3.3986603920855005

Epoch: 6| Step: 7
Training loss: 3.804256469624798
Validation loss: 3.3975153012083448

Epoch: 6| Step: 8
Training loss: 3.7255387089486804
Validation loss: 3.397691873506133

Epoch: 6| Step: 9
Training loss: 3.2026188148059735
Validation loss: 3.398097578056421

Epoch: 6| Step: 10
Training loss: 3.6409439143696583
Validation loss: 3.398778446960392

Epoch: 6| Step: 11
Training loss: 3.457755457997574
Validation loss: 3.396949354172066

Epoch: 6| Step: 12
Training loss: 2.8025400765622077
Validation loss: 3.3968972862629463

Epoch: 6| Step: 13
Training loss: 2.2200218101667306
Validation loss: 3.395781998227761

Epoch: 32| Step: 0
Training loss: 3.2874792642265787
Validation loss: 3.39461059470029

Epoch: 6| Step: 1
Training loss: 4.028641677522232
Validation loss: 3.3951829344929814

Epoch: 6| Step: 2
Training loss: 2.8239013155804007
Validation loss: 3.3946460425175045

Epoch: 6| Step: 3
Training loss: 3.917211670528989
Validation loss: 3.3939299199797173

Epoch: 6| Step: 4
Training loss: 2.852399144174172
Validation loss: 3.3928483508768155

Epoch: 6| Step: 5
Training loss: 3.3273612565392647
Validation loss: 3.3935828881085355

Epoch: 6| Step: 6
Training loss: 3.719625930847037
Validation loss: 3.391778175093363

Epoch: 6| Step: 7
Training loss: 3.7710988634452978
Validation loss: 3.3912945815815823

Epoch: 6| Step: 8
Training loss: 4.3499193907536595
Validation loss: 3.3899095163246344

Epoch: 6| Step: 9
Training loss: 3.1485062584574766
Validation loss: 3.388611087062942

Epoch: 6| Step: 10
Training loss: 3.8993294408392583
Validation loss: 3.3887438288051492

Epoch: 6| Step: 11
Training loss: 4.371397660695555
Validation loss: 3.388326654630746

Epoch: 6| Step: 12
Training loss: 3.522952974757613
Validation loss: 3.387322761831165

Epoch: 6| Step: 13
Training loss: 2.89389924885937
Validation loss: 3.38692762306047

Epoch: 33| Step: 0
Training loss: 3.7136662459197898
Validation loss: 3.38599534054628

Epoch: 6| Step: 1
Training loss: 4.049383026977063
Validation loss: 3.386428600490163

Epoch: 6| Step: 2
Training loss: 3.6714264291329783
Validation loss: 3.385291334282292

Epoch: 6| Step: 3
Training loss: 4.531325977609252
Validation loss: 3.3849496786596207

Epoch: 6| Step: 4
Training loss: 3.8082747262219487
Validation loss: 3.383891240224054

Epoch: 6| Step: 5
Training loss: 3.9077987652353845
Validation loss: 3.383417128862828

Epoch: 6| Step: 6
Training loss: 2.8700588722703673
Validation loss: 3.382968881827057

Epoch: 6| Step: 7
Training loss: 2.941404304655731
Validation loss: 3.382554558314716

Epoch: 6| Step: 8
Training loss: 4.1409467464174226
Validation loss: 3.3820207615612645

Epoch: 6| Step: 9
Training loss: 3.8285506031348415
Validation loss: 3.382866306422187

Epoch: 6| Step: 10
Training loss: 3.5455034603843862
Validation loss: 3.3812227584951264

Epoch: 6| Step: 11
Training loss: 3.67692964717154
Validation loss: 3.381106527581714

Epoch: 6| Step: 12
Training loss: 2.4579930689615437
Validation loss: 3.3793561556350333

Epoch: 6| Step: 13
Training loss: 2.076327356669276
Validation loss: 3.3799357083492265

Epoch: 34| Step: 0
Training loss: 3.1011984200668294
Validation loss: 3.379076819400507

Epoch: 6| Step: 1
Training loss: 3.2622514301185532
Validation loss: 3.3808566800690847

Epoch: 6| Step: 2
Training loss: 2.8627659436752078
Validation loss: 3.379490331266145

Epoch: 6| Step: 3
Training loss: 3.3458379483379175
Validation loss: 3.377722771779966

Epoch: 6| Step: 4
Training loss: 3.4630971675925437
Validation loss: 3.378853646079389

Epoch: 6| Step: 5
Training loss: 3.5408058167469703
Validation loss: 3.377679205764807

Epoch: 6| Step: 6
Training loss: 4.346734866989963
Validation loss: 3.3796890739474534

Epoch: 6| Step: 7
Training loss: 3.9364111469580396
Validation loss: 3.3767770413264286

Epoch: 6| Step: 8
Training loss: 3.5651679505836946
Validation loss: 3.3791514788338746

Epoch: 6| Step: 9
Training loss: 3.801053985188244
Validation loss: 3.3783240225492466

Epoch: 6| Step: 10
Training loss: 3.090374579086247
Validation loss: 3.376282961972508

Epoch: 6| Step: 11
Training loss: 3.6979026829987953
Validation loss: 3.3756949021926714

Epoch: 6| Step: 12
Training loss: 3.891054551031636
Validation loss: 3.374739692703515

Epoch: 6| Step: 13
Training loss: 4.735913923576771
Validation loss: 3.374461899447201

Epoch: 35| Step: 0
Training loss: 3.4064700554276697
Validation loss: 3.375196089644434

Epoch: 6| Step: 1
Training loss: 3.0461769282452766
Validation loss: 3.372774968382174

Epoch: 6| Step: 2
Training loss: 3.599644081747359
Validation loss: 3.373490439945921

Epoch: 6| Step: 3
Training loss: 3.7786864110484206
Validation loss: 3.3727888431886304

Epoch: 6| Step: 4
Training loss: 3.8180536562395018
Validation loss: 3.372108134321881

Epoch: 6| Step: 5
Training loss: 3.4063842467005148
Validation loss: 3.3722513826504468

Epoch: 6| Step: 6
Training loss: 3.270697054281584
Validation loss: 3.371747583092473

Epoch: 6| Step: 7
Training loss: 3.5592844321071246
Validation loss: 3.3713194430138063

Epoch: 6| Step: 8
Training loss: 3.7712665259859284
Validation loss: 3.3711246587020542

Epoch: 6| Step: 9
Training loss: 3.6494123639028024
Validation loss: 3.3702209085664956

Epoch: 6| Step: 10
Training loss: 2.978053563032739
Validation loss: 3.367964539254672

Epoch: 6| Step: 11
Training loss: 4.030518931257439
Validation loss: 3.36966287881886

Epoch: 6| Step: 12
Training loss: 4.120171003403868
Validation loss: 3.369013028765657

Epoch: 6| Step: 13
Training loss: 3.986262334479756
Validation loss: 3.369160297723362

Epoch: 36| Step: 0
Training loss: 3.553411166595315
Validation loss: 3.3689631224425516

Epoch: 6| Step: 1
Training loss: 2.9075949233378804
Validation loss: 3.3669911746500607

Epoch: 6| Step: 2
Training loss: 3.00010839902224
Validation loss: 3.3664238808599998

Epoch: 6| Step: 3
Training loss: 2.7513795340174285
Validation loss: 3.366990195484341

Epoch: 6| Step: 4
Training loss: 4.213253254994608
Validation loss: 3.366342843705895

Epoch: 6| Step: 5
Training loss: 4.178462510325456
Validation loss: 3.3658948956932466

Epoch: 6| Step: 6
Training loss: 3.601005593890607
Validation loss: 3.363951982147344

Epoch: 6| Step: 7
Training loss: 3.645105053051053
Validation loss: 3.364236347777671

Epoch: 6| Step: 8
Training loss: 3.7905525974236856
Validation loss: 3.365984417557497

Epoch: 6| Step: 9
Training loss: 3.4899195874413267
Validation loss: 3.363549582689295

Epoch: 6| Step: 10
Training loss: 3.392916278753985
Validation loss: 3.3635404753511473

Epoch: 6| Step: 11
Training loss: 4.363052184564651
Validation loss: 3.3637058677510843

Epoch: 6| Step: 12
Training loss: 3.0804618833437765
Validation loss: 3.362818040592925

Epoch: 6| Step: 13
Training loss: 4.201179593060089
Validation loss: 3.3614854178480895

Epoch: 37| Step: 0
Training loss: 3.7061474533432763
Validation loss: 3.3600889423618723

Epoch: 6| Step: 1
Training loss: 3.9279436675031536
Validation loss: 3.3626053065022092

Epoch: 6| Step: 2
Training loss: 3.2835551566180117
Validation loss: 3.3599348864176717

Epoch: 6| Step: 3
Training loss: 3.5623400468220177
Validation loss: 3.358121355196776

Epoch: 6| Step: 4
Training loss: 3.267554192418333
Validation loss: 3.3627920154254576

Epoch: 6| Step: 5
Training loss: 4.290034505354113
Validation loss: 3.3665925286324603

Epoch: 6| Step: 6
Training loss: 3.6607575629995757
Validation loss: 3.3603256418221923

Epoch: 6| Step: 7
Training loss: 2.8996329502779985
Validation loss: 3.3574206792426304

Epoch: 6| Step: 8
Training loss: 3.7178002434924733
Validation loss: 3.355910638446901

Epoch: 6| Step: 9
Training loss: 2.743077495074088
Validation loss: 3.355558779983485

Epoch: 6| Step: 10
Training loss: 3.0036447954426873
Validation loss: 3.3574165345579785

Epoch: 6| Step: 11
Training loss: 3.652068657128367
Validation loss: 3.35669013084941

Epoch: 6| Step: 12
Training loss: 4.508549092900697
Validation loss: 3.356471240230318

Epoch: 6| Step: 13
Training loss: 3.6373559248139706
Validation loss: 3.353914437236562

Epoch: 38| Step: 0
Training loss: 3.4880489942714377
Validation loss: 3.353910508358581

Epoch: 6| Step: 1
Training loss: 3.1376200861955628
Validation loss: 3.3528309381957113

Epoch: 6| Step: 2
Training loss: 3.7232825601975588
Validation loss: 3.352493283478404

Epoch: 6| Step: 3
Training loss: 3.8089655768015005
Validation loss: 3.3509517256286845

Epoch: 6| Step: 4
Training loss: 3.288863876035731
Validation loss: 3.3546110768450195

Epoch: 6| Step: 5
Training loss: 3.686551376135854
Validation loss: 3.3533774071322995

Epoch: 6| Step: 6
Training loss: 3.279097223253428
Validation loss: 3.348739258346959

Epoch: 6| Step: 7
Training loss: 3.560409200060437
Validation loss: 3.3509484037863935

Epoch: 6| Step: 8
Training loss: 3.5738310389955603
Validation loss: 3.349077847281975

Epoch: 6| Step: 9
Training loss: 4.812870952626989
Validation loss: 3.348732242803025

Epoch: 6| Step: 10
Training loss: 3.426983369028318
Validation loss: 3.348838455830122

Epoch: 6| Step: 11
Training loss: 3.363849870949158
Validation loss: 3.3486243605048367

Epoch: 6| Step: 12
Training loss: 3.306724551781194
Validation loss: 3.350746600663459

Epoch: 6| Step: 13
Training loss: 3.3530415292608953
Validation loss: 3.3610873956424725

Epoch: 39| Step: 0
Training loss: 2.3736636769135244
Validation loss: 3.349947947925916

Epoch: 6| Step: 1
Training loss: 3.2795417335252184
Validation loss: 3.3470200948053863

Epoch: 6| Step: 2
Training loss: 3.882049424160957
Validation loss: 3.3474119442369745

Epoch: 6| Step: 3
Training loss: 3.820437813480272
Validation loss: 3.3480924574197415

Epoch: 6| Step: 4
Training loss: 3.167987865761917
Validation loss: 3.3465414646089653

Epoch: 6| Step: 5
Training loss: 4.20034369016138
Validation loss: 3.347073306265567

Epoch: 6| Step: 6
Training loss: 4.217535225495562
Validation loss: 3.346235512076292

Epoch: 6| Step: 7
Training loss: 3.3224734466157586
Validation loss: 3.3451906063607524

Epoch: 6| Step: 8
Training loss: 3.452880022153636
Validation loss: 3.34332458991668

Epoch: 6| Step: 9
Training loss: 4.0562830378475665
Validation loss: 3.3440289983314875

Epoch: 6| Step: 10
Training loss: 3.3083777058762154
Validation loss: 3.3416098322983614

Epoch: 6| Step: 11
Training loss: 3.2346624716563537
Validation loss: 3.3452932258039945

Epoch: 6| Step: 12
Training loss: 3.4776395693756568
Validation loss: 3.3454407251063367

Epoch: 6| Step: 13
Training loss: 4.147066913639814
Validation loss: 3.350594800777766

Epoch: 40| Step: 0
Training loss: 3.737525281533563
Validation loss: 3.342799038733701

Epoch: 6| Step: 1
Training loss: 2.9367632652211086
Validation loss: 3.3447881694521504

Epoch: 6| Step: 2
Training loss: 4.32735659391994
Validation loss: 3.3423016393497402

Epoch: 6| Step: 3
Training loss: 3.9887526454934696
Validation loss: 3.343425969257806

Epoch: 6| Step: 4
Training loss: 3.628914528171061
Validation loss: 3.342556174203807

Epoch: 6| Step: 5
Training loss: 4.2333924677365635
Validation loss: 3.340162115509528

Epoch: 6| Step: 6
Training loss: 3.3271978815210033
Validation loss: 3.340608561932254

Epoch: 6| Step: 7
Training loss: 3.2874241461179743
Validation loss: 3.34011544997831

Epoch: 6| Step: 8
Training loss: 3.691475099597681
Validation loss: 3.3396603792833366

Epoch: 6| Step: 9
Training loss: 3.8402402407279608
Validation loss: 3.3392902258358195

Epoch: 6| Step: 10
Training loss: 3.5027713702636754
Validation loss: 3.338796223517472

Epoch: 6| Step: 11
Training loss: 2.79591071698753
Validation loss: 3.3379205316586407

Epoch: 6| Step: 12
Training loss: 3.2804445277185343
Validation loss: 3.337747853666683

Epoch: 6| Step: 13
Training loss: 2.761942939345673
Validation loss: 3.3379748320772946

Epoch: 41| Step: 0
Training loss: 3.5194456236115643
Validation loss: 3.337714421499339

Epoch: 6| Step: 1
Training loss: 3.8114817776114913
Validation loss: 3.3369596096608194

Epoch: 6| Step: 2
Training loss: 3.7571010748898512
Validation loss: 3.3368925655545176

Epoch: 6| Step: 3
Training loss: 2.8374275097430903
Validation loss: 3.3338991597577885

Epoch: 6| Step: 4
Training loss: 3.3337320725052275
Validation loss: 3.3359628478374415

Epoch: 6| Step: 5
Training loss: 3.365607012432347
Validation loss: 3.3357643327837203

Epoch: 6| Step: 6
Training loss: 3.7311985440436217
Validation loss: 3.3374877948514006

Epoch: 6| Step: 7
Training loss: 4.648284242812346
Validation loss: 3.335574898174193

Epoch: 6| Step: 8
Training loss: 3.1094688516379514
Validation loss: 3.3325702414173453

Epoch: 6| Step: 9
Training loss: 3.0252856537429924
Validation loss: 3.333745277750534

Epoch: 6| Step: 10
Training loss: 3.7533198602230176
Validation loss: 3.3342641628017278

Epoch: 6| Step: 11
Training loss: 3.4791383266246507
Validation loss: 3.3339526006269886

Epoch: 6| Step: 12
Training loss: 4.091335370752048
Validation loss: 3.3330365761564105

Epoch: 6| Step: 13
Training loss: 2.753973690857504
Validation loss: 3.333235928947886

Epoch: 42| Step: 0
Training loss: 3.4518549037599087
Validation loss: 3.3331140851139023

Epoch: 6| Step: 1
Training loss: 3.3932829252694643
Validation loss: 3.33200066188204

Epoch: 6| Step: 2
Training loss: 3.324727648142953
Validation loss: 3.335434106033575

Epoch: 6| Step: 3
Training loss: 2.9553035390418927
Validation loss: 3.3338243281828874

Epoch: 6| Step: 4
Training loss: 3.750010681137132
Validation loss: 3.3351783742694905

Epoch: 6| Step: 5
Training loss: 3.9489581798465223
Validation loss: 3.3313981735249554

Epoch: 6| Step: 6
Training loss: 2.8061250280747037
Validation loss: 3.3397039898857037

Epoch: 6| Step: 7
Training loss: 3.6519463144390447
Validation loss: 3.331209777368795

Epoch: 6| Step: 8
Training loss: 4.00445475473134
Validation loss: 3.3304600150083243

Epoch: 6| Step: 9
Training loss: 3.1052064796876455
Validation loss: 3.3297007168508546

Epoch: 6| Step: 10
Training loss: 3.6348939244719487
Validation loss: 3.329554149512266

Epoch: 6| Step: 11
Training loss: 4.273019271553588
Validation loss: 3.32819123553424

Epoch: 6| Step: 12
Training loss: 3.9908212014571025
Validation loss: 3.331524700254607

Epoch: 6| Step: 13
Training loss: 3.1512496165026045
Validation loss: 3.328461434325642

Epoch: 43| Step: 0
Training loss: 3.352765914304643
Validation loss: 3.3290719254610504

Epoch: 6| Step: 1
Training loss: 3.096441312076381
Validation loss: 3.328987505505374

Epoch: 6| Step: 2
Training loss: 3.016410448634089
Validation loss: 3.326543852685147

Epoch: 6| Step: 3
Training loss: 2.867247702982564
Validation loss: 3.3287484991093876

Epoch: 6| Step: 4
Training loss: 3.3014982810321443
Validation loss: 3.327470852148447

Epoch: 6| Step: 5
Training loss: 3.5393294008508236
Validation loss: 3.328032788155581

Epoch: 6| Step: 6
Training loss: 3.6097462120562023
Validation loss: 3.327317266886593

Epoch: 6| Step: 7
Training loss: 2.781368981720258
Validation loss: 3.326795149876464

Epoch: 6| Step: 8
Training loss: 4.568944064296574
Validation loss: 3.327069686150813

Epoch: 6| Step: 9
Training loss: 3.8115423281702636
Validation loss: 3.3266361551227286

Epoch: 6| Step: 10
Training loss: 4.052510112394486
Validation loss: 3.326301518468981

Epoch: 6| Step: 11
Training loss: 4.111143478632714
Validation loss: 3.3262073770092746

Epoch: 6| Step: 12
Training loss: 3.4983789232060083
Validation loss: 3.325267957545228

Epoch: 6| Step: 13
Training loss: 4.0564353865239795
Validation loss: 3.3240456371015403

Epoch: 44| Step: 0
Training loss: 2.714613123915933
Validation loss: 3.3222605220460353

Epoch: 6| Step: 1
Training loss: 3.01013316015184
Validation loss: 3.3243541531615675

Epoch: 6| Step: 2
Training loss: 4.177321404246971
Validation loss: 3.324735204746782

Epoch: 6| Step: 3
Training loss: 3.154031408140248
Validation loss: 3.325444264708919

Epoch: 6| Step: 4
Training loss: 3.2830093753249745
Validation loss: 3.32782052050353

Epoch: 6| Step: 5
Training loss: 2.6374344370137237
Validation loss: 3.327310469680624

Epoch: 6| Step: 6
Training loss: 3.3595285779756883
Validation loss: 3.349002675107844

Epoch: 6| Step: 7
Training loss: 3.7071019960813847
Validation loss: 3.3234515232057014

Epoch: 6| Step: 8
Training loss: 4.445916374501169
Validation loss: 3.323232229898046

Epoch: 6| Step: 9
Training loss: 3.477749945339948
Validation loss: 3.320587082764437

Epoch: 6| Step: 10
Training loss: 4.0447374980612345
Validation loss: 3.320752188073456

Epoch: 6| Step: 11
Training loss: 4.40795432602608
Validation loss: 3.323679349891397

Epoch: 6| Step: 12
Training loss: 3.0239721017791927
Validation loss: 3.32407379499508

Epoch: 6| Step: 13
Training loss: 3.9975050059102903
Validation loss: 3.322592126766939

Epoch: 45| Step: 0
Training loss: 3.6485150020626036
Validation loss: 3.3224175347988125

Epoch: 6| Step: 1
Training loss: 4.186492798793007
Validation loss: 3.3239801334064674

Epoch: 6| Step: 2
Training loss: 2.515465678033008
Validation loss: 3.3225597203120776

Epoch: 6| Step: 3
Training loss: 3.444461778029714
Validation loss: 3.323470167383275

Epoch: 6| Step: 4
Training loss: 3.424055267128595
Validation loss: 3.3219645110653144

Epoch: 6| Step: 5
Training loss: 2.895204617610305
Validation loss: 3.3230255990668844

Epoch: 6| Step: 6
Training loss: 3.28170104786803
Validation loss: 3.321109064185804

Epoch: 6| Step: 7
Training loss: 4.073747763104921
Validation loss: 3.320725391636853

Epoch: 6| Step: 8
Training loss: 4.210831055153938
Validation loss: 3.3202820880614268

Epoch: 6| Step: 9
Training loss: 3.7216220311723913
Validation loss: 3.32040383297158

Epoch: 6| Step: 10
Training loss: 2.7896290265178307
Validation loss: 3.319068497871972

Epoch: 6| Step: 11
Training loss: 4.052776261078729
Validation loss: 3.318859656610129

Epoch: 6| Step: 12
Training loss: 3.6977089980292455
Validation loss: 3.319085391709901

Epoch: 6| Step: 13
Training loss: 3.2529197195696873
Validation loss: 3.31849935345348

Epoch: 46| Step: 0
Training loss: 3.690917678067937
Validation loss: 3.319525997620978

Epoch: 6| Step: 1
Training loss: 3.7361389846108644
Validation loss: 3.3210594615840883

Epoch: 6| Step: 2
Training loss: 2.552489662261563
Validation loss: 3.3192772626613833

Epoch: 6| Step: 3
Training loss: 3.479744747052386
Validation loss: 3.3213905586976034

Epoch: 6| Step: 4
Training loss: 4.133279755973178
Validation loss: 3.316407670806175

Epoch: 6| Step: 5
Training loss: 2.9874296682849653
Validation loss: 3.315510632156326

Epoch: 6| Step: 6
Training loss: 3.607315863273794
Validation loss: 3.314743669016698

Epoch: 6| Step: 7
Training loss: 3.594168597181866
Validation loss: 3.314833191029069

Epoch: 6| Step: 8
Training loss: 2.880175700126406
Validation loss: 3.314012056598143

Epoch: 6| Step: 9
Training loss: 3.2806044170528277
Validation loss: 3.3136016010788243

Epoch: 6| Step: 10
Training loss: 3.588846061800067
Validation loss: 3.3131640235587336

Epoch: 6| Step: 11
Training loss: 3.595752589327412
Validation loss: 3.3144251483566034

Epoch: 6| Step: 12
Training loss: 4.643058780860877
Validation loss: 3.3134076172730027

Epoch: 6| Step: 13
Training loss: 3.5064814363687473
Validation loss: 3.312729022513174

Epoch: 47| Step: 0
Training loss: 3.5851386350164476
Validation loss: 3.311606647545344

Epoch: 6| Step: 1
Training loss: 3.1046556091974504
Validation loss: 3.311279373812571

Epoch: 6| Step: 2
Training loss: 3.3885591603642653
Validation loss: 3.3113490384524398

Epoch: 6| Step: 3
Training loss: 3.3140974691327516
Validation loss: 3.3109257711522475

Epoch: 6| Step: 4
Training loss: 4.211890854076159
Validation loss: 3.3098369565494674

Epoch: 6| Step: 5
Training loss: 4.3366832744760275
Validation loss: 3.310389255850661

Epoch: 6| Step: 6
Training loss: 3.1867312832057717
Validation loss: 3.3103483180639683

Epoch: 6| Step: 7
Training loss: 3.3406958491321372
Validation loss: 3.3108973574193725

Epoch: 6| Step: 8
Training loss: 3.666476042445146
Validation loss: 3.3166158780369708

Epoch: 6| Step: 9
Training loss: 2.9871040369133026
Validation loss: 3.31604702160101

Epoch: 6| Step: 10
Training loss: 3.018572221974711
Validation loss: 3.3143088227001942

Epoch: 6| Step: 11
Training loss: 4.078501950670257
Validation loss: 3.309932624724272

Epoch: 6| Step: 12
Training loss: 3.171907471739575
Validation loss: 3.3081265696088087

Epoch: 6| Step: 13
Training loss: 4.2300052406513045
Validation loss: 3.3073790257299502

Epoch: 48| Step: 0
Training loss: 2.808168593950652
Validation loss: 3.309481456845062

Epoch: 6| Step: 1
Training loss: 3.956329976459167
Validation loss: 3.3096448946271027

Epoch: 6| Step: 2
Training loss: 4.3516694471822035
Validation loss: 3.3088310634959694

Epoch: 6| Step: 3
Training loss: 3.2672871279383453
Validation loss: 3.3067935712249974

Epoch: 6| Step: 4
Training loss: 2.626248562289048
Validation loss: 3.3077393877048844

Epoch: 6| Step: 5
Training loss: 3.5971296258412737
Validation loss: 3.3060960710055207

Epoch: 6| Step: 6
Training loss: 3.4568319317099228
Validation loss: 3.306811013086325

Epoch: 6| Step: 7
Training loss: 3.8240949320401776
Validation loss: 3.3051203388964856

Epoch: 6| Step: 8
Training loss: 3.225140496084228
Validation loss: 3.305553291738021

Epoch: 6| Step: 9
Training loss: 3.9480491891055722
Validation loss: 3.306199399096175

Epoch: 6| Step: 10
Training loss: 3.5766705217959864
Validation loss: 3.3046613754410856

Epoch: 6| Step: 11
Training loss: 2.773381966048321
Validation loss: 3.3045246704080933

Epoch: 6| Step: 12
Training loss: 4.165585237672428
Validation loss: 3.3120962644905654

Epoch: 6| Step: 13
Training loss: 3.653445089004566
Validation loss: 3.3115444294876615

Epoch: 49| Step: 0
Training loss: 3.6495602695575275
Validation loss: 3.3123068758049046

Epoch: 6| Step: 1
Training loss: 3.3719457298970714
Validation loss: 3.3045940911060425

Epoch: 6| Step: 2
Training loss: 3.164828586848087
Validation loss: 3.305545256971397

Epoch: 6| Step: 3
Training loss: 3.9708864964345074
Validation loss: 3.311633750006756

Epoch: 6| Step: 4
Training loss: 3.1606544507438388
Validation loss: 3.308658842368623

Epoch: 6| Step: 5
Training loss: 3.6178387906253664
Validation loss: 3.305870906859366

Epoch: 6| Step: 6
Training loss: 3.404418172770903
Validation loss: 3.300113995330449

Epoch: 6| Step: 7
Training loss: 3.961068476631337
Validation loss: 3.3008853347172025

Epoch: 6| Step: 8
Training loss: 3.694224804409929
Validation loss: 3.299994433756609

Epoch: 6| Step: 9
Training loss: 3.536820330887408
Validation loss: 3.2987663606998177

Epoch: 6| Step: 10
Training loss: 3.282737757954479
Validation loss: 3.2988207375295877

Epoch: 6| Step: 11
Training loss: 3.828233616124923
Validation loss: 3.2970092999580274

Epoch: 6| Step: 12
Training loss: 3.2165247067238334
Validation loss: 3.296067179757955

Epoch: 6| Step: 13
Training loss: 3.6964932706553113
Validation loss: 3.298975219722718

Epoch: 50| Step: 0
Training loss: 3.624294738564973
Validation loss: 3.2962505458945337

Epoch: 6| Step: 1
Training loss: 3.6472503233620595
Validation loss: 3.296821273819287

Epoch: 6| Step: 2
Training loss: 3.719853341687948
Validation loss: 3.2959834109541073

Epoch: 6| Step: 3
Training loss: 2.890956880230075
Validation loss: 3.2966633281477056

Epoch: 6| Step: 4
Training loss: 3.549179605599403
Validation loss: 3.29737169787077

Epoch: 6| Step: 5
Training loss: 3.483402954817298
Validation loss: 3.2959618345032786

Epoch: 6| Step: 6
Training loss: 3.846645102305491
Validation loss: 3.295914278697992

Epoch: 6| Step: 7
Training loss: 3.62362618557545
Validation loss: 3.297218318486204

Epoch: 6| Step: 8
Training loss: 3.562585796193099
Validation loss: 3.2950454889951506

Epoch: 6| Step: 9
Training loss: 4.4076644034186705
Validation loss: 3.2961240588844514

Epoch: 6| Step: 10
Training loss: 3.630756017599968
Validation loss: 3.2949490851353267

Epoch: 6| Step: 11
Training loss: 3.3964582621013157
Validation loss: 3.295062337946051

Epoch: 6| Step: 12
Training loss: 2.3164270409717247
Validation loss: 3.294964692036796

Epoch: 6| Step: 13
Training loss: 3.3930095953857666
Validation loss: 3.2970515938061835

Epoch: 51| Step: 0
Training loss: 3.252853314783807
Validation loss: 3.2930308503639907

Epoch: 6| Step: 1
Training loss: 3.541429818405471
Validation loss: 3.2956875663700376

Epoch: 6| Step: 2
Training loss: 4.221654725557998
Validation loss: 3.296549646625785

Epoch: 6| Step: 3
Training loss: 4.2102797636827605
Validation loss: 3.294417949703636

Epoch: 6| Step: 4
Training loss: 3.3620798975921096
Validation loss: 3.294803197217675

Epoch: 6| Step: 5
Training loss: 3.584030807984296
Validation loss: 3.292893053671586

Epoch: 6| Step: 6
Training loss: 3.169984000132523
Validation loss: 3.2910698588104736

Epoch: 6| Step: 7
Training loss: 3.728003265363057
Validation loss: 3.294072887124185

Epoch: 6| Step: 8
Training loss: 4.524837613221649
Validation loss: 3.293944325629696

Epoch: 6| Step: 9
Training loss: 3.2777758416926237
Validation loss: 3.2945205748804804

Epoch: 6| Step: 10
Training loss: 3.027701749245664
Validation loss: 3.2919013496708036

Epoch: 6| Step: 11
Training loss: 2.528740097682721
Validation loss: 3.29594429167127

Epoch: 6| Step: 12
Training loss: 3.2625681610587387
Validation loss: 3.2945024532066403

Epoch: 6| Step: 13
Training loss: 3.0883736181402357
Validation loss: 3.2910957672097396

Epoch: 52| Step: 0
Training loss: 3.4056549952476503
Validation loss: 3.292062244709042

Epoch: 6| Step: 1
Training loss: 4.030044966984002
Validation loss: 3.29039171532496

Epoch: 6| Step: 2
Training loss: 2.399313701414004
Validation loss: 3.2895110068111793

Epoch: 6| Step: 3
Training loss: 3.820698911631201
Validation loss: 3.28681358028354

Epoch: 6| Step: 4
Training loss: 4.321554877947329
Validation loss: 3.2891226850114412

Epoch: 6| Step: 5
Training loss: 2.949390451851973
Validation loss: 3.289660826436756

Epoch: 6| Step: 6
Training loss: 3.2273240933988965
Validation loss: 3.290166660801196

Epoch: 6| Step: 7
Training loss: 4.032543122829015
Validation loss: 3.289252170714338

Epoch: 6| Step: 8
Training loss: 3.5488621191014262
Validation loss: 3.287976285202864

Epoch: 6| Step: 9
Training loss: 3.212246147842823
Validation loss: 3.2925242476029424

Epoch: 6| Step: 10
Training loss: 3.428365048373237
Validation loss: 3.2963172508073404

Epoch: 6| Step: 11
Training loss: 3.4525162518427455
Validation loss: 3.3038223613156616

Epoch: 6| Step: 12
Training loss: 3.733957434895362
Validation loss: 3.301562819107606

Epoch: 6| Step: 13
Training loss: 3.3760563645380812
Validation loss: 3.2823045683506678

Epoch: 53| Step: 0
Training loss: 3.053830702250505
Validation loss: 3.2802780649512737

Epoch: 6| Step: 1
Training loss: 3.3401332796653094
Validation loss: 3.2863504867185007

Epoch: 6| Step: 2
Training loss: 3.231802539326659
Validation loss: 3.294508483919023

Epoch: 6| Step: 3
Training loss: 3.715135885759524
Validation loss: 3.3034288615146434

Epoch: 6| Step: 4
Training loss: 3.4915724517808817
Validation loss: 3.295082393811587

Epoch: 6| Step: 5
Training loss: 3.4490874147737944
Validation loss: 3.30252522119542

Epoch: 6| Step: 6
Training loss: 3.2852983478018896
Validation loss: 3.2818579279070956

Epoch: 6| Step: 7
Training loss: 4.554044229874831
Validation loss: 3.2752219281733255

Epoch: 6| Step: 8
Training loss: 2.688045712445617
Validation loss: 3.2763900494646294

Epoch: 6| Step: 9
Training loss: 3.660136838554116
Validation loss: 3.281379172912155

Epoch: 6| Step: 10
Training loss: 4.1089922940703465
Validation loss: 3.287099858557209

Epoch: 6| Step: 11
Training loss: 3.5681121523384096
Validation loss: 3.2924012568660097

Epoch: 6| Step: 12
Training loss: 3.241189311232085
Validation loss: 3.29037636332517

Epoch: 6| Step: 13
Training loss: 3.6908759488054073
Validation loss: 3.2756189424780686

Epoch: 54| Step: 0
Training loss: 3.2623806401776987
Validation loss: 3.2670198187713364

Epoch: 6| Step: 1
Training loss: 3.93682552797707
Validation loss: 3.26330842530934

Epoch: 6| Step: 2
Training loss: 3.2837297061544293
Validation loss: 3.2584645328575745

Epoch: 6| Step: 3
Training loss: 3.480746034479242
Validation loss: 3.2579540513979635

Epoch: 6| Step: 4
Training loss: 2.744945562826939
Validation loss: 3.255487948445313

Epoch: 6| Step: 5
Training loss: 3.90239775871347
Validation loss: 3.2562583367242945

Epoch: 6| Step: 6
Training loss: 4.035439613341377
Validation loss: 3.2557852993805563

Epoch: 6| Step: 7
Training loss: 3.479116945806107
Validation loss: 3.255118744566915

Epoch: 6| Step: 8
Training loss: 3.700241833593474
Validation loss: 3.258015248573802

Epoch: 6| Step: 9
Training loss: 3.5554308438946993
Validation loss: 3.251011895224154

Epoch: 6| Step: 10
Training loss: 3.1304971791236254
Validation loss: 3.248574407266121

Epoch: 6| Step: 11
Training loss: 2.6170420136510226
Validation loss: 3.245989193339398

Epoch: 6| Step: 12
Training loss: 4.073021278436282
Validation loss: 3.2492914650147213

Epoch: 6| Step: 13
Training loss: 3.4430968064950607
Validation loss: 3.2450745849226346

Epoch: 55| Step: 0
Training loss: 3.212927282988061
Validation loss: 3.249250686883409

Epoch: 6| Step: 1
Training loss: 3.9563161160457097
Validation loss: 3.2451775270933005

Epoch: 6| Step: 2
Training loss: 3.2072444570762437
Validation loss: 3.244946407255595

Epoch: 6| Step: 3
Training loss: 2.701269141133359
Validation loss: 3.2427439088028374

Epoch: 6| Step: 4
Training loss: 3.763646029199009
Validation loss: 3.2412206044947514

Epoch: 6| Step: 5
Training loss: 4.194129819768143
Validation loss: 3.2442047647593135

Epoch: 6| Step: 6
Training loss: 3.2673488611758987
Validation loss: 3.2406474352359718

Epoch: 6| Step: 7
Training loss: 3.5021374851255738
Validation loss: 3.240877200481562

Epoch: 6| Step: 8
Training loss: 3.329931207811189
Validation loss: 3.2373036374326256

Epoch: 6| Step: 9
Training loss: 3.4083098736416533
Validation loss: 3.2409001340275534

Epoch: 6| Step: 10
Training loss: 3.83351297925088
Validation loss: 3.239665159620387

Epoch: 6| Step: 11
Training loss: 3.742900995394899
Validation loss: 3.2389390229070547

Epoch: 6| Step: 12
Training loss: 3.1027918764539892
Validation loss: 3.2398662688243682

Epoch: 6| Step: 13
Training loss: 3.212511108616722
Validation loss: 3.242170920282051

Epoch: 56| Step: 0
Training loss: 3.220131882993625
Validation loss: 3.240754917137859

Epoch: 6| Step: 1
Training loss: 3.0374086091535264
Validation loss: 3.2407070543212

Epoch: 6| Step: 2
Training loss: 3.808257196668387
Validation loss: 3.2397195606508484

Epoch: 6| Step: 3
Training loss: 3.5687605074378754
Validation loss: 3.252182592851742

Epoch: 6| Step: 4
Training loss: 2.818761171712115
Validation loss: 3.239669810256937

Epoch: 6| Step: 5
Training loss: 3.4044456252463173
Validation loss: 3.234591109419605

Epoch: 6| Step: 6
Training loss: 3.480596161125393
Validation loss: 3.2336887311033538

Epoch: 6| Step: 7
Training loss: 3.529164196195192
Validation loss: 3.236776587326797

Epoch: 6| Step: 8
Training loss: 3.5611342104200485
Validation loss: 3.239847388834049

Epoch: 6| Step: 9
Training loss: 4.305536369909931
Validation loss: 3.23432985820897

Epoch: 6| Step: 10
Training loss: 3.0056893125218718
Validation loss: 3.230843838386148

Epoch: 6| Step: 11
Training loss: 3.8916504515828096
Validation loss: 3.2316488299961503

Epoch: 6| Step: 12
Training loss: 3.626140283596767
Validation loss: 3.2311622722444113

Epoch: 6| Step: 13
Training loss: 3.0399968689350265
Validation loss: 3.2317518896550657

Epoch: 57| Step: 0
Training loss: 3.2305717774721265
Validation loss: 3.233008224077091

Epoch: 6| Step: 1
Training loss: 4.2622683106937025
Validation loss: 3.2313936909235434

Epoch: 6| Step: 2
Training loss: 3.526601787275624
Validation loss: 3.2317545518564734

Epoch: 6| Step: 3
Training loss: 2.788303988025458
Validation loss: 3.23008085417037

Epoch: 6| Step: 4
Training loss: 3.8523160185750878
Validation loss: 3.238093146023773

Epoch: 6| Step: 5
Training loss: 3.3295342412340205
Validation loss: 3.2355361351514

Epoch: 6| Step: 6
Training loss: 2.6727756521520956
Validation loss: 3.231691557998582

Epoch: 6| Step: 7
Training loss: 3.201000867724934
Validation loss: 3.231067723210971

Epoch: 6| Step: 8
Training loss: 3.8755522303707934
Validation loss: 3.2279990497073383

Epoch: 6| Step: 9
Training loss: 3.773845137224231
Validation loss: 3.2277808135481054

Epoch: 6| Step: 10
Training loss: 3.6151320217817924
Validation loss: 3.229092361648537

Epoch: 6| Step: 11
Training loss: 3.760961913983259
Validation loss: 3.2271953354370035

Epoch: 6| Step: 12
Training loss: 3.31004919401647
Validation loss: 3.226208767824021

Epoch: 6| Step: 13
Training loss: 2.8751492668876804
Validation loss: 3.2251227397222246

Epoch: 58| Step: 0
Training loss: 3.284611605788256
Validation loss: 3.2230128012781343

Epoch: 6| Step: 1
Training loss: 3.067547900285248
Validation loss: 3.2258408953765922

Epoch: 6| Step: 2
Training loss: 2.868070793778459
Validation loss: 3.223992029351561

Epoch: 6| Step: 3
Training loss: 2.939597010338478
Validation loss: 3.2225758424872355

Epoch: 6| Step: 4
Training loss: 4.235448497096573
Validation loss: 3.2245495918492924

Epoch: 6| Step: 5
Training loss: 3.7667295490068473
Validation loss: 3.2234637618803794

Epoch: 6| Step: 6
Training loss: 2.8019019615344827
Validation loss: 3.223140629486791

Epoch: 6| Step: 7
Training loss: 3.9706161797232036
Validation loss: 3.223246251027819

Epoch: 6| Step: 8
Training loss: 4.066973292146533
Validation loss: 3.221013269130361

Epoch: 6| Step: 9
Training loss: 2.7108180654638945
Validation loss: 3.221914320753809

Epoch: 6| Step: 10
Training loss: 3.2117197239493174
Validation loss: 3.2261818059326823

Epoch: 6| Step: 11
Training loss: 3.887317523169408
Validation loss: 3.229847858731392

Epoch: 6| Step: 12
Training loss: 3.550450879329723
Validation loss: 3.226648743244156

Epoch: 6| Step: 13
Training loss: 3.9676780154043927
Validation loss: 3.2191527644598987

Epoch: 59| Step: 0
Training loss: 3.8626477654595646
Validation loss: 3.2211679499680845

Epoch: 6| Step: 1
Training loss: 3.3743223287022412
Validation loss: 3.2192777142731552

Epoch: 6| Step: 2
Training loss: 3.70248909814068
Validation loss: 3.218945518104439

Epoch: 6| Step: 3
Training loss: 2.198113985530275
Validation loss: 3.220697791876824

Epoch: 6| Step: 4
Training loss: 2.6504675362769783
Validation loss: 3.2193654092597934

Epoch: 6| Step: 5
Training loss: 3.311330480868352
Validation loss: 3.2183747575110186

Epoch: 6| Step: 6
Training loss: 3.7702200937151815
Validation loss: 3.2140480773047986

Epoch: 6| Step: 7
Training loss: 3.2910648874280373
Validation loss: 3.217855545652781

Epoch: 6| Step: 8
Training loss: 3.445522587397818
Validation loss: 3.218147042151029

Epoch: 6| Step: 9
Training loss: 3.1524360198895507
Validation loss: 3.2186817496869566

Epoch: 6| Step: 10
Training loss: 3.286407196243564
Validation loss: 3.215184367440901

Epoch: 6| Step: 11
Training loss: 4.347987680749365
Validation loss: 3.2157380503374036

Epoch: 6| Step: 12
Training loss: 4.016357592540438
Validation loss: 3.2150042448744784

Epoch: 6| Step: 13
Training loss: 3.679281094860788
Validation loss: 3.2085000612629195

Epoch: 60| Step: 0
Training loss: 3.2735811261189522
Validation loss: 3.208870335547448

Epoch: 6| Step: 1
Training loss: 3.4893992513052683
Validation loss: 3.2090683081770504

Epoch: 6| Step: 2
Training loss: 2.8989451495926377
Validation loss: 3.2091458115818585

Epoch: 6| Step: 3
Training loss: 2.6969816927177113
Validation loss: 3.2068768306064896

Epoch: 6| Step: 4
Training loss: 3.66307318046299
Validation loss: 3.2114474654557217

Epoch: 6| Step: 5
Training loss: 3.348542816029637
Validation loss: 3.212550648552993

Epoch: 6| Step: 6
Training loss: 4.077422918343068
Validation loss: 3.2137709538292594

Epoch: 6| Step: 7
Training loss: 3.0410294235396647
Validation loss: 3.207489126073501

Epoch: 6| Step: 8
Training loss: 3.9332911688489722
Validation loss: 3.2077548226350157

Epoch: 6| Step: 9
Training loss: 3.3620340868273138
Validation loss: 3.204107939387603

Epoch: 6| Step: 10
Training loss: 3.8388878068003867
Validation loss: 3.207276025585077

Epoch: 6| Step: 11
Training loss: 3.6267235703305016
Validation loss: 3.205642056181483

Epoch: 6| Step: 12
Training loss: 3.1698905863366487
Validation loss: 3.2076853761177135

Epoch: 6| Step: 13
Training loss: 3.935492594228646
Validation loss: 3.2094511160611305

Epoch: 61| Step: 0
Training loss: 2.9595594596374295
Validation loss: 3.2144516478362193

Epoch: 6| Step: 1
Training loss: 3.55624912040713
Validation loss: 3.218475102267367

Epoch: 6| Step: 2
Training loss: 3.0268612581737058
Validation loss: 3.219865283358108

Epoch: 6| Step: 3
Training loss: 3.032131106337671
Validation loss: 3.2195486465165133

Epoch: 6| Step: 4
Training loss: 4.0031473175546415
Validation loss: 3.219159774111803

Epoch: 6| Step: 5
Training loss: 4.347776892839846
Validation loss: 3.2175128190681224

Epoch: 6| Step: 6
Training loss: 3.9034667819107245
Validation loss: 3.213349811470176

Epoch: 6| Step: 7
Training loss: 3.3408872524625837
Validation loss: 3.2132590737321354

Epoch: 6| Step: 8
Training loss: 3.627044627278728
Validation loss: 3.2119993693504205

Epoch: 6| Step: 9
Training loss: 3.169396996892875
Validation loss: 3.209988669760492

Epoch: 6| Step: 10
Training loss: 3.038860716409252
Validation loss: 3.20545707383541

Epoch: 6| Step: 11
Training loss: 3.259266627147644
Validation loss: 3.2089598871859746

Epoch: 6| Step: 12
Training loss: 3.129530712205537
Validation loss: 3.203204901754399

Epoch: 6| Step: 13
Training loss: 3.8464846923555265
Validation loss: 3.206792432355905

Epoch: 62| Step: 0
Training loss: 3.246235648128261
Validation loss: 3.2077690036249606

Epoch: 6| Step: 1
Training loss: 3.286293440771445
Validation loss: 3.207582638165566

Epoch: 6| Step: 2
Training loss: 3.7172248341375984
Validation loss: 3.205207425914064

Epoch: 6| Step: 3
Training loss: 3.3262725115977996
Validation loss: 3.209032605508868

Epoch: 6| Step: 4
Training loss: 4.081178888282657
Validation loss: 3.207835510544436

Epoch: 6| Step: 5
Training loss: 3.1675830987328384
Validation loss: 3.2064199352744356

Epoch: 6| Step: 6
Training loss: 3.6470552558447165
Validation loss: 3.2109630537691665

Epoch: 6| Step: 7
Training loss: 3.663662561253688
Validation loss: 3.2081610091720236

Epoch: 6| Step: 8
Training loss: 3.5523306274842845
Validation loss: 3.206623350970608

Epoch: 6| Step: 9
Training loss: 3.9383565788427863
Validation loss: 3.2069019554710105

Epoch: 6| Step: 10
Training loss: 2.965619173034153
Validation loss: 3.203358922740943

Epoch: 6| Step: 11
Training loss: 3.3704662247264077
Validation loss: 3.2002679720318445

Epoch: 6| Step: 12
Training loss: 3.4164787488913166
Validation loss: 3.2009645456823757

Epoch: 6| Step: 13
Training loss: 1.8114155122837194
Validation loss: 3.1991523332009777

Epoch: 63| Step: 0
Training loss: 2.9123790470270197
Validation loss: 3.1984552334288447

Epoch: 6| Step: 1
Training loss: 3.6487537712555986
Validation loss: 3.1980686331341923

Epoch: 6| Step: 2
Training loss: 2.7728731682678536
Validation loss: 3.1994750045355045

Epoch: 6| Step: 3
Training loss: 3.0135449761641615
Validation loss: 3.1997616040735815

Epoch: 6| Step: 4
Training loss: 3.417195364511769
Validation loss: 3.1994283935679277

Epoch: 6| Step: 5
Training loss: 3.3120100990639005
Validation loss: 3.206666434816329

Epoch: 6| Step: 6
Training loss: 3.368066093367164
Validation loss: 3.213009242104143

Epoch: 6| Step: 7
Training loss: 3.412348336562952
Validation loss: 3.2075958991917957

Epoch: 6| Step: 8
Training loss: 3.8632676728938624
Validation loss: 3.200626738633794

Epoch: 6| Step: 9
Training loss: 4.02033690449987
Validation loss: 3.196421367266999

Epoch: 6| Step: 10
Training loss: 4.296418210805213
Validation loss: 3.196234721140445

Epoch: 6| Step: 11
Training loss: 3.192636875931495
Validation loss: 3.200229004515563

Epoch: 6| Step: 12
Training loss: 3.5419625700960515
Validation loss: 3.1999845214694997

Epoch: 6| Step: 13
Training loss: 2.824425400893931
Validation loss: 3.199731869898009

Epoch: 64| Step: 0
Training loss: 3.7356672405415963
Validation loss: 3.2021900412190125

Epoch: 6| Step: 1
Training loss: 3.146944132010468
Validation loss: 3.201802228055345

Epoch: 6| Step: 2
Training loss: 3.644491083019881
Validation loss: 3.1950062906091414

Epoch: 6| Step: 3
Training loss: 3.532157848766603
Validation loss: 3.192167417787036

Epoch: 6| Step: 4
Training loss: 3.311272015669412
Validation loss: 3.1924000482996067

Epoch: 6| Step: 5
Training loss: 2.884730747557019
Validation loss: 3.190086582010643

Epoch: 6| Step: 6
Training loss: 3.1606016469963585
Validation loss: 3.190520454185135

Epoch: 6| Step: 7
Training loss: 3.865357245236303
Validation loss: 3.193450393977701

Epoch: 6| Step: 8
Training loss: 3.956976661418567
Validation loss: 3.1926419764903566

Epoch: 6| Step: 9
Training loss: 3.281442109796589
Validation loss: 3.199120812745862

Epoch: 6| Step: 10
Training loss: 3.574705130414141
Validation loss: 3.1892993568596104

Epoch: 6| Step: 11
Training loss: 3.5692926532088243
Validation loss: 3.1917442248952352

Epoch: 6| Step: 12
Training loss: 3.2353956298406223
Validation loss: 3.18695006511562

Epoch: 6| Step: 13
Training loss: 2.9088405425533304
Validation loss: 3.191910867327136

Epoch: 65| Step: 0
Training loss: 2.5812023869665257
Validation loss: 3.1923990147806296

Epoch: 6| Step: 1
Training loss: 3.3923400197999793
Validation loss: 3.1911488880085606

Epoch: 6| Step: 2
Training loss: 3.9537037060198528
Validation loss: 3.192841489313276

Epoch: 6| Step: 3
Training loss: 3.861398884381063
Validation loss: 3.191615809928596

Epoch: 6| Step: 4
Training loss: 3.323413361325861
Validation loss: 3.1926088403779316

Epoch: 6| Step: 5
Training loss: 3.053353801419925
Validation loss: 3.19089926151091

Epoch: 6| Step: 6
Training loss: 4.150517920841985
Validation loss: 3.192140129018594

Epoch: 6| Step: 7
Training loss: 3.013169944632127
Validation loss: 3.189684285735158

Epoch: 6| Step: 8
Training loss: 3.926681066226517
Validation loss: 3.1903961539563306

Epoch: 6| Step: 9
Training loss: 2.6892748450180988
Validation loss: 3.1883882575399984

Epoch: 6| Step: 10
Training loss: 3.3513285948754827
Validation loss: 3.1894168169353425

Epoch: 6| Step: 11
Training loss: 3.400812411017644
Validation loss: 3.191877657764325

Epoch: 6| Step: 12
Training loss: 3.991993042750593
Validation loss: 3.1881868996410896

Epoch: 6| Step: 13
Training loss: 2.5384272793145293
Validation loss: 3.188012918491277

Epoch: 66| Step: 0
Training loss: 3.0542176024251884
Validation loss: 3.186534881055849

Epoch: 6| Step: 1
Training loss: 2.47965314777619
Validation loss: 3.187165098152109

Epoch: 6| Step: 2
Training loss: 3.3733322826831174
Validation loss: 3.186224460040747

Epoch: 6| Step: 3
Training loss: 3.838879981416292
Validation loss: 3.1853382582514405

Epoch: 6| Step: 4
Training loss: 3.8239673691638227
Validation loss: 3.1857341593781454

Epoch: 6| Step: 5
Training loss: 3.814611131840073
Validation loss: 3.1881845259189046

Epoch: 6| Step: 6
Training loss: 3.6448299371425983
Validation loss: 3.189071403050019

Epoch: 6| Step: 7
Training loss: 3.0059190215004725
Validation loss: 3.185630919506295

Epoch: 6| Step: 8
Training loss: 3.6696770765547484
Validation loss: 3.1849286933770506

Epoch: 6| Step: 9
Training loss: 2.895350537202079
Validation loss: 3.1840518813284135

Epoch: 6| Step: 10
Training loss: 3.7785974451704862
Validation loss: 3.1864820765550643

Epoch: 6| Step: 11
Training loss: 3.517406232786499
Validation loss: 3.188047789461806

Epoch: 6| Step: 12
Training loss: 3.7870953988992366
Validation loss: 3.1883934436927865

Epoch: 6| Step: 13
Training loss: 2.78779064425182
Validation loss: 3.195468536433442

Epoch: 67| Step: 0
Training loss: 2.8788910118745297
Validation loss: 3.194647268377972

Epoch: 6| Step: 1
Training loss: 3.8122500978707863
Validation loss: 3.1944848856269106

Epoch: 6| Step: 2
Training loss: 2.812764473242222
Validation loss: 3.189911916070039

Epoch: 6| Step: 3
Training loss: 3.236923614213491
Validation loss: 3.1884981314184886

Epoch: 6| Step: 4
Training loss: 3.8520727844809053
Validation loss: 3.1882552479296726

Epoch: 6| Step: 5
Training loss: 3.3386940923799346
Validation loss: 3.187392721797788

Epoch: 6| Step: 6
Training loss: 2.981139021433302
Validation loss: 3.1841027052364317

Epoch: 6| Step: 7
Training loss: 4.271311340873984
Validation loss: 3.1838744341188114

Epoch: 6| Step: 8
Training loss: 3.695151714673974
Validation loss: 3.182239240748868

Epoch: 6| Step: 9
Training loss: 3.9596728952731732
Validation loss: 3.1809167601457133

Epoch: 6| Step: 10
Training loss: 3.9994082013084586
Validation loss: 3.182991894280299

Epoch: 6| Step: 11
Training loss: 3.1305309939687898
Validation loss: 3.1833635611490303

Epoch: 6| Step: 12
Training loss: 2.8628565537055337
Validation loss: 3.1849915955220247

Epoch: 6| Step: 13
Training loss: 2.0343354486467686
Validation loss: 3.1841839393579447

Epoch: 68| Step: 0
Training loss: 2.596855602352625
Validation loss: 3.1843402344964304

Epoch: 6| Step: 1
Training loss: 3.7245340964796982
Validation loss: 3.185814255891703

Epoch: 6| Step: 2
Training loss: 3.211970031009402
Validation loss: 3.1827426791729088

Epoch: 6| Step: 3
Training loss: 2.035774590978141
Validation loss: 3.183630898326415

Epoch: 6| Step: 4
Training loss: 2.833813925730061
Validation loss: 3.1813620226886323

Epoch: 6| Step: 5
Training loss: 3.4553050068596964
Validation loss: 3.1887642405990744

Epoch: 6| Step: 6
Training loss: 3.3828542235446544
Validation loss: 3.181431054271468

Epoch: 6| Step: 7
Training loss: 3.5305187177066006
Validation loss: 3.1802481787144155

Epoch: 6| Step: 8
Training loss: 3.74457106207972
Validation loss: 3.180653258750606

Epoch: 6| Step: 9
Training loss: 3.734267229256893
Validation loss: 3.1827257769023323

Epoch: 6| Step: 10
Training loss: 3.9179401491743344
Validation loss: 3.1841917199991716

Epoch: 6| Step: 11
Training loss: 3.451553194129318
Validation loss: 3.180284640626182

Epoch: 6| Step: 12
Training loss: 3.8140519532304378
Validation loss: 3.1814082109835256

Epoch: 6| Step: 13
Training loss: 4.433969517046839
Validation loss: 3.1820893842753932

Epoch: 69| Step: 0
Training loss: 2.9167755833225835
Validation loss: 3.1786542043305688

Epoch: 6| Step: 1
Training loss: 2.615824785885959
Validation loss: 3.1827606993560384

Epoch: 6| Step: 2
Training loss: 3.971718466470691
Validation loss: 3.181241767844122

Epoch: 6| Step: 3
Training loss: 3.6618407453558306
Validation loss: 3.177660374088895

Epoch: 6| Step: 4
Training loss: 3.8022655007952295
Validation loss: 3.17841204625511

Epoch: 6| Step: 5
Training loss: 3.6598446121999797
Validation loss: 3.1771874814015093

Epoch: 6| Step: 6
Training loss: 3.779605350177235
Validation loss: 3.1778276469638924

Epoch: 6| Step: 7
Training loss: 3.490386156945556
Validation loss: 3.1770206218617782

Epoch: 6| Step: 8
Training loss: 2.903090205153435
Validation loss: 3.176514946526878

Epoch: 6| Step: 9
Training loss: 3.3935587623626615
Validation loss: 3.177277228888861

Epoch: 6| Step: 10
Training loss: 4.066748642225503
Validation loss: 3.1759869751381484

Epoch: 6| Step: 11
Training loss: 2.9265639273033592
Validation loss: 3.1774608552507804

Epoch: 6| Step: 12
Training loss: 2.9250929141162985
Validation loss: 3.1743941269893803

Epoch: 6| Step: 13
Training loss: 3.5062706496230724
Validation loss: 3.1766890973990707

Epoch: 70| Step: 0
Training loss: 2.844829144970697
Validation loss: 3.1741498799763015

Epoch: 6| Step: 1
Training loss: 1.7097110620184859
Validation loss: 3.1725887423203663

Epoch: 6| Step: 2
Training loss: 2.923807902192923
Validation loss: 3.17382921383873

Epoch: 6| Step: 3
Training loss: 3.5807572057377572
Validation loss: 3.1733457197745727

Epoch: 6| Step: 4
Training loss: 3.3647077948793527
Validation loss: 3.1737375271395174

Epoch: 6| Step: 5
Training loss: 3.2456327586133615
Validation loss: 3.1722739212441606

Epoch: 6| Step: 6
Training loss: 4.442850030902993
Validation loss: 3.175259468716699

Epoch: 6| Step: 7
Training loss: 3.973474528942311
Validation loss: 3.174263750216728

Epoch: 6| Step: 8
Training loss: 4.313302228089268
Validation loss: 3.1754008700818948

Epoch: 6| Step: 9
Training loss: 3.8339944490522897
Validation loss: 3.1753445508841955

Epoch: 6| Step: 10
Training loss: 3.6689748146022407
Validation loss: 3.1740743457080245

Epoch: 6| Step: 11
Training loss: 2.957766483067819
Validation loss: 3.176459526793681

Epoch: 6| Step: 12
Training loss: 3.143260097061769
Validation loss: 3.1742200763459922

Epoch: 6| Step: 13
Training loss: 2.5936662591491753
Validation loss: 3.1723140572506576

Epoch: 71| Step: 0
Training loss: 2.8373286930753774
Validation loss: 3.1728219720564192

Epoch: 6| Step: 1
Training loss: 3.8307842127071283
Validation loss: 3.1736256324659213

Epoch: 6| Step: 2
Training loss: 3.444652952699092
Validation loss: 3.1740765983304953

Epoch: 6| Step: 3
Training loss: 3.107057100437393
Validation loss: 3.1749378068094103

Epoch: 6| Step: 4
Training loss: 3.15832255083993
Validation loss: 3.1697731863962137

Epoch: 6| Step: 5
Training loss: 3.9494650563028193
Validation loss: 3.1708313062226203

Epoch: 6| Step: 6
Training loss: 2.9842855230369314
Validation loss: 3.170902554329946

Epoch: 6| Step: 7
Training loss: 3.383256209172503
Validation loss: 3.17212784177315

Epoch: 6| Step: 8
Training loss: 2.784891038334884
Validation loss: 3.169896169923488

Epoch: 6| Step: 9
Training loss: 3.5363573257486265
Validation loss: 3.1702962102666445

Epoch: 6| Step: 10
Training loss: 2.756623873795551
Validation loss: 3.168488417812031

Epoch: 6| Step: 11
Training loss: 4.276941512194254
Validation loss: 3.169918085245024

Epoch: 6| Step: 12
Training loss: 3.582101270018338
Validation loss: 3.1683338563287102

Epoch: 6| Step: 13
Training loss: 4.156940833020528
Validation loss: 3.1686616975285062

Epoch: 72| Step: 0
Training loss: 4.173194933618545
Validation loss: 3.1692608347062037

Epoch: 6| Step: 1
Training loss: 3.4702850244525942
Validation loss: 3.1712622841534577

Epoch: 6| Step: 2
Training loss: 3.1356556612264126
Validation loss: 3.178646719838209

Epoch: 6| Step: 3
Training loss: 2.8355635299225024
Validation loss: 3.1801731512441114

Epoch: 6| Step: 4
Training loss: 3.592085743209962
Validation loss: 3.17578320353771

Epoch: 6| Step: 5
Training loss: 4.135678889162888
Validation loss: 3.177564126599762

Epoch: 6| Step: 6
Training loss: 3.8744031384931317
Validation loss: 3.166759125849889

Epoch: 6| Step: 7
Training loss: 3.4750410887120897
Validation loss: 3.1679341208990466

Epoch: 6| Step: 8
Training loss: 3.066892626633802
Validation loss: 3.168669249294981

Epoch: 6| Step: 9
Training loss: 2.9084739789502105
Validation loss: 3.1660366019824764

Epoch: 6| Step: 10
Training loss: 3.215333625486032
Validation loss: 3.1661729902754896

Epoch: 6| Step: 11
Training loss: 2.615911280781223
Validation loss: 3.1655614974753425

Epoch: 6| Step: 12
Training loss: 3.6850255649047354
Validation loss: 3.166828017557902

Epoch: 6| Step: 13
Training loss: 3.072627701615804
Validation loss: 3.1655707840502743

Epoch: 73| Step: 0
Training loss: 3.6206859042080897
Validation loss: 3.168447407237571

Epoch: 6| Step: 1
Training loss: 4.0011866716630635
Validation loss: 3.1679982546793966

Epoch: 6| Step: 2
Training loss: 3.1765928463065665
Validation loss: 3.184055833004109

Epoch: 6| Step: 3
Training loss: 3.2686296721679646
Validation loss: 3.207406532740995

Epoch: 6| Step: 4
Training loss: 3.8064269176639396
Validation loss: 3.1853854769984262

Epoch: 6| Step: 5
Training loss: 3.1014315099464427
Validation loss: 3.1645734833428474

Epoch: 6| Step: 6
Training loss: 3.439661629469408
Validation loss: 3.1645982012070384

Epoch: 6| Step: 7
Training loss: 3.208836668751408
Validation loss: 3.1633910793137163

Epoch: 6| Step: 8
Training loss: 3.805355945435323
Validation loss: 3.16494864802473

Epoch: 6| Step: 9
Training loss: 3.132758009286861
Validation loss: 3.163331180606226

Epoch: 6| Step: 10
Training loss: 3.7670571543968094
Validation loss: 3.1636646486001307

Epoch: 6| Step: 11
Training loss: 2.73306460997961
Validation loss: 3.1645670559536385

Epoch: 6| Step: 12
Training loss: 3.395507110341098
Validation loss: 3.164893611404277

Epoch: 6| Step: 13
Training loss: 2.950618103704492
Validation loss: 3.1618254371166823

Epoch: 74| Step: 0
Training loss: 3.0630498898459924
Validation loss: 3.1630578126589577

Epoch: 6| Step: 1
Training loss: 3.9932437104202076
Validation loss: 3.1623869220440346

Epoch: 6| Step: 2
Training loss: 3.0953626956942393
Validation loss: 3.1619238501178693

Epoch: 6| Step: 3
Training loss: 2.9588130687314127
Validation loss: 3.1617680020365166

Epoch: 6| Step: 4
Training loss: 2.999483699875749
Validation loss: 3.162495611076612

Epoch: 6| Step: 5
Training loss: 3.275743787329756
Validation loss: 3.1609459975263654

Epoch: 6| Step: 6
Training loss: 2.9071647270989445
Validation loss: 3.1635065459030827

Epoch: 6| Step: 7
Training loss: 3.36601134113253
Validation loss: 3.1626690780900772

Epoch: 6| Step: 8
Training loss: 3.9628972429020024
Validation loss: 3.1625906343129495

Epoch: 6| Step: 9
Training loss: 3.617299286204635
Validation loss: 3.16353634017295

Epoch: 6| Step: 10
Training loss: 3.001175173422875
Validation loss: 3.1639388456885382

Epoch: 6| Step: 11
Training loss: 3.759293801563614
Validation loss: 3.1613503849710107

Epoch: 6| Step: 12
Training loss: 3.6914022455748783
Validation loss: 3.16263446877852

Epoch: 6| Step: 13
Training loss: 3.9603681587781665
Validation loss: 3.170376284407204

Epoch: 75| Step: 0
Training loss: 3.578963135752476
Validation loss: 3.159615329859218

Epoch: 6| Step: 1
Training loss: 3.110098596463482
Validation loss: 3.159370787459414

Epoch: 6| Step: 2
Training loss: 2.7344771011908757
Validation loss: 3.1610044256336107

Epoch: 6| Step: 3
Training loss: 4.350117140321797
Validation loss: 3.1578884528219366

Epoch: 6| Step: 4
Training loss: 3.1010874040840184
Validation loss: 3.1586332011654807

Epoch: 6| Step: 5
Training loss: 4.078528607152981
Validation loss: 3.15894626695224

Epoch: 6| Step: 6
Training loss: 4.07584290943153
Validation loss: 3.158843305637556

Epoch: 6| Step: 7
Training loss: 2.578993957192958
Validation loss: 3.1565384693892864

Epoch: 6| Step: 8
Training loss: 2.8697800725482296
Validation loss: 3.156483137499079

Epoch: 6| Step: 9
Training loss: 3.285286881506519
Validation loss: 3.15703815702321

Epoch: 6| Step: 10
Training loss: 3.0721560468975624
Validation loss: 3.157535026190453

Epoch: 6| Step: 11
Training loss: 3.413094180292264
Validation loss: 3.156696528011658

Epoch: 6| Step: 12
Training loss: 3.62938175432678
Validation loss: 3.1560476021540005

Epoch: 6| Step: 13
Training loss: 3.2344529884260766
Validation loss: 3.155356344107784

Epoch: 76| Step: 0
Training loss: 3.3952272182380305
Validation loss: 3.15622366048779

Epoch: 6| Step: 1
Training loss: 3.1154067227991136
Validation loss: 3.155392301503642

Epoch: 6| Step: 2
Training loss: 3.373051398737557
Validation loss: 3.155476546329889

Epoch: 6| Step: 3
Training loss: 4.084329730062458
Validation loss: 3.1547438403612604

Epoch: 6| Step: 4
Training loss: 3.5261025510383917
Validation loss: 3.1547236610595224

Epoch: 6| Step: 5
Training loss: 4.071655520469305
Validation loss: 3.154198199649194

Epoch: 6| Step: 6
Training loss: 3.2451725833652043
Validation loss: 3.152682485822797

Epoch: 6| Step: 7
Training loss: 3.1324881292972186
Validation loss: 3.154597212431886

Epoch: 6| Step: 8
Training loss: 3.4445899672855997
Validation loss: 3.1537908726984427

Epoch: 6| Step: 9
Training loss: 2.2663243759920104
Validation loss: 3.1530838824200234

Epoch: 6| Step: 10
Training loss: 3.4544912543904576
Validation loss: 3.155457517263713

Epoch: 6| Step: 11
Training loss: 3.0650823176968367
Validation loss: 3.1583075195663683

Epoch: 6| Step: 12
Training loss: 3.3466584578130996
Validation loss: 3.1628837323134924

Epoch: 6| Step: 13
Training loss: 3.990416131942494
Validation loss: 3.1554256318245426

Epoch: 77| Step: 0
Training loss: 3.33140910557727
Validation loss: 3.1541711423885523

Epoch: 6| Step: 1
Training loss: 3.292090247862783
Validation loss: 3.1523383906840468

Epoch: 6| Step: 2
Training loss: 3.8918467369051895
Validation loss: 3.1517919422974443

Epoch: 6| Step: 3
Training loss: 3.576282543259639
Validation loss: 3.1501773070088865

Epoch: 6| Step: 4
Training loss: 3.440859869234647
Validation loss: 3.1509799664784905

Epoch: 6| Step: 5
Training loss: 3.2860374765609843
Validation loss: 3.151642454484073

Epoch: 6| Step: 6
Training loss: 3.4160755080246514
Validation loss: 3.151067117405032

Epoch: 6| Step: 7
Training loss: 2.9061550001799286
Validation loss: 3.149998991667076

Epoch: 6| Step: 8
Training loss: 3.591594414452618
Validation loss: 3.1501536137031216

Epoch: 6| Step: 9
Training loss: 3.3193622261481055
Validation loss: 3.1503743954632157

Epoch: 6| Step: 10
Training loss: 3.429654410165687
Validation loss: 3.1512799513169

Epoch: 6| Step: 11
Training loss: 3.4566938505020417
Validation loss: 3.1544604065368183

Epoch: 6| Step: 12
Training loss: 3.11200667918452
Validation loss: 3.151524057518425

Epoch: 6| Step: 13
Training loss: 3.6240343583522465
Validation loss: 3.1524490656223487

Epoch: 78| Step: 0
Training loss: 3.1452111308879296
Validation loss: 3.1498390880008014

Epoch: 6| Step: 1
Training loss: 3.068225413311357
Validation loss: 3.15013811375434

Epoch: 6| Step: 2
Training loss: 3.1558456917329303
Validation loss: 3.150480911257751

Epoch: 6| Step: 3
Training loss: 2.895455607929473
Validation loss: 3.148497800118027

Epoch: 6| Step: 4
Training loss: 3.847655134636577
Validation loss: 3.1486976316781887

Epoch: 6| Step: 5
Training loss: 3.814728007688627
Validation loss: 3.1496380200336764

Epoch: 6| Step: 6
Training loss: 3.43066976119474
Validation loss: 3.1494270108602187

Epoch: 6| Step: 7
Training loss: 3.5727684205258172
Validation loss: 3.150083463741213

Epoch: 6| Step: 8
Training loss: 3.7518725488322047
Validation loss: 3.148633777303241

Epoch: 6| Step: 9
Training loss: 3.200986269119687
Validation loss: 3.1481413827569136

Epoch: 6| Step: 10
Training loss: 3.014598296118886
Validation loss: 3.1488539035819034

Epoch: 6| Step: 11
Training loss: 3.4173191346959935
Validation loss: 3.1474017798458696

Epoch: 6| Step: 12
Training loss: 3.857107631583051
Validation loss: 3.1481517475913754

Epoch: 6| Step: 13
Training loss: 3.0737827093579897
Validation loss: 3.147628920963657

Epoch: 79| Step: 0
Training loss: 3.4576763003864883
Validation loss: 3.1471572194966657

Epoch: 6| Step: 1
Training loss: 3.3777481475863396
Validation loss: 3.147504894706919

Epoch: 6| Step: 2
Training loss: 3.656135752922589
Validation loss: 3.147275422332024

Epoch: 6| Step: 3
Training loss: 3.6153317133877425
Validation loss: 3.1505390826464876

Epoch: 6| Step: 4
Training loss: 2.8410458965306855
Validation loss: 3.149695274222702

Epoch: 6| Step: 5
Training loss: 2.895590316857869
Validation loss: 3.1512025045447984

Epoch: 6| Step: 6
Training loss: 3.6569054170998543
Validation loss: 3.151471107296544

Epoch: 6| Step: 7
Training loss: 3.3230801883909695
Validation loss: 3.151871010275669

Epoch: 6| Step: 8
Training loss: 3.3219403753011076
Validation loss: 3.157460840917875

Epoch: 6| Step: 9
Training loss: 4.473467277723542
Validation loss: 3.166810112334265

Epoch: 6| Step: 10
Training loss: 2.8578633966601212
Validation loss: 3.1515579656274606

Epoch: 6| Step: 11
Training loss: 3.689329307825089
Validation loss: 3.1462052637527

Epoch: 6| Step: 12
Training loss: 2.7046642882057936
Validation loss: 3.145154748746276

Epoch: 6| Step: 13
Training loss: 3.248989828547615
Validation loss: 3.1433862155400796

Epoch: 80| Step: 0
Training loss: 3.697183212111412
Validation loss: 3.1431714336460166

Epoch: 6| Step: 1
Training loss: 3.302858247695489
Validation loss: 3.142176528580019

Epoch: 6| Step: 2
Training loss: 3.2695771901174364
Validation loss: 3.1431509842978156

Epoch: 6| Step: 3
Training loss: 2.896204167687875
Validation loss: 3.1418733735468933

Epoch: 6| Step: 4
Training loss: 3.237289074245909
Validation loss: 3.1432627020847526

Epoch: 6| Step: 5
Training loss: 3.347995807604062
Validation loss: 3.141201457173675

Epoch: 6| Step: 6
Training loss: 3.701259094659981
Validation loss: 3.1429965153195227

Epoch: 6| Step: 7
Training loss: 3.3077358318051657
Validation loss: 3.1435065810708283

Epoch: 6| Step: 8
Training loss: 3.4945164366966104
Validation loss: 3.1426019113142245

Epoch: 6| Step: 9
Training loss: 3.7323487981791748
Validation loss: 3.1423644479855373

Epoch: 6| Step: 10
Training loss: 3.2676880083231277
Validation loss: 3.1413690033392117

Epoch: 6| Step: 11
Training loss: 3.434376910472057
Validation loss: 3.142541736273385

Epoch: 6| Step: 12
Training loss: 4.014110234957873
Validation loss: 3.1426269276201513

Epoch: 6| Step: 13
Training loss: 1.6495432105809198
Validation loss: 3.1415360901112543

Epoch: 81| Step: 0
Training loss: 4.352159442056556
Validation loss: 3.140485960971753

Epoch: 6| Step: 1
Training loss: 3.882407215235428
Validation loss: 3.1403172900933147

Epoch: 6| Step: 2
Training loss: 2.8205679569101574
Validation loss: 3.1390728409431334

Epoch: 6| Step: 3
Training loss: 3.249623496915312
Validation loss: 3.143177878686626

Epoch: 6| Step: 4
Training loss: 3.347433752724889
Validation loss: 3.1396966291724437

Epoch: 6| Step: 5
Training loss: 3.2449092608962418
Validation loss: 3.13853262692289

Epoch: 6| Step: 6
Training loss: 3.704583375803715
Validation loss: 3.1391486147178447

Epoch: 6| Step: 7
Training loss: 3.1069788302267285
Validation loss: 3.1393162165469684

Epoch: 6| Step: 8
Training loss: 3.8407537676189296
Validation loss: 3.1390211213495305

Epoch: 6| Step: 9
Training loss: 3.3683984972957806
Validation loss: 3.138661929730448

Epoch: 6| Step: 10
Training loss: 2.4338267109227947
Validation loss: 3.1373622146785047

Epoch: 6| Step: 11
Training loss: 3.5405343134175813
Validation loss: 3.137282718118767

Epoch: 6| Step: 12
Training loss: 2.6152274464293956
Validation loss: 3.138274951289591

Epoch: 6| Step: 13
Training loss: 3.562678282442782
Validation loss: 3.1390095184617466

Epoch: 82| Step: 0
Training loss: 3.889050268427556
Validation loss: 3.137255143979761

Epoch: 6| Step: 1
Training loss: 3.0310418755568844
Validation loss: 3.138781881824017

Epoch: 6| Step: 2
Training loss: 2.502494044796987
Validation loss: 3.140168501858704

Epoch: 6| Step: 3
Training loss: 3.63415502536877
Validation loss: 3.1574114816169887

Epoch: 6| Step: 4
Training loss: 4.22711888739065
Validation loss: 3.148636045683987

Epoch: 6| Step: 5
Training loss: 3.8029872847411457
Validation loss: 3.133112846393766

Epoch: 6| Step: 6
Training loss: 3.041597618120556
Validation loss: 3.134757504142644

Epoch: 6| Step: 7
Training loss: 3.2293632857647516
Validation loss: 3.1360083670942966

Epoch: 6| Step: 8
Training loss: 2.7792527817896393
Validation loss: 3.1364663641052055

Epoch: 6| Step: 9
Training loss: 3.900014432244618
Validation loss: 3.136800921913138

Epoch: 6| Step: 10
Training loss: 2.6976508128633125
Validation loss: 3.1388018360953356

Epoch: 6| Step: 11
Training loss: 3.7139462771785037
Validation loss: 3.1434618046008933

Epoch: 6| Step: 12
Training loss: 3.3958556441683845
Validation loss: 3.1410771167305622

Epoch: 6| Step: 13
Training loss: 2.9556486457690347
Validation loss: 3.139707933123513

Epoch: 83| Step: 0
Training loss: 3.0948302569701633
Validation loss: 3.1370310567061943

Epoch: 6| Step: 1
Training loss: 4.4528793534906335
Validation loss: 3.138040787814614

Epoch: 6| Step: 2
Training loss: 2.8019368489110605
Validation loss: 3.134182848955179

Epoch: 6| Step: 3
Training loss: 3.0605213234814057
Validation loss: 3.131846436517296

Epoch: 6| Step: 4
Training loss: 2.909498470648852
Validation loss: 3.1325762325162874

Epoch: 6| Step: 5
Training loss: 2.892958899967197
Validation loss: 3.1299736370808633

Epoch: 6| Step: 6
Training loss: 3.655110760431277
Validation loss: 3.1318175719115424

Epoch: 6| Step: 7
Training loss: 2.838122994347229
Validation loss: 3.131510347353498

Epoch: 6| Step: 8
Training loss: 2.7372499012032065
Validation loss: 3.1372692514050073

Epoch: 6| Step: 9
Training loss: 3.6538732906059717
Validation loss: 3.1461775298796884

Epoch: 6| Step: 10
Training loss: 3.6017265365216553
Validation loss: 3.132317965401221

Epoch: 6| Step: 11
Training loss: 3.398310937388286
Validation loss: 3.1349656531493237

Epoch: 6| Step: 12
Training loss: 3.9656504143997005
Validation loss: 3.1349068705774408

Epoch: 6| Step: 13
Training loss: 4.2555496782395625
Validation loss: 3.134338599661795

Epoch: 84| Step: 0
Training loss: 3.8335418368039713
Validation loss: 3.132397254042057

Epoch: 6| Step: 1
Training loss: 2.9198549192783174
Validation loss: 3.1345583296458917

Epoch: 6| Step: 2
Training loss: 3.132941873595039
Validation loss: 3.1311446717458353

Epoch: 6| Step: 3
Training loss: 3.5552582335004246
Validation loss: 3.130426881041848

Epoch: 6| Step: 4
Training loss: 3.6309481523237537
Validation loss: 3.12999315115824

Epoch: 6| Step: 5
Training loss: 3.7995928546228317
Validation loss: 3.1280611349241907

Epoch: 6| Step: 6
Training loss: 2.7449459102561446
Validation loss: 3.1276845430979674

Epoch: 6| Step: 7
Training loss: 3.970458496484033
Validation loss: 3.1263233442791787

Epoch: 6| Step: 8
Training loss: 3.31964061446478
Validation loss: 3.127289899031471

Epoch: 6| Step: 9
Training loss: 2.573914575044017
Validation loss: 3.1281499791213143

Epoch: 6| Step: 10
Training loss: 4.234371846891123
Validation loss: 3.126174312341095

Epoch: 6| Step: 11
Training loss: 2.258660919341274
Validation loss: 3.1259103273577806

Epoch: 6| Step: 12
Training loss: 3.354652953980544
Validation loss: 3.127565317873305

Epoch: 6| Step: 13
Training loss: 3.5557610200749945
Validation loss: 3.1263870631091266

Epoch: 85| Step: 0
Training loss: 3.170330705209712
Validation loss: 3.126055744634218

Epoch: 6| Step: 1
Training loss: 4.0910535478614465
Validation loss: 3.1248579932321006

Epoch: 6| Step: 2
Training loss: 2.6832719412784183
Validation loss: 3.1257376967092325

Epoch: 6| Step: 3
Training loss: 3.1614059787460342
Validation loss: 3.1261427596747935

Epoch: 6| Step: 4
Training loss: 3.929501841958106
Validation loss: 3.124940219430411

Epoch: 6| Step: 5
Training loss: 2.9426156808676334
Validation loss: 3.124926138384401

Epoch: 6| Step: 6
Training loss: 3.9082270387511753
Validation loss: 3.1237944314089425

Epoch: 6| Step: 7
Training loss: 2.96769358259833
Validation loss: 3.123505126104154

Epoch: 6| Step: 8
Training loss: 3.004820130307791
Validation loss: 3.1248246617503317

Epoch: 6| Step: 9
Training loss: 2.950575277842415
Validation loss: 3.1232578023431277

Epoch: 6| Step: 10
Training loss: 3.3902878835415398
Validation loss: 3.123507698357478

Epoch: 6| Step: 11
Training loss: 3.567737677608945
Validation loss: 3.126390370171562

Epoch: 6| Step: 12
Training loss: 3.9123653303375625
Validation loss: 3.127392753167619

Epoch: 6| Step: 13
Training loss: 3.219745667169207
Validation loss: 3.125341246646594

Epoch: 86| Step: 0
Training loss: 3.743074252322339
Validation loss: 3.128304381359305

Epoch: 6| Step: 1
Training loss: 3.258603811785817
Validation loss: 3.127164967734784

Epoch: 6| Step: 2
Training loss: 3.2884232359666257
Validation loss: 3.1231036447683582

Epoch: 6| Step: 3
Training loss: 3.4915590680886597
Validation loss: 3.123346157722893

Epoch: 6| Step: 4
Training loss: 3.6088967274777493
Validation loss: 3.119862793008187

Epoch: 6| Step: 5
Training loss: 3.1849187235140906
Validation loss: 3.122323457280238

Epoch: 6| Step: 6
Training loss: 3.5157264525292167
Validation loss: 3.121101526927334

Epoch: 6| Step: 7
Training loss: 3.400836387308238
Validation loss: 3.122979183020453

Epoch: 6| Step: 8
Training loss: 3.3005954667575765
Validation loss: 3.118510522677269

Epoch: 6| Step: 9
Training loss: 3.268116561753276
Validation loss: 3.1196703050679573

Epoch: 6| Step: 10
Training loss: 2.823082321955792
Validation loss: 3.1204615987507403

Epoch: 6| Step: 11
Training loss: 3.489382306282092
Validation loss: 3.1204531679096905

Epoch: 6| Step: 12
Training loss: 2.8458435400970155
Validation loss: 3.1183412748037167

Epoch: 6| Step: 13
Training loss: 4.32315648650797
Validation loss: 3.118464512604028

Epoch: 87| Step: 0
Training loss: 3.5153130286927885
Validation loss: 3.118911505334419

Epoch: 6| Step: 1
Training loss: 2.999155561492476
Validation loss: 3.118344416932403

Epoch: 6| Step: 2
Training loss: 2.985094712638179
Validation loss: 3.1171122804626727

Epoch: 6| Step: 3
Training loss: 2.827041418392191
Validation loss: 3.118275486682118

Epoch: 6| Step: 4
Training loss: 3.7680079094870584
Validation loss: 3.1172889045116636

Epoch: 6| Step: 5
Training loss: 3.3320952182367174
Validation loss: 3.11715742227203

Epoch: 6| Step: 6
Training loss: 2.9842505304234295
Validation loss: 3.11792772593822

Epoch: 6| Step: 7
Training loss: 2.387447064996244
Validation loss: 3.1181662264335444

Epoch: 6| Step: 8
Training loss: 4.536071737512683
Validation loss: 3.1177341359068955

Epoch: 6| Step: 9
Training loss: 3.467483014186849
Validation loss: 3.115452809300243

Epoch: 6| Step: 10
Training loss: 3.7132458383969236
Validation loss: 3.1157898834403843

Epoch: 6| Step: 11
Training loss: 3.2568898163646773
Validation loss: 3.115452011930408

Epoch: 6| Step: 12
Training loss: 3.355005163424707
Validation loss: 3.1170131895629045

Epoch: 6| Step: 13
Training loss: 3.8246801953230785
Validation loss: 3.115495914694622

Epoch: 88| Step: 0
Training loss: 3.3753862513171815
Validation loss: 3.1164631096069275

Epoch: 6| Step: 1
Training loss: 4.159127522822381
Validation loss: 3.115979000910191

Epoch: 6| Step: 2
Training loss: 3.475560556111664
Validation loss: 3.1143812184704918

Epoch: 6| Step: 3
Training loss: 3.7475995328077385
Validation loss: 3.1164226491622675

Epoch: 6| Step: 4
Training loss: 3.013565229703309
Validation loss: 3.1160459165173617

Epoch: 6| Step: 5
Training loss: 3.9125520452870757
Validation loss: 3.115033365819307

Epoch: 6| Step: 6
Training loss: 3.274281104005408
Validation loss: 3.1155052402391368

Epoch: 6| Step: 7
Training loss: 4.287541354232961
Validation loss: 3.1154052498235987

Epoch: 6| Step: 8
Training loss: 2.7238252119767874
Validation loss: 3.1150687414227876

Epoch: 6| Step: 9
Training loss: 3.131271173401779
Validation loss: 3.113787466072855

Epoch: 6| Step: 10
Training loss: 2.626022139863397
Validation loss: 3.1136235586894743

Epoch: 6| Step: 11
Training loss: 3.1547938849926647
Validation loss: 3.11440382735912

Epoch: 6| Step: 12
Training loss: 3.175985144419483
Validation loss: 3.1129154655326

Epoch: 6| Step: 13
Training loss: 1.8567519077729346
Validation loss: 3.1138435978152317

Epoch: 89| Step: 0
Training loss: 3.4552829265545046
Validation loss: 3.1209900639979975

Epoch: 6| Step: 1
Training loss: 2.9540371570975026
Validation loss: 3.12392544227349

Epoch: 6| Step: 2
Training loss: 3.498879525804824
Validation loss: 3.1292821852318444

Epoch: 6| Step: 3
Training loss: 2.463895055951191
Validation loss: 3.1153707079366666

Epoch: 6| Step: 4
Training loss: 3.0081910526799702
Validation loss: 3.113457625332435

Epoch: 6| Step: 5
Training loss: 3.1603594927979732
Validation loss: 3.11376945179925

Epoch: 6| Step: 6
Training loss: 3.6116323306838716
Validation loss: 3.111959586037056

Epoch: 6| Step: 7
Training loss: 2.9768634954338733
Validation loss: 3.112971619586788

Epoch: 6| Step: 8
Training loss: 3.7258623853037287
Validation loss: 3.1129722784146034

Epoch: 6| Step: 9
Training loss: 3.581185044370297
Validation loss: 3.113430513738432

Epoch: 6| Step: 10
Training loss: 3.182178618092688
Validation loss: 3.1122123382051905

Epoch: 6| Step: 11
Training loss: 4.00750885941638
Validation loss: 3.1143863303030406

Epoch: 6| Step: 12
Training loss: 3.5198664193382894
Validation loss: 3.1161340078570077

Epoch: 6| Step: 13
Training loss: 3.9935594205799823
Validation loss: 3.116213120888737

Epoch: 90| Step: 0
Training loss: 3.5671019695519837
Validation loss: 3.1152689397946984

Epoch: 6| Step: 1
Training loss: 3.322965679385219
Validation loss: 3.113577013663843

Epoch: 6| Step: 2
Training loss: 3.1515594981703603
Validation loss: 3.1105518716174156

Epoch: 6| Step: 3
Training loss: 4.081556958839599
Validation loss: 3.1124210164297845

Epoch: 6| Step: 4
Training loss: 3.678057850343857
Validation loss: 3.11016474383457

Epoch: 6| Step: 5
Training loss: 3.6204467327075203
Validation loss: 3.1126970994322605

Epoch: 6| Step: 6
Training loss: 3.0989028711992495
Validation loss: 3.110780052717985

Epoch: 6| Step: 7
Training loss: 2.7752444116680297
Validation loss: 3.111398277003995

Epoch: 6| Step: 8
Training loss: 3.2673854919309506
Validation loss: 3.1104904369691715

Epoch: 6| Step: 9
Training loss: 3.9488298203871004
Validation loss: 3.1138312054151576

Epoch: 6| Step: 10
Training loss: 3.31509556835385
Validation loss: 3.1108622752373787

Epoch: 6| Step: 11
Training loss: 2.3015543702519987
Validation loss: 3.107449570316594

Epoch: 6| Step: 12
Training loss: 3.137644249993004
Validation loss: 3.109084926841043

Epoch: 6| Step: 13
Training loss: 3.566724447572606
Validation loss: 3.109817310999246

Epoch: 91| Step: 0
Training loss: 3.0844995166260616
Validation loss: 3.1084236993816936

Epoch: 6| Step: 1
Training loss: 3.7731147454327636
Validation loss: 3.1101364149163673

Epoch: 6| Step: 2
Training loss: 2.8544449125297535
Validation loss: 3.1090214561758205

Epoch: 6| Step: 3
Training loss: 3.588413555514184
Validation loss: 3.108123600032372

Epoch: 6| Step: 4
Training loss: 2.537079115665877
Validation loss: 3.1074575488649807

Epoch: 6| Step: 5
Training loss: 3.7429975616422677
Validation loss: 3.107139594742157

Epoch: 6| Step: 6
Training loss: 3.4561387111412953
Validation loss: 3.1084746233461726

Epoch: 6| Step: 7
Training loss: 2.922914044865479
Validation loss: 3.109305061241805

Epoch: 6| Step: 8
Training loss: 3.4718655178376645
Validation loss: 3.1068102843189624

Epoch: 6| Step: 9
Training loss: 3.4930842056936453
Validation loss: 3.1097745522731413

Epoch: 6| Step: 10
Training loss: 3.4669883309809686
Validation loss: 3.10940649526072

Epoch: 6| Step: 11
Training loss: 3.9718058678397967
Validation loss: 3.109629120555035

Epoch: 6| Step: 12
Training loss: 3.562802753634238
Validation loss: 3.106939536781436

Epoch: 6| Step: 13
Training loss: 2.360370047216356
Validation loss: 3.1060816051691083

Epoch: 92| Step: 0
Training loss: 3.507547959035845
Validation loss: 3.1047512681375737

Epoch: 6| Step: 1
Training loss: 2.276820336941456
Validation loss: 3.108064690872733

Epoch: 6| Step: 2
Training loss: 3.661079151964049
Validation loss: 3.1124758656575846

Epoch: 6| Step: 3
Training loss: 3.1654542475870495
Validation loss: 3.1138846623133203

Epoch: 6| Step: 4
Training loss: 3.5285887015622097
Validation loss: 3.1194277643972086

Epoch: 6| Step: 5
Training loss: 2.664684950079223
Validation loss: 3.1253857347881877

Epoch: 6| Step: 6
Training loss: 3.2498001624070754
Validation loss: 3.1352204101374213

Epoch: 6| Step: 7
Training loss: 4.065057976228341
Validation loss: 3.123817484270235

Epoch: 6| Step: 8
Training loss: 3.1616970686455454
Validation loss: 3.114761265694402

Epoch: 6| Step: 9
Training loss: 3.2514670068814135
Validation loss: 3.110138229992711

Epoch: 6| Step: 10
Training loss: 3.3799041156598935
Validation loss: 3.106414033147946

Epoch: 6| Step: 11
Training loss: 3.9111134275034587
Validation loss: 3.1057122800943557

Epoch: 6| Step: 12
Training loss: 3.6510845767704363
Validation loss: 3.1023900019291424

Epoch: 6| Step: 13
Training loss: 3.1564575731364966
Validation loss: 3.103219788002514

Epoch: 93| Step: 0
Training loss: 3.4258330285781975
Validation loss: 3.1047746853352693

Epoch: 6| Step: 1
Training loss: 2.5510809869774658
Validation loss: 3.104679596873422

Epoch: 6| Step: 2
Training loss: 3.9896686169678017
Validation loss: 3.1055607880172027

Epoch: 6| Step: 3
Training loss: 2.818212852978352
Validation loss: 3.1027871520287302

Epoch: 6| Step: 4
Training loss: 3.2263949075913576
Validation loss: 3.1096054678534726

Epoch: 6| Step: 5
Training loss: 3.2610823141715155
Validation loss: 3.1034605488498928

Epoch: 6| Step: 6
Training loss: 3.6187629976187403
Validation loss: 3.1030109949619495

Epoch: 6| Step: 7
Training loss: 2.9352031412610526
Validation loss: 3.10212945306252

Epoch: 6| Step: 8
Training loss: 3.4836123876421707
Validation loss: 3.100463742823018

Epoch: 6| Step: 9
Training loss: 3.835897224043905
Validation loss: 3.1026659339371125

Epoch: 6| Step: 10
Training loss: 3.585369921210896
Validation loss: 3.1011902485093747

Epoch: 6| Step: 11
Training loss: 3.8327573813492433
Validation loss: 3.101764813182572

Epoch: 6| Step: 12
Training loss: 2.946113457281275
Validation loss: 3.1018832688596003

Epoch: 6| Step: 13
Training loss: 3.236250771131604
Validation loss: 3.1033957620406962

Epoch: 94| Step: 0
Training loss: 3.5863102073043174
Validation loss: 3.1029711572103187

Epoch: 6| Step: 1
Training loss: 3.041038204395943
Validation loss: 3.102887508577593

Epoch: 6| Step: 2
Training loss: 3.0312443369389754
Validation loss: 3.101870064180357

Epoch: 6| Step: 3
Training loss: 2.8072391049778944
Validation loss: 3.10215085543697

Epoch: 6| Step: 4
Training loss: 2.9459043358461305
Validation loss: 3.101575177816328

Epoch: 6| Step: 5
Training loss: 4.008767532866973
Validation loss: 3.1017980693001306

Epoch: 6| Step: 6
Training loss: 3.6173567598425396
Validation loss: 3.1015514240194726

Epoch: 6| Step: 7
Training loss: 2.938817804058159
Validation loss: 3.1015917883388213

Epoch: 6| Step: 8
Training loss: 2.7792406002735683
Validation loss: 3.101681180781614

Epoch: 6| Step: 9
Training loss: 3.183768537906974
Validation loss: 3.100456951837751

Epoch: 6| Step: 10
Training loss: 3.6520369293752366
Validation loss: 3.1013105926663247

Epoch: 6| Step: 11
Training loss: 3.6514245166751786
Validation loss: 3.0990537225290695

Epoch: 6| Step: 12
Training loss: 3.794582349791685
Validation loss: 3.1010877430272554

Epoch: 6| Step: 13
Training loss: 3.9158539165489756
Validation loss: 3.1002729479321087

Epoch: 95| Step: 0
Training loss: 3.7259121693258246
Validation loss: 3.1005919733134886

Epoch: 6| Step: 1
Training loss: 3.656105495107796
Validation loss: 3.0998121530844274

Epoch: 6| Step: 2
Training loss: 3.451720077074402
Validation loss: 3.0995679410694223

Epoch: 6| Step: 3
Training loss: 3.7324472982438053
Validation loss: 3.0986197561294806

Epoch: 6| Step: 4
Training loss: 2.8036286206785643
Validation loss: 3.10171171274588

Epoch: 6| Step: 5
Training loss: 4.091276163914392
Validation loss: 3.100889578916543

Epoch: 6| Step: 6
Training loss: 3.573100998167142
Validation loss: 3.0991432725558195

Epoch: 6| Step: 7
Training loss: 3.3557890449394674
Validation loss: 3.097959109402047

Epoch: 6| Step: 8
Training loss: 3.1204607229696375
Validation loss: 3.0995551988003176

Epoch: 6| Step: 9
Training loss: 2.274030260762062
Validation loss: 3.097995521971846

Epoch: 6| Step: 10
Training loss: 2.924863378480417
Validation loss: 3.0986816354417606

Epoch: 6| Step: 11
Training loss: 3.1619988387393447
Validation loss: 3.0968827087393156

Epoch: 6| Step: 12
Training loss: 3.1021952332006086
Validation loss: 3.0981289130124865

Epoch: 6| Step: 13
Training loss: 3.7969011219523234
Validation loss: 3.0978834287740793

Epoch: 96| Step: 0
Training loss: 2.9533118133392353
Validation loss: 3.097557654006086

Epoch: 6| Step: 1
Training loss: 3.2597723538539
Validation loss: 3.1002901483985923

Epoch: 6| Step: 2
Training loss: 3.069467209798203
Validation loss: 3.099814235547697

Epoch: 6| Step: 3
Training loss: 3.7383306135308594
Validation loss: 3.0988359018477865

Epoch: 6| Step: 4
Training loss: 3.0978057171044946
Validation loss: 3.098633090488154

Epoch: 6| Step: 5
Training loss: 3.8423499061789874
Validation loss: 3.101563953099585

Epoch: 6| Step: 6
Training loss: 3.688172101339182
Validation loss: 3.0982906828422307

Epoch: 6| Step: 7
Training loss: 2.5183946041662537
Validation loss: 3.1021971223404816

Epoch: 6| Step: 8
Training loss: 3.5699182205022875
Validation loss: 3.096769282169831

Epoch: 6| Step: 9
Training loss: 3.5679318694465296
Validation loss: 3.1053640023787508

Epoch: 6| Step: 10
Training loss: 2.9542235899383353
Validation loss: 3.0979294027437194

Epoch: 6| Step: 11
Training loss: 3.544889188253228
Validation loss: 3.0981087853163416

Epoch: 6| Step: 12
Training loss: 3.579348425789007
Validation loss: 3.0924239214326215

Epoch: 6| Step: 13
Training loss: 3.2038865091366353
Validation loss: 3.091345540353609

Epoch: 97| Step: 0
Training loss: 3.18430692021573
Validation loss: 3.0938468612170076

Epoch: 6| Step: 1
Training loss: 2.404387607923174
Validation loss: 3.090078927562068

Epoch: 6| Step: 2
Training loss: 3.5322069879969784
Validation loss: 3.0912334904754544

Epoch: 6| Step: 3
Training loss: 3.5319103872524207
Validation loss: 3.0913154732499217

Epoch: 6| Step: 4
Training loss: 3.1370169947914452
Validation loss: 3.0910917769579664

Epoch: 6| Step: 5
Training loss: 2.9904844053697666
Validation loss: 3.0898196637407116

Epoch: 6| Step: 6
Training loss: 3.2945589002426363
Validation loss: 3.0896295441317907

Epoch: 6| Step: 7
Training loss: 3.9305577916534737
Validation loss: 3.089999761024214

Epoch: 6| Step: 8
Training loss: 3.9782135838956405
Validation loss: 3.087132107349922

Epoch: 6| Step: 9
Training loss: 3.3359926741814623
Validation loss: 3.086674615633629

Epoch: 6| Step: 10
Training loss: 3.530265603379966
Validation loss: 3.086293203057248

Epoch: 6| Step: 11
Training loss: 2.9635880415807114
Validation loss: 3.084391277461575

Epoch: 6| Step: 12
Training loss: 3.8316192249902574
Validation loss: 3.0843079519616112

Epoch: 6| Step: 13
Training loss: 2.435854919090858
Validation loss: 3.083361435695338

Epoch: 98| Step: 0
Training loss: 3.495748662699959
Validation loss: 3.081239700957461

Epoch: 6| Step: 1
Training loss: 3.1544917279695968
Validation loss: 3.0791935993650617

Epoch: 6| Step: 2
Training loss: 2.960128472349628
Validation loss: 3.0785040169455167

Epoch: 6| Step: 3
Training loss: 2.795776662995996
Validation loss: 3.0754517529617797

Epoch: 6| Step: 4
Training loss: 3.9852838414670173
Validation loss: 3.072343834985858

Epoch: 6| Step: 5
Training loss: 2.6497630175304856
Validation loss: 3.068534140040175

Epoch: 6| Step: 6
Training loss: 3.1188683435771813
Validation loss: 3.0716764193835893

Epoch: 6| Step: 7
Training loss: 4.517920098924247
Validation loss: 3.0763788762837785

Epoch: 6| Step: 8
Training loss: 3.242932484533584
Validation loss: 3.0656579406640354

Epoch: 6| Step: 9
Training loss: 3.621345782845193
Validation loss: 3.0688821950799787

Epoch: 6| Step: 10
Training loss: 3.122904570905806
Validation loss: 3.0698594280346705

Epoch: 6| Step: 11
Training loss: 3.3389248838792387
Validation loss: 3.071412507188486

Epoch: 6| Step: 12
Training loss: 2.9619795845147263
Validation loss: 3.080633922967232

Epoch: 6| Step: 13
Training loss: 3.31770750292294
Validation loss: 3.0747306268215624

Epoch: 99| Step: 0
Training loss: 3.484998843878359
Validation loss: 3.0703346067741837

Epoch: 6| Step: 1
Training loss: 3.1799988090464923
Validation loss: 3.0704095211364524

Epoch: 6| Step: 2
Training loss: 3.6745744887040552
Validation loss: 3.069921359285885

Epoch: 6| Step: 3
Training loss: 2.407062046704611
Validation loss: 3.068909522294707

Epoch: 6| Step: 4
Training loss: 3.807472290819899
Validation loss: 3.0681215583140364

Epoch: 6| Step: 5
Training loss: 2.519028913706792
Validation loss: 3.067276515173323

Epoch: 6| Step: 6
Training loss: 3.3076563996974464
Validation loss: 3.067087082804553

Epoch: 6| Step: 7
Training loss: 2.830771540956607
Validation loss: 3.0645254459358213

Epoch: 6| Step: 8
Training loss: 3.2890210364258476
Validation loss: 3.0641532848564514

Epoch: 6| Step: 9
Training loss: 3.846305431900055
Validation loss: 3.06282502476052

Epoch: 6| Step: 10
Training loss: 4.008542475858491
Validation loss: 3.0598285576365694

Epoch: 6| Step: 11
Training loss: 3.900192324468972
Validation loss: 3.060865393329945

Epoch: 6| Step: 12
Training loss: 2.6942194837102282
Validation loss: 3.0599015785360586

Epoch: 6| Step: 13
Training loss: 2.887122759596393
Validation loss: 3.060066530401316

Epoch: 100| Step: 0
Training loss: 3.498400186303075
Validation loss: 3.066160810377464

Epoch: 6| Step: 1
Training loss: 3.6938139314492355
Validation loss: 3.0624490683034895

Epoch: 6| Step: 2
Training loss: 2.2814384278117696
Validation loss: 3.0627401951278186

Epoch: 6| Step: 3
Training loss: 2.129894006446971
Validation loss: 3.086266556404595

Epoch: 6| Step: 4
Training loss: 3.569816972330988
Validation loss: 3.0859797399934035

Epoch: 6| Step: 5
Training loss: 2.922210510900871
Validation loss: 3.0558119610039336

Epoch: 6| Step: 6
Training loss: 3.3844927343740543
Validation loss: 3.0603675843431204

Epoch: 6| Step: 7
Training loss: 3.8328715889407996
Validation loss: 3.0655582419329965

Epoch: 6| Step: 8
Training loss: 3.1792252788082016
Validation loss: 3.069344702525062

Epoch: 6| Step: 9
Training loss: 3.642017540224877
Validation loss: 3.06528421679003

Epoch: 6| Step: 10
Training loss: 3.4750114495617077
Validation loss: 3.0598468551259175

Epoch: 6| Step: 11
Training loss: 3.7391719892948685
Validation loss: 3.059435297289379

Epoch: 6| Step: 12
Training loss: 2.5070139721791858
Validation loss: 3.054097203143259

Epoch: 6| Step: 13
Training loss: 4.502091451576089
Validation loss: 3.053397839731248

Epoch: 101| Step: 0
Training loss: 3.246791576382184
Validation loss: 3.052479106628026

Epoch: 6| Step: 1
Training loss: 3.5298237578834937
Validation loss: 3.0513685622052225

Epoch: 6| Step: 2
Training loss: 3.3349021716546403
Validation loss: 3.0489100321688114

Epoch: 6| Step: 3
Training loss: 3.295470458324124
Validation loss: 3.0506108765445843

Epoch: 6| Step: 4
Training loss: 3.1016904098309843
Validation loss: 3.0471166404990195

Epoch: 6| Step: 5
Training loss: 3.153127806769068
Validation loss: 3.0476929178112506

Epoch: 6| Step: 6
Training loss: 3.308851427945473
Validation loss: 3.0502047812445983

Epoch: 6| Step: 7
Training loss: 3.1556336962587053
Validation loss: 3.045047663245863

Epoch: 6| Step: 8
Training loss: 3.0367658316552157
Validation loss: 3.0473131898060113

Epoch: 6| Step: 9
Training loss: 2.8445607800667823
Validation loss: 3.047974107690416

Epoch: 6| Step: 10
Training loss: 3.501633535376976
Validation loss: 3.0467637766690925

Epoch: 6| Step: 11
Training loss: 3.0367454188073557
Validation loss: 3.0479844851225066

Epoch: 6| Step: 12
Training loss: 3.789047650180308
Validation loss: 3.0484913701648466

Epoch: 6| Step: 13
Training loss: 4.360998145474165
Validation loss: 3.049655337589498

Epoch: 102| Step: 0
Training loss: 3.6200423705008196
Validation loss: 3.0480802825105697

Epoch: 6| Step: 1
Training loss: 3.8473412089456995
Validation loss: 3.0458705074023165

Epoch: 6| Step: 2
Training loss: 3.499935149545687
Validation loss: 3.0480262804655127

Epoch: 6| Step: 3
Training loss: 3.5884732192348903
Validation loss: 3.0449300956882155

Epoch: 6| Step: 4
Training loss: 2.6090186326870124
Validation loss: 3.045811083550362

Epoch: 6| Step: 5
Training loss: 2.951578371036604
Validation loss: 3.0453344379207032

Epoch: 6| Step: 6
Training loss: 3.4496975973530772
Validation loss: 3.044563598472748

Epoch: 6| Step: 7
Training loss: 2.8848520729578357
Validation loss: 3.0433933135057525

Epoch: 6| Step: 8
Training loss: 3.6305372106517853
Validation loss: 3.0437679497354897

Epoch: 6| Step: 9
Training loss: 2.631115012432691
Validation loss: 3.04366364766018

Epoch: 6| Step: 10
Training loss: 3.492688034336905
Validation loss: 3.0436624347655643

Epoch: 6| Step: 11
Training loss: 3.1499281920468074
Validation loss: 3.042986529648218

Epoch: 6| Step: 12
Training loss: 3.6331293439617665
Validation loss: 3.0422723680912616

Epoch: 6| Step: 13
Training loss: 2.9039280958074905
Validation loss: 3.041391813429803

Epoch: 103| Step: 0
Training loss: 3.1518219961550455
Validation loss: 3.0440780637704323

Epoch: 6| Step: 1
Training loss: 3.2053799763119355
Validation loss: 3.042505672533571

Epoch: 6| Step: 2
Training loss: 2.900432383432556
Validation loss: 3.0414409449746924

Epoch: 6| Step: 3
Training loss: 3.588713724397463
Validation loss: 3.043047151873629

Epoch: 6| Step: 4
Training loss: 3.4595693807601213
Validation loss: 3.0404979296688643

Epoch: 6| Step: 5
Training loss: 3.026983818068916
Validation loss: 3.040807290465223

Epoch: 6| Step: 6
Training loss: 3.5384091075151267
Validation loss: 3.0428045765278733

Epoch: 6| Step: 7
Training loss: 3.1292882869432614
Validation loss: 3.040305067325122

Epoch: 6| Step: 8
Training loss: 3.5894638375207433
Validation loss: 3.0393557235320636

Epoch: 6| Step: 9
Training loss: 2.6933151141894425
Validation loss: 3.0403116663437717

Epoch: 6| Step: 10
Training loss: 3.042837901601458
Validation loss: 3.0392165576903754

Epoch: 6| Step: 11
Training loss: 4.074549016979972
Validation loss: 3.0393463646675367

Epoch: 6| Step: 12
Training loss: 3.5529422709668044
Validation loss: 3.0399799876345046

Epoch: 6| Step: 13
Training loss: 3.034701869342525
Validation loss: 3.0399161636987837

Epoch: 104| Step: 0
Training loss: 3.8243199959465324
Validation loss: 3.0401691644931423

Epoch: 6| Step: 1
Training loss: 2.942670775767426
Validation loss: 3.038292892587695

Epoch: 6| Step: 2
Training loss: 3.172072531276162
Validation loss: 3.0386824258015555

Epoch: 6| Step: 3
Training loss: 2.942352345407315
Validation loss: 3.0374404320040584

Epoch: 6| Step: 4
Training loss: 3.4402593461680304
Validation loss: 3.0404883217915124

Epoch: 6| Step: 5
Training loss: 3.6688483567838674
Validation loss: 3.0397569884771185

Epoch: 6| Step: 6
Training loss: 2.7209244724994455
Validation loss: 3.039958532949992

Epoch: 6| Step: 7
Training loss: 3.2503333287598175
Validation loss: 3.038848618045105

Epoch: 6| Step: 8
Training loss: 2.746808541007128
Validation loss: 3.0401068961520608

Epoch: 6| Step: 9
Training loss: 3.422304170075993
Validation loss: 3.0433673046076772

Epoch: 6| Step: 10
Training loss: 3.2649091456158432
Validation loss: 3.041564542432891

Epoch: 6| Step: 11
Training loss: 4.030744180808681
Validation loss: 3.045276300886544

Epoch: 6| Step: 12
Training loss: 3.0067523623798413
Validation loss: 3.0417035789345857

Epoch: 6| Step: 13
Training loss: 3.7431131066352967
Validation loss: 3.04136248652275

Epoch: 105| Step: 0
Training loss: 3.364575286635155
Validation loss: 3.0420033674084546

Epoch: 6| Step: 1
Training loss: 3.843285757422678
Validation loss: 3.0399914802195487

Epoch: 6| Step: 2
Training loss: 2.9604954049800036
Validation loss: 3.0403756944631164

Epoch: 6| Step: 3
Training loss: 3.6936304889586404
Validation loss: 3.0375786748882847

Epoch: 6| Step: 4
Training loss: 3.008861804591706
Validation loss: 3.0351673621773254

Epoch: 6| Step: 5
Training loss: 3.2250643524136806
Validation loss: 3.0337447782813336

Epoch: 6| Step: 6
Training loss: 3.240575476978907
Validation loss: 3.033580070971118

Epoch: 6| Step: 7
Training loss: 2.8972942225904257
Validation loss: 3.0344269222901916

Epoch: 6| Step: 8
Training loss: 3.7526881437768527
Validation loss: 3.0336468355302446

Epoch: 6| Step: 9
Training loss: 3.23727449198776
Validation loss: 3.038844166246663

Epoch: 6| Step: 10
Training loss: 3.046368366081619
Validation loss: 3.0365948242271994

Epoch: 6| Step: 11
Training loss: 3.3758271228133943
Validation loss: 3.0339771161161653

Epoch: 6| Step: 12
Training loss: 2.58766361032594
Validation loss: 3.0346800014149817

Epoch: 6| Step: 13
Training loss: 4.051616468559281
Validation loss: 3.0330236979959704

Epoch: 106| Step: 0
Training loss: 3.5361236428871723
Validation loss: 3.033737472887638

Epoch: 6| Step: 1
Training loss: 2.853656825358737
Validation loss: 3.0334081381149876

Epoch: 6| Step: 2
Training loss: 3.37907022949283
Validation loss: 3.032772297233027

Epoch: 6| Step: 3
Training loss: 2.888109587029955
Validation loss: 3.0317294121519307

Epoch: 6| Step: 4
Training loss: 3.468970489367633
Validation loss: 3.0324390330265816

Epoch: 6| Step: 5
Training loss: 3.0367892277505426
Validation loss: 3.032411218212677

Epoch: 6| Step: 6
Training loss: 3.4486155344295892
Validation loss: 3.031525774717567

Epoch: 6| Step: 7
Training loss: 3.7603647047064923
Validation loss: 3.030894103077265

Epoch: 6| Step: 8
Training loss: 3.5323160638456947
Validation loss: 3.031429255447608

Epoch: 6| Step: 9
Training loss: 2.9320512924912
Validation loss: 3.0308182593593584

Epoch: 6| Step: 10
Training loss: 3.6353281150606462
Validation loss: 3.0311194847298286

Epoch: 6| Step: 11
Training loss: 2.9467687270094607
Validation loss: 3.0292192834505585

Epoch: 6| Step: 12
Training loss: 3.455211716608954
Validation loss: 3.0315768614643113

Epoch: 6| Step: 13
Training loss: 3.0518707791591613
Validation loss: 3.0294175550055584

Epoch: 107| Step: 0
Training loss: 3.5166473936544147
Validation loss: 3.031504980708059

Epoch: 6| Step: 1
Training loss: 3.319663596977068
Validation loss: 3.041525248466537

Epoch: 6| Step: 2
Training loss: 3.315072410333505
Validation loss: 3.0413356110030736

Epoch: 6| Step: 3
Training loss: 3.0262649287438985
Validation loss: 3.033737582743312

Epoch: 6| Step: 4
Training loss: 3.5159868520375857
Validation loss: 3.0280048382374023

Epoch: 6| Step: 5
Training loss: 3.25026276333171
Validation loss: 3.0267870649664363

Epoch: 6| Step: 6
Training loss: 3.5860590363561284
Validation loss: 3.02692097273763

Epoch: 6| Step: 7
Training loss: 3.1134576879113136
Validation loss: 3.0255148713625744

Epoch: 6| Step: 8
Training loss: 3.725680520793158
Validation loss: 3.0265833025214905

Epoch: 6| Step: 9
Training loss: 3.302581332387024
Validation loss: 3.0264601487014335

Epoch: 6| Step: 10
Training loss: 3.1410728628700095
Validation loss: 3.025833710406594

Epoch: 6| Step: 11
Training loss: 3.2998132132639935
Validation loss: 3.026239193663908

Epoch: 6| Step: 12
Training loss: 2.692578153334905
Validation loss: 3.025885472763665

Epoch: 6| Step: 13
Training loss: 3.296953100933627
Validation loss: 3.0246683099731713

Epoch: 108| Step: 0
Training loss: 2.4990198121188043
Validation loss: 3.025649821698189

Epoch: 6| Step: 1
Training loss: 3.603760948204217
Validation loss: 3.0241190934945745

Epoch: 6| Step: 2
Training loss: 3.321707111756168
Validation loss: 3.025161543725779

Epoch: 6| Step: 3
Training loss: 3.39578276676528
Validation loss: 3.024535065321332

Epoch: 6| Step: 4
Training loss: 2.7897708965564605
Validation loss: 3.0261045169867353

Epoch: 6| Step: 5
Training loss: 2.8026387587130848
Validation loss: 3.0244401241945114

Epoch: 6| Step: 6
Training loss: 2.9700672640392307
Validation loss: 3.0274585074679496

Epoch: 6| Step: 7
Training loss: 3.5179512973990392
Validation loss: 3.0233691566753484

Epoch: 6| Step: 8
Training loss: 3.8713637487829304
Validation loss: 3.0254542266105315

Epoch: 6| Step: 9
Training loss: 3.755301860150799
Validation loss: 3.0237743014890395

Epoch: 6| Step: 10
Training loss: 3.150219585697218
Validation loss: 3.0235675820774572

Epoch: 6| Step: 11
Training loss: 3.9249646908089098
Validation loss: 3.0238708056712285

Epoch: 6| Step: 12
Training loss: 2.932139924065998
Validation loss: 3.0231980982627604

Epoch: 6| Step: 13
Training loss: 3.1895668957911902
Validation loss: 3.0216937821640304

Epoch: 109| Step: 0
Training loss: 3.2057636092830544
Validation loss: 3.023290817723016

Epoch: 6| Step: 1
Training loss: 2.681955162100238
Validation loss: 3.0236100405188906

Epoch: 6| Step: 2
Training loss: 3.08435419726869
Validation loss: 3.02107034049799

Epoch: 6| Step: 3
Training loss: 2.6896825400291564
Validation loss: 3.0207740469529596

Epoch: 6| Step: 4
Training loss: 3.27147562965249
Validation loss: 3.0217471705496113

Epoch: 6| Step: 5
Training loss: 3.2046151021426676
Validation loss: 3.0213947174792963

Epoch: 6| Step: 6
Training loss: 3.261116090937171
Validation loss: 3.022485563935385

Epoch: 6| Step: 7
Training loss: 3.2327638013074735
Validation loss: 3.0212631638312377

Epoch: 6| Step: 8
Training loss: 3.7197764286415316
Validation loss: 3.0226831449267793

Epoch: 6| Step: 9
Training loss: 3.5308724260600703
Validation loss: 3.0212886952242255

Epoch: 6| Step: 10
Training loss: 3.794053775999463
Validation loss: 3.0236177247920755

Epoch: 6| Step: 11
Training loss: 3.5865541812979407
Validation loss: 3.022323201677602

Epoch: 6| Step: 12
Training loss: 3.361043258556586
Validation loss: 3.0221926495377778

Epoch: 6| Step: 13
Training loss: 3.2684897674778517
Validation loss: 3.0200230010537448

Epoch: 110| Step: 0
Training loss: 2.794372376620111
Validation loss: 3.0206184138194425

Epoch: 6| Step: 1
Training loss: 3.6805522574803833
Validation loss: 3.0214877807590357

Epoch: 6| Step: 2
Training loss: 2.908984958550784
Validation loss: 3.021183524592164

Epoch: 6| Step: 3
Training loss: 3.902056831450452
Validation loss: 3.0204421460899

Epoch: 6| Step: 4
Training loss: 3.905597235498071
Validation loss: 3.0192471878561475

Epoch: 6| Step: 5
Training loss: 3.293201008453641
Validation loss: 3.019101480600762

Epoch: 6| Step: 6
Training loss: 1.6356437266308697
Validation loss: 3.019035567066346

Epoch: 6| Step: 7
Training loss: 4.032093994740435
Validation loss: 3.018278594845986

Epoch: 6| Step: 8
Training loss: 3.7115894266995233
Validation loss: 3.0188708962473676

Epoch: 6| Step: 9
Training loss: 3.067028201256827
Validation loss: 3.019307241504201

Epoch: 6| Step: 10
Training loss: 2.61625322205937
Validation loss: 3.0213070945961094

Epoch: 6| Step: 11
Training loss: 3.38013688978372
Validation loss: 3.017453159317699

Epoch: 6| Step: 12
Training loss: 2.796819249455269
Validation loss: 3.017963344242123

Epoch: 6| Step: 13
Training loss: 3.675551890758741
Validation loss: 3.0166323742854715

Epoch: 111| Step: 0
Training loss: 3.7018324773259996
Validation loss: 3.0170600830604157

Epoch: 6| Step: 1
Training loss: 3.454951290996262
Validation loss: 3.015008231574742

Epoch: 6| Step: 2
Training loss: 3.579785357386118
Validation loss: 3.0138885056738145

Epoch: 6| Step: 3
Training loss: 2.851888225189516
Validation loss: 3.0168068234287913

Epoch: 6| Step: 4
Training loss: 3.0314337291291
Validation loss: 3.0147948191650817

Epoch: 6| Step: 5
Training loss: 3.1644291418071075
Validation loss: 3.0157879498413265

Epoch: 6| Step: 6
Training loss: 3.192093923338955
Validation loss: 3.0144091388783756

Epoch: 6| Step: 7
Training loss: 2.683139901465252
Validation loss: 3.014570019896806

Epoch: 6| Step: 8
Training loss: 3.3108571135054747
Validation loss: 3.0138675193759297

Epoch: 6| Step: 9
Training loss: 3.776346100560146
Validation loss: 3.0135873418732757

Epoch: 6| Step: 10
Training loss: 2.5916408557976265
Validation loss: 3.01451144092573

Epoch: 6| Step: 11
Training loss: 3.7236264096456884
Validation loss: 3.0152556397041512

Epoch: 6| Step: 12
Training loss: 3.0928799725592655
Validation loss: 3.0160984197110112

Epoch: 6| Step: 13
Training loss: 3.8414153165091554
Validation loss: 3.0151471832679677

Epoch: 112| Step: 0
Training loss: 3.1780238192645736
Validation loss: 3.016726426639862

Epoch: 6| Step: 1
Training loss: 3.121547775760836
Validation loss: 3.015706163185841

Epoch: 6| Step: 2
Training loss: 3.6011129831070354
Validation loss: 3.0157765469373192

Epoch: 6| Step: 3
Training loss: 3.275558330903358
Validation loss: 3.0159841964649052

Epoch: 6| Step: 4
Training loss: 2.9641715633454484
Validation loss: 3.0151181180487425

Epoch: 6| Step: 5
Training loss: 3.7309365503482645
Validation loss: 3.01473843851532

Epoch: 6| Step: 6
Training loss: 2.9572834426391092
Validation loss: 3.014107071083477

Epoch: 6| Step: 7
Training loss: 2.971150281209329
Validation loss: 3.0143740128893124

Epoch: 6| Step: 8
Training loss: 3.926974078344203
Validation loss: 3.0138822128619918

Epoch: 6| Step: 9
Training loss: 3.1703917695086155
Validation loss: 3.014355071117858

Epoch: 6| Step: 10
Training loss: 3.1216484407652207
Validation loss: 3.013686256394846

Epoch: 6| Step: 11
Training loss: 3.3055597691727256
Validation loss: 3.013900314655185

Epoch: 6| Step: 12
Training loss: 3.565242849159974
Validation loss: 3.0127905965080073

Epoch: 6| Step: 13
Training loss: 2.686648832866208
Validation loss: 3.0116363667768513

Epoch: 113| Step: 0
Training loss: 3.186724699388446
Validation loss: 3.013504561405693

Epoch: 6| Step: 1
Training loss: 3.3176070377011206
Validation loss: 3.0116662521407873

Epoch: 6| Step: 2
Training loss: 3.4004816331248193
Validation loss: 3.0127043682523444

Epoch: 6| Step: 3
Training loss: 2.637245679408646
Validation loss: 3.0129938639790392

Epoch: 6| Step: 4
Training loss: 3.849939588592973
Validation loss: 3.0131901139098716

Epoch: 6| Step: 5
Training loss: 3.3305640797368543
Validation loss: 3.011271549560942

Epoch: 6| Step: 6
Training loss: 2.9992205878905707
Validation loss: 3.011656925126574

Epoch: 6| Step: 7
Training loss: 2.9081804980441124
Validation loss: 3.0111265853096545

Epoch: 6| Step: 8
Training loss: 3.1433458072203146
Validation loss: 3.0113793078835673

Epoch: 6| Step: 9
Training loss: 3.2249299507517772
Validation loss: 3.012346340660759

Epoch: 6| Step: 10
Training loss: 3.071775442161329
Validation loss: 3.010033075319011

Epoch: 6| Step: 11
Training loss: 3.705986108761078
Validation loss: 3.0112367905157216

Epoch: 6| Step: 12
Training loss: 3.737081018138731
Validation loss: 3.0101471683902847

Epoch: 6| Step: 13
Training loss: 3.269075897483988
Validation loss: 3.011037830935122

Epoch: 114| Step: 0
Training loss: 2.9900257877526375
Validation loss: 3.0098766414951195

Epoch: 6| Step: 1
Training loss: 3.697053462902065
Validation loss: 3.0090224267111454

Epoch: 6| Step: 2
Training loss: 3.23540034604219
Validation loss: 3.010870880992884

Epoch: 6| Step: 3
Training loss: 2.6789597838296237
Validation loss: 3.0140105672923063

Epoch: 6| Step: 4
Training loss: 3.7293182995761067
Validation loss: 3.0177881464244254

Epoch: 6| Step: 5
Training loss: 3.3985183180045535
Validation loss: 3.0285624701225897

Epoch: 6| Step: 6
Training loss: 3.5867946821952494
Validation loss: 3.031020028588423

Epoch: 6| Step: 7
Training loss: 3.380373597574636
Validation loss: 3.034287267630946

Epoch: 6| Step: 8
Training loss: 2.829151620576726
Validation loss: 3.0223104781242585

Epoch: 6| Step: 9
Training loss: 3.610967111569276
Validation loss: 3.017728446532002

Epoch: 6| Step: 10
Training loss: 3.329937651683455
Validation loss: 3.0104163867774174

Epoch: 6| Step: 11
Training loss: 3.3986886468802373
Validation loss: 3.0093405485957807

Epoch: 6| Step: 12
Training loss: 2.5591371381474857
Validation loss: 3.006049146993463

Epoch: 6| Step: 13
Training loss: 3.305553277778019
Validation loss: 3.0052281477131295

Epoch: 115| Step: 0
Training loss: 3.9880490585722614
Validation loss: 3.0057282894346464

Epoch: 6| Step: 1
Training loss: 3.4948834759193197
Validation loss: 3.006232916268121

Epoch: 6| Step: 2
Training loss: 3.248834107423177
Validation loss: 3.0071202129611283

Epoch: 6| Step: 3
Training loss: 3.4635958483289477
Validation loss: 3.0064899734849932

Epoch: 6| Step: 4
Training loss: 3.067824270306075
Validation loss: 3.0069507759630887

Epoch: 6| Step: 5
Training loss: 3.438049411216669
Validation loss: 3.0065618912343637

Epoch: 6| Step: 6
Training loss: 3.219954182079674
Validation loss: 3.0056077457812513

Epoch: 6| Step: 7
Training loss: 3.1529609992908756
Validation loss: 3.0077327279277215

Epoch: 6| Step: 8
Training loss: 3.095857153108194
Validation loss: 3.006973581312569

Epoch: 6| Step: 9
Training loss: 2.8916192071924507
Validation loss: 3.0073367921660195

Epoch: 6| Step: 10
Training loss: 2.806297413992546
Validation loss: 3.0064432561262153

Epoch: 6| Step: 11
Training loss: 3.337828053557029
Validation loss: 3.005346324942509

Epoch: 6| Step: 12
Training loss: 3.0339585620562475
Validation loss: 3.006044135776349

Epoch: 6| Step: 13
Training loss: 3.709300497282228
Validation loss: 3.0040096487749994

Epoch: 116| Step: 0
Training loss: 3.690412631857254
Validation loss: 3.0041920246904525

Epoch: 6| Step: 1
Training loss: 2.811370283634673
Validation loss: 3.0038237233474137

Epoch: 6| Step: 2
Training loss: 3.6057692182491987
Validation loss: 3.001286029334527

Epoch: 6| Step: 3
Training loss: 2.937897026340088
Validation loss: 3.001907359279089

Epoch: 6| Step: 4
Training loss: 3.974817039069797
Validation loss: 3.002557262767273

Epoch: 6| Step: 5
Training loss: 3.726567874160826
Validation loss: 3.0017647047836724

Epoch: 6| Step: 6
Training loss: 3.7656548843147686
Validation loss: 3.002600550228028

Epoch: 6| Step: 7
Training loss: 2.8560314537261053
Validation loss: 3.002645519039322

Epoch: 6| Step: 8
Training loss: 2.9806756064049766
Validation loss: 3.0039343176600086

Epoch: 6| Step: 9
Training loss: 3.428048057005639
Validation loss: 3.001367932188682

Epoch: 6| Step: 10
Training loss: 2.408665423172877
Validation loss: 3.0013630532376356

Epoch: 6| Step: 11
Training loss: 2.817078995479619
Validation loss: 3.0035293457648558

Epoch: 6| Step: 12
Training loss: 3.1340755665718114
Validation loss: 3.00284121590049

Epoch: 6| Step: 13
Training loss: 3.34185594766243
Validation loss: 3.0035423264146344

Epoch: 117| Step: 0
Training loss: 2.3769752921431953
Validation loss: 3.0010680584188902

Epoch: 6| Step: 1
Training loss: 2.929887037475705
Validation loss: 3.0070099472556375

Epoch: 6| Step: 2
Training loss: 3.5009057371671384
Validation loss: 2.9998867020354436

Epoch: 6| Step: 3
Training loss: 3.5993788713161807
Validation loss: 3.002179644370511

Epoch: 6| Step: 4
Training loss: 2.4025999847470536
Validation loss: 3.0063885974212665

Epoch: 6| Step: 5
Training loss: 3.2052294261305696
Validation loss: 3.0077432578397305

Epoch: 6| Step: 6
Training loss: 3.6239583064327183
Validation loss: 3.0083718815151967

Epoch: 6| Step: 7
Training loss: 2.9041878552167852
Validation loss: 3.0072619007331545

Epoch: 6| Step: 8
Training loss: 3.3146073457785996
Validation loss: 3.003047751149952

Epoch: 6| Step: 9
Training loss: 4.226949677564208
Validation loss: 3.0096812709177048

Epoch: 6| Step: 10
Training loss: 3.465370525239295
Validation loss: 3.003089824454844

Epoch: 6| Step: 11
Training loss: 3.6489841615265717
Validation loss: 3.001882965412164

Epoch: 6| Step: 12
Training loss: 2.255808221146208
Validation loss: 3.000601626131485

Epoch: 6| Step: 13
Training loss: 4.021430305610289
Validation loss: 2.998592689240975

Epoch: 118| Step: 0
Training loss: 3.075180271726079
Validation loss: 2.997426220183262

Epoch: 6| Step: 1
Training loss: 3.609909480431494
Validation loss: 2.9987498416527942

Epoch: 6| Step: 2
Training loss: 2.8608379686293777
Validation loss: 2.9972185996027303

Epoch: 6| Step: 3
Training loss: 3.45488145439936
Validation loss: 2.996980454962276

Epoch: 6| Step: 4
Training loss: 3.6100884595267067
Validation loss: 2.9946642959423975

Epoch: 6| Step: 5
Training loss: 4.141331335317404
Validation loss: 2.995787924565411

Epoch: 6| Step: 6
Training loss: 2.7343879917381098
Validation loss: 2.994664301078814

Epoch: 6| Step: 7
Training loss: 2.595630010374521
Validation loss: 2.994813946841247

Epoch: 6| Step: 8
Training loss: 3.631862590022196
Validation loss: 2.9967646106785883

Epoch: 6| Step: 9
Training loss: 3.4894135998492626
Validation loss: 2.995161274933558

Epoch: 6| Step: 10
Training loss: 3.662586427261233
Validation loss: 2.9963732728596226

Epoch: 6| Step: 11
Training loss: 2.84534418045498
Validation loss: 2.99594495284326

Epoch: 6| Step: 12
Training loss: 2.2571644628501297
Validation loss: 2.9954498814636774

Epoch: 6| Step: 13
Training loss: 3.328460246649401
Validation loss: 2.995477769897193

Epoch: 119| Step: 0
Training loss: 3.626196302130103
Validation loss: 2.9926899924170134

Epoch: 6| Step: 1
Training loss: 2.7976489994026488
Validation loss: 2.995252835512939

Epoch: 6| Step: 2
Training loss: 2.7211021683875125
Validation loss: 2.994303252567209

Epoch: 6| Step: 3
Training loss: 3.6572585059936746
Validation loss: 2.9948588134314615

Epoch: 6| Step: 4
Training loss: 2.8824854719551865
Validation loss: 2.9919014869560363

Epoch: 6| Step: 5
Training loss: 3.6750941673203252
Validation loss: 2.9938985997291985

Epoch: 6| Step: 6
Training loss: 3.2366772994532367
Validation loss: 2.9903726397969037

Epoch: 6| Step: 7
Training loss: 3.136099216185962
Validation loss: 2.992522442924289

Epoch: 6| Step: 8
Training loss: 3.0203646241420183
Validation loss: 2.993137706211031

Epoch: 6| Step: 9
Training loss: 3.2696700892713597
Validation loss: 2.989616496476117

Epoch: 6| Step: 10
Training loss: 3.11087138145458
Validation loss: 2.9920136692452033

Epoch: 6| Step: 11
Training loss: 3.058243732716333
Validation loss: 2.991557021412217

Epoch: 6| Step: 12
Training loss: 3.8283351295565513
Validation loss: 2.9921531772736056

Epoch: 6| Step: 13
Training loss: 3.6592774206323715
Validation loss: 2.994398750257236

Epoch: 120| Step: 0
Training loss: 3.1005545643097796
Validation loss: 2.9942329830824477

Epoch: 6| Step: 1
Training loss: 2.5949805224795695
Validation loss: 2.9935277259593764

Epoch: 6| Step: 2
Training loss: 3.067419343990118
Validation loss: 2.994281326760814

Epoch: 6| Step: 3
Training loss: 3.8632321253354207
Validation loss: 2.991867407726992

Epoch: 6| Step: 4
Training loss: 2.804998269038083
Validation loss: 2.9908666409992595

Epoch: 6| Step: 5
Training loss: 3.50963845762943
Validation loss: 2.989437511469763

Epoch: 6| Step: 6
Training loss: 3.2661379178624004
Validation loss: 2.989466991878449

Epoch: 6| Step: 7
Training loss: 3.7745997690408015
Validation loss: 2.9869073012556657

Epoch: 6| Step: 8
Training loss: 3.0721473549827554
Validation loss: 2.989592603443499

Epoch: 6| Step: 9
Training loss: 3.6930053476707565
Validation loss: 2.988699244455701

Epoch: 6| Step: 10
Training loss: 3.2378219444417713
Validation loss: 2.9870026285844835

Epoch: 6| Step: 11
Training loss: 2.8156368141053476
Validation loss: 2.990010598059944

Epoch: 6| Step: 12
Training loss: 3.389055301839765
Validation loss: 2.987249638275158

Epoch: 6| Step: 13
Training loss: 3.1749823622326283
Validation loss: 2.9881664747640824

Epoch: 121| Step: 0
Training loss: 3.14547431025507
Validation loss: 2.987190755266978

Epoch: 6| Step: 1
Training loss: 3.5116459687257726
Validation loss: 2.9877895310177935

Epoch: 6| Step: 2
Training loss: 3.033210985280382
Validation loss: 2.9877907931932377

Epoch: 6| Step: 3
Training loss: 3.337718336414459
Validation loss: 2.985299156576162

Epoch: 6| Step: 4
Training loss: 3.956111578907762
Validation loss: 2.9867538878010333

Epoch: 6| Step: 5
Training loss: 2.914427051803356
Validation loss: 2.98499935357979

Epoch: 6| Step: 6
Training loss: 2.978251301027627
Validation loss: 2.9853724006107702

Epoch: 6| Step: 7
Training loss: 3.0770836632344647
Validation loss: 2.984393396735876

Epoch: 6| Step: 8
Training loss: 3.4725768827931196
Validation loss: 2.984570168331356

Epoch: 6| Step: 9
Training loss: 3.726604085566252
Validation loss: 2.984548783467768

Epoch: 6| Step: 10
Training loss: 2.649449248032808
Validation loss: 2.9851438140565016

Epoch: 6| Step: 11
Training loss: 2.8460663803841144
Validation loss: 2.9854981990491285

Epoch: 6| Step: 12
Training loss: 3.340505291298951
Validation loss: 2.9845524547072526

Epoch: 6| Step: 13
Training loss: 3.5948775139794593
Validation loss: 2.9861244864012026

Epoch: 122| Step: 0
Training loss: 3.069952480184477
Validation loss: 2.9860252401093192

Epoch: 6| Step: 1
Training loss: 3.242887196242526
Validation loss: 2.9869276967946927

Epoch: 6| Step: 2
Training loss: 3.17775373212643
Validation loss: 2.986108334206081

Epoch: 6| Step: 3
Training loss: 3.9108979915462845
Validation loss: 2.9850236621241146

Epoch: 6| Step: 4
Training loss: 2.740235506086055
Validation loss: 2.985010087358683

Epoch: 6| Step: 5
Training loss: 3.1580782590208396
Validation loss: 2.986388913589015

Epoch: 6| Step: 6
Training loss: 3.219197658778376
Validation loss: 2.9844914088121817

Epoch: 6| Step: 7
Training loss: 2.8834780206558657
Validation loss: 2.984980448705892

Epoch: 6| Step: 8
Training loss: 3.1867600124312867
Validation loss: 2.9837123910748633

Epoch: 6| Step: 9
Training loss: 3.063064523164879
Validation loss: 2.982780728662749

Epoch: 6| Step: 10
Training loss: 3.214335553221856
Validation loss: 2.9831707618687164

Epoch: 6| Step: 11
Training loss: 3.790157702544348
Validation loss: 2.9843041307895253

Epoch: 6| Step: 12
Training loss: 3.045142360923544
Validation loss: 2.9827642755900956

Epoch: 6| Step: 13
Training loss: 4.092441262282147
Validation loss: 2.9833325411883225

Epoch: 123| Step: 0
Training loss: 3.4056936387124725
Validation loss: 2.9820639659338855

Epoch: 6| Step: 1
Training loss: 3.2115724404539288
Validation loss: 2.983506250471742

Epoch: 6| Step: 2
Training loss: 3.5933041503325147
Validation loss: 2.98562487145634

Epoch: 6| Step: 3
Training loss: 3.200092201096715
Validation loss: 2.98448915826424

Epoch: 6| Step: 4
Training loss: 3.369864618768553
Validation loss: 2.9851760944453867

Epoch: 6| Step: 5
Training loss: 2.284752025880092
Validation loss: 2.9870784708075493

Epoch: 6| Step: 6
Training loss: 3.303300282312668
Validation loss: 2.991354487807053

Epoch: 6| Step: 7
Training loss: 3.5095816655845504
Validation loss: 2.9858964674216697

Epoch: 6| Step: 8
Training loss: 3.434093382572683
Validation loss: 2.9889464535882726

Epoch: 6| Step: 9
Training loss: 2.9723482511268027
Validation loss: 2.98986301326578

Epoch: 6| Step: 10
Training loss: 3.4340364520138347
Validation loss: 2.994036856286775

Epoch: 6| Step: 11
Training loss: 3.1337213505948207
Validation loss: 2.9914905052570435

Epoch: 6| Step: 12
Training loss: 3.250979789349555
Validation loss: 2.987977059903352

Epoch: 6| Step: 13
Training loss: 3.4518734143896017
Validation loss: 2.9793898446300378

Epoch: 124| Step: 0
Training loss: 3.0960801722276714
Validation loss: 2.976842730384118

Epoch: 6| Step: 1
Training loss: 2.7610975373478372
Validation loss: 2.9789656437825074

Epoch: 6| Step: 2
Training loss: 2.394775577295875
Validation loss: 2.977932555124923

Epoch: 6| Step: 3
Training loss: 2.4164975425033655
Validation loss: 2.9785718194188373

Epoch: 6| Step: 4
Training loss: 2.9545294434440375
Validation loss: 2.9802044306528783

Epoch: 6| Step: 5
Training loss: 3.35353197683659
Validation loss: 2.9821424353811787

Epoch: 6| Step: 6
Training loss: 3.4430587213202553
Validation loss: 2.982193067444408

Epoch: 6| Step: 7
Training loss: 3.377299620291295
Validation loss: 2.9821183904808404

Epoch: 6| Step: 8
Training loss: 3.659920830417554
Validation loss: 2.981586452568453

Epoch: 6| Step: 9
Training loss: 4.276111944490744
Validation loss: 2.9792064994239027

Epoch: 6| Step: 10
Training loss: 3.6860445674079254
Validation loss: 2.9799238505258523

Epoch: 6| Step: 11
Training loss: 3.5403496630981963
Validation loss: 2.977960017910361

Epoch: 6| Step: 12
Training loss: 3.0170926490544696
Validation loss: 2.9796662041259916

Epoch: 6| Step: 13
Training loss: 3.0584040128629173
Validation loss: 2.977518002533904

Epoch: 125| Step: 0
Training loss: 2.900464606064048
Validation loss: 2.9784745206103014

Epoch: 6| Step: 1
Training loss: 3.447543228686142
Validation loss: 2.9775384064231734

Epoch: 6| Step: 2
Training loss: 3.8448750159855396
Validation loss: 2.9766106431938217

Epoch: 6| Step: 3
Training loss: 3.0900778506943882
Validation loss: 2.9764586516062272

Epoch: 6| Step: 4
Training loss: 3.5739213663426193
Validation loss: 2.976361333674491

Epoch: 6| Step: 5
Training loss: 2.2575382475290193
Validation loss: 2.975677781639062

Epoch: 6| Step: 6
Training loss: 2.310424698270202
Validation loss: 2.981308637256351

Epoch: 6| Step: 7
Training loss: 3.739411345682531
Validation loss: 2.9804690553520956

Epoch: 6| Step: 8
Training loss: 4.033592785353603
Validation loss: 2.9791530870133434

Epoch: 6| Step: 9
Training loss: 3.3830921506810894
Validation loss: 2.976685959573479

Epoch: 6| Step: 10
Training loss: 3.169078778246823
Validation loss: 2.975208950865395

Epoch: 6| Step: 11
Training loss: 2.53502157409035
Validation loss: 2.9824118075410495

Epoch: 6| Step: 12
Training loss: 3.530184694813033
Validation loss: 2.986450137020142

Epoch: 6| Step: 13
Training loss: 3.053634423010078
Validation loss: 2.989577515310502

Epoch: 126| Step: 0
Training loss: 3.730533938811967
Validation loss: 2.9796307769717005

Epoch: 6| Step: 1
Training loss: 3.394578448319743
Validation loss: 2.9804412613020417

Epoch: 6| Step: 2
Training loss: 3.9023819960666457
Validation loss: 2.9738282685859625

Epoch: 6| Step: 3
Training loss: 2.9626508199552384
Validation loss: 2.9739637083714716

Epoch: 6| Step: 4
Training loss: 3.1967019788470963
Validation loss: 2.9724474331455557

Epoch: 6| Step: 5
Training loss: 2.874871956005647
Validation loss: 2.971712288405344

Epoch: 6| Step: 6
Training loss: 2.4341639651299096
Validation loss: 2.9704783444674963

Epoch: 6| Step: 7
Training loss: 2.5127935171673403
Validation loss: 2.972017251303124

Epoch: 6| Step: 8
Training loss: 3.1373577678402786
Validation loss: 2.970682385927728

Epoch: 6| Step: 9
Training loss: 3.249542791044623
Validation loss: 2.9734133800157507

Epoch: 6| Step: 10
Training loss: 3.437787824198367
Validation loss: 2.973841278879881

Epoch: 6| Step: 11
Training loss: 3.256530363054084
Validation loss: 2.9710671518829836

Epoch: 6| Step: 12
Training loss: 3.4969778637249513
Validation loss: 2.970759771823019

Epoch: 6| Step: 13
Training loss: 3.786155608125534
Validation loss: 2.970838358634267

Epoch: 127| Step: 0
Training loss: 3.232916166654
Validation loss: 2.972315441570261

Epoch: 6| Step: 1
Training loss: 2.6879288087341067
Validation loss: 2.9718143987864134

Epoch: 6| Step: 2
Training loss: 3.6869860792070535
Validation loss: 2.9715643417802013

Epoch: 6| Step: 3
Training loss: 3.400380528416946
Validation loss: 2.971781274503224

Epoch: 6| Step: 4
Training loss: 2.975213333302691
Validation loss: 2.9706164448644903

Epoch: 6| Step: 5
Training loss: 3.5108594002077815
Validation loss: 2.9709625858968804

Epoch: 6| Step: 6
Training loss: 3.203355436642459
Validation loss: 2.9711571589347616

Epoch: 6| Step: 7
Training loss: 3.684618972064726
Validation loss: 2.9705642795360676

Epoch: 6| Step: 8
Training loss: 2.7841502294784983
Validation loss: 2.972443576186394

Epoch: 6| Step: 9
Training loss: 2.118178470012089
Validation loss: 2.972060962008435

Epoch: 6| Step: 10
Training loss: 3.470450319647665
Validation loss: 2.9694764194653356

Epoch: 6| Step: 11
Training loss: 3.7094561702135467
Validation loss: 2.970506475975211

Epoch: 6| Step: 12
Training loss: 3.1116324812883027
Validation loss: 2.969033951016949

Epoch: 6| Step: 13
Training loss: 3.6921631375161637
Validation loss: 2.968196276247775

Epoch: 128| Step: 0
Training loss: 3.2323425098829315
Validation loss: 2.9675907939570645

Epoch: 6| Step: 1
Training loss: 3.25715407343298
Validation loss: 2.966410644266654

Epoch: 6| Step: 2
Training loss: 3.3200516901243655
Validation loss: 2.9708670407319864

Epoch: 6| Step: 3
Training loss: 2.957958645441909
Validation loss: 2.9695620813711745

Epoch: 6| Step: 4
Training loss: 3.1456653137473607
Validation loss: 2.9755155964677695

Epoch: 6| Step: 5
Training loss: 3.428102026891105
Validation loss: 2.981449718445283

Epoch: 6| Step: 6
Training loss: 2.8384846999492006
Validation loss: 2.982071333439532

Epoch: 6| Step: 7
Training loss: 2.887360415036682
Validation loss: 2.9700995719092407

Epoch: 6| Step: 8
Training loss: 3.217066796934739
Validation loss: 2.9679855243201163

Epoch: 6| Step: 9
Training loss: 3.5556416666676585
Validation loss: 2.968324916870252

Epoch: 6| Step: 10
Training loss: 3.526363130882463
Validation loss: 2.9675643444427697

Epoch: 6| Step: 11
Training loss: 3.5626913989668627
Validation loss: 2.9656606993729864

Epoch: 6| Step: 12
Training loss: 2.878655804489772
Validation loss: 2.9660278093432755

Epoch: 6| Step: 13
Training loss: 3.7067124899997985
Validation loss: 2.965327605247148

Epoch: 129| Step: 0
Training loss: 3.293416165945971
Validation loss: 2.964818739029976

Epoch: 6| Step: 1
Training loss: 2.8058894140267823
Validation loss: 2.9657644720489

Epoch: 6| Step: 2
Training loss: 3.8750546359240516
Validation loss: 2.964888489926997

Epoch: 6| Step: 3
Training loss: 3.7043285104232813
Validation loss: 2.9650990391921903

Epoch: 6| Step: 4
Training loss: 3.255842093254225
Validation loss: 2.966214618160618

Epoch: 6| Step: 5
Training loss: 3.2145786848217988
Validation loss: 2.963805332360442

Epoch: 6| Step: 6
Training loss: 2.9279698740967546
Validation loss: 2.963415609496294

Epoch: 6| Step: 7
Training loss: 3.3114438082526547
Validation loss: 2.962250534013937

Epoch: 6| Step: 8
Training loss: 3.193113283713397
Validation loss: 2.964433438803527

Epoch: 6| Step: 9
Training loss: 2.736906612655332
Validation loss: 2.9608315130054033

Epoch: 6| Step: 10
Training loss: 3.418380695041573
Validation loss: 2.9614556032681496

Epoch: 6| Step: 11
Training loss: 2.846277978731936
Validation loss: 2.962901498574771

Epoch: 6| Step: 12
Training loss: 3.138654555704394
Validation loss: 2.9606788161422926

Epoch: 6| Step: 13
Training loss: 3.6549866931010304
Validation loss: 2.9643988094338063

Epoch: 130| Step: 0
Training loss: 2.853896432228442
Validation loss: 2.963347758331601

Epoch: 6| Step: 1
Training loss: 3.3495951393647934
Validation loss: 2.962801865476804

Epoch: 6| Step: 2
Training loss: 3.090229690310964
Validation loss: 2.962908862679971

Epoch: 6| Step: 3
Training loss: 3.122279394342058
Validation loss: 2.961779653964117

Epoch: 6| Step: 4
Training loss: 2.6775257521814746
Validation loss: 2.964700126657682

Epoch: 6| Step: 5
Training loss: 4.258048122780902
Validation loss: 2.963445267453088

Epoch: 6| Step: 6
Training loss: 3.193338469923928
Validation loss: 2.960127614952856

Epoch: 6| Step: 7
Training loss: 3.09538672722632
Validation loss: 2.96037623748696

Epoch: 6| Step: 8
Training loss: 3.362768260365975
Validation loss: 2.9607462981303043

Epoch: 6| Step: 9
Training loss: 2.9039097048800744
Validation loss: 2.9611558562289835

Epoch: 6| Step: 10
Training loss: 2.8406160293622107
Validation loss: 2.95778365504577

Epoch: 6| Step: 11
Training loss: 2.762414135181046
Validation loss: 2.9588530573700855

Epoch: 6| Step: 12
Training loss: 3.958477753798717
Validation loss: 2.9628760039721493

Epoch: 6| Step: 13
Training loss: 3.69906767362436
Validation loss: 2.961346019650751

Epoch: 131| Step: 0
Training loss: 2.9304133215482455
Validation loss: 2.962083550199566

Epoch: 6| Step: 1
Training loss: 3.7446627464262594
Validation loss: 2.963034737508386

Epoch: 6| Step: 2
Training loss: 3.046743536827348
Validation loss: 2.9591826837697113

Epoch: 6| Step: 3
Training loss: 3.2455789867116738
Validation loss: 2.956963057266849

Epoch: 6| Step: 4
Training loss: 4.085125640094969
Validation loss: 2.958566049599356

Epoch: 6| Step: 5
Training loss: 2.6068446516978985
Validation loss: 2.9563686658962443

Epoch: 6| Step: 6
Training loss: 3.7655097658878898
Validation loss: 2.9588265193502394

Epoch: 6| Step: 7
Training loss: 2.842207270087404
Validation loss: 2.9581679243484484

Epoch: 6| Step: 8
Training loss: 2.828583906677378
Validation loss: 2.956918857208367

Epoch: 6| Step: 9
Training loss: 2.7338043489360606
Validation loss: 2.957496686522398

Epoch: 6| Step: 10
Training loss: 3.156072630478034
Validation loss: 2.957524849626704

Epoch: 6| Step: 11
Training loss: 3.579815461074993
Validation loss: 2.959797878115875

Epoch: 6| Step: 12
Training loss: 2.8670862164395334
Validation loss: 2.9579446171234984

Epoch: 6| Step: 13
Training loss: 3.713380928716165
Validation loss: 2.9583521184768244

Epoch: 132| Step: 0
Training loss: 2.89860711025597
Validation loss: 2.9573339559114866

Epoch: 6| Step: 1
Training loss: 3.6301032351691926
Validation loss: 2.9586774570151295

Epoch: 6| Step: 2
Training loss: 2.6492453274283836
Validation loss: 2.958685376649625

Epoch: 6| Step: 3
Training loss: 3.3639860932088785
Validation loss: 2.9560730003100466

Epoch: 6| Step: 4
Training loss: 3.223455748365397
Validation loss: 2.9569324855073598

Epoch: 6| Step: 5
Training loss: 3.403158762530523
Validation loss: 2.9566618567721017

Epoch: 6| Step: 6
Training loss: 2.9069062179171907
Validation loss: 2.9552956849474312

Epoch: 6| Step: 7
Training loss: 3.0482049631405124
Validation loss: 2.9593130347136705

Epoch: 6| Step: 8
Training loss: 3.2786450899874224
Validation loss: 2.9700558893066122

Epoch: 6| Step: 9
Training loss: 3.714305369356571
Validation loss: 2.969448326546214

Epoch: 6| Step: 10
Training loss: 3.561167149756644
Validation loss: 2.9670756257133646

Epoch: 6| Step: 11
Training loss: 2.869854676558203
Validation loss: 2.9628495443833636

Epoch: 6| Step: 12
Training loss: 3.458631173296093
Validation loss: 2.969882523253285

Epoch: 6| Step: 13
Training loss: 3.1930109889757996
Validation loss: 2.959039418976221

Epoch: 133| Step: 0
Training loss: 3.517198541082459
Validation loss: 2.957090600915889

Epoch: 6| Step: 1
Training loss: 2.942462706090495
Validation loss: 2.9576949416210163

Epoch: 6| Step: 2
Training loss: 3.0694965705262107
Validation loss: 2.954503673555216

Epoch: 6| Step: 3
Training loss: 3.3264291947129982
Validation loss: 2.9542108403652763

Epoch: 6| Step: 4
Training loss: 3.9408640947040086
Validation loss: 2.953503282969538

Epoch: 6| Step: 5
Training loss: 3.1537944948714314
Validation loss: 2.9539003792617216

Epoch: 6| Step: 6
Training loss: 3.111786640335533
Validation loss: 2.9542826892008534

Epoch: 6| Step: 7
Training loss: 3.9607157447632404
Validation loss: 2.9554903378511588

Epoch: 6| Step: 8
Training loss: 3.2226213303032347
Validation loss: 2.9542516853183947

Epoch: 6| Step: 9
Training loss: 1.8371228226711527
Validation loss: 2.955868404842564

Epoch: 6| Step: 10
Training loss: 3.2779736828495287
Validation loss: 2.955748424582035

Epoch: 6| Step: 11
Training loss: 3.2428942541996184
Validation loss: 2.959280463542617

Epoch: 6| Step: 12
Training loss: 3.02475506760368
Validation loss: 2.9559590091146974

Epoch: 6| Step: 13
Training loss: 3.279474559193807
Validation loss: 2.955289921448003

Epoch: 134| Step: 0
Training loss: 3.4255568671171575
Validation loss: 2.953078553953897

Epoch: 6| Step: 1
Training loss: 3.6162435070181296
Validation loss: 2.953219591344574

Epoch: 6| Step: 2
Training loss: 3.5417284492638896
Validation loss: 2.952364707644257

Epoch: 6| Step: 3
Training loss: 2.7062856905303865
Validation loss: 2.9535782720032944

Epoch: 6| Step: 4
Training loss: 3.810406594795833
Validation loss: 2.9524235141558126

Epoch: 6| Step: 5
Training loss: 3.7103497170190045
Validation loss: 2.9539325358965454

Epoch: 6| Step: 6
Training loss: 3.347673912402356
Validation loss: 2.956073420056778

Epoch: 6| Step: 7
Training loss: 3.1646504927225165
Validation loss: 2.951964728205908

Epoch: 6| Step: 8
Training loss: 3.206769256484017
Validation loss: 2.9670811053828934

Epoch: 6| Step: 9
Training loss: 3.020646731872493
Validation loss: 2.96395705597487

Epoch: 6| Step: 10
Training loss: 2.542187267413653
Validation loss: 2.9644485580551003

Epoch: 6| Step: 11
Training loss: 3.2830610817540875
Validation loss: 2.9548095058778983

Epoch: 6| Step: 12
Training loss: 2.5813467529489253
Validation loss: 2.953897162016794

Epoch: 6| Step: 13
Training loss: 2.92417922934697
Validation loss: 2.953145523811654

Epoch: 135| Step: 0
Training loss: 4.1288270247986905
Validation loss: 2.952033204009182

Epoch: 6| Step: 1
Training loss: 2.843143272651458
Validation loss: 2.953742900253467

Epoch: 6| Step: 2
Training loss: 3.1633794353356186
Validation loss: 2.956185949924216

Epoch: 6| Step: 3
Training loss: 3.751771762640653
Validation loss: 2.954825325949587

Epoch: 6| Step: 4
Training loss: 3.155784345968025
Validation loss: 2.9570644562815676

Epoch: 6| Step: 5
Training loss: 2.9597342670859312
Validation loss: 2.955400971798225

Epoch: 6| Step: 6
Training loss: 3.5437422710246955
Validation loss: 2.9588943736880826

Epoch: 6| Step: 7
Training loss: 2.377901012083262
Validation loss: 2.9553062420808396

Epoch: 6| Step: 8
Training loss: 2.9225536517071733
Validation loss: 2.955959983935928

Epoch: 6| Step: 9
Training loss: 3.170489680498574
Validation loss: 2.95537405319758

Epoch: 6| Step: 10
Training loss: 3.4221561960839115
Validation loss: 2.95478174896962

Epoch: 6| Step: 11
Training loss: 2.995494479211703
Validation loss: 2.954274165074714

Epoch: 6| Step: 12
Training loss: 3.5321550137901467
Validation loss: 2.950255897557781

Epoch: 6| Step: 13
Training loss: 2.8794931877096714
Validation loss: 2.949823438923551

Epoch: 136| Step: 0
Training loss: 3.5742681114248596
Validation loss: 2.9504035754296933

Epoch: 6| Step: 1
Training loss: 3.4006074138425704
Validation loss: 2.9496731133280596

Epoch: 6| Step: 2
Training loss: 3.770571803231923
Validation loss: 2.949591201313677

Epoch: 6| Step: 3
Training loss: 3.29230779528532
Validation loss: 2.948907315612435

Epoch: 6| Step: 4
Training loss: 2.9067493953072634
Validation loss: 2.949718861212829

Epoch: 6| Step: 5
Training loss: 2.4612523437612834
Validation loss: 2.9460448969655992

Epoch: 6| Step: 6
Training loss: 3.16688061710851
Validation loss: 2.9447920396991174

Epoch: 6| Step: 7
Training loss: 3.6765539348354994
Validation loss: 2.9448050250573

Epoch: 6| Step: 8
Training loss: 3.037024591863232
Validation loss: 2.9447014600966677

Epoch: 6| Step: 9
Training loss: 3.319738863591009
Validation loss: 2.945486541059836

Epoch: 6| Step: 10
Training loss: 3.138152558449404
Validation loss: 2.9547009338606944

Epoch: 6| Step: 11
Training loss: 2.951347502374627
Validation loss: 2.955328426685129

Epoch: 6| Step: 12
Training loss: 3.086731164009854
Validation loss: 2.9616050157187157

Epoch: 6| Step: 13
Training loss: 3.2455657639764284
Validation loss: 2.948558122020301

Epoch: 137| Step: 0
Training loss: 3.2187726658884146
Validation loss: 2.9438689435903305

Epoch: 6| Step: 1
Training loss: 3.535944695829924
Validation loss: 2.946425341852211

Epoch: 6| Step: 2
Training loss: 3.5203012519585615
Validation loss: 2.9464549942014444

Epoch: 6| Step: 3
Training loss: 2.6722536766789964
Validation loss: 2.9481549478502638

Epoch: 6| Step: 4
Training loss: 2.487804900225927
Validation loss: 2.94739048571419

Epoch: 6| Step: 5
Training loss: 4.082884601667335
Validation loss: 2.9475945807281394

Epoch: 6| Step: 6
Training loss: 2.8999591956063178
Validation loss: 2.9483940789909764

Epoch: 6| Step: 7
Training loss: 3.51430069458324
Validation loss: 2.947944709826782

Epoch: 6| Step: 8
Training loss: 3.4657240032230083
Validation loss: 2.94950993542919

Epoch: 6| Step: 9
Training loss: 3.3950503954286155
Validation loss: 2.945685368631721

Epoch: 6| Step: 10
Training loss: 3.004608111986688
Validation loss: 2.9473174633488783

Epoch: 6| Step: 11
Training loss: 2.7761958629923873
Validation loss: 2.946157334767551

Epoch: 6| Step: 12
Training loss: 2.774666355455055
Validation loss: 2.9478729191462554

Epoch: 6| Step: 13
Training loss: 3.7529098665069864
Validation loss: 2.9468638425276588

Epoch: 138| Step: 0
Training loss: 3.616910128741732
Validation loss: 2.948797114400824

Epoch: 6| Step: 1
Training loss: 3.7382520397484043
Validation loss: 2.9457031828226232

Epoch: 6| Step: 2
Training loss: 2.4497569099809207
Validation loss: 2.9442334313941707

Epoch: 6| Step: 3
Training loss: 3.3364760524736976
Validation loss: 2.946597805063062

Epoch: 6| Step: 4
Training loss: 3.490449955307042
Validation loss: 2.9484253140200356

Epoch: 6| Step: 5
Training loss: 3.657118082920528
Validation loss: 2.94869636745082

Epoch: 6| Step: 6
Training loss: 3.3349673716537493
Validation loss: 2.944300128771599

Epoch: 6| Step: 7
Training loss: 2.6388849247238992
Validation loss: 2.9434159418624164

Epoch: 6| Step: 8
Training loss: 3.5914376158523997
Validation loss: 2.9417586010493455

Epoch: 6| Step: 9
Training loss: 2.4542939140694178
Validation loss: 2.9429146219107736

Epoch: 6| Step: 10
Training loss: 2.8891518628012833
Validation loss: 2.9416956178326448

Epoch: 6| Step: 11
Training loss: 2.92258726200196
Validation loss: 2.941135639556308

Epoch: 6| Step: 12
Training loss: 3.772987481050729
Validation loss: 2.9412864799362755

Epoch: 6| Step: 13
Training loss: 2.5754087993964743
Validation loss: 2.9403745349143375

Epoch: 139| Step: 0
Training loss: 3.7768233689347768
Validation loss: 2.939603849386962

Epoch: 6| Step: 1
Training loss: 3.4379668872385936
Validation loss: 2.9406577099415454

Epoch: 6| Step: 2
Training loss: 3.1179956903825476
Validation loss: 2.93909625142803

Epoch: 6| Step: 3
Training loss: 2.970380154821964
Validation loss: 2.9390126106031773

Epoch: 6| Step: 4
Training loss: 2.9186334427426313
Validation loss: 2.9410967305899542

Epoch: 6| Step: 5
Training loss: 3.1213372700093487
Validation loss: 2.9441369926736094

Epoch: 6| Step: 6
Training loss: 3.2420195386651995
Validation loss: 2.9388889344599836

Epoch: 6| Step: 7
Training loss: 2.591114681702006
Validation loss: 2.942321519024146

Epoch: 6| Step: 8
Training loss: 2.7967305918659746
Validation loss: 2.9436764092390337

Epoch: 6| Step: 9
Training loss: 3.1070170447523835
Validation loss: 2.9385810857752985

Epoch: 6| Step: 10
Training loss: 3.4396692540608527
Validation loss: 2.9377192745086167

Epoch: 6| Step: 11
Training loss: 3.688787461869113
Validation loss: 2.9375211723226156

Epoch: 6| Step: 12
Training loss: 3.41762191320602
Validation loss: 2.9341257806659016

Epoch: 6| Step: 13
Training loss: 3.3990065525729123
Validation loss: 2.933214799475433

Epoch: 140| Step: 0
Training loss: 3.191618110413545
Validation loss: 2.9345142635357155

Epoch: 6| Step: 1
Training loss: 3.215552955168849
Validation loss: 2.931515936487067

Epoch: 6| Step: 2
Training loss: 3.6434697509615575
Validation loss: 2.9269751161386512

Epoch: 6| Step: 3
Training loss: 3.365622597129481
Validation loss: 2.925852286394302

Epoch: 6| Step: 4
Training loss: 2.912837775949183
Validation loss: 2.9284430057965873

Epoch: 6| Step: 5
Training loss: 3.628219753082792
Validation loss: 2.9295314488569253

Epoch: 6| Step: 6
Training loss: 2.8700593706961537
Validation loss: 2.929555045028843

Epoch: 6| Step: 7
Training loss: 3.2708808911666623
Validation loss: 2.936269478398449

Epoch: 6| Step: 8
Training loss: 3.7245611098652422
Validation loss: 2.9348723266881938

Epoch: 6| Step: 9
Training loss: 3.5342466079772272
Validation loss: 2.9367017514466984

Epoch: 6| Step: 10
Training loss: 2.87371366168423
Validation loss: 2.9323753211381876

Epoch: 6| Step: 11
Training loss: 1.9197841528919517
Validation loss: 2.927401811772089

Epoch: 6| Step: 12
Training loss: 2.685461468812404
Validation loss: 2.9222698461449954

Epoch: 6| Step: 13
Training loss: 4.113950785370813
Validation loss: 2.9226685738782243

Epoch: 141| Step: 0
Training loss: 3.5207651496620316
Validation loss: 2.9236704528422597

Epoch: 6| Step: 1
Training loss: 3.3256501501516382
Validation loss: 2.923319924063366

Epoch: 6| Step: 2
Training loss: 3.908681860202662
Validation loss: 2.9273142654384907

Epoch: 6| Step: 3
Training loss: 2.849402877092224
Validation loss: 2.9214951594749556

Epoch: 6| Step: 4
Training loss: 2.6720920050765
Validation loss: 2.9249752018735125

Epoch: 6| Step: 5
Training loss: 2.588909458202387
Validation loss: 2.9259081140138745

Epoch: 6| Step: 6
Training loss: 3.0069231576339837
Validation loss: 2.925362132411476

Epoch: 6| Step: 7
Training loss: 2.8901008749387587
Validation loss: 2.924973172854557

Epoch: 6| Step: 8
Training loss: 3.4297225359471843
Validation loss: 2.9225886023355896

Epoch: 6| Step: 9
Training loss: 3.3337037516455106
Validation loss: 2.92343764858647

Epoch: 6| Step: 10
Training loss: 3.82448657211438
Validation loss: 2.923613959913261

Epoch: 6| Step: 11
Training loss: 3.3099219888673654
Validation loss: 2.923485117999158

Epoch: 6| Step: 12
Training loss: 3.3147129368374717
Validation loss: 2.920355387120891

Epoch: 6| Step: 13
Training loss: 2.0612849500109394
Validation loss: 2.922088285361587

Epoch: 142| Step: 0
Training loss: 3.594618982489307
Validation loss: 2.922782688085819

Epoch: 6| Step: 1
Training loss: 3.791779289389529
Validation loss: 2.920697015834068

Epoch: 6| Step: 2
Training loss: 3.4783729211235763
Validation loss: 2.917362733630295

Epoch: 6| Step: 3
Training loss: 3.65128713409336
Validation loss: 2.9182606315930797

Epoch: 6| Step: 4
Training loss: 2.668552139416142
Validation loss: 2.917195894127853

Epoch: 6| Step: 5
Training loss: 3.615753746542987
Validation loss: 2.9189956566227946

Epoch: 6| Step: 6
Training loss: 1.7232295529065471
Validation loss: 2.9166304086520505

Epoch: 6| Step: 7
Training loss: 3.200173111047874
Validation loss: 2.914021754186846

Epoch: 6| Step: 8
Training loss: 3.5135267990043535
Validation loss: 2.9122087102091205

Epoch: 6| Step: 9
Training loss: 3.1187275306641427
Validation loss: 2.9137438044195316

Epoch: 6| Step: 10
Training loss: 2.475036150735728
Validation loss: 2.9163428172201

Epoch: 6| Step: 11
Training loss: 3.094341028959707
Validation loss: 2.9140554901595617

Epoch: 6| Step: 12
Training loss: 2.808251117291428
Validation loss: 2.9111672820464425

Epoch: 6| Step: 13
Training loss: 3.674715672088239
Validation loss: 2.9108643038155257

Epoch: 143| Step: 0
Training loss: 3.1385867968400727
Validation loss: 2.9107411138989168

Epoch: 6| Step: 1
Training loss: 3.1233387918604403
Validation loss: 2.9097210350748512

Epoch: 6| Step: 2
Training loss: 3.1674741083666103
Validation loss: 2.911486542305838

Epoch: 6| Step: 3
Training loss: 3.7826560692820808
Validation loss: 2.9137509839394955

Epoch: 6| Step: 4
Training loss: 2.7094259747876492
Validation loss: 2.90810229141254

Epoch: 6| Step: 5
Training loss: 2.762472651419613
Validation loss: 2.9076222022772247

Epoch: 6| Step: 6
Training loss: 3.191433443025978
Validation loss: 2.910803582315409

Epoch: 6| Step: 7
Training loss: 2.8021733908852693
Validation loss: 2.9117112184276115

Epoch: 6| Step: 8
Training loss: 2.858707704485553
Validation loss: 2.90848285149556

Epoch: 6| Step: 9
Training loss: 4.059112310095851
Validation loss: 2.9121502382440587

Epoch: 6| Step: 10
Training loss: 3.0731804341190014
Validation loss: 2.910902790788278

Epoch: 6| Step: 11
Training loss: 3.1890461481582557
Validation loss: 2.9128317383342046

Epoch: 6| Step: 12
Training loss: 3.460932815583032
Validation loss: 2.91003517966612

Epoch: 6| Step: 13
Training loss: 3.1296861226711585
Validation loss: 2.9104929056819184

Epoch: 144| Step: 0
Training loss: 2.972610533434188
Validation loss: 2.908097263040989

Epoch: 6| Step: 1
Training loss: 2.9901600634748964
Validation loss: 2.90980189593339

Epoch: 6| Step: 2
Training loss: 3.4419979838088857
Validation loss: 2.9099382401302765

Epoch: 6| Step: 3
Training loss: 2.211208798643016
Validation loss: 2.9092376327261156

Epoch: 6| Step: 4
Training loss: 3.153313658923764
Validation loss: 2.9092243053205626

Epoch: 6| Step: 5
Training loss: 3.970753561995211
Validation loss: 2.908167615374947

Epoch: 6| Step: 6
Training loss: 3.9967634696998333
Validation loss: 2.9067151247328646

Epoch: 6| Step: 7
Training loss: 3.479268390439985
Validation loss: 2.9070440718820865

Epoch: 6| Step: 8
Training loss: 2.9874422778055836
Validation loss: 2.9090854354799447

Epoch: 6| Step: 9
Training loss: 3.5372916332115834
Validation loss: 2.908391747518449

Epoch: 6| Step: 10
Training loss: 3.3562414414280717
Validation loss: 2.9099987189180108

Epoch: 6| Step: 11
Training loss: 2.7609424498189306
Validation loss: 2.9065058579357093

Epoch: 6| Step: 12
Training loss: 2.4064637126394084
Validation loss: 2.9072944368948184

Epoch: 6| Step: 13
Training loss: 2.886472286290219
Validation loss: 2.907842536083419

Epoch: 145| Step: 0
Training loss: 2.9934993885881354
Validation loss: 2.906675226702828

Epoch: 6| Step: 1
Training loss: 3.0705918823170664
Validation loss: 2.90950561306384

Epoch: 6| Step: 2
Training loss: 3.75069777036866
Validation loss: 2.908506146866541

Epoch: 6| Step: 3
Training loss: 3.2009076142640716
Validation loss: 2.9100748757013966

Epoch: 6| Step: 4
Training loss: 3.1618406430165096
Validation loss: 2.912412169130887

Epoch: 6| Step: 5
Training loss: 3.709653098038695
Validation loss: 2.9200944145571763

Epoch: 6| Step: 6
Training loss: 3.3092275325493437
Validation loss: 2.922851802826096

Epoch: 6| Step: 7
Training loss: 2.9008680162673266
Validation loss: 2.92492039595561

Epoch: 6| Step: 8
Training loss: 3.5654060156106127
Validation loss: 2.9177738836326754

Epoch: 6| Step: 9
Training loss: 2.9135889072473096
Validation loss: 2.917497407295359

Epoch: 6| Step: 10
Training loss: 2.991021070890138
Validation loss: 2.910509819272174

Epoch: 6| Step: 11
Training loss: 3.361344013254141
Validation loss: 2.9061241074119133

Epoch: 6| Step: 12
Training loss: 2.3627989726139105
Validation loss: 2.9050112441833726

Epoch: 6| Step: 13
Training loss: 3.2709610705530023
Validation loss: 2.904365838245228

Epoch: 146| Step: 0
Training loss: 3.721704799754558
Validation loss: 2.904668017735343

Epoch: 6| Step: 1
Training loss: 3.1141157192615148
Validation loss: 2.905684597074991

Epoch: 6| Step: 2
Training loss: 2.675830077679496
Validation loss: 2.9031545963578194

Epoch: 6| Step: 3
Training loss: 3.5399486788030656
Validation loss: 2.9030876672004653

Epoch: 6| Step: 4
Training loss: 3.8561335862948996
Validation loss: 2.90361028504469

Epoch: 6| Step: 5
Training loss: 2.7474521625161996
Validation loss: 2.9028937871737712

Epoch: 6| Step: 6
Training loss: 2.891492723698888
Validation loss: 2.9017439369422564

Epoch: 6| Step: 7
Training loss: 3.2456465687394127
Validation loss: 2.903174434968482

Epoch: 6| Step: 8
Training loss: 2.6423395673687033
Validation loss: 2.904728837487973

Epoch: 6| Step: 9
Training loss: 3.2266279680385246
Validation loss: 2.900958019454349

Epoch: 6| Step: 10
Training loss: 2.9480797999954333
Validation loss: 2.902524506444775

Epoch: 6| Step: 11
Training loss: 3.435605168457976
Validation loss: 2.9027350238202163

Epoch: 6| Step: 12
Training loss: 2.810141952431614
Validation loss: 2.9012425958178483

Epoch: 6| Step: 13
Training loss: 3.8091368302705577
Validation loss: 2.9018551670522306

Epoch: 147| Step: 0
Training loss: 3.970014956275575
Validation loss: 2.901389720914554

Epoch: 6| Step: 1
Training loss: 3.022695682018981
Validation loss: 2.902408034105543

Epoch: 6| Step: 2
Training loss: 3.224541204183632
Validation loss: 2.905575211141752

Epoch: 6| Step: 3
Training loss: 2.495331410507751
Validation loss: 2.906033893709568

Epoch: 6| Step: 4
Training loss: 4.0033950702651175
Validation loss: 2.9149407238944467

Epoch: 6| Step: 5
Training loss: 3.4966381821201
Validation loss: 2.917882339575912

Epoch: 6| Step: 6
Training loss: 3.3115615955022886
Validation loss: 2.9196395065287026

Epoch: 6| Step: 7
Training loss: 3.136573417593645
Validation loss: 2.907838835880791

Epoch: 6| Step: 8
Training loss: 3.166881821668139
Validation loss: 2.909323750051531

Epoch: 6| Step: 9
Training loss: 3.050130659963058
Validation loss: 2.902321584823344

Epoch: 6| Step: 10
Training loss: 2.736795193592524
Validation loss: 2.901983540816705

Epoch: 6| Step: 11
Training loss: 2.2808317036100823
Validation loss: 2.8983090363962734

Epoch: 6| Step: 12
Training loss: 3.1572523885910155
Validation loss: 2.903023306302904

Epoch: 6| Step: 13
Training loss: 3.1636914447744835
Validation loss: 2.8978131088857584

Epoch: 148| Step: 0
Training loss: 3.5797244832240174
Validation loss: 2.8970869857465775

Epoch: 6| Step: 1
Training loss: 3.44108172996371
Validation loss: 2.8973656052602537

Epoch: 6| Step: 2
Training loss: 3.2443678544931607
Validation loss: 2.8969705372656414

Epoch: 6| Step: 3
Training loss: 3.5088123009684824
Validation loss: 2.89530617309734

Epoch: 6| Step: 4
Training loss: 2.7205381103774062
Validation loss: 2.8980754943207407

Epoch: 6| Step: 5
Training loss: 3.789545968269798
Validation loss: 2.895990174611965

Epoch: 6| Step: 6
Training loss: 2.9245792053631208
Validation loss: 2.8970949941066295

Epoch: 6| Step: 7
Training loss: 3.3320509987141893
Validation loss: 2.897216541481337

Epoch: 6| Step: 8
Training loss: 3.5835274636371355
Validation loss: 2.8951018188476065

Epoch: 6| Step: 9
Training loss: 2.189309162235686
Validation loss: 2.8962040915630287

Epoch: 6| Step: 10
Training loss: 3.158171418266165
Validation loss: 2.8950267780152315

Epoch: 6| Step: 11
Training loss: 2.6780587187035265
Validation loss: 2.8939583965331517

Epoch: 6| Step: 12
Training loss: 3.169525027627458
Validation loss: 2.8946924595227856

Epoch: 6| Step: 13
Training loss: 2.7739717210787282
Validation loss: 2.8952450748275704

Epoch: 149| Step: 0
Training loss: 3.0843344085712374
Validation loss: 2.8945487058975417

Epoch: 6| Step: 1
Training loss: 2.842307259257921
Validation loss: 2.8930742604761868

Epoch: 6| Step: 2
Training loss: 2.51779962220816
Validation loss: 2.8960659765523777

Epoch: 6| Step: 3
Training loss: 3.5932579698839833
Validation loss: 2.8947312606984985

Epoch: 6| Step: 4
Training loss: 4.070145206344907
Validation loss: 2.896683783545105

Epoch: 6| Step: 5
Training loss: 3.1605165556727655
Validation loss: 2.8938584060684636

Epoch: 6| Step: 6
Training loss: 3.147310495405909
Validation loss: 2.8960969199576843

Epoch: 6| Step: 7
Training loss: 2.844352574487411
Validation loss: 2.8980260500076676

Epoch: 6| Step: 8
Training loss: 2.3470313943291847
Validation loss: 2.900178376377753

Epoch: 6| Step: 9
Training loss: 3.376478930793553
Validation loss: 2.8993696633097708

Epoch: 6| Step: 10
Training loss: 3.225484524783323
Validation loss: 2.8972226930445775

Epoch: 6| Step: 11
Training loss: 3.625421696831749
Validation loss: 2.8976913980898393

Epoch: 6| Step: 12
Training loss: 2.999540293757854
Validation loss: 2.8958185023945138

Epoch: 6| Step: 13
Training loss: 3.558957530416471
Validation loss: 2.8923347771104835

Epoch: 150| Step: 0
Training loss: 3.426029418168752
Validation loss: 2.89185832994502

Epoch: 6| Step: 1
Training loss: 3.009017267088252
Validation loss: 2.892139069995833

Epoch: 6| Step: 2
Training loss: 3.009774180207666
Validation loss: 2.891861383059205

Epoch: 6| Step: 3
Training loss: 3.27515098864359
Validation loss: 2.891692769026557

Epoch: 6| Step: 4
Training loss: 3.4185858817868455
Validation loss: 2.8912920518369276

Epoch: 6| Step: 5
Training loss: 3.2422761836045124
Validation loss: 2.8919951726054243

Epoch: 6| Step: 6
Training loss: 3.226990456637045
Validation loss: 2.892684290801879

Epoch: 6| Step: 7
Training loss: 3.3569956315290286
Validation loss: 2.8922074278781285

Epoch: 6| Step: 8
Training loss: 3.568120705192201
Validation loss: 2.8937007350320907

Epoch: 6| Step: 9
Training loss: 3.2031500094298044
Validation loss: 2.89202240987469

Epoch: 6| Step: 10
Training loss: 2.1388814466382744
Validation loss: 2.8909051734419204

Epoch: 6| Step: 11
Training loss: 2.608860536215824
Validation loss: 2.8923124683098194

Epoch: 6| Step: 12
Training loss: 3.098054915530639
Validation loss: 2.8907738910832275

Epoch: 6| Step: 13
Training loss: 4.147028509545645
Validation loss: 2.8888590279743136

Testing loss: 3.100304011679656
