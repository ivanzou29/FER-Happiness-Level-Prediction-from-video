Epoch: 1| Step: 0
Training loss: 4.213869571685791
Validation loss: 5.166842701614544

Epoch: 6| Step: 1
Training loss: 4.512909412384033
Validation loss: 5.162689516621251

Epoch: 6| Step: 2
Training loss: 6.06391716003418
Validation loss: 5.158294277806436

Epoch: 6| Step: 3
Training loss: 5.361604690551758
Validation loss: 5.153940328987696

Epoch: 6| Step: 4
Training loss: 4.3124775886535645
Validation loss: 5.149696503916094

Epoch: 6| Step: 5
Training loss: 5.8433732986450195
Validation loss: 5.145665132871238

Epoch: 6| Step: 6
Training loss: 4.850135326385498
Validation loss: 5.141131672807919

Epoch: 6| Step: 7
Training loss: 5.463613033294678
Validation loss: 5.136967551323675

Epoch: 6| Step: 8
Training loss: 3.9239912033081055
Validation loss: 5.132686497062765

Epoch: 6| Step: 9
Training loss: 5.2622880935668945
Validation loss: 5.128136650208504

Epoch: 6| Step: 10
Training loss: 4.820387840270996
Validation loss: 5.123677381905177

Epoch: 6| Step: 11
Training loss: 4.44097900390625
Validation loss: 5.1191323905862784

Epoch: 6| Step: 12
Training loss: 5.4264678955078125
Validation loss: 5.114115468917355

Epoch: 6| Step: 13
Training loss: 4.344907283782959
Validation loss: 5.108956152392972

Epoch: 2| Step: 0
Training loss: 4.764493942260742
Validation loss: 5.104045150100544

Epoch: 6| Step: 1
Training loss: 4.9357404708862305
Validation loss: 5.098481773048319

Epoch: 6| Step: 2
Training loss: 4.552284240722656
Validation loss: 5.092812066437096

Epoch: 6| Step: 3
Training loss: 4.872814178466797
Validation loss: 5.087468495932958

Epoch: 6| Step: 4
Training loss: 6.207590579986572
Validation loss: 5.081190939872496

Epoch: 6| Step: 5
Training loss: 4.321200847625732
Validation loss: 5.07490825140348

Epoch: 6| Step: 6
Training loss: 4.629949569702148
Validation loss: 5.068383611658568

Epoch: 6| Step: 7
Training loss: 6.12172269821167
Validation loss: 5.061691273925125

Epoch: 6| Step: 8
Training loss: 2.8471548557281494
Validation loss: 5.054780319172849

Epoch: 6| Step: 9
Training loss: 5.913690567016602
Validation loss: 5.0472961548836

Epoch: 6| Step: 10
Training loss: 4.37432336807251
Validation loss: 5.039888364012524

Epoch: 6| Step: 11
Training loss: 4.965789318084717
Validation loss: 5.03172424275388

Epoch: 6| Step: 12
Training loss: 3.9488461017608643
Validation loss: 5.023236592610677

Epoch: 6| Step: 13
Training loss: 6.112293720245361
Validation loss: 5.014313959306286

Epoch: 3| Step: 0
Training loss: 4.771928787231445
Validation loss: 5.0057753798782185

Epoch: 6| Step: 1
Training loss: 5.078363418579102
Validation loss: 4.99588962780532

Epoch: 6| Step: 2
Training loss: 3.8288121223449707
Validation loss: 4.98598575592041

Epoch: 6| Step: 3
Training loss: 4.200229167938232
Validation loss: 4.975522554048928

Epoch: 6| Step: 4
Training loss: 5.4345784187316895
Validation loss: 4.9655347921515025

Epoch: 6| Step: 5
Training loss: 5.788141250610352
Validation loss: 4.954828441783946

Epoch: 6| Step: 6
Training loss: 4.593300819396973
Validation loss: 4.943629572468419

Epoch: 6| Step: 7
Training loss: 4.699969291687012
Validation loss: 4.932504484730382

Epoch: 6| Step: 8
Training loss: 4.707491397857666
Validation loss: 4.920273750059066

Epoch: 6| Step: 9
Training loss: 4.851833343505859
Validation loss: 4.90887096364011

Epoch: 6| Step: 10
Training loss: 4.387752532958984
Validation loss: 4.895929295529601

Epoch: 6| Step: 11
Training loss: 4.734172821044922
Validation loss: 4.884232116001908

Epoch: 6| Step: 12
Training loss: 4.758445739746094
Validation loss: 4.8715179658705186

Epoch: 6| Step: 13
Training loss: 4.181430339813232
Validation loss: 4.858301321665446

Epoch: 4| Step: 0
Training loss: 4.627086639404297
Validation loss: 4.845372000048237

Epoch: 6| Step: 1
Training loss: 6.1369147300720215
Validation loss: 4.8328418911144295

Epoch: 6| Step: 2
Training loss: 3.4621174335479736
Validation loss: 4.818721802003922

Epoch: 6| Step: 3
Training loss: 4.854450225830078
Validation loss: 4.804640646903746

Epoch: 6| Step: 4
Training loss: 4.436540126800537
Validation loss: 4.791120477901992

Epoch: 6| Step: 5
Training loss: 3.8631749153137207
Validation loss: 4.776577052249704

Epoch: 6| Step: 6
Training loss: 5.208579063415527
Validation loss: 4.762268271497501

Epoch: 6| Step: 7
Training loss: 4.542914390563965
Validation loss: 4.747672686012843

Epoch: 6| Step: 8
Training loss: 4.145503044128418
Validation loss: 4.732483263938658

Epoch: 6| Step: 9
Training loss: 4.428987503051758
Validation loss: 4.716577832416822

Epoch: 6| Step: 10
Training loss: 5.165575981140137
Validation loss: 4.701994552407213

Epoch: 6| Step: 11
Training loss: 4.425278663635254
Validation loss: 4.685390605721422

Epoch: 6| Step: 12
Training loss: 4.618597984313965
Validation loss: 4.667997411502305

Epoch: 6| Step: 13
Training loss: 3.0347118377685547
Validation loss: 4.6506058990314445

Epoch: 5| Step: 0
Training loss: 4.843794345855713
Validation loss: 4.6321901711084505

Epoch: 6| Step: 1
Training loss: 4.6535139083862305
Validation loss: 4.614371422798403

Epoch: 6| Step: 2
Training loss: 3.5239765644073486
Validation loss: 4.594923357809743

Epoch: 6| Step: 3
Training loss: 4.30319356918335
Validation loss: 4.573740482330322

Epoch: 6| Step: 4
Training loss: 4.126758575439453
Validation loss: 4.552752033356698

Epoch: 6| Step: 5
Training loss: 4.599156379699707
Validation loss: 4.531726519266765

Epoch: 6| Step: 6
Training loss: 4.3707427978515625
Validation loss: 4.509785180450768

Epoch: 6| Step: 7
Training loss: 4.184690475463867
Validation loss: 4.486794107703752

Epoch: 6| Step: 8
Training loss: 4.409737586975098
Validation loss: 4.462545125715194

Epoch: 6| Step: 9
Training loss: 4.4993391036987305
Validation loss: 4.439777810086486

Epoch: 6| Step: 10
Training loss: 3.319413900375366
Validation loss: 4.41841261873963

Epoch: 6| Step: 11
Training loss: 3.756058692932129
Validation loss: 4.395362002875215

Epoch: 6| Step: 12
Training loss: 4.814477443695068
Validation loss: 4.374073572056268

Epoch: 6| Step: 13
Training loss: 5.0702667236328125
Validation loss: 4.354659690651842

Epoch: 6| Step: 0
Training loss: 3.943002700805664
Validation loss: 4.332249728582239

Epoch: 6| Step: 1
Training loss: 4.217219829559326
Validation loss: 4.311328257283857

Epoch: 6| Step: 2
Training loss: 5.112070560455322
Validation loss: 4.290563485955679

Epoch: 6| Step: 3
Training loss: 3.25172758102417
Validation loss: 4.2708301698007896

Epoch: 6| Step: 4
Training loss: 5.433136463165283
Validation loss: 4.251230111686132

Epoch: 6| Step: 5
Training loss: 3.6990466117858887
Validation loss: 4.230049146118985

Epoch: 6| Step: 6
Training loss: 3.354745864868164
Validation loss: 4.212521271039081

Epoch: 6| Step: 7
Training loss: 2.9400267601013184
Validation loss: 4.19402959269862

Epoch: 6| Step: 8
Training loss: 5.377643585205078
Validation loss: 4.176711892568937

Epoch: 6| Step: 9
Training loss: 3.658494710922241
Validation loss: 4.1582024815262

Epoch: 6| Step: 10
Training loss: 2.8019120693206787
Validation loss: 4.1436774474318305

Epoch: 6| Step: 11
Training loss: 3.165259599685669
Validation loss: 4.127321889323573

Epoch: 6| Step: 12
Training loss: 4.977447509765625
Validation loss: 4.1137058145256455

Epoch: 6| Step: 13
Training loss: 4.827081203460693
Validation loss: 4.099779211064821

Epoch: 7| Step: 0
Training loss: 3.3559882640838623
Validation loss: 4.08566100623018

Epoch: 6| Step: 1
Training loss: 3.673267364501953
Validation loss: 4.0722519095226

Epoch: 6| Step: 2
Training loss: 4.723994255065918
Validation loss: 4.061098849901589

Epoch: 6| Step: 3
Training loss: 4.040288925170898
Validation loss: 4.049188075527068

Epoch: 6| Step: 4
Training loss: 4.750569820404053
Validation loss: 4.037877426352552

Epoch: 6| Step: 5
Training loss: 4.783185958862305
Validation loss: 4.026406283019691

Epoch: 6| Step: 6
Training loss: 3.2952356338500977
Validation loss: 4.015858750189504

Epoch: 6| Step: 7
Training loss: 3.7473602294921875
Validation loss: 4.007120716956354

Epoch: 6| Step: 8
Training loss: 3.3697075843811035
Validation loss: 3.995619320100354

Epoch: 6| Step: 9
Training loss: 2.388352870941162
Validation loss: 3.9858209215184695

Epoch: 6| Step: 10
Training loss: 3.2557761669158936
Validation loss: 3.977667162495275

Epoch: 6| Step: 11
Training loss: 3.7590723037719727
Validation loss: 3.970196052264142

Epoch: 6| Step: 12
Training loss: 4.481601715087891
Validation loss: 3.9605573684938493

Epoch: 6| Step: 13
Training loss: 4.868937969207764
Validation loss: 3.95140064659939

Epoch: 8| Step: 0
Training loss: 3.178086996078491
Validation loss: 3.9420787852297545

Epoch: 6| Step: 1
Training loss: 3.1523513793945312
Validation loss: 3.9335498091995076

Epoch: 6| Step: 2
Training loss: 3.588528871536255
Validation loss: 3.9238758907523206

Epoch: 6| Step: 3
Training loss: 4.172435283660889
Validation loss: 3.9130250869258756

Epoch: 6| Step: 4
Training loss: 3.158522844314575
Validation loss: 3.902780996855869

Epoch: 6| Step: 5
Training loss: 3.25972318649292
Validation loss: 3.892748345610916

Epoch: 6| Step: 6
Training loss: 3.9288830757141113
Validation loss: 3.884153794216853

Epoch: 6| Step: 7
Training loss: 4.371959686279297
Validation loss: 3.8723145813070317

Epoch: 6| Step: 8
Training loss: 3.575181245803833
Validation loss: 3.8640586201862623

Epoch: 6| Step: 9
Training loss: 4.707819938659668
Validation loss: 3.8522388781270673

Epoch: 6| Step: 10
Training loss: 3.8818247318267822
Validation loss: 3.844348035832887

Epoch: 6| Step: 11
Training loss: 4.042362213134766
Validation loss: 3.8311060782401793

Epoch: 6| Step: 12
Training loss: 4.505744934082031
Validation loss: 3.8211218695486746

Epoch: 6| Step: 13
Training loss: 2.3042097091674805
Validation loss: 3.8085852720404185

Epoch: 9| Step: 0
Training loss: 3.5348684787750244
Validation loss: 3.798025467062509

Epoch: 6| Step: 1
Training loss: 4.091418743133545
Validation loss: 3.7875625753915436

Epoch: 6| Step: 2
Training loss: 3.7847378253936768
Validation loss: 3.7798237185324393

Epoch: 6| Step: 3
Training loss: 3.613469123840332
Validation loss: 3.7706621769935853

Epoch: 6| Step: 4
Training loss: 4.2307233810424805
Validation loss: 3.7603622764669438

Epoch: 6| Step: 5
Training loss: 3.534759283065796
Validation loss: 3.7536444048727713

Epoch: 6| Step: 6
Training loss: 4.243294715881348
Validation loss: 3.7457738640487834

Epoch: 6| Step: 7
Training loss: 3.0514519214630127
Validation loss: 3.738134886628838

Epoch: 6| Step: 8
Training loss: 4.224232196807861
Validation loss: 3.730436178945726

Epoch: 6| Step: 9
Training loss: 3.201427698135376
Validation loss: 3.724382656876759

Epoch: 6| Step: 10
Training loss: 3.3661856651306152
Validation loss: 3.71541860026698

Epoch: 6| Step: 11
Training loss: 3.4993016719818115
Validation loss: 3.7108260816143406

Epoch: 6| Step: 12
Training loss: 3.6719274520874023
Validation loss: 3.7047450234813075

Epoch: 6| Step: 13
Training loss: 2.3620760440826416
Validation loss: 3.6973855136543192

Epoch: 10| Step: 0
Training loss: 3.0742149353027344
Validation loss: 3.69289130549277

Epoch: 6| Step: 1
Training loss: 3.071925401687622
Validation loss: 3.687472612627091

Epoch: 6| Step: 2
Training loss: 3.5126466751098633
Validation loss: 3.6802208756887786

Epoch: 6| Step: 3
Training loss: 3.2021267414093018
Validation loss: 3.677545693612868

Epoch: 6| Step: 4
Training loss: 3.2162680625915527
Validation loss: 3.6720417238050893

Epoch: 6| Step: 5
Training loss: 4.746114730834961
Validation loss: 3.664556457150367

Epoch: 6| Step: 6
Training loss: 3.8559911251068115
Validation loss: 3.6582342783610025

Epoch: 6| Step: 7
Training loss: 2.6168034076690674
Validation loss: 3.650509480507143

Epoch: 6| Step: 8
Training loss: 3.8269617557525635
Validation loss: 3.6473756913215882

Epoch: 6| Step: 9
Training loss: 2.6959924697875977
Validation loss: 3.643882110554685

Epoch: 6| Step: 10
Training loss: 3.466491222381592
Validation loss: 3.6379794818098827

Epoch: 6| Step: 11
Training loss: 3.7347025871276855
Validation loss: 3.630753306932347

Epoch: 6| Step: 12
Training loss: 4.5307111740112305
Validation loss: 3.623017849460725

Epoch: 6| Step: 13
Training loss: 4.940154075622559
Validation loss: 3.618703942145071

Epoch: 11| Step: 0
Training loss: 3.355504274368286
Validation loss: 3.611739607267482

Epoch: 6| Step: 1
Training loss: 2.4710021018981934
Validation loss: 3.6075551843130462

Epoch: 6| Step: 2
Training loss: 3.294605016708374
Validation loss: 3.6031074216288905

Epoch: 6| Step: 3
Training loss: 3.380985736846924
Validation loss: 3.600779712841075

Epoch: 6| Step: 4
Training loss: 4.556430339813232
Validation loss: 3.597202049788608

Epoch: 6| Step: 5
Training loss: 4.5360612869262695
Validation loss: 3.5938902875428558

Epoch: 6| Step: 6
Training loss: 2.999410390853882
Validation loss: 3.5883666084658716

Epoch: 6| Step: 7
Training loss: 3.0966451168060303
Validation loss: 3.581485527817921

Epoch: 6| Step: 8
Training loss: 2.3662424087524414
Validation loss: 3.5790310649461645

Epoch: 6| Step: 9
Training loss: 2.877617120742798
Validation loss: 3.575120915648758

Epoch: 6| Step: 10
Training loss: 4.434327125549316
Validation loss: 3.5713314292251424

Epoch: 6| Step: 11
Training loss: 4.214239120483398
Validation loss: 3.5680606954841205

Epoch: 6| Step: 12
Training loss: 4.348929405212402
Validation loss: 3.5635298375160462

Epoch: 6| Step: 13
Training loss: 2.84118390083313
Validation loss: 3.557379748231621

Epoch: 12| Step: 0
Training loss: 4.231411933898926
Validation loss: 3.55665187938239

Epoch: 6| Step: 1
Training loss: 2.7690951824188232
Validation loss: 3.553070024777484

Epoch: 6| Step: 2
Training loss: 4.3014116287231445
Validation loss: 3.55301252231803

Epoch: 6| Step: 3
Training loss: 3.9221436977386475
Validation loss: 3.548432716759302

Epoch: 6| Step: 4
Training loss: 3.32537841796875
Validation loss: 3.544227502679312

Epoch: 6| Step: 5
Training loss: 3.160177230834961
Validation loss: 3.540404014689948

Epoch: 6| Step: 6
Training loss: 3.9449758529663086
Validation loss: 3.53641918910447

Epoch: 6| Step: 7
Training loss: 2.3998358249664307
Validation loss: 3.5349191952777166

Epoch: 6| Step: 8
Training loss: 2.9237446784973145
Validation loss: 3.53255122195008

Epoch: 6| Step: 9
Training loss: 2.379117012023926
Validation loss: 3.5278327721421436

Epoch: 6| Step: 10
Training loss: 4.22920036315918
Validation loss: 3.5274327903665523

Epoch: 6| Step: 11
Training loss: 3.6882057189941406
Validation loss: 3.523001855419528

Epoch: 6| Step: 12
Training loss: 4.118596076965332
Validation loss: 3.518192557878392

Epoch: 6| Step: 13
Training loss: 2.79787540435791
Validation loss: 3.514783554179694

Epoch: 13| Step: 0
Training loss: 3.0909619331359863
Validation loss: 3.5141112701867216

Epoch: 6| Step: 1
Training loss: 4.43651008605957
Validation loss: 3.511174722384381

Epoch: 6| Step: 2
Training loss: 4.632021903991699
Validation loss: 3.5073852282698437

Epoch: 6| Step: 3
Training loss: 3.0558388233184814
Validation loss: 3.506234963734945

Epoch: 6| Step: 4
Training loss: 2.436248302459717
Validation loss: 3.5023041335485314

Epoch: 6| Step: 5
Training loss: 2.8057210445404053
Validation loss: 3.5006184936851583

Epoch: 6| Step: 6
Training loss: 3.2898077964782715
Validation loss: 3.496007950075211

Epoch: 6| Step: 7
Training loss: 3.25569486618042
Validation loss: 3.4910430395475

Epoch: 6| Step: 8
Training loss: 3.1098289489746094
Validation loss: 3.4876695089442755

Epoch: 6| Step: 9
Training loss: 3.6783344745635986
Validation loss: 3.488779837085355

Epoch: 6| Step: 10
Training loss: 4.059569358825684
Validation loss: 3.483062133994154

Epoch: 6| Step: 11
Training loss: 4.038660049438477
Validation loss: 3.4810931016040105

Epoch: 6| Step: 12
Training loss: 3.10587215423584
Validation loss: 3.476005369617093

Epoch: 6| Step: 13
Training loss: 2.6861696243286133
Validation loss: 3.4718557865388933

Epoch: 14| Step: 0
Training loss: 3.3740382194519043
Validation loss: 3.4614250377942155

Epoch: 6| Step: 1
Training loss: 3.5620622634887695
Validation loss: 3.456251851973995

Epoch: 6| Step: 2
Training loss: 2.9956793785095215
Validation loss: 3.451069877993676

Epoch: 6| Step: 3
Training loss: 2.672365188598633
Validation loss: 3.445522541640907

Epoch: 6| Step: 4
Training loss: 3.974726915359497
Validation loss: 3.447537447816582

Epoch: 6| Step: 5
Training loss: 4.027755260467529
Validation loss: 3.4462293245459117

Epoch: 6| Step: 6
Training loss: 3.7486021518707275
Validation loss: 3.440224483448972

Epoch: 6| Step: 7
Training loss: 4.7244062423706055
Validation loss: 3.439120169608824

Epoch: 6| Step: 8
Training loss: 2.8880674839019775
Validation loss: 3.4389033548293577

Epoch: 6| Step: 9
Training loss: 2.1543383598327637
Validation loss: 3.434838274473785

Epoch: 6| Step: 10
Training loss: 3.7406818866729736
Validation loss: 3.431266984631938

Epoch: 6| Step: 11
Training loss: 3.4975099563598633
Validation loss: 3.4295130904002855

Epoch: 6| Step: 12
Training loss: 2.517826795578003
Validation loss: 3.4255752845477034

Epoch: 6| Step: 13
Training loss: 3.6120409965515137
Validation loss: 3.4258887511427685

Epoch: 15| Step: 0
Training loss: 3.9445583820343018
Validation loss: 3.420264208188621

Epoch: 6| Step: 1
Training loss: 3.3443737030029297
Validation loss: 3.417923955507176

Epoch: 6| Step: 2
Training loss: 3.456841468811035
Validation loss: 3.4159453940647904

Epoch: 6| Step: 3
Training loss: 3.3926358222961426
Validation loss: 3.415059971553023

Epoch: 6| Step: 4
Training loss: 3.4754652976989746
Validation loss: 3.4115604200670795

Epoch: 6| Step: 5
Training loss: 2.786269187927246
Validation loss: 3.409116801395211

Epoch: 6| Step: 6
Training loss: 4.047004699707031
Validation loss: 3.406776379513484

Epoch: 6| Step: 7
Training loss: 3.0935826301574707
Validation loss: 3.405773111568984

Epoch: 6| Step: 8
Training loss: 2.7761268615722656
Validation loss: 3.40012792874408

Epoch: 6| Step: 9
Training loss: 3.443384885787964
Validation loss: 3.400312731342931

Epoch: 6| Step: 10
Training loss: 3.308044910430908
Validation loss: 3.3950470647504254

Epoch: 6| Step: 11
Training loss: 2.795542001724243
Validation loss: 3.395593527824648

Epoch: 6| Step: 12
Training loss: 3.072740316390991
Validation loss: 3.3890039690079226

Epoch: 6| Step: 13
Training loss: 4.597610950469971
Validation loss: 3.386827907254619

Epoch: 16| Step: 0
Training loss: 3.7301783561706543
Validation loss: 3.385684715804233

Epoch: 6| Step: 1
Training loss: 4.470644950866699
Validation loss: 3.384537563529066

Epoch: 6| Step: 2
Training loss: 3.1297006607055664
Validation loss: 3.3824297894713697

Epoch: 6| Step: 3
Training loss: 3.4271652698516846
Validation loss: 3.3782439411327405

Epoch: 6| Step: 4
Training loss: 4.001446723937988
Validation loss: 3.3781188380333687

Epoch: 6| Step: 5
Training loss: 3.120683193206787
Validation loss: 3.3742632353177635

Epoch: 6| Step: 6
Training loss: 3.337660551071167
Validation loss: 3.372185335364393

Epoch: 6| Step: 7
Training loss: 3.2947545051574707
Validation loss: 3.3771095147696872

Epoch: 6| Step: 8
Training loss: 3.583282470703125
Validation loss: 3.375993041582005

Epoch: 6| Step: 9
Training loss: 3.200831890106201
Validation loss: 3.3736063485504477

Epoch: 6| Step: 10
Training loss: 3.4877676963806152
Validation loss: 3.3650320294082805

Epoch: 6| Step: 11
Training loss: 3.015246629714966
Validation loss: 3.364489152867307

Epoch: 6| Step: 12
Training loss: 2.5004842281341553
Validation loss: 3.3597299334823445

Epoch: 6| Step: 13
Training loss: 1.5455327033996582
Validation loss: 3.359680132199359

Epoch: 17| Step: 0
Training loss: 4.054869651794434
Validation loss: 3.364035424365792

Epoch: 6| Step: 1
Training loss: 3.9841065406799316
Validation loss: 3.3622278039173414

Epoch: 6| Step: 2
Training loss: 3.913628339767456
Validation loss: 3.363277840357955

Epoch: 6| Step: 3
Training loss: 3.3661608695983887
Validation loss: 3.3577821946913198

Epoch: 6| Step: 4
Training loss: 3.2342140674591064
Validation loss: 3.3515883927704184

Epoch: 6| Step: 5
Training loss: 2.0060997009277344
Validation loss: 3.3480775587020384

Epoch: 6| Step: 6
Training loss: 2.816615581512451
Validation loss: 3.3474800766155286

Epoch: 6| Step: 7
Training loss: 1.912217617034912
Validation loss: 3.34936527539325

Epoch: 6| Step: 8
Training loss: 3.4805386066436768
Validation loss: 3.3480393527656473

Epoch: 6| Step: 9
Training loss: 4.196438789367676
Validation loss: 3.3470530407403105

Epoch: 6| Step: 10
Training loss: 2.691732883453369
Validation loss: 3.3398123582204184

Epoch: 6| Step: 11
Training loss: 4.066173553466797
Validation loss: 3.3414832956047467

Epoch: 6| Step: 12
Training loss: 3.0793566703796387
Validation loss: 3.3372361916367725

Epoch: 6| Step: 13
Training loss: 3.6724658012390137
Validation loss: 3.3358804487412974

Epoch: 18| Step: 0
Training loss: 3.3777754306793213
Validation loss: 3.337810675303141

Epoch: 6| Step: 1
Training loss: 3.1248950958251953
Validation loss: 3.3351122076793382

Epoch: 6| Step: 2
Training loss: 2.3486855030059814
Validation loss: 3.3338881461851058

Epoch: 6| Step: 3
Training loss: 3.018559694290161
Validation loss: 3.3345093291292907

Epoch: 6| Step: 4
Training loss: 3.3227059841156006
Validation loss: 3.328824427820021

Epoch: 6| Step: 5
Training loss: 3.4305505752563477
Validation loss: 3.32895323025283

Epoch: 6| Step: 6
Training loss: 3.758244037628174
Validation loss: 3.3283295733954317

Epoch: 6| Step: 7
Training loss: 3.570956230163574
Validation loss: 3.3231415440959315

Epoch: 6| Step: 8
Training loss: 4.174637317657471
Validation loss: 3.3277403359772055

Epoch: 6| Step: 9
Training loss: 3.4139444828033447
Validation loss: 3.328765610212921

Epoch: 6| Step: 10
Training loss: 2.801098108291626
Validation loss: 3.3286674971221597

Epoch: 6| Step: 11
Training loss: 4.024666786193848
Validation loss: 3.3249609752367904

Epoch: 6| Step: 12
Training loss: 2.7362289428710938
Validation loss: 3.3190934376050065

Epoch: 6| Step: 13
Training loss: 2.7519900798797607
Validation loss: 3.3169559842796734

Epoch: 19| Step: 0
Training loss: 3.3839569091796875
Validation loss: 3.3154136057822936

Epoch: 6| Step: 1
Training loss: 3.8015530109405518
Validation loss: 3.3152536038429505

Epoch: 6| Step: 2
Training loss: 3.4085443019866943
Validation loss: 3.3105868370302263

Epoch: 6| Step: 3
Training loss: 3.6903202533721924
Validation loss: 3.309699817370343

Epoch: 6| Step: 4
Training loss: 2.6875710487365723
Validation loss: 3.3129346498879055

Epoch: 6| Step: 5
Training loss: 3.2689313888549805
Validation loss: 3.309047786138391

Epoch: 6| Step: 6
Training loss: 2.5717267990112305
Validation loss: 3.304995629095262

Epoch: 6| Step: 7
Training loss: 3.501408576965332
Validation loss: 3.3051206783581804

Epoch: 6| Step: 8
Training loss: 3.3333935737609863
Validation loss: 3.30103906508415

Epoch: 6| Step: 9
Training loss: 2.7674827575683594
Validation loss: 3.3044003184123705

Epoch: 6| Step: 10
Training loss: 2.7354161739349365
Validation loss: 3.3017000203491538

Epoch: 6| Step: 11
Training loss: 3.634460926055908
Validation loss: 3.301634345003354

Epoch: 6| Step: 12
Training loss: 3.7287497520446777
Validation loss: 3.3002994855244956

Epoch: 6| Step: 13
Training loss: 3.422008752822876
Validation loss: 3.297259182058355

Epoch: 20| Step: 0
Training loss: 3.6233670711517334
Validation loss: 3.2932279391955306

Epoch: 6| Step: 1
Training loss: 3.529038906097412
Validation loss: 3.2927731237103863

Epoch: 6| Step: 2
Training loss: 3.6302928924560547
Validation loss: 3.2920376664848736

Epoch: 6| Step: 3
Training loss: 3.489041328430176
Validation loss: 3.2924230175633586

Epoch: 6| Step: 4
Training loss: 3.541882038116455
Validation loss: 3.2885803150874313

Epoch: 6| Step: 5
Training loss: 2.83113431930542
Validation loss: 3.2877471395718154

Epoch: 6| Step: 6
Training loss: 2.6849074363708496
Validation loss: 3.2883263070096254

Epoch: 6| Step: 7
Training loss: 2.9406890869140625
Validation loss: 3.2866335120252383

Epoch: 6| Step: 8
Training loss: 3.2351248264312744
Validation loss: 3.285120059085149

Epoch: 6| Step: 9
Training loss: 3.4020986557006836
Validation loss: 3.2805112100416616

Epoch: 6| Step: 10
Training loss: 3.603482246398926
Validation loss: 3.281335082105411

Epoch: 6| Step: 11
Training loss: 2.7491188049316406
Validation loss: 3.278212034574119

Epoch: 6| Step: 12
Training loss: 3.5441648960113525
Validation loss: 3.2787959088561354

Epoch: 6| Step: 13
Training loss: 2.5684151649475098
Validation loss: 3.276896966400967

Epoch: 21| Step: 0
Training loss: 3.7189908027648926
Validation loss: 3.2796921217313377

Epoch: 6| Step: 1
Training loss: 3.514974355697632
Validation loss: 3.278642931292134

Epoch: 6| Step: 2
Training loss: 3.6694226264953613
Validation loss: 3.27419465075257

Epoch: 6| Step: 3
Training loss: 3.2135369777679443
Validation loss: 3.2744811734845563

Epoch: 6| Step: 4
Training loss: 2.8600292205810547
Validation loss: 3.2725637830713743

Epoch: 6| Step: 5
Training loss: 2.7087156772613525
Validation loss: 3.2733073798559045

Epoch: 6| Step: 6
Training loss: 3.7358760833740234
Validation loss: 3.2711891384534937

Epoch: 6| Step: 7
Training loss: 3.6135380268096924
Validation loss: 3.2696692277026433

Epoch: 6| Step: 8
Training loss: 3.4360549449920654
Validation loss: 3.2707268627741004

Epoch: 6| Step: 9
Training loss: 2.5479936599731445
Validation loss: 3.2676752075072257

Epoch: 6| Step: 10
Training loss: 3.2326443195343018
Validation loss: 3.2687991716528453

Epoch: 6| Step: 11
Training loss: 3.2885520458221436
Validation loss: 3.263664004623249

Epoch: 6| Step: 12
Training loss: 2.8611245155334473
Validation loss: 3.262277503167429

Epoch: 6| Step: 13
Training loss: 2.996577262878418
Validation loss: 3.265506777712094

Epoch: 22| Step: 0
Training loss: 2.7024714946746826
Validation loss: 3.2610869356380996

Epoch: 6| Step: 1
Training loss: 3.8115615844726562
Validation loss: 3.2600611589288198

Epoch: 6| Step: 2
Training loss: 2.9390158653259277
Validation loss: 3.2561541988003637

Epoch: 6| Step: 3
Training loss: 3.511232852935791
Validation loss: 3.255249915584441

Epoch: 6| Step: 4
Training loss: 3.7713475227355957
Validation loss: 3.257676693700975

Epoch: 6| Step: 5
Training loss: 3.399303913116455
Validation loss: 3.253401110249181

Epoch: 6| Step: 6
Training loss: 3.539987087249756
Validation loss: 3.250101350968884

Epoch: 6| Step: 7
Training loss: 2.7518584728240967
Validation loss: 3.2513301808346986

Epoch: 6| Step: 8
Training loss: 2.2550108432769775
Validation loss: 3.2498232677418697

Epoch: 6| Step: 9
Training loss: 3.4729533195495605
Validation loss: 3.249080970723142

Epoch: 6| Step: 10
Training loss: 3.783158540725708
Validation loss: 3.2516931154394664

Epoch: 6| Step: 11
Training loss: 3.2279090881347656
Validation loss: 3.245579914380145

Epoch: 6| Step: 12
Training loss: 3.477647304534912
Validation loss: 3.239067851856191

Epoch: 6| Step: 13
Training loss: 2.241502285003662
Validation loss: 3.238431792105398

Epoch: 23| Step: 0
Training loss: 2.24947190284729
Validation loss: 3.2405754032955376

Epoch: 6| Step: 1
Training loss: 2.672661542892456
Validation loss: 3.239186066453175

Epoch: 6| Step: 2
Training loss: 3.0378904342651367
Validation loss: 3.2435196497107066

Epoch: 6| Step: 3
Training loss: 3.6608214378356934
Validation loss: 3.244687564911381

Epoch: 6| Step: 4
Training loss: 3.189220905303955
Validation loss: 3.2404354003167923

Epoch: 6| Step: 5
Training loss: 4.776582717895508
Validation loss: 3.239804349919801

Epoch: 6| Step: 6
Training loss: 3.007133960723877
Validation loss: 3.235539041539674

Epoch: 6| Step: 7
Training loss: 3.617091178894043
Validation loss: 3.234248661225842

Epoch: 6| Step: 8
Training loss: 3.3175950050354004
Validation loss: 3.233849597233598

Epoch: 6| Step: 9
Training loss: 3.1292014122009277
Validation loss: 3.2353912271479124

Epoch: 6| Step: 10
Training loss: 3.632134437561035
Validation loss: 3.238583880086099

Epoch: 6| Step: 11
Training loss: 3.3419923782348633
Validation loss: 3.2294348824408745

Epoch: 6| Step: 12
Training loss: 2.815537452697754
Validation loss: 3.2306837394673336

Epoch: 6| Step: 13
Training loss: 2.2704145908355713
Validation loss: 3.2275882844002015

Epoch: 24| Step: 0
Training loss: 3.7222304344177246
Validation loss: 3.2329661589796825

Epoch: 6| Step: 1
Training loss: 3.5458762645721436
Validation loss: 3.2473872400099233

Epoch: 6| Step: 2
Training loss: 4.020694732666016
Validation loss: 3.2258330032389653

Epoch: 6| Step: 3
Training loss: 2.369168758392334
Validation loss: 3.2169852666957404

Epoch: 6| Step: 4
Training loss: 2.7778239250183105
Validation loss: 3.2187889750285814

Epoch: 6| Step: 5
Training loss: 4.281603813171387
Validation loss: 3.2220443756349626

Epoch: 6| Step: 6
Training loss: 3.4802255630493164
Validation loss: 3.2187159907433296

Epoch: 6| Step: 7
Training loss: 2.9979496002197266
Validation loss: 3.216280693648964

Epoch: 6| Step: 8
Training loss: 2.7648415565490723
Validation loss: 3.2117482564782582

Epoch: 6| Step: 9
Training loss: 3.051677942276001
Validation loss: 3.2096544440074632

Epoch: 6| Step: 10
Training loss: 3.400542974472046
Validation loss: 3.2097135307968303

Epoch: 6| Step: 11
Training loss: 2.9689178466796875
Validation loss: 3.210767981826618

Epoch: 6| Step: 12
Training loss: 3.100207805633545
Validation loss: 3.214502731959025

Epoch: 6| Step: 13
Training loss: 1.915956974029541
Validation loss: 3.2148974736531577

Epoch: 25| Step: 0
Training loss: 2.6056084632873535
Validation loss: 3.21341710962275

Epoch: 6| Step: 1
Training loss: 3.519576072692871
Validation loss: 3.204350774006177

Epoch: 6| Step: 2
Training loss: 3.37677001953125
Validation loss: 3.1972587441885345

Epoch: 6| Step: 3
Training loss: 3.8747079372406006
Validation loss: 3.1974338716076267

Epoch: 6| Step: 4
Training loss: 3.653181314468384
Validation loss: 3.1992726633625646

Epoch: 6| Step: 5
Training loss: 3.4298417568206787
Validation loss: 3.200174136828351

Epoch: 6| Step: 6
Training loss: 3.2607522010803223
Validation loss: 3.1986615888534056

Epoch: 6| Step: 7
Training loss: 3.3700995445251465
Validation loss: 3.1979712183757494

Epoch: 6| Step: 8
Training loss: 2.7732138633728027
Validation loss: 3.198287497284592

Epoch: 6| Step: 9
Training loss: 2.646392345428467
Validation loss: 3.1961639312005814

Epoch: 6| Step: 10
Training loss: 3.456066131591797
Validation loss: 3.1959322191053823

Epoch: 6| Step: 11
Training loss: 2.760084629058838
Validation loss: 3.1959979482876357

Epoch: 6| Step: 12
Training loss: 3.0290069580078125
Validation loss: 3.197484247146114

Epoch: 6| Step: 13
Training loss: 2.866964101791382
Validation loss: 3.1941703211876655

Epoch: 26| Step: 0
Training loss: 3.6213104724884033
Validation loss: 3.1958961871362503

Epoch: 6| Step: 1
Training loss: 3.486107349395752
Validation loss: 3.1905407956851426

Epoch: 6| Step: 2
Training loss: 2.610595703125
Validation loss: 3.1844305607580368

Epoch: 6| Step: 3
Training loss: 2.800347328186035
Validation loss: 3.18881130731234

Epoch: 6| Step: 4
Training loss: 3.7012951374053955
Validation loss: 3.1904690573292394

Epoch: 6| Step: 5
Training loss: 3.6329219341278076
Validation loss: 3.188792738863217

Epoch: 6| Step: 6
Training loss: 2.8942947387695312
Validation loss: 3.1846540563849994

Epoch: 6| Step: 7
Training loss: 3.7164034843444824
Validation loss: 3.1809191703796387

Epoch: 6| Step: 8
Training loss: 3.154435157775879
Validation loss: 3.1771044474776073

Epoch: 6| Step: 9
Training loss: 3.690737724304199
Validation loss: 3.177676077811949

Epoch: 6| Step: 10
Training loss: 3.1542603969573975
Validation loss: 3.1768234160638626

Epoch: 6| Step: 11
Training loss: 2.4510984420776367
Validation loss: 3.1773047626659436

Epoch: 6| Step: 12
Training loss: 2.9471089839935303
Validation loss: 3.174943836786414

Epoch: 6| Step: 13
Training loss: 2.4284145832061768
Validation loss: 3.174829270250054

Epoch: 27| Step: 0
Training loss: 3.2891759872436523
Validation loss: 3.173031596727269

Epoch: 6| Step: 1
Training loss: 3.2017884254455566
Validation loss: 3.172696723732897

Epoch: 6| Step: 2
Training loss: 2.628525733947754
Validation loss: 3.171963712220551

Epoch: 6| Step: 3
Training loss: 3.3975977897644043
Validation loss: 3.1711156804074525

Epoch: 6| Step: 4
Training loss: 3.163576126098633
Validation loss: 3.16917509161016

Epoch: 6| Step: 5
Training loss: 3.8884737491607666
Validation loss: 3.170452276865641

Epoch: 6| Step: 6
Training loss: 3.03659725189209
Validation loss: 3.175341711249403

Epoch: 6| Step: 7
Training loss: 3.078531265258789
Validation loss: 3.17564889436127

Epoch: 6| Step: 8
Training loss: 3.786224842071533
Validation loss: 3.168801692224318

Epoch: 6| Step: 9
Training loss: 2.4595000743865967
Validation loss: 3.1721119367948143

Epoch: 6| Step: 10
Training loss: 3.17279052734375
Validation loss: 3.176248319687382

Epoch: 6| Step: 11
Training loss: 2.346829414367676
Validation loss: 3.1683274802341255

Epoch: 6| Step: 12
Training loss: 3.486222267150879
Validation loss: 3.1645895588782524

Epoch: 6| Step: 13
Training loss: 3.780372142791748
Validation loss: 3.1624080391340357

Epoch: 28| Step: 0
Training loss: 2.2704977989196777
Validation loss: 3.1648789605786725

Epoch: 6| Step: 1
Training loss: 3.762030601501465
Validation loss: 3.1624010506496636

Epoch: 6| Step: 2
Training loss: 2.901475429534912
Validation loss: 3.1625304709198656

Epoch: 6| Step: 3
Training loss: 2.9196810722351074
Validation loss: 3.163315062881798

Epoch: 6| Step: 4
Training loss: 3.199666738510132
Validation loss: 3.1591321883663053

Epoch: 6| Step: 5
Training loss: 3.9591684341430664
Validation loss: 3.157484964657855

Epoch: 6| Step: 6
Training loss: 3.2322099208831787
Validation loss: 3.156274393040647

Epoch: 6| Step: 7
Training loss: 3.1588494777679443
Validation loss: 3.153768165137178

Epoch: 6| Step: 8
Training loss: 3.4647841453552246
Validation loss: 3.158229740717078

Epoch: 6| Step: 9
Training loss: 3.137584686279297
Validation loss: 3.160007599861391

Epoch: 6| Step: 10
Training loss: 3.020223379135132
Validation loss: 3.1556386332358084

Epoch: 6| Step: 11
Training loss: 2.807620048522949
Validation loss: 3.1515891705789874

Epoch: 6| Step: 12
Training loss: 3.294114112854004
Validation loss: 3.151363121565952

Epoch: 6| Step: 13
Training loss: 3.348883628845215
Validation loss: 3.1494461285170687

Epoch: 29| Step: 0
Training loss: 3.406369686126709
Validation loss: 3.1496877824106524

Epoch: 6| Step: 1
Training loss: 2.9196834564208984
Validation loss: 3.1479232208703154

Epoch: 6| Step: 2
Training loss: 2.820455551147461
Validation loss: 3.1460762562290316

Epoch: 6| Step: 3
Training loss: 2.256653308868408
Validation loss: 3.142999992575697

Epoch: 6| Step: 4
Training loss: 4.3760666847229
Validation loss: 3.150731840441304

Epoch: 6| Step: 5
Training loss: 3.06185245513916
Validation loss: 3.144972590989964

Epoch: 6| Step: 6
Training loss: 3.1105055809020996
Validation loss: 3.140707664592292

Epoch: 6| Step: 7
Training loss: 3.0531320571899414
Validation loss: 3.1404702304511942

Epoch: 6| Step: 8
Training loss: 2.583343029022217
Validation loss: 3.145991917579405

Epoch: 6| Step: 9
Training loss: 3.7846999168395996
Validation loss: 3.1433934037403395

Epoch: 6| Step: 10
Training loss: 3.306086301803589
Validation loss: 3.1355465227557766

Epoch: 6| Step: 11
Training loss: 3.958850860595703
Validation loss: 3.1343007241525958

Epoch: 6| Step: 12
Training loss: 2.48482084274292
Validation loss: 3.1330296403618267

Epoch: 6| Step: 13
Training loss: 3.000328540802002
Validation loss: 3.133071832759406

Epoch: 30| Step: 0
Training loss: 3.1630356311798096
Validation loss: 3.1352470049294094

Epoch: 6| Step: 1
Training loss: 2.581235647201538
Validation loss: 3.135108388880248

Epoch: 6| Step: 2
Training loss: 2.9416046142578125
Validation loss: 3.132839669463455

Epoch: 6| Step: 3
Training loss: 3.5938005447387695
Validation loss: 3.1304074897561023

Epoch: 6| Step: 4
Training loss: 2.4107658863067627
Validation loss: 3.1277327178626932

Epoch: 6| Step: 5
Training loss: 4.143821716308594
Validation loss: 3.1251547516033216

Epoch: 6| Step: 6
Training loss: 3.257305145263672
Validation loss: 3.1262675203302854

Epoch: 6| Step: 7
Training loss: 4.487029075622559
Validation loss: 3.125037411207794

Epoch: 6| Step: 8
Training loss: 2.767406702041626
Validation loss: 3.123326542556927

Epoch: 6| Step: 9
Training loss: 2.9662437438964844
Validation loss: 3.1318116700777443

Epoch: 6| Step: 10
Training loss: 2.1036036014556885
Validation loss: 3.1241133546316497

Epoch: 6| Step: 11
Training loss: 3.4957938194274902
Validation loss: 3.119541404067829

Epoch: 6| Step: 12
Training loss: 2.5755887031555176
Validation loss: 3.1177752248702513

Epoch: 6| Step: 13
Training loss: 3.9028210639953613
Validation loss: 3.1166636533634637

Epoch: 31| Step: 0
Training loss: 4.185333251953125
Validation loss: 3.1152374949506534

Epoch: 6| Step: 1
Training loss: 2.9665002822875977
Validation loss: 3.115764259010233

Epoch: 6| Step: 2
Training loss: 2.6514511108398438
Validation loss: 3.1120464468515046

Epoch: 6| Step: 3
Training loss: 2.681036949157715
Validation loss: 3.1120320802093833

Epoch: 6| Step: 4
Training loss: 3.282456874847412
Validation loss: 3.110613984446372

Epoch: 6| Step: 5
Training loss: 2.990365743637085
Validation loss: 3.1153573477140037

Epoch: 6| Step: 6
Training loss: 3.287607431411743
Validation loss: 3.1091082660100793

Epoch: 6| Step: 7
Training loss: 2.96956205368042
Validation loss: 3.1076361184479087

Epoch: 6| Step: 8
Training loss: 2.9865808486938477
Validation loss: 3.105021745927872

Epoch: 6| Step: 9
Training loss: 3.230215549468994
Validation loss: 3.1049694066406577

Epoch: 6| Step: 10
Training loss: 3.0273995399475098
Validation loss: 3.108670578208021

Epoch: 6| Step: 11
Training loss: 3.2035467624664307
Validation loss: 3.1288185914357505

Epoch: 6| Step: 12
Training loss: 3.6920411586761475
Validation loss: 3.1346245965650006

Epoch: 6| Step: 13
Training loss: 2.4751622676849365
Validation loss: 3.1089618949479956

Epoch: 32| Step: 0
Training loss: 3.0556800365448
Validation loss: 3.1003288043442594

Epoch: 6| Step: 1
Training loss: 3.4228663444519043
Validation loss: 3.1015797635560394

Epoch: 6| Step: 2
Training loss: 4.589472770690918
Validation loss: 3.1021245423183648

Epoch: 6| Step: 3
Training loss: 3.187981605529785
Validation loss: 3.102805773417155

Epoch: 6| Step: 4
Training loss: 2.6889357566833496
Validation loss: 3.1037198035947737

Epoch: 6| Step: 5
Training loss: 3.0377635955810547
Validation loss: 3.101974651377688

Epoch: 6| Step: 6
Training loss: 3.3584189414978027
Validation loss: 3.105596524412914

Epoch: 6| Step: 7
Training loss: 2.3512115478515625
Validation loss: 3.094027319262105

Epoch: 6| Step: 8
Training loss: 2.8924264907836914
Validation loss: 3.0920937548401537

Epoch: 6| Step: 9
Training loss: 3.5145492553710938
Validation loss: 3.09229084496857

Epoch: 6| Step: 10
Training loss: 2.979757308959961
Validation loss: 3.091318925221761

Epoch: 6| Step: 11
Training loss: 2.0268259048461914
Validation loss: 3.0915967008118987

Epoch: 6| Step: 12
Training loss: 3.6863179206848145
Validation loss: 3.0991650601868987

Epoch: 6| Step: 13
Training loss: 2.994540214538574
Validation loss: 3.0993763862117643

Epoch: 33| Step: 0
Training loss: 2.9461252689361572
Validation loss: 3.1028458790112565

Epoch: 6| Step: 1
Training loss: 4.2412309646606445
Validation loss: 3.0951505348246586

Epoch: 6| Step: 2
Training loss: 2.2291626930236816
Validation loss: 3.0868319683177496

Epoch: 6| Step: 3
Training loss: 2.804163932800293
Validation loss: 3.0871763460097776

Epoch: 6| Step: 4
Training loss: 3.2858355045318604
Validation loss: 3.0840259521238265

Epoch: 6| Step: 5
Training loss: 3.329225778579712
Validation loss: 3.0871906613790863

Epoch: 6| Step: 6
Training loss: 3.6240885257720947
Validation loss: 3.0854204623929915

Epoch: 6| Step: 7
Training loss: 2.6589479446411133
Validation loss: 3.0834165157810336

Epoch: 6| Step: 8
Training loss: 3.4889392852783203
Validation loss: 3.08389635239878

Epoch: 6| Step: 9
Training loss: 3.413886308670044
Validation loss: 3.082926680964808

Epoch: 6| Step: 10
Training loss: 2.7788097858428955
Validation loss: 3.081273184027723

Epoch: 6| Step: 11
Training loss: 3.3731155395507812
Validation loss: 3.089420800567955

Epoch: 6| Step: 12
Training loss: 2.6142354011535645
Validation loss: 3.0914738947345364

Epoch: 6| Step: 13
Training loss: 2.716953754425049
Validation loss: 3.083997926404399

Epoch: 34| Step: 0
Training loss: 3.123415470123291
Validation loss: 3.0787275427131244

Epoch: 6| Step: 1
Training loss: 3.0548439025878906
Validation loss: 3.0774995485941568

Epoch: 6| Step: 2
Training loss: 2.5452816486358643
Validation loss: 3.0769361244734896

Epoch: 6| Step: 3
Training loss: 3.205899477005005
Validation loss: 3.0750788873241794

Epoch: 6| Step: 4
Training loss: 2.8985671997070312
Validation loss: 3.077140223595404

Epoch: 6| Step: 5
Training loss: 2.4290387630462646
Validation loss: 3.0739180759717057

Epoch: 6| Step: 6
Training loss: 3.4514403343200684
Validation loss: 3.071791095118369

Epoch: 6| Step: 7
Training loss: 4.18258810043335
Validation loss: 3.0724888873356644

Epoch: 6| Step: 8
Training loss: 3.3442957401275635
Validation loss: 3.0740194064314648

Epoch: 6| Step: 9
Training loss: 3.3883776664733887
Validation loss: 3.0727716812523465

Epoch: 6| Step: 10
Training loss: 2.0734610557556152
Validation loss: 3.073544484312816

Epoch: 6| Step: 11
Training loss: 3.774780750274658
Validation loss: 3.0702328425581737

Epoch: 6| Step: 12
Training loss: 2.7618885040283203
Validation loss: 3.072598680373161

Epoch: 6| Step: 13
Training loss: 3.5073697566986084
Validation loss: 3.0706663721351215

Epoch: 35| Step: 0
Training loss: 2.482813596725464
Validation loss: 3.0708593809476463

Epoch: 6| Step: 1
Training loss: 2.155141592025757
Validation loss: 3.070113694795998

Epoch: 6| Step: 2
Training loss: 3.7962000370025635
Validation loss: 3.0734118492372575

Epoch: 6| Step: 3
Training loss: 1.9765617847442627
Validation loss: 3.074065275089715

Epoch: 6| Step: 4
Training loss: 3.239219903945923
Validation loss: 3.072698370102913

Epoch: 6| Step: 5
Training loss: 2.4732954502105713
Validation loss: 3.0709834816635295

Epoch: 6| Step: 6
Training loss: 3.4278013706207275
Validation loss: 3.074828476034185

Epoch: 6| Step: 7
Training loss: 4.303956985473633
Validation loss: 3.0752560759103424

Epoch: 6| Step: 8
Training loss: 3.302257776260376
Validation loss: 3.068618607777421

Epoch: 6| Step: 9
Training loss: 3.2139782905578613
Validation loss: 3.0672295016627156

Epoch: 6| Step: 10
Training loss: 4.062768936157227
Validation loss: 3.063123080038255

Epoch: 6| Step: 11
Training loss: 2.628897190093994
Validation loss: 3.0630936520074004

Epoch: 6| Step: 12
Training loss: 3.858530282974243
Validation loss: 3.064120031172229

Epoch: 6| Step: 13
Training loss: 2.1655969619750977
Validation loss: 3.062288389411024

Epoch: 36| Step: 0
Training loss: 3.1275463104248047
Validation loss: 3.0635649927200808

Epoch: 6| Step: 1
Training loss: 3.2064459323883057
Validation loss: 3.0649381401718303

Epoch: 6| Step: 2
Training loss: 2.945219039916992
Validation loss: 3.06188182164264

Epoch: 6| Step: 3
Training loss: 3.4728660583496094
Validation loss: 3.0619101831989903

Epoch: 6| Step: 4
Training loss: 2.782202959060669
Validation loss: 3.069141803249236

Epoch: 6| Step: 5
Training loss: 2.718177318572998
Validation loss: 3.065170711086642

Epoch: 6| Step: 6
Training loss: 3.2570102214813232
Validation loss: 3.06978770994371

Epoch: 6| Step: 7
Training loss: 2.7431704998016357
Validation loss: 3.0606524687941357

Epoch: 6| Step: 8
Training loss: 4.104585647583008
Validation loss: 3.0691408598294823

Epoch: 6| Step: 9
Training loss: 2.7567899227142334
Validation loss: 3.060850763833651

Epoch: 6| Step: 10
Training loss: 2.6880757808685303
Validation loss: 3.0575384298960366

Epoch: 6| Step: 11
Training loss: 3.6352713108062744
Validation loss: 3.0551619862997406

Epoch: 6| Step: 12
Training loss: 3.2705817222595215
Validation loss: 3.0557709304235314

Epoch: 6| Step: 13
Training loss: 2.41566801071167
Validation loss: 3.0572464312276533

Epoch: 37| Step: 0
Training loss: 3.0350937843322754
Validation loss: 3.0602907314095447

Epoch: 6| Step: 1
Training loss: 3.2318100929260254
Validation loss: 3.058458907629854

Epoch: 6| Step: 2
Training loss: 3.5463316440582275
Validation loss: 3.0642085793197795

Epoch: 6| Step: 3
Training loss: 2.545474052429199
Validation loss: 3.0579621099656626

Epoch: 6| Step: 4
Training loss: 2.6109039783477783
Validation loss: 3.056050705653365

Epoch: 6| Step: 5
Training loss: 3.1395931243896484
Validation loss: 3.051469749019992

Epoch: 6| Step: 6
Training loss: 2.2463488578796387
Validation loss: 3.050701149048344

Epoch: 6| Step: 7
Training loss: 4.227719783782959
Validation loss: 3.049720897469469

Epoch: 6| Step: 8
Training loss: 3.5179271697998047
Validation loss: 3.0486310246170207

Epoch: 6| Step: 9
Training loss: 3.1759512424468994
Validation loss: 3.0489506157495643

Epoch: 6| Step: 10
Training loss: 3.398426055908203
Validation loss: 3.0484000739230903

Epoch: 6| Step: 11
Training loss: 2.744601249694824
Validation loss: 3.0491301551941903

Epoch: 6| Step: 12
Training loss: 3.337052583694458
Validation loss: 3.049287365328881

Epoch: 6| Step: 13
Training loss: 2.238173246383667
Validation loss: 3.0535154573379026

Epoch: 38| Step: 0
Training loss: 2.5260908603668213
Validation loss: 3.0573532427510908

Epoch: 6| Step: 1
Training loss: 3.2327733039855957
Validation loss: 3.046629910827965

Epoch: 6| Step: 2
Training loss: 3.2308292388916016
Validation loss: 3.0435581720003517

Epoch: 6| Step: 3
Training loss: 2.5001044273376465
Validation loss: 3.046876717639226

Epoch: 6| Step: 4
Training loss: 3.6247479915618896
Validation loss: 3.050509170819354

Epoch: 6| Step: 5
Training loss: 3.2524056434631348
Validation loss: 3.0475213784043507

Epoch: 6| Step: 6
Training loss: 2.9744248390197754
Validation loss: 3.0434374988719983

Epoch: 6| Step: 7
Training loss: 3.434091091156006
Validation loss: 3.0465480409642702

Epoch: 6| Step: 8
Training loss: 3.3420872688293457
Validation loss: 3.043720519670876

Epoch: 6| Step: 9
Training loss: 2.8328537940979004
Validation loss: 3.0441874124670543

Epoch: 6| Step: 10
Training loss: 3.2836711406707764
Validation loss: 3.0414292504710536

Epoch: 6| Step: 11
Training loss: 2.788496255874634
Validation loss: 3.041002678614791

Epoch: 6| Step: 12
Training loss: 2.879204750061035
Validation loss: 3.042243121772684

Epoch: 6| Step: 13
Training loss: 3.727428913116455
Validation loss: 3.0442213217417398

Epoch: 39| Step: 0
Training loss: 3.867931365966797
Validation loss: 3.0459367075274066

Epoch: 6| Step: 1
Training loss: 2.736464262008667
Validation loss: 3.0450192677077426

Epoch: 6| Step: 2
Training loss: 2.299905300140381
Validation loss: 3.040028167027299

Epoch: 6| Step: 3
Training loss: 3.170865535736084
Validation loss: 3.039476571544524

Epoch: 6| Step: 4
Training loss: 2.687939167022705
Validation loss: 3.039682352414695

Epoch: 6| Step: 5
Training loss: 3.9514596462249756
Validation loss: 3.0386212692465833

Epoch: 6| Step: 6
Training loss: 3.165081024169922
Validation loss: 3.037784384142968

Epoch: 6| Step: 7
Training loss: 2.82733154296875
Validation loss: 3.037788014258108

Epoch: 6| Step: 8
Training loss: 3.350146770477295
Validation loss: 3.037704808737642

Epoch: 6| Step: 9
Training loss: 3.0783896446228027
Validation loss: 3.036344930689822

Epoch: 6| Step: 10
Training loss: 2.140237331390381
Validation loss: 3.036667431554487

Epoch: 6| Step: 11
Training loss: 4.170361042022705
Validation loss: 3.0364186276671705

Epoch: 6| Step: 12
Training loss: 2.6657958030700684
Validation loss: 3.036288156304308

Epoch: 6| Step: 13
Training loss: 3.174959182739258
Validation loss: 3.0371660109489196

Epoch: 40| Step: 0
Training loss: 2.9225053787231445
Validation loss: 3.036772656184371

Epoch: 6| Step: 1
Training loss: 3.7048020362854004
Validation loss: 3.040164424527076

Epoch: 6| Step: 2
Training loss: 3.2816996574401855
Validation loss: 3.0360353044284287

Epoch: 6| Step: 3
Training loss: 4.504859924316406
Validation loss: 3.033682992381434

Epoch: 6| Step: 4
Training loss: 2.5034868717193604
Validation loss: 3.0319144597617527

Epoch: 6| Step: 5
Training loss: 3.2448930740356445
Validation loss: 3.031729628962855

Epoch: 6| Step: 6
Training loss: 3.2963476181030273
Validation loss: 3.0325177613125054

Epoch: 6| Step: 7
Training loss: 2.7614145278930664
Validation loss: 3.0311362948468936

Epoch: 6| Step: 8
Training loss: 2.227416753768921
Validation loss: 3.0302163888049383

Epoch: 6| Step: 9
Training loss: 3.1196467876434326
Validation loss: 3.0281696909217426

Epoch: 6| Step: 10
Training loss: 2.9519026279449463
Validation loss: 3.030481848665463

Epoch: 6| Step: 11
Training loss: 2.102311134338379
Validation loss: 3.0301298479880057

Epoch: 6| Step: 12
Training loss: 3.5215115547180176
Validation loss: 3.0309433552526657

Epoch: 6| Step: 13
Training loss: 2.9968957901000977
Validation loss: 3.0330951931656047

Epoch: 41| Step: 0
Training loss: 3.356088876724243
Validation loss: 3.0306854273683284

Epoch: 6| Step: 1
Training loss: 2.5165867805480957
Validation loss: 3.0293351399001254

Epoch: 6| Step: 2
Training loss: 2.6528077125549316
Validation loss: 3.030409889836465

Epoch: 6| Step: 3
Training loss: 2.6951920986175537
Validation loss: 3.035250151029197

Epoch: 6| Step: 4
Training loss: 2.8514232635498047
Validation loss: 3.031376838684082

Epoch: 6| Step: 5
Training loss: 3.7055206298828125
Validation loss: 3.029973291581677

Epoch: 6| Step: 6
Training loss: 2.7970237731933594
Validation loss: 3.0280772229676605

Epoch: 6| Step: 7
Training loss: 3.2148325443267822
Validation loss: 3.0279237890756256

Epoch: 6| Step: 8
Training loss: 3.172363758087158
Validation loss: 3.022635175335792

Epoch: 6| Step: 9
Training loss: 3.4940569400787354
Validation loss: 3.0228521003518054

Epoch: 6| Step: 10
Training loss: 4.280264854431152
Validation loss: 3.021710293267363

Epoch: 6| Step: 11
Training loss: 3.393292188644409
Validation loss: 3.023577631160777

Epoch: 6| Step: 12
Training loss: 2.225161075592041
Validation loss: 3.024796016754643

Epoch: 6| Step: 13
Training loss: 2.5651698112487793
Validation loss: 3.0215801090322514

Epoch: 42| Step: 0
Training loss: 2.560500383377075
Validation loss: 3.0233638030226513

Epoch: 6| Step: 1
Training loss: 3.271078586578369
Validation loss: 3.025846265977429

Epoch: 6| Step: 2
Training loss: 3.1080260276794434
Validation loss: 3.0268667949143278

Epoch: 6| Step: 3
Training loss: 4.061651229858398
Validation loss: 3.027784893589635

Epoch: 6| Step: 4
Training loss: 3.534876823425293
Validation loss: 3.0215473918504614

Epoch: 6| Step: 5
Training loss: 2.4034316539764404
Validation loss: 3.0211724850439254

Epoch: 6| Step: 6
Training loss: 2.564596652984619
Validation loss: 3.0201739803437264

Epoch: 6| Step: 7
Training loss: 3.1489665508270264
Validation loss: 3.020582140132945

Epoch: 6| Step: 8
Training loss: 3.4611241817474365
Validation loss: 3.0223919781305457

Epoch: 6| Step: 9
Training loss: 3.5796024799346924
Validation loss: 3.0199567733272428

Epoch: 6| Step: 10
Training loss: 2.658308506011963
Validation loss: 3.018109344667004

Epoch: 6| Step: 11
Training loss: 2.754988670349121
Validation loss: 3.0176791888411327

Epoch: 6| Step: 12
Training loss: 2.9448118209838867
Validation loss: 3.017626964917747

Epoch: 6| Step: 13
Training loss: 3.001234769821167
Validation loss: 3.01819025060182

Epoch: 43| Step: 0
Training loss: 3.4388952255249023
Validation loss: 3.028508129940238

Epoch: 6| Step: 1
Training loss: 3.2193617820739746
Validation loss: 3.026549539258403

Epoch: 6| Step: 2
Training loss: 3.0080795288085938
Validation loss: 3.029205637593423

Epoch: 6| Step: 3
Training loss: 2.897091865539551
Validation loss: 3.0207973167460453

Epoch: 6| Step: 4
Training loss: 3.1405696868896484
Validation loss: 3.0193158631683676

Epoch: 6| Step: 5
Training loss: 2.0386078357696533
Validation loss: 3.0121024424029934

Epoch: 6| Step: 6
Training loss: 2.8899731636047363
Validation loss: 3.0131109991381244

Epoch: 6| Step: 7
Training loss: 2.061616897583008
Validation loss: 3.013670734179917

Epoch: 6| Step: 8
Training loss: 4.353874683380127
Validation loss: 3.0168623975528184

Epoch: 6| Step: 9
Training loss: 4.505173206329346
Validation loss: 3.0121960870681272

Epoch: 6| Step: 10
Training loss: 3.2811362743377686
Validation loss: 3.011095316179337

Epoch: 6| Step: 11
Training loss: 2.164884328842163
Validation loss: 3.0102333458521033

Epoch: 6| Step: 12
Training loss: 3.27390193939209
Validation loss: 3.010023616975354

Epoch: 6| Step: 13
Training loss: 2.5176095962524414
Validation loss: 3.009145934094665

Epoch: 44| Step: 0
Training loss: 3.136164426803589
Validation loss: 3.0117163119777555

Epoch: 6| Step: 1
Training loss: 3.149916648864746
Validation loss: 3.0104734051612114

Epoch: 6| Step: 2
Training loss: 1.8243157863616943
Validation loss: 3.0115032478045394

Epoch: 6| Step: 3
Training loss: 3.199824810028076
Validation loss: 3.0094358485232116

Epoch: 6| Step: 4
Training loss: 3.2416305541992188
Validation loss: 3.0128893416414977

Epoch: 6| Step: 5
Training loss: 3.7291600704193115
Validation loss: 3.0153843766899517

Epoch: 6| Step: 6
Training loss: 3.457937002182007
Validation loss: 3.0128999064045567

Epoch: 6| Step: 7
Training loss: 3.4191765785217285
Validation loss: 3.011546552822154

Epoch: 6| Step: 8
Training loss: 3.059678077697754
Validation loss: 3.0085148631885485

Epoch: 6| Step: 9
Training loss: 4.3403191566467285
Validation loss: 3.0044771471331195

Epoch: 6| Step: 10
Training loss: 2.4774482250213623
Validation loss: 3.005982886078537

Epoch: 6| Step: 11
Training loss: 2.4478330612182617
Validation loss: 3.007724138998216

Epoch: 6| Step: 12
Training loss: 2.86434006690979
Validation loss: 3.006264971148583

Epoch: 6| Step: 13
Training loss: 2.28937029838562
Validation loss: 3.009142691089261

Epoch: 45| Step: 0
Training loss: 3.1597418785095215
Validation loss: 3.0151395490092616

Epoch: 6| Step: 1
Training loss: 3.709171772003174
Validation loss: 3.028887238553775

Epoch: 6| Step: 2
Training loss: 2.2879252433776855
Validation loss: 3.0385088818047636

Epoch: 6| Step: 3
Training loss: 3.919888973236084
Validation loss: 3.0386913976361676

Epoch: 6| Step: 4
Training loss: 2.9905831813812256
Validation loss: 3.0215093961326023

Epoch: 6| Step: 5
Training loss: 3.7030680179595947
Validation loss: 3.0152048474998883

Epoch: 6| Step: 6
Training loss: 2.8933420181274414
Validation loss: 3.019525145971647

Epoch: 6| Step: 7
Training loss: 2.1499531269073486
Validation loss: 3.0200660151820027

Epoch: 6| Step: 8
Training loss: 3.7977118492126465
Validation loss: 3.044534542227304

Epoch: 6| Step: 9
Training loss: 2.420100212097168
Validation loss: 3.0356869800116426

Epoch: 6| Step: 10
Training loss: 3.3571643829345703
Validation loss: 3.018497433713687

Epoch: 6| Step: 11
Training loss: 2.553802251815796
Validation loss: 3.0166730496191208

Epoch: 6| Step: 12
Training loss: 3.0446128845214844
Validation loss: 3.0152605656654603

Epoch: 6| Step: 13
Training loss: 3.1975526809692383
Validation loss: 3.015228722685127

Epoch: 46| Step: 0
Training loss: 2.2508668899536133
Validation loss: 3.0138419443561184

Epoch: 6| Step: 1
Training loss: 3.0074586868286133
Validation loss: 3.014592683443459

Epoch: 6| Step: 2
Training loss: 2.775731086730957
Validation loss: 3.0134446185122252

Epoch: 6| Step: 3
Training loss: 3.403480052947998
Validation loss: 3.0131116810665337

Epoch: 6| Step: 4
Training loss: 3.3283350467681885
Validation loss: 3.0055039544259348

Epoch: 6| Step: 5
Training loss: 3.3495116233825684
Validation loss: 3.005822576502318

Epoch: 6| Step: 6
Training loss: 3.86734676361084
Validation loss: 3.0025507634685886

Epoch: 6| Step: 7
Training loss: 2.520470380783081
Validation loss: 3.0027473459961596

Epoch: 6| Step: 8
Training loss: 3.169563055038452
Validation loss: 3.001485752803023

Epoch: 6| Step: 9
Training loss: 2.719913959503174
Validation loss: 2.996417353230138

Epoch: 6| Step: 10
Training loss: 2.603078603744507
Validation loss: 2.9965620809985745

Epoch: 6| Step: 11
Training loss: 4.458952903747559
Validation loss: 3.0030275160266506

Epoch: 6| Step: 12
Training loss: 2.2029800415039062
Validation loss: 2.9967115950840775

Epoch: 6| Step: 13
Training loss: 3.4564502239227295
Validation loss: 2.9926847668104273

Epoch: 47| Step: 0
Training loss: 2.666257858276367
Validation loss: 2.9959769454053653

Epoch: 6| Step: 1
Training loss: 3.3756120204925537
Validation loss: 2.9944121196705806

Epoch: 6| Step: 2
Training loss: 2.96895170211792
Validation loss: 2.992272602614536

Epoch: 6| Step: 3
Training loss: 3.261695384979248
Validation loss: 2.9895289533881733

Epoch: 6| Step: 4
Training loss: 2.4480037689208984
Validation loss: 2.9908339797809558

Epoch: 6| Step: 5
Training loss: 3.4450159072875977
Validation loss: 2.9893538259690806

Epoch: 6| Step: 6
Training loss: 4.626384735107422
Validation loss: 2.986771447684175

Epoch: 6| Step: 7
Training loss: 2.4959607124328613
Validation loss: 2.988297813682146

Epoch: 6| Step: 8
Training loss: 3.5264110565185547
Validation loss: 2.983292207922987

Epoch: 6| Step: 9
Training loss: 2.6119208335876465
Validation loss: 2.985767402956563

Epoch: 6| Step: 10
Training loss: 1.5574026107788086
Validation loss: 2.9849587460999847

Epoch: 6| Step: 11
Training loss: 3.84519100189209
Validation loss: 2.9832651820234073

Epoch: 6| Step: 12
Training loss: 3.388639450073242
Validation loss: 2.984016018529092

Epoch: 6| Step: 13
Training loss: 2.244117259979248
Validation loss: 2.9842644250521095

Epoch: 48| Step: 0
Training loss: 4.332755088806152
Validation loss: 2.986505195658694

Epoch: 6| Step: 1
Training loss: 1.9268864393234253
Validation loss: 2.9883824676595707

Epoch: 6| Step: 2
Training loss: 2.715012311935425
Validation loss: 2.9885764916737876

Epoch: 6| Step: 3
Training loss: 3.201737880706787
Validation loss: 2.98847960400325

Epoch: 6| Step: 4
Training loss: 2.655790328979492
Validation loss: 2.984218874285298

Epoch: 6| Step: 5
Training loss: 2.9717283248901367
Validation loss: 2.9807228042233374

Epoch: 6| Step: 6
Training loss: 2.405503511428833
Validation loss: 2.982478139221027

Epoch: 6| Step: 7
Training loss: 2.6237688064575195
Validation loss: 2.9828338905047347

Epoch: 6| Step: 8
Training loss: 3.077039957046509
Validation loss: 2.9812049173539683

Epoch: 6| Step: 9
Training loss: 3.564612865447998
Validation loss: 2.9755583629813245

Epoch: 6| Step: 10
Training loss: 3.5961179733276367
Validation loss: 2.981769710458735

Epoch: 6| Step: 11
Training loss: 3.408498525619507
Validation loss: 2.9826339701170563

Epoch: 6| Step: 12
Training loss: 3.259018898010254
Validation loss: 2.9804634227547595

Epoch: 6| Step: 13
Training loss: 2.8725030422210693
Validation loss: 2.9806680064047537

Epoch: 49| Step: 0
Training loss: 2.709571361541748
Validation loss: 2.9786764524316274

Epoch: 6| Step: 1
Training loss: 2.935664653778076
Validation loss: 2.9829258944398616

Epoch: 6| Step: 2
Training loss: 2.686147928237915
Validation loss: 2.9862761958952873

Epoch: 6| Step: 3
Training loss: 3.206991195678711
Validation loss: 2.98131533591978

Epoch: 6| Step: 4
Training loss: 2.8745388984680176
Validation loss: 2.9772109677714687

Epoch: 6| Step: 5
Training loss: 3.154597282409668
Validation loss: 2.979007351783014

Epoch: 6| Step: 6
Training loss: 3.8992812633514404
Validation loss: 2.9769786045115483

Epoch: 6| Step: 7
Training loss: 2.9727578163146973
Validation loss: 2.975025530784361

Epoch: 6| Step: 8
Training loss: 2.8756484985351562
Validation loss: 2.9810136415625132

Epoch: 6| Step: 9
Training loss: 2.8977723121643066
Validation loss: 2.9804063894415416

Epoch: 6| Step: 10
Training loss: 3.42851185798645
Validation loss: 2.9790606396172636

Epoch: 6| Step: 11
Training loss: 2.6411545276641846
Validation loss: 2.97605792168648

Epoch: 6| Step: 12
Training loss: 2.806075096130371
Validation loss: 2.9705276950713126

Epoch: 6| Step: 13
Training loss: 3.9656002521514893
Validation loss: 2.970224611220821

Epoch: 50| Step: 0
Training loss: 3.2334134578704834
Validation loss: 2.9742127157026723

Epoch: 6| Step: 1
Training loss: 2.6653594970703125
Validation loss: 2.969462974097139

Epoch: 6| Step: 2
Training loss: 3.0098395347595215
Validation loss: 2.968882683784731

Epoch: 6| Step: 3
Training loss: 4.205671310424805
Validation loss: 2.965652870875533

Epoch: 6| Step: 4
Training loss: 3.2197303771972656
Validation loss: 2.966968572267922

Epoch: 6| Step: 5
Training loss: 3.4370501041412354
Validation loss: 2.964551889768211

Epoch: 6| Step: 6
Training loss: 2.768184185028076
Validation loss: 2.9629959547391502

Epoch: 6| Step: 7
Training loss: 3.541419506072998
Validation loss: 2.9674278023422405

Epoch: 6| Step: 8
Training loss: 2.4022293090820312
Validation loss: 2.9661103115286878

Epoch: 6| Step: 9
Training loss: 2.8535757064819336
Validation loss: 2.964342104491367

Epoch: 6| Step: 10
Training loss: 1.841261863708496
Validation loss: 2.9644943309086624

Epoch: 6| Step: 11
Training loss: 2.892904758453369
Validation loss: 2.9632867779783023

Epoch: 6| Step: 12
Training loss: 3.2083749771118164
Validation loss: 2.9651703296169156

Epoch: 6| Step: 13
Training loss: 3.5368165969848633
Validation loss: 2.963618493849231

Epoch: 51| Step: 0
Training loss: 2.146263599395752
Validation loss: 2.961232836528491

Epoch: 6| Step: 1
Training loss: 3.398684024810791
Validation loss: 2.9640616063148744

Epoch: 6| Step: 2
Training loss: 2.4090189933776855
Validation loss: 2.960621626146378

Epoch: 6| Step: 3
Training loss: 2.8884456157684326
Validation loss: 2.9609415095339537

Epoch: 6| Step: 4
Training loss: 2.130215644836426
Validation loss: 2.962031820768951

Epoch: 6| Step: 5
Training loss: 3.8863844871520996
Validation loss: 2.9594329018746652

Epoch: 6| Step: 6
Training loss: 3.4381022453308105
Validation loss: 2.9566269664354223

Epoch: 6| Step: 7
Training loss: 2.8843352794647217
Validation loss: 2.9586204815936346

Epoch: 6| Step: 8
Training loss: 2.627938985824585
Validation loss: 2.958570623910555

Epoch: 6| Step: 9
Training loss: 4.469127655029297
Validation loss: 2.9594128618958178

Epoch: 6| Step: 10
Training loss: 2.8508167266845703
Validation loss: 2.9560133821220806

Epoch: 6| Step: 11
Training loss: 3.4931304454803467
Validation loss: 2.959382362263177

Epoch: 6| Step: 12
Training loss: 2.877483367919922
Validation loss: 2.9578351948850896

Epoch: 6| Step: 13
Training loss: 3.0058915615081787
Validation loss: 2.9591612072401148

Epoch: 52| Step: 0
Training loss: 3.365670680999756
Validation loss: 2.958348710049865

Epoch: 6| Step: 1
Training loss: 3.2828922271728516
Validation loss: 2.953942375798379

Epoch: 6| Step: 2
Training loss: 2.632709264755249
Validation loss: 2.9543672069426505

Epoch: 6| Step: 3
Training loss: 3.3251397609710693
Validation loss: 2.954675018146474

Epoch: 6| Step: 4
Training loss: 2.1885323524475098
Validation loss: 2.954762433164863

Epoch: 6| Step: 5
Training loss: 3.6119422912597656
Validation loss: 2.9578057001995783

Epoch: 6| Step: 6
Training loss: 3.8403968811035156
Validation loss: 2.956541271619899

Epoch: 6| Step: 7
Training loss: 3.0748329162597656
Validation loss: 2.9638552845165296

Epoch: 6| Step: 8
Training loss: 3.4771246910095215
Validation loss: 2.9609464573603805

Epoch: 6| Step: 9
Training loss: 1.466069221496582
Validation loss: 2.963107362870247

Epoch: 6| Step: 10
Training loss: 3.538576364517212
Validation loss: 2.9579070716775875

Epoch: 6| Step: 11
Training loss: 2.3078150749206543
Validation loss: 2.9607835610707602

Epoch: 6| Step: 12
Training loss: 2.901179313659668
Validation loss: 2.962448981500441

Epoch: 6| Step: 13
Training loss: 3.725825786590576
Validation loss: 2.9627342583030782

Epoch: 53| Step: 0
Training loss: 3.559380292892456
Validation loss: 2.9528057088134108

Epoch: 6| Step: 1
Training loss: 2.235039234161377
Validation loss: 2.961771103643602

Epoch: 6| Step: 2
Training loss: 3.5900707244873047
Validation loss: 2.9634303303175074

Epoch: 6| Step: 3
Training loss: 2.9595932960510254
Validation loss: 2.9737595204384095

Epoch: 6| Step: 4
Training loss: 2.890471935272217
Validation loss: 2.964087370903261

Epoch: 6| Step: 5
Training loss: 3.5208733081817627
Validation loss: 2.9577788588821248

Epoch: 6| Step: 6
Training loss: 3.7915735244750977
Validation loss: 2.963549008933447

Epoch: 6| Step: 7
Training loss: 2.2318477630615234
Validation loss: 2.956751682425058

Epoch: 6| Step: 8
Training loss: 3.0234031677246094
Validation loss: 2.9533041548985306

Epoch: 6| Step: 9
Training loss: 3.464380979537964
Validation loss: 2.9538110609977477

Epoch: 6| Step: 10
Training loss: 2.5316686630249023
Validation loss: 2.952250526797387

Epoch: 6| Step: 11
Training loss: 2.0117123126983643
Validation loss: 2.949224833519228

Epoch: 6| Step: 12
Training loss: 2.7300000190734863
Validation loss: 2.95382155910615

Epoch: 6| Step: 13
Training loss: 4.533484935760498
Validation loss: 2.9638920753232894

Epoch: 54| Step: 0
Training loss: 3.149630069732666
Validation loss: 2.9714718480263986

Epoch: 6| Step: 1
Training loss: 2.528233528137207
Validation loss: 2.9671847512645106

Epoch: 6| Step: 2
Training loss: 3.017812728881836
Validation loss: 2.9678356570582234

Epoch: 6| Step: 3
Training loss: 3.907374143600464
Validation loss: 2.95583922888643

Epoch: 6| Step: 4
Training loss: 2.74642276763916
Validation loss: 2.9483688621110815

Epoch: 6| Step: 5
Training loss: 1.9404890537261963
Validation loss: 2.948187510172526

Epoch: 6| Step: 6
Training loss: 2.6071128845214844
Validation loss: 2.9487028993586057

Epoch: 6| Step: 7
Training loss: 2.7830138206481934
Validation loss: 2.94835510048815

Epoch: 6| Step: 8
Training loss: 2.9740493297576904
Validation loss: 2.950714054928031

Epoch: 6| Step: 9
Training loss: 2.617926836013794
Validation loss: 2.948529544697013

Epoch: 6| Step: 10
Training loss: 3.849700450897217
Validation loss: 2.9489907167291127

Epoch: 6| Step: 11
Training loss: 3.132127285003662
Validation loss: 2.9488707229655278

Epoch: 6| Step: 12
Training loss: 3.8049278259277344
Validation loss: 2.947568888305336

Epoch: 6| Step: 13
Training loss: 3.6038389205932617
Validation loss: 2.9469820171274166

Epoch: 55| Step: 0
Training loss: 3.096409797668457
Validation loss: 2.9415182734048493

Epoch: 6| Step: 1
Training loss: 2.3228461742401123
Validation loss: 2.9433497357112106

Epoch: 6| Step: 2
Training loss: 2.421100378036499
Validation loss: 2.9436647174178914

Epoch: 6| Step: 3
Training loss: 3.8206355571746826
Validation loss: 2.9454361751515377

Epoch: 6| Step: 4
Training loss: 1.5254359245300293
Validation loss: 2.9428743675190914

Epoch: 6| Step: 5
Training loss: 3.0811150074005127
Validation loss: 2.9503734496331986

Epoch: 6| Step: 6
Training loss: 3.3617920875549316
Validation loss: 2.950197399303477

Epoch: 6| Step: 7
Training loss: 3.8169050216674805
Validation loss: 2.950087265301776

Epoch: 6| Step: 8
Training loss: 3.338407039642334
Validation loss: 2.9474908818480787

Epoch: 6| Step: 9
Training loss: 2.9658682346343994
Validation loss: 2.9461966560732935

Epoch: 6| Step: 10
Training loss: 2.3865504264831543
Validation loss: 2.9447224370894896

Epoch: 6| Step: 11
Training loss: 3.5057249069213867
Validation loss: 2.941545573613977

Epoch: 6| Step: 12
Training loss: 3.3400237560272217
Validation loss: 2.9383368927945375

Epoch: 6| Step: 13
Training loss: 3.618271827697754
Validation loss: 2.9413993576521515

Epoch: 56| Step: 0
Training loss: 2.8957009315490723
Validation loss: 2.9420625958391415

Epoch: 6| Step: 1
Training loss: 2.6729087829589844
Validation loss: 2.9421931902567544

Epoch: 6| Step: 2
Training loss: 3.2354164123535156
Validation loss: 2.9432890363918838

Epoch: 6| Step: 3
Training loss: 3.4259278774261475
Validation loss: 2.944708929266981

Epoch: 6| Step: 4
Training loss: 3.4921629428863525
Validation loss: 2.949289834627541

Epoch: 6| Step: 5
Training loss: 3.9830663204193115
Validation loss: 2.944180675732192

Epoch: 6| Step: 6
Training loss: 3.1229658126831055
Validation loss: 2.9390497053823164

Epoch: 6| Step: 7
Training loss: 2.689701557159424
Validation loss: 2.936505425360895

Epoch: 6| Step: 8
Training loss: 2.9157140254974365
Validation loss: 2.939104357073384

Epoch: 6| Step: 9
Training loss: 2.530487537384033
Validation loss: 2.9374708872969433

Epoch: 6| Step: 10
Training loss: 3.265702486038208
Validation loss: 2.9365245373018327

Epoch: 6| Step: 11
Training loss: 2.5783448219299316
Validation loss: 2.9367927274396344

Epoch: 6| Step: 12
Training loss: 2.199092388153076
Validation loss: 2.9363180052849556

Epoch: 6| Step: 13
Training loss: 3.4717884063720703
Validation loss: 2.941586591864145

Epoch: 57| Step: 0
Training loss: 3.44482421875
Validation loss: 2.9429795152397564

Epoch: 6| Step: 1
Training loss: 3.9640889167785645
Validation loss: 2.9444975750420683

Epoch: 6| Step: 2
Training loss: 3.8824172019958496
Validation loss: 2.9451810288172897

Epoch: 6| Step: 3
Training loss: 3.727794647216797
Validation loss: 2.9489781010535454

Epoch: 6| Step: 4
Training loss: 2.7052297592163086
Validation loss: 2.9532193265935427

Epoch: 6| Step: 5
Training loss: 3.336622953414917
Validation loss: 2.9538372690959642

Epoch: 6| Step: 6
Training loss: 2.6370315551757812
Validation loss: 2.97173144484079

Epoch: 6| Step: 7
Training loss: 2.3528528213500977
Validation loss: 2.9659493430968253

Epoch: 6| Step: 8
Training loss: 2.959444999694824
Validation loss: 2.972661349081224

Epoch: 6| Step: 9
Training loss: 2.680656909942627
Validation loss: 2.9551419545245428

Epoch: 6| Step: 10
Training loss: 3.3754000663757324
Validation loss: 2.945308854503016

Epoch: 6| Step: 11
Training loss: 2.2098844051361084
Validation loss: 2.945417352901992

Epoch: 6| Step: 12
Training loss: 2.493072986602783
Validation loss: 2.951494206664383

Epoch: 6| Step: 13
Training loss: 2.2142281532287598
Validation loss: 2.9562942725355907

Epoch: 58| Step: 0
Training loss: 3.1365880966186523
Validation loss: 2.9529163939978487

Epoch: 6| Step: 1
Training loss: 3.4409310817718506
Validation loss: 2.9532272995159192

Epoch: 6| Step: 2
Training loss: 2.8758227825164795
Validation loss: 2.951625257410029

Epoch: 6| Step: 3
Training loss: 3.1051530838012695
Validation loss: 2.9510603438141527

Epoch: 6| Step: 4
Training loss: 3.745652675628662
Validation loss: 2.9449018150247555

Epoch: 6| Step: 5
Training loss: 2.4004435539245605
Validation loss: 2.9382252513721423

Epoch: 6| Step: 6
Training loss: 3.3927700519561768
Validation loss: 2.9347459782836256

Epoch: 6| Step: 7
Training loss: 2.606722116470337
Validation loss: 2.935393225762152

Epoch: 6| Step: 8
Training loss: 2.837489128112793
Validation loss: 2.9439135751416607

Epoch: 6| Step: 9
Training loss: 2.306656837463379
Validation loss: 2.9619118859691005

Epoch: 6| Step: 10
Training loss: 3.719062328338623
Validation loss: 2.9636090135061615

Epoch: 6| Step: 11
Training loss: 2.8666443824768066
Validation loss: 2.9580188387183735

Epoch: 6| Step: 12
Training loss: 2.9982662200927734
Validation loss: 2.9475534346795853

Epoch: 6| Step: 13
Training loss: 2.86356520652771
Validation loss: 2.9349938977149224

Epoch: 59| Step: 0
Training loss: 3.1519765853881836
Validation loss: 2.929275446040656

Epoch: 6| Step: 1
Training loss: 3.3269870281219482
Validation loss: 2.9332248703125985

Epoch: 6| Step: 2
Training loss: 2.6128203868865967
Validation loss: 2.9327137803518646

Epoch: 6| Step: 3
Training loss: 2.9420487880706787
Validation loss: 2.932511975688319

Epoch: 6| Step: 4
Training loss: 2.632322311401367
Validation loss: 2.9403852288440993

Epoch: 6| Step: 5
Training loss: 3.0077571868896484
Validation loss: 2.9440253960189

Epoch: 6| Step: 6
Training loss: 2.756533622741699
Validation loss: 2.9505426165878132

Epoch: 6| Step: 7
Training loss: 3.2161314487457275
Validation loss: 2.9622671834884153

Epoch: 6| Step: 8
Training loss: 3.035861015319824
Validation loss: 2.9580057205692416

Epoch: 6| Step: 9
Training loss: 3.207892417907715
Validation loss: 2.9359322696603756

Epoch: 6| Step: 10
Training loss: 4.192773342132568
Validation loss: 2.9331158104763237

Epoch: 6| Step: 11
Training loss: 2.790428400039673
Validation loss: 2.9319509536989274

Epoch: 6| Step: 12
Training loss: 2.297560214996338
Validation loss: 2.928874328572263

Epoch: 6| Step: 13
Training loss: 3.311051368713379
Validation loss: 2.9251868237731276

Epoch: 60| Step: 0
Training loss: 2.207237720489502
Validation loss: 2.923256602338565

Epoch: 6| Step: 1
Training loss: 2.754206657409668
Validation loss: 2.9308462783854496

Epoch: 6| Step: 2
Training loss: 3.6554813385009766
Validation loss: 2.931176854718116

Epoch: 6| Step: 3
Training loss: 3.3724751472473145
Validation loss: 2.931613063299528

Epoch: 6| Step: 4
Training loss: 3.550875186920166
Validation loss: 2.9293548881366687

Epoch: 6| Step: 5
Training loss: 2.859218120574951
Validation loss: 2.9263556747026342

Epoch: 6| Step: 6
Training loss: 1.7758102416992188
Validation loss: 2.925762789223784

Epoch: 6| Step: 7
Training loss: 3.6225955486297607
Validation loss: 2.927119429393481

Epoch: 6| Step: 8
Training loss: 2.7585854530334473
Validation loss: 2.9243231691339964

Epoch: 6| Step: 9
Training loss: 3.1096689701080322
Validation loss: 2.9214533759701635

Epoch: 6| Step: 10
Training loss: 2.855501890182495
Validation loss: 2.9248111427471204

Epoch: 6| Step: 11
Training loss: 3.4772815704345703
Validation loss: 2.9268132999379146

Epoch: 6| Step: 12
Training loss: 3.5323843955993652
Validation loss: 2.921881401410667

Epoch: 6| Step: 13
Training loss: 2.522737741470337
Validation loss: 2.9223825162456882

Epoch: 61| Step: 0
Training loss: 3.2195825576782227
Validation loss: 2.9212942764323246

Epoch: 6| Step: 1
Training loss: 2.8555800914764404
Validation loss: 2.9228552567061556

Epoch: 6| Step: 2
Training loss: 3.323507070541382
Validation loss: 2.9204979071053128

Epoch: 6| Step: 3
Training loss: 2.5737500190734863
Validation loss: 2.9206460906613256

Epoch: 6| Step: 4
Training loss: 2.991995334625244
Validation loss: 2.918586907848235

Epoch: 6| Step: 5
Training loss: 3.826573133468628
Validation loss: 2.9184948116220455

Epoch: 6| Step: 6
Training loss: 3.4135756492614746
Validation loss: 2.9183843443470616

Epoch: 6| Step: 7
Training loss: 2.784752130508423
Validation loss: 2.919412233496225

Epoch: 6| Step: 8
Training loss: 2.397737979888916
Validation loss: 2.918088138744395

Epoch: 6| Step: 9
Training loss: 2.527324914932251
Validation loss: 2.917816577419158

Epoch: 6| Step: 10
Training loss: 2.918994665145874
Validation loss: 2.923323567195605

Epoch: 6| Step: 11
Training loss: 3.3782248497009277
Validation loss: 2.9182871362214446

Epoch: 6| Step: 12
Training loss: 3.128748893737793
Validation loss: 2.9187408390865532

Epoch: 6| Step: 13
Training loss: 2.5810701847076416
Validation loss: 2.918365245224327

Epoch: 62| Step: 0
Training loss: 4.051699638366699
Validation loss: 2.9222802141661286

Epoch: 6| Step: 1
Training loss: 3.422116279602051
Validation loss: 2.924085153046475

Epoch: 6| Step: 2
Training loss: 3.7821364402770996
Validation loss: 2.924056189034575

Epoch: 6| Step: 3
Training loss: 2.5921411514282227
Validation loss: 2.923904908600674

Epoch: 6| Step: 4
Training loss: 2.3160979747772217
Validation loss: 2.924733236271848

Epoch: 6| Step: 5
Training loss: 3.2285571098327637
Validation loss: 2.9274337471172376

Epoch: 6| Step: 6
Training loss: 2.598231315612793
Validation loss: 2.9226477889604467

Epoch: 6| Step: 7
Training loss: 2.777811050415039
Validation loss: 2.9259607868809856

Epoch: 6| Step: 8
Training loss: 2.9008138179779053
Validation loss: 2.9224367423724105

Epoch: 6| Step: 9
Training loss: 3.150681972503662
Validation loss: 2.923985960663006

Epoch: 6| Step: 10
Training loss: 2.407607078552246
Validation loss: 2.927014389345723

Epoch: 6| Step: 11
Training loss: 2.561495304107666
Validation loss: 2.938868768753544

Epoch: 6| Step: 12
Training loss: 3.3554296493530273
Validation loss: 2.9279955689625075

Epoch: 6| Step: 13
Training loss: 2.888458728790283
Validation loss: 2.918238111721572

Epoch: 63| Step: 0
Training loss: 3.570225477218628
Validation loss: 2.917141622112643

Epoch: 6| Step: 1
Training loss: 3.179866313934326
Validation loss: 2.913823758402178

Epoch: 6| Step: 2
Training loss: 2.0514349937438965
Validation loss: 2.9123918241070164

Epoch: 6| Step: 3
Training loss: 4.245244979858398
Validation loss: 2.9146258933569795

Epoch: 6| Step: 4
Training loss: 2.0993072986602783
Validation loss: 2.9135163804536224

Epoch: 6| Step: 5
Training loss: 3.4606428146362305
Validation loss: 2.914906273606003

Epoch: 6| Step: 6
Training loss: 2.6112465858459473
Validation loss: 2.9171953047475507

Epoch: 6| Step: 7
Training loss: 2.792001247406006
Validation loss: 2.916397753582206

Epoch: 6| Step: 8
Training loss: 2.0535969734191895
Validation loss: 2.9169314779261106

Epoch: 6| Step: 9
Training loss: 2.975583553314209
Validation loss: 2.921487982555102

Epoch: 6| Step: 10
Training loss: 3.495434284210205
Validation loss: 2.9217582620600218

Epoch: 6| Step: 11
Training loss: 3.2825562953948975
Validation loss: 2.919605332036172

Epoch: 6| Step: 12
Training loss: 3.344350814819336
Validation loss: 2.914104917997955

Epoch: 6| Step: 13
Training loss: 2.8096673488616943
Validation loss: 2.914832589446857

Epoch: 64| Step: 0
Training loss: 3.064457416534424
Validation loss: 2.9158740966550765

Epoch: 6| Step: 1
Training loss: 3.0595321655273438
Validation loss: 2.9148304000977547

Epoch: 6| Step: 2
Training loss: 2.566537618637085
Validation loss: 2.9163044011721047

Epoch: 6| Step: 3
Training loss: 3.940640926361084
Validation loss: 2.9237130636809976

Epoch: 6| Step: 4
Training loss: 2.621073007583618
Validation loss: 2.9148188124420824

Epoch: 6| Step: 5
Training loss: 2.8838908672332764
Validation loss: 2.910901797715054

Epoch: 6| Step: 6
Training loss: 3.858898639678955
Validation loss: 2.9192949418098695

Epoch: 6| Step: 7
Training loss: 3.4747042655944824
Validation loss: 2.9083118900176017

Epoch: 6| Step: 8
Training loss: 3.339756965637207
Validation loss: 2.9098361666484545

Epoch: 6| Step: 9
Training loss: 3.141737937927246
Validation loss: 2.910353575983355

Epoch: 6| Step: 10
Training loss: 2.5349068641662598
Validation loss: 2.909700714131837

Epoch: 6| Step: 11
Training loss: 2.655576229095459
Validation loss: 2.909345080775599

Epoch: 6| Step: 12
Training loss: 1.9474377632141113
Validation loss: 2.9089462962201846

Epoch: 6| Step: 13
Training loss: 2.882467031478882
Validation loss: 2.9099381149456067

Epoch: 65| Step: 0
Training loss: 3.531372547149658
Validation loss: 2.906326268308906

Epoch: 6| Step: 1
Training loss: 2.992036819458008
Validation loss: 2.9080542825883433

Epoch: 6| Step: 2
Training loss: 2.88909912109375
Validation loss: 2.9069100605544222

Epoch: 6| Step: 3
Training loss: 2.8307414054870605
Validation loss: 2.9092549175344486

Epoch: 6| Step: 4
Training loss: 2.5816686153411865
Validation loss: 2.905753630463795

Epoch: 6| Step: 5
Training loss: 2.853119134902954
Validation loss: 2.9035591284434

Epoch: 6| Step: 6
Training loss: 2.8997714519500732
Validation loss: 2.904982166905557

Epoch: 6| Step: 7
Training loss: 2.7438297271728516
Validation loss: 2.9069118602301485

Epoch: 6| Step: 8
Training loss: 2.7344789505004883
Validation loss: 2.903494724663355

Epoch: 6| Step: 9
Training loss: 4.321695327758789
Validation loss: 2.9047748068327546

Epoch: 6| Step: 10
Training loss: 2.780994176864624
Validation loss: 2.9000643581472416

Epoch: 6| Step: 11
Training loss: 3.1561923027038574
Validation loss: 2.9020307371693272

Epoch: 6| Step: 12
Training loss: 3.4273734092712402
Validation loss: 2.9009759708117415

Epoch: 6| Step: 13
Training loss: 1.6715295314788818
Validation loss: 2.901205344866681

Epoch: 66| Step: 0
Training loss: 3.0416316986083984
Validation loss: 2.9023155678984938

Epoch: 6| Step: 1
Training loss: 2.911590576171875
Validation loss: 2.899706473914526

Epoch: 6| Step: 2
Training loss: 3.095410108566284
Validation loss: 2.9009191836080244

Epoch: 6| Step: 3
Training loss: 3.6990175247192383
Validation loss: 2.899886623505623

Epoch: 6| Step: 4
Training loss: 2.9166066646575928
Validation loss: 2.900987402085335

Epoch: 6| Step: 5
Training loss: 2.026054859161377
Validation loss: 2.9002857772252892

Epoch: 6| Step: 6
Training loss: 2.890803575515747
Validation loss: 2.9004795474390828

Epoch: 6| Step: 7
Training loss: 3.3489158153533936
Validation loss: 2.9007127387549287

Epoch: 6| Step: 8
Training loss: 2.1830368041992188
Validation loss: 2.9018563019332064

Epoch: 6| Step: 9
Training loss: 3.8184802532196045
Validation loss: 2.900742200113112

Epoch: 6| Step: 10
Training loss: 3.9204208850860596
Validation loss: 2.8984074054225797

Epoch: 6| Step: 11
Training loss: 2.5039563179016113
Validation loss: 2.898722028219572

Epoch: 6| Step: 12
Training loss: 2.861100196838379
Validation loss: 2.899398919074766

Epoch: 6| Step: 13
Training loss: 2.4690022468566895
Validation loss: 2.9003733563166794

Epoch: 67| Step: 0
Training loss: 2.5917372703552246
Validation loss: 2.8978488573464016

Epoch: 6| Step: 1
Training loss: 1.7412660121917725
Validation loss: 2.896830807449997

Epoch: 6| Step: 2
Training loss: 3.7069895267486572
Validation loss: 2.9000564339340373

Epoch: 6| Step: 3
Training loss: 3.525285482406616
Validation loss: 2.896179827310706

Epoch: 6| Step: 4
Training loss: 3.227726697921753
Validation loss: 2.8947657487725698

Epoch: 6| Step: 5
Training loss: 3.5856664180755615
Validation loss: 2.9030495407760784

Epoch: 6| Step: 6
Training loss: 2.4770898818969727
Validation loss: 2.901762600867979

Epoch: 6| Step: 7
Training loss: 3.2709643840789795
Validation loss: 2.9006328634036485

Epoch: 6| Step: 8
Training loss: 2.3200244903564453
Validation loss: 2.901051031645908

Epoch: 6| Step: 9
Training loss: 2.895569324493408
Validation loss: 2.904435611540271

Epoch: 6| Step: 10
Training loss: 3.4907312393188477
Validation loss: 2.902484945071641

Epoch: 6| Step: 11
Training loss: 2.8190250396728516
Validation loss: 2.904210659765428

Epoch: 6| Step: 12
Training loss: 2.9747281074523926
Validation loss: 2.898694246046005

Epoch: 6| Step: 13
Training loss: 3.449258327484131
Validation loss: 2.8982389203963743

Epoch: 68| Step: 0
Training loss: 3.459101915359497
Validation loss: 2.895642940716077

Epoch: 6| Step: 1
Training loss: 1.969809651374817
Validation loss: 2.896296811360185

Epoch: 6| Step: 2
Training loss: 2.951533794403076
Validation loss: 2.89732119857624

Epoch: 6| Step: 3
Training loss: 2.8180196285247803
Validation loss: 2.8976035707740375

Epoch: 6| Step: 4
Training loss: 3.1832566261291504
Validation loss: 2.903926880128922

Epoch: 6| Step: 5
Training loss: 3.237182140350342
Validation loss: 2.9183122727178756

Epoch: 6| Step: 6
Training loss: 3.0253262519836426
Validation loss: 2.9239823151660222

Epoch: 6| Step: 7
Training loss: 2.938843250274658
Validation loss: 2.918663053102391

Epoch: 6| Step: 8
Training loss: 3.2651760578155518
Validation loss: 2.899465690376938

Epoch: 6| Step: 9
Training loss: 3.3501110076904297
Validation loss: 2.8941182910755114

Epoch: 6| Step: 10
Training loss: 2.819255828857422
Validation loss: 2.8957951427787862

Epoch: 6| Step: 11
Training loss: 3.20997953414917
Validation loss: 2.891410817382156

Epoch: 6| Step: 12
Training loss: 2.637976884841919
Validation loss: 2.8933714717947026

Epoch: 6| Step: 13
Training loss: 3.0406980514526367
Validation loss: 2.8941170515552646

Epoch: 69| Step: 0
Training loss: 3.6227352619171143
Validation loss: 2.8945567300242763

Epoch: 6| Step: 1
Training loss: 2.749014377593994
Validation loss: 2.8921463104986374

Epoch: 6| Step: 2
Training loss: 3.805994749069214
Validation loss: 2.8958285803435952

Epoch: 6| Step: 3
Training loss: 2.8373117446899414
Validation loss: 2.8986855681224535

Epoch: 6| Step: 4
Training loss: 2.17635440826416
Validation loss: 2.900368188017158

Epoch: 6| Step: 5
Training loss: 2.736447811126709
Validation loss: 2.9168136453115814

Epoch: 6| Step: 6
Training loss: 2.0834763050079346
Validation loss: 2.9072685190426406

Epoch: 6| Step: 7
Training loss: 2.4486184120178223
Validation loss: 2.9143178257890927

Epoch: 6| Step: 8
Training loss: 3.6034278869628906
Validation loss: 2.906747023264567

Epoch: 6| Step: 9
Training loss: 3.1503186225891113
Validation loss: 2.900178891356273

Epoch: 6| Step: 10
Training loss: 3.8873348236083984
Validation loss: 2.894439725465672

Epoch: 6| Step: 11
Training loss: 2.8331284523010254
Validation loss: 2.8943405100094375

Epoch: 6| Step: 12
Training loss: 2.7916507720947266
Validation loss: 2.890774216703189

Epoch: 6| Step: 13
Training loss: 3.281538963317871
Validation loss: 2.8880765489352647

Epoch: 70| Step: 0
Training loss: 3.556067705154419
Validation loss: 2.8887552087024977

Epoch: 6| Step: 1
Training loss: 3.263887405395508
Validation loss: 2.887963315492035

Epoch: 6| Step: 2
Training loss: 2.9801247119903564
Validation loss: 2.88801053262526

Epoch: 6| Step: 3
Training loss: 2.768158197402954
Validation loss: 2.8872951769059703

Epoch: 6| Step: 4
Training loss: 3.107938051223755
Validation loss: 2.8884779560950493

Epoch: 6| Step: 5
Training loss: 2.6817708015441895
Validation loss: 2.890872293902982

Epoch: 6| Step: 6
Training loss: 3.558887004852295
Validation loss: 2.889179268190938

Epoch: 6| Step: 7
Training loss: 2.824817180633545
Validation loss: 2.8882771615059144

Epoch: 6| Step: 8
Training loss: 2.281157970428467
Validation loss: 2.885938467517976

Epoch: 6| Step: 9
Training loss: 2.9552812576293945
Validation loss: 2.8866152865912325

Epoch: 6| Step: 10
Training loss: 2.307539701461792
Validation loss: 2.8858070783717658

Epoch: 6| Step: 11
Training loss: 3.267645835876465
Validation loss: 2.8824128207340034

Epoch: 6| Step: 12
Training loss: 2.951150894165039
Validation loss: 2.885550791217435

Epoch: 6| Step: 13
Training loss: 3.506636619567871
Validation loss: 2.886298156553699

Epoch: 71| Step: 0
Training loss: 2.7210617065429688
Validation loss: 2.881631834532625

Epoch: 6| Step: 1
Training loss: 3.1362228393554688
Validation loss: 2.8843944252178235

Epoch: 6| Step: 2
Training loss: 3.2040185928344727
Validation loss: 2.880911739923621

Epoch: 6| Step: 3
Training loss: 2.480853796005249
Validation loss: 2.882617719711796

Epoch: 6| Step: 4
Training loss: 2.4343295097351074
Validation loss: 2.882841007683867

Epoch: 6| Step: 5
Training loss: 2.707303047180176
Validation loss: 2.8817162206096034

Epoch: 6| Step: 6
Training loss: 2.161297082901001
Validation loss: 2.8828309453943723

Epoch: 6| Step: 7
Training loss: 3.3447318077087402
Validation loss: 2.880278423268308

Epoch: 6| Step: 8
Training loss: 2.373734951019287
Validation loss: 2.881565104248703

Epoch: 6| Step: 9
Training loss: 4.158987045288086
Validation loss: 2.88254221793144

Epoch: 6| Step: 10
Training loss: 2.5623865127563477
Validation loss: 2.881701184857276

Epoch: 6| Step: 11
Training loss: 3.180077314376831
Validation loss: 2.881068404002856

Epoch: 6| Step: 12
Training loss: 3.2659921646118164
Validation loss: 2.8832178474754415

Epoch: 6| Step: 13
Training loss: 4.796850681304932
Validation loss: 2.881001874964724

Epoch: 72| Step: 0
Training loss: 3.036344289779663
Validation loss: 2.883078762280044

Epoch: 6| Step: 1
Training loss: 3.2410314083099365
Validation loss: 2.8792520825580885

Epoch: 6| Step: 2
Training loss: 3.2113490104675293
Validation loss: 2.878099374873664

Epoch: 6| Step: 3
Training loss: 3.8315396308898926
Validation loss: 2.8781655808930755

Epoch: 6| Step: 4
Training loss: 2.0679054260253906
Validation loss: 2.878902284047937

Epoch: 6| Step: 5
Training loss: 2.3633012771606445
Validation loss: 2.880270819510183

Epoch: 6| Step: 6
Training loss: 3.4811477661132812
Validation loss: 2.881557972200455

Epoch: 6| Step: 7
Training loss: 3.2672014236450195
Validation loss: 2.883483668809296

Epoch: 6| Step: 8
Training loss: 3.257603168487549
Validation loss: 2.8826006407378824

Epoch: 6| Step: 9
Training loss: 3.1093292236328125
Validation loss: 2.8822992745266167

Epoch: 6| Step: 10
Training loss: 2.9727625846862793
Validation loss: 2.879279669894967

Epoch: 6| Step: 11
Training loss: 2.6456475257873535
Validation loss: 2.882613225649762

Epoch: 6| Step: 12
Training loss: 2.4931905269622803
Validation loss: 2.8833945489698842

Epoch: 6| Step: 13
Training loss: 2.53999924659729
Validation loss: 2.8805554348935365

Epoch: 73| Step: 0
Training loss: 2.934126853942871
Validation loss: 2.882644186737717

Epoch: 6| Step: 1
Training loss: 2.739769697189331
Validation loss: 2.879567943593507

Epoch: 6| Step: 2
Training loss: 2.8228211402893066
Validation loss: 2.880809194298201

Epoch: 6| Step: 3
Training loss: 3.453859806060791
Validation loss: 2.8837574374291206

Epoch: 6| Step: 4
Training loss: 3.4553940296173096
Validation loss: 2.885821993632983

Epoch: 6| Step: 5
Training loss: 3.467684268951416
Validation loss: 2.8826795624148462

Epoch: 6| Step: 6
Training loss: 2.8737287521362305
Validation loss: 2.8809602811772335

Epoch: 6| Step: 7
Training loss: 2.8506007194519043
Validation loss: 2.8831402409461235

Epoch: 6| Step: 8
Training loss: 2.849168300628662
Validation loss: 2.8788516905999955

Epoch: 6| Step: 9
Training loss: 1.992354393005371
Validation loss: 2.882632747773201

Epoch: 6| Step: 10
Training loss: 3.253706216812134
Validation loss: 2.880712439936976

Epoch: 6| Step: 11
Training loss: 3.3117127418518066
Validation loss: 2.8845039260002876

Epoch: 6| Step: 12
Training loss: 2.287470817565918
Validation loss: 2.8814441004107074

Epoch: 6| Step: 13
Training loss: 3.581181049346924
Validation loss: 2.883660231867144

Epoch: 74| Step: 0
Training loss: 3.0817782878875732
Validation loss: 2.8826755041717202

Epoch: 6| Step: 1
Training loss: 2.5995121002197266
Validation loss: 2.8921442852225354

Epoch: 6| Step: 2
Training loss: 2.5427396297454834
Validation loss: 2.9021005399765505

Epoch: 6| Step: 3
Training loss: 3.4658172130584717
Validation loss: 2.898044963036814

Epoch: 6| Step: 4
Training loss: 2.8068175315856934
Validation loss: 2.9078436897646998

Epoch: 6| Step: 5
Training loss: 2.5907669067382812
Validation loss: 2.892772618160453

Epoch: 6| Step: 6
Training loss: 3.5845651626586914
Validation loss: 2.8855820625059065

Epoch: 6| Step: 7
Training loss: 2.8760335445404053
Validation loss: 2.880869468053182

Epoch: 6| Step: 8
Training loss: 2.7247743606567383
Validation loss: 2.8795890346650155

Epoch: 6| Step: 9
Training loss: 3.046135902404785
Validation loss: 2.8920350715678227

Epoch: 6| Step: 10
Training loss: 3.166440963745117
Validation loss: 2.899743608249131

Epoch: 6| Step: 11
Training loss: 2.8693830966949463
Validation loss: 2.89114103522352

Epoch: 6| Step: 12
Training loss: 3.0737571716308594
Validation loss: 2.891915803314537

Epoch: 6| Step: 13
Training loss: 3.425774335861206
Validation loss: 2.878728938359086

Epoch: 75| Step: 0
Training loss: 2.7938342094421387
Validation loss: 2.876094789915187

Epoch: 6| Step: 1
Training loss: 3.401714563369751
Validation loss: 2.8760787184520433

Epoch: 6| Step: 2
Training loss: 2.7632899284362793
Validation loss: 2.873476330951978

Epoch: 6| Step: 3
Training loss: 3.0335137844085693
Validation loss: 2.875821687841928

Epoch: 6| Step: 4
Training loss: 3.0207161903381348
Validation loss: 2.8720303273970083

Epoch: 6| Step: 5
Training loss: 3.1107304096221924
Validation loss: 2.8808394247485745

Epoch: 6| Step: 6
Training loss: 2.9489078521728516
Validation loss: 2.88142728805542

Epoch: 6| Step: 7
Training loss: 2.5192413330078125
Validation loss: 2.882922277655653

Epoch: 6| Step: 8
Training loss: 2.4303884506225586
Validation loss: 2.898210164039366

Epoch: 6| Step: 9
Training loss: 2.4225263595581055
Validation loss: 2.914862181550713

Epoch: 6| Step: 10
Training loss: 3.742398977279663
Validation loss: 2.881031784960019

Epoch: 6| Step: 11
Training loss: 3.254284381866455
Validation loss: 2.8719309017222416

Epoch: 6| Step: 12
Training loss: 3.5941755771636963
Validation loss: 2.874693262961603

Epoch: 6| Step: 13
Training loss: 2.1410703659057617
Validation loss: 2.8740245373018327

Epoch: 76| Step: 0
Training loss: 2.406299591064453
Validation loss: 2.873311201731364

Epoch: 6| Step: 1
Training loss: 2.0049099922180176
Validation loss: 2.874874558500064

Epoch: 6| Step: 2
Training loss: 2.9753975868225098
Validation loss: 2.8757234081145255

Epoch: 6| Step: 3
Training loss: 3.61993408203125
Validation loss: 2.8732385225193475

Epoch: 6| Step: 4
Training loss: 3.019688367843628
Validation loss: 2.8696276731388544

Epoch: 6| Step: 5
Training loss: 3.5650386810302734
Validation loss: 2.8692560477923323

Epoch: 6| Step: 6
Training loss: 4.233517646789551
Validation loss: 2.873470239741828

Epoch: 6| Step: 7
Training loss: 2.624476671218872
Validation loss: 2.8672669164596067

Epoch: 6| Step: 8
Training loss: 3.76194429397583
Validation loss: 2.8733578907546176

Epoch: 6| Step: 9
Training loss: 2.572295665740967
Validation loss: 2.8713193042303926

Epoch: 6| Step: 10
Training loss: 3.1461095809936523
Validation loss: 2.870494945074922

Epoch: 6| Step: 11
Training loss: 2.2528557777404785
Validation loss: 2.875893280070315

Epoch: 6| Step: 12
Training loss: 2.3828177452087402
Validation loss: 2.8720567841683664

Epoch: 6| Step: 13
Training loss: 2.929367780685425
Validation loss: 2.8790092980989845

Epoch: 77| Step: 0
Training loss: 2.1344518661499023
Validation loss: 2.8794348214262273

Epoch: 6| Step: 1
Training loss: 2.4929847717285156
Validation loss: 2.883031242637224

Epoch: 6| Step: 2
Training loss: 3.692648410797119
Validation loss: 2.884795332467684

Epoch: 6| Step: 3
Training loss: 3.2870776653289795
Validation loss: 2.883795053728165

Epoch: 6| Step: 4
Training loss: 2.9626619815826416
Validation loss: 2.8848980652388705

Epoch: 6| Step: 5
Training loss: 3.1681807041168213
Validation loss: 2.8878899005151566

Epoch: 6| Step: 6
Training loss: 3.1939549446105957
Validation loss: 2.882653531207833

Epoch: 6| Step: 7
Training loss: 3.5093657970428467
Validation loss: 2.870659610276581

Epoch: 6| Step: 8
Training loss: 3.1823582649230957
Validation loss: 2.867074369102396

Epoch: 6| Step: 9
Training loss: 3.037736177444458
Validation loss: 2.8608279484574513

Epoch: 6| Step: 10
Training loss: 2.922555923461914
Validation loss: 2.865338968974288

Epoch: 6| Step: 11
Training loss: 2.6741321086883545
Validation loss: 2.859969357008575

Epoch: 6| Step: 12
Training loss: 1.8784809112548828
Validation loss: 2.863695077998664

Epoch: 6| Step: 13
Training loss: 3.654771089553833
Validation loss: 2.8662194154595815

Epoch: 78| Step: 0
Training loss: 2.8710572719573975
Validation loss: 2.8690832994317494

Epoch: 6| Step: 1
Training loss: 2.7121119499206543
Validation loss: 2.8716890606828915

Epoch: 6| Step: 2
Training loss: 2.739405632019043
Validation loss: 2.8688739551010953

Epoch: 6| Step: 3
Training loss: 2.7813761234283447
Validation loss: 2.8687126431413876

Epoch: 6| Step: 4
Training loss: 3.3611323833465576
Validation loss: 2.8717614425125944

Epoch: 6| Step: 5
Training loss: 3.4355032444000244
Validation loss: 2.8666116781132196

Epoch: 6| Step: 6
Training loss: 2.841829776763916
Validation loss: 2.8666929429577244

Epoch: 6| Step: 7
Training loss: 2.8127517700195312
Validation loss: 2.8683905165682555

Epoch: 6| Step: 8
Training loss: 2.524178981781006
Validation loss: 2.8655353284651235

Epoch: 6| Step: 9
Training loss: 3.259061813354492
Validation loss: 2.8668145133603002

Epoch: 6| Step: 10
Training loss: 2.9412336349487305
Validation loss: 2.8662854958606023

Epoch: 6| Step: 11
Training loss: 3.5165843963623047
Validation loss: 2.8651653053939983

Epoch: 6| Step: 12
Training loss: 2.9509291648864746
Validation loss: 2.8645199293731363

Epoch: 6| Step: 13
Training loss: 2.6095168590545654
Validation loss: 2.8643338039357173

Epoch: 79| Step: 0
Training loss: 2.733008861541748
Validation loss: 2.8623770924024683

Epoch: 6| Step: 1
Training loss: 2.2269625663757324
Validation loss: 2.8589264321070846

Epoch: 6| Step: 2
Training loss: 3.003973960876465
Validation loss: 2.858350992202759

Epoch: 6| Step: 3
Training loss: 2.450892448425293
Validation loss: 2.8619198978588147

Epoch: 6| Step: 4
Training loss: 2.917111396789551
Validation loss: 2.859691155854092

Epoch: 6| Step: 5
Training loss: 2.889228582382202
Validation loss: 2.8575088080539497

Epoch: 6| Step: 6
Training loss: 2.243088722229004
Validation loss: 2.8572759935932774

Epoch: 6| Step: 7
Training loss: 2.9515671730041504
Validation loss: 2.857877016067505

Epoch: 6| Step: 8
Training loss: 3.566392421722412
Validation loss: 2.8610459886571413

Epoch: 6| Step: 9
Training loss: 3.822648286819458
Validation loss: 2.85803234705361

Epoch: 6| Step: 10
Training loss: 3.272010564804077
Validation loss: 2.8616706709707938

Epoch: 6| Step: 11
Training loss: 3.232839345932007
Validation loss: 2.858466245794809

Epoch: 6| Step: 12
Training loss: 3.260662794113159
Validation loss: 2.855472574951828

Epoch: 6| Step: 13
Training loss: 2.807915210723877
Validation loss: 2.857431968053182

Epoch: 80| Step: 0
Training loss: 2.61889910697937
Validation loss: 2.859662578951928

Epoch: 6| Step: 1
Training loss: 2.742152690887451
Validation loss: 2.856558681816183

Epoch: 6| Step: 2
Training loss: 2.957639455795288
Validation loss: 2.8550084919057865

Epoch: 6| Step: 3
Training loss: 3.01163911819458
Validation loss: 2.8567700514229397

Epoch: 6| Step: 4
Training loss: 3.4390869140625
Validation loss: 2.8535005789931103

Epoch: 6| Step: 5
Training loss: 2.718895673751831
Validation loss: 2.8537865531060005

Epoch: 6| Step: 6
Training loss: 1.9461421966552734
Validation loss: 2.8561166999160603

Epoch: 6| Step: 7
Training loss: 3.534424066543579
Validation loss: 2.855124586371965

Epoch: 6| Step: 8
Training loss: 2.500546932220459
Validation loss: 2.8558623995832217

Epoch: 6| Step: 9
Training loss: 3.8487300872802734
Validation loss: 2.8544484979362896

Epoch: 6| Step: 10
Training loss: 2.2461795806884766
Validation loss: 2.8580420478697746

Epoch: 6| Step: 11
Training loss: 3.370059013366699
Validation loss: 2.8554835293882634

Epoch: 6| Step: 12
Training loss: 3.20662260055542
Validation loss: 2.8588297802914857

Epoch: 6| Step: 13
Training loss: 3.462029457092285
Validation loss: 2.8599329789479575

Epoch: 81| Step: 0
Training loss: 3.308096408843994
Validation loss: 2.8573173476803686

Epoch: 6| Step: 1
Training loss: 2.5385937690734863
Validation loss: 2.8613802104867916

Epoch: 6| Step: 2
Training loss: 3.0886051654815674
Validation loss: 2.856030325735769

Epoch: 6| Step: 3
Training loss: 3.622366428375244
Validation loss: 2.856458943377259

Epoch: 6| Step: 4
Training loss: 2.730961322784424
Validation loss: 2.8578429427198184

Epoch: 6| Step: 5
Training loss: 3.3924343585968018
Validation loss: 2.8592597489715903

Epoch: 6| Step: 6
Training loss: 3.2306182384490967
Validation loss: 2.8575657388215423

Epoch: 6| Step: 7
Training loss: 2.388824462890625
Validation loss: 2.8577751549341346

Epoch: 6| Step: 8
Training loss: 3.1218807697296143
Validation loss: 2.8533092493652017

Epoch: 6| Step: 9
Training loss: 2.9790241718292236
Validation loss: 2.856734698818576

Epoch: 6| Step: 10
Training loss: 2.976414680480957
Validation loss: 2.851389395293369

Epoch: 6| Step: 11
Training loss: 2.309983253479004
Validation loss: 2.851881757859261

Epoch: 6| Step: 12
Training loss: 2.8382344245910645
Validation loss: 2.8578180241328415

Epoch: 6| Step: 13
Training loss: 2.6849334239959717
Validation loss: 2.859169508821221

Epoch: 82| Step: 0
Training loss: 2.4894487857818604
Validation loss: 2.8579279248432448

Epoch: 6| Step: 1
Training loss: 3.0559749603271484
Validation loss: 2.8526811625367854

Epoch: 6| Step: 2
Training loss: 2.8913559913635254
Validation loss: 2.8565144179969706

Epoch: 6| Step: 3
Training loss: 3.6598901748657227
Validation loss: 2.8574038320972073

Epoch: 6| Step: 4
Training loss: 2.193899154663086
Validation loss: 2.8455352629384687

Epoch: 6| Step: 5
Training loss: 3.532723903656006
Validation loss: 2.85304686843708

Epoch: 6| Step: 6
Training loss: 2.661113977432251
Validation loss: 2.850736815442321

Epoch: 6| Step: 7
Training loss: 3.5938429832458496
Validation loss: 2.8555460437651603

Epoch: 6| Step: 8
Training loss: 3.4302825927734375
Validation loss: 2.8537009121269308

Epoch: 6| Step: 9
Training loss: 3.202150344848633
Validation loss: 2.8548502922058105

Epoch: 6| Step: 10
Training loss: 2.5470657348632812
Validation loss: 2.8574556791654198

Epoch: 6| Step: 11
Training loss: 2.4963388442993164
Validation loss: 2.8557146544097574

Epoch: 6| Step: 12
Training loss: 2.216750144958496
Validation loss: 2.857499550747615

Epoch: 6| Step: 13
Training loss: 3.624784231185913
Validation loss: 2.861919613294704

Epoch: 83| Step: 0
Training loss: 2.45999813079834
Validation loss: 2.8615545739409742

Epoch: 6| Step: 1
Training loss: 2.3464741706848145
Validation loss: 2.8609042859846547

Epoch: 6| Step: 2
Training loss: 3.830695152282715
Validation loss: 2.858285055365614

Epoch: 6| Step: 3
Training loss: 3.626483201980591
Validation loss: 2.8600960444378596

Epoch: 6| Step: 4
Training loss: 2.7138476371765137
Validation loss: 2.853728453318278

Epoch: 6| Step: 5
Training loss: 2.4831790924072266
Validation loss: 2.85038322787131

Epoch: 6| Step: 6
Training loss: 3.494934558868408
Validation loss: 2.84185363400367

Epoch: 6| Step: 7
Training loss: 2.7015624046325684
Validation loss: 2.846279505760439

Epoch: 6| Step: 8
Training loss: 3.425100803375244
Validation loss: 2.8495820824817946

Epoch: 6| Step: 9
Training loss: 2.364284038543701
Validation loss: 2.849966969541324

Epoch: 6| Step: 10
Training loss: 3.0843677520751953
Validation loss: 2.8471050928997736

Epoch: 6| Step: 11
Training loss: 2.7210543155670166
Validation loss: 2.8470456266915924

Epoch: 6| Step: 12
Training loss: 2.5655410289764404
Validation loss: 2.847583863043016

Epoch: 6| Step: 13
Training loss: 3.773860454559326
Validation loss: 2.847126373680689

Epoch: 84| Step: 0
Training loss: 2.2730586528778076
Validation loss: 2.846245247830627

Epoch: 6| Step: 1
Training loss: 3.2850403785705566
Validation loss: 2.8476753696318595

Epoch: 6| Step: 2
Training loss: 2.656940460205078
Validation loss: 2.8442725366161716

Epoch: 6| Step: 3
Training loss: 3.464507579803467
Validation loss: 2.8427689331834034

Epoch: 6| Step: 4
Training loss: 2.5743136405944824
Validation loss: 2.844440039768014

Epoch: 6| Step: 5
Training loss: 3.5457329750061035
Validation loss: 2.84521395673034

Epoch: 6| Step: 6
Training loss: 3.6352906227111816
Validation loss: 2.8456016381581626

Epoch: 6| Step: 7
Training loss: 2.599606990814209
Validation loss: 2.849890088522306

Epoch: 6| Step: 8
Training loss: 2.4173316955566406
Validation loss: 2.849751217390901

Epoch: 6| Step: 9
Training loss: 3.824699878692627
Validation loss: 2.851106823131602

Epoch: 6| Step: 10
Training loss: 2.749136209487915
Validation loss: 2.852608678161457

Epoch: 6| Step: 11
Training loss: 2.994436502456665
Validation loss: 2.845400566695839

Epoch: 6| Step: 12
Training loss: 3.005673885345459
Validation loss: 2.8421141588559715

Epoch: 6| Step: 13
Training loss: 1.6946723461151123
Validation loss: 2.8394725861087924

Epoch: 85| Step: 0
Training loss: 3.8665225505828857
Validation loss: 2.8466807257744575

Epoch: 6| Step: 1
Training loss: 2.952326774597168
Validation loss: 2.843382650806058

Epoch: 6| Step: 2
Training loss: 3.481264352798462
Validation loss: 2.842335788152551

Epoch: 6| Step: 3
Training loss: 2.3903746604919434
Validation loss: 2.8402191003163657

Epoch: 6| Step: 4
Training loss: 2.526237964630127
Validation loss: 2.838184730980986

Epoch: 6| Step: 5
Training loss: 2.033234119415283
Validation loss: 2.8403605902066795

Epoch: 6| Step: 6
Training loss: 3.295602321624756
Validation loss: 2.8438263734181723

Epoch: 6| Step: 7
Training loss: 2.794358968734741
Validation loss: 2.85670328909351

Epoch: 6| Step: 8
Training loss: 3.3370158672332764
Validation loss: 2.8533246260817333

Epoch: 6| Step: 9
Training loss: 3.6584348678588867
Validation loss: 2.8598763917082097

Epoch: 6| Step: 10
Training loss: 2.628566265106201
Validation loss: 2.849331135390907

Epoch: 6| Step: 11
Training loss: 3.2516143321990967
Validation loss: 2.8530565128531507

Epoch: 6| Step: 12
Training loss: 2.208968162536621
Validation loss: 2.843094607835175

Epoch: 6| Step: 13
Training loss: 2.69451904296875
Validation loss: 2.840085232129661

Epoch: 86| Step: 0
Training loss: 3.7228446006774902
Validation loss: 2.837253265483405

Epoch: 6| Step: 1
Training loss: 2.970578908920288
Validation loss: 2.8367995472364527

Epoch: 6| Step: 2
Training loss: 3.0397684574127197
Validation loss: 2.8419947444751696

Epoch: 6| Step: 3
Training loss: 2.7732834815979004
Validation loss: 2.840927247078188

Epoch: 6| Step: 4
Training loss: 3.683539390563965
Validation loss: 2.8440668198370163

Epoch: 6| Step: 5
Training loss: 1.8699676990509033
Validation loss: 2.84549984880673

Epoch: 6| Step: 6
Training loss: 2.607292652130127
Validation loss: 2.8434926514984458

Epoch: 6| Step: 7
Training loss: 3.1313939094543457
Validation loss: 2.8447080735237367

Epoch: 6| Step: 8
Training loss: 2.814685106277466
Validation loss: 2.842529389166063

Epoch: 6| Step: 9
Training loss: 3.189309597015381
Validation loss: 2.8458381109340216

Epoch: 6| Step: 10
Training loss: 2.383981466293335
Validation loss: 2.848520658349478

Epoch: 6| Step: 11
Training loss: 2.9079599380493164
Validation loss: 2.8478768820403726

Epoch: 6| Step: 12
Training loss: 3.4008021354675293
Validation loss: 2.8448032127913607

Epoch: 6| Step: 13
Training loss: 2.3814191818237305
Validation loss: 2.84463160012358

Epoch: 87| Step: 0
Training loss: 2.577671766281128
Validation loss: 2.837277438050957

Epoch: 6| Step: 1
Training loss: 3.0371341705322266
Validation loss: 2.837731376771004

Epoch: 6| Step: 2
Training loss: 2.781625747680664
Validation loss: 2.8445387066051526

Epoch: 6| Step: 3
Training loss: 2.9564027786254883
Validation loss: 2.8563072758336223

Epoch: 6| Step: 4
Training loss: 2.0706329345703125
Validation loss: 2.8604969721968456

Epoch: 6| Step: 5
Training loss: 4.104198455810547
Validation loss: 2.8684863864734607

Epoch: 6| Step: 6
Training loss: 2.050480365753174
Validation loss: 2.8734454493368826

Epoch: 6| Step: 7
Training loss: 3.4762473106384277
Validation loss: 2.874761084074615

Epoch: 6| Step: 8
Training loss: 2.372241497039795
Validation loss: 2.8563567822979343

Epoch: 6| Step: 9
Training loss: 3.4312143325805664
Validation loss: 2.8486351505402596

Epoch: 6| Step: 10
Training loss: 2.8362669944763184
Validation loss: 2.8501695766243884

Epoch: 6| Step: 11
Training loss: 3.118746280670166
Validation loss: 2.8495608401554886

Epoch: 6| Step: 12
Training loss: 3.3608388900756836
Validation loss: 2.8528651140069448

Epoch: 6| Step: 13
Training loss: 3.015451669692993
Validation loss: 2.855472433951593

Epoch: 88| Step: 0
Training loss: 2.080432415008545
Validation loss: 2.857647652267128

Epoch: 6| Step: 1
Training loss: 2.6702356338500977
Validation loss: 2.8482923764054493

Epoch: 6| Step: 2
Training loss: 3.5151028633117676
Validation loss: 2.8443043642146613

Epoch: 6| Step: 3
Training loss: 2.401461362838745
Validation loss: 2.842303358098512

Epoch: 6| Step: 4
Training loss: 3.5902998447418213
Validation loss: 2.839839496920186

Epoch: 6| Step: 5
Training loss: 3.8765788078308105
Validation loss: 2.840313378200736

Epoch: 6| Step: 6
Training loss: 3.1747689247131348
Validation loss: 2.8382776373176166

Epoch: 6| Step: 7
Training loss: 2.4379982948303223
Validation loss: 2.844557169945009

Epoch: 6| Step: 8
Training loss: 2.5247514247894287
Validation loss: 2.842967615332655

Epoch: 6| Step: 9
Training loss: 3.698263168334961
Validation loss: 2.8536909626376246

Epoch: 6| Step: 10
Training loss: 2.3595476150512695
Validation loss: 2.8606757322947183

Epoch: 6| Step: 11
Training loss: 2.736482620239258
Validation loss: 2.901046658074984

Epoch: 6| Step: 12
Training loss: 2.4846835136413574
Validation loss: 2.9013119102806173

Epoch: 6| Step: 13
Training loss: 4.125516891479492
Validation loss: 2.8851462230887464

Epoch: 89| Step: 0
Training loss: 2.5958080291748047
Validation loss: 2.8467849787845405

Epoch: 6| Step: 1
Training loss: 2.9885504245758057
Validation loss: 2.8387658339674755

Epoch: 6| Step: 2
Training loss: 3.242676258087158
Validation loss: 2.8306526240482124

Epoch: 6| Step: 3
Training loss: 2.975515604019165
Validation loss: 2.8348999715620473

Epoch: 6| Step: 4
Training loss: 2.2877748012542725
Validation loss: 2.8455589048324095

Epoch: 6| Step: 5
Training loss: 3.2445685863494873
Validation loss: 2.8499273638571463

Epoch: 6| Step: 6
Training loss: 2.979546546936035
Validation loss: 2.8542522307365172

Epoch: 6| Step: 7
Training loss: 2.574553966522217
Validation loss: 2.85197933771277

Epoch: 6| Step: 8
Training loss: 2.8252792358398438
Validation loss: 2.8505361259624524

Epoch: 6| Step: 9
Training loss: 3.1215004920959473
Validation loss: 2.8516998444834063

Epoch: 6| Step: 10
Training loss: 3.886479377746582
Validation loss: 2.850379846429312

Epoch: 6| Step: 11
Training loss: 2.5669989585876465
Validation loss: 2.8516154494336856

Epoch: 6| Step: 12
Training loss: 2.8018388748168945
Validation loss: 2.8503676127361994

Epoch: 6| Step: 13
Training loss: 3.0710809230804443
Validation loss: 2.8455029046663673

Epoch: 90| Step: 0
Training loss: 2.8217835426330566
Validation loss: 2.839220472561416

Epoch: 6| Step: 1
Training loss: 3.2817914485931396
Validation loss: 2.840533282167168

Epoch: 6| Step: 2
Training loss: 3.369818687438965
Validation loss: 2.836610801758305

Epoch: 6| Step: 3
Training loss: 2.5410749912261963
Validation loss: 2.8348496601145756

Epoch: 6| Step: 4
Training loss: 2.634775161743164
Validation loss: 2.8316386745822046

Epoch: 6| Step: 5
Training loss: 3.1682639122009277
Validation loss: 2.838357053777223

Epoch: 6| Step: 6
Training loss: 2.2692699432373047
Validation loss: 2.834520939857729

Epoch: 6| Step: 7
Training loss: 2.943783760070801
Validation loss: 2.847613993511405

Epoch: 6| Step: 8
Training loss: 2.6360342502593994
Validation loss: 2.8412621918544976

Epoch: 6| Step: 9
Training loss: 3.1600053310394287
Validation loss: 2.8444432827734176

Epoch: 6| Step: 10
Training loss: 3.4963479042053223
Validation loss: 2.8363148063741703

Epoch: 6| Step: 11
Training loss: 2.4441957473754883
Validation loss: 2.8297806657770628

Epoch: 6| Step: 12
Training loss: 3.4615840911865234
Validation loss: 2.826450453009657

Epoch: 6| Step: 13
Training loss: 2.7816145420074463
Validation loss: 2.8251039238386255

Epoch: 91| Step: 0
Training loss: 3.8533318042755127
Validation loss: 2.826169280595677

Epoch: 6| Step: 1
Training loss: 2.831021308898926
Validation loss: 2.82594568498673

Epoch: 6| Step: 2
Training loss: 2.356506586074829
Validation loss: 2.831926079206569

Epoch: 6| Step: 3
Training loss: 3.208865165710449
Validation loss: 2.830332084368634

Epoch: 6| Step: 4
Training loss: 2.8304834365844727
Validation loss: 2.8341436334835586

Epoch: 6| Step: 5
Training loss: 3.1359899044036865
Validation loss: 2.828226084350258

Epoch: 6| Step: 6
Training loss: 2.454834461212158
Validation loss: 2.8385606042800413

Epoch: 6| Step: 7
Training loss: 3.4300246238708496
Validation loss: 2.8352063343089116

Epoch: 6| Step: 8
Training loss: 2.4444057941436768
Validation loss: 2.8293645433200303

Epoch: 6| Step: 9
Training loss: 1.8463661670684814
Validation loss: 2.832253784261724

Epoch: 6| Step: 10
Training loss: 3.564919948577881
Validation loss: 2.8347774064669045

Epoch: 6| Step: 11
Training loss: 2.8341500759124756
Validation loss: 2.8391650261417514

Epoch: 6| Step: 12
Training loss: 2.7402868270874023
Validation loss: 2.838883320490519

Epoch: 6| Step: 13
Training loss: 4.039747714996338
Validation loss: 2.829219953988188

Epoch: 92| Step: 0
Training loss: 3.526414394378662
Validation loss: 2.829037795784653

Epoch: 6| Step: 1
Training loss: 3.5608081817626953
Validation loss: 2.834684979531073

Epoch: 6| Step: 2
Training loss: 2.53053879737854
Validation loss: 2.828249539098432

Epoch: 6| Step: 3
Training loss: 2.68170428276062
Validation loss: 2.825065169283139

Epoch: 6| Step: 4
Training loss: 3.3353934288024902
Validation loss: 2.8246814256073325

Epoch: 6| Step: 5
Training loss: 2.494377613067627
Validation loss: 2.826311337050571

Epoch: 6| Step: 6
Training loss: 2.2636258602142334
Validation loss: 2.8273596891792874

Epoch: 6| Step: 7
Training loss: 2.038726329803467
Validation loss: 2.8303218272424515

Epoch: 6| Step: 8
Training loss: 2.941329002380371
Validation loss: 2.833004766894925

Epoch: 6| Step: 9
Training loss: 3.3026204109191895
Validation loss: 2.8334833114377913

Epoch: 6| Step: 10
Training loss: 3.3353023529052734
Validation loss: 2.8217303804171983

Epoch: 6| Step: 11
Training loss: 2.546668529510498
Validation loss: 2.8196653807035057

Epoch: 6| Step: 12
Training loss: 3.072772979736328
Validation loss: 2.8252898877666843

Epoch: 6| Step: 13
Training loss: 3.6721179485321045
Validation loss: 2.825807548338367

Epoch: 93| Step: 0
Training loss: 2.430541753768921
Validation loss: 2.826569744335708

Epoch: 6| Step: 1
Training loss: 2.546626329421997
Validation loss: 2.822953498491677

Epoch: 6| Step: 2
Training loss: 3.054553747177124
Validation loss: 2.820539323232507

Epoch: 6| Step: 3
Training loss: 4.176120758056641
Validation loss: 2.8221293623729418

Epoch: 6| Step: 4
Training loss: 3.014270782470703
Validation loss: 2.8183511713499665

Epoch: 6| Step: 5
Training loss: 2.1627490520477295
Validation loss: 2.8204821566099763

Epoch: 6| Step: 6
Training loss: 3.4731392860412598
Validation loss: 2.821265930770546

Epoch: 6| Step: 7
Training loss: 2.473407506942749
Validation loss: 2.8202549975405455

Epoch: 6| Step: 8
Training loss: 3.3540549278259277
Validation loss: 2.8239562293534637

Epoch: 6| Step: 9
Training loss: 2.2806429862976074
Validation loss: 2.822129859719225

Epoch: 6| Step: 10
Training loss: 3.0524487495422363
Validation loss: 2.8227286748988654

Epoch: 6| Step: 11
Training loss: 3.4478020668029785
Validation loss: 2.826679470718548

Epoch: 6| Step: 12
Training loss: 2.5531487464904785
Validation loss: 2.8260783969715075

Epoch: 6| Step: 13
Training loss: 2.865260124206543
Validation loss: 2.822407886546145

Epoch: 94| Step: 0
Training loss: 2.368190288543701
Validation loss: 2.825598511644589

Epoch: 6| Step: 1
Training loss: 3.157817840576172
Validation loss: 2.8248373000852522

Epoch: 6| Step: 2
Training loss: 3.652862548828125
Validation loss: 2.822588341210478

Epoch: 6| Step: 3
Training loss: 3.2532906532287598
Validation loss: 2.817386906634095

Epoch: 6| Step: 4
Training loss: 2.569272518157959
Validation loss: 2.819215629690437

Epoch: 6| Step: 5
Training loss: 2.6531739234924316
Validation loss: 2.8186482229540424

Epoch: 6| Step: 6
Training loss: 2.846665859222412
Validation loss: 2.8180324954371296

Epoch: 6| Step: 7
Training loss: 2.635878801345825
Validation loss: 2.82008203383415

Epoch: 6| Step: 8
Training loss: 3.453805923461914
Validation loss: 2.816944094114406

Epoch: 6| Step: 9
Training loss: 2.829036235809326
Validation loss: 2.8183422396259923

Epoch: 6| Step: 10
Training loss: 2.8192596435546875
Validation loss: 2.8179935742450017

Epoch: 6| Step: 11
Training loss: 3.1188292503356934
Validation loss: 2.8173323497977307

Epoch: 6| Step: 12
Training loss: 2.617922067642212
Validation loss: 2.8185163467161116

Epoch: 6| Step: 13
Training loss: 2.7777345180511475
Validation loss: 2.8216872189634588

Epoch: 95| Step: 0
Training loss: 2.637040376663208
Validation loss: 2.819352134581535

Epoch: 6| Step: 1
Training loss: 2.306016206741333
Validation loss: 2.819727128551852

Epoch: 6| Step: 2
Training loss: 1.9843411445617676
Validation loss: 2.8182474003043225

Epoch: 6| Step: 3
Training loss: 2.9627413749694824
Validation loss: 2.819257551623929

Epoch: 6| Step: 4
Training loss: 2.5253939628601074
Validation loss: 2.816617278642552

Epoch: 6| Step: 5
Training loss: 3.3023791313171387
Validation loss: 2.8221555832893617

Epoch: 6| Step: 6
Training loss: 2.4915475845336914
Validation loss: 2.8230849978744343

Epoch: 6| Step: 7
Training loss: 2.7019810676574707
Validation loss: 2.821039266483758

Epoch: 6| Step: 8
Training loss: 3.2899019718170166
Validation loss: 2.815446948492399

Epoch: 6| Step: 9
Training loss: 3.6757493019104004
Validation loss: 2.8189572108689176

Epoch: 6| Step: 10
Training loss: 2.9918999671936035
Validation loss: 2.8200898042289158

Epoch: 6| Step: 11
Training loss: 3.23047137260437
Validation loss: 2.8212693173398256

Epoch: 6| Step: 12
Training loss: 3.267890453338623
Validation loss: 2.815832625153244

Epoch: 6| Step: 13
Training loss: 3.6813478469848633
Validation loss: 2.813667792145924

Epoch: 96| Step: 0
Training loss: 3.3163790702819824
Validation loss: 2.8179813149154826

Epoch: 6| Step: 1
Training loss: 3.1028308868408203
Validation loss: 2.813332765333114

Epoch: 6| Step: 2
Training loss: 3.0666909217834473
Validation loss: 2.816573768533686

Epoch: 6| Step: 3
Training loss: 2.9417362213134766
Validation loss: 2.818473172444169

Epoch: 6| Step: 4
Training loss: 3.157686233520508
Validation loss: 2.8211984634399414

Epoch: 6| Step: 5
Training loss: 3.1866843700408936
Validation loss: 2.8219431779717885

Epoch: 6| Step: 6
Training loss: 2.885279655456543
Validation loss: 2.81877464120106

Epoch: 6| Step: 7
Training loss: 3.108884334564209
Validation loss: 2.8213662973014255

Epoch: 6| Step: 8
Training loss: 2.58247447013855
Validation loss: 2.819808536960233

Epoch: 6| Step: 9
Training loss: 2.9597103595733643
Validation loss: 2.8265943706676526

Epoch: 6| Step: 10
Training loss: 2.9347615242004395
Validation loss: 2.8298979625906995

Epoch: 6| Step: 11
Training loss: 2.139467239379883
Validation loss: 2.837432461400186

Epoch: 6| Step: 12
Training loss: 3.180513381958008
Validation loss: 2.855760669195524

Epoch: 6| Step: 13
Training loss: 1.5236356258392334
Validation loss: 2.869577976965135

Epoch: 97| Step: 0
Training loss: 3.265629291534424
Validation loss: 2.8406486870140157

Epoch: 6| Step: 1
Training loss: 2.4298644065856934
Validation loss: 2.827754948728828

Epoch: 6| Step: 2
Training loss: 2.94748854637146
Validation loss: 2.8153678345423874

Epoch: 6| Step: 3
Training loss: 3.305824041366577
Validation loss: 2.8158715437817317

Epoch: 6| Step: 4
Training loss: 2.9740071296691895
Validation loss: 2.815353167954312

Epoch: 6| Step: 5
Training loss: 2.552849769592285
Validation loss: 2.8210067672114216

Epoch: 6| Step: 6
Training loss: 3.2047414779663086
Validation loss: 2.8186644251628588

Epoch: 6| Step: 7
Training loss: 2.865976095199585
Validation loss: 2.810393125780167

Epoch: 6| Step: 8
Training loss: 3.0509886741638184
Validation loss: 2.812337939457227

Epoch: 6| Step: 9
Training loss: 2.150923490524292
Validation loss: 2.8090063653966433

Epoch: 6| Step: 10
Training loss: 2.644869565963745
Validation loss: 2.81278645864097

Epoch: 6| Step: 11
Training loss: 3.0082998275756836
Validation loss: 2.815846630322036

Epoch: 6| Step: 12
Training loss: 2.9471616744995117
Validation loss: 2.819142290340957

Epoch: 6| Step: 13
Training loss: 3.876295804977417
Validation loss: 2.8151734618730444

Epoch: 98| Step: 0
Training loss: 2.070735454559326
Validation loss: 2.815478627399732

Epoch: 6| Step: 1
Training loss: 3.3903141021728516
Validation loss: 2.808432294476417

Epoch: 6| Step: 2
Training loss: 3.2349133491516113
Validation loss: 2.8097526770766064

Epoch: 6| Step: 3
Training loss: 2.594759464263916
Validation loss: 2.8116288082574004

Epoch: 6| Step: 4
Training loss: 2.397132635116577
Validation loss: 2.816430732768069

Epoch: 6| Step: 5
Training loss: 2.816039562225342
Validation loss: 2.808418514908001

Epoch: 6| Step: 6
Training loss: 2.8919851779937744
Validation loss: 2.810816116230462

Epoch: 6| Step: 7
Training loss: 2.365476131439209
Validation loss: 2.8112386042071926

Epoch: 6| Step: 8
Training loss: 3.202730894088745
Validation loss: 2.816686191866475

Epoch: 6| Step: 9
Training loss: 3.1898717880249023
Validation loss: 2.8086935499662995

Epoch: 6| Step: 10
Training loss: 3.4417028427124023
Validation loss: 2.807079751004455

Epoch: 6| Step: 11
Training loss: 2.0958642959594727
Validation loss: 2.8081671191800024

Epoch: 6| Step: 12
Training loss: 3.747744083404541
Validation loss: 2.8058480165338002

Epoch: 6| Step: 13
Training loss: 3.551669120788574
Validation loss: 2.8064921056070635

Epoch: 99| Step: 0
Training loss: 3.41208815574646
Validation loss: 2.807490107833698

Epoch: 6| Step: 1
Training loss: 2.965726137161255
Validation loss: 2.804802058845438

Epoch: 6| Step: 2
Training loss: 2.546269416809082
Validation loss: 2.812614656263782

Epoch: 6| Step: 3
Training loss: 2.3966727256774902
Validation loss: 2.8101391433387675

Epoch: 6| Step: 4
Training loss: 2.330232620239258
Validation loss: 2.8069133809817735

Epoch: 6| Step: 5
Training loss: 2.4336743354797363
Validation loss: 2.807056542365782

Epoch: 6| Step: 6
Training loss: 3.632772922515869
Validation loss: 2.8107539325632076

Epoch: 6| Step: 7
Training loss: 3.2497434616088867
Validation loss: 2.8120505245782996

Epoch: 6| Step: 8
Training loss: 2.5972900390625
Validation loss: 2.8103652718246623

Epoch: 6| Step: 9
Training loss: 2.5794405937194824
Validation loss: 2.811981257571969

Epoch: 6| Step: 10
Training loss: 1.8693368434906006
Validation loss: 2.8083678624963246

Epoch: 6| Step: 11
Training loss: 4.002115249633789
Validation loss: 2.81236425522835

Epoch: 6| Step: 12
Training loss: 3.8075361251831055
Validation loss: 2.812368162216679

Epoch: 6| Step: 13
Training loss: 2.7037973403930664
Validation loss: 2.8133540025321384

Epoch: 100| Step: 0
Training loss: 3.0292820930480957
Validation loss: 2.80648099735219

Epoch: 6| Step: 1
Training loss: 2.948075771331787
Validation loss: 2.8148809376583306

Epoch: 6| Step: 2
Training loss: 1.9559000730514526
Validation loss: 2.807231672348515

Epoch: 6| Step: 3
Training loss: 2.4032235145568848
Validation loss: 2.8184498125506985

Epoch: 6| Step: 4
Training loss: 4.283953666687012
Validation loss: 2.819310265202676

Epoch: 6| Step: 5
Training loss: 2.613859176635742
Validation loss: 2.8196344708883636

Epoch: 6| Step: 6
Training loss: 1.6890556812286377
Validation loss: 2.8223639765093402

Epoch: 6| Step: 7
Training loss: 2.8078713417053223
Validation loss: 2.822951747525123

Epoch: 6| Step: 8
Training loss: 3.540144443511963
Validation loss: 2.8238161404927573

Epoch: 6| Step: 9
Training loss: 3.3911938667297363
Validation loss: 2.8348765065593104

Epoch: 6| Step: 10
Training loss: 3.066075325012207
Validation loss: 2.837890681400094

Epoch: 6| Step: 11
Training loss: 2.8398520946502686
Validation loss: 2.8276879043989283

Epoch: 6| Step: 12
Training loss: 3.5141398906707764
Validation loss: 2.8239105106681905

Epoch: 6| Step: 13
Training loss: 2.3483006954193115
Validation loss: 2.8104146654887865

Epoch: 101| Step: 0
Training loss: 2.9162516593933105
Validation loss: 2.810115655263265

Epoch: 6| Step: 1
Training loss: 1.679808497428894
Validation loss: 2.823815502146239

Epoch: 6| Step: 2
Training loss: 3.1734542846679688
Validation loss: 2.837563189127112

Epoch: 6| Step: 3
Training loss: 3.733720302581787
Validation loss: 2.8498122922835813

Epoch: 6| Step: 4
Training loss: 3.118561267852783
Validation loss: 2.837473274559103

Epoch: 6| Step: 5
Training loss: 3.255500316619873
Validation loss: 2.8345435691136185

Epoch: 6| Step: 6
Training loss: 1.6623010635375977
Validation loss: 2.8307936524832122

Epoch: 6| Step: 7
Training loss: 2.7626073360443115
Validation loss: 2.83398848964322

Epoch: 6| Step: 8
Training loss: 3.3433492183685303
Validation loss: 2.8207330549916914

Epoch: 6| Step: 9
Training loss: 3.374065637588501
Validation loss: 2.8135985635942027

Epoch: 6| Step: 10
Training loss: 3.7140517234802246
Validation loss: 2.812145112663187

Epoch: 6| Step: 11
Training loss: 2.1227641105651855
Validation loss: 2.8116590079440864

Epoch: 6| Step: 12
Training loss: 2.9733364582061768
Validation loss: 2.805118768445907

Epoch: 6| Step: 13
Training loss: 3.0919387340545654
Validation loss: 2.802184033137496

Epoch: 102| Step: 0
Training loss: 3.3448987007141113
Validation loss: 2.79832100611861

Epoch: 6| Step: 1
Training loss: 2.015228271484375
Validation loss: 2.7955880165100098

Epoch: 6| Step: 2
Training loss: 3.1853156089782715
Validation loss: 2.794576368024272

Epoch: 6| Step: 3
Training loss: 2.8690125942230225
Validation loss: 2.795875354479718

Epoch: 6| Step: 4
Training loss: 4.030887603759766
Validation loss: 2.7950661836131925

Epoch: 6| Step: 5
Training loss: 2.981192111968994
Validation loss: 2.8028446551292174

Epoch: 6| Step: 6
Training loss: 2.9541239738464355
Validation loss: 2.808399982349847

Epoch: 6| Step: 7
Training loss: 3.1087894439697266
Validation loss: 2.811699528847971

Epoch: 6| Step: 8
Training loss: 2.6432981491088867
Validation loss: 2.813793577173705

Epoch: 6| Step: 9
Training loss: 3.358619213104248
Validation loss: 2.801484174625848

Epoch: 6| Step: 10
Training loss: 2.577404260635376
Validation loss: 2.8037013341021795

Epoch: 6| Step: 11
Training loss: 2.539811611175537
Validation loss: 2.792139253308696

Epoch: 6| Step: 12
Training loss: 2.6918582916259766
Validation loss: 2.7914314398201565

Epoch: 6| Step: 13
Training loss: 2.0311155319213867
Validation loss: 2.7921642334230485

Epoch: 103| Step: 0
Training loss: 2.7372233867645264
Validation loss: 2.79147236065198

Epoch: 6| Step: 1
Training loss: 1.605553388595581
Validation loss: 2.795284983932331

Epoch: 6| Step: 2
Training loss: 3.612245559692383
Validation loss: 2.796074503211565

Epoch: 6| Step: 3
Training loss: 3.374882459640503
Validation loss: 2.7968269727563344

Epoch: 6| Step: 4
Training loss: 3.2715094089508057
Validation loss: 2.798760788415068

Epoch: 6| Step: 5
Training loss: 2.9582550525665283
Validation loss: 2.8044798169084775

Epoch: 6| Step: 6
Training loss: 2.8465490341186523
Validation loss: 2.801003045933221

Epoch: 6| Step: 7
Training loss: 3.551518440246582
Validation loss: 2.80689170283656

Epoch: 6| Step: 8
Training loss: 2.3649845123291016
Validation loss: 2.804834414553899

Epoch: 6| Step: 9
Training loss: 3.0628652572631836
Validation loss: 2.809387401867938

Epoch: 6| Step: 10
Training loss: 2.63724946975708
Validation loss: 2.8083501323576896

Epoch: 6| Step: 11
Training loss: 2.1559789180755615
Validation loss: 2.809494838919691

Epoch: 6| Step: 12
Training loss: 3.443152904510498
Validation loss: 2.81035384567835

Epoch: 6| Step: 13
Training loss: 3.050936460494995
Validation loss: 2.8127062038708757

Epoch: 104| Step: 0
Training loss: 3.1204190254211426
Validation loss: 2.8077197587618263

Epoch: 6| Step: 1
Training loss: 2.514716625213623
Validation loss: 2.797169913527786

Epoch: 6| Step: 2
Training loss: 2.728771209716797
Validation loss: 2.7944240288067888

Epoch: 6| Step: 3
Training loss: 3.616830825805664
Validation loss: 2.792525355533887

Epoch: 6| Step: 4
Training loss: 2.8025059700012207
Validation loss: 2.790326984979773

Epoch: 6| Step: 5
Training loss: 3.074214458465576
Validation loss: 2.7899140055461595

Epoch: 6| Step: 6
Training loss: 3.4418225288391113
Validation loss: 2.7876078287760415

Epoch: 6| Step: 7
Training loss: 3.0748062133789062
Validation loss: 2.7872064959618355

Epoch: 6| Step: 8
Training loss: 2.843980312347412
Validation loss: 2.786978070453931

Epoch: 6| Step: 9
Training loss: 2.384883165359497
Validation loss: 2.788266271673223

Epoch: 6| Step: 10
Training loss: 2.774883270263672
Validation loss: 2.794757525126139

Epoch: 6| Step: 11
Training loss: 2.12857723236084
Validation loss: 2.787486663428686

Epoch: 6| Step: 12
Training loss: 3.7762351036071777
Validation loss: 2.7918555839087373

Epoch: 6| Step: 13
Training loss: 1.9218698740005493
Validation loss: 2.794952723287767

Epoch: 105| Step: 0
Training loss: 3.761493682861328
Validation loss: 2.790699535800565

Epoch: 6| Step: 1
Training loss: 2.481736183166504
Validation loss: 2.787005219408261

Epoch: 6| Step: 2
Training loss: 2.8983583450317383
Validation loss: 2.7932293671433643

Epoch: 6| Step: 3
Training loss: 2.1886277198791504
Validation loss: 2.790214036100654

Epoch: 6| Step: 4
Training loss: 2.52847957611084
Validation loss: 2.7926393683238695

Epoch: 6| Step: 5
Training loss: 2.605804443359375
Validation loss: 2.802832708563856

Epoch: 6| Step: 6
Training loss: 2.4974403381347656
Validation loss: 2.819900951077861

Epoch: 6| Step: 7
Training loss: 2.6655094623565674
Validation loss: 2.817565502658967

Epoch: 6| Step: 8
Training loss: 3.5363662242889404
Validation loss: 2.8191974650147142

Epoch: 6| Step: 9
Training loss: 3.1883912086486816
Validation loss: 2.8060999147353636

Epoch: 6| Step: 10
Training loss: 3.3795528411865234
Validation loss: 2.7959818609299196

Epoch: 6| Step: 11
Training loss: 2.8802554607391357
Validation loss: 2.7943183863034813

Epoch: 6| Step: 12
Training loss: 2.7771525382995605
Validation loss: 2.790696346631614

Epoch: 6| Step: 13
Training loss: 3.285076856613159
Validation loss: 2.7878640826030443

Epoch: 106| Step: 0
Training loss: 3.456991672515869
Validation loss: 2.788817277518652

Epoch: 6| Step: 1
Training loss: 2.776024580001831
Validation loss: 2.787697712580363

Epoch: 6| Step: 2
Training loss: 2.588557243347168
Validation loss: 2.7885485028707855

Epoch: 6| Step: 3
Training loss: 4.09036111831665
Validation loss: 2.7888262887154855

Epoch: 6| Step: 4
Training loss: 2.7095956802368164
Validation loss: 2.7895593438097226

Epoch: 6| Step: 5
Training loss: 2.2660975456237793
Validation loss: 2.7932990571503997

Epoch: 6| Step: 6
Training loss: 2.222667932510376
Validation loss: 2.7916480315628873

Epoch: 6| Step: 7
Training loss: 2.2415826320648193
Validation loss: 2.7897011926097255

Epoch: 6| Step: 8
Training loss: 2.8961215019226074
Validation loss: 2.7930533334773076

Epoch: 6| Step: 9
Training loss: 3.2252516746520996
Validation loss: 2.791956781059183

Epoch: 6| Step: 10
Training loss: 2.884428024291992
Validation loss: 2.799645734089677

Epoch: 6| Step: 11
Training loss: 2.9477028846740723
Validation loss: 2.79743714486399

Epoch: 6| Step: 12
Training loss: 3.022233247756958
Validation loss: 2.7911683077453286

Epoch: 6| Step: 13
Training loss: 3.1744778156280518
Validation loss: 2.7941711051489717

Epoch: 107| Step: 0
Training loss: 1.937173843383789
Validation loss: 2.7955944461207234

Epoch: 6| Step: 1
Training loss: 3.1935338973999023
Validation loss: 2.813787519290883

Epoch: 6| Step: 2
Training loss: 2.662818670272827
Validation loss: 2.810281333102975

Epoch: 6| Step: 3
Training loss: 3.0328965187072754
Validation loss: 2.8322721168559086

Epoch: 6| Step: 4
Training loss: 3.392155885696411
Validation loss: 2.818989405068018

Epoch: 6| Step: 5
Training loss: 2.3809356689453125
Validation loss: 2.811365471091322

Epoch: 6| Step: 6
Training loss: 3.760220527648926
Validation loss: 2.799821927983274

Epoch: 6| Step: 7
Training loss: 2.385385513305664
Validation loss: 2.805650839241602

Epoch: 6| Step: 8
Training loss: 4.033394813537598
Validation loss: 2.7994203567504883

Epoch: 6| Step: 9
Training loss: 3.592310667037964
Validation loss: 2.7915891857557398

Epoch: 6| Step: 10
Training loss: 2.2580366134643555
Validation loss: 2.784709927856281

Epoch: 6| Step: 11
Training loss: 2.8146064281463623
Validation loss: 2.78793397513769

Epoch: 6| Step: 12
Training loss: 2.205259084701538
Validation loss: 2.787448401092201

Epoch: 6| Step: 13
Training loss: 2.4539248943328857
Validation loss: 2.7880347313419467

Epoch: 108| Step: 0
Training loss: 3.5487747192382812
Validation loss: 2.791327688001817

Epoch: 6| Step: 1
Training loss: 3.035832405090332
Validation loss: 2.790983171873195

Epoch: 6| Step: 2
Training loss: 3.0963099002838135
Validation loss: 2.7885494437268985

Epoch: 6| Step: 3
Training loss: 2.7596347332000732
Validation loss: 2.7894101271065335

Epoch: 6| Step: 4
Training loss: 2.020244598388672
Validation loss: 2.7908552487691245

Epoch: 6| Step: 5
Training loss: 2.5452699661254883
Validation loss: 2.7882955151219524

Epoch: 6| Step: 6
Training loss: 3.461871385574341
Validation loss: 2.783907946719918

Epoch: 6| Step: 7
Training loss: 4.01676082611084
Validation loss: 2.7884652640229914

Epoch: 6| Step: 8
Training loss: 3.290679454803467
Validation loss: 2.7861266059260212

Epoch: 6| Step: 9
Training loss: 2.6915040016174316
Validation loss: 2.7860210839138237

Epoch: 6| Step: 10
Training loss: 2.977243185043335
Validation loss: 2.7804569967331423

Epoch: 6| Step: 11
Training loss: 2.0887820720672607
Validation loss: 2.785253091525006

Epoch: 6| Step: 12
Training loss: 2.3169944286346436
Validation loss: 2.7803714429178545

Epoch: 6| Step: 13
Training loss: 2.321187734603882
Validation loss: 2.779097100739838

Epoch: 109| Step: 0
Training loss: 2.8163371086120605
Validation loss: 2.7780605977581394

Epoch: 6| Step: 1
Training loss: 3.5162062644958496
Validation loss: 2.7824035536858345

Epoch: 6| Step: 2
Training loss: 2.687443256378174
Validation loss: 2.781162208126437

Epoch: 6| Step: 3
Training loss: 2.6502907276153564
Validation loss: 2.802464838950865

Epoch: 6| Step: 4
Training loss: 2.474008560180664
Validation loss: 2.8362259813534316

Epoch: 6| Step: 5
Training loss: 3.7097573280334473
Validation loss: 2.8542218080130954

Epoch: 6| Step: 6
Training loss: 2.3885107040405273
Validation loss: 2.8592194126498316

Epoch: 6| Step: 7
Training loss: 2.2230064868927
Validation loss: 2.8574304144869567

Epoch: 6| Step: 8
Training loss: 3.6043038368225098
Validation loss: 2.839199484035533

Epoch: 6| Step: 9
Training loss: 2.5526697635650635
Validation loss: 2.827523828834616

Epoch: 6| Step: 10
Training loss: 2.9970595836639404
Validation loss: 2.810793533120104

Epoch: 6| Step: 11
Training loss: 2.8421378135681152
Validation loss: 2.7910427816452517

Epoch: 6| Step: 12
Training loss: 3.3504276275634766
Validation loss: 2.7854405551828365

Epoch: 6| Step: 13
Training loss: 2.508608818054199
Validation loss: 2.7835602016859156

Epoch: 110| Step: 0
Training loss: 2.7717678546905518
Validation loss: 2.7904170713117047

Epoch: 6| Step: 1
Training loss: 2.3617749214172363
Validation loss: 2.7877510798874723

Epoch: 6| Step: 2
Training loss: 2.250333786010742
Validation loss: 2.788008174588603

Epoch: 6| Step: 3
Training loss: 2.5542659759521484
Validation loss: 2.784055702147945

Epoch: 6| Step: 4
Training loss: 3.1547722816467285
Validation loss: 2.7996335285966114

Epoch: 6| Step: 5
Training loss: 3.208451747894287
Validation loss: 2.8049088344779065

Epoch: 6| Step: 6
Training loss: 2.949294090270996
Validation loss: 2.797998338617304

Epoch: 6| Step: 7
Training loss: 2.7628331184387207
Validation loss: 2.7909226673905567

Epoch: 6| Step: 8
Training loss: 2.9791197776794434
Validation loss: 2.7865595920111543

Epoch: 6| Step: 9
Training loss: 2.8296570777893066
Validation loss: 2.7806578477223716

Epoch: 6| Step: 10
Training loss: 2.8790817260742188
Validation loss: 2.778310606556554

Epoch: 6| Step: 11
Training loss: 3.2904858589172363
Validation loss: 2.783555482023506

Epoch: 6| Step: 12
Training loss: 3.23067045211792
Validation loss: 2.792432205651396

Epoch: 6| Step: 13
Training loss: 3.4906551837921143
Validation loss: 2.799086570739746

Epoch: 111| Step: 0
Training loss: 2.941988945007324
Validation loss: 2.794635372777139

Epoch: 6| Step: 1
Training loss: 2.310122013092041
Validation loss: 2.7738062822690575

Epoch: 6| Step: 2
Training loss: 2.865802526473999
Validation loss: 2.77459620147623

Epoch: 6| Step: 3
Training loss: 2.9176266193389893
Validation loss: 2.776283215450984

Epoch: 6| Step: 4
Training loss: 2.987316846847534
Validation loss: 2.7744461028806624

Epoch: 6| Step: 5
Training loss: 2.651984214782715
Validation loss: 2.7807716733665875

Epoch: 6| Step: 6
Training loss: 2.9164390563964844
Validation loss: 2.77855864391532

Epoch: 6| Step: 7
Training loss: 2.4793567657470703
Validation loss: 2.774286893106276

Epoch: 6| Step: 8
Training loss: 3.137451410293579
Validation loss: 2.7795696925091486

Epoch: 6| Step: 9
Training loss: 3.021280288696289
Validation loss: 2.777472183268557

Epoch: 6| Step: 10
Training loss: 2.800459384918213
Validation loss: 2.7813122221218642

Epoch: 6| Step: 11
Training loss: 3.501009225845337
Validation loss: 2.7875831075893935

Epoch: 6| Step: 12
Training loss: 3.2908077239990234
Validation loss: 2.7999260528113252

Epoch: 6| Step: 13
Training loss: 2.0521974563598633
Validation loss: 2.8024948566190657

Epoch: 112| Step: 0
Training loss: 3.2156906127929688
Validation loss: 2.792576651419363

Epoch: 6| Step: 1
Training loss: 3.0384368896484375
Validation loss: 2.8007767213288175

Epoch: 6| Step: 2
Training loss: 3.0955188274383545
Validation loss: 2.786424672731789

Epoch: 6| Step: 3
Training loss: 2.474968671798706
Validation loss: 2.7726353086451048

Epoch: 6| Step: 4
Training loss: 2.6812856197357178
Validation loss: 2.7733987018626225

Epoch: 6| Step: 5
Training loss: 3.632488965988159
Validation loss: 2.779635288382089

Epoch: 6| Step: 6
Training loss: 2.7125067710876465
Validation loss: 2.7922110813920216

Epoch: 6| Step: 7
Training loss: 2.6494312286376953
Validation loss: 2.805448978177963

Epoch: 6| Step: 8
Training loss: 2.4642977714538574
Validation loss: 2.813370768741895

Epoch: 6| Step: 9
Training loss: 2.74607515335083
Validation loss: 2.8200535799867366

Epoch: 6| Step: 10
Training loss: 2.2495853900909424
Validation loss: 2.840073500910113

Epoch: 6| Step: 11
Training loss: 2.8004705905914307
Validation loss: 2.8339530088568248

Epoch: 6| Step: 12
Training loss: 3.6521143913269043
Validation loss: 2.8349584071866927

Epoch: 6| Step: 13
Training loss: 3.5513761043548584
Validation loss: 2.806642024747787

Epoch: 113| Step: 0
Training loss: 2.7030391693115234
Validation loss: 2.7918822662804716

Epoch: 6| Step: 1
Training loss: 3.4448652267456055
Validation loss: 2.7836780881368988

Epoch: 6| Step: 2
Training loss: 2.1320888996124268
Validation loss: 2.7746556394843647

Epoch: 6| Step: 3
Training loss: 3.1411666870117188
Validation loss: 2.7737036238434496

Epoch: 6| Step: 4
Training loss: 2.1436848640441895
Validation loss: 2.773617708554832

Epoch: 6| Step: 5
Training loss: 2.9926888942718506
Validation loss: 2.785452755548621

Epoch: 6| Step: 6
Training loss: 2.8827004432678223
Validation loss: 2.789917407497283

Epoch: 6| Step: 7
Training loss: 2.906827688217163
Validation loss: 2.8016186683408675

Epoch: 6| Step: 8
Training loss: 3.077378273010254
Validation loss: 2.799682878678845

Epoch: 6| Step: 9
Training loss: 3.1370816230773926
Validation loss: 2.8005765253497708

Epoch: 6| Step: 10
Training loss: 2.5944666862487793
Validation loss: 2.789448312533799

Epoch: 6| Step: 11
Training loss: 2.093226194381714
Validation loss: 2.7780144958085913

Epoch: 6| Step: 12
Training loss: 3.8172993659973145
Validation loss: 2.7704023597060994

Epoch: 6| Step: 13
Training loss: 3.2571299076080322
Validation loss: 2.771089733287852

Epoch: 114| Step: 0
Training loss: 2.3629767894744873
Validation loss: 2.773175270326676

Epoch: 6| Step: 1
Training loss: 3.135575771331787
Validation loss: 2.7893599258956088

Epoch: 6| Step: 2
Training loss: 3.56282901763916
Validation loss: 2.796439481037919

Epoch: 6| Step: 3
Training loss: 2.473912477493286
Validation loss: 2.7860166411246023

Epoch: 6| Step: 4
Training loss: 2.719963550567627
Validation loss: 2.7797899502579884

Epoch: 6| Step: 5
Training loss: 2.8484082221984863
Validation loss: 2.778319325498355

Epoch: 6| Step: 6
Training loss: 3.5627670288085938
Validation loss: 2.7654048447967856

Epoch: 6| Step: 7
Training loss: 2.831665515899658
Validation loss: 2.7627820276444957

Epoch: 6| Step: 8
Training loss: 2.3930134773254395
Validation loss: 2.7675622150462162

Epoch: 6| Step: 9
Training loss: 3.5639374256134033
Validation loss: 2.7650857433196037

Epoch: 6| Step: 10
Training loss: 2.326603412628174
Validation loss: 2.7650396746973835

Epoch: 6| Step: 11
Training loss: 3.1991658210754395
Validation loss: 2.7691372338161675

Epoch: 6| Step: 12
Training loss: 2.2446630001068115
Validation loss: 2.775361445642287

Epoch: 6| Step: 13
Training loss: 3.174004554748535
Validation loss: 2.7737172495934272

Epoch: 115| Step: 0
Training loss: 2.9375295639038086
Validation loss: 2.776719703469225

Epoch: 6| Step: 1
Training loss: 2.10075044631958
Validation loss: 2.770311329954414

Epoch: 6| Step: 2
Training loss: 2.3703060150146484
Validation loss: 2.773888408496816

Epoch: 6| Step: 3
Training loss: 2.387129306793213
Validation loss: 2.777369268478886

Epoch: 6| Step: 4
Training loss: 3.9112279415130615
Validation loss: 2.7777755132285495

Epoch: 6| Step: 5
Training loss: 2.9852731227874756
Validation loss: 2.7718317047242196

Epoch: 6| Step: 6
Training loss: 3.2535669803619385
Validation loss: 2.770440983515914

Epoch: 6| Step: 7
Training loss: 3.518126964569092
Validation loss: 2.7734134915054485

Epoch: 6| Step: 8
Training loss: 2.270303726196289
Validation loss: 2.771108417100804

Epoch: 6| Step: 9
Training loss: 3.1846251487731934
Validation loss: 2.767419481790194

Epoch: 6| Step: 10
Training loss: 2.953371524810791
Validation loss: 2.7650930599499772

Epoch: 6| Step: 11
Training loss: 2.6286628246307373
Validation loss: 2.759576730830695

Epoch: 6| Step: 12
Training loss: 3.6554718017578125
Validation loss: 2.7652428765450754

Epoch: 6| Step: 13
Training loss: 1.5294908285140991
Validation loss: 2.7619983560295513

Epoch: 116| Step: 0
Training loss: 2.2711143493652344
Validation loss: 2.761749482923938

Epoch: 6| Step: 1
Training loss: 3.2651290893554688
Validation loss: 2.7595393401320263

Epoch: 6| Step: 2
Training loss: 3.7013728618621826
Validation loss: 2.7593207795132875

Epoch: 6| Step: 3
Training loss: 2.849820613861084
Validation loss: 2.7592142089720695

Epoch: 6| Step: 4
Training loss: 2.6440701484680176
Validation loss: 2.755277165802576

Epoch: 6| Step: 5
Training loss: 2.8768060207366943
Validation loss: 2.7590549761249172

Epoch: 6| Step: 6
Training loss: 3.0213441848754883
Validation loss: 2.752973771864368

Epoch: 6| Step: 7
Training loss: 1.7413957118988037
Validation loss: 2.7559967758835002

Epoch: 6| Step: 8
Training loss: 3.860013961791992
Validation loss: 2.7568048379754506

Epoch: 6| Step: 9
Training loss: 2.750802755355835
Validation loss: 2.7536643346150718

Epoch: 6| Step: 10
Training loss: 2.75736141204834
Validation loss: 2.756181768191758

Epoch: 6| Step: 11
Training loss: 3.3123373985290527
Validation loss: 2.7546818102559736

Epoch: 6| Step: 12
Training loss: 2.407578945159912
Validation loss: 2.75823300884616

Epoch: 6| Step: 13
Training loss: 2.720651865005493
Validation loss: 2.7540227725941646

Epoch: 117| Step: 0
Training loss: 2.6009347438812256
Validation loss: 2.755354445467713

Epoch: 6| Step: 1
Training loss: 3.5091466903686523
Validation loss: 2.7564504146575928

Epoch: 6| Step: 2
Training loss: 2.3943872451782227
Validation loss: 2.7574291024156796

Epoch: 6| Step: 3
Training loss: 3.5612897872924805
Validation loss: 2.7582272022001204

Epoch: 6| Step: 4
Training loss: 3.1749699115753174
Validation loss: 2.7566286210090882

Epoch: 6| Step: 5
Training loss: 3.34307861328125
Validation loss: 2.756188131147815

Epoch: 6| Step: 6
Training loss: 3.048588275909424
Validation loss: 2.7567389190837903

Epoch: 6| Step: 7
Training loss: 2.7327895164489746
Validation loss: 2.756357508320962

Epoch: 6| Step: 8
Training loss: 3.1574368476867676
Validation loss: 2.7561102374907462

Epoch: 6| Step: 9
Training loss: 2.740253448486328
Validation loss: 2.758349557076731

Epoch: 6| Step: 10
Training loss: 2.1517958641052246
Validation loss: 2.761753341203095

Epoch: 6| Step: 11
Training loss: 3.266599178314209
Validation loss: 2.7568126058065765

Epoch: 6| Step: 12
Training loss: 1.7478394508361816
Validation loss: 2.758233818956601

Epoch: 6| Step: 13
Training loss: 2.458834648132324
Validation loss: 2.7592513458703154

Epoch: 118| Step: 0
Training loss: 2.8904776573181152
Validation loss: 2.7573395544482815

Epoch: 6| Step: 1
Training loss: 3.186163902282715
Validation loss: 2.7604880486765215

Epoch: 6| Step: 2
Training loss: 2.63857364654541
Validation loss: 2.7604272109206005

Epoch: 6| Step: 3
Training loss: 2.211293935775757
Validation loss: 2.7600202611697617

Epoch: 6| Step: 4
Training loss: 3.643551826477051
Validation loss: 2.763826242057226

Epoch: 6| Step: 5
Training loss: 1.7764954566955566
Validation loss: 2.762527806784517

Epoch: 6| Step: 6
Training loss: 4.014570713043213
Validation loss: 2.7627712475356234

Epoch: 6| Step: 7
Training loss: 3.123964786529541
Validation loss: 2.7626971455030542

Epoch: 6| Step: 8
Training loss: 3.2506775856018066
Validation loss: 2.761303973454301

Epoch: 6| Step: 9
Training loss: 2.582601547241211
Validation loss: 2.761472814826555

Epoch: 6| Step: 10
Training loss: 2.217446804046631
Validation loss: 2.7570021895952124

Epoch: 6| Step: 11
Training loss: 2.1555893421173096
Validation loss: 2.7612582381053636

Epoch: 6| Step: 12
Training loss: 3.3591365814208984
Validation loss: 2.760222445252121

Epoch: 6| Step: 13
Training loss: 3.2579543590545654
Validation loss: 2.758756673464211

Epoch: 119| Step: 0
Training loss: 2.5013718605041504
Validation loss: 2.7592101661107873

Epoch: 6| Step: 1
Training loss: 3.330052375793457
Validation loss: 2.758735320901358

Epoch: 6| Step: 2
Training loss: 3.7668304443359375
Validation loss: 2.759158108824043

Epoch: 6| Step: 3
Training loss: 2.5070314407348633
Validation loss: 2.758414585103271

Epoch: 6| Step: 4
Training loss: 2.675900936126709
Validation loss: 2.757047830089446

Epoch: 6| Step: 5
Training loss: 2.099127769470215
Validation loss: 2.7587466957748576

Epoch: 6| Step: 6
Training loss: 2.479811191558838
Validation loss: 2.7564019362131753

Epoch: 6| Step: 7
Training loss: 2.0168604850769043
Validation loss: 2.758678123515139

Epoch: 6| Step: 8
Training loss: 3.3758177757263184
Validation loss: 2.7611537953858734

Epoch: 6| Step: 9
Training loss: 2.237236499786377
Validation loss: 2.758132988406766

Epoch: 6| Step: 10
Training loss: 2.8821027278900146
Validation loss: 2.7584710095518377

Epoch: 6| Step: 11
Training loss: 4.424427032470703
Validation loss: 2.756460964038808

Epoch: 6| Step: 12
Training loss: 3.28835391998291
Validation loss: 2.755641609109858

Epoch: 6| Step: 13
Training loss: 2.198404550552368
Validation loss: 2.7538329503869496

Epoch: 120| Step: 0
Training loss: 2.6354660987854004
Validation loss: 2.74951341331646

Epoch: 6| Step: 1
Training loss: 2.8206424713134766
Validation loss: 2.7536351526937177

Epoch: 6| Step: 2
Training loss: 2.9743785858154297
Validation loss: 2.750581846442274

Epoch: 6| Step: 3
Training loss: 2.496720552444458
Validation loss: 2.752759846307898

Epoch: 6| Step: 4
Training loss: 2.7737183570861816
Validation loss: 2.754911099710772

Epoch: 6| Step: 5
Training loss: 3.336944818496704
Validation loss: 2.752320553666802

Epoch: 6| Step: 6
Training loss: 2.3992562294006348
Validation loss: 2.754074876026441

Epoch: 6| Step: 7
Training loss: 3.0264251232147217
Validation loss: 2.751549877146239

Epoch: 6| Step: 8
Training loss: 2.4107322692871094
Validation loss: 2.7551288502190703

Epoch: 6| Step: 9
Training loss: 2.8640294075012207
Validation loss: 2.761988288612776

Epoch: 6| Step: 10
Training loss: 2.9279208183288574
Validation loss: 2.761539054173295

Epoch: 6| Step: 11
Training loss: 3.0764694213867188
Validation loss: 2.7658206057804886

Epoch: 6| Step: 12
Training loss: 2.760143518447876
Validation loss: 2.7628888519861365

Epoch: 6| Step: 13
Training loss: 3.8454360961914062
Validation loss: 2.7667263861625426

Epoch: 121| Step: 0
Training loss: 2.79337739944458
Validation loss: 2.7684064449802523

Epoch: 6| Step: 1
Training loss: 3.6933388710021973
Validation loss: 2.7728913163626068

Epoch: 6| Step: 2
Training loss: 2.7320985794067383
Validation loss: 2.7742177927365868

Epoch: 6| Step: 3
Training loss: 3.1288657188415527
Validation loss: 2.764798064385691

Epoch: 6| Step: 4
Training loss: 3.249598503112793
Validation loss: 2.757543889425134

Epoch: 6| Step: 5
Training loss: 2.2865896224975586
Validation loss: 2.7516365384542816

Epoch: 6| Step: 6
Training loss: 2.937631130218506
Validation loss: 2.756206927760955

Epoch: 6| Step: 7
Training loss: 2.4706573486328125
Validation loss: 2.7533505655104116

Epoch: 6| Step: 8
Training loss: 3.2243988513946533
Validation loss: 2.757237629223895

Epoch: 6| Step: 9
Training loss: 1.8047491312026978
Validation loss: 2.7489362070637364

Epoch: 6| Step: 10
Training loss: 2.4837424755096436
Validation loss: 2.752889084559615

Epoch: 6| Step: 11
Training loss: 2.970355987548828
Validation loss: 2.762049677551434

Epoch: 6| Step: 12
Training loss: 2.90012526512146
Validation loss: 2.772214307579943

Epoch: 6| Step: 13
Training loss: 3.3908157348632812
Validation loss: 2.775600851223033

Epoch: 122| Step: 0
Training loss: 2.72259521484375
Validation loss: 2.776505006256924

Epoch: 6| Step: 1
Training loss: 4.067129611968994
Validation loss: 2.759861869196738

Epoch: 6| Step: 2
Training loss: 2.5426809787750244
Validation loss: 2.7635054895954747

Epoch: 6| Step: 3
Training loss: 3.438983917236328
Validation loss: 2.748943610857892

Epoch: 6| Step: 4
Training loss: 2.303407907485962
Validation loss: 2.748814521297332

Epoch: 6| Step: 5
Training loss: 2.4145989418029785
Validation loss: 2.74944547940326

Epoch: 6| Step: 6
Training loss: 3.882964611053467
Validation loss: 2.7519591418645715

Epoch: 6| Step: 7
Training loss: 2.3859500885009766
Validation loss: 2.7580185859434065

Epoch: 6| Step: 8
Training loss: 2.1581053733825684
Validation loss: 2.7538385673235823

Epoch: 6| Step: 9
Training loss: 3.0902180671691895
Validation loss: 2.7517209514494865

Epoch: 6| Step: 10
Training loss: 2.539794445037842
Validation loss: 2.7590776156353694

Epoch: 6| Step: 11
Training loss: 3.0711300373077393
Validation loss: 2.757855564035395

Epoch: 6| Step: 12
Training loss: 3.1925225257873535
Validation loss: 2.761081093101091

Epoch: 6| Step: 13
Training loss: 1.677228569984436
Validation loss: 2.751968824735252

Epoch: 123| Step: 0
Training loss: 3.4160685539245605
Validation loss: 2.7494988236376035

Epoch: 6| Step: 1
Training loss: 2.083146095275879
Validation loss: 2.7534473583262455

Epoch: 6| Step: 2
Training loss: 3.022563934326172
Validation loss: 2.748660987423312

Epoch: 6| Step: 3
Training loss: 2.4594569206237793
Validation loss: 2.7597323617627545

Epoch: 6| Step: 4
Training loss: 3.08077335357666
Validation loss: 2.787441474135204

Epoch: 6| Step: 5
Training loss: 2.598695755004883
Validation loss: 2.803326755441645

Epoch: 6| Step: 6
Training loss: 1.9322731494903564
Validation loss: 2.80258366369432

Epoch: 6| Step: 7
Training loss: 3.0994718074798584
Validation loss: 2.7920070258519982

Epoch: 6| Step: 8
Training loss: 2.742246389389038
Validation loss: 2.7678639914399836

Epoch: 6| Step: 9
Training loss: 3.2247371673583984
Validation loss: 2.7607075898878035

Epoch: 6| Step: 10
Training loss: 3.337388515472412
Validation loss: 2.751758026820357

Epoch: 6| Step: 11
Training loss: 3.1622354984283447
Validation loss: 2.7462445279603362

Epoch: 6| Step: 12
Training loss: 2.7424912452697754
Validation loss: 2.7455555854305143

Epoch: 6| Step: 13
Training loss: 3.266301155090332
Validation loss: 2.745733076526273

Epoch: 124| Step: 0
Training loss: 3.3443398475646973
Validation loss: 2.751612801705637

Epoch: 6| Step: 1
Training loss: 2.9107799530029297
Validation loss: 2.748363776873517

Epoch: 6| Step: 2
Training loss: 2.563920736312866
Validation loss: 2.747409787229312

Epoch: 6| Step: 3
Training loss: 2.619802951812744
Validation loss: 2.752824898689024

Epoch: 6| Step: 4
Training loss: 3.2510759830474854
Validation loss: 2.747590777694538

Epoch: 6| Step: 5
Training loss: 2.1724445819854736
Validation loss: 2.750658953061668

Epoch: 6| Step: 6
Training loss: 2.366879940032959
Validation loss: 2.749235855635776

Epoch: 6| Step: 7
Training loss: 2.895824670791626
Validation loss: 2.747248298378401

Epoch: 6| Step: 8
Training loss: 3.338756799697876
Validation loss: 2.745038345295896

Epoch: 6| Step: 9
Training loss: 2.840768575668335
Validation loss: 2.7469300352117068

Epoch: 6| Step: 10
Training loss: 2.2733120918273926
Validation loss: 2.7414315144220986

Epoch: 6| Step: 11
Training loss: 2.771866798400879
Validation loss: 2.7421749843064176

Epoch: 6| Step: 12
Training loss: 3.3863003253936768
Validation loss: 2.7443730241508892

Epoch: 6| Step: 13
Training loss: 3.472383975982666
Validation loss: 2.740203252402685

Epoch: 125| Step: 0
Training loss: 1.6524395942687988
Validation loss: 2.7394829257842033

Epoch: 6| Step: 1
Training loss: 2.2338221073150635
Validation loss: 2.742659117585869

Epoch: 6| Step: 2
Training loss: 3.7484545707702637
Validation loss: 2.7415006186372493

Epoch: 6| Step: 3
Training loss: 3.9212372303009033
Validation loss: 2.740964884399086

Epoch: 6| Step: 4
Training loss: 2.828711986541748
Validation loss: 2.747665515509985

Epoch: 6| Step: 5
Training loss: 2.9019968509674072
Validation loss: 2.7560830808454946

Epoch: 6| Step: 6
Training loss: 2.8356800079345703
Validation loss: 2.7574403055252565

Epoch: 6| Step: 7
Training loss: 2.477247714996338
Validation loss: 2.7645436025434926

Epoch: 6| Step: 8
Training loss: 2.5670714378356934
Validation loss: 2.76569886361399

Epoch: 6| Step: 9
Training loss: 2.4346530437469482
Validation loss: 2.7770598216723372

Epoch: 6| Step: 10
Training loss: 2.8387744426727295
Validation loss: 2.7886222613755094

Epoch: 6| Step: 11
Training loss: 3.403813362121582
Validation loss: 2.7906129001289286

Epoch: 6| Step: 12
Training loss: 2.9128527641296387
Validation loss: 2.774560587380522

Epoch: 6| Step: 13
Training loss: 3.2572672367095947
Validation loss: 2.767200880153205

Epoch: 126| Step: 0
Training loss: 2.002898693084717
Validation loss: 2.7507162632480746

Epoch: 6| Step: 1
Training loss: 3.079516649246216
Validation loss: 2.7436124176107426

Epoch: 6| Step: 2
Training loss: 3.518160104751587
Validation loss: 2.7407285756962274

Epoch: 6| Step: 3
Training loss: 1.9492989778518677
Validation loss: 2.737916010682301

Epoch: 6| Step: 4
Training loss: 2.662959575653076
Validation loss: 2.741452693939209

Epoch: 6| Step: 5
Training loss: 3.363943099975586
Validation loss: 2.741352178717172

Epoch: 6| Step: 6
Training loss: 3.1409010887145996
Validation loss: 2.7450443877968738

Epoch: 6| Step: 7
Training loss: 2.986205577850342
Validation loss: 2.742877314167638

Epoch: 6| Step: 8
Training loss: 2.8223090171813965
Validation loss: 2.743186599464827

Epoch: 6| Step: 9
Training loss: 2.7067246437072754
Validation loss: 2.745515279872443

Epoch: 6| Step: 10
Training loss: 2.4503350257873535
Validation loss: 2.7442596881620345

Epoch: 6| Step: 11
Training loss: 3.4652533531188965
Validation loss: 2.7449236326320197

Epoch: 6| Step: 12
Training loss: 2.443183422088623
Validation loss: 2.7460324430978424

Epoch: 6| Step: 13
Training loss: 3.721987009048462
Validation loss: 2.7424198555689987

Epoch: 127| Step: 0
Training loss: 2.366819381713867
Validation loss: 2.7426019765997447

Epoch: 6| Step: 1
Training loss: 2.7331783771514893
Validation loss: 2.7376132216504825

Epoch: 6| Step: 2
Training loss: 2.4298014640808105
Validation loss: 2.73901560742368

Epoch: 6| Step: 3
Training loss: 2.8777289390563965
Validation loss: 2.7390601558070027

Epoch: 6| Step: 4
Training loss: 3.2270874977111816
Validation loss: 2.7437287940773913

Epoch: 6| Step: 5
Training loss: 3.36014986038208
Validation loss: 2.7474240231257614

Epoch: 6| Step: 6
Training loss: 3.8103699684143066
Validation loss: 2.746296682665425

Epoch: 6| Step: 7
Training loss: 2.161362648010254
Validation loss: 2.750119455399052

Epoch: 6| Step: 8
Training loss: 2.550168037414551
Validation loss: 2.7515883830285843

Epoch: 6| Step: 9
Training loss: 2.815971612930298
Validation loss: 2.7472632187668995

Epoch: 6| Step: 10
Training loss: 3.700213670730591
Validation loss: 2.750018045466433

Epoch: 6| Step: 11
Training loss: 3.5423836708068848
Validation loss: 2.753813676936652

Epoch: 6| Step: 12
Training loss: 1.6480633020401
Validation loss: 2.7576750016981557

Epoch: 6| Step: 13
Training loss: 2.2676172256469727
Validation loss: 2.7497449485204553

Epoch: 128| Step: 0
Training loss: 2.3770041465759277
Validation loss: 2.7471707379946144

Epoch: 6| Step: 1
Training loss: 2.1852011680603027
Validation loss: 2.75311109840229

Epoch: 6| Step: 2
Training loss: 2.3518288135528564
Validation loss: 2.7551676022109164

Epoch: 6| Step: 3
Training loss: 3.229408025741577
Validation loss: 2.770527116713985

Epoch: 6| Step: 4
Training loss: 3.657320022583008
Validation loss: 2.780978513020341

Epoch: 6| Step: 5
Training loss: 3.4989259243011475
Validation loss: 2.786722219118508

Epoch: 6| Step: 6
Training loss: 3.491152286529541
Validation loss: 2.758299191792806

Epoch: 6| Step: 7
Training loss: 3.126628875732422
Validation loss: 2.7470511159589215

Epoch: 6| Step: 8
Training loss: 2.371208667755127
Validation loss: 2.734008268643451

Epoch: 6| Step: 9
Training loss: 3.224855661392212
Validation loss: 2.736072063446045

Epoch: 6| Step: 10
Training loss: 2.136204242706299
Validation loss: 2.741673948944256

Epoch: 6| Step: 11
Training loss: 2.7372329235076904
Validation loss: 2.7381571210840696

Epoch: 6| Step: 12
Training loss: 3.1498937606811523
Validation loss: 2.7379226223115

Epoch: 6| Step: 13
Training loss: 1.8002686500549316
Validation loss: 2.7418736847498084

Epoch: 129| Step: 0
Training loss: 2.4649367332458496
Validation loss: 2.7430222265182005

Epoch: 6| Step: 1
Training loss: 3.5619564056396484
Validation loss: 2.74089160273152

Epoch: 6| Step: 2
Training loss: 3.624176502227783
Validation loss: 2.7377655198497157

Epoch: 6| Step: 3
Training loss: 1.865549087524414
Validation loss: 2.735696933602774

Epoch: 6| Step: 4
Training loss: 2.6045069694519043
Validation loss: 2.7359806260754986

Epoch: 6| Step: 5
Training loss: 3.1432180404663086
Validation loss: 2.734765919305945

Epoch: 6| Step: 6
Training loss: 1.4422175884246826
Validation loss: 2.735441438613399

Epoch: 6| Step: 7
Training loss: 1.9738425016403198
Validation loss: 2.737597665479106

Epoch: 6| Step: 8
Training loss: 3.4296743869781494
Validation loss: 2.7372412194487867

Epoch: 6| Step: 9
Training loss: 2.83543062210083
Validation loss: 2.7392138486267417

Epoch: 6| Step: 10
Training loss: 3.7142653465270996
Validation loss: 2.742711877310148

Epoch: 6| Step: 11
Training loss: 3.221658706665039
Validation loss: 2.7373885441851873

Epoch: 6| Step: 12
Training loss: 3.0653843879699707
Validation loss: 2.7363127687925934

Epoch: 6| Step: 13
Training loss: 2.940859794616699
Validation loss: 2.731483264635968

Epoch: 130| Step: 0
Training loss: 2.0525197982788086
Validation loss: 2.7292812575576124

Epoch: 6| Step: 1
Training loss: 2.700660228729248
Validation loss: 2.729940829738494

Epoch: 6| Step: 2
Training loss: 4.081432342529297
Validation loss: 2.7275927656440326

Epoch: 6| Step: 3
Training loss: 2.4711222648620605
Validation loss: 2.7302115732623684

Epoch: 6| Step: 4
Training loss: 2.6531496047973633
Validation loss: 2.7334314674459477

Epoch: 6| Step: 5
Training loss: 2.51718807220459
Validation loss: 2.7308196175482964

Epoch: 6| Step: 6
Training loss: 2.8749165534973145
Validation loss: 2.7252218056750555

Epoch: 6| Step: 7
Training loss: 2.5632357597351074
Validation loss: 2.7251479907702376

Epoch: 6| Step: 8
Training loss: 2.5459253787994385
Validation loss: 2.7243985001758864

Epoch: 6| Step: 9
Training loss: 2.890514850616455
Validation loss: 2.7259418400385047

Epoch: 6| Step: 10
Training loss: 3.473285675048828
Validation loss: 2.7260461315031974

Epoch: 6| Step: 11
Training loss: 3.0637288093566895
Validation loss: 2.7309061634925103

Epoch: 6| Step: 12
Training loss: 2.619706153869629
Validation loss: 2.735743499571277

Epoch: 6| Step: 13
Training loss: 3.658963441848755
Validation loss: 2.743863792829616

Epoch: 131| Step: 0
Training loss: 3.4666223526000977
Validation loss: 2.730772464506088

Epoch: 6| Step: 1
Training loss: 2.655031681060791
Validation loss: 2.7271836009076846

Epoch: 6| Step: 2
Training loss: 2.440500259399414
Validation loss: 2.723185452081824

Epoch: 6| Step: 3
Training loss: 3.2826874256134033
Validation loss: 2.7244715459885134

Epoch: 6| Step: 4
Training loss: 2.362821340560913
Validation loss: 2.7250076878455376

Epoch: 6| Step: 5
Training loss: 2.687819480895996
Validation loss: 2.7228989652408067

Epoch: 6| Step: 6
Training loss: 2.396131992340088
Validation loss: 2.7227924408451205

Epoch: 6| Step: 7
Training loss: 3.5113162994384766
Validation loss: 2.725287188765823

Epoch: 6| Step: 8
Training loss: 2.265639066696167
Validation loss: 2.7254721964559248

Epoch: 6| Step: 9
Training loss: 2.7178707122802734
Validation loss: 2.7203638117800475

Epoch: 6| Step: 10
Training loss: 2.832396984100342
Validation loss: 2.7232749539036907

Epoch: 6| Step: 11
Training loss: 2.884456157684326
Validation loss: 2.7233253473876626

Epoch: 6| Step: 12
Training loss: 3.7003631591796875
Validation loss: 2.722111348182924

Epoch: 6| Step: 13
Training loss: 2.2396669387817383
Validation loss: 2.726601290446456

Epoch: 132| Step: 0
Training loss: 3.1276097297668457
Validation loss: 2.7273383960928967

Epoch: 6| Step: 1
Training loss: 3.414104461669922
Validation loss: 2.724697187382688

Epoch: 6| Step: 2
Training loss: 2.4655332565307617
Validation loss: 2.7246868277108796

Epoch: 6| Step: 3
Training loss: 1.9342279434204102
Validation loss: 2.7208372392962055

Epoch: 6| Step: 4
Training loss: 3.292511224746704
Validation loss: 2.7199743973311556

Epoch: 6| Step: 5
Training loss: 2.6441266536712646
Validation loss: 2.718990400273313

Epoch: 6| Step: 6
Training loss: 3.569138765335083
Validation loss: 2.7204438024951565

Epoch: 6| Step: 7
Training loss: 2.3385825157165527
Validation loss: 2.7196106500523065

Epoch: 6| Step: 8
Training loss: 2.406855821609497
Validation loss: 2.7204379907218357

Epoch: 6| Step: 9
Training loss: 3.9408621788024902
Validation loss: 2.725037743968348

Epoch: 6| Step: 10
Training loss: 2.374659538269043
Validation loss: 2.7236568184309107

Epoch: 6| Step: 11
Training loss: 3.2348031997680664
Validation loss: 2.7292000247586157

Epoch: 6| Step: 12
Training loss: 2.2903332710266113
Validation loss: 2.7199971573327177

Epoch: 6| Step: 13
Training loss: 2.5703258514404297
Validation loss: 2.722990600011682

Epoch: 133| Step: 0
Training loss: 3.4961493015289307
Validation loss: 2.725584791552636

Epoch: 6| Step: 1
Training loss: 3.448147773742676
Validation loss: 2.7222218410943144

Epoch: 6| Step: 2
Training loss: 1.917472004890442
Validation loss: 2.722820198664101

Epoch: 6| Step: 3
Training loss: 2.9219820499420166
Validation loss: 2.7208073549373175

Epoch: 6| Step: 4
Training loss: 2.687079906463623
Validation loss: 2.7215417072337162

Epoch: 6| Step: 5
Training loss: 3.0740702152252197
Validation loss: 2.725234898187781

Epoch: 6| Step: 6
Training loss: 2.724393367767334
Validation loss: 2.7293275402438257

Epoch: 6| Step: 7
Training loss: 2.0948243141174316
Validation loss: 2.7318155791169856

Epoch: 6| Step: 8
Training loss: 2.9146807193756104
Validation loss: 2.7362179627982517

Epoch: 6| Step: 9
Training loss: 2.1441869735717773
Validation loss: 2.724770692086989

Epoch: 6| Step: 10
Training loss: 2.688847064971924
Validation loss: 2.726863181719216

Epoch: 6| Step: 11
Training loss: 2.945411205291748
Validation loss: 2.7260862422245804

Epoch: 6| Step: 12
Training loss: 3.080883502960205
Validation loss: 2.725949643760599

Epoch: 6| Step: 13
Training loss: 3.9249491691589355
Validation loss: 2.7172385133722776

Epoch: 134| Step: 0
Training loss: 3.033334732055664
Validation loss: 2.724290019722395

Epoch: 6| Step: 1
Training loss: 2.8696117401123047
Validation loss: 2.7210360727002545

Epoch: 6| Step: 2
Training loss: 1.7249581813812256
Validation loss: 2.720429748617193

Epoch: 6| Step: 3
Training loss: 4.087275981903076
Validation loss: 2.7228520557444584

Epoch: 6| Step: 4
Training loss: 2.875864028930664
Validation loss: 2.7306307669608825

Epoch: 6| Step: 5
Training loss: 2.732165813446045
Validation loss: 2.7301200256552747

Epoch: 6| Step: 6
Training loss: 2.910242795944214
Validation loss: 2.7366785618566696

Epoch: 6| Step: 7
Training loss: 2.0300703048706055
Validation loss: 2.7426693285665205

Epoch: 6| Step: 8
Training loss: 2.849247455596924
Validation loss: 2.7313759557662474

Epoch: 6| Step: 9
Training loss: 2.0930352210998535
Validation loss: 2.735357746001213

Epoch: 6| Step: 10
Training loss: 3.1264750957489014
Validation loss: 2.7383264008388726

Epoch: 6| Step: 11
Training loss: 3.301483631134033
Validation loss: 2.7378674886559926

Epoch: 6| Step: 12
Training loss: 3.0664680004119873
Validation loss: 2.7278052837617937

Epoch: 6| Step: 13
Training loss: 2.7852046489715576
Validation loss: 2.721245478558284

Epoch: 135| Step: 0
Training loss: 2.267326831817627
Validation loss: 2.724598002690141

Epoch: 6| Step: 1
Training loss: 2.2602181434631348
Validation loss: 2.7276331250385573

Epoch: 6| Step: 2
Training loss: 2.9355826377868652
Validation loss: 2.7367302397246003

Epoch: 6| Step: 3
Training loss: 2.5923030376434326
Validation loss: 2.7303398552761284

Epoch: 6| Step: 4
Training loss: 3.4767398834228516
Validation loss: 2.7411270987602974

Epoch: 6| Step: 5
Training loss: 3.423762559890747
Validation loss: 2.741702671973936

Epoch: 6| Step: 6
Training loss: 3.0822672843933105
Validation loss: 2.7363788312481296

Epoch: 6| Step: 7
Training loss: 2.621159315109253
Validation loss: 2.7339137164495324

Epoch: 6| Step: 8
Training loss: 2.829857110977173
Validation loss: 2.7347765353418167

Epoch: 6| Step: 9
Training loss: 2.8246912956237793
Validation loss: 2.735354692705216

Epoch: 6| Step: 10
Training loss: 3.2942521572113037
Validation loss: 2.7300179953216226

Epoch: 6| Step: 11
Training loss: 1.962190866470337
Validation loss: 2.728936090264269

Epoch: 6| Step: 12
Training loss: 2.8904964923858643
Validation loss: 2.7395211112114692

Epoch: 6| Step: 13
Training loss: 3.1598637104034424
Validation loss: 2.751935705061882

Epoch: 136| Step: 0
Training loss: 2.906550884246826
Validation loss: 2.7377823578414096

Epoch: 6| Step: 1
Training loss: 2.5562634468078613
Validation loss: 2.7399491084519254

Epoch: 6| Step: 2
Training loss: 2.1945648193359375
Validation loss: 2.74703662882569

Epoch: 6| Step: 3
Training loss: 3.163980484008789
Validation loss: 2.7376236069586968

Epoch: 6| Step: 4
Training loss: 2.466585159301758
Validation loss: 2.7304461643260014

Epoch: 6| Step: 5
Training loss: 3.610452175140381
Validation loss: 2.723151676116451

Epoch: 6| Step: 6
Training loss: 3.3234972953796387
Validation loss: 2.725250438977313

Epoch: 6| Step: 7
Training loss: 2.6346147060394287
Validation loss: 2.7170323479560112

Epoch: 6| Step: 8
Training loss: 3.0333173274993896
Validation loss: 2.7104902498183714

Epoch: 6| Step: 9
Training loss: 2.953113317489624
Validation loss: 2.7147939794807026

Epoch: 6| Step: 10
Training loss: 2.62862491607666
Validation loss: 2.716745679096509

Epoch: 6| Step: 11
Training loss: 2.7107021808624268
Validation loss: 2.7128445589414207

Epoch: 6| Step: 12
Training loss: 3.3736276626586914
Validation loss: 2.7124902432964695

Epoch: 6| Step: 13
Training loss: 1.1758838891983032
Validation loss: 2.719058093204293

Epoch: 137| Step: 0
Training loss: 2.6090950965881348
Validation loss: 2.7365719759336082

Epoch: 6| Step: 1
Training loss: 2.5273756980895996
Validation loss: 2.747425866383378

Epoch: 6| Step: 2
Training loss: 2.9980554580688477
Validation loss: 2.7618072571293

Epoch: 6| Step: 3
Training loss: 2.4356303215026855
Validation loss: 2.758346390980546

Epoch: 6| Step: 4
Training loss: 2.3704419136047363
Validation loss: 2.749788458629321

Epoch: 6| Step: 5
Training loss: 2.8970370292663574
Validation loss: 2.740795176516297

Epoch: 6| Step: 6
Training loss: 2.4879486560821533
Validation loss: 2.7235831906718593

Epoch: 6| Step: 7
Training loss: 2.7033510208129883
Validation loss: 2.7225331209039174

Epoch: 6| Step: 8
Training loss: 2.8384976387023926
Validation loss: 2.7212506084031958

Epoch: 6| Step: 9
Training loss: 3.7883827686309814
Validation loss: 2.7221685096781743

Epoch: 6| Step: 10
Training loss: 2.56992244720459
Validation loss: 2.7204736509630756

Epoch: 6| Step: 11
Training loss: 3.085700511932373
Validation loss: 2.721728506908622

Epoch: 6| Step: 12
Training loss: 3.2495622634887695
Validation loss: 2.7153299316283195

Epoch: 6| Step: 13
Training loss: 2.9953255653381348
Validation loss: 2.7159196330655004

Epoch: 138| Step: 0
Training loss: 1.774997353553772
Validation loss: 2.7192865225576583

Epoch: 6| Step: 1
Training loss: 2.556140899658203
Validation loss: 2.721462221555812

Epoch: 6| Step: 2
Training loss: 2.8398337364196777
Validation loss: 2.7199138364484234

Epoch: 6| Step: 3
Training loss: 3.874969959259033
Validation loss: 2.7242341938839165

Epoch: 6| Step: 4
Training loss: 3.3288686275482178
Validation loss: 2.7270035641167754

Epoch: 6| Step: 5
Training loss: 2.053788661956787
Validation loss: 2.7256409147734284

Epoch: 6| Step: 6
Training loss: 2.700550079345703
Validation loss: 2.7243357755804576

Epoch: 6| Step: 7
Training loss: 2.7219700813293457
Validation loss: 2.7293336801631476

Epoch: 6| Step: 8
Training loss: 2.215651512145996
Validation loss: 2.7362722632705525

Epoch: 6| Step: 9
Training loss: 2.816739559173584
Validation loss: 2.7376937738028904

Epoch: 6| Step: 10
Training loss: 3.826144218444824
Validation loss: 2.744540209411293

Epoch: 6| Step: 11
Training loss: 2.8723583221435547
Validation loss: 2.7430606349822013

Epoch: 6| Step: 12
Training loss: 3.193957805633545
Validation loss: 2.7312109085821334

Epoch: 6| Step: 13
Training loss: 2.5687203407287598
Validation loss: 2.7306890026215584

Epoch: 139| Step: 0
Training loss: 2.2998123168945312
Validation loss: 2.720794816170969

Epoch: 6| Step: 1
Training loss: 3.203402519226074
Validation loss: 2.7240357809169318

Epoch: 6| Step: 2
Training loss: 4.519051551818848
Validation loss: 2.7167161075017785

Epoch: 6| Step: 3
Training loss: 2.9281179904937744
Validation loss: 2.7149478235552387

Epoch: 6| Step: 4
Training loss: 3.297499179840088
Validation loss: 2.71362369291244

Epoch: 6| Step: 5
Training loss: 1.9853551387786865
Validation loss: 2.7167580819899038

Epoch: 6| Step: 6
Training loss: 2.119375705718994
Validation loss: 2.7135132256374566

Epoch: 6| Step: 7
Training loss: 3.6391828060150146
Validation loss: 2.710432298721806

Epoch: 6| Step: 8
Training loss: 2.032900333404541
Validation loss: 2.704110466023927

Epoch: 6| Step: 9
Training loss: 2.59763765335083
Validation loss: 2.7109255944528887

Epoch: 6| Step: 10
Training loss: 3.053769111633301
Validation loss: 2.7073444909946893

Epoch: 6| Step: 11
Training loss: 2.8443191051483154
Validation loss: 2.70688783994285

Epoch: 6| Step: 12
Training loss: 1.928916096687317
Validation loss: 2.7159872567781838

Epoch: 6| Step: 13
Training loss: 2.9999046325683594
Validation loss: 2.725771350245322

Epoch: 140| Step: 0
Training loss: 2.9421653747558594
Validation loss: 2.733280333139563

Epoch: 6| Step: 1
Training loss: 2.688300132751465
Validation loss: 2.7412209356984785

Epoch: 6| Step: 2
Training loss: 2.557102918624878
Validation loss: 2.7383905944003852

Epoch: 6| Step: 3
Training loss: 1.8313472270965576
Validation loss: 2.7318110260912167

Epoch: 6| Step: 4
Training loss: 2.9405417442321777
Validation loss: 2.7402638132854173

Epoch: 6| Step: 5
Training loss: 2.5788960456848145
Validation loss: 2.7269958885767127

Epoch: 6| Step: 6
Training loss: 3.2247109413146973
Validation loss: 2.7132044069228636

Epoch: 6| Step: 7
Training loss: 3.056319236755371
Validation loss: 2.706929365793864

Epoch: 6| Step: 8
Training loss: 3.2174441814422607
Validation loss: 2.704622858314104

Epoch: 6| Step: 9
Training loss: 1.8149006366729736
Validation loss: 2.701776663462321

Epoch: 6| Step: 10
Training loss: 3.244584560394287
Validation loss: 2.7048518401320263

Epoch: 6| Step: 11
Training loss: 2.9575390815734863
Validation loss: 2.7116096224836124

Epoch: 6| Step: 12
Training loss: 3.3408889770507812
Validation loss: 2.711067530416673

Epoch: 6| Step: 13
Training loss: 3.330944538116455
Validation loss: 2.7084689396683888

Epoch: 141| Step: 0
Training loss: 2.6247053146362305
Validation loss: 2.708609314375026

Epoch: 6| Step: 1
Training loss: 1.7974939346313477
Validation loss: 2.7066225697917323

Epoch: 6| Step: 2
Training loss: 2.8699240684509277
Validation loss: 2.700117567534088

Epoch: 6| Step: 3
Training loss: 3.39141845703125
Validation loss: 2.699442571209323

Epoch: 6| Step: 4
Training loss: 3.4094784259796143
Validation loss: 2.7010071585255284

Epoch: 6| Step: 5
Training loss: 1.7661901712417603
Validation loss: 2.709758937999766

Epoch: 6| Step: 6
Training loss: 1.890716314315796
Validation loss: 2.706519626802014

Epoch: 6| Step: 7
Training loss: 3.4498181343078613
Validation loss: 2.7164458305604997

Epoch: 6| Step: 8
Training loss: 2.7714905738830566
Validation loss: 2.728882756284488

Epoch: 6| Step: 9
Training loss: 2.899937629699707
Validation loss: 2.7284983973349295

Epoch: 6| Step: 10
Training loss: 3.406329393386841
Validation loss: 2.725676505796371

Epoch: 6| Step: 11
Training loss: 2.9946224689483643
Validation loss: 2.716882997943509

Epoch: 6| Step: 12
Training loss: 3.4411392211914062
Validation loss: 2.71412391560052

Epoch: 6| Step: 13
Training loss: 2.6429121494293213
Validation loss: 2.7027937673753306

Epoch: 142| Step: 0
Training loss: 3.5824880599975586
Validation loss: 2.702142241180584

Epoch: 6| Step: 1
Training loss: 2.354260206222534
Validation loss: 2.69743255389634

Epoch: 6| Step: 2
Training loss: 3.2729415893554688
Validation loss: 2.693337017490018

Epoch: 6| Step: 3
Training loss: 2.6593382358551025
Validation loss: 2.6982645552645446

Epoch: 6| Step: 4
Training loss: 2.6930410861968994
Validation loss: 2.694342787547778

Epoch: 6| Step: 5
Training loss: 2.503632068634033
Validation loss: 2.695905203460365

Epoch: 6| Step: 6
Training loss: 2.2756359577178955
Validation loss: 2.7028647930391374

Epoch: 6| Step: 7
Training loss: 2.747046947479248
Validation loss: 2.710817075544788

Epoch: 6| Step: 8
Training loss: 2.69271183013916
Validation loss: 2.717664746827977

Epoch: 6| Step: 9
Training loss: 3.542635917663574
Validation loss: 2.7353753095032065

Epoch: 6| Step: 10
Training loss: 2.89536714553833
Validation loss: 2.750284407728462

Epoch: 6| Step: 11
Training loss: 2.962940216064453
Validation loss: 2.7466997433734197

Epoch: 6| Step: 12
Training loss: 2.6905884742736816
Validation loss: 2.7520679709731892

Epoch: 6| Step: 13
Training loss: 2.249906063079834
Validation loss: 2.7269372478608163

Epoch: 143| Step: 0
Training loss: 2.9243130683898926
Validation loss: 2.7138630754204205

Epoch: 6| Step: 1
Training loss: 2.851375102996826
Validation loss: 2.7031127329795592

Epoch: 6| Step: 2
Training loss: 3.1412839889526367
Validation loss: 2.703329678504698

Epoch: 6| Step: 3
Training loss: 2.3270034790039062
Validation loss: 2.7004216409498647

Epoch: 6| Step: 4
Training loss: 2.249286651611328
Validation loss: 2.698238049784014

Epoch: 6| Step: 5
Training loss: 1.889369010925293
Validation loss: 2.6950341116997505

Epoch: 6| Step: 6
Training loss: 3.0507893562316895
Validation loss: 2.690553926652478

Epoch: 6| Step: 7
Training loss: 3.641082286834717
Validation loss: 2.693200775372085

Epoch: 6| Step: 8
Training loss: 2.7397894859313965
Validation loss: 2.695848795675462

Epoch: 6| Step: 9
Training loss: 2.2763209342956543
Validation loss: 2.6927565323409213

Epoch: 6| Step: 10
Training loss: 3.6131458282470703
Validation loss: 2.6958500185320453

Epoch: 6| Step: 11
Training loss: 2.958500862121582
Validation loss: 2.7064931751579366

Epoch: 6| Step: 12
Training loss: 2.4471006393432617
Validation loss: 2.7082638432902675

Epoch: 6| Step: 13
Training loss: 3.2859914302825928
Validation loss: 2.714323846242761

Epoch: 144| Step: 0
Training loss: 2.442610025405884
Validation loss: 2.713082662192724

Epoch: 6| Step: 1
Training loss: 2.505492687225342
Validation loss: 2.7235831868263984

Epoch: 6| Step: 2
Training loss: 2.9912071228027344
Validation loss: 2.727378217122888

Epoch: 6| Step: 3
Training loss: 2.2512574195861816
Validation loss: 2.7288662464387956

Epoch: 6| Step: 4
Training loss: 2.5971672534942627
Validation loss: 2.71827454720774

Epoch: 6| Step: 5
Training loss: 3.636589527130127
Validation loss: 2.7044960145027406

Epoch: 6| Step: 6
Training loss: 2.5801076889038086
Validation loss: 2.701241439388644

Epoch: 6| Step: 7
Training loss: 2.9607510566711426
Validation loss: 2.7002124581285702

Epoch: 6| Step: 8
Training loss: 3.0820584297180176
Validation loss: 2.6966430243625434

Epoch: 6| Step: 9
Training loss: 3.0046939849853516
Validation loss: 2.6994625624789985

Epoch: 6| Step: 10
Training loss: 3.8629255294799805
Validation loss: 2.6999021678842525

Epoch: 6| Step: 11
Training loss: 1.791916847229004
Validation loss: 2.6970940225867817

Epoch: 6| Step: 12
Training loss: 2.5423965454101562
Validation loss: 2.7052962908180813

Epoch: 6| Step: 13
Training loss: 3.0449745655059814
Validation loss: 2.7002563809835785

Epoch: 145| Step: 0
Training loss: 3.849243402481079
Validation loss: 2.7058737995803996

Epoch: 6| Step: 1
Training loss: 1.8897464275360107
Validation loss: 2.6972986857096353

Epoch: 6| Step: 2
Training loss: 2.029849052429199
Validation loss: 2.6934445032509426

Epoch: 6| Step: 3
Training loss: 2.8584699630737305
Validation loss: 2.7018041174898864

Epoch: 6| Step: 4
Training loss: 2.805884838104248
Validation loss: 2.7028379030125116

Epoch: 6| Step: 5
Training loss: 2.9661474227905273
Validation loss: 2.7076886956409743

Epoch: 6| Step: 6
Training loss: 2.989593982696533
Validation loss: 2.713718839870986

Epoch: 6| Step: 7
Training loss: 3.1720242500305176
Validation loss: 2.719882947142406

Epoch: 6| Step: 8
Training loss: 3.5249905586242676
Validation loss: 2.720801479072981

Epoch: 6| Step: 9
Training loss: 2.604980707168579
Validation loss: 2.7255304551893667

Epoch: 6| Step: 10
Training loss: 2.606356143951416
Validation loss: 2.711638799277685

Epoch: 6| Step: 11
Training loss: 2.419618606567383
Validation loss: 2.720548686160836

Epoch: 6| Step: 12
Training loss: 2.482931137084961
Validation loss: 2.7105751678507817

Epoch: 6| Step: 13
Training loss: 3.0658459663391113
Validation loss: 2.6984604712455504

Epoch: 146| Step: 0
Training loss: 3.0051143169403076
Validation loss: 2.707406948971492

Epoch: 6| Step: 1
Training loss: 2.0420026779174805
Validation loss: 2.7049307438635055

Epoch: 6| Step: 2
Training loss: 2.60357666015625
Validation loss: 2.699894025761594

Epoch: 6| Step: 3
Training loss: 3.1205759048461914
Validation loss: 2.7100743478344334

Epoch: 6| Step: 4
Training loss: 2.1649839878082275
Validation loss: 2.7115064564571587

Epoch: 6| Step: 5
Training loss: 2.3978843688964844
Validation loss: 2.706446950153638

Epoch: 6| Step: 6
Training loss: 2.0313472747802734
Validation loss: 2.7185609135576474

Epoch: 6| Step: 7
Training loss: 2.5489823818206787
Validation loss: 2.714919497889857

Epoch: 6| Step: 8
Training loss: 2.834030866622925
Validation loss: 2.706948952008319

Epoch: 6| Step: 9
Training loss: 2.5617246627807617
Validation loss: 2.7042617797851562

Epoch: 6| Step: 10
Training loss: 2.749331474304199
Validation loss: 2.699613527585101

Epoch: 6| Step: 11
Training loss: 3.6077871322631836
Validation loss: 2.6938666912817184

Epoch: 6| Step: 12
Training loss: 4.011055946350098
Validation loss: 2.69396387633457

Epoch: 6| Step: 13
Training loss: 3.862314462661743
Validation loss: 2.6929104199973484

Epoch: 147| Step: 0
Training loss: 2.1186611652374268
Validation loss: 2.6971030619836625

Epoch: 6| Step: 1
Training loss: 2.746915102005005
Validation loss: 2.6978806910976285

Epoch: 6| Step: 2
Training loss: 3.1347672939300537
Validation loss: 2.698072320671492

Epoch: 6| Step: 3
Training loss: 3.7776622772216797
Validation loss: 2.7119948299982215

Epoch: 6| Step: 4
Training loss: 2.9501771926879883
Validation loss: 2.7087649171070387

Epoch: 6| Step: 5
Training loss: 2.5487115383148193
Validation loss: 2.709390501822195

Epoch: 6| Step: 6
Training loss: 2.900087594985962
Validation loss: 2.7256692301842476

Epoch: 6| Step: 7
Training loss: 2.8297553062438965
Validation loss: 2.7304640739194808

Epoch: 6| Step: 8
Training loss: 2.8667726516723633
Validation loss: 2.719928131308607

Epoch: 6| Step: 9
Training loss: 3.125457525253296
Validation loss: 2.697344333894791

Epoch: 6| Step: 10
Training loss: 3.181011915206909
Validation loss: 2.6856760081424507

Epoch: 6| Step: 11
Training loss: 2.206392288208008
Validation loss: 2.6861245247625534

Epoch: 6| Step: 12
Training loss: 2.097994565963745
Validation loss: 2.6795453615086053

Epoch: 6| Step: 13
Training loss: 2.518580198287964
Validation loss: 2.680276784845578

Epoch: 148| Step: 0
Training loss: 2.3638968467712402
Validation loss: 2.6805186604940765

Epoch: 6| Step: 1
Training loss: 2.6448142528533936
Validation loss: 2.6820430165977887

Epoch: 6| Step: 2
Training loss: 3.1711597442626953
Validation loss: 2.675886715612104

Epoch: 6| Step: 3
Training loss: 2.902709484100342
Validation loss: 2.684486545542235

Epoch: 6| Step: 4
Training loss: 2.883446455001831
Validation loss: 2.6833841134143133

Epoch: 6| Step: 5
Training loss: 2.6603829860687256
Validation loss: 2.6754434083097722

Epoch: 6| Step: 6
Training loss: 2.4611377716064453
Validation loss: 2.681613568336733

Epoch: 6| Step: 7
Training loss: 3.2105941772460938
Validation loss: 2.6826082121941353

Epoch: 6| Step: 8
Training loss: 2.6578164100646973
Validation loss: 2.6815720527402815

Epoch: 6| Step: 9
Training loss: 2.9612343311309814
Validation loss: 2.684023246970228

Epoch: 6| Step: 10
Training loss: 2.794070243835449
Validation loss: 2.682855654788274

Epoch: 6| Step: 11
Training loss: 3.1456055641174316
Validation loss: 2.6870715336133073

Epoch: 6| Step: 12
Training loss: 2.1539053916931152
Validation loss: 2.6900855341265277

Epoch: 6| Step: 13
Training loss: 3.377904176712036
Validation loss: 2.6904546368506645

Epoch: 149| Step: 0
Training loss: 2.9496326446533203
Validation loss: 2.689975537279601

Epoch: 6| Step: 1
Training loss: 1.5292936563491821
Validation loss: 2.6855382406583397

Epoch: 6| Step: 2
Training loss: 2.966726541519165
Validation loss: 2.693808745312434

Epoch: 6| Step: 3
Training loss: 3.015490770339966
Validation loss: 2.7005728060199368

Epoch: 6| Step: 4
Training loss: 2.2291924953460693
Validation loss: 2.6987134769398677

Epoch: 6| Step: 5
Training loss: 1.9870271682739258
Validation loss: 2.6999666434462353

Epoch: 6| Step: 6
Training loss: 2.8172478675842285
Validation loss: 2.6965711962792183

Epoch: 6| Step: 7
Training loss: 3.221212148666382
Validation loss: 2.6945630478602585

Epoch: 6| Step: 8
Training loss: 3.0169308185577393
Validation loss: 2.6923649567429737

Epoch: 6| Step: 9
Training loss: 2.776968479156494
Validation loss: 2.6800752865370883

Epoch: 6| Step: 10
Training loss: 3.337040424346924
Validation loss: 2.688509013063164

Epoch: 6| Step: 11
Training loss: 2.8669519424438477
Validation loss: 2.679624734386321

Epoch: 6| Step: 12
Training loss: 3.2033214569091797
Validation loss: 2.68060738296919

Epoch: 6| Step: 13
Training loss: 3.415311098098755
Validation loss: 2.681763772041567

Epoch: 150| Step: 0
Training loss: 2.5570311546325684
Validation loss: 2.680914782708691

Epoch: 6| Step: 1
Training loss: 2.5240888595581055
Validation loss: 2.68612862402393

Epoch: 6| Step: 2
Training loss: 2.5409674644470215
Validation loss: 2.691318586308469

Epoch: 6| Step: 3
Training loss: 3.3415510654449463
Validation loss: 2.695488211929157

Epoch: 6| Step: 4
Training loss: 3.2111520767211914
Validation loss: 2.7020535212691112

Epoch: 6| Step: 5
Training loss: 2.993253231048584
Validation loss: 2.716254831642233

Epoch: 6| Step: 6
Training loss: 2.0363454818725586
Validation loss: 2.724981564347462

Epoch: 6| Step: 7
Training loss: 2.4084033966064453
Validation loss: 2.7424741816777054

Epoch: 6| Step: 8
Training loss: 2.2310004234313965
Validation loss: 2.7421866873259186

Epoch: 6| Step: 9
Training loss: 3.0386595726013184
Validation loss: 2.7498938755322526

Epoch: 6| Step: 10
Training loss: 3.345038414001465
Validation loss: 2.7374145010466218

Epoch: 6| Step: 11
Training loss: 2.850996494293213
Validation loss: 2.701579293897075

Epoch: 6| Step: 12
Training loss: 3.1941490173339844
Validation loss: 2.6908643578970306

Epoch: 6| Step: 13
Training loss: 2.9442014694213867
Validation loss: 2.676019596797164

Epoch: 151| Step: 0
Training loss: 2.794528007507324
Validation loss: 2.6804866278043358

Epoch: 6| Step: 1
Training loss: 2.5737195014953613
Validation loss: 2.687472076826198

Epoch: 6| Step: 2
Training loss: 2.314814329147339
Validation loss: 2.695678029009091

Epoch: 6| Step: 3
Training loss: 1.789954423904419
Validation loss: 2.6949283897235827

Epoch: 6| Step: 4
Training loss: 2.840585231781006
Validation loss: 2.699751946233934

Epoch: 6| Step: 5
Training loss: 3.259775161743164
Validation loss: 2.695852966718776

Epoch: 6| Step: 6
Training loss: 2.5295932292938232
Validation loss: 2.691077398997481

Epoch: 6| Step: 7
Training loss: 3.0740060806274414
Validation loss: 2.6847735604932232

Epoch: 6| Step: 8
Training loss: 3.493621826171875
Validation loss: 2.6814694584056897

Epoch: 6| Step: 9
Training loss: 2.850767135620117
Validation loss: 2.6778227180562992

Epoch: 6| Step: 10
Training loss: 3.2159299850463867
Validation loss: 2.676239208508563

Epoch: 6| Step: 11
Training loss: 3.755155086517334
Validation loss: 2.6748352871146253

Epoch: 6| Step: 12
Training loss: 2.476146936416626
Validation loss: 2.6743419554925736

Epoch: 6| Step: 13
Training loss: 2.0222818851470947
Validation loss: 2.6666692149254585

Epoch: 152| Step: 0
Training loss: 2.313490867614746
Validation loss: 2.66986261388307

Epoch: 6| Step: 1
Training loss: 3.1293373107910156
Validation loss: 2.6691878252131964

Epoch: 6| Step: 2
Training loss: 2.4552786350250244
Validation loss: 2.6698336883257796

Epoch: 6| Step: 3
Training loss: 2.1988730430603027
Validation loss: 2.66993183987115

Epoch: 6| Step: 4
Training loss: 1.5174673795700073
Validation loss: 2.675461689631144

Epoch: 6| Step: 5
Training loss: 2.6348013877868652
Validation loss: 2.6889877268063125

Epoch: 6| Step: 6
Training loss: 2.6134140491485596
Validation loss: 2.686692027635472

Epoch: 6| Step: 7
Training loss: 2.8318982124328613
Validation loss: 2.690895849658597

Epoch: 6| Step: 8
Training loss: 3.6444485187530518
Validation loss: 2.6907312793116414

Epoch: 6| Step: 9
Training loss: 3.9649853706359863
Validation loss: 2.6967441753674577

Epoch: 6| Step: 10
Training loss: 2.919220209121704
Validation loss: 2.680616404420586

Epoch: 6| Step: 11
Training loss: 2.579191207885742
Validation loss: 2.681052518147294

Epoch: 6| Step: 12
Training loss: 3.6214942932128906
Validation loss: 2.6787360842509935

Epoch: 6| Step: 13
Training loss: 2.6056110858917236
Validation loss: 2.6750815581249934

Epoch: 153| Step: 0
Training loss: 3.2615342140197754
Validation loss: 2.676559261096421

Epoch: 6| Step: 1
Training loss: 3.056291103363037
Validation loss: 2.677226686990389

Epoch: 6| Step: 2
Training loss: 2.4283370971679688
Validation loss: 2.6844788853840162

Epoch: 6| Step: 3
Training loss: 2.4999287128448486
Validation loss: 2.684988831961027

Epoch: 6| Step: 4
Training loss: 3.190650463104248
Validation loss: 2.683861663264613

Epoch: 6| Step: 5
Training loss: 3.559713363647461
Validation loss: 2.6809789672974618

Epoch: 6| Step: 6
Training loss: 2.336820125579834
Validation loss: 2.684980002782678

Epoch: 6| Step: 7
Training loss: 2.8536105155944824
Validation loss: 2.686264107304235

Epoch: 6| Step: 8
Training loss: 2.846679449081421
Validation loss: 2.682165017691992

Epoch: 6| Step: 9
Training loss: 2.16117000579834
Validation loss: 2.677678769634616

Epoch: 6| Step: 10
Training loss: 2.828577995300293
Validation loss: 2.66996164988446

Epoch: 6| Step: 11
Training loss: 2.618781089782715
Validation loss: 2.6682909637369137

Epoch: 6| Step: 12
Training loss: 2.9052412509918213
Validation loss: 2.6644983445444415

Epoch: 6| Step: 13
Training loss: 2.1294524669647217
Validation loss: 2.6603309544183875

Epoch: 154| Step: 0
Training loss: 2.9480130672454834
Validation loss: 2.6596531252707205

Epoch: 6| Step: 1
Training loss: 2.353785991668701
Validation loss: 2.663986506000642

Epoch: 6| Step: 2
Training loss: 2.588456630706787
Validation loss: 2.6615782348058556

Epoch: 6| Step: 3
Training loss: 2.5533359050750732
Validation loss: 2.6595256815674486

Epoch: 6| Step: 4
Training loss: 3.456378936767578
Validation loss: 2.6605144521241546

Epoch: 6| Step: 5
Training loss: 2.492413282394409
Validation loss: 2.6608174206108175

Epoch: 6| Step: 6
Training loss: 3.8176021575927734
Validation loss: 2.657801981895201

Epoch: 6| Step: 7
Training loss: 2.5324981212615967
Validation loss: 2.66329389233743

Epoch: 6| Step: 8
Training loss: 2.8544883728027344
Validation loss: 2.6657115285114577

Epoch: 6| Step: 9
Training loss: 2.3267486095428467
Validation loss: 2.669902491313155

Epoch: 6| Step: 10
Training loss: 2.7221336364746094
Validation loss: 2.6697630113170994

Epoch: 6| Step: 11
Training loss: 2.702432155609131
Validation loss: 2.6798983209876606

Epoch: 6| Step: 12
Training loss: 3.05413818359375
Validation loss: 2.6841275615076863

Epoch: 6| Step: 13
Training loss: 2.4036855697631836
Validation loss: 2.6939454796493694

Epoch: 155| Step: 0
Training loss: 3.086639404296875
Validation loss: 2.7058195375627085

Epoch: 6| Step: 1
Training loss: 2.863816499710083
Validation loss: 2.7099903809126986

Epoch: 6| Step: 2
Training loss: 2.1984376907348633
Validation loss: 2.7143477855190152

Epoch: 6| Step: 3
Training loss: 3.1924664974212646
Validation loss: 2.7318781242575696

Epoch: 6| Step: 4
Training loss: 2.08050274848938
Validation loss: 2.722634618000318

Epoch: 6| Step: 5
Training loss: 2.3343679904937744
Validation loss: 2.7078647664798203

Epoch: 6| Step: 6
Training loss: 3.342353343963623
Validation loss: 2.6835955830030542

Epoch: 6| Step: 7
Training loss: 2.4381885528564453
Validation loss: 2.665651249629195

Epoch: 6| Step: 8
Training loss: 2.7385222911834717
Validation loss: 2.6620747504695768

Epoch: 6| Step: 9
Training loss: 3.2719411849975586
Validation loss: 2.664654485640987

Epoch: 6| Step: 10
Training loss: 2.124907970428467
Validation loss: 2.664185034331455

Epoch: 6| Step: 11
Training loss: 3.8478145599365234
Validation loss: 2.659901511284613

Epoch: 6| Step: 12
Training loss: 2.710749864578247
Validation loss: 2.6643342894892537

Epoch: 6| Step: 13
Training loss: 2.850210189819336
Validation loss: 2.6635170393092658

Epoch: 156| Step: 0
Training loss: 2.066769599914551
Validation loss: 2.6646519322549143

Epoch: 6| Step: 1
Training loss: 2.7114195823669434
Validation loss: 2.6625196831200713

Epoch: 6| Step: 2
Training loss: 1.942168951034546
Validation loss: 2.6573245397178074

Epoch: 6| Step: 3
Training loss: 2.2969374656677246
Validation loss: 2.6597377407935356

Epoch: 6| Step: 4
Training loss: 3.259598731994629
Validation loss: 2.6626271945174023

Epoch: 6| Step: 5
Training loss: 2.172943115234375
Validation loss: 2.6604393707808627

Epoch: 6| Step: 6
Training loss: 2.4958548545837402
Validation loss: 2.662226143703666

Epoch: 6| Step: 7
Training loss: 2.663048267364502
Validation loss: 2.6694752529103267

Epoch: 6| Step: 8
Training loss: 4.026007175445557
Validation loss: 2.6711784024392404

Epoch: 6| Step: 9
Training loss: 3.7003800868988037
Validation loss: 2.6758487250215266

Epoch: 6| Step: 10
Training loss: 3.006993293762207
Validation loss: 2.676386474281229

Epoch: 6| Step: 11
Training loss: 3.0769262313842773
Validation loss: 2.687012944170224

Epoch: 6| Step: 12
Training loss: 2.884214401245117
Validation loss: 2.682427921602803

Epoch: 6| Step: 13
Training loss: 2.6177783012390137
Validation loss: 2.6833283773032566

Epoch: 157| Step: 0
Training loss: 1.9952406883239746
Validation loss: 2.682770816228723

Epoch: 6| Step: 1
Training loss: 2.786939859390259
Validation loss: 2.679777006949148

Epoch: 6| Step: 2
Training loss: 2.712519407272339
Validation loss: 2.6804486782320085

Epoch: 6| Step: 3
Training loss: 2.4197773933410645
Validation loss: 2.67948636188302

Epoch: 6| Step: 4
Training loss: 2.3229894638061523
Validation loss: 2.674492830871254

Epoch: 6| Step: 5
Training loss: 2.849915027618408
Validation loss: 2.678452927579162

Epoch: 6| Step: 6
Training loss: 3.9679319858551025
Validation loss: 2.6716730492089384

Epoch: 6| Step: 7
Training loss: 2.20076322555542
Validation loss: 2.6716246963829122

Epoch: 6| Step: 8
Training loss: 3.057835102081299
Validation loss: 2.6746936818604827

Epoch: 6| Step: 9
Training loss: 1.8462417125701904
Validation loss: 2.6836887790310766

Epoch: 6| Step: 10
Training loss: 2.940993547439575
Validation loss: 2.688809125654159

Epoch: 6| Step: 11
Training loss: 3.429943084716797
Validation loss: 2.703631449771184

Epoch: 6| Step: 12
Training loss: 3.0438404083251953
Validation loss: 2.715455421837427

Epoch: 6| Step: 13
Training loss: 3.692983865737915
Validation loss: 2.70279634639781

Epoch: 158| Step: 0
Training loss: 3.4641895294189453
Validation loss: 2.6787809915440057

Epoch: 6| Step: 1
Training loss: 3.074544906616211
Validation loss: 2.6643940479524675

Epoch: 6| Step: 2
Training loss: 2.7722549438476562
Validation loss: 2.655910579107141

Epoch: 6| Step: 3
Training loss: 3.158189535140991
Validation loss: 2.6554240052418043

Epoch: 6| Step: 4
Training loss: 2.2101316452026367
Validation loss: 2.660763881539786

Epoch: 6| Step: 5
Training loss: 2.871732711791992
Validation loss: 2.6588125997974026

Epoch: 6| Step: 6
Training loss: 3.094383716583252
Validation loss: 2.656767314480197

Epoch: 6| Step: 7
Training loss: 2.4974560737609863
Validation loss: 2.6620684926227858

Epoch: 6| Step: 8
Training loss: 2.3284976482391357
Validation loss: 2.6541572104218187

Epoch: 6| Step: 9
Training loss: 2.8442065715789795
Validation loss: 2.656602003241098

Epoch: 6| Step: 10
Training loss: 2.7261269092559814
Validation loss: 2.6606968987372612

Epoch: 6| Step: 11
Training loss: 2.516162872314453
Validation loss: 2.65934770594361

Epoch: 6| Step: 12
Training loss: 3.1054272651672363
Validation loss: 2.6574040946140083

Epoch: 6| Step: 13
Training loss: 1.8410496711730957
Validation loss: 2.66479020221259

Epoch: 159| Step: 0
Training loss: 2.67857027053833
Validation loss: 2.6573703391577608

Epoch: 6| Step: 1
Training loss: 4.046385288238525
Validation loss: 2.669439895178682

Epoch: 6| Step: 2
Training loss: 2.4154412746429443
Validation loss: 2.676920316552603

Epoch: 6| Step: 3
Training loss: 2.974364757537842
Validation loss: 2.679457564507761

Epoch: 6| Step: 4
Training loss: 2.7779860496520996
Validation loss: 2.681793228272469

Epoch: 6| Step: 5
Training loss: 2.4805803298950195
Validation loss: 2.670410607450752

Epoch: 6| Step: 6
Training loss: 2.259631633758545
Validation loss: 2.6881497649736303

Epoch: 6| Step: 7
Training loss: 2.586320161819458
Validation loss: 2.6995631751193794

Epoch: 6| Step: 8
Training loss: 3.17665958404541
Validation loss: 2.69859678001814

Epoch: 6| Step: 9
Training loss: 2.6494107246398926
Validation loss: 2.6948807726624193

Epoch: 6| Step: 10
Training loss: 2.7896318435668945
Validation loss: 2.685071755481023

Epoch: 6| Step: 11
Training loss: 1.9706504344940186
Validation loss: 2.674290262242799

Epoch: 6| Step: 12
Training loss: 3.277303695678711
Validation loss: 2.6742933129751556

Epoch: 6| Step: 13
Training loss: 2.5796589851379395
Validation loss: 2.675024514557213

Epoch: 160| Step: 0
Training loss: 2.149949789047241
Validation loss: 2.661778406430316

Epoch: 6| Step: 1
Training loss: 2.7698252201080322
Validation loss: 2.665076235289215

Epoch: 6| Step: 2
Training loss: 2.9915812015533447
Validation loss: 2.6609766073124383

Epoch: 6| Step: 3
Training loss: 3.424466609954834
Validation loss: 2.6536786146061395

Epoch: 6| Step: 4
Training loss: 2.5224668979644775
Validation loss: 2.652076931409938

Epoch: 6| Step: 5
Training loss: 2.845973253250122
Validation loss: 2.654293175666563

Epoch: 6| Step: 6
Training loss: 2.875574827194214
Validation loss: 2.651840973925847

Epoch: 6| Step: 7
Training loss: 3.214095115661621
Validation loss: 2.6553389769728466

Epoch: 6| Step: 8
Training loss: 2.131026268005371
Validation loss: 2.6583179889186734

Epoch: 6| Step: 9
Training loss: 3.539844036102295
Validation loss: 2.660352107017271

Epoch: 6| Step: 10
Training loss: 2.2963666915893555
Validation loss: 2.667502990332983

Epoch: 6| Step: 11
Training loss: 1.879384160041809
Validation loss: 2.6752267396578224

Epoch: 6| Step: 12
Training loss: 3.128248453140259
Validation loss: 2.7009449979310394

Epoch: 6| Step: 13
Training loss: 3.061260223388672
Validation loss: 2.7264040875178512

Epoch: 161| Step: 0
Training loss: 2.53488826751709
Validation loss: 2.7463175609547603

Epoch: 6| Step: 1
Training loss: 3.0440151691436768
Validation loss: 2.742510808411465

Epoch: 6| Step: 2
Training loss: 3.100785255432129
Validation loss: 2.715002534210041

Epoch: 6| Step: 3
Training loss: 2.161771297454834
Validation loss: 2.6869053404818297

Epoch: 6| Step: 4
Training loss: 2.6539666652679443
Validation loss: 2.666184184371784

Epoch: 6| Step: 5
Training loss: 3.5025668144226074
Validation loss: 2.6638061769547

Epoch: 6| Step: 6
Training loss: 1.7009458541870117
Validation loss: 2.6574699981238252

Epoch: 6| Step: 7
Training loss: 2.7373971939086914
Validation loss: 2.656903161797472

Epoch: 6| Step: 8
Training loss: 2.5974926948547363
Validation loss: 2.6519446706259124

Epoch: 6| Step: 9
Training loss: 2.6905980110168457
Validation loss: 2.6572019900045087

Epoch: 6| Step: 10
Training loss: 2.9686365127563477
Validation loss: 2.655976664635443

Epoch: 6| Step: 11
Training loss: 3.1250998973846436
Validation loss: 2.6546491012778333

Epoch: 6| Step: 12
Training loss: 3.0995354652404785
Validation loss: 2.667660851632395

Epoch: 6| Step: 13
Training loss: 3.076673746109009
Validation loss: 2.667361056932839

Epoch: 162| Step: 0
Training loss: 3.3581252098083496
Validation loss: 2.6717036718963296

Epoch: 6| Step: 1
Training loss: 3.0254740715026855
Validation loss: 2.6728103801768315

Epoch: 6| Step: 2
Training loss: 2.6746647357940674
Validation loss: 2.6744749751142276

Epoch: 6| Step: 3
Training loss: 2.3591556549072266
Validation loss: 2.6862229480538318

Epoch: 6| Step: 4
Training loss: 2.6796817779541016
Validation loss: 2.6741974481972317

Epoch: 6| Step: 5
Training loss: 3.2627339363098145
Validation loss: 2.671715597952566

Epoch: 6| Step: 6
Training loss: 2.2487587928771973
Validation loss: 2.680840825521818

Epoch: 6| Step: 7
Training loss: 2.780466079711914
Validation loss: 2.6691724997694775

Epoch: 6| Step: 8
Training loss: 1.8540292978286743
Validation loss: 2.661385974576396

Epoch: 6| Step: 9
Training loss: 3.050114631652832
Validation loss: 2.6564961607738207

Epoch: 6| Step: 10
Training loss: 2.053267478942871
Validation loss: 2.6563220331745763

Epoch: 6| Step: 11
Training loss: 3.848851442337036
Validation loss: 2.6512927239941013

Epoch: 6| Step: 12
Training loss: 2.8830955028533936
Validation loss: 2.655963561868155

Epoch: 6| Step: 13
Training loss: 2.4018146991729736
Validation loss: 2.653122191788048

Epoch: 163| Step: 0
Training loss: 2.89056396484375
Validation loss: 2.646741226155271

Epoch: 6| Step: 1
Training loss: 2.281559467315674
Validation loss: 2.6550241349845805

Epoch: 6| Step: 2
Training loss: 3.562276840209961
Validation loss: 2.6553288916105866

Epoch: 6| Step: 3
Training loss: 3.0181937217712402
Validation loss: 2.6528461158916516

Epoch: 6| Step: 4
Training loss: 2.9494996070861816
Validation loss: 2.6505321046357513

Epoch: 6| Step: 5
Training loss: 3.2722742557525635
Validation loss: 2.6476955106181483

Epoch: 6| Step: 6
Training loss: 2.542692184448242
Validation loss: 2.6453999447566208

Epoch: 6| Step: 7
Training loss: 1.9066898822784424
Validation loss: 2.6481488904645367

Epoch: 6| Step: 8
Training loss: 2.7116332054138184
Validation loss: 2.6440829359075075

Epoch: 6| Step: 9
Training loss: 3.0152909755706787
Validation loss: 2.653089015714584

Epoch: 6| Step: 10
Training loss: 2.27856707572937
Validation loss: 2.667746187538229

Epoch: 6| Step: 11
Training loss: 2.0748116970062256
Validation loss: 2.6738910828867266

Epoch: 6| Step: 12
Training loss: 3.6508588790893555
Validation loss: 2.688900496370049

Epoch: 6| Step: 13
Training loss: 2.52903413772583
Validation loss: 2.7136981154000885

Epoch: 164| Step: 0
Training loss: 2.079807758331299
Validation loss: 2.6905351428575415

Epoch: 6| Step: 1
Training loss: 2.8890576362609863
Validation loss: 2.6832100781061317

Epoch: 6| Step: 2
Training loss: 4.449810028076172
Validation loss: 2.671587477448166

Epoch: 6| Step: 3
Training loss: 1.70001220703125
Validation loss: 2.663170078749298

Epoch: 6| Step: 4
Training loss: 2.751269817352295
Validation loss: 2.6551817976018435

Epoch: 6| Step: 5
Training loss: 3.1489312648773193
Validation loss: 2.649977207183838

Epoch: 6| Step: 6
Training loss: 3.0467710494995117
Validation loss: 2.642555041979718

Epoch: 6| Step: 7
Training loss: 2.4807252883911133
Validation loss: 2.6418107222485285

Epoch: 6| Step: 8
Training loss: 2.597355365753174
Validation loss: 2.6423237708307084

Epoch: 6| Step: 9
Training loss: 3.201658248901367
Validation loss: 2.647998568832233

Epoch: 6| Step: 10
Training loss: 2.103425979614258
Validation loss: 2.652885872830627

Epoch: 6| Step: 11
Training loss: 2.5920417308807373
Validation loss: 2.643810587544595

Epoch: 6| Step: 12
Training loss: 2.945228099822998
Validation loss: 2.64464638310094

Epoch: 6| Step: 13
Training loss: 2.559468984603882
Validation loss: 2.6418584187825522

Epoch: 165| Step: 0
Training loss: 2.8789124488830566
Validation loss: 2.641941329484345

Epoch: 6| Step: 1
Training loss: 2.7876524925231934
Validation loss: 2.645059557371242

Epoch: 6| Step: 2
Training loss: 2.610696315765381
Validation loss: 2.6454286780408633

Epoch: 6| Step: 3
Training loss: 3.4384074211120605
Validation loss: 2.6407498005897767

Epoch: 6| Step: 4
Training loss: 3.583221435546875
Validation loss: 2.637208151560958

Epoch: 6| Step: 5
Training loss: 2.0036251544952393
Validation loss: 2.6407162604793424

Epoch: 6| Step: 6
Training loss: 2.719060182571411
Validation loss: 2.6400395593335553

Epoch: 6| Step: 7
Training loss: 2.276317834854126
Validation loss: 2.6367050268316783

Epoch: 6| Step: 8
Training loss: 2.2654008865356445
Validation loss: 2.6384474385169243

Epoch: 6| Step: 9
Training loss: 3.2018585205078125
Validation loss: 2.6445347262967016

Epoch: 6| Step: 10
Training loss: 2.5832316875457764
Validation loss: 2.642340096094275

Epoch: 6| Step: 11
Training loss: 3.103600025177002
Validation loss: 2.6458511685812347

Epoch: 6| Step: 12
Training loss: 2.553563117980957
Validation loss: 2.638633435772311

Epoch: 6| Step: 13
Training loss: 2.548945426940918
Validation loss: 2.646914912808326

Epoch: 166| Step: 0
Training loss: 3.230865240097046
Validation loss: 2.6541178867381108

Epoch: 6| Step: 1
Training loss: 2.9873671531677246
Validation loss: 2.6596629568325576

Epoch: 6| Step: 2
Training loss: 2.6007823944091797
Validation loss: 2.657334522534442

Epoch: 6| Step: 3
Training loss: 2.6850626468658447
Validation loss: 2.6661764985771588

Epoch: 6| Step: 4
Training loss: 2.8165535926818848
Validation loss: 2.685909393013165

Epoch: 6| Step: 5
Training loss: 3.203015089035034
Validation loss: 2.69187149693889

Epoch: 6| Step: 6
Training loss: 2.709960460662842
Validation loss: 2.690696483017296

Epoch: 6| Step: 7
Training loss: 2.2700090408325195
Validation loss: 2.686047387379472

Epoch: 6| Step: 8
Training loss: 2.9174818992614746
Validation loss: 2.6867368093100925

Epoch: 6| Step: 9
Training loss: 2.951350688934326
Validation loss: 2.6584384543921358

Epoch: 6| Step: 10
Training loss: 2.094177484512329
Validation loss: 2.6511343961120932

Epoch: 6| Step: 11
Training loss: 1.9725639820098877
Validation loss: 2.6471953520210842

Epoch: 6| Step: 12
Training loss: 3.0625667572021484
Validation loss: 2.645452299425679

Epoch: 6| Step: 13
Training loss: 3.387141227722168
Validation loss: 2.635339908702399

Epoch: 167| Step: 0
Training loss: 2.1521475315093994
Validation loss: 2.6379794382279917

Epoch: 6| Step: 1
Training loss: 2.764148235321045
Validation loss: 2.637592977093112

Epoch: 6| Step: 2
Training loss: 3.267827033996582
Validation loss: 2.6380246531578804

Epoch: 6| Step: 3
Training loss: 3.1845507621765137
Validation loss: 2.6345074894607707

Epoch: 6| Step: 4
Training loss: 2.7279791831970215
Validation loss: 2.634620379376155

Epoch: 6| Step: 5
Training loss: 2.320481300354004
Validation loss: 2.6315197624186033

Epoch: 6| Step: 6
Training loss: 2.115168571472168
Validation loss: 2.6362746300235873

Epoch: 6| Step: 7
Training loss: 2.293031930923462
Validation loss: 2.6399501010935795

Epoch: 6| Step: 8
Training loss: 3.135021924972534
Validation loss: 2.6539075630967335

Epoch: 6| Step: 9
Training loss: 2.428866386413574
Validation loss: 2.653336509581535

Epoch: 6| Step: 10
Training loss: 3.371723175048828
Validation loss: 2.68248817869412

Epoch: 6| Step: 11
Training loss: 2.852717876434326
Validation loss: 2.7034606420865623

Epoch: 6| Step: 12
Training loss: 2.9541192054748535
Validation loss: 2.716500118214597

Epoch: 6| Step: 13
Training loss: 3.3517279624938965
Validation loss: 2.7226453237636115

Epoch: 168| Step: 0
Training loss: 2.8190643787384033
Validation loss: 2.7233932197734876

Epoch: 6| Step: 1
Training loss: 2.8844032287597656
Validation loss: 2.705620324739846

Epoch: 6| Step: 2
Training loss: 2.8585479259490967
Validation loss: 2.689836596929899

Epoch: 6| Step: 3
Training loss: 2.435060501098633
Validation loss: 2.666761593152118

Epoch: 6| Step: 4
Training loss: 2.9044017791748047
Validation loss: 2.650778724301246

Epoch: 6| Step: 5
Training loss: 3.572721004486084
Validation loss: 2.6448110611208024

Epoch: 6| Step: 6
Training loss: 2.768737316131592
Validation loss: 2.643630381553404

Epoch: 6| Step: 7
Training loss: 2.4657983779907227
Validation loss: 2.6378415041072394

Epoch: 6| Step: 8
Training loss: 2.7369117736816406
Validation loss: 2.6427498966135006

Epoch: 6| Step: 9
Training loss: 2.9211738109588623
Validation loss: 2.6393767813200593

Epoch: 6| Step: 10
Training loss: 2.8440046310424805
Validation loss: 2.638323865911012

Epoch: 6| Step: 11
Training loss: 2.145195245742798
Validation loss: 2.639582654481293

Epoch: 6| Step: 12
Training loss: 3.172672748565674
Validation loss: 2.634751319885254

Epoch: 6| Step: 13
Training loss: 1.5546870231628418
Validation loss: 2.6382818452773558

Epoch: 169| Step: 0
Training loss: 2.943801164627075
Validation loss: 2.63346742814587

Epoch: 6| Step: 1
Training loss: 2.4714298248291016
Validation loss: 2.634812549878192

Epoch: 6| Step: 2
Training loss: 2.741961717605591
Validation loss: 2.6318037074099303

Epoch: 6| Step: 3
Training loss: 2.0997636318206787
Validation loss: 2.6341757107806463

Epoch: 6| Step: 4
Training loss: 2.663910150527954
Validation loss: 2.634897344855852

Epoch: 6| Step: 5
Training loss: 2.919424533843994
Validation loss: 2.639260527908161

Epoch: 6| Step: 6
Training loss: 2.8450124263763428
Validation loss: 2.6441560406838693

Epoch: 6| Step: 7
Training loss: 2.929244041442871
Validation loss: 2.6514416125512894

Epoch: 6| Step: 8
Training loss: 2.1587607860565186
Validation loss: 2.6571291492831324

Epoch: 6| Step: 9
Training loss: 3.1054885387420654
Validation loss: 2.6538792169222267

Epoch: 6| Step: 10
Training loss: 3.075408458709717
Validation loss: 2.653852988314885

Epoch: 6| Step: 11
Training loss: 2.7139029502868652
Validation loss: 2.6562758927704184

Epoch: 6| Step: 12
Training loss: 2.1987698078155518
Validation loss: 2.645741929290115

Epoch: 6| Step: 13
Training loss: 4.278078079223633
Validation loss: 2.639587104961436

Epoch: 170| Step: 0
Training loss: 1.7026933431625366
Validation loss: 2.6396630656334663

Epoch: 6| Step: 1
Training loss: 2.848210334777832
Validation loss: 2.644942065720917

Epoch: 6| Step: 2
Training loss: 3.108930826187134
Validation loss: 2.642251919674617

Epoch: 6| Step: 3
Training loss: 3.199492931365967
Validation loss: 2.6305400838134108

Epoch: 6| Step: 4
Training loss: 2.7081966400146484
Validation loss: 2.639060817739015

Epoch: 6| Step: 5
Training loss: 2.54429292678833
Validation loss: 2.6406483034933768

Epoch: 6| Step: 6
Training loss: 3.5644562244415283
Validation loss: 2.6357511448603805

Epoch: 6| Step: 7
Training loss: 2.692166328430176
Validation loss: 2.642170680466519

Epoch: 6| Step: 8
Training loss: 2.4110705852508545
Validation loss: 2.6405271073823333

Epoch: 6| Step: 9
Training loss: 2.2619004249572754
Validation loss: 2.6494467002089306

Epoch: 6| Step: 10
Training loss: 3.3711376190185547
Validation loss: 2.6447558723470217

Epoch: 6| Step: 11
Training loss: 3.3604607582092285
Validation loss: 2.6493490434462026

Epoch: 6| Step: 12
Training loss: 2.2973294258117676
Validation loss: 2.662543771087482

Epoch: 6| Step: 13
Training loss: 1.9809695482254028
Validation loss: 2.6502813446906304

Epoch: 171| Step: 0
Training loss: 2.9438631534576416
Validation loss: 2.638103281297991

Epoch: 6| Step: 1
Training loss: 2.8174171447753906
Validation loss: 2.645474223680394

Epoch: 6| Step: 2
Training loss: 3.045773506164551
Validation loss: 2.652488454695671

Epoch: 6| Step: 3
Training loss: 2.5882091522216797
Validation loss: 2.6500507580336703

Epoch: 6| Step: 4
Training loss: 1.981125831604004
Validation loss: 2.6432931833369757

Epoch: 6| Step: 5
Training loss: 3.1193294525146484
Validation loss: 2.6470750736933883

Epoch: 6| Step: 6
Training loss: 2.206564426422119
Validation loss: 2.646283495810724

Epoch: 6| Step: 7
Training loss: 1.7522320747375488
Validation loss: 2.6486535943964475

Epoch: 6| Step: 8
Training loss: 3.4235363006591797
Validation loss: 2.6456280651912896

Epoch: 6| Step: 9
Training loss: 3.198826313018799
Validation loss: 2.6432783936941497

Epoch: 6| Step: 10
Training loss: 3.036719799041748
Validation loss: 2.6451588343548518

Epoch: 6| Step: 11
Training loss: 2.948301315307617
Validation loss: 2.6472404618417062

Epoch: 6| Step: 12
Training loss: 2.1226744651794434
Validation loss: 2.6377865524702173

Epoch: 6| Step: 13
Training loss: 3.424856424331665
Validation loss: 2.6355694596485426

Epoch: 172| Step: 0
Training loss: 2.5754880905151367
Validation loss: 2.6296217159558366

Epoch: 6| Step: 1
Training loss: 2.808237075805664
Validation loss: 2.6299125866223405

Epoch: 6| Step: 2
Training loss: 2.5193347930908203
Validation loss: 2.625983617639029

Epoch: 6| Step: 3
Training loss: 2.291990280151367
Validation loss: 2.6250933549737416

Epoch: 6| Step: 4
Training loss: 2.899369716644287
Validation loss: 2.6324948803071053

Epoch: 6| Step: 5
Training loss: 2.8572001457214355
Validation loss: 2.6307772667177263

Epoch: 6| Step: 6
Training loss: 2.2782721519470215
Validation loss: 2.63863548668482

Epoch: 6| Step: 7
Training loss: 2.61958646774292
Validation loss: 2.6452110531509563

Epoch: 6| Step: 8
Training loss: 2.8744258880615234
Validation loss: 2.652010258807931

Epoch: 6| Step: 9
Training loss: 2.558474063873291
Validation loss: 2.66138264184357

Epoch: 6| Step: 10
Training loss: 3.702688694000244
Validation loss: 2.6809868197287283

Epoch: 6| Step: 11
Training loss: 2.8914098739624023
Validation loss: 2.6710249121471117

Epoch: 6| Step: 12
Training loss: 3.2714099884033203
Validation loss: 2.6467356861278577

Epoch: 6| Step: 13
Training loss: 2.0622568130493164
Validation loss: 2.634828016322146

Epoch: 173| Step: 0
Training loss: 2.3151328563690186
Validation loss: 2.620269580553937

Epoch: 6| Step: 1
Training loss: 2.496264934539795
Validation loss: 2.6185762061867663

Epoch: 6| Step: 2
Training loss: 2.928868293762207
Validation loss: 2.623862281922371

Epoch: 6| Step: 3
Training loss: 2.470550060272217
Validation loss: 2.611537712876515

Epoch: 6| Step: 4
Training loss: 3.014589786529541
Validation loss: 2.619854057988813

Epoch: 6| Step: 5
Training loss: 2.764047145843506
Validation loss: 2.6160404682159424

Epoch: 6| Step: 6
Training loss: 2.3561463356018066
Validation loss: 2.6177484604620163

Epoch: 6| Step: 7
Training loss: 2.9299511909484863
Validation loss: 2.6117725449223674

Epoch: 6| Step: 8
Training loss: 2.832965850830078
Validation loss: 2.619308912625877

Epoch: 6| Step: 9
Training loss: 2.8282737731933594
Validation loss: 2.6261826484434065

Epoch: 6| Step: 10
Training loss: 2.561306953430176
Validation loss: 2.6327953107895388

Epoch: 6| Step: 11
Training loss: 2.5228984355926514
Validation loss: 2.630409663723361

Epoch: 6| Step: 12
Training loss: 3.6334164142608643
Validation loss: 2.6381046592548327

Epoch: 6| Step: 13
Training loss: 2.623443603515625
Validation loss: 2.6202584338444534

Epoch: 174| Step: 0
Training loss: 2.74961519241333
Validation loss: 2.620454590807679

Epoch: 6| Step: 1
Training loss: 2.799133539199829
Validation loss: 2.606165883361652

Epoch: 6| Step: 2
Training loss: 2.5791211128234863
Validation loss: 2.613814930762014

Epoch: 6| Step: 3
Training loss: 2.9813010692596436
Validation loss: 2.620897877600885

Epoch: 6| Step: 4
Training loss: 2.7361526489257812
Validation loss: 2.6153958997418805

Epoch: 6| Step: 5
Training loss: 2.831326484680176
Validation loss: 2.6228675816648748

Epoch: 6| Step: 6
Training loss: 1.7188313007354736
Validation loss: 2.614004486350603

Epoch: 6| Step: 7
Training loss: 2.916208267211914
Validation loss: 2.624622328307039

Epoch: 6| Step: 8
Training loss: 3.271609306335449
Validation loss: 2.6226866245269775

Epoch: 6| Step: 9
Training loss: 2.555191993713379
Validation loss: 2.624741800369755

Epoch: 6| Step: 10
Training loss: 2.800536870956421
Validation loss: 2.6301927822892384

Epoch: 6| Step: 11
Training loss: 2.406968116760254
Validation loss: 2.630731564696117

Epoch: 6| Step: 12
Training loss: 2.5912928581237793
Validation loss: 2.6491736135175152

Epoch: 6| Step: 13
Training loss: 3.578446388244629
Validation loss: 2.6565719676274124

Epoch: 175| Step: 0
Training loss: 2.6332740783691406
Validation loss: 2.6687574514778714

Epoch: 6| Step: 1
Training loss: 2.219764471054077
Validation loss: 2.6673304291181665

Epoch: 6| Step: 2
Training loss: 1.8299282789230347
Validation loss: 2.66176789294007

Epoch: 6| Step: 3
Training loss: 3.014655828475952
Validation loss: 2.6638178133195445

Epoch: 6| Step: 4
Training loss: 2.4462926387786865
Validation loss: 2.647096895402478

Epoch: 6| Step: 5
Training loss: 2.9601521492004395
Validation loss: 2.6335629634959723

Epoch: 6| Step: 6
Training loss: 3.1527187824249268
Validation loss: 2.633171030270156

Epoch: 6| Step: 7
Training loss: 2.664311408996582
Validation loss: 2.6134574233844714

Epoch: 6| Step: 8
Training loss: 3.383432388305664
Validation loss: 2.618167563151288

Epoch: 6| Step: 9
Training loss: 2.782036781311035
Validation loss: 2.611913873303321

Epoch: 6| Step: 10
Training loss: 2.541388511657715
Validation loss: 2.611156307240968

Epoch: 6| Step: 11
Training loss: 2.9666433334350586
Validation loss: 2.6104378597710722

Epoch: 6| Step: 12
Training loss: 2.4099462032318115
Validation loss: 2.6063249982813352

Epoch: 6| Step: 13
Training loss: 3.4312973022460938
Validation loss: 2.60373770037005

Epoch: 176| Step: 0
Training loss: 2.788455009460449
Validation loss: 2.602831689260339

Epoch: 6| Step: 1
Training loss: 2.6779823303222656
Validation loss: 2.604742362935056

Epoch: 6| Step: 2
Training loss: 2.6587092876434326
Validation loss: 2.613846734005918

Epoch: 6| Step: 3
Training loss: 2.829390525817871
Validation loss: 2.6170366733304915

Epoch: 6| Step: 4
Training loss: 2.283013105392456
Validation loss: 2.6140051708426526

Epoch: 6| Step: 5
Training loss: 3.856557846069336
Validation loss: 2.6141273616462626

Epoch: 6| Step: 6
Training loss: 2.3673205375671387
Validation loss: 2.595337665209206

Epoch: 6| Step: 7
Training loss: 2.9844937324523926
Validation loss: 2.604946176211039

Epoch: 6| Step: 8
Training loss: 3.00388765335083
Validation loss: 2.603300740641932

Epoch: 6| Step: 9
Training loss: 2.403959035873413
Validation loss: 2.610535260169737

Epoch: 6| Step: 10
Training loss: 2.456578016281128
Validation loss: 2.6224930030043407

Epoch: 6| Step: 11
Training loss: 2.6379051208496094
Validation loss: 2.62487522761027

Epoch: 6| Step: 12
Training loss: 2.1672632694244385
Validation loss: 2.625311787410449

Epoch: 6| Step: 13
Training loss: 3.1620330810546875
Validation loss: 2.6284603482933453

Epoch: 177| Step: 0
Training loss: 2.9133503437042236
Validation loss: 2.6278750563180573

Epoch: 6| Step: 1
Training loss: 2.4550890922546387
Validation loss: 2.6167331152064826

Epoch: 6| Step: 2
Training loss: 2.9329440593719482
Validation loss: 2.605800305643389

Epoch: 6| Step: 3
Training loss: 2.2997183799743652
Validation loss: 2.598798805667508

Epoch: 6| Step: 4
Training loss: 1.9039620161056519
Validation loss: 2.594132154218612

Epoch: 6| Step: 5
Training loss: 2.3490376472473145
Validation loss: 2.5891421738491265

Epoch: 6| Step: 6
Training loss: 2.7749440670013428
Validation loss: 2.5910752665612007

Epoch: 6| Step: 7
Training loss: 2.7935333251953125
Validation loss: 2.591605745336061

Epoch: 6| Step: 8
Training loss: 2.6763358116149902
Validation loss: 2.587548881448725

Epoch: 6| Step: 9
Training loss: 3.754408836364746
Validation loss: 2.5870143675035044

Epoch: 6| Step: 10
Training loss: 2.6168875694274902
Validation loss: 2.5838858530085576

Epoch: 6| Step: 11
Training loss: 2.8070311546325684
Validation loss: 2.583669036947271

Epoch: 6| Step: 12
Training loss: 2.9417319297790527
Validation loss: 2.585225664159303

Epoch: 6| Step: 13
Training loss: 3.0152392387390137
Validation loss: 2.5878018256156676

Epoch: 178| Step: 0
Training loss: 2.9577574729919434
Validation loss: 2.587940021227765

Epoch: 6| Step: 1
Training loss: 2.9840893745422363
Validation loss: 2.594078028073875

Epoch: 6| Step: 2
Training loss: 2.558553457260132
Validation loss: 2.5992398415842364

Epoch: 6| Step: 3
Training loss: 2.2806990146636963
Validation loss: 2.610214033434468

Epoch: 6| Step: 4
Training loss: 2.906407594680786
Validation loss: 2.633956123423833

Epoch: 6| Step: 5
Training loss: 2.9588115215301514
Validation loss: 2.632128679624168

Epoch: 6| Step: 6
Training loss: 3.3846347332000732
Validation loss: 2.63348937290971

Epoch: 6| Step: 7
Training loss: 2.732626438140869
Validation loss: 2.620550763222479

Epoch: 6| Step: 8
Training loss: 2.4009101390838623
Validation loss: 2.6077741448597243

Epoch: 6| Step: 9
Training loss: 2.8711185455322266
Validation loss: 2.5992294306396158

Epoch: 6| Step: 10
Training loss: 2.7068638801574707
Validation loss: 2.587404258789555

Epoch: 6| Step: 11
Training loss: 3.216714382171631
Validation loss: 2.5903401054361814

Epoch: 6| Step: 12
Training loss: 2.2988510131835938
Validation loss: 2.5826835760506253

Epoch: 6| Step: 13
Training loss: 1.1428780555725098
Validation loss: 2.591561302062004

Epoch: 179| Step: 0
Training loss: 1.6877896785736084
Validation loss: 2.583529838951685

Epoch: 6| Step: 1
Training loss: 2.6148288249969482
Validation loss: 2.6030157125124367

Epoch: 6| Step: 2
Training loss: 3.0804381370544434
Validation loss: 2.6147195395602973

Epoch: 6| Step: 3
Training loss: 3.288271903991699
Validation loss: 2.634289779970723

Epoch: 6| Step: 4
Training loss: 3.072047472000122
Validation loss: 2.637932518477081

Epoch: 6| Step: 5
Training loss: 2.756413221359253
Validation loss: 2.6314090323704544

Epoch: 6| Step: 6
Training loss: 1.8974182605743408
Validation loss: 2.6223481726902786

Epoch: 6| Step: 7
Training loss: 4.207762718200684
Validation loss: 2.6095765149721535

Epoch: 6| Step: 8
Training loss: 2.844674587249756
Validation loss: 2.5997818131600656

Epoch: 6| Step: 9
Training loss: 1.870227575302124
Validation loss: 2.5907578058140253

Epoch: 6| Step: 10
Training loss: 2.1581995487213135
Validation loss: 2.5844785885144304

Epoch: 6| Step: 11
Training loss: 3.0119073390960693
Validation loss: 2.5888119307897424

Epoch: 6| Step: 12
Training loss: 2.588125705718994
Validation loss: 2.585491466265853

Epoch: 6| Step: 13
Training loss: 3.0187978744506836
Validation loss: 2.57871493985576

Epoch: 180| Step: 0
Training loss: 3.6139800548553467
Validation loss: 2.5816565021391837

Epoch: 6| Step: 1
Training loss: 2.3011364936828613
Validation loss: 2.5747229642765497

Epoch: 6| Step: 2
Training loss: 2.35408353805542
Validation loss: 2.5852110180803525

Epoch: 6| Step: 3
Training loss: 2.900402545928955
Validation loss: 2.5829143190896637

Epoch: 6| Step: 4
Training loss: 3.7886857986450195
Validation loss: 2.580553017636781

Epoch: 6| Step: 5
Training loss: 2.3379175662994385
Validation loss: 2.5832669965682493

Epoch: 6| Step: 6
Training loss: 3.0528674125671387
Validation loss: 2.587126301180932

Epoch: 6| Step: 7
Training loss: 2.2394795417785645
Validation loss: 2.599366106012816

Epoch: 6| Step: 8
Training loss: 2.9422640800476074
Validation loss: 2.6118394995248444

Epoch: 6| Step: 9
Training loss: 2.0128345489501953
Validation loss: 2.617110190852996

Epoch: 6| Step: 10
Training loss: 2.277693748474121
Validation loss: 2.642725734300511

Epoch: 6| Step: 11
Training loss: 2.381042003631592
Validation loss: 2.687395816208214

Epoch: 6| Step: 12
Training loss: 2.7009589672088623
Validation loss: 2.6839602737016577

Epoch: 6| Step: 13
Training loss: 3.571857452392578
Validation loss: 2.679804484049479

Epoch: 181| Step: 0
Training loss: 3.3717846870422363
Validation loss: 2.6684638761704966

Epoch: 6| Step: 1
Training loss: 3.006554126739502
Validation loss: 2.6495310952586513

Epoch: 6| Step: 2
Training loss: 2.507969856262207
Validation loss: 2.632031648389755

Epoch: 6| Step: 3
Training loss: 2.2836151123046875
Validation loss: 2.621654716871118

Epoch: 6| Step: 4
Training loss: 3.232952117919922
Validation loss: 2.591947824724259

Epoch: 6| Step: 5
Training loss: 2.715176582336426
Validation loss: 2.5898817969906713

Epoch: 6| Step: 6
Training loss: 3.1269216537475586
Validation loss: 2.5797731081644693

Epoch: 6| Step: 7
Training loss: 3.4785549640655518
Validation loss: 2.572247851279474

Epoch: 6| Step: 8
Training loss: 1.9728941917419434
Validation loss: 2.577728489393829

Epoch: 6| Step: 9
Training loss: 1.6768531799316406
Validation loss: 2.5782585823407738

Epoch: 6| Step: 10
Training loss: 2.5105466842651367
Validation loss: 2.57855365865974

Epoch: 6| Step: 11
Training loss: 3.244804859161377
Validation loss: 2.5792236071760937

Epoch: 6| Step: 12
Training loss: 2.4845058917999268
Validation loss: 2.5806920323320615

Epoch: 6| Step: 13
Training loss: 2.1822702884674072
Validation loss: 2.578341328969566

Epoch: 182| Step: 0
Training loss: 3.3659191131591797
Validation loss: 2.5717808969559206

Epoch: 6| Step: 1
Training loss: 2.255966901779175
Validation loss: 2.5725587849975913

Epoch: 6| Step: 2
Training loss: 2.5133233070373535
Validation loss: 2.5735842335608696

Epoch: 6| Step: 3
Training loss: 1.6090482473373413
Validation loss: 2.5715944305542977

Epoch: 6| Step: 4
Training loss: 2.836099863052368
Validation loss: 2.5769767709957656

Epoch: 6| Step: 5
Training loss: 2.623307943344116
Validation loss: 2.576377667406554

Epoch: 6| Step: 6
Training loss: 2.857692003250122
Validation loss: 2.580405742891373

Epoch: 6| Step: 7
Training loss: 1.906746506690979
Validation loss: 2.5844529803081224

Epoch: 6| Step: 8
Training loss: 3.581178665161133
Validation loss: 2.5850163557196177

Epoch: 6| Step: 9
Training loss: 2.828096866607666
Validation loss: 2.58807292292195

Epoch: 6| Step: 10
Training loss: 2.6860146522521973
Validation loss: 2.587880644747006

Epoch: 6| Step: 11
Training loss: 2.9334754943847656
Validation loss: 2.5857012835882043

Epoch: 6| Step: 12
Training loss: 2.8547723293304443
Validation loss: 2.591487205156716

Epoch: 6| Step: 13
Training loss: 3.414914846420288
Validation loss: 2.5907031259229107

Epoch: 183| Step: 0
Training loss: 2.9599294662475586
Validation loss: 2.5968247331598753

Epoch: 6| Step: 1
Training loss: 2.5682919025421143
Validation loss: 2.5888816207967777

Epoch: 6| Step: 2
Training loss: 2.8925561904907227
Validation loss: 2.586289152022331

Epoch: 6| Step: 3
Training loss: 3.115464687347412
Validation loss: 2.5860844991540395

Epoch: 6| Step: 4
Training loss: 2.5604090690612793
Validation loss: 2.5799639865916264

Epoch: 6| Step: 5
Training loss: 2.902879238128662
Validation loss: 2.5850270050828175

Epoch: 6| Step: 6
Training loss: 2.6351847648620605
Validation loss: 2.5811037966000137

Epoch: 6| Step: 7
Training loss: 2.7377662658691406
Validation loss: 2.5815336986254622

Epoch: 6| Step: 8
Training loss: 2.6586742401123047
Validation loss: 2.585290288412443

Epoch: 6| Step: 9
Training loss: 2.689422130584717
Validation loss: 2.586356983389906

Epoch: 6| Step: 10
Training loss: 2.11924147605896
Validation loss: 2.5890493982581684

Epoch: 6| Step: 11
Training loss: 3.2732059955596924
Validation loss: 2.602374084534184

Epoch: 6| Step: 12
Training loss: 2.039792060852051
Validation loss: 2.6059079708591586

Epoch: 6| Step: 13
Training loss: 2.645789384841919
Validation loss: 2.610104432670019

Epoch: 184| Step: 0
Training loss: 2.644559383392334
Validation loss: 2.6140175711724067

Epoch: 6| Step: 1
Training loss: 2.595125675201416
Validation loss: 2.605381355490736

Epoch: 6| Step: 2
Training loss: 2.168180465698242
Validation loss: 2.5976734725377892

Epoch: 6| Step: 3
Training loss: 2.672823905944824
Validation loss: 2.6055255269491546

Epoch: 6| Step: 4
Training loss: 3.1804792881011963
Validation loss: 2.604937227823401

Epoch: 6| Step: 5
Training loss: 2.904700994491577
Validation loss: 2.5996762296204925

Epoch: 6| Step: 6
Training loss: 2.838007926940918
Validation loss: 2.5897939794807026

Epoch: 6| Step: 7
Training loss: 2.8446829319000244
Validation loss: 2.5885796777663694

Epoch: 6| Step: 8
Training loss: 2.566110134124756
Validation loss: 2.587509839765487

Epoch: 6| Step: 9
Training loss: 2.5626168251037598
Validation loss: 2.5783670230578353

Epoch: 6| Step: 10
Training loss: 1.783370018005371
Validation loss: 2.5893358927901073

Epoch: 6| Step: 11
Training loss: 3.3705501556396484
Validation loss: 2.5867975809240855

Epoch: 6| Step: 12
Training loss: 3.242155075073242
Validation loss: 2.5929984636204217

Epoch: 6| Step: 13
Training loss: 2.174013376235962
Validation loss: 2.5844468326978784

Epoch: 185| Step: 0
Training loss: 3.1128323078155518
Validation loss: 2.603174873577651

Epoch: 6| Step: 1
Training loss: 3.2116663455963135
Validation loss: 2.586708463648314

Epoch: 6| Step: 2
Training loss: 2.4677610397338867
Validation loss: 2.587277186814175

Epoch: 6| Step: 3
Training loss: 3.0697927474975586
Validation loss: 2.569807726849792

Epoch: 6| Step: 4
Training loss: 2.0331501960754395
Validation loss: 2.5611141445816203

Epoch: 6| Step: 5
Training loss: 2.9142889976501465
Validation loss: 2.5638020884606147

Epoch: 6| Step: 6
Training loss: 3.25673508644104
Validation loss: 2.5613834832304265

Epoch: 6| Step: 7
Training loss: 2.245845317840576
Validation loss: 2.566202748206354

Epoch: 6| Step: 8
Training loss: 2.892179489135742
Validation loss: 2.562172177017376

Epoch: 6| Step: 9
Training loss: 2.8518218994140625
Validation loss: 2.569584931096723

Epoch: 6| Step: 10
Training loss: 2.6214845180511475
Validation loss: 2.5649746771781676

Epoch: 6| Step: 11
Training loss: 2.048476457595825
Validation loss: 2.564557190864317

Epoch: 6| Step: 12
Training loss: 3.1211929321289062
Validation loss: 2.5672445784332933

Epoch: 6| Step: 13
Training loss: 1.7672009468078613
Validation loss: 2.5706821821069203

Epoch: 186| Step: 0
Training loss: 2.6152138710021973
Validation loss: 2.5814843370068457

Epoch: 6| Step: 1
Training loss: 2.988848924636841
Validation loss: 2.5979894438097553

Epoch: 6| Step: 2
Training loss: 2.577643394470215
Validation loss: 2.609737483404016

Epoch: 6| Step: 3
Training loss: 2.2253618240356445
Validation loss: 2.6198466362491732

Epoch: 6| Step: 4
Training loss: 3.2450923919677734
Validation loss: 2.6170390408526183

Epoch: 6| Step: 5
Training loss: 2.0865530967712402
Validation loss: 2.6177688490959907

Epoch: 6| Step: 6
Training loss: 2.4012556076049805
Validation loss: 2.6127699677662184

Epoch: 6| Step: 7
Training loss: 2.9861927032470703
Validation loss: 2.603220044925649

Epoch: 6| Step: 8
Training loss: 2.7678780555725098
Validation loss: 2.56728563257443

Epoch: 6| Step: 9
Training loss: 2.626741886138916
Validation loss: 2.563262208815544

Epoch: 6| Step: 10
Training loss: 3.299469470977783
Validation loss: 2.5627356139562463

Epoch: 6| Step: 11
Training loss: 2.7666072845458984
Validation loss: 2.5674376718459593

Epoch: 6| Step: 12
Training loss: 2.972224473953247
Validation loss: 2.5722527862876974

Epoch: 6| Step: 13
Training loss: 2.067600727081299
Validation loss: 2.576175361551264

Epoch: 187| Step: 0
Training loss: 3.113321304321289
Validation loss: 2.579524568332139

Epoch: 6| Step: 1
Training loss: 2.8083560466766357
Validation loss: 2.5794846345019597

Epoch: 6| Step: 2
Training loss: 2.3603639602661133
Validation loss: 2.580422939792756

Epoch: 6| Step: 3
Training loss: 2.6164770126342773
Validation loss: 2.581287109723655

Epoch: 6| Step: 4
Training loss: 2.878955364227295
Validation loss: 2.575248888743821

Epoch: 6| Step: 5
Training loss: 2.814328670501709
Validation loss: 2.5755512099112234

Epoch: 6| Step: 6
Training loss: 2.6473846435546875
Validation loss: 2.5776352113293064

Epoch: 6| Step: 7
Training loss: 2.068141222000122
Validation loss: 2.5738403053693872

Epoch: 6| Step: 8
Training loss: 2.873279571533203
Validation loss: 2.5653505222771757

Epoch: 6| Step: 9
Training loss: 2.164714813232422
Validation loss: 2.5649762743262836

Epoch: 6| Step: 10
Training loss: 2.2837557792663574
Validation loss: 2.5640733524035384

Epoch: 6| Step: 11
Training loss: 2.442577600479126
Validation loss: 2.5695321559906006

Epoch: 6| Step: 12
Training loss: 3.6910037994384766
Validation loss: 2.5875384705041045

Epoch: 6| Step: 13
Training loss: 3.7922422885894775
Validation loss: 2.5895025499405397

Epoch: 188| Step: 0
Training loss: 3.0619235038757324
Validation loss: 2.611578510653588

Epoch: 6| Step: 1
Training loss: 1.6356909275054932
Validation loss: 2.6257287866325787

Epoch: 6| Step: 2
Training loss: 2.7281501293182373
Validation loss: 2.633981381693194

Epoch: 6| Step: 3
Training loss: 3.3021492958068848
Validation loss: 2.6357161460384244

Epoch: 6| Step: 4
Training loss: 2.409118413925171
Validation loss: 2.6385101554214314

Epoch: 6| Step: 5
Training loss: 2.019953727722168
Validation loss: 2.6495545833341536

Epoch: 6| Step: 6
Training loss: 3.393949031829834
Validation loss: 2.6470536698577223

Epoch: 6| Step: 7
Training loss: 2.7766029834747314
Validation loss: 2.640047704019854

Epoch: 6| Step: 8
Training loss: 2.1230931282043457
Validation loss: 2.6300904981551634

Epoch: 6| Step: 9
Training loss: 3.1809747219085693
Validation loss: 2.5962853688065723

Epoch: 6| Step: 10
Training loss: 3.3569257259368896
Validation loss: 2.5724212815684657

Epoch: 6| Step: 11
Training loss: 2.823481798171997
Validation loss: 2.5626086957993044

Epoch: 6| Step: 12
Training loss: 2.5708460807800293
Validation loss: 2.557299206333776

Epoch: 6| Step: 13
Training loss: 2.2123641967773438
Validation loss: 2.554647681533649

Epoch: 189| Step: 0
Training loss: 3.3328118324279785
Validation loss: 2.559840711214209

Epoch: 6| Step: 1
Training loss: 2.71928071975708
Validation loss: 2.5596626855993785

Epoch: 6| Step: 2
Training loss: 2.42317533493042
Validation loss: 2.5580393652762137

Epoch: 6| Step: 3
Training loss: 2.275062322616577
Validation loss: 2.558509793332828

Epoch: 6| Step: 4
Training loss: 2.4949023723602295
Validation loss: 2.557148979556176

Epoch: 6| Step: 5
Training loss: 2.973226547241211
Validation loss: 2.5537626153679303

Epoch: 6| Step: 6
Training loss: 2.6008219718933105
Validation loss: 2.5506533884233042

Epoch: 6| Step: 7
Training loss: 2.8740882873535156
Validation loss: 2.5516583996434368

Epoch: 6| Step: 8
Training loss: 2.5352444648742676
Validation loss: 2.5531759928631526

Epoch: 6| Step: 9
Training loss: 2.144617795944214
Validation loss: 2.5568231690314507

Epoch: 6| Step: 10
Training loss: 3.691490411758423
Validation loss: 2.5567657152811685

Epoch: 6| Step: 11
Training loss: 2.5669209957122803
Validation loss: 2.559846903688164

Epoch: 6| Step: 12
Training loss: 2.8690762519836426
Validation loss: 2.5554013072803454

Epoch: 6| Step: 13
Training loss: 2.381391763687134
Validation loss: 2.5559712020299767

Epoch: 190| Step: 0
Training loss: 2.700963020324707
Validation loss: 2.568500300889374

Epoch: 6| Step: 1
Training loss: 3.3129971027374268
Validation loss: 2.5853259486536824

Epoch: 6| Step: 2
Training loss: 2.5693936347961426
Validation loss: 2.5980607719831568

Epoch: 6| Step: 3
Training loss: 2.5866448879241943
Validation loss: 2.6229582704523557

Epoch: 6| Step: 4
Training loss: 2.538926124572754
Validation loss: 2.6358485350044827

Epoch: 6| Step: 5
Training loss: 2.725461006164551
Validation loss: 2.645748092282203

Epoch: 6| Step: 6
Training loss: 3.2916085720062256
Validation loss: 2.6234829323266142

Epoch: 6| Step: 7
Training loss: 2.66178822517395
Validation loss: 2.6242285543872463

Epoch: 6| Step: 8
Training loss: 2.2152609825134277
Validation loss: 2.60535458595522

Epoch: 6| Step: 9
Training loss: 2.76163387298584
Validation loss: 2.5830070075168403

Epoch: 6| Step: 10
Training loss: 2.2520952224731445
Validation loss: 2.572181099204607

Epoch: 6| Step: 11
Training loss: 2.9337754249572754
Validation loss: 2.571684819395824

Epoch: 6| Step: 12
Training loss: 2.3402881622314453
Validation loss: 2.559805800837855

Epoch: 6| Step: 13
Training loss: 3.4077863693237305
Validation loss: 2.563624338437152

Epoch: 191| Step: 0
Training loss: 3.1679630279541016
Validation loss: 2.5606029956571517

Epoch: 6| Step: 1
Training loss: 3.043015480041504
Validation loss: 2.5525004633011354

Epoch: 6| Step: 2
Training loss: 2.5769128799438477
Validation loss: 2.553106041364772

Epoch: 6| Step: 3
Training loss: 2.8877742290496826
Validation loss: 2.556898616975354

Epoch: 6| Step: 4
Training loss: 2.138690948486328
Validation loss: 2.5625776116565993

Epoch: 6| Step: 5
Training loss: 2.9601259231567383
Validation loss: 2.571383153238604

Epoch: 6| Step: 6
Training loss: 2.4447860717773438
Validation loss: 2.5734770836368686

Epoch: 6| Step: 7
Training loss: 3.0595927238464355
Validation loss: 2.590307107535742

Epoch: 6| Step: 8
Training loss: 2.442605495452881
Validation loss: 2.5911376168650966

Epoch: 6| Step: 9
Training loss: 2.516193151473999
Validation loss: 2.6009070668169247

Epoch: 6| Step: 10
Training loss: 2.3740203380584717
Validation loss: 2.6002092951087543

Epoch: 6| Step: 11
Training loss: 2.5235283374786377
Validation loss: 2.5957215345034035

Epoch: 6| Step: 12
Training loss: 2.6044929027557373
Validation loss: 2.592735057236046

Epoch: 6| Step: 13
Training loss: 3.0817627906799316
Validation loss: 2.580017464135283

Epoch: 192| Step: 0
Training loss: 3.2311246395111084
Validation loss: 2.5675114200961207

Epoch: 6| Step: 1
Training loss: 3.085813283920288
Validation loss: 2.5628929215092815

Epoch: 6| Step: 2
Training loss: 2.0784244537353516
Validation loss: 2.5629649264838106

Epoch: 6| Step: 3
Training loss: 2.1246519088745117
Validation loss: 2.5624867587961178

Epoch: 6| Step: 4
Training loss: 2.1978261470794678
Validation loss: 2.5635884602864585

Epoch: 6| Step: 5
Training loss: 2.8452396392822266
Validation loss: 2.5739488909321446

Epoch: 6| Step: 6
Training loss: 3.1000492572784424
Validation loss: 2.573715953416722

Epoch: 6| Step: 7
Training loss: 2.6697514057159424
Validation loss: 2.5726631174805346

Epoch: 6| Step: 8
Training loss: 2.553635358810425
Validation loss: 2.579918030769594

Epoch: 6| Step: 9
Training loss: 2.152661085128784
Validation loss: 2.600571060693392

Epoch: 6| Step: 10
Training loss: 2.7801408767700195
Validation loss: 2.589058324854861

Epoch: 6| Step: 11
Training loss: 2.8285036087036133
Validation loss: 2.597596932482976

Epoch: 6| Step: 12
Training loss: 3.24581241607666
Validation loss: 2.5957533697928152

Epoch: 6| Step: 13
Training loss: 2.8909318447113037
Validation loss: 2.589490803339148

Epoch: 193| Step: 0
Training loss: 2.844104766845703
Validation loss: 2.59711169427441

Epoch: 6| Step: 1
Training loss: 2.454411506652832
Validation loss: 2.5855957692669285

Epoch: 6| Step: 2
Training loss: 2.4965381622314453
Validation loss: 2.5749429810431694

Epoch: 6| Step: 3
Training loss: 2.436591386795044
Validation loss: 2.5845242572087113

Epoch: 6| Step: 4
Training loss: 3.447835683822632
Validation loss: 2.5814666953138126

Epoch: 6| Step: 5
Training loss: 2.8635072708129883
Validation loss: 2.5714748213368077

Epoch: 6| Step: 6
Training loss: 2.290055274963379
Validation loss: 2.5640187930035334

Epoch: 6| Step: 7
Training loss: 2.999098300933838
Validation loss: 2.564857977692799

Epoch: 6| Step: 8
Training loss: 2.7277936935424805
Validation loss: 2.5614552369681736

Epoch: 6| Step: 9
Training loss: 1.972177267074585
Validation loss: 2.5740171940095964

Epoch: 6| Step: 10
Training loss: 2.615570545196533
Validation loss: 2.591215888659159

Epoch: 6| Step: 11
Training loss: 3.2666378021240234
Validation loss: 2.6027391623425227

Epoch: 6| Step: 12
Training loss: 2.3033621311187744
Validation loss: 2.5920844001154744

Epoch: 6| Step: 13
Training loss: 3.0678606033325195
Validation loss: 2.5925046987431024

Epoch: 194| Step: 0
Training loss: 2.1868505477905273
Validation loss: 2.5830517045913206

Epoch: 6| Step: 1
Training loss: 2.3837852478027344
Validation loss: 2.5772943112158004

Epoch: 6| Step: 2
Training loss: 2.614447593688965
Validation loss: 2.5821220900422786

Epoch: 6| Step: 3
Training loss: 2.2013840675354004
Validation loss: 2.5795689167514926

Epoch: 6| Step: 4
Training loss: 2.6360907554626465
Validation loss: 2.58087823980598

Epoch: 6| Step: 5
Training loss: 3.490001916885376
Validation loss: 2.5712375461414294

Epoch: 6| Step: 6
Training loss: 2.8973324298858643
Validation loss: 2.5698078986137145

Epoch: 6| Step: 7
Training loss: 3.032620906829834
Validation loss: 2.5553485296105825

Epoch: 6| Step: 8
Training loss: 2.651909351348877
Validation loss: 2.5550377471472627

Epoch: 6| Step: 9
Training loss: 3.735532283782959
Validation loss: 2.55455340877656

Epoch: 6| Step: 10
Training loss: 2.847163438796997
Validation loss: 2.5497338489819596

Epoch: 6| Step: 11
Training loss: 2.684854745864868
Validation loss: 2.5513402082586802

Epoch: 6| Step: 12
Training loss: 2.3854291439056396
Validation loss: 2.545101293953516

Epoch: 6| Step: 13
Training loss: 1.345527172088623
Validation loss: 2.551377696375693

Epoch: 195| Step: 0
Training loss: 3.0006628036499023
Validation loss: 2.550293195632196

Epoch: 6| Step: 1
Training loss: 2.8581395149230957
Validation loss: 2.5516542080909974

Epoch: 6| Step: 2
Training loss: 3.1408374309539795
Validation loss: 2.5528587397708686

Epoch: 6| Step: 3
Training loss: 2.4046764373779297
Validation loss: 2.559426051314159

Epoch: 6| Step: 4
Training loss: 3.4589157104492188
Validation loss: 2.5660251904559392

Epoch: 6| Step: 5
Training loss: 1.8238492012023926
Validation loss: 2.5736369009940856

Epoch: 6| Step: 6
Training loss: 3.0757288932800293
Validation loss: 2.581564126476165

Epoch: 6| Step: 7
Training loss: 1.9003053903579712
Validation loss: 2.5843562362014607

Epoch: 6| Step: 8
Training loss: 2.1649913787841797
Validation loss: 2.591374087077315

Epoch: 6| Step: 9
Training loss: 3.4898838996887207
Validation loss: 2.5814714867581605

Epoch: 6| Step: 10
Training loss: 2.3113014698028564
Validation loss: 2.578494284742622

Epoch: 6| Step: 11
Training loss: 2.0880465507507324
Validation loss: 2.5733950958457044

Epoch: 6| Step: 12
Training loss: 3.366079330444336
Validation loss: 2.5637087565596386

Epoch: 6| Step: 13
Training loss: 2.480677604675293
Validation loss: 2.560695681520688

Epoch: 196| Step: 0
Training loss: 3.283977508544922
Validation loss: 2.546774628341839

Epoch: 6| Step: 1
Training loss: 3.0201942920684814
Validation loss: 2.5457766030424382

Epoch: 6| Step: 2
Training loss: 1.9682039022445679
Validation loss: 2.5463901694102953

Epoch: 6| Step: 3
Training loss: 2.5314855575561523
Validation loss: 2.537680795115809

Epoch: 6| Step: 4
Training loss: 2.5483694076538086
Validation loss: 2.5416803975259104

Epoch: 6| Step: 5
Training loss: 2.4084601402282715
Validation loss: 2.5372558345076857

Epoch: 6| Step: 6
Training loss: 1.8452866077423096
Validation loss: 2.538950591958979

Epoch: 6| Step: 7
Training loss: 2.905435562133789
Validation loss: 2.5385071180200063

Epoch: 6| Step: 8
Training loss: 3.2814056873321533
Validation loss: 2.5372782855905514

Epoch: 6| Step: 9
Training loss: 2.2169783115386963
Validation loss: 2.5378530204937024

Epoch: 6| Step: 10
Training loss: 3.008875846862793
Validation loss: 2.54070480151843

Epoch: 6| Step: 11
Training loss: 2.4885873794555664
Validation loss: 2.5467106014169674

Epoch: 6| Step: 12
Training loss: 3.226940631866455
Validation loss: 2.551861329745221

Epoch: 6| Step: 13
Training loss: 3.1148970127105713
Validation loss: 2.561579829903059

Epoch: 197| Step: 0
Training loss: 2.884293556213379
Validation loss: 2.566430681495256

Epoch: 6| Step: 1
Training loss: 3.316882848739624
Validation loss: 2.576966921488444

Epoch: 6| Step: 2
Training loss: 3.2659788131713867
Validation loss: 2.5992654831178728

Epoch: 6| Step: 3
Training loss: 1.7088947296142578
Validation loss: 2.5887282458684777

Epoch: 6| Step: 4
Training loss: 2.61411190032959
Validation loss: 2.5835909612717165

Epoch: 6| Step: 5
Training loss: 3.1067769527435303
Validation loss: 2.5613116166924916

Epoch: 6| Step: 6
Training loss: 2.7795841693878174
Validation loss: 2.5462850832170054

Epoch: 6| Step: 7
Training loss: 1.9458448886871338
Validation loss: 2.5462184977787796

Epoch: 6| Step: 8
Training loss: 3.161860704421997
Validation loss: 2.5398146183260026

Epoch: 6| Step: 9
Training loss: 2.412301778793335
Validation loss: 2.5369993896894556

Epoch: 6| Step: 10
Training loss: 2.450000524520874
Validation loss: 2.5380459088151173

Epoch: 6| Step: 11
Training loss: 2.3260416984558105
Validation loss: 2.5358668655477543

Epoch: 6| Step: 12
Training loss: 3.2137036323547363
Validation loss: 2.5347158729389148

Epoch: 6| Step: 13
Training loss: 2.4190874099731445
Validation loss: 2.5367118876467467

Epoch: 198| Step: 0
Training loss: 2.3297393321990967
Validation loss: 2.5393847009187103

Epoch: 6| Step: 1
Training loss: 2.5667035579681396
Validation loss: 2.540329481965752

Epoch: 6| Step: 2
Training loss: 2.5869388580322266
Validation loss: 2.53667873977333

Epoch: 6| Step: 3
Training loss: 2.816528797149658
Validation loss: 2.541037380054433

Epoch: 6| Step: 4
Training loss: 2.6531455516815186
Validation loss: 2.5416527640435005

Epoch: 6| Step: 5
Training loss: 2.7987213134765625
Validation loss: 2.5454142016749226

Epoch: 6| Step: 6
Training loss: 2.2012720108032227
Validation loss: 2.544426143810313

Epoch: 6| Step: 7
Training loss: 2.6636404991149902
Validation loss: 2.5473287156833115

Epoch: 6| Step: 8
Training loss: 3.1685662269592285
Validation loss: 2.5589894838230585

Epoch: 6| Step: 9
Training loss: 3.34645414352417
Validation loss: 2.5591630910032537

Epoch: 6| Step: 10
Training loss: 2.4190192222595215
Validation loss: 2.5587508140071744

Epoch: 6| Step: 11
Training loss: 3.1520891189575195
Validation loss: 2.5507956166421213

Epoch: 6| Step: 12
Training loss: 2.2038888931274414
Validation loss: 2.5476640783330446

Epoch: 6| Step: 13
Training loss: 2.7342770099639893
Validation loss: 2.5489362183437554

Epoch: 199| Step: 0
Training loss: 2.7974507808685303
Validation loss: 2.547800710124354

Epoch: 6| Step: 1
Training loss: 2.133629322052002
Validation loss: 2.5534014599297636

Epoch: 6| Step: 2
Training loss: 2.727560043334961
Validation loss: 2.551368595451437

Epoch: 6| Step: 3
Training loss: 2.9634900093078613
Validation loss: 2.553529308688256

Epoch: 6| Step: 4
Training loss: 2.3889641761779785
Validation loss: 2.551262145401329

Epoch: 6| Step: 5
Training loss: 3.159440755844116
Validation loss: 2.558121212067143

Epoch: 6| Step: 6
Training loss: 2.002941131591797
Validation loss: 2.5541728850333922

Epoch: 6| Step: 7
Training loss: 2.9259839057922363
Validation loss: 2.5612018698005268

Epoch: 6| Step: 8
Training loss: 2.0938220024108887
Validation loss: 2.5598276661288355

Epoch: 6| Step: 9
Training loss: 3.581233024597168
Validation loss: 2.564041253059141

Epoch: 6| Step: 10
Training loss: 2.9031081199645996
Validation loss: 2.561254788470525

Epoch: 6| Step: 11
Training loss: 3.0013012886047363
Validation loss: 2.563184666377242

Epoch: 6| Step: 12
Training loss: 2.1564269065856934
Validation loss: 2.5585454151194584

Epoch: 6| Step: 13
Training loss: 2.5610036849975586
Validation loss: 2.5611036490368586

Epoch: 200| Step: 0
Training loss: 3.722622871398926
Validation loss: 2.5603511205283542

Epoch: 6| Step: 1
Training loss: 2.873762607574463
Validation loss: 2.560845293024535

Epoch: 6| Step: 2
Training loss: 1.8399405479431152
Validation loss: 2.5623541339751212

Epoch: 6| Step: 3
Training loss: 2.355625867843628
Validation loss: 2.5595052498643116

Epoch: 6| Step: 4
Training loss: 2.6210827827453613
Validation loss: 2.5555908218506844

Epoch: 6| Step: 5
Training loss: 2.4559688568115234
Validation loss: 2.5573166724174254

Epoch: 6| Step: 6
Training loss: 2.237778663635254
Validation loss: 2.559233788521059

Epoch: 6| Step: 7
Training loss: 3.3091282844543457
Validation loss: 2.5628220086456626

Epoch: 6| Step: 8
Training loss: 2.411442279815674
Validation loss: 2.5699547747130036

Epoch: 6| Step: 9
Training loss: 2.983074426651001
Validation loss: 2.574303521904894

Epoch: 6| Step: 10
Training loss: 2.056929111480713
Validation loss: 2.558680042143791

Epoch: 6| Step: 11
Training loss: 2.7510223388671875
Validation loss: 2.5484906140194146

Epoch: 6| Step: 12
Training loss: 3.1908931732177734
Validation loss: 2.551886994351623

Epoch: 6| Step: 13
Training loss: 2.56234073638916
Validation loss: 2.55358132239311

Testing loss: 2.6279690000745983
