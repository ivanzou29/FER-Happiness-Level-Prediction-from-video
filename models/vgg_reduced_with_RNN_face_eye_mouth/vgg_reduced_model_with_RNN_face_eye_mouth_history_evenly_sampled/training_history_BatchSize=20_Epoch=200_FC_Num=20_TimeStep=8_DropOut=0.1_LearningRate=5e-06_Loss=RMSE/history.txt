Epoch: 1| Step: 0
Training loss: 4.803212505429513
Validation loss: 5.7152164022508485

Epoch: 5| Step: 1
Training loss: 5.661121609900293
Validation loss: 5.70983050372722

Epoch: 5| Step: 2
Training loss: 5.799441856626262
Validation loss: 5.704947815959531

Epoch: 5| Step: 3
Training loss: 5.227194526901626
Validation loss: 5.700120117153862

Epoch: 5| Step: 4
Training loss: 6.102863715185114
Validation loss: 5.694949466225035

Epoch: 5| Step: 5
Training loss: 5.363445904587418
Validation loss: 5.6898628545443195

Epoch: 5| Step: 6
Training loss: 5.142059033393654
Validation loss: 5.684671168386544

Epoch: 5| Step: 7
Training loss: 6.808422863424909
Validation loss: 5.679757416785081

Epoch: 5| Step: 8
Training loss: 6.198664293690933
Validation loss: 5.675014461245752

Epoch: 5| Step: 9
Training loss: 5.564722538669206
Validation loss: 5.669925423451964

Epoch: 5| Step: 10
Training loss: 6.106449294962119
Validation loss: 5.664408854077665

Epoch: 2| Step: 0
Training loss: 5.532213547397532
Validation loss: 5.658490833199551

Epoch: 5| Step: 1
Training loss: 6.580180157453215
Validation loss: 5.653089941490836

Epoch: 5| Step: 2
Training loss: 5.037148755419927
Validation loss: 5.646948408634424

Epoch: 5| Step: 3
Training loss: 5.6810994446196945
Validation loss: 5.640896116618819

Epoch: 5| Step: 4
Training loss: 4.534205032202211
Validation loss: 5.634627371128215

Epoch: 5| Step: 5
Training loss: 5.791579797033807
Validation loss: 5.627427494095138

Epoch: 5| Step: 6
Training loss: 6.503028457562911
Validation loss: 5.620926003092158

Epoch: 5| Step: 7
Training loss: 5.350022945176592
Validation loss: 5.613656475722503

Epoch: 5| Step: 8
Training loss: 5.32073892237288
Validation loss: 5.605403414950017

Epoch: 5| Step: 9
Training loss: 5.7995151974866745
Validation loss: 5.597455390816503

Epoch: 5| Step: 10
Training loss: 5.93537945274326
Validation loss: 5.589120037339279

Epoch: 3| Step: 0
Training loss: 6.30268534997977
Validation loss: 5.580364949163787

Epoch: 5| Step: 1
Training loss: 5.940845390297244
Validation loss: 5.571000934462544

Epoch: 5| Step: 2
Training loss: 4.919265879003703
Validation loss: 5.561474036182134

Epoch: 5| Step: 3
Training loss: 5.898744365465529
Validation loss: 5.551450717994217

Epoch: 5| Step: 4
Training loss: 5.447991608298136
Validation loss: 5.541100110905097

Epoch: 5| Step: 5
Training loss: 5.123725546568873
Validation loss: 5.530040473617051

Epoch: 5| Step: 6
Training loss: 5.652269005693176
Validation loss: 5.518793480177287

Epoch: 5| Step: 7
Training loss: 5.788321134842001
Validation loss: 5.50627184338076

Epoch: 5| Step: 8
Training loss: 4.955810973841443
Validation loss: 5.493506154409185

Epoch: 5| Step: 9
Training loss: 5.68035372640043
Validation loss: 5.48053291935842

Epoch: 5| Step: 10
Training loss: 5.373176442798917
Validation loss: 5.465715375126923

Epoch: 4| Step: 0
Training loss: 5.444428337921054
Validation loss: 5.451847597077384

Epoch: 5| Step: 1
Training loss: 4.557167176499075
Validation loss: 5.436905185865807

Epoch: 5| Step: 2
Training loss: 5.903841042092256
Validation loss: 5.421062169655145

Epoch: 5| Step: 3
Training loss: 6.0649629289542935
Validation loss: 5.406127668442169

Epoch: 5| Step: 4
Training loss: 5.3606992814836225
Validation loss: 5.389038870315429

Epoch: 5| Step: 5
Training loss: 5.618647909456895
Validation loss: 5.371578061162159

Epoch: 5| Step: 6
Training loss: 6.226577816206069
Validation loss: 5.3538632296326

Epoch: 5| Step: 7
Training loss: 4.954834267070468
Validation loss: 5.335460768563811

Epoch: 5| Step: 8
Training loss: 5.871618068528962
Validation loss: 5.317092082502374

Epoch: 5| Step: 9
Training loss: 4.086726796224874
Validation loss: 5.296806414137735

Epoch: 5| Step: 10
Training loss: 5.052330823781206
Validation loss: 5.277608403436909

Epoch: 5| Step: 0
Training loss: 4.992703263409998
Validation loss: 5.258774586762544

Epoch: 5| Step: 1
Training loss: 5.731632585142252
Validation loss: 5.238485365071181

Epoch: 5| Step: 2
Training loss: 4.846719139441234
Validation loss: 5.217977811400779

Epoch: 5| Step: 3
Training loss: 5.537380807941441
Validation loss: 5.1980568403310174

Epoch: 5| Step: 4
Training loss: 5.074432626963896
Validation loss: 5.176102693327198

Epoch: 5| Step: 5
Training loss: 5.166231793386081
Validation loss: 5.154932253825599

Epoch: 5| Step: 6
Training loss: 5.79696021827102
Validation loss: 5.13417029544778

Epoch: 5| Step: 7
Training loss: 5.0251913613088846
Validation loss: 5.111326317375395

Epoch: 5| Step: 8
Training loss: 5.225146913060103
Validation loss: 5.0906449071628534

Epoch: 5| Step: 9
Training loss: 4.21183854974478
Validation loss: 5.069081359093578

Epoch: 5| Step: 10
Training loss: 5.5859060860130665
Validation loss: 5.048660176448408

Epoch: 6| Step: 0
Training loss: 5.804298767791939
Validation loss: 5.026859724860803

Epoch: 5| Step: 1
Training loss: 5.066006046862331
Validation loss: 5.005704406772441

Epoch: 5| Step: 2
Training loss: 5.168843190322905
Validation loss: 4.984107353232154

Epoch: 5| Step: 3
Training loss: 5.089465439761273
Validation loss: 4.963914241980391

Epoch: 5| Step: 4
Training loss: 4.487949767458898
Validation loss: 4.9432841126960545

Epoch: 5| Step: 5
Training loss: 4.289334203455771
Validation loss: 4.922615627096837

Epoch: 5| Step: 6
Training loss: 5.187475365270008
Validation loss: 4.902950935722583

Epoch: 5| Step: 7
Training loss: 4.814995453100543
Validation loss: 4.8828879152442175

Epoch: 5| Step: 8
Training loss: 3.57002333924601
Validation loss: 4.863084210807797

Epoch: 5| Step: 9
Training loss: 5.7536791765062905
Validation loss: 4.84499268616194

Epoch: 5| Step: 10
Training loss: 5.369829574239025
Validation loss: 4.825116010628555

Epoch: 7| Step: 0
Training loss: 5.153603169202141
Validation loss: 4.805011917127992

Epoch: 5| Step: 1
Training loss: 4.33438197921268
Validation loss: 4.784671083641165

Epoch: 5| Step: 2
Training loss: 3.803191029736344
Validation loss: 4.765446945729309

Epoch: 5| Step: 3
Training loss: 4.772195457785094
Validation loss: 4.745101077725844

Epoch: 5| Step: 4
Training loss: 4.876977763879491
Validation loss: 4.724075648956298

Epoch: 5| Step: 5
Training loss: 5.2923795365078705
Validation loss: 4.702574654963868

Epoch: 5| Step: 6
Training loss: 5.305519634256153
Validation loss: 4.681420225074758

Epoch: 5| Step: 7
Training loss: 4.747332576875038
Validation loss: 4.664894722737594

Epoch: 5| Step: 8
Training loss: 4.595785714966552
Validation loss: 4.648634482698186

Epoch: 5| Step: 9
Training loss: 5.055002948522415
Validation loss: 4.631608427314243

Epoch: 5| Step: 10
Training loss: 4.521389670646958
Validation loss: 4.616740743418095

Epoch: 8| Step: 0
Training loss: 4.8509405109042545
Validation loss: 4.60126607600231

Epoch: 5| Step: 1
Training loss: 4.533955785615688
Validation loss: 4.585606822004717

Epoch: 5| Step: 2
Training loss: 4.244696955024025
Validation loss: 4.571700483691165

Epoch: 5| Step: 3
Training loss: 3.8154458093705332
Validation loss: 4.55720859584307

Epoch: 5| Step: 4
Training loss: 5.467264376893229
Validation loss: 4.54407628014874

Epoch: 5| Step: 5
Training loss: 4.574074890324264
Validation loss: 4.529848701735508

Epoch: 5| Step: 6
Training loss: 4.582120746541788
Validation loss: 4.516566392490575

Epoch: 5| Step: 7
Training loss: 4.477557273170437
Validation loss: 4.505352931488367

Epoch: 5| Step: 8
Training loss: 4.305148063709757
Validation loss: 4.491884575073693

Epoch: 5| Step: 9
Training loss: 4.868691691097207
Validation loss: 4.47998318204272

Epoch: 5| Step: 10
Training loss: 5.0778087341418585
Validation loss: 4.468486439357338

Epoch: 9| Step: 0
Training loss: 4.637301606821251
Validation loss: 4.456595223006855

Epoch: 5| Step: 1
Training loss: 3.508803195855894
Validation loss: 4.445405570228311

Epoch: 5| Step: 2
Training loss: 4.757209927590543
Validation loss: 4.435492924059209

Epoch: 5| Step: 3
Training loss: 4.518766689665432
Validation loss: 4.422501399103772

Epoch: 5| Step: 4
Training loss: 3.9061171852421106
Validation loss: 4.414084702360692

Epoch: 5| Step: 5
Training loss: 5.389393010543462
Validation loss: 4.404271975996841

Epoch: 5| Step: 6
Training loss: 3.888411784802494
Validation loss: 4.391367117121892

Epoch: 5| Step: 7
Training loss: 4.659138442852186
Validation loss: 4.380980484509973

Epoch: 5| Step: 8
Training loss: 4.703234699782199
Validation loss: 4.369021837173141

Epoch: 5| Step: 9
Training loss: 4.794837543810343
Validation loss: 4.3590300390396335

Epoch: 5| Step: 10
Training loss: 4.592605344408259
Validation loss: 4.347267073241426

Epoch: 10| Step: 0
Training loss: 5.175870613910135
Validation loss: 4.338075056566212

Epoch: 5| Step: 1
Training loss: 3.2725300043069665
Validation loss: 4.325923046953413

Epoch: 5| Step: 2
Training loss: 5.042891970876596
Validation loss: 4.317598930682958

Epoch: 5| Step: 3
Training loss: 4.426625857184249
Validation loss: 4.308966206685793

Epoch: 5| Step: 4
Training loss: 3.3395481982716015
Validation loss: 4.299159756445708

Epoch: 5| Step: 5
Training loss: 4.747898239137922
Validation loss: 4.290482514298147

Epoch: 5| Step: 6
Training loss: 3.2245213885349915
Validation loss: 4.281998308684597

Epoch: 5| Step: 7
Training loss: 4.194989921912362
Validation loss: 4.274564369168653

Epoch: 5| Step: 8
Training loss: 5.120254552593026
Validation loss: 4.267777536993844

Epoch: 5| Step: 9
Training loss: 5.015077555124261
Validation loss: 4.258775370189163

Epoch: 5| Step: 10
Training loss: 4.301319611797295
Validation loss: 4.253350169802704

Epoch: 11| Step: 0
Training loss: 5.153090555181178
Validation loss: 4.243396232169804

Epoch: 5| Step: 1
Training loss: 3.9977899644953494
Validation loss: 4.2365732255743875

Epoch: 5| Step: 2
Training loss: 4.074018844718215
Validation loss: 4.229465402336821

Epoch: 5| Step: 3
Training loss: 4.263335455406045
Validation loss: 4.221913113925292

Epoch: 5| Step: 4
Training loss: 4.384698635345734
Validation loss: 4.21531884213958

Epoch: 5| Step: 5
Training loss: 4.427626680428267
Validation loss: 4.207831372410409

Epoch: 5| Step: 6
Training loss: 4.142823064128352
Validation loss: 4.201482851315678

Epoch: 5| Step: 7
Training loss: 4.517600712965039
Validation loss: 4.194186205512465

Epoch: 5| Step: 8
Training loss: 4.414733727656562
Validation loss: 4.188212670021464

Epoch: 5| Step: 9
Training loss: 3.656701475781609
Validation loss: 4.180582956224677

Epoch: 5| Step: 10
Training loss: 4.584110448442056
Validation loss: 4.173118777985463

Epoch: 12| Step: 0
Training loss: 4.3107583772307665
Validation loss: 4.167339968681517

Epoch: 5| Step: 1
Training loss: 4.912519397648766
Validation loss: 4.161184334722783

Epoch: 5| Step: 2
Training loss: 4.73472407599489
Validation loss: 4.151925564126853

Epoch: 5| Step: 3
Training loss: 4.260833844167996
Validation loss: 4.142774304940272

Epoch: 5| Step: 4
Training loss: 3.853661388921433
Validation loss: 4.1338082318255545

Epoch: 5| Step: 5
Training loss: 3.6228508991387067
Validation loss: 4.124034180596015

Epoch: 5| Step: 6
Training loss: 4.507300283331055
Validation loss: 4.112587920345391

Epoch: 5| Step: 7
Training loss: 4.403346193820867
Validation loss: 4.101644233166613

Epoch: 5| Step: 8
Training loss: 4.104338253455641
Validation loss: 4.090523445298126

Epoch: 5| Step: 9
Training loss: 4.3095215172925885
Validation loss: 4.082907507371798

Epoch: 5| Step: 10
Training loss: 3.5750762077692024
Validation loss: 4.075252289508129

Epoch: 13| Step: 0
Training loss: 3.4715544215269816
Validation loss: 4.067819774558514

Epoch: 5| Step: 1
Training loss: 3.812625695329662
Validation loss: 4.0621156016847255

Epoch: 5| Step: 2
Training loss: 4.029431546540633
Validation loss: 4.056126577708921

Epoch: 5| Step: 3
Training loss: 3.9666098283387337
Validation loss: 4.050170560015596

Epoch: 5| Step: 4
Training loss: 4.47833163735675
Validation loss: 4.044476479507098

Epoch: 5| Step: 5
Training loss: 5.190014333245803
Validation loss: 4.038396368350185

Epoch: 5| Step: 6
Training loss: 4.261615140024328
Validation loss: 4.033372406010507

Epoch: 5| Step: 7
Training loss: 4.348689940921347
Validation loss: 4.026221720129547

Epoch: 5| Step: 8
Training loss: 3.78981523410667
Validation loss: 4.0213669814849835

Epoch: 5| Step: 9
Training loss: 4.732073838380974
Validation loss: 4.013358574838531

Epoch: 5| Step: 10
Training loss: 3.5637234377264164
Validation loss: 4.006051439002055

Epoch: 14| Step: 0
Training loss: 3.5214029938513116
Validation loss: 4.000839140251611

Epoch: 5| Step: 1
Training loss: 4.499141823213149
Validation loss: 3.993731249826986

Epoch: 5| Step: 2
Training loss: 3.7333615256562016
Validation loss: 3.9889550024973275

Epoch: 5| Step: 3
Training loss: 4.433093394811251
Validation loss: 3.982180251789779

Epoch: 5| Step: 4
Training loss: 3.205772236406365
Validation loss: 3.9768355338872636

Epoch: 5| Step: 5
Training loss: 3.6997326470774987
Validation loss: 3.970610252623344

Epoch: 5| Step: 6
Training loss: 4.722176021773779
Validation loss: 3.9656881158598742

Epoch: 5| Step: 7
Training loss: 4.16836457308035
Validation loss: 3.95811668196009

Epoch: 5| Step: 8
Training loss: 4.746750774352742
Validation loss: 3.951940446328948

Epoch: 5| Step: 9
Training loss: 3.766370770695396
Validation loss: 3.943125871159141

Epoch: 5| Step: 10
Training loss: 4.5935050224325735
Validation loss: 3.9371049731333216

Epoch: 15| Step: 0
Training loss: 3.473540426317465
Validation loss: 3.931395220860876

Epoch: 5| Step: 1
Training loss: 4.427806959663655
Validation loss: 3.9235729069867

Epoch: 5| Step: 2
Training loss: 3.9116747000933736
Validation loss: 3.9188393721611363

Epoch: 5| Step: 3
Training loss: 4.613653337555893
Validation loss: 3.9128969195277663

Epoch: 5| Step: 4
Training loss: 4.50182792837035
Validation loss: 3.9062225878994496

Epoch: 5| Step: 5
Training loss: 3.9615362493552997
Validation loss: 3.898521136219146

Epoch: 5| Step: 6
Training loss: 4.801235540636889
Validation loss: 3.8927904219351332

Epoch: 5| Step: 7
Training loss: 3.378781354944271
Validation loss: 3.889285149482179

Epoch: 5| Step: 8
Training loss: 3.7702118728558407
Validation loss: 3.882056027988407

Epoch: 5| Step: 9
Training loss: 3.443552411013583
Validation loss: 3.8774778546240913

Epoch: 5| Step: 10
Training loss: 4.091302270972036
Validation loss: 3.870013260452587

Epoch: 16| Step: 0
Training loss: 4.523212117590527
Validation loss: 3.8637637159328397

Epoch: 5| Step: 1
Training loss: 4.044438987653728
Validation loss: 3.860223265159932

Epoch: 5| Step: 2
Training loss: 3.706038861749807
Validation loss: 3.852277546963606

Epoch: 5| Step: 3
Training loss: 3.56960965840851
Validation loss: 3.843704899669127

Epoch: 5| Step: 4
Training loss: 4.413754396741606
Validation loss: 3.8408365987862085

Epoch: 5| Step: 5
Training loss: 4.0580596131768045
Validation loss: 3.8335163804837857

Epoch: 5| Step: 6
Training loss: 4.198870806805813
Validation loss: 3.830575062100123

Epoch: 5| Step: 7
Training loss: 3.3957932982785906
Validation loss: 3.8254918357498267

Epoch: 5| Step: 8
Training loss: 4.022535026592203
Validation loss: 3.823812580884403

Epoch: 5| Step: 9
Training loss: 4.322426249557224
Validation loss: 3.8183394424702497

Epoch: 5| Step: 10
Training loss: 3.583668109129812
Validation loss: 3.811928281073179

Epoch: 17| Step: 0
Training loss: 3.669328171566541
Validation loss: 3.8062545750745382

Epoch: 5| Step: 1
Training loss: 4.986832063927306
Validation loss: 3.800271358526758

Epoch: 5| Step: 2
Training loss: 3.962139962864405
Validation loss: 3.7958817382339816

Epoch: 5| Step: 3
Training loss: 4.4547938382005
Validation loss: 3.791012073379997

Epoch: 5| Step: 4
Training loss: 3.2354551713809334
Validation loss: 3.7864479143449286

Epoch: 5| Step: 5
Training loss: 3.2097232499655837
Validation loss: 3.7818224927872057

Epoch: 5| Step: 6
Training loss: 4.231286981553446
Validation loss: 3.7770580926857247

Epoch: 5| Step: 7
Training loss: 3.0502147661482635
Validation loss: 3.772232147475906

Epoch: 5| Step: 8
Training loss: 4.269181218854377
Validation loss: 3.767651222087354

Epoch: 5| Step: 9
Training loss: 4.391212722702623
Validation loss: 3.7618969600660157

Epoch: 5| Step: 10
Training loss: 3.5489173420265945
Validation loss: 3.7587791183586057

Epoch: 18| Step: 0
Training loss: 3.54517891952891
Validation loss: 3.752550549823031

Epoch: 5| Step: 1
Training loss: 3.916298842236647
Validation loss: 3.7527792213021236

Epoch: 5| Step: 2
Training loss: 3.971426234190705
Validation loss: 3.7458369893671204

Epoch: 5| Step: 3
Training loss: 3.949421833072755
Validation loss: 3.742173678108664

Epoch: 5| Step: 4
Training loss: 4.089287108803629
Validation loss: 3.7376025605157936

Epoch: 5| Step: 5
Training loss: 4.005188676102133
Validation loss: 3.7330990519677614

Epoch: 5| Step: 6
Training loss: 4.228605161075738
Validation loss: 3.7280212795553878

Epoch: 5| Step: 7
Training loss: 4.217234473516294
Validation loss: 3.724455333508319

Epoch: 5| Step: 8
Training loss: 3.404365648285172
Validation loss: 3.7190949054369997

Epoch: 5| Step: 9
Training loss: 3.813070661016625
Validation loss: 3.718132918502639

Epoch: 5| Step: 10
Training loss: 3.8082292744271586
Validation loss: 3.7114144181681765

Epoch: 19| Step: 0
Training loss: 4.047516407453281
Validation loss: 3.7074040051166035

Epoch: 5| Step: 1
Training loss: 3.350078832353561
Validation loss: 3.704965986974997

Epoch: 5| Step: 2
Training loss: 3.323480795366203
Validation loss: 3.7000079030443356

Epoch: 5| Step: 3
Training loss: 4.334245121226305
Validation loss: 3.69834959946897

Epoch: 5| Step: 4
Training loss: 2.8930965270715756
Validation loss: 3.6900984679912705

Epoch: 5| Step: 5
Training loss: 3.9017411722345017
Validation loss: 3.689072749259886

Epoch: 5| Step: 6
Training loss: 4.094338411165653
Validation loss: 3.6833911582926473

Epoch: 5| Step: 7
Training loss: 3.915888499339302
Validation loss: 3.6841534375634235

Epoch: 5| Step: 8
Training loss: 4.104816649938734
Validation loss: 3.6795878356237717

Epoch: 5| Step: 9
Training loss: 4.503221206643297
Validation loss: 3.674029736837208

Epoch: 5| Step: 10
Training loss: 3.8432970477925332
Validation loss: 3.6706703697299656

Epoch: 20| Step: 0
Training loss: 2.4492729704238116
Validation loss: 3.668037200826851

Epoch: 5| Step: 1
Training loss: 4.039086583432794
Validation loss: 3.66582843749019

Epoch: 5| Step: 2
Training loss: 3.699735611413382
Validation loss: 3.66295443878739

Epoch: 5| Step: 3
Training loss: 3.502299370911043
Validation loss: 3.6599291337014304

Epoch: 5| Step: 4
Training loss: 4.224813441384359
Validation loss: 3.6553416239023124

Epoch: 5| Step: 5
Training loss: 3.9527158261559543
Validation loss: 3.651192828369801

Epoch: 5| Step: 6
Training loss: 3.3905916695780416
Validation loss: 3.64838200987839

Epoch: 5| Step: 7
Training loss: 3.8064695097667838
Validation loss: 3.64371150044693

Epoch: 5| Step: 8
Training loss: 4.41879715307563
Validation loss: 3.640536751598055

Epoch: 5| Step: 9
Training loss: 3.67221028846524
Validation loss: 3.643836971836413

Epoch: 5| Step: 10
Training loss: 4.782456588587974
Validation loss: 3.637289797637231

Epoch: 21| Step: 0
Training loss: 4.099262282829404
Validation loss: 3.632989750971767

Epoch: 5| Step: 1
Training loss: 2.848553635180493
Validation loss: 3.628171447878855

Epoch: 5| Step: 2
Training loss: 3.6543485473698403
Validation loss: 3.6309600845942605

Epoch: 5| Step: 3
Training loss: 3.7904548525067017
Validation loss: 3.6245389368622196

Epoch: 5| Step: 4
Training loss: 3.65758235815204
Validation loss: 3.624183823156862

Epoch: 5| Step: 5
Training loss: 4.300272538175678
Validation loss: 3.6235861292891998

Epoch: 5| Step: 6
Training loss: 3.8972897722609394
Validation loss: 3.621411200172987

Epoch: 5| Step: 7
Training loss: 3.9341693900196617
Validation loss: 3.6188745566377403

Epoch: 5| Step: 8
Training loss: 3.7881535334504544
Validation loss: 3.6166867528132416

Epoch: 5| Step: 9
Training loss: 4.286195891431768
Validation loss: 3.613368244182611

Epoch: 5| Step: 10
Training loss: 3.4763551114406948
Validation loss: 3.615445030440643

Epoch: 22| Step: 0
Training loss: 4.073522550326385
Validation loss: 3.6082295659750176

Epoch: 5| Step: 1
Training loss: 3.665107366594735
Validation loss: 3.6049290157298257

Epoch: 5| Step: 2
Training loss: 4.129090102044369
Validation loss: 3.600843466029792

Epoch: 5| Step: 3
Training loss: 3.6792829092692
Validation loss: 3.5998598668524275

Epoch: 5| Step: 4
Training loss: 3.018572379942489
Validation loss: 3.599136216837104

Epoch: 5| Step: 5
Training loss: 3.502583231621141
Validation loss: 3.594889567403035

Epoch: 5| Step: 6
Training loss: 4.3619858228338515
Validation loss: 3.5916602480375888

Epoch: 5| Step: 7
Training loss: 3.5259881440481013
Validation loss: 3.5921466048679713

Epoch: 5| Step: 8
Training loss: 4.213972310935265
Validation loss: 3.589940957027103

Epoch: 5| Step: 9
Training loss: 3.495572559571046
Validation loss: 3.5882280511160287

Epoch: 5| Step: 10
Training loss: 3.8685577739233916
Validation loss: 3.585628816428054

Epoch: 23| Step: 0
Training loss: 3.9838372559532833
Validation loss: 3.5856456097586857

Epoch: 5| Step: 1
Training loss: 4.035599365720114
Validation loss: 3.5835129618187453

Epoch: 5| Step: 2
Training loss: 3.2966007642905586
Validation loss: 3.5782983271053075

Epoch: 5| Step: 3
Training loss: 2.656103332060614
Validation loss: 3.5762318447470687

Epoch: 5| Step: 4
Training loss: 3.972297344668197
Validation loss: 3.574182972941056

Epoch: 5| Step: 5
Training loss: 3.8825413323319076
Validation loss: 3.57475049345527

Epoch: 5| Step: 6
Training loss: 3.9318921557797863
Validation loss: 3.5748462234033225

Epoch: 5| Step: 7
Training loss: 4.039100750090887
Validation loss: 3.5674241150000907

Epoch: 5| Step: 8
Training loss: 3.356014682469401
Validation loss: 3.5673114090839624

Epoch: 5| Step: 9
Training loss: 3.8574730514801407
Validation loss: 3.568205923661475

Epoch: 5| Step: 10
Training loss: 4.310116758955617
Validation loss: 3.5666713763637077

Epoch: 24| Step: 0
Training loss: 4.117733653143731
Validation loss: 3.5620683985372747

Epoch: 5| Step: 1
Training loss: 3.594765295821614
Validation loss: 3.561745037399167

Epoch: 5| Step: 2
Training loss: 3.944889340510645
Validation loss: 3.5603979990848704

Epoch: 5| Step: 3
Training loss: 4.211670763934343
Validation loss: 3.562303384746283

Epoch: 5| Step: 4
Training loss: 3.4845778059848103
Validation loss: 3.557472759253191

Epoch: 5| Step: 5
Training loss: 3.730994701756969
Validation loss: 3.5608531093515987

Epoch: 5| Step: 6
Training loss: 3.3564227239111157
Validation loss: 3.55993792363035

Epoch: 5| Step: 7
Training loss: 3.979990143308463
Validation loss: 3.5550244834796056

Epoch: 5| Step: 8
Training loss: 3.613081445066873
Validation loss: 3.5487081974392676

Epoch: 5| Step: 9
Training loss: 2.597401725518093
Validation loss: 3.5532552832914077

Epoch: 5| Step: 10
Training loss: 4.50351704804167
Validation loss: 3.552458076507656

Epoch: 25| Step: 0
Training loss: 3.817839588582201
Validation loss: 3.5474026354258155

Epoch: 5| Step: 1
Training loss: 2.925873330962968
Validation loss: 3.5462481741845373

Epoch: 5| Step: 2
Training loss: 3.9442915700262176
Validation loss: 3.5462380952710553

Epoch: 5| Step: 3
Training loss: 4.097128835070007
Validation loss: 3.548177000483993

Epoch: 5| Step: 4
Training loss: 3.9872847161130385
Validation loss: 3.545106653084732

Epoch: 5| Step: 5
Training loss: 3.3118040685334167
Validation loss: 3.5396324661637046

Epoch: 5| Step: 6
Training loss: 3.0545434161691345
Validation loss: 3.5393730254980813

Epoch: 5| Step: 7
Training loss: 3.923949768094864
Validation loss: 3.541988703197541

Epoch: 5| Step: 8
Training loss: 3.8588627154783803
Validation loss: 3.541909798101013

Epoch: 5| Step: 9
Training loss: 4.201861450409509
Validation loss: 3.5369793130011282

Epoch: 5| Step: 10
Training loss: 3.887912402096337
Validation loss: 3.5382757531408404

Epoch: 26| Step: 0
Training loss: 3.3226201195168494
Validation loss: 3.5346956132312917

Epoch: 5| Step: 1
Training loss: 2.5822419558150593
Validation loss: 3.5360618749784227

Epoch: 5| Step: 2
Training loss: 3.601591362496199
Validation loss: 3.5351792194202885

Epoch: 5| Step: 3
Training loss: 3.640192882122481
Validation loss: 3.5328432903232545

Epoch: 5| Step: 4
Training loss: 3.3192731599407024
Validation loss: 3.5313550037072843

Epoch: 5| Step: 5
Training loss: 3.8294887060010567
Validation loss: 3.532095282789437

Epoch: 5| Step: 6
Training loss: 4.173055988842079
Validation loss: 3.536590208837882

Epoch: 5| Step: 7
Training loss: 4.566876963950028
Validation loss: 3.5267427882550773

Epoch: 5| Step: 8
Training loss: 3.73147278700465
Validation loss: 3.526443781088366

Epoch: 5| Step: 9
Training loss: 4.019628762711135
Validation loss: 3.528626402677421

Epoch: 5| Step: 10
Training loss: 4.012405945813438
Validation loss: 3.528025256854535

Epoch: 27| Step: 0
Training loss: 3.942425024351362
Validation loss: 3.523075816521614

Epoch: 5| Step: 1
Training loss: 3.2371494353798345
Validation loss: 3.5223655335122803

Epoch: 5| Step: 2
Training loss: 3.983035112866462
Validation loss: 3.5214659128715287

Epoch: 5| Step: 3
Training loss: 4.19030371791987
Validation loss: 3.522071752127693

Epoch: 5| Step: 4
Training loss: 3.6613746658829833
Validation loss: 3.5202239523072656

Epoch: 5| Step: 5
Training loss: 3.2853147488889975
Validation loss: 3.52112763256072

Epoch: 5| Step: 6
Training loss: 3.668608035926521
Validation loss: 3.5201919509316784

Epoch: 5| Step: 7
Training loss: 3.7260857043153637
Validation loss: 3.5200579224385993

Epoch: 5| Step: 8
Training loss: 3.5257766300968236
Validation loss: 3.516237916010319

Epoch: 5| Step: 9
Training loss: 3.9141226819069628
Validation loss: 3.51801153817112

Epoch: 5| Step: 10
Training loss: 3.814389245376851
Validation loss: 3.5156578115301653

Epoch: 28| Step: 0
Training loss: 4.1146280922044705
Validation loss: 3.5151765766625296

Epoch: 5| Step: 1
Training loss: 3.5503048886752344
Validation loss: 3.5120945391926823

Epoch: 5| Step: 2
Training loss: 3.7611339585928047
Validation loss: 3.5101952585061587

Epoch: 5| Step: 3
Training loss: 3.683931984446487
Validation loss: 3.5100125617920948

Epoch: 5| Step: 4
Training loss: 5.210304050176735
Validation loss: 3.507041542585035

Epoch: 5| Step: 5
Training loss: 3.3721468132702976
Validation loss: 3.50728273734162

Epoch: 5| Step: 6
Training loss: 3.436774437364954
Validation loss: 3.5070085100882133

Epoch: 5| Step: 7
Training loss: 3.273733485275976
Validation loss: 3.509406506433095

Epoch: 5| Step: 8
Training loss: 3.5737878091472597
Validation loss: 3.5076614735811216

Epoch: 5| Step: 9
Training loss: 3.405373556789225
Validation loss: 3.5041929610514697

Epoch: 5| Step: 10
Training loss: 2.9929630081332776
Validation loss: 3.502636924023538

Epoch: 29| Step: 0
Training loss: 3.644846551959232
Validation loss: 3.50126679080285

Epoch: 5| Step: 1
Training loss: 3.6811289950367927
Validation loss: 3.5015830841384123

Epoch: 5| Step: 2
Training loss: 3.818581280516449
Validation loss: 3.5009284992614194

Epoch: 5| Step: 3
Training loss: 4.000546656447721
Validation loss: 3.5019635319528692

Epoch: 5| Step: 4
Training loss: 3.402610584398764
Validation loss: 3.500293148087283

Epoch: 5| Step: 5
Training loss: 3.7362908592299964
Validation loss: 3.4947782449314944

Epoch: 5| Step: 6
Training loss: 4.385307594567867
Validation loss: 3.498249376445811

Epoch: 5| Step: 7
Training loss: 3.7432509406497574
Validation loss: 3.495594614200631

Epoch: 5| Step: 8
Training loss: 3.5240565938139827
Validation loss: 3.4930247885792722

Epoch: 5| Step: 9
Training loss: 2.711082168808517
Validation loss: 3.4958726921321603

Epoch: 5| Step: 10
Training loss: 3.984841113782004
Validation loss: 3.5045972551473317

Epoch: 30| Step: 0
Training loss: 3.93925243314714
Validation loss: 3.4915043036707356

Epoch: 5| Step: 1
Training loss: 3.1244753587922878
Validation loss: 3.491232489512111

Epoch: 5| Step: 2
Training loss: 3.8064517213582585
Validation loss: 3.4925856850411456

Epoch: 5| Step: 3
Training loss: 3.4037189003948716
Validation loss: 3.494273923470487

Epoch: 5| Step: 4
Training loss: 4.085369588505135
Validation loss: 3.4902832524361886

Epoch: 5| Step: 5
Training loss: 4.150029396044937
Validation loss: 3.489192890234734

Epoch: 5| Step: 6
Training loss: 3.60450449042028
Validation loss: 3.486063801004916

Epoch: 5| Step: 7
Training loss: 4.359199547740558
Validation loss: 3.4885359260959805

Epoch: 5| Step: 8
Training loss: 3.180615788703364
Validation loss: 3.4856845126391436

Epoch: 5| Step: 9
Training loss: 3.542668339317462
Validation loss: 3.4856927440875176

Epoch: 5| Step: 10
Training loss: 3.2609312648741002
Validation loss: 3.4847806899182543

Epoch: 31| Step: 0
Training loss: 2.9991347336683294
Validation loss: 3.48440969207002

Epoch: 5| Step: 1
Training loss: 4.425414054162757
Validation loss: 3.4839860840813808

Epoch: 5| Step: 2
Training loss: 2.904794964538933
Validation loss: 3.4818566214711537

Epoch: 5| Step: 3
Training loss: 3.1362731541082605
Validation loss: 3.4811568001036926

Epoch: 5| Step: 4
Training loss: 2.7905597674871556
Validation loss: 3.481961160665997

Epoch: 5| Step: 5
Training loss: 4.2984895759181905
Validation loss: 3.4791709797207178

Epoch: 5| Step: 6
Training loss: 4.125202520774264
Validation loss: 3.4788107662650574

Epoch: 5| Step: 7
Training loss: 3.2582460110435867
Validation loss: 3.4773613456586685

Epoch: 5| Step: 8
Training loss: 3.992448354063366
Validation loss: 3.4772976286003963

Epoch: 5| Step: 9
Training loss: 4.212821807794452
Validation loss: 3.478183568880313

Epoch: 5| Step: 10
Training loss: 4.025314574654602
Validation loss: 3.4769360324923135

Epoch: 32| Step: 0
Training loss: 3.6657328427996867
Validation loss: 3.4743022861275543

Epoch: 5| Step: 1
Training loss: 3.6436076900376317
Validation loss: 3.4739558296817554

Epoch: 5| Step: 2
Training loss: 3.470851227407745
Validation loss: 3.4776462157694024

Epoch: 5| Step: 3
Training loss: 2.981496491228771
Validation loss: 3.477535950041617

Epoch: 5| Step: 4
Training loss: 3.6723879192120763
Validation loss: 3.4782385282904684

Epoch: 5| Step: 5
Training loss: 4.664620677576456
Validation loss: 3.4754146283416048

Epoch: 5| Step: 6
Training loss: 2.8386375667692474
Validation loss: 3.474378442555032

Epoch: 5| Step: 7
Training loss: 3.19410619373105
Validation loss: 3.472897575465657

Epoch: 5| Step: 8
Training loss: 3.260513466727507
Validation loss: 3.472819089281206

Epoch: 5| Step: 9
Training loss: 4.439716269216701
Validation loss: 3.473663182247375

Epoch: 5| Step: 10
Training loss: 4.411261988402215
Validation loss: 3.4732704864685315

Epoch: 33| Step: 0
Training loss: 3.376580609966329
Validation loss: 3.471242558798737

Epoch: 5| Step: 1
Training loss: 3.9255587234817804
Validation loss: 3.4694551377358107

Epoch: 5| Step: 2
Training loss: 3.1741536792166616
Validation loss: 3.4677053983327464

Epoch: 5| Step: 3
Training loss: 4.268521956556334
Validation loss: 3.467859449682453

Epoch: 5| Step: 4
Training loss: 2.233398651002941
Validation loss: 3.4698401167062274

Epoch: 5| Step: 5
Training loss: 4.186542914033597
Validation loss: 3.4683306691021527

Epoch: 5| Step: 6
Training loss: 4.096875577296632
Validation loss: 3.465536000098843

Epoch: 5| Step: 7
Training loss: 3.6354805285829896
Validation loss: 3.4643786874414917

Epoch: 5| Step: 8
Training loss: 4.271025540128355
Validation loss: 3.464121604081925

Epoch: 5| Step: 9
Training loss: 3.7372262197390302
Validation loss: 3.4651938296924314

Epoch: 5| Step: 10
Training loss: 2.9768662185106933
Validation loss: 3.4667735796984447

Epoch: 34| Step: 0
Training loss: 3.470932145255827
Validation loss: 3.4649210850475467

Epoch: 5| Step: 1
Training loss: 3.4027641728620104
Validation loss: 3.4674274436474404

Epoch: 5| Step: 2
Training loss: 3.2256180163690202
Validation loss: 3.466238985606353

Epoch: 5| Step: 3
Training loss: 3.7858704640132745
Validation loss: 3.4602934546583155

Epoch: 5| Step: 4
Training loss: 3.63014474354258
Validation loss: 3.4591290689812717

Epoch: 5| Step: 5
Training loss: 3.501792721071957
Validation loss: 3.4586458184842894

Epoch: 5| Step: 6
Training loss: 2.9394307385983094
Validation loss: 3.4589917094537244

Epoch: 5| Step: 7
Training loss: 3.9556560630983033
Validation loss: 3.4589578504734653

Epoch: 5| Step: 8
Training loss: 4.122679549009159
Validation loss: 3.4599945036259836

Epoch: 5| Step: 9
Training loss: 4.1756149844121015
Validation loss: 3.457738206650613

Epoch: 5| Step: 10
Training loss: 4.126485383751462
Validation loss: 3.455361434159887

Epoch: 35| Step: 0
Training loss: 4.2521110228490935
Validation loss: 3.4551784230668328

Epoch: 5| Step: 1
Training loss: 3.130926996501495
Validation loss: 3.454198470438619

Epoch: 5| Step: 2
Training loss: 3.5195933007328386
Validation loss: 3.4557075144029956

Epoch: 5| Step: 3
Training loss: 3.6864916182401637
Validation loss: 3.4530830505106684

Epoch: 5| Step: 4
Training loss: 3.6798571245819347
Validation loss: 3.4542206779085043

Epoch: 5| Step: 5
Training loss: 2.5731938221854187
Validation loss: 3.453455630615529

Epoch: 5| Step: 6
Training loss: 2.930002587222887
Validation loss: 3.454698272433157

Epoch: 5| Step: 7
Training loss: 4.91401902802711
Validation loss: 3.4529011511420515

Epoch: 5| Step: 8
Training loss: 3.6069570922499246
Validation loss: 3.4529214543907223

Epoch: 5| Step: 9
Training loss: 4.327299955208068
Validation loss: 3.4502748007503374

Epoch: 5| Step: 10
Training loss: 3.0570791106714608
Validation loss: 3.4490860768679994

Epoch: 36| Step: 0
Training loss: 3.53153004843966
Validation loss: 3.4485251513070905

Epoch: 5| Step: 1
Training loss: 3.7859767658308647
Validation loss: 3.4478685161094877

Epoch: 5| Step: 2
Training loss: 3.489074138480155
Validation loss: 3.4479397602359394

Epoch: 5| Step: 3
Training loss: 3.33325072821942
Validation loss: 3.4483108738796813

Epoch: 5| Step: 4
Training loss: 4.087353317008639
Validation loss: 3.4471083612065274

Epoch: 5| Step: 5
Training loss: 4.3163085926452665
Validation loss: 3.4487443944149128

Epoch: 5| Step: 6
Training loss: 3.747013937670459
Validation loss: 3.4476459157575197

Epoch: 5| Step: 7
Training loss: 3.4685754130648743
Validation loss: 3.4464433957141307

Epoch: 5| Step: 8
Training loss: 2.937237829318389
Validation loss: 3.4482974977330803

Epoch: 5| Step: 9
Training loss: 3.874137905575068
Validation loss: 3.447088022231482

Epoch: 5| Step: 10
Training loss: 3.5901072740599007
Validation loss: 3.4464627595909976

Epoch: 37| Step: 0
Training loss: 4.020190304479194
Validation loss: 3.4447009929084724

Epoch: 5| Step: 1
Training loss: 3.737425767040162
Validation loss: 3.4445981838103905

Epoch: 5| Step: 2
Training loss: 3.2996123461903575
Validation loss: 3.4437099845959507

Epoch: 5| Step: 3
Training loss: 3.5785273030097495
Validation loss: 3.444597577991207

Epoch: 5| Step: 4
Training loss: 4.0875455707961175
Validation loss: 3.445850331730425

Epoch: 5| Step: 5
Training loss: 3.190466155190265
Validation loss: 3.445600510859619

Epoch: 5| Step: 6
Training loss: 3.2335503305458753
Validation loss: 3.4415303606995917

Epoch: 5| Step: 7
Training loss: 3.4200555850414114
Validation loss: 3.4419536344507073

Epoch: 5| Step: 8
Training loss: 3.353370019043401
Validation loss: 3.4411537791359685

Epoch: 5| Step: 9
Training loss: 4.544220559207338
Validation loss: 3.4419544999330354

Epoch: 5| Step: 10
Training loss: 3.585045531128735
Validation loss: 3.4386279272058524

Epoch: 38| Step: 0
Training loss: 3.6065401115942253
Validation loss: 3.4405736223841137

Epoch: 5| Step: 1
Training loss: 3.785845903334734
Validation loss: 3.4419711287706827

Epoch: 5| Step: 2
Training loss: 3.8606567725365113
Validation loss: 3.438985130502505

Epoch: 5| Step: 3
Training loss: 3.853602985024083
Validation loss: 3.438884709777162

Epoch: 5| Step: 4
Training loss: 3.667625273038757
Validation loss: 3.44075275950024

Epoch: 5| Step: 5
Training loss: 3.999079359918819
Validation loss: 3.4357758584314637

Epoch: 5| Step: 6
Training loss: 3.042584337430668
Validation loss: 3.4400389318154283

Epoch: 5| Step: 7
Training loss: 3.6816193840567633
Validation loss: 3.4378710116788045

Epoch: 5| Step: 8
Training loss: 3.065215794494947
Validation loss: 3.4392704182924727

Epoch: 5| Step: 9
Training loss: 3.686597163997874
Validation loss: 3.4374024139603225

Epoch: 5| Step: 10
Training loss: 3.897038088202485
Validation loss: 3.434623987324165

Epoch: 39| Step: 0
Training loss: 3.679838076221821
Validation loss: 3.4338691396877024

Epoch: 5| Step: 1
Training loss: 3.4806554810581045
Validation loss: 3.4359349108241086

Epoch: 5| Step: 2
Training loss: 3.856602093467308
Validation loss: 3.4345914212640625

Epoch: 5| Step: 3
Training loss: 4.429219216112461
Validation loss: 3.436771014973026

Epoch: 5| Step: 4
Training loss: 4.036942122805436
Validation loss: 3.433126752669581

Epoch: 5| Step: 5
Training loss: 4.141939235342844
Validation loss: 3.4330727983021143

Epoch: 5| Step: 6
Training loss: 3.723680833556404
Validation loss: 3.4323050359759706

Epoch: 5| Step: 7
Training loss: 2.5935670719214445
Validation loss: 3.4325110962116154

Epoch: 5| Step: 8
Training loss: 2.9540928460615206
Validation loss: 3.4329229816799036

Epoch: 5| Step: 9
Training loss: 3.406686177456022
Validation loss: 3.4333965550961727

Epoch: 5| Step: 10
Training loss: 3.5128964835013834
Validation loss: 3.4334110435996514

Epoch: 40| Step: 0
Training loss: 3.8214274458635247
Validation loss: 3.4351625715921927

Epoch: 5| Step: 1
Training loss: 3.537127169854465
Validation loss: 3.4339976108858603

Epoch: 5| Step: 2
Training loss: 3.5647706943293582
Validation loss: 3.4326134204005085

Epoch: 5| Step: 3
Training loss: 4.563823142300142
Validation loss: 3.4315359424009495

Epoch: 5| Step: 4
Training loss: 4.244276568591901
Validation loss: 3.433126175442313

Epoch: 5| Step: 5
Training loss: 3.582651797989814
Validation loss: 3.4306568976445573

Epoch: 5| Step: 6
Training loss: 3.7325133467663667
Validation loss: 3.4299623647071056

Epoch: 5| Step: 7
Training loss: 3.3887347740470113
Validation loss: 3.4304085052430175

Epoch: 5| Step: 8
Training loss: 3.4491722993757863
Validation loss: 3.429186575083239

Epoch: 5| Step: 9
Training loss: 2.6782733533402454
Validation loss: 3.43006717455501

Epoch: 5| Step: 10
Training loss: 3.2470219979958173
Validation loss: 3.4286772266179772

Epoch: 41| Step: 0
Training loss: 4.063907320843125
Validation loss: 3.4289435175534257

Epoch: 5| Step: 1
Training loss: 3.278715771733867
Validation loss: 3.427474688928393

Epoch: 5| Step: 2
Training loss: 3.927483913454248
Validation loss: 3.4259906897988284

Epoch: 5| Step: 3
Training loss: 3.3796383103288696
Validation loss: 3.4248995485448743

Epoch: 5| Step: 4
Training loss: 4.411226532966368
Validation loss: 3.425861364581158

Epoch: 5| Step: 5
Training loss: 3.795454348178416
Validation loss: 3.4238901161415805

Epoch: 5| Step: 6
Training loss: 2.6974709534163934
Validation loss: 3.425512439610772

Epoch: 5| Step: 7
Training loss: 3.4285469678732836
Validation loss: 3.424796176465677

Epoch: 5| Step: 8
Training loss: 4.073175108271983
Validation loss: 3.4256382816240865

Epoch: 5| Step: 9
Training loss: 3.514034335242776
Validation loss: 3.427684904062357

Epoch: 5| Step: 10
Training loss: 3.1862998647817355
Validation loss: 3.424232609098157

Epoch: 42| Step: 0
Training loss: 3.560892645974774
Validation loss: 3.4246395277380692

Epoch: 5| Step: 1
Training loss: 3.1557718046919323
Validation loss: 3.4223103516257227

Epoch: 5| Step: 2
Training loss: 3.3831984231544223
Validation loss: 3.4219993605795516

Epoch: 5| Step: 3
Training loss: 3.397653353319931
Validation loss: 3.424610530349212

Epoch: 5| Step: 4
Training loss: 4.178690055122805
Validation loss: 3.424831362756033

Epoch: 5| Step: 5
Training loss: 4.519230337189749
Validation loss: 3.4220374628768027

Epoch: 5| Step: 6
Training loss: 3.9920568276834563
Validation loss: 3.423333859889403

Epoch: 5| Step: 7
Training loss: 3.2243984992185277
Validation loss: 3.420806371776368

Epoch: 5| Step: 8
Training loss: 3.0672469426291507
Validation loss: 3.420034144441654

Epoch: 5| Step: 9
Training loss: 4.4584449445117285
Validation loss: 3.420030502157409

Epoch: 5| Step: 10
Training loss: 2.4446720344866653
Validation loss: 3.420134394562766

Epoch: 43| Step: 0
Training loss: 4.087095486751229
Validation loss: 3.419929725007955

Epoch: 5| Step: 1
Training loss: 4.614820257552994
Validation loss: 3.419661879781576

Epoch: 5| Step: 2
Training loss: 3.2009885036043975
Validation loss: 3.419834756093242

Epoch: 5| Step: 3
Training loss: 3.3254911361160953
Validation loss: 3.4196612388079872

Epoch: 5| Step: 4
Training loss: 4.346160439420702
Validation loss: 3.41881821181468

Epoch: 5| Step: 5
Training loss: 2.8971006698524935
Validation loss: 3.4167809836178864

Epoch: 5| Step: 6
Training loss: 3.267360098542829
Validation loss: 3.416180994574271

Epoch: 5| Step: 7
Training loss: 3.678147044152227
Validation loss: 3.414345660985688

Epoch: 5| Step: 8
Training loss: 2.7925576074134364
Validation loss: 3.4155474612220216

Epoch: 5| Step: 9
Training loss: 3.7348236708274265
Validation loss: 3.4172271450885328

Epoch: 5| Step: 10
Training loss: 3.676335259583507
Validation loss: 3.415481234680087

Epoch: 44| Step: 0
Training loss: 4.15049609240996
Validation loss: 3.4157702372745518

Epoch: 5| Step: 1
Training loss: 3.1088400529151343
Validation loss: 3.4142625107681104

Epoch: 5| Step: 2
Training loss: 4.274417297627003
Validation loss: 3.4107992021910754

Epoch: 5| Step: 3
Training loss: 3.863464165996428
Validation loss: 3.4092263905056956

Epoch: 5| Step: 4
Training loss: 3.358063481724257
Validation loss: 3.407655591323387

Epoch: 5| Step: 5
Training loss: 3.369937915173516
Validation loss: 3.4068599236522803

Epoch: 5| Step: 6
Training loss: 3.4481372282507308
Validation loss: 3.407317657396153

Epoch: 5| Step: 7
Training loss: 4.624454363005173
Validation loss: 3.4047837192403323

Epoch: 5| Step: 8
Training loss: 3.386239164158356
Validation loss: 3.4031867102942552

Epoch: 5| Step: 9
Training loss: 2.7027547946626647
Validation loss: 3.4015745536238713

Epoch: 5| Step: 10
Training loss: 3.1788454932638586
Validation loss: 3.4019229918322793

Epoch: 45| Step: 0
Training loss: 3.389237783708396
Validation loss: 3.401892846762179

Epoch: 5| Step: 1
Training loss: 3.6288723487214907
Validation loss: 3.403488334170606

Epoch: 5| Step: 2
Training loss: 3.487227978232563
Validation loss: 3.399012704086238

Epoch: 5| Step: 3
Training loss: 3.47373151062516
Validation loss: 3.3994448057103455

Epoch: 5| Step: 4
Training loss: 3.8829229020631737
Validation loss: 3.3961413769895494

Epoch: 5| Step: 5
Training loss: 2.8390930946729673
Validation loss: 3.398097007704205

Epoch: 5| Step: 6
Training loss: 3.803793674886423
Validation loss: 3.3993451226718134

Epoch: 5| Step: 7
Training loss: 4.349617268178738
Validation loss: 3.398955077335005

Epoch: 5| Step: 8
Training loss: 3.806591019911529
Validation loss: 3.399547924579391

Epoch: 5| Step: 9
Training loss: 3.636407595065318
Validation loss: 3.3966476734320334

Epoch: 5| Step: 10
Training loss: 3.3791056491471445
Validation loss: 3.3988772143520047

Epoch: 46| Step: 0
Training loss: 3.642752488286566
Validation loss: 3.401859204723379

Epoch: 5| Step: 1
Training loss: 4.179096501003209
Validation loss: 3.402976653500343

Epoch: 5| Step: 2
Training loss: 3.5708165053004848
Validation loss: 3.398637329759265

Epoch: 5| Step: 3
Training loss: 4.054452760696652
Validation loss: 3.396983500663258

Epoch: 5| Step: 4
Training loss: 3.3753386433566077
Validation loss: 3.396507148520322

Epoch: 5| Step: 5
Training loss: 3.7864024469937934
Validation loss: 3.3936323991377693

Epoch: 5| Step: 6
Training loss: 3.1513407079283398
Validation loss: 3.391836650884366

Epoch: 5| Step: 7
Training loss: 3.9490364251464927
Validation loss: 3.392552060623818

Epoch: 5| Step: 8
Training loss: 3.397551743405992
Validation loss: 3.393116619536075

Epoch: 5| Step: 9
Training loss: 3.2639532601431984
Validation loss: 3.390999598040769

Epoch: 5| Step: 10
Training loss: 3.2663776315248785
Validation loss: 3.39122212777613

Epoch: 47| Step: 0
Training loss: 3.3435340882941453
Validation loss: 3.3905251710728814

Epoch: 5| Step: 1
Training loss: 3.1963584325939194
Validation loss: 3.3901316094424874

Epoch: 5| Step: 2
Training loss: 4.271712099553832
Validation loss: 3.3883624693157355

Epoch: 5| Step: 3
Training loss: 3.879356273656936
Validation loss: 3.3921443052516516

Epoch: 5| Step: 4
Training loss: 3.673276982599264
Validation loss: 3.389748615940242

Epoch: 5| Step: 5
Training loss: 3.337221135408352
Validation loss: 3.3885276783376472

Epoch: 5| Step: 6
Training loss: 4.119063758765977
Validation loss: 3.388183086421773

Epoch: 5| Step: 7
Training loss: 3.6661267027491498
Validation loss: 3.3879016433628037

Epoch: 5| Step: 8
Training loss: 3.218507627972685
Validation loss: 3.387061563846928

Epoch: 5| Step: 9
Training loss: 3.67040609643957
Validation loss: 3.3854196876278912

Epoch: 5| Step: 10
Training loss: 3.1570164722379017
Validation loss: 3.387191468285828

Epoch: 48| Step: 0
Training loss: 4.236220967409136
Validation loss: 3.385154330530891

Epoch: 5| Step: 1
Training loss: 3.5467951425309376
Validation loss: 3.3854720653358643

Epoch: 5| Step: 2
Training loss: 3.4834860450330414
Validation loss: 3.384259790189622

Epoch: 5| Step: 3
Training loss: 3.569720797266163
Validation loss: 3.3862182203412114

Epoch: 5| Step: 4
Training loss: 3.268744771745341
Validation loss: 3.383090971574714

Epoch: 5| Step: 5
Training loss: 3.5522137093132926
Validation loss: 3.3842324360728546

Epoch: 5| Step: 6
Training loss: 3.3850773724456946
Validation loss: 3.3849462932387255

Epoch: 5| Step: 7
Training loss: 4.01441931528893
Validation loss: 3.3835829021167934

Epoch: 5| Step: 8
Training loss: 4.1310823853809415
Validation loss: 3.381819672486922

Epoch: 5| Step: 9
Training loss: 2.5841044126325396
Validation loss: 3.3825582583841522

Epoch: 5| Step: 10
Training loss: 3.705632773043927
Validation loss: 3.3819406075373117

Epoch: 49| Step: 0
Training loss: 3.2963279523373203
Validation loss: 3.382078960348629

Epoch: 5| Step: 1
Training loss: 4.600251456312329
Validation loss: 3.381479194510841

Epoch: 5| Step: 2
Training loss: 2.5897897107684624
Validation loss: 3.3816097963140215

Epoch: 5| Step: 3
Training loss: 3.287606032369491
Validation loss: 3.3828609879607128

Epoch: 5| Step: 4
Training loss: 3.7031548736268656
Validation loss: 3.3811226474139464

Epoch: 5| Step: 5
Training loss: 4.143244076967134
Validation loss: 3.3822286361956313

Epoch: 5| Step: 6
Training loss: 3.101108931039484
Validation loss: 3.380503502689758

Epoch: 5| Step: 7
Training loss: 3.777426938676455
Validation loss: 3.378788216287546

Epoch: 5| Step: 8
Training loss: 3.616562461816769
Validation loss: 3.3799765375110233

Epoch: 5| Step: 9
Training loss: 3.3981554637818254
Validation loss: 3.379607694921184

Epoch: 5| Step: 10
Training loss: 3.850074588994389
Validation loss: 3.377431961780246

Epoch: 50| Step: 0
Training loss: 4.1159256045455095
Validation loss: 3.377009536033908

Epoch: 5| Step: 1
Training loss: 3.1729865170206484
Validation loss: 3.376926870181199

Epoch: 5| Step: 2
Training loss: 3.6157962109014843
Validation loss: 3.376638159993002

Epoch: 5| Step: 3
Training loss: 3.0163135434289567
Validation loss: 3.37628714727883

Epoch: 5| Step: 4
Training loss: 3.1271437349189393
Validation loss: 3.376202228281356

Epoch: 5| Step: 5
Training loss: 3.750210311078478
Validation loss: 3.3774636519802588

Epoch: 5| Step: 6
Training loss: 3.8170216746465666
Validation loss: 3.3797952683465513

Epoch: 5| Step: 7
Training loss: 3.5674763773488247
Validation loss: 3.3812519611721967

Epoch: 5| Step: 8
Training loss: 3.3533512490655335
Validation loss: 3.3915658863320073

Epoch: 5| Step: 9
Training loss: 4.12322636244802
Validation loss: 3.3765436726579967

Epoch: 5| Step: 10
Training loss: 3.8342354721885514
Validation loss: 3.3714695493835296

Epoch: 51| Step: 0
Training loss: 3.4637307634098238
Validation loss: 3.3713853850339

Epoch: 5| Step: 1
Training loss: 3.266392229839784
Validation loss: 3.3720784936174906

Epoch: 5| Step: 2
Training loss: 4.084241000650133
Validation loss: 3.3723300512013377

Epoch: 5| Step: 3
Training loss: 3.464367271440871
Validation loss: 3.3727367884267423

Epoch: 5| Step: 4
Training loss: 4.384475909137001
Validation loss: 3.3713376217206408

Epoch: 5| Step: 5
Training loss: 4.038692022041464
Validation loss: 3.3714498049703923

Epoch: 5| Step: 6
Training loss: 3.8465361383154453
Validation loss: 3.3685042820096656

Epoch: 5| Step: 7
Training loss: 2.495039691953338
Validation loss: 3.3665864115441106

Epoch: 5| Step: 8
Training loss: 3.649408705383076
Validation loss: 3.3633772700186095

Epoch: 5| Step: 9
Training loss: 3.0940012203675265
Validation loss: 3.3623673142911543

Epoch: 5| Step: 10
Training loss: 3.4137299329851634
Validation loss: 3.362166437500312

Epoch: 52| Step: 0
Training loss: 3.348891966040039
Validation loss: 3.3613031156436723

Epoch: 5| Step: 1
Training loss: 4.519792897028718
Validation loss: 3.3576306434328167

Epoch: 5| Step: 2
Training loss: 3.364503007211417
Validation loss: 3.3563052079413525

Epoch: 5| Step: 3
Training loss: 3.463735581708378
Validation loss: 3.3544864098326777

Epoch: 5| Step: 4
Training loss: 3.874076733271854
Validation loss: 3.3527602712969604

Epoch: 5| Step: 5
Training loss: 2.4784588698313716
Validation loss: 3.35318611582536

Epoch: 5| Step: 6
Training loss: 3.450986588431302
Validation loss: 3.3527705326941066

Epoch: 5| Step: 7
Training loss: 3.1204481925361693
Validation loss: 3.3534842619695886

Epoch: 5| Step: 8
Training loss: 3.784522035925445
Validation loss: 3.353750186337512

Epoch: 5| Step: 9
Training loss: 3.8074760479339615
Validation loss: 3.351544324180823

Epoch: 5| Step: 10
Training loss: 3.9256828637391576
Validation loss: 3.351575305318681

Epoch: 53| Step: 0
Training loss: 4.225718979915347
Validation loss: 3.350135415832491

Epoch: 5| Step: 1
Training loss: 3.3750952248031845
Validation loss: 3.3507444813486758

Epoch: 5| Step: 2
Training loss: 3.2091267252929194
Validation loss: 3.348421654752195

Epoch: 5| Step: 3
Training loss: 3.765979544382967
Validation loss: 3.3473743840755232

Epoch: 5| Step: 4
Training loss: 3.2408944734309135
Validation loss: 3.3493277293182806

Epoch: 5| Step: 5
Training loss: 3.9544050835516757
Validation loss: 3.348491875754971

Epoch: 5| Step: 6
Training loss: 4.369705920766794
Validation loss: 3.347280803883703

Epoch: 5| Step: 7
Training loss: 2.6770139653066396
Validation loss: 3.346834443972435

Epoch: 5| Step: 8
Training loss: 3.5200394105872452
Validation loss: 3.344758223792537

Epoch: 5| Step: 9
Training loss: 3.234905254739482
Validation loss: 3.34480801299853

Epoch: 5| Step: 10
Training loss: 3.463229899130076
Validation loss: 3.3443890845339204

Epoch: 54| Step: 0
Training loss: 3.1198229822657932
Validation loss: 3.3468751177771434

Epoch: 5| Step: 1
Training loss: 3.3394786612863707
Validation loss: 3.3457158799513746

Epoch: 5| Step: 2
Training loss: 3.508646774485906
Validation loss: 3.3429199267945777

Epoch: 5| Step: 3
Training loss: 3.7055133569981367
Validation loss: 3.3381996938866285

Epoch: 5| Step: 4
Training loss: 4.151809040713081
Validation loss: 3.33858977426441

Epoch: 5| Step: 5
Training loss: 3.696638776595423
Validation loss: 3.336077308784658

Epoch: 5| Step: 6
Training loss: 3.1297676338986746
Validation loss: 3.336002034243724

Epoch: 5| Step: 7
Training loss: 3.995358993385069
Validation loss: 3.3333359154311815

Epoch: 5| Step: 8
Training loss: 3.2371389769522585
Validation loss: 3.3328864618419023

Epoch: 5| Step: 9
Training loss: 3.2598460777781617
Validation loss: 3.3306629010403705

Epoch: 5| Step: 10
Training loss: 4.043984813446598
Validation loss: 3.32601094815381

Epoch: 55| Step: 0
Training loss: 3.933563686888595
Validation loss: 3.32318996915773

Epoch: 5| Step: 1
Training loss: 2.7285696255058087
Validation loss: 3.323487179236256

Epoch: 5| Step: 2
Training loss: 3.356630845723201
Validation loss: 3.319982532413757

Epoch: 5| Step: 3
Training loss: 4.070636992598664
Validation loss: 3.320707037767227

Epoch: 5| Step: 4
Training loss: 3.7702068138565674
Validation loss: 3.318931612286373

Epoch: 5| Step: 5
Training loss: 3.292625689935161
Validation loss: 3.31624518012668

Epoch: 5| Step: 6
Training loss: 3.7876551580594704
Validation loss: 3.3168831753403802

Epoch: 5| Step: 7
Training loss: 3.3221153480948495
Validation loss: 3.3124802678411105

Epoch: 5| Step: 8
Training loss: 3.952891829176633
Validation loss: 3.3107621364247337

Epoch: 5| Step: 9
Training loss: 3.374166597677393
Validation loss: 3.310015296976281

Epoch: 5| Step: 10
Training loss: 3.2481781181203924
Validation loss: 3.3230556186772806

Epoch: 56| Step: 0
Training loss: 3.764175072582409
Validation loss: 3.3133777207035187

Epoch: 5| Step: 1
Training loss: 3.122323683073996
Validation loss: 3.309906727452834

Epoch: 5| Step: 2
Training loss: 3.05936115328
Validation loss: 3.3090836175065186

Epoch: 5| Step: 3
Training loss: 2.9267729643314
Validation loss: 3.311327518767917

Epoch: 5| Step: 4
Training loss: 3.4249453073854395
Validation loss: 3.3087709828359215

Epoch: 5| Step: 5
Training loss: 3.5519444204484096
Validation loss: 3.31006561032601

Epoch: 5| Step: 6
Training loss: 3.6829025574760688
Validation loss: 3.3072040713241093

Epoch: 5| Step: 7
Training loss: 3.8423845300344355
Validation loss: 3.3074342794614253

Epoch: 5| Step: 8
Training loss: 3.6528446608795333
Validation loss: 3.3072683527154374

Epoch: 5| Step: 9
Training loss: 4.048997006020224
Validation loss: 3.3056138357133866

Epoch: 5| Step: 10
Training loss: 3.8258489576677235
Validation loss: 3.305337749255704

Epoch: 57| Step: 0
Training loss: 3.02135954033691
Validation loss: 3.3054981958032554

Epoch: 5| Step: 1
Training loss: 3.8717293010697067
Validation loss: 3.300492737639991

Epoch: 5| Step: 2
Training loss: 4.628363958213258
Validation loss: 3.304234151106186

Epoch: 5| Step: 3
Training loss: 3.5216404969638733
Validation loss: 3.3034652163608977

Epoch: 5| Step: 4
Training loss: 3.327279856655709
Validation loss: 3.3012962607958385

Epoch: 5| Step: 5
Training loss: 3.322967688349151
Validation loss: 3.3002917783162964

Epoch: 5| Step: 6
Training loss: 3.144248883382073
Validation loss: 3.300437007282171

Epoch: 5| Step: 7
Training loss: 3.1116067362896684
Validation loss: 3.2980230809360647

Epoch: 5| Step: 8
Training loss: 3.764558126551321
Validation loss: 3.2986345438762665

Epoch: 5| Step: 9
Training loss: 3.5302000932474433
Validation loss: 3.2961753449238587

Epoch: 5| Step: 10
Training loss: 3.423618377684713
Validation loss: 3.2962591492926387

Epoch: 58| Step: 0
Training loss: 3.6828923290795204
Validation loss: 3.2967099267647906

Epoch: 5| Step: 1
Training loss: 4.0484877506319075
Validation loss: 3.2957628235864407

Epoch: 5| Step: 2
Training loss: 4.160615392430017
Validation loss: 3.2952480363711536

Epoch: 5| Step: 3
Training loss: 3.592230035862709
Validation loss: 3.2949738722121693

Epoch: 5| Step: 4
Training loss: 3.292398604770217
Validation loss: 3.294842462321662

Epoch: 5| Step: 5
Training loss: 3.0976774929323625
Validation loss: 3.295704477379744

Epoch: 5| Step: 6
Training loss: 2.8393512282991766
Validation loss: 3.293010140511659

Epoch: 5| Step: 7
Training loss: 2.793883871331594
Validation loss: 3.2958300284119204

Epoch: 5| Step: 8
Training loss: 4.216319196253679
Validation loss: 3.294135167460142

Epoch: 5| Step: 9
Training loss: 3.774488346212742
Validation loss: 3.2936721762987116

Epoch: 5| Step: 10
Training loss: 2.931417457986542
Validation loss: 3.2917200372080853

Epoch: 59| Step: 0
Training loss: 3.8454578606242604
Validation loss: 3.291723247481567

Epoch: 5| Step: 1
Training loss: 3.462000285421323
Validation loss: 3.291722155583951

Epoch: 5| Step: 2
Training loss: 2.790097426624191
Validation loss: 3.289222862054815

Epoch: 5| Step: 3
Training loss: 3.318139799239164
Validation loss: 3.2906547248450666

Epoch: 5| Step: 4
Training loss: 3.57750020131791
Validation loss: 3.290010281369171

Epoch: 5| Step: 5
Training loss: 3.069047740158512
Validation loss: 3.2924070321359213

Epoch: 5| Step: 6
Training loss: 2.992886693153725
Validation loss: 3.29091284144599

Epoch: 5| Step: 7
Training loss: 4.17160250456041
Validation loss: 3.288064042574688

Epoch: 5| Step: 8
Training loss: 4.554246308565986
Validation loss: 3.2878636569254804

Epoch: 5| Step: 9
Training loss: 3.299112871166177
Validation loss: 3.2858562009862764

Epoch: 5| Step: 10
Training loss: 3.397690965058913
Validation loss: 3.2894132046841786

Epoch: 60| Step: 0
Training loss: 4.028682393765235
Validation loss: 3.2900288898608303

Epoch: 5| Step: 1
Training loss: 3.994332351373323
Validation loss: 3.290571929232875

Epoch: 5| Step: 2
Training loss: 3.843175953744245
Validation loss: 3.290386054945635

Epoch: 5| Step: 3
Training loss: 3.3595358166903786
Validation loss: 3.290025468324953

Epoch: 5| Step: 4
Training loss: 3.836357140360949
Validation loss: 3.286474079103266

Epoch: 5| Step: 5
Training loss: 2.8113323754928703
Validation loss: 3.288066334055969

Epoch: 5| Step: 6
Training loss: 2.8104340488885087
Validation loss: 3.2853751492557253

Epoch: 5| Step: 7
Training loss: 3.295411567048983
Validation loss: 3.2867479741613947

Epoch: 5| Step: 8
Training loss: 3.4086314984193584
Validation loss: 3.2866026941217257

Epoch: 5| Step: 9
Training loss: 3.767133481853939
Validation loss: 3.2889952831645357

Epoch: 5| Step: 10
Training loss: 3.3905531352641143
Validation loss: 3.2840452602223746

Epoch: 61| Step: 0
Training loss: 3.2190769362841127
Validation loss: 3.2836955218082147

Epoch: 5| Step: 1
Training loss: 3.2019688450323973
Validation loss: 3.280558403170217

Epoch: 5| Step: 2
Training loss: 3.6554611528826806
Validation loss: 3.2799815377161763

Epoch: 5| Step: 3
Training loss: 3.7866438549545607
Validation loss: 3.279037909696598

Epoch: 5| Step: 4
Training loss: 3.399066314400527
Validation loss: 3.2788620345418753

Epoch: 5| Step: 5
Training loss: 2.9248002856289914
Validation loss: 3.278395397544838

Epoch: 5| Step: 6
Training loss: 3.23046520744969
Validation loss: 3.278855945340317

Epoch: 5| Step: 7
Training loss: 3.645878876901176
Validation loss: 3.281349543923466

Epoch: 5| Step: 8
Training loss: 3.574023565580767
Validation loss: 3.283427412256111

Epoch: 5| Step: 9
Training loss: 4.114085003899594
Validation loss: 3.281870132654434

Epoch: 5| Step: 10
Training loss: 3.8639762106769298
Validation loss: 3.276560758775796

Epoch: 62| Step: 0
Training loss: 3.682253839639328
Validation loss: 3.2826499378499854

Epoch: 5| Step: 1
Training loss: 3.346031052640847
Validation loss: 3.2795120293074973

Epoch: 5| Step: 2
Training loss: 3.548738099522001
Validation loss: 3.281917449837053

Epoch: 5| Step: 3
Training loss: 3.7069884158072575
Validation loss: 3.2810292534473184

Epoch: 5| Step: 4
Training loss: 3.6743575124880863
Validation loss: 3.2765402773516437

Epoch: 5| Step: 5
Training loss: 3.518336763390827
Validation loss: 3.275796218870387

Epoch: 5| Step: 6
Training loss: 2.9118930626296904
Validation loss: 3.272899192918557

Epoch: 5| Step: 7
Training loss: 3.6667223550440102
Validation loss: 3.2776911455092157

Epoch: 5| Step: 8
Training loss: 3.979301064237144
Validation loss: 3.2815910619161524

Epoch: 5| Step: 9
Training loss: 3.4729537922217903
Validation loss: 3.275434389248266

Epoch: 5| Step: 10
Training loss: 2.9648788108310664
Validation loss: 3.271817052287898

Epoch: 63| Step: 0
Training loss: 3.0730556822975834
Validation loss: 3.273352481670832

Epoch: 5| Step: 1
Training loss: 2.760056833290203
Validation loss: 3.2732627462337467

Epoch: 5| Step: 2
Training loss: 3.2200674675454293
Validation loss: 3.2718218060978415

Epoch: 5| Step: 3
Training loss: 3.801457281259738
Validation loss: 3.2713189147042177

Epoch: 5| Step: 4
Training loss: 3.425808113714869
Validation loss: 3.2722113294189334

Epoch: 5| Step: 5
Training loss: 3.7135122903497457
Validation loss: 3.2708372627225812

Epoch: 5| Step: 6
Training loss: 3.445843368078994
Validation loss: 3.271016569526147

Epoch: 5| Step: 7
Training loss: 3.7373970604438793
Validation loss: 3.2730246553320987

Epoch: 5| Step: 8
Training loss: 3.8763549650730624
Validation loss: 3.2730048418394944

Epoch: 5| Step: 9
Training loss: 4.098642934114557
Validation loss: 3.271481731023747

Epoch: 5| Step: 10
Training loss: 3.2350444008847545
Validation loss: 3.2691147407221206

Epoch: 64| Step: 0
Training loss: 3.5930217502614097
Validation loss: 3.272277120439166

Epoch: 5| Step: 1
Training loss: 4.12614725516003
Validation loss: 3.2688950019921235

Epoch: 5| Step: 2
Training loss: 2.8287792818894464
Validation loss: 3.2677034496552384

Epoch: 5| Step: 3
Training loss: 3.626280459802376
Validation loss: 3.267872588737457

Epoch: 5| Step: 4
Training loss: 3.4822408529612403
Validation loss: 3.2701666075175675

Epoch: 5| Step: 5
Training loss: 3.6971658007027144
Validation loss: 3.2671521868739175

Epoch: 5| Step: 6
Training loss: 3.0063798142795464
Validation loss: 3.267263562008108

Epoch: 5| Step: 7
Training loss: 3.3840259375513817
Validation loss: 3.265866790689614

Epoch: 5| Step: 8
Training loss: 3.470760415827446
Validation loss: 3.266883426675489

Epoch: 5| Step: 9
Training loss: 4.302002888343796
Validation loss: 3.2652229068993313

Epoch: 5| Step: 10
Training loss: 2.594885428220213
Validation loss: 3.268021958515477

Epoch: 65| Step: 0
Training loss: 4.038399913163947
Validation loss: 3.2658270170726804

Epoch: 5| Step: 1
Training loss: 3.44778180891069
Validation loss: 3.2643889132678225

Epoch: 5| Step: 2
Training loss: 2.8607591291123766
Validation loss: 3.2657414238119307

Epoch: 5| Step: 3
Training loss: 3.4050194153533258
Validation loss: 3.2665417379440775

Epoch: 5| Step: 4
Training loss: 3.3013490809197013
Validation loss: 3.263398220789692

Epoch: 5| Step: 5
Training loss: 3.4925525995005886
Validation loss: 3.2652094465179426

Epoch: 5| Step: 6
Training loss: 3.8129145912751423
Validation loss: 3.2620477314112226

Epoch: 5| Step: 7
Training loss: 3.5017389337295777
Validation loss: 3.2642918906878373

Epoch: 5| Step: 8
Training loss: 3.748793725868214
Validation loss: 3.26501911248127

Epoch: 5| Step: 9
Training loss: 3.195973073862635
Validation loss: 3.266146911406059

Epoch: 5| Step: 10
Training loss: 3.6623299412743906
Validation loss: 3.2671028518612126

Epoch: 66| Step: 0
Training loss: 3.4555607141154367
Validation loss: 3.2688427766007173

Epoch: 5| Step: 1
Training loss: 3.5677366083885644
Validation loss: 3.2657129874752338

Epoch: 5| Step: 2
Training loss: 4.080360705942623
Validation loss: 3.2729249819718613

Epoch: 5| Step: 3
Training loss: 3.0470593518948275
Validation loss: 3.2665963090205397

Epoch: 5| Step: 4
Training loss: 3.354720186483822
Validation loss: 3.264742928046025

Epoch: 5| Step: 5
Training loss: 4.170188991737262
Validation loss: 3.2622955081532754

Epoch: 5| Step: 6
Training loss: 3.2483972852455296
Validation loss: 3.260458364530968

Epoch: 5| Step: 7
Training loss: 2.4902638631832503
Validation loss: 3.2609014272938888

Epoch: 5| Step: 8
Training loss: 3.496474670458058
Validation loss: 3.260338190077775

Epoch: 5| Step: 9
Training loss: 3.1832429470258847
Validation loss: 3.26070030404734

Epoch: 5| Step: 10
Training loss: 4.192351989135176
Validation loss: 3.258638503237201

Epoch: 67| Step: 0
Training loss: 1.999994277945916
Validation loss: 3.259944134682799

Epoch: 5| Step: 1
Training loss: 3.2944484657776254
Validation loss: 3.256680231009329

Epoch: 5| Step: 2
Training loss: 4.038242869343269
Validation loss: 3.2580223272656874

Epoch: 5| Step: 3
Training loss: 3.246099332031151
Validation loss: 3.2579231360475385

Epoch: 5| Step: 4
Training loss: 3.5329240189994797
Validation loss: 3.258253938993634

Epoch: 5| Step: 5
Training loss: 3.432334069938935
Validation loss: 3.2578730577193675

Epoch: 5| Step: 6
Training loss: 4.267447616711534
Validation loss: 3.2575494547854786

Epoch: 5| Step: 7
Training loss: 3.864387253605052
Validation loss: 3.259334804730006

Epoch: 5| Step: 8
Training loss: 3.2485942734855557
Validation loss: 3.2574879183192724

Epoch: 5| Step: 9
Training loss: 3.8141005861474078
Validation loss: 3.2601302371422607

Epoch: 5| Step: 10
Training loss: 3.2336417578713803
Validation loss: 3.2596108402238286

Epoch: 68| Step: 0
Training loss: 3.4879799570680166
Validation loss: 3.265294956368842

Epoch: 5| Step: 1
Training loss: 3.660911522845176
Validation loss: 3.2647800905941526

Epoch: 5| Step: 2
Training loss: 3.486147852919751
Validation loss: 3.2587230487288017

Epoch: 5| Step: 3
Training loss: 3.0849657291134838
Validation loss: 3.2576973069131574

Epoch: 5| Step: 4
Training loss: 3.612615674552709
Validation loss: 3.261255117093914

Epoch: 5| Step: 5
Training loss: 3.3277645005386005
Validation loss: 3.2717080630124626

Epoch: 5| Step: 6
Training loss: 3.243639811443218
Validation loss: 3.2717548125487568

Epoch: 5| Step: 7
Training loss: 2.929215456762898
Validation loss: 3.2569429072071725

Epoch: 5| Step: 8
Training loss: 3.9414089115916435
Validation loss: 3.2537852103280023

Epoch: 5| Step: 9
Training loss: 4.045403761734913
Validation loss: 3.2524140812930473

Epoch: 5| Step: 10
Training loss: 3.54380147583728
Validation loss: 3.2524897959221373

Epoch: 69| Step: 0
Training loss: 3.4295448499484036
Validation loss: 3.252890011047183

Epoch: 5| Step: 1
Training loss: 3.40142676766473
Validation loss: 3.2540345041051992

Epoch: 5| Step: 2
Training loss: 3.1509194258421482
Validation loss: 3.25221177969151

Epoch: 5| Step: 3
Training loss: 2.9423894568772475
Validation loss: 3.251537823705512

Epoch: 5| Step: 4
Training loss: 3.998301383798935
Validation loss: 3.251686401721897

Epoch: 5| Step: 5
Training loss: 4.133874536789075
Validation loss: 3.2507846766910062

Epoch: 5| Step: 6
Training loss: 3.7560904318228614
Validation loss: 3.2505101260289258

Epoch: 5| Step: 7
Training loss: 3.127070084623616
Validation loss: 3.2506528108811574

Epoch: 5| Step: 8
Training loss: 3.8114522526099917
Validation loss: 3.247231230916897

Epoch: 5| Step: 9
Training loss: 3.675755045652478
Validation loss: 3.248669480553975

Epoch: 5| Step: 10
Training loss: 2.672824623939422
Validation loss: 3.2468490186916257

Epoch: 70| Step: 0
Training loss: 3.8356299500404702
Validation loss: 3.2499406618265616

Epoch: 5| Step: 1
Training loss: 3.490770159019437
Validation loss: 3.250531206821075

Epoch: 5| Step: 2
Training loss: 3.482459255837302
Validation loss: 3.25218339611214

Epoch: 5| Step: 3
Training loss: 3.3129977446092735
Validation loss: 3.2489883356499902

Epoch: 5| Step: 4
Training loss: 3.8620639345002408
Validation loss: 3.251362359659952

Epoch: 5| Step: 5
Training loss: 3.5690320012097367
Validation loss: 3.251047774823799

Epoch: 5| Step: 6
Training loss: 3.559823888215863
Validation loss: 3.2494264101231933

Epoch: 5| Step: 7
Training loss: 2.758321482776029
Validation loss: 3.24798457599271

Epoch: 5| Step: 8
Training loss: 3.3541960784064875
Validation loss: 3.2482689648294385

Epoch: 5| Step: 9
Training loss: 3.312688426290673
Validation loss: 3.246321019676463

Epoch: 5| Step: 10
Training loss: 3.830840475028579
Validation loss: 3.246962109561764

Epoch: 71| Step: 0
Training loss: 3.3507629721337144
Validation loss: 3.248251549570259

Epoch: 5| Step: 1
Training loss: 2.6051015066040506
Validation loss: 3.245641148643183

Epoch: 5| Step: 2
Training loss: 3.495352384077948
Validation loss: 3.247231540395037

Epoch: 5| Step: 3
Training loss: 3.731872102898895
Validation loss: 3.24606154493617

Epoch: 5| Step: 4
Training loss: 3.3807274998200536
Validation loss: 3.2447043802364433

Epoch: 5| Step: 5
Training loss: 3.0205725370934666
Validation loss: 3.2453801344676423

Epoch: 5| Step: 6
Training loss: 4.029998348415595
Validation loss: 3.2453350667606173

Epoch: 5| Step: 7
Training loss: 2.575586352207633
Validation loss: 3.2455107508163485

Epoch: 5| Step: 8
Training loss: 3.433846908107272
Validation loss: 3.2453613323709276

Epoch: 5| Step: 9
Training loss: 4.153169106736492
Validation loss: 3.24556840378845

Epoch: 5| Step: 10
Training loss: 4.28510728806349
Validation loss: 3.2476612870727366

Epoch: 72| Step: 0
Training loss: 3.6709953390708603
Validation loss: 3.2476513534927713

Epoch: 5| Step: 1
Training loss: 2.6263876380785187
Validation loss: 3.244508280204289

Epoch: 5| Step: 2
Training loss: 3.780940523960611
Validation loss: 3.2457681464966472

Epoch: 5| Step: 3
Training loss: 4.041040404784464
Validation loss: 3.2435933537954917

Epoch: 5| Step: 4
Training loss: 3.9195110598054206
Validation loss: 3.243305614540879

Epoch: 5| Step: 5
Training loss: 2.9673474662933854
Validation loss: 3.2440780628973354

Epoch: 5| Step: 6
Training loss: 2.9795885298665
Validation loss: 3.2433967447453425

Epoch: 5| Step: 7
Training loss: 4.031270108431558
Validation loss: 3.2425581936486845

Epoch: 5| Step: 8
Training loss: 2.9987240303063105
Validation loss: 3.2422730722314617

Epoch: 5| Step: 9
Training loss: 3.823365409492584
Validation loss: 3.241562681435978

Epoch: 5| Step: 10
Training loss: 3.10809790680194
Validation loss: 3.2432058641380874

Epoch: 73| Step: 0
Training loss: 3.317198246540014
Validation loss: 3.2400768041223897

Epoch: 5| Step: 1
Training loss: 3.68431406270012
Validation loss: 3.2401270767995127

Epoch: 5| Step: 2
Training loss: 3.5591428230527216
Validation loss: 3.2410033313943063

Epoch: 5| Step: 3
Training loss: 3.1789528937772094
Validation loss: 3.240248450237335

Epoch: 5| Step: 4
Training loss: 2.8156025198696355
Validation loss: 3.240353497522906

Epoch: 5| Step: 5
Training loss: 3.2367668706257287
Validation loss: 3.242037199321874

Epoch: 5| Step: 6
Training loss: 3.9282068454952945
Validation loss: 3.242851751278594

Epoch: 5| Step: 7
Training loss: 3.791303149113962
Validation loss: 3.2415511822287684

Epoch: 5| Step: 8
Training loss: 3.2691037571948027
Validation loss: 3.241132458342596

Epoch: 5| Step: 9
Training loss: 3.6303868224797977
Validation loss: 3.2390306645843148

Epoch: 5| Step: 10
Training loss: 3.845067488495991
Validation loss: 3.2384929095244948

Epoch: 74| Step: 0
Training loss: 3.839933159564353
Validation loss: 3.239057177603619

Epoch: 5| Step: 1
Training loss: 3.371120059373726
Validation loss: 3.24111908141942

Epoch: 5| Step: 2
Training loss: 3.478870919881516
Validation loss: 3.2390344494581322

Epoch: 5| Step: 3
Training loss: 3.6020009731734093
Validation loss: 3.239501567233787

Epoch: 5| Step: 4
Training loss: 4.029122671040311
Validation loss: 3.2378596820104217

Epoch: 5| Step: 5
Training loss: 3.2239670925401422
Validation loss: 3.23674098832188

Epoch: 5| Step: 6
Training loss: 3.2650607410990697
Validation loss: 3.2370380909091825

Epoch: 5| Step: 7
Training loss: 2.958516683851543
Validation loss: 3.2373611103026536

Epoch: 5| Step: 8
Training loss: 3.484472846466339
Validation loss: 3.236643411807053

Epoch: 5| Step: 9
Training loss: 3.226530873880264
Validation loss: 3.2350933887554794

Epoch: 5| Step: 10
Training loss: 3.7972806235076955
Validation loss: 3.234908237682766

Epoch: 75| Step: 0
Training loss: 3.7170826996969972
Validation loss: 3.2369907813775067

Epoch: 5| Step: 1
Training loss: 3.1353078593049886
Validation loss: 3.2351162491909804

Epoch: 5| Step: 2
Training loss: 4.125158364695042
Validation loss: 3.2364134156956874

Epoch: 5| Step: 3
Training loss: 3.4256813095634544
Validation loss: 3.2365211855356475

Epoch: 5| Step: 4
Training loss: 3.28489351979655
Validation loss: 3.236585157873286

Epoch: 5| Step: 5
Training loss: 3.7293239254887935
Validation loss: 3.2365751071300037

Epoch: 5| Step: 6
Training loss: 2.991260036223712
Validation loss: 3.237357052645074

Epoch: 5| Step: 7
Training loss: 3.6643672726891436
Validation loss: 3.2386882457989046

Epoch: 5| Step: 8
Training loss: 3.1739263806906335
Validation loss: 3.23743816682048

Epoch: 5| Step: 9
Training loss: 3.7785840685594634
Validation loss: 3.2359617752976746

Epoch: 5| Step: 10
Training loss: 3.0342321768874703
Validation loss: 3.236599965019113

Epoch: 76| Step: 0
Training loss: 2.9698076472303474
Validation loss: 3.234574482838484

Epoch: 5| Step: 1
Training loss: 3.3195957981081645
Validation loss: 3.2330083850476177

Epoch: 5| Step: 2
Training loss: 3.4858114933646296
Validation loss: 3.2350376570500976

Epoch: 5| Step: 3
Training loss: 4.085996083993851
Validation loss: 3.235513833908272

Epoch: 5| Step: 4
Training loss: 3.644169338692617
Validation loss: 3.2366758008765313

Epoch: 5| Step: 5
Training loss: 3.609380284425244
Validation loss: 3.2378981823966786

Epoch: 5| Step: 6
Training loss: 3.1283551324875085
Validation loss: 3.2340734784243477

Epoch: 5| Step: 7
Training loss: 3.030012684408397
Validation loss: 3.2325695361382776

Epoch: 5| Step: 8
Training loss: 3.693486542834839
Validation loss: 3.232696451153458

Epoch: 5| Step: 9
Training loss: 3.88512647975222
Validation loss: 3.2344039401285003

Epoch: 5| Step: 10
Training loss: 3.1993764388984176
Validation loss: 3.2396626566461406

Epoch: 77| Step: 0
Training loss: 2.890696756657923
Validation loss: 3.258336861866072

Epoch: 5| Step: 1
Training loss: 3.497192755640584
Validation loss: 3.2762142277915536

Epoch: 5| Step: 2
Training loss: 3.1762271582132295
Validation loss: 3.2932659878154893

Epoch: 5| Step: 3
Training loss: 3.177133495164116
Validation loss: 3.2524227092144846

Epoch: 5| Step: 4
Training loss: 3.0077072323299947
Validation loss: 3.2316367386193567

Epoch: 5| Step: 5
Training loss: 3.793281141591384
Validation loss: 3.2292565869458816

Epoch: 5| Step: 6
Training loss: 3.6179632092530047
Validation loss: 3.2301468207479527

Epoch: 5| Step: 7
Training loss: 3.392815651317242
Validation loss: 3.230416777921407

Epoch: 5| Step: 8
Training loss: 4.1924502591462
Validation loss: 3.228957366246971

Epoch: 5| Step: 9
Training loss: 3.6339404908316486
Validation loss: 3.2297611405208184

Epoch: 5| Step: 10
Training loss: 3.799073136379009
Validation loss: 3.2293421279178327

Epoch: 78| Step: 0
Training loss: 3.971249611734162
Validation loss: 3.2281227581235297

Epoch: 5| Step: 1
Training loss: 3.2372955552284464
Validation loss: 3.2287902586187704

Epoch: 5| Step: 2
Training loss: 4.014419552851131
Validation loss: 3.2294889375927593

Epoch: 5| Step: 3
Training loss: 3.0366571709170005
Validation loss: 3.2291506578655285

Epoch: 5| Step: 4
Training loss: 3.771983875640677
Validation loss: 3.2341817447661034

Epoch: 5| Step: 5
Training loss: 3.4648160879585608
Validation loss: 3.2372630218956076

Epoch: 5| Step: 6
Training loss: 2.927195880576939
Validation loss: 3.2409623398211473

Epoch: 5| Step: 7
Training loss: 3.282354550418544
Validation loss: 3.24914427346452

Epoch: 5| Step: 8
Training loss: 3.2050336408114206
Validation loss: 3.2406308167861115

Epoch: 5| Step: 9
Training loss: 3.281743766327156
Validation loss: 3.2360264423789844

Epoch: 5| Step: 10
Training loss: 3.909368750112098
Validation loss: 3.226872575921084

Epoch: 79| Step: 0
Training loss: 3.5840030014842954
Validation loss: 3.226316787154244

Epoch: 5| Step: 1
Training loss: 3.3121986971882835
Validation loss: 3.225582819565067

Epoch: 5| Step: 2
Training loss: 2.758270571437394
Validation loss: 3.224117310054919

Epoch: 5| Step: 3
Training loss: 3.27959204067321
Validation loss: 3.225243132586239

Epoch: 5| Step: 4
Training loss: 3.0116905676170056
Validation loss: 3.2268593885525525

Epoch: 5| Step: 5
Training loss: 4.094357278057906
Validation loss: 3.2240671511254093

Epoch: 5| Step: 6
Training loss: 3.61894694107005
Validation loss: 3.224129148151378

Epoch: 5| Step: 7
Training loss: 3.7838864553727456
Validation loss: 3.225542748706563

Epoch: 5| Step: 8
Training loss: 3.3087146651366792
Validation loss: 3.224888607008235

Epoch: 5| Step: 9
Training loss: 3.7911546102887668
Validation loss: 3.2255095166266345

Epoch: 5| Step: 10
Training loss: 3.4873295732100025
Validation loss: 3.221533468928373

Epoch: 80| Step: 0
Training loss: 3.828314702530199
Validation loss: 3.221894574883923

Epoch: 5| Step: 1
Training loss: 3.1476139477623284
Validation loss: 3.2208825611400753

Epoch: 5| Step: 2
Training loss: 3.6648925621865924
Validation loss: 3.2213776636385423

Epoch: 5| Step: 3
Training loss: 3.7607671657100252
Validation loss: 3.2205229958666575

Epoch: 5| Step: 4
Training loss: 3.061345408250785
Validation loss: 3.219358970220954

Epoch: 5| Step: 5
Training loss: 3.2482485820374043
Validation loss: 3.2199523731740713

Epoch: 5| Step: 6
Training loss: 3.066247321219816
Validation loss: 3.222380811965613

Epoch: 5| Step: 7
Training loss: 3.6036905551206018
Validation loss: 3.2234304049761864

Epoch: 5| Step: 8
Training loss: 3.4790863819719475
Validation loss: 3.220964042440481

Epoch: 5| Step: 9
Training loss: 3.5880793406071985
Validation loss: 3.221032384473671

Epoch: 5| Step: 10
Training loss: 3.636031105269361
Validation loss: 3.2212749358085366

Epoch: 81| Step: 0
Training loss: 3.6482662838739937
Validation loss: 3.221574360759203

Epoch: 5| Step: 1
Training loss: 3.327283726061452
Validation loss: 3.2227000820526404

Epoch: 5| Step: 2
Training loss: 3.6965785367990147
Validation loss: 3.222587714885043

Epoch: 5| Step: 3
Training loss: 3.482137329320747
Validation loss: 3.2192400614900927

Epoch: 5| Step: 4
Training loss: 3.0655892808487866
Validation loss: 3.2206306701847005

Epoch: 5| Step: 5
Training loss: 3.6399099278047715
Validation loss: 3.218546985914688

Epoch: 5| Step: 6
Training loss: 3.215563038932472
Validation loss: 3.2174519973076765

Epoch: 5| Step: 7
Training loss: 3.3480742826709675
Validation loss: 3.21868545494591

Epoch: 5| Step: 8
Training loss: 3.2407118782897655
Validation loss: 3.217815459831593

Epoch: 5| Step: 9
Training loss: 3.820845677901155
Validation loss: 3.2178587356070443

Epoch: 5| Step: 10
Training loss: 3.577460481330772
Validation loss: 3.216961888956259

Epoch: 82| Step: 0
Training loss: 3.2097853475324305
Validation loss: 3.2208252606556522

Epoch: 5| Step: 1
Training loss: 3.2966295485404573
Validation loss: 3.22430454853424

Epoch: 5| Step: 2
Training loss: 3.552264316158158
Validation loss: 3.2177981052209104

Epoch: 5| Step: 3
Training loss: 3.6398019801762596
Validation loss: 3.216271216672049

Epoch: 5| Step: 4
Training loss: 3.631067919474909
Validation loss: 3.2153312989137532

Epoch: 5| Step: 5
Training loss: 3.6566227127906274
Validation loss: 3.214022056716016

Epoch: 5| Step: 6
Training loss: 2.966822269373708
Validation loss: 3.215328800119033

Epoch: 5| Step: 7
Training loss: 3.4743302282998836
Validation loss: 3.2137121273453504

Epoch: 5| Step: 8
Training loss: 3.4974820752942244
Validation loss: 3.2157622792613565

Epoch: 5| Step: 9
Training loss: 3.869042770326811
Validation loss: 3.2138820602269242

Epoch: 5| Step: 10
Training loss: 3.1819713741431896
Validation loss: 3.213420844441428

Epoch: 83| Step: 0
Training loss: 3.9345781899508507
Validation loss: 3.2131287707776797

Epoch: 5| Step: 1
Training loss: 3.4794975321405066
Validation loss: 3.2131940848785794

Epoch: 5| Step: 2
Training loss: 3.3448148083705505
Validation loss: 3.213643117491173

Epoch: 5| Step: 3
Training loss: 3.326746838838826
Validation loss: 3.2117136990220727

Epoch: 5| Step: 4
Training loss: 2.994299559035997
Validation loss: 3.2125718515515924

Epoch: 5| Step: 5
Training loss: 3.4749897689119846
Validation loss: 3.213672957486746

Epoch: 5| Step: 6
Training loss: 3.5634194241702324
Validation loss: 3.2126242224382358

Epoch: 5| Step: 7
Training loss: 3.3841831874999935
Validation loss: 3.2121721470925317

Epoch: 5| Step: 8
Training loss: 4.030380746731386
Validation loss: 3.2111481420650256

Epoch: 5| Step: 9
Training loss: 2.2812536579259524
Validation loss: 3.2106648174577708

Epoch: 5| Step: 10
Training loss: 3.9789636104096084
Validation loss: 3.2114377631219027

Epoch: 84| Step: 0
Training loss: 3.4542270472594234
Validation loss: 3.2112501336674417

Epoch: 5| Step: 1
Training loss: 3.5609638850869514
Validation loss: 3.21129106064536

Epoch: 5| Step: 2
Training loss: 3.696946280945832
Validation loss: 3.209445697941807

Epoch: 5| Step: 3
Training loss: 3.350182024437298
Validation loss: 3.215830585157442

Epoch: 5| Step: 4
Training loss: 3.647090949273537
Validation loss: 3.2106019495878884

Epoch: 5| Step: 5
Training loss: 3.1641839651646793
Validation loss: 3.21501508070897

Epoch: 5| Step: 6
Training loss: 3.349290339899607
Validation loss: 3.23100714074444

Epoch: 5| Step: 7
Training loss: 2.715929870700095
Validation loss: 3.2313430998995436

Epoch: 5| Step: 8
Training loss: 4.016070270713838
Validation loss: 3.2123671094846458

Epoch: 5| Step: 9
Training loss: 3.173841045646777
Validation loss: 3.2093443455533013

Epoch: 5| Step: 10
Training loss: 3.804476440340697
Validation loss: 3.2084523485085987

Epoch: 85| Step: 0
Training loss: 3.567403396977294
Validation loss: 3.2067167787838486

Epoch: 5| Step: 1
Training loss: 3.511499722686761
Validation loss: 3.207464488569526

Epoch: 5| Step: 2
Training loss: 3.585784576413143
Validation loss: 3.207649422284826

Epoch: 5| Step: 3
Training loss: 2.9643966076276724
Validation loss: 3.2070444301708947

Epoch: 5| Step: 4
Training loss: 3.3618980691447704
Validation loss: 3.2065483521987472

Epoch: 5| Step: 5
Training loss: 2.778652649966134
Validation loss: 3.20490212992833

Epoch: 5| Step: 6
Training loss: 3.2482137906694226
Validation loss: 3.207186054435805

Epoch: 5| Step: 7
Training loss: 4.0802389344207395
Validation loss: 3.206157057822564

Epoch: 5| Step: 8
Training loss: 3.234207075247133
Validation loss: 3.206122864379413

Epoch: 5| Step: 9
Training loss: 3.4406564265867914
Validation loss: 3.206474725248315

Epoch: 5| Step: 10
Training loss: 4.150031004640512
Validation loss: 3.204605508720825

Epoch: 86| Step: 0
Training loss: 3.437277630636024
Validation loss: 3.2038251582316604

Epoch: 5| Step: 1
Training loss: 3.63117573279697
Validation loss: 3.2043573433488333

Epoch: 5| Step: 2
Training loss: 3.1694916288039936
Validation loss: 3.2096533859712726

Epoch: 5| Step: 3
Training loss: 3.6461608448970475
Validation loss: 3.205965419350114

Epoch: 5| Step: 4
Training loss: 4.0743346156673
Validation loss: 3.2108568469275265

Epoch: 5| Step: 5
Training loss: 2.9242436401058
Validation loss: 3.205695096880311

Epoch: 5| Step: 6
Training loss: 3.4849152424164025
Validation loss: 3.2029257035301266

Epoch: 5| Step: 7
Training loss: 3.1025634995201448
Validation loss: 3.203158661200019

Epoch: 5| Step: 8
Training loss: 3.4523470593497234
Validation loss: 3.2042000451925636

Epoch: 5| Step: 9
Training loss: 3.0675663982688435
Validation loss: 3.208297339883263

Epoch: 5| Step: 10
Training loss: 3.9103142918860274
Validation loss: 3.201940023280716

Epoch: 87| Step: 0
Training loss: 3.5051354471066416
Validation loss: 3.202563768346438

Epoch: 5| Step: 1
Training loss: 3.1899643889445497
Validation loss: 3.204397073500959

Epoch: 5| Step: 2
Training loss: 3.160727167603579
Validation loss: 3.2022728147282193

Epoch: 5| Step: 3
Training loss: 3.6514158977678344
Validation loss: 3.2034729807328355

Epoch: 5| Step: 4
Training loss: 3.437281792390652
Validation loss: 3.203539487211392

Epoch: 5| Step: 5
Training loss: 3.106291962921569
Validation loss: 3.2017589218186537

Epoch: 5| Step: 6
Training loss: 3.415315097106622
Validation loss: 3.2024611326621497

Epoch: 5| Step: 7
Training loss: 3.077056544416931
Validation loss: 3.20299487546202

Epoch: 5| Step: 8
Training loss: 3.900158702849112
Validation loss: 3.2006209002792585

Epoch: 5| Step: 9
Training loss: 3.3772311429892192
Validation loss: 3.2033522674587265

Epoch: 5| Step: 10
Training loss: 4.098305766191469
Validation loss: 3.1999203349651557

Epoch: 88| Step: 0
Training loss: 3.248382899645225
Validation loss: 3.201879334862751

Epoch: 5| Step: 1
Training loss: 3.5366508570062147
Validation loss: 3.2014623633284187

Epoch: 5| Step: 2
Training loss: 3.76778644244911
Validation loss: 3.2002104017731385

Epoch: 5| Step: 3
Training loss: 3.147003377286531
Validation loss: 3.20107308290954

Epoch: 5| Step: 4
Training loss: 4.052082967226981
Validation loss: 3.2014751612370285

Epoch: 5| Step: 5
Training loss: 3.0352187770063614
Validation loss: 3.2011531031517415

Epoch: 5| Step: 6
Training loss: 3.6762074984493562
Validation loss: 3.2014672416262338

Epoch: 5| Step: 7
Training loss: 3.781475722456296
Validation loss: 3.2009809367839215

Epoch: 5| Step: 8
Training loss: 3.644099202770664
Validation loss: 3.2029913297384884

Epoch: 5| Step: 9
Training loss: 2.5680217332425372
Validation loss: 3.2000128481078893

Epoch: 5| Step: 10
Training loss: 3.186531667789325
Validation loss: 3.2018128883810517

Epoch: 89| Step: 0
Training loss: 4.2551509833080035
Validation loss: 3.200894961454404

Epoch: 5| Step: 1
Training loss: 3.309587745924503
Validation loss: 3.2009607894765626

Epoch: 5| Step: 2
Training loss: 3.44442924544013
Validation loss: 3.2008947868552124

Epoch: 5| Step: 3
Training loss: 3.7414593396310356
Validation loss: 3.199315124107462

Epoch: 5| Step: 4
Training loss: 2.9901007405026494
Validation loss: 3.197633581180185

Epoch: 5| Step: 5
Training loss: 3.421247450883701
Validation loss: 3.1990022448438533

Epoch: 5| Step: 6
Training loss: 2.7282413243753827
Validation loss: 3.200097281761578

Epoch: 5| Step: 7
Training loss: 3.861701665551489
Validation loss: 3.199570780406702

Epoch: 5| Step: 8
Training loss: 3.4480068198842444
Validation loss: 3.200736318944171

Epoch: 5| Step: 9
Training loss: 3.044215523527617
Validation loss: 3.2005320869324785

Epoch: 5| Step: 10
Training loss: 3.4092661251932412
Validation loss: 3.200269397937223

Epoch: 90| Step: 0
Training loss: 2.835987773691356
Validation loss: 3.2039914923794064

Epoch: 5| Step: 1
Training loss: 2.9847009291100624
Validation loss: 3.2006234257754

Epoch: 5| Step: 2
Training loss: 3.332944434049849
Validation loss: 3.1999807993635834

Epoch: 5| Step: 3
Training loss: 3.534602641389769
Validation loss: 3.2010663043459924

Epoch: 5| Step: 4
Training loss: 3.754554144832253
Validation loss: 3.1959842557740954

Epoch: 5| Step: 5
Training loss: 3.7973753046152234
Validation loss: 3.1966253277911103

Epoch: 5| Step: 6
Training loss: 3.71439151036847
Validation loss: 3.1946975080476854

Epoch: 5| Step: 7
Training loss: 3.5243388374314737
Validation loss: 3.1940058458959384

Epoch: 5| Step: 8
Training loss: 3.4595095614320317
Validation loss: 3.1955093269813855

Epoch: 5| Step: 9
Training loss: 3.5764093408750814
Validation loss: 3.1942128852950566

Epoch: 5| Step: 10
Training loss: 3.236726652297332
Validation loss: 3.1944686586146807

Epoch: 91| Step: 0
Training loss: 3.472736164628147
Validation loss: 3.1925976402202885

Epoch: 5| Step: 1
Training loss: 3.6338603159585587
Validation loss: 3.1925730732900925

Epoch: 5| Step: 2
Training loss: 3.0491448188437587
Validation loss: 3.1943519452865923

Epoch: 5| Step: 3
Training loss: 3.272706453180078
Validation loss: 3.192154963234586

Epoch: 5| Step: 4
Training loss: 3.889978194187896
Validation loss: 3.195501763231747

Epoch: 5| Step: 5
Training loss: 3.769619670878447
Validation loss: 3.1935056922509792

Epoch: 5| Step: 6
Training loss: 3.1151641168115702
Validation loss: 3.194381302585076

Epoch: 5| Step: 7
Training loss: 3.726886983056054
Validation loss: 3.1960459705583597

Epoch: 5| Step: 8
Training loss: 2.6811089929880683
Validation loss: 3.1923789915893637

Epoch: 5| Step: 9
Training loss: 3.563463984117291
Validation loss: 3.1942372357573463

Epoch: 5| Step: 10
Training loss: 3.508270709520127
Validation loss: 3.1930321643598356

Epoch: 92| Step: 0
Training loss: 3.667105446195354
Validation loss: 3.1927287891293843

Epoch: 5| Step: 1
Training loss: 3.516437623096549
Validation loss: 3.1957907999806396

Epoch: 5| Step: 2
Training loss: 3.621298774914838
Validation loss: 3.2037771694057846

Epoch: 5| Step: 3
Training loss: 3.554477425540463
Validation loss: 3.206616488201784

Epoch: 5| Step: 4
Training loss: 3.1993239761579235
Validation loss: 3.193717824384002

Epoch: 5| Step: 5
Training loss: 3.709810298583615
Validation loss: 3.192361149369827

Epoch: 5| Step: 6
Training loss: 3.6456141524052943
Validation loss: 3.1908809755597503

Epoch: 5| Step: 7
Training loss: 2.5096065010657846
Validation loss: 3.191311170589265

Epoch: 5| Step: 8
Training loss: 3.388329357239329
Validation loss: 3.189026380454786

Epoch: 5| Step: 9
Training loss: 3.6007570371436546
Validation loss: 3.1895302104471877

Epoch: 5| Step: 10
Training loss: 3.219190400744056
Validation loss: 3.188832078068245

Epoch: 93| Step: 0
Training loss: 2.9539784000668527
Validation loss: 3.1882085203734523

Epoch: 5| Step: 1
Training loss: 3.6897396463072756
Validation loss: 3.1881286367948345

Epoch: 5| Step: 2
Training loss: 3.56887902128482
Validation loss: 3.1905445982028446

Epoch: 5| Step: 3
Training loss: 3.6604213557523604
Validation loss: 3.187878659602644

Epoch: 5| Step: 4
Training loss: 2.934810462303485
Validation loss: 3.1871254990699645

Epoch: 5| Step: 5
Training loss: 3.599641962260931
Validation loss: 3.1885157620878877

Epoch: 5| Step: 6
Training loss: 3.968685840478563
Validation loss: 3.1870959430175536

Epoch: 5| Step: 7
Training loss: 4.054385723430906
Validation loss: 3.1871505310880948

Epoch: 5| Step: 8
Training loss: 3.3525069179932903
Validation loss: 3.1837264792709443

Epoch: 5| Step: 9
Training loss: 2.84900807971284
Validation loss: 3.1843744484956913

Epoch: 5| Step: 10
Training loss: 2.844031854432344
Validation loss: 3.1871981227507784

Epoch: 94| Step: 0
Training loss: 3.359392033023679
Validation loss: 3.1859953415565494

Epoch: 5| Step: 1
Training loss: 3.690938736309232
Validation loss: 3.1864080398471057

Epoch: 5| Step: 2
Training loss: 4.149794074774929
Validation loss: 3.188474891718819

Epoch: 5| Step: 3
Training loss: 3.557155146662394
Validation loss: 3.1856146103746266

Epoch: 5| Step: 4
Training loss: 2.721850501737484
Validation loss: 3.1883535752279113

Epoch: 5| Step: 5
Training loss: 3.7260186460297704
Validation loss: 3.1874814098313893

Epoch: 5| Step: 6
Training loss: 2.809526270102531
Validation loss: 3.1863853312002925

Epoch: 5| Step: 7
Training loss: 3.82225689231565
Validation loss: 3.1877567333442953

Epoch: 5| Step: 8
Training loss: 3.452053542498772
Validation loss: 3.1847088034028554

Epoch: 5| Step: 9
Training loss: 3.351933385428344
Validation loss: 3.1854501044613954

Epoch: 5| Step: 10
Training loss: 2.73849708479245
Validation loss: 3.186511549803132

Epoch: 95| Step: 0
Training loss: 3.3539042083854866
Validation loss: 3.1855980355888005

Epoch: 5| Step: 1
Training loss: 3.7663995096668192
Validation loss: 3.186245324895726

Epoch: 5| Step: 2
Training loss: 3.4110121728863856
Validation loss: 3.185226598059533

Epoch: 5| Step: 3
Training loss: 3.179374060775951
Validation loss: 3.1849549822411554

Epoch: 5| Step: 4
Training loss: 3.411593384532617
Validation loss: 3.184774244735387

Epoch: 5| Step: 5
Training loss: 3.2290825781589767
Validation loss: 3.1854149475159548

Epoch: 5| Step: 6
Training loss: 3.0150753172518217
Validation loss: 3.18378096567987

Epoch: 5| Step: 7
Training loss: 3.6925565027499547
Validation loss: 3.1844284351492322

Epoch: 5| Step: 8
Training loss: 3.927059439966721
Validation loss: 3.183582202460875

Epoch: 5| Step: 9
Training loss: 3.6244032796173196
Validation loss: 3.184756694779616

Epoch: 5| Step: 10
Training loss: 2.9397997680261194
Validation loss: 3.182610583894698

Epoch: 96| Step: 0
Training loss: 3.8665403498921034
Validation loss: 3.181322043542132

Epoch: 5| Step: 1
Training loss: 3.180372609555036
Validation loss: 3.1814361115540453

Epoch: 5| Step: 2
Training loss: 3.3133669024736325
Validation loss: 3.181890320409595

Epoch: 5| Step: 3
Training loss: 3.2710517437818143
Validation loss: 3.181500883706187

Epoch: 5| Step: 4
Training loss: 3.568365655568843
Validation loss: 3.1812679517920293

Epoch: 5| Step: 5
Training loss: 3.7349960257676313
Validation loss: 3.1805047945584013

Epoch: 5| Step: 6
Training loss: 3.432621910558628
Validation loss: 3.1813272524959175

Epoch: 5| Step: 7
Training loss: 3.5515436711548567
Validation loss: 3.181455078709533

Epoch: 5| Step: 8
Training loss: 3.061766400347259
Validation loss: 3.180304198264846

Epoch: 5| Step: 9
Training loss: 3.310022399227267
Validation loss: 3.179916012019188

Epoch: 5| Step: 10
Training loss: 3.3351563872540377
Validation loss: 3.181055885596346

Epoch: 97| Step: 0
Training loss: 3.9899149359333324
Validation loss: 3.178873213098596

Epoch: 5| Step: 1
Training loss: 3.2976180409899953
Validation loss: 3.180896393070812

Epoch: 5| Step: 2
Training loss: 4.064599536346618
Validation loss: 3.1799883271210327

Epoch: 5| Step: 3
Training loss: 3.1719611395804175
Validation loss: 3.1806671285529013

Epoch: 5| Step: 4
Training loss: 3.148437802903987
Validation loss: 3.1813345566209574

Epoch: 5| Step: 5
Training loss: 3.0518385926808724
Validation loss: 3.185135429394138

Epoch: 5| Step: 6
Training loss: 2.3688795633035067
Validation loss: 3.1897711869076053

Epoch: 5| Step: 7
Training loss: 4.088624730653371
Validation loss: 3.1934638132332203

Epoch: 5| Step: 8
Training loss: 3.645249994022481
Validation loss: 3.201759933099544

Epoch: 5| Step: 9
Training loss: 3.432662889765103
Validation loss: 3.188404283930951

Epoch: 5| Step: 10
Training loss: 3.043247978904841
Validation loss: 3.1771497752105855

Epoch: 98| Step: 0
Training loss: 3.266267704118237
Validation loss: 3.177555697201701

Epoch: 5| Step: 1
Training loss: 3.0748681202962764
Validation loss: 3.1768897411983144

Epoch: 5| Step: 2
Training loss: 3.3534277502865035
Validation loss: 3.175564332030595

Epoch: 5| Step: 3
Training loss: 3.433489037350271
Validation loss: 3.176552458490514

Epoch: 5| Step: 4
Training loss: 3.1382751783863503
Validation loss: 3.175339270756818

Epoch: 5| Step: 5
Training loss: 3.257905295534671
Validation loss: 3.1761200069582887

Epoch: 5| Step: 6
Training loss: 3.4749357039177435
Validation loss: 3.1765640961482355

Epoch: 5| Step: 7
Training loss: 3.1358093995833256
Validation loss: 3.174651086827069

Epoch: 5| Step: 8
Training loss: 4.033414983842447
Validation loss: 3.174760631044978

Epoch: 5| Step: 9
Training loss: 3.9551162228103363
Validation loss: 3.1750722221110075

Epoch: 5| Step: 10
Training loss: 3.432859305339196
Validation loss: 3.1748143063723386

Epoch: 99| Step: 0
Training loss: 2.315066588661441
Validation loss: 3.1734673563309284

Epoch: 5| Step: 1
Training loss: 4.167170125426612
Validation loss: 3.172986382899576

Epoch: 5| Step: 2
Training loss: 2.586386189329665
Validation loss: 3.1751812584784656

Epoch: 5| Step: 3
Training loss: 3.414986980631238
Validation loss: 3.174780504531371

Epoch: 5| Step: 4
Training loss: 4.299079246413511
Validation loss: 3.1736918645468233

Epoch: 5| Step: 5
Training loss: 3.548764301202705
Validation loss: 3.174318446700653

Epoch: 5| Step: 6
Training loss: 3.2593507497000553
Validation loss: 3.1750013162656856

Epoch: 5| Step: 7
Training loss: 3.2461467789083853
Validation loss: 3.173283649145942

Epoch: 5| Step: 8
Training loss: 3.2720756520243843
Validation loss: 3.175927565034445

Epoch: 5| Step: 9
Training loss: 3.718043925468588
Validation loss: 3.175958878979381

Epoch: 5| Step: 10
Training loss: 3.331746168563608
Validation loss: 3.177244641777996

Epoch: 100| Step: 0
Training loss: 2.999937533681935
Validation loss: 3.1779275117930506

Epoch: 5| Step: 1
Training loss: 3.7962779136839817
Validation loss: 3.1763221225548066

Epoch: 5| Step: 2
Training loss: 3.395467367910552
Validation loss: 3.1725992212193215

Epoch: 5| Step: 3
Training loss: 2.9827241975433867
Validation loss: 3.1714836383103227

Epoch: 5| Step: 4
Training loss: 3.7707568138044305
Validation loss: 3.1704734099175496

Epoch: 5| Step: 5
Training loss: 2.8965033069488335
Validation loss: 3.1706284047939914

Epoch: 5| Step: 6
Training loss: 3.1084674680129476
Validation loss: 3.171108623459521

Epoch: 5| Step: 7
Training loss: 4.1091573099125105
Validation loss: 3.170755247400487

Epoch: 5| Step: 8
Training loss: 3.4817774374801025
Validation loss: 3.1707534411510716

Epoch: 5| Step: 9
Training loss: 3.2519271712083686
Validation loss: 3.1695691253121034

Epoch: 5| Step: 10
Training loss: 3.6488868060966286
Validation loss: 3.1712442067160995

Epoch: 101| Step: 0
Training loss: 3.915349996032368
Validation loss: 3.1697078672499766

Epoch: 5| Step: 1
Training loss: 3.0994729178473617
Validation loss: 3.1690544059710053

Epoch: 5| Step: 2
Training loss: 3.280270966292981
Validation loss: 3.168762941805917

Epoch: 5| Step: 3
Training loss: 2.790456984226177
Validation loss: 3.1688974750249663

Epoch: 5| Step: 4
Training loss: 2.72789340614745
Validation loss: 3.169128282641622

Epoch: 5| Step: 5
Training loss: 3.914160325584828
Validation loss: 3.1690054877367735

Epoch: 5| Step: 6
Training loss: 4.241579577757928
Validation loss: 3.167655043075119

Epoch: 5| Step: 7
Training loss: 3.88060134160428
Validation loss: 3.1684624632272946

Epoch: 5| Step: 8
Training loss: 3.5306622851633658
Validation loss: 3.1672100082426446

Epoch: 5| Step: 9
Training loss: 2.551887868026141
Validation loss: 3.165533001036674

Epoch: 5| Step: 10
Training loss: 3.186577757016714
Validation loss: 3.167295075149272

Epoch: 102| Step: 0
Training loss: 3.9962077045320394
Validation loss: 3.166479499987163

Epoch: 5| Step: 1
Training loss: 2.8855275340533963
Validation loss: 3.165630506758058

Epoch: 5| Step: 2
Training loss: 3.9041017041794834
Validation loss: 3.166096027644333

Epoch: 5| Step: 3
Training loss: 3.0799361579025257
Validation loss: 3.1666366584362025

Epoch: 5| Step: 4
Training loss: 3.3618759427031177
Validation loss: 3.166172752224575

Epoch: 5| Step: 5
Training loss: 2.9088421818216808
Validation loss: 3.166858841052343

Epoch: 5| Step: 6
Training loss: 3.856385096033737
Validation loss: 3.1656048883114822

Epoch: 5| Step: 7
Training loss: 3.527739949328103
Validation loss: 3.1675869414602347

Epoch: 5| Step: 8
Training loss: 3.44144393779023
Validation loss: 3.166767109593228

Epoch: 5| Step: 9
Training loss: 3.6418046472686023
Validation loss: 3.1637167108275177

Epoch: 5| Step: 10
Training loss: 2.5534401744603965
Validation loss: 3.1639400772967323

Epoch: 103| Step: 0
Training loss: 3.740021972999692
Validation loss: 3.165722233900549

Epoch: 5| Step: 1
Training loss: 3.4487367943472536
Validation loss: 3.1629242849410537

Epoch: 5| Step: 2
Training loss: 3.624147249089233
Validation loss: 3.1647421494421244

Epoch: 5| Step: 3
Training loss: 3.8756886762418015
Validation loss: 3.163925785750575

Epoch: 5| Step: 4
Training loss: 2.4702792682378925
Validation loss: 3.166644045020898

Epoch: 5| Step: 5
Training loss: 3.3136003214251604
Validation loss: 3.163332606142347

Epoch: 5| Step: 6
Training loss: 3.171877405325443
Validation loss: 3.1645736955906676

Epoch: 5| Step: 7
Training loss: 4.057497671412224
Validation loss: 3.1655001642561693

Epoch: 5| Step: 8
Training loss: 3.1364022329214736
Validation loss: 3.164807705544565

Epoch: 5| Step: 9
Training loss: 3.8498064413584863
Validation loss: 3.161884900574218

Epoch: 5| Step: 10
Training loss: 2.282142986943194
Validation loss: 3.1625557031362237

Epoch: 104| Step: 0
Training loss: 3.7941917702687613
Validation loss: 3.1653590762530337

Epoch: 5| Step: 1
Training loss: 2.331788221312457
Validation loss: 3.1629123344845995

Epoch: 5| Step: 2
Training loss: 2.995813309377531
Validation loss: 3.1625232148176674

Epoch: 5| Step: 3
Training loss: 3.873202245291946
Validation loss: 3.16192875536371

Epoch: 5| Step: 4
Training loss: 3.489022205084227
Validation loss: 3.164745391312736

Epoch: 5| Step: 5
Training loss: 3.8831875349406646
Validation loss: 3.162290034582742

Epoch: 5| Step: 6
Training loss: 3.022829926234596
Validation loss: 3.1606569943859615

Epoch: 5| Step: 7
Training loss: 3.4018816453461267
Validation loss: 3.159876730256392

Epoch: 5| Step: 8
Training loss: 3.0055512883251434
Validation loss: 3.1630324270620718

Epoch: 5| Step: 9
Training loss: 3.9420353034929017
Validation loss: 3.160365695123091

Epoch: 5| Step: 10
Training loss: 3.4585823674140683
Validation loss: 3.160070030388659

Epoch: 105| Step: 0
Training loss: 3.723318547418982
Validation loss: 3.1608999627942995

Epoch: 5| Step: 1
Training loss: 3.0635188996317417
Validation loss: 3.160261410728515

Epoch: 5| Step: 2
Training loss: 3.380354695416043
Validation loss: 3.160524741748469

Epoch: 5| Step: 3
Training loss: 2.747664673775783
Validation loss: 3.1591527183482024

Epoch: 5| Step: 4
Training loss: 3.03174956619588
Validation loss: 3.160490842237223

Epoch: 5| Step: 5
Training loss: 3.4161166857192127
Validation loss: 3.160116529887541

Epoch: 5| Step: 6
Training loss: 3.7950440061729274
Validation loss: 3.160705647636404

Epoch: 5| Step: 7
Training loss: 3.673269193842805
Validation loss: 3.1614341158494375

Epoch: 5| Step: 8
Training loss: 3.6319611895247936
Validation loss: 3.1590892489646554

Epoch: 5| Step: 9
Training loss: 3.815659886356116
Validation loss: 3.1652571820651976

Epoch: 5| Step: 10
Training loss: 2.9377405595690225
Validation loss: 3.157128199584477

Epoch: 106| Step: 0
Training loss: 3.7032473258244023
Validation loss: 3.1615906096250357

Epoch: 5| Step: 1
Training loss: 3.0775300821031792
Validation loss: 3.1611848580345643

Epoch: 5| Step: 2
Training loss: 3.670103644173032
Validation loss: 3.156724101250309

Epoch: 5| Step: 3
Training loss: 2.9248177300418714
Validation loss: 3.1573994696977548

Epoch: 5| Step: 4
Training loss: 3.23385630700869
Validation loss: 3.1533383837503375

Epoch: 5| Step: 5
Training loss: 3.1156783884691204
Validation loss: 3.154870068586158

Epoch: 5| Step: 6
Training loss: 3.605432776770703
Validation loss: 3.1550059352715114

Epoch: 5| Step: 7
Training loss: 4.2540977021598225
Validation loss: 3.152215689946677

Epoch: 5| Step: 8
Training loss: 3.2815134578477116
Validation loss: 3.153298387514855

Epoch: 5| Step: 9
Training loss: 3.2878289525911444
Validation loss: 3.154059203002616

Epoch: 5| Step: 10
Training loss: 3.0603271872932365
Validation loss: 3.154022034756184

Epoch: 107| Step: 0
Training loss: 3.4750033536387117
Validation loss: 3.153182374749373

Epoch: 5| Step: 1
Training loss: 3.830766039302841
Validation loss: 3.1524319179786167

Epoch: 5| Step: 2
Training loss: 3.41574900019012
Validation loss: 3.1516713164764583

Epoch: 5| Step: 3
Training loss: 3.3407927653881093
Validation loss: 3.1504485018550943

Epoch: 5| Step: 4
Training loss: 3.8144982526212394
Validation loss: 3.1510151740539922

Epoch: 5| Step: 5
Training loss: 3.3204311215023874
Validation loss: 3.1519831672678316

Epoch: 5| Step: 6
Training loss: 4.195719381311027
Validation loss: 3.1511127287295126

Epoch: 5| Step: 7
Training loss: 3.091122985772547
Validation loss: 3.1509063021775994

Epoch: 5| Step: 8
Training loss: 2.9068468362923916
Validation loss: 3.151171684108268

Epoch: 5| Step: 9
Training loss: 2.9649984648573504
Validation loss: 3.149759479851851

Epoch: 5| Step: 10
Training loss: 2.6957131792872384
Validation loss: 3.151608184490332

Epoch: 108| Step: 0
Training loss: 3.0028791916486135
Validation loss: 3.151324125339198

Epoch: 5| Step: 1
Training loss: 2.5525946487677924
Validation loss: 3.151546068058347

Epoch: 5| Step: 2
Training loss: 4.192579007572929
Validation loss: 3.1507710544636467

Epoch: 5| Step: 3
Training loss: 3.563097451957838
Validation loss: 3.151079606624696

Epoch: 5| Step: 4
Training loss: 3.335601003502282
Validation loss: 3.1496294361294908

Epoch: 5| Step: 5
Training loss: 3.718468919918309
Validation loss: 3.151121974088835

Epoch: 5| Step: 6
Training loss: 3.5473840827095717
Validation loss: 3.1487733912204767

Epoch: 5| Step: 7
Training loss: 3.0036535268364997
Validation loss: 3.147866918840276

Epoch: 5| Step: 8
Training loss: 3.225416372463691
Validation loss: 3.148479149024694

Epoch: 5| Step: 9
Training loss: 3.6801506123612775
Validation loss: 3.147496648704876

Epoch: 5| Step: 10
Training loss: 3.288399890110732
Validation loss: 3.149794650607383

Epoch: 109| Step: 0
Training loss: 2.6652730836926897
Validation loss: 3.150872704370919

Epoch: 5| Step: 1
Training loss: 3.583687269488732
Validation loss: 3.1503326266439142

Epoch: 5| Step: 2
Training loss: 2.9160687696618153
Validation loss: 3.1523660296928977

Epoch: 5| Step: 3
Training loss: 3.976955551777695
Validation loss: 3.1506215255353642

Epoch: 5| Step: 4
Training loss: 3.025081374910285
Validation loss: 3.1498987761076216

Epoch: 5| Step: 5
Training loss: 3.312596733552188
Validation loss: 3.150209442509591

Epoch: 5| Step: 6
Training loss: 3.7471070893018643
Validation loss: 3.1483872720904347

Epoch: 5| Step: 7
Training loss: 2.900152886405537
Validation loss: 3.145869223825851

Epoch: 5| Step: 8
Training loss: 3.7315000057330354
Validation loss: 3.145738553126522

Epoch: 5| Step: 9
Training loss: 4.141553091005261
Validation loss: 3.144438124454571

Epoch: 5| Step: 10
Training loss: 2.9653326342648203
Validation loss: 3.1456666388974894

Epoch: 110| Step: 0
Training loss: 2.866513872140654
Validation loss: 3.144830796752381

Epoch: 5| Step: 1
Training loss: 3.5703226502522565
Validation loss: 3.146537849103919

Epoch: 5| Step: 2
Training loss: 3.592254858393453
Validation loss: 3.145549682876834

Epoch: 5| Step: 3
Training loss: 4.151111150692112
Validation loss: 3.1453304892611986

Epoch: 5| Step: 4
Training loss: 3.527925124474572
Validation loss: 3.1474741472069363

Epoch: 5| Step: 5
Training loss: 3.0979896548783694
Validation loss: 3.145779250169766

Epoch: 5| Step: 6
Training loss: 3.6599165309706008
Validation loss: 3.1462931458240506

Epoch: 5| Step: 7
Training loss: 3.3593101317774163
Validation loss: 3.1492411385462935

Epoch: 5| Step: 8
Training loss: 3.4035294894020667
Validation loss: 3.1492677367128703

Epoch: 5| Step: 9
Training loss: 3.3303425882431252
Validation loss: 3.14225285817131

Epoch: 5| Step: 10
Training loss: 2.392090391932602
Validation loss: 3.145300023711052

Epoch: 111| Step: 0
Training loss: 2.8665947158418783
Validation loss: 3.1421635952153206

Epoch: 5| Step: 1
Training loss: 3.799820875664245
Validation loss: 3.141904082839076

Epoch: 5| Step: 2
Training loss: 3.1679219384738886
Validation loss: 3.1412102811997675

Epoch: 5| Step: 3
Training loss: 3.7202394211539676
Validation loss: 3.142182688471944

Epoch: 5| Step: 4
Training loss: 3.5448742571698517
Validation loss: 3.140053422137818

Epoch: 5| Step: 5
Training loss: 3.109588462364986
Validation loss: 3.1411187001177048

Epoch: 5| Step: 6
Training loss: 3.9034032595718235
Validation loss: 3.140828850414339

Epoch: 5| Step: 7
Training loss: 3.5219899521813804
Validation loss: 3.1406665248877563

Epoch: 5| Step: 8
Training loss: 3.1097966967303696
Validation loss: 3.1413002747303347

Epoch: 5| Step: 9
Training loss: 3.747586045552956
Validation loss: 3.1392293690277175

Epoch: 5| Step: 10
Training loss: 2.4372787375161145
Validation loss: 3.141341024376261

Epoch: 112| Step: 0
Training loss: 2.834999454774081
Validation loss: 3.1487445938531673

Epoch: 5| Step: 1
Training loss: 4.384671230192179
Validation loss: 3.152946750671873

Epoch: 5| Step: 2
Training loss: 3.1729062663605214
Validation loss: 3.152805244827649

Epoch: 5| Step: 3
Training loss: 2.809315807495465
Validation loss: 3.1471999590785

Epoch: 5| Step: 4
Training loss: 2.293835971478844
Validation loss: 3.154332339763885

Epoch: 5| Step: 5
Training loss: 3.134842136673359
Validation loss: 3.1574091464657936

Epoch: 5| Step: 6
Training loss: 3.714179042709669
Validation loss: 3.1603655182847983

Epoch: 5| Step: 7
Training loss: 3.5933925285016666
Validation loss: 3.1580703929368927

Epoch: 5| Step: 8
Training loss: 3.7570256858843183
Validation loss: 3.142360859955524

Epoch: 5| Step: 9
Training loss: 3.9516521620165803
Validation loss: 3.1365743428201216

Epoch: 5| Step: 10
Training loss: 3.189994135405791
Validation loss: 3.135987354382611

Epoch: 113| Step: 0
Training loss: 3.1920365606427477
Validation loss: 3.1376201417560057

Epoch: 5| Step: 1
Training loss: 2.912638216463707
Validation loss: 3.1370202179150337

Epoch: 5| Step: 2
Training loss: 4.013312360343332
Validation loss: 3.1372234151157103

Epoch: 5| Step: 3
Training loss: 3.402498892083923
Validation loss: 3.137130704327686

Epoch: 5| Step: 4
Training loss: 2.8817846435201258
Validation loss: 3.1373881144033766

Epoch: 5| Step: 5
Training loss: 2.915594685060616
Validation loss: 3.1377892721720366

Epoch: 5| Step: 6
Training loss: 3.033961233888428
Validation loss: 3.1374415564240463

Epoch: 5| Step: 7
Training loss: 3.821184117401572
Validation loss: 3.136948608873533

Epoch: 5| Step: 8
Training loss: 3.922535145433765
Validation loss: 3.1363592677278023

Epoch: 5| Step: 9
Training loss: 3.3061704802730465
Validation loss: 3.1362606737721483

Epoch: 5| Step: 10
Training loss: 3.713517554990899
Validation loss: 3.1365834642962174

Epoch: 114| Step: 0
Training loss: 3.1570095243699994
Validation loss: 3.1351495302691905

Epoch: 5| Step: 1
Training loss: 3.1386138397909273
Validation loss: 3.135635900322761

Epoch: 5| Step: 2
Training loss: 3.605707857049795
Validation loss: 3.1345953966332254

Epoch: 5| Step: 3
Training loss: 4.1695799497548265
Validation loss: 3.1347982276179738

Epoch: 5| Step: 4
Training loss: 3.1271475469988115
Validation loss: 3.1337647168149054

Epoch: 5| Step: 5
Training loss: 3.2503905428471627
Validation loss: 3.1334740085043955

Epoch: 5| Step: 6
Training loss: 3.880971184143644
Validation loss: 3.132581064233544

Epoch: 5| Step: 7
Training loss: 2.914657082123396
Validation loss: 3.1335579639320654

Epoch: 5| Step: 8
Training loss: 3.102414261634551
Validation loss: 3.1388344090410087

Epoch: 5| Step: 9
Training loss: 3.4531444704361287
Validation loss: 3.1334970997847114

Epoch: 5| Step: 10
Training loss: 3.252813588535355
Validation loss: 3.138070951311849

Epoch: 115| Step: 0
Training loss: 2.4961367321343304
Validation loss: 3.1363851078917104

Epoch: 5| Step: 1
Training loss: 3.483312607358268
Validation loss: 3.1368436228009453

Epoch: 5| Step: 2
Training loss: 4.012031342419163
Validation loss: 3.1335225193044787

Epoch: 5| Step: 3
Training loss: 3.9511169640972477
Validation loss: 3.1377122824944403

Epoch: 5| Step: 4
Training loss: 3.063240895860425
Validation loss: 3.1383250869934445

Epoch: 5| Step: 5
Training loss: 3.7454501206724555
Validation loss: 3.146818620492579

Epoch: 5| Step: 6
Training loss: 3.7463350824896815
Validation loss: 3.139111559028218

Epoch: 5| Step: 7
Training loss: 3.1789591936946566
Validation loss: 3.134441044199686

Epoch: 5| Step: 8
Training loss: 3.027866323344856
Validation loss: 3.1302870499828956

Epoch: 5| Step: 9
Training loss: 2.9711188251842535
Validation loss: 3.1314958766950785

Epoch: 5| Step: 10
Training loss: 3.2234962801952505
Validation loss: 3.132099173406712

Epoch: 116| Step: 0
Training loss: 3.62940553447688
Validation loss: 3.130444810105787

Epoch: 5| Step: 1
Training loss: 3.748940636092326
Validation loss: 3.130263030043677

Epoch: 5| Step: 2
Training loss: 2.938709578144832
Validation loss: 3.1305893821058426

Epoch: 5| Step: 3
Training loss: 3.011425196965541
Validation loss: 3.1301510219184374

Epoch: 5| Step: 4
Training loss: 3.81556978302914
Validation loss: 3.1308722486140397

Epoch: 5| Step: 5
Training loss: 3.0344873818075304
Validation loss: 3.1324560444247322

Epoch: 5| Step: 6
Training loss: 3.808445885551137
Validation loss: 3.130803807085934

Epoch: 5| Step: 7
Training loss: 3.286832293450421
Validation loss: 3.129087674656948

Epoch: 5| Step: 8
Training loss: 4.088284170542264
Validation loss: 3.1303445852145018

Epoch: 5| Step: 9
Training loss: 2.6561187711724616
Validation loss: 3.130558592940342

Epoch: 5| Step: 10
Training loss: 2.8166629076449197
Validation loss: 3.1311815523516335

Epoch: 117| Step: 0
Training loss: 3.5603465213789125
Validation loss: 3.130828816945385

Epoch: 5| Step: 1
Training loss: 3.545596392223781
Validation loss: 3.1316995551286633

Epoch: 5| Step: 2
Training loss: 3.3314842499611577
Validation loss: 3.1301794235917137

Epoch: 5| Step: 3
Training loss: 4.207964412016557
Validation loss: 3.1307819758037785

Epoch: 5| Step: 4
Training loss: 2.820400923507814
Validation loss: 3.12744368303423

Epoch: 5| Step: 5
Training loss: 2.8325001295582943
Validation loss: 3.127569091733534

Epoch: 5| Step: 6
Training loss: 3.805064470544487
Validation loss: 3.1258519526975364

Epoch: 5| Step: 7
Training loss: 3.03867837787741
Validation loss: 3.125301381006433

Epoch: 5| Step: 8
Training loss: 3.231228242133135
Validation loss: 3.1252769577188118

Epoch: 5| Step: 9
Training loss: 3.3841905143803697
Validation loss: 3.1274835279244444

Epoch: 5| Step: 10
Training loss: 3.2183530988700335
Validation loss: 3.127216330877742

Epoch: 118| Step: 0
Training loss: 2.9874635063719683
Validation loss: 3.1268720913591914

Epoch: 5| Step: 1
Training loss: 2.8462084529023954
Validation loss: 3.124813982441638

Epoch: 5| Step: 2
Training loss: 2.758884815816151
Validation loss: 3.1240043186030113

Epoch: 5| Step: 3
Training loss: 3.3543001389257148
Validation loss: 3.1233130399333393

Epoch: 5| Step: 4
Training loss: 2.783607426774919
Validation loss: 3.1241863184049694

Epoch: 5| Step: 5
Training loss: 3.4651548983477576
Validation loss: 3.1227152440021

Epoch: 5| Step: 6
Training loss: 3.384025373918352
Validation loss: 3.123220308582686

Epoch: 5| Step: 7
Training loss: 4.033405526095716
Validation loss: 3.1232980929821115

Epoch: 5| Step: 8
Training loss: 3.803069160195676
Validation loss: 3.123273764018905

Epoch: 5| Step: 9
Training loss: 3.998218855073034
Validation loss: 3.1231187469717234

Epoch: 5| Step: 10
Training loss: 3.475290815959603
Validation loss: 3.122351377581011

Epoch: 119| Step: 0
Training loss: 3.547404783233224
Validation loss: 3.121976839682224

Epoch: 5| Step: 1
Training loss: 2.841201478650389
Validation loss: 3.122580832682063

Epoch: 5| Step: 2
Training loss: 2.9822213755664992
Validation loss: 3.1221326310838604

Epoch: 5| Step: 3
Training loss: 3.488153025971305
Validation loss: 3.1201819590482325

Epoch: 5| Step: 4
Training loss: 3.5408467559188956
Validation loss: 3.121953316661368

Epoch: 5| Step: 5
Training loss: 3.374747231519414
Validation loss: 3.1220048000346643

Epoch: 5| Step: 6
Training loss: 3.3745809224224477
Validation loss: 3.12082498562086

Epoch: 5| Step: 7
Training loss: 3.2547742549122285
Validation loss: 3.12329460945393

Epoch: 5| Step: 8
Training loss: 3.6202614166119793
Validation loss: 3.122156067358047

Epoch: 5| Step: 9
Training loss: 3.76286879851645
Validation loss: 3.1184357411658743

Epoch: 5| Step: 10
Training loss: 3.2505142098564965
Validation loss: 3.1216487396986734

Epoch: 120| Step: 0
Training loss: 2.9735051671084753
Validation loss: 3.1191049639352637

Epoch: 5| Step: 1
Training loss: 2.889838694258385
Validation loss: 3.1215544116337446

Epoch: 5| Step: 2
Training loss: 3.020673725691022
Validation loss: 3.1194907537757603

Epoch: 5| Step: 3
Training loss: 3.5745217116733423
Validation loss: 3.120500523932763

Epoch: 5| Step: 4
Training loss: 3.34573177185087
Validation loss: 3.1181788737400233

Epoch: 5| Step: 5
Training loss: 3.0348093431092895
Validation loss: 3.1194057770686134

Epoch: 5| Step: 6
Training loss: 3.8628197250625766
Validation loss: 3.1247858675533102

Epoch: 5| Step: 7
Training loss: 3.948415008468786
Validation loss: 3.1194381177996813

Epoch: 5| Step: 8
Training loss: 2.8572740184105863
Validation loss: 3.119648095926714

Epoch: 5| Step: 9
Training loss: 3.8942031033394486
Validation loss: 3.1199665624873987

Epoch: 5| Step: 10
Training loss: 3.468462408017431
Validation loss: 3.118307811183433

Epoch: 121| Step: 0
Training loss: 3.926368115338708
Validation loss: 3.118398001988638

Epoch: 5| Step: 1
Training loss: 3.1788207426311
Validation loss: 3.116987662548619

Epoch: 5| Step: 2
Training loss: 2.3928525432550596
Validation loss: 3.118644432477421

Epoch: 5| Step: 3
Training loss: 3.598057296881959
Validation loss: 3.1178899707450998

Epoch: 5| Step: 4
Training loss: 3.8327604916228486
Validation loss: 3.1180531588951235

Epoch: 5| Step: 5
Training loss: 2.989528500434011
Validation loss: 3.1166616670643985

Epoch: 5| Step: 6
Training loss: 3.4004866812699954
Validation loss: 3.1167782331257823

Epoch: 5| Step: 7
Training loss: 3.3733411880321302
Validation loss: 3.1179832026642154

Epoch: 5| Step: 8
Training loss: 3.618486142462867
Validation loss: 3.1171758873930586

Epoch: 5| Step: 9
Training loss: 2.9795824485467737
Validation loss: 3.1162604705961208

Epoch: 5| Step: 10
Training loss: 3.5714133671028203
Validation loss: 3.1160471032941333

Epoch: 122| Step: 0
Training loss: 3.8664489657404366
Validation loss: 3.115591563355797

Epoch: 5| Step: 1
Training loss: 2.817028553605052
Validation loss: 3.1165765013480677

Epoch: 5| Step: 2
Training loss: 3.440441745517118
Validation loss: 3.1142055457812714

Epoch: 5| Step: 3
Training loss: 4.204484117140197
Validation loss: 3.1152207998069406

Epoch: 5| Step: 4
Training loss: 3.891554143178788
Validation loss: 3.1130481003293906

Epoch: 5| Step: 5
Training loss: 3.096587604078704
Validation loss: 3.11449658415071

Epoch: 5| Step: 6
Training loss: 2.5037029499236323
Validation loss: 3.1127008921424273

Epoch: 5| Step: 7
Training loss: 2.9307852760983235
Validation loss: 3.113689067184755

Epoch: 5| Step: 8
Training loss: 3.7877502056607955
Validation loss: 3.113383565641826

Epoch: 5| Step: 9
Training loss: 2.6979661345396013
Validation loss: 3.113739377280625

Epoch: 5| Step: 10
Training loss: 3.4145913838324025
Validation loss: 3.112019060726744

Epoch: 123| Step: 0
Training loss: 3.5934056656115136
Validation loss: 3.112614382609687

Epoch: 5| Step: 1
Training loss: 3.8233221325852993
Validation loss: 3.1117275138174367

Epoch: 5| Step: 2
Training loss: 2.822578513149036
Validation loss: 3.1120593502372293

Epoch: 5| Step: 3
Training loss: 3.667008701901895
Validation loss: 3.112992975419429

Epoch: 5| Step: 4
Training loss: 3.2469794101467584
Validation loss: 3.112178970137626

Epoch: 5| Step: 5
Training loss: 2.9553759841417135
Validation loss: 3.113812167193953

Epoch: 5| Step: 6
Training loss: 3.5546829391282553
Validation loss: 3.1128953477952255

Epoch: 5| Step: 7
Training loss: 3.6033054859121627
Validation loss: 3.1124374422238468

Epoch: 5| Step: 8
Training loss: 3.252445328038189
Validation loss: 3.112680965743388

Epoch: 5| Step: 9
Training loss: 2.809950032859002
Validation loss: 3.113508414265817

Epoch: 5| Step: 10
Training loss: 3.596167903701629
Validation loss: 3.1153475218011737

Epoch: 124| Step: 0
Training loss: 4.307675081260527
Validation loss: 3.1166304935367344

Epoch: 5| Step: 1
Training loss: 3.187452876920745
Validation loss: 3.1114745574797005

Epoch: 5| Step: 2
Training loss: 3.408868745442867
Validation loss: 3.1138857918716356

Epoch: 5| Step: 3
Training loss: 2.497043960068221
Validation loss: 3.114071720477364

Epoch: 5| Step: 4
Training loss: 3.147253983073525
Validation loss: 3.1120592925728903

Epoch: 5| Step: 5
Training loss: 2.965127119713347
Validation loss: 3.113119354940264

Epoch: 5| Step: 6
Training loss: 3.6158103216182935
Validation loss: 3.11300237352055

Epoch: 5| Step: 7
Training loss: 2.8991688425162465
Validation loss: 3.1107729175217638

Epoch: 5| Step: 8
Training loss: 3.4959191646352554
Validation loss: 3.111081565317686

Epoch: 5| Step: 9
Training loss: 3.6862493430803553
Validation loss: 3.1094147977540647

Epoch: 5| Step: 10
Training loss: 3.5285637014292295
Validation loss: 3.1079398908269633

Epoch: 125| Step: 0
Training loss: 3.900818733938293
Validation loss: 3.1084782801802375

Epoch: 5| Step: 1
Training loss: 2.3575697301784753
Validation loss: 3.1077244442954

Epoch: 5| Step: 2
Training loss: 3.29377492355964
Validation loss: 3.1074102176481557

Epoch: 5| Step: 3
Training loss: 3.545674662881867
Validation loss: 3.1082691805459275

Epoch: 5| Step: 4
Training loss: 3.848511762440714
Validation loss: 3.107314303950071

Epoch: 5| Step: 5
Training loss: 3.0679425515536938
Validation loss: 3.1061220476266196

Epoch: 5| Step: 6
Training loss: 3.593490989307525
Validation loss: 3.107131560096778

Epoch: 5| Step: 7
Training loss: 3.105103592426853
Validation loss: 3.1066564658829003

Epoch: 5| Step: 8
Training loss: 3.977392203778222
Validation loss: 3.10551843462201

Epoch: 5| Step: 9
Training loss: 3.122579629094999
Validation loss: 3.1058398126657814

Epoch: 5| Step: 10
Training loss: 2.7390967881036277
Validation loss: 3.107011551144143

Epoch: 126| Step: 0
Training loss: 2.6860138976020904
Validation loss: 3.105811051392407

Epoch: 5| Step: 1
Training loss: 2.900657934335996
Validation loss: 3.105674630644703

Epoch: 5| Step: 2
Training loss: 3.4832025445602017
Validation loss: 3.1076240418356504

Epoch: 5| Step: 3
Training loss: 3.195520520142739
Validation loss: 3.1105039223657673

Epoch: 5| Step: 4
Training loss: 3.799106020924862
Validation loss: 3.1132332390288937

Epoch: 5| Step: 5
Training loss: 3.132439113064786
Validation loss: 3.105999648977575

Epoch: 5| Step: 6
Training loss: 3.807597651190584
Validation loss: 3.1047476036108947

Epoch: 5| Step: 7
Training loss: 3.554599232678145
Validation loss: 3.1056005388929777

Epoch: 5| Step: 8
Training loss: 3.9975925591818475
Validation loss: 3.1033848049498114

Epoch: 5| Step: 9
Training loss: 2.6054026811221216
Validation loss: 3.1046538751414015

Epoch: 5| Step: 10
Training loss: 3.5365207462487
Validation loss: 3.1049100161033714

Epoch: 127| Step: 0
Training loss: 3.509999840021809
Validation loss: 3.1057609290120625

Epoch: 5| Step: 1
Training loss: 2.8071634314035103
Validation loss: 3.1073308194412124

Epoch: 5| Step: 2
Training loss: 3.864367017150067
Validation loss: 3.1070346410656935

Epoch: 5| Step: 3
Training loss: 3.311322560766382
Validation loss: 3.10669410673467

Epoch: 5| Step: 4
Training loss: 3.311754682651474
Validation loss: 3.103923912546614

Epoch: 5| Step: 5
Training loss: 3.621324714940658
Validation loss: 3.1027138398915657

Epoch: 5| Step: 6
Training loss: 3.592646288352146
Validation loss: 3.102753097616646

Epoch: 5| Step: 7
Training loss: 3.745937690228863
Validation loss: 3.103028051367984

Epoch: 5| Step: 8
Training loss: 2.7631127968074085
Validation loss: 3.1018083435227743

Epoch: 5| Step: 9
Training loss: 3.347261527970783
Validation loss: 3.1031010768415865

Epoch: 5| Step: 10
Training loss: 2.8606667857736445
Validation loss: 3.101995455537079

Epoch: 128| Step: 0
Training loss: 3.0958272722543465
Validation loss: 3.102710144039488

Epoch: 5| Step: 1
Training loss: 3.300770126414319
Validation loss: 3.102455936850204

Epoch: 5| Step: 2
Training loss: 3.0616372897988926
Validation loss: 3.100736647419905

Epoch: 5| Step: 3
Training loss: 3.8734330731636284
Validation loss: 3.10212419789672

Epoch: 5| Step: 4
Training loss: 3.8072513659945266
Validation loss: 3.1012908890183093

Epoch: 5| Step: 5
Training loss: 3.1445341311613353
Validation loss: 3.0999922933889574

Epoch: 5| Step: 6
Training loss: 3.7878404672013657
Validation loss: 3.100478332683224

Epoch: 5| Step: 7
Training loss: 3.0420475203133703
Validation loss: 3.0994329246114076

Epoch: 5| Step: 8
Training loss: 2.7372267321054866
Validation loss: 3.098633739954428

Epoch: 5| Step: 9
Training loss: 2.861882678769522
Validation loss: 3.099321961192182

Epoch: 5| Step: 10
Training loss: 4.051712032196477
Validation loss: 3.098925735303562

Epoch: 129| Step: 0
Training loss: 3.6777597873192667
Validation loss: 3.0993017899596484

Epoch: 5| Step: 1
Training loss: 3.1354342404165587
Validation loss: 3.0985301735978474

Epoch: 5| Step: 2
Training loss: 3.2027551949256203
Validation loss: 3.0984308814386705

Epoch: 5| Step: 3
Training loss: 2.818336872690401
Validation loss: 3.0978772908602847

Epoch: 5| Step: 4
Training loss: 3.5792786183610303
Validation loss: 3.0968556937628793

Epoch: 5| Step: 5
Training loss: 3.0550366760649617
Validation loss: 3.0980202902520397

Epoch: 5| Step: 6
Training loss: 3.347131178282947
Validation loss: 3.096815037575506

Epoch: 5| Step: 7
Training loss: 3.6480066996730387
Validation loss: 3.0967840980513253

Epoch: 5| Step: 8
Training loss: 3.31543371455941
Validation loss: 3.097069712735884

Epoch: 5| Step: 9
Training loss: 3.74881102468715
Validation loss: 3.0963144935885403

Epoch: 5| Step: 10
Training loss: 3.2732631300049055
Validation loss: 3.0964817421808912

Epoch: 130| Step: 0
Training loss: 4.203202597883835
Validation loss: 3.09505432251138

Epoch: 5| Step: 1
Training loss: 3.4386012307437257
Validation loss: 3.0961812446265085

Epoch: 5| Step: 2
Training loss: 2.9533623494028154
Validation loss: 3.095757183113943

Epoch: 5| Step: 3
Training loss: 3.5172839510355023
Validation loss: 3.0961627735289308

Epoch: 5| Step: 4
Training loss: 3.2597072589236284
Validation loss: 3.0952093304367247

Epoch: 5| Step: 5
Training loss: 2.9476930423384635
Validation loss: 3.095897462489493

Epoch: 5| Step: 6
Training loss: 3.4856436434160503
Validation loss: 3.0951896757449284

Epoch: 5| Step: 7
Training loss: 2.8622543762637376
Validation loss: 3.0939860970111006

Epoch: 5| Step: 8
Training loss: 3.4775749875285618
Validation loss: 3.0954409796951072

Epoch: 5| Step: 9
Training loss: 3.5174104352988325
Validation loss: 3.094638036989884

Epoch: 5| Step: 10
Training loss: 2.9657383148444216
Validation loss: 3.094635484646133

Epoch: 131| Step: 0
Training loss: 3.6148658370874016
Validation loss: 3.0949142252582518

Epoch: 5| Step: 1
Training loss: 3.0410280123282547
Validation loss: 3.093356302501039

Epoch: 5| Step: 2
Training loss: 3.0220032279138094
Validation loss: 3.0942372600980015

Epoch: 5| Step: 3
Training loss: 3.8458996476021405
Validation loss: 3.0932686660100277

Epoch: 5| Step: 4
Training loss: 2.922038517420679
Validation loss: 3.0938960024664866

Epoch: 5| Step: 5
Training loss: 3.603243024072529
Validation loss: 3.092301995332542

Epoch: 5| Step: 6
Training loss: 3.0406733070919385
Validation loss: 3.093246423948792

Epoch: 5| Step: 7
Training loss: 2.8942966546295836
Validation loss: 3.0929298469735067

Epoch: 5| Step: 8
Training loss: 3.98639965600631
Validation loss: 3.0923928816021036

Epoch: 5| Step: 9
Training loss: 2.965521412076365
Validation loss: 3.0917093311237616

Epoch: 5| Step: 10
Training loss: 3.7488757673525233
Validation loss: 3.0935629179766586

Epoch: 132| Step: 0
Training loss: 3.2758081269020236
Validation loss: 3.0919368680771924

Epoch: 5| Step: 1
Training loss: 3.226894260003972
Validation loss: 3.093196765982946

Epoch: 5| Step: 2
Training loss: 3.1549126841799926
Validation loss: 3.0935229651843383

Epoch: 5| Step: 3
Training loss: 2.950626507196928
Validation loss: 3.0954259685546943

Epoch: 5| Step: 4
Training loss: 3.4259335213272473
Validation loss: 3.0928637064847426

Epoch: 5| Step: 5
Training loss: 3.9379744470948106
Validation loss: 3.0910423680245342

Epoch: 5| Step: 6
Training loss: 3.323331003854663
Validation loss: 3.0899068529517857

Epoch: 5| Step: 7
Training loss: 3.883360304077094
Validation loss: 3.0910193394462855

Epoch: 5| Step: 8
Training loss: 3.1410971519118958
Validation loss: 3.090281773536541

Epoch: 5| Step: 9
Training loss: 2.9904595308357553
Validation loss: 3.0884653919773704

Epoch: 5| Step: 10
Training loss: 3.4284711692546934
Validation loss: 3.08910680301089

Epoch: 133| Step: 0
Training loss: 3.411206340461478
Validation loss: 3.0894763539818344

Epoch: 5| Step: 1
Training loss: 3.6419303420316727
Validation loss: 3.090675141861698

Epoch: 5| Step: 2
Training loss: 3.2551374178473362
Validation loss: 3.088180673347787

Epoch: 5| Step: 3
Training loss: 2.9277405640153065
Validation loss: 3.089434872112075

Epoch: 5| Step: 4
Training loss: 3.26084645194003
Validation loss: 3.088940936992467

Epoch: 5| Step: 5
Training loss: 2.9324690571459002
Validation loss: 3.0891342193683053

Epoch: 5| Step: 6
Training loss: 2.886428508698533
Validation loss: 3.0884004516446657

Epoch: 5| Step: 7
Training loss: 3.4295210743629365
Validation loss: 3.0881617990921093

Epoch: 5| Step: 8
Training loss: 3.766125784217302
Validation loss: 3.086615743957443

Epoch: 5| Step: 9
Training loss: 3.7516652542398563
Validation loss: 3.0873487301545333

Epoch: 5| Step: 10
Training loss: 3.4438496985430107
Validation loss: 3.088308909969171

Epoch: 134| Step: 0
Training loss: 3.3079027627586353
Validation loss: 3.086969046864358

Epoch: 5| Step: 1
Training loss: 3.3653558054937966
Validation loss: 3.08736662622902

Epoch: 5| Step: 2
Training loss: 3.74512800988495
Validation loss: 3.0868310094049574

Epoch: 5| Step: 3
Training loss: 3.135108163722934
Validation loss: 3.0863547522157893

Epoch: 5| Step: 4
Training loss: 3.103927671376339
Validation loss: 3.085942613258139

Epoch: 5| Step: 5
Training loss: 3.505031511325646
Validation loss: 3.085694382419774

Epoch: 5| Step: 6
Training loss: 3.637083500354344
Validation loss: 3.086004319771442

Epoch: 5| Step: 7
Training loss: 3.1909850273295097
Validation loss: 3.0858171569611663

Epoch: 5| Step: 8
Training loss: 3.4780986006866788
Validation loss: 3.0864105572314737

Epoch: 5| Step: 9
Training loss: 3.358754513236713
Validation loss: 3.0840972352087577

Epoch: 5| Step: 10
Training loss: 2.846267256787055
Validation loss: 3.084878281411411

Epoch: 135| Step: 0
Training loss: 3.110572929230093
Validation loss: 3.085125546682548

Epoch: 5| Step: 1
Training loss: 2.9873516157641196
Validation loss: 3.084890681253983

Epoch: 5| Step: 2
Training loss: 3.0628339624290266
Validation loss: 3.084944382027559

Epoch: 5| Step: 3
Training loss: 3.0796535975865744
Validation loss: 3.0847277432971474

Epoch: 5| Step: 4
Training loss: 4.222343214431885
Validation loss: 3.0845414613148434

Epoch: 5| Step: 5
Training loss: 3.0813835440087765
Validation loss: 3.083402392327123

Epoch: 5| Step: 6
Training loss: 3.3982009279188876
Validation loss: 3.0829711281157794

Epoch: 5| Step: 7
Training loss: 3.664921576479252
Validation loss: 3.081834081597661

Epoch: 5| Step: 8
Training loss: 3.0683466317964214
Validation loss: 3.082760557825827

Epoch: 5| Step: 9
Training loss: 3.550434897204785
Validation loss: 3.080992752882031

Epoch: 5| Step: 10
Training loss: 3.382850558659321
Validation loss: 3.08304402746538

Epoch: 136| Step: 0
Training loss: 3.4264506922343823
Validation loss: 3.0828400682655412

Epoch: 5| Step: 1
Training loss: 2.9391087124328243
Validation loss: 3.0805847557410955

Epoch: 5| Step: 2
Training loss: 3.1614213634426283
Validation loss: 3.0814603919459693

Epoch: 5| Step: 3
Training loss: 3.7968501337438054
Validation loss: 3.0852168986291866

Epoch: 5| Step: 4
Training loss: 2.474714293510096
Validation loss: 3.0855592083795766

Epoch: 5| Step: 5
Training loss: 3.3747297108113288
Validation loss: 3.0840572803242052

Epoch: 5| Step: 6
Training loss: 3.288794717285323
Validation loss: 3.0902444736673575

Epoch: 5| Step: 7
Training loss: 2.476932052813842
Validation loss: 3.0872220197911107

Epoch: 5| Step: 8
Training loss: 3.2916927739005386
Validation loss: 3.084909243112694

Epoch: 5| Step: 9
Training loss: 3.9843800264214617
Validation loss: 3.085025876276535

Epoch: 5| Step: 10
Training loss: 4.27289361648381
Validation loss: 3.0842487741127917

Epoch: 137| Step: 0
Training loss: 3.2266236823610592
Validation loss: 3.0811109795742233

Epoch: 5| Step: 1
Training loss: 2.5445188143141966
Validation loss: 3.0792373555419923

Epoch: 5| Step: 2
Training loss: 4.102353206893142
Validation loss: 3.0798474711331196

Epoch: 5| Step: 3
Training loss: 3.533844796236003
Validation loss: 3.0790834518680614

Epoch: 5| Step: 4
Training loss: 3.5834726410038686
Validation loss: 3.0801763450023025

Epoch: 5| Step: 5
Training loss: 3.1483190623078245
Validation loss: 3.080158418803768

Epoch: 5| Step: 6
Training loss: 3.875604766906081
Validation loss: 3.083046581089999

Epoch: 5| Step: 7
Training loss: 2.932054219815352
Validation loss: 3.0840392802576444

Epoch: 5| Step: 8
Training loss: 2.6755899402697905
Validation loss: 3.0812957159234156

Epoch: 5| Step: 9
Training loss: 3.3185108278232094
Validation loss: 3.0816720684890666

Epoch: 5| Step: 10
Training loss: 3.585460755813949
Validation loss: 3.079497653478891

Epoch: 138| Step: 0
Training loss: 3.4951680753402874
Validation loss: 3.07826027813144

Epoch: 5| Step: 1
Training loss: 3.6032147041528946
Validation loss: 3.0778731418044933

Epoch: 5| Step: 2
Training loss: 3.560772125434659
Validation loss: 3.0773326936175422

Epoch: 5| Step: 3
Training loss: 3.42208764099224
Validation loss: 3.077274226381724

Epoch: 5| Step: 4
Training loss: 2.7114914210016914
Validation loss: 3.0753213488268267

Epoch: 5| Step: 5
Training loss: 2.086828834317811
Validation loss: 3.0766348047968326

Epoch: 5| Step: 6
Training loss: 3.6677682840087735
Validation loss: 3.0767353261282024

Epoch: 5| Step: 7
Training loss: 3.3214235847775577
Validation loss: 3.07602554882182

Epoch: 5| Step: 8
Training loss: 3.2818201932033966
Validation loss: 3.075699878583856

Epoch: 5| Step: 9
Training loss: 3.9241980249676693
Validation loss: 3.0772145300395426

Epoch: 5| Step: 10
Training loss: 3.2630898888727797
Validation loss: 3.0756417153878077

Epoch: 139| Step: 0
Training loss: 3.377938580728753
Validation loss: 3.0798581606936306

Epoch: 5| Step: 1
Training loss: 2.9733032645286026
Validation loss: 3.0787451284789027

Epoch: 5| Step: 2
Training loss: 3.3940977252115374
Validation loss: 3.084153845803738

Epoch: 5| Step: 3
Training loss: 4.120096934020793
Validation loss: 3.079688525093974

Epoch: 5| Step: 4
Training loss: 3.5122809888227624
Validation loss: 3.0814094350282697

Epoch: 5| Step: 5
Training loss: 3.478092705507291
Validation loss: 3.0853969870611606

Epoch: 5| Step: 6
Training loss: 3.118440686866576
Validation loss: 3.0763117232716164

Epoch: 5| Step: 7
Training loss: 3.274585604476157
Validation loss: 3.0755391077604197

Epoch: 5| Step: 8
Training loss: 2.8955353142138285
Validation loss: 3.0727475216578903

Epoch: 5| Step: 9
Training loss: 2.9225498990774574
Validation loss: 3.072869718070284

Epoch: 5| Step: 10
Training loss: 3.514840271577727
Validation loss: 3.0714901947011715

Epoch: 140| Step: 0
Training loss: 3.1539966357690337
Validation loss: 3.0732845519307865

Epoch: 5| Step: 1
Training loss: 3.5127536831402693
Validation loss: 3.072528884861258

Epoch: 5| Step: 2
Training loss: 2.675183573333145
Validation loss: 3.0743931185877793

Epoch: 5| Step: 3
Training loss: 3.5809028870028046
Validation loss: 3.0715045132077607

Epoch: 5| Step: 4
Training loss: 3.725987164051922
Validation loss: 3.071813626437226

Epoch: 5| Step: 5
Training loss: 3.26266549812403
Validation loss: 3.072070605375873

Epoch: 5| Step: 6
Training loss: 3.458288138833473
Validation loss: 3.0711022400126744

Epoch: 5| Step: 7
Training loss: 3.4702207179601507
Validation loss: 3.0705963674026666

Epoch: 5| Step: 8
Training loss: 3.1053314754447223
Validation loss: 3.070720552078796

Epoch: 5| Step: 9
Training loss: 2.951103043021749
Validation loss: 3.0712482114421698

Epoch: 5| Step: 10
Training loss: 3.6959728594522465
Validation loss: 3.0709684680963023

Epoch: 141| Step: 0
Training loss: 3.7461290089337163
Validation loss: 3.0711871859278728

Epoch: 5| Step: 1
Training loss: 3.8087786663843297
Validation loss: 3.0688936262105635

Epoch: 5| Step: 2
Training loss: 3.4632488997015765
Validation loss: 3.068722345254172

Epoch: 5| Step: 3
Training loss: 3.036545051570901
Validation loss: 3.069940478462798

Epoch: 5| Step: 4
Training loss: 3.1416477037527026
Validation loss: 3.070002372171337

Epoch: 5| Step: 5
Training loss: 2.4185561543543157
Validation loss: 3.0693938785789703

Epoch: 5| Step: 6
Training loss: 3.1040012563034347
Validation loss: 3.0688443026325816

Epoch: 5| Step: 7
Training loss: 3.4015624663563675
Validation loss: 3.068493979166555

Epoch: 5| Step: 8
Training loss: 3.0126726789567146
Validation loss: 3.0687079068331116

Epoch: 5| Step: 9
Training loss: 3.7229868370805055
Validation loss: 3.068862246468902

Epoch: 5| Step: 10
Training loss: 3.5960239016594637
Validation loss: 3.0673357881175938

Epoch: 142| Step: 0
Training loss: 3.269145327526042
Validation loss: 3.066750223025531

Epoch: 5| Step: 1
Training loss: 4.065647021387204
Validation loss: 3.0667570493611

Epoch: 5| Step: 2
Training loss: 3.2675858592724514
Validation loss: 3.070652904634381

Epoch: 5| Step: 3
Training loss: 2.8119992976072474
Validation loss: 3.068608229499128

Epoch: 5| Step: 4
Training loss: 3.328470847915722
Validation loss: 3.0736343810946205

Epoch: 5| Step: 5
Training loss: 3.506223730849052
Validation loss: 3.068326044710035

Epoch: 5| Step: 6
Training loss: 2.9765219698171554
Validation loss: 3.068765089532885

Epoch: 5| Step: 7
Training loss: 3.590219239364992
Validation loss: 3.0689325939832157

Epoch: 5| Step: 8
Training loss: 3.4631227780155807
Validation loss: 3.066399891067327

Epoch: 5| Step: 9
Training loss: 3.0799929764902862
Validation loss: 3.0675926967371536

Epoch: 5| Step: 10
Training loss: 3.0755089811548366
Validation loss: 3.067831316535295

Epoch: 143| Step: 0
Training loss: 3.2908327680097686
Validation loss: 3.0670675638522056

Epoch: 5| Step: 1
Training loss: 3.103440338431545
Validation loss: 3.0659967198523144

Epoch: 5| Step: 2
Training loss: 3.822457364769548
Validation loss: 3.0649114176259578

Epoch: 5| Step: 3
Training loss: 3.6208090397612787
Validation loss: 3.067047256554066

Epoch: 5| Step: 4
Training loss: 3.402065261322505
Validation loss: 3.0653253329954904

Epoch: 5| Step: 5
Training loss: 3.2060588519429243
Validation loss: 3.0643493362463134

Epoch: 5| Step: 6
Training loss: 3.139210548536366
Validation loss: 3.0653657461369095

Epoch: 5| Step: 7
Training loss: 3.3836093871398942
Validation loss: 3.0650600275054876

Epoch: 5| Step: 8
Training loss: 2.8770124606703633
Validation loss: 3.0649685682750616

Epoch: 5| Step: 9
Training loss: 3.115419885738217
Validation loss: 3.071658787439298

Epoch: 5| Step: 10
Training loss: 3.6109278917700625
Validation loss: 3.0678570361373816

Epoch: 144| Step: 0
Training loss: 3.5797896198707235
Validation loss: 3.0660931467798638

Epoch: 5| Step: 1
Training loss: 2.384450180848304
Validation loss: 3.0635666210921415

Epoch: 5| Step: 2
Training loss: 3.1973555545824794
Validation loss: 3.063290724759675

Epoch: 5| Step: 3
Training loss: 3.92825515762075
Validation loss: 3.063131302906211

Epoch: 5| Step: 4
Training loss: 2.43690258432192
Validation loss: 3.0635567424669183

Epoch: 5| Step: 5
Training loss: 3.6825880536586246
Validation loss: 3.06237590639669

Epoch: 5| Step: 6
Training loss: 3.6585640390653125
Validation loss: 3.0642961446325665

Epoch: 5| Step: 7
Training loss: 3.0114147463300474
Validation loss: 3.0657012678755358

Epoch: 5| Step: 8
Training loss: 4.037406773863838
Validation loss: 3.0671947783465705

Epoch: 5| Step: 9
Training loss: 2.267535541933013
Validation loss: 3.065269491196611

Epoch: 5| Step: 10
Training loss: 3.902830778933319
Validation loss: 3.0646819829181724

Epoch: 145| Step: 0
Training loss: 3.691391136501799
Validation loss: 3.0662135850407437

Epoch: 5| Step: 1
Training loss: 3.433974938178437
Validation loss: 3.0643374832469377

Epoch: 5| Step: 2
Training loss: 3.3248719269602667
Validation loss: 3.0632343797136716

Epoch: 5| Step: 3
Training loss: 3.1084002783335736
Validation loss: 3.063241023069933

Epoch: 5| Step: 4
Training loss: 3.4367233786234177
Validation loss: 3.0644397163687285

Epoch: 5| Step: 5
Training loss: 3.4906616973997004
Validation loss: 3.0617975756667803

Epoch: 5| Step: 6
Training loss: 3.9506745112617296
Validation loss: 3.0633621492317893

Epoch: 5| Step: 7
Training loss: 3.0412846852310773
Validation loss: 3.06184329269864

Epoch: 5| Step: 8
Training loss: 2.529692841984255
Validation loss: 3.0609976905307272

Epoch: 5| Step: 9
Training loss: 3.029126396768563
Validation loss: 3.0620417742854253

Epoch: 5| Step: 10
Training loss: 3.3944964127239983
Validation loss: 3.060313390318645

Epoch: 146| Step: 0
Training loss: 2.7788148141595945
Validation loss: 3.060398258737534

Epoch: 5| Step: 1
Training loss: 3.4492969957680724
Validation loss: 3.0602862418460415

Epoch: 5| Step: 2
Training loss: 3.253199689522558
Validation loss: 3.0583180295535555

Epoch: 5| Step: 3
Training loss: 3.563485795539902
Validation loss: 3.0601555826831572

Epoch: 5| Step: 4
Training loss: 3.907699194069703
Validation loss: 3.059867578016886

Epoch: 5| Step: 5
Training loss: 3.5936542000648246
Validation loss: 3.061643288518461

Epoch: 5| Step: 6
Training loss: 2.684582657159458
Validation loss: 3.0591301516886866

Epoch: 5| Step: 7
Training loss: 2.982186038942208
Validation loss: 3.058496704414361

Epoch: 5| Step: 8
Training loss: 3.002954935107278
Validation loss: 3.056645239588975

Epoch: 5| Step: 9
Training loss: 3.663297203193563
Validation loss: 3.057456324442664

Epoch: 5| Step: 10
Training loss: 3.4769862913224068
Validation loss: 3.055421252078701

Epoch: 147| Step: 0
Training loss: 2.9417123014748463
Validation loss: 3.055266026203545

Epoch: 5| Step: 1
Training loss: 2.2798770274076885
Validation loss: 3.0567697469903994

Epoch: 5| Step: 2
Training loss: 3.611434547089984
Validation loss: 3.0564779063813647

Epoch: 5| Step: 3
Training loss: 3.441083254254032
Validation loss: 3.054319215739333

Epoch: 5| Step: 4
Training loss: 3.3168332529324998
Validation loss: 3.0575784192828155

Epoch: 5| Step: 5
Training loss: 2.9492245705654483
Validation loss: 3.054680391560447

Epoch: 5| Step: 6
Training loss: 3.367659745877167
Validation loss: 3.0535577907438127

Epoch: 5| Step: 7
Training loss: 3.9712083066409254
Validation loss: 3.052200763384607

Epoch: 5| Step: 8
Training loss: 3.1602289783233384
Validation loss: 3.05404587109349

Epoch: 5| Step: 9
Training loss: 3.526991986111221
Validation loss: 3.0575924700724166

Epoch: 5| Step: 10
Training loss: 3.7325294435212335
Validation loss: 3.055274527843192

Epoch: 148| Step: 0
Training loss: 3.225975001607814
Validation loss: 3.0577075067022106

Epoch: 5| Step: 1
Training loss: 2.972859960887142
Validation loss: 3.055294476228499

Epoch: 5| Step: 2
Training loss: 2.786310371439699
Validation loss: 3.054543901277371

Epoch: 5| Step: 3
Training loss: 3.999823924003989
Validation loss: 3.054199723638386

Epoch: 5| Step: 4
Training loss: 3.4673024499309077
Validation loss: 3.052925787079946

Epoch: 5| Step: 5
Training loss: 3.0451956008700973
Validation loss: 3.054737322395525

Epoch: 5| Step: 6
Training loss: 4.160971347672601
Validation loss: 3.0561370343559173

Epoch: 5| Step: 7
Training loss: 2.694891678397237
Validation loss: 3.0529876621333014

Epoch: 5| Step: 8
Training loss: 2.9074320696490954
Validation loss: 3.0528099731921112

Epoch: 5| Step: 9
Training loss: 3.5007399730466586
Validation loss: 3.0524579052481995

Epoch: 5| Step: 10
Training loss: 3.439825762394771
Validation loss: 3.0506421061997275

Epoch: 149| Step: 0
Training loss: 3.826333261136667
Validation loss: 3.051619954883578

Epoch: 5| Step: 1
Training loss: 3.0903326098736423
Validation loss: 3.0523571286519733

Epoch: 5| Step: 2
Training loss: 3.6946029788415222
Validation loss: 3.0531467059579467

Epoch: 5| Step: 3
Training loss: 3.067032398999272
Validation loss: 3.0513339574607983

Epoch: 5| Step: 4
Training loss: 3.2322551764984424
Validation loss: 3.054658330954281

Epoch: 5| Step: 5
Training loss: 3.1218477753911773
Validation loss: 3.051683811266761

Epoch: 5| Step: 6
Training loss: 3.117559501612399
Validation loss: 3.050731405013508

Epoch: 5| Step: 7
Training loss: 3.2631185303371657
Validation loss: 3.050360641191462

Epoch: 5| Step: 8
Training loss: 3.6504164889232213
Validation loss: 3.051208260330905

Epoch: 5| Step: 9
Training loss: 2.5876413131678033
Validation loss: 3.0498839340975055

Epoch: 5| Step: 10
Training loss: 3.721310671567055
Validation loss: 3.049726429085928

Epoch: 150| Step: 0
Training loss: 3.1125689640601175
Validation loss: 3.051273352003418

Epoch: 5| Step: 1
Training loss: 3.5113958394885003
Validation loss: 3.048976235702367

Epoch: 5| Step: 2
Training loss: 3.3101761061734822
Validation loss: 3.0502939281317234

Epoch: 5| Step: 3
Training loss: 3.649541716350134
Validation loss: 3.050050774253694

Epoch: 5| Step: 4
Training loss: 3.2215239784097895
Validation loss: 3.0487873126978284

Epoch: 5| Step: 5
Training loss: 3.417194387728112
Validation loss: 3.0513760396282983

Epoch: 5| Step: 6
Training loss: 3.2853160551667515
Validation loss: 3.050392760902373

Epoch: 5| Step: 7
Training loss: 2.3149436205596086
Validation loss: 3.0507176705245276

Epoch: 5| Step: 8
Training loss: 4.105225299037724
Validation loss: 3.051309819268188

Epoch: 5| Step: 9
Training loss: 2.800980947868926
Validation loss: 3.0491558615449543

Epoch: 5| Step: 10
Training loss: 3.475816282274568
Validation loss: 3.049273977438753

Epoch: 151| Step: 0
Training loss: 2.564925092975322
Validation loss: 3.0499609612693717

Epoch: 5| Step: 1
Training loss: 3.808057103618451
Validation loss: 3.0517902585640773

Epoch: 5| Step: 2
Training loss: 3.731904429644075
Validation loss: 3.0513093739742922

Epoch: 5| Step: 3
Training loss: 3.267887627536114
Validation loss: 3.0510914947987575

Epoch: 5| Step: 4
Training loss: 3.213570733250628
Validation loss: 3.0558341894578085

Epoch: 5| Step: 5
Training loss: 2.9833001403098636
Validation loss: 3.052352311045884

Epoch: 5| Step: 6
Training loss: 3.469235085600657
Validation loss: 3.048974119357332

Epoch: 5| Step: 7
Training loss: 3.514413853877788
Validation loss: 3.0494019737564177

Epoch: 5| Step: 8
Training loss: 2.778988894181986
Validation loss: 3.0476846044753474

Epoch: 5| Step: 9
Training loss: 3.620237444682847
Validation loss: 3.054601725962943

Epoch: 5| Step: 10
Training loss: 3.2827329645049654
Validation loss: 3.0500494832086784

Epoch: 152| Step: 0
Training loss: 2.661388229571589
Validation loss: 3.050966154038114

Epoch: 5| Step: 1
Training loss: 3.1787944917494064
Validation loss: 3.04670000901616

Epoch: 5| Step: 2
Training loss: 3.384521898232342
Validation loss: 3.05183014363207

Epoch: 5| Step: 3
Training loss: 3.2994607484820797
Validation loss: 3.046029679606332

Epoch: 5| Step: 4
Training loss: 2.9969573485961054
Validation loss: 3.049436312907737

Epoch: 5| Step: 5
Training loss: 3.036438267392336
Validation loss: 3.0511725514066765

Epoch: 5| Step: 6
Training loss: 3.9196233478908473
Validation loss: 3.048880856618389

Epoch: 5| Step: 7
Training loss: 3.514445602953354
Validation loss: 3.0461487465376975

Epoch: 5| Step: 8
Training loss: 3.436939263125417
Validation loss: 3.044641022954627

Epoch: 5| Step: 9
Training loss: 3.4375464696344102
Validation loss: 3.0442537781146863

Epoch: 5| Step: 10
Training loss: 3.41426808591534
Validation loss: 3.042394998971649

Epoch: 153| Step: 0
Training loss: 3.480972613201992
Validation loss: 3.043825549591919

Epoch: 5| Step: 1
Training loss: 2.587829911581446
Validation loss: 3.043106720681612

Epoch: 5| Step: 2
Training loss: 3.01209538698566
Validation loss: 3.0437542293071367

Epoch: 5| Step: 3
Training loss: 3.274793248530001
Validation loss: 3.044257137347391

Epoch: 5| Step: 4
Training loss: 3.5371084313309757
Validation loss: 3.042292396676043

Epoch: 5| Step: 5
Training loss: 3.7503726774043917
Validation loss: 3.042539314327916

Epoch: 5| Step: 6
Training loss: 3.816112370338022
Validation loss: 3.0426605568551666

Epoch: 5| Step: 7
Training loss: 3.3283813091316703
Validation loss: 3.042999237517354

Epoch: 5| Step: 8
Training loss: 2.710927210191882
Validation loss: 3.044422232035332

Epoch: 5| Step: 9
Training loss: 3.211654397426015
Validation loss: 3.0442225772427434

Epoch: 5| Step: 10
Training loss: 3.4975899164122533
Validation loss: 3.045273162498999

Epoch: 154| Step: 0
Training loss: 3.150728286839059
Validation loss: 3.048867810017004

Epoch: 5| Step: 1
Training loss: 3.6733917350303464
Validation loss: 3.0544306390025984

Epoch: 5| Step: 2
Training loss: 2.8998200854035687
Validation loss: 3.0601678372431347

Epoch: 5| Step: 3
Training loss: 4.073213506289876
Validation loss: 3.0682075442923327

Epoch: 5| Step: 4
Training loss: 2.7139342177254164
Validation loss: 3.050915328938377

Epoch: 5| Step: 5
Training loss: 3.3367784498800614
Validation loss: 3.042517440378804

Epoch: 5| Step: 6
Training loss: 2.5084602256269175
Validation loss: 3.039870242559271

Epoch: 5| Step: 7
Training loss: 3.9214029825980283
Validation loss: 3.041532342135886

Epoch: 5| Step: 8
Training loss: 3.383505664313913
Validation loss: 3.0409466313624978

Epoch: 5| Step: 9
Training loss: 3.241838919043691
Validation loss: 3.041892970543435

Epoch: 5| Step: 10
Training loss: 3.1881207628339747
Validation loss: 3.0418081639768784

Epoch: 155| Step: 0
Training loss: 3.70812457636476
Validation loss: 3.0483794859260365

Epoch: 5| Step: 1
Training loss: 2.386337024986217
Validation loss: 3.046490652844346

Epoch: 5| Step: 2
Training loss: 2.4517808864324895
Validation loss: 3.059312589412849

Epoch: 5| Step: 3
Training loss: 2.807630179997112
Validation loss: 3.068187927188083

Epoch: 5| Step: 4
Training loss: 3.0421621014945965
Validation loss: 3.0623873400480464

Epoch: 5| Step: 5
Training loss: 3.793032361802449
Validation loss: 3.0441525176986373

Epoch: 5| Step: 6
Training loss: 3.047867207485479
Validation loss: 3.0390451394241733

Epoch: 5| Step: 7
Training loss: 3.1748392319713994
Validation loss: 3.038752184574188

Epoch: 5| Step: 8
Training loss: 3.881544186166768
Validation loss: 3.0376205399824903

Epoch: 5| Step: 9
Training loss: 3.6655954761405614
Validation loss: 3.036547982848336

Epoch: 5| Step: 10
Training loss: 4.128142344852022
Validation loss: 3.0385522061534784

Epoch: 156| Step: 0
Training loss: 2.981063043582274
Validation loss: 3.040933162920444

Epoch: 5| Step: 1
Training loss: 3.4381940661165853
Validation loss: 3.040573015091017

Epoch: 5| Step: 2
Training loss: 3.485263044152977
Validation loss: 3.0512396468698926

Epoch: 5| Step: 3
Training loss: 3.3267975788184243
Validation loss: 3.0387961282523124

Epoch: 5| Step: 4
Training loss: 3.555542962396361
Validation loss: 3.037687149065524

Epoch: 5| Step: 5
Training loss: 3.3106747762903614
Validation loss: 3.038639803370155

Epoch: 5| Step: 6
Training loss: 3.556579756909824
Validation loss: 3.0352947472581957

Epoch: 5| Step: 7
Training loss: 3.3317623410045374
Validation loss: 3.035046412435801

Epoch: 5| Step: 8
Training loss: 3.2714094557652835
Validation loss: 3.0340196282970666

Epoch: 5| Step: 9
Training loss: 2.7414122787152735
Validation loss: 3.034561608087994

Epoch: 5| Step: 10
Training loss: 3.326856201164628
Validation loss: 3.0337418468304995

Epoch: 157| Step: 0
Training loss: 3.8011244866856506
Validation loss: 3.0343268090958886

Epoch: 5| Step: 1
Training loss: 3.0066175589036614
Validation loss: 3.0340674225253603

Epoch: 5| Step: 2
Training loss: 3.022805633363602
Validation loss: 3.034708156152455

Epoch: 5| Step: 3
Training loss: 3.452716924107741
Validation loss: 3.033972842219899

Epoch: 5| Step: 4
Training loss: 3.193021591940255
Validation loss: 3.035815914793691

Epoch: 5| Step: 5
Training loss: 3.5878188573048155
Validation loss: 3.0338755465004206

Epoch: 5| Step: 6
Training loss: 3.555522979812273
Validation loss: 3.0326514928940016

Epoch: 5| Step: 7
Training loss: 2.8585762617645396
Validation loss: 3.0320174346582958

Epoch: 5| Step: 8
Training loss: 3.1358100078308957
Validation loss: 3.0323019372809363

Epoch: 5| Step: 9
Training loss: 3.2154255707848884
Validation loss: 3.0341615672807305

Epoch: 5| Step: 10
Training loss: 3.4435551804615807
Validation loss: 3.0328462265266225

Epoch: 158| Step: 0
Training loss: 2.7310011621596364
Validation loss: 3.0323150500847094

Epoch: 5| Step: 1
Training loss: 2.802868691658502
Validation loss: 3.0336877061678673

Epoch: 5| Step: 2
Training loss: 3.757931015461536
Validation loss: 3.034066337607095

Epoch: 5| Step: 3
Training loss: 3.8247218361232838
Validation loss: 3.0347583656871033

Epoch: 5| Step: 4
Training loss: 3.460941908857237
Validation loss: 3.034855737428348

Epoch: 5| Step: 5
Training loss: 4.060946123349588
Validation loss: 3.0329630148916853

Epoch: 5| Step: 6
Training loss: 3.3480922277091745
Validation loss: 3.0342006583544774

Epoch: 5| Step: 7
Training loss: 2.586952955127135
Validation loss: 3.0324660478389864

Epoch: 5| Step: 8
Training loss: 3.3981852119896807
Validation loss: 3.0291559521616978

Epoch: 5| Step: 9
Training loss: 2.8888001326432855
Validation loss: 3.0315597590727745

Epoch: 5| Step: 10
Training loss: 3.074337715842592
Validation loss: 3.030764952945113

Epoch: 159| Step: 0
Training loss: 3.6717635766837606
Validation loss: 3.03162879129048

Epoch: 5| Step: 1
Training loss: 2.6966618353097433
Validation loss: 3.0338535002344567

Epoch: 5| Step: 2
Training loss: 3.163377626495531
Validation loss: 3.0285930552588156

Epoch: 5| Step: 3
Training loss: 3.4881612280758696
Validation loss: 3.0300822028236616

Epoch: 5| Step: 4
Training loss: 3.317174959451022
Validation loss: 3.03108768516973

Epoch: 5| Step: 5
Training loss: 3.1364460181673666
Validation loss: 3.0304372357736096

Epoch: 5| Step: 6
Training loss: 3.2731732464378185
Validation loss: 3.031614382542047

Epoch: 5| Step: 7
Training loss: 3.480488204473547
Validation loss: 3.033443601479831

Epoch: 5| Step: 8
Training loss: 3.614819932096133
Validation loss: 3.03239232993093

Epoch: 5| Step: 9
Training loss: 2.8645889189694596
Validation loss: 3.03012994155604

Epoch: 5| Step: 10
Training loss: 3.4993342720137552
Validation loss: 3.033351506752692

Epoch: 160| Step: 0
Training loss: 2.69686199375168
Validation loss: 3.03034064714701

Epoch: 5| Step: 1
Training loss: 3.4623941839141086
Validation loss: 3.0300988008434095

Epoch: 5| Step: 2
Training loss: 3.553991765276246
Validation loss: 3.0323852148803185

Epoch: 5| Step: 3
Training loss: 3.6814743206802523
Validation loss: 3.031469771200441

Epoch: 5| Step: 4
Training loss: 2.555038847954544
Validation loss: 3.0339553621073994

Epoch: 5| Step: 5
Training loss: 3.3125110841961516
Validation loss: 3.0298188136361546

Epoch: 5| Step: 6
Training loss: 3.356389195914002
Validation loss: 3.0287851186559016

Epoch: 5| Step: 7
Training loss: 3.3204938771691586
Validation loss: 3.0282306457273753

Epoch: 5| Step: 8
Training loss: 3.607625165580142
Validation loss: 3.027518460898518

Epoch: 5| Step: 9
Training loss: 3.234194248327253
Validation loss: 3.025395980405792

Epoch: 5| Step: 10
Training loss: 3.3041020589495402
Validation loss: 3.0243097761782844

Epoch: 161| Step: 0
Training loss: 3.6531057287120676
Validation loss: 3.024025594060425

Epoch: 5| Step: 1
Training loss: 2.9288914934235826
Validation loss: 3.0250404252832865

Epoch: 5| Step: 2
Training loss: 4.058897798253846
Validation loss: 3.0270856460277784

Epoch: 5| Step: 3
Training loss: 2.937835187253257
Validation loss: 3.023937905830991

Epoch: 5| Step: 4
Training loss: 3.602608022135801
Validation loss: 3.0273263433923896

Epoch: 5| Step: 5
Training loss: 3.254398890246987
Validation loss: 3.0257365444073634

Epoch: 5| Step: 6
Training loss: 2.8793994579431526
Validation loss: 3.021810348302201

Epoch: 5| Step: 7
Training loss: 3.256984102233185
Validation loss: 3.0238802917015257

Epoch: 5| Step: 8
Training loss: 3.1198191612360993
Validation loss: 3.0248808333985564

Epoch: 5| Step: 9
Training loss: 2.876360695643095
Validation loss: 3.0225818777156803

Epoch: 5| Step: 10
Training loss: 3.5061648434992385
Validation loss: 3.0213812755794165

Epoch: 162| Step: 0
Training loss: 3.214195510567359
Validation loss: 3.0212505147275746

Epoch: 5| Step: 1
Training loss: 3.397421077572299
Validation loss: 3.0212757458481385

Epoch: 5| Step: 2
Training loss: 2.4040646227816453
Validation loss: 3.0226509852070595

Epoch: 5| Step: 3
Training loss: 3.362502093119484
Validation loss: 3.0214015868932362

Epoch: 5| Step: 4
Training loss: 3.664396941776288
Validation loss: 3.022015959547335

Epoch: 5| Step: 5
Training loss: 3.4864203090928774
Validation loss: 3.0261608070179573

Epoch: 5| Step: 6
Training loss: 3.5416417438901737
Validation loss: 3.025120018917441

Epoch: 5| Step: 7
Training loss: 2.5483324058469488
Validation loss: 3.0190072016323573

Epoch: 5| Step: 8
Training loss: 2.9667290484552584
Validation loss: 3.0206604426848287

Epoch: 5| Step: 9
Training loss: 3.625958283139691
Validation loss: 3.019730426780156

Epoch: 5| Step: 10
Training loss: 3.7966662690986066
Validation loss: 3.020097830698911

Epoch: 163| Step: 0
Training loss: 2.9016680951437226
Validation loss: 3.0205087664891295

Epoch: 5| Step: 1
Training loss: 3.5358543423302637
Validation loss: 3.0193185733366317

Epoch: 5| Step: 2
Training loss: 3.183496990956747
Validation loss: 3.019055123979449

Epoch: 5| Step: 3
Training loss: 3.2429858592075327
Validation loss: 3.0220509169710255

Epoch: 5| Step: 4
Training loss: 3.601141319554922
Validation loss: 3.020489365821769

Epoch: 5| Step: 5
Training loss: 2.9325165377229427
Validation loss: 3.0204086231460607

Epoch: 5| Step: 6
Training loss: 3.0779934772722264
Validation loss: 3.0191508746860016

Epoch: 5| Step: 7
Training loss: 3.3200100390730594
Validation loss: 3.0209283753671246

Epoch: 5| Step: 8
Training loss: 3.6403198114269815
Validation loss: 3.018209703214164

Epoch: 5| Step: 9
Training loss: 3.567961805857664
Validation loss: 3.0182475849727

Epoch: 5| Step: 10
Training loss: 3.0936673856551558
Validation loss: 3.0162502845391512

Epoch: 164| Step: 0
Training loss: 3.3936283152983946
Validation loss: 3.016241815695805

Epoch: 5| Step: 1
Training loss: 3.1964204914450605
Validation loss: 3.0177053282756456

Epoch: 5| Step: 2
Training loss: 3.276735524423887
Validation loss: 3.0160870791799996

Epoch: 5| Step: 3
Training loss: 3.1717960742470326
Validation loss: 3.018379158788363

Epoch: 5| Step: 4
Training loss: 2.5802686622372737
Validation loss: 3.017253579010429

Epoch: 5| Step: 5
Training loss: 3.6661822403616897
Validation loss: 3.0183805720955696

Epoch: 5| Step: 6
Training loss: 2.51049300166106
Validation loss: 3.0170905587778747

Epoch: 5| Step: 7
Training loss: 3.456117188038631
Validation loss: 3.0171377748840467

Epoch: 5| Step: 8
Training loss: 3.331672175067154
Validation loss: 3.016367607530932

Epoch: 5| Step: 9
Training loss: 3.395037333489659
Validation loss: 3.0180842387372415

Epoch: 5| Step: 10
Training loss: 4.037047483046377
Validation loss: 3.0172528797399063

Epoch: 165| Step: 0
Training loss: 2.6762586181729926
Validation loss: 3.0172775605776008

Epoch: 5| Step: 1
Training loss: 3.3599833092956155
Validation loss: 3.017233069839969

Epoch: 5| Step: 2
Training loss: 3.198049701984368
Validation loss: 3.0171167780489982

Epoch: 5| Step: 3
Training loss: 2.3890331678167867
Validation loss: 3.017008581406206

Epoch: 5| Step: 4
Training loss: 3.5068299546558546
Validation loss: 3.0176763301726575

Epoch: 5| Step: 5
Training loss: 3.3077823945676976
Validation loss: 3.013560152720057

Epoch: 5| Step: 6
Training loss: 3.385503319829514
Validation loss: 3.016381220506784

Epoch: 5| Step: 7
Training loss: 2.822594984431255
Validation loss: 3.015743524686562

Epoch: 5| Step: 8
Training loss: 3.634298828586316
Validation loss: 3.013585527342452

Epoch: 5| Step: 9
Training loss: 3.914342447651374
Validation loss: 3.012624356393935

Epoch: 5| Step: 10
Training loss: 3.687037552106641
Validation loss: 3.014272878167694

Epoch: 166| Step: 0
Training loss: 3.109815096740172
Validation loss: 3.0154463149578534

Epoch: 5| Step: 1
Training loss: 3.6666105150489305
Validation loss: 3.01351493928886

Epoch: 5| Step: 2
Training loss: 3.36062925123159
Validation loss: 3.0118999126392487

Epoch: 5| Step: 3
Training loss: 2.710210609275755
Validation loss: 3.011716547037193

Epoch: 5| Step: 4
Training loss: 2.7343034135439535
Validation loss: 3.0137330460679848

Epoch: 5| Step: 5
Training loss: 3.0424371727605672
Validation loss: 3.015037957674279

Epoch: 5| Step: 6
Training loss: 3.3059694225191856
Validation loss: 3.0109026769517757

Epoch: 5| Step: 7
Training loss: 3.6231484781912444
Validation loss: 3.012835089029961

Epoch: 5| Step: 8
Training loss: 3.4024738063546773
Validation loss: 3.012057451684274

Epoch: 5| Step: 9
Training loss: 3.7794703559586
Validation loss: 3.0138638736382393

Epoch: 5| Step: 10
Training loss: 3.1643076860537827
Validation loss: 3.0162387898889245

Epoch: 167| Step: 0
Training loss: 3.46473062324129
Validation loss: 3.0151187336384337

Epoch: 5| Step: 1
Training loss: 3.2714660097432273
Validation loss: 3.0194615022500537

Epoch: 5| Step: 2
Training loss: 3.3578477803502973
Validation loss: 3.016823088291728

Epoch: 5| Step: 3
Training loss: 2.4048533163722485
Validation loss: 3.0159644062825923

Epoch: 5| Step: 4
Training loss: 3.982160124658833
Validation loss: 3.0126980389293356

Epoch: 5| Step: 5
Training loss: 3.8978403127108163
Validation loss: 3.0088453245815936

Epoch: 5| Step: 6
Training loss: 2.7059235831873223
Validation loss: 3.007737755083124

Epoch: 5| Step: 7
Training loss: 3.2681089746429204
Validation loss: 3.0088518869457275

Epoch: 5| Step: 8
Training loss: 3.1132282554107857
Validation loss: 3.008712361628173

Epoch: 5| Step: 9
Training loss: 3.3552932426906894
Validation loss: 3.0088163501499414

Epoch: 5| Step: 10
Training loss: 2.9524029853250635
Validation loss: 3.007984649841473

Epoch: 168| Step: 0
Training loss: 3.313309192786999
Validation loss: 3.0074011625951633

Epoch: 5| Step: 1
Training loss: 3.214844936588481
Validation loss: 3.0077103826402127

Epoch: 5| Step: 2
Training loss: 3.0172239817977466
Validation loss: 3.007453428883412

Epoch: 5| Step: 3
Training loss: 3.745387737742285
Validation loss: 3.007723007713962

Epoch: 5| Step: 4
Training loss: 2.627673558710488
Validation loss: 3.0075659448544965

Epoch: 5| Step: 5
Training loss: 3.182311678676251
Validation loss: 3.0077055540383824

Epoch: 5| Step: 6
Training loss: 4.039868036513248
Validation loss: 3.007532545191569

Epoch: 5| Step: 7
Training loss: 3.226317463361231
Validation loss: 3.007716394302584

Epoch: 5| Step: 8
Training loss: 3.4569444893332526
Validation loss: 3.006480203207231

Epoch: 5| Step: 9
Training loss: 3.1852627550909713
Validation loss: 3.0070995971672914

Epoch: 5| Step: 10
Training loss: 2.7863700115906536
Validation loss: 3.0058359923209492

Epoch: 169| Step: 0
Training loss: 2.643196794784579
Validation loss: 3.0067474401555545

Epoch: 5| Step: 1
Training loss: 3.5157869428847346
Validation loss: 3.0057659915983193

Epoch: 5| Step: 2
Training loss: 2.860130502084238
Validation loss: 3.0073387067952853

Epoch: 5| Step: 3
Training loss: 3.6784021679882217
Validation loss: 3.006880459303661

Epoch: 5| Step: 4
Training loss: 2.9657005308479607
Validation loss: 3.007553838233428

Epoch: 5| Step: 5
Training loss: 3.1448587756447823
Validation loss: 3.0084207180601656

Epoch: 5| Step: 6
Training loss: 3.1573430047832174
Validation loss: 3.0071500801209488

Epoch: 5| Step: 7
Training loss: 3.452700213373257
Validation loss: 3.011465240373093

Epoch: 5| Step: 8
Training loss: 3.5110396257868146
Validation loss: 3.0048538749383074

Epoch: 5| Step: 9
Training loss: 3.724697198017437
Validation loss: 3.006333358707653

Epoch: 5| Step: 10
Training loss: 3.2400735236879745
Validation loss: 3.0056912465385537

Epoch: 170| Step: 0
Training loss: 3.4345901657888667
Validation loss: 3.004239979414432

Epoch: 5| Step: 1
Training loss: 3.4281441728860784
Validation loss: 3.005013795035132

Epoch: 5| Step: 2
Training loss: 3.353174351082831
Validation loss: 3.0031746300165114

Epoch: 5| Step: 3
Training loss: 3.7644955535996174
Validation loss: 3.0045721393299623

Epoch: 5| Step: 4
Training loss: 3.590746080234542
Validation loss: 3.003728500554941

Epoch: 5| Step: 5
Training loss: 3.749523895557858
Validation loss: 3.0033627227739763

Epoch: 5| Step: 6
Training loss: 2.4381512481051035
Validation loss: 3.0027606722928066

Epoch: 5| Step: 7
Training loss: 3.1496008907763535
Validation loss: 3.002122032815192

Epoch: 5| Step: 8
Training loss: 2.849775031061423
Validation loss: 3.0029612269138815

Epoch: 5| Step: 9
Training loss: 3.5591256741754984
Validation loss: 3.0029866048716345

Epoch: 5| Step: 10
Training loss: 2.219177527272771
Validation loss: 3.0016657689303137

Epoch: 171| Step: 0
Training loss: 3.365237067205467
Validation loss: 3.0018102378208336

Epoch: 5| Step: 1
Training loss: 3.250229313903335
Validation loss: 3.0022672696093453

Epoch: 5| Step: 2
Training loss: 3.021229492168403
Validation loss: 3.0036108870091023

Epoch: 5| Step: 3
Training loss: 3.28835174782249
Validation loss: 3.001032069810228

Epoch: 5| Step: 4
Training loss: 3.08969929932573
Validation loss: 3.0054795408746506

Epoch: 5| Step: 5
Training loss: 3.407573058030156
Validation loss: 3.002075453287311

Epoch: 5| Step: 6
Training loss: 2.956506639756673
Validation loss: 3.0066925968405993

Epoch: 5| Step: 7
Training loss: 3.9848357289533483
Validation loss: 3.008877245040424

Epoch: 5| Step: 8
Training loss: 3.1612930045138468
Validation loss: 3.0044874465960794

Epoch: 5| Step: 9
Training loss: 3.3591951543883414
Validation loss: 2.99989569903127

Epoch: 5| Step: 10
Training loss: 2.995622779404446
Validation loss: 2.999289787476995

Epoch: 172| Step: 0
Training loss: 3.2765495420098745
Validation loss: 2.9993101150542913

Epoch: 5| Step: 1
Training loss: 3.4622050906851
Validation loss: 2.999406703781102

Epoch: 5| Step: 2
Training loss: 2.7655270661509137
Validation loss: 2.999163287479196

Epoch: 5| Step: 3
Training loss: 3.2683129450583426
Validation loss: 2.9978528918961427

Epoch: 5| Step: 4
Training loss: 3.055880184461136
Validation loss: 2.9990273389194098

Epoch: 5| Step: 5
Training loss: 3.2818867383495265
Validation loss: 3.0011181234604645

Epoch: 5| Step: 6
Training loss: 3.15009167855683
Validation loss: 2.9987645288526563

Epoch: 5| Step: 7
Training loss: 4.1541722202295785
Validation loss: 2.9984718997635205

Epoch: 5| Step: 8
Training loss: 3.3725698693731627
Validation loss: 2.999945458904238

Epoch: 5| Step: 9
Training loss: 3.3225380294150404
Validation loss: 3.0005332958152593

Epoch: 5| Step: 10
Training loss: 2.5705004220460204
Validation loss: 2.9960879332107364

Epoch: 173| Step: 0
Training loss: 3.1703504083509375
Validation loss: 2.9976724753006097

Epoch: 5| Step: 1
Training loss: 3.4997817380152605
Validation loss: 2.997095814756789

Epoch: 5| Step: 2
Training loss: 3.662935063166905
Validation loss: 2.9976222552156377

Epoch: 5| Step: 3
Training loss: 2.7667002338839644
Validation loss: 2.9960949753063306

Epoch: 5| Step: 4
Training loss: 4.052366323649051
Validation loss: 2.9971635237610097

Epoch: 5| Step: 5
Training loss: 2.7411261349380442
Validation loss: 2.9966739517855756

Epoch: 5| Step: 6
Training loss: 2.6583598116649196
Validation loss: 2.995641751475852

Epoch: 5| Step: 7
Training loss: 3.4832002173241903
Validation loss: 2.9962547896327303

Epoch: 5| Step: 8
Training loss: 3.306682011840449
Validation loss: 3.0043362927432944

Epoch: 5| Step: 9
Training loss: 2.9114703801997153
Validation loss: 3.0010543008078443

Epoch: 5| Step: 10
Training loss: 3.46887261801154
Validation loss: 3.008509970594528

Epoch: 174| Step: 0
Training loss: 2.359146005999737
Validation loss: 3.00501351350516

Epoch: 5| Step: 1
Training loss: 3.511428430626643
Validation loss: 3.008006255023774

Epoch: 5| Step: 2
Training loss: 3.250519637600842
Validation loss: 3.006689349967666

Epoch: 5| Step: 3
Training loss: 2.6269445936780613
Validation loss: 3.004950136171575

Epoch: 5| Step: 4
Training loss: 3.182001794743826
Validation loss: 3.0062372415404175

Epoch: 5| Step: 5
Training loss: 3.618302834509804
Validation loss: 3.00194471573988

Epoch: 5| Step: 6
Training loss: 3.8237245764484196
Validation loss: 2.997940263919894

Epoch: 5| Step: 7
Training loss: 3.4592742712282214
Validation loss: 2.9992204006961645

Epoch: 5| Step: 8
Training loss: 3.2104684900205824
Validation loss: 2.993739634130748

Epoch: 5| Step: 9
Training loss: 3.553813717942106
Validation loss: 2.9920093602548494

Epoch: 5| Step: 10
Training loss: 3.075819362242443
Validation loss: 2.994865802776425

Epoch: 175| Step: 0
Training loss: 3.575048998516926
Validation loss: 2.9922439491475408

Epoch: 5| Step: 1
Training loss: 3.612695924930342
Validation loss: 2.9927076595888673

Epoch: 5| Step: 2
Training loss: 3.12652642163951
Validation loss: 2.992545306827517

Epoch: 5| Step: 3
Training loss: 2.6121706120674952
Validation loss: 2.9933910431355177

Epoch: 5| Step: 4
Training loss: 3.478102713596613
Validation loss: 2.992773206420789

Epoch: 5| Step: 5
Training loss: 3.074912626684401
Validation loss: 2.9925443687675553

Epoch: 5| Step: 6
Training loss: 3.485422156664592
Validation loss: 2.9924955249926004

Epoch: 5| Step: 7
Training loss: 3.5613698672590717
Validation loss: 2.9927030063756765

Epoch: 5| Step: 8
Training loss: 2.9575580243620347
Validation loss: 2.991480022687522

Epoch: 5| Step: 9
Training loss: 3.0984461427876813
Validation loss: 2.9906540226413973

Epoch: 5| Step: 10
Training loss: 3.2349077606022236
Validation loss: 2.9918170799166277

Epoch: 176| Step: 0
Training loss: 3.761128507042052
Validation loss: 2.991976097964971

Epoch: 5| Step: 1
Training loss: 2.684232366500595
Validation loss: 3.0009657645229897

Epoch: 5| Step: 2
Training loss: 2.4748910745098414
Validation loss: 3.009001862289652

Epoch: 5| Step: 3
Training loss: 3.694514698581158
Validation loss: 3.0169177711670927

Epoch: 5| Step: 4
Training loss: 2.6810741340208177
Validation loss: 3.010031240759897

Epoch: 5| Step: 5
Training loss: 3.7393276938331677
Validation loss: 3.0066556762439145

Epoch: 5| Step: 6
Training loss: 3.1332447391186733
Validation loss: 2.997844672097353

Epoch: 5| Step: 7
Training loss: 3.43023552133254
Validation loss: 2.99867546330289

Epoch: 5| Step: 8
Training loss: 3.238297300218442
Validation loss: 2.9992500311173327

Epoch: 5| Step: 9
Training loss: 3.4225998202271537
Validation loss: 2.9888153038624603

Epoch: 5| Step: 10
Training loss: 3.386963163397979
Validation loss: 2.9889055029393132

Epoch: 177| Step: 0
Training loss: 3.397446621664291
Validation loss: 2.9880420687484612

Epoch: 5| Step: 1
Training loss: 3.4065305261849743
Validation loss: 2.9865485966361587

Epoch: 5| Step: 2
Training loss: 3.4280411020616888
Validation loss: 2.9876573317046695

Epoch: 5| Step: 3
Training loss: 3.4140578909347465
Validation loss: 2.9883418864763582

Epoch: 5| Step: 4
Training loss: 3.5820280551376156
Validation loss: 2.9875371126703345

Epoch: 5| Step: 5
Training loss: 3.5704647507540184
Validation loss: 2.986767261516048

Epoch: 5| Step: 6
Training loss: 3.0487333450394236
Validation loss: 2.9875449841188497

Epoch: 5| Step: 7
Training loss: 2.893020544533645
Validation loss: 2.9869654096789096

Epoch: 5| Step: 8
Training loss: 3.564212454417813
Validation loss: 2.9886168734669667

Epoch: 5| Step: 9
Training loss: 2.9230461833279615
Validation loss: 2.9886957678792077

Epoch: 5| Step: 10
Training loss: 2.3874990932602684
Validation loss: 2.9881338852196104

Epoch: 178| Step: 0
Training loss: 3.134665381234037
Validation loss: 2.9878172953222712

Epoch: 5| Step: 1
Training loss: 3.4673951398400114
Validation loss: 2.9890838911317523

Epoch: 5| Step: 2
Training loss: 2.986298265925366
Validation loss: 2.986898132101024

Epoch: 5| Step: 3
Training loss: 3.165426530105015
Validation loss: 2.98569047246157

Epoch: 5| Step: 4
Training loss: 3.1257898476922654
Validation loss: 2.986917095217239

Epoch: 5| Step: 5
Training loss: 3.478081600607352
Validation loss: 2.9862351970705507

Epoch: 5| Step: 6
Training loss: 3.2012667592424355
Validation loss: 2.9849817489995263

Epoch: 5| Step: 7
Training loss: 3.25899420147708
Validation loss: 2.9844338715608405

Epoch: 5| Step: 8
Training loss: 3.7491124692313247
Validation loss: 2.9846514244337503

Epoch: 5| Step: 9
Training loss: 2.9561879254330354
Validation loss: 2.98333992188822

Epoch: 5| Step: 10
Training loss: 3.3254069660062644
Validation loss: 2.984740923925487

Epoch: 179| Step: 0
Training loss: 3.9196823495500897
Validation loss: 2.984824995121312

Epoch: 5| Step: 1
Training loss: 3.2829598467739114
Validation loss: 2.986091862551544

Epoch: 5| Step: 2
Training loss: 2.1621714568421626
Validation loss: 2.984578120616625

Epoch: 5| Step: 3
Training loss: 3.446263188616035
Validation loss: 2.9854753833622913

Epoch: 5| Step: 4
Training loss: 3.356628714848531
Validation loss: 2.9875639027983785

Epoch: 5| Step: 5
Training loss: 3.142834545648759
Validation loss: 2.9876225673627603

Epoch: 5| Step: 6
Training loss: 3.612101792296302
Validation loss: 2.9874329129203394

Epoch: 5| Step: 7
Training loss: 3.7659159820957373
Validation loss: 2.9820405084311936

Epoch: 5| Step: 8
Training loss: 3.121096500018344
Validation loss: 2.982528282662482

Epoch: 5| Step: 9
Training loss: 2.865053136043217
Validation loss: 2.981821715304145

Epoch: 5| Step: 10
Training loss: 2.7647897784593836
Validation loss: 2.9826262288186576

Epoch: 180| Step: 0
Training loss: 3.0550778815149022
Validation loss: 2.982129561024617

Epoch: 5| Step: 1
Training loss: 3.4222172256807566
Validation loss: 2.9827463062867037

Epoch: 5| Step: 2
Training loss: 4.162764642224292
Validation loss: 2.981086226706721

Epoch: 5| Step: 3
Training loss: 3.260047347304183
Validation loss: 2.982153997840199

Epoch: 5| Step: 4
Training loss: 3.2330776690313607
Validation loss: 2.9813425525558

Epoch: 5| Step: 5
Training loss: 3.3666583926662588
Validation loss: 2.980541693856127

Epoch: 5| Step: 6
Training loss: 2.664784979528664
Validation loss: 2.981009397839317

Epoch: 5| Step: 7
Training loss: 2.8973748657484584
Validation loss: 2.9811422015392766

Epoch: 5| Step: 8
Training loss: 2.9695960194610356
Validation loss: 2.9839879894063817

Epoch: 5| Step: 9
Training loss: 3.2938083650749026
Validation loss: 2.980913880571641

Epoch: 5| Step: 10
Training loss: 3.3258623482026275
Validation loss: 2.9818154541207775

Epoch: 181| Step: 0
Training loss: 3.3514801228676636
Validation loss: 2.980948707671273

Epoch: 5| Step: 1
Training loss: 2.677939954527534
Validation loss: 2.980654016420425

Epoch: 5| Step: 2
Training loss: 3.7245302556980726
Validation loss: 2.983934169433635

Epoch: 5| Step: 3
Training loss: 3.3532969292951837
Validation loss: 2.981167310326107

Epoch: 5| Step: 4
Training loss: 3.7714977767919575
Validation loss: 2.981080222399706

Epoch: 5| Step: 5
Training loss: 3.5705116266526864
Validation loss: 2.9804422453188852

Epoch: 5| Step: 6
Training loss: 3.0355576258395227
Validation loss: 2.9792522335234755

Epoch: 5| Step: 7
Training loss: 2.9949925275145786
Validation loss: 2.9809711899235154

Epoch: 5| Step: 8
Training loss: 2.436189935216805
Validation loss: 2.9824806991571653

Epoch: 5| Step: 9
Training loss: 3.357329273555726
Validation loss: 2.9801628953522252

Epoch: 5| Step: 10
Training loss: 3.323625702185422
Validation loss: 2.978760146350719

Epoch: 182| Step: 0
Training loss: 2.5023602787916586
Validation loss: 2.979809997430034

Epoch: 5| Step: 1
Training loss: 3.751879793132597
Validation loss: 2.981334337970492

Epoch: 5| Step: 2
Training loss: 3.290834651691414
Validation loss: 2.9779697130283838

Epoch: 5| Step: 3
Training loss: 3.1605233449582175
Validation loss: 2.9767888725142475

Epoch: 5| Step: 4
Training loss: 3.376206076547087
Validation loss: 2.977430161238201

Epoch: 5| Step: 5
Training loss: 2.9458217838246195
Validation loss: 2.9787285090501006

Epoch: 5| Step: 6
Training loss: 3.3436993746623926
Validation loss: 2.9753171743256552

Epoch: 5| Step: 7
Training loss: 2.76203210933288
Validation loss: 2.9776903385916103

Epoch: 5| Step: 8
Training loss: 3.430597067378869
Validation loss: 2.979364275142325

Epoch: 5| Step: 9
Training loss: 3.7838710811663123
Validation loss: 2.9802147885809895

Epoch: 5| Step: 10
Training loss: 3.2152590292229957
Validation loss: 2.9743803344935507

Epoch: 183| Step: 0
Training loss: 3.397642266198014
Validation loss: 2.975620747696223

Epoch: 5| Step: 1
Training loss: 2.464164724993164
Validation loss: 2.975693987005565

Epoch: 5| Step: 2
Training loss: 3.060984333764669
Validation loss: 2.974935263224698

Epoch: 5| Step: 3
Training loss: 2.9366901985925864
Validation loss: 2.9752553254447878

Epoch: 5| Step: 4
Training loss: 4.330420811315705
Validation loss: 2.975833211676716

Epoch: 5| Step: 5
Training loss: 4.045090447582845
Validation loss: 2.9744322441419095

Epoch: 5| Step: 6
Training loss: 3.539009683311734
Validation loss: 2.9744413741544107

Epoch: 5| Step: 7
Training loss: 2.351643912594823
Validation loss: 2.97398954669303

Epoch: 5| Step: 8
Training loss: 2.5077751370792947
Validation loss: 2.9742065766290113

Epoch: 5| Step: 9
Training loss: 3.4927248957319303
Validation loss: 2.9737533746686666

Epoch: 5| Step: 10
Training loss: 3.006981038689971
Validation loss: 2.974920564374982

Epoch: 184| Step: 0
Training loss: 2.991820629128672
Validation loss: 2.9737224427476887

Epoch: 5| Step: 1
Training loss: 3.690915998571127
Validation loss: 2.972665086212701

Epoch: 5| Step: 2
Training loss: 3.7425042577807224
Validation loss: 2.974265623601808

Epoch: 5| Step: 3
Training loss: 2.820778256155196
Validation loss: 2.9740916823272427

Epoch: 5| Step: 4
Training loss: 3.175554518447729
Validation loss: 2.9745620681654845

Epoch: 5| Step: 5
Training loss: 2.9365516917496737
Validation loss: 2.9737407881398688

Epoch: 5| Step: 6
Training loss: 3.695919188685271
Validation loss: 2.9733801097281534

Epoch: 5| Step: 7
Training loss: 3.5647046144157737
Validation loss: 2.971142658831367

Epoch: 5| Step: 8
Training loss: 2.953277745409043
Validation loss: 2.9720527157312593

Epoch: 5| Step: 9
Training loss: 3.2215439605105427
Validation loss: 2.973333764531679

Epoch: 5| Step: 10
Training loss: 2.6787646959607487
Validation loss: 2.97352798842655

Epoch: 185| Step: 0
Training loss: 3.2509746557237573
Validation loss: 2.973394353195284

Epoch: 5| Step: 1
Training loss: 3.2258042744659954
Validation loss: 2.9795733196606697

Epoch: 5| Step: 2
Training loss: 2.9690927408033603
Validation loss: 2.9761982270358134

Epoch: 5| Step: 3
Training loss: 2.987566774013095
Validation loss: 2.978920946601617

Epoch: 5| Step: 4
Training loss: 3.5794755144428763
Validation loss: 2.97753953432419

Epoch: 5| Step: 5
Training loss: 3.4648290244631417
Validation loss: 2.9742752393968703

Epoch: 5| Step: 6
Training loss: 3.776098983154257
Validation loss: 2.9727677313093204

Epoch: 5| Step: 7
Training loss: 2.6911882331588632
Validation loss: 2.96970136561445

Epoch: 5| Step: 8
Training loss: 2.8732369033965073
Validation loss: 2.9710284079661227

Epoch: 5| Step: 9
Training loss: 3.7001026551723504
Validation loss: 2.97143141197907

Epoch: 5| Step: 10
Training loss: 3.046358817954558
Validation loss: 2.9715431264522927

Epoch: 186| Step: 0
Training loss: 3.354688489298148
Validation loss: 2.972126139571116

Epoch: 5| Step: 1
Training loss: 3.0379437346179716
Validation loss: 2.973612578377558

Epoch: 5| Step: 2
Training loss: 3.3696839179255482
Validation loss: 2.9713841753375383

Epoch: 5| Step: 3
Training loss: 3.1926292588033895
Validation loss: 2.9726295954561546

Epoch: 5| Step: 4
Training loss: 3.067786033868263
Validation loss: 2.9703452020806007

Epoch: 5| Step: 5
Training loss: 3.584274138916452
Validation loss: 2.970605360477675

Epoch: 5| Step: 6
Training loss: 3.553603055091654
Validation loss: 2.9735431226487155

Epoch: 5| Step: 7
Training loss: 2.901842281922019
Validation loss: 2.971001877742886

Epoch: 5| Step: 8
Training loss: 2.6640358305460357
Validation loss: 2.968556101694718

Epoch: 5| Step: 9
Training loss: 3.3930958828789612
Validation loss: 2.968348919772383

Epoch: 5| Step: 10
Training loss: 3.609309076144784
Validation loss: 2.9673291504912003

Epoch: 187| Step: 0
Training loss: 2.984558099851903
Validation loss: 2.969533806239847

Epoch: 5| Step: 1
Training loss: 3.9608822429346495
Validation loss: 2.972391094480405

Epoch: 5| Step: 2
Training loss: 3.738334057473804
Validation loss: 2.977314457947442

Epoch: 5| Step: 3
Training loss: 2.664643344596073
Validation loss: 2.9798930325538753

Epoch: 5| Step: 4
Training loss: 3.4764726605755154
Validation loss: 2.975198240320024

Epoch: 5| Step: 5
Training loss: 3.524115588116508
Validation loss: 2.9774351422613887

Epoch: 5| Step: 6
Training loss: 2.8917880631028785
Validation loss: 2.974929969510031

Epoch: 5| Step: 7
Training loss: 2.4326635453544
Validation loss: 2.975015784608049

Epoch: 5| Step: 8
Training loss: 3.5410719129041137
Validation loss: 2.9697568713387112

Epoch: 5| Step: 9
Training loss: 2.7729026601099918
Validation loss: 2.9710961475788515

Epoch: 5| Step: 10
Training loss: 3.4138356707399384
Validation loss: 2.9680465236084816

Epoch: 188| Step: 0
Training loss: 3.638169405976983
Validation loss: 2.966088093480111

Epoch: 5| Step: 1
Training loss: 3.5271412399474573
Validation loss: 2.966015178794009

Epoch: 5| Step: 2
Training loss: 3.9304368383469
Validation loss: 2.9642456528808747

Epoch: 5| Step: 3
Training loss: 3.3053768512137975
Validation loss: 2.965962625693031

Epoch: 5| Step: 4
Training loss: 3.0207802778824635
Validation loss: 2.965363676178228

Epoch: 5| Step: 5
Training loss: 3.164323358025843
Validation loss: 2.9649012195242626

Epoch: 5| Step: 6
Training loss: 3.237015977416441
Validation loss: 2.9646191772215422

Epoch: 5| Step: 7
Training loss: 2.7909382301528654
Validation loss: 2.965340160916903

Epoch: 5| Step: 8
Training loss: 2.8850099205758877
Validation loss: 2.9643975952408383

Epoch: 5| Step: 9
Training loss: 3.049213783363717
Validation loss: 2.9642999808012083

Epoch: 5| Step: 10
Training loss: 2.9393194529406883
Validation loss: 2.962927274160756

Epoch: 189| Step: 0
Training loss: 3.4274820175088707
Validation loss: 2.963796332200741

Epoch: 5| Step: 1
Training loss: 3.4624058900017975
Validation loss: 2.96449276432225

Epoch: 5| Step: 2
Training loss: 3.7654868452758934
Validation loss: 2.9640349521795057

Epoch: 5| Step: 3
Training loss: 2.7876415747027505
Validation loss: 2.9646222193941076

Epoch: 5| Step: 4
Training loss: 2.9090272492791023
Validation loss: 2.9632278966307455

Epoch: 5| Step: 5
Training loss: 3.7429700443374667
Validation loss: 2.965038674422638

Epoch: 5| Step: 6
Training loss: 3.2664802562958357
Validation loss: 2.966637088005532

Epoch: 5| Step: 7
Training loss: 2.9606609768943457
Validation loss: 2.966597772051553

Epoch: 5| Step: 8
Training loss: 2.83864613378698
Validation loss: 2.9660668346607326

Epoch: 5| Step: 9
Training loss: 3.571283321151729
Validation loss: 2.967491170573188

Epoch: 5| Step: 10
Training loss: 2.5929372961993287
Validation loss: 2.9655098954214107

Epoch: 190| Step: 0
Training loss: 3.4531774732650558
Validation loss: 2.966895058806675

Epoch: 5| Step: 1
Training loss: 2.3208706887581583
Validation loss: 2.969049178086568

Epoch: 5| Step: 2
Training loss: 3.884895732958226
Validation loss: 2.9653760778098763

Epoch: 5| Step: 3
Training loss: 3.4786203530346445
Validation loss: 2.9625742346951975

Epoch: 5| Step: 4
Training loss: 3.018549790466345
Validation loss: 2.9612529172234408

Epoch: 5| Step: 5
Training loss: 2.889432258938025
Validation loss: 2.96052186136247

Epoch: 5| Step: 6
Training loss: 2.7500421347424635
Validation loss: 2.958630798326759

Epoch: 5| Step: 7
Training loss: 3.9263891252402856
Validation loss: 2.959551435796138

Epoch: 5| Step: 8
Training loss: 3.5287564005778496
Validation loss: 2.9603912951912608

Epoch: 5| Step: 9
Training loss: 2.9573005342009053
Validation loss: 2.9602199542922754

Epoch: 5| Step: 10
Training loss: 3.077344766477682
Validation loss: 2.9610577063582117

Epoch: 191| Step: 0
Training loss: 2.9825120473843802
Validation loss: 2.961183136963895

Epoch: 5| Step: 1
Training loss: 3.196335756943905
Validation loss: 2.96001957231163

Epoch: 5| Step: 2
Training loss: 3.1223417038264887
Validation loss: 2.9599805781260224

Epoch: 5| Step: 3
Training loss: 3.609720320923504
Validation loss: 2.9596535040536396

Epoch: 5| Step: 4
Training loss: 3.593712582600725
Validation loss: 2.960220991796579

Epoch: 5| Step: 5
Training loss: 3.366892649050381
Validation loss: 2.9584109914160517

Epoch: 5| Step: 6
Training loss: 3.1713096979316466
Validation loss: 2.961083615739797

Epoch: 5| Step: 7
Training loss: 3.1553310151721985
Validation loss: 2.9584173970206535

Epoch: 5| Step: 8
Training loss: 3.5072654518452167
Validation loss: 2.962360243406021

Epoch: 5| Step: 9
Training loss: 2.8047679156407774
Validation loss: 2.9593500530369004

Epoch: 5| Step: 10
Training loss: 3.009234203875533
Validation loss: 2.9600831252462476

Epoch: 192| Step: 0
Training loss: 3.1329943825299713
Validation loss: 2.963921322554306

Epoch: 5| Step: 1
Training loss: 2.69647651636956
Validation loss: 2.9618142369216383

Epoch: 5| Step: 2
Training loss: 3.2331649801989024
Validation loss: 2.959781433271218

Epoch: 5| Step: 3
Training loss: 3.1802880472204804
Validation loss: 2.9538426601228465

Epoch: 5| Step: 4
Training loss: 2.911123148413597
Validation loss: 2.95830735249068

Epoch: 5| Step: 5
Training loss: 3.2071607519433996
Validation loss: 2.9595034880618183

Epoch: 5| Step: 6
Training loss: 3.5164924060138016
Validation loss: 2.9593140066974675

Epoch: 5| Step: 7
Training loss: 3.9689989387355085
Validation loss: 2.9600361847197045

Epoch: 5| Step: 8
Training loss: 3.2690884416763573
Validation loss: 2.9571363120736707

Epoch: 5| Step: 9
Training loss: 2.886515567633818
Validation loss: 2.956261882052642

Epoch: 5| Step: 10
Training loss: 3.465761564159383
Validation loss: 2.956276823697965

Epoch: 193| Step: 0
Training loss: 3.024801414844149
Validation loss: 2.9556938917729334

Epoch: 5| Step: 1
Training loss: 3.1017070131241717
Validation loss: 2.958499611447047

Epoch: 5| Step: 2
Training loss: 2.8254419740609436
Validation loss: 2.9678159720003445

Epoch: 5| Step: 3
Training loss: 2.992038015909467
Validation loss: 2.968821811293244

Epoch: 5| Step: 4
Training loss: 2.601924836641094
Validation loss: 2.959345071893813

Epoch: 5| Step: 5
Training loss: 3.7850679401059977
Validation loss: 2.953297131000141

Epoch: 5| Step: 6
Training loss: 3.885955091435856
Validation loss: 2.954568902635512

Epoch: 5| Step: 7
Training loss: 3.7550072618355865
Validation loss: 2.95414753078682

Epoch: 5| Step: 8
Training loss: 2.457221334652107
Validation loss: 2.9553913830724223

Epoch: 5| Step: 9
Training loss: 3.9222576061114
Validation loss: 2.9532368071225816

Epoch: 5| Step: 10
Training loss: 2.7479245416867255
Validation loss: 2.955389008005986

Epoch: 194| Step: 0
Training loss: 2.503340396828809
Validation loss: 2.9557688243627367

Epoch: 5| Step: 1
Training loss: 3.6491094783167592
Validation loss: 2.9554867380711225

Epoch: 5| Step: 2
Training loss: 3.515829394014992
Validation loss: 2.9549815300780207

Epoch: 5| Step: 3
Training loss: 2.7936308389464677
Validation loss: 2.95454379340625

Epoch: 5| Step: 4
Training loss: 3.863101287754211
Validation loss: 2.9542133517543565

Epoch: 5| Step: 5
Training loss: 3.530035704737445
Validation loss: 2.9558521957274606

Epoch: 5| Step: 6
Training loss: 3.2656555174355315
Validation loss: 2.9566870069744615

Epoch: 5| Step: 7
Training loss: 2.607089292196209
Validation loss: 2.9558863467349648

Epoch: 5| Step: 8
Training loss: 3.1181918942541187
Validation loss: 2.956560825474747

Epoch: 5| Step: 9
Training loss: 3.1778271080699434
Validation loss: 2.956320879865956

Epoch: 5| Step: 10
Training loss: 3.3306207746098466
Validation loss: 2.9581104999407497

Epoch: 195| Step: 0
Training loss: 2.552820299099055
Validation loss: 2.9557918589458683

Epoch: 5| Step: 1
Training loss: 3.553759644529155
Validation loss: 2.9558772114484984

Epoch: 5| Step: 2
Training loss: 3.580228628604751
Validation loss: 2.9581851113285955

Epoch: 5| Step: 3
Training loss: 3.3570400906402673
Validation loss: 2.9549297706547293

Epoch: 5| Step: 4
Training loss: 2.826970407418112
Validation loss: 2.954412907507763

Epoch: 5| Step: 5
Training loss: 2.912908003229474
Validation loss: 2.95403992725124

Epoch: 5| Step: 6
Training loss: 3.525972997690756
Validation loss: 2.9555511621944297

Epoch: 5| Step: 7
Training loss: 2.5211623006082533
Validation loss: 2.952688799245001

Epoch: 5| Step: 8
Training loss: 3.1509923673614195
Validation loss: 2.958708596479861

Epoch: 5| Step: 9
Training loss: 3.438961481311806
Validation loss: 2.9551935537947953

Epoch: 5| Step: 10
Training loss: 3.975383591287258
Validation loss: 2.9545386653288332

Epoch: 196| Step: 0
Training loss: 3.1259253085652903
Validation loss: 2.950204103888677

Epoch: 5| Step: 1
Training loss: 3.68931638303704
Validation loss: 2.9497723294630354

Epoch: 5| Step: 2
Training loss: 3.2099349412831577
Validation loss: 2.948616168919139

Epoch: 5| Step: 3
Training loss: 3.7194513252643517
Validation loss: 2.951684688549391

Epoch: 5| Step: 4
Training loss: 3.183955896292556
Validation loss: 2.950895743400769

Epoch: 5| Step: 5
Training loss: 2.880906050998994
Validation loss: 2.9488050240569703

Epoch: 5| Step: 6
Training loss: 3.068614538741862
Validation loss: 2.9520742397498436

Epoch: 5| Step: 7
Training loss: 3.2653678537270205
Validation loss: 2.9480124385218085

Epoch: 5| Step: 8
Training loss: 3.2869611175159226
Validation loss: 2.948857315235432

Epoch: 5| Step: 9
Training loss: 2.8841326412327364
Validation loss: 2.9493910846370226

Epoch: 5| Step: 10
Training loss: 3.1097454827965323
Validation loss: 2.9488920054017025

Epoch: 197| Step: 0
Training loss: 3.3266290159012373
Validation loss: 2.9492420886943833

Epoch: 5| Step: 1
Training loss: 3.6208019283031634
Validation loss: 2.950403959488707

Epoch: 5| Step: 2
Training loss: 3.065152012600935
Validation loss: 2.9486730626916224

Epoch: 5| Step: 3
Training loss: 3.8006530300989323
Validation loss: 2.9506837583931653

Epoch: 5| Step: 4
Training loss: 2.319356907799935
Validation loss: 2.948423015944243

Epoch: 5| Step: 5
Training loss: 3.0759559386015694
Validation loss: 2.9481384180605072

Epoch: 5| Step: 6
Training loss: 3.8066148204134356
Validation loss: 2.946710674168115

Epoch: 5| Step: 7
Training loss: 2.4977329465505185
Validation loss: 2.9500414437493454

Epoch: 5| Step: 8
Training loss: 2.839178246094835
Validation loss: 2.955549004106181

Epoch: 5| Step: 9
Training loss: 3.7163389708656167
Validation loss: 2.9502888125337376

Epoch: 5| Step: 10
Training loss: 3.0570628889139493
Validation loss: 2.952834612972292

Epoch: 198| Step: 0
Training loss: 2.8464444987536406
Validation loss: 2.951562504030168

Epoch: 5| Step: 1
Training loss: 3.574413390149382
Validation loss: 2.954060373543719

Epoch: 5| Step: 2
Training loss: 2.7508328650457874
Validation loss: 2.9534786438208216

Epoch: 5| Step: 3
Training loss: 3.1561517983446765
Validation loss: 2.9561738210689645

Epoch: 5| Step: 4
Training loss: 3.0801748818129253
Validation loss: 2.9605970172587113

Epoch: 5| Step: 5
Training loss: 2.9987846137812357
Validation loss: 2.95792350431821

Epoch: 5| Step: 6
Training loss: 3.12687809774919
Validation loss: 2.9549947083716996

Epoch: 5| Step: 7
Training loss: 3.6025346945707457
Validation loss: 2.9523736740544484

Epoch: 5| Step: 8
Training loss: 3.7943058819571323
Validation loss: 2.947372600829599

Epoch: 5| Step: 9
Training loss: 3.6457029628150748
Validation loss: 2.9473711699993514

Epoch: 5| Step: 10
Training loss: 2.6424600218146024
Validation loss: 2.9462873431319183

Epoch: 199| Step: 0
Training loss: 3.0451584895938675
Validation loss: 2.94485455188563

Epoch: 5| Step: 1
Training loss: 3.759979448059404
Validation loss: 2.9499645919649278

Epoch: 5| Step: 2
Training loss: 2.952183972143894
Validation loss: 2.949949419336388

Epoch: 5| Step: 3
Training loss: 2.6641587047042297
Validation loss: 2.948293433047194

Epoch: 5| Step: 4
Training loss: 3.565854551129304
Validation loss: 2.951592707552272

Epoch: 5| Step: 5
Training loss: 2.9496023976977632
Validation loss: 2.948435478397349

Epoch: 5| Step: 6
Training loss: 3.4597113441498073
Validation loss: 2.9479240250126932

Epoch: 5| Step: 7
Training loss: 3.345579840976908
Validation loss: 2.9469337878658948

Epoch: 5| Step: 8
Training loss: 3.132874904401064
Validation loss: 2.9460000762369143

Epoch: 5| Step: 9
Training loss: 2.7177636122037634
Validation loss: 2.9443476458131186

Epoch: 5| Step: 10
Training loss: 3.806858328577819
Validation loss: 2.9437541157909877

Epoch: 200| Step: 0
Training loss: 3.1804667649699807
Validation loss: 2.94603618975746

Epoch: 5| Step: 1
Training loss: 3.331062560685873
Validation loss: 2.946729471345384

Epoch: 5| Step: 2
Training loss: 3.5159768161638607
Validation loss: 2.946525523481686

Epoch: 5| Step: 3
Training loss: 3.120042454357342
Validation loss: 2.9453251801608946

Epoch: 5| Step: 4
Training loss: 2.7472821590295418
Validation loss: 2.942795653721504

Epoch: 5| Step: 5
Training loss: 2.9102730746790173
Validation loss: 2.9401432399052982

Epoch: 5| Step: 6
Training loss: 3.787311330194074
Validation loss: 2.9417833435889955

Epoch: 5| Step: 7
Training loss: 3.486711479929893
Validation loss: 2.9434293478735207

Epoch: 5| Step: 8
Training loss: 3.0800920581683906
Validation loss: 2.94108887690982

Epoch: 5| Step: 9
Training loss: 3.1907684921593167
Validation loss: 2.942200710121091

Epoch: 5| Step: 10
Training loss: 2.96426229090144
Validation loss: 2.942487227510898

Testing loss: 3.1418244036429774
