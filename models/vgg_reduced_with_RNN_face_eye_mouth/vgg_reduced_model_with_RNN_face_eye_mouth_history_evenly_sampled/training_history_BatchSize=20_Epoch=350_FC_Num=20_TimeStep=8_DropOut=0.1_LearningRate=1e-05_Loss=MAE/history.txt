Epoch: 1| Step: 0
Training loss: 4.163674354553223
Validation loss: 5.161619201783211

Epoch: 5| Step: 1
Training loss: 4.285572528839111
Validation loss: 5.149562266565138

Epoch: 5| Step: 2
Training loss: 5.962437152862549
Validation loss: 5.140039067114553

Epoch: 5| Step: 3
Training loss: 4.7206501960754395
Validation loss: 5.131865255294308

Epoch: 5| Step: 4
Training loss: 6.239814758300781
Validation loss: 5.125361898893951

Epoch: 5| Step: 5
Training loss: 3.928218126296997
Validation loss: 5.119052635726108

Epoch: 5| Step: 6
Training loss: 4.710047245025635
Validation loss: 5.112988000274987

Epoch: 5| Step: 7
Training loss: 5.786144733428955
Validation loss: 5.106468939012097

Epoch: 5| Step: 8
Training loss: 4.872609615325928
Validation loss: 5.099400156287737

Epoch: 5| Step: 9
Training loss: 4.1193132400512695
Validation loss: 5.091456500432825

Epoch: 5| Step: 10
Training loss: 5.359686851501465
Validation loss: 5.082436843584943

Epoch: 2| Step: 0
Training loss: 3.4320449829101562
Validation loss: 5.072328126558694

Epoch: 5| Step: 1
Training loss: 5.438869476318359
Validation loss: 5.061298226797453

Epoch: 5| Step: 2
Training loss: 4.1355485916137695
Validation loss: 5.050330433794247

Epoch: 5| Step: 3
Training loss: 5.49260950088501
Validation loss: 5.037594892645395

Epoch: 5| Step: 4
Training loss: 4.795313358306885
Validation loss: 5.023669714568763

Epoch: 5| Step: 5
Training loss: 4.881040573120117
Validation loss: 5.009284952635406

Epoch: 5| Step: 6
Training loss: 4.916490077972412
Validation loss: 4.9940681149882655

Epoch: 5| Step: 7
Training loss: 4.1536784172058105
Validation loss: 4.977313672342608

Epoch: 5| Step: 8
Training loss: 4.3601975440979
Validation loss: 4.960129609671972

Epoch: 5| Step: 9
Training loss: 5.799042701721191
Validation loss: 4.941374240383025

Epoch: 5| Step: 10
Training loss: 5.47929048538208
Validation loss: 4.921370949796451

Epoch: 3| Step: 0
Training loss: 5.321871757507324
Validation loss: 4.900267416431058

Epoch: 5| Step: 1
Training loss: 5.9934797286987305
Validation loss: 4.877136927779003

Epoch: 5| Step: 2
Training loss: 4.0831685066223145
Validation loss: 4.854024728139241

Epoch: 5| Step: 3
Training loss: 5.297022342681885
Validation loss: 4.829626206428774

Epoch: 5| Step: 4
Training loss: 2.910707712173462
Validation loss: 4.803527683340093

Epoch: 5| Step: 5
Training loss: 4.707895755767822
Validation loss: 4.777000360591437

Epoch: 5| Step: 6
Training loss: 3.988774061203003
Validation loss: 4.750611607746412

Epoch: 5| Step: 7
Training loss: 5.120010852813721
Validation loss: 4.723238191296978

Epoch: 5| Step: 8
Training loss: 4.580529689788818
Validation loss: 4.69489065806071

Epoch: 5| Step: 9
Training loss: 3.436370372772217
Validation loss: 4.6669381203189975

Epoch: 5| Step: 10
Training loss: 4.849210262298584
Validation loss: 4.638676463916737

Epoch: 4| Step: 0
Training loss: 3.340733289718628
Validation loss: 4.610439146718671

Epoch: 5| Step: 1
Training loss: 4.467484474182129
Validation loss: 4.581136308690553

Epoch: 5| Step: 2
Training loss: 2.986445188522339
Validation loss: 4.551895823529971

Epoch: 5| Step: 3
Training loss: 4.78148889541626
Validation loss: 4.520821653386598

Epoch: 5| Step: 4
Training loss: 4.133791923522949
Validation loss: 4.4908619978094615

Epoch: 5| Step: 5
Training loss: 4.4437255859375
Validation loss: 4.459573253508537

Epoch: 5| Step: 6
Training loss: 4.895174026489258
Validation loss: 4.430603786181378

Epoch: 5| Step: 7
Training loss: 4.459076881408691
Validation loss: 4.40106249624683

Epoch: 5| Step: 8
Training loss: 4.387219429016113
Validation loss: 4.37218629416599

Epoch: 5| Step: 9
Training loss: 5.054600715637207
Validation loss: 4.344013639675674

Epoch: 5| Step: 10
Training loss: 3.848480224609375
Validation loss: 4.314797596264911

Epoch: 5| Step: 0
Training loss: 4.304521083831787
Validation loss: 4.287691898243402

Epoch: 5| Step: 1
Training loss: 4.785068988800049
Validation loss: 4.260905819554483

Epoch: 5| Step: 2
Training loss: 2.9899144172668457
Validation loss: 4.232885191517491

Epoch: 5| Step: 3
Training loss: 4.296485424041748
Validation loss: 4.205540610897925

Epoch: 5| Step: 4
Training loss: 3.9689598083496094
Validation loss: 4.178060485470679

Epoch: 5| Step: 5
Training loss: 2.7878246307373047
Validation loss: 4.1518520027078605

Epoch: 5| Step: 6
Training loss: 4.637999057769775
Validation loss: 4.129664533881731

Epoch: 5| Step: 7
Training loss: 3.8006234169006348
Validation loss: 4.10739641804849

Epoch: 5| Step: 8
Training loss: 3.5201544761657715
Validation loss: 4.087198611228697

Epoch: 5| Step: 9
Training loss: 4.62487268447876
Validation loss: 4.068507179137199

Epoch: 5| Step: 10
Training loss: 4.1030073165893555
Validation loss: 4.049541170879077

Epoch: 6| Step: 0
Training loss: 4.416693687438965
Validation loss: 4.030347283168505

Epoch: 5| Step: 1
Training loss: 3.739011287689209
Validation loss: 4.012182845864245

Epoch: 5| Step: 2
Training loss: 4.739721298217773
Validation loss: 3.996091950324274

Epoch: 5| Step: 3
Training loss: 3.267955780029297
Validation loss: 3.9795702375391477

Epoch: 5| Step: 4
Training loss: 3.6734421253204346
Validation loss: 3.9656567573547363

Epoch: 5| Step: 5
Training loss: 3.0996108055114746
Validation loss: 3.952611702744679

Epoch: 5| Step: 6
Training loss: 3.9034812450408936
Validation loss: 3.940426452185518

Epoch: 5| Step: 7
Training loss: 4.320850849151611
Validation loss: 3.9311831946014077

Epoch: 5| Step: 8
Training loss: 3.5199203491210938
Validation loss: 3.917004659611692

Epoch: 5| Step: 9
Training loss: 3.233708143234253
Validation loss: 3.9027748313001407

Epoch: 5| Step: 10
Training loss: 3.9765756130218506
Validation loss: 3.889030876980033

Epoch: 7| Step: 0
Training loss: 3.4857609272003174
Validation loss: 3.876712409398889

Epoch: 5| Step: 1
Training loss: 5.010506629943848
Validation loss: 3.865104244601342

Epoch: 5| Step: 2
Training loss: 4.1086602210998535
Validation loss: 3.8543448499453965

Epoch: 5| Step: 3
Training loss: 3.753182888031006
Validation loss: 3.843381820186492

Epoch: 5| Step: 4
Training loss: 3.231219530105591
Validation loss: 3.8343492374625257

Epoch: 5| Step: 5
Training loss: 4.29420804977417
Validation loss: 3.8237980360625894

Epoch: 5| Step: 6
Training loss: 3.386439085006714
Validation loss: 3.816351890563965

Epoch: 5| Step: 7
Training loss: 3.3030648231506348
Validation loss: 3.807402100614322

Epoch: 5| Step: 8
Training loss: 4.013344764709473
Validation loss: 3.798621372510028

Epoch: 5| Step: 9
Training loss: 2.568209648132324
Validation loss: 3.793321483878679

Epoch: 5| Step: 10
Training loss: 3.657041549682617
Validation loss: 3.7826458202895297

Epoch: 8| Step: 0
Training loss: 3.9104912281036377
Validation loss: 3.7757857486765873

Epoch: 5| Step: 1
Training loss: 2.6036903858184814
Validation loss: 3.7676927428091727

Epoch: 5| Step: 2
Training loss: 4.419327735900879
Validation loss: 3.7574460532075618

Epoch: 5| Step: 3
Training loss: 3.1541030406951904
Validation loss: 3.7482400607037287

Epoch: 5| Step: 4
Training loss: 4.5884575843811035
Validation loss: 3.736056384219918

Epoch: 5| Step: 5
Training loss: 3.800488233566284
Validation loss: 3.724786320040303

Epoch: 5| Step: 6
Training loss: 2.924597978591919
Validation loss: 3.71516276174976

Epoch: 5| Step: 7
Training loss: 4.597759246826172
Validation loss: 3.7099909449136383

Epoch: 5| Step: 8
Training loss: 3.1717941761016846
Validation loss: 3.7028879247685915

Epoch: 5| Step: 9
Training loss: 3.7497763633728027
Validation loss: 3.6933230712849605

Epoch: 5| Step: 10
Training loss: 2.819455146789551
Validation loss: 3.6878416102419616

Epoch: 9| Step: 0
Training loss: 3.694375514984131
Validation loss: 3.681470381316318

Epoch: 5| Step: 1
Training loss: 4.294466495513916
Validation loss: 3.6744938460729455

Epoch: 5| Step: 2
Training loss: 3.4728660583496094
Validation loss: 3.6696264231076805

Epoch: 5| Step: 3
Training loss: 3.6571571826934814
Validation loss: 3.6705164729907946

Epoch: 5| Step: 4
Training loss: 3.069423198699951
Validation loss: 3.658275552975234

Epoch: 5| Step: 5
Training loss: 4.003230094909668
Validation loss: 3.648555112141435

Epoch: 5| Step: 6
Training loss: 4.304868698120117
Validation loss: 3.639627951447682

Epoch: 5| Step: 7
Training loss: 3.3329033851623535
Validation loss: 3.6370614677347164

Epoch: 5| Step: 8
Training loss: 3.232832431793213
Validation loss: 3.633050021304879

Epoch: 5| Step: 9
Training loss: 2.859745979309082
Validation loss: 3.6300106022947576

Epoch: 5| Step: 10
Training loss: 3.203350782394409
Validation loss: 3.624677481189851

Epoch: 10| Step: 0
Training loss: 3.2992846965789795
Validation loss: 3.614965172224147

Epoch: 5| Step: 1
Training loss: 3.361745834350586
Validation loss: 3.6110153121332966

Epoch: 5| Step: 2
Training loss: 3.9164040088653564
Validation loss: 3.6049098353232107

Epoch: 5| Step: 3
Training loss: 3.314648389816284
Validation loss: 3.6001823051001436

Epoch: 5| Step: 4
Training loss: 2.9607343673706055
Validation loss: 3.596608966909429

Epoch: 5| Step: 5
Training loss: 3.7924647331237793
Validation loss: 3.5906815272505566

Epoch: 5| Step: 6
Training loss: 4.876641750335693
Validation loss: 3.587233246013682

Epoch: 5| Step: 7
Training loss: 2.672344446182251
Validation loss: 3.5781951873533187

Epoch: 5| Step: 8
Training loss: 3.5984275341033936
Validation loss: 3.5734659779456353

Epoch: 5| Step: 9
Training loss: 3.608349561691284
Validation loss: 3.569653329028878

Epoch: 5| Step: 10
Training loss: 3.2072832584381104
Validation loss: 3.5660338171066774

Epoch: 11| Step: 0
Training loss: 3.3794665336608887
Validation loss: 3.5619817074909004

Epoch: 5| Step: 1
Training loss: 3.9721763134002686
Validation loss: 3.558106432678879

Epoch: 5| Step: 2
Training loss: 3.7120368480682373
Validation loss: 3.550358890205301

Epoch: 5| Step: 3
Training loss: 3.506931781768799
Validation loss: 3.5421799126491753

Epoch: 5| Step: 4
Training loss: 3.4772896766662598
Validation loss: 3.540068969931654

Epoch: 5| Step: 5
Training loss: 2.761542797088623
Validation loss: 3.536783597802603

Epoch: 5| Step: 6
Training loss: 4.30753231048584
Validation loss: 3.5334749888348322

Epoch: 5| Step: 7
Training loss: 2.762803077697754
Validation loss: 3.5281379069051435

Epoch: 5| Step: 8
Training loss: 3.934751033782959
Validation loss: 3.5231963511436217

Epoch: 5| Step: 9
Training loss: 3.15971302986145
Validation loss: 3.514570046496648

Epoch: 5| Step: 10
Training loss: 3.1094374656677246
Validation loss: 3.5128778590950915

Epoch: 12| Step: 0
Training loss: 2.6346278190612793
Validation loss: 3.51062169126285

Epoch: 5| Step: 1
Training loss: 4.310533046722412
Validation loss: 3.505947715492659

Epoch: 5| Step: 2
Training loss: 4.361763954162598
Validation loss: 3.499428246610908

Epoch: 5| Step: 3
Training loss: 3.212458848953247
Validation loss: 3.4952383195200274

Epoch: 5| Step: 4
Training loss: 3.2959322929382324
Validation loss: 3.4927339476923787

Epoch: 5| Step: 5
Training loss: 3.149597644805908
Validation loss: 3.49195997945724

Epoch: 5| Step: 6
Training loss: 3.8963241577148438
Validation loss: 3.4865614521887993

Epoch: 5| Step: 7
Training loss: 3.5441977977752686
Validation loss: 3.480149176812941

Epoch: 5| Step: 8
Training loss: 2.817183256149292
Validation loss: 3.4741272644330095

Epoch: 5| Step: 9
Training loss: 3.003570318222046
Validation loss: 3.4690155265151814

Epoch: 5| Step: 10
Training loss: 3.479541301727295
Validation loss: 3.467861362682876

Epoch: 13| Step: 0
Training loss: 3.165508270263672
Validation loss: 3.46425961935392

Epoch: 5| Step: 1
Training loss: 2.3605926036834717
Validation loss: 3.4630600406277563

Epoch: 5| Step: 2
Training loss: 4.122454643249512
Validation loss: 3.458461061600716

Epoch: 5| Step: 3
Training loss: 3.8726749420166016
Validation loss: 3.453728675842285

Epoch: 5| Step: 4
Training loss: 3.5162882804870605
Validation loss: 3.452626520587552

Epoch: 5| Step: 5
Training loss: 2.975860595703125
Validation loss: 3.4465278810070408

Epoch: 5| Step: 6
Training loss: 4.136960029602051
Validation loss: 3.4442349198043987

Epoch: 5| Step: 7
Training loss: 3.254281520843506
Validation loss: 3.4413387467784267

Epoch: 5| Step: 8
Training loss: 4.2377519607543945
Validation loss: 3.435556552743399

Epoch: 5| Step: 9
Training loss: 2.6453027725219727
Validation loss: 3.4279244279348724

Epoch: 5| Step: 10
Training loss: 2.9322779178619385
Validation loss: 3.4266788805684736

Epoch: 14| Step: 0
Training loss: 2.8677704334259033
Validation loss: 3.422271195278373

Epoch: 5| Step: 1
Training loss: 3.188243865966797
Validation loss: 3.4139076740511003

Epoch: 5| Step: 2
Training loss: 2.296112298965454
Validation loss: 3.41012284832616

Epoch: 5| Step: 3
Training loss: 4.379906177520752
Validation loss: 3.409204198468116

Epoch: 5| Step: 4
Training loss: 3.1513195037841797
Validation loss: 3.402159124292353

Epoch: 5| Step: 5
Training loss: 2.7999396324157715
Validation loss: 3.3932531264520462

Epoch: 5| Step: 6
Training loss: 3.227130889892578
Validation loss: 3.3888552727237826

Epoch: 5| Step: 7
Training loss: 4.024964809417725
Validation loss: 3.3867658645875993

Epoch: 5| Step: 8
Training loss: 4.259153366088867
Validation loss: 3.383162244673698

Epoch: 5| Step: 9
Training loss: 4.065237045288086
Validation loss: 3.3803811073303223

Epoch: 5| Step: 10
Training loss: 2.432720422744751
Validation loss: 3.37793134104821

Epoch: 15| Step: 0
Training loss: 3.9410080909729004
Validation loss: 3.382511123534172

Epoch: 5| Step: 1
Training loss: 2.4222888946533203
Validation loss: 3.379869868678431

Epoch: 5| Step: 2
Training loss: 3.334594249725342
Validation loss: 3.367177168528239

Epoch: 5| Step: 3
Training loss: 3.8846828937530518
Validation loss: 3.3696078228694137

Epoch: 5| Step: 4
Training loss: 3.250666856765747
Validation loss: 3.3628532630141064

Epoch: 5| Step: 5
Training loss: 3.3923134803771973
Validation loss: 3.3523973188092633

Epoch: 5| Step: 6
Training loss: 2.5002052783966064
Validation loss: 3.3536139047274025

Epoch: 5| Step: 7
Training loss: 3.983039140701294
Validation loss: 3.3545563067159345

Epoch: 5| Step: 8
Training loss: 3.196824312210083
Validation loss: 3.3557206379470004

Epoch: 5| Step: 9
Training loss: 4.236478805541992
Validation loss: 3.3491212168047504

Epoch: 5| Step: 10
Training loss: 2.1947171688079834
Validation loss: 3.3414472251810055

Epoch: 16| Step: 0
Training loss: 2.8262710571289062
Validation loss: 3.3397166652064167

Epoch: 5| Step: 1
Training loss: 3.2265892028808594
Validation loss: 3.3408775893590783

Epoch: 5| Step: 2
Training loss: 2.2909042835235596
Validation loss: 3.334897343830396

Epoch: 5| Step: 3
Training loss: 3.497509717941284
Validation loss: 3.3287143553456953

Epoch: 5| Step: 4
Training loss: 3.6131012439727783
Validation loss: 3.327433132356213

Epoch: 5| Step: 5
Training loss: 4.295146465301514
Validation loss: 3.3212145759213354

Epoch: 5| Step: 6
Training loss: 2.7504818439483643
Validation loss: 3.317874849483531

Epoch: 5| Step: 7
Training loss: 3.775308609008789
Validation loss: 3.313083989645845

Epoch: 5| Step: 8
Training loss: 3.4740002155303955
Validation loss: 3.311459841266755

Epoch: 5| Step: 9
Training loss: 3.520444393157959
Validation loss: 3.3113840036494757

Epoch: 5| Step: 10
Training loss: 2.8239428997039795
Validation loss: 3.303386193449779

Epoch: 17| Step: 0
Training loss: 3.2876830101013184
Validation loss: 3.299984916563957

Epoch: 5| Step: 1
Training loss: 3.4946601390838623
Validation loss: 3.2955761724902737

Epoch: 5| Step: 2
Training loss: 4.849903583526611
Validation loss: 3.290910877207274

Epoch: 5| Step: 3
Training loss: 3.670029401779175
Validation loss: 3.2897030999583583

Epoch: 5| Step: 4
Training loss: 3.3848133087158203
Validation loss: 3.2810243816785913

Epoch: 5| Step: 5
Training loss: 2.3967669010162354
Validation loss: 3.278562207375803

Epoch: 5| Step: 6
Training loss: 3.353363037109375
Validation loss: 3.280502050153671

Epoch: 5| Step: 7
Training loss: 2.7033088207244873
Validation loss: 3.274876004906111

Epoch: 5| Step: 8
Training loss: 3.247143507003784
Validation loss: 3.2744617077612106

Epoch: 5| Step: 9
Training loss: 2.553631544113159
Validation loss: 3.26964811612201

Epoch: 5| Step: 10
Training loss: 2.838334083557129
Validation loss: 3.265926132919968

Epoch: 18| Step: 0
Training loss: 3.4591574668884277
Validation loss: 3.262526507018715

Epoch: 5| Step: 1
Training loss: 2.9632771015167236
Validation loss: 3.2589634131359797

Epoch: 5| Step: 2
Training loss: 3.4420552253723145
Validation loss: 3.2587067388719126

Epoch: 5| Step: 3
Training loss: 2.8781771659851074
Validation loss: 3.254171822660713

Epoch: 5| Step: 4
Training loss: 2.902937650680542
Validation loss: 3.258434000835624

Epoch: 5| Step: 5
Training loss: 3.3973755836486816
Validation loss: 3.2494802039156676

Epoch: 5| Step: 6
Training loss: 3.1936092376708984
Validation loss: 3.2464126668950564

Epoch: 5| Step: 7
Training loss: 2.445087194442749
Validation loss: 3.2418047074348695

Epoch: 5| Step: 8
Training loss: 3.795673370361328
Validation loss: 3.2358685565251175

Epoch: 5| Step: 9
Training loss: 3.2232983112335205
Validation loss: 3.233156640042541

Epoch: 5| Step: 10
Training loss: 3.931406021118164
Validation loss: 3.2296737060751965

Epoch: 19| Step: 0
Training loss: 3.712451934814453
Validation loss: 3.2475885703999507

Epoch: 5| Step: 1
Training loss: 3.3978888988494873
Validation loss: 3.223639101110479

Epoch: 5| Step: 2
Training loss: 2.5860259532928467
Validation loss: 3.224260212272726

Epoch: 5| Step: 3
Training loss: 3.531621217727661
Validation loss: 3.2281515136841805

Epoch: 5| Step: 4
Training loss: 3.416411876678467
Validation loss: 3.227570882407568

Epoch: 5| Step: 5
Training loss: 4.370333671569824
Validation loss: 3.224182903125722

Epoch: 5| Step: 6
Training loss: 2.9213597774505615
Validation loss: 3.2160496891185804

Epoch: 5| Step: 7
Training loss: 2.263207197189331
Validation loss: 3.211208930579565

Epoch: 5| Step: 8
Training loss: 2.897752285003662
Validation loss: 3.2128581846913984

Epoch: 5| Step: 9
Training loss: 2.778961658477783
Validation loss: 3.2079319543735956

Epoch: 5| Step: 10
Training loss: 3.496260643005371
Validation loss: 3.2060238904850458

Epoch: 20| Step: 0
Training loss: 3.5784249305725098
Validation loss: 3.2049199714455554

Epoch: 5| Step: 1
Training loss: 2.824415683746338
Validation loss: 3.196910806881484

Epoch: 5| Step: 2
Training loss: 3.5151207447052
Validation loss: 3.197361739732886

Epoch: 5| Step: 3
Training loss: 2.950392246246338
Validation loss: 3.1933167724199194

Epoch: 5| Step: 4
Training loss: 4.331620216369629
Validation loss: 3.192693853891024

Epoch: 5| Step: 5
Training loss: 3.2373898029327393
Validation loss: 3.195147281051964

Epoch: 5| Step: 6
Training loss: 2.35267972946167
Validation loss: 3.191861044976019

Epoch: 5| Step: 7
Training loss: 3.3714778423309326
Validation loss: 3.184705483016147

Epoch: 5| Step: 8
Training loss: 2.6573760509490967
Validation loss: 3.1837630169365996

Epoch: 5| Step: 9
Training loss: 2.921421527862549
Validation loss: 3.183163542901316

Epoch: 5| Step: 10
Training loss: 3.43308424949646
Validation loss: 3.208757754295103

Epoch: 21| Step: 0
Training loss: 3.9828765392303467
Validation loss: 3.177320170146163

Epoch: 5| Step: 1
Training loss: 3.4468371868133545
Validation loss: 3.1928053004767305

Epoch: 5| Step: 2
Training loss: 3.320754289627075
Validation loss: 3.2026455402374268

Epoch: 5| Step: 3
Training loss: 2.9973068237304688
Validation loss: 3.1944114931168093

Epoch: 5| Step: 4
Training loss: 2.691354751586914
Validation loss: 3.180190558074623

Epoch: 5| Step: 5
Training loss: 3.10463547706604
Validation loss: 3.172948081006286

Epoch: 5| Step: 6
Training loss: 2.762180805206299
Validation loss: 3.1718794966256745

Epoch: 5| Step: 7
Training loss: 3.4543118476867676
Validation loss: 3.1865772585715018

Epoch: 5| Step: 8
Training loss: 3.2731246948242188
Validation loss: 3.167810191390335

Epoch: 5| Step: 9
Training loss: 3.084641933441162
Validation loss: 3.1664657464591404

Epoch: 5| Step: 10
Training loss: 2.8983283042907715
Validation loss: 3.164681552558817

Epoch: 22| Step: 0
Training loss: 3.803131580352783
Validation loss: 3.163379784553282

Epoch: 5| Step: 1
Training loss: 3.5452053546905518
Validation loss: 3.1615327660755446

Epoch: 5| Step: 2
Training loss: 2.6521458625793457
Validation loss: 3.158716188964023

Epoch: 5| Step: 3
Training loss: 3.8422482013702393
Validation loss: 3.1577427925602084

Epoch: 5| Step: 4
Training loss: 2.8433918952941895
Validation loss: 3.1535145416054675

Epoch: 5| Step: 5
Training loss: 2.8542933464050293
Validation loss: 3.1515150788009807

Epoch: 5| Step: 6
Training loss: 3.366046905517578
Validation loss: 3.1469908837349183

Epoch: 5| Step: 7
Training loss: 2.5486416816711426
Validation loss: 3.1440459707731843

Epoch: 5| Step: 8
Training loss: 3.1139941215515137
Validation loss: 3.1397917450115247

Epoch: 5| Step: 9
Training loss: 3.0039336681365967
Validation loss: 3.1401091237221994

Epoch: 5| Step: 10
Training loss: 3.213637113571167
Validation loss: 3.140750592754733

Epoch: 23| Step: 0
Training loss: 2.965176820755005
Validation loss: 3.1367954182368454

Epoch: 5| Step: 1
Training loss: 3.3300442695617676
Validation loss: 3.130539604412612

Epoch: 5| Step: 2
Training loss: 2.843474864959717
Validation loss: 3.1263001708574194

Epoch: 5| Step: 3
Training loss: 2.512322425842285
Validation loss: 3.1220799876797583

Epoch: 5| Step: 4
Training loss: 2.9886202812194824
Validation loss: 3.116593466010145

Epoch: 5| Step: 5
Training loss: 4.183926582336426
Validation loss: 3.1179577881290066

Epoch: 5| Step: 6
Training loss: 3.0740504264831543
Validation loss: 3.115406702923518

Epoch: 5| Step: 7
Training loss: 2.9727354049682617
Validation loss: 3.112773028753137

Epoch: 5| Step: 8
Training loss: 3.0643467903137207
Validation loss: 3.1055915637682845

Epoch: 5| Step: 9
Training loss: 3.4173412322998047
Validation loss: 3.103658381328788

Epoch: 5| Step: 10
Training loss: 3.1891188621520996
Validation loss: 3.0978956965989966

Epoch: 24| Step: 0
Training loss: 2.8026795387268066
Validation loss: 3.097112291602678

Epoch: 5| Step: 1
Training loss: 2.800706386566162
Validation loss: 3.096728547926872

Epoch: 5| Step: 2
Training loss: 3.138701915740967
Validation loss: 3.09681640132781

Epoch: 5| Step: 3
Training loss: 2.432004451751709
Validation loss: 3.0986728411848827

Epoch: 5| Step: 4
Training loss: 3.4627747535705566
Validation loss: 3.0933489620044665

Epoch: 5| Step: 5
Training loss: 3.549837589263916
Validation loss: 3.0894031127293906

Epoch: 5| Step: 6
Training loss: 3.2899177074432373
Validation loss: 3.0881704361208024

Epoch: 5| Step: 7
Training loss: 2.4860870838165283
Validation loss: 3.0845565180624686

Epoch: 5| Step: 8
Training loss: 3.1339237689971924
Validation loss: 3.0873908330035467

Epoch: 5| Step: 9
Training loss: 3.3167901039123535
Validation loss: 3.0837394575918875

Epoch: 5| Step: 10
Training loss: 4.047014236450195
Validation loss: 3.0774121105030017

Epoch: 25| Step: 0
Training loss: 3.1343753337860107
Validation loss: 3.077300133243684

Epoch: 5| Step: 1
Training loss: 2.6342670917510986
Validation loss: 3.07368044699392

Epoch: 5| Step: 2
Training loss: 4.006993770599365
Validation loss: 3.072922593803816

Epoch: 5| Step: 3
Training loss: 4.014565467834473
Validation loss: 3.071431508628271

Epoch: 5| Step: 4
Training loss: 2.8961856365203857
Validation loss: 3.0707624471315773

Epoch: 5| Step: 5
Training loss: 3.498138427734375
Validation loss: 3.0671128201228317

Epoch: 5| Step: 6
Training loss: 3.1431822776794434
Validation loss: 3.066413402557373

Epoch: 5| Step: 7
Training loss: 2.840761661529541
Validation loss: 3.0639654846601587

Epoch: 5| Step: 8
Training loss: 2.71694278717041
Validation loss: 3.0621352400830997

Epoch: 5| Step: 9
Training loss: 2.8748810291290283
Validation loss: 3.0604884316844325

Epoch: 5| Step: 10
Training loss: 2.2999374866485596
Validation loss: 3.064470737211166

Epoch: 26| Step: 0
Training loss: 3.0294501781463623
Validation loss: 3.0576834294103805

Epoch: 5| Step: 1
Training loss: 3.09682035446167
Validation loss: 3.0571695809723227

Epoch: 5| Step: 2
Training loss: 3.0568044185638428
Validation loss: 3.0535028467896166

Epoch: 5| Step: 3
Training loss: 2.7421727180480957
Validation loss: 3.0549587024155485

Epoch: 5| Step: 4
Training loss: 3.0715928077697754
Validation loss: 3.053581124992781

Epoch: 5| Step: 5
Training loss: 2.587631940841675
Validation loss: 3.0523299965807187

Epoch: 5| Step: 6
Training loss: 4.531866073608398
Validation loss: 3.052848664663171

Epoch: 5| Step: 7
Training loss: 3.213928699493408
Validation loss: 3.050323288927796

Epoch: 5| Step: 8
Training loss: 2.2062301635742188
Validation loss: 3.0474533598910094

Epoch: 5| Step: 9
Training loss: 2.7779107093811035
Validation loss: 3.0473203761603243

Epoch: 5| Step: 10
Training loss: 3.882387399673462
Validation loss: 3.045380566709785

Epoch: 27| Step: 0
Training loss: 3.6891582012176514
Validation loss: 3.0453328906848864

Epoch: 5| Step: 1
Training loss: 2.837909460067749
Validation loss: 3.0431395858846684

Epoch: 5| Step: 2
Training loss: 3.3360862731933594
Validation loss: 3.0437756584536646

Epoch: 5| Step: 3
Training loss: 2.858764171600342
Validation loss: 3.0441244545803277

Epoch: 5| Step: 4
Training loss: 2.7083325386047363
Validation loss: 3.0438084551083144

Epoch: 5| Step: 5
Training loss: 3.162290096282959
Validation loss: 3.040176071146483

Epoch: 5| Step: 6
Training loss: 3.319398880004883
Validation loss: 3.039258780017976

Epoch: 5| Step: 7
Training loss: 3.0977566242218018
Validation loss: 3.0397658783902406

Epoch: 5| Step: 8
Training loss: 2.784397602081299
Validation loss: 3.0357938992079867

Epoch: 5| Step: 9
Training loss: 3.069671154022217
Validation loss: 3.035709047830233

Epoch: 5| Step: 10
Training loss: 3.1433796882629395
Validation loss: 3.036137152743596

Epoch: 28| Step: 0
Training loss: 3.0609123706817627
Validation loss: 3.0365241727521344

Epoch: 5| Step: 1
Training loss: 3.6113903522491455
Validation loss: 3.032997341566188

Epoch: 5| Step: 2
Training loss: 2.770799160003662
Validation loss: 3.0337186577499553

Epoch: 5| Step: 3
Training loss: 3.370007276535034
Validation loss: 3.031124089353828

Epoch: 5| Step: 4
Training loss: 3.1823103427886963
Validation loss: 3.0312686299764984

Epoch: 5| Step: 5
Training loss: 2.2127413749694824
Validation loss: 3.0308104868858092

Epoch: 5| Step: 6
Training loss: 3.1932010650634766
Validation loss: 3.03176196159855

Epoch: 5| Step: 7
Training loss: 2.908029556274414
Validation loss: 3.0288082502221547

Epoch: 5| Step: 8
Training loss: 3.5234596729278564
Validation loss: 3.0289865668101976

Epoch: 5| Step: 9
Training loss: 2.7934136390686035
Validation loss: 3.028424932110694

Epoch: 5| Step: 10
Training loss: 3.3356504440307617
Validation loss: 3.0263213470417965

Epoch: 29| Step: 0
Training loss: 3.352295398712158
Validation loss: 3.026420380479546

Epoch: 5| Step: 1
Training loss: 3.4644546508789062
Validation loss: 3.0275092612030687

Epoch: 5| Step: 2
Training loss: 3.3759140968322754
Validation loss: 3.023962720747917

Epoch: 5| Step: 3
Training loss: 2.844982862472534
Validation loss: 3.024191548747401

Epoch: 5| Step: 4
Training loss: 2.6104094982147217
Validation loss: 3.0245413677666777

Epoch: 5| Step: 5
Training loss: 3.0837173461914062
Validation loss: 3.024812408672866

Epoch: 5| Step: 6
Training loss: 3.143592357635498
Validation loss: 3.0211279725515716

Epoch: 5| Step: 7
Training loss: 3.355304002761841
Validation loss: 3.0214574285732803

Epoch: 5| Step: 8
Training loss: 3.2785866260528564
Validation loss: 3.0194773981648106

Epoch: 5| Step: 9
Training loss: 3.2519593238830566
Validation loss: 3.017640439412927

Epoch: 5| Step: 10
Training loss: 1.9217625856399536
Validation loss: 3.0169546860520557

Epoch: 30| Step: 0
Training loss: 3.0176663398742676
Validation loss: 3.015918413798014

Epoch: 5| Step: 1
Training loss: 3.553555965423584
Validation loss: 3.018270866845244

Epoch: 5| Step: 2
Training loss: 2.6208651065826416
Validation loss: 3.0148641883686023

Epoch: 5| Step: 3
Training loss: 2.3549060821533203
Validation loss: 3.013247513001965

Epoch: 5| Step: 4
Training loss: 2.7199337482452393
Validation loss: 3.0122366515539025

Epoch: 5| Step: 5
Training loss: 2.377622127532959
Validation loss: 3.010453362618723

Epoch: 5| Step: 6
Training loss: 2.940944194793701
Validation loss: 3.0093973349499445

Epoch: 5| Step: 7
Training loss: 3.55011248588562
Validation loss: 3.0085221182915474

Epoch: 5| Step: 8
Training loss: 3.986967086791992
Validation loss: 3.0062702932665424

Epoch: 5| Step: 9
Training loss: 3.4707446098327637
Validation loss: 3.0054639513774584

Epoch: 5| Step: 10
Training loss: 3.2080790996551514
Validation loss: 3.0066518296477613

Epoch: 31| Step: 0
Training loss: 2.837371587753296
Validation loss: 3.0050453216798845

Epoch: 5| Step: 1
Training loss: 4.112360000610352
Validation loss: 3.0009443965009464

Epoch: 5| Step: 2
Training loss: 2.9413983821868896
Validation loss: 2.997727435122254

Epoch: 5| Step: 3
Training loss: 2.8090872764587402
Validation loss: 3.0005885862535044

Epoch: 5| Step: 4
Training loss: 2.6210649013519287
Validation loss: 3.0004157712382655

Epoch: 5| Step: 5
Training loss: 3.284165620803833
Validation loss: 2.9993973034684376

Epoch: 5| Step: 6
Training loss: 3.6173062324523926
Validation loss: 2.994845341610652

Epoch: 5| Step: 7
Training loss: 3.326223850250244
Validation loss: 2.990209746104415

Epoch: 5| Step: 8
Training loss: 2.4068198204040527
Validation loss: 2.9908658509613364

Epoch: 5| Step: 9
Training loss: 2.1127495765686035
Validation loss: 2.9916684089168424

Epoch: 5| Step: 10
Training loss: 3.6964547634124756
Validation loss: 2.9887176354726157

Epoch: 32| Step: 0
Training loss: 2.7037322521209717
Validation loss: 2.9892373725932133

Epoch: 5| Step: 1
Training loss: 2.0922775268554688
Validation loss: 2.9903160423360844

Epoch: 5| Step: 2
Training loss: 2.995702028274536
Validation loss: 2.9888636937705417

Epoch: 5| Step: 3
Training loss: 3.3358089923858643
Validation loss: 2.990000558155839

Epoch: 5| Step: 4
Training loss: 2.7125837802886963
Validation loss: 2.9856161455954275

Epoch: 5| Step: 5
Training loss: 3.022852897644043
Validation loss: 2.9838453236446587

Epoch: 5| Step: 6
Training loss: 3.0367603302001953
Validation loss: 2.984740746918545

Epoch: 5| Step: 7
Training loss: 2.943408489227295
Validation loss: 2.9896603835526334

Epoch: 5| Step: 8
Training loss: 3.7879409790039062
Validation loss: 2.993120108881304

Epoch: 5| Step: 9
Training loss: 3.885190486907959
Validation loss: 2.9841823475335234

Epoch: 5| Step: 10
Training loss: 3.074887990951538
Validation loss: 2.978059930186118

Epoch: 33| Step: 0
Training loss: 3.0966439247131348
Validation loss: 2.977815079432662

Epoch: 5| Step: 1
Training loss: 2.8421616554260254
Validation loss: 2.9783971796753588

Epoch: 5| Step: 2
Training loss: 3.3103537559509277
Validation loss: 2.9786457374531734

Epoch: 5| Step: 3
Training loss: 3.22583270072937
Validation loss: 2.9782091571438696

Epoch: 5| Step: 4
Training loss: 3.5089645385742188
Validation loss: 2.979758924053561

Epoch: 5| Step: 5
Training loss: 3.1324570178985596
Validation loss: 2.977447622565813

Epoch: 5| Step: 6
Training loss: 2.9100637435913086
Validation loss: 2.97549420274714

Epoch: 5| Step: 7
Training loss: 2.744812488555908
Validation loss: 2.9712969718440885

Epoch: 5| Step: 8
Training loss: 2.34210205078125
Validation loss: 2.9696742591037544

Epoch: 5| Step: 9
Training loss: 3.0196449756622314
Validation loss: 2.9654439495455835

Epoch: 5| Step: 10
Training loss: 3.4548873901367188
Validation loss: 2.966268365101148

Epoch: 34| Step: 0
Training loss: 2.79746150970459
Validation loss: 2.9642197931966474

Epoch: 5| Step: 1
Training loss: 3.196201801300049
Validation loss: 2.966065183762581

Epoch: 5| Step: 2
Training loss: 2.6393465995788574
Validation loss: 2.9668842977093113

Epoch: 5| Step: 3
Training loss: 3.577414035797119
Validation loss: 2.9662084656376995

Epoch: 5| Step: 4
Training loss: 3.2311692237854004
Validation loss: 2.964548715981104

Epoch: 5| Step: 5
Training loss: 2.769042491912842
Validation loss: 2.9592218040138163

Epoch: 5| Step: 6
Training loss: 3.208219528198242
Validation loss: 2.9585594259282595

Epoch: 5| Step: 7
Training loss: 3.39436674118042
Validation loss: 2.954618054051553

Epoch: 5| Step: 8
Training loss: 2.566598892211914
Validation loss: 2.956781292474398

Epoch: 5| Step: 9
Training loss: 3.4856066703796387
Validation loss: 2.959237560149162

Epoch: 5| Step: 10
Training loss: 2.4758832454681396
Validation loss: 2.956710087355747

Epoch: 35| Step: 0
Training loss: 3.0783069133758545
Validation loss: 2.953341127723776

Epoch: 5| Step: 1
Training loss: 2.300658702850342
Validation loss: 2.9541984476068968

Epoch: 5| Step: 2
Training loss: 2.8293280601501465
Validation loss: 2.9552203916734263

Epoch: 5| Step: 3
Training loss: 3.1427788734436035
Validation loss: 2.951383290752288

Epoch: 5| Step: 4
Training loss: 3.349011182785034
Validation loss: 2.9500968328086277

Epoch: 5| Step: 5
Training loss: 3.218398332595825
Validation loss: 2.9516162282677105

Epoch: 5| Step: 6
Training loss: 3.1272525787353516
Validation loss: 2.9522551234050463

Epoch: 5| Step: 7
Training loss: 2.685243844985962
Validation loss: 2.9487332964456208

Epoch: 5| Step: 8
Training loss: 3.2616939544677734
Validation loss: 2.946889485082319

Epoch: 5| Step: 9
Training loss: 3.3901963233947754
Validation loss: 2.945920621195147

Epoch: 5| Step: 10
Training loss: 2.9275894165039062
Validation loss: 2.947427488142444

Epoch: 36| Step: 0
Training loss: 2.9334750175476074
Validation loss: 2.9445552415745233

Epoch: 5| Step: 1
Training loss: 2.9867606163024902
Validation loss: 2.9461395971236692

Epoch: 5| Step: 2
Training loss: 3.4243736267089844
Validation loss: 2.9439073993313696

Epoch: 5| Step: 3
Training loss: 3.1799283027648926
Validation loss: 2.945912309872207

Epoch: 5| Step: 4
Training loss: 3.153618812561035
Validation loss: 2.9401452079896004

Epoch: 5| Step: 5
Training loss: 3.2564125061035156
Validation loss: 2.941789460438554

Epoch: 5| Step: 6
Training loss: 2.11149263381958
Validation loss: 2.9419847867822133

Epoch: 5| Step: 7
Training loss: 3.4050021171569824
Validation loss: 2.941753033668764

Epoch: 5| Step: 8
Training loss: 2.6075947284698486
Validation loss: 2.9414224880997852

Epoch: 5| Step: 9
Training loss: 3.076648712158203
Validation loss: 2.939089262357322

Epoch: 5| Step: 10
Training loss: 3.1775033473968506
Validation loss: 2.9413393338521323

Epoch: 37| Step: 0
Training loss: 3.2182910442352295
Validation loss: 2.939202585527974

Epoch: 5| Step: 1
Training loss: 3.7350316047668457
Validation loss: 2.9363515300135457

Epoch: 5| Step: 2
Training loss: 2.9325997829437256
Validation loss: 2.9369715695740073

Epoch: 5| Step: 3
Training loss: 3.2383885383605957
Validation loss: 2.932018223629203

Epoch: 5| Step: 4
Training loss: 2.549340009689331
Validation loss: 2.9366502018385034

Epoch: 5| Step: 5
Training loss: 2.6619949340820312
Validation loss: 2.937731606985933

Epoch: 5| Step: 6
Training loss: 3.486180543899536
Validation loss: 2.937913679307507

Epoch: 5| Step: 7
Training loss: 2.535675287246704
Validation loss: 2.934007929217431

Epoch: 5| Step: 8
Training loss: 3.035418748855591
Validation loss: 2.933342359399283

Epoch: 5| Step: 9
Training loss: 3.1743855476379395
Validation loss: 2.9314344467655307

Epoch: 5| Step: 10
Training loss: 2.595435857772827
Validation loss: 2.931876459429341

Epoch: 38| Step: 0
Training loss: 2.8852455615997314
Validation loss: 2.9360134345228954

Epoch: 5| Step: 1
Training loss: 3.100167751312256
Validation loss: 2.9321318082911993

Epoch: 5| Step: 2
Training loss: 3.79351806640625
Validation loss: 2.9342776729214575

Epoch: 5| Step: 3
Training loss: 3.764423370361328
Validation loss: 2.930960096338744

Epoch: 5| Step: 4
Training loss: 2.866258144378662
Validation loss: 2.9284968042886383

Epoch: 5| Step: 5
Training loss: 3.432396650314331
Validation loss: 2.932130052197364

Epoch: 5| Step: 6
Training loss: 2.9858171939849854
Validation loss: 2.9315057441752446

Epoch: 5| Step: 7
Training loss: 2.918287754058838
Validation loss: 2.9268726482186267

Epoch: 5| Step: 8
Training loss: 2.25028657913208
Validation loss: 2.929151096651631

Epoch: 5| Step: 9
Training loss: 2.5422780513763428
Validation loss: 2.9254133701324463

Epoch: 5| Step: 10
Training loss: 2.579765796661377
Validation loss: 2.9243331775870374

Epoch: 39| Step: 0
Training loss: 2.7598814964294434
Validation loss: 2.92370698272541

Epoch: 5| Step: 1
Training loss: 3.3642678260803223
Validation loss: 2.924107315719769

Epoch: 5| Step: 2
Training loss: 3.9655280113220215
Validation loss: 2.9254124523490987

Epoch: 5| Step: 3
Training loss: 2.6360435485839844
Validation loss: 2.922580826667047

Epoch: 5| Step: 4
Training loss: 2.198378086090088
Validation loss: 2.922634837447956

Epoch: 5| Step: 5
Training loss: 3.0773348808288574
Validation loss: 2.919808259574316

Epoch: 5| Step: 6
Training loss: 2.94148325920105
Validation loss: 2.9197886400325324

Epoch: 5| Step: 7
Training loss: 2.277181625366211
Validation loss: 2.9217082095402542

Epoch: 5| Step: 8
Training loss: 3.0406367778778076
Validation loss: 2.920825389123732

Epoch: 5| Step: 9
Training loss: 4.013763427734375
Validation loss: 2.92149846271802

Epoch: 5| Step: 10
Training loss: 2.8267269134521484
Validation loss: 2.9289419471576648

Epoch: 40| Step: 0
Training loss: 3.9233901500701904
Validation loss: 2.929785600272558

Epoch: 5| Step: 1
Training loss: 3.3938896656036377
Validation loss: 2.9260805268441477

Epoch: 5| Step: 2
Training loss: 3.2788238525390625
Validation loss: 2.9212725777779855

Epoch: 5| Step: 3
Training loss: 2.2922439575195312
Validation loss: 2.916938417701311

Epoch: 5| Step: 4
Training loss: 2.8082618713378906
Validation loss: 2.9150086705402662

Epoch: 5| Step: 5
Training loss: 3.4461135864257812
Validation loss: 2.9136353564518753

Epoch: 5| Step: 6
Training loss: 3.232151508331299
Validation loss: 2.912324828486289

Epoch: 5| Step: 7
Training loss: 2.877121925354004
Validation loss: 2.9094486877482426

Epoch: 5| Step: 8
Training loss: 2.570718288421631
Validation loss: 2.90830224303789

Epoch: 5| Step: 9
Training loss: 2.5691142082214355
Validation loss: 2.907397413766512

Epoch: 5| Step: 10
Training loss: 2.6101253032684326
Validation loss: 2.9070840343352287

Epoch: 41| Step: 0
Training loss: 2.762012004852295
Validation loss: 2.904622459924349

Epoch: 5| Step: 1
Training loss: 2.7101407051086426
Validation loss: 2.9068262013055945

Epoch: 5| Step: 2
Training loss: 2.490999221801758
Validation loss: 2.9007341220814693

Epoch: 5| Step: 3
Training loss: 3.1214356422424316
Validation loss: 2.9121315684369815

Epoch: 5| Step: 4
Training loss: 3.6815972328186035
Validation loss: 2.930534070537936

Epoch: 5| Step: 5
Training loss: 3.1458230018615723
Validation loss: 2.923410713031728

Epoch: 5| Step: 6
Training loss: 2.625913619995117
Validation loss: 2.904020206902617

Epoch: 5| Step: 7
Training loss: 2.1049141883850098
Validation loss: 2.941866769585558

Epoch: 5| Step: 8
Training loss: 3.589141845703125
Validation loss: 3.009347400357646

Epoch: 5| Step: 9
Training loss: 3.476917266845703
Validation loss: 2.905878764326854

Epoch: 5| Step: 10
Training loss: 3.546666383743286
Validation loss: 2.8978657363563456

Epoch: 42| Step: 0
Training loss: 2.4651217460632324
Validation loss: 2.907154765180362

Epoch: 5| Step: 1
Training loss: 2.4070796966552734
Validation loss: 2.918998836189188

Epoch: 5| Step: 2
Training loss: 3.339820146560669
Validation loss: 2.954968326835222

Epoch: 5| Step: 3
Training loss: 4.059796333312988
Validation loss: 3.0008757729684152

Epoch: 5| Step: 4
Training loss: 2.745331287384033
Validation loss: 2.9736920274713987

Epoch: 5| Step: 5
Training loss: 2.9915764331817627
Validation loss: 2.925417359157275

Epoch: 5| Step: 6
Training loss: 2.590928316116333
Validation loss: 2.8998041768227854

Epoch: 5| Step: 7
Training loss: 3.3103976249694824
Validation loss: 2.895891656157791

Epoch: 5| Step: 8
Training loss: 2.3194046020507812
Validation loss: 2.9044234932109876

Epoch: 5| Step: 9
Training loss: 3.3813483715057373
Validation loss: 2.9119769065610823

Epoch: 5| Step: 10
Training loss: 3.661363124847412
Validation loss: 2.9699704339427333

Epoch: 43| Step: 0
Training loss: 2.7429680824279785
Validation loss: 3.0030262598427395

Epoch: 5| Step: 1
Training loss: 3.808910846710205
Validation loss: 2.985165642153832

Epoch: 5| Step: 2
Training loss: 3.162018060684204
Validation loss: 2.9050868608618297

Epoch: 5| Step: 3
Training loss: 2.3411107063293457
Validation loss: 2.89277474341854

Epoch: 5| Step: 4
Training loss: 3.449842929840088
Validation loss: 2.896178614708685

Epoch: 5| Step: 5
Training loss: 3.2414863109588623
Validation loss: 2.894721228589294

Epoch: 5| Step: 6
Training loss: 2.9039461612701416
Validation loss: 2.89700763199919

Epoch: 5| Step: 7
Training loss: 2.342611789703369
Validation loss: 2.908269436128678

Epoch: 5| Step: 8
Training loss: 3.076890707015991
Validation loss: 2.9118147819272933

Epoch: 5| Step: 9
Training loss: 3.7066829204559326
Validation loss: 2.9014256333792083

Epoch: 5| Step: 10
Training loss: 2.2049641609191895
Validation loss: 2.887976474659417

Epoch: 44| Step: 0
Training loss: 3.3585426807403564
Validation loss: 2.893360968559019

Epoch: 5| Step: 1
Training loss: 2.376650333404541
Validation loss: 2.8862658495544107

Epoch: 5| Step: 2
Training loss: 2.5732693672180176
Validation loss: 2.8805693657167497

Epoch: 5| Step: 3
Training loss: 3.03892183303833
Validation loss: 2.883818047021025

Epoch: 5| Step: 4
Training loss: 3.557436466217041
Validation loss: 2.8823882764385593

Epoch: 5| Step: 5
Training loss: 3.793060302734375
Validation loss: 2.8796832817856983

Epoch: 5| Step: 6
Training loss: 3.1609151363372803
Validation loss: 2.878049486426897

Epoch: 5| Step: 7
Training loss: 3.5088400840759277
Validation loss: 2.877183242510724

Epoch: 5| Step: 8
Training loss: 2.5074563026428223
Validation loss: 2.8749717845711658

Epoch: 5| Step: 9
Training loss: 2.066020965576172
Validation loss: 2.8754962464814544

Epoch: 5| Step: 10
Training loss: 2.831951141357422
Validation loss: 2.878780598281532

Epoch: 45| Step: 0
Training loss: 3.476024627685547
Validation loss: 2.8823070449213826

Epoch: 5| Step: 1
Training loss: 2.722527027130127
Validation loss: 2.8845437162665912

Epoch: 5| Step: 2
Training loss: 2.652686357498169
Validation loss: 2.8803352976358063

Epoch: 5| Step: 3
Training loss: 3.5200698375701904
Validation loss: 2.8809798866189937

Epoch: 5| Step: 4
Training loss: 2.5756664276123047
Validation loss: 2.8805619926862818

Epoch: 5| Step: 5
Training loss: 2.784060001373291
Validation loss: 2.873693266222554

Epoch: 5| Step: 6
Training loss: 3.4078662395477295
Validation loss: 2.8740024105195077

Epoch: 5| Step: 7
Training loss: 3.117809772491455
Validation loss: 2.8715764655861804

Epoch: 5| Step: 8
Training loss: 3.100494384765625
Validation loss: 2.8700115860149427

Epoch: 5| Step: 9
Training loss: 2.2684214115142822
Validation loss: 2.870621386394706

Epoch: 5| Step: 10
Training loss: 3.139065742492676
Validation loss: 2.8708843902875016

Epoch: 46| Step: 0
Training loss: 2.5575859546661377
Validation loss: 2.87093158178432

Epoch: 5| Step: 1
Training loss: 2.754526138305664
Validation loss: 2.8689713862634476

Epoch: 5| Step: 2
Training loss: 3.202664852142334
Validation loss: 2.8727466906270673

Epoch: 5| Step: 3
Training loss: 2.8835346698760986
Validation loss: 2.869830678868037

Epoch: 5| Step: 4
Training loss: 2.389646291732788
Validation loss: 2.8749272233696392

Epoch: 5| Step: 5
Training loss: 3.5504469871520996
Validation loss: 2.8786169021360335

Epoch: 5| Step: 6
Training loss: 3.066223621368408
Validation loss: 2.8822097265592186

Epoch: 5| Step: 7
Training loss: 3.1242289543151855
Validation loss: 2.880367173943468

Epoch: 5| Step: 8
Training loss: 3.8042075634002686
Validation loss: 2.8738355687869492

Epoch: 5| Step: 9
Training loss: 2.8553218841552734
Validation loss: 2.8687769623212915

Epoch: 5| Step: 10
Training loss: 2.3862977027893066
Validation loss: 2.8631910867588495

Epoch: 47| Step: 0
Training loss: 3.131012201309204
Validation loss: 2.8640244571111535

Epoch: 5| Step: 1
Training loss: 2.2723331451416016
Validation loss: 2.8623503638852026

Epoch: 5| Step: 2
Training loss: 2.143389940261841
Validation loss: 2.8631399395645305

Epoch: 5| Step: 3
Training loss: 2.7048935890197754
Validation loss: 2.8629355353693806

Epoch: 5| Step: 4
Training loss: 3.4601478576660156
Validation loss: 2.857597038310061

Epoch: 5| Step: 5
Training loss: 3.218395233154297
Validation loss: 2.861459670528289

Epoch: 5| Step: 6
Training loss: 2.724069118499756
Validation loss: 2.856879024095433

Epoch: 5| Step: 7
Training loss: 3.260676622390747
Validation loss: 2.8615463728545816

Epoch: 5| Step: 8
Training loss: 3.1683878898620605
Validation loss: 2.8622129091652493

Epoch: 5| Step: 9
Training loss: 3.124223470687866
Validation loss: 2.85921214472863

Epoch: 5| Step: 10
Training loss: 3.4253408908843994
Validation loss: 2.8573793288200133

Epoch: 48| Step: 0
Training loss: 3.1926722526550293
Validation loss: 2.8593970370549027

Epoch: 5| Step: 1
Training loss: 3.3002872467041016
Validation loss: 2.8574413125232985

Epoch: 5| Step: 2
Training loss: 2.266244411468506
Validation loss: 2.855708263253653

Epoch: 5| Step: 3
Training loss: 3.175715446472168
Validation loss: 2.8634025409657466

Epoch: 5| Step: 4
Training loss: 2.5051279067993164
Validation loss: 2.8660124322419525

Epoch: 5| Step: 5
Training loss: 3.222191572189331
Validation loss: 2.8715037838105233

Epoch: 5| Step: 6
Training loss: 2.880152940750122
Validation loss: 2.874263063553841

Epoch: 5| Step: 7
Training loss: 2.8501267433166504
Validation loss: 2.870773838412377

Epoch: 5| Step: 8
Training loss: 2.8107831478118896
Validation loss: 2.8555625510472122

Epoch: 5| Step: 9
Training loss: 3.6245980262756348
Validation loss: 2.8549139063845397

Epoch: 5| Step: 10
Training loss: 2.6906986236572266
Validation loss: 2.850154240926107

Epoch: 49| Step: 0
Training loss: 2.656543254852295
Validation loss: 2.84887126440643

Epoch: 5| Step: 1
Training loss: 2.482156276702881
Validation loss: 2.8495131359305432

Epoch: 5| Step: 2
Training loss: 2.8794569969177246
Validation loss: 2.846961680278983

Epoch: 5| Step: 3
Training loss: 3.0070130825042725
Validation loss: 2.8484835111966698

Epoch: 5| Step: 4
Training loss: 3.5822110176086426
Validation loss: 2.8435095945994058

Epoch: 5| Step: 5
Training loss: 3.1178956031799316
Validation loss: 2.848127947058729

Epoch: 5| Step: 6
Training loss: 3.2079715728759766
Validation loss: 2.8463726505156486

Epoch: 5| Step: 7
Training loss: 1.8999965190887451
Validation loss: 2.845377770803308

Epoch: 5| Step: 8
Training loss: 3.6451268196105957
Validation loss: 2.8448241679899153

Epoch: 5| Step: 9
Training loss: 2.775702714920044
Validation loss: 2.8425398924017466

Epoch: 5| Step: 10
Training loss: 3.246258020401001
Validation loss: 2.847650656136133

Epoch: 50| Step: 0
Training loss: 2.8853096961975098
Validation loss: 2.8478933047222834

Epoch: 5| Step: 1
Training loss: 2.3627352714538574
Validation loss: 2.854246567654353

Epoch: 5| Step: 2
Training loss: 2.86891508102417
Validation loss: 2.8695329671264975

Epoch: 5| Step: 3
Training loss: 3.2270686626434326
Validation loss: 2.8614788952694146

Epoch: 5| Step: 4
Training loss: 2.8043408393859863
Validation loss: 2.8426613012949624

Epoch: 5| Step: 5
Training loss: 3.8245434761047363
Validation loss: 2.841088330873879

Epoch: 5| Step: 6
Training loss: 3.2134718894958496
Validation loss: 2.838810584878409

Epoch: 5| Step: 7
Training loss: 2.6241824626922607
Validation loss: 2.840125560760498

Epoch: 5| Step: 8
Training loss: 2.9089505672454834
Validation loss: 2.836645910816808

Epoch: 5| Step: 9
Training loss: 3.2212796211242676
Validation loss: 2.839207510794363

Epoch: 5| Step: 10
Training loss: 2.4704995155334473
Validation loss: 2.8375076350345405

Epoch: 51| Step: 0
Training loss: 3.039395570755005
Validation loss: 2.8391503723718787

Epoch: 5| Step: 1
Training loss: 2.6557040214538574
Validation loss: 2.839661708442114

Epoch: 5| Step: 2
Training loss: 3.098116636276245
Validation loss: 2.846456722546649

Epoch: 5| Step: 3
Training loss: 3.471806764602661
Validation loss: 2.8361921746243715

Epoch: 5| Step: 4
Training loss: 3.321195125579834
Validation loss: 2.840351458518736

Epoch: 5| Step: 5
Training loss: 3.1447882652282715
Validation loss: 2.8372517503717893

Epoch: 5| Step: 6
Training loss: 2.8366026878356934
Validation loss: 2.8367630794484127

Epoch: 5| Step: 7
Training loss: 2.7849655151367188
Validation loss: 2.8363010216784734

Epoch: 5| Step: 8
Training loss: 2.5284478664398193
Validation loss: 2.83792693127868

Epoch: 5| Step: 9
Training loss: 2.782316207885742
Validation loss: 2.8383338041202997

Epoch: 5| Step: 10
Training loss: 2.662130355834961
Validation loss: 2.8382795856844996

Epoch: 52| Step: 0
Training loss: 2.945338010787964
Validation loss: 2.845959463427144

Epoch: 5| Step: 1
Training loss: 2.88189959526062
Validation loss: 2.8356161630281838

Epoch: 5| Step: 2
Training loss: 3.0024123191833496
Validation loss: 2.8326163394476778

Epoch: 5| Step: 3
Training loss: 2.1652538776397705
Validation loss: 2.833074059537662

Epoch: 5| Step: 4
Training loss: 3.314795970916748
Validation loss: 2.8322522281318583

Epoch: 5| Step: 5
Training loss: 2.5146687030792236
Validation loss: 2.836781153114893

Epoch: 5| Step: 6
Training loss: 3.1435627937316895
Validation loss: 2.8343849976857505

Epoch: 5| Step: 7
Training loss: 3.617903232574463
Validation loss: 2.8362744341614428

Epoch: 5| Step: 8
Training loss: 3.1173133850097656
Validation loss: 2.8381531982011694

Epoch: 5| Step: 9
Training loss: 2.8308658599853516
Validation loss: 2.839508628332487

Epoch: 5| Step: 10
Training loss: 2.8147268295288086
Validation loss: 2.83573156274775

Epoch: 53| Step: 0
Training loss: 2.6419413089752197
Validation loss: 2.8362818071919103

Epoch: 5| Step: 1
Training loss: 3.3121700286865234
Validation loss: 2.841398944136917

Epoch: 5| Step: 2
Training loss: 2.958747386932373
Validation loss: 2.841598146705217

Epoch: 5| Step: 3
Training loss: 3.9370827674865723
Validation loss: 2.838880992704822

Epoch: 5| Step: 4
Training loss: 3.101274013519287
Validation loss: 2.843451894739623

Epoch: 5| Step: 5
Training loss: 2.450979471206665
Validation loss: 2.8374716184472524

Epoch: 5| Step: 6
Training loss: 2.789590835571289
Validation loss: 2.837325544767482

Epoch: 5| Step: 7
Training loss: 3.1189048290252686
Validation loss: 2.8335595233466035

Epoch: 5| Step: 8
Training loss: 2.900291919708252
Validation loss: 2.8353465218697824

Epoch: 5| Step: 9
Training loss: 2.6369640827178955
Validation loss: 2.832697909365418

Epoch: 5| Step: 10
Training loss: 2.381056785583496
Validation loss: 2.824654371507706

Epoch: 54| Step: 0
Training loss: 2.9318573474884033
Validation loss: 2.8310799957603536

Epoch: 5| Step: 1
Training loss: 2.8834612369537354
Validation loss: 2.8263043101115892

Epoch: 5| Step: 2
Training loss: 2.2098793983459473
Validation loss: 2.826766226881294

Epoch: 5| Step: 3
Training loss: 3.4627017974853516
Validation loss: 2.8288085947754564

Epoch: 5| Step: 4
Training loss: 2.9366393089294434
Validation loss: 2.8294564139458442

Epoch: 5| Step: 5
Training loss: 2.851566791534424
Validation loss: 2.825238525226552

Epoch: 5| Step: 6
Training loss: 3.015146017074585
Validation loss: 2.82079037286902

Epoch: 5| Step: 7
Training loss: 2.869393825531006
Validation loss: 2.8242283354523363

Epoch: 5| Step: 8
Training loss: 3.082181215286255
Validation loss: 2.821579702438847

Epoch: 5| Step: 9
Training loss: 2.534914016723633
Validation loss: 2.8195689134700324

Epoch: 5| Step: 10
Training loss: 3.5679402351379395
Validation loss: 2.825969034625638

Epoch: 55| Step: 0
Training loss: 2.43489408493042
Validation loss: 2.8227847289013606

Epoch: 5| Step: 1
Training loss: 2.7004876136779785
Validation loss: 2.8255442880815074

Epoch: 5| Step: 2
Training loss: 3.6130142211914062
Validation loss: 2.8355881424360376

Epoch: 5| Step: 3
Training loss: 2.8104591369628906
Validation loss: 2.8495621988850255

Epoch: 5| Step: 4
Training loss: 2.2172791957855225
Validation loss: 2.840964645467779

Epoch: 5| Step: 5
Training loss: 2.985975742340088
Validation loss: 2.8386317991441294

Epoch: 5| Step: 6
Training loss: 3.61175274848938
Validation loss: 2.8435054543197795

Epoch: 5| Step: 7
Training loss: 2.356379985809326
Validation loss: 2.8278139611726165

Epoch: 5| Step: 8
Training loss: 2.9961652755737305
Validation loss: 2.822484741928757

Epoch: 5| Step: 9
Training loss: 3.1216187477111816
Validation loss: 2.821711701731528

Epoch: 5| Step: 10
Training loss: 3.4605605602264404
Validation loss: 2.819350319523965

Epoch: 56| Step: 0
Training loss: 3.3352394104003906
Validation loss: 2.8141758595743487

Epoch: 5| Step: 1
Training loss: 2.596306085586548
Validation loss: 2.819892724355062

Epoch: 5| Step: 2
Training loss: 2.846626043319702
Validation loss: 2.815554570126277

Epoch: 5| Step: 3
Training loss: 3.086101531982422
Validation loss: 2.8153631712800715

Epoch: 5| Step: 4
Training loss: 2.671593427658081
Validation loss: 2.8163316147301787

Epoch: 5| Step: 5
Training loss: 2.7989501953125
Validation loss: 2.8177985401563745

Epoch: 5| Step: 6
Training loss: 2.293771743774414
Validation loss: 2.8163711435051373

Epoch: 5| Step: 7
Training loss: 3.335590362548828
Validation loss: 2.8145835040717997

Epoch: 5| Step: 8
Training loss: 2.8790855407714844
Validation loss: 2.811593673562491

Epoch: 5| Step: 9
Training loss: 3.0240471363067627
Validation loss: 2.811177376777895

Epoch: 5| Step: 10
Training loss: 3.375194549560547
Validation loss: 2.807704387172576

Epoch: 57| Step: 0
Training loss: 3.270906448364258
Validation loss: 2.8092075035136235

Epoch: 5| Step: 1
Training loss: 2.8796792030334473
Validation loss: 2.809683128069806

Epoch: 5| Step: 2
Training loss: 2.810359477996826
Validation loss: 2.808229325920023

Epoch: 5| Step: 3
Training loss: 2.79722261428833
Validation loss: 2.814639396564935

Epoch: 5| Step: 4
Training loss: 3.243208646774292
Validation loss: 2.8119035664425103

Epoch: 5| Step: 5
Training loss: 2.918055772781372
Validation loss: 2.8133363082844722

Epoch: 5| Step: 6
Training loss: 2.8503308296203613
Validation loss: 2.812606955087313

Epoch: 5| Step: 7
Training loss: 2.3381285667419434
Validation loss: 2.8137104152351298

Epoch: 5| Step: 8
Training loss: 2.935058355331421
Validation loss: 2.813903198447279

Epoch: 5| Step: 9
Training loss: 2.930541515350342
Validation loss: 2.8172989301784064

Epoch: 5| Step: 10
Training loss: 3.1289846897125244
Validation loss: 2.8228210556891655

Epoch: 58| Step: 0
Training loss: 3.6447768211364746
Validation loss: 2.8256356716156006

Epoch: 5| Step: 1
Training loss: 2.4139389991760254
Validation loss: 2.8265679523509037

Epoch: 5| Step: 2
Training loss: 2.5449752807617188
Validation loss: 2.825854642416841

Epoch: 5| Step: 3
Training loss: 2.792050838470459
Validation loss: 2.8140040802699264

Epoch: 5| Step: 4
Training loss: 2.7772228717803955
Validation loss: 2.806601773026169

Epoch: 5| Step: 5
Training loss: 3.0512478351593018
Validation loss: 2.8062219850478636

Epoch: 5| Step: 6
Training loss: 2.4143080711364746
Validation loss: 2.8035556782958326

Epoch: 5| Step: 7
Training loss: 3.2658779621124268
Validation loss: 2.8035639921824136

Epoch: 5| Step: 8
Training loss: 2.8406059741973877
Validation loss: 2.804907447548323

Epoch: 5| Step: 9
Training loss: 2.843632936477661
Validation loss: 2.8037538618169804

Epoch: 5| Step: 10
Training loss: 3.60257625579834
Validation loss: 2.807142573018228

Epoch: 59| Step: 0
Training loss: 2.8273582458496094
Validation loss: 2.804195004124795

Epoch: 5| Step: 1
Training loss: 2.42852783203125
Validation loss: 2.804998036353819

Epoch: 5| Step: 2
Training loss: 3.331820011138916
Validation loss: 2.8048196300383537

Epoch: 5| Step: 3
Training loss: 2.0998282432556152
Validation loss: 2.8045357170925347

Epoch: 5| Step: 4
Training loss: 3.142542600631714
Validation loss: 2.804907755185199

Epoch: 5| Step: 5
Training loss: 3.61102294921875
Validation loss: 2.8130113335065943

Epoch: 5| Step: 6
Training loss: 3.1410346031188965
Validation loss: 2.811794150260187

Epoch: 5| Step: 7
Training loss: 3.195747137069702
Validation loss: 2.8107856858161187

Epoch: 5| Step: 8
Training loss: 2.460981845855713
Validation loss: 2.8198420104160102

Epoch: 5| Step: 9
Training loss: 3.085054874420166
Validation loss: 2.832296779078822

Epoch: 5| Step: 10
Training loss: 2.741487741470337
Validation loss: 2.819085926137945

Epoch: 60| Step: 0
Training loss: 3.9130771160125732
Validation loss: 2.817141245770198

Epoch: 5| Step: 1
Training loss: 2.469336986541748
Validation loss: 2.811780798819757

Epoch: 5| Step: 2
Training loss: 2.949389934539795
Validation loss: 2.810080994841873

Epoch: 5| Step: 3
Training loss: 2.405144214630127
Validation loss: 2.8120706055753972

Epoch: 5| Step: 4
Training loss: 2.5963006019592285
Validation loss: 2.8006112575531006

Epoch: 5| Step: 5
Training loss: 2.6847236156463623
Validation loss: 2.798797330548686

Epoch: 5| Step: 6
Training loss: 3.2522120475769043
Validation loss: 2.796845607860114

Epoch: 5| Step: 7
Training loss: 3.6329140663146973
Validation loss: 2.798003227479996

Epoch: 5| Step: 8
Training loss: 2.8022258281707764
Validation loss: 2.7989782389774116

Epoch: 5| Step: 9
Training loss: 2.8280932903289795
Validation loss: 2.79722342183513

Epoch: 5| Step: 10
Training loss: 2.3657822608947754
Validation loss: 2.7952819075635684

Epoch: 61| Step: 0
Training loss: 3.3635470867156982
Validation loss: 2.7946292431123796

Epoch: 5| Step: 1
Training loss: 2.5520591735839844
Validation loss: 2.795170030286235

Epoch: 5| Step: 2
Training loss: 2.6507747173309326
Validation loss: 2.7908271435768373

Epoch: 5| Step: 3
Training loss: 2.469207286834717
Validation loss: 2.792974901455705

Epoch: 5| Step: 4
Training loss: 3.0698535442352295
Validation loss: 2.7955090538147958

Epoch: 5| Step: 5
Training loss: 3.5946507453918457
Validation loss: 2.7940648960810837

Epoch: 5| Step: 6
Training loss: 3.2137551307678223
Validation loss: 2.7925864317083873

Epoch: 5| Step: 7
Training loss: 2.5885987281799316
Validation loss: 2.794195270025602

Epoch: 5| Step: 8
Training loss: 2.4277234077453613
Validation loss: 2.8006831317819576

Epoch: 5| Step: 9
Training loss: 2.84468150138855
Validation loss: 2.8016297458320536

Epoch: 5| Step: 10
Training loss: 3.2245380878448486
Validation loss: 2.7978561180894093

Epoch: 62| Step: 0
Training loss: 3.7044131755828857
Validation loss: 2.7944439098399174

Epoch: 5| Step: 1
Training loss: 2.1747560501098633
Validation loss: 2.7909366084683325

Epoch: 5| Step: 2
Training loss: 2.4047412872314453
Validation loss: 2.791392813446701

Epoch: 5| Step: 3
Training loss: 3.207581043243408
Validation loss: 2.789210299009918

Epoch: 5| Step: 4
Training loss: 2.399156332015991
Validation loss: 2.7920673560070735

Epoch: 5| Step: 5
Training loss: 2.4749934673309326
Validation loss: 2.7891260090694634

Epoch: 5| Step: 6
Training loss: 3.5724761486053467
Validation loss: 2.7909485806701

Epoch: 5| Step: 7
Training loss: 3.186392307281494
Validation loss: 2.790768159333096

Epoch: 5| Step: 8
Training loss: 2.9590954780578613
Validation loss: 2.7895539012006534

Epoch: 5| Step: 9
Training loss: 2.360133647918701
Validation loss: 2.789669406029486

Epoch: 5| Step: 10
Training loss: 3.517777919769287
Validation loss: 2.787678475021034

Epoch: 63| Step: 0
Training loss: 2.907589912414551
Validation loss: 2.783630265984484

Epoch: 5| Step: 1
Training loss: 3.395925998687744
Validation loss: 2.7864974083439

Epoch: 5| Step: 2
Training loss: 3.221207857131958
Validation loss: 2.7858315155070317

Epoch: 5| Step: 3
Training loss: 2.5578153133392334
Validation loss: 2.790452657207366

Epoch: 5| Step: 4
Training loss: 2.7710280418395996
Validation loss: 2.7983082186791206

Epoch: 5| Step: 5
Training loss: 2.4126522541046143
Validation loss: 2.7935686342177855

Epoch: 5| Step: 6
Training loss: 3.3995513916015625
Validation loss: 2.794543512405888

Epoch: 5| Step: 7
Training loss: 3.184630870819092
Validation loss: 2.792573098213442

Epoch: 5| Step: 8
Training loss: 2.292926788330078
Validation loss: 2.7858971165072535

Epoch: 5| Step: 9
Training loss: 2.690363883972168
Validation loss: 2.7870492524998163

Epoch: 5| Step: 10
Training loss: 3.0437605381011963
Validation loss: 2.7885091561143116

Epoch: 64| Step: 0
Training loss: 2.2225093841552734
Validation loss: 2.7905566641079482

Epoch: 5| Step: 1
Training loss: 3.2390758991241455
Validation loss: 2.789841862135036

Epoch: 5| Step: 2
Training loss: 2.7106690406799316
Validation loss: 2.790934242228026

Epoch: 5| Step: 3
Training loss: 2.972790002822876
Validation loss: 2.7863348017456713

Epoch: 5| Step: 4
Training loss: 2.3356974124908447
Validation loss: 2.787632139780188

Epoch: 5| Step: 5
Training loss: 2.674783229827881
Validation loss: 2.7904235573225122

Epoch: 5| Step: 6
Training loss: 3.677298069000244
Validation loss: 2.7943120412929083

Epoch: 5| Step: 7
Training loss: 2.959181308746338
Validation loss: 2.799154984053745

Epoch: 5| Step: 8
Training loss: 3.024543285369873
Validation loss: 2.8022511056674424

Epoch: 5| Step: 9
Training loss: 3.4791808128356934
Validation loss: 2.8019551333560737

Epoch: 5| Step: 10
Training loss: 2.5156283378601074
Validation loss: 2.7927286727454073

Epoch: 65| Step: 0
Training loss: 2.5873067378997803
Validation loss: 2.7845854015760523

Epoch: 5| Step: 1
Training loss: 3.358668088912964
Validation loss: 2.7826502758969545

Epoch: 5| Step: 2
Training loss: 3.0250706672668457
Validation loss: 2.7832525494278118

Epoch: 5| Step: 3
Training loss: 2.375727891921997
Validation loss: 2.783430258433024

Epoch: 5| Step: 4
Training loss: 2.404792070388794
Validation loss: 2.785573951659664

Epoch: 5| Step: 5
Training loss: 3.0114052295684814
Validation loss: 2.786498867055421

Epoch: 5| Step: 6
Training loss: 1.7075382471084595
Validation loss: 2.7803257562780894

Epoch: 5| Step: 7
Training loss: 3.4142704010009766
Validation loss: 2.7778198385751374

Epoch: 5| Step: 8
Training loss: 3.6329734325408936
Validation loss: 2.7809874216715493

Epoch: 5| Step: 9
Training loss: 3.2907118797302246
Validation loss: 2.7861275570366972

Epoch: 5| Step: 10
Training loss: 3.0272748470306396
Validation loss: 2.793306996745448

Epoch: 66| Step: 0
Training loss: 2.9410805702209473
Validation loss: 2.7940231395024124

Epoch: 5| Step: 1
Training loss: 3.2463791370391846
Validation loss: 2.799884144977857

Epoch: 5| Step: 2
Training loss: 2.8416409492492676
Validation loss: 2.8006990417357414

Epoch: 5| Step: 3
Training loss: 2.8444206714630127
Validation loss: 2.8195226346292803

Epoch: 5| Step: 4
Training loss: 3.324368953704834
Validation loss: 2.8140031291592504

Epoch: 5| Step: 5
Training loss: 2.680288791656494
Validation loss: 2.8349340602915776

Epoch: 5| Step: 6
Training loss: 1.863349199295044
Validation loss: 2.80776071804826

Epoch: 5| Step: 7
Training loss: 3.054962158203125
Validation loss: 2.796764583997829

Epoch: 5| Step: 8
Training loss: 3.068883180618286
Validation loss: 2.785884585431827

Epoch: 5| Step: 9
Training loss: 2.888780355453491
Validation loss: 2.777520059257425

Epoch: 5| Step: 10
Training loss: 3.1253108978271484
Validation loss: 2.7787376757591002

Epoch: 67| Step: 0
Training loss: 2.3821117877960205
Validation loss: 2.776786058179794

Epoch: 5| Step: 1
Training loss: 2.715792417526245
Validation loss: 2.776186332907728

Epoch: 5| Step: 2
Training loss: 3.08970046043396
Validation loss: 2.774812632991422

Epoch: 5| Step: 3
Training loss: 3.648688793182373
Validation loss: 2.7741916282202608

Epoch: 5| Step: 4
Training loss: 2.812652111053467
Validation loss: 2.7741047336209204

Epoch: 5| Step: 5
Training loss: 3.3734183311462402
Validation loss: 2.7730336522543304

Epoch: 5| Step: 6
Training loss: 2.8969311714172363
Validation loss: 2.7730589630783244

Epoch: 5| Step: 7
Training loss: 2.3237693309783936
Validation loss: 2.773497663518434

Epoch: 5| Step: 8
Training loss: 2.593458652496338
Validation loss: 2.7698796846533336

Epoch: 5| Step: 9
Training loss: 2.133913516998291
Validation loss: 2.770856544535647

Epoch: 5| Step: 10
Training loss: 3.892608165740967
Validation loss: 2.772763862404772

Epoch: 68| Step: 0
Training loss: 2.7506911754608154
Validation loss: 2.76913135538819

Epoch: 5| Step: 1
Training loss: 3.056528091430664
Validation loss: 2.771195550118723

Epoch: 5| Step: 2
Training loss: 2.18926739692688
Validation loss: 2.7756274284855014

Epoch: 5| Step: 3
Training loss: 3.5793557167053223
Validation loss: 2.777353112415601

Epoch: 5| Step: 4
Training loss: 2.7855384349823
Validation loss: 2.785109361012777

Epoch: 5| Step: 5
Training loss: 2.842864513397217
Validation loss: 2.7827985286712646

Epoch: 5| Step: 6
Training loss: 2.8834967613220215
Validation loss: 2.77913764984377

Epoch: 5| Step: 7
Training loss: 3.3700027465820312
Validation loss: 2.778636650372577

Epoch: 5| Step: 8
Training loss: 2.8409371376037598
Validation loss: 2.7821505710642827

Epoch: 5| Step: 9
Training loss: 2.546403408050537
Validation loss: 2.7742528120676675

Epoch: 5| Step: 10
Training loss: 2.8429574966430664
Validation loss: 2.770255183660856

Epoch: 69| Step: 0
Training loss: 2.2666640281677246
Validation loss: 2.766716141854563

Epoch: 5| Step: 1
Training loss: 3.30833101272583
Validation loss: 2.7678727539636756

Epoch: 5| Step: 2
Training loss: 3.1173624992370605
Validation loss: 2.7648505498004217

Epoch: 5| Step: 3
Training loss: 3.3454978466033936
Validation loss: 2.766113470959407

Epoch: 5| Step: 4
Training loss: 3.2251198291778564
Validation loss: 2.764010311454855

Epoch: 5| Step: 5
Training loss: 2.4422030448913574
Validation loss: 2.7589308984817995

Epoch: 5| Step: 6
Training loss: 2.411353588104248
Validation loss: 2.760965918981901

Epoch: 5| Step: 7
Training loss: 2.645977020263672
Validation loss: 2.7592451828782276

Epoch: 5| Step: 8
Training loss: 2.826496124267578
Validation loss: 2.758270073962468

Epoch: 5| Step: 9
Training loss: 3.2519214153289795
Validation loss: 2.759680196803103

Epoch: 5| Step: 10
Training loss: 2.7312088012695312
Validation loss: 2.7559027184722242

Epoch: 70| Step: 0
Training loss: 3.0398809909820557
Validation loss: 2.7534966263719785

Epoch: 5| Step: 1
Training loss: 2.2208240032196045
Validation loss: 2.7565316205383628

Epoch: 5| Step: 2
Training loss: 3.349745512008667
Validation loss: 2.752839252512942

Epoch: 5| Step: 3
Training loss: 3.3098435401916504
Validation loss: 2.756811095822242

Epoch: 5| Step: 4
Training loss: 2.010244369506836
Validation loss: 2.754126194984682

Epoch: 5| Step: 5
Training loss: 2.7376210689544678
Validation loss: 2.749918245500134

Epoch: 5| Step: 6
Training loss: 2.4463164806365967
Validation loss: 2.7517462674007622

Epoch: 5| Step: 7
Training loss: 3.430647373199463
Validation loss: 2.7492935478046374

Epoch: 5| Step: 8
Training loss: 2.517528772354126
Validation loss: 2.74850703823951

Epoch: 5| Step: 9
Training loss: 3.231826066970825
Validation loss: 2.746775793772872

Epoch: 5| Step: 10
Training loss: 3.257420301437378
Validation loss: 2.747811989117694

Epoch: 71| Step: 0
Training loss: 3.9513161182403564
Validation loss: 2.7494335200196955

Epoch: 5| Step: 1
Training loss: 2.358588695526123
Validation loss: 2.7438938540797078

Epoch: 5| Step: 2
Training loss: 3.4591317176818848
Validation loss: 2.7445857089052916

Epoch: 5| Step: 3
Training loss: 3.4424309730529785
Validation loss: 2.7439282991552867

Epoch: 5| Step: 4
Training loss: 1.8180049657821655
Validation loss: 2.746630314857729

Epoch: 5| Step: 5
Training loss: 2.7298245429992676
Validation loss: 2.744263579768519

Epoch: 5| Step: 6
Training loss: 2.9521467685699463
Validation loss: 2.7500793036594184

Epoch: 5| Step: 7
Training loss: 2.5208799839019775
Validation loss: 2.7498096907010643

Epoch: 5| Step: 8
Training loss: 2.2829267978668213
Validation loss: 2.7564412675878054

Epoch: 5| Step: 9
Training loss: 3.1187567710876465
Validation loss: 2.749794098638719

Epoch: 5| Step: 10
Training loss: 2.839901924133301
Validation loss: 2.7456041023295414

Epoch: 72| Step: 0
Training loss: 2.766666889190674
Validation loss: 2.7423601535058792

Epoch: 5| Step: 1
Training loss: 2.5130386352539062
Validation loss: 2.7403127788215556

Epoch: 5| Step: 2
Training loss: 2.007162570953369
Validation loss: 2.736332416534424

Epoch: 5| Step: 3
Training loss: 3.1576640605926514
Validation loss: 2.744203370104554

Epoch: 5| Step: 4
Training loss: 2.816066265106201
Validation loss: 2.7440006502213015

Epoch: 5| Step: 5
Training loss: 2.895535945892334
Validation loss: 2.7425542749384397

Epoch: 5| Step: 6
Training loss: 3.3862998485565186
Validation loss: 2.737761999971123

Epoch: 5| Step: 7
Training loss: 3.1716978549957275
Validation loss: 2.7398585375919136

Epoch: 5| Step: 8
Training loss: 2.7996268272399902
Validation loss: 2.742258092408539

Epoch: 5| Step: 9
Training loss: 3.454275608062744
Validation loss: 2.7418624790765906

Epoch: 5| Step: 10
Training loss: 2.350177526473999
Validation loss: 2.744504864497851

Epoch: 73| Step: 0
Training loss: 3.2424538135528564
Validation loss: 2.7524088890321794

Epoch: 5| Step: 1
Training loss: 3.008338212966919
Validation loss: 2.7433235465839343

Epoch: 5| Step: 2
Training loss: 3.3833584785461426
Validation loss: 2.738933547850578

Epoch: 5| Step: 3
Training loss: 3.320859432220459
Validation loss: 2.739191398825697

Epoch: 5| Step: 4
Training loss: 2.976086139678955
Validation loss: 2.7412273140363794

Epoch: 5| Step: 5
Training loss: 3.1045565605163574
Validation loss: 2.73991217664493

Epoch: 5| Step: 6
Training loss: 2.681154727935791
Validation loss: 2.735382882497644

Epoch: 5| Step: 7
Training loss: 1.9080231189727783
Validation loss: 2.7362651440405075

Epoch: 5| Step: 8
Training loss: 2.730675220489502
Validation loss: 2.7338744773659656

Epoch: 5| Step: 9
Training loss: 2.4246621131896973
Validation loss: 2.7345878180637153

Epoch: 5| Step: 10
Training loss: 2.4669923782348633
Validation loss: 2.737261972119731

Epoch: 74| Step: 0
Training loss: 3.6716651916503906
Validation loss: 2.734163991866573

Epoch: 5| Step: 1
Training loss: 2.770167350769043
Validation loss: 2.7348800000324043

Epoch: 5| Step: 2
Training loss: 3.1702959537506104
Validation loss: 2.7332052210325837

Epoch: 5| Step: 3
Training loss: 2.6328039169311523
Validation loss: 2.731128482408421

Epoch: 5| Step: 4
Training loss: 2.4709930419921875
Validation loss: 2.729264477247833

Epoch: 5| Step: 5
Training loss: 2.8185486793518066
Validation loss: 2.728943271021689

Epoch: 5| Step: 6
Training loss: 2.2875571250915527
Validation loss: 2.730229377746582

Epoch: 5| Step: 7
Training loss: 2.525186538696289
Validation loss: 2.734049904731012

Epoch: 5| Step: 8
Training loss: 3.5683302879333496
Validation loss: 2.729127727529054

Epoch: 5| Step: 9
Training loss: 2.5378236770629883
Validation loss: 2.730547058966852

Epoch: 5| Step: 10
Training loss: 2.866727113723755
Validation loss: 2.7328022064701205

Epoch: 75| Step: 0
Training loss: 2.9162373542785645
Validation loss: 2.7380500839602564

Epoch: 5| Step: 1
Training loss: 2.842573642730713
Validation loss: 2.731181311350997

Epoch: 5| Step: 2
Training loss: 2.5078015327453613
Validation loss: 2.728359801794893

Epoch: 5| Step: 3
Training loss: 3.109990358352661
Validation loss: 2.727661999323035

Epoch: 5| Step: 4
Training loss: 3.2799148559570312
Validation loss: 2.7292444423962663

Epoch: 5| Step: 5
Training loss: 1.8706728219985962
Validation loss: 2.7241643039129113

Epoch: 5| Step: 6
Training loss: 2.0690035820007324
Validation loss: 2.7290903137576197

Epoch: 5| Step: 7
Training loss: 3.8341479301452637
Validation loss: 2.728415794270013

Epoch: 5| Step: 8
Training loss: 2.653184413909912
Validation loss: 2.7268185461721113

Epoch: 5| Step: 9
Training loss: 3.1221423149108887
Validation loss: 2.7297654151916504

Epoch: 5| Step: 10
Training loss: 3.070986032485962
Validation loss: 2.7301302494541293

Epoch: 76| Step: 0
Training loss: 2.516186475753784
Validation loss: 2.7265412999737646

Epoch: 5| Step: 1
Training loss: 3.0924220085144043
Validation loss: 2.726029424257176

Epoch: 5| Step: 2
Training loss: 2.6822712421417236
Validation loss: 2.721674273090978

Epoch: 5| Step: 3
Training loss: 2.6384246349334717
Validation loss: 2.724449793497721

Epoch: 5| Step: 4
Training loss: 3.1453163623809814
Validation loss: 2.7271438824233187

Epoch: 5| Step: 5
Training loss: 2.7068111896514893
Validation loss: 2.7318659315827074

Epoch: 5| Step: 6
Training loss: 2.3309426307678223
Validation loss: 2.7536502345915763

Epoch: 5| Step: 7
Training loss: 3.188458204269409
Validation loss: 2.7427351090215866

Epoch: 5| Step: 8
Training loss: 3.1983730792999268
Validation loss: 2.7362154081303585

Epoch: 5| Step: 9
Training loss: 3.178581714630127
Validation loss: 2.7391736763779835

Epoch: 5| Step: 10
Training loss: 2.603411912918091
Validation loss: 2.7438675870177565

Epoch: 77| Step: 0
Training loss: 2.598510265350342
Validation loss: 2.751659218982984

Epoch: 5| Step: 1
Training loss: 2.582195281982422
Validation loss: 2.7447995293524956

Epoch: 5| Step: 2
Training loss: 2.289924144744873
Validation loss: 2.739735113677158

Epoch: 5| Step: 3
Training loss: 3.007608413696289
Validation loss: 2.7279306996253228

Epoch: 5| Step: 4
Training loss: 3.045361042022705
Validation loss: 2.72420403521548

Epoch: 5| Step: 5
Training loss: 3.2657535076141357
Validation loss: 2.719006020535705

Epoch: 5| Step: 6
Training loss: 2.8910579681396484
Validation loss: 2.7160574697679087

Epoch: 5| Step: 7
Training loss: 2.8001856803894043
Validation loss: 2.71863801504976

Epoch: 5| Step: 8
Training loss: 2.924055576324463
Validation loss: 2.7161663065674486

Epoch: 5| Step: 9
Training loss: 2.6657519340515137
Validation loss: 2.7186655100955757

Epoch: 5| Step: 10
Training loss: 3.2117128372192383
Validation loss: 2.721435844257314

Epoch: 78| Step: 0
Training loss: 3.0120136737823486
Validation loss: 2.720841948704053

Epoch: 5| Step: 1
Training loss: 3.5211234092712402
Validation loss: 2.7225177159873386

Epoch: 5| Step: 2
Training loss: 3.697357177734375
Validation loss: 2.7171969324029903

Epoch: 5| Step: 3
Training loss: 2.8755831718444824
Validation loss: 2.7162422467303533

Epoch: 5| Step: 4
Training loss: 2.634070634841919
Validation loss: 2.716332407407863

Epoch: 5| Step: 5
Training loss: 2.3130550384521484
Validation loss: 2.716671548863893

Epoch: 5| Step: 6
Training loss: 2.0779385566711426
Validation loss: 2.7109031523427656

Epoch: 5| Step: 7
Training loss: 2.6517281532287598
Validation loss: 2.7098697129116265

Epoch: 5| Step: 8
Training loss: 2.943155288696289
Validation loss: 2.7112098765629593

Epoch: 5| Step: 9
Training loss: 2.9387950897216797
Validation loss: 2.712202154180055

Epoch: 5| Step: 10
Training loss: 2.554288864135742
Validation loss: 2.7081872211989535

Epoch: 79| Step: 0
Training loss: 2.6885268688201904
Validation loss: 2.7085069584590133

Epoch: 5| Step: 1
Training loss: 2.690047264099121
Validation loss: 2.711294668976979

Epoch: 5| Step: 2
Training loss: 3.9750900268554688
Validation loss: 2.7156155981043333

Epoch: 5| Step: 3
Training loss: 2.860360622406006
Validation loss: 2.7144731321642475

Epoch: 5| Step: 4
Training loss: 2.909459352493286
Validation loss: 2.711750579136674

Epoch: 5| Step: 5
Training loss: 2.774848461151123
Validation loss: 2.7170229368312384

Epoch: 5| Step: 6
Training loss: 1.8174006938934326
Validation loss: 2.710808633476175

Epoch: 5| Step: 7
Training loss: 2.6577677726745605
Validation loss: 2.712854749412947

Epoch: 5| Step: 8
Training loss: 2.289203643798828
Validation loss: 2.712509839765487

Epoch: 5| Step: 9
Training loss: 3.1154403686523438
Validation loss: 2.706707118659891

Epoch: 5| Step: 10
Training loss: 3.457648515701294
Validation loss: 2.7050094143036874

Epoch: 80| Step: 0
Training loss: 3.1328606605529785
Validation loss: 2.7057369960251676

Epoch: 5| Step: 1
Training loss: 2.723012685775757
Validation loss: 2.703923245911957

Epoch: 5| Step: 2
Training loss: 2.722848415374756
Validation loss: 2.699780105262674

Epoch: 5| Step: 3
Training loss: 2.575556755065918
Validation loss: 2.703733931305588

Epoch: 5| Step: 4
Training loss: 2.044037342071533
Validation loss: 2.7033622610953545

Epoch: 5| Step: 5
Training loss: 3.3643345832824707
Validation loss: 2.7062318401951946

Epoch: 5| Step: 6
Training loss: 2.965263605117798
Validation loss: 2.7010810426486436

Epoch: 5| Step: 7
Training loss: 3.2788174152374268
Validation loss: 2.7023808417781705

Epoch: 5| Step: 8
Training loss: 3.6616992950439453
Validation loss: 2.6992686281922045

Epoch: 5| Step: 9
Training loss: 2.2272865772247314
Validation loss: 2.700453442911948

Epoch: 5| Step: 10
Training loss: 2.3116261959075928
Validation loss: 2.698099777262698

Epoch: 81| Step: 0
Training loss: 2.6325416564941406
Validation loss: 2.6997851966529764

Epoch: 5| Step: 1
Training loss: 2.811033248901367
Validation loss: 2.694117505063293

Epoch: 5| Step: 2
Training loss: 2.984198808670044
Validation loss: 2.695167403067312

Epoch: 5| Step: 3
Training loss: 2.9172825813293457
Validation loss: 2.695418442449262

Epoch: 5| Step: 4
Training loss: 3.0371406078338623
Validation loss: 2.6927422323534564

Epoch: 5| Step: 5
Training loss: 2.22160005569458
Validation loss: 2.689682173472579

Epoch: 5| Step: 6
Training loss: 3.02760648727417
Validation loss: 2.6903678909424813

Epoch: 5| Step: 7
Training loss: 3.0094730854034424
Validation loss: 2.6967642038099227

Epoch: 5| Step: 8
Training loss: 3.0892343521118164
Validation loss: 2.6990871121806483

Epoch: 5| Step: 9
Training loss: 2.9780917167663574
Validation loss: 2.698134660720825

Epoch: 5| Step: 10
Training loss: 2.2089405059814453
Validation loss: 2.7019344004251624

Epoch: 82| Step: 0
Training loss: 2.779003143310547
Validation loss: 2.699241239537475

Epoch: 5| Step: 1
Training loss: 2.4167048931121826
Validation loss: 2.701157295575706

Epoch: 5| Step: 2
Training loss: 2.7623982429504395
Validation loss: 2.7001859423934773

Epoch: 5| Step: 3
Training loss: 2.6052403450012207
Validation loss: 2.7020292692286993

Epoch: 5| Step: 4
Training loss: 3.1668612957000732
Validation loss: 2.7034323753849154

Epoch: 5| Step: 5
Training loss: 3.2507553100585938
Validation loss: 2.6965537635228967

Epoch: 5| Step: 6
Training loss: 2.5077478885650635
Validation loss: 2.694849711592479

Epoch: 5| Step: 7
Training loss: 3.3652427196502686
Validation loss: 2.695307775210309

Epoch: 5| Step: 8
Training loss: 3.027723789215088
Validation loss: 2.6917595581341813

Epoch: 5| Step: 9
Training loss: 2.718057155609131
Validation loss: 2.693187480331749

Epoch: 5| Step: 10
Training loss: 2.294355869293213
Validation loss: 2.691519239897369

Epoch: 83| Step: 0
Training loss: 2.903623580932617
Validation loss: 2.693629403268137

Epoch: 5| Step: 1
Training loss: 2.4316916465759277
Validation loss: 2.688146973168978

Epoch: 5| Step: 2
Training loss: 2.6711153984069824
Validation loss: 2.68359233743401

Epoch: 5| Step: 3
Training loss: 2.9577114582061768
Validation loss: 2.6793373733438473

Epoch: 5| Step: 4
Training loss: 2.3360018730163574
Validation loss: 2.678413921786893

Epoch: 5| Step: 5
Training loss: 2.465275764465332
Validation loss: 2.682175354291034

Epoch: 5| Step: 6
Training loss: 2.5199782848358154
Validation loss: 2.6833345197862193

Epoch: 5| Step: 7
Training loss: 2.414198637008667
Validation loss: 2.6897795072165867

Epoch: 5| Step: 8
Training loss: 3.5437088012695312
Validation loss: 2.6885007863403647

Epoch: 5| Step: 9
Training loss: 3.4315555095672607
Validation loss: 2.6908950446754374

Epoch: 5| Step: 10
Training loss: 3.3959834575653076
Validation loss: 2.6861557729782595

Epoch: 84| Step: 0
Training loss: 2.629603862762451
Validation loss: 2.689380638061031

Epoch: 5| Step: 1
Training loss: 2.8770222663879395
Validation loss: 2.6910804420389156

Epoch: 5| Step: 2
Training loss: 3.1991450786590576
Validation loss: 2.6819435857957408

Epoch: 5| Step: 3
Training loss: 3.0680370330810547
Validation loss: 2.68361081359207

Epoch: 5| Step: 4
Training loss: 2.895031452178955
Validation loss: 2.6839250800430134

Epoch: 5| Step: 5
Training loss: 2.2991995811462402
Validation loss: 2.674670652676654

Epoch: 5| Step: 6
Training loss: 3.566863536834717
Validation loss: 2.679303971670007

Epoch: 5| Step: 7
Training loss: 2.5064868927001953
Validation loss: 2.6754819936649774

Epoch: 5| Step: 8
Training loss: 2.4472222328186035
Validation loss: 2.672964813888714

Epoch: 5| Step: 9
Training loss: 2.424240827560425
Validation loss: 2.678065987043483

Epoch: 5| Step: 10
Training loss: 2.970170497894287
Validation loss: 2.6764895275074947

Epoch: 85| Step: 0
Training loss: 2.5278830528259277
Validation loss: 2.6773632521270425

Epoch: 5| Step: 1
Training loss: 2.239898204803467
Validation loss: 2.680453810640561

Epoch: 5| Step: 2
Training loss: 3.772498607635498
Validation loss: 2.676900702138101

Epoch: 5| Step: 3
Training loss: 2.959150791168213
Validation loss: 2.678765050826534

Epoch: 5| Step: 4
Training loss: 2.919743537902832
Validation loss: 2.6778331084917952

Epoch: 5| Step: 5
Training loss: 2.7781319618225098
Validation loss: 2.6764060784411687

Epoch: 5| Step: 6
Training loss: 2.8631081581115723
Validation loss: 2.6722165692237114

Epoch: 5| Step: 7
Training loss: 2.899973154067993
Validation loss: 2.671337740395659

Epoch: 5| Step: 8
Training loss: 2.6414682865142822
Validation loss: 2.6693806058617047

Epoch: 5| Step: 9
Training loss: 2.546340227127075
Validation loss: 2.670161183162402

Epoch: 5| Step: 10
Training loss: 2.660778522491455
Validation loss: 2.678586242019489

Epoch: 86| Step: 0
Training loss: 2.9414453506469727
Validation loss: 2.67972239371269

Epoch: 5| Step: 1
Training loss: 2.445348024368286
Validation loss: 2.684309741502167

Epoch: 5| Step: 2
Training loss: 3.1118760108947754
Validation loss: 2.6826312926507767

Epoch: 5| Step: 3
Training loss: 3.0204198360443115
Validation loss: 2.680718716754708

Epoch: 5| Step: 4
Training loss: 2.432399034500122
Validation loss: 2.6748084381062496

Epoch: 5| Step: 5
Training loss: 2.537282943725586
Validation loss: 2.664467538556745

Epoch: 5| Step: 6
Training loss: 2.9301249980926514
Validation loss: 2.6667962279371036

Epoch: 5| Step: 7
Training loss: 3.5766100883483887
Validation loss: 2.6715042898731847

Epoch: 5| Step: 8
Training loss: 2.2483558654785156
Validation loss: 2.6748856165075816

Epoch: 5| Step: 9
Training loss: 3.2474493980407715
Validation loss: 2.6779972968562955

Epoch: 5| Step: 10
Training loss: 2.39473819732666
Validation loss: 2.6799363192691597

Epoch: 87| Step: 0
Training loss: 2.6612181663513184
Validation loss: 2.6762577897758892

Epoch: 5| Step: 1
Training loss: 3.9320359230041504
Validation loss: 2.670808797241539

Epoch: 5| Step: 2
Training loss: 2.555837631225586
Validation loss: 2.6670971096202893

Epoch: 5| Step: 3
Training loss: 2.438676595687866
Validation loss: 2.6656610863183134

Epoch: 5| Step: 4
Training loss: 2.402416944503784
Validation loss: 2.6632961021956576

Epoch: 5| Step: 5
Training loss: 3.34224271774292
Validation loss: 2.6636222818846345

Epoch: 5| Step: 6
Training loss: 2.9551308155059814
Validation loss: 2.669735062506891

Epoch: 5| Step: 7
Training loss: 2.565852642059326
Validation loss: 2.674250818067981

Epoch: 5| Step: 8
Training loss: 2.729330539703369
Validation loss: 2.6714787329396894

Epoch: 5| Step: 9
Training loss: 2.8016607761383057
Validation loss: 2.6722062582610757

Epoch: 5| Step: 10
Training loss: 2.413241147994995
Validation loss: 2.6674338463814027

Epoch: 88| Step: 0
Training loss: 3.6293342113494873
Validation loss: 2.666242468741632

Epoch: 5| Step: 1
Training loss: 3.3205885887145996
Validation loss: 2.65888532259131

Epoch: 5| Step: 2
Training loss: 2.3676629066467285
Validation loss: 2.659760934050365

Epoch: 5| Step: 3
Training loss: 3.1910274028778076
Validation loss: 2.65724584620486

Epoch: 5| Step: 4
Training loss: 2.768094301223755
Validation loss: 2.6625023029183827

Epoch: 5| Step: 5
Training loss: 2.635625123977661
Validation loss: 2.658641976694907

Epoch: 5| Step: 6
Training loss: 2.686699628829956
Validation loss: 2.6589563815824446

Epoch: 5| Step: 7
Training loss: 2.509749412536621
Validation loss: 2.6604533221132014

Epoch: 5| Step: 8
Training loss: 1.8386503458023071
Validation loss: 2.659373278258949

Epoch: 5| Step: 9
Training loss: 3.021010160446167
Validation loss: 2.6558701966398504

Epoch: 5| Step: 10
Training loss: 2.739511728286743
Validation loss: 2.6542653678565897

Epoch: 89| Step: 0
Training loss: 2.3025593757629395
Validation loss: 2.654677860198482

Epoch: 5| Step: 1
Training loss: 2.7710723876953125
Validation loss: 2.663690620853055

Epoch: 5| Step: 2
Training loss: 2.921708583831787
Validation loss: 2.6680112551617365

Epoch: 5| Step: 3
Training loss: 3.013179302215576
Validation loss: 2.6715024414882866

Epoch: 5| Step: 4
Training loss: 3.6620326042175293
Validation loss: 2.671872623505131

Epoch: 5| Step: 5
Training loss: 2.632111072540283
Validation loss: 2.6646639864931823

Epoch: 5| Step: 6
Training loss: 3.0906283855438232
Validation loss: 2.6633578269712386

Epoch: 5| Step: 7
Training loss: 2.5924735069274902
Validation loss: 2.6631892470903296

Epoch: 5| Step: 8
Training loss: 2.330343246459961
Validation loss: 2.6643655787232103

Epoch: 5| Step: 9
Training loss: 2.6472318172454834
Validation loss: 2.661198990319365

Epoch: 5| Step: 10
Training loss: 2.798696517944336
Validation loss: 2.6513513647099978

Epoch: 90| Step: 0
Training loss: 2.7967967987060547
Validation loss: 2.6540529061389226

Epoch: 5| Step: 1
Training loss: 3.040417194366455
Validation loss: 2.646309170671689

Epoch: 5| Step: 2
Training loss: 2.2539761066436768
Validation loss: 2.6531880978615052

Epoch: 5| Step: 3
Training loss: 3.4246857166290283
Validation loss: 2.6508958980601323

Epoch: 5| Step: 4
Training loss: 2.098940372467041
Validation loss: 2.651801375932591

Epoch: 5| Step: 5
Training loss: 2.42881441116333
Validation loss: 2.653263074095531

Epoch: 5| Step: 6
Training loss: 2.5829389095306396
Validation loss: 2.649864186522781

Epoch: 5| Step: 7
Training loss: 2.3083508014678955
Validation loss: 2.6496112885013705

Epoch: 5| Step: 8
Training loss: 3.4068310260772705
Validation loss: 2.6520399816574587

Epoch: 5| Step: 9
Training loss: 3.075737714767456
Validation loss: 2.649009350807436

Epoch: 5| Step: 10
Training loss: 3.3583970069885254
Validation loss: 2.656392740946944

Epoch: 91| Step: 0
Training loss: 2.100555896759033
Validation loss: 2.657657492545343

Epoch: 5| Step: 1
Training loss: 2.8791322708129883
Validation loss: 2.6567022826081965

Epoch: 5| Step: 2
Training loss: 2.404738664627075
Validation loss: 2.661005179087321

Epoch: 5| Step: 3
Training loss: 1.871951699256897
Validation loss: 2.650583036484257

Epoch: 5| Step: 4
Training loss: 3.973534107208252
Validation loss: 2.653569972643288

Epoch: 5| Step: 5
Training loss: 3.1591382026672363
Validation loss: 2.653804809816422

Epoch: 5| Step: 6
Training loss: 2.7250983715057373
Validation loss: 2.6509323273935625

Epoch: 5| Step: 7
Training loss: 3.3700919151306152
Validation loss: 2.6502926247094267

Epoch: 5| Step: 8
Training loss: 3.111454486846924
Validation loss: 2.6530247067892425

Epoch: 5| Step: 9
Training loss: 2.717078447341919
Validation loss: 2.655246626946234

Epoch: 5| Step: 10
Training loss: 2.282197952270508
Validation loss: 2.6618890839238323

Epoch: 92| Step: 0
Training loss: 3.006413221359253
Validation loss: 2.676928893212349

Epoch: 5| Step: 1
Training loss: 2.753147602081299
Validation loss: 2.693119725873393

Epoch: 5| Step: 2
Training loss: 3.2370076179504395
Validation loss: 2.6606942094782347

Epoch: 5| Step: 3
Training loss: 3.0342342853546143
Validation loss: 2.652885465211766

Epoch: 5| Step: 4
Training loss: 3.163470506668091
Validation loss: 2.6605514326403217

Epoch: 5| Step: 5
Training loss: 2.7587509155273438
Validation loss: 2.663803638950471

Epoch: 5| Step: 6
Training loss: 2.5418543815612793
Validation loss: 2.666421203203099

Epoch: 5| Step: 7
Training loss: 3.447610855102539
Validation loss: 2.651349982907695

Epoch: 5| Step: 8
Training loss: 1.8954509496688843
Validation loss: 2.652980266078826

Epoch: 5| Step: 9
Training loss: 2.2143993377685547
Validation loss: 2.651111674565141

Epoch: 5| Step: 10
Training loss: 2.7428951263427734
Validation loss: 2.6495955656933528

Epoch: 93| Step: 0
Training loss: 2.210667610168457
Validation loss: 2.6470802368656283

Epoch: 5| Step: 1
Training loss: 2.8779120445251465
Validation loss: 2.647180357287007

Epoch: 5| Step: 2
Training loss: 2.595541000366211
Validation loss: 2.6516396255903345

Epoch: 5| Step: 3
Training loss: 2.648930072784424
Validation loss: 2.6604390195620957

Epoch: 5| Step: 4
Training loss: 2.8475422859191895
Validation loss: 2.6690241931587138

Epoch: 5| Step: 5
Training loss: 3.1242117881774902
Validation loss: 2.6723646322886148

Epoch: 5| Step: 6
Training loss: 2.952545642852783
Validation loss: 2.6605078199858307

Epoch: 5| Step: 7
Training loss: 3.3541197776794434
Validation loss: 2.6486184340651318

Epoch: 5| Step: 8
Training loss: 2.59261155128479
Validation loss: 2.6385150853023736

Epoch: 5| Step: 9
Training loss: 2.9490907192230225
Validation loss: 2.6332004916283394

Epoch: 5| Step: 10
Training loss: 2.525085210800171
Validation loss: 2.6382759847948627

Epoch: 94| Step: 0
Training loss: 1.9114744663238525
Validation loss: 2.6461391705338673

Epoch: 5| Step: 1
Training loss: 3.2904751300811768
Validation loss: 2.6521223796311246

Epoch: 5| Step: 2
Training loss: 2.7523722648620605
Validation loss: 2.661991327039657

Epoch: 5| Step: 3
Training loss: 2.555605411529541
Validation loss: 2.6501286388725362

Epoch: 5| Step: 4
Training loss: 2.8376896381378174
Validation loss: 2.6482731783261864

Epoch: 5| Step: 5
Training loss: 2.168912410736084
Validation loss: 2.645489746524442

Epoch: 5| Step: 6
Training loss: 2.8731868267059326
Validation loss: 2.642084131958664

Epoch: 5| Step: 7
Training loss: 2.942237377166748
Validation loss: 2.6391001568045667

Epoch: 5| Step: 8
Training loss: 3.6477227210998535
Validation loss: 2.6355604830608574

Epoch: 5| Step: 9
Training loss: 2.9306273460388184
Validation loss: 2.633237228598646

Epoch: 5| Step: 10
Training loss: 2.6747684478759766
Validation loss: 2.6285489938592397

Epoch: 95| Step: 0
Training loss: 3.17318058013916
Validation loss: 2.6298510541198072

Epoch: 5| Step: 1
Training loss: 3.3265938758850098
Validation loss: 2.630386834503502

Epoch: 5| Step: 2
Training loss: 2.5090296268463135
Validation loss: 2.628618665920791

Epoch: 5| Step: 3
Training loss: 2.728574752807617
Validation loss: 2.627291082054056

Epoch: 5| Step: 4
Training loss: 3.4692158699035645
Validation loss: 2.63113042359711

Epoch: 5| Step: 5
Training loss: 2.3530354499816895
Validation loss: 2.6316323946881037

Epoch: 5| Step: 6
Training loss: 2.609499454498291
Validation loss: 2.6353692136785036

Epoch: 5| Step: 7
Training loss: 2.3960041999816895
Validation loss: 2.636795351582189

Epoch: 5| Step: 8
Training loss: 1.9388099908828735
Validation loss: 2.639863303912583

Epoch: 5| Step: 9
Training loss: 3.241668701171875
Validation loss: 2.632565972625568

Epoch: 5| Step: 10
Training loss: 2.815349578857422
Validation loss: 2.629150277824812

Epoch: 96| Step: 0
Training loss: 3.426612138748169
Validation loss: 2.627284857534593

Epoch: 5| Step: 1
Training loss: 2.578277587890625
Validation loss: 2.624871023239628

Epoch: 5| Step: 2
Training loss: 2.926743984222412
Validation loss: 2.6217508008403163

Epoch: 5| Step: 3
Training loss: 2.633207321166992
Validation loss: 2.625577824090117

Epoch: 5| Step: 4
Training loss: 2.614673614501953
Validation loss: 2.627581738656567

Epoch: 5| Step: 5
Training loss: 2.9405517578125
Validation loss: 2.6287882199851413

Epoch: 5| Step: 6
Training loss: 2.4976375102996826
Validation loss: 2.630807645859257

Epoch: 5| Step: 7
Training loss: 2.7210910320281982
Validation loss: 2.6305312341259373

Epoch: 5| Step: 8
Training loss: 2.6984763145446777
Validation loss: 2.630725191485497

Epoch: 5| Step: 9
Training loss: 2.836519479751587
Validation loss: 2.6222847277118313

Epoch: 5| Step: 10
Training loss: 2.571542978286743
Validation loss: 2.62190495767901

Epoch: 97| Step: 0
Training loss: 2.353386402130127
Validation loss: 2.6186625931852605

Epoch: 5| Step: 1
Training loss: 3.4608778953552246
Validation loss: 2.621144146047613

Epoch: 5| Step: 2
Training loss: 2.3092987537384033
Validation loss: 2.6224039677650697

Epoch: 5| Step: 3
Training loss: 3.069667100906372
Validation loss: 2.6252114618978193

Epoch: 5| Step: 4
Training loss: 2.738929271697998
Validation loss: 2.6229923976364957

Epoch: 5| Step: 5
Training loss: 2.7889645099639893
Validation loss: 2.632075955790858

Epoch: 5| Step: 6
Training loss: 3.198732852935791
Validation loss: 2.6263247715529574

Epoch: 5| Step: 7
Training loss: 2.668330192565918
Validation loss: 2.6226504669394544

Epoch: 5| Step: 8
Training loss: 3.066776752471924
Validation loss: 2.6209652628949893

Epoch: 5| Step: 9
Training loss: 2.6727986335754395
Validation loss: 2.6192968686421714

Epoch: 5| Step: 10
Training loss: 1.9756691455841064
Validation loss: 2.616651499143211

Epoch: 98| Step: 0
Training loss: 2.5614731311798096
Validation loss: 2.618487642657372

Epoch: 5| Step: 1
Training loss: 2.9582810401916504
Validation loss: 2.61902456386115

Epoch: 5| Step: 2
Training loss: 2.2406222820281982
Validation loss: 2.6212713308231805

Epoch: 5| Step: 3
Training loss: 3.093057155609131
Validation loss: 2.6216971489690963

Epoch: 5| Step: 4
Training loss: 3.164186954498291
Validation loss: 2.6270739211831042

Epoch: 5| Step: 5
Training loss: 2.682796001434326
Validation loss: 2.6295223928266958

Epoch: 5| Step: 6
Training loss: 3.1158382892608643
Validation loss: 2.6288516675272295

Epoch: 5| Step: 7
Training loss: 2.69708514213562
Validation loss: 2.6322807650412283

Epoch: 5| Step: 8
Training loss: 2.5423264503479004
Validation loss: 2.6416415578575543

Epoch: 5| Step: 9
Training loss: 2.870601177215576
Validation loss: 2.626018170387514

Epoch: 5| Step: 10
Training loss: 2.524691581726074
Validation loss: 2.6151093744462535

Epoch: 99| Step: 0
Training loss: 2.687631130218506
Validation loss: 2.616582852537914

Epoch: 5| Step: 1
Training loss: 2.6355292797088623
Validation loss: 2.620260694975494

Epoch: 5| Step: 2
Training loss: 3.0555341243743896
Validation loss: 2.6505159895907164

Epoch: 5| Step: 3
Training loss: 3.370781421661377
Validation loss: 2.657978665444159

Epoch: 5| Step: 4
Training loss: 3.027432680130005
Validation loss: 2.6660684847062632

Epoch: 5| Step: 5
Training loss: 2.5092434883117676
Validation loss: 2.6626937209918933

Epoch: 5| Step: 6
Training loss: 2.0403411388397217
Validation loss: 2.6424816372574016

Epoch: 5| Step: 7
Training loss: 2.3835933208465576
Validation loss: 2.6307502561999905

Epoch: 5| Step: 8
Training loss: 2.8371787071228027
Validation loss: 2.626126258603988

Epoch: 5| Step: 9
Training loss: 3.5215554237365723
Validation loss: 2.625145863461238

Epoch: 5| Step: 10
Training loss: 2.5621495246887207
Validation loss: 2.6218149303108134

Epoch: 100| Step: 0
Training loss: 2.614683151245117
Validation loss: 2.6149029513841033

Epoch: 5| Step: 1
Training loss: 2.8697879314422607
Validation loss: 2.6093848084890716

Epoch: 5| Step: 2
Training loss: 2.546448230743408
Validation loss: 2.6101390059276293

Epoch: 5| Step: 3
Training loss: 1.956075668334961
Validation loss: 2.623189587746897

Epoch: 5| Step: 4
Training loss: 2.1561379432678223
Validation loss: 2.620497388224448

Epoch: 5| Step: 5
Training loss: 3.7224173545837402
Validation loss: 2.628095637085617

Epoch: 5| Step: 6
Training loss: 2.4258761405944824
Validation loss: 2.6263257406091176

Epoch: 5| Step: 7
Training loss: 3.508234739303589
Validation loss: 2.627028626780356

Epoch: 5| Step: 8
Training loss: 3.1228079795837402
Validation loss: 2.614025159548688

Epoch: 5| Step: 9
Training loss: 2.7931969165802
Validation loss: 2.6090276087484052

Epoch: 5| Step: 10
Training loss: 2.752711057662964
Validation loss: 2.6069622116704143

Epoch: 101| Step: 0
Training loss: 4.297812461853027
Validation loss: 2.606595875114523

Epoch: 5| Step: 1
Training loss: 2.8331308364868164
Validation loss: 2.6077099615527737

Epoch: 5| Step: 2
Training loss: 2.204878091812134
Validation loss: 2.604751499750281

Epoch: 5| Step: 3
Training loss: 2.723029851913452
Validation loss: 2.611972032054778

Epoch: 5| Step: 4
Training loss: 3.0353007316589355
Validation loss: 2.6080532407247894

Epoch: 5| Step: 5
Training loss: 2.5389175415039062
Validation loss: 2.610484746194655

Epoch: 5| Step: 6
Training loss: 2.0272066593170166
Validation loss: 2.606471179634012

Epoch: 5| Step: 7
Training loss: 2.6148228645324707
Validation loss: 2.6054625793169905

Epoch: 5| Step: 8
Training loss: 2.6449368000030518
Validation loss: 2.6062707337000037

Epoch: 5| Step: 9
Training loss: 2.8233084678649902
Validation loss: 2.609235052139528

Epoch: 5| Step: 10
Training loss: 2.5661096572875977
Validation loss: 2.608980494160806

Epoch: 102| Step: 0
Training loss: 1.8634201288223267
Validation loss: 2.6187645363551315

Epoch: 5| Step: 1
Training loss: 3.528963088989258
Validation loss: 2.631784339104929

Epoch: 5| Step: 2
Training loss: 3.0882153511047363
Validation loss: 2.652436948591663

Epoch: 5| Step: 3
Training loss: 2.4518306255340576
Validation loss: 2.6178093546180317

Epoch: 5| Step: 4
Training loss: 2.011653184890747
Validation loss: 2.614799960967033

Epoch: 5| Step: 5
Training loss: 3.3855648040771484
Validation loss: 2.607446309058897

Epoch: 5| Step: 6
Training loss: 2.3436527252197266
Validation loss: 2.602440080335063

Epoch: 5| Step: 7
Training loss: 2.208263874053955
Validation loss: 2.602908149842293

Epoch: 5| Step: 8
Training loss: 2.7341785430908203
Validation loss: 2.602050204430857

Epoch: 5| Step: 9
Training loss: 2.9855432510375977
Validation loss: 2.605193663668889

Epoch: 5| Step: 10
Training loss: 3.875403881072998
Validation loss: 2.6069417794545493

Epoch: 103| Step: 0
Training loss: 2.5122251510620117
Validation loss: 2.608622371509511

Epoch: 5| Step: 1
Training loss: 2.3743205070495605
Validation loss: 2.6047247481602493

Epoch: 5| Step: 2
Training loss: 3.0857560634613037
Validation loss: 2.6046999321188977

Epoch: 5| Step: 3
Training loss: 2.403879404067993
Validation loss: 2.6030158535126717

Epoch: 5| Step: 4
Training loss: 1.959280014038086
Validation loss: 2.6011485361283824

Epoch: 5| Step: 5
Training loss: 2.3788001537323
Validation loss: 2.5982220839428645

Epoch: 5| Step: 6
Training loss: 3.2582061290740967
Validation loss: 2.5987395419869372

Epoch: 5| Step: 7
Training loss: 2.8157429695129395
Validation loss: 2.600451869349326

Epoch: 5| Step: 8
Training loss: 3.1416831016540527
Validation loss: 2.6029063270938013

Epoch: 5| Step: 9
Training loss: 3.1902925968170166
Validation loss: 2.6076628674742994

Epoch: 5| Step: 10
Training loss: 3.233201503753662
Validation loss: 2.606390283953759

Epoch: 104| Step: 0
Training loss: 2.774390459060669
Validation loss: 2.6083869395717496

Epoch: 5| Step: 1
Training loss: 3.0015339851379395
Validation loss: 2.6109775855977047

Epoch: 5| Step: 2
Training loss: 1.9287595748901367
Validation loss: 2.6151391972777662

Epoch: 5| Step: 3
Training loss: 3.1227827072143555
Validation loss: 2.6231591163143033

Epoch: 5| Step: 4
Training loss: 2.673166513442993
Validation loss: 2.61619302790652

Epoch: 5| Step: 5
Training loss: 2.4737708568573
Validation loss: 2.6131170898355465

Epoch: 5| Step: 6
Training loss: 2.8948559761047363
Validation loss: 2.6165890565482517

Epoch: 5| Step: 7
Training loss: 2.8821048736572266
Validation loss: 2.6257775163137786

Epoch: 5| Step: 8
Training loss: 3.035731554031372
Validation loss: 2.662475232155092

Epoch: 5| Step: 9
Training loss: 2.717360019683838
Validation loss: 2.6809603629573697

Epoch: 5| Step: 10
Training loss: 3.081876516342163
Validation loss: 2.665429130677254

Epoch: 105| Step: 0
Training loss: 2.04990816116333
Validation loss: 2.6548052680107856

Epoch: 5| Step: 1
Training loss: 2.621492385864258
Validation loss: 2.6254408256981963

Epoch: 5| Step: 2
Training loss: 2.8413805961608887
Validation loss: 2.614559699130315

Epoch: 5| Step: 3
Training loss: 1.9362369775772095
Validation loss: 2.6065112621553483

Epoch: 5| Step: 4
Training loss: 2.861848831176758
Validation loss: 2.6087303776894846

Epoch: 5| Step: 5
Training loss: 3.63187837600708
Validation loss: 2.610353018647881

Epoch: 5| Step: 6
Training loss: 2.346597194671631
Validation loss: 2.618362242175687

Epoch: 5| Step: 7
Training loss: 2.96201753616333
Validation loss: 2.6273235608172674

Epoch: 5| Step: 8
Training loss: 3.2265491485595703
Validation loss: 2.613412539164225

Epoch: 5| Step: 9
Training loss: 3.242638111114502
Validation loss: 2.595916974929071

Epoch: 5| Step: 10
Training loss: 2.660177230834961
Validation loss: 2.5953215014549995

Epoch: 106| Step: 0
Training loss: 2.6686596870422363
Validation loss: 2.5894220849519134

Epoch: 5| Step: 1
Training loss: 2.476508617401123
Validation loss: 2.583700914536753

Epoch: 5| Step: 2
Training loss: 2.7891268730163574
Validation loss: 2.5896275171669583

Epoch: 5| Step: 3
Training loss: 2.9060797691345215
Validation loss: 2.589773080682242

Epoch: 5| Step: 4
Training loss: 3.234732151031494
Validation loss: 2.587204376856486

Epoch: 5| Step: 5
Training loss: 2.667168140411377
Validation loss: 2.591482970022386

Epoch: 5| Step: 6
Training loss: 2.7871053218841553
Validation loss: 2.5930128764080744

Epoch: 5| Step: 7
Training loss: 2.9243245124816895
Validation loss: 2.6021942374526814

Epoch: 5| Step: 8
Training loss: 2.832444429397583
Validation loss: 2.6022445924820437

Epoch: 5| Step: 9
Training loss: 2.482649803161621
Validation loss: 2.5975968350646315

Epoch: 5| Step: 10
Training loss: 2.4691355228424072
Validation loss: 2.5908341510321504

Epoch: 107| Step: 0
Training loss: 3.4562182426452637
Validation loss: 2.586902238989389

Epoch: 5| Step: 1
Training loss: 2.6093080043792725
Validation loss: 2.5871357328148297

Epoch: 5| Step: 2
Training loss: 2.0318729877471924
Validation loss: 2.5912711363966747

Epoch: 5| Step: 3
Training loss: 2.7808239459991455
Validation loss: 2.592427951033397

Epoch: 5| Step: 4
Training loss: 2.6807808876037598
Validation loss: 2.6018251834377164

Epoch: 5| Step: 5
Training loss: 2.299936056137085
Validation loss: 2.6041885832304597

Epoch: 5| Step: 6
Training loss: 2.8508682250976562
Validation loss: 2.603790421639719

Epoch: 5| Step: 7
Training loss: 3.4167094230651855
Validation loss: 2.5960213856030534

Epoch: 5| Step: 8
Training loss: 2.714599132537842
Validation loss: 2.5834902794130388

Epoch: 5| Step: 9
Training loss: 2.33347487449646
Validation loss: 2.5782934978444088

Epoch: 5| Step: 10
Training loss: 3.1602623462677
Validation loss: 2.5790404017253588

Epoch: 108| Step: 0
Training loss: 2.8756585121154785
Validation loss: 2.586139027790357

Epoch: 5| Step: 1
Training loss: 3.6048030853271484
Validation loss: 2.5922882403096845

Epoch: 5| Step: 2
Training loss: 2.781869411468506
Validation loss: 2.592182913134175

Epoch: 5| Step: 3
Training loss: 2.356198787689209
Validation loss: 2.592848262479228

Epoch: 5| Step: 4
Training loss: 2.678122043609619
Validation loss: 2.59839548859545

Epoch: 5| Step: 5
Training loss: 2.373708724975586
Validation loss: 2.595026144417383

Epoch: 5| Step: 6
Training loss: 2.6093974113464355
Validation loss: 2.592283974411667

Epoch: 5| Step: 7
Training loss: 2.914792060852051
Validation loss: 2.59034909484207

Epoch: 5| Step: 8
Training loss: 2.6560702323913574
Validation loss: 2.590169334924349

Epoch: 5| Step: 9
Training loss: 3.0184903144836426
Validation loss: 2.5901836528572986

Epoch: 5| Step: 10
Training loss: 2.3332152366638184
Validation loss: 2.5839242345543316

Epoch: 109| Step: 0
Training loss: 2.372636556625366
Validation loss: 2.5841203607538694

Epoch: 5| Step: 1
Training loss: 1.7313783168792725
Validation loss: 2.5986085784050728

Epoch: 5| Step: 2
Training loss: 2.9498469829559326
Validation loss: 2.59415768038842

Epoch: 5| Step: 3
Training loss: 3.3828060626983643
Validation loss: 2.57870513649397

Epoch: 5| Step: 4
Training loss: 3.0279135704040527
Validation loss: 2.57738918899208

Epoch: 5| Step: 5
Training loss: 2.026681900024414
Validation loss: 2.5755646844064035

Epoch: 5| Step: 6
Training loss: 3.484703540802002
Validation loss: 2.571869691212972

Epoch: 5| Step: 7
Training loss: 2.359945774078369
Validation loss: 2.576202848906158

Epoch: 5| Step: 8
Training loss: 3.394911527633667
Validation loss: 2.5764078299204507

Epoch: 5| Step: 9
Training loss: 2.92201566696167
Validation loss: 2.577060063680013

Epoch: 5| Step: 10
Training loss: 2.475296974182129
Validation loss: 2.5803269468328005

Epoch: 110| Step: 0
Training loss: 3.1768951416015625
Validation loss: 2.578853399522843

Epoch: 5| Step: 1
Training loss: 2.7702584266662598
Validation loss: 2.5851189936361005

Epoch: 5| Step: 2
Training loss: 3.1419920921325684
Validation loss: 2.583542175190423

Epoch: 5| Step: 3
Training loss: 2.8403091430664062
Validation loss: 2.5886980538727133

Epoch: 5| Step: 4
Training loss: 2.3514342308044434
Validation loss: 2.5772682723178657

Epoch: 5| Step: 5
Training loss: 3.7649307250976562
Validation loss: 2.579212914231003

Epoch: 5| Step: 6
Training loss: 2.1620540618896484
Validation loss: 2.5756434855922574

Epoch: 5| Step: 7
Training loss: 2.761455535888672
Validation loss: 2.5723427059829875

Epoch: 5| Step: 8
Training loss: 2.4489831924438477
Validation loss: 2.5714551992313837

Epoch: 5| Step: 9
Training loss: 2.5420570373535156
Validation loss: 2.565959413846334

Epoch: 5| Step: 10
Training loss: 2.032522439956665
Validation loss: 2.5685171337537867

Epoch: 111| Step: 0
Training loss: 3.017533779144287
Validation loss: 2.5680571474054807

Epoch: 5| Step: 1
Training loss: 2.4677436351776123
Validation loss: 2.568841495821553

Epoch: 5| Step: 2
Training loss: 3.6286263465881348
Validation loss: 2.568825985795708

Epoch: 5| Step: 3
Training loss: 2.393353223800659
Validation loss: 2.569626400547643

Epoch: 5| Step: 4
Training loss: 2.6451950073242188
Validation loss: 2.567802908600018

Epoch: 5| Step: 5
Training loss: 2.7254061698913574
Validation loss: 2.5704806056073917

Epoch: 5| Step: 6
Training loss: 3.2019600868225098
Validation loss: 2.568451991645239

Epoch: 5| Step: 7
Training loss: 2.182877540588379
Validation loss: 2.5666028350912113

Epoch: 5| Step: 8
Training loss: 2.5711545944213867
Validation loss: 2.5671463986878753

Epoch: 5| Step: 9
Training loss: 2.752218008041382
Validation loss: 2.563087717179329

Epoch: 5| Step: 10
Training loss: 2.392031669616699
Validation loss: 2.564175977501818

Epoch: 112| Step: 0
Training loss: 2.172293186187744
Validation loss: 2.5649249604953233

Epoch: 5| Step: 1
Training loss: 1.8797156810760498
Validation loss: 2.564262895173924

Epoch: 5| Step: 2
Training loss: 3.1494977474212646
Validation loss: 2.564048003124934

Epoch: 5| Step: 3
Training loss: 2.4631505012512207
Validation loss: 2.562368654435681

Epoch: 5| Step: 4
Training loss: 2.424539089202881
Validation loss: 2.5679948919562885

Epoch: 5| Step: 5
Training loss: 3.2303528785705566
Validation loss: 2.5693486711030364

Epoch: 5| Step: 6
Training loss: 3.2424004077911377
Validation loss: 2.5675170037054245

Epoch: 5| Step: 7
Training loss: 3.384481430053711
Validation loss: 2.5626994871324107

Epoch: 5| Step: 8
Training loss: 1.9656248092651367
Validation loss: 2.5715926718968216

Epoch: 5| Step: 9
Training loss: 3.149122714996338
Validation loss: 2.5663778961345716

Epoch: 5| Step: 10
Training loss: 3.0130345821380615
Validation loss: 2.5688286340364845

Epoch: 113| Step: 0
Training loss: 1.7853686809539795
Validation loss: 2.567501947443972

Epoch: 5| Step: 1
Training loss: 3.7365517616271973
Validation loss: 2.5661377009525093

Epoch: 5| Step: 2
Training loss: 2.6769614219665527
Validation loss: 2.56687105342906

Epoch: 5| Step: 3
Training loss: 2.1666133403778076
Validation loss: 2.56224984763771

Epoch: 5| Step: 4
Training loss: 2.943777084350586
Validation loss: 2.5583537701637513

Epoch: 5| Step: 5
Training loss: 3.0744144916534424
Validation loss: 2.563221752002675

Epoch: 5| Step: 6
Training loss: 3.012160539627075
Validation loss: 2.5637481725344093

Epoch: 5| Step: 7
Training loss: 2.5403101444244385
Validation loss: 2.5634385026911253

Epoch: 5| Step: 8
Training loss: 2.648000955581665
Validation loss: 2.5604590600536716

Epoch: 5| Step: 9
Training loss: 2.4977259635925293
Validation loss: 2.5654660655606176

Epoch: 5| Step: 10
Training loss: 2.9101204872131348
Validation loss: 2.5778961796914377

Epoch: 114| Step: 0
Training loss: 2.8378102779388428
Validation loss: 2.5920625271335727

Epoch: 5| Step: 1
Training loss: 2.654222011566162
Validation loss: 2.6185880707156275

Epoch: 5| Step: 2
Training loss: 2.8485729694366455
Validation loss: 2.6372092923810406

Epoch: 5| Step: 3
Training loss: 3.3522636890411377
Validation loss: 2.648521251575921

Epoch: 5| Step: 4
Training loss: 2.7572686672210693
Validation loss: 2.6335965074518675

Epoch: 5| Step: 5
Training loss: 2.6109042167663574
Validation loss: 2.591677887465364

Epoch: 5| Step: 6
Training loss: 2.7255091667175293
Validation loss: 2.5776474757861068

Epoch: 5| Step: 7
Training loss: 2.092245101928711
Validation loss: 2.5863509152525213

Epoch: 5| Step: 8
Training loss: 2.4793782234191895
Validation loss: 2.57183551531966

Epoch: 5| Step: 9
Training loss: 2.7666678428649902
Validation loss: 2.570879997745637

Epoch: 5| Step: 10
Training loss: 2.964831590652466
Validation loss: 2.567296576756303

Epoch: 115| Step: 0
Training loss: 2.631701946258545
Validation loss: 2.5596650108214347

Epoch: 5| Step: 1
Training loss: 2.3917853832244873
Validation loss: 2.557115485591273

Epoch: 5| Step: 2
Training loss: 2.294127941131592
Validation loss: 2.5669809182484946

Epoch: 5| Step: 3
Training loss: 2.6551926136016846
Validation loss: 2.581385148468838

Epoch: 5| Step: 4
Training loss: 2.588306188583374
Validation loss: 2.5714383689306115

Epoch: 5| Step: 5
Training loss: 2.4061007499694824
Validation loss: 2.5601165038283153

Epoch: 5| Step: 6
Training loss: 2.629688024520874
Validation loss: 2.5592131076320523

Epoch: 5| Step: 7
Training loss: 3.1990768909454346
Validation loss: 2.5699050503392376

Epoch: 5| Step: 8
Training loss: 2.780538558959961
Validation loss: 2.5847173788214244

Epoch: 5| Step: 9
Training loss: 2.951751708984375
Validation loss: 2.580687612615606

Epoch: 5| Step: 10
Training loss: 3.541377305984497
Validation loss: 2.577794331376271

Epoch: 116| Step: 0
Training loss: 2.3541676998138428
Validation loss: 2.58055454684842

Epoch: 5| Step: 1
Training loss: 2.841860294342041
Validation loss: 2.5957648984847532

Epoch: 5| Step: 2
Training loss: 2.797670602798462
Validation loss: 2.5859997657037552

Epoch: 5| Step: 3
Training loss: 2.688710927963257
Validation loss: 2.5758460234570246

Epoch: 5| Step: 4
Training loss: 2.8642899990081787
Validation loss: 2.566419345076366

Epoch: 5| Step: 5
Training loss: 2.6156599521636963
Validation loss: 2.5658306742227204

Epoch: 5| Step: 6
Training loss: 3.393439769744873
Validation loss: 2.5549063887647403

Epoch: 5| Step: 7
Training loss: 2.0563881397247314
Validation loss: 2.553916008241715

Epoch: 5| Step: 8
Training loss: 2.8906614780426025
Validation loss: 2.557959997525779

Epoch: 5| Step: 9
Training loss: 2.5502769947052
Validation loss: 2.5511056864133446

Epoch: 5| Step: 10
Training loss: 2.8763959407806396
Validation loss: 2.55092425756557

Epoch: 117| Step: 0
Training loss: 2.055375337600708
Validation loss: 2.5515535569960073

Epoch: 5| Step: 1
Training loss: 2.9843075275421143
Validation loss: 2.553757475268456

Epoch: 5| Step: 2
Training loss: 2.1521413326263428
Validation loss: 2.5498488539008686

Epoch: 5| Step: 3
Training loss: 2.8460211753845215
Validation loss: 2.545499796508461

Epoch: 5| Step: 4
Training loss: 3.095907211303711
Validation loss: 2.5512198786581717

Epoch: 5| Step: 5
Training loss: 3.365753173828125
Validation loss: 2.546855670149608

Epoch: 5| Step: 6
Training loss: 2.9793665409088135
Validation loss: 2.546734094619751

Epoch: 5| Step: 7
Training loss: 2.454068660736084
Validation loss: 2.5450013350414973

Epoch: 5| Step: 8
Training loss: 3.3748302459716797
Validation loss: 2.5424399529733965

Epoch: 5| Step: 9
Training loss: 1.993594765663147
Validation loss: 2.5398017821773404

Epoch: 5| Step: 10
Training loss: 2.546449899673462
Validation loss: 2.5400442692541305

Epoch: 118| Step: 0
Training loss: 3.066056251525879
Validation loss: 2.546257031861172

Epoch: 5| Step: 1
Training loss: 2.149977922439575
Validation loss: 2.5446618910758727

Epoch: 5| Step: 2
Training loss: 2.2552847862243652
Validation loss: 2.5435918915656304

Epoch: 5| Step: 3
Training loss: 2.3538193702697754
Validation loss: 2.544446086370817

Epoch: 5| Step: 4
Training loss: 2.5748040676116943
Validation loss: 2.5511375345209593

Epoch: 5| Step: 5
Training loss: 3.2621073722839355
Validation loss: 2.550588551387992

Epoch: 5| Step: 6
Training loss: 2.677140712738037
Validation loss: 2.549822343293057

Epoch: 5| Step: 7
Training loss: 3.068006992340088
Validation loss: 2.557720994436613

Epoch: 5| Step: 8
Training loss: 2.533936023712158
Validation loss: 2.5697848027752292

Epoch: 5| Step: 9
Training loss: 3.1834449768066406
Validation loss: 2.5770695235139582

Epoch: 5| Step: 10
Training loss: 2.8548948764801025
Validation loss: 2.5897836915908323

Epoch: 119| Step: 0
Training loss: 2.9424970149993896
Validation loss: 2.5615538653507026

Epoch: 5| Step: 1
Training loss: 2.5511205196380615
Validation loss: 2.5449331960370465

Epoch: 5| Step: 2
Training loss: 2.8719515800476074
Validation loss: 2.552368248662641

Epoch: 5| Step: 3
Training loss: 2.39723539352417
Validation loss: 2.5700550566437426

Epoch: 5| Step: 4
Training loss: 3.150277614593506
Validation loss: 2.579300288231142

Epoch: 5| Step: 5
Training loss: 2.5651776790618896
Validation loss: 2.586618992590135

Epoch: 5| Step: 6
Training loss: 2.5030853748321533
Validation loss: 2.5853300556059806

Epoch: 5| Step: 7
Training loss: 2.557891368865967
Validation loss: 2.5770606968992498

Epoch: 5| Step: 8
Training loss: 2.7979836463928223
Validation loss: 2.563623064307756

Epoch: 5| Step: 9
Training loss: 2.6507568359375
Validation loss: 2.552366179804648

Epoch: 5| Step: 10
Training loss: 3.0983355045318604
Validation loss: 2.547151116914647

Epoch: 120| Step: 0
Training loss: 2.9905405044555664
Validation loss: 2.542048279957105

Epoch: 5| Step: 1
Training loss: 2.70811128616333
Validation loss: 2.536082219052058

Epoch: 5| Step: 2
Training loss: 2.733168125152588
Validation loss: 2.5362406033341602

Epoch: 5| Step: 3
Training loss: 2.9641594886779785
Validation loss: 2.5301293506417224

Epoch: 5| Step: 4
Training loss: 2.7338924407958984
Validation loss: 2.534982337746569

Epoch: 5| Step: 5
Training loss: 2.4551544189453125
Validation loss: 2.531651948087959

Epoch: 5| Step: 6
Training loss: 2.0093719959259033
Validation loss: 2.528962307078864

Epoch: 5| Step: 7
Training loss: 2.9528934955596924
Validation loss: 2.5299081853640977

Epoch: 5| Step: 8
Training loss: 2.7213237285614014
Validation loss: 2.530395543703469

Epoch: 5| Step: 9
Training loss: 2.8682610988616943
Validation loss: 2.539699774916454

Epoch: 5| Step: 10
Training loss: 2.7193431854248047
Validation loss: 2.54233298506788

Epoch: 121| Step: 0
Training loss: 3.2271201610565186
Validation loss: 2.530871037513979

Epoch: 5| Step: 1
Training loss: 2.6329853534698486
Validation loss: 2.5278721112076954

Epoch: 5| Step: 2
Training loss: 2.6088428497314453
Validation loss: 2.5299801108657674

Epoch: 5| Step: 3
Training loss: 2.2684738636016846
Validation loss: 2.5285814628806165

Epoch: 5| Step: 4
Training loss: 3.0142745971679688
Validation loss: 2.5304607165757047

Epoch: 5| Step: 5
Training loss: 2.600324869155884
Validation loss: 2.5313032519432808

Epoch: 5| Step: 6
Training loss: 2.179884672164917
Validation loss: 2.52780310825635

Epoch: 5| Step: 7
Training loss: 2.976600408554077
Validation loss: 2.5332489782764065

Epoch: 5| Step: 8
Training loss: 2.7024431228637695
Validation loss: 2.5294561693745274

Epoch: 5| Step: 9
Training loss: 2.86417293548584
Validation loss: 2.5304191573973625

Epoch: 5| Step: 10
Training loss: 2.697192907333374
Validation loss: 2.5332711076223724

Epoch: 122| Step: 0
Training loss: 2.647913694381714
Validation loss: 2.5271909108725925

Epoch: 5| Step: 1
Training loss: 2.7128219604492188
Validation loss: 2.5277929767485587

Epoch: 5| Step: 2
Training loss: 3.1073005199432373
Validation loss: 2.53278874710042

Epoch: 5| Step: 3
Training loss: 3.1561503410339355
Validation loss: 2.541088665685346

Epoch: 5| Step: 4
Training loss: 2.83577823638916
Validation loss: 2.5548664190435924

Epoch: 5| Step: 5
Training loss: 2.7849345207214355
Validation loss: 2.561797088192355

Epoch: 5| Step: 6
Training loss: 2.048867702484131
Validation loss: 2.5581866695034887

Epoch: 5| Step: 7
Training loss: 2.172049045562744
Validation loss: 2.5491479417329193

Epoch: 5| Step: 8
Training loss: 2.5102570056915283
Validation loss: 2.5455380332085396

Epoch: 5| Step: 9
Training loss: 2.677259922027588
Validation loss: 2.5625546183637393

Epoch: 5| Step: 10
Training loss: 3.3468778133392334
Validation loss: 2.556738015144102

Epoch: 123| Step: 0
Training loss: 2.1771903038024902
Validation loss: 2.5554462735370924

Epoch: 5| Step: 1
Training loss: 2.4728779792785645
Validation loss: 2.551965787846555

Epoch: 5| Step: 2
Training loss: 2.133297920227051
Validation loss: 2.54881057687985

Epoch: 5| Step: 3
Training loss: 2.851884365081787
Validation loss: 2.5439322481873217

Epoch: 5| Step: 4
Training loss: 2.963489532470703
Validation loss: 2.5305161758135726

Epoch: 5| Step: 5
Training loss: 3.026139497756958
Validation loss: 2.52708415831289

Epoch: 5| Step: 6
Training loss: 2.5911269187927246
Validation loss: 2.529455525900728

Epoch: 5| Step: 7
Training loss: 2.684818744659424
Validation loss: 2.5229951361174225

Epoch: 5| Step: 8
Training loss: 3.18452525138855
Validation loss: 2.523979781776346

Epoch: 5| Step: 9
Training loss: 2.964993715286255
Validation loss: 2.523246713863906

Epoch: 5| Step: 10
Training loss: 2.6803090572357178
Validation loss: 2.534482309895177

Epoch: 124| Step: 0
Training loss: 2.410684823989868
Validation loss: 2.5487785877720004

Epoch: 5| Step: 1
Training loss: 2.642111301422119
Validation loss: 2.560939459390538

Epoch: 5| Step: 2
Training loss: 2.2976508140563965
Validation loss: 2.572953361336903

Epoch: 5| Step: 3
Training loss: 3.0209617614746094
Validation loss: 2.569120732686853

Epoch: 5| Step: 4
Training loss: 2.3721370697021484
Validation loss: 2.5738445174309517

Epoch: 5| Step: 5
Training loss: 2.604992628097534
Validation loss: 2.563318339727258

Epoch: 5| Step: 6
Training loss: 2.6024575233459473
Validation loss: 2.5612038130401285

Epoch: 5| Step: 7
Training loss: 3.625765562057495
Validation loss: 2.550425555116387

Epoch: 5| Step: 8
Training loss: 2.7504184246063232
Validation loss: 2.5352968631252164

Epoch: 5| Step: 9
Training loss: 2.749443292617798
Validation loss: 2.531915556999945

Epoch: 5| Step: 10
Training loss: 2.801971197128296
Validation loss: 2.5240456032496628

Epoch: 125| Step: 0
Training loss: 2.2815489768981934
Validation loss: 2.520358813706265

Epoch: 5| Step: 1
Training loss: 2.69012451171875
Validation loss: 2.53295297520135

Epoch: 5| Step: 2
Training loss: 3.270463228225708
Validation loss: 2.539448017715126

Epoch: 5| Step: 3
Training loss: 2.582740306854248
Validation loss: 2.5411261153477493

Epoch: 5| Step: 4
Training loss: 2.8922348022460938
Validation loss: 2.5437717283925703

Epoch: 5| Step: 5
Training loss: 1.9045419692993164
Validation loss: 2.5626390954499603

Epoch: 5| Step: 6
Training loss: 3.130537748336792
Validation loss: 2.565293929910147

Epoch: 5| Step: 7
Training loss: 2.9409804344177246
Validation loss: 2.5592271820191415

Epoch: 5| Step: 8
Training loss: 3.095675468444824
Validation loss: 2.583066837761992

Epoch: 5| Step: 9
Training loss: 2.8427281379699707
Validation loss: 2.553209084336476

Epoch: 5| Step: 10
Training loss: 2.078461170196533
Validation loss: 2.5292560490228797

Epoch: 126| Step: 0
Training loss: 3.2545742988586426
Validation loss: 2.5258926037819154

Epoch: 5| Step: 1
Training loss: 2.186105251312256
Validation loss: 2.518605060474847

Epoch: 5| Step: 2
Training loss: 3.0754642486572266
Validation loss: 2.5186376571655273

Epoch: 5| Step: 3
Training loss: 2.8496956825256348
Validation loss: 2.5187531581488987

Epoch: 5| Step: 4
Training loss: 2.440629005432129
Validation loss: 2.515836556752523

Epoch: 5| Step: 5
Training loss: 2.993974208831787
Validation loss: 2.516911809162427

Epoch: 5| Step: 6
Training loss: 2.5758633613586426
Validation loss: 2.5168707960395404

Epoch: 5| Step: 7
Training loss: 2.7354822158813477
Validation loss: 2.5155605449471423

Epoch: 5| Step: 8
Training loss: 2.2830538749694824
Validation loss: 2.517538491115775

Epoch: 5| Step: 9
Training loss: 2.9293344020843506
Validation loss: 2.5192272611843642

Epoch: 5| Step: 10
Training loss: 2.2362499237060547
Validation loss: 2.5208746105112056

Epoch: 127| Step: 0
Training loss: 2.3311407566070557
Validation loss: 2.5333565050555813

Epoch: 5| Step: 1
Training loss: 2.6577725410461426
Validation loss: 2.553464645980507

Epoch: 5| Step: 2
Training loss: 2.8790831565856934
Validation loss: 2.5882030046114357

Epoch: 5| Step: 3
Training loss: 2.291531801223755
Validation loss: 2.580368877739035

Epoch: 5| Step: 4
Training loss: 2.587052822113037
Validation loss: 2.565417358952184

Epoch: 5| Step: 5
Training loss: 3.009718656539917
Validation loss: 2.5563850889923754

Epoch: 5| Step: 6
Training loss: 3.7222354412078857
Validation loss: 2.5266793722747476

Epoch: 5| Step: 7
Training loss: 2.266590118408203
Validation loss: 2.5231662155479513

Epoch: 5| Step: 8
Training loss: 2.919257640838623
Validation loss: 2.519977866962392

Epoch: 5| Step: 9
Training loss: 2.6159515380859375
Validation loss: 2.52026338987453

Epoch: 5| Step: 10
Training loss: 2.402956247329712
Validation loss: 2.52381500633814

Epoch: 128| Step: 0
Training loss: 2.754668951034546
Validation loss: 2.524357675224222

Epoch: 5| Step: 1
Training loss: 2.9988722801208496
Validation loss: 2.517614746606478

Epoch: 5| Step: 2
Training loss: 2.6041259765625
Validation loss: 2.517612418820781

Epoch: 5| Step: 3
Training loss: 2.6366870403289795
Validation loss: 2.519185446923779

Epoch: 5| Step: 4
Training loss: 3.032186985015869
Validation loss: 2.5312035955408567

Epoch: 5| Step: 5
Training loss: 2.2143924236297607
Validation loss: 2.543055106234807

Epoch: 5| Step: 6
Training loss: 2.173832654953003
Validation loss: 2.5669078544903825

Epoch: 5| Step: 7
Training loss: 3.183448314666748
Validation loss: 2.563523474559989

Epoch: 5| Step: 8
Training loss: 2.6212410926818848
Validation loss: 2.562629102378763

Epoch: 5| Step: 9
Training loss: 2.406047821044922
Validation loss: 2.563624992165514

Epoch: 5| Step: 10
Training loss: 3.2087583541870117
Validation loss: 2.557868819082937

Epoch: 129| Step: 0
Training loss: 2.7172205448150635
Validation loss: 2.551483328624438

Epoch: 5| Step: 1
Training loss: 2.8252084255218506
Validation loss: 2.5442806084950766

Epoch: 5| Step: 2
Training loss: 2.5333945751190186
Validation loss: 2.5305001504959597

Epoch: 5| Step: 3
Training loss: 2.4945805072784424
Validation loss: 2.529038098550612

Epoch: 5| Step: 4
Training loss: 2.285337448120117
Validation loss: 2.5202271528141473

Epoch: 5| Step: 5
Training loss: 2.7192842960357666
Validation loss: 2.5163816995518182

Epoch: 5| Step: 6
Training loss: 2.945685386657715
Validation loss: 2.5202852961837605

Epoch: 5| Step: 7
Training loss: 2.064983367919922
Validation loss: 2.5248134597655265

Epoch: 5| Step: 8
Training loss: 3.300194501876831
Validation loss: 2.5181203067943616

Epoch: 5| Step: 9
Training loss: 2.6802115440368652
Validation loss: 2.507086407753729

Epoch: 5| Step: 10
Training loss: 3.1366007328033447
Validation loss: 2.509561043913646

Epoch: 130| Step: 0
Training loss: 2.7164151668548584
Validation loss: 2.500870914869411

Epoch: 5| Step: 1
Training loss: 2.604801893234253
Validation loss: 2.5005213086323073

Epoch: 5| Step: 2
Training loss: 2.803018093109131
Validation loss: 2.5019715755216536

Epoch: 5| Step: 3
Training loss: 3.251347303390503
Validation loss: 2.5030623610301683

Epoch: 5| Step: 4
Training loss: 2.9667043685913086
Validation loss: 2.5077660019679735

Epoch: 5| Step: 5
Training loss: 2.0074024200439453
Validation loss: 2.5066022232014644

Epoch: 5| Step: 6
Training loss: 2.6231913566589355
Validation loss: 2.512093949061568

Epoch: 5| Step: 7
Training loss: 2.5299408435821533
Validation loss: 2.509980837504069

Epoch: 5| Step: 8
Training loss: 2.6923375129699707
Validation loss: 2.5144798422372467

Epoch: 5| Step: 9
Training loss: 2.511113166809082
Validation loss: 2.513355390999907

Epoch: 5| Step: 10
Training loss: 2.962393283843994
Validation loss: 2.514721585858253

Epoch: 131| Step: 0
Training loss: 3.159315586090088
Validation loss: 2.510242182721374

Epoch: 5| Step: 1
Training loss: 2.6220498085021973
Validation loss: 2.507490227299352

Epoch: 5| Step: 2
Training loss: 2.8220887184143066
Validation loss: 2.5079258667525424

Epoch: 5| Step: 3
Training loss: 2.289968967437744
Validation loss: 2.5078320990326586

Epoch: 5| Step: 4
Training loss: 2.7229833602905273
Validation loss: 2.512541873480684

Epoch: 5| Step: 5
Training loss: 2.3440027236938477
Validation loss: 2.5044787852994856

Epoch: 5| Step: 6
Training loss: 3.0493528842926025
Validation loss: 2.508302178434146

Epoch: 5| Step: 7
Training loss: 2.70398211479187
Validation loss: 2.5071651986850205

Epoch: 5| Step: 8
Training loss: 2.513434886932373
Validation loss: 2.503926246396957

Epoch: 5| Step: 9
Training loss: 2.3968520164489746
Validation loss: 2.49990939581266

Epoch: 5| Step: 10
Training loss: 3.053049087524414
Validation loss: 2.4981263401687785

Epoch: 132| Step: 0
Training loss: 2.7478995323181152
Validation loss: 2.496753610590453

Epoch: 5| Step: 1
Training loss: 3.0947682857513428
Validation loss: 2.496842973975725

Epoch: 5| Step: 2
Training loss: 1.9640651941299438
Validation loss: 2.4954611998732372

Epoch: 5| Step: 3
Training loss: 2.3552823066711426
Validation loss: 2.499918988955918

Epoch: 5| Step: 4
Training loss: 2.377606153488159
Validation loss: 2.4981016882004274

Epoch: 5| Step: 5
Training loss: 3.313408613204956
Validation loss: 2.5026630560557046

Epoch: 5| Step: 6
Training loss: 2.769768714904785
Validation loss: 2.4979147180434196

Epoch: 5| Step: 7
Training loss: 3.503781795501709
Validation loss: 2.4996725782271354

Epoch: 5| Step: 8
Training loss: 2.6237435340881348
Validation loss: 2.5005855585939143

Epoch: 5| Step: 9
Training loss: 2.0988221168518066
Validation loss: 2.502006338488671

Epoch: 5| Step: 10
Training loss: 2.681436777114868
Validation loss: 2.498654427066926

Epoch: 133| Step: 0
Training loss: 2.8357021808624268
Validation loss: 2.50403182993653

Epoch: 5| Step: 1
Training loss: 2.572960615158081
Validation loss: 2.5124693480871056

Epoch: 5| Step: 2
Training loss: 2.7776732444763184
Validation loss: 2.514739005796371

Epoch: 5| Step: 3
Training loss: 2.685939311981201
Validation loss: 2.5146314995263213

Epoch: 5| Step: 4
Training loss: 2.31581974029541
Validation loss: 2.5138778686523438

Epoch: 5| Step: 5
Training loss: 2.8449349403381348
Validation loss: 2.509234405332996

Epoch: 5| Step: 6
Training loss: 3.4335811138153076
Validation loss: 2.507627505128102

Epoch: 5| Step: 7
Training loss: 2.838937759399414
Validation loss: 2.505264684718142

Epoch: 5| Step: 8
Training loss: 2.386213779449463
Validation loss: 2.5045102052791144

Epoch: 5| Step: 9
Training loss: 2.4946353435516357
Validation loss: 2.5008884322258735

Epoch: 5| Step: 10
Training loss: 2.2457356452941895
Validation loss: 2.5004736890075026

Epoch: 134| Step: 0
Training loss: 2.507270097732544
Validation loss: 2.495826029008435

Epoch: 5| Step: 1
Training loss: 2.0807864665985107
Validation loss: 2.4959308126921296

Epoch: 5| Step: 2
Training loss: 3.2925829887390137
Validation loss: 2.5007359135535454

Epoch: 5| Step: 3
Training loss: 3.4500670433044434
Validation loss: 2.506970536324286

Epoch: 5| Step: 4
Training loss: 2.7781853675842285
Validation loss: 2.5173418444971882

Epoch: 5| Step: 5
Training loss: 2.3419806957244873
Validation loss: 2.5176253139331775

Epoch: 5| Step: 6
Training loss: 2.5335943698883057
Validation loss: 2.52392081804173

Epoch: 5| Step: 7
Training loss: 2.378457546234131
Validation loss: 2.523979692048924

Epoch: 5| Step: 8
Training loss: 2.2713210582733154
Validation loss: 2.5295901811251076

Epoch: 5| Step: 9
Training loss: 2.6965699195861816
Validation loss: 2.530963082467356

Epoch: 5| Step: 10
Training loss: 3.1265227794647217
Validation loss: 2.52985712276992

Epoch: 135| Step: 0
Training loss: 2.8841769695281982
Validation loss: 2.520968734577138

Epoch: 5| Step: 1
Training loss: 2.927238941192627
Validation loss: 2.511787542732813

Epoch: 5| Step: 2
Training loss: 2.8967463970184326
Validation loss: 2.5173943683665287

Epoch: 5| Step: 3
Training loss: 2.2351317405700684
Validation loss: 2.5126612417159544

Epoch: 5| Step: 4
Training loss: 2.964993715286255
Validation loss: 2.517007484230944

Epoch: 5| Step: 5
Training loss: 2.8532638549804688
Validation loss: 2.521726785167571

Epoch: 5| Step: 6
Training loss: 2.49979567527771
Validation loss: 2.5312935947090067

Epoch: 5| Step: 7
Training loss: 2.1336402893066406
Validation loss: 2.5371077060699463

Epoch: 5| Step: 8
Training loss: 3.184877395629883
Validation loss: 2.5271432515113585

Epoch: 5| Step: 9
Training loss: 2.888831853866577
Validation loss: 2.530371589045371

Epoch: 5| Step: 10
Training loss: 1.9275485277175903
Validation loss: 2.5183417233087684

Epoch: 136| Step: 0
Training loss: 2.910848617553711
Validation loss: 2.520646397785474

Epoch: 5| Step: 1
Training loss: 2.3986706733703613
Validation loss: 2.5248718005354687

Epoch: 5| Step: 2
Training loss: 2.659498691558838
Validation loss: 2.527023282102359

Epoch: 5| Step: 3
Training loss: 2.3766379356384277
Validation loss: 2.5249373899993075

Epoch: 5| Step: 4
Training loss: 2.679719924926758
Validation loss: 2.5183921167927403

Epoch: 5| Step: 5
Training loss: 2.993849754333496
Validation loss: 2.507801463527064

Epoch: 5| Step: 6
Training loss: 2.0511319637298584
Validation loss: 2.500558617294476

Epoch: 5| Step: 7
Training loss: 2.439596652984619
Validation loss: 2.500891141994025

Epoch: 5| Step: 8
Training loss: 2.683614492416382
Validation loss: 2.4956302617185857

Epoch: 5| Step: 9
Training loss: 3.1651337146759033
Validation loss: 2.4923709182329077

Epoch: 5| Step: 10
Training loss: 3.1113646030426025
Validation loss: 2.492411069972541

Epoch: 137| Step: 0
Training loss: 2.179190158843994
Validation loss: 2.49320279013726

Epoch: 5| Step: 1
Training loss: 2.658073663711548
Validation loss: 2.488332671503867

Epoch: 5| Step: 2
Training loss: 3.1942057609558105
Validation loss: 2.4917911483395483

Epoch: 5| Step: 3
Training loss: 2.3269424438476562
Validation loss: 2.4957816267526276

Epoch: 5| Step: 4
Training loss: 3.2754006385803223
Validation loss: 2.489163831997943

Epoch: 5| Step: 5
Training loss: 1.7764027118682861
Validation loss: 2.487783806298369

Epoch: 5| Step: 6
Training loss: 3.323085069656372
Validation loss: 2.492704212024648

Epoch: 5| Step: 7
Training loss: 2.524155855178833
Validation loss: 2.4930471451051774

Epoch: 5| Step: 8
Training loss: 3.003249406814575
Validation loss: 2.4860193370490946

Epoch: 5| Step: 9
Training loss: 2.525304079055786
Validation loss: 2.4884385806258007

Epoch: 5| Step: 10
Training loss: 2.582308053970337
Validation loss: 2.491292474090412

Epoch: 138| Step: 0
Training loss: 2.615668773651123
Validation loss: 2.4908487514782975

Epoch: 5| Step: 1
Training loss: 2.3436391353607178
Validation loss: 2.4933097054881435

Epoch: 5| Step: 2
Training loss: 3.4303627014160156
Validation loss: 2.494756393535163

Epoch: 5| Step: 3
Training loss: 3.0923962593078613
Validation loss: 2.4970504558214577

Epoch: 5| Step: 4
Training loss: 3.155479907989502
Validation loss: 2.4955230220671623

Epoch: 5| Step: 5
Training loss: 2.6744391918182373
Validation loss: 2.4957742819222073

Epoch: 5| Step: 6
Training loss: 2.7427785396575928
Validation loss: 2.4936335189368135

Epoch: 5| Step: 7
Training loss: 2.3775644302368164
Validation loss: 2.491935381325342

Epoch: 5| Step: 8
Training loss: 2.658344268798828
Validation loss: 2.495127753544879

Epoch: 5| Step: 9
Training loss: 2.0917065143585205
Validation loss: 2.492839913214407

Epoch: 5| Step: 10
Training loss: 2.102710485458374
Validation loss: 2.4944684274734987

Epoch: 139| Step: 0
Training loss: 2.1884963512420654
Validation loss: 2.4951452388558337

Epoch: 5| Step: 1
Training loss: 3.0152363777160645
Validation loss: 2.5130613029644056

Epoch: 5| Step: 2
Training loss: 2.733536958694458
Validation loss: 2.504985474771069

Epoch: 5| Step: 3
Training loss: 2.053959846496582
Validation loss: 2.4994784144945044

Epoch: 5| Step: 4
Training loss: 2.410330295562744
Validation loss: 2.514449888660062

Epoch: 5| Step: 5
Training loss: 2.999591112136841
Validation loss: 2.519090149992256

Epoch: 5| Step: 6
Training loss: 2.3885719776153564
Validation loss: 2.5222408848424114

Epoch: 5| Step: 7
Training loss: 2.9279277324676514
Validation loss: 2.526717121883105

Epoch: 5| Step: 8
Training loss: 3.2024130821228027
Validation loss: 2.520507925300188

Epoch: 5| Step: 9
Training loss: 1.942388892173767
Validation loss: 2.502442959816225

Epoch: 5| Step: 10
Training loss: 3.603156566619873
Validation loss: 2.4989132932437363

Epoch: 140| Step: 0
Training loss: 3.205496311187744
Validation loss: 2.489865251766738

Epoch: 5| Step: 1
Training loss: 2.8003647327423096
Validation loss: 2.493980546151438

Epoch: 5| Step: 2
Training loss: 3.660662889480591
Validation loss: 2.496405924520185

Epoch: 5| Step: 3
Training loss: 2.929182529449463
Validation loss: 2.508698509585473

Epoch: 5| Step: 4
Training loss: 2.213040828704834
Validation loss: 2.520992357243774

Epoch: 5| Step: 5
Training loss: 3.352024555206299
Validation loss: 2.5342425274592575

Epoch: 5| Step: 6
Training loss: 2.0794734954833984
Validation loss: 2.5276522995323263

Epoch: 5| Step: 7
Training loss: 2.035639524459839
Validation loss: 2.5257034711940314

Epoch: 5| Step: 8
Training loss: 2.289454936981201
Validation loss: 2.51553871041985

Epoch: 5| Step: 9
Training loss: 2.5816855430603027
Validation loss: 2.5012976661805184

Epoch: 5| Step: 10
Training loss: 2.1009695529937744
Validation loss: 2.479505649176977

Epoch: 141| Step: 0
Training loss: 2.961085796356201
Validation loss: 2.4756010193978586

Epoch: 5| Step: 1
Training loss: 2.146543264389038
Validation loss: 2.472557670326643

Epoch: 5| Step: 2
Training loss: 2.602727174758911
Validation loss: 2.481747001729986

Epoch: 5| Step: 3
Training loss: 3.1725621223449707
Validation loss: 2.4803313798801874

Epoch: 5| Step: 4
Training loss: 2.254988670349121
Validation loss: 2.501338315266435

Epoch: 5| Step: 5
Training loss: 2.6114978790283203
Validation loss: 2.49703969365807

Epoch: 5| Step: 6
Training loss: 1.9835630655288696
Validation loss: 2.495658887329922

Epoch: 5| Step: 7
Training loss: 3.019054412841797
Validation loss: 2.481214492551742

Epoch: 5| Step: 8
Training loss: 3.1589527130126953
Validation loss: 2.4741471121388097

Epoch: 5| Step: 9
Training loss: 2.74963116645813
Validation loss: 2.473795929262715

Epoch: 5| Step: 10
Training loss: 2.885411024093628
Validation loss: 2.477210929316859

Epoch: 142| Step: 0
Training loss: 1.9534832239151
Validation loss: 2.475372791290283

Epoch: 5| Step: 1
Training loss: 2.5559775829315186
Validation loss: 2.4747522543835383

Epoch: 5| Step: 2
Training loss: 2.4075112342834473
Validation loss: 2.4757727884477183

Epoch: 5| Step: 3
Training loss: 3.1484599113464355
Validation loss: 2.471665951513475

Epoch: 5| Step: 4
Training loss: 2.7880859375
Validation loss: 2.476543449586438

Epoch: 5| Step: 5
Training loss: 2.6964173316955566
Validation loss: 2.474376404157249

Epoch: 5| Step: 6
Training loss: 3.073333263397217
Validation loss: 2.4732458694006807

Epoch: 5| Step: 7
Training loss: 2.464320659637451
Validation loss: 2.4733533167069957

Epoch: 5| Step: 8
Training loss: 2.348456621170044
Validation loss: 2.4736697417433544

Epoch: 5| Step: 9
Training loss: 2.9902825355529785
Validation loss: 2.47063543463266

Epoch: 5| Step: 10
Training loss: 3.0775527954101562
Validation loss: 2.4701635709372898

Epoch: 143| Step: 0
Training loss: 2.4327542781829834
Validation loss: 2.4687343874285297

Epoch: 5| Step: 1
Training loss: 2.458113431930542
Validation loss: 2.4726160367329917

Epoch: 5| Step: 2
Training loss: 2.6520352363586426
Validation loss: 2.4710436251855667

Epoch: 5| Step: 3
Training loss: 3.276719570159912
Validation loss: 2.4716718068686863

Epoch: 5| Step: 4
Training loss: 2.8624892234802246
Validation loss: 2.478149257680421

Epoch: 5| Step: 5
Training loss: 2.41129994392395
Validation loss: 2.4762742339923816

Epoch: 5| Step: 6
Training loss: 2.591277599334717
Validation loss: 2.4730273113455823

Epoch: 5| Step: 7
Training loss: 2.6493184566497803
Validation loss: 2.4775543802527973

Epoch: 5| Step: 8
Training loss: 3.3427157402038574
Validation loss: 2.4796521945666243

Epoch: 5| Step: 9
Training loss: 2.308506965637207
Validation loss: 2.479845036742508

Epoch: 5| Step: 10
Training loss: 2.306938409805298
Validation loss: 2.4836361023687545

Epoch: 144| Step: 0
Training loss: 2.4310059547424316
Validation loss: 2.4809655143368627

Epoch: 5| Step: 1
Training loss: 2.6425445079803467
Validation loss: 2.4767034566530617

Epoch: 5| Step: 2
Training loss: 2.1429080963134766
Validation loss: 2.474924420797697

Epoch: 5| Step: 3
Training loss: 3.0428383350372314
Validation loss: 2.482382515425323

Epoch: 5| Step: 4
Training loss: 2.677448272705078
Validation loss: 2.478414943141322

Epoch: 5| Step: 5
Training loss: 3.4785923957824707
Validation loss: 2.4820518621834378

Epoch: 5| Step: 6
Training loss: 2.889005184173584
Validation loss: 2.481930507126675

Epoch: 5| Step: 7
Training loss: 2.699052333831787
Validation loss: 2.4830918312072754

Epoch: 5| Step: 8
Training loss: 2.3511223793029785
Validation loss: 2.4870124504130375

Epoch: 5| Step: 9
Training loss: 2.5798206329345703
Validation loss: 2.4796991694358086

Epoch: 5| Step: 10
Training loss: 2.2245841026306152
Validation loss: 2.4782197526706162

Epoch: 145| Step: 0
Training loss: 2.431974411010742
Validation loss: 2.478987516895417

Epoch: 5| Step: 1
Training loss: 2.4741461277008057
Validation loss: 2.4761822121117705

Epoch: 5| Step: 2
Training loss: 2.9543304443359375
Validation loss: 2.477445461416757

Epoch: 5| Step: 3
Training loss: 2.557918071746826
Validation loss: 2.4887295102560394

Epoch: 5| Step: 4
Training loss: 2.395958423614502
Validation loss: 2.4779063065846763

Epoch: 5| Step: 5
Training loss: 2.3773081302642822
Validation loss: 2.5038874841505483

Epoch: 5| Step: 6
Training loss: 3.100285291671753
Validation loss: 2.4885368449713594

Epoch: 5| Step: 7
Training loss: 3.2646610736846924
Validation loss: 2.482752610278386

Epoch: 5| Step: 8
Training loss: 2.79465651512146
Validation loss: 2.472202480480235

Epoch: 5| Step: 9
Training loss: 2.3296351432800293
Validation loss: 2.466885551329582

Epoch: 5| Step: 10
Training loss: 2.4866280555725098
Validation loss: 2.4640862300831783

Epoch: 146| Step: 0
Training loss: 2.5249240398406982
Validation loss: 2.4706703693636003

Epoch: 5| Step: 1
Training loss: 3.049182176589966
Validation loss: 2.4668701771766908

Epoch: 5| Step: 2
Training loss: 2.2220139503479004
Validation loss: 2.4634547720673265

Epoch: 5| Step: 3
Training loss: 3.2308459281921387
Validation loss: 2.4665245830371814

Epoch: 5| Step: 4
Training loss: 1.928722620010376
Validation loss: 2.4683511308444444

Epoch: 5| Step: 5
Training loss: 2.0112087726593018
Validation loss: 2.468137425761069

Epoch: 5| Step: 6
Training loss: 3.177445650100708
Validation loss: 2.470420068310153

Epoch: 5| Step: 7
Training loss: 2.8962340354919434
Validation loss: 2.4677463270002797

Epoch: 5| Step: 8
Training loss: 2.3571760654449463
Validation loss: 2.467144081669469

Epoch: 5| Step: 9
Training loss: 3.0917744636535645
Validation loss: 2.4671076113177883

Epoch: 5| Step: 10
Training loss: 2.7686777114868164
Validation loss: 2.4645147913245746

Epoch: 147| Step: 0
Training loss: 2.1915812492370605
Validation loss: 2.4656502380166003

Epoch: 5| Step: 1
Training loss: 2.2645926475524902
Validation loss: 2.475081579659575

Epoch: 5| Step: 2
Training loss: 2.288729190826416
Validation loss: 2.4687796805494573

Epoch: 5| Step: 3
Training loss: 3.4743142127990723
Validation loss: 2.4690563396740983

Epoch: 5| Step: 4
Training loss: 2.7304465770721436
Validation loss: 2.4743026738525717

Epoch: 5| Step: 5
Training loss: 1.850195288658142
Validation loss: 2.4821353215043263

Epoch: 5| Step: 6
Training loss: 2.756803035736084
Validation loss: 2.4800692591615903

Epoch: 5| Step: 7
Training loss: 3.5461018085479736
Validation loss: 2.487022961339643

Epoch: 5| Step: 8
Training loss: 2.2880287170410156
Validation loss: 2.4848501284917197

Epoch: 5| Step: 9
Training loss: 3.0817313194274902
Validation loss: 2.4811500298079623

Epoch: 5| Step: 10
Training loss: 2.7972865104675293
Validation loss: 2.484610883138513

Epoch: 148| Step: 0
Training loss: 2.608438014984131
Validation loss: 2.4878830935365412

Epoch: 5| Step: 1
Training loss: 3.403109073638916
Validation loss: 2.50602223027137

Epoch: 5| Step: 2
Training loss: 2.4737839698791504
Validation loss: 2.513700403192992

Epoch: 5| Step: 3
Training loss: 2.7266128063201904
Validation loss: 2.5308733755542385

Epoch: 5| Step: 4
Training loss: 1.5824285745620728
Validation loss: 2.5334806339715117

Epoch: 5| Step: 5
Training loss: 2.2475571632385254
Validation loss: 2.5407261643358456

Epoch: 5| Step: 6
Training loss: 2.8268940448760986
Validation loss: 2.518440285036641

Epoch: 5| Step: 7
Training loss: 2.366490125656128
Validation loss: 2.5036237675656556

Epoch: 5| Step: 8
Training loss: 3.441096067428589
Validation loss: 2.492700289654475

Epoch: 5| Step: 9
Training loss: 3.315119981765747
Validation loss: 2.4737392087136545

Epoch: 5| Step: 10
Training loss: 2.1413419246673584
Validation loss: 2.470147209782754

Epoch: 149| Step: 0
Training loss: 2.116373062133789
Validation loss: 2.486176884302529

Epoch: 5| Step: 1
Training loss: 3.048748254776001
Validation loss: 2.492765301017351

Epoch: 5| Step: 2
Training loss: 2.0048911571502686
Validation loss: 2.5060389118809856

Epoch: 5| Step: 3
Training loss: 2.595852851867676
Validation loss: 2.496195964915778

Epoch: 5| Step: 4
Training loss: 2.665350914001465
Validation loss: 2.4985502740388275

Epoch: 5| Step: 5
Training loss: 2.8756842613220215
Validation loss: 2.485988438770335

Epoch: 5| Step: 6
Training loss: 3.3194079399108887
Validation loss: 2.4709563844947406

Epoch: 5| Step: 7
Training loss: 2.6307711601257324
Validation loss: 2.4594438870747886

Epoch: 5| Step: 8
Training loss: 2.565532922744751
Validation loss: 2.448934380726148

Epoch: 5| Step: 9
Training loss: 2.97859263420105
Validation loss: 2.4524412872970744

Epoch: 5| Step: 10
Training loss: 2.419710159301758
Validation loss: 2.4566904396139164

Epoch: 150| Step: 0
Training loss: 2.6733951568603516
Validation loss: 2.4537500360960602

Epoch: 5| Step: 1
Training loss: 2.243436098098755
Validation loss: 2.452968138520436

Epoch: 5| Step: 2
Training loss: 2.7882492542266846
Validation loss: 2.4499353234485914

Epoch: 5| Step: 3
Training loss: 2.4248743057250977
Validation loss: 2.448708952114146

Epoch: 5| Step: 4
Training loss: 2.299917221069336
Validation loss: 2.4474556984439975

Epoch: 5| Step: 5
Training loss: 3.099658966064453
Validation loss: 2.449411117902366

Epoch: 5| Step: 6
Training loss: 2.3882462978363037
Validation loss: 2.452152180415328

Epoch: 5| Step: 7
Training loss: 3.0032451152801514
Validation loss: 2.4567875682666735

Epoch: 5| Step: 8
Training loss: 3.1733803749084473
Validation loss: 2.4560022431035198

Epoch: 5| Step: 9
Training loss: 2.8365890979766846
Validation loss: 2.46105440714026

Epoch: 5| Step: 10
Training loss: 2.3066840171813965
Validation loss: 2.4558584408093522

Epoch: 151| Step: 0
Training loss: 2.3569369316101074
Validation loss: 2.4623531628680486

Epoch: 5| Step: 1
Training loss: 2.6886565685272217
Validation loss: 2.466987015098654

Epoch: 5| Step: 2
Training loss: 3.7779459953308105
Validation loss: 2.4811859951224378

Epoch: 5| Step: 3
Training loss: 2.4867186546325684
Validation loss: 2.483466758522936

Epoch: 5| Step: 4
Training loss: 2.324275493621826
Validation loss: 2.4864647003912155

Epoch: 5| Step: 5
Training loss: 2.7071189880371094
Validation loss: 2.4615565705043014

Epoch: 5| Step: 6
Training loss: 2.760373592376709
Validation loss: 2.468552138215752

Epoch: 5| Step: 7
Training loss: 2.037670850753784
Validation loss: 2.465397201558595

Epoch: 5| Step: 8
Training loss: 2.9538607597351074
Validation loss: 2.479587444695093

Epoch: 5| Step: 9
Training loss: 2.9865338802337646
Validation loss: 2.484082427076114

Epoch: 5| Step: 10
Training loss: 1.8476810455322266
Validation loss: 2.501004501055646

Epoch: 152| Step: 0
Training loss: 1.7949011325836182
Validation loss: 2.500912845775645

Epoch: 5| Step: 1
Training loss: 2.4543306827545166
Validation loss: 2.5042951107025146

Epoch: 5| Step: 2
Training loss: 2.5127060413360596
Validation loss: 2.5058450852670977

Epoch: 5| Step: 3
Training loss: 3.5438003540039062
Validation loss: 2.5437344146031204

Epoch: 5| Step: 4
Training loss: 3.190950393676758
Validation loss: 2.5178669191175893

Epoch: 5| Step: 5
Training loss: 3.250586748123169
Validation loss: 2.5092276296307965

Epoch: 5| Step: 6
Training loss: 2.733642339706421
Validation loss: 2.4880889628523137

Epoch: 5| Step: 7
Training loss: 2.3033032417297363
Validation loss: 2.4682136633062877

Epoch: 5| Step: 8
Training loss: 2.254467248916626
Validation loss: 2.458724093693559

Epoch: 5| Step: 9
Training loss: 2.683670997619629
Validation loss: 2.4697925172826296

Epoch: 5| Step: 10
Training loss: 2.4855144023895264
Validation loss: 2.475474626787247

Epoch: 153| Step: 0
Training loss: 2.0821566581726074
Validation loss: 2.472836817464521

Epoch: 5| Step: 1
Training loss: 3.0193912982940674
Validation loss: 2.467277398673437

Epoch: 5| Step: 2
Training loss: 3.121248722076416
Validation loss: 2.4705755428601335

Epoch: 5| Step: 3
Training loss: 2.0080418586730957
Validation loss: 2.466883482471589

Epoch: 5| Step: 4
Training loss: 2.9945566654205322
Validation loss: 2.4626102524418987

Epoch: 5| Step: 5
Training loss: 2.536705493927002
Validation loss: 2.469004677188012

Epoch: 5| Step: 6
Training loss: 2.896885633468628
Validation loss: 2.466580815212701

Epoch: 5| Step: 7
Training loss: 2.40317440032959
Validation loss: 2.4520541006518948

Epoch: 5| Step: 8
Training loss: 3.6236367225646973
Validation loss: 2.4627131569770073

Epoch: 5| Step: 9
Training loss: 1.9216712713241577
Validation loss: 2.467844219617946

Epoch: 5| Step: 10
Training loss: 2.55637526512146
Validation loss: 2.472198978547127

Epoch: 154| Step: 0
Training loss: 1.9828720092773438
Validation loss: 2.4664855451994043

Epoch: 5| Step: 1
Training loss: 3.012662410736084
Validation loss: 2.4804376889300603

Epoch: 5| Step: 2
Training loss: 2.882275104522705
Validation loss: 2.4913735030799784

Epoch: 5| Step: 3
Training loss: 2.724030017852783
Validation loss: 2.50013457575152

Epoch: 5| Step: 4
Training loss: 3.1689493656158447
Validation loss: 2.4720460214922504

Epoch: 5| Step: 5
Training loss: 2.3827102184295654
Validation loss: 2.456544148024692

Epoch: 5| Step: 6
Training loss: 2.0539090633392334
Validation loss: 2.4458862171378186

Epoch: 5| Step: 7
Training loss: 2.659242630004883
Validation loss: 2.4494735348609185

Epoch: 5| Step: 8
Training loss: 2.8361899852752686
Validation loss: 2.4557357142048497

Epoch: 5| Step: 9
Training loss: 2.995344877243042
Validation loss: 2.4625829214690835

Epoch: 5| Step: 10
Training loss: 2.4748754501342773
Validation loss: 2.4627452845214517

Epoch: 155| Step: 0
Training loss: 2.113616943359375
Validation loss: 2.4603419585894515

Epoch: 5| Step: 1
Training loss: 3.0963072776794434
Validation loss: 2.455385361948321

Epoch: 5| Step: 2
Training loss: 3.1163649559020996
Validation loss: 2.4552821087580856

Epoch: 5| Step: 3
Training loss: 2.548563241958618
Validation loss: 2.4580796534015286

Epoch: 5| Step: 4
Training loss: 2.6983282566070557
Validation loss: 2.4553385652521604

Epoch: 5| Step: 5
Training loss: 2.8598368167877197
Validation loss: 2.45577956527792

Epoch: 5| Step: 6
Training loss: 2.2911171913146973
Validation loss: 2.4536866398267847

Epoch: 5| Step: 7
Training loss: 2.4758713245391846
Validation loss: 2.460083197521907

Epoch: 5| Step: 8
Training loss: 2.7009084224700928
Validation loss: 2.4528344574794976

Epoch: 5| Step: 9
Training loss: 2.6710076332092285
Validation loss: 2.4631776450782694

Epoch: 5| Step: 10
Training loss: 2.317214012145996
Validation loss: 2.4698263804117837

Epoch: 156| Step: 0
Training loss: 2.438222646713257
Validation loss: 2.4985622744406424

Epoch: 5| Step: 1
Training loss: 2.48386549949646
Validation loss: 2.51623430303348

Epoch: 5| Step: 2
Training loss: 3.155488967895508
Validation loss: 2.542370988476661

Epoch: 5| Step: 3
Training loss: 2.3118033409118652
Validation loss: 2.5117648211858605

Epoch: 5| Step: 4
Training loss: 2.439135789871216
Validation loss: 2.508772314235728

Epoch: 5| Step: 5
Training loss: 2.044086456298828
Validation loss: 2.5041336500516502

Epoch: 5| Step: 6
Training loss: 3.2981162071228027
Validation loss: 2.498182292907469

Epoch: 5| Step: 7
Training loss: 3.2407937049865723
Validation loss: 2.4954210019880727

Epoch: 5| Step: 8
Training loss: 2.7978272438049316
Validation loss: 2.503689104510892

Epoch: 5| Step: 9
Training loss: 1.9003006219863892
Validation loss: 2.499204497183523

Epoch: 5| Step: 10
Training loss: 3.0407183170318604
Validation loss: 2.505251543496245

Epoch: 157| Step: 0
Training loss: 2.6039609909057617
Validation loss: 2.5125304832253406

Epoch: 5| Step: 1
Training loss: 2.88100004196167
Validation loss: 2.516417395684027

Epoch: 5| Step: 2
Training loss: 2.3472890853881836
Validation loss: 2.52228876339492

Epoch: 5| Step: 3
Training loss: 2.561424732208252
Validation loss: 2.524702310562134

Epoch: 5| Step: 4
Training loss: 2.9314329624176025
Validation loss: 2.5184468633385113

Epoch: 5| Step: 5
Training loss: 2.2113747596740723
Validation loss: 2.50843886662555

Epoch: 5| Step: 6
Training loss: 2.3001461029052734
Validation loss: 2.4734119215319232

Epoch: 5| Step: 7
Training loss: 2.7751171588897705
Validation loss: 2.4811701287505445

Epoch: 5| Step: 8
Training loss: 2.7344329357147217
Validation loss: 2.4634115644680556

Epoch: 5| Step: 9
Training loss: 3.0761749744415283
Validation loss: 2.4557450150930755

Epoch: 5| Step: 10
Training loss: 2.723578691482544
Validation loss: 2.452798135818974

Epoch: 158| Step: 0
Training loss: 3.0439608097076416
Validation loss: 2.4719035035820416

Epoch: 5| Step: 1
Training loss: 2.956845998764038
Validation loss: 2.4871551631599345

Epoch: 5| Step: 2
Training loss: 3.785439968109131
Validation loss: 2.5154565765011694

Epoch: 5| Step: 3
Training loss: 2.6149444580078125
Validation loss: 2.484344559331094

Epoch: 5| Step: 4
Training loss: 2.7341299057006836
Validation loss: 2.4718967740253737

Epoch: 5| Step: 5
Training loss: 2.2764506340026855
Validation loss: 2.456838289896647

Epoch: 5| Step: 6
Training loss: 1.696515440940857
Validation loss: 2.4613472364282094

Epoch: 5| Step: 7
Training loss: 2.764752149581909
Validation loss: 2.473271054606284

Epoch: 5| Step: 8
Training loss: 2.320718765258789
Validation loss: 2.4631633835454143

Epoch: 5| Step: 9
Training loss: 2.3370933532714844
Validation loss: 2.4842675065481536

Epoch: 5| Step: 10
Training loss: 2.329136371612549
Validation loss: 2.4809450795573573

Epoch: 159| Step: 0
Training loss: 2.6379282474517822
Validation loss: 2.4855598506107124

Epoch: 5| Step: 1
Training loss: 2.9244375228881836
Validation loss: 2.4929565383541967

Epoch: 5| Step: 2
Training loss: 2.5324528217315674
Validation loss: 2.4949279651846936

Epoch: 5| Step: 3
Training loss: 2.1655659675598145
Validation loss: 2.519841983754148

Epoch: 5| Step: 4
Training loss: 2.920372724533081
Validation loss: 2.5254631401390157

Epoch: 5| Step: 5
Training loss: 2.7825400829315186
Validation loss: 2.524853188504455

Epoch: 5| Step: 6
Training loss: 2.572575092315674
Validation loss: 2.508685399127263

Epoch: 5| Step: 7
Training loss: 2.6323695182800293
Validation loss: 2.4958337968395603

Epoch: 5| Step: 8
Training loss: 3.1028733253479004
Validation loss: 2.4974974073389524

Epoch: 5| Step: 9
Training loss: 2.098358392715454
Validation loss: 2.4818298073225122

Epoch: 5| Step: 10
Training loss: 2.662407875061035
Validation loss: 2.4841935839704288

Epoch: 160| Step: 0
Training loss: 2.57391095161438
Validation loss: 2.481027982568228

Epoch: 5| Step: 1
Training loss: 2.6878418922424316
Validation loss: 2.4817873380517446

Epoch: 5| Step: 2
Training loss: 2.648266553878784
Validation loss: 2.4901558827328425

Epoch: 5| Step: 3
Training loss: 2.4924135208129883
Validation loss: 2.480940144549134

Epoch: 5| Step: 4
Training loss: 3.007697343826294
Validation loss: 2.4688448136852634

Epoch: 5| Step: 5
Training loss: 2.4428439140319824
Validation loss: 2.456894664354222

Epoch: 5| Step: 6
Training loss: 2.3932485580444336
Validation loss: 2.457964548500635

Epoch: 5| Step: 7
Training loss: 3.1449484825134277
Validation loss: 2.468801462522117

Epoch: 5| Step: 8
Training loss: 2.4041430950164795
Validation loss: 2.46648318793184

Epoch: 5| Step: 9
Training loss: 2.5515549182891846
Validation loss: 2.468404910897696

Epoch: 5| Step: 10
Training loss: 2.5910091400146484
Validation loss: 2.47198921890669

Epoch: 161| Step: 0
Training loss: 2.462963581085205
Validation loss: 2.4895475705464682

Epoch: 5| Step: 1
Training loss: 2.5281102657318115
Validation loss: 2.4791248818879486

Epoch: 5| Step: 2
Training loss: 3.042858600616455
Validation loss: 2.479829372898225

Epoch: 5| Step: 3
Training loss: 2.557905673980713
Validation loss: 2.472000857835175

Epoch: 5| Step: 4
Training loss: 3.0056228637695312
Validation loss: 2.458600062195973

Epoch: 5| Step: 5
Training loss: 2.528517961502075
Validation loss: 2.4517396034732943

Epoch: 5| Step: 6
Training loss: 2.7953333854675293
Validation loss: 2.4385250460716987

Epoch: 5| Step: 7
Training loss: 2.3115170001983643
Validation loss: 2.436950788703016

Epoch: 5| Step: 8
Training loss: 2.0209712982177734
Validation loss: 2.4259032254577964

Epoch: 5| Step: 9
Training loss: 2.580954074859619
Validation loss: 2.4243260660479145

Epoch: 5| Step: 10
Training loss: 3.2630467414855957
Validation loss: 2.4202069672205115

Epoch: 162| Step: 0
Training loss: 2.5750937461853027
Validation loss: 2.4278256816248738

Epoch: 5| Step: 1
Training loss: 2.3414652347564697
Validation loss: 2.4351256124434935

Epoch: 5| Step: 2
Training loss: 2.81864333152771
Validation loss: 2.4297036432450816

Epoch: 5| Step: 3
Training loss: 1.9229423999786377
Validation loss: 2.4310267330497823

Epoch: 5| Step: 4
Training loss: 2.0782058238983154
Validation loss: 2.4547546730246594

Epoch: 5| Step: 5
Training loss: 2.9725325107574463
Validation loss: 2.4521531674169723

Epoch: 5| Step: 6
Training loss: 3.132516384124756
Validation loss: 2.455735542440927

Epoch: 5| Step: 7
Training loss: 3.1707684993743896
Validation loss: 2.453766220359392

Epoch: 5| Step: 8
Training loss: 2.694403886795044
Validation loss: 2.4397854240991736

Epoch: 5| Step: 9
Training loss: 2.983100652694702
Validation loss: 2.4404634788472164

Epoch: 5| Step: 10
Training loss: 2.213874578475952
Validation loss: 2.4430511741228003

Epoch: 163| Step: 0
Training loss: 2.5666160583496094
Validation loss: 2.4402889820837204

Epoch: 5| Step: 1
Training loss: 3.036783456802368
Validation loss: 2.4500459829966226

Epoch: 5| Step: 2
Training loss: 2.045957088470459
Validation loss: 2.4558948521972983

Epoch: 5| Step: 3
Training loss: 2.5526156425476074
Validation loss: 2.4740659754763366

Epoch: 5| Step: 4
Training loss: 2.4874520301818848
Validation loss: 2.4795529560376237

Epoch: 5| Step: 5
Training loss: 2.546313524246216
Validation loss: 2.4882919352541686

Epoch: 5| Step: 6
Training loss: 3.2605392932891846
Validation loss: 2.4927812289166194

Epoch: 5| Step: 7
Training loss: 2.7855420112609863
Validation loss: 2.49080164201798

Epoch: 5| Step: 8
Training loss: 2.5966670513153076
Validation loss: 2.4800566011859524

Epoch: 5| Step: 9
Training loss: 2.4466283321380615
Validation loss: 2.470668033886981

Epoch: 5| Step: 10
Training loss: 2.481153964996338
Validation loss: 2.4723843195105113

Epoch: 164| Step: 0
Training loss: 2.7218213081359863
Validation loss: 2.451404966333861

Epoch: 5| Step: 1
Training loss: 1.9934686422348022
Validation loss: 2.439301339528894

Epoch: 5| Step: 2
Training loss: 2.762068271636963
Validation loss: 2.434461442373132

Epoch: 5| Step: 3
Training loss: 2.0533459186553955
Validation loss: 2.432682196299235

Epoch: 5| Step: 4
Training loss: 3.074488401412964
Validation loss: 2.435510743048883

Epoch: 5| Step: 5
Training loss: 2.4920856952667236
Validation loss: 2.4345354444237164

Epoch: 5| Step: 6
Training loss: 2.9726474285125732
Validation loss: 2.4193750581433697

Epoch: 5| Step: 7
Training loss: 2.295663833618164
Validation loss: 2.422739589086143

Epoch: 5| Step: 8
Training loss: 2.9865882396698
Validation loss: 2.428845702960927

Epoch: 5| Step: 9
Training loss: 2.7433767318725586
Validation loss: 2.4242547917109665

Epoch: 5| Step: 10
Training loss: 2.781099319458008
Validation loss: 2.4301145230570147

Epoch: 165| Step: 0
Training loss: 2.9130613803863525
Validation loss: 2.431424148621098

Epoch: 5| Step: 1
Training loss: 2.398512840270996
Validation loss: 2.4349767597772742

Epoch: 5| Step: 2
Training loss: 2.6064953804016113
Validation loss: 2.4401360019560783

Epoch: 5| Step: 3
Training loss: 2.4288547039031982
Validation loss: 2.441793123881022

Epoch: 5| Step: 4
Training loss: 2.885554790496826
Validation loss: 2.44802592133963

Epoch: 5| Step: 5
Training loss: 2.719489812850952
Validation loss: 2.4584960424771873

Epoch: 5| Step: 6
Training loss: 2.772024393081665
Validation loss: 2.4647121121806483

Epoch: 5| Step: 7
Training loss: 2.1281986236572266
Validation loss: 2.4538163984975507

Epoch: 5| Step: 8
Training loss: 1.9606043100357056
Validation loss: 2.4463409403319

Epoch: 5| Step: 9
Training loss: 3.078929901123047
Validation loss: 2.439247695348596

Epoch: 5| Step: 10
Training loss: 3.093339681625366
Validation loss: 2.430642702246225

Epoch: 166| Step: 0
Training loss: 2.203047275543213
Validation loss: 2.422615364033689

Epoch: 5| Step: 1
Training loss: 3.146096706390381
Validation loss: 2.423871294144661

Epoch: 5| Step: 2
Training loss: 2.4874682426452637
Validation loss: 2.431707941075807

Epoch: 5| Step: 3
Training loss: 2.295563220977783
Validation loss: 2.4442513258226457

Epoch: 5| Step: 4
Training loss: 2.471735954284668
Validation loss: 2.4477834137537147

Epoch: 5| Step: 5
Training loss: 2.95426607131958
Validation loss: 2.451977978470505

Epoch: 5| Step: 6
Training loss: 2.438164234161377
Validation loss: 2.456594810690931

Epoch: 5| Step: 7
Training loss: 3.100682020187378
Validation loss: 2.459488848204254

Epoch: 5| Step: 8
Training loss: 2.3348803520202637
Validation loss: 2.4520667060728996

Epoch: 5| Step: 9
Training loss: 2.516082763671875
Validation loss: 2.454924734689856

Epoch: 5| Step: 10
Training loss: 2.9334211349487305
Validation loss: 2.4452197628636516

Epoch: 167| Step: 0
Training loss: 3.0016753673553467
Validation loss: 2.4415809826184343

Epoch: 5| Step: 1
Training loss: 2.606226921081543
Validation loss: 2.438630239937895

Epoch: 5| Step: 2
Training loss: 2.976916790008545
Validation loss: 2.4434429599392797

Epoch: 5| Step: 3
Training loss: 2.331744432449341
Validation loss: 2.4507875724505355

Epoch: 5| Step: 4
Training loss: 2.344928741455078
Validation loss: 2.451196385968116

Epoch: 5| Step: 5
Training loss: 2.505448818206787
Validation loss: 2.4601547436047624

Epoch: 5| Step: 6
Training loss: 2.3470966815948486
Validation loss: 2.4709202653618267

Epoch: 5| Step: 7
Training loss: 2.6254754066467285
Validation loss: 2.4756273531144664

Epoch: 5| Step: 8
Training loss: 2.51794171333313
Validation loss: 2.4774008258696525

Epoch: 5| Step: 9
Training loss: 3.0517356395721436
Validation loss: 2.4771768585328133

Epoch: 5| Step: 10
Training loss: 2.6218881607055664
Validation loss: 2.4756844671823646

Epoch: 168| Step: 0
Training loss: 2.757575511932373
Validation loss: 2.4578481463975805

Epoch: 5| Step: 1
Training loss: 2.973881244659424
Validation loss: 2.4576078819972214

Epoch: 5| Step: 2
Training loss: 2.094041347503662
Validation loss: 2.45423057002406

Epoch: 5| Step: 3
Training loss: 2.3674206733703613
Validation loss: 2.4645348620671097

Epoch: 5| Step: 4
Training loss: 2.2037405967712402
Validation loss: 2.4653809301314817

Epoch: 5| Step: 5
Training loss: 2.923964023590088
Validation loss: 2.458672518371254

Epoch: 5| Step: 6
Training loss: 2.496922492980957
Validation loss: 2.4498148349023636

Epoch: 5| Step: 7
Training loss: 2.067103147506714
Validation loss: 2.445827740494923

Epoch: 5| Step: 8
Training loss: 3.095093250274658
Validation loss: 2.438983919799969

Epoch: 5| Step: 9
Training loss: 2.8146634101867676
Validation loss: 2.4287087584054596

Epoch: 5| Step: 10
Training loss: 3.041842460632324
Validation loss: 2.4369279543558755

Epoch: 169| Step: 0
Training loss: 2.5439021587371826
Validation loss: 2.4448071602852113

Epoch: 5| Step: 1
Training loss: 2.290316104888916
Validation loss: 2.4594761710013113

Epoch: 5| Step: 2
Training loss: 3.2350914478302
Validation loss: 2.4825005249310563

Epoch: 5| Step: 3
Training loss: 1.8042411804199219
Validation loss: 2.4988013288026214

Epoch: 5| Step: 4
Training loss: 3.410508632659912
Validation loss: 2.5074057758495374

Epoch: 5| Step: 5
Training loss: 2.426254987716675
Validation loss: 2.5028825600941977

Epoch: 5| Step: 6
Training loss: 2.5104289054870605
Validation loss: 2.4734826908316663

Epoch: 5| Step: 7
Training loss: 2.1585195064544678
Validation loss: 2.4737810729652323

Epoch: 5| Step: 8
Training loss: 2.183806896209717
Validation loss: 2.499112034356722

Epoch: 5| Step: 9
Training loss: 3.19460391998291
Validation loss: 2.517837729505313

Epoch: 5| Step: 10
Training loss: 3.4645745754241943
Validation loss: 2.4942557427190963

Epoch: 170| Step: 0
Training loss: 2.750072479248047
Validation loss: 2.447953301091348

Epoch: 5| Step: 1
Training loss: 2.377453327178955
Validation loss: 2.4222677599999214

Epoch: 5| Step: 2
Training loss: 3.7238335609436035
Validation loss: 2.4110865721138577

Epoch: 5| Step: 3
Training loss: 2.721351146697998
Validation loss: 2.4165541612973778

Epoch: 5| Step: 4
Training loss: 3.2080752849578857
Validation loss: 2.453744352504771

Epoch: 5| Step: 5
Training loss: 2.1958816051483154
Validation loss: 2.483088888147826

Epoch: 5| Step: 6
Training loss: 2.4372339248657227
Validation loss: 2.495025339946952

Epoch: 5| Step: 7
Training loss: 2.098043203353882
Validation loss: 2.459188130594069

Epoch: 5| Step: 8
Training loss: 2.9731006622314453
Validation loss: 2.4380257283487627

Epoch: 5| Step: 9
Training loss: 1.9549907445907593
Validation loss: 2.413432610932217

Epoch: 5| Step: 10
Training loss: 2.4716641902923584
Validation loss: 2.4163064443936912

Epoch: 171| Step: 0
Training loss: 2.5354056358337402
Validation loss: 2.416667681868358

Epoch: 5| Step: 1
Training loss: 2.7092041969299316
Validation loss: 2.4166698199446484

Epoch: 5| Step: 2
Training loss: 2.3115172386169434
Validation loss: 2.428675433640839

Epoch: 5| Step: 3
Training loss: 2.376335382461548
Validation loss: 2.4465781398998794

Epoch: 5| Step: 4
Training loss: 2.112983226776123
Validation loss: 2.4414437073533253

Epoch: 5| Step: 5
Training loss: 2.6068615913391113
Validation loss: 2.4446168304771505

Epoch: 5| Step: 6
Training loss: 2.9404702186584473
Validation loss: 2.4620821911801576

Epoch: 5| Step: 7
Training loss: 3.0137364864349365
Validation loss: 2.469944956482098

Epoch: 5| Step: 8
Training loss: 3.1991970539093018
Validation loss: 2.461018418753019

Epoch: 5| Step: 9
Training loss: 2.583777904510498
Validation loss: 2.450078377159693

Epoch: 5| Step: 10
Training loss: 2.3182244300842285
Validation loss: 2.4411384597901375

Epoch: 172| Step: 0
Training loss: 2.3004143238067627
Validation loss: 2.4518130440865793

Epoch: 5| Step: 1
Training loss: 2.4727578163146973
Validation loss: 2.4574858680848153

Epoch: 5| Step: 2
Training loss: 1.7742096185684204
Validation loss: 2.457579066676478

Epoch: 5| Step: 3
Training loss: 2.937880039215088
Validation loss: 2.4586225273788616

Epoch: 5| Step: 4
Training loss: 2.669497013092041
Validation loss: 2.4526241389654015

Epoch: 5| Step: 5
Training loss: 2.6325161457061768
Validation loss: 2.451753754769602

Epoch: 5| Step: 6
Training loss: 2.9313175678253174
Validation loss: 2.4541143243030836

Epoch: 5| Step: 7
Training loss: 2.092104434967041
Validation loss: 2.4580515712820072

Epoch: 5| Step: 8
Training loss: 2.3395004272460938
Validation loss: 2.4456374055595806

Epoch: 5| Step: 9
Training loss: 3.521435499191284
Validation loss: 2.4483994207074566

Epoch: 5| Step: 10
Training loss: 3.015354633331299
Validation loss: 2.432803464192216

Epoch: 173| Step: 0
Training loss: 2.4868216514587402
Validation loss: 2.4458474779641755

Epoch: 5| Step: 1
Training loss: 2.377629041671753
Validation loss: 2.447814746569562

Epoch: 5| Step: 2
Training loss: 2.774005174636841
Validation loss: 2.4470917460738972

Epoch: 5| Step: 3
Training loss: 2.630798816680908
Validation loss: 2.452173335577852

Epoch: 5| Step: 4
Training loss: 2.7920970916748047
Validation loss: 2.4406690136078866

Epoch: 5| Step: 5
Training loss: 2.99306058883667
Validation loss: 2.4351713836833997

Epoch: 5| Step: 6
Training loss: 2.754946231842041
Validation loss: 2.428697839859993

Epoch: 5| Step: 7
Training loss: 2.482823133468628
Validation loss: 2.424950030542189

Epoch: 5| Step: 8
Training loss: 2.3119518756866455
Validation loss: 2.4279465239535094

Epoch: 5| Step: 9
Training loss: 2.549675464630127
Validation loss: 2.4195078470373668

Epoch: 5| Step: 10
Training loss: 2.299769401550293
Validation loss: 2.432673315848074

Epoch: 174| Step: 0
Training loss: 2.7113265991210938
Validation loss: 2.4429186057018977

Epoch: 5| Step: 1
Training loss: 2.7301154136657715
Validation loss: 2.4526388158080397

Epoch: 5| Step: 2
Training loss: 2.9416401386260986
Validation loss: 2.469370931707403

Epoch: 5| Step: 3
Training loss: 2.595261335372925
Validation loss: 2.4918737539681057

Epoch: 5| Step: 4
Training loss: 2.8025403022766113
Validation loss: 2.5079589505349436

Epoch: 5| Step: 5
Training loss: 2.1046090126037598
Validation loss: 2.4890066910815496

Epoch: 5| Step: 6
Training loss: 2.644425868988037
Validation loss: 2.4810963138457267

Epoch: 5| Step: 7
Training loss: 2.38555645942688
Validation loss: 2.4820584661217144

Epoch: 5| Step: 8
Training loss: 2.7954983711242676
Validation loss: 2.4639087518056235

Epoch: 5| Step: 9
Training loss: 2.58553147315979
Validation loss: 2.44863466037217

Epoch: 5| Step: 10
Training loss: 2.28100848197937
Validation loss: 2.4429909157496628

Epoch: 175| Step: 0
Training loss: 2.237067699432373
Validation loss: 2.4402101014250066

Epoch: 5| Step: 1
Training loss: 2.4214882850646973
Validation loss: 2.429805850469938

Epoch: 5| Step: 2
Training loss: 2.385211944580078
Validation loss: 2.4303417205810547

Epoch: 5| Step: 3
Training loss: 2.7659735679626465
Validation loss: 2.440429990009595

Epoch: 5| Step: 4
Training loss: 2.5249147415161133
Validation loss: 2.423406785534274

Epoch: 5| Step: 5
Training loss: 2.9824295043945312
Validation loss: 2.421655721561883

Epoch: 5| Step: 6
Training loss: 2.1687240600585938
Validation loss: 2.4222379140956427

Epoch: 5| Step: 7
Training loss: 2.9548428058624268
Validation loss: 2.430099477050125

Epoch: 5| Step: 8
Training loss: 3.427788257598877
Validation loss: 2.433002030977639

Epoch: 5| Step: 9
Training loss: 1.9611561298370361
Validation loss: 2.4433984295014413

Epoch: 5| Step: 10
Training loss: 2.8042750358581543
Validation loss: 2.4666210656524985

Epoch: 176| Step: 0
Training loss: 2.283184289932251
Validation loss: 2.4834081742071334

Epoch: 5| Step: 1
Training loss: 2.397418260574341
Validation loss: 2.4654416781599804

Epoch: 5| Step: 2
Training loss: 2.204813003540039
Validation loss: 2.4651005063005673

Epoch: 5| Step: 3
Training loss: 2.4918456077575684
Validation loss: 2.4562063576072775

Epoch: 5| Step: 4
Training loss: 3.000135898590088
Validation loss: 2.4373596150388

Epoch: 5| Step: 5
Training loss: 2.951345205307007
Validation loss: 2.4056926337621545

Epoch: 5| Step: 6
Training loss: 2.678429126739502
Validation loss: 2.4001252830669446

Epoch: 5| Step: 7
Training loss: 2.207048177719116
Validation loss: 2.396489374099239

Epoch: 5| Step: 8
Training loss: 1.9511789083480835
Validation loss: 2.38953899311763

Epoch: 5| Step: 9
Training loss: 3.287583112716675
Validation loss: 2.397827225346719

Epoch: 5| Step: 10
Training loss: 3.1467998027801514
Validation loss: 2.393078860416207

Epoch: 177| Step: 0
Training loss: 2.893465757369995
Validation loss: 2.394558737354894

Epoch: 5| Step: 1
Training loss: 2.600093364715576
Validation loss: 2.3902216803643013

Epoch: 5| Step: 2
Training loss: 2.280808687210083
Validation loss: 2.3848495509034846

Epoch: 5| Step: 3
Training loss: 2.4882400035858154
Validation loss: 2.3858281950796805

Epoch: 5| Step: 4
Training loss: 2.7279818058013916
Validation loss: 2.3800200364922963

Epoch: 5| Step: 5
Training loss: 2.615781784057617
Validation loss: 2.385318648430609

Epoch: 5| Step: 6
Training loss: 2.7187178134918213
Validation loss: 2.401580455482647

Epoch: 5| Step: 7
Training loss: 3.0557258129119873
Validation loss: 2.4069970833357943

Epoch: 5| Step: 8
Training loss: 2.4128472805023193
Validation loss: 2.4145594437917075

Epoch: 5| Step: 9
Training loss: 2.4901881217956543
Validation loss: 2.415936271349589

Epoch: 5| Step: 10
Training loss: 2.3436148166656494
Validation loss: 2.4197375338564635

Epoch: 178| Step: 0
Training loss: 2.382127523422241
Validation loss: 2.4350557045270036

Epoch: 5| Step: 1
Training loss: 2.6986117362976074
Validation loss: 2.44702269441338

Epoch: 5| Step: 2
Training loss: 2.8202452659606934
Validation loss: 2.451765993589996

Epoch: 5| Step: 3
Training loss: 2.4902400970458984
Validation loss: 2.449144576185493

Epoch: 5| Step: 4
Training loss: 2.6004252433776855
Validation loss: 2.4393990578189975

Epoch: 5| Step: 5
Training loss: 2.581357479095459
Validation loss: 2.4301289768629175

Epoch: 5| Step: 6
Training loss: 2.0772552490234375
Validation loss: 2.427654953413112

Epoch: 5| Step: 7
Training loss: 2.511059284210205
Validation loss: 2.427247942134898

Epoch: 5| Step: 8
Training loss: 2.7936439514160156
Validation loss: 2.4196934648739394

Epoch: 5| Step: 9
Training loss: 2.6176483631134033
Validation loss: 2.43173127020559

Epoch: 5| Step: 10
Training loss: 2.9669179916381836
Validation loss: 2.4333194084064935

Epoch: 179| Step: 0
Training loss: 2.5129990577697754
Validation loss: 2.4236999891137563

Epoch: 5| Step: 1
Training loss: 2.2306408882141113
Validation loss: 2.4358566358525264

Epoch: 5| Step: 2
Training loss: 2.3416781425476074
Validation loss: 2.4445680059412473

Epoch: 5| Step: 3
Training loss: 2.9350104331970215
Validation loss: 2.4537632003907235

Epoch: 5| Step: 4
Training loss: 2.3598625659942627
Validation loss: 2.4541498563622914

Epoch: 5| Step: 5
Training loss: 2.6092312335968018
Validation loss: 2.4510587902479273

Epoch: 5| Step: 6
Training loss: 3.052021026611328
Validation loss: 2.451638114067816

Epoch: 5| Step: 7
Training loss: 2.4099888801574707
Validation loss: 2.4497833610862814

Epoch: 5| Step: 8
Training loss: 3.640535831451416
Validation loss: 2.452633724417738

Epoch: 5| Step: 9
Training loss: 2.0442886352539062
Validation loss: 2.4532259536045853

Epoch: 5| Step: 10
Training loss: 2.3767476081848145
Validation loss: 2.4396276243271364

Epoch: 180| Step: 0
Training loss: 2.7945656776428223
Validation loss: 2.425575307620469

Epoch: 5| Step: 1
Training loss: 2.660853862762451
Validation loss: 2.4277364464216333

Epoch: 5| Step: 2
Training loss: 2.6512036323547363
Validation loss: 2.4172173007842033

Epoch: 5| Step: 3
Training loss: 2.500608444213867
Validation loss: 2.414473233684417

Epoch: 5| Step: 4
Training loss: 2.529357433319092
Validation loss: 2.4054786005327777

Epoch: 5| Step: 5
Training loss: 2.469313144683838
Validation loss: 2.4101117349440053

Epoch: 5| Step: 6
Training loss: 2.408824920654297
Validation loss: 2.4025881623709076

Epoch: 5| Step: 7
Training loss: 2.6447672843933105
Validation loss: 2.3989535172780356

Epoch: 5| Step: 8
Training loss: 2.5683302879333496
Validation loss: 2.3913370473410493

Epoch: 5| Step: 9
Training loss: 2.428842067718506
Validation loss: 2.3947292553481234

Epoch: 5| Step: 10
Training loss: 2.5838394165039062
Validation loss: 2.401611899816862

Epoch: 181| Step: 0
Training loss: 2.330697536468506
Validation loss: 2.4254286212305867

Epoch: 5| Step: 1
Training loss: 2.928684949874878
Validation loss: 2.439566248206682

Epoch: 5| Step: 2
Training loss: 2.7629384994506836
Validation loss: 2.4343865674029113

Epoch: 5| Step: 3
Training loss: 2.1575913429260254
Validation loss: 2.4425969816023305

Epoch: 5| Step: 4
Training loss: 2.968921661376953
Validation loss: 2.414375526930696

Epoch: 5| Step: 5
Training loss: 2.6934337615966797
Validation loss: 2.398334203227874

Epoch: 5| Step: 6
Training loss: 2.6569111347198486
Validation loss: 2.3968835210287445

Epoch: 5| Step: 7
Training loss: 1.4033278226852417
Validation loss: 2.3824914886105444

Epoch: 5| Step: 8
Training loss: 2.9485297203063965
Validation loss: 2.395405056656048

Epoch: 5| Step: 9
Training loss: 2.7688398361206055
Validation loss: 2.4007559822451685

Epoch: 5| Step: 10
Training loss: 2.7283570766448975
Validation loss: 2.3936912270002466

Epoch: 182| Step: 0
Training loss: 2.302459239959717
Validation loss: 2.399885049430273

Epoch: 5| Step: 1
Training loss: 2.4313457012176514
Validation loss: 2.3926170487557687

Epoch: 5| Step: 2
Training loss: 3.1800537109375
Validation loss: 2.386491629385179

Epoch: 5| Step: 3
Training loss: 2.582545518875122
Validation loss: 2.3818878153319

Epoch: 5| Step: 4
Training loss: 2.6519813537597656
Validation loss: 2.376946928680584

Epoch: 5| Step: 5
Training loss: 2.82059907913208
Validation loss: 2.3764728371815016

Epoch: 5| Step: 6
Training loss: 2.027782917022705
Validation loss: 2.3829602733735116

Epoch: 5| Step: 7
Training loss: 3.200138568878174
Validation loss: 2.3820108393187165

Epoch: 5| Step: 8
Training loss: 2.757239818572998
Validation loss: 2.3843701116500364

Epoch: 5| Step: 9
Training loss: 2.294821262359619
Validation loss: 2.393460771088959

Epoch: 5| Step: 10
Training loss: 2.1981213092803955
Validation loss: 2.410880147769887

Epoch: 183| Step: 0
Training loss: 2.437832832336426
Validation loss: 2.414759196260924

Epoch: 5| Step: 1
Training loss: 2.697119951248169
Validation loss: 2.4316820611235914

Epoch: 5| Step: 2
Training loss: 1.8649892807006836
Validation loss: 2.451806091493176

Epoch: 5| Step: 3
Training loss: 2.3012213706970215
Validation loss: 2.446636499897126

Epoch: 5| Step: 4
Training loss: 2.911606550216675
Validation loss: 2.4632341066996255

Epoch: 5| Step: 5
Training loss: 2.819183588027954
Validation loss: 2.4717995992270847

Epoch: 5| Step: 6
Training loss: 2.7334189414978027
Validation loss: 2.47525962193807

Epoch: 5| Step: 7
Training loss: 2.1633248329162598
Validation loss: 2.471277657375541

Epoch: 5| Step: 8
Training loss: 3.0169005393981934
Validation loss: 2.4743472581268637

Epoch: 5| Step: 9
Training loss: 2.7585384845733643
Validation loss: 2.4507798225648942

Epoch: 5| Step: 10
Training loss: 2.76501727104187
Validation loss: 2.4414894734659502

Epoch: 184| Step: 0
Training loss: 2.3181326389312744
Validation loss: 2.4066388145569833

Epoch: 5| Step: 1
Training loss: 2.146390438079834
Validation loss: 2.410272370102585

Epoch: 5| Step: 2
Training loss: 2.0409350395202637
Validation loss: 2.4025311777668614

Epoch: 5| Step: 3
Training loss: 2.6645801067352295
Validation loss: 2.402502647010229

Epoch: 5| Step: 4
Training loss: 2.212562084197998
Validation loss: 2.4026327645906838

Epoch: 5| Step: 5
Training loss: 2.6633055210113525
Validation loss: 2.4029422498518422

Epoch: 5| Step: 6
Training loss: 3.147799015045166
Validation loss: 2.399846781966507

Epoch: 5| Step: 7
Training loss: 2.297781467437744
Validation loss: 2.3956458107117684

Epoch: 5| Step: 8
Training loss: 2.9980239868164062
Validation loss: 2.384979300601508

Epoch: 5| Step: 9
Training loss: 2.484384775161743
Validation loss: 2.383810576572213

Epoch: 5| Step: 10
Training loss: 3.36377215385437
Validation loss: 2.3935342860478226

Epoch: 185| Step: 0
Training loss: 2.268259286880493
Validation loss: 2.38441292701229

Epoch: 5| Step: 1
Training loss: 3.5232436656951904
Validation loss: 2.3832104795722553

Epoch: 5| Step: 2
Training loss: 2.501512289047241
Validation loss: 2.380759790379514

Epoch: 5| Step: 3
Training loss: 2.9268393516540527
Validation loss: 2.3849629996925272

Epoch: 5| Step: 4
Training loss: 2.0243144035339355
Validation loss: 2.3919508790457122

Epoch: 5| Step: 5
Training loss: 2.6855645179748535
Validation loss: 2.409349021091256

Epoch: 5| Step: 6
Training loss: 2.53641939163208
Validation loss: 2.437813897286692

Epoch: 5| Step: 7
Training loss: 2.478116989135742
Validation loss: 2.4424151476993354

Epoch: 5| Step: 8
Training loss: 2.181063175201416
Validation loss: 2.461439845382526

Epoch: 5| Step: 9
Training loss: 2.2729990482330322
Validation loss: 2.4641183166093725

Epoch: 5| Step: 10
Training loss: 3.145124912261963
Validation loss: 2.4620108655703965

Epoch: 186| Step: 0
Training loss: 2.867152452468872
Validation loss: 2.436466319586641

Epoch: 5| Step: 1
Training loss: 2.4701876640319824
Validation loss: 2.433054725329081

Epoch: 5| Step: 2
Training loss: 2.789916515350342
Validation loss: 2.4228480426214074

Epoch: 5| Step: 3
Training loss: 3.055893659591675
Validation loss: 2.4504502537429973

Epoch: 5| Step: 4
Training loss: 2.6703317165374756
Validation loss: 2.4384095591883503

Epoch: 5| Step: 5
Training loss: 2.1270248889923096
Validation loss: 2.425786461881412

Epoch: 5| Step: 6
Training loss: 2.219050407409668
Validation loss: 2.402727847458214

Epoch: 5| Step: 7
Training loss: 2.9300754070281982
Validation loss: 2.384634010253414

Epoch: 5| Step: 8
Training loss: 2.151097536087036
Validation loss: 2.380093659124067

Epoch: 5| Step: 9
Training loss: 2.9245166778564453
Validation loss: 2.3707224092175885

Epoch: 5| Step: 10
Training loss: 2.358175277709961
Validation loss: 2.364915191486318

Epoch: 187| Step: 0
Training loss: 2.87333607673645
Validation loss: 2.364448970363986

Epoch: 5| Step: 1
Training loss: 3.0133163928985596
Validation loss: 2.355396878334784

Epoch: 5| Step: 2
Training loss: 2.5562984943389893
Validation loss: 2.3620533609902985

Epoch: 5| Step: 3
Training loss: 2.435082197189331
Validation loss: 2.354489149585847

Epoch: 5| Step: 4
Training loss: 3.0921483039855957
Validation loss: 2.3720633035065024

Epoch: 5| Step: 5
Training loss: 2.1209826469421387
Validation loss: 2.375229812437488

Epoch: 5| Step: 6
Training loss: 1.8002312183380127
Validation loss: 2.3771014546835296

Epoch: 5| Step: 7
Training loss: 2.6987385749816895
Validation loss: 2.3702519785973335

Epoch: 5| Step: 8
Training loss: 2.674281120300293
Validation loss: 2.3703023079902894

Epoch: 5| Step: 9
Training loss: 2.663682460784912
Validation loss: 2.3775401576872794

Epoch: 5| Step: 10
Training loss: 2.601703405380249
Validation loss: 2.4027165136029645

Epoch: 188| Step: 0
Training loss: 2.4925801753997803
Validation loss: 2.4025228433711554

Epoch: 5| Step: 1
Training loss: 2.880866765975952
Validation loss: 2.3860055836298133

Epoch: 5| Step: 2
Training loss: 2.441300868988037
Validation loss: 2.3884145559803134

Epoch: 5| Step: 3
Training loss: 2.791944980621338
Validation loss: 2.383000901950303

Epoch: 5| Step: 4
Training loss: 2.8665611743927
Validation loss: 2.379802844857657

Epoch: 5| Step: 5
Training loss: 3.0646042823791504
Validation loss: 2.3702308977803876

Epoch: 5| Step: 6
Training loss: 2.5732991695404053
Validation loss: 2.3791684463459957

Epoch: 5| Step: 7
Training loss: 2.2316813468933105
Validation loss: 2.3772062563127085

Epoch: 5| Step: 8
Training loss: 2.655365467071533
Validation loss: 2.3787977439101025

Epoch: 5| Step: 9
Training loss: 2.2730066776275635
Validation loss: 2.377019428437756

Epoch: 5| Step: 10
Training loss: 1.9584513902664185
Validation loss: 2.380803890125726

Epoch: 189| Step: 0
Training loss: 3.107823133468628
Validation loss: 2.3778096642545474

Epoch: 5| Step: 1
Training loss: 2.9730608463287354
Validation loss: 2.382380226606964

Epoch: 5| Step: 2
Training loss: 2.4802327156066895
Validation loss: 2.395118050677802

Epoch: 5| Step: 3
Training loss: 2.2731175422668457
Validation loss: 2.388580145374421

Epoch: 5| Step: 4
Training loss: 2.583552598953247
Validation loss: 2.3871983738355738

Epoch: 5| Step: 5
Training loss: 2.6768107414245605
Validation loss: 2.38407310106421

Epoch: 5| Step: 6
Training loss: 2.3942928314208984
Validation loss: 2.3861674390813357

Epoch: 5| Step: 7
Training loss: 2.637566328048706
Validation loss: 2.3796906958344164

Epoch: 5| Step: 8
Training loss: 1.6792045831680298
Validation loss: 2.390390347408992

Epoch: 5| Step: 9
Training loss: 2.8226754665374756
Validation loss: 2.400421650178971

Epoch: 5| Step: 10
Training loss: 2.5354201793670654
Validation loss: 2.4020984147184636

Epoch: 190| Step: 0
Training loss: 1.5168774127960205
Validation loss: 2.400502748386834

Epoch: 5| Step: 1
Training loss: 2.1110033988952637
Validation loss: 2.4041540391983522

Epoch: 5| Step: 2
Training loss: 2.992793560028076
Validation loss: 2.3993605080471245

Epoch: 5| Step: 3
Training loss: 2.131819725036621
Validation loss: 2.4089402050100346

Epoch: 5| Step: 4
Training loss: 2.8911478519439697
Validation loss: 2.4126719403010544

Epoch: 5| Step: 5
Training loss: 2.7882909774780273
Validation loss: 2.4118695002730175

Epoch: 5| Step: 6
Training loss: 2.633754014968872
Validation loss: 2.410909675782727

Epoch: 5| Step: 7
Training loss: 2.6932663917541504
Validation loss: 2.4123962451052923

Epoch: 5| Step: 8
Training loss: 2.6025807857513428
Validation loss: 2.402177015940348

Epoch: 5| Step: 9
Training loss: 2.9147989749908447
Validation loss: 2.4021175112775577

Epoch: 5| Step: 10
Training loss: 2.909792900085449
Validation loss: 2.4112285337140484

Epoch: 191| Step: 0
Training loss: 2.6385324001312256
Validation loss: 2.407683317379285

Epoch: 5| Step: 1
Training loss: 2.5848159790039062
Validation loss: 2.423256328029017

Epoch: 5| Step: 2
Training loss: 1.9029104709625244
Validation loss: 2.4079818648676716

Epoch: 5| Step: 3
Training loss: 3.0965633392333984
Validation loss: 2.4182839162888063

Epoch: 5| Step: 4
Training loss: 2.553858995437622
Validation loss: 2.411369864658643

Epoch: 5| Step: 5
Training loss: 2.4230730533599854
Validation loss: 2.4077395418638825

Epoch: 5| Step: 6
Training loss: 2.0885002613067627
Validation loss: 2.3989441266623874

Epoch: 5| Step: 7
Training loss: 2.9286036491394043
Validation loss: 2.4017799259513937

Epoch: 5| Step: 8
Training loss: 2.377607583999634
Validation loss: 2.396878404002036

Epoch: 5| Step: 9
Training loss: 2.9213509559631348
Validation loss: 2.385438390957412

Epoch: 5| Step: 10
Training loss: 2.330094337463379
Validation loss: 2.387809953381938

Epoch: 192| Step: 0
Training loss: 2.392634630203247
Validation loss: 2.393710941396734

Epoch: 5| Step: 1
Training loss: 2.7247791290283203
Validation loss: 2.4023166318093576

Epoch: 5| Step: 2
Training loss: 3.0938048362731934
Validation loss: 2.3946127481358026

Epoch: 5| Step: 3
Training loss: 2.4032444953918457
Validation loss: 2.4122524364020235

Epoch: 5| Step: 4
Training loss: 2.411332607269287
Validation loss: 2.3966287874406382

Epoch: 5| Step: 5
Training loss: 2.442026138305664
Validation loss: 2.401413966250676

Epoch: 5| Step: 6
Training loss: 2.8039231300354004
Validation loss: 2.3998483380963727

Epoch: 5| Step: 7
Training loss: 2.2367045879364014
Validation loss: 2.3878400069411083

Epoch: 5| Step: 8
Training loss: 2.52575945854187
Validation loss: 2.3893035919435563

Epoch: 5| Step: 9
Training loss: 2.2944374084472656
Validation loss: 2.392853234403877

Epoch: 5| Step: 10
Training loss: 2.6759395599365234
Validation loss: 2.386508867304812

Epoch: 193| Step: 0
Training loss: 2.3886845111846924
Validation loss: 2.3800762750769175

Epoch: 5| Step: 1
Training loss: 2.6478192806243896
Validation loss: 2.3671758226169053

Epoch: 5| Step: 2
Training loss: 2.0366058349609375
Validation loss: 2.363042522502202

Epoch: 5| Step: 3
Training loss: 2.6440234184265137
Validation loss: 2.3595277468363443

Epoch: 5| Step: 4
Training loss: 3.102517604827881
Validation loss: 2.3604704077525804

Epoch: 5| Step: 5
Training loss: 2.5464799404144287
Validation loss: 2.356696464682138

Epoch: 5| Step: 6
Training loss: 2.9119067192077637
Validation loss: 2.3720498725932133

Epoch: 5| Step: 7
Training loss: 2.6867549419403076
Validation loss: 2.377700731318484

Epoch: 5| Step: 8
Training loss: 2.352907657623291
Validation loss: 2.379642096898889

Epoch: 5| Step: 9
Training loss: 2.2341299057006836
Validation loss: 2.3630993212423017

Epoch: 5| Step: 10
Training loss: 2.501120090484619
Validation loss: 2.361380592469246

Epoch: 194| Step: 0
Training loss: 2.842804431915283
Validation loss: 2.363122788808679

Epoch: 5| Step: 1
Training loss: 2.47098970413208
Validation loss: 2.368600783809539

Epoch: 5| Step: 2
Training loss: 2.33840274810791
Validation loss: 2.3639955418084257

Epoch: 5| Step: 3
Training loss: 2.2043051719665527
Validation loss: 2.360861711604621

Epoch: 5| Step: 4
Training loss: 2.717721939086914
Validation loss: 2.366260620855516

Epoch: 5| Step: 5
Training loss: 2.321018934249878
Validation loss: 2.3605404335965394

Epoch: 5| Step: 6
Training loss: 1.5104955434799194
Validation loss: 2.377269414163405

Epoch: 5| Step: 7
Training loss: 2.5400733947753906
Validation loss: 2.367932476023192

Epoch: 5| Step: 8
Training loss: 2.886793613433838
Validation loss: 2.3693197388802805

Epoch: 5| Step: 9
Training loss: 3.2470169067382812
Validation loss: 2.380204600672568

Epoch: 5| Step: 10
Training loss: 2.8534584045410156
Validation loss: 2.3762453422751477

Epoch: 195| Step: 0
Training loss: 3.3312137126922607
Validation loss: 2.397359699331304

Epoch: 5| Step: 1
Training loss: 2.831671953201294
Validation loss: 2.405840089244227

Epoch: 5| Step: 2
Training loss: 2.05415415763855
Validation loss: 2.397951623444916

Epoch: 5| Step: 3
Training loss: 3.2134528160095215
Validation loss: 2.4001731564921718

Epoch: 5| Step: 4
Training loss: 2.463137149810791
Validation loss: 2.387207051759125

Epoch: 5| Step: 5
Training loss: 2.441077470779419
Validation loss: 2.365299533772212

Epoch: 5| Step: 6
Training loss: 2.18489933013916
Validation loss: 2.3777640276057745

Epoch: 5| Step: 7
Training loss: 2.064725160598755
Validation loss: 2.376365310402327

Epoch: 5| Step: 8
Training loss: 1.9925949573516846
Validation loss: 2.3754550923583326

Epoch: 5| Step: 9
Training loss: 2.51829195022583
Validation loss: 2.366857541504727

Epoch: 5| Step: 10
Training loss: 2.7363524436950684
Validation loss: 2.3619038699775614

Epoch: 196| Step: 0
Training loss: 3.1615653038024902
Validation loss: 2.3751623092159146

Epoch: 5| Step: 1
Training loss: 2.342958927154541
Validation loss: 2.3669506196052796

Epoch: 5| Step: 2
Training loss: 2.5940139293670654
Validation loss: 2.365309856271231

Epoch: 5| Step: 3
Training loss: 2.525714159011841
Validation loss: 2.3589545424266527

Epoch: 5| Step: 4
Training loss: 2.204085111618042
Validation loss: 2.3621936767332015

Epoch: 5| Step: 5
Training loss: 2.568233013153076
Validation loss: 2.3621923820946806

Epoch: 5| Step: 6
Training loss: 1.8120043277740479
Validation loss: 2.386311041411533

Epoch: 5| Step: 7
Training loss: 2.732800245285034
Validation loss: 2.395498844885057

Epoch: 5| Step: 8
Training loss: 3.0366692543029785
Validation loss: 2.3946173665344075

Epoch: 5| Step: 9
Training loss: 2.73520565032959
Validation loss: 2.3859455226570048

Epoch: 5| Step: 10
Training loss: 2.080312728881836
Validation loss: 2.381210752712783

Epoch: 197| Step: 0
Training loss: 2.0292322635650635
Validation loss: 2.3961933761514644

Epoch: 5| Step: 1
Training loss: 2.1195333003997803
Validation loss: 2.3784890828594083

Epoch: 5| Step: 2
Training loss: 2.476111650466919
Validation loss: 2.3698509508563625

Epoch: 5| Step: 3
Training loss: 2.2975945472717285
Validation loss: 2.375939153855847

Epoch: 5| Step: 4
Training loss: 3.0592567920684814
Validation loss: 2.364163678179505

Epoch: 5| Step: 5
Training loss: 2.0634026527404785
Validation loss: 2.361521613213324

Epoch: 5| Step: 6
Training loss: 2.9221010208129883
Validation loss: 2.3611189242332213

Epoch: 5| Step: 7
Training loss: 2.4180049896240234
Validation loss: 2.3599116981670423

Epoch: 5| Step: 8
Training loss: 2.7117505073547363
Validation loss: 2.353007886999397

Epoch: 5| Step: 9
Training loss: 2.6998913288116455
Validation loss: 2.358251157627311

Epoch: 5| Step: 10
Training loss: 2.972372531890869
Validation loss: 2.3568357472778647

Epoch: 198| Step: 0
Training loss: 3.066052198410034
Validation loss: 2.3561914300405853

Epoch: 5| Step: 1
Training loss: 2.929997205734253
Validation loss: 2.3661171851619596

Epoch: 5| Step: 2
Training loss: 2.198636293411255
Validation loss: 2.3667522399656233

Epoch: 5| Step: 3
Training loss: 2.1928467750549316
Validation loss: 2.3629194639062368

Epoch: 5| Step: 4
Training loss: 2.1470212936401367
Validation loss: 2.3484626816165064

Epoch: 5| Step: 5
Training loss: 2.2175803184509277
Validation loss: 2.3494842795915503

Epoch: 5| Step: 6
Training loss: 2.179408550262451
Validation loss: 2.358795996635191

Epoch: 5| Step: 7
Training loss: 2.645022392272949
Validation loss: 2.3679888017715944

Epoch: 5| Step: 8
Training loss: 2.642120599746704
Validation loss: 2.374612062208114

Epoch: 5| Step: 9
Training loss: 3.021408796310425
Validation loss: 2.3968122595099994

Epoch: 5| Step: 10
Training loss: 2.579253673553467
Validation loss: 2.38670862361949

Epoch: 199| Step: 0
Training loss: 1.869659423828125
Validation loss: 2.3818244421353905

Epoch: 5| Step: 1
Training loss: 2.46311616897583
Validation loss: 2.3720952464688208

Epoch: 5| Step: 2
Training loss: 2.636183261871338
Validation loss: 2.3712783654530845

Epoch: 5| Step: 3
Training loss: 2.1020469665527344
Validation loss: 2.356179975694226

Epoch: 5| Step: 4
Training loss: 2.278331756591797
Validation loss: 2.366263463932981

Epoch: 5| Step: 5
Training loss: 2.5855445861816406
Validation loss: 2.3622900298846665

Epoch: 5| Step: 6
Training loss: 2.419980049133301
Validation loss: 2.3739170541045485

Epoch: 5| Step: 7
Training loss: 2.616377353668213
Validation loss: 2.3689550635635213

Epoch: 5| Step: 8
Training loss: 3.1084604263305664
Validation loss: 2.3827477321829846

Epoch: 5| Step: 9
Training loss: 3.140636920928955
Validation loss: 2.3864043707488687

Epoch: 5| Step: 10
Training loss: 2.5551533699035645
Validation loss: 2.3753463786135436

Epoch: 200| Step: 0
Training loss: 2.423125743865967
Validation loss: 2.373582560528991

Epoch: 5| Step: 1
Training loss: 1.8528680801391602
Validation loss: 2.3656171034741145

Epoch: 5| Step: 2
Training loss: 1.6491825580596924
Validation loss: 2.3715789112993466

Epoch: 5| Step: 3
Training loss: 2.957554578781128
Validation loss: 2.3703608820515294

Epoch: 5| Step: 4
Training loss: 2.6588611602783203
Validation loss: 2.371219781137282

Epoch: 5| Step: 5
Training loss: 2.8170034885406494
Validation loss: 2.364813076552524

Epoch: 5| Step: 6
Training loss: 3.3497314453125
Validation loss: 2.341364035042383

Epoch: 5| Step: 7
Training loss: 2.805894613265991
Validation loss: 2.330408348832079

Epoch: 5| Step: 8
Training loss: 2.0404677391052246
Validation loss: 2.3361161088430755

Epoch: 5| Step: 9
Training loss: 2.2440075874328613
Validation loss: 2.3460455325341996

Epoch: 5| Step: 10
Training loss: 3.0560550689697266
Validation loss: 2.363740477510678

Epoch: 201| Step: 0
Training loss: 2.807020902633667
Validation loss: 2.374344510416831

Epoch: 5| Step: 1
Training loss: 2.199345111846924
Validation loss: 2.388314413767989

Epoch: 5| Step: 2
Training loss: 2.3485686779022217
Validation loss: 2.3883247683125157

Epoch: 5| Step: 3
Training loss: 2.637767791748047
Validation loss: 2.381234779152819

Epoch: 5| Step: 4
Training loss: 2.8218917846679688
Validation loss: 2.3583579499234437

Epoch: 5| Step: 5
Training loss: 2.376237392425537
Validation loss: 2.3550561858761694

Epoch: 5| Step: 6
Training loss: 2.7250778675079346
Validation loss: 2.3496096916096185

Epoch: 5| Step: 7
Training loss: 2.958042621612549
Validation loss: 2.353140305447322

Epoch: 5| Step: 8
Training loss: 2.3595964908599854
Validation loss: 2.3559550252012027

Epoch: 5| Step: 9
Training loss: 2.096872329711914
Validation loss: 2.354529070597823

Epoch: 5| Step: 10
Training loss: 2.587284564971924
Validation loss: 2.354378936111286

Epoch: 202| Step: 0
Training loss: 2.158007860183716
Validation loss: 2.353056541053198

Epoch: 5| Step: 1
Training loss: 3.0159213542938232
Validation loss: 2.3555039218676987

Epoch: 5| Step: 2
Training loss: 2.4254441261291504
Validation loss: 2.3569605965768137

Epoch: 5| Step: 3
Training loss: 2.142897129058838
Validation loss: 2.3443512326927594

Epoch: 5| Step: 4
Training loss: 2.856841564178467
Validation loss: 2.3550654893280356

Epoch: 5| Step: 5
Training loss: 2.4665212631225586
Validation loss: 2.349893328964069

Epoch: 5| Step: 6
Training loss: 2.2680351734161377
Validation loss: 2.354386216850691

Epoch: 5| Step: 7
Training loss: 2.1041970252990723
Validation loss: 2.3643691514127996

Epoch: 5| Step: 8
Training loss: 3.200099229812622
Validation loss: 2.3557756536750385

Epoch: 5| Step: 9
Training loss: 2.53166127204895
Validation loss: 2.3527853617104153

Epoch: 5| Step: 10
Training loss: 2.510979175567627
Validation loss: 2.349294290747694

Epoch: 203| Step: 0
Training loss: 2.6608974933624268
Validation loss: 2.3702582210622807

Epoch: 5| Step: 1
Training loss: 1.6557890176773071
Validation loss: 2.36281281773762

Epoch: 5| Step: 2
Training loss: 2.6590018272399902
Validation loss: 2.340891509927729

Epoch: 5| Step: 3
Training loss: 2.6616053581237793
Validation loss: 2.3371562393762733

Epoch: 5| Step: 4
Training loss: 2.6334805488586426
Validation loss: 2.332701483080464

Epoch: 5| Step: 5
Training loss: 2.539393901824951
Validation loss: 2.324504478003389

Epoch: 5| Step: 6
Training loss: 2.668297529220581
Validation loss: 2.3157213990406325

Epoch: 5| Step: 7
Training loss: 2.9286277294158936
Validation loss: 2.3207791479684974

Epoch: 5| Step: 8
Training loss: 2.367439031600952
Validation loss: 2.318343577846404

Epoch: 5| Step: 9
Training loss: 2.6789557933807373
Validation loss: 2.324094239101615

Epoch: 5| Step: 10
Training loss: 2.2123332023620605
Validation loss: 2.31533404063153

Epoch: 204| Step: 0
Training loss: 2.146268606185913
Validation loss: 2.323762293784849

Epoch: 5| Step: 1
Training loss: 2.8981099128723145
Validation loss: 2.341744927949803

Epoch: 5| Step: 2
Training loss: 2.45383882522583
Validation loss: 2.3578005247218634

Epoch: 5| Step: 3
Training loss: 2.854602813720703
Validation loss: 2.359882406009141

Epoch: 5| Step: 4
Training loss: 2.008251667022705
Validation loss: 2.367809967328143

Epoch: 5| Step: 5
Training loss: 2.0520734786987305
Validation loss: 2.3699623948784283

Epoch: 5| Step: 6
Training loss: 2.5080513954162598
Validation loss: 2.370370393158287

Epoch: 5| Step: 7
Training loss: 2.943591833114624
Validation loss: 2.369977169139411

Epoch: 5| Step: 8
Training loss: 2.731942892074585
Validation loss: 2.3718945851889988

Epoch: 5| Step: 9
Training loss: 2.359964370727539
Validation loss: 2.374465616800452

Epoch: 5| Step: 10
Training loss: 2.6067352294921875
Validation loss: 2.3656916131255445

Epoch: 205| Step: 0
Training loss: 3.244236469268799
Validation loss: 2.363904094183317

Epoch: 5| Step: 1
Training loss: 2.366333484649658
Validation loss: 2.356790804093884

Epoch: 5| Step: 2
Training loss: 2.398942470550537
Validation loss: 2.3702149416810725

Epoch: 5| Step: 3
Training loss: 2.9281466007232666
Validation loss: 2.3738420958160074

Epoch: 5| Step: 4
Training loss: 2.349997043609619
Validation loss: 2.3782283465067544

Epoch: 5| Step: 5
Training loss: 2.192103862762451
Validation loss: 2.3746929296883206

Epoch: 5| Step: 6
Training loss: 2.0189638137817383
Validation loss: 2.3677052426081833

Epoch: 5| Step: 7
Training loss: 2.924635410308838
Validation loss: 2.3436821532505814

Epoch: 5| Step: 8
Training loss: 2.1589152812957764
Validation loss: 2.3507763211445143

Epoch: 5| Step: 9
Training loss: 2.032593250274658
Validation loss: 2.340175074915732

Epoch: 5| Step: 10
Training loss: 2.9726815223693848
Validation loss: 2.344995293565976

Epoch: 206| Step: 0
Training loss: 1.939684271812439
Validation loss: 2.3548847103631623

Epoch: 5| Step: 1
Training loss: 2.2886507511138916
Validation loss: 2.3365641358078166

Epoch: 5| Step: 2
Training loss: 3.026132106781006
Validation loss: 2.339679048907372

Epoch: 5| Step: 3
Training loss: 2.696593761444092
Validation loss: 2.3256657149202082

Epoch: 5| Step: 4
Training loss: 2.6566195487976074
Validation loss: 2.329821127717213

Epoch: 5| Step: 5
Training loss: 2.607640504837036
Validation loss: 2.3605348397326726

Epoch: 5| Step: 6
Training loss: 2.5701253414154053
Validation loss: 2.3438142755980134

Epoch: 5| Step: 7
Training loss: 2.6775925159454346
Validation loss: 2.350081974460233

Epoch: 5| Step: 8
Training loss: 2.40486216545105
Validation loss: 2.344407376422677

Epoch: 5| Step: 9
Training loss: 2.2139971256256104
Validation loss: 2.334252498483145

Epoch: 5| Step: 10
Training loss: 2.359812021255493
Validation loss: 2.3346626092028875

Epoch: 207| Step: 0
Training loss: 2.689307689666748
Validation loss: 2.3198393211569837

Epoch: 5| Step: 1
Training loss: 2.8137669563293457
Validation loss: 2.3266866642941713

Epoch: 5| Step: 2
Training loss: 2.2581582069396973
Validation loss: 2.3235274771208405

Epoch: 5| Step: 3
Training loss: 2.405526638031006
Validation loss: 2.3291146909036944

Epoch: 5| Step: 4
Training loss: 2.2759037017822266
Validation loss: 2.3287332160498506

Epoch: 5| Step: 5
Training loss: 2.7477424144744873
Validation loss: 2.3419458584118913

Epoch: 5| Step: 6
Training loss: 2.9122467041015625
Validation loss: 2.364357417629611

Epoch: 5| Step: 7
Training loss: 2.292088508605957
Validation loss: 2.3813949528560845

Epoch: 5| Step: 8
Training loss: 2.375885009765625
Validation loss: 2.39051793723978

Epoch: 5| Step: 9
Training loss: 2.4469528198242188
Validation loss: 2.379735977418961

Epoch: 5| Step: 10
Training loss: 2.3622305393218994
Validation loss: 2.3697295957996

Epoch: 208| Step: 0
Training loss: 1.9986941814422607
Validation loss: 2.3647045730262675

Epoch: 5| Step: 1
Training loss: 3.0593085289001465
Validation loss: 2.3656031931600263

Epoch: 5| Step: 2
Training loss: 2.2934489250183105
Validation loss: 2.3775947170872844

Epoch: 5| Step: 3
Training loss: 2.143608570098877
Validation loss: 2.389769523374496

Epoch: 5| Step: 4
Training loss: 2.8914101123809814
Validation loss: 2.3938387337551323

Epoch: 5| Step: 5
Training loss: 2.7418336868286133
Validation loss: 2.400589209730907

Epoch: 5| Step: 6
Training loss: 2.288041591644287
Validation loss: 2.4089405434105986

Epoch: 5| Step: 7
Training loss: 2.7793631553649902
Validation loss: 2.4024479645554737

Epoch: 5| Step: 8
Training loss: 2.5026068687438965
Validation loss: 2.395232110895136

Epoch: 5| Step: 9
Training loss: 2.0483219623565674
Validation loss: 2.376250410592684

Epoch: 5| Step: 10
Training loss: 2.9040818214416504
Validation loss: 2.3565007435378207

Epoch: 209| Step: 0
Training loss: 2.603435516357422
Validation loss: 2.3612407894544702

Epoch: 5| Step: 1
Training loss: 2.1292030811309814
Validation loss: 2.3809243966174383

Epoch: 5| Step: 2
Training loss: 2.5535292625427246
Validation loss: 2.407952941874022

Epoch: 5| Step: 3
Training loss: 2.830540180206299
Validation loss: 2.4064959428643666

Epoch: 5| Step: 4
Training loss: 3.0157790184020996
Validation loss: 2.4009567050523657

Epoch: 5| Step: 5
Training loss: 2.0228705406188965
Validation loss: 2.395160513539468

Epoch: 5| Step: 6
Training loss: 3.0717849731445312
Validation loss: 2.3658349539643977

Epoch: 5| Step: 7
Training loss: 2.7833926677703857
Validation loss: 2.3421366573661886

Epoch: 5| Step: 8
Training loss: 2.1182291507720947
Validation loss: 2.327458555980395

Epoch: 5| Step: 9
Training loss: 2.0962345600128174
Validation loss: 2.3477242736406225

Epoch: 5| Step: 10
Training loss: 2.5380983352661133
Validation loss: 2.3526650680008756

Epoch: 210| Step: 0
Training loss: 2.1808578968048096
Validation loss: 2.3532310660167406

Epoch: 5| Step: 1
Training loss: 2.905313014984131
Validation loss: 2.364326169413905

Epoch: 5| Step: 2
Training loss: 2.540837287902832
Validation loss: 2.3384441432132514

Epoch: 5| Step: 3
Training loss: 2.7085561752319336
Validation loss: 2.3301588758345573

Epoch: 5| Step: 4
Training loss: 2.838388681411743
Validation loss: 2.3102069747063423

Epoch: 5| Step: 5
Training loss: 2.1000261306762695
Validation loss: 2.335724107680782

Epoch: 5| Step: 6
Training loss: 1.9761883020401
Validation loss: 2.368891126366072

Epoch: 5| Step: 7
Training loss: 2.047184467315674
Validation loss: 2.3795713301627868

Epoch: 5| Step: 8
Training loss: 2.6059532165527344
Validation loss: 2.3936262605010823

Epoch: 5| Step: 9
Training loss: 2.5240461826324463
Validation loss: 2.4059449831644693

Epoch: 5| Step: 10
Training loss: 3.336667060852051
Validation loss: 2.377973582154961

Epoch: 211| Step: 0
Training loss: 2.110067129135132
Validation loss: 2.3574615268297094

Epoch: 5| Step: 1
Training loss: 2.8999600410461426
Validation loss: 2.333189054202008

Epoch: 5| Step: 2
Training loss: 3.1362388134002686
Validation loss: 2.3242045025671683

Epoch: 5| Step: 3
Training loss: 2.306057929992676
Validation loss: 2.33890954397058

Epoch: 5| Step: 4
Training loss: 2.1000571250915527
Validation loss: 2.3542006041413996

Epoch: 5| Step: 5
Training loss: 2.8230926990509033
Validation loss: 2.3778109268475602

Epoch: 5| Step: 6
Training loss: 2.958043098449707
Validation loss: 2.384563466554047

Epoch: 5| Step: 7
Training loss: 2.78450345993042
Validation loss: 2.380320325974495

Epoch: 5| Step: 8
Training loss: 2.7265381813049316
Validation loss: 2.375554661596975

Epoch: 5| Step: 9
Training loss: 1.9195743799209595
Validation loss: 2.349687398120921

Epoch: 5| Step: 10
Training loss: 2.1066246032714844
Validation loss: 2.320866500177691

Epoch: 212| Step: 0
Training loss: 2.2514731884002686
Validation loss: 2.3055586635425525

Epoch: 5| Step: 1
Training loss: 1.9532554149627686
Validation loss: 2.3012369627593667

Epoch: 5| Step: 2
Training loss: 2.4020702838897705
Validation loss: 2.293801438423895

Epoch: 5| Step: 3
Training loss: 2.86795711517334
Validation loss: 2.3168585326081965

Epoch: 5| Step: 4
Training loss: 2.3050332069396973
Validation loss: 2.344721873601278

Epoch: 5| Step: 5
Training loss: 2.2180628776550293
Validation loss: 2.348110745030065

Epoch: 5| Step: 6
Training loss: 2.854965925216675
Validation loss: 2.357694431017804

Epoch: 5| Step: 7
Training loss: 3.0002169609069824
Validation loss: 2.37124543036184

Epoch: 5| Step: 8
Training loss: 2.474095582962036
Validation loss: 2.3595186536030104

Epoch: 5| Step: 9
Training loss: 2.8775200843811035
Validation loss: 2.3417119133856987

Epoch: 5| Step: 10
Training loss: 2.384103298187256
Validation loss: 2.33009764968708

Epoch: 213| Step: 0
Training loss: 2.9399912357330322
Validation loss: 2.328617444602392

Epoch: 5| Step: 1
Training loss: 1.2869153022766113
Validation loss: 2.3263340893612114

Epoch: 5| Step: 2
Training loss: 2.266094207763672
Validation loss: 2.3347448084944036

Epoch: 5| Step: 3
Training loss: 2.2971267700195312
Validation loss: 2.3456877329016246

Epoch: 5| Step: 4
Training loss: 2.400057792663574
Validation loss: 2.353680344038112

Epoch: 5| Step: 5
Training loss: 2.825681686401367
Validation loss: 2.3510215666986283

Epoch: 5| Step: 6
Training loss: 2.31760835647583
Validation loss: 2.356808075340845

Epoch: 5| Step: 7
Training loss: 2.5122313499450684
Validation loss: 2.3478371353559595

Epoch: 5| Step: 8
Training loss: 3.0599045753479004
Validation loss: 2.348736342563424

Epoch: 5| Step: 9
Training loss: 2.7466769218444824
Validation loss: 2.35243082815601

Epoch: 5| Step: 10
Training loss: 2.930898666381836
Validation loss: 2.3645647725751324

Epoch: 214| Step: 0
Training loss: 2.835165500640869
Validation loss: 2.3649138468568043

Epoch: 5| Step: 1
Training loss: 2.5323781967163086
Validation loss: 2.3967576001280095

Epoch: 5| Step: 2
Training loss: 2.5810248851776123
Validation loss: 2.397744901718632

Epoch: 5| Step: 3
Training loss: 2.66579270362854
Validation loss: 2.4118225805221067

Epoch: 5| Step: 4
Training loss: 2.4972519874572754
Validation loss: 2.3998586721317743

Epoch: 5| Step: 5
Training loss: 2.4625813961029053
Validation loss: 2.3942274355119273

Epoch: 5| Step: 6
Training loss: 2.091855049133301
Validation loss: 2.383303621763824

Epoch: 5| Step: 7
Training loss: 2.762406826019287
Validation loss: 2.3679664058070027

Epoch: 5| Step: 8
Training loss: 2.6405186653137207
Validation loss: 2.3465612421753588

Epoch: 5| Step: 9
Training loss: 2.5827856063842773
Validation loss: 2.3480698062527563

Epoch: 5| Step: 10
Training loss: 1.8663322925567627
Validation loss: 2.3239851151743243

Epoch: 215| Step: 0
Training loss: 2.376114845275879
Validation loss: 2.3433407480998705

Epoch: 5| Step: 1
Training loss: 2.2286171913146973
Validation loss: 2.324130529998451

Epoch: 5| Step: 2
Training loss: 2.625283718109131
Validation loss: 2.3345695567387406

Epoch: 5| Step: 3
Training loss: 2.5193381309509277
Validation loss: 2.348090115413871

Epoch: 5| Step: 4
Training loss: 2.583487033843994
Validation loss: 2.3512661995426303

Epoch: 5| Step: 5
Training loss: 2.8188304901123047
Validation loss: 2.3466543484759588

Epoch: 5| Step: 6
Training loss: 1.7525129318237305
Validation loss: 2.3406130626637447

Epoch: 5| Step: 7
Training loss: 2.8879342079162598
Validation loss: 2.348038428573198

Epoch: 5| Step: 8
Training loss: 2.497957468032837
Validation loss: 2.3302712017490017

Epoch: 5| Step: 9
Training loss: 2.363732099533081
Validation loss: 2.3161759850799397

Epoch: 5| Step: 10
Training loss: 2.8472702503204346
Validation loss: 2.32225792125989

Epoch: 216| Step: 0
Training loss: 2.449596643447876
Validation loss: 2.304671900246733

Epoch: 5| Step: 1
Training loss: 2.2241158485412598
Validation loss: 2.3087008640330327

Epoch: 5| Step: 2
Training loss: 2.4154293537139893
Validation loss: 2.3153955449340162

Epoch: 5| Step: 3
Training loss: 3.0525259971618652
Validation loss: 2.3226894358152985

Epoch: 5| Step: 4
Training loss: 2.090418815612793
Validation loss: 2.335292144488263

Epoch: 5| Step: 5
Training loss: 2.5338826179504395
Validation loss: 2.351049905182213

Epoch: 5| Step: 6
Training loss: 2.2369284629821777
Validation loss: 2.35436890714912

Epoch: 5| Step: 7
Training loss: 2.8190102577209473
Validation loss: 2.361942950115409

Epoch: 5| Step: 8
Training loss: 2.464287281036377
Validation loss: 2.352053716618528

Epoch: 5| Step: 9
Training loss: 2.7904484272003174
Validation loss: 2.3282579683488414

Epoch: 5| Step: 10
Training loss: 2.146474838256836
Validation loss: 2.3204402846674763

Epoch: 217| Step: 0
Training loss: 2.3646960258483887
Validation loss: 2.332328664359226

Epoch: 5| Step: 1
Training loss: 2.4541237354278564
Validation loss: 2.3239868789590816

Epoch: 5| Step: 2
Training loss: 2.760864734649658
Validation loss: 2.32597755616711

Epoch: 5| Step: 3
Training loss: 2.8338654041290283
Validation loss: 2.3160008640699488

Epoch: 5| Step: 4
Training loss: 2.416630268096924
Validation loss: 2.3066650821316625

Epoch: 5| Step: 5
Training loss: 2.1728851795196533
Validation loss: 2.2998557193304903

Epoch: 5| Step: 6
Training loss: 1.9911632537841797
Validation loss: 2.2883639361268733

Epoch: 5| Step: 7
Training loss: 2.0991225242614746
Validation loss: 2.282666221741707

Epoch: 5| Step: 8
Training loss: 2.569579839706421
Validation loss: 2.2859884167230256

Epoch: 5| Step: 9
Training loss: 2.771423816680908
Validation loss: 2.3003539167424685

Epoch: 5| Step: 10
Training loss: 3.027855157852173
Validation loss: 2.3147074817329325

Epoch: 218| Step: 0
Training loss: 2.3464362621307373
Validation loss: 2.3183060025656097

Epoch: 5| Step: 1
Training loss: 2.041193723678589
Validation loss: 2.3218378892508884

Epoch: 5| Step: 2
Training loss: 2.4139952659606934
Validation loss: 2.317663053030609

Epoch: 5| Step: 3
Training loss: 2.584120273590088
Validation loss: 2.3255430857340493

Epoch: 5| Step: 4
Training loss: 2.5503907203674316
Validation loss: 2.320229084261002

Epoch: 5| Step: 5
Training loss: 2.8575172424316406
Validation loss: 2.306657500164483

Epoch: 5| Step: 6
Training loss: 2.6118688583374023
Validation loss: 2.30854364877106

Epoch: 5| Step: 7
Training loss: 2.687854051589966
Validation loss: 2.3167380645710933

Epoch: 5| Step: 8
Training loss: 1.9608409404754639
Validation loss: 2.3183728392406175

Epoch: 5| Step: 9
Training loss: 2.846544027328491
Validation loss: 2.3323082590615876

Epoch: 5| Step: 10
Training loss: 2.3947970867156982
Validation loss: 2.3161321391341505

Epoch: 219| Step: 0
Training loss: 3.301962375640869
Validation loss: 2.325130239609749

Epoch: 5| Step: 1
Training loss: 2.6299281120300293
Validation loss: 2.3164792240306897

Epoch: 5| Step: 2
Training loss: 2.4514241218566895
Validation loss: 2.3149860930699173

Epoch: 5| Step: 3
Training loss: 1.8841625452041626
Validation loss: 2.301043559146184

Epoch: 5| Step: 4
Training loss: 2.751676559448242
Validation loss: 2.3035069063145626

Epoch: 5| Step: 5
Training loss: 1.996025800704956
Validation loss: 2.3079269214343

Epoch: 5| Step: 6
Training loss: 3.0024991035461426
Validation loss: 2.3339077477814048

Epoch: 5| Step: 7
Training loss: 2.2627856731414795
Validation loss: 2.3097787851928384

Epoch: 5| Step: 8
Training loss: 2.6335716247558594
Validation loss: 2.325024894488755

Epoch: 5| Step: 9
Training loss: 2.154982089996338
Validation loss: 2.318941213751352

Epoch: 5| Step: 10
Training loss: 1.8695675134658813
Validation loss: 2.3312614066626436

Epoch: 220| Step: 0
Training loss: 2.750256061553955
Validation loss: 2.3446873644346833

Epoch: 5| Step: 1
Training loss: 2.37735915184021
Validation loss: 2.342865469635174

Epoch: 5| Step: 2
Training loss: 2.572571277618408
Validation loss: 2.336925442500781

Epoch: 5| Step: 3
Training loss: 2.0404953956604004
Validation loss: 2.330541136444256

Epoch: 5| Step: 4
Training loss: 3.2274093627929688
Validation loss: 2.3335858570632113

Epoch: 5| Step: 5
Training loss: 2.4787509441375732
Validation loss: 2.3385543413059686

Epoch: 5| Step: 6
Training loss: 2.72965931892395
Validation loss: 2.3399006320584204

Epoch: 5| Step: 7
Training loss: 1.9171603918075562
Validation loss: 2.34966129385015

Epoch: 5| Step: 8
Training loss: 2.4300551414489746
Validation loss: 2.328953484053253

Epoch: 5| Step: 9
Training loss: 2.386240005493164
Validation loss: 2.329591258879631

Epoch: 5| Step: 10
Training loss: 2.010223150253296
Validation loss: 2.3348918345666703

Epoch: 221| Step: 0
Training loss: 1.9683319330215454
Validation loss: 2.323332522505073

Epoch: 5| Step: 1
Training loss: 2.6080734729766846
Validation loss: 2.3179740777579685

Epoch: 5| Step: 2
Training loss: 3.037682056427002
Validation loss: 2.335696046070386

Epoch: 5| Step: 3
Training loss: 2.118121385574341
Validation loss: 2.3261671194466214

Epoch: 5| Step: 4
Training loss: 2.501706600189209
Validation loss: 2.322044516122469

Epoch: 5| Step: 5
Training loss: 3.3953781127929688
Validation loss: 2.3260880003693285

Epoch: 5| Step: 6
Training loss: 2.197242259979248
Validation loss: 2.332097799547257

Epoch: 5| Step: 7
Training loss: 1.8644596338272095
Validation loss: 2.3135604089306248

Epoch: 5| Step: 8
Training loss: 2.514509439468384
Validation loss: 2.3097568583744827

Epoch: 5| Step: 9
Training loss: 2.0218358039855957
Validation loss: 2.3151314591848724

Epoch: 5| Step: 10
Training loss: 2.690507650375366
Validation loss: 2.3072363356108307

Epoch: 222| Step: 0
Training loss: 3.1162900924682617
Validation loss: 2.313492182762392

Epoch: 5| Step: 1
Training loss: 2.2450060844421387
Validation loss: 2.312991788310389

Epoch: 5| Step: 2
Training loss: 2.7833027839660645
Validation loss: 2.303959074840751

Epoch: 5| Step: 3
Training loss: 2.1490328311920166
Validation loss: 2.295364042764069

Epoch: 5| Step: 4
Training loss: 2.3722290992736816
Validation loss: 2.296044272761191

Epoch: 5| Step: 5
Training loss: 2.9811601638793945
Validation loss: 2.2844997106059903

Epoch: 5| Step: 6
Training loss: 2.1676621437072754
Validation loss: 2.2815545117983254

Epoch: 5| Step: 7
Training loss: 2.0514492988586426
Validation loss: 2.3058873568811724

Epoch: 5| Step: 8
Training loss: 1.6786493062973022
Validation loss: 2.3127777345718874

Epoch: 5| Step: 9
Training loss: 2.707200527191162
Validation loss: 2.3173143966223604

Epoch: 5| Step: 10
Training loss: 2.6941936016082764
Validation loss: 2.3260124473161596

Epoch: 223| Step: 0
Training loss: 2.8793044090270996
Validation loss: 2.3523010028305875

Epoch: 5| Step: 1
Training loss: 2.9294092655181885
Validation loss: 2.3370158646696355

Epoch: 5| Step: 2
Training loss: 1.7296230792999268
Validation loss: 2.3498236492115963

Epoch: 5| Step: 3
Training loss: 2.2111783027648926
Validation loss: 2.3256418961350636

Epoch: 5| Step: 4
Training loss: 1.9822756052017212
Validation loss: 2.324786086236277

Epoch: 5| Step: 5
Training loss: 2.4399917125701904
Validation loss: 2.311454419166811

Epoch: 5| Step: 6
Training loss: 3.1276841163635254
Validation loss: 2.301011859729726

Epoch: 5| Step: 7
Training loss: 3.079167127609253
Validation loss: 2.291078867450837

Epoch: 5| Step: 8
Training loss: 2.0028443336486816
Validation loss: 2.293432520281884

Epoch: 5| Step: 9
Training loss: 2.443164825439453
Validation loss: 2.305099647532227

Epoch: 5| Step: 10
Training loss: 2.1681950092315674
Validation loss: 2.3049770016824045

Epoch: 224| Step: 0
Training loss: 2.2973954677581787
Validation loss: 2.3067976044070337

Epoch: 5| Step: 1
Training loss: 2.8583462238311768
Validation loss: 2.320172781585365

Epoch: 5| Step: 2
Training loss: 3.521987199783325
Validation loss: 2.3429846020155054

Epoch: 5| Step: 3
Training loss: 2.3678464889526367
Validation loss: 2.34410830466978

Epoch: 5| Step: 4
Training loss: 2.3150229454040527
Validation loss: 2.3327915130123014

Epoch: 5| Step: 5
Training loss: 1.9337012767791748
Validation loss: 2.3361271517251128

Epoch: 5| Step: 6
Training loss: 2.40274977684021
Validation loss: 2.3296860725648942

Epoch: 5| Step: 7
Training loss: 2.4249932765960693
Validation loss: 2.3051812725682415

Epoch: 5| Step: 8
Training loss: 2.4986894130706787
Validation loss: 2.278688241076726

Epoch: 5| Step: 9
Training loss: 2.1384634971618652
Validation loss: 2.280793818094397

Epoch: 5| Step: 10
Training loss: 2.016472339630127
Validation loss: 2.294770186947238

Epoch: 225| Step: 0
Training loss: 2.2046494483947754
Validation loss: 2.2906465248395036

Epoch: 5| Step: 1
Training loss: 2.2563250064849854
Validation loss: 2.2890709215594875

Epoch: 5| Step: 2
Training loss: 2.411818742752075
Validation loss: 2.2822538909091743

Epoch: 5| Step: 3
Training loss: 2.8647351264953613
Validation loss: 2.294640294967159

Epoch: 5| Step: 4
Training loss: 1.8978484869003296
Validation loss: 2.2850924307300198

Epoch: 5| Step: 5
Training loss: 2.531589984893799
Validation loss: 2.295971547403643

Epoch: 5| Step: 6
Training loss: 2.708878993988037
Validation loss: 2.318353009480302

Epoch: 5| Step: 7
Training loss: 2.4078330993652344
Validation loss: 2.30819970305248

Epoch: 5| Step: 8
Training loss: 2.584050416946411
Validation loss: 2.3312293098818873

Epoch: 5| Step: 9
Training loss: 2.6483378410339355
Validation loss: 2.344433546066284

Epoch: 5| Step: 10
Training loss: 2.4686973094940186
Validation loss: 2.3343536623062624

Epoch: 226| Step: 0
Training loss: 1.9695615768432617
Validation loss: 2.305664905937769

Epoch: 5| Step: 1
Training loss: 2.1800734996795654
Validation loss: 2.2792137797160814

Epoch: 5| Step: 2
Training loss: 2.6941189765930176
Validation loss: 2.2822290902496665

Epoch: 5| Step: 3
Training loss: 2.583348035812378
Validation loss: 2.2853253400453957

Epoch: 5| Step: 4
Training loss: 2.7750632762908936
Validation loss: 2.2967615871019262

Epoch: 5| Step: 5
Training loss: 2.1555731296539307
Validation loss: 2.2896015413345827

Epoch: 5| Step: 6
Training loss: 2.865220069885254
Validation loss: 2.2970172128369732

Epoch: 5| Step: 7
Training loss: 2.485210657119751
Validation loss: 2.3125220114184963

Epoch: 5| Step: 8
Training loss: 2.492069721221924
Validation loss: 2.3125728202122513

Epoch: 5| Step: 9
Training loss: 2.445164442062378
Validation loss: 2.3147612643498245

Epoch: 5| Step: 10
Training loss: 2.011004686355591
Validation loss: 2.3169168451780915

Epoch: 227| Step: 0
Training loss: 1.8775602579116821
Validation loss: 2.340307838173323

Epoch: 5| Step: 1
Training loss: 2.1478962898254395
Validation loss: 2.3378672497246855

Epoch: 5| Step: 2
Training loss: 2.959167957305908
Validation loss: 2.356575542880643

Epoch: 5| Step: 3
Training loss: 2.7932324409484863
Validation loss: 2.3308403850883566

Epoch: 5| Step: 4
Training loss: 2.5383543968200684
Validation loss: 2.350817338112862

Epoch: 5| Step: 5
Training loss: 2.2383217811584473
Validation loss: 2.325526036242003

Epoch: 5| Step: 6
Training loss: 2.376741409301758
Validation loss: 2.3006339150090374

Epoch: 5| Step: 7
Training loss: 2.5082077980041504
Validation loss: 2.2837342011031283

Epoch: 5| Step: 8
Training loss: 2.1803760528564453
Validation loss: 2.2854832064720894

Epoch: 5| Step: 9
Training loss: 2.6105294227600098
Validation loss: 2.2843212158449235

Epoch: 5| Step: 10
Training loss: 2.7798476219177246
Validation loss: 2.2807997734315935

Epoch: 228| Step: 0
Training loss: 2.250737428665161
Validation loss: 2.2789959381985407

Epoch: 5| Step: 1
Training loss: 2.4985368251800537
Validation loss: 2.275714202593732

Epoch: 5| Step: 2
Training loss: 2.2842679023742676
Validation loss: 2.268575768316946

Epoch: 5| Step: 3
Training loss: 3.0951123237609863
Validation loss: 2.26415648383479

Epoch: 5| Step: 4
Training loss: 2.4340391159057617
Validation loss: 2.2770935335466937

Epoch: 5| Step: 5
Training loss: 1.9393389225006104
Validation loss: 2.277727573148666

Epoch: 5| Step: 6
Training loss: 2.537510395050049
Validation loss: 2.2812321621884584

Epoch: 5| Step: 7
Training loss: 2.6607704162597656
Validation loss: 2.296070155277047

Epoch: 5| Step: 8
Training loss: 2.466764450073242
Validation loss: 2.306987411232405

Epoch: 5| Step: 9
Training loss: 2.8664395809173584
Validation loss: 2.293143205745246

Epoch: 5| Step: 10
Training loss: 1.8180209398269653
Validation loss: 2.304110606511434

Epoch: 229| Step: 0
Training loss: 2.2519454956054688
Validation loss: 2.295765569133143

Epoch: 5| Step: 1
Training loss: 2.3956046104431152
Validation loss: 2.285961451069001

Epoch: 5| Step: 2
Training loss: 2.523167371749878
Validation loss: 2.2889062743033133

Epoch: 5| Step: 3
Training loss: 2.3866262435913086
Validation loss: 2.2988835034831876

Epoch: 5| Step: 4
Training loss: 2.2947757244110107
Validation loss: 2.2948890962908344

Epoch: 5| Step: 5
Training loss: 2.4063076972961426
Validation loss: 2.3041534987829064

Epoch: 5| Step: 6
Training loss: 2.6444125175476074
Validation loss: 2.2961234097839682

Epoch: 5| Step: 7
Training loss: 2.3888025283813477
Validation loss: 2.2918380768068376

Epoch: 5| Step: 8
Training loss: 2.292600154876709
Validation loss: 2.295465669324321

Epoch: 5| Step: 9
Training loss: 2.788424015045166
Validation loss: 2.271306227612239

Epoch: 5| Step: 10
Training loss: 2.275219678878784
Validation loss: 2.273508607700307

Epoch: 230| Step: 0
Training loss: 2.45715069770813
Validation loss: 2.2790946678448747

Epoch: 5| Step: 1
Training loss: 2.193662643432617
Validation loss: 2.28912676277981

Epoch: 5| Step: 2
Training loss: 2.131577968597412
Validation loss: 2.302596817734421

Epoch: 5| Step: 3
Training loss: 2.157743215560913
Validation loss: 2.3256938918944328

Epoch: 5| Step: 4
Training loss: 3.2548859119415283
Validation loss: 2.33658940304992

Epoch: 5| Step: 5
Training loss: 2.221116304397583
Validation loss: 2.3547934511656403

Epoch: 5| Step: 6
Training loss: 2.6030993461608887
Validation loss: 2.36950780499366

Epoch: 5| Step: 7
Training loss: 2.4108245372772217
Validation loss: 2.369568463294737

Epoch: 5| Step: 8
Training loss: 2.3146615028381348
Validation loss: 2.368666641173824

Epoch: 5| Step: 9
Training loss: 2.3550286293029785
Validation loss: 2.352591132604948

Epoch: 5| Step: 10
Training loss: 2.949732542037964
Validation loss: 2.33298598822727

Epoch: 231| Step: 0
Training loss: 2.792501926422119
Validation loss: 2.325773436536071

Epoch: 5| Step: 1
Training loss: 2.8168914318084717
Validation loss: 2.3186694345166607

Epoch: 5| Step: 2
Training loss: 2.5390753746032715
Validation loss: 2.331134819215344

Epoch: 5| Step: 3
Training loss: 2.1099483966827393
Validation loss: 2.3317892730876966

Epoch: 5| Step: 4
Training loss: 1.7439861297607422
Validation loss: 2.343967545417047

Epoch: 5| Step: 5
Training loss: 2.242445230484009
Validation loss: 2.3275767782683014

Epoch: 5| Step: 6
Training loss: 2.270921230316162
Validation loss: 2.3383350141586794

Epoch: 5| Step: 7
Training loss: 1.918614149093628
Validation loss: 2.338679687951201

Epoch: 5| Step: 8
Training loss: 2.876763105392456
Validation loss: 2.3332837473961616

Epoch: 5| Step: 9
Training loss: 2.666696071624756
Validation loss: 2.307994306728404

Epoch: 5| Step: 10
Training loss: 3.061960220336914
Validation loss: 2.310558548537634

Epoch: 232| Step: 0
Training loss: 2.104346752166748
Validation loss: 2.310739417229929

Epoch: 5| Step: 1
Training loss: 2.5774502754211426
Validation loss: 2.3155026769125335

Epoch: 5| Step: 2
Training loss: 2.3954460620880127
Validation loss: 2.3347755401365218

Epoch: 5| Step: 3
Training loss: 2.2368502616882324
Validation loss: 2.316158212641234

Epoch: 5| Step: 4
Training loss: 2.7094974517822266
Validation loss: 2.3256498511119554

Epoch: 5| Step: 5
Training loss: 2.2936019897460938
Validation loss: 2.336304682557301

Epoch: 5| Step: 6
Training loss: 2.5861616134643555
Validation loss: 2.3281752345382527

Epoch: 5| Step: 7
Training loss: 1.959525465965271
Validation loss: 2.320887824540497

Epoch: 5| Step: 8
Training loss: 2.591374397277832
Validation loss: 2.3149158595710673

Epoch: 5| Step: 9
Training loss: 2.802813768386841
Validation loss: 2.304707068268971

Epoch: 5| Step: 10
Training loss: 2.448410987854004
Validation loss: 2.294511737362031

Epoch: 233| Step: 0
Training loss: 2.7211525440216064
Validation loss: 2.2841268944483932

Epoch: 5| Step: 1
Training loss: 2.2735371589660645
Validation loss: 2.2699496438426356

Epoch: 5| Step: 2
Training loss: 3.0610148906707764
Validation loss: 2.275451124355357

Epoch: 5| Step: 3
Training loss: 1.3174906969070435
Validation loss: 2.2793600687416653

Epoch: 5| Step: 4
Training loss: 2.620974063873291
Validation loss: 2.277037038598009

Epoch: 5| Step: 5
Training loss: 2.6136906147003174
Validation loss: 2.2749355018779798

Epoch: 5| Step: 6
Training loss: 2.509143352508545
Validation loss: 2.2747286468423824

Epoch: 5| Step: 7
Training loss: 2.4232938289642334
Validation loss: 2.278102764519312

Epoch: 5| Step: 8
Training loss: 2.2331244945526123
Validation loss: 2.268192570696595

Epoch: 5| Step: 9
Training loss: 2.374375820159912
Validation loss: 2.266894055951026

Epoch: 5| Step: 10
Training loss: 2.5970022678375244
Validation loss: 2.28971855871139

Epoch: 234| Step: 0
Training loss: 2.27870774269104
Validation loss: 2.2859447130592923

Epoch: 5| Step: 1
Training loss: 1.9705150127410889
Validation loss: 2.278075591210396

Epoch: 5| Step: 2
Training loss: 2.1584105491638184
Validation loss: 2.280684514712262

Epoch: 5| Step: 3
Training loss: 2.60502290725708
Validation loss: 2.291125071946011

Epoch: 5| Step: 4
Training loss: 2.2765910625457764
Validation loss: 2.2662186250891736

Epoch: 5| Step: 5
Training loss: 1.934758186340332
Validation loss: 2.255585419234409

Epoch: 5| Step: 6
Training loss: 2.751338481903076
Validation loss: 2.257204471095916

Epoch: 5| Step: 7
Training loss: 2.6784887313842773
Validation loss: 2.275135335101876

Epoch: 5| Step: 8
Training loss: 2.456282615661621
Validation loss: 2.2778242839279996

Epoch: 5| Step: 9
Training loss: 2.9055867195129395
Validation loss: 2.2896781172803653

Epoch: 5| Step: 10
Training loss: 2.530632257461548
Validation loss: 2.291589340855998

Epoch: 235| Step: 0
Training loss: 2.1252996921539307
Validation loss: 2.286375884086855

Epoch: 5| Step: 1
Training loss: 2.228353977203369
Validation loss: 2.292500857383974

Epoch: 5| Step: 2
Training loss: 2.5858511924743652
Validation loss: 2.2822126111676617

Epoch: 5| Step: 3
Training loss: 2.7111735343933105
Validation loss: 2.27988923493252

Epoch: 5| Step: 4
Training loss: 2.3552818298339844
Validation loss: 2.2759581201819965

Epoch: 5| Step: 5
Training loss: 2.386542797088623
Validation loss: 2.2869524007202475

Epoch: 5| Step: 6
Training loss: 2.6741483211517334
Validation loss: 2.278277192064511

Epoch: 5| Step: 7
Training loss: 2.3827197551727295
Validation loss: 2.292538655701504

Epoch: 5| Step: 8
Training loss: 2.722878932952881
Validation loss: 2.3144659278213338

Epoch: 5| Step: 9
Training loss: 1.8025814294815063
Validation loss: 2.306934554089782

Epoch: 5| Step: 10
Training loss: 2.517457962036133
Validation loss: 2.3159906966711885

Epoch: 236| Step: 0
Training loss: 2.034816026687622
Validation loss: 2.2921353668294926

Epoch: 5| Step: 1
Training loss: 2.0508780479431152
Validation loss: 2.2716277312206965

Epoch: 5| Step: 2
Training loss: 2.2230560779571533
Validation loss: 2.261484407609509

Epoch: 5| Step: 3
Training loss: 2.4611661434173584
Validation loss: 2.2607416004262944

Epoch: 5| Step: 4
Training loss: 2.4653286933898926
Validation loss: 2.2671706830301592

Epoch: 5| Step: 5
Training loss: 2.272226095199585
Validation loss: 2.274796998629006

Epoch: 5| Step: 6
Training loss: 2.491118907928467
Validation loss: 2.26596135990594

Epoch: 5| Step: 7
Training loss: 2.749626874923706
Validation loss: 2.2616045936461417

Epoch: 5| Step: 8
Training loss: 2.282733917236328
Validation loss: 2.269999752762497

Epoch: 5| Step: 9
Training loss: 2.770115613937378
Validation loss: 2.261864081505806

Epoch: 5| Step: 10
Training loss: 2.954472064971924
Validation loss: 2.2552172650573072

Epoch: 237| Step: 0
Training loss: 2.851986885070801
Validation loss: 2.2502388620889313

Epoch: 5| Step: 1
Training loss: 2.869067430496216
Validation loss: 2.2484882544445735

Epoch: 5| Step: 2
Training loss: 2.192197322845459
Validation loss: 2.2689971898191716

Epoch: 5| Step: 3
Training loss: 1.9010875225067139
Validation loss: 2.2688718675285258

Epoch: 5| Step: 4
Training loss: 2.2309978008270264
Validation loss: 2.3025260997074906

Epoch: 5| Step: 5
Training loss: 2.333372116088867
Validation loss: 2.3211225514770835

Epoch: 5| Step: 6
Training loss: 2.443150281906128
Validation loss: 2.311799108341176

Epoch: 5| Step: 7
Training loss: 2.370251178741455
Validation loss: 2.3192301155418478

Epoch: 5| Step: 8
Training loss: 2.4273874759674072
Validation loss: 2.3076493663172566

Epoch: 5| Step: 9
Training loss: 2.8141028881073
Validation loss: 2.294525879685597

Epoch: 5| Step: 10
Training loss: 1.9989875555038452
Validation loss: 2.288600247393372

Epoch: 238| Step: 0
Training loss: 2.356475830078125
Validation loss: 2.286761860693655

Epoch: 5| Step: 1
Training loss: 2.477632761001587
Validation loss: 2.2819559087035475

Epoch: 5| Step: 2
Training loss: 3.2259159088134766
Validation loss: 2.279399989753641

Epoch: 5| Step: 3
Training loss: 2.1788103580474854
Validation loss: 2.279815671264484

Epoch: 5| Step: 4
Training loss: 2.9866440296173096
Validation loss: 2.2719574333519064

Epoch: 5| Step: 5
Training loss: 2.143026351928711
Validation loss: 2.265363358682202

Epoch: 5| Step: 6
Training loss: 2.10953950881958
Validation loss: 2.2599843368735364

Epoch: 5| Step: 7
Training loss: 1.6691720485687256
Validation loss: 2.2527816680169876

Epoch: 5| Step: 8
Training loss: 2.3046255111694336
Validation loss: 2.2460947088015977

Epoch: 5| Step: 9
Training loss: 2.9548797607421875
Validation loss: 2.243519934274817

Epoch: 5| Step: 10
Training loss: 2.0226190090179443
Validation loss: 2.258897453226069

Epoch: 239| Step: 0
Training loss: 2.1728014945983887
Validation loss: 2.2532422388753583

Epoch: 5| Step: 1
Training loss: 2.6534738540649414
Validation loss: 2.27288451117854

Epoch: 5| Step: 2
Training loss: 2.2130491733551025
Validation loss: 2.2734762289190806

Epoch: 5| Step: 3
Training loss: 2.057584285736084
Validation loss: 2.2877024783883044

Epoch: 5| Step: 4
Training loss: 2.6132264137268066
Validation loss: 2.309682866578461

Epoch: 5| Step: 5
Training loss: 1.676177740097046
Validation loss: 2.291819259684573

Epoch: 5| Step: 6
Training loss: 2.013493061065674
Validation loss: 2.282797780088199

Epoch: 5| Step: 7
Training loss: 2.8385143280029297
Validation loss: 2.271726610840008

Epoch: 5| Step: 8
Training loss: 3.0487380027770996
Validation loss: 2.2788769327184206

Epoch: 5| Step: 9
Training loss: 2.37353253364563
Validation loss: 2.2751641709317445

Epoch: 5| Step: 10
Training loss: 2.67121958732605
Validation loss: 2.2710126189775366

Epoch: 240| Step: 0
Training loss: 2.551366090774536
Validation loss: 2.262727443889905

Epoch: 5| Step: 1
Training loss: 1.6374914646148682
Validation loss: 2.2710216353016515

Epoch: 5| Step: 2
Training loss: 2.5774893760681152
Validation loss: 2.2772162396420716

Epoch: 5| Step: 3
Training loss: 2.772524833679199
Validation loss: 2.275515002589072

Epoch: 5| Step: 4
Training loss: 2.1650309562683105
Validation loss: 2.2794381610808836

Epoch: 5| Step: 5
Training loss: 2.2832133769989014
Validation loss: 2.2790253803294194

Epoch: 5| Step: 6
Training loss: 2.3745882511138916
Validation loss: 2.2600058535093903

Epoch: 5| Step: 7
Training loss: 2.69130539894104
Validation loss: 2.2643843466235745

Epoch: 5| Step: 8
Training loss: 2.4907784461975098
Validation loss: 2.2983710906838857

Epoch: 5| Step: 9
Training loss: 2.2119548320770264
Validation loss: 2.345029015694895

Epoch: 5| Step: 10
Training loss: 3.0343761444091797
Validation loss: 2.360155254281977

Epoch: 241| Step: 0
Training loss: 2.6458687782287598
Validation loss: 2.3557428057475756

Epoch: 5| Step: 1
Training loss: 1.8978052139282227
Validation loss: 2.3209337547261226

Epoch: 5| Step: 2
Training loss: 1.8926769495010376
Validation loss: 2.2804947104505313

Epoch: 5| Step: 3
Training loss: 2.551572322845459
Validation loss: 2.268372784378708

Epoch: 5| Step: 4
Training loss: 2.4135842323303223
Validation loss: 2.252251153351158

Epoch: 5| Step: 5
Training loss: 2.5156970024108887
Validation loss: 2.2480680070897585

Epoch: 5| Step: 6
Training loss: 2.356215000152588
Validation loss: 2.2410711601216304

Epoch: 5| Step: 7
Training loss: 2.722287178039551
Validation loss: 2.2557752004233738

Epoch: 5| Step: 8
Training loss: 2.2496511936187744
Validation loss: 2.2606430284438597

Epoch: 5| Step: 9
Training loss: 2.2762770652770996
Validation loss: 2.252804688228074

Epoch: 5| Step: 10
Training loss: 2.930309295654297
Validation loss: 2.2546531974628405

Epoch: 242| Step: 0
Training loss: 2.45190691947937
Validation loss: 2.260934499002272

Epoch: 5| Step: 1
Training loss: 2.965688467025757
Validation loss: 2.268611961795438

Epoch: 5| Step: 2
Training loss: 2.6528220176696777
Validation loss: 2.2707169478939426

Epoch: 5| Step: 3
Training loss: 2.4097018241882324
Validation loss: 2.2836331936620895

Epoch: 5| Step: 4
Training loss: 2.08490252494812
Validation loss: 2.3017727598067252

Epoch: 5| Step: 5
Training loss: 3.145024299621582
Validation loss: 2.29155888993253

Epoch: 5| Step: 6
Training loss: 1.9615137577056885
Validation loss: 2.3077361327345653

Epoch: 5| Step: 7
Training loss: 2.2802844047546387
Validation loss: 2.300421740419121

Epoch: 5| Step: 8
Training loss: 2.1794791221618652
Validation loss: 2.2940940216023433

Epoch: 5| Step: 9
Training loss: 2.048269748687744
Validation loss: 2.2849803393886936

Epoch: 5| Step: 10
Training loss: 2.1155312061309814
Validation loss: 2.288545831557243

Epoch: 243| Step: 0
Training loss: 1.8948745727539062
Validation loss: 2.280679207976146

Epoch: 5| Step: 1
Training loss: 2.6145987510681152
Validation loss: 2.2748668860363703

Epoch: 5| Step: 2
Training loss: 1.9457600116729736
Validation loss: 2.2850159957844722

Epoch: 5| Step: 3
Training loss: 2.61714506149292
Validation loss: 2.2799813516678347

Epoch: 5| Step: 4
Training loss: 2.497870445251465
Validation loss: 2.280569432884134

Epoch: 5| Step: 5
Training loss: 2.8064162731170654
Validation loss: 2.263370760025517

Epoch: 5| Step: 6
Training loss: 3.137892961502075
Validation loss: 2.270864443112445

Epoch: 5| Step: 7
Training loss: 2.521544933319092
Validation loss: 2.2626484106945735

Epoch: 5| Step: 8
Training loss: 2.0055248737335205
Validation loss: 2.27670225533106

Epoch: 5| Step: 9
Training loss: 1.4810529947280884
Validation loss: 2.277440583834084

Epoch: 5| Step: 10
Training loss: 2.9589126110076904
Validation loss: 2.310385778386106

Epoch: 244| Step: 0
Training loss: 2.3435187339782715
Validation loss: 2.312093512986296

Epoch: 5| Step: 1
Training loss: 2.490804672241211
Validation loss: 2.32210615886155

Epoch: 5| Step: 2
Training loss: 1.9394184350967407
Validation loss: 2.2846056235733854

Epoch: 5| Step: 3
Training loss: 2.654953718185425
Validation loss: 2.2565178127699

Epoch: 5| Step: 4
Training loss: 2.2305140495300293
Validation loss: 2.2587415890027116

Epoch: 5| Step: 5
Training loss: 2.8029744625091553
Validation loss: 2.2428736661070134

Epoch: 5| Step: 6
Training loss: 2.280932664871216
Validation loss: 2.2525764011567637

Epoch: 5| Step: 7
Training loss: 2.6993415355682373
Validation loss: 2.2484305340756654

Epoch: 5| Step: 8
Training loss: 2.4448344707489014
Validation loss: 2.2498515421344387

Epoch: 5| Step: 9
Training loss: 2.2534546852111816
Validation loss: 2.2757555912899714

Epoch: 5| Step: 10
Training loss: 2.135470151901245
Validation loss: 2.284834405427338

Epoch: 245| Step: 0
Training loss: 2.5511016845703125
Validation loss: 2.2867789935040217

Epoch: 5| Step: 1
Training loss: 2.4683616161346436
Validation loss: 2.273542170883507

Epoch: 5| Step: 2
Training loss: 2.0644943714141846
Validation loss: 2.2818986164626254

Epoch: 5| Step: 3
Training loss: 2.083904504776001
Validation loss: 2.297174092262022

Epoch: 5| Step: 4
Training loss: 2.2890968322753906
Validation loss: 2.274475118165375

Epoch: 5| Step: 5
Training loss: 2.1703438758850098
Validation loss: 2.270793660994499

Epoch: 5| Step: 6
Training loss: 2.4942498207092285
Validation loss: 2.267547671512891

Epoch: 5| Step: 7
Training loss: 2.408923625946045
Validation loss: 2.262288342240036

Epoch: 5| Step: 8
Training loss: 2.334865093231201
Validation loss: 2.2664820225008073

Epoch: 5| Step: 9
Training loss: 3.029947280883789
Validation loss: 2.255917159459924

Epoch: 5| Step: 10
Training loss: 2.1846818923950195
Validation loss: 2.2587046956503265

Epoch: 246| Step: 0
Training loss: 2.036973476409912
Validation loss: 2.243968641886147

Epoch: 5| Step: 1
Training loss: 2.697762966156006
Validation loss: 2.253964562569895

Epoch: 5| Step: 2
Training loss: 3.4291069507598877
Validation loss: 2.2488214623543525

Epoch: 5| Step: 3
Training loss: 2.490895986557007
Validation loss: 2.2465328503680486

Epoch: 5| Step: 4
Training loss: 1.6032536029815674
Validation loss: 2.2408272374060845

Epoch: 5| Step: 5
Training loss: 1.913844347000122
Validation loss: 2.227518743084323

Epoch: 5| Step: 6
Training loss: 2.9724578857421875
Validation loss: 2.228232367064363

Epoch: 5| Step: 7
Training loss: 1.925339698791504
Validation loss: 2.225646362509779

Epoch: 5| Step: 8
Training loss: 2.5144402980804443
Validation loss: 2.22988268380524

Epoch: 5| Step: 9
Training loss: 2.317850112915039
Validation loss: 2.2195912791836645

Epoch: 5| Step: 10
Training loss: 2.154125213623047
Validation loss: 2.228039897898192

Epoch: 247| Step: 0
Training loss: 2.9848392009735107
Validation loss: 2.2383975008482575

Epoch: 5| Step: 1
Training loss: 1.9299428462982178
Validation loss: 2.250885009765625

Epoch: 5| Step: 2
Training loss: 2.5359044075012207
Validation loss: 2.25353531940009

Epoch: 5| Step: 3
Training loss: 2.017547607421875
Validation loss: 2.257343061508671

Epoch: 5| Step: 4
Training loss: 2.3638527393341064
Validation loss: 2.270526837277156

Epoch: 5| Step: 5
Training loss: 2.1104629039764404
Validation loss: 2.2746403037860827

Epoch: 5| Step: 6
Training loss: 2.5119926929473877
Validation loss: 2.275697200529037

Epoch: 5| Step: 7
Training loss: 2.2363743782043457
Validation loss: 2.2874134586703394

Epoch: 5| Step: 8
Training loss: 2.294628620147705
Validation loss: 2.2862902302895822

Epoch: 5| Step: 9
Training loss: 2.3510897159576416
Validation loss: 2.288122664215744

Epoch: 5| Step: 10
Training loss: 2.764355182647705
Validation loss: 2.2778934304432203

Epoch: 248| Step: 0
Training loss: 2.307809829711914
Validation loss: 2.2802016171075965

Epoch: 5| Step: 1
Training loss: 2.8101348876953125
Validation loss: 2.2763443044436875

Epoch: 5| Step: 2
Training loss: 2.6036386489868164
Validation loss: 2.280961113591348

Epoch: 5| Step: 3
Training loss: 2.521183967590332
Validation loss: 2.2652615706125894

Epoch: 5| Step: 4
Training loss: 1.889258623123169
Validation loss: 2.267681303844657

Epoch: 5| Step: 5
Training loss: 2.5638606548309326
Validation loss: 2.253637062605991

Epoch: 5| Step: 6
Training loss: 2.2422709465026855
Validation loss: 2.258636860437291

Epoch: 5| Step: 7
Training loss: 1.969268560409546
Validation loss: 2.2498882252682924

Epoch: 5| Step: 8
Training loss: 2.7321643829345703
Validation loss: 2.2561926713553806

Epoch: 5| Step: 9
Training loss: 2.523571729660034
Validation loss: 2.249140508713261

Epoch: 5| Step: 10
Training loss: 1.8665857315063477
Validation loss: 2.2677699135195826

Epoch: 249| Step: 0
Training loss: 2.3051955699920654
Validation loss: 2.257450957452097

Epoch: 5| Step: 1
Training loss: 2.393742561340332
Validation loss: 2.266204298183482

Epoch: 5| Step: 2
Training loss: 2.6849427223205566
Validation loss: 2.256559492439352

Epoch: 5| Step: 3
Training loss: 2.120826482772827
Validation loss: 2.2362127765532462

Epoch: 5| Step: 4
Training loss: 2.093661308288574
Validation loss: 2.2349445691672702

Epoch: 5| Step: 5
Training loss: 2.6632142066955566
Validation loss: 2.2445543273802726

Epoch: 5| Step: 6
Training loss: 2.390136480331421
Validation loss: 2.24135793793586

Epoch: 5| Step: 7
Training loss: 2.423588275909424
Validation loss: 2.2371743084282003

Epoch: 5| Step: 8
Training loss: 2.2742414474487305
Validation loss: 2.237137045911563

Epoch: 5| Step: 9
Training loss: 2.4682209491729736
Validation loss: 2.243040359148415

Epoch: 5| Step: 10
Training loss: 2.3275840282440186
Validation loss: 2.2634308825257006

Epoch: 250| Step: 0
Training loss: 1.9639074802398682
Validation loss: 2.2795187504060808

Epoch: 5| Step: 1
Training loss: 2.1522490978240967
Validation loss: 2.300885151791316

Epoch: 5| Step: 2
Training loss: 2.8723461627960205
Validation loss: 2.317113550760413

Epoch: 5| Step: 3
Training loss: 2.2994155883789062
Validation loss: 2.317066172117828

Epoch: 5| Step: 4
Training loss: 2.2090368270874023
Validation loss: 2.314161733914447

Epoch: 5| Step: 5
Training loss: 1.9895178079605103
Validation loss: 2.2719613787948445

Epoch: 5| Step: 6
Training loss: 2.268286943435669
Validation loss: 2.2644608892420286

Epoch: 5| Step: 7
Training loss: 2.635338544845581
Validation loss: 2.251174367884154

Epoch: 5| Step: 8
Training loss: 2.579253673553467
Validation loss: 2.242534004231935

Epoch: 5| Step: 9
Training loss: 3.055785894393921
Validation loss: 2.2492190522532307

Epoch: 5| Step: 10
Training loss: 2.1927528381347656
Validation loss: 2.247917631621002

Epoch: 251| Step: 0
Training loss: 2.393839120864868
Validation loss: 2.24839093864605

Epoch: 5| Step: 1
Training loss: 1.8522193431854248
Validation loss: 2.245274402761972

Epoch: 5| Step: 2
Training loss: 2.145426034927368
Validation loss: 2.2334509575238792

Epoch: 5| Step: 3
Training loss: 2.824929714202881
Validation loss: 2.228832103872812

Epoch: 5| Step: 4
Training loss: 2.362393856048584
Validation loss: 2.219182660502772

Epoch: 5| Step: 5
Training loss: 2.3091773986816406
Validation loss: 2.2110765108498196

Epoch: 5| Step: 6
Training loss: 2.5981526374816895
Validation loss: 2.216846763446767

Epoch: 5| Step: 7
Training loss: 2.7125611305236816
Validation loss: 2.2404633375906173

Epoch: 5| Step: 8
Training loss: 2.251760721206665
Validation loss: 2.2481512613193964

Epoch: 5| Step: 9
Training loss: 2.490337610244751
Validation loss: 2.255062410908361

Epoch: 5| Step: 10
Training loss: 2.0975136756896973
Validation loss: 2.247995840605869

Epoch: 252| Step: 0
Training loss: 2.4012913703918457
Validation loss: 2.248085424464236

Epoch: 5| Step: 1
Training loss: 2.8383665084838867
Validation loss: 2.2480578576364825

Epoch: 5| Step: 2
Training loss: 2.5901103019714355
Validation loss: 2.234569013759654

Epoch: 5| Step: 3
Training loss: 1.9516394138336182
Validation loss: 2.2545738143305623

Epoch: 5| Step: 4
Training loss: 2.92870831489563
Validation loss: 2.2415988573464016

Epoch: 5| Step: 5
Training loss: 2.4410641193389893
Validation loss: 2.243666192536713

Epoch: 5| Step: 6
Training loss: 2.270820140838623
Validation loss: 2.238431553686819

Epoch: 5| Step: 7
Training loss: 2.3734326362609863
Validation loss: 2.250783351159865

Epoch: 5| Step: 8
Training loss: 2.227604866027832
Validation loss: 2.232117764411434

Epoch: 5| Step: 9
Training loss: 1.6535875797271729
Validation loss: 2.2376172516935613

Epoch: 5| Step: 10
Training loss: 2.0674188137054443
Validation loss: 2.264729957426748

Epoch: 253| Step: 0
Training loss: 2.386657238006592
Validation loss: 2.289553811473231

Epoch: 5| Step: 1
Training loss: 2.4433443546295166
Validation loss: 2.299130855068084

Epoch: 5| Step: 2
Training loss: 1.9921677112579346
Validation loss: 2.3072645254032587

Epoch: 5| Step: 3
Training loss: 2.040907621383667
Validation loss: 2.2874781008689635

Epoch: 5| Step: 4
Training loss: 2.4207143783569336
Validation loss: 2.2789581001445813

Epoch: 5| Step: 5
Training loss: 2.610398769378662
Validation loss: 2.273143978529079

Epoch: 5| Step: 6
Training loss: 2.046518087387085
Validation loss: 2.274122136895375

Epoch: 5| Step: 7
Training loss: 1.9932149648666382
Validation loss: 2.2709773407187512

Epoch: 5| Step: 8
Training loss: 2.186753511428833
Validation loss: 2.2682052837905062

Epoch: 5| Step: 9
Training loss: 2.906186103820801
Validation loss: 2.2616820335388184

Epoch: 5| Step: 10
Training loss: 2.771108865737915
Validation loss: 2.2464044145358506

Epoch: 254| Step: 0
Training loss: 2.5020880699157715
Validation loss: 2.2429671133718183

Epoch: 5| Step: 1
Training loss: 2.380174160003662
Validation loss: 2.228872017193866

Epoch: 5| Step: 2
Training loss: 2.438117504119873
Validation loss: 2.2174601939416703

Epoch: 5| Step: 3
Training loss: 2.64892840385437
Validation loss: 2.214891684952603

Epoch: 5| Step: 4
Training loss: 2.762392520904541
Validation loss: 2.2322089364451747

Epoch: 5| Step: 5
Training loss: 2.1691174507141113
Validation loss: 2.217184441063994

Epoch: 5| Step: 6
Training loss: 1.9583327770233154
Validation loss: 2.222761592557353

Epoch: 5| Step: 7
Training loss: 1.5682553052902222
Validation loss: 2.2417226465799476

Epoch: 5| Step: 8
Training loss: 2.570749521255493
Validation loss: 2.236275483203191

Epoch: 5| Step: 9
Training loss: 2.0689845085144043
Validation loss: 2.2433512133936726

Epoch: 5| Step: 10
Training loss: 2.632115602493286
Validation loss: 2.242242528546241

Epoch: 255| Step: 0
Training loss: 2.486021041870117
Validation loss: 2.2387891020826114

Epoch: 5| Step: 1
Training loss: 1.9172868728637695
Validation loss: 2.230683377994004

Epoch: 5| Step: 2
Training loss: 2.561908483505249
Validation loss: 2.2264193821978826

Epoch: 5| Step: 3
Training loss: 1.761060118675232
Validation loss: 2.2410478591918945

Epoch: 5| Step: 4
Training loss: 2.91776967048645
Validation loss: 2.2524132626031035

Epoch: 5| Step: 5
Training loss: 2.576808214187622
Validation loss: 2.24779329505018

Epoch: 5| Step: 6
Training loss: 2.3239660263061523
Validation loss: 2.257030748551892

Epoch: 5| Step: 7
Training loss: 2.7305779457092285
Validation loss: 2.248331482692431

Epoch: 5| Step: 8
Training loss: 1.9770580530166626
Validation loss: 2.227529607793336

Epoch: 5| Step: 9
Training loss: 2.4432382583618164
Validation loss: 2.2232516786103607

Epoch: 5| Step: 10
Training loss: 1.8892837762832642
Validation loss: 2.261144563715945

Epoch: 256| Step: 0
Training loss: 2.7262520790100098
Validation loss: 2.2512335828555528

Epoch: 5| Step: 1
Training loss: 2.2796502113342285
Validation loss: 2.274826708660331

Epoch: 5| Step: 2
Training loss: 2.597264051437378
Validation loss: 2.2831423692805792

Epoch: 5| Step: 3
Training loss: 1.8775144815444946
Validation loss: 2.2841010862781155

Epoch: 5| Step: 4
Training loss: 2.2812328338623047
Validation loss: 2.2703125399927937

Epoch: 5| Step: 5
Training loss: 2.2056217193603516
Validation loss: 2.2473645851176274

Epoch: 5| Step: 6
Training loss: 1.9532543420791626
Validation loss: 2.2169021867936656

Epoch: 5| Step: 7
Training loss: 2.573101282119751
Validation loss: 2.2332529329484507

Epoch: 5| Step: 8
Training loss: 2.9061763286590576
Validation loss: 2.2375598466524513

Epoch: 5| Step: 9
Training loss: 2.543933391571045
Validation loss: 2.260591212139335

Epoch: 5| Step: 10
Training loss: 2.0492146015167236
Validation loss: 2.2715403072295652

Epoch: 257| Step: 0
Training loss: 2.6266684532165527
Validation loss: 2.276784889159664

Epoch: 5| Step: 1
Training loss: 2.4841678142547607
Validation loss: 2.26409343237518

Epoch: 5| Step: 2
Training loss: 2.335796594619751
Validation loss: 2.270017323955413

Epoch: 5| Step: 3
Training loss: 2.6092395782470703
Validation loss: 2.2747428955570346

Epoch: 5| Step: 4
Training loss: 1.966769814491272
Validation loss: 2.2720175532884497

Epoch: 5| Step: 5
Training loss: 2.0582218170166016
Validation loss: 2.274175077356318

Epoch: 5| Step: 6
Training loss: 2.560701370239258
Validation loss: 2.2343476510817006

Epoch: 5| Step: 7
Training loss: 2.8656578063964844
Validation loss: 2.2256857015753306

Epoch: 5| Step: 8
Training loss: 2.0019330978393555
Validation loss: 2.2105229798183648

Epoch: 5| Step: 9
Training loss: 1.928305983543396
Validation loss: 2.1998543072772283

Epoch: 5| Step: 10
Training loss: 2.2291977405548096
Validation loss: 2.2153464440376527

Epoch: 258| Step: 0
Training loss: 1.8016719818115234
Validation loss: 2.2315131182311685

Epoch: 5| Step: 1
Training loss: 2.2074697017669678
Validation loss: 2.2273963574440248

Epoch: 5| Step: 2
Training loss: 2.180870771408081
Validation loss: 2.271856225946898

Epoch: 5| Step: 3
Training loss: 3.5317397117614746
Validation loss: 2.269546124242967

Epoch: 5| Step: 4
Training loss: 2.706277370452881
Validation loss: 2.252813377688008

Epoch: 5| Step: 5
Training loss: 2.096235752105713
Validation loss: 2.240540942838115

Epoch: 5| Step: 6
Training loss: 2.201305389404297
Validation loss: 2.234656774869529

Epoch: 5| Step: 7
Training loss: 1.9222743511199951
Validation loss: 2.220824399302083

Epoch: 5| Step: 8
Training loss: 2.989157199859619
Validation loss: 2.228482254089848

Epoch: 5| Step: 9
Training loss: 1.8904812335968018
Validation loss: 2.272750000799856

Epoch: 5| Step: 10
Training loss: 2.496546983718872
Validation loss: 2.3130551922705864

Epoch: 259| Step: 0
Training loss: 2.3258187770843506
Validation loss: 2.3462828449023667

Epoch: 5| Step: 1
Training loss: 2.601724863052368
Validation loss: 2.3514500920490553

Epoch: 5| Step: 2
Training loss: 2.803967237472534
Validation loss: 2.330567923925256

Epoch: 5| Step: 3
Training loss: 2.04646635055542
Validation loss: 2.337541805800571

Epoch: 5| Step: 4
Training loss: 1.8271310329437256
Validation loss: 2.286574068889823

Epoch: 5| Step: 5
Training loss: 2.028377056121826
Validation loss: 2.247624156295612

Epoch: 5| Step: 6
Training loss: 2.2402005195617676
Validation loss: 2.269774575387278

Epoch: 5| Step: 7
Training loss: 3.209728956222534
Validation loss: 2.2745745464037825

Epoch: 5| Step: 8
Training loss: 2.278430223464966
Validation loss: 2.3055907782687934

Epoch: 5| Step: 9
Training loss: 2.3650898933410645
Validation loss: 2.30737631551681

Epoch: 5| Step: 10
Training loss: 2.1185014247894287
Validation loss: 2.3072834758348364

Epoch: 260| Step: 0
Training loss: 2.4321932792663574
Validation loss: 2.301498774559267

Epoch: 5| Step: 1
Training loss: 2.25130295753479
Validation loss: 2.2865347118787867

Epoch: 5| Step: 2
Training loss: 2.0480797290802
Validation loss: 2.2760275025521555

Epoch: 5| Step: 3
Training loss: 2.360039234161377
Validation loss: 2.2596840050912674

Epoch: 5| Step: 4
Training loss: 2.3882393836975098
Validation loss: 2.2382920198543097

Epoch: 5| Step: 5
Training loss: 2.247943162918091
Validation loss: 2.250889875555551

Epoch: 5| Step: 6
Training loss: 2.4450008869171143
Validation loss: 2.2616919984099684

Epoch: 5| Step: 7
Training loss: 2.493518114089966
Validation loss: 2.283905270279095

Epoch: 5| Step: 8
Training loss: 2.147460460662842
Validation loss: 2.286856092432494

Epoch: 5| Step: 9
Training loss: 2.1147608757019043
Validation loss: 2.3042150492309244

Epoch: 5| Step: 10
Training loss: 2.901930093765259
Validation loss: 2.303501311168876

Epoch: 261| Step: 0
Training loss: 2.624368190765381
Validation loss: 2.2568776915150304

Epoch: 5| Step: 1
Training loss: 2.8324761390686035
Validation loss: 2.2452939018126457

Epoch: 5| Step: 2
Training loss: 2.518245220184326
Validation loss: 2.225143071143858

Epoch: 5| Step: 3
Training loss: 2.317203998565674
Validation loss: 2.2067781750873854

Epoch: 5| Step: 4
Training loss: 2.0551719665527344
Validation loss: 2.1994101232097996

Epoch: 5| Step: 5
Training loss: 2.1535348892211914
Validation loss: 2.1950818389974613

Epoch: 5| Step: 6
Training loss: 2.025482177734375
Validation loss: 2.196423287032753

Epoch: 5| Step: 7
Training loss: 2.555427312850952
Validation loss: 2.1885613241503314

Epoch: 5| Step: 8
Training loss: 2.423776149749756
Validation loss: 2.1926870730615433

Epoch: 5| Step: 9
Training loss: 2.218947410583496
Validation loss: 2.1910395981163107

Epoch: 5| Step: 10
Training loss: 1.7758842706680298
Validation loss: 2.1763581127248783

Epoch: 262| Step: 0
Training loss: 2.3405275344848633
Validation loss: 2.2088338431491645

Epoch: 5| Step: 1
Training loss: 2.654481887817383
Validation loss: 2.2506142021507345

Epoch: 5| Step: 2
Training loss: 2.161184787750244
Validation loss: 2.2943569255131546

Epoch: 5| Step: 3
Training loss: 3.269336223602295
Validation loss: 2.2905297586994786

Epoch: 5| Step: 4
Training loss: 1.8122926950454712
Validation loss: 2.272812779231738

Epoch: 5| Step: 5
Training loss: 2.572525978088379
Validation loss: 2.277078943867837

Epoch: 5| Step: 6
Training loss: 2.6387596130371094
Validation loss: 2.2669056282248548

Epoch: 5| Step: 7
Training loss: 2.101412296295166
Validation loss: 2.278822247700025

Epoch: 5| Step: 8
Training loss: 1.9718797206878662
Validation loss: 2.2754864615778767

Epoch: 5| Step: 9
Training loss: 2.2258732318878174
Validation loss: 2.2601696547641548

Epoch: 5| Step: 10
Training loss: 1.746801733970642
Validation loss: 2.271390635480163

Epoch: 263| Step: 0
Training loss: 1.6451812982559204
Validation loss: 2.2803930518447713

Epoch: 5| Step: 1
Training loss: 1.8685028553009033
Validation loss: 2.3022509159580355

Epoch: 5| Step: 2
Training loss: 2.052628755569458
Validation loss: 2.286605692678882

Epoch: 5| Step: 3
Training loss: 2.5311999320983887
Validation loss: 2.274066312338716

Epoch: 5| Step: 4
Training loss: 2.427283763885498
Validation loss: 2.2613310057629823

Epoch: 5| Step: 5
Training loss: 2.751851797103882
Validation loss: 2.247804272559381

Epoch: 5| Step: 6
Training loss: 2.3735218048095703
Validation loss: 2.2191225021116194

Epoch: 5| Step: 7
Training loss: 1.9437278509140015
Validation loss: 2.203184025261992

Epoch: 5| Step: 8
Training loss: 2.7213218212127686
Validation loss: 2.2016653476222867

Epoch: 5| Step: 9
Training loss: 2.3586490154266357
Validation loss: 2.2135948224734237

Epoch: 5| Step: 10
Training loss: 2.659900426864624
Validation loss: 2.205299177477437

Epoch: 264| Step: 0
Training loss: 2.6499552726745605
Validation loss: 2.2092334634514263

Epoch: 5| Step: 1
Training loss: 1.592210054397583
Validation loss: 2.210440138334869

Epoch: 5| Step: 2
Training loss: 2.813314437866211
Validation loss: 2.1915096493177515

Epoch: 5| Step: 3
Training loss: 1.7812083959579468
Validation loss: 2.1953208805412374

Epoch: 5| Step: 4
Training loss: 2.19026255607605
Validation loss: 2.180671500903304

Epoch: 5| Step: 5
Training loss: 2.0871329307556152
Validation loss: 2.1935695602047827

Epoch: 5| Step: 6
Training loss: 2.4187490940093994
Validation loss: 2.1743536264665666

Epoch: 5| Step: 7
Training loss: 3.0301454067230225
Validation loss: 2.1905710902265323

Epoch: 5| Step: 8
Training loss: 2.2992866039276123
Validation loss: 2.208429067365585

Epoch: 5| Step: 9
Training loss: 2.217055320739746
Validation loss: 2.2091783246686383

Epoch: 5| Step: 10
Training loss: 1.7901203632354736
Validation loss: 2.227652334397839

Epoch: 265| Step: 0
Training loss: 2.032681941986084
Validation loss: 2.2207696668563353

Epoch: 5| Step: 1
Training loss: 1.488950490951538
Validation loss: 2.2264440290389524

Epoch: 5| Step: 2
Training loss: 2.2343087196350098
Validation loss: 2.2398473652460242

Epoch: 5| Step: 3
Training loss: 2.105712413787842
Validation loss: 2.228144681581887

Epoch: 5| Step: 4
Training loss: 1.633641004562378
Validation loss: 2.2361938286853094

Epoch: 5| Step: 5
Training loss: 2.7483930587768555
Validation loss: 2.229851858590239

Epoch: 5| Step: 6
Training loss: 3.0661747455596924
Validation loss: 2.235703319631597

Epoch: 5| Step: 7
Training loss: 1.9934148788452148
Validation loss: 2.2292526845009095

Epoch: 5| Step: 8
Training loss: 3.0235559940338135
Validation loss: 2.2336258349880094

Epoch: 5| Step: 9
Training loss: 1.8991390466690063
Validation loss: 2.246658816132494

Epoch: 5| Step: 10
Training loss: 2.737501859664917
Validation loss: 2.241497165413313

Epoch: 266| Step: 0
Training loss: 2.3200249671936035
Validation loss: 2.230480429946735

Epoch: 5| Step: 1
Training loss: 2.4320168495178223
Validation loss: 2.2195210777303225

Epoch: 5| Step: 2
Training loss: 2.7619192600250244
Validation loss: 2.220965608473747

Epoch: 5| Step: 3
Training loss: 2.789778470993042
Validation loss: 2.2006699731273036

Epoch: 5| Step: 4
Training loss: 2.011401414871216
Validation loss: 2.2094056375565065

Epoch: 5| Step: 5
Training loss: 1.8468506336212158
Validation loss: 2.1994252102349394

Epoch: 5| Step: 6
Training loss: 2.6340651512145996
Validation loss: 2.1970540246655865

Epoch: 5| Step: 7
Training loss: 2.3702855110168457
Validation loss: 2.194933852841777

Epoch: 5| Step: 8
Training loss: 1.5910764932632446
Validation loss: 2.201961963407455

Epoch: 5| Step: 9
Training loss: 1.771261215209961
Validation loss: 2.2231086748902515

Epoch: 5| Step: 10
Training loss: 2.240328550338745
Validation loss: 2.226428057557793

Epoch: 267| Step: 0
Training loss: 2.7115769386291504
Validation loss: 2.2270505607769056

Epoch: 5| Step: 1
Training loss: 2.3800342082977295
Validation loss: 2.2166705387894825

Epoch: 5| Step: 2
Training loss: 1.7813682556152344
Validation loss: 2.205041768730328

Epoch: 5| Step: 3
Training loss: 1.9834489822387695
Validation loss: 2.199969558305638

Epoch: 5| Step: 4
Training loss: 1.927507758140564
Validation loss: 2.1995809514035463

Epoch: 5| Step: 5
Training loss: 2.6581969261169434
Validation loss: 2.201436404258974

Epoch: 5| Step: 6
Training loss: 1.6915223598480225
Validation loss: 2.1875883353653776

Epoch: 5| Step: 7
Training loss: 2.3834712505340576
Validation loss: 2.2120608719446326

Epoch: 5| Step: 8
Training loss: 2.119202136993408
Validation loss: 2.2169595431256037

Epoch: 5| Step: 9
Training loss: 2.6113524436950684
Validation loss: 2.203800488543767

Epoch: 5| Step: 10
Training loss: 2.4570810794830322
Validation loss: 2.2053437335516817

Epoch: 268| Step: 0
Training loss: 2.1072418689727783
Validation loss: 2.2013231169792915

Epoch: 5| Step: 1
Training loss: 2.280189037322998
Validation loss: 2.21313081249114

Epoch: 5| Step: 2
Training loss: 3.069568157196045
Validation loss: 2.237153437829787

Epoch: 5| Step: 3
Training loss: 2.040187358856201
Validation loss: 2.2260213487891742

Epoch: 5| Step: 4
Training loss: 2.6674506664276123
Validation loss: 2.2370228382848922

Epoch: 5| Step: 5
Training loss: 2.104381799697876
Validation loss: 2.2296091766767603

Epoch: 5| Step: 6
Training loss: 2.2876152992248535
Validation loss: 2.219452829771144

Epoch: 5| Step: 7
Training loss: 1.7264735698699951
Validation loss: 2.1929672712920816

Epoch: 5| Step: 8
Training loss: 1.9400001764297485
Validation loss: 2.1894556937679166

Epoch: 5| Step: 9
Training loss: 2.6128153800964355
Validation loss: 2.1789827026346678

Epoch: 5| Step: 10
Training loss: 1.705466866493225
Validation loss: 2.185822461241035

Epoch: 269| Step: 0
Training loss: 1.9337139129638672
Validation loss: 2.189268732583651

Epoch: 5| Step: 1
Training loss: 2.4813570976257324
Validation loss: 2.1953998432364514

Epoch: 5| Step: 2
Training loss: 1.8422046899795532
Validation loss: 2.2004664751791183

Epoch: 5| Step: 3
Training loss: 2.561296224594116
Validation loss: 2.217745332307713

Epoch: 5| Step: 4
Training loss: 2.028747081756592
Validation loss: 2.1906923017194195

Epoch: 5| Step: 5
Training loss: 1.913750410079956
Validation loss: 2.1763206002532796

Epoch: 5| Step: 6
Training loss: 2.161252498626709
Validation loss: 2.1931748415834162

Epoch: 5| Step: 7
Training loss: 2.472255229949951
Validation loss: 2.1976232656868557

Epoch: 5| Step: 8
Training loss: 2.498788356781006
Validation loss: 2.1996621008842223

Epoch: 5| Step: 9
Training loss: 2.423698902130127
Validation loss: 2.2155822451396654

Epoch: 5| Step: 10
Training loss: 2.1082687377929688
Validation loss: 2.2293361976582515

Epoch: 270| Step: 0
Training loss: 2.67820405960083
Validation loss: 2.2380975369484193

Epoch: 5| Step: 1
Training loss: 2.8856260776519775
Validation loss: 2.231114192675519

Epoch: 5| Step: 2
Training loss: 2.6165664196014404
Validation loss: 2.2280930511413084

Epoch: 5| Step: 3
Training loss: 1.8609803915023804
Validation loss: 2.2233902510776313

Epoch: 5| Step: 4
Training loss: 1.927415132522583
Validation loss: 2.207863748714488

Epoch: 5| Step: 5
Training loss: 1.7958946228027344
Validation loss: 2.1992953259457826

Epoch: 5| Step: 6
Training loss: 2.505505084991455
Validation loss: 2.1913840745085027

Epoch: 5| Step: 7
Training loss: 1.9184566736221313
Validation loss: 2.1875465723776046

Epoch: 5| Step: 8
Training loss: 1.9252830743789673
Validation loss: 2.182474966972105

Epoch: 5| Step: 9
Training loss: 2.317363739013672
Validation loss: 2.197893169618422

Epoch: 5| Step: 10
Training loss: 2.2320916652679443
Validation loss: 2.1980077682002896

Epoch: 271| Step: 0
Training loss: 2.259669542312622
Validation loss: 2.2078640896786927

Epoch: 5| Step: 1
Training loss: 1.844530701637268
Validation loss: 2.209383726119995

Epoch: 5| Step: 2
Training loss: 2.1018991470336914
Validation loss: 2.1905179408288773

Epoch: 5| Step: 3
Training loss: 2.4717822074890137
Validation loss: 2.1939236438402565

Epoch: 5| Step: 4
Training loss: 2.0400493144989014
Validation loss: 2.1702902829775246

Epoch: 5| Step: 5
Training loss: 2.3733644485473633
Validation loss: 2.1743650026218866

Epoch: 5| Step: 6
Training loss: 2.1484293937683105
Validation loss: 2.1693983795822307

Epoch: 5| Step: 7
Training loss: 2.324674606323242
Validation loss: 2.1670817534128823

Epoch: 5| Step: 8
Training loss: 2.2146658897399902
Validation loss: 2.1645206610361734

Epoch: 5| Step: 9
Training loss: 2.1541225910186768
Validation loss: 2.1661832537702335

Epoch: 5| Step: 10
Training loss: 3.011784315109253
Validation loss: 2.1660415434068248

Epoch: 272| Step: 0
Training loss: 2.3287932872772217
Validation loss: 2.176073992124168

Epoch: 5| Step: 1
Training loss: 2.5823254585266113
Validation loss: 2.181540109777963

Epoch: 5| Step: 2
Training loss: 2.177887201309204
Validation loss: 2.206636498051305

Epoch: 5| Step: 3
Training loss: 2.3579745292663574
Validation loss: 2.234186218630883

Epoch: 5| Step: 4
Training loss: 2.0133132934570312
Validation loss: 2.2354593405159573

Epoch: 5| Step: 5
Training loss: 2.5877184867858887
Validation loss: 2.2456938528245494

Epoch: 5| Step: 6
Training loss: 2.067268133163452
Validation loss: 2.2369181635559245

Epoch: 5| Step: 7
Training loss: 2.3434383869171143
Validation loss: 2.2281109850893737

Epoch: 5| Step: 8
Training loss: 2.1822450160980225
Validation loss: 2.201941869592154

Epoch: 5| Step: 9
Training loss: 2.2259013652801514
Validation loss: 2.1943542752214658

Epoch: 5| Step: 10
Training loss: 1.649147629737854
Validation loss: 2.1850548290437266

Epoch: 273| Step: 0
Training loss: 2.142886161804199
Validation loss: 2.1749647484030774

Epoch: 5| Step: 1
Training loss: 2.535531997680664
Validation loss: 2.1843394771698983

Epoch: 5| Step: 2
Training loss: 2.230766773223877
Validation loss: 2.180839151464483

Epoch: 5| Step: 3
Training loss: 2.2106223106384277
Validation loss: 2.1732673247655234

Epoch: 5| Step: 4
Training loss: 2.01365327835083
Validation loss: 2.1678110937918387

Epoch: 5| Step: 5
Training loss: 1.8377529382705688
Validation loss: 2.173323490286386

Epoch: 5| Step: 6
Training loss: 2.70530366897583
Validation loss: 2.1725326661140687

Epoch: 5| Step: 7
Training loss: 1.7711219787597656
Validation loss: 2.1831762995771182

Epoch: 5| Step: 8
Training loss: 2.6794142723083496
Validation loss: 2.2056675623821955

Epoch: 5| Step: 9
Training loss: 1.9288699626922607
Validation loss: 2.1895819658874185

Epoch: 5| Step: 10
Training loss: 2.2329955101013184
Validation loss: 2.1904203353389615

Epoch: 274| Step: 0
Training loss: 2.062229633331299
Validation loss: 2.1895456237177693

Epoch: 5| Step: 1
Training loss: 2.762549877166748
Validation loss: 2.2211628754933677

Epoch: 5| Step: 2
Training loss: 2.3407320976257324
Validation loss: 2.22411004189522

Epoch: 5| Step: 3
Training loss: 2.219860792160034
Validation loss: 2.228671763532905

Epoch: 5| Step: 4
Training loss: 2.8400001525878906
Validation loss: 2.2171523827378468

Epoch: 5| Step: 5
Training loss: 1.6693404912948608
Validation loss: 2.1986172737613803

Epoch: 5| Step: 6
Training loss: 2.1932528018951416
Validation loss: 2.177623487287952

Epoch: 5| Step: 7
Training loss: 2.232170581817627
Validation loss: 2.1820920449431225

Epoch: 5| Step: 8
Training loss: 2.1697793006896973
Validation loss: 2.18573599220604

Epoch: 5| Step: 9
Training loss: 1.6745719909667969
Validation loss: 2.1976986213396956

Epoch: 5| Step: 10
Training loss: 2.378641128540039
Validation loss: 2.206547091084142

Epoch: 275| Step: 0
Training loss: 1.7868999242782593
Validation loss: 2.242202812625516

Epoch: 5| Step: 1
Training loss: 2.4904134273529053
Validation loss: 2.242236263008528

Epoch: 5| Step: 2
Training loss: 2.03727388381958
Validation loss: 2.230561764009537

Epoch: 5| Step: 3
Training loss: 2.816002368927002
Validation loss: 2.226465097037695

Epoch: 5| Step: 4
Training loss: 2.09800124168396
Validation loss: 2.2114713217622493

Epoch: 5| Step: 5
Training loss: 2.251032590866089
Validation loss: 2.2016870001310944

Epoch: 5| Step: 6
Training loss: 2.3094048500061035
Validation loss: 2.200641485952562

Epoch: 5| Step: 7
Training loss: 2.0237956047058105
Validation loss: 2.213254710679413

Epoch: 5| Step: 8
Training loss: 2.3869659900665283
Validation loss: 2.2133882173927883

Epoch: 5| Step: 9
Training loss: 2.346992015838623
Validation loss: 2.2123075736466276

Epoch: 5| Step: 10
Training loss: 1.711540937423706
Validation loss: 2.2075589010792394

Epoch: 276| Step: 0
Training loss: 2.0772502422332764
Validation loss: 2.192782809657435

Epoch: 5| Step: 1
Training loss: 1.9798862934112549
Validation loss: 2.1912272976290796

Epoch: 5| Step: 2
Training loss: 2.157684803009033
Validation loss: 2.1950496909438924

Epoch: 5| Step: 3
Training loss: 2.6603150367736816
Validation loss: 2.19543037363278

Epoch: 5| Step: 4
Training loss: 2.2532479763031006
Validation loss: 2.1988042170001614

Epoch: 5| Step: 5
Training loss: 2.2055318355560303
Validation loss: 2.209800217741279

Epoch: 5| Step: 6
Training loss: 2.2451181411743164
Validation loss: 2.2127449461208877

Epoch: 5| Step: 7
Training loss: 1.8011350631713867
Validation loss: 2.212074507949173

Epoch: 5| Step: 8
Training loss: 2.8814401626586914
Validation loss: 2.260176181793213

Epoch: 5| Step: 9
Training loss: 2.125771999359131
Validation loss: 2.2641846543999127

Epoch: 5| Step: 10
Training loss: 2.323179006576538
Validation loss: 2.2496301486927974

Epoch: 277| Step: 0
Training loss: 2.309239625930786
Validation loss: 2.2673691241971907

Epoch: 5| Step: 1
Training loss: 2.003295421600342
Validation loss: 2.2289625444719867

Epoch: 5| Step: 2
Training loss: 2.4794301986694336
Validation loss: 2.2081267602982058

Epoch: 5| Step: 3
Training loss: 2.6299872398376465
Validation loss: 2.2008338282185216

Epoch: 5| Step: 4
Training loss: 2.22367787361145
Validation loss: 2.2034631198452366

Epoch: 5| Step: 5
Training loss: 2.0646674633026123
Validation loss: 2.1822342693164782

Epoch: 5| Step: 6
Training loss: 2.1056230068206787
Validation loss: 2.178580589191888

Epoch: 5| Step: 7
Training loss: 1.9863275289535522
Validation loss: 2.1803881673402685

Epoch: 5| Step: 8
Training loss: 2.2655189037323
Validation loss: 2.1570588657932896

Epoch: 5| Step: 9
Training loss: 2.300257921218872
Validation loss: 2.1580161612520934

Epoch: 5| Step: 10
Training loss: 2.353261709213257
Validation loss: 2.153825890633368

Epoch: 278| Step: 0
Training loss: 2.038759708404541
Validation loss: 2.1627514387971614

Epoch: 5| Step: 1
Training loss: 1.5281686782836914
Validation loss: 2.183699551449027

Epoch: 5| Step: 2
Training loss: 2.488309860229492
Validation loss: 2.2026979615611415

Epoch: 5| Step: 3
Training loss: 2.6887717247009277
Validation loss: 2.22506885374746

Epoch: 5| Step: 4
Training loss: 2.0653786659240723
Validation loss: 2.2189936996788107

Epoch: 5| Step: 5
Training loss: 2.3468661308288574
Validation loss: 2.2563685422302573

Epoch: 5| Step: 6
Training loss: 2.035621166229248
Validation loss: 2.259082199424826

Epoch: 5| Step: 7
Training loss: 2.1020641326904297
Validation loss: 2.2231267831658803

Epoch: 5| Step: 8
Training loss: 2.381167411804199
Validation loss: 2.1929560284460745

Epoch: 5| Step: 9
Training loss: 2.6858162879943848
Validation loss: 2.1770022325618292

Epoch: 5| Step: 10
Training loss: 2.032517910003662
Validation loss: 2.2043701628203034

Epoch: 279| Step: 0
Training loss: 1.6499258279800415
Validation loss: 2.21333888781968

Epoch: 5| Step: 1
Training loss: 2.8695549964904785
Validation loss: 2.2402574554566415

Epoch: 5| Step: 2
Training loss: 2.476531505584717
Validation loss: 2.2480914080014793

Epoch: 5| Step: 3
Training loss: 2.171762228012085
Validation loss: 2.2281187054931477

Epoch: 5| Step: 4
Training loss: 1.9936268329620361
Validation loss: 2.22773507589935

Epoch: 5| Step: 5
Training loss: 2.1030075550079346
Validation loss: 2.23757162145389

Epoch: 5| Step: 6
Training loss: 2.4419023990631104
Validation loss: 2.2100457837504726

Epoch: 5| Step: 7
Training loss: 2.3032870292663574
Validation loss: 2.2028996226608113

Epoch: 5| Step: 8
Training loss: 2.092627763748169
Validation loss: 2.185304690432805

Epoch: 5| Step: 9
Training loss: 1.9876251220703125
Validation loss: 2.1952913192010697

Epoch: 5| Step: 10
Training loss: 2.389699697494507
Validation loss: 2.206665792772847

Epoch: 280| Step: 0
Training loss: 2.373749256134033
Validation loss: 2.2224925987182127

Epoch: 5| Step: 1
Training loss: 2.136620044708252
Validation loss: 2.232698990452674

Epoch: 5| Step: 2
Training loss: 1.6392936706542969
Validation loss: 2.236925373795212

Epoch: 5| Step: 3
Training loss: 1.5997101068496704
Validation loss: 2.2184671714741695

Epoch: 5| Step: 4
Training loss: 2.346555233001709
Validation loss: 2.1918199767348585

Epoch: 5| Step: 5
Training loss: 2.23511004447937
Validation loss: 2.1723812472435737

Epoch: 5| Step: 6
Training loss: 2.2856383323669434
Validation loss: 2.1681581338246665

Epoch: 5| Step: 7
Training loss: 3.0097885131835938
Validation loss: 2.1594097281015046

Epoch: 5| Step: 8
Training loss: 1.9866317510604858
Validation loss: 2.167947269255115

Epoch: 5| Step: 9
Training loss: 2.4270198345184326
Validation loss: 2.167432923470774

Epoch: 5| Step: 10
Training loss: 2.3773393630981445
Validation loss: 2.1772774175931047

Epoch: 281| Step: 0
Training loss: 2.538147211074829
Validation loss: 2.1907457690085135

Epoch: 5| Step: 1
Training loss: 2.7294023036956787
Validation loss: 2.1834308537103797

Epoch: 5| Step: 2
Training loss: 1.4740008115768433
Validation loss: 2.1832447718548518

Epoch: 5| Step: 3
Training loss: 2.180934429168701
Validation loss: 2.1774643018681514

Epoch: 5| Step: 4
Training loss: 2.3020102977752686
Validation loss: 2.1791291775241977

Epoch: 5| Step: 5
Training loss: 1.7081835269927979
Validation loss: 2.1766636730522237

Epoch: 5| Step: 6
Training loss: 2.6181564331054688
Validation loss: 2.1936612770121586

Epoch: 5| Step: 7
Training loss: 1.9066492319107056
Validation loss: 2.1821274808658067

Epoch: 5| Step: 8
Training loss: 2.13584566116333
Validation loss: 2.191079748574124

Epoch: 5| Step: 9
Training loss: 1.9557826519012451
Validation loss: 2.230082602911098

Epoch: 5| Step: 10
Training loss: 2.5954082012176514
Validation loss: 2.2464176377942486

Epoch: 282| Step: 0
Training loss: 2.3954310417175293
Validation loss: 2.3027256509309173

Epoch: 5| Step: 1
Training loss: 2.3100361824035645
Validation loss: 2.2496786937918714

Epoch: 5| Step: 2
Training loss: 2.430565357208252
Validation loss: 2.208988566552439

Epoch: 5| Step: 3
Training loss: 1.252223253250122
Validation loss: 2.1749677222262145

Epoch: 5| Step: 4
Training loss: 2.127798318862915
Validation loss: 2.1798805024034236

Epoch: 5| Step: 5
Training loss: 2.201699733734131
Validation loss: 2.162911448427426

Epoch: 5| Step: 6
Training loss: 2.164846897125244
Validation loss: 2.154787148198774

Epoch: 5| Step: 7
Training loss: 1.8556798696517944
Validation loss: 2.1556563787562872

Epoch: 5| Step: 8
Training loss: 2.7243919372558594
Validation loss: 2.162766977023053

Epoch: 5| Step: 9
Training loss: 2.406576633453369
Validation loss: 2.169046281486429

Epoch: 5| Step: 10
Training loss: 2.1872801780700684
Validation loss: 2.1661211547031196

Epoch: 283| Step: 0
Training loss: 2.308781147003174
Validation loss: 2.1791791967166367

Epoch: 5| Step: 1
Training loss: 1.9218361377716064
Validation loss: 2.188088519598848

Epoch: 5| Step: 2
Training loss: 2.1574740409851074
Validation loss: 2.189422412585187

Epoch: 5| Step: 3
Training loss: 2.6618993282318115
Validation loss: 2.1848509593676497

Epoch: 5| Step: 4
Training loss: 3.269300937652588
Validation loss: 2.167788242781034

Epoch: 5| Step: 5
Training loss: 1.9959468841552734
Validation loss: 2.167512068184473

Epoch: 5| Step: 6
Training loss: 1.7534992694854736
Validation loss: 2.1736688716437227

Epoch: 5| Step: 7
Training loss: 2.12823486328125
Validation loss: 2.170364231191656

Epoch: 5| Step: 8
Training loss: 1.7538878917694092
Validation loss: 2.176462170898273

Epoch: 5| Step: 9
Training loss: 2.3634660243988037
Validation loss: 2.1871566772460938

Epoch: 5| Step: 10
Training loss: 1.5677295923233032
Validation loss: 2.208557641634377

Epoch: 284| Step: 0
Training loss: 2.467785120010376
Validation loss: 2.2223457085189

Epoch: 5| Step: 1
Training loss: 2.079833984375
Validation loss: 2.2453976241491174

Epoch: 5| Step: 2
Training loss: 2.630033493041992
Validation loss: 2.225193310809392

Epoch: 5| Step: 3
Training loss: 2.3193981647491455
Validation loss: 2.2285717892390426

Epoch: 5| Step: 4
Training loss: 2.0304858684539795
Validation loss: 2.204479125238234

Epoch: 5| Step: 5
Training loss: 1.7772899866104126
Validation loss: 2.1944047225418912

Epoch: 5| Step: 6
Training loss: 2.317629337310791
Validation loss: 2.193153222401937

Epoch: 5| Step: 7
Training loss: 1.9167144298553467
Validation loss: 2.1810712378512145

Epoch: 5| Step: 8
Training loss: 1.8543479442596436
Validation loss: 2.182854030721931

Epoch: 5| Step: 9
Training loss: 2.2419371604919434
Validation loss: 2.1838107596161547

Epoch: 5| Step: 10
Training loss: 2.5891928672790527
Validation loss: 2.1681576569875083

Epoch: 285| Step: 0
Training loss: 1.7667957544326782
Validation loss: 2.1834437103681665

Epoch: 5| Step: 1
Training loss: 2.3420698642730713
Validation loss: 2.17209788035321

Epoch: 5| Step: 2
Training loss: 1.807922601699829
Validation loss: 2.1668206619960007

Epoch: 5| Step: 3
Training loss: 2.247255802154541
Validation loss: 2.170936248635733

Epoch: 5| Step: 4
Training loss: 1.806592345237732
Validation loss: 2.183653503335932

Epoch: 5| Step: 5
Training loss: 2.58575701713562
Validation loss: 2.1825094889569026

Epoch: 5| Step: 6
Training loss: 1.8594858646392822
Validation loss: 2.1778368949890137

Epoch: 5| Step: 7
Training loss: 2.7594971656799316
Validation loss: 2.1607139520747687

Epoch: 5| Step: 8
Training loss: 2.418806552886963
Validation loss: 2.159912578521236

Epoch: 5| Step: 9
Training loss: 2.0361266136169434
Validation loss: 2.144111584591609

Epoch: 5| Step: 10
Training loss: 2.09073543548584
Validation loss: 2.148162995615313

Epoch: 286| Step: 0
Training loss: 1.9799566268920898
Validation loss: 2.1584399284855014

Epoch: 5| Step: 1
Training loss: 1.9133033752441406
Validation loss: 2.182266976243706

Epoch: 5| Step: 2
Training loss: 2.1992228031158447
Validation loss: 2.186200950735359

Epoch: 5| Step: 3
Training loss: 2.100595712661743
Validation loss: 2.211263325906569

Epoch: 5| Step: 4
Training loss: 2.4547905921936035
Validation loss: 2.2070369746095393

Epoch: 5| Step: 5
Training loss: 2.1226305961608887
Validation loss: 2.184399486869894

Epoch: 5| Step: 6
Training loss: 1.9379136562347412
Validation loss: 2.189147162181075

Epoch: 5| Step: 7
Training loss: 2.923779010772705
Validation loss: 2.1762919836146857

Epoch: 5| Step: 8
Training loss: 2.7551028728485107
Validation loss: 2.199268653828611

Epoch: 5| Step: 9
Training loss: 1.3250892162322998
Validation loss: 2.2109022807049494

Epoch: 5| Step: 10
Training loss: 2.1236019134521484
Validation loss: 2.2286618307072628

Epoch: 287| Step: 0
Training loss: 1.7757354974746704
Validation loss: 2.236959216415241

Epoch: 5| Step: 1
Training loss: 1.9561407566070557
Validation loss: 2.208423514519968

Epoch: 5| Step: 2
Training loss: 1.496671438217163
Validation loss: 2.1875445304378385

Epoch: 5| Step: 3
Training loss: 2.2881176471710205
Validation loss: 2.1603666120959866

Epoch: 5| Step: 4
Training loss: 2.1359448432922363
Validation loss: 2.156191356720463

Epoch: 5| Step: 5
Training loss: 2.2234129905700684
Validation loss: 2.149766775869554

Epoch: 5| Step: 6
Training loss: 2.204456329345703
Validation loss: 2.165914948268603

Epoch: 5| Step: 7
Training loss: 2.2782390117645264
Validation loss: 2.166859434496972

Epoch: 5| Step: 8
Training loss: 2.4757049083709717
Validation loss: 2.1843158634760047

Epoch: 5| Step: 9
Training loss: 2.4388630390167236
Validation loss: 2.1942379295185046

Epoch: 5| Step: 10
Training loss: 2.596280097961426
Validation loss: 2.1937288033064974

Epoch: 288| Step: 0
Training loss: 2.7347095012664795
Validation loss: 2.1686803704948834

Epoch: 5| Step: 1
Training loss: 2.2230849266052246
Validation loss: 2.1905559801286265

Epoch: 5| Step: 2
Training loss: 2.0747506618499756
Validation loss: 2.2053689495209725

Epoch: 5| Step: 3
Training loss: 1.8637548685073853
Validation loss: 2.2280190478089037

Epoch: 5| Step: 4
Training loss: 2.0195841789245605
Validation loss: 2.2402899303743915

Epoch: 5| Step: 5
Training loss: 1.7862451076507568
Validation loss: 2.2406906312511814

Epoch: 5| Step: 6
Training loss: 2.3151092529296875
Validation loss: 2.192130345170216

Epoch: 5| Step: 7
Training loss: 1.917097806930542
Validation loss: 2.140368955109709

Epoch: 5| Step: 8
Training loss: 2.168980360031128
Validation loss: 2.1280334098364717

Epoch: 5| Step: 9
Training loss: 2.581636667251587
Validation loss: 2.1231757902329966

Epoch: 5| Step: 10
Training loss: 2.2303125858306885
Validation loss: 2.13809448160151

Epoch: 289| Step: 0
Training loss: 2.5513172149658203
Validation loss: 2.1339548480126167

Epoch: 5| Step: 1
Training loss: 1.3172619342803955
Validation loss: 2.170092644230012

Epoch: 5| Step: 2
Training loss: 1.8543304204940796
Validation loss: 2.1658914986477105

Epoch: 5| Step: 3
Training loss: 1.924517273902893
Validation loss: 2.167366409814486

Epoch: 5| Step: 4
Training loss: 1.9954646825790405
Validation loss: 2.182122125420519

Epoch: 5| Step: 5
Training loss: 2.351687431335449
Validation loss: 2.166796217682541

Epoch: 5| Step: 6
Training loss: 2.1001105308532715
Validation loss: 2.1876903298080608

Epoch: 5| Step: 7
Training loss: 2.0179848670959473
Validation loss: 2.181493415627428

Epoch: 5| Step: 8
Training loss: 2.9280807971954346
Validation loss: 2.200226510724714

Epoch: 5| Step: 9
Training loss: 2.579963207244873
Validation loss: 2.207142742731238

Epoch: 5| Step: 10
Training loss: 2.0664567947387695
Validation loss: 2.185237648666546

Epoch: 290| Step: 0
Training loss: 1.9644362926483154
Validation loss: 2.1962731576734975

Epoch: 5| Step: 1
Training loss: 2.5786690711975098
Validation loss: 2.191294821359778

Epoch: 5| Step: 2
Training loss: 2.617520332336426
Validation loss: 2.2001947484990603

Epoch: 5| Step: 3
Training loss: 2.1123929023742676
Validation loss: 2.195402809368667

Epoch: 5| Step: 4
Training loss: 2.496673107147217
Validation loss: 2.1749906360462146

Epoch: 5| Step: 5
Training loss: 1.7512954473495483
Validation loss: 2.161353426594888

Epoch: 5| Step: 6
Training loss: 2.2038300037384033
Validation loss: 2.1541307639050227

Epoch: 5| Step: 7
Training loss: 2.1611335277557373
Validation loss: 2.152410344410968

Epoch: 5| Step: 8
Training loss: 2.2687485218048096
Validation loss: 2.1405144494066954

Epoch: 5| Step: 9
Training loss: 1.6666847467422485
Validation loss: 2.136095982725902

Epoch: 5| Step: 10
Training loss: 1.627616047859192
Validation loss: 2.137461611019668

Epoch: 291| Step: 0
Training loss: 1.0030062198638916
Validation loss: 2.130153348368983

Epoch: 5| Step: 1
Training loss: 2.3487977981567383
Validation loss: 2.1376533815937657

Epoch: 5| Step: 2
Training loss: 1.8172203302383423
Validation loss: 2.1399287216125

Epoch: 5| Step: 3
Training loss: 1.8315269947052002
Validation loss: 2.141303536712482

Epoch: 5| Step: 4
Training loss: 1.8498780727386475
Validation loss: 2.146177282897375

Epoch: 5| Step: 5
Training loss: 2.8331761360168457
Validation loss: 2.1435004203550276

Epoch: 5| Step: 6
Training loss: 2.5113024711608887
Validation loss: 2.1422336434805267

Epoch: 5| Step: 7
Training loss: 1.7896705865859985
Validation loss: 2.1382924741314304

Epoch: 5| Step: 8
Training loss: 2.1454849243164062
Validation loss: 2.1595699864049114

Epoch: 5| Step: 9
Training loss: 2.4433953762054443
Validation loss: 2.1607612422717515

Epoch: 5| Step: 10
Training loss: 2.762570381164551
Validation loss: 2.1739789491058676

Epoch: 292| Step: 0
Training loss: 1.9524179697036743
Validation loss: 2.1917426278514247

Epoch: 5| Step: 1
Training loss: 2.2447926998138428
Validation loss: 2.193116029103597

Epoch: 5| Step: 2
Training loss: 1.7744455337524414
Validation loss: 2.205299505623438

Epoch: 5| Step: 3
Training loss: 2.78598690032959
Validation loss: 2.218819428515691

Epoch: 5| Step: 4
Training loss: 2.774218797683716
Validation loss: 2.2376207202993412

Epoch: 5| Step: 5
Training loss: 1.7829735279083252
Validation loss: 2.2456068941341933

Epoch: 5| Step: 6
Training loss: 1.922401785850525
Validation loss: 2.254126012966197

Epoch: 5| Step: 7
Training loss: 1.332294225692749
Validation loss: 2.2470611731211343

Epoch: 5| Step: 8
Training loss: 2.468491554260254
Validation loss: 2.2454692932867233

Epoch: 5| Step: 9
Training loss: 2.7580480575561523
Validation loss: 2.2352994039494503

Epoch: 5| Step: 10
Training loss: 1.6115244626998901
Validation loss: 2.204678181679018

Epoch: 293| Step: 0
Training loss: 1.89508855342865
Validation loss: 2.179692291444348

Epoch: 5| Step: 1
Training loss: 2.1930739879608154
Validation loss: 2.140876757201328

Epoch: 5| Step: 2
Training loss: 2.2634785175323486
Validation loss: 2.1404989380990305

Epoch: 5| Step: 3
Training loss: 1.7834510803222656
Validation loss: 2.124702194685577

Epoch: 5| Step: 4
Training loss: 2.3705697059631348
Validation loss: 2.11793609844741

Epoch: 5| Step: 5
Training loss: 2.3206355571746826
Validation loss: 2.137887183056083

Epoch: 5| Step: 6
Training loss: 2.0231659412384033
Validation loss: 2.1325553155714467

Epoch: 5| Step: 7
Training loss: 1.9323310852050781
Validation loss: 2.1472272398651286

Epoch: 5| Step: 8
Training loss: 2.061086893081665
Validation loss: 2.1511831437387774

Epoch: 5| Step: 9
Training loss: 2.5585036277770996
Validation loss: 2.150833745156565

Epoch: 5| Step: 10
Training loss: 2.0402510166168213
Validation loss: 2.166348159954112

Epoch: 294| Step: 0
Training loss: 2.445300579071045
Validation loss: 2.167703923358712

Epoch: 5| Step: 1
Training loss: 1.9419338703155518
Validation loss: 2.1714753784159178

Epoch: 5| Step: 2
Training loss: 1.586029052734375
Validation loss: 2.1630587834183888

Epoch: 5| Step: 3
Training loss: 2.2975971698760986
Validation loss: 2.173246573376399

Epoch: 5| Step: 4
Training loss: 2.237726926803589
Validation loss: 2.1641885824100946

Epoch: 5| Step: 5
Training loss: 1.8208239078521729
Validation loss: 2.1746087548553303

Epoch: 5| Step: 6
Training loss: 3.314075469970703
Validation loss: 2.179559346168272

Epoch: 5| Step: 7
Training loss: 2.008439302444458
Validation loss: 2.194055417532562

Epoch: 5| Step: 8
Training loss: 1.4984936714172363
Validation loss: 2.1729618387837566

Epoch: 5| Step: 9
Training loss: 2.00508451461792
Validation loss: 2.1893314110335482

Epoch: 5| Step: 10
Training loss: 2.0486185550689697
Validation loss: 2.1768387427894016

Epoch: 295| Step: 0
Training loss: 2.485344886779785
Validation loss: 2.167645054478799

Epoch: 5| Step: 1
Training loss: 2.0735862255096436
Validation loss: 2.1671333812898204

Epoch: 5| Step: 2
Training loss: 1.9395980834960938
Validation loss: 2.1701581067936395

Epoch: 5| Step: 3
Training loss: 2.4020628929138184
Validation loss: 2.149151894354051

Epoch: 5| Step: 4
Training loss: 2.3987581729888916
Validation loss: 2.1390804142080326

Epoch: 5| Step: 5
Training loss: 1.8060897588729858
Validation loss: 2.1303339824881604

Epoch: 5| Step: 6
Training loss: 2.784785747528076
Validation loss: 2.143892288208008

Epoch: 5| Step: 7
Training loss: 1.4520028829574585
Validation loss: 2.155983242937314

Epoch: 5| Step: 8
Training loss: 1.309749722480774
Validation loss: 2.1674954455385924

Epoch: 5| Step: 9
Training loss: 1.6558431386947632
Validation loss: 2.160052623800052

Epoch: 5| Step: 10
Training loss: 2.863964557647705
Validation loss: 2.155918381547415

Epoch: 296| Step: 0
Training loss: 2.154186725616455
Validation loss: 2.1521999630876767

Epoch: 5| Step: 1
Training loss: 2.5922317504882812
Validation loss: 2.172606845055857

Epoch: 5| Step: 2
Training loss: 1.5997244119644165
Validation loss: 2.156110191857943

Epoch: 5| Step: 3
Training loss: 1.5499975681304932
Validation loss: 2.1566371097359607

Epoch: 5| Step: 4
Training loss: 2.1179006099700928
Validation loss: 2.144782861073812

Epoch: 5| Step: 5
Training loss: 2.5293638706207275
Validation loss: 2.158278831871607

Epoch: 5| Step: 6
Training loss: 2.0066959857940674
Validation loss: 2.1732793469582834

Epoch: 5| Step: 7
Training loss: 2.4136059284210205
Validation loss: 2.1725709848506476

Epoch: 5| Step: 8
Training loss: 1.998081922531128
Validation loss: 2.1763930115648495

Epoch: 5| Step: 9
Training loss: 1.9550174474716187
Validation loss: 2.1954288200665544

Epoch: 5| Step: 10
Training loss: 2.288952112197876
Validation loss: 2.1900073379598637

Epoch: 297| Step: 0
Training loss: 1.5297613143920898
Validation loss: 2.2061827746770715

Epoch: 5| Step: 1
Training loss: 2.700878858566284
Validation loss: 2.1943603177224436

Epoch: 5| Step: 2
Training loss: 1.7479336261749268
Validation loss: 2.1944160948517504

Epoch: 5| Step: 3
Training loss: 2.540144205093384
Validation loss: 2.211326983667189

Epoch: 5| Step: 4
Training loss: 1.817389726638794
Validation loss: 2.1919650928948515

Epoch: 5| Step: 5
Training loss: 1.8146960735321045
Validation loss: 2.2017354978028165

Epoch: 5| Step: 6
Training loss: 1.9909803867340088
Validation loss: 2.190163207310502

Epoch: 5| Step: 7
Training loss: 2.0289318561553955
Validation loss: 2.197943672057121

Epoch: 5| Step: 8
Training loss: 2.0752155780792236
Validation loss: 2.1930714422656643

Epoch: 5| Step: 9
Training loss: 2.006495952606201
Validation loss: 2.195152800570252

Epoch: 5| Step: 10
Training loss: 2.753465175628662
Validation loss: 2.1990182784295853

Epoch: 298| Step: 0
Training loss: 2.128859043121338
Validation loss: 2.1669686096970753

Epoch: 5| Step: 1
Training loss: 1.862047791481018
Validation loss: 2.160866388710596

Epoch: 5| Step: 2
Training loss: 2.2544727325439453
Validation loss: 2.158214687019266

Epoch: 5| Step: 3
Training loss: 1.6398519277572632
Validation loss: 2.152293594934607

Epoch: 5| Step: 4
Training loss: 1.8609756231307983
Validation loss: 2.155311248635733

Epoch: 5| Step: 5
Training loss: 2.689931631088257
Validation loss: 2.1526187748037358

Epoch: 5| Step: 6
Training loss: 1.93105149269104
Validation loss: 2.136121655023226

Epoch: 5| Step: 7
Training loss: 2.548522710800171
Validation loss: 2.1307939739637476

Epoch: 5| Step: 8
Training loss: 1.9715741872787476
Validation loss: 2.141999098562425

Epoch: 5| Step: 9
Training loss: 2.3384664058685303
Validation loss: 2.13432970610998

Epoch: 5| Step: 10
Training loss: 1.532422661781311
Validation loss: 2.1533969781732045

Epoch: 299| Step: 0
Training loss: 1.8193976879119873
Validation loss: 2.1420236838761197

Epoch: 5| Step: 1
Training loss: 1.9406770467758179
Validation loss: 2.1501608356352775

Epoch: 5| Step: 2
Training loss: 2.2781455516815186
Validation loss: 2.1585301263358003

Epoch: 5| Step: 3
Training loss: 2.121154308319092
Validation loss: 2.1660230582760227

Epoch: 5| Step: 4
Training loss: 2.8072752952575684
Validation loss: 2.173629255704982

Epoch: 5| Step: 5
Training loss: 2.106752872467041
Validation loss: 2.1791122292959564

Epoch: 5| Step: 6
Training loss: 1.8434998989105225
Validation loss: 2.1961926157756517

Epoch: 5| Step: 7
Training loss: 2.3900043964385986
Validation loss: 2.20392785533782

Epoch: 5| Step: 8
Training loss: 1.8000411987304688
Validation loss: 2.205811910731818

Epoch: 5| Step: 9
Training loss: 2.158722400665283
Validation loss: 2.1891253045810166

Epoch: 5| Step: 10
Training loss: 1.4989428520202637
Validation loss: 2.172481103609967

Epoch: 300| Step: 0
Training loss: 2.138519763946533
Validation loss: 2.17258789718792

Epoch: 5| Step: 1
Training loss: 1.9051618576049805
Validation loss: 2.1724476147723455

Epoch: 5| Step: 2
Training loss: 2.0331215858459473
Validation loss: 2.1758679189989643

Epoch: 5| Step: 3
Training loss: 2.179116725921631
Validation loss: 2.1646133122905606

Epoch: 5| Step: 4
Training loss: 1.9235423803329468
Validation loss: 2.1568057255078386

Epoch: 5| Step: 5
Training loss: 2.3497297763824463
Validation loss: 2.1375983402293217

Epoch: 5| Step: 6
Training loss: 2.329538345336914
Validation loss: 2.133871950129027

Epoch: 5| Step: 7
Training loss: 1.9253184795379639
Validation loss: 2.1310118731632026

Epoch: 5| Step: 8
Training loss: 1.7310504913330078
Validation loss: 2.1363728969327864

Epoch: 5| Step: 9
Training loss: 1.8629264831542969
Validation loss: 2.140526311371916

Epoch: 5| Step: 10
Training loss: 2.4458298683166504
Validation loss: 2.139245540865006

Epoch: 301| Step: 0
Training loss: 2.2763094902038574
Validation loss: 2.134570845993616

Epoch: 5| Step: 1
Training loss: 1.772475004196167
Validation loss: 2.152548454141104

Epoch: 5| Step: 2
Training loss: 1.9596083164215088
Validation loss: 2.1444975150528776

Epoch: 5| Step: 3
Training loss: 2.111532688140869
Validation loss: 2.159174942201184

Epoch: 5| Step: 4
Training loss: 1.6352752447128296
Validation loss: 2.1567085020003782

Epoch: 5| Step: 5
Training loss: 2.2603225708007812
Validation loss: 2.1561009601880143

Epoch: 5| Step: 6
Training loss: 1.8341134786605835
Validation loss: 2.1467290796259397

Epoch: 5| Step: 7
Training loss: 2.4281601905822754
Validation loss: 2.1535083773315593

Epoch: 5| Step: 8
Training loss: 1.9010646343231201
Validation loss: 2.177552535969724

Epoch: 5| Step: 9
Training loss: 2.235071897506714
Validation loss: 2.167826155180572

Epoch: 5| Step: 10
Training loss: 2.328540086746216
Validation loss: 2.1627376310286985

Epoch: 302| Step: 0
Training loss: 1.8361564874649048
Validation loss: 2.1625014428169496

Epoch: 5| Step: 1
Training loss: 2.337752342224121
Validation loss: 2.1532119602285404

Epoch: 5| Step: 2
Training loss: 1.9493906497955322
Validation loss: 2.1423636085243634

Epoch: 5| Step: 3
Training loss: 2.0223004817962646
Validation loss: 2.1402687949519

Epoch: 5| Step: 4
Training loss: 2.0091259479522705
Validation loss: 2.140972242560438

Epoch: 5| Step: 5
Training loss: 2.640230178833008
Validation loss: 2.1334937874988844

Epoch: 5| Step: 6
Training loss: 1.5597119331359863
Validation loss: 2.1668008142902004

Epoch: 5| Step: 7
Training loss: 2.275700092315674
Validation loss: 2.1990058422088623

Epoch: 5| Step: 8
Training loss: 1.8731606006622314
Validation loss: 2.2012647198092554

Epoch: 5| Step: 9
Training loss: 1.7747653722763062
Validation loss: 2.1979244678251204

Epoch: 5| Step: 10
Training loss: 2.7595512866973877
Validation loss: 2.195561283378191

Epoch: 303| Step: 0
Training loss: 2.362351655960083
Validation loss: 2.1656891351105063

Epoch: 5| Step: 1
Training loss: 1.6581008434295654
Validation loss: 2.14541345642459

Epoch: 5| Step: 2
Training loss: 1.9450817108154297
Validation loss: 2.1345258835823304

Epoch: 5| Step: 3
Training loss: 2.1548774242401123
Validation loss: 2.1281382294111353

Epoch: 5| Step: 4
Training loss: 2.1219520568847656
Validation loss: 2.1344430215897097

Epoch: 5| Step: 5
Training loss: 2.2101657390594482
Validation loss: 2.157723513982629

Epoch: 5| Step: 6
Training loss: 2.2321529388427734
Validation loss: 2.1396848950334775

Epoch: 5| Step: 7
Training loss: 2.7357044219970703
Validation loss: 2.1446823432881343

Epoch: 5| Step: 8
Training loss: 1.919041395187378
Validation loss: 2.139270362033639

Epoch: 5| Step: 9
Training loss: 1.9550930261611938
Validation loss: 2.1469904799615183

Epoch: 5| Step: 10
Training loss: 1.3606443405151367
Validation loss: 2.1727691235080844

Epoch: 304| Step: 0
Training loss: 1.8906383514404297
Validation loss: 2.1752874851226807

Epoch: 5| Step: 1
Training loss: 2.1875576972961426
Validation loss: 2.189075154642905

Epoch: 5| Step: 2
Training loss: 2.2897791862487793
Validation loss: 2.1815915774273615

Epoch: 5| Step: 3
Training loss: 2.205540418624878
Validation loss: 2.1825912383294876

Epoch: 5| Step: 4
Training loss: 1.9641139507293701
Validation loss: 2.1900581082990094

Epoch: 5| Step: 5
Training loss: 2.0770158767700195
Validation loss: 2.1843990049054547

Epoch: 5| Step: 6
Training loss: 1.9888538122177124
Validation loss: 2.1736557893855597

Epoch: 5| Step: 7
Training loss: 2.021557569503784
Validation loss: 2.1602153034620386

Epoch: 5| Step: 8
Training loss: 2.1177148818969727
Validation loss: 2.1577385407622143

Epoch: 5| Step: 9
Training loss: 1.6589759588241577
Validation loss: 2.1645379912468696

Epoch: 5| Step: 10
Training loss: 1.9871991872787476
Validation loss: 2.1401341512639034

Epoch: 305| Step: 0
Training loss: 2.1917357444763184
Validation loss: 2.1481986366292483

Epoch: 5| Step: 1
Training loss: 1.962462067604065
Validation loss: 2.1415891519156833

Epoch: 5| Step: 2
Training loss: 2.2883923053741455
Validation loss: 2.1350737143588323

Epoch: 5| Step: 3
Training loss: 1.7256141901016235
Validation loss: 2.1192113558451333

Epoch: 5| Step: 4
Training loss: 2.278573513031006
Validation loss: 2.137780781715147

Epoch: 5| Step: 5
Training loss: 1.9970130920410156
Validation loss: 2.1512433162299534

Epoch: 5| Step: 6
Training loss: 2.2402477264404297
Validation loss: 2.1558571810363443

Epoch: 5| Step: 7
Training loss: 1.7800346612930298
Validation loss: 2.1615646910923783

Epoch: 5| Step: 8
Training loss: 1.8739105463027954
Validation loss: 2.1643190383911133

Epoch: 5| Step: 9
Training loss: 2.0134530067443848
Validation loss: 2.166936548807288

Epoch: 5| Step: 10
Training loss: 2.131112575531006
Validation loss: 2.166256261128251

Epoch: 306| Step: 0
Training loss: 2.962723970413208
Validation loss: 2.1331153633773967

Epoch: 5| Step: 1
Training loss: 1.4882001876831055
Validation loss: 2.136467851618285

Epoch: 5| Step: 2
Training loss: 1.609326958656311
Validation loss: 2.149085970335109

Epoch: 5| Step: 3
Training loss: 2.038710117340088
Validation loss: 2.1390583194712156

Epoch: 5| Step: 4
Training loss: 2.131425380706787
Validation loss: 2.1538562851567424

Epoch: 5| Step: 5
Training loss: 2.181042432785034
Validation loss: 2.1546251671288603

Epoch: 5| Step: 6
Training loss: 2.396855354309082
Validation loss: 2.1495047128328713

Epoch: 5| Step: 7
Training loss: 2.467329740524292
Validation loss: 2.1641251630680536

Epoch: 5| Step: 8
Training loss: 2.240354537963867
Validation loss: 2.1453211140888993

Epoch: 5| Step: 9
Training loss: 1.440688967704773
Validation loss: 2.156580425077869

Epoch: 5| Step: 10
Training loss: 1.2423001527786255
Validation loss: 2.149074703134516

Epoch: 307| Step: 0
Training loss: 1.2950643301010132
Validation loss: 2.1517241744584936

Epoch: 5| Step: 1
Training loss: 1.7983348369598389
Validation loss: 2.1496996623213573

Epoch: 5| Step: 2
Training loss: 1.97384512424469
Validation loss: 2.1636178903682257

Epoch: 5| Step: 3
Training loss: 2.3027193546295166
Validation loss: 2.177618044678883

Epoch: 5| Step: 4
Training loss: 1.4914696216583252
Validation loss: 2.160050671587708

Epoch: 5| Step: 5
Training loss: 2.005833625793457
Validation loss: 2.157476202134163

Epoch: 5| Step: 6
Training loss: 2.5086939334869385
Validation loss: 2.136987187529123

Epoch: 5| Step: 7
Training loss: 2.816774368286133
Validation loss: 2.1295282148545787

Epoch: 5| Step: 8
Training loss: 1.7172540426254272
Validation loss: 2.132470717994116

Epoch: 5| Step: 9
Training loss: 1.8657119274139404
Validation loss: 2.137041275219251

Epoch: 5| Step: 10
Training loss: 2.4295313358306885
Validation loss: 2.138063206467577

Epoch: 308| Step: 0
Training loss: 2.2934775352478027
Validation loss: 2.140885178760816

Epoch: 5| Step: 1
Training loss: 1.9595359563827515
Validation loss: 2.137564871900825

Epoch: 5| Step: 2
Training loss: 1.9544951915740967
Validation loss: 2.123838847683322

Epoch: 5| Step: 3
Training loss: 2.3175272941589355
Validation loss: 2.1507837541641726

Epoch: 5| Step: 4
Training loss: 2.521754026412964
Validation loss: 2.1565007266177925

Epoch: 5| Step: 5
Training loss: 1.933433175086975
Validation loss: 2.1544975465343845

Epoch: 5| Step: 6
Training loss: 1.9210211038589478
Validation loss: 2.1433997974600842

Epoch: 5| Step: 7
Training loss: 1.9224662780761719
Validation loss: 2.133480061766922

Epoch: 5| Step: 8
Training loss: 1.3595223426818848
Validation loss: 2.121023375500915

Epoch: 5| Step: 9
Training loss: 2.012866497039795
Validation loss: 2.1155196774390435

Epoch: 5| Step: 10
Training loss: 2.029298782348633
Validation loss: 2.1309648342030023

Epoch: 309| Step: 0
Training loss: 1.6688621044158936
Validation loss: 2.1247168612736527

Epoch: 5| Step: 1
Training loss: 1.8458398580551147
Validation loss: 2.1246121814174037

Epoch: 5| Step: 2
Training loss: 2.591487169265747
Validation loss: 2.1369630059888287

Epoch: 5| Step: 3
Training loss: 2.1255345344543457
Validation loss: 2.1403604758683072

Epoch: 5| Step: 4
Training loss: 1.6969120502471924
Validation loss: 2.149315203389814

Epoch: 5| Step: 5
Training loss: 1.8475477695465088
Validation loss: 2.1467424336300103

Epoch: 5| Step: 6
Training loss: 1.5715389251708984
Validation loss: 2.1335033037329234

Epoch: 5| Step: 7
Training loss: 2.487640857696533
Validation loss: 2.1359951367942234

Epoch: 5| Step: 8
Training loss: 2.3413608074188232
Validation loss: 2.1487956457240607

Epoch: 5| Step: 9
Training loss: 1.7272205352783203
Validation loss: 2.1686276184615267

Epoch: 5| Step: 10
Training loss: 2.152771234512329
Validation loss: 2.1638406348484818

Epoch: 310| Step: 0
Training loss: 1.8232901096343994
Validation loss: 2.155258422256798

Epoch: 5| Step: 1
Training loss: 1.8435560464859009
Validation loss: 2.158856322688441

Epoch: 5| Step: 2
Training loss: 1.9820632934570312
Validation loss: 2.1547689899321525

Epoch: 5| Step: 3
Training loss: 1.8858931064605713
Validation loss: 2.1564989705239572

Epoch: 5| Step: 4
Training loss: 2.150876998901367
Validation loss: 2.1524599200935772

Epoch: 5| Step: 5
Training loss: 1.9254264831542969
Validation loss: 2.150128913182084

Epoch: 5| Step: 6
Training loss: 1.9208685159683228
Validation loss: 2.14502562246015

Epoch: 5| Step: 7
Training loss: 2.338075637817383
Validation loss: 2.123933695977734

Epoch: 5| Step: 8
Training loss: 2.645169734954834
Validation loss: 2.1124395196155836

Epoch: 5| Step: 9
Training loss: 1.9730560779571533
Validation loss: 2.10170256194248

Epoch: 5| Step: 10
Training loss: 1.4603595733642578
Validation loss: 2.1045007660824764

Epoch: 311| Step: 0
Training loss: 1.4285757541656494
Validation loss: 2.099560909373786

Epoch: 5| Step: 1
Training loss: 2.273270845413208
Validation loss: 2.1105988679393644

Epoch: 5| Step: 2
Training loss: 1.631317138671875
Validation loss: 2.117001241253268

Epoch: 5| Step: 3
Training loss: 2.6733555793762207
Validation loss: 2.110104486506472

Epoch: 5| Step: 4
Training loss: 2.275331974029541
Validation loss: 2.120548261109219

Epoch: 5| Step: 5
Training loss: 2.1344220638275146
Validation loss: 2.1391525268554688

Epoch: 5| Step: 6
Training loss: 2.326035261154175
Validation loss: 2.125225269666282

Epoch: 5| Step: 7
Training loss: 1.6633141040802002
Validation loss: 2.137409358896235

Epoch: 5| Step: 8
Training loss: 1.7582257986068726
Validation loss: 2.1579346041525564

Epoch: 5| Step: 9
Training loss: 1.945622444152832
Validation loss: 2.1640101966037544

Epoch: 5| Step: 10
Training loss: 1.7836103439331055
Validation loss: 2.1471542953163065

Epoch: 312| Step: 0
Training loss: 2.0297675132751465
Validation loss: 2.153540439503167

Epoch: 5| Step: 1
Training loss: 2.7370967864990234
Validation loss: 2.15514838182798

Epoch: 5| Step: 2
Training loss: 1.3795028924942017
Validation loss: 2.149605699764785

Epoch: 5| Step: 3
Training loss: 2.156242609024048
Validation loss: 2.1523684840048514

Epoch: 5| Step: 4
Training loss: 1.9093087911605835
Validation loss: 2.1234761796971804

Epoch: 5| Step: 5
Training loss: 1.9864469766616821
Validation loss: 2.113381967749647

Epoch: 5| Step: 6
Training loss: 1.7215378284454346
Validation loss: 2.0911294209059847

Epoch: 5| Step: 7
Training loss: 1.6924604177474976
Validation loss: 2.099028823196247

Epoch: 5| Step: 8
Training loss: 2.479231595993042
Validation loss: 2.1234515354197514

Epoch: 5| Step: 9
Training loss: 2.1723227500915527
Validation loss: 2.122267383401112

Epoch: 5| Step: 10
Training loss: 1.6848862171173096
Validation loss: 2.1320312664073002

Epoch: 313| Step: 0
Training loss: 2.038334369659424
Validation loss: 2.139033353456887

Epoch: 5| Step: 1
Training loss: 1.739166498184204
Validation loss: 2.127925395965576

Epoch: 5| Step: 2
Training loss: 1.8501293659210205
Validation loss: 2.1246393572899605

Epoch: 5| Step: 3
Training loss: 1.853679895401001
Validation loss: 2.1295431634431243

Epoch: 5| Step: 4
Training loss: 1.742934226989746
Validation loss: 2.136394270004765

Epoch: 5| Step: 5
Training loss: 3.330556869506836
Validation loss: 2.1632437808539278

Epoch: 5| Step: 6
Training loss: 1.537860631942749
Validation loss: 2.1611656399183374

Epoch: 5| Step: 7
Training loss: 1.9707549810409546
Validation loss: 2.160045446888093

Epoch: 5| Step: 8
Training loss: 2.015955686569214
Validation loss: 2.1500194867451987

Epoch: 5| Step: 9
Training loss: 1.7388019561767578
Validation loss: 2.1505862333441295

Epoch: 5| Step: 10
Training loss: 2.0613512992858887
Validation loss: 2.132448027210851

Epoch: 314| Step: 0
Training loss: 2.434434175491333
Validation loss: 2.1292404718296503

Epoch: 5| Step: 1
Training loss: 2.194395065307617
Validation loss: 2.1102858294722853

Epoch: 5| Step: 2
Training loss: 2.0607290267944336
Validation loss: 2.1202790019332722

Epoch: 5| Step: 3
Training loss: 2.1561036109924316
Validation loss: 2.1306162726494575

Epoch: 5| Step: 4
Training loss: 1.6044505834579468
Validation loss: 2.1281997567863873

Epoch: 5| Step: 5
Training loss: 1.772993803024292
Validation loss: 2.131739618957684

Epoch: 5| Step: 6
Training loss: 1.784897804260254
Validation loss: 2.1128173515360844

Epoch: 5| Step: 7
Training loss: 1.6388208866119385
Validation loss: 2.0991214462505874

Epoch: 5| Step: 8
Training loss: 2.368739604949951
Validation loss: 2.0941689219526065

Epoch: 5| Step: 9
Training loss: 1.6837161779403687
Validation loss: 2.104681073978383

Epoch: 5| Step: 10
Training loss: 1.9002324342727661
Validation loss: 2.109791407021143

Epoch: 315| Step: 0
Training loss: 2.0007596015930176
Validation loss: 2.115022784920149

Epoch: 5| Step: 1
Training loss: 2.2181191444396973
Validation loss: 2.12347589513307

Epoch: 5| Step: 2
Training loss: 1.9080489873886108
Validation loss: 2.105391562625926

Epoch: 5| Step: 3
Training loss: 1.6565759181976318
Validation loss: 2.132697646335889

Epoch: 5| Step: 4
Training loss: 1.9344230890274048
Validation loss: 2.143553762025731

Epoch: 5| Step: 5
Training loss: 1.5680824518203735
Validation loss: 2.150376419867239

Epoch: 5| Step: 6
Training loss: 2.1190426349639893
Validation loss: 2.1436977130110546

Epoch: 5| Step: 7
Training loss: 2.0912060737609863
Validation loss: 2.131762473813949

Epoch: 5| Step: 8
Training loss: 2.173170804977417
Validation loss: 2.1166163465028167

Epoch: 5| Step: 9
Training loss: 1.692508339881897
Validation loss: 2.117377677271443

Epoch: 5| Step: 10
Training loss: 2.183555841445923
Validation loss: 2.129264485451483

Epoch: 316| Step: 0
Training loss: 2.9872219562530518
Validation loss: 2.118187617230159

Epoch: 5| Step: 1
Training loss: 1.8224737644195557
Validation loss: 2.096377888033467

Epoch: 5| Step: 2
Training loss: 1.9962221384048462
Validation loss: 2.106575760790097

Epoch: 5| Step: 3
Training loss: 1.7193400859832764
Validation loss: 2.0912635685295187

Epoch: 5| Step: 4
Training loss: 2.154036283493042
Validation loss: 2.1013348371751848

Epoch: 5| Step: 5
Training loss: 1.846229910850525
Validation loss: 2.1222722017636864

Epoch: 5| Step: 6
Training loss: 1.8818261623382568
Validation loss: 2.116560536046182

Epoch: 5| Step: 7
Training loss: 1.9483578205108643
Validation loss: 2.1157384713490806

Epoch: 5| Step: 8
Training loss: 1.9626182317733765
Validation loss: 2.1207544572891726

Epoch: 5| Step: 9
Training loss: 1.921134352684021
Validation loss: 2.117336052720265

Epoch: 5| Step: 10
Training loss: 1.556797981262207
Validation loss: 2.1427017347787016

Epoch: 317| Step: 0
Training loss: 2.2704341411590576
Validation loss: 2.1971757719593663

Epoch: 5| Step: 1
Training loss: 2.1463966369628906
Validation loss: 2.2132451700907882

Epoch: 5| Step: 2
Training loss: 2.0114660263061523
Validation loss: 2.2193580622314126

Epoch: 5| Step: 3
Training loss: 2.328690528869629
Validation loss: 2.180136298620573

Epoch: 5| Step: 4
Training loss: 1.669268250465393
Validation loss: 2.1479879040871896

Epoch: 5| Step: 5
Training loss: 1.9016202688217163
Validation loss: 2.110378078235093

Epoch: 5| Step: 6
Training loss: 2.0315136909484863
Validation loss: 2.1099855758810557

Epoch: 5| Step: 7
Training loss: 1.9553453922271729
Validation loss: 2.1098441411090154

Epoch: 5| Step: 8
Training loss: 1.7774693965911865
Validation loss: 2.125935480158816

Epoch: 5| Step: 9
Training loss: 2.1103432178497314
Validation loss: 2.1262599883540982

Epoch: 5| Step: 10
Training loss: 1.6426454782485962
Validation loss: 2.117874465962892

Epoch: 318| Step: 0
Training loss: 2.1211228370666504
Validation loss: 2.115160419094947

Epoch: 5| Step: 1
Training loss: 1.7543985843658447
Validation loss: 2.108143478311518

Epoch: 5| Step: 2
Training loss: 2.197693347930908
Validation loss: 2.1288139730371456

Epoch: 5| Step: 3
Training loss: 2.3090572357177734
Validation loss: 2.150769677213443

Epoch: 5| Step: 4
Training loss: 2.0711307525634766
Validation loss: 2.1721181843870427

Epoch: 5| Step: 5
Training loss: 1.9503681659698486
Validation loss: 2.148916197079484

Epoch: 5| Step: 6
Training loss: 1.395111322402954
Validation loss: 2.1683031705117997

Epoch: 5| Step: 7
Training loss: 1.8941078186035156
Validation loss: 2.1780697607224986

Epoch: 5| Step: 8
Training loss: 1.6540905237197876
Validation loss: 2.1643593465128252

Epoch: 5| Step: 9
Training loss: 1.947092056274414
Validation loss: 2.1853457753376295

Epoch: 5| Step: 10
Training loss: 2.2543959617614746
Validation loss: 2.1584362945249005

Epoch: 319| Step: 0
Training loss: 2.5242767333984375
Validation loss: 2.1380975502793507

Epoch: 5| Step: 1
Training loss: 1.9892799854278564
Validation loss: 2.1165256692517187

Epoch: 5| Step: 2
Training loss: 1.3865201473236084
Validation loss: 2.0850568612416587

Epoch: 5| Step: 3
Training loss: 2.046839475631714
Validation loss: 2.0995393260832755

Epoch: 5| Step: 4
Training loss: 1.4770395755767822
Validation loss: 2.0957503331604825

Epoch: 5| Step: 5
Training loss: 1.6714332103729248
Validation loss: 2.0781252845641105

Epoch: 5| Step: 6
Training loss: 1.5799204111099243
Validation loss: 2.0877871257002636

Epoch: 5| Step: 7
Training loss: 2.1246559619903564
Validation loss: 2.091782751903739

Epoch: 5| Step: 8
Training loss: 2.10660982131958
Validation loss: 2.10199765236147

Epoch: 5| Step: 9
Training loss: 2.2756905555725098
Validation loss: 2.0940161443525747

Epoch: 5| Step: 10
Training loss: 2.2719833850860596
Validation loss: 2.1089797173776934

Epoch: 320| Step: 0
Training loss: 1.9615795612335205
Validation loss: 2.132874027375252

Epoch: 5| Step: 1
Training loss: 1.5940544605255127
Validation loss: 2.13169293121625

Epoch: 5| Step: 2
Training loss: 2.557062864303589
Validation loss: 2.151736154351183

Epoch: 5| Step: 3
Training loss: 2.091581106185913
Validation loss: 2.1418917384198917

Epoch: 5| Step: 4
Training loss: 1.7921183109283447
Validation loss: 2.1404817847795385

Epoch: 5| Step: 5
Training loss: 2.180403470993042
Validation loss: 2.1307931100168536

Epoch: 5| Step: 6
Training loss: 1.6805315017700195
Validation loss: 2.121631981224142

Epoch: 5| Step: 7
Training loss: 1.7216994762420654
Validation loss: 2.133239410256827

Epoch: 5| Step: 8
Training loss: 2.4587814807891846
Validation loss: 2.1156317380166825

Epoch: 5| Step: 9
Training loss: 1.9610134363174438
Validation loss: 2.1018855366655576

Epoch: 5| Step: 10
Training loss: 1.3771597146987915
Validation loss: 2.0825004039272184

Epoch: 321| Step: 0
Training loss: 1.8467390537261963
Validation loss: 2.075808322557839

Epoch: 5| Step: 1
Training loss: 1.8005002737045288
Validation loss: 2.0888403872007966

Epoch: 5| Step: 2
Training loss: 1.562530755996704
Validation loss: 2.081266583934907

Epoch: 5| Step: 3
Training loss: 1.855292558670044
Validation loss: 2.0990709207391225

Epoch: 5| Step: 4
Training loss: 2.1134705543518066
Validation loss: 2.1011206975547214

Epoch: 5| Step: 5
Training loss: 2.1407437324523926
Validation loss: 2.098429605525027

Epoch: 5| Step: 6
Training loss: 1.9103062152862549
Validation loss: 2.0953537674360376

Epoch: 5| Step: 7
Training loss: 1.8659671545028687
Validation loss: 2.102975732536726

Epoch: 5| Step: 8
Training loss: 1.7191979885101318
Validation loss: 2.1118237587713424

Epoch: 5| Step: 9
Training loss: 2.5457992553710938
Validation loss: 2.127432502726073

Epoch: 5| Step: 10
Training loss: 1.8509622812271118
Validation loss: 2.1251232713781376

Epoch: 322| Step: 0
Training loss: 1.777410864830017
Validation loss: 2.140474819367932

Epoch: 5| Step: 1
Training loss: 1.5445976257324219
Validation loss: 2.123316281585283

Epoch: 5| Step: 2
Training loss: 1.8750168085098267
Validation loss: 2.123263156542214

Epoch: 5| Step: 3
Training loss: 1.7027381658554077
Validation loss: 2.135973604776526

Epoch: 5| Step: 4
Training loss: 2.2127466201782227
Validation loss: 2.159901995812693

Epoch: 5| Step: 5
Training loss: 1.8604803085327148
Validation loss: 2.150745927646596

Epoch: 5| Step: 6
Training loss: 1.4236408472061157
Validation loss: 2.130137948579686

Epoch: 5| Step: 7
Training loss: 1.7865488529205322
Validation loss: 2.1325618477277857

Epoch: 5| Step: 8
Training loss: 2.5583815574645996
Validation loss: 2.118848946786696

Epoch: 5| Step: 9
Training loss: 2.304004430770874
Validation loss: 2.1213748249956357

Epoch: 5| Step: 10
Training loss: 2.085519790649414
Validation loss: 2.0979613360538276

Epoch: 323| Step: 0
Training loss: 2.244431972503662
Validation loss: 2.0802393344140824

Epoch: 5| Step: 1
Training loss: 1.912217378616333
Validation loss: 2.0853553843754593

Epoch: 5| Step: 2
Training loss: 1.641589879989624
Validation loss: 2.0773232547185754

Epoch: 5| Step: 3
Training loss: 2.5426151752471924
Validation loss: 2.0925218648807977

Epoch: 5| Step: 4
Training loss: 1.6599647998809814
Validation loss: 2.1047681352143646

Epoch: 5| Step: 5
Training loss: 1.7304527759552002
Validation loss: 2.111807994945075

Epoch: 5| Step: 6
Training loss: 1.6970930099487305
Validation loss: 2.1341797510782876

Epoch: 5| Step: 7
Training loss: 2.145052194595337
Validation loss: 2.141769354061414

Epoch: 5| Step: 8
Training loss: 2.0440292358398438
Validation loss: 2.13250381459472

Epoch: 5| Step: 9
Training loss: 1.586342692375183
Validation loss: 2.149207512537638

Epoch: 5| Step: 10
Training loss: 1.9346836805343628
Validation loss: 2.1314161644187024

Epoch: 324| Step: 0
Training loss: 2.4077506065368652
Validation loss: 2.138387862072196

Epoch: 5| Step: 1
Training loss: 1.9800589084625244
Validation loss: 2.1092025464580906

Epoch: 5| Step: 2
Training loss: 1.591012716293335
Validation loss: 2.097207151433473

Epoch: 5| Step: 3
Training loss: 2.6278927326202393
Validation loss: 2.0934308857046147

Epoch: 5| Step: 4
Training loss: 1.8888905048370361
Validation loss: 2.1160479361011135

Epoch: 5| Step: 5
Training loss: 2.235724687576294
Validation loss: 2.1064018793003534

Epoch: 5| Step: 6
Training loss: 1.3068264722824097
Validation loss: 2.0979267461325533

Epoch: 5| Step: 7
Training loss: 1.9298290014266968
Validation loss: 2.098911177727484

Epoch: 5| Step: 8
Training loss: 1.9385864734649658
Validation loss: 2.1302775234304447

Epoch: 5| Step: 9
Training loss: 1.8000116348266602
Validation loss: 2.120265215955755

Epoch: 5| Step: 10
Training loss: 1.2513229846954346
Validation loss: 2.1300274095227643

Epoch: 325| Step: 0
Training loss: 1.7352886199951172
Validation loss: 2.125659442717029

Epoch: 5| Step: 1
Training loss: 1.7832874059677124
Validation loss: 2.129226723024922

Epoch: 5| Step: 2
Training loss: 1.93606698513031
Validation loss: 2.1391219195499214

Epoch: 5| Step: 3
Training loss: 1.8107755184173584
Validation loss: 2.130662977054555

Epoch: 5| Step: 4
Training loss: 2.5768942832946777
Validation loss: 2.155199396994806

Epoch: 5| Step: 5
Training loss: 1.4928988218307495
Validation loss: 2.1482420531652306

Epoch: 5| Step: 6
Training loss: 2.517120361328125
Validation loss: 2.161555644004576

Epoch: 5| Step: 7
Training loss: 1.7385612726211548
Validation loss: 2.1362756144615913

Epoch: 5| Step: 8
Training loss: 1.8939714431762695
Validation loss: 2.1354022769517798

Epoch: 5| Step: 9
Training loss: 1.8086096048355103
Validation loss: 2.1171468842414116

Epoch: 5| Step: 10
Training loss: 1.6720037460327148
Validation loss: 2.1106048758311937

Epoch: 326| Step: 0
Training loss: 2.684210777282715
Validation loss: 2.1042840737168507

Epoch: 5| Step: 1
Training loss: 1.4800827503204346
Validation loss: 2.1135661884020736

Epoch: 5| Step: 2
Training loss: 1.9984636306762695
Validation loss: 2.1430422029187604

Epoch: 5| Step: 3
Training loss: 1.7375208139419556
Validation loss: 2.136060801885461

Epoch: 5| Step: 4
Training loss: 2.5887484550476074
Validation loss: 2.166116088949224

Epoch: 5| Step: 5
Training loss: 2.003037214279175
Validation loss: 2.177440571528609

Epoch: 5| Step: 6
Training loss: 1.8819713592529297
Validation loss: 2.1518162835028862

Epoch: 5| Step: 7
Training loss: 1.3269914388656616
Validation loss: 2.125797458874282

Epoch: 5| Step: 8
Training loss: 1.4777982234954834
Validation loss: 2.1101771195729575

Epoch: 5| Step: 9
Training loss: 1.7916122674942017
Validation loss: 2.148274906219975

Epoch: 5| Step: 10
Training loss: 2.394474983215332
Validation loss: 2.1723034663866927

Epoch: 327| Step: 0
Training loss: 1.8457839488983154
Validation loss: 2.1985376099104523

Epoch: 5| Step: 1
Training loss: 1.9585998058319092
Validation loss: 2.2088828522671937

Epoch: 5| Step: 2
Training loss: 2.0360703468322754
Validation loss: 2.2057531290156867

Epoch: 5| Step: 3
Training loss: 1.7963988780975342
Validation loss: 2.2030821769468245

Epoch: 5| Step: 4
Training loss: 1.302362322807312
Validation loss: 2.173130344319087

Epoch: 5| Step: 5
Training loss: 2.254436492919922
Validation loss: 2.138096123613337

Epoch: 5| Step: 6
Training loss: 2.0527751445770264
Validation loss: 2.1087505548231062

Epoch: 5| Step: 7
Training loss: 1.7665560245513916
Validation loss: 2.1139364434826757

Epoch: 5| Step: 8
Training loss: 2.171903610229492
Validation loss: 2.1029353654512795

Epoch: 5| Step: 9
Training loss: 1.8348859548568726
Validation loss: 2.0866032851639615

Epoch: 5| Step: 10
Training loss: 2.2354013919830322
Validation loss: 2.0760100221121185

Epoch: 328| Step: 0
Training loss: 1.650463342666626
Validation loss: 2.0588889429646153

Epoch: 5| Step: 1
Training loss: 1.7115672826766968
Validation loss: 2.0602964432008806

Epoch: 5| Step: 2
Training loss: 2.069240093231201
Validation loss: 2.062903126080831

Epoch: 5| Step: 3
Training loss: 2.3912036418914795
Validation loss: 2.0753078281238513

Epoch: 5| Step: 4
Training loss: 1.797760009765625
Validation loss: 2.0756463132878786

Epoch: 5| Step: 5
Training loss: 2.000619888305664
Validation loss: 2.0751037264382965

Epoch: 5| Step: 6
Training loss: 1.5206451416015625
Validation loss: 2.0920601198750157

Epoch: 5| Step: 7
Training loss: 2.106370449066162
Validation loss: 2.082905511702261

Epoch: 5| Step: 8
Training loss: 2.285728931427002
Validation loss: 2.119996864308593

Epoch: 5| Step: 9
Training loss: 1.6426109075546265
Validation loss: 2.1106495639329315

Epoch: 5| Step: 10
Training loss: 1.706670880317688
Validation loss: 2.1221216199218587

Epoch: 329| Step: 0
Training loss: 2.0781233310699463
Validation loss: 2.1548890708595194

Epoch: 5| Step: 1
Training loss: 1.8546050786972046
Validation loss: 2.173875939461493

Epoch: 5| Step: 2
Training loss: 2.2413527965545654
Validation loss: 2.187181629160399

Epoch: 5| Step: 3
Training loss: 2.0750441551208496
Validation loss: 2.178181295753807

Epoch: 5| Step: 4
Training loss: 1.9717985391616821
Validation loss: 2.1756227452267884

Epoch: 5| Step: 5
Training loss: 1.5436677932739258
Validation loss: 2.152090013668101

Epoch: 5| Step: 6
Training loss: 2.033478260040283
Validation loss: 2.1282797808288247

Epoch: 5| Step: 7
Training loss: 0.9867496490478516
Validation loss: 2.122938912401917

Epoch: 5| Step: 8
Training loss: 1.4928882122039795
Validation loss: 2.114098375843417

Epoch: 5| Step: 9
Training loss: 2.53873610496521
Validation loss: 2.120756974784277

Epoch: 5| Step: 10
Training loss: 2.069528341293335
Validation loss: 2.112023371522145

Epoch: 330| Step: 0
Training loss: 2.1306347846984863
Validation loss: 2.107643932424566

Epoch: 5| Step: 1
Training loss: 1.8449041843414307
Validation loss: 2.1144922651270384

Epoch: 5| Step: 2
Training loss: 1.8475242853164673
Validation loss: 2.102063226443465

Epoch: 5| Step: 3
Training loss: 1.6981303691864014
Validation loss: 2.115791215691515

Epoch: 5| Step: 4
Training loss: 1.6533111333847046
Validation loss: 2.1151663308502524

Epoch: 5| Step: 5
Training loss: 1.6807146072387695
Validation loss: 2.138227588386946

Epoch: 5| Step: 6
Training loss: 2.253197193145752
Validation loss: 2.1427648990384993

Epoch: 5| Step: 7
Training loss: 1.893707036972046
Validation loss: 2.145774643908265

Epoch: 5| Step: 8
Training loss: 1.6854909658432007
Validation loss: 2.140824601214419

Epoch: 5| Step: 9
Training loss: 2.5561583042144775
Validation loss: 2.1461389859517417

Epoch: 5| Step: 10
Training loss: 1.233068585395813
Validation loss: 2.133510684454313

Epoch: 331| Step: 0
Training loss: 1.6107618808746338
Validation loss: 2.119569327241631

Epoch: 5| Step: 1
Training loss: 1.3635475635528564
Validation loss: 2.116864278752317

Epoch: 5| Step: 2
Training loss: 2.322324514389038
Validation loss: 2.124379848921171

Epoch: 5| Step: 3
Training loss: 1.9154809713363647
Validation loss: 2.1243272519880727

Epoch: 5| Step: 4
Training loss: 1.5499134063720703
Validation loss: 2.1412970455743934

Epoch: 5| Step: 5
Training loss: 1.6199591159820557
Validation loss: 2.1231276258345573

Epoch: 5| Step: 6
Training loss: 1.8763182163238525
Validation loss: 2.1179171082794026

Epoch: 5| Step: 7
Training loss: 2.5320792198181152
Validation loss: 2.110484851303921

Epoch: 5| Step: 8
Training loss: 1.785797119140625
Validation loss: 2.1156557452294136

Epoch: 5| Step: 9
Training loss: 1.7480159997940063
Validation loss: 2.138628658427987

Epoch: 5| Step: 10
Training loss: 2.3126864433288574
Validation loss: 2.15029308103746

Epoch: 332| Step: 0
Training loss: 1.9548122882843018
Validation loss: 2.1413920464054232

Epoch: 5| Step: 1
Training loss: 2.3424012660980225
Validation loss: 2.1049004831621723

Epoch: 5| Step: 2
Training loss: 2.1140499114990234
Validation loss: 2.103856966059695

Epoch: 5| Step: 3
Training loss: 1.6509023904800415
Validation loss: 2.1052750182408158

Epoch: 5| Step: 4
Training loss: 2.011276960372925
Validation loss: 2.1127576494729645

Epoch: 5| Step: 5
Training loss: 1.7735671997070312
Validation loss: 2.1111531744721117

Epoch: 5| Step: 6
Training loss: 1.8410999774932861
Validation loss: 2.091281895996422

Epoch: 5| Step: 7
Training loss: 1.9559104442596436
Validation loss: 2.086978103524895

Epoch: 5| Step: 8
Training loss: 1.463395118713379
Validation loss: 2.08731657971618

Epoch: 5| Step: 9
Training loss: 1.9631245136260986
Validation loss: 2.1094402087632047

Epoch: 5| Step: 10
Training loss: 1.3997725248336792
Validation loss: 2.110881850283633

Epoch: 333| Step: 0
Training loss: 1.3844621181488037
Validation loss: 2.1284046288459533

Epoch: 5| Step: 1
Training loss: 1.9182517528533936
Validation loss: 2.1411190314959456

Epoch: 5| Step: 2
Training loss: 2.3395256996154785
Validation loss: 2.16817041366331

Epoch: 5| Step: 3
Training loss: 1.8578999042510986
Validation loss: 2.149935527514386

Epoch: 5| Step: 4
Training loss: 1.5124269723892212
Validation loss: 2.142627759646344

Epoch: 5| Step: 5
Training loss: 2.0320794582366943
Validation loss: 2.14217572827493

Epoch: 5| Step: 6
Training loss: 1.8996025323867798
Validation loss: 2.115870870569701

Epoch: 5| Step: 7
Training loss: 1.8547477722167969
Validation loss: 2.0954238086618404

Epoch: 5| Step: 8
Training loss: 2.0056545734405518
Validation loss: 2.085098211483289

Epoch: 5| Step: 9
Training loss: 2.1369729042053223
Validation loss: 2.0892970869618077

Epoch: 5| Step: 10
Training loss: 1.3177812099456787
Validation loss: 2.070162888496153

Epoch: 334| Step: 0
Training loss: 1.9950135946273804
Validation loss: 2.0635847712075837

Epoch: 5| Step: 1
Training loss: 1.8104242086410522
Validation loss: 2.0587036084103327

Epoch: 5| Step: 2
Training loss: 2.2064568996429443
Validation loss: 2.0543442541553127

Epoch: 5| Step: 3
Training loss: 1.6920862197875977
Validation loss: 2.0614137700808945

Epoch: 5| Step: 4
Training loss: 1.5498002767562866
Validation loss: 2.0590322607307026

Epoch: 5| Step: 5
Training loss: 1.334246277809143
Validation loss: 2.0727099359676404

Epoch: 5| Step: 6
Training loss: 2.3291568756103516
Validation loss: 2.0857275378319526

Epoch: 5| Step: 7
Training loss: 1.6126445531845093
Validation loss: 2.0918554516248804

Epoch: 5| Step: 8
Training loss: 2.3260796070098877
Validation loss: 2.1211549492292505

Epoch: 5| Step: 9
Training loss: 1.5855989456176758
Validation loss: 2.13333301390371

Epoch: 5| Step: 10
Training loss: 1.7933956384658813
Validation loss: 2.1756380206795147

Epoch: 335| Step: 0
Training loss: 1.1514499187469482
Validation loss: 2.177458668267855

Epoch: 5| Step: 1
Training loss: 1.8755333423614502
Validation loss: 2.1630724373684136

Epoch: 5| Step: 2
Training loss: 2.0772476196289062
Validation loss: 2.187953410610076

Epoch: 5| Step: 3
Training loss: 2.1184074878692627
Validation loss: 2.1679525862457933

Epoch: 5| Step: 4
Training loss: 1.9111642837524414
Validation loss: 2.1944322278422694

Epoch: 5| Step: 5
Training loss: 2.046058177947998
Validation loss: 2.1912593251915387

Epoch: 5| Step: 6
Training loss: 1.867466688156128
Validation loss: 2.197046190179804

Epoch: 5| Step: 7
Training loss: 1.3523403406143188
Validation loss: 2.16192009756642

Epoch: 5| Step: 8
Training loss: 1.8852916955947876
Validation loss: 2.1527502229136806

Epoch: 5| Step: 9
Training loss: 1.7714335918426514
Validation loss: 2.1195109249443136

Epoch: 5| Step: 10
Training loss: 2.3897945880889893
Validation loss: 2.1020436466381116

Epoch: 336| Step: 0
Training loss: 2.3027994632720947
Validation loss: 2.078050405748429

Epoch: 5| Step: 1
Training loss: 2.049116611480713
Validation loss: 2.0589082138512724

Epoch: 5| Step: 2
Training loss: 1.385345697402954
Validation loss: 2.075964696945683

Epoch: 5| Step: 3
Training loss: 2.1718716621398926
Validation loss: 2.0412648826517086

Epoch: 5| Step: 4
Training loss: 1.4263885021209717
Validation loss: 2.036418044438926

Epoch: 5| Step: 5
Training loss: 2.1710495948791504
Validation loss: 2.060419850451972

Epoch: 5| Step: 6
Training loss: 1.6917762756347656
Validation loss: 2.0610410474961802

Epoch: 5| Step: 7
Training loss: 1.1512254476547241
Validation loss: 2.066890080769857

Epoch: 5| Step: 8
Training loss: 2.0093963146209717
Validation loss: 2.095396634071104

Epoch: 5| Step: 9
Training loss: 2.070979356765747
Validation loss: 2.0977516610135316

Epoch: 5| Step: 10
Training loss: 2.069831371307373
Validation loss: 2.100597116254991

Epoch: 337| Step: 0
Training loss: 1.7268455028533936
Validation loss: 2.1203493084958804

Epoch: 5| Step: 1
Training loss: 1.2778770923614502
Validation loss: 2.135317744747285

Epoch: 5| Step: 2
Training loss: 1.3531157970428467
Validation loss: 2.148537794748942

Epoch: 5| Step: 3
Training loss: 1.6922804117202759
Validation loss: 2.1477149199413996

Epoch: 5| Step: 4
Training loss: 2.4773478507995605
Validation loss: 2.147225961890272

Epoch: 5| Step: 5
Training loss: 2.0301952362060547
Validation loss: 2.1318313806287703

Epoch: 5| Step: 6
Training loss: 2.1776950359344482
Validation loss: 2.1397872150585218

Epoch: 5| Step: 7
Training loss: 1.7044727802276611
Validation loss: 2.125324918377784

Epoch: 5| Step: 8
Training loss: 1.6435105800628662
Validation loss: 2.113666649787657

Epoch: 5| Step: 9
Training loss: 1.9053148031234741
Validation loss: 2.1113259253963346

Epoch: 5| Step: 10
Training loss: 2.2759242057800293
Validation loss: 2.087540311198081

Epoch: 338| Step: 0
Training loss: 2.061847686767578
Validation loss: 2.106648116983393

Epoch: 5| Step: 1
Training loss: 1.9623596668243408
Validation loss: 2.094078279310657

Epoch: 5| Step: 2
Training loss: 2.5024986267089844
Validation loss: 2.112874613013319

Epoch: 5| Step: 3
Training loss: 1.8650739192962646
Validation loss: 2.100995409873224

Epoch: 5| Step: 4
Training loss: 1.3522323369979858
Validation loss: 2.1330163055850613

Epoch: 5| Step: 5
Training loss: 1.5998033285140991
Validation loss: 2.1268433986171598

Epoch: 5| Step: 6
Training loss: 1.8762500286102295
Validation loss: 2.132579590684624

Epoch: 5| Step: 7
Training loss: 1.6388604640960693
Validation loss: 2.118923456438126

Epoch: 5| Step: 8
Training loss: 1.3993334770202637
Validation loss: 2.1196119029034852

Epoch: 5| Step: 9
Training loss: 1.6167685985565186
Validation loss: 2.14244859192961

Epoch: 5| Step: 10
Training loss: 2.1599602699279785
Validation loss: 2.1297082490818475

Epoch: 339| Step: 0
Training loss: 1.647834062576294
Validation loss: 2.131825870083224

Epoch: 5| Step: 1
Training loss: 1.807233452796936
Validation loss: 2.141846095362017

Epoch: 5| Step: 2
Training loss: 2.2342190742492676
Validation loss: 2.1184335908582135

Epoch: 5| Step: 3
Training loss: 2.046705484390259
Validation loss: 2.1003879654792046

Epoch: 5| Step: 4
Training loss: 1.6822096109390259
Validation loss: 2.100164290397398

Epoch: 5| Step: 5
Training loss: 1.9352766275405884
Validation loss: 2.11087046131011

Epoch: 5| Step: 6
Training loss: 1.430243968963623
Validation loss: 2.120526184317886

Epoch: 5| Step: 7
Training loss: 2.6566874980926514
Validation loss: 2.11320891944311

Epoch: 5| Step: 8
Training loss: 1.411137342453003
Validation loss: 2.0933082654911983

Epoch: 5| Step: 9
Training loss: 1.530178427696228
Validation loss: 2.078912427348475

Epoch: 5| Step: 10
Training loss: 1.5743285417556763
Validation loss: 2.0592989126841226

Epoch: 340| Step: 0
Training loss: 2.3613991737365723
Validation loss: 2.0651229414888608

Epoch: 5| Step: 1
Training loss: 1.3800239562988281
Validation loss: 2.0643775258012997

Epoch: 5| Step: 2
Training loss: 1.7386707067489624
Validation loss: 2.0596733118898127

Epoch: 5| Step: 3
Training loss: 1.46645987033844
Validation loss: 2.0900055464877876

Epoch: 5| Step: 4
Training loss: 1.9046528339385986
Validation loss: 2.0877320689539753

Epoch: 5| Step: 5
Training loss: 2.4503824710845947
Validation loss: 2.120740439302178

Epoch: 5| Step: 6
Training loss: 1.625766396522522
Validation loss: 2.129144735233758

Epoch: 5| Step: 7
Training loss: 1.9103498458862305
Validation loss: 2.1757078004139725

Epoch: 5| Step: 8
Training loss: 1.6284494400024414
Validation loss: 2.178036046284501

Epoch: 5| Step: 9
Training loss: 1.9667564630508423
Validation loss: 2.211939634815339

Epoch: 5| Step: 10
Training loss: 1.6559306383132935
Validation loss: 2.183390441761222

Epoch: 341| Step: 0
Training loss: 1.650369644165039
Validation loss: 2.153991268527123

Epoch: 5| Step: 1
Training loss: 1.8565871715545654
Validation loss: 2.130158849941787

Epoch: 5| Step: 2
Training loss: 1.9748016595840454
Validation loss: 2.0752737496488836

Epoch: 5| Step: 3
Training loss: 1.778609037399292
Validation loss: 2.0858197596765335

Epoch: 5| Step: 4
Training loss: 1.8635221719741821
Validation loss: 2.0629763436573807

Epoch: 5| Step: 5
Training loss: 1.9511511325836182
Validation loss: 2.0626059334765197

Epoch: 5| Step: 6
Training loss: 1.9179279804229736
Validation loss: 2.0408755617757

Epoch: 5| Step: 7
Training loss: 1.6972131729125977
Validation loss: 2.0483813157645603

Epoch: 5| Step: 8
Training loss: 1.7154178619384766
Validation loss: 2.087093955727034

Epoch: 5| Step: 9
Training loss: 1.8746150732040405
Validation loss: 2.117305829960813

Epoch: 5| Step: 10
Training loss: 1.7550852298736572
Validation loss: 2.1209700235756497

Epoch: 342| Step: 0
Training loss: 1.7901942729949951
Validation loss: 2.1141376879907425

Epoch: 5| Step: 1
Training loss: 1.9872148036956787
Validation loss: 2.0907566649939424

Epoch: 5| Step: 2
Training loss: 1.8660863637924194
Validation loss: 2.1026540187097367

Epoch: 5| Step: 3
Training loss: 1.4725151062011719
Validation loss: 2.117686717740951

Epoch: 5| Step: 4
Training loss: 1.874976396560669
Validation loss: 2.141262990172191

Epoch: 5| Step: 5
Training loss: 1.888214111328125
Validation loss: 2.152801767472298

Epoch: 5| Step: 6
Training loss: 2.0361359119415283
Validation loss: 2.1578298973780807

Epoch: 5| Step: 7
Training loss: 1.5427525043487549
Validation loss: 2.1624576853167627

Epoch: 5| Step: 8
Training loss: 1.814681053161621
Validation loss: 2.171661671771798

Epoch: 5| Step: 9
Training loss: 1.4596871137619019
Validation loss: 2.1765400286643737

Epoch: 5| Step: 10
Training loss: 2.367733955383301
Validation loss: 2.1786236660454863

Epoch: 343| Step: 0
Training loss: 1.626863718032837
Validation loss: 2.153299100937382

Epoch: 5| Step: 1
Training loss: 1.801974892616272
Validation loss: 2.1523769235098236

Epoch: 5| Step: 2
Training loss: 1.6244312524795532
Validation loss: 2.1467825494786745

Epoch: 5| Step: 3
Training loss: 2.250328302383423
Validation loss: 2.1074855635243077

Epoch: 5| Step: 4
Training loss: 1.6918351650238037
Validation loss: 2.088514539503282

Epoch: 5| Step: 5
Training loss: 1.835736632347107
Validation loss: 2.068038378992388

Epoch: 5| Step: 6
Training loss: 1.663678765296936
Validation loss: 2.061037895500019

Epoch: 5| Step: 7
Training loss: 1.5669078826904297
Validation loss: 2.06731572715185

Epoch: 5| Step: 8
Training loss: 1.6413657665252686
Validation loss: 2.07214529027221

Epoch: 5| Step: 9
Training loss: 2.038546085357666
Validation loss: 2.08525320535065

Epoch: 5| Step: 10
Training loss: 1.9076777696609497
Validation loss: 2.1037455912559264

Epoch: 344| Step: 0
Training loss: 2.398611545562744
Validation loss: 2.1008556222402923

Epoch: 5| Step: 1
Training loss: 1.7004568576812744
Validation loss: 2.10730403982183

Epoch: 5| Step: 2
Training loss: 1.7315607070922852
Validation loss: 2.1308916255991948

Epoch: 5| Step: 3
Training loss: 2.1262683868408203
Validation loss: 2.135561276507634

Epoch: 5| Step: 4
Training loss: 1.402477502822876
Validation loss: 2.125442015227451

Epoch: 5| Step: 5
Training loss: 1.5149325132369995
Validation loss: 2.1199111784658125

Epoch: 5| Step: 6
Training loss: 2.173063278198242
Validation loss: 2.1168737052589335

Epoch: 5| Step: 7
Training loss: 1.8383651971817017
Validation loss: 2.0981720262958157

Epoch: 5| Step: 8
Training loss: 1.7166643142700195
Validation loss: 2.102823994492972

Epoch: 5| Step: 9
Training loss: 1.310119390487671
Validation loss: 2.0936363986743394

Epoch: 5| Step: 10
Training loss: 1.5110681056976318
Validation loss: 2.129438813014697

Epoch: 345| Step: 0
Training loss: 1.682482123374939
Validation loss: 2.135201468262621

Epoch: 5| Step: 1
Training loss: 2.023175001144409
Validation loss: 2.1288314686026624

Epoch: 5| Step: 2
Training loss: 2.217224359512329
Validation loss: 2.11670163882676

Epoch: 5| Step: 3
Training loss: 1.3372193574905396
Validation loss: 2.0866607107141966

Epoch: 5| Step: 4
Training loss: 1.820068359375
Validation loss: 2.074943155370733

Epoch: 5| Step: 5
Training loss: 1.6576282978057861
Validation loss: 2.0789333158923733

Epoch: 5| Step: 6
Training loss: 1.7053020000457764
Validation loss: 2.08013948317497

Epoch: 5| Step: 7
Training loss: 1.4621326923370361
Validation loss: 2.0809388724706506

Epoch: 5| Step: 8
Training loss: 1.938551664352417
Validation loss: 2.0974745750427246

Epoch: 5| Step: 9
Training loss: 1.17389976978302
Validation loss: 2.0933498861969158

Epoch: 5| Step: 10
Training loss: 2.3172998428344727
Validation loss: 2.1467302845370386

Epoch: 346| Step: 0
Training loss: 1.690626859664917
Validation loss: 2.1534000596692486

Epoch: 5| Step: 1
Training loss: 1.4621983766555786
Validation loss: 2.1351233143960275

Epoch: 5| Step: 2
Training loss: 1.7030487060546875
Validation loss: 2.125365598227388

Epoch: 5| Step: 3
Training loss: 1.789170265197754
Validation loss: 2.145941739441246

Epoch: 5| Step: 4
Training loss: 2.0952115058898926
Validation loss: 2.1262029281226535

Epoch: 5| Step: 5
Training loss: 1.2998186349868774
Validation loss: 2.1117980685285342

Epoch: 5| Step: 6
Training loss: 1.9536504745483398
Validation loss: 2.1009368217119606

Epoch: 5| Step: 7
Training loss: 1.4254474639892578
Validation loss: 2.0990503782867105

Epoch: 5| Step: 8
Training loss: 1.8111438751220703
Validation loss: 2.0897879562070294

Epoch: 5| Step: 9
Training loss: 1.987876534461975
Validation loss: 2.0797456413187008

Epoch: 5| Step: 10
Training loss: 2.104548215866089
Validation loss: 2.0885569023829635

Epoch: 347| Step: 0
Training loss: 1.270214319229126
Validation loss: 2.0824693582391225

Epoch: 5| Step: 1
Training loss: 1.7670042514801025
Validation loss: 2.0618550239070768

Epoch: 5| Step: 2
Training loss: 0.9849093556404114
Validation loss: 2.051075639263276

Epoch: 5| Step: 3
Training loss: 2.1621499061584473
Validation loss: 2.0527370796408704

Epoch: 5| Step: 4
Training loss: 1.977594017982483
Validation loss: 2.054181191229051

Epoch: 5| Step: 5
Training loss: 2.0876359939575195
Validation loss: 2.085567988375182

Epoch: 5| Step: 6
Training loss: 1.8311971426010132
Validation loss: 2.0820891370055494

Epoch: 5| Step: 7
Training loss: 1.9554249048233032
Validation loss: 2.100374872966479

Epoch: 5| Step: 8
Training loss: 1.5246961116790771
Validation loss: 2.131161812813051

Epoch: 5| Step: 9
Training loss: 1.568792700767517
Validation loss: 2.128117822831677

Epoch: 5| Step: 10
Training loss: 2.0389564037323
Validation loss: 2.1216313146775767

Epoch: 348| Step: 0
Training loss: 1.4616625308990479
Validation loss: 2.1452352218730475

Epoch: 5| Step: 1
Training loss: 1.4805850982666016
Validation loss: 2.139264346450888

Epoch: 5| Step: 2
Training loss: 1.9631000757217407
Validation loss: 2.143673686571019

Epoch: 5| Step: 3
Training loss: 1.892565369606018
Validation loss: 2.127895498788485

Epoch: 5| Step: 4
Training loss: 1.9232673645019531
Validation loss: 2.146900398756868

Epoch: 5| Step: 5
Training loss: 1.6203155517578125
Validation loss: 2.1303396994067776

Epoch: 5| Step: 6
Training loss: 1.5478545427322388
Validation loss: 2.1161671582088677

Epoch: 5| Step: 7
Training loss: 2.4466552734375
Validation loss: 2.113385708101334

Epoch: 5| Step: 8
Training loss: 1.2449153661727905
Validation loss: 2.1162769922646145

Epoch: 5| Step: 9
Training loss: 1.9841617345809937
Validation loss: 2.1087390145947857

Epoch: 5| Step: 10
Training loss: 1.4685757160186768
Validation loss: 2.089243386381416

Epoch: 349| Step: 0
Training loss: 1.8436691761016846
Validation loss: 2.1134895342652515

Epoch: 5| Step: 1
Training loss: 1.9809811115264893
Validation loss: 2.126735350137116

Epoch: 5| Step: 2
Training loss: 2.3676533699035645
Validation loss: 2.13647618345035

Epoch: 5| Step: 3
Training loss: 1.3038526773452759
Validation loss: 2.1436028967621508

Epoch: 5| Step: 4
Training loss: 2.07057523727417
Validation loss: 2.136617683595227

Epoch: 5| Step: 5
Training loss: 1.368238091468811
Validation loss: 2.1324009126232517

Epoch: 5| Step: 6
Training loss: 1.9291422367095947
Validation loss: 2.108248314549846

Epoch: 5| Step: 7
Training loss: 2.1489713191986084
Validation loss: 2.0948886717519453

Epoch: 5| Step: 8
Training loss: 0.9085966944694519
Validation loss: 2.0923325797562957

Epoch: 5| Step: 9
Training loss: 1.6535733938217163
Validation loss: 2.0910891602116246

Epoch: 5| Step: 10
Training loss: 1.797735571861267
Validation loss: 2.06873228216684

Epoch: 350| Step: 0
Training loss: 2.319592237472534
Validation loss: 2.0865800919071322

Epoch: 5| Step: 1
Training loss: 1.4980385303497314
Validation loss: 2.1321737945720716

Epoch: 5| Step: 2
Training loss: 1.0710361003875732
Validation loss: 2.151194562194168

Epoch: 5| Step: 3
Training loss: 1.7358919382095337
Validation loss: 2.1882093773093274

Epoch: 5| Step: 4
Training loss: 1.8969452381134033
Validation loss: 2.2183390137969807

Epoch: 5| Step: 5
Training loss: 1.7216596603393555
Validation loss: 2.2319178555601384

Epoch: 5| Step: 6
Training loss: 2.3076493740081787
Validation loss: 2.195731432207169

Epoch: 5| Step: 7
Training loss: 1.7050988674163818
Validation loss: 2.1516034526209675

Epoch: 5| Step: 8
Training loss: 1.6343988180160522
Validation loss: 2.1356218989177416

Epoch: 5| Step: 9
Training loss: 1.6588077545166016
Validation loss: 2.1019993905098207

Epoch: 5| Step: 10
Training loss: 1.8009183406829834
Validation loss: 2.05836683575825

Testing loss: 2.3281393316056995
